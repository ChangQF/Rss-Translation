<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 13 May 2024 15:16:00 GMT</lastBuildDate>
    <item>
      <title>在huggingface模型中哪里可以找到CLS代币？</title>
      <link>https://stackoverflow.com/questions/78473151/where-to-find-cls-token-in-huggingface-models</link>
      <description><![CDATA[我正在关注这个kaggle笔记本  并使用不同的模型（例如 Bert、Distilbert、Xlnet、Roberta 等）进行文本分类。我看到本笔记本的作者使用不同的代码从不同的模型获取 CLS 令牌。例如，
对于伯特[1]-
transformer_bert_model = TFBertModel.from_pretrained(&#39;bert-base-uncased&#39;, config = config)
伯特 = Transformer_bert_model.layers[0]
bert_model = bert(输入)[1]

对于 Distilbert [:,0,:]-
transformer_distilbert_model = TFDistilBertModel.from_pretrained(&#39;distilbert-base-uncased&#39;, config = config)
distilbert = Transformer_distilbert_model.layers[0]
distilbert_model = distilbert(输入)[0][:,0,:]

对于 XLNet [:, -1:, :]-
transformer_xlnet_model = TFXLNetModel.from_pretrained(&#39;xlnet-base-cased&#39;, config = config)
xlnet = Transformer_xlnet_model.layers[0]
xlnet_model = xlnet(输入)[0]
xlnet_model = tf.squeeze(xlnet_model[:, -1:, :], axis=1)

如何知道使用什么切片代码？有什么方法可以获取正确的 CLS 令牌或类似的东西吗？例如，如果我想使用不同的模型，例如 TheBritishLibrary/bl-books-genre 如何获取 CLS 令牌？
&lt;小时/&gt;
PS。我对变压器的理解有限，不知道这个问题是否有意义。]]></description>
      <guid>https://stackoverflow.com/questions/78473151/where-to-find-cls-token-in-huggingface-models</guid>
      <pubDate>Mon, 13 May 2024 14:59:31 GMT</pubDate>
    </item>
    <item>
      <title>在深度训练/验证循环期间使用分层 k 折叠时出现越界错误</title>
      <link>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</guid>
      <pubDate>Mon, 13 May 2024 14:43:39 GMT</pubDate>
    </item>
    <item>
      <title>MSE 高且 R 方值为负的原因</title>
      <link>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</guid>
      <pubDate>Mon, 13 May 2024 14:10:35 GMT</pubDate>
    </item>
    <item>
      <title>预测社交媒体参与率的最佳机器学习模型</title>
      <link>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</link>
      <description><![CDATA[根据你们的意见，哪个模型是预测社交媒体（例如 Facebook）中参与度帖子的最佳模型。
如果你们中有人遇到过同样的情况，请分享一下您的经验
谢谢
我尝试了这两个：

线性回归（11% 准确度）

LightGBM 回归器（准确度 79%）

]]></description>
      <guid>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</guid>
      <pubDate>Mon, 13 May 2024 13:59:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么二元分类中非 sigmoid 变换输出比 sigmoid 变换输出更匹配目标矩阵？</title>
      <link>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</link>
      <description><![CDATA[我正在使用神经网络进行二元分类任务，其中模型输出 logits，然后通过 sigmoid 函数将其映射到概率。目标矩阵是一个 17x17 网格，其中距中心曼哈顿距离 &lt;=2 内的单元格标记为 1（正类），所有其他单元格标记为 0（负类）：
目标矩阵
这是损失的代码。我使用 binary_cross_entropy_with_logits 作为我的损失函数。 sigmoid函数在pytorch提供的上述函数中实现：
 defforward(自身，输入，目标)：
        pos_mask =（目标== 1）
        neg_mask =（目标== 0）
        pos_num = pos_mask.sum().float()
        neg_num = neg_mask.sum().float()
        重量 = target.new_zeros(target.size())
        权重[pos_mask] = 1 / pos_num
        权重[neg_mask] = 1 / neg_num * self.neg_weight
        重量 /= 重量.sum()
        返回 F.binary_cross_entropy_with_logits(
            输入，目标，权重，减少=&#39;总和&#39;）

然后我可视化训练模型的输出，并注意到一个意想不到的现象。可视化显示了两张图像：一张是模型直接输出的 logits（左），另一张是通过对这些 logits 应用 sigmoid 函数获得的概率（右）。令人惊讶的是，与 sigmoid 变换输出（概率）相比，非 sigmoid 变换输出（logits）似乎更好地匹配目标矩阵的模式。
可视化
这个结果令人费解，因为在训练过程中，损失函数对 sigmoid 变换后的概率进行运算。因此，人们会期望 sigmoid 变换的输出更接近目标矩阵。
这种行为背后是否存在解释或常见原因，即原始逻辑在视觉上比从其派生的概率更准确地匹配目标结构？我可能缺少任何可能影响此外观的可视化或缩放因素吗？
我在网上搜索过，但似乎没有与我类似的问题。我仔细检查了 binary_cross_entropy_with_logits 中是否存在 sigmoid 函数：
labels = self._create_labels(responses.size())
loss = self.criterion(responses, labels) # 标准：binary_cross_entropy_with_logits

_responses = torch.sigmoid(responses)
_loss = self._criterion(_responses, labels) # 标准：binary_cross_entropy

但是，在我的实验中，loss 等于 _loss，这意味着虽然是 sigmoided 响应尝试拟合目标矩阵，但非 sigmoided 响应却拟合目标矩阵目标矩阵更好。
&lt;小时/&gt;
如果您想了解有关该项目的更多详细信息，请参阅以下描述。我正在使用 SiamFC 重现一个对象跟踪项目，可视化 siamfc 中第 171 行的响应图-pytorch/siamfc/siamfc.py，作为反应图，反映第一帧中的groundtruth目标与后续帧中的搜索区域之间的相似性。您可以在项目中下载预训练的模型，插入一些代码进行可视化并运行代码查看结果。]]></description>
      <guid>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</guid>
      <pubDate>Mon, 13 May 2024 13:45:05 GMT</pubDate>
    </item>
    <item>
      <title>如何创建我自己的自定义输入器以在 pyspark.ml 管道中无缝输入常量值</title>
      <link>https://stackoverflow.com/questions/78472581/how-to-create-my-own-custom-imputter-to-input-constant-values-seamlessly-in-pysp</link>
      <description><![CDATA[我想通过 CV 搜索来优化数据集上缺失值的插补。这在我熟悉的 sklearn 中是微不足道的——但是，我是第一次使用集群分布式 Spark 数据帧，并且必须使用 pyspark.ml 模块。
据我所知， pyspark.ml.feature.Imputer 类无法估算（选择）常量值，这是我想测试的一件事。
您建议我如何执行此操作？我研究了编写一个自定义转换器，这在 sklearn API 中也很容易，但我还没有在 pyspark.ml 中找到明确的方法来做到这一点。
非常感谢任何见解。]]></description>
      <guid>https://stackoverflow.com/questions/78472581/how-to-create-my-own-custom-imputter-to-input-constant-values-seamlessly-in-pysp</guid>
      <pubDate>Mon, 13 May 2024 13:26:04 GMT</pubDate>
    </item>
    <item>
      <title>易于计算机器学习算法的决策边界[关闭]</title>
      <link>https://stackoverflow.com/questions/78471748/easy-to-compute-decision-boundaries-of-a-machine-learning-algorithm</link>
      <description><![CDATA[可用于精确计算数值数据的 2D 或 ND 分类的决策边界的最佳机器学习算法是什么。我对分类的性能不感兴趣，而是对决策边界的简单性和计算时间感兴趣。我已经将 SVM 与 sk-learn 一起使用，但它只返回每条线的方程，而不返回界定 2D 类的多边形。我感兴趣的是提取每个类别的最终分类的多边形或确切形状。
非常感谢。
我尝试了 SVM，但库没有提供解决方案。我期待一种有监督的机器学习算法，具有易于提取决策边界的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78471748/easy-to-compute-decision-boundaries-of-a-machine-learning-algorithm</guid>
      <pubDate>Mon, 13 May 2024 10:49:18 GMT</pubDate>
    </item>
    <item>
      <title>我需要 ph2 数据集用于分类项目</title>
      <link>https://stackoverflow.com/questions/78471681/i-need-ph2-data-set-for-classification-project</link>
      <description><![CDATA[我在大学有一个关于人工智能的项目“ ph2数据集中的分类和深度学习但是我无法找到适合这个项目的数据，因为Kaggle中的数据只是图片，不包含样本是否患病的信息。谁有合适的数据？
我意识到除了有人已经在使用这个数据集之外没有其他解决方案，因为我没有时间在大学展示该项目]]></description>
      <guid>https://stackoverflow.com/questions/78471681/i-need-ph2-data-set-for-classification-project</guid>
      <pubDate>Mon, 13 May 2024 10:38:48 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林模型进行多目标预测的误差</title>
      <link>https://stackoverflow.com/questions/78471569/error-in-multi-objective-prediction-using-random-forest-model</link>
      <description><![CDATA[以下是实际流程

原始混凝土配合比的实验数据为1000块，采用的算法模型为随机森林回归模型。

以下代码用于创建模型、训练模型、预测目标值和优化 Optuna。


通过多重预测多个输出项时如何优化参数，使RMSE拟合值接近0输入项目？ 
RMSE的拟合指数为27.781625571862275。]]></description>
      <guid>https://stackoverflow.com/questions/78471569/error-in-multi-objective-prediction-using-random-forest-model</guid>
      <pubDate>Mon, 13 May 2024 10:17:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOv5 标记对象的正确方法</title>
      <link>https://stackoverflow.com/questions/78471070/correct-way-to-tag-objects-with-yolov5</link>
      <description><![CDATA[我需要标记一系列图像以用于织物上的缝纫检测。我使用 YOLOv5 算法。
我遇到的问题是，我不清楚标记这些缝纫的最佳方式应该是什么。
下图显示了织物中的缝线。

正如您在图片中看到的，缝线总是会占据布料的整个宽度。最初，我曾想过对缝纫的几个部分/部分进行标记（检测到的缝纫数量并不重要，对我来说真正重要的是它检测到至少有一个缝纫）。下图展示了这个想法：

但是，我不清楚这是否是正确的方法（而是最佳方法），或者应该创建一个完全包围缝纫的单个标签。
另一方面，根据文档中给出的标签提示，标签应该恰好包围要检测的对象，在对象和标签的边界框之间留出尽可能小的空间。
&lt;块引用&gt;
标签准确性。标签必须紧密包围每个对象。没有空间
应该存在于对象与其边界框之间。没有物体
应该缺少标签。

获得最佳训练结果的提示
在这种特殊情况下，考虑到缝线总是以非常相似的方式出现（它们总是具有水平方向），这些标签将非常薄（高度很小），因此不清楚我认为该算法将能够检测到它们。以我的拙见，我认为稍微增加标签的高度将使算法更有效地检测缝纫，因为通过这些缝纫连接的织物可能具有相同的颜色。 （第二张图片显示了我正在谈论的想法）。
如果您能帮助我并告诉我进行此标记的最佳方法，我将不胜感激。
提前非常感谢您。]]></description>
      <guid>https://stackoverflow.com/questions/78471070/correct-way-to-tag-objects-with-yolov5</guid>
      <pubDate>Mon, 13 May 2024 08:48:35 GMT</pubDate>
    </item>
    <item>
      <title>我如何进一步推进这个 AI/ML 项目？</title>
      <link>https://stackoverflow.com/questions/78469835/how-can-i-proceed-further-in-this-ai-ml-project</link>
      <description><![CDATA[我有 10 个数据集 (.csv)，每个数据集有 100,000 行，每行包含 5 个输入（-4.0f 到 +4.0f）和一个输出列 (0/1)。我想使用它来训练神经网络并预测给定的测试数据集（也有 100,000 行，但没有填充输出列）。
我想创建一个 5--(reLU)--&gt; 32 --(reLU)--&gt; 32 --（乙状结肠） --&gt; 1 个神经网络并用这样的奖励系统对其进行训练 [if (expec.op ==0)reward=1- o/pfromNN; if (expec.op ==1) 奖励= o/pfromNN].
如何使用此调整 NN 的权重或如何进一步进行？我是 NN 的新手。
我想过像体育馆的月球着陆器模块一样这样做，但由于这里没有涉及任何州，我很困惑]]></description>
      <guid>https://stackoverflow.com/questions/78469835/how-can-i-proceed-further-in-this-ai-ml-project</guid>
      <pubDate>Mon, 13 May 2024 02:25:15 GMT</pubDate>
    </item>
    <item>
      <title>准确的时间序列异常检测[关闭]</title>
      <link>https://stackoverflow.com/questions/78469052/accurate-time-series-anomaly-detection</link>
      <description><![CDATA[尝试以最高精度对时间序列数据执行异常检测。您最近遇到的任何框架或 python 库。或者请告诉我您遇到过或使用过的最好的图书馆。
尝试过像 PyCaret 这样的库，但错误率很高。]]></description>
      <guid>https://stackoverflow.com/questions/78469052/accurate-time-series-anomaly-detection</guid>
      <pubDate>Sun, 12 May 2024 19:18:40 GMT</pubDate>
    </item>
    <item>
      <title>Yolo 模型中的增量分类器和表示学习</title>
      <link>https://stackoverflow.com/questions/78448470/incremental-classifier-and-representation-learning-in-yolo-models</link>
      <description><![CDATA[我的 YOLO 模型遇到问题。
最初，我用 7 个类对其进行了训练。现在，我想向模型添加 4 个新类。然而，当我将原始 7 个类别的数据与新的 4 个类别的数据结合起来时，训练时间和相关的云成本显着增加。有什么好的解决方案可以有效地将这些额外的类合并到模型中而不增加训练时间和成本？
我的期望是减少增量学习的成本和培训时间。]]></description>
      <guid>https://stackoverflow.com/questions/78448470/incremental-classifier-and-representation-learning-in-yolo-models</guid>
      <pubDate>Wed, 08 May 2024 12:20:14 GMT</pubDate>
    </item>
    <item>
      <title>训练 DL 模型时，本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束</title>
      <link>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</link>
      <description><![CDATA[我正在创建一个植物病害识别模型。我有一个包含 38 种疾病的数据集，每种疾病有大约 2000 张图像。但是在训练模型时，由于一些 OUT_OF_RANGE 错误，一些时期被跳过。有人可以帮我解决这个问题吗？
导入操作系统
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、展平、密集、输入

train_dir = &#39;数据集/火车&#39;
valid_dir = &#39;数据集/有效&#39;
批量大小 = 32

train_datagen = 图像数据生成器(
    重新缩放=1./255，
    旋转范围=40，
    宽度偏移范围=0.2，
    height_shift_range=0.2，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真，
    fill_mode=&#39;最近&#39;
）

valid_datagen = ImageDataGenerator(重新缩放=1./255)

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

valid_generator = valid_datagen.flow_from_directory(
    有效目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

模型=顺序（[
    输入(形状=(150, 150, 3)),
    Conv2D(32, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    展平（），
    密集（512，激活=&#39;relu&#39;），
    Dense(38,activation=&#39;softmax&#39;) # 根据疾病类别的数量调整输出单位
]）

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=10，
    验证数据=有效生成器，
    valid_steps=valid_generator.samples // 批量大小
）

model.save(&#39;plant_disease_model.h5&#39;)

class_indices = train_generator.class_indices
疾病名称 = 列表(class_indices.keys())
print(“类索引到疾病名称的映射：”, class_indices)

终端：
找到属于 38 个类别的 70295 个图像。
找到属于 38 个类别的 17572 张图像。
2024-04-23 19：50：32.085744：我tensorflow / core / platform / cpu_feature_guard.cc：210]此TensorFlow二进制文件经过优化以使用可用的CPU仪器
性能关键操作中的操作。
要启用以下指令：AVX2 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
纪元 1/10
\.venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.p
y：120：用户警告：您的“PyDataset”类应在其构造函数中调用“super().__init__(**kwargs)”。 `**kwargs` 可以包括 `workers`、`use_m
ultiprocessing`、`max_queue_size`。不要将这些参数传递给“fit()”，因为它们将被忽略。
  self._warn_if_super_not_used()
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m905s←[0m 411ms/步]]准确度：0.4608 - 损失：1.8737 - val_accuracy：0.7432 - val_
损失：0.8556
纪元 2/10
←[1m 1/2196←[0m ←[37m–––––––––––––––––––←[0m ←[1m12:02←[0m 329ms/步 - 精度: 0.6875] -损失：0.78202024-04-23 20:05:37.996528：W张量
ow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束
         [[{{节点It​​eratorGetNext}}]]
C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py:155: UserWarning: 您的输入数据不足；中断训练。嘛
确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次。您可能需要使用`.repeat()`函数
构建您的数据集。
  self.gen.throw（类型，值，回溯）
2024-04-23 20:05:38.068817：W tensorflow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：结束
顺序
         [[{{节点It​​eratorGetNext}}]]
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m0s←[0m 49us/步]]准确度：0.6875 - 损失：0.7820 - val_accuracy：0.7500 - val_los
秒：0.2462

如上所示，epoch 1 已成功完成，但 epoch 2 由于某些错误而终止。同样，epoch 3、5、7、9 成功完成，但 epoch 4、6、8、10 出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</guid>
      <pubDate>Wed, 24 Apr 2024 06:27:20 GMT</pubDate>
    </item>
    <item>
      <title>scikit 学习 1.1.3。 import 无法在 python 中导入名称“METRIC_MAPPING64”</title>
      <link>https://stackoverflow.com/questions/78327535/scikit-learn-1-1-3-import-cannot-import-name-metric-mapping64-in-python</link>
      <description><![CDATA[我试图将 scikit-learn 中的线性模型导入到 vscode 中的 python 代码中，但收到意外的错误消息。
导入sklearn
从sklearn导入线性模型

错误：
无法从“sklearn.metrics._dist_metrics”导入名称“METRIC_MAPPING64”

我不想导入这些指标，如何解决这个问题？
使用的scikit-learn版本是1.1.3。]]></description>
      <guid>https://stackoverflow.com/questions/78327535/scikit-learn-1-1-3-import-cannot-import-name-metric-mapping64-in-python</guid>
      <pubDate>Mon, 15 Apr 2024 09:54:33 GMT</pubDate>
    </item>
    </channel>
</rss>