<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 30 Jan 2024 15:13:53 GMT</lastBuildDate>
    <item>
      <title>拟合模型需要多少时间</title>
      <link>https://stackoverflow.com/questions/77907135/how-much-time-required-to-fit-a-model</link>
      <description><![CDATA[我想计算每个模型（LR、DS、KNN、SVM、ANN）的时间复杂度，以找出与时间相比具有最佳精度的最佳模型。为此，我实现了代码。
start_time = perf_counter()
logModel = LogisticRegression()
logModel.fit(X_train, Y_train)

#训练数据的准确性
x_train_prediction = logModel.predict(X_train)
训练数据准确度=准确度分数（x_train_预测，Y_train）
print(&#39;训练数据的准确性：,&#39;,training_data_accuracy)

# 测试数据的准确性
x_test_prediction = logModel.predict(X_test)
test_data_accuracy=accuracy_score(x_test_prediction,Y_test)
print(&#39;测试数据的准确度得分：&#39; ,test_data_accuracy)
生成_模型_报告（Y_测试，x_测试_预测）
结束时间 = perf_counter()
经过时间 = 结束时间 - 开始时间

print(&quot;经过时间：&quot;,elapsed_time)

在此代码中，我使用 elapsed_time 来计算逻辑回归模型所需的时间。我的代码可以计算时间吗？]]></description>
      <guid>https://stackoverflow.com/questions/77907135/how-much-time-required-to-fit-a-model</guid>
      <pubDate>Tue, 30 Jan 2024 14:33:04 GMT</pubDate>
    </item>
    <item>
      <title>sklearn“transform_output”设置在 Flask 应用程序上下文和请求上下文中不同</title>
      <link>https://stackoverflow.com/questions/77907033/sklearn-transform-output-setting-different-in-flask-application-context-v-requ</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77907033/sklearn-transform-output-setting-different-in-flask-application-context-v-requ</guid>
      <pubDate>Tue, 30 Jan 2024 14:17:46 GMT</pubDate>
    </item>
    <item>
      <title>如何向 NEAT 输入节点提供非浮点值</title>
      <link>https://stackoverflow.com/questions/77906768/how-to-provide-non-float-values-to-neat-input-nodes</link>
      <description><![CDATA[我试图使用 CV2 将图像的 RGB 通道提供给 python 中的 NEAT 算法，将图像分割为表示为数组的三个通道。
图像 = cv2.imread(cell)
cv2.imshow(“细胞”,图像)
蓝色通道、红色通道、绿色通道 = cv2.split(图像)
net.activate((blueChannel.tolist(),greenChannel.tolist(),redChannel.tolist()))

但是，当我这样做时，我收到错误
无法将序列乘以“float”类型的非 int

据我了解，这意味着我的所有输入都需要是 float 或 int 值。
如何向神经网络提供非浮点或整数值的输入？]]></description>
      <guid>https://stackoverflow.com/questions/77906768/how-to-provide-non-float-values-to-neat-input-nodes</guid>
      <pubDate>Tue, 30 Jan 2024 13:38:31 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 Predict() 中开始和结束日期的 ARIMA 错误？</title>
      <link>https://stackoverflow.com/questions/77906749/how-to-fix-the-arima-error-for-start-and-end-dates-in-predict</link>
      <description><![CDATA[我正在使用时间序列数据来预测可可的价值。
数据集：https://raw.githubusercontent.com /nunesisabella/Analise-Preditiv-Cacau/main/ICCO_2010_2023.csv
我已经成功定义和训练了模型，但是当我尝试根据测试数据集索引设置开始和结束日期来进行预测时，出现以下错误：
KeyError：“‘start’参数无法与与数据索引相关的位置匹配。”

我认为发生错误是因为我的数据集中的日期仅包括工作日，当我尝试进行预测时，我无法解释这一点。考虑到我的数据集中不存在某些日期，如何进行预测？
我的代码的模型部分如下：
从 statsmodels.tsa.arima.model 导入 ARIMA

df = pd.read_csv(&#39;https://raw.githubusercontent.com/nunesisabella/Analise-Preditiv-Cacau/main/ICCO_2010_2023.csv&#39;,sep=&quot;&quot;)

df[&quot;ICCO_USD&quot;] = df[&quot;ICCO_USD&quot;].str.replace(&quot;,&quot;, &quot;&quot;).astype(float)
df[&#39;Data&#39;] = pd.to_datetime(df[&#39;Data&#39;], format=&#39;%d.%m.%Y&#39;)
df.set_index(&#39;数据&#39;, inplace=True)
df = df.sort_values(&#39;数据&#39;)

火车 = df.loc[df.index &lt; &#39;01-01-2020&#39;]
测试 = df.loc[df.index &gt;= &#39;01-01-2020&#39;]

ARIMA_model = ARIMA(火车, 顺序=(2,1,2))
ARIMA_fit = ARIMA_model.fit()
测试[&#39;预测&#39;] = ARIMA_fit.predict(start=test.index[0], end=test.index[-1])
]]></description>
      <guid>https://stackoverflow.com/questions/77906749/how-to-fix-the-arima-error-for-start-and-end-dates-in-predict</guid>
      <pubDate>Tue, 30 Jan 2024 13:36:09 GMT</pubDate>
    </item>
    <item>
      <title>为什么令牌嵌入与 BartForConditionalGeneration 模型的嵌入不同</title>
      <link>https://stackoverflow.com/questions/77906649/why-token-embedding-different-from-the-embedding-by-the-bartforconditionalgenera</link>
      <description><![CDATA[为什么即使我使用相同的 BartForConditionalGenration 模型生成嵌入，它们仍然不同？
第一个嵌入是通过组合令牌嵌入和位置嵌入生成的
embed_pos = modelBART.model.encoder.embed_positions(input_ids.input_ids)
input_embeds = modelBART.model.encoder.embed_tokens(input_ids.input_ids)

模型的第二次嵌入
输出 = modelBART(input_ids.input_ids)
print(&quot;\n\n 输出：\n\n&quot;,output.encoder_last_hidden_​​state)

第一个和第二个的嵌入不应该相同吗？如何使第一个和第二个嵌入的差异为零？]]></description>
      <guid>https://stackoverflow.com/questions/77906649/why-token-embedding-different-from-the-embedding-by-the-bartforconditionalgenera</guid>
      <pubDate>Tue, 30 Jan 2024 13:18:34 GMT</pubDate>
    </item>
    <item>
      <title>读取条码前如何提高图像质量</title>
      <link>https://stackoverflow.com/questions/77906456/how-to-improve-image-quality-before-reading-barcode</link>
      <description><![CDATA[我正在使用 zxing-cpp 库从图像中读取条形码。
&lt;前&gt;&lt;代码&gt;导入cv2
导入zxingcpp

img = cv2.imread(&#39;test.jpg&#39;)
结果= zxingcpp.read_barcodes(img)
对于结果中的结果：
    print(&#39;找到条形码：&#39;
    f&#39;\n 有效：“{result.valid}”&#39;
        f&#39;\n 文本：“{结果.文本}”&#39;
        f&#39;\n 格式：{结果.格式}&#39;
        f&#39;\n 内容：{result.content_type}&#39;
        f&#39;\n 位置：{结果.位置}&#39;)
如果 len(结果) == 0:
    print(“找不到任何条形码。”)

但是，该库无法从 图片。
如何处理图像并提高图像质量以便读取条形码？
我使用了这个问题的答案作为指南，但仍然不成功，因此我提出这个问题并寻求帮助？]]></description>
      <guid>https://stackoverflow.com/questions/77906456/how-to-improve-image-quality-before-reading-barcode</guid>
      <pubDate>Tue, 30 Jan 2024 12:45:45 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：Python ARIMA 实现中需要解压的值太多（预期为 3）</title>
      <link>https://stackoverflow.com/questions/77906395/valueerror-too-many-values-to-unpack-expected-3-in-python-arima-implementatio</link>
      <description><![CDATA[我正在尝试创建一个 ARIMA 模型来预测股票市场价值（对此进行实验，不会在现实生活中使用它）并将其以 PNG 格式导出，用于我的数据集中的所有 512 只股票。在 PNG 中将显示实际值和预测值。
错误：
预测，stderr，conf_int = model_fit.forecast(steps=len(X_test))
ValueError：需要解包的值太多（预期为 3）

导入操作系统
将 pandas 导入为 pd
从 statsmodels.tsa.arima.model 导入 ARIMA

# 加载训练和测试数据。
train_df = pd.read_csv(r&#39;mypath\train.csv&#39;, parse_dates=[&#39;日期时间&#39;])
test_df = pd.read_csv(r&#39;mypath\test.csv&#39;, parse_dates=[&#39;datetime&#39;])

# 获取独特的股票名称。
stock = train_df[&#39;公司简称&#39;].unique()

# 创建一个目录来保存png。
输出目录 = r&#39;ARIMAprediction&#39;
os.makedirs（输出目录，exist_ok = True）

对于股票中的股票：
    print(f&quot;处理库存：{stock}&quot;)

    # 过滤当前股票的数据。
    train_stock = train_df[train_df[&#39;公司简称&#39;] == stock]
    test_stock = test_df[test_df[&#39;公司简称&#39;] == stock]

    # 提取特征（为此，使用所有数据集）。
    features = [&#39;开盘价&#39;, &#39;最高价&#39;, &#39;最低价&#39;, &#39;收盘价&#39;, &#39;成交量&#39;]
    X_train, y_train = train_stock[特征], train_stock[&#39;关闭&#39;]
    X_test, y_test = test_stock[功能], test_stock[&#39;关闭&#39;]

    # 拟合ARIMA模型
    顺序 = (5, 1, 2)
    模型 = ARIMA(y_train, 阶数=阶数)
    model_fit = model.fit()

    ＃ 预言。
    预测，stderr，conf_int = model_fit.forecast（steps=len（X_test））
]]></description>
      <guid>https://stackoverflow.com/questions/77906395/valueerror-too-many-values-to-unpack-expected-3-in-python-arima-implementatio</guid>
      <pubDate>Tue, 30 Jan 2024 12:35:43 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace Transformers ValueError：训练 Roberta 模型时没有足够的值来解包（预期为 2，得到 1）</title>
      <link>https://stackoverflow.com/questions/77906314/huggingface-transformers-valueerror-not-enough-values-to-unpack-expected-2-go</link>
      <description><![CDATA[我正在尝试使用 Hugging Face Transformers 库训练 Roberta 模型。我的Python代码如下：
# 来自train_prompt_model.py的相关代码
# ...

# 加载预训练模型和分词器
model_type =“CLTL/MedRoBERTa.nl”
模型 = AutoModelForCausalLM.from_pretrained(model_type)
tokenizer = AutoTokenizer.from_pretrained(model_type)
如果 tokenizer.pad_token 为 None：
    tokenizer.pad_token = tokenizer.eos_token


# 加载数据集
def gen() -&gt;;字典：
    &#39;&#39;&#39;
    读取路径中的 json 文件并生成每一行。
    &#39;&#39;&#39;
    使用 open(&#39;datasets/HealthCareMagic-100k/HealthCareMagic100k.json&#39;, &#39;r&#39;) 作为 f：
        对于 f 中的行：
            行= json.loads(行)
            产量{“上下文”：行[“system_prompt”]，“提示”：行[“question_text”]，“输出”：行[“orig_answer_texts”]}

def preprocess_function（示例）：
    文本 = &#39; &#39;.join(example[&#39;context&#39;]) + &#39; &#39; + &#39; &#39;.join(example[&#39;prompt&#39;])
    目标=示例[&#39;输出&#39;]
    model_inputs = tokenizer(文本, 截断=True, 填充=“max_length”, max_length=1000)
    model_inputs[“labels”] = tokenizer(target, truncation=True, padding=“max_length”, max_length=1000)[“input_ids”]
    
    返回模型输入

# ...

# 定义训练参数并实例化 Trainer
训练参数 = 训练参数（
    output_dir=“测试训练器”，
    evaluation_strategy=“纪元”，
    per_device_train_batch_size=16，
    per_device_eval_batch_size=64，
）

教练=教练（
    型号=型号，
    参数=训练参数，
    训练数据集=训练数据集，
    eval_dataset = test_dataset，
    计算指标=计算指标，
    data_collat​​or = data_collat​​or，
）

训练师.train()

但是，当我运行脚本时，出现以下错误：
ValueError：没有足够的值来解压（预期为 2，得到 1）

该错误似乎源自 Transformers 库中的这一行（.env/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py）：
batch_size, seq_length = input_shape

我不确定是什么导致了这个错误。看起来 input_shape 变量只有一个值，而预期它有两个值。关于可能导致此问题的原因以及如何解决它有什么想法吗？
我尝试打印 input_shape 值，但这会产生 torch.Size([16])。这对应于批量大小，但我不明白应该如何重新调整它（我假设）才能传递给模型。非常感谢任何帮助！
NB 我的数据最初格式如下：{“context”, “prompt”, “output”}]]></description>
      <guid>https://stackoverflow.com/questions/77906314/huggingface-transformers-valueerror-not-enough-values-to-unpack-expected-2-go</guid>
      <pubDate>Tue, 30 Jan 2024 12:22:48 GMT</pubDate>
    </item>
    <item>
      <title>考虑到所分析的问题，LSTM 的输入形状是否正确？</title>
      <link>https://stackoverflow.com/questions/77905948/is-the-input-shape-for-the-lstm-correct-considering-the-problem-under-analysis</link>
      <description><![CDATA[我有一个数据集，其中包含 5000 个模拟 x 21 个时间步长 x 49 个节点，总共 5145000 个观测值。该数据集是基于有限元模拟创建的。我正在尝试使用 LSTM 来预测每个节点的 x、y、z 坐标（每个节点对应一个观察值）。
&lt;前&gt;&lt;代码&gt;OUTPUT_SHAPE = 3

模型=顺序（）
model.add(LSTM(num_neurons,activation=activation_function,input_shape=(x_train.shape[1],x_train.shape[2])))
model.add（密集（OUTPUT_SHAPE））

模型.编译(
    损失=“平均绝对误差”，
    优化器=tf.keras.optimizers.Adam(learning_rate=learning_rate),
    指标=[“平均绝对误差”]
）

以下是 1 次模拟的数据集示例：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

时间
节点位置
壮举3
壮举4
壮举5
壮举6
壮举7
壮举8
壮举9
壮举10


&lt;正文&gt;

0
0
...
...
...
...
...
...
...
...


0
1
...
...
...
...
...
...
...
...


...
...
...
...
...
...
...
...
...
...


0
48
...
...
...
...
...
...
...
...


--------
--------
--------
--------
--------
--------
--------
--------
--------
--------


...
...
...
...
...
...
...
...
...
...


--------
--------
--------
--------
--------
--------
--------
--------
--------
--------


20
0
...
...
...
...
...
...
...
...


20
1
...
...
...
...
...
...
...
...


...
...
...
...
...
...
...
...
...
...


20
48
...
...
...
...
...
...
...
...




由于我想预测每个观测值的坐标，因此 LSTM 的输入形式被定义为 n° 样本 x 1 x 10（10 是特征数量）。我使用 1 作为时间步长，因为每次模拟中我拥有的唯一信息是 t=0 的信息，因此我无法使用更多过去的观察结果来预测新的观察结果。
X_train.shape = (1039290, 1, 10)
y_train.shape = (1039290, 3)

问题是我没有唯一的时间序列，我有多个时间序列（每个模拟有 49 个时间序列对应于每个节点位移）。
那么这样考虑 LSTM 的输入是错误的吗？]]></description>
      <guid>https://stackoverflow.com/questions/77905948/is-the-input-shape-for-the-lstm-correct-considering-the-problem-under-analysis</guid>
      <pubDate>Tue, 30 Jan 2024 11:18:34 GMT</pubDate>
    </item>
    <item>
      <title>成为机器学习工程师[关闭]</title>
      <link>https://stackoverflow.com/questions/77905900/become-machine-learning-engineer</link>
      <description><![CDATA[几年前我已经完成了计算机应用硕士学位。现在我有兴趣开始我的机器学习职业生涯。但是当我谷歌搜索时，它说我需要从数据分析师开始我的职业生涯，才能成为机器学习工程师。]]></description>
      <guid>https://stackoverflow.com/questions/77905900/become-machine-learning-engineer</guid>
      <pubDate>Tue, 30 Jan 2024 11:11:56 GMT</pubDate>
    </item>
    <item>
      <title>尽管最小/最大有效，但陆地卫星频带中的空值</title>
      <link>https://stackoverflow.com/questions/77905652/null-values-in-landsat-bands-despite-valid-min-max</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77905652/null-values-in-landsat-bands-despite-valid-min-max</guid>
      <pubDate>Tue, 30 Jan 2024 10:33:39 GMT</pubDate>
    </item>
    <item>
      <title>Ray集群无法调度资源</title>
      <link>https://stackoverflow.com/questions/77904953/ray-cluster-cant-schedule-resources</link>
      <description><![CDATA[我是机器学习的初学者。当我尝试重现 FedRolex 的实验时，我遇到了这个问题：它不断地告诉我
“警告：现在无法调度以下资源请求：{&#39;GPU&#39;: 0.15, &#39;CPU&#39;: 1.0}。这可能是由于所有集群资源都被参与者占用。考虑创建更少的参与者或向该 Ray 集群添加更多节点。”
我以为没关系，但是这个实验到现在已经运行了大约3个小时，所以应该有问题。在此处输入图片描述
我在 https://github.com/AIoT-MLSys-Lab/ 中使用相同的程序联邦劳力士
我尝试更换显卡，也更换了新版本的Ray，但还是无法解决这个问题。希望有人能告诉我这个程序运行这么长时间是否正常，是吗？卡在某个地方或者只是需要运行很长时间。
我的母语不是英语，所以我猜我的表达可能有点紧张。
感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77904953/ray-cluster-cant-schedule-resources</guid>
      <pubDate>Tue, 30 Jan 2024 08:43:42 GMT</pubDate>
    </item>
    <item>
      <title>将张量流中的非序列数据的掩蔽层和密集层结合起来</title>
      <link>https://stackoverflow.com/questions/77904938/combining-masking-and-dense-layers-for-non-sequential-data-in-tensorflow</link>
      <description><![CDATA[我正在研究一个分类问题，其中有不同长度的数据。每个样本都是 -1 到 1 之间的实数值的 numpy 数组。因为每个样本的长度不同，所以我使用填充，以便可以将其输入神经网络。根据tensorflow的文档，我还需要一个与填充结合使用的掩蔽层。然而，我还了解到，并非每一层都会传播掩码，我担心这可能是我的网络表现不佳的原因。我运行了带有和不带有填充+掩蔽层的分类器，结果相似。我想问您将遮罩层与致密层结合使用的最佳方法是什么。下面是我的网络的代码示例。
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入密集，掩蔽
从tensorflow.keras.utils导入pad_sequences
从 sklearn.model_selection 导入 train_test_split

X_padd = pad_sequences(X, padding=&#39;post&#39;, dtype=&#39;float32&#39;)

X_train, X_test, y_train, y_test = train_test_split(X_pangled, y, test_size=0.3, random_state=101, shuffle=True)

模型=顺序（）
model.add(掩蔽(mask_value=0.0, input_shape=(X_train.shape[1],)))
model.add（密集（1024，激活=&#39;relu&#39;））
model.add（密集（512，激活=&#39;relu&#39;））
model.add（密集（1，激活=&#39;sigmoid&#39;））

model.compile（优化器=&#39;adam&#39;，损失=&#39;binary_crossentropy&#39;，指标=[“准确性”]）

model.fit（x = X_train，y = y_train，epochs = 600，validation_data =（X_test，y_test））

训练数据看起来或多或少像这样：
&lt;预&gt;&lt;代码&gt;X = [[-0.1, 0.2, 0.1], [0.4, 0.3], [-0.2, -0.44, 0.32, 0.5], ...]
y = [0, 1, 1, ...]
]]></description>
      <guid>https://stackoverflow.com/questions/77904938/combining-masking-and-dense-layers-for-non-sequential-data-in-tensorflow</guid>
      <pubDate>Tue, 30 Jan 2024 08:41:04 GMT</pubDate>
    </item>
    <item>
      <title>具有多个输入和多个输出的 RNN</title>
      <link>https://stackoverflow.com/questions/77903939/rnn-with-multiple-inputs-and-multiple-outputs</link>
      <description><![CDATA[我想实现一个具有多个输入和输出的 RNN。我特别想实现如下图所示的功能。也就是说，在我处理完输入后，我想开始生成输出，是否可以在 pytorch RNN 模块中轻松实现这一点？
]]></description>
      <guid>https://stackoverflow.com/questions/77903939/rnn-with-multiple-inputs-and-multiple-outputs</guid>
      <pubDate>Tue, 30 Jan 2024 04:43:40 GMT</pubDate>
    </item>
    <item>
      <title>Flutter web 和 tflite 机器学习自定义模型</title>
      <link>https://stackoverflow.com/questions/76004223/flutter-web-and-tflite-machine-learning-custom-model</link>
      <description><![CDATA[我在将自定义训练的人工智能图像分类器模型集成到我的 flutter Web 应用程序中时遇到麻烦。我已经将模型转换并保存在 tflite 和 labels.txt 文件中，但 tflite 包文档仅显示对 android &amp; 的支持。 ios。有没有办法将 tflite 集成到我的 flutter web 应用程序中，或者我应该寻找其他解决方案
tflite、label.txt、图库中的图像选择器]]></description>
      <guid>https://stackoverflow.com/questions/76004223/flutter-web-and-tflite-machine-learning-custom-model</guid>
      <pubDate>Thu, 13 Apr 2023 10:10:39 GMT</pubDate>
    </item>
    </channel>
</rss>