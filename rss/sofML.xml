<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 21:13:51 GMT</lastBuildDate>
    <item>
      <title>为什么模型训练需要填充数据？</title>
      <link>https://stackoverflow.com/questions/78551888/why-is-padding-data-for-model-training-necessary</link>
      <description><![CDATA[为什么需要填充？有人能解释一下吗？如果你的张量大小不同，它们可以堆叠，但问题是什么？有人能用一个现实生活中的例子来解释一下吗？（我问过 gpt4，但它没有给出令人满意的答案）
我正在尝试制作一个 AI 机器人，它告诉我要填充我的输入，但我不明白为什么？]]></description>
      <guid>https://stackoverflow.com/questions/78551888/why-is-padding-data-for-model-training-necessary</guid>
      <pubDate>Wed, 29 May 2024 20:47:59 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 处理作业权限被拒绝保存 /opt/ml/processing/<folder> 下的 csv 文件</title>
      <link>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</link>
      <description><![CDATA[我正在开展一个涉及 Step Functions 和 SageMaker 的项目。我有一个现有的 Step Function，需要将 SageMaker 集成到其中，我尝试添加处理、模型训练、注册模型和批量转换作业请求等步骤。我还在每个资源的末尾添加了 .sync，以便等待一个资源完成后再开始下一个资源。
但是，我在 Step Function 的 SageMaker 处理作业中遇到了问题。处理作业运行但未完成，因为权限被拒绝从我处理的 pandas 数据框保存 CSV 文件。
# 依赖项导入
df = pd.read_csv(&quot;/opt/ml/processing/input/data/data.csv&quot;)
print(df.head())

# 对 df 进行一些处理

df.to_csv(&quot;/opt/ml/processing/output/result.csv&quot;, index=False)

以下是处理请求的状态机配置：
如果您需要查看我的配置的其他部分，请给我留言
{
&quot;AppSpecification&quot;: {
&quot;ContainerEntryPoint&quot;: [
&quot;python3&quot;,
&quot;/opt/ml/processing/input/code/processing.py&quot;
]
},
&quot;ProcessingInputs&quot;: [
{
&quot;InputName&quot;: &quot;Input-1&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/data&quot;
}
},
{
&quot;InputName&quot;: &quot;Input-2&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/processing.py&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/code&quot;
}
}
],
&quot;ProcessingOutputConfig&quot;: {
&quot;Outputs&quot;: [
{
&quot;OutputName&quot;: &quot;Output-1&quot;,
&quot;S3Output&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/output/&quot;,
&quot;S3U​​ploadMode&quot;: &quot;EndOfJob&quot;
}
}
]
}
}

ProcessingInputs 配置按预期工作。我在日志中看到 df.head() 将 data.csv 内容正确打印在日志中。但是，当它到达最后一行代码时，我收到以下错误：
PermissionError: Permission Denied &#39;/opt/ml/processing/output/result.csv&#39;
我还尝试将其保存到其他文件夹，如我在网上找到的一些示例中所见，例如保存到 training、result 等文件夹，但到目前为止还没有成功。它给了我同样的权限错误。我使用了为此专门创建的 Lambda 函数，并向 SageMaker 处理作业发出请求，并得到了完全相同的权限被拒绝错误。
我还尝试将文件保存到 /opt/ml/processing/ 之外的完全不同的文件夹中，但 /result.csv
但它给了我不同的错误，因为 SageMaker 只允许我们将 csv 文件保存在 /opt/ml/processing/ 下......所以我不知道该怎么做。
目前，我正在使用 boto3 api 手动保存结果集，并等待处理作业通过我设置的 StoppingCondition.MaxRuntimeInSeconds 时间，最终它停止，我使用附加步骤来获取它。
但我不喜欢我解决问题的方式，我真的需要找到更好的方法来解决这个问题。
有人能告诉我我遗漏了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</guid>
      <pubDate>Wed, 29 May 2024 19:34:23 GMT</pubDate>
    </item>
    <item>
      <title>当我指定“准确度”时，R 使用“ROC”指标吗？</title>
      <link>https://stackoverflow.com/questions/78551346/r-using-roc-metric-when-i-specify-accuracy</link>
      <description><![CDATA[我正在使用 reapeatedCV 训练随机森林分类器
# 加载必要的库
library(randomForest)
library(readxl)
library(caret)

# 加载带有标签的原始 DataFrame
df_1 &lt;- read_excel(&quot;path\to\excel&quot;)

df_1$label &lt;- as.factor(df_1$label) 

# 初始化并训练随机森林分类器
set.seed(42)
train_control &lt;- trainControl(method = &quot;repeatedcv&quot;, 
number = 5, 
repeats = 10,
summaryFunction = twoClassSummary,
classProb = TRUE,
savePredictions = &quot;all&quot;)

random_forest_model &lt;- train(label ~ ., 
data = df_1, 
method = &quot;rf&quot;, 
trControl = train_control,
classwt = c(&quot;X0&quot; = 0.6, &quot;X1&quot; = 0.4),
ntree = 500,
metric = &quot;Accuracy&quot;, 
significance = TRUE)

但是，我仍然收到此错误：
在 train.default(x, y, weights = w, ...) 中：
结果集中没有指标 &quot;Accuracy&quot;。将改用 ROC。

我已指定我还需要计算 &quot;Accuracy&quot;作为指标。
此外，我需要在最后添加 4 个表格，以显示结果，如这张照片所示。]]></description>
      <guid>https://stackoverflow.com/questions/78551346/r-using-roc-metric-when-i-specify-accuracy</guid>
      <pubDate>Wed, 29 May 2024 18:20:38 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习方法选择加权平均的权重集</title>
      <link>https://stackoverflow.com/questions/78551292/using-machine-learning-approach-to-select-weight-sets-for-weighted-average</link>
      <description><![CDATA[我有多个风速预测，我试图为每个预测分配不同的权重，以获得最佳的“混合”预测，从而获得最佳的预测性能。假设每个风速预测在温度和湿度等外部条件下的表现不同。
我知道这可以建模为优化问题，但我很好奇这是否可以通过机器学习来解决，因为 NN 基本上是在解决优化问题，并且由权重和偏差组成。
因此，给定预测，并且可能给定外部条件（例如温度），模型将返回最佳权重选择。
你们觉得呢？]]></description>
      <guid>https://stackoverflow.com/questions/78551292/using-machine-learning-approach-to-select-weight-sets-for-weighted-average</guid>
      <pubDate>Wed, 29 May 2024 18:08:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在嵌套 k 折交叉验证机器学习模型中提取 SHAP 值？</title>
      <link>https://stackoverflow.com/questions/78551276/how-to-extract-shap-values-in-the-context-of-a-nested-k-fold-cross-validated-mac</link>
      <description><![CDATA[为了计算具有连续结果的随机森林模型的变量重要性，我想计算训练中的 SHAP 值，并在嵌套 k 倍交叉验证过程的每个折叠处设置它们并取平均值。Scheda 等人 已经完成了这项工作，似乎很容易在 Python 中完成。但是，在 R 中似乎没有简单的方法来实现这一点。这是我尝试执行的操作的模式，基于 Scheda 和其他人，但仅适用于训练集（正如他们在文章中对两者所做的那样）。

这是我的所在位置，带有一个可复制的示例：

嵌套 k 折交叉验证的常用 for 循环

library(iml)
library(caret)
library(tidyverse)

#upload car data
data(cars)

#create the folds
folds.samp = createFolds(cars$Price,k=4,list=F)

#创建 k 倍的 for 循环预测
rf_preds = list()#样本外预测的空列表
rf_models= list()#列出模型

#for 循环：这为我提供了经过训练和验证的模型（每个 fold 一个），这些模型基于训练数据，并在未见数据上进行了测试
for(j in 1:4){
rf = caret::train(Price~.,cars[folds.samp!=j,],
method = &quot;rf&quot;,
trControl=trainControl(method=&quot;cv&quot;),
ntree=150)#ntrees 通常设置为 2000 以获得稳健变量重要性，但出于示例目的设置为 150
rf_models=c(rf_models,list(rf))
rf_preds[[j]]=predict(rf,cars[folds.samp==j,])
} 


我尝试在 k 折 for 循环中加入另一个 for 循环，以提取每次折叠时每行的训练 SHAP 值，但这不起作用。我知道代码很乱，但除了使用 iml 包，我不知道还有其他方法可以做到这一点，通过为给定模型创建预测器对象，然后在没有结果变量的情况下循环遍历数据集。以下是我尝试调整代码以提取 K 折 CV 训练集上的 SHAP 值的方法。

# 使用 shapley 值
# 在 k 折上创建 for 循环预测
rf_preds = list()# 用于样本外预测的空列表
rf_models= list()# 带有模型的列表
shap_vals_matrix_list=list()
# for 循环：这为我提供了经过训练和验证的模型（每个折一个），这些模型在训练数据上进行训练，并在未见数据上进行测试
for(j in 1:5){
rf = caret::train(Price~.,cars[folds.samp!=j,],
method = &quot;rf&quot;,
trControl=trainControl(method=&quot;cv&quot;),
ntree=150)# ntrees 通常设置为 2000 以获得稳健变量重要性，但出于示例目的设置为 150
rf_models=c(rf_models,list(rf))
rf_preds[[j]]=predict(rf,cars[folds.samp==j,])
###循环的Shapley值部分###
mod = Predictor$new(rf_models[[j]]$finalModel, data = cars)#创建预测器对象
# 创建一个空矩阵来收集结果
shap_vals &lt;- matrix(NA,nrow(cars[folds.samp!=j,]),ncol(cars)-1)
# 预测器的训练数据
X &lt;- cars[folds.samp!=j, -which(names(cars) == &quot;Price&quot;)]
# 创建一个预测器对象
predictor &lt;- Predictor$new(model = rf_models[[j]]$finalModel, data = X, y = cars[folds.samp!=j,&quot;Price&quot;])
#创建一个内部循环来计算实际的 SHAP 值
for(i in 1:nrow(cars[folds.samp!=j,])){
shapley &lt;- Shapley$new(mod, x.interest = cars[i,-1])
shap_vals[i,] = abs(shapley$results$phi)[1:(ncol(cars)-1)]
mean_shap_values &lt;- colMeans(shap_vals, na.rm = TRUE)#每行的平均值
}
shap_vals_matrix_list=c(shap_vals_matrix_list,list(mean_shap_values))
}

如何使代码正常工作或使其更简单？]]></description>
      <guid>https://stackoverflow.com/questions/78551276/how-to-extract-shap-values-in-the-context-of-a-nested-k-fold-cross-validated-mac</guid>
      <pubDate>Wed, 29 May 2024 18:04:24 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 CLI 创建 Azure 机器学习工作区</title>
      <link>https://stackoverflow.com/questions/78550892/unable-to-create-an-azure-machine-learning-workspace-using-the-cli</link>
      <description><![CDATA[我目前正在尝试使用 CLI 创建一个 Azure 机器学习工作区。我使用了以下代码：
az ml working create --name &quot;rg-dp100-labs&quot; --resource-group &quot;rg-dp100-labs&quot;

我收到以下错误。
代码：ValidationError
消息：工作区 json 中缺少依赖资源
目标：工作区
异常详细信息：（无效）工作区 json 中缺少依赖资源
代码：无效
消息：工作区 json 中缺少依赖资源
目标：工作区

仅创建了 KeyVault 和存储帐户。参考Microsoft Learn 上的链接，我发现其他人也遇到了同样的问题。甚至谷歌搜索也给了我与上面相同的代码。lease，有人遇到过同样的问题并解决了吗？我认为这是最近出现的问题。]]></description>
      <guid>https://stackoverflow.com/questions/78550892/unable-to-create-an-azure-machine-learning-workspace-using-the-cli</guid>
      <pubDate>Wed, 29 May 2024 16:44:20 GMT</pubDate>
    </item>
    <item>
      <title>如何追踪多标签MLP的损失？</title>
      <link>https://stackoverflow.com/questions/78550784/how-to-track-loss-of-multi-label-mlp</link>
      <description><![CDATA[我获得了维度为 5,000 的二进制数据点。我被要求执行机器学习，预测长度为 1k 的二进制向量，其中输出的每个位置都是一个类。这些类别不互斥。
我对类别分布的了解：

索引较小的位置更常见
一个样本可以属于多个类别
每个样本仅满足少数类别要求（即输出是“稀疏的”）

如何跟踪我的 ML 模型中的损失？我使用了多层感知器（pytorch）和交叉熵损失（CE 损失），但我发现很难解释结果。我假设当您有多个类别但一次只选择一个（多类分类）时使用 CE 损失。
此外，我的预测导致向量设置了大约一半的位，而我预计设置了 20 到 50 位，不会更多。
# 一个“示例”数据点：
point = [1, 0, 0, 1, 0, 0, 1, 1, ...,1, 1, 0, 0, 1, 0, 1] # 长度 5000
label = [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...,0] # 长度 1000
# 标签仅设置了 20-50 位
]]></description>
      <guid>https://stackoverflow.com/questions/78550784/how-to-track-loss-of-multi-label-mlp</guid>
      <pubDate>Wed, 29 May 2024 16:17:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和深度学习在 5 年或 10 年后蓬勃发展，而人工智能无法做到或我们可以说它无法进入这个领域或行业 [关闭]</title>
      <link>https://stackoverflow.com/questions/78550741/the-way-ai-deep-learning-is-booming-after-5-or-10-years-later-what-ai-will-not</link>
      <description><![CDATA[人工智能正在迅速发展，但在某些领域，它不太可能在未来 5-10 年内完全取代人类。以下是人类能力可能仍占优势的一些领域：**
社会工作和治疗：这些领域严重依赖于理解复杂情绪、建立信任和提供个性化指导。人工智能可以协助进行数据分析和初步评估，但人类治疗师擅长建立融洽关系和提供情感支持。
客户服务：虽然人工智能聊天机器人可以处理常规查询，但复杂问题或需要同理心的问题更适合人类代表。
高度创造性的领域：
艺术、音乐创作和写作：虽然人工智能可以生成创造性的文本格式或艺术风格，但它往往缺乏人类创作作品中的原创性和情感深度。人类创造力是由人工智能目前难以复制的经历和情感所驱动的。]]></description>
      <guid>https://stackoverflow.com/questions/78550741/the-way-ai-deep-learning-is-booming-after-5-or-10-years-later-what-ai-will-not</guid>
      <pubDate>Wed, 29 May 2024 16:05:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 CSE-CIC-IDS2018 数据集的机器学习创建网络入侵检测系统 (NIDS)？</title>
      <link>https://stackoverflow.com/questions/78549360/how-to-create-a-network-intrusion-detection-system-nids-using-machine-learning</link>
      <description><![CDATA[我目前正在开展一个名为 NetGuardian 的项目，这是一个利用机器学习来检测入侵的网络入侵检测系统 (NIDS)。我计划使用 CSE-CIC-IDS2018 数据集来训练我的模型。但是，我面临挑战，希望得到以下方面的指导：

数据预处理：


我应该如何预处理 CSE-CIC-IDS2018 数据集以实现最佳训练？
是否有推荐的特定技术或库来处理此数据集？


特征选择：


在这种情况下，特征选择的最佳实践是什么？
我应该使用提供的所有特征还是选择一个子集更好？如果是，我该如何确定哪些特征最重要？


模型选择：


哪些机器学习算法对 NIDS 最有效？
是否有特定模型在 CSE-CIC-IDS2018 数据集上表现特别好？


训练和评估：


我应该如何拆分数据集进行训练和测试以确保可靠的性能评估？
我应该使用哪些指标来评估我的 NIDS 的性能？


实施：


是否有任何教程或资源可以指导我使用机器学习构建 NIDS？
在构建过程中我应该避免哪些常见陷阱实现？

我熟悉 Python 和常用库，例如​​ Pandas、Scikit-Learn 和 TensorFlow/PyTorch。
我的目标是创建一个强大而高效的 NIDS，可以准确检测各种类型的网络入侵。]]></description>
      <guid>https://stackoverflow.com/questions/78549360/how-to-create-a-network-intrusion-detection-system-nids-using-machine-learning</guid>
      <pubDate>Wed, 29 May 2024 11:55:47 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的均匀分布数据[关闭]</title>
      <link>https://stackoverflow.com/questions/78549325/uniformly-distibuted-data-for-machine-learning</link>
      <description><![CDATA[对于线性模型，如逻辑回归、线性 SVM、MLP，我有一些均匀分布的变量，假设变量服从正态分布，变量服从多重共线，对吧？如果数据服从幂律、对数正态或偏斜，我们可以应用 box-cox 变换将其转换为高斯分布，现在如果数据服从正态分布，我可以直接应用模型吗？当数据服从均匀分布时它也能很好地工作吗？如果不是，如何将均匀分布转换为正态分布]]></description>
      <guid>https://stackoverflow.com/questions/78549325/uniformly-distibuted-data-for-machine-learning</guid>
      <pubDate>Wed, 29 May 2024 11:49:49 GMT</pubDate>
    </item>
    <item>
      <title>Anylogic 和 ML 模型</title>
      <link>https://stackoverflow.com/questions/78549243/anylogic-and-ml-models</link>
      <description><![CDATA[我的目标是在我的 Anylogic 模型中包含一个随机森林模型，以预测我的代理变量的值。
我见过一个 Python 连接和 ML 模型使用示例，其中包含 pyCom 库，带有 AI 的简单医院，但我甚至无法运行它。
我已经导入了 pypeline 库。
但我遇到两个错误：
第一个在运行模型之前：

无法解析导入 com.google。位置：简单医院（AI 测试平台）/患者 - 代理类型

运行它时的第二个：

无法运行 Python 代码；反馈：TypeError(&quot;&lt;class &#39;keras.src.initializers.random_initializers.GlorotUniform&#39;&gt; 无法正确反序列化。请确保 get_config() 返回的 Python 对象实例（层、模型等）的组件在模型的 from_config() 方法中明确反序列化。\n\nconfig={&#39;module&#39;: &#39;keras.initializers&#39;, &#39;class_name&#39;: &#39;GlorotUniform&#39;, &#39;config&#39;: {&#39;seed&#39;: None, &#39;dtype&#39;: &#39;float32&#39;}, &#39;registered_name&#39;: None}.\n\n遇到异常：GlorotUniform.init() 获得了意外的关键字参数 &#39;dtype&#39;&quot;)

我的电脑上有 python，包含所有库（numpy、pandas、tensorflow、 skit-learn...) 和 pyCommunicator 似乎可以工作，因为我测试了基本教程。在第二种情况下，问题可能是 keras 的版本？但哪个是正确的版本？]]></description>
      <guid>https://stackoverflow.com/questions/78549243/anylogic-and-ml-models</guid>
      <pubDate>Wed, 29 May 2024 11:33:27 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助根据加速度计数据确定步进节奏[关闭]</title>
      <link>https://stackoverflow.com/questions/78538684/need-help-determining-step-rhythm-from-accelerometer-data</link>
      <description><![CDATA[背景：
我目前正在开展一个项目，该项目中我拥有来自安装在马匹前腿上的 MetaWear 加速度计传感器的数据。数据包括所有三个轴点的时间序列信息，并在马匹持续慢跑时记录下来。我之前曾使用梯度提升机 (GBM) 进行过特征提取，以确定马匹是在慢跑还是其他步态。
目标：
我的目标是仅根据加速度计数据确定马匹在慢跑时移动的节奏。例如，马匹可以以非常慢的慢跑或非常快的慢跑速度前进，我希望能够通过测量每分钟的步数来捕捉慢跑速度的变化。本质上，我想了解步频节奏在给定时间范围内重复的频率。
挑战：
我的数据没有标签，但我可以直观地识别重复模式。
我需要一种有效的方法来标记数据，最好不要手动标记所有重复。
我研究过 Grafana 之类的工具，但发现它们不能满足我的需求。
问题：
从给定的加速度计数据中确定节奏（节拍或每分钟步数）的最佳方法是什么？
是否有任何拖放标记工具可以帮助有效地标记大约 100 次重复？或者，是否有任何技术可以避免手动标记？
您是否会推荐其他策略来以不同的方式解决此问题？
其他信息：
以下是我的数据屏幕截图的链接 https://docs.google.com/document/d/1iAnwyA9y2AlG2p_CiVEAYdeVEJjL9QKPrbyegsFpCJ8/edit?usp=sharing，以提供更多背景信息。]]></description>
      <guid>https://stackoverflow.com/questions/78538684/need-help-determining-step-rhythm-from-accelerometer-data</guid>
      <pubDate>Mon, 27 May 2024 11:04:47 GMT</pubDate>
    </item>
    <item>
      <title>如何将图像分割成一系列块而不丢弃剩余像素</title>
      <link>https://stackoverflow.com/questions/78534650/how-to-split-an-image-into-a-series-of-patches-without-discarding-leftover-pixel</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78534650/how-to-split-an-image-into-a-series-of-patches-without-discarding-leftover-pixel</guid>
      <pubDate>Sun, 26 May 2024 08:09:57 GMT</pubDate>
    </item>
    <item>
      <title>如何解决未定义功能错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/78517764/how-do-i-resolve-features-not-defined-error</link>
      <description><![CDATA[函数传递特征参数
这是预测分析纽约出租车乘车问题。
我一直在通过 Great Learning 学习数据科学/ML 课程。我遇到了一个函数问题，我之前已经定义了参数，但它返回了一个错误，提示未定义。任何帮助都非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/78517764/how-do-i-resolve-features-not-defined-error</guid>
      <pubDate>Wed, 22 May 2024 13:07:00 GMT</pubDate>
    </item>
    <item>
      <title>结果集中未包含指标“ROC”。将改用准确度</title>
      <link>https://stackoverflow.com/questions/73351901/the-metric-roc-was-not-in-the-result-set-accuracy-will-be-used-instead</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/73351901/the-metric-roc-was-not-in-the-result-set-accuracy-will-be-used-instead</guid>
      <pubDate>Sun, 14 Aug 2022 13:10:17 GMT</pubDate>
    </item>
    </channel>
</rss>