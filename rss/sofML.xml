<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 16 May 2024 15:14:57 GMT</lastBuildDate>
    <item>
      <title>我如何使变压器输出相对于特定上下文的翻译</title>
      <link>https://stackoverflow.com/questions/78490608/how-can-i-make-a-transformer-output-a-translation-relative-to-a-specific-context</link>
      <description><![CDATA[所以我目前正在做一个类似机器翻译的项目，其中我有一个具有编码器-解码器结构的转换器，它应该从自然语言命令生成 SQL 查询，例如：
输入：计算 XYZ 公司生产的飞机数量
输出：从飞机中选择 COUNT(*) 个，其中制造商=&#39;XYZ&#39;；
现在我已经实现了我的目标，我的模型在大多数情况下都可以生成看起来不错的查询，但仍然有一个问题需要解决，那就是它可以生成的查询在语法上都是正确的，但它并没有解决问题属性/表名称，例如：
输入：计算 XYZ 公司生产的飞机数量
输出： SELECT COUNT(*) FROM 飞机，其中生产=&#39;XYZ&#39;;
或者：
输入：显示所有 40 岁以上的员工
输出： SELECT * FROM员工，其中国家/地区&gt; 40；
就像我说的，从语法上讲，查询没有错误，但它肯定无法在数据库本身上正确执行。
我的模型是在 json 数据集上进行训练的，该数据集包含遵循以下形式的样本列表：
&lt;前&gt;&lt;代码&gt;[
  [
    “计算 XYZ 公司生产的飞机数量”，
    “从制造商 = &#39;XYZ&#39; 的飞机中选择 COUNT(*)；”
  ],
  [
    “大西洋发现了多少海洋物种？”,
    “SELECT COUNT(*) FROM Marine_species WHERE location = &#39;Atlantic Ocean&#39;;”
  ]
]

尽管我发现一些数据集包含数据库架构作为一组 CREATE 查询，如下所示：
{“指令”：“CREATE TABLE table_72445 (
    “县”文本，
    “人口”真实的，
    “人均收入”文本，
    “家庭收入中位数”文本，
    “家庭收入中位数”文本
）
-- 列出河滨家庭收入中位数”，
“输出”：“选择\“家庭收入中位数” FROM table_72445 WHERE \“县\” =“河滨”}

那么我是否可以利用这种数据集，以便为我的转换器提供它应该工作的数据库上下文，或者是否有其他方法来实现此任务目标？
注意：我无法将之前的语料库作为一个整体作为我的输入，因为这会导致巨大的性能开销。想象一下，每次我想执行时，都会定义包含数十个表的相同集合，因此这是别无选择。
提前谢谢大家。]]></description>
      <guid>https://stackoverflow.com/questions/78490608/how-can-i-make-a-transformer-output-a-translation-relative-to-a-specific-context</guid>
      <pubDate>Thu, 16 May 2024 14:25:29 GMT</pubDate>
    </item>
    <item>
      <title>具有数值列和数组列的机器学习输入，处理机器学习中的混合类型数据</title>
      <link>https://stackoverflow.com/questions/78490240/machine-learning-input-with-numerical-columns-and-array-columns-handling-mixed</link>
      <description><![CDATA[我正在开发一个机器学习项目，其中有一个数据集，其中包含数字列和包含数组的列的组合。数字列（例如平均值）包含单个值，而带有数组的列（例如梯度）每行可以包含可变数量的元素。
处理此类输入的最佳实践是什么？我可以在机器学习模型中同时使用数字列和带有数组的列吗？如果是这样，在模型的预处理和训练阶段处理这种数据异构性的最常见策略是什么？
如果有任何建议或资源可以帮助我更好地了解如何应对这一挑战，我将不胜感激。
示例：
模型输入：

&lt;标题&gt;

平均值
渐变


&lt;正文&gt;

0.5
[1,2,3,45,0.2]


1
[2,5,1.2,5,0]



预先感谢您的帮助！
我尝试在网上搜索，但找不到真正的答案。]]></description>
      <guid>https://stackoverflow.com/questions/78490240/machine-learning-input-with-numerical-columns-and-array-columns-handling-mixed</guid>
      <pubDate>Thu, 16 May 2024 13:28:46 GMT</pubDate>
    </item>
    <item>
      <title>如何评估 SVM 模型的变量重要性？</title>
      <link>https://stackoverflow.com/questions/78488619/how-do-i-asses-variable-importance-of-a-svm-model</link>
      <description><![CDATA[我正在开发一个机器学习项目。我的目标变量是二进制的，我用插入符构建了一个 SVM 径向模型：
ctrl_SVM &lt;- trainControl(method=“cv”，number=10，search=“grid”，summaryFunction = TwoClassSummary，classProbs = TRUE)
param_grid_SVM_radial &lt;- Expand.grid(C = c(0.01, 0.1, 1, 10, 100), sigma = c(0.01, 0.1, 1, 10))
SVM_radial &lt;- train(Target~., data=under_svm, method = &quot;svmRadial&quot;, trControl = ctrl_SVM,tuneGrid = param_grid_SVM_radial,
                    指标=“ROC”，预处理=NULL）

如何评估变量的重要性？正确的代码是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78488619/how-do-i-asses-variable-importance-of-a-svm-model</guid>
      <pubDate>Thu, 16 May 2024 08:44:20 GMT</pubDate>
    </item>
    <item>
      <title>有谁可以询问有关使用 NER 和 XLM-RoBERTa 进行信息提取的问题吗？</title>
      <link>https://stackoverflow.com/questions/78488394/is-there-anyone-can-i-ask-about-information-extraction-using-ner-with-xlm-robert</link>
      <description><![CDATA[大家好我想问一下关于从PDF文档中提取信息的问题。因此，我将使用 XLM-RoBERTa 和 NER 来执行信息提取，并使用来自以下来源的代码进行微调：https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a。从这个来源来看，它确实使用了 BERT，并且在我尝试之后，结果发现来自单词的预测实体与真实值不同。我很困惑是否需要从代码中更改某些内容，或者数据集是否有问题，因为我使用的数据集是自制的数据集。有什么可以问的吗？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78488394/is-there-anyone-can-i-ask-about-information-extraction-using-ner-with-xlm-robert</guid>
      <pubDate>Thu, 16 May 2024 08:03:25 GMT</pubDate>
    </item>
    <item>
      <title>识别和提取特定语句</title>
      <link>https://stackoverflow.com/questions/78487711/identifying-and-extracting-particular-statements</link>
      <description><![CDATA[鉴于一份包含排除声明的文件，例如“提供的所有文件都证明没有涉及印度尼西亚船只”。我想从文件中识别此类声明，然后使用机器学习模型提取国家/地区。我
正在考虑我们可以使用 lstm 和 NER 或 smtng...请给我更好的管道]]></description>
      <guid>https://stackoverflow.com/questions/78487711/identifying-and-extracting-particular-statements</guid>
      <pubDate>Thu, 16 May 2024 05:26:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 DeepSeekMath 7b 模型在 vllm 中进行无说明的断言，为什么，如何修复？</title>
      <link>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model-why-how-to-fix</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model-why-how-to-fix</guid>
      <pubDate>Thu, 16 May 2024 02:49:09 GMT</pubDate>
    </item>
    <item>
      <title>如何避免保存pytorch中register_forward_hook跳过的参数？</title>
      <link>https://stackoverflow.com/questions/78487193/how-to-avoid-saving-params-skipped-by-register-forward-hook-in-pytorch</link>
      <description><![CDATA[代码如下。
我可以跳过 register_forward_hook 跳过的保存权重吗？
def get_activation(mem, 名称):
    def get_output_hook（模块，输入，输出）：
        mem[名称] = 输出

    返回 get_output_hook

def add_hook（网络，mem，mapping_layers）：
    对于 net.named_modules() 中的 n、m：
        如果mapping_layers中有n：
            m.register_forward_hook(get_activation(mem, n))

行为_stu = {}
mapping_layers_stu = [&#39;块1&#39;,&#39;块2&#39;]
add_hook（网络，acts_stu，mapping_layers_stu）

]]></description>
      <guid>https://stackoverflow.com/questions/78487193/how-to-avoid-saving-params-skipped-by-register-forward-hook-in-pytorch</guid>
      <pubDate>Thu, 16 May 2024 01:44:44 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker SDK 无法使用自定义算法运行训练</title>
      <link>https://stackoverflow.com/questions/78486992/unable-to-sagemaker-sdk-to-run-training-using-a-custom-algorithm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78486992/unable-to-sagemaker-sdk-to-run-training-using-a-custom-algorithm</guid>
      <pubDate>Wed, 15 May 2024 23:54:42 GMT</pubDate>
    </item>
    <item>
      <title>调查 TensorFlow 和 PyTorch 性能的差异</title>
      <link>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</guid>
      <pubDate>Tue, 14 May 2024 13:54:26 GMT</pubDate>
    </item>
    <item>
      <title>将 PyG 数据对象列表转换为 PyG 数据集？</title>
      <link>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</link>
      <description><![CDATA[我有一个 torch_geometric.data.Data 对象的 python 列表（每个对象代表一个图形）。我没有简单的方法来访问这些数据的原始文件：我只有列表。我需要将此数据对象列表转换为 torch_geometric.data.InMemoryDataset 或 torch_geometric.data.Dataset 对象，以便将其与我没有编写的更大的代码库集成。我该怎么做？
需要明确的是，我知道可以使用一系列数据对象来创建 torch_geometric.data.DataLoader 对象。但是，我特别需要一个 Dataset 对象，而不是 DataLoader 对象，因为较大的代码库在将 Dataset 对象转换为加载器之前会对它们执行一些额外的处理步骤。
我不明白为什么 PyG 让这变得如此困难。难道没有一种非常简单的方法可以做到这一点吗？
我尝试使用一个简单的 CustomDataset 类
类 CustomDataset(InMemoryDataset):
    def __init__(自身，数据)：
        超级().__init__()
        self.data = 数据
    
    def __len__(自身):
        返回 len(self.data)
    
    def __getitem__(self, idx):
        样本 = self.data[idx]
        返回样品

当尝试获取索引 0 处的 Data 对象时，它给了我一个 KeyIndex 错误。我还尝试了上述代码的一个版本，其中超类是 Dataset 而不是 InMemoryDataset，但我不知道如何制作整理方法有效。]]></description>
      <guid>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</guid>
      <pubDate>Sun, 05 May 2024 18:30:03 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制多类分类中所有类的 SHAP 摘要图</title>
      <link>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</link>
      <description><![CDATA[我正在使用 XGBoost 和 SHAP 来分析多类分类问题中的特征重要性，并且需要帮助一次性绘制所有类的 SHAP 摘要图。目前，我一次只能生成一个类的绘图。
SHAP 版本：0.45.0
Python版本：3.10.12

这是我的代码：
将 xgboost 导入为 xgb
导入形状
将 numpy 导入为 np
将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.datasets 导入 make_classification
从 sklearn.metrics 导入 precision_score

# 生成合成数据
X，y = make_classification（n_samples = 500，n_features = 20，n_informative = 4，n_classes = 6，random_state = 42）
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# 训练用于多类分类的 XGBoost 模型
模型 = xgb.XGBClassifier(objective=“multi:softprob”, random_state=42)
model.fit(X_train, y_train)

然后我尝试绘制形状值：
# 创建一个 SHAP TreeExplainer
解释器 = shap.TreeExplainer(模型)

# 计算测试集的SHAP值
shap_values = 解释器.shap_values(X_test)

# 尝试绘制所有类的摘要
shap.summary_plot（shap_values，X_test，plot_type =“酒吧”）

我得到了这个交互图：

我在 此帖子：
shap.summary_plot(shap_values[:,:,0], X_test,plot_type=&quot;bar&quot;)

它给出了 0 类的正常条形图：

然后我可以对类 1、2、3 等执行相同的操作。
问题是，如何为所有类别制作汇总图？即，显示某个特征对每个类的贡献的单个图？]]></description>
      <guid>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</guid>
      <pubDate>Sat, 27 Apr 2024 19:02:16 GMT</pubDate>
    </item>
    <item>
      <title>错误消息 R - PrettyNum(.Internal(format(x,rim,digits,nsmall,width,3L,：‘digits’参数的值 0 无效”</title>
      <link>https://stackoverflow.com/questions/75961903/error-message-r-prettynum-internalformatx-trim-digits-nsmall-width-3l</link>
      <description><![CDATA[我想知道是否有人可以帮助我识别和解决使用 LCAvarsel 时遇到的错误术语。
就上下文而言，该库旨在用于潜在类别分析中的变量选择。
install.packages(&quot;LCAvarsel&quot;)
install.packages(&quot;poLCA&quot;)
library(LCAvarsel)
library(poLCA)

data(carcinoma)
sel1 &lt;- LCAvarsel(carcinoma) 

返回以下错误：
prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3L, :
&#39;digits&#39; 参数的值 0 无效
https://www.rdocumentation.org/packages/LCAvarsel/versions/1.1/topics/LCAvarsel]]></description>
      <guid>https://stackoverflow.com/questions/75961903/error-message-r-prettynum-internalformatx-trim-digits-nsmall-width-3l</guid>
      <pubDate>Fri, 07 Apr 2023 20:59:28 GMT</pubDate>
    </item>
    <item>
      <title>在一个巨大的向量上执行余弦相似度时出现内存错误</title>
      <link>https://stackoverflow.com/questions/73629817/got-memory-error-while-performing-cosine-similarity-on-a-huge-vector</link>
      <description><![CDATA[我试图使用词袋模型构建一个基于内容的推荐系统。我接下来的教程使用 sklearn 库中大小为 (4000,5000) 的向量的余弦相似度，其中 4000 是数据集中的行数，5000 是特征数。
从 sklearn.feature_extraction.text 导入 CountVectorizer
cv = CountVectorizer(max_features=5000, stop_words=&#39;english&#39;)
向量 = cv.fit_transform(new_df[&#39;tags&#39;]).toarray()
// 这里 new_df 是数据帧，new_df[tags] 包含将执行推荐的所有标签（例如：位置、流派）

但是，当我尝试在另一个具有 94955 行的数据集上实现余弦相似度（这会产生大小为 (94955, 5000) 的向量时，我收到以下错误
MemoryError：无法为形状为 (94955, 94955) 和数据类型 float64 的数组分配 67.2 GiB

上线了
相似度= cosine_similarity(向量，dense_output=False)
有没有办法实现余弦相似度的批处理，以便我可以克服这个问题，或者我应该更改算法？]]></description>
      <guid>https://stackoverflow.com/questions/73629817/got-memory-error-while-performing-cosine-similarity-on-a-huge-vector</guid>
      <pubDate>Wed, 07 Sep 2022 03:33:45 GMT</pubDate>
    </item>
    <item>
      <title>从训练集或测试集计算残差值</title>
      <link>https://stackoverflow.com/questions/56552458/calculate-residual-values-from-trainfset-or-test-set</link>
      <description><![CDATA[我想执行残差分析，并且我知道残差等于观测值减去预测值。但我不知道我应该计算训练集还是测试集的残差？
我应该使用这个：
导入 statsmodels.api 作为 sm
# 进行预测
lm = sm.OLS(y_train,X_train).fit()

y_pred = lm.predict(X_train)
残差 = y_train - y_pred.to_frame(&#39;价格&#39;)

或者这个：
导入 statsmodels.api 作为 sm
# 进行预测
lm = sm.OLS(y_train,X_train).fit()

y_pred = lm.predict(X_test)
resid = y_test- y_pred.to_frame(&#39;价格&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/56552458/calculate-residual-values-from-trainfset-or-test-set</guid>
      <pubDate>Tue, 11 Jun 2019 22:33:05 GMT</pubDate>
    </item>
    <item>
      <title>比 tf/idf 和余弦相似度更好的文本文档聚类？</title>
      <link>https://stackoverflow.com/questions/17537722/better-text-documents-clustering-than-tf-idf-and-cosine-similarity</link>
      <description><![CDATA[我正在尝试对 Twitter 流进行聚类。我想将每条推文放入讨论同一主题的集群中。我尝试使用具有 tf/idf 和余弦相似度的在线聚类算法对流进行聚类，但我发现结果非常糟糕。
使用 tf/idf 的主要缺点是它会聚集关键字相似的文档，因此只能识别几乎相同的文档。例如，考虑以下句子：
1- Stackoverflow 网站是一个不错的地方。
2- Stackoverflow 是一个网站。
前面的两个句子可能会以合理的阈值聚集在一起，因为它们共享很多关键字。但现在考虑以下两句话：
1- Stackoverflow 网站是一个不错的地方。
2- 我定期访问 Stackoverflow。
现在，通过使用 tf/idf，聚类算法将严重失败，因为即使它们谈论同一主题，它们也只共享一个关键字。
我的问题：是否有更好的技术来聚类文档？]]></description>
      <guid>https://stackoverflow.com/questions/17537722/better-text-documents-clustering-than-tf-idf-and-cosine-similarity</guid>
      <pubDate>Mon, 08 Jul 2013 23:40:57 GMT</pubDate>
    </item>
    </channel>
</rss>