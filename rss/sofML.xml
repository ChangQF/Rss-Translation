<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 13 Mar 2024 18:16:18 GMT</lastBuildDate>
    <item>
      <title>将一种概率分布转换/预测为另一种概率分布的网络</title>
      <link>https://stackoverflow.com/questions/78155703/a-network-to-transform-predict-one-probability-distribution-to-another</link>
      <description><![CDATA[我有一个特定密度的随机变量（例如，正态分布）和一个已知的概率分布（例如，混合高斯分布）。我使用一种简单的 KL 度量来预测/转换彼此。现在我需要使用神经网络来执行此类任务，并将一个随机变量转换为另一个随机变量。您能否建议一种网络类型来执行此操作，如果有开源代码将会非常有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78155703/a-network-to-transform-predict-one-probability-distribution-to-another</guid>
      <pubDate>Wed, 13 Mar 2024 17:20:04 GMT</pubDate>
    </item>
    <item>
      <title>当我在 python(jupyter Notebook) 中设置依赖项时，如何修复此错误？</title>
      <link>https://stackoverflow.com/questions/78155493/how-can-i-fix-this-error-while-i-was-setting-up-dependencies-in-pythonjupyter-n</link>
      <description><![CDATA[我只是想为我的机器学习作业设置依赖关系
!apt-get install -y xvfb python-opengl &gt; /dev/null 2&gt;&amp;1
！pip installgym pyvirtualdisplay&gt; /dev/null 2&gt;&amp;1
！pip installgym pyvirtualdisplay&gt; /dev/null 2&gt;&amp;1
!apt-get install -y xvfb python-opengl ffmpeg &gt; /dev/null 2&gt;&amp;1
!pip 安装gym[classic_control]
!apt-get 更新 &gt; /dev/null 2&gt;&amp;1
!apt-get install cmake &gt; /dev/null 2&gt;&amp;1
!pip install --upgrade setuptools 2&gt;&amp;1
!pip install ez_setup &gt; /dev/null 2&gt;&amp;1

我收到此错误输出，显示某些安装正确，但有很多“系统找不到指定的路径。”
系统找不到指定的路径。

还有另一个错误
错误：子进程退出并出现错误
  
  python setup.py Egg_info 未成功运行。
  退出代码：1
  
  [77行输出]
  
  
  警告，没有“设置”文件存在，正在运行“buildconfig/config.py”
  使用WINDOWS配置...
  
 
  未找到 FREETYPE 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  找不到 PNG 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  未找到 JPEG 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  freetype 的 DLL：prebuilt-x64/SDL2_ttf-2.0.15/lib/x64/libfreetype-6.dll
  
  ---
  如需编译帮助，请参阅：
      https://www.pygame.org/wiki/CompileWindows
  要为 pygame 开发做出贡献，请参阅：
      https://www.pygame.org/contribute.html
  ---
  
  [输出结束]
  
  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：元数据生成失败

生成包元数据时遇到错误。

请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip 的问题。
提示：详细信息请参见上文。

我尝试用谷歌搜索答案，也尝试过chatgpt，但没有一个能给我答案。任何人都可以帮助这里可怜的灵魂吗:-(,.]]></description>
      <guid>https://stackoverflow.com/questions/78155493/how-can-i-fix-this-error-while-i-was-setting-up-dependencies-in-pythonjupyter-n</guid>
      <pubDate>Wed, 13 Mar 2024 16:44:29 GMT</pubDate>
    </item>
    <item>
      <title>我无法让任何神经网络在 Pytorch 中工作。我究竟做错了什么？</title>
      <link>https://stackoverflow.com/questions/78155402/i-cant-make-any-nn-work-in-pytorch-what-am-i-doing-wrong</link>
      <description><![CDATA[我处理数据，并且在 Python 方面有不错的技能，我知道如何使用不同的模型，但之前我从未尝试过使用神经网络。
所以我是 pytorch 的新手，我决定使用在线教程和视频进行培训。
不幸的是，我发现我真的无法让这些模型发挥作用，并且得到了极其错误的结果。无论我遵循什么指南，这种情况都会发生，所以这肯定是我做错了。
例如，我遵循此分步指南，介绍如何使用波士顿住房数据集创建用于回归的神经网络。
这是我基本上从指南中复制的代码，因此应该没有任何区别。
导入火炬
从火炬导入 nn
从 torch.utils.data 导入 DataLoader
从 sklearn.preprocessing 导入 StandardScaler
将 pandas 导入为 pd

### 导入数据集
波士顿 = pd.read_csv(&#39;./housing.csv&#39;, header=None, sep=&#39;\s+&#39;)
波士顿.列= [
    &#39;犯罪&#39;，
    &#39;ZN&#39;,
    &#39;印度&#39;,
    &#39;查斯&#39;,
    &#39;氮氧化物&#39;,
    &#39;R M&#39;，
    &#39;年龄&#39;，
    &#39;DIS&#39;,
    &#39;RAD&#39;,
    &#39;税&#39;，
    &#39;普拉蒂奥&#39;,
    &#39;B&#39;,
    &#39;LSTAT&#39;,
    &#39;MEDV&#39;
]
xcol = boston.drop(columns=[&#39;MEDV&#39;]).columns
ycol = [&#39;MEDV&#39;]

X = 波士顿[xcol].values
y = 波士顿[ycol].值

### 创建 Torch 数据集
类 TorchDataset(torch.utils.data.Dataset):
    def __init__(self, X, y, scale_data=True):
        如果不是 torch.is_tensor(X) 也不是 torch.is_tensor(y)：
            如果比例数据：
                X = StandardScaler().fit_transform(X)
            self.X = torch.from_numpy(X)
            self.y = torch.from_numpy(y)

    def __len__(自身):
        返回 len(self.X)
    
    def __getitem__(自我，我)：
        返回 self.X[i], self.y[i]

### 构建 MLP
类 MLP(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.layers = nn.Sequential(
            nn.线性(13, 64),
            ReLU(),
            nn.线性(64, 32),
            ReLU(),
            nn.线性(32, 1)
            ）
        
    def 前向（自身，x）：
        返回 self.layers(x)

火炬.manual_seed(42)

数据集 = TorchDataset(X, y)
trainloader = DataLoader（数据集，batch_size = 10，shuffle = True，num_workers = 0）

MLP = MLP()

loss_function = nn.L1Loss()
优化器 = torch.optim.Adam(mlp.parameters(), lr=0.001)

### 训练循环
损失向量 = []

对于范围（1000）内的纪元：
    纪元损失 = 0

    对于 i，enumerate(trainloader, 0) 中的数据：
        输入、目标 = 数据
        输入，目标 = 输入.float(), 目标.float()
        目标 = 目标.reshape((目标.shape[0], 1))

        ## 将梯度归零
        优化器.zero_grad()
        
        ## 前向传球
        输出 = mlp(输入)

        ## 计算损失
        损失=损失函数（输出，目标）

        ## 向后传递
        loss.backward()
        
        ＃＃ 优化
        优化器.step()
        
        ## 统计
        epoch_loss += loss.item()
    
    loss_vec.append(epoch_loss)

## 可视化损失曲线
将plotly.express导入为px
px.scatter(loss_vec)

## 检查观察值和预测值之间的 R2 分数
从 sklearn.metrics 导入 r2_score

y_pred = mlp(torch.tensor(X, dtype=torch.float)).detach().numpy()


r2_score(y.flatten(), y_pred.flatten()) ##总是一个很大的负数

这是损失图

但最奇怪的部分是预测值
pd.DataFrame({
    &#39;观测&#39;:y.flatten(),
    &#39;Pred&#39;:y_pred.flatten()
})


正如您所看到的，我的神经网络预测的值完全超出了范围。
你能告诉我我在这里做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78155402/i-cant-make-any-nn-work-in-pytorch-what-am-i-doing-wrong</guid>
      <pubDate>Wed, 13 Mar 2024 16:30:40 GMT</pubDate>
    </item>
    <item>
      <title>不稳定、依赖种子的训练，具有约 4 种不同的模式</title>
      <link>https://stackoverflow.com/questions/78155315/unstable-seed-dependent-training-with-4-distinct-patterns</link>
      <description><![CDATA[我正在尝试复制一篇论文，但我遇到了不稳定训练的问题。更准确地说，重新运行代码会产生截然不同的结果。不过，我认为有 4 个主要模式。
模型和训练如下所示（完整代码位于https://www. kaggle.com/code/adelphene/dagmm）：
类 DAGMM(nn.Module):
    def __init__(self, input_dim=118, Latent_dim=1, n_gmm=4):
        超级().__init__()

        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 60), nn.Tanh(),
            nn.Linear(60, 30), nn.Tanh(),
            nn.Linear(30, 10), nn.Tanh(),
            nn.Linear(10, Latent_dim),
        ）

        self.decoder = nn.Sequential(
            nn.Linear(latent_dim, 10), nn.Tanh(),
            nn.Linear(10, 30), nn.Tanh(),
            nn.Linear(30, 60), nn.Tanh(),
            nn.Linear(60, input_dim),
        ）

        self.estimator = nn.Sequential(
            nn.Linear(latent_dim + 2, 10), nn.Tanh(),
            nn.Dropout(),
            nn.Linear(10, n_gmm), nn.Softmax(dim=1)
        ）

    def 前向（自身，x）：
        l = self.encoder(x)
        r = self.decoder(l)

        re = (x - r).norm(p=2, dim=1) / x.norm(p=2, dim=1)
        cs = F.cosine_similarity(x, r, 暗淡=1)
        z = torch.cat((l, re.unsqueeze(-1), cs.unsqueeze(-1)), 暗淡=1)

        g = 自估计器(z)

        返回 r、z、g

#------------------------------------------------- -----

torch.autograd.set_detect_anomaly(False)

历元 = 200
lr = 1e-4

loss_fn = 损失()
批次 = len(train_dataloader)
模型 = DAGMM(n_gmm=4).to(设备)
优化器 = torch.optim.Adam(model.parameters(), lr=lr)

对于范围内的纪元（纪元）：
    对于批量，枚举（train_dataloader）中的（x，_）：
        r, z, g = model.train()(x)
        损失，_ = loss_fn(x, r, z, g)
        loss.backward()
        优化器.step()
        优化器.zero_grad()

        如果批次 % 400 == 0:
            r、z、g = model.eval()(val_dataset.x)
            val_loss, e = loss_fn(val_dataset.x, r, z, g)
            阈值 = np.percentile(e.detach().cpu(), 80)
            y_pred = (e &gt; 阈值) * 1
            y_true = val_dataset.y
            报告=分类报告（y_true.cpu（），y_pred.cpu（），output_dict = True）
            a = round(报告[“准确度”], 2)
            p = round(报告[“宏平均值”][“精度”], 2)
            r = round(报告[“宏观平均值”][“召回率”], 2)
            print(f&quot;loss: {round(loss.item(), 3)}, 准确度: {a}, 精度: {p}, 召回率: {r} [{batch+1}/{batches}] [{epoch +1}/{纪元}]”)

需要明确的是，纪元数、优化器和学习率直接取自论文。
我得到的模式如下：

损失降低至 0.5/0.6/0.7，准确率约为 0.88，精确率和召回率均约为 0.82
损失值约为 2.0，准确率约为 0.6，精确率和召回率约为 0.44
损失在 ~1.5 和 ~0.8 之间，准确度在 ~0.75 和 ~0.85 之间，精确率和召回率在 ~0.65 和 ~0.75 之间
（最佳）准确率下降至 ~1.2/~0.8，准确率上升至 ~0.94，精确率和召回率上升至 ~0.92

我不太确定应该如何处理这个问题。任何指导表示赞赏！
PS：我相信我比其他人更频繁地观察模式 2。]]></description>
      <guid>https://stackoverflow.com/questions/78155315/unstable-seed-dependent-training-with-4-distinct-patterns</guid>
      <pubDate>Wed, 13 Mar 2024 16:18:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 sklearns 的 cross_validate 对样本进行加权仅用于评分？</title>
      <link>https://stackoverflow.com/questions/78155034/how-to-weight-samples-with-sklearnss-cross-validate-for-scoring-only</link>
      <description><![CDATA[我正在对由真实样本和增强样本组成的数据集运行回归任务。增强样本是通过抖动真实样本生成的。我想通过与 sklearn 进行交叉验证来选择性能最佳的模型。
为此我想：

在由真实样本和增强样本组成的集合上训练模型。我不希望拟合过程考虑样本的来源（即它应该相当于运行estimator.fit(..., sample_weights = [1,1,..., 1]).
根据模型仅在真实样本上的表现对模型进行评分。为此，我考虑将增强（或真实）样本的权重设置为 0（或 1）。

如何使用sklearn的cross_validate&lt;来实现这一点/代码&gt;？
我尝试了以下方法：
来自 sklearn 导入 model_selection
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 r2_score、mean_squared_error、make_scorer
将 numpy 导入为 np

n_smpl, n_feats = 100, 5
arr_source = np.random.random((n_smpl, n_feats))
arr_target = np.random.random((n_smpl, n_feats))
arr_weight = np.random.randint(0, 2, n_smpl) # 0 表示增强，1 表示真实

模型 = RandomForestRegressor()
kfold_splitter = model_selection.KFold(n_splits=5, random_state=7, shuffle=True)
我的得分者 = {
    “r2_weighted”：make_scorer（r2_score，sample_weight = arr_weight），
    “mse_weighted”：make_scorer（mean_squared_error，greater_is_better = False，sample_weight = arr_weight）
}

cv_results = model_selection.cross_validate（模型，arr_source，arr_target，评分= my_scorers，cv = kfold_splitter）

但这会返回ValueError：发现样本数量不一致的输入变量：[20, 20, 100]。我知道发生这种情况是因为 cross_validate 无法根据折叠分割样本权重。
有什么方法可以让它通过交叉验证吗？或者还有其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78155034/how-to-weight-samples-with-sklearnss-cross-validate-for-scoring-only</guid>
      <pubDate>Wed, 13 Mar 2024 15:36:03 GMT</pubDate>
    </item>
    <item>
      <title>我们可以结合 RL 和 ML/DL 来进行复杂的二元分类吗？</title>
      <link>https://stackoverflow.com/questions/78154666/can-we-conbine-rl-and-ml-dl-to-do-a-complex-binary-classfication</link>
      <description><![CDATA[事情是这样的：
有一个金融数据集（Freddie Mac Single-Family Loan-Level Dataset），其中包含：客户的地址、交易流向以及许多其他特征（大约20个）。
有一个特征可以判断客户是否存在延期还款的情况，即判断他是否是诈骗者。
我想通过 RL 和 ML/DL 组合来学习所有其他功能。然后只有通过在模型中输入其他特征来判断该客户是否会进行欺诈。
我目前的想法是：从随机分类开始，然后利用RL和ML/DL结合模型不断调整分类方法（调整特征权重、模型中的内部指标等）以获得最佳分类方法并获得最高的分类精度。
但是我不知道如何开始，因为我对强化学习不是很熟悉。 （我对深度学习和机器学习比较熟悉）
我找不到任何相关参考资料。
有人可以给我一个想法或教程吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78154666/can-we-conbine-rl-and-ml-dl-to-do-a-complex-binary-classfication</guid>
      <pubDate>Wed, 13 Mar 2024 14:42:00 GMT</pubDate>
    </item>
    <item>
      <title>使用文本特征的二元分类导致 AUC 分数非常低</title>
      <link>https://stackoverflow.com/questions/78154496/binary-classification-using-textual-features-results-in-very-low-auc-scores</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78154496/binary-classification-using-textual-features-results-in-very-low-auc-scores</guid>
      <pubDate>Wed, 13 Mar 2024 14:20:24 GMT</pubDate>
    </item>
    <item>
      <title>如何对困难数据进行多项式回归？</title>
      <link>https://stackoverflow.com/questions/78154421/how-do-i-do-polynomial-regression-right-on-difficult-data</link>
      <description><![CDATA[我的多项式回归遇到问题。由于某种原因，我的线画错了。我查看了堆栈上的其他类似问题，但找不到适合我的解决方案。我正在处理价格 (y) 和评论数量 (X)。
有人遇到过类似的事情或对相似的数据成功完成多项式回归吗？
这是我的代码：
# 定义自变量和因变量
X = cph_listings_df[[&#39;reviews_per_month&#39;]].values.reshape(-1, 1)
y = cph_listings_df[&#39;价格&#39;].values.reshape(-1, 1)

# 分为测试和训练
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# 尺度特征
定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)

# 对数据集进行线性回归拟合
lin_reg = 线性回归()
lin_reg.fit(X, y)

# 将多项式回归拟合到数据集
poly_model = 多项式特征（度=2）
X_poly = poly_model.fit_transform(X) # 将 X 变换为多边形特征
pol_reg = LinearRegression() # 线性回归实例
pol_reg.fit(X_poly, y) # 训练模型
y_predict = pol_reg.predict(X_poly) # 对训练模型进行预测
plt.scatter(X, y, color=&#39;red&#39;) # red = 实际数据点
    plt.plot(X, y_predict, color=&#39;blue&#39;)
    plt.title(&#39;多项式回归)&#39;)
    plt.xlabel(&#39;评论数量&#39;)
    plt.ylabel(&#39;价格&#39;)
    plt.show()

这是图表：

这是我的老师告诉我我需要得到的（我自己画的线）：

我尝试在运行代码之前对 X 值进行排序，但对我来说没有任何改变。]]></description>
      <guid>https://stackoverflow.com/questions/78154421/how-do-i-do-polynomial-regression-right-on-difficult-data</guid>
      <pubDate>Wed, 13 Mar 2024 14:06:54 GMT</pubDate>
    </item>
    <item>
      <title>在python中创建线性回归模型的问题</title>
      <link>https://stackoverflow.com/questions/78152862/problem-with-creating-a-linear-regression-model-in-python</link>
      <description><![CDATA[我有一个数据库，其中包含一个城市的多个属性：
该数据库中保存了各种属性（约 19,000 个）。每个房产都有一些特征，例如：销售价格、房产面积、浴室数量、建造年份、上市天数......
我是机器学习算法编程的新手，希望首先编写一个简单的线性回归模型，该模型可以根据其他数据预测该房产的上市天数。
数据保存在Excel中。
这就是我所做的：
&lt;前&gt;&lt;代码&gt;
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.metrics 导入mean_squared_error, r2_score
从 sklearn.model_selection 导入 train_test_split
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd
导入请求


模型=线性回归()
data=pd.read_excel(r“C:\Users....”)

X=np.array(data.drop([“daysOnMarket”], axis=1))
Y=np.array(数据[“daysOnMarket”])
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)
model.fit(x_train, y_train)
y_pred=模型.预测(x_test)
print(model.score(x_test, y_test))
打印（均方误差（y_test，y_pred））


现在让我觉得我做错了的是，我得到的分数是 0.9999852324248868，均方误差是 0.07659752059595726
现在我不明白这是一个过度拟合问题还是我只是在编程中做错了什么。
谁能帮我找出问题出在哪里吗？
这是我的数据示例：
]]></description>
      <guid>https://stackoverflow.com/questions/78152862/problem-with-creating-a-linear-regression-model-in-python</guid>
      <pubDate>Wed, 13 Mar 2024 10:06:17 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用不同的 yaml 文件来微调新数据集的模型，但与之前的数据集具有相同的类吗？</title>
      <link>https://stackoverflow.com/questions/78152669/can-we-use-different-yaml-file-for-fine-tuning-a-model-with-newdataset-but-has-s</link>
      <description><![CDATA[我使用我的自定义数据集训练了 YOLOv8 模型，其中使用了 ultralytics 和 pytorch。我具有与第一个数据集相同的数据集，但图像中对象的位置在新数据集中发生了更改。现在，如果我在不从第一个数据集 YAML 文件中获取任何引用的情况下进行注释，它会起作用吗？
第一个经过训练的 YAML 文件如下：
训练：/home/user/Code/newdata/YOLODataset/images/train/
val：/home/user/Code/newdata/YOLODataset/images/val/
测试：/home/user/Code/newdata/YOLODataset/images/test/
数控：8
名称：[“货架”、“托盘”、“条形码”、“box-botte”、“mbox”、“cobj”、“糖浆”、“半”]

微调 yaml 文件：
训练：/home/user/Code/newdata/YOLODataset/images/train/
val：/home/user/Code/newdata/YOLODataset/images/val/
测试：/home/user/Code/newdata/YOLODataset/images/test/
数控：7
名称：[“货架”、“托盘”、“条形码”、“盒子瓶”、“mbox”、“糖浆”、“半个”]

第二个 YAML 文件适合微调自定义预训练模型吗？我第一次使用 520 张图像和 25 个 epoch 进行训练。现在我应该微调模型多少张图像和纪元？
提前致谢
我使用 Pytorch 和 Ultralytics。我可以按照上面的YAML文件进行微调吗？]]></description>
      <guid>https://stackoverflow.com/questions/78152669/can-we-use-different-yaml-file-for-fine-tuning-a-model-with-newdataset-but-has-s</guid>
      <pubDate>Wed, 13 Mar 2024 09:41:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么 e 在神经网络中使用得如此之多？</title>
      <link>https://stackoverflow.com/questions/78152237/why-is-e-used-so-much-in-the-nn</link>
      <description><![CDATA[我不明白为什么我们在神经网络中如此频繁地使用“e”，可能是 sigmoid 函数或 softmax 函数。
在 sigmoid 函数中，我们本质上是将值 y=mx+b 压缩到 0-1 范围内，那么为什么我们专门使用“e”。如果我们凭直觉，使用“2”而不是“e”是有意义的，我的意思是我们要进行二元分类，这样才有意义，对吗？
另外，在softmax函数中，我们采用e^x / sum(e^x)，为​​什么我们需要这样做，我的意思是我们试图获得x属于哪个类的概率，所以为什么不能我们只是知道像这样 x/sum(abs(x)) 吗？]]></description>
      <guid>https://stackoverflow.com/questions/78152237/why-is-e-used-so-much-in-the-nn</guid>
      <pubDate>Wed, 13 Mar 2024 08:31:52 GMT</pubDate>
    </item>
    <item>
      <title>如何检测图片是否上下颠倒？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78151191/how-to-detect-if-a-picture-is-upside-down</link>
      <description><![CDATA[我的团队正在开发一项在 AWS 上运行并从 S3 存储桶中提取图片的服务。这些图片是来自监控摄像头视频流的帧，导致它们没有 Exif 元数据，而且大多数时候，图片中不会有任何人。
该服务需要“读取”这些图片并区分其中是否有颠倒的情况，以便我们确定这些相机是否正常工作。最初我以为可以使用AWS Rekognition，但是看了文档，似乎无法满足要求。
所以，我想知道是否有任何 AWS 服务或库可以完成此任务并部署在 Lambda 或 ECS 中？]]></description>
      <guid>https://stackoverflow.com/questions/78151191/how-to-detect-if-a-picture-is-upside-down</guid>
      <pubDate>Wed, 13 Mar 2024 04:08:00 GMT</pubDate>
    </item>
    <item>
      <title>为多标签 ViTForImageClassification 准备数据集</title>
      <link>https://stackoverflow.com/questions/77967230/prepare-a-dataset-for-multilabel-vitforimageclassification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77967230/prepare-a-dataset-for-multilabel-vitforimageclassification</guid>
      <pubDate>Fri, 09 Feb 2024 09:52:59 GMT</pubDate>
    </item>
    <item>
      <title>xgboost 错误：dtypes 必须是 int、float 或 bool，但它们是</title>
      <link>https://stackoverflow.com/questions/67977854/xgboost-error-dtypes-must-be-int-float-or-bool-but-they-are</link>
      <description><![CDATA[我有一个经过预处理的房地产相关DataFrame，具有以下数据类型：
&lt;前&gt;&lt;代码&gt;&gt;&gt; df.dtype

OHE_Cat__x0_单户住宅 Int64
OHE_Cat__x0_联排别墅 Int64
OHE_Cat__x1_1 Int64
OHE_Cat__x1_2 Int64
邮政编码 Int64
价格 Int64
床位 Int64
浴室 Float64
平方英尺 Int64
批量大小 Int64
建造年份 Int64
纬度 Float64
经度 Float64
年龄 Int64
时间 VAR UNIX Int64
is_Pandemic 布尔值
is_CY 布尔值
数据类型：对象

但是，当尝试拟合我的 XGBRegressor 时，我收到以下错误：
ValueError：数据的 DataFrame.dtypes 必须是 int、float 或 bool。
            没想到字段 OHE_Cat__x0_Single Family Residential、OHE_Cat__x0_Townhouse、OHE_Cat__x1_1、OHE_Cat__x1_2、ZIP OR POSTAL CODE、BEDS、BATHS、SQUARE FEET、LOT SIZE、YEAR BUILT、LATITUDE、LONGITUDE、Age、TIME VAR UNIX、is_Pandemic、is_CY 中的数据类型

奇怪的是，当我使用pd.get_dummmies时，这个错误并不存在，但在切换到sklearn.preprocessing.OneHotEncoder后，我开始收到它，所以我在想我的下面的代码有错误吗？
oneHotE = OneHotEncoder(drop=&#39;first&#39;)
变压器 = ColumnTransformer([(&#39;OHE_Cat&#39;, oneHotE, 分类)], 剩余 = &#39;直通&#39;)
    
df = pd.DataFrame(transformer.fit_transform(df), columns=transformer.get_feature_names()).convert_dtypes()

在train_test_split之前，我已尝试对数据集进行以下更改：
df = df.apply(pd.to_numeric, axis=1)
df = df.apply(pd.to_numeric, axis=0)
df = df.convert_dtypes()
df = df.dropna()
df = df._get_numeric_data()

编辑：

RandomForestRegressor 运行正常，没有错误，但出现以下警告：

&lt;块引用&gt;
futurewarning：字节/字符串数组正在转换为十进制
如果 dtype=&#39;numeric&#39; 则为数字。此行为在 0.24 中已弃用，并且
将在 1.1 中删除（0.26 重命名）。请将您的数据转换为
明确地改为数值。


CatBoostRegressor 出现以下错误：无法将 FloatingArray 转换为 numpy.ndarray
]]></description>
      <guid>https://stackoverflow.com/questions/67977854/xgboost-error-dtypes-must-be-int-float-or-bool-but-they-are</guid>
      <pubDate>Mon, 14 Jun 2021 22:20:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在sklearn中计算.fit()训练模型的实际大小？</title>
      <link>https://stackoverflow.com/questions/45601897/how-to-calculate-the-actual-size-of-a-fit-trained-model-in-sklearn</link>
      <description><![CDATA[是否可以在 scikit-learn 中计算模型（假设是随机森林分类器）的大小？ 
例如：

&lt;块引用&gt;
 from sklearn.ensemble import RandomForestClassifier
  clf = RandomForestClassifier(n_jobs=-1, n_estimators=10000, min_samples_leaf=50)
  clf.fit(self.X_train, self.y_train)


我可以确定clf的大小吗？]]></description>
      <guid>https://stackoverflow.com/questions/45601897/how-to-calculate-the-actual-size-of-a-fit-trained-model-in-sklearn</guid>
      <pubDate>Wed, 09 Aug 2017 23:00:07 GMT</pubDate>
    </item>
    </channel>
</rss>