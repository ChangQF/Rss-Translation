<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 27 Oct 2024 21:14:43 GMT</lastBuildDate>
    <item>
      <title>调用 BroadcastTo.call() 时遇到异常</title>
      <link>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</guid>
      <pubDate>Sun, 27 Oct 2024 19:29:36 GMT</pubDate>
    </item>
    <item>
      <title>绝对、相对、旋转和学习位置编码之间的区别[关闭]</title>
      <link>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</link>
      <description><![CDATA[位置编码（绝对、相对、旋转）和学习到的位置编码之间有什么区别？
我了解绝对、相对和旋转编码之间的区别，但我无法识别这些编码和学习到的位置编码之间的任何区别。]]></description>
      <guid>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</guid>
      <pubDate>Sun, 27 Oct 2024 16:39:04 GMT</pubDate>
    </item>
    <item>
      <title>删除所有人口后，Python NEAT 给出错误</title>
      <link>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</guid>
      <pubDate>Sun, 27 Oct 2024 16:27:23 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的负损失没有减少</title>
      <link>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</guid>
      <pubDate>Sun, 27 Oct 2024 16:07:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么卷积层的输出形状不能跨通道相乘？</title>
      <link>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</link>
      <description><![CDATA[# 第一个卷积层：输入通道 = 1，输出通道 = 32，内核大小 = 5x5，填充 = 2（相同）
self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)
# 第一个池化层：最大池化，内核大小 = 2x2，步长 = 2
self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

# 第二个卷积层：输入通道 = 32，输出通道 = 64，内核大小 = 5x5，填充 = 2（相同）
self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
# 第二个池化层：最大池化，内核大小 = 2x2， stride = 2
self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

问题：为什么第二个卷积层后的输出不是
14 * 14 * 32 * 64？对于32通道的输入，每个卷积核只作用于一个通道，因此会产生64种不同的结果。难道不应该将32个通道相乘吗？
我得到的答案是：对于输入的每个14 * 14位置，5532核与5532输入区域进行点积将产生14*14的单通道输出。核大小不是5 * 5吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</guid>
      <pubDate>Sun, 27 Oct 2024 14:14:47 GMT</pubDate>
    </item>
    <item>
      <title>输入图像与 TensorFlow 模型输入形状不兼容</title>
      <link>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</link>
      <description><![CDATA[我正在构建一个模型，我想测试它的性能，因此我导入了一个本地文件并加载它，并尝试使用以下代码预测它的标签：
from tensorflow.preprocessing import image
# tensorlfow 等的其他导入。

#...

# 示例图像
img_path = &quot;./Model/data/brain/train/Glioma/images/gg (2).jpg&quot;
img = image.load_img(img_path,target_size=(256,256))
arr = image.img_to_array(img)
t_img = tf.convert_to_tensor(arr)
print(t_img.shape) # 返回 (256,256,3)
# 客户端测试
client = Client(&quot;brain&quot;) # 自定义类。包含模型：顺序（已编译和训练）
client.predict(img=t_img) # 调用 self.model.predict(t_img)

但是我收到以下错误：
输入 Tensor(&quot;data:0&quot;, shape=(32, 256, 3), dtype=float32) 的输入形状无效。预期形状 (None, 256, 256, 3)，但输入具有不兼容的形状 (32, 256, 3)

我在训练模型中有一个输入层，其 input_shape=[256,256,3]（来自图像宽度、高度和 rgb 值）
您能帮助我理解问题并解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</guid>
      <pubDate>Sun, 27 Oct 2024 11:57:01 GMT</pubDate>
    </item>
    <item>
      <title>在节点特征向量中添加缺失的独立特征类别并进行填充</title>
      <link>https://stackoverflow.com/questions/79130492/add-the-missing-independent-feature-categories-in-node-feature-vector-with-paddi</link>
      <description><![CDATA[我正在使用 esm-2 编码蛋白质的每个节点特征，并使用 graphormer 编码全局配体特征。
我希望我可以连接两个特征矩阵，并在蛋白质和配体图中缺失的特征类别上添加填充 0，例如，蛋白质特征（二级结构）和配体特征（节点类型）在这两个图中均未找到。如果我在输入线性层以计算密集特征之前添加 0 来填补这些缺失的类别，然后再输入到其他模型中，这会给模型造成很大的混乱吗？
我在这里遇到了困难：
模型会将 0 解释为该标签应该是类别集之一的值，例如（0 = 来自 esm-2 的 beta sheet 类类别，那么如果我在类别中填充，它会让模型无法理解配体吗？）
这种方法是否有效区分蛋白质或配体特征的不同？
我搜索了填补缺失类别的方法。天气特征传播或融合矩阵或匹配。我不太符合我目前的情况。]]></description>
      <guid>https://stackoverflow.com/questions/79130492/add-the-missing-independent-feature-categories-in-node-feature-vector-with-paddi</guid>
      <pubDate>Sun, 27 Oct 2024 11:44:02 GMT</pubDate>
    </item>
    <item>
      <title>从 CLIP 的中间层提取嵌入</title>
      <link>https://stackoverflow.com/questions/79130488/extracting-embeddings-from-clips-intermediate-layers</link>
      <description><![CDATA[我正在试验 CLIP 模型。
我加载了一个预训练模型，想看看中间层的嵌入是什么样子。我使用的代码如下：
dataset = CelebADataset(root_dir=&quot;celeba/img_align_celeba&quot;, transform=preprocess)
dataloader = DataLoader(dataset, batch_size=32, shuffle=False)

device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
model, _ = clip.load(&quot;ViT-B/32&quot;, device=device)

features = {}
def hook_fn(module, input, output):
features[module] = output[:, 0, :]

# model.patch_embed.register_forward_hook(hook_fn) # 不为 patch_embed 层注册钩子

for i, block in enumerate(model.visual.transformer.resblocks):
block.register_forward_hook(hook_fn) # 每个块

all_features = {
# &#39;patch_embed&#39;: [],
&#39;block_0&#39;: [],
&#39;block_1&#39;: [],
&#39;block_2&#39;: [],
&#39;block_3&#39;: [],
&#39;block_4&#39;: [],
&#39;block_5&#39;: [],
&#39;block_6&#39;: [],
&#39;block_7&#39;: [],
&#39;block_8&#39;: [],
&#39;block_9&#39;: [],
&#39;block_10&#39;: [],
&#39;block_11&#39;: [],
&#39;final&#39;: []
}
all_labels = []

使用 torch.no_grad():
for input in tqdm(dataloader):
input = input.to(device)
final_output = model.encode_image(inputs)

# 将特征转换为 numpy 并存储
for i in range(12):
all_features[f&#39;block_{i}&#39;].append(features[model.visual.transformer.resblocks[i]].cpu().numpy())
all_features[&#39;final&#39;].append(final_output.cpu().numpy())

# all_labels.append(labels.cpu().numpy())

for key在 all_features 中：
all_features[key] = np.concatenate(all_features[key], axis=0)
# all_labels = np.concatenate(all_labels, axis=0)

np.save(&quot;celeba_block0.npy&quot;, all_features[f&#39;block_{0}&#39;])
np.save(&quot;celeba_block1.npy&quot;, all_features[f&#39;block_{1}&#39;])
...

我之前用 Dino 做过类似的事情，在对 Dino 的嵌入进行降维后，我可以看到不同标签组中的图像形成了不同的簇。然而，当我检查 CLIP 的嵌入时，除了最终的嵌入之外，我没有看到清晰的集群。
这是因为 CLIP 的网络结构与 Dino 不同，还是我的代码错误？
我试图查看 CLIP 的结构，但我无法找到对此的解释。]]></description>
      <guid>https://stackoverflow.com/questions/79130488/extracting-embeddings-from-clips-intermediate-layers</guid>
      <pubDate>Sun, 27 Oct 2024 11:38:57 GMT</pubDate>
    </item>
    <item>
      <title>通过电子邮件对话训练 GPT-3</title>
      <link>https://stackoverflow.com/questions/75783524/train-gpt-3-on-email-conversations</link>
      <description><![CDATA[我必须在电子邮件数据上训练 GPT-3，以便支持团队可以从聊天机器人那里快速获得客户之前提出的问题的答案。客户和支持团队之间有电子邮件对话（客户 1 提出问题，支持团队回答，客户 1 提出另一个问题……）。我必须：

过滤重要的对话并仅向 GPT-3 提供它们。
准备并将它们转换为正确的格式，以便我可以训练模型。

关于如何实现这些步骤以及是否使用微调或嵌入，有什么想法吗？
GPT-3 必须将问题与支持团队给出的答案联系起来。]]></description>
      <guid>https://stackoverflow.com/questions/75783524/train-gpt-3-on-email-conversations</guid>
      <pubDate>Sun, 19 Mar 2023 16:44:07 GMT</pubDate>
    </item>
    <item>
      <title>如何对不同特征工程过程中的特征进行标准化和规范化？</title>
      <link>https://stackoverflow.com/questions/66376105/how-to-perform-standardization-and-normalization-on-features-from-different-feat</link>
      <description><![CDATA[我正在处理一个数据集，其中每个样本都包含数字和文本数据。因此，采用多种方法从数据集构建训练特征矩阵。对于数据集中的每个样本，我从 3 个部分构建一个向量表示。

段落文本的 Doc2Vec 向量表示：我使用 gensim 段落向量的实现 将文本编码为 [-5, 5] 之间的 100-D 浮点向量

文本标签的独热编码向量：数据集中的每个样本都有零个或多个文本标签，我汇总数据集中使用的所有唯一标签并将其编码为仅包含 0 和 1 的二进制数组。例如，如果完整的标签集为 [Python, Java, JavaScript, C++]，且样本包含标签 Python 和 Java，则结果向量将为 [1, 1, 0, 0]。

数值数据 &amp;分类数据：

数字数据字段按原样内置到特征向量中
分类数据映射到整数并内置到特征向量中



生成的特征矩阵如下所示
[
[-1.02, 1.33, 2.35, -0.48, ... -4.11, 1, 0, 1, 1, 0, 0, ..., 1, 0, 235, 11.5, 333],
[-0.22, 3.03, 1.95, -0.48, ... -4.11, 0, 1, 1, 1, 0, 0, ..., 0, 0, 233, 22, 333],
[-2.07, -1.33, -2.35, -0.48, ... -4.11, 1, 1, 0, 1, 1, 0, ..., 1, 1, 102, 13, 333],
[-4.32, 4.33, 1.75, -0.48, ... -4.11, 0, 0, 0, 1, 0, 1, ..., 1, 0, 98, 8, 333],
]

我是否应该对数据集应用任何标准化或规范化？如果是，我应该在连接特征的不同部分之前还是之后进行？
我正在使用 scikit-learn，我使用的主要算法是梯度提升。]]></description>
      <guid>https://stackoverflow.com/questions/66376105/how-to-perform-standardization-and-normalization-on-features-from-different-feat</guid>
      <pubDate>Thu, 25 Feb 2021 20:38:50 GMT</pubDate>
    </item>
    <item>
      <title>了解 FeatureHasher、碰撞和向量大小权衡</title>
      <link>https://stackoverflow.com/questions/65108407/understanding-featurehasher-collisions-and-vector-size-trade-off</link>
      <description><![CDATA[在实施机器学习模型之前，我正在预处理我的数据。一些特征具有高基数，例如国家和语言。
由于将这些特征编码为独热向量会产生稀疏数据，因此我决定研究哈希技巧并使用 python 的 category_encoders，如下所示：
from category_encoders.hashing import HashingEncoder
ce_hash = HashingEncoder(cols = [&#39;country&#39;])
encoded = ce_hash.fit_transform(df.country)
encoded[&#39;country&#39;] = df.country
encoded.head()

查看结果时，我可以看到冲突
 col_0 col_1 col_2 col_3 col_4 col_5 col_6 col_7 国家
0 0 0 1 0 0 0 0 0 US &lt;━┓
1 0 1 0 0 0 0 0 0 CA。┃ US 和 SE 相撞 
2 0 0 1 0 0 0 0 0 SE &lt;━┛
3 0 0 0 0 0 0 1 0 JP

进一步调查让我找到了这篇 Kaggle 文章。那里的哈希示例包括X 和 y。

y 的用途是什么，它有助于解决碰撞问题吗？
我是否应该向编码器添加更多列并同时编码多个特征（例如国家和语言）？

如何使用哈希技巧对这些类别进行编码？
更新：
根据我从@CoMartel 得到的评论，我查看了Sklearn FeatureHasher并编写了以下代码来哈希国家列：
from sklearn.feature_extraction import FeatureHasher
h = FeatureHasher(n_features=10,input_type=&#39;string&#39;)
f = h.transform(df.country)
df1 = pd.DataFrame(f.toarray())
df1[&#39;country&#39;] = df.country
df1.head()

并得到以下输出：
 0 1 2 3 4 5 6 7 8 9 country
0 -1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 -1.0 0.0 US
1 -1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 -1.0 0.0 US
2 -1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 -1.0 0.0 美国 3 0.0 -1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 CA 4 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 -1.0 0.0 SE 5 0.0 0.0 0.0 0.0 0.0 0.0 .0 0.0 0.0 0.0 日本 6 -1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 AU 7 -1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 AU 8 -1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 DK
9 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 -1.0 0.0 SE


这是使用库来编码高分类值的方法吗？
为什么有些值为负数？
您如何选择“正确”的 n_features 值？
如何检查碰撞率？
]]></description>
      <guid>https://stackoverflow.com/questions/65108407/understanding-featurehasher-collisions-and-vector-size-trade-off</guid>
      <pubDate>Wed, 02 Dec 2020 12:46:42 GMT</pubDate>
    </item>
    <item>
      <title>如何计算召回率、准确率和 f 度量？</title>
      <link>https://stackoverflow.com/questions/56608300/how-to-calculate-recall-precision-and-f-measure</link>
      <description><![CDATA[我正在做一个情绪分析项目。
我需要计算召回率、准确率和 f 度量，但我不知道我的数据集的语法，如下所示：
#训练数据格式，包含文本的单词及其权重和文本的类标签

train_set = [
({&#39;adam&#39;: 0.05,&#39;is&#39;: 0.0, &#39;a&#39;: 0.0, &#39;good&#39;: 0.02, &#39;man&#39;: 0.0}, 1),
({&#39;eve&#39;: 0.0, &#39;is&#39;: 0.0, &#39;a&#39;: 0.0,&#39;good&#39;: 0.02,&#39;woman&#39;: 0.0}, 1),
({&#39;adam&#39;: 0.05, &#39;is&#39;: 0.0, &#39;evil&#39;: 0.0}, 0)]

#0 或 1 表示类标签

#测试数据与训练数据相同

这是我当前的代码
from nltk.classify import apply_features

def naivebyse(finaltfidfVector):
train_set = []
j = 0
for vector in finaltfidfVector:
if j &lt; 2100: # 取 70% 的数据进行训练
train_set.append(vector)
j += 1
else:
break

test_set = []
j = 0
for vector in finaltfidfVector:
if j &lt; 3000 和 j &gt;= 2100：# 测试的 30%
test_set.append(vector)
if j&gt;= 3000:
break
j += 1

classifier = nltk.NaiveBayesClassifier.train(train_set)
print(&quot;讽刺分类器的准确率：&quot;, 
(nltk.classify.accuracy(classifier, test_set)*100))
refsets = collections.defaultdict(set)
testsets = collections.defaultdict(set)

for i, (feats, label) in enumerate(test_set):
refsets[label].add(i)
perceived = classifier.classify(feats)
testsets[observed].add(i)

print(&quot;准确率百分比：&quot; , nltk.metrics.precision(refsets[&#39;1&#39;], 
testsets[&#39;1&#39;])*100)
print(&quot;Recall Percentage : &quot;, nltk.metrics.recall(refsets[&#39;1&#39;], 
testsets[&#39;1&#39;])*100)

异常
Tkinter 回调中的异常
无法重新分配 20234 字节

有人可以提供一些关于如何执行任务的提示吗？]]></description>
      <guid>https://stackoverflow.com/questions/56608300/how-to-calculate-recall-precision-and-f-measure</guid>
      <pubDate>Sat, 15 Jun 2019 07:25:35 GMT</pubDate>
    </item>
    <item>
      <title>理解策略和价值函数强化学习[关闭]</title>
      <link>https://stackoverflow.com/questions/44157418/understanding-policy-and-value-functions-reinforcement-learning</link>
      <description><![CDATA[您有一个策略，它实际上是我所有状态的行动概率分布。价值函数决定了实现最高奖励的最佳行动方案。
所以我有一个随机策略。我得到了价值函数。我根据价值函数用新的分布更新我的策略。我得到了这个新更新策略的价值函数并再次重新评估。
根据这个定义，我很难理解价值迭代将如何工作，我认为这是对价值函数的误解。
价值函数不是最佳行动方案，它只是决定奖励的行动方案？策略迭代是否只是寻找一个提供比当前奖励更高的奖励的价值函数，然后立即更新，从而为我的状态提供新的操作分布（新策略），然后迭代地对每个状态执行此操作，直到收敛？
在这种情况下，价值迭代是否会在序列中的每个状态下寻找单个最佳操作（而不是更好的操作）？我在这里努力理解为什么不会更新策略？
我对策略和价值函数等的理解是否正确？
我认为我对策略的理解肯定是错误的：如果策略只是对我的状态的所有可能操作的分布，那么我不完全确定“更新”是什么意思。如果它只是更新分布，那么如果它使用“更差”的分布，那么价值迭代究竟如何工作，因为策略在初始化时最初不是随机的吗？我不明白这些如何能融合并且同样好？]]></description>
      <guid>https://stackoverflow.com/questions/44157418/understanding-policy-and-value-functions-reinforcement-learning</guid>
      <pubDate>Wed, 24 May 2017 11:42:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 scikit learn 计算多类别情况的精确度、召回率、准确度和 f1 分数？</title>
      <link>https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case</guid>
      <pubDate>Wed, 15 Jul 2015 04:17:36 GMT</pubDate>
    </item>
    <item>
      <title>强化学习的良好实现？[关闭]</title>
      <link>https://stackoverflow.com/questions/740389/good-implementations-of-reinforcement-learning</link>
      <description><![CDATA[对于一个人工智能项目，我需要实现一个强化学习算法，该算法可以打败一个简单的俄罗斯方块游戏。该游戏是用 Java 编写的，我们有源代码。我知道强化学习理论的基础知识，但想知道 SO 社区中是否有人有这方面的经验。

对于在俄罗斯方块游戏中实施强化学习，您推荐的阅读材料是什么？
是否有值得一看的优秀开源项目可以完成类似的事情？

越具体越好，但欢迎提供有关该主题的一般资源。
跟进：
这是我为未来的学生提供的解决方案（代码和写作）：
论文 / 代码]]></description>
      <guid>https://stackoverflow.com/questions/740389/good-implementations-of-reinforcement-learning</guid>
      <pubDate>Sat, 11 Apr 2009 16:32:19 GMT</pubDate>
    </item>
    </channel>
</rss>