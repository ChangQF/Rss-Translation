<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 17 Apr 2024 09:14:27 GMT</lastBuildDate>
    <item>
      <title>机器学习模型中分类数据平均二进制编码方法的澄清</title>
      <link>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</link>
      <description><![CDATA[有很多方法可以将分类数据转换为各种机器学习任务的数值数据。然而，大多数编码方法（例如 One-Hot 编码）会创建更多的数据集列，从而产生高维数据。因此，我介绍一种称为平均二进制编码的方法，该方法在训练模型中应用二进制数据表示。提出的方法如下：
平均二进制值 (X)} = \\frac{1}{|N|}\\sum\_{i=1}^{|N|} B\_{X}

哪里|N|是分类数据X中二进制值的长度，B是分类数据X的二进制表示。
&lt;前&gt;&lt;代码&gt;|分类数据 |应用于配方|编码数据|
| ---------------- | -------------------------------------------------- -------------------------------------------------- --| ------------------ |
|男 | (0+1+0+0+1+1+0+1+0+1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0 +1+1+0+0+1+0+1) ÷ 32 | 0.46875 |
|女 | (0+1+0+0+0+1+1+0+0+1+1+0+0+1+0+1+0+1+1+0+1+1+0+1+0 +1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0+1+1+0+0+1+0+1) ÷ 48 | 0.4791666666666667 |
|是的 | (0+1+0+1+1+0+0+1+0+1+1+0+0+1+0+1+0+1+1+1+0+0+1+1) ÷ 24 | 0.5416666666666666 |
|没有 | (0+1+0+0+1+1+1+0+0+1+1+0+1+1+1+1) ÷16 | 0.625 | 0.625
| 1 | (0+0+1+1+0+0+0+1) ÷ 8 | 0.375 | 0.375
| 0 | (0+0+1+1+0+0+0+0) ÷ 8 | 0.25 | 0.25

例如，
分类数据“男性”的二进制表示为 01001101011000010110110001100101。
该二进制数据的长度是 32。
因此，根据公式，编码值为0.46875。
我想进一步了解这种编码方法，看看它是否适用于机器学习模型。
对分类数据进行编码是否有任何具体注意事项或限制？]]></description>
      <guid>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</guid>
      <pubDate>Wed, 17 Apr 2024 09:09:55 GMT</pubDate>
    </item>
    <item>
      <title>是否有在训练中使用负例来改进特征学习的方法？</title>
      <link>https://stackoverflow.com/questions/78339582/are-there-methods-for-using-negative-examples-in-training-in-order-to-improve-fe</link>
      <description><![CDATA[我有一个人工智能，它应该生成图像作为合成数据，用于训练图像分类人工智能。
结果不够现实/准确，无法用作培训课程的实际数据点。
我可以将它们用作“反例”，以便人工智能学会不以某种方式对它们进行分类，即使它们看起来与真实物体相似？这可以用来让人工智能更详细地了解课程的真实特征吗？
是否存在这样的事情，或者这是一个不好的方法？
我尝试在网上做一些研究，但诸如“out-ouf-distributionlearning”、“contrastivelearning”、“inversereinforcementlearning”之类的东西都没有。都指不同的事物...]]></description>
      <guid>https://stackoverflow.com/questions/78339582/are-there-methods-for-using-negative-examples-in-training-in-order-to-improve-fe</guid>
      <pubDate>Wed, 17 Apr 2024 08:45:04 GMT</pubDate>
    </item>
    <item>
      <title>** 进入 DGEES 时，参数号 13 具有非法值</title>
      <link>https://stackoverflow.com/questions/78338695/on-entry-to-dgees-parameter-number-13-had-an-illegal-value</link>
      <description><![CDATA[我是机器学习的新手。
我正在运行一个定义了 arima 模型（auto_arima 函数）的 python 应用程序。
与 scipy==1.12.0 &amp; numpy==1.26.4。
执行后，出现错误，
** 在进入 DGEES 参数 13 时有一个非法值
如何查看数字 13 是多少？我该如何处理这个问题？
如果需要更多详细信息，请告诉我。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78338695/on-entry-to-dgees-parameter-number-13-had-an-illegal-value</guid>
      <pubDate>Wed, 17 Apr 2024 06:08:48 GMT</pubDate>
    </item>
    <item>
      <title>隔离森林、自动编码器、ADTK Lib</title>
      <link>https://stackoverflow.com/questions/78338298/isolation-forest-vs-autoencoder-vs-adtk-lib</link>
      <description><![CDATA[我有一个项目，我对不同公司的股票市场数据进行异常检测，数据集为雅虎财经。隔离森林、自动编码器和 ADTK Lib 哪种异常检测方法最好。
我已经准备好了代码。我得到的准确度大致相同。]]></description>
      <guid>https://stackoverflow.com/questions/78338298/isolation-forest-vs-autoencoder-vs-adtk-lib</guid>
      <pubDate>Wed, 17 Apr 2024 04:08:46 GMT</pubDate>
    </item>
    <item>
      <title>小时间序列数据集中的异常值检测[关闭]</title>
      <link>https://stackoverflow.com/questions/78337873/outliers-detection-in-a-small-time-series-dataset</link>
      <description><![CDATA[我在一个月内从 400 个网络外围设备获取了数据，每 15 分钟记录一次。我的目标是单独识别每天的异常情况。鉴于数据集相对较小（每天 96 个点）
哪种机器学习方法最适合获得最佳结果？]]></description>
      <guid>https://stackoverflow.com/questions/78337873/outliers-detection-in-a-small-time-series-dataset</guid>
      <pubDate>Wed, 17 Apr 2024 01:00:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么在测试阶段没有出现 F1 分数最高的班级？</title>
      <link>https://stackoverflow.com/questions/78337814/why-do-classes-with-the-highest-f1-scores-not-appear-during-testing-phase</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78337814/why-do-classes-with-the-highest-f1-scores-not-appear-during-testing-phase</guid>
      <pubDate>Wed, 17 Apr 2024 00:28:10 GMT</pubDate>
    </item>
    <item>
      <title>请求 DFS、PMI 和成对约束实施方面的帮助 (Python) [已关闭]</title>
      <link>https://stackoverflow.com/questions/78337813/request-for-assistance-with-dfs-pmi-and-pairwise-constraints-implementation-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78337813/request-for-assistance-with-dfs-pmi-and-pairwise-constraints-implementation-p</guid>
      <pubDate>Wed, 17 Apr 2024 00:27:43 GMT</pubDate>
    </item>
    <item>
      <title>边界框检测模型：单图像输入的预测不准确</title>
      <link>https://stackoverflow.com/questions/78337404/bounding-box-detection-model-inaccurate-predictions-with-single-image-inputs</link>
      <description><![CDATA[在使用单个图像输入进行预测时，我的边界框检测模型遇到了令人费解的问题。场景如下：我使用迁移学习以 VGG16 作为基础架构训练了一个模型。在训练过程中，我使用了一批图像，当提供一批图像进行推理时，模型表现良好。但是，当我尝试使用单个图像预测边界框坐标时，模型始终会产生不准确的结果，返回诸如 [0., 0., 1., 0.] 之类的预测。
学习数据实际上非常简单：带有随机创建的白框的黑色图像。该模型的想法是预测这些框的坐标。
为了解决此问题，我尝试重新调整输入数据、调整模型架构并检查推理代码，但问题仍然存在。这是令人困惑的，因为当我传递一批 64 个黑色图像（但仅修改第一个图像以创建白色矩形）时，模型预测准确，但对于单个图像则失败。
我怀疑模型在训练和推理过程中处理输入数据的方式可能存在差异，或者单个图像和批次之间可能存在不同的预处理步骤。我还考虑了模型层如何根据批量大小处理输入数据的潜在差异。
尽管解决方法效果很好（传递 (64, 100, 100, 3) 输入形状作为输入），但我想真正理解这一点，因为我想学习的不仅仅是复制粘贴。
项目代码可以在此 Kaggle 笔记本中找到，这是高级计算机视觉 Udemy 课程的第一部分。
我正在向社区寻求有关此问题的潜在原因的见解以及解决该问题的建议。任何帮助或指导将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78337404/bounding-box-detection-model-inaccurate-predictions-with-single-image-inputs</guid>
      <pubDate>Tue, 16 Apr 2024 21:31:11 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ppo 加快 python 国际象棋机器人的训练时间？</title>
      <link>https://stackoverflow.com/questions/78337397/how-can-i-speed-up-my-training-time-for-a-python-chess-bot-using-ppo</link>
      <description><![CDATA[我正在尝试构建一个国际象棋机器人，它可以使用近端策略优化进行学习。我目前正在使用 python-chess 库 (https://python-chess. readthedocs.io/en/latest/index.html#）作为我的代理与自己进行游戏并学习的环境。我面临的问题是训练游戏速度非常慢。每场比赛的移动限制为 200 次，我的机器人可以在大约 1 秒内与自己进行一场比赛。这 1 秒还包括训练的 PPO 部分，使用 GPU 平均需要 0.01 秒。
我正在使用 PyTorch，因此我已经将所有张量移至 GPU。除此之外我还没有找到任何其他方法来加快执行时间。
我希望将玩游戏的执​​行时间减少到每场游戏 0.5 秒或更少，但我一直无法找到实现此目标的方法。
如果有人知道可能的解决方案，我将非常感谢您的反馈和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78337397/how-can-i-speed-up-my-training-time-for-a-python-chess-bot-using-ppo</guid>
      <pubDate>Tue, 16 Apr 2024 21:27:24 GMT</pubDate>
    </item>
    <item>
      <title>如何用 0 个初始训练数据构建实时推荐系统？</title>
      <link>https://stackoverflow.com/questions/78336322/how-do-i-build-a-real-time-recommendation-system-with-0-initial-training-data</link>
      <description><![CDATA[我正在开发一个实时流媒体网络应用程序。我们目前有 0 个用户和流数据。
如果我只是随机生成自己的数据，则存在创建不良数据的风险，那么我应该如何训练 ML 模型呢？我应该使用服务（AWZ、Azure 等）吗？]]></description>
      <guid>https://stackoverflow.com/questions/78336322/how-do-i-build-a-real-time-recommendation-system-with-0-initial-training-data</guid>
      <pubDate>Tue, 16 Apr 2024 17:16:45 GMT</pubDate>
    </item>
    <item>
      <title>当环境处于截断的情况下时，我应该如何处理值函数？</title>
      <link>https://stackoverflow.com/questions/78334914/how-should-i-handle-the-value-function-when-the-environment-is-rested-in-a-trunc</link>
      <description><![CDATA[我阅读了终止/截断的文档并理解了之间的区别环境的终止情况和截断情况，但我无法理解为什么该值会像下面这样更新。
如果终止：# case 1
    下一个 q 值 = 奖励
否则：#情况2
    下一个 q 值 = 奖励 + 折扣因子 * Q 的最大动作（下一个状态，动作）

# 这样可以更有效地编写
下一个q值=奖励+（未终止）*折扣因子*Q的最大动作（下一个状态，动作）

据我了解，截断信号后环境将被重置，下一步是环境的初始步骤，从 env.reset() 调用。在这种情况下，状态和下一个状态之间没有关系，我不知道为什么使用下一个状态的 Q 值来更新该值。
假设环境的时间限制是1000。那么，无论第1000步的状态是什么，下一步都将是环境的初始步骤。即使在相同的状态和相同的动作下，如果时间步不是1000，下一个状态也会不同，并且会使用不同的Q值。
为什么使用下一个状态的 Q 项来更新截断情况下的值？在截断的情况下也忽略 Q 项不是更好吗？
另外，我想知道如何处理连续任务中下一个状态的 Q 项。在每个截断的情况下，错误的状态（从 env.reset() 调用）是否会被视为下一个状态？
我试图找到类似的问题，但没有找到。可能有一些原因，但我可以找出原因。]]></description>
      <guid>https://stackoverflow.com/questions/78334914/how-should-i-handle-the-value-function-when-the-environment-is-rested-in-a-trunc</guid>
      <pubDate>Tue, 16 Apr 2024 13:31:42 GMT</pubDate>
    </item>
    <item>
      <title>使用张量流创建的 u-net 时，max_pooling2d 之前的尺寸存在问题</title>
      <link>https://stackoverflow.com/questions/78310228/problem-with-dimensions-before-max-pooling2d-while-using-a-u-net-created-with-te</link>
      <description><![CDATA[我有一个用tensorflow编码的u-net架构：
def down_block(x, 过滤器, kernel_size=(3, 3), padding=&#39;same&#39;, strides=1):
    x = tf.keras.layers.Conv2D（过滤器，kernel_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.Conv2D（过滤器，kernel_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    返回x

def up_block(x, 跳过, 过滤器, kernel_size=(3, 3), padding=&#39;相同&#39;, strides=1):
    x = tf.keras.layers.UpSampling2D((2, 2))(x)
    x = tf.keras.layers.Concatenate(axis=3)([x, 跳过])
    x = tf.keras.layers.Conv2D（过滤器，kernel_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.Conv2D（过滤器，kernel_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    返回x

def Unet(input_size=(256, 256, 3), 类=2, dropout_rate=0.5):
    输入 = tf.keras.Input(input_size)
    过滤器 = [64, 128, 256, 512, 1024]

    ＃ 向下
    x = 输入
    跳过 = []
    对于过滤器 [:-1] 中的 f：
        x = down_block(x, f)
        跳过.append(x)
        x = tf.keras.layers.MaxPooling2D((2, 2))(x)

    x = down_block(x, 过滤器[-1])

    ＃ 向上
    对于反转中的 i（范围（len（跳过）））：
        x = up_block(x, 跳过[i], 过滤器[i])

    #x = tf.keras.layers.Dropout(dropout_rate)(x)
    x = tf.keras.layers.Conv2D(类, (1, 1), 填充=“相同”, 激活=“sigmoid”)(x)

    模型= tf.keras.models.Model（输入，x，名称=“U-Net”）
    返回模型

当我尝试用我的数据训练这个架构时，我遇到了这个错误，我不明白为什么：
W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES 在 mkl_maxpooling_op.cc:214 处失败：中止：计算收到异常：状态：2，消息：无法为池转发创建描述符传播原语，在文件tensorflow/core/kernels/mkl/mkl_maxpooling_op.cc:211中
tensorflow.python.framework.errors_impl.AbortedError：调用层“max_pooling2d”（类型 MaxPooling2D）时遇到异常。
[...]
{{function_node __wrapped__MaxPool_device_/job:localhost/replica:0/task:0/device:CPU:0}} 计算收到异常：状态：2，消息：无法在文件张量流中为池化前向传播原语创建描述符/core/kernels/mkl/mkl_maxpooling_op.cc:211 [Op:MaxPool] 名称：
调用层“max_pooling2d”接收的参数（类型 MaxPooling2D）：
  输入=tf.Tensor（形状=（1024,1024,1,64），dtype=float32）

我尝试了很多不同尺寸的图片，将“channels_first”放在或“channels_last”，但在调用 model.fit() 时总会出现问题。
这是我用来测试模型的代码：
`
如果 __name__ == &#39;__main__&#39;:
    打印（tf.__版本__）
    模型 = Unet(input_size=(1024, 1024, 1), 类=1, dropout_rate=0.2)
    模型.summary()

    大小 = (1024, 1024, 1)
    img = np.random.randn(大小[0],大小[1],大小[2])*100
    标签 = np.random.randn(大小[0],大小[1],大小[2])
    对于范围内的 i(0,size[0]):
        对于范围（0，大小[1]）中的j：
            对于范围（0，大小[2]）中的k：
                如果标签[i][j][k]&gt;0：标签[i][j][k]=1
                否则：标签[i][j][k]=0
    img_list = [img, img, img]
    标签列表 = [标签，标签，标签]

    数据 = 列表(zip(img_list,label_list))
    input_dataset = tf.data.Dataset.from_tensor_slices([data_point[0] for data_point in data])
    target_dataset = tf.data.Dataset.from_tensor_slices([data_point[1] for data_point in data])
    数据集 = tf.data.Dataset.zip((input_dataset, target_dataset))

    对于img，数据集中的标签：
        打印（img.形状，标签.形状）

    model.compile(optimizer=tf.keras.optimizers.RMSprop(),
                  损失=tf.keras.losses.BinaryCrossentropy(),
                  指标=[&#39;binary_accuracy&#39;],
                  run_eagerly=真）

    new_var = model.fit(数据集,epochs=10)

我已经尝试了很多事情：更小或更大的图片尺寸，将其作为 fit() 函数的参数的不同方法，使用 tf.transpose 来成功 maxpooling2D...
我只是希望使用该模型在灰色模式下使用方形图片 (512x512x1) 或 (1024x1024x1) 成功完成训练阶段。]]></description>
      <guid>https://stackoverflow.com/questions/78310228/problem-with-dimensions-before-max-pooling2d-while-using-a-u-net-created-with-te</guid>
      <pubDate>Thu, 11 Apr 2024 12:08:33 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：使用 `bitsandbytes` 8 位量化需要加速：`pip install Accelerate` 和最新版本的 Bitsandbytes：`pip install</title>
      <link>https://stackoverflow.com/questions/78254344/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78254344/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</guid>
      <pubDate>Mon, 01 Apr 2024 08:15:53 GMT</pubDate>
    </item>
    <item>
      <title>在 Mac 上安装 pgvector 扩展</title>
      <link>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</link>
      <description><![CDATA[我正在尝试在我的 Mac 上安装 postgres 矢量扩展，但我得到了
错误：扩展名“向量”没有版本“0.4.0”的安装脚本或更新路径。

这就是我所做的：

按照 github 上所示的安装指南进行操作：


但是当我运行CREATE EXTENSION vector;时出现错误：
错误：无法打开扩展控制文件“/Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/vector.control”：没有这样的文件或目录


我使用以下方法将 pgvector 的内容复制到 posgresql/extension 中：
sudo cp -r ~/Downloads/pgvector/* /Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/


尝试运行CREATE EXTENSION向量；现在错误是：
错误：扩展名“向量”没有版本“0.4.0”的安装脚本或更新路径。

这里有人遇到过这个问题吗？
顺便说一句，我正在使用PostgreSQL 13.10]]></description>
      <guid>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</guid>
      <pubDate>Tue, 07 Mar 2023 15:32:42 GMT</pubDate>
    </item>
    <item>
      <title>Python 上每个系数具有特定约束的多元线性回归</title>
      <link>https://stackoverflow.com/questions/50410037/multiple-linear-regression-with-specific-constraint-on-each-coefficients-on-pyth</link>
      <description><![CDATA[我目前正在数据集上运行多元线性回归。起初，我没有意识到我需要限制自己的体重；事实上，我需要有具体的积极和积极的态度。负权重。
更准确地说，我正在做一个评分系统，这就是为什么我的一些变量应该对笔记产生积极或消极的影响。然而，当运行我的模型时，结果并不符合我的预期，我的一些“正”变量得到负系数，反之亦然。
举个例子，假设我的模型是：
&lt;预置&gt;&lt;代码&gt;y = W0*x0 + W1*x1 + W2*x2

如果 x2 是一个“正”变量，我想对 W2 施加一个约束使其为正！
我已经对这个问题进行了很多研究，但我没有发现任何关于特定权重/系数的约束，我发现的只是将所有系数设置为正或将它们加起来为一。
我正在使用 ScikitLearn 包开发 Python。这就是我获得最佳模型的方法：
def ridge(Xtrain, Xtest, Ytrain, Ytest, 位置):
    param_grid={&#39;alpha&#39;:[0.01, 0.1, 1, 10, 50, 100, 1000]}
    gs = grid_search.GridSearchCV(Ridge(), param_grid=param_grid, n_jobs=-1, cv=3)
    gs.fit(Xtrain, Ytrain)
    hatytrain = gs.predict(Xtrain)
    hatytest = gs.predict(Xtest)

知道如何对特定变量的系数分配约束吗？定义每个约束可能会很麻烦，但我不知道该怎么做。]]></description>
      <guid>https://stackoverflow.com/questions/50410037/multiple-linear-regression-with-specific-constraint-on-each-coefficients-on-pyth</guid>
      <pubDate>Fri, 18 May 2018 11:10:22 GMT</pubDate>
    </item>
    </channel>
</rss>