<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Jan 2024 18:17:57 GMT</lastBuildDate>
    <item>
      <title>使用模式识别、机器学习和清算数据预测资产价格走势[关闭]</title>
      <link>https://stackoverflow.com/questions/77801769/predicting-assests-price-moves-using-pattern-recognition-machine-learing-and-li</link>
      <description><![CDATA[我在加密货币市场进行交易，并使用电报机器人 https://t.me/BinanceLiquidations 进行提醒价格在哪里。机器人的每条消息都包含价格、时间、清算价值和红色（多头）或绿色（空头）。现在问题就在这里。几个月来我一直在观察数据，幸运的是发现了两种模式。此后，它激发了我的兴趣，即使用机器学习可以利用数据寻找模式来开发优势。]]></description>
      <guid>https://stackoverflow.com/questions/77801769/predicting-assests-price-moves-using-pattern-recognition-machine-learing-and-li</guid>
      <pubDate>Thu, 11 Jan 2024 16:49:00 GMT</pubDate>
    </item>
    <item>
      <title>训练随机森林花费的时间太长</title>
      <link>https://stackoverflow.com/questions/77801017/training-random-forest-taking-too-long</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77801017/training-random-forest-taking-too-long</guid>
      <pubDate>Thu, 11 Jan 2024 15:02:53 GMT</pubDate>
    </item>
    <item>
      <title>基于地理空间点数据约束的聚类[关闭]</title>
      <link>https://stackoverflow.com/questions/77800495/clustering-based-on-constraints-on-geospatial-point-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77800495/clustering-based-on-constraints-on-geospatial-point-data</guid>
      <pubDate>Thu, 11 Jan 2024 13:42:13 GMT</pubDate>
    </item>
    <item>
      <title>创建一个根据所提供的 5 个 PDF 文档内容进行训练的聊天机器人。以下是需要完成的任务：[关闭]</title>
      <link>https://stackoverflow.com/questions/77799235/create-a-chatbot-that-is-trained-based-on-content-from-the-5-pdf-documents-provi</link>
      <description><![CDATA[a.提取文本和数据，将数据转换为数值向量，并将向量和文档详细信息存储在数据库中。
b.聊天机器人需要接受用户查询/输入并根据这些 PDF 文档的内容返回响应。用于响应用户查询/问题的创造力非常重要。
c.当 PDF 中没有找到相关结果时，应依赖法学硕士的内容来构建响应。如果仍然没有合适的答案，它应该提供用户友好的响应。
d. UI 界面应该具有聊天机器人的外观和感觉。
e.创建此功能的视频并向我们发送 Google Drive 或
可以下载的视频文件。
我期待满足上述需求的代码。]]></description>
      <guid>https://stackoverflow.com/questions/77799235/create-a-chatbot-that-is-trained-based-on-content-from-the-5-pdf-documents-provi</guid>
      <pubDate>Thu, 11 Jan 2024 10:15:51 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习全局聚合后准确率下降</title>
      <link>https://stackoverflow.com/questions/77798059/the-accuacy-decreased-after-global-aggregation-in-federated-learning</link>
      <description><![CDATA[我正在开展一个联合学习项目。我编写了一段代码来刺激联邦学习的过程。然而，每次迭代进行全局聚合后，全局模型的测试精度会下降很多，并且在接下来的迭代中保持不变。我使用的聚合算法是FedAvg。我尝试将我的代码分成不同的单元来找出问题所在。
对于本地训练，所选客户训练 3 轮。在这个实验中，将选择所有五个客户端进行训练和聚合，我用于本地的模型是从 torchvision 分叉的 vgg16，数据集是 MNIST，并以 i.i.d 方式分割每个客户端： 
for id, net_id in enumerate(selected):
    logging.info(“训练所选设备 %s。” % (str(net_id)))
    结果 = Userlists[net_id].train(hparams[&#39;n_local_epochs&#39;])
    logging.info(&#39;&gt;&gt; 局部模型 %d: 局部精度: %f in round %d\n&#39; % (id, result[&#39;local_test_acc&#39;], step+1))

在本地模型聚合之前，我使用全局服务器的测试数据来测试本地模型的准确性，
tesc，conf = Misc.compute_accuracy(Userlists[2].model，test_dl_global，get_confusion_matrix=True，device=hparams[&#39;device&#39;])
打印（测试）
&gt; 0.2478966346153846
tesc，conf = Misc.compute_accuracy（Userlists [3] .model，test_dl_global，get_confusion_matrix = True，device = hparams [&#39;device&#39;]）
打印（测试）
&gt; 0.14413060897435898
tesc,conf=misc.compute_accuracy(Userlists[4].model,test_dl_global,get_confusion_matrix=True,device=hparams[&#39;device&#39;])
打印（测试）
&gt; 0.17387820512820512

我使用下面的聚合代码来聚合所选客户端的权重：
&lt;前&gt;&lt;代码&gt;total_sum = 0.0
对于选定的 client_idx：
    Total_sum += 用户列表[client_idx].data_len
    
    
global_para = global_model.state_dict()
client_weights = [torch.tensor( Userlists[client_idx].data_len/total_sum, device=hparams[&#39;device&#39;]) for client_idx in selected]

使用 torch.no_grad()：
    对于顺序，枚举中的 idx（选定）：
        logging.info(f“对于客户端 {idx}”)
        net_para = Userlists[idx].model.state_dict()
        
        如果订单 == 0：
            对于 net_para.keys() 中的键：
                global_para[key] = net_para[key] * client_weights[订单]
        别的：
            对于 net_para.keys() 中的键：
                global_para[key] += net_para[key] * client_weights[订单]


global_model.load_state_dict(global_para)
tesc,conf=misc.compute_accuracy(global_model,train_dl_global,get_confusion_matrix=True,device=hparams[&#39;device&#39;])

全局测试精度下降并保持不变
&lt;前&gt;&lt;代码&gt;&gt; 0.11236666666666667

尽管我尝试增加本地训练的纪元，局部准确率提高到 40%，但全局准确率仍然落入与之前相同的值。我的聚合代码中是否有错误的地方？
测试精度应与本地精度保持在同一水平。]]></description>
      <guid>https://stackoverflow.com/questions/77798059/the-accuacy-decreased-after-global-aggregation-in-federated-learning</guid>
      <pubDate>Thu, 11 Jan 2024 06:30:41 GMT</pubDate>
    </item>
    <item>
      <title>数据帧和多变量标签的嵌套目录上的多视图谱聚类</title>
      <link>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</guid>
      <pubDate>Thu, 11 Jan 2024 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到<class 'NoneType'> [关闭]</title>
      <link>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</link>
      <description><![CDATA[我正在尝试对我的数据运行深度学习代码；但是，由于输入数据中缺少数据集，我遇到了问题。如何解决这个问题？我正在努力解决下面给出的这个错误，下面还提供了输入链接。
python3 Validation2co.py
BP_benchmarkSet_2.csv
BP seqmodel 启动
序列模块（
  (seq_CNN): 顺序(
    (0): Conv1d(100, 64, kernel_size=(16,), stride=(1,), padding=(8,))
    (1): ReLU(原地=True)
    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv1d(64, 32, kernel_size=(16,), stride=(1,), padding=(8,))
    (4): ReLU(inplace=True)
    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv1d(32, 16, kernel_size=(16,), stride=(1,), padding=(8,))
    (7): ReLU(原地=True)
    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  ）
  （seq_FClayer）：线性（in_features = 3008，out_features = 1024，偏差= True）
  （seq_outlayer）：线性（in_features = 1024，out_features = 491，偏差= True）
）
batch_size_32，learning_rate_0.0001，epoch_time_30
selected_208964_ Protein_score.csv
selected_208964_ Protein_score.csv
警告：iprID Q9HTQ2 数据丢失。跳过...
警告：iprID Q9I559 数据丢失。跳过...
警告：iprID Q9HT21 数据丢失。跳过...
警告：iprID Q9I0Q1 数据丢失。跳过...
警告：iprID Q9HVI7 数据丢失。跳过...
警告：iprID Q9I422 数据丢失。跳过...
警告：iprID Q9I2V9 数据丢失。跳过...
警告：iprID Q9HWB6 数据丢失。跳过...
警告：iprID Q9HVT7 数据丢失。跳过...
警告：iprID Q9I3I5 数据丢失。跳过...
警告：iprID Q9I4C1 数据丢失。跳过...
警告：iprID Q9I5K0 数据丢失。跳过...
警告：iprID P26995 数据丢失。跳过...
警告：iprID Q9I1Y7 数据丢失。跳过...
警告：iprID Q9I316 数据丢失。跳过...
警告：iprID Q9I299 数据丢失。跳过...
警告：iprID Q9I2Q4 数据丢失。跳过...
警告：iprID Q9HT20 数据丢失。跳过...
警告：iprID Q9HV34 数据丢失。跳过...
警告：iprID Q9HX99 数据丢失。跳过...
警告：iprID Q9HZK1 数据丢失。跳过...
警告：iprID Q9HXG5 数据丢失。跳过...
警告：iprID Q9I3F5 数据丢失。跳过...
警告：iprID Q9HV44 数据丢失。跳过...
警告：iprID Q9HY92 数据丢失。跳过...
警告：iprID Q9HVX9 数据丢失。跳过...
警告：iprID Q9I6Z3 数据丢失。跳过...
警告：iprID Q9HU16 数据丢失。跳过...
警告：iprID Q9HYL8 数据丢失。跳过...
警告：iprID Q9HI37 数据丢失。跳过...
警告：iprID Q9I1Y4 数据丢失。跳过...
警告：iprID Q9HW04 数据丢失。跳过...
回溯（最近一次调用最后一次）：
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 990 行，在  中。
    验证（条款[0], 5）
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 972 行，验证中
    每个_fold_scores = Main(train_set, test_set, func=func)
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 831 行，位于 Main 中
    seq_train_out, seq_test_out, seq_t = Seq_train(0.0001, 16, train_benchmark, test_benchmark, 30, func) # 15
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 408 行，Seq_train
    对于batch_idx，枚举（train_data_loader）中的（seqMatrix，domainStence，ppiVect，GO_annotiations）：
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 681 行，位于 __next__
    数据 = self._next_data()
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 721 行，位于 _next_data
    data = self._dataset_fetcher.fetch(index) # 可能会引发 StopIteration
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py​​”，第 52 行，在 fetch 中
    返回 self.collat​​e_fn(数据)
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/collat​​e.py”，第 183 行，default_collat​​e
    引发 TypeError(default_collat​​e_err_msg_format.format(elem_type))
**类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到**
]]></description>
      <guid>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</guid>
      <pubDate>Thu, 11 Jan 2024 04:55:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用离群数据来训练随机森林回归以用于填充其他缺失数据</title>
      <link>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</link>
      <description><![CDATA[dataAgeNull = data[data[“年龄”].isnull()]
dataAgeNotNull = data[data[“年龄”].notnull()]
remove_outlier = dataAgeNotNull[(np.abs(dataAgeNotNull[“票价”]-dataAgeNotNull[“票价”].mean())&gt;(4*dataAgeNotNull[“票价”].std()))|
                      (np.abs(dataAgeNotNull[“Family_Size”]-dataAgeNotNull[“Family_Size”].mean())&gt;(4*dataAgeNotNull[“Family_Size”].std()))
                     ]
rfModel_age = RandomForestRegressor(n_estimators=2000,random_state=42)
ageColumns = [&#39;出发&#39;, &#39;票价&#39;, &#39;舱位等级&#39;, &#39;性别&#39;, &#39;Family_Size&#39;, &#39;标题1&#39;, &#39;标题2&#39;,&#39;客舱&#39;,&#39;机票信息&#39;]
rfModel_age.fit(remove_outlier[ageColumns], remove_outlier[“年龄”])

ageNullValues = rfModel_age.predict(X= dataAgeNull[ageColumns])
dataAgeNull.loc[:,&quot;年龄&quot;] = AgeNullValues
数据 = dataAgeNull.append(dataAgeNotNull)
data.reset_index(inplace=True, drop=True)

为什么我们使用“票价”的离群数据和“family_size”训练 RandomForestRegressor 来填充“年龄”的缺失数据？
我试图理解这段代码，但仍然无法弄清楚
4]]></description>
      <guid>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</guid>
      <pubDate>Thu, 11 Jan 2024 03:58:16 GMT</pubDate>
    </item>
    <item>
      <title>回归任务中日志转换后的指标解释问题</title>
      <link>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</link>
      <description><![CDATA[我目前正在研究房价预测任务，由于目标变量（价格）的非正态分布，我对它进行了对数转换。我使用 RMSE、MAE 和 MAPE 等指标，并且对于模型训练，我使用了 cross_val_score。
获得预测后，我采用 MAE 和 MAPE 指标的指数将其恢复到原始规模。然而，我遇到了意想不到的小值；两个指标都等于 1。我怀疑这些值不正确。
kf = KFold(n_splits=5, random_state=42, shuffle=True)

def rmse_cv（模型）：
    mse_scorer = make_scorer(mean_squared_error)
    rmse = np.sqrt(cross_val_score(模型, 训练, y_train, 评分=mse_scorer, cv=kf))
    返回均方根误差

def mae_cv（模型）：
    mae_scorer = make_scorer(mean_absolute_error)
    mae = cross_val_score(模型, 训练, y_train, 评分=mae_scorer, cv=kf)
    返回梅

def mape_cv（模型）：
    mape_scorer = make_scorer(mean_absolute_percentage_error)
    mape = cross_val_score(模型, 训练, y_train, 评分=mape_scorer, cv=kf)
    返回马普

lightgbm = LGBMRegressor(num_leaves=6, max_depth=7, random_state=42, n_estimators=500, Objective=&#39;回归&#39;)

rmse = rmse_cv(lightgbm)
mae = mae_cv(lightgbm)
映射 = 映射_cv(lightgbm)
print(&#39;Lightgbm rmse %.4f&#39; % (rmse.mean()))
print(&#39;Lightgbm mae %.4f&#39; % (mae.mean()))
print(&#39;Lightgbm mape %.4f&#39; % (mape.mean()))

Lightgbm rmse 0.1331
Lightgbm mae 0.0874
Lightgbm 映射 0.0073

我希望获得合理且可解释的值，以反映模型在原始范围内的性能。然而，这两个指标都得出了意想不到的小值 1，这似乎不准确。我期望在原始价格范围内能够更有意义地表示模型误差。]]></description>
      <guid>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</guid>
      <pubDate>Thu, 11 Jan 2024 03:13:07 GMT</pubDate>
    </item>
    <item>
      <title>考虑到 3D CNN 的挑战和预训练 VideoMAE 模型的内存问题，对震颤强度进行分类的有效方法是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77794520/what-are-efficient-methods-for-classifying-tremor-intensity-given-challenges-wi</link>
      <description><![CDATA[我有一个包含 80 个视频的训练数据集（没有增强）。它们是以 30fps 和 240*480 尺寸录制的 15 秒视频。训练分类模型有哪些选择？问题陈述是我有颤抖者的视频。我想按 1 - 3 级对震颤强度进行分类。请建议一些处理此问题的方法
我尝试过使用 3D CNN，但它需要过多的计算能力。我还尝试通过微调 Huggingface 中的预训练 VideoMAE 模型来训练模型，但它只接受 16 帧而不是 450 帧（15s * 30fps）。我尝试更改拱门，但它给了我内存错误。]]></description>
      <guid>https://stackoverflow.com/questions/77794520/what-are-efficient-methods-for-classifying-tremor-intensity-given-challenges-wi</guid>
      <pubDate>Wed, 10 Jan 2024 15:31:50 GMT</pubDate>
    </item>
    <item>
      <title>Handritten 数字识别算法前向传播中的矩阵乘法效率低下</title>
      <link>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</link>
      <description><![CDATA[我正在用 python 编写手写数字识别神经网络算法，而不使用预先编写的 ML 库。我目前正在尝试实现一个 DenseLayer 类，并在其中实现一个前向传播函数。我当前的功能如下所示。
类 DenseLayer：
  ...
  
  ...
  def for_prop(自身, input_data):
    self.input = input_data

    transpose_weights = self.weights.T
    # matMulComponent = np.matmul(input_data, transpose_weights)
    print(f&quot;转置形状：{transpose_weights.shape} 和输入形状 {input_data.shape}&quot;)
    matMulComponent = input_data.T @ transpose_weights
    打印（len（matMulComponent））

    z = matMulComponent + self.biases.T
    f_wb = self.act_fun(z)
    
    

    self.output = f_wb.reshape(-1, 1)
    print(f&quot;形状结果：{self.output.shape}&quot;)
    返回自身输出

问题是我正在进行大量的重塑和转置以获得结果。这似乎效率不高。
所以我的问题是：

这个实施起来好吗（因此会导致效率低下）
有没有更好的方法来实现这个前向传播函数

这就是我的输入数据数组的样子（我刚刚打印它并采取了 ss）。我供参考的输入数据是一个扁平的 28*28 数组，每个单元格代表一种颜色。我首先对数据进行标准化（z 分数标准化）
输入数据图像
如果有帮助的话，我还截取了第一层的权重格式的屏幕截图。 （请记住，它在 for_prop 函数中使用之前已被转置）。
第一个隐藏层的权重矩阵图片
前向传播似乎确实有效，但这很好：前向传播进度 ]]></description>
      <guid>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</guid>
      <pubDate>Wed, 10 Jan 2024 04:20:06 GMT</pubDate>
    </item>
    <item>
      <title>我在视觉变压器中有矩形图像数据集。我设置 image_size= (128, 256) 但补丁大小可能是多少？</title>
      <link>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</guid>
      <pubDate>Tue, 09 Jan 2024 16:55:52 GMT</pubDate>
    </item>
    <item>
      <title>scikit 的 RFECV 类如何计算 cv_results_？</title>
      <link>https://stackoverflow.com/questions/77788410/how-does-scikits-rfecv-class-compute-cv-results</link>
      <description><![CDATA[我对递归特征消除交叉验证的理解： (sklearn.feature_selection.RFECV) 您提供一种算法，该算法在整个数据集上进行训练并创建特征重要性排名使用属性 coef_ 或 feature_importances_。现在包含了所有功能，该算法通过交叉验证进行评估。然后，删除排名底部的特征，并在数据集上重新训练模型并创建新的排名，再次通过交叉验证进行评估。这一过程将持续下去，直到只剩下一个特征（或由 min_features_to_select 指定），并且最终选择的特征数量取决于产生最高 CV 分数的特征。 （来源)
问题：每个特征数量的 CV 分数存储在 rfecv.cv_results_[“mean_test_score”] 中，我在尝试复制时遇到了麻烦这些分数无需使用 scikit 的内置方法。
这是我试图获得 n-1 个特征的分数，其中 n 是特征总数。
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.model_selection 导入 StratifiedKFold
从 sklearn.model_selection 导入 cross_validate
从 sklearn.feature_selection 导入 RFECV

alg = DecisionTreeClassifier(random_state = 0)
cv_split = 分层KFold(5)
# train 是 pandas 数据框，x_var 和 y_var 都是包含变量字符串的列表
X = 火车[x_var]
y = np.ravel(train[y_var])

alg.fit(X, y)
最低排名特征 = np.argmin(alg.feature_importances_)
x_var.pop(最低排名特征)

one_removed_feature = 火车[x_var]
alg.fit(one_removed_feature, y)
cv_score = cross_validate(alg, one_removed_feature, y, cv=cv_split, 评分=“准确度”)
np.mean(cv_score[“test_score”])

这是提供不同分数的内置方法：
&lt;前&gt;&lt;代码&gt;rfecv = RFECV(
    估计量=alg,
    步骤=1，
    CV=CV_分裂，
    评分=“准确度”，
）

rfecv.fit(X, y)
rfecv.cv_results_[“mean_test_score”][-2]

如何获得内置方法中计算出的准确分数？
我还想提一下，我确实首先尝试了所有 n 个功能，并且我的方法与
rfecv.cv_results_[“mean_test_score”][-1]。]]></description>
      <guid>https://stackoverflow.com/questions/77788410/how-does-scikits-rfecv-class-compute-cv-results</guid>
      <pubDate>Tue, 09 Jan 2024 16:47:46 GMT</pubDate>
    </item>
    <item>
      <title>在 WSL conda 环境中安装 lightgbm GPU</title>
      <link>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</link>
      <description><![CDATA[--------------------原来的问题------------------------- --------
如何安装LightGBM？
我检查了多个来源，但仍然无法安装。
我尝试了 pip 和 conda 但都返回错误：
[LightGBM] [警告] 目前不支持在 CUDA 中使用稀疏特征。
[LightGBM] [致命] 此版本中未启用 CUDA Tree Learner。
请使用 CMake 选项 -DUSE_CUDA=1 重新编译

我尝试过的内容如下：
git clone --recursive https://github.com/microsoft/LightGBM
cd LightGBM/
mkdir -p 构建
光盘构建
cmake -DUSE_GPU=1 ..
使-j$(nproc)
cd ../python-package
点安装。

-------------------- 下面是我的解决方案（cuda）--------------------- ------------
谢谢各位的回复。我尝试了一些方法，最终效果如下：
首先，确保已安装 cmake（在 wsl 下）：
sudo apt-get update
sudo apt-get 安装 cmake
须藤 apt-get 安装 g++

那么，
git clone --recursive https://github.com/microsoft/LightGBM
cd光GBM
mkdir 构建
光盘构建
cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..
使-j4

目前，安装尚未链接到任何 conda env。为此，在 vscode 终端（或仍然是 wsl）下，conda 激活一个 env，然后创建一个 jupyter 笔记本进行测试：
确保lib_lightgbm.so位于LightGBM/python-package下，如果没有，则复制到该文件夹​​中。
然后在jupyter笔记本中：
导入系统
将 numpy 导入为 np
sys.path.append(&#39;/mnt/d/lgm-test2/LightGBM/python-package&#39;)
将 lightgbm 导入为 lgb

最后一点是，您可以参考 Jame 的回复，设备需要设置为“cuda”而不是“gpu”。]]></description>
      <guid>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</guid>
      <pubDate>Thu, 28 Dec 2023 17:34:48 GMT</pubDate>
    </item>
    <item>
      <title>媒体管道是否与深脸一起使用进行人脸识别以获得更好的准确性</title>
      <link>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</link>
      <description><![CDATA[我使用深脸进行识别，但准确性不好，所以我尝试实现媒体管道，在​​其中提取地标，因此我将其交给深脸以获得更好的准确性。有什么办法可以做到这一点吗？
我从媒体管道中提取特征向量，但如何将其传递到深层脸部？有什么可行的方法吗？
是否使用媒体管道地标进行深度面部识别以提高准确性？]]></description>
      <guid>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</guid>
      <pubDate>Thu, 28 Dec 2023 09:38:05 GMT</pubDate>
    </item>
    </channel>
</rss>