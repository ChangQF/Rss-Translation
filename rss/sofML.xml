<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 08 Aug 2024 09:16:29 GMT</lastBuildDate>
    <item>
      <title>使用 Python 改进 Telegram 机器人中的关键字识别和提取</title>
      <link>https://stackoverflow.com/questions/78847420/improving-keyword-recognition-and-extraction-in-a-telegram-bot-using-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78847420/improving-keyword-recognition-and-extraction-in-a-telegram-bot-using-python</guid>
      <pubDate>Thu, 08 Aug 2024 08:52:23 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量</title>
      <link>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</link>
      <description><![CDATA[我无法加载我的模型，它一直显示错误
ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量。收到的输入：[&lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2896&gt;, &lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2897&gt;]
这是我的代码
image_generator = ImageDataGenerator(
rescale=1./255,
rotation_range=20,
zoom_range=0.2,
width_shift_range=0.2,
height_shift_range=0.2,
Horizo​​ntal_flip=True,
validation_split=0.2
)

train_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;training&#39;
)

validation_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;validation&#39;
)

# 加载数据集中子文件夹中的 (num_classes) 类
num_classes = len(train_dataset.class_indices)

from tensorflow.keras.applications.mobilenet import MobileNet

# 加载 MobileNet 模型
pre_trained_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),
include_top=False,
weights=&#39;imagenet&#39;)

pre_trained_model.summary()

# 打印数据集信息以供调试
print(f&quot;训练数据集形状：{train_dataset.image_shape}&quot;)
print(f&quot;验证数据集形状：{validation_dataset.image_shape}&quot;)

pre_trained_model.trainable = False

# 为预训练模型添加自定义层
model = tf.keras.Sequential([
pre_trained_model,
tf.keras.layers.GlobalAveragePooling2D(),
tf.keras.layers.Dense(1024,activation=&#39;relu&#39;),
tf.keras.layers.Dropout(0.5),
tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;) 
])

# 编译模型
#from tensorflow.keras.optimizers import RMSprop
model.compile(optimizer=Adam(learning_rate=0.0001),
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

# batch=40
# history = model.fit(train_dataset,
# validation_data=validation_dataset,
# epochs=20,
# steps_per_epoch = train_dataset.samples//batch,
# validation_steps = validation_dataset.samples//batch,
# verbose = 1
# )

epochs = 20
batch_size = 32

for epoch in range(epochs):
print(f&quot;Epoch {epoch + 1}/{epochs}&quot;)

# 训练 
# 使用 model.fit 进行训练，而不是手动迭代
history = model.fit(
train_dataset,
epochs=1, # 在外循环中一次训练一个 epoch
validation_data=validation_dataset,
steps_per_epoch=train_dataset.samples // batch_size,
validation_steps=validation_dataset.samples // batch_size,
verbose=1
)

# 验证 - 此部分可以保持不变
val_loss, val_accuracy = model.evaluate(validation_dataset)
print(f&quot;验证 - 损失：{val_loss:.4f}, 准确率： {val_accuracy:.4f}&quot;)

print(&quot;训练完成。&quot;)from keras.models import load_model
model_save_path = &#39;/content/drive/MyDrive/Machine Learning/saved_models/model_plastik.h5&#39;
model.save(model_save_path,save_format=&#39;keras&#39;)

model.summary()
print(f&#39;Model disimpan di: {model_save_path}&#39;)

# 加载模型
model_save_path = &#39;/content/drive/MyDrive/Machine Learning/saved_models/model_plastik.h5&#39;

# 加载模型，确保在需要时对其进行编译
loaded_model = tf.keras.models.load_model(model_save_path) 

# 现在您可以根据需要修改已加载的模型
# 例如，如果您想要提取子模型：
input_layer_index = 0 # 用实际索引替换
dense_2_index = 3 # 用实际索引替换
loaded_model = tf.keras.models.Model(inputs=loaded_model.layers[input_layer_index].input, 
outputs=loaded_model.layers[dense_2_index].output)

# 检查已加载模型的配置
for i, layer in enumerate(loaded_model.layers):
print(f&quot;Layer {i}: {layer.name} - 输入形状：{layer.input_shape} - 输出形状：{layer.output_shape}&quot;)

print(&quot;修订后的模型已成功加载。&quot;)

我尝试加载模型，并希望它已加载以进行测试]]></description>
      <guid>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</guid>
      <pubDate>Thu, 08 Aug 2024 07:06:54 GMT</pubDate>
    </item>
    <item>
      <title>无法在 AWS 或 Vercel 上部署 ML 项目</title>
      <link>https://stackoverflow.com/questions/78846779/unable-to-deploy-ml-project-on-aws-or-vercel</link>
      <description><![CDATA[我创建了一个简单的 ML 项目，根据性别、体重和身高预测一个人的 BMI，这是 GitHub 代码存储库的链接
https://github.com/sid111nov/BMIProject
我可以在本地机器上运行它，但无法将其部署到 AWS Bean Stack 或 Vercel。然后我认为我的项目可能存在一些问题，但构建似乎没问题。非常感谢任何解决此问题的意见，提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78846779/unable-to-deploy-ml-project-on-aws-or-vercel</guid>
      <pubDate>Thu, 08 Aug 2024 06:23:07 GMT</pubDate>
    </item>
    <item>
      <title>我正在编写决策树修剪算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78846680/i-am-writing-a-decision-tree-pruning-algorithm</link>
      <description><![CDATA[我正在尝试修剪决策树，这是我的代码，它没有按照我的预期工作，这里到底出了什么问题，
我试图实现的是，我试图根据 2 个标准（纯度阈值和人口阈值）修剪树，下面的算法没有给我我想要的结果，我这里缺少什么条件或检查，如何使其更强大？
# 使用前序遍历和标准修剪树的函数
def prune_preorder(inner_tree, index, purity_threshold=95,population_threshold=5):
# 处理当前节点
node_samples = inner_tree.n_node_samples[index]
# 修复修剪节点的特征确定逻辑
feature = feature_names[inner_tree.feature[index]] if inner_tree.feature[index] != -1 else &quot;Leaf节点”
阈值 = f” &lt;= {inner_tree.threshold[index]:.2f}”如果 inner_tree.feature[index] != -1 否则””
值 = inner_tree.value[index][0]
多数类别计数 = max(值)
纯度 = (多数类别计数 / 总和(值)) * 100 如果节点样本 &gt; 0 否则 0
人口百分比 = (节点样本 / 总样本) * 100 如果节点样本 &gt; 0 else 0

# 在修剪决策之前打印节点统计信息
print(f&quot;Node {feature} {index} : Samples={node_samples}, Purity={purity:.2f}%, Population={population_pct:.2f}%&quot;)

# 检查是否应修剪节点
if purity &gt;= purity_threshold orpopulation_pct &lt;人口阈值：
print(f&quot;修剪节点 {feature} {index} {threshold} (纯度： {purity:.2f}%, 人口： {population_pct:.2f}%)&quot;)
# 通过将子指针设置为 -1 将节点标记为叶子
inner_tree.children_left[index] = -1
inner_tree.children_right[index] = -1
else:
# 如果存在左子树，则遍历左子树
if inner_tree.children_left[index] != -1:
prune_preorder(inner_tree, inner_tree.children_left[index], purity_threshold, 人口阈值)

# 如果存在右子树，则遍历右子树
if inner_tree.children_right[index] != -1:
prune_preorder(inner_tree, inner_tree.children_right[index], purity_threshold,人口阈值)

# 使用前序遍历从根节点应用修剪
prune_preorder(clf.tree_, 0, purity_threshold=95,population_threshold=5)

# 为修剪后的树创建节点标签
node_labels_pruned = custom_node_labels(clf, feature_names, xmtrain, ymtrain)

理想情况下，树在满足修剪标准的任何地方都不应有子节点，但我看到一些标记为叶子的节点没有样本，还有更多子节点，理想情况下不应该这样。]]></description>
      <guid>https://stackoverflow.com/questions/78846680/i-am-writing-a-decision-tree-pruning-algorithm</guid>
      <pubDate>Thu, 08 Aug 2024 05:47:13 GMT</pubDate>
    </item>
    <item>
      <title>未找到与 torch==1.9.1 匹配的分布</title>
      <link>https://stackoverflow.com/questions/78846461/no-matching-distribution-found-for-torch-1-9-1</link>
      <description><![CDATA[我尝试使用 google colab 安装 torchmeta，但它依赖于 torch&lt;1.10.0 and &gt;=1.4.0，每当我尝试安装 torch 1.9.0 或任何版本的 torch&lt;1.10.0 and &gt;=1.4.0 时，都会出现以下错误：

错误：找不到满足要求 torch==1.9.1 的版本（来自版本：1.11.0、1.12.0、1.12.1、1.13.0、1.13.1、2.0.0、2.0.1、2.1.0、2.1.1、2.1.2、2.2.0、2.2.1， 2.2.2、2.3.0、2.3.1、2.4.0)错误：未找到与 torch==1.9.1 匹配的发行版

如何解决此问题？
我正在使用 Google colab，Python 版本 3.10.12。
如果我遇到的问题无法解决，请告诉我使用 colab 安装 torchmeta 的其他方法。
我正在尝试安装 torch&lt;1.10.0 和 &gt;1.4.0，然后安装依赖于我提到的 torch 版本 torch&lt;1.10.0 和 &gt;1.4.0 的 torchmeta。]]></description>
      <guid>https://stackoverflow.com/questions/78846461/no-matching-distribution-found-for-torch-1-9-1</guid>
      <pubDate>Thu, 08 Aug 2024 03:54:54 GMT</pubDate>
    </item>
    <item>
      <title>人工智能技术用于查找两个时间序列之间的相关性/模式/共同趋势[关闭]</title>
      <link>https://stackoverflow.com/questions/78846294/ai-techniques-to-find-correlation-pattern-common-trend-between-two-time-series</link>
      <description><![CDATA[我有一个想法，使用人工智能技术在两个连续的时间序列数据之间找到有用的信息。结果可以是相关值、共同模式或趋势等，输出结果如 TS1（时间序列 1）数据与 TS2 数据相关，反之亦然。
稍后我想特别指出这种关系究竟发生在哪里，以及它是什么类型的效果。

例如：
输入：过去 5 年的 TS1 和 TS2 数据。[浮点/双精度值]
过程：寻找相关性/模式/共同趋势。[这是我寻求指导的部分。]
输出：TS1 的变化每个月都会对 TS2 产生负面影响。 [输出文本可以由

过程部分的结果组成。]

加载数据、将其传递给模型/系统，并为非技术人员解释结果并不是一项艰巨的任务。对我来说，有趣的部分是如何找到某种关系。
到目前为止，我已经使用了 Person、Spearman 和 Kendall 相关性，并且根据我的要求，它工作得很好。但是，我想了解和使用多种技术，尤其是高级统计和机器学习模型。
由于我是时间序列数据的新手，我对选择正确的路径来实现上述目标的知识有限。所以，有人可以指导我哪些高级技术/模型（静态、机器学习等）适合找到两个连续时间序列数据之间的关系？
提前谢谢您。
祝您有美好的一天！ :)]]></description>
      <guid>https://stackoverflow.com/questions/78846294/ai-techniques-to-find-correlation-pattern-common-trend-between-two-time-series</guid>
      <pubDate>Thu, 08 Aug 2024 02:13:43 GMT</pubDate>
    </item>
    <item>
      <title>face_recognition 模块以某种方式严重干扰了 Speech_recognition 模块（python）</title>
      <link>https://stackoverflow.com/questions/78845929/face-recognition-module-somehow-badly-interfering-with-speech-recognition-module</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78845929/face-recognition-module-somehow-badly-interfering-with-speech-recognition-module</guid>
      <pubDate>Wed, 07 Aug 2024 22:40:22 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Mediapipe 根据特定面部区域过滤面部标志坐标？</title>
      <link>https://stackoverflow.com/questions/78845589/how-to-filter-face-landmark-coordinates-by-specific-facial-regions-using-mediapi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78845589/how-to-filter-face-landmark-coordinates-by-specific-facial-regions-using-mediapi</guid>
      <pubDate>Wed, 07 Aug 2024 20:41:07 GMT</pubDate>
    </item>
    <item>
      <title>构建模拟 SVM 模型的自定义分类器</title>
      <link>https://stackoverflow.com/questions/78843755/building-a-custom-classifier-that-simulates-svm-model</link>
      <description><![CDATA[我在代码中使用了以下 SVM：
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classes_report, confusion_matrix, f1_score

# 加载数据
data = pd.read_csv(&#39;data.csv&#39;)

# 分离特征 (X) 和目标变量 (y)
X = data.drop(columns=&#39;label&#39;)
y = data[&#39;label&#39;]

# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 标准化特征
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 定义小网格搜索的参数网格
param_grid = {
&#39;C&#39;: [0.1, 1, 10],
&#39;gamma&#39;: [&#39;scale&#39;, 0.01, 0.1]
}

# 执行带有交叉验证的网格搜索
grid_search = GridSearchCV(SVC(kernel=&#39;rbf&#39;), param_grid, cv=3,scoring=&#39;f1_weighted&#39;, verbose=2, n_jobs=-1)
grid_search.fit(X_train_scaled, y_train)

# 来自网格搜索的最佳参数
best_params = grid_search.best_params_
print(f&#39;Best parameters: {best_params}\n&#39;)

# 训练 SVM 模型使用最佳参数
svm_best = SVC(kernel=&#39;rbf&#39;, C=best_params[&#39;C&#39;], gamma=best_params[&#39;gamma&#39;])
svm_best.fit(X_train_scaled, y_train)

# 对测试集进行预测
y_pred_best = svm_best.predict(X_test_scaled)

# 对改进模型的评估
print(&quot;改进的 SVM 模型评估&quot;)
print(confusion_matrix(y_test, y_pred_best))
print(classification_report(y_test, y_pred_best))
improved_f1 = f1_score(y_test, y_pred_best, average=&#39;weighted&#39;)
print(f&#39;改进的加权 F1 分数： {improved_f1}\n&#39;)


如您所见，我直接使用来自 sklearn 的 SVM 模型。我如何创建一个名为“分类器”的类，它将执行相同的操作并获得相同的结果？这可能吗？
我尝试创建类并使用每个函数的参数，但结果总是更糟。]]></description>
      <guid>https://stackoverflow.com/questions/78843755/building-a-custom-classifier-that-simulates-svm-model</guid>
      <pubDate>Wed, 07 Aug 2024 12:39:48 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“datachain.lib”的模块；“datachain”不是一个包</title>
      <link>https://stackoverflow.com/questions/78843004/modulenotfounderror-no-module-named-datachain-lib-datachain-is-not-a-packa</link>
      <description><![CDATA[
为什么我会遇到 datachain.lib 模块的 ModuleNotFoundError？
我需要采取其他步骤才能在项目中正确使用 datachain 包吗？

我正在开发一个 Python 项目，在尝试导入模块时遇到以下错误：
import os
os.environ[&quot;PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION&quot;] = &quot;python&quot;
import tensorflow as tf
import numpy as np
from PIL import Image
from datachain.lib.dc import Column, DataChain

错误消息：
ModuleNotFoundError：没有名为“datachain.lib”的模块； &#39;datachain&#39; 不是包

详细信息：

我已使用 pip 安装了 datachain：pip install datachain。
通过运行 pip list 可看到 datachain 的安装版本为 0.2.18。
我已验证包已正确安装并位于我的 Python 环境中。
]]></description>
      <guid>https://stackoverflow.com/questions/78843004/modulenotfounderror-no-module-named-datachain-lib-datachain-is-not-a-packa</guid>
      <pubDate>Wed, 07 Aug 2024 09:53:07 GMT</pubDate>
    </item>
    <item>
      <title>如何在 TensorFlow Pipeline 中对大型数据集应用图像增强？</title>
      <link>https://stackoverflow.com/questions/78816835/how-to-apply-image-augmentations-in-tensorflow-pipeline-for-large-dataset</link>
      <description><![CDATA[我有一个图像数据集，每个图像包含一个 1 到 5 个字母的单词。我想使用深度学习对每个图像中组成单词的字符进行分类。这些图像的标签格式如下：
totalcharacter_indexoffirstchar_indexofsecondchar_.._indexoflastchar
我正尝试将这些图像加载到 TensorFlow 管道中，以降低由于内存限制而导致的复杂性。下面是我从目录加载和处理图像和标签的代码：
def process_img(file_path):
label = get_label(file_path)
image = tf.io.read_file(file_path)
image = tf.image.decode_png(image, channels=1) 
image = tf.image.convert_image_dtype(image, tf.float32) 
target_shape = [695, 1204]
image = tf.image.resize_with_crop_or_pad(image, target_shape[0], target_shape[1])

# 对标签进行编码
coded_label = tf.py_function(func=encode_label, inp=[label], Tout=tf.float32)
coded_label.set_shape([5, len(urdu_alphabets)])

return image,coded_label
input_dir = &#39;/kaggle/input/dataset/Data/*&#39;
images_ds = tf.data.Dataset.list_files(input_dir, shuffle=True)

train_count = int(tf.math.round(len(images_ds) * 0.8))
train_ds = images_ds.take(train_count)
test_ds = images_ds.skip(train_count)
train_ds = train_ds.map(process_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.map(process_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.batch(32)
train_ds = train_ds.cache()
test_ds = test_ds.cache()
train_ds = train_ds.shuffle(len(train_ds))
test_ds = test_ds.prefetch(tf.data.AUTOTUNE)
print(train_ds)
print(test_ds)

train_ds 如下所示：
&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(None, 695, 1204, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5, 39), dtype=tf.float32, name=None))&gt;
现在，我想对图像应用简单的增强，例如旋转、剪切、侵蚀和扩张。我最初使用了以下函数：
def augment(image, label):
image = tf.image.random_flip_left_right(image)
image = tf.image.random_flip_up_down(image)
image = tf.keras.preprocessing.image.random_rotation(image, rg=15, row_axis=0, col_axis=1, channel_axis=2, fill_mode=&#39;nearest&#39;, cval=0.0, interpolation_order=1)
image = tf.image.random_zoom(image, [0.85, 0.85])
image = tf.image.random_shear(image, 0.3)
image = tf.image.random_shift(image, 0.1, 0.1)
return image, label

train_augmented_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)
train_augmented_ds = train_augmented_ds.prefetch(buffer_size=tf.data.AUTOTUNE)

但是，tf.image 中的许多函数都已弃用。如何以高效的方式在 TensorFlow 管道中将这些增强应用于图像？
注意：我可以通过不使用 TensorFlow 管道使用 NumPy 数组加载图像来执行这些增强，但我的数据集非常大（110 万张图像），因此我需要一种高效的方法来执行此操作。]]></description>
      <guid>https://stackoverflow.com/questions/78816835/how-to-apply-image-augmentations-in-tensorflow-pipeline-for-large-dataset</guid>
      <pubDate>Wed, 31 Jul 2024 14:11:01 GMT</pubDate>
    </item>
    <item>
      <title>Python Darts 中的 RNN 训练指标</title>
      <link>https://stackoverflow.com/questions/78144820/rnn-training-metrics-in-python-darts</link>
      <description><![CDATA[我目前正在使用 python darts 训练 RNNModel。为了比较不同的训练模型，我想从 fit 方法中提取 train_loss 和 val_loss。我该怎么做？我读过一些关于度量集合的内容，但不知道如何使用它。
这是我当前的代码
from darts.models import RNNModel
from darts import TimeSeries

train = # training data as TimeSeries
model = RNNModel(model=&quot;LSTM&quot;, input_chunk_length=self.past_samples)
model.fit(train)

训练期间，控制台中会显示损失，但我不知道如何访问它。
到目前为止，我尝试在网上查找任何文档，并向 bing chat 和 ChatGPT 寻求帮助。但是他们告诉我使用不存在的 model.history.history[&quot;loss&quot;]]]></description>
      <guid>https://stackoverflow.com/questions/78144820/rnn-training-metrics-in-python-darts</guid>
      <pubDate>Tue, 12 Mar 2024 05:29:49 GMT</pubDate>
    </item>
    <item>
      <title>无法在 python 中安装 lap==0.4.0 库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark 中的过采样或 SMOTE</title>
      <link>https://stackoverflow.com/questions/53936850/oversampling-or-smote-in-pyspark</link>
      <description><![CDATA[我有 7 个类，总记录数为 115，我想对这些数据运行随机森林模型。但由于数据不足以获得高精度。所以我想对所有类进行过采样，使多数类本身获得更高的计数，然后少数类获得更高的计数。这在 PySpark 中可行吗？
+---------+-----+
| SubTribe|count|
+---------+-----+
| Chill| 10|
| Cool| 18|
|Adventure| 18|
| Quirk| 13|
| Mystery| 25|
| Party| 18|
|Glamorous| 13|
+---------+-----+
]]></description>
      <guid>https://stackoverflow.com/questions/53936850/oversampling-or-smote-in-pyspark</guid>
      <pubDate>Wed, 26 Dec 2018 20:31:36 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的神经元应该是异步的吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/38250558/should-the-neurons-in-a-neural-network-be-asynchronous</link>
      <description><![CDATA[我正在设计一个神经网络，并试图确定我是否应该以这样一种方式编写它，即每个神经元都是 Erlang 中的自己的“进程”，或者我是否应该只使用 C++ 并在一个线程中运行一个网络（我仍然会通过在每个网络自己的线程中运行一个实例来使用我的所有核心）。
是否有充分的理由放弃 C++ 的速度而选择 Erlang 提供的异步神经元？]]></description>
      <guid>https://stackoverflow.com/questions/38250558/should-the-neurons-in-a-neural-network-be-asynchronous</guid>
      <pubDate>Thu, 07 Jul 2016 16:17:43 GMT</pubDate>
    </item>
    </channel>
</rss>