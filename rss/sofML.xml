<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Dec 2023 12:24:47 GMT</lastBuildDate>
    <item>
      <title>Flask 应用程序返回 None</title>
      <link>https://stackoverflow.com/questions/77703234/flask-application-returns-none</link>
      <description><![CDATA[这是一个根据鸢尾花的属性对鸢尾花进行分类的 Web 应用程序。
这里是 GitHub 链接 运行代码时，预测路由不会将值推送到输出路径。
帮我解决这个问题
我尝试在预测函数中调用输出函数，并尝试将其转换为具有相应花的字符串。
我尝试了一堆 if else 语句来解决该问题，但仍然不起作用。
output.html 呈现如下：
你的花没有
我诚实地尝试了我所知道的一切来解决这个问题，但仍然遇到同样的问题:(]]></description>
      <guid>https://stackoverflow.com/questions/77703234/flask-application-returns-none</guid>
      <pubDate>Fri, 22 Dec 2023 10:54:12 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：微调 LLM 时需要解包的值太多（预期为 2）</title>
      <link>https://stackoverflow.com/questions/77702885/valueerror-too-many-values-to-unpack-expected-2-when-fine-tuning-an-llm</link>
      <description><![CDATA[我对大型语言模型 (LLM) 比较陌生，目前正在学习如何对其进行微调。但是，无论我如何修改数据处理方法，在微调过程中执行 Trainer.train() 时都会遇到一致的错误。错误如下：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-11-3435b262f1ae&gt;在&lt;细胞系：1&gt;()
----&gt; 1 个训练器.train()

12帧
/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py 在 _expand_mask(mask, dtype, tgt_len)
    152 将attention_mask从“[bsz，seq_len]”扩展到“[bsz，1，tgt_seq_len，src_seq_len]”。
    第153章
--&gt;第154章
    [第 155 章]
    156

ValueError：需要解压的值太多（预期为 2）

表明扩展注意力掩码时出现问题。该错误消息表明解压值时出现问题，期望有两个值，但得到更多。
我检查了我的注意力蒙版的尺寸，它似乎是二维的，我认为这是正确的。以下是我的一项数据条目的示例：
{&#39;input_ids&#39;: 张量([[ ...张量值... ]]),
 &#39;attention_mask&#39;: 张量([[1, 1, 1, ... 0, 0]])}


有人可以帮我确定问题可能出在哪里吗？任何指导或建议将不胜感激。
预先感谢您的帮助和时间！
我一直在搜索各种文章和教程，寻找一种有效处理这种数据格式以进行LLM微调的方法，但到目前为止，我尝试过的方法都没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77702885/valueerror-too-many-values-to-unpack-expected-2-when-fine-tuning-an-llm</guid>
      <pubDate>Fri, 22 Dec 2023 09:48:31 GMT</pubDate>
    </item>
    <item>
      <title>收到“ValueError：X 有 6 个特征，但 LinearRegression 期望 7 个特征作为输入。”可能是由于列转换（管道）步骤</title>
      <link>https://stackoverflow.com/questions/77702656/getting-valueerror-x-has-6-features-but-linearregression-is-expecting-7-featu</link>
      <description><![CDATA[泰坦尼克号 = pd.read_csv(“train.csv”)
titanic_test = pd.read_csv(“test.csv”)
titanic_train_labels = 泰坦尼克号[&#39;幸存&#39;].copy()
泰坦尼克号 = 泰坦尼克号.drop(columns = &#39;幸存&#39;)

**
＃管道**
titanic_num = [&#39;年龄&#39;, &#39;票价&#39;]
titanic_cat = [&#39;性别&#39;, &#39;登船&#39;]

num_pipeline = 管道([
        (“imputer”, SimpleImputer(strategy=&#39;median&#39;)),
        （“std_scaler”，StandardScaler（）），
    ]）

cat_pipeline = 管道([
        (“enc”, OneHotEncoder(drop=&#39;if_binary&#39;))
    ]）

def full_pipeline(num_attribs, cat_attribs):
    返回列转换器（[
        (“num”, num_pipeline, num_attribs),
        （“猫”，cat_pipeline，cat_attribs）
    ]）

titanic_prepared = full_pipeline(titanic_num, titanic_cat)
泰坦尼克号清洁 = 泰坦尼克号准备.fit_transform(泰坦尼克号)
**
#在这里，我通过相同的管道准备测试数据**
泰坦尼克号测试编号 = 泰坦尼克号测试编号
泰坦尼克号测试猫 = 泰坦尼克号猫
titanic_test_prepared = full_pipeline(titanic_test_num, titanic_test_cat)
泰坦尼克号测试清洁 = 泰坦尼克号测试准备.fit_transform(泰坦尼克号测试)
Final_model.fit(titanic_clean, titanic_train_labels)

标题上出现错误的代码：
final_model.predict(titanic_test_clean)

&lt;小时/&gt;
打印可能提示问题的有用信息：
titanic_clean[0] -&gt; &gt;数组([-0.56573646,-0.50244517,1.,0.,0.,
        1., 0.]) # 7 项
titanic_test_clean[0] -&gt; 泰坦尼克号测试清洁[0] -&gt;数组([ 0.38623105, -0.49741333, 1., 0., 1.,
        0.]) # 6 项

根据上面的信息，我认为问题在于 onecodeencoder 的数量不匹配。我怀疑训练集和测试集的分类值数量不同。但他们确实是。
数据集的链接 -&gt; https://github.com/minsuk-heo/ kaggle-titanic/blob/master/input/test.csv]]></description>
      <guid>https://stackoverflow.com/questions/77702656/getting-valueerror-x-has-6-features-but-linearregression-is-expecting-7-featu</guid>
      <pubDate>Fri, 22 Dec 2023 09:05:39 GMT</pubDate>
    </item>
    <item>
      <title>用于实时流处理的 Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</link>
      <description><![CDATA[我正在 aws 上对实时视频流进行实时机器学习处理。
对于直播，正在使用 kinesis 视频流。
我正在从模型工件（存储我们的推理脚本和模型文件的位置）创建 sagemaker 端点
当我们从实时流中获取它们时，每个帧都会独立调用此端点。
挑战在于维护变量的缓存/会话状态。当每个帧到达端点时，它没有有关先前运行的结果的信息。为了解决这个问题，我为每次调用下载缓存并将其上传到数据库（dynamo db），这似乎是一种低效的方法。
我想探索是否有某种方式 - 实例在整个直播流中都处于活动状态，每当实例接收到帧时，都会对其进行处理，缓存将一直存在，直到实例死亡。
而不是为每个帧单独流调用端点。
供参考 - 我在推理脚本中使用 pytorch 框架中外部训练的 YOLO 对象检测模型。]]></description>
      <guid>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</guid>
      <pubDate>Fri, 22 Dec 2023 08:28:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么这两类深度神经网络计算layer2_delta的方法不同？</title>
      <link>https://stackoverflow.com/questions/77702306/why-are-the-methods-of-computing-layer2-delta-different-in-these-two-types-of-de</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77702306/why-are-the-methods-of-computing-layer2-delta-different-in-these-two-types-of-de</guid>
      <pubDate>Fri, 22 Dec 2023 07:42:33 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制交叉验证的 AUROC 并找到最佳阈值？</title>
      <link>https://stackoverflow.com/questions/77702305/how-to-plot-cross-validated-auroc-and-find-the-optimal-threshold</link>
      <description><![CDATA[在通过交叉验证评估我的机器学习模型时，我遇到了一个问题。我知道如何在交叉验证中绘制 AUROC 和每个折叠的相应阈值，但我不确定是否绘制所有折叠的平均 AUROC 及其相应阈值。
为此，我在Stack Overflow上探索了相关问题，并找到了相应的解决方案。您可以通过以下链接找到原始问题：[https://stackoverflow.com/questions/57708023/plotting-the-roc-curve-of-k-fold-cross-validation%5C]。尽管我成功生成了平均 ROC，但在准确绘制相应阈值方面遇到了挑战。为了解决这个问题，我根据自己的理解合并了额外的代码，但我不确定这种方法的正确性。
此外，我观察到使用 np.mean() 计算的平均 AUC 与使用 sklearn.metrics 计算的 AUC 值之间存在差异。因此，我正在寻求关于哪个值更准确以获得精确的 AUC 结果的指导。下面是我调整后的修改代码。
X，y = make_classification（n_samples = 1000，n_features = 20，n_classes = 2，random_state = 42）

cv = 分层KFold(n_splits=10)
分类器= SVC（内核=&#39;sigmoid&#39;，概率= True，random_state = 0）

tprs = []
曲线面积=[]
最佳阈值 = []
Mean_fpr = np.linspace(0, 1, 100)
plt.figure(figsize=(10,10))
我=0
对于火车，在 cv.split(X, y) 中测试：
    probas_ = classifier.fit(X[训练], y[训练]).predict_proba(X[测试])
    # 计算 ROC 曲线并计算曲线面积
    fpr, tpr, 阈值 = roc_curve(y[测试], probas_[:, 1])

    # 我添加的代码：
    最优阈值索引 = np.argmax(tpr-fpr)
    最优阈值 = 阈值[最优阈值索引]
    最佳阈值.append(最佳阈值)
    #

    tprs.append(np.interp(mean_fpr, fpr, tpr))
    tprs[-1][0] = 0.0
    roc_auc = auc(fpr, tpr)
    aucs.append(roc_auc)
    plt.plot(fpr, tpr, lw=1, alpha=0.3,
             label=&#39;ROC 折叠 %d (AUC = %0.4f)&#39; % (i, roc_auc))

    我 += 1



plt.plot([0, 1], [0, 1], 线型=&#39;--&#39;, lw=2, 颜色=&#39;r&#39;,
         标签=&#39;机会&#39;，alpha=.8)

mean_tpr = np.mean(tprs, 轴=0)
平均值_tpr[-1] = 1.0


mean_auc = auc(mean_fpr,mean_tpr)

# 我添加的代码：
np_mean_AUC = np.mean(aucs)
# print(f&quot;np_mean_AUC={np_mean_AUC},mean_auc={mean_auc}&quot;)
#

std_auc = np.std(aucs)

plt.plot(mean_fpr,mean_tpr,颜色=&#39;b&#39;,
         标签=r&#39;平均ROC (AUC = %0.4f $\pm$ %0.4f)&#39; % (np_mean_AUC, std_auc),
         lw=2，阿尔法=.8)

# 我添加的代码：
mean_optimal_threshold_index = np.argmax(mean_tpr-mean_fpr)
plt.annotate(f&#39;平均最佳阈值({np.mean(optimal_thresholds):.2f})&#39;,
                xy=(mean_fpr[平均最佳阈值索引],mean_tpr[平均最佳阈值索引]),
                xy 文本=(5, -5),
                textcoords=&#39;偏移点&#39;,
                arrowprops = dict（facecolor =&#39;红色&#39;，arrowstyle =&#39;楔形，tail_width = 0.7&#39;，shrinkA = 0，shrinkB = 10），
                颜色=&#39;红色&#39;）
#

std_tpr = np.std(tprs, 轴=0)
tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
plt.fill_ Between(mean_fpr, tprs_lower, tprs_upper, color=&#39;grey&#39;, alpha=.2,
                 标签=r&#39;$\pm$ 1 标准。开发。”）

plt.xlim([-0.01, 1.01])
plt.ylim([-0.01, 1.01])
plt.xlabel(&#39;误报率&#39;,fontsize=18)
plt.ylabel(&#39;真阳性率&#39;,fontsize=18)
plt.title(&#39;SVM的交叉验证ROC&#39;,fontsize=18)
plt.legend(loc=“右下”, prop={&#39;size&#39;: 15})
plt.show()

以下是输出：
在此处输入图像描述
请告诉我我在代码中所做的更改是否可以准确绘制用于交叉验证的 ROC 曲线以及相应的阈值，以及标记的 AUC 值是否有意义。]]></description>
      <guid>https://stackoverflow.com/questions/77702305/how-to-plot-cross-validated-auroc-and-find-the-optimal-threshold</guid>
      <pubDate>Fri, 22 Dec 2023 07:42:20 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用 Google Vision 从图像创建 Excel 工作表吗</title>
      <link>https://stackoverflow.com/questions/77702105/can-we-create-an-excel-sheet-from-an-image-using-google-vision</link>
      <description><![CDATA[我想要转换为 Excel 表格的收据
上面是一张收据图像，我现在想从此图像创建一个 csv 工作表，我正在使用 google Vision ocr，通过它我获取的文本也没有任何结构，我该怎么办？
我从 google Vision ocr 获得的输出如下所示
Workie 塔，SP 365 大楼，
詹吉尔瓦拉广场
阿普纳大道酒店对面，
新帕拉西亚 Janjeerwala 广场附近，
印多尔, 中央邦 452003
支票/ACH 号码 2456345
支票/存款日期
付款方式
索赔编号：2349824
单价
数量
56.0 美元
5.0
12/01/24
系统检查
超出金额
$234.0
拒绝数量
金额被拒绝
0.00
5.76 美元
总优惠券。
新的
扩展
数量
$434.0
$434.0
供应商ID
汇给
这是标题，请阅读它
CPT代码
彩色显像管描述
124245283752345
4
发票号码：
kjfbglwknwpr9t9045820989
今天的日期 12/01/24
D4532
护理，在
家;乙
CPT评论
00:00-00:00（08:00 开始）
申请金额。
患者编号
患者姓名
2345234
AKJSNDFKJNS
asdvsfvdfv
sdfvsf sfvsfv sfvsfv
$434.0
发票日期：24 年 12 月 1 日
开始日期
结束日期
12/01/24
12/02/25
这只是一些随机数据，这只是
一些随机数据，这只是一些
随机数据，这只是一些随机数据
数据，这只是一些随机数据，
注意：这只是一些随机数据，这只是一些
随机数据，这只是一些随机数据，这只是
一些随机数据，这只是一些随机数据，
原因代码
原因代码说明
Vue 评论
审稿人意见]]></description>
      <guid>https://stackoverflow.com/questions/77702105/can-we-create-an-excel-sheet-from-an-image-using-google-vision</guid>
      <pubDate>Fri, 22 Dec 2023 06:54:52 GMT</pubDate>
    </item>
    <item>
      <title>谁能建议更好的机器学习算法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77701763/can-anyone-suggest-a-better-machine-learning-algorithm</link>
      <description><![CDATA[你能建议一个更好的算法吗？
我有一个数据集，有 29 个输入和 1 个输出。目前训练数据集由 2242 行组成。
我尝试了几种算法，最好的算法是高斯过程回归指数 GP2(R^2=0.50) 。你能建议一个更好的算法吗？
如果需要，我可以与您分享数据集。我感谢任何帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77701763/can-anyone-suggest-a-better-machine-learning-algorithm</guid>
      <pubDate>Fri, 22 Dec 2023 05:01:47 GMT</pubDate>
    </item>
    <item>
      <title>GPT4/gpt 3.5 turb0 的支持/置信度得分 [关闭]</title>
      <link>https://stackoverflow.com/questions/77700790/support-confidence-score-for-gpt4-gpt-3-5-turb0</link>
      <description><![CDATA[计算以下 API 输出的置信度得分的方法或过程：
 openai.ChatCompletion.create
有没有办法使用azure open ai api接收置信度分数目前没有提供置信度值的open ai api]]></description>
      <guid>https://stackoverflow.com/questions/77700790/support-confidence-score-for-gpt4-gpt-3-5-turb0</guid>
      <pubDate>Thu, 21 Dec 2023 22:10:51 GMT</pubDate>
    </item>
    <item>
      <title>人工神经网络实施中的故障排除</title>
      <link>https://stackoverflow.com/questions/77700758/troubleshooting-issues-in-artificial-neural-network-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77700758/troubleshooting-issues-in-artificial-neural-network-implementation</guid>
      <pubDate>Thu, 21 Dec 2023 22:01:55 GMT</pubDate>
    </item>
    <item>
      <title>保存 jit 跟踪时 SwishImplementation 错误</title>
      <link>https://stackoverflow.com/questions/74813562/swishimplementation-error-when-saving-jit-trace</link>
      <description><![CDATA[我正在尝试 jit 跟踪并从分段模型包中保存我的 pytorch 模型。但我收到错误。 &quot;无法导出 Python 函数调用“SwishImplementation”。在导出之前删除对 python 函数的调用。您是否忘记添加@script或@scrript_method注释？如果这是一个 nn.ModuleList，请将其添加到 _ constants _”只有当我使用 effectivenet 主干网时才会发生这种情况。如何让 save() 函数正常工作？我需要能够在 C++ 应用程序中使用该模型。
导入火炬
将segmentation_models_pytorch导入为smp

模型 = smp.Unet(&#39;efficientnet-b7&#39;)
模型.eval()

输入 = torch.randn((1,3,224,224))
torch_out = 模型（输入）

模型 = torch.jit.trace(模型,输入)
跟踪输出 = 模型（输入）

model.save(&#39;model.pt&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/74813562/swishimplementation-error-when-saving-jit-trace</guid>
      <pubDate>Thu, 15 Dec 2022 15:04:50 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace AutoModelForCasualLM “仅解码器架构”警告，即使在设置 padding_side='left' 后也是如此</title>
      <link>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</link>
      <description><![CDATA[我正在使用
AutoModelForCausalLM 和 AutoTokenizer 使用 DialoGPT 生成文本输出。
无论出于何种原因，即使使用 Huggingface 提供的示例，我也会收到此警告：
&lt;块引用&gt;
正在使用仅解码器架构，但检测到右填充！为了正确的生成结果，请在初始化分词器时设置 padding_side=&#39;left&#39;。

从变压器导入 AutoModelForCausalLM, AutoTokenizer
进口火炬


tokenizer = AutoTokenizer.from_pretrained(“microsoft/DialoGPT-medium”)
模型 = AutoModelForCausalLM.from_pretrained(“microsoft/DialoGPT-medium”)

# 我们聊5行吧
对于范围（5）中的步骤：
    # 对新的用户输入进行编码，添加 eos_token 并在 Pytorch 中返回一个张量
    new_user_input_ids = tokenizer.encode(input(“&gt;&gt;用户:”) + tokenizer.eos_token, return_tensors=&#39;pt&#39;)

    # 将新的用户输入标记附加到聊天历史记录中
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) 如果步骤 &gt; 0 其他 new_user_input_ids

    # 生成响应，同时将总聊天历史记录限制为 1000 个令牌，
    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)

    # 漂亮地打印机器人最后的输出令牌
    print(“DialoGPT: {}”.format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0],skip_special_tokens=True)))

代码由 微软在 Huggingface 的模型卡上
我尝试将 padding_side=&#39;left&#39; 添加到标记生成器，但这不会改变任何内容。
显然（从一些阅读来看）DialoGPT 无论如何都希望在右侧填充？
我无法弄清楚这一点，当我尝试谷歌搜索时几乎没有结果。
我能够像这样抑制警告：
from Transformers.utils 导入日志记录

记录.set_verbosity_info()

但这似乎不是最好的答案？]]></description>
      <guid>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</guid>
      <pubDate>Fri, 09 Dec 2022 20:39:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么要打乱测试数据集？</title>
      <link>https://stackoverflow.com/questions/72294686/why-would-you-shuffle-the-test-dataset</link>
      <description><![CDATA[我完全理解如何使用与测试集分开的训练集。
我也理解为什么你会打乱训练集中的批次来计算小批量的梯度。
但是，pyTorch教程中提到的广告，我不明白为什么要使用测试集的洗牌，如下所示：
test_dataloader = DataLoader(test_data,batch_size=64,shuffle=True)

在什么情况下这会有用？]]></description>
      <guid>https://stackoverflow.com/questions/72294686/why-would-you-shuffle-the-test-dataset</guid>
      <pubDate>Wed, 18 May 2022 19:05:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么每个 epoch 之后损失都会突然下降？</title>
      <link>https://stackoverflow.com/questions/57248723/why-there-is-sudden-drop-in-loss-after-every-epoch</link>
      <description><![CDATA[我在小批量中使用自定义损失函数（三元组损失），在纪元期间，损失逐渐减少，但在每个纪元之后，损失会突然下降（约下降的 10％），然后在期间逐渐减少那个时代（忽略准确性）。正常吗？
对此问题的每一个答案和参考都将受到赞赏。
纪元 1/5
198/198 [================================] - 3299s 17s/步 - 损失：0.2500 - 加速：0.0014
纪元 2/5
 99/198 [==============&gt;.................................] - 预计到达时间：26:16 - 损失：0.1220 - 累积费用：0.0016&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/57248723/why-there-is-sudden-drop-in-loss-after-every-epoch</guid>
      <pubDate>Mon, 29 Jul 2019 07:09:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 hmmlearn 解决基本的 HMM 问题</title>
      <link>https://stackoverflow.com/questions/49880279/how-to-solve-basic-hmm-problems-with-hmmlearn</link>
      <description><![CDATA[存在三个基本的 HMM 问题：

&lt;块引用&gt;
  问题 1（可能性）：给定 HMM λ = (A,B) 和观测值
  序列O，确定似然P(O|λ)。
问题 2（解码）：给定观察序列 O 和 HMM λ =
  (A,B)，发现最佳隐藏状态序列Q。
问题 3（学习）：给定一个观察序列 O 和一组
  HMM 中的状态，学习 HMM 参数 A 和 B。

我对问题## 1和3感兴趣。一般来说，第一个问题可以用前向算法解决，第三个问题可以用鲍姆-韦尔奇算法解决。我应该使用 hmmlearn 中的 fit(X, lengths) 和 score(X, lengths) 方法分别解决第一个问题和第三个问题，对吗？ （文档没有说 score 使用前向算法。）
我还有一些关于 score 方法的问题。为什么score计算log概率？为什么如果我将多个序列传递给 score 它会返回对数概率之和而不是每个序列的概率？
我最初的任务如下：我有 100 万个大小相等的短句子（10 个单词）。我想用该数据训练 HMM 模型，并用测试数据（又是 10 个单词的句子）预测模型中每个句子的概率。根据这个概率，我将决定是常用还是不寻常的短语。
也许 python 有更好的库来解决这些问题？]]></description>
      <guid>https://stackoverflow.com/questions/49880279/how-to-solve-basic-hmm-problems-with-hmmlearn</guid>
      <pubDate>Tue, 17 Apr 2018 14:05:10 GMT</pubDate>
    </item>
    </channel>
</rss>