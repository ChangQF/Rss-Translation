<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 21 Jul 2024 21:13:29 GMT</lastBuildDate>
    <item>
      <title>目标文件的对称拟合问题</title>
      <link>https://stackoverflow.com/questions/78776322/symmetry-fitting-problem-with-target-file</link>
      <description><![CDATA[我正在构建一个有 6 列和 6700 行的数据集。该数据是从不同研究的各种蒙特卡罗模拟中提取的光子剂量转换系数获得的。数据中的列包括能量、器官名称、器官质量、器官密度、AP 剂量、PA 剂量和横向剂量。能量行表示从 1keV 到 20 MeV 的每个能量箱计算出的剂量，分为 20 个箱。每个箱重复器官名称、器官质量和器官密度。
如果我们排除器官名称，数据可用于数值拟合。但是，如果我们使用独热编码器对器官名称进行编码，则可以更有效地使用数据，并且交叉验证比仅有数值数据显示出更好的结果。不同器官的剂量取自不同的幻像，其中一些幻像比其他幻像拥有更多的器官。使用独热编码器后，合并的器官总数为 32。
当尝试从新的模型中预测器官时，问题就出现了，因为模型显示输入和目标文件之间存在对称性错误。我的问题是，我们如何解决这个问题？
如果我使用一个带有 1000 个箱子的模型来表示 20 个器官，并预测另一个带有 1000 个箱子的模型，其中 20 个器官完全相同，但器官质量和密度不同，则该文件有效
如何使用分类整体数据（来自 32 个器官的 6700 个箱子来预测（32 个器官的 1000 个箱子）？]]></description>
      <guid>https://stackoverflow.com/questions/78776322/symmetry-fitting-problem-with-target-file</guid>
      <pubDate>Sun, 21 Jul 2024 20:47:32 GMT</pubDate>
    </item>
    <item>
      <title>我们如何通过解决问题的能力来提高问题分析和设计能力？[关闭]</title>
      <link>https://stackoverflow.com/questions/78775745/how-can-we-improve-problem-analysis-and-design-skills-through-problem-solving-ab</link>
      <description><![CDATA[我希望提高我的问题分析和设计技能，并了解提高我的问题解决能力是这一过程的关键部分。作为一名在 Python、Java、机器学习和数据科学方面有经验的程序员，我想知道：

在开始编码之前，系统地分析问题的最佳实践或方法是什么？
如何有效地将复杂问题分解为可管理的部分？
是否有特定的练习或项目类型可以帮助提高我的问题解决和设计技能？
如何将计算机科学的概念（如算法、数据结构和设计模式）应用于现实世界的问题解决场景？
推荐哪些资源（书籍、课程、在线平台）来提高这些技能？
]]></description>
      <guid>https://stackoverflow.com/questions/78775745/how-can-we-improve-problem-analysis-and-design-skills-through-problem-solving-ab</guid>
      <pubDate>Sun, 21 Jul 2024 16:28:07 GMT</pubDate>
    </item>
    <item>
      <title>如何优化递归多步预测以提高性能？</title>
      <link>https://stackoverflow.com/questions/78775642/how-to-optimize-recursive-multi-step-forecasting-to-improve-performance</link>
      <description><![CDATA[我正在开发一个用于每小时销售预测的机器学习项目。我需要提前 7 天进行销售预测。我的模型 (XGBoost) 使用 24 小时前的滞后销售作为输入之一，为了能够在生产中使用它，我必须使用预测值作为第二天预测的滞后特征。我目前使用的递归实现非常慢，需要几分钟才能完成，这是不可行的，因为我每天需要为数百个模型运行它。
当前实现
下面是我正在使用的代码：
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def predict_7_days_ahead(model, X_test, y_test, transform_target_func):
y_pred_df = pd.DataFrame()
input_forecasts_df = pd.DataFrame()

concatenated_df = pd.concat([X_test, y_test], axis=1)

for hour in concatenated_df.index.hour.unique():
print(f&quot;Processing hour: {hour}&quot;)
df = concatenated_df[concatenated_df.index.hour == hour]

for index, row in df.iterrows():
data = df.copy(deep=True)
predictions = []

for steps_ahead in range(8): # 0 到 7
datetime = index + pd.Timedelta(days=steps_ahead)

if datetime in data.index:
row = data.loc[datetime]
X = row.drop(&#39;sales&#39;).values.reshape(1, -1)
y_pred = model.predict(X)
y_pred = transform_target_func(y_pred, method=&#39;log&#39;, how=&#39;inverse&#39;)

col_name = &#39;sales(t)&#39; if steps_ahead == 0 else f&#39;sales(t+{steps_ahead})&#39;
y_pred_df.loc[index, col_name] = y_pred[0]

predictions.append(y_pred[0])

# 更新第二天的滞后特征
next_day_index = datetime + pd.Timedelta(days=1)
if next_day_index in data.index:
for lag in range(1, min(len(forecasts) + 1, 8)):
data.loc[next_day_index, f&#39;sales_lag_{lag}&#39;] = Forecasts[-lag]

input_forecasts_df = pd.concat([input_forecasts_df, row.to_frame().T])

return y_pred_df, input_forecasts_df

def convert_y_test_to_multi_steps_ahead(y_test, steps_ahead=7):
sales = y_test.copy(deep=True)
sales.index = pd.to_datetime(sales.index)
sales = sales.to_frame(name=&#39;sales(t)&#39;)

for i in range(1, steps_ahead+1):
sales[f&#39;sales(t+{i})&#39;] = sales[&#39;sales(t)&#39;].shift(-15*i) # 从 24 更改为 15

return sales

def calculate_and_plot_accuracy(actual_df, Forecast_df, column_prefix=&#39;sales(t&#39;, Threshold=80):
columns = [col for col in Forecast_df.columns if col.startswith(column_prefix)]
columns.sort(key=lambda x: int(x.split(&#39;+&#39;)[-1][:-1]) if &#39;+&#39; in x else 0)

accuracies = []

for column in columns:
if column not in actual_df.columns or column not in Forecast_df.columns:
print(f&quot;在一个或两个数据框中未找到列 {column}。&quot;)
continue

actual = actual_df[column]
Forecast = Forecast_df[column]

accuracy = ((100 - np.abs(actual - Forecast) / actual * 100) &gt;= Threshold).mean() * 100
accuracies.append(accuracy)

# 绘图
plt.figure(figsize=(12, 6))
plt.plot(columns, accuracies, marker=&#39;o&#39;)
plt.title(f&quot;每个步骤的预测准确度 (阈值：{threshold}%)&quot;)
plt.xlabel(&quot;预测步骤&quot;)
plt.ylabel(&quot;准确度 (%)&quot;)
plt.ylim(0, 100)
plt.xticks(rotation=45, ha=&#39;right&#39;)

for i, (col, accuracy) in enumerate(zip(columns, accuracies)):
plt.annotate(f&#39;{accuracy:.2f}%&#39;, (col, accuracy), textcoords=&quot;offset points&quot;, xytext=(0,10), ha=&#39;center&#39;)

plt.tight_layout()
plt.show()

y_pred_df, input_forecasts_df = predict_7_days_ahead(model, X_test, y_test, transform_target)
y_test_multi = convert_y_test_to_multi_steps_ahead(y_test, steps_ahead=7)
calculate_and_plot_accuracy(y_test_multi, y_pred_df, column_prefix=&#39;sales(t&#39;,阈值=80)


是否有任何最佳实践或技术可以优化此递归预测过程？
如何在保持预测准确性的同时提高此函数的性能？
在这种情况下，矢量化操作或使用特定库（例如 Dask、Joblib）是否有帮助？]]></description>
      <guid>https://stackoverflow.com/questions/78775642/how-to-optimize-recursive-multi-step-forecasting-to-improve-performance</guid>
      <pubDate>Sun, 21 Jul 2024 15:45:41 GMT</pubDate>
    </item>
    <item>
      <title>我想使用基于 PCA 的人脸识别技术对 Yaledatabase 进行识别，并使用留一交叉验证法测量识别率</title>
      <link>https://stackoverflow.com/questions/78775565/i-want-to-use-pca-based-face-recognition-for-yaledatabase-and-measure-the-recogn</link>
      <description><![CDATA[我不确定增加特征向量的数量却没有看到识别率发生明显变化有什么问题。我使用的 yaledatabase 总共有 15 组，我通过对每组留一然后除以总数据集来获得识别率，但我不确定哪里出了问题……
import numpy as np
import cv2
import os
from numpy import linalg as LA
def read_images(path):
images = []
filenames = []
for root, dirs, files in os.walk(path):
for index, file in enumerate(files):
if(file.endswith(&#39;.gif&#39;)):
img_path = os.path.join(root, file)
img = loadImageFromPath(img_path)
img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
img_resized = cv2.resize(img_gray, (20,20))
img_normalized = img_resized / 255.0 
images.append((img_normalized, index))
filenames.append(file)
else:
img_path = os.path.join(root, file)
img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
if img_gray 不为 None:
img_resized = cv2.resize(img_gray, (20,20))
img_normalized = img_resized / 255.0 
images.append((img_normalized, index))
filenames.append(file)
返回图像、文件名
def loadImageFromPath(imgPath):
try:
if str(imgPath).lower().endswith(&#39;.gif&#39;):
gif = cv2.VideoCapture(imgPath)
ret, frame = gif.read() # 如果找到帧则 ret=True，否则为 False。
if ret:
返回帧
else:
返回 cv2.imread(imgPath,cv2.IMREAD_GRAYSCALE)
除 Exception 外，因为 e:
print(e)
返回 None

def image_as_row(x):
返回 x.flatten()

def covariance(m):
返回 np.cov(m, rowvar=False) 

def eigenvector(m, k):
w, v = np.linalg.eig(m)
idx = np.argsort(w)[::-1][:k] 
返回 v[:, idx] 

def im_map(image, mean, mv):
new = image_as_row(image)
new = np.subtract(new, mean)
返回 np.dot(new, mv)

def Euclidean_distance(v1, v2):
返回np.sqrt(np.sum(np.power((v1 - v2), 2)))

def find_similar(image, tagged):
distances = [Euclidean_distance(image, m) for m in tagged]
return np.argmin(distances)

def leave_one_out(images, k):
if len(images) == 0:
print(&quot;Error: 没有要处理的图像在 leave_one_out&quot;)
return 0
correct_predictions = 0
n = len(images)

for leave_out_index in range(n):
test_image, test_image_index = images[leave_out_index]
train_images = images[:leave_out_index] + images[leave_out_index + 1:]

vector = np.array([image_as_row(image[0]) for image in train_images])
mean_train = vector.mean(axis=0)
diff = np.subtract(vector, mean_train)
cov = covariance(diff) / len(train_images)
mv = eigenvector(cov, k)

mapped_train = np.dot(diff, mv)
new_image = im_map(test_image, mean_train, mv)

index = find_similar(new_image,mapped_train)
print(f&quot;测试图像 {test_image_index} 与训练图像 {index} 最相似&quot;)

if leave_out_index == index:
correct_predictions += 1

recognition_rate = correct_predictions / n
return identification_rate

def main():
base_path = &#39;Yaledatabase_full/data&#39;
num_sets = 10
images_per_set = 10
k = 10 # Number主成分

all_recognition_rates = []
for set_index in range(1, num_sets + 1):
set_path = os.path.join(base_path, f&quot;{set_index:01d}&quot;)
images, filenames = read_images(set_path)

print(f&quot;Images in set {set_index}:&quot;)
for idx, filename in enumerate(filenames):
print(f&quot;Index: {idx}, Filename: {filename}&quot;)

recognition_rate = leave_one_out(images, k)
all_recognition_rates.append(recognition_rate)
print(f&#39;Recognition rate for set {set_index}: {recognition_rate * 100:.2f}%&#39;)
print(&#39;---------------------------------------------&#39;)

overall_recognition_rate = np.mean(all_recognition_rates)
print(&#39;---------------------------------------------&#39;)
print(f&#39;总体识别率为 {overall_recognition_rate * 100:.2f}%&#39;)

if __name__ == &quot;__main__&quot;:
main()

我想知道，当有 100 个特征向量时，基于 PCA 技术的人脸识别的识别率是否约为 40%，如各种论文所示。]]></description>
      <guid>https://stackoverflow.com/questions/78775565/i-want-to-use-pca-based-face-recognition-for-yaledatabase-and-measure-the-recogn</guid>
      <pubDate>Sun, 21 Jul 2024 15:13:11 GMT</pubDate>
    </item>
    <item>
      <title>计算计算机断层扫描的内轮廓</title>
      <link>https://stackoverflow.com/questions/78775537/calculate-the-inner-contour-of-a-computed-tomography</link>
      <description><![CDATA[我正在做一个计算胸部畸形程度的项目。
为此，我需要从断层扫描中找到胸部的内轮廓，但我不知道如何选择内轮廓。
首先，我将图像转换为二进制并应用阈值。
import cv2
import numpy as np
from PIL import Image

import matplotlib.pyplot as plt

def process_and_plot(image_path):
def process(image_path):
image = cv2.imread(image_path)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
blur_image = cv2.GaussianBlur(gray_image, (5, 5), 0)
_, binary_image = cv2.threshold(blurred_image, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
return binary_image

fig,axes = plt.subplots(1, 2,figsize=(10, 5))

img = Image.open(image_path)
axes[0].imshow(img,cmap=&#39;gray&#39;)
axes[0].set_title(&#39;Original Image&#39;)

processed_image = process(image_path)
axes[1].imshow(processed_image,cmap=&#39;gray&#39;) 
axes[1].set_title(&#39;Processed Image&#39;)

plt.show()

process_and_plot(&#39;test.jpeg&#39;)



我期望得到红色轮廓。
]]></description>
      <guid>https://stackoverflow.com/questions/78775537/calculate-the-inner-contour-of-a-computed-tomography</guid>
      <pubDate>Sun, 21 Jul 2024 15:02:37 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型中的极端 RMSE 验证分数</title>
      <link>https://stackoverflow.com/questions/78775154/extreme-rmse-validation-score-in-time-series-model</link>
      <description><![CDATA[我有一个包含每小时数据的数据集，有 4000 行和 3 个数字列。它没有明显的趋势或季节性。我在下面分享了 stl 分解图以及一个目标列的原始线图。
这是一列目标的图表
我使用此代码进行训练：
tscv = TimeSeriesSplit(n_splits=5,gap=24)
train_rmse_scores = []
val_rmse_scores = []

for fold, (train_index, test_index) in enumerate(tscv.split(melen_forecast_df), start=1):
train_df, test_df = melen_forecast_df.iloc[train_index], melen_forecast_df.iloc[test_index]

# 仅使用训练集创建特征
X_train = create_all_features(train_df)
y_train = train_df[targets]

# 为测试集创建特征
X_test = create_all_features(test_df)
y_test = test_df[targets]

X_train = X_train.iloc[4:]
y_train = y_train.iloc[4:]
X_test = X_test.iloc[4:]
y_test = y_test.iloc[4:]

print(f&quot;Fold {fold} - 训练数据形状：{X_train.shape}, 验证数据形状：{X_test.shape}&quot;)

model = MultiOutputRegressor(xgb.XGBRegressor(objective=&#39;reg:squarederror&#39;,n_estimators=500,learning_rate=0.015))
# 训练模型
model.fit(X_train, y_train)

# 预测并计算训练集的 RMSE
y_train_pred = model.predict(X_train)
train_rmse_per_target = [np.sqrt(mean_squared_error(y_train.iloc[:, i], y_train_pred[:, i])) 
for i in range(y_train.shape[1])]
train_rmse_scores.append(train_rmse_per_target)

for i, rmse in enumerate(train_rmse_per_target, start=1):
print(f&quot;Fold {fold} - Training Target {i} RMSE: {rmse:.4f}&quot;)

# 预测并计算验证集的 RMSE
y_pred = model.predict(X_test)
val_rmse_per_target = [np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i])) 
for i in range(y_test.shape[1])]
val_rmse_scores.append(val_rmse_per_target)

for i, rmse in enumerate(val_rmse_per_target, start=1):
print(f&quot;Fold {fold} - Validation Target {i} RMSE: {rmse:.4f}&quot;)

# 计算并打印所有折叠的平均 RMSE
avg_train_rmse = np.mean(train_rmse_scores, axis=0)
avg_val_rmse = np.mean(val_rmse_scores, axis=0)

我正在尝试使用 MultiOutputRegressor 训练这 3 个目标列，包装XGBoostRegressor。我的问题是 RMSE 分数对于训练和验证来说都太高了。即使使用 optuna 调整超参数后，效果似乎也不好。我甚至看到验证 RMSE 等于 7000。此时我无法确定我的模型是过度拟合还是欠拟合，因为如果我开始使用基本特征进行训练，我的验证分数会从非常高的验证 RMSE 开始，然后继续下去。我想我在某个时候犯了严重的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78775154/extreme-rmse-validation-score-in-time-series-model</guid>
      <pubDate>Sun, 21 Jul 2024 12:14:40 GMT</pubDate>
    </item>
    <item>
      <title>在多分类中如何进行特征和模型选择以及参数调整？</title>
      <link>https://stackoverflow.com/questions/78775112/how-to-do-feature-and-model-selection-with-the-parameter-tuning-in-multi-class-c</link>
      <description><![CDATA[在此处输入图片描述
我想使用这三个数据，传感器与地面的距离（因为有冰和无冰的地面的距离会有所不同）、湿度和表面温度。
我想使用 SVM 方法，因为我认为数据足够干净，使用神经网络会太多。
我想进行多类分类，预测“干冰环境（创建 O ）”、“干冰环境（创建 X ）”、“湿路”、“干路”......
并使用三个特征：传感器与地面的距离、湿度和表面温度。

我怎样才能制作一个好的预测监督机器学习算法？
我尝试了 SVM 和 NN 方法，两者的准确率都是 1.0，但打印出来的结果却不同，通过搜索我发现这可能是过度拟合。是吗？以及如何修复？
我发现精度召回率 f1 分数和准确率的指标为 1.0，这很奇怪。

我的代码
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classes_report

file_path_blackice = &#39;&#39;
df_blackice = pd.read_excel(file_path_blackice, sheet_name=None, header=0)
sheet_name_blackice = list(df_blackice.keys())[0]
df_blackice_all = df_blackice[sheet_name_blackice]

df_blackice_gen = df_blackice_all.iloc[20:40, :]
df_blackice_gen = df_blackice_gen[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_blackice_gen[&#39;标签&#39;] = &#39;黑冰（已生成）&#39;

df_blackice_notgen = df_blackice_all.drop(df_blackice_gen.index)
df_blackice_notgen = df_blackice_notgen[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_blackice_notgen[&#39;标签&#39;] = &#39;黑冰（未生成）&#39;

file_path_wet_asphalt = &#39;&#39;
df_wet_asphalt = pd.read_excel(file_path_wet_asphalt, sheet_name=None, header=0)
sheet_name_wet_asphalt = list(df_wet_asphalt.keys())[0]
df_wet_asphalt = df_wet_asphalt[sheet_name_wet_asphalt].dropna()[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_wet_asphalt[&#39;标签&#39;] = &#39;湿沥青&#39;

file_path_dry_asphalt = &#39;&#39;
df_dry_asphalt = pd.read_excel(file_path_dry_asphalt, sheet_name=None, header=0)
sheet_name_dry_asphalt = list(df_dry_asphalt.keys())[0]
df_dry_asphalt = df_dry_asphalt[sheet_name_dry_asphalt].dropna()[[&#39;湿度&#39;,&#39;表面温度&#39;,&#39;距离&#39;]]
df_dry_asphalt[&#39;标签&#39;] = &#39;干沥青&#39;

df_blackice_all = df_blackice_all[(df_blackice_all[&#39;距离&#39;] &gt; 0) &amp; (df_blackice_all[&#39;距离&#39;] &lt; 10000)]
df_wet_asphalt = df_wet_asphalt[(df_wet_asphalt[&#39;距离&#39;] &gt; 0) &amp; (df_wet_asphalt[&#39;Distance&#39;] &lt; 10000)]
df_dry_asphalt = df_dry_asphalt[(df_dry_asphalt[&#39;Distance&#39;] &gt; 0) &amp; (df_dry_asphalt[&#39;Distance&#39;] &lt; 10000)]

df = pd.concat([df_blackice_gen, df_blackice_notgen, df_wet_asphalt, df_dry_asphalt])

features = df[[&#39;Humidity&#39;,&#39;SurfaceTemp&#39;,&#39;Distance&#39;]]
labels = df[&#39;Label&#39;]

X = features.to_numpy()
y = labels.to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

svm_model = SVC(kernel=&#39;linear&#39;, C=1.0, random_state=42)
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)
test_acc = accuracy_score(y_test, y_pred)
print(f&quot;测试准确率：{test_acc}&quot;)
print(classification_report(y_test, y_pred, target_names=[&#39;黑冰（已生成）&#39;, &#39;黑冰（未生成）&#39;, &#39;湿沥青&#39;, &#39;干沥青&#39;]))

def predict_surface_condition(svm_model, scaler, new_data):
new_data_scaled = scaler.transform(new_data)
prediction = svm_model.predict(new_data_scaled)
return prediction

new_data = np.array([[63, 15, 20]]) # 地形（地形、地形、地形）
prediction = predict_surface_condition(svm_model, scaler, new_data)
print(f&quot;新数据的预测：{prediction[0]}&quot;)

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, project=&#39;3d&#39;)

ax.scatter(df_blackice_gen[&#39;Humidity&#39;], df_blackice_gen[&#39;SurfaceTemp&#39;], df_blackice_gen[&#39;Distance&#39;], c=&#39;blue&#39;, label=&#39;Black Ice （已生成）&#39;)
ax.scatter(df_blackice_notgen[&#39;湿度&#39;], df_blackice_notgen[&#39;表面温度&#39;], df_blackice_notgen[&#39;距离&#39;], c=&#39;lightblue&#39;, label=&#39;黑冰（未生成）&#39;)
ax.scatter(df_wet_asphalt[&#39;湿度&#39;], df_wet_asphalt[&#39;表面温度&#39;], df_wet_asphalt[&#39;距离&#39;], c=&#39;绿色&#39;, label=&#39;湿沥青&#39;)
ax.scatter(df_dry_asphalt[&#39;湿度&#39;], df_dry_asphalt[&#39;表面温度&#39;], df_dry_asphalt[&#39;距离&#39;], c=&#39;红色&#39;, label=&#39;干沥青&#39;)

ax.set_xlabel(&#39;湿度&#39;)
ax.set_ylabel(&#39;表面温度&#39;)
ax.set_zlabel(&#39;距离&#39;)
ax.set_title(&#39;湿度、表面温度和距离的 3D 散点图&#39;)

ax.legend()

plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78775112/how-to-do-feature-and-model-selection-with-the-parameter-tuning-in-multi-class-c</guid>
      <pubDate>Sun, 21 Jul 2024 11:54:53 GMT</pubDate>
    </item>
    <item>
      <title>是否有用于模糊 iOS 图像中人脸和裸露部分的库？[关闭]</title>
      <link>https://stackoverflow.com/questions/78773917/are-there-libraries-for-blurring-faces-and-nudity-in-images-for-ios</link>
      <description><![CDATA[我正在寻找一个库或 ML 模型，可用于模糊图像中存在的面部和裸体。您对此类库或模型有什么建议吗？
或者您将如何为此目的训练 ML 模型？我对 ML 还很陌生，因此如果我必须创建自己的 ML 模型或库，我将非常感激示例和教程。]]></description>
      <guid>https://stackoverflow.com/questions/78773917/are-there-libraries-for-blurring-faces-and-nudity-in-images-for-ios</guid>
      <pubDate>Sat, 20 Jul 2024 21:07:35 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习方法检测玩具车中的未知缺陷</title>
      <link>https://stackoverflow.com/questions/78773870/detecting-unknown-defects-in-toy-car-using-deep-learning-methods</link>
      <description><![CDATA[我们需要从玩具车图片中判断汽车是否有缺陷。我们没有缺陷汽车的图片，我们无法提前知道这些汽车可能存在哪些缺陷。
我们可以使用各种技巧拍摄数千张完好无损的汽车照片。此外，我们还可以自动拍摄数千/数万张汽车 CAD 图像的快照。
我尝试过的方法：

在传统方法中，我尝试过 OpenCV，但它对所有事物都过于敏感，并且只能应用于以完全相同方式拍摄的两张照片。 :(

Siamese Network 和 Sentence Transformers（余弦相似度等...）也不适合，因为它们对摄影产生的差异很敏感。 :(

Autoencoder 有两种不同的方法：

3.1. 我用基于 CAD 的快照训练了一个自动编码器，然后在真实的有缺陷和无缺陷的图像上对其进行了测试，根据这些重建误差的分布从两个方向切断异常值。这个想法来自这里：https://github.com/sohamk10/Image-reconstruction-and-Anomaly-detection。不是很好解决方案。

3.2. 我用原始照片（大约 10,000 张照片，仅从一个视角拍摄）创建了一个自动编码器模型，其中解码器部分是从 ResNet50 拍摄（并冻结）的，我只训练了编码器部分。我也尝试了其他模型（MobileNetV3、EfficientNet-B3）。结果非常令人满意：它根据重建误差独立于照片环境识别训练过的对象，但它也将那些有轻微缺陷的对象识别为好对象，而它不应该这样做。



YOLO v7：产生与上一点（3.2.）中提到的自动编码器类似的结果。因此，它识别了物体，但不幸的是，它也会识别有缺陷的物体。


如何使用人工智能甚至不使用人工智能来解决这个业余项目问题？
如何修改第 3.2 点中提到的自动编码器。在训练期间提供较低的 loss 和 val_loss 值（目前约为 0.6，但在 MNIST 数据集上为 0.02...）？]]></description>
      <guid>https://stackoverflow.com/questions/78773870/detecting-unknown-defects-in-toy-car-using-deep-learning-methods</guid>
      <pubDate>Sat, 20 Jul 2024 20:36:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么我通过 Mediapipe Model Maker 训练制作的自定义模型会将人检测为我的对象？[关闭]</title>
      <link>https://stackoverflow.com/questions/78773679/why-does-my-custom-model-made-by-training-through-mediapipe-model-maker-detect-p</link>
      <description><![CDATA[我有一个想要检测的软玩具。我使用 Mediapipe Model Maker 对大约 100 张图像进行了训练。结果还不错。该模型大多数时候都能从正面识别我的玩具。但问题是，它似乎认为任何人（人的侧面或正面）都是我的玩具，而且比例很高（比如 &gt;90%）。
我不明白为什么会发生这种情况，我该怎么做才能微调我的模型，让它不把人检测为我的玩具。我已将我的玩具和检测示例的图像附在下面。

]]></description>
      <guid>https://stackoverflow.com/questions/78773679/why-does-my-custom-model-made-by-training-through-mediapipe-model-maker-detect-p</guid>
      <pubDate>Sat, 20 Jul 2024 19:04:20 GMT</pubDate>
    </item>
    <item>
      <title>如何在评估商业项目时实施 NLP 进行文本分析？</title>
      <link>https://stackoverflow.com/questions/78773575/how-to-implement-nlp-for-text-analysis-in-evaluating-business-projects</link>
      <description><![CDATA[我需要根据特定标准评估业务活动（项目）的资格。我们通过采访利益相关者来收集数据，获取项目名称、描述、不确定性和结果等详细信息。然后根据这些叙述评估每个项目的资格。
我正在考虑将数据科学融入该项目的几种方法，并希望得到有关最佳方法的建议。具体来说，我有兴趣实施 NLP 进行文本分析：

如何分析项目描述以确定共同主题和关键术语？

推荐使用哪些工具和库来使用主题建模来发现共同主题和文本分类来对项目进行分类？


我正在考虑的其他方法包括预测建模、聚类分析和情绪分析。如果您对这些方法有任何建议或资源，那也会很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78773575/how-to-implement-nlp-for-text-analysis-in-evaluating-business-projects</guid>
      <pubDate>Sat, 20 Jul 2024 18:23:40 GMT</pubDate>
    </item>
    <item>
      <title>如何将职位名称与职位空缺名称或职位空缺描述相匹配？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78772979/how-to-match-job-title-with-vacancies-name-or-vacancy-descriptions</link>
      <description><![CDATA[如何将 400 个职业与 10,000 个职位空缺进行匹配？我有两个文件：一个文件包含职业名称及其所属部门，第二个文件是来自 hh.kz 的 10,000 个职位空缺，包含职位名称及其描述。我需要将 400 个职业分配到适当的职位空缺，例如，将“高级前端开发人员”与“Web 开发人员”、“UI/UX 设计师”与“Web 设计师”等进行匹配。我已经清理和规范化了数据，使用了词嵌入，但效果不佳。我还能尝试什么？
我尝试使用关键字，但对我来说不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78772979/how-to-match-job-title-with-vacancies-name-or-vacancy-descriptions</guid>
      <pubDate>Sat, 20 Jul 2024 14:06:15 GMT</pubDate>
    </item>
    <item>
      <title>Python机器学习pytorch测试/训练epoch结果问题</title>
      <link>https://stackoverflow.com/questions/77977231/python-machine-learning-pytorch-test-train-epoch-results-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77977231/python-machine-learning-pytorch-test-train-epoch-results-problem</guid>
      <pubDate>Sun, 11 Feb 2024 15:07:50 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将 ML 模型从 R 转换为 ONNX 格式</title>
      <link>https://stackoverflow.com/questions/77522002/is-it-possible-to-transfer-a-ml-model-from-r-into-onnx-format</link>
      <description><![CDATA[我目前正在 R 中训练 ML 模型（具体来说是使用 mlr3 框架 - 如果不行，我也愿意使用其他软件包）。稍后我想将模型应用到生产中，但为此它需要采用 ONNX 格式。我的在线研究并没有找到任何可能的解决方案，可以将任何在 R 中训练的 ML 模型转换为 ONNX 格式。这可能吗？]]></description>
      <guid>https://stackoverflow.com/questions/77522002/is-it-possible-to-transfer-a-ml-model-from-r-into-onnx-format</guid>
      <pubDate>Tue, 21 Nov 2023 10:18:59 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 用于特征选择</title>
      <link>https://stackoverflow.com/questions/62771535/lightgbm-for-feature-selection</link>
      <description><![CDATA[我正在研究二元分类问题，我的训练数据有数百万条记录和约 2000 个变量。我正在运行 lightGBM 进行特征选择，并使用从 lightGBM 中选择的特征来运行神经网络（使用 Keras）模型进行预测。我对所采用的方法有几个问题。

在使用 lightGBM 进行特征选择时，我正在执行超参数调整。这是基于我的理解，即随着超参数的变化，所选特征也会有所不同。我使用“goss”算法和“gain”作为特征重要性类型。我看过几篇文章，其中他们使用 lightGBM 进行特征选择，但我没有看到任何进行超参数调整的文章，他们只是使用默认设置。这是正确的方法吗？
使用 lightGBM 进行特征选择，使用神经网络根据从 lightGBM 中选择的特征构建预测模型可以吗？

非常感谢您的帮助。谢谢]]></description>
      <guid>https://stackoverflow.com/questions/62771535/lightgbm-for-feature-selection</guid>
      <pubDate>Tue, 07 Jul 2020 08:56:03 GMT</pubDate>
    </item>
    </channel>
</rss>