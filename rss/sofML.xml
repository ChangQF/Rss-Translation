<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sat, 22 Feb 2025 12:29:24 GMT</lastBuildDate>
    <item>
      <title>有效的网络验证损失Stagnan不降低，验证精度提高，但Stagnan</title>
      <link>https://stackoverflow.com/questions/79459417/efficientnetb0-validation-loss-stagnan-not-decreases-validation-accuracy-increa</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79459417/efficientnetb0-validation-loss-stagnan-not-decreases-validation-accuracy-increa</guid>
      <pubDate>Sat, 22 Feb 2025 10:14:34 GMT</pubDate>
    </item>
    <item>
      <title>如何设计AI系统来预测Gherkin用户故事的自动测试？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79458762/how-to-design-an-ai-system-to-predict-automated-tests-from-gherkin-user-stories</link>
      <description><![CDATA[我正在构建一个AI驱动系统，以从用户故事中生成自动测试用例。我对AI没有太多知识，所以我需要一些指导
 这是完整的描述： 
来自AI 驱动的用户故事的自动测试的智能预测
 任务：
•分析用户故事并预测测试用例
•过程并归一化测试数据
•探索和使用不同的机器/深度学习模型
•将开发的AI模型集成到HMI中，以预测所需的自动测试
  Technologies 烧瓶，Django，CI/CD（MLOPS），Gherkin，Python，ML/DL，Crisp-DM方法，NLP 
我期待一些指导，并就该项目提供建议，也许是拟议的阶段]]></description>
      <guid>https://stackoverflow.com/questions/79458762/how-to-design-an-ai-system-to-predict-automated-tests-from-gherkin-user-stories</guid>
      <pubDate>Fri, 21 Feb 2025 22:33:13 GMT</pubDate>
    </item>
    <item>
      <title>使用射线调节器进行超参数调整的序列化误差</title>
      <link>https://stackoverflow.com/questions/79457834/serialization-error-using-ray-tuner-for-hyperparameter-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79457834/serialization-error-using-ray-tuner-for-hyperparameter-tuning</guid>
      <pubDate>Fri, 21 Feb 2025 15:18:38 GMT</pubDate>
    </item>
    <item>
      <title>加载CNN模型后的Numpy急切执行问题</title>
      <link>https://stackoverflow.com/questions/79457437/numpy-eager-execution-problem-after-loading-a-cnn-model</link>
      <description><![CDATA[我想保存和加载CNN模型以进一步培训。我已经开发了一个模型，并将其保存为 .h5 文件。首次运行时创建，培训和节省时没有问题。
加载现有 .h5 模型并尝试训练它时，问题存在。以下代码描述了实现和问题。
  import os.path
导入TensorFlow作为TF

＃启用急切的执行
tf.compat.v1.enable_eager_execution（）

...＃删除以供可读性

def train_model（model_name：str，model_handler：tensormodel，Visualiser：Visualiser，logger：logger，x_train，y_train，y_train，x_test，y_test，y_test，batch_size） - ＆gt;元组：
    logger.info（f＆quort启用启用：{tf.executing_eagerly（）};）

    ＃检查模型是否已经受过培训
    如果use_existing_models and os.path..exists（f＆quot; models/{model_name} .h5＆quort;）：
        模型=模型= tf.keras.models.models.load_model（f＆quot; model/{model_name} .h5＆quort;）
        （x_train，y_train），（x_test，y_test）= model_handler.load_data（）
    别的：
        如果model_name ==＆quot; base_model＆quot;：
            model = model_handler.create_cnn（）
        别的：
            model = model_handler.create_cnn（batch_normalisation = true）

    历史= model.fit（x_train，y_train，epochs = num_epochs，batch_size = batch_size，validation_data =（x_test，y_test））
    test_loss，test_acc = model.evaluate（x_test，y_test）
    model.save（f＆quot; model/{model_name} .h5;）
    
    logger.info（f＆quot“模型精度：{test_acc * 100：.2f}％＆quort”）
    Visualiser.plot_training_history（历史记录，model_name）
    返回（model，model_name），（test_acc）
 
以下是产生的错误。
  file＆quot＆quot＆quot＆quod&gt;&#39;
    历史= model.fit（x_train，y_train，epochs = num_epochs，batch_size = batch_size，validation_data =（x_test，y_test））
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^因为^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^因为^^^
  file＆quot＆quot＆quot＆quot＆quotement/machine_learning/machine-learning-real-time-objectification/.venv/lib/python3.12/site-packages/keras/keras/keras/src/src/src/src/utils/traceback_utils.py，1002222 ，在error_handler中
    从无
  file＆quot＆quot＆quot＆quot＆quotevelovermation/machine_learning/machine-learning-real-time-objectification/.venv/lib/python3.12/site-packages/keras/keras/keras/src/backend/backend/backend/tensorflow/core.core.pycore.py&quot;第155行，convert_to_numpy
    返回NP.Array（X）
           ^^^^^^^^^^^^
notimplementedError：numpy（）仅在启用急切执行时可用。
 
日志记录显示急切执行已启用以下内容：
  2025-02-21 13：46：42,505-信息 - 启用：true：true
 
我缺少什么？]]></description>
      <guid>https://stackoverflow.com/questions/79457437/numpy-eager-execution-problem-after-loading-a-cnn-model</guid>
      <pubDate>Fri, 21 Feb 2025 13:00:54 GMT</pubDate>
    </item>
    <item>
      <title>在ML中获取错误格式错误。</title>
      <link>https://stackoverflow.com/questions/79457387/getting-incorrect-format-error-in-ml-neet-forcasting-the-data</link>
      <description><![CDATA[  int预测= 144;
 var datapoints = 480;

列表＆lt; pcidatapoint＆gt; pcidata = dataPoints.Select（x =＆gt; new PcidApoint {value =（float）x}）。tolist（）;
            idataview dataview = mlcontext.data.data.loadfromenumerable（pcidata）;
            
        //定义SSA预测模型
        var pipeline = mlcontext.forecasting.forecastbyssa（
            outputcolumnname：＆quot“ pciforecastedvalues＆quot＆quot＆quot＆quot of tougply starlically设置输出列
            InputColumnName：nameof（pcidatapoint.value），//正确输入列
            Windowsize：预测，// BeackBack窗口大小
            系列节目：datapoints.count，//整个系列长度
            trainsize：datapoints.count，//培训数据大小
            地平线：预测，//预测数量
            Concidencelevel：0.95F，//置信度
            ConcidencelowerBoundColumn：&#39;ConfidencelowerBound＆quot
            CressupupperboundColumn：“ CressialUperpBound”
        ）；

        //训练模型
        var model = pipeline.fit（dataview）;
 
获得错误的格式错误是错误的，在此我的代码中，我的系列长度是480，我的horizo​​n leth是144是正确的方法来提供获取前进值的详细信息]]></description>
      <guid>https://stackoverflow.com/questions/79457387/getting-incorrect-format-error-in-ml-neet-forcasting-the-data</guid>
      <pubDate>Fri, 21 Feb 2025 12:39:40 GMT</pubDate>
    </item>
    <item>
      <title>拟合功能在时期1之后停止</title>
      <link>https://stackoverflow.com/questions/79457237/fit-function-stops-after-epoch-1</link>
      <description><![CDATA[我已经实现了此功能以适合模型
  def fit_model（型号，x_train_sequence_tensor，y_train_sequence_tensor，epochs，val_set，time_windows，sualer）：
    
    x_column_list = [val_set.columns.to_list（）中的项目中的项目，如果不在[&#39;date&#39;，&#39;deres&#39;&#39;&#39;，&#39;rank&#39;，&#39;rank_group&#39;，&#39;counts&#39;，&#39;counts&#39;，&#39;target&#39;]]中
    x_val_set = val_set [x_column_list] .Round（2）
                    
    X_VAL_SET [X_VAL_SET.COLUMNS] = SCALER.TRANSFORM（X_VAL_SET [X_VAL_SET.COLUMNS]）
    x_val_sequence = get_feature_array（x_val_set，x_column_list，time_windows）
    X_VAL_SECONCE_TENSOR = TF.CONVERT_TO_TENSOR（X_VAL_SECERESE，dtype = tf.float32）
    
    y_column_list = [&#39;target&#39;]                
    y_val_set = val_set [y_column_list] .Round（2）
    y_val_sequence = get_feature_array（y_val_set，y_column_list，time_windows）
    y_val_sequence_tensor = tf.convert_to_tensor（y_val_sequence，dtype = tf.float32）

                    
    历史= model.fit（x_train_sequence_tensor，y_train_sequence_tensor，epochs， 
                        验证_data =（x_val_secorence_tensor，y_val_sepence_tensor））
    返回模型，历史记录

 
但是当我称其为时
  fitted_model，history = fit_model（模型，x_train_secorence_tensor，y_train_secorce_tensor， 
                    epochs = 100，val_set = val_set，time_windows = 90，scaleer = scaleer）
 
它在第一个时期后停止。它不能按要求所有100个运行。
我试图在函数调用之外打电话给它。
 `＃步骤3.2：安装模型 +我们通过一些验证
                                                ＃监视验证损失和指标
                                                ＃在每个时代的末尾
                    x_val_set = val_set [x_column_list] .Round（2）
                    
                    ＃x_val_set.values = scaler.transform（x_val_set.values）
                    
                    X_VAL_SET [X_VAL_SET.COLUMNS] = SCALER.TRANSFORM（X_VAL_SET [X_VAL_SET.COLUMNS]）
                    x_val_sequence = get_feature_array（x_val_set，x_column_list，90）
                    X_VAL_SECONCE_TENSOR = TF.CONVERT_TO_TENSOR（X_VAL_SECERESE，dtype = tf.float32）
                    
                    y_val_set = val_set [y_column_list] .Round（2）
                    y_val_sequence = get_feature_array（y_val_set，y_column_list，90）
                    y_val_sequence_tensor = tf.convert_to_tensor（y_val_sequence，dtype = tf.float32）

                    
                    triench_history = cnn1d_bilstm_model.fit（x_train_sequence_tensor，y_train_sequence_tensor，epochs = 200， 
                                                            ＃我们通过一些验证
                                                            ＃监视验证损失和指标
                                                            ＃在每个时代的末尾
                                                            验证_data =（x_val_secorence_tensor，y_val_sepence_tensor））
 
我在做什么错？]]></description>
      <guid>https://stackoverflow.com/questions/79457237/fit-function-stops-after-epoch-1</guid>
      <pubDate>Fri, 21 Feb 2025 11:26:50 GMT</pubDate>
    </item>
    <item>
      <title>我面临的问题是阅读Python中的MT数据[关闭]</title>
      <link>https://stackoverflow.com/questions/79456454/i-am-facing-problem-to-read-mt-data-in-python</link>
      <description><![CDATA[错误是
  parserError                               
Trackback（最近的电话最后一次）
[9]中的单元，第1行
----＆gt; 1 data = pd.read_csv（r＆quot; c：\ users \ rosha \ oneDrive \ desktop \ vbox data \ vbox.csv＆quot;

File ~\anaconda3\Lib\site-packages\pandas\io\parsers\readers.py:912, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace， skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, FoqueChar，引用，双语，EscapeChar，评论，编码，encoding_errors，言语，on_bad_lines，delim_whitespace，low_memory，memory_map，float_map，float_precision，storage_options，storage_options，dtype_backend），dtype_backend）
    899 kwds_defaults = _refine_defaults_read（
    900方言，
    901定界符，
   （...）
    908 dtype_backend = dtype_backend，
    909）
    910 kwds.update（kwds_defaults）
 - ＆gt; 912返回_read（filepath_or_buffer，kwds）

文件〜\ anaconda3 \ lib \ site-packages \ pandas \ io \ parsers \ parsers \ readers.py：583，in _read（filepath_or_buffer，kwds）
    580返回解析器
    582与解析器：
 - ＆gt; 583返回parser.Read（nrows）

file〜 \ anaconda3 \ lib \ site-packages \ pandas \ io \ parsers \ parsers \ readers.py：1704，in textfileReader.read.read（self，nrows）
   1697 nrows = validate_integer（&#39;nrows＆quot; nrows）
   1698尝试：
   1699＃错误：“ parserbase”没有“读”属性。
   1700（
   1701索引，
   1702列，
   1703 col_dict，
 - ＆gt; 1704）= self._engine.Read（＃类型：忽略[attr-defined]
   1705 nrows
   1706）
   1707除例外：
   1708 self.close（）

file〜 \ anaconda3 \ lib \ lib \ site-packages \ pandas \ io \ parsers \ c_parser_wrapper.py：234，在cparserwrapper.read（self，nrows）中
    232尝试：
    233如果self.low_memory：
 - ＆gt; 234块= self._reader.read_low_memory（nrows）
    235＃破坏了大块
    236数据= _concatenate_chunks（块）

文件〜\ anaconda3 \ lib \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：814，in pandas._libs.parsers.parsers.textreader.read_low_memory（）

文件〜\ anaconda3 \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：875，在pandas._libs.parsers.parsers.textreader._read_rows（）

文件〜\ anaconda3 \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：850，在pandas._libs.parsers.parsers.textreader._tokenize_rows（）

文件〜\ anaconda3 \ lib \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：861，in pandas._libs.parsers.parsers.textreader._check_tokenize_tokenize_status（）

file〜 \ anaconda3 \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：2029，in pandas._libs.parsers.raise_parser_parser_error（）

ParserError：错误令牌数据。 C错误：第6行中的预期2个字段，Saw 20
 
如何解决它？]]></description>
      <guid>https://stackoverflow.com/questions/79456454/i-am-facing-problem-to-read-mt-data-in-python</guid>
      <pubDate>Fri, 21 Feb 2025 06:01:03 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow模型训练，列表到Numpy阵列转换不均会改变数据形状</title>
      <link>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</link>
      <description><![CDATA[我正在尝试从MRI图像中预测LSDC。对于每个研究_id，都有多个图像。每个研究_id代表每个患者。我想在5个级别上预测5个条件下的3级严重程度。
我正在尝试使用 sequence 类从TensorFlow创建数据集。这是我的DataGenerator类：
 类CustomDatagenerator（序列）：
    def __init __（self，image_dict，num_img，labels_dict = none，batch_size = 8，image_size =（224，224），shuffle = true）：
       self.image_dict = image_dict
       self.labels_dict = labels_dict
       self.batch_size = batch_size
       self.image_size = image_size
       self.shuffle =洗牌
       self.ids = list（image_dict.keys（））
       self.num_img = num_img
       self.on_epoch_end（）

    def __len __（自我）：
       返回int（np.floor（len（self.ids） / self.batch_size））

    def __getItem __（自我，索引）：
       start = index * self.batch_size
       end = min（（索引 + 1） * self.batch_size，len（self.ids））
       batch_ids = self.ids [start：end]
       batch_images = []
       batch_labels = []

       对于batch_ids中的ID_：
           图像= []

           对于self.image_dict.get（id_，[]）中的image_path：
               dicomdata = pydicom.dcmread（image_path）
               图像= dicomdata.pixel_array
               图像= cv2.resize（图像，self.image_size）
               image = np.expand_dims（图像，axis = -1）
               image = image.astype（&#39;float32&#39;） / np.max（图像）
               图像= np.Repeat（图像，3，轴= -1）
               images.append（图像）

           图像= np.Array（图像）

           如果Len（Images）＆lt; self.num_img：
               pad_amount = self.num_img- len（图像）
               padding = [（0，pad_amount）] + [（0，0）] *（len（images.shape） -  1）
               图像= np.pad（图像，填充，模式=&#39;常数&#39;）

           batch_images.append（图像）

           如果self.labels_dict：
               label = np.array（self.labels_dict.get（id_），dtype = np.float32）
               batch_labels.append（标签）

       batch_images = np.stack（batch_images）
       如果self.labels_dict：
           batch_labels = np.array（batch_labels，dtype = np.float32）
           返回batch_images，batch_labels

       返回batch_images

    def on_epoch_end（self）：
       如果self.shuffle：
           np.random.shuffle（self.ids）
 
我的标签字典如下：
  i，sid在枚举中（train_df [&#39;study_id&#39;]）：
        labels_dict [str（sid）] = []
        对于条件下的骗局：
            如果train_df.loc [i，con] ==&#39;normal_mild&#39;：
                labels_dict [str（sid）]。附加（[1，0，0]）
            elif train_df.loc [i，con] ==&#39;严重&#39;：
                labels_dict [str（sid）]。附加（[0，0，1]）
            别的：
                labels_dict [str（sid）]。附加（[0，1，0]）

       labels_dict [str（sid）] = np.array（labels_dict [str（sid）]，dtype = np.float32）
 
我尝试了多种方法将 labels_dict 转换为numpy数组。但是，要么在训练时显示形状错过错误。或试图查看数据时显示错误。
它显示的错误如下：
  -----＆gt; 1 Model.Fit（train_generator，epochs = 2）＃，step_per_epoch = len（train_generator）// 8）

/USR/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py in Error_handler（*args，** kwargs）
    120＃要获取完整的堆栈跟踪，请致电：
    121＃`keras.config.disable_traceback_filtering（）`
 - ＆gt; 122从无
    123最后：
    124 del filtered_tb

＆lt; ipython-Input-12-Cf42609bddda＆gt;在__getItem __（自我，索引）中
     47 batch_images = np.stack（batch_images）
     48如果self.labels_dict：
---＆gt; 49 batch_labels = np.array（batch_labels，dtype = np.float32）
     50返回batch_images，batch_labels
     51 

ValueError：设置具有序列的数组元素。 1个维度后，请求的阵列具有不均匀的形状。检测到的形状为（8，） +不均匀部分。
 
我尝试使用 np.stack 或 batch_labels = batch_labels.reshape（（（batch_labels.shape.shape.shape [0]），len（presition），3），3））），但它显示不同的错误。我的数据没有任何 nan ，所有 labels_dict 均为Shape （batch_size，num_of_condition，severity_class）。即使我尝试从发电机打印数据。生成器数据形状来自 data_x，data_y = next（iter（train_generator））显示模型输入和输出的数据形状。我无法弄清楚这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</guid>
      <pubDate>Thu, 20 Feb 2025 17:02:54 GMT</pubDate>
    </item>
    <item>
      <title>Qiskit Importerror</title>
      <link>https://stackoverflow.com/questions/79448915/qiskit-importerror</link>
      <description><![CDATA[我试图使用以下内容导入量子级：
 来自qiskit_machine_learning.kernels导入量子kernel
 
但是我遇到了这个错误：
 来自qiskit_machine_learning.kernels导入量子kernel
Importerror：无法从&#39;qiskit_machine_learning.kernels&#39;导入名称&#39;量子kernel&#39; 
（c：\ user \ pshre \ appdata \ local \ program \ python \ python \ python310 \ lib \ site-packages \ qiskit_machine_learning \ kernels \ kernels \ __ init__ init__.py）
 
 qiskit版本：0.8.2 
我已经更新了模块：
  pip安装 - 升级qiskit-machine学习
 ]]></description>
      <guid>https://stackoverflow.com/questions/79448915/qiskit-importerror</guid>
      <pubDate>Tue, 18 Feb 2025 16:05:55 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习和NER自动化网络刮擦，以进行产品数据提取</title>
      <link>https://stackoverflow.com/questions/79426509/automating-web-scraping-with-machine-learning-and-ner-for-product-data-extractio</link>
      <description><![CDATA[我目前正在执行数据＆amp; AI实习。我的工作是通过从制造商的网站中检索信息（产品名称，图像，描述，零件号/SKU，技术规格，数据表等）来构建产品数据库。
挑战是，有300多个不同的制造商，每个制造商都有自己的网站和结构，使传统的网络刮擦不切实际且难以维护。为了克服这一点，我正在考虑使用AI和机器学习，以使我的刮擦剂适应每个页面的HTML结构的更改。
我已经下载并手动标记了50页。这是我的数据集的样子：
 ＃列非零计数dtype 
------------------------------------------- 
 0文本52非挂钩对象
 1个product_name 49非无效对象
 2 HTML_PRODUCT_NAME 51非无效对象
 3 image_url 50非无效对象
 4 html_image_url 50非挂钩对象
 5说明32非无效对象
 6 HTML_DESCRIPTION 51非无效对象
 7 part_number 35非无效对象
 8 HTML_PART_NUMBER 36非无效对象
 9 html_specification 44非无效对象
 10 dataSheet_url 40非无效对象
 11 HTML_DATASHEET_URL 41非无效对象
 12规格2非无效对象 
 
文本列包含产品页面的清洁html，而其他列则代表目标字段 - 需要识别和提取的HTML的特定部分。
这个问题似乎与命名实体识别（NER）非常相似。如何训练机器学习模型以成功地从RAW HTML中提取这些字段？最好的方法是什么（例如，微调变压器模型，序列标签或其他方法）？
预先感谢！]]></description>
      <guid>https://stackoverflow.com/questions/79426509/automating-web-scraping-with-machine-learning-and-ner-for-product-data-extractio</guid>
      <pubDate>Mon, 10 Feb 2025 08:46:11 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek拥抱面模型加载问题</title>
      <link>https://stackoverflow.com/questions/79424312/deepseek-huggingface-model-loading-issue</link>
      <description><![CDATA[我正在使用huggingface的此代码：
此代码直接从 huggingface网站上的页面 是插件代码：
 来自变形金刚导入管道

消息= [
{&#39;&#39;：＆quot“ user quot”内容“：;
这是给出的
pipe = pipeline（＆quort&#39;text-generation＆quort＆quote =&#39;deepSeek-ai/deepseek-r1＆quort; trust_remote_code = true）
管道（消息）
 
，但我无法加载模型。当我这样做时，我会得到这个问题：
  file＆quot＆lt; ...＆gt;/site-packages/transformers/quantizers/auto.py＆quot;，第97行，在from_dict
提高价值Error（

ValueError：未知量化类型，获得FP8-支持类型为： 
[&#39;awq&#39;，&#39;bitsandbytes_4bit&#39;，&#39;bitsandbytes_8bit&#39;，&#39;gptq&#39;，&#39;aqlm&#39;，&#39;quanto&#39;，&#39;eetq&#39;，&#39;eetq&#39;， 
&#39;HQQ&#39;，“压缩张量”，“ fbgemm_fp8&#39;，&#39;torchao&#39;，&#39;bitnet&#39;]
 
我尝试了不同的代码：
 导入火炬
generate_text = pipeline（model =; deepSeek-ai/deepSeek-r1; torch_dtype = torch.bfloat16，trust_remote_code = true，device_map =; auto;
generate_text（消息）
 
这给出以下错误：
raise ValueError( ValueError: Unknown quantization type, got fp8 - supported types are: [&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39; ，&#39;higgs&#39;，&#39;hqq&#39;，&#39;compressed-tensors&#39;，&#39;fbgemm_fp8&#39;， &#39;torchao&#39;，&#39;bitnet&#39;，&#39;vptq&#39;]  
我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/deepseek-huggingface-model-loading-issue</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>训练扩散器/unet2dconditionmodel时形状不匹配</title>
      <link>https://stackoverflow.com/questions/78844279/shapes-mismatch-while-training-diffusers-unet2dconditionmodel</link>
      <description><![CDATA[我正在尝试从头开始训练扩散器/unet2dcongitionmodel。目前，我在UNET转发上有错误：MAT1和MAT2形状无法乘以（288x512和1280x512）。我注意到Mat1第一维（288）可能会根据数据集批处理而有所不同。
如何修复矩阵形状错误？我是否需要用零填充Mat1以使其形状与Mat2：1280x512相同，或者我设置了无效的模型初始参数。我将感谢您的任何帮助。
这是我的培训代码
 导入火炬
来自torch.utils.data导入数据集，dataloader
从火炬导入转换为t
从变形金刚导入夹具，剪贴电台，cliptextmodel，autotokenizer
从扩散器导入autocoderkl，unet2dconditionmodel，ddpmscheduler
导入大熊猫作为pd
从PIL导入图像
导入IO
来自TQDM.Auto Import TQDM

设备= torch.device（cuda; if torch.cuda.is_available（）else&#39;


＃数据集类，返回图像和相应的文本字幕
类Textimgdataset（数据集）：
    def __init __（自我，fp：str）：
        self.df = pd.read_parquet（fp）
        self.transform = t.compose（[[
            t.lambda（lambda img：img.convert（&#39;rgb&#39;）如果img.mode！=&#39;rgb&#39;else img），
            T.Resize（（64，64）），
            t.totensor（），
        ）））

    def __len __（self） - ＆gt; INT：
        返回self.df.Shape [0]

    def __getItem __（self，idx） - ＆gt; （Torch.Tensor，str）：
        行= self.df.iloc [idx]
        img_bytes = io.bytesio（row [&#39;image&#39;] [&#39;bytes&#39;]）
        image = image.open（img_bytes）
        image_tensor = self.transform（图像）
        字幕=行[&#39;text&#39;]

        返回image_tensor，标题


＃初始化模型
clip_model = clipmodel.from_pretaining（&#39;Openai/clip-vit-base-patch32＆quort）。到（设备）
clip_processor = clipprocessor.from_pretrateing（&#39;OpenAi/clip-vit-base-patch32＆quot&#39;）

text_encoder = cliptextmodel.from_pretrated（&#39;OpenAi/clip-vit-base-patch32＆quort&#39;）
tokenizer = autotokenizer.from_pretaining（“ openai/clip-vit-base-patch32”）

vae = autoencoderkl.from_single_file（
    ＆quot&#39;https：//huggingface.co/stocietyai/sd-vae-ft-mse-original/blob/main/main/vae-ft-mse-840000-mse-840000-ema-pruned.safetensors＆quot＆quot＆quot;）
    设备）

unet = unet2dconditionmodel（
    in_channels = 4，
    OUT_CHANNELS = 4，
    layers_per_block = 2，
    sample_size = 64，
    block_out_channels =（128，256，512，512），
    down_block_types =（&#39;downblock2d;
    up_block_types =（ust; attnupblock2d＆quot;
）.to（设备）

noyes_scheduler = ddpmscheduler（num_train_timesteps = 1000，beta_start = 0.0001，beta_end = 0.02，beta_schedule =; linear＆quort;

＃Dataloader
＃我从此处使用数据集
dataset = textimgdataset（fp =&#39;〜/dataset.parquet&#39;）
dataloader = dataloader（数据集，batch_size = 16，shuffle = true）

＃优化器
Optimizer_Vae = Torch.optim.adam（vae.parameters（），lr = 1e-4）
Optimizer_unet = Torch.optim.adam（unet.parameters（），lr = 1e-4）

＃训练循环
num_epochs = 10

unet.train（）

对于范围（num_epochs）的时代：
    对于TQDM（数据加载程序）中的批次：
        图像，字幕=批次
        图像=图像TO（设备）
        lettents = vae.encode（图像）.latent_dist.sample（）
        litents = lettents * vae.config.scaling_factor

        噪声= torch.randn_like（潜伏）
        bsz = litents.shape [0]
        timeSteps = torch.randint（0，noings_scheduler.num_train_timesteps，（bsz，），device = litents.device）.long（）

        inputs = tokenizer（字幕，padding = true，return_tensors =＆quord; pt; quord; truncation = true）
        outputs = text_encoder（**输入）.last_hidden_​​state.to（设备）

        noisy_latents = noings_scheduler.add_noise（潜伏，噪声，时间段）
        #noisy_latents形状：[16，4，8，8]
        #timesteps形状：Torch.Size（[16]）
        #encoder_hidden_​​states形状：torch.size（[16，18，512]）
        pred = unet（sample = noisy_latents，timeStep = timeSteps，encoder_hidden_​​states = outputs，return_dict = false）＃在此处获取错误

        ＃....其余代码（反向传播和采样）

 ]]></description>
      <guid>https://stackoverflow.com/questions/78844279/shapes-mismatch-while-training-diffusers-unet2dconditionmodel</guid>
      <pubDate>Wed, 07 Aug 2024 14:35:26 GMT</pubDate>
    </item>
    <item>
      <title>比较通过转移学习训练的几种不同Yolov8S模型的重量和偏见</title>
      <link>https://stackoverflow.com/questions/76220101/comparing-the-weights-and-biases-of-several-different-yolov8s-models-trained-thr</link>
      <description><![CDATA[我有3种不同的Yolov8s模型，我想评估：

  yolov8s接受了普通模型训练。Train（）命令

  yolo8vs模型，训练有冷冻骨干

  yolov8s模型，训练有所有层冰冻


我正在使用回调功能冻结重量，请参见下文：
  def freeze_layer（训练器）：
    型号= Trainer.Model
    num_freeze = 10
    打印（f＆quot {num_freeze}层；）
    冻结= [f&#39;model。{x}。&#39;&#39;对于x范围（num_freeze）]＃冻结层
    对于k，v in Model.Named_pa​​rameters（）：
        v.requires_grad = true＃火车所有层
        如果有（x中的x in for x in freeze）：
            打印（f&#39;Freezing {k}&#39;）
            v.requires_grad = false
    打印（f＆quot {num_freeze}层被冷冻。＆quot;）

如果__name__ ==＆quot __ Main __＆quot;：
    模型= Yolo（Yolov8s.pt）
    model.add_callback（＆quot; on_train_start＆quort＆quot; freeze_layer）
    模型。
        data =&#39;coco128.yaml＆quort;
        时代= 300，
        IMGSZ = 640
        ）
 
我希望能够评估这三个神经网络之间的权重和偏见的差异。我想看看哪些神经元在转移学习后死亡，并评估所有三个神经网络之间的主要差异。是否有任何标准解决方案可用于获得对神经网络的这种见解？
我已经比较了Yolo提供的标准培训指标，例如地图和损失，一切都是预期的。冻结的层越多，表现较差。当我冻结整个网络时，性能比其他两个实例要差得多。
我几乎不知道在比较同一网络架构时从哪里开始，但训练有不同的训练。
任何帮助都非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/76220101/comparing-the-weights-and-biases-of-several-different-yolov8s-models-trained-thr</guid>
      <pubDate>Wed, 10 May 2023 15:13:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在R中绘制SVM模型的ROC曲线</title>
      <link>https://stackoverflow.com/questions/46844891/how-to-plot-a-roc-curve-for-a-svm-model-in-r</link>
      <description><![CDATA[我已经使用以下代码培训并测试了模型
 库（E1071）
库（readxl）
图书馆（Caret）

class1.svm.model＆lt;  -  svm（class〜。，data = class1.trainset，成本= 20，cross = 10，type =“ c-classification”，kernel =“ radial”，na.Action = na.omit）
class1.svm.pred＆lt;  - 预测（class1.svm.model，class1.testset）
finalmatrix＆lt; -data.matrix（class1.svm.pred，rownames.force = f）

test＆lt; -table（pred = class1.svm.pred，true = class1.testset [，c（15768）]）

混淆（测试）
 
但无法为模型绘制ROC曲线。请用正确的语法帮助我绘制ROC曲线以查看我的测试数据的性能。]]></description>
      <guid>https://stackoverflow.com/questions/46844891/how-to-plot-a-roc-curve-for-a-svm-model-in-r</guid>
      <pubDate>Fri, 20 Oct 2017 08:11:29 GMT</pubDate>
    </item>
    <item>
      <title>r分类树与rpart</title>
      <link>https://stackoverflow.com/questions/31154748/r-classification-tree-with-rpart</link>
      <description><![CDATA[我有一些我想细分的数据。
我的第一个想法是从rpart软件包中的r中的分类树。
我的培训数据包括许多解释变量和一个0-1响应变量，称为“已出售”。响应值“ 1”出现在大约80％的行中。
当我尝试使用 rpart（已出售〜。，triagh_data，method =“ class”）构建树时，r无法创建树。我认为原因是它找不到任何彼此之间有很大差异的段。  经过快速检查数据后，我希望我的树看起来像左节点的售出的85％，右节点将有75％的出售。 
有什么方法可以在此类数据集上创建分类树？]]></description>
      <guid>https://stackoverflow.com/questions/31154748/r-classification-tree-with-rpart</guid>
      <pubDate>Wed, 01 Jul 2015 07:11:40 GMT</pubDate>
    </item>
    </channel>
</rss>