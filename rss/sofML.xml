<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 05 Feb 2024 00:59:18 GMT</lastBuildDate>
    <item>
      <title>RNN 的训练循环在每个 epoch 后返回相同的损失</title>
      <link>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</link>
      <description><![CDATA[我正在尝试借助此存储库从头开始构建 RNN (https: //github.com/nicklashansen/rnn_lstm_from_scratch/tree/master），但每个时期后的训练损失保持不变。训练循环的代码如下：
# 超参数
纪元数 = 1000

# 初始化一个新网络
参数 = init_rnn(hidden_​​size=hidden_​​size, vocab_size=vocab_size)

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 轨迹丢失
训练损失、验证损失 = []、[]

def check_if_params_updated(old_params, new_params):
    # 该函数检查两组参数是否不同
    对于 zip 中的 old_param、new_param(old_params, new_params)：
        如果不是 np.array_equal(old_param, new_param):
            return True # 参数已更新
    return False # 参数尚未更新


# 对于每个纪元
对于范围内的 i（num_epochs）：
    
    # 轨迹丢失
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
     # 对于验证集中的每个句子
    对于输入，val_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，_ =向后传递（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        
        # 更新损失
        epoch_validation_loss += 损失
    
    # 对于训练集中的每个句子
    对于输入，train_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，梯度=backward_pass（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        打印（inputs_one_hot.shape）
        
        如果 np.isnan(损失):
            raise ValueError(&#39;梯度消失/爆炸！&#39;)
        
        # 更新参数
        params = update_parameters(params, grads, lr=1e-3)
        
        # 更新损失
        epoch_training_loss += 损失
        
    # 保存绘图损失
    Training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # 每 100 个 epoch 打印损失
    如果我％100==0：
        print(f&#39;Epoch {i}, 训练损失: {training_loss[-1]}, 验证损失: {validation_loss[-1]}&#39;)


# 获取测试集中的第一个句子
输入，目标 = test_set[1]

# One-hot 编码输入和目标序列
input_one_hot = one_hot_encode_sequence（输入，vocab_size）
target_one_hot = one_hot_encode_sequence（目标，vocab_size）

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 前向传递
输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）
output_sentence = [idx_to_word[np.argmax(output)] 用于输出中的输出]
print(&#39;输入句子：&#39;)
打印（输入）

print(&#39;\n目标序列:&#39;)
打印（目标）

print(&#39;\n预测序列:&#39;)
print([idx_to_word[np.argmax(output)] 用于输出中的输出])

# 绘制训练和验证损失图
纪元 = np.arange(len(training_loss))
plt.figure()
plt.plot(epoch, Training_loss, &#39;r&#39;, label=&#39;训练损失&#39;,)
plt.plot(epoch,validation_loss,&#39;b&#39;,label=&#39;验证损失&#39;)
plt.图例()
plt.xlabel(&#39;Epoch&#39;), plt.ylabel(&#39;NLL&#39;)
plt.show()

我尝试检查我的参数是否正在更新，它们确实更新了，还尝试检查梯度，它们并不是指数小。每次迭代后损失都会减少，但总纪元的损失保持不变。您可以在存储库中找到完整的代码，其中包括前向和后向传递(https://github.com/危险dude237/RNN_From_Scratch）。]]></description>
      <guid>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</guid>
      <pubDate>Mon, 05 Feb 2024 00:28:27 GMT</pubDate>
    </item>
    <item>
      <title>在Mini Batch梯度下降中应用StandardScaler，应用错误</title>
      <link>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</link>
      <description><![CDATA[ValueError：需要 2D 数组，却得到 1D 数组：
数组=[0。 0. 0. ... 0. 0. 1.]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

当我尝试运行代码时，我不断收到此错误：
# 分离特征 (X) 和目标变量 (y)
X = np.array(df[&#39;默认&#39;])
y = np.array(df[&#39;默认&#39;])
l = len(X)

# 将数据分为训练集和测试集

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 添加特征标量器 Z 分数标准化

定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)


# 实现小批量梯度

类 mini_batch_gradient_descent:
    
    def create_batch(self,X_train,y_train,batch_size):
        小批量=[]
        数据=np.stack((X_train,y_train),轴=1)
        np.random.shuffle(数据)
        batches=X_train.shape[0]//batch_size
        对于范围内的 i（批次）：
            mini_batch=数据[i*batch_size:(i+1)*batch_size]
            mini_batches.append((mini_batch[:,0], mini_batch[:,1]))
        如果 X_train.shape[0]/batch_size!=0:
            mini_batch=数据[i*batch_size:]
            mini_batches.append((mini_batch[:, 0], mini_batch[:,1]))
        返回小批量
    
    def fit(self,X_train,y_test,alpha,epochs,batch_size):
        self.m=np.random.randn(1,1)
        self.c=np.random.randn(1,1)
        l=len(X_train)
        对于范围内的 i（纪元）：
            批次= self.create_batch（X_train，y_train，batch_size）
            对于批量批次：
                xb=批次[0]
                yb=批次[1]
                xb=xb.reshape(1, xb.shape[0])
                截距=np.sum((np.dot(self.m,xb)+self.c)-yb)
                斜率=np.sum((np.dot(self.m,xb)+self.c)-yb)
                self.m=self.m-alpha*(斜率/l)
                self.c=self.c-alpha*(斜率/l)
    
    def 斜率截距():
        print(f&quot;斜率为 {self.m[0][0]}&quot;)
        print(f&quot;截距为 {self.c[0][0]}&quot;)
        
    
    def 预测（自我，X_test）：
        X_test=X_test.reshape(X_test.shape[0],1)
        self.m=self.m.reshape(self.m.shape[1],self.m.shape[0])
        结果=np.dot(X_test, self.m)+self.c
        返回结果

我尝试使用 loc/iloc，但它一直收到错误。
我正在使用数据帧，然后转换为 np.array 来运行程序。它可以在没有功能缩放器的情况下工作，但当我尝试实现缩放器时，它开始给我错误。不确定在功能扩展方面我还有什么其他选择。]]></description>
      <guid>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</guid>
      <pubDate>Sun, 04 Feb 2024 23:19:53 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 ADNI 分类器将字符串转换为浮点型</title>
      <link>https://stackoverflow.com/questions/77937811/could-not-convert-string-to-float-w-adni-classifier</link>
      <description><![CDATA[导入 pandas 作为 pd
将 numpy 导入为 np
从张量流导入keras
从tensorflow.keras导入层

# 加载数据
数据 = pd.read_csv(“/content/ADNI1_Complete_3Yr_3T_1_31_2024.csv”)

# 将数据拆分为特征和标签
X = data.drop(“组”, axis=1).values
y = 数据[“组”].值

# 对标签进行编码
从 sklearn.preprocessing 导入 LabelEncoder
编码器 = LabelEncoder()
y = 编码器.fit_transform(y)

# 将数据分为训练集和测试集
从 sklearn.model_selection 导入 train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 标准化数据
X_train = X_train.astype(“float32”) / 255.0
X_test = X_test.astype(“float32”) / 255.0

# 重塑数据以包含通道
X_train = np.expand_dims(X_train, -1)
X_test = np.expand_dims(X_test, -1)

# 定义CNN模型
模型 = keras.Sequential([
    层.Conv2D(32, (3, 3), 激活=“relu”, input_shape=(X_train.shape[1], X_train.shape[2], 1)),
    层.MaxPooling2D((2, 2)),
    层.Conv2D(64, (3, 3), 激活=“relu”),
    层.MaxPooling2D((2, 2)),
    层.Conv2D(128, (3, 3), 激活=“relu”),
    层.MaxPooling2D((2, 2)),
    层.Flatten(),
    层.密集（128，激活=“relu”），
    层.密集（3，激活=“softmax”），
]）

# 编译模型
model.compile(loss=“sparse_categorical_crossentropy”，optimizer=“adam”，metrics=[“accuracy”])
model.fit(X_train, y_train)

此 CNN 输出 ValueError 无法将字符串转换为浮点数：&#39;I120798&#39;。我正在使用 ADNI 数据集。数据归一化部分输出错误。我预计这将开始训练 CNN。我应该在此代码中更改哪些内容才能开始使用数据集训练 CNN。]]></description>
      <guid>https://stackoverflow.com/questions/77937811/could-not-convert-string-to-float-w-adni-classifier</guid>
      <pubDate>Sun, 04 Feb 2024 22:20:09 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch ArrayRef 线性神经网络的无效索引问题</title>
      <link>https://stackoverflow.com/questions/77937339/pytorch-arrayref-invalid-index-problem-with-linear-nn</link>
      <description><![CDATA[我头疼，下面的代码让我晚上睡不着觉：
1 导入火炬
  2 导入torch.nn为nn
  3 导入torch.optim作为optim
  4 将numpy导入为np
  6 个样本 = torch.linspace(0, 100,100) # 生成集合
  7 train_split = int(len(样本)*0.8)
  8 x_train, x_test = 样本[:train_split], 样本[train_split:]
  9 y_labels = 2*samples-4 # 定义函数
 10 y_labels += torch.tensor(np.random.normal(0, 5, len(samples))) # 添加噪声
 13类神经网络（nn.Module）：
 14 def __init__(自我):
 15 超级().__init__()
 16 self.fc1 = nn.Linear(1, 1)
 17 def 向前（自身，x）：
 18 返回 self.fc1(x)
 19 模型 = NeuralNetwork()
 20 loss_func = nn.MSELoss()
 21 优化器 = optim.Adam(model.parameters(), lr=0.001)
 22 num_epochs = 50
 23 代表纪元范围（num_epochs）：
 24 用于输入，zip(x_train, y_labels[:train_split]) 中的标签：
 25
 26 y_pred = model(inputs) # 文件“.../torch/nn/modules/linear.py”，第 116 行，向前
    返回 F.线性(输入, self.weight, self.bias)
运行时错误：ArrayRef：无效索引索引= 18446744073709551615；长度 = 0
 27 损失 = loss_func(y_pred, 标签)
 28 优化器.zero_grad()
 29 损失.backward()
 30 优化器.step()
 31 print(&quot;纪元 %d - 损失: %.4f%&quot; % (纪元, 损失))



这是一个简单的单层事情，而且我做得很直观，所以没有必要称我为傻瓜。
我在几台机器上运行它，没有区别......
附注任何有关进一步改进这些野兽的编写过程的建议将不胜感激！！！]]></description>
      <guid>https://stackoverflow.com/questions/77937339/pytorch-arrayref-invalid-index-problem-with-linear-nn</guid>
      <pubDate>Sun, 04 Feb 2024 19:40:19 GMT</pubDate>
    </item>
    <item>
      <title>不知道如何在此 ML 程序中进行用户输入</title>
      <link>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 r2_score、mean_squared_error

# 加载数据集
dp = pd.read_csv(&#39;https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv&#39;)

# 分离特征（x）和目标变量（y）
y = dp[&#39;logS&#39;]
x = dp.drop(&#39;logS&#39;, 轴=1)

# 分割数据
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)

# 线性回归模型
lr = 线性回归()
lr.fit(x_train, y_train)
y_train_pred_lr = lr.predict(x_train)
y_test_pred_lr = lr.predict(x_test)

# 随机森林回归模型
k1 = RandomForestRegressor（最大深度=2，随机状态=100）
k1.fit(x_train, y_train)
y_train_pred_rf = k1.predict(x_train)
y_test_pred_rf = k1.predict(x_test)

# 评估线性回归模型
y_train_mse_lr =mean_squared_error(y_train, y_train_pred_lr)
y_train_r2_lr = r2_score(y_train, y_train_pred_lr)
y_test_mse_lr = 均方误差(y_test, y_test_pred_lr)
y_test_r2_lr = r2_score(y_test, y_test_pred_lr)

# 评估随机森林回归模型
y_train_mse_rf =mean_squared_error(y_train, y_train_pred_rf)
y_train_r2_rf = r2_score(y_train, y_train_pred_rf)
y_test_mse_rf =mean_squared_error(y_test, y_test_pred_rf)
y_test_r2_rf = r2_score(y_test, y_test_pred_rf)

# 创建数据框
rs_lr = pd.DataFrame({“方法”: [“线性回归”],
                      “训练MSE”：[y_train_mse_lr]，
                      “训练R2”：[y_train_r2_lr]，
                      “测试 MSE”：[y_test_mse_lr]，
                      “测试 R2”：[y_test_r2_lr]})

rs_rf = pd.DataFrame({“方法”: [“随机森林回归器”],
                      “训练MSE”：[y_train_mse_rf]，
                      “训练R2”：[y_train_r2_rf]，
                      “测试 MSE”：[y_test_mse_rf]，
                      “测试 R2”：[y_test_r2_rf]})

# 连接数据帧
结局 = pd.concat([rs_lr, rs_rf],ignore_index=True)
打印（结局）

加载数据集：它使用 Pandas 从 URL 加载数据集。该数据集与分子溶解度相关，包含各种分子描述符。
数据准备：它将特征（x）和目标变量（y）从数据集中分离出来。本例中的目标变量是溶解度的对数 (logS)。
数据拆分：它使用 scikit-learn 中的 train_test_split 函数将数据集拆分为训练集和测试集。训练集用于训练模型，测试集用于评估模型的性能。
模型训练：它使用训练数据训练两个回归模型 - 线性回归模型 (lr) 和随机森林回归模型 (k1)。
预测：它使用经过训练的模型对训练集和测试集进行预测。
模型评估：它使用均方误差 (MSE) 和 R 平方 (R2) 分数评估两个模型的性能。这些指标可以深入了解模型对数据的拟合程度。
创建 DataFrame：它创建两个单独的 DataFrame（rs_lr 和 rs_rf）来存储每个模型的评估指标。
串联：它将两个 DataFrame 连接成一个最终的 DataFrame（结局）。此 DataFrame 总结了两种模型的训练和测试性能。
打印结果：最后，它打印串联的 DataFrame（结局），其中包括线性回归和随机森林回归模型的方法名称、训练 MSE、训练 R2、测试 MSE 和测试 R2。
该程序的目标是比较线性回归和随机森林回归模型在根据描述符预测分子溶解度方面的性能。
我希望用户输入值。那么我该如何修改代码呢？]]></description>
      <guid>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</guid>
      <pubDate>Sun, 04 Feb 2024 18:32:58 GMT</pubDate>
    </item>
    <item>
      <title>在每个点上绘制指向图中线条的箭头</title>
      <link>https://stackoverflow.com/questions/77936741/plot-arrow-on-each-point-towards-the-line-in-graph</link>
      <description><![CDATA[我正在尝试使用 matplotlib 绘制从每个数据点到图表中的线的箭头。

我希望箭头代表每个点和线之间的距离。我怎样才能做到这一点？
这是我的代码：
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np

# 创建一条直线（45度角）
x_line = np.linspace(0, 10, 100)
y_线 = x_线

# 在线周围添加一些随机点
点数 = 20
x_points = np.linspace(2, 8, num_points) # 根据需要调整范围
y_points = x_points + np.random.normal(0, 0.5, num_points) # 添加一些随机性

# 绘制直线
plt.plot(x_line, y_line, label=&#39;Line&#39;, color=&#39;blue&#39;)

# 绘制点
plt.scatter(x_points, y_points, label=&#39;点&#39;, color=&#39;红色&#39;)

# 设置标签和标题
plt.xlabel(&#39;X轴&#39;)
plt.ylabel(&#39;Y轴&#39;)
plt.title(&#39;围绕一条线的散点图&#39;)

# 显示图例
plt.图例()

# 显示绘图
plt.show()

我自己尝试这样做但失败了：

代码：
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np

# 创建一条直线（45度角）
x_line = np.linspace(0, 10, 100)
y_线 = x_线

# 在线周围添加一些随机点
点数 = 20
x_points = np.linspace(2, 8, num_points) # 根据需要调整范围
y_points = x_points + np.random.normal(0, 0.5, num_points) # 添加一些随机性

# 绘制直线
plt.plot(x_line, y_line, label=&#39;Line&#39;, color=&#39;blue&#39;)

# 绘制点
plt.scatter(x_points, y_points, label=&#39;点&#39;, color=&#39;红色&#39;)

# 添加从每个点到直线的箭头
对于 zip(x_points, y_points) 中的 x, y：
    plt.arrow(x, y, 0, y - x, color=&#39;black&#39;, linestyle=&#39;dashed&#39;, linewidth=0.5, head_width=0.2)

# 设置标签和标题
plt.xlabel(&#39;X轴&#39;)
plt.ylabel(&#39;Y轴&#39;)
plt.title(&#39;围绕一条线的散点图&#39;)

# 显示图例
plt.图例()

# 显示绘图
plt.show()

正如您所看到的，数据点发生了移动，箭头指向外侧，而不是向内或指向直线。]]></description>
      <guid>https://stackoverflow.com/questions/77936741/plot-arrow-on-each-point-towards-the-line-in-graph</guid>
      <pubDate>Sun, 04 Feb 2024 17:00:07 GMT</pubDate>
    </item>
    <item>
      <title>更改房间图像中的地板纹理[关闭]</title>
      <link>https://stackoverflow.com/questions/77935330/change-the-floor-texture-in-a-room-image</link>
      <description><![CDATA[我正在尝试创建一个房间可视化工具，用户可以在其中上传他们的房间图像，并可以将不同的纹理应用到地板上。我成功地使用 roboflow 中的地板分割模型提取图像中的地板坐标，并将纹理图像应用到坐标上，现在的问题是纹理在某些图像上看起来很好，但在某些图像上看起来更糟。我知道我做错了什么，任何人都可以建议一种方法来处理分段蒙版上的纹理应用程序。我正在附加我得到的输出图像  
这是我现在实际做的事情的逻辑
 来自 PIL 导入图像
    将 numpy 导入为 np
    将 matplotlib.pyplot 导入为 plt
    从 io 导入 BytesIO
    导入base64
    从 roboflow 导入 Roboflow
    
    rf = Roboflow(api_key=&quot;key&quot;)
    项目 = rf.workspace().project(“名称”)
    模型 = 项目.版本(1).模型
    
    # 推断本地图像
    # print(model.predict(“room3.jpg”).json())
    
    # 加载房间和纹理图像
    room_image_path = &#39;newwww.jpg&#39;
    纹理图像路径 = &#39;tex3.jpg&#39;
    房间图像 = Image.open(房间图像路径)
    纹理图像 = Image.open(纹理图像路径)
    
    # 显示房间图像
    # plt.imshow(房间图像)
    # plt.title(&#39;房间图片&#39;)
    # plt.axis(&#39;关闭&#39;)
    # plt.show()
    
    # 显示纹理图像
    # plt.imshow(纹理图像)
    # plt.title(&#39;纹理图像&#39;)
    # plt.axis(&#39;关闭&#39;)
    # plt.show()
    
    # JSON 数据
    json_data = model.predict(“newwww.jpg”).json()
    
    # 提取楼层坐标
    Floor_data = json_data[&#39;预测&#39;][0]
    Floor_points = Floor_data[&#39;点&#39;]
    
    # 创建点的元组列表
    Floor_coordinates = [(point[&#39;x&#39;], point[&#39;y&#39;]) for Floor_points 中的点]
    
    # 打印提取的楼层坐标
    print(&#39;提取的楼层坐标：&#39;)
    打印（地板坐标）
    
    
    # 根据地板坐标创建遮罩的函数
    从 matplotlib.path 导入路径
    
    def create_mask_from_points(image_size, 点):
        # 创建点网格
        y, x = np.mgrid[:image_size[1], :image_size[0]]
        点 = np.array(点)
        路径=路径（点）
        mask = path.contains_points(np.vstack((x.ravel(), y.ravel())).T)
        mask = mask.reshape((image_size[1], image_size[0]))
        返回掩码
    
    # 为地板创建遮罩
    mask = create_mask_from_points(room_image.size, 地板坐标)
    
    # 将纹理叠加在房间图像上
    # 为简单起见，调整纹理大小以匹配房间图像大小
    调整大小的纹理=纹理图像.调整大小（房间图像.大小）
    
    # 使用遮罩来组合图像
    room_with_texture = np.array(room_image)
    room_with_texture[掩码] = np.array(resized_texture)[掩码]
    
    # 转换回图像
    room_with_texture_image = Image.fromarray(room_with_texture)
    
    # 保存结果
    输出图像路径 = &#39;final2.jpg&#39;
    room_with_texture_image.save（输出图像路径）
    
    # 显示结果
    plt.imshow(room_with_texture_image)
    plt.title(&#39;带有纹理叠加的房间&#39;)
    plt.axis(&#39;关闭&#39;)
    plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/77935330/change-the-floor-texture-in-a-room-image</guid>
      <pubDate>Sun, 04 Feb 2024 10:08:55 GMT</pubDate>
    </item>
    <item>
      <title>WEKA凯姆包</title>
      <link>https://stackoverflow.com/questions/77934889/weka-caim-package</link>
      <description><![CDATA[在网络搜索中找不到任何用于 CAIM 离散化的 WEKA 包。我需要 WEKA v3 的软件包。
在 google 上搜索 WEKA 软件包，但没有找到任何内容，但一些文档 说它存在。
谁能提供 WEKA 的 CAIM 包的工作链接吗？]]></description>
      <guid>https://stackoverflow.com/questions/77934889/weka-caim-package</guid>
      <pubDate>Sun, 04 Feb 2024 07:13:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 M3 Mac 上安装 ML-Agents：Onnx 和 Protobuf 问题</title>
      <link>https://stackoverflow.com/questions/77934861/how-to-install-ml-agents-on-m3-mac-onnx-protobuf-issues</link>
      <description><![CDATA[我正在尝试使用 conda 在我的 M3 Mac 上安装 ML-Agents。我按照网络文档中列出的说明进行操作（https://unity-technologies。 github.io/ml-agents/Installation/），但我遇到了 protobuf 版本的问题。我将其更改为 3.6，但这不适用于 onnx，它似乎需要 4.25。我真的不确定如何解决这个问题，如果有任何帮助，我将不胜感激！
以下是我为实现这一点而运行的命令：

conda create -n mlagents python=3.10.12 &amp;&amp; conda 激活 magents
git clone --branch release_21 https://github.com/Unity-Technologies /ml-agents.git
python -m pip install ./ml-agents-envs（已工作）
python -m pip install ./ml-agents
]]></description>
      <guid>https://stackoverflow.com/questions/77934861/how-to-install-ml-agents-on-m3-mac-onnx-protobuf-issues</guid>
      <pubDate>Sun, 04 Feb 2024 06:53:10 GMT</pubDate>
    </item>
    <item>
      <title>拟合和评估模型需要多少时间？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77907135/how-much-time-is-required-to-fit-and-evaluate-a-model</link>
      <description><![CDATA[我想计算每个模型的时间复杂度（LR，DS，k-NN，SVM 和 ANN）找出与时间相比精度最高的最佳模型。为此，我实现了代码。
start_time = perf_counter()
logModel = LogisticRegression()
logModel.fit(X_train, Y_train)

# 训练数据的准确性
x_train_prediction = logModel.predict(X_train)
训练数据准确度 = 准确度得分（x_train_预测，Y_train）
print(&#39;训练数据的准确性:,&#39;,training_data_accuracy)

# 测试数据的准确性
x_test_prediction = logModel.predict(X_test)
test_data_accuracy = precision_score(x_test_prediction, Y_test)
print(&#39;测试数据的准确率得分：&#39;, test_data_accuracy)
生成_模型_报告（Y_测试，x_测试_预测）
结束时间 = perf_counter()
经过时间 = 结束时间 - 开始时间

print(&quot;经过时间：&quot;, elapsed_time)

在此代码中，我在这里使用elapsed_time来计算所需的时间逻辑回归模型。我的代码可以计算时间吗？]]></description>
      <guid>https://stackoverflow.com/questions/77907135/how-much-time-is-required-to-fit-and-evaluate-a-model</guid>
      <pubDate>Tue, 30 Jan 2024 14:33:04 GMT</pubDate>
    </item>
    <item>
      <title>无法在python中安装lap==0.4.0库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类算法的训练类型与测试误差（评估方差）</title>
      <link>https://stackoverflow.com/questions/70836956/types-of-training-vs-test-error-for-random-forest-classification-algorithm-asse</link>
      <description><![CDATA[如果可能的话，我想确定两个问题（问题以粗体显示）：
我最近了解了（我希望）随机森林分类算法，并尝试使用 Python 上的 sklearn 将其应用于从卫星图像派生的相当大的像素数据集（其特征是不同的波段，并且标签是我自己概述的特定特征，即植被、云等）。然后我想了解模型是否遇到方差问题，因此我想到的第一个想法是比较训练数据和测试数据。
现在这就是我感到困惑的地方 - 我知道有很多不同的帖子：

与袋外 (OOB) 错误相比，应该/不应该使用 CV 错误
按照设计，随机森林分类器的训练误差几乎总是~0（即，将我的模型拟合到训练数据上并使用它来预测同一组训练数据） - 无论如何，情况似乎都是如此树的深度

关于第 2 点，我似乎永远无法比较我的训练误差和测试误差，因为前者总是很低，因此我决定使用 OOB 误差作为整个模型的“代表性”训练误差。然后我意识到 OOB 错误可能是伪测试错误，因为它本质上是在树没有专门学习的点上测试树（在引导树的情况下），因此我默认将 CV 错误作为我的新“代表性”训练错误对于整个模型。
回顾 CV 误差的用法，我最初将其用于超参数调整（例如，最大树深度、树数量、标准类型等），因此我再次怀疑自己是否应该将其用作我的将官方训练错误与我的测试错误进行比较。
更糟糕的是，我很难根据网络上的帖子来验证我认为正确的内容，因为每个答案只回答了一小部分，并且可能相互矛盾，因此任何人都可以帮助我困境在于使用什么作为我的官方训练错误来与我的测试错误进行比较？
我的第二个问题围绕 OOB 错误如何可能是基于引导期间未选择的数据点的伪测试错误。如果这是真的，如果禁用引导，可以公平地说这不成立吗（该算法在技术上仍然是随机森林，因为特征仍然对每棵树进行随机子采样，只是相关性树之间可能更高）？]]></description>
      <guid>https://stackoverflow.com/questions/70836956/types-of-training-vs-test-error-for-random-forest-classification-algorithm-asse</guid>
      <pubDate>Mon, 24 Jan 2022 16:14:46 GMT</pubDate>
    </item>
    <item>
      <title>随机森林算法中的置信度与概率</title>
      <link>https://stackoverflow.com/questions/45810720/confidence-vs-probability-in-random-forest-algorithm</link>
      <description><![CDATA[我一直在尝试使用 scikit-learn 运行随机森林分类器。我想了解概率和置信度之间的区别。假设我们有 5 个类别 A、B、C、D、E 。现在，如果我运行 predict_proba() 并获得 A 类的匹配项，返回的概率是否是 5 个类中 A 类的概率？这意味着如果 A 类的概率为 0.95，那么剩余的 0.05 会为其余类共享？如果是这样的话，我想了解是否有办法获得预测的置信水平，这意味着分类器以 0.95 的概率预测 A 类的置信度有多大？有这样的机制吗？
我想了解这一点的原因是因为假设我输入的分类数据不属于这 5 个类别中的任何一个，我想抛出它不属于这 5 个类别中的任何一个类。我觉得分类器目前会尝试将其放入 5 个类别之一，并且可能会返回很高的概率？即使它对此没有信心？]]></description>
      <guid>https://stackoverflow.com/questions/45810720/confidence-vs-probability-in-random-forest-algorithm</guid>
      <pubDate>Tue, 22 Aug 2017 06:50:28 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 pred_proba 输出四舍五入值</title>
      <link>https://stackoverflow.com/questions/31141133/random-forest-pred-proba-outputs-rounded-off-values</link>
      <description><![CDATA[我在 scikit learn 中使用随机森林进行分类并获取类概率，我使用了 pred_proba 函数。但它输出的概率四舍五入到小数点后第一位
我尝试使用示例虹膜数据集
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df[&#39;is_train&#39;] = np.random.uniform(0, 1, len(df)) &lt;= .75
df[&#39;物种&#39;] = pd.Categorical(iris.target, iris.target_names)
df.head()

训练，测试 = df[df[&#39;is_train&#39;]==True]，df[df[&#39;is_train&#39;]==False]

特征 = df.columns[:4]
clf = 随机森林分类器(n_jobs=2)
y, _ = pd.factorize(train[&#39;物种&#39;])
clf.fit(训练[特征], y)
clf.predict_proba(训练[特征])

输出概率

&lt;前&gt;&lt;代码&gt; [ 1. , 0. , 0. ],
   [ 1. , 0. , 0. ],
   [ 1. , 0. , 0. ],
   [ 1. , 0. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 0.8, 0.2],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],

这是默认输出吗？可以增加小数位数吗？
注意：
找到了解决方案。
默认编号增加树数后，树数=10。树数达到百时，概率的精度提高了。 ]]></description>
      <guid>https://stackoverflow.com/questions/31141133/random-forest-pred-proba-outputs-rounded-off-values</guid>
      <pubDate>Tue, 30 Jun 2015 14:30:47 GMT</pubDate>
    </item>
    <item>
      <title>随机森林：%IncMSE 和 %NodePurity 之间不匹配</title>
      <link>https://stackoverflow.com/questions/16465109/random-forest-mismatch-between-incmse-and-nodepurity</link>
      <description><![CDATA[我在一个相当小的数据集（即 11 个变量的 28 个观测值）上对 100,000 个分类树进行了随机森林分析。
然后我绘制了变量重要性的图
在结果图中，至少有一个重要变量的 %IncMSE 和 IncNodePurity 之间存在严重不匹配。事实上，该变量的重要性在前者中排名第七（即 %IncMSE&lt;0），但在后者中排名第三。
我应该如何解释这种不匹配？
所讨论的变量与在两张图中始终排在第二位的另一个变量显着相关。这可能是一个线索吗？]]></description>
      <guid>https://stackoverflow.com/questions/16465109/random-forest-mismatch-between-incmse-and-nodepurity</guid>
      <pubDate>Thu, 09 May 2013 15:10:33 GMT</pubDate>
    </item>
    </channel>
</rss>