<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Dec 2024 12:36:01 GMT</lastBuildDate>
    <item>
      <title>有没有简单或好的路线图来开始使用 GenAI ？请不要建议视频讲座，它非常耗时 [关闭]</title>
      <link>https://stackoverflow.com/questions/79250738/is-there-any-easy-or-a-good-roadmap-to-get-started-with-genai-please-do-not-su</link>
      <description><![CDATA[想开始使用生成式人工智能，但不知道从哪里开始。我确实看了一些相关视频并询问了我的同事，但他们都告诉我去观看不同类型的视频讲座。但我不想看长时间的视频。]]></description>
      <guid>https://stackoverflow.com/questions/79250738/is-there-any-easy-or-a-good-roadmap-to-get-started-with-genai-please-do-not-su</guid>
      <pubDate>Wed, 04 Dec 2024 10:20:39 GMT</pubDate>
    </item>
    <item>
      <title>Python 错误：rv_generic.interval() 缺少 1 个必需的位置参数：“confidence”</title>
      <link>https://stackoverflow.com/questions/79250549/python-error-rv-generic-interval-missing-1-required-positional-argument-con</link>
      <description><![CDATA[我一直在尝试运行下面的代码来使用 t 分布计算上限和下限置信区间，但它一直在主题中抛出错误。代码片段如下：
def trans_threshold(Day):
Tran_Cnt=Tran_Cnt_DF[[&#39;Sample&#39;,Day]].dropna()
Tran_Cnt=Tran_Cnt.astype({&#39;Sample&#39;:&#39;str&#39;})
Tran_Cnt.dtypes
#通过 IQR 查找 Materiality 中的异常值
X_Tran = Tran_Cnt.drop(&#39;Sample&#39;, axis=1)
Tran_arr1 = X_Tran.values
#查找第一个四分位数
Tran_q1= np.quantile(Tran_arr1, 0.25)
# 查找第三个四分位数
Tran_q3 = np.quantile(Tran_arr1, 0.75)
# 查找 iqr 区域
Tran_iqr = Tran_q3-Tran_q1
# 查找上限和下限异常值
Tran_upper_bound = Tran_q3+(1.5*Tran_iqr)
Tran_lower_bound = Tran_q1-(1.5*Tran_iqr)
# 删除异常值
Tran_arr2 = Tran_arr1[(Tran_arr1 &gt;= Tran_lower_bound) &amp; (Tran_arr1 &lt;= Tran_upper_bound)]
# 使用 t 分布确定实质性限值
Tran_Threshold_mat=st.t.interval(alpha=0.99999999999, df=len(Tran_arr2-1),
loc=np.mean(Tran_arr2),
scale=st.sem(Tran_arr2))
return Tran_Threshold_mat

trn_lim_FullFeed_Mon = trans_threshold(Day) 

-------------------------------------------------------------------------------------------
TypeError Traceback (最近一次调用最后一次)
Cell In[106]，第 19 行
17 Tran_arr2 = Tran_arr1[(Tran_arr1 &gt;= Tran_lower_bound) &amp; (Tran_arr1 &lt;= Tran_upper_bound)]
18 #使用 t 分布计算实质性限值
---&gt; 19 Tran_Threshold_mat=st.t.interval(alpha=0.99999999999, df=len(Tran_arr2-1),
20 loc=np.mean(Tran_arr2),
21 scale=st.sem(Tran_arr2))

TypeError: rv_generic.interval() 缺少 1 个必需的位置参数：&#39;confidence&#39;

问题似乎出在下面的一段特定代码上。但是，我提供了计算置信区间所需的所有参数，包括自由度，但仍然出现此错误。请指出我哪里做错了以及需要做什么。
Tran_Threshold_mat=st.t.interval(alpha=0.999999999999, df=len(Tran_arr2-1),
loc=np.mean(Tran_arr2),
scale=st.sem(Tran_arr2))

---&gt; 19 Tran_Threshold_mat=st.t.interval(alpha=0.99999999999, df=len(Tran_arr2-1),
20 loc=np.mean(Tran_arr2),
21 scale=st.sem(Tran_arr2))

TypeError: rv_generic.interval() 缺少 1 个必需的位置参数：&#39;confidence&#39;

此外，Tran_arr2 列表如下所示：
array([12617., 12000., 1123., 537., 8605., 4365., 11292., 12231.,
7640., 9583., 9257., 13864., 14682., 11744., 10501., 8694.,
5327., 10066., 13022., 11092., 7444., 11658., 14920., 12849.,
14681., 5719., 11029., 3814., 14703., 5593., 9772., 8851.,
9551., 15975., 6532., 13827., 8547.])

因此，直到代码块的最后一行使用 t 分布估计置信区间之前，都没有问题。
我使用了下面的包：
将 pandas 导入为 pd
将 numpy 导入为 np
将 scipy.stats 导入为 st
将 matplotlib.pyplot 导入为 plt
将 matplotlib.ticker 导入为 tkr
将 matplotlib.scale 导入为 mscale
从 matplotlib.ticker 导入 FixedLocator、NullFormatter
pd.options.display.float_format = &#39;{:.0f}&#39;.format
pd.options.mode.chained_assignment = None

请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/79250549/python-error-rv-generic-interval-missing-1-required-positional-argument-con</guid>
      <pubDate>Wed, 04 Dec 2024 09:32:13 GMT</pubDate>
    </item>
    <item>
      <title>为特定任务和具体交付成果实施 AI/ML 任务 [关闭]</title>
      <link>https://stackoverflow.com/questions/79249348/implementing-ai-ml-tasks-for-specific-taskst-and-concrete-deliverables</link>
      <description><![CDATA[我所在的公司正在大力推动人工智能，我已经看到许多空缺职位，包括人工智能/机器学习架构师、具有人工智能/机器学习经验的人等。我想了解更多，但我仍然不确定如何以个人贡献者的身份使用这项新技术。
例如，我目前工作中的一项任务可能是开发 powerbi 仪表板或 SSRS 报告（及其相关的 sql）。另一项任务可能是修复执行时中断的存储过程。更大的用户故事可能是创建一个读取一些 JSON 并将其转储到 sql 表的 Web 服务。这些都是具有具体可交付成果的特定任务（即交付仪表板/报告、成功运行 SP、检查表是否具有解析的 JSON）。
按照这种思路，哪些具体任务会涉及人工智能/机器学习？例如，我如何使用 Amazon Bedrock、SageMaker 或 Azure OpenAI 来完成任务？那么可交付成果是什么？
我粘贴了关于 AI 和 ML 的一般概念，它很有意义，但听起来不像是个人贡献者会做的事情。

AI 是一个通用术语，用于试图模仿人类行为及其智能的领域。任何能够做到这一点的方法或方式都属于 AI。


机器学习是 AI 的一个子集，它通过从数据中学习模式来实现 AI，然后根据这些模式进行预测。
]]></description>
      <guid>https://stackoverflow.com/questions/79249348/implementing-ai-ml-tasks-for-specific-taskst-and-concrete-deliverables</guid>
      <pubDate>Tue, 03 Dec 2024 22:23:50 GMT</pubDate>
    </item>
    <item>
      <title>当我的训练和测试数据大小不同时，如何像使用 sklearn 模型一样使用拟合和预测函数创建神经网络类？</title>
      <link>https://stackoverflow.com/questions/79249247/how-do-i-make-a-neural-network-class-with-fit-and-predict-functions-like-with-sk</link>
      <description><![CDATA[我正在尝试创建一个可以回答线性回归问题的神经网络模型（我已经使用 sklearn 的 LinearRegression 建立了一个模型，我想比较一下这两个模型）。最终，我想创建一个包含 fit 和 predict 函数的类，就像 sklearn 中的模型一样，这样我就可以创建一个循环来测试我在项目中使用的所有模型。
为此，我遵循了此问题答案中的代码：编写一个具有模型拟合和预测功能的 pytorch 神经网络类。
经过一些修改，我得到了以下结果：
import torch
import torch.nn as nn
import torch.optim as optim

class MyNeuralNet(nn.Module):
def __init__(self):
super().__init__()
self.layer1 = nn.Linear(2, 4, bias=True)
self.layer2 = nn.Linear(4, 1, bias=True)
self.loss = nn.MSELoss()
self.compile_()

def forward(self, x):
x = self.layer1(x)
x = self.layer2(x)
return x.squeeze()

def fit(self, x, y):
x = torch.tensor(x.values, dtype=torch.float32)
y = torch.tensor(y.values, dtype=torch.float32)
loss = []
for epoch in range(100):
## 推理
res = self.forward(x)#self(self,x)
loss_value = self.loss(res,y)

## 反向传播
loss_value.backward() # 计算梯度
self.opt.zero_grad() # 刷新前一个 epoch 的梯度
self.opt.step() # 使用上面的梯度执行迭代

## 日志记录
loss.append(loss_value.item())

def compile_(self):
self.opt = optim.SGD(self.parameters(), lr=0.01)

def predict(self, x_test):
self.eval()
y_test_hat = self(x_test)
return y_test_hat.detach().numpy()
# self.train()

注意，您还需要 numpy，我只是没有在这里，因为此代码已放入单独的 .py 文件中。
导入我的类后，这是我使用模型的方式：
model = MyNeuralNet()
X_train = # pandas 数据框，包含 1168 行和 49 列
y_train = # pandas 数据框，包含 1168 行和 1 列
X_test = # pandas 数据框，包含 292 行和 49 列
model.fit(X_train, y_train)
pred = model.predict(X_test)
print(pred)

我得到的错误是 RuntimeError：mat1 和 mat2 形状无法相乘（1168x49 和 2x4），在 fit 步骤。我理解这与我的网络线性层的参数有关。我认为，如果我将第一个线性层的输入大小更改为 49，将第二个线性层的输出大小更改为 1168，那么它将适用于 fit 步骤（或至少类似的步骤，以匹配训练数据的大小）。但是，我的测试数据的大小不同，我很确定 predict 步骤将不起作用。
是否可以创建一个训练和测试数据大小不同的神经网络类？]]></description>
      <guid>https://stackoverflow.com/questions/79249247/how-do-i-make-a-neural-network-class-with-fit-and-predict-functions-like-with-sk</guid>
      <pubDate>Tue, 03 Dec 2024 21:41:10 GMT</pubDate>
    </item>
    <item>
      <title>想要构建一个验证码求解器但不知道如何做？[关闭]</title>
      <link>https://stackoverflow.com/questions/79248824/want-to-built-an-captcha-solver-but-dont-know-how</link>
      <description><![CDATA[我有一个来自我大学网站的 1000 张带标签的 CAPTCHA 图像数据集，我想训练一个模型，该模型可以在未见过的数据上准确解决类似的 CAPTCHA。CAPTCHA 通常由 6 个字母数字字符（A-Z、0-9）组成。尽管尝试了几种方法，但该模型仍无法实现高精度。
数据集：

样本数量：1000 张带标签的图像。
CAPTCHA 类型：6 个字母数字字符。
图像示例：[附加示例 CAPTCHA 图像]。
我尝试过的方法：
卷积神经网络 (CNN)：

我创建了一个具有多个卷积层和密集层的 CNN 模型。
将输出展平，以为每个字符输入单独的密集层。
在未见过的 CAPTCHA 上实现了较差的泛化。
迁移学习：
使用 MobileNetV2 作为带有自定义头的特征提取器。
调整输入大小（灰度到 RGB 转换）。
由于数据有限，该模型容易过度拟合
我想训练一个模型：

可以高精度处理未见过的 CAPTCHA。
有效地解码字母数字字符序列。

解决此类 CAPTCHA 的最佳方法或架构是什么？我应该使用：

CNN 用于特征提取，然后 LSTM 用于序列解码？
完全卷积架构（例如 CRNN）？
对于有限的数据集，还有其他更好的方法吗？

如果可能，您能否建议一个完整的模型架构、预处理步骤或可能有帮助的损失函数设置？对于这项任务，有没有什么技巧可以增强小数据集？]]></description>
      <guid>https://stackoverflow.com/questions/79248824/want-to-built-an-captcha-solver-but-dont-know-how</guid>
      <pubDate>Tue, 03 Dec 2024 18:37:33 GMT</pubDate>
    </item>
    <item>
      <title>溢出 CUDA 内存错误但有可用空间[关闭]</title>
      <link>https://stackoverflow.com/questions/79248530/overflowing-cuda-memory-error-but-have-free-space</link>
      <description><![CDATA[我遇到这个问题已经有一段时间了，当我尝试将嵌入暗度从 64 加倍到 128 或将批处理大小从 1 增加时，我总是收到此错误。这是一个具有 120 万个参数的语言模型。它使用相同数据的 30 万个参数，但如果我使用包含 20 万个样本的较大数据集，它就会崩溃。当前数据集有 4k 个样本。样本是堆叠在一起的 50 种蛋白质序列。如果有人能帮忙，我将不胜感激。
错误代码是：
torch.cuda.OutOfMemoryError：CUDA 内存不足。尝试分配 150.00 MiB（GPU 0；总容量 31.74 GiB；已分配 21.32 GiB；空闲 9.86 GiB；允许 21.58 GiB；PyTorch 总共保留 21.37 GiB）
以下是参数：
nb_blocks=6, embed_dim=128, nb_heads=4, nb_epochs=20, warmup_steps=300, learning_rate=0.0001, check_val_every=1000, batch_size=1
我使用的是 NVIDIA V100 PCIe 32 GB GPU 的集群设置。
Lightning 设置为：
slurm_args = {
&quot;accelerator&quot;: &quot;gpu&quot;,
&quot;devices&quot;: int(os.environ[&quot;SLURM_GPUS_ON_NODE&quot;]),
&quot;num_nodes&quot;: int(os.environ[&quot;SLURM_NNODES&quot;]),
&quot;strategy&quot;: &quot;ddp&quot;,
&quot;precision&quot;: 16,
}

...

accelerator = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
trainer_args = {
&quot;max_epochs&quot;: args.nb_epochs,
&quot;log_every_n_steps&quot;: LOGGING_STEPS,
&quot;val_check_interval&quot;: VAL_CHECK_STEPS,
&quot;logger&quot;: wandb_logger,
&quot;callbacks&quot;: callbacks,
&quot;accelerator&quot;: accelerater,
**slurm_args,
}

我尝试过的方法：

将精度设置为 16（从 32 降低）：将内存溢出从 300MiB 减半到 150MiB（至少取得了一些进展，但没有解决问题问题）
torch.cuda.set_per_process_memory_fraction(0.7)：释放了空间，但该空间未分配用于内存溢出，我无法弄清楚如何分配该备用内存以用于上述问题
手动覆盖分配并将权重、数据和模型移动到 CPU。没有做任何事情，因为几乎所有初始化都已初始化到 CPU。
将 slurm_args 中的 accelerator 设置为 cpu。解决了内存问题，但每次迭代从 1.2 秒增加到 25 秒。换句话说，它太慢了，根本没用
将策略从 ddp 更改为 FSDPStrategy(cpu_offload=True)，但没有任何变化
尝试设置 PYTORCH_CUDA_ALLOC_CONF，但没有任何效果
在参数中使用不同的值设置 accumulate_grad_batches，没有变化
]]></description>
      <guid>https://stackoverflow.com/questions/79248530/overflowing-cuda-memory-error-but-have-free-space</guid>
      <pubDate>Tue, 03 Dec 2024 16:51:36 GMT</pubDate>
    </item>
    <item>
      <title>保留验证集-超参数调整</title>
      <link>https://stackoverflow.com/questions/79247785/holdout-validation-set-hyperparameter-tuning</link>
      <description><![CDATA[我有一个大型数据集，我将其拆分为：

训练集 (80%)
验证集 (10%)
测试集 (10%)

在每个集合上，我执行了缺失值插补和特征选择（在训练集上训练，并复制到验证和测试集中）以避免数据泄露。
现在，我想用 Python 训练 XGBoost 模型，并希望使用训练集执行超参数调整，并使用验证集评估每个参数集。我如何使用 RandomizedSearchCV 等随机方法执行此操作，以便不运行所有参数集？
如果我是正确的，GridSearch 和 RandomizedSearchCV 仅允许交叉验证，这不是我想要的，因为将预处理的训练集拆分成几层会导致数据泄露。
我知道我可以构建一个 sklearn 管道，在其中对每个折叠进行预处理，但我想避免后一种选择。
我只能考虑像在 GridSearch 中一样运行每个参数集的代码：
from sklearn.model_selection import ParameterGrid
import xgboost as xgb

# 定义你的超参数网格
param_grid = {
&#39;max_depth&#39;: [3, 5, 7],
&#39;learning_rate&#39;: [0.01, 0.1, 0.2],
&#39;n_estimators&#39;: [100, 200, 300]
}

best_score = -1
best_params = {}

for params in ParameterGrid(param_grid):
model = xgb.XGBClassifier(**params)
model.fit(X_train, y_train)
val_score = model.score(X_val, y_val) # 或者使用更具体的指标

if val_score &gt; best_score:
best_score = val_score
best_params = params

# 使用最佳超参数训练最终模型
best_model = xgb.XGBClassifier(**best_params)
best_model.fit(X_train, y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/79247785/holdout-validation-set-hyperparameter-tuning</guid>
      <pubDate>Tue, 03 Dec 2024 13:26:56 GMT</pubDate>
    </item>
    <item>
      <title>获取文本分类的 Captum 文本解释时出错</title>
      <link>https://stackoverflow.com/questions/79247672/error-in-getting-captum-text-explanations-for-text-classification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79247672/error-in-getting-captum-text-explanations-for-text-classification</guid>
      <pubDate>Tue, 03 Dec 2024 12:47:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的逻辑回归的准确率只有 25%？</title>
      <link>https://stackoverflow.com/questions/79247069/why-my-logistic-regression-has-25-accuracy</link>
      <description><![CDATA[我正在实现逻辑回归。我知道已经有很多库可以实现它。但问题是我无法理解那些。所以我为它创建了自己的数据集。
它有 3 个东西，房价、标准 和 购买决策
标准 代表生活水平。
0 : 低
1 : 中
2 : 高
当房价非常低时，只有生活水平低（0）的人才会买房。
当房价非常高时，只有生活水平高（2）的人才会买。
这是我做的
# %%
来自 sklearn.datasets 导入 load_breast_cancer
来自 sklearn.linear_model 导入 LogisticRegression
来自 sklearn.model_selection 导入 train_test_split
来自 sklearn.metrics 导入 accuracy_score
导入 pandas
来自 sklearn.preprocessing 导入 StandardScaler

# %%
house_buy = pandas.read_csv(&quot;Datasets/house.csv&quot;)
house_buy

# %%
house_test = pandas.read_csv(&quot;Datasets/house test.csv&quot;)
house_test.head()

# %%
house_independent = house_buy.iloc[:,:-1]
house_dependent = house_buy[&quot;购买预测&quot;]

# %%
column_names = house_independent.columns.tolist()
column_names

# %%
scaler = StandardScaler()
scaled_house_independent = pandas.DataFrame(scaler.fit_transform(house_independent), columns=column_names)
scaled_house_independent.head()

# %%
house_dependent.shape

# %%
house_test_independent = house_test.iloc[:,:2]
house_test_dependent = house_test[&quot;购买预测&quot;]
house_test_independent, house_test_dependent

# %%
# 缩放房屋测试
scaled_house_test_independent = pandas.DataFrame(scaler.transform(house_test_independent), columns=column_names)
scaled_house_test_independent

# %%
house_regression_model = LogisticRegression(random_state=42).fit(scaled_house_independent, house_dependent)

# %%
#Test
house_predicted_dependent = house_regression_model.predict(scaled_house_test_independent)
house_predicted_dependent

# %%
accuracy = accuracy_score(house_test_dependent,house_predicted_dependent)
accuracy

# %%

这是我的数据集和 ipynb 文件实施
测试数据集有 array(1,1,0,0) 作为购买决策，但我的模型给出 array(0,1,1,1)
我知道我的数据集很小，但这一定不是准确率如此低的唯一原因。
我做错了什么？如何执行？]]></description>
      <guid>https://stackoverflow.com/questions/79247069/why-my-logistic-regression-has-25-accuracy</guid>
      <pubDate>Tue, 03 Dec 2024 09:54:08 GMT</pubDate>
    </item>
    <item>
      <title>set_transform 或 with_transform 之后 transformer 的数据集结构出现意外</title>
      <link>https://stackoverflow.com/questions/79241735/unexpected-transformers-dataset-structure-after-set-transform-or-with-transform</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79241735/unexpected-transformers-dataset-structure-after-set-transform-or-with-transform</guid>
      <pubDate>Sun, 01 Dec 2024 14:07:14 GMT</pubDate>
    </item>
    <item>
      <title>尽管有多个 GPU，CUDA 仍出现内存不足错误</title>
      <link>https://stackoverflow.com/questions/78800294/cuda-out-of-memory-error-despite-having-multiple-gpus</link>
      <description><![CDATA[尝试运行 PyTorch 模型时，我遇到了 CUDA 内存不足错误，尽管我的系统有多个 NVIDIA GPU。
# 加载 tokenizer 和模型
tokenizer = AutoTokenizer.from_pretrained(&quot;MODEL_TYPE&quot;)
model = AutoModelForCausalLM.from_pretrained(&quot;MODEL_TYPE&quot;, output_attentions=True, device_map = &#39;auto&#39;, torch_dtype=torch.float16, low_cpu_mem_usage=True)

我有 8 个 GPU，模型分布在所有 GPU 上。但是，由于我的输入是长上下文（大约 20k 个 token）。尽管其他 GPU 中有很多空间，但我还是收到 GPU0 的 CUDA 内存错误。请注意，这是对批处理大小 1 的推断。
OutOfMemoryError：CUDA 内存不足。尝试分配 20.11 GiB。GPU 0 的总容量为 22.17 GiB，其中 16.06 GiB 是空闲的。包括非 PyTorch 内存在内，此进程使用了​​ 6.10 GiB 内存。在分配的内存中，5.57 GiB 由 PyTorch 分配，308.62 MiB 由 PyTorch 保留但未分配。如果保留但未分配的内存很大，请尝试设置 max_split_size_mb 以避免碎片化。请参阅内存管理和 PYTORCH_CUDA_ALLOC_CONF 的文档

inputs = tokenizer(prompt, return_tensors=&quot;pt&quot;)
torch.cuda.empty_cache()
model.generation_config.temperature = temp
model.eval()
with torch.no_grad():
output = model.generate(inputs.input_ids, max_length=25000, output_attentions=False,output_scores=False, return_dict_in_generate=True)
print(&quot;temp:&quot;,model.generation_config.temperature)
tokens = tokenizer.convert_ids_to_tokens(inputs[&#39;input_ids&#39;][0])

response = tokenizer.batch_decode(output[0], skip_special_tokens=False, clean_up_tokenization_spaces=False)[0]

如何有效利用可用的 GPU 进行长上下文输入以避免内存不足错误？
我尝试将输入强制到其他 GPU，但没有成功：
inputs = tokenizer(prompt, return_tensors=&quot;pt&quot;).to(&quot;cuda:1&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78800294/cuda-out-of-memory-error-despite-having-multiple-gpus</guid>
      <pubDate>Sat, 27 Jul 2024 01:14:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么基于 Tensorflow.js 的天气预测模型无法预测正确的天气</title>
      <link>https://stackoverflow.com/questions/78536168/why-tensorflow-js-based-weather-prediction-model-is-unable-to-predict-correct-we</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78536168/why-tensorflow-js-based-weather-prediction-model-is-unable-to-predict-correct-we</guid>
      <pubDate>Sun, 26 May 2024 18:36:09 GMT</pubDate>
    </item>
    <item>
      <title>在 SageMaker 上的 TensorFlow 推荐器中初始化 FactorizedTopK 时出错：“无法将‘计数器’转换为形状”</title>
      <link>https://stackoverflow.com/questions/78144515/error-initializing-factorizedtopk-in-tensorflow-recommenders-on-sagemaker-cann</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78144515/error-initializing-factorizedtopk-in-tensorflow-recommenders-on-sagemaker-cann</guid>
      <pubDate>Tue, 12 Mar 2024 03:28:18 GMT</pubDate>
    </item>
    <item>
      <title>将 Pandas 数据框列转换为浮点数的问题</title>
      <link>https://stackoverflow.com/questions/65834947/problem-with-converting-a-pandas-dataframe-column-into-a-float</link>
      <description><![CDATA[我正在尝试构建一个名人相似程序，使用 VggFace 和 IMDb 名人脸部数据库，我计算数据库中每个脸部的嵌入，并将其存储在 pandas 数据框中。但是，当我尝试加载该嵌入后使用它来计算余弦距离时，我无法使其工作，显然它以字符串内的列表形式存储（即“[ 1.3 -1 .... ] ）等”。所以我有几个问题：

我如何才能看到这些向量的实际存储方式？当我使用 Excel 查看数据时，它似乎没问题。

我如何将此字符串转换为浮点数列表；我尝试使用 ast，但没有成功。


我的代码太长了，所以我不知道是否应该将数据框上传到网上，以便你们查看。
这是使用 df.to_dict() 的一行：
518 : &#39;[ 3.8515975 0.4580283 1.964929 ... -6.336113 1.31456 4.2759323]&#39;
我正在尝试使用此代码遍历数据框并将每行与用户面部的嵌入表示相乘：
vect = calculVecteur(&#39;imagesUtilisateur/test.jpg&#39;,model)
vect = list(map(float, vect))
meta_data_imdb = pd.read_csv(&quot;resources/vectorisation/imdb_metadata_v.csv&quot;)
meta_data_imdb[&#39;distance&#39;] = meta_data_imdb[&#39;vecteur&#39;].apply(lambda x: calculerDistance(x,vect))

calculVecteur()
使用 Vgg 模型计算用户图像的嵌入，然后我使用 calculerDistance()
方法计算余弦距离。
使用调试器，我得到的结果如下：https://i.sstatic.net/Olh76.jpg]]></description>
      <guid>https://stackoverflow.com/questions/65834947/problem-with-converting-a-pandas-dataframe-column-into-a-float</guid>
      <pubDate>Thu, 21 Jan 2021 20:02:35 GMT</pubDate>
    </item>
    <item>
      <title>在 pytorch 中初始化模型时出现问题</title>
      <link>https://stackoverflow.com/questions/62849789/problems-initializing-model-in-pytorch</link>
      <description><![CDATA[我无法在 pytorch 中初始化我的模型并获取：
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-82-9bfee30a439d&gt; 在 &lt;module&gt;() 中
288 dataset = News_Dataset(true_path=args.true_news_file, 
fake_path=args.fake_news_file, 
289 embeddings_path=args.embeddings_file)
--&gt; 290 分类器 = News_classifier_resnet_based().cuda()
291 尝试：
292 分类器.load_state_dict(torch.load(args.model_state_file))

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in 
__call__(self, *input, **kwargs)
548 结果 = self._slow_forward(*input, **kwargs)
549 其他：
--&gt; 550 result = self.forward(*input, **kwargs)
551 for hook in self._forward_hooks.values():
552 hook_result = hook(self, input, result)

TypeError: forward() 缺少 1 个必需的位置参数：&#39;input&#39;

这是我的代码：
class News_classifier_resnet_based(torch.nn.Module):
def __init__(self):
super().__init__()

self.activation = torch.nn.ReLU6()
self.sigmoid = torch.nn.Sigmoid()

self.positional_encodings = PositionalEncoder()

self.resnet = list(torch.hub.load(&#39;pytorch/vision:v0.6.0&#39;, &#39;resnet18&#39;, pretrained=True).children())

self.to_appropriate_shape = torch.nn.Conv2d(in_channels=1, out_channels=1, kernel_size=77)

self.conv1 = torch.nn.Conv2d(in_channels=1,out_channels=64,kernel_size=7,stride=2,padding=3)
self.conv1.weight = torch.nn.Parameter(self.resnet[0].weight[:,0,:,:].data)
self.center = torch.nn.Sequential(*self.resnet[1:-2])
self.conv2 = torch.nn.Conv2d(in_channels=512, out_channels=1, kernel_size=1)
self.conv3 = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=7)

self.title_conv = torch.nn.Sequential(
torch.nn.Conv2d(输入通道=1，输出通道=1，内核大小=3，步幅=3),
self.activation(),
torch.nn.Conv2d(输入通道=1，输出通道=1，内核大小=2，步幅=2),
self.activation(),
torch.nn.Conv2d(输入通道=1，输出通道=1，内核大小=2，步幅=2)
)
self.title_lin = torch.nn.Linear(25,1)

self.year_lin = torch.nn.Linear(10,1)
self.month_lin = torch.nn.Linear(12,1)
self.day_lin = torch.nn.Linear(31,1)
self.date_lin = torch.nn.Linear(3,1)

self.final_lin = torch.nn.Linear(3,1)

def forward(self,x_in):
#输入形状 - (batch_size, 3+title_len+seq_len, embedding_dim)
#输出形状 - (batch_size, 1)
year = x_in[:,0,:10]
month = x_in[:,1,:12]
day = x_in[:,2,:31]

title = x_in[:,3:3+args.title_len,:]
text = x_in[:,3+args.title_len:,:]
title = self.positional_encodings(title)
text = self.positional_encodings(text)

text = text.unsqueeze(1)
text = self.activation(self.to_appropriate_shape(text))
text = self.activation(self.conv1(text))
text = self.activation(self.center(text))
text = self.activation(self.conv2(text))
text = self.activation(self.conv3(text))
text = text.reshape(args.batch_size,-1)

title = title.unsqueeze(1)
title = self.activation(self.title_conv(title))
title = title.reshape(args.batch_size,-1)
title = self.activation(self.title_lin(title))

year = self.activation(self.year_lin(year))
month = self.activation(self.month_lin(month))
day = self.activation(self.day_lin(day))
date = torch.cat([year,month,day], dim=-1)
date = self.activation(self.date_lin(date))

final = torch.cat([date,title,text], dim=-1)
final = self.sigmoid(self.final_lin(final))

return final

classifier = News_classifier_resnet_based().cuda()

我该怎么办？我正在尝试使用词嵌入对文本进行分类，但问题出在最后一行。我正在使用 google colab。此外，当我在其他代码块中创建一些模型时，我没有遇到任何问题。]]></description>
      <guid>https://stackoverflow.com/questions/62849789/problems-initializing-model-in-pytorch</guid>
      <pubDate>Sat, 11 Jul 2020 13:29:05 GMT</pubDate>
    </item>
    </channel>
</rss>