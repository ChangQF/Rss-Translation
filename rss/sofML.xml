<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 19 Jul 2024 09:15:50 GMT</lastBuildDate>
    <item>
      <title>XGBoost 分类器，网格搜索</title>
      <link>https://stackoverflow.com/questions/78768511/xgboost-classifier-grid-search</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78768511/xgboost-classifier-grid-search</guid>
      <pubDate>Fri, 19 Jul 2024 09:07:04 GMT</pubDate>
    </item>
    <item>
      <title>如何了解 sklean 序数编码器完成的映射</title>
      <link>https://stackoverflow.com/questions/78768207/how-to-get-to-know-the-mappings-done-by-skleatn-ordinal-encoder</link>
      <description><![CDATA[我使用 sklearn 对数据集的两列进行了序数编码
我想知道哪一列映射到哪一列
假设 0 映射到两列的什么位置
我想知道语法，试过询问 gpt 但没有用]]></description>
      <guid>https://stackoverflow.com/questions/78768207/how-to-get-to-know-the-mappings-done-by-skleatn-ordinal-encoder</guid>
      <pubDate>Fri, 19 Jul 2024 08:02:11 GMT</pubDate>
    </item>
    <item>
      <title>从 TMT（螺纹铣刀测试）报告中提取文本</title>
      <link>https://stackoverflow.com/questions/78767922/extracting-text-from-an-tmt-thread-mill-test-report</link>
      <description><![CDATA[我有一项任务，需要从表格的 TMT PNG 图像中提取特定值。根据所需的输出，我需要从表格单元格中提取特定值或从图像中的报告中提取一些文本。
您能否建议现有的机器学习模型和任何能够从图像中的特定位置提取文本、数字或特殊符号并将其输出到 Excel 文件中的库？此外，请将过程分解为分步任务以实现所需的输出。
目前我已经开始研究库
pytesseract opencv-python-headless pandas pillow openpyxl
!sudo apt-get install tesseract-ocr
我需要知道是否有任何方法可以探索，我应该学习什么来实现新方法并解决这个问题，请向我解释，以便我可以对此进行研究]]></description>
      <guid>https://stackoverflow.com/questions/78767922/extracting-text-from-an-tmt-thread-mill-test-report</guid>
      <pubDate>Fri, 19 Jul 2024 06:53:53 GMT</pubDate>
    </item>
    <item>
      <title>如何减少 AWS SageMaker 上实时机器学习模型部署的延迟？[关闭]</title>
      <link>https://stackoverflow.com/questions/78767578/how-to-reduce-latency-in-real-time-machine-learning-model-deployment-on-aws-sage</link>
      <description><![CDATA[我在 AWS SageMaker 上部署的实时 ML 模型中遇到了严重的延迟。我尝试了各种实例类型、简化的预处理和模型优化，但延迟仍然存在。
我优化了实例、简化了预处理并精简了模型。预计延迟会降低，但仍然很高。]]></description>
      <guid>https://stackoverflow.com/questions/78767578/how-to-reduce-latency-in-real-time-machine-learning-model-deployment-on-aws-sage</guid>
      <pubDate>Fri, 19 Jul 2024 04:56:43 GMT</pubDate>
    </item>
    <item>
      <title>如何注释 VQA 数据集？</title>
      <link>https://stackoverflow.com/questions/78767391/how-to-annotate-vqa-dataset</link>
      <description><![CDATA[找不到好用的标注平台或软件？大家是怎么解决这个问题的？又是如何整理数据集的JSON的？
我用过label me和label studio，效果都不太好，没能像我预期的那样高效地标注。]]></description>
      <guid>https://stackoverflow.com/questions/78767391/how-to-annotate-vqa-dataset</guid>
      <pubDate>Fri, 19 Jul 2024 03:15:00 GMT</pubDate>
    </item>
    <item>
      <title>尽管数据类型为数字且形状正确，KNNImputer 仍会删除列</title>
      <link>https://stackoverflow.com/questions/78767192/knnimputer-drops-columns-despite-of-numeric-datatypes-and-right-shape</link>
      <description><![CDATA[我正在使用 KNNImputer 在几个 pd.DataFrame 中估算 np.nan 值。我检查了每个数据框的所有数据类型都是数字。但是，KNNImputer 在某些数据框中删除了一些列：
&gt;&gt;&gt;input_df.shape 
(816, 216) 

&gt;&gt;&gt; input_df.dtypes.value_count()
float64 216
dtype: int64

&gt;&gt;output_df.shape 
(816, 27)

我使用了以下 KNNImputer 配置
imputer = KNNImputer(n_neighbors=1, 
weights=&quot;uniform&quot;,
add_indicator=False)

output_df = imputer.fit_transform(input_df)

我想知道为什么会发生这种情况，因为每个数据框都有 np.nan 值。顺便说一句，参数 n_neighbors=1 不应该对结果产生任何影响，因为我正在用最近邻居的值替换缺失值。]]></description>
      <guid>https://stackoverflow.com/questions/78767192/knnimputer-drops-columns-despite-of-numeric-datatypes-and-right-shape</guid>
      <pubDate>Fri, 19 Jul 2024 01:17:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Intel Iris 在训练 Yolov8 模型方面表现优于 RTX 3050 笔记本电脑 GPU [关闭]</title>
      <link>https://stackoverflow.com/questions/78766852/why-the-intel-iris-performs-better-than-rtx-3050-laptop-gpu-in-training-a-yolov8</link>
      <description><![CDATA[我有一台戴尔 G-15 游戏笔记本电脑，配备 Core i5 12500h 和 Rtx 3050。我是深度学习和人工智能的新手。我正在使用 Yolo v8 训练一个模型，用于自动车牌检测，其自定义数据集包含 28k 张图像。
当我尝试训练模型时，我遇到了一个奇怪的问题。当我使用我的 集成 GPU 时，训练速度非常快，大约 5-6it/s，但当我切换到 Rtx 3050 时，性能下降到 3-4it/s。我在 Tensorflow 中也遇到了这个问题。




我不明白为什么集成 GPU 更快。专用 GPU 不是应该更快吗？
此外，当使用专用 GPU 时，其使用率为 100%，但当使用集成 GPU 时，其使用率仅为 30-40%。为什么？
我对这种行为一无所知。我的所有驱动程序都是最新的。


]]></description>
      <guid>https://stackoverflow.com/questions/78766852/why-the-intel-iris-performs-better-than-rtx-3050-laptop-gpu-in-training-a-yolov8</guid>
      <pubDate>Thu, 18 Jul 2024 22:10:21 GMT</pubDate>
    </item>
    <item>
      <title>训练帮助混合模型，该模型集成了上下文和数值特征以解决分类问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78766812/training-help-hybrid-based-model-that-integrates-contextual-and-numerical-featur</link>
      <description><![CDATA[我想要一个关键的生产风险分析问题。因此，根据记录，我想将每条记录的风险等级从 0 到 5。训练集相当不平衡。
&gt; &quot;0.0 964 
&gt; 1.0 393 
&gt; 2.0 396
&gt; 3.0 286 
&gt; 4.0 109 
&gt; 5.0 44&quot;

现在，当前训练集如下所示：
 2 风险等级 float64
3 a_weights int64 
4 b_weights float64
5 c_weights float64
6 d_weights float64
7 e_weights float64
8 f_weights float64
9 g_weights float64
10 FinalDesc 对象 

FinalDesc 列包含一个字符串（工作单的描述）。
例如：
“HVAC 更换工具因恶劣环境而无法使用。请小心修理”
我在 Final Desc 中也有关键词的权重，这将有助于排名。
但是，现在的问题是，我的主管给了我工厂特定的背景信息，这可能有助于预测。例如：
&quot;
消防监视记录被认为风险较低，
高压灭菌器上的阀门 4/5 或由于库存水平较高而通常风险较低。
用于审查 PM 详细信息的 REL 记录不会带来直接风险。
&quot;
还有更多背景信息。进行这些排名的最佳方法是什么？我应该利用 LLM 的力量吗？请让我知道整合背景的最佳方法。
我目前的方法是：

矢量化描述并添加到数据框
使用随机 Forrest 分类器对工作订单进行排名（训练、预测）。同时使用数值和描述

它的准确率为 66%。我想添加更复杂的 AI/ML 功能来解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/78766812/training-help-hybrid-based-model-that-integrates-contextual-and-numerical-featur</guid>
      <pubDate>Thu, 18 Jul 2024 21:51:38 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：在 dim 1 处预期长度为 129 的序列（得到 46）</title>
      <link>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</guid>
      <pubDate>Thu, 18 Jul 2024 18:40:37 GMT</pubDate>
    </item>
    <item>
      <title>在模型训练中，处理 Web 应用程序上的错误输入数据时遇到困难</title>
      <link>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</guid>
      <pubDate>Thu, 18 Jul 2024 09:48:16 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的分割</title>
      <link>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</link>
      <description><![CDATA[即使将单个特征输入模型，神经网络是否也能从细分中受益？
目前我的模型具有基于用户交互和时间的特征。
如果我们根据这些特征输入一些客户细分，我的模型是否会受益？]]></description>
      <guid>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</guid>
      <pubDate>Thu, 18 Jul 2024 04:04:29 GMT</pubDate>
    </item>
    <item>
      <title>自定义参数激活函数导致 NaN 损失和权重</title>
      <link>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</guid>
      <pubDate>Wed, 17 Jul 2024 20:02:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAN 进行欺诈检测</title>
      <link>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</link>
      <description><![CDATA[我正在使用 GAN 实现基于交易的欺诈检测模型，但我仍然想指定我的模型，即我想强调 RIB 和交易时间（尤其是发行时间）我想知道个人通过这些变量（时间和 RIB）的行为如何影响交易是否是欺诈性的。基本上，这个模型很好，但它仍然很肤浅，我们需要通过强调提到的变量来更深入地研究。
我的数据集的头部
就像我说的，我尝试了一个通用的 GAN 模型，但我想实现一个专注于 RIB 和发行时间的指定 GAN 模型]]></description>
      <guid>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</guid>
      <pubDate>Wed, 17 Jul 2024 19:15:59 GMT</pubDate>
    </item>
    <item>
      <title>karateclub MUSAE 嵌入产生奇怪的列数</title>
      <link>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</link>
      <description><![CDATA[我正在试验属性节点嵌入和结构嵌入，但 karateclub 实现返回的矩阵具有奇怪的列数。
MUSAE 给出 128 个“特征”，而不是请求的 32 个。当我请求 32 个时，GLEE 给出了 33 个。我遗漏了什么吗？
import random
import numpy as np
import networkx as nx
from scipy.sparse import coo_matrix

from karateclub.node_embedding.attributed import MUSAE
from karateclub.node_embedding.neighbourhood import GLEE

g = nx.newman_watts_strogatz_graph(50, 10, 0.2)

X = {i: random.sample(range(150),50) for i in range(50)}

row = np.array([k for k, v in X.items() for val in v])
col = np.array([val for k, v in X.items() for val in v])
data = np.ones(50*50)
shape = (50, 150)

X = coo_matrix((data, (row, col)), shape=shape)

model = MUSAE(dimensions=32)
model.fit(g, X)
emb = model.get_embedding()
print(emb.shape)

model = GLEE(dimensions=32)
model.fit(g)
emb = model.get_embedding()
print(emb.shape)

输出：
(50, 128)
(50, 33)
]]></description>
      <guid>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</guid>
      <pubDate>Fri, 14 Jun 2024 15:02:08 GMT</pubDate>
    </item>
    <item>
      <title>在谷歌云平台中运行 jupyter lab 时出现错误 524</title>
      <link>https://stackoverflow.com/questions/68862621/getting-error-524-while-running-jupyter-lab-in-google-cloud-platform</link>
      <description><![CDATA[我无法访问在 Google Cloud 上创建的 jupyter lab

我使用 Google AI 平台创建了一个笔记本。我能够启动它并工作，但它突然停止了，我现在无法启动它。我尝试构建并重新启动 jupyterlab，但毫无用处。我也检查了我的磁盘使用情况，只有 12%。
我尝试了诊断工具，结果如下：

但没有修复。
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/68862621/getting-error-524-while-running-jupyter-lab-in-google-cloud-platform</guid>
      <pubDate>Fri, 20 Aug 2021 12:57:57 GMT</pubDate>
    </item>
    </channel>
</rss>