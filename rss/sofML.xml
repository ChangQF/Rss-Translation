<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Mar 2024 18:16:34 GMT</lastBuildDate>
    <item>
      <title>源代码显示的不同输出（机器学习）（Python）</title>
      <link>https://stackoverflow.com/questions/78207935/different-output-showing-from-a-source-code-machine-learning-python</link>
      <description><![CDATA[我目前正在尝试开展一个小型图像机器学习项目。我找到了这个人的 Kaggle 代码，并尝试从头开始复制它。然而，即使在主要部分，我也已经遇到了错误。
我确信我的结局一定存在本地化问题，但我不知道是什么。
我的代码：
#导入库

#数据处理模块
将 pandas 导入为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
导入CV2
#文件目录模块
将 glob 导入为 gb
导入操作系统
#训练和测试（机器学习）模块
将张量流导入为 tf
导入keras

#将图像导入到代码中

trainDataset = &#39;melanoma_cancer_dataset/train&#39;
testDataset = &#39;melanoma_cancer_dataset/test&#39;
预测数据集 = &#39;melanoma_cancer_dataset/skinTest&#39;

#为要处理的图像创建空列表
训练列表 = []
测试列表 = []
#为良性和恶性这两个键制作一个分类字典
#用于插入图像
词典 = {&#39;良性&#39;: 0, &#39;恶性&#39;: 1}

#读取文件夹的长度内容
对于 os.listdir(trainDataset) 中的文件夹：
    数据 = gb.glob(路径名=str(trainDataset + 文件夹 + &#39;/*.jpg&#39;))
    print(f&#39;{len(data)} 在文件夹 {fold}&#39;)
    #读取图像，按照统一的顺序调整它们的大小，并将它们存储在空列表中
    对于数据中的数据：
        图像 = cv2.imread(数据)
        imageList = cv2.resize(图像(120,120))
        Training_List.append(列表(imageList))

笔记本的输出显示该文件夹中存储了 0 个图像/内容。现在我有点怀疑这里发生了什么，并且希望得到一些答案。提前致谢。我也在使用自己的 VScode。
这是我的文件的屏幕截图：
]]></description>
      <guid>https://stackoverflow.com/questions/78207935/different-output-showing-from-a-source-code-machine-learning-python</guid>
      <pubDate>Fri, 22 Mar 2024 17:27:51 GMT</pubDate>
    </item>
    <item>
      <title>Text2sql NLP：如何实现与用户的交互界面以进行自然输入并获取模型生成的输出</title>
      <link>https://stackoverflow.com/questions/78207916/text2sql-nlp-how-to-implement-an-interactive-interface-with-the-user-for-natura</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78207916/text2sql-nlp-how-to-implement-an-interactive-interface-with-the-user-for-natura</guid>
      <pubDate>Fri, 22 Mar 2024 17:23:36 GMT</pubDate>
    </item>
    <item>
      <title>我使用 sklearn 和 xgboost 训练了一个模型，现在我想将其转换为 tflite 文件，我该怎么做？我在colab中进行了编码</title>
      <link>https://stackoverflow.com/questions/78207843/i-trained-a-model-using-sklearn-and-xgboost-and-now-i-want-to-convert-it-as-a-tf</link>
      <description><![CDATA[我想使用firebase将其集成到react-native应用程序中，我可以直接将tflite文件添加到firebase。我训练的模型不是tensorflow模型，但我使用sklearn库来使用xgboost。
如果可能的话，我期待相同的过程和代码。]]></description>
      <guid>https://stackoverflow.com/questions/78207843/i-trained-a-model-using-sklearn-and-xgboost-and-now-i-want-to-convert-it-as-a-tf</guid>
      <pubDate>Fri, 22 Mar 2024 17:10:01 GMT</pubDate>
    </item>
    <item>
      <title>尝试在 Web 应用程序中运行数字分类器以捕获绘图板中的图像时出现问题</title>
      <link>https://stackoverflow.com/questions/78207771/problem-in-trying-to-run-a-digit-classifier-in-a-webapp-that-captures-image-in-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78207771/problem-in-trying-to-run-a-digit-classifier-in-a-webapp-that-captures-image-in-a</guid>
      <pubDate>Fri, 22 Mar 2024 16:57:34 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮助我创建一个给定主题的项目：“从 FIR 数据集预测适用的 IPC 部分”[关闭]</title>
      <link>https://stackoverflow.com/questions/78207528/can-someone-help-to-me-create-a-project-on-given-topic-predicting-applicable</link>
      <description><![CDATA[在这个项目中，我们放置了 FIR 报告，然后它将显示哪些 IPC 部分适用于它
实际上我不知道从哪里开始，我没有任何想法，所以请帮助我，我必须尽快在大学提交这个项目。]]></description>
      <guid>https://stackoverflow.com/questions/78207528/can-someone-help-to-me-create-a-project-on-given-topic-predicting-applicable</guid>
      <pubDate>Fri, 22 Mar 2024 16:14:07 GMT</pubDate>
    </item>
    <item>
      <title>Python：运行保存的 SVM 模型时出错：ValueError：X 有 2943 个功能，但 SVC 期望 330320 个功能作为输入</title>
      <link>https://stackoverflow.com/questions/78207432/python-error-while-running-saved-svm-model-valueerror-x-has-2943-features-bu</link>
      <description><![CDATA[我使用 Sickit-learn 创建了一个 SVM 模型：
导入 pandas 作为 pd
df = pd.read_csv(r&quot;C:\Users\aaa\Documents\bbb\svm_.csv&quot;, 编码=&#39;latin1&#39;, sep=&#39;;&#39;)

从 imblearn.over_sampling 导入 RandomOverSampler
过采样器 = RandomOverSampler(sampling_strategy=&#39;auto&#39;, random_state=42)

X_resampled, y_resampled = oversampler.fit_resample(df.drop(columns=[&#39;alvo&#39;]), df[&#39;alvo&#39;])

df_resampled = pd.concat([X_resampled, pd.DataFrame({&#39;alvo&#39;: y_resampled})], axis=1)

打印（df_重采样）

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.svm 导入 SVC
从sklearn.metrics导入accuracy_score，classification_report
从 sklearn.preprocessing 导入 OneHotEncoder

X = df_resampled.drop(columns=[&#39;alvo&#39;])
y = df_resampled[&#39;alvo&#39;]

编码器 = OneHotEncoder()
X_encoded = 编码器.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=2)

svm_classifier = SVC(kernel=&#39;poly&#39;, random_state=42)

svm_classifier.fit(X_train, y_train)

y_pred = svm_classifier.predict(X_test)

准确度=准确度_得分(y_test, y_pred)
分类报告结果 = 分类报告(y_test, y_pred)

print(f&quot;准确度: {accuracy}&quot;)
print(&quot;分类报告：\n&quot;,classification_report_result)

进口泡菜

model_file_path = “C:\\Users\\aaa\\Documents\\bbb\\svm_modelo_sent_simnao2.pkl”

打开（model_file_path，&#39;wb&#39;）作为f：
    pickle.dump(svm_classifier, f)

print(&quot;模型保存成功！&quot;)




支持向量机的简单实现来预测分类变量是正确的，工作得很好。
但是，当加载模型并运行以下代码时：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 OneHotEncoder
导入作业库

model_file_path = &quot;C:\\Users\\AAA\\Documents\\BBB\\svm_modelo_sent_simnao.pkl&quot;
svm_classifier = joblib.load(model_file_path)

new_df = pd.read_csv(r&quot;C:\Users\AAA\Documents\BBB\svm_simnao_rodar.csv&quot;, 编码=&#39;latin1&#39;, sep=&#39;;&#39;)

X_new = new_df.drop(columns=[&#39;alvo&#39;, &#39;ID_ASSUNTO&#39;], axis=1) # 删除 &#39;alvo&#39; 和 &#39;ID_ASSUNTO&#39; 列

categorical_columns = [&#39;UF&#39;, &#39;TIPO_ACAO&#39;, &#39;AREA_JURIDICA&#39;, &#39;VARA_CAMARA&#39;, &#39;CLIENTE_NOME&#39;] # 分类列列表
编码器= OneHotEncoder（类别=&#39;自动&#39;，稀疏=假）
X_new_encoded = 编码器.fit_transform(X_new[categorical_columns])

X_new_processed = pd.concat([pd.DataFrame(X_new_encoded), X_new.drop(columns=categorical_columns)], axis=1)

y_pred_new = svm_classifier.predict(X_new_processed)

new_df[&#39;alvo&#39;] = y_pred_new

预测 = new_df[[&#39;ID_ASSUNTO&#39;, &#39;alvo&#39;]]

打印（预测）

什么会导致以下错误：
ValueError Traceback（最近一次调用最后一次）
 在
22 号
23 # 进行预测
---&gt; 24 y_pred_new = svm_classifier.predict(X_new_processed)
25
26 # 将预测（&#39;alvo&#39;）添加到新数据
~\AppData\Roaming\Python\Python39\site-packages\sklearn\svm_base.py 在预测(self, X)
第818章
第819章：
--&gt;第820章
第821章
第822章
~\AppData\Roaming\Python\Python39\site-packages\sklearn\svm_base.py 在预测(self, X)
第431章 预测值。
第432章
--&gt;第433章
第434章
[第 435 章]
~\AppData\Roaming\Python\Python39\site-packages\sklearn\svm_base.py validate_for_predict(self, X)
611
...
--&gt;第389章
[第 390 章]
[第 391 章] 第 391 章
ValueError：X 有 2943 个特征，但 SVC 期望输入 330320 个特征。
我在部署代码中用来预测 alvo 的数据与我训练模型的数据具有完全相同的结构，并且我在训练和部署代码中都使用 OneHotEncoding...所以我有点迷失了一个。
知道如何解决这个问题吗？
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78207432/python-error-while-running-saved-svm-model-valueerror-x-has-2943-features-bu</guid>
      <pubDate>Fri, 22 Mar 2024 15:57:18 GMT</pubDate>
    </item>
    <item>
      <title>用于API结构转换的AI/ML模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78207358/ai-ml-model-for-api-structure-conversion</link>
      <description><![CDATA[是否有一个 AI 模型可以将不同 API 的响应转换为单一 JSON 格式？
所有 API 响应都有不同的结构。我正在寻找一种将响应转换为通用格式的模型。所有API都与数据集相关。
我正在尝试将不同的结构化 API 响应转换为单一格式，以便更容易使用。目前我创建了一个程序来做到这一点，但它需要针对不同的 API 进行少量的手动工作。]]></description>
      <guid>https://stackoverflow.com/questions/78207358/ai-ml-model-for-api-structure-conversion</guid>
      <pubDate>Fri, 22 Mar 2024 15:43:09 GMT</pubDate>
    </item>
    <item>
      <title>Azure ML Studio Web 服务始终返回相同的预测</title>
      <link>https://stackoverflow.com/questions/78207131/azure-ml-studio-web-service-always-returns-the-same-prediction</link>
      <description><![CDATA[我目前正在为我的课程开发一个小型项目，但遇到了障碍，希望能得到一些帮助。在 Azure 机器学习工作室中训练 SVM 模型并将其部署为 Web 服务后，我遇到了一个特殊问题 - 无论输入数据如何，该服务都会返回相同的预测。
这里有人遇到过类似的问题或者对可能出现的问题有什么建议吗？我已无计可施，任何建议或见解将不胜感激！
预先感谢您的帮助！
https://gallery.cortanaintelligence.com/Experiment/Binary-Classifier -SVM-Web
https://gallery.cortanaintelligence.com/Experiment/Binary-Classifiers-SVM
这是我到目前为止所做的事情：
确保所有预处理步骤与模型训练阶段使用的步骤相同（包括数据标准化和缺失值处理）。
仔细检查模型是否使用输入数据进行评分。
验证了 Web 服务的配置，特别是在构建响应时以确保不返回静态值。
确保输入数据的格式与预期模式匹配。
该模型在 ML Studio 环境中表现良好，并根据测试数据进行准确预测。但是，部署的 Web 服务似乎没有反映此行为并输出恒定值。]]></description>
      <guid>https://stackoverflow.com/questions/78207131/azure-ml-studio-web-service-always-returns-the-same-prediction</guid>
      <pubDate>Fri, 22 Mar 2024 15:06:25 GMT</pubDate>
    </item>
    <item>
      <title>对于用于训练的完全相同的数据，张量流预测较低</title>
      <link>https://stackoverflow.com/questions/78206996/tensorflow-prediction-is-low-for-the-exact-same-data-thats-been-used-for-traini</link>
      <description><![CDATA[张量流2.16.1
为了检测静音（小噪音），我使用多个波形文件训练了张量流模型。
所有波形文件均为单声道、16kHz、PCM16 格式。
MFCC 是使用 python_speech_features 包每 0.1 秒的数据计算一次。
mfcc_feat = np.mean(mfcc(block, # 1600 个浮点数的数组，可存储 0.1 秒的数据
                         16000,
                         数量=20，
                         温伦=160/16000,
                         胜步=160/16000,
                         nfilt=20),
                         轴=0）

最终数组 X 的形状为 (1500, 20)，并且使用以下方法定义、编译和训练模型
# 定义并编译模型
模型 = models.Sequential([
    Layers.Input(shape=(20,)), # 输入形状是 20(mfcc) 个浮点数的一维数组
    层.Dense(128, 激活=&#39;relu&#39;),
    层数.密集(20),
    层.Dense(X.shape[0], 激活=&#39;softmax&#39;)
]）

# 编译模型
model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;sparse_categorical_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

# 训练模型
model.fit(X, y, epochs=10, verbose=0)


第一个图是测试声音文件，最后一个词的发音。
接下来的两个是使用阈值0.8的预测结果，它们是不同的。
用于训练的文件之一是从测试文件本身中提取的。
第二个图中的一个小块和第三个图中开头的两个小块与测试文件 (silence_test2) 中的相同，但预测值仍然较低 (&lt;0.1, 0.4, 0.7)。我可以想到三种可能性：

mfcc 计算不正确
模型定义不正确
训练时需要更多数据

原因是什么以及如何改进预测？除此之外，一般欢迎提出建议。]]></description>
      <guid>https://stackoverflow.com/questions/78206996/tensorflow-prediction-is-low-for-the-exact-same-data-thats-been-used-for-traini</guid>
      <pubDate>Fri, 22 Mar 2024 14:44:06 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn：训练期间的 ValueError 特征形状与验证期间的特征形状不同</title>
      <link>https://stackoverflow.com/questions/78206595/sklearn-valueerror-feature-shape-during-training-is-different-than-feature-sha</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78206595/sklearn-valueerror-feature-shape-during-training-is-different-than-feature-sha</guid>
      <pubDate>Fri, 22 Mar 2024 13:33:48 GMT</pubDate>
    </item>
    <item>
      <title>在另存为 PNG 之前隐藏 htmlwidget 图的元素</title>
      <link>https://stackoverflow.com/questions/78206448/hide-elements-of-htmlwidget-plot-before-saving-as-png</link>
      <description><![CDATA[我一直在 R 中使用一个名为“aweSOM”的库。它是一个基于为自组织地图 (SOM) 提供 HTML 交互式视觉效果的库。
aweSOM 比类似的 SOM 包产生更好的视觉效果，所以我会使用它。然而，问题有两个：

HTML 交互式视觉效果不适合发布。
当我另存为 PNG 时，图像上仍保留有（交互式）文本
PNG“将鼠标悬停在绘图上以获取信息。”

因此，我想知道是否可以编写一个函数，将“绘图”保存为 PNG，但没有上面的交互式文本？
因此，有效地编写一个函数，仅保存特定大小的正方形，从而省略文本？
非常感谢您的反馈和帮助。
install.packages(“aweSOM”)
图书馆（aweSOM）

full.data &lt;- iris
train.data &lt;- full.data[, c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, &quot;Petal.Length&quot;, &quot;Petal.Width&quot;)]
train.data &lt;- 规模(train.data)

设置.种子(1465)
init &lt;- somInit(train.data, 4, 4)
iris.som &lt;- kohonen::som(train.data, grid = kohonen::somgrid(4, 4, “六边形”),
                         rlen = 100, 阿尔法 = c(0.05, 0.01), 半径 = c(2.65,-2.65),
                         dist.fcts = “sumofsquares”, init = init)

superclust_pam &lt;- cluster::pam(iris.som$codes[[1]], 3)
superclasses_pam &lt;- superclust_pam$聚类

###########
#带有互动文本的问题情节
##########

情节&lt; - aweSOMplot（som = iris.som，类型=“云”，数据= full.data，
           变量= c(“种类”,“萼片.长度”,“萼片.宽度”,
                         “花瓣长度”、“花瓣宽度”)、
           超类 = superclasses_pam)


所有有关修复可视化的帮助将不胜感激。这里有一个小插曲：
https://cran .r-project.org/web/packages/aweSOM/vignettes/aweSOM.html#the-awesom-package
]]></description>
      <guid>https://stackoverflow.com/questions/78206448/hide-elements-of-htmlwidget-plot-before-saving-as-png</guid>
      <pubDate>Fri, 22 Mar 2024 13:05:59 GMT</pubDate>
    </item>
    <item>
      <title>Walker 2D Pybullet 环境</title>
      <link>https://stackoverflow.com/questions/78205900/walker-2d-pybullet-environment</link>
      <description><![CDATA[我正在尝试通过实现 SAC 算法来解决 Walker2DBulletEnv-v0 问题。在前 700 集左右，机器人保持平衡，返回约 600 分。这些结果是有希望的吗？我应该继续运行该程序以改善网络，还是应该尝试调整超参数。此外，如果这些结果没有希望，那么哪些结果被认为是“好的”；]]></description>
      <guid>https://stackoverflow.com/questions/78205900/walker-2d-pybullet-environment</guid>
      <pubDate>Fri, 22 Mar 2024 11:27:38 GMT</pubDate>
    </item>
    <item>
      <title>给定标签集之外的短 2-3 个标记文本或用户搜索查询的序列标签 [关闭]</title>
      <link>https://stackoverflow.com/questions/78204207/sequence-labelling-for-short-2-3-token-text-or-user-search-queries-out-of-given</link>
      <description><![CDATA[我正在使用FLAIR模块解决序列标签问题。
我有包含 3 种不同类型实体的虚拟电子商务数据，每个实体都有大约 1K 个子实体。训练数据（大小约为 200K）是通过 3K 标签的组合综合创建的。
我尝试使用查询分类模型（带有 3K 标签）验证 FLAIR 序列标签。 FLAIR 模型（F1-score：60%）严重低于分类模型（F1-score：80%） &gt;).
我不愿意开发序列标签模块，因为我希望序列标签器也能够检测并提出新实体。
你能帮我了解哪里可能出错以及我可以尝试哪些其他模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/78204207/sequence-labelling-for-short-2-3-token-text-or-user-search-queries-out-of-given</guid>
      <pubDate>Fri, 22 Mar 2024 05:30:33 GMT</pubDate>
    </item>
    <item>
      <title>在 llm_chain input_variables 中找不到 StuffDocumentsChain document_variable_name 上下文的验证错误：['input'] (type=value_error)</title>
      <link>https://stackoverflow.com/questions/78199098/validation-error-for-stuffdocumentschain-document-variable-name-context-was-not</link>
      <description><![CDATA[我正在尝试根据路由使用不同的rags在langchain中创建路由链，每个rags都有不同的提示模板，这是我的代码：
period_template = &quot;&quot;&quot;AAAText
多曼达：
{输入}“””


ref_template = &quot;&quot;&quot;BBBtext.
多曼达：
{输入}“””

list_template = &quot;&quot;&quot;CCCText.
多曼达：
{输入}“””

提示信息 = [
    {
        “名称”：“期间”，
        “描述”：“AAA”，
        “提示模板”：期间模板
    },
    {
        “名称”：“参考”，
        “描述”：“BBB”，
        “提示模板”：参考模板
    },
    {
        “名称”：“历史”，
        “描述”：“CCC”，
        “提示模板”：列表模板
    }
]

目的地链 = {}
对于提示信息中的 p_info：
    PROMPT = PromptTemplate(template=p_info[“prompt_template”], input_variables=[“input”])
    链 = RetrievalQA.from_chain_type(
        聊天模型，
        检索器=db.as_retriever(),
        return_source_documents=真，
        chain_type_kwargs={“提示”: 提示}
    ）
    destination_chains[p_info[“名称”]] = 链

我收到错误：
&lt;块引用&gt;
ValidationError：StuffDocumentsChain 出现 1 个验证错误
root document_variable_name 上下文在 llm_chain input_variables 中找不到：[&#39;input&#39;] (type=value_error)

出了什么问题，如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78199098/validation-error-for-stuffdocumentschain-document-variable-name-context-was-not</guid>
      <pubDate>Thu, 21 Mar 2024 10:16:24 GMT</pubDate>
    </item>
    <item>
      <title>运行 XGBoost 时不使用 GPU</title>
      <link>https://stackoverflow.com/questions/76827589/gpu-not-used-when-running-xgboost</link>
      <description><![CDATA[我在 ML 世界中还是个新手，对于使用 XGBoost 模型完成的项目，我尝试使用 GPU 进行 GridSearch 和参数调整。不幸的是，我感觉我的 GPU 没有被使用，因为显示的有关每次折叠运行时间的信息在 CPU 上约为 0,1 秒，使用“gpu_hist”参数时约为 0,9 秒。
我安装了 CUDA 工具包，所以这不是问题。
这是传递“gpu_hist”树方法参数时发生的情况：
gpu_hist
如果没有它，就会发生以下情况：
无 GPU 参数
您知道如何让 GPU 工作吗？
此问题是否是由于我的 CPU 中的集成显卡造成的？
我在使用 jupyter Notebook 和 pycharm 时遇到同样的问题。
我的CPU：AMD Ryzen 9 7900x
我的 GPU：Nvidia GeForce RTX 3070
提前谢谢您！
我尝试运行 pytorch 命令
导入火炬
use_cuda = torch.cuda.is_available()

如果使用_cuda：
    print(&#39;__CUDNN 版本:&#39;, torch.backends.cudnn.version())
    print(&#39;__CUDA 设备数量:&#39;, torch.cuda.device_count())
    print(&#39;__CUDA 设备名称:&#39;,torch.cuda.get_device_name(0))
    print(&#39;__CUDA 设备总内存 [GB]:&#39;,torch.cuda.get_device_properties(0).total_memory/1e9)

看看我的 GPU 是否被识别，但一切似乎都正常，因为我得到：
__CUDNN 版本：8700
__CUDA 设备数量：1
__CUDA 设备名称：NVIDIA GeForce RTX 3070
__CUDA 设备总内存 [GB]：8.589410304]]></description>
      <guid>https://stackoverflow.com/questions/76827589/gpu-not-used-when-running-xgboost</guid>
      <pubDate>Thu, 03 Aug 2023 11:19:41 GMT</pubDate>
    </item>
    </channel>
</rss>