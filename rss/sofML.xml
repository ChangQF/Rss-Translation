<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Dec 2024 15:19:11 GMT</lastBuildDate>
    <item>
      <title>保留验证集 - 超参数调整 - RandomizedSearchCV - XGBoost</title>
      <link>https://stackoverflow.com/questions/79247785/holdout-validation-set-hyperparameter-tuning-randomizedsearchcv-xgboost</link>
      <description><![CDATA[我有一个大型数据集，我将其拆分为：

训练集 (80%)
验证集 (10%)
测试集 (10%)

在每个集合上，我执行了缺失值插补和特征选择（在训练集上训练，并复制到验证和测试集中）以避免数据泄露。
现在，我想用 Python 训练 XGBoost 模型，并希望使用训练集执行超参数调整，并使用验证集评估每个参数集。我如何使用 RandomizedSearchCV 等随机方法执行此操作，以便不运行所有参数集？
如果我是正确的，GridSearch 和 RandomizedSearchCV 仅允许交叉验证，这不是我想要的，因为将预处理的训练集拆分成几层会导致数据泄露。
我知道我可以构建一个 sklearn 管道，在其中对每个折叠进行预处理，但我想避免后一种选择。
我只能考虑像在 GridSearch 中一样运行每个参数集的代码：
from sklearn.model_selection import ParameterGrid
import xgboost as xgb

# 定义你的超参数网格
param_grid = {
&#39;max_depth&#39;: [3, 5, 7],
&#39;learning_rate&#39;: [0.01, 0.1, 0.2],
&#39;n_estimators&#39;: [100, 200, 300]
}

best_score = -1
best_params = {}

for params in ParameterGrid(param_grid):
model = xgb.XGBClassifier(**params)
model.fit(X_train, y_train)
val_score = model.score(X_val, y_val) # 或者使用更具体的指标

if val_score &gt; best_score:
best_score = val_score
best_params = params

# 使用最佳超参数训练最终模型
best_model = xgb.XGBClassifier(**best_params)
best_model.fit(X_train, y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/79247785/holdout-validation-set-hyperparameter-tuning-randomizedsearchcv-xgboost</guid>
      <pubDate>Tue, 03 Dec 2024 13:26:56 GMT</pubDate>
    </item>
    <item>
      <title>获取文本分类的 Captum 文本解释时出错</title>
      <link>https://stackoverflow.com/questions/79247672/error-in-getting-captum-text-explanations-for-text-classification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79247672/error-in-getting-captum-text-explanations-for-text-classification</guid>
      <pubDate>Tue, 03 Dec 2024 12:47:45 GMT</pubDate>
    </item>
    <item>
      <title>Python 版本 3.8.2，迁移至 Python 版本 3.11.9。（PKL 文件兼容性问题）</title>
      <link>https://stackoverflow.com/questions/79247110/python-version-3-8-2-migrate-it-to-python-version-3-11-9-pkl-file-compatiblity</link>
      <description><![CDATA[我有一个使用 Python 版本 3.8.2 训练的 PKL 文件，但现在我需要将其迁移到 Python 版本 3.11.9。但是，当我在升级后的环境中执行它时，它会抛出一个错误，而在旧环境中它可以正常工作。
错误是：
TypeError：code() 参数 13 必须是 str，而不是 int

这是模型的路径：
在 python 3.8.2 中训练的所有模型中都出现类似的问题。
我已经尝试过 pickle 和 cloudpickle，
使用 subprocess 从 Python 3.11 环境执行 Python 3.8 脚本，但这不是永久的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/79247110/python-version-3-8-2-migrate-it-to-python-version-3-11-9-pkl-file-compatiblity</guid>
      <pubDate>Tue, 03 Dec 2024 10:03:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的逻辑回归的准确率只有 25%？</title>
      <link>https://stackoverflow.com/questions/79247069/why-my-logistic-regression-has-25-accuracy</link>
      <description><![CDATA[我正在实现逻辑回归。我知道已经有很多数据库可以实现它。但问题是我无法理解那些。所以我为它创建了自己的数据集。
它有 3 个东西，房价、标准 和 购买决策
标准 代表生活水平。
0 : 低
1 : 中
2 : 高
当房价非常低时，只有生活水平低（0）的人才会买房。
当房价非常高时，只有生活水平高（2）的人才会买房。
这是我的实现的数据集和 ipynb 文件
测试数据集有 array(1,1,0,0) 作为购买决策，但我的模型给出 array(0,1,1,1)
我知道我的数据集很小，但这一定不是准确率如此低的唯一原因。
我做错了什么？如何执行。
如果链接无法访问，请告诉我。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/79247069/why-my-logistic-regression-has-25-accuracy</guid>
      <pubDate>Tue, 03 Dec 2024 09:54:08 GMT</pubDate>
    </item>
    <item>
      <title>如何将原始二进制图像数据转换为 TexImageSource [关闭]</title>
      <link>https://stackoverflow.com/questions/79245288/how-do-i-convert-raw-binary-image-data-to-teximagesource</link>
      <description><![CDATA[所以我有一个带 Wi-Fi 的微控制器。我正在向托管在我电脑上的 Web 服务器发送 HTTP 请求，该服务器托管一个对象检测模型。此 HTTP 请求包含原始二进制图像数据，但 Mediapipe（我用来运行该模型的库）需要 TexImageSource，但我不确定如何将二进制图像数据转换为 TexImageSource 以在 mediapipe.s 中使用]]></description>
      <guid>https://stackoverflow.com/questions/79245288/how-do-i-convert-raw-binary-image-data-to-teximagesource</guid>
      <pubDate>Mon, 02 Dec 2024 19:08:10 GMT</pubDate>
    </item>
    <item>
      <title>CNN 中的可变大小输入[关闭]</title>
      <link>https://stackoverflow.com/questions/79245135/variable-sized-input-in-cnn</link>
      <description><![CDATA[我有一个包含不同分辨率图像的数据集。我想将它们缩放为固定分辨率。有没有关于缩放图像的最佳尺寸的建议？
我想到的是取平均值、最大值或均值作为固定分辨率。]]></description>
      <guid>https://stackoverflow.com/questions/79245135/variable-sized-input-in-cnn</guid>
      <pubDate>Mon, 02 Dec 2024 18:10:59 GMT</pubDate>
    </item>
    <item>
      <title>SVHN 数据集中的标签错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/79244553/wrong-labels-in-svhn-dataset</link>
      <description><![CDATA[我一直在对 SVHN 数据集进行一些实验，主要是我想在进行一些训练之前裁剪出每个数字，这时我偶然发现测试数据集中的图像 53.png 有错误的标签（9 和 3，而不是 3 和 3）。
我很好奇是否有人也可以复制该问题，如果标签真的错了，也许可以建议如何处理它？&lt;​​/p&gt;
我从官方网站下载了数据集，解压缩并尝试读取 digitStruct.mat。
我的代码（假设所有数据都在 data/train 文件夹中）：
import os
from PIL import Image
from pymatreader import read_mat
import matplotlib.pyplot as plt
train_mat = read_mat(&#39;data/train/digitStruct.mat&#39;)

print(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][52])
print(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][52])

返回
&gt;&gt;53.png
&gt;&gt;{&#39;label&#39;: [9.0, 3.0], &#39;height&#39;: [84.0, 84.0], &#39;width&#39;: [59.0, 52.0], &#39;left&#39;: [160.0, 208.0], &#39;top&#39;: [34.0, 18.0]}

我还尝试显示其他图像以防出现类似异常，但我没有发现任何问题。
import cv2 
from matplotlib import pyplot as plt 

fig = plt.figure(figsize=(10, 7))

# 使用 OpenCV 读取图像（OpenCV 以 BGR 格式加载图像）
image1 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][0])
image2 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][27])
image3 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][52])
image4 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][90])

# 将图像从 BGR 转换为 RGB 格式，以便 Matplotlib 可以正确显示它们
image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)
image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)
image3 = cv2.cvtColor(image3, cv2.COLOR_BGR2RGB)
image4 = cv2.cvtColor(image4, cv2.COLOR_BGR2RGB)

# 将第一幅图像添加到图中（左上角位置）
plt.subplot(2, 2, 1) # 2 行，2 列，第一个位置
plt.imshow(image1) 
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][0] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][0][&#39;label&#39;]))

# 将第二幅图像添加到图中（右上位置）
plt.subplot(2, 2, 2) # 2 行，2 列，第二个位置
plt.imshow(image2) 
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][27] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][27][&#39;label&#39;])) 

# 将第三幅图像添加到图中（左下位置）
plt.subplot(2, 2, 3) # 2 行，2 列，第三个位置
plt.imshow(image3)
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][52] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][52][&#39;label&#39;])) 
# 将第四幅图像添加到图中（右下角位置）
plt.subplot(2, 2, 4) # 2 行，2 列，第四个位置
plt.imshow(image4) 
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][90] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][90][&#39;label&#39;]))

输出：SVHN 比较]]></description>
      <guid>https://stackoverflow.com/questions/79244553/wrong-labels-in-svhn-dataset</guid>
      <pubDate>Mon, 02 Dec 2024 15:03:58 GMT</pubDate>
    </item>
    <item>
      <title>anomalib 的零样本 winCLIP 不起作用</title>
      <link>https://stackoverflow.com/questions/79244492/zero-shot-winclip-from-anomalib-not-working</link>
      <description><![CDATA[随着异常分类/分割的最新进展，我想尝试新的 winCLIP 模型，anomalib 库也有一个实现。
如何测试零样本或为少样本提供几张“正常/健康”图像？由于这是一个零样本模型，我认为它很容易开箱即用，但我无法让它工作。这是我当前的代码：
from anomalib.models.image import WinClip
from anomalib.engine import Engine

# 导入数据模块
from anomalib.data import Folder
from anomalib.data.utils import TestSplitMode

# 创建数据模块
datamodule = Folder(
name=&quot;lasercut_plank&quot;,
root=&quot;./DATA_0shot&quot;,
normal_dir=&quot;normal&quot;,
test_split_mode=TestSplitMode.NONE
)

# 设置数据模块
datamodule.setup()

# 访问数据集
train_dataset = datamodule.train_data

# 访问数据加载器
train_dataloader = datamodule.train_dataloader()

# 创建模型和引擎
model = WinClip(class_name=&quot;lasercut_plank&quot;)
engine = Engine(task=&quot;segmentation&quot;)

# 在给定的数据模块上训练 Patchcore 模型
engine.train(datamodule=datamodule, model=model)
]]></description>
      <guid>https://stackoverflow.com/questions/79244492/zero-shot-winclip-from-anomalib-not-working</guid>
      <pubDate>Mon, 02 Dec 2024 14:43:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么预先训练的 Swin Transformer 编码器在 TPU 上失败但在 Colab 中的 CPU 上可以运行？</title>
      <link>https://stackoverflow.com/questions/79244294/why-does-pre-trained-swin-transformer-encoder-fail-on-tpu-but-works-on-cpu-in-co</link>
      <description><![CDATA[我正在处理图像分割任务，并尝试使用预先训练的 Swin Transformer Large (Swin-L) 编码器作为特征提取主干。代码在 Colab 中的 CPU 上完美运行。但是，当切换到 TPU 时，它会抛出如下所示的错误。
代码：
from tensorflow.keras import layer, Model, Input
from tfswin import SwinTransformerLarge224

def load_swin_encoder(input_shape=(512, 512, 3)):
# 加载预训练的 Swin-L 模型
swin_encoder = SwinTransformerLarge224(include_top=False, weights=&#39;imagenet&#39;,
input_shape=input_shape)

# 冻结预训练层
for layer in swin_encoder.layers:
layer.trainable = False

# 从四个阶段提取输出
stage_outputs = [
swin_encoder.get_layer(&#39;normalize&#39;).output, # 从 0 阶段输出
swin_encoder.get_layer(&#39;layers.0&#39;).output, # 第一阶段的输出
swin_encoder.get_layer(&#39;layers.1&#39;).output, # 第二阶段的输出
swin_encoder.get_layer(&#39;layers.2&#39;).output, # 第三阶段的输出
swin_encoder.get_layer(&#39;layers.3&#39;).output, # 第四阶段的输出
]
return Model(swin_encoder.input, stage_outputs, name=&quot;SwinTransformerEncoder&quot;)

# 测试代码
encoder = load_swin_encoder(input_shape=(512, 512, 3))
dummy_input = tf.random.uniform((1, 512, 512, 3))
encoder_outputs =coder(dummy_input)

for i, output in enumerate(encoder_outputs):
print(f&quot;阶段 {i + 1} 输出形状：{output.shape}&quot;)


错误：
代码在 TPU 上抛出以下错误：
------------------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-28-3cb122d32678&gt; 在 &lt;cell line: 2&gt;()
1 # 加载健全性检查
----&gt; 2 编码器 = load_swin_encoder(input_shape=(512, 512, 3))
3 dummy_input = tf.random.uniform((1, 512, 512, 3))
4 编码器输出 = 编码器(dummy_input)
5 

2 帧
/usr/local/lib/python3.10/dist-packages/keras/src/models/ functional.py in __init__(self, 输入, 输出, 名称, **kwargs)
117 for x in flat_inputs:
118 if not isinstance(x, backend.KerasTensor):
-&gt; 119 引发 ValueError(
120 “所有 `inputs` 值都必须是 KerasTensors。已收到：”
121 f“inputs={inputs} 包括无效值 {x}”

ValueError：所有 `inputs` 值都必须是 KerasTensors。已收到：inputs=KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=&#39;input_4&#39;), name=&#39;input_4&#39;, description=“由层 &#39;input_4&#39; 创建”) 包括无效值 KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=&#39;input_4&#39;), name=&#39;input_4&#39;, description=“由层创建” &#39;input_4&#39;&quot;) 类型为 &lt;class &#39;tf_keras.src.engine.keras_tensor.KerasTensor&#39;&gt;


问题：
为什么此代码在 Colab 中的 CPU 上有效，但在 TPU 上失败？我该如何修复此问题以使其与 TPU 执行兼容？
任何见解或指导都将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79244294/why-does-pre-trained-swin-transformer-encoder-fail-on-tpu-but-works-on-cpu-in-co</guid>
      <pubDate>Mon, 02 Dec 2024 13:35:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 MNIST 训练模型对自定义图像进行了错误分类？</title>
      <link>https://stackoverflow.com/questions/79243340/why-is-my-mnist-trained-model-misclassifying-a-custom-image</link>
      <description><![CDATA[我使用 MNIST 数据集训练了一个神经网络模型来识别手写数字。该模型在 MNIST 测试集上的准确率达到 97%，但无法正确预测自定义图像文件中的数字。例如，下图包含数字 8，但模型的预测始终不正确。
我在预处理步骤中做错了什么，如何正确准备自定义图像以匹配 MNIST 数据格式？
import cv2
import numpy as np
import os
from keras.api.datasets import mnist
from keras.api.models import Sequential
from keras.api.layers import Dense, Flatten
from keras.api.utils import to_categorical
from PIL import Image

# 加载 MNIST 数据集
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# 将 mnist 数据集从 uint8 转换为 float32，因为大多数深度学习框架都希望输入数据为浮点格式。
train_images = train_images.astype(&#39;float32&#39;) / 255
test_images = test_images.astype(&#39;float32&#39;) / 255

# 添加新的通道维度，得到形状 (num_samples, 28, 28, 1)
train_images = np.expand_dims(train_images, axis=-1)
test_images = np.expand_dims(test_images, axis=-1)

# 对标签进行独热编码
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# 构建模型
model = Sequential([
Flatten(input_shape=(28, 28, 1)),
Dense(128,activation=&#39;relu&#39;),
Dense(10,activation=&#39;softmax&#39;)
])

#编译模型
model.compile(optimizer=&#39;adam&#39;,
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

# 训练模型
print(&quot;训练模型...&quot;)
model.fit(train_images, train_labels, epochs=5, batch_size=128)

# 评估模型
loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)
print(f&quot;测试准确率：{accuracy * 100:.2f}%&quot;)

# 加载图像进行预测
image_path = &#39;digit.png&#39; # 替换为您的图像路径
print(f&quot;加载并预测 {image_path}...&quot;)

try:
# 以灰度读取图像
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

if image is None:
raise IOError(f&quot;Error loading image at {image_path}&quot;)

# 将图像大小调整为 28x28
image = cv2.resize(image, (28, 28))

# 反转颜色（如果需要）
image = cv2.bitwise_not(image)

# 标准化图像
image_normalized = image.astype(&#39;float32&#39;) / 255

# 转换为可以保存为 PNG 的格式（值 0 到 255）
image_for_saving = (image_normalized * 255).astype(np.uint8)

# 定义保存图像的路径
preprocessed_image_path = &quot;preprocessed_digit.png&quot;

# 确保目录存在（当前目录）
output_directory = os.path.dirname(preprocessed_image_path)
if not os.path.exists(output_directory) and output_directory != &#39;&#39;:
os.makedirs(output_directory)

# 使用 PIL 保存图像
pil_image = Image.fromarray(image_for_saving)
pil_image.save(preprocessed_image_path)
print(f&quot;已将预处理图像保存到 {preprocessed_image_path}&quot;)

# 使用模型预测数字（假设模型已加载）
# 必要时将图像重塑为模型输入格式
image_input = np.expand_dims(image_normalized, axis=0)
image_input = np.expand_dims(image_input, axis=-1)
prediction = np.argmax(model.predict(image_input))
print(&quot;预测数字：&quot;, prediction)

except Exception as e:
print(f&quot;处理图像时出错：{e}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/79243340/why-is-my-mnist-trained-model-misclassifying-a-custom-image</guid>
      <pubDate>Mon, 02 Dec 2024 08:03:19 GMT</pubDate>
    </item>
    <item>
      <title>set_transform 或 with_transform 之后 transformer 的数据集结构出现意外</title>
      <link>https://stackoverflow.com/questions/79241735/unexpected-transformers-dataset-structure-after-set-transform-or-with-transform</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79241735/unexpected-transformers-dataset-structure-after-set-transform-or-with-transform</guid>
      <pubDate>Sun, 01 Dec 2024 14:07:14 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 不接受数据集生成器的列表类型</title>
      <link>https://stackoverflow.com/questions/79241634/tensorflow-does-not-accept-list-type-for-dataset-generator</link>
      <description><![CDATA[我正在构建一个神经网络。我无法一次性将所有训练数据加载到内存中，因此我使用 TensorFlow 的 tf.data.Dataset.from_generator 函数逐步加载数据。但是，它会抛出一个错误，指出它不接受张量列表作为类型。
TypeError：`output_signature` 必须包含属于 
`tf.TypeSpec` 子类的对象，但发现 &lt;class &#39;list&#39;&gt; 不是。

我的神经网络的输入是 151 个独立张量的列表。我如何在生成器中表示它？我的代码如下：
def generator(file_paths, batch_size, files_per_batch, tam, value):
return tf.data.Dataset.from_generator(
lambda: data_generator(file_paths, batch_size, files_per_batch, tam, value),
output_signature=(
[tf.TensorSpec(shape=(batch_size, tam), dtype=tf.float32) for _ in range(tam+1)], # 151 个张量列表
tf.TensorSpec(shape=(batch_size, tam), dtype=tf.float32) # 数组
)
)

inputArray = [Input(shape=(tam,)) for _ in range(tam + 1)]

train_dataset = generator(file_paths, batch_size, files_per_batch, tam, False)
train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)

model.fit(train_dataset, epochs=1000, validation_split=0.2, verbose=1)

我尝试使用 tf.data.Dataset.from_generator 将数据批量输入到我的神经网络中，因为我无法一次将所有数据加载到内存中。
但是，我遇到了一个错误：
TypeError：output_signature 必须包含属于 tf.TypeSpec 子类的对象，但发现 &lt;class &#39;list&#39;&gt; 不是。
]]></description>
      <guid>https://stackoverflow.com/questions/79241634/tensorflow-does-not-accept-list-type-for-dataset-generator</guid>
      <pubDate>Sun, 01 Dec 2024 13:13:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中实现 Softmax，其中输入是有符号的 8 个整数</title>
      <link>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</link>
      <description><![CDATA[我正在尝试实现一个softmax 函数，该函数接受有符号的 int8 输入并返回有符号的 int8 输出数组。
我目前正在进行的实现是这样的，
 import numpy as np

def softmax_int8(inputs):
input = np.array(inputs, dtype=np.int8)

x = input.astype(np.int32)
x_max = np.max(x)
x_shifted = x - x_max
scale_factor = 2 ** 14
exp_limit = 16
exp_x = np.clip(x_shifted + exp_limit, 0, None)
exp_x = (1 &lt;&lt; exp_x)
sum_exp_x = np.sum(exp_x)

如果 sum_exp_x == 0:
sum_exp_x = 1

softmax_probs = (exp_x * scale_factor) // sum_exp_x
max_prob = np.max(softmax_probs)
min_prob = np.min(softmax_probs)
range_prob = max_prob - min_prob 如果 max_prob != min_prob 否则 1

scaled_probs = ((softmax_probs - min_prob) * 255) // range_prob - 128
output = scaled_probs.astype(np.int8)

返回输出

我使用此输入进行测试，Input = [101, 49, 6, -34, -75, -79, -38, 120, -55, 115]
但我得到此输出 array([-128, -128, -128, -128, -128, -128, -128, 127, -128, -121],dtype=int8)。
我的预期输出是 array([-57, -70, -79, -86, -92, -94, -88, -54, -91, -56], dtype=int8)。
我在这里做错了什么，我该如何修复？]]></description>
      <guid>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</guid>
      <pubDate>Sat, 30 Nov 2024 09:37:57 GMT</pubDate>
    </item>
    <item>
      <title>这些 `[0]` 在创建变量时是否有意义</title>
      <link>https://stackoverflow.com/questions/79236682/do-those-0-make-sense-in-making-the-variable</link>
      <description><![CDATA[使用 HuggingFace 工具集微调 Gemma 的指南位于：https://huggingface.co/blog/gemma-peft
链接到以下行：https://huggingface.co/blog/gemma-peft#:~:text=Quote%3A%20%7Bexample-,%5B%27quote%27%5D%5B0%5D,-%7D%5CnAuthor%3A
数据输入格式化函数是：
def formatting_func(example):
text = f&quot;Quote: {example[&#39;quote&#39;][0]}\nAuthor: {example[&#39;author&#39;][0]}&lt;eos&gt;&quot;
return [text]

这些 [0] 有意义吗？它们看起来不对，因为当打印出 text 变量时，我可以看到它们只是字符而不是字符串。]]></description>
      <guid>https://stackoverflow.com/questions/79236682/do-those-0-make-sense-in-making-the-variable</guid>
      <pubDate>Fri, 29 Nov 2024 10:14:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bootstrap 重采样、LASSO 和逐步回归进行特征选择</title>
      <link>https://stackoverflow.com/questions/76204705/feature-selection-using-bootstrap-resampling-lasso-and-stepwise-regression</link>
      <description><![CDATA[在本文中，作者通过以下方式进行放射组学特征选择以预测生存：

使用 Bootstrap 重采样数据集 x 1000
将交叉验证的 LASSO 模型拟合到每个重采样数据集
在所有 1000 个模型中保留 10 个最常见的非零系数特征
使用十个选定的特征对重采样数据集（与步骤 1 中生成的数据集相同）进行反向逐步回归拟合
根据最常见的 cox 回归模型选择最终特征。

我想复制这种方法（尽管是针对逻辑回归而不是cox-regression)。
我能够使用以下 R 代码，使用“boot”库从 Lasso 模型中获取前 K 个特征：
lasso_Select &lt;- function(x, indices){ 
x &lt;- x[indices,]
y &lt;- x$Outcome
x = subset(x, select = -Outcome)
x2 &lt;- as.matrix(x)
fit &lt;- glmnet(x2, y , family=&quot;binomial&quot;,alpha=1, standardize=TRUE)
cv &lt;- cv.glmnet(x2, y, family=&quot;binomial&quot;,alpha=1, standardize=TRUE)
fit &lt;- glmnet(x2, y, family=&quot;binomial&quot;,alpha=1, lambda=cv$lambda.min, standardize=TRUE)
return(coef(fit)[,1])
}

myBootstrap &lt;- boot(scaled_train, lasso_Select, R = 1000, parallel = &quot;multicore&quot;, ncpus=5)

但是，我不认为我可以访问单个重采样数据集，然后运行多个逻辑回归模型并选择最常见的模型。
关于如何处理这个问题，有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/76204705/feature-selection-using-bootstrap-resampling-lasso-and-stepwise-regression</guid>
      <pubDate>Mon, 08 May 2023 21:06:44 GMT</pubDate>
    </item>
    </channel>
</rss>