<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 04 Jan 2024 03:15:52 GMT</lastBuildDate>
    <item>
      <title>Python 中带有否定词的词袋</title>
      <link>https://stackoverflow.com/questions/77755646/bag-of-words-with-negative-words-in-python</link>
      <description><![CDATA[我有这个文件
这不是普通的文本
这是科学术语的文本
这些文档的正文是这样的
&lt;前&gt;&lt;代码&gt;RepID,Txt

1、K9G3P9 4H477 -Q207KL41 98464 ... Q207KL41
2、D84T8X4 -D9W4S2 -D9W4S2 8E8E65 ... D9W4S2
3、-05L8NJ38 K2DD949 0W28DZ48 207441 ... K2D28K84

我可以使用 BOW 算法构建功能集
这是我的代码
def BOW(df):
  CountVec = CountVectorizer() # 仅使用二元组 ngram_range=(2,2)
  Count_data = CountVec.fit_transform(df)
  Count_data = Count_data.astype(np.uint8)
  cv_dataframe=pd.DataFrame(Count_data.toarray(), columns=CountVec.get_feature_names_out(), index=df.index) # &lt;- 这里
  返回 cv_dataframe.astype(np.uint8)

df_reps = pd.read_csv(“c:\\file.csv”)
df = BOW(df_reps[“Txt”])

结果将是“Txt”中的字数。专栏。
&lt;预&gt;&lt;代码&gt;RepID K9G3P9 4H477 -Q207KL41 98464 ... Q207KL41
1 2 8 3 2 ... 1
2 0 1 1 4 ... 3

这里我需要帮助的地方是，其中一些术语前面有一个-，这应该算作负值
因此，如果文本具有这些值Q207KL41 -Q207KL41 -Q207KL41
在这种情况下，以 - 开头的项应计为负数，因此 Q207KL41 的 BOW 为 -1
而不是具有Q207KL41和-Q207KL41的功能
它们都计入相同的术语Q207KL41，但具有正数和负数
如何做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/77755646/bag-of-words-with-negative-words-in-python</guid>
      <pubDate>Thu, 04 Jan 2024 02:56:20 GMT</pubDate>
    </item>
    <item>
      <title>Brain.js 可以将一个单词转换为另一个单词吗？</title>
      <link>https://stackoverflow.com/questions/77755432/can-brain-js-convert-one-word-into-another</link>
      <description><![CDATA[我注意到 LSTM 网络可能不适合分类任务，因为它们有时会产生奇怪的输出。所以，我决定看看它们是否适合将常规单词转换为有趣和粗俗的版本，因为“Floptok”社区（说唱歌手 CupcakKe 的粉丝）中有一个模因，他们将普通单词转换为幽默和粗俗的版本一。例如：Reddit = Reddick 或 Jennie = Jennitals。
const net = new Brain.recurrent.LSTM();
常量训练数据= [
{ 输入：“Google”，输出：“Googulp” },
{ 输入：“亚马逊”，输出：“Amoanzon” },
{ 输入：“Alexa”，输出：“Asexa” },
{ 输入：“Cortana”，输出：“Cvmtana” },
{ 输入：“台湾”，输出：“Tightwan” },
{ 输入：“越南”，输出：“Viethong” },
{ 输入：“柬埔寨”，输出：“柬埔寨” },
{ 输入：“马来西亚”，输出：“Moanslaysia” },
{ 输入：“泰国”，输出：“Tightland” },
{ 输入：“菲律宾”，输出：“菲律宾” },
{ 输入：“新加坡”，输出：“新加坡” },
{ 输入：“巧克力”，输出：“Cookcolate” },
// 更多示例（总计：201）
];
net.train(trainingData, { 迭代次数: 5000, log: true });
const result = net.run(“钛”);
// 预期结果：Twatanium
console.log(结果);
// 结果：“Camhoedia”、“TitaniumTighland”、“Coog”或空输出。
`
我做错了什么吗？我的数据集太小了吗？我需要配置一些参数吗？如果有，是哪些？我期待您的回复。
我已经尝试添加更多神经元，但没有发生任何新的情况。]]></description>
      <guid>https://stackoverflow.com/questions/77755432/can-brain-js-convert-one-word-into-another</guid>
      <pubDate>Thu, 04 Jan 2024 01:31:42 GMT</pubDate>
    </item>
    <item>
      <title>DataFrame'对象没有属性'符号</title>
      <link>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</link>
      <description><![CDATA[我想使用机器学习创建股票价格预测，但出现“‘DataFrame’对象没有属性‘符号’”我的错误是什么以及如何修复它
` `将 numpy 导入为 np
      将 pandas 导入为 pd
      从sklearn导入预处理
      从 sklearn.model_selection 导入 train_test_split
      从 sklearn. Linear_model 导入 LinearRegression

      def prepare_data(df,forecast_col,forecast_out,test_size) :
    label = df[forecast_col].shift(-forecast_out) #创建名为 label 的新列，最后 5 行为 nan
         X = np.array(df [[forecast_col]]) #创建特征数组
         X = preprocessing.scale(X) #处理特征数组
         X_lately = X[-forecast_out:] #创建我想稍后在预测方法中使用的列
         X = X[:-forecast_out] # X 将包含训练和测试
         label.dropna(inplace=True) #删除na值
         y = np.array(label) # 分配 Y
         X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=test_size, random_state=0) #交叉验证

        响应 = [X_train,X_test,Y_train,Y_test,X_lately]
        返回响应

    df = pd.read_csv(“GOOG.csv”)
    df = df[df.symbol == &quot;GOOG&quot;]- &quot;错误信息出现的位置&quot;
   Forecast_col = “关闭”
   预测输出 = 5
   

测试大小 = 0,2

X_train、X_test、Y_train、Y_test、X_lately = 准备数据（df、forecast_col、forecast_out、test_size）
学习者 = 线性回归()
learner.fit (X_train,Y_train )
Score=learner.score(X_test,Y_test)#测试线性回归模型
Forecast= learner.predict(X_lately) #将包含预测数据的集合
响应={}#creting json 对象
    响应[&#39;test_score&#39;]=分数
    响应[&#39;forecast_set&#39;]=预测`

打印（响应）`
]]></description>
      <guid>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</guid>
      <pubDate>Thu, 04 Jan 2024 01:24:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 roboflow 使用实例分割底层模型的预测在分割部分上覆盖另一个图像</title>
      <link>https://stackoverflow.com/questions/77755071/how-to-use-predicitons-from-instance-segmentation-floor-model-to-overlay-another</link>
      <description><![CDATA[我有一个实例分割模型，我已经训练该模型来检测地板，现在我得到了正确的输出，我如何使用该分割的地板在分割部分上覆盖另一个图像，我得到 JSON 格式的预测。我使用 roboflow 训练模型来检测房间图像中的地板，现在我得到了房间图像中检测到的地板的输出作为 JSON 格式的预测，现在我想在预测上覆盖图像，我该怎么做{
“预测”：[
   

     {
          “x”：319.5，
          “y”：441，
          “宽度”：637，
          “高度”：102，
          “置信度”：0.823，
          “类”：“楼层”，
          “点”：[
            {
              “x”：402，
              “y”：392.831
            },
            {
              “x”：401，
              “y”：393.6
            },
            {
              “x”：400，
              “y”：393.6
            },
            {
              “x”：399，
              “y”：394.369
            },
            {
              “x”：398，
              “y”：394.369
            },
            {
              “x”：397，
              “y”：395.138
            },
            {
              “x”：397，
              “y”：396.675
            },
            {
              “x”：396，
              “y”：397.444
            },
            {
              “x”：396，
              “y”：398.981
            },
            {
              “x”：397，
              “y”：399.75
            },
            {
              “x”：397，
              “y”：412.05
            },
            {
              “x”：396，
              “y”：412.819
            },
            {
              “x”：396，
              “y”：424.35
            },
            {
              “x”：395，
              “y”：425.119
            },
            {
              “x”：395，
              “y”：427.425
            },
            {
              “x”：394，
              “y”：428.194
            },
            {
              “x”：394，
              “y”：428.963
            },
            {
              “x”：393，
              “y”：429.731
            },
            {
              “x”：393，
              “y”：439.725
            },
            {
              “x”：394，
              “y”：440.494
            },
            {
              “x”：394，
              “y”：441.263
            },
            {
              “x”：392，
              “y”：442.8
            },
            {
              “x”：392，
              “y”：443.569
            },
            {
              “x”：391，
              “y”：444.338
            },
            {
              “x”：390，
              “y”：444.338
            },
            {
              “x”：389，
              “y”：445.106
            },
            {
              “x”：385，
              “y”：445.106
            },
            {
              “x”：384，
              “y”：444.338
            },
            {
              “x”：384，
              “y”：443.569
            },
            {
              “x”：383，
              “y”：442.8
            },
            {
              “x”：383，
              “y”：442.031
            },
            {
              “x”：382，
              “y”：441.263
            },
            {
              “x”：382，
              “y”：438.956
            },
            {
              “x”：381，
              “y”：438.188
            },
            {
        
          ],
          “class_id”：0
        }
      ]
    }

像这样]]></description>
      <guid>https://stackoverflow.com/questions/77755071/how-to-use-predicitons-from-instance-segmentation-floor-model-to-overlay-another</guid>
      <pubDate>Wed, 03 Jan 2024 23:04:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在Elasticnet机器学习模型上使用SHAP？</title>
      <link>https://stackoverflow.com/questions/77754925/how-to-use-shap-on-elasticnet-machine-learning-model</link>
      <description><![CDATA[我正在 RStudio 中使用弹性网络 (glmnet) 运行机器学习分析。我想使用 shapr 包来查找我的模型的预测蛋白。我用 5 次重复和 5 次折叠训练了我的模型，然后基于此训练了最终模型。下面是我使用的代码。我遇到的问题是 shapr 不能在自定义模型上使用。与 Xgboost 相比，我更喜欢 Elastic Net，我认为它希望我使用 Elastic Net。
库(glmnet)
库（pROC）
图书馆（夏普）
库（插入符号）

#计算 SHAP（内核）以确定哪些特征对该模型很重要
#使用高斯方法

解释器 &lt;- shapr(train_data, Final_model)

target_variable &lt;- as.numeric(target_variable)

p &lt;- 平均值（目标变量）

解释高斯 &lt;- 解释（
  测试数据，
  方法=“高斯”，
  解释者 = 解释者,
  预测_零 = p
）

#绘制观察结果 1 和 6 的解释

绘图（解释高斯，plot_phi0 = FALSE，index_x_test = c（1, 6））

get_model_specs(model) 中的错误：
  您将模型传递给 shapr，但本机不支持该模型 请参阅 ?shapr::shapr 或小插图
有关如何使用自定义模型运行 shapr 的更多信息。
]]></description>
      <guid>https://stackoverflow.com/questions/77754925/how-to-use-shap-on-elasticnet-machine-learning-model</guid>
      <pubDate>Wed, 03 Jan 2024 22:22:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 html 将逗号分隔值插入 numpy 数组中进行预测</title>
      <link>https://stackoverflow.com/questions/77753838/how-to-use-html-to-insert-comma-seperated-values-into-a-numpy-array-for-predicti</link>
      <description><![CDATA[我试过了
&lt;输入类型=“文本” name=“n1”&gt;&lt;/td&gt;

接受输入。
&lt;预&gt;&lt;代码&gt;17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0。 01587,0.03003,0.006193,25.38,17.33, 184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189

我将其输入到 view.py 中的 numpy 数组中。
np.array((request.GET[&#39;n1&#39;]))

但我收到以下错误消息。
/预测/输出处的值错误
预期是二维数组，却得到一维数组：
数组=[&#39;17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01 587,0.03003,0.006193,25.38,17.33,184.6, 2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189&#39;]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

view.py（v1 = np.array((request.GET[&#39;n1&#39;])) 在第 8 行）
def 输出（请求）：
    dff = pd.read_csv(r&#39;C:\Users\Downloads\data.csv&#39;)
    y = dff[&#39;诊断&#39;].值
    x = dff.drop(&#39;诊断&#39;, axis=1).values
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40)
    模型=逻辑回归()
    model.fit(x_train, y_train)
    v1 = np.array((request.GET[&#39;n1&#39;]))

pred = model.predict([v1])
    pred1 = &quot;&quot;;
    如果 pred==[1]:
        pred1 =“阳性”
    别的：
        pred1 =“阴性”
return render(request, &#39;prediction.html&#39;, {&quot;predictResult&quot;:**pred1**})


prediction.html（第6行是获取输入）
;
    &lt;表单动作＝“输出”&gt;
        &lt;表&gt;
            &lt;tr&gt;
                &lt;tdalign=“右”&gt;怀孕&lt;/td&gt;
               &lt;输入类型=“文本” name=“n1”&gt;&lt;/td&gt;
            
    &lt;/表&gt;
     &lt;输入类型=“提交”&gt;
    &lt;/表格&gt;

    结果：{{ 预测结果 }}

]]></description>
      <guid>https://stackoverflow.com/questions/77753838/how-to-use-html-to-insert-comma-seperated-values-into-a-numpy-array-for-predicti</guid>
      <pubDate>Wed, 03 Jan 2024 18:02:59 GMT</pubDate>
    </item>
    <item>
      <title>用于具有非常小的值的回归问题的度量[关闭]</title>
      <link>https://stackoverflow.com/questions/77753161/metric-to-use-for-regression-problems-with-very-small-values</link>
      <description><![CDATA[我正在研究一个回归问题，目标列中的值范围在 0.01 到 0.1 之间。我正在尝试找到正确的指标来评估训练模型的性能。
r2 分数似乎不太适合它。任何人都可以为这种情况推荐一个吗？]]></description>
      <guid>https://stackoverflow.com/questions/77753161/metric-to-use-for-regression-problems-with-very-small-values</guid>
      <pubDate>Wed, 03 Jan 2024 16:08:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在回归中找到特征值以获得因变量范围内的值？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77753120/how-can-i-find-the-feature-values-in-a-regression-to-get-values-within-a-range</link>
      <description><![CDATA[我已经进行了回归，拟合效果很好。我的响应变量是从 0 到 1 连续的，我想找到给我的值大于 0.7 的解释变量的值。我能做什么？]]></description>
      <guid>https://stackoverflow.com/questions/77753120/how-can-i-find-the-feature-values-in-a-regression-to-get-values-within-a-range</guid>
      <pubDate>Wed, 03 Jan 2024 15:59:36 GMT</pubDate>
    </item>
    <item>
      <title>用于支持向量数据描述的Python包[关闭]</title>
      <link>https://stackoverflow.com/questions/77752655/python-package-for-support-vector-data-description</link>
      <description><![CDATA[在寻找支持向量数据描述（SVDD）代码示例时，我发现了这个代码示例页面，其中 SVDD 显示为实用程序，可能位于 python 中的包 libsvm 下。但在包手册页中发现没有类似的东西存在。我发现的其他软件包是 libsvm-svdd 和 SVDD-python 但我无法按照描述使用它们。请建议一个可用的 SVDD 包，我将在疾病数据的研究工作中使用它。]]></description>
      <guid>https://stackoverflow.com/questions/77752655/python-package-for-support-vector-data-description</guid>
      <pubDate>Wed, 03 Jan 2024 14:43:53 GMT</pubDate>
    </item>
    <item>
      <title>如何从不同样本预测多变量时间序列[关闭]</title>
      <link>https://stackoverflow.com/questions/77752189/how-to-predict-multi-variate-timeseries-from-different-samples</link>
      <description><![CDATA[在使用不同样本的数据集进行训练时，我无法找到预测时间序列的最佳方法。
我有一个数据集，显示 10 只兔子从第一天到第 50 天的体重，每天测量 5 次。有了它，我还有一些不同的值，例如房间的温度、湿度和其他值。还有更多，但它们可能真的很有用。
我想用一只新兔子的数据来预测它会如何成长。例如，如果兔子只有 30 天大，到目前为止所有其他数据都已收集完毕，我想预测它接下来 20 天的体重。
我不确定如何使用所有信息来完成此任务。我正在考虑使用 ARIMA 或 LSTM 等时间序列预测方法，但考虑到我拥有不同兔子的数据，这可能不是最佳选择。
我也不确定如何将同一特征/目标的多个数据集合并到模型中，以便我可以预测新兔子的数据。使用兔子的名字作为分类变量/特征可能会起作用。
这是绘制的数据图，它们有些相似，但偏移量不同（抱歉，我无法向外部提供这些数据）
所以问题是：

使用所需的尽可能多的数据来预测新兔子未来 20 天的体重的最佳方法是什么？
我真的可以使用 10 只兔子的数据集吗？还是应该只得到它们的平均值，因为它们看起来很相似，只是偏移量有所不同？
如果其他特征/值（例如温度）不可预测/可控，但预测时可能会出现一些错误（例如天气数据），那么使用它们是否会有危险？

我做了什么：
仅针对体重的 ARIMA 效果并不好，但我尝试使用梯度提升等回归模型，将兔子的名称作为数字和分类值来识别每个数据。
我尝试使用迭代方式进行预测，仅预测下一个重量（不使用温度或湿度等其他数据），并通过对每个数据进行滞后来使用一些过去的重量作为特征。结果不太好
我尝试添加一堆目标滞后，但为了未来的权重（例如，weight_after_1_day 等 20 个新功能将成为未来 20 天的目标），以便我使用尽可能多的数据。
我也尝试过 LSTM，但我不知道如何使 calcategories 变量起作用，所以我想知道我之前是否做对了。也许在这种情况下这是不可能的，我应该只使用一个兔子时间序列？]]></description>
      <guid>https://stackoverflow.com/questions/77752189/how-to-predict-multi-variate-timeseries-from-different-samples</guid>
      <pubDate>Wed, 03 Jan 2024 13:23:38 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 中使用 StandardScaler 时 CustomScaler 中出现类型错误</title>
      <link>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</link>
      <description><![CDATA[我在使用 scikit-learn 的 Python 中遇到自定义缩放器类的问题。我有一个继承自 BaseEstimator 和 TransformerMixin 的 CustomScaler 类，它使用 StandardScaler。但是，我在初始化过程中遇到了类型错误。相关代码如下：
从 sklearn.base 导入 BaseEstimator、TransformerMixin
从 sklearn.preprocessing 导入 StandardScaler

类 CustomScaler(BaseEstimator,TransformerMixin):
    
    def __init__(self,columns,copy=True,with_mean=True,with_std=True):
        self.scaler = StandardScaler(复制,with_mean,with_std)
        self.columns = 列
        self.mean_ = 无
        self.var_ = 无

    def fit(self, X, y=None):
        self.scaler.fit(X[self.columns], y)
        self.mean_ = np.mean(X[self.columns])
        self.var_ = np.var(X[self.columns])
        返回自我

    def 变换（自身，X，y=无，复制=无）：
        init_col_order = X.列
        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)
        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]
        返回 pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]


unscaled_input.columns.values
columns_to_scale = [&#39;月份值&#39;,
       “星期几”、“交通费用”、“上班距离”、
       ‘年龄’、‘每日平均工作负荷’、‘体重指数’、‘儿童’、‘宠物’]

absenteeism_scaler = CustomScaler(columns= columns_to_scale) // 这一步出错
缺席主义_scaler.fit（unscaled_input）

我检查了 StandardScaler 类的 scikit-learn 文档以确保正确使用，但我找不到此错误的任何解决方案。
什么可能导致此问题？有其他方法可以解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</guid>
      <pubDate>Wed, 03 Jan 2024 10:34:48 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17)</title>
      <link>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</link>
      <description><![CDATA[
第 1 步：创建管道
第2步：将管道转换为数据帧
第3步：我正在尝试将管道转换为数据帧，但出现异常。如何解决这个问题
第 4 步：如何解决 ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17) 在管道转换为数据帧之上，

from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
从 sklearn.impute 导入 SimpleImputer
从 sklearn.pipeline 导入管道
从 sklearn.compose 导入 ColumnTransformer

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split

print(&quot;步骤1：导入lib&quot;)
print(&quot;第2步：加载原始数据&quot;)
df = pd.read_csv(“online_shoppers_intention.csv”)

print(&quot;第三步：数据准备&quot;)
X = df.drop([&#39;收入&#39;], axis = 1)
y = df[&#39;收入&#39;]

print(&quot;第四步：数据分割&quot;)
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size = .3、random_state = 0)
名称 = X_train.columns.tolist()

numeric_transformer = SimpleImputer(策略 = &#39;常量&#39;)
categorical_transformer = OneHotEncoder(handle_unknown = &#39;忽略&#39;)

numeric_cols = X.select_dtypes(exclude = &quot;object&quot;).columns.values.tolist()
categorical_cols = X.select_dtypes(exclude = [&#39;int&#39;, &#39;float64&#39;, &#39;bool&#39;]).columns.values.tolist()
    
预处理器 = ColumnTransformer(
    变形金刚=[
    (&#39;num&#39;, numeric_transformer, numeric_cols)
    ,(&#39;猫&#39;, categorical_transformer, categorical_cols)
    ],
    余数 = &#39;直通&#39;)

pipeline_preprocessor = Pipeline(steps = [(“预处理器”, 预处理器), (“pandarizer”, FunctionTransformer(lambda x: pd.DataFrame(x, columns = 名称)))]).fit(X_train)
    
X_train_pipe = pipeline_preprocessor.transform(X_train)
X_test_pipe = pipeline_preprocessor.transform(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</guid>
      <pubDate>Wed, 03 Jan 2024 07:51:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用GPT-2计算单词和句子嵌入？</title>
      <link>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</link>
      <description><![CDATA[我正在开发一个使用 GPT-2（特别是 GPT2Model 类）计算单词和句子嵌入的程序。对于词嵌入，我在转发 input_ids 后提取最后一个隐藏状态 outputs[0]，其形状为 batch size x seq len ，到 GPT2Model 类。至于句子嵌入，我在序列末尾提取单词的隐藏状态。这是我尝试过的代码：
从变压器导入 GPT2Tokenizer、GPT2Model
进口火炬

tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)
模型 = GPT2Model.from_pretrained(&#39;gpt2&#39;)
Captions = [“示例标题”、“示例鸟”、“鸟是黄色的，有红色翅膀”、“嗨”、“非常好”]

encoded_captions = [tokenizer.encode(caption) 用于字幕中的字幕]

# 用 0 将序列填充到相同的长度
max_len = max(len(seq) 用于编码字幕中的 seq)
padded_captions = [seq + [0] * (max_len - len(seq)) 对于encoded_captions中的seq]

# 转换为批量大小为 5 的 PyTorch 张量
input_ids = torch.tensor(padded_captions)

输出=模型(input_ids)
word_embedding = 输出[0].连续()
句子嵌入 = word_embedding[ :, -1, : ].contigious()


我不确定我对单词和句子嵌入的计算是否正确，有人可以帮我确认一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</guid>
      <pubDate>Tue, 02 Jan 2024 21:55:52 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Keras ValueError：“predict_function”的意外结果（空batch_outputs）</title>
      <link>https://stackoverflow.com/questions/77745874/tensorflow-keras-valueerror-unexpected-result-of-predict-function-empty-batc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77745874/tensorflow-keras-valueerror-unexpected-result-of-predict-function-empty-batc</guid>
      <pubDate>Tue, 02 Jan 2024 11:47:52 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：无法打开 shape_predictor_68_face_landmarks.dat，但没有任何帖子有帮助</title>
      <link>https://stackoverflow.com/questions/76096228/runtimeerror-unable-to-open-shape-predictor-68-face-landmarks-dat-but-none-of</link>
      <description><![CDATA[导入 dlib
导入CV2

# 加载检测器
检测器 = dlib.get_frontal_face_ detector()

# 加载预测器
预测器 = dlib.shape_predictor(“shape_predictor_68_face_landmarks.dat”)

# 加载图像
图片 = cv2.imread(“32_172.jpg.jpg”)

# 将图像转换为灰度图
灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

# 检测图像中的人脸
面孔 = 探测器（灰色）

# 循环脸部
对于面孔中的面孔：
    # 获取方框 d 中脸部的标志/部位。
    地标 = 预测器（灰色，脸部）

    # 循环地标并将它们绘制在原始图像上
    对于范围 (0, 68) 内的 n：
        x = 地标.part(n).x
        y = 地标.part(n).y
        cv2.circle(图像, (x, y), 1, (0, 255, 0), -1)

# 显示带有面部标志的图像
cv2.imshow(“面部标志”，图像)
cv2.waitKey(0)

代码在这里，我试图从图像中提取特征，但错误不断出现。我尝试了堆栈中的一些东西，但它不起作用。顺便说一句，我正在使用 jupyter 笔记本
!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 # 下载链接

!bunzip2 /content/shape_predictor_68_face_landmarks.dat.bz2

datFile =“/content/shape_predictor_68_face_landmarks.dat”

我尝试运行它们，但没有帮助]]></description>
      <guid>https://stackoverflow.com/questions/76096228/runtimeerror-unable-to-open-shape-predictor-68-face-landmarks-dat-but-none-of</guid>
      <pubDate>Mon, 24 Apr 2023 21:27:01 GMT</pubDate>
    </item>
    </channel>
</rss>