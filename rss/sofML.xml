<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 09 Aug 2024 12:29:21 GMT</lastBuildDate>
    <item>
      <title>在浏览器/API 中通过 RTSP 流实时处理低延迟视频的方法</title>
      <link>https://stackoverflow.com/questions/78852698/ways-for-real-time-processing-of-video-via-rtsp-stream-in-browser-api-with-low-l</link>
      <description><![CDATA[对于 RTSP 流，我想使用基于 Python 的模型来处理它，问题是延迟，对于实时处理，没有太多经济上可行的选择，这些选择由于延迟问题而受到限制。
独特而有趣的方式是使用 roboflow.js 进行浏览器推理，但将 RTSP 转换为另一种格式，以便可以使用该流，这给我带来了另一个问题。
处理结果的整个流需要在 UI 上显示
鉴于需要使用 Python 实用程序实时处理 RTSP 流，最佳选择是什么？
我已经通过命令行工具获取 RTSP 流然后转换为 HLS 格式，但流是在 10 秒内创建的，除了处理（鉴于我已经有一个模型），它可能需要更长的时间，那么有没有更好的方法可以处理 RTSP 并实时处理？]]></description>
      <guid>https://stackoverflow.com/questions/78852698/ways-for-real-time-processing-of-video-via-rtsp-stream-in-browser-api-with-low-l</guid>
      <pubDate>Fri, 09 Aug 2024 12:12:35 GMT</pubDate>
    </item>
    <item>
      <title>每秒 2500 帧视频处理的硬件要求</title>
      <link>https://stackoverflow.com/questions/78852250/hardware-requirement-for-video-processing-of-2500-frames-per-second</link>
      <description><![CDATA[我有 50 个摄像头，每个摄像头都提供 1080p 分辨率的馈送，我正在使用 YOLOv8n 模型在这些摄像头上应用视频分析和计算机视觉技术。为了满足我的要求，我需要每秒处理大约 2,500 帧。
我在配备 32GB RAM 的 Rtx3090 GPU 上进行了测试，我能够每秒处理 200 帧。
您能否建议实现此目标所需的适​​当硬件和 GPU 设置？此外，是否有经济高效的替代方案，例如使用多个 Jetson AGX Orin 设备或选择基于云的解决方案？]]></description>
      <guid>https://stackoverflow.com/questions/78852250/hardware-requirement-for-video-processing-of-2500-frames-per-second</guid>
      <pubDate>Fri, 09 Aug 2024 10:24:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 device_map 选择可用的 GPU 设备</title>
      <link>https://stackoverflow.com/questions/78852192/choose-available-gpu-devices-with-device-map</link>
      <description><![CDATA[from transformers import AutoTokenizer, AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
model_id,
torch_dtype=torch.bfloat16,
device_map=&quot;cuda:3&quot;,
)

服务器上有很多 GPU，但我只能使用其中两个。我应该如何配置 device_map（或其他参数）才能让模型在两个 GPU 上运行？]]></description>
      <guid>https://stackoverflow.com/questions/78852192/choose-available-gpu-devices-with-device-map</guid>
      <pubDate>Fri, 09 Aug 2024 10:04:34 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Android Studio 中创建情绪识别应用程序[关闭]</title>
      <link>https://stackoverflow.com/questions/78851919/how-to-create-emotion-recognition-app-in-android-studio</link>
      <description><![CDATA[我想创建一个基本上可以检测人类情绪的应用程序，我可以使用 jupyter 笔记本来验证它，但是当我想做同样的事情时，我无法做到，因为无法下载 opencv、mlkit 和其他不同的库。
如何在 android studio 中安装这些库以及如何在 android studio 中运行此代码]]></description>
      <guid>https://stackoverflow.com/questions/78851919/how-to-create-emotion-recognition-app-in-android-studio</guid>
      <pubDate>Fri, 09 Aug 2024 08:56:02 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Tensorflow / Python 中修剪这个神经网络？</title>
      <link>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-in-tensorflow-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-in-tensorflow-python</guid>
      <pubDate>Fri, 09 Aug 2024 07:50:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的精度突然降到0.5？</title>
      <link>https://stackoverflow.com/questions/78850531/why-does-my-precision-suddenly-drop-to-0-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78850531/why-does-my-precision-suddenly-drop-to-0-5</guid>
      <pubDate>Thu, 08 Aug 2024 21:43:15 GMT</pubDate>
    </item>
    <item>
      <title>营销中的机器学习算法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78849579/ml-algorithms-in-marketing</link>
      <description><![CDATA[我接到一个任务，要将营销预算（假设为 100 万）按产品类别进行分配，从而实现收入最大化。
我熟悉机器学习的基本算法，但经验不足。
如果您能帮助我使用什么算法/提供一些想法，那就太好了？
我有一个想法，先运行回归，但我真的不明白如何进行优化。]]></description>
      <guid>https://stackoverflow.com/questions/78849579/ml-algorithms-in-marketing</guid>
      <pubDate>Thu, 08 Aug 2024 16:49:51 GMT</pubDate>
    </item>
    <item>
      <title>如何在 sklearn 管道中实现反向序数编码并避免 NotFittedError？</title>
      <link>https://stackoverflow.com/questions/78848893/how-to-implement-reverse-ordinal-encoding-in-a-sklearn-pipeline-and-avoid-a-notf</link>
      <description><![CDATA[我正在尝试清理一个数据集，该数据集包含来自不同特征（包括数字和分类）的大量缺失值。我的想法如下：

使用 OrdinalEncoder 只保留数值并将缺失值保留为 NaN（不能使用 OneHotEncoder，因为它会创建新列，这些列为 NaN）
使用 KNNImputer 估算缺失值
反转编码，因为没有合理的理由在类别中绘制某种顺序

这是我目前的代码：
import pandas as pd
import numpy as np
from sklearn import set_config
set_config(transform_output=&quot;pandas&quot;)
from sklearn.preprocessing import OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute 导入 KNNImputer
从 sklearn.base 导入 BaseEstimator、TransformerMixin

class RoundingToIntegerTransformer(BaseEstimator、TransformerMixin):
def fit(self, X, y=None):
return self

def transform(self, X):
return np.round(X) 

class ReverseOrdinalEncoder(BaseEstimator、TransformerMixin):
def __init__(self,coder_name, categorical_columns):
self.encoder_name =coder_name
self.categorical_columns = categorical_columns

def fit(self, X, y=None):
return self

def transform(self, X, y=None):
X_ = X.copy()
coder = self.encoder_name
X_categorical = X_[categorical_columns] 
X_categorical =编码器.逆变换（X_categorical）
X_[categorical_columns] = X_categorical
返回 X_

数据 = pd.DataFrame({
&#39;类别 1&#39;：[&#39;a&#39;，&#39;b&#39;，&#39;a&#39;，np.nan，&#39;c&#39;，&#39;b&#39;]，
&#39;类别 2&#39;：[&#39;x&#39;，&#39;y&#39;，&#39;x&#39;，&#39;z&#39;，np.nan，&#39;y&#39;]，
&#39;数值 1&#39;：[1.1，np.nan，3.3，4.4，5.5，np.nan]，
&#39;数值 2&#39;：[np.nan，2.2，np.nan，4.4，5.5，6.6]
})

数值列 = data.select_dtypes(include=&#39;number&#39;).columns.tolist()
categorical_columns = data.select_dtypes(include=&#39;object&#39;).columns.tolist()

ordinal_encoder = OrdinalEncoder(encoded_missing_value=np.nan)

first_encoder = ColumnTransformer(transformers=[
(&#39;ordinal_cat&#39;, ordinal_encoder, categorical_columns)
],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False)

imputer = Pipeline([
(&#39;KNN_imputing&#39;, KNNImputer()),
(&#39;rounding&#39;, ColumnTransformer(transformers=[(&#39;round_cat&#39;, RoundingToIntegerTransformer() , categorical_columns)],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False))
])

reverse_encoder = ReverseOrdinalEncoder(
coder_name=first_encoder.transformers[0][1], 
categorical_columns=categorical_columns
)

preprocessor = Pipeline([
(&#39;encoding&#39;, first_encoder),
(&#39;imputing&#39;, imputer),
(&#39;decoding&#39;, reverse_encoder)
])

我尝试了一段时间，但从未成功，我总是收到以下错误：
&gt;NotFittedError：此 OrdinalEncoder 实例尚未安装。使用此估算器之前，请使用适当的参数调用“fit”。

我理解这个错误，但我认为由于序数编码器在管道中出现得早，因此在反向编码器中使用时它会被安装。有没有什么办法可以实现这个功能？]]></description>
      <guid>https://stackoverflow.com/questions/78848893/how-to-implement-reverse-ordinal-encoding-in-a-sklearn-pipeline-and-avoid-a-notf</guid>
      <pubDate>Thu, 08 Aug 2024 14:07:04 GMT</pubDate>
    </item>
    <item>
      <title>高效编码原则[关闭]</title>
      <link>https://stackoverflow.com/questions/78848312/principles-of-efficient-coding</link>
      <description><![CDATA[我是一名拥有 3 年以上经验的机器学习工程师。这 3 年中，我大部分时间都花在提出解决方案和为它们训练良好的模型（特别是 CV）上，仅此而已，我过去为我的团队提供模型，他们过去负责处理其余的事情。不过，最近我转向创建整个项目，包括它们的生产，现在我觉得自己对编码一无所知，因为我的代码通常很慢、很乱、效率很低。
为了解决这个问题，我开始学习一些东西，我学会了：

使用高效的数据类型
不要使用嵌套循环
学习了大 O 复杂度的概念
此外，我还在研究代码的可读性，如何使用记录器、异常、关注点分离、PEP8 标准、config.yaml、.env 文件等。

我的问题是，我似乎没有理解它的要点，效率和可读性对我来说并不自然。所以我的问题，特别是针对专业人士，当你开始任何项目时，你对代码的方法是什么，你是否有特殊的模式开始或编写和重构，你如何确保你的代码得到优化，你是否曾经想过你可能没有最好的方法。
此外，是否有一些你经常使用的库？例如，我刚刚了解了 PQDM 以及它如何并行化您的代码，那么您有什么可以帮助我的主要注意事项吗？我主要从事 ML 项目（如果这有帮助的话）。
欢迎任何想法或意见，我只是想自然地掌握它。
感谢大家的参与。
我观看了 YouTube 视频，联系了一些前辈，尝试阅读 OOP 概念和书籍，阅读数据结构等。]]></description>
      <guid>https://stackoverflow.com/questions/78848312/principles-of-efficient-coding</guid>
      <pubDate>Thu, 08 Aug 2024 12:04:57 GMT</pubDate>
    </item>
    <item>
      <title>在 RAG 中处理没有 LLMS 的问候类型问题</title>
      <link>https://stackoverflow.com/questions/78843382/handling-greet-type-of-questions-without-llm-in-rag</link>
      <description><![CDATA[我正在为一个聊天机器人实现一个检索增强生成 (RAG) 系统，该系统可以处理各种用户查询。虽然 RAG 的主要设计目的是通过检索相关文档并使用语言模型 (LLM) 生成响应来提供信息丰富的响应，但我想处理某些类型的查询，例如问候和礼貌交流，而无需借助 LLM 来提高效率和控制力。
具体来说，我想管理问候类型的问题，例如“你好”、“你好吗？”、 “早上好”等。这些问题通常是公式化的，不需要像更复杂的问题那样深入理解上下文。依靠 LLM 来处理这些问题可能会效率低下且过度。
是否有可能在没有 LLM 的情况下创建类似聊天机器人的问候交流系统？]]></description>
      <guid>https://stackoverflow.com/questions/78843382/handling-greet-type-of-questions-without-llm-in-rag</guid>
      <pubDate>Wed, 07 Aug 2024 11:17:51 GMT</pubDate>
    </item>
    <item>
      <title>如何继续创建视频描述模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</link>
      <description><![CDATA[我一直在尝试制作一个可以实时将视频转换为文本的应用程序。这意味着您可以将实时视频转换为文本。
首先，我尝试仅使用 gpt api，但当然速度很慢，而且远远达不到实时。然后我想到使用对象检测模型和 gpt 来生成视频描述，但问题是它非常不准确，因为只检测到了对象，但错过了背景或动作，我尝试过跟踪以及 yolo 的姿势模型，但这似乎也不起作用。那么，有什么建议可能有效吗？]]></description>
      <guid>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</guid>
      <pubDate>Wed, 07 Aug 2024 07:34:13 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 和 Opacus 用于差异隐私</title>
      <link>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</link>
      <description><![CDATA[在使用 Jupyter Notebook（可从此处获取）测试来自 TensorFlow 网站的示例代码时，我遇到了错误。您可以在此处找到我关于该错误的 SO 问题。
因此，我决定使用 PyTorch、Opacus 和 PySyft 为相同功能编写等效实现。然而，不幸的是，我又遇到了另一个错误。
下面是实现与 TensorFlow 网站中的示例代码相同功能的代码，但使用 PyTorch 和 Opacus 和 PySyft，以及错误消息。
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from opacus import PrivacyEngine

# 定义一个简单的模型
class SimpleCNN(nn.Module):
def __init__(self):
super(SimpleCNN, self).__init__()
self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
self.fc1 = nn.Linear(32*26*26, 10)

def forward(self, x):
x = torch.relu(self.conv1(x))
x = x.view(-1, 32*26*26)
x = self.fc1(x)
return torch.log_softmax(x, dim=1)

# 数据加载器
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = datasets.MNIST(&#39;.&#39;, train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 初始化模型、优化器和损失函数
model = SimpleCNN()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.NLLLoss()

# 初始化 PrivacyEngine
privacy_engine = PrivacyEngine(
model,
batch_size=64,
sample_size=len(train_loader.dataset),
epochs=1,
max_grad_norm=1.0,
)

privacy_engine.attach(optimizer)

# 训练循环
model.train()
for epoch in range(1):
for data, target in train_loader:
optimizer.zero_grad()
output = model(data)
loss = criterion(output, target)
loss.backward()
optimizer.step()

# 打印隐私统计数据
epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(1e-5)
print(f&quot;Epsilon: {epsilon}, Delta: 1e-5&quot;)

错误：
-------------------------------------------------------------------------------
TypeError Traceback (最近一次调用最后一次)
Cell In[1]，第 32 行
29 criterion = nn.NLLLoss()
31 # 初始化 PrivacyEngine
---&gt; 32 privacy_engine = PrivacyEngine(
33 model,
34 batch_size=64,
35 sample_size=len(train_loader.dataset),
36 epochs=1,
37 max_grad_norm=1.0,
38 )
40 privacy_engine.attach(optimizer)
42 # 训练循环

TypeError: PrivacyEngine.__init__() 获得了意外的关键字参数“batch_size”
]]></description>
      <guid>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</guid>
      <pubDate>Tue, 06 Aug 2024 13:17:08 GMT</pubDate>
    </item>
    <item>
      <title>如果训练数据集中的正样本多于负样本，XGBoost 的 scale_pos_weight 是否可以正确平衡正样本？</title>
      <link>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我相信 scale_pos_weight 会是一种更好的方法。
是否可以安全地假设，由于比率小于 1，它仍将正确平衡类别？特异性在我的研究中很重要，但我们的主要目标集中在召回率、精确度和 F1 分数上。此设置是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>f1 分数低且损失函数分数也低</title>
      <link>https://stackoverflow.com/questions/76812516/low-f1-score-and-also-low-loss-function-score</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76812516/low-f1-score-and-also-low-loss-function-score</guid>
      <pubDate>Tue, 01 Aug 2023 14:10:31 GMT</pubDate>
    </item>
    <item>
      <title>如何处理预测标签比例很重要的多标签分类问题？</title>
      <link>https://stackoverflow.com/questions/62597159/how-to-approach-a-multilabel-classification-problem-where-the-proportions-of-the</link>
      <description><![CDATA[我最初的任务是根据基因表达模式对各种细胞类型（类别）进行分类，而这个问题只是涉及从多个类别中预测一个标签。这很容易做到，因为我可以分配一个独热编码向量并训练神经网络。
现在的新问题是样本中可能混合了各种细胞（因此是多标签问题）。新的挑战不仅是检测多个标签，还要检测每个标签的比例。例如，如果总共有 3 个 cell_types，并且样本包含 2 个 cell_type_1、1 个 cell_type_2 和 1 个 cell_type_3，则分类器的输出应为 [0.50, 0.25, 0.25]，而不是 [1, 1, 1]。
从我所做的简短研究来看，有多种方法可以进行二元分类，但比例分类的方法并不多。我读过关于不同准确度函数的文章，例如精确匹配率和汉明损失，这些函数似乎对这类问题很有希望。还了解到最后一层的激活函数应该是 S 型函数，而不是 Softmax，因为 Softmax 会分配一个概率，而这个属性会削弱其识别多个标签的能力。我想知道，由于比例很重要，这是否会对我有利？
我想首先了解一下这个问题是否可能（我习惯于做分类），针对这个问题推荐的损失/准确度函数类型，各种架构（如果以前已经做得很好），以及任何其他建议/资源。此外，如果这可能有助于提供更多背景信息，我正在使用 R 中的 Keras。]]></description>
      <guid>https://stackoverflow.com/questions/62597159/how-to-approach-a-multilabel-classification-problem-where-the-proportions-of-the</guid>
      <pubDate>Fri, 26 Jun 2020 14:40:54 GMT</pubDate>
    </item>
    </channel>
</rss>