<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 20 Apr 2024 09:13:02 GMT</lastBuildDate>
    <item>
      <title>我正在尝试使用 grad-cam，但得到 ValueError: The layerequential has never be called and 因此没有定义的输入</title>
      <link>https://stackoverflow.com/questions/78357635/i-am-trying-to-use-grad-cam-but-get-valueerror-the-layer-sequential-has-never</link>
      <description><![CDATA[将张量流导入为 tf
将 numpy 导入为 np
导入CV2
从 keras.models 导入 load_model
模型 = load_model(r&#39;.\CNN.keras&#39;)
定义感兴趣的层（例如，conv2d_19）
图层名称=&#39;conv2d_1&#39;
创建一个输出所选层激活的模型
activation_model = tf.keras.Model(inputs=model.input,outputs=model.get_layer(layer_name).output)
生成示例输入图像（替换为您的实际数据）
input_image = np.random.rand(1, 120, 120, 3) # 示例形状，根据需要调整
获取输出相对于所选层的梯度
使用 tf.GradientTape() 作为磁带：
last_conv_layer_output =activation_model(input_image)

磁带.watch(last_conv_layer_output)

preds = 模型（输入图像）

top_class = tf.argmax(preds[0])

计算顶层类相对于所选图层的梯度
grads = Tape.gradient(preds[:, top_class], last_conv_layer_output)[0]
计算热图的权重
权重 = tf.reduce_mean(grads, axis=(0, 1))
将特征图乘以权重以获得热图
热图 = tf.reduce_sum(last_conv_layer_output * 权重, axis=-1)
调整热图大小以匹配输入图像大小
heatmap = cv2.resize(heatmap.numpy(), (input_image.shape[1], input_image.shape[2]))
标准化热图
热图 = np.maximum(热图, 0) / np.max(热图)
将热图叠加在原始图像上
热图 = cv2.applyColorMap(np.uint8(255 * 热图), cv2.COLORMAP_JET)
superimpose_img = cv2.addWeighted(input_image[0], 0.6, 热图, 0.4, 0)
显示或保存叠加图像
cv2.imshow(“Grad-CAM”, superimpose_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
这是我的代码，但我得到 ValueError: The Layerequential 从未被调用，因此没有定义的输入。
我希望从 grad-cam 获取热图，以便我可以可视化触发模型预测的图像部分]]></description>
      <guid>https://stackoverflow.com/questions/78357635/i-am-trying-to-use-grad-cam-but-get-valueerror-the-layer-sequential-has-never</guid>
      <pubDate>Sat, 20 Apr 2024 09:07:26 GMT</pubDate>
    </item>
    <item>
      <title>警告：由于元数据条目“名称”无效，正在跳过 C:\Users\abhis\AppData\Roaming\Python\Python312\site-packages\jupyter_client-8.6.0.dist-info</title>
      <link>https://stackoverflow.com/questions/78357455/warning-skipping-c-users-abhis-appdata-roaming-python-python312-site-packages</link>
      <description><![CDATA[我遇到了错误，希望得到解决该错误的帮助。有人可以提供有关如何解决此问题的指导吗？
它应该显示我的系统中安装的所有库列表，没有任何错误]]></description>
      <guid>https://stackoverflow.com/questions/78357455/warning-skipping-c-users-abhis-appdata-roaming-python-python312-site-packages</guid>
      <pubDate>Sat, 20 Apr 2024 08:09:54 GMT</pubDate>
    </item>
    <item>
      <title>对质谱数据库搜索结果进行分类的统计方法</title>
      <link>https://stackoverflow.com/questions/78357067/statistical-methods-for-classifying-mass-spectrometry-database-search-results</link>
      <description><![CDATA[作为一名新手，我想尝试生物信息学方面的一些东西，即用于对质谱数据库搜索结果进行分类的机器学习统计方法。然而，我未能获得用于此目的的公开数据。
我尝试在 NCBI 上搜索某种要使用的数据，但未能在本地计算机上下载和使用任何数据。]]></description>
      <guid>https://stackoverflow.com/questions/78357067/statistical-methods-for-classifying-mass-spectrometry-database-search-results</guid>
      <pubDate>Sat, 20 Apr 2024 05:17:15 GMT</pubDate>
    </item>
    <item>
      <title>使用自动调谐后，如何改进训练/验证图的准确性和损失？ （美国有线电视新闻网）</title>
      <link>https://stackoverflow.com/questions/78357031/how-can-i-improve-the-results-of-this-training-validation-graph-of-accuracy-and</link>
      <description><![CDATA[训练和验证准确性和损失图
我运行了我的 CNN 模型（7 个类、大约 33k 图像和 22 层）100 个 epoch，并得到了这张图。它不是扁平的，而是非常尖的。下面是我添加到模型中的图层。
模型 = 顺序（[
    数据增强，
    图层.重新缩放(1./255, input_shape=(img_height, img_width, 3)),
    层.Conv2D(16, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Conv2D(32, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Conv2D(64, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层数.Dropout(0.05),
    层.Conv2D(128, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Conv2D(256, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层数.Dropout(0.05),
    层.Conv2D(512, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Flatten(),
    层.密集（512，激活=&#39;relu&#39;），
    层数.Dropout(0.05),
    层.Dense(256, 激活=&#39;relu&#39;),
    层数.Dropout(0.05),
    层.Dense(128, 激活=&#39;relu&#39;),
    Layers.Dense(num_classes, name=&quot;outputs&quot;)
]）

这是我运行自动调整数据的方法
AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

这是使用自动调谐之前图表的样子
添加自动调谐之前的图表
虽然这个图表也不平坦，但它仍然比第一个图表好得多。如何使我的图表变平？
我不太确定如何正确展平图表。我只需要运行更多的纪元吗？]]></description>
      <guid>https://stackoverflow.com/questions/78357031/how-can-i-improve-the-results-of-this-training-validation-graph-of-accuracy-and</guid>
      <pubDate>Sat, 20 Apr 2024 04:55:34 GMT</pubDate>
    </item>
    <item>
      <title>在weka中重新采样过滤器</title>
      <link>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</link>
      <description><![CDATA[我的数据集中的数据实例数量很少。所以，我尝试了“重新采样” Weka中的过滤器可以增加数据量，从而提高模型性能。样本量百分比设置为200可以吗？因为那时我在交叉验证测试中获得了良好的相关系数。
我想知道将样本大小百分比设置为 200 时，重新采样过滤器是否工作正常。
使用此过滤器后，我的模型会准确预测吗？
由于数据量较少，是否有其他增强方法可以增强模型的性能？]]></description>
      <guid>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</guid>
      <pubDate>Sat, 20 Apr 2024 04:29:50 GMT</pubDate>
    </item>
    <item>
      <title>无法安装gensim模块</title>
      <link>https://stackoverflow.com/questions/78356738/unable-to-install-gensim-module</link>
      <description><![CDATA[我尝试在终端中运行“pip install gensim”命令，但发生了以下情况：
*ld_w2v_模型
运行 build_ext
构建“gensim.models.word2vec_inner”扩展
错误：需要 Microsoft Visual C++ 14.0 或更高版本。使用“Microsoft C++ 构建工具”获取它：https://visualstudio.microsoft。 com/visual-cpp-build-tools/
[输出结束]
注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：gensim 构建轮子失败
构建gen​​sim失败
错误：无法为 gensim 构建轮子，这是安装基于 pyproject.toml 的项目所必需的
*
我该如何解决此错误？
我尝试使用“pip install --use-pep517 gensim==3.8.0”命令并安装了它，但是，在运行我的实际 python 脚本时，模块的错误仍然发生：
回溯（最近一次调用最后一次）：
文件“C:\Users\Anuja Alice Thomas\Documents\CHRIST UNIVERSITY\Trimester 3\Java Planning\Assignments\Sample1\python.py”，第 4 行，位于
导入gensim
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim_init_.py”，第 5 行，位于
from gensim 导入解析、语料库、matutils、接口、模型、相似性、摘要、utils # noqa:F401
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\corpora_init_.py”，第 6 行，位于
from .indexedcorpus import IndexedCorpus # noqa:F401 必须出现在其他类之前
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\corpora\indexedcorpus.py”，第 15 行，位于
从 gensim 导入接口、utils
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\interfaces.py”，第 21 行，位于
从 gensim 导入 utils、matutils
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\matutils.py”，第 24 行，位于
从 scipy.linalg.special_matrices 导入 triu
ImportError: 无法从 &#39;scipy.linalg.special_matrices&#39; 导入名称 &#39;triu&#39; (C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\scipy\linalg\special_matrices.py) ]]></description>
      <guid>https://stackoverflow.com/questions/78356738/unable-to-install-gensim-module</guid>
      <pubDate>Sat, 20 Apr 2024 01:37:22 GMT</pubDate>
    </item>
    <item>
      <title>DQN 模型中从未实现的目标状态</title>
      <link>https://stackoverflow.com/questions/78356381/goal-state-never-achieved-in-dqn-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78356381/goal-state-never-achieved-in-dqn-model</guid>
      <pubDate>Fri, 19 Apr 2024 22:22:39 GMT</pubDate>
    </item>
    <item>
      <title>在SVM中，当超参数C增大时，margin会变大吗？</title>
      <link>https://stackoverflow.com/questions/78356095/in-svm-when-hyper-parameter-c-increases-the-margin-will-be-larger</link>
      <description><![CDATA[我目前正在研究SVM，发现关于超参数C和margin之间的关系有两种相反的解释。我知道在支持向量分类器中，C 限制 epsilon 的总和不能大于 C。问题是，我发布的第一张图片说当 C 增加时，边距会更大，但我发布的第二张图片和我发现的其他一些信息说边距会变窄。我很困惑。
在此处输入图像描述
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78356095/in-svm-when-hyper-parameter-c-increases-the-margin-will-be-larger</guid>
      <pubDate>Fri, 19 Apr 2024 20:43:04 GMT</pubDate>
    </item>
    <item>
      <title>使用邮递员使用临时凭证调用 Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/78356002/calling-sagemaker-endpoint-using-postman-using-temporary-credentials</link>
      <description><![CDATA[我已将 AWS CLI 配置为通过 SSO 使用配置文件。我已引用此文档 AWS 文档
我想使用邮递员调用 Sagemaker 端点。有没有办法做到。我尝试在邮递员中提供我的凭据，但它返回 404 错误。
一些额外的细节 -
Sagemaker 端点使用 VPC。]]></description>
      <guid>https://stackoverflow.com/questions/78356002/calling-sagemaker-endpoint-using-postman-using-temporary-credentials</guid>
      <pubDate>Fri, 19 Apr 2024 20:13:01 GMT</pubDate>
    </item>
    <item>
      <title>Llama2-7b 根据提示生成文本的运行时间较长</title>
      <link>https://stackoverflow.com/questions/78355789/llama2-7b-long-runtime-to-generate-text-from-a-prompt</link>
      <description><![CDATA[我已将 HuggingFace 中的 Llama2-7b 模型加载到我的计算机上，以根据简单的提示生成文本。该模型加载速度非常快（大约 2 分钟），但当我想从简单的提示中生成非常简单的响应时，例如“什么是 LLM？”该模型需要两个多小时才能生成响应。我需要它运行得更快，但不知道让它运行得更快有什么问题。有什么建议吗？
这是我的代码：
类 LlamaInference():
    “”“使用 Llama 70b 参数 LLM 的文本生成类。生成数据集。“”“
    def __init__(self, 输出文件路径):
        ”“”初始化 LlamaInference 类和所有变量
        关键字参数：
        output_file_path -- 数据集生成后输出文件的位置
        ”“”
        self.output_file_path = 输出文件路径
        self.pipeline = 无
        self.output_list = []
        self.output_list_condensed = []

    def __set_up(自我):
        ”“”使用特定模型和修订版设置 Huggingface 管道
        ”“”
        #model =“meta-llama/Llama-2-70b-chat-hf”
        #revision =“e6152b720bd3cd67afc66e36d06893a0e1f84b48”
        模型=“meta-llama/Llama-2-7b-chat-hf”
        修订版=“08751db2aca9bf2f7f80d2e516117a53d7450235”


    
        self.tokenizer = AutoTokenizer.from_pretrained(模型, padding_side=“左”)

        self.pipeline = 变压器.pipeline(
            “文本生成”，
            型号=型号，
            分词器=self.分词器，
            torch_dtype=torch.float16,
            device_map=“自动”，
            修订=修订，
            do_sample=真，
            return_full_text=False
        ）
        self.pipeline.tokenizer.pad_token_id = self.tokenizer.eos_token_id


    def gen_text(自我，提示，**kwargs)：
        ”“”根据提示生成文本

        关键字参数：
        提示——我们向法学硕士提出的问题
        **kwargs——传递给 self.pipeline 的参数
        ”“”
        尝试：
            如果 self.pipeline 为 None：
                self.__set_up()
            如果“batch_size”是不在 kwargs 中：
                kwargs[“batch_size”] = 1
            
            如果“max_new_tokens”是不在 kwargs 中：
                kwargs[“max_new_tokens”] = 2048

            kwargs.update(
                {
                    “pad_token_id”：self.pipeline.tokenizer.eos_token_id，
                    “eos_token_id”：self.pipeline.tokenizer.eos_token_id，
                }
            ）
            显示（&#39;启动管道&#39;）
            token_outputs = self.tokenizer(提示)
            显示（令牌输出）
            输出= self.pipeline（提示，**kwargs）
            显示(&#39;结束管道&#39;)
            返回输出
        除了异常作为错误：
            显示（f&#39;__gen_text错误：{错误}&#39;）

推理 = LlamaInference(&#39;test.json&#39;)
结果 = inference.gen_text(“你好”，max_new_tokens=2048，batch_size=1，温度=0.5)
]]></description>
      <guid>https://stackoverflow.com/questions/78355789/llama2-7b-long-runtime-to-generate-text-from-a-prompt</guid>
      <pubDate>Fri, 19 Apr 2024 19:18:13 GMT</pubDate>
    </item>
    <item>
      <title>从 torchensemble 中的基本模型获取嵌入</title>
      <link>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</guid>
      <pubDate>Fri, 19 Apr 2024 18:25:20 GMT</pubDate>
    </item>
    <item>
      <title>在序列模型中使用归一化层时，adapt() 会出错吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</link>
      <description><![CDATA[在顺序模型中使用归一化层时，通过适应（），我收到了未绑定错误：
这是错误
我做了以下事情：
标准化器 = 标准化()
标准化器.adapt(X_train)

但这给出了以下错误：
未绑定错误：赋值前引用了局部变量“input_shape”。
为什么我会收到此错误？如果不是这样，还有其他方法可以标准化神经网络中的数据吗？]]></description>
      <guid>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</guid>
      <pubDate>Fri, 19 Apr 2024 17:04:02 GMT</pubDate>
    </item>
    <item>
      <title>请为我的毕业设计解决机器学习中牙齿分割模型的Valueerror</title>
      <link>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</link>
      <description><![CDATA[大家好，我从 此处。
该程序应为用户提供两种选择：

从图像中读取并提取特征：此选项使用 FeatureExtraction 模块从图像中提取 9 个特征（包括图像名称）。
读取预先存在的数据集：此选项读取包含 labels.csv、features.csv 和图像文件的数据集。然后它会询问用户：

执行程序的次数（假设为 5）。
使用 K 折交叉验证分割数据所需的折叠数（假设为 5 折叠，即 k=5）。
测试数据集的大小（假设为 20%）。



模型然后将这些参数传递给classification模块中的分类函数。这就是问题出现的地方：

代码将整个数据集传递给 onlyfiles，其中包含 973 个条目。
然后，它会从 labels.csv（有 778 个条目）中识别 images_name 和 label_color。这代表训练数据集，因为我们之前指定了 20% 的测试集（778 = 973 的 80%）。
以下 for 循环迭代由 k_folds.split(images_name) 生成的分割。此时，我们仍在处理训练数据集，并且当 k=5 时，应该有：

train_index 中有 662 个索引（用于训练数据）。
test_index 中有 156 个索引（用于在训练集中进行验证）。



这是下一个 for 循环中发生错误的位置：
对于 train_index 中的 i：
    current_filename = onlyfiles[i].split(&#39;.&#39;)[0].strip()
    如果 current_filename 在训练数据集中：
        # ...（其余代码）
    别的：
        print(f“警告：在 images_name 中找不到‘{current_filename}’，因为它的索引是 {i}.train。”)


第一行根据 train_index 中的索引 i 检索文件名 (current_filename)。假设 i 为 324，train_index 包含从 156 到 777 的索引（而 test_index 范围从 0 到 155）。
出现此错误的原因是，有时循环会尝试在 images_name 中查找 current_filename，但该文件并不存在。这是因为 images_name 只有 778 个条目（训练数据），其余 195 个条目（测试数据）不包括在内。因此，current_filename 实际上可能属于测试数据集，从而导致错误“101_0032.JPG 不在列表中”。

我尝试对列表进行排序并删除随机播放（在 k_folds.split 中设置 shuffle=False），但错误仍然存​​在。我非常感谢您为解决此问题提供一些帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</guid>
      <pubDate>Thu, 18 Apr 2024 23:03:02 GMT</pubDate>
    </item>
    <item>
      <title>流式 LightGBM 数据集构建在训练中冻结</title>
      <link>https://stackoverflow.com/questions/78344537/streaming-lightgbm-dataset-construction-freezes-on-training</link>
      <description><![CDATA[我一直在尝试使用参考数据集（称为 ref_dataset）以流方式在 Python 中构建 LightGBM 数据集。我不确定它是如何完成的，它涉及调用 Dataset 类中看似非公共的方法。
我已经尝试过：
label_column = “标签”
权重列=“权重”
ref_dataset = lightgbm.Dataset(
   Sample_df.drop(列=[标签列，权重列])
   标签=sample_df[标签_列],
   权重=sample_df[权重列],
   参数=配置，
   **（ref_dataset_kwargs 或 {}），
）
ref_dataset.construct()
temp_dataset = lightgbm.Dataset（无，参考= ref_dataset，params = ref_dataset.get_params（））
# train_filenames_and_part_infos 只是一个元组列表[filename,part_info_dict]
估计行数=总和（
    part_info[“num_rows”] for _，train_filenames_and_part_infos 中的part_info
）
temp_dataset._init_from_ref_dataset(estimated_num_rows, ref_dataset._handle)

权重列表 = []
标签列表=[]
# 这个循环实际上不是我的代码，它更复杂，但基本上是它的作用
对于文件名，train_filenames_and_part_infos 中的 _：
    tbl: pyarrow.Table = load_from_file(文件名)
    标签 = tbl[label_column].to_pandas().to_numpy()
    权重 = tbl[weight_column].to_pandas().to_numpy()

    labels_list.append(标签)
    weights_list.append(权重)
    tbl = tbl.drop_columns([label_column, Weight_column])
    np_array: np.ndarray = tbl.to_pandas().to_numpy()
    如果 temp_dataset._start_row + np_array.shape[0] &gt; temp_dataset.num_data()：
        raise RuntimeError(“数据集太小，无法容纳数据”)
    temp_dataset._push_rows(np_array)

all_weights = np.concatenate(weights_list)
all_labels = np.concatenate(labels_list)
实际长度 = all_weights.shape[0]
# 不幸的是，由于各种原因，这个估计并不准确
extra_zeros_features = np.zeros(
     （估计行数 - 实际长度，temp_dataset.num_feature()），dtype=np.float32
）
temp_dataset._push_rows(extra_zeros_features)
_LIB.LGBM_DatasetMarkFinished(temp_dataset._handle)
extra_zeros = np.zeros(估计行数 - 实际长度, dtype=np.float32)
temp_dataset.set_weight(np.concatenate([all_weights, extra_zeros]))
temp_dataset.set_label(np.concatenate([all_labels, extra_zeros]))

lightgbm.train(
    params=config, # 包含分布式投票并行训练的网络参数
    train_set=temp_dataset，
    num_boost_round=100,
    valid_sets=valid_sets, # 在其他地方初始化
    valid_names=valid_names, # 在其他地方初始化
    init_model=starting_model, # 不是很有必要
    **lightgbm_train_kwargs, # 空
）

不幸的是，当我运行这段代码时，我得到了这个控制台输出（有些行可能是无序的，因为我实际上是在分布式上运行它，并且日志是聚合的；我已经做了一些简单的编辑删除干扰线）：
[LightGBM] [Info] 总 bin 137618
[LightGBM] [Info] 尝试绑定端口 50627...
[LightGBM] [Info] 绑定端口50627成功
[LightGBM] [信息] 聆听...
[LightGBM] [Info] 训练集中的数据点数量：3934363，使用的特征数量：1382
[LightGBM] [信息] 连接到等级 0
[LightGBM] [信息] 连接到排名 1
[LightGBM] [信息] 连接到等级 2
[LightGBM] [信息] 连接到等级 3
[LightGBM] [信息] 连接到等级 4
[LightGBM] [信息] 已连接至排名 5
[LightGBM] [信息] 已连接至排名 6
[LightGBM] [信息] 已连接至排名 8
[LightGBM] [Info] 本地排名：7，机器总数：9
[LightGBM] [Info] 自动选择col-wise多线程，测试开销为5.318313秒。
[LightGBM] [Info] 从分数-0.000000开始训练

然后它就坐在那里，CPU 和网络都处于空闲状态。我没有看到它在几个小时内取得任何进展。我已经检查了所有的排名，是不是我做错了什么？我还如何使用给定的样本进行构建？
更多信息：
检查空闲 Python 进程的堆栈跟踪显示代码卡在：
更新（lightgbm/basic.py:3891）
火车（lightgbm/engine.py:276）
...我的代码...

对于我正在使用的 LightGBM 版本 (4.3.0)，这对应于代码：
_safe_call(_LIB.LGBM_BoosterUpdateOneIter(
                self._handle,
                ctypes.byref(is_finished)))

另一个更新：
工人之间的垃圾箱数量似乎有所不同；有些有 137608、137612、137616。这是一个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78344537/streaming-lightgbm-dataset-construction-freezes-on-training</guid>
      <pubDate>Thu, 18 Apr 2024 02:25:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 OpenCV 和 Mediapipe 实现逼真的唇色变化？</title>
      <link>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</guid>
      <pubDate>Mon, 20 Mar 2023 17:50:46 GMT</pubDate>
    </item>
    </channel>
</rss>