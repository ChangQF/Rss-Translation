<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 07 Aug 2024 09:17:20 GMT</lastBuildDate>
    <item>
      <title>如何继续创建视频描述模型？</title>
      <link>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</link>
      <description><![CDATA[我最近一直在尝试制作一个可以实时将视频转换为文本的应用程序。这意味着您可以将实时视频转换为文本。
首先，我尝试只使用 gpt api，但当然速度很慢而且远没有达到实时，然后我想到使用对象检测模型和 gpt 来生成视频描述，但问题是它非常不准确，因为只检测到了对象，但错过了背景或动作，我尝试过跟踪以及 yolo 的姿势模型，但这似乎也不起作用。所以我想我会尝试在这里询问任何可能有用的建议？]]></description>
      <guid>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</guid>
      <pubDate>Wed, 07 Aug 2024 07:34:13 GMT</pubDate>
    </item>
    <item>
      <title>无需深度学习或 Tesseract 的文本图像二元分类器</title>
      <link>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</link>
      <description><![CDATA[我有 20k 张小标签图像，每张图像都有单词“Back”或“Front”。
图像分辨率为全部 (200px, 25px)

我可以使用 tesseract_OCR 对这些图像进行 100% 准确率的分类。
 txt = pytesseract.image_to_string(img, lang=&#39;eng&#39;)
if &quot;Front&quot; in txt:
return &quot;Front&quot;
if &quot;Back&quot; in txt:
return &quot;Back&quot;

问题是，它太慢了（20k 张图像需要 1 小时）并且需要安装 OCR 包。
我知道即使是 3 层的简单 CNN 也能很好地运行，但我认为这个问题似乎可以用简单的算法解决，而不需要复杂的技术。
你能给我推荐一种新方法吗？
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</guid>
      <pubDate>Wed, 07 Aug 2024 06:46:36 GMT</pubDate>
    </item>
    <item>
      <title>对于暴露的情况，孪生网络是否是正确的算法？[关闭]</title>
      <link>https://stackoverflow.com/questions/78842114/is-a-siamese-network-the-right-algorithm-for-the-exposed-case</link>
      <description><![CDATA[我的数据库中存储了 20,000 多张艺术品图片（绘画、雕塑、罐子等）。实际作品分布在多个仓库中。理想情况下，实物应该贴上标签（带有其 ID、QR 码等），这些标签是纸质的，因此可能会受损、印刷不良、无法读取、完全丢失甚至放错位置。我的目标是创建一个模型，该模型接收输入（任何仓库的某人发送的图像），从可用数据中识别完全相同的艺术品并返回其 ID、详细信息等。
在我的例子中，样本是静态的、固定的（不会有“新”艺术品，除非客户购买更多），因此模型永远不会“看到”新图像，这让我认为过度拟合可能是模型最理想的结果（这意味着大量的数据增强和大量的 epoch）。
请注意，每个类（艺术作品）只有一个图像可用。这就是无法改变的情况。
所选的编程语言是 R，主要是 tensorflow 和 keras3 库。
话虽如此，我很难找到解决方案，因为每个文档都依赖于相同的 cat vs dogs 或 mnist 数据集。我的问题是：

暹罗网络是否是用于此目的的正确算法？
我可以采取哪些方法来提高准确性？

仅出于测试目的，我抽取了 10 个样本，从每个样本中生成了 9 个其他样本（数据增强、应用旋转、垂直/水平翻转、随机饱和度因子、随机亮度因子等）。后来，为每个类别创建了 5 个正对和 5 个负对。最后，我运行了一个暹罗网络，但准确率似乎停留在 49%。]]></description>
      <guid>https://stackoverflow.com/questions/78842114/is-a-siamese-network-the-right-algorithm-for-the-exposed-case</guid>
      <pubDate>Wed, 07 Aug 2024 06:29:33 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 张量与标量相乘后丢失requires_grad</title>
      <link>https://stackoverflow.com/questions/78841738/pytorch-tensor-losing-requires-grad-after-multiplication-with-a-scalar</link>
      <description><![CDATA[我正在开展一个深度学习项目，并试图实现一个投影网络。简而言之，我有一个根据某些损失函数输出值的神经网络。如果这些值不满足所有约束，我想将它们放入梯度下降网络（损失为 ReLU（需要 - 已实现））。在下面的代码中，我用 p 和 phi 参数（第一个网络输出的值）初始化投影网络并希望它们进行训练。但是，我遇到了 p 和 phi（theta）变量都失去梯度跟踪的问题，导致损失没有梯度跟踪。如果这很简单，我深表歉意，因为我对 Pytorch 还很陌生，在网上找不到任何东西。
投影 nn 的代码：
class Projection(nn.Module):
def __init__(self, p, phi):
super().__init__()
self.p = nn.Parameter(p.clone().detach().requires_grad_(True))
self.phi = nn.Parameter(phi.clone().detach().requires_grad_(True))

def forward(self, u, g, v):
print(self.p.requires_grad, self.phi.requires_grad) ## 均为 true
p = self.p * P_max
print(p.requires_grad) # 在此点之后为 false
p = p.view(batch_size, K, 1)
sig = torch.nn.Sigmoid()
theta = torch.diag_embed(torch.exp(sig(self.phi) * 2 * torch.pi * 1j))
print(theta.requires_grad) # 在此点之后为 false
gh = torch.conj(torch.transpose(g,-1,-2))
print(gh.shape, theta.shape, v.shape)
term = torch.matmul(torch.matmul(gh, theta), v)
u_tilde = torch.add(u, term)
print(u_tilde.shape, p.shape)
harvested = eta * torch.matmul(torch.square(torch.abs(torch.transpose(u_tilde, -1, -2))), p) * 1e6
ReLU = torch.nn.ReLU()
diff = e_min_gen - harvested
loss = torch.sum(ReLU(diff))
print(loss.requires_grad)
return loss

P_max 声明如下：
P_max = 0.5
我特别困惑，因为在同一个项目中我使用梯度下降来生成可行数据。模型如下：
class Descent(nn.Module):
def __init__(self):
super().__init__()
self.weight = nn.Parameter(torch.randn(N, require_grad=True))

def forward(self, u, g, phi, v, p):
phi = phi * self.weight
sig = torch.nn.Sigmoid()
theta = torch.diag_embed(torch.exp(sig(phi) * 2 * torch.pi * 1j))
gh = torch.conj(torch.transpose(g,-1,0))
term = torch.mm(torch.mm(gh, theta), v)
u_tilde = torch.add(u, term)
harvested = eta * torch.matmul(torch.square(torch.abs(torch.transpose(u_tilde, 0, 1))), p) * 1e6
ReLU = torch.nn.ReLU()
diff = e_min_gen - harvested
loss = torch.sum(ReLU(diff))
return loss

此模型保留 require_grad 直到最后。
任何解决方法都将不胜感激。感谢您的时间。
我尝试查找梯度跟踪丢失的原因。我已经准确地确定了跟踪停止的点。如果我不将 self.p 乘以 P_max，则 p 的 gradient_tracking=True。]]></description>
      <guid>https://stackoverflow.com/questions/78841738/pytorch-tensor-losing-requires-grad-after-multiplication-with-a-scalar</guid>
      <pubDate>Wed, 07 Aug 2024 03:39:37 GMT</pubDate>
    </item>
    <item>
      <title>如何最好地将 ML 模型集成到 Web 应用程序？</title>
      <link>https://stackoverflow.com/questions/78841736/how-to-best-integrate-ml-models-to-web-application</link>
      <description><![CDATA[我没有机器学习经验，是 Web 应用程序编程的新手。我目前有一个使用 audiocraft 和分类模型的 flask 应用程序。目前我已将它们本地存储在应用程序文件夹中。我已构建此应用程序的映像，结果显示它有 7GB。
有没有办法将这些模型/框架存储在其他地方，并且仅在需要时引用它们？
此外，当我在 docker 上运行容器时，从 audiocraft 生成 8 秒音频大约需要 10 分钟。您建议我做什么来加快这个过程？
music_generation\routes.py（片段）
def load_model():
model = MusicGen.get_pretrained(&#39;facebook/musicgen-small&#39;)
return model

def generate_music_tensors(description, duration: int):
model = load_model()
model.set_generation_params(
use_sampling=True,
top_k=250,
duration=duration
)
output = model.generate(
descriptions=[description],
progress=True,
return_tokens=True
)
return output[0]

@music_generation_bp.route(&#39;/&#39;, methods=[&#39;POST&#39;])
def generate_music():
data = request.json

description = data.get(&#39;description&#39;)
duration = data.get(&#39;duration&#39;, 8) # 如果未提供，则默认为 8 秒
print(&quot;Description:&quot;, description)
print(&quot;Duration:&quot;, duration)

如果没有 description:
return jsonify({&#39;error&#39;: &#39;Description is required&#39;}), 400
# 为用户生成唯一密钥
user_id = str(uuid.uuid4()) # 或使用来自身份验证系统的用户 ID
audio_key_prefix = f&quot;generated_music_{user_id}_{description}&quot;

# 生成音乐张量
music_tensors = generate_music_tensors(description, duration)
print(&quot;Music Tensors: &quot;, music_tensors)
...


image_classification\routes.py (代码片段)
# 加载预训练模型
model_path = os.path.join(MODELS_DIR, &#39;multi_output_model.h5&#39;)
model = tf.keras.models.load_model(model_path)

@image_classification_bp.route(&#39;/&#39;, methods=[&#39;POST&#39;])
@limiter.limit(&quot;1/minute&quot;)
def classify_image():
if &#39;file&#39; not in request.files:
return jsonify({&quot;error&quot;: &quot;No file part in the request&quot;}), 400

file = request.files[&#39;file&#39;]

if file.filename == &#39;&#39;:
return jsonify({&quot;error&quot;: &quot;No selected file&quot;}), 400

#file = os.path.join(TEST_IMG_DIR, &#39;blue-dress2.png&#39;)

if file:
# 读取图像文件
img = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_UNCHANGED)
img = cv2.resize(img, (IMAGE_DIMS[1], IMAGE_DIMS[0]))
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img = preprocess_input(img)
img = np.expand_dims(img, axis=0)

# 执行预测
predictions = model.predict(img)

]]></description>
      <guid>https://stackoverflow.com/questions/78841736/how-to-best-integrate-ml-models-to-web-application</guid>
      <pubDate>Wed, 07 Aug 2024 03:39:15 GMT</pubDate>
    </item>
    <item>
      <title>当我导入库时，为什么我的代码会出现错误“sklearn 未定义”？</title>
      <link>https://stackoverflow.com/questions/78841652/why-is-my-code-giving-error-sklearn-not-defined-when-i-have-imported-the-libra</link>
      <description><![CDATA[我的代码：
import numpy as np
import pandas as pd
import pickle as pk
from sklearn import linear_model
from sklearn.utils import shuffle

data = pd.read_csv(&quot;student-mat.csv&quot;, sep=&quot;;&quot;)
data = data[[&quot;G1&quot;, &quot;G2&quot;, &quot;G3&quot;, &quot;studytime&quot;, &quot;failures&quot;, &quot;absences&quot;]]
print(data.head())
predict = &quot;G3&quot;
x = np.array(data.drop(predict, axis=1))
y = np.array(data[predict])
x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.1)
linear = linear_model.LinearRegression()
linear.fit(x_train, y_train)
acc = linear.score(x_test, y_test)
print(acc)
with open(&quot;studentmodel.pickle&quot;, &quot;wb&quot;) as f:
pickle.dump(linear,f)
pickle_in = open(&quot;studentmodel.pickle&quot;, &quot;rb&quot;)
linear = pickle.load(pickle_in)
print(&quot;coefficient:\n&quot;, linear.coef_)
print(&quot;intercept:\n&quot;, linear.intercept_)`

当我运行此代码时，它会抛出错误 name sklearn is not defined。但是，这很奇怪，因为我导入了正确的 sklearn 库。
完整错误：
NameError Traceback（最近一次调用最后一次）
Cell In[1]，第 14 行
12 x = np.array(data.drop(predict, axis=1))
13 y = np.array(data[predict])
---&gt; 14 x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, test_size=0.1)
15 linear = linear_model.LinearRegression()
16 linear.fit(x_train, y_train)

NameError：名称“sklearn”未定义
]]></description>
      <guid>https://stackoverflow.com/questions/78841652/why-is-my-code-giving-error-sklearn-not-defined-when-i-have-imported-the-libra</guid>
      <pubDate>Wed, 07 Aug 2024 02:46:41 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助在 Adruino Nano RP2040 Connect 上运行 CNN 模型</title>
      <link>https://stackoverflow.com/questions/78841395/need-help-to-run-a-cnn-model-on-an-adruino-nano-rp2040-connect</link>
      <description><![CDATA[我正在尝试在 Arduino Nano RP2040 Connect 上运行一个检测咳嗽和打喷嚏的 CNN 模型（使用 Tensorflow 开发），我的模型的输入是大小为 (603,28,1) 的频谱图。但是，我对嵌入式编程还比较陌生，想得到一些关于音频处理和特征提取以及在 Arduino 上运行 CNN 模型等问题的指导。
问题 1：
在此设备上，它有一个称为 PDM 的音频库，可以捕获音频数据并读入特定大小的缓冲区数组，每个索引都是一个 16 位整数，使用此缓冲区数组，我如何将其转换为频谱图以及如何将其调整为正确的大小 (603,28,1) 以输入到我的模型中。
问题 2：
我需要在频谱图图像上运行我的模型，有没有专门用于 Arduino 的 Tensorflow 库？
此外，如果您可以让我了解您在这个项目上的实施流程，那就太好了。]]></description>
      <guid>https://stackoverflow.com/questions/78841395/need-help-to-run-a-cnn-model-on-an-adruino-nano-rp2040-connect</guid>
      <pubDate>Tue, 06 Aug 2024 23:58:45 GMT</pubDate>
    </item>
    <item>
      <title>什么是Tokens、Top K、Top P？</title>
      <link>https://stackoverflow.com/questions/78841275/what-are-tokens-top-k-and-top-p</link>
      <description><![CDATA[我正在学习使用 Google AI Studio，在生成代码片段时，我遇到了这些术语：
constgenerationConfig = {
temperature: 1,
topP: 0.95,
topK: 64,
maxOutputTokens: 8192,
responseMimeType:&quot;text/plain&quot;,
};

我很难理解这些术语的含义。topP、topK 和 maxOutputTokens 是什么。我想了解这些，以便正确使用它们。]]></description>
      <guid>https://stackoverflow.com/questions/78841275/what-are-tokens-top-k-and-top-p</guid>
      <pubDate>Tue, 06 Aug 2024 22:55:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 Hugging Face Transformers 训练 GPT-2 模型时如何修复分段错误？</title>
      <link>https://stackoverflow.com/questions/78841125/how-to-fix-segmentation-fault-when-training-gpt-2-model-using-hugging-face-trans</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78841125/how-to-fix-segmentation-fault-when-training-gpt-2-model-using-hugging-face-trans</guid>
      <pubDate>Tue, 06 Aug 2024 21:47:06 GMT</pubDate>
    </item>
    <item>
      <title>Coral Ordinal AttributeError：'str' 对象没有属性 'name'</title>
      <link>https://stackoverflow.com/questions/78840945/coral-ordinal-attributeerror-str-object-has-no-attribute-name</link>
      <description><![CDATA[我正在开发一个使用 Python 和 Tensorflow 中的有序回归/分类的项目。我发现 pip 包 coral-ordinal 实现了有序回归并包含有用的损失函数。然而，当我浏览他们的 Google Colab 教程时，我得到了错误
AttributeError: &#39;str&#39; 对象没有属性 &#39;name&#39; 

运行 model.fit() 时。
当我尝试在其他代码中使用它时也会出现此错误。发生错误之前的代码如下
import tensorflow as tf
print(&quot;Tensorflow version&quot;, tf.__version__)

import coral_ordinal as coral
print(&quot;CORAL Ordinal version:&quot;, coral.__version__)

############################
### SETTINGS
############################

# 超参数
random_seed = 1 # 尚未使用
learning_rate = 0.05
batch_size = 128
num_epochs = 2

# 架构
NUM_CLASSES = 10

# 获取并格式化 mnist 数据
(mnist_images, mnist_labels), (mnist_images_test, mnist_labels_test) = tf.keras.datasets.mnist.load_data()

# 拆分验证数据集以进行早期停止
from sklearn import model_selection
mnist_images, mnist_images_val, mnist_labels, mnist_labels_val = \
model_selection.train_test_split(mnist_images, mnist_labels, test_size = 5000, random_state = 1)

print(&quot;训练图像的形状：&quot;, mnist_images.shape)

print(&quot;训练标签的形状：&quot;, mnist_labels.shape)

print(&quot;测试图像的形状：&quot;, mnist_images_test.shape)

print(&quot;测试标签的形状：&quot;, mnist_labels_test.shape)

print(&quot;验证图像的形状：&quot;, mnist_images_val.shape)
print(&quot;验证标签的形状：&quot;, mnist_labels_val.shape)

# 也重新调整为 0-1 范围。
dataset = tf.data.Dataset.from_tensor_slices(
(tf.cast(mnist_images[..., tf.newaxis] / 255, tf.float32),
tf.cast(mnist_labels, tf.int64)))
dataset = dataset.shuffle(1000).batch(batch_size)

test_dataset = tf.data.Dataset.from_tensor_slices(
(tf.cast(mnist_images_test[..., tf.newaxis] / 255, tf.float32),
tf.cast(mnist_labels_test, tf.int64)))
#test_dataset = test_dataset.shuffle(1000).batch(batch_size)
# 这里我们不对测试数据集进行打乱。
test_dataset = test_dataset.batch(batch_size)

val_dataset = tf.data.Dataset.from_tensor_slices(
(tf.cast(mnist_images_val[..., tf.newaxis] / 255, tf.float32),
tf.cast(mnist_labels_val, tf.int64)))
val_dataset = val_dataset.shuffle(1000).batch(batch_size)

def create_model(num_classes):
model = tf.keras.Sequential()
model.add(tf.keras.layers.Flatten(input_shape = (28, 28, )))
model.add(tf.keras.layers.Dense(128, 激活 = &quot;relu&quot;))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(32,activation = &quot;relu&quot;))
model.add(tf.keras.layers.Dropout(0.1))
# 具有一定数量的类别/等级/标签的有序输出层。
# 未指定激活函数，因此将输出累积对数。
model.add(coral.CoralOrdinal(num_classes))
return model

model = create_model(NUM_CLASSES)

# 请注意，模型生成的输出比类别数量少 1。
model.summary()

model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),
loss = coral.OrdinalCrossEntropy(num_classes = NUM​​_CLASSES),
metrics = [coral.MeanAbsoluteErrorLabels()])

# 这在 CPU 上大约需要 5 分钟，在 GPU 上大约需要 2.5 分钟。
history = model.fit(dataset, epochs = 5, validation_data = val_dataset,
callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)])

如何解决这个问题？我会在他们的 github 上提出问题，但最后一次回复是 2 年前，所以我怀疑维护者是否会回复。
或者，如果没有任何现实的选择来完成这项工作，是否有任何替代方案可以帮助 tensorflow 中的有序回归/分类？]]></description>
      <guid>https://stackoverflow.com/questions/78840945/coral-ordinal-attributeerror-str-object-has-no-attribute-name</guid>
      <pubDate>Tue, 06 Aug 2024 20:41:21 GMT</pubDate>
    </item>
    <item>
      <title>我们如何才能优化 Longformer 模型以提高效率，同时又不损害 NLP 任务中的长期上下文理解？</title>
      <link>https://stackoverflow.com/questions/78835795/how-can-we-optimize-longformer-models-for-efficiency-without-compromising-long-t</link>
      <description><![CDATA[Longformer 模型使用全局和局部注意力机制的混合来处理长序列，使其适合于文档分类、摘要和共指解析等任务。优化这些模型涉及平衡计算效率与维护长期上下文的需求。
可以应用哪些特定技术或修改来增强 Longformer 模型的性能？
是否有特定的训练策略、修剪方法或硬件考虑因素可以帮助实现这种平衡？深入了解 Longformer 模型已成功优化的实际实施和案例研究将非常有价值。]]></description>
      <guid>https://stackoverflow.com/questions/78835795/how-can-we-optimize-longformer-models-for-efficiency-without-compromising-long-t</guid>
      <pubDate>Mon, 05 Aug 2024 17:47:13 GMT</pubDate>
    </item>
    <item>
      <title>yolov9 在自定义数据上进行训练</title>
      <link>https://stackoverflow.com/questions/78834445/yolov9-training-on-custom-data</link>
      <description><![CDATA[我正尝试在 PyCharm 而不是 google colab 上用一些自定义数据训练 yolov9。我该怎么做？
将存储库克隆到我的计算机后，我在虚拟环境中安装了所有要求。然后我创建了训练脚本，但我觉得有些短。
这是我的训练脚本：
import os
import subprocess

dataset_path = &#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject&#39;

def train_yolov5(train_images_path, val_images_path, yaml_file_path, weights_path=&#39;C:/Users/rsingh/Desktop/Musa_PDC/yolov9-main/yolov9-c.pt&#39;, epochs=50):

# 获取 yolov5 目录的绝对路径
yolov9_dir = os.path.abspath(&#39;C:/Users/rsingh/Desktop/Musa_PDC/yolov9-main&#39;)

# 将当前工作目录更改为 yolov9 目录
os.chdir(yolov9_dir)
# 训练 yolov9 模型
command = f&#39;python train.py --workers 8 --device cpu --batch 16 --data {dataset_path}/sfdV2_musa.yaml --img 640 --cfg models/detect/yolov9-c.yaml --weights yolov9-c --hyp hyp.scratch-high.yaml --min-items 0 --epochs 5 --close-mosaic 15&#39;

# 执行命令
process = subprocess.Popen(command, shell=True)
process.wait()

if __name__ == &quot;__main__&quot;:
TRAIN_IMAGES_PATH = (
&#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject/captured_images/images/train&#39;)
VAL_IMAGES_PATH = (
&#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject/captured_images/images/val&#39;)
YAML_FILE_PATH = (
&#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject/sfdV2_musa.yaml&#39;)

# 训练 YOLOv9 模型
train_yolov5(TRAIN_IMAGES_PATH, VAL_IMAGES_PATH, YAML_FILE_PATH)`

我在运行训练脚本时收到此未来错误，并且我正在努力解决该错误：FutureWarning：torch.cuda.amp.autocast(args...) 已弃用。请改用 torch.amp.autocast(&#39;cuda&#39;, args...)。使用 torch.cuda.amp.autocast(amp)]]></description>
      <guid>https://stackoverflow.com/questions/78834445/yolov9-training-on-custom-data</guid>
      <pubDate>Mon, 05 Aug 2024 12:28:07 GMT</pubDate>
    </item>
    <item>
      <title>nltk 是适合 NLP 的优秀 Python 库吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78831441/is-nltk-good-python-library-for-nlp</link>
      <description><![CDATA[我不确定是否应该使用 TensorFlow 或 NLTK 来完成我的 NLP 任务。两者似乎都是很受欢迎的选择，但我不清楚哪一个更适合我这个水平的人。
TensorFlow 似乎是一个功能强大的库，它提供了广泛的机器学习和深度学习工具，包括对神经网络和大规模机器学习模型的支持。它似乎用途广泛，可用于复杂的 NLP 任务，如情绪分析、文本生成和翻译。但是，我不知道它对于像我这样的初学者来说是否太高级了，因为我读到过它的学习曲线很陡峭。
另一方面，NLTK（自然语言工具包）通常推荐给那些刚接触 NLP 的人。它为基本的 NLP 任务（如标记化、解析和词干提取）提供了易于使用的界面和功能。它似乎更侧重于传统的 NLP 方法，可以作为理解文本处理和分析基础知识的一个很好的起点。
我寻求指导，在转向 TensorFlow 之前，我是否应该从 NLTK 开始，在 NLP 中打下坚实的基础，或者我是否应该考虑采用其他方法。]]></description>
      <guid>https://stackoverflow.com/questions/78831441/is-nltk-good-python-library-for-nlp</guid>
      <pubDate>Sun, 04 Aug 2024 15:28:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 Skip-Gram 实现产生了错误的结果？</title>
      <link>https://stackoverflow.com/questions/78824197/why-is-my-skip-gram-implementation-producing-incorrect-results</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78824197/why-is-my-skip-gram-implementation-producing-incorrect-results</guid>
      <pubDate>Fri, 02 Aug 2024 07:15:07 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的激活函数[关闭]</title>
      <link>https://stackoverflow.com/questions/49391576/activation-function-in-machine-learning</link>
      <description><![CDATA[机器学习中的激活函数是什么意思。我浏览了大多数文章和视频，每个人都提到或将其与神经网络进行比较。我是机器学习的新手，对深度学习和神经网络不太熟悉。所以，有人能给我解释一下激活函数到底是什么吗？而不是用神经网络来解释。我在学习逻辑回归的 Sigmoid 函数时就被这种模棱两可的感觉所困扰。]]></description>
      <guid>https://stackoverflow.com/questions/49391576/activation-function-in-machine-learning</guid>
      <pubDate>Tue, 20 Mar 2018 18:21:08 GMT</pubDate>
    </item>
    </channel>
</rss>