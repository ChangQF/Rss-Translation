<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 24 Jun 2024 09:18:22 GMT</lastBuildDate>
    <item>
      <title>与前一天相比，同一特征的 MSE 的负和正百分比增加</title>
      <link>https://stackoverflow.com/questions/78660957/negative-and-positive-increase-in-mse-for-a-same-feature-over-previous-day</link>
      <description><![CDATA[我有一个包含过去几天的数据和当天数据的数据框。
示例列 [cases、mobility、temp、rh、cases_1、mobility_1、temp_1、rh_1、cases_2、mobility_2、temp_2、rh_2 等。。]。我的目标列 (Y) 是“cases”，col_i 表示当前日期前 i 天的参数。
%inc mse 的代码如下所示。这会导致某些特征（如 temp）具有正值，而 temp_1 具有负值，temp_2 也可以具有正值或负值，其他特征也是如此。我该如何解释这些结果并找到过去几天的列的综合累积效应？
from tabulate import tabulate
feature_importance_df = pd.DataFrame({&#39;Feature Name&#39;: X_pastdays_test.columns}) 

y_pred_baseline = rf_regressor.predict(X_pastdays_test)
baseline_mse = mean_squared_error(y_test, y_pred_baseline)

percent_inc_mse_list = []
for feature_name in X_pastdays_test.columns:
# 排列测试数据中特征的值
x_test_perturbed = X_pastdays_test.copy()
x_test_perturbed[feature_name] = np.random.permutation(x_test_perturbed[feature_name])

# 使用扰动数据进行预测数据
y_pred_perturbed = rf_regressor.predict(x_test_perturbed)

# 使用扰动数据计算均方误差
perturbed_mse = mean_squared_error(y_test, y_pred_perturbed)

# 将 %Inc MSE 计算为 MSE 的百分比增加
percent_inc_mse = ((perturbed_mse - baseline_mse) / baseline_mse) * 100
percent_inc_mse_list.append(percent_inc_mse)

feature_importance_df[&#39;%Inc MSE&#39;] = percent_inc_mse_list

feature_importance_df = feature_importance_df.sort_values(by=&#39;%Inc MSE&#39;, accending=False)

print(feature_importance_df)
]]></description>
      <guid>https://stackoverflow.com/questions/78660957/negative-and-positive-increase-in-mse-for-a-same-feature-over-previous-day</guid>
      <pubDate>Mon, 24 Jun 2024 07:02:32 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 时，损失为 Nan</title>
      <link>https://stackoverflow.com/questions/78660903/loss-is-nan-with-tensorflow</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78660903/loss-is-nan-with-tensorflow</guid>
      <pubDate>Mon, 24 Jun 2024 06:50:02 GMT</pubDate>
    </item>
    <item>
      <title>当模型在高度不平衡的数据集上进行训练时，其性能如何[关闭]</title>
      <link>https://stackoverflow.com/questions/78660719/how-is-the-performance-of-a-model-when-its-trained-on-highly-unbalanced-dataset</link>
      <description><![CDATA[假设我们有 1000 个 1 类样本和 1000 个 2 类样本。我们用这个数据训练了一个模型，发现模型的性能很好。如果用 10000 个 1 类样本和 90000 个 2 类样本的数据训练模型，模型的性能会发生什么变化？
我认为模型过度拟合了 2 类数据，性能会下降。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/78660719/how-is-the-performance-of-a-model-when-its-trained-on-highly-unbalanced-dataset</guid>
      <pubDate>Mon, 24 Jun 2024 05:43:12 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型的评估结果为损失 = 68（大于 1）</title>
      <link>https://stackoverflow.com/questions/78660583/evaluation-of-keras-model-gets-me-a-loss-68-greater-than-1</link>
      <description><![CDATA[我按照书中的示例，使用时尚 MNIST
我的代码如下：
\`import tensorflow as tf
from tensorflow import keras
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()
X_valid, X_train = X_train_full\[:5000\] / 255.0, X_train_full\[5000:\] / 255.0
y_valid, y_train = y_train_full\[:5000\], y_train_full\[5000:\]

class_names = \[&quot;T-shirt/top&quot;, &quot;Trouser&quot;, “套头衫”、“连衣裙”、“外套”、“凉鞋”、“衬衫”、“运动鞋”、“包”、“踝靴”\]

#构建神经网络模型
model = keras.models.Sequential() 
model.add(keras.layers.Flatten(input_shape=\[28, 28\]))
model.add(keras.layers.Dense(300,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(100,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(10,激活=&quot;softmax&quot;))

model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=&quot;sgd&quot;, metrics=\[&quot;accuracy&quot;\])

history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))

model.evaluate(X_test, y_test)\`

我这次评估的输出是这样的
313/313 [===============================] - 1s 3ms/step - 损失：68.7269 - 准确率：0.8385
[68.72686004638672, 0.8385000228881836]
使用 .fit 方法后，我得到了以下结果：
Epoch 30/30
1719/1719 [==============================] - 9s 5ms/step - 损失：0.2115 - 准确度：0.9236 - val_loss：0.2171 - val_accuracy：0.9209
我还在学习，我不知道该怎么做才能解决这个问题，我也不知道我可能哪里做错了……]]></description>
      <guid>https://stackoverflow.com/questions/78660583/evaluation-of-keras-model-gets-me-a-loss-68-greater-than-1</guid>
      <pubDate>Mon, 24 Jun 2024 04:51:24 GMT</pubDate>
    </item>
    <item>
      <title>这个销售问题应该使用什么机器学习模型？我是新手，很困惑 [关闭]</title>
      <link>https://stackoverflow.com/questions/78660178/what-machine-learning-model-should-be-used-in-this-sales-problem-im-new-and-c</link>
      <description><![CDATA[我在这个领域很新，最近我有一个建立模型的练习。我很困惑是建立回归模型还是分类模型。我应该怎么做，我应该继续使用这个模型还是建立一个新模型？如果我继续，应该改进什么？
数据集链接
我尝试建立一个随机森林模型，并获得 0.5 的准确度得分和 f1 得分。特征包括地区、国家、商品类型、销售渠道、订单优先级，目标是销售单位。我试图将每个特征对销售单位的重要性包括在内。]]></description>
      <guid>https://stackoverflow.com/questions/78660178/what-machine-learning-model-should-be-used-in-this-sales-problem-im-new-and-c</guid>
      <pubDate>Mon, 24 Jun 2024 00:37:32 GMT</pubDate>
    </item>
    <item>
      <title>System.AccessViolationException：尝试在 TorchSharp.PInvoke.LibTorchSharp.THSGenerator_manual_seed 读取或写入受保护的内存</title>
      <link>https://stackoverflow.com/questions/78660054/system-accessviolationexception-attempted-to-read-or-write-protected-memory-at</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78660054/system-accessviolationexception-attempted-to-read-or-write-protected-memory-at</guid>
      <pubDate>Sun, 23 Jun 2024 23:08:49 GMT</pubDate>
    </item>
    <item>
      <title>我正在做一个足球分析跟踪机器学习项目，我得到了速度和距离估计器的导入错误</title>
      <link>https://stackoverflow.com/questions/78659710/i-am-making-a-football-analysis-tracking-machine-learning-project-i-am-getting-i</link>
      <description><![CDATA[ImportError: 无法从 
&#39;speed_and_distance_estimator.speed_and_distance_estimator&#39; 
(c:\Users...\Football analysis\speed_and_distance_estimator\speed_and_distance_estimator.py) 导入名称 &#39;Speed_and_Distance_Estimator&#39;

在我的文件 speed_and_distance_estimator.py 中
sys.path.append(&#39;../&#39;)
from utils import measure_distance, get_foot_position

class Speed_and_Distance_Estimator:
pass

在我的 init.py 中
from .speed_and_distance_estimator import Speed_and_Distance_Estimator

我预计我的 main.py 中不会出现任何错误
from utils import read_video, save_video
from trackers import Tracker
import cv2
import numpy as np
from team_assigner import TeamAssigner
from player_ball_assigner import PlayerBallAssigner
from camera_movement_estimator import CameraMovementEstimator
from view_transformer import ViewTransformer
from speed_and_distance_estimator import Speed_and_Distance_Estimator

def main():
# 读取视频
video_frames = read_video(&#39;input_videos/08fd33_4.mp4&#39;)

# 初始化跟踪器
tracker = Tracker(&#39;models/best.pt&#39;)

tracks = tracker.get_object_tracks(video_frames,
read_from_stub=True,
stub_path=&#39;stubs/track_stubs.pkl&#39;)
# 获取对象位置 
tracker.add_position_to_tracks(tracks)

# 相机运动估计器
camera_movement_estimator = CameraMovementEstimator(video_frames[0])
camera_movement_per_frame = camera_movement_estimator.get_camera_movement(video_frames,
read_from_stub=True,
stub_path=&#39;stubs/camera_movement_stub.pkl&#39;)
camera_movement_estimator.add_adjust_positions_to_tracks(tracks,camera_movement_per_frame)

# 视图转换器
view_transformer = ViewTransformer()
view_transformer.add_transformed_position_to_tracks(tracks)

# 插入球位置
tracks[&quot;ball&quot;] = tracker.interpolate_ball_positions(tracks[&quot;ball&quot;])

# 速度和距离估算器
speed_and_distance_estimator = Speed_and_Distance_Estimator()
speed_and_distance_estimator.add_speed_and_distance_to_tracks(tracks)

# 分配球员队伍
team_assigner = TeamAssigner()
team_assigner.assign_team_color(video_frames[0], 
tracks[&#39;players&#39;][0])

for frame_num, player_track in enumerate(tracks[&#39;players&#39;]):
for player_id, track in player_track.items():
team = team_assigner.get_player_team(video_frames[frame_num], 
track[&#39;bbox&#39;],
player_id)
tracks[&#39;players&#39;][frame_num][player_id][&#39;team&#39;] = team 
tracks[&#39;players&#39;][frame_num][player_id][&#39;team_color&#39;] = team_assigner.team_colors[team]

# 分配球获取
player_assigner =PlayerBallAssigner()
team_ball_control= []
for frame_num, player_track in enumerate(tracks[&#39;players&#39;]):
ball_bbox = tracks[&#39;ball&#39;][frame_num][1][&#39;bbox&#39;]
assigned_player = player_assigner.assign_ball_to_player(player_track, ball_bbox)

if assignment_player != -1:
tracks[&#39;players&#39;][frame_num][assigned_player][&#39;has_ball&#39;] = True
team_ball_control.append(tracks[&#39;players&#39;][frame_num][assigned_player][&#39;team&#39;])
else:
team_ball_control.append(team_ball_control[-1])
team_ball_control= np.array(team_ball_control)

# 绘制输出 
## 绘制对象轨迹
output_video_frames = tracker.draw_annotations(video_frames, tracks,team_ball_control)

## 绘制摄像机运动
output_video_frames = camera_movement_estimator.draw_camera_movement(output_video_frames,camera_movement_per_frame)

## 绘制速度和距离
speed_and_distance_estimator.draw_speed_and_distance(output_video_frames,tracks)

# 保存视频
save_video(output_video_frames, &#39;output_videos/output_video.avi&#39;)

if __name__ == &#39;__main__&#39;:
main()
]]></description>
      <guid>https://stackoverflow.com/questions/78659710/i-am-making-a-football-analysis-tracking-machine-learning-project-i-am-getting-i</guid>
      <pubDate>Sun, 23 Jun 2024 20:05:06 GMT</pubDate>
    </item>
    <item>
      <title>为训练、验证和测试分割创建 LMDB 文件 [关闭]</title>
      <link>https://stackoverflow.com/questions/78659680/create-lmdb-files-for-train-validation-and-test-splits</link>
      <description><![CDATA[为训练、验证和测试分割创建 LMDB 文件。
python tools/create_dataset.py --root_dir &lt;dataset_dir&gt; --save &lt;lmdb_dst_path&gt;

数据集文件夹应遵循与 IIIT-INDIC-HW-WORDS 结构相同的结构。
生成一个包含用于预测的 Unicode 符号/字符的文件。将此文件移动到 alphabet/ 文件夹。此 repo 已包含 alphabet/ 文件夹中印度语脚本的排序字母表列表。
python tools/create_dataset.py --root_dir /Users/armanmansury/Developer/Work/indic-htr-main/tools/create_dataset.py --save /Users/armanmansury/Developer/Work/indic-htr-main
]]></description>
      <guid>https://stackoverflow.com/questions/78659680/create-lmdb-files-for-train-validation-and-test-splits</guid>
      <pubDate>Sun, 23 Jun 2024 19:50:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 vif 选择线性回归的变量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78659510/how-to-use-vif-to-select-variables-for-linear-regression</link>
      <description><![CDATA[我正在尝试使用此 kaggle 数据集，通过 mlr 预测学生的期末成绩。
我知道你应该
a) 对所有二进制和分类数据进行编码
b) 丢弃显示多重共线性的变量
c) 选择与你的因变量具有线性关系的变量（我对此也有点困惑，因为到目前为止，在我看过的很多视频中，人们在使用线性回归训练模型时并没有真正检查这一点）
我已经通过对我的二进制变量进行标签编码和对我的分类变量进行单热编码来完成 (a)。我甚至为每个变量计算了我的 vif（经过单热编码的变量具有无限的 vif 值）。现在……我不知道该如何继续。我只能肯定地说，由于 G2 具有较高的 vif 分数，我可以丢弃它；而且由于 Medu 的得分与 Fedu 接近但更高，我也可以将其丢弃（Walc 和 Dalc 相同）
这是我得到的值：
const 0.000000
school 1.518331
sex 1.489316
age 1.818399
address 1.388570
famsize 1.153361
Pstatus 1.145962
Medu 2.946452
Fedu 2.147572
traveltime 1.322387
studytime 1.398220
failures 1.567588
schoolsup 1.262329
famsup 1.306325
paid 1.339139
activities 1.167950
托儿所 1.153852
高等教育 1.316551
互联网 1.258651
浪漫 1.179480
家庭 1.173444
空闲时间 1.322079
外出 1.496537
Dalc 2.036903
Walc 2.405555
健康 1.181635
缺勤 1.297898
G1 4.794857
G2 8.414788
G3 6.483623
Mjob__at_home inf
Mjob__health inf
Mjob__other inf
Mjob__services inf
Mjob__teacher inf
Fjob__at_home inf
Fjob__health inf
Fjob__other inf
Fjob__services inf
Fjob__teacher inf
reason__course inf
reason__home inf
reason__other inf
reason__reputation inf
guardian__father inf
guardian__mother inf
guardian__other inf
dtype: float64

顺便说一句，我还尝试通过删除每列来删除 inf 值，这是更新后的表格：
const 444.290274
school 1.511859
sex 1.467679
age 1.812452
address 1.374540
famsize 1.133540
Pstatus 1.135528
Fedu 1.573887
traveltime 1.307404
studytime 1.359323
失败 1.564388
学校辅导 1.256581
家庭辅导 1.297111
付费 1.322515
活动 1.160221
托儿所 1.143275
更高 1.315591
互联网 1.250430
浪漫 1.163283
家庭关系 1.116803
空闲时间 1.317057
外出 1.302700
Dalc 1.413114
健康 1.151149
缺勤 1.245384
G1 3.665802
G3 3.347264
Mjob__at_home 1.420409
Mjob__health 1.392905
Mjob__services 1.555274
Mjob__teacher 1.685721
Fjob__at_home 1.167256
Fjob__health 1.237499
Fjob__services 1.352274
Fjob__teacher 1.422042
reason__course 1.668734
reason__other 1.401163
reason__reputation 1.619025
guardian__father 1.213142
guardian__other 1.457884
dtype: float64
]]></description>
      <guid>https://stackoverflow.com/questions/78659510/how-to-use-vif-to-select-variables-for-linear-regression</guid>
      <pubDate>Sun, 23 Jun 2024 18:16:56 GMT</pubDate>
    </item>
    <item>
      <title>循环训练模型（每次迭代都会生成新模型），经过近 600 次循环迭代后，训练时间会增加</title>
      <link>https://stackoverflow.com/questions/78659373/training-model-in-loop-new-model-in-each-iteration-training-time-increases-af</link>
      <description><![CDATA[我正在训练一个 LSTM 模型，并使用“留一法”交叉验证对其进行验证。我有 11520 个样本，所以我必须训练一个新模型 11520 次。我对 scikit learn 的“LeaveOneOut”函数给出的每个数据分割使用循环，在该循环中，我初始化一个新模型，对其进行训练，预测测试集，然后使用“keras.backend.clear_session()”清除旧模型，之后使用“tf.compat.v1.reset_default_graph()”重置图形，然后使用“gc.collect()”收集抓取的数据。最初，模型的训练时间约为 6-7 秒，但在训练 600 个模型后，训练时间增加到 25-50 秒。这是我的代码：
def get_model(channels):

model2 = keras.models.Sequential()
model2.add(keras.layers.LSTM(64, return_sequences=False))
model2.add(keras.layers.Dense(1,activation=&#39;sigmoid&#39;))

model2.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

return model2 

def leaveOneOutCVLSTM(X, y, epochs, batch_size, validation_split):

X_shuffle, y_shuffle = shuffle(X, y, random_state=42)
cv = LeaveOneOut()
# 枚举分割
y_true, y_pred = list(), list()
i = 1
for train_ix, test_ix in cv.split(X_shuffle):
# 分割数据
X_train, X_test = X_shuffle[train_ix, :], X_shuffle[test_ix, :]

scalers = {}
X_train_scaled = np.random.rand(X_train.shape[0], X_train.shape[1], X_train.shape[2])
X_test_scaled = np.random.rand(X_test.shape[0], X_test.shape[1], X_test.shape[2])
for j in range(X_train.shape[2]):
scalers[j] = StandardScaler()
X_train_scaled[:, :, j] = scalers[j].fit_transform(X_train[:, :, j])
for j in range(X_test.shape[2]):
X_test_scaled[:, :, j] = scalers[j].transform(X_test[:, :, j])

y_train, y_test = y_shuffle[train_ix], y_shuffle[test_ix]
# 拟合模型
new_model = get_model(X_train_scaled.shape[1])
st = time()
if(i &lt;= 5):
new_model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)
else:
new_model.fit(X_train_scaled, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split, verbose=False)

# 评估模型
y_hat = new_model.predict(X_test_scaled, verbose=False)

ed = time()
dr = ed-st
print(i,&quot; &quot;,dr)
# store
y_true.append(y_test[0])
y_pred.append(y_hat[0])
i+=1
keras.backend.clear_session()
tf.compat.v1.reset_default_graph()
gc.collect()

return y_true, y_pred

X_batch = X.reshape(11520, 1, 156)

y_true, y_pred = leaveOneOutCVLSTM(X_batch, Y, 10, 32, 0.2)

这是我从第 1 次迭代到第 16 次迭代打印的训练时间
1 8.427346229553223
2 7.397351503372192
3 7.472941875457764
4 7.418887615203857
5 7.5288026332855225
6 6.432919502258301
7 6.417744398117065
8 6.312522649765015
9 6.350329160690308
10 6.340737342834473
11 6.3199241161346436
12 6.310317039489746
13 6.3174097537994385
14 6.346491813659668
15 6.2766053676605225
16 6.296995401382446

以及第 600 次迭代至第 616 次迭代
600 26.77048420906067
601 20.864712238311768
602 20.118656873703003
603 23.869750022888184
604 23.6923668384552
605 26.10648512840271
606 23.909359216690063
607 36.399033069610596
608 22.179851055145264
609 16.407938718795776
610 30.585895776748657
611 23.5596022605896
612 25.86080241203308
613 44.86601257324219
614 23.27703547477722
615 24.88290023803711
616 19.156887531280518

我已使用 keras.backend.clear_session()、tf.compat.v1.reset_default_graph()、gc.collect() 来清除开销，但训练时间仍然增加。所以我想知道

为什么循环 600 次迭代后训练时间会增加？
我应该怎么做才能使训练时间保持在 6-7 秒？
]]></description>
      <guid>https://stackoverflow.com/questions/78659373/training-model-in-loop-new-model-in-each-iteration-training-time-increases-af</guid>
      <pubDate>Sun, 23 Jun 2024 17:20:17 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch Vision Transformer 模型中的异常、验证损失、测试准确度和正常准确度计算 [关闭]</title>
      <link>https://stackoverflow.com/questions/78659312/anomaly-in-pytorch-vision-transformer-model-validation-loss-testing-accuracy-a</link>
      <description><![CDATA[我正在尝试使用 PyTorch 为我的个人项目创建一个视觉变换模型。
问题是，当我运行测试代码时，我不确定我是否正确计算了训练损失、验证损失、训练准确率和测试（+ 前 2 名测试）准确率。
这是我的代码：
criterion = nn.CrossEntropyLoss()
optimizer = AdamW(vit.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)

# 训练循环
train_losses, val_losses, accuracies, top2_accuracies= [], [], [], []
training_start = time.time()

for epoch in range(NUM_EPOCHS):
log_str = write_and_print_str(log_str, f&quot;EPOCH [{epoch+1}/{NUM_EPOCHS}]&quot;)
start = time.time()
vit.train()
running_loss = []
for images, labels in train_dataloader:
images, labels = images.to(device), labels.to(device)
optimizer.zero_grad()
output = vit(images)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()
running_loss.append(loss.item())

avg_train_loss = sum(running_loss) / len(running_loss)
train_losses.append(avg_train_loss)
log_str = write_and_print_str(log_str, f&#39;Loss: {avg_train_loss}&#39;)

vit.eval()
val_loss = []
correct = 0
top2_correct = 0
total = 0
with torch.no_grad():
for images, labels in test_dataloader:
images, labels = images.to(device), labels.to(device)
output = vit(images)
loss = criterion(outputs, labels)
val_loss.append(loss.item())
_, predicted = torch.max(outputs.data, 1)
total += labels.size(0)
correct += (predicted == labels).sum().item()

# 计算 top-2 准确率
top2_pred = torch.topk(outputs, 2, dim=1).indices
top2_correct += (top2_pred == labels.unsqueeze(1)).sum().item()
end = time.time()
avg_val_loss = sum(val_loss) / len(val_loss)
accuracy = 100 * correct / total
top2_accuracy = 100 * top2_correct / total

val_losses.append(avg_val_loss)
accuracies.append(accuracy)
top2_accuracies.append(top2_accuracy)

log_str = write_and_print_str(log_str, f&#39;验证损失：{avg_val_loss}，\n准确率：{accuracy}%，\nTop-2 准确率：{top2_accuracy}%\n时间：{round(end-start, 2)}\n\n&#39;)

training_end = time.time()

log_str = write_and_print_str(log_str, f&#39;训练持续时间：{round(training_end - training_start, 2)}\n&#39;)

print(&quot;EPOCHS 已成功保存到文件中&quot;)


我运行了 20 多次，并记录了所有运行广泛的方法。
在所有结果中，验证损失开始超过 1并降低到 0.20。但问题是在这些情况下我的准确率约为 90%，所以我认为我的代码在计算方面出了问题。
为了更详细地说明准确率和损失的数值，以下是我的一些 EPOCH 结果
EPOCH [1/50]
损失：1.4692728799123032
验证损失：1.1625839814995274，
准确率：49.58932238193019%，
Top-2 准确率：75.77002053388091%
时间：29.71

EPOCH [10/50]
损失：0.1079550055715327
验证损失： 0.5106942771059094，
准确率：83.26488706365502%，
Top-2 准确率：97.53593429158111%
时间：25.86

EPOCH [20/50]
损失：0.037730065656293076
验证损失：0.4059527646185774，
准确率：89.52772073921972%，
Top-2 准确率：97.94661190965093%
时间：26.12

EPOCH [30/50]
损失： 0.00011380775267753052
验证损失：0.22308006276955095，
准确率：94.6611909650924%，
Top-2 准确率：99.48665297741273%
时间：24.41

EPOCH [40/50]
损失：3.5449059315886606e-05
验证损失：0.23672400451808548，
准确率：94.76386036960986%，
Top-2 准确率：99.48665297741273%
时间：25.46

EPOCH [50/50]
损失：1.367992779425829e-05
验证损失：0.24671741761443572，
准确率：94.6611909650924%，
Top-2 准确率：99.48665297741273%
时间：25.66

希望您能帮我解决这个问题。我只是需要澄清一下]]></description>
      <guid>https://stackoverflow.com/questions/78659312/anomaly-in-pytorch-vision-transformer-model-validation-loss-testing-accuracy-a</guid>
      <pubDate>Sun, 23 Jun 2024 16:52:16 GMT</pubDate>
    </item>
    <item>
      <title>即使管道运行正常，管道输出仍为空</title>
      <link>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</link>
      <description><![CDATA[以下代码模拟了一个简单的 TFX 管道，它提取 CSV 文件并将其转换为 TFRecord。
您还可以查看相应的笔记本：https://colab.research.google.com/drive/1GEytZjnNZZ7r_f9QQ9FbauohKNLGSooC?usp=sharing
output_config = example_gen_pb2.Output(split_config=
example_gen_pb2.SplitConfig(splits=[
example_gen_pb2.SplitConfig.Split(name=&#39;train&#39;, hash_buckets=8),
example_gen_pb2.SplitConfig.Split(name=&#39;eval&#39;, hash_buckets=2)
])
)

example_gen = CsvExampleGen(
input_base=&#39;data&#39;,
output_config=output_config
)

pipeline_root = &#39;artifacts&#39;

pipeline = Pipeline(
pipeline_name=&#39;testing pipeline&#39;,
pipeline_root=pipeline_root,
components=[example_gen],
enable_cache=True,
metadata_connection_config=metadata.sqlite_metadata_connection_config(
os.path.join(&#39;artifacts&#39;, &#39;metadata.sqlite&#39;)
)
)

LocalDagRunner().run(pipeline)

我已手动验证 TFRecord 已正确生成。但是，管道的输出字典是空的。
print(pipeline.outputs)
# output: {}
print(example_gen.outputs[&#39;examples&#39;].get())
# output: []

此问题在 .ipynb 笔记本和 .py 文件中都存在。
有趣的是，InteractiveContext 没有这个问题。
是什么原因造成的？]]></description>
      <guid>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</guid>
      <pubDate>Sun, 23 Jun 2024 14:03:09 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MASK R_CNN 通过 OpenCV 提取图像中的精确区域？</title>
      <link>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</link>
      <description><![CDATA[我有一个医疗项目，需要提取一个特殊部分（结膜眼球）

自动提取眼睛图像而不了解其坐标，而不是手动提取，而且这个所需区域的坐标也在变化，因为我从许多患者那里捕捉到了图像，我认为必须找到它的形状。我的目标是通过计算结膜眼球中的红色像素来确定贫血和非贫血。我使用掩蔽方法（k 均值）来做到这一点，但我希望可以先直接提取结膜眼球，然后使用 k 均值掩蔽图像并查找，因为我的结果会更准确。当我使用图像分割中的 k 均值时，我发现另一个重叠的红色像素破坏了我的准确性。
。我也听说过机器学习，但在使用机器学习找到患者图像中的邻近区域后，我需要提取结膜髓核。所以我需要代码来仅提取结膜髓核。
我尝试了 k_means 和 kernel，但又添加了一个不需要的红色像素。我听说过实例分割和MASK RCNN。您假设我有我想要的区域，如上图所示，它是 CNN 的数据，那么如何将其用于我的项目。
import cv2
import numpy as np

# 读取图像
image = cv2.imread(&#39;c:/users/stk/desktop/d.png&#39;)

# 将图像转换为 HSV
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# 定义红色的下限和上限
lower_red = np.array([0, 120, 70])
upper_red = np.array([10, 255, 255])

# 为红色创建蒙版
mask1 = cv2.inRange(hsv, lower_red, upper_red)

# 定义红色的下限和上限
lower_red = np.array([170, 120, 70])
upper_red = np.array([180, 255, 255])

# 为红色创建蒙版
mask2 = cv2.inRange(hsv, lower_red, upper_red)

# 合并两个蒙版
mask = mask1 + mask2

# 为形态学操作创建内核
kernal = np.ones((5, 5), np.uint8)

# 执行形态学操作
mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernal)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernal)

# 将蒙版应用于原始图像
result = cv2.bitwise_and(image, image, mask = mask)

# 保存result
cv2.imwrite(&#39;extracted_red_object.png&#39;, result)

# 显示结果
cv2.imshow(&#39;EXTRACTED RED OBJECT&#39;, result)
cv2.waitKey(0)
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</guid>
      <pubDate>Sun, 23 Jun 2024 03:58:40 GMT</pubDate>
    </item>
    <item>
      <title>所有时期的损失和准确率相同</title>
      <link>https://stackoverflow.com/questions/78645720/same-loss-and-accuracy-for-all-epochs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78645720/same-loss-and-accuracy-for-all-epochs</guid>
      <pubDate>Thu, 20 Jun 2024 06:01:17 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 Huggingface 训练器的学习率？</title>
      <link>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</link>
      <description><![CDATA[我正在使用以下参数训练模型：
Seq2SeqTrainingArguments(
output_dir = &quot;./out&quot;, 
overwrite_output_dir = True,
do_train = True,
do_eval = True,

per_device_train_batch_size = 2, 
gradient_accumulation_steps = 4,
per_device_eval_batch_size = 8, 

learning_rate = 1.25e-5,
warmup_steps = 1,

save_total_limit = 1,

evaluation_strategy = &quot;epoch&quot;,
save_strategy = &quot;epoch&quot;,
logs_strategy = &quot;epoch&quot;, 
num_train_epochs = 5, 

gradient_checkpointing = True,
fp16 = True, 

predict_with_generate = True,
generation_max_length = 225,

report_to = [&quot;tensorboard&quot;],
load_best_model_at_end = True,
metric_for_best_model = &quot;wer&quot;,
greater_is_better = False,
push_to_hub = False,
)

我假设 warmup_steps=1 固定了学习率。
但是，训练结束后，我查看文件 trainer_state.json，发现学习率似乎没有固定。
以下是 learning_rate 和 step 的值：
learning_rate，steps
1.0006 e-05 1033
7.5062 e-06 2066
5.0058 e-06 3099
2.5053 e-06 4132
7.2618 e-09 5165

学习率似乎没有固定在 1.25e-5（步骤 1 之后）。我遗漏了什么？如何修复学习率。]]></description>
      <guid>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</guid>
      <pubDate>Wed, 10 Jan 2024 09:14:26 GMT</pubDate>
    </item>
    </channel>
</rss>