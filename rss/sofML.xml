<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 16 Jan 2024 15:14:46 GMT</lastBuildDate>
    <item>
      <title>max在遗传算法中起什么作用？</title>
      <link>https://stackoverflow.com/questions/77826027/what-role-does-max-play-in-genetic-algorithms</link>
      <description><![CDATA[在网上找到了一个遗传算法代码，求解的是f(x)=2*sin(x) + cos(x)的最大值，但是我发现代码中有一个参数max_value，并且不知道有什么作用。
GA代码如下：
随机导入
导入数学
将 matplotlib.pyplot 导入为 plt


def 物种起源（种群大小，染色体长度）：
    人口=[[]]
    对于范围内的 i（population_size）：
        临时=[]
        对于范围内的 j（染色体长度）：
            临时.append(随机.randint(0, 1))
        人口.追加（临时）
    返回人口[1:]


def 翻译（人口，染色体长度）：
    临时=[]
    对于范围内的 i(len(population))：
        总计 = 0
        对于范围内的 j（染色体长度）：
            总计 = 总计 + 人口[i][j] * (math.pow(2, j))
        临时.追加（总计）
    暂时返回


def 函数（群体、染色体长度、最大值）：
    临时=[]
    函数1 = []
    临时=翻译（人口，染色体长度）
    对于范围内的 i(len(临时))：
        x = 临时[i] * max_value / (math.pow(2, chtomosome_length) - 1)
        function1.append(2 * math.sin(x) + math.cos(x))
    返回函数1

def 健身（功能1）：
    健身1 = []
    最小适应度 = mf = 0
    对于范围内的 i(len(function1))：
        如果（函数 1[i] + mf &gt; 0）：
            临时 = mf + 函数 1[i]
        别的：
            临时 = 0.0
        Fitness1.append（临时）
    返回健身1


def sum(fitness1):
    总计 = 0
    对于范围内的 i(len(fitness1))：
        总计 += 适应度1[i]
    返回总计

# https://blog.csdn.net/weixin_39068956/article/details/105121469
def cumsum(健身1):
    对于范围内的 i(len(fitness1) - 2, -1, -1)：
        总计 = 0
        j = 0
        而（j &lt;= i）：
            总计 += 适应度1[j]
            j += 1
        适应度1[i] = 总计
        健身1[len(健身1) - 1] = 1


def选择（人口，适应度1）：
    新健身=[]
    总适应度=总和（适应度1）
    对于范围内的 i(len(fitness1))：
        new_fitness.append(fitness1[i]/total_fitness)


    cumsum(new_fitness)

    毫秒 = []
    人口长度 = pop_len = len(人口)
    对于范围内的 i(pop_len)：
        ms.append(随机.随机())
    ms.sort()

    适应= 0
    纽因 = 0
    新人口 = 新人口 = 人口

    而纽因 &lt;流行长度：
        if (ms[newin] &lt; new_fitness[fitin]):
            new_pop[newin] = 人口[fitin]
            纽因 += 1
        别的：
            适合+= 1
    人口=新人口


def 交叉（人口，pcB00）：
    pop_len = len(人口)

    对于范围内的 i(pop_len - 1)：
        cpoint = random.randint(0, len(population[0]))
        临时1 = []
        临时2 = []

        临时1.extend(人口[i][0:cpoint])
        临时1.extend(population[i + 1][cpoint:len(population[i])])

        临时2.extend(人口[i + 1][0:cpoint])
        临时2.extend(population[i][cpoint:len(population[i])])

        人口[i] = 临时1
        人口[i + 1] = 临时2


def 突变（群体，pm）：
    px = len(人口)
    py = len(人口[0])

    对于范围内的 i（px）：
        if (random.random() &lt; pm):
            mpoint = random.randint(0, py - 1)
            if (人口[i][mpoint] == 1):
                人口[i][m点] = 0
            别的：
                人口[i][m点] = 1


def b2d(b, 最大值, 染色体长度):
    总计 = 0
    对于范围内的 i(len(b))：
        总计 = 总计 + b[i] * math.pow(2, i)
    总计 = 总计 * max_value / (math.pow(2, 染色体长度) - 1)
    返回总计


def best（人口，健身1）：
    px = len(人口)
    最佳个人=[]
    最佳适应度 = 适应度1[0]

    对于范围 (1, px) 内的 i：
        if (fitness1[i] &gt; bestfitness):
            最佳适应度 = 适应度1[i]
            最佳个体 = 总体[i]

    返回[最佳个体，最佳适应度]

＃ 主要的
人口规模 = 500
最大值 = 10
染色体长度 = 10
个人计算机=0.6
下午 = 0.01
结果=[[]]
健身1 = []
拟合平均值 = []

人口=流行=物种起源（人口大小，染色体长度）


对于范围内的 i（population_size）：
    函数 1 = 函数（群体、染色体长度、最大值）
    适应度1 = 适应度(函数1)
    best_individual, best_fitness = best(人口, 健身1)
    results.append([best_fitness, b2d(best_individual, max_value, 染色体长度)])

    选择（人口，适应度1）
    交叉（人口，个人电脑）
    突变（群体，pm）

结果=结果[1:]
结果.sort()
X = []
Y = []
对于范围（500）内的 i：
    X.追加(i)
    Y.append(结果[i][0])
plt.plot(X, Y)
plt.show()

我尝试调整max_value的值，发现对结果影响很大，这让我很困惑。]]></description>
      <guid>https://stackoverflow.com/questions/77826027/what-role-does-max-play-in-genetic-algorithms</guid>
      <pubDate>Tue, 16 Jan 2024 13:20:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在多维复杂数据上训练模型？</title>
      <link>https://stackoverflow.com/questions/77825016/how-to-train-a-model-on-multidimensional-complex-data</link>
      <description><![CDATA[我有一个输入数据数组，它们是 5 个不同长度的数组。如何构建正确的张量和形式进行训练？
&lt;前&gt;&lt;代码&gt;[
[
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ],],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]],
[
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ],],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]
],
...
],
]
]]></description>
      <guid>https://stackoverflow.com/questions/77825016/how-to-train-a-model-on-multidimensional-complex-data</guid>
      <pubDate>Tue, 16 Jan 2024 10:22:33 GMT</pubDate>
    </item>
    <item>
      <title>是否建议对经过one-hot编码的数据进行主成分分析（PCA）</title>
      <link>https://stackoverflow.com/questions/77824892/is-it-recommended-to-perform-principal-component-analysis-pca-on-data-that-has</link>
      <description><![CDATA[我正在做一个项目，虽然机器学习模型做得还不错，但我觉得它还可以更好。该模型可以很好地预测多数类别，但不能很好地预测少数类别。多数类的召回率和精度分别为 84% 和 82%，少数类的召回率和精度分别为 39% 和 52%。
我向数据中添加了更多特征，并使用 SMOTE 来平衡数据的分布，少数类别的召回率和精度分别提高到 54% 和 52%，这是一个显着的结果，但是少数类别的召回率和精度多数阶层仍分别保持在 84% 和 82%。
我希望少数类的查全率和查准率都在 70% 以上，我想尝试的一种方法是对数据进行 one-hot 编码，然后使用主成分分析 (PCA) 来减小特征空间的大小同时保留尽可能多的信息，但我不知道是否建议这样做。
那么有谁知道是否建议对经过 one-hot 编码的数据执行主成分分析（PCA）？]]></description>
      <guid>https://stackoverflow.com/questions/77824892/is-it-recommended-to-perform-principal-component-analysis-pca-on-data-that-has</guid>
      <pubDate>Tue, 16 Jan 2024 10:02:11 GMT</pubDate>
    </item>
    <item>
      <title>尝试运行 SVC 分类模型，花了一个小时但没有响应</title>
      <link>https://stackoverflow.com/questions/77822664/trying-to-run-a-classification-model-for-svc-taking-hour-and-not-responding</link>
      <description><![CDATA[我已经尝试运行 SVC 分类模型三天了，但该模型没有响应。我检查了我的数据、标准缩放器、训练测试拆分和所有必要的库，所有这些都已正确应用和工作。我运行随机森林分类器模型，该模型运行成功，但存在良好的准确度分数（F1 分数）。但是 SVC 不工作，可能是什么问题？
我尝试过 RandomForest，效果很好，但 SVC 从未起作用。可能是什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77822664/trying-to-run-a-classification-model-for-svc-taking-hour-and-not-responding</guid>
      <pubDate>Mon, 15 Jan 2024 22:38:54 GMT</pubDate>
    </item>
    <item>
      <title>TicTacToe 的表格 Q-Learning - 仅最后一个状态/动作对存储在 Q-Table 字典中，其值不为 0</title>
      <link>https://stackoverflow.com/questions/77821339/tabular-q-learning-for-tictactoe-only-the-last-state-action-pair-is-stored-in</link>
      <description><![CDATA[我的 tictactoe 3x3 板的表格 q-learning 实现存在问题。
问题在于，只有最后一步（获胜、失败、平局）及其各自的棋盘状态存储在 q 值不是“0.0”的 q 表中。导致最后移动的所有其他状态和动作对仍然具有值“0.0”。我在下面添加了 q 表，其中显示最后一步的值为“0.2”。但之前所有的移动的值为“0.0”。这只是第一集。即使增加了剧集也不会改变任何事情。只有最后一个动作的 q 值不是“0.0”
类标记（enum.StrEnum）：
    十字＝“X”
    NAUGHT=“O”
    空=“_”


类奖励（enum.IntEnum）：
    获胜=1
    输=-1
    平局 = -0.065
    非终端 = -0.01


# Q-Learning 的常量
EPSILON = 0.1 # 探索因子
ALPHA = 0.2 # 学习率
GAMMA = 0.95 # 折扣系数

TOTAL_EPISODES = 1 # 代理将玩的游戏总数

BOARD = np.array([Mark.EMPTY] * BOARD_SIZE)

def update_q_table(board、action、reward、new_board)：
    board_key = &quot;&quot;.join(board)
    new_board_key = &quot;&quot;.join(new_board)

    旧值 = Q_TABLE_DICT.get((board_key, 操作), 0)

    如果游戏结束（新棋盘）：
        # 如果是最终状态，则无需考虑未来的奖励
        下一个最大= 0
    别的：
        # 估计最优未来值
        下一个最大=最大（
            Q_TABLE_DICT.get((new_board_key, a), 0) for a in possible_moves(new_board)
        ）

    # 使用贝尔曼方程更新当前状态-动作对的 Q 值
    q_value = old_value + ALPHA * (奖励 + GAMMA * next_max - old_value)
    Q_TABLE_DICT[(board_key, 操作)] = q_value

def train_q_learning_agent():
    对于范围内的剧集（TOTAL_EPISODES）：
        board = np.array([Mark.EMPTY] * BOARD_SIZE) # 重置板
        当前标记 = 标记.CROSS

        而不是游戏结束（棋盘）：
            # Q-学习代理 (X) 采取行动
            如果 current_mark == Mark.CROSS:
                动作=选择_动作_q_学习（板，训练=真）
                new_board = make_move_to(板、操作、当前标记)
                奖励 = get_reward(new_board, current_mark)
                打印（新板）
                update_q_table（板、操作、奖励、new_board）

            # 随机玩家 (O) 采取行动
            别的：
                动作= get_random_move（板）
                new_board = make_move_to(板、操作、当前标记)

            板=新板
            current_mark = Mark.NAUGHT 如果 current_mark == Mark.CROSS else Mark.CROSS

def Choose_action_q_learning(board, Training=True) -&gt; &gt;整数：
    如果训练且 random.uniform(0, 1) &lt;厄普西隆：
        # 探索：选择一个随机动作
        返回 np.random.choice(possible_moves(board))
    别的：
        # 利用：根据当前 Q 表选择最佳操作
        board_key = &quot;&quot;.join(board)
        q_值 = {
            动作： Q_TABLE_DICT.get((board_key, 动作), 0)
            对于 possible_moves(board) 中的操作
        }
        返回 max(q_values, key=q_values.get)

第一集的 Q-Table 字典为 json：
&lt;前&gt;&lt;代码&gt;{
    “(&#39;_________&#39;, 0)”: 0.0,
    “（&#39;XO_______&#39;，2）”：0.0，
    “(&#39;XOX____O_&#39;, 3)”: 0.0,
    “(&#39;XOXX___OO&#39;, 4)”: 0.0,
    “（&#39;XOXXXO_OO&#39;，6）”：0.2
}
]]></description>
      <guid>https://stackoverflow.com/questions/77821339/tabular-q-learning-for-tictactoe-only-the-last-state-action-pair-is-stored-in</guid>
      <pubDate>Mon, 15 Jan 2024 17:10:26 GMT</pubDate>
    </item>
    <item>
      <title>当尝试使用tuner.search运行GridTuner类时我遇到了问题</title>
      <link>https://stackoverflow.com/questions/77821202/when-trying-to-run-gridtuner-class-using-tuner-search-%c4%b1-am-having-problem</link>
      <description><![CDATA[类 GridTuner(keras_tuner.GridSearch):
def __init__(self, 超模型, \*\*kwargs):
super().__init__(超级模型，\*\*kwargs)

    def run_Trial(自我, 审判, *args, **kwargs):
        hp = 试验.超参数
        模型 = self.hypermodel.build(hp)
        返回 self.hypermodel.fit(hp, model, *args, **kwargs)
                调谐器 = GridTuner(
                构建模型，
                目标=&#39;val_loss&#39;,
                覆盖=真，
                目录=“D:\\kaggle\\working\\hyperparameters”,
                project_name=f“driams-{有机体}-{抗菌剂}”，
）
                

                tuner.search_space_summary()



                调谐器. 搜索(
                    X_火车，
                    y_火车，
                    验证数据=（X_val，y_val），
                    批量大小=128，
                    纪元=100，
                    类别权重=类别权重，
                    回调=[提前停止(耐心=15)]
）

            best_hp =tuner.get_best_hyperparameters()[0]
            best_model =tuner.hypermodel.build(best_hp)
            best_model.summary()

我正在尝试运行有关超参数的试验，但出现以下错误：
文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\scriptrunner\ \script_runner.py”，第 534 行，在 \_run_script exec(code, module.__dict__) 文件“C:\\Users\\90507\\OneDrive\\Masaüstü\\demo\\app.py”，第 266 行，在\&lt;模块\&gt;; main() 文件“C:\\Users\\90507\\OneDrive\\Masaüstü\\demo\\app.py”，第 234 行，在 maintuner.search( 文件“C:\\Users\\90507”中\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py”，第 234 行，在搜索 self.on_Trial_end(Trial)文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py”，第 338 行，在 on_trial_end self.oracle.end_trial(Trial) 文件 &quot;C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner \\src\\engine\\oracle.py”，第 108 行，wrapped_func ret_val = func(\*args, \*\*kwargs) ^^^^^^^^^^^^^^^^^^ ^^^ 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\tuners\\gridsearch.txt” py”，第 318 行，在 end_Trial super().end_Trial(Trial) 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages \\keras_tuner\\src\\engine\\oracle.py”，第 108 行，wrapped_func ret_val = func(\*args, \*\*kwargs) ^^^^^^^^^^^^^^^^ ^^^^^^ 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\ \oracle.py”，第 586 行，end_Trial self.\_check_consecutive_failures() 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site- packages\\keras_tuner\\src\\engine\\oracle.py”，第 543 行，在 \_check_consecutive_failures 中引发 RuntimeError( ValueError: 无法将 NumPy 数组转换为张量（不支持的对象类型 NoneType）。
我尝试查看数据集内部，检查导入、库并尝试更改代码。我正在尝试这个 https://www.kaggle.com/code/ hlysine/driams-maldi-tof-classifier 代码来制作有关 ML 的 Web 应用程序，我正在使用 Streamlit。]]></description>
      <guid>https://stackoverflow.com/questions/77821202/when-trying-to-run-gridtuner-class-using-tuner-search-%c4%b1-am-having-problem</guid>
      <pubDate>Mon, 15 Jan 2024 16:43:50 GMT</pubDate>
    </item>
    <item>
      <title>在使用pywinauto生成的多个系统中使用Wrapper_objects</title>
      <link>https://stackoverflow.com/questions/77819573/using-wrapper-objects-in-multiple-systems-generated-using-pywinauto</link>
      <description><![CDATA[我在使用 pywinauto 执行操作时得到了一个包装器。
现在我想在不同的系统上使用同一应用程序上的相同包装器来播放它。
可能吗？
我正在使用它创建包装对象：
from ctypes.wintypes import tagPOINT
导入 pywinauto
导入时间
时间.睡眠(2)
def get_ElementFromPoint(x,y):
     elem = pywinauto.uia_defines.IUIA().iuia.ElementFromPoint(tagPOINT(x, y))
     元素 = pywinauto.uia_element_info.UIAElementInfo(elem)
     包装器 = pywinauto.controls.uiawrapper.UIAWrapper(元素)
     返回包装器

创建的对象示例如下：


如何在不同的系统中使用此包装器来自动执行我的任务？]]></description>
      <guid>https://stackoverflow.com/questions/77819573/using-wrapper-objects-in-multiple-systems-generated-using-pywinauto</guid>
      <pubDate>Mon, 15 Jan 2024 11:49:34 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 3.12.1 上安装 PyTorch</title>
      <link>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</link>
      <description><![CDATA[我正在安装 DARTS TimeSeries 库 (https: //github.com/unit8co/darts/blob/master/INSTALL.md#enabling-Optional-dependencies），但我遇到了依赖项安装问题。在 DARTS 安装指南中，它说如果我们遇到这个问题，我们必须参考 PyTorch 的官方安装指南，然后尝试再次安装 Darts。然后，当我尝试在 python 3.12.1 上安装 torch 时，我遇到了这个错误：
&lt;块引用&gt;
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版。

如何解决这个问题？
我使用 PyCharm 作为 Python 代码编辑器。
我尝试了pip install darts，但它没有安装所有软件包并遇到此错误错误：subprocess-exited-with-error
 用于安装构建依赖项的 pip 子进程未成功运行。
  │ 退出代码：1
  ╰─&gt; 【136行输出】
      正在收集setuptools&gt;=64.0
        从 https://files.pythonhosted.org/packages 获取 setuptools&gt;=64.0 的依赖信息

然后，我尝试使用 pip install torch 安装 torch 并遇到此错误
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版]]></description>
      <guid>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</guid>
      <pubDate>Wed, 10 Jan 2024 10:16:06 GMT</pubDate>
    </item>
    <item>
      <title>回归问题中的精度和准确度相当于什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77778210/what-are-equivalent-of-precision-and-accuracy-in-regression-problems</link>
      <description><![CDATA[我已经使用多层感知器神经网络解决了回归问题。我听说过 MSE、RMASE、MAE 和 R^2 指标。我想确切地知道哪个指标等于或类似于分类问题中的精度和准确度？换句话说，回归问题中的精度和准确度相当于什么？]]></description>
      <guid>https://stackoverflow.com/questions/77778210/what-are-equivalent-of-precision-and-accuracy-in-regression-problems</guid>
      <pubDate>Mon, 08 Jan 2024 09:08:25 GMT</pubDate>
    </item>
    <item>
      <title>Bigquery ML，用于表中分区的多个线性回归模型</title>
      <link>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</link>
      <description><![CDATA[任务
我想使用 bigquery ml 对表中的分区执行多元线性回归，最好使用 dbt 实现。
背景
该表包含 customer_key、c​​ategory、week_key 和花费。应为每个分区计算回归线：customer_key 和类别，按周升序排序。这样，每个类别的每个客户都可以获得该分区内几周内支出趋势的斜率系数。实际上，我需要每个分区一个回归模型，而不是整个表一个回归模型。回归模型的数量估计约为 1 亿个。因此，我想使用 bigquery 来实现工作负载的并行化。

最终结果应该是一个表，其中包含：所有客户的 customer_key、类别、斜率。

此外，我使用 dbt 来运行所有模型，并使用 bigquery 作为数据的计算和存储。因此，我想使用dbt来实现该解决方案。
研究
通过与各个 llms 的聊天，他们似乎建议结合使用程序语句和跨每个分区的 for 循环来执行回归。但是，我想并行化计算。从这个问题 bigquery ML: Running a regression per group and全部组合起来，似乎“BQML 目前不支持在单个 CREATE MODEL 语句中指定不同的组 id 进行回归。”。
创建临时表partitioned_data AS
选择 customer_key、类别、week_key、支出
来自你的表
按客户键分组，类别；

DECLARE partition_list ARRAY&gt;；
开始
-- 迭代暂存表中的每个分区
FOR 分区 IN (
  选择客户键，类别
  FROM 分区数据
  按客户键分组，类别
 ）
 环形
   -- 提取当前分区的数据
 DECLARE partition_data ARRAY&gt;；
 开始
  FOR week_data IN (
    选择 week_key，花费
    FROM 分区数据
    WHERE customer_key = 分区.customer_key
    AND 类别 = 分区.类别
  ）
  环形
    array_append(partition_data, week_data);
  结束循环；
结尾

-- 为当前分区创建模型
创建或替换模型 my_model
选项（
  model_type = &#39;线性回归&#39;,
  标签=&#39;花费&#39;，
  特征 = &#39;week_key&#39;
）
作为
选择 *
FROM UNNEST(partition_data);
结束循环；
结尾;

创建临时表 Final_results AS
选择
  s.customer_key，
  s.类别，
  米坡度
FROM 分区数据 p
加入 （
  选择
    *,
    斜率 = MEAN(statistics.mean_slope)
   来自 ML.MODEL_STATS(model.my_model)
   按客户键、商店键、类别分组
  ）米
 ON p.customer_key = m.customer_key
 AND p.category = m.category;

但是，这个建议的解决方案无法在 bigquery gui 中运行，也不能在 dbt 中运行。
问题
如何完成这个回归任务？要么在 bigquery 上将上面的 sql 代码作为单独的脚本运行，要么重写它以在 dbt 中工作。]]></description>
      <guid>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</guid>
      <pubDate>Thu, 04 Jan 2024 09:36:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在海量数据上训练机器学习模型？</title>
      <link>https://stackoverflow.com/questions/74886400/how-to-train-a-machine-learning-model-on-huge-amount-of-data</link>
      <description><![CDATA[关键点：数据集太大了，我几乎无法将其存储在硬件中。 （拍字节）
假设我的数据集中有数万亿行。该数据集太大，无法存储在内存中。我想在这个数据集上训练一个机器学习模型，比如逻辑回归。我该怎么办？
现在，我知道亚马逊/谷歌在大量数据上进行机器学习。他们怎样做呢？例如点击数据集，全局每个智能设备的输入都存储在一个数据集中。
拼命寻找新想法并乐于接受修正。
我的思路：

加载部分数据到内存
执行梯度下降

这样优化就是小批量下降。
现在的问题是，在优化中，无论是SGD还是mini Batch，在最坏的情况下，当它遍历完所有数据时就会停止。遍历整个数据集是不可能的。
所以我有了提前停止的想法。提前停止保留验证集，并在错误停止下降/收敛于验证集时停止优化。但由于数据集的大小，这可能不可行。
现在我正在考虑简单地随机采样训练集和测试集，并使用可行的大小来训练模型。]]></description>
      <guid>https://stackoverflow.com/questions/74886400/how-to-train-a-machine-learning-model-on-huge-amount-of-data</guid>
      <pubDate>Thu, 22 Dec 2022 09:16:33 GMT</pubDate>
    </item>
    <item>
      <title>Ubuntu 上安装的 AWS EFS 文件系统中的 Python AWS Lambda 错误“libgomp.so.1：无法打开共享对象文件：没有此类文件或目录”</title>
      <link>https://stackoverflow.com/questions/67844901/python-aws-lambda-error-libgomp-so-1-cannot-open-shared-object-file-no-such-f</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/67844901/python-aws-lambda-error-libgomp-so-1-cannot-open-shared-object-file-no-such-f</guid>
      <pubDate>Fri, 04 Jun 2021 23:09:34 GMT</pubDate>
    </item>
    <item>
      <title>机器学习线性回归 - Sklearn</title>
      <link>https://stackoverflow.com/questions/55096288/machine-learning-liner-regression-sklearn</link>
      <description><![CDATA[我是机器学习领域的新手，对于学习回归我有一些疑问
1：在练习sklearn学习回归模型预测方法时出现以下错误。 
代码：
sklearn.linear_model.LinearRegression.predict(25)

错误：
 “ValueError：需要 2D 数组，改为标量数组：array=25。如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据，如果数据包含，则使用 array.reshape(1, -1) 重塑数据单个样本。”
我需要传递一个二维数组吗？检查了 sklearn 文档页面，没有找到任何版本更新的内容。
 **在 Kaggle 上运行我的代码
https://www.kaggle.com/aman9d/bikesharingdemand-upx/ &lt; /p&gt;

2：数据集的索引会影响模型的得分（权重）吗？]]></description>
      <guid>https://stackoverflow.com/questions/55096288/machine-learning-liner-regression-sklearn</guid>
      <pubDate>Mon, 11 Mar 2019 06:29:10 GMT</pubDate>
    </item>
    <item>
      <title>R 中奇怪的 svm 行为 (e1071)</title>
      <link>https://stackoverflow.com/questions/51852415/weird-svm-behavior-in-r-e1071</link>
      <description><![CDATA[我在 R（第一个示例）和 Python（第二个示例）中使用 SVM 运行了以下代码来执行二元分类任务。 
给定随机生成的数据(X)和响应(Y)，此代码执行离开组交叉验证 1000 次。因此，Y 的每个条目都是 CV 迭代预测的平均值。 
曲线下的计算面积应为 ~0.5，因为 X 和 Y 是完全随机的。然而，这并不是我们所看到的。曲线下面积通常显着高于 0.5。 X 的行数非常少，这显然会导致问题。 
知道这里会发生什么吗？我知道我可以增加 X 的行数或减少列数来解决问题，但我正在寻找其他问题。 
Y=as.factor(rep(c(1,2), times=14))
X=矩阵(runif(长度(Y)*100), nrow=长度(Y))

图书馆(e1071)
库（pROC）

列名(X)=1:ncol(X)
迭代=1000
ansMat=矩阵(NA,长度(Y),iter)
for(i in seq(iter)){
    #搭火车

    训练=样本(seq(长度(Y)),0.5*长度(Y))
    if(min(表(Y[train]))==0)
    下一个

    #从火车上测试
    测试=seq(长度(Y))[-train]

    #训练模型
    XX=X[火车,]
    YY=Y[火车]
    mod=svm(XX,YY,概率=FALSE)
    XXX=X[测试,]
    predVec=预测(mod,XXX)
    RFans=attr(predVec,&#39;decision.values&#39;)
    ansMat[测试，i]=as.numeric(predVec)
}

ans=rowMeans(ansMat,na.rm=TRUE)

r=roc(Y,ans)$auc
打印(r)

同样，当我在 Python 中实现相同的事情时，我得到了类似的结果。 
Y = np.array([1, 2]*14)
X = np.random.uniform(size=[len(Y), 100])
n_iter = 1000
ansMat = np.full((len(Y), n_iter), np.nan)
对于范围内的 i(n_iter)：
    # 获取训练/测试索引
    火车= np.random.choice（范围（len（Y）），大小= int（0.5 * len（Y）），替换= False，p =无）
    如果 len(np.unique(Y)) == 1:
        继续
    test = np.array([i for i in range(len(Y)) if i not in train])
    # 训练模型
    mod = SVC(概率=假)
    mod.fit(X=X[火车, :], y=Y[火车])
    # 预测并收集答案
    ansMat[测试，i] = mod.predict(X[测试，:])
ans = np.nanmean(ansMat, 轴=1)
fpr、tpr、阈值 = roc_curve(Y、ans、pos_label=1)
打印（auc（fpr，tpr））`
]]></description>
      <guid>https://stackoverflow.com/questions/51852415/weird-svm-behavior-in-r-e1071</guid>
      <pubDate>Wed, 15 Aug 2018 03:06:09 GMT</pubDate>
    </item>
    <item>
      <title>数据科学模型和培训 - 理解[关闭]</title>
      <link>https://stackoverflow.com/questions/48197227/data-science-model-and-training-understanding</link>
      <description><![CDATA[来自编写代码、测试、部署、运行的编程背景。我试图理解数据科学中“训练模型”或“经过训练的模型”的概念，并部署该模型训练有素的模型。 
我并不真正关心部署环境、自动化等。我正在尝试了解部署单元......一个经过训练的模型。经过训练的模型在文件系统上是什么样子，它包含什么？ 
我理解训练模型并将一组数据拆分为训练集和测试集的概念，但是假设我有一个笔记本（python / jupyter）并且我加载一些数据，在训练/测试之间进行拆分数据，并运行算法来“训练”我的模型。我的幕后成果是什么？当我训练模型时，我认为内存中会存储一定量的数据……那么这些数据如何成为训练模型的一部分呢？它显然不能包含用于训练的所有数据；因此，例如，如果我正在训练一个聊天机器人代理（基于检索），那么在我添加/输入用户问题或“意图”的示例之后，作为该训练的一部分实际发生了什么，以及我的可部署性是什么训练有素的模型？这个经过训练的模型是否包含某种来自训练或术语数组的数据总和，它可以达到多大（可部署大小）？
虽然这个问题看起来相对简单“什么是经过训练的模型”，但我如何用简单的术语向 DevOps 技术解释它？这是一个“对数据科学感兴趣的 IT 人员，试图在与数据科学人员的讨论中理解经过训练的模型的有形单元”。 
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/48197227/data-science-model-and-training-understanding</guid>
      <pubDate>Wed, 10 Jan 2018 22:36:27 GMT</pubDate>
    </item>
    </channel>
</rss>