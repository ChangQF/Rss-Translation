<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 28 Apr 2024 21:13:18 GMT</lastBuildDate>
    <item>
      <title>是否仍然建议手动使用 `del` 或 `torch.cuda.empty_cache()` ？</title>
      <link>https://stackoverflow.com/questions/78399631/is-it-still-recommended-to-use-del-or-torch-cuda-empty-cache-manually</link>
      <description><![CDATA[许多在线机器学习代码仍然使用这个。但到了2024年，还推荐吗？如果没有的话，有什么具体的案例可以推荐吗？ （例如调试？）
我希望更多地了解为什么这些以前如此常见以及它们是否仍然有必要]]></description>
      <guid>https://stackoverflow.com/questions/78399631/is-it-still-recommended-to-use-del-or-torch-cuda-empty-cache-manually</guid>
      <pubDate>Sun, 28 Apr 2024 20:56:20 GMT</pubDate>
    </item>
    <item>
      <title>java中的机器学习是否可行？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78399466/machine-learning-in-java-is-possible-or-not</link>
      <description><![CDATA[
我们可以使用 Java 进行机器学习吗？
如何使用它？
Java 中有哪些可用的机器学习库？
Java 中的机器学习比 Python 更高效吗？
如果java有机器学习功能，它比python更有价值吗？

我在谷歌上搜索了上述问题并得到了几个答案，但我必须从工作专业人士那里得到答案，这样我才能消除我的疑虑......]]></description>
      <guid>https://stackoverflow.com/questions/78399466/machine-learning-in-java-is-possible-or-not</guid>
      <pubDate>Sun, 28 Apr 2024 19:45:18 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：X 有 3 个特征，但 MultinomialNB 期望 235 个特征作为输入</title>
      <link>https://stackoverflow.com/questions/78399309/valueerror-x-has-3-features-but-multinomialnb-is-expecting-235-features-as-inp</link>
      <description><![CDATA[我正在尝试使用 Flask 制作一个 Web 应用程序来预测 HTML 表单的输入。
我收到错误“ValueError：X 有 3 个特征，但 MultinomialNB 预计有 235 个特征作为输入”。
这是我的 Python 代码片段：
from sklearn.model_selection import train_test_split
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
从 sklearn.naive_bayes 导入 MultinomialNB
从 sklearn.metrics 导入 precision_score

X_train, X_test, y_train, y_test = train_test_split(df[&#39;Aduan&#39;], df[&#39;Bag_Pelayanan&#39;], test_size=0.2, random_state=42)

向量化器 = TfidfVectorizer()
X_train_vec = 矢量化器.fit_transform(X_train)
X_test_vec = 矢量化器.transform(X_test)

NB = 多项式NB()
NB.fit(X_train_vec, y_train)

y_pred = NB.predict(X_test_vec)

NB_accuracy = precision_score(y_test, y_pred)

这是我的 Flask 代码片段：
def preprocess_text(text):
    文本 = 文本.lower()
    文本 = 删除标点符号（文本）
    文本 = 删除停用词（文本）
    文本=stem_text(文本)
    返回文本.strip()

def 删除标点符号（文本）：
    return text.translate(str.maketrans(&#39;&#39;, &#39;&#39;, string.punctuation))

def remove_stopwords(文本):
    return &#39; &#39;.join([如果单词不在 stop_words 中则在 text.split() 中逐字逐句])

def 词干文本(文本):
    返回stemmer.stem(文本)

@app.route(&#39;/&#39;, method=[&quot;GET&quot;, &quot;POST&quot;])
定义索引（）：
    if request.method == &quot;POST&quot;;和 request.form 中的“用户名”：
        用户名 = request.form[&#39;用户名&#39;]
        aduan = request.form[&#39;aduan&#39;]

        preprocessed_aduan = preprocess_text(aduan)
        aduan_vec = 矢量化器.fit_transform(preprocessed_aduan)

        预测 = model.predict(aduan_vec)

        游标 = mysql.connection.cursor(MySQLdb.cursors.DictCursor)
        cursor.execute(&#39;INSERT INTO pengaduan (用户名, bag_pelayanan, aduan) VALUES (%s, %s, %s)&#39;, (用户名, 预测[0], aduan))
        mysql.connection.commit()
        光标.close()
        
        return render_template(“success.html”,预测=预测)
    
    返回 render_template(“index.html”)

这是我在 Flask 应用程序中遇到的错误
烧瓶应用程序中出现错误
谁能帮助我了解此错误的原因以及如何修复它？
非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/78399309/valueerror-x-has-3-features-but-multinomialnb-is-expecting-235-features-as-inp</guid>
      <pubDate>Sun, 28 Apr 2024 18:57:44 GMT</pubDate>
    </item>
    <item>
      <title>任何人都可以修复这个错误，我已经尽可能长时间地尝试这个错误，我不是一个很好的编码员</title>
      <link>https://stackoverflow.com/questions/78399063/can-anyone-fix-this-error-i-have-been-trying-this-for-as-long-as-possible-as-i</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78399063/can-anyone-fix-this-error-i-have-been-trying-this-for-as-long-as-possible-as-i</guid>
      <pubDate>Sun, 28 Apr 2024 17:29:11 GMT</pubDate>
    </item>
    <item>
      <title>Python开发中使用虚拟环境的实践</title>
      <link>https://stackoverflow.com/questions/78398967/practices-for-using-virtual-environments-in-python-development</link>
      <description><![CDATA[有人可以解释一下以下内容吗：
在 Python 项目中有效使用虚拟环境的最佳实践有哪些？
使用虚拟环境时是否有任何常见的陷阱或误解需要注意？
Python 开发者在他们的作品中使用虚拟环境吗？这对他们有什么帮助？]]></description>
      <guid>https://stackoverflow.com/questions/78398967/practices-for-using-virtual-environments-in-python-development</guid>
      <pubDate>Sun, 28 Apr 2024 16:56:18 GMT</pubDate>
    </item>
    <item>
      <title>我正在寻找这些列类型的什么类型的机器学习？</title>
      <link>https://stackoverflow.com/questions/78398611/what-type-of-machine-learning-am-i-looking-for-with-these-column-types</link>
      <description><![CDATA[我一直在学习一些关于机器学习的知识，并使用了一些模型类型（xgboost、LogisticRegression）和一些测试数据。我使用这些模型的次数越多，我就越意识到它们处理的是一种特定类型的数据，即可以转换为数字的列。甚至像汽车的品牌/型号之类的东西也可以转化为数字，因为它们是有限的并且在数据集中重复。
我真正想要使用的数据集包含名字和姓氏、公司名称、电子邮件地址等唯一的字符串。这是一个例子

&lt;标题&gt;

名字和姓氏
公司名称
电子邮件地址
是欺诈


&lt;正文&gt;

全食 CVS 评估
全食/CVS 评估
laime.barry9989@gmail.com
正确


全食店
全食店
laimeb.a.r.ry9989@gmail.com
正确


蒂娜·罗森
最佳商品鞋
tina.rosen@gmail.com
错误


乔约翰
全食品市场调查
wholefoodsmark.et.l.inc@gmail.com
正确


史黛西帕克特
S Parket 奥特莱斯
sales@parkeroutlet.com
错误


迈克尔·费兰
克罗格
b.ill.h.o.rt2.2@gmail.com
正确



这是我拥有的一小部分数据，但您可以看到它不适合我所了解和使用的模型的正常数据集。我尝试过诸如 OneHotEncoder 和 LabelEncoder 之类的东西，但它们将它们转换为实际上没有任何意义的整数，因为它们不重复。
我知道看到该示例很容易想到“哦，只需自己编写验证器来查找电子邮件中的多个句点、名称中的特定单词等”即可。但有数千个重复的欺诈帐户不适合。
所以我的问题是，是否有一种机器学习模型可以接收这些电子邮件地址/名称等内容并了解欺诈电子邮件地址/名称的样子？]]></description>
      <guid>https://stackoverflow.com/questions/78398611/what-type-of-machine-learning-am-i-looking-for-with-these-column-types</guid>
      <pubDate>Sun, 28 Apr 2024 15:01:24 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的数据增强：我应该对验证集应用数据增强吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78398283/data-augmentation-in-machine-learning-should-i-apply-data-augmentation-for-vali</link>
      <description><![CDATA[我正在皮肤损伤医学图像数据集上训练卷积神经网络。原始数据集由训练和测试文件夹组成。因此，我将一些图像从训练文件夹移动到新的有效文件夹进行验证。由于数据集不平衡，我随后将数据增强应用于训练集。我现在的问题是：我应该使用之前创建的验证集，还是通过从增强训练集中提取图像来创建新的验证集？另外，如果我使用准确性作为验证指标，验证集是否应该保持不平衡（我知道准确性需要平衡的数据集），或者每个类的样本数量是否需要相同？
使用的数据集由九个类组成。到目前为止，仅当数据增强应用于训练集和验证集时，我才能够在训练集和验证集上获得良好的准确性性能。但当我进入测试阶段时，结果却不太令人满意。我目前正在尝试使用 Keras Tuner 在平衡数据集和原始验证集上搜索各种模型。]]></description>
      <guid>https://stackoverflow.com/questions/78398283/data-augmentation-in-machine-learning-should-i-apply-data-augmentation-for-vali</guid>
      <pubDate>Sun, 28 Apr 2024 13:14:45 GMT</pubDate>
    </item>
    <item>
      <title>决策树信息增益与特征重要性</title>
      <link>https://stackoverflow.com/questions/78398063/decision-trees-information-gain-vs-feature-importance</link>
      <description><![CDATA[我基于Sklearn用Python编写了一个决策树，但是当我计算结果并显示决策树（以及20个最重要的特征）时，特征“A”被忽略了。最重要，也作为根节点。
但是，当我计算每个特征的信息增益并将结果显示在列表中时，特征“B”会出现。具有最高的信息增益(特征“A”也具有相当高的信息增益，但不如特征B)。尽管如此，特征 A 被用作根节点......所以我的问题是：我是否犯了编程错误，或者这是一种可能的情况（根据定义，具有最高信息增益的特征不被用作根节点）。 
在另一个主题中，有人写了以下内容：
&lt;块引用&gt;
对于使用信息增益的决策树，算法选择
提供最大信息增益的属性（这是
也是导致熵减少最大的属性）。

还有（尤其是这部分非常有趣）：
&lt;块引用&gt;
决策树算法是“贪婪的”算法。从某种意义上说，他们总是
选择产生最大信息增益的属性
正在考虑当前节点（分支），而无需稍后重新考虑
添加后续子分支后的属性。所以要回答你的
第二个问题：决策树算法尝试放置属性
在树根部附近信息增益最大。注意
由于算法的贪婪行为，决策树算法
不一定会产生一棵提供最大可能的树
熵的总体减少。

所以在这种情况下，它没有理由选择类别 B 而不是类别 A，这意味着我可能犯了一个编码错误..？]]></description>
      <guid>https://stackoverflow.com/questions/78398063/decision-trees-information-gain-vs-feature-importance</guid>
      <pubDate>Sun, 28 Apr 2024 11:50:34 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法评估模型是否能够识别有影响的变量（使用 make_classification 生成的变量）？</title>
      <link>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</link>
      <description><![CDATA[我有一个关于 scikit-learn 的 make_classification 的问题。我使用 make_classification（二元分类任务）创建了一个数据集，目的是测试不同模型区分重要特征和不太重要特征的能力。
如何设置一个实验来评估模型是否能够识别有影响的变量？
我查看了 make_classification 的文档，但不幸的是我没有进一步了解。
我设置了以下内容：
X,y = make_classification(n_samples=50000, n_features=10, n_informative=5,
                    n_redundant=2、n_repeated=0、n_classes=2、n_clusters_per_class=2、
                          类间隔=1，
                   Flip_y=0.01，权重=[0.9,0.1]，shuffle=True，random_state=42）

谢谢您，我们非常感谢任何想法或建议。]]></description>
      <guid>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</guid>
      <pubDate>Sun, 28 Apr 2024 11:37:08 GMT</pubDate>
    </item>
    <item>
      <title>如何将稀疏分类熵给出的预测类的二维数组输出转换为预测类</title>
      <link>https://stackoverflow.com/questions/78397693/how-to-convert-2d-array-output-of-predicted-classes-given-by-sparse-categorical</link>
      <description><![CDATA[我在大学里被分配了一项任务，编写一个简单文本数据集的分类器。我有 5 个类：[&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;]。我不太了解神经网络，所以我使用互联网写了一些东西 =)
但是
如果我使用 categorical_crossentropy，它会给我一个错误
参数“target”和“output”必须具有相同的等级 (ndim)。已收到：target。 shape=(None,), output.shape=(None,6)

如果我使用“sparse_categorical_crossentropy”，它会在输出中给出 2d 数组。
x_train, x_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

x_train = x_train / 255
x_test = x_test / 255

def b_m(hp):
model = Sequential()
activation_choice = hp.Choice(&#39;activation&#39;, values=[&#39;relu&#39;, &#39;sigmoid&#39;, &#39;tanh&#39;, &#39;elu&#39;, &#39;selu&#39;])
model.add(Dense(units=hp.Int(&#39;units_input&#39;,
min_value=512,
max_value=1024,
step=32),
input_dim=2,
activation=activation_choice))
model.add(Dense(units=hp.Int(&#39;units_hidden&#39;,
min_value=128,
max_value=600,
step=32),
activation=activation_choice))
model.add(Dense(5,activation=&#39;softmax&#39;))
model.compile(
optimizer=hp.Choice(&#39;optimizer&#39;, values=[&#39;adam&#39;,&#39;rmsprop&#39;,&#39;SGD&#39;]),
loss=&#39;sparse_categorical_crossentropy&#39;,
#loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])
return model

tuner = kt.Hyperband(b_m,
objective=&#39;val_accuracy&#39;,
max_epochs=10,
factor=3,
directory=&#39;test_dir&#39;)

stop_early = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, waiting=5)

tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])

best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]

model = tuner.hypermodel.build(best_hps)
history = model.fit(x_train, y_train, epochs=50, validation_split=0.2)

val_acc_per_epoch = history.history[&#39;val_accuracy&#39;]
best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1

hypermodel = tuner.hypermodel.build(best_hps)

hypermodel.fit(x_train, y_train, epochs=best_epoch, validation_split=0.2)

eval_result = hypermodel.evaluate(x_test, y_test)
print(&quot;[loss, test]:&quot;, eval_result)

y_pred = hypermodel.predict(x_test)


所以，我有三个问题：1. 在这种情况下最好使用哪种类型的损失？
2. 如果最好使用 categorical_crossentropy，那么如何修复发生的错误
3. 如果最好使用 sparse_categorical_crossentropy，那么如何将输出从 2d 数组转换为具有类的一维数组
请帮忙
我尝试重塑输入数据并更改模型的参数，但什么也没发生]]></description>
      <guid>https://stackoverflow.com/questions/78397693/how-to-convert-2d-array-output-of-predicted-classes-given-by-sparse-categorical</guid>
      <pubDate>Sun, 28 Apr 2024 09:26:46 GMT</pubDate>
    </item>
    <item>
      <title>我们如何以优雅的方式捕获使用optimizer.step()完成的更新？</title>
      <link>https://stackoverflow.com/questions/78392429/how-can-we-capture-update-done-with-optimizer-step-in-an-elegant-way</link>
      <description><![CDATA[我想实现一种方法，按照 Karpathy 视频中提到的想法，在使用 PyTorch 训练期间在 Tensorboard 中监控更新数据比率。我已经提出了一个解决方案，但我正在寻找一种更优雅且可配置的方法。
当前的实现直接修改训练循环如下：
对于步骤，在 data_loader 中进行批处理：
    x, y = 批次
    优化器.zero_grad()
    对于名称，model.named_pa​​rameters() 中的参数：
        如果 param.requires_grad 和“weight”是名称：
            param.data_before_step = param.data.clone()
    输出=模型(x)
    损失 = loss_fn(输出, y)
    loss.backward()
    优化器.step()
    lr_scheduler.step()
    对于名称，model.named_pa​​rameters() 中的参数：
        if hasattr(param, “data_before_step”):
            更新 = param.data - param.data_before_step
            update_to_data = (update.std() / param.data_before_step.std()).log10().item()
            summary_writer.add_scalar(f“更新：数据比率 {name}”，update_to_data，epoch * len(data_loader) + 步骤)
            param.data_before_step = param.data.clone()

但是，这种方法直接在训练循环中添加代码，这可能会使代码变得混乱，如果我们想要使其可配置，则需要 if-else 语句，这会使代码更加混乱。
我还探索过使用 PyTorch hooks 来实现这一点。我已经成功实现了一个钩子来跟踪梯度：
类 GradToDataRatioHook：
    def __init__(自身、名称、参数、start_step、summary_writer):
        self.name = 名字
        self.param = 参数
        self.summary_writer = 摘要_writer
        自我.毕业生 = []
        self.grads_to_data = []
        self.param.update_step = start_step

    def __call__(自我，毕业生)：
        self.grads.append(grad.std().item())
        self.grads_to_data.append((grad.std() / (self.param.data.std() + 1e-5)).log10().item())
        self.summary_writer.add_scalar(f&quot;Grad {self.name}&quot;, self.grads[-1], self.param.update_step)
        self.summary_writer.add_scalar(f&quot;梯度:数据比例{self.name}&quot;, self.grads_to_data[-1], self.param.update_step)
        self.param.update_step += 1

但是，实现类似的钩子来捕获更新似乎很棘手。据我了解， param.register_hook(...) 注册了钩子，该钩子在计算梯度时调用，即在 optimizer.step() 之前调用叫。虽然梯度和学习率为标准 SGD 提供了更新的直接值，但像 Adam 这样的现代优化器使更新过程变得更加复杂。我正在寻找一种以与优化器无关的方式捕获更新的解决方案，最好使用 PyTorch 挂钩。但是，任何建议或替代方法也将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78392429/how-can-we-capture-update-done-with-optimizer-step-in-an-elegant-way</guid>
      <pubDate>Fri, 26 Apr 2024 18:32:22 GMT</pubDate>
    </item>
    <item>
      <title>多类问题的层次分类方法</title>
      <link>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</link>
      <description><![CDATA[有一个多类分类任务。我的目标是使用每父节点本地分类器 (LCPN) 方法来解决这个问题。
让我解释一下如何使用 MWE。
假设我有这个虚拟数据集：
将 numpy 导入为 np
从 sklearn.datasets 导入 make_classification
从 scipy.cluster 导入层次结构

X, y = make_classification(n_samples=1000, n_features=10, n_classes=5,
                             n_信息=4）

我想出了这些类之间的距离矩阵：
d = np.array(
[[ 0.、201.537、197.294、200.823、194.517]、
 [201.537, 0., 199.449, 202.941, 196.703],
 [197.294, 199.449, 0., 198.728, 192.354],
 [200.823, 202.941, 198.728, 0., 195.972],
[[194.517, 196.703, 192.354, 195.972, 0.]]
）

因此，我确定了类层次结构，如下所示：
hc = hierarchy.linkage(d, method=&#39;complete&#39;)

得到的树状图如下：
dendrogram = hierarchy.dendrogram(hc, labels=[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;, &#39;D&#39;, &#39;F&#39;])
树状图


我使用hierarchy.to_tree()以树状结构进行说明：

我的问题：
如何按照 LCPN 方法在每个内部节点（包括根）处安装分类器，例如 DecisionTreeClassifier 或 SVM，以像在树中一样进行上图？]]></description>
      <guid>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</guid>
      <pubDate>Sat, 20 Apr 2024 14:08:05 GMT</pubDate>
    </item>
    <item>
      <title>如何消除在张量流的 Tape.gradient 方法中将虚数转换为实值的警告？</title>
      <link>https://stackoverflow.com/questions/77185089/how-to-remove-this-warning-of-casting-imaginary-into-real-values-within-tape-gra</link>
      <description><![CDATA[我正在使用tape.gradient方法来优化一些神经网络。它按预期工作，但当我在单次迭代中多次使用 Tape.gradients 计算梯度时，不断发出此警告。这意味着在单个循环内，在执行 back prop 时，它会在某个地方摆弄复数。
警告：tensorflow：您正在将complex64类型的输入转换为不兼容的dtype float64。这将丢弃虚部，并且可能不是您想要的。

cost_progress=[]
跟踪进度=[]
对于我在范围内（次数）：

  使用 tf.GradientTape() 作为磁带：
    磁带.watch(参数)
    损失，跟踪 = 成本（参数，比率）
    trace_progress.append(trace)
    cost_progress.append(损失)

  梯度 = Tape.gradient(loss, params)
  opt.apply_gradients(zip([渐变], [参数]))

现在，所有参数和损失都是 tf.float64，但仍在 Tape.gradient() 中给出了一些复杂类型，我想手动将它们转换为真实值，以便此警告停止显示在我的屏幕上。但我无法找到如何投射以免弄乱。
强制gradients = tf.cast(tape.gradient(loss, params),tf.float64)不起作用。我已验证 gradients = Tape.gradient(loss, params) 发出警告，并且 loss 和 params 均为 tf.float64 类型。]]></description>
      <guid>https://stackoverflow.com/questions/77185089/how-to-remove-this-warning-of-casting-imaginary-into-real-values-within-tape-gra</guid>
      <pubDate>Wed, 27 Sep 2023 06:26:47 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中获取多类分类问题中每个类的 SHAP 值</title>
      <link>https://stackoverflow.com/questions/71753428/how-to-get-shap-values-for-each-class-on-a-multiclass-classification-problem-in</link>
      <description><![CDATA[我有以下数据框：
导入 pandas 作为 pd
随机导入

导入xgboost
导入形状

foo = pd.DataFrame({&#39;id&#39;:[1,2,3,4,5,6,7,8,9,10],
                   &#39;var1&#39;:random.sample(范围(1, 100), 10),
                   &#39;var2&#39;:random.sample(范围(1, 100), 10),
                   &#39;var3&#39;:random.sample(范围(1, 100), 10),
                   &#39;类&#39;: [&#39;a&#39;,&#39;a&#39;,&#39;a&#39;,&#39;a&#39;,&#39;a&#39;,&#39;b&#39;,&#39;b&#39;,&#39;c&#39;,&#39;c&#39;,&#39;c&#39;]})

我想运行分类算法来预测 3 个类别。
因此，我将数据集分成训练集和测试集，并运行了 xgboost 分类
cl_cols = foo.filter(regex=&#39;var&#39;).columns
X_train, X_test, y_train, y_test = train_test_split(foo[cl_cols],
                                                        foo[[&#39;类&#39;]],
                                                        测试大小=0.33，随机状态=42）


模型= xgboost.XGBClassifier（目标=“二进制：逻辑”）
model.fit(X_train, y_train)

现在我想获取每个类的平均 SHAP 值，而不是从此代码生成的绝对 SHAP 值的平均值：
shap_values = shap.TreeExplainer(model).shap_values(X_test)
shap.summary_plot(shap_values, X_test)


此外，该图将 class 标记为 0,1,2。我怎么知道 0,1 和 0,1 属于哪一类？ 2与原文对应？
因为这段代码：
shap.summary_plot(shap_values, X_test,
                 类名= [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])

给出

和这段代码：
shap.summary_plot(shap_values, X_test,
                 类名= [&#39;b&#39;, &#39;c&#39;, &#39;a&#39;])

给出

所以我不再确定这个传说了。
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/71753428/how-to-get-shap-values-for-each-class-on-a-multiclass-classification-problem-in</guid>
      <pubDate>Tue, 05 Apr 2022 14:21:03 GMT</pubDate>
    </item>
    <item>
      <title>批量读取Cifar10数据集</title>
      <link>https://stackoverflow.com/questions/37512290/reading-cifar10-dataset-in-batches</link>
      <description><![CDATA[我正在尝试读取 CIFAR10 数据集，这些数据集是从 https:// www.cs.toronto.edu/~kriz/cifar.html&gt;。我正在尝试使用 pickle 将其放入数据框中并读取其中的“数据”部分。但我收到此错误。
KeyError Traceback（最近一次调用最后一次）
&lt;ipython-input-24-8758b7a31925&gt;在&lt;模块&gt;()中
----&gt; 1 unpickle(&#39;数据集/cifar-10-batches-py/test_batch&#39;)

&lt;ipython-input-23-04002b89d842&gt;在unpickle（文件）中
      3 fo = 打开（文件，&#39;rb&#39;）
      4 dict = pickle.load(fo, 编码 =&#39;字节&#39;)
----&gt; 5 X = 字典[&#39;数据&#39;]
      6 fo.close()
      7 返回字典

密钥错误：“数据”。
我正在使用 ipython，这是我的代码：
def unpickle(文件):

 fo = 打开（文件，&#39;rb&#39;）
 dict = pickle.load(fo, 编码 =&#39;字节&#39;)
 X = 字典[&#39;数据&#39;]
 fo.close()
 返回字典

unpickle(&#39;数据集/cifar-10-batches-py/test_batch&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/37512290/reading-cifar10-dataset-in-batches</guid>
      <pubDate>Sun, 29 May 2016 16:29:55 GMT</pubDate>
    </item>
    </channel>
</rss>