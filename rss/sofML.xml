<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Wed, 12 Mar 2025 01:18:45 GMT</lastBuildDate>
    <item>
      <title>创建用于水压预测的ML模型</title>
      <link>https://stackoverflow.com/questions/79502209/creating-ml-model-for-water-pressure-prediction</link>
      <description><![CDATA[我正在从事我的最后一年项目，我真的可以使用社区的一些指导。该项目涉及监测管道系统中的水压，并使用机器学习来检测异常。
问题：
•我有一个主管，带有压力传感器，可连续监视水压。
•连接到主管的多个阀门可以打开或关闭，创建不同的流动方案。
•我想开发一个可以：的ML模型

预测基于阀状态的预期压力（开放/关闭）。
检测异常，如果实时压力显着偏离预测值。

挑战：
•在许多阀中，组合数的数量呈指数增长（n个阀门为2ⁿ）。存储所有可能的压力值是不切实际的。
•我需要一种在不手动记录每个阀组合的情况下建模系统的方法。
•理想情况下，该模型也应概括和预测，即使是看不见的组合也应推广压力。
到目前为止我的方法：
•我已经考虑使用线性回归模型来映射阀态以施加压力，但担心它可能无法捕获复杂的关系。
•我正在探索神经网络或决策树，但是我不确定如何有效地构建输入功能。
•我计划从传感器中收集现实世界数据，并使用它来训练和验证模型。
我需要帮助：

 最佳ML方法：我应该坚持简单回归，还是像随机森林，梯度增强甚至LSTM之类的东西会更好？

 功能工程：如何有效地表示阀门？

 模型评估：可靠评估性能和标记异常的最佳方法是什么？

 缩放：如何为带有许多阀门的大型系统做这项工作？

]]></description>
      <guid>https://stackoverflow.com/questions/79502209/creating-ml-model-for-water-pressure-prediction</guid>
      <pubDate>Tue, 11 Mar 2025 21:46:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在梯度下降线性回归中减轻高MAE/MSE？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79501719/how-to-mitigate-high-mae-mse-in-gradient-descent-linear-regression</link>
      <description><![CDATA[我正在通过从头开始实现机器学习算法。从基础知识开始，我正在研究线性回归。但是，我面临模型性能的问题。鉴于数据集的简单性，我希望该模型可以密切预测输出，旨在MAE/MSE小于1。。
这是我目前的结果：
  [[[29.76307389]]＃重量
MAE：11.860197526386747
MSE：[320.16732974]
RMSE：[17.89322022]
 
我的问题是：如何减轻高成本功能？这是数据扩展问题（我认为不是）吗？我在代码逻辑中看不到任何缺陷。

我的实现：
 导入numpy作为NP
从sklearn.datasets导入make_regression
来自sklearn.model_selection导入train_test_split

班级体重：

    def __init __（self，n_features：int）：
        self.lim = 1 / np.sqrt（n_features）
        self.n_features = n_features
        self.seed = 42
        np.random.seed（self.seed）

    def Random_uniform（self）：
        返回np.random.uniform（-self.lim，self.lim，（self.n_features，1））

班级回归：
    def __init __（self，n_iter：int，l_rate：float）：
        self.n_iter = n_iter
        self.l_rate = l_rate
        self.w =无
        self.b = 0
        self.Error = 0

    def预测（self，x）：
        返回np.dot（x，self.w） + self.b

    def fit（self，x，y，reg_factor：str = none）：
        n_samples，n_features = x。形状
        如果self.w是无：＃持续权重
            self.w = strige（n_features）.random_rand（）
        y = np.Reshape（y，（-1，1））＃将数组转换为列向量
        正则化= self.regularize（）

        对于_范围（self.n_iter）：
            y_pred = self.predict（x）
            self.error = y -y__pred
            grad_w =（-2 * np.dot（x.t，self.error） / n_samples） 
            grad_b =（-2 * np.sum（self.error）） / n_samples
            self.w-- = self.l_rate * grad_w＃l_rate *（grad_w +正则化_factor）
            self.b- = self.l_rate * grad_b＃l_rate * grad_b


类线性回归（回归）：
    def __init __（self，n_iter：int，l_rate：float）：
        super（）.__ init __（n_iter，l_rate）

    def渐变发达（self，x，y）：
        super（）。拟合（x，y）

类评估对：
    def __init __（self，n：int，y，y_pred）：
        self.n = n
        self.y = np.Reshape（y，（-1，1））＃实际值
        self.y_pred = y_pred＃预测值

    Def Mae（自我）：
        返回np.mean（np.abs（self.y -self.y_pred））
    Def MSE（自我）：
        返回总和（np.pow（（（self.y -self.y_pred），2）） / self.n
    def rmse（self）：
        返回np.sqrt（sum（np.pow（（（self.y -y -self.y_pred）），2）） / self.n）

x，y = make_regression（n_samples = 1000，n_features = 1，噪声= 15，Random_state = 4）

    x_train，x_test，y_train，y_test = train_test_split（
        X，Y，test_size = 0.4，Random_State = 42
    ）

    LR =线性重试（1000，0.01）
    lr.gradientdescent（x_train，y_train）
    lr.printweights（）
    y_pred = lr.predict（x_train）

    mae = essalmetrics（n = x_train.shape [0]，y = y_train，y_pred = y_pred）.mae（）
    打印（f＆quot; mae：{mae}＆quot;）
    MSE = essutuationMetrics（n = x_test.shape [0]，y = y_train，y_pred = y_pred）.mse（）
    打印（MSE：{MSE}＆quot;）
    rmse = evaluationMetrics（n = x_test.shape [0]，y = y_train，y_pred = y_pred）.rmse（）
    打印（f＆quot&#39;rmse：{rmse}＆quot;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79501719/how-to-mitigate-high-mae-mse-in-gradient-descent-linear-regression</guid>
      <pubDate>Tue, 11 Mar 2025 18:00:42 GMT</pubDate>
    </item>
    <item>
      <title>有关机器学习模型上等渗回归的适用性的问题[封闭]</title>
      <link>https://stackoverflow.com/questions/79501560/question-about-suitability-of-isotonic-regression-on-machine-learning-models</link>
      <description><![CDATA[我知道等渗回归是一种很好的校准方法，尤其是对于单调增加的关系而言。我的数据集具有多个功能，结果是二进制的。我正在该数据集培训机器学习模型，并预测概率。我想校准预测的概率，但是我不确定等渗回归是否是一个不错的选择，因为数量超过10个，结果是二进制的，而不是连续的。校准方法适合这种情况吗？]]></description>
      <guid>https://stackoverflow.com/questions/79501560/question-about-suitability-of-isotonic-regression-on-machine-learning-models</guid>
      <pubDate>Tue, 11 Mar 2025 17:01:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Python SDK将环境变量传递到亚马逊萨吉式制造商的自定义培训脚本？</title>
      <link>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</link>
      <description><![CDATA[我正在使用Amazon Sagemaker中的脚本进行自定义模型，并使用Python SDK启动这项工作。我想将一些环境变量（例如API键或配置标志）传递到培训作业，以便通过OS.Environ在脚本中访问它们。
这是我的代码的简化版本：
 来自sagemaker.stimator导入估算器

估算器=估算器（
    image_uri =&#39;123456789012.dkr.ecr.us-west-2.amazonaws.com/my-custom-image：最新图像&#39;，
    角色=角色，
    instance_count = 1，
    instance_type =&#39;ml.g5.xlarge&#39;，
    entry_point =&#39;train.py&#39;，
    source_dir =&#39;src&#39;，
    环境= {
        &#39;my_api_key&#39;：&#39;abcdef123456&#39;，
        &#39;debug_mode&#39;：&#39;true&#39;
    }
）
 
在我的培训脚本中，我尝试读取变量：
 导入OS

api_key = os.environ.get（&#39;my_api_key&#39;）
打印（＆quot; api键：＆quot; api_key）
 
这是使用Python SDK将环境变量传递给萨吉人培训工作的正确方法吗？我应该注意任何局限性或最佳实践，特别是对于诸如API键之类的敏感信息？]]></description>
      <guid>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</guid>
      <pubDate>Tue, 11 Mar 2025 10:00:30 GMT</pubDate>
    </item>
    <item>
      <title>当我试图运行命令spartlit运行main.py时，为什么我会得到RuntimeError：没有运行事件循环，并且在我的VS代码中？</title>
      <link>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</guid>
      <pubDate>Tue, 11 Mar 2025 09:34:06 GMT</pubDate>
    </item>
    <item>
      <title>如何删除具有不同文件名和大小但在Android中相同的内容的重复图像？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79499987/how-to-delete-duplicate-images-with-different-file-names-and-sizes-but-identical</link>
      <description><![CDATA[我在我的Android设备上有大量从iPhone传输的图像。不幸的是，我现在有许多重复的图像：

没有相同的文件名。
没有相同的文件大小或分辨率。
但包含相同的视觉内容（相同图像）。

我想根据其内容查找并删除这些重复的图像（不是基于文件名，大小或分辨率）。
我尝试通过Google App搜索文件中的内置选项，但找不到根据内容检测重复图像的任何选项。
是否有任何可以根据内容扫描和删除重复图像的Android应用程序或工具？另外，我可以使用任何Python脚本或开源工具来实现这一目标吗？我的目标是自动删除所有具有相同内容的重复图像，无论其文件名，大小或分辨率如何。]]></description>
      <guid>https://stackoverflow.com/questions/79499987/how-to-delete-duplicate-images-with-different-file-names-and-sizes-but-identical</guid>
      <pubDate>Tue, 11 Mar 2025 07:53:05 GMT</pubDate>
    </item>
    <item>
      <title>与拆分数量少的类交叉验证的错误[关闭]</title>
      <link>https://stackoverflow.com/questions/79499678/error-on-crossvalidation-with-classes-that-have-less-samples-than-number-of-spli</link>
      <description><![CDATA[我目前正在研究这个问题：
 https://github.com/scikit-com/scikit-learn/scikit-learn/scikit-learn/scikit-learn/scikit-learn/issues/30832  
我正在研究修复它的可能方法。
说明：
使用logistic回归和交叉验证时，在交叉验证时，样本少于拆分数量的类别少于每倍的样本，导致执行Python程序时出现错误。
即使这可能是一个数据问题，也应该有更好的方法来处理它。
复制错误的代码：
 来自sklearn.linear_model导入logisticRegressioncv
导入numpy作为NP
n，m = 20，5
x = np.random.randn（n，m）
y = np.random.randint（0，2，n）
y [-3：] = [3，4，5]
logisticRegressioncv（）。fit（x，y）
 
我想到的一些方法：

将系数设置为代表性不足的类中的0; 
根据我们拥有的真实数据自动创建新数据（即使仅是1个示例）; 
重复数据，直到最低样本的类达到分裂次数； 
简单地提出一个更有意义的例外。

这只是一个数据问题，我应该提出一个例外，还是我可以在这里做更多的事情？
您能给我一些有关解决此问题的好方法的提示或想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79499678/error-on-crossvalidation-with-classes-that-have-less-samples-than-number-of-spli</guid>
      <pubDate>Tue, 11 Mar 2025 04:44:50 GMT</pubDate>
    </item>
    <item>
      <title>我可以将Pytorch与Django Web框架集成在一起吗？</title>
      <link>https://stackoverflow.com/questions/79499340/can-i-integrate-pytorch-with-django-web-framework</link>
      <description><![CDATA[我希望使用Django在网站上创建一些游戏。我想对游戏进行一些机器学习，以便玩家可以与机器学习模型进行比赛。 Django和Pytorch的结合是否可以？我听说了一些称为ONNX的东西，可以帮助将模型提供到前端，我只是想仔细检查与Django一起使用的，而不仅仅是与Nodejs一起使用。如果它不起作用，那么我会感谢任何其他解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/79499340/can-i-integrate-pytorch-with-django-web-framework</guid>
      <pubDate>Mon, 10 Mar 2025 23:06:51 GMT</pubDate>
    </item>
    <item>
      <title>如何训练网络以检测LIDAR PointCloud对象[关闭]</title>
      <link>https://stackoverflow.com/questions/79498544/how-to-train-a-network-to-detect-lidar-pointcloud-objects</link>
      <description><![CDATA[我正在使用OS1激光雷达传感器，因此我可以访问点云数据集。我需要能够识别对象。
我知道如何预处理数据，如何注释数据，并且我一直在阅读有关尖头柱和深入学习以学习如何训练网络的信息，但是没有存储库来解释如何在自定义数据上进行操作。 
如何训练网络以获取自定义数据？你有消息来源吗？他们中的大多数与汽车或行人有关，但我想确定自己的物体。
我一直在使用MATLAB可视化和注释我感兴趣的对象，但是我无法继续下一步，因为我不了解它们。
https://www.mathworks.com/help/lidar/ug/object-detection-with-point-clouds.html]]></description>
      <guid>https://stackoverflow.com/questions/79498544/how-to-train-a-network-to-detect-lidar-pointcloud-objects</guid>
      <pubDate>Mon, 10 Mar 2025 16:00:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地运行DeepSeek模型</title>
      <link>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</link>
      <description><![CDATA[我试图根据他们的说明在本地运行DeepSeek，但它不能带来一些愚蠢的错误（我将稍后显示）。
这就是我正在做的。

从此处下载最小型号（3.5GB） noreferrer“&gt; https://huggingface.co/deepseek-ai/deepseek-r1-distill-qwen-1.5b  
按照此处的步骤操作： https://github.com/deepseek-ai/deepseek-v3?tab=readMe-Readme-ov-file#6-how-to-to-to-run-locally  

 2.1获取这个项目
 https://github.com/deepseek-ai/deepseek-ai/deepseek-ai/deepseek-v3.git 
 2.2运行码头容器类似于预先创建的卷以放置模型
  docker run  -  gpus all -it -it -name deepSeek01 -rm -mount source = deepSeekv3，target =/root/deepSeekv3 python：3.10 -Slim bash
 
我正在使用python：3.10-slim，因为这里（ https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-how-to-run-locally ）
＆quot&#39; linux只有python 3.10。 Mac和Windows不支持。
 2.3安装最新更新
apt-get Update 
 2.4获取此文件 https://github.com/deepseek-ai/deepseek-v3/blob/main/main/inference/requirements.txt 并安装要求
  pip install -r sumpliont.txt
 
 2.5将模型复制到安装在Docker容器上的音量。这5个文件来自此处 https：//hugging.co/deepseek-aiek-ai/deepseek-ai/deepseek-ai/deepseek-ai/deepseek/deepseek-ipseek-r1-r1-r1-r1-pp&gt;   config.json
generation_config.json
模型。系统
tokenizer.json
tokenizer_config.json
 
 2.6在此处编写的模型转换 https://github.com/deepseek-ai/deepseek-v3?tab=readme-readme-ov-file#model-weights-conversion 通过此命令
  python convert.py-hf-ckpt-path/root/deepSeekv3/source_model -save-path/root/deepSeekv3/converted_model -n-experts 256-model-parelally 16
 
在此步骤中（转换模型）我得到了此错误
  trackback（最近的最新通话）：
  file＆quort＆quort＆quot deepseekv3/inference/convert.py&quot;，第96行，in＆lt; module＆gt;
    main（args.hf_ckpt_path，args.save_path，args.n_experts，args.model_parallel）
  file＆quot＆quot&#39;deepseekv3/inference/convert.py&quot;，第63行，在main中
    主张映射中的密钥
断言
 
因此，基本上，下一步没有意义，因为这是必不可少的步骤。
我的问题：

我做错了什么？
 YouTube上有一些视频，其中DeepSeek与Ollama一起安装了。真的需要吗？我是否应该像他们在这里描述的那样能够运行它， https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-to-run-locally ？

更新1 
为了调试一点，我添加了这2行。
  print（＆quot;丢失键：＆quot;键）
打印（可用键：＆quot; list（mapping.keys（）））
 
缺少键是以下内容：
  embed_tokens
input_layernorm
down_proj
gate_proj
UP_PROJ
post_attention_layernorm
k_proj
 
虽然所有这些都确实存在于模型中。
另外，@hans Kilian在评论中提到，我可能会放一些文件，而这些文件不需要到source_model文件夹中。
我在convert.py中检查了第11行，其中一些键在模型中不存在。]]></description>
      <guid>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</guid>
      <pubDate>Tue, 25 Feb 2025 22:14:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么拥抱面提供的DeepSeek代码会导致“未知量化类型”错误？</title>
      <link>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</link>
      <description><![CDATA[我正在使用huggingface的此代码：
此代码直接从 deepseek上的huggingface网站页面上的页面

 来自变形金刚导入管道

消息= [
{&#39;&#39;：＆quot“ user quot”内容“：;
这是给出的
pipe =管道（＆quot&#39;text-generation＆quot; deepseek-ai/deepseek-r1＆quort; trust_remote_code = true）
管道（消息）
 

，但我无法加载模型。当我这样做时，我会得到这个问题：
  file＆quot＆lt; ...＆gt;/site-packages/transformers/quantizers/auto.py＆quot;，第97行，在from_dict

提高价值Error（

ValueError：未知量化类型，获得FP8-支持类型为： 
[&#39;awq&#39;，&#39;bitsandbytes_4bit&#39;，&#39;bitsandbytes_8bit&#39;，&#39;gptq&#39;，&#39;aqlm&#39;，&#39;quanto&#39;，&#39;eetq&#39;，&#39;eetq&#39;， 
&#39;HQQ&#39;，“压缩张量”，“ fbgemm_fp8&#39;，&#39;torchao&#39;，&#39;bitnet&#39;]
 
我尝试了不同的代码：
 导入火炬
generate_text = pipeline（model =; deepSeek-ai/deepSeek-r1; torch_dtype = torch.bfloat16，trust_remote_code = true，device_map =; auto;
generate_text（消息）
 
这给出以下错误：

raise ValueError( ValueError: Unknown quantization type, got fp8 - supported types are: [&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39;, &#39;higgs&#39;, &#39;hqq&#39;, &#39;compressed-tensors&#39;, &#39;fbgemm_fp8&#39;, &#39;torchao&#39;，&#39;bitnet&#39;，&#39;vptq&#39;] 

我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>Importerror：无法从“火炬”（未知位置）导入“张量”的名称</title>
      <link>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</link>
      <description><![CDATA[我正在尝试从Pytorch导入 ：
 来自火炬导入张量
 
但我一直遇到此错误：
  Importerror：无法从“火炬”（未知位置）导入名称&#39;tensor&#39;
 
我尝试的是：

检查是否已安装了Pytorch（ pip show torch ），我正在使用版本 2.5.1 。。
重新安装了Pytorch：
  pip卸载火炬
PIP安装火炬
 

测试了python壳中的导入，但错误仍然存​​在。

环境：

 Python版本：3.10 
 Pytorch版本：2.5.1 
 OS：Windows 10 
虚拟环境：是

我该如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</guid>
      <pubDate>Sat, 18 Jan 2025 13:04:35 GMT</pubDate>
    </item>
    <item>
      <title>小学习率与大学习率</title>
      <link>https://stackoverflow.com/questions/62690725/small-learning-rate-vs-big-learning-rate</link>
      <description><![CDATA[在对神经网络的反向传播学习中，我们是否应该从较小的学习率开始并在学习过程中慢慢增加它？还是我们应该从大型学习率开始，并在学习过程中慢慢降低它？
哪个是正确的？]]></description>
      <guid>https://stackoverflow.com/questions/62690725/small-learning-rate-vs-big-learning-rate</guid>
      <pubDate>Thu, 02 Jul 2020 07:02:54 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch模型没有训练</title>
      <link>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</link>
      <description><![CDATA[我有一个我无法解决的问题。我正在尝试构建CIFAR -10分类器，但是我每批随机跳跃后我的损失值即使在同一批批次上也无法改善（我什至无法用一批批量过度拟合），所以我想唯一可能的原因是 - 权重是没有更新。 
 我的模块类 
 类NET（NN.MODULE）：
def __init __（自我）：
    超级（net，self）.__ init __（）
    self.conv_pool = nn.Sequepential（
        nn.conv2d（3，64，3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（64、128、3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（128，256，3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（256，512，3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（512，512，1），
        nn.relu（），
        nn.maxpool2d（2，2））

    self.fcnn = nn。
        nn.linear（512，2048），
        nn.relu（），
        nn.linear（2048，2048），
        nn.relu（），
        nn.linear（2048，10）
    ）

def向前（self，x）：
    x = self.conv_pool（x）
    X = X.View（-1，512）
    x = self.fcnn（x）
    返回x
 
优化器我正在使用：
  net = net（）
标准= nn.Crossentropyloss（）
优化器= optim.sgd（net.parameters（），lr = 0.001，动量= 0.9）
 
我的火车功能：
  def train（）：
对于范围（5）范围内的时期：＃多次循环数据集循环
    对于我的范围（0，df_size）：
        ＃获取数据

        尝试：
            图像，标签= LoadBatch（DS，I）
        除了baseexception：
            继续

        ＃ 裹 
        输入=变量（图像）

        优化器.zero_grad（）

        输出= NET（输入）

        损失=标准（输出，变量（标签））

        loss.backward（）
        优化器.step（）
        ACC =测试（图像，标签）
        打印（“损失：” + str（lose.data [0]） +“精度％：” + str（acc） +“迭代：” + str（i））

        如果我％40 == 39：
            TORCH.SAVE（net.state_dict（），“ model_save_cifar”）

    打印（“完成时代” + str（epoch））
 
我正在使用 batch_size  = 20， image_size  = 32（cifar-10）
  loadBatch 功能返回 longtensor  20x3x32x32的元组，用于图像的 longtensor  20x1 for Labels 
，如果您能帮助我或建议解决方案，我会感到非常高兴（我猜想是因为NN中的顺序模块，但是我传递给优化器的参数似乎是正确的））]]></description>
      <guid>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</guid>
      <pubDate>Thu, 27 Jul 2017 19:07:27 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法选择</title>
      <link>https://stackoverflow.com/questions/15292547/machine-learning-algorithm-selection</link>
      <description><![CDATA[我是机器学习的新手。我的问题是制作一台机器，根据学生的位置和感兴趣的领域为学生选择大学。即，应该在同一城市中选择与学生地址相同的大学。我对选择算法感到困惑，我可以将perceptron算法用于此任务。 ]]></description>
      <guid>https://stackoverflow.com/questions/15292547/machine-learning-algorithm-selection</guid>
      <pubDate>Fri, 08 Mar 2013 11:07:51 GMT</pubDate>
    </item>
    </channel>
</rss>