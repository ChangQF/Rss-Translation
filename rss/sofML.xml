<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 28 Dec 2023 18:17:03 GMT</lastBuildDate>
    <item>
      <title>Errno 2]使用 pydub 时没有这样的文件或目录：'ffprobe'</title>
      <link>https://stackoverflow.com/questions/77728410/errno-2-no-such-file-or-directory-ffprobe-when-using-pydub</link>
      <description><![CDATA[当我运行以下代码时，收到以下错误消息：[Errno 2] No such file or directory: &#39;ffprobe&#39;：
`对于剩余剪辑中的 mp3_clip：
wav_clip = os.path.splitext(mp3_clip)[0] + “.wav”
如果不是 os.path.exists(wav_clip):
    Convert_mp3_to_wav(mp3_clip, wav_clip)`

我知道问题与 pydub 找不到 ffprobe 有关，但是当我运行 which ffprobe 或 which ffmpeg 时，我的路径 /opt/homebrew/bin/ffmpeg、/opt/homebrew/bin/ffprobe 中都有。
我不太确定如何解决它或者这是否是 m1 问题。我感谢您的帮助！
我希望它从 mp3 文件创建 wav 文件]]></description>
      <guid>https://stackoverflow.com/questions/77728410/errno-2-no-such-file-or-directory-ffprobe-when-using-pydub</guid>
      <pubDate>Thu, 28 Dec 2023 17:50:40 GMT</pubDate>
    </item>
    <item>
      <title>在 WSL conda 环境中安装 lightgbm GPU</title>
      <link>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</link>
      <description><![CDATA[有人有安装指南吗？
我检查了多个来源，但仍然无法安装。
我尝试了 pip 和 conda，但都返回错误：
[LightGBM] [警告] 目前不支持在 CUDA 中使用稀疏特征。
[LightGBM] [致命] 此版本中未启用 CUDA Tree Learner。
请使用 CMake 选项 -DUSE_CUDA=1 重新编译

我尝试过的内容如下：
git clone --recursive https://github.com/microsoft/LightGBM
cd LightGBM/
mkdir -p 构建
光盘构建
cmake -DUSE_GPU=1 ..
使-j$(nproc)
cd ../python-package
点安装。

]]></description>
      <guid>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</guid>
      <pubDate>Thu, 28 Dec 2023 17:34:48 GMT</pubDate>
    </item>
    <item>
      <title>我的代码行中出现以下错误，可能是什么原因？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77728129/i-am-getting-the-following-error-in-my-code-line-what-could-be-the-reason</link>
      <description><![CDATA[我的代码行：
将 numpy 导入为 np
将 pandas 导入为 pd
将seaborn导入为sns
从 matplotlib 导入 pyplot 作为 plt

从 statsmodels.tsa.api 导入 ExptentialSmoothing、SimpleExpSmoothing、Holt
从 sklearn. Linear_model 导入 LinearRegression

进口警告
warnings.filter 警告(&#39;忽略&#39;)

df = pd.read_csv(“monthly_csv.csv”)
df.head()

警告：
NameError Traceback（最近一次调用最后一次）
第 1 行 [4] 中的单元格
----&gt; `1 df = pd.read_csv(&quot;monthly_csv.csv&quot;)
      2 df.head()`

名称错误：名称“pd”未定义

我尝试运行代码，但它不起作用。我应该编辑什么才能让它工作？]]></description>
      <guid>https://stackoverflow.com/questions/77728129/i-am-getting-the-following-error-in-my-code-line-what-could-be-the-reason</guid>
      <pubDate>Thu, 28 Dec 2023 16:46:50 GMT</pubDate>
    </item>
    <item>
      <title>将文本转换为十进制数量的问题（处理“3个半”场景）</title>
      <link>https://stackoverflow.com/questions/77728048/issue-with-converting-text-to-decimal-quantities-handling-3-and-a-half-scenar</link>
      <description><![CDATA[此代码应将文本转换为小数
如果我写三个，它会将其转换为 3，但是当我写三个半时会出现问题
这种情况有什么解决办法吗？
示例：
“请给我三个半番茄和一瓶牛奶，三公斤胡萝卜和半公斤豆子最后一瓶水，谢谢”
结果：
购物清单：
1瓶牛奶
3.0公斤胡萝卜
0.5公斤番茄
1.0瓶水
0.5公斤豆子

结果应该是：
购物清单：
1瓶牛奶
3.0公斤胡萝卜
3.5公斤番茄
1.0瓶水
0.5公斤豆子

def Convert_to_decimal(quantity_text):
    数量文本 = 数量文本.lower()
    如果数量文本==&#39;一半&#39;：
        返回0.5
    elif数量_文本==&#39;季度&#39;：
        返回 0.25
    数量文本中的 elif &#39;/&#39;：
        分数 = text_to_fraction(quantity_text)
        如果分数不是 None：
            返回浮点数（分数）
    elif数量_文本.isdigit():
        返回浮点数（数量文本）
    别的：
        单词到数字 = {
            “一”：1、“二”：2、“三”：3、“四”：4、“五”：5、
            “六”：6、“七”：7、“八”：8、“九”：9、“十”：10、
            “十一”：11、“十二”：12、“十三”：13、“十四”：14、
            “十五”：15、“十六”：16、“十七”：17、“十八”：18、
            “十九”：19、“二十”：20、“三十”：30、“四十”：40、
            “五十”：50、“六十”：60、“七十”：70、“八十”：80、
            “九十”：90
        }

        单词 = amount_text.split()
        总数量 = 0
        当前编号 = 0
        分数 = []

        # 将数字单词转换为实际数字
        字中字：
            如果单词在words_to_numbers中：
                当前数字+=单词到数字[单词]
            elif 词 == &#39;和&#39;:
                pass # 忽略“和”
            elif &#39;/&#39; 在单词中：
                分数 = text_to_fraction(单词)
                如果分数不是 None：
                    分数.append(分数)
            别的：
                尝试：
                    数字=浮点（字）
                    当前编号 += 编号
                除了值错误：
                    经过

        # 检查是否有“a half”，如果找到则添加 0.5
        如果单词中的“a”和单词中的“half”：
            总数量 += 0.5

        总数量 += 当前数量 + 总和（分数）
        返回总数量

&lt;前&gt;&lt;代码&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77728048/issue-with-converting-text-to-decimal-quantities-handling-3-and-a-half-scenar</guid>
      <pubDate>Thu, 28 Dec 2023 16:30:50 GMT</pubDate>
    </item>
    <item>
      <title>将矩阵映射到坐标平面</title>
      <link>https://stackoverflow.com/questions/77727863/mapping-a-matrix-onto-a-coordinate-plane</link>
      <description><![CDATA[我正在研究如何将矩阵映射到坐标平面上。例如，我们考虑一个 4x4 矩阵。我希望这个矩阵映射到坐标平面上，x 轴上的点范围为 -2 到 +2，y 轴上的点范围为 -2 到 +2。矩阵的中心应始终位于点 (0,0)。因此，点(-1.5,1.7)应该对应于矩阵[0][0]点。有没有一种技术可以实现这一点？
]]></description>
      <guid>https://stackoverflow.com/questions/77727863/mapping-a-matrix-onto-a-coordinate-plane</guid>
      <pubDate>Thu, 28 Dec 2023 15:50:25 GMT</pubDate>
    </item>
    <item>
      <title>无标签预测</title>
      <link>https://stackoverflow.com/questions/77727723/prediction-without-labels</link>
      <description><![CDATA[我被分配到一个项目，我必须根据某些功能确定项目的可靠性。我有一个包含近 8000 个条目的数据集。每个条目都有 5 个功能。特征是 1- 手动交易数量 2- 供应商的交付绩效 3- 审核数量等。我没有项目可靠性的标记数据，因此监督学习不是一种选择。我知道无监督学习提供了一些根据输入特征对项目进行分类的想法。但我需要确定项目可靠性的分数。我想知道我该如何处理这样的项目。我很感激任何建议。
我问了一个关于如何解决问题的问题。我期待一些主动性]]></description>
      <guid>https://stackoverflow.com/questions/77727723/prediction-without-labels</guid>
      <pubDate>Thu, 28 Dec 2023 15:20:26 GMT</pubDate>
    </item>
    <item>
      <title>将回归问题中的预测值转换为实际值</title>
      <link>https://stackoverflow.com/questions/77726639/covert-the-predicted-values-into-the-actual-ones-in-regression-problem</link>
      <description><![CDATA[我有一个回归代码，它获取数据并使用 one-hot 编码器将其转换为数值，.. 用于数值和分类值并预测温度（目标类别）。
我想显示代码的实际预测值而不是编码的值。
这是代码：
# 特征工程步骤（缩放和编码）
numeric_cols = data.select_dtypes(include=[&#39;number&#39;]).columns
categorical_cols = data.select_dtypes(exclude=[&#39;number&#39;]).columns

缩放器 = MinMaxScaler()
数据[数值列] = scaler.fit_transform(数据[数值列])

数据 = pd.get_dummies(数据, columns=categorical_cols, drop_first=True)

# 反转温度缩放以获得原始值
温度缩放器 = MinMaxScaler()
temp = data[&#39;家里设置的温度&#39;].values.reshape(-1, 1)
data[&#39;家里设置的温度&#39;] = temp_scaler.fit_transform(温度)

# 将数据拆分为特征 (X) 和目标变量 (y)
X = data.drop(columns=[&#39;家里设置的温度&#39;])
y = data[&#39;家中设置的温度&#39;]

# 将数据拆分为训练集（X_train）和测试集（X_test，y_train，y_test）
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

有任何帮助来显示预测的实际值而不是编码的预测值吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77726639/covert-the-predicted-values-into-the-actual-ones-in-regression-problem</guid>
      <pubDate>Thu, 28 Dec 2023 11:38:30 GMT</pubDate>
    </item>
    <item>
      <title>model.fit() 不使用 GPU，在 google colab 中训练深度学习模型</title>
      <link>https://stackoverflow.com/questions/77726390/model-fit-is-not-using-gpu-training-deep-learning-model-in-google-colab</link>
      <description><![CDATA[我正在 google colab pro 上训练我的模型，我看到我已连接到 V100 GPU 运行时，但训练并未使用它，仅使用 RAM。这就是我加载数据的方式，也许有帮助：
def data_generator(nifti_files, mask_files):
    对于 zip 中的 nifti_file、mask_file(nifti_files, mask_files)：
        nifti_image = np.load（nifti_file）
        nifti_mask = np.load（掩码文件）

        裁剪图像 = nifti_image[56:184, 56:184, 13:141]
        裁剪后的掩码 = nifti_mask[56:184, 56:184, 13:141]

        产量（cropped_image，cropped_mask）

# 创建数据集
数据集 = tf.data.Dataset.from_generator(
    lambda：data_generator（train_volumes，train_masks），
    输出签名=(
        tf.TensorSpec(形状=(128, 128, 128, 1), dtype=tf.float32),
        tf.TensorSpec(形状=(128, 128, 128, 4), dtype=tf.float32)
    ）
）

dataset_val = tf.data.Dataset.from_generator(
    lambda: data_generator(val_volumes, val_masks),
    输出签名=(
        tf.TensorSpec(形状=(128, 128, 128, 1), dtype=tf.float32),
        tf.TensorSpec(形状=(128, 128, 128, 4), dtype=tf.float32)
    ）
）

这是资源，在这里您可以看到没有使用 GPU：
图片]]></description>
      <guid>https://stackoverflow.com/questions/77726390/model-fit-is-not-using-gpu-training-deep-learning-model-in-google-colab</guid>
      <pubDate>Thu, 28 Dec 2023 10:43:45 GMT</pubDate>
    </item>
    <item>
      <title>脑肿瘤生存模型的预测结果是二元的——如何解释？</title>
      <link>https://stackoverflow.com/questions/77725853/predicted-results-from-brain-tumor-survival-model-are-binary-how-to-interpret</link>
      <description><![CDATA[我正在使用 BraTS20 数据集进行“脑肿瘤总体生存预测”。
模型的输出是一个二进制数组，但是如何预测患者的生存时间？
为什么预测结果是二进制的？
如何在脑肿瘤生存时间的背景下解释这些二元结果？
我需要对模型或后处理步骤进行任何具体调整吗？
我想在向模型提供 MRI 输入时预测生存时间，我必须为此设计一个 Web 应用程序，用户在其中提供 MRI 以获得总体生存时间。
这里是数据转换成数组的地方
def getListAgeDays(id_list): # 仅创建年龄：类别数据

    x_val = [] # 初始化一个空列表来存储特征数据
    y_val = [] # 初始化一个空列表来存储类别标签
    对于 id_list 中的 i：
        if (i not in age_dict): # 检查 &#39;i&#39; 是否存在于 &#39;age_dict&#39; 字典中
            继续
        mask = getMaskSizesForVolume(nib.load(TRAIN_DATASET_PATH + f&#39;\\BraTS20_Training_{i[-3:]}/BraTS20_Training_{i[-3:]}_seg.nii&#39;).get_fdata())
        # 加载分割掩码并提取其大小信息
        Brain_vol = getBrainSizeForVolume(nib.load(TRAIN_DATASET_PATH + f&#39;\\BraTS20_Training_{i[-3:]}/BraTS20_Training_{i[-3:]}_t1.nii&#39;).get_fdata())
        # 加载大脑体积图像并提取其大小信息
        mask[1] = mask[1]/brain_vol # 标准化 mask 的大小
        掩码[2] = 掩码[2]/brain_vol
        掩码[3] = 掩码[3]/brain_vol
        合并 = [age_dict[i]、掩码[1]、掩码[2]、掩码[3]]
        # 通过将“age_dict[i]”与掩码大小值相结合来创建特征向量
        radiomics_values = df_radiomics.loc[df_radiomics[&#39;目标&#39;] == str(i)]
        # 查询 DataFrame &#39;df_radiomics&#39; 中与 &#39;i&#39; 相关的放射组学值
        如果 radiomics_values.empty：
            continue # 如果没有放射组学值则跳过本次迭代
        merged.extend(radiomics_values.values.tolist()[0][:-1])
        # 将放射组学值添加到“合并”特征向量（不包括最后一个值）
        x_val.append(merged) # 将特征向量附加到 &#39;x_val&#39;
        如果（days_dict[i] &lt; 250）：
            y_val.append([1, 0, 0]) # 根据 &#39;days_dict&#39; 条件附加类别标签
        elif (days_dict[i] &gt;= 250 且 days_dict[i] &lt; 450):
            y_val.append([0, 1, 0])
        别的：
            y_val.append([0, 0, 1])
    return np.array(x_val), np.array(y_val) # 以 NumPy 数组形式返回特征数据和类别标签

X_all, y_all = getListAgeDays(brats_ids) # 使用 &#39;train_and_test_ids&#39; 调用该函数
print(f&#39;X_test: {X_all.shape}&#39;) # 打印特征数据的形状

这是进入模型的 X_test：
数组([[0.424, 0.385, 0.725, 0.262, 0.304, 0.352, 0.555, 0.368, 0.276,
        0.531、0.054、0.286、0.337、0.447、0.464、0.334、0.235、0.607、
        0.789, 0.569, 0.849],
       [0.691, 0.066, 0.026, 0.165, 0.019, 0.063, 0.209, 0.81 , 0. ,
        0.419、0.、1.、0.383、0.335、0.36、0.392、0.335、0.429、
        0.381、0.255、0.257]……

将模型保存到Joblib中
joblib.dump(model, &#39;model_joblib&#39;)
mj = joblib.load(&#39;model_joblib&#39;)
这是预测
mj.predict(X_test) 输出为： array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])]]></description>
      <guid>https://stackoverflow.com/questions/77725853/predicted-results-from-brain-tumor-survival-model-are-binary-how-to-interpret</guid>
      <pubDate>Thu, 28 Dec 2023 08:51:33 GMT</pubDate>
    </item>
    <item>
      <title>Llama 2 上的 PEFT QLoRA 培训</title>
      <link>https://stackoverflow.com/questions/77725437/peft-qlora-training-on-llama-2</link>
      <description><![CDATA[这是一个更具概念性的问题。我正在尝试在 Llama 2 上执行 PEFT QLoRA，特别是在 imdb 电影评论数据集上。我仅使用 650 个样本进行训练，使用 650 个样本进行测试。我使用了“meta-llama/Llama-2-7b-chat-hf”模型作为我的基本 llama 2 模型。使用 SFTTrainer 训练后，我将模型保存到目录中。如果我没有记错的话，只有适配器权重会保存到目录中，而不是整个模型权重。完成此操作后，我知道这些适配器权重可以与原始模型权重一起加载。
模型 = PeftModel.from_pretrained(
    模型，
    “./my_dir”，
）

完成此操作后，我们应该将这些适配器权重合并到原始模型
merged_model = model.merge_and_unload()

但是，当我使用此 merged_model 进行推理时，我注意到性能非常差，因为仅对 PEFT 加载的模型进行推理，即来自
模型 = PeftModel.from_pretrained(
    模型，
    “./my_dir”，
）

是理想的。这种行为是预期的吗？我正在这样进行推理
tokenizer = AutoTokenizer.from_pretrained(“meta-llama/Llama-2-7b-chat-hf”)
管道=变压器.管道(
    “文本生成”，
    型号=型号，
    分词器=分词器，
    torch_dtype=torch.float16,
    device_map=“自动”，
）

序列=管道（
    迅速的，
    do_sample=真，
    顶部_k=10,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
    最大长度=500，
）
对于序列中的 seq：
    print(f&quot;结果：{seq[&#39;生成的文本&#39;]}&quot;)

还有什么我可以做得更好的吗？]]></description>
      <guid>https://stackoverflow.com/questions/77725437/peft-qlora-training-on-llama-2</guid>
      <pubDate>Thu, 28 Dec 2023 07:01:41 GMT</pubDate>
    </item>
    <item>
      <title>在训练神经网络模型时，如何在 matlab 中编写 Garson 算法来查找参数的相对重要性？</title>
      <link>https://stackoverflow.com/questions/77725247/how-do-you-code-garsons-algorithm-in-matlab-to-find-the-relative-importance-of</link>
      <description><![CDATA[我正在进行一项预测分析研究，并遇到了加森算法，但我在为其编写公式时遇到了麻烦。这是我的代码：
&lt;前&gt;&lt;代码&gt;
%%% 数据输入
输入=数据(:, 1:4)&#39;;
目标=数据(:, 5)&#39;;

%%% 创建前馈神经网络
净 = 前馈网络([10, 15, 20]);

%%%% 设置每个隐藏层的神经元数量
net.layers{1}.size = 10;
net.layers{2}.size = 15;
net.layers{3}.size = 20;

%%%% 更改激活函数（例如，将输出层的“tansig”更改为“purelin”）
net.layers{1}.transferFcn = &#39;tansig&#39;; % 第一个隐藏层的激活函数
net.layers{2}.transferFcn = &#39;tansig&#39;; % 第二隐藏层的激活函数
net.layers{3}.transferFcn = &#39;tansig&#39;; % 第三隐藏层的激活函数
net.layers{4}.transferFcn = &#39;purelin&#39;; % 输出层的激活函数

%%%% 划分数据进行训练、验证和测试
net.divideParam.trainRatio = 0.7;
net.divideParam.valRatio = 0.15;
net.divideParam.testRatio = 0.15;

%%%% 训练神经网络
[net, tr] = train(net, 输入, 目标);

%%%%计算Garson的重要性
重要性= garsonsAlgorithm(net);

%%%% 显示特征重要性
disp(&#39;特征重要性（Garson 算法）:&#39;);
对于 i = 1：长度（重要性）
    disp([&#39;x 的重要性&#39; num2str(i) &#39;: &#39; num2str(importance(i))]);
结尾

&lt;前&gt;&lt;代码&gt;
这是我写的garson算法函数：

函数重要性 = garsonsAlgorithm(net)
    %%% 从神经网络中提取连接权重
    权重 = cell2mat(net.IW);
    
    % 检查权重是否存在偏差
    如果 isfield(net, &#39;b&#39;)
        bias_weights = cell2mat(net.b);
        权重 = [权重;偏差权重]；
    结尾
    
    %%%计算权重的绝对值
    绝对权重=abs(权重);
    
    %%%计算每个输入特征的重要性
    重要性 = sum(absolute_weights, 1);
    
    %%% 标准化重要性值
    重要性=重要性/总和（重要性）；
结尾





我想知道这是否正确，因为我是编程新手。另外，当改变加森算法中的输入数量时，输出会出现任何变化（相对重要性）吗？
我附上了Garson算法的公式供参考：
Garson 算法公式]]></description>
      <guid>https://stackoverflow.com/questions/77725247/how-do-you-code-garsons-algorithm-in-matlab-to-find-the-relative-importance-of</guid>
      <pubDate>Thu, 28 Dec 2023 06:04:03 GMT</pubDate>
    </item>
    <item>
      <title>将道馆环境与 Pokemon Essentials 游戏连接起来</title>
      <link>https://stackoverflow.com/questions/77725007/connecting-gymnasium-environment-with-pokemon-essentials-game</link>
      <description><![CDATA[我正在研究一个基于 RPG Maker XP 和 RGSS 制作的 Pokemon Essentials 游戏的强化学习模型，我想做的第一步是为gymnasium 创建一个与游戏交互的环境。然而，由于游戏是用 RGSS 编码的，我很难弄清楚如何使环境与游戏连接起来。有什么办法可以做到这一点吗？
我的第一个解决方案是尝试将 RPG 游戏制作成类似终端的格式，其中仅打印战斗统计数据，并且模型将根据这些统计数据进行工作，但是我也不知道如何做到这一点.]]></description>
      <guid>https://stackoverflow.com/questions/77725007/connecting-gymnasium-environment-with-pokemon-essentials-game</guid>
      <pubDate>Thu, 28 Dec 2023 04:23:49 GMT</pubDate>
    </item>
    <item>
      <title>在制作 yolov5 对象检测 iOS 应用程序时遇到问题</title>
      <link>https://stackoverflow.com/questions/77718415/having-trouble-making-a-yolov5-object-detection-ios-app</link>
      <description><![CDATA[我正在关注这个教程，但我的 Mac 硅 M2 芯片遇到一些问题（不确定这是否是问题），我已经克隆了 GitHub 存储库并手动安装了依赖项。但每次我在终端中执行下一步时：
python export-nms.py --include coreml --weights yolov5n.pt

我得到同样的错误：
&lt;块引用&gt;
CoreML：导出失败：无法仅从模型规范对象加载 mlProgram 类型的 MLModel。它还需要权重文件的路径。请同时使用“weights_dir”参数提供该信息。

我尝试将我的 Python 版本更改为教程使用的版本，但这不起作用，我也尝试过
python export-nms.py --weights /Users/oscarcanning-thompson/Documents/app/yolov5/yolov5n.pt --include coreml

ChatGPT 给了我（最后的手段），但这也不起作用
也许我把权重文件位置放错了。我不知道这是什么。]]></description>
      <guid>https://stackoverflow.com/questions/77718415/having-trouble-making-a-yolov5-object-detection-ios-app</guid>
      <pubDate>Tue, 26 Dec 2023 17:29:52 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的Python REST API aiohttp 加载时间错误[关闭]</title>
      <link>https://stackoverflow.com/questions/77714772/python-rest-api-for-machine-learning-aiohttp-bad-load-times</link>
      <description><![CDATA[我在Python中使用aiohttp。我有一个机器学习项目，我想通过restapi 提供该项目。我对这些函数进行了计时，它们执行起来并不需要很长时间。他们不会等待结果，而是检查进度并开始任务。问题是等待时间相当长。我试图找到问题所在，它不是函数本身，而是 aiohttp 来运行函数或发送结果。函数本身不是问题。（等待时间10s，函数执行2e-05）。我只是创建一个包含该项目的类。有人对如何确保快速响应时间有建议吗？有没有办法为 API 预先分配资源或在单独的线程中生成机器学习项目。]]></description>
      <guid>https://stackoverflow.com/questions/77714772/python-rest-api-for-machine-learning-aiohttp-bad-load-times</guid>
      <pubDate>Mon, 25 Dec 2023 19:30:24 GMT</pubDate>
    </item>
    <item>
      <title>我遇到错误“不可散列类型：'numpy.ndarray'”</title>
      <link>https://stackoverflow.com/questions/70868316/i-am-facing-an-error-unhashable-type-numpy-ndarray</link>
      <description><![CDATA[这是我的代码
我尝试了很多方法，但都行不通
将 tkinter 导入为 tk
从 tkinter 导入文件对话框
从 tkinter 导入 *
从 PIL 导入 ImageTk，图像

导入numpy
#加载训练好的模型对符号进行分类
从 keras.models 导入 load_model
模型 = load_model(&#39;my_model.h5&#39;)

#dictionary 标记所有交通标志类别。
classes = { 1:&#39;限速（20公里/小时）&#39;,
            2:&#39;限速（30公里/小时）&#39;,
            3:&#39;限速（50公里/小时）&#39;,
            4:&#39;限速（60公里/小时）&#39;,
            5:&#39;限速（70公里/小时）&#39;,
            6:&#39;限速（80公里/小时）&#39;,
            7:&#39;限速结束（80公里/小时）&#39;,
            8:&#39;限速（100公里/小时）&#39;,
            9:&#39;限速（120公里/小时）&#39;,
            10:&#39;禁止通过&#39;,
            11:&#39;禁止超过3.5吨的车辆通过&#39;,
            12:&#39;十字路口的通行权&#39;,
            13:&#39;优先道路&#39;,
            14：&#39;产量&#39;，
            15：&#39;停止&#39;，
            16：“没有车辆”，
            17：&#39;Veh&gt;禁止3.5吨&#39;,
            18:&#39;禁止进入&#39;,
            19：“一般警告”，
            20:&#39;危险曲线左转&#39;,
            21:&#39;右危险曲线&#39;,
            22:&#39;双曲线&#39;,
            23：“崎岖不平的道路”，
            24：“路滑”，
            25:&#39;道路右侧变窄&#39;,
            26：“道路施工”，
            27：&#39;交通信号&#39;，
            28：“行人”，
            29：“儿童过马路”，
            30:&#39;自行车过路&#39;,
            31：“小心冰/雪”，
            32：“野生动物穿越”，
            33:&#39;结束速度+通过限制&#39;,
            34：“向前右转”，
            35：“前方左转”，
            36：&#39;仅向前&#39;，
            37：“直走或右转”，
            38：&#39;直走或左转&#39;,
            39：“靠右行驶”，
            40：“靠左行驶”，
            41：“强制迂回”，
            42：“禁止通过的结束”，
            43：&#39;结束禁止超车&gt; 3.5吨&#39;}

#初始化图形用户界面
顶部=tk.Tk()
顶部.几何(&#39;800x600&#39;)
top.title(&#39;交通标志分类&#39;)
顶部.configure(背景=&#39;#CDCDCD&#39;)

标签=标签(顶部,背景=&#39;#CDCCDD&#39;,字体=(&#39;arial&#39;,15,&#39;bold&#39;))
标志图像 = 标签（顶部）

def 分类（文件路径）：
    全局标签打包
    图像 = Image.open(文件路径)
    图像 = image.resize((30,30))
    图像 = numpy.expand_dims(图像, 轴=0)
    图像 = numpy.array(图像)
    Predict_x=model.predict(图像)
    pred=numpy.argmax(predict_x,axis=1)
    符号=类[pred+1]
    打印（签名）
    label.configure(foreground=&#39;#011638&#39;, text=sign)

def show_classify_button(文件路径):
    分类_b =按钮（顶部，文本=“分类图像”，命令= lambda：分类（文件路径），padx = 10，pady = 5）
    classify_b.configure(背景=&#39;#364156&#39;,前景=&#39;白色&#39;,字体=(&#39;arial&#39;,10,&#39;bold&#39;))
    分类b.place(relx=0.79,rely=0.46)

def upload_image():
    尝试：
        file_path=filedialog.askopenfilename()
        上传=Image.open(文件路径)
        上传的缩略图(((top.winfo_width()/2.25),(top.winfo_height()/2.25)))
        im=ImageTk.PhotoImage(已上传)

        sign_image.configure(图像=im)
        标志图像.image=im
        标签.configure(text=&#39;&#39;)
        显示分类按钮（文件路径）
    除了：
        经过

upload=Button(top,text=“上传图片”,command=upload_image,padx=10,pady=5)
upload.configure(background=&#39;#364156&#39;, foreground=&#39;white&#39;,font=(&#39;arial&#39;,10,&#39;bold&#39;))

upload.pack(side=BOTTOM,pady=50)
sign_image.pack(side=BOTTOM,expand=True)
label.pack(side=BOTTOM,expand=True)
header = Label(top, text=“了解你的交通标志”,pady=20, font=(&#39;arial&#39;,20,&#39;bold&#39;))
header.configure(背景=&#39;#CDCDCD&#39;,前景=&#39;#364156&#39;)
标题.pack()
顶部.mainloop()

我遇到的错误：
Tkinter 回调中出现异常
回溯（最近一次调用最后一次）：
  文件“C:\Program Files\Python310\lib\tkinter\__init__.py”，第 1921 行，在 __call__ 中
    返回 self.func(*args)
  文件“C:\Users\GOWTHAM\AppData\Local\Temp\ipykernel_10936\430013951.py”，第 78 行，位于 &lt;lambda&gt; 中。
    分类_b =按钮（顶部，文本=“分类图像”，命令= lambda：分类（文件路径），padx = 10，pady = 5）
  文件“C:\Users\GOWTHAM\AppData\Local\Temp\ipykernel_10936\430013951.py”，第 73 行，分类
    符号=类[pred+1]


类型错误：不可散列的类型：&#39;numpy.ndarray&#39;

任何人都可以帮我解决这个问题吗？提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/70868316/i-am-facing-an-error-unhashable-type-numpy-ndarray</guid>
      <pubDate>Wed, 26 Jan 2022 18:12:47 GMT</pubDate>
    </item>
    </channel>
</rss>