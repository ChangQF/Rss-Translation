<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 06 Oct 2024 01:21:21 GMT</lastBuildDate>
    <item>
      <title>分类神经网络不收敛</title>
      <link>https://stackoverflow.com/questions/79058176/classification-neural-network-not-converging</link>
      <description><![CDATA[我为 MNIST 构建了一个简单的分类网络，但当我训练它时，验证准确率保持不变 ~ 10%。我尝试了不同的优化器（SGD、Adam、Nadam）&amp;不同的学习率（0.1、1e-3、1e-4、1e-5），但验证准确率在每个时期都保持不变~10%。
这是我的代码：
import tensorflow as tf
from tensorflow import keras

(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()
X_train, X_val = X_train[5000:]/255.0, X_train[:5000]/255.0
y_train, y_val = y_train[5000:]/255.0, y_train[:5000]/255.0

class_NN = keras.models.Sequential([
keras.layers.Input(shape = [28, 28]),
keras.layers.Flatten(),
keras.layers.Dense(300,activation = &quot;relu&quot;),
keras.layers.Dense(100,activation = &quot;relu&quot;),
keras.layers.Dense(10,activation = &quot;softmax&quot;)
])

class_NN.compile(loss = &quot;sparse_categorical_crossentropy&quot;,
optimizer = keras.optimizers.SGD(learning_rate = 1e-3), 
metrics = [&quot;accuracy&quot;])
class_NN.fit(X_train, y_train, epochs = 15,
validation_data = (X_val, y_val))

在写这个问题的时候，我之前从代码中删除了 /255.0训练。现在，训练期间验证准确率会上升。我能够达到约 96% 的验证准确率。为什么当我删除 /255.0 时，训练期间验证准确率会上升？
X_train, X_val = X_train[5000:], X_train[:5000]
y_train, y_val = y_train[5000:], y_train[:5000]
]]></description>
      <guid>https://stackoverflow.com/questions/79058176/classification-neural-network-not-converging</guid>
      <pubDate>Sun, 06 Oct 2024 00:55:12 GMT</pubDate>
    </item>
    <item>
      <title>如何创建用于算法交易的人工智能机器人？[关闭]</title>
      <link>https://stackoverflow.com/questions/79058024/how-to-create-an-ai-bot-for-algorithmic-trading</link>
      <description><![CDATA[我和其他开发人员有一个项目（更像是一种爱好），我们想创建一个基于人工智能的机器人来预测场外市场（二元期权）的下一个一分钟蜡烛图。我们还没有开始做任何事情，这就是为什么我们要向社区寻求有关解决这个问题的最佳方法的建议。
在开始之前，我们还有一些疑问，例如：
该机器人是基于人工智能的，但什么是最合适的方法？例如，我们应该使用神经网络吗？如果是，哪种类型？（LSTM 等）。我们应该考虑 SVM 吗？我也看过应用模式识别技术的文档。哪种技术最适合这种类型的问题？
由于我们使用的是一分钟蜡烛图，我们知道训练将非常耗时，并且需要大量的计算能力。我们可以在哪里训练模型？ （我考虑的是 AWS 之类的云服务或类似的东西）。
我们不是在寻找一个具体的答案，而是要了解哪些条件和解决方案最适合以最佳方式实现这一目标。
如果需要有关该问题的更多背景信息，我将检查并编辑该帖子。]]></description>
      <guid>https://stackoverflow.com/questions/79058024/how-to-create-an-ai-bot-for-algorithmic-trading</guid>
      <pubDate>Sat, 05 Oct 2024 22:13:56 GMT</pubDate>
    </item>
    <item>
      <title>在二元分类数据上拟合神经网络模型的问题</title>
      <link>https://stackoverflow.com/questions/79057502/problem-with-fitting-a-neural-network-model-on-binary-classification-data</link>
      <description><![CDATA[我有一个包含 280 个样本的数据集，其中有 20 个特征和 0.1 个结果。我缩放了它们。
此外，还有三个神经网络模型来训练它们的数据。
但是在循环模型时，我收到了拟合错误。
如何解决？
import numpy as np
import math

import tensorflow as tf

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler,PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import密集

model1 = Sequential([
密集(单位=25, 激活=&#39;relu&#39;),
密集(单位=15, 激活=&#39;relu&#39;),
密集(单位=1, 激活=&#39;线性&#39;)
])
model2 = Sequential([
密集(单位=20, 激活=&#39;relu&#39;),
密集(单位=12, 激活=&#39;relu&#39;),
密集(单位=12, 激活=&#39;relu&#39;),
密集(单位=20, 激活=&#39;relu&#39;),
密集(单位=1, 激活=&#39;线性&#39;)
])
model3 = Sequential([
密集(单位=32, 激活=&#39;relu&#39;),
密集(单位=16, 激活=&#39;relu&#39;),
密集(单位=8, 激活=&#39;relu&#39;),
密集(单位=4, 激活=&#39;relu&#39;),
Dense(units=12,activation=&#39;relu&#39;),
Dense(units=1,activation=&#39;linear&#39;)
])

nn_train_error = []
nn_cv_error = []

models_bc = [model1, model2, model3]
for model in models_bc:

# 设置损失和优化器
model.compile(
loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),
optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
)

print(f&quot;Training {model.name}...&quot;)
# 训练模型
model.fit(x_bc_train_scaled, y_bc_train, epochs=100, verbose=0)
print(&quot;Done!\n&quot;)

# 设置阈值用于分类
threshold = 0.5

# 记录训练集错误分类示例的比例
yhat = model.predict(x_bc_train_scaled)
yhat = tf.math.sigmoid(yhat)
yhat = np.where(yhat &gt;= Threshold, 1, 0)# np 中的 where：条件函数
train_error = np.mean(yhat != y_bc_train)# np 中的 mean：显示错误分类的百分比

nn_train_error.append(train_error)

# 记录交叉验证集错误分类示例的比例
yhat = model.predict(x_bc_cv_scaled)
yhat = tf.math.sigmoid(yhat)
yhat = np.where(yhat &gt;= Threshold, 1, 0)
cv_error = np.mean(yhat != y_bc_cv)

nn_cv_error.append(cv_error)

print(nn_train_error)
print(nn_cv_error)

输出：
 ValueError Traceback（最近一次调用
最后）单元格 In\[109\]，第 15 行 13 print(f&quot;Training
{model.name}...&quot;) 14 # 训练模型 ---\&gt; 15
model.fit(x_bc_train_scaled, y_bc_train, epochs=100, verbose=0) 
16 print(&quot;Done!\\n&quot;)

Sequential.call() 接收的参数：
• input=tf.Tensor(shape=(None, 20), dtype=float32)
• training=True 
• mask=None
]]></description>
      <guid>https://stackoverflow.com/questions/79057502/problem-with-fitting-a-neural-network-model-on-binary-classification-data</guid>
      <pubDate>Sat, 05 Oct 2024 16:52:02 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：无法将 NumPy 数组转换为 Tensor（不支持的对象类型 csr_matrix）</title>
      <link>https://stackoverflow.com/questions/79057484/valueerror-failed-to-convert-a-numpy-array-to-a-tensor-unsupported-object-type</link>
      <description><![CDATA[我尝试运行：
import numpy as np
import pandas as pd
import tensorflow as tf
import numpy as np

从 tensorflow.keras 导入 Sequential
从 tensorflow.keras.layers 导入 Dense、Embedding、GlobalAveragePooling1D
从 tensorflow.keras.layers 导入 TextVectorization
从 sklearn.model_selection 导入 train_test_split
从 tensorflow 导入 keras

从 nltk.tokenize.treebank 导入 TreebankWordTokenizer、TreebankWordDetokenizer
从 sklearn.feature_extraction.text 导入CountVectorizer

dataf=pd.read_csv(&#39;D:/datafile.csv&#39;)
data=pd.read_csv(&quot;D:/dataset1c2f4b7/dataset/train.csv&quot;,encoding=&#39;latin-1&#39;)
l=[]
对于 dataf[&#39;text&#39;] 中的 a:
l.append(a)
m=[]
对于 dataf[&#39;target&#39;] 中的 a:
m.append(a)

X_train, X_test, y_train, y_test = train_test_split(l, m, test_size=0.2, random_state=42)

vectorizer = CountVectorizer()
vectorizer.fit(X_train)
X_train = vectorizer.transform(X_train)
X_test = vectorizer.transform(X_test)
X_train=np.array(X_train)
X_test=np.array(X_test)
y_train=np.array(y_train)
y_test=np.array(y_test)
print(X_train)
model = keras.models.Sequential() 
model.add(keras.layers.Embedding(10000, 128)) 
model.add(keras.layers.SimpleRNN(64, return_sequences=True)) 
model.add(keras.layers.SimpleRNN(64)) 
model.add(keras.layers.Dense(128,activation=&quot;relu&quot;)) 
model.add(keras.layers.Dropout(0.4)) 
model.add(keras.layers.Dense(1,激活=“sigmoid”）） 
model.summary() 

model.compile(“rmsprop”， 
“binary_crossentropy”， 
metrics=[“accuracy”])
model.fit(X_train, y_train,epochs=5,verbose=False,validation_data=(X_test, y_test),batch_size=10)
model.save(&#39;gfgModel.h5&#39;) 
tf.saved_model.save(model, &#39;one_step 05&#39;)

这显示
ValueError：无法将 NumPy 数组转换为 Tensor（不支持的对象类型 csr_matrix）

我正在尝试创建一个文本分类器。
我只是期待要训​​练的模型，因为所有内容都是数组形式。]]></description>
      <guid>https://stackoverflow.com/questions/79057484/valueerror-failed-to-convert-a-numpy-array-to-a-tensor-unsupported-object-type</guid>
      <pubDate>Sat, 05 Oct 2024 16:43:01 GMT</pubDate>
    </item>
    <item>
      <title>如何将有限列表中的元素作为输入传递？</title>
      <link>https://stackoverflow.com/questions/79057233/how-to-pass-an-element-from-a-limited-list-as-input</link>
      <description><![CDATA[我拥有“石头剪刀布”游戏中手臂不同状态的汇编。我的目的是以类似的方式对这些类别进行编程。
[1, 0, 0] - 石头 
[0, 1, 0] - 布 
[0, 0, 1] - 剪刀

有没有方便的自动方法？
我使用了嵌入层，但我不确定它是否合适。]]></description>
      <guid>https://stackoverflow.com/questions/79057233/how-to-pass-an-element-from-a-limited-list-as-input</guid>
      <pubDate>Sat, 05 Oct 2024 14:23:29 GMT</pubDate>
    </item>
    <item>
      <title>如果两个基因组没有匹配的连接，如何获得 NEAT 算法中兼容距离的平均权重差异[关闭]</title>
      <link>https://stackoverflow.com/questions/79055601/how-do-i-get-the-average-weight-difference-for-the-compatibility-distance-in-a-n</link>
      <description><![CDATA[由于计算两个基因组的兼容性距离的公式包括平均权重差异，如果它们没有一个匹配的连接，就会出现问题。通常，你会通过将总权重差异除以共享权重的总量来计算平均权重差异。但由于你不能用 0 除以某个数，所以这是一个问题。
我可以将平均权重差异设置为无穷大或一个非常大的数字吗？或者有更好的解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/79055601/how-do-i-get-the-average-weight-difference-for-the-compatibility-distance-in-a-n</guid>
      <pubDate>Fri, 04 Oct 2024 19:28:30 GMT</pubDate>
    </item>
    <item>
      <title>我的梯度下降实现有什么问题（带铰链损失的 SVM 分类器）</title>
      <link>https://stackoverflow.com/questions/79055573/what-is-wrong-with-my-gradient-descent-implementation-svm-classifier-with-hinge</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79055573/what-is-wrong-with-my-gradient-descent-implementation-svm-classifier-with-hinge</guid>
      <pubDate>Fri, 04 Oct 2024 19:19:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Google Cloud Services 设计实时产品建议管道？[关闭]</title>
      <link>https://stackoverflow.com/questions/79055177/how-to-design-a-real-time-product-suggesting-pipeline-using-google-cloud-service</link>
      <description><![CDATA[我正在考虑一个用例，我需要使用谷歌云功能进行设计。
案例是：
假设用户正在点击一个产品。
该产品 ID 将被发送到实时流式数据流管道，
它将选择与该产品相关的更多项目并
将该产品 ID 发送回该特定用户。
然后该 ID 将用于获取产品信息，并将在页面上的某个位置呈现，例如 -&gt; 您可能喜欢的部分。
信息将存储在 Bigtable 中，这样我们就可以非常快速地获取我们的产品 ID，因为 Bigtable 具有非常高的吞吐量。
现在的问题是，如何将 ID 发送回同一个用户，以便该产品在该特定用户窗口中呈现，而不是其他用户？
如果有人有更好的方法，他们也可以提到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/79055177/how-to-design-a-real-time-product-suggesting-pipeline-using-google-cloud-service</guid>
      <pubDate>Fri, 04 Oct 2024 16:39:19 GMT</pubDate>
    </item>
    <item>
      <title>分类器的数据集极度不平衡[关闭]</title>
      <link>https://stackoverflow.com/questions/79055091/extremely-imbalanced-dataset-for-a-classifier</link>
      <description><![CDATA[我正在研究一种二分类器。我面临的挑战是我的数据集是多么的不平衡。只有 2% 的行属于 A 类（正）。剩下的 98% 属于 B 类（负）。
在这种情况下，获得很高的准确率并不意味着什么。你可以想象我追求的是真正的阳性。
我曾尝试在 Azure 机器学习设计器上使用 SMOTE，但得到的结果很差。为了防止发生任何数据泄露，我在拆分数据后应用了 SMOTE。
我曾尝试过自动化机器学习，希望它能以某种方式处理不平衡的数据集，但事实并非如此。它只是向我发送了一条关于 Imalabace 类的警告消息。结果也很糟糕。
我想知道我是否也可以应用 SMOTE 和可能的 Tomek Links，但仅限于 Auto ML 的训练数据集。
我想我需要去笔记本，复制排名最高的自动化模型的代码，并对其进行调整，以便我可以将这些转换仅应用于训练部分（如果可能的话）。此外，通过这样做，我不会使用自动化 ML 的功能，但我只使用自动化 ml 生成的模型之一。
有什么想法和指导吗？
在 Azure ML Designer 上应用了 SMOTE，希望更平衡的训练数据集能够帮助模型学习。但是我得到的结果并不好。
我尝试使用 AutomatedML，因为我读到它有一些内置功能可以帮助解决不平衡的数据集。但是，我没有看到任何进展。
在这两种情况下，我选择的指标都是精度。我也尝试了 Designer AUC 加权，但没有任何改善。]]></description>
      <guid>https://stackoverflow.com/questions/79055091/extremely-imbalanced-dataset-for-a-classifier</guid>
      <pubDate>Fri, 04 Oct 2024 16:10:32 GMT</pubDate>
    </item>
    <item>
      <title>nnUNetv2_plan_and_preprocess：未找到命令</title>
      <link>https://stackoverflow.com/questions/79054923/nnunetv2-plan-and-preprocess-command-not-found</link>
      <description><![CDATA[在程序中，U-Mamba，
当我运行
nnUNetv2_plan_and_preprocess -d 701 --verify_dataset_integrity

它显示
nnUNetv2_plan_and_preprocess：未找到命令

我的运行环境：
Ubuntu 20.04.6 LTS (GNU/Linux 5.15.0-101-generic x86_64)
RTX 2080ti，RTX 3090
这些事情已经完成：

conda activate env-...
torch with cuda
causal-conv1d
mamba-ssm
umamba pip install -e .
nnunetv2 pip install -e .
nnU-Net 数据集格式
导出 nnUNet_raw、nnUNet_preprocessed、nnUNet_results
]]></description>
      <guid>https://stackoverflow.com/questions/79054923/nnunetv2-plan-and-preprocess-command-not-found</guid>
      <pubDate>Fri, 04 Oct 2024 15:22:50 GMT</pubDate>
    </item>
    <item>
      <title>多模态命名实体识别</title>
      <link>https://stackoverflow.com/questions/79054866/multimodal-named-entity-recognition</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79054866/multimodal-named-entity-recognition</guid>
      <pubDate>Fri, 04 Oct 2024 15:08:57 GMT</pubDate>
    </item>
    <item>
      <title>BigQuery Arima Plus 预测高于预期</title>
      <link>https://stackoverflow.com/questions/79032297/bigquery-arima-plus-forecasts-are-higher-than-expected</link>
      <description><![CDATA[我试图以 15 分钟的分辨率预测来自许多不同设备（1000 个，出于性能原因在几百个设备上进行测试）的值。所有设备都记录：名称和值。我尝试过不同的时间范围进行训练，但到目前为止还没有成功。
问题的一些示例：
设备始终记录 40 -&gt; Arima 从第一次预测（30 天训练）开始预测 20-80 的范围
设备记录 60-64 -&gt; Arima 预测 65-120 个峰值，然后在 102 时趋于平稳（1 天训练）。我正在努力理解 Arima plus 如何得出比训练数据集中的所有值都高出数量级的值。
这是 arima plus 模型创建和预测的伪代码：
我使用摘要表作为数据源，数据分辨率为 15 分钟
训练：
CREATE OR REPLACE MODEL predictioning.model
OPTIONS(
MODEL_TYPE=&#39;ARIMA_PLUS&#39;
,TIME_SERIES_TIMESTAMP_COL=&#39;timestamp&#39;
,TIME_SERIES_DATA_COL=&#39;value&#39;
,TIME_SERIES_ID_COL=&#39;id&#39;
-- ,auto_arima = TRUE
,clean_spikes_and_dips = FALSE
,adjust_step_changes = FALSE
-- ,data_frequency = &#39;AUTO_FREQUENCY&#39;
-- ,auto_arima_max_order = 2 -- 默认值为 5
-- ,max_time_series_length = 96 -- 1 d?
) AS
(
SELECT timestamp
,id
,SUM(value) as value

FROM `forecasting.summary`
WHERE CAST(TIMESTAMP_TRUNC(timestamp, DAY) AS DATE) &lt; _CUTOFF_DATE
AND CAST(TIMESTAMP_TRUNC(timestamp, DAY) AS DATE) &gt;= DATE_ADD(CURRENT_DATE(), INTERVAL _PERIOD DAY)
GROUP BY 1,2

);

虽然我确实使用了 SUM(value)，但很确定它只有 1 行的总和。从其他尝试中得出。
SELECT 
id
,forecast_timestamp as timestamp
,forecast_value as value
,standard_error 
,confidence_level 
,prediction_interval_lower_bound 
,prediction_interval_upper_bound
FROM 
ML.FORECAST(MODEL `forecasting.forecast`
,STRUCT(672 as horizo​​n -- 192 is 2d; 672 is 7d 
,0.95 as confidence_level
)
)
;

过去对我有用的一种方法是将每 15m 预测为其自己的时间序列。问题是，在这种情况下，它会导致数万或数十万个时间序列。虽然 ArimaPlus 声称能够处理数百万个数据，但如果我进行 30 天训练并且不限制最大 pdq，它的训练性能就已经很慢了。
我在预测表现出每日和每周季节性的数据时也遇到了类似的问题。在当前设备数据的情况下，可能存在与气候和天气条件相关的每日和年度季节性。
我怎样才能让 Arima 发挥作用？如果不行，你会推荐什么方法？]]></description>
      <guid>https://stackoverflow.com/questions/79032297/bigquery-arima-plus-forecasts-are-higher-than-expected</guid>
      <pubDate>Fri, 27 Sep 2024 16:57:25 GMT</pubDate>
    </item>
    <item>
      <title>总参数：0，执行 model.summary() keras</title>
      <link>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</link>
      <description><![CDATA[model = Sequential()
model.add(Embedding(283, 100, input_length=56))
model.add(LSTM(150))
model.add(LSTM(150))
model.add(Dense(283,activation=&#39;softmax&#39;))

model.compile(loss=&#39;categorical_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;])

model.summary()

Tensorflow 版本：2.16.1，
Keras 版本：3.3.3，
设备 - M3 pro macbook
我尝试使用虚拟数据集（有 282 个唯一单词，使用 tokenizer 检查）构建用于文本生成的 LSTM 模型，预期参数为非零，但输出每个层都有 0 个参数。]]></description>
      <guid>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</guid>
      <pubDate>Fri, 10 May 2024 19:49:53 GMT</pubDate>
    </item>
    <item>
      <title>在 FastAPI 中使用机器学习时出现“TypeError：float（）参数必须是字符串或数字，而不是‘PatientAttendance’”[关闭]</title>
      <link>https://stackoverflow.com/questions/71606629/getting-typeerror-float-argument-must-be-a-string-or-a-number-not-patienta</link>
      <description><![CDATA[我目前正在使用 FastAPI 构建 API 来部署我的逻辑回归模型。由于某种原因，我在测试模型时在服务器文档中收到上述错误。
我的代码如下：
app = FastAPI()

class PatientAttendance(BaseModel):
apptslotduration: int
patientage: int
log_distance: float
pct_appts_missed: float
doc_no_show_rate: float
zip_no_show_rate: float
note_no_show_rate: float
type_no_show_rate: float
spec_type_no_show_rate: float
monthly_no_show_rate: float
seasonal_no_show_rate: float
dow_no_show_rate: float
clinic_no_show_rate: float
lead_time_in_days: int
groupedstarttime: int
priminsurance_no_show_rate:浮点数
secondinsurance_no_show_rate：浮点数

@app.post(&#39;/predict/&#39;)
def predict(features：PatientAttendance)：
data = features
prediction = model.predict([[data]])
if prediction[0] == 0:
result = &quot;Patient Show&quot;
else:
result = &quot;No-Show&quot;
probability = model.predict_proba([[data]])

return {
&#39;prediction&#39;: prediction,
&#39;probability&#39;: probability
}

if __name__ == &#39;__main__&#39;:
uvicorn.run(app, host=&quot;127.0.0.1&quot;, port=8000)

错误：
TypeError: float() 参数必须是字符串或数字，而不是 &#39;PatientAttendance&#39;

我正在使用 Pydantic BaseModel，但我不知道为什么会收到此错误。我相信我的应用程序相对于服务器指向了正确的方向。我尝试使用 GET 和 POST。features 是我标准化并转换为字典的数据集中的特征数组。所有功能都已矢量化。每当我在服务器文档中测试 API 时，我似乎总是会遇到某种类型的错误。]]></description>
      <guid>https://stackoverflow.com/questions/71606629/getting-typeerror-float-argument-must-be-a-string-or-a-number-not-patienta</guid>
      <pubDate>Thu, 24 Mar 2022 17:08:12 GMT</pubDate>
    </item>
    <item>
      <title>错误：尝试在自定义 HF 数据集上使用 trainer.train() 时，vars() 参数必须具有 __dict__ 属性？</title>
      <link>https://stackoverflow.com/questions/69539538/error-vars-argument-must-have-dict-attribute-when-trying-to-use-trainer-t</link>
      <description><![CDATA[我有以下正在尝试微调的模型（CLIP_ViT + 分类头）。这是我的模型定义：
class CLIPNN(nn.Module):

def __init__(self, num_labels, pretrained_name=&quot;openai/clip-vit-base-patch32&quot;, dropout=0.1):
super().__init__()
self.num_labels = num_labels
# 加载预训练的转换器 &amp;处理器
self.transformer = CLIPVisionModel.from_pretrained(pretrained_name)
self.processor = CLIPProcessor.from_pretrained(pretrained_name)
# 初始化其他层（transformer 主体之后的头部）
self.classifier = nn.Sequential(
nn.Linear(512, 128, bias=True),
nn.ReLU(inplace=True),
nn.Dropout(p=dropout, inplace=False),
nn.Linear(128, self.num_labels, bias=True))

def forward(self, input, labels=None, **kwargs):
logits = self.classifier(inputs)
loss = None
if labels 不是 None:
loss_fct = nn.CrossEntropyLoss()
loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))

return SequenceClassifierOutput(
loss=loss,
logits=logits,
)

我还对数据集进行了以下定义：
class CLIPDataset(nn.utils.data.Dataset):
def __init__(self, embeddings, labels):
self.embeddings = embeddings
self.labels = labels

def __getitem__(self, idx):
item = {&quot;embeddings&quot;: nn.Tensor(self.embeddings[idx])}
item[&#39;labels&#39;] = nn.LongTensor([self.labels[idx]])
return item

def __len__(self):
return len(self.labels)


注意：这里我假设模型输入的是预先计算的嵌入，而不是计算嵌入，我知道这是如果我想微调 CLIP 基础模型，那么这不是正确的逻辑，我只是​​想让我的代码工作。
类似这样的事情会引发错误：
model = CLIPNN(num_labels=2)
train_data = CLIPDataset(train_data, y_train)
test_data = CLIPDataset(test_data, y_test)

trainer = Trainer(
model=model, args=training_args, train_dataset=train_data, eval_dataset=test_data
)
trainer.train()


TypeError Traceback (most recent call last) in
----&gt; 1 trainer.train()
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py
in train(self, resume_from_checkpoint, trial, ignore_keys_for_eval,
**kwargs) 1256 self.control = self.callback_handler.on_epoch_begin(args, self.state, self.control)
1257 → 1258 for step, input in enumerate(epoch_iterator): 1259 1260 #
如果恢复训练，则跳过任何已经训练过的步骤
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/utils/data/dataloader.py in next(self) 515 if self._sampler_iter为 None: 516 self._reset() →
517 data = self._next_data() 518 self._num_yielded += 1 519 if
self._dataset_kind == _DatasetKind.Iterable and \
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/utils/data/dataloader.py in _next_data(self) 555 def _next_data(self): 556 index =
self._next_index() # 可能引发 StopIteration → 557 data =
self._dataset_fetcher.fetch(index) # 可能引发 StopIteration 558 if
self._pin_memory: 559 data = _utils.pin_memory.pin_memory(数据)
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py​​
在 fetch(self, perhaps_batched_index) 45 else: 46 data =
self.dataset[possibly_batched_index] —&gt; 47 return
self.collat​​e_fn(数据)
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/data/data_collat​​or.py
在 default_data_collat​​or(features, return_tensors) 64 65 if
return_tensors == “pt”: —&gt; 66 返回
torch_default_data_collat​​or(features) 67 elif return_tensors == “tf”:
68 返回 tf_default_data_collat​​or(features)
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/data/data_collat​​or.py
在 torch_default_data_collat​​or(features) 中 80 81 如果不是
isinstance(features[0], (dict, BatchEncoding)): —&gt; 82 features =
[vars(f) for f in features] 83 first = features[0] 84 batch = {
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/data/data_collat​​or.py
in (.0) 80 81 if not isinstance(features[0], (dict, BatchEncoding)):
—&gt; 82 features = [vars(f) for f in features] 83 first = features[0] 84
batch = {
TypeError: vars() 参数必须具有 dict 属性

知道我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/69539538/error-vars-argument-must-have-dict-attribute-when-trying-to-use-trainer-t</guid>
      <pubDate>Tue, 12 Oct 2021 11:12:03 GMT</pubDate>
    </item>
    </channel>
</rss>