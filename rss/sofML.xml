<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 14 Jul 2024 15:22:36 GMT</lastBuildDate>
    <item>
      <title>无法将 (Dimension(None)、Dimension(80)) 的元素转换为张量</title>
      <link>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</link>
      <description><![CDATA[我正在尝试阅读 LibRecommender 中有关模型训练过程的教程：https://librecommender.readthedocs.io/en/latest/tutorial.html
我停在了训练模型阶段，代码如下：
model = WideDeep(
task=&quot;ranking&quot;,
data_info=data_info,
embed_size=16,
n_epochs=2,
loss_type=&quot;cross_entropy&quot;,
lr={&quot;wide&quot;: 0.05, &quot;deep&quot;: 7e-4},
batch_size=2048,
use_bn=True,
hidden_​​units=(128, 64, 32),
)

model.fit(
train_data,
neg_sampling=True, # 对训练和评估数据执行负抽样
verbose=2,
shuffle=True,
eval_data=eval_data,
metrics=[&quot;loss&quot;, &quot;roc_auc&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;ndcg&quot;],
)

我收到错误：
TypeError：调用 Flatten.call() 时遇到异常。

无法将 (Dimension(None)、Dimension(80)) 的元素转换为 Tensor。请考虑将元素转换为受支持的类型。请参阅 https://www.tensorflow.org/api_docs/python/tf/dtypes 了解受支持的 TF 数据类型。

Flatten.call() 接收的参数：
• 输入=tf.Tensor(shape=(?, 5, 16), dtype=float32)

我不知道为什么会收到此错误？我假设本教程中没有错误，我按照所示按 1:1 执行。
我在 PyCharm 环境中工作并使用 Jupyter 笔记本。]]></description>
      <guid>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</guid>
      <pubDate>Sun, 14 Jul 2024 14:37:06 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow 中无需编译新模型即可增加神经网络层的大小</title>
      <link>https://stackoverflow.com/questions/78746621/increasing-the-size-of-a-neural-network-layer-without-compiling-a-new-model-in-t</link>
      <description><![CDATA[我正在训练一个窄 3 层 TensorFlow 神经网络，其层大小为 (input_size, small_number_hidden_​​units, output_size)，并使用学习到的权重作为更宽 3 层网络的初始条件的蓝图，其层大小为 (input_size, large_number_hidden_​​units, output_size)。我的目标是利用窄模型找到的解决方案，降低更宽模型的训练成本。除了隐藏单元的数量外，这两个模型都具有相同的架构。
是否可以通过使用单个模型并在需要时向其隐藏层添加单元来避免创建和编译两个模型的开销？例如，是否可以采用层大小为 (input_size, small_number_hidden_​​units, output_size) 的未经训练的网络，关闭大部分隐藏单元，以便在前向和后向传递过程中忽略它们，在该状态下训练网络以节省计算时间，然后在训练过程中的某个时间点打开所有隐藏单元并完成训练？
我曾考虑使用掩码关闭隐藏单元，如这篇文章中所述，但我不清楚这是否真的会降低计算成本。]]></description>
      <guid>https://stackoverflow.com/questions/78746621/increasing-the-size-of-a-neural-network-layer-without-compiling-a-new-model-in-t</guid>
      <pubDate>Sun, 14 Jul 2024 14:28:44 GMT</pubDate>
    </item>
    <item>
      <title>如何正确识别并在图像中最大的轮廓周围绘制椭圆</title>
      <link>https://stackoverflow.com/questions/78746435/how-to-correctly-identify-and-draw-an-ellipse-around-the-largest-contour-in-an-i</link>
      <description><![CDATA[背景
我有一张椭圆形的图片，我的任务是计算它的面积并精确地画出来。
这是原始图片和目标图片，显示了绘制椭圆形的预期结果。
当前代码
import cv2
import numpy as np
import matplotlib.pyplot as plt

# 将 CLAHE 应用于灰度图像
clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
image_gray = cv2.imread(&quot;../data/results/phantom/capture_1_2024-07-09T15-42-41.png&quot;, cv2.IMREAD_GRAYSCALE)
image_gray = clahe.apply(image_gray)

# 对图像进行阈值处理以创建二值图像
_, binary = cv2.threshold(image_gray, 128, 255, cv2.THRESH_BINARY)

# 在二值图像中查找轮廓
contours, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

# 按面积查找最大轮廓
largest_contour = max(contours, key=cv2.contourArea)

# 拟合如果椭圆有足够多的点，则将其绘制到最大轮廓
如果 len(largest_contour) &gt;= 5:
ellipse = cv2.fitEllipse(largest_contour)
(x, y), (major_axis, minor_axis), angle = ellipse

# 检查椭圆尺寸是否有效
如果 major_axis &gt; 0 且 minor_axis &gt; 0:
# 在图像上绘制椭圆
image_with_ellipse = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)
cv2.ellipse(image_with_ellipse, ellipse, (0, 255, 0), 2)

# 计算椭圆的面积
semi_major_axis = major_axis / 2
semi_minor_axis = minor_axis / 2
ellipse_area = np.pi * semi_major_axis * semi_minor_axis
print(f&quot;Ellipse parameters: Center=({x:.2f}, {y:.2f}), &quot;
f&quot;Major Axis={major_axis:.2f}, Minor Axis={minor_axis:.2f}, Angle={angle:.2f}&quot;)
print(f&quot;计算的椭圆面积：{ellipse_area:.2f} 平方像素&quot;)

# 显示图像
plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.imshow(image_gray, cmap=&#39;gray&#39;)
plt.title(&#39;CLAHE 图像&#39;)
plt.subplot(1, 3, 2)
plt.imshow(binary, cmap=&#39;gray&#39;)
plt.title(&#39;二值图像&#39;)
plt.subplot(1, 3, 3)
plt.imshow(cv2.cvtColor(image_with_ellipse, cv2.COLOR_BGR2RGB))
plt.title(&#39;带有椭圆的结果图像&#39;)
plt.show()
else:
print(&quot;在最大contour&quot;)

结果图
问题
图片中的椭圆没有被正确识别，导致椭圆面积计算错误。
问题：
如何正确识别并绘制图片中的椭圆？]]></description>
      <guid>https://stackoverflow.com/questions/78746435/how-to-correctly-identify-and-draw-an-ellipse-around-the-largest-contour-in-an-i</guid>
      <pubDate>Sun, 14 Jul 2024 12:56:04 GMT</pubDate>
    </item>
    <item>
      <title>多线程 TFRecord 写入在 kaggle 笔记本上突然停止</title>
      <link>https://stackoverflow.com/questions/78746204/multithreading-tfrecord-writing-stops-abruptly-on-kaggle-notebook</link>
      <description><![CDATA[我正在寻求有关在 Kaggle 笔记本中 TFRecord 写入的多线程方面的帮助。我目前正在研究 VGGFace2 数据集，旨在将图像对转换为 TFRecords，用于训练、验证和测试集，但该过程在单线程上运行速度过慢。
TFRecord 文件包含此配对图像的 protobuf 示例，以表示同一个人和不同的人。
挑战和我尝试过的方法：

单线程处理速度慢：即使是处理数据集的有限子集（每个目录 5 个图像对用于训练，每个目录 2 个图像对用于验证/测试），使用单线程也需要大量时间（可能长达 24 小时）。我已尽可能优化代码，因此我开始探索多线程以提高性能。

多线程问题：当我使用 concurrent.futures.ThreadPoolExecutor 实现多线程时，会话突然停止，没有任何错误消息。此外，所有变量都丢失，需要从头开始完全重新启动。有趣的是，使用单个目录时，多线程可以完美运行（因为我实现的多线程是同时处理不同的目录，所以即使使用多线程池执行器对象，处理单个目录也不再是多线程，而是单线程进程），但即使使用两个目录也会导致与上述相同的问题（VGGFace2 大约有 8631 个目录）。


我的问题：

潜在原因：这些多线程问题背后的原因可能是什么？这是 Kaggle 资源的内存限制吗？

替代方法：其他人是否遇到过类似的挑战？在 Kaggle 环境中，是否有其他方法可以加速 TFRecord 写入？


附加说明：

我正在使用 contextlib.ExitStack 库来打开许多写入器并同时写入。

我在 Kaggle 讨论和 Stack Overflow 上广泛搜索解决方案，但没有找到针对这种情况的具体解决方案。


如果您对 Kaggle 笔记本中的多线程有任何见解或经验，我将不胜感激，特别是在处理 VGGFace2 等数据集时。提前感谢您的支持！]]></description>
      <guid>https://stackoverflow.com/questions/78746204/multithreading-tfrecord-writing-stops-abruptly-on-kaggle-notebook</guid>
      <pubDate>Sun, 14 Jul 2024 11:10:50 GMT</pubDate>
    </item>
    <item>
      <title>我的机器学习模型不断出错</title>
      <link>https://stackoverflow.com/questions/78745963/i-keep-getting-errors-with-my-machine-learning-model</link>
      <description><![CDATA[这只是我制作的预测股票的模型的一个版本，当我运行它时，它工作正常，但输出时返回错误，注意缩进很乱，但它是不言自明的
这是代码：
import yfinance as yf
from sklearn.linear_model import LinearRegression

start_date = &quot;2000-01-01&quot;
end_date = None
model = LinearRegression()
tickers = (&quot;AMZN&quot;,&quot;AAPL&quot;,&quot;TSLA&quot;)

对于 stock_symbol in tickers:
stock_data = yf.download(tickers = stock_symbol, start=start_date, end=end_date, interval = &quot;1d&quot;)
model.fit(stock_data[[&#39;Open&#39;, &#39;Low&#39;, &#39;Close&#39;, &#39;Volume&#39;]], stock_data[&#39;High&#39;])

today_data = yf.download(stock_symbol, period=&quot;1d&quot;, interval=&quot;1d&quot;)
today_features = today_data[[&#39;Open&#39;, &#39;Low&#39;, &#39;Close&#39;, &#39;Volume&#39;]]
predicted_high_tomorrow = model.predict(today_features)

如果float(predicted_high_tomorrow) &gt; float(today_data[&quot;High&quot;]):
status = &quot;BUY&quot;
else:
status = &quot;SELL&quot;

today_high = today_data[&quot;High&quot;]
print(f&quot;{stock_symbol} {today_high} {predicted_high_tomorrow} {status}&quot;)

它返回正确的输出，以及一些错误：
DeprecationWarning：将 ndim &gt; 0 的数组转换为标量已弃用
FutureWarning：在单个元素 Series 上调用 float 已弃用，将来会引发 TypeError。
]]></description>
      <guid>https://stackoverflow.com/questions/78745963/i-keep-getting-errors-with-my-machine-learning-model</guid>
      <pubDate>Sun, 14 Jul 2024 09:00:47 GMT</pubDate>
    </item>
    <item>
      <title>教导人工智能展现简单情绪以对抗孤独 [关闭]</title>
      <link>https://stackoverflow.com/questions/78745027/teaching-an-ai-to-show-simple-emotions-to-fight-loneliness</link>
      <description><![CDATA[我计划开发一种尽可能自然的计算机宠物。我认为神经网络可以很好地用于此，因为它们可以不断适应用户，并且不需要任何硬编码规则。
该程序应该记录用户的脸部，也许还会向 KI 传输一些额外的状态详细信息。
我在考虑一种 AI，它在最后选择某个状态，然后将其作为图像显示给用户。我的问题是我不知道从哪里获取
（对于监督学习）我应该从哪里获取训练数据或
（对于强化学习）我应该如何制作评估函数。
也许无监督学习也适用于这种情况。
最后，我想把整个东西喂给一个可爱的机器人，然后它只会让用户感觉到有人在那里感知你，所以除了一个有情绪反应的人工智能之外，我对其他任何东西都不感兴趣。
我在这个领域真的不太了解，所以另一个非常基本的问题：我也听说过一些关于“情绪-BICA”的事情，这可以用吗？或者首先应该如何设计一个神经、情绪网络？
在我的研究过程中，我遇到了莫夫林和其他一些人工宠物。但是，我看不出它们是如何工作的。
最后，我只想再说一遍，我只想学习一种构建对用户做出反应的人工智能的方法，而不是真正的宠物，我只是希望它比简单的算法更好。我还相信，当你让人工智能做它的事情时，它会特别强大，当你给它一些元规则时，它就会发展出复杂的行为。]]></description>
      <guid>https://stackoverflow.com/questions/78745027/teaching-an-ai-to-show-simple-emotions-to-fight-loneliness</guid>
      <pubDate>Sat, 13 Jul 2024 21:32:19 GMT</pubDate>
    </item>
    <item>
      <title>BERT 嵌入余弦相似度看起来非常随机且无用</title>
      <link>https://stackoverflow.com/questions/78744975/bert-embedding-cosine-similarities-look-very-random-and-useless</link>
      <description><![CDATA[我是这个领域的新手，所以也许我误解了一些东西。但是，我认为您可以使用 BERT 嵌入来确定语义相似性。我试图用这个将一些单词分组，但结果很糟糕。
例如，这是一个关于动物和水果的小例子。注意到相似度最高的是猫和香蕉吗？
import torch
from transformers import BertTokenizer, BertModel
from sklearn.metrics.pairwise import cosine_similarity

tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)
model = BertModel.from_pretrained(&#39;bert-base-uncased&#39;, output_hidden_​​states=True).eval()

def gen_embedding(word):
encoding = tokenizer(word, return_tensors=&#39;pt&#39;)
with torch.no_grad():
output = model(**encoding)

token_embeddings = output.last_hidden_​​state.squeeze()
token_embeddings = token_embeddings[1 : -1]
word_embedding = token_embeddings.mean(dim=0)
return word_embedding

words = [
&#39;cat&#39;,
&#39;seagull&#39;,
&#39;mango&#39;,
&#39;banana&#39;
]

embs = [gen_embedding(word) for word in words]

print(cosine_similarity(embs))

# array([[1. , 0.33929926, 0.7086487 , 0.79372996],
# [0.33929926, 1.0000001 , 0.29915804, 0.4000572 ],
# [0.7086487 , 0.29915804, 1. , 0.7659105 ],
# [0.79372996, 0.4000572 , 0.7659105 , 0.99999976]], dtype=float32)

我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78744975/bert-embedding-cosine-similarities-look-very-random-and-useless</guid>
      <pubDate>Sat, 13 Jul 2024 20:58:49 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中对 NN 的输出求导</title>
      <link>https://stackoverflow.com/questions/78744355/taking-derivative-of-output-of-nn-wrt-to-inputs-in-pytorch</link>
      <description><![CDATA[我正在尝试使用 PyTorch 中的 NN 构建 ODE 求解器，模型的一部分涉及对模型输出相对于输入求导。
我研究过求解标量值函数的情况。在这种情况下，我的 NN 有 1 个输入节点和 1 个输出节点。根据一些论文，我使用
dy_dt = torch.autograd.grad(y,t, torch.ones_like(y), create_graph=True)[0]
来获得有效的梯度。因此，当我有一个形状为 [N,1] 的张量的训练集时，我得到的结果导数具有形状 [N,1]，这是有道理的。但是，当我尝试求解平面方程时遇到了问题。现在我的 NN 有 1 个输入节点和 2 个输出节点。当我输入一个形状为 [N,1] 的张量时，我从 NN 中得到了一个形状为 [N,2] 的张量，这是有道理的。然而，得到的 dy_dt 的形状为 [N,1]，而它应该是 [N,2]。我还尝试使用
dy_dt = torch.autograd. functional.jacobian(model, t)
它返回一个形状为 [N,2,N,1] 的张量，我认为可以从中访问正确的导数，尽管它不那么简单。我想知道是否有办法使用 autograd.grad 来获得正确的导数。也许它与 grad_output 参数有关？]]></description>
      <guid>https://stackoverflow.com/questions/78744355/taking-derivative-of-output-of-nn-wrt-to-inputs-in-pytorch</guid>
      <pubDate>Sat, 13 Jul 2024 16:01:15 GMT</pubDate>
    </item>
    <item>
      <title>无法在 databricks 中运行 Pysparkling</title>
      <link>https://stackoverflow.com/questions/78744050/unable-to-run-pysparkling-in-databricks</link>
      <description><![CDATA[!pip install h2o_pysparkling_3.5
from pysparkling import H2OConf,H2OContext
hc = H2OContext.getOrCreate()

我收到以下错误
IllegalArgumentException：不支持的参数：（spark.speculation，true）

我尝试了 spark.conf.set(&quot;spark.speculation&quot;, &quot;false&quot;)，但出现了以下错误
[CANNOT_MODIFY_CONFIG] 无法修改 Spark 配置的值：
&quot;spark.speculation&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/78744050/unable-to-run-pysparkling-in-databricks</guid>
      <pubDate>Sat, 13 Jul 2024 14:02:12 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 指标显示“TypeError：‘property’对象不可迭代”</title>
      <link>https://stackoverflow.com/questions/78741833/tensorflow-metrics-is-showing-typeerror-property-object-is-not-iterable</link>
      <description><![CDATA[我正在建立一个 ANN 模型。当我运行以下代码时，它显示为
TypeError: &#39;property&#39; 对象不可迭代

如何修复此问题？
代码：
model=Sequential()
model.add(Dense(512,activation=tf.nn.relu))
model.add(Dense(256,activation=tf.nn.tanh))
model.add(Dense(128,activation=tf.nn.relu))
model.add(Dense(7))

# # 拟合模型

loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
accuracy=tf.keras.metrics.SparseCategoricalAccuracy
optimizer=tf.keras.optimizers.Adam()

model.compile(loss=loss,优化器=优化器，指标=[准确率])
history=model.fit(xtrain, ytrain, validation_data=(xval, yval), batch_size=64, epochs=100)
]]></description>
      <guid>https://stackoverflow.com/questions/78741833/tensorflow-metrics-is-showing-typeerror-property-object-is-not-iterable</guid>
      <pubDate>Fri, 12 Jul 2024 18:44:28 GMT</pubDate>
    </item>
    <item>
      <title>通过向 CNN 输入添加位置和字符信息来增强文档布局分析</title>
      <link>https://stackoverflow.com/questions/78739816/enhancing-document-layout-analysis-by-adding-positional-and-character-informatio</link>
      <description><![CDATA[我正在研究文档布局分析，并一直在探索 CNN 和基于 Transformer 的网络来完成这项任务。通常，图像作为 3 通道 RGB 输入传递给这些网络。但是，我的数据源是 PDF 格式，我可以直接从中提取准确的位置和字符信息。
我担心将这些 PDF 数据转换为图像进行分析会导致宝贵的位置和字符信息丢失。我的想法是将 CNN 的输入维度从标准的 3 RGB 通道修改为包含这些额外位置和字符信息的更高维度输入。
我了解 CNN 的工作原理，并高度怀疑这种方法可能行不通，但我很感谢社区的任何反馈或建议。有没有人尝试过以这种方式增强输入通道，或者有没有人对将位置和字符数据直接集成到 CNN 中有什么见解？]]></description>
      <guid>https://stackoverflow.com/questions/78739816/enhancing-document-layout-analysis-by-adding-positional-and-character-informatio</guid>
      <pubDate>Fri, 12 Jul 2024 10:17:29 GMT</pubDate>
    </item>
    <item>
      <title>BART 配备所有虚拟功能</title>
      <link>https://stackoverflow.com/questions/78731704/bart-with-all-dummy-features</link>
      <description><![CDATA[我正尝试将 BART 应用于分类问题，其中预测变量是虚拟变量以及 y 变量。我知道这是一种不常见的设置，但不幸的是这就是设置。实际上，0 和 1 值是从 -4 到 4 的分类变量中获得的，将负值设置为 0，将正值添加到 1。我还有数据的分类版本，以防它有用。
现在，我的预测变量包含大量 NA 值（即 70%），由 648x48 的 0-1 虚拟变量矩阵组成。我的 y 变量不包含缺失值，有 648 个值。
我目前正在使用 RStudio 在 R 中工作。然而，当我执行下面的代码时，结果却令人失望：
bart_machine = build_bart_machine(predictors, response_var,use_missing_data = TRUE, use_missing_data_dummies_as_covars = TRUE)
bart_machine$confusion_matrix

也就是说，我获得了一个 NULL 混淆矩阵，并且
bartMachine v1.3.4.1 用于回归

缺失数据功能开启
训练数据大小：n = 638 和 p = 96
在 8 个核心、50 棵树、250 个 burn-in 和 1000 个 post 上构建，耗时 5.8 秒。样本

事先对 y 的 sigsq 估计：0.016

老化后的平均 sigsq 估计：0.00314

样本内统计数据：
L1 = 9.91
L2 = 1.01
rmse = 0.04
Pseudo-Rsq = 0.9547
残差的 shapiro-wilk 正态性检验的 p-val：0

零均值噪声的 p-val：0.99451

现在我的问题是：

您是否认为我有太多 NA 值而无法执行 BART？

您认为我的设置至少应该产生一个混淆矩阵吗？

您认为数据的分类版本在这里可能更有帮助还是上述令人失望的结果是由于更深层次的原因吗？


编辑：我实际上已经进行了预测，但它们相当令人失望：
# 提取特征名称
feature_names &lt;- bart_machine[[&quot;training_data_features_with_missing_features&quot;]]

# 删除&quot;M_&quot;前缀
feature_names &lt;- gsub(&quot;^M_&quot;, &quot;&quot;, feature_names)

# 使用重命名的特征名称更新 bart_machine 对象
bart_machine[[&quot;training_data_features_with_missing_features&quot;]] &lt;- feature_names

# 检查 bart_machine 训练数据中的特征名称
training_data &lt;- bart_machine[[&quot;model_matrix_training_data&quot;]]
training_feature_names &lt;- colnames(training_data)

# 删除 &quot;M_&quot;列名中的前缀
training_feature_names &lt;- gsub(&quot;^M_&quot;, &quot;&quot;, training_feature_names)

# 使用重命名的列更新 bart_machine 对象
colnames(training_data) &lt;- training_feature_names
bart_machine[[&quot;model_matrix_training_data&quot;]] &lt;- training_data

# 使用相同方法在 albany2005_predictors 中插入缺失数据
imputed_data_2005 &lt;- mice(albany2005[, -1], m = 5, method = &#39;pmm&#39;, maxit = 50, seed = 500)
complete_data_2005 &lt;- complete(imputed_data_2005, 1)

# 删除 &quot;M_&quot; albany2005_predictors 中列名的前缀
colnames(complete_data_2005) &lt;- gsub(&quot;^M_&quot;, &quot;&quot;, colnames(complete_data_2005))

# 确保 albany2005_predictors 具有与训练数据相同的列，但不包括“y_remaining”
required_cols &lt;- setdiff(training_feature_names, &quot;y_remaining&quot;)
albany2005_predictors &lt;- complete_data_2005[, required_cols, drop = FALSE]

# 为 albany2005_response 中的非 NA 值创建逻辑向量
non_na_indices &lt;- !is.na(albany2005_response)

# 子集预测值和albany2005_response 使用 non_na_indices
non_na_predicted_values &lt;- predict_values[non_na_indices]
non_na_actual_values &lt;- albany2005_response[non_na_indices]

# 使用 bartMachine 模型对 2005 年数据进行预测
predicted_values &lt;- predict(bart_machine, albany2005_predictors, type = &quot;class&quot;)

# 计算 RMSE
# 将预测值转换为数字
non_na_predicted_values &lt;- as.numeric(as.character(non_na_predicted_values))

# 将实际值转换为数字
non_na_actual_values &lt;- as.numeric(as.character(non_na_actual_values))

rmse &lt;- sqrt(mean((non_na_predicted_values - non_na_actual_values)^2))

# 打印 RMSE
print(paste(&quot;RMSE: &quot;, rmse))。###非常高的 RMSE!!!
]]></description>
      <guid>https://stackoverflow.com/questions/78731704/bart-with-all-dummy-features</guid>
      <pubDate>Wed, 10 Jul 2024 16:18:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我在 TensorFlow 中使用 model.fit() 时会得到 ValueError：无法识别的数据类型：x=[...] (类型 <class 'list'>)？</title>
      <link>https://stackoverflow.com/questions/78271090/why-do-i-get-valueerror-unrecognized-data-type-x-of-type-class-list</link>
      <description><![CDATA[我尝试运行以下代码，该代码取自 CS50 的 AI 课程：
import csv
import tensorflow as tf
from sklearn.model_selection import train_test_split

# 从文件读取数据
with open(&quot;banknotes.csv&quot;) as f:
reader = csv.reader(f)
next(reader)

data = []
for row in reader:
data.append(
{
&quot;evidence&quot;: [float(cell) for cell in row[:4]],
&quot;label&quot;: 1 if row[4] == &quot;0&quot; else 0,
}
)

#将数据分为训练组和测试组
evidence = [row[&quot;evidence&quot;] for row in data]
labels = [row[&quot;label&quot;] for row in data]
X_training, X_testing, y_training, y_testing = train_test_split(
evidence, labels, test_size=0.4
)

# 创建神经网络
model = tf.keras.models.Sequential()

# 添加一个有 8 个单元的隐藏层，使用 ReLU 激活函数
model.add(tf.keras.layers.Dense(8, input_shape=(4,),activation=&quot;relu&quot;))

# 添加一个有 1 个单元的输出层，使用 sigmoid 激活函数
model.add(tf.keras.layers.Dense(1,activation=&quot;sigmoid&quot;))

# 训练神经网络
model.compile(
optimizer=&quot;adam&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;]
)
model.fit(X_training, y_training, epochs=20)

# 评估模型的表现
model.evaluate(X_testing, y_testing, verbose=2)

但是，我收到以下错误：
Traceback（最近一次调用最后一次）：
文件“C:\Users\Eric\Desktop\coding\cs50\ai\lectures\lecture5\banknotes\banknotes.py”，第 41 行，位于&lt;module&gt;
model.fit(X_training, y_training, epochs=20)
文件 &quot;C:\Users\Eric\Desktop\coding\cs50\ai\.venv\Lib\site-packages\keras\src\utils\traceback_utils.py&quot;，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件 &quot;C:\Users\Eric\Desktop\coding\cs50\ai\.venv\Lib\site-packages\keras\src\trainers\data_adapters\__init__.py&quot;，第 113 行，位于 get_data_adapter 中
引发 ValueError(f&quot;无法识别的数据类型：x={x}（类型为 {type(x)}）&quot;)
ValueError：无法识别的数据类型：x=[...]（类型为 &lt;class &#39;list&#39;&gt;)

其中“...”是训练数据。
知道哪里出错了吗？我在 Windows 计算机上使用 Python 版本 3.11.8 和 TensorFlow 版本 2.16.1。
我尝试在 Google Colab 笔记本中运行相同的代码，并且成功了：问题仅发生在我的本地机器上。这是我期望的输出：
Epoch 1/20
26/26 [==============================] - 1s 2ms/step - 损失：1.1008 - 准确度：0.5055
Epoch 2/20
26/26 [===============================] - 0s 2ms/step - 损失：0.8588 - 准确度：0.5334
Epoch 3/20
26/26 [================================] - 0s 2ms/step - 损失：0.6946 - 准确度：0.5917
Epoch 4/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.5970 - 准确度：0.6683
纪元 5/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.5265 - 准确度：0.7120
纪元 6/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.4717 - 准确度：0.7655
纪元 7/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.4258 - 准确度：0.8177
纪元 8/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.3861 - 准确度：0.8433
纪元 9/20
26/26 [================================] - 0s 2ms/步 - 损失：0.3521 - 准确度：0.8615
纪元 10/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.3226 - 准确度：0.8870
纪元 11/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.2960 - 准确度：0.9028
纪元 12/20
26/26 [================================] - 0s 2ms/步 - 损失：0.2722 - 准确度：0.9125
纪元 13/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.2506 - 准确度：0.9283
纪元 14/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.2306 - 准确度：0.9514
纪元 15/20
26/26 [================================] - 0s 3ms/步 - 损失：0.2124 - 准确度：0.9660
纪元 16/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.1961 - 准确度：0.9769
纪元 17/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.1813 - 准确度：0.9781
纪元 18/20
26/26 [================================] - 0s 2ms/步 - 损失：0.1681 - 准确度：0.9793
纪元 19/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.1562 - 准确度：0.9793
Epoch 20/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.1452 - 准确度：0.9830
18/18 - 0s - 损失：0.1407 - 准确度：0.9891 - 187ms/epoch - 10ms/步
[0.14066053926944733, 0.9890710115432739]
]]></description>
      <guid>https://stackoverflow.com/questions/78271090/why-do-i-get-valueerror-unrecognized-data-type-x-of-type-class-list</guid>
      <pubDate>Thu, 04 Apr 2024 00:28:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Textract 中获取 BLOCK 类型 LAYOUT_TITLE、LAYOUT_SECTION_HEADER 和 LAYOUT_xx 的内容</title>
      <link>https://stackoverflow.com/questions/78252584/how-to-get-content-of-block-types-layout-title-layout-section-header-and-layout</link>
      <description><![CDATA[我正在尝试使用 textract 抓取多页 pdf。
需要抓取 pdf 并根据其部分、子部分、表格格式化为 json。
在尝试使用 LAYOUT 和 Table 进行 UI 演示时，它能够准确显示布局标题、布局部分、布局文本、布局页脚、页码
在从 UI 演示下载的 csv 文件中可以观察到相同的信息：layout.csv 文件。
在 json 文件中也是如此：analyzeDocResponse.json 也一样，但它包含所有内容（LINES、WORDS、LAYOUT_TITLE 和所有与布局相关的数据），我认为 textract 按顺序执行所有类型的块类型。
出于调试目的，我使用以下代码打印整个块字典。
以及块类型，后面跟着相应的文本。
如果对 pdf 文件感兴趣：其药物的 SmPC：SmPC 文件
代码 1：以 json 格式打印每个块。

def start_textract_job(bucket, document):
response = textract.start_document_analysis(
DocumentLocation={
&#39;S3Object&#39;: {
&#39;Bucket&#39;: bucket,
&#39;Name&#39;: document
}
},
FeatureTypes=[&quot;LAYOUT&quot;] # 您可以根据需要调整 FeatureTypes
)
return response[&#39;JobId&#39;]

def print_blocks(job_id):
next_token = None
while True:
if next_token:
response = textract.get_document_analysis(JobId=job_id, NextToken=next_token)
else:
response = textract.get_document_analysis(JobId=job_id)

for block in response.get(&#39;Blocks&#39;, []):
print(json.dumps(block, indent=4))

next_token = response.get(&#39;NextToken&#39;, None)
if not next_token:
break

它根据 UI Demo 打印类似信息，块类型 LINES、WORDS、LAYOUT_
但如果我尝试使用以下代码打印每种块类型的文本，它无法打印与 LAYOUT_ 相关的文本，不知道为什么，我是否遗漏了什么？
代码 2：打印块类型，然后打印其内容。

def start_textract_job 与上面的 LAYOUT 相同。

def print_blocks(job_id):
next_token = None
while True:
if next_token:
response = textract.get_document_analysis(JobId=job_id, NextToken=next_token)
else:
response = textract.get_document_analysis(JobId=job_id)

for block in response.get(&#39;Blocks&#39;, []):
print(f&quot;{block[&#39;BlockType&#39;]}: {block.get(&#39;Text&#39;, &#39;&#39;)}&quot;)

next_token = response.get(&#39;NextToken&#39;, None)
if not next_token:
break

我可以看到块类型 LINES、WORDS 的值
但 LAYOUT 为空，如下所示，我认为，它在块类型中识别，但不是其值。
LAYOUT_TITLE:
LAYOUT_FIGURE:
LAYOUT_TEXT:
LAYOUT_SECTION_HEADER:
LAYOUT_TEXT:
LAYOUT_SECTION_HEADER:
LAYOUT_TEXT:
LAYOUT_TEXT:
LAYOUT_TEXT:
LAYOUT_TEXT:
LAYOUT_TEXT:
LAYOUT_PAGE_NUMBER:
LAYOUT_FOOTER:
任何帮助都非常感谢，我查阅了文档和其他一些 StackOverflow 问题，但找不到任何帮助。
Tetract 新手，抱歉，如果是新手，请提问：)]]></description>
      <guid>https://stackoverflow.com/questions/78252584/how-to-get-content-of-block-types-layout-title-layout-section-header-and-layout</guid>
      <pubDate>Sun, 31 Mar 2024 19:28:51 GMT</pubDate>
    </item>
    <item>
      <title>NameError：名称“plot_confusion_matrix”未定义</title>
      <link>https://stackoverflow.com/questions/65651544/nameerror-name-plot-confusion-matrix-is-not-defined</link>
      <description><![CDATA[我正在尝试使用 VGG16 创建一个分类模型，但是在项目结束时，我在获取混淆矩阵时遇到了错误。下面给出了代码，
导入的包和模块是：
import os
import keras
import numpy as np
import tensorflow as tf
from keras.models import Model
import matplotlib.pyplot as plt
from keras.optimizers import Adam
from keras.applications import MobileNet
from sklearn.metrics import chaos_matrix
from keras.layers.core import Dense, Activation
from keras.metrics import categorical_crossentropy
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.mobilenet import preprocess_input
from tensorflow.keras.preprocessing import image_dataset_from_directory

注意：对于简短地讲我只是跳过了链接的数据集
下面定义 VGG16：
vgg16_model = keras.applications.vgg16.VGG16()
vgg16_model.summary()

现在，定义模型：
model = Sequential()
for layer in vgg16_model.layers:
model.add(layer)

for layer in model.layers:
layer.trainable = False

model.add(Dense(2,activation=&#39;softmax&#39;))

编译模型：
model.compile(Adam(lr=.0001),loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

拟合模型：
model.fit_generator(train_batches, steps_per_epoch=4, validation_data=valid_batches, validation_steps=4, epochs=10, verbose=2)

现在是混淆矩阵：
test_imgs, test_labels = next(test_batches)
plots(test_imgs, titles=test_labels)
test_labels = test_labels[:,0] 
predictions = model.predict_generator(test_batches, steps=1, verbose=0)
cm = chaos_matrix(test_labels, np.round(predictions[:,0]))

下面我遇到了一个错误，请关注下面代码，
cm_plot_labels = [&#39;diseaseAffectedEggplant&#39;,&#39;freshEggplant&#39;]
plot_confusion_matrix(cm, cm_plot_labels, title=&quot;Confusion Matrix&quot;) // 这行，我遇到了一个错误

错误如下，
-------------------------------------------------------------------------------
NameError Traceback (most recent call last)
&lt;ipython-input-28-43b96d543746&gt; in &lt;module&gt;()
1 cm_plot_labels = [&#39;diseaseAffectedEggplant&#39;,&#39;freshEggplant&#39;]
----&gt; 2 plot_confusion_matrix(cm, cm_plot_labels, title=&quot;Confusion Matrix&quot;)

NameError: 名称 &#39;plot_confusion_matrix&#39; 未定义
]]></description>
      <guid>https://stackoverflow.com/questions/65651544/nameerror-name-plot-confusion-matrix-is-not-defined</guid>
      <pubDate>Sun, 10 Jan 2021 08:53:18 GMT</pubDate>
    </item>
    </channel>
</rss>