<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 25 Mar 2024 03:16:35 GMT</lastBuildDate>
    <item>
      <title>谁能帮助我评估我的人工智能学校项目的架构？</title>
      <link>https://stackoverflow.com/questions/78216842/can-anyone-help-me-evaluate-this-architecture-for-my-ai-school-project</link>
      <description><![CDATA[我计划为医疗保健行业开发一种人工智能，可以帮助专业人士为患者提供诊断和预后。将有一系列模型将集成到该系统中。在第一部分中，我希望系统能够根据输入（这将是实验室测试结果的图像，和/或手动输入文本数据）来预测患者是否有很高的机会患有糖尿病、肾病和心血管疾病。它将总结和分析数据集，以解决某些疾病的概率。然后，处理和分析这些数据的算法将由外部强化学习模型进行评估，以改进每个模型的学习过程。我希望我的解释是有道理的。
注意：我计划使用多模态模型单独处理图像中的文本，使用 CNN 处理 X 射线、核磁共振等图像，使用 RNN 处理手动文本输入。
期待您的批评，以进一步提高我的知识。谢谢！！
我创建了模型的流程图，它将帮助我可视化实现系统目标所需的过程。]]></description>
      <guid>https://stackoverflow.com/questions/78216842/can-anyone-help-me-evaluate-this-architecture-for-my-ai-school-project</guid>
      <pubDate>Mon, 25 Mar 2024 02:39:55 GMT</pubDate>
    </item>
    <item>
      <title>构建用于机器学习的定制 PC：GPU 选择所需的帮助 [关闭]</title>
      <link>https://stackoverflow.com/questions/78216358/building-a-custom-pc-for-machine-learning-help-needed-with-gpu-selection</link>
      <description><![CDATA[“我正在规划我的定制 PC 构建，专门用于深入研究机器学习、深度学习和法学硕士。以下是我正在考虑的规格：

英特尔酷睿 i7 14700K 处理器
微星Pro Z790-A Max WIFI主板
威刚 XPG Lancer RGB DDR5 32GB (16x2) 5200MHz 白色
技嘉 RTX 4060 Ti Aero OC 8GB 显卡
NZXT Kraken 360mm RGB CPU 液冷散热器（带 LCD 显示屏）（白色）
西部数据 Blue SN580 1TB M.2 NVMe 内置 SSD
Cooler Master MWE 750 V2 80+ 金牌全模块化电源（750W）
联力 O11 Vision (E-ATX) 中塔机柜（白色）
NZXT F120 RGB 核心 120 毫米三重装机柜风扇白色
Nzxt F120 RGB 核心 120mm 机柜风扇 - 白色（单包）
Cooler Master Master Gel Pro（免费）

但是，我在 GPU 的选择上面临着两难的境地。我目前正在考虑 RTX 4060Ti，但我不确定它是否能满足我的需求，或者我是否应该选择更高端的型号，如 4070、4080 甚至 4090。我愿意延长我的时间如有必要，请进行预算，因为我打算仅将这台电脑用于机器学习目的。虽然我知道像 Google Colab 这样的替代品，但我仍然更喜欢构建自己的机器。我将非常感谢有关此事的任何见解或建议。谢谢！”]]></description>
      <guid>https://stackoverflow.com/questions/78216358/building-a-custom-pc-for-machine-learning-help-needed-with-gpu-selection</guid>
      <pubDate>Sun, 24 Mar 2024 22:39:23 GMT</pubDate>
    </item>
    <item>
      <title>python sklearn ValueError：用序列设置数组元素</title>
      <link>https://stackoverflow.com/questions/78216115/python-sklearn-valueerror-setting-an-array-element-with-a-sequence</link>
      <description><![CDATA[训练 sklearn sgd 分类器。根据数组中的姓名和年龄，获得颜色。乙
sgdclassifier 的 .fit() 错误。错误：“使用序列设置数组元素。”意思是？这是否意味着 sklearn 中的 sgd 分类器不能将数组的数组作为输入？
但是，如果名称和年龄不是数组（而只是单个元素），则不会出现错误。
from sklearn.model_selection import train_test_split
将 pandas 导入为 pd
将 numpy 导入为 np`

a=np.array([0, 2, 5, 2])
b=np.array( [0, 5, 0, 2])
c=np.array([2,2,0,0])
d=np.array([5,2,5,0])


age_a=np.array([5, 10, 7, 6])
Age_b=np.array([3, 7, 11,8])
age_c=np.array([15, 10, 17, 2])
Age_d=np.array([2, 8, 12,7])

color_a=np.array([0,2,1,1])
color_b=np.array([1,12,0,1])
color_c=np.array([0,1,1,0])
color_d=np.array([1,0,0,1])

#data2={&#39;姓名&#39;:[a,b,c,d],&#39;年龄&#39;:[年龄_a,年龄_b,年龄_c,年龄_d],&#39;颜色&#39;:[颜色_a,颜色_b,颜色_c,颜色_d]}

data2={&#39;姓名&#39;:[a,b,c,d],&#39;年龄&#39;:[age_a,age_b,age_c,age_d],&#39;颜色&#39;:[0,1,0,1]}
new2 = pd.DataFrame.from_dict(data2)

打印（新2）

x = new2.loc[:, new2.columns != &#39;颜色&#39;]
y = new2.loc[:, &#39;颜色&#39;]

x=np.array(x,dtype=对象)
y=np.array(y)



x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)



从 sklearn.linear_model 导入 SGDClassifier

sgd_clf=SGDClassifier(random_state=42)
sgd_clf.fit(x_train, y_train)
sgd_clf.预测（x_test）`

`
TypeError Traceback（最近一次调用最后一次）
类型错误：float() 参数必须是字符串或实数，而不是“列表”
上述异常是导致以下异常的直接原因：

ValueError Traceback（最近一次调用最后一次）
[117] 中的单元格，第 25 行
     21 打印（y_测试）
     24 clf = SGDClassifier(loss=“hinge”,penalty=“l2”,max_iter=5)
     25 clf.fit(x_train, y_train)
     26 #SGDClassifier(max_iter=100)
     28 clf.predict([[2., 2.]])


ValueError：使用序列设置数组元素。
]]></description>
      <guid>https://stackoverflow.com/questions/78216115/python-sklearn-valueerror-setting-an-array-element-with-a-sequence</guid>
      <pubDate>Sun, 24 Mar 2024 21:08:03 GMT</pubDate>
    </item>
    <item>
      <title>KeyError：“[‘建筑年龄’、‘楼层’、‘楼层数’]不在索引中”</title>
      <link>https://stackoverflow.com/questions/78215783/keyerror-building-age-floor-number-of-floors-not-in-index</link>
      <description><![CDATA[导入 pandas 作为 pd
将 numpy 导入为 np
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.metrics 导入mean_squared_error, r2_score
将类别编码器导入为 ce

# 读取数据
transactions_master_df = pd.read_csv(&#39;my_data.csv&#39;)

# 计算各区平均房价
avg_price_per_district = transactions_master_df.groupby(&#39;地区&#39;)[&#39;价格&#39;].mean().reset_index()
avg_price_per_district.rename(columns={&#39;Price&#39;: &#39;AvgPrice&#39;}, inplace=True)

#打印每个地区的平均价格，旁边是地区列
打印（每个地区的平均价格）

# 将平均价格信息与原始DataFrame合并
transactions_master_df = pd.merge(transactions_master_df, avg_price_per_district, on=&#39;地区&#39;, how=&#39;左&#39;)

# 对“District”特征进行二进制编码
编码器 = ce.BinaryEncoder(cols=[&#39;District&#39;], base=6)
transactions_encoded = 编码器.fit_transform(transactions_master_df)

# 将附加功能连接到编码的 DataFrame
extra_features = [&#39;建筑年龄&#39;,&#39;楼层&#39;,&#39;楼层数&#39;,&#39;电梯&#39;,
                      &#39;浴室数量&#39;, &#39;Otopark&#39;, &#39;陡峭的小巷&#39;,
                      “用料和奢华”、“景观”、
                      “该地区及其周边地区的声望”]

# 检查 transactions_encoded DataFrame 中是否存在其他功能
对于additional_features中的功能：
    如果功能不在 transactions_encoded.columns 中：
        print(f“警告：在 transactions_encoded DataFrame 中找不到 {feature} 列。”)

# 将附加功能连接到编码的 DataFrame
Final_features = pd.concat([transactions_encoded[[&#39;District_0&#39;, &#39;District_1&#39;, &#39;District_2&#39;, &#39;SquareMeter&#39;]],
                            transactions_encoded[additional_features]]，轴=1）

# 确保“final_features”包含训练所需的列
打印（final_features.head（））



你好，
在这段代码中，我正在为我的房价数据集构建一个模型。首先，我对一些非数字特征进行编码，然后当我连接其余特征以接收 Final_features 变量时，出现以下错误：
final_features = pd.concat([transactions_encoded[[&#39;District_0&#39;, &#39;District_1&#39;, &#39;District_2&#39;, &#39;SquareMeter&#39;]],
---&gt; 38 transactions_encoded[additional_features]], axis=1)
KeyError：“[&#39;建筑年龄&#39;，&#39;楼层&#39;，&#39;楼层数&#39;]不在索引中”


奇怪的是，这些功能存在于我的数据集中，但我不知道为什么它会给我这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/78215783/keyerror-building-age-floor-number-of-floors-not-in-index</guid>
      <pubDate>Sun, 24 Mar 2024 19:10:52 GMT</pubDate>
    </item>
    <item>
      <title>如何实现这个 Copula 变分推理算法？</title>
      <link>https://stackoverflow.com/questions/78215616/how-do-i-implement-this-copula-variational-inference-algorithm</link>
      <description><![CDATA[我是机器学习新手，不确定如何实现本文第 5 页中的伪代码：https://proceedings.neurips.cc/paper_files/paper/2015/file/e4dd5528f7596dcdf871aa55cfccc53c-Paper.pdf
我的困惑点如下：我是否需要自己计算梯度并更新参数，或者 loss.backward() 是否足够？
ChatGPT给出的算法如下：
def copula_vi(x, p, q, 阈值=1e-5, max_iter=100, lr=0.01):
    d = x.shape[1] # 数据的维数
    lambda_param = torch.randn(d,requires_grad=True)
    eta_param = torch.ones_like(x,requires_grad=True)

    optimer_lambda = optim.SGD([lambda_param], lr=lr)
    Optimizer_eta = optim.SGD([eta_param], lr=lr)

    prev_elbo = float(&#39;-inf&#39;)

    而真实：
        # 固定 η，最大化 λ
        t = 1
        而真实：
            u = torch.rand_like(x) # 绘制样本 u ~ Unif([0, 1]^d)
            q_sample = q(u, eta_param)
            损失 = -torch.mean(torch.log(p(x, q_sample)) - torch.log(q_sample))
            optimizer_lambda.zero_grad()
            loss.backward()
            优化器_lambda.step()

            if t &gt;= max_iter 或 torch.abs(prev_elbo - loss.item()) &lt;临界点：
                休息
            
            prev_elbo = loss.item()
            t+=1
        
        # 固定 λ，最大化 η
        t = 1
        而真实：
            u = torch.rand_like(x) # 绘制样本 u ~ Unif([0, 1]^d)
            q_sample = q(u, eta_param)
            损失 = -torch.mean(torch.log(p(x, q_sample)) - torch.log(q_sample))
            Optimizer_eta.zero_grad()
            loss.backward()
            优化器_eta.step()

            if t &gt;= max_iter 或 torch.abs(prev_elbo - loss.item()) &lt;临界点：
                休息
            
            prev_elbo = loss.item()
            t+=1
        
        if torch.abs(prev_elbo - loss.item()) &lt;临界点：
            休息
    
    返回 lambda_param, eta_param`
]]></description>
      <guid>https://stackoverflow.com/questions/78215616/how-do-i-implement-this-copula-variational-inference-algorithm</guid>
      <pubDate>Sun, 24 Mar 2024 18:19:55 GMT</pubDate>
    </item>
    <item>
      <title>Nevopy 用于两名或以上玩家的游戏</title>
      <link>https://stackoverflow.com/questions/78215459/nevopy-for-games-with-two-or-more-players</link>
      <description><![CDATA[我尝试过 nevopy 为四子棋制作一个好的 KI。在fitness_fuction中，我想让一个模型与随机选择的人口对手进行比赛，但我无法使用人口变量，尽管它是全局的。当一个模型的适应度依赖于其他模型时，是否有一种方法可以使用总体适应度函数？ nevopy 还应该如何用于多人游戏？
我想使用nevopy，因为它很简单，而且不像neat-python那么难理解。
我预计我可以在适应度函数中使用人口变量，但这不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78215459/nevopy-for-games-with-two-or-more-players</guid>
      <pubDate>Sun, 24 Mar 2024 17:24:29 GMT</pubDate>
    </item>
    <item>
      <title>使用量子电路实现强化学习模型的错误</title>
      <link>https://stackoverflow.com/questions/78215361/error-in-implementing-reinforcement-learning-model-using-quantum-circuit</link>
      <description><![CDATA[我已经完成了大部分部分，请参阅下面的代码
导入tensorflow为tf
从张量流导入keras
从tensorflow.keras导入层
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

类 HadamardLayer(layers.Layer):
  def __init__(self, **kwargs):
    super().__init__(**kwargs)

  def 构建（自身，input_shape）：
    super().build(input_shape)

  def 调用（自身，输入）：
    hadamard_gate = tf.constant([[1/np.sqrt(2), 1/np.sqrt(2)],
                                 [1/np.sqrt(2), -1/np.sqrt(2)]])
    返回 tf.linalg.matmul(hadamard_gate, 输入)

类 QuantumExplorationCircuit(keras.Model):
  def __init__(自身):
    超级().__init__()
    self.qubits = Layers.Input(shape=(1,)) # 假设 1 个量子位用于探索
    self.h = HadamardLayer() # 使用自定义 Hadamard 层

  def 调用（自身，输入）：
    super().call(输入)
    探索_prob = self.h（输入）
    返回探索概率

def run_episode_tensorflow（sess，env，action_prob，探索电路）：
  obs = env.reset()
  完成=假

  状态列表 = []
  动作列表 = []
  r_列表 = []
  虽然没有完成：
    cur_action_prob = sess.run(action_prob, feed_dict={observation_placeholder: obs.reshape(1, 4)})


#error 在这里 TypeError: Can not conversion a NoneType into a Tensor or Operations。
    Exploration_probs = sess.run(exploration_ Circuit, feed_dict={exploration_placeholder: np.zeros((1, 1))})

    组合概率 = (1 - epsilon) * cur_action_prob[0] + epsilon *探索_probs[0]
    动作 = np.random.choice([0, 1], p=combined_prob)

    state_list.append(obs)
    action_list.append(动作)
    obs, r, 完成, info = env.step(action)
    r_list.append(r)
  返回状态列表、动作列表、r_列表

epsilon = tf.constant(0.05, dtype=tf.float32)
Observation_placeholder = tf.compat.v1.placeholder(dtype=tf.float32, shape=(无, 4))
action_placeholder = tf.compat.v1.placeholder(dtype=tf.int32, shape=())
v = tf.compat.v1.placeholder(dtype=tf.float32, shape=())

model_params = tf.Variable(tf.compat.v1.random_uniform(shape=(4, 2), minval=0, maxval=1.0, dtype=tf.float32))
preds = tf.matmul(observation_placeholder, model_params)
action_prob = tf.nn.softmax(preds)

explore_placeholder = tf.compat.v1.placeholder(dtype=tf.float32, shape=(无, 1))
探索电路=量子探索电路（）

action_grad = tf.gradients(tf.compat.v1.log(action_prob[:, action_placeholder]), model_params)
update_step = model_params.assign(model_params + epsilon * tf.squeeze(action_grad) * v)

尝试列表 = []

对于范围内的剧集（100）：
  尝试次数 = 0
  当前_r = 0

  将 tf.compat.v1.Session() 用作 sess：
    sess.run(tf.compat.v1.global_variables_initializer())

    而 cur_r &lt; 200：
      state_list、action_list、r_list = run_episode_tensorflow(sess、env、action_prob、探索电路)
      cur_r = 总和(r_list)
      尝试次数 += 1
      对于 idx，枚举（zip（state_list，action_list））中的（状态，操作）：
        _ = sess.run(update_step, feed_dict={observation_placeholder: state.reshape(1, 4), action_placeholder: action, v:sum(r_list[idx:])})

    attempts_list.append(num_tries)

n，bins，补丁= plt.hist（tries_list，bins = max（tries_list），align =&#39;left&#39;）
plt.xlabel(&#39;解决环境之前的集数&#39;)
plt.ylabel(&#39;频率&#39;)
plt.title(&#39;蒙特卡罗策略梯度与量子探索的结果&#39;)
plt.网格（真）
plt.show()

错误是
类型错误：无法将 NoneType 转换为张量或操作。
文件的其余部分
这是我的 google colab 文件的可编辑链接，看看是否可以使其工作
https://colab.research.google.com/drive /1RYKXvMtDZqRD2T2b39N04VjNmolLC-QS#scrollTo=g1s1EnHJTLUy]]></description>
      <guid>https://stackoverflow.com/questions/78215361/error-in-implementing-reinforcement-learning-model-using-quantum-circuit</guid>
      <pubDate>Sun, 24 Mar 2024 16:59:17 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch EMNIST 数据集加载器返回文件未找到或损坏</title>
      <link>https://stackoverflow.com/questions/78215347/pytorch-emnist-dataset-loader-return-file-not-found-or-corrupted</link>
      <description><![CDATA[我正在处理 EMNIST 数据集，并希望从 PyTorch 加载它，但它返回一个奇怪的错误：
&lt;块引用&gt;
运行时错误：文件未找到或已损坏。

这是我尝试加载数据集的方法：
trainset = torchvision.datasets.EMNIST(root=“emnist”,
                                   split=“字母”，
                                   火车=真，
                                   下载=真，
                                   变换=transforms.ToTensor())

可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78215347/pytorch-emnist-dataset-loader-return-file-not-found-or-corrupted</guid>
      <pubDate>Sun, 24 Mar 2024 16:53:53 GMT</pubDate>
    </item>
    <item>
      <title>机器学习和创建简单的人工智能[关闭]</title>
      <link>https://stackoverflow.com/questions/78214831/machine-learning-and-creating-a-simple-ai</link>
      <description><![CDATA[我想创建一个可以和我一起玩简单游戏的人工智能。这个游戏有一些思维层次，所以我应该教人工智能如何在不同的独特情况下思考等。但我不知道从哪里开始。该游戏将在 iOS(swiftui) 上运行。我在考虑 createML，但我不想把精力花在错误的事情上，所以我需要你的帮助。基本上需要一个路线图。
我没有尝试太多。我知道 Apple 发布了 CoreML 和 CreateML，但不知道这些是否适合我。]]></description>
      <guid>https://stackoverflow.com/questions/78214831/machine-learning-and-creating-a-simple-ai</guid>
      <pubDate>Sun, 24 Mar 2024 14:12:48 GMT</pubDate>
    </item>
    <item>
      <title>用于多标签分类的堆叠集成学习</title>
      <link>https://stackoverflow.com/questions/78214688/stacking-ensamble-learning-for-multilabelclassification</link>
      <description><![CDATA[我有两个 BERT 模型来实现代码中漏洞检测的多标签分类。一名接受过源代码培训，另一名接受过编译代码培训。他们实现的任务是多标签分类，因此两个模型的单个输出都是一个包含 6 个元素的数组，每个元素可以是 0 或 1，指示漏洞是否存在。
我想在这两个模型之上构建一个经典的 ML 分类器（如 RandomForest、SVM 等），实现称为 Stacking 的集成技术。知道我正在处理多标签分类，我该如何实现这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78214688/stacking-ensamble-learning-for-multilabelclassification</guid>
      <pubDate>Sun, 24 Mar 2024 13:28:23 GMT</pubDate>
    </item>
    <item>
      <title>如果文件夹已存在 ChromaDB，则防止创建嵌入</title>
      <link>https://stackoverflow.com/questions/78214495/prevent-create-embeddings-if-folder-already-present-chromadb</link>
      <description><![CDATA[这是我第一次尝试RAG应用。我正在尝试使用法学硕士进行问答。我将在下面粘贴运行良好的代码。我的问题是每次运行 python 代码时都会运行生成嵌入的代码。有没有办法只运行一次或检查嵌入文件夹是否为空，然后运行该代码。
from langchain_community.document_loaders import WebBaseLoader
从 langchain_community.document_loaders 导入 TextLoader
从 langchain_community.vectorstores 导入 Chroma
从 langchain_community 导入嵌入
从 langchain_community.chat_models 导入 ChatOllama
从 langchain_core.runnables 导入 RunnablePassthrough
从 langchain_core.output_parsers 导入 StrOutputParser
从 langchain_core.prompts 导入 ChatPromptTemplate
从 langchain.output_parsers 导入 PydanticOutputParser
从 langchain.text_splitter 导入 CharacterTextSplitter
从 langchain_community.embeddings 导入 OllamaEmbeddings

model_local = ChatOllama(model=&quot;codellama:7b&quot;)

loader = TextLoader(“remedy.txt”)
raw_doc = loader.load()

# 将文本文件内容分割成块
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
splitted_docs = text_splitter.split_documents(raw_doc)

# 使用嵌入函数将它们存储在向量数据库中
ollamaEmbeddings = embeddings.ollama.OllamaEmbeddings(model=“nomic-embed-text”)


# 使用色度向量数据库来存储数据
矢量存储 = Chroma.from_documents(
    文档=splitted_docs，
    嵌入=ollamaEmbeddings，
    persist_directory=&quot;./vector/my_data&quot;,
）

# 这会将数据写入本地
检索器 = vectorstore.as_retriever()

# 4. RAG 之后
print(&quot;RAG 之后\n&quot;)
after_rag_template = “””
    仅根据以下上下文回答问题：
    {语境}
    问题{问题}？
”“”
after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)
after_rag_chain = (
    {“上下文”：检索器，“问题”：RunnablePassthrough()}
    | after_rag_prompt
    |模型本地
    | StrOutputParser()
）
print(after_rag_chain.invoke(“普通感冒的家庭疗法是什么？”))
]]></description>
      <guid>https://stackoverflow.com/questions/78214495/prevent-create-embeddings-if-folder-already-present-chromadb</guid>
      <pubDate>Sun, 24 Mar 2024 12:31:15 GMT</pubDate>
    </item>
    <item>
      <title>TPU 连接问题 训练 TF 模型 Google Colab</title>
      <link>https://stackoverflow.com/questions/78209293/tpu-connectivity-issue-training-tf-model-google-colab</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78209293/tpu-connectivity-issue-training-tf-model-google-colab</guid>
      <pubDate>Fri, 22 Mar 2024 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 的 Google Colab Bert 实例化错误</title>
      <link>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</link>
      <description><![CDATA[我正在尝试在 Colab 上使用 Tensorflow 构建 Bert 模型。这段代码几周前就可以完美运行。现在，如果我尝试实例化模型，则会收到以下错误：
初始化 TF 2.0 模型 TFBertModel 时未使用 PyTorch 模型的某些权重：[&#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls .predictions.transform.LayerNorm.weight&#39;、&#39;cls.predictions.bias&#39;、&#39;cls.seq_relationship.bias&#39;、&#39;cls.predictions.transform.dense.bias&#39;、&#39;cls.seq_relationship.weight&#39;]
- 如果您从在其他任务或其他架构上训练的 PyTorch 模型初始化 TFBertModel（例如，从 BertForPreTraining 模型初始化 TFBertForSequenceClassification 模型），这是预期的。
- 如果您从希望完全相同的 PyTorch 模型初始化 TFBertModel（例如，从 BertForSequenceClassification 模型初始化 TFBertForSequenceClassification 模型），则不会出现这种情况。
TFBertModel 的所有权重都是从 PyTorch 模型初始化的。
如果您的任务与检查点模型训练的任务类似，您就可以使用 TFBertModel 进行预测，而无需进一步训练。
-------------------------------------------------- ------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-14-b0e769ef7​​890&gt;在&lt;细胞系：7&gt;()
      5 SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
      6 SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
----&gt; 7 SC_pooler_output = SC_bert_model(SC_input_layer, Attention_mask=SC_mask_layer)[1] # 第二个输出，che è il pooler_output
      8
      9 # 辍学层的Aggiungi

36帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py 在 type_spec_from_value(value) 中
   1002 3，“无法将 %r 转换为张量：%s” % (类型(值).__name__, e))
   1003
-&gt;第1004章
   第1005章 1005
   1006

TypeError：调用层“嵌入”时遇到异常（类型 TFBertEmbeddings）。

无法为名称构建 TypeSpec：“tf.debugging.assert_less_5/assert_less/Assert/Assert”
op：“断言”
输入：“tf.debugging.assert_less_5/assert_less/All”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_0”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_1”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_2”
输入：“占位符”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_4”
输入：“tf.debugging.assert_less_5/assert_less/y”
属性{
  键：“总结”
  价值 {
    我：3
  }
}
属性{
  键：“T”
  价值 {
    列表 {
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_INT32
      类型：DT_STRING
      类型：DT_INT32
    }
  }
}
 不支持的类型。

调用层“embeddings”接收的参数（类型 TFBertEmbeddings）：
  • input_ids=
  •position_ids=无
  • token_type_ids=
  • input_embeds=无
  •过去的键值长度=0
  • 训练=False

模型的代码是：
SC_input_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“input_ids”)
SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
SC_pooler_output = SC_bert_model（SC_input_layer，attention_mask = SC_mask_layer）[1]

# Dropout 层的Aggiungi
SC_dropout_layer = Dropout(dropout_rate)(SC_pooler_output)
SC_output_layer = 密集（6，激活=&#39;sigmoid&#39;）（SC_dropout_layer）
SC_model = 模型(输入=[SC_input_layer, SC_mask_layer], 输出=SC_output_layer)

我发现安装tensorflow 2.10.0可以工作，但是使用Google Colab时我的CUDA版本有问题，并且使用tensorflow 2.10它无法识别GPU。
该代码几周前就可以工作，有人有解决方案吗？
编辑：同样的错误出现在 Kaggle 上。]]></description>
      <guid>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</guid>
      <pubDate>Sun, 17 Mar 2024 17:03:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tkinter 和 OpenCV 训练人脸识别模型的问题</title>
      <link>https://stackoverflow.com/questions/76396140/issue-with-training-a-face-recognition-model-using-tkinter-and-opencv</link>
      <description><![CDATA[描述：
我目前正在开发一个人脸识别项目，使用 Tkinter 作为 GUI，使用 OpenCV 在 Visual Studio 上进行图像处理。我的目标是使用图像数据集训练模型并显示一条弹出消息，指示训练完成。但是，我遇到了一个问题，当我单击“火车数据”按钮时没有任何反应。按钮。该窗口不会打开，也不会显示任何错误消息。
代码：
来自 tkinter 导入 *
从 tkinter 导入 ttk
从 PIL 导入图像、ImageTk
从 tkinter 导入消息框
导入 mysql.connector
导入CV2
导入操作系统
将 numpy 导入为 np

班次 火车：
    def __init__(自我，根)：
        self.root = 根
        self.root.geometry(“1530x790+0+0”)
        self.root.title(&quot;人脸识别系统&quot;)
        
        title_lbl= Label(self.root, text= &quot;列车数据集&quot;,font=(&quot;times new roman&quot;,35,&quot;粗体&quot;), bg=&quot;白色&quot;,fg=&quot;深绿色&quot;)
        title_lbl.place(x=0,y=0,宽度=1530,高度=45)
        
        img_top= Image.open(r&quot;C:\Users\The-Javeira\Desktop\test\images\b.jpg&quot;)
        img_top= img_top.resize((1530,325), Image.ANTIALIAS)
        self.photoimg_top= ImageTk.PhotoImage(img_top)
        
        f_lbl2= 标签(self.root,image=self.photoimg_top)
        f_lbl2.place(x=0,y=55,宽度=1530,高度=325)
        
         ＃按钮
        b1_1=Button(self.root ,text=“训练数据”,command=self.train_classifier,cursor=“hand2”,font=(“times new roman”,30,“bold”), bg=” ;红色”,fg=“白色”)
        b1_1.place(x=0,y=380,宽度=1530,高度=60)
        
        img_bottom= Image.open(r&quot;C:\Users\The-Javeira\Desktop\test\images\train2.JPEG&quot;)
        img_bottom= img_bottom.resize((1530,325), Image.ANTIALIAS)
        self.photoimg_bottom= ImageTk.PhotoImage(img_bottom)
        
        f_lbl2= 标签(self.root,image=self.photoimg_bottom)
        f_lbl2.place(x=0,y=440,宽度=1530,高度=325)
        
    def train_classifier(自身):
        data_dir=(“图像数据”)
        path=[os.path.join(data_dir,file) for file in os.listdir(data_dir)]
        
        面孔=[]
        id=[]
        
        对于路径中的图像：
            img=Image.open(image).convert(&#39;L&#39;) #灰度图像
            imageNp=np.array(img,&#39;uint8&#39;)
            id=int(os.path.split(image)[1].split(&#39;.&#39;)[1])
            
            faces.append(imageNp)
            ids.append(id)
            cv2.imshow(“训练数据”,imageNp)
            cv2.waitKey(1)==13
        
        ids=np.array(ids)
        
        #============训练分类器并保存===========
      
        clf=cv2.face.LBPHFaceRecognizer_create()
        clf.train(面孔,ids)
        clf.write(“Classifier.xml”)
        messagebox.showinfo(&quot;结果&quot;,&quot;训练数据集完成！！&quot;)
        cv2.destroyAllWindows()


如果 __name__ == “__main__”：
    根 = Tk()
    obj = 火车（根）
    root.mainloop()
        

        
        
        
            
            
        
             
     

预期行为：
当我点击“火车数据”时按钮，我希望打开一个窗口，显示训练进度并显示图像。
训练完成后，我预计会弹出一条消息“训练数据集已完成！”出现。
分类器应保存为“Classifier.xml”在指定目录中。
实际行为：
当我点击“火车数据”时按钮，什么也没有发生。该窗口不会打开，并且没有显示错误消息。
没有出现预期的指示训练完成的弹出消息。
没有“Classifier.xml”文件在指定目录下创建
其他信息
所有必需的依赖项均已安装。]]></description>
      <guid>https://stackoverflow.com/questions/76396140/issue-with-training-a-face-recognition-model-using-tkinter-and-opencv</guid>
      <pubDate>Sat, 03 Jun 2023 12:40:21 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch mat1和mat2必须具有相同的dtype mlp</title>
      <link>https://stackoverflow.com/questions/75259774/pytorch-mat1-and-mat2-must-have-the-same-dtype-mlp</link>
      <description><![CDATA[所以我正在尝试做一个使用 PyTorch 训练 mlp 的函数。
我的代码如下：
def mlp_gradient_descent(x,y, 模型, eta = 1e-6, nb_iter = 30000) :

    损失下降= []
    dtype = torch.float
    设备 = torch.device(“CPU”)
    x = torch.from_numpy(x)
    y = torch.from_numpy(y)

    params = model.parameters()

    学习率 = eta
    对于范围内的 t(nb_iter)：
        y_pred = 模型(x)
        损失 = (y_pred - y).pow(2).sum()
        打印（丢失）
        如果 t % 100 == 99：
            打印（t，loss.item（））
            loss_descent.append([t, loss.item()])
        loss.backward()
        使用 torch.no_grad()：
            对于 params 中的参数：
                param -= Learning_rat*param.grad
            对于 params 中的参数：
                参数=无

我遇到了这个错误：
mat1 和 mat2 必须具有相同的 dtype

请注意：问题来自 model(x)，x 和 y 是 numpy 数组。
谢谢大家。
祝你有美好的一天。]]></description>
      <guid>https://stackoverflow.com/questions/75259774/pytorch-mat1-and-mat2-must-have-the-same-dtype-mlp</guid>
      <pubDate>Fri, 27 Jan 2023 14:54:14 GMT</pubDate>
    </item>
    </channel>
</rss>