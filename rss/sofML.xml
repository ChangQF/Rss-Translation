<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 19 May 2024 15:14:17 GMT</lastBuildDate>
    <item>
      <title>“无法解析 MainActivity 上的方法“startActivity(Intent)”和“无法解析构造函数“Intent(MainActivity, Class<CombineLettersActivity>)”</title>
      <link>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</link>
      <description><![CDATA[我正在按照此播放列表开发手语翻译应用。
我遇到以下错误：
无法解析方法“startActivity(Intent)”
无法解析构造函数“Intent（MainActivity，Class）”
无法解析构造函数“Intent（MainActivity，Class）”
以下是相关代码片段：
&lt;前&gt;&lt;代码&gt;@Override
protected void onCreate(Bundle savingInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    camera_button = findViewById(R.id.camera_button);
    camera_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看v）{
            startActivity(new Intent(MainActivity.this, CameraActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });

    merge_letter_button = findViewById(R.id.combine_letter_button);
    merge_letter_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看视图）{
            startActivity(new Intent(MainActivity.this，CombineLettersActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });
}


我尝试更改 Gradle 和 JDK 版本，但问题仍然存在。与我一起参与该项目的一位朋友也尝试解决该问题，但我们尚未成功。
任何帮助将不胜感激。感谢您的时间和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</guid>
      <pubDate>Sun, 19 May 2024 15:03:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 CoLab 中仅运行部分代码</title>
      <link>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</link>
      <description><![CDATA[我目前正在做一个图像识别项目，模型执行之前的预处理步骤需要相当长的时间。当模型出现错误时，我必须从头开始重新运行所有内容，这是非常耗时的。有没有办法避免从头开始运行整个流程而只执行模型部分？
如果代码没有从头开始执行，则初始部分中的包安装和标签部分将无法正常运行。]]></description>
      <guid>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</guid>
      <pubDate>Sun, 19 May 2024 14:37:50 GMT</pubDate>
    </item>
    <item>
      <title>如何判断我的 Datasat 是否服从高斯分布？</title>
      <link>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</link>
      <description><![CDATA[我正在遵循一些有关进行线性回归的教程，并且在构建笔记本时，我正在研究异常值检测，并且在用于进行异常值检测的技术中，其中之一涉及计算标准偏差，但是对于我需要知道我的列是否属于高斯分布。我知道有不同的技术，例如：
直方图
KDE 图
Q-Q图
科洛莫戈洛夫-斯米尔诺夫检验
夏皮罗-威尔克检验
达戈斯蒂诺和皮尔逊检验
我敢打赌还有更多。那么什么是最好用的呢？我想直方图只是提供了线索，但并没有显示出真正的意图。识别数据集是否为高斯分布的标准做法是什么？例如，我绘制了波士顿数据集和 RM 列的直方图（每个住宅的平均房间数），我发现它是高斯分布：

但是当我使用 shapiro 和 kstest 时，它说 RM 不是高斯！
对于 X.columns 中的 i：
    print(f&#39;{i}: {“非高斯” if shapiro(X[i])[1]&lt;0.05 else “高斯”} {shapiro(X[i])}&#39;)
    print(f&#39;{i}: {“非高斯” if kstest(X[i].values,“范数”)[1]&lt;0.05 else “高斯”} {kstest(X[i].values) ,“标准”)}&#39;)

上面的代码打印：
RM：非高斯 ShapiroResult（统计=0.9608722575483464，pvalue=2.411976537849353e-10）
RM：非高斯 KstestResult（统计=0.9998152774582629，pvalue=0.0，statistic_location=3.561，statistic_sign=-1）

怎么会这样呢？我应该相信什么？]]></description>
      <guid>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</guid>
      <pubDate>Sun, 19 May 2024 14:15:12 GMT</pubDate>
    </item>
    <item>
      <title>如何解决pickle.load()中的内存错误？</title>
      <link>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</link>
      <description><![CDATA[以 open(r&#39;..\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
glove_embedding = pickle.load(fp)
MemoryError Traceback（最近一次调用最后一次）
[39] 中的单元格，第 2 行
1 以 open(r&#39;D:\NuVision\Sentiment Analysis\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
----&gt; 2 glove_embedding = pickle.load(fp)
内存错误：
如何解决这个问题，因为 glove.pkl 大约为 3 GB]]></description>
      <guid>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</guid>
      <pubDate>Sun, 19 May 2024 13:24:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 的简单 QA 模型中的运行时错误</title>
      <link>https://stackoverflow.com/questions/78501874/runtimeerror-in-a-simple-qa-model-using-transformer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501874/runtimeerror-in-a-simple-qa-model-using-transformer</guid>
      <pubDate>Sun, 19 May 2024 07:28:22 GMT</pubDate>
    </item>
    <item>
      <title>名称特征不匹配 ML</title>
      <link>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</guid>
      <pubDate>Sun, 19 May 2024 05:37:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在训练模型时修复此 KeyError？</title>
      <link>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</guid>
      <pubDate>Sun, 19 May 2024 00:36:44 GMT</pubDate>
    </item>
    <item>
      <title>标准化将 NaN 值插入到我的数据框中</title>
      <link>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</guid>
      <pubDate>Sat, 18 May 2024 23:40:21 GMT</pubDate>
    </item>
    <item>
      <title>GflowNet 无法学习某些奖励</title>
      <link>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</link>
      <description><![CDATA[我尝试将问题简化为以下代码：
# 图表上的转换
转换 = {
    # 0：无操作
    ＃1：N
    ＃2：S
    ＃3：W
    ＃4：E
    1：{0：1、1：2、2：1、3：3、4：1}，
    2：{0：2、1：12、2：1、3：2、4：2}，
    3: {0: 3, 1: 3, 2: 3, 3: 4, 4: 1},
    4：{0：4、1：5、2：4、3：6、4：3}，
    5: {0: 5, 1: 13, 2: 4, 3: 5, 4: 5},
    6: {0: 6, 1: 6, 2: 6, 3: 7, 4: 4},
    7: {0: 7, 1: 8, 2: 7, 3: 9, 4: 6},
    8: {0: 8, 1: 14, 2: 7, 3: 8, 4: 8},
    9: {0: 9, 1: 9, 2: 9, 3: 10, 4: 7},
    10: {0: 10, 1: 11, 2: 10, 3: 10, 4: 9},
    11: {0: 11, 1: 15, 2: 10, 3: 16, 4: 11},
    12: {0: 12, 1: 18, 2: 2, 3: 12, 4: 12},
    13: {0: 13, 1: 19, 2: 5, 3: 13, 4: 13},
    14: {0: 14, 1: 20, 2: 8, 3: 14, 4: 14},
    15: {0: 15, 1: 21, 2: 11, 3: 17, 4: 15},
    16: {0: 16, 1: 17, 2: 16, 3: 16, 4: 11},
    17: {0: 17, 1: 22, 2: 16, 3: 23, 4: 15},
    18: {0: 18, 1: 18, 2: 12, 3: 25, 4: 18},
    19: {0: 19, 1: 19, 2: 13, 3: 26, 4: 25},
    20: {0: 20, 1: 20, 2: 14, 3: 27, 4: 26},
    21: {0: 21, 1: 21, 2: 15, 3: 22, 4: 27},
    22: {0: 22, 1: 22, 2: 17, 3: 24, 4: 21},
    23: {0: 23, 1: 24, 2: 17, 3: 23, 4: 17},
    24: {0: 24, 1: 22, 2: 23, 3: 24, 4: 22},
    25: {0: 25, 1: 25, 2: 25, 3: 19, 4: 18},
    26: {0: 26, 1: 26, 2: 26, 3: 20, 4: 19},
    27: {0: 27, 1: 27, 2: 27, 3: 21, 4: 20}
}

＃ 模型
类 TBModel(nn.Module):
  def __init__(self, num_hid):
    超级().__init__()

    self.mlp_forward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                     nn.LeakyReLU(),
                                     nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.mlp_backward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                      nn.LeakyReLU(),
                                      nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.logZ = nn.Parameter(torch.ones(1))

  def 前向（自身，x）：
    P_F = self.mlp_forward(x)
    返回P_F
  
  def向后（自身，x）：
    P_B = torch.tensor([(1/INPUT_DIMS)]*INPUT_DIMS)#self.mlp_backward(x)

    返回P_B

# 奖励函数
def奖励_that_model_does_not_learn（轨迹）：
  目标轨迹 = [21, 27, 20, 14, 8]
  奖励=0
  对于范围内的 i(len(轨迹))：
    如果轨迹[i] == goal_trajectory[i]：
      奖励=奖励+1
  返回 torch.tensor(奖励)

def奖励_that_model_learns（轨迹）：
  如果轨迹 == [21, 27, 20, 14, 8]：
    返回 torch.tensor([1])
  返回 torch.tensor([0])


模型 = TBModel(512)
opt = torch.optim.Adam(model.parameters(), 3e-4)

tb_losses = []
tb_奖励 = []
logZs = []
小批量损失= 0
小批量奖励 = 0

对于 tqdm.tqdm 中的剧集（范围（NUM_EPOCHS），ncols = 40）：
  
  gflow_state = torch.zeros(TRAJECTORY_LENGTH)
  状态 = 起始节点
  总计_P_F = 0
  总P_B = 0
  轨迹=[]

  对于范围内的 t（TRAJECTORY_LENGTH）：
    轨迹.append(状态)
    P_F_s = model.forward(gflow_state)
    P_B_s = torch.tensor([(1/5)])

    猫=分类（logits=P_F_s）
    动作 = cat.sample()
    _gflow_state = gflow_state.clone()
    _gflow_state[t] = 操作
    gflow_state = _gflow_state.clone()

    new_state = 转换[状态][action.item()]
    Total_P_F += cat.log_prob(动作)
    Total_P_B += torch.log(P_B_s)

    状态 = 新状态

  奖励=reward_that_model_does_not_learn（轨迹）

  损失 = (model.logZ +total_P_F - torch.log(reward).clip(-20) -total_P_B).pow(2)
  
  minibatch_loss += 损失
  minibatch_reward += 奖励

  if (episode + 1) % BATCH_SIZE == 0:
    wandb.log({
      “损失”：minibatch_loss.item(),
      “奖励”：minibatch_reward.item()/BATCH_SIZE,
      “Z”：model.logZ.item()
    })
    minibatch_loss.backward()
    opt.step()
    opt.zero_grad()
    小批量损失= 0
    小批量奖励 = 0

这是我对 GFlowNet 的实现。我正在使用此模型引导代理通过具有 27 个节点的地图，如转换所述。 GFlowNet 对动作排列进行采样，这些动作将使代理在地图上移动。在轨迹结束时，将为代理计算奖励。该模型能够通过奖励reward_that_model_learns来学习明确的轨迹。然而，代理在学习优化由 reward_that_model_does_not_learn 定义的奖励时要困难得多。两者之间的唯一区别是，一个得分为全有或全无，而另一种则对轨迹给予部分评分。我不明白为什么该模型可以与一个模型斗争，但可以学习另一个模型，因为在这两种情况下，它都处理相同的状态空间（动作的排列）。如果能从理论上理解为什么某些奖励更难学习以及如何继续前进，那就太好了，谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</guid>
      <pubDate>Sat, 18 May 2024 21:22:00 GMT</pubDate>
    </item>
    <item>
      <title>感知器的图像识别不起作用</title>
      <link>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</link>
      <description><![CDATA[我必须调整我的图像识别代码，以便它使用感知器来代替分类器进行图像识别。我按照讲师提供的示例执行了所有操作（并且我正在使用他们的感知器代码）。使用分类器，我的图像识别工作完美，没有出错，但是当我用感知器替换这些分类器时，无论我使用什么图像，它总是被识别为第二种类型。
我的图像识别代码：
folder_names=[“First_type”] 、“第二类型”、“第三类型”]
images_in_folder=[25, 25, 25]
标签=[]
学习矩阵 = []

网络=感知器.PerceptronNetwork(6000,1)
label_matrix=[[0],[1],[2]]*25
大小=75,6000
Learning_matrix=np.zeros(大小，dtype=np.float32)

def GaborFilter(image_name):
    k大小 = 31
    西格玛 = 5
    theta_range = np.array([0, np.pi/4, np.pi/2])
    
    频率 = np.array([1.1, 2.1, 3.1, 4.1, 5.1])
    相位=0
    gabor_filter_points = []
    
    原始图像 = cv2.imread(图像名称, cv2.IMREAD_GRAYSCALE)
    调整大小的图像 = cv2.resize(原始图像, (1000, 1000))
    
    step_size_height = resized_image.shape[1] // 20
    step_size_width = resized_image.shape[0] // 20

    对于 theta_range 中的 theta：
        对于频率中的 freq：
            过滤器= cv2.getGaborKernel（（ksize，ksize），西格玛，西塔，频率，相位）
            filtered_image=cv2.filter2D（src=resized_image，d深度=-1，kernel=filter）
            对于范围内的 x（0，resized_image.shape[0]，step_size_width）：
                对于范围内的 y(0, resized_image.shape[1], step_size_height):
                    gabor_filter_points.append(filtered_image[x][y]/255)
    返回 gabor_filter_points

gabor_attributes=[]

对于范围（25）内的 image_nr：
    对于folder_index，枚举中的num_of_images（images_in_folder）：
        文件夹名称 = 文件夹名称[文件夹索引]
        image_path = os.path.join(folder_name, str(image_nr + 1) + &quot;.jpg&quot;)
        gabor_attr_for_image = GaborFilter(图像路径)
        gabor_attributes.append(gabor_attr_for_image)

学习矩阵=gabor_attributes
纪元数=0
对于范围（100）内的纪元：
    总错误数=0
    对于范围 (75) 内的 i：
        error_in_network=network.teachNetwork(learning_matrix[i],label_matrix[i])
        总错误数+=网络中的错误数
    number_of_epochs+=1
    如果总错误数==0：
        休息;

识别矩阵=[]
recognize_matrix=(GaborFilter(“Test.jpg”))
雷兹=[10]
网络.giveNetworkAnswer(recognition_matrix, rez)

如果 rez[0]==0:
    print(&quot;第一种类型&quot;)
elif rez[0]==1:
    print(&quot;第二个管子&quot;)
elif rez[0]==2:
    print(&quot;第三种类型&quot;)
别的：
    print(&quot;错误：&quot;+str(rez[0]))

感知器代码，由我的讲师提供：
### 单独的神经元（感知器）类###
神经元类：
    利亚姆达 = 0.001
    def __init__(this, input_nr):
        this.input_number = input_nr
        this.权重 = []

        对于范围内的 i（this.input_number）：
            this.weights.append(np.random.normal(0, 0.01))
        this.threshold = np.random.normal(0, 0.01)
        
    def 响应（此，输入信号）：
        总和 = 0
        对于范围内的 i（this.input_number）：
            sum += inputSignal[i] * this.weights[i]
        sum -= this.threshold
        如果总和 &gt; 返回 1 0 否则 0
            
    def changeWeights(this, inputSignal, targetResponse):
        实际响应 = this.response(inputSignal)
        错误 = 目标响应 - 实际响应
        
        如果错误！= 0：
            对于范围内的 i（this.input_number）：
                deltaSvoris = this.liambda * inputSignal[i] * 错误
                this.weights[i] += deltaSvoris
            this.threshold += this.liambda * 错误
        返回错误
           
########## 感知器 ANN 类 ############
类感知器网络：
    def __init__(this, 输入_nr, 输出_nr):
        this.input_number = input_nr
        this.neuronNumber = 输出编号
        this.outputLayer = []
        对于范围内的 i(this.neuronNumber)：
            神经元 = 神经元(this.input_number)
            this.outputLayer.append(神经元)

    def示教网络（这个，输入向量，输出向量）：
        错误编号输入输出 = 0
        对于范围内的 i(this.neuronNumber)：
            神经响应 = this.outputLayer[i].response(inputVector)
            如果神经元响应！= 输出向量[i]：
                错误= this.outputLayer [i] .changeWeights（inputVector，outputVector [i]）
                错误编号输入输出+=abs(错误)
        返回错误编号输入输出
    
    def GiveNetworkAnswer(this, inputVector, networkResponse):
        对于范围内的 i(this.neuronNumber)：
            networkResponse[i] = this.outputLayer[i].response(inputVector)
            打印（f“{networkResponse}”）

我尝试更改纪元数，打印出一些值以查看我使用的数据是否存在错误，但没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</guid>
      <pubDate>Sat, 18 May 2024 18:12:53 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中却不行 [关闭]</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 python 写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def preprocess_image(image_path):
    # 想象中的卡里卡
    img = Image.open(图像路径)
    # 在 scala di grigi 中进行想象和转换
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将 l&#39;immagine 转换为 un array numpy 并将 Ridimensiona 转换为 un unico vettare
    img_array = np.array(img).reshape(1, -1)
    返回img_array
*强调文字*
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;成功模型&quot;)
    # 模型用途
    # Carica e pre-elabora un&#39;immagine
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # Prevedere la classe del nuovo esempio
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

在橙色工作流程中，我使用了逻辑回归，该模型的准确性相当高。在图像嵌入中我使用了 Inception v3。 这是我获取数据集的位置。我认为我预处理图像的方式有问题，也许它与Orange方法不同，但我无法解决问题 这是橙色工作流程的图像。
编辑：我还尝试在输入中提供一个图像文件夹，结果并不总是相同，但在包含 500 张猫和狗照片的文件夹中，模型只能识别 10 只狗（对绝大多数狗进行错误分类）]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    <item>
      <title>反馈管理器需要具有单一签名推断的模型</title>
      <link>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</link>
      <description><![CDATA[我在尝试运行机器运行模型时遇到了此错误，该模型应该为驾驶员睡意检测项目提供动力
&lt;前&gt;&lt;代码&gt;W0000 00:00:1715924294.765512 2256 inference_feedback_manager.cc:114]
反馈管理器需要具有单一签名推断的模型。
禁用对反馈张量的支持。

模型架构如下：
&lt;前&gt;&lt;代码&gt;#**型号**
从 keras.layers 导入 BatchNormalization
模型 = tf.keras.models.Sequential()
# 输入形状是所需的图像大小 145 x 145，颜色为 3 字节

#这是第一个卷积
   model.add(Conv2D(16, 3, 激活=&#39;relu&#39;, input_shape=X_train.shape[1:]))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第二次卷积
   model.add(Conv2D(32, 5, 激活=&#39;relu&#39;))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第三次卷积
  model.add(Conv2D(64, 10, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())
  model.add(MaxPooling2D())
  tf.keras.layers.Dropout(0.3)

# 第四次卷积
  model.add(Conv2D(128, 12, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())

# 将结果压平以输入 DNN
  模型.add(压平())
  model.add（密集（128，激活=&#39;relu&#39;））
  模型.add(Dropout(0.25))
  model.add（密集（64，激活=&#39;relu&#39;））
# 只有 1 个输出神经元。
  model.add（密集（1，激活=&#39;sigmoid&#39;））

  model.compile(loss=“binary_crossentropy”，metrics=[“accuracy”]，optimizer=Adam(lr=0.001))
  历史= model.fit（train_generator，epochs = 10，batch_size = 32，validation_data = test_generator）

# 定义服务签名
  输入签名 = [
      tf.TensorSpec(shape=[None, 145, 145, 3], dtype=tf.float32, name=&#39;input_tensor&#39;)
  ]

@tf.function(input_signature=input_signature)
defserving_fn（输入）：
    返回模型（输入）

export_dir = &#39;E:\系统项目\项目&#39;
tf.saved_model.save（serving_fn，export_dir）

# 加载模型进行推理
load_model = tf.saved_model.load(&#39;my_model.keras&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</guid>
      <pubDate>Fri, 17 May 2024 05:59:50 GMT</pubDate>
    </item>
    <item>
      <title>为职位推荐系统选择正确的集成方法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</link>
      <description><![CDATA[我正在开发机器学习职位推荐系统，并且正在考虑使用集成学习方法。我使用的数据集很全面，包括各种属性，例如职位、职位描述、工资、地点和公司详细信息。它包含数字、分类和文本数据的混合。
我计划使用结合多种模型和技术的混合方法来提高其性能：
协作过滤或矩阵分解来捕获用户和职位发布之间的交互。
神经网络用于处理复杂的数据类型，例如职位描述中的文本。
决策树或随机森林的可解释性以及处理数字和分类数据混合的能力。
我正在寻求有关哪种集成方法最适合此任务的建议。我希望模型能够很好地过滤、灵活地处理数据类型、在训练和时间上具有良好的性能，并提供可解释性。
我还没有开始，但我会考虑尝试任何合理的方法！]]></description>
      <guid>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</guid>
      <pubDate>Fri, 10 May 2024 17:51:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将 FastAI 分类器集成到 sklearn VotingClassifier 中？</title>
      <link>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</link>
      <description><![CDATA[我有一堆表格数据，我设法用它们训练了一个 RandomForestClassifier、一个 GradientBoostingClassifier 和一个深度学习模型（来自 fastai 的表格学习器）。我在结果中注意到，每个模型在特定标签上的表现都比其他模型要好，每个模型都不一样。我想知道我是否可以将所有模型放入 VotingClassifier（来自 sklearn 的模型）。我对 RandomForestClassifier 和 GradientBoostingClassifier 没有问题，但我没有找到有关将表格学习器放入 VotingClassifier 中的内容。可以这样做吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</guid>
      <pubDate>Mon, 06 May 2024 07:21:01 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“numpy.linalg._umath_linalg”没有属性“_ilp64”</title>
      <link>https://stackoverflow.com/questions/77451004/attributeerror-module-numpy-linalg-umath-linalg-has-no-attribute-ilp64</link>
      <description><![CDATA[在 google colab 上运行此代码块。&quot;import nltk&quot; 导致问题。
错误语句：
/usr/local/lib/python3.10/dist-packages/numpy/testing/_private/utils.py 在 &lt;module&gt; 中
55 IS_PYSTON = hasattr(sys, &quot;pyston_version_info&quot;)
56 HAS_REFCOUNT = getattr(sys, &#39;getrefcount&#39;, None) 不是 None 也不是 IS_PYSTON
---&gt; 57 HAS_LAPACK64 = numpy.linalg._umath_linalg._ilp64
58 
59 _OLD_PROMOTION = lambda: np._get_promotion_state() == &#39;legacy&#39;

**AttributeError: 模块 &#39;numpy.linalg._umath_linalg&#39; 没有属性 &#39;_ilp64&#39;**

import sys
import numpy as np
#!pip uninstall -y numpy
#!pip install numpy
!pip install setuptools
import pandas as pd
import matplotlib.pyplot as plt
import warnings
import csv
import urllib.parse as parse
import pickle
!pip uninstall -y nltk
!pip install nltk
import nltk
nltk.download(&#39;punkt&#39;)
from nltk.tokenize import word_tokenize
from urllib.parse import unquote

如何纠正？
我尝试卸载并重新安装 numpy 和 nltk。我也尝试升级它们，但同样的错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/77451004/attributeerror-module-numpy-linalg-umath-linalg-has-no-attribute-ilp64</guid>
      <pubDate>Thu, 09 Nov 2023 06:45:03 GMT</pubDate>
    </item>
    </channel>
</rss>