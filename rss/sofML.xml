<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 19 Jun 2024 18:19:09 GMT</lastBuildDate>
    <item>
      <title>控制 Azure ML 命令源代码的上传位置</title>
      <link>https://stackoverflow.com/questions/78643575/control-where-source-code-for-azure-ml-command-gets-uploaded</link>
      <description><![CDATA[我正在 Azure 机器学习工作室的笔记本中工作，并使用以下代码块通过 命令函数 实例化作业。
来自 azure.ai.ml 导入命令、输入、输出
来自 azure.ai.ml.entities 导入数据
来自 azure.ai.ml.constants 导入 AssetTypes

subscription_id = &quot;&lt;subscription_id&gt;&quot;
resource_group = &quot;&lt;resource_group&gt;&quot;
working = &quot;&lt;workspace&gt;&quot;
storage_account = &quot;&lt;storage_account&gt;&quot;
输入路径 = &quot;&lt;输入路径&gt;&quot;
输出路径 = &quot;&lt;输出路径&gt;&quot;

input_dict = {
&quot;input_data_object&quot;: 输入(
type=AssetTypes.URI_FILE, 
path=f&quot;azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace}/datastores/{storage_account}/paths/{input_path}&quot;
)
}

output_dict = {
&quot;output_folder_object&quot;: 输出(
type=AssetTypes.URI_FOLDER,
path=f&quot;azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/workspaces/{workspace}/datastores/{storage_account}/paths/{output_path}&quot;,
)
}

job = command(
code=&quot;./src&quot;, 
command=&quot;python 01_read_write_data.py -v --input_data=${{inputs.input_data_object}} --output_folder=${{outputs.output_folder_object}}&quot;,
inputs=input_dict,
outputs=output_dict,
environment=&quot;&lt;asset_env&gt;&quot;,
compute=&quot;&lt;compute_cluster&gt;&quot;,
)

returned_job = ml_client.create_or_update(job)

此操作成功运行，但每次运行时，如果存储在 ./src 目录中的代码发生变化，则会将新副本上传到默认的 blob 存储帐户。我不介意这一点，但每次运行时，代码都会上传到我的 blob 存储帐户根目录下的新容器中。因此，我的默认存储帐户会因容器而变得杂乱无章。我已阅读使用 command() 函数实例化 command 对象的文档，但我没有看到可用于控制 ./src 代码上传位置的参数。有什么方法可以控制吗？]]></description>
      <guid>https://stackoverflow.com/questions/78643575/control-where-source-code-for-azure-ml-command-gets-uploaded</guid>
      <pubDate>Wed, 19 Jun 2024 16:06:28 GMT</pubDate>
    </item>
    <item>
      <title>如果动作依赖于状态并且动作空间巨大，那么如何定义动作？</title>
      <link>https://stackoverflow.com/questions/78643467/how-to-define-action-if-the-actions-are-state-dependent-and-the-action-space-are</link>
      <description><![CDATA[我正在尝试使用 RL 来解决我的问题。这个问题具有巨大的状态空间（离散）和巨大的动作空间。此外，每个状态可用的动作各不相同（取决于状态）。因此，我不能使用通用 DQN，其中输出状态等于类的数量。此外，我在将动作编码到 NN 中时遇到了问题（因为大小和不同的类别）。但是，这个问题中的转换是确定性的，其中我知道采取行动后从当前状态到下一个状态。
有什么方法可以表示动作？或者有没有比 DQN 更好的 RL 算法可以使用？
谢谢
目前的想法是训练一个 DQN，其中输入既是当前状态，也是采取行动后的下一个状态。]]></description>
      <guid>https://stackoverflow.com/questions/78643467/how-to-define-action-if-the-actions-are-state-dependent-and-the-action-space-are</guid>
      <pubDate>Wed, 19 Jun 2024 15:40:09 GMT</pubDate>
    </item>
    <item>
      <title>用于 NAO 机器人手部物体姿势估计的任何库[关闭]</title>
      <link>https://stackoverflow.com/questions/78643191/any-library-for-hand-object-pose-estimation-for-nao-robot</link>
      <description><![CDATA[什么是与 naoqi 集成的库，用于估计 NAO 机器人的手部物体姿势（用于抓取物体）？
在执行结果中，我应该有 nao 机器人应该移动手臂以抓取目标物体的坐标。
代码应该适用于 Python 2.7。]]></description>
      <guid>https://stackoverflow.com/questions/78643191/any-library-for-hand-object-pose-estimation-for-nao-robot</guid>
      <pubDate>Wed, 19 Jun 2024 14:44:22 GMT</pubDate>
    </item>
    <item>
      <title>cached_download 是从 HF 中心下载文件的传统方式，请考虑升级到“hf_hub_download</title>
      <link>https://stackoverflow.com/questions/78642556/cached-download-is-the-legacy-way-to-download-files-from-the-hf-hub-please-cons</link>
      <description><![CDATA[我在使用嵌入模块进行人脸编码时遇到了这个问题。我该如何解决它们？
我尝试下载 Hugging Face 库并对其进行了探索，但找不到方法，并且还出现了类似 Future Warning: feature_extractor 已弃用并将在 v5 中删除的警告。请改用 image_processor。或已弃用并将在 v5 中删除。请改用image_processor\。它在笔记本电脑上运行良好，并会生成警告，但在 Raspbery Pi 中，它会终止程序。]]></description>
      <guid>https://stackoverflow.com/questions/78642556/cached-download-is-the-legacy-way-to-download-files-from-the-hf-hub-please-cons</guid>
      <pubDate>Wed, 19 Jun 2024 12:36:27 GMT</pubDate>
    </item>
    <item>
      <title>Mathematica 查询中的旋转量子比特神经网络</title>
      <link>https://stackoverflow.com/questions/78642555/rotating-qubit-neural-network-in-mathematica-query</link>
      <description><![CDATA[我正在研究的基本物理示例问题（尝试使用 Mathematica 了解基本神经网络的使用），如 Nolan 的论文（见图 2a） 中所述，是一个绕 y 轴旋转的量子比特，其中旋转间隔离散化为 $\theta_j \in [0,π]$。该设置涉及在 z 基础上测量的 y 旋转量子比特（因此自旋向上和自旋向下投影仪测量）。此场景涉及使用测量结果概率为每个离散旋转角度生成训练数据（使用 Mathematica 中的随机数生成器）。然后，我通过将自旋向上和自旋向下的元组与表示旋转角度的独热向量相关联来训练网络。
请参阅以下代码示例。最终图使用单个自旋向上和自旋向下的结果测试网络，即 {{1,0}} 和 {{0,1}}，虽然显示了正确的总体趋势，但与 Nolan 的论文中显示的趋势不一致（我在代码后显示了它们）。非常感谢您的帮助，请随时要求澄清任何问题。
(*Y 旋转量子比特上的自旋向上/自旋向下测量概率 *)

Pu[\[Theta]_] := (Cos[\[Theta]/2])^2; 
Pd[\[Theta]_] := 1 - Pu[\[Theta]]

(*评估每个 theta 值的测量概率*)

pr = Table[
List[N[FullSimplify[Re[Pu[\[Theta]]]]], 
N[FullSimplify[Re[Pd[\[Theta]]]]]], {\[Theta], \[Pi]/
40, \[Pi], \[Pi]/40}]
(*为每个 theta_j 生成训练测量结果，（使用随机数生成器），1 表示旋转向上结果，0 \
表示旋转向下*)

m = 1000;

meas = Table[{}, {Length[pr]}];
Table[Do[ b = ConstantArray[0, 1]; Clear[r];
updateTally[] := Block[{r}, r = RandomReal[];
如果[r &lt; pr[[j]][[1]], b[[1]] += 1, 
如果[pr[[j]][[1]] &lt;= r &lt; pr[[j]][[1]] + pr[[j]][[2]], 
b[[1]] += 0]]];
Do[updateTally[], {1}]; AppendTo[meas[[j]], b], {i, 1, m}], {j, 
Length[pr]}];

meas = Partition[Flatten[meas], m];
(*计数 1 和 0 的函数*)
countOnesZeros[list_] := {Count[list, 1], Count[list, 0]}

meas = Map[countOnesZeros, meas]

(*将 \[Theta] 离散化为 40 个 bin，每个 bin 测量 m = 10000*)

binToOneHot[bins_List, totalBins_Integer] := 
Table[If[i == #, 1, 0], {i, 1, totalBins}] &amp; /@ bins
bins = Range[40]; 
oneHotEncoded = binToOneHot[bins, 40]

trainingData = Rule @@@ Transpose[{meas, oneHotEncoded}]

(*这是 Nolan 论文 Fig2a 中的一个示例测试*)

su = {{1, 0}}

sd = {{0, 1}}

trainedNet /@ su

trainedNet /@ sd

Show[ListPlot[trainedNet /@ su, PlotStyle -&gt; Blue], 
ListPlot[trainedNet /@ sd, PlotStyle -&gt; Green], PlotRange -&gt; All]

]]></description>
      <guid>https://stackoverflow.com/questions/78642555/rotating-qubit-neural-network-in-mathematica-query</guid>
      <pubDate>Wed, 19 Jun 2024 12:36:15 GMT</pubDate>
    </item>
    <item>
      <title>了解 ICML 2013 鲸鱼挑战赛 - 露脊鲸重现中的数据泄露文章</title>
      <link>https://stackoverflow.com/questions/78642417/understanding-the-data-leakage-article-on-the-icml-2013-whale-challenge-right</link>
      <description><![CDATA[我在尝试进一步了解数据泄露时偶然发现了这篇文章。 https://www.kaggle.com/competitions/the-icml-2013-whale-challenge-right-whale-redux/discussion/4865
虽然这里确实突出了很好的观点，但我仍然不明白数据泄露发生在哪里。需要一些帮助来了解这篇文章如何识别数据泄露吗？]]></description>
      <guid>https://stackoverflow.com/questions/78642417/understanding-the-data-leakage-article-on-the-icml-2013-whale-challenge-right</guid>
      <pubDate>Wed, 19 Jun 2024 12:05:53 GMT</pubDate>
    </item>
    <item>
      <title>U-Net 无法过度拟合单个训练示例 - 损失平台</title>
      <link>https://stackoverflow.com/questions/78642145/u-net-unable-to-overfit-single-training-example-loss-plateaus</link>
      <description><![CDATA[我正在通过在由单个训练示例（图像到图像）组成的“数据集”上训练 U-Net 架构来测试它。输入图像是输出图像的噪声版本。最初，输出图像开始看起来更像所需的输出，但损失曲线开始趋于稳定，模型停止改进。
我的问题是：

U-Net（或任何没有完全连接层的 CNN）是否应该能够在给定单个示例的情况下在恒定图像上过度拟合？
如果它不能完成这个简单的任务，会犯什么常见错误或需要注意什么？

我通过将深度降低到几乎双卷积层（没有任何编码器/解码器层）来简化架构，并调整了学习率，但它仍然不会过度拟合。我期望模型在单个训练示例上完美地过度拟合，但事实并非如此。我已经调整了学习率，但模型仍然无法在这个简单的任务上实现完美的过度拟合。
缩放输入图像
缩放地面实况
达到平台期后的缩放模型输出

以下是我的实验的具体内容：
架构（深度 1）：
UNet(
(encoders): ModuleList(
(0): Sequential(
(0): Conv2d(4, 64，kernel_size=(3, 3)，stride=(1, 1)，padding=(1, 1))
(1): ReLU(inplace=True)
(2): Conv2d(64, 64，kernel_size=(3, 3)，stride=(1, 1)，padding=(1, 1))
(3): ReLU(inplace=True)
)
)
(解码器): ModuleList(
(0): ConvTranspose2d(128, 64，kernel_size=(2, 2)，stride=(2, 2))
(1): Sequential(
(0): Conv2d(128, 64，kernel_size=(3, 3)，stride=(1, 1)，padding=(1, 1))
(1): ReLU(inplace=True)
(2): Conv2d(64, 64，kernel_size=(3, 3)，步幅=(1, 1), 填充=(1, 1))
(3): ReLU(inplace=True)
)
)
(pool): MaxPool2d(kernel_size=2, 步幅=2, 填充=0, 扩张=1, ceil_mode=False)
(bottleneck): Sequential(
(0): Conv2d(64, 128, kernel_size=(3, 3), 步幅=(1, 1), 填充=(1, 1))
(1): ReLU(inplace=True)
(2): Conv2d(128, 128, kernel_size=(3, 3), 步幅=(1, 1), 填充=(1, 1))
(3): ReLU(inplace=True)
)
(out_conv): Conv2d(64, 4, kernel_size=(1, 1), 步幅=(1, 1))
)

初始化：Kaiming Normal
 def _initialize_weights(self) -&gt; None:
for m in self.modules():
if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
nn.init.kaiming_normal_(m.weight, mode=&#39;fan_in&#39;, nonlinearity=&#39;relu&#39;)
if m.bias is not None:
nn.init.constant_(m.bias, 0)

上采样方法：Crop 和 Concat
 def crop_and_concat(self, upsampled: torch.Tensor,
passive: torch.Tensor) -&gt; torch.Tensor:
diffY =pass.size()[2] - upsampled.size()[2]
diffX =pass.size()[3] - upsampled.size()[3]
upsampled = F.pad(upsampled, (diffX // 2, diffX - diffX // 2,
diffY // 2, diffY - diffY // 2))
return torch.cat((upsampled,bypass), dim=1)

损失：MSELoss
优化器：Adam，学习率从 1e-3 到 1e-4（上面的一切都在震荡，下面的也达到了稳定状态并且收敛速度较慢）]]></description>
      <guid>https://stackoverflow.com/questions/78642145/u-net-unable-to-overfit-single-training-example-loss-plateaus</guid>
      <pubDate>Wed, 19 Jun 2024 11:09:33 GMT</pubDate>
    </item>
    <item>
      <title>机器学习混淆矩阵 矩阵解释</title>
      <link>https://stackoverflow.com/questions/78641974/machine-learning-confusion-matrix-explanation-of-matrix</link>
      <description><![CDATA[`下面显示了几个混淆矩阵。TP、FP、FN 和 TN 已标记（使用 ChatGPT）
我知道对角线代表 TP。但是 FP、FN 和 TN 又如何呢？ TN 被识别（或区分）了吗？
请用矩阵解释您的答案
# [[TP=12 FP=0 FN=0]
# [FN=0 TP=7 FP=2]
# [FN=0 FN=0 TP=9]]

# [[TP=12 FP=1 FP=2]
# [FN=3 TP=7 FP=4]
# [FN=5 FP=1 TP=9]]

# [[TP_0=12 FP_1=1 FP_2=2 TN_3=0]
# [FN_0=3 TP_1=7 FP_2=4 FP_3=1]
# [FN_0=5 FP_1=1 TP_2=9 FP_3=2]
# [TN_0=0 FN_1=2 FN_2=3 TP_3=11]]

我试过 ChatGPT。
它用 TP、FP、FN 和 TN 标记矩阵。但没有得到适当的解释
解释我们如何在混淆矩阵中标记 FP、FN 和 TN`]]></description>
      <guid>https://stackoverflow.com/questions/78641974/machine-learning-confusion-matrix-explanation-of-matrix</guid>
      <pubDate>Wed, 19 Jun 2024 10:32:46 GMT</pubDate>
    </item>
    <item>
      <title>是否应将多个分类嵌入组合成条件 GAN（cGAN）？[关闭]</title>
      <link>https://stackoverflow.com/questions/78639650/should-multiple-categorical-embeddings-be-combined-for-a-conditional-gan-cgan</link>
      <description><![CDATA[我正在尝试制作一个条件 GAN (cGAN)，它可以根据标题和视频类别/流派生成 YouTube 缩略图。
它根本不起作用，甚至没有接近，所以我试图回到有关我的架构的基本问题。现在，我所做的是制作两个嵌入向量，一个用于标题，一个用于类别，然后我将它们组合起来并将它们都发送到生成器和鉴别器。
以下是我的代码：
class CategoryTitleEmbeddingNet(nn.Module):
def __init__(self, num_categories:int, category_embedding_dim:int, vocab_size:int, title_embedding_dim:int, title_max_length:int):
&quot;&quot;&quot;
初始化标题/类别嵌入神经网络

参数：
num_categories：唯一类别的总数。
category_embedding_dim：类别嵌入向量的维度。
vocab_size：唯一标记的总数。
title_embedding_dim：标题嵌入向量的维度。
title_max_length：标题中允许的最大标记数。

返回：
无
&quot;&quot;&quot;
super(CategoryTitleEmbeddingNet，self).__init__()
self.category_embedding = nn.Embedding(num_categories，category_embedding_dim)
self.title_embedding = nn.Embedding(vocab_size，title_embedding_dim)

self.fully_connected1 = nn.Linear(category_embedding_dim + title_embedding_dim * title_max_length，256)
self.fully_connected2 = nn.Linear(256，128)
self.fully_connected3 = nn.Linear(128，64)
self.fully_connected4 = nn.Linear(64，1)

def forward(self，category_indices：torch.Tensor，title_indices：torch.Tensor) -&gt; torch.Tensor:

category_embedded = self.category_embedding(category_indices)
title_embedded = self.title_embedding(title_indices)
title_embedded = title_embedded.view(title_embedded.size(0), -1)
category_embedded = category_embedded.view(category_embedded.size(0), -1)

combined_embeddings = torch.cat((category_embedded, title_embedded), dim=1)
combined_output = torch.relu(self.fully_connected1(combined_embeddings))
combined_output = torch.relu(self.fully_connected2(combined_output))
combined_output = torch.relu(self.fully_connected3(combined_output))
final_output = self.fully_connected4(combined_output)
返回final_output

我只是将两个嵌入向量连接成一个。我想知道这样做可以吗？还是我应该分别传递它们？我尝试对此进行一些研究，但这是一个相当小众的问题]]></description>
      <guid>https://stackoverflow.com/questions/78639650/should-multiple-categorical-embeddings-be-combined-for-a-conditional-gan-cgan</guid>
      <pubDate>Tue, 18 Jun 2024 21:04:12 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“keras.src.backend”没有属性“convert_to_numpy”</title>
      <link>https://stackoverflow.com/questions/78638871/attributeerror-module-keras-src-backend-has-no-attribute-convert-to-numpy</link>
      <description><![CDATA[我尝试使用 utoencoder 和 rus 相应的代码，并在使用 tensorflow 和 keras 时遇到问题，在下面的代码中我展示了代码和相应的错误。当我拟合自动编码器模型时，它显示 AttributeError: module &#39;keras.src.backend&#39; 没有属性 &#39;convert_to_numpy&#39;。我无法理解这个错误和相应的解决方案。对于这种情况我该如何解决我的问题？我使用 anaconda3 运行此代码。我使用 tensorflow 版本 2.16.1 和 keras 版本 3.3.3，错误显示在模型、拟合线中。我尝试使用自动编码器消除噪音，在这种情况下我编写了代码。我尝试运行多次但没有成功。我在 genimi 中写入错误。它向我展示了两种方法 1. 升级 tensorflow 和 keras 2. 不要使用 backend.convert_to_numpy，而是使用推荐的方法在较新版本中将张量转换为 NumPy 数组。]]></description>
      <guid>https://stackoverflow.com/questions/78638871/attributeerror-module-keras-src-backend-has-no-attribute-convert-to-numpy</guid>
      <pubDate>Tue, 18 Jun 2024 17:28:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 scikit-learn 在 Python 中对未标记数据实现层次聚类？</title>
      <link>https://stackoverflow.com/questions/78625589/how-to-implement-hierarchical-clustering-in-python-with-scikit-learn-for-unlabel</link>
      <description><![CDATA[我正在学习聚类，在尝试查找带有标记数据的数据库时遇到了一些问题，这对我来说是一个限制，因为我发现了非常有趣的未标记数据集。我读过各种无监督聚类技术，并想实现层次聚类。
我将数据加载到 pandas DataFrame 中，对数据进行标准化并应用层次聚类。然后我可视化了树状图，但我不确定如何解释结果或我是否使用了正确的参数。]]></description>
      <guid>https://stackoverflow.com/questions/78625589/how-to-implement-hierarchical-clustering-in-python-with-scikit-learn-for-unlabel</guid>
      <pubDate>Sat, 15 Jun 2024 04:03:59 GMT</pubDate>
    </item>
    <item>
      <title>实现神经网络的岭回归方程</title>
      <link>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network</link>
      <description><![CDATA[我试图在 MATLAB 中复制以下方程，以使用岭回归训练找到神经网络的最佳输出权重矩阵。
使用岭回归训练后的神经网络输出权重矩阵：

此方程来自 Mantas Lukosevicius 提供的回声状态网络指南，可在以下位置找到：https://www.researchgate.net/publication/319770153_A_practical_guide_to_applying_echo_state_networks（见第 11 页）
我的尝试如下。我认为外括号（红色）使其成为非传统的双重求和，这意味着 Voss 提出的方法（见 https://www.mathworks.com/matlabcentral/answers/1694960-nested-loops-for-double-summation）无法遵循。请注意，y_i 是一个 T x 1 向量，而 y_i_target 也是一个 T x 1 向量。Wout_i 是一个 N x 1 向量，其中 N 是神经网络中的节点数。我为每个 i^th 目标训练信号生成三个 Ny x 1 向量 Wout_i,y_i,y_i_target，其中 Ny 是训练信号的数量。Wout 的最终输出是一个 N x 1 向量，其中向量中的每个元素都是网络中每个节点的最佳权重。
N = 100; % 神经网络节点数
Ny = 200; % 训练信号数
T = 50; % 每个训练信号的时间长度 
X = rand(N,T); % 神经网络状态矩阵
reg = 10^-4; % 岭回归系数
outer_sum = zeros(Ny,1);
for i = 1:Ny
y_i_target = rand(T,1); % 训练信号
Wout_i = ((X*X&#39; + reg*eye(N)) \ (X*y_i_target)); 
Wouts{i} = Wout_i; % 针对每个第 i 个目标训练信号收集的每个 Wout_i 的单元矩阵
y_i = Wout_i&#39;*X; % 预测信号 
inner_sum = sum(((y_i&#39;-y_i_target).^2)+reg*norm(Wout_i)^2);
outer_sum(i) = inner_sum;
end
outer_sum = outer_sum.*(1/Ny);
[minval, minidx] = min(outer_sum);
Wout = cell2mat(Wouts(minidx));

我对 Wout 的最终答案是 N 乘以 1，正如它应该的那样，但我对我的答案不确定。我特别不确定我是否正确地完成了关于 Wout 操作的双重求和和 arg min。有什么方法可以验证我的答案吗？
解决方案：
我尝试了另一种方法/尝试，如下所示：
N = 100; % 神经网络中的节点数
Ny = 200; % 训练信号数
T = 50; % 每个训练信号的时间长度
X = rand(N,T); % 神经网络状态矩阵
reg = 10^-4; % 岭回归系数
MSE = zeros(Ny,1);
for i = 1:Ny
y_i_target = rand(T,1); % 训练信号
Wout_i = ((X*X&#39; + reg*eye(N)) \ (X*y_i_target)); % Luko 等人的 Eq. 9。
Wouts{i} = Wout_i; % 为每个第 i 个目标训练信号收集每个 Wout_i 的单元矩阵
y_i = Wout_i&#39;*X; % 预测信号
MSE(i) = (1/T)*sum((y_i&#39;-y_i_target).^2); % 均方误差
end
[minval, minidx] = min(MSE);
Wout = cell2mat(Wouts(minidx));

我相信这次尝试比第一次更好，但我不确定它是否仍然正确。
正如 BillBokeey 所强调的那样，所需的方程只是 Luko 等人提出的方程 9 的迭代版本。要进行训练，必须将方程 9 应用于训练数据集中的每个目标信号，并选择最小化均方误差 (MSE) 的结果 W_out。
最终更新：
我仍在寻找我的第二个解决方案的验证。我特别担心的是，我正在挑选出最小化 MSE 的最佳 Wout_i N x 1 向量，并有效地忽略所有其他 Wout_i 向量。]]></description>
      <guid>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network</guid>
      <pubDate>Sat, 08 Jun 2024 22:31:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 BARTDecoder 和 cached_property 的 Nougat OCR 中的 ImportError 和 TypeError 问题</title>
      <link>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</guid>
      <pubDate>Sat, 08 Jun 2024 05:43:48 GMT</pubDate>
    </item>
    <item>
      <title>如何从句子中删除不带有积极或消极情绪的词语？</title>
      <link>https://stackoverflow.com/questions/71284177/how-to-remove-words-from-a-sentence-that-carry-no-positive-or-negative-sentiment</link>
      <description><![CDATA[我正在尝试一种基于情感分析的方法来分析 youtube 评论，但评论中很多时候都有像 mrbeast、tiger/&#39;s、lion/&#39;s、pewdiepie、james 等这样的词，这些词并没有给句子增添任何感觉。我已经尝试过 nltk 的 average_perception_tagger，但效果不佳，因为它给出了如下结果
我的输入：
&quot;mrbeast james lion tigers bad sad clickbait fight nice good&quot;

我的句子中需要的单词：
&quot;bad sad clickbait fight nice good&quot;

我使用 average_perception_tagger 得到的结果：
[(&#39;mrbeast&#39;, &#39;NN&#39;),
(&#39;james&#39;, &#39;NNS&#39;),
(&#39;lion&#39;, &#39;JJ&#39;),
(&#39;tigers&#39;, &#39;NNS&#39;),
(&#39;bad&#39;, &#39;JJ&#39;),
(&#39;sad&#39;, &#39;JJ&#39;),
(&#39;clickbait&#39;, &#39;NN&#39;),
(&#39;fight&#39;, &#39;NN&#39;),
(&#39;nice&#39;, &#39;RB&#39;),
(&#39;good&#39;, &#39;JJ&#39;)]


因此，如您所见，如果我删除 mrbeast 即 NN，clickbait、fight 等词也会被删除，最终会从该句子中删除表达。]]></description>
      <guid>https://stackoverflow.com/questions/71284177/how-to-remove-words-from-a-sentence-that-carry-no-positive-or-negative-sentiment</guid>
      <pubDate>Sun, 27 Feb 2022 10:59:01 GMT</pubDate>
    </item>
    <item>
      <title>sklearn ImportError：无法导入名称 plot_roc_curve</title>
      <link>https://stackoverflow.com/questions/60321389/sklearn-importerror-cannot-import-name-plot-roc-curve</link>
      <description><![CDATA[我尝试按照 sklearn 文档中提供的 示例，绘制带有交叉验证的接收者操作特性 (ROC) 曲线。但是，以下导入在 python2 和 python3 中都给出了 ImportError。
from sklearn.metrics import plot_roc_curve

错误：
回溯（最近一次调用最后一次）：
文件“&lt;stdin&gt;”，第 1 行，在 &lt;module&gt;
ImportError：无法导入名称 plot_roc_curve

python-2.7 sklearn 版本：0.20.2.
python-3.6 sklearn 版本：0.21.3.
我发现以下导入工作正常，但它与 plot_roc_curve 不太一样。
from sklearn.metrics import roc_curve

plot_roc_curve 是否已弃用？有人可以尝试代码并告诉我 sklearn 版本是否有效吗？]]></description>
      <guid>https://stackoverflow.com/questions/60321389/sklearn-importerror-cannot-import-name-plot-roc-curve</guid>
      <pubDate>Thu, 20 Feb 2020 13:44:41 GMT</pubDate>
    </item>
    </channel>
</rss>