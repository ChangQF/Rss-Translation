<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 23 Jul 2024 09:17:05 GMT</lastBuildDate>
    <item>
      <title>在 vscode 上导入 tensorflow 时出现 NotFoundError（IMAC M1）</title>
      <link>https://stackoverflow.com/questions/78782546/notfounderror-while-importing-tensorflow-on-vscode-imac-m1</link>
      <description><![CDATA[有人能解释一下这个错误或者帮我解决这个问题吗？
代码：
# 导入库
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf

错误：
------------------------------------------------------------------------------
NotFoundError Traceback (最近一次调用最后一次)
Cell In[17]，第 4 行
2 import cv2
3 import matplotlib.pyplot as plt
----&gt; 4 将 tensorflow 导入为 tf
5 将 tensorflow_hub 导入为 hub
6 将 numpy 导入为 np

文件 /opt/homebrew/lib/python3.9/site-packages/tensorflow/__init__.py:434
432 _plugin_dir = _os.path.join(_s, &quot;tensorflow-plugins&quot;)
433 如果 _os.path.exists(_plugin_dir):
--&gt; 434 _ll.load_library(_plugin_dir)
435 # 加载可插拔设备库
436 _ll.load_pluggable_device_library(_plugin_dir)

文件 /opt/homebrew/lib/python3.9/site-packages/tensorflow/python/framework/load_library.py:151，在 load_library(library_location) 中
148 kernel_libraries = [library_location]
150 for lib in kernel_libraries:
--&gt; 151 py_tf.TF_LoadLibrary(lib)
153 else:
154 raise OSError(
155 errno.ENOENT,
156 &#39;用于加载内核库的文件或文件夹不存在。&#39;,
157 library_location)

NotFoundError: dlopen(/opt/homebrew/lib/python3.9/site-packages/tensorflow-plugins/libmetal_plugin.dylib, 0x0006): 未在平面命名空间中找到符号 (__ZN10tensorflow8internal10LogMessage16VmoduleActivatedEPKci)

大多数解决方案包括创建一个新的虚拟环境或/和执行

pip3 install tensorflow-macos

pip3 install tensorflow-metal


没有帮助或更改错误
多次刷新 VSCode]]></description>
      <guid>https://stackoverflow.com/questions/78782546/notfounderror-while-importing-tensorflow-on-vscode-imac-m1</guid>
      <pubDate>Tue, 23 Jul 2024 09:04:05 GMT</pubDate>
    </item>
    <item>
      <title>如何利用深度信息改进距离估计</title>
      <link>https://stackoverflow.com/questions/78782389/how-to-improve-distance-estimation-with-depth-information</link>
      <description><![CDATA[我一直在研究距离估计项目，但我遇到了 OpenCV 等库所采用的方法的问题。这些库基于像素测量来估计距离，这会导致不准确的结果。例如，靠近相机的两个物体与远离相机的两个物体具有相同的基于像素的距离，这是不正确的。
为了解决这个问题，我想结合深度估计来区分近处和远处的物体，从而提高距离估计的准确性。
但是，我找不到任何论文或代码示例来演示如何实现这一点。有人可以指出相关资源或提供有关如何实现基于深度的距离估计的指导吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78782389/how-to-improve-distance-estimation-with-depth-information</guid>
      <pubDate>Tue, 23 Jul 2024 08:31:39 GMT</pubDate>
    </item>
    <item>
      <title>任何人都可以告诉我们为什么我们使用正确的参数网格来微调预测精度</title>
      <link>https://stackoverflow.com/questions/78781865/any-one-can-please-tell-why-we-use-correct-parameter-grid-for-fine-tune-a-predic</link>
      <description><![CDATA[parameters = {
&#39;n_estimators&#39;: [100, 200],
&#39;learning_rate&#39;: [0.01, 0.1],
&#39;max_depth&#39;: [3, 5],
&#39;subsample&#39;: [0.8, 1.0],
&#39;colsample_bytree&#39;: [0.8, 1.0],
&#39;gamma&#39;: [0, 0.1],
&#39;min_child_weight&#39;: [1, 2]
}

并且需要更多时间来拟合
对此的解释和用例。
grid_search.fit(X_train, y_train) 当我执行此行时，它需要超过 45 分钟，但仍然没有完成
什么是 GridSearchCV？它的用例？什么是 cv=3，为什么我们给它以及什么是评分？为什么我们使用 GridSearchCV？]]></description>
      <guid>https://stackoverflow.com/questions/78781865/any-one-can-please-tell-why-we-use-correct-parameter-grid-for-fine-tune-a-predic</guid>
      <pubDate>Tue, 23 Jul 2024 06:28:25 GMT</pubDate>
    </item>
    <item>
      <title>机器学习（逻辑回归）使用数组作为特征/独立变量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78781575/machine-learning-logistic-regression-using-an-array-as-a-feature-independent-v</link>
      <description><![CDATA[抱歉，如果这是一个更一般/初学者的问题，但我在网上搜索答案时没有找到任何运气 - 也许我在谷歌上搜索了错误的东西。
所以本质上假设我有一个数据框：
-主题ID（int）
-年龄（int）
-性别（int 1-代表男性，2-代表女性）
-Pearson CC代表功能网络（矩阵）
这意味着我有一个PearsonCC数组。例如：



p_id
性别
PearsonCC




128_S_0200
M
[0.5052435694128596, 0.3375816208945487, 0.206...


003_S_0908
F
[-0.18955977794142087, 0.01652734870786999, -0...


141_S_1052
F
[0.0562331642358682, 0.5698911953687733, -0.17... -0...



所以我明白我们需要展平矩阵/矢量化上三角
然后将其转换为 numpy 以便进行特征缩放。我尝试过类似这样的方法：
X_mat_train = np.vstack(X_matrix_train[&#39;Z_new&#39;].values)
X_mat_test = np.vstack(X_matrix_train[&#39;Z_new&#39;].values)
我的问题是：
在使用它来拟合模型时，我是否应该将向量转换回原始形式？
因为我在网上搜索时得到了混合的结果。我很困惑，不知道对于这个特定的列，什么格式最好？
任何帮助都非常感谢！
如果我使用 sklearn 的 Logistic 回归：
model = LogisticRegression(max_iter=1000)
model.fit(X_train_final, y_train)
我收到一个错误，提示 PearsonCC 列可能只能是 int/float：
TypeError Traceback（最近一次调用最后一次）
TypeError：只有 size-1 数组可以转换为 Python 标量
为了扩展该功能，这是我的方法：
scaler = StandardScaler()

X_mat_train = np.vstack(X_matrix_train[&#39;Z_new&#39;].values)
X_mat_test = np.vstack(X_matrix_train[&#39;Z_new&#39;].values)

X_mat_train_scaled = scaler.fit_transform(X_mat_train)
X_mat_test_scaled = scaler.transform(X_mat_test)


我只是不确定如何将这个 X_mat_train 转换回 ML/Regression 可接受的格式]]></description>
      <guid>https://stackoverflow.com/questions/78781575/machine-learning-logistic-regression-using-an-array-as-a-feature-independent-v</guid>
      <pubDate>Tue, 23 Jul 2024 04:35:17 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch LSTM 模型上的 CrossEntropyLoss 每个时间步进行一个分类</title>
      <link>https://stackoverflow.com/questions/78781313/crossentropyloss-on-pytorch-lstm-model-with-one-classification-per-timestep</link>
      <description><![CDATA[我正在尝试制作一个 LSTM 模型，用于检测时间序列数据中的异常。它需要 5 个输入并产生 1 个布尔输出（如果检测到异常则为 True/False）。异常模式通常连续出现在 3 - 4 个时间步之间。与大多数 LSTM 示例不同，它们预测未来数据或对整个数据序列进行分类，我试图在每个时间步长输出一个 True/False 检测标志（如果检测到，则在模式中的最后一个时间步长点输出 True）。
不幸的是，CrossEntropyLoss 似乎不允许超过 1D 的输出张量，在这种情况下它将是 2D [序列数，序列长度和布尔数据]
以下是我正在尝试生成的一些示例代码：
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# 定义 LSTM 分类器模型
class LSTMClassifier(nn.Module):
def __init__(self, input_size, hidden_​​size, num_layers, output_size):
super(LSTMClassifier, self).__init__()
self.hidden_​​size = hidden_​​size
self.num_layers = num_layers
self.lstm = nn.LSTM(input_size, hidden_​​size, num_layers, batch_first=True)
self.fc = nn.Linear(hidden_​​size, output_size)

def forward(self, x):
h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​size).to(x.device)
c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​size).to(x.device)
out, _ = self.lstm(x, (h0, c0))
out = self.fc(out[:, -1, :])
return out

# 输入 - 100 个示例，每个时间步包含 5 个数据点（其中有 10 个时间步）
X_train = np.random.rand(100, 10, 5)
# 输出 - 100 个示例，每个时间步包含 1 个 True/False 输出以匹配输入
y_train = np.random.choice(a=[True, False], size=(100, 10)) # 二进制标签（True 或 False）

# 将数据转换为 PyTorch 张量
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.bool)

# 定义模型参数
input_size = X_train.shape[2] # 每个时间步 5 个输入
hidden_​​size = 4 # 我们尝试检测的模式通常为 4 个时间步长
num_layers = 1
output_size = 1 # True/False

# 实例化模型
model = LSTMClassifier(input_size, hidden_​​size, num_layers, output_size)

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练模型
num_epochs = 10
for epoch in range(num_epochs):
optimizer.zero_grad()
output = model(X_train_tensor)
loss = criterion(outputs, y_train_tensor)
loss.backward()
optimizer.step()
print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}&#39;)

# 测试模型
X_test = np.random.rand(10, 10, 5) # 生成一些测试数据 - 与输入相同的维度
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
with torch.no_grad():
predictions = model(X_test_tensor)
predict_outputs = torch.argmax(predictions, dim=1)
print(&quot;Predicted Outputs:&quot;, predict_outputs)

我是否需要重新调整输出（或者使 LSTM 的输出数量等于序列长度），或者使用不同的损失函数，或者使用 LSTM 以外的模型？]]></description>
      <guid>https://stackoverflow.com/questions/78781313/crossentropyloss-on-pytorch-lstm-model-with-one-classification-per-timestep</guid>
      <pubDate>Tue, 23 Jul 2024 02:11:04 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是出路吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78781284/is-artificial-intelligence-the-way-to-go</link>
      <description><![CDATA[大家好吗？我是一名电影行业专业人士，每个人都知道，目前从事这个行业很糟糕。有一件事让我着迷，那就是人工智能。我认为它远没有现在被描绘成的可怕流行语那么可怕。就我个人而言，我相信对于适应的电影制作人来说，它将是一个很好的工具。问题是，大多数人不会因为恐惧而适应。
话虽如此，我想更多地了解人工智能。我不知道从哪里开始，在这方面我完全是个新手。我希望真正熟练掌握它，这样我在未来几年就会有优势。有人有什么建议吗？我应该学习什么关于人工智能的知识？我应该学习如何使用生成式人工智能吗？如何“制造”生成式人工智能？目标应该是放弃电影制作事业，转而进入一家更依赖人工智能的公司吗？
请记住，我是个完全的新手。目标是获得一套有用的新技能。
谢谢！
我还没有尝试任何东西，因为我不确定如何开始。我应该进入机器学习领域吗？我应该学习 Python 吗？有什么期刊我应该关注吗？]]></description>
      <guid>https://stackoverflow.com/questions/78781284/is-artificial-intelligence-the-way-to-go</guid>
      <pubDate>Tue, 23 Jul 2024 01:55:46 GMT</pubDate>
    </item>
    <item>
      <title>无法在 React Native 中运行 FaceNet 或机器学习</title>
      <link>https://stackoverflow.com/questions/78781135/cannot-run-facenet-or-machine-learning-in-react-native</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78781135/cannot-run-facenet-or-machine-learning-in-react-native</guid>
      <pubDate>Tue, 23 Jul 2024 00:19:25 GMT</pubDate>
    </item>
    <item>
      <title>CNN 的可变大小输入</title>
      <link>https://stackoverflow.com/questions/78781105/variable-size-input-for-cnn</link>
      <description><![CDATA[我想创建一个可以猜测图像序列中下一张图像的 AI，我的想法是将 1、2、3、...、n-1 张图像作为输入提供给 CNN，然后通过 LSTM 运行它，输出是第 2、3、4...、第 n 张图像。
因此，我的想法是，一个 epoch 将是
步骤#1：输入：第一张图像，输出是第二张图像
步骤#2：输入：第一张和第二张图像，输出是第三张图像
步骤#3：输入：第一张、第二张和第三张图像，输出是第四张图像
.
.
.
最后一步：输入：第 1、2、3、...、第 (n-1) 张图像，输出是第 n（最后）张图像
然后我会通过将所有 n 张图像作为输入来预测第 (n+1) 张图像的输出
我以前从未使用过 LSTM，但我读到它可以处理可变的输入大小，我的问题是它需要为卷积层提供可变的输入大小，这有可能以某种方式工作吗？
我知道如何制作 CNN，但我不知道是否有可能拥有具有可变输入大小的 CNN]]></description>
      <guid>https://stackoverflow.com/questions/78781105/variable-size-input-for-cnn</guid>
      <pubDate>Mon, 22 Jul 2024 23:58:33 GMT</pubDate>
    </item>
    <item>
      <title>带偏移的增强回归树模型中的错误</title>
      <link>https://stackoverflow.com/questions/78780133/error-in-boosted-regression-tree-model-with-offset</link>
      <description><![CDATA[我正在使用增强回归树模型 (BRT) 来预测海豚物种出现的概率。为此，我有存在/不存在数据和几个环境变量。发生数据被分成几段，我想使用段的长度作为模型中的偏移量，以说明数据收集的工作量。
我使用 dismo 包中的 gbm.step() 函数来拟合模型。
brt&lt;-gbm.step(data=df, gbm.x=c(6,7,12,42,43,15,45,53,93,41,81,87,97), gbm.y = 4, offset = offset, family=&quot;bernoulli&quot;, tree.complexity=3, learning.rate = 0.01, bag.fraction = 0.6)

我将偏移量定义为 log(length of段）
offset&lt;-log(df$eff_length)

&gt; head(offset)
[1] 9.017928 9.171184 9.239406 9.367430 9.264165 9.233178
&gt; summary(offset)
最小值 第 1 区 中位数 平均值 第 3 区 最大值。
8.987 9.065 9.146 9.181 9.265 9.615 

当我运行模型时，它会反复出现此警告：
gbm::predict.gbm(model.list[[i]], x.data[pred.mask, , drop = FALSE], 中出现警告：
predict.gbm 不会将偏移量添加到预测值中。

随后出现此错误：
if (cv.loss.values[j] &gt; cv.loss.values[j - 1]) { 中的错误：
需要 TRUE/FALSE 的值缺失

我尝试包含 fold.vector=offset，因为看起来错误与交叉验证过程，但它给了我相同的警告和错误。
我在这里遗漏了什么？它与伯努利分布类型有关吗？]]></description>
      <guid>https://stackoverflow.com/questions/78780133/error-in-boosted-regression-tree-model-with-offset</guid>
      <pubDate>Mon, 22 Jul 2024 17:51:21 GMT</pubDate>
    </item>
    <item>
      <title>有人能帮我解决这个基本的机器学习问题吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78753768/can-anyone-help-me-with-this-basic-ml-question</link>
      <description><![CDATA[ MCQ 问题 
我想找到这个关于 ML 的基本问题的答案。你能帮我吗？我希望了解机器学习中的关键概念和技术，例如算法、数据预处理、模型训练和评估。如果您有任何提示或资源可以帮助我很好地掌握这些主题并将它们应用于实际场景，那就太好了。]]></description>
      <guid>https://stackoverflow.com/questions/78753768/can-anyone-help-me-with-this-basic-ml-question</guid>
      <pubDate>Tue, 16 Jul 2024 09:36:19 GMT</pubDate>
    </item>
    <item>
      <title>使用注释数据进行图像分类</title>
      <link>https://stackoverflow.com/questions/78386605/image-classification-using-annotated-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78386605/image-classification-using-annotated-data</guid>
      <pubDate>Thu, 25 Apr 2024 18:31:50 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：X 有 1 个特征，但 LinearRegression 需要 2 个特征作为输入</title>
      <link>https://stackoverflow.com/questions/73132252/valueerror-x-has-1-features-but-linearregression-is-expecting-2-features-as-in</link>
      <description><![CDATA[我正在使用 pywebio 为我的机器学习程序创建一个小型脚本运行用户界面。当不使用小型 UI 时，运行线性回归 predict() 函数时没有任何错误。
UI 正在从用户那里检索两个数字，一个 &#39;age&#39; 和一个 &#39;salary&#39;。这两个数字被输入到一个 numpy 数组中，并且 numpy 数组已从 1D 数组重塑为 2D 数组，因为我在 numpy 数组形状上收到错误。
现在，我收到一条错误消息，提示 predict() 方法仅接收 1 个特征而不是 2 个，而 sklearn 文档指出线性回归 predict() 方法始终获取“self”和另一个特征。我该如何修复此错误？
这是我的 UI 代码：
age = int(input(&quot;输入您的年龄：&quot;, type=NUMBER))
salary = int(input(&quot;输入您的薪水：&quot;, type=NUMBER))

entry = np.array([age, salary])
reshaped_entry = entry.reshape(-1, 1)

estimate = regr.predict(reshaped_entry) 

以下是错误消息：
ValueError Traceback (most recent call last)
Input In [21], in &lt;cell line: 22&gt;()

Input In [21], in retired_ui()

文件~\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:362，位于 LinearModel.predict(self, X) 中
348 def predict(self, X):
349 &quot;&quot;&quot;
350 使用线性模型进行预测。
351 
(...)
360 返回预测值。
361 &quot;&quot;&quot;
--&gt; 362 return self._decision_function(X)

文件 ~\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:345，位于 LinearModel._decision_function(self, X) 中
342 def _decision_function(self, X):
343 check_is_fitted(self)
--&gt; 345 X = self._validate_data(X, accept_sparse=[&quot;csr&quot;, &quot;csc&quot;, &quot;coo&quot;], reset=False)
346 return safe_sparse_dot(X, self.coef_.T, density_output=True) + self.intercept_

文件 ~\anaconda3\lib\site-packages\sklearn\base.py:585, in BaseEstimator._validate_data(self, X, y, reset, valid_separately, **check_params)
582 out = X, y
584 if not no_val_X and check_params.get(&quot;ensure_2d&quot;, True):
--&gt; 585 self._check_n_features(X, reset=reset)
587 return out

File ~\anaconda3\lib\site-packages\sklearn\base.py:400, in BaseEstimator._check_n_features(self, X, reset)
397 return
399 if n_features != self.n_features_in_:
--&gt; 400 raise ValueError(
401 f&quot;X 有 {n_features} 个特征，但 {self.__class__.__name__} &quot;
402 f&quot;需要 {self.n_features_in_} 个特征作为输入。&quot;
403 )

ValueError: X 有 1 个特征，但 LinearRegression 需要 2 个特征作为输入。
​​]]></description>
      <guid>https://stackoverflow.com/questions/73132252/valueerror-x-has-1-features-but-linearregression-is-expecting-2-features-as-in</guid>
      <pubDate>Wed, 27 Jul 2022 04:29:07 GMT</pubDate>
    </item>
    <item>
      <title>TypeError: 无法将函数返回值转换为 Python 类型！签名为 () -> handle anaconda spyder</title>
      <link>https://stackoverflow.com/questions/72179285/typeerror-unable-to-convert-function-return-value-to-a-python-type-the-signatu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/72179285/typeerror-unable-to-convert-function-return-value-to-a-python-type-the-signatu</guid>
      <pubDate>Mon, 09 May 2022 23:48:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中使用具有焦点损失的类权重来处理多类分类的不平衡数据集</title>
      <link>https://stackoverflow.com/questions/64751157/how-to-use-class-weights-with-focal-loss-in-pytorch-for-imbalanced-dataset-for-m</link>
      <description><![CDATA[我正在研究语言任务的多类分类（4 个类别），并且我正在使用 BERT 模型进行分类任务。我正在关注这篇博文NLP 迁移学习：针对文本分类的微调 BERT。 我的 BERT Fine Tuned 模型返回 nn.LogSoftmax(dim=1)。
我的数据非常不平衡，因此我使用 sklearn.utils.class_weight.compute_class_weight 来计算类别的权重，并使用 Loss 中的权重。
class_weights = compute_class_weight(&#39;balanced&#39;, np.unique(train_labels), train_labels)
weights= torch.tensor(class_weights,dtype=torch.float)
cross_entropy = nn.NLLLoss(weight=weights) 


我的结果不太好，因此我想用 Focal Loss 进行实验，并为 Focal Loss 编写了一个代码。
class FocalLoss(nn.Module):
def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):
super(FocalLoss, self).__init__()
self.alpha = alpha
self.gamma = gamma
self.logits = logits
self.reduce = reduce

def forward(self, input, target):
BCE_loss = nn.CrossEntropyLoss()(inputs, target)

pt = torch.exp(-BCE_loss)
F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss

if self.reduce:
return torch.mean(F_loss)
else:
return F_loss

我现在有 3 个问题。首先也是最重要的是

我应该将类权重与 Focal Loss 结合使用吗？
如果我必须在这个 Focal Loss 中实现权重，我可以在 nn.CrossEntropyLoss() 中使用 weights 参数吗？
如果这个实现不正确，那么包括权重在内的正确代码应该是什么（如果可能）
]]></description>
      <guid>https://stackoverflow.com/questions/64751157/how-to-use-class-weights-with-focal-loss-in-pytorch-for-imbalanced-dataset-for-m</guid>
      <pubDate>Mon, 09 Nov 2020 11:53:49 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以获得包含世界上几乎所有国家护照的护照图像数据集？</title>
      <link>https://stackoverflow.com/questions/60039938/where-can-i-get-passport-images-dataset-that-contain-passport-of-almost-all-coun</link>
      <description><![CDATA[我正在训练一个 OCR 模型，用于从护照中识别 MRZ。为了训练我的模型以获得更高的准确性，我需要用尽可能多的图片来训练它。我试图在 KAGGLE 上找到护照的数据集，但找不到。
有人能告诉我从哪里可以获得包含几乎所有国家或北美和南美护照的护照图像数据集吗？
非常感谢您的帮助。
祝好，
Asma]]></description>
      <guid>https://stackoverflow.com/questions/60039938/where-can-i-get-passport-images-dataset-that-contain-passport-of-almost-all-coun</guid>
      <pubDate>Mon, 03 Feb 2020 13:11:08 GMT</pubDate>
    </item>
    </channel>
</rss>