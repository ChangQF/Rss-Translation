<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 09 Jun 2024 06:19:43 GMT</lastBuildDate>
    <item>
      <title>我们如何使用字典列表作为 tfidfvectorizer 的输入</title>
      <link>https://stackoverflow.com/questions/78597657/how-we-can-use-list-of-dictionary-for-input-of-tfidfvectorizer</link>
      <description><![CDATA[我有一份字典列表，每个字典都显示一个 pdf，键是页码和 pdf 每页的词干标记值，如何使用此结构输入 tfidf vectorize？
我知道 tfidfvectorize 的输入必须是字符串，但我不知道如何转换我的输入，以便系统分别理解每个 pdf 和每页的标记，因为我想建立倒排索引]]></description>
      <guid>https://stackoverflow.com/questions/78597657/how-we-can-use-list-of-dictionary-for-input-of-tfidfvectorizer</guid>
      <pubDate>Sun, 09 Jun 2024 05:28:06 GMT</pubDate>
    </item>
    <item>
      <title>哪种技术对于创建自定义数据模型以增强聊天机器人至关重要？[关闭]</title>
      <link>https://stackoverflow.com/questions/78597646/which-technology-is-essential-for-creating-custom-data-models-to-enhance-chatbot</link>
      <description><![CDATA[哪种技术对于创建自定义数据模型以增强聊天机器人至关重要？

TensorFlow
PyTorch
Scikit-learn
Hugging Face Transformers

哪种技术对于创建自定义数据模型以增强聊天机器人至关重要？]]></description>
      <guid>https://stackoverflow.com/questions/78597646/which-technology-is-essential-for-creating-custom-data-models-to-enhance-chatbot</guid>
      <pubDate>Sun, 09 Jun 2024 05:18:41 GMT</pubDate>
    </item>
    <item>
      <title>为神经网络 MATLAB 实现岭回归方程</title>
      <link>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network-matlab</link>
      <description><![CDATA[我试图在 MATLAB 中复制以下方程，以使用岭回归训练找到神经网络的最佳输出权重矩阵。
使用岭回归训练后的神经网络输出权重矩阵：

我的尝试如下。请注意，y_i 是一个 T x 1 向量，而 y_i_target 也是一个 T x 1 向量。 Wout_i 是一个 N x 1 向量，其中 N 是神经网络中的节点数。我为每个 i^th 目标训练信号生成一个 Wout_i,y_i,y_i_target。为了简单起见，我没有在我的可重现示例中计算 Wout_i,y_i,y_i_target。
Ny = 1000; % 训练信号数量
T = 100; % 每个训练信号的时间长度
reg = 10^-4; % 岭回归系数
outer_sum = 0;
for i = 1:Ny
Wouts{i} = Wout_i; % 为每个第 i 个目标训练信号收集每个 Wout_i 的单元矩阵
inner_sum = sum(((y_i-y_i_target).^2)+reg*norm(Wout_i)^2);
outer_sum(i) = inner_sum;
end
outer_sum = outer_sum.*(1/Ny);
[minval, minidx] = min(outer_sum);
Wout = cell2mat(Wouts(minidx));

我对 Wout 的最终答案是 N 乘以 1，正如它应该的那样，但我对我的答案不确定。我特别不确定我是否正确地完成了 Wout 运算的双重求和和 arg min。有什么方法可以验证我的答案吗？]]></description>
      <guid>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network-matlab</guid>
      <pubDate>Sat, 08 Jun 2024 22:31:47 GMT</pubDate>
    </item>
    <item>
      <title>同一组内距离最小的图节点着色</title>
      <link>https://stackoverflow.com/questions/78597010/graph-node-coloring-with-minimal-distance-within-same-group</link>
      <description><![CDATA[我有一个带有权重的边列表（节点 1 节点 2 权重）作为无向图的输入。
A B 10
A C 9
A D 2
B C 1

我还有一个颜色列表作为输入，如下所示：
红色：2
蓝色：2

假设我们定义 2 个节点的距离是节点 A 和 B 之间的最短路径，用 dist(A,B) 表示。
同一组内节点对的距离总和表示如下：I红色、
I蓝色，等等。
一个组与另一个组之间的节点对的距离总和表示如下：E红色，蓝色 
将颜色分配给节点后，解决方案通过以下公式进行评估：

如果我们在上面的例子中选择 B、C 为红色，A、D 为蓝色，则得分为：
I红色=1
I红色=2
E红色，蓝色=dist(A,B)+dist(A,C)+dist(D,B)+dist(D,C)=10+9+12+11=42
得分=4/5(1+2)+1/5(42)=2.4+8.4=10.8
我正在寻找一种算法，该算法以某种方式将颜色分配给节点，使计算出的得分最小。我相信在多项式复杂度下不可能找到全局最优值，但该算法至少应该找到一个很好的近似值。]]></description>
      <guid>https://stackoverflow.com/questions/78597010/graph-node-coloring-with-minimal-distance-within-same-group</guid>
      <pubDate>Sat, 08 Jun 2024 21:44:35 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 空气质量指数预测模型中滞后特征和滚动统计的实现</title>
      <link>https://stackoverflow.com/questions/78596781/implementation-of-lag-features-and-rolling-statistics-in-xgboost-prediction-mode</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78596781/implementation-of-lag-features-and-rolling-statistics-in-xgboost-prediction-mode</guid>
      <pubDate>Sat, 08 Jun 2024 19:47:08 GMT</pubDate>
    </item>
    <item>
      <title>在 PyCharm 中运行 Teachable Machines 对象识别器</title>
      <link>https://stackoverflow.com/questions/78596363/running-teachable-machines-object-recognizer-in-pycharm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78596363/running-teachable-machines-object-recognizer-in-pycharm</guid>
      <pubDate>Sat, 08 Jun 2024 16:51:36 GMT</pubDate>
    </item>
    <item>
      <title>机器学习是否适合预测生产速度等值？</title>
      <link>https://stackoverflow.com/questions/78596285/is-machine-learning-good-for-predicting-values-like-production-speed</link>
      <description><![CDATA[我想知道机器学习是否是预测生产性能指标（如机器速度 pcs/h、机器设置时间、浪费）的好方法。产品是纸箱，因此从构造角度来看相当简单（易于分类）

场景是存在几种类型的机器、不同设计的盒子（可以分为 10 种类型），因此这些参数不是数字，然后我们有数字参数，如纸箱克重、盒子宽度、长度、高度、颜色数量。所以我希望训练一个模型，在提供机器类型、盒子类型、克重、宽度、长度等后，该模型将预测机器设置时间、运行速度 i pcs/h、浪费百分比。

如果机器学习是用于此目的的好工具，那么请告诉我哪种模型最适合。
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/78596285/is-machine-learning-good-for-predicting-values-like-production-speed</guid>
      <pubDate>Sat, 08 Jun 2024 16:20:27 GMT</pubDate>
    </item>
    <item>
      <title>在 Raspberry Pi 4 上安装 mediapipe 的问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78596275/problem-with-installation-mediapipe-on-raspberry-pi-4</link>
      <description><![CDATA[我在 raspberry pi 4 上安装 mediapipe 时遇到问题。首先，我遇到一个错误，即没有 mediapipe，安装 mediapipe-rpi4 后，我收到此警报。
这是一条错误消息：

导入 mediapipe
回溯（最近一次调用最后一次）：
文件“”，第 1 行，在
文件“/home/pi/TWT/TWT_V2/RobotProgram/env/lib/python3.9/site-packages/mediapipe/init.py”，第 16 行，在
来自 mediapipe.python 导入 *
文件“/home/pi/TWT/TWT_V2/RobotProgram/env/lib/python3.9/site-packages/mediapipe/python/init.py”，第 17 行，在
来自mediapipe.python._framework_bindings import resource_util
ModuleNotFoundError：没有名为“mediapipe.python._framework_bindings”的模块

有人能帮我吗？
我正在尝试在 raspberry pi 4 上安装 mediapipe 作为我的手部检测模块。]]></description>
      <guid>https://stackoverflow.com/questions/78596275/problem-with-installation-mediapipe-on-raspberry-pi-4</guid>
      <pubDate>Sat, 08 Jun 2024 16:17:17 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 不直接使用特征中的标签/答案进行学习</title>
      <link>https://stackoverflow.com/questions/78596157/lstm-not-learning-with-the-label-answer-literally-in-the-features</link>
      <description><![CDATA[在我的代码中，我将标签作为第一个时间步中的第一个特征，而 LSTM 无法获知答案在第一个时间步中，几乎就像它对此视而不见一样。
我运行此测试是因为在我的实际数据中，我的 LSTM 认为最后一个时间步中的一些变量在预测中并不重要，但同一数据上的梯度树发现了这种模式。
我的 LSTM 怎么了？它们看起来太差了。
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional

test_length = 0.15

test_length = 0.15

#features = np.random.rand(1000000, 20, 20)
features = np.zeros((100000, 40, 40))
labels = np.random.rand(100000)

features[:, 0, 0] = labels.copy()

features_train = features[0:int(len(features)*(1-test_length))]
labels_train = labels[0:int(len(labels)*(1-test_length))]
features_test = features[int(len(features)*(1-test_length)):]
labels_test = labels[int(len(labels)*(1-test_length)):]

model = Sequential([
LSTM(100, return_sequences=False),
Dropout(0.2),
Dense(50, 激活=&#39;relu&#39;),
Dropout(0.2),
Dense(30, 激活=&#39;relu&#39;),
Dropout(0.2),
Dense(1, 激活=&#39;linear&#39;)
])

model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

history = model.fit(
features_train, labels_train,
epochs=1,
batch_size=40,
validation_data=(features_test, labels_test),
verbose=1
)
]]></description>
      <guid>https://stackoverflow.com/questions/78596157/lstm-not-learning-with-the-label-answer-literally-in-the-features</guid>
      <pubDate>Sat, 08 Jun 2024 15:34:21 GMT</pubDate>
    </item>
    <item>
      <title>将 ML 数据集拆分为详细样本的缺陷</title>
      <link>https://stackoverflow.com/questions/77438417/pitfalls-of-splitting-the-ml-dataset-into-detailed-samples</link>
      <description><![CDATA[请问您能否说明将 ML 数据集拆分为详细样本可能存在的缺陷？
详细信息。
任务 - 机器学习二元分类（客户购买产品的概率）。
工具 - 梯度提升 (XGBoost)
特征数量 - 20
当前数据集（样本数量 - 100 000）



Unique_client_id
feature1
target




1
20
1


2
23
0



所需数据集（样本数量 - 1 000 000）



Unique_client_id
client_phone
feature1
target




1
1
32
1


1
2
22
0


2
1
23
0



因此，我将预测目标值不是针对客户端，而是针对手机号码。
一个客户可能有 1 个电话号码，另一个客户可能有 100 个电话号码。
拥有 100 个电话号码的客户将在数据集中占据 100 行。
某些属于客户（而不是电话，例如年龄）的特征在 100 行中重复出现。
拥有一个电话号码的客户将在数据集中占据一行。
目前，我看到唯一的缺陷：在电话号码特征中缺少信息的情况下，客户特征会将它们强制剔除。]]></description>
      <guid>https://stackoverflow.com/questions/77438417/pitfalls-of-splitting-the-ml-dataset-into-detailed-samples</guid>
      <pubDate>Tue, 07 Nov 2023 13:02:05 GMT</pubDate>
    </item>
    <item>
      <title>由于“tokenizer”不为“none”，因此不会使用参数“token_pattern”</title>
      <link>https://stackoverflow.com/questions/77149319/the-parameter-token-pattern-will-not-be-used-since-tokenizer-is-not-none</link>
      <description><![CDATA[我试图删除标点符号和空格（包括换行符）并过滤仅由字母组成的标记，然后返回标记文本。
我首先定义函数
 return [t.text for t in nlp(doc) if \
not t.is_punct and \
not t.is_space and \
t.is_alpha]

然后我进行矢量化
vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)
train_feature_vects = vectorizer.fit_transform(train_data)

终端卡住了，并说参数“token_pattern”不会被使用，因为“tokenizer”不是“none”。
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/77149319/the-parameter-token-pattern-will-not-be-used-since-tokenizer-is-not-none</guid>
      <pubDate>Thu, 21 Sep 2023 10:17:24 GMT</pubDate>
    </item>
    <item>
      <title>如何根据特征重要性进行特征选择循环，其中在 Python 中每次迭代中删除 imp = 0 或低于平均 imp 的特征？</title>
      <link>https://stackoverflow.com/questions/75271441/how-to-make-loop-with-features-selection-by-features-importance-where-deleted-fe</link>
      <description><![CDATA[我在 Python Pandas 中有如下 DataFrame：
输入数据：

Y - 二进制目标
X1...X5 - 预测变量

DataFrame 的源代码：
import pandas as pd
import numpy as np

from xgboost import XGBClassifier

df = pd.DataFrame()
df[&quot;Y&quot;] = [1,0,1,0]
df[&quot;X1&quot;] = [111,12,150,270]
df[&quot;X2&quot;] = [22,33,44,55]
df[&quot;X3&quot;] = [1,1,0,0]
df[&quot;X4&quot;] = [0,0,0,1]
df[&quot;X5&quot;] = [150, 222,230,500]

Y | X1 | X2 | X3 | X4 | X5 | ... | Xn
----|-----|-------|-------|-----|-----|-------
1 | 111 | 22 | 1 | 0 | 150 | ... | ...
0 | 12 | 33 | 1 | 0 | 222 | ... | ...
1 | 150 | 44 | 0 | 0 | 230 | ... | ...
0 | 270 | 55 | 0 | 1 | 500 | ... | ...

我通过在每次迭代中删除重要性 = 0 的特征来进行特征选择，或者如果没有重要性 = 0 的特征，我会在该迭代中删除重要性低于平均重要性的特征：
第一次迭代：
model_importance = XGBClassifier()
model_importance.fit(X = df.drop(labels=[&quot;Y&quot;], axis=1), y = df[&quot;Y&quot;])

importances = pd.DataFrame({&quot;Feature&quot;:df.drop(labels=[&quot;Y&quot;], axis=1).columns,
&quot;Importance&quot;:model_importance.feature_importances_})

importances_to_drop_1 = importants[importances[&quot;Importance&quot;]==0].index.tolist()

df.drop(columns = importants_to_drop_1, axis = 1, inplace = True)

第二次迭代：
model_importance_2 = XGBClassifier()
model_importance_2.fit(X = df.drop(labels=[&quot;Y&quot;], axis=1), y = df[&quot;Y&quot;])

importances_2 = pd.DataFrame({&quot;Feature&quot;:df.drop(labels=[&quot;Y&quot;], axis=1).columns,
&quot;Importance&quot;:model_importance_2.feature_importances_})

importances_to_drop_2 = importants_2[importances_2[&quot;Importance&quot;]&lt;importances_2.Importance.mean()].index.tolist()

df.drop(columns = importants_to_drop_2, axis = 1, inplace = True)

要求：

我需要创建一个循环，在每次迭代中，将删除重要性 = 0 的特征，或者如果没有重要性 = 0 的特征，则某些迭代将删除该迭代中重要性低于平均重要性的特征
最后，我需要至少有 150 个特征
我需要在一个循环（一段代码）中完成它，而不是像现在在几段代码中完成它

如何在 Python 中做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/75271441/how-to-make-loop-with-features-selection-by-features-importance-where-deleted-fe</guid>
      <pubDate>Sat, 28 Jan 2023 22:47:52 GMT</pubDate>
    </item>
    <item>
      <title>如何修改循环构建 ML 模型并生成 DataFrame 并在 Python 中的 for 循环每次迭代中删除列呈现的变量？</title>
      <link>https://stackoverflow.com/questions/75270910/how-to-modify-loop-builing-ml-models-and-generated-dataframe-with-column-present</link>
      <description><![CDATA[我有如下 Pandas DataFrame：
输入数据：

Y - 二元目标
X1...X5 - 预测器

DataFrame 的源代码：
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import roc_auc_score
from sklearn import metrics
from xgboost import XGBClassifier

df = pd.DataFrame()
df[&quot;Y&quot;] = [1,0,1,0]
df[&quot;X1&quot;] = [111,12,150,270]
df[&quot;X2&quot;] = [22,33,44,55]
df[&quot;X3&quot;] = [1,1,0,0]
df[&quot;X4&quot;] = [0,0,0,1]
df[&quot;X5&quot;] = [150, 222,230,500]

Y | X1 | X2 | X3 | X4 | X5
----|-----|-----|-------|-------|-----
1 | 111 | 22 | 1 | 0 | 150
0 | 12 | 33 | 1 | 0 | 222
1 | 150 | 44 | 0 | 0 | 230
0 | 270 | 55 | 0 | 1 | 500

我的代码： -&gt;我运行 XGBClassifier() 模型，在循环的每次连续迭代中都会删除一个变量，因此，每个连续模型的构建变量都比前一个少 1 个，迭代中的最后一个模型仅使用 1 个预测变量构建
X_train, X_test, y_train, y_test = train_test_split(df.drop(&quot;Y&quot;, axis=1)
, df.Y
, train_size = 0.70
, test_size=0.30
, random_state=1
, stratify = df.Y)

results = []
list_of_models = []
Num_var_in = []
predictors = X_train.columns.tolist()
Var_out = []

for i in X_train.columns:

#model building
model = XGBClassifier()
model.fit(X_train, y_train)
list_of_models.append(model)

#evaluation
results.append({&quot;AUC_train&quot;: round(metrics.roc_auc_score(y_train, model.predict_proba(X_train)[:,1]), 5),
&quot;AUC_test&quot;: round(metrics.roc_auc_score(y_test, model.predict_proba(X_test)[:,1]), 5),})

#Num_var_in - 在该迭代期间用于创建模型的预测变量数量
Num_var_in.append(len(X_train.columns.tolist()))

#Var_out - 在该迭代期间删除的变量的名称
if sorted(predictors) == sorted(X_train.columns.tolist()):
Var_out.append(np.nan)
else:
Var_out.append(set(predictors) - set(X_train.columns.tolist()))

#每次循环迭代后删除 1 个预测器
X_train = X_train.drop(i, axis=1)
X_test = X_test.drop(i, axis=1)

#将结果保存到 DataFrame
results = pd.DataFrame(results)
results[&quot;Num_var_in&quot;] = Num_var_in
results[&quot;Var_out&quot;] = Var_out
results.reset_index(inplace = True)
results.rename(columns = {&quot;index&quot;:&quot;Model&quot;}, inplace = True)
results

当前输出：

要求：

在输出中的“Var_out”列中，我需要有一个在给定迭代中被丢弃的变量，而不是迄今为止被丢弃的所有变量

期望输出：
模型 | AUC_train | AUC_test | Num_var_in | Var_out
------|------------|------------|-------------|---------
0 | 0.5 | 0.5 | 5 | NaN
1 | 0.5 | 0.5 | 4 | X1
2 | 0.5 | 0.5 | 3 | X2
3 | 0.5 | 0.5 | 2 | X3
4 | 0.5 | 0.5 | 1 | X4

我如何修改 Python 代码，以便像“期望输出”中那样在 Var_out 中输出？]]></description>
      <guid>https://stackoverflow.com/questions/75270910/how-to-modify-loop-builing-ml-models-and-generated-dataframe-with-column-present</guid>
      <pubDate>Sat, 28 Jan 2023 21:10:18 GMT</pubDate>
    </item>
    <item>
      <title>如何通过所有变量创建一些机器学习模型，并在每次迭代之后在 Python 中创建具有少 1 个变量的下一个 XGBClassifier？</title>
      <link>https://stackoverflow.com/questions/75262963/how-to-create-a-few-machine-learning-models-through-all-variables-and-after-each</link>
      <description><![CDATA[我在 Python Pandas 中有如下 DataFrame：
输入数据：

Y - 二进制目标

X1...X5 - 预测变量



Y
X1
X2
X3
X4
X5




1
111
22
1
0
150


0
12
33
1
0
222


1
150
44
0
0
230


0
270
55
0
1
500


...
...
...
...
...
...





要求：
并且我需要：

对所有变量进行循环，这样每次迭代后都会创建一个新的 XGBoost 分类模型，并且每次迭代后都会丢弃其中一个变量并创建下一个模型
因此，如果我有例如 5 个预测变量 (X1...X5)，我需要创建 5 个 XGBoost 分类模型，并且在每个连续模型中必须少 1 个变量
每个模型都应通过 roc_auc_score 进行评估
作为输出，我需要：list_of_models = []，其中将保存创建的模型和带有训练和测试 AUC 的 DataFrame

期望输出：
因此，我需要有如下所示的内容

模型 - 模型在list_of_models

Num_var - 模型中使用的预测变量数量

AUC_train - 训练数据集上的 roc_auc_score

AUC_test - 测试数据集上的 roc_auc_score



模型
Num_var
AUC_train
AUC_test




0
5
0.887
0.884


1
4
0.875
0.845
&lt; /tr&gt;

2
3
0.854
0.843


3
2
0.965
0.928


4
1
0.922
0.921





我的draft: 这是错误的，因为它应该循环遍历所有变量，这样每次迭代后都会创建一个新的 XGBoost 分类模型，并且每次迭代后都会丢弃其中一个变量并创建下一个模型
X_train, X_test, y_train, y_test = train_test_split(df.drop(&quot;Y&quot;, axis=1)
, df.Y
, train_size = 0.70
, test_size=0.30
, random_state=1
, stratify = df.Y)

results = []
list_of_models = []

for val in X_train:

model = XGBClassifier()
model.fit(X_train, y_train)
list_of_models.append(model)

preds_train = model.predict(X_train)
preds_test = model.predict(X_test)
preds_prob_train = model.predict_proba(X_train)[:,1]
preds_prob_test = model.predict_proba(X_test)[:,1]

results.append({(&quot;AUC_train&quot;:round(metrics.roc_auc_score(y_train,preds_prod_test),3),
&quot;AUC_test&quot;:round(metrics.roc_auc_score(y_test,preds_prod_test),3})

results = pd.DataFrame(results)

如何在 Python 中做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/75262963/how-to-create-a-few-machine-learning-models-through-all-variables-and-after-each</guid>
      <pubDate>Fri, 27 Jan 2023 20:18:43 GMT</pubDate>
    </item>
    <item>
      <title>如何修复将 KerasTensor 传递给 TF API 时出现的错误？</title>
      <link>https://stackoverflow.com/questions/71808327/how-to-fix-error-where-a-kerastensor-is-passed-to-a-tf-api</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/71808327/how-to-fix-error-where-a-kerastensor-is-passed-to-a-tf-api</guid>
      <pubDate>Sat, 09 Apr 2022 13:03:40 GMT</pubDate>
    </item>
    </channel>
</rss>