<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Jun 2024 09:17:29 GMT</lastBuildDate>
    <item>
      <title>在 Azure Databricks 中使用 pyspark ML 库函数时出现 Py4J 安全错误</title>
      <link>https://stackoverflow.com/questions/78585509/py4j-security-error-while-using-pyspark-ml-library-functions-in-azure-databricks</link>
      <description><![CDATA[我试图在我的 Azure Databricks 工作簿中运行以下代码
import pyspark.ml.feature
from pyspark.ml.feature import Tokenizer,StopWordsRemover
tokenizer = Tokenizer()

但是我遇到了这个错误：
Py4JError：调用 
None.org.apache.spark.ml.feature.Tokenizer 时发生错误。跟踪：
py4j.security.Py4JSecurityException：构造函数 public 
org.apache.spark.ml.feature.Tokenizer(java.lang.String) 未列入白名单。

StopWordsRemover 和 pyspark.ml.feature 中的其他一些函数也会出现类似的错误
有没有办法避免此错误，以便我可以使用相同的代码？]]></description>
      <guid>https://stackoverflow.com/questions/78585509/py4j-security-error-while-using-pyspark-ml-library-functions-in-azure-databricks</guid>
      <pubDate>Thu, 06 Jun 2024 08:56:01 GMT</pubDate>
    </item>
    <item>
      <title>Azure ML-如何从 Blob 容器注册模型？</title>
      <link>https://stackoverflow.com/questions/78584772/azure-ml-how-to-register-model-from-blob-container</link>
      <description><![CDATA[我有预定义的模型并存储在 blob 存储中。现在我想注册模型并部署它，并在 Azure ML 中启用端点。我使用了以下代码
from azureml.core import Model
from azureml.core import Workspace

subscription_id = &#39;mysub
resource_group = &#39;my_resource_group&#39;
workspace_name = &#39;my_ws_name&#39;

ws = Workspace(subscription_id, resource_group, working_name)

model_path = &#39;my_model.joblib&#39;

container = &#39;mycontainer&#39;

model_name = &#39;my_model_v1&#39;

model = Model.register(workspace=ws,
model_name=model_name,
model_path=model_path,
description=&quot;Test_Model&quot;,
tags={&#39;area&#39;: &quot;emotion detection&quot;},
model_framework=Model.Framework.SCIKITLEARN,
model_framework_version=&#39;0.24.1&#39;,
resource_configuration=None,
container_registry=None,
properties=None,
sample_input_dataset=None,
sample_output_dataset=None,
datasets=None,
model_url=f&#39;https://mystorage.blob.core.windows.net/{container}/{model_path}&#39;)
print(&quot;Ws object created&quot;)

但下面的代码返回错误
TypeError: register() 得到了一个意外的关键字参数 &#39;container_registry&#39;

有没有什么解决办法或者其他方法？]]></description>
      <guid>https://stackoverflow.com/questions/78584772/azure-ml-how-to-register-model-from-blob-container</guid>
      <pubDate>Thu, 06 Jun 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>使用前向验证时，时间序列数据的 LSTM 性能急剧下降</title>
      <link>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</guid>
      <pubDate>Thu, 06 Jun 2024 06:12:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么偏差的导数是对所有数据点求和而不是平均值</title>
      <link>https://stackoverflow.com/questions/78584207/why-is-derviative-of-bias-summed-across-all-data-points-dout-and-not-average</link>
      <description><![CDATA[我有一个基本的仿射层，即，我有 out=X@W+bias，其中 X@W 的形状为 (N,C)，b 的形状为 (C,)。如果我有损失的导数，wrt out 为 dout，形状为 (N.C)，为什么 db=dout 所有行的总和？为什么不是平均值之类的东西？]]></description>
      <guid>https://stackoverflow.com/questions/78584207/why-is-derviative-of-bias-summed-across-all-data-points-dout-and-not-average</guid>
      <pubDate>Thu, 06 Jun 2024 02:19:01 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 detector2 中语义分割的每个类的像素总数</title>
      <link>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</link>
      <description><![CDATA[我想计算每个分割类的总像素数，我只需要每个一般对象的计数，例如每辆车一个类，每个人一个类等等。出于这个原因，我使用语义分割而不是实例分割（实例分割会分别考虑每个车辆或人员实例）。但detectron2中语义分割的输出没有二进制掩码。
我知道实例分割的输出是二进制掩码，可以使用以下代码获取像素数：
masks = output[&#39;instances&#39;].pred_masks 
results = torch.sum(torch.flatten(masks, start_dim=1),dim=1)

这给出了像素数，但分别考虑了每个车辆实例，这是我不想要的。
但是语义分割的输出是字段“sem_seg”，其中包含每个一般类的预测类概率而不是二元掩码，我怎样才能继续获取语义分割中每个类的像素数？]]></description>
      <guid>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</guid>
      <pubDate>Wed, 05 Jun 2024 22:40:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 模型或其他实践在大型数据集中识别名字和姓氏的最佳实践是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</guid>
      <pubDate>Wed, 05 Jun 2024 20:00:15 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的残差</title>
      <link>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</link>
      <description><![CDATA[假设我们有一个线性模型，该模型适用于某些数据，其残差呈正态分布。我要问的问题是，我们能否在建模方面做得更好？有没有比这个线性模型更好的模型？
由于残差是 ND，因此没有模式可学习，因此线性模型是最好的。你对此有什么看法？
谢谢
我试图找到我的主张的严格证据，但找不到。]]></description>
      <guid>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</guid>
      <pubDate>Wed, 05 Jun 2024 15:14:26 GMT</pubDate>
    </item>
    <item>
      <title>将图像置于中心并在导出时添加背景</title>
      <link>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</link>
      <description><![CDATA[我想自动完成所有这些操作：

选择图像中的对象
在此对象上裁剪我的图像
裁剪为 1:1 的宽高比，在此对象周围留出一点空隙
以 800x800px 的 JPG 格式导出我的图像，我的对象位于图像中心，背景为白色。

我在 win11 64 位上
我做了什么：

安装 Python 并创建环境
安装opencv-python-headless、pillow、numpy、Pytorch以用于 CUDA 11.8
克隆存储库 segment-anything.git 并使用 PIP 安装它
下载sam_vit_b_01ec64.pth

像这样对 py 文件进行编码：
import os
import cv2
import numpy as np
from PIL import Image
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator

def load_image(image_path):
return cv2.imread(image_path)

def save_image(image, path):
cv2.imwrite(path + &#39;.jpg&#39;, image)

def select_object(image):
sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;sam_vit_b_01ec64.pth&quot;)
mask_generator = SamAutomaticMaskGenerator(sam)
mask = mask_generator.generate(image)
largest_mask = max(masks, key=lambda x: x[&#39;area&#39;])
返回 largest_mask[&#39;segmentation&#39;]

def crop_to_object(image, mask):
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
padding = 5
x = max(0, x - padding)
y = max(0, y - padding)
w = min(image.shape[1] - x, w + 2 * padding)
h = min(image.shape[0] - y, h + 2 * padding)

cropped_image = image[y:y+h, x:x+w]
返回 cropped_image

def resize_to_square(image, size=800):
h, w = image.shape[:2]
scale = size / max(h, w)
new_h, new_w = int(h * scale), int(w * scale)
resized_image = cv2.resize(image, (new_w, new_h), 插值=cv2.INTER_LANCZOS4)

new_image = np.ones((size, size, 3), dtype=np.uint8) * 255

top = (size - new_h) // 2
left = (size - new_w) // 2
bottom = top + new_h
right = left + new_w

new_image[top:top+new_h, left:left+new_w] = resized_image

return new_image

def process_image(image_path, output_path):

image = load_image(image_path)
mask = select_object(image)
cropped_image = crop_to_object(image, mask)
final_image = resize_to_square(cropped_image, 800)
save_image(final_image, output_path + &#39;.jpg&#39;)

def process_folder(input_folder, output_folder):

如果 os.path.exists(output_folder):
os.makedirs(output_folder)

对于 root, _, files in os.walk(input_folder):
对于 filename in files:
如果 filename.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;, &#39;.bmp&#39;, &#39;.tiff&#39;)):
input_path = os.path.join(root, filename)

relative_path = os.path.relpath(input_path, input_folder)
output_path = os.path.join(output_folder,relative_path)

output_dir = os.path.dirname(output_path)
如果 os.path.exists(output_dir):
os.makedirs(output_dir)

尝试:
process_image(input_path, output_path)
print(f&quot;已处理 {input_path}&quot;)
except Exception as e:
print(f&quot;无法处理 {input_path}：{e}&quot;)

if __name__ == &quot;__main__&quot;:
input_folder = &quot;&quot;
output_folder = &quot;&quot;
process_folder(input_folder, output_folder)

发生了什么：
我导入了基本图像，我想要预期结果，并且我获得了结果
我得到了一些不同的基本结果：

基本白色背景 -&gt; 结果
Base-nobg -&gt; &gt; 结果

有人能帮我理解我错过了什么吗？
提前谢谢，
Cyril]]></description>
      <guid>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</guid>
      <pubDate>Wed, 05 Jun 2024 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 logistf 包在 R 中计算 Firth 模型非收敛误差</title>
      <link>https://stackoverflow.com/questions/78579401/firths-model-non-converge-error-in-r-using-the-logistf-package</link>
      <description><![CDATA[这是示例数据的链接（示例数据不大 - 只有 23 kb，但可能是导致错误的原因）：

https://drive.google.com/file/d/1TWkFIKhq9VZkFnhUrt6LxYmab54ouODd/view?usp=sharing

这是我运行 firth 模型的代码。我在不同的运行中遇到了不同的错误（重新启动 r 或 r 会话），有时程序似乎卡住了（但是，活动监视器显示 CPU 使用率为 99%），其他时候我遇到了诸如不收敛之类的错误，并建议我增加迭代次数，但这并没有真正帮助。
library(caret)
library(logistf)
library(data.table)

# 定义训练控制
train_control &lt;- trainControl(method = &quot;repeatedcv&quot;, 
number = 3, repeats = 3,
savePredictions = TRUE,
classProbs = TRUE)

# 定义自定义模型函数
firth_model &lt;- list(
type = &quot;Classification&quot;,
library = &quot;logistf&quot;,
loop = NULL,
parameters = data.frame(parameter = c(&quot;none&quot;), class = c(&quot;character&quot;), label = c(&quot;none&quot;)),
grid = function(x, y, len = NULL, search = &quot;grid&quot;) {
data.frame(none = &quot;none&quot;)
},
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
data &lt;- as.data.frame(x)
data$group &lt;- y
logistf(group ~ ., data = data, control = logistf.control(maxit = 100), ...)
},
predict = function(modelFit, newdata, submodels = NULL) {
as.factor(ifelse(predict(modelFit, newdata, type = &quot;response&quot;) &gt; 0.5, &quot;AD&quot;, &quot;control&quot;))
},
prob = function(modelFit, newdata, submodels = NULL) {
preds &lt;- predict(modelFit, newdata, type = &quot;response&quot;)
data.frame(control = 1 - preds, AD = preds)
}
)

train_proc &lt;- fread(&quot;train_proc.csv&quot;)

# 训练模型
set.seed(123)
firth.logist.model &lt;- train(train_proc[, .SD, .SDcols = !c(&quot;group&quot;)],
train_proc$group,
method = firth_model,
trControl = train_control)

print(firth.logist.model)


这是最新的错误
logistf(group ~ ., data = data, control = logistf.control(maxit = 100), 中出现警告：
未收敛的 PL 置信限度：变量的最大迭代次数：（截距）、x1、x2、x3、x4、x5、x6、x7、x8、x9、x10、x11、x12、x13、x14、x15、x16、x17、x18、x19、x20、x21、x22、x23、x24 超出。尝试通过将“logistpl.control(maxit=...)”传递给参数 plcontrol 来增加迭代次数

相同的代码似乎在某些数据集上运行，但在其他数据集上运行不起来。但这也可能是由于我的函数无法针对特定数据集进行自定义。我遇到了许多不同类型的错误，我开始怀疑 logistf 包本身是否不稳定。
为了提供更多信息，这是我的 r 版本：
R.version
_ 
platform aarch64-apple-darwin20 
arch aarch64 
os darwin20 
system aarch64, darwin20 
status 
major 4 
minor 3.2 
year 2023 
month 10 
day 31 
svn rev 85441 
language R 
version.string R version 4.3.2 (2023-10-31)
nickname Eye Holes 

这是我的包版本：
&gt; packageVersion(&quot;caret&quot;)
[1] ‘6.0.94’
&gt; packageVersion(&quot;logistf&quot;)
[1] ‘1.26.0’
&gt; packageVersion(&quot;data.table&quot;)
[1] ‘1.14.10’
]]></description>
      <guid>https://stackoverflow.com/questions/78579401/firths-model-non-converge-error-in-r-using-the-logistf-package</guid>
      <pubDate>Wed, 05 Jun 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>Julia MLJ Forest Load：错误：MethodError：没有与 BetaML.Bmlj.RandomForestRegressor() 匹配的方法</title>
      <link>https://stackoverflow.com/questions/78577415/julia-mlj-forest-loaderror-methoderror-no-method-matching-betaml-bmlj-randomf</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78577415/julia-mlj-forest-loaderror-methoderror-no-method-matching-betaml-bmlj-randomf</guid>
      <pubDate>Tue, 04 Jun 2024 19:40:11 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 处理作业权限被拒绝保存 /opt/ml/processing/<folder> 下的 csv 文件</title>
      <link>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</link>
      <description><![CDATA[我正在开展一个涉及 Step Functions 和 SageMaker 的项目。我有一个现有的 Step Function，需要将 SageMaker 集成到其中，我尝试添加处理、模型训练、注册模型和批量转换作业请求等步骤。我还在每个资源的末尾添加了 .sync，以便它等待一个资源完成后再开始下一个资源。
但是，我在 Step Function 的 SageMaker 处理作业中遇到了问题。处理作业运行但未完成，因为权限被拒绝从我处理的 pandas 数据框保存 CSV 文件。
# 依赖项导入
df = pd.read_csv(&quot;/opt/ml/processing/input/data/data.csv&quot;)
print(df.head())

# 对 df 进行一些处理

df.to_csv(&quot;/opt/ml/processing/output/result.csv&quot;, index=False)

以下是处理请求的状态机配置：
如果您需要查看我的配置的其他部分，请给我留言
{
&quot;AppSpecification&quot;: {
&quot;ContainerEntryPoint&quot;: [
&quot;python3&quot;,
&quot;/opt/ml/processing/input/code/processing.py&quot;
]
},
&quot;ProcessingInputs&quot;: [
{
&quot;InputName&quot;: &quot;Input-1&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/data&quot;
}
},
{
&quot;InputName&quot;: &quot;Input-2&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/processing.py&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/code&quot;
}
}
],
&quot;ProcessingOutputConfig&quot;: {
&quot;Outputs&quot;: [
{
&quot;OutputName&quot;: &quot;Output-1&quot;,
&quot;S3Output&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/output/&quot;,
&quot;S3U​​ploadMode&quot;: &quot;EndOfJob&quot;
}
}
]
}
}

ProcessingInputs 配置按预期工作。我在日志中看到 df.head() 将 data.csv 内容正确打印在日志中。但是，当它到达最后一行代码时，我收到以下错误：
PermissionError: Permission Denied &#39;/opt/ml/processing/output/result.csv&#39;
我还尝试将其保存到其他文件夹，如我在网上找到的一些示例中所见，例如保存到 training、result 等文件夹，但到目前为止还没有成功。它给了我同样的权限错误。我使用了为此专门创建的 Lambda 函数，并向 SageMaker 处理作业发出请求，并得到了完全相同的权限被拒绝错误。
我还尝试将文件保存到 /opt/ml/processing/ 之外的完全不同的文件夹中，但 /result.csv
但它给了我不同的错误，因为 SageMaker 只允许我们将 csv 文件保存在 /opt/ml/processing/ 下......所以我不知道该怎么做。
目前，我正在使用 boto3 api 手动保存结果集，并等待处理作业通过我设置的 StoppingCondition.MaxRuntimeInSeconds 时间，最终它停止，我使用附加步骤来获取它。
但我不喜欢我解决问题的方式，我真的需要找到更好的方法来解决这个问题。
有人能告诉我我遗漏了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</guid>
      <pubDate>Wed, 29 May 2024 19:34:23 GMT</pubDate>
    </item>
    <item>
      <title>微调模型时内存不足</title>
      <link>https://stackoverflow.com/questions/78542429/running-out-of-ram-when-finetuning-model</link>
      <description><![CDATA[我目前正在尝试微调 Wav2Vec2 模型：https://huggingface.co/dima806/bird_sounds_classification。但是我的 RAM 使用率超过了 Google Colab 的免费套餐。
以下是我的代码：
from transformers import TrainingArguments, Trainer

# 使用 ignore_mismatched_sizes=True 加载模型
model = Wav2Vec2ForSequenceClassification.from_pretrained(
&quot;dima806/bird_sounds_classification&quot;,
num_labels=len(label2id),
ignore_mismatched_sizes=True
)

# 使用梯度累积设置训练
batch_size = 1 # 减少批次大小以管理内存
accumulation_steps = 4 # 在 4 个步骤中累积梯度

training_args = TrainingArguments(
output_dir=&quot;./results&quot;,
evaluation_strategy=&quot;epoch&quot;,
learning_rate=2e-5,
per_device_train_batch_size=batch_size,
per_device_eval_batch_size=batch_size,
gradient_accumulation_steps=accumulation_steps, # 梯度累积
num_train_epochs=3,
weight_decay=0.01,
fp16=True, # 启用混合精度训练
)

trainer = Trainer(
model=model,
args=training_args,
train_dataset=train_dataset,
eval_dataset=val_dataset,
tokenizer=feature_extractor,
)

# 训练模型
trainer.train()

RAM 超过 12.7GB 的原因可能是什么？我的数据集只包含 20 个项目。我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78542429/running-out-of-ram-when-finetuning-model</guid>
      <pubDate>Tue, 28 May 2024 07:10:21 GMT</pubDate>
    </item>
    <item>
      <title>错误 conda.core.link:_execute(698): 安装包“defaults::icu-58.2-ha925a31_3”时发生错误</title>
      <link>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</link>
      <description><![CDATA[我使用 anaconda prompt conda create -n talkingbot python=3.5 创建了环境，然后安装了 pip install tensorflow==1.0.0（遵循与 udemy 课程中使用的相同命令），但是当我尝试使用 conda install spyder 安装 spyder 时，它给了我这个错误：
准备交易：完成
验证交易：完成
执行交易：完成
错误 conda.core.link:_execute(698)：安装包“defaults::icu-58.2-ha925a31_3”时发生错误。
回滚事务：完成

[Errno 13] 权限被拒绝：&#39;C:\\Users\\Lenovo\\anaconda3\\envs\\talkingbot\\Library\\bin\\icudt58.dll&#39;
()

然后我尝试使用 anaconda navigator 安装 spyder，但 spyder 也未安装。
帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</guid>
      <pubDate>Sun, 13 Sep 2020 13:42:24 GMT</pubDate>
    </item>
    <item>
      <title>什么时候 dropout 对分割任务有用？</title>
      <link>https://stackoverflow.com/questions/44160030/when-dropout-is-useful-for-segmentation-task</link>
      <description><![CDATA[我正在从事分割任务。我的数据集很少。我的网络非常深（基于 Resnet）。我的问题是，dropout 在我的领域什么时候有用？我知道 dropout 通常用于处理过拟合问题。但对于分割，我没有看到很多使用 dropout 的论文。谢谢]]></description>
      <guid>https://stackoverflow.com/questions/44160030/when-dropout-is-useful-for-segmentation-task</guid>
      <pubDate>Wed, 24 May 2017 13:37:00 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn：如何获得真阳性、真阴性、假阳性和假阴性</title>
      <link>https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal</link>
      <description><![CDATA[我的问题：
我有一个数据集，它是一个大型 JSON 文件。我读取它并将其存储在 trainList 变量中。
接下来，我对其进行预处理 - 以便能够使用它。
完成后，我开始分类：

我使用 kfold 交叉验证方法来获得平均准确率并训练分类器。
我进行预测并获得该折叠的准确率和混淆矩阵。
在此之后，我想获得 真阳性 (TP)、真阴性 (TN)、假阳性 (FP) 和 假阴性 (FN) 值。我将使用这些参数来获得敏感性和特异性。 

最后，我将使用它将其放入 HTML 中，以便显示包含每个标签的 TP 的图表。
代码：
我目前拥有的变量：
trainList #这是一个包含我数据集的所有数据的 JSON 格式列表
labelList #这是一个包含我数据的所有标签的列表

该方法的大部分内容：
#我将数据从 JSON 格式转换为数字格式
X=vec.fit_transform(trainList)

#我缩放矩阵（不知道为什么，但没有它，就会出错）
X=preprocessing.scale(X.toarray())

#我生成一个 KFold 以进行交叉验证
kf = KFold(len(X), n_folds=10, indices=True, shuffle=True, random_state=1)

#我开始对 kf 中的 train_indices、test_indices 进行交叉验证

X_train=[X[ii] for ii in train_indices]
X_test=[X[ii] for ii in test_indices]
y_train=[listaLabels[ii] for ii in train_indices]
y_test=[listaLabels[ii] for ii in test_indices]

#我训练分类器
trained=qda.fit(X_train,y_train)

#我进行预测
predicted=qda.predict(X_test)

#我获得此折叠的准确率
ac=accuracy_score(predicted,y_test)

#我获得混淆矩阵
cm=confusion_matrix(y_test, predicted)

#我应该计算 TP、TN、FP 和 FN
#我不知道如何继续
]]></description>
      <guid>https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal</guid>
      <pubDate>Thu, 09 Jul 2015 17:19:02 GMT</pubDate>
    </item>
    </channel>
</rss>