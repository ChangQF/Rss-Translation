<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 05 Jan 2025 06:22:31 GMT</lastBuildDate>
    <item>
      <title>加载已保存的模型（catboost）后始终具有相同的预测值</title>
      <link>https://stackoverflow.com/questions/79330154/always-the-same-prediction-value-after-loading-saved-modelcatboost</link>
      <description><![CDATA[scaler = MinMaxScaler()
X_scaled= scaler.fit_transform(X_resampled)
#设置测试和训练的初始值
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_resampled,
test_size=0.30,
random_state=42)
cat_model = CatBoostClassifier().fit(X_train, y_train)
# 测试结果为 yapma
y_pred = cat_model.predict(X_test)
while True:
................

kullanici_veri = pd.DataFrame({
................

})

break

# 保存部分
file_path = &quot;cat_model.cbm&quot;
cat_model.save_model(file_path)

# 加载部分
loaded_model = CatBoostClassifier()
loaded_model.load_model(file_path)

# 预测部分
glycemic_control_prediction = loaded_model.predict(scaled_data)
print(f&quot;Glycemic Control Tahmini: {glycemic_control_prediction[0]}&quot;)

加载保存的模型后，预测值始终相同
我尝试了其他保存/加载方法，但没有奏效
我尝试了 Joblib、Pickle，检查了过度拟合、数据泄漏等所有问题
有什么办法可以解决这个问题？我遗漏了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/79330154/always-the-same-prediction-value-after-loading-saved-modelcatboost</guid>
      <pubDate>Sun, 05 Jan 2025 04:03:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Ridge Regression 在视觉追踪一个物体时会表现得像这样？</title>
      <link>https://stackoverflow.com/questions/79330150/why-does-ridge-regression-behave-like-this-when-visually-tracking-an-object</link>
      <description><![CDATA[我正在尝试实现没有边界效应的 KCF 跟踪器像这里。简而言之，它是一个没有使用任何傅里叶变换的核化相关滤波器。我正在像这样计算过滤器权重 alpha：
Idm = np.identity(Kxx.shape[1])
A = Kxx.T @ Kxx
B = Kxx.T @ y
alpha = np.linalg.solve(A + 2e-4*Idm, B)

Kxx 是当前帧上训练区域的自相关矩阵，y 是我使用得到的高斯标签矩阵
g1 = cv2.getGaussianKernel(Kxx.shape[0], 1.5)
g2 = cv2.getGaussianKernel(Kxx.shape[1], 1.5)
y = g1 @ g2.T

我预测下一帧中物体的新位置使用response = Kxz@alpha
其中 Kxz 是训练区域和目标对象块的相关矩阵。
当我垂直移动训练区域时，响应图的行为如下：
垂直移动训练区域
但是，当我水平移动训练区域时，目标对象的移动不会显示在响应图上：
水平移动训练区域
实际上，我可以使用 response = alpha@Kxz.T 获得仅表示水平移动的响应图。但由于矩阵形状不同，这不适用于该文章中提到的相关方法。我认为这不是计算相关矩阵的问题，因为我已经尝试了几种相关方法，例如 cv2.filter2D 和文章中的方法。]]></description>
      <guid>https://stackoverflow.com/questions/79330150/why-does-ridge-regression-behave-like-this-when-visually-tracking-an-object</guid>
      <pubDate>Sun, 05 Jan 2025 04:01:38 GMT</pubDate>
    </item>
    <item>
      <title>如何从物理信息神经网络 (PINN) 获取具有初始和边界条件的 PDE 的单一解？</title>
      <link>https://stackoverflow.com/questions/79329941/how-to-get-a-single-solution-from-a-physics-informed-neural-network-pinn-for-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79329941/how-to-get-a-single-solution-from-a-physics-informed-neural-network-pinn-for-a</guid>
      <pubDate>Sun, 05 Jan 2025 01:01:10 GMT</pubDate>
    </item>
    <item>
      <title>无法从‘transformers’导入名称‘T2TViTModel’</title>
      <link>https://stackoverflow.com/questions/79329851/cannot-import-name-t2tvitmodel-from-transformers</link>
      <description><![CDATA[我尝试训练我的模型并从 Python 脚本中的 transformers 库导入 T2TViTModel，但遇到了以下错误：

回溯（最近一次调用）：
文件“/Users/mac/PycharmProjects/Heart-rate Model/training.py”，第 8 行，来自 transformers 导入 T2TViTModel
ImportError：无法从“transformers”（/Users/mac/PycharmProjects/pythonProject/.venv/lib/python3.12/site-packages/transformers/init.py）导入名称“T2TViTModel”。

我已确保 transformers 库已安装并更新为最新版本。但是，我在库中找不到 T2TViTModel。
有人能帮助我理解为什么导入失败以及如何解决这个问题吗？
我使用 PyTorch 和 transformers 库中的 T2T-ViT 模型实现了心率估计模型。我的代码的主要组件包括：

数据加载：自定义 HeartRateDataset 类，用于从 CSV 文件加载图像和心率标签。
模型定义：HeartRateEstimator 模型，包含 T2T-ViT 并添加回归头用于心率预测。
训练循环：用于跨多个时期训练模型、计算损失并针对单独数据集进行验证的函数。
评估：用于在测试数据集上评估训练后的模型并计算性能指标的功能。

我希望代码能够顺利运行，成功训练模型，并观察到训练和验证损失在各个时期的减少，最终从测试集评估中获得 MAE、RMSE 和 R² 等指标。]]></description>
      <guid>https://stackoverflow.com/questions/79329851/cannot-import-name-t2tvitmodel-from-transformers</guid>
      <pubDate>Sun, 05 Jan 2025 01:01:10 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“llama_index.text_splitter”的模块</title>
      <link>https://stackoverflow.com/questions/79329352/modulenotfounderror-no-module-named-llama-index-text-splitter</link>
      <description><![CDATA[我用这个来导入
从 llama_index.text_splitter 导入 SentenceSplitter

我的 python 版本 - 3.11.5 和 llama_index 版本 - 0.12.8 但出现此错误
ModuleNotFoundError：没有名为“llama_index.text_splitter”的模块

如何解决这个问题？
我询问 chatgpt，谷歌其他 AI 但找不到解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/79329352/modulenotfounderror-no-module-named-llama-index-text-splitter</guid>
      <pubDate>Sat, 04 Jan 2025 18:08:25 GMT</pubDate>
    </item>
    <item>
      <title>如何将 pixelClassificationLayer() 更新为自定义损失函数？</title>
      <link>https://stackoverflow.com/questions/79328556/how-do-i-update-pixelclassificationlayer-to-a-custom-loss-function</link>
      <description><![CDATA[我在 Mathworks 官方网站上看到 pixelClassificationLayer() 函数，我应该使用以下代码将其更新为自定义损失函数：
function loss = modelLoss(Y,T) 
mask = ~isnan(T);
target(isnan(T)) = 0;
loss = crossentropy(Y,T,Mask=mask,NormalizationFactor=&quot;mask-included&quot;); 
end

netTrained = trainnet(images,net,@modelLoss,options); 

但是，我看不到任何关于输入“Classes”或“ClassWeights”的提及，我目前正使用它们来定义自定义 pixelClassificationLayer：
pixelClassificationLayer(&#39;Classes&#39;,classNames,&#39;ClassWeights&#39;,classWeights)，其中 classNames 是一个向量，以字符串形式包含每个类的名称，classWeights 是一个向量，包含每个类的权重，用于在训练数据中存在代表性不足的类时平衡类。
如何在自定义损失函数中包含这些参数？]]></description>
      <guid>https://stackoverflow.com/questions/79328556/how-do-i-update-pixelclassificationlayer-to-a-custom-loss-function</guid>
      <pubDate>Sat, 04 Jan 2025 09:05:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么在将 ART 的 KerasClassifier 与 TensorFlow 2.x 结合使用时会收到 AttributeError：模块“tensorflow.keras.backend”没有属性“placeholder”？</title>
      <link>https://stackoverflow.com/questions/79328497/why-do-i-get-attributeerror-module-tensorflow-keras-backend-has-no-attribute</link>
      <description><![CDATA[我尝试在 TensorFlow 2.x 中将 Adversarial Robustness Toolbox (ART) 与简单的 Keras 模型结合使用，但遇到了以下错误：
AttributeError：模块“tensorflow.keras.backend”没有属性“placeholder”
我的代码如下所示：
import tensorflow as tf
print(tf.__version__)

import numpy as np
from art.estimators.classification import KerasClassifier
from art.attacks.evasion import FastGradientMethod
from art.utils import load_mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam

# 加载 MNIST 数据集
(x_train, y_train), (x_test, y_test), min_, max_ = load_mnist()
x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype(&#39;float32&#39;) / 255.0
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype(&#39;float32&#39;) / 255.0

# 创建 keras 模型
model = Sequential([
Flatten(input_shape=(28, 28, 1)),
Dense(128,activation=&#39;relu&#39;),
Dense(10,activation=&#39;softmax&#39;)
])
model.compile(optimizer=Adam(), loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 训练模型
model.fit(x_train, y_train, epochs=3, batch_size=128, verbose=1)

tf.compat.v1.disable_eager_execution()
# 将 keras 模型编译成 ART 分类器
classifier = KerasClassifier(model=model, clip_values=(0, 1), use_logits=False)

# 配置 FGSM-attack
attack = FastGradientMethod(estimator=classifier, eps=0.2)

# 创建对抗样本
x_test_adv = attack.generate(x=x_test)

# 使用对抗样本评估模型
predictions = np.argmax(classifier.predict(x_test_adv), axis=1)
accuracy = np.sum(predictions == np.argmax(y_test, axis=1)) / len(y_test)
print(f&quot;Genauigkeit错误原因：{accuracy * 100:.2f}%&quot;)

# 可视化
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
for i in range(5):
plt.subplot(2, 5, i + 1)
plt.imshow(x_test[i].reshape(28, 28), cmap=&quot;gray&quot;)
plt.title(&quot;Original&quot;)
plt.axis(&quot;off&quot;)

plt.subplot(2, 5, i + 6)
plt.imshow(x_test_adv[i].reshape(28, 28), cmap=&quot;gray&quot;)
plt.title(&quot;Adversarial&quot;)
plt.axis(&quot;off&quot;)
plt.tight_layout()
plt.show()

初始化 KerasClassifier 时，ART 库中会出现此错误。我安装了 TensorFlow 2.x，并且正在使用最新版本的 Adversarial Robustness Toolbox (ART)。
我尝试过的方法：

使用 tf.compat.v1.disable_eager_execution() 禁用 Eager Execution，但无法解决问题。
检查 ART 或 TensorFlow 是否有任何更新，但所有内容都是最新的。

有人能建议为什么会出现此错误以及如何在 TensorFlow 2.x 中解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/79328497/why-do-i-get-attributeerror-module-tensorflow-keras-backend-has-no-attribute</guid>
      <pubDate>Sat, 04 Jan 2025 08:46:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 训练 DNN 时 NaN 损失输出</title>
      <link>https://stackoverflow.com/questions/79328433/nan-loss-output-when-training-dnn-with-keras</link>
      <description><![CDATA[我正在尝试做 Aurelien Geron 的 Hands-On ML 中的一项练习。但是，当我尝试使用自己的解决方案并从答案中复制和粘贴解决方案时，我总是得到这个不应该发生的结果。每个时期的损失和 val_loss 都是 nan，准确率根本没有提高。本练习尝试在 CIFAR10 数据集上构建一个具有 20 个隐藏层的 DNN。
代码如下：
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()
X_val, y_val = X_train[:5000], y_train[:5000]
X_train, y_train = X_train[5000:], y_train[5000:]
tf.random.set_seed(42)

model = tf.keras.Sequential()
model.add(tf.keras.layers.Input(shape=[32,32,3]))
model.add(tf.keras.layers.Flatten())

## 20 个隐藏层 
for _ in range(20):
model.add(tf.keras.layers.Dense(100,activation=&#39;swish&#39;, 
kernel_initializer=&#39;he_normal&#39;))

# 输出层
model.add(tf.keras.layers.Dense(10,activation=&#39;softmax&#39;))

optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-6)
model.compile(optimizer=opimizer,
loss=&#39;sparse_categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])
import datetime

early_stopping = tf.keras.callbacks.EarlyStopping(patience=20, 
restore_best_weights=True)

log_dir = &quot;logs/my_cifar10_model/&quot; + datetime.datetime.now().strftime(&quot;%Y%m%d- 
%H%M%S&quot;)
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)

model.fit(X_train, y_train, epochs=100, callbacks=[early_stopping, 
tensorboard_callback],
validation_data=(X_val, y_val))

输出如下：
Epoch 1/100
1407/1407 ━━━━━━━━━━━━━━━━━━━━━━━ 8s 3ms/step - 准确率： 0.1005 - 损失：nan - 
val_accuracy：0.0996 - val_loss：nan
Epoch 2/100
1407/1407 ━━━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step - 准确度：0.1007 - 损失：nan - 
val_accuracy：0.0996 - val_loss：nan
Epoch 3/100
1407/1407 ━━━━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step - 准确度：0.1007 - 损失：nan - 
val_accuracy：0.0996 - val_loss：nan

...
Epoch 20/100
1407/1407 ━━━━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step - 准确度：0.1007 - 损失：nan - 
val_accuracy：0.0996 - val_loss：nan
Epoch 21/100
1407/1407 ━━━━━━━━━━━━━━━━━━━━━ 5s 3ms/step - 准确率：0.1007 - 损失：nan - 
val_accuracy：0.0996 - val_loss：nan
&lt;keras.src.callbacks.history.History at 0x7801cde19fa0&gt;

TF 或 python 实际上没有引发任何错误。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79328433/nan-loss-output-when-training-dnn-with-keras</guid>
      <pubDate>Sat, 04 Jan 2025 07:45:22 GMT</pubDate>
    </item>
    <item>
      <title>如何检查随机森林模型是否过度拟合？</title>
      <link>https://stackoverflow.com/questions/79327542/how-to-check-if-the-model-is-overfitting-for-random-forest</link>
      <description><![CDATA[我已经为数据集实现了随机森林，并且平衡了数据，我使用了 80-10-10、70-15-15、60-20-20 和 80-20 方法。我还使用了特征重要性，并在 41 个独立特征中使用了 10 个 imp 特征、15 个 imp 特征、24 个 imp 特征和 34 个 imp 特征。所有上述方法的平均召回率为 95.8%，平均准确率为 96.6%，精确率为 97%。交叉验证召回率（我主要关注召回率）为 95.5%。
我使用训练数据对训练数据本身进行预测，得到了 99.8%
我还使用了热图并删除了 3 个高度相关的特征，但我得到了 80-10-10 的相同分数（热图之后）。
我的模型是否过度拟合？如何检查是否过度拟合？]]></description>
      <guid>https://stackoverflow.com/questions/79327542/how-to-check-if-the-model-is-overfitting-for-random-forest</guid>
      <pubDate>Fri, 03 Jan 2025 19:56:33 GMT</pubDate>
    </item>
    <item>
      <title>如何修复具有可变时间维度的 3D U-Net 中的跳过连接维度不匹配问题？[关闭]</title>
      <link>https://stackoverflow.com/questions/79326988/how-to-fix-skip-connection-dimension-mismatch-in-3d-u-net-with-variable-temporal</link>
      <description><![CDATA[我正在开发一个用于 3D 数据的 U-Net 模型，其中输入有三个维度：（高度、宽度、时间）。第三个维度 时间 是可变的，这给编码器和解码器之间的跳过连接带来了挑战。
出现此问题的原因是编码器和解码器特征图在某些层中的时间维度不匹配。例如：

编码器输出形状：tf.Tensor(shape=(1, 32, 32, 16, 256), dtype=float32)
解码器输出形状：tf.Tensor(shape=(1, 32, 32, 15, 256), dtype=float32)

时间维度（16 vs. 15）不匹配，导致连接期间出现维度不匹配错误。
可能的解决方案：

裁剪编码器特征图：减少编码器特征图的时间维度以与解码器对齐。
填充解码器特征图：向解码器特征图的时间维度添加填充以匹配编码器。

是否有一种首选方法（裁剪与填充）来解决这种不匹配问题，特别是在语义分割中？是否有任何其他最佳实践来处理 3D U-Net 中的可变时间维度？]]></description>
      <guid>https://stackoverflow.com/questions/79326988/how-to-fix-skip-connection-dimension-mismatch-in-3d-u-net-with-variable-temporal</guid>
      <pubDate>Fri, 03 Jan 2025 15:53:08 GMT</pubDate>
    </item>
    <item>
      <title>虚拟变量为布尔值而不是整数[关闭]</title>
      <link>https://stackoverflow.com/questions/79325633/dummy-variable-as-boolean-rather-than-integer</link>
      <description><![CDATA[我正在用 Python 开发一个机器学习项目。使用 pandas pd.get_dummies，我尝试为数据中的分类列创建虚拟变量，但变量被转换为布尔值而不是整数，这使得 statsmodels 无法拟合 OLS 模型。我尝试将布尔值转换为整数，但一直出现错误。我该如何解决这个问题？？
我使用了 .astype(int) 方法，我也尝试使用 numpy 转换为整数。
ocean_proximity_dummies = pd.get_dummies(data[&#39;ocean_proximity&#39;], prefix= &#39;ocean_proximity&#39;)

data = pd.concat([data.drop(&quot;ocean_proximity&quot;, axis =1), ocean_proximity_dummies], axis=1)

ocean_proximity_dummies = ocean_proximity_dummies.astype(int)
ocean_proximity_dummies
]]></description>
      <guid>https://stackoverflow.com/questions/79325633/dummy-variable-as-boolean-rather-than-integer</guid>
      <pubDate>Fri, 03 Jan 2025 06:15:51 GMT</pubDate>
    </item>
    <item>
      <title>训练最小 U-Net 时的方法错误</title>
      <link>https://stackoverflow.com/questions/79316648/methoderror-in-training-minimal-u-net</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79316648/methoderror-in-training-minimal-u-net</guid>
      <pubDate>Mon, 30 Dec 2024 01:52:08 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.neighbors._base”导入名称“_check_weights”</title>
      <link>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</link>
      <description><![CDATA[我正在尝试使用 Missforest 作为处理表数据中缺失值的方法。
import sklearn
print(sklearn.__version__)
-&gt;1.2.1

import sklearn.neighbors._base
import sys
sys.modules[&#39;sklearn.neighbors.base&#39;] = sklearn.neighbors._base

!pip install missingpy
from missingpy import MissForest

到目前为止，它运行良好，但从昨天开始，出现了以下错误消息。
ImportError：无法从“sklearn.neighbors._base”导入名称“_check_weights”

我想知道如何处理这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</guid>
      <pubDate>Sat, 04 Mar 2023 01:48:43 GMT</pubDate>
    </item>
    <item>
      <title>对批量数据进行在线方差更新的有效算法[关闭]</title>
      <link>https://stackoverflow.com/questions/75545944/efficient-algorithm-for-online-variance-update-over-batched-data</link>
      <description><![CDATA[我有大量多维数据，想计算所有数据中某个轴的方差。从内存角度来看，我无法创建一个大型数组来一步计算方差。因此，我需要分批加载数据，并需要在每个批次之后以在线方式更新当前方差。
示例
最后，按批次更新的 online_var 应该与 correct_var 匹配。
但是，我很难找到一种有效的算法。
import numpy as np
np.random.seed(0)
# 正确计算方差
all_data = np.random.randint(0, 9, (9, 3)) # &lt;-- 不适合内存
correct_var = all_data.var(axis=0)
# 创建批次
batches = all_data.reshape(-1, 3, 3)

online_var = 0
for batch in batches:
batch_var = batch.var(axis=0)
online_var = ? # 如何正确更新
assert np.allclose(correct_var, online_var)


我找到了Welford 在线算法，但是它非常慢，因为它只更新单个新值的方差，即它不能一次处理整个批次。当我处理图像时，每个像素和每个通道都需要更新。

如何以有效的方式更新多个新观测值的方差，同时考虑整个批次？]]></description>
      <guid>https://stackoverflow.com/questions/75545944/efficient-algorithm-for-online-variance-update-over-batched-data</guid>
      <pubDate>Thu, 23 Feb 2023 14:10:26 GMT</pubDate>
    </item>
    <item>
      <title>如何根据信用记录计算信用评分[关闭]</title>
      <link>https://stackoverflow.com/questions/37712731/how-to-calculate-credit-score-on-the-basis-of-credit-history</link>
      <description><![CDATA[我有一个特定人群的信用历史数据集，我需要计算每个人的信用评分。
我计划根据信用历史变量计算概率，然后尝试将该概率转换为分数。这种方法会起作用吗？或者我应该遵循什么技术或方法？]]></description>
      <guid>https://stackoverflow.com/questions/37712731/how-to-calculate-credit-score-on-the-basis-of-credit-history</guid>
      <pubDate>Wed, 08 Jun 2016 20:54:30 GMT</pubDate>
    </item>
    </channel>
</rss>