<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 30 Apr 2024 03:15:14 GMT</lastBuildDate>
    <item>
      <title>神经网络可以有损失函数吗？</title>
      <link>https://stackoverflow.com/questions/78405886/neural-network-can-have-loss-functions</link>
      <description><![CDATA[我自学了神经网络，因为我认为它可以解决我的问题。一般来说，我对机器学习或人工智能一无所知。
我的问题很复杂，但可以很容易地转化为：我需要两个输出，其中一个是坏的，一个是无用的，一个是好的。
示例：一款真人快打风格的游戏，我需要选择：我是否应该攻击，如果我攻击了，我是赢了还是输了。所以：

output_1：我应该攻击吗（布尔值：是/否）
output_2：如果我攻击，我造成或受到伤害（bool：造成/受到伤害）

很明显，在这种情况下，如果我一直选择不攻击，那是没有用的，所以我不能选择理想的输出。
所以我需要攻击，但前提是我的输入告诉我这是一个好主意（例如：距离合适并且对手没有攻击）。
有没有办法只用神经网络来做到这一点？我错过了什么吗？
我问“那个”著名的人工智能引擎如何做到这一点，它告诉我在神经网络中使用损失函数，但我找不到神经网络中损失函数的任何示例，只能在机器学习中找到。
那么如果我想解决这个问题，我是否需要从 NN 更改为任何其他 ML 算法？请问是哪一个？]]></description>
      <guid>https://stackoverflow.com/questions/78405886/neural-network-can-have-loss-functions</guid>
      <pubDate>Tue, 30 Apr 2024 01:52:36 GMT</pubDate>
    </item>
    <item>
      <title>RFE 与 GBM 集成，用于特征选择和超参数调整</title>
      <link>https://stackoverflow.com/questions/78405164/integration-of-rfe-with-gbm-for-feature-selection-and-hyperparameter-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78405164/integration-of-rfe-with-gbm-for-feature-selection-and-hyperparameter-tuning</guid>
      <pubDate>Mon, 29 Apr 2024 21:00:14 GMT</pubDate>
    </item>
    <item>
      <title>如何提高汽车价格估算中的 RMSE？</title>
      <link>https://stackoverflow.com/questions/78405026/how-can-i-improve-the-rmse-in-my-car-price-estimate</link>
      <description><![CDATA[如何提高汽车价格估算中的 RMSE？

首先，我将根据行驶公里数估算缺失的条件值。

&lt;前&gt;&lt;代码&gt;`
new_condition_df = df[df[&#39;condition&#39;].map(condition_mapping) == 2]
top_1000_highest_mileage = new_condition_df.nlargest(1000, &#39;里程&#39;)[&#39;里程&#39;]
average_top_1000_highest_mileage = top_1000_highest_mileage.mean()

# 过滤 DataFrame 中条件为 null 或未指定的行
null_condition_df = df[df[&#39;条件&#39;].isnull() | (df[&#39;条件&#39;] == &#39;&#39;)]

# 根据里程条件更新“条件”
null_condition_df.loc[null_condition_df[&#39;mileage&#39;] &gt;=average_top_1000_highest_mileage, &#39;condition&#39;] = &#39;CONDITION_USED&#39;
null_condition_df.loc[null_condition_df[&#39;里程&#39;] &lt; average_top_1000_highest_mileage, &#39;条件&#39;] = &#39;CONDITION_NEW&#39;

# 使用修改后的行更新原始 DataFrame
df.update(null_condition_df)
`


删除一些空行

columns_with_null = [&#39;color&#39;, &#39;vat_reclaimable&#39;, &#39;cubic_capacity&#39;, &#39;seller_country&#39;, &#39;feature&#39;]
df.dropna（子集=columns_with_null，inplace=True）

df[&#39;air_conditioning&#39;].fillna(&#39;AIRCONDITIONING_NONE&#39;, inplace=True)
df[&#39;parking_camera&#39;].fillna(&#39;PARKINGCAMERA_NONE&#39;, inplace=True)
df[&#39;parking_sensors&#39;].fillna(&#39;PARKINGSENZOR_NONE&#39;, inplace=True)


这里我试图估计drive列的缺失值，其中包含汽车是4x4还是4x2的信息，drive包含大量空值，这就是为什么我用如此复杂的方式估计它方式

features = [&#39;里程&#39;, &#39;立方容量&#39;, &#39;功率&#39;, &#39;年份&#39;] + list(df.columns[df.columns.str.startswith(&#39;car_style_&#39;)]) + list(df .columns[df.columns.str.startswith(&#39;transmission_&#39;)]) + list(df.columns[df.columns.str.startswith(&#39;fuel_type_&#39;)])

train_data = df.dropna(subset=[&#39;drive&#39;]) # Odstranění řádků s chybějícími hodnotami sloupce &#39;drive&#39;
X_train, X_test, y_train, y_test = train_test_split(train_data[features], pd.get_dummies(train_data[&#39;drive&#39;]), test_size=0.2, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

Missing_data = df[df[&#39;drive&#39;].isnull()]
X_missing = Missing_data[特征]
预测值 = model.predict(X_missing)


df_imput = df.copy()
Predicted_df = pd.DataFrame(predicted_values, columns=y_train.columns, index=missing_data.index)
df_impulated.loc[df_impulated[&#39;drive&#39;].isnull(), y_train.columns] = Predicted_df.values

Predicted_df_encoded = pd.DataFrame(predicted_values, columns=y_train.columns, index=missing_data.index)
Predicted_df_encoded = (predicted_df_encoded &gt; 0.5).astype(int)

对于 Predicted_df_encoded.columns 中的列：
    df_impulated[column] = 0 # Přidání sloupce se všemi hodnotami 0
    df_impulated.loc[predicted_df_encoded.index, 列] = Predicted_df_encoded[列].values

unique_values_impulated_encoded = df_impulated[&#39;drive&#39;].unique()
df = df_估算
df.drop(列=[&#39;drive&#39;], inplace=True)


这里我对特征字段进行编码

from sklearn.preprocessing import MultiLabelBinarizer

mlb = MultiLabelBinarizer()
df = df.join(pd.DataFrame(mlb.fit_transform(df[&#39;feature&#39;]),columns=mlb.classes_))
df.fillna(0,就地=True)

df = df.drop(列=[&#39;特征&#39;])


培训本身

df_encoded = pd.get_dummies(df)

X_train, X_test, y_train, y_test = train_test_split(df_encoded.drop(columns=[&#39;price_with_vat_czk&#39;]), df_encoded[&#39;price_with_vat_czk&#39;], test_size=0.25, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)


所有程序：https://onecompiler.com/python/42brp9a4r
数据集https://filetransfer.io/data-package/a0mFEfg4#link
我的 RMSE 约为 64k]]></description>
      <guid>https://stackoverflow.com/questions/78405026/how-can-i-improve-the-rmse-in-my-car-price-estimate</guid>
      <pubDate>Mon, 29 Apr 2024 20:23:39 GMT</pubDate>
    </item>
    <item>
      <title>如何可视化 yolo best.pt 模型架构</title>
      <link>https://stackoverflow.com/questions/78404883/how-to-visualize-yolo-best-pt-model-architecture</link>
      <description><![CDATA[我想以图形方式可视化 yolo v9 模型的架构
我尝试将其转换为 keras 但不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78404883/how-to-visualize-yolo-best-pt-model-architecture</guid>
      <pubDate>Mon, 29 Apr 2024 19:49:00 GMT</pubDate>
    </item>
    <item>
      <title>NefTune 在 Transformers 上获得 0 训练损失</title>
      <link>https://stackoverflow.com/questions/78404768/neftune-receiving-0-training-loss-on-transformers</link>
      <description><![CDATA[我基本上是在尝试使用 Neftune 微调我的模型。模型基于土耳其语言。但在那里我的训练损失为零。我尝试过另一种模型，例如 Turkish-GPT2 没有问题一切都好。我认为模型可能有问题。我不知道如何处理这个问题。
加载模型：
从变压器导入 AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(“asafaya/kanarya-750m”)
模型 = AutoModelForCausalLM.from_pretrained(“asafaya/kanarya-750m”)

v3_prompt =“”“Aşağıda，daha fazla bağlam sağlayan bir girdiyle eşleştirilmiş，bir görevi açıklayan bir talimat bulunmaktadır。请注意，请确保您的设备正常工作。

＃＃＃ 输入：
{}

＃＃＃ 指示：
{}

＃＃＃ 回复：
{}
”“”

更改格式提示：
EOS_TOKEN = tokenizer.eos_token # 必须添加EOS_TOKEN
defformatting_prompts_func（示例）：
    输入=示例[“输入”]
    说明 = 示例[&#39;说明&#39;]
    输出=示例[“响应”]
    文本=[]
    对于 zip 中的输入、指令、输出（输入、指令、输出）：
        # 必须添加EOS_TOKEN，否则你的一代将永远延续下去！
        text = v3_prompt.format(输入、指令、输出) + EOS_TOKEN
        文本.append(文本)
    返回 {“文本”； ：文本，}
经过

从数据集导入数据集

数据集 = Dataset.from_pandas(数据[:40000])
数据集= dataset.map(formatting_prompts_func,batched=True)

Neftune：
from trl import SFTTrainer
从 Transformers 导入 TrainingArguments

trainer_2 = SFTTrainer(
    型号=型号，
    train_dataset=数据集，
    dataset_text_field=&quot;文本&quot;,
    最大序列长度=512，
    neftune_noise_alpha=5,
    包装=假，
    args = 训练参数(
        per_device_train_batch_size = 1, # 批量大小
        gradient_accumulation_steps = 2, # 梯度累积步数
        热身步骤 = 5,
        最大步数 = 80,
        学习率 = 2e-4,
        fp16 = 假，
        bf16 = torch.cuda.is_bf16_supported(),
        日志记录步骤 = 1,
        优化=“adamw_8bit”，
        权重衰减 = 0.01,
        lr_scheduler_type =“线性”，
        种子=3407，
        输出目录=“输出”，
    ),
）
trainer_2.train()

输出：
&lt;前&gt;&lt;代码&gt; [80/80 00:25，纪元 0/1]
步数训练损失
1 0.000000
2 0.000000
3 0.000000
4 0.000000
5 0.000000
6 0.000000
7 0.000000
8 0.000000
9 0.000000
10 0.000000
11 0.000000
12 0.000000
13 0.000000
14 0.000000
15 0.000000
16 0.000000
17 0.000000
18 0.000000
19 0.000000
20 0.000000
21 0.000000
22 0.000000
23 0.000000
24 0.000000
25 0.000000
26 0.000000
27 0.000000
28 0.000000
29 0.000000
30 0.000000
31 0.000000
32 0.000000
33 0.000000
34 0.000000
35 0.000000
36 0.000000
37 0.000000
38 0.000000
39 0.000000
40 0.000000
41 0.000000
42 0.000000
43 0.000000
44 0.000000
45 0.000000
46 0.000000
47 0.000000
48 0.000000
49 0.000000
50 0.000000
51 0.000000
52 0.000000
53 0.000000
54 0.000000
55 0.000000
56 0.000000
57 0.000000
58 0.000000
59 0.000000
60 0.000000
61 0.000000
62 0.000000
63 0.000000
64 0.000000
65 0.000000
66 0.000000
67 0.000000
68 0.000000
69 0.000000
70 0.000000
71 0.000000
72 0.000000
73 0.000000
74 0.000000
75 0.000000
76 0.000000
77 0.000000
78 0.000000
79 0.000000
80 0.000000
TrainOutput（global_step = 80，training_loss = 0.0，metrics = {&#39;train_runtime&#39;：25.3789，&#39;train_samples_per_second&#39;：6.304，&#39;train_steps_per_second&#39;：3.152，&#39;total_flos&#39;：117937578909696.0，&#39;train_loss&#39;：0.0，&#39;epoch&#39;： 0.004})
]]></description>
      <guid>https://stackoverflow.com/questions/78404768/neftune-receiving-0-training-loss-on-transformers</guid>
      <pubDate>Mon, 29 Apr 2024 19:23:04 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[我有以下输入矩阵
inp_tensor = torch.tensor(
        [[0.7860, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.7980, 0.0000],
        [1.0000, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.0000, 1.0000]])

和零元素的索引
mask_indices = torch.tensor(
[[7, 2],
[2, 6]])

如何从与以下矩阵的乘法中排除非零元素：
my_tensor = torch.tensor(
        [[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.2566, 0.7936, 0.9408],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696],
        [0.4414, 0.2969, 0.8317]])

也就是说，不要将其相乘（包括零）：
a = torch.mm(inp_tensor, my_tensor)
打印（一）
张量([[1.7866, 2.5468, 1.6330],
        [2.2041、2.5388、2.3315]]）

我想排除零个元素（以及 my_tensor 的相应行）：
inp_tensor = torch.tensor(
        [[0.7860, 0.1115, 0.6524, 0.6057, 0.3725, 0.7980]]) # 删除零个元素

my_tensor = torch.tensor(
        [[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696]]) # 删除对应的零元素行

b = torch.mm(inp_tensor, my_tensor)
打印(b)
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330]])

inp_tensor = torch.tensor([[1.0000, 0.1115, 0.6524, 0.6057, 0.3725, 1.0000]]) # 删除零个元素

my_tensor = torch.tensor(
        [
        [0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.4414, 0.2969, 0.8317]]) # 删除对应的零元素行

c = torch.mm(inp_tensor, my_tensor)
打印（三）
&gt;&gt;&gt;&gt;&gt;张量([[2.2041, 2.5388, 2.3315]])
打印（火炬.cat（[b，c]））
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330],
        [2.2041、2.5388、2.3315]]）

我需要它是高效的（即，没有for循环），因为我的张量非常大，并且还需要保持梯度（即，如果我调用optimizer.backward( ）更新计算图中的相关参数）]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在 Designer 中使用在 Azure AutoML 中创建的 ML 模型？</title>
      <link>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</link>
      <description><![CDATA[我知道我可以在 Azure Designer 中创建自定义代码模块，但是有没有办法连接我在 AutoML 中本机创建的 ML 模型？
AutoML 模型正在使用 XGBoost，这似乎不是 Designer 的 ML 组件功能下的选项。我的目标是创建一个低代码解决方案，因此我不想使用自定义 Python 代码组件。
有什么想法吗？
使用 AutoML 构建模型，需要连接到 Designer 中的现有数据管道]]></description>
      <guid>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</guid>
      <pubDate>Mon, 29 Apr 2024 14:52:21 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 - 针对 AUC 或 F1 分数进行优化</title>
      <link>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</link>
      <description><![CDATA[我在 sklearn 中使用随机森林，并且我的数据集相当不平衡（20% 为正类，80% 为其他类）。有没有办法让它针对考虑到这一点的某些指标（例如 AUC 分数或 F1 分数）进行训练（优化）？我可以使用什么技巧来推动它朝这个方向发展吗？
到目前为止，我想到/尝试过的唯一方法是使用不同的类别权重。
或者，是否有其他实现（或其他模型，例如 xgboost）允许我使用这样的自定义指标？]]></description>
      <guid>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</guid>
      <pubDate>Mon, 29 Apr 2024 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能寻找好的视频质量增强器[关闭]</title>
      <link>https://stackoverflow.com/questions/78402402/searching-for-a-good-video-quality-enhancer-using-ai</link>
      <description><![CDATA[我有一些 15 年前制作的旧视频。质量很差，它确实被压缩了，而且我有一些小故障，因为此时视频导入非常有问题。
我想尝试一些能够使用人工智能增强这些视频的程序。
如果只有可用的模型，我什至可以编写此代码。
我搜索 MacOS 或 Linux 工具。我更喜欢它是开源的。
你知道我在哪里可以找到一个好的工具吗？我尝试了一些，但质量不太好。
如果没有程序可以做到这一点，我该如何继续训练我的模型？我不知道这是否是一个好方法，因为它需要大量视频来完成......
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78402402/searching-for-a-good-video-quality-enhancer-using-ai</guid>
      <pubDate>Mon, 29 Apr 2024 11:32:19 GMT</pubDate>
    </item>
    <item>
      <title>关于机器学习中预测时间序列的分析和模型的建议[关闭]</title>
      <link>https://stackoverflow.com/questions/78402245/suggestion-about-analysis-and-model-for-forecasting-time-series-in-ml</link>
      <description><![CDATA[我必须根据 csv 数据对给定日期的网络单元格进行流量预测，其中包含 5 列：区域、站点、单元格、日期、流量
例如：
&lt;上一页&gt;&lt;代码&gt;AAN,AAN001,AAN001A,2021-01-01,2.56

AAN,AAN001,AAN001B,2021-01-01,5.6

ANM,ANM448,ANM448B,2021-04-19,1.2

ANM,ANM448,ANM448C,2021-04-19,3.6

有人可以帮助我一点，我仍然是机器和深度学习的初学者
我已经尝试过 randomforst 但没有成功。
我做了一些研究，被告知我们可以使用 LSTM 模型？]]></description>
      <guid>https://stackoverflow.com/questions/78402245/suggestion-about-analysis-and-model-for-forecasting-time-series-in-ml</guid>
      <pubDate>Mon, 29 Apr 2024 11:01:17 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法评估模型是否能够识别有影响的变量（使用 make_classification 生成的变量）？</title>
      <link>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</link>
      <description><![CDATA[我有一个关于 scikit-learn 的 make_classification 的问题。我使用 make_classification（二元分类任务）创建了一个数据集，目的是测试不同模型区分重要特征和不太重要特征的能力。
如何设置一个实验来评估模型是否能够识别有影响的变量？
我查看了 make_classification 的文档，但不幸的是我没有进一步了解。
我设置了以下内容：
X,y = make_classification(n_samples=50000, n_features=10, n_informative=5,
                    n_redundant=2、n_repeated=0、n_classes=2、n_clusters_per_class=2、
                          类间隔=1，
                   Flip_y=0.01，权重=[0.9,0.1]，shuffle=True，random_state=42）

谢谢您，我们非常感谢任何想法或建议。]]></description>
      <guid>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</guid>
      <pubDate>Sun, 28 Apr 2024 11:37:08 GMT</pubDate>
    </item>
    <item>
      <title>呼吸信号的对数功率谱</title>
      <link>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</link>
      <description><![CDATA[我的数据集是噪声频谱的LPS，我的标签是干净频谱的LPS，每个图片大小是（1025*1292）。我使用unet作为我的模型。
型号：
导入火炬
将 torch.nn 导入为 nn

解码器类（nn.Module）：
    def __init__(self, in_channels,out_features, kernel_size, maxpoolindex, apply_dropout,stride):
        super(解码器, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels、out_channels=out_features、kernel_size=kernel_size、stride=stride、padding=0、bias=True)
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.LeakyReLU(负斜率=0.2)
        self.dropout = nn.Dropout(p=0.1)
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) 如果 maxpoolindex == 1 否则无

    def 前向（自身，x）：
        x = self.conv(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        如果 self.maxpool 不是 None：
            x = self.maxpool(x)
        返回x

编码器类（nn.Module）：
    def __init__(self,in_channels, out_features, kernel_size, apply_dropout):
        super(编码器, self).__init__()
        self.conv_transpose = nn.ConvTranspose2d（in_channels = in_channels，out_channels = out_features，kernel_size = kernel_size，stride = 2，padding = 0，bias = True）
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)

    def 前向（自身，x）：
        x = self.conv_transpose(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        返回x

class DenoiseUnet(nn.Module):#除到第一个奇数停止的设计
    def __init__(自身):
        超级（DenoiseUnet，自我）.__init__()
        self.down_procedure = nn.ModuleList([
            解码器(1,8,2,0,0,2),
            解码器(8,16,2,0,0,2),
            解码器(16,32,2,0,0,2),
            解码器(32,128,2,0,0,2),
            解码器(128,128,1,0,0,1)
        ]）
        self.up_procedure = nn.ModuleList([
            编码器(2​​56,32,2,0),
            编码器(64,16,2,0),
            编码器(32,8,2,0),
            编码器(16,4,2,0),
        ]）
        self.convert = nn.ConvTranspose2d(4, 1, kernel_size=1, stride=1, padding=0)


    def 前向（自身，x）：
        连接=[]
        对于 self.down_procedure 中的 down：
            x = 向下(x)
            连接.append(x)

        连接=列表（反转（连接[：-1]））
        对于 up，在 zip(self.up_procedure, connection) 中连接：


            如果 x.shape[2] &lt;连接.形状[2]：
              连接 = 连接[:, :, :x.shape[2], :]
            别的：
              x = x[:, :, :connect.shape[2], :]

            如果 x.shape[3] &lt;连接.形状[3]：
              连接 = 连接[:, :, :, :x.shape[3]]
            别的：
              x = x[:, :, :, :connect.shape[3]]



            x = torch.cat([x, 连接], 暗淡=1)
            x = 上(x)

        y = self.convert(x)
        返回y


模型 = DenoiseUnet()
打印（模型）

但是经过 10 轮训练后，我得到这样的结果：
https://i.sstatic.net/b8DxXHUr.png
https://i.sstatic.net/UDhZNKHE.png
一个是预测结果，一个是测试，任何人都可以帮我找出问题所在吗？
数据集数量不同，看起来是一样的。]]></description>
      <guid>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</guid>
      <pubDate>Thu, 25 Apr 2024 17:43:28 GMT</pubDate>
    </item>
    <item>
      <title>在 lightgbm 中，当数据集构建中已经存在时，为什么 train 和 cv API 接受 categorical_feature 参数</title>
      <link>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</link>
      <description><![CDATA[以下是.cv lightgbm的API
&lt;块引用&gt;
lightgbm.cv（params，train_set，num_boost_round = 100，folds = None，nfold = 5，stratified = True，shuffle = True，metrics = None，feval = None，init_model = None，feature_name =&#39;auto&#39;，categorical_feature =&#39;auto&#39;，fpreproc=None，seed=0，callbacks=None，eval_train_metric=False，return_cvbooster=False）

有一个参数cateogrical_feature
&lt;块引用&gt;
分类特征。如果是 int 列表，则解释为索引。如果是 str 列表，则解释为功能名称（还需要指定 feature_name）。

现在是 .train API 
&lt;块引用&gt;
lightgbm.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, keep_training_booster=False, 回调=None ）

这里还有一个categorical_feature参数。这方面的文档与上面相同
现在，您注意到这两个 API 都使用 lightgbm 数据集 本身带有一个categorical_feature 参数。文档完全一样
问题：

如果两者都指定，哪一个优先？
建议在哪一个位置指定 categorical_feature？
这两种选择在 lightgbm 管道的工作内部有什么不同吗？
]]></description>
      <guid>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</guid>
      <pubDate>Thu, 25 Apr 2024 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>我尝试使用（pip install pickle5）安装 Python 的 pickle 包，但安装包失败</title>
      <link>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</link>
      <description><![CDATA[这是我尝试过的：
pip install pickle5

这是包含错误消息的快照。
这也是我得到的错误：
错误：无法为 pickle5 构建轮子，这是安装基于 pyproject.toml 的项目所必需的
我尝试按照其他一些帖子中的建议安装并重新安装 Microsoft Visual C++，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</guid>
      <pubDate>Sat, 27 Jan 2024 05:36:19 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker实例中的CUDA路径解决NameError：名称'_C'未使用GroundingDINO定义</title>
      <link>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</link>
      <description><![CDATA[我正在尝试在 Sagemaker 实例中安装和使用 grounding dino（使用 GPU ）但我收到错误：
NameError：名称“_C”未定义

我发现原因是因为变量CUDA_HOME没有配置所以要解决它我需要设置变量，但是在搜索答案后（我已经检查了公共路径/usr/local/cuda）我找不到sagemaker实例中cuda的安装路径。
cuda 安装在 sagemaker 实例中的什么位置以便我可以设置 CUDA_HOME？]]></description>
      <guid>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</guid>
      <pubDate>Fri, 26 Jan 2024 18:45:06 GMT</pubDate>
    </item>
    </channel>
</rss>