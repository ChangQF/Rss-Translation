<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 30 Sep 2024 06:25:33 GMT</lastBuildDate>
    <item>
      <title>使用 NumPy 从头开始​​实现 AdaGrad 优化器的问题</title>
      <link>https://stackoverflow.com/questions/79037845/problem-implementing-adagrad-optimizer-from-scratch-with-numpy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79037845/problem-implementing-adagrad-optimizer-from-scratch-with-numpy</guid>
      <pubDate>Mon, 30 Sep 2024 03:42:07 GMT</pubDate>
    </item>
    <item>
      <title>Ibm Watson/IBM cloud pak 数据错误</title>
      <link>https://stackoverflow.com/questions/79036541/error-in-ibm-watson-ibm-cloud-pak-for-data</link>
      <description><![CDATA[我遇到了此错误：错误：提取数据单个位置索引器超出范围。
我不确定为什么。我的 CSV 文件是 3 列 X 200 行。这是文件内容的示例：
单词名称颜色
“Aardvark” “Alabama Crimson” “#a32638” 

我遗漏了什么？我该如何纠正此错误？
我合并了两个数据集，然后缩短了数据集以解决之前的错误。]]></description>
      <guid>https://stackoverflow.com/questions/79036541/error-in-ibm-watson-ibm-cloud-pak-for-data</guid>
      <pubDate>Sun, 29 Sep 2024 13:47:17 GMT</pubDate>
    </item>
    <item>
      <title>使用模糊逻辑和人工智能进行名称匹配评分</title>
      <link>https://stackoverflow.com/questions/79036523/name-matching-score-using-fuzzy-logic-and-ai</link>
      <description><![CDATA[我有一个 excel，里面有两个姓名列和一个显示两个姓名的姓名匹配分数的列，即两个数字匹配的百分比。
我需要一个用 Python 编写的机器学习代码，该代码可以在这个 excel 上进行训练，并且能够预测姓名匹配分数的进一步值。]]></description>
      <guid>https://stackoverflow.com/questions/79036523/name-matching-score-using-fuzzy-logic-and-ai</guid>
      <pubDate>Sun, 29 Sep 2024 13:44:05 GMT</pubDate>
    </item>
    <item>
      <title>XFormersMetadata.__init__() 收到意外的关键字参数“is_prompt”</title>
      <link>https://stackoverflow.com/questions/79036452/xformersmetadata-init-got-an-unexpected-keyword-argument-is-prompt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79036452/xformersmetadata-init-got-an-unexpected-keyword-argument-is-prompt</guid>
      <pubDate>Sun, 29 Sep 2024 13:03:20 GMT</pubDate>
    </item>
    <item>
      <title>如何在 R pROC 中建立多因素模型？</title>
      <link>https://stackoverflow.com/questions/79036243/how-to-make-a-multifactor-model-in-r-proc</link>
      <description><![CDATA[我有一个数据表，其中包含响应“y”和一些预测变量，其中包括“X1”和“X2”。我可以使用 pROC 创建两个单因素模型：
roc1 &lt;- roc(data$y, data$X1)
roc2 &lt;- roc(data$y, data$X2)

但我正在尝试计算双因素模型的 ROC AUC：
t1 = data$X1
t2 = data$X2
t12 = cbind(t1, t2)
roc12 &lt;- roc(data$y, t12)

并收到一条错误消息：
响应和预测变量必须是长度相同的向量。

有没有办法在 pROC 中制作多因素模型？]]></description>
      <guid>https://stackoverflow.com/questions/79036243/how-to-make-a-multifactor-model-in-r-proc</guid>
      <pubDate>Sun, 29 Sep 2024 11:16:18 GMT</pubDate>
    </item>
    <item>
      <title>RubixML 模型在 PHP 中始终返回相同的预测</title>
      <link>https://stackoverflow.com/questions/79035928/rubixml-model-always-return-the-same-prediction-in-php</link>
      <description><![CDATA[我尝试使用 https://rubixml.com/ 提取不同句子的产品价格，但它总是返回 260，这是我给它的第一个标签
&lt;?php
include_once &#39;../vendor/autoload.php&#39;;

use Rubix\ML\Datasets\Labeled;
use Rubix\ML\Datasets\Unlabeled;
use Rubix\ML\Classifiers\KNearestNeighbors;
use Rubix\ML\Transformers\WordCountVectorizer;
use Rubix\ML\Transformers\TfIdfTransformer;
use Rubix\ML\Pipeline;
use Rubix\ML\Extractors\CSV;

$samples= [&#39;价格是 260&#39;,&#39;成本是 500&#39;,&#39;这件衬衫的成本是 300&#39;,&#39;这件商品的价值是 450&#39;,&#39;售价 150 美元&#39;];
$labels = [&#39;260&#39;, &#39;500&#39;, &#39;300&#39;, &#39;450&#39;, &#39;150&#39;];

$dataset = new Labeled($samples, $labels);

// 生成模型
$pipeline = new Pipeline([
new WordCountVectorizer(100),
new TfIdfTransformer(),
], new KNearestNeighbors(3));

// 使用数据集进行训练
$pipeline-&gt;train($dataset);

// 分析新的 frace
$new = Unlabeled::build([
[&#39;价格：1200&#39;],
]);

// 预测
$predictions = $pipeline-&gt;predict($new);
var_dump($predictions);

我更改了 KNearestNeighbors 的值，为训练数据集提供了更大的输入，更改了 Vectorizer。但什么都没有改变。]]></description>
      <guid>https://stackoverflow.com/questions/79035928/rubixml-model-always-return-the-same-prediction-in-php</guid>
      <pubDate>Sun, 29 Sep 2024 08:25:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 和 scikit-image 在 xray 图像上分割肺部对象时出现问题[关闭]</title>
      <link>https://stackoverflow.com/questions/79035911/problem-when-segmenting-lung-objects-on-xray-images-using-python-and-scikit-ima</link>
      <description><![CDATA[如何分割肺部切片？我尝试了几次，但效果并不完美。这是因为肺部前部的骨头部分。
肺部图像
我尝试模糊图像以使骨头更透明，但它影响了物体的周围环境。]]></description>
      <guid>https://stackoverflow.com/questions/79035911/problem-when-segmenting-lung-objects-on-xray-images-using-python-and-scikit-ima</guid>
      <pubDate>Sun, 29 Sep 2024 08:16:12 GMT</pubDate>
    </item>
    <item>
      <title>如何针对每个数据集的每次训练迭代训练 LSTM 自动编码器</title>
      <link>https://stackoverflow.com/questions/79035730/how-can-i-train-an-lstm-autoencoder-for-each-iteration-of-training-with-each-dat</link>
      <description><![CDATA[描述
我一直在尝试构建和训练 LSTM 自动编码器。虽然我使用的参考仅训练了一次模型，但我添加了一个函数，如果每个数据集的每次训练迭代都结束，则多次运行训练。
不过，我并不确定我是否走在正确的轨道上。感觉我的代码在每次迭代时都有可能覆盖训练好的模型。
问题
所以我想问一下下面的 Python 代码是否真的在用每个数据集对每次迭代进行训练（有 75 个 CSV 文件可用于训练此模型）。
以下是我在单个函数（trainModel()）内添加的用于构建和训练模型的 Python 代码
from sklearn.preprocessing import StandardScaler 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed
from tensorflow.keras.callbacks import EarlyStopping

# LSTM 网络以输入形状相等间隔的子序列形式获取输入（n_sample、n_timesteps、features）。
# 我们将使用以下自定义函数来创建这些序列
def create_sequences(X, y, time_steps=1):
Xs, ys = [], []
for i in range(len(X) - time_steps):
v = X.iloc[i:(i + time_steps)].values
Xs.append(v)
ys.append(y.iloc[i + time_steps])
return np.array(Xs), np.array(ys)

def trainModel():
for i in range(75):
fileList = pd.read_csv(&quot;/content/drive/MyDrive/fileList.csv&quot;)
filename = fileList.iloc[i, 0]
temp = pd.read_csv(&quot;/content/drive/MyDrive/dataFolder/&quot;+filename+&quot;.csv&quot;)
train_size = int(len(temp[[&quot;time_abs(%Y-%m-%dT%H:%M:%S.%f)&quot;, &quot;velocity(m/s)&quot;]]))
train = df.iloc[0:train_size]

# 规范化数据
scalar = StandardScaler()
scalar = scalar.fit(train[[&#39;velocity(m/s)&#39;]])

train[&#39;velocity(m/s)&#39;] = scalar.transform(train[[&#39;velocity(m/s)&#39;]])

time_steps = 30

X_train, y_train = create_sequences(train[[&#39;velocity(m/s)&#39;]],train[&#39;velocity(m/s)&#39;],time_steps)

# 构建 LSTM 自动编码器

# 自动编码器是一种神经网络模型旨在学习输入的压缩表示。
# 它们使用监督学习方法进行训练，称为自监督。
# 在这种架构中，编码器 LSTM 模型逐步读取输入序列。
# 读取整个输入序列后，该模型的隐藏状态或输出表示
# 整个输入序列的内部学习表示为固定长度向量。
# 然后将该向量作为输入提供给解码器模型，解码器模型将其解释为输出序列中的每个步骤
# 生成。
# timesteps = X_train.shape[1]
num_features = X_train.shape[2]

model = Sequential()
model.add(LSTM(128,input_shape=(timesteps,num_features)))
model.add(Dropout(0.2))
model.add(RepeatVector(timesteps)) # 重复输入 n 次。
model.add(LSTM(128,return_sequences=True))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(num_features))) # 将层应用于输入的每个时间片段。

model.compile(loss=&#39;mae&#39;,optimizer=&#39;adam&#39;)

# 训练自动编码器
early_stop = EarlyStopping(monitor=&#39;val_loss&#39;,patience=3,mode=&#39;min&#39;) # 如果监控指标相对于应用的 3 个时期的模式没有变化，则停止训练
history = model.fit(X_train,y_train,epochs=100,batch_size=32,validation_split=0.1,callbacks=[early_stop],shuffle=False)

model.save(&#39;anomaly_model.h5&#39;, overwrite=False)
model.save(&#39;anomaly_model_&#39;+ i +&#39;.h5&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/79035730/how-can-i-train-an-lstm-autoencoder-for-each-iteration-of-training-with-each-dat</guid>
      <pubDate>Sun, 29 Sep 2024 06:28:59 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型中的自定义编码器和解码器层显示为未构建</title>
      <link>https://stackoverflow.com/questions/79034907/custom-encoder-and-decoder-layers-within-keras-model-show-as-unbuilt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79034907/custom-encoder-and-decoder-layers-within-keras-model-show-as-unbuilt</guid>
      <pubDate>Sat, 28 Sep 2024 18:27:22 GMT</pubDate>
    </item>
    <item>
      <title>变压器数据集</title>
      <link>https://stackoverflow.com/questions/79034901/dataset-for-transformer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79034901/dataset-for-transformer</guid>
      <pubDate>Sat, 28 Sep 2024 18:25:45 GMT</pubDate>
    </item>
    <item>
      <title>安装 CausalML 时遇到问题</title>
      <link>https://stackoverflow.com/questions/79033786/trouble-installing-causalml</link>
      <description><![CDATA[我尝试使用 Python 3.12 在我的 Windows 机器上安装 causalml，命令为 pip install causalml。
但在尝试为 causalml 构建 wheel 时安装失败。以下是错误片段：
注意：此错误源自子进程，可能不是 pip 的问题。
错误：无法为 causalml 构建 wheel
无法构建 causalml
错误：错误：无法为某些基于 pyproject.toml 的项目 (causalml) 构建可安装的 wheel

我已将错误附加到 pastebin 上：
https://pastebin.com/dehRfgrk
但关键错误消息是：
&#39;use_tracing&#39;：不是 causalml/inference/tree/_tree/_tree.cpp 中 &#39;_PyCFrame&#39; 的成员。
命令“cl.exe”失败，退出代码为 2。
关于弃用的 NumPy API 和 Python 2.7 选项使用的警告（bdist_wheel.universal 已弃用）。
Setuptools 警告包配置中缺少包（causalml.inference.tree 等）

我正在使用：
Python 版本：3.12。
操作系统：Windows 10。
编译器：Microsoft Visual Studio 2022 构建工具。
环境：Anaconda 3。
NumPy 版本：1.26.4。
我尝试更新 Visual Studio 构建工具并安装了最新版本并确保包含 C++ 构建工具。]]></description>
      <guid>https://stackoverflow.com/questions/79033786/trouble-installing-causalml</guid>
      <pubDate>Sat, 28 Sep 2024 08:47:08 GMT</pubDate>
    </item>
    <item>
      <title>加载变压器时出现问题；ModuleNotFoundError：没有名为“transformers”的模块</title>
      <link>https://stackoverflow.com/questions/79031959/problem-loading-transformers-modulenotfounderror-no-module-named-transformers</link>
      <description><![CDATA[我想使用 huggingface 提供的一些模型。我甚至在开始的时候都遇到了最大的困难。有人能帮我识别和解决这个问题吗？
我正在使用 Kubuntu 24.04。

首先，我创建并激活一个虚拟环境，在其中安装变压器。
python3 -m venv .env
source .env/bin/activate

这是成功的，因为现在我在 Visual Code Studio 中的终端有前缀“(.env)”。
接下来，我从 github 安装最新的变压器：
pip install git+https://github.com/huggingface/transformers

输出成功。然后，我使用 hugginface.co 上推荐的方法测试其成功率：
python3 -c &quot;from transformers import pipeline; print(pipeline(&#39;sentiment-analysis&#39;)(&#39;I love you&#39;))&quot;

输出对我来说看起来正确：
未提供模型，默认为 distilbert/distilbert-base-uncased-finetuned-sst-2-english 和修订版本 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)。
不建议在生产中使用未指定模型名称和修订版本的管道。
硬件加速器（例如 GPU）在环境中可用，但没有将“设备”参数传递给“管道”对象。模型将在 CPU 上。
[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9998656511306763}]

从那里，我尝试运行以下代码：
from transformers import pipeline

但每次我都会得到以下输出：
/bin/python3 /path-to/main.py
回溯（最近一次调用最后一次）：
文件&quot;/path-to/main.py&quot;，第 5 行，在&lt;module&gt;
from transformers import pipeline
ModuleNotFoundError：没有名为“transformers”的模块
]]></description>
      <guid>https://stackoverflow.com/questions/79031959/problem-loading-transformers-modulenotfounderror-no-module-named-transformers</guid>
      <pubDate>Fri, 27 Sep 2024 15:09:24 GMT</pubDate>
    </item>
    <item>
      <title>将基于 Bert 的 PyTorch 模型导出到 CoreML。如何让 CoreML 模型适用于任何输入？</title>
      <link>https://stackoverflow.com/questions/78704542/exporting-a-bert-based-pytorch-model-to-coreml-how-can-i-make-the-coreml-model</link>
      <description><![CDATA[我使用以下代码将基于 Bert 的 PyTorch 模型导出到 CoreML。
由于我使用
dummy_input = tokenizer(&quot;A French fan&quot;, return_tensors=&quot;pt&quot;)

在 macOS 上测试时，CoreML 模型仅适用于该输入。如何让 CoreML 模型适用于任何输入（即任何文本）？

导出脚本：
# -*- coding: utf-8 -*-
&quot;&quot;&quot;Core ML Export
pip install tr​​ansformers torch coremltools nltk
&quot;&quot;&quot;
导入 os
从 transformers 导入 AutoModelForTokenClassification、AutoTokenizer
导入 torch
导入 torch.nn 作为 nn
导入 nltk
导入 coremltools 作为 ct
nltk.download(&#39;punkt&#39;)
# 加载模型和 tokenizer
model_path = os.path.join(&#39;model&#39;)
model = AutoModelForTokenClassification.from_pretrained(model_path, local_files_only=True)
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
# 修改模型的 forward 方法以返回元组
class ModifiedModel(nn.Module):
def __init__(self, model):
super(ModifiedModel, self).__init__()
self.model = model
self.device = model.device # 添加设备属性

def forward(self, input_ids,tention_mask, token_type_ids=None):
outputs = self.model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)
returnoutputs.logits

modified_model = ModifiedModel(model)

# 导出到 Core ML
def convert_to_coreml(model, tokenizer):
# 定义用于跟踪的虚拟输入
dummy_input = tokenizer(&quot;A French fan&quot;, return_tensors=&quot;pt&quot;)
dummy_input = {k: v.to(model.device) for k, v in dummy_input.items()}

# 使用虚拟输入跟踪模型
traced_model = torch.jit.trace(model,(
dummy_input[&#39;input_ids&#39;],dummy_input[&#39;attention_mask&#39;], dummy_input.get(&#39;token_type_ids&#39;)))

# 转换为 Core ML
输入 = [
ct.TensorType(name=&quot;input_ids&quot;, shape=dummy_input[&#39;input_ids&#39;].shape),
ct.TensorType(name=&quot;attention_mask&quot;, shape=dummy_input[&#39;attention_mask&#39;].shape)
]
if &#39;token_type_ids&#39; in dummy_input:
输入.append(ct.TensorType(name=&quot;token_type_ids&quot;, shape=dummy_input[&#39;token_type_ids&#39;].shape))

mlmodel = ct.convert(traced_model, 输入=inputs)

# 保存 Core ML 模型
mlmodel.save(&quot;model.mlmodel&quot;)
print(&quot;模型导出到 Core ML成功&quot;)

convert_to_coreml(modified_model, tokenizer)

要使用导出的模型：
import os
from transformers import AutoModelForTokenClassification, AutoTokenizer
import torch
import torch.nn as nn
import nltk
import coremltools as ct
from coremltools.models import MLModel
import numpy as np
from transformers import AutoTokenizer
import nltk

nltk.download(&#39;punkt&#39;)

# 加载 Core ML 模型
model = MLModel(&#39;model.mlmodel&#39;)

# 加载 tokenizer
model_path = &#39;model&#39;
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)

def prepare_input(text, tokenizer):
tokens = nltk.tokenize.word_tokenize(text)
tokenized_inputs = tokenizer(tokens, is_split_into_words=True, return_tensors=&quot;np&quot;)
input_ids = tokenized_inputs[&#39;input_ids&#39;].astype(np.int32)
tention_mask = tokenized_inputs[&#39;attention_mask&#39;].astype(np.int32)

input_data = {
&#39;input_ids&#39;: input_ids,
&#39;attention_mask&#39;:tention_mask
}

if &#39;token_type_ids&#39; in tokenized_inputs:
input_data[&#39;token_type_ids&#39;] = tokenized_inputs[&#39;token_type_ids&#39;].astype(np.int32)

return input_data, tokens

def predict(text):
# 准备输入
input_data, tokens = prepare_input(text, tokenizer)

# 进行预测
prediction = model.predict(input_data)

# 提取预测标签
logits = prediction[&#39;output&#39;] # 根据模型的输出调整此键
predicted_label = np.argmax(logits, axis=-1)[0]

# 显示结果
for word, label in zip(tokens, predicted_label):
print(f&quot;{word}: {model.model_description.outputDescriptions[0].dictionaryType.int64KeyType.stringDictionary[label]}&quot;)

# 用一个句子测试模型
predict(&quot;A French fan&quot;)

该脚本仅适用于示例“A French Fan”。当我尝试另一个示例 predict(&quot;A football fan is standing in the stadium.&quot;) 时，它会触发错误：
NSLocalizedDescription = &quot;MultiArray shape (1 x 12) does not match the shape (1 x 5) specified in the model description&quot;;


环境：

导出脚本：在 Ubuntu 20.04 上测试了 Python 3.10 和 torch 2.3.1（在 Windows 10 上不起作用）。
预测脚本：必须在 macOS 10.13+ 上运行，因为 CoreML 模型仅支持在 macOS 10.13+ 上进行预测。
]]></description>
      <guid>https://stackoverflow.com/questions/78704542/exporting-a-bert-based-pytorch-model-to-coreml-how-can-i-make-the-coreml-model</guid>
      <pubDate>Wed, 03 Jul 2024 23:39:36 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 进行迁移学习进行图像分类</title>
      <link>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</link>
      <description><![CDATA[我正在尝试使用已经训练过的模型将学习转移到我将要创建的模型中，并且只修改最后几层。这样做的目的是使用已经训练过的模型（已经在数百万张图像上训练过）来帮助我的模型对食物项目识别进行分类。我对 Keras 还很陌生，我遇到了一个问题，我现在开始理解它，但不知道如何解决
# 从 TensorFlow Hub 加载模型
model_url = &quot;https://www.kaggle.com/models/tensorflow/resnet-50/TensorFlow2/classification/1&quot;
hub_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3))

# 创建 Sequential 模型
model = tf.keras.Sequential()

# 将 TensorFlow Hub 层添加到 Sequential 模型
model.add(hub_layer)

# 构建 Sequential 模型
model.build((None, 224, 224, 3))

# 模型摘要
model.summary()

错误：
-------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
Cell In[56]，第 9 行
6 model = tf.keras.Sequential()
8 # 将 TensorFlow Hub 层添加到 Sequential 模型
----&gt; 9 model.add(hub_layer)
11 # 构建 Sequential 模型
12 model.build((None, 224, 224, 3))

文件 c:\Users\Karim\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\sequential.py:95，位于 Sequential.add(self, layer, rebuild)
93 layer = origin_layer
94 if not isinstance(layer, Layer):
---&gt; 95 raise ValueError(
96 &quot;只有 `keras.Layer` 的实例可以 &quot;
97 f&quot;添加到 Sequential 模型中。收到：{layer} &quot;
98 f&quot;（类型为 {type(layer)}）&quot;
99 )
100 if not self._is_layer_name_unique(layer):
101 raise ValueError(
102 &quot;添加到 Sequential 模型的所有层 &quot;
103 f&quot;应具有唯一名称。名称 &#39;{layer.name}&#39; 已经是 &quot;
104 &quot;此模型中层的名称。更新 `name` 参数 &quot;
105 &quot;以传递唯一名称。&quot;
106 )

ValueError：只有 `keras.Layer` 的实例可以添加到 Sequential 模型中。已收到：&lt;tensorflow_hub.keras_layer.KerasLayer 对象位于 0x00000190C6B8AD20&gt;（类型为 &lt;class &#39;tensorflow_hub.keras_layer.KerasLayer&#39;&gt;）
]]></description>
      <guid>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</guid>
      <pubDate>Mon, 29 Apr 2024 09:15:19 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker 批量转换器与我自己的预训练模型</title>
      <link>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:54:18 GMT</pubDate>
    </item>
    </channel>
</rss>