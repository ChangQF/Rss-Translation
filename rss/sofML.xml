<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 06 Jan 2025 12:34:10 GMT</lastBuildDate>
    <item>
      <title>寻找合作者为 Elixir 构建 ML 库：专注于线性回归和神经网络 [关闭]</title>
      <link>https://stackoverflow.com/questions/79332774/looking-for-collaborators-to-build-an-ml-library-for-elixir-focus-on-linear-reg</link>
      <description><![CDATA[我正在深入研究 Elixir 的并发模型，并探索如何将其应用于分布式机器学习。作为一个示例应用程序，我正在研究分布式神经网络的简单实现，以学习 XNOR 函数。
概念：
这个项目不仅仅是关于 XNOR，它还展示了 Elixir 中的独立进程如何模拟神经网络中的神经元。每个神经元都作为自己的进程运行（使用 GenServer），并通过消息传递与其他神经元通信，展示了 Elixir 独特的并发功能。
示例架构：
3 个神经元 (n₁、n₂、n₃) 作为独立进程运行。
输入 (x₁、x₂) 传递到神经元 n₁ 和 n₂。
神经元计算加权总和和激活，然后将输出发送到 n₃。
最终神经元 (n₃) 结合输出以产生预测 (Y)。
以下是供参考的简单图表：
（如果您在线托管图像，请用实际链接替换此链接）
为什么选择 Elixir？
Elixir 的参与者模型和轻量级流程非常适合分布式系统。该项目是一个值得探索的概念证明：
使用 Elixir 进行机器学习的可行性。
消息传递和函数式编程原理如何支持神经网络架构。
合作目标：
我希望与以下开发人员合作：
想要探索 Elixir 中的机器学习概念。
可以帮助改进神经网络流程的设计。
对为 ML 构建可扩展的分布式系统感兴趣。
对使用 Elixir 训练算法（例如反向传播）有想法。
可以为进程通信的实时可视化做出贡献。
到目前为止所做的工作：
作为 GenServer 进程的神经元的基本框架。
在神经元之间传递输入和输出的初始设置。
XNOR 函数是系统可以解决的问题的一个简单示例。
后续步骤：
实现用于优化权重的训练循环。
探索大型网络的性能优化。
设计分布式部署（例如，跨多个节点）。
该项目是将 Elixir 应用于更复杂的 ML 问题（例如分布式深度学习系统）的垫脚石。
开源：
我计划将这个项目开源，以便它能够随着社区的贡献而发展。
如果这听起来令人兴奋或符合您的兴趣，我很乐意听取您的意见！让我们突破 Elixir 在机器学习中的作用的界限。
感谢您的阅读！
我成功地实现了一个小型神经网络，使用 3 个神经元来学习 XNOR 函数，每个神经元都作为独立的 Elixir 进程运行。经过 10,000 次迭代训练后，网络表现非常出色。此外，我还开发了一个基础线性回归模型来根据输入数据预测输出。为了支持这些实现，我利用 Elixir 的函数式编程范式，为关键的机器学习操作（例如权重更新和激活函数）编写了 Elixir 函数。结果令人鼓舞，展示了 Elixir 在机器学习应用中的潜力。您可以在 GitHub 上找到该项目 https://github.com/ouerghi01/ElixirLinearRegressor.git：
Elixir Linear Regressor。]]></description>
      <guid>https://stackoverflow.com/questions/79332774/looking-for-collaborators-to-build-an-ml-library-for-elixir-focus-on-linear-reg</guid>
      <pubDate>Mon, 06 Jan 2025 10:39:21 GMT</pubDate>
    </item>
    <item>
      <title>如何获取在线视频游戏的类型？我的数据集包含大约 3500 个用户 ID、大约 5000 个游戏及其由这些用户给出的评分 [关闭]</title>
      <link>https://stackoverflow.com/questions/79332726/how-do-i-get-the-genre-of-video-games-online-my-dataset-contains-around-3500-us</link>
      <description><![CDATA[我正在尝试构建一个推荐引擎作为家庭作业的一部分。数据集包含大约 3500 个用户 ID、大约 5000 个游戏及其由这些用户给出的评分。我的当务之急是确定这些游戏的类型，根据一些人的说法，最好的方法是编写一个 Python 程序来获取包含此类信息的列表。但是，我不知道如何找到这样的列表。如果您有推荐系统经验，请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/79332726/how-do-i-get-the-genre-of-video-games-online-my-dataset-contains-around-3500-us</guid>
      <pubDate>Mon, 06 Jan 2025 10:16:01 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将手势识别集成到 .NET MAUI 中？</title>
      <link>https://stackoverflow.com/questions/79332674/is-there-any-way-to-integrate-hand-gesture-recognition-in-net-maui</link>
      <description><![CDATA[我有一个名为“手语应用”的项目，我需要在其中集成手势识别功能来识别手语。我不知道从哪里开始，因为我只具备 C# 基础知识。
我需要指南或建议，看看是否可行。我是大学二年级计算机科学专业学生]]></description>
      <guid>https://stackoverflow.com/questions/79332674/is-there-any-way-to-integrate-hand-gesture-recognition-in-net-maui</guid>
      <pubDate>Mon, 06 Jan 2025 09:55:54 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Flutter 应用中自动裁剪收据以仅显示购买的商品和价格？</title>
      <link>https://stackoverflow.com/questions/79332546/how-to-automatically-crop-a-receipt-to-show-only-purchased-items-and-prices-in-a</link>
      <description><![CDATA[我正在构建一个 Flutter 应用，用户可以在其中上传收据，我想处理这些收据，以便只显示购买的商品、金额和价格。我的最终目标是提取这些信息以供进一步处理。
以下是我迄今为止尝试过的方法：

OCR：我使用 google_ml_kit 进行 OCR，但它会捕获收据上的所有文本，包括页眉、页脚和其他不相关的部分。
正则表达式：我尝试使用正则表达式过滤 OCR 输出以匹配价格和商品的模式，但这不起作用，因为收据的格式和结构差异很大。

为了提高准确性，我考虑使用图像标记或训练自定义 TensorFlow Lite 模型来识别和裁剪收据中包含购买商品和价格的部分，然后再应用 OCR。但是，我不确定如何有效地解决这个问题，特别是在 Flutter 的背景下。
挑战：

收据具有不同的布局、字体和大小，因此没有固定的裁剪区域。
以编程方式准确识别购买商品和价格的区域。
将经过训练的 TensorFlow Lite 模型整合到 Flutter 应用中以进行图像分割或标记。

问题：

如何使用图像处理或机器学习技术自动裁剪收据的相关部分（包含购买的商品和价格）？
训练自定义 TensorFlow Lite 模型是一种可行的方法吗？如果是，我该如何训练它来检测收据的相关部分？
是否有现有的工具、框架或软件包（与 Flutter/Dart 兼容）可以简化此过程？

示例图像（所以我只想要框中的内容）：
]]></description>
      <guid>https://stackoverflow.com/questions/79332546/how-to-automatically-crop-a-receipt-to-show-only-purchased-items-and-prices-in-a</guid>
      <pubDate>Mon, 06 Jan 2025 08:50:54 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow 中加载模型时出现图形断开错误</title>
      <link>https://stackoverflow.com/questions/79331871/graph-disconnected-error-when-loading-model-in-tensorflow</link>
      <description><![CDATA[我正在运行代码存储库，在重新创建模型时收到一条错误消息。

ValueError：图形断开连接：无法获取层“resnet50”处张量 KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=&#39;resnet50_input&#39;), name=&#39;resnet50_input&#39;, description=&quot;created by layer &#39;resnet50_input&#39;&quot;) 的值。以下先前的层可以毫无问题地访问：......

我使用的是 Tensorflow 2.14.0 和 Python 3.10
这是测试代码，我发现这是来自 repo 的错误代码：
num_classes = 10
input_shape = (32, 32, 3)
model = tf.keras.Sequential()
base_model = tf.keras.applications.ResNet50(weights=&#39;imagenet&#39;, include_top=False, input_shape=input_shape)
for layer in base_model.layers:
layer.trainable = False
model.add(base_model)
model.add(tf.keras.layers.GlobalAveragePooling2D())
model.add(tf.keras.layers.Dense(num_classes,激活=&#39;softmax&#39;))

extractor = tf.keras.Model(inputs=model.layers[0].input,
outputs=[layer.output for layer in model.layers])

我搜索了谷歌，尝试了所有方法。有人说我应该先创建一个输入，但下面的代码仍然出错。有人能给我一个解决方案吗？我很感激。
num_classes = 10
input_shape = (32, 32, 3)
input_tensor = tf.keras.Input(shape=input_shape)
model = tf.keras.Sequential()
base_model = tf.keras.applications.ResNet50(weights=&#39;imagenet&#39;, include_top=False, input_shape=input_shape, input_tensor=input_tensor)
for layer in base_model.layers:
layer.trainable = False
model.add(base_model)
model.add(tf.keras.layers.GlobalAveragePooling2D())
model.add(tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;))

extractor = tf.keras.Model(inputs=model.layers[0].input,
输出=[模型层中的层层输出])
]]></description>
      <guid>https://stackoverflow.com/questions/79331871/graph-disconnected-error-when-loading-model-in-tensorflow</guid>
      <pubDate>Mon, 06 Jan 2025 01:35:22 GMT</pubDate>
    </item>
    <item>
      <title>如何提高我的多类分类模型的准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/79331544/how-to-increase-the-accuracy-of-my-multiclass-classification-model</link>
      <description><![CDATA[在此处输入图片说明
我正在研究驾驶员得分预测问题。我的数据集包括 RPM、角度、速度和油门等特征。然而，挑战在于我没有基本事实标签。为了解决这个问题，我进行了彻底的分析，并咨询了业内专业人士。基于这些见解，我创建了一个方程，其中驾驶员得分计算为特征的加权总和（权重 * 特征）。
具体来说，对于刹车痕迹特征，我单独包含了它的权重，因为它是一个二元变量。数据集显示大多数特征之间具有高度相关性，但角度除外，它与其他特征的相关性似乎最小。此外，数据不平衡，应用缩放后，RPM 和速度都呈正态分布。然而，角度表现得更像一个多维特征。
我读到几篇研究论文，它们表明特征相关性对于分类任务来说并不是一个关键问题，尤其是在使用随机森林等模型时。为了进一步增强数据集，我引入了加速度，使用公式 (Δv / Δt) 来确定制动事件是突然的还是正常的，如上式所示。
尽管付出了这些努力，但模型的准确性仍然很低。我最初避免平衡数据，因为应用 SMOTE（合成少数过采样技术）会导致严重的数据失真。 SMOTE 生成的合成数据严重依赖于特征空间的边缘，这使得分布偏离了正态性，从而使结果更糟。
关于如何提高模型性能，有什么建议吗？
我尝试了 pca 分析，结果表明角度贡献不大，但根据专家的说法，角度非常重要，在这种情况下使用 iforest 是否比 xgboost 或 randomforest 分类器更好？我自己计算了驾驶员得分，然后将其分为 [0,30,50,70,100]，差，平均，好，优秀，不平衡在于我们的道路类型，高速公路比另一种道路少得多，优秀的道路也比平均水平低得多]]></description>
      <guid>https://stackoverflow.com/questions/79331544/how-to-increase-the-accuracy-of-my-multiclass-classification-model</guid>
      <pubDate>Sun, 05 Jan 2025 20:53:17 GMT</pubDate>
    </item>
    <item>
      <title>CNN 模型准确率达 80%，但部署后无法识别人员</title>
      <link>https://stackoverflow.com/questions/79331264/cnn-model-gives-80-accuracy-but-fails-to-identify-person-after-deployment</link>
      <description><![CDATA[我使用卷积神经网络 (CNN) 开发了一个人物分类 AI 模型。在测试期间，该模型的准确率达到了 80%。然而，在部署模型后，它无法在现实场景中正确识别人员。
# 构建 CNN 模型
model = Sequential([
Conv2D(32, (3, 3),activation=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.01), input_shape=(224, 224, 3)),
MaxPooling2D(pool_size=(2, 2)),
Conv2D(64, (3, 3),activation=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.01)),
MaxPooling2D(pool_size=(2, 2)),
Conv2D(128, (3, 3),activation=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.01)),
MaxPooling2D(pool_size=(2, 2)),
Flatten(),
Dense(128,activation=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.01)),
Dropout(0.3),
Dense(train_generator.num_classes,activation=&#39;softmax&#39;)
])

# 编译模型
model.compile(optimizer=Adam(learning_rate=0.0001),loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
]]></description>
      <guid>https://stackoverflow.com/questions/79331264/cnn-model-gives-80-accuracy-but-fails-to-identify-person-after-deployment</guid>
      <pubDate>Sun, 05 Jan 2025 17:59:17 GMT</pubDate>
    </item>
    <item>
      <title>检测器模型中框的正确损失函数</title>
      <link>https://stackoverflow.com/questions/79331211/correct-loss-function-for-bboxes-in-a-detector-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79331211/correct-loss-function-for-bboxes-in-a-detector-model</guid>
      <pubDate>Sun, 05 Jan 2025 17:31:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Flutter 应用程序中实现 Roboflow 模型 API？</title>
      <link>https://stackoverflow.com/questions/79330782/how-to-implement-roboflow-model-api-in-flutter-app</link>
      <description><![CDATA[我正在尝试在我的 Flutter 应用中实现 RoboFlow 模型 API 来分析图像。我想从用户那里获取图像并使用 Roboflow 模型 API 对其进行分析。
URL、API 密钥、模型 API、版本一切都正确，但输入数据有些错误。
下面是我的函数：
Future&lt;void&gt; testRoboflowAPI(File imagePath) async {
try {
List&lt;int&gt; imageBytes = imagePath.readAsBytesSync();
String base64Image = base64Encode(imageBytes);

final url =
&#39;https://classify.roboflow.com/**********/1?api_key=*********&#39;;
final headers = {&#39;Content-Type&#39;: &#39;application/x-www-form-urlencoded&#39;};

final body = {
&quot;data&quot;: base64Image,
};

finalcodedBody = Uri(queryParameters: body).query;
final response = await http.post(
Uri.parse(url),
headers: headers,
body:codedBody,
);

if (response.statusCode == 200) {
print(&#39;成功：${response.body}&#39;);
} else {
print(
&#39;错误：状态代码 ${response.statusCode}，响应：${response.body}&#39;);
}
} catch (e) {
print(&#39;异常：${e.toString()}&#39;);
}
}

我收到给定的错误：
错误：状态代码 400，响应：{&quot;message&quot;:&quot;无法加载输入图像。原因：base64 输入图像格式错误。&quot;}

您能帮我得到正确的响应并解决错误吗？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79330782/how-to-implement-roboflow-model-api-in-flutter-app</guid>
      <pubDate>Sun, 05 Jan 2025 13:15:11 GMT</pubDate>
    </item>
    <item>
      <title>验证损失增加且准确率停滞 [关闭]</title>
      <link>https://stackoverflow.com/questions/79326823/validation-loss-increasing-and-accuracy-is-stuck</link>
      <description><![CDATA[在此处输入图片说明
在此处输入图片说明

# 导入必要的库

导入 numpy 作为 np
导入 pandas 作为 pd
导入 matplotlib.pyplot 作为 plt
导入 os
导入 keras
导入 seaborn 作为 sns
导入 tensorflow 作为 tf
从 sklearn.model_selection 导入 train_test_split
从 tensorflow.keras.preprocessing.image 导入 ImageDataGenerator
从 tensorflow.keras 导入 Input
从 tensorflow.keras.models 导入 Sequential
从 tensorflow.keras.layers 导入 Conv2D， MaxPooling2D、Flatten、Dense、Dropout
来自 sklearn.metrics 导入分类报告、confusion_matrix
来自 tensorflow.keras.utils 导入 load_img、img_to_array
来自 tensorflow.keras.applications 导入 VGG16
来自 tensorflow.keras.models 导入模型
来自 tensorflow.keras.preprocessing 导入图像
来自 tensorflow.keras.layers 导入 BatchNormalization
来自 tensorflow.keras.callbacks 导入 ReduceLROnPlateau
来自 tensorflow.keras.callbacks 导入 EarlyStopping
来自 tensorflow.keras.optimizers 导入 Adam
来自 google.colab 导入 drive

# 数据集加载

drive.mount(&#39;/content/drive&#39;)
train_dir = &#39;/content/drive/MyDrive/CSE427/Project/Dataset/New Train&#39;
test_dir = &#39;/content/drive/MyDrive/CSE427/Project/Dataset/New Test&#39;

# 预处理数据 &amp;数据增强

train_datagen = ImageDataGenerator(
rescale=1./255,
sher_range=0.2,
zoom_range=0.2,
Horizo​​ntal_flip=True,
rotation_range=30,
bright_range=(0.8, 1.2),
width_shift_range=0.2,
height_shift_range=0.2,
channel_shift_range=30)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
train_dir,
target_size=(128, 128),
batch_size=32,
class_mode=&#39;binary&#39;)

validation_generator = test_datagen.flow_from_directory(
test_dir,
target_size=(128, 128),
batch_size=32,
class_mode=&#39;binary&#39;)

print(&#39;\n&#39;,train_generator.class_indices)

# 构建自定义 CNN 模型
from tensorflow.keras.regularizers import l2
model = Sequential([
Input(shape=(128, 128, 3)), 
Conv2D(32, (3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling2D(pool_size=(2, 2)),
Dropout(0.3),
Conv2D(64, (3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling2D(pool_size=(2, 2)),
Dropout(0.3),
Conv2D(128, (3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling2D(pool_size=(2, 2)),
Flatten(),
Dense(128, 激活=&#39;relu&#39;, kernel_regularizer=l2(0.01)),
Dropout(0.5),
Dense(1, 激活=&#39;sigmoid&#39;)
])

model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 训练模型
lr_scheduler = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.5, waiting=5, min_lr=1e-6, verbose=1)
early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, waiting=5, restore_best_weights=True, verbose=1)

history = model.fit(
train_generator,
steps_per_epoch=len(train_generator),
epochs=30,
validation_data=validation_generator,
validation_steps=len(validation_generator),
callbacks=[early_stopping, lr_scheduler])

# 在测试数据上评估模型
test_loss, test_acc = model.evaluate(validation_generator)
print(f&quot;测试准确率：{test_acc*100}%&quot;)

请有人帮我确定模型实现是否正确。我是这个领域的新手。我尝试了很多次，但无法解决这个问题。但在一次迭代中，它给出了 91.3% 的准确率。我正在根据图像对适合公交车和不适合公交车进行分类。训练图像为 482 张，验证图像为 46 张]]></description>
      <guid>https://stackoverflow.com/questions/79326823/validation-loss-increasing-and-accuracy-is-stuck</guid>
      <pubDate>Fri, 03 Jan 2025 14:46:02 GMT</pubDate>
    </item>
    <item>
      <title>对随机森林进行修改，每次分割时都会评估某些特征</title>
      <link>https://stackoverflow.com/questions/79290974/modification-of-random-forest-to-always-evaluate-some-features-at-every-split</link>
      <description><![CDATA[我正在尝试更改随机森林分类器的功能。虽然通常每次分割都会随机选择特征，但我希望每次分割时都评估一个特定特征。我知道这会影响性能，但我想尝试一下这在非常具体的用例中是否是个好主意。因此，调整的结果应为：用于分割的特征是随机选择的（像往常一样），但始终会考虑一个特定特征（例如索引 15）（不一定使用）。
我不知道有哪些软件包允许开箱即用。有没有一个，或者也许有一个简单的解决方法来实现相同的效果？]]></description>
      <guid>https://stackoverflow.com/questions/79290974/modification-of-random-forest-to-always-evaluate-some-features-at-every-split</guid>
      <pubDate>Wed, 18 Dec 2024 11:48:27 GMT</pubDate>
    </item>
    <item>
      <title>‘super’ 对象没有属性‘__sklearn_tags__’</title>
      <link>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</link>
      <description><![CDATA[我在使用 Scikit-learn 中的 RandomizedSearchCV 拟合 XGBRegressor 时遇到了 AttributeError。错误消息指出：
&#39;super&#39; 对象没有属性 &#39;__sklearn_tags__&#39;。

当我在 RandomizedSearchCV 对象上调用 fit 方法时会发生这种情况。我怀疑它可能与 Scikit-learn 和 XGBoost 或 Python 版本之间的兼容性问题有关。我使用的是 Python 3.12，并且 Scikit-learn 和 XGBoost 都安装了最新版本。
我尝试使用 Scikit-learn 中的 RandomizedSearchCV 调整 XGBRegressor 的超参数。我希望模型能够毫无问题地拟合训练数据，并在交叉验证后提供最佳参数。
我还检查了兼容性问题，确保库是最新的，并重新安装了 Scikit-learn 和 XGBoost，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</guid>
      <pubDate>Wed, 18 Dec 2024 11:45:52 GMT</pubDate>
    </item>
    <item>
      <title>改进深度学习模型以检测不同条件下的火车车厢间隙</title>
      <link>https://stackoverflow.com/questions/75897626/improving-deep-learning-model-to-detect-train-wagon-gaps-in-variable-conditions</link>
      <description><![CDATA[我们的团队从背景和与铁轨距离不同的各个摄像机位置记录移动火车的视频流。我们的任务是收集有关每节车厢的信息，这需要检测它们之间的间隙。我们使用 Yolov5 架构和默认数据增强在包含 2000 多张带标签图像以及无间隙的未标记图像的数据集上训练了一个深度神经网络。然而，我们在低光照条件下遇到了几个误报和性能不佳的问题。
我们当前的后处理步骤包括运行 dbscan 算法将帧与“耦合器”分组（参见下图中耦合器周围 bbox 的示例），并根据平均置信度和标准差过滤掉低置信度示例。
此外，我们最近从不同位置收集了 50k 张图像，包括带耦合器和不带耦合器的图像。使用当前应用程序动态收集图像，如果我们在图像中发现一个置信度至少为 60% 的耦合器，则为该图像分配一个类“GAP”。耦合器置信度低于 60% 的图像被拒绝，没有耦合器的图像被分配到“NO_GAP”类。使用这些图像，我们使用 Yolov8 架构训练了一个带有标签 [GAP, NO_GAP] 的二元分类器。但是，我们不确定二元分类器是否能够很好地概括我们的任务，因为我们将许多不同的概念视为“NO_GAP”。
我们正在考虑其他深度学习架构，例如半监督学习和对比学习，作为我们问题的潜在解决方案。我们也对尝试不同的架构感兴趣，例如采用修补方法的 VIT，尽管我们对这些架构的经验有限。
我们的主要问题是：

您建议我们探索哪些深度学习架构或技术来提高我们的模型在可变照明和环境条件下检测火车车厢间隙的准确性？

是否值得继续使用分类但使用不同的架构，例如采用修补方法的 VIT？
是否有这些架构的具体实现或示例可供参考？

我们有很多未标记的数据。是否值得尝试使用自监督学习作为“预训练”步骤？对于未标记/标记数据比例、所需计算能力、选择算法以及如何确定何时停止预训练过程等问题，是否有经验法则？


视频帧示例（检测到耦合器）

]]></description>
      <guid>https://stackoverflow.com/questions/75897626/improving-deep-learning-model-to-detect-train-wagon-gaps-in-variable-conditions</guid>
      <pubDate>Fri, 31 Mar 2023 10:44:13 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.neighbors._base”导入名称“_check_weights”</title>
      <link>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</link>
      <description><![CDATA[我正在尝试使用 Missforest 来处理表数据中的缺失值。
import sklearn
print(sklearn.__version__)
-&gt;1.2.1

import sklearn.neighbors._base
import sys
sys.modules[&#39;sklearn.neighbors.base&#39;] = sklearn.neighbors._base

!pip install missingpy
from missingpy import MissForest

到目前为止，它运行良好，但从昨天开始，出现了以下错误消息。
ImportError：无法从“sklearn.neighbors._base”导入名称“_check_weights”

我想知道如何处理这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</guid>
      <pubDate>Sat, 04 Mar 2023 01:48:43 GMT</pubDate>
    </item>
    <item>
      <title>CNN 中的反向传播（通过卷积层）和梯度</title>
      <link>https://stackoverflow.com/questions/42588047/backpropagation-through-convolutional-layer-and-gradients-in-cnn</link>
      <description><![CDATA[我正在学习使用卷积神经网络，并继续为这些神经网络编写自己的框架。
我被困在必须通过网络反向传播误差（增量）并计算梯度的部分。我知道 CNN 中的过滤器是 3D 的，所以我们有一些过滤器的宽度、高度和深度。
前馈很好。让我们看一下前馈步骤中某些层的输出计算公式：

为了进行卷积，l 层中过滤器的深度应与前一层 l-1 的输出 z 的输出通道数（深度）相同。因此，在这里，在这个公式中，我们将前一层的输出与当前层的权重进行卷积，这是有效的，因为这两个中的第三个坐标（深度）是相等的。现在，让我们检查一下误差反向传播的公式：

在这个公式中，我们有来自 l+1 层的 delta 和权重数组 w 的卷积。现在这就是让我困惑的地方，因为一般来说它们的第三个坐标（深度）并不总是相等的。考虑一下 VGGNet 架构，让我们看一下过滤器数量变化的三个连续层：
...
CONV3-128：[112x112x128] 内存：112*112*128=1.6M 权重：(3*3*128)*128 = 147,456
POOL2：[56x56x128] 内存：56*56*128=400K 权重：0
CONV3-256：[56x56x256] 内存：56*56*256=800K 权重：(3*3*128)*256 = 294,912
...
在过滤器数量从128 到 256（在 CONV3-256 层中），它具有上述激活（和误差增量）和权重的维度。但是，由于过滤器的深度（在本例中为 128）与其增量的第 3 维（在本例中为 256）不同，我该如何对这两个数组进行卷积？非常感谢任何能提供帮助的人。我觉得这很令人困惑，我在网上找不到太多这方面的帮助。它大多解释得不太清楚或被认为是“已知的”。]]></description>
      <guid>https://stackoverflow.com/questions/42588047/backpropagation-through-convolutional-layer-and-gradients-in-cnn</guid>
      <pubDate>Fri, 03 Mar 2017 20:38:26 GMT</pubDate>
    </item>
    </channel>
</rss>