<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 10 Jun 2024 09:17:22 GMT</lastBuildDate>
    <item>
      <title>MultiScale Vision Transformer 张量不匹配形状问题</title>
      <link>https://stackoverflow.com/questions/78600117/multiscale-vision-transformer-tensor-mismatch-shape-issue</link>
      <description><![CDATA[MultiScale Vision Transformer 似乎存在张量不匹配形状问题。有人知道如何解决这个问题吗？
https://github.com/facebookresearch/mvit/issues/22]]></description>
      <guid>https://stackoverflow.com/questions/78600117/multiscale-vision-transformer-tensor-mismatch-shape-issue</guid>
      <pubDate>Mon, 10 Jun 2024 00:51:05 GMT</pubDate>
    </item>
    <item>
      <title>时间序列中具有小数据集的机器学习模型</title>
      <link>https://stackoverflow.com/questions/78599891/machine-learning-models-with-small-datasets-in-time-series</link>
      <description><![CDATA[我正在开展一个预测项目，我的数据集包含 24 个月的历史销售数据。我使用 20 个月进行训练和验证，其余 4 个月进行测试。对于验证，我使用滚动预测起源（类似于 TimeSeriesSplit）。
我尝试使用几种模型，包括 SVR、GBR、随机森林、Facebook Prophet、ARIMA 和线性回归。但是，我很难找到一个正常工作的模型。我所有的预测图看起来都不一致，并且与数据不太吻合。
您能否解释为什么机器学习模型在像我这样的小数据集上可能表现不佳，并建议任何更适合小数据集的技术或模型？
我所有的预测结果看起来都像图像一样，有一条直线。
谢谢！
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78599891/machine-learning-models-with-small-datasets-in-time-series</guid>
      <pubDate>Sun, 09 Jun 2024 22:25:42 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林对心电图数据进行验证和测试的准确率较低</title>
      <link>https://stackoverflow.com/questions/78599809/low-validation-and-test-accuracy-with-random-forest-on-ecg-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78599809/low-validation-and-test-accuracy-with-random-forest-on-ecg-data</guid>
      <pubDate>Sun, 09 Jun 2024 21:43:40 GMT</pubDate>
    </item>
    <item>
      <title>将 Unet 模型转换为 tflite</title>
      <link>https://stackoverflow.com/questions/78599481/converting-unet-model-to-tflite</link>
      <description><![CDATA[我正在尝试将 .h5 模型（用于图像分割的 Unet 的简化版本）转换为 .tflite 模型。我该如何正确执行此操作？到目前为止，.h5 模型似乎做出了很好的预测，但是当我尝试 .tflite 模型时，预测实际上是一张完全紫色的图像。
这是我所做的：
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with open(&#39;unet_model_prueba_sin_int8.tflite&#39;, &#39;wb&#39;) as f:
f.write(tflite_model)

然后测试 .tflite 模型：
interpreter = tf.lite.Interpreter(model_path=&quot;unet_model_prueba_sin_int8.tflite&quot;)
interpreter.allocate_tensors()

input_details =解释器。获取输入细节（）
输出细节 = 解释器。获取输出细节（）

def load_and_preprocess_image(image_path, target_size):
image = Image.open(image_path).resize(target_size)
image_array = np.array(image, dtype=np.float32) / 255.0 # 标准化图像
image_array = np.expand_dims(image_array, axis=0)
return image_array

def predict_with_tflite(image_array):
input_tensor = image_array.astype(np.float32)
解释器。设置输入细节（输入细节[0][&#39;index&#39;], 输入细节）
解释器。invoke()
输出 = 解释器。获取输出细节（输出细节[0][&#39;index&#39;])
return output

image_path = &quot;image_path/image.jpg&quot;

image_array = load_and_preprocess_image(image_path, target_size=(96, 96))

prediction = predict_with_tflite(image_array)

def display_segmentation_mask(pred):
&quot;&quot;&quot;显示分割掩码。&quot;&quot;&quot;
mask = np.argmax(pred, axis=-1) 
plt.imshow(mask[0], cmap=&#39;viridis&#39;) 
plt.axis(&#39;off&#39;) 
plt.show()

display_segmentation_mask(prediction)
]]></description>
      <guid>https://stackoverflow.com/questions/78599481/converting-unet-model-to-tflite</guid>
      <pubDate>Sun, 09 Jun 2024 19:11:05 GMT</pubDate>
    </item>
    <item>
      <title>搜索具有相似文本的文档</title>
      <link>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</link>
      <description><![CDATA[我有一个包含三个属性的文档：标签、位置和文本。
目前，我正在使用 LangChain/pgvector/embeddings 对它们全部进行索引。
我得到了满意的结果，但我想知道是否有更好的方法，因为我想查找一个或多个具有特定标签和位置的文档，但文本可能会有很大差异，但含义仍然相同。出于这个原因，我考虑使用嵌入/向量数据库。
这是否也是使用 RAG（检索增强生成）来“教”的一个例子LLM 不知道的一些常见缩写？
import pandas as pd

from langchain_core.documents import Document
from langchain_postgres import PGVector
from langchain_postgres.vectorstores import PGVector
from langchain_openai.embeddings import OpenAIEmbeddings

connection = &quot;postgresql+psycopg://langchain:langchain@localhost:5432/langchain&quot;
embeddings = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)
collection_name = &quot;notas_v0&quot;

vectorstore = PGVector(
embeddings=embeddings,
collection_name=collection_name,
connection=connection,
use_jsonb=True,
)

# 开始索引

# df = pd.read_csv(&quot;notes.csv&quot;)
# df = df.dropna() # .head(10000)
# df[&quot;tags&quot;] = df[&quot;tags&quot;].apply(
# lambda x: [tag.strip() for tag in x.split(&quot;,&quot;) if tag.strip()]
# )

# long_texts = df[&quot;Texto Longo&quot;].tolist()
# wc = df[&quot;Centro Trabalho Responsável&quot;].tolist()
# notes = df[&quot;Nota&quot;].tolist()
# tags = df[&quot;tags&quot;].tolist()

# documents = list(
# map(
# lambda x: Document(
# page_content=x[0], metadata={&quot;wc&quot;: x[1], &quot;note&quot;: x[2], &quot;tags&quot;: x[3]}
# ),
# zip(long_texts, wc, notes, tags),
# )
# )

# print(
# [
# vectorstore.add_documents(documents=documents[i : i + 100])
# for i in range(0, len(documents), 100)
# ]
# )
# print(&quot;Done.&quot;)

### END INDEX

### BEGIN QUERY

result = vectorstore.similarity_search_with_relevance_scores(
&quot;EVTD202301222707&quot;,
filter={&quot;note&quot;: {&quot;$in&quot;: [&quot;15310116&quot;]}, &quot;tags&quot;: {&quot;$in&quot;: [&quot;abcd&quot;, &quot;xyz&quot;]}},
k=10, # 结果限制
)

### END QUERY
]]></description>
      <guid>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</guid>
      <pubDate>Sun, 09 Jun 2024 16:40:32 GMT</pubDate>
    </item>
    <item>
      <title>使用上下文检测自动从 AutoCAD PDF 平面图中提取尺寸 [关闭]</title>
      <link>https://stackoverflow.com/questions/78599084/automating-dimension-extraction-from-autocad-pdf-plans-with-context-detection</link>
      <description><![CDATA[几个月来我一直在考虑一个项目。
今天，我决定开始着手做这件事。但是，我不知道从哪里开始，也不想走错路。
让我解释一下：
我在一家工业设计公司工作。我们每月创建大约 300 个 AutoCAD 计划。这些计划或多或少都相似。
我的项目背后的想法是获取我们发送给客户的最终计划 (PDF)，并从这些计划中提取尺寸，然后将它们输入到 Excel 工作表中。
听起来很简单，但我希望我的程序能够检测尺寸的上下文。例如，如果计划是一辆汽车，我希望我的程序说：“这个尺寸是车轮的尺寸，这个是左门的高度。”
我做了很多研究，但我发现自己迷失了方向。我甚至不确定我是否需要为此使用 AI...
我读过文档并观看了许多视频。我以为我会很容易找到解决方案，但对于我的情况，没有什么是很清楚的。
我很幸运，我已经拥有大量潜在 AI 的训练数据。
我主要是 .NET 开发人员，但如果真的有必要，我可以切换到 Python。
有人能告诉我应该遵循哪种方式吗？]]></description>
      <guid>https://stackoverflow.com/questions/78599084/automating-dimension-extraction-from-autocad-pdf-plans-with-context-detection</guid>
      <pubDate>Sun, 09 Jun 2024 16:23:48 GMT</pubDate>
    </item>
    <item>
      <title>如何提高多标签分类的准确度得分？</title>
      <link>https://stackoverflow.com/questions/78598665/how-to-improve-accuracy-score-in-multilabel-classification</link>
      <description><![CDATA[我想知道如何在多标签分类问题中提高准确率并降低损失。
如果你查看 sklearn 参考，你会发现在多类和多输出算法中提到了多标签，我现在正在测试它。
（https://scikit-learn.org/stable/modules/multiclass.html）
样本数据使用sklearn.datasets中的make_multilabel_classification有10个特征，通过修改n_classes创建一个数据集。
当multilabel有两个类时，似乎准确率和损失都比较令人满意。
from numpy import mean
from numpy import std
from sklearn.datasets import make_multilabel_classification
from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import accuracy_score, hamming_loss

# define dataset
X, y = make_multilabel_classification(n_samples=10000, n_features=10, n_classes=2, random_state=1)

# 总结数据集形状
print(X.shape, y.shape)
# 总结前几个示例
for i in range(10):
print(X[i], y[i])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
print(scaler.mean_)
print(scaler.var_)

x_train_std = scaler.transform(X_train)
x_test_std = scaler.transform(X_test)

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(x_train_std, y_train)

pred = knn.predict(x_test_std)

print(accuracy_score(y_test, pred))
print(hamming_loss(y_test, pred))

accuracy_score: 0.8345, hamming_loss: 0.08875
但是，随着类别数超过3，准确率得分逐渐下降，损失增加。
# define dataset
X, y = make_multilabel_classification(n_samples=10000, n_features=10, n_classes=3, random_state=1)

n_classes= 3 --&gt; accuracy_score: 0.772, hamming_loss: 0.116
n_classes= 4 --&gt; accuracy_score: 0.4875, hamming_loss: 0.194125
使用 RandomForestClassifier 算法时也是如此，如参考中所示，或者使用 ClassifierChain(estimator=SVC) 使用不支持多标签分类的算法时也是如此。
我想知道为什么会出现这种情况，以及如何调整超参数以提高准确性？]]></description>
      <guid>https://stackoverflow.com/questions/78598665/how-to-improve-accuracy-score-in-multilabel-classification</guid>
      <pubDate>Sun, 09 Jun 2024 13:03:31 GMT</pubDate>
    </item>
    <item>
      <title>Python 中事件/事件关系的关联规则</title>
      <link>https://stackoverflow.com/questions/78591986/association-rule-on-incident-event-relations-in-python</link>
      <description><![CDATA[我有两组数据：一个事件列表和一个已解决的事件列表，以及导致每个事件的事件。如何训练模型来预测哪个事件导致新事件发生？
例如，使用以下方法：
已解决的训练事件列表：



N°
服务来源
客户来源
...
事件来源




1
服务 A
人力资源团队
...
A345


2
服务 B
开发团队
...
B678


3
服务 A
外部
...
C901



培训活动列表：



N°
目标服务
变更生效
开发人员
...




A345
服务 A
函数重构
Mike I
...


U567
服务 C
函数弃用
Mike I
...


B678
服务 B
错误修复
John D
...


T234
服务 A
函数重构
Dave L
...


C901
服务 A
函数弃用
Dave L
...


V890
服务 B
错误修复
Mike I
...



我现在希望模型预测此事件的来源：



N°
服务来源
客户来源
...
事件源




4
服务 C
外部
...




来自此事件列表：



N°
目标服务
变更生效
开发人员
...




R123
服务 A
函数重构
Mike I
...


S456
服务 C
函数弃用
Mike I
...


T789
服务 C
错误修复
John D
...


]]></description>
      <guid>https://stackoverflow.com/questions/78591986/association-rule-on-incident-event-relations-in-python</guid>
      <pubDate>Fri, 07 Jun 2024 12:38:09 GMT</pubDate>
    </item>
    <item>
      <title>如果训练数据集中的正样本多于负样本，XGBoost 的 scale_pos_weight 是否可以正确平衡正样本？</title>
      <link>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我相信 scale_pos_weight 会是一种更好的方法。
是否可以安全地假设，由于比率小于 1，它仍将正确平衡类别？特异性在我的研究中很重要，但我们的主要目标集中在召回率、精确度和 F1 分数上。此设置是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在 Elixir Nx/Schorar 中进行 ELISA 分析？</title>
      <link>https://stackoverflow.com/questions/78565463/is-elisa-analysis-in-elixir-nx-schorar-possible</link>
      <description><![CDATA[我已阅读 Medium 上的文章 ELISA Analysis in Python。
上述文章使用 SciPy 的 curve_fit 函数根据 4 参数逻辑回归 (4PL) 模型找到近似曲线，如下所示：
from scipy.optimize import curve_fit

x = [1.95, 3.91, 7.381, 15.63, 31.25, 62.5, 125,250, 500, 1000]
y = [0.274, 0.347, 0.392, 0.420, 0.586, 1.115, 1.637, 2.227, 2.335, 2.372]

def log4pl(x, A, B, C, D):
return(((A - D) / (1.0 + ((x / C) ** B))) + D)

params, _ = curve_fit(log4pl, x, y)
A, B, C, D = params[0], params[1], params[2], params[3]

我想使用 Nx/Scholar Elixir 中的库。
可能吗？如果您能给我任何提示，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78565463/is-elisa-analysis-in-elixir-nx-schorar-possible</guid>
      <pubDate>Sun, 02 Jun 2024 04:29:18 GMT</pubDate>
    </item>
    <item>
      <title>通过单一数字指标训练 XGBoost</title>
      <link>https://stackoverflow.com/questions/78558863/training-xgboost-over-a-single-number-metric</link>
      <description><![CDATA[假设我正在用 Python（xgboost 版本 2.0.3）构建一个 XGBoost 模型（这里的回归或分类完全不重要）来预测股票市场时间序列分析中的目标变量。
例如，目标可能是：时间序列中的下一个值或二进制变量，如果下一个值高于前一个值，则设置为 1，否则设置为 0。
为了训练模型，是否可以使用回归问题中的 MSE 或分类问题中的“二元逻辑”。
训练后，可以根据测试集中模型的输出对策略进行回测并计算总体回报。
我的问题是：使用 xgboost scikit-learn 接口，是否可以根据用于回测策略的性能指标来训练模型？
例如：按照策略最大化训练集中的总体回报规则。
在xgboost库网站上，展示了如何使用自定义损失函数来训练模型：
def softprob_obj(labels: np.ndarray, predt: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
rows = labels.shape[0]
classes = predt.shape[1]
grad = np.zeros((rows, classes), dtype=float)
hess = np.zeros((rows, classes), dtype=float)
eps = 1e-6
for r in range(predt.shape[0]):
target = labels[r]
p = softmax(predt[r, :])
for c in range(predt.shape[1]):
g = p[c] - 1.0 if c == target else p[c]
h = max((2.0 * p[c] * (1.0 - p[c])).item(), eps)
grad[r, c] = g
hess[r, c] = h

grad = grad.reshape((rows * classes, 1))
hess = hess.reshape((rows * classes, 1))
return grad, hess

clf = xgb.XGBClassifier(tree_method=&quot;hist&quot;, objective=softprob_obj)

目标函数需要计算梯度和 hessian。
假设函数定义如下：
def maximum_performance_metric(y_true: np.ndarray, y_pred: np.ndarray):
# 指标计算（例如：使用 y_pred 计算总体回报
overall_return = get_overall_return(y_pred, real_prices, ...) #overall_return 是浮点数
return grad, hess


是否可以根据总体回报计算梯度和 hessian，然后使用此自定义损失训练模型函数？
函数 maximize_performance_metric() 如何访问包含 real_prices 的变量（需要整体回报计算）？]]></description>
      <guid>https://stackoverflow.com/questions/78558863/training-xgboost-over-a-single-number-metric</guid>
      <pubDate>Fri, 31 May 2024 08:14:07 GMT</pubDate>
    </item>
    <item>
      <title>tf.keras.callbacks.ModelCheckpoint 保存 HDF5 格式或 SavedModel 格式</title>
      <link>https://stackoverflow.com/questions/75587367/tf-keras-callbacks-modelcheckpoint-saves-hdf5-format-or-savedmodel-format</link>
      <description><![CDATA[save_weights_only=False 时，如何配置 tf.keras.callbacks.ModelCheckpoint 以保存 SavedModel 格式而不是 HDF5 格式？
与此相关的两个问题。我使用的是 TF2.4
https://github.com/tensorflow/tensorflow/issues/39679
https://github.com/keras-team/keras/issues/16657]]></description>
      <guid>https://stackoverflow.com/questions/75587367/tf-keras-callbacks-modelcheckpoint-saves-hdf5-format-or-savedmodel-format</guid>
      <pubDate>Tue, 28 Feb 2023 02:34:32 GMT</pubDate>
    </item>
    <item>
      <title>当观察次数有限时的时间序列预测</title>
      <link>https://stackoverflow.com/questions/59054968/time-series-prediction-when-you-have-limited-number-of-observations</link>
      <description><![CDATA[我在 Keras 中训练了一个 NN 来预测每周需求，并进行了所有超参数调整，我能得到的最好的结果就是下图。
我的理解是，由于两个原因，预测结果不好：

我没有足够的观察值（每周需求）
信号本身看起来非常随机，很难预测这种信号。

你有处理类似时间序列数据的经验吗？你有什么建议吗？
]]></description>
      <guid>https://stackoverflow.com/questions/59054968/time-series-prediction-when-you-have-limited-number-of-observations</guid>
      <pubDate>Tue, 26 Nov 2019 16:06:11 GMT</pubDate>
    </item>
    <item>
      <title>Opencv C++ 识别数字</title>
      <link>https://stackoverflow.com/questions/34122975/opencv-c-recognize-number</link>
      <description><![CDATA[这应该很容易。我正在研究 Sedoku 解算器，并试图弄清楚如何分辨我正在查看哪个数字。 

我能够隔离如上所示的数字。我只是无法使任何图像识别工作。我尝试过 Knearest 和一种称为 tesseract 的东西，但无济于事。有什么帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/34122975/opencv-c-recognize-number</guid>
      <pubDate>Sun, 06 Dec 2015 21:25:16 GMT</pubDate>
    </item>
    <item>
      <title>如何从 scikit-learn 决策树中提取决策规则？</title>
      <link>https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree</link>
      <description><![CDATA[我可以从决策树中经过训练的树中提取底层决策规则（或“决策路径”）作为文本列表吗？
类似于：
如果 A&gt;0.4，则如果 B&lt;0.2，则如果 C&gt;0.8，则 class=&#39;X&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree</guid>
      <pubDate>Tue, 26 Nov 2013 17:58:00 GMT</pubDate>
    </item>
    </channel>
</rss>