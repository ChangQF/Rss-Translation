<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 10 Jan 2024 18:17:59 GMT</lastBuildDate>
    <item>
      <title>我是 ML 新手，我有一个问题，是否有任何方法可以根据输入数据自动预测模型（如分类、回归、TS）？</title>
      <link>https://stackoverflow.com/questions/77795481/i-am-new-to-ml-i-have-a-question-is-there-is-any-way-to-predict-model-like-c</link>
      <description><![CDATA[我想知道我们根据输入数据预测模型的条件
可以根据输入数据自动预测模型（时间序列、回归、分类）。
像 pycaret 这样的库会有帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/77795481/i-am-new-to-ml-i-have-a-question-is-there-is-any-way-to-predict-model-like-c</guid>
      <pubDate>Wed, 10 Jan 2024 18:00:22 GMT</pubDate>
    </item>
    <item>
      <title>制作 XGBoost AOC 曲线时出现错误</title>
      <link>https://stackoverflow.com/questions/77795107/getting-an-error-when-making-xgboost-aoc-curve</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77795107/getting-an-error-when-making-xgboost-aoc-curve</guid>
      <pubDate>Wed, 10 Jan 2024 16:57:58 GMT</pubDate>
    </item>
    <item>
      <title>我应该在合并数据集之前还是合并数据集之后删除异常值？</title>
      <link>https://stackoverflow.com/questions/77795045/should-i-remove-outliers-before-combining-the-dataset-or-after-combining-the-dat</link>
      <description><![CDATA[我正在对自定义数据集进行一些探索性数据分析。我有 3 个不同的数据框：

df1 属于 0 类。
df2 属于类别 1。
df3 属于 2 类。

我正在组合数据帧上进行 k 均值聚类（通过组合 df1、df2、df3）。我应该在组合数据帧之前还是组合数据帧之后删除异常值？
我正在使用 IQR 技术删除异常值。在组合数据框之前我一直在这样做，但我想知道这是否是正确的方法。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77795045/should-i-remove-outliers-before-combining-the-dataset-or-after-combining-the-dat</guid>
      <pubDate>Wed, 10 Jan 2024 16:50:30 GMT</pubDate>
    </item>
    <item>
      <title>是什么导致 keras.model.evaluate 出现错误？不兼容的形状：[32] 与 [32,3]，并且“输出”必须具有等级 (ndim)“target.ndim - 1”</title>
      <link>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</guid>
      <pubDate>Wed, 10 Jan 2024 16:47:49 GMT</pubDate>
    </item>
    <item>
      <title>SHAP KernelExplainer 不接受 DMatrix 也不接受 numpy 数组</title>
      <link>https://stackoverflow.com/questions/77794688/shap-kernelexplainer-not-accepting-a-dmatrix-nor-a-numpy-array</link>
      <description><![CDATA[我正在尝试绘制我训练的 XGBoost 模型的 SHAP 分析图。类似于这个.
但是，我使用了 Dart booster，所以 shap.TreeExplainer 不起作用。然后，我尝试使用应该对我有用的 shap.KernelExplainer 。但是，它不接受任何常见类型的输入。
我的代码是这样的：
第一次尝试
# 要预测的数据
full_data = xgb.DMatrix(full_X, label=full_y, feature_names=feature_names)

# 使用 DART booster 预训练的 XGB 模型
loaded_model.set_param({“device”:“cuda”})


xgb_predict = lambda x:loaded_model.predict(x)
解释器 = shap.KernelExplainer(xgb_predict, full_data)

我得到：
TypeError：作为数据对象传递的未知类型：

第二次尝试
我还尝试提供一个 numpy 数组：
X_np = np.array(full_X)


解释器 = shap.KernelExplainer(xgb_predict, X_np)


但它也会返回一个错误：
TypeError: (&#39;期望数据是 DMatrix 对象，得到：&#39;, )


我使用的是 shap 0.44.0 和 xgboost 2.0.2
我不确定问题出在哪里。]]></description>
      <guid>https://stackoverflow.com/questions/77794688/shap-kernelexplainer-not-accepting-a-dmatrix-nor-a-numpy-array</guid>
      <pubDate>Wed, 10 Jan 2024 15:55:55 GMT</pubDate>
    </item>
    <item>
      <title>训练视频分类器</title>
      <link>https://stackoverflow.com/questions/77794520/training-a-video-classifier</link>
      <description><![CDATA[我有一个包含 80 个视频的训练数据集（没有增强）。它们是以 30fps 和 240*480 尺寸录制的 15 秒视频。训练分类模型有哪些选择？问题陈述是我有颤抖者的视频。我想按 1 - 3 级对震颤强度进行分类。请建议一些处理此问题的方法
我尝试过使用 3D CNN，但它需要过多的计算能力。我还尝试通过微调 Huggingface 中的预训练 VideoMAE 模型来训练模型，但它只接受 16 帧而不是 450 帧（15s * 30fps）。我尝试更改拱门，但它给了我内存错误。]]></description>
      <guid>https://stackoverflow.com/questions/77794520/training-a-video-classifier</guid>
      <pubDate>Wed, 10 Jan 2024 15:31:50 GMT</pubDate>
    </item>
    <item>
      <title>CNN最后一层的SVR</title>
      <link>https://stackoverflow.com/questions/77794156/svr-on-the-last-layer-of-cnn</link>
      <description><![CDATA[所以我正在尝试创建 CNN + SVR 模型来猜测手稿的制作日期。我正在使用 CNN 的 google 架构，现在如何将 SVR 添加到 CNN 的全连接层来猜测这个日期？
这是我对谷歌架构模型的修改版本：
在此处输入图片描述
嗯，我的第一个想法是提取特征向量，因为最后一层的 CNN 给了我 1x1x1024“图像”最后，但是支持向量回归真的接受特征向量吗？

所以，这里的旁注是我的数据库包含 1300-1600 年时期的拉丁手稿（遗憾的是并不是每年都会给出）。我尝试使用 SVR，因为我的模型应该允许 +-10 年的错误，因为显然很难猜测确切的年份
]]></description>
      <guid>https://stackoverflow.com/questions/77794156/svr-on-the-last-layer-of-cnn</guid>
      <pubDate>Wed, 10 Jan 2024 14:33:07 GMT</pubDate>
    </item>
    <item>
      <title>ValueError: Expected n_neighbors <= n_samples （指定的邻居数量与数据中的样本数量不匹配）</title>
      <link>https://stackoverflow.com/questions/77793613/valueerror-expected-n-neighbors-n-samples-mismatch-between-the-number-of-ne</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77793613/valueerror-expected-n-neighbors-n-samples-mismatch-between-the-number-of-ne</guid>
      <pubDate>Wed, 10 Jan 2024 13:05:17 GMT</pubDate>
    </item>
    <item>
      <title>如何计算两篇论文的loss一起</title>
      <link>https://stackoverflow.com/questions/77793412/how-to-calculate-the-loss-of-two-papers-together</link>
      <description><![CDATA[我的目的是把code2加入到code1中，在paper1的环境下一起计算loss，但是试了很多次都没能计算出结果
我认为关键是处理trainLoder和loss（局部变量和全局变量），如何定义它们？你能帮我解决这个问题吗？
code1：（计算paper1损失的代码）
对于范围内的纪元（args.epochs）：
        t = 时间.time()

        模型.train()
        优化器.zero_grad()
        moc、g1、g2、DGI_loss1、DGI_loss2 = 模型（特征、adj_norm、adj_tensor、drug_nums）
        标签 = adj_label.to_dense().view(-1)

        # BCEloss：监督损失
        BCEloss = torch.mean(loss_function_BCE(moc, labels) * adj_mask)
        BCEloss += torch.mean(loss_function_BCE(g1, labels) * adj_mask)
        BCEloss += torch.mean(loss_function_BCE(g2, labels) * adj_mask)
        打印（BCE损失）

code2:(计算paper2损失的代码)
对于范围内的 e(param.epoch)：
     运行损失 = 0.0 ###
     epo_标签 = []
     epo_分数 = []
     print(&quot;纪元：&quot;, e + 1)
     模型.train()
     开始 = 时间.time()
     对于 i，枚举（trainLoader）中的项目：
         数据，标签=项目
         train_data = data.cuda()
         true_label = label.cuda() ###
         pre_score = 模型(simData, train_data)##*
         train_loss = torch.nn.BCELoss()
         **损失 = train_loss(pre_score, true_label)**
         loss.backward()
         优化器.step()
         优化器.zero_grad()
         running_loss += loss.item() ###
         print(f&quot;批次 {i + 1} 后：loss= {loss:.3f};&quot;, end=&#39;\n&#39;)###

code3：（我试图将它们组合在一起的代码）
train_data = loading_data(参数)

simData = Simdata_pro(参数)
kfolds = 参数.kfold
train_labels = train_data[&#39;train_Labels&#39;]
状态=&#39;有效&#39;
#trainLoader=无
如果状态==&#39;有效&#39;：
    kf = KFold(n_splits=kfolds, shuffle=True, random_state=1)
    train_idx, valid_idx = [], []
    #trainLoader=无
    对于 train_index，kf.split(train_edges) 中的 valid_index：
        train_idx.append(train_index)
        valid_idx.append(valid_index)
    对于范围内的 i（kfolds）：
        Edges_train, Edges_valid = train_edges[train_idx[i]], train_edges[valid_idx[i]]
        labels_train, labels_valid = train_labels[train_idx[i]], train_labels[valid_idx[i]]
        trainEdges = CVEdgeDataset(edges_train, labels_train)
        trainLoader = DataLoader.DataLoader(trainEdges,batch_size=param.batchSize,shuffle=True,num_workers=0)
        # validLoader = DataLoader.DataLoader(validEdges, batch_size=param.batchSize, shuffle=True, num_workers=0)


        对于范围内的纪元（args.epochs）：
            t = 时间.time()

            模型.train()
            优化器.zero_grad()
            moc、g1、g2、DGI_loss1、DGI_loss2 = 模型（特征、adj_norm、adj_tensor、drug_nums）
            标签 = adj_label.to_dense().view(-1)

           ** # BCEloss：监督损失
            BCEloss = torch.mean(loss_function_BCE(moc, labels) * adj_mask)
            BCEloss += torch.mean(loss_function_BCE(g1, labels) * adj_mask)
            BCEloss += torch.mean(loss_function_BCE(g2, labels) * adj_mask)
            打印（&#39;BCEloss=&#39;）
            打印（BCE损失）**

   
            运行损失 = 0.0 ###
            epo_标签 = []
            epo_分数 = []
            print(&quot;纪元：&quot;, 纪元 + 1)
            模型.train()
            开始 = 时间.time()
            #损失=0
         # 新损失=0
            如果 trainLoader 不是 None：
                #损失=0
                for i, item in enumerate(trainLoader): ##i 是索引，item 是具体的值
                    数据，标签=项目
                    train_data = data.cuda()
                    true_label = label.cuda() ###
                    pre_score = 模型(simData, train_data) ##*
                    train_loss = torch.nn.BCELoss()
                   ** 损失 = train_loss(pre_score, true_label)**
                    loss.backward()
                    优化器.step()
                    优化器.zero_grad()
                    running_loss += loss.item() ###
                    print(f&quot;批次 {i + 1} 后：loss= {loss:.3f};&quot;, end=&#39;\n&#39;) ###

                新损失=BCE损失+损失
                打印（&#39;新损失=&#39;）
                打印（新损失）
                打印（&#39;损失&#39;）
                打印（丢失）
    

在哪里定义loss和trainLoder？]]></description>
      <guid>https://stackoverflow.com/questions/77793412/how-to-calculate-the-loss-of-two-papers-together</guid>
      <pubDate>Wed, 10 Jan 2024 12:34:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在 BART 模型中使用自定义嵌入？以及如何生成可由 BART 模型使用的位置嵌入？</title>
      <link>https://stackoverflow.com/questions/77792221/how-to-use-custom-embedding-in-bart-model-and-how-to-generate-positinal-embeddi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77792221/how-to-use-custom-embedding-in-bart-model-and-how-to-generate-positinal-embeddi</guid>
      <pubDate>Wed, 10 Jan 2024 09:28:11 GMT</pubDate>
    </item>
    <item>
      <title>如何进行标题预测？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77791809/how-can-i-perform-title-prediction</link>
      <description><![CDATA[我正在使用 python bert-base-uncased 模型基于句子创建标题。这是我写的代码。我需要根据possible_labels预测标题。有没有什么可能的方法可以根据possible_labels执行标题预测？
加载预训练的 BERT 模型和分词器以进行文本分类
从转换器导入 AutoTokenizer、AutoModelForSequenceClassification
进口火炬
model_name = “bert-base-uncased”；
tokenizer = AutoTokenizer.from_pretrained(model_name)
模型 = AutoModelForSequenceClassification.from_pretrained(model_name)

定义类标签
可能的标签 = [
    “问候”，
    《再见》，
    《表达谢意》，
    “道歉”，
    “请求”，
    “命令或指示”，
    “广告或促销”，
    “新闻更新”，
    “问题”，
    “积极情绪”，
    “负面情绪”，
    “中立声明”，
    # 根据需要添加更多标签
]

输入句子进行分类
text = “正在工作”

# 对输入句子进行分词和编码
编码输入 = 分词器（文本，return_tensors =“pt”）

# 进行预测
输出=模型（**编码输入）

# 获取预测的类别索引
Predicted_class_index = torch.argmax(output.logits, dim=1).item()

# 获取预测标签
预测标签=可能的标签[预测类别索引]

打印结果
print(“输入句子：”, text)
print(&quot;预测标签：&quot;, Predicted_label)

打印所有概率
概率 = torch.nn.function.softmax(output.logits, dim=1).tolist()[0]
对于标签，zip 中的概率（possible_labels，概率）：
    print(f“{label} 的概率：{prob:.4f}”)
]]></description>
      <guid>https://stackoverflow.com/questions/77791809/how-can-i-perform-title-prediction</guid>
      <pubDate>Wed, 10 Jan 2024 08:18:12 GMT</pubDate>
    </item>
    <item>
      <title>Handritten 数字识别算法前向传播中的矩阵乘法效率低下</title>
      <link>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</link>
      <description><![CDATA[我正在用 python 编写手写数字识别神经网络算法，而不使用预先编写的 ML 库。我目前正在尝试实现一个 DenseLayer 类，并在其中实现一个前向传播函数。我当前的功能如下所示。
类 DenseLayer：
  ...
  
  ...
  def for_prop(自身, input_data):
    self.input = input_data

    transpose_weights = self.weights.T
    # matMulComponent = np.matmul(input_data, transpose_weights)
    print(f&quot;转置形状：{transpose_weights.shape} 和输入形状 {input_data.shape}&quot;)
    matMulComponent = input_data.T @ transpose_weights
    打印（len（matMulComponent））

    z = matMulComponent + self.biases.T
    f_wb = self.act_fun(z)
    
    

    self.output = f_wb.reshape(-1, 1)
    print(f&quot;形状结果：{self.output.shape}&quot;)
    返回自身输出

问题是我正在进行大量的重塑和转置以获得结果。这似乎效率不高。
所以我的问题是：

这个实施起来好吗（因此会导致效率低下）
有没有更好的方法来实现这个前向传播函数

这就是我的输入数据数组的样子（我刚刚打印它并采取了 ss）。我供参考的输入数据是一个扁平的 28*28 数组，每个单元格代表一种颜色。我首先对数据进行标准化（z 分数标准化）
输入数据图像
如果有帮助的话，我还截取了第一层的权重格式的屏幕截图。 （请记住，它在 for_prop 函数中使用之前已被转置）。
第一个隐藏层的权重矩阵图片
前向传播似乎确实有效，但这很好：前向传播进度 ]]></description>
      <guid>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</guid>
      <pubDate>Wed, 10 Jan 2024 04:20:06 GMT</pubDate>
    </item>
    <item>
      <title>NLTK 词形还原器收到错误 BadZipFile：文件不是 zip 文件</title>
      <link>https://stackoverflow.com/questions/77790772/nltk-lemmatizer-received-error-badzipfile-file-is-not-a-zip-file</link>
      <description><![CDATA[我正在尝试使用 NLTK 包中的词形还原器，但出现此错误：
回溯（最近一次调用最后一次）：

  compat_exec 中的文件 /opt/anaconda3/lib/python3.8/site-packages/spyder_kernels/py3compat.py:356
    exec（代码、全局变量、局部变量）

  文件~/Documents/NLP course/exercise.py:21
    print(wn.lemmatize(&#39;平均值&#39;))

  lemmatize 中的文件 /opt/anaconda3/lib/python3.8/site-packages/nltk/stem/wordnet.py:45
    引理 = wn._morphy(word, pos)

  __getattr__ 中的文件 /opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py:121
    self.__load()

  __load 中的文件 /opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py:81
    root = nltk.data.find(f&quot;{self.subdir}/{self.__name}&quot;)

  查找文件/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py:555
    返回 find(修改后的名称, 路径)

  查找文件/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py:542
    返回 ZipFilePathPointer(p, zipentry)

  _decorator 中的文件 /opt/anaconda3/lib/python3.8/site-packages/nltk/compat.py:41
    返回 init_func(*args, **kwargs)

  __init__ 中的文件 /opt/anaconda3/lib/python3.8/site-packages/nltk/data.py:394
    zipfile = OpenOnDemandZipFile(os.path.abspath(zipfile))

  _decorator 中的文件 /opt/anaconda3/lib/python3.8/site-packages/nltk/compat.py:41
    返回 init_func(*args, **kwargs)

  __init__ 中的文件 /opt/anaconda3/lib/python3.8/site-packages/nltk/data.py:935
    zipfile.ZipFile.__init__(self, 文件名)

  __init__ 中的文件 /opt/anaconda3/lib/python3.8/zipfile.py:1269
    self._RealGetContents()

  _RealGetContents 中的文件 /opt/anaconda3/lib/python3.8/zipfile.py:1336
    raise BadZipFile(“文件不是 zip 文件”)

BadZipFile：文件不是 zip 文件

我的代码如下：
导入字符串
进口再
从 nltk.stem 导入 WordNetLemmatizer
wn = WordNetLemmatizer()

print(wn.lemmatize(&#39;平均值&#39;))
print(wn.lemmatize(&#39;含义&#39;))

到目前为止已采取措施但仍无法解决问题：

我尝试使用 conda uninstall nltk 卸载 nltk 软件包并重新下载
我还尝试删除 nltk_data 文件并使用 nltk.download() 再次下载该文件。我注意到随后弹出了下载文件的窗​​口，文件的状态为“已过时”，并且我还收到了错误“下载的 zip 文件出错”

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77790772/nltk-lemmatizer-received-error-badzipfile-file-is-not-a-zip-file</guid>
      <pubDate>Wed, 10 Jan 2024 03:19:26 GMT</pubDate>
    </item>
    <item>
      <title>如何将变量的每种组合纳入机器学习建模？</title>
      <link>https://stackoverflow.com/questions/77790711/how-to-get-every-combination-of-vars-into-ml-modeling</link>
      <description><![CDATA[假设我有 var a 和 b。我正在使用 var a 进行聚类，另一个使用 b 进行聚类，另一个使用 a 和 b 进行聚类。我不知道如何用 python 实现这个。
在下面的代码中，我添加了“#HAS TO BE AUTOMATED”我认为需要自动化的地方
示例数据：
    id 年龄 bp sg al 苏 rbc
0 0 48 80 1.020 1 0 1
1 1 7 50 1.020 4 0 1


id：建模中不需要
年龄 bp sg al su ：数字
rbc ：分类

将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
从 kmodes 导入 kprototypes

数据集 = pd.read_csv(..)
df=数据集.copy()


#删除不必要的列
df.drop(列=[“id”],inplace=True)

#标准化
columns_to_normalize = [&#39;age&#39;,&#39;bp&#39;,&#39;sg&#39;,&#39;al&#39;,&#39;su&#39;] #必须自动化
df[columns_to_normalize] = df[columns_to_normalize].apply(lambda x: (x - x.mean()) / np.std(x))


#获取值数组
data_array=df.值


#指定数据类型
data_array[:, 0:4] = data_array[:, 0:4].astype(float) #必须自动化
data_array[:, 5] = data_array[:, 5].astype(str) #必须自动化


#创建未经训练的模型
untrained_model = kprototypes.KPrototypes(n_clusters=2,max_iter=20)


#预测集群
集群 = untrained_model.fit_predict(data_array, categorical=[5])

数据集[“聚类标签”]=聚类
print(&quot;聚类后的数据是：&quot;)

]]></description>
      <guid>https://stackoverflow.com/questions/77790711/how-to-get-every-combination-of-vars-into-ml-modeling</guid>
      <pubDate>Wed, 10 Jan 2024 03:01:06 GMT</pubDate>
    </item>
    <item>
      <title>计算混淆矩阵的精度和召回率</title>
      <link>https://stackoverflow.com/questions/77785162/calculate-precision-and-recall-on-confusion-matrix</link>
      <description><![CDATA[正如主题所说，我必须计算混淆矩阵的精度和召回率。

我将如何继续使用这个矩阵来计算精度和召回率？]]></description>
      <guid>https://stackoverflow.com/questions/77785162/calculate-precision-and-recall-on-confusion-matrix</guid>
      <pubDate>Tue, 09 Jan 2024 08:04:36 GMT</pubDate>
    </item>
    </channel>
</rss>