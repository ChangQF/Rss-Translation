<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Dec 2023 21:12:07 GMT</lastBuildDate>
    <item>
      <title>在机器学习模型中对 NDVI 和 LST 数据使用相同的空间分辨率</title>
      <link>https://stackoverflow.com/questions/77705553/using-same-spatial-resolution-for-ndvi-and-lst-data-in-machine-learning-model</link>
      <description><![CDATA[我目前正在开发干旱预报机器学习模型，这是我第一次处理卫星数据。我的两个数据源是来自 Google Earth Engine 的用于获取 NDVI 值的 MOD13A1 数据集和用于获取 LST 值的 MOD11A1 数据集。感兴趣的区域是南加州。根据 Google Earth Engine，MOD13A1 的默认分辨率为 500m，而 MOD11A1 的默认分辨率为 1000m。
我是否需要对这两种产品使用相同的空间分辨率才能最大限度地提高模型的性能？如果是这样，那会是什么决议？
我尝试更改 NDVI 的 getRegion() 方法中的“scale”参数，当我这样做时，我得到了不同的值。这就是我提出问题的原因。]]></description>
      <guid>https://stackoverflow.com/questions/77705553/using-same-spatial-resolution-for-ndvi-and-lst-data-in-machine-learning-model</guid>
      <pubDate>Fri, 22 Dec 2023 19:46:46 GMT</pubDate>
    </item>
    <item>
      <title>我无法将数组传递给 svm 模型，它显示使用序列设置数组元素的错误</title>
      <link>https://stackoverflow.com/questions/77705514/i-am-not-able-to-pass-an-array-to-svm-model-it-is-showing-an-error-of-setting-an</link>
      <description><![CDATA[由于我正在处理音频数据集，所以首先我提取了 MFCC 特征并将其存储到列表中，然后我进行了填充和展平，我收到了此警告，但我忽略了它一段时间
我不能在这里将数据类型声明为对象，因为我必须在 Svm 模型中传递它
mfcc 功能及其数组的代码
SVM 代码：
svm 代码和错误
那么任何人都可以更正代码，以便我可以将其传递到我的 Svm 模型中，并且我可以进行音频分类吗？]]></description>
      <guid>https://stackoverflow.com/questions/77705514/i-am-not-able-to-pass-an-array-to-svm-model-it-is-showing-an-error-of-setting-an</guid>
      <pubDate>Fri, 22 Dec 2023 19:34:37 GMT</pubDate>
    </item>
    <item>
      <title>如何解决机器学习中的值错误？</title>
      <link>https://stackoverflow.com/questions/77705470/how-do-i-solve-a-value-error-in-machine-learning</link>
      <description><![CDATA[我正在尝试使用朴素贝叶斯选择和训练我的模型，并且正在处理糖尿病数据集，但我不断收到如下值错误：
ValueError Traceback（最近一次调用最后一次）
〜\ AppData \ Local \ Temp \ ipykernel_15552 \ 3536100043.py 在？（）
      1 模型 = GaussianNB()
----&gt; 2 model.fit(X_train, y_train)

〜\ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ sklearn \ naive_bayes.py 在？（自我，X，y，sample_weight）
    263 返回实例本身。
    第264章
    第265章
    266 y = self._validate_data(y=y)
--&gt; [第 267 章]
    第268章
    第269章）

〜\ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ sklearn \ naive_bayes.py 在？（自我，X，y，类，_refit，sample_weight）
    第424章
    第425章
    第426章
    第427章
--&gt;第428章
    第429章
    第430章
    第431章

〜\ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ sklearn \ base.py 在？（自我，X，y，重置，validate_separately，** check_params）
    [580] 第580章不在 check_y_params 中：
    第581章
    第582章
    第583章：
--&gt;第584章
    第585章
    第586章
    第587章

〜\ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ sklearn \ utils \ validation.py 中？（X，y，accept_sparse，accept_large_sparse，dtype，order，copy，force_all_finite，ensure_2d，allow_nd，multi_output， Ensure_min_samples、ensure_min_features、y_numeric、估计器）
   第1102章
   第1103章 1103
   第1104章）
   1105
-&gt;第1106章
   第1107章
   第1108章
   第1109章

〜\ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ sklearn \ utils \ validation.py 在？（数组，accept_sparse，accept_large_sparse，dtype，order，copy，force_all_finite，ensure_2d，allow_nd，ensure_min_samples，ensure_min_features，估计器，输入名称）
    第876章）
    第877章
    第878章：
    第879章
--&gt;第880章
    第881章
    第882章
    第883章）

〜\ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ sklearn \ utils \ _array_api.py 在？（数组，dtype，顺序，复制，xp）
    第181章
    182 xp，_ = get_namespace（数组）
    183 if xp.__name__ in {“numpy”,“numpy.array_api”}：
    [第 184 章] 第 184 章
--&gt; array[185] = numpy.asarray(数组, order=order, dtype=dtype)
    186 return xp.asarray(数组，复制=复制)
    187 其他：
    [第 188 章]

〜\ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ pandas \ core \ generic.py？（自我，dtype）
   1996 def __array__(self, dtype: npt.DTypeLike | None = None) -&gt; np.ndarray：
   1997 值 = self._values
-&gt; 1998 arr = np.asarray（值，dtype = dtype）
   1999 如果 (
   2000 astype_is_view（值.dtype，arr.dtype）
   2001 和 using_copy_on_write()

ValueError：无法将字符串转换为浮点数：&#39;F&#39;

我尝试再次运行所有代码单元，因为我使用的是 Jupyter Notebook，但结果与我不断得到的结果相同。]]></description>
      <guid>https://stackoverflow.com/questions/77705470/how-do-i-solve-a-value-error-in-machine-learning</guid>
      <pubDate>Fri, 22 Dec 2023 19:21:17 GMT</pubDate>
    </item>
    <item>
      <title>Keras 变分自动编码器的输入 (X) 和输出层 (Y) 不匹配，无法运行模型</title>
      <link>https://stackoverflow.com/questions/77705287/input-x-and-output-layers-y-of-keras-variational-autoencoder-dont-match-ca</link>
      <description><![CDATA[我正在尝试在 Keras 中构建一个变分自动编码器，输入形状为 X= (1,50) 和 Y= (1,20) .
我做了 2 个输入，一个用于 Y 的预测，第二个用于重建，我将用它来生成新的简单。重建训练得很好，但是模型无法学习。
0.77 中的 val_predictor_loss 堆栈
有什么问题吗？
这是我的代码：
&lt;前&gt;&lt;代码&gt;# %% [代码]
从 keras.layers 导入 Lambda、输入、密集、重塑、重复向量、丢弃
从 keras.models 导入模型
从 keras.datasets 导入 mnist
从 keras.losses 导入 mse，binary_crossentropy
从 keras.utils 导入plot_model
从 keras 导入后端为 K
从 keras.constraints 导入 unit_norm, max_norm
将张量流导入为 tf

从 scipy 导入统计数据
将 pandas 导入为 pd
将 numpy 导入为 np
导入 matplotlib
将 matplotlib.pyplot 导入为 plt
导入argparse
导入操作系统
从 sklearn.manifold 导入 MDS
从 sklearn.model_selection 导入 StratifiedKFold
从 sklearn.metrics 导入mean_squared_error, r2_score
从 keras.layers 导入输入、密集、扁平化、Lambda、Conv1D、BatchNormalization、MaxPooling1D、激活
从 keras.models 导入模型
将 keras.backend 导入为 K
将 numpy 导入为 np

从 mpl_toolkits.mplot3d 导入 Axes3D



# 重新参数化技巧
# 采样 eps = N(0,I)，而不是从 Q(z|X) 采样
# z = z_mean + sqrt(var)*eps
def 采样（参数）：
    “”“通过对各向同性单位高斯进行采样来重新参数化技巧。
    # 参数：
        args（张量）：Q(z|X) 的方差均值和对数
    # 返回：
        z（张量）：采样的潜在向量
    ”“”

    z_mean、z_log_var = args
    批次 = K.shape(z_mean)[0]
    暗淡 = K.int_shape(z_mean)[1]
    # 默认情况下，random_normal 的mean=0 和std=1.0
    epsilon = K.random_normal(shape=(batch, dim))
    thre = K.random_uniform(shape=(batch,1))
    返回 z_mean + K.exp(0.5 * z_log_var) * epsilon


# 加载我的数据
训练特征 = X
ground_truth_r = Y

np.random.seed(种子=0)
原始尺寸 = 32

# 定义VAE模型组件
输入形状_x = (32, )
输入形状_r = (16, )
中间暗度 = 32
潜伏暗度 = 32

# 编码器网络
input_x = 输入（形状=input_shape_x，名称=&#39;encoder_input&#39;）
input_x_dropout = Dropout(0.25)(inputs_x)
inter_x1 = 密集（128，激活=&#39;tanh&#39;）（inputs_x_dropout）
inter_x2 = 密集（intermediate_dim，激活=&#39;tanh&#39;）（inter_x1）
z_mean = 密集（latent_dim，名称=&#39;z_mean&#39;）（inter_x2）
z_log_var = 密集（latent_dim，名称=&#39;z_log_var&#39;）（inter_x2）
z = Lambda(采样, output_shape=(latent_dim,), name=&#39;z&#39;)([z_mean, z_log_var])
编码器 = 模型(inputs_x, [z_mean, z_log_var, z], name=&#39;编码器&#39;)

# 用于重建的解码器网络
Latent_inputs = 输入（形状=（latent_dim，），名称=&#39;z_sampling&#39;）
inter_y1 = 密集（intermediate_dim，激活=&#39;tanh&#39;）（latent_inputs）
inter_y2 = 密集（128，激活=&#39;tanh&#39;）（inter_y1）
输出重建 = 密集（original_dim）（inter_y2）
解码器=模型（latent_inputs，outputs_reconstruction，name=&#39;解码器&#39;）

# 将预测网络与潜在空间分开
outputs_prediction = Dense(Y.shape[1])(inter_y2) # 根据您的数据调整 Y.shape[1]
预测器=模型（潜在输入，输出预测，名称=&#39;预测器&#39;）

# 实例化具有两个输出的 VAE 模型
outputs_vae = [解码器（编码器（inputs_x）[2]），预测器（编码器（inputs_x）[2]）]
vae = 模型(inputs_x,outputs_vae,name=&#39;vae_mlp&#39;)
vae.compile(optimizer=&#39;adam&#39;, loss=[&#39;mean_squared_error&#39;, &#39;mean_squared_error&#39;])

# 训练模型
历史记录 = vae.fit(X, [X, Y], epochs=200, batch_size=64, shuffle=True,validation_data=(XX,[XX, YY]))
]]></description>
      <guid>https://stackoverflow.com/questions/77705287/input-x-and-output-layers-y-of-keras-variational-autoencoder-dont-match-ca</guid>
      <pubDate>Fri, 22 Dec 2023 18:31:14 GMT</pubDate>
    </item>
    <item>
      <title>输入数据耗尽，中断张量流训练</title>
      <link>https://stackoverflow.com/questions/77705086/input-ran-out-of-data-interrupting-training-in-tensorflow</link>
      <description><![CDATA[我正在从事肿瘤分割工作，图像是 nifti 格式的 3D（MRI 图像）。我创建了一个数据生成器，因为如果我将完整数据集上传到 RAM，它会因 3D 图像而崩溃。该数据集由611张图像组成，尺寸为（240,240,160），计算时的块数为61000和11375
这是我的数据管道：
def load_nifti_image(文件路径, patch_size=(48, 48, 32), step_size=(48, 48, 32)):
    nifti = nib.load(文件路径)
    体积 = nifti.get_fdata()

    # 从卷创建补丁
    补丁 = patchify(体积, patch_size, 步骤=step_size)

    # 重塑 patch 相乘 (5, 5, 5) 并添加通道维度（1 表示灰度）
    补丁 = patchs.reshape(-1, *patches.shape[-3:])
    补丁= np.expand_dims（补丁，轴=-1）

    返回补丁

＃  -  -  -  -  -  -  -  -  -  -  - -火车 -  -  -  -  -  -  -  -  -  -  - -
nifti_files = [os.path.join(“/content/drive/MyDrive/Interpolated/train/images”, f) for f in os.listdir(“/content/drive/MyDrive/Interpolated/train/images”) if f.endswith(&#39;.nii.gz&#39;)]
mask_files = [os.path.join(“/content/drive/MyDrive/Interpolated/train/masks”, f) for f in os.listdir(“/content/drive/MyDrive/Interpolated/train/masks”) if f.endswith(&#39;.nii.gz&#39;)]

 ＃  -  -  -  -  -  -  -  -  -  -  - -验证 -  -  -  -  -  -  -  -  -  -  - -
nifti_files_val = [os.path.join(&quot;/content/drive/MyDrive/Interpolated/validation/images&quot;, f) for f in os.listdir(&quot;/content/drive/MyDrive/Interpolated/validation/images&quot;) if f.endswith(&#39;.nii.gz&#39;)]
mask_files_val = [os.path.join(“/content/drive/MyDrive/Interpolated/validation/masks”, f) for f in os.listdir(“/content/drive/MyDrive/Interpolated/validation/masks”) if f.endswith(&#39;.nii.gz&#39;)]

defcalculate_patches(文件路径, patch_size=(48, 48, 32), step_size=(48, 48, 32)):
    nifti = nib.load(文件路径)
    体积 = nifti.get_fdata()

    # 计算补丁数量
    patch_shape = [((i - p) // s) + 1 for i, p, s in zip(volume.shape, patch_size, step_size)]
    num_patches = np.prod(patches_shape)

    返回 num_patches

num_train_patches = sum(calculate_patches(f) for i, f in enumerate(nifti_files) if print(f“处理文件 {i}...”) 为 None)
num_val_patches = sum(calculate_patches(f) for i, f in enumerate(nifti_files_val) if print(f“处理文件 {i}...”) 为 None)

def data_generator(image_files, mask_files):
    对于 zip(image_files, mask_files) 中的 img_file、mask_file：
        image_patches = load_nifti_image(img_file)
        mask_patches = load_nifti_image(mask_file)

        对于 zip(image_patches, mask_patches) 中的 img_patch、mask_patch：
            产量 img_patch, mask_patch

train_generator = data_generator(nifti_files, mask_files)
val_generator = data_generator(nifti_files_val, mask_files_val)

输出签名 = (
    tf.TensorSpec(形状=(48, 48, 32, 1), dtype=tf.float64),
    tf.TensorSpec(形状=(48, 48, 32, 1), dtype=tf.float64)
）

数据集= tf.data.Dataset.from_generator（lambda：train_generator，output_signature=output_signature）.repeat（）
dataset_val = tf.data.Dataset.from_generator(lambda: val_generator, output_signature=output_signature).repeat()

数据集=数据集.batch(32)
dataset_val = dataset_val.batch(32)

test_model.fit（数据集，validation_data=dataset_val，epochs=100，steps_per_epoch=num_train_patches//32，validation_steps=num_val_patches//32）

我添加了 .repeat() 希望它能有所帮助，但事实并非如此。
我还尝试计算补丁的数量并手动插入它们，但它也不起作用。
这是完整的回溯：
纪元 1/100
1906/1906 [================================] - 1963s 1s/步 - 损失：0.6447 - dice_coefficient：0.3553 - val_loss ：0.9113 - val_dice_系数：0.0887
纪元 2/100
   1/1906 [................................] - 预计到达时间：10:17 - 损失：1.0000 - dice_coefficient：1.7961e -05

警告：tensorflow：您的输入数据不足；中断训练。确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次（在本例中为 190600 个批次）。构建数据集时，您可能需要使用 Repeat() 函数。
警告：tensorflow：您的输入数据不足；中断训练。确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次（在本例中为 355 个批次）。构建数据集时，您可能需要使用 Repeat() 函数。

1906/1906 [================================] - 0s 31us/步 - 损失：1.0000 - dice_coefficient：1.7961e- 05


]]></description>
      <guid>https://stackoverflow.com/questions/77705086/input-ran-out-of-data-interrupting-training-in-tensorflow</guid>
      <pubDate>Fri, 22 Dec 2023 17:43:32 GMT</pubDate>
    </item>
    <item>
      <title>在本地计算机上使用 jupyter lab 时卡在 train_data_loader 中</title>
      <link>https://stackoverflow.com/questions/77704959/stuck-in-the-train-data-loader-while-using-jupyter-lab-on-local-machine</link>
      <description><![CDATA[已经过去几个小时了，但我的代码根本没有运行，在任务管理器的 CPU 资源中，它显示 python 使用的资源为零。
在kaggle笔记本中使用相同的代码时，它工作得很好。
这是什么问题。
&lt;前&gt;&lt;代码&gt;
# 训练数据集样本
对于图像，目标在 (train_data_loader) 中：
    休息
images = list(image.to(device) 用于图像中的图像)
目标 = [{k: v.to(device) for k, v in t.items()} for t in Targets]

对于 random.sample([1,2,3],3) 中的数字：
  框 = 目标[数字][&#39;框&#39;].cpu().numpy().astype(np.int32)
  img = 图片[数字].permute(1,2,0).cpu().numpy()
  标签=目标[数字][&#39;标签&#39;].cpu().numpy().astype(np.int32)
  图, ax = plt.subplots(1, 1, Figsize=(16, 8))

  对于范围内的 i(len(boxes))：
      img = cv2.rectangle(img,(boxes[i][0]+paddingSize,boxes[i][1]+paddingSize),(boxes[i][2]+paddingSize,boxes[i][3]+paddingSize ),(255,0,0),2)
      #print(le.inverse_transform([labels[i]-1])[0])
      #print(label_to_name(标签[i]), (int(boxes[i][0]), int(boxes[i][1])))
      img = cv2.putText(img, label_to_name(labels[i]), (int(boxes[i][0]), int(boxes[i][1])), cv2.FONT_HERSHEY_TRIPLEX,1, (255,0 ,0), 2, cv2.LINE_AA)

  ax.set_axis_off()
  斧头.imshow(img)

训练数据加载器代码：
# 将数据集拆分为训练集和测试集
索引 = torch.randperm(len(train_dataset)).tolist()
# 创建训练并验证数据加载器
train_data_loader = 数据加载器(
    训练数据集，
    批量大小=8，
    随机播放=真，
    工人数=12，
    collat​​e_fn=整理_fn
）

valid_data_loader = 数据加载器(
    有效数据集，
    批量大小=8，
    随机播放=假，
    工人数=12，
    collat​​e_fn=整理_fn
）

创建数据集的代码
class MalariaDataset(torch.utils.data.Dataset)：
    def __init__(自身、数据、变换=无):
        超级().__init__()
        ”“”
        输入
            数据：数据框
            转换：撰写或列表
                Torchvision 图像转换。
        ”“”
        self.data = 数据
        self.transforms = 变换
        self.label_dict = label_dict
    def __getitem__(self, idx):
        img_path = self.data.pathname.unique()[idx]
        
        ann_df = self.data[self.data.pathname == img_path]
        
        图像 = plt.imread(img_path)*255
        
            
        盒子=[]
        标签=[]
        对于 _，ann_df.iterrows() 中的行：
            x1 = 行[&#39;x1&#39;]
            y1 = 行[&#39;y1&#39;]
            x2 = 行[&#39;x2&#39;]
            y2 = 行[&#39;y2&#39;]
            标签=行[&#39;类名&#39;]
            
            box.append([x1, y1, x2, y2])
            labels.append(标签)
            
        盒子 = np.array(盒子)
        面积 = (盒子[:, 3] - 盒子[:, 1]) * (盒子[:, 2] - 盒子[:, 0])
        面积 = torch.as_tensor(面积, dtype=torch.float32)
        
        标签 = torch.as_tensor(标签, dtype=torch.int64)
            
        
        目标={}
        目标[&#39;盒子&#39;] = 盒子
        目标[&#39;标签&#39;] = 标签
        目标[&#39;区域&#39;] = 区域
        如果自我变换：
            样本={
                    “图像”：图像，
                    &#39;bboxes&#39;：目标[&#39;boxes&#39;]，
                    ‘标签’：标签
            }
            样本 = self.transforms(**样本)
            图像 = 样本[&#39;图像&#39;]
            
        
            target[&#39;boxes&#39;] = torch.tensor(sample[&#39;bboxes&#39;])
        返回（图像，目标）
    def __len__(自身):
        返回 self.data.pathname.unique().shape[0]


我尝试使用 Kaggle 笔记本，代码运行良好]]></description>
      <guid>https://stackoverflow.com/questions/77704959/stuck-in-the-train-data-loader-while-using-jupyter-lab-on-local-machine</guid>
      <pubDate>Fri, 22 Dec 2023 17:09:35 GMT</pubDate>
    </item>
    <item>
      <title>NLP 模型从未下载过</title>
      <link>https://stackoverflow.com/questions/77704834/nlp-model-never-downloaded</link>
      <description><![CDATA[我正在 Mac (M1 Max) 上工作并尝试一些文本增强技术。然而，当我尝试进行一些嵌入时，我的 Python 被卡住了，无法下载任何内容 —— 等待 30 分钟后，它仍然是 0%。如何解决？
]]></description>
      <guid>https://stackoverflow.com/questions/77704834/nlp-model-never-downloaded</guid>
      <pubDate>Fri, 22 Dec 2023 16:40:52 GMT</pubDate>
    </item>
    <item>
      <title>Resnet34第一层7x7或3x3</title>
      <link>https://stackoverflow.com/questions/77704426/resnet34-first-layer-7x7-or-3x3</link>
      <description><![CDATA[我一直在尝试使用 pytorch 实现 Resnet34，但在查看其他实现时，我发现其中一些具有 3x3 卷积层 + bn + relu 作为第一层。然而，架构图上却写着7x7/2的卷积层。我真的很困惑哪一个是正确的。顺便说一下，我正在 CIFAR10 上进行训练，目前使用 7x7 卷积层经过 100 个周期后获得了 0.9 的准确率。
谢谢！
架构图
self.input_layer = nn.Sequential(
nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False),
nn.BatchNorm2d(64),
ReLU(),
nn.MaxPool2d(3, 步长=2, 填充=1)
）

这是我的第一个卷积层的代码。]]></description>
      <guid>https://stackoverflow.com/questions/77704426/resnet34-first-layer-7x7-or-3x3</guid>
      <pubDate>Fri, 22 Dec 2023 15:14:50 GMT</pubDate>
    </item>
    <item>
      <title>对新数据集进行预测</title>
      <link>https://stackoverflow.com/questions/77704141/make-prediction-on-new-data-set</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77704141/make-prediction-on-new-data-set</guid>
      <pubDate>Fri, 22 Dec 2023 14:13:16 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络不学习</title>
      <link>https://stackoverflow.com/questions/77704108/convolutional-neural-network-not-learning</link>
      <description><![CDATA[我正在尝试在包含 1500 张图像（15 个类别）的训练集上训练用于图像识别的卷积神经网络。有人告诉我，采用这种架构和从均值为 0、标准差为 0.01 的高斯分布得出的初始权重以及初始偏差值为 0 的情况，在适当的学习率下，它应该达到 30 左右的准确度%。
但是，它根本没有学到任何东西：准确率与随机分类器相似，并且训练后的权重仍然遵循正态分布。我做错了什么？
这是神经网络
class simpleCNN(nn.Module)：
  def __init__(自身):
    super(simpleCNN,self).__init__() #初始化模型

    self.conv1=nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=1) #输出图像大小为(size+2*padding-kernel)/stride --&gt;62*62
    self.relu1=nn.ReLU()
    self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2) #输出图像62/2--&gt;31*31

    self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=1) #输出图像为29*29
    self.relu2=nn.ReLU()
    self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2) #输出图像为29/2--&gt;14*14（MaxPool2d近似大小与floor）

    self.conv3=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1) #输出图像为12*12
    self.relu3=nn.ReLU()

    self.fc1=nn.Linear(32*12*12,15) #16 个通道 * 16*16 图像（64*64，步幅为 2 的 2 个 maxpooling），15 个输出特征=15 个类
    self.softmax = nn.Softmax(dim=1)

  def 前向（自身，x）：
    x=self.conv1(x)
    x=self.relu1(x)
    x=self.maxpool1(x)

    x=self.conv2(x)
    x=self.relu2(x)
    x=self.maxpool2(x)

    x=self.conv3(x)
    x=self.relu3(x)

    x=x.view(-1,32*12*12)

    x=self.fc1(x)
    x=self.softmax(x)

    返回x

初始化：
def init_weights(m):
  如果 isinstance(m,nn.Conv2d) 或 isinstance(m,nn.Linear)：
    nn.init.normal_(m.weight,0,0.01)
    nn.init.zeros_(m.bias)

模型 = simpleCNN()
模型.应用（init_weights）

训练函数：
loss_function=nn.CrossEntropyLoss()
优化器=optim.SGD(model.parameters(),lr=0.1,动量=0.9)

def train_one_epoch(epoch_index,loader):
  运行损失=0

  对于 i，枚举（加载器）中的数据：

    input,labels=data #获取小批量
    输出=模型（输入）#前向传递

    loss=loss_function(outputs,labels) #计算损失
    running_loss+=loss.item() #总结到目前为止处理的小批量的损失

    Optimizer.zero_grad() #重置梯度
    loss.backward() #计算梯度
    optimizer.step() #更新权重

  return running_loss/(i+1) # 每个小批量的平均损失


培训：
&lt;前&gt;&lt;代码&gt;纪元=20

best_validation_loss=np.inf

对于范围内的纪元（EPOCHS）：
  print(&#39;纪元{}:&#39;.format(纪元+1))

  模型.train(True)
  train_loss=train_one_epoch(epoch,train_loader)

  运行验证损失=0.0

  模型.eval()

  with torch.no_grad(): # 禁用梯度计算并减少内存消耗
    对于 i，枚举中的 vdata（validation_loader）：
      vinputs,vlabels=vdata
      v输出=模型（v输入）
      vloss=loss_function(v输出,v标签)
      running_validation_loss+=vloss.item()
  验证损失=运行验证损失/(i+1)
  print(&#39;LOSS 训练：{} 验证：{}&#39;.format(train_loss,validation_loss))

  if validation_loss
使用默认初始化，效果会好一些，但使用高斯应该可以达到 30%。
您能发现一些可能导致它无法学习的问题吗？我已经尝试过不同的学习率和动力。]]></description>
      <guid>https://stackoverflow.com/questions/77704108/convolutional-neural-network-not-learning</guid>
      <pubDate>Fri, 22 Dec 2023 14:06:23 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：微调 LLM 时需要解包的值太多（预期为 2）</title>
      <link>https://stackoverflow.com/questions/77702885/valueerror-too-many-values-to-unpack-expected-2-when-fine-tuning-an-llm</link>
      <description><![CDATA[我正在学习如何微调法学硕士。但是，无论我如何修改数据处理方法，在微调过程中执行 Trainer.train() 时都会遇到一致的错误。错误如下：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-11-3435b262f1ae&gt;在&lt;细胞系：1&gt;()
----&gt; 1 个训练器.train()

12帧
/usr/local/lib/python3.10/dist-packages/transformers/modeling_attn_mask_utils.py 在 _expand_mask(mask, dtype, tgt_len)
    152 将attention_mask从“[bsz，seq_len]”扩展到“[bsz，1，tgt_seq_len，src_seq_len]”。
    第153章
--&gt;第154章
    [第 155 章]
    156

ValueError：需要解压的值太多（预期为 2）

表明扩展注意力掩码时出现问题。该错误消息表明解压值时出现问题，期望有两个值，但得到更多。
我检查了我的注意力蒙版的尺寸，它似乎是二维的，我认为这是正确的。以下是我的一项数据条目的示例：
{&#39;input_ids&#39;: 张量([[ ...张量值... ]]),
 &#39;attention_mask&#39;: 张量([[1, 1, 1, ... 0, 0]])}


我正在使用格式如下的数据集：
&lt;前&gt;&lt;代码&gt;{
“id”：“聊天1”，
“对话”：[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好，你好吗？&quot;},
{“角色”：“助理”，“内容”：“我做得很好。今天我能为您提供什么帮助吗？”},
{“角色”：“用户”，“内容”：“我想展示聊天模板的工作原理！”}
]
}

这是我的脚本：
导入json
从变压器导入 AutoTokenizer、AutoModelForCausalLM、Trainer、TrainingArguments
从 torch.utils.data 导入数据集
进口火炬

file_path = &#39;/content/gdrive/MyDrive/kirin.json&#39;
以 open(file_path, &#39;r&#39;) 作为文件：
    数据 = json.load(文件)

tokenizer = AutoTokenizer.from_pretrained(“/content/gdrive/MyDrive/ColabNotebooks/Taiwan-LLM-7B-v2.0.1-chat”)
模型 = AutoModelForCausalLM.from_pretrained(“/content/gdrive/MyDrive/ColabNotebooks/Taiwan-LLM-7B-v2.0.1-chat”)

def format_conversation（对话）：
    格式化=“”
    轮流对话[&#39;对话&#39;]：
        格式化+=转[&#39;角色&#39;]+&quot;:&quot; + 转[&#39;内容&#39;] + &quot;\n&quot;
    返回格式化的.strip()

formatted_data = [数据中的转换的format_conversation(conv)]

类 ConversationDataset（数据集）：
    def __init__(自身、转换、分词器、max_length=512):
        self.tokenizer = 分词器
        self.inputs = [tokenizer(text, return_tensors=“pt”, max_length=max_length, truncation=True, padding=“max_length”) 用于转换中的文本]

    def __len__(自身):
        返回 len(self.inputs)

    def __getitem__(self, idx):
        返回 self.inputs[idx]

数据集 = ConversationDataset(formatted_data, tokenizer)

训练参数 = 训练参数（
    output_dir=&quot;./llama2-finetuned&quot;,
    num_train_epochs=3,
    per_device_train_batch_size=1,
    保存步骤=10_000，
    save_total_limit=2,
）

教练=教练（
    型号=型号，
    参数=训练参数，
    train_dataset=数据集
）
训练师.train()


]]></description>
      <guid>https://stackoverflow.com/questions/77702885/valueerror-too-many-values-to-unpack-expected-2-when-fine-tuning-an-llm</guid>
      <pubDate>Fri, 22 Dec 2023 09:48:31 GMT</pubDate>
    </item>
    <item>
      <title>用于实时流处理的 Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</link>
      <description><![CDATA[我正在 aws 上对实时视频流进行实时机器学习处理。
对于直播，正在使用 kinesis 视频流。
我正在从模型工件（存储我们的推理脚本和模型文件的位置）创建 sagemaker 端点
当我们从实时流中获取它们时，每个帧都会独立调用此端点。
挑战在于维护变量的缓存/会话状态。当每个帧到达端点时，它没有有关先前运行的结果的信息。为了解决这个问题，我为每次调用下载缓存并将其上传到数据库（dynamo db），这似乎是一种低效的方法。
我想探索是否有某种方式 - 实例在整个直播流中处于活动状态，每当实例接收到帧时，都会对其进行处理，缓存将一直存在，直到实例死亡？
而不是为每个帧单独流调用端点。
供参考 - 我在推理脚本中使用 pytorch 框架中外部训练的 YOLO 对象检测模型。]]></description>
      <guid>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</guid>
      <pubDate>Fri, 22 Dec 2023 08:28:38 GMT</pubDate>
    </item>
    <item>
      <title>使用 Camera Flutter 应用程序进行实时绘画识别</title>
      <link>https://stackoverflow.com/questions/77691918/live-paintings-recognition-with-camera-flutter-app</link>
      <description><![CDATA[我正在开发一个带有 flutter 的应用程序，我需要实现使用智能手机摄像头实时识别一些绘画（从完成的集合中）并在屏幕上显示一些弹出按钮的可能性，该按钮可能会重定向到网页你描述这幅画的地方。
在网上搜索了一下，第一个解决方案是使用机器学习实时对象识别模型，但对我来说似乎有点太复杂了。因此，我的问题是：考虑到要识别的绘画作品集很小而且确实有限，是否有更简单的方法？
千谢万谢
我查看了这个软件包，但它似乎有点太复杂https://pub.dev/packages/google_mlkit_object_detection ]]></description>
      <guid>https://stackoverflow.com/questions/77691918/live-paintings-recognition-with-camera-flutter-app</guid>
      <pubDate>Wed, 20 Dec 2023 13:25:40 GMT</pubDate>
    </item>
    <item>
      <title>如何训练 Yolo 识别训练数据集中没有的类？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77690929/how-to-train-yolo-to-recognize-classes-that-are-not-in-the-training-dataset</link>
      <description><![CDATA[我最近开始研究计算机视觉。有一家企业需要摄像头判断员工是否佩戴个人防护用品。不幸的是，绝对不可能在违规者的数据中组装这些摄像机的训练数据集，因为每个人都遵守安全规则。训练后，模型将只能识别穿着个人防护装备（头盔、手套等）的人。如何训练 Yolo 以便她能够识别违规行为？请提出任何解决此问题的方法。
根据我的想法，第一个是使用隔离森林，但我必须将图像转换为向量空间，或者以某种方式使用 IoU。]]></description>
      <guid>https://stackoverflow.com/questions/77690929/how-to-train-yolo-to-recognize-classes-that-are-not-in-the-training-dataset</guid>
      <pubDate>Wed, 20 Dec 2023 10:43:43 GMT</pubDate>
    </item>
    <item>
      <title>尝试通过回归来预测算法的运行时间</title>
      <link>https://stackoverflow.com/questions/65862139/trying-to-predict-running-time-of-algorithms-through-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/65862139/trying-to-predict-running-time-of-algorithms-through-regression</guid>
      <pubDate>Sat, 23 Jan 2021 17:19:51 GMT</pubDate>
    </item>
    </channel>
</rss>