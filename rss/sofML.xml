<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 08 Jul 2024 06:22:27 GMT</lastBuildDate>
    <item>
      <title>POintNet++ 实现</title>
      <link>https://stackoverflow.com/questions/78719320/pointnet-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78719320/pointnet-implementation</guid>
      <pubDate>Mon, 08 Jul 2024 06:10:06 GMT</pubDate>
    </item>
    <item>
      <title>如何将模板草图与制造零件的图像进行比较？</title>
      <link>https://stackoverflow.com/questions/78718809/how-do-i-compare-a-template-sketch-to-an-image-of-a-manufactured-part</link>
      <description><![CDATA[我有一个模板图像，用作基准来确定零件在电路板上的焊接位置。我无法保证图像具有相同的大小或比例。基准图像由外部来源提供给我，我自己焊接零件。焊接板的图像是我拍摄的。我想快速检查错误 - 应该放置但实际上没有放置的零件、应该跳过但实际上没有放置的零件等。
我希望在错误的零件上有一个边界框。我已附上两张描绘有问题的图像的图像（根据我的工作政策，我无法提供真实图像）。PCB 和 模板。
红色方框表示我不应该放置的部件，绿色方框表示我应该放置的部件。
我遵循了此处的信息。我尝试使用结构相似性指数。由于图像彼此之间差异很大，因此效果不佳。
我不认为密集向量表示对我有用，因为它会得出相似性分数，而不是暴露所犯的任何错误。
理想情况下，我可以从 SSI 方法生成输出以显示遗漏了哪些问题。]]></description>
      <guid>https://stackoverflow.com/questions/78718809/how-do-i-compare-a-template-sketch-to-an-image-of-a-manufactured-part</guid>
      <pubDate>Mon, 08 Jul 2024 01:28:36 GMT</pubDate>
    </item>
    <item>
      <title>对键盘上的按键数据历史进行分类，以识别不适当的内容（对计算机有危险）</title>
      <link>https://stackoverflow.com/questions/78718328/classification-of-key-press-data-history-on-the-keyboard-to-identify-inappropria</link>
      <description><![CDATA[最近，我从计算机视觉转向了 NLP 任务。
我收集了一组以 ASCII 文本文件形式记录的按键数据历史记录，记录了用户在会话期间的每次击键。目标是对这些数据进行分类，以检测不适当的内容，例如尝试下载病毒、访问非法网站等。
注意：

高噪声水平：按键数据历史文件包含大量噪声，这是由于频繁的嘈杂按键（例如，用户在玩游戏时按“wasd”）造成的，因此很难提取有意义的文本。

多语言输入：我想为多种语言进行输入。
例如，用户可能会输入“crfxfnm dbhec” （另一种语言的短语，含义为“下载病毒”，使用经典英语键盘布局）


我尝试使用预训练的 BERT 模型对原始数据进行文本分类，预测两个类别：正上下文和负上下文。但是，这种方法不起作用。
此外，我还探索了原始数据（相同的预训练 BERT 模型）上的 token 分类结果，噪声数据中的真实单词被突出显示。仍然希望能够准确识别 token。
基于 Transformer 的分类器（例如 Hugging Face 的 BERT）能否有效处理和标记这种类型的噪声和多语言输入？token 分类任务是否可行？因此，我们有原始数据的 token 分类任务
是否应该清理数据集以删除这些噪声字符，如何清理？训练模型进行文本分类之后如何清理？因此，我们有两个主要步骤：过滤 + 文本分类任务。使用经典 ML + NN 进行过滤以进行文本分类？
是否有必要为每种语言训练单独的模型，在训练之前可能将字符转换为其真实语言？
如何为训练模型形成合成数据集？手动标记听起来很疯狂]]></description>
      <guid>https://stackoverflow.com/questions/78718328/classification-of-key-press-data-history-on-the-keyboard-to-identify-inappropria</guid>
      <pubDate>Sun, 07 Jul 2024 20:15:34 GMT</pubDate>
    </item>
    <item>
      <title>评估无监督学习 - 播放列表生成器应用程序[关闭]</title>
      <link>https://stackoverflow.com/questions/78718024/evaluate-unsupervised-learning-playlist-generator-app</link>
      <description><![CDATA[我正在为我的简历做一个项目，我想创建一个播放列表生成器应用程序。该应用程序将接收一个播放列表作为输入，并生成一个适合作为输出的播放列表。我的数据将包括从 Spotify for Developers API 中提取的歌曲名称、歌词和歌曲属性，数据集大小约为 150K 个条目。
我正在考虑使用 K-means 来完成这个无监督任务（或另一种无监督算法），以便对于给定的播放列表输入，我可以将歌曲分类为标签，然后从同一标签中选择相似的歌曲。然而，我开始认为这可能会有问题，因为我不知道事后如何评估我的模型。我无法手动创建带标签的测试数据，因为这对我来说不可行，即使可以，给定的播放列表也没有基本事实。
那么当我完成后，我怎么知道我的模型是否在发挥作用？]]></description>
      <guid>https://stackoverflow.com/questions/78718024/evaluate-unsupervised-learning-playlist-generator-app</guid>
      <pubDate>Sun, 07 Jul 2024 17:53:45 GMT</pubDate>
    </item>
    <item>
      <title>从 UNETR 获取预测后，在 matplotlib 中显示多类标签分割</title>
      <link>https://stackoverflow.com/questions/78717927/multi-class-label-segmentation-display-in-matplotlib-after-getting-preds-from-un</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78717927/multi-class-label-segmentation-display-in-matplotlib-after-getting-preds-from-un</guid>
      <pubDate>Sun, 07 Jul 2024 17:10:00 GMT</pubDate>
    </item>
    <item>
      <title>ValuerError：发现输入变量的样本数量不一致</title>
      <link>https://stackoverflow.com/questions/78717924/valuererror-found-input-variables-with-inconsistent-numbers-of-samples</link>
      <description><![CDATA[我编写了以下代码来学习机器学习方法中的分数。但是我收到了以下错误。原因是什么？？
ValueError: 发现输入变量的样本数量不一致：[6396, 1599]

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv(&#39;Armenian Market Car Prices.csv&#39;)

df[&#39;Car Name&#39;] = df[&#39;Car Name&#39;].astype(&#39;category&#39;).cat.codes

df = df.join(pd.get_dummies(df.FuelType, dtype=int))
df = df.drop(&#39;FuelType&#39;, axis=1)

df[&#39;Region&#39;] = df[&#39;Region&#39;].astype(&#39;category&#39;).cat.codes

df[&#39;Price&#39;] = df.pop(&#39;Price&#39;)

X = df.drop(&#39;Price&#39;, axis=1)
y = df[&#39;Price&#39;]

来自 sklearn.model_selection 导入 train_test_split
来自 sklearn.linear_model 导入 LinearRegression

X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2)
model = LinearRegression()

model.fit(X_train, y_train)

-------------------------------------------------------------------------------
ValueError Traceback (最近一次调用最后一次)
Cell In[358]，第 1 行
----&gt; 1 model.fit(X_train, y_train)

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py:1473，在 _fit_context.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(estimator, *args, **kwargs)
1466 estimator._validate_params()
1468 使用 config_context(
1469 skip_parameter_validation=(
1470 prefer_skip_nested_validation 或 global_skip_validation
1471 )
1472 ):
-&gt; 1473 返回 fit_method(estimator, *args, **kwargs)

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\linear_model\_base.py:609，位于 LinearRegression.fit(self, X, y, sample_weight)
605 n_jobs_ = self.n_jobs
607 accept_sparse = False if self.positive else [&quot;csr&quot;, &quot;csc&quot;, &quot;coo&quot;]
--&gt; 609 X, y = self._validate_data(
610 X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True
611 )
613 has_sw = sample_weight 不为 None
614 if has_sw:

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py:650，位于 BaseEstimator._validate_data(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)
648 y = check_array(y, input_name=&quot;y&quot;, **check_y_params)
649 else:
--&gt; 650 X, y = check_X_y(X, y, **check_params)
651 out = X, y
653 如果不是 no_val_X 且 check_params.get(&quot;ensure_2d&quot;, True):

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\utils\validation.py:1291，在 check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, Ensure_2d, allow_nd, multi_output, Ensure_min_samples, Ensure_min_features, y_numeric, estimator)
1273 X = check_array(
1274 X,
1275 accept_sparse=accept_sparse,
(...)
1286 input_name=&quot;X&quot;,
1287 )
1289 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)
-&gt; 1291 check_consistent_length(X, y)
1293 return X, y

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\utils\validation.py:460，位于 check_consistent_length(*arrays)
458 uniques = np.unique(lengths)
459 if len(uniques) &gt; 1:
-&gt; 460 raise ValueError(
461 &quot;找到样本数量不一致的输入变量：%r&quot;
462 % [int(l) for l in lengths]
463 )

ValueError：找到样本数量不一致的输入变量：[6396, 1599]

我尝试了所有方法，但都没有用，或者我不知道如何解决问题。
Jupyternaut：

您提供的错误消息表明输入数据存在问题。具体来说，似乎有两个不同版本的输入数据，一个有 6396 个样本，另一个有 1599 个样本。这可能会在尝试拟合模型或对数据执行其他操作时导致问题。
要解决此问题，您可能需要检查代码并确保对每个操作使用正确版本的输入数据。您可能还想尝试清理输入数据，删除任何重复或不一致的数据。
]]></description>
      <guid>https://stackoverflow.com/questions/78717924/valuererror-found-input-variables-with-inconsistent-numbers-of-samples</guid>
      <pubDate>Sun, 07 Jul 2024 17:09:03 GMT</pubDate>
    </item>
    <item>
      <title>我在 WLASL 视频数据集上训练的用于预测手语手势的 ConvLSTM 模型在 10 个周期的训练阶段没有提高准确率</title>
      <link>https://stackoverflow.com/questions/78717922/my-convlstm-model-for-predicting-sign-language-gestures-trained-on-wlasl-video-d</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78717922/my-convlstm-model-for-predicting-sign-language-gestures-trained-on-wlasl-video-d</guid>
      <pubDate>Sun, 07 Jul 2024 17:07:23 GMT</pubDate>
    </item>
    <item>
      <title>元特征分析：评估不同特征组合之间复杂性的中间结果</title>
      <link>https://stackoverflow.com/questions/78717886/meta-feature-analysis-intermediate-results-to-assess-complexity-among-different</link>
      <description><![CDATA[我正在使用 meta-feature 分析包。它提供了一种方便的方式来汇总元特征统计信息。
但是在这种情况下，我正在寻找一种通过成对特征组合来访问数据集中数据点复杂性分析的“中间”结果的方法。这是为了让我理解具有特征的数据集比其他数据集具有更高的类重叠（复杂性）。
例如，在只有 4 个特征（萼片长度、萼片宽度、花瓣长度、花瓣宽度）的鸢尾花数据集中：
pip install -U pymfe # package install

from sklearn.datasets import load_iris
from pymfe.mfe import MFE
data = load_iris()
X= data.data
y = data.target

而不是整体摘要：
extractor = MFE(features=[ &quot;f1&quot;], groups=[&quot;complexity&quot;],
summary=[&quot;mean&quot;, &quot;sd&quot;])
extractor.fit(X,y)
meta_feat = extractor.extract()

为了获得平均值和标准差，我想分析由于萼片长度 v 萼片宽度、萼片长度 v 花瓣长度、萼片长度 v 花瓣宽度等造成的复杂性...因为f1沿垂直轴投射数据点以组合二元特征。
如何实现这一目标？
如果可能的话，一些可视化帮助也将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78717886/meta-feature-analysis-intermediate-results-to-assess-complexity-among-different</guid>
      <pubDate>Sun, 07 Jul 2024 16:51:09 GMT</pubDate>
    </item>
    <item>
      <title>在生物学项目中对人体细胞进行实例分割</title>
      <link>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</link>
      <description><![CDATA[我被困在为与生物学相关的项目进行实例分割的过程中。
我有一些人类细胞的图片（每张图片大约有 5 个细胞），我想要实现的是创建一个模型来拍摄这些图片并识别这些细胞。我面临的问题是：我可以让模型识别细胞，但它无法区分不同的细胞。（这意味着作为输出，我得到的 .png 图片要么是 0 代表背景，要么是 1 代表细胞；所以我没有得到关于它们分离的信息）。例如，如果我想计算图片上有多少个单元格，那么这将是一个问题。
澄清一下：我手头有：单元格图片（RGB，.jpg）和 2 种类型的蒙版：第一种是灰度（背景为 0，单元格全部为 1，.png）和 RGB 图片，其中所有单元格都有不同的 RGB 值（如果图片上有 4 个单元格，则存在 4 个不同的 RGB 值；背景始终为 0）。也是 .png。
使用 fastai，我的 DataBlock 如下所示：
dblock = DataBlock(blocks = (ImageBlock, MaskBlock(codes)),
get_items = get_image_files,
splitter = RandomSplitter(),
get_y = get_label,
item_tfms = Resize(224))

dls = dblock.dataloaders(path, bs=5)

问题：我知道此代码无法工作，因为模型输入的灰度图像只有 0 和 1。但我不知道如何合并其他类型的掩码，该掩码实际上包含有关不同细胞分离的信息（所有细胞都是同一类型）。]]></description>
      <guid>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</guid>
      <pubDate>Fri, 05 Jul 2024 10:24:16 GMT</pubDate>
    </item>
    <item>
      <title>如何转换日期格式</title>
      <link>https://stackoverflow.com/questions/78708002/how-to-convert-date-formet</link>
      <description><![CDATA[我正在用 Python 训练模型，下面是我的代码。
#将数据拆分为 x 和 y
x = tsla.drop(&quot;Date&quot;, axis=1)
y = tsla[&#39;Date&#39;]

#将数据拆分为训练和测试
x_train, x_test, y_train, y_tset = train_test_split(x,y, test_size=0.2, random_state=42)

# 模型 
model = LinearRegression()
model.fit(x_train, y_train)

我尝试在 x y 上训练模型。
但这是我的代码得到的错误：
ValueError：无法将字符串转换为浮点数：&#39;2020-03-24&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/78708002/how-to-convert-date-formet</guid>
      <pubDate>Thu, 04 Jul 2024 15:47:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Pytorch 从多幅图像中获取一定数量图像的梯度？而不是所有输入图像的梯度？</title>
      <link>https://stackoverflow.com/questions/78705415/how-can-i-get-the-gradient-of-a-certain-number-of-image-out-of-multiple-images-w</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78705415/how-can-i-get-the-gradient-of-a-certain-number-of-image-out-of-multiple-images-w</guid>
      <pubDate>Thu, 04 Jul 2024 06:39:42 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用免费资源在本地机器上的大数据集上训练 gpt2 [关闭]</title>
      <link>https://stackoverflow.com/questions/78686632/trying-to-train-gpt2-on-large-dataset-in-local-machine-with-free-resources</link>
      <description><![CDATA[是否可以在 colab、jupyter 或 kaggle 上对 1.5m 个数据点进行 gpt2 训练？
到目前为止，我尝试在 colab 中进行此操作，但在标记化过程中会耗尽存储空间，这是可以理解的。我也尝试了批处理技术。后来我尝试在 kaggle 上运行相同的算法，但目前它在加载转换器时显示错误。仍在尝试运行它。我只是想知道是否可以做到这一点！]]></description>
      <guid>https://stackoverflow.com/questions/78686632/trying-to-train-gpt2-on-large-dataset-in-local-machine-with-free-resources</guid>
      <pubDate>Sat, 29 Jun 2024 17:07:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我定义自己的调用函数而没有参数“training”时，我可以使用 model(x, training =True)？</title>
      <link>https://stackoverflow.com/questions/72716154/why-can-i-use-modelx-training-true-when-i-define-my-own-call-function-withou</link>
      <description><![CDATA[请注意，当我创建模型时，我使用参数 something = False 定义了调用函数，当我在函数 train_step 中使用该模型时，我输入了“something =True, training = True”，训练未在我的调用中定义，但它在默认的 tf.keras.model 调用中。
为什么我能够毫无错误地执行此操作？输出基本上打印了一堆“我的调用”。
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# 添加通道维度
x_train = x_train[..., tf.newaxis].astype(&quot;float32&quot;)
x_test = x_test[..., tf.newaxis].astype(&quot;float32&quot;)

train_ds = tf.data.Dataset.from_tensor_slices(
(x_train, y_train)).shuffle(10000).batch(32)

class MyModel(Model):
def __init__(self):
super(MyModel, self).__init__()
self.fl = Flatten()
self.d = Dense(10)

######我的问题#######
def call(self, x, something=False):
if something:
tf.print(&#39;my call&#39;)
x = self.fl(x)
return self.d(x)

model = MyModel()
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.Adam()

@tf.function
def train_step(X,Y):
with tf.GradientTape() as tape:
######我的问题#######
predictions = model(X, something =True, training = True)
loss = loss_object(Y, predictions)
gradients = tape.gradient(loss, model.trainable_variables)
optimizer.apply_gradients(zip(gradients, model.trainable_variables))

对于范围 (3) 中的 epoch：

对于 train_ds 中的 X、Y：
train_step(X,Y)
]]></description>
      <guid>https://stackoverflow.com/questions/72716154/why-can-i-use-modelx-training-true-when-i-define-my-own-call-function-withou</guid>
      <pubDate>Wed, 22 Jun 2022 13:10:23 GMT</pubDate>
    </item>
    <item>
      <title>我们应该在 train_test_split() 中为 random_state 使用什么值，以及在哪种情况下使用？[关闭]</title>
      <link>https://stackoverflow.com/questions/54264452/what-value-should-we-use-for-random-state-in-train-test-split-and-in-which-sce</link>
      <description><![CDATA[X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

在上面的代码中，random_state 使用的是 0。为什么我们不使用 1？]]></description>
      <guid>https://stackoverflow.com/questions/54264452/what-value-should-we-use-for-random-state-in-train-test-split-and-in-which-sce</guid>
      <pubDate>Sat, 19 Jan 2019 05:52:01 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中的 pipeline 和 make_pipeline 有什么区别？</title>
      <link>https://stackoverflow.com/questions/40708077/what-is-the-difference-between-pipeline-and-make-pipeline-in-scikit-learn</link>
      <description><![CDATA[我从 sklearn 网页上获得此信息：

Pipeline：具有最终估算器的转换管道

Make_pipeline：根据给定的估算器构造管道。这是 Pipeline 构造函数的简写。


但我仍然不明白何时必须使用每个管道。有人可以给我举个例子吗？]]></description>
      <guid>https://stackoverflow.com/questions/40708077/what-is-the-difference-between-pipeline-and-make-pipeline-in-scikit-learn</guid>
      <pubDate>Sun, 20 Nov 2016 18:56:16 GMT</pubDate>
    </item>
    </channel>
</rss>