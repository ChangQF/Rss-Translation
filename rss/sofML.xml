<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 18 Mar 2024 09:13:50 GMT</lastBuildDate>
    <item>
      <title>具有一个标签的训练集，具有许多其他标签的测试集</title>
      <link>https://stackoverflow.com/questions/78179042/training-set-with-one-label-testing-set-with-many-other-labels</link>
      <description><![CDATA[我一直在从事一个机器学习项目，专注于心电图记录中的异常检测。目标是区分正常和异常记录，异常类别包括各种类型的异常情况。提供的数据集由标记为“正常”的训练集和标记为多个类别的测试集组成，包括“异常”、“噪声”和其他标签。
在这种情况下，最适合的机器学习方法是什么？会是有监督的机器学习吗？正常类和异常类都有标签数据，但是如何用一个标签来训练模型，而测试数据有很多其他标签。或者半监督将是更好的预测方法？
我确实想尝试半监督机器学习，但我还没有真正有机会学习它。所以这对我来说是一个挑战。]]></description>
      <guid>https://stackoverflow.com/questions/78179042/training-set-with-one-label-testing-set-with-many-other-labels</guid>
      <pubDate>Mon, 18 Mar 2024 09:09:04 GMT</pubDate>
    </item>
    <item>
      <title>分层时间序列 (HTS) 中的多元时间序列预测是否可行？</title>
      <link>https://stackoverflow.com/questions/78179004/is-multivariate-time-series-forecasting-possible-in-hierarchical-time-series-ht</link>
      <description><![CDATA[我需要一些关于 hts 中的多元时间序列预测的澄清。是否可以使用 hts 执行多元时间序列预测？不同的事件变量是否可以合并到hts算法中]]></description>
      <guid>https://stackoverflow.com/questions/78179004/is-multivariate-time-series-forecasting-possible-in-hierarchical-time-series-ht</guid>
      <pubDate>Mon, 18 Mar 2024 09:02:07 GMT</pubDate>
    </item>
    <item>
      <title>cross_val_predict 中是否有 xgb.XGBRegressor 的示例，其中回调=[early_stop], Early_stop=xgb.callback.EarlyStopping？</title>
      <link>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</link>
      <description><![CDATA[在文档
XGBClassifier 有一个 EarlyStopping：
&lt;前&gt;&lt;代码&gt;```
es = xgboost.callback.EarlyStopping(
    轮数=2，
    min_delta=1e-3,
    save_best=真，
    最大化=假，
    data_name=“validation_0”，
    metric_name=“mlogloss”,
    ）
clf = xgboost.XGBClassifier(tree_method=“hist”, device=“cuda”, 回调=[es])

X, y = load_digits(return_X_y=True)
clf.fit(X, y, eval_set=[(X, y)])```

但是“validation_0”是如何实现的？引用 clf.fit 中的 eval_set 来让 EarlyStopping 指标进行评估？
我尝试将其应用到 XGBRegressor：
`将 xgboost 导入为 xgb
从 sklearn.model_selection 导入 cross_val_predict，KFold
将 pandas 导入为 pd
将 numpy 导入为 np

类 CustomEarlyStopping(xgb.callback.EarlyStopping):
    def __init__(self, rounds=2, min_delta=1e-3, save_best=True, maximise=False, data_name=“validation_0”, metric_name=“rmse”):
        super().__init__(rounds=rounds, min_delta=min_delta, save_best=save_best, maximise=maximize, data_name=data_name, metric_name=metric_name)


    # 重写`before_iteration`方法来更新折叠索引
    
# 火车模型（10x10 倍 CV）
cvx = KFold(n_splits=10, shuffle=True, random_state=239)
es = 自定义早期停止()

模型= xgb.XGBRegressor（colsample_bytree = 0.3，learning_rate = 0.1，max_深度= 10，alpha = 10，n_estimators = 500，n_jobs = -1，
                     random_state=239，回调=[es]）
model.set_params(tree_method=&#39;approx&#39;, device=&#39;cpu&#39;)

cv_preds = []
对于范围 (0,10) 内的 i：
    cv_preds.append(cross_val_predict(模型, np.asarray(X_train), np.asarray(y_train), cv=cvx, method=&#39;predict&#39;, n_jobs=1, verbose=2))`

我把data_name=“validation_0”放在在 EarlyStopping __init__ 中，而不在每个 cv 折叠中命名测试集。
这段代码的行为有什么问题？谢谢。
XGBRegressor 的代码返回了此错误：
ValueError：必须至少有 1 个验证数据集才能提前停止。

应该发生的情况是 cv_preds 被 10 个预测 y 的 ndarray 填充。]]></description>
      <guid>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</guid>
      <pubDate>Mon, 18 Mar 2024 08:42:57 GMT</pubDate>
    </item>
    <item>
      <title>Python Flask 错误：导入“依赖项”时，引发了 ImportError</title>
      <link>https://stackoverflow.com/questions/78178785/python-flask-error-while-importing-dependencies-an-importerror-was-raised</link>
      <description><![CDATA[文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 1488 行，调用
返回 self.wsgi_app（环境，start_response）
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 1466 行，在 wsgi_app 中
响应 = self.handle_exception(e)
^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask_cors\extension.py”，第 176 行，位于wrapped_function 中
返回 cors_after_request(app.make_response(f(*args, **kwargs)))
^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 1463 行，在 wsgi_app 中
响应 = self.full_dispatch_request()
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 872 行，在 full_dispatch_request
rv = self.handle_user_exception(e)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask_cors\extension.py”，第 176 行，位于wrapped_function 中
返回 cors_after_request(app.make_response(f(*args, **kwargs)))
^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 870 行，在 full_dispatch_request
rv = self.dispatch_request()
^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 855 行，dispatch_request
return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args) # 类型：忽略[no-any-return]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Y.L.Deepak\OneDrive\Desktop\Twizer-main\app.py”，第 154 行，在标签中
从 keras.models 导入 load_model
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras_init_.py”，第 3 行，位于
从 keras 导入内部
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras_internal__init_.py”，第 3 行，位于
来自 keras。内部导入后端
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras_internal_\backend_init_.py”，第 3 行， 在
from keras.src.backend import initialize_variables 作为initialize_variables
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\src_init.py”，第 21 行，位于
从 keras.src 导入应用程序
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\src\applications_init_.py”，第 18 行，位于
从 keras.src.applications.convnext 导入 ConvNeXtBase
文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\src\applications\convnext.py”，第 26 行，位于
将tensorflow.compat.v2导入为tf
ModuleNotFoundError：没有名为“tensorflow.compat”的模块
我的前端应用程序正在显示，但在前端输入任何文本提示后，我遇到了这些错误有人可以帮助我吗！！！]]></description>
      <guid>https://stackoverflow.com/questions/78178785/python-flask-error-while-importing-dependencies-an-importerror-was-raised</guid>
      <pubDate>Mon, 18 Mar 2024 08:15:42 GMT</pubDate>
    </item>
    <item>
      <title>这是合适的卦模型吗？</title>
      <link>https://stackoverflow.com/questions/78178740/is-this-appropriate-trigram-model</link>
      <description><![CDATA[导入火炬

导入 torch.nn.function 作为 F

Words = open(&#39;names.txt&#39;, &#39;r&#39;).read().splitlines() #[&#39;emma&#39;, &#39;olivia&#39;, &#39;ava&#39;, &#39;isabella&#39;...]

字符 = [&#39;.&#39;,&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;,&#39;h&#39;,&#39;i&#39;,&#39;j&#39;,&#39;k&#39; , &#39;l&#39;, &#39;m&#39;, &#39;n&#39;, &#39;o&#39;, &#39;p&#39;, &#39;q&#39;, &#39;r&#39;, &#39;s&#39;, &#39;t&#39;, &#39;u&#39;, &#39;v&#39;, &#39;w&#39;, &#39; x&#39;、&#39;y&#39;、&#39;z&#39;]

def stoi（字符串）：
    ”“”
    使用字符列表作为基础将字符串转换为整数。
    ”“”
    结果 = 0
    基数 = len(字符)
    对于字符串中的字符：
        结果 = 结果 * 基数 + chars.index(char)
    返回结果

def itos(数字):
    ”“”
    使用字符列表作为基础将整数转换为字符串。
    ”“”
    结果=[]
    基数 = len(字符)
    当 num &gt; 时0:
        result.append(chars[num % base])
        num //= 基数
    结果.reverse()
    return &#39;&#39;.join(结果)

xs = []
y = []

对于单词中的 w：
    chs = [&#39;.&#39;] + 列表(w) + [&#39;.&#39;]
    对于 zip 中的 ch1、ch2、ch3(chs,chs[1:],chs[2:])：
        xs.append(stoi(ch1+ch2))
        ys.append(stoi(ch3))

xs = 火炬.张量(xs)
ys = 火炬.张量(ys)

xenc = F.one_hot(xs, num_classes=729).float()
W = torch.randn((729,27),requires_grad=True)

对于范围（300）内的 i：
    logits = xenc @ W
    计数 = logits.exp()
    probs = counts / counts.sum(1, keepdims=True)
    损失 = -probs[torch.arange(xs.nelement()), ys].log().mean()
    如果我％10==0：
        打印(loss.item())

    W.grad = 无
    loss.backward()

    W.data += -40 * W.grad

在我观看 Andrej Karpathy 的双字母视频之后(https://www.youtube.com/watch ?v=PaCmpygFfXo)，我制作了这个三元组模型作为练习。这是一个合适的卦模型吗？请告诉我是否有一些错误或错误以及改进。]]></description>
      <guid>https://stackoverflow.com/questions/78178740/is-this-appropriate-trigram-model</guid>
      <pubDate>Mon, 18 Mar 2024 08:06:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用具有一般约束的安全强化学习？</title>
      <link>https://stackoverflow.com/questions/78178739/how-to-use-safe-rl-with-general-constraints</link>
      <description><![CDATA[我读了很多关于安全RL的文章，发现都是解决CMDP框架的方法，都是为了降低每一步动作的成本来设置一个约束来降低不安全动作的概率，但是如果约束不是单步动作的约束，而是整个动作轨迹的约束，好像没有相关文章
我想知道是否有办法解决这样的问题，或类似的场景问题]]></description>
      <guid>https://stackoverflow.com/questions/78178739/how-to-use-safe-rl-with-general-constraints</guid>
      <pubDate>Mon, 18 Mar 2024 08:06:13 GMT</pubDate>
    </item>
    <item>
      <title>检测手绘图像中的形状/对象</title>
      <link>https://stackoverflow.com/questions/78178295/detect-shape-object-in-an-image-of-handdrawing</link>
      <description><![CDATA[给定一个手绘图像，我需要弄清楚该对象是什么并用正确的绘图替换它。对象可以是基本形状，如矩形或圆形，也可以是简单的对象，如飞机、苹果或计算机。例如：

我找到了一个名为 AutoDraw 的链接 (https://www.autodraw.com/)，但是它仅适用于墨迹笔画。它依赖于用户的顺序和准确的笔划来对图像进行分类。但是，对于静态图像，我们没有此笔划信息。
请建议解决该问题的最简单方法，我想避免自己训练 CNN。]]></description>
      <guid>https://stackoverflow.com/questions/78178295/detect-shape-object-in-an-image-of-handdrawing</guid>
      <pubDate>Mon, 18 Mar 2024 06:19:47 GMT</pubDate>
    </item>
    <item>
      <title>神经运算符背后的数学[关闭]</title>
      <link>https://stackoverflow.com/questions/78178093/the-math-behind-neural-operators</link>
      <description><![CDATA[似乎几乎所有神经算子论文，如 FNO 等，总是使用 vt+1(x) = σ ( W vt(x)+ ∫ K(x, y) vt(y) 形式的层) dy ) ，其中 t 是图层。
有什么证据证明这有效吗？看起来很多解释都表明该形式类似于格林函数解决方案，但每种方法都使用不同的内核，与格林函数或其工作原理没有具体关系。
谢谢
米娜
我尝试阅读查找解释，但无法在网上找到内容]]></description>
      <guid>https://stackoverflow.com/questions/78178093/the-math-behind-neural-operators</guid>
      <pubDate>Mon, 18 Mar 2024 05:21:52 GMT</pubDate>
    </item>
    <item>
      <title>检测/分类给定手绘图像的形状[关闭]</title>
      <link>https://stackoverflow.com/questions/78177334/detect-classify-shape-given-image-of-the-hand-drawing</link>
      <description><![CDATA[给定一个手绘图像，我需要弄清楚该对象是什么并用正确的绘图替换它。对象可以是基本形状，如矩形或圆形，也可以是简单的对象，如飞机、苹果或计算机。
例如：

我找到了一个名为 AutoDraw 的工具 (https://www.autodraw.com/)，但是它仅适用于墨迹笔画。它依赖于用户的顺序和准确的笔划来对图像进行分类。但是，对于静态图像，我们没有此笔划信息。
请建议解决该问题的最简单方法，我想避免自己训练 CNN。]]></description>
      <guid>https://stackoverflow.com/questions/78177334/detect-classify-shape-given-image-of-the-hand-drawing</guid>
      <pubDate>Sun, 17 Mar 2024 23:36:44 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归实现 - 损失不收敛且模型结果不佳</title>
      <link>https://stackoverflow.com/questions/78175088/logistic-regression-implementation-loss-is-not-converging-and-poor-model-resul</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78175088/logistic-regression-implementation-loss-is-not-converging-and-poor-model-resul</guid>
      <pubDate>Sun, 17 Mar 2024 11:42:37 GMT</pubDate>
    </item>
    <item>
      <title>在吉他指法谱特征提取的 CNN 中保留空间意识 [关闭]</title>
      <link>https://stackoverflow.com/questions/78173966/preserving-spatial-awareness-in-a-cnn-for-guitar-tablature-feature-extraction</link>
      <description><![CDATA[我正在构建一个卷积神经网络 (CNN)，以从吉他指法谱图像中提取音符、小节等特征。虽然我在检测图像中的这些特征方面取得了进展，但在特征提取过程中我仍在努力保持空间意识。
对于那些不熟悉标签的人来说，简单来说，有六行代表吉他上的六根弦，数字表示琴弦上的品格位置。

我正在寻求有关如何改进 CNN 架构或调整训练过程以应对这些挑战的建议。具体来说，我对能够帮助保留空间意识，同时仍保持特征提取的高精度的技术或方法感兴趣。
任何见解、建议或推荐资源将不胜感激。
这是迄今为止我的方法的细分：
数据准备：我收集了吉他谱图像的数据集，其中包含音符、和弦和小节等各种特征。每张图像都标有相应的特征。
模型架构：我设计了一个用于特征提取的 CNN 架构。它由卷积层和用于特征检测的池化层组成。
训练：我使用标记数据集训练了 CNN，以学习吉他指法谱图像中存在的不同特征的模式。
虽然该模型可以准确地检测图像中的各个特征，但它缺乏空间意识，而这对于理解指法谱的结构布局至关重要。例如，音符和小节的相对位置对于准确解释音乐至关重要。
CNN 似乎只专注于识别单个特征，而不考虑它们的空间关系，即每个音符在相关字符串上的位置。]]></description>
      <guid>https://stackoverflow.com/questions/78173966/preserving-spatial-awareness-in-a-cnn-for-guitar-tablature-feature-extraction</guid>
      <pubDate>Sun, 17 Mar 2024 03:20:15 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器整形问题</title>
      <link>https://stackoverflow.com/questions/78165698/autoencoder-shaping-issue</link>
      <description><![CDATA[我的自动编码器出现问题，因为我错误地调整了输出。目前自动编码器的编码与此类似。
我收到此错误：
&lt;块引用&gt;
ValueError：尺寸必须相等，但为 2000 和 3750
&#39;{{节点mean_absolute_error/sub}} =
Sub[T=DT_FLOAT](sequential_8/sequential_7/conv1d_transpose_14/BiasAdd,
IteratorGetNext:1)&#39;，输入形状：[?,2000,3], [?,3750,3]。

如果可能的话，有人可以帮助调整架构吗？我似乎忘记了最初为此调整所做的原始修改。
导入tensorflow为tf
从tensorflow.keras.models导入模型
从tensorflow.keras.layers导入输入，Conv1D，MaxPooling1D，UpSampling1D，连接
从tensorflow.keras.callbacks导入EarlyStopping

# 提供的编码器
编码器 = tf.keras.models.Sequential([
    tf.keras.layers.Reshape([3750, 3], input_shape=[3750, 3]),
    tf.keras.layers.Conv1D(32，kernel_size=5，padding=“相同”，激活=“relu”)，
    tf.keras.layers.MaxPool1D(pool_size=2),
    tf.keras.layers.Conv1D(64，kernel_size=5，padding=“相同”，激活=“relu”)，
    tf.keras.layers.MaxPool1D(pool_size=2),
    tf.keras.layers.Conv1D(128，kernel_size=5，padding=“相同”，激活=“relu”)，
    tf.keras.layers.MaxPool1D(pool_size=2),
    tf.keras.layers.Conv1D(256，kernel_size=5，padding=“相同”，激活=“relu”)，
    tf.keras.layers.MaxPool1D(pool_size=2),
    tf.keras.layers.Conv1D(512，kernel_size=5，padding=“相同”，激活=“relu”)，
    tf.keras.layers.MaxPool1D(pool_size=2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512)
]）

#潜在空间

解码器 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(512 * 125, input_shape=[512]),
    tf.keras.layers.Reshape([125, 512]),
    tf.keras.layers.Conv1DTranspose（512，kernel_size = 5，strides = 1，padding =“相同”，激活=“relu”），
    tf.keras.layers.UpSampling1D（大小=2），
    tf.keras.layers.Conv1DTranspose（256，kernel_size = 5，strides = 1，padding =“相同”，激活=“relu”），
    tf.keras.layers.UpSampling1D（大小=2），
    tf.keras.layers.Conv1DTranspose（128，kernel_size = 5，strides = 1，padding =“相同”，激活=“relu”），
    tf.keras.layers.UpSampling1D（大小=2），
    tf.keras.layers.Conv1DTranspose（64，kernel_size = 5，strides = 1，padding =“相同”，激活=“relu”），
    tf.keras.layers.UpSampling1D（大小=2），
    # 调整内核大小和填充以匹配输入形状
    tf.keras.layers.Conv1DTranspose(3，kernel_size=5，strides=1，padding=“相同”，激活=“线性”)
]）

# 向编码器和解码器添加更多具有更大内核大小的层。
ae = tf.keras.models.Sequential([编码器，解码器])

ae.编译(
    损失=“均方误差”，
    优化器=tf.keras.optimizers.Adam(learning_rate=0.00001)
）
# 定义早期停止标准
Early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, 耐心=30, mode=&#39;min&#39;)

历史= ae.fit（X_train，X_train，batch_size = 8，epochs = 150，validation_data =（X_val，X_val），callbacks = [early_stopping]）```
]]></description>
      <guid>https://stackoverflow.com/questions/78165698/autoencoder-shaping-issue</guid>
      <pubDate>Fri, 15 Mar 2024 08:56:02 GMT</pubDate>
    </item>
    <item>
      <title>由于 ValueError，autoencoder.fit 不起作用</title>
      <link>https://stackoverflow.com/questions/78163348/autoencoder-fit-doesnt-work-becaue-of-a-valueerror</link>
      <description><![CDATA[我不明白我的问题是什么。它应该可以工作，只是因为它是张量流文档中的标准自动编码器。
这是错误
第 64 行，通话中
    解码 = self.decoder(编码)
ValueError：调用 Autoencoder.call() 时遇到异常。

无效的数据类型：&lt;0x7fb471cc1c60 处的属性对象&gt;

Autoencoder.call() 收到的参数：
  x=tf.Tensor(形状=(32,28,28),dtype=float32)

这是我的代码
(x_train, _), (x_test, _) = Fashion_mnist.load_data()

x_train = x_train.astype(&#39;float32&#39;) / 255.
x_test = x_test.astype(&#39;float32&#39;) / 255.

打印（x_train.shape）
打印（x_test.shape）

类自动编码器（模型）：
  def __init__(自身，latent_dim，形状)：
    super(自动编码器, self).__init__()
    self.latent_dim = Latent_dim
    self.shape = 形状
    self.encoder = tf.keras.Sequential([
      层.Flatten(),
      层.Dense（latent_dim，激活=&#39;relu&#39;），
    ]）
    self.decoder = tf.keras.Sequential([
      层.Dense（tf.math.reduce_prod（形状），激活=&#39;sigmoid&#39;），
      图层.重塑（形状）
    ]）

  def 调用（自身，x）：
    编码 = self.encoder(x)
    打印（编码）
    解码 = self.decoder(编码)
    打印（解码）
    返回解码后的内容


形状 = x_test.shape[1:]
潜伏暗度 = 64
自动编码器 = 自动编码器（latent_dim，形状）

autoencoder.compile(optimizer=&#39;adam&#39;, loss=losses.MeanSquaredError())

自动编码器.fit(x_train, x_train,
                纪元=10，
                随机播放=真，
                验证数据=（x_test，x_test））

我尝试更改数据库并尝试了不同的形状]]></description>
      <guid>https://stackoverflow.com/questions/78163348/autoencoder-fit-doesnt-work-becaue-of-a-valueerror</guid>
      <pubDate>Thu, 14 Mar 2024 20:39:06 GMT</pubDate>
    </item>
    <item>
      <title>将低秩近似应用于可学习参数</title>
      <link>https://stackoverflow.com/questions/78158096/applying-low-rank-approximation-to-learnable-parameters</link>
      <description><![CDATA[我试图了解将低秩近似应用于类中的可学习参数是否有意义。目标是减少参数数量。
我有以下自定义模块：
类 CustomPara(nn.Module):
    
    def __init__(self, num_blocks, in_planes, out_planes, kernel_size):
        super(CustomPara, self).__init__()
        self.coefficient_shape = (num_blocks,1,1,1,1)
        块 = [torch.Tensor(out_planes, in_planes, kernel_size, kernel_size) for _ in range(num_blocks)]
        对于范围内的 i(num_blocks): init.kaiming_normal_(blocks[i])
        self.blocks = nn.Parameter(torch.stack(blocks)) # 这是我们稍后将冻结的内容

    def 前向（自身，系数）：
        Final_blocks = (self.blocks*系数).sum(0)
        返回final_blocks

是否可以使用 blocks 参数上的低秩自适应来减少此处可学习参数的数量？]]></description>
      <guid>https://stackoverflow.com/questions/78158096/applying-low-rank-approximation-to-learnable-parameters</guid>
      <pubDate>Thu, 14 Mar 2024 04:22:39 GMT</pubDate>
    </item>
    <item>
      <title>显示 ML 模型的结果</title>
      <link>https://stackoverflow.com/questions/76464982/displaying-result-from-ml-model</link>
      <description><![CDATA[我正在创建一个 API，用于加载 wav 文件并使用已部署在云运行上的 ML 模型来处理它们。当我尝试在邮递员上测试它时，我希望得到预测的结果，但显然它们无法出现。我已经使用 python 测试了这个模型，它运行顺利，但在 Node.js 上运行不佳
结果.js
const axios = require(“axios”);
const fs = require(“fs”);
constexpress = require(“express”);
const 路由器 = Express.Router();

router.post(“/”, async (req, res) =&gt; {
  尝试 {
    const filePath = &quot;./audio_history/ch-4.wav&quot;; //指定WAV文件的路径

    // 读取音频文件
    const fileData = fs.readFileSync(filePath);

    // 向 ML 模型 API 端点发出 POST 请求
    const mlModelEndpoint = “https://getprediction-7rpnuc6dkq-as.a.run.app”;
    const 响应 = 等待 axios.post(mlModelEndpoint, { 音频: fileData });

    // 从响应中提取预测结果
    const 预测结果 = 响应.数据.预测;

    // 将预测结果作为 API 响应发送
    res.json({ 预测: 预测结果 });
  } 捕获（错误）{
    控制台.错误（错误）；
    res.status(500).json({ message: &quot;内部服务器错误&quot; });
  }
});

module.exports = 路由器；


输出
&lt;前&gt;&lt;代码&gt;{}

]]></description>
      <guid>https://stackoverflow.com/questions/76464982/displaying-result-from-ml-model</guid>
      <pubDate>Tue, 13 Jun 2023 12:31:46 GMT</pubDate>
    </item>
    </channel>
</rss>