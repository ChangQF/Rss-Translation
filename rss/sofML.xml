<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sun, 02 Mar 2025 15:17:25 GMT</lastBuildDate>
    <item>
      <title>如何在智能手机上进行行为分析？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79479223/how-to-do-behavioural-analysis-on-a-smartphone</link>
      <description><![CDATA[我正在开发一个大学项目，我需要在该项目中跟踪社交媒体的使用模式以及个人的参与情绪，以监控人的行为并根据所分析的数据给出心理健康评分。
有一个约束：它应该是设备，即没有云API。
这是一个心理健康监测系统项目的一部分，我从各种来源收集数据并实时分析其心理健康。
我需要实现3种不同的模型 -  

文本输入分析
音频分析
搜索历史和行为分析

我没有做很多ML项目，这是我完全独自做的第一个项目。所以我不知道从哪里开始和做什么。]]></description>
      <guid>https://stackoverflow.com/questions/79479223/how-to-do-behavioural-analysis-on-a-smartphone</guid>
      <pubDate>Sun, 02 Mar 2025 14:19:08 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络推断期间的分批归一化[关闭]</title>
      <link>https://stackoverflow.com/questions/79479122/batch-normalization-during-inference-in-convolutional-neural-network</link>
      <description><![CDATA[我确实在同一主题上看到了很多答案。但是，我有一个仍然让我感到困惑的部分，所以我问这个问题。
 卷积神经网络中的批量归一化  
 Maverick Meerkat的答案的第二个最后一段告诉Mean和STD是通过[m，n_w，n_h]计算的，含义大小，宽度，高度。
 原始论文说，使用说，

 M&#39;= | B |的效率小批量的小批量= M * P Q 

其中m是minibatch大小，p x q是convnets的特征映射大小。
 p x q是特征映射尺寸，表示P，Q是batchnorm&#39;ed的张量的宽度和列大小。
但是我要确认的是E [x]和var [x]的方程，这是推理时间时使用的均值和方差。
原始论文中的方程式为e [x] = e_b [μ_b]和var [x] = m/m -1 e_b [σ^2_b] 
很明显，我们将用3D张量计算μ_b和σ^2_b，在有效的迷你批次范围内=张量的张量x高度x宽度x宽度x的尺寸。的高度。
因此，向量μ_b和σ^2_b的长度将是张量的深度。向量的μ_b和σ^2_b的数量为（时代的大小）/（MiniBatch的大小）。
因此
 e [x] = e_b [μ_b] =（sumμ_b） / depth &lt; / p&gt;
和
 var [x] = m / m-1 e_b [σ^2_b] = m / m-1（σ^2_b / depth）&lt; / p&gt;
问题是我们应该如何在VAR [x]定义中解释M。本文确实说他们使用了“效率小型批量尺寸（M&#39;）”。而不是批处理大小（m）和说

 alg。 2的修改类似，以便
在推断期间，BN变换应用相同的线性
在给定特征图中对每个激活的转换。

在原始论文中。
问题：
但是，由于我的数学知识有限，我无法确认我们是否应该解释var [x] = m/m -1 e_b [σ^2_b]为var [x] = m&#39;/m&#39;/m&#39;/m&#39; -1 e_b [σ^2_b]，用于m&#39;= m * p * q。
原始论文确实说Var [X] = M/M -1 E_B [σ^2_b]是“无偏差估计”。在1D矢量X的情况下。我希望有人可以确认var [x] = m&#39;/m&#39;1 e_b [σ^2_b]确实是convnet Tensor的一个无偏差估计值，其中m&#39;是有效的迷你批量大小。 ]]></description>
      <guid>https://stackoverflow.com/questions/79479122/batch-normalization-during-inference-in-convolutional-neural-network</guid>
      <pubDate>Sun, 02 Mar 2025 12:53:34 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型来剥削漏洞吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79478954/diffusion-model-denoising-vulnerabilities-to-exploit</link>
      <description><![CDATA[在过去的一年中，我一直在看到针对生成模型的扰动工具，旨在破坏这些模型输出（文本到图像）的图像。我正在基于他们的研究。
由于其流行，我决定专门针对扩散模型。目前，我正在尝试了解扩散模型的工作原理以及它们如何生成图像，因为我试图寻找弱点和脆弱性来利用我的自定义对抗性工具。我正在阅读DDPM的原始论文，但老实说，它的技术程度使我不知所措。老实说，我不知道在哪里寻求帮助，也不相信要求AI帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/79478954/diffusion-model-denoising-vulnerabilities-to-exploit</guid>
      <pubDate>Sun, 02 Mar 2025 10:46:25 GMT</pubDate>
    </item>
    <item>
      <title>如何解释机器学习模型的MASE和RMSE值[封闭]</title>
      <link>https://stackoverflow.com/questions/79478926/how-to-interpret-mase-and-rmse-values-for-a-machine-learning-model</link>
      <description><![CDATA[拟合机器学习模型并在使用指标RMSE，MASE，R2分数评估预测的同时
同一模型的MASE值很低，但是R2得分也很低，RMSE较高。
在其他情况下，MASE很高，RMSE较低，R2为负。
要选择最佳模型，我们可以基于单个指标选择，或者如果需要组合所有指标，我们如何解释结果中值的对立？]]></description>
      <guid>https://stackoverflow.com/questions/79478926/how-to-interpret-mase-and-rmse-values-for-a-machine-learning-model</guid>
      <pubDate>Sun, 02 Mar 2025 10:23:25 GMT</pubDate>
    </item>
    <item>
      <title>Tsonorflow模型的内存足迹如何在TFLITE转换后增加？</title>
      <link>https://stackoverflow.com/questions/79478810/how-come-memory-footprint-of-a-tensorflow-model-is-increasing-after-tflite-conve</link>
      <description><![CDATA[训练了一个简单的张量流模型，该模型包含一些LSTM和密集的进料层。训练后，我将模型量化并转换为 tf.lite 用于边缘部署的格式。这是代码的相关部分。
  ...
model_size：int = sum（weight.numpy（）。型号中的nbytes。
打印（f&#39;model大小：{model_size /（1024）:. 2f} kb&#39;）
tf_lite_converter = tf.lite.tfliteconverter.from_keras_model（型号=模型）
tf_lite_converter.optimizations = [tf.lite.optimize.optimize_for_size]]
tf_lite_converter.target_spec.supported_types = [tf.float16]
tflite_model：bytes = tf_lite_converter.convert（）
打印（tf Lite模型的f&#39;size是{len（tflite_model）/1024} kb&#39;）
 
作为 tf_lite 只是一个字节数组，我只是将其长度除以1024以获取内存中的大小。
原始型号大小：33.4 kb
压缩和定量后：55 kb 
那么，如果TF_Lite转换器增加内存中的大小，那么这可能会有什么可能甚至有益？或者，我是否错误地测量了（记忆中的）尺寸？任何线索如何进行公平的比较？
另外，对于可穿戴边缘设备，通常可以接受55kb的内存足迹？
注意
我已经比较了磁盘中的尺寸（因为我坚​​持模型），是的，Tflite显示出明显的压缩益处。但这是要找到好处的地方吗？]]></description>
      <guid>https://stackoverflow.com/questions/79478810/how-come-memory-footprint-of-a-tensorflow-model-is-increasing-after-tflite-conve</guid>
      <pubDate>Sun, 02 Mar 2025 08:44:09 GMT</pubDate>
    </item>
    <item>
      <title>MATLAB中支持向量机的输出中的框约束是什么？</title>
      <link>https://stackoverflow.com/questions/79478755/what-is-the-box-constraint-in-the-output-of-a-support-vector-machine-in-matlab</link>
      <description><![CDATA[在MATLAB中，函数 FITCSVM 训练支持向量机。
在输出中，有一个组件 boxconstraints 。我已经阅读了帖子此帖子
并了解框约束的含义。
但是在帖子的回答中，框约束C是标量，而在MATLAB的输出中，它是一个矢量，示例数量相同，而所有词则是1，我在输入中使用了默认的框约束1。   。
我不明白输出是什么。
（我已经在上阅读了svm的部分，统计学习的要素    ，因此我认为这可能是不同的术语选择。如果您想回答，您可以跳过解释SVM的基本概念。）））]]></description>
      <guid>https://stackoverflow.com/questions/79478755/what-is-the-box-constraint-in-the-output-of-a-support-vector-machine-in-matlab</guid>
      <pubDate>Sun, 02 Mar 2025 07:40:03 GMT</pubDate>
    </item>
    <item>
      <title>DQN代理：损失减少，库尔。奖励停滞不前，Q值在所有动作中都非常相似，并且越来越高</title>
      <link>https://stackoverflow.com/questions/79477950/dqn-agent-loss-decreases-cumul-reward-stagnates-q-values-are-very-similar-ov</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79477950/dqn-agent-loss-decreases-cumul-reward-stagnates-q-values-are-very-similar-ov</guid>
      <pubDate>Sat, 01 Mar 2025 17:05:14 GMT</pubDate>
    </item>
    <item>
      <title>如何将“ data.irearner”模型转换为azure ML中的“ model.pkl”（增强决策树回归）？</title>
      <link>https://stackoverflow.com/questions/79477586/how-to-convert-data-ilearner-model-to-model-pkl-in-azure-ml-boosted-decisio</link>
      <description><![CDATA[ 标题：如何将&#39;data.Ilerner&#39;转换为azure ML中的&#39;model.pkl&#39;（增强决策树回归）？
 身体： 
我在Azure ML中创建了一个管道，该管道使用提升决策树回归训练模型。从我的理解来看，该模型被保存为  data.Ilerner  。。
但是，我无法将此模型转换为  model.pkl  格式，可以使用 joblib 。加载。
 问题： 

如何在 azure ml 中创建 model.pkl 为提升决策树回归模型？
在

   源代码尝试： 
我试图使用以下python脚本加载和转换模型：
 导入lightgbm作为lgb
导入约伯利布

＃加载LightGBM型号
model = lgb.booster（model_file =＆quot; data.ilerner; quot;）

＃另存为泡菜文件
Joblib.dump（Model，“ Model.pkl”） 
 
 错误消息： 
运行脚本时，我会收到以下错误：
 ％python3 convert_to_model_pkl.py 
[LightGBM] [致命]模型文件数据中未知模型格式或子模型类型
Trackback（最近的最新电话）：
  file＆quot＆quot＆quot＆tomasz.olchawa/ng/ml/convert_to_model_pkl.py&quot;，5，第5行，in＆lt; module＆gt;
    model = lgb.booster（model_file =＆quot; data.ilerner; quot;）
  file＆quot＆quot＆quot tomasz.olchawa/ng/ml/myenv/lib/python3.13/site-packages/lightgbm/basic.py&quot; line 3697，in __init__ in __init__
    _safe_call（
    ~~~~~~~~~~^
        _lib.lgbm_boostercreatefrommodelfile（
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^”
    ...＆lt; 3行＆gt; ...
        ）
        ^
    ）
    ^
  file＆quot＆quot /../ ng/ml/myenv/lib/python3.13/site-packages/lightgbm/basic.py，第313行，在_safe_call中
    提高lightgbmerror（_lib.lgbm_getlasterror（）。解码（&#39;utf-8＆quot））
lightgbm.basic.lightgbmerror：未知模型格式或模型文件中的子模型类型
 ]]></description>
      <guid>https://stackoverflow.com/questions/79477586/how-to-convert-data-ilearner-model-to-model-pkl-in-azure-ml-boosted-decisio</guid>
      <pubDate>Sat, 01 Mar 2025 12:45:07 GMT</pubDate>
    </item>
    <item>
      <title>时间融合变压器：0.45R²（Yahoo）与负R²（Investing.com） - 帮助！ FX价格预测</title>
      <link>https://stackoverflow.com/questions/79477349/temporal-fusion-transformer-0-45-r%c2%b2-yahoo-vs-negative-r%c2%b2-investing-com-h</link>
      <description><![CDATA[我正在使用时间融合变压器（TFT）来预测每日FX价格变化。它在Yahoo Finance数据（R²= 0.45）上运行良好，但在Investing.com数据（负R²）上的失败不佳，尽管进行了相同的预处理。每日收益的分布截然不同。数据差异（例如不同的日常定义）是否会成为原因？]]></description>
      <guid>https://stackoverflow.com/questions/79477349/temporal-fusion-transformer-0-45-r%c2%b2-yahoo-vs-negative-r%c2%b2-investing-com-h</guid>
      <pubDate>Sat, 01 Mar 2025 09:21:32 GMT</pubDate>
    </item>
    <item>
      <title>减少类别数量的数量会改善Yolo的性能吗？</title>
      <link>https://stackoverflow.com/questions/79477144/does-reducing-the-number-of-categories-improve-yolo-performance</link>
      <description><![CDATA[假设我有一组包含两个类似类别的图像和一个与前两个不同的类别。想想猫，狗和网球。现在，我需要训练Yolo对象检测器以找到这些对象。我可以使用一些策略：

标记所有对象，在此标记的数据集上训练Yolo 
使用经典的计算机视觉方法检测圆形对象。然后只标记猫和狗，然后训练Yolo才能检测到猫和狗。在推理时，也这样做 - 经典的简历可以找到网球，然后Yolo找到猫和狗。

我是否通过方法2获得任何分类准确性？在第二种情况下训练的模型会使猫的狗不经常混淆吗？]]></description>
      <guid>https://stackoverflow.com/questions/79477144/does-reducing-the-number-of-categories-improve-yolo-performance</guid>
      <pubDate>Sat, 01 Mar 2025 05:32:23 GMT</pubDate>
    </item>
    <item>
      <title>KNN搜索在一个非常大的数据集上，该数据集带有Torchscript兼容库[封闭]</title>
      <link>https://stackoverflow.com/questions/79476351/knn-search-on-a-very-large-dataset-with-a-torchscript-compatible-library</link>
      <description><![CDATA[我正在尝试运行K-NN搜索非常大的数据集（1E5点）。  pykeops 在内存和时间方面工作正常，但不幸的是，它不是Torchscript兼容。还有其他方法吗，我可以进行此搜索并提高内存效率。主要要求是它应该兼容Torchscript。]]></description>
      <guid>https://stackoverflow.com/questions/79476351/knn-search-on-a-very-large-dataset-with-a-torchscript-compatible-library</guid>
      <pubDate>Fri, 28 Feb 2025 18:10:20 GMT</pubDate>
    </item>
    <item>
      <title>管道Future Warning：此管道实例尚未拟合</title>
      <link>https://stackoverflow.com/questions/79475986/pipeline-futurewarning-this-pipeline-instance-is-not-fitted-yet</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79475986/pipeline-futurewarning-this-pipeline-instance-is-not-fitted-yet</guid>
      <pubDate>Fri, 28 Feb 2025 15:25:11 GMT</pubDate>
    </item>
    <item>
      <title>在梯度下降算法中，如何诱导-2*WX</title>
      <link>https://stackoverflow.com/questions/78171263/in-gradient-descent-algorithm-how-to-induce-2wx</link>
      <description><![CDATA[ 梯度下降算法的一部分  
  this.upDateWeights = function（）{
 
  令WX;
  令w_deriv = 0;
  令b_deriv = 0;

  for（让i = 0; i＆lt; this.points; i ++）{
    wx = this.yarr [i]  - （this.ueight * this.xarr [i] + this.bias）;
    w_deriv += -2 * wx * this.xarr [i];
    b_deriv += -2 * wx;
  }
  
  此。
  this.bias- =（b_deriv / this.points） * this.learnc;
}
            
 
请解释这部分！
  -2 * wx * this.xarr [i]
 
该部分是诱导的....？
如何通过数学公式诱导.... ]]></description>
      <guid>https://stackoverflow.com/questions/78171263/in-gradient-descent-algorithm-how-to-induce-2wx</guid>
      <pubDate>Sat, 16 Mar 2024 09:41:21 GMT</pubDate>
    </item>
    <item>
      <title>将辍学层提高准确性</title>
      <link>https://stackoverflow.com/questions/60591577/will-dropout-layer-enhance-accuracy</link>
      <description><![CDATA[我知道，在CNN模型中添加辍学层会提高精度，因为它会降低过度拟合的影响。但是，我构建了一个CNN模型，使用16,32和64个过滤器，尺寸3和2为2的Maxpool，并注意到，没有辍学层的模型比所有情况下都有辍学层的模型更好。 
 来自keras.models导入顺序
来自keras.layers导入conv2d，激活，maxpooling2d，密集，扁平，辍学
导入numpy作为NP
来自keras.preprocessing.image导入imagedatagenerator
来自ipython.display导入显示
导入matplotlib.pyplot作为PLT
从PIL导入图像
来自sklearn.metrics导入classification_report，confusion_matrix
进口keras
来自keras.layers导入批次正规化
从keras.optimizer导入亚当
进口泡菜

分类器= sequention（）
classifier.add（conv2d（16，（3,3），input_shape =（200,200,3））））））
classifier.add（激活（&#39;relu&#39;））
classifier.add（maxpooling2d（pool_size =（2,2）））
classifier.add（flatten（））
classifier.Add（密集（128））
classifier.add（激活（&#39;relu&#39;））
classifier.add（辍学（0.5））
classifier.add（密集（7））
classifier.add（激活（&#39;softmax&#39;））
classifier.summary（）
classifier.compile（优化器= keras.optimizers.adam（lr = 0.001），
                   损失=&#39;apcorical_crossentropy&#39;，
                   指标= [&#39;准确性&#39;]）
train_datagen = imagedatagenerator（recage = 1./255，
                                   shear_range = 0.2，
                                   zoom_range = 0.2，
                                   Horizo​​ntal_flip = true）
test_datagen = imagedatagenerator（recage = 1./255）

batchsize = 10
triending_set = train_datagen.flow_from_directory（&#39;/home/osboxes/downloads/downloads/journal_paper/malware_families/spectrogram/train/&#39;，            
                                                target_size =（200,200），
                                                batch_size = batchsize，
                                                class_mode =&#39;分类&#39;）

test_set = test_datagen.flow_from_directory（&#39;/home/osboxes/downloads/downloads/journal_paper/malware_families/spectragram/validate/&#39;，    
                                           target_size =（200,200），
                                           batch_size = batchsize，
                       洗牌= false，
                                           class_mode =&#39;分类&#39;）
历史= clastifier.fit_generator（triending_set，
                        step_per_epoch = 2340 // batchsize，
                        时代= 100，
                        验证_data = test_set，
                        验证_steps = 781 //批处理）

classifier.save（&#39;16_with_dropout_rl_001.h5&#39;）
使用open（&#39;16_with_dropout_rl_001.h5&#39;，&#39;wb&#39;）作为file_pi：
        pickle.dump（history.thistory，file_pi）
y_pred = clastifier.predict_generator（test_set，steps = 781 // batchsize+1）
y_pred = np.argmax（y_pred，axis = 1）
打印（“混淆矩阵”）
打印（Confusion_matrix（test_set.classes，y_pred））
打印（“分类报告”）
target_names = test_set.classes
class_labels = list（test_set.class_indices.keys（）） 
target_names = [&#39;coinhive&#39;，&#39;soptet&#39;，fareit&#39;，&#39;gafgyt&#39;，&#39;mirai&#39;，&#39;ramnit&#39;，&#39;razy&#39;]  
报告= classification_report（test_set.classes，y_pred，target_names = class_labels）
打印（报告） 

＃总结历史的准确性
plt.plot（历史学家[&#39;准确性&#39;]）
plt.plot（history.history [&#39;val_accuracy&#39;]）
plt.title（&#39;模型精度16带辍学的RL .001&#39;）
plt.ylabel（“准确性”）
plt.xlabel（&#39;epoch&#39;）
plt.legend（[&#39;train&#39;，&#39;test&#39;]，loc =“左上”）
plt.show（）
＃总结损失的历史
plt.plot（历史学家[&#39;损失&#39;]）
plt.plot（history.history [&#39;val_loss&#39;]）
plt.title（&#39;带有RL .001的型号损失16）
plt.ylabel（“损失”）
plt.xlabel（&#39;epoch&#39;）
plt.legend（[&#39;train&#39;，&#39;test&#39;]，loc =“左上”）
plt.show（）
 
     &lt;img alt =“ Enter Image Description在此处”]]></description>
      <guid>https://stackoverflow.com/questions/60591577/will-dropout-layer-enhance-accuracy</guid>
      <pubDate>Sun, 08 Mar 2020 20:04:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么在神经网络中需要体重和偏见？</title>
      <link>https://stackoverflow.com/questions/44497187/why-are-weights-and-biases-necessary-in-neural-networks</link>
      <description><![CDATA[关于神经网络，为什么我们需要权重和偏见？
对于权重，我有了这个直觉，我们正在尝试将某些常数乘以输入，以便我们可以达到 y 的价值，并且知道关系，kinda&#39;sike  y = mx + c 。如果可能的话，请帮助我进行直觉。]]></description>
      <guid>https://stackoverflow.com/questions/44497187/why-are-weights-and-biases-necessary-in-neural-networks</guid>
      <pubDate>Mon, 12 Jun 2017 10:27:35 GMT</pubDate>
    </item>
    </channel>
</rss>