<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 23 Jun 2024 15:14:15 GMT</lastBuildDate>
    <item>
      <title>TensorFlow Extended (TFX)：即使管道运行正常，管道输出仍为空</title>
      <link>https://stackoverflow.com/questions/78658886/tensorflow-extended-tfx-pipeline-outputs-is-empty-even-though-the-pipeline-is</link>
      <description><![CDATA[以下代码模拟了一个简单的管道，提取 CSV 文件并将其转换为 TFRecord。
您还可以查看相应的笔记本：https://colab.research.google.com/drive/1GEytZjnNZZ7r_f9QQ9FbauohKNLGSooC?usp=sharing
output_config = example_gen_pb2.Output(split_config=
example_gen_pb2.SplitConfig(splits=[
example_gen_pb2.SplitConfig.Split(name=&#39;train&#39;, hash_buckets=8),
example_gen_pb2.SplitConfig.Split(name=&#39;eval&#39;, hash_buckets=2)
])
)

example_gen = CsvExampleGen(
input_base=&#39;data&#39;,
output_config=output_config
)

pipeline_root = &#39;artifacts&#39;

pipeline = Pipeline(
pipeline_name=&#39;testing pipeline&#39;,
pipeline_root=pipeline_root,
components=[example_gen],
enable_cache=True,
metadata_connection_config=metadata.sqlite_metadata_connection_config(
os.path.join(&#39;artifacts&#39;, &#39;metadata.sqlite&#39;)
)
)

LocalDagRunner().run(pipeline)

我已手动验证 TFRecord 已正确生成。但是，管道的输出字典是空的。
print(pipeline.outputs)
# output: {}
print(example_gen.outputs[&#39;examples&#39;].get())
# output: []

此问题在 .ipynb 笔记本和 .py 文件中都存在。
有趣的是，InteractiveContext 没有这个问题。
有人知道是什么原因造成的吗？]]></description>
      <guid>https://stackoverflow.com/questions/78658886/tensorflow-extended-tfx-pipeline-outputs-is-empty-even-though-the-pipeline-is</guid>
      <pubDate>Sun, 23 Jun 2024 14:03:09 GMT</pubDate>
    </item>
    <item>
      <title>BOVW 用视觉词语来“描述”图像</title>
      <link>https://stackoverflow.com/questions/78658878/bovw-describe-images-in-terms-of-visual-words</link>
      <description><![CDATA[我正在尝试使用 BOVW 模型进行图像分类 (https://en.wikipedia.org/wiki/Bag-of-words_model_in_computer_vision)
以下是我目前所做的工作：

通过从我的数据集中加载图像，获得一个带标签的 numpy 数组数组
使用 SIFT 将图像转换为其特征列表
通过将所有特征放入 1D 数组并将它们输入到 kmeans 聚类中，创建了一个视觉词汇表

以下是我创建词汇表的方法
def get_vocab(imgs):
#从所有图像中获取特征
描述符= [f for img in imgs for f in extractFeatures(img)]

km = KMeans(n_clusters).fit(descriptors) 
return km.cluster_centers_

如果我正确理解了模型，下一步就是计算频率直方图，这是一个数组，存储了图像中出现的每个视觉词的计数。
我的问题是：

如何“计数”图像中出现的视觉词？
我是否要获取一个特征（一个 numpy 数组）并找到最接近它的视觉词，然后将其添加到该计数中？

如何找到与任何给定特征“最接近”的视觉词？

我可以“重复使用”来自聚类算法的数据（即找出某个特征被放入了哪个聚类）？

]]></description>
      <guid>https://stackoverflow.com/questions/78658878/bovw-describe-images-in-terms-of-visual-words</guid>
      <pubDate>Sun, 23 Jun 2024 13:58:57 GMT</pubDate>
    </item>
    <item>
      <title>机器翻译模型失败：为什么我的 Transformer 模型无法学习？</title>
      <link>https://stackoverflow.com/questions/78658444/machine-translation-model-fails-why-isn-t-my-transformer-model-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78658444/machine-translation-model-fails-why-isn-t-my-transformer-model-learning</guid>
      <pubDate>Sun, 23 Jun 2024 10:48:15 GMT</pubDate>
    </item>
    <item>
      <title>经过微调的 Wave2Vec2 无法识别口语</title>
      <link>https://stackoverflow.com/questions/78658388/fine-tuned-wave2vec2-does-not-recognise-spoken-words</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78658388/fine-tuned-wave2vec2-does-not-recognise-spoken-words</guid>
      <pubDate>Sun, 23 Jun 2024 10:21:11 GMT</pubDate>
    </item>
    <item>
      <title>对于深度学习，将胸部 CT 图像从 jpg 转换为 NIFTI 有什么好处吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78658245/for-deep-learning-is-there-any-benefits-converting-chest-ct-images-from-jpg-to</link>
      <description><![CDATA[我正在研究从胸部 CT 图像中自动检测疾病。我一直与一家医院保持联系，他们向我提供胸部 CT 切片，全部为 jpg 格式。我担心转换为 jpg 格式可能会导致空间信息丢失，如果由我决定，我会将 dicom 转换为 nifti
现在，我已使用 python 中的 nibabel 库将 3D 体积从 jpg 转换为 nifti，希望医学图像的 3D 体积能够更好地表示数据。我的假设正确吗？将 jpg 图像切片转换为 3D nifti 体积有什么好处吗？]]></description>
      <guid>https://stackoverflow.com/questions/78658245/for-deep-learning-is-there-any-benefits-converting-chest-ct-images-from-jpg-to</guid>
      <pubDate>Sun, 23 Jun 2024 09:11:04 GMT</pubDate>
    </item>
    <item>
      <title>RAG 模型错误：Mistral7B 未给出正确响应，在本地部署时，每次都会返回相同的不相关响应</title>
      <link>https://stackoverflow.com/questions/78658020/rag-model-error-mistral7b-is-not-giving-correct-response-when-deployed-locally</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78658020/rag-model-error-mistral7b-is-not-giving-correct-response-when-deployed-locally</guid>
      <pubDate>Sun, 23 Jun 2024 07:27:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MASK R_CNN 通过 OpenCV 提取图像中的精确区域？</title>
      <link>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</link>
      <description><![CDATA[我有一个医疗项目，需要提取一个特殊部分（结膜眼球）

自动提取眼睛图像而不了解其坐标，而不是手动提取，而且这个所需区域的坐标也在变化，因为我从许多患者那里捕捉到了图像，我认为必须找到它的形状。我的目标是通过计算结膜眼球中的红色像素来确定贫血和非贫血。我使用掩蔽方法（k 均值）来做到这一点，但我希望可以先直接提取结膜眼球，然后使用 k 均值掩蔽图像并查找，因为我的结果会更准确。当我使用图像分割中的 k 均值时，我发现另一个重叠的红色像素破坏了我的准确性。
。我也听说过机器学习，但在使用机器学习找到患者图像中的邻近区域后，我需要提取结膜髓核。所以我需要代码来仅提取结膜髓核。
我尝试了 k_means 和 kernel，但又添加了一个不需要的红色像素。我听说过实例分割和MASK RCNN。您假设我有我想要的区域，如上图所示，它是 CNN 的数据，那么如何将其用于我的项目。
import cv2
import numpy as np

# 读取图像
image = cv2.imread(&#39;c:/users/stk/desktop/d.png&#39;)

# 将图像转换为 HSV
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# 定义红色的下限和上限
lower_red = np.array([0, 120, 70])
upper_red = np.array([10, 255, 255])

# 为红色创建蒙版
mask1 = cv2.inRange(hsv, lower_red, upper_red)

# 定义红色的下限和上限
lower_red = np.array([170, 120, 70])
upper_red = np.array([180, 255, 255])

# 为红色创建蒙版
mask2 = cv2.inRange(hsv, lower_red, upper_red)

# 合并两个蒙版
mask = mask1 + mask2

# 为形态学操作创建内核
kernal = np.ones((5, 5), np.uint8)

# 执行形态学操作
mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernal)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernal)

# 将蒙版应用于原始图像
result = cv2.bitwise_and(image, image, mask = mask)

# 保存result
cv2.imwrite(&#39;extracted_red_object.png&#39;, result)

# 显示结果
cv2.imshow(&#39;EXTRACTED RED OBJECT&#39;, result)
cv2.waitKey(0)
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</guid>
      <pubDate>Sun, 23 Jun 2024 03:58:40 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络实现中的损失并没有减少</title>
      <link>https://stackoverflow.com/questions/78657540/my-loss-doesnt-drop-in-my-neural-network-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78657540/my-loss-doesnt-drop-in-my-neural-network-implementation</guid>
      <pubDate>Sun, 23 Jun 2024 00:58:18 GMT</pubDate>
    </item>
    <item>
      <title>当使用多个 GPU 时，如何在 PyTorch 闪电日志中设置 sync_dist 和 rank_zero_only？</title>
      <link>https://stackoverflow.com/questions/78657505/how-do-i-set-sync-dist-and-rank-zero-only-in-pytorch-lightning-logging-when-usin</link>
      <description><![CDATA[我正在使用带有四 (4) 个 GPU 的 PyTorch lightning DDP 来训练模型。我注意到在记录时，在训练步骤或验证步骤中可以选择设置 sync_dist=True 和 rank_zero_only =True。它们是什么意思？正确的设置方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78657505/how-do-i-set-sync-dist-and-rank-zero-only-in-pytorch-lightning-logging-when-usin</guid>
      <pubDate>Sun, 23 Jun 2024 00:27:02 GMT</pubDate>
    </item>
    <item>
      <title>Keras 3 中加载模型时出错：不支持的文件格式[关闭]</title>
      <link>https://stackoverflow.com/questions/78656789/error-in-loading-model-in-keras-3-unsupported-file-forma</link>
      <description><![CDATA[我正在尝试从以下 GitHub [[1]: https://github.com/eertay/Digital-Meter-Reading][1]存储库运行一个项目：Digital-Meter-Reading。具体来说，我正在处理预处理文件，但在第二个单元格中遇到了错误。代码如下：
from keras.models import load_model
import numpy as np
from matplotlib import pyplot as plt
import cv2
from scipy import ndimage
classifier=load_model(&#39;cnn_svhn.model&#39;)
但是，当我尝试执行此代码时，出现以下错误：
问题
错误表明 Keras 3 不支持 cnn_svhn.model 文件格式。根据错误消息，Keras 3 仅支持 V3 .keras 文件和旧版 H5 格式文件（.h5 扩展名）。Keras 3 中的 load_model() 不支持旧版 SavedModel 格式。
问题
如何将 cnn_svhn.model 转换或更新为与 Keras 3 兼容的格式？
有没有办法在不降级 Keras 或 TensorFlow 的情况下加载现有的模型文件？]]></description>
      <guid>https://stackoverflow.com/questions/78656789/error-in-loading-model-in-keras-3-unsupported-file-forma</guid>
      <pubDate>Sat, 22 Jun 2024 17:48:57 GMT</pubDate>
    </item>
    <item>
      <title>修复 TimeSeries Transformer 中的张量形状/维度不匹配错误以进行股票价格预测</title>
      <link>https://stackoverflow.com/questions/78655715/fixing-tensor-shape-dimension-mismatch-errors-in-timeseries-transformer-for-stoc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78655715/fixing-tensor-shape-dimension-mismatch-errors-in-timeseries-transformer-for-stoc</guid>
      <pubDate>Sat, 22 Jun 2024 10:08:00 GMT</pubDate>
    </item>
    <item>
      <title>如何验证 Coursera 中的 Jupyter 笔记本分数错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/78655480/how-to-validate-jupyter-notebook-score-error-in-coursera</link>
      <description><![CDATA[课程：监督机器学习：回归和分类
平台：Coursera
提交时练习未正确验证，即使通过了测试用例场景，分数仍为“0”。
Jupyter 笔记本嵌入在 Coursera 应用程序中。
我尝试多次保存文件并重新运行服务器。
我希望文件能够针对给定的解决方案进行验证，从而获得分数。
我已附上已通过的测试用例场景练习。
请分享您的见解 @
jerome.arvin123@gmail.com
最终得分截图
练习 1
练习 2
练习3
练习 4
练习 5
练习 6]]></description>
      <guid>https://stackoverflow.com/questions/78655480/how-to-validate-jupyter-notebook-score-error-in-coursera</guid>
      <pubDate>Sat, 22 Jun 2024 08:21:29 GMT</pubDate>
    </item>
    <item>
      <title>如何计算数据集中颜色的相关性？</title>
      <link>https://stackoverflow.com/questions/62289967/how-to-calculate-correlation-of-colours-in-a-dataset</link>
      <description><![CDATA[在这篇 Distill 文章 (https://distill.pub/2017/feature-visualization/) 的脚注 8 中，作者写道：
傅里叶变换在空间上去相关，但颜色之间仍存在相关性。为了解决这个问题，我们明确测量训练集中颜色之间的相关性，并使用 Cholesky 分解来去相关。

我很难理解如何做到这一点。我理解对于任意图像，我可以通过将图像的形状解释为 [通道，宽度*高度] 而不是 [通道，高度，宽度] 来计算相关矩阵。但如何将整个数据集考虑在内？可以对其进行平均，但这与 Cholesky 分解无关。
检查代码让我更加困惑（https://github.com/tensorflow/lucid/blob/master/lucid/optvis/param/color.py#L24）。没有用于计算相关性的代码，但有一个硬​​编码版本的矩阵（去相关是通过与该矩阵进行矩阵乘法来实现的）。该矩阵名为 color_correlation_svd_sqrt，其中包含 svd，而 SVD 在其他任何地方都没有提及。此外，那里的矩阵是非三角矩阵，这意味着它不是来自 Cholesky 分解。
如能就我提到的任何要点作出澄清，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/62289967/how-to-calculate-correlation-of-colours-in-a-dataset</guid>
      <pubDate>Tue, 09 Jun 2020 18:58:14 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的聚类时间序列数据</title>
      <link>https://stackoverflow.com/questions/45604143/clustering-time-series-data-in-python</link>
      <description><![CDATA[我尝试使用不同的聚类技术在 Python 中对时间序列数据进行聚类。K 均值没有给出良好的结果。以下图像是我使用凝聚聚类进行聚类后得到的图像。我还尝试了动态时间扭曲。这两个似乎给出了类似的结果。
我理想情况下希望第二幅图中的时间序列有两个不同的聚类。第一幅图像是快速增加的聚类。第二幅图像没有增加，有点稳定，第三幅图像是下降趋势的聚类。我想知道哪些时间序列既稳定又受欢迎（这里的流行是指高计数）。我尝试了层次聚类，但结果显示层次太多，我不确定如何选择层次级别。有人能解释一下如何将第二幅图中的时间序列分成两个不同的聚类，一个计数低，另一个计数高吗？可以做到吗？或者我应该直接选择一个阈值将它们一分为二？
快速增加的集群：

计数稳定的集群：

下降趋势的集群：

这非常非常模糊，但这是我的层次聚类的结果。 

我知道这个特定的图像根本没有用，但这对我来说也像是死胡同。 
一般来说，如果你想区分趋势，例如对于 YouTube 视频，如何只有一些被选入“趋势”部分，而另一些被选入“本周趋势”部分？我理解“趋势”部分的视频是那些与第一张图片具有相似特征的视频。 “本周热门”部分收集了一些视频，这些视频的观看次数非常高，但数量相当稳定（即没有出现快速增长）。我知道，对于 YouTube，除了观看次数之外，还有很多其他因素需要考虑。对于第二张图片，我试图做的类似于“本周热门”部分。我想挑选那些观看次数非常高的视频。在这种情况下，我该如何分割时间序列？
我知道 DTW 可以捕捉趋势。DTW 给出的结果与上面的图片相同。它已经确定了第二张图片中的趋势是“稳定的”。但它没有捕捉到这里的“数量”元素。我希望捕捉到趋势和数量，在这种情况下是稳定和高数量。
上面的图片是基于计数聚类的时间序列。我是否错过了其他可以实现这一点的聚类技术？即使只是计数，我如何根据自己的需求进行不同的聚类？
任何想法都将不胜感激。提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/45604143/clustering-time-series-data-in-python</guid>
      <pubDate>Thu, 10 Aug 2017 03:51:00 GMT</pubDate>
    </item>
    <item>
      <title>在 NumPy 中将索引数组转换为独热编码数组</title>
      <link>https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-one-hot-encoded-array-in-numpy</link>
      <description><![CDATA[给定一个 1D 索引数组：
a = array([1, 0, 3])

我想将其独热编码为 2D 数组：
b = array([[0,1,0,0], [1,0,0,0], [0,0,0,1]])
]]></description>
      <guid>https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-one-hot-encoded-array-in-numpy</guid>
      <pubDate>Thu, 23 Apr 2015 18:24:54 GMT</pubDate>
    </item>
    </channel>
</rss>