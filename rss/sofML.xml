<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Wed, 02 Apr 2025 21:16:42 GMT</lastBuildDate>
    <item>
      <title>您如何设置Python环境？</title>
      <link>https://stackoverflow.com/questions/79551578/how-do-you-go-about-setting-up-a-python-environment</link>
      <description><![CDATA[我正在从事机器学习项目，设置虚拟环境真是令人头疼。火炬只能与numpy 1.x一起使用，一些github代码仅适用于Tensorflow 1.x，它仅适用于较旧的Python版本，因此我降级了我的Python版本，但后来又遇到了其他问题。 。
启动项目时，您是否有一种特定的方法来建立环境？还是只是反复试验直到起作用？]]></description>
      <guid>https://stackoverflow.com/questions/79551578/how-do-you-go-about-setting-up-a-python-environment</guid>
      <pubDate>Wed, 02 Apr 2025 21:03:22 GMT</pubDate>
    </item>
    <item>
      <title>RmarkDown编织期间的随机森林预测错误</title>
      <link>https://stackoverflow.com/questions/79551460/random-forest-prediction-error-during-rmarkdown-knitting</link>
      <description><![CDATA[问题描述
编织包含随机森林代码的RmarkDown文档时，我会遇到错误。该错误仅在编织期间发生 - 当在rstudio中交互式运行代码块时，一切正常。
错误消息
 `predive.randomforest（）`：
呢新数据中的预测变量类型与培训数据的类型不匹配。
backtrace：
    ▆
 1。├-stats :: Predivice（RF2，newdata = test，type =＆quot; prob; quot;）
 2。└ -  randomforest ::: precent.randomforest（rf2，newdata = test，type =; prob; prob; quot;）

从第305-344行退出[rf2pred]（Boosting.RMD）
执行停止
 
代码引起错误
我正在训练一个随机的森林模型，然后试图在测试集上产生预测：
在
  默认〜持续时间+金额+分期付款+年龄+
    历史+目的+外国+租金，
  数据=火车，＃最初使用data =信用，子集= interain
  重要性= true，
  ntree = 500，
  mtry = 4，
  nodesize = 1
）

＃错误在编织过程中发生
default_probs＆lt;  - 预测（rf2，newdata = test，type =; prob; prob;）
 
我已经尝试过的

  更改了模型培训从使用 data = CRECT，subset = intrain 直接使用 data = triar = train  

  添加了显式因子水平检查：


  all_factors＆lt;  -  sapply（train，is.factor）
factor_vars＆lt;  - 名称（火车）[all_factors]

对于（factor_vars中的var）{
  train_levels＆lt;  - 级别（train [[[var]]）
  test_levels＆lt;  - 级别（test [[[var]]）
  
  如果（！
    停止（
      sprintf（“％s”的因子水平不匹配：\ n火车水平：％s \ n测试水平：％s＆quort;
              var，
              粘贴（train_levels，collapse =; quot;），
              粘贴（test_levels，collapse =; quot;））
    ）
  }
}
 

  尝试了不同的预测方法：

更改 type =; prob; prob;  to  type =; wordss =; wordesp&#39; 
试图使用不同形式的预测功能
对 stats :: Predive（）进行明确调用，以确保使用正确的方法


  试图通过明确转换为数据帧并确保训练和测试数据之间的因子水平来协调数据结构 


尽管进行了所有这些努力，但该错误仍然存​​在，但仅在编织期间 - 当互动会话中按线执行时，代码才能完美运行。]]></description>
      <guid>https://stackoverflow.com/questions/79551460/random-forest-prediction-error-during-rmarkdown-knitting</guid>
      <pubDate>Wed, 02 Apr 2025 19:55:38 GMT</pubDate>
    </item>
    <item>
      <title>如何提高GridSearch CV速度？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79550884/how-to-improve-gridsearch-cv-speed</link>
      <description><![CDATA[下面的代码正在为38000行数据集使用7-8小时。该代码只是以最佳的精度返回模型参数。预先召回问题。但是为了节省时间，我只是将精度放在代码中，因为要优先。  这是我的PC上有14个内核。  逻辑处理器：20 
  def createModelandTrain（input_data_df）：
    
    target = input_data_df [&#39;target_flag&#39;]
    输入= input_data_df.drop（[&#39;a&#39;，&#39;b&#39;，&#39;c&#39;]，axis = 1）
    inputs.fillna（0，Inplope = true）
    input_data_df.sample（frac = 1）.Reset_index（drop = true）
    x_train，x_test，y_train，y_test = train_test_split（输入，target，test_size = 0.2，Random_State = 365，stratefify = target）
    缩放= minmaxscaler（feature_range =（ -  1,1））。fit（x_train）
    X_TRAIN_RESCALED = scaling.transform（x_train）
    tuned_pa​​rameters = [
       {kernel;：[&#39;&#39;linear＆quot;]，;
       {&#39;kernel;：[poly&#39;&#39;
       {&#39;kernel;：[rbf; quot; quot; quamp;
    这是给出的

    分数= [＆quot; precision＆quot;]
    #scores = [＆quord;
    分数的得分：
        打印（“＃调整超级参数为％s＆quot”％得分）
        #precision_scorer = make_scorer（precision_score，zero_division = 0）
        #custom_scoring = {准确性;：＆quoce; quot;
        clf = GridSearchCV（svm.svc（），tuned_pa​​rameters，cv = 5，评分=＆quot;％s_macro＆quot&#39;％得分，n_jobs = -1）
        #clf = GridSearchCV（svm.svc（），tuned_pa​​rameters，评分= custom_scoring，refit =; qucife＆quort＆quort;
        clf.fit（x_train_rescaled，y_train）
    
        打印（开发集合中找到的“最佳参数：”）
        打印（）
        打印（clf.best_params_）
        打印（）
        打印（开发集合的网格分数：“）
        打印（）
        均值= clf.cv_results _ [＆quot; mean_test_score＆quort;]
        stds = clf.cv_results _ [＆quot; std_test_score＆quot;]
        对于均值，std，zip中的参数（均值，std，clf.cv_results _ [＆quot; params; quot; quot;]）：
            print（％r＆quot;％（均值，std * 2，params））打印（&#39;％0.3F（+/ - ％0.03F））
        打印（）
    
        打印（“详细的分类报告：”）
        打印（）
        打印（“模型经过完整开发集的培训。”）
        打印（“分数是在完整评估集中计算的。”）
        打印（）
        y_true，y_pred = y_test，clf.predict（scaping.transform（x_test））
        打印（Confusion_matrix（y_true，y_pred））
        print（classification_report（y_true，y_pred））
        返回clf.best_params_
 
想要加快速度并将其运行在AWS Glue crawler上。
有什么想法将运行时从7小时下降到不到一个小时的东西？]]></description>
      <guid>https://stackoverflow.com/questions/79550884/how-to-improve-gridsearch-cv-speed</guid>
      <pubDate>Wed, 02 Apr 2025 14:16:19 GMT</pubDate>
    </item>
    <item>
      <title>仅分割图像的特定区域[封闭]</title>
      <link>https://stackoverflow.com/questions/79550598/segmentation-to-only-a-specific-region-of-an-image</link>
      <description><![CDATA[我安装了单元格，如何仅将分割应用于图像的特定区域？我的图像来自培养皿，边缘被检测为面具。
我试图在GUI中找到解决方案，但没有发现]]></description>
      <guid>https://stackoverflow.com/questions/79550598/segmentation-to-only-a-specific-region-of-an-image</guid>
      <pubDate>Wed, 02 Apr 2025 12:14:48 GMT</pubDate>
    </item>
    <item>
      <title>液体。 AI模型后端[关闭]</title>
      <link>https://stackoverflow.com/questions/79550170/liquid-ai-models-backend</link>
      <description><![CDATA[我正在检查Liquid.ai。我探索了各种博客，但找不到查询的答案，即液体现有的ML或DL型号。EAI在后端使用？]]></description>
      <guid>https://stackoverflow.com/questions/79550170/liquid-ai-models-backend</guid>
      <pubDate>Wed, 02 Apr 2025 09:02:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用前向光流施加向后的翘曲（Pytorch的grid_sample）？</title>
      <link>https://stackoverflow.com/questions/79548719/how-to-apply-backward-warp-pytorchs-grid-sample-with-forward-optical-flow</link>
      <description><![CDATA[我最近一直在研究光流算法，并一直在使用pytorch应用光流场。
我注意到大多数库仅实现了向后的扭曲功能，例如 torch.nn.functional.grid_sample 和 cv2.remap 。
我相信我已经正确实现了标准化和网格方向，因为我的图像被类似于目标图像。下面是我实现的某些部分给定3D流场 opt_flow  
 ＃标准化流场
＃3，W，H，D
opt_flow [0] /=（W-1）
opt_flow [1] /=（H-1）
opt_flow [2] /=（D-1）

＃创建网格
＃请注意，Torch.meshgrid返回指示为z，y，x
grid = TORCH.STACK（TORCH.MESHGRID（[[TORCH.LINSPACE（-1，1，i）for opt_flow.shape.shape [1：]]，索引=&#39;ij&#39;），3），3）。
        
＃翻转网格，以使说明为x，y，z
网格=火炬。Flip（网格，[3]）

＃D，H，W，3
opt_flow = opt_flow.permute（1，2，3，0）

＃将流场添加到网格中以表示新坐标
＃我减去了，因为最初我认为这会解释
网格 -  = opt_flow
        
＃添加批处理维度
网格=网格[无，...]

applied = f.grid_sample（self._to_tensor（img）[none，none，none，...]，grid，mode =&#39;bilinear&#39;，padding_mode =&#39;zeros&#39;，align_corners&#39;，align_corners = true）.squeeze（dim =（0，1））
 
我注意到的问题是向后翘曲需要“ 逆光流（如果）”而不是正向光流（FF，由prev  - ＆gt; cur计算出的光流）。这是因为GRID_Sample中所需的网格表示应从每个像素中采样的位置。但是这种关系不仅是如果= -ff 。 （如何在图像上应用反向光流量向量？
简化为2D图像，假设我的FF在网格索引（5，6）处具有位移矢量（3，4）。然后，从Grid_sample的角度来看，我们希望在网格索引（8、10）处存储（-3，-4）的IF网格。简单地否定会导致（-3，-4）存储在（5，6），在grid_sample期间带来错误的像素值。
一个简单的解决方案将是将向后的光流（BF，从CUR -＆GT; PREV计算的光流）将其应用于上级图像。但是将BF应用于“ PREV”似乎是违反直觉的。图像。但同时，由于grid_sample是“向后”的。经扭曲，应用“落后”似乎也很直观。 prev的光场
另一个解决方案将是使用ff上迭代的循环实现向前的翘曲。
对于每个索引i，ff的j，存储网格[i，j]*（-1）位置[i+x_displacement，j+y_displacement]。但这将是一个不可集成的函数。
所以我的问题是：

 是否有一种简单的方法使用向后翘曲（例如grid_sample）应用FF？

 我是否必须将FF应用于上述错误的直觉？ （可以将BF应用于上一个吗？）

 如何创建一个可集成的向前翘曲函数？

]]></description>
      <guid>https://stackoverflow.com/questions/79548719/how-to-apply-backward-warp-pytorchs-grid-sample-with-forward-optical-flow</guid>
      <pubDate>Tue, 01 Apr 2025 13:05:29 GMT</pubDate>
    </item>
    <item>
      <title>使用Yolo在CPU上使用RTSP流滞后的车辆检测 - 寻求优化[封闭]</title>
      <link>https://stackoverflow.com/questions/79547886/vehicle-detection-using-yolo-on-cpu-with-rtsp-stream-lagging-seeking-optimizat</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79547886/vehicle-detection-using-yolo-on-cpu-with-rtsp-stream-lagging-seeking-optimizat</guid>
      <pubDate>Tue, 01 Apr 2025 06:40:27 GMT</pubDate>
    </item>
    <item>
      <title>需要透彻了解因果ML研究论文的背景吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79547011/required-background-for-thorough-understanding-of-causal-ml-research-papers</link>
      <description><![CDATA[我有兴趣在因果推理和机器学习的交集中进行研究，尤其是在因果发现和因果代表学习方面。通过到目前为止，通过我的探索，我发现对以下书籍进行研究至关重要，然后再阅读该领域的研究。

通过墨菲和主教的书（可以选择任何人）的强大ML基金会
理解机器学习（第1部分）的理论ML背景，通常在提出休闲学习理论之前引用。
 Judea Pearl的因果关系，以深入了解因果推论，然后是Bernhard Scholkopf因果发现的因果推断的要素。

我的问题是：
这些书足以准备该主题的研究吗？如果没有，您将添加到此列表中？
成功完成这些书籍的一些基本先决条件是什么？例如贝叶斯因果关系的可能性？还是其他？]]></description>
      <guid>https://stackoverflow.com/questions/79547011/required-background-for-thorough-understanding-of-causal-ml-research-papers</guid>
      <pubDate>Mon, 31 Mar 2025 18:37:31 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测模型，带有XGBoost和Dask大数据集崩溃</title>
      <link>https://stackoverflow.com/questions/79547006/time-series-forecasting-model-with-xgboost-and-dask-large-datasets-crashing</link>
      <description><![CDATA[我正在Python建立一个时间序列预测模型，以预测公用事业公司不同客户类型的每小时KWH负载。该数据集包含约8100万行，在2  -  4年内为2300个客户提供每小时负载数据。客户类型由二进制列表示：EV，HP，太阳能和TOU。数据集具有以下变量：
   -  read_date：datetime64 [us]
   - 仪表：字符串
  -KWH：float64
   - 城市：弦
   - 温度：float64
  -EV：INT64
   - 太阳能：INT64
  -HP：INT64
  -TOU：INT64
   - 小时：INT32
   - 天：INT32
   - 月份：INT32
   - 年：INT64
  -day_of_week：int32
   - 季节：弦
  -customer_type：字符串
  -HOUR_SIN：FLOAT64
  -HOUR_COS：FLOAT64
  -month_sin：float64
  -month_cos：float64
  -Day_of_week_sin：float64
  -Day_of_week_cos：float64
  -Day_sin：float64
  -Day_cos：float64
   -  is_holiday：int64
  -City_Reading：INT64
  -City_lynnfield：INT64
  -City_NorthReading：INT64
  -City_wilmington：INT64
   - 季_WINTER：INT64
  -Season_spring：INT64
   -  sepen_summer：int64
   -  sepen_fall：INT64
 
After cleaning the data, I dropped the following features from both the training and test datasets: meter, customer_type, season, read_date, city, day, month, hour, day_of_week.我的目标变量是小时kWh负载。
我试图使用dask构建XGBoost模型以进行分发，但它一直在以下错误崩溃：
  essertionError：错误
2025-03-31 14：12：26,995-分布式。
 
我正在使用128GB RAM和Intel I7-14700K 3.40 GHz处理器的本地计算机工作。我正在寻找有关如何处理此大型数据集预测时间序列的指导，以及如何在使用DASK进行分发时避免崩溃。这是我的示例代码：
 ＃导入必要的库
导入numpy作为NP
导入dask.dataframe作为DD
导入dask.array作为da
导入XGBoost为XGB
来自dask.distribed Import客户端
来自dask.diarostics导入进步键 
来自sklearn.metrics incort cone_absolute_error，mean_squared_error，r2_score
进口警告
导入matplotlib.pyplot作为PLT
从TQDM导入TQDM

＃使用dask加载数据（大型镶木文件有效）
some_feats_dd = dd.read_parquet（&#39;pre_ml_some_features.parquet＆quort＆quot;）

＃重命名dataFrame
df_processed = some_feats_dd

＃基于读取_DATE进行训练和测试的数据
df_train = df_processed [df_processed [＆quot; 2025]＃在2025年之前保持行
df_test = df_processed [df_processed [&#39;Year; eart; quot; quot; quot; quort; quot; quort; quot&#39;== 2025]＃从2025年开始保持行

＃排除列并准备训练的功能和目标变量
dublude_cols = [kwh＆quot&#39;米，&#39;customer_type&#39;&#39;&#39; 
                ＆quot&#39;&#39;

＃准备培训功能（x）和目标变量（y）
x_train = df_train.drop（columns = ubl_cols）
y_train = df_train [＆quot; kwh＆quot;]

＃计算总长度并确保精确3个块
train_size = len（y_train.compute（））
test_size = len（df_test）＃无需计算，dask可以推断

＃用强制3个块将y_train和y_test转换为dask阵列
y_train = da.from_array（y_train.compute（），chunks =（train_size // 3，））
y_test = da.from_array（df_test [＆quot; kwh;]。compute（），chunks =（test_size // test_size // 2，））

＃确保与x_train和x_test的分区匹配
x_train = x_train.repartition（npartitions = 3）
x_test = x_test.repartition（npartitions = 3）

＃启动DASK客户端以进行并行处理
客户端=客户端（）

＃打印D​​ask仪表板URL
打印（f＆quot“ dask仪表板

＃从xgboost.dask使用daskdmatrix
dask_train_data = xgb.dask.daskdmatrix（客户端，x_train，y_train）

＃设置XGBoost的参数
params = {
    “目标”：“ reg：squaredErr”，＃回归任务
    &#39;eval_metric&#39;：&#39;rmse&#39;，
    &#39;tree_method&#39;：“历史”，＃使用基于直方图的方法来更快训练
    &#39;冗长&#39;：1，＃启用基本记录
}

＃初始化dask-xgboost模型
dask_gbr = xgb.dask.daskxgbregressor（**参数）

＃使用DASK训练模型（这将自动并行化）
使用进度栏（）：＃显示训练期间的进度
    dask_gbr.fit（dask_train_data）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79547006/time-series-forecasting-model-with-xgboost-and-dask-large-datasets-crashing</guid>
      <pubDate>Mon, 31 Mar 2025 18:33:41 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：数据加载器对象不可订阅</title>
      <link>https://stackoverflow.com/questions/79546578/typeerror-dataloader-object-is-not-subscriptable</link>
      <description><![CDATA[我正在创建一个AI模型来生成人群的密度图。将数据集分为两个，一个用于培训，一个用于验证，我创建了两个数据集，然后尝试使用 torch.utils.data.dataloader（test_set，batch_size = batch_size = batch_size，shuffle = false））。之后，要测试数据，我迭代并使用下一个函数获取数据集的下一个元素，然后获得TypeError。
我正在使用Kaggle的数据集从Kaggle使用：这是完整的代码：
  batch_size = 8 
设备=&#39;cuda：0&#39;如果torch.cuda.is_available（）else&#39;cpu&#39;

train_root_dir =＆quot; data/part_a/train_data/＆quot
init_training_set = dataloader（train_root_dir，shuffle = true）

＃将培训集的一部分分为验证集
train_size = int（0.9 * len（init_training_set））
val_size = len（init_training_set）-train_size

train_indices = list（range（train_size））
val_indices = list（range（train_size，len（init_training_set））））））
train_dataset = torch.utils.data.dataset.subset（init_training_set，train_indices）
val_dataset = torch.utils.data.dataset.subset（init_training_set，val_indices）

train_loader = torch.utils.data.dataloader（train_dataset，batch_size = batch_size，shuffle = true）
val_loader = torch.utils.data.dataloader（val_dataset，batch_size = batch_size，shuffle = false）

test_root_dir =＆quot; data/part_a/test_data/＆quot
test_set = dataloader（test_root_dir，shuffle = false）
test_loader = torch.utils.data.dataloader（test_set，batch_size = batch_size，shuffle = false）

dataiter = iter（train_loader）
ex_images，ex_dmaps，ex_n_people = next（dataiter）


＃显示图像和密度图
plot_corresponding_pairs（ex_images，ex_dmaps）
 
具体错误是：
  trackback（最近的最新通话）：
 第61行，in＆lt;模块＆gt;
    对于ex_images，ex_dmaps，ex_n_people in train_loader中
typeError：“数据加载程序”对象不可订阅
 ]]></description>
      <guid>https://stackoverflow.com/questions/79546578/typeerror-dataloader-object-is-not-subscriptable</guid>
      <pubDate>Mon, 31 Mar 2025 15:02:15 GMT</pubDate>
    </item>
    <item>
      <title>无法下载MMCV 1.3.0并构建车轮</title>
      <link>https://stackoverflow.com/questions/77479005/not-able-to-download-mmcv-1-3-0-and-build-wheels</link>
      <description><![CDATA[当我尝试安装 mmcv-full == 1.3.0 时，它无法下载并构建轮子（我已经更新了车轮）
  错误无法为MMCV-Full构建车轮，这是安装pyproject.toml项目所需的
 但是当我尝试使用时
 MIM安装mmcv-full  
错误消息：
  RROR：MMCV-Full的建筑轮失败
  运行设置。
无法构建mmcv-full
错误：无法为MMCV-Full构建车轮，这是安装pyproject.toml的项目所需的
 
可以下载 mmcv-full 的最新版本，但是由于我试图克隆的存储库需要使用 MMCV版本1.3.0 。
我正在使用 Windows 11 ，想知道我应该如何下载版本。]]></description>
      <guid>https://stackoverflow.com/questions/77479005/not-able-to-download-mmcv-1-3-0-and-build-wheels</guid>
      <pubDate>Tue, 14 Nov 2023 08:00:38 GMT</pubDate>
    </item>
    <item>
      <title>凯拉斯调整更喜欢更快的型号？</title>
      <link>https://stackoverflow.com/questions/76248184/keras-tuning-that-prefers-faster-models</link>
      <description><![CDATA[我正在尝试调整超参数，以了解哪些值在Tensorflow Keras模型中是最佳的。我将在Minimax算法中使用最佳模型，因此，由于算法的估计量，评估速度很重要。另外，通过评估我可以看到的模型几乎没有添加精度，但需要更长的时间来使调谐速度更长。 。
简而言之，某些模型kt.hyprand吐出的精度略高，但要花费更多的时间来适应和预测。有没有一种方法来重视准确性，而更喜欢简单，更快的型号？
这是我当前的代码：
 ！pip install -q -u keras -tuner
导入keras_tuner作为kt

DEF Model_builder（HP）：
    全局val_dataset
    全球train_dataset
    全局test_dataset
    模型= keras。
        tf.keras.layers.conv2d（hp.int（&#39;conv1filter&#39;，min_value = 32，max_value = 512*3，步骤= 512/2），
                               hp.int（&#39;conv1kernal&#39;，min_value = 2，max_value = 20，步骤= 2）， 
                               填充=; same＆quot; 
                               激活=“ relu＆quot”， 
                               input_shape =（14,8,8）），
        tf.keras.layers.batchnormalization（axis = -1，动量= 0.99，epsilon = 1e-05），
        tf.keras.layers.conv2d（hp.int（&#39;conv2filter&#39;，min_value = 32，max_value = 512*3，step = 512/2），
                               hp.int（&#39;Conv2Kernal&#39;，min_value = 2，max_value = 20，步骤= 2）， 
                               填充=; same＆quot; 
                               激活=; relu＆quort;），
        tf.keras.layers.batchnormalization（axis = -1，动量= 0.99，epsilon = 1e-05），
        layers.flatten（），
        tf.keras.layers.dense（hp.int（&#39;dense1&#39;，min_value = 32，max_value = 512，step = 32），activation =&#39;relu&#39;），），
        tf.keras.layers.dense（hp.int（&#39;dense2&#39;，min_value = 32，max_value = 512，step = 32），activation =&#39;relu&#39;），），
        tf.keras.layers.dense（hp.int（&#39;dense3&#39;，min_value = 32，max_value = 512，step = 32），activation =&#39;relu&#39;），），
        tf.keras.layers.dense（1，activation =&#39;tanh&#39;），

  ）））
    HP_LEARNING_RATE = HP.CHOICE（&#39;Learning_rate&#39;，values = [1e-2，1e-3，1e-4]）
    model.compile（优化器= keras.optimizers.adam（Learning_rate = hp_learning_rate），
                损失=&#39;mean_absolute_error&#39;，
                指标= [&#39;准确性&#39;]）

    返回模型

调谐器= kt.hyprand（model_builder，
                     objective =&#39;val_accuracy&#39;，
                     max_epochs = 10，
                     覆盖= true，
                     目录=&#39;my_dir30&#39;，
                     project_name =&#39;Into_to_kt30&#39;）
stop_early = tf.keras.callbacks.earlystopping（Monitor =&#39;val_accuracy&#39;，耐心= 5）
tuner.search（x_train，y_train，validation_data =（x_val，y_val），epochs = 50，callbacks = [stop_early]）

＃获取最佳的超参数
best_hps = tuner.get_best_hyperparameters（num_trials = 1）[0]

型号= tuner.hypermodel.build（best_hps）
＃使用最佳超参数构建模型，并在50个时期的数据上训练它
历史= model.fit（x_train，y_train，validation_data =（x_val，y_val），epochs = 50）

val_acc_per_epoch =历史[&#39;val_accuracy&#39;]
best_epoch = val_acc_per_epoch.index（max（val_acc_per_epoch）） + 1
hypermodel = tuner.hypermodel.build（best_hps）

＃重新训练模型
hypermodel.fit（x_train，y_train，validation_data =（x_val，y_val），epochs = best_epoch）
eval_result = hypermodel.evaluate（x_test，y_test）
打印（测试损失，测试准确性]：＆quort; eval_result）
hypermodel.save（&#39;/notebooks/saved_model/my_model&#39;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/76248184/keras-tuning-that-prefers-faster-models</guid>
      <pubDate>Sun, 14 May 2023 15:07:49 GMT</pubDate>
    </item>
    <item>
      <title>NOTFittitError：不安装估算器，在利用模型之前调用``fit''</title>
      <link>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</link>
      <description><![CDATA[我在MacBook OSX 10.2.1（Sierra）上运行Python 3.5.2。
尝试从Kaggle运行一些泰坦尼克号数据集的代码时，我一直遇到以下错误：


 NotFittitedError Trackback（最近的电话
  last）in（）
        6 
        7＃使用测试集进行预测并打印。
  ----&gt; 8 my_prediction = my_tree_one.predict（test_features）
        9印刷（my_prediction）
       10 
/library/frameworks/python.framework/3.5/lib/python3.5/site-packages/sklearn/tree/tree/tree.py.py
  在预测（self，x，check_input）中
      429“”
      430 
   - &gt; 431 x = self._validate_x_predict（x，check_input）
      432 proba = self.tree_.predict（x）
      433 n_samples = X.Shape [0] 
/library/frameworks/python.framework/3.5/lib/python3.5/site-packages/sklearn/tree/tree/tree.py.py
  在_validate_x_predict（self，x，check_input）中
      每当试图预测，应用，预测_proba“”时，386“”“验证X
      387如果self.tree_无：
   - &gt; 388提出不拟合eRror（“不安装估算器”，
      389“调用 fit 在利用模型之前。”）
      390 
 notFittitError：不拟合估算器，在利用该 fit 之前
  型号。

有问题的代码似乎就是这样：
 ＃将缺失的值归为中位数
test.fare [152] = test.fare.median（）

＃从测试集中提取功能：PCLASS，性别，年龄和票价。
test_features = test [[[“ pclass”，“ sex”，“ age”，“ fare”]。

＃使用测试集进行预测并打印。
my_prediction = my_tree_one.predict（test_features）
打印（my_prediction）

＃创建一个具有两列的数据框架：PassengerId＆amp;幸存。幸存的包含您的预测
pastengerid = np.Array（test [“ passenterid”]）。astype（int）
my_solution = pd.dataframe（my_prediction，passenterid，columns = [“幸存”]）
打印（my_solution）

＃检查您的数据框是否有418个条目
打印（my_solution.shape）

＃用名称my_solution.csv将解决方案写入CSV文件
my_solution.to_csv（“ my_solution_one.csv”，index_label = [“ passenterid”]）
 
这是由于我已经称为“ fit”函数，所以我无法理解此错误消息。我要去哪里？感谢您的时间。
 编辑：
事实证明，问题是从上一个代码块继承的。
 ＃适合您的第一个决策树：my_tree_one
my_tree_one = tree.decisionstreeclalsifier（）
my_tree_one = my_tree_one.fit（features_one，target）

＃查看随附功能的重要性和分数
打印（my_tree_one.feature_importances_）
打印（my_tree_one.score（femant_one，target））
 
与行：
 my_tree_one = my_tree_one.fit（features_one，target） 
生成错误：

 valueerror：输入包含NAN，Infinity或一个太大的值
  dtype（&#39;float32&#39;）。
]]></description>
      <guid>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</guid>
      <pubDate>Fri, 02 Dec 2016 17:10:22 GMT</pubDate>
    </item>
    <item>
      <title>如何找到功能对逻辑回归模型的重要性？</title>
      <link>https://stackoverflow.com/questions/34052115/how-to-find-the-importance-of-the-features-for-a-logistic-regression-model</link>
      <description><![CDATA[我有一个由逻辑回归算法训练的二进制预测模型。我想知道哪些功能（预测指标）对于正面或负面类别的决策更为重要。我知道有来自Scikit-Learn软件包的 COEF _ 参数，但我不知道它是否足以满足重要性。另一件事是我如何根据否定和正类别的重要性来评估 coef _ 值。我还阅读了有关标准化回归系数的信息，但我不知道它是什么。
可以说，有肿瘤大小，肿瘤重量等特征，可以决定恶性肿瘤或不恶性等测试案例。我想知道哪些功能对于恶性和不是恶性预测更为重要。]]></description>
      <guid>https://stackoverflow.com/questions/34052115/how-to-find-the-importance-of-the-features-for-a-logistic-regression-model</guid>
      <pubDate>Wed, 02 Dec 2015 20:11:21 GMT</pubDate>
    </item>
    <item>
      <title>幼稚的贝叶斯分类器从头开始实现</title>
      <link>https://stackoverflow.com/questions/19349567/naive-bayes-classifier-implementation-from-scratch</link>
      <description><![CDATA[我正在尝试自己实施我的第一个天真的贝叶斯分类器，以更好地理解。因此，我的数据集来自 http://archive.ics.uci.uci.uci.uci.edu/ml/datasets/datasets/datasets/Adult  Adadult  American Census Data，Spersus sass seals seals＆lt; &#39;＆gt; 50k&#39;）。
这是我的python代码：
 导入系统
导入CSV

word_stats = {}＃{&#39;word&#39;：{&#39;class1&#39;：cnt，&#39;class2&#39;：cnt&#39;}}}
word_cnt = 0

targets_stats = {}＃{&#39;class1&#39;：3234，&#39;class2&#39;：884}每个类中有多少个单词
class_stats = {}＃{&#39;class1&#39;：7896，&#39;class2&#39;：3034}每个类中有多少行
items_cnt = 0

def train（数据集，目标）：
    global word_stats，words_cnt，targets_stats，items_cnt，class_stats

    num = len（数据集）
    对于Xrange（num）中的项目：
        class_stats [targets [item]] = class_stats.get（targets [item]，0） + 1

        对于i在Xrange（len（dataset [item]）））：
            word = dataset [item] [i]
            如果不是words_stats.has_key（word）：
                word_stats [word] = {}

            TGT =目标[项目]

            cnt = word_stats [word] .get（tgt，0）
            word_stats [word] [tgt] = cnt + 1

            targets_stats [tgt] = targets_stats.get（tgt，0） + 1
            word_cnt += 1

    items_cnt = num

DEF分类（DOC，TGT_SET）：
    global words_stats，words_cnt，targets_stats，items_cnt

    probs = {}＃概率本身p（c | w）= p（w | c） * p（c） / p（w）
    PC = {}＃probability of Clofe in Document set p（c）中
    pwc = {}＃probability在特定类中的单词设置。 P（W | C）
    pw = 1 #1＃documet set中的单词集

    doc中的单词：
        如果在words_stats中没有单词：
            继续#dirty，非常肮脏 
        pw = pw * float（sum（word_stats [word] .values（））） / word_cnt

    对于TGT_SET中的TGT：
        PC [tgt] = class_stats [tgt] / float（items_cnt）
        doc中的单词：
            如果在words_stats中没有单词：
                继续#dirty，非常肮脏
            tgt_wrd_cnt = word_stats [word] .get（tgt，0）
            pwc [tgt] = pwc.get（tgt，1） * float（tgt_wrd_cnt） / targets_stats [tgt]

        probs [tgt] =（pwc [tgt] * pc [tgt]） / pw

    l =排序（probs.items（），key = lambda i：i [1]，反向= true）
    打印概率
    返回L [0] [0]

def check_results（数据集，目标）：
    num = len（数据集）
    tgt_set = set（目标）
    正确= 0
    错误= 0

    对于Xrange（num）中的项目：
        res =分类（dataset [item]，tgt_set）
        如果res ==目标[项目]：
            正确=正确 + 1
        别的：
            错误=不正确 + 1

    打印“正确：”，float（正确） / num，&#39;不正确：&#39;，float（不正确） / num
            
def load_data（fil）：
    数据= []
    tgts = []

    阅读器= csv.reader（fil）
    对于读者中的行：
        d = [X.Strip（）in in in in in in in in in in]
        如果 &#39;？&#39;在D：
            继续

        如果不是Len（D）：
            继续
        
        data.append（d [： -  1]）
        tgts.append（D [-1：] [0]）

    返回数据，TGTS

如果__name__ ==&#39;__ -main __&#39;：
    如果Len（sys.argv）＆lt; 3：
        打印&#39;./program train_data.txt test_data.txt&#39;
        sys.exit（1）

    文件名= sys.argv [1]
    fil = open（文件名，&#39;r&#39;）
    数据，tgt = load_data（fil）
    火车（数据，TGT）

    test_file = open（sys.argv [2]，&#39;r&#39;）
    test_data，test_tgt = load_data（test_file）

    check_results（test_data，tgt）
 
它给出了〜61％的正确结果。当我打印概率时，我会得到以下内容：
  {&#39;＆lt; = 50K&#39;：0.07371606889800396，&#39;＆gt; 50K&#39;：15.325378327213354}
 
但是，在正确的分类器的情况下，我希望看到这两个概率的总和等于1。
起初，我认为问题是在浮动底流中，并试图以对数进行所有计算，但结果是相似的。
我知道省略一些单词会影响准确性，但是概率是错误的。
我做错了什么或不明白？
出于您的说服力，我在这里上传了数据集和Python脚本：
&lt;A href =“ https://dl.dropboxusercontent.com/u/36180992/adult.tar.gz”]]></description>
      <guid>https://stackoverflow.com/questions/19349567/naive-bayes-classifier-implementation-from-scratch</guid>
      <pubDate>Sun, 13 Oct 2013 19:52:37 GMT</pubDate>
    </item>
    </channel>
</rss>