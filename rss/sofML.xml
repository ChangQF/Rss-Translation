<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 23 May 2024 15:16:15 GMT</lastBuildDate>
    <item>
      <title>图像分类中的融合特征向量？</title>
      <link>https://stackoverflow.com/questions/78523862/fuse-feature-vector-in-image-classification</link>
      <description><![CDATA[目前，我正在处理一个关于面部情感分类的图像分类问题。我使用 2 种提取方法：HOG 和面部地标。我的想法是使用 HOG 来查找图像的梯度大小和方向，并使用面部标志来查找面部关键点。我想我可以融合两种方法来制作更好的功能。但新特征比 HOG 差，比面部特征点好（评估相同模型）。我有一个问题：

我想知道如何融合这两种方法，其中 HOG 归一化之前和面部标志返回 68x2 对点整数。

如果可以，我应该在熔断之前进行正常化或其他操作吗？我可以尝试哪种方法来融合它们（连接、加法、乘法……）？

有没有办法衡量我的方法会更好或评估它？我也尝试融合 HOG 和 SIFT（视觉词袋）。


我曾尝试融合 HOG 和 Facial Landmark 功能，但在同一模型中，它比 HOG 更差，但比 Facial Landmark 更好。我还融合了（SIFT）视觉词袋和 HOG，但它仍然比 HOG 差，但比视觉词袋好。这是我使用的代码：
x_hogp_train = pca.transform(x_hog_train)[:,:382]
x_hogp_valid = pca.transform(x_hog_valid)[:,:382]
x_hogp_test = pca.transform(x_hog_test)[:,:382]

scaler = StandardScaler() # 缩放 bovw 特征
缩放器.fit(x_bovw_train)
x_scale_bovw_train = 缩放器.transform(x_bovw_train)
x_scale_bovw_valid = 缩放器.transform(x_bovw_valid)
x_scale_bovw_test = 缩放器.transform(x_bovw_test)

# 使用 concat 融合它们
x_fused_train = np.concatenate((x_hogp_train, x_scale_bovw_train), axis=1)
x_fused_valid = np.concatenate((x_hogp_valid, x_scale_bovw_valid), axis=1)
x_fused_test = np.concatenate((x_hogp_test, x_scale_bovw_test), axis=1)

]]></description>
      <guid>https://stackoverflow.com/questions/78523862/fuse-feature-vector-in-image-classification</guid>
      <pubDate>Thu, 23 May 2024 14:35:09 GMT</pubDate>
    </item>
    <item>
      <title>我使用 K 均值对图像中的颜色进行聚类。当使用 matplotlib 中的 imshow() 进行重建时，绘图为空白</title>
      <link>https://stackoverflow.com/questions/78522757/i-used-k-means-to-cluster-the-colors-in-my-image-when-use-imshow-from-matplot</link>
      <description><![CDATA[我在kaggle上运行以下代码
img = imread(“/kaggle/input/image-segmentation/ladybug.png”)
x = img.reshape(-1, 3)
kmeans = KMeans(n_clusters=8, random_state=42).fit(x)
segmented_img = kmeans.cluster_centers_[kmeans.labels_]
Segmented_img = Segmented_img.reshape(img.shape)
图 = plt.figure()
ax = Fig.add_subplot(1,2,1)
斧头.imshow(img)

ax = Fig.add_subplot(1,2,2)
ax.imshow(segmented_img)

我得到这个输出。请告诉我为什么我没有获得分割图像。
]]></description>
      <guid>https://stackoverflow.com/questions/78522757/i-used-k-means-to-cluster-the-colors-in-my-image-when-use-imshow-from-matplot</guid>
      <pubDate>Thu, 23 May 2024 11:19:11 GMT</pubDate>
    </item>
    <item>
      <title>如何从电脑屏幕上的 (x,y) 像素点确定 3D 凝视矢量值？</title>
      <link>https://stackoverflow.com/questions/78522525/how-to-determine-3d-gaze-vector-values-from-x-y-pixels-points-on-pc-screen</link>
      <description><![CDATA[我有一个拍摄对象距离屏幕 X 厘米。屏幕尺寸 (S1xS2) 分辨率也是已知的。摄像头位于屏幕顶部中间。屏幕上显示随机点。我也有面部标志检测。
问题是，如何获得人注视位置的 3D 凝视向量？]]></description>
      <guid>https://stackoverflow.com/questions/78522525/how-to-determine-3d-gaze-vector-values-from-x-y-pixels-points-on-pc-screen</guid>
      <pubDate>Thu, 23 May 2024 10:37:40 GMT</pubDate>
    </item>
    <item>
      <title>利用 500 多个拟合模型的预测能力来预测多个并发应用程序用户的输入</title>
      <link>https://stackoverflow.com/questions/78522289/using-the-prediction-power-of-500-fitted-models-for-predicting-the-input-of-mul</link>
      <description><![CDATA[我正在开发一个应用程序，它将同时接收来自多个用户的输入 JSON 对象。我们假设有一个交货时间估算应用程序。另外，我们假设一个 JSON 对象类似于 {“feaure_1”: 0.45, “feature_2”: 1,...}。
我有 1 亿行历史数据，出于内存效率的原因，我将历史数据拆分为 500 个块。因此，它的块有 200k 行。现在，对于每个块，我都训练了一个 RandomForestRegressor() 并将其回归器保存到磁盘，名称为 chunk_{i}_model.joblib。
我的问题是如何利用这 500 个模型（未来可能是 1_000、2_000 甚至更多）的预测能力，使用用户的单个输入进行快速预测。
到目前为止我已经看到了两种方法：
方法 1：平均预测
预测 = np.zeros((1, len(models)))
    对于 i，枚举中的模型（模型）：
        预测[:, i] = model.predict(json_input)
    返回 np.mean(预测，轴=1)

此方法将迭代每个保存的模型（因此，迭代 500 次），将生成 500 个交付时间结果，对结果进行平均并向用户返回响应。

优点：内存使用量较少
缺点：等待响应的空闲时间较长。 （执行 500 多次迭代 + 从磁盘读取每个模型的时间）。

方法 2：使用前 20 个模型。
我有一个 JSON 元数据文件，用于记录测试数据的模型名称和 RMSE 分数。同样，测试数据位于每个块内（每个块 200_000 行 -&gt; 170_000 训练，30_000 测试）。我可以过滤前 20 个 RMSE 分数，并使用这些前 20 个模型进行平均方法。

优点：由于仅迭代 20 个模型，因此执行速度更快。
缺点：当我使用所有 500 个模型时（在方法 1 中），在 20*200_000 = 4_000_000 条记录上训练的 20 个模型的预测可能会错过 100_000_000 条记录中的模式。

我可以使用其他方法来有效应对这一软件开发挑战吗？我正在尝试开发一种解决方案，该解决方案可以使用 Python（而不是 Spark）针对许多模型和来自多个用户的请求进行扩展。此外，使用 VotingRegressor() 或元堆栈方法也是不可能的，因为我每次都必须重新调整数据。我正在寻找的解决方案将使用已安装在较小的原始数据块中的模型，直到使用所有 1 亿条历史记录。]]></description>
      <guid>https://stackoverflow.com/questions/78522289/using-the-prediction-power-of-500-fitted-models-for-predicting-the-input-of-mul</guid>
      <pubDate>Thu, 23 May 2024 09:54:41 GMT</pubDate>
    </item>
    <item>
      <title>何时在卷积神经网络中使用/不使用偏差项</title>
      <link>https://stackoverflow.com/questions/78522177/when-to-use-not-use-bias-term-in-convolutional-neural-networks</link>
      <description><![CDATA[这个问题最近突然出现在我的脑海里。我向 GPT 和其他几个模型询问了卷积网络中偏差项的重要性。他们所有人的反应都不同，而且非常肤浅。我偶尔也会看到 Kaggle 笔记本，人们在训练模型时在 conv/dense 层中设置“bias=False”或“bias=True”。您能否分享关于为什么偏差术语可能很重要以及何时考虑启用/禁用它的见解？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78522177/when-to-use-not-use-bias-term-in-convolutional-neural-networks</guid>
      <pubDate>Thu, 23 May 2024 09:34:17 GMT</pubDate>
    </item>
    <item>
      <title>AIF360 我是否使用 BinaryLabel 或 StandardDataset 作为自定义数据集/数据框？</title>
      <link>https://stackoverflow.com/questions/78522103/aif360-do-i-use-binarylabel-or-standarddataset-for-a-custom-dataset-dataframe</link>
      <description><![CDATA[我有一个自定义数据集，已将其加载到数据框中，并且希望使用 AIF360 进行公平的机器学习。
我总是使用 pandas 的 get_dummies() 方法对分类特征进行 one-hot 编码。
现在，我是否必须将 BinaryLabelDataset 类用于 one-hot 编码数据，而 StandardDataset 类也用于自定义数据集，但尚未进行 one-hot 编码？
基本上，我不确定在哪种情况下使用哪个类（对于单热编码的 dataframe = BinaryLabelDataset？ - 对于没有 transformations = StandardDataset 的数据帧？）&lt; /p&gt;
我阅读了 AIF360 的文档和 API 参考指南。但是，我不太清楚应该使用哪一个。
我知道 BinaryLabelDataset 类是基于 StandardDataset 类构建的。
另外，StandardDataset类还可以做一些数据转换。
另外，我还可以使用与 sklearn 兼容的 API。]]></description>
      <guid>https://stackoverflow.com/questions/78522103/aif360-do-i-use-binarylabel-or-standarddataset-for-a-custom-dataset-dataframe</guid>
      <pubDate>Thu, 23 May 2024 09:22:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在不执行代码的情况下计算代码的递归深度/循环深度？</title>
      <link>https://stackoverflow.com/questions/78521967/how-to-calculate-recursion-depth-loop-depth-of-a-code-without-executing-it</link>
      <description><![CDATA[我正在尝试构建一个模型，该模型能够从静态变量（例如行数、函数数量、复杂性等）推断出动态指标，例如内存分配、GPU 消耗和 CPU 消耗。 
我想到的一个问题是如何将输入作为静态特征包含在这个模型中（我认为这是一个非常相关的变量）
以阶乘函数为例：
&lt;前&gt;&lt;代码&gt;结果 = 1
  对于范围 (1, 8 + 1) 内的 i：
     结果*=我
  返回结果

结果 = 1
  对于范围 (1, 80000 + 1) 内的 i：
     结果*=我
  返回结果

在此示例中，第二个代码的执行时间比第一个代码长得多。这种差异对于人眼来说是显而易见的，但如何才能静态地使模型变得明显呢？我指的是一个可以理解输入参数影响的通用模型。这可以在不执行代码的情况下实现吗？]]></description>
      <guid>https://stackoverflow.com/questions/78521967/how-to-calculate-recursion-depth-loop-depth-of-a-code-without-executing-it</guid>
      <pubDate>Thu, 23 May 2024 08:58:11 GMT</pubDate>
    </item>
    <item>
      <title>实施机器学习模型来评估成绩并根据教育流数据库选择继续教育路径的最简单方法是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78521362/what-is-the-easiest-way-to-implement-a-ml-model-to-evaluate-grades-and-choose-th</link>
      <description><![CDATA[要实施用于评估学生成绩和推荐教育途径的机器学习模型，首先要收集和预处理数据，包括成绩、课外活动和学生兴趣。对数据进行标准化和编码，然后将其分为训练集和测试集。选择并训练适当的模型，例如决策树或随机森林，并使用准确性和 F1 分数等指标评估其性能。使用用户友好的界面部署模型，以提供实时建议并确保遵守数据隐私法。利用新数据和反馈不断改进模型，解决任何偏差以保持公平性和准确性。
期望基于全面的数据分析，提供准确、公正的指导。目标是创建一个用户友好的实时推荐系统，通过新数据和反馈不断改进，同时确保数据隐私并解决潜在偏见。]]></description>
      <guid>https://stackoverflow.com/questions/78521362/what-is-the-easiest-way-to-implement-a-ml-model-to-evaluate-grades-and-choose-th</guid>
      <pubDate>Thu, 23 May 2024 06:46:07 GMT</pubDate>
    </item>
    <item>
      <title>寻找特定于移动设备的二进制文件的数据集</title>
      <link>https://stackoverflow.com/questions/78521260/seeking-dataset-of-mobile-specific-binaries</link>
      <description><![CDATA[我目前正在训练机器学习模型，并需要特定于移动设备的二进制文件的数据集。尽管我付出了努力，但我仍然无法找到大量的数据集。
向我建议的另一种选择是从 AOSP 批量下载二进制文件，但我不确定如何开始此过程。]]></description>
      <guid>https://stackoverflow.com/questions/78521260/seeking-dataset-of-mobile-specific-binaries</guid>
      <pubDate>Thu, 23 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用权重和偏差 wandb 扫描实现多处理以实现最大并行化，特别是 count var 在此设置中如何工作？</title>
      <link>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</guid>
      <pubDate>Thu, 23 May 2024 05:25:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 if 条件将两个 scikit-learn 子模型组合成一个整体并将其保存到 pickle 文件中？</title>
      <link>https://stackoverflow.com/questions/78520659/how-to-combine-two-scikit-learn-sub-models-into-an-ensemble-using-an-if-conditio</link>
      <description><![CDATA[我使用 IF 条件训练了两个 scikit-learn 模型（根据 X1 功能定义的标准生成了两个训练集）。如何将这个 if 条件与这两个经过训练的模型集成到一个单个整体模型中并将其保存到 pickle 文件中？]]></description>
      <guid>https://stackoverflow.com/questions/78520659/how-to-combine-two-scikit-learn-sub-models-into-an-ensemble-using-an-if-conditio</guid>
      <pubDate>Thu, 23 May 2024 02:12:38 GMT</pubDate>
    </item>
    <item>
      <title>对数核和指数激活的非线性关系模型精度无法达到 100%</title>
      <link>https://stackoverflow.com/questions/78514097/model-accuracy-for-non-linear-relationship-with-logarithm-kernel-and-exponential</link>
      <description><![CDATA[我正在开展一个项目，需要使用神经网络对非线性关系进行建模。关系为 ( y = 3x_1^2x_2^3 )。网络设置如下：

预处理：输入的自然对数
网络设计：单层，一个神经元
激活函数：指数
损失函数：MAE（平均绝对误差）
优化器： Adam
纪元：50
批量大小：32

输入和预期输出：

输入：([x1, x2])
正确权重：([2, 3])
正确的偏差：(\ln 3)

尽管有这些设置，我仍无法达到 100% 的准确度。我尝试过随机初始化权重和偏差以及使用特定值。
这是代码：
将 numpy 导入为 np
将张量流导入为 tf
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从tensorflow.keras.optimizers导入Adam

# 生成数据
x1 = np.random.randint(1, 21, 大小=(1000, 1))
x2 = np.random.randint(1, 21, 大小=(1000, 1))
y = 3 * (x1 ** 2) * (x2 ** 3)

# 预处理数据
log_x1 = np.log(x1)
log_x2 = np.log(x2)
log_inputs = np.hstack((log_x1, log_x2))

# 定义模型
模型=顺序（）
model.add（密集（1，input_dim = 2，激活=&#39;指数&#39;，kernel_initializer =&#39;ones&#39;，bias_initializer =&#39;zeros&#39;））

# 编译模型
model.compile(优化器=Adam(learning_rate=0.01), loss=&#39;mae&#39;)

# 训练模型
model.fit（log_inputs，np.log（y），epochs = 50，batch_size = 32）

# 评估模型
test_x1 = np.array([[2], [4], [5]])
test_x2 = np.array([[3], [7], [19]])
test_inputs = np.hstack((np.log(test_x1), np.log(test_x2)))
预测 = model.predict(test_inputs)
print(np.exp(预测))

有人对如何提高该模型的准确性有建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78514097/model-accuracy-for-non-linear-relationship-with-logarithm-kernel-and-exponential</guid>
      <pubDate>Tue, 21 May 2024 19:54:48 GMT</pubDate>
    </item>
    <item>
      <title>cnn 模型的纪元大小 [关闭]</title>
      <link>https://stackoverflow.com/questions/78494862/epoch-size-for-cnn-model</link>
      <description><![CDATA[如果我有一个包含大约 200 个样本的数据集，并且我正在应用 CNN，那么我的 epoch 大小应该是多少？
我尝试了 epoch 大小为 50，但结果非常差。
但是当我将 epoch = 5 时，它给出了明显更好的结果，但我不确定正确的 epoch 大小应该是多少。]]></description>
      <guid>https://stackoverflow.com/questions/78494862/epoch-size-for-cnn-model</guid>
      <pubDate>Fri, 17 May 2024 09:52:20 GMT</pubDate>
    </item>
    <item>
      <title>获取“ValidationError：VectorstoreIndexCreator 嵌入的 1 个验证错误”</title>
      <link>https://stackoverflow.com/questions/78112934/getting-validationerror-1-validation-error-for-vectorstoreindexcreator-embeddi</link>
      <description><![CDATA[我正在尝试构建一个 pdf 聊天机器人，您可以在其中上传 pdf 并询问与 pdf 相关的问题。为此，我正在考虑基于 RAG 的应用程序。所以我想为我的输入 pdf 创建矢量嵌入，但是当我这样做时，
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
embed_model = HuggingFaceEmbedding(model_name=“BAAI/bge-small-en-v1.5”)
index_creator = VectorstoreIndexCreator(
    矢量store_cls = 卡桑德拉，
    嵌入=嵌入模型，
    text_splitter = RecursiveCharacterTextSplitter(
        块大小 = 400,
        块重叠 = 30
    ),

    矢量store_kwargs={
        &#39;会话&#39;：会话，
        &#39;键空间&#39;：键空间，
        &#39;表名&#39;：表名
    }
）

我收到验证错误。
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValidationError Traceback（最近一次调用最后一次）
&lt;ipython-input-17-b83dc7fd1587&gt;在&lt;细胞系：4&gt;()
      2 keyspace = “pdf_qa_name”
      3 
----&gt; 4 index_creator = VectorstoreIndexCreator(
      5 矢量store_cls = 卡桑德拉，
      6 嵌入 = embed_model,

/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py 在 __init__(__pydantic_self__, **data)
    第 339 部分
    第340章
--&gt;第341章
    第342章
    第343章

ValidationError：VectorstoreIndexCreator 出现 1 个验证错误
嵌入
  预期 Embeddings 的实例（type=type_error.任意_type；expected_throtary_type=Embeddings）

有什么想法吗？
尝试了 2 个不同的模型（Jina 和 BAAI/bge）。错误不会继续。我正在使用 open ai gpt 3.5 api。]]></description>
      <guid>https://stackoverflow.com/questions/78112934/getting-validationerror-1-validation-error-for-vectorstoreindexcreator-embeddi</guid>
      <pubDate>Wed, 06 Mar 2024 08:47:33 GMT</pubDate>
    </item>
    <item>
      <title>如何将极坐标数据框与 scikit-learn 一起使用？</title>
      <link>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</link>
      <description><![CDATA[我无法将极坐标数据帧与 scikit-learn 一起使用进行机器学习训练。
目前，我正在预处理 Polars 中的所有数据帧，并将它们转换为 pandas 进行模型训练，以使其正常工作。
是否有任何方法可以通过 scikit-learn API 直接使用极坐标数据帧（无需先转换为 pandas）？]]></description>
      <guid>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</guid>
      <pubDate>Fri, 11 Nov 2022 05:59:55 GMT</pubDate>
    </item>
    </channel>
</rss>