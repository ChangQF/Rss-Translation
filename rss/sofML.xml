<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 03:19:00 GMT</lastBuildDate>
    <item>
      <title>Tensorflow model.evaluate() 崩溃，因为不支持 lab​​el_mode 中的 None 值</title>
      <link>https://stackoverflow.com/questions/78823152/tensorflow-model-evaluate-crashing-because-none-values-from-label-mode-not-sup</link>
      <description><![CDATA[我尝试在 preprocessing.image_dataset_from_directory 上运行 model.evaluate()，但由于 label_mode=None 而无济于事
我尝试从 ImageDataGenerator 的 flow_from_directory 实现与 class_mode=&#39;input&#39; 类似的功能。我尝试了多次，但一直收到相同的错误消息。我也尝试过手动更改模型的输入，但我仍然不确定我哪里出错了。下面是我的代码：
 SIZE = 128
batch_size = 64

train_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\noncloud_train&#39;, 
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None
)

validation_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\noncloud_test&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None

)

anomaly_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\cloud&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None

)

rescaling_layer = layer.Rescaling(1./255)

def change_inputs(images, labels=None):
x = tensorflow.image.resize(rescaling_layer(images),[SIZE, SIZE], method=tensorflow.image.ResizeMethod.NEAREST_NEIGHBOR)
return x, x

train_dataset = train_generator.map(change_inputs)
validation_dataset = validation_generator.map(change_inputs)
anomaly_dataset = anomaly_generator.map(change_inputs)

#此处有一些模型构建和编译代码，但我省略了它#

# 检查侦察。验证数据和异常图像之间的误差
validation_error = model.evaluate(validation_generator)
anomaly_error = model.evaluate(anomaly_generator)

# 打印出结果
print(f&quot;Recon. error for the validation data is {validation_error}&quot;)
print(f&quot;Recon. error for the anomaly_error is {anomaly_error}&quot;)

最后四行是由于 label_mode 而出现的问题]]></description>
      <guid>https://stackoverflow.com/questions/78823152/tensorflow-model-evaluate-crashing-because-none-values-from-label-mode-not-sup</guid>
      <pubDate>Thu, 01 Aug 2024 21:50:38 GMT</pubDate>
    </item>
    <item>
      <title>如何开始开发我自己的机器学习模型 Swift [关闭]</title>
      <link>https://stackoverflow.com/questions/78823105/how-to-start-developing-my-own-machine-learning-model-swift</link>
      <description><![CDATA[最近我一直在研究机器学习功能，例如 CreateML 和 CoreML，但我不太确定它们是否适合我想要完成的任务，因为它们更多地涉及图像识别/文本/语音/语音/等。
本质上，我正在尝试创建一个模型，该模型可以理解用户的颜色偏好，并在应用程序为他们设计的服装中重新创建类似的调色板。
例如，在最初启动应用程序时，用户会对一组随机的服装配色方案进行评分，然后将其用作训练数据以开发用户的风格偏好。
我已经有使用 Python 进行机器学习的经验，有没有办法将 Python 脚本集成到我的 Swift 应用程序中（我只见过一些 hackish tape 和 wish 解决方案，但我不确定这是否有效），或者我如何在 Swift 中使用 CoreML 或类似的东西来创建我自己的模型？ （到目前为止，我看过的教程都只是处理图像识别，我不确定从哪里开始使用这些教程的颜色偏好算法）
请记住，我是 Swift 的新手，但对编程并不陌生，所以老实说，只要指向正确的方向就会很有帮助，我可以弄清楚其余的！]]></description>
      <guid>https://stackoverflow.com/questions/78823105/how-to-start-developing-my-own-machine-learning-model-swift</guid>
      <pubDate>Thu, 01 Aug 2024 21:29:45 GMT</pubDate>
    </item>
    <item>
      <title>两个数据集的随机森林的数据集结构[关闭]</title>
      <link>https://stackoverflow.com/questions/78822403/dataset-structure-for-random-forest-of-two-datasets</link>
      <description><![CDATA[我有两个单独的数据集，就变量而言，它们包含相同类型的数据，涉及 2000 多名农民，但针对的是同一农民的 2021 年和 2022 年（列数相同，为 70，行数不同；两者都接近 5000）。我必须使用机器学习和随机森林算法预测 2023 年的产量 (Y)（动物公斤数/农场总公顷数）。但是，我不确定您如何统一数据集（2021 年和 2022 年），或者我应该如何设置最终数据集以进行预测，这意味着：

我应该将两个数据集统一为一个吗？如果是，怎么办？
选项 A：



ID 农民
KG 动物
农场公顷
产量
年份
...




1
30
2
15
2021
...


1
40
3
13
2022
...


2
 20
4
5
2021
...


2
30
5
6
2022
...


...
...
...
...
...
...



选项B:



农民 ID
2021 年牲畜公斤数
2022 年牲畜公斤数
2021 年农场公顷数
2022 年农场公顷数
2021 年产量
产量2022




1
30
40
2
3
15
13


2
20
30
4
5
5
6


...
...
...
...
...
...
...



如果不是，最好的构造方法是什么？算法需要什么来构造数据集？或者它需要什么输入才能进行可靠的预测（我是机器学习的新手）？

我是否应该只将基于 2021 年的变化数据添加到 2022 年的数据集中，因此 kg、农场公顷的增加、减少 ecc 的百分比添加到新列中？或者应该如何设置？

我应该使用另一个机器学习模型进行预测吗？如果是，哪一个？我知道我不能使用时间序列预测，因为时间数据很少。

]]></description>
      <guid>https://stackoverflow.com/questions/78822403/dataset-structure-for-random-forest-of-two-datasets</guid>
      <pubDate>Thu, 01 Aug 2024 17:50:10 GMT</pubDate>
    </item>
    <item>
      <title>训练模型时出现错误“对象 __array__ 方法未生成数组”</title>
      <link>https://stackoverflow.com/questions/78822263/getting-error-object-array-method-not-producing-an-array-while-training-a</link>
      <description><![CDATA[我正在尝试使用神经网络模型 Sequential 来训练一个模型。在模型编译之前，一切都进展顺利。当我点击 model.fit() 进行模型训练时，我收到错误“对象 array 方法未生成数组”。请告诉我错误在哪里。我还打印了 X_train 和 y_train 样本及其形状。
下面是相同的代码。
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.utils import to_categorical
import numpy as np

# 编码分类特征
label_encoders = {}
for column in solidated_super.columns:
le = LabelEncoder()
consolidated_super[column] = le.fit_transform(consolidated_super[column])
label_encoders[column] = le

# 将数据拆分为输入和输出
X = solidated_super[[&#39;DeviceName_df1&#39;, &#39;AlarmName_df1&#39;]].values
y = solided_super[[&#39;DeviceName_df2&#39;, &#39;AlarmName_df2&#39;]].values

# 对输出标签进行独热编码
y_device = to_categorical(consolidated_super[&#39;DeviceName_df2&#39;])
y_alarm = to_categorical(consolidated_super[&#39;AlarmName_df2&#39;])

# 合并独热编码输出
y = np.concatenate([y_device, y_alarm], axis=1)

# 确保 y 为数字且具有正确的形状
print(f&#39;X shape: {X.shape}, y shape: {y.shape}&#39;)
print(f&#39;X sample: {X[:5]}, y sample: {y[:5]}&#39;)
&#39;&#39;&#39;
上述打印语句的 op
X shape: (396, 2), y shape: (396, 25)
X 样本：[[16 19]
[16 19]
[16 19]
[16 19]
[12 20]]，y 样本：[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 
0. 0.
1.]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
0.]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
0.]]
&#39;&#39;&#39;

# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
random_state=42)

# 对输入特征进行归一化
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 定义神经网络模型
model = Sequential()
model.add(Input(shape=(X_train.shape[1],)))
model.add(Dense(64,激活=&#39;relu&#39;))
model.add(Dense(32, 激活=&#39;relu&#39;))
model.add(Dense(y_train.shape[1], 激活=&#39;softmax&#39;)) # 使用 softmax 进行多类分类
# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 训练模型
model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)

在执行 model.fit() 时，我收到错误：-
ValueError Traceback (most recent call last) Cell In[59], line 2
1 # 训练模型
----&gt; 2 model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)
文件 C:\Python312\Lib\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 中引发 e.with_traceback(filtered_tb)
123 最后：
124 delfiltered_tb
文件 C:\Python312\Lib\site-packages\tensorflow\python\framework\constant_op.py:108，在 convert_to_eager_tensor(value, ctx, dtype) 中
106 dtype = dtypes.as_dtype(dtype).as_datatype_enum
107 ctx.ensure_initialized()
--&gt; 108 返回 ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: 对象 __array__ 方法未生成数组

示例数据框为：-
{
&#39;DeviceName_df1&#39;: [&#39;Device A&#39;, &#39;Device B&#39;, &#39;Device C&#39;],
&#39;AlarmName_df1&#39;: [&#39;Alarm1&#39;, &#39;Alarm2&#39;, &#39;Alarm3&#39;],
&#39;DeviceName_df2&#39;: [&#39;Device X&#39;, &#39;Device Y&#39;, &#39;Device Z&#39;],
&#39;AlarmName_df2&#39;: [&#39;Alarm4&#39;, &#39;Alarm5&#39;, &#39;Alarm6&#39;]
}

所有字符串值。]]></description>
      <guid>https://stackoverflow.com/questions/78822263/getting-error-object-array-method-not-producing-an-array-while-training-a</guid>
      <pubDate>Thu, 01 Aug 2024 17:19:22 GMT</pubDate>
    </item>
    <item>
      <title>AWS SageMaker createJob 不存在程序并停留在“inProgress”状态</title>
      <link>https://stackoverflow.com/questions/78821736/aws-sagemaker-createjob-not-existing-a-program-and-stuck-in-inprogress-status</link>
      <description><![CDATA[我有一个 SageMaker 作业，它运行并创建一个用于进行预测的模型。
该过程从 createProcessingJob、createTrainingJob、createModelJob 和 createTransform 开始。
我在 createProcessingJob 和 createTransform 作业中遇到了错误。
我用于 createTransformJob 的 docker 镜像是 python:3.11，我在网上研究时，尝试了多种退出代码的方法。
sys.exit(0)
os._exit(0)
os.abort()
os.kill()
os.kill(os.getpid(), singal.SIGTERM)

以上方法均无效。
我找到了这篇帖子：https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-signal-success-failure.html
它让我意识到我可能缺少权限。
但是，当我检查 AWS CloudTrail 时，我没有看到任何错误消息。
因此，目前，我找不到任何错误消息，但作业未正确完成。
我找不到该帖子，但我还看到一篇 AWS 帖子建议使用 sys.exit()。
该帖子还提到，根据图像，程序不会自行退出。
因此，如果我使用 python:3.11，我应该怎么做才能退出代码？
或者我不应该使用 python3.11？
我不想使用停止条件或手动停止并处理这种情况。]]></description>
      <guid>https://stackoverflow.com/questions/78821736/aws-sagemaker-createjob-not-existing-a-program-and-stuck-in-inprogress-status</guid>
      <pubDate>Thu, 01 Aug 2024 15:17:47 GMT</pubDate>
    </item>
    <item>
      <title>模型输出与输入具有相同的形状</title>
      <link>https://stackoverflow.com/questions/78821552/model-output-has-the-same-shape-as-the-input</link>
      <description><![CDATA[我尝试制作一个股票价格预测程序，而不是根据最后 60 个值获取单个值，而是获得一个具有不同数字且形状与输入相同的输出，而不是单个值。
!pip install yfinance tensorflow==2.10.0
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import yfinance as yf
import datetime as dt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
import tensorflow as tf

start = dt.datetime(2012,1,1)
end = dt.datetime(2020,1,1)

data = yf.download(&quot;META&quot;, start=&#39;2012-01-01&#39;, end=&#39;2020-01-01&#39;)

data = pd.DataFrame(data)
data.head()

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data[&#39;Close&#39;].values.reshape(-1,1))

prediction_days = 60
x_train = []
y_train = []

for x in range(prediction_days,len(scaled_data)):
x_train.append(scaled_data[x-prediction_days:x,0]​​)
y_train.append(scaled_data[x,0])

x_train, y_train = np.array(x_train), np.array(y_train)
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))
ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32)

model = Sequential()
model.add(tf.keras.Input(shape = (60,1)))
model.add(Dense(64,activation = &#39;relu&#39;))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(Dense(64,activation = &#39;relu&#39;))
model.add(Dense(1))

model.compile(optimizer = &#39;adam&#39;,loss = tf.keras.losses.MeanSquaredError())
model.fit(ds,epochs = 10)

test_data = yf.download(&quot;META&quot;, start=&#39;2020-01-01&#39;, end=&#39;2024-07-30&#39;)
actual_prices = test_data[&#39;Close&#39;].values
total_dataset = pd.concat((data[&#39;Close&#39;], test_data[&#39;Close&#39;]),axis = 0)
model_inputs = total_dataset[len(total_dataset)-len(test_data)-prediction_days:].values
model_inputs = model_inputs.reshape(-1,1)
model_inputs = scaler.transform(model_inputs)

x_test = []

for x in range(prediction_days, len(model_inputs)):
x_test.append(model_inputs[x-prediction_days:x,0]​​)

x_test = np.array(x_test)
x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))
print(x_test)
predicted_prices = model.predict(x_test)
print(predicted_prices)

我尝试了不同的 tensorflow 版本和不同的损失函数，甚至为最后一层设置了不同的激活函数，但还是不起作用。
模式的输入形状为 (60,1)，输出应该只有一个数字，但却是一个形状为的随机数的完整列表（60,1）（当我运行它时，在我的例子中它是输入形状（1150,60,1）并且输出也是（1150,60,1））]]></description>
      <guid>https://stackoverflow.com/questions/78821552/model-output-has-the-same-shape-as-the-input</guid>
      <pubDate>Thu, 01 Aug 2024 14:40:25 GMT</pubDate>
    </item>
    <item>
      <title>Colab：内存不足，无法加载 Llama 3</title>
      <link>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</link>
      <description><![CDATA[我正在按照 Youtube 上的教程操作，然后想要加载 Llama3 8B：
model_name = &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;

tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hugging_face_key)
model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key)

得到：
您的会话失败，因为所有可用 RAM 都已使用

尝试过：model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key, low_cpu_mem_usage=True)
但再次出现同样的错误]]></description>
      <guid>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</guid>
      <pubDate>Thu, 01 Aug 2024 12:45:03 GMT</pubDate>
    </item>
    <item>
      <title>有哪些方法可以将图像与设置融合在一起？[关闭]</title>
      <link>https://stackoverflow.com/questions/78820940/what-are-some-approaches-for-blending-an-image-in-with-a-setting</link>
      <description><![CDATA[我有一张想要放入场景中的物体图像，我尝试了几种不同的方法，以下是我最初的印象

使用物体图像和提示作为输入生成整个场景（发现物体变化太大）
覆盖绘画（结果质量不一致）
使用预选图像作为场景并通过蒙版、裁剪、重新照明、使用 opencv 添加阴影等方式添加（半手动执行此操作时效果非常好

到目前为止，第 3 种方法最有希望，这让我想到是否有任何工具或方法可以专门做到这一点，而不是我将一堆不同的增强步骤堆叠在一起？]]></description>
      <guid>https://stackoverflow.com/questions/78820940/what-are-some-approaches-for-blending-an-image-in-with-a-setting</guid>
      <pubDate>Thu, 01 Aug 2024 12:22:54 GMT</pubDate>
    </item>
    <item>
      <title>需要一些开源软件资源或代码片段来自动注释图像[关闭]</title>
      <link>https://stackoverflow.com/questions/78820910/need-some-open-source-software-resource-or-code-snippet-for-automatic-annotation</link>
      <description><![CDATA[我目前正在使用 labelImg、cvat（免费试用版）软件对图像进行手动注释。我需要一些帮助来查找用于自动注释图像的开源软件资源或代码片段。Manually_annotated_Img
我需要一些帮助来查找用于自动注释图像的开源软件资源或代码片段]]></description>
      <guid>https://stackoverflow.com/questions/78820910/need-some-open-source-software-resource-or-code-snippet-for-automatic-annotation</guid>
      <pubDate>Thu, 01 Aug 2024 12:15:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 llama 3 8b 训练 LLaVA-NeXT</title>
      <link>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</guid>
      <pubDate>Thu, 01 Aug 2024 11:56:36 GMT</pubDate>
    </item>
    <item>
      <title>裁剪、旋转或翻转重复项的图像识别</title>
      <link>https://stackoverflow.com/questions/78820730/image-recognition-for-cropped-rotated-or-flipped-duplicates</link>
      <description><![CDATA[多年来，我收集了大量图像，我想清除积累的重复图像。
大多数图像都可以通过寻找视觉相似性轻松找到，因为差异可能只是由于不同的 JPEG 级别而产生的压缩伪影。
但我也有一部分图像被翻转或旋转了 90/180/270 度，目前我不知道如何轻松找到它们。
我尝试的一种方法是收集所有图像的直方图“指纹”，然后强力比较所有翻转和 90 度旋转的排列与匹配对。
但后来我遇到了一个问题，即 CV2 提供的各种直方图算法对非常相似的图像有不同的假阳性和假阴性。
这仍然是减少一些重复项的一种选择，但显然并不理想。
但它无法解决裁剪图像的剩余问题。此时，我认为最好进行图像识别。
所以我想知道我应该为此研究什么。我尝试过使用 Milvus，但我从未设置过类似的东西，所以我还没有取得很大进展。
这就是为什么我要尝试看看我是否在这里寻找正确的选择，同时牢记我的要求：

它应该是开源的，或者没有前期成本，这只是一种“爱好”毕竟是项目
它应该有一个与 Python 的接口，无论它是第一方还是第三方，对我来说都无所谓
它不需要了解它在图像中看到的是什么，只需要了解以下内容：
(&quot;其他图像&quot; 表示其数据库中的图像)

&quot;此图像看起来像是另一幅图像的一部分&quot;
&quot;此图像看起来像是另一幅图像的翻转/旋转版本&quot;



我理解这显然需要首先训练识别算法，但如何做到这一点才能得到上面列出的结果也是我需要指导的事情。
例如，我如何以正确的方式准备训练图像，以便它可以学习模式而不是精确的图像。]]></description>
      <guid>https://stackoverflow.com/questions/78820730/image-recognition-for-cropped-rotated-or-flipped-duplicates</guid>
      <pubDate>Thu, 01 Aug 2024 11:30:46 GMT</pubDate>
    </item>
    <item>
      <title>如何在人工神经网络中进行样本外预测？</title>
      <link>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</guid>
      <pubDate>Thu, 01 Aug 2024 10:36:16 GMT</pubDate>
    </item>
    <item>
      <title>情绪分析-澄清</title>
      <link>https://stackoverflow.com/questions/78819506/sentiment-analysis-clarification</link>
      <description><![CDATA[我正在对熊猫数据框进行情绪分析，并尝试了许多不同的途径来获得某种相似的情绪分数/分析。我只需要确保我写的内容是正确的，因为我是一个新手程序员。
以下是我为文本清理所做的工作：
from nltk.stem import PorterStemmer
import re

porter = PorterStemmer()

#假设 Paris_review_texts 是一个带有“Review_Text”列的 DataFrame

documents = california_review_texts[&#39;Review_Text&#39;]

Cleaned_doc = []
for r in range(len(documents)):
review = documents.iloc[r] # 使用 iloc for Series 按索引获取行
try:
# 确保 review 是一个字符串
if not isinstance(review, str):
continue

# 删除除字母之外的所有内容
review = re.sub(&#39;[^A-Za-z]&#39;, &#39; &#39;, review)
# 将所有文本变为小写
review = review.lower()
# 应用标记化
Tokens = review.split()
# 应用词干提取操作（可选）
for t in range(len(Tokens)):
Tokens[t] = porter.stem(Tokens[t])
# 删除短词
Filtered_token = [w for w in Tokens if len(w) &gt; 3]
review = &#39; &#39;.join(Filtered_token)
except Exception as e:
print(f&quot;Error processing review at index {r}: {e}&quot;)
continue
# 保存已清理的文本
Cleaned_doc.append(review)
print(&#39;-[Review Text]: &#39;, review)

打印出以下示例：
&quot;-[Review Text]: love christma light park crowd were ugly ever seen have been disneyland mani time have experienc long wait time past visit overwhelm with crowd crowd poopl they park wheel chair even monitor entri into park allow onli peopl time upon peopl&quot;
然后我使用以下代码删除停用词：
from nltk.corpus import stopwords import nltk
nltk.download(&#39;stopwords&#39;)

stop_words = stopwords.words(&#39;english&#39;)

#删除停用词

for r in range(len(Cleaned_doc)):
each_item = []
for t in Cleaned_doc[r].split():
if t not in stop_words:
each_item.append(t)
Cleaned_doc[r] = &#39; &#39;.join(each_item)
print(&#39;-[Cleaned Text]: &#39;, Cleaned_doc[r])


打印出以下示例：
-[Cleaned Text]: love christma light park crowd fastest ever seen disneyland mani time experienc long wait time past visit overwhelm crowd crowd peopl park wheel chair even monitor entri park allow onli peopl time upon peopl exit light decor awesom think return dure圣诞假期
最终收集以下情绪代码进行分析：
来自 nltk.tokenize 导入 sent_tokenize
来自 nltk.sentiment.vader 导入 SentimentIntensityAnalyzer

sid = SentimentIntensityAnalyzer()
OverallSen = sid.polarity_scores(cali_str)
print(&#39;总体情绪得分： \\n&#39;, OverallSen)

总体情绪得分：
{&#39;neg&#39;: 0.052, &#39;neu&#39;: 0.746, &#39;pos&#39;: 0.202, &#39;compound&#39;: 1.0
出于某种原因，我所有的评论文本都出现了 1.0 复合分数和与此情绪分数类似的低负面/正面分数 - am我绊倒了还是这是正确的？]]></description>
      <guid>https://stackoverflow.com/questions/78819506/sentiment-analysis-clarification</guid>
      <pubDate>Thu, 01 Aug 2024 06:51:51 GMT</pubDate>
    </item>
    <item>
      <title>面部识别 - 机器学习 [关闭]</title>
      <link>https://stackoverflow.com/questions/78818666/facial-recognition-machine-learning</link>
      <description><![CDATA[我尝试在 Google Colab 上使用 Tensorflow 进行面部识别，但遇到了错误。之前运行正常，但现在却出现此错误。完整的 .ipynb 文件已链接（请注意，您需要一个包含 .jpg 文件的负、正和锚文件夹才能运行程序。）
使暹罗模型出错
文件链接：https://www.mediafire.com/file/a5azngcpmdrrxyd/facial_recognition.ipynb/file
我尝试从 4.3 函数中删除嵌入函数，但当它进入训练时会抛出另一个错误。训练错误
文本代码错误复制：
（删除嵌入后）
Epoch 1/100
-----------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-123-5343d5708b2c&gt; in &lt;cell line: 5&gt;()
3 
4 # 使用提供的训练数据和指定的 epoch 数训练 Siamese 网络
----&gt; 5 训练（siamese_model、train_data、EPOCHS）

7 帧
/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py 在 binary_crossentropy（target、output、from_logits）中
666 
667 如果 len（target.shape）!= len（output.shape）：
-&gt; 668 引发 ValueError(
669 “参数 `target` 和 `output` 必须具有相同的等级”
670 “(ndim)。已收到：”

ValueError：在用户代码中：

文件“&lt;ipython-input-20-c4cff50f6a59&gt;”，第 18 行，在 train_step *
loss = binary_cross_loss(y, yhat)
文件“/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py”，第 43 行，在 __call__ **
loss = self.call(y_true, y_pred)
文件“/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py”，第 27 行，在 call
return self.fn(y_true, y_pred, **self._fn_kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py&quot;，第 1913 行，在 binary_crossentropy 中
ops.binary_crossentropy(y_true, y_pred, from_logits=from_logits),
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py&quot;，第 1398 行，在 binary_crossentropy 中
return backend.nn.binary_crossentropy(
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py&quot;，第 668 行，在 binary_crossentropy 中
引发 ValueError(

ValueError: 参数 `target` 和 `output` 必须具有相同的等级 (ndim)。收到：target.shape=(16,)，output.shape=(16, 100, 100, 1)

（在删除嵌入之前）

[&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_87&gt;]
-------------------------------------------------------------------------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-139-ccc48c560ce8&gt; in &lt;cell line: 24&gt;()
22 
23 # 使用 make_siamese_model() 函数创建 Siamese 神经网络模型
---&gt; 24 siamese_model = make_siamese_model()
25 
26 # 显示 Siamese 模型的架构和参数摘要

2 帧
&lt;ipython-input-138-755d3b4e05cd&gt; in call(self, input_embedding, validation_embedding)
7 # 魔法在这里发生 - 相似度计算
8 def call(self, input_embedding, validation_embedding):
----&gt; 9 return tf.math.abs(input_embedding - validation_embedding)

TypeError：调用 L1Dist.call() 时遇到异常。

无法自动推断“l1_dist_12”（类型为 L1Dist）的输出形状/dtype。 `L1Dist.call()` 方法不正确，或者您需要实现 `L1Dist.compute_output_spec() / compute_output_shape()` 方法。遇到错误：

不支持的操作数类型：-：&#39;list&#39; 和 &#39;list&#39;

L1Dist.call() 收到的参数：
• args=([&#39;&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_88&gt;&#39;], [&#39;&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_89&gt;&#39;])
• kwargs=&lt;class &#39;inspect._empty&#39;&gt;
]]></description>
      <guid>https://stackoverflow.com/questions/78818666/facial-recognition-machine-learning</guid>
      <pubDate>Wed, 31 Jul 2024 23:57:30 GMT</pubDate>
    </item>
    <item>
      <title>TF2 和 Python 中的 BERT 预处理器模型存在问题</title>
      <link>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</link>
      <description><![CDATA[我正在尝试使用 BERT 进行文本分类项目。但是我一直遇到此错误
`
ValueError Traceback（最近一次调用最后一次）
Cell In[37]，第 4 行
2 text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
3 bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;preprocessing&#39;)
----&gt; 4 preprocessed_text = bert_preprocess(text_input)
5 bert_encoder = hub.KerasLayer(encoder_url, 
6 trainable=True, 
7 name=&#39;BERT_encoder&#39;)
8 output = bert_encoder(preprocessed_text)
ValueError：调用层“preprocessing”（类型 KerasLayer）时遇到异常。
KerasTensor 是符号化的：它是形状和数据类型的占位符。它没有任何实际数值。您无法将其转换为 NumPy 数组。

调用层“预处理”（类型 KerasLayer）接收的参数：
• 输入=&lt;KerasTensor shape=(None,), dtype=string, sparse=None, name=text&gt;
• 训练=None

KerasTensor 是符号化的：它是形状和数据类型的占位符。它没有任何实际数值。您无法将其转换为 NumPy 数组。


构建此模型时：

preprocess_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3&#39;
encoder_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-768-a-12/versions/2&#39;

# Bert 层
text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;preprocessing&#39;)
preprocessed_text = bert_preprocess(text_input)
bert_encoder = hub.KerasLayer(encoder_url,
trainable=True, 
name=&#39;BERT_encoder&#39;)
outputs = bert_encoder(preprocessed_text)

# 神经网络层
l = tf.keras.layers.Dropout(0.1)(outputs[&#39;pooled_output&#39;])
l = tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;,name=&#39;output&#39;)(l)

# 构建最终模型
model = tf.keras.Model(inputs=[text_input],outputs=[l])

我看过无数教程，甚至使用过 tensorflow 文档中的教程，但即使我复制粘贴，它们仍然不起作用。我尝试过不同版本的 tf、tf-text 和 tf-hub。我正在为这个项目使用 tensorflow-gpu-jupyter docker 容器。
以下是我安装库的方法：
!pip install &quot;tensorflow-text&quot;
!pip install &quot;tf-models-official&quot;
!pip install &quot;tensorflow-hub&quot;

版本如下：
Tensorflow：2.16.1
tensorflow-text：2.16.1
tensorflow-hub：0.16.1
我看到的所有其他论坛都说要执行 tf.config.run_functions_eagerly(True)，但这不起作用。
任何方法都会有帮助。如果您知道如何解决，请回答。]]></description>
      <guid>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</guid>
      <pubDate>Tue, 19 Mar 2024 01:42:01 GMT</pubDate>
    </item>
    </channel>
</rss>