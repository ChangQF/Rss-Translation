<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 21 Sep 2024 06:21:21 GMT</lastBuildDate>
    <item>
      <title>使用 Scikit-learn、XGBoost 和 Prophet 时，保存训练模型的最佳文件格式是什么？</title>
      <link>https://stackoverflow.com/questions/79008634/what-is-the-best-file-format-to-save-trained-model-when-using-scikit-learn-xgbo</link>
      <description><![CDATA[问题
我正在使用 Scikit-learn 开展 ML 项目。根据我的研究，人们建议使用 .joblib 保存经过训练的 Scikit-learn 模型。
这就是我将模型保存到 .joblib 的方式
import os
from joblib import dump

model_path = os.path.join(script_dir, &quot;../models/trained_model.joblib&quot;)
dump(model, model_path)
print(f&quot;Model saved at {model_path}&quot;)

我还想使用 XGBoost 和 Prophet 测试此模型，只是为了尝试不同的库。

什么是实现此目标的最佳文件格式？我在搜索过程中多次看到 ONNX，但似乎它与 Prophet 不兼容。

有没有办法同时将我的模型保存为 joblib 和 onnx，或者我是否需要将 jobllib 转换为 onnx 文件？


任何最佳实践或建议都会有所帮助！]]></description>
      <guid>https://stackoverflow.com/questions/79008634/what-is-the-best-file-format-to-save-trained-model-when-using-scikit-learn-xgbo</guid>
      <pubDate>Sat, 21 Sep 2024 01:49:12 GMT</pubDate>
    </item>
    <item>
      <title>与其他架构相比，LSTM 为 Apple 的语言识别提供了哪些优势？[关闭]</title>
      <link>https://stackoverflow.com/questions/79008154/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</link>
      <description><![CDATA[既然 LSTM 的强大功能来自其长程依赖性记忆，那么为什么我们要使用 LSTM 而不是其他架构来从短文本字符串中进行基于字符的语言识别 (LID)？
例如，Apple 发布了一篇行业博客文章，指出他们使用 biLSTM 进行语言识别：https://machinelearning.apple.com/research/language-identification-from-very-short-strings
然后这篇论文试图复制它：https://aclanthology.org/2021.eacl-srw.6/
我在阅读 Karpathy 关于 RNN 的著名文章时，尝试训练一个小型语言识别模型进行练习。我首先尝试了一种简单、直观（对我来说）的方法：使用 tf-idf，使用在训练数据中的双或三元计数上训练的朴素贝叶斯分类器。我的数据集包含不同语系的 13 种语言。虽然我的简单分类器确实表现良好，但在查看类似语言时会出错。例如，西班牙语通常被归类为葡萄牙语。
我研究了神经网络架构，发现 LSTM 经常用于语言识别任务。在阅读了有关 RNN 和 LSTM 的内容后，我无法完全理解为什么 LSTM 更适合用于 LID，尤其是短文本字符串。这不是违反直觉的吗，因为 LSTM 擅长记住长距离依赖关系，而 RNN 则不然？对于短文本字符串，我建议使用 vanilla RNN....
Apple 博客确实说过，

在本文中，我们探讨了如何通过将其视为字符级别的序列标记问题，并使用在短字符序列上训练的双向长短期记忆 (bi-LSTM) 神经网络来提高 LID 准确性。

我觉得我没有理解这里的一些基本知识。
那么，他们的 LSTM 的学习目标是否是正确分类给定的字符 n-gram？这就是他们所说的“序列标记”问题吗？序列标记任务的根本难道不就是分类任务吗（“用 N 个预定义标签中的 1 个标记来自测试集的给定输入”）？
当您使用已知可以处理长序列的架构时，在短字符序列上训练 LSTM 有什么意义？]]></description>
      <guid>https://stackoverflow.com/questions/79008154/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</guid>
      <pubDate>Fri, 20 Sep 2024 20:18:48 GMT</pubDate>
    </item>
    <item>
      <title>复杂、混乱、非线性序列中的下一个数字 [关闭]</title>
      <link>https://stackoverflow.com/questions/79006702/next-number-in-a-complex-chaotic-and-non-linear-sequence</link>
      <description><![CDATA[查看图片
我试图预测一个复杂、混乱且非线性序列中的下一个数字。即使我无法准确预测下一个数字，我也想发现影响序列中值的模式。我认为可能发生的情况如下：
多种因素在起作用：序列中的每个数字可能受到多种不同属性或因素的影响，并且这些因素可以以复杂的方式相互作用。
可能存在噪音：序列可能包含噪音或异常，这意味着可能存在混淆事物的假阳性或假阴性。
属性之间的相互作用：某些属性可能不会产生孤立的影响，而是可以与其他属性（来自序列中的不同位置）相互作用以影响数字的值。
模式发现和预测：最终，我的目标是识别任何潜在模式（如果存在）。即使它是一个混乱的系统，我也希望预测序列中下一个数字的成功率至少达到 60%。
训练数据的困难：鉴于系统非常混乱，我不确定是否可以通过传统方式在一组测试数据上训练系统。
我需要帮助：

使用神经网络是解决此问题的最佳方法吗？
是否有任何现有程序或产品可用于解决此问题？

到目前为止我还没有尝试过任何方法]]></description>
      <guid>https://stackoverflow.com/questions/79006702/next-number-in-a-complex-chaotic-and-non-linear-sequence</guid>
      <pubDate>Fri, 20 Sep 2024 12:16:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 Imagecaption 模型虽然没有过度拟合且损失很低，但性能却很差？[关闭]</title>
      <link>https://stackoverflow.com/questions/79006661/why-does-my-imagecaption-model-perform-poorly-even-though-it-is-not-overfitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79006661/why-does-my-imagecaption-model-perform-poorly-even-though-it-is-not-overfitting</guid>
      <pubDate>Fri, 20 Sep 2024 12:03:50 GMT</pubDate>
    </item>
    <item>
      <title>从 Colab 获取不相关的响应</title>
      <link>https://stackoverflow.com/questions/79006597/getting-irrelevant-responses-from-the-colab</link>
      <description><![CDATA[我正在使用“Bringing-Old-Photos-Back-to-Life”存储库 colab。
但它运行整个存储库，并且没有在划痕图像上显示实际生成的图像。
GitHub Repo
示例图像附在下面：
左图为原始图像，右图由模型生成
我期待有人指导如何改进它。]]></description>
      <guid>https://stackoverflow.com/questions/79006597/getting-irrelevant-responses-from-the-colab</guid>
      <pubDate>Fri, 20 Sep 2024 11:44:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 tch-rs 在 rust 中实现残差神经网络</title>
      <link>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</link>
      <description><![CDATA[我正在尝试使用 tch-rs (Torch) 在 rust 中实现前馈残差神经网络。
到目前为止，这是我的代码：（这是一个最小的可重现示例）
use tch::{nn::{self, batch_norm1d, layer_norm, BatchNormConfig, ConvConfigND, LayerNormConfig, Module, ModuleT}, Tensor};
const NUM_HIDDEN: i64 = 10;

fn res_block(vs: &amp;nn::Path) -&gt; impl ModuleT {
let mut default = ConvConfigND::default();
default.padding = 1;
let conv1 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn1 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
让 conv2 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn2 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
nn::func_t(|x,train| {
let mut residual = Tensor::new();
x.clone(&amp;residual);
let x = bn1.forward_t(&amp;conv1.forward(x),train).relu();
let x = bn2.forward_t(&amp;conv2.forward(&amp;x),train);
let x = x + residual;
return x.relu();
})
}

当我编译此代码时，出现此错误：
`*mut torch_sys::C_tensor` 无法在线程之间安全地共享
在 `BatchNorm` 中，`*mut torch_sys::C_tensor` 未实现特征 `Sync`，而这是 `{closure@src\nn.rs:11:16: 所要求的11:25}：`&amp;BatchNorm` 实现 `Send` 所需的 Send

当我将 forward_t 行放入 func_t 中时，会发生此问题。
我该如何让它工作？
我也尝试使用顺序网络，但它们无法进一步传递残差变量。有没有办法让它工作？还是我需要做其他事情？]]></description>
      <guid>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</guid>
      <pubDate>Fri, 20 Sep 2024 09:07:36 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 lbl2vec 中的 SSL 认证错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/79005521/how-to-solve-ssl-certificaiton-error-in-lbl2vec</link>
      <description><![CDATA[我正在使用 lbl2vec 标记一些非结构化文本数据。但我开始收到 SSL 证书错误。如何解决此问题？
错误详细信息：
SSLError: (MaxRetryError(&quot;HTTPSConnectionPool(host=&#39;huggingface.co&#39;, 
port=443): url 的最大重试次数已超出：/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json 
(由 SSLError(SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] 
证书验证失败：无法获取本地颁发者证书 (_ssl.c:1000)&#39;)))&quot;), &#39;(请求 ID：xxxxxxxxxxxxxxxxxxxxxxxx)&#39;)

引发错误的代码：
from lbl2vec import Lbl2Vec

#使用参数初始化模型
Lbl2Vec_model = Lbl2Vec(keywords_list=list(labels.keywords), tagged_documents=newsgroup_full_corpus[&#39;tagged_docs&#39;][newsgroup_full_corpus[&#39;data_set_type&#39;] == &#39;train&#39;], label_names=list(labels.class_name), similarity_threshold=0.43, min_num_docs=100, epochs=10)

# 训练模型
Lbl2Vec_model.fit()
]]></description>
      <guid>https://stackoverflow.com/questions/79005521/how-to-solve-ssl-certificaiton-error-in-lbl2vec</guid>
      <pubDate>Fri, 20 Sep 2024 06:36:43 GMT</pubDate>
    </item>
    <item>
      <title>网页抓取问题：从网站提取干净数据 [关闭]</title>
      <link>https://stackoverflow.com/questions/79005517/issues-with-web-scraping-extracting-clean-data-from-websites</link>
      <description><![CDATA[问题：
我正在开展一个网页抓取项目，旨在从网站中提取干净、结构化的数据，以进一步丰富检索增强生成 (RAG) 模型。虽然我已经成功抓取并处理了 YouTube 转录本，但在抓取网站数据时我仍面临挑战。
我的方法：

使用的技术：

用于动态内容呈现的 Selenium
用于解析和提取 HTML 内容的 BeautifulSoup
用于过滤不需要的模式和噪音的 Regex 和 NLTK


我已采取的步骤：

删除了 &lt;script&gt;、&lt;style&gt; 等不属于主要内容的 HTML 元素。
使用正则表达式模式过滤掉不相关的数据，例如日期、电子邮件地址和 URL。
应用了 NLTK停用词来进一步清理文本。


代码片段：
这是我的 BeautifulSoup 抓取工具的一个示例：
from bs4 import BeautifulSoup
import request
import re
from nltk.corpus import stopwords

stop_words = set(stopwords.words(&#39;english&#39;))

class BeautifulSoupScraper:
@staticmethod
def extract_text_from_url(url):
response = request.get(url)
soup = BeautifulSoup(response.text, &#39;html.parser&#39;)

# 删除不需要的元素
for unwanted in soup([&#39;script&#39;, &#39;style&#39;, &#39;header&#39;, &#39;footer&#39;, &#39;nav&#39;, &#39;aside&#39;, &#39;form&#39;]):
unwanted.decompose()

段落 = soup.find_all(&#39;p&#39;)
文本 = &quot;\n&quot;.join([para.get_text() for para in 段落])
返回文本

@staticmethod
def filter_text(text):
# 删除不需要的模式（例如 URL、日期等）
unwanted_pa​​tterns = [r&#39;http[s]?://\S+&#39;, r&#39;\b\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\b&#39;]
for pattern in unwanted_pa​​tterns:
文本 = re.sub(pattern, &#39;&#39;, text)
返回 &#39; &#39;.join([word for word in text.split() if word.lower() not in stop_words])

我还使用 Selenium 动态收集搜索结果：
from selenium import webdriver
来自 selenium.webdriver.common.by import By

class GoogleSearch:
@staticmethod
def search(keyword, num_results=5):
driver = webdriver.Chrome()
driver.get(f&quot;https://www.google.com/search?q={keyword}&quot;)
elements = driver.find_elements(By.CLASS_NAME, &quot;MjjYud&quot;)[:num_results]
links = [element.find_element(By.TAG_NAME, &#39;a&#39;).get_attribute(&#39;href&#39;) for element in elements]
driver.quit()
return links



问题：
尽管使用 BeautifulSoup 和正则表达式过滤掉不需要的数据，但提取的内容中仍然有很多噪音，尤其是来自评论部分、广告和其他不相关的内容网页的部分。我的目标是干净地提取有意义的文本（例如，博客内容、文章文本），而不产生这些噪音。
我尝试过的方法：

使用正则表达式删除日期、URL 和电子邮件地址等常见模式。
使用 NLTK 删除停用词。
按关键字过滤（例如，“订阅”、“评论”），但这仍然会留下不需要的网页部分。

我需要的方法：

改进过滤过程的最佳实践或建议，尤其是删除网页中不相关的部分。
除了正则表达式和基本停用词过滤之外，还有更有效的清理抓取数据的方法的建议。
在处理不同类型的网站时，有没有关于如何使提取过程更准确、无噪音的建议结构。
]]></description>
      <guid>https://stackoverflow.com/questions/79005517/issues-with-web-scraping-extracting-clean-data-from-websites</guid>
      <pubDate>Fri, 20 Sep 2024 06:34:55 GMT</pubDate>
    </item>
    <item>
      <title>在将作业提交给 QPU 之前，如何预先检查代码中的错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/79005253/how-to-check-for-errors-beforehand-in-the-code-before-submitting-the-job-to-qpu</link>
      <description><![CDATA[在 QSVM 中，有没有办法在将量子代码提交给 QPU 进行处理之前检查错误？因为即使代码有错误，QPU 也会运行，这意味着我们将白白浪费大量时间。那么，有没有什么方法可以解决这个问题呢？]]></description>
      <guid>https://stackoverflow.com/questions/79005253/how-to-check-for-errors-beforehand-in-the-code-before-submitting-the-job-to-qpu</guid>
      <pubDate>Fri, 20 Sep 2024 04:51:21 GMT</pubDate>
    </item>
    <item>
      <title>无法从 Pytorch Dataset 的 __get_item__ 返回布尔变量</title>
      <link>https://stackoverflow.com/questions/79000230/unable-to-return-a-boolean-variable-from-pytorch-datasets-get-item</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79000230/unable-to-return-a-boolean-variable-from-pytorch-datasets-get-item</guid>
      <pubDate>Wed, 18 Sep 2024 21:33:47 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface Pretrained 中 device_map = "auto" 的替代方案</title>
      <link>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</link>
      <description><![CDATA[我有一个从 huggingface 读取的模型，使用以下代码：
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

现在我读取了模型，并对内部层做了一些修改，并添加了更多层。当我开始训练/微调时，我发现并非所有东西都在同一个模型上。
现在经过更多调查，我发现我的自定义层没有像原始模型那样分布在多个 GPU 上。因此我需要类似 device_map=&quot;auto&quot; 的内容，但在读取模型之后。
因此只需类似
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

model.device_map = &quot;auto&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</guid>
      <pubDate>Sat, 14 Sep 2024 12:42:03 GMT</pubDate>
    </item>
    <item>
      <title>尽管分类报告很好，但模型无法正确预测</title>
      <link>https://stackoverflow.com/questions/78976316/model-cant-predict-correctly-even-though-has-a-good-classification-report</link>
      <description><![CDATA[我尝试从链接运行此模型：
https://www.kaggle.com/code/alexfordna/garbage-classification-mobilenetv2-92-accuracy/notebook
当我在 colab 上使用类似数据集（但较小，2100 张图片到 6 个类）执行此操作时，效果很好。但是当我添加此代码来预测输入图像时：
from google.colab import files
from PIL import Image

def process_uploaded_image(image_path, target_size=(224, 224)):
img = Image.open(image_path)
img = img.resize(target_size) 
img_array = np.array(img) 

if img_array.shape[-1] == 4: 
img_array = img_array[..., :3]

img_array = img_array / 255.0 
img_array = np.expand_dims(img_array, axis=0) 
img_array = mobilenetv2.preprocess_input(img_array) 

return img_array

uploaded = files.upload()

for fn in uploaded.keys(): 
processed_image = process_uploaded_image(fn, target_size=IMAGE_SIZE) 
preds = model.predict(processed_image)
pred_class = np.argmax(preds, axis=1)

plt.imshow(Image.open(fn)) # 显示上传的图片
plt.title(f&#39;预测的类别：{categories[pred_class[0]]}&#39;)
plt.axis(&#39;off&#39;)
plt.show()
print(f&#39;文件 {fn} 被预测为：{categories[pred_class[0]]}&#39;)

结果是错误的预测。例如，模型总是将我的输入预测为“垃圾”类。当我停止运行时，它会更改为另一个类，但它仍然处于错误的预测中。
我还添加了此代码来检查预测概率：
preds = model.predict(processed_image)
pred_probs = preds[0] # 获取第一个（也是唯一一个）批次的预测概率
print(&quot;Prediction probabilities:&quot;, pred_probs)
pred_class = np.argmax(pred_probs)
print(&quot;Predicted class:&quot;, categories[pred_class])

输出：
**1/1** ━━━━━━━━━━━━━━━━━━━━━━ **0s** 24ms/步 预测概率：\[0.31027108 0.12315894 0.47848797 0.00863316 0.07789086 0.00155797\] 
预测类别：金属 

为什么会发生这种情况，我的模型如何正确预测结果？]]></description>
      <guid>https://stackoverflow.com/questions/78976316/model-cant-predict-correctly-even-though-has-a-good-classification-report</guid>
      <pubDate>Thu, 12 Sep 2024 02:58:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在 nltk 中下载 punkt tokenizer？</title>
      <link>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</link>
      <description><![CDATA[我使用 安装了 NLTK 库
pip install nltk

在使用库时
from nltk.tokenize import sent_tokenize 
sent_tokenize(text)

我收到此错误
LookupError: 
**************************************************************************
未找到资源 punkt。
请使用 NLTK 下载器获取资源：

&gt;&gt;&gt; import nltk
&gt;&gt;&gt; nltk.download(&#39;punkt&#39;)

有关更多信息，请参阅：https://www.nltk.org/data.html

尝试加载 tokenizers/punkt/english.pickle

搜索位置：
- &#39;C:\\Users\\adars/nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\share\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Roaming\\nltk_data&#39;
- &#39;C:\\nltk_data&#39;
- &#39;D:\\nltk_data&#39;
- &#39;E:\\nltk_data&#39;
- &#39;&#39;

因此，为了解决此错误，我尝试了
import nltk
nltk.download(&#39;punkt&#39;)

但是我无法下载此包，因为每次运行此包时都会出现错误，提示
[nltk_data] 加载 punkt 时出错：&lt;urlopen 错误 [WinError 10060] A
[nltk_data] 连接尝试失败，因为连接方
[nltk_data] 在一段时间后未正确响应，或者
[nltk_data] 建立连接失败，因为连接的主机
[nltk_data] 未响应&gt;

请帮帮我]]></description>
      <guid>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</guid>
      <pubDate>Tue, 19 Sep 2023 04:36:59 GMT</pubDate>
    </item>
    <item>
      <title>如何继续进一步训练预先训练的 YOLOv8 模型</title>
      <link>https://stackoverflow.com/questions/75730103/how-to-continue-to-further-train-a-pre-trained-yolov8-model</link>
      <description><![CDATA[我已经在自定义数据集上训练了一个包含 4 个类别的 YOLOv8 模型，用于对象检测。
现在我想通过增加数据集来训练它以检测更多类别。
我是否可以在新数据集上进一步专门训练它，而不是从头开始训练模型？]]></description>
      <guid>https://stackoverflow.com/questions/75730103/how-to-continue-to-further-train-a-pre-trained-yolov8-model</guid>
      <pubDate>Tue, 14 Mar 2023 07:23:23 GMT</pubDate>
    </item>
    <item>
      <title>onnxruntime 推理比 GPU 上的 pytorch 慢得多</title>
      <link>https://stackoverflow.com/questions/70740287/onnxruntime-inference-is-way-slower-than-pytorch-on-gpu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/70740287/onnxruntime-inference-is-way-slower-than-pytorch-on-gpu</guid>
      <pubDate>Mon, 17 Jan 2022 11:03:53 GMT</pubDate>
    </item>
    </channel>
</rss>