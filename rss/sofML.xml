<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 09 Dec 2023 18:16:18 GMT</lastBuildDate>
    <item>
      <title>TensorFlow 的自定义优化器</title>
      <link>https://stackoverflow.com/questions/77632195/custom-optimizer-for-tensorflow</link>
      <description><![CDATA[我正在尝试在 TensorFlow 上试验神经网络的自定义优化算法，但由于缺乏有关该主题的信息而陷入困境。我需要的是一些代码，这些代码将在每次迭代时为我提供向量 x （当前点）和向量 g （x 处的梯度），然后我将更新 x，然后使用一些代码来设置更新后的值。这是我目前所拥有的：
来自tensorflow.python.framework导入操作
从tensorflow.python.ops导入gen_training_ops
从tensorflow.python.ops导入math_ops
从tensorflow.python.training导入优化器
从tensorflow.python.util.tf_export导入tf_export
将张量流导入为 tf
将 numpy 导入为 np

类 TestGD(优化器.优化器):
  def __init__(自身, rad=0.01,
               use_locking=False, name=“TestGD”）：
    super(TestGD, self).__init__(use_locking, 名称)
    self._radius = rad

  def _create_slots(self, var_list):
    num_dims = len(var_list)
    self._beta = (num_dims - 1) / (num_dims + 1)
    self._B_matrix = np.identity(num_dims)

  def _prepare（自我）：
    self._radn_t = ops.convert_to_tensor(self._call_if_callable(self._radius), name=“beta”)
    self._beta_t = ops.convert_to_tensor(self._call_if_callable(self._beta), name=“beta”)
    self._B_matrix_t = ops.convert_to_tensor(self._call_if_callable(self._B_matrix), name=“B”)

  def _apply_dense（自身，梯度，变量）：
    返回 self._resource_apply_dense(grad, var)

  def _resource_apply_dense（自身，梯度，变量）：
    print(grad.shape, &quot;&lt;------------&quot;)
    #我计划在这里的某个地方实现我的算法
    var_update = tf.compat.v1.assign_sub(var, 0.01 * grad)
    返回 tf.group(var_update)

  def _apply_sparse(自我, grad, var):
    raise NotImplementedError(“不支持稀疏梯度更新。”)


# 构建LeNet模型
模型 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), 激活=&#39;relu&#39;, input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), 激活=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(120, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(84, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(10, 激活=&#39;softmax&#39;)
]）

# 使用您的自定义优化器
#custom_optimizer = SimpleGD(learning_rate=0.001)
自定义优化器 = TestGD()

# 使用自定义优化器编译模型
model.compile(优化器=custom_optimizer,
              损失=&#39;sparse_categorical_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

# 获取数据集
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0 # 将像素值标准化为 0 到 1 之间

x_train = x_train[..., tf.newaxis].astype(“float32”)
x_test = x_test[..., tf.newaxis].astype(“float32”)

train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=60000).batch(64)

test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
测试数据集 = 测试数据集.batch(64)

＃ 训练
model.fit(train_dataset, epochs=5)

＃ 评估
test_loss, test_acc = model.evaluate(test_dataset)
print(f&quot;测试准确度：{test_acc}&quot;)

问题是，我得到的 grad 和 var 的形状非常奇怪，它们绝对不是向量。我应该怎么做才能将问题减少到 x 和 g 向量以及如何在最小化步骤后正确更新结果？]]></description>
      <guid>https://stackoverflow.com/questions/77632195/custom-optimizer-for-tensorflow</guid>
      <pubDate>Sat, 09 Dec 2023 17:23:42 GMT</pubDate>
    </item>
    <item>
      <title>协助在 Python 代码中集成预训练数据和测试 [关闭]</title>
      <link>https://stackoverflow.com/questions/77630814/assistance-with-integrating-pretrained-data-and-testing-in-python-code</link>
      <description><![CDATA[我正在开发一个 Python 项目，我需要将训练数据和测试数据集成到我的代码中全局算法已在 C++ 中实现。然而，我对是否将预训练数据放置在正确的位置感到有点迷失。我尝试添加数据，但不确定它是否位于正确的位置。
此外，我在使用自己的数据集测试代码并分析输出方面面临挑战。任何人都可以提供有关预训练数据的正确放置的指导或建议，并提供使用自定义数据有效测试代码的见解吗？
仓库：https://github.com/Lecanyu/JigsawNet]]></description>
      <guid>https://stackoverflow.com/questions/77630814/assistance-with-integrating-pretrained-data-and-testing-in-python-code</guid>
      <pubDate>Sat, 09 Dec 2023 09:39:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在wmt数据集中提取人类得分[关闭]</title>
      <link>https://stackoverflow.com/questions/77630433/how-to-extract-human-score-in-wmt-dataset</link>
      <description><![CDATA[我需要带有人工评分的 WMT 新闻数据。我查看了github链接 https://github.com/wmt-conference/wmt22-news -systems ，有一个 xml 文件夹，其中包含源、参考、翻译数据。还有另一个名为 humaneval 的文件夹，其中提供了人工评分。
我面临着连接这两个数据的挑战。在 humaneval 数据中提供了 SID 列，但其值与 xml 数据中提供的 source_id 不同。
如果有人可以帮助指导这两个数据文件夹之间的连接，那将会很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77630433/how-to-extract-human-score-in-wmt-dataset</guid>
      <pubDate>Sat, 09 Dec 2023 07:03:35 GMT</pubDate>
    </item>
    <item>
      <title>计算学习问题：3-DNF 约简 [关闭]</title>
      <link>https://stackoverflow.com/questions/77630359/computational-learning-problem-3-dnf-reduction</link>
      <description><![CDATA[我不知道如何解决这个问题。问题陈述是：考虑二元分类问题，其中 X = R
d 和 Y = {0, 1}。考虑
由三个半空间的交集给出的二元分类器的类别。
表明正确的学习是正确的。此类三个半空间的交集（
F 类）在计算上很难正确学习，除非 NP = RP。具体来说
提示：请记住，我们只考虑正确的学习。尝试使用减少
3学期DNF课程。额外的提示是使用 d = 2m, m 坐标来包含
每个坐标和 m 坐标以包含它们的否定。
我正在从 3-DNF 进行简化，并尝试将其转换为 3-CNF，这可以通过在 [-1,+1]^d 中设置 x 并在 [0,1]^d 中设置 w 来实现。但我不确定从那里开始应该采取什么步骤。
问题描述
我已经写出了以下内容作为解决该问题的一般方法，但我不确定如何真正解释如何证明减少的第二个陈述：
当前工作]]></description>
      <guid>https://stackoverflow.com/questions/77630359/computational-learning-problem-3-dnf-reduction</guid>
      <pubDate>Sat, 09 Dec 2023 06:29:12 GMT</pubDate>
    </item>
    <item>
      <title>RandomForest 函数在预测函数中应用时给出错误[关闭]</title>
      <link>https://stackoverflow.com/questions/77629933/randomforest-function-giving-error-when-applied-in-predict-function</link>
      <description><![CDATA[当我使用 randomForest 训练模型，然后尝试按以下方式进行预测时，没有问题：
rf &lt;- randomForest(price_category~., data=train_set, ntree=300,importance=TRUE)

test_set$ClassPredicted &lt;- 预测(rf, newdata = test_set, &quot;class&quot;)

但是，当我尝试选择预测变量并按以下方式构建它时：
 rf1 &lt;- randomForest（价格类别 = 生活区域 + 年 + n_照片 + 能源标签，数据 = train_set，ntree=1000，重要性=TRUE）

test_set$ClassPredicted &lt;- 预测(rf1, newdata = test_set, &quot;class&quot;)

弹出此错误：
predict.randomForest(rf1, newdata = test_set, &quot;response&quot;) 中的错误没有森林
对象中的组件

为什么会发生这种情况以及如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77629933/randomforest-function-giving-error-when-applied-in-predict-function</guid>
      <pubDate>Sat, 09 Dec 2023 02:24:34 GMT</pubDate>
    </item>
    <item>
      <title>MMDetection3D 和 nuScenes：输出格式、转换和比较</title>
      <link>https://stackoverflow.com/questions/77629887/mmdetection3d-and-nuscenes-output-format-conversion-and-comparision</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77629887/mmdetection3d-and-nuscenes-output-format-conversion-and-comparision</guid>
      <pubDate>Sat, 09 Dec 2023 01:53:34 GMT</pubDate>
    </item>
    <item>
      <title>实时多重检测 (RTMDet) CONFIG_PATH fileNotFoundError</title>
      <link>https://stackoverflow.com/questions/77629676/real-time-multi-detection-rtmdet-config-path-filenotfounderror</link>
      <description><![CDATA[我正在尝试遵循 Roboflow 指南&lt; /a&gt; 在自定义数据集上训练 RTMDet。我没有高端 GPU，因此我尝试使用 Colab 环境。
当我尝试使用 rtmdet_m 权重和配置文件初始化模型时，我收到 filenotfound 错误，即使我 100% 肯定文件存在于驱动器目录中。我相信这个问题与下面的配置文件中的 Base 有关
_base_ = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_l_syncbn_fast_8xb32-300e_coco.py&#39;



# ========================修改参数======================
加深因子 = 0.67
加宽因子 = 0.75

# =======================大多数情况下未修改==================
模型=字典（
主干=字典（深度因子=深度因子，加宽因子=加宽因子），
颈部=字典（深度因子=深度因子，加宽因子=加宽因子），
bbox_head=dict(head_module=dict(widen_factor=widen_factor)))

我还尝试将配置文件移动到本地 /content 目录，但它没有解决问题
这是我用于初始化的其余代码以及确切的错误消息
# 设置配置和权重文件的路径
WEIGHTS_PATH = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_m_syncbn_fast_8xb32-
300e_coco_20230102_135952-40af4fe8.pth&#39;
CONFIG_PATH = &#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_m_syncbn_fast_8xb32-300e_coco.py&#39;

# 初始化模型
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
模型= init_ detector（CONFIG_PATH，WEIGHTS_PATH，设备= DEVICE）

-------------------------------------------------- ------------------------
FileNotFoundError Traceback（最近一次调用最后一次）
&lt;ipython-input-61-1d88a7ed1feb&gt;在&lt;细胞系：3&gt;()
      1 # 初始化模型
      2 DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
----&gt; 3 模型= init_ detector（CONFIG_PATH，WEIGHTS_PATH，设备= DEVICE）

5帧
_is_lazy_import(文件名)中的/usr/local/lib/python3.10/dist-packages/mmengine/config/config.py
   第1653章
   第1654章
-&gt;第1655章
   第1656章
   第1657章

FileNotFoundError: [Errno 2] 没有这样的文件或目录:
&#39;/content/drive/MyDrive/RTMDet_Models/rtmdet_l_syncbn_fast_8xb32-300e_coco.py&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/77629676/real-time-multi-detection-rtmdet-config-path-filenotfounderror</guid>
      <pubDate>Fri, 08 Dec 2023 23:50:24 GMT</pubDate>
    </item>
    <item>
      <title>将“n”个文件夹中的一组图像转换为数据集（例如：Mnist），以与 CNN 一起使用</title>
      <link>https://stackoverflow.com/questions/77629619/convert-a-group-of-images-in-n-folders-to-dataset-eg-mnist-to-work-with-cn</link>
      <description><![CDATA[我正在尝试将生成的图像转换为数据集。
（我只有 n 文件夹中的 png 图像，没有标签或元数据）
这就是我渴望做的事情：

我正在使用 torch audio 将音频格式转换为 Mel 频谱图 并将图像保存为 png 格式。状态：完成

现在我有 n 个带有图像的文件夹（类），所以我很好奇是否可以将新生成的图像转换为数据并
目标与普通数据集中一样，以便我可以使用 sklearn 来执行
测试列车分割sklearn.model_selection.train_test_split
。
状态：未完成


例如：获取 mnist 数据集
ds_mnist = sklearn.datasets.fetch_openml(
     数据 ID=554，
     as_frame=假
 ）

将数据和目标拆分为 X 和 y
dataset_X = ds_mnist .data.astype(&#39;float32&#39;)

dataset_y = ds_mnist .target.astype(&#39;int64&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/77629619/convert-a-group-of-images-in-n-folders-to-dataset-eg-mnist-to-work-with-cn</guid>
      <pubDate>Fri, 08 Dec 2023 23:30:07 GMT</pubDate>
    </item>
    <item>
      <title>为深度学习项目寻找替代库[关闭]</title>
      <link>https://stackoverflow.com/questions/77629191/looking-for-alternate-libraries-for-a-deep-learning-project</link>
      <description><![CDATA[我有Python 3.12.0。我的项目需要 TensorFlow，但它只能与 Python 3.11 一起使用。 PyTorch 也是如此。有谁知道我可以使用其他库来代替我提到的库，并且与 Python 3.12 兼容？尝试安装 TensorFlow 和 PyTorch。]]></description>
      <guid>https://stackoverflow.com/questions/77629191/looking-for-alternate-libraries-for-a-deep-learning-project</guid>
      <pubDate>Fri, 08 Dec 2023 21:09:44 GMT</pubDate>
    </item>
    <item>
      <title>如何提取 SequentialFeatureSelector 的最佳估计器</title>
      <link>https://stackoverflow.com/questions/77629138/how-to-extract-best-estimator-of-a-sequentialfeatureselector</link>
      <description><![CDATA[我已经从 sklearn 训练了一个 SequentialFeatureSelector，现在对它生成的最佳模型（基于给定的评分方法）感兴趣。是否有可能提取参数并使用它们生成所使用的模型？
我已经看到 SequentialFeatureSelector 存在一个 get_params() 函数，但我不明白如何解释输出并检索最佳估计器。&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77629138/how-to-extract-best-estimator-of-a-sequentialfeatureselector</guid>
      <pubDate>Fri, 08 Dec 2023 20:58:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 WEKA 检测信用卡欺诈？需要帮助[关闭]</title>
      <link>https://stackoverflow.com/questions/77629043/how-to-detect-credit-card-fraud-using-weka-help-needed</link>
      <description><![CDATA[我的计算机科学模块有这项作业。我需要使用 WEKA 来检测哪些用户可能拖欠信用卡到期付款。
我是 WEKA 的新手，所以有点困难。我收到了一个包含 48 个属性的 CSV，其中包括一个类：defaultnmIndicator 下个月默认的指示器（1=是，0=否）。
我需要预测，所以我知道我需要一个分类器。其中很多都是灰色的，包括 j48 和后勤。
例如，当我对整个集合运行线性回归时，相关系数约为 0.48。
我认为我在这里遗漏了一些非常明显的步骤。我的讲师刚刚建议我们搜索 YouTube，所以您可以想象这有多大帮助？
尝试的步骤：

我对数据集进行了标准化
估算缺失数据
使用完整训练集运行 CorrelationAttributeEval
尝试添加或删除此列表底部和顶部的属性，但模型没有得到真正的改进。
前 3 名：
`排名属性：
0.32588 43 金融压力指数
0.26159 22 平均循环信用卡利用率
0.24705 23 平均活跃信用额度利用率

&lt;小时/&gt;
底部3
-0.2096 30 任期最旧信用额度
-0.22082 自上次错过付款后 29 天
-0.40432 2 信用评分
`
我期望相关系数会更高。
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77629043/how-to-detect-credit-card-fraud-using-weka-help-needed</guid>
      <pubDate>Fri, 08 Dec 2023 20:33:44 GMT</pubDate>
    </item>
    <item>
      <title>不确定为什么我在 Snowflake 上使用 Python 进行逻辑回归时会遇到类型错误？</title>
      <link>https://stackoverflow.com/questions/77628292/unsure-why-im-running-into-type-errors-in-logistic-regression-using-python-on-s</link>
      <description><![CDATA[我正在使用 Python 在 Snowflake 上创建逻辑回归模型。我在本地 R 中做了相同的逻辑回归，但想将其转换到我的 Snowflake 数据仓库。我取得了一些成功，但我对 Python 的熟悉度还不如对 R 的熟悉度。
我相信回归是拟合并给出了一个模型。我真的不知道预测的概率是什么样的，但这确实是目前的次要问题。
我只想从 pandas DataFrame 返回一个雪花 DataFrame。我无法让它发生。
下面是我的代码片段。
导入snowflake.snowpark作为snowpark
导入 Snowflake.snowpark.functions 作为 F
从 sklearn.linear_model 导入 LogisticRegression
从 Snowflake.snowpark.functions 导入 col
将 pandas 导入为 pd

def main（会话：snowpark.Session）：
#
# 下面的一切都是数据转换，一切都工作得很好
＃ 据我所知

# ind_cols 和 dep_cols 是列名数组
# 定义哪些列是自变量，哪些列是因变量。
# 这里我将样本分为独立列和从属列，
# 并使用 scikit-learn 中的 LogisticRegression。

    X = full_sample[ind_cols].to_pandas()
    y = full_sample[dep_col].to_pandas()

# ret_df 是我有兴趣预测概率的雪花数据帧。
    ret_df_lm = ret_df[ind_cols].to_pandas()

    lm = 逻辑回归()

    lm.fit(X, y)

    y_pred = lm.predict_proba(ret_df_lm)

    y_final = session.table(y_pred)

    #retention_pred = lm.predict(ret_df)

    返回 y_final

当我尝试返回y_final时，我收到错误TypeError：序列项0：预期的str实例，找到numpy.ndarray。我一定错过了一些东西。我尝试过其他东西，比如雪花的 session.write_pandas() 但我不确定这是否是我需要的。
如何使 y_final 成为雪花 DataFrame？]]></description>
      <guid>https://stackoverflow.com/questions/77628292/unsure-why-im-running-into-type-errors-in-logistic-regression-using-python-on-s</guid>
      <pubDate>Fri, 08 Dec 2023 17:36:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么 tfidf 对象会抛出“没有属性预测”错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77626940/why-is-the-tfidf-object-throwing-the-has-no-attribute-predict-error</link>
      <description><![CDATA[在此处输入图像描述
这是我的代码
在此处输入图片描述
在此处输入图像说明
我正在尝试加载两个预定义模型，一个是 tfidf，另一个是 LR_model，但如果电影评论是正面还是负面，它将进行分类。]]></description>
      <guid>https://stackoverflow.com/questions/77626940/why-is-the-tfidf-object-throwing-the-has-no-attribute-predict-error</guid>
      <pubDate>Fri, 08 Dec 2023 13:32:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 RNN 确定可接受的情感分析基线</title>
      <link>https://stackoverflow.com/questions/77623881/determining-an-acceptable-baseline-for-sentiment-analysis-using-rnns</link>
      <description><![CDATA[按照我发现的教程，我一直在尝试使用循环神经网络 (RNN) 进行情感分析 此处。虽然我的模型可以正常运行，但我在准确性方面遇到了障碍，始终达到 85-90% 之间。我尝试了各种优化，但我不确定什么构成了结束我的努力的合理基线，特别是考虑到基于 Transformer 的 LSTM 模型的潜在效率。
我的主要查询并不是以进一步提高准确性为中心；相反，我寻求指导来确定何时考虑情感分析模型对于实际使用足够有效，特别是在使用 RNN 来完成此任务时。由于我对机器学习相对陌生，因此我不清楚何时确定我的目标已实现。]]></description>
      <guid>https://stackoverflow.com/questions/77623881/determining-an-acceptable-baseline-for-sentiment-analysis-using-rnns</guid>
      <pubDate>Fri, 08 Dec 2023 01:35:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用LSTM模型进行多步预测？</title>
      <link>https://stackoverflow.com/questions/69785891/how-to-use-the-lstm-model-for-multi-step-forecasting</link>
      <description><![CDATA[我用 LSTM 开发了一个时间序列模型。我不能用它来预测未来几天的股价。我想用它来预测明年的股价并绘制它。如何用它来预测未来（明年）的股价？
df=pd.read_csv(&#39;foolad.csv&#39;)
df=df.set_index(pd.DatetimeIndex(df[&#39;Date&#39;].values))

data=df.filter([&#39;关闭&#39;])
数据集=数据.值

Training_data_len=math.ceil(len(数据集)*0.8)
缩放器=MinMaxScaler(feature_range=(0,1))
scaled_data=scaler.fit_transform(数据集)
缩放数据

训练数据=缩放数据[0:训练数据长度，:]

xtrain=[]
y火车=[]
人数 = 60

对于范围内的 i(n,len(training_data))：
    xtrain.append(training_data[i-n:i, 0])
    ytrain.append(training_data[i,0])

xtrain , ytrain = np.array(xtrain) , np.array(ytrain)
xtrain=np.reshape(xtrain , (xtrain.shape[0],xtrain.shape[1],1))
xtrain.shape

模型=顺序()
model.add(LSTM(50,return_sequences=True,input_shape=(xtrain.shape[1],1)))
model.add(LSTM(50,return_sequences=False))
model.add(密集(25))
model.add(密集(1))

model.compile(loss=&#39;mean_squared_error&#39;,optimizer=&#39;adam&#39;)

model.fit(xtrain,ytrain,epochs=1,batch_size=1)

test_data=scaled_data[training_data_len - n : , :]
x测试=[]
ytest=数据集[training_data_len:,:]
对于范围内的 i(n , len(test_data))：
    xtest.append(test_data[i-n : i , 0])

xtest=np.array(xtest)
xtest=np.reshape(xtest , (xtest.shape[0],xtest.shape[1],1))

预测=模型.预测(xtest)
预测=scaler.inverse_transform(预测)

#未来360天我能做什么？......

]]></description>
      <guid>https://stackoverflow.com/questions/69785891/how-to-use-the-lstm-model-for-multi-step-forecasting</guid>
      <pubDate>Sun, 31 Oct 2021 10:20:32 GMT</pubDate>
    </item>
    </channel>
</rss>