<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 10 Apr 2024 00:57:59 GMT</lastBuildDate>
    <item>
      <title>用于大规模服务器管理的人工智能自动化</title>
      <link>https://stackoverflow.com/questions/78301638/artificial-intelligence-enabled-automation-for-large-scale-server-management</link>
      <description><![CDATA[简介：在当今世界，有效管理企业的服务器基础设施可能既复杂又耗时。跟踪和管理数千台服务器在不同团队中的分布情况以及负责人通常会给管理员带来一项具有挑战性的任务。然而，人工智能 (AI) 和机器学习 (ML) 技术的发展为克服这些挑战提供了新的创新解决方案。
人工智能服务器管理：人工智能服务器管理可以作为有效管理大规模服务器基础设施的强大工具。这种方法涉及利用人工智能模型来确定哪些团队使用服务器以及谁负责它们。例如，可以创建包含服务器的 IP 地址、位置、功能和其他相关详细信息等信息的数据集。
通过机器学习自动化服务器部署：机器学习算法可以利用此数据集来预测哪些团队使用服务器。例如，可以开发基于特定服务器特征的分类模型。利用该模型可以预测服务器所属的团队，为管理员优化服务器部署提供指导。
安全和数据隐私：在支持人工智能的服务器管理应用程序中，安全和数据隐私是至关重要的问题。因此，必须实施安全措施来保护用户身份和密码等敏感信息。例如，服务器访问信息应安全存储，并且只有授权用户才能访问。
结论和建议：支持人工智能的服务器管理可以成为有效管理大规模服务器基础设施的有效工具。机器学习模型的利用可以在确定使用服务器的团队和优化服务器部署方面发挥重要作用。但是，始终考虑安全和数据隐私问题并实施适当的安全措施至关重要。
此时，在人工智能服务器管理领域需要进一步的研究和开发。然而，利用现有技术和方法，高效、安全地管理大规模服务器基础设施是可以实现的。
**综上所述，考虑到上述几点，我如何通过人工智能确定我的服务器（Red Hat、Solaris、Ubuntu、Debian 等）分配给哪个团队？注意：所有服务器都有可用的 root 用户和密码信息，我可以通过 SSH 连接。 **]]></description>
      <guid>https://stackoverflow.com/questions/78301638/artificial-intelligence-enabled-automation-for-large-scale-server-management</guid>
      <pubDate>Wed, 10 Apr 2024 00:21:07 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：“模型”层的输入 0 与该层不兼容：预期形状=（无，64，32，1），发现形状=（32，32，1）</title>
      <link>https://stackoverflow.com/questions/78301623/valueerror-input-0-of-layer-model-is-incompatible-with-the-layer-expected-sh</link>
      <description><![CDATA[我尝试调试并添加了打印语句，令我惊讶的是它的形状是正确的，但程序说它的形状不正确
形状：（无、64、32、1）
型号：“型号”
&lt;小时/&gt;
层（类型）输出形状参数#
图像（输入层）[(无, 64, 32, 1)] 0
Conv1（Conv2D）（无、64、32、32）320
pool1 (MaxPooling2D)（无、32、16、32）0
batch_normalization (BatchN (无, 32, 16, 32) 128
正规化）
重塑（重塑）（无、32、512）0
dense2（密集）（无、32、16）8208
batch_normalization_1（Batc（无、32、16）64
h归一化）
双向（Bidirectiona（无、32、256）148480
l)
dense3（密集）（无、32、42）10794
================================================== =================
总参数：167,994
可训练参数：167,898
不可训练参数：96
&lt;小时/&gt;
无
输入形状：(64,32,1)
回溯（最近一次调用最后一次）：
文件“D:\Arabic-Handwriting-OCR\Arabic-Handwriting-OCR\inference.py”，第 156 行，位于
preds = Prediction_model.predict(batch_images)
文件“C:\Users\User\miniconda3\envs\tf\lib\site-packages\keras\utils\traceback_utils.py”，第 70 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件“C:\Users\User\AppData\Local\Temp_autograph_ generated_file42woagrz.py”，第 15 行，位于 tf__predict_function 中
retval = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError：在用户代码中：ValueError：层“模型”的输入 0与图层不兼容：预期形状=(无, 64, 32, 1)，发现形状=(32, 32, 1)
我尝试检查模型输入的形状，它的字面意思是 (64, 32, 1)，但回溯显示找到的形状=(32,32,1)，为什么呢？我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78301623/valueerror-input-0-of-layer-model-is-incompatible-with-the-layer-expected-sh</guid>
      <pubDate>Wed, 10 Apr 2024 00:15:22 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch dataloader 参数 num_worker>0 导致我的闪电模块完全冻结</title>
      <link>https://stackoverflow.com/questions/78301144/pytorch-dataloader-parameter-num-worker0-causes-my-lightning-module-to-freeze-c</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78301144/pytorch-dataloader-parameter-num-worker0-causes-my-lightning-module-to-freeze-c</guid>
      <pubDate>Tue, 09 Apr 2024 21:25:53 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow EMNIST 预测</title>
      <link>https://stackoverflow.com/questions/78300818/tensorflow-emnist-predictions</link>
      <description><![CDATA[我是张量流新手，目前已经制作了 eMNIST 字母数据集的模型，我想用它来预测笔迹。目前，我为模型指定字母“a”的小写版本。当我执行我提供的代码行时，我收到多个没有多大意义的输出数组。这些数组都有 27 个索引，而 emnist 字母应该只包含 26 个，对吗？
以下是图片：
我用来测试给定图像（jpg 文件）的代码
输出预测数组
我猜测这些索引与给定的字母相对应，但是我为模型指定的字母“a”应该位于第一个索引之一中。
不知道从这里去哪里。我很好奇这些指数的含义。
感谢您提前提供的任何帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78300818/tensorflow-emnist-predictions</guid>
      <pubDate>Tue, 09 Apr 2024 19:53:52 GMT</pubDate>
    </item>
    <item>
      <title>尽管已安装，脚本仍不断请求安装face_recognition_models</title>
      <link>https://stackoverflow.com/questions/78300706/script-continuously-requests-face-recognition-models-installation-despite-being</link>
      <description><![CDATA[我在使用 Face_recognition 库的 Python 脚本中遇到问题。尽管已经成功安装了face_recognition_models包，但当我尝试执行脚本时，脚本反复提示我安装它。这是我收到的命令和输出：
说明问题的图片
代码：
导入操作系统
导入人脸识别
导入人脸识别模型
导入CV2


image_path = “tes.png”;

# 检查图片文件是否存在
如果不是 os.path.isfile(image_path):
    print(&quot;图像文件不存在:&quot;, image_path)
    出口（）

# 获取网络摄像头 #0 的引用（默认摄像头）
video_capture = cv2.VideoCapture(0)

# 加载您的图像并学习如何识别它。
图像=face_recognition.load_image_file(image_path)
face_encoding =face_recognition.face_encodings(图像)[0]

# 创建已知面部编码及其名称的数组
已知人脸编码 = [
    面部编码，
]
已知面孔名称 = [
        “瓦利德”
]

而真实：
        # 抓取单帧视频
        ret, 帧 = video_capture.read()

        # 将图像从 BGR 颜色（OpenCV 使用）转换为 RGB 颜色（face_recognition 使用）
        rgb_frame = 帧[:, :, ::-1]

        # 查找当前帧视频中的所有人脸
        面部位置 = 面部识别.面部位置(rgb_frame)
        face_encodings =face_recognition.face_encodings（rgb_frame，face_locations）

        # 循环遍历该视频帧中的每张脸
        对于（上，右，下，左），zip中的face_encoding（face_locations，face_encodings）：
            # 查看该面孔是否与已知面孔匹配
            匹配=face_recognition.compare_faces（known_face_encodings，face_encoding）

            名称=“未知”

            如果匹配中为真：
                first_match_index = matches.index(True)
                名称 =known_face_names[first_match_index]

            # 在脸部周围画一个框
            cv2.rectangle(frame, (左, 上), (右, 下), (0, 0, 255), 2)

            # 在脸部下方画一个带有名字的标签
            cv2.rectangle(frame, (左, 下 - 35), (右, 下), (0, 0, 255), cv2.FILLED)
            字体= cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(框架, 名称, (左 + 6, 下 - 6), 字体, 1.0, (255, 255, 255), 1)

        # 显示结果图像
        cv2.imshow(&#39;视频&#39;, 帧)

        # 按键盘上的“q”退出！
        如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
            休息

# 释放网络摄像头的句柄
video_capture.release()
cv2.destroyAllWindows()


我尝试利用face_recognition 库执行Python 脚本。尽管成功安装了face_recognition_models包，但该脚本在执行时不断提示我安装它。我希望脚本能够识别已安装的包并执行而不会出现错误，但它继续请求安装face_recognition_models。]]></description>
      <guid>https://stackoverflow.com/questions/78300706/script-continuously-requests-face-recognition-models-installation-despite-being</guid>
      <pubDate>Tue, 09 Apr 2024 19:29:09 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 keras 和张量流实现双任务分类实验</title>
      <link>https://stackoverflow.com/questions/78300510/how-do-i-implement-a-dual-task-classification-experiment-using-keras-and-tensor</link>
      <description><![CDATA[我正在谈论以下代码（为书籍 NLP 迁移学习).
input1_shape = (len(train_x[0]),)
input2_shape = (len(train_x2[0]),)
sent2vec_vectors1 = 输入（形状=input1_shape）
sent2vec_vectors2 = 输入（形状=input2_shape）
组合 = 连接（[sent2vec_vectors1，sent2vec_vectors2]）
密集1 = 密集（512，激活=&#39;relu&#39;）（组合）
密集1 = Dropout(0.3)(密集1)
输出1 = 密集（1，激活=&#39;sigmoid&#39;，名称=&#39;分类1&#39;）（密集1）
输出2 = 密集（1，激活=&#39;sigmoid&#39;，名称=&#39;分类2&#39;）（密集1）
模型 = 模型(输入=[sent2vec_vectors1,sent2vec_vectors2], 输出=[输出1,输出2])

model.compile(loss={&#39;classification1&#39;: &#39;binary_crossentropy&#39;,
                    &#39;classification2&#39;: &#39;binary_crossentropy&#39;},
              优化器=&#39;亚当&#39;，指标=[&#39;准确性&#39;]）
历史 = model.fit([train_x,train_x2],[train_y,train_y2],
                    验证数据=([test_x,test_x2],[test_y,test_y2]),
                                     batch_size = 32，nb_epoch = 10，shuffle = True）

上面的代码适用于旧版本的张量流：&lt; 2.0
我一直在尝试让它在 TensorFlow 版本：2.16.1 上运行，并进行了以下更改
input1_shape = (len(train_x[0]),)
input2_shape = (len(train_x2[0]),)
sent2vec_vectors1 = 输入（形状=input1_shape，名称=“向量1”）
sent2vec_vectors2 = 输入（形状=input2_shape，名称=“向量2”）

类 ConcatenateLayer（层）：
    def 调用（自身，输入，轴=0）：
        返回 tf.concat(输入，轴=轴)
    


组合 = ConcatenateLayer()([sent2vec_vectors1,sent2vec_vectors2],axis=0)
密集1 = 密集（512，激活=&#39;relu&#39;）（组合）
密集1 = Dropout(0.3)(密集1)
输出1 = 密集（1，激活=&#39;sigmoid&#39;，名称=&#39;分类1&#39;）（密集1）
输出2 = 密集（1，激活=&#39;sigmoid&#39;，名称=&#39;分类2&#39;）（密集1）

模型 = 模型(输入=[sent2vec_vectors1,sent2vec_vectors2], 输出=[输出1,输出2])
model.compile(loss={&#39;classification1&#39;: &#39;binary_crossentropy&#39;,
                    &#39;classification2&#39;: &#39;binary_crossentropy&#39;},
              优化器=&#39;亚当&#39;，指标=[&#39;准确性&#39;，&#39;准确性&#39;]）

历史 = model.fit([train_x, train_x2], [train_y, train_y2],
                    验证数据=([test_x, test_x2], [test_y, test_y2]),
                     纪元 = 10，洗牌 = True
                    ）

我不断收到不兼容的形状错误，例如：
不兼容的形状：[64,1] 与 [32,1]
     [[{{节点gradient_tape/compile_loss/binary_crossentropy_1/logistic_loss/mul/BroadcastGradientArgs}}]] [操作：__inference_one_step_on_iterator_8871]


我在拟合函数中尝试了不同的批量大小，并尝试重塑数据。我试图将错误跟踪到张量流代码中，但一切都无济于事。
数据的形状如下：

对象名称：train_x 形状：形状：(1400,600)
对象名称：train_x2 形状：形状：(1400,600)
对象名称：train_y 形状：形状：(1400,)
对象名称：train_y2 形状：形状：(1400,)
对象名称：test_x 形状：形状：(600,600)
对象名称：test_x2 形状：形状：(600,600)
对象名称：test_y 形状：形状：(600,)
对象名称：test_y2 形状：形状：(600,)

还有
输入形状：

sent2vec_vectors1：（无，600）
sent2vec_vectors2：（无，600）

输出形状：

输出1：（无，1）
输出2：（无，1）

我觉得我错过了一些东西。我正在努力寻找 2.16.1 中类似方法的良好参考示例。任何建议。
我尝试过重塑数据并尝试了一系列批量大小，但我对张量流非常陌生。]]></description>
      <guid>https://stackoverflow.com/questions/78300510/how-do-i-implement-a-dual-task-classification-experiment-using-keras-and-tensor</guid>
      <pubDate>Tue, 09 Apr 2024 18:46:59 GMT</pubDate>
    </item>
    <item>
      <title>我可以将回归值和分类值合并到时间序列模型中吗？</title>
      <link>https://stackoverflow.com/questions/78300450/can-i-incorporate-both-regression-and-classification-values-in-time-series-model</link>
      <description><![CDATA[我可以将回归值和分类值作为特征结合起来，使用 ARIMA、SARIMAX 和 Prophet 等算法开发风速预测模型，其中预测输出（风速）位于分类值中吗？]]></description>
      <guid>https://stackoverflow.com/questions/78300450/can-i-incorporate-both-regression-and-classification-values-in-time-series-model</guid>
      <pubDate>Tue, 09 Apr 2024 18:29:16 GMT</pubDate>
    </item>
    <item>
      <title>标签未包含在我的张量数据集中</title>
      <link>https://stackoverflow.com/questions/78297824/label-not-included-inside-my-tensor-dataset</link>
      <description><![CDATA[我是机器学习新手，我想使用 BERT 模型中的预训练模型。
我面临以下问题：标签输出未插入张量类型数据集。
有没有人有解决办法？
from sklearn.model_selection import train_test_split
X = 特征[&#39;clean_text&#39;]
y = 特征[&#39;标签&#39;]
X_train、X_test、y_train、y_test=train_test_split(X、y、test_size = 0.3、random_state = 42)
X_train = tokenizer(X_train.tolist(), 填充 = True, 截断 = True)
X_test = tokenizer(X_test.tolist(), 填充 = True, 截断 = True)
X_train = 字典(X_train)
X_test = 字典(X_test)
y_train = y_train.tolist()
y_test = y_test.tolist()
df_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))
df_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))
输入，输出=下一个（iter（df_train））
打印出）

输出如下：tf.Tensor(0, shape=(), dtype=int32)]]></description>
      <guid>https://stackoverflow.com/questions/78297824/label-not-included-inside-my-tensor-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 10:36:28 GMT</pubDate>
    </item>
    <item>
      <title>识别和清理数据集中有问题的三元组[关闭]</title>
      <link>https://stackoverflow.com/questions/78297420/identifying-and-cleaning-problematic-triplets-in-a-dataset</link>
      <description><![CDATA[我有三元组（嵌入、嵌入、相关标志）我有大约 5k 个这样的三元组。
有一些三元组（一些少量）实际上并不相关，但在我的数据中显示为相关。
嵌入维度为512。
什么是不相关我认为没有问题。
有什么想法可以找到那些被怀疑是错误的有问题的三元组，可以手动检查和清理。
我尝试构建分类器，但它们的性能不太好。]]></description>
      <guid>https://stackoverflow.com/questions/78297420/identifying-and-cleaning-problematic-triplets-in-a-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 09:23:02 GMT</pubDate>
    </item>
    <item>
      <title>如何计算二元分类概率[关闭]</title>
      <link>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</link>
      <description><![CDATA[我正在研究一些基于数值特征的二元分类问题，例如预测维护、信用卡欺诈、心脏病等。我通常喜欢使用随机森林，因为它用途广泛、稳健且可以获得高指标。
除了预测1或0之外，我还想预测获得1的概率（在0.00到1.00之间浮动）。如何在代码中实现这一点？
我使用了随机森林分类器的predict_proba()方法。然而，它主要产生极值（0.00 - 0.10 和 0.90 - 1.00）。 也许它没有很好地校准？另外，我使用了SVM分类器的decision_function()方法，但SVM似乎不是很通用。因此我正在寻找一种不同的方法。
我更喜欢与 RF 分类器相关的方法，但我对其他方法持开放态度。
这是我的代码的相关部分：
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

校准器 = CaliberatedClassifierCV(rf, cv=&#39;prefit&#39;)
模型 = calibrator.fit(X_train, y_train)

概率 = model.predict_proba(X_test)

y_pred = model.predict(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</guid>
      <pubDate>Tue, 09 Apr 2024 07:56:47 GMT</pubDate>
    </item>
    <item>
      <title>CNN 教程模型根本拒绝训练</title>
      <link>https://stackoverflow.com/questions/78293057/cnn-tutorial-models-refusing-to-train-at-all</link>
      <description><![CDATA[我遇到的问题涉及在一些众所周知的数据集上创建和使用 CNN 模型。问题始于我的一项家庭作业，我们应该创建一个 CNN 并在 CIFAR10 数据集上运行它。然而这个问题似乎更加严重，我怀疑可能出了什么问题。
我注意到，在运行我自己的模型时，无论我制作什么模型或调整什么超参数，性能都与随机猜测一致。
为了更好地了解什么是好的模型，我在 CIFAR10 和 MNIST 上在线下载了一些教程。教程页面、网站等上的这些模型都报告了不错的准确度，范围在 60-80% 之间。
然而事情就变得奇怪了。当我使用相同的数据预处理等运行这些完全相同的模型（我下载了文件，因此没有复制/粘贴错误）时，我得到了与我自己的模型相同的结果，没有学习发生，并且准确性保持在 10%。这种行为与我在网上找到的至少四个不同的教程示例是一致的。
我尝试创建一个新的 conda 环境，以便我可以全新安装 tensorflow-gpu，并确保尽可能使用与教程相同的版本，但无论出于何种原因，模型似乎拒绝训练为我。下面是一个最小的可重现示例，我只是从 tensorflow.org 上的 CNN 教程示例和我的结果中复制/粘贴了该示例。
从tensorflow.keras导入数据集、图层、模型

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# 将像素值标准化为 0 到 1 之间
训练图像，测试图像 = 训练图像 / 255.0，测试图像 / 255.0


模型 = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), 激活=&#39;relu&#39;, input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), 激活=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), 激活=&#39;relu&#39;))


model.add(layers.Flatten())
model.add(layers.Dense(64,activation=&#39;relu&#39;))
model.add(layers.Dense(10))

模型.编译(
    优化器=&#39;亚当&#39;,
    损失=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    指标=[&#39;准确性&#39;])

历史= model.fit(train_images, train_labels, epochs=10,
                    验证数据=（测试图像，测试标签））


结果
1563/1563 [================================] - 250s 11ms/步 - 损耗：2.3027 - 准确度：0.0977 - val_loss：2.3026 - val_accuracy：0.1000
纪元 2/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3028 - 精度：0.0999 - val_loss ：2.3027 - val_accuracy：0.1000
纪元 3/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3027 - 准确度：0.1011 - val_loss ：2.3027 - val_accuracy：0.1000
纪元 4/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3028 - 准确度：0.0993 - val_loss ：2.3027 - val_accuracy：0.1000
纪元 5/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3027 - 准确度：0.0957 - val_loss ：2.3026 - val_accuracy：0.1000
纪元 6/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3028 - 准确度：0.0979 - val_loss ：2.3026 - val_accuracy：0.1000
纪元 7/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3027 - 准确度：0.0997 - val_loss ：2.3026 - val_accuracy：0.1000
]]></description>
      <guid>https://stackoverflow.com/questions/78293057/cnn-tutorial-models-refusing-to-train-at-all</guid>
      <pubDate>Mon, 08 Apr 2024 13:58:28 GMT</pubDate>
    </item>
    <item>
      <title>每批次和历元的验证和训练损失</title>
      <link>https://stackoverflow.com/questions/65638101/validation-and-training-loss-per-batch-and-epoch</link>
      <description><![CDATA[我正在使用 Pytorch 运行一些深度学习模型。我目前正在跟踪每个时期的训练和验证损失，这是相当标准的。但是，跟踪每批/迭代的训练和验证损失的最佳方法是什么？
对于训练损失，我可以在每次训练循环后保留一个损失列表。但是，验证损失是在整个 epoch 之后计算的，所以我不确定如何计算每批的验证损失。我唯一能想到的就是在每个训练批次之后运行整个验证步骤并跟踪这些步骤，但这似乎有点矫枉过正并且需要大量计算。
比如训练是这样的：
for epoch in range(2): # 多次循环数据集
running_loss = 0.0
对于 i，enumerate(trainloader, 0) 中的数据：
    # 获取输入；数据是[输入，标签]的列表
    输入，标签=数据

    # 将参数梯度归零
    优化器.zero_grad()

    # 前向+后向+优化
    输出 = 净值（输入）
    损失=标准（输出，标签）
    loss.backward()
    优化器.step()

    # 打印统计数据
    running_loss += loss.item()

对于验证损失：
与 torch.no_grad():
    对于测试加载器中的数据：
        图像、标签=数据
        输出=净（图像）
        _, 预测 = torch.max(outputs.data, 1)
        总计 += labels.size(0)
        正确+=（预测==标签）.sum().item()
        # 验证损失
        batch_loss = error(outputs.float(), labels.long()).item()
        loss_test +=batch_loss
    loss_test /= len(testloader)

验证损失/测试部分是在每个时期完成的。我正在寻找一种方法来获取每批次的验证损失，这就是我上面的观点。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/65638101/validation-and-training-loss-per-batch-and-epoch</guid>
      <pubDate>Sat, 09 Jan 2021 00:25:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用gensim使用deepset的词嵌入预训练模型？</title>
      <link>https://stackoverflow.com/questions/65121932/how-to-use-deepsets-word-embedding-pre-trained-models-using-gensim</link>
      <description><![CDATA[我试图理解 word2vec，并决定尝试使用德语 word2vec 模型。然后我找到了deepset的页面关于他们的预训练模型，但我不明白如何使用（加载）word2vec 模型。我期待一个文件，但有 &quot;矢量&quot;和“词汇 ”文本文件。如何使用这些文件通过 gensim（或任何其他工具）加载预训练模型？
更新：
我尝试了 @gojomo 的回答，但收到了此错误：
回溯（最近一次调用最后一次）：
  文件“/home/bugra/word2vec_imp/pretrained_models/testtt.py”，第 11 行，在  中。
    二进制=假）
  文件“/home/bugra/word2vec_imp/project_envv/lib/python3.7/site-packages/gensim/models/keyedvectors.py”，第 1549 行，采用 load_word2vec_format
    限制=限制，数据类型=数据类型）
  文件“/home/bugra/word2vec_imp/project_envv/lib/python3.7/site-packages/gensim/models/utils_any2vec.py”，第 277 行，采用 _load_word2vec_format
    vocab_size, vector_size = (int(x) for x in header.split()) # 因文件格式无效而抛出异常
  文件“/home/bugra/word2vec_imp/project_envv/lib/python3.7/site-packages/gensim/models/utils_any2vec.py”，第 277 行，位于  中。
    vocab_size, vector_size = (int(x) for x in header.split()) # 因文件格式无效而抛出异常
ValueError：基数为 10 的 int() 的文字无效：“b&#39;UNK””

因此，在 Traceack 中，vocab_size, vector_size = (int(x) for x in header.split()) header 是 Vector 的第一行来自 gensim 页面的文本。它看起来像这样：
&lt;预&gt;&lt;代码&gt;b&#39;UNK&#39; -0.07903 0.01641 0.006979 -0.035038 0.006474 0.002469 -0.050103 0.142654 -0.03505 0.003106 -0.021312 0.094076 -0.01825 5 -0.098097 0.087143 0.105799 0.008606 -0.001315 0.069005 0.062015 0.019944 -0.007749 -0.007412 0.050015 -0.083615 0.007712 0.0331 61 0.017965 - 0.06154 -0.017696 0.061967 0.053028 0.038143 -0.07057 0.01561 0.019588 -0.041708 0.034371 -0.066838 -0.059769 0.075711 -0.114826 0.014009 0.050187 -0.01899 -0.076014 -0.052502 0.086082 0.049812 0.008456 -0.01283 0.039918 -0.001924 -0.003752 0.031073 0.034325 0 .040086 0.078946 -0.012194 0.056323 0.126129 -0.024503 0.026304 - 0.074797 -0.098972 0.003672 0.051386 -0.017574 -0.050253 -0.07677 0.004362 -0.069935 -0.048108 0.020127 0.007066 -0.024247 0.04191 1 0.03377 -0.011906 -0.0168 -0.00355 -0.003168 0.05164 -0.055769 0.01488 -6e-06 0.094575 -0.066246 -0.111004 -0.031954 0.006958 0.0052 59 0.15825 0.102919 0.010383 -0.064236 -0.037729 -0.031751 -0.069492 -0.004198 -0.034654 -0.060518 -0.046611 -0.048463 -0.010096 -0.057894 -0.046687 0.062827 0.0169 07 0.096869 -0.036037 -0.106403 0.056466 0.095621 -0.046383 0.090213 -0.019204 -0.116271 -0.00824 -0.017732 0.037387 -0.021405 -0.0404 93 - 0.059114 0.12289 0.032563 0.103712 0.072411 -0.106944 -0.110485 -0.027564 0.023977 -0.048099 0.036966 -0.11356 -0.009166 0.074402 0.128162 0.080086 0.112749 0.050494 0.064998 0.089217 0.029182 -0.07277 0.058653 0.061047 -0.05293 -0.01979 0.107459 0.002719 -0 .008774 -0.098009 0.009321 0.099869 0.024181 -0.071247 -0.054372 0.019997 0.024442 0.108639 0.053727 -0.089804 0.118491 -0.044407 -0.045336 0.078483 0.059462 -0.012287 0.028941 0.064551 0.066738 0.029614 0.0927 68 0.021783 -0.018141 -0.032692 0.000178 0.021413 0.044657 -0.041903 0.027439 -0.029112 -0.027419 -0.091497 0.00712 -0.076297 -0.0976 02 -0.098875 -0.067403 -0.015912 0.055845 0.057585 -0.061145 -0.006828 0.044573 0.049632 0.014541 -0.024579 -0.045455 0.095474 -0.02978 -0.060053 -0.005672 -0.002711 0.059481 -0.060563 0.04756 2 -0.086001 0.064536 0.196527 -0.105742 -0.019043 0.038534 -0.099681 0.031009 -0.020548 -0.058781 0.064247 0.008213 0.126322 0.0298 59 0.013129 -0.021303 0.043993 0.033347 0.020245 0.037738 - 0.02178 0.027693 -0.07024 0.004687 0.045271 -0.022966 0.014069 0.022861 -0.02787 0.082912 -0.049544 0.016079 -0.004684 0.000572 0.077382 0.036401 0.054974 -0.039538 0.002119 0.034002 -0.008836 -0.014758 0.00959 -0.064647 -0.034766 0.016912 -0.036381 -0.037106 0.073451 -0.098941 -0.092281 -0.018656 0.050538 0.041422 0.041235 0.011248 -0.106058 0.066443 0.083865 0.094636 0.004414 -0.092855 -0.027255 0.005234 0.066584 0.055394 0.023019 -0.001949 -0.0667 94 -0.064739 0.038924 -0.016647 0.000555 0.02428 0.016469 -0.0467 -0.035343 -0.066789 -0.025929 -0.023397 0.062855 0.020142 -0.047568 0.010299 -0.021509 -0.02826 0.029225 0.01803 0.024336 0.018226 -0.009453 -0.068584

如有任何帮助，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/65121932/how-to-use-deepsets-word-embedding-pre-trained-models-using-gensim</guid>
      <pubDate>Thu, 03 Dec 2020 08:02:21 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow 和 keras：不支持 None 值</title>
      <link>https://stackoverflow.com/questions/59672402/tensorflow-and-keras-none-values-not-supported</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/59672402/tensorflow-and-keras-none-values-not-supported</guid>
      <pubDate>Thu, 09 Jan 2020 21:31:09 GMT</pubDate>
    </item>
    <item>
      <title>拟合模型时，批量大小和轮数应该有多大？</title>
      <link>https://stackoverflow.com/questions/35050753/how-big-should-batch-size-and-number-of-epochs-be-when-fitting-a-model</link>
      <description><![CDATA[我的训练集有 970 个样本，验证集有 243 个样本。
拟合模型以优化 val_acc 时，批量大小和轮数应该有多大？是否有基于数据输入大小的经验法则可供使用？]]></description>
      <guid>https://stackoverflow.com/questions/35050753/how-big-should-batch-size-and-number-of-epochs-be-when-fitting-a-model</guid>
      <pubDate>Thu, 28 Jan 2016 00:21:39 GMT</pubDate>
    </item>
    </channel>
</rss>