<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>ä¸»åŠ¨é—®é¢˜æ ‡è®°çš„æœºå™¨å­¦ä¹  - å †æ ˆæº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æœ€è¿‘çš„30ä¸ªæ¥è‡ªstackoverflow.com</description>
    <lastBuildDate>Tue, 25 Mar 2025 18:24:38 GMT</lastBuildDate>
    <item>
      <title>è®­ç»ƒé‡ï¼šâ€œåŒ…è£…â€å’Œâ€œ group_by_lengthâ€ç›¸äº’æŠµæ¶ˆï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79533473/trainingarguments-do-packing-and-group-by-length-counteract-each-other</link>
      <description><![CDATA[åœ¨huggingfaceçš„ sftConfig ï¼ˆä» trieb&gt; triagn&gt; triagn&gt; triebs triaght&gt; triaghtarguments ï¼‰ä¸­ï¼Œæœ‰ä¸¤ä¸ªå‚ä¸priaged ï¼‰


  group_by_length ï¼šæ˜¯å¦å°†è®­ç»ƒæ•°æ®é›†ä¸­å¤§è‡´ç›¸åŒé•¿åº¦çš„æ ·æœ¬ç»„åˆåœ¨ä¸€èµ·ï¼ˆä»¥æœ€å¤§ç¨‹åº¦åœ°å‡å°‘åº”ç”¨çš„å¡«å……å¹¶æ›´æœ‰æ•ˆï¼‰ã€‚ä»…åœ¨åº”ç”¨åŠ¨æ€å¡«å……æ—¶æœ‰ç”¨ã€‚
 åŒ…è£…ï¼šæ˜¯å¦å°†å¤šä¸ªåºåˆ—æ‰“åŒ…åˆ°å›ºå®šé•¿åº¦æ ¼å¼ä¸­ã€‚ä½¿ç”¨ max_length å®šä¹‰åºåˆ—é•¿åº¦ã€‚


  config = sftConfigï¼ˆ...ï¼Œï¼Œï¼Œ 
                   group_by_length = trueï¼Œ 
                   åŒ…è£…= trueï¼Œ...ï¼‰
 
è¿™äº›è®ºç‚¹çš„ç›®çš„æ˜¯å‡å°‘å¡«å……æ¡¨çš„åŠªåŠ›ã€‚ä½†æ˜¯ï¼Œå½“ packing = true æ—¶ï¼Œä½¿ç”¨ ä½¿ç”¨ group_by_length = true ã€‚æˆ‘ä»¬æ˜¯å¦å¯ä»¥ä¸¤è€…éƒ½æé«˜è®­ç»ƒè¡¨ç°ï¼Ÿä»–ä»¬äº’ç›¸æŠµæ¶ˆå—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79533473/trainingarguments-do-packing-and-group-by-length-counteract-each-other</guid>
      <pubDate>Tue, 25 Mar 2025 11:13:20 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨HuggingFace Seq2Seqtrainerä¸­ä½¿ç”¨åŸ¹è®­ï¼ŒéªŒè¯å’Œæµ‹è¯•é›†</title>
      <link>https://stackoverflow.com/questions/79532570/use-of-training-validation-and-test-set-in-huggingface-seq2seqtrainer</link>
      <description><![CDATA[ iå…·æœ‰ä»¥ä¸‹æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†å…·æœ‰3ä¸ªæ‹†åˆ†ï¼ˆ Train ï¼ŒéªŒè¯å’Œ test ï¼‰ã€‚æ•°æ®æ˜¯2ç§è¯­è¨€çš„å¹³è¡Œè¯­æ–™åº“ã€‚
  datasetDictï¼ˆ{{
    ç«è½¦ï¼šæ•°æ®é›†ï¼ˆ{
        åŠŸèƒ½ï¼š[&#39;translation&#39;]ï¼Œ
        num_rowsï¼š109942
    }ï¼‰ï¼‰
    éªŒè¯ï¼šæ•°æ®é›†ï¼ˆ{
        åŠŸèƒ½ï¼š[&#39;translation&#39;]ï¼Œ
        num_rowsï¼š6545
    }ï¼‰ï¼‰
    æµ‹è¯•ï¼šæ•°æ®é›†ï¼ˆ{
        åŠŸèƒ½ï¼š[&#39;translation&#39;]ï¼Œ
        num_rowsï¼š13743
    }ï¼‰ï¼‰
}ï¼‰ï¼‰
 
å¯¹äºæˆ‘çš„ seq2seqtrainer ï¼Œæˆ‘æä¾›æ•°æ®é›†å¦‚ä¸‹ï¼š
  trainer = seq2seqtrainerï¼ˆ
    æ¨¡å‹=æ¨¡å‹ï¼Œ
    args =è®­ç»ƒ_argsï¼Œ
    train_dataset = tokenized_dataset [&#39;train&#39;]ï¼Œ
    eval_dataset = tokenized_dataset [&#39;éªŒè¯&#39;]ï¼Œ
    tokenizer = tokenizerï¼Œ
    data_collatâ€‹â€‹or = data_collatâ€‹â€‹orï¼Œ
    compute_metrics = compute_metricsï¼Œ
ï¼‰
 
å°†éªŒè¯æ‹†åˆ† ever_dataset ä¸­çš„æ‹†åˆ†æ˜¯æ­£ç¡®çš„å—ï¼Ÿåœ¨ documentation&gt; documentation 

ç”¨äºè¯„ä¼°çš„æ•°æ®é›†ã€‚å¦‚æœæ˜¯æ•°æ®é›†ï¼Œåˆ™è‡ªåŠ¨åˆ é™¤ model.forwardï¼ˆï¼‰æ–¹æ³•æœªæ¥å—çš„åˆ—ã€‚å¦‚æœæ˜¯å­—å…¸ï¼Œå®ƒå°†åœ¨æ¯ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚

æˆ–è€…æˆ‘åº”è¯¥å°†æµ‹è¯•åˆ†é…åœ¨ eval_dataset ä¸­ï¼Ÿæ— è®ºå“ªç§æ–¹å¼ï¼Œéƒ½æ²¡æœ‰ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªåˆ†è£‚ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79532570/use-of-training-validation-and-test-set-in-huggingface-seq2seqtrainer</guid>
      <pubDate>Tue, 25 Mar 2025 02:22:21 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰ä»€ä¹ˆæ–¹æ³•å¯ä»¥åœ¨ä½¿ç”¨CV2ä¿æŒæ–‡æœ¬çš„æ¸…æ™°åº¦çš„åŒæ—¶åˆ é™¤æ­¤è¿˜åŸå›¾åƒçš„èƒŒæ™¯å™ªå£°ï¼Ÿ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79531758/is-there-any-way-to-remove-the-background-noise-of-this-restored-image-while-mai</link>
      <description><![CDATA[åŸå§‹å›¾åƒï¼š
è¿™æ˜¯åŸå§‹å›¾åƒ 
éƒ¨åˆ†è¿˜åŸå›¾åƒï¼š
è¿™æ˜¯éƒ¨åˆ†ä¿®å¤çš„å›¾åƒ 
ç¬¬ä¸€ä¸ªå›¾åƒæ˜¯åœ¨é€šè¿‡ä¸€äº›æ¢å¤æŠ€æœ¯è¿è¡Œä¹‹å‰ã€‚ç¬¬äºŒå¼ å›¾åƒæ˜¯åœ¨ä¿®å¤åã€‚èƒŒæ™¯å™ªéŸ³å¾ˆå¤šï¼Œå­—ç¬¦çš„ä¸€éƒ¨åˆ†ç¼ºå°‘ã€‚æˆ‘æƒ³ä»æ­¤å›¾åƒä¸­æå–æ–‡æœ¬ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä¿æŒæ–‡æœ¬çš„å‡†ç¡®æ€§çš„åŒæ—¶æ‰§è¡Œæ­¤æ“ä½œå—ï¼Ÿä»»ä½•å¸®åŠ©éƒ½å°†å—åˆ°èµèµï¼]]></description>
      <guid>https://stackoverflow.com/questions/79531758/is-there-any-way-to-remove-the-background-noise-of-this-restored-image-while-mai</guid>
      <pubDate>Mon, 24 Mar 2025 17:32:07 GMT</pubDate>
    </item>
    <item>
      <title>CATBOOSTæ¨¡å‹çš„ä¸²è”TF-IDFæ•°æ®å’Œåˆ†ç±»æ•°æ®</title>
      <link>https://stackoverflow.com/questions/79531266/concatenating-tf-idf-data-and-categorical-data-for-catboost-model</link>
      <description><![CDATA[æˆ‘ä¸€ç›´åœ¨å°è¯•å°†TF-IDFæ•°æ®ä¸åˆ†ç±»æ•°æ®ç›¸è¿ã€‚ä½†æ˜¯ï¼Œå½“ä¸²è”æ—¶ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ†ç±»æ•°æ®ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºfloatã€‚ç”±äºcatboostä¸æ”¯æŒåˆ†ç±»ç‰¹å¾çš„æµ®åŠ¨ï¼Œå› æ­¤ç”±äºä¸å†è¢«è®¤ä¸ºæ˜¯åˆ†ç±»æ•°æ®è€Œå¯¼è‡´ç¨€ç–æ•°æ®çš„é”™è¯¯ã€‚
æœ‰è§£å†³è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ¡ˆå—ï¼Ÿè¯·åœ¨ä¸‹é¢æ‰¾åˆ°æˆ‘çš„ä»£ç ä»¥ä¾›å‚è€ƒï¼š
 å¯¼å…¥numpyä½œä¸ºNP
å¯¼å…¥å¤§ç†ŠçŒ«ä½œä¸ºpd
æ¥è‡ªCatboost Import CatboostClassifier
æ¥è‡ªsklearn.feature_extraction.textå¯¼å…¥tfidfvectorizer
ä»Sklearn.Preprocessing Import LabElenCoder
æ¥è‡ªscipy.sparseå¯¼å…¥hstackï¼Œcsr_matrix

text_data = [
    â€œæˆ‘å–œæ¬¢æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦â€
    â€œæ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é›†â€
    â€œè‡ªç„¶è¯­è¨€å¤„ç†æ˜¯æƒŠäººçš„â€
    â€œ AIæ­£åœ¨æ”¹å˜ä¸–ç•Œâ€
    â€œå¤§æ•°æ®å’ŒAIæ­£åœ¨å½»åº•æ”¹å˜è¡Œä¸šâ€ã€‚
è¿™æ˜¯ç»™å‡ºçš„

pecorical_data = {
    â€œ cantoryâ€ï¼šâ€œ tech; quotâ€ tech&#39;tech&#39;nlpâ€™s&#39;&#39;
    â€œåœ°åŒºâ€ï¼šâ€œæ¬§æ´²â€ï¼Œâ€œäºšæ´²â€æ¬§æ´²â€œæ¬§æ´²â€
}

y = np.Arrayï¼ˆ[0ï¼Œ1ï¼Œ0ï¼Œ1ï¼Œ1]ï¼‰

df_cat = pd.dataframeï¼ˆcentorical_dataï¼‰

vectorizer = tfidfvectorizerï¼ˆï¼‰
x_tfidf = vectorizer.fit_transformï¼ˆtext_dataï¼‰

df_cat_encoded = df_cat.applyï¼ˆlabelencoderï¼ˆï¼‰ã€‚fit_transformï¼‰

x_categorical = csr_matrixï¼ˆdf_cat_encoded.valuesï¼‰

x_combind = hstackï¼ˆ[x_tfidfï¼Œx_categorical]ï¼‰

model = catboostClassifierï¼ˆè¿­ä»£= 100ï¼ŒLearning_rate = 0.1ï¼Œæ·±åº¦= 5ï¼Œå†—é•¿= 0ï¼‰

model.fitï¼ˆx_combinedï¼Œyï¼Œcat_features = [x_tfidf.shape [1]ï¼Œx_tfidf.shape [1] + 1]ï¼‰

é¢„æµ‹= model.predictï¼ˆx_combinedï¼‰

æ‰“å°ï¼ˆé¢„æµ‹ï¼‰
 
é”™è¯¯ï¼š
  catboostrorï¼š&#39;data&#39;æ˜¯scipy.sparse.spmatrix floating Pointæ•°å€¼ç±»å‹ï¼Œ 
è¿™æ„å‘³ç€æ²¡æœ‰åˆ†ç±»åŠŸèƒ½ï¼Œä½†æ˜¯â€œ cat_featuresâ€å‚æ•°æŒ‡å®šéé›¶ 
åˆ†ç±»åŠŸèƒ½çš„æ•°é‡
 ]]></description>
      <guid>https://stackoverflow.com/questions/79531266/concatenating-tf-idf-data-and-categorical-data-for-catboost-model</guid>
      <pubDate>Mon, 24 Mar 2025 13:53:36 GMT</pubDate>
    </item>
    <item>
      <title>Lora Fineted Llama 8bçš„è‡ªå®šä¹‰å‰å¾€å‰æ–¹æ³• - ä½¿ç”¨Unsploth</title>
      <link>https://stackoverflow.com/questions/79531231/custom-forward-method-for-lora-finetuned-llama-8b-using-unsloth</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•å¯¹æˆ‘çš„å›ºå®šæ¨¡å‹è¿›è¡Œä¸€äº›æ¶ˆèç ”ç©¶ã€‚è¯•å›¾è¶…è½½å‰å‘æ–¹æ³•
 ç±»GROK_CUSTOMPEFTCAUSALLMï¼ˆTORCH.NN.MODULEï¼‰ï¼š
def __init __ï¼ˆè‡ªæˆ‘ï¼Œæ¨¡å‹ï¼‰ï¼š
    superï¼ˆï¼‰.__ init __ï¼ˆï¼‰
    self.model =å‹å·ï¼ƒåŸå§‹fastlanguagemodel

    ï¼ƒä¿®è¡¥å†…éƒ¨æ¨¡å‹çš„å‰è¿›
    orig_forward = self.model.model.forward

    def new_forwardï¼ˆinned_selfï¼Œinput_idsï¼Œactivation_mask = noneï¼Œnum_logits_to_keep = noneï¼Œ** kwargsï¼‰ï¼š
        æ‰“å°ï¼ˆ&#39;ğŸ”¹è‡ªå®šä¹‰å‰è¿›è¢«è°ƒç”¨ï¼ï¼†quot; flush = trueï¼‰

        ï¼ƒåµŒå…¥
        hidden_â€‹â€‹states = inner_self.model.embed_tokensï¼ˆinput_idsï¼‰
        æ‰“å°ï¼ˆåµŒå…¥åéšè—çŠ¶æ€ï¼š{hidden_â€‹â€‹states.shape}ï¼†quot; flush = trueï¼‰

        ï¼ƒæ³¨æ„é¢å…·
        å¦‚æœactive_maskæ— ï¼š
            activation_mask = torch.onesï¼ˆinput_ids.shapeï¼Œdtype = type = turch.bfloat16ï¼Œdevice = input_ids.deviceï¼‰.boolï¼ˆï¼‰
        åˆ«çš„ï¼š
            ##å¼ºåˆ¶å…¥bool
            activation_mask = activation_mask.boolï¼ˆï¼‰

        ï¼ƒå±‚
        past_key_values =æ— 
        å¯¹äºiï¼Œåœ¨æšä¸¾ä¸­å±‚ï¼ˆinner_self.model.layersï¼‰ï¼š
            æ‰“å°ï¼ˆfï¼†quot&#39;layer {i}ï¼†quotï¼†quotï¼†clush = trueï¼‰
            layer_output = layerï¼ˆhidden_â€‹â€‹statesï¼Œactivation_mask = activation_maskï¼‰
            printï¼ˆf&#39;layer {i} outputï¼š{typeï¼ˆlayer_outputï¼‰}ï¼Œlenï¼š{lenï¼ˆlayer_outputï¼‰å¦‚æœisInstanceï¼ˆlayer_outputï¼Œtupleï¼Œtupleï¼‰else 1}ï¼†quot;ï¼Œ\ \
                                                                                              å†²æ´—= trueï¼‰
            hidden_â€‹â€‹states = layer_output [0]å¦‚æœisInstanceï¼ˆlayer_outputï¼Œtupleï¼‰else layer_output
            å¦‚æœlenï¼ˆlayer_outputï¼‰ï¼†gt; 1ï¼š
                past_key_values = layer_output [1]ï¼ƒæ›´æ–°kvç¼“å­˜
            printï¼ˆfï¼†quot&#39;efter layer {i}ï¼š{hidden_â€‹â€‹states.shape}ï¼†quortï¼†quortï¼†quort; flush = trueï¼‰

        ï¼ƒè§„èŒƒ
        hidden_â€‹â€‹states = inner_self.model.normï¼ˆhidden_â€‹â€‹statesï¼‰
        printï¼ˆfï¼†quot&#39;normï¼š{hidden_â€‹â€‹states.shape}ï¼†quortï¼†quot; flush = trueï¼‰

        ï¼ƒlogits
        logits = inner_self.lm_headï¼ˆhidden_â€‹â€‹statesï¼‰
        printï¼ˆfï¼†quotâ€œ logitsï¼š{logits.shape}ï¼†quortâ€ï¼Œflush = trueï¼‰

        ï¼ƒè¿”å›å®Œæ•´è¾“å‡º
        è¿”å›causallMoutputwithpastï¼ˆlogits = logitsï¼Œpast_key_values = past_key_valuesï¼‰
    ï¼ƒè¦†ç›–å†…éƒ¨æ¨¡å‹çš„å‰è¿›
    å¯¼å…¥ç±»å‹
    self.model.model.forward = types.methodtypeï¼ˆnew_forwardï¼Œself.model.modelï¼‰

defç”Ÿæˆï¼ˆselfï¼Œ *argsï¼Œ** kwargsï¼‰ï¼š
    æ‰“å°ï¼ˆ&#39;ğŸ”¹è‡ªå®šä¹‰ç”Ÿæˆè°ƒç”¨ï¼ï¼†quot; flush = trueï¼‰
    ï¼ƒè¿‡æ»¤num_logits_to_keep

    if&#39;num_logits_to_keepï¼†quotåœ¨å¤¸å°”æ ¼æ–¯ï¼š
        del Kwargs [ï¼†quot; num_logits_to_keep;]
    è¿”å›self.model.generateï¼ˆ*argsï¼Œ** kwargsï¼‰
 
æˆ‘åƒè¿™æ ·è°ƒç”¨äº†
 æ¨¡å‹ï¼Œtokenizer = fastlanguagemodel.from_pretrateingï¼ˆ
        model_name = inf_model_ï¼Œ
        max_seq_length = 3072ï¼Œ
        dtype = noneï¼Œ
        load_in_4bit = true
ï¼‰

eos_token = tokenizer.eos_token

æ¨¡å‹= fastlanguagemodel.for_inferenceï¼ˆæ¨¡å‹ï¼‰

ï¼ƒè¡¥ä¸ä¼ é€’é€šè¡Œè¯
æ¨¡å‹= grok_custompeftcausallmï¼ˆæ¨¡å‹ï¼‰
printï¼ˆtypeï¼ˆmodel.modelï¼‰ï¼‰ï¼ƒç¡®ä¿å®ƒæ˜¯æ‚¨çš„â€œ SkippableModelâ€
è¾“å…¥= tokenizerï¼ˆ
[
    data_prompt.formatï¼ˆ
        è¯­å¢ƒ_ï¼Œ
        â€œâ€
    ï¼‰
]ï¼Œreturn_tensors =; pt; quotã€‚


printï¼ˆdata_prompt.formatï¼ˆä¸Šä¸‹æ–‡_ï¼Œ; quord;ï¼‰ï¼‰
å¯åŠ¨å™¨_ = time.timeï¼ˆï¼‰
è¾“å‡º=å‹å·ã€‚generateï¼ˆ**è¾“å…¥ï¼Œmax_new_tokens = 800ï¼Œæ¸©åº¦= 0.1ï¼‰
æ‰“å°ï¼ˆ&#39;take out ::&#39;ï¼Œtime.timeï¼ˆï¼‰ - å¯åŠ¨_ï¼‰

ç­”æ¡ˆ= tokenizer.batch_decodeï¼ˆè¾“å‡ºï¼‰
 
å®ƒåªæ˜¯ç”Ÿæˆgibberishï¼ˆåœ¨æ²¡æœ‰æ­¤è¶…è½½çš„æƒ…å†µä¸‹ï¼Œå®ƒçš„æ€§èƒ½ç»å¯¹æ˜¯é¢„æœŸçš„ - è‰¯å¥½çš„ä»£ç ç”Ÿæˆï¼‰ã€‚ç°åœ¨çš„é—®é¢˜æ˜¯ï¼Œæˆ‘å¯ä»¥ä½¿ç”¨çš„å±‚æ¬¡ç»“æ„çš„å”¯ä¸€éƒ¨åˆ†æ˜¯Model.Modelï¼Œå®ƒæŒ‡å‘åŸºæœ¬Meta Llamaä¸Šçš„CasualllamaåŒ…è£…å™¨ã€‚æˆ‘æœ‰ä¸€ç§ä¸å¥½çš„æ„Ÿè§‰ï¼Œè¿™ä¸æ˜¯æ­£ç¡®çš„å‰è¿›ï¼Œä¸å¡åœ¨å¼•æ“ç›–ä¸‹å‘ç”Ÿäº†å…¶ä»–äº‹æƒ…ã€‚æˆ‘åœ¨è¿™é‡Œé”™è¿‡äº†ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79531231/custom-forward-method-for-lora-finetuned-llama-8b-using-unsloth</guid>
      <pubDate>Mon, 24 Mar 2025 13:38:48 GMT</pubDate>
    </item>
    <item>
      <title>TABPFNåŠŸèƒ½é€‰æ‹©æé«˜äº†keyErrorï¼ˆfâ€œ [{key}]ä¸­çš„ä¸€ä¸ªéƒ½ä¸åœ¨[{axis_name}]ä¸­</title>
      <link>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</guid>
      <pubDate>Sun, 23 Mar 2025 22:59:22 GMT</pubDate>
    </item>
    <item>
      <title>å½“è®­ç»ƒæ¨¡å‹ä½¿ç”¨KAFKAå’ŒRDLç´¢å¼•4096è®­ç»ƒæ¨¡å‹æ—¶çš„é”™è¯¯æ˜¯å¦è¶…å‡ºäº†å°ºå¯¸4096çš„è½´0</title>
      <link>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</guid>
      <pubDate>Sat, 22 Mar 2025 05:30:38 GMT</pubDate>
    </item>
    <item>
      <title>DL4Jè‡ªåŠ¨ç¼–ç å™¨ç”¨äºå¼‚å¸¸æ£€æµ‹ï¼šæ„å¤–ç»“æœ</title>
      <link>https://stackoverflow.com/questions/79523631/dl4j-autoencoder-for-anomaly-detection-unexpected-results</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79523631/dl4j-autoencoder-for-anomaly-detection-unexpected-results</guid>
      <pubDate>Thu, 20 Mar 2025 16:59:01 GMT</pubDate>
    </item>
    <item>
      <title>é«˜æ•ˆNETB3æ¨¡å‹çš„å‡†ç¡®æ€§éå¸¸ä½ï¼Œå¹¶ä¸”åœ¨è¯†åˆ«è„‘è‚¿ç˜¤é—®é¢˜æ–¹é¢å­¦ä¹ é«˜åŸ</title>
      <link>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</guid>
      <pubDate>Mon, 27 Jan 2025 11:58:17 GMT</pubDate>
    </item>
    <item>
      <title>ç¥ç»ç½‘ç»œç²¾ç¡®åº¦ä½</title>
      <link>https://stackoverflow.com/questions/73780627/neural-network-low-accuracy</link>
      <description><![CDATA[è¯¥æ¨¡å‹çš„ç²¾åº¦ç¡®å®å¾ˆä½ã€‚è¿™æ˜¯æˆ‘ç¬¬ä¸€æ¬¡å†™ç¥ç»ç½‘ç»œï¼Œæ‰€ä»¥æˆ‘çœŸçš„ä¸çŸ¥é“å¦‚ä½•ä½¿å®ƒå˜å¾—æ›´å¥½
 å°†TensorFlowå¯¼å…¥ä¸ºTF
å¯¼å…¥matplotlib.pyplotä½œä¸ºPLT
    
#dataè®¾ç½®
data = tf.keras.datasets.cifar10


ï¼ˆx_trainï¼Œy_trainï¼‰ï¼Œï¼ˆx_testï¼Œy_testï¼‰= data.load_dataï¼ˆï¼‰
plt.imshowï¼ˆx_train [0]ï¼Œcmap = plt.cm.binaryï¼‰

#normalizeæ•°æ®
x_train = tf.keras.utils.normalizeï¼ˆx_trainï¼Œaxis = 1ï¼‰
x_test = tf.keras.utils.normalizeï¼ˆx_testï¼Œaxis = 1ï¼‰

#building AIæ¨¡å‹

å‹å·= tf.keras.models.sequeentialï¼ˆï¼‰
Model.Addï¼ˆtf.keras.layers.flattenï¼ˆï¼‰ï¼‰
model.Addï¼ˆtf.keras.layers.denseï¼ˆ128ï¼Œæ¿€æ´»= tf.nn.reluï¼‰ï¼‰
model.Addï¼ˆtf.keras.layers.denseï¼ˆ128ï¼Œæ¿€æ´»= tf.nn.reluï¼‰ï¼‰
model.Addï¼ˆtf.keras.layers.denseï¼ˆ10ï¼Œæ¿€æ´»= tf.nn.softmaxï¼‰ï¼‰ï¼‰



#compileæ¨¡å‹
model.compileï¼ˆä¼˜åŒ–å™¨=&#39;adam&#39;ï¼Œ
             æŸå¤±=&#39;Sparse_categorical_crossentropy&#39;ï¼Œ
             æŒ‡æ ‡= [&#39;å‡†ç¡®æ€§&#39;]ï¼‰

plt.showï¼ˆï¼‰
#Train AIæ¨¡å‹
model.fitï¼ˆx_trainï¼Œy_trainï¼Œepochs = 3ï¼‰
 ]]></description>
      <guid>https://stackoverflow.com/questions/73780627/neural-network-low-accuracy</guid>
      <pubDate>Tue, 20 Sep 2022 00:59:44 GMT</pubDate>
    </item>
    <item>
      <title>ç¥ç»ç½‘ç»œçš„ç²¾åº¦éå¸¸ä½</title>
      <link>https://stackoverflow.com/questions/65777704/getting-a-very-low-accuracy-with-neural-network</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨kerasåœ¨CIFAR-10æ•°æ®é›†ä¸Šå®ç°ANN
ä½†æ˜¯ç”±äºæŸç§åŸå› ï¼Œæˆ‘ä¸çŸ¥é“æˆ‘åªèƒ½è·å¾—10ï¼…çš„å‡†ç¡®æ€§ï¼Ÿ
æˆ‘åˆ†åˆ«ä½¿ç”¨äº†5ä¸ªéšè—å±‚IWTH 8,16,32,64,128ç¥ç»å…ƒã€‚
 è¿™æ˜¯jupyterç¬”è®°æœ¬ çš„é“¾æ¥
  model = sequentionï¼ˆï¼‰
model.Addï¼ˆå¯†é›†ï¼ˆå•ä½= 8ï¼Œactivation =&#39;sigmoid&#39;ï¼Œinput_dim = x.shape [1]ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰
model.Addï¼ˆå¯†é›†ï¼ˆå•ä½= 16ï¼Œactivation =&#39;Sigmoid&#39;ï¼‰ï¼‰ï¼‰ï¼‰
model.Addï¼ˆå¯†é›†ï¼ˆå•ä½= 32ï¼Œactivation =&#39;Sigmoid&#39;ï¼‰ï¼‰
model.Addï¼ˆå¯†é›†ï¼ˆå•ä½= 64ï¼Œactivation =&#39;sigmoid&#39;ï¼‰ï¼‰
model.Addï¼ˆå¯†é›†ï¼ˆå•ä½= 128ï¼Œactivation =&#39;Sigmoid&#39;ï¼‰ï¼‰
model.Addï¼ˆå¯†åº¦ï¼ˆå•ä½= 10ï¼Œactivation =&#39;softmax&#39;ï¼‰ï¼‰

model.compileï¼ˆloss =&#39;accorical_crossentropy&#39;ï¼Œimportizer =&#39;adam&#39;ï¼Œé‡è¡¨= [&#39;fecicy&#39;]ï¼‰

model.fitï¼ˆx_trainï¼Œy_trainï¼Œepochs = 1000ï¼Œbatch_size = 500ï¼‰
 ]]></description>
      <guid>https://stackoverflow.com/questions/65777704/getting-a-very-low-accuracy-with-neural-network</guid>
      <pubDate>Mon, 18 Jan 2021 15:44:46 GMT</pubDate>
    </item>
    <item>
      <title>ç¥ç»ç½‘ç»œä¸ç¡®å®šçš„ä¹³è…ºç™Œæ•°æ®é›†</title>
      <link>https://stackoverflow.com/questions/52358505/neural-network-undefitting-breast-cancer-dataset</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•åœ¨ä¹³è…ºç™Œæ•°æ®é›†ä¸Šåˆ›å»ºä¸€ä¸ªç”¨äºäºŒè¿›åˆ¶åˆ†ç±»çš„ç¥ç»ç½‘ç»œï¼š
  https://wwwww.kaggle.com/uciml/uciml/uciml/breast-cancer-cancer-wisconsin-data-data-data-data-data-data 
æˆ‘çš„ç¥ç»ç½‘ç»œç”±3å±‚ç»„æˆï¼ˆä¸åŒ…æ‹¬è¾“å…¥å±‚ï¼‰ï¼š

 ç¬¬ä¸€å±‚ï¼š6ä¸ªå¸¦æœ‰Tanhæ¿€æ´»çš„ç¥ç»å…ƒã€‚

 ç¬¬äºŒå±‚ï¼š6ä¸ªå¸¦æœ‰Tanhæ¿€æ´»çš„ç¥ç»å…ƒã€‚

 æœ€ç»ˆå±‚ï¼š1ä¸ªç¥ç»å…ƒï¼Œå¸¦æœ‰Sigmoidæ¿€æ´»ã€‚


ä¸å¹¸çš„æ˜¯ï¼Œæˆ‘åœ¨è®­ç»ƒç¤ºä¾‹ä¸­ä»…è·å¾—çº¦44ï¼…çš„ç²¾åº¦ï¼Œåœ¨æµ‹è¯•ç¤ºä¾‹ä¸­çš„ç²¾åº¦çº¦ä¸º23ï¼…ã€‚
è¿™æ˜¯æˆ‘çš„pythonä»£ç ï¼š
 å¯¼å…¥numpyä½œä¸ºNP
å¯¼å…¥å¤§ç†ŠçŒ«ä½œä¸ºpd
å¯¼å…¥matplotlib.pyplotä½œä¸ºPLT

data = pd.read_csvï¼ˆ&#39;data.csv; quot;ï¼‰
data = data.dropï¼ˆ[&#39;id&#39;]ï¼Œè½´= 1ï¼‰
data = data.dropï¼ˆdata.columns [31]ï¼Œè½´= 1ï¼‰
data = data.replaceï¼ˆ{&#39;m&#39;ï¼š1ï¼Œ&#39;b&#39;ï¼š0}ï¼‰

x =æ•°æ®
x = x.dropï¼ˆ[&#39;è¯Šæ–­&#39;]ï¼Œè½´= 1ï¼‰
x = np.arrayï¼ˆxï¼‰

x_mean = np.meanï¼ˆxï¼Œaxis = 1ï¼Œkeepdims = trueï¼‰
x_std = np.stdï¼ˆxï¼Œaxis = 1ï¼Œkeepdims = trueï¼‰
x_n =ï¼ˆx -x_meanï¼‰ / x_std
y = np.arrayï¼ˆæ•°æ®[&#39;è¯Šæ–­&#39;]ï¼‰
y = y.Reshapeï¼ˆ569ï¼Œ1ï¼‰
M = 378
y_train = y [ï¼šmï¼Œï¼š]
y_test = y [mï¼šï¼Œï¼š]

x_train = x_n [ï¼šMï¼Œï¼š]
x_test = x_n [m :ï¼Œï¼š]

Def Sigmoidï¼ˆZï¼‰ï¼š
  è¿”å›1 /ï¼ˆ1 + np.expï¼ˆ-zï¼‰ï¼‰

def dsigmoidï¼ˆzï¼‰ï¼š
  è¿”å›np.multiplyï¼ˆzï¼Œï¼ˆ1 -zï¼‰ï¼‰

def tanhï¼ˆzï¼‰ï¼š
  è¿”å›ï¼ˆnp.expï¼ˆzï¼‰-np.expï¼ˆ-zï¼‰ï¼‰ /ï¼ˆnp.expï¼ˆzï¼‰ + np.expï¼ˆ-zï¼‰ï¼‰

def dtanhï¼ˆzï¼‰ï¼š
  è¿”å›1 -np.squareï¼ˆtanhï¼ˆzï¼‰ï¼‰

defæˆæœ¬ï¼ˆaï¼Œyï¼‰ï¼š
  m = y.å½¢[0]
  è¿”å› - ï¼ˆ1.0/mï¼‰ *np.sumï¼ˆnp.dotï¼ˆy.tï¼Œnp.logï¼ˆaï¼‰ï¼‰ + np.dotï¼ˆï¼ˆï¼ˆ1 -yï¼‰.tï¼Œnpï¼Œnp.logï¼ˆ1 -aï¼‰ï¼‰ï¼‰

def trainï¼ˆxï¼Œyï¼Œå‹å·ï¼Œepocsï¼Œaï¼‰ï¼š
  W1 =æ¨¡å‹[&#39;W1&#39;]
  W2 =æ¨¡å‹[&#39;W2&#39;]
  W3 =æ¨¡å‹[&#39;W3&#39;]
  
  B1 =æ¨¡å‹[&#39;B1&#39;]
  B2 =æ¨¡å‹[&#39;B2&#39;]
  B3 =æ¨¡å‹[&#39;B3&#39;]
  
  è´¹ç”¨= []
  
  å¯¹äºæˆ‘çš„èŒƒå›´ï¼ˆEPOCï¼‰ï¼š
    
    ï¼ƒå‰ä¼ æ’­

    z1 = np.dotï¼ˆxï¼Œw1ï¼‰ + b1
    a1 = tanhï¼ˆz1ï¼‰

    z2 = np.dotï¼ˆa1ï¼Œw2ï¼‰ + b2
    a2 = tanhï¼ˆz2ï¼‰

    z3 = np.dotï¼ˆa2ï¼Œw3ï¼‰ + b3
    A3 = Sigmoidï¼ˆZ3ï¼‰
    
    costs.appendï¼ˆæˆæœ¬ï¼ˆA3ï¼Œyï¼‰ï¼‰

    #backç¹æ®–
    
    dz3 = z3 -y
    d3 = np.multiplyï¼ˆdz3ï¼Œdsigmoidï¼ˆz3ï¼‰ï¼‰
    dw3 = np.dotï¼ˆa2.tï¼Œd3ï¼‰
    db3 = np.sumï¼ˆd3ï¼Œaxis = 0ï¼Œkeepdims = trueï¼‰

    d2 = np.multiplyï¼ˆnp.dotï¼ˆd3ï¼Œw3.tï¼‰ï¼Œdtanhï¼ˆz2ï¼‰ï¼‰
    dw2 = np.dotï¼ˆa1.tï¼Œd2ï¼‰
    db2 = np.sumï¼ˆd2ï¼Œè½´= 0ï¼Œkeepdims = trueï¼‰

    d1 = np.multiplyï¼ˆnp.dotï¼ˆd2ï¼Œw2.tï¼‰ï¼Œdtanhï¼ˆz1ï¼‰ï¼‰
    dw1 = np.dotï¼ˆx.Tï¼Œd1ï¼‰
    db1 = np.sumï¼ˆd1ï¼Œaxis = 0ï¼Œkeepdims = trueï¼‰

    W1  -  =ï¼ˆA / Mï¼‰ * DW1
    W2- =ï¼ˆA / Mï¼‰ * DW2
    w3- =ï¼ˆa / mï¼‰ * dw3

    B1  -  =ï¼ˆA / Mï¼‰ * DB1
    b2  -  =ï¼ˆa / mï¼‰ * db2
    B3  -  =ï¼ˆA / Mï¼‰ * DB3
    
  cache = {&#39;w1&#39;ï¼šw1ï¼Œ&#39;w2&#39;ï¼šw2ï¼Œ&#39;w3&#39;ï¼šw3ï¼Œ&#39;b1&#39;ï¼šb1&#39;ï¼šb1ï¼Œ&#39;b2&#39;ï¼šb2ï¼Œ&#39;b3&#39;ï¼šb3}
  è¿”å›ç¼“å­˜ï¼Œæˆæœ¬

np.random.seedï¼ˆ0ï¼‰

å‹å·= {&#39;w1&#39;ï¼šnp.random.randï¼ˆ30ï¼Œ6ï¼‰ * 0.01ï¼Œ&#39;w2&#39;ï¼šnp.random.randï¼ˆ6ï¼Œ6ï¼‰ * 0.01ï¼Œ&#39;w3&#39;ï¼šnp.random.randï¼ˆ6ï¼Œ1ï¼‰ &#39;b3&#39;ï¼šnp.random.randï¼ˆ1ï¼Œ1ï¼‰}

å‹å·ï¼Œæˆæœ¬=ç«è½¦ï¼ˆx_trainï¼Œy_trainï¼Œå‹å·ï¼Œ1000ï¼Œ0.1ï¼‰

plt.plotï¼ˆ[iåœ¨èŒƒå›´å†…ï¼ˆ1000ï¼‰]ï¼Œè´¹ç”¨ï¼‰
æ‰“å°ï¼ˆè´¹ç”¨[999]ï¼‰
plt.showï¼ˆï¼‰



defé¢„æµ‹ï¼ˆxï¼Œyï¼Œæ¨¡å‹ï¼‰ï¼š
  W1 =æ¨¡å‹[&#39;W1&#39;]
  W2 =æ¨¡å‹[&#39;W2&#39;]
  W3 =æ¨¡å‹[&#39;W3&#39;]
  
  B1 =æ¨¡å‹[&#39;B1&#39;]
  B2 =æ¨¡å‹[&#39;B2&#39;]
  B3 =æ¨¡å‹[&#39;B3&#39;]
  
  z1 = np.dotï¼ˆxï¼Œw1ï¼‰ + b1
  a1 = tanhï¼ˆz1ï¼‰

  z2 = np.dotï¼ˆa1ï¼Œw2ï¼‰ + b2
  a2 = tanhï¼ˆz2ï¼‰

  z3 = np.dotï¼ˆa2ï¼Œw3ï¼‰ + b3
  A3 = Sigmoidï¼ˆZ3ï¼‰
  
  m = a3.å½¢[0]
  y_predict = np.zerosï¼ˆï¼ˆMï¼Œ1ï¼‰ï¼‰
  
  å¯¹äºæˆ‘çš„èŒƒå›´ï¼ˆmï¼‰ï¼š
    y_predict = 1å¦‚æœa3 [iï¼Œ0]ï¼†gt; 0.5å…¶ä»–0
  è¿”å›y_predict
 ]]></description>
      <guid>https://stackoverflow.com/questions/52358505/neural-network-undefitting-breast-cancer-dataset</guid>
      <pubDate>Sun, 16 Sep 2018 21:24:54 GMT</pubDate>
    </item>
    <item>
      <title>Pytorchä¸­çš„æ•°æ®å¢å¼º</title>
      <link>https://stackoverflow.com/questions/51677788/data-augmentation-in-pytorch</link>
      <description><![CDATA[æˆ‘å¯¹Pytorchä¸­æ‰§è¡Œçš„æ•°æ®å¢åŠ æœ‰äº›å›°æƒ‘ã€‚ç°åœ¨ï¼Œæ®æˆ‘æ‰€çŸ¥ï¼Œå½“æˆ‘ä»¬æ‰§è¡Œæ•°æ®å¢å¼ºæ—¶ï¼Œæˆ‘ä»¬å°†ä¿ç•™åŸå§‹æ•°æ®é›†ï¼Œç„¶åæ·»åŠ å…¶ä»–ç‰ˆæœ¬ï¼ˆç¿»è½¬ï¼Œè£å‰ªç­‰ï¼‰ã€‚ä½†è¿™ä¼¼ä¹å¹¶æ²¡æœ‰å‘ç”Ÿåœ¨Pytorchä¸­ã€‚æ®æˆ‘ä»å‚è€ƒæ–‡çŒ®ä¸­ç†è§£æ—¶ï¼Œå½“æˆ‘ä»¬åœ¨pytorchä¸­ä½¿ç”¨ data.transforms æ—¶ï¼Œå®ƒå°†å®ƒä»¬ä¸€ä¸€åº”ç”¨å®ƒä»¬ã€‚å› æ­¤ï¼š
  data_transforms = {
    &#39;train&#39;ï¼štransforms.composeï¼ˆ[
        transforms.randomresizedcropï¼ˆ224ï¼‰ï¼Œ
        transforms.randomhorizoâ€‹â€‹ntalflipï¼ˆï¼‰ï¼Œ
        transforms.totensorï¼ˆï¼‰ï¼Œ
        transforms.normizeï¼ˆ[0.485ï¼Œ0.456ï¼Œ0.406]ï¼Œ[0.229ï¼Œ0.224ï¼Œ0.225]ï¼‰
    ]ï¼‰ï¼Œï¼Œ
    &#39;val&#39;ï¼štransforms.composeï¼ˆ[
        è½¬æ¢å¼Resizeï¼ˆ256ï¼‰ï¼Œ
        transforms.centercropï¼ˆ224ï¼‰ï¼Œ
        transforms.totensorï¼ˆï¼‰ï¼Œ
        transforms.normizeï¼ˆ[0.485ï¼Œ0.456ï¼Œ0.406]ï¼Œ[0.229ï¼Œ0.224ï¼Œ0.225]ï¼‰
    ]ï¼‰ï¼Œï¼Œ
}
 
åœ¨è¿™é‡Œï¼Œå¯¹äºåŸ¹è®­ï¼Œæˆ‘ä»¬é¦–å…ˆæ˜¯éšæœºè£å‰ªå›¾åƒå¹¶å°†å…¶è°ƒæ•´ä¸ºShape ï¼ˆ224,224ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›ï¼ˆ224,224ï¼‰å›¾åƒè¿›è¡Œæ°´å¹³ç¿»è½¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†ç°åœ¨ä»…åŒ…å«æ°´å¹³ç¿»è½¬çš„å›¾åƒï¼Œå› æ­¤åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„åŸå§‹å›¾åƒä¸¢å¤±äº†ã€‚
æˆ‘å¯¹å—ï¼Ÿè¿™ç†è§£æ˜¯æ­£ç¡®çš„å—ï¼Ÿå¦‚æœä¸æ˜¯ï¼Œé‚£ä¹ˆæˆ‘ä»¬åœ¨ä¸Šé¢çš„æ­¤ä»£ç ä¸­ï¼ˆå–è‡ªå®˜æ–¹æ–‡æ¡£ï¼‰å°†Pytorchå‘Šè¯‰åŸå§‹å›¾åƒå¹¶å°†å…¶è°ƒæ•´åˆ°é¢„æœŸå½¢çŠ¶ï¼ˆ224,224ï¼‰ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/51677788/data-augmentation-in-pytorch</guid>
      <pubDate>Fri, 03 Aug 2018 17:51:49 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨GridSearchCVä¸­å¾—åˆ†XGBoost</title>
      <link>https://stackoverflow.com/questions/50296817/scoring-in-gridsearchcv-for-xgboost</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨XGBoosté¦–æ¬¡åˆ†ææ•°æ®ã€‚æˆ‘æƒ³ä½¿ç”¨GridSearchCVæ‰¾åˆ°æœ€ä½³å‚æ•°ã€‚æˆ‘æƒ³æœ€å¤§ç¨‹åº¦åœ°å‡å°‘å‡æ–¹æ ¹é”™è¯¯ï¼Œä¸ºæ­¤ï¼Œæˆ‘ä½¿ç”¨äº†â€œ rmseâ€ã€‚ä½œä¸ºeval_metricã€‚ä½†æ˜¯ï¼Œç½‘æ ¼æœç´¢çš„è¯„åˆ†æ²¡æœ‰è¿™æ ·çš„åº¦é‡ã€‚æˆ‘åœ¨æ­¤ç½‘ç«™ä¸Šå‘ç°â€œ neg_mean_squared_errorâ€è¿™æ ·åšä¸€æ ·ï¼Œä½†æ˜¯æˆ‘å‘ç°è¿™ç»™æˆ‘ä¸RMSEä¸åŒçš„ç»“æœã€‚å½“æˆ‘è®¡ç®—â€œ neg_mean_squared_errorâ€çš„ç»å¯¹å€¼çš„æ ¹ç›®å½•æ—¶ï¼Œæˆ‘çš„å€¼çº¦ä¸º8.9ï¼Œè€Œä¸åŒçš„åŠŸèƒ½ä½¿æˆ‘çš„RMSEçº¦ä¸º4.4ã€‚
æˆ‘ä¸çŸ¥é“æ€ä¹ˆäº†ï¼Œæˆ–è€…å¦‚ä½•è·å¾—è¿™ä¸¤ä¸ªåŠŸèƒ½åŒæ„/ç»™å‡ºç›¸åŒçš„å€¼ï¼Ÿ
ç”±äºè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘é‡åˆ°äº†é”™è¯¯çš„å€¼ï¼Œå› ä¸º best_params _ ï¼Œå®ƒæ¯”æˆ‘æœ€åˆå¼€å§‹è°ƒéŸ³çš„æŸäº›å€¼æ›´é«˜çš„RMSEã€‚
å¦‚ä½•åœ¨ç½‘æ ¼æœç´¢ä¸­è·å¾—RMSEçš„åˆ†æ•°ä»¥åŠä¸ºä»€ä¹ˆæˆ‘çš„ä»£ç ç»™å‡ºä¸åŒçš„å€¼ï¼Ÿ
  def modelfitï¼ˆalgï¼Œtrainxï¼Œtrainyï¼Œusetraincv = trueï¼Œcv_folds = 10ï¼Œarmond_stopping_rounds = 50ï¼‰ï¼š
    å¦‚æœç”¨UsetrainCVï¼š
        xgb_param = alg.get_xgb_paramsï¼ˆï¼‰
        xgtrain = xgb.dmatrixï¼ˆtrainxï¼Œlabel = Trainyï¼‰
        cvresult = xgb.cvï¼ˆxgb_paramï¼Œxgtrainï¼Œnum_boost_round = alg.get_paramsï¼ˆï¼‰[&#39;n_estimators&#39;]ï¼Œnfold = cv_foldsï¼Œ
                          æŒ‡æ ‡=&#39;rmse&#39;ï¼Œropard_stopping_rounds = armon_stopping_roundsï¼‰
        alg.set_paramsï¼ˆn_estimators = cvresult.shape [0]ï¼‰

    ï¼ƒå°†ç®—æ³•é€‚åˆæ•°æ®
    alg.fitï¼ˆTrainxï¼ŒTrainyï¼Œeval_metric =&#39;rmse&#39;ï¼‰

    ï¼ƒé¢„æµ‹è®­ç»ƒé›†ï¼š
    dtrain_predictions = alg.predictï¼ˆtrainxï¼‰
    ï¼ƒdtrain_predprob = alg.predict_probaï¼ˆTrainyï¼‰[ï¼šï¼Œ1]
    æ‰“å°ï¼ˆdtrain_predictionsï¼‰
    printï¼ˆnp.sqrtï¼ˆmean_squared_errorï¼ˆtrainyï¼Œdtrain_predictionsï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰

    ï¼ƒæ‰“å°æ¨¡å‹æŠ¥å‘Šï¼š
    æ‰“å°ï¼ˆâ€œ \ nmodelæŠ¥å‘Šâ€ï¼‰
    æ‰“å°ï¼ˆ&#39;rmseï¼šï¼….4G;ï¼…np.sqrtï¼ˆé‡å­¦

 param_test2 = {
 &#39;max_depth&#39;ï¼š[6,7,8]ï¼Œ
 &#39;min_child_weight&#39;ï¼š[2,3,4]
}

grid2 = gridSearchCVï¼ˆä¼°ç®—= xgb.xgb.xgbregressorï¼ˆLearning_rate = 0.1ï¼Œn_estimators = 2000ï¼Œmax_depth = 5ï¼Œ
 min_child_weight = 2ï¼Œgamma = 0ï¼Œsubsampe = 0.8ï¼Œcolsample_bytree = 0.8ï¼Œ
 objective =&#39;regï¼šlinear&#39;ï¼Œnthread = 4ï¼Œscale_pos_weight = 1ï¼Œandury_state = 4ï¼‰ï¼Œ
 param_grid = param_test2ï¼Œè¯„åˆ†=&#39;neg_mean_squared_error&#39;ï¼Œn_jobs = 4ï¼Œiid = falseï¼Œcv = 10ï¼Œå†—é•¿= 20ï¼‰
grid2.fitï¼ˆx_trainï¼Œy_trainï¼‰
ï¼ƒbest_estimatorçš„å¹³å‡äº¤å‰éªŒè¯å¾—åˆ†
printï¼ˆgrid2.best_params_ï¼Œnp.sqrtï¼ˆnp.absï¼ˆgrid2.best_score_ï¼‰ï¼‰ï¼‰ï¼‰ï¼Œprintï¼ˆnp.sqrtï¼ˆnp.absï¼ˆgrid2.score2.scoreï¼ˆx_trainï¼Œy_trainï¼Œy_trainï¼‰ï¼‰ï¼‰ï¼‰
modelfitï¼ˆgrid2.best_estimator_ï¼Œx_trainï¼Œy_trainï¼‰
printï¼ˆnp.sqrtï¼ˆnp.absï¼ˆgrid2.scoreï¼‰ï¼ˆx_trainï¼Œy_trainï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰ï¼‰
 ]]></description>
      <guid>https://stackoverflow.com/questions/50296817/scoring-in-gridsearchcv-for-xgboost</guid>
      <pubDate>Fri, 11 May 2018 16:46:16 GMT</pubDate>
    </item>
    <item>
      <title>å¯¹ç¥ç»ç½‘ç»œçš„è¾“å…¥ç±»å‹å¾ˆé‡è¦ï¼Ÿ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/37438078/does-type-of-input-to-the-neural-network-matter</link>
      <description><![CDATA[æˆ‘æ­£åœ¨åšè§†é¢‘åˆ†ç±»ã€‚
æˆ‘æœ‰ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œæˆ‘å¿…é¡»ä½¿ç”¨è§†é¢‘ï¼ˆå›¾åƒç»„ï¼‰è®­ç»ƒã€‚
æˆ‘å¯ä»¥é€‰æ‹©ä»å‡ ä¸ªé€‰é¡¹æ›´æ”¹ç½‘ç»œè¾“å…¥çš„å½¢çŠ¶ã€‚
åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼Œæˆ‘éƒ½è®¤ä¸ºç½‘ç»œä½“ç³»ç»“æ„ï¼ˆæ’åˆ—å’Œå±‚æ•°ï¼‰ï¼†amp;å­¦ä¹ å‚æ•°ï¼ˆLR/Decay/æ­£åˆ™åŒ–/ç­‰ï¼‰æ˜¯æ’å®šçš„ã€‚
ä¾‹å¦‚ï¼Œæˆ‘å¯ä»¥é€‰æ‹©å°†ç½‘ç»œè¾“å…¥ä½œä¸ºä»¥ä¸‹å†…å®¹ä¹‹ä¸€ã€‚

  batch_size xï¼ˆno_of_imgs*no_of_channelsï¼‰xé«˜åº¦xå®½åº¦{3å°ºå¯¸è¾“å…¥} 

  batch_size x no_of_imgs x no_of_channels xé«˜åº¦xå®½åº¦{4å°ºå¯¸è¾“å…¥} 

  batch_size x no_of_channels x no_of_imgs xé«˜åº¦xå®½åº¦{4å°ºå¯¸è¾“å…¥} 


è¾“å…¥å½¢çŠ¶å°†å¦‚ä½•å½±å“ç½‘ç»œçš„å‡†ç¡®æ€§ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/37438078/does-type-of-input-to-the-neural-network-matter</guid>
      <pubDate>Wed, 25 May 2016 13:04:48 GMT</pubDate>
    </item>
    </channel>
</rss>