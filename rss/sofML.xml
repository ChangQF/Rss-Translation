<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 30 Dec 2023 12:23:29 GMT</lastBuildDate>
    <item>
      <title>高斯判别分析是否不适用于x较大且y较大的数据？</title>
      <link>https://stackoverflow.com/questions/77735867/is-gaussian-discriminant-analysis-unsuitable-for-data-where-x-is-bigger-and-y-is</link>
      <description><![CDATA[例如，x（肿瘤大小）越大，y（诊断概率）越大。这样的数据是不是不适合高斯判别分析模型。
因为这样的数据并不是当x接近平均值μ时y（诊断概率）最大化的情况]]></description>
      <guid>https://stackoverflow.com/questions/77735867/is-gaussian-discriminant-analysis-unsuitable-for-data-where-x-is-bigger-and-y-is</guid>
      <pubDate>Sat, 30 Dec 2023 12:10:56 GMT</pubDate>
    </item>
    <item>
      <title>变压器解码不正确</title>
      <link>https://stackoverflow.com/questions/77735779/incorrect-transformer-decoding</link>
      <description><![CDATA[我在序列到序列翻译任务（英语到西班牙语）上应用了标准转换器。我已启用在解码器的自注意力部分中引起屏蔽，并且我正在使用 keras_nlp 中的正弦位置嵌入层。在训练中，损失在短短 5 个时期内就下降到 0.0084，这是不寻常的，然后在解码测试句子时，所有模型生成的都是重复的 &lt;&lt;开始&gt;象征。显然，我做错了什么，但我无法识别它，所以如果有人能指出我到底错在哪里，我将不胜感激。
变压器编码器：
def Transformer_encoder(输入、head_size、num_heads、ff_dim、dropout=0)：
# 标准化和注意力
attn_output = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(输入, 输入)
attn_output = 辍学（辍学）（attn_output）
out1 = LayerNormalization(epsilon=1e-6)(输入 + attn_output)

# 前馈部分
ffn_output = 密集（ff_dim，激活 =“relu”）（out1）
ffn_output = 辍学（辍学）（ffn_output）
ffn_output = 密集(inputs.shape[-1])(ffn_output)
返回 LayerNormalization(epsilon=1e-6)(out1 + ffn_output)

变压器解码器：
def Transformer_decoder(输入、enc_outputs、head_size、num_heads、ff_dim、dropout=0)：
# 标准化和注意力
x = 层标准化（epsilon=1e-6）（输入）
mha = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)
a = mha(查询=x，键=x，值=x，use_causal_mask=True)
x = 辍学（辍学）（a）
分辨率 = x + 输入

# 编码器-解码器注意力
x = 层标准化(epsilon=1e-6)(res)
x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, enc_outputs)
x = 辍学（辍学）（x）
分辨率 = x + 分辨率

# 前馈部分
x = 层标准化(epsilon=1e-6)(res)
x = 密集（ff_dim，激活=“relu”）（x）
x = 辍学（辍学）（x）
x = 密集(输入.形状[-1])(x)
返回 x + 分辨率

构建模型：
def build_transformer(vocab_size_eng, vocab_size_spa, max_len_eng, max_len_spa, head_size=64, num_heads=4, ff_dim=64, dropout=0.1):
# 编码器
编码器输入=输入（形状=（max_len_eng，））
x_enc = 嵌入(vocab_size_eng, head_size)(encoder_inputs)
x_enc_pos = keras_nlp.layers.SinePositionEncoding()(x_enc)
x_enc = x_enc + x_enc_pos

对于范围（2）内的 _：
    x_enc = Transformer_encoder(x_enc, head_size, num_heads, ff_dim, dropout)

# 解码器
解码器输入=输入（形状=（max_len_spa，））
x_dec = 嵌入(vocab_size_spa, head_size)(decoder_inputs)
x_dec_pos = keras_nlp.layers.SinePositionEncoding()(x_dec)
x_dec = x_dec + x_dec_pos

对于 _ 在范围（2）中：
    x_dec = Transformer_decoder(x_dec, x_enc, head_size, num_heads, ff_dim, dropout)

# 输出层
输出=密集（vocab_size_spa，激活=&#39;softmax&#39;）（x_dec）

# 定义并返回模型
模型 = 模型（输入=[编码器输入，解码器输入]，输出=输出）
返回模型

Colab 笔记本链接及结果供进一步参考：https://colab。 Research.google.com/drive/1MXrKkme53wLHoeriaFGY29P6pkeuB213?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/77735779/incorrect-transformer-decoding</guid>
      <pubDate>Sat, 30 Dec 2023 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>ML.net 中的 DataView 到 IDataView</title>
      <link>https://stackoverflow.com/questions/77735721/dataview-to-idataview-in-ml-net</link>
      <description><![CDATA[我有一个源自 CSV 文件的 DataView。像这样
数据视图 RateDataView = LoadData(mlContext, dataPath);
现在我有使用 IDataView 的功能，例如 FitAndSaveModel(mlContext, RateDataView,rateModelPath);
无论如何，是否可以将 DataView 转换为 IDataView。
我在尝试此操作时遇到以下错误。
无法从“System.Data.DataView”转换为“Microsoft.ML.IDataView”]]></description>
      <guid>https://stackoverflow.com/questions/77735721/dataview-to-idataview-in-ml-net</guid>
      <pubDate>Sat, 30 Dec 2023 11:12:43 GMT</pubDate>
    </item>
    <item>
      <title>libsvm 中的标准化数据错误</title>
      <link>https://stackoverflow.com/questions/77735344/wrong-normalizing-data-in-libsvm</link>
      <description><![CDATA[我正在学习 libsvm。
现在，我有 25 个 RGB 格式的训练文本文件，并且想要将数据标准化到 0 到 1 的范围
我知道libsvm格式是
标签 1：值 2：值 ...
但无论我做什么，它总是给我一个 Wong 格式。
我的数据
&lt;前&gt;&lt;代码&gt; R G B
1 1:39 2:8 3:100
1 1:34 2:3 3:67

我输入了 cmd svm-scale -l 0 -u 1 train.txt &gt;扩展规模
输出
&lt;前&gt;&lt;代码&gt;1 1:1 2:1 3:1
1

不输出什么1 1:0.xxx 2:0.xxx 3:0.xxx ...？
我查了好几天的资料，然后我有一些疑问。

如何正确地将 0 标准化为 1？

标签的具体用途是什么？

我有 25 个训练文本。我应该将它们全部复制到一个文本文件中然后进行转换吗？

]]></description>
      <guid>https://stackoverflow.com/questions/77735344/wrong-normalizing-data-in-libsvm</guid>
      <pubDate>Sat, 30 Dec 2023 08:45:24 GMT</pubDate>
    </item>
    <item>
      <title>对所有特征进行编码还是仅对字符串特征进行编码？</title>
      <link>https://stackoverflow.com/questions/77735091/encode-all-features-or-just-string-features</link>
      <description><![CDATA[假设我有这个数据框：
DataFrame
当我尝试时，我发现对所有特征进行编码的 MSE 低于对某些指定特征进行编码的 MSE。但不知道哪种方式才是正确的？我想知道，我应该对 bmi、smoker 和region 使用 LabelEncoder 还是对所有功能使用 LabelEncoder？正确的做法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/77735091/encode-all-features-or-just-string-features</guid>
      <pubDate>Sat, 30 Dec 2023 06:51:28 GMT</pubDate>
    </item>
    <item>
      <title>通过减少 val_loss 和增加 val_accuracy 来改进模型？</title>
      <link>https://stackoverflow.com/questions/77735071/improving-the-model-by-decreasing-val-loss-and-increasing-val-accuracy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77735071/improving-the-model-by-decreasing-val-loss-and-increasing-val-accuracy</guid>
      <pubDate>Sat, 30 Dec 2023 06:41:04 GMT</pubDate>
    </item>
    <item>
      <title>使用JAXopt进行约束优化（非负）</title>
      <link>https://stackoverflow.com/questions/77734910/using-jaxopt-on-constrained-optimizationnon-negative</link>
      <description><![CDATA[我正在尝试对我的损失函数进行优化（使用 JAX），该函数来自一个基本物理模型，该模型是以不同速率增长的两层。因为增长率总是正的。我想对我的优化器应用非负约束。我查了一下，发现了一些关于 JAXopt 的文档。但是，我不太确定如何将其包含在我的案例中，因为我的损失函数的定义与他们的示例非常不同。
这是一个简短的代码（65 行），它捕获了我想要展示的所有功能。我想使用 JAXopt 的投影梯度确保参数 {raw_vs1, raw_vs2} 均为非负。
导入 jax.numpy 作为 jnp
从 jax 导入随机、宽松、梯度、jit
将 matplotlib.pyplot 导入为 plt
进口光税
从 jaxopt 导入 ProjectedGradient
从 jaxopt.projection 导入projection_non_negative


# 优化代码设置
尼克斯 = 1000
新台币 = 100
密钥 = random.PRNGKey(0)
dt = 0.01
reg_a = 1.0
reg_b = 1.0
reg_c = 1.0
d = 3
ds = 0.003

xs = jnp.linspace(-1.0, 1.0, Nx)
参数 = {
    &#39;raw_vs1&#39;: random.uniform(key, shape=(Nt, Nx)),
    &#39;raw_vs2&#39;: random.uniform(key, shape=(Nt, Nx))
}
目标 = jnp.power(xs, 4)
y0 = jnp.power(xs, 2)
lengths0 = jnp.power(xs, 0) * 0.001 # 将每个时间步每个点的长度初始化为 0.1

def 模拟（参数，dt）：
    vs1 = 参数[&#39;raw_vs1&#39;]
    vs2 = 参数[&#39;raw_vs2&#39;]
    vs = vs1 - vs2
    vf = (vs1 + vs2 )/ 2

    def _step(进位, t):
        y，长度=进位
        y_new = y + vs[t] * dt
        lengths_new = lengths + vf[t] * dt # 在时间步 t 更新每个索引的长度
        返回（y_new，lengths_new），（y_new，lengths_new）

    Carry = (y0, lengths0) # 具有第一个时间步长的初始进位
    (yf,_), (ys, lengths_final) = lax.scan(_step, 进位, jnp.arange(Nt))
    print(&quot;lengths_final 的形状：&quot;, lengths_final.shape)
    print(&quot;yf 的形状：&quot;, yf.shape)
    print(&quot;ys 的形状：&quot;, ys.shape)
    返回 yf, ys, lengths_final

def损失（参数，dt，reg_a = reg_a，reg_b = reg_b，reg_c = reg_c，target_length = d）：
    yf, ys, leng = 模拟(params, dt)
    dt_term = jnp.sum(jnp.power(jnp.diff(ys, axis=0), 2))
    dx_term = jnp.sum(jnp.power(jnp.diff(ys, axis=1), 2))
    target_term = jnp.power(yf - 目标, 2)
    总长度 = jnp.sum(leng[-1])
    长度项 = (总长度 - 目标长度) ** 2
    返回 reg_a*dt_term + reg_b*dx_term + jnp.sum(reg_c*target_term) + reg_c*length_term


# 优化设置
g_loss = jit(grad(损失))
优化器 = optax.adam(0.01)
opt_state = 优化器.init(params)

# 优化循环
损失_t = []
对于范围内的 i（2000）：
    梯度 = g_loss(参数, dt)
    更新， opt_state = optimizationr.update(grads, opt_state)
    params = optax.apply_updates(params, 更新)
    loss_t.append(损失(params, dt))
]]></description>
      <guid>https://stackoverflow.com/questions/77734910/using-jaxopt-on-constrained-optimizationnon-negative</guid>
      <pubDate>Sat, 30 Dec 2023 05:01:58 GMT</pubDate>
    </item>
    <item>
      <title>有人可以帮我处理我的张量流代码吗[关闭]</title>
      <link>https://stackoverflow.com/questions/77734479/can-some-one-help-me-with-my-tensorflow-code</link>
      <description><![CDATA[所以我编写了一组基本的张量流代码，测试集准确率达到 97%，然后使用下面的代码帮助我编写一些数字，保存屏幕并打开图像，然后将其转换为 28x28 图像，然后将其输入到模型中，但由于某种原因，模型总是预测 4。
如果您想查看完整代码，请参阅存储库链接：https://github.com/Deadskullcandy/ Mnist_Model
导入 pygame


# 初始化 Pygame
pygame.init()

# 设置屏幕
宽度, 高度 = 280, 280
屏幕 = pygame.display.set_mode((宽度，高度))
pygame.display.set_caption(&#39;绘制并预测&#39;)

# 设置颜色
白色 = (255, 255, 255)

# 设置绘图参数
绘图 = 假

# 主循环
运行=真
在跑步的时候：
    对于 pygame.event.get() 中的事件：
        如果 event.type == pygame.QUIT：
            运行=假
        
        elif event.type == pygame.MOUSEBUTTONDOWN：
            绘图=真实
        
        elif event.type == pygame.MOUSEBUTTONUP：
            绘图 = 假
        
        elif event.type == pygame.MOUSEMOTION 和绘图：
            mouse_pos = pygame.mouse.get_pos()
            pygame.draw.circle（屏幕，白色，mouse_pos，5）
        
        elif event.type == pygame.KEYDOWN：
            如果 event.key == pygame.K_SPACE：
                pygame.image.save（屏幕，&#39;temp.png&#39;）
                图像 = pygame.image.load(&#39;temp.png&#39;).convert()
                图像 = pygame.transform.scale(图像,(28,28))
                图像 = pygame.transform.flip(图像, True, False)
                image_array = pygame.surfarray.array2d(图像)
                image_array = np.resize(image_array,(1,28,28))
                预测=probability_model.predict(image_array)
                打印（np.argmax（预测[0]））

            如果 event.key == pygame.K_r:
                screen.fill(&#39;黑色&#39;)
                
    pygame.display.flip()

pygame.quit()

我不知道如何修复它或模型发生了什么]]></description>
      <guid>https://stackoverflow.com/questions/77734479/can-some-one-help-me-with-my-tensorflow-code</guid>
      <pubDate>Sat, 30 Dec 2023 00:28:56 GMT</pubDate>
    </item>
    <item>
      <title>收到存在密钥的 KeyError [关闭]</title>
      <link>https://stackoverflow.com/questions/77733832/receiving-keyerror-for-a-key-that-exists</link>
      <description><![CDATA[所以我想尝试一个机器学习项目来了解更多信息，并决定建立一个预测比特币价格的模型。当我尝试从每个 wiki 修订版中检索评论时，我收到一个关键错误，指出“comment”键不存在。
&lt;前&gt;&lt;代码&gt;编辑 = {}

对于转速（以转数为单位）：
    date = time.strftine(&quot;%Y-%m-%d&quot;, rev[&quot;时间戳&quot;])

    如果日期不在编辑中：
        编辑[日期]=dict(情感=列表()，edit_count=0)
                         
    编辑[日期][“编辑计数”] += 1


    评论 = rev[“评论”]
    编辑[日期][“情绪”].append(find_sentiment(评论))

输出
&lt;前&gt;&lt;代码&gt; -------------------------------------------------------- -----------------------
    KeyError Traceback（最近一次调用最后一次）
    [10] 中的单元格，第 10 行
         8 次编辑[日期]=dict(sentiments=list(), edit_count=0)
         9 次编辑[日期][“编辑计数”] += 1
    ---&gt;10 评论 = rev[&#39;comment&#39;]
        11 次编辑[日期][“情绪”].append(find_sentiment(comment))
    
    关键错误：“评论”

当我查看字典时，它有注释键。我尝试查找问题，但每个人都说通过打印错误消息来处理异常，而我需要数据。任何帮助将不胜感激，我已经在这方面遇到了很多问题，这似乎是一个死胡同。
revs =排序(revs, key=lambda rev: rev[“时间戳”])

转速[0]

输出
 OrderedDict([(&#39;revid&#39;, 275832581),
             (&#39;父代&#39;, 0),
             (&#39;用户&#39;, &#39;Pratyeka&#39;),
             (&#39;时间戳&#39;,
              time.struct_time(tm_year=2009, tm_mon=3, tm_mday=8, tm_hour=16, tm_min=41, tm_sec=7, tm_wday=6, tm_yday=67, tm_isdst=-1)),
             (&#39;评论&#39;, &#39;创建(存根)&#39;)])

如果这有帮助的话，这也是我试图遵循的项目：
视频]]></description>
      <guid>https://stackoverflow.com/questions/77733832/receiving-keyerror-for-a-key-that-exists</guid>
      <pubDate>Fri, 29 Dec 2023 20:06:32 GMT</pubDate>
    </item>
    <item>
      <title>使用自我训练的 AI 模型生成导入定义[关闭]</title>
      <link>https://stackoverflow.com/questions/77733066/generate-import-definitions-using-a-self-trained-ai-modell</link>
      <description><![CDATA[在我们的应用程序中，我们有一个导入模块，用户可以在其中指定如何从文本文件（以及其他文件类型、XML 和 ODBC）中提取数据。与将文本文件导入 Excel 有点类似 - 但有更多的可能性。大多数文本文件都具有不符合标准的专有结构。导入模块可以处理各种结构，例如简单的 csv 文件以及嵌套的键值对等。
我们有这方面的样本数据（可能有 100 个或数百个示例）。
所以我正在考虑创建和训练一个人工智能模型，该模型可以为使用的任何新文件创建这样的导入定义。用户只需打开文件，AI 模型就会创建第一个导入定义（如何以及在何处提取应用程序中表和列的文本）。
所以这里的输入是具有未知结构的文本，输出是已定义的结构。
我在 C++ 编程方面有经验，但在 AI 方面没有经验。
如何才能做到这一点？我还无法找到一些与这个问题至少有点相似的示例或教程。]]></description>
      <guid>https://stackoverflow.com/questions/77733066/generate-import-definitions-using-a-self-trained-ai-modell</guid>
      <pubDate>Fri, 29 Dec 2023 16:48:15 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对新数据集进行预测</title>
      <link>https://stackoverflow.com/questions/77732371/make-prediction-on-new-data-set-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77732371/make-prediction-on-new-data-set-in-r</guid>
      <pubDate>Fri, 29 Dec 2023 14:03:24 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：使用 URL 'http://127.0.0.1:8237' 初始化剩余存储时出错：模块 'jwt' 没有属性 'encode'</title>
      <link>https://stackoverflow.com/questions/77730757/runtimeerror-error-initializing-rest-store-with-url-http-127-0-0-18237-mo</link>
      <description><![CDATA[第一个命令“python run_deployment.py --config deploy”运行成功并建议我运行下一个命令 - zenml up
“zenml up”生成以下错误。图片 1图片 2图片 3图片 4图片 5图片 6图片 7
我正在 YouTube 上关注 Ayush 的 MLOPs 课程。感谢您提前提供的帮助。
我试过了
&lt;前&gt;&lt;代码&gt;1。 pip 安装 jwt
2.pip安装PyJWT
3. pip卸载jwt
4. pip安装jwt==1.3.0
5. pip install --upgrade --force-reinstall PyJWT
6. pip install --upgrade --force-reinstall jwt
]]></description>
      <guid>https://stackoverflow.com/questions/77730757/runtimeerror-error-initializing-rest-store-with-url-http-127-0-0-18237-mo</guid>
      <pubDate>Fri, 29 Dec 2023 07:34:39 GMT</pubDate>
    </item>
    <item>
      <title>AutoTrain 高级 CLI：错误：无法识别的参数：--fp16 --use-int4</title>
      <link>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</link>
      <description><![CDATA[我目前在使用提供的自动训练工具在 Colab 笔记本中使用 LLM 模型微调数据时遇到问题。错误消息表明 autotrain 无法识别参数“--fp16”和“--use-int4”。我已经检查了文档和语法，但问题仍然存在。您能否提供解决此问题的指导或提供有关任何潜在解决方案的见解？谢谢。
/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13：
 UserWarning：无法加载图像Python扩展：&#39;/usr/local/lib/python3.10/dist-packages/torchvision/image.so：未定义符号：_ZN3c104cuda9SetDeviceEi&#39;如果您不打算使用`torchvision中的图像功能。 io`，你可以忽略这个警告。否则，您的环境可能有问题。在从源代码构建“torchvision”之前，您是否安装了“libjpeg”或“libpng”？ warn( 用法: autotrain  [] AutoTrain 高级 CLI: 错误: 无法识别的参数: --fp16 --use-int4

错误的屏幕截图
直到昨天，这段代码在这个 https://github.com/huggingface/autotrain-advanced 存储库中给出的 colab 笔记本上运行良好微调LLM，现在出现此错误。]]></description>
      <guid>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</guid>
      <pubDate>Fri, 15 Dec 2023 07:53:31 GMT</pubDate>
    </item>
    <item>
      <title>整洁模型变量的重要性变量的函数，工作流程[关闭]</title>
      <link>https://stackoverflow.com/questions/73010592/function-for-importance-variables-of-tidy-models-variables-workflow</link>
      <description><![CDATA[我需要一个在变量重要性工作流中使用的函数，该函数返回类似于 %IncMSE 的内容，我使用了 VIP 包中的函数，但它只返回绘图，我想要列名格式及其重要性在侧面。以下是我需要的输出格式：
]]></description>
      <guid>https://stackoverflow.com/questions/73010592/function-for-importance-variables-of-tidy-models-variables-workflow</guid>
      <pubDate>Sun, 17 Jul 2022 09:17:02 GMT</pubDate>
    </item>
    <item>
      <title>MLFLOW 工件存储在 ftp 服务器上但未显示在 ui 中</title>
      <link>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</link>
      <description><![CDATA[我在远程跟踪服务器上训练期间使用 MLFLOW 存储一些参数和指标。现在我还尝试添加一个 .png 文件作为工件，但由于 MLFLOW 服务器远程运行，我将该文件存储在 ftp 服务器上。我通过以下方式提供了 ftp 服务器地址和 MLFLOW 路径：
mlflow 服务器 --backend-store-uri sqlite:///mlflow.sqlite --default-artifact-root ftp://user:password@1.2.3.4/artifacts/ --host 0.0.0.0 &amp;

现在我训练一个网络并通过运行来存储工件：
mlflow.set_tracking_uri(remote_server_uri)
mlflow.set_experiment(“默认”)
mlflow.pytorch.autolog()

使用 mlflow.start_run()：
    mlflow.log_params(flow_params)
    训练师.fit(模型)
    训练师.test()
    mlflow.log_artifact(“confusion_matrix.png”)
mlflow.end_run()

我将 .png 文件保存在本地，然后使用 mlflow.log_artifact(“confusion_matrix.png”) 将其记录到与实验对应的右侧文件夹中的 ftp 服务器。到目前为止，一切正常，只是该工件没有显示在在线 mlflow ui 中。记录的参数和指标正常显示。工件面板保持空白，仅显示
未记录任何工件
使用日志工件 API 存储 MLflow 运行的文件输出。

我发现了类似的线程，但仅限于在本地 mlflow 存储上遇到相同问题的用户。不幸的是，我无法将这些修复应用于我的问题。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</guid>
      <pubDate>Tue, 10 Aug 2021 14:15:42 GMT</pubDate>
    </item>
    </channel>
</rss>