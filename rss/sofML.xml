<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 07 Oct 2024 12:33:51 GMT</lastBuildDate>
    <item>
      <title>尝试在 SageMaker 实例中下载数据时无法执行对 S3 的请求</title>
      <link>https://stackoverflow.com/questions/79061602/unable-to-execute-request-to-s3-while-trying-to-donwload-data-in-sagemaker-insta</link>
      <description><![CDATA[我正尝试在存储在 S3 存储桶中的数据集上专门训练一个模型 meta-textgeneration-llama-2-7b，但每次我尝试将数据集下载到 SageMaker 实例中时，我都会不断收到
UnexpectedStatusException：训练作业 meta-textgeneration-llama-2-7b-2024-10-07-09-50-08-039 的错误：失败。原因：ClientError：数据下载失败：无法下载数据。ListObjectsV2 对 s3://genaiwithawsproject2024/training-datasets/medical 失败，nextToken：[null]：无法执行对 S3 的请求。查看常见错误的故障排除指南：https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html

我不确定为什么这个问题一直出现。
我正在使用的代码
from sagemaker.jumpstart.estimator import JumpStartEstimator
import boto3

estimator = JumpStartEstimator(model_id=model_id, environment={&quot;accept_eula&quot;: &quot;true&quot;},instance_type = &quot;ml.g5.2xlarge&quot;) 

estimator.set_hyperparameters(instruction_tuned=&quot;False&quot;, epoch=&quot;5&quot;)

#使用您要从上面使用的数据集填写下面的代码
#示例： estimator.fit({&quot;training&quot;: f&quot;s3://genaiwithawsproject2024/training-datasets/finance&quot;})
estimator.fit({&quot;training&quot;: f&quot;s3://genaiwithawsproject2024/training-datasets/finance&quot;})

有解决方案吗？
到目前为止，我为解决这个问题所采取的步骤如下：

确保我使用的 IAM 角色具有执行此任务的正确权限。我确保我可以使用 !aws s3 ls s3://genaiwithawsproject2024/training-datasets/medical 在 Jupyter Notebook 中列出和移动 S3 存储桶中的文件，该操作有效。
更新了 sageMaker 数据集。
在 pytorch 和 tensorflow 之间切换，因为我发现 pytorch 有时在访问 S3 存储桶时会出现问题。
多次创建和销毁 SageMaker 实例和 IAM 角色，但都没有成功。
]]></description>
      <guid>https://stackoverflow.com/questions/79061602/unable-to-execute-request-to-s3-while-trying-to-donwload-data-in-sagemaker-insta</guid>
      <pubDate>Mon, 07 Oct 2024 10:35:34 GMT</pubDate>
    </item>
    <item>
      <title>验证多元线性回归模型的 AUC 计算</title>
      <link>https://stackoverflow.com/questions/79061528/validating-auc-calculation-for-a-multiple-linear-regression-model</link>
      <description><![CDATA[我正在尝试计算多元线性回归模型（两个变量）的 AUC 值，因此我正在处理以下代码并想与您确认。
我有两个变量，分别名为 Sa_T1 和 Sa_07，x 轴和 y 轴，z 轴上有 log_EDPs，我确实使用多元线性回归来确定以下关系：
log_EDPs = coef_log_Sa_T1 * log_Sa_T1 + coef_log_Sa_07 * log_Sa_07 + 截距
结果分别为以下值：0.3364、0.6530、-7.1452。现在我想计算 AUC，我根据我之前的单变量案例代码开发了以下代码：
# 系数
coef_log_Sa_T1 = 0.3364
coef_log_Sa_07 = 0.6530
intercept = -7.1452

# 使用回归模型预测的 log(edp)
predicted_log_edp = coef_log_Sa_T1 * log_Sa_T1 + coef_log_Sa_07 * log_Sa_07 + 截距

# 基于阈值的 log(edp)
threshold_SA = np.log(np.median(log_EDPs))
y_true = (log_EDPs &gt;= Threshold_SA).astype(int) 

y_pred_binary = (predicted_log_edp &gt;= Threshold_SA).astype(int)

y_pred_prob = (predicted_log_edp - predicted_log_edp.min()) / (predicted_log_edp.max() - predict_log_edp.min()) 

# 根据预测概率计算 AUC
auc_prob = roc_auc_score(y_true, y_pred_prob)
print(f&quot;AUC (probabilities): {auc_prob}&quot;)

结果 AUC 值为 0.9802。
代码是否进行了正确的计算？]]></description>
      <guid>https://stackoverflow.com/questions/79061528/validating-auc-calculation-for-a-multiple-linear-regression-model</guid>
      <pubDate>Mon, 07 Oct 2024 10:12:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 DDP 时，在多 GPU 上获得相同的损失，但梯度不同</title>
      <link>https://stackoverflow.com/questions/79061290/get-same-loss-but-different-grad-on-multi-gpus-when-using-ddp</link>
      <description><![CDATA[当将 torch.nn.parallel.DistributedDataParallel 添加到单 GPU 训练代码时，我遇到一个问题，即在不同的 GPU 上得到相同的损失但不同的梯度。与之前的单 GPU 训练代码相比，我确信损失是正确的，但在 loss.backward() 之后，我观察了各层的权重和偏差的梯度，发现在 all_gather 之前它们在不同的 GPU 上是不同的，在 all_gather 和计算损失之间的各层的梯度在不同的 GPU 上是相同的。

这是一个对比学习代码，所以我 all_gather 所有 GPU 上的张量来计算共同的最终损失。

以下是该模型的部分代码：
import torch.nn as nn
import torch
from config.base_config import Config
from modules.transformer import Transformer
from modules.stochastic_module import StochasticText
from modules.basic_utils import AllGather
allgather = AllGather.apply
from modules.tokenization_clip 导入 SimpleTokenizer

class CLIPStochastic(nn.Module):
def __init__(self, config: Config):
super(CLIPStochastic, self).__init__()
self.config = config

从 transformers 导入 CLIPModel
如果 config.clip_arch == &#39;ViT-B/32&#39;:
self.clip = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)
elif config.clip_arch == &#39;ViT-B/16&#39;:
self.clip = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch16&quot;)
else:
引发 ValueError

self.task_config = config
config.pooling_type = &#39;transformer&#39;
self.pool_frames = Transformer(config)
self.stochastic = StochasticText(config)

def forward(self, data, return_all_frames=False, is_train=True):
batch_size = data[&#39;video&#39;].shape[0]
text_data = data[&#39;text&#39;] # text_data[&quot;input_ids&quot;].shape = torch.Size([16, 17])
video_data = data[&#39;video&#39;] # [16, 12, 3, 224, 224]
video_data = video_data.reshape(-1, 3, self.config.input_res, self.config.input_res) # [192, 3, 224, 224]

if is_train:

text_features = self.clip.get_text_features(**text_data)
video_features = self.clip.get_image_features(video_data)

video_features = video_features.reshape(batch_size, self.config.num_frames, -1) # [bs, #F, 512]

text_features = allgather(text_features,self.task_config)
video_features = allgather(video_features,self.task_config)
torch.distributed.barrier()

video_features_pooled = self.pool_frames(text_features, video_features)

# @WJM：执行随机文本
text_features_stochstic, text_mean, log_var = self.stochastic(text_features, video_features)

if return_all_frames:
return text_features, video_features, video_features_pooled, text_features_stochstic, text_mean, log_var

return text_features, video_features_pooled, text_features_stochstic, text_mean, log_var

else:

text_features = self.clip.get_text_features(**text_data)
video_features = self.clip.get_image_features(video_data)

video_features = video_features.reshape(batch_size, self.config.num_frames, -1)
video_features_pooled = self.pool_frames(text_features, video_features)

# @WJM：文本的重新参数化（独立于文本条件池化）
text_features_stochstic, _, _ = self.stochastic(text_features, video_features)

if return_all_frames:
return text_features, video_features, video_features_pooled, text_features_stochstic

return text_features, video_features_pooled, text_features_stochstic


allgather 函数如下：
class AllGather(torch.autograd.Function):
&quot;&quot;&quot;对张量执行 allgather 的 autograd 函数。&quot;&quot;&quot;

@staticmethod
def forward(ctx, tensor, args):
output = [torch.empty_like(tensor) for _ in range(args.world_size)]
torch.distributed.all_gather(output, tensor)
ctx.rank = local_rank
ctx.batch_size = tensor.shape[0]
return torch.cat(output, dim=0)

@staticmethod
def behind(ctx, grad_output):
local_grad = grad_output[ctx.batch_size * ctx.rank : ctx.batch_size * (ctx.rank + 1)]
return local_grad, None

我尝试在 AllGather 类中向后添加 all_reduce，代码如下，但似乎不起作用，可能是因为 DDP 自带了同步梯度函数？
def behind(ctx, *grads):
all_gradients = torch.stack(grads)
torch.distributed.all_reduce(all_gradients)
return all_gradients[torch.distributed.get_rank()]
]]></description>
      <guid>https://stackoverflow.com/questions/79061290/get-same-loss-but-different-grad-on-multi-gpus-when-using-ddp</guid>
      <pubDate>Mon, 07 Oct 2024 09:03:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用销售数据（价格、SKU、UPC、单位、日期）来预测盈利产品？[关闭]</title>
      <link>https://stackoverflow.com/questions/79061087/how-can-i-use-my-sales-data-price-sku-upc-units-date-to-predict-profitable</link>
      <description><![CDATA[作为店主，我想使用销售数据来预测下个季度（3 个月）哪些商品的库存利润最高，这样我就可以优化库存并实现销售最大化。
验收标准：

我可以上传我的销售数据，包括：
每件商品的销售价格
SKU（库存单位）
UPC（通用产品代码）
产品名称
每件商品的销售单位（在 1 到 10 之间随机分配）
销售日期（在 1 月 1 日至 12 月 30 日之间随机分配）

如何构建模型？
我尝试使用逻辑回归，也使用了时间序列分析，但由于数据集很小，因此可视化效果不合适。我希望首先将数据集可视化并从中提取有意义的特征，然后进行可视化，之后我希望构建能够以最高准确度和更少错误预测销售量的模型。]]></description>
      <guid>https://stackoverflow.com/questions/79061087/how-can-i-use-my-sales-data-price-sku-upc-units-date-to-predict-profitable</guid>
      <pubDate>Mon, 07 Oct 2024 07:57:31 GMT</pubDate>
    </item>
    <item>
      <title>ConvLSTM 能否处理降雨事件和地形模型中的时空数据以进行洪水预测？[关闭]</title>
      <link>https://stackoverflow.com/questions/79061076/can-convlstm-handle-spatiotemporal-data-from-rainfall-events-and-terrain-models</link>
      <description><![CDATA[我正在开展一个洪水预测项目，我想使用 ConvLSTM 模型根据降雨事件作为输入来预测特定区域的径流和洪水深度。
为了准备数据，我使用了 QGIS 和 SWMM：
QGIS 用于创建研究区域的地形模型（海拔、坡度）。
SWMM 用于模拟各种降雨事件并计算每个路口的洪水值，计算不同情景下特定区域的径流和洪水深度值。
我打算使用这些数据训练 ConvLSTM 模型来预测每个路口的径流和周边地区的洪水深度。
通常，ConvLSTM 用于处理连续的 2D 图像数据，例如视频。但是，就我而言，我正在处理包括降雨事件（例如，随时间变化的降雨强度）和地形信息（例如，海拔、坡度）的时空数据。这些数据随时间变化而形成 2D 网格，但它并不代表实际的图像序列；相反，它代表降雨和地形数据。
我的问题是：

是否可以使用 TensorFlow 的 ConvLSTM 模型来处理 2D 网格数据（如降雨和地形信息）而不是图像序列？

如果可以，在 TensorFlow 中构建 ConvLSTM 模型以将时空网格数据作为输入来预测洪水深度和径流时，我应该考虑什么？


最初，我计划使用图像数据训练 ConvLSTM 模型。但是，这种方法需要通过 SWMM 和 QGIS 生成图像，因此很难根据实时降雨数据预测洪水。为了解决这个问题，我设计了上述方法，以便模型可以仅使用实时降雨数据工作。我想知道这种方法在理论上和实践上是否可行。]]></description>
      <guid>https://stackoverflow.com/questions/79061076/can-convlstm-handle-spatiotemporal-data-from-rainfall-events-and-terrain-models</guid>
      <pubDate>Mon, 07 Oct 2024 07:55:06 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 TensorFlow 训练中的这个问题？未知图像文件格式。需要 JPEG、PNG、GIF、BMP 之一</title>
      <link>https://stackoverflow.com/questions/79060211/how-do-i-fix-this-problem-with-my-tensorflow-training-unknown-image-file-format</link>
      <description><![CDATA[我正在构建一个 U-Net 模型来检测乳腺癌，我从这里获取了数据集：https://www.kaggle.com/datasets/aryashah2k/breast-ultrasound-images-dataset
尽管所有图像都是 png 格式，但在尝试训练我的模型时，会出现错误，指出我的图像格式不正确。
错误如下：
---------------------------------------------------------------------------
InvalidArgumentError Traceback（最近一次调用最后一次）
Cell In[51]，第 7 行
5 train_dataset = image_ds.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
6 print(image_ds.element_spec)
----&gt; 7 model_history = unet.fit(train_dataset, epochs=EPOCHS)

文件 ~\anaconda3\Lib\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
123 最后：
124 delfiltered_tb

文件 ~\anaconda3\Lib\site-packages\tensorflow\python\eager\execute.py:53，在 quick_execute(op_name, num_outputs, input, attrs, ctx, name) 中
51 尝试：
52 ctx.ensure_initialized()
---&gt; 53 张量 = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
54 输入、属性、输出)
55 除 core._NotOkStatusException 外，因为 e:
56 如果名称不为 None:

InvalidArgumentError：图形执行错误：

在节点处检测到，decode_image/DecodeImage 定义在（最近一次调用最后一次）：
&lt;堆栈跟踪不可用&gt;
传递给 MapDataset:3 转换的用户定义函数中的错误，迭代器：Iterator::Root::Prefetch::BatchV2::Shuffle::MemoryCacheImpl::Filter::ParallelMapV2：未知图像文件格式。需要 JPEG、PNG、GIF、BMP 之一。
[[{{node decrypt_image/DecodeImage}}]]
[[IteratorGetNext]] [Op:__inference_one_step_on_iterator_9520]

错误仅在尝试训练模型时发生，它引用此函数：
def preprocess_image(image, mask, target_size=(256, 256)):
try:
# 安全地解码图像和掩码
image = tf.io.decode_image(image, channels=3, expand_animations=False)
mask = tf.io.decode_image(mask, channels=1, expand_animations=False)

# 检查未定义或零维度
if image.shape is None or image.shape[0] == 0 or image.shape[1] == 0:
print(f&quot;Error: Image has undefined or zero Dimensions: {image.shape}&quot;)
return None, None

if mask.shape is None or mask.shape[0] == 0 or mask.shape[1] == 0:
print(f&quot;Error: Mask 具有未定义或零维度：{mask.shape}&quot;)
return None, None

# 确保图像恰好有 3 个通道 (RGB)
if image.shape[-1] != 3:
print(f&quot;Error: Image does not have 3 channels (found {image.shape[-1]}).&quot;)
return None, None

# 将图像标准化为范围 [0, 1]
image = tf.image.convert_image_dtype(image, tf.float32)

# 将图像和 mask 的大小调整为目标尺寸 (256*256)
image = tf.image.resize(image, target_size, method=&#39;nearest&#39;)
mask = tf.image.resize(mask, target_size, method=&#39;nearest&#39;)

#将 mask 转换为二进制（0 或 1）格式以用于分类任务
mask = tf.cast(tf.math.reduce_max(mask, axis=-1, keepdims=True) &gt; 0, tf.float32) # 确保二进制 mask

return image, mask

except Exception as e:
print(f&quot;Error during preprocessing: {str(e)}&quot;)
return None, None

# 将预处理函数应用于数据集
image_ds = dataset.map(preprocess_image)

# 过滤掉 preprocess_image 返回的 None 值
image_ds = image_ds.filter(lambda img, mask: img is not None and mask is not None)

我尝试了多种方法尝试使用 chatgpt 修复此问题，但似乎没有任何效果。]]></description>
      <guid>https://stackoverflow.com/questions/79060211/how-do-i-fix-this-problem-with-my-tensorflow-training-unknown-image-file-format</guid>
      <pubDate>Sun, 06 Oct 2024 22:45:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 Auto ARIMA 预测与具有明显趋势和季节性的实际需求数据不一致？</title>
      <link>https://stackoverflow.com/questions/79060171/why-is-my-auto-arima-forecast-showing-misalignment-with-actual-demand-data-with</link>
      <description><![CDATA[我正在使用 Auto ARIMA 模型来预测时间序列数据集的需求。查看结果后，我注意到预测值与实际需求数据不太吻合，尽管我绘制了残差并且它是随机的。
以下是模型拟合代码：
import pandas as pd
import matplotlib.pyplot as plt
from pmdarima import auto_arima
from sklearn.metrics import mean_squared_error
import numpy as np

# 假设您的 DataFrame 是“df”，其中包含“需求”列

df[&#39;demand&#39;] = df[&#39;demand&#39;].interpolate(method=&#39;linear&#39;) # 使用插值填充 NaN 值

# 设置频率（根据需要调整：“D”表示每日，“M”表示每月等）
df = df.asfreq(&#39;D&#39;)

# 将数据集拆分为训练集和测试集（80% 训练，20% 测试）
train_size = int(len(df) * 0.8)
train, test = df[:train_size], df[train_size:]

# 使用自动 ARIMA 找到最佳模型
model = auto_arima(train[&#39;demand&#39;], 
seasonal=True, # 如果存在季节性
m=12, # 设置为 7 表示每周季节性（如果是每日数据）
d=1, # 设置非季节性差异
D=1, # 设置季节性差异
trace=True, # 打印进度
suppress_warnings=True, 
stepwise=True) # 使用逐步搜索

# 打印最佳模型摘要
print(model.summary())

绘图代码：
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# 计算 RMSE
rmse = np.sqrt(mean_squared_error(test[&#39;demand&#39;], Forecast))

# 创建图
plt.figure(figsize=(10, 6))

# 绘制测试（实际）需求
plt.plot(test.index, test[&#39;demand&#39;], label=&#39;Actual Demand&#39;, color=&#39;blue&#39;)

# 绘制预测需求
plt.plot(forecast_index, Forecast, label=&#39;Forecasted Demand&#39;, color=&#39;red&#39;)

# 添加标签和标题
plt.title(&#39;Actual vs Forecasted Demand (Zoomed In)&#39;)
plt.xlabel(&#39;Date&#39;)
plt.ylabel(&#39;Demand&#39;)
plt.legend()

# 在图上显示 RMSE
plt.text(forecast_index[-1], test[&#39;demand&#39;].max(), f&#39;RMSE: {rmse:.2f}&#39;, fontsize=12, ha=&#39;right&#39;, color=&#39;black&#39;)

plt.show()

# 打印预测需求检查值
打印（预测）


结果图：
在此处输入图片描述
我尝试使用不同的值更改自动 ARIMA 中的 m 参数，但结果不错！]]></description>
      <guid>https://stackoverflow.com/questions/79060171/why-is-my-auto-arima-forecast-showing-misalignment-with-actual-demand-data-with</guid>
      <pubDate>Sun, 06 Oct 2024 22:15:09 GMT</pubDate>
    </item>
    <item>
      <title>是DataLoader的问题还是模型的问题？</title>
      <link>https://stackoverflow.com/questions/79059527/is-the-problem-with-the-dataloader-or-the-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79059527/is-the-problem-with-the-dataloader-or-the-model</guid>
      <pubDate>Sun, 06 Oct 2024 16:04:47 GMT</pubDate>
    </item>
    <item>
      <title>无法运行 Github 存储库 [关闭]</title>
      <link>https://stackoverflow.com/questions/79058738/not-able-to-run-github-repository</link>
      <description><![CDATA[我的项目是“社交媒体中的多模态命名实体识别”（尝试将其扩展为聊天机器人）
我正尝试使用这个 github 存储库作为基础
https://github.com/Multimodal-NER/RpBERT
尽管尝试了几次，我还是无法运行它。
有人可以帮我吗？你能告诉我如何实现它的步骤吗？
我已经将它克隆到我的系统中。我的系统中的 loader.py 文件出现错误，但不知何故修复了它。我运行了 main.py 文件。它似乎正在运行。但我仍然有几个疑问。我想知道如何从头开始实现它。]]></description>
      <guid>https://stackoverflow.com/questions/79058738/not-able-to-run-github-repository</guid>
      <pubDate>Sun, 06 Oct 2024 09:38:24 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Stanza 导出为 ONNX 格式？</title>
      <link>https://stackoverflow.com/questions/70205743/how-to-export-stanza-to-onnx-format</link>
      <description><![CDATA[如何将 Stanza 导出为 ONNX 格式？
似乎不可能只是简单地训练模型。]]></description>
      <guid>https://stackoverflow.com/questions/70205743/how-to-export-stanza-to-onnx-format</guid>
      <pubDate>Thu, 02 Dec 2021 19:59:27 GMT</pubDate>
    </item>
    <item>
      <title>如何建立随机森林和粒子群优化器的混合模型来寻找产品的最优折扣？</title>
      <link>https://stackoverflow.com/questions/63413064/how-to-build-hybrid-model-of-random-forest-and-particle-swarm-optimizer-to-find</link>
      <description><![CDATA[我需要找到每种产品（例如 A、B、C）的最佳折扣，以便最大化总销售额。我为每种产品都建立了随机森林模型，将折扣和季节与销售额进行映射。我如何组合这些模型并将它们提供给优化器以找到每个产品的最佳折扣？
选择模型的原因：

RF：它能够提供更好的（相对于线性模型）预测因子和响应（sales_uplift_norm）之间的关系。
PSO：在许多白皮书中都有建议（可在researchgate/IEEE 获得），也可以在此处和此处的python 包中找到。

输入数据：样本数据用于在产品级别构建模型。数据一览如下：

我的想法/步骤：

针对每个产品构建 RF 模型
 # 预处理数据
products_pre_processed_data = {key:pre_process_data(df, key) for key, df in df_basepack_dict.items()}
# rf 模型
products_rf_model = {key:rf_fit(df) for key, df in products_pre_processed_data .items()}




将模型传递给优化器

目标函数：最大化sales_uplift_norm（RF 模型的响应变量）
约束：

总支出（A + B + C 的支出&lt;= 20），支出 = 产品总销售量 * 折扣百分比 * 产品 mrp_of_products
产品下限（A、B、C）：[0.0, 0.0, 0.0] # 折扣百分比下限
产品上限（A、B、C）：[0.3, 0.4, 0.4] # 折扣百分比上限




sudo/sample code # 因为我无法找到将 product_models 传递到优化器。
from pyswarm import pso
def obj(x):
model1 = products_rf_model.get(&#39;A&#39;)
model2 = products_rf_model.get(&#39;B&#39;)
model3 = products_rf_model.get(&#39;C&#39;)
return -(model1 + model2 + model3) # -ve 符号表示最大化

def con(x):
x1 = x[0]
x2 = x[1]
x3 = x[2]
return np.sum(units_A*x*mrp_A + unit_B*x*mrp_B + unit_C* x *spend_C)-20 # 支出预算

lb = [0.0, 0.0, 0.0]
ub = [0.3, 0.4, 0.4]

xopt, fopt = pso(obj, lb, ub, f_ieqcons=con)

如何将 PSO 优化器（如果我没有遵循正确的优化器，可以使用任何其他优化器）与 RF 一起使用？
添加用于模型的函数：
def pre_process_data(df,product):
data = df.copy().reset_index()
# print(data)
bp = product
print(&quot;-------product: {}-------&quot;.format(bp))
# 预处理步骤
print(&quot;pre process df.shape {}&quot;.format(df.shape))
#1. 响应变量转换
response = data.sales_uplift_norm # 已转换

#2.预测器数值变量转换 
numeric_vars = [&#39;discount_percentage&#39;] # 可能包括 mrp、深度
df_numeric = data[numeric_vars]
df_norm = df_numeric.apply(lambda x: scale(x), axis = 0) # 中心和尺度

#3. char 字段 dummification
#选择类别字段
cat_cols = data.select_dtypes(&#39;category&#39;).columns
#选择字符串字段
str_to_cat_cols = data.drop([&#39;product&#39;], axis = 1).select_dtypes(&#39;object&#39;).astype(&#39;category&#39;).columns
# 合并所有分类字段
all_cat_cols = [*cat_cols,*str_to_cat_cols]
# print(all_cat_cols)

#将 cat 转换为 dummies
df_dummies = pd.get_dummies(data[all_cat_cols])

#4.将 num 和 char df 组合在一起
df_combined = pd.concat([df_dummies.reset_index(drop=True), df_norm.reset_index(drop=True)], axis=1)

df_combined[&#39;sales_uplift_norm&#39;] = response
df_processed = df_combined.copy()
print(&quot;post process df.shape {}&quot;.format(df_processed.shape))
# print(&quot;model fields: {}&quot;.format(df_processed.columns))
return(df_processed)

def rf_fit(df, random_state = 12):

train_features = df.drop(&#39;sales_uplift_norm&#39;, axis = 1)
train_labels = df[&#39;sales_uplift_norm&#39;]

#随机森林回归器
rf = RandomForestRegressor(n_estimators = 500,
random_state = random_state,
bootstrap = True,
oob_score=True)
# RF 模型
rf_fit = rf.fit(train_features, train_labels)

return(rf_fit)
]]></description>
      <guid>https://stackoverflow.com/questions/63413064/how-to-build-hybrid-model-of-random-forest-and-particle-swarm-optimizer-to-find</guid>
      <pubDate>Fri, 14 Aug 2020 12:47:25 GMT</pubDate>
    </item>
    <item>
      <title>我的目标变量在时间上分布不均匀</title>
      <link>https://stackoverflow.com/questions/59667381/my-target-variable-is-not-evenly-distributed-in-time</link>
      <description><![CDATA[我尝试使用机器学习来预测哪些客户会购买特定产品（购买产品是我的目标变量）。我拥有大量有关客户的特征和足够的历史数据。
我的问题是，我的目标变量具有很强的季节性——大多数产品在 12 月售出，其他月份的销量很少。
我必须做什么来弥补这种不平衡？目标变量是否需要进行一些调整？我需要模型在所有月份都具有一致的性能。]]></description>
      <guid>https://stackoverflow.com/questions/59667381/my-target-variable-is-not-evenly-distributed-in-time</guid>
      <pubDate>Thu, 09 Jan 2020 15:34:43 GMT</pubDate>
    </item>
    <item>
      <title>是否可以将单一回归技术应用于具有不同模式的数据？</title>
      <link>https://stackoverflow.com/questions/52666845/is-it-possible-to-apply-a-single-regression-technique-to-data-that-has-different</link>
      <description><![CDATA[我想根据温度估算多种不同产品的销售量，有些产品之间存在关系。对于其中一种产品，销售额和温度之间的关系绘制出来后如下所示：

这只是一种产品，但这里有一个总体趋势，即从 10 度之后销售额会增加。对于其他产品，关系可能更线性，其他产品可能有多项式关系，而其他产品可能根本没有关系。另一个产品的例子是，其销量和温度之间没有相关性，可能是这个产品：

首先，我想从一个产品中预测一些东西，所以我使用了第一个图中的产品来尝试建模。我最终将数据拆分，这样我就得到了一个数据框，其中包含从 -5 度到 10 度的所有值，并执行了线性回归，类似地，我将 10 度拆分到 30 度以执行线性回归，如下所示：

这里的一个问题是，我正在做各种各样的事情来将我的数据仅适合一种产品。我有一个包含 1000 种产品的数据集，我希望能够根据温度估算某些产品的销量。我想以某种方式循环遍历我的所有数据集，找出哪些数据集在销售和温度之间有某种关系，然后自动应用该特定产品的最佳回归模型，在给定某个温度 X 的情况下估算该产品的销售量。
我看过很多不同的神经网络回归教程，但我根本不知道如何开始或搜索什么，或者我尝试做的事情是否可行？]]></description>
      <guid>https://stackoverflow.com/questions/52666845/is-it-possible-to-apply-a-single-regression-technique-to-data-that-has-different</guid>
      <pubDate>Fri, 05 Oct 2018 13:34:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 sklearn LogisticRegression 和 RandomForest 模型的 Predict() 总是预测少数类 (1)</title>
      <link>https://stackoverflow.com/questions/51968669/predict-with-sklearn-logisticregression-and-randomforest-models-always-predict</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/51968669/predict-with-sklearn-logisticregression-and-randomforest-models-always-predict</guid>
      <pubDate>Wed, 22 Aug 2018 14:03:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 sklearn 的 RandomForestRegressor 进行预测</title>
      <link>https://stackoverflow.com/questions/46694664/prediction-using-sklearns-randomforestregressor</link>
      <description><![CDATA[我的数据如下...
date,locale,category,site,alexa_rank,sessions,user_logins
20170110,US,1,google,1,500,5000
20170110,EU,1,google,2,400,2000
20170111,US,2,facebook,2,400,2000

... 等等。这只是我想出的一个玩具数据集，但与原始数据相似。
我正在尝试使用 sklearn 的 RandomForestRegressor 构建一个模型来预测特定网站将有多少用户登录和会话。
我做了一些常规工作，将类别编码为标签，并根据今年前八个月的数据训练了我的模型，现在我想预测第九个月的登录和会话。我创建了一个针对登录进行训练的模型，以及另一个针对会话进行训练的模型。
我的测试数据集具有相同的形式：
date,locale,category,site,alexa_rank,sessions,user_logins
20170910,US,1,google,1,500,5000
20170910,EU,1,google,2,400,2000
20170911,US,2,facebook,2,400,2000

理想情况下，我希望传入测试数据集时不包含我需要预测的列，但 RandomForestRegressor 抱怨训练集和测试集之间的维度不同。
当我以当前形式传入测试数据集时，模型会预测 sessions 中的 精确 值，并且在大多数情况下，user_logins 列为零，否则值会有微小变化。
我将测试数据中的 sessions 和 user_logins 列归零，并将其传递给模型，但模型预测几乎全部为零。

我的工作流程正确吗？我是否正确使用了 RandomForestRegressor？
当我的测试数据集确实包含实际值时，我如何如此接近实际值？测试数据中的实际值是否用于预测？
如果模型正常工作，如果我将要预测的列（sessions 和 user_logins）归零，我不应该得到相同的预测值吗？
]]></description>
      <guid>https://stackoverflow.com/questions/46694664/prediction-using-sklearns-randomforestregressor</guid>
      <pubDate>Wed, 11 Oct 2017 17:55:37 GMT</pubDate>
    </item>
    </channel>
</rss>