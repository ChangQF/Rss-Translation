<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Sep 2024 09:17:48 GMT</lastBuildDate>
    <item>
      <title>RubixML 模型在 PHP 中总是返回相同的预测</title>
      <link>https://stackoverflow.com/questions/79035928/rubixml-model-always-return-the-same-prediction-in-php</link>
      <description><![CDATA[我尝试使用 https://rubixml.com/ 提取不同句子的产品价格，但它总是返回 260，这是我给它的第一个标签
&lt;?php
include_once &#39;../vendor/autoload.php&#39;;

use Rubix\ML\Datasets\Labeled;
use Rubix\ML\Datasets\Unlabeled;
use Rubix\ML\Classifiers\KNearestNeighbors;
use Rubix\ML\Transformers\WordCountVectorizer;
use Rubix\ML\Transformers\TfIdfTransformer;
use Rubix\ML\Pipeline;
use Rubix\ML\Extractors\CSV;

$samples= [&#39;价格是 260&#39;,&#39;成本是 500&#39;,&#39;这件衬衫的成本是 300&#39;,&#39;这件商品的价值是 450&#39;,&#39;售价 150 美元&#39;];
$labels = [&#39;260&#39;, &#39;500&#39;, &#39;300&#39;, &#39;450&#39;, &#39;150&#39;];

$dataset = new Labeled($samples, $labels);

// 生成模型
$pipeline = new Pipeline([
new WordCountVectorizer(100),
new TfIdfTransformer(),
], new KNearestNeighbors(3));

// 使用数据集进行训练
$pipeline-&gt;train($dataset);

// 分析新的 frace
$new = Unlabeled::build([
[&#39;价格：1200&#39;],
]);

// 预测
$predictions = $pipeline-&gt;predict($new);
var_dump($predictions);

我更改了 KNearestNeighbors 的值，为训练数据集提供了更大的输入，更改了 Vectorizer。但什么都没有改变。]]></description>
      <guid>https://stackoverflow.com/questions/79035928/rubixml-model-always-return-the-same-prediction-in-php</guid>
      <pubDate>Sun, 29 Sep 2024 08:25:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 和 scikit-image 在 xray 图像上分割肺部对象时出现问题</title>
      <link>https://stackoverflow.com/questions/79035911/problem-when-segmenting-lung-objects-on-xray-images-using-python-and-scikit-ima</link>
      <description><![CDATA[如何分割肺部切片？我尝试过几次，但效果并不完美。这是因为肺部前部的骨头部分。
肺部图像
我尝试模糊图像以使骨头更透明，但它影响了物体的周围环境。]]></description>
      <guid>https://stackoverflow.com/questions/79035911/problem-when-segmenting-lung-objects-on-xray-images-using-python-and-scikit-ima</guid>
      <pubDate>Sun, 29 Sep 2024 08:16:12 GMT</pubDate>
    </item>
    <item>
      <title>如何针对每个数据集的每次训练迭代训练 LSTM 自动编码器</title>
      <link>https://stackoverflow.com/questions/79035730/how-can-i-train-an-lstm-autoencoder-for-each-iteration-of-training-with-each-dat</link>
      <description><![CDATA[描述
我一直在尝试构建和训练 LSTM 自动编码器。虽然我使用的参考仅训练了一次模型，但我添加了一个函数，如果每个数据集的每次训练迭代都结束，则多次运行训练。
不过，我并不确定我是否走在正确的轨道上。感觉我的代码在每次迭代时都有可能覆盖训练好的模型。
问题
所以我想问一下下面的 Python 代码是否真的在用每个数据集对每个迭代进行训练（有 75 个 CSV 文件可用于训练此模型）。
以下是我在单个函数（trainModel()）内添加的用于构建和训练模型的 Python 代码
from sklearn.preprocessing import StandardScaler 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed
from tensorflow.keras.callbacks import EarlyStopping

# LSTM 网络以输入形状相等间隔的子序列的形式获取输入（n_sample、n_timesteps、features）。
# 我们将使用以下自定义函数来创建这些序列
def create_sequences(X, y, time_steps=1):
Xs, ys = [], []
for i in range(len(X) - time_steps):
v = X.iloc[i:(i + time_steps)].values
Xs.append(v)
ys.append(y.iloc[i + time_steps])
return np.array(Xs), np.array(ys)

def trainModel():
for i in range(75):
fileList = pd.read_csv(&quot;/content/drive/MyDrive/fileList.csv&quot;)
filename = fileList.iloc[i, 0]
temp = pd.read_csv(&quot;/content/drive/MyDrive/dataFolder/&quot;+filename+&quot;.csv&quot;)
train_size = int(len(temp[[&quot;time_abs(%Y-%m-%dT%H:%M:%S.%f)&quot;, &quot;velocity(m/s)&quot;]]))
train = df.iloc[0:train_size]

# 规范化数据
scalar = StandardScaler()
scalar = scalar.fit(train[[&#39;velocity(m/s)&#39;]])

train[&#39;velocity(m/s)&#39;] = scalar.transform(train[[&#39;velocity(m/s)&#39;]])

time_steps = 30

X_train, y_train = create_sequences(train[[&#39;velocity(m/s)&#39;]],train[&#39;velocity(m/s)&#39;],time_steps)

# 构建 LSTM 自动编码器

# 自动编码器是一种神经网络模型旨在学习输入的压缩表示。
# 它们使用监督学习方法进行训练，称为自监督。
# 在这种架构中，编码器 LSTM 模型逐步读取输入序列。
# 读取整个输入序列后，此模型的隐藏状态或输出表示
# 整个输入序列的内部学习表示为固定长度向量。
# 然后将此向量作为输入提供给解码器模型，解码器模型将其解释为输出序列中的每个步骤
# 生成。
# timesteps = X_train.shape[1]
num_features = X_train.shape[2]

model = Sequential()
model.add(LSTM(128,input_shape=(timesteps,num_features)))
model.add(Dropout(0.2))
model.add(RepeatVector(timesteps)) # 重复输入 n 次。
model.add(LSTM(128,return_sequences=True))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(num_features))) # 将层应用于输入的每个时间片段。

model.compile(loss=&#39;mae&#39;,optimizer=&#39;adam&#39;)

# 训练自动编码器
early_stop = EarlyStopping(monitor=&#39;val_loss&#39;,patience=3,mode=&#39;min&#39;) # 如果监控指标相对于应用的 3 个时期的模式没有变化，则停止训练
history = model.fit(X_train,y_train,epochs=100,batch_size=32,validation_split=0.1,callbacks=[early_stop],shuffle=False)

model.save(&#39;anomaly_model.h5&#39;, overwrite=False)
model.save(&#39;anomaly_model_&#39;+ i +&#39;.h5&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/79035730/how-can-i-train-an-lstm-autoencoder-for-each-iteration-of-training-with-each-dat</guid>
      <pubDate>Sun, 29 Sep 2024 06:28:59 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型中的自定义编码器和解码器层显示为未构建</title>
      <link>https://stackoverflow.com/questions/79034907/custom-encoder-and-decoder-layers-within-keras-model-show-as-unbuilt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79034907/custom-encoder-and-decoder-layers-within-keras-model-show-as-unbuilt</guid>
      <pubDate>Sat, 28 Sep 2024 18:27:22 GMT</pubDate>
    </item>
    <item>
      <title>变压器数据集</title>
      <link>https://stackoverflow.com/questions/79034901/dataset-for-transformer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79034901/dataset-for-transformer</guid>
      <pubDate>Sat, 28 Sep 2024 18:25:45 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 torchmeta 冲突</title>
      <link>https://stackoverflow.com/questions/79034188/how-to-fix-torchmeta-conflicts</link>
      <description><![CDATA[我正在尝试在 google colab 中使用 !pip install torchmeta 命令安装 torchmeta。但显示以下错误：
错误：无法安装 torchmeta==1.1.0、torchmeta==1.1.1、torchmeta==1.2.0、torchmeta==1.2.1、torchmeta==1.2.2、torchmeta==1.3.0、torchmeta==1.3.1、torchmeta==1.3.2、torchmeta==1.3.3、torchmeta==1.3.4、torchmeta==1.4.0、torchmeta==1.4.1、torchmeta==1.4.2、torchmeta==1.4.3、torchmeta==1.4.4、torchmeta==1.4.5、torchmeta==1.4.6， torchmeta==1.5.0、torchmeta==1.5.1、torchmeta==1.5.2、torchmeta==1.5.3、torchmeta==1.6.0、torchmeta==1.6.1、torchmeta==1.7.0 和 torchmeta==1.8.0，因为这些软件包版本存在依赖冲突。

冲突的原因是：
torchmeta 1.8.0 依赖于 torch&lt;1.10.0 和 &gt;=1.4.0
torchmeta 1.7.0 依赖于 torch&lt;1.9.0 和 &gt;=1.4.0
torchmeta 1.6.1 依赖于 torch&lt;1.8.0 和 &gt;=1.4.0
要解决此问题，您可以尝试：
1. 放宽您指定的软件包版本范围
2. 删除软件包版本以允许 pip 尝试解决依赖项冲突

如何解决此问题？我也尝试安装较低版本的 pytorch，但我不能，有什么方法可以安装 torchmeta。我使用的是 windows (google colab) Pytorch-geometric 2.3.1]]></description>
      <guid>https://stackoverflow.com/questions/79034188/how-to-fix-torchmeta-conflicts</guid>
      <pubDate>Sat, 28 Sep 2024 12:32:30 GMT</pubDate>
    </item>
    <item>
      <title>安装 CausalML 时遇到问题</title>
      <link>https://stackoverflow.com/questions/79033786/trouble-installing-causalml</link>
      <description><![CDATA[我尝试使用 Python 3.12 在我的 Windows 机器上安装 causalml，命令为 pip install causalml。
但在尝试为 causalml 构建 wheel 时安装失败。以下是错误片段：
注意：此错误源自子进程，可能不是 pip 的问题。
错误：无法为 causalml 构建 wheel
无法构建 causalml
错误：错误：无法为某些基于 pyproject.toml 的项目 (causalml) 构建可安装的 wheel

我已将错误附加到 pastebin 上：
https://pastebin.com/dehRfgrk
但关键错误消息是：
&#39;use_tracing&#39;：不是 causalml/inference/tree/_tree/_tree.cpp 中 &#39;_PyCFrame&#39; 的成员。
命令“cl.exe”失败，退出代码为 2。
关于弃用的 NumPy API 和 Python 2.7 选项使用的警告（bdist_wheel.universal 已弃用）。
Setuptools 警告包配置中缺少包（causalml.inference.tree 等）

我正在使用：
Python 版本：3.12。
操作系统：Windows 10。
编译器：Microsoft Visual Studio 2022 构建工具。
环境：Anaconda 3。
NumPy 版本：1.26.4。
我尝试更新 Visual Studio 构建工具并安装了最新版本并确保包含 C++ 构建工具。]]></description>
      <guid>https://stackoverflow.com/questions/79033786/trouble-installing-causalml</guid>
      <pubDate>Sat, 28 Sep 2024 08:47:08 GMT</pubDate>
    </item>
    <item>
      <title>当步长为小数时，会向下舍入吗？</title>
      <link>https://stackoverflow.com/questions/79033026/do-steps-round-down-when-its-fractional</link>
      <description><![CDATA[我开始尝试训练机器学习模型，并对训练过程中的时期和步骤概念感到困惑。在网上搜索时，我偶然发现了一个与时期、步骤和批次大小相关的公式 (𝜎 = (𝜀 × 𝜂) ÷ 𝛽)。将此公式应用于我自己的数据集会得到小数个步骤，这让我对实际中通常如何处理步骤产生了疑问。我不确定小数步骤是否向下舍入，或者这如何准确地转化为实际的训练过程。我缺乏实施训练循环的实践经验，因此很难直观地掌握这些概念如何映射到现实世界的模型训练场景。
为了更好地理解 epoch、steps 和 batch size 之间的关系，我尝试将我找到的公式 (𝜎 = (𝜀 × 𝜂) ÷ 𝛽) 应用于数据集（这只是一个理论示例数据集）：
total_samples = 10000 # 我的数据集中的样本总数
batch_size = 32 # 我计划使用的 batch size
epochs = 10 # 我想要训练的 epoch 数量

steps_per_epoch = total_samples / batch_size
total_steps = (epochs * total_samples) / batch_size

print(f&quot;Steps per epoch: {steps_per_epoch}&quot;)
print(f&quot;Total步骤：{total_steps}&quot;)

这产生了以下输出：
每轮步骤：312.5
总步骤：3125.0

每轮步骤的分数结果（312.5）让我不确定这将如何在实际训练循环中实现。具体来说：

在实践中，分数步骤通常会向下舍入吗？
如果发生舍入，这是否意味着每个时期可能会跳过一些数据样本？
常见的机器学习框架如何处理这种情况？

我还没有真正实现训练循环，所以我不确定这些分数步骤将如何在代码中处理。我的主要困难是弥合理论计算与其在模型训练中的实际应用之间的差距。]]></description>
      <guid>https://stackoverflow.com/questions/79033026/do-steps-round-down-when-its-fractional</guid>
      <pubDate>Fri, 27 Sep 2024 22:03:59 GMT</pubDate>
    </item>
    <item>
      <title>Keras 未显示正确的 f1_score</title>
      <link>https://stackoverflow.com/questions/79032877/keras-not-showing-the-correct-f1-score</link>
      <description><![CDATA[我使用来自 Kaggle 的以下数据集 卫星图像中的船舶
我使用的代码是：
import os
import cv2
import numpy as np
from keras.applications import ResNet50
from tensorflow.keras.layers import Input, Dense, Flatten
from tensorflow.keras.models import Model

IMG_PATH = &quot;/kaggle/input/ships-in-satellite-imagery/shipsnet/shipsnet&quot;
IMG_WIDTH = 80
IMG_HEIGHT = 80
CHANNELS = 3

X_train = []
y_train = []
y_train_bbox = []
对于 os.listdir(IMG_PATH)[:3000] 中的文件：
img_annotations = os.path.splitext(file)[0].split(&#39;_&#39;)
label = int(img_annotations[0])
longitude = float(img_annotations[-2])
latitude = float(img_annotations[-1])
img = cv2.imread(os.path.join(IMG_PATH, file))
X_train.append(img)
y_train.append(label)
y_train_bbox.append(np.array([longitude, latitude]))
X_train = np.array(X_train)
y_train = np.array(y_train).reshape(-1,1)
y_train_bbox = np.array(y_train_bbox)

X_train = []
y_train = []
y_train_bbox = []
对于 os.listdir(IMG_PATH)[:3000] 中的文件：
img_annotations = os.path.splitext(file)[0].split(&#39;_&#39;)
label = int(img_annotations[0])
longitude = float(img_annotations[-2])
latitude = float(img_annotations[-1])
img = cv2.imread(os.path.join(IMG_PATH, file))
X_train.append(img)
y_train.append(label)
y_train_bbox.append(np.array([经度，纬度]))
X_train = np.array(X_train)
y_train = np.array(y_train).reshape(-1,1)
y_train_bbox = np.array(y_train_bbox)

base_model = ResNet50(input_tensor=Input(shape=(80, 80, 3)), include_top=False)

head_model = base_model.output
head_model = Flatten()(head_model)
head_model = Dense(128, &#39;relu&#39;)(head_model)
head_model = Dense(64, &#39;relu&#39;)(head_model)
head_model = Dense(32, &#39;relu&#39;)(head_model)
head_model = Dense(16, &#39;relu&#39;)(head_model)
head_model = Dense(8, &#39;relu&#39;)(head_model)
head_model = Dense(1, &#39;sigmoid&#39;)(head_model)

model = Model(inputs=base_model.input, output=head_model)
for layer in base_model.layers:
layer.trainable = False

model.compile(loss=&quot;binary_crossentropy&quot;, metrics=[
&quot;precision&quot;, &quot;recall&quot;, &quot;f1_score&quot;, &quot;true_positives&quot;, &quot;false_positives&quot;, &quot;true_negatives&quot;, &quot;false_negatives&quot;
])

model.fit(X_train, y_train, batch_size=len(X_train), epochs=3)

拟合结果如下：
Epoch 1/3
1/1 ━━━━━━━━━━━━━━━━━━━━━━━ 41s 41s/step - f1_score: 0.4017 - false_negatives: 197.0000 - false_positives: 1913.0000 - loss: 0.7405 - precision: 0.2255 - recall: 0.7387 - true_negatives: 333.0000 - true_positives: 557.0000
时代 2/3
1/1 ━━━━━━━━━━━━━━━━━━━━━━ 31s 31s/step - f1_score：0.4017 - 假阴性：195.0000 - 假阳性：42.0000 - 损失：0.2302 - 精度：0.9301 - 召回率：0.7414 - 真阴性：2204.0000 - 真阳性：559.0000
时代 3/3
1/1 ━━━━━━━━━━━━━━━━━━━━━ 41s 41s/step - f1_score: 0.4017 - false_negatives: 0.0000e+00 - false_positives: 1424.0000 - loss: 1.2052 - precision: 0.3462 - recall: 1.0000 - true_negatives: 822.0000 - true_positives: 754.0000

为什么尽管 precision 和 recall 是正确的，但 f1_score 是错误的？

我知道 Keras 在训练期间根据批次大小对结果进行平均，但是这里的批次大小是相同的作为训练数据集的长度。
]]></description>
      <guid>https://stackoverflow.com/questions/79032877/keras-not-showing-the-correct-f1-score</guid>
      <pubDate>Fri, 27 Sep 2024 20:54:31 GMT</pubDate>
    </item>
    <item>
      <title>尝试保存自定义 Keras 模型时出现“TypeError：不支持的整数大小 (0)”</title>
      <link>https://stackoverflow.com/questions/79032646/typeerror-unsupported-integer-size-0-when-attempted-to-save-custom-keras-mo</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79032646/typeerror-unsupported-integer-size-0-when-attempted-to-save-custom-keras-mo</guid>
      <pubDate>Fri, 27 Sep 2024 19:14:51 GMT</pubDate>
    </item>
    <item>
      <title>加载变压器时出现问题；ModuleNotFoundError：没有名为“transformers”的模块</title>
      <link>https://stackoverflow.com/questions/79031959/problem-loading-transformers-modulenotfounderror-no-module-named-transformers</link>
      <description><![CDATA[我想使用 huggingface 提供的一些模型。我甚至在开始的时候都遇到了最大的困难。有人能帮我识别和解决这个问题吗？
我正在使用 Kubuntu 24.04。

首先，我创建并激活一个虚拟环境，在其中安装变压器。
python3 -m venv .env
source .env/bin/activate

这是成功的，因为现在我在 Visual Code Studio 中的终端有前缀“(.env)”。
接下来，我从 github 安装最新的变压器：
pip install git+https://github.com/huggingface/transformers

输出成功。然后，我使用 hugginface.co 上推荐的方法测试其成功率：
python3 -c &quot;from transformers import pipeline; print(pipeline(&#39;sentiment-analysis&#39;)(&#39;I love you&#39;))&quot;

输出对我来说看起来正确：
未提供模型，默认为 distilbert/distilbert-base-uncased-finetuned-sst-2-english 和修订版本 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)。
不建议在生产中使用未指定模型名称和修订版本的管道。
硬件加速器（例如 GPU）在环境中可用，但没有将“设备”参数传递给“管道”对象。模型将在 CPU 上。
[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9998656511306763}]

从那里，我尝试运行以下代码：
from transformers import pipeline

但每次我都会得到以下输出：
/bin/python3 /path-to/main.py
回溯（最近一次调用最后一次）：
文件&quot;/path-to/main.py&quot;，第 5 行，在&lt;module&gt;
from transformers import pipeline
ModuleNotFoundError：没有名为“transformers”的模块
]]></description>
      <guid>https://stackoverflow.com/questions/79031959/problem-loading-transformers-modulenotfounderror-no-module-named-transformers</guid>
      <pubDate>Fri, 27 Sep 2024 15:09:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中训练眼睛验证（而非识别）模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/79019854/how-to-train-an-eye-verification-not-recognition-model-in-pytorch</link>
      <description><![CDATA[我想知道我们如何训练一对一图像验证模型。模型拍摄两张图像并验证它们是否相同。我想要训练眼睛认证模型的软件算法。
我在网上搜索过，但只能找到关于识别软件算法（一对多）的答案。
如何在 PyTorch 代码中训练验证模型？
需要澄清的是，相同是指眼睛相同，即它们属于同一个人。这是一个验证模型。]]></description>
      <guid>https://stackoverflow.com/questions/79019854/how-to-train-an-eye-verification-not-recognition-model-in-pytorch</guid>
      <pubDate>Tue, 24 Sep 2024 18:10:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 进行迁移学习进行图像分类</title>
      <link>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</link>
      <description><![CDATA[我正在尝试使用已经训练过的模型将学习转移到我将要创建的模型中，并且只修改最后几层。这样做的目的是使用已经训练过的模型（已经在数百万张图像上训练过）来帮助我的模型对食物项目识别进行分类。我对 Keras 还很陌生，我遇到了一个问题，我现在开始理解它，但不知道如何解决
# 从 TensorFlow Hub 加载模型
model_url = &quot;https://www.kaggle.com/models/tensorflow/resnet-50/TensorFlow2/classification/1&quot;
hub_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3))

# 创建 Sequential 模型
model = tf.keras.Sequential()

# 将 TensorFlow Hub 层添加到 Sequential 模型
model.add(hub_layer)

# 构建 Sequential 模型
model.build((None, 224, 224, 3))

# 模型摘要
model.summary()

错误：
-------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
Cell In[56]，第 9 行
6 model = tf.keras.Sequential()
8 # 将 TensorFlow Hub 层添加到 Sequential 模型
----&gt; 9 model.add(hub_layer)
11 # 构建 Sequential 模型
12 model.build((None, 224, 224, 3))

文件 c:\Users\Karim\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\sequential.py:95，位于 Sequential.add(self, layer, rebuild)
93 layer = origin_layer
94 if not isinstance(layer, Layer):
---&gt; 95 raise ValueError(
96 &quot;只有 `keras.Layer` 的实例可以 &quot;
97 f&quot;添加到 Sequential 模型中。收到：{layer} &quot;
98 f&quot;（类型为 {type(layer)}）&quot;
99 )
100 if not self._is_layer_name_unique(layer):
101 raise ValueError(
102 &quot;添加到 Sequential 模型的所有层 &quot;
103 f&quot;应具有唯一名称。名称 &#39;{layer.name}&#39; 已经是 &quot;
104 &quot;此模型中层的名称。更新 `name` 参数 &quot;
105 &quot;以传递唯一名称。&quot;
106 )

ValueError：只有 `keras.Layer` 的实例可以添加到 Sequential 模型中。已收到：&lt;tensorflow_hub.keras_layer.KerasLayer 对象位于 0x00000190C6B8AD20&gt;（类型为 &lt;class &#39;tensorflow_hub.keras_layer.KerasLayer&#39;&gt;）
]]></description>
      <guid>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</guid>
      <pubDate>Mon, 29 Apr 2024 09:15:19 GMT</pubDate>
    </item>
    <item>
      <title>模块“keras.layers”没有属性“experimental”</title>
      <link>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</link>
      <description><![CDATA[你好，我试图调整数据集的大小和比例，如下所示，但遇到了此错误：
AttributeError：模块“keras.layers”没有属性“experimental”

resize_and_rescale= tf.keras.Sequential([
layers.experimental.preprocessing.Resizing(IMAGE_SIZE,IMAGE_SIZE),
layers.experimental.preprocessing.Rescaling(1.0/255)
])

]]></description>
      <guid>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</guid>
      <pubDate>Wed, 14 Dec 2022 00:43:49 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 高斯过程回归器中的优化器调整</title>
      <link>https://stackoverflow.com/questions/44932469/optimizer-tuning-in-sklearn-gaussian-process-regressor</link>
      <description><![CDATA[我尝试使用 GaussianProcessRegressor 作为 scikit-learn 0.18.1 的一部分
我正在对 200 个数据点进行训练，并使用 13 个输入特征作为我的内核 - 一个常数乘以一个具有十二个元素的径向基函数。该模型运行没有问题，但如果我多次运行相同的脚本，我会注意到我有时会得到不同的解决方案。值得注意的是，几个优化参数都超出了我提供的界限（我目前正在研究哪些特性很重要）。
我尝试将参数 n_restarts_optimizer 增加到 50，虽然这需要更长的时间来运行，但它并没有消除明显的随机性因素。似乎可以更改优化器本身，尽管我没有运气。从快速扫描来看，语法上最相似的似乎是 Scipy 的 fmin_tnc 和 fmin_slsqp（其他优化器不包括界限）。但是，使用其中任何一个都会导致其他问题：例如，fmin_tnc 不会返回目标函数的最小值。
关于如何获得更具确定性的脚本有什么建议吗？理想情况下，我希望它无论迭代次数如何都打印相同的值，因为就目前情况而言，这有点像彩票（因此得出任何结论都是值得怀疑的）。
我正在使用的代码片段：
来自 sklearn.gaussian_process 导入 GaussianProcessRegressor 作为 GPR
来自 sklearn.gaussian_process.kernels 导入 RBF，ConstantKernel 作为 C

lbound = 1e-2
rbound = 1e1
n_restarts = 50
n_features = 12 # 实际上在代码的其他地方确定
kernel = C(1.0, (lbound,rbound)) * RBF(n_features*[10], (lbound,rbound))
gp = GPR(kernel=kernel, n_restarts_optimizer=n_restarts)
gp.fit(train_input, train_outputs)
test_model, sigma2_pred = gp.predict(test_input, return_std=True)
print gp.kernel_
]]></description>
      <guid>https://stackoverflow.com/questions/44932469/optimizer-tuning-in-sklearn-gaussian-process-regressor</guid>
      <pubDate>Wed, 05 Jul 2017 17:23:06 GMT</pubDate>
    </item>
    </channel>
</rss>