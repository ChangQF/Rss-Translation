<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 May 2024 18:20:20 GMT</lastBuildDate>
    <item>
      <title>fastapi 机器学习脚本中的结果为空</title>
      <link>https://stackoverflow.com/questions/78556222/null-results-in-a-fastapi-machine-learning-script</link>
      <description><![CDATA[我正在开发一个 fastAPI 简单机器学习脚本。我已经成功训练了管道，它按预期工作。但现在我正尝试使用 fastAPI 和 uvicorn 来部署它。我不知道为什么它总是返回一个空值作为结果。这是一个二元分类。一些数据输入，1 或 0 应该输出。现在我这样做了：
从 pydantic 导入 BaseModel
从 fastapi 导入 FastAPI
导入 pandas 作为 pd
导入 joblib
导入 uvicorn
# 实例
app = FastAPI()
# 数据模型
类 DataModel(BaseModel):
id: str
radius_mean: float
...
# 除必须预测的目标变量之外的所有其他特征

类 ItemOut(BaseModel):
id: str
诊断: int

def load_weights():
模型 = joblib.load(&quot;models/RF/RF_weights_v1.0.pkl&quot;)
返回模型

def predict(data):
模型 = load_weights()
预处理 = model.named_steps[&quot;preprocessing&quot;]
transformed_data = preprocessing.transform(data)
分类器 = model.named_steps[&quot;classifier&quot;]
预测值 = classifier.predict(transformed_data)
return predict_values

@app.post(&quot;/predict&quot;, response_model=ItemOut)
async def predict(dataModel: DataModel):
data = pd.DataFrame([dataModel.dict()])
predictions = predict(data)
return {&quot;id&quot;: &quot;id&quot;, &quot;diagnosis&quot;: predictions}

if __name__ == &quot;__main__&quot;:
uvicorn.run(app, host=&quot;0.0.0.1&quot;, port=8000)

现在，我不知道模型的权重是否正确加载。最重要的是，预测的结果应该是 1 维数组（在这种情况下只有一个值），根据分类结果为 0 或 1。
但返回的却是空值。
我使用的模型是“SVC”（我用随机森林做了第二个模型，没什么特别的）。
我做错了什么？
同样，我不知道这是否是最好的方法，或者例如，最佳实践应该是加载包含这些值的 json 或加载包含多个值的 json 文件。
你能帮助我吗？非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/78556222/null-results-in-a-fastapi-machine-learning-script</guid>
      <pubDate>Thu, 30 May 2024 16:27:16 GMT</pubDate>
    </item>
    <item>
      <title>具有不平衡类别的 U-Net 分割的图像块提取</title>
      <link>https://stackoverflow.com/questions/78555784/image-patch-extraction-for-u-net-segmentation-with-imbalanced-classes</link>
      <description><![CDATA[我目前正在使用 U-Net 进行学生多类图像分割项目。
我的数据集的类别分布不平衡。有些类别几乎出现在每幅图像中，而其他类别则很少见。我不确定图像修补的最佳方法：
在每个补丁内做出相等的类别表示？在这种情况下，对于某些类别，我将不得不使用数据增强技术。
还是保持补丁内原始的不平衡比例？
我很感激任何见解或建议]]></description>
      <guid>https://stackoverflow.com/questions/78555784/image-patch-extraction-for-u-net-segmentation-with-imbalanced-classes</guid>
      <pubDate>Thu, 30 May 2024 14:57:49 GMT</pubDate>
    </item>
    <item>
      <title>平衡的 KNN 分类器，用于不平衡的二元响应</title>
      <link>https://stackoverflow.com/questions/78555660/balanced-knn-classifier-for-imbalance-binary-response</link>
      <description><![CDATA[我想建立平衡 k-NN 分类器关于平衡风险的一致性。
设 ( \hat{I}(x) ) 为一组指标 ( i )，使得 ( X_i \in B(x; \hat{\xi}_x) )。回归函数 ( \hat{\eta}(x) ) 的估计定义为：
\hat{\eta}(x) = \frac{1}{k} \sum_{i \in \hat{I}(x)} \mathbf{1}_{Y_i = 1
在标准最近邻分类中，使用 ( \hat{\eta}(x) ) 后的多数投票进行预测。具体来说，只要 ( \hat{\eta}(x) \geq \frac{1}{2} )，就会预测为类别 1。
我正在寻找有关如何理解和可能通过替换 ( \hat{\eta}(x) \geq \hat{p}) 来实现平衡 k-NN 方法的见解。其中 \hat{p} 是训练集中少数类的概率。如有任何指导或说明，我们将不胜感激。
library(class)
library(dplyr)
set.seed(123)
n &lt;- 1000
p &lt;- 0.05 # 正例比例
X &lt;- matrix(rnorm(n * 2), ncol = 2)
Y &lt;- ifelse(runif(n) &lt; p, 1, 0)

# 将数据拆分为训练集和测试集
set.seed(123)
train_index &lt;- sample(1:n, 0.7 * n)
train_data &lt;- data.frame(X = X[train_index, ], Y = Y[train_index])
test_data &lt;- data.frame(X = X[-train_index, ], Y = Y[-train_index])
# 计算训练集中正例的比例数据
#p_hat &lt;- mean(train_data$Y)

train_X &lt;- train_data %&gt;% select(-Y) %&gt;% as.matrix()
train_Y &lt;- train_data$Y
test_X &lt;- test_data %&gt;% select(-Y) %&gt;% as.matrix()
train_X &lt;- train_data %&gt;% select(-Y) %&gt;% as.matrix()

# 使用 k-NN 分类器
knn_result &lt;- knn(train = train_X, test = test_X, cl = train_Y, k = k, prob = TRUE)


如何使用上述方法或以下第 3.2 节“不平衡分类的尖锐误差界限：少数类中有多少个示例？”将标准 kNN 更改为平衡 kNN哪篇论文专门讨论了这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78555660/balanced-knn-classifier-for-imbalance-binary-response</guid>
      <pubDate>Thu, 30 May 2024 14:34:16 GMT</pubDate>
    </item>
    <item>
      <title>多视图谱聚类</title>
      <link>https://stackoverflow.com/questions/78555303/multiview-spectral-clustering</link>
      <description><![CDATA[我一直在致力于实现多视图谱聚类，最初我用一个视图实现了谱聚类，效果很好，现在有了多个视图，我在初始化 a(v) 时遇到了问题，a(v) 是反映第 v 个视图的贡献/重要性的变量，为具有相似值的视图初始化 a(v) 不会有帮助，可能有视图包含有关数据点的更好信息，那么这通常是如何完成的？
我尝试了一个循环来收敛 a(v) 的值（现在假设在第 100 次迭代时收敛），这是我从 chatgpt 获得的，但我不明白它是如何工作的，它没有给出任何有意义的结果：
for i in range(100):
L_combinee_vue = np.power(a1,r)*L_vue1 + np.power(a2,r)*L_vue2 + np.power(a3,r)*L_vue3 + np.power(a4,r)*L_vue4
eigvals, eigvecs = np.linalg.eigh(L_combinee_vue)
f = eigvecs[:, -3:] 
a1 = 1 / np.trace(np.dot(f.T, np.dot(L_vue1, f))) # 搜索 
a2 = 1 / np.trace(np.dot(f.T, np.dot(L_vue2, f)))
a3 = 1 / np.trace(np.dot(f.T, np.dot(L_vue3, f)))
a4 = 1 / np.trace(np.dot(f.T, np.dot(L_vue4, f)))

fnormalized = normalize(f)
km = KMeans(n_clusters=5, random_state=random_state)
clustered_data = km.fit_predict(fnormalized)
]]></description>
      <guid>https://stackoverflow.com/questions/78555303/multiview-spectral-clustering</guid>
      <pubDate>Thu, 30 May 2024 13:31:28 GMT</pubDate>
    </item>
    <item>
      <title>有没有什么方法可以提高vit的性能？</title>
      <link>https://stackoverflow.com/questions/78555148/is-there-method-to-enhance-the-performance-of-vit</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78555148/is-there-method-to-enhance-the-performance-of-vit</guid>
      <pubDate>Thu, 30 May 2024 13:02:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Spring Boot AI App 中处理 HTTP 429？</title>
      <link>https://stackoverflow.com/questions/78554966/how-to-handle-http-429-in-spring-boot-ai-app</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78554966/how-to-handle-http-429-in-spring-boot-ai-app</guid>
      <pubDate>Thu, 30 May 2024 12:30:31 GMT</pubDate>
    </item>
    <item>
      <title>如何将多个观测值拟合到单个高斯过程</title>
      <link>https://stackoverflow.com/questions/78554891/how-to-fit-a-multiple-observations-to-single-gaussian-process</link>
      <description><![CDATA[我试图将多个观测值拟合到单个高斯过程。
我尝试像这样拟合两个观测值 (Y) 的数据：
import numpy as np
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

# 示例数据

# 输入数据 X 
X = np.array([[1.0], [2.0], [3.0], [4.0], [5.0]])

# 输出数据 Y 
Y = np.array([[1.5, 2.5], [2.5, 3.5], [3.5, 4.5], [4.5, 5.5], [5.5, 6.5]])
kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)

# 拟合模型
gp.fit(X, Y)

mean_prediction, cov_prediction = gp.predict(X, return_cov=True)

我得到了两个 mean_prediction 数组和两个 cov_prediction 矩阵。但我想要一个与单个拟合 GP 对应的观测值相同维度的单个均值和协方差矩阵。我该如何实现？]]></description>
      <guid>https://stackoverflow.com/questions/78554891/how-to-fit-a-multiple-observations-to-single-gaussian-process</guid>
      <pubDate>Thu, 30 May 2024 12:16:10 GMT</pubDate>
    </item>
    <item>
      <title>如何正确计算图像和文本嵌入之间的余弦相似度以检索结果</title>
      <link>https://stackoverflow.com/questions/78554528/how-to-correctly-compute-cosine-similarity-between-image-and-text-embeddings-for</link>
      <description><![CDATA[我在图像-文本对上训练了一个对比学习模型，现在我想根据图像检索最相似的文本。为此，我使用预训练的图像和文本编码器生成测试图像（嵌入）和测试文本（嵌入）。
然后我想测量每个文本和所有图像嵌入之间的余弦相似度，如下所示
images = (i1, i2, i3) text = (t1,t2, t3)

余弦相似度 = [(t1,i1),(t1, i2), (t1, i3)], [(t2, i1), (t2, i2), (t2, i3)], [(t3, i1), (t3, i2), (t3, i3)]

使用此代码
 image_embeddings = [loaded_global_vision_encoder(image) for image in test_images]

# 生成查找嵌入
finding_embeddings = [loaded_finding_encoder(tf.convert_to_tensor([finding])) for finding in test_findings]

# 计算图像和查找嵌入之间的余弦相似度

cosine_similarities = []
for finding_emb in finding_embeddings:
similarities = [tf.keras.losses.cosine_similarity(finding_emb, image_emb, axis=-1) for image_emb in image_embeddings]
cosine_similarities.append(similarities)


然后我找到具有高相似度得分的前 1 对，如下所示
image_embeddings = [
[0.1, 0.2, 0.3],
[0.4, 0.5, 0.6],
]

finding_embeddings = [
[0.3, 0.4, 0.5],
[0.6, 0.7, 0.8]
]

对于第一个发现的嵌入 [0.3, 0.4, 0.5]:
余弦相似度:

对于 [0.1, 0.2, 0.3]: 0.9746

对于 [0.4, 0.5, 0.6]: 0.9873


对于第二个发现的嵌入 [0.6, 0.7, 0.8]:
余弦相似度:

对于 [0.1, 0.2, 0.3]: 0.8847

对于 [0.4, 0.5, 0.6]: 0.9603


步骤 2：找到前 k 个最相似的图像索引
假设 k = 2
对于第一个发现嵌入 [0.3, 0.4, 0.5]：

前 2 个最相似的图像索引：[3, 1]

对于第二个发现嵌入 [0.6, 0.7, 0.8]：

前 2 个最相似的图像索引：[2, 4]
results = [
[3, 1],
[2, 4],
]


使用此代码
 k = 1
results = [tf.math.top_k(similarities, k).indices.numpy() for余弦相似性]

所以现在我完全不知道这个检索部分，我非常困惑。我这样做代码
predicted_reports = [[test_findings[int(idx)] for idx in indices] for indices in results]

我认为它是这样工作的
test_findings = [
&quot;无急性心肺过程。&quot;,
&quot;心脏大小正常。无局灶性气腔疾病或积液。&quot;,
&quot;肺容量低。无急性发现。&quot;,
&quot;肺部清晰。无胸腔积液或气胸。&quot;,
&quot;胸椎退行性变化。&quot;
]

results = [
[3, 1],
[2, 4],
[0, 3]
]

predict_reports = [
[
&quot;肺部清晰。无胸腔积液或气胸。&quot;,
&quot;心脏大小正常。无局灶性气腔疾病或积液。&quot;
],
[
&quot;肺容量低。无急性发现。&quot;,
&quot;胸椎退行性变化。&quot;
],
[
&quot;无急性心肺过程。&quot;,
&quot;肺部清晰。无胸腔积液或气胸。&quot;
]
]

如果它按照我解释的方式工作，那么我会很高兴，因为我对使用这种检索方式的结果并不满意，但是我很想知道我对这个代码的概念是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/78554528/how-to-correctly-compute-cosine-similarity-between-image-and-text-embeddings-for</guid>
      <pubDate>Thu, 30 May 2024 10:57:43 GMT</pubDate>
    </item>
    <item>
      <title>Android 上的随机森林[关闭]</title>
      <link>https://stackoverflow.com/questions/78554436/random-forest-on-android</link>
      <description><![CDATA[如何使用 CSV 数据在 Android 上使用机器学习随机森林。数据以表格形式呈现，时间段为 2023 年至 2017 年，每年从第 1 个月到第 12 个月。
给我一个教程。
完美完成，没有错误。]]></description>
      <guid>https://stackoverflow.com/questions/78554436/random-forest-on-android</guid>
      <pubDate>Thu, 30 May 2024 10:37:30 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 KNN 中的列？</title>
      <link>https://stackoverflow.com/questions/78554214/how-to-deal-with-columns-in-knn</link>
      <description><![CDATA[目前，我正在学习 ML，从 K 邻居分类开始，我想知道如何处理给我的所有参数（列）。我只有 1 个包含 10k 行的数据集，我将其拆分为 80/20。我在另一个 csv 中也有测试数据（没有 y）。
但困扰我的是，我在学习时只能获得约 78% 的准确率，我想知道如何才能提高我的结果。查看列时，我对这些列特别有一些疑问：
第一个数据集包含 2 个不同的组，而测试数据包含均匀分布的点
与第一张图片相反的情况
与其他列相同
有些奇怪
我应该删除它们吗，还是应该尝试对它们做些什么以在我的训练中使用它们数据？
此外，目前，我不明白为什么我的模型使用 metric=&#39;manhattan&#39; 而不是 euclidean 效果更好，以及如何使用测试/训练数据选择最佳 K。我读到你应该使用 sqrt(N)，其中 N 是测试行数，但事实真的如此吗？
训练/测试数据]]></description>
      <guid>https://stackoverflow.com/questions/78554214/how-to-deal-with-columns-in-knn</guid>
      <pubDate>Thu, 30 May 2024 09:51:40 GMT</pubDate>
    </item>
    <item>
      <title>我正在加载鸢尾花数据集，但出现错误，提示不允许使用重复的名称，我甚至尝试更改名称，但又出现另一个错误</title>
      <link>https://stackoverflow.com/questions/78554157/i-was-loading-the-iris-dataset-but-there-is-an-error-where-it-says-duplicate-na</link>
      <description><![CDATA[url= &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/iris.data&quot;
names = [&#39;sepal-length&#39;,&#39;sepal-width&#39;,&#39;petal-length&#39;,&#39;petal-width&#39;,&#39;petal-width&#39;,&#39;class&#39;] 
dataset = pandas.read_csv(url, names = names)


ValueError: 不允许重复的名称。

我原本期待这个输出，但却出现了错误]]></description>
      <guid>https://stackoverflow.com/questions/78554157/i-was-loading-the-iris-dataset-but-there-is-an-error-where-it-says-duplicate-na</guid>
      <pubDate>Thu, 30 May 2024 09:42:33 GMT</pubDate>
    </item>
    <item>
      <title>特征提取 + 逻辑回归 与 特征提取 + softmax 密集层的区别</title>
      <link>https://stackoverflow.com/questions/78553888/differences-on-features-extraction-logistic-regression-vs-features-extraction</link>
      <description><![CDATA[我有一个用于分类问题的小型图像数据库，因此我选择迁移学习方法。我从 Tensorflow 中的经典方法开始：

在 ImageNet 数据库上预训练的 ResNet50
GlobalMaxPooling2D 层
具有 softmax 激活函数的类数的密集层
使用 Adam 编译器、交叉熵损失和准确率作为指标进行编译。

然后我需要优化超参数，例如批量大小和时期。
一段代码是
将 tensorflow 导入为 tf
数据 = 加载并预处理您的数据
输入 = tf.keras.Input(shape=(None, None, 3))
x= base_resnet(x)
输出 = tf.keras.layers.GlobalMaxPooling2D()(x)
extractor = tf.keras.Model(inputs, output)
x = tf.keras.layers.Dense(nClasses)(x)
outputs = tf.keras.layers.Activation(activation=&quot;softmax&quot;, dtype = &#39;float32&#39;)(x)
model = tf.keras.Model(inputs, output)
model.compile(optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;], loss = &quot;categorical_crossentropy&quot;)

超参数优化之后我会做的
model.fit(...)
model.evaluate(...)

也许是哥伦布蛋，但我已经尝试了提取特征方法加上逻辑回归scikit-learn。
代码片段如下：
from sklearn.linear_model import LogisticRegression

x= base_resnet(x)
outputs = tf.keras.layers.GlobalMaxPooling2D()(x)
extractor = tf.keras.Model(inputs, output)
features = extractor.predict(data) # features extractor

# logistic 回归
log_reg = LogisticRegression(max_iter=500)
log_reg.fit(features, y)

log_reg.predict(features_test)

我在这两种方法中都获得了几乎相同的良好性能（测试集上的准确率接近 91%），但第二种方法快了 10 倍。我遗漏了什么吗？我的方法正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/78553888/differences-on-features-extraction-logistic-regression-vs-features-extraction</guid>
      <pubDate>Thu, 30 May 2024 08:47:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SHAP 值来分组特征重要性？</title>
      <link>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-grouped-feature-importance</link>
      <description><![CDATA[我做什么：
我借助不同的机器学习算法和不同的预处理步骤等分析来自 EEG 数据的不同生物标志物。这为每种预处理步骤和算法的组合产生了多个模型。
每个模型都使用 StratifiedGroupKFold 进行训练，总共 6 个折叠。
每个折叠都保存为作业库，即 .joblib
生物标志物：
EEG 信号的每个波段都有许多生物标志物。这些生物标志物又由来自 EEG 所有电极的所有信号组成。因此，生物标志物由多个特征组成，这些特征不能分开（每个生物标志物必须包含所有电极数据）。
我想做什么：
在我的第一种方法中，我用所有生物标志物训练了每个模型。现在我想使用特征重要性来确定是否可以省略其中一些。
为此，我想研究每个预处理步骤和每个模型。
有人向我推荐 SHAP，但我的问题是我不知道如何总结每个生物标志物的通道。
编辑：
在这篇论文的帮助下，我终于总结了折叠。但我仍然不明白如何总结每个生物标志物的通道。
新代码：
for r, fold_file in enumerate(fold_files):
model = joblib.load(fold_file)

fold_splits = list(sgkf.split(X, y, groups))

for train_index, test_index in fold_splits:
X_train, X_test = X.iloc[train_index], X.iloc[test_index]
y_train, y_test = y.iloc[train_index], y.iloc[test_index]

explainer = shap.Explainer(model, X_train)
train_shap_values = explainer(X_train)
test_shap_values = explainer(X_test)

for i in range(len(train_index)):
train_folds_shap_values[train_index[i]] += train_shap_values.values[i] / (len(fold_splits) - 1)
for i in range(len(test_index)):
test_folds_shap_values[test_index[i]] += test_shap_values.values[i]

average_train_folds_shap_values = train_folds_shap_values / R
average_test_folds_shap_values = test_folds_shap_values / R

train_shap_df = pd.DataFrame(average_train_folds_shap_values, columns=columns)
test_shap_df = pd.DataFrame(average_test_folds_shap_values, columns=columns)


我第一次尝试它就像这个：
grouped_features = group_features(columns, biomarker_names, bands)

defaggregate_shap_values(shap_df, grouped_features):
aggregated_shap_values = pd.DataFrame()
for group, features in grouped_features.items():
aggregated_shap_values[group] = shap_df[features].sum(axis=1)
returnaggregated_shap_values

train_aggregated_shap_df =aggregate_shap_values(train_shap_df, grouped_features)

test_aggregated_shap_df =aggregate_shap_values(test_shap_df, grouped_features)

shap.summary_plot(train_aggregated_shap_df.values, feature_names=train_aggregated_shap_df.columns.tolist())

但它看起来……不对。我忽略了重要性之间的区别。
分组：

未分组：

提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-grouped-feature-importance</guid>
      <pubDate>Wed, 29 May 2024 06:28:02 GMT</pubDate>
    </item>
    <item>
      <title>A3C 代理（连续动作空间）没有得到适当的训练，只能达到</title>
      <link>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</guid>
      <pubDate>Sat, 25 May 2024 05:21:08 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv8：如何在测试集上计算映射</title>
      <link>https://stackoverflow.com/questions/78073911/yolov8-how-to-calculate-map-on-test-set</link>
      <description><![CDATA[假设我有一个名为“test”的文件夹，里面有“images”和“labels”文件夹。我还有一个经过训练的 YOLOv8 模型，名为“best.pt”。我的标签是多边形（yolo-obb .txt 文件）。
我想找到我的 YOLOv8 模型在此测试集上的平均精度 (MAP)。
我已经阅读了预测和基准测试的文档，但是，我很难找到从一些测试图像计算地图的示例。
https://docs.ultralytics.com/modes/predict/
https://docs.ultralytics.com/modes/benchmark/
from ultralytics import YOLO

# 加载预训练YOLOv8n 模型
model = YOLO(&#39;best.pt&#39;)

# 对图像运行推理
results = model([&#39;test/images/bus.jpg&#39;, &#39;test/images/zidane.jpg&#39;]) # 2 个 Results 对象的列表

我想我必须将图像列表放在上面，然后编写代码来计算测试文件夹中所有内容的映射并取平均值。有没有已经完成此操作的软件包？
实现此任务的代码是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78073911/yolov8-how-to-calculate-map-on-test-set</guid>
      <pubDate>Wed, 28 Feb 2024 11:05:52 GMT</pubDate>
    </item>
    </channel>
</rss>