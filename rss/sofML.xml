<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 05 May 2024 21:12:17 GMT</lastBuildDate>
    <item>
      <title>如何在多个 GPU 上进行训练？</title>
      <link>https://stackoverflow.com/questions/78433502/how-do-i-train-on-multiple-gpus</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78433502/how-do-i-train-on-multiple-gpus</guid>
      <pubDate>Sun, 05 May 2024 19:27:19 GMT</pubDate>
    </item>
    <item>
      <title>向 Python Streamlit 饮食推荐应用程序添加饮食偏好按钮</title>
      <link>https://stackoverflow.com/questions/78433479/adding-dietary-preference-button-to-python-streamlit-diet-recommendation-app</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78433479/adding-dietary-preference-button-to-python-streamlit-diet-recommendation-app</guid>
      <pubDate>Sun, 05 May 2024 19:19:19 GMT</pubDate>
    </item>
    <item>
      <title>将 PyG 数据对象列表转换为 PyG 数据集？</title>
      <link>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</link>
      <description><![CDATA[我有一个 torch_geometric.data.Data 对象的 python 列表（每个对象代表一个图形）。我没有简单的方法来访问这些数据的原始文件：我只有列表。我需要将此数据对象列表转换为 torch_geometric.data.InMemoryDataset 或 torch_geometric.data.Dataset 对象，以便将其与我没有编写的更大的代码库集成。我该怎么做？
需要明确的是，我知道可以使用一系列数据对象来创建 torch_geometric.data.DataLoader 对象。但是，我特别需要一个 Dataset 对象，而不是 DataLoader 对象，因为较大的代码库在将 Dataset 对象转换为加载器之前会对它们执行一些额外的处理步骤。
我不明白为什么 PyG 让这变得如此困难。难道没有一种非常简单的方法可以做到这一点吗？
我尝试使用一个简单的 CustomDataset 类
类 CustomDataset(InMemoryDataset):
    def __init__(自身，数据)：
        超级().__init__()
        self.data = 数据
    
    def __len__(自身):
        返回 len(self.data)
    
    def __getitem__(self, idx):
        样本 = self.data[idx]
        返回样品

当我尝试获取索引 0 处的 Data 对象时，它给了我一个 KeyIndex 错误。我还尝试了上述代码的一个版本，其中超类是 Dataset 而不是 InMemoryDataset，但我不知道如何制作整理方法有效。]]></description>
      <guid>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</guid>
      <pubDate>Sun, 05 May 2024 18:30:03 GMT</pubDate>
    </item>
    <item>
      <title>Python 项目中“tokenizer”的 ModuleNotFoundError</title>
      <link>https://stackoverflow.com/questions/78433151/modulenotfounderror-for-tokenizer-in-python-project</link>
      <description><![CDATA[回溯（最近一次调用）：
  文件“/usr/ML/image-captioning-oscar-main/oscar/run_captioning.py”，来自 oscar.utils.caption_evaluate import (evaluate_on_coco_caption,
  文件“/usr/ML/image-captioning-oscar-main/oscar/utils/caption_evaluate.py”，来自 coco_caption.pycocoevalcap.eval 的行导入 COCOEvalCap
  文件“/usr/ML/image-captioning-oscar-main/oscar/coco_caption/pycocoevalcap/tokenizer/ptbtokenizer.py”，行 from tokenizer.ptbtokenizer import PTBTokenizer
ModuleNotFoundError：没有名为“tokenizer”的模块

我已经提供了我的项目的目录结构以获取更多上下文。以下是相关目录的外观：
usr/
└── ML/
    └── 图像字幕-oscar-main/
        └── 奥斯卡/
            ├── 数据集/
            │ ├── __init__.py
            │ ├── build.py
            │ └── 标题_tsv.py
            ├── 造型/
            │ ├── __init__.py
            │ ├── 建模_bert.py
            │ └── modeling_utils.py
            ├── 实用工具/
            │ ├── __init__.py
            │ ├── infer_on_single.py
            │ └── run_captioning.py
            └── 脚本/
                ├── 自述文件.md
                └── 需求.txt

此目录结构中似乎不存在 run_captioning.py 脚本所需的 tokenizer 模块。这可能是该模块位于其他地方的问题，还是我应该单独安装该模块？
请验证 tokenizer 是否应该是另一个已安装软件包的一部分，或者是否应该包含在您的项目目录中。如果它应该是您项目的一部分，请确保该目录存在于 Python 期望的位置，并且它包含在您的项目文件中。如果 tokenizer 是第三方库，请确保它已正确安装在您的 Python 环境中。如果缺少，您可能需要通过 pip 或 conda 安装它，或者确保您的环境具有正确的路径设置。
我尝试过的：

检查了目录结构：我验证了项目的目录结构包含 tokenizer 模块，并且包含一个可被识别为 Python 包的 __init__.py 文件。
检查 Python 路径：我将包含 tokenizer 模块的目录添加到 Python 路径中，以确保 Python 可以检测到它。
已验证导入：我确保项目其他部分中的导入语句正常工作，这表明问题可能与分词器模块的导入方式或其位置有关。

我所期待的：
我希望 Python 能够毫无问题地从 tokenizer.ptbtokenizer 模块中查找并导入 PTBTokenizer 类。该脚本应该能够使用此模块来标记字符串，作为图像字幕过程的一部分。相反，我遇到了 ModuleNotFoundError，这表明 Python 无法找到 tokenizer 模块，即使它似乎正确放置在项目的目录结构中并且正确构建为包.]]></description>
      <guid>https://stackoverflow.com/questions/78433151/modulenotfounderror-for-tokenizer-in-python-project</guid>
      <pubDate>Sun, 05 May 2024 17:27:06 GMT</pubDate>
    </item>
    <item>
      <title>由于图像容器问题，无法启动 sagemaker 训练作业</title>
      <link>https://stackoverflow.com/questions/78433082/unable-to-launch-sagemaker-training-job-due-to-issues-with-image-container</link>
      <description><![CDATA[我正在尝试从 sagemaker studio 代码编辑器实例中启动 sagemaker 培训作业。我有一个自定义的 docker 映像，其中包含一个requirements.txt 文件，其中包含一系列要安装的 python 库。此过程利用了 sagemaker 培训工具包，不幸的是，该库集合依赖于 python 3.10 及更高版本中已弃用的模块（请参阅此 github 开放问题 了解更多）。因此，我决定使用 python 3.9 运行我的容器，但这现在导致了与工具包的 sagemaker-containers 库相关的一系列问题。当尝试启动训练作业时，我收到此错误：
ImportError：无法从“jinja2”导入名称“escape”（/usr/local/lib/python3.9/site-packages/jinja2/__init__.py）

一些研究告诉我，jinja2 中的 escape 模块在较新版本的库中已被弃用，jinja2 是  的依赖项&gt;flask 和 flask 是 sagemaker-containers 的依赖项。 解决方案是将flask添加到需求文件并将其版本日期指定为更高版本，但是问题是 sagemaker-containers 依赖于旧版本的 Flask==1.1.1（请参阅以下）。我尝试过不指定 sagemaker-containers 的版本，我尝试过将其设置为旧版本，我尝试过更新 flask 和各种版本。我似乎找不到可以运行的组合。我还可能会补充一点，我不清楚为什么当我通过 sagemaker-training 安装了训练工具包时需要安装 sagemaker-container （但没有出现另一个错误）这是通过在其他地方讨论安装它来解决的）。
94.67 冲突的原因是：
94.67 用户请求 Flask==2.0.3
94.67 sagemaker-containers 2.8.6.post2 依赖于flask==1.1.1

Python 脚本启动作业：
导入 sagemaker
从 sagemaker.estimator 导入估算器

角色 = &#39;aws 角色&#39;
s3_bucket = &#39;s3-bucket-name&#39;
实例类型 = &#39;&#39;
类别 = &#39;视频游戏&#39;
输出路径 = f&#39;s3://{s3_bucket}/classification/{category}/output&#39;
图像_uri = &#39;我的图像_uri&#39;
source_dir = &#39;/home/sagemaker-user/data-analytics/data_science/classifcation/pipeline/auxilary/source_code/&#39;

估计器 = 估计器(image_uri=image_uri,
                      角色=角色，
                      实例计数=1，
                      实例类型=实例类型，
                      输出路径=输出路径，
                      Entry_point=&#39;train.py&#39;,
                      源目录=源目录）

estimator.set_hyperparameters(类别=类别,
                              s3_bucket=s3_bucket,
                              target_column=&#39;注释&#39;,
                              测试大小=0.2）

估计器.fit()

Dockerfile
# 使用 python 图像作为基础
来自Python：3.9

# 设置环境变量
ENV Python不写入字节码1
ENV Python 无缓冲 1

# 安装系统依赖
运行 apt-get update \
    &amp;&amp; apt-get install -y --no-install-recommends \
        libpq-dev \
        海湾合作委员会\
    &amp;&amp; rm -rf /var/lib/apt/lists/*

# 在容器中设置工作目录
工作目录/代码

# 安装Python依赖项
复制requirements.txt /代码/
运行 pip install --no-cache-dir --exists-action i -rrequirements.txt

# 复制其余的应用程序代码
复制 。 /代码/

requirements.txt 文件
Flask==2.0.3
简单变压器==0.70.0
熊猫==2.1.1
numpy==1.26.0
火炬==2.2.1
sklearn-deap==0.3.0
sklearn-遗传-opt==0.10.1
贤者==2.215.0
Sagemaker-培训==4.7.4
boto3==1.33.3
Sagemaker-容器
]]></description>
      <guid>https://stackoverflow.com/questions/78433082/unable-to-launch-sagemaker-training-job-due-to-issues-with-image-container</guid>
      <pubDate>Sun, 05 May 2024 17:07:35 GMT</pubDate>
    </item>
    <item>
      <title>如何在自定义估计器上使用 GridSearchCV？</title>
      <link>https://stackoverflow.com/questions/78433029/how-to-use-gridsearchcv-on-a-customized-estimator</link>
      <description><![CDATA[我使用 sklearn BaseEstimator 和 ClassifierMixin 构建了一个自定义 Estimator。但当涉及到交叉验证时，GridSearchCV 给我的分数是 nan 值。
这是估计器的代码：
class RegressionClassifier(ClassifierMixin, BaseEstimator):
    def __init__(self, 回归器=RidgeCV(cv=10, fit_intercept=True), alpha=0, n_components=1):
        self.alpha = alpha
        self.n_组件 = n_组件
        self.regressor = 回归器
        自估计器=无

    def fit(自身, X, y):
        管道=管道（步骤=[
            (&#39;估算&#39;，SimpleImputer(missing_values=np.nan，策略=“中位数”))，
            （&#39;缩放&#39;，StandardScaler（）），
            (&#39;减少&#39;, PCA(self.n_components)),
            (&#39;回归&#39;, self.regressor)
        ]）
        self.estimator = pipeline.fit(X, y)
        返回自我
        
    def 预测（自身，X）：
        预测 = self.estimator.predict(X)
        转换器 = [
        预测&lt; -自我阿尔法，
        (-self.alpha &lt;= 预测) &amp; （预测&lt; self.alpha），
        预测 &gt;= self.alpha
         ]
        类 = [2, 0, 0]
        Predicted_class = np.select（转换器，类）
        返回预测类

    def 分数(自身, X, y):
        y_true = train_new_y[y.index]
        返回准确度分数（y_true，y_true）


这应该返回 1 作为分数，因为我计算了相同预测的准确性。
估算器的工作原理如下：

管道（进行线性回归）-&gt;输出（回归结果向量）

转换器（获取管道结果）-&gt;输出（对回归结果进行一些神奇操作的类）

分数应该采用生成的类以及这些类和目标向量之间的输出准确性


网格搜索结果：
对 100 名候选者每人拟合 5 次，总共 500 次拟合
[CV 1/5] END ........alpha=0.0, n_components=50.0;, 分数=nan 总时间= 0.2s
[CV 2/5] END ........alpha=0.0, n_components=50.0;, 分数=nan 总时间= 0.1s
[CV 3/5] END ........alpha=0.0, n_components=50.0;, 分数=nan 总时间= 0.2s
]]></description>
      <guid>https://stackoverflow.com/questions/78433029/how-to-use-gridsearchcv-on-a-customized-estimator</guid>
      <pubDate>Sun, 05 May 2024 16:51:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Torchvison Mixup 解决多标签问题？</title>
      <link>https://stackoverflow.com/questions/78432917/how-to-use-torchvison-mixup-with-a-multilabel-problem</link>
      <description><![CDATA[我想使用 MixUp 作为多标签图像分类问题的数据增强，但它似乎只支持形状为 (batch_size,) 的标签。如何修改它以允许使用 [0.0, 1.0, 0.0, 1.0] 之类的标签
我尝试在标签向量 [0.0, 1.0, 0.0, 1.0] 上调用 argmax ，这给了我一个索引。这使得该函数可以工作，但它只是对单个类进行混合。]]></description>
      <guid>https://stackoverflow.com/questions/78432917/how-to-use-torchvison-mixup-with-a-multilabel-problem</guid>
      <pubDate>Sun, 05 May 2024 16:17:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 bart_machine_Arr 时如何调查变量重要性并获取 bartmachine 对象列表？</title>
      <link>https://stackoverflow.com/questions/78432817/how-to-investigate-variable-importance-when-using-bart-machine-arr-and-get-a-lis</link>
      <description><![CDATA[对于单个 bartmachine 对象，我们可以使用函数 investigate_var_importance 来获取变量重要性结果。然而，即使在函数中使用num_replicates_for_avg语句，结果仍然不稳定。
我们有 bartMachineArr(bart_machine, R=5) 函数，它可以让我们计算五个 bartmachine 并获得稳定的平均值。但我认为 investigate_var_importance 函数不能应用于 bartMachineArr 的结果，因为它是 bartmachine 对象的列表。这是同时实现这两个的错误：
&lt;块引用&gt;
&lt;块引用&gt;
调查_var_重要性（bart_machine_Arr，num_replicates_for_avg = 20）
check_serialization(bart_machine) 中的错误：
此 bartMachine 对象是从 R 图像加载的，但未序列化。
请使用选项“serialize = TRUE”构建 bartMachine下次。


因此，我想知道是否有任何可能的方法来研究变量重要性对更稳定的 bartmachine 结果的影响？非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78432817/how-to-investigate-variable-importance-when-using-bart-machine-arr-and-get-a-lis</guid>
      <pubDate>Sun, 05 May 2024 15:46:59 GMT</pubDate>
    </item>
    <item>
      <title>在python中安装pyttsx3模块后出错</title>
      <link>https://stackoverflow.com/questions/78431349/error-after-installing-pyttsx3-module-in-python</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;导入 pyttsx3

引擎 = pyttsx3.init(&#39;sapi5&#39;)
声音 = engine.getProperty(&#39;声音&#39;)
engine.setProperty(&#39;声音&#39;,声音[0].id)

def 说话（音频）：
    引擎.say（音频）
    引擎.runAndWait()

如果 __name__ == “__main__”：
    说话（“嗨，我是维拉”）

我试图使用 pyttsx3 模块让 Jarvis 说话，但我的系统说 pyttsx3 未安装，即使在安装模块后它也会抛出 MoudleNotFoundError]]></description>
      <guid>https://stackoverflow.com/questions/78431349/error-after-installing-pyttsx3-module-in-python</guid>
      <pubDate>Sun, 05 May 2024 07:13:41 GMT</pubDate>
    </item>
    <item>
      <title>使用自定义数据训练 Mask R-CNN，但训练不会停止且不会产生任何输出或错误</title>
      <link>https://stackoverflow.com/questions/78430026/training-mask-r-cnn-on-custom-data-but-the-training-doesnt-stop-and-produces-n</link>
      <description><![CDATA[以下是我的流程的简要概述：

我通过将边界框的 SAM 掩码应用到我的图像，使用 PyTorch 生成数据集。
创建数据集后，我将其分为训练集和测试集。
我使用 torch.utils.data.DataLoader 加载这两个集合。
我使用的是包含 11 个类别的预训练模型。

但是，我在训练过程中遇到了问题。该过程似乎花费了异常长的时间，并且我没有看到任何可从中进行故障排除的进度或错误消息。
我的数据集

可能出了什么问题或者如何改进我的培训过程？]]></description>
      <guid>https://stackoverflow.com/questions/78430026/training-mask-r-cnn-on-custom-data-but-the-training-doesnt-stop-and-produces-n</guid>
      <pubDate>Sat, 04 May 2024 18:34:21 GMT</pubDate>
    </item>
    <item>
      <title>显示未识别的检测到的面孔的姓名的问题</title>
      <link>https://stackoverflow.com/questions/78429558/issues-with-displaying-the-name-of-detected-faces-that-arent-recognized</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78429558/issues-with-displaying-the-name-of-detected-faces-that-arent-recognized</guid>
      <pubDate>Sat, 04 May 2024 15:47:26 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：无法同步创建数据集（名称已存在）</title>
      <link>https://stackoverflow.com/questions/78429387/valueerror-unable-to-synchronously-create-dataset-name-already-exists</link>
      <description><![CDATA[当我尝试将模型另存为 h5 时
caption_model.save(“/kaggle/working/mymodel.h5”)

我发现了这个错误
ValueError Traceback（最近一次调用最后一次）
[19] 中的单元格，第 1 行
----&gt; 1 title_model.save(“/kaggle/working/mymodel.h5”)

文件 /opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122，位于filter_traceback..error_handler(*args, **kwargs)
    第119章
    120 # 要获取完整的堆栈跟踪，请调用：
    121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
    123 最后：
    124 删除filtered_tb

文件 /opt/conda/lib/python3.10/site-packages/h5py/_hl/group.py:183，在 Group.create_dataset(self, name, shape, dtype, data, **kwds)
    第180章 180
    [第 181 回]
--&gt;第183章
    184 dset = 数据集. 数据集（dsid）
    185 返回数据集

文件 /opt/conda/lib/python3.10/site-packages/h5py/_hl/dataset.py:163，在 make_new_dset(parent、shape、dtype、数据、名称、块、压缩、shuffle、fletcher32、maxshape、compression_opts 中、 fillvalue、scaleoffset、track_times、external、track_order、dcpl、dapl、efile_prefix、virtual_prefix、allow_unknown_filter、rdcc_nslots、rdcc_nbytes、rdcc_w0)
    160 其他：
    161 sid = h5s.create_simple（形状，maxshape）
--&gt;第163章
    165 if (data is not None) and (not isinstance(data, Empty)):
    166 dset_id.write（h5s.ALL，h5s.ALL，数据）

文件 h5py/_objects.pyx:54，在 h5py._objects.with_phil.wrapper() 中

文件 h5py/_objects.pyx:55，在 h5py._objects.with_phil.wrapper() 中

文件 h5py/h5d.pyx:137，在 h5py.h5d.create() 中

ValueError：无法同步创建数据集（名称已存在）

你们以前遇到过这个问题或者知道如何解决吗？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78429387/valueerror-unable-to-synchronously-create-dataset-name-already-exists</guid>
      <pubDate>Sat, 04 May 2024 14:51:33 GMT</pubDate>
    </item>
    <item>
      <title>如何导入 Gensim？ Pip Install 有效，但我无法在没有出现 ImportError: Cannot import name 'triu' 错误的情况下运行 Import Gensim</title>
      <link>https://stackoverflow.com/questions/78427675/how-do-i-import-gensim-pip-install-worked-but-i-cant-run-import-gensim-withou</link>
      <description><![CDATA[我正在尝试执行此 Word2Vec 代码并收到 NameError: name &#39;gensim&#39; is not Defined:
w2v_model = gensim.models.Word2Vec（docgen，min_count = 5，sg = 1，seed = 22122，workers = 1）

当我导入 gensim 时，出现此错误：ImportError: Cannot import name &#39;triu&#39; from &#39;scipy.linalg&#39; (/opt/conda/lib/python3.9/site-packages/scipy/ linalg/__init__.py)
如何修复代码以便能够调用 Gensim？我需要 Word2Vec 才能运行，之前没有遇到过这个问题；我今天早上运行这个模型，一切都很好，但现在突然出现错误。
我看到你必须升级 Scipy，而且它似乎有效。这是完整的代码：
!pip install scipy==1.10.1
!pip 安装 gensim

from numpy import triu
导入gensim
从 gensim 导入语料库、模型

w2v_model = gensim.models.Word2Vec(docgen, min_count=3, sg=1, 种子=22122, 工人=1)

谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78427675/how-do-i-import-gensim-pip-install-worked-but-i-cant-run-import-gensim-withou</guid>
      <pubDate>Sat, 04 May 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 GAN 模型训练在 90 次迭代时停止？</title>
      <link>https://stackoverflow.com/questions/78425198/why-does-my-gan-model-training-stop-at-90-iterations</link>
      <description><![CDATA[我正在训练一个cycleGAN模型，每个域40张图片。 epoch 应该为 50，batch_size=1，总迭代次数为 2000，batch_per_epoch 为 40，但是模型在迭代 90 次后停止训练，不存在甚至将 90 视为 true 且模型停止的条件.
def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, 数据集, epochs=1):
    # 定义训练运行的属性
    n_epochs, n_batch, = epochs, 1 #batch size固定为1，如论文中建议的
    # 确定鉴别器的输出正方形形状
    n_patch = d_model_A.output_shape[1]
    # 解压数据集
    trainA, trainB = 数据集
    # print(trainA.shape,trainB.shape)
    # 为假图像准备图像池
    池A，池B = 列表（），列表（）
    # 计算每个训练时期的批次数
    bat_per_epo = int(len(trainA) / n_batch)
    # 计算训练迭代次数
    n_steps = bat_per_epo * n_epochs
    
    打印（n_steps，bat_per_epo）
    # 手动枚举纪元
    对于范围内的 i（n_steps）：
        # 从每个域（A和B）中选择一批真实样本
        X_realA, y_realA =generate_real_samples(trainA, n_batch, n_patch)
        X_realB, y_realB =generate_real_samples(trainB, n_batch, n_patch)
        # 使用 B to A 和 A to B 生成器生成一批假样本。
        X_fakeA, y_fakeA =generate_fake_samples(g_model_BtoA, X_realB, n_patch)
        X_fakeB, y_fakeB =generate_fake_samples(g_model_AtoB, X_realA, n_patch)
        # 更新池中的假图像。请记住，论文建议使用 50 个图像的缓冲区
        X_fakeA = update_image_pool(poolA, X_fakeA)
        X_fakeB = update_image_pool(poolB, X_fakeB)
        # 通过复合模型更新生成器 B-&gt;A
        # print(类型(X_realA),类型(X_realB),类型(X_fakeA),类型(X_fakeB),类型(y_realA),类型(y_realB),类型(y_fakeA),类型(y_fakeB))
        
        g_loss2 = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])
        
        # 更新 A 的鉴别器 -&gt; [真/假]
        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)
        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)
        
        # 通过复合模型更新生成器 A-&gt;B
        g_loss1 = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])
        # 更新 B 的鉴别器 -&gt; [真/假]
        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)
        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)
        
        # 总结性能
        #由于我们的批量大小=1，迭代次数将与数据集的大小相同。
        #在一个纪元中，迭代次数等于图像数量。
        #如果你有 100 张图像，那么 1 epoch 就是 100 次迭代
        print(&#39;迭代&gt;%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]&#39; % (i+1, dA_loss1,dA_loss2, dB_loss1 ,dB_loss2, g_loss1,g_loss2))
        # 定期评估模型性能
        #如果批量大小（总图像）=100，则每 75 次迭代后将总结性能。
        如果 (i+1) % (bat_per_epo * 1) == 0:
            # 绘制 A-&gt;B 翻译
            总结性能（i，g_model_AtoB，trainA，&#39;AtoB&#39;）
            # 情节 B-&gt;A 翻译
            总结性能（i，g_model_BtoA，trainB，&#39;BtoA&#39;）
        如果 (i+1) % (bat_per_epo * 5) == 0:
            # 保存模型
            # #如果批量大小（总图像）=100，模型将在之后保存
            #每 75 次迭代 x 5 = 375 次迭代。
            save_models(i, g_model_AtoB, g_model_BtoA)

这是训练函数，历元传递为 50，最后一个条件：
如果 (i+1) % (bat_per_epo * 5) == 0:
    # 保存模型
    # #如果批量大小（总图像）=100，模型将在之后保存
    #每 75 次迭代 x 5 = 375 次迭代。
    save_models(i, g_model_AtoB, g_model_BtoA)

没有被执行。
随着生成器损失的减少，模型似乎正在训练和改进，生成的图像并没有那么糟糕，因为它只训练了 40 次迭代和 80 次迭代，在第 40 次和 80 次之后生成了图片并保存了模型迭代，然后停止。
这是我得到的结果：
40 次迭代后：

80次迭代后：
]]></description>
      <guid>https://stackoverflow.com/questions/78425198/why-does-my-gan-model-training-stop-at-90-iterations</guid>
      <pubDate>Fri, 03 May 2024 14:13:14 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制以下代码片段的ROC曲线？</title>
      <link>https://stackoverflow.com/questions/64962372/how-to-draw-roc-curve-for-the-following-code-snippet</link>
      <description><![CDATA[我是深度学习新手。我正在尝试为以下代码生成 ROC 曲线。我正在使用喀拉拉。
类大小为 10，图像为大小为 1001003 的 RGB 图像。
&lt;前&gt;&lt;代码&gt;target_size=(100,100,3)

train_generator = train_datagen.flow_from_directory(&#39;路径&#39;,
    目标大小=目标大小[:-1],
    批量大小=16，
    class_mode=&#39;分类&#39;,
    子集=&#39;训练&#39;,
    种子=随机种子）

有效生成器 = ...

测试生成器 = ...
n_classes = len(set(train_generator.classes))

打印（n_类）

input_layer = keras.layers.Input(shape=target_size)

conv2d_1 = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1, padding=&#39;same&#39;,
激活=&#39;relu&#39;,
                           kernel_initializer=&#39;he_normal&#39;)(input_layer)

batchnorm_1 = keras.layers.BatchNormalization()(conv2d_1)
maxpool1=keras.layers.MaxPool2D(pool_size=(2,2))(batchnorm_1)


conv2d_2 = keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, padding=&#39;same&#39;,
激活=&#39;relu&#39;,
                           kernel_initializer=&#39;he_normal&#39;)(maxpool1)
batchnorm_2 = keras.layers.BatchNormalization()(conv2d_2)

maxpool2=keras.layers.MaxPool2D(pool_size=(2,2))(batchnorm_2)


展平 = keras.layers.Flatten()(maxpool2)
稠密_1 = keras.layers.Dense(256, 激活=&#39;relu&#39;)(展平)

稠密_2 = keras.layers.Dense(n_classes, 激活=&#39;softmax&#39;)(dense_1)



模型= keras.models.Model（input_layer，dense_3）

model.compile(优化器=keras.optimizers.Adam(0.001),
          损失=&#39;分类交叉熵&#39;，
          指标=[&#39;acc&#39;])
模型.summary()

model.fit_generator（生成器=train_generator，validation_data=valid_generator，
                纪元=200）
                
分数 = model.evaluate_generator(test_generator)

打印（分数）

我想看到曲线并生成 ROC 曲线。请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/64962372/how-to-draw-roc-curve-for-the-following-code-snippet</guid>
      <pubDate>Mon, 23 Nov 2020 03:58:45 GMT</pubDate>
    </item>
    </channel>
</rss>