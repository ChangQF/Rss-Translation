<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 13 Dec 2023 12:26:01 GMT</lastBuildDate>
    <item>
      <title>我应该在 Adam 优化器的顶部应用余弦退火调度程序吗？</title>
      <link>https://stackoverflow.com/questions/77653513/should-i-apply-a-cosine-annealing-scheduler-on-the-top-of-the-adam-optimizer</link>
      <description><![CDATA[Adam 优化器以其自适应调整学习率的能力而闻名，那么余弦退火调度器还有用吗？
我还没有完成实验，部分原因是我没有干净的余弦退火代码示例。特别感谢那些可以提供代码片段的人。]]></description>
      <guid>https://stackoverflow.com/questions/77653513/should-i-apply-a-cosine-annealing-scheduler-on-the-top-of-the-adam-optimizer</guid>
      <pubDate>Wed, 13 Dec 2023 12:16:11 GMT</pubDate>
    </item>
    <item>
      <title>执行与自然语言处理相关的代码时出错</title>
      <link>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</link>
      <description><![CDATA[此代码显示了图像中给出的错误。我无法理解其中的原因。

我不知道如何在Python中使用导入命令。我尝试了所有可能的方法进行检查，包括删除带有其他新闻门户名称的“路透社”，但没有任何效果。现在，如果有人帮助我正确编写代码的“导入”部分，那就更好了。我认为其他部分没问题，因为没有显示其他消息。]]></description>
      <guid>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</guid>
      <pubDate>Wed, 13 Dec 2023 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>朴素贝叶斯分类器需要估计多少个参数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77652867/how-many-parameters-need-to-be-estimated-for-na%c3%afve-bayes-classifier</link>
      <description><![CDATA[这是来自 GATE 数据科学与人工智能 (DA) 样本论文的 MCQ 问题：
Q.28
&lt;块引用&gt;
给定一个包含𝑁点的𝐾类数据集，其中描述了样本点
使用 𝐷 离散特征，每个特征都能够取 𝑉 值，如何
朴素贝叶斯分类器需要估计很多参数？
(A) (𝑉^D)𝐾 
(B) (𝐾^V)^D 
(C) 𝑉𝐷𝐾 + K 
(D) 𝐾(𝑉 + 𝐷)

根据chatgpt正确答案是(A)：
总参数=类的数量×(每个特征的值的数量)^特征的数量+类的数量
而 Bard 通过取 K、V 和 D 的一些值给出了正确答案 (C)。
我想知道这是否正确，如果可能的话，进一步阅读有关该主题的内容会很好。]]></description>
      <guid>https://stackoverflow.com/questions/77652867/how-many-parameters-need-to-be-estimated-for-na%c3%afve-bayes-classifier</guid>
      <pubDate>Wed, 13 Dec 2023 10:38:01 GMT</pubDate>
    </item>
    <item>
      <title>用转换层替换平均池层</title>
      <link>https://stackoverflow.com/questions/77652246/replacing-a-avg-pool-layer-with-a-conv-layer</link>
      <description><![CDATA[我有一个内核大小为 (4,3) 的平均池层，其步长为 (4,3) 和 0 填充。我想将其转换为等效的转换层，以便在我的神经网络中实现。
所以，在我的模型中，我替换了这个：
self.pool = nn.AvgPool2d((4, 3))

使用这一行（32 是输入通道数）：
self.pool = nn.Conv2d(32, 32, (4, 3), stride=(4, 3), 偏差=False)

对我来说，这两个层似乎应该是等效的，并且这两个层的输出大小都是 (1, 32, 32, 13) （它有 32 个通道）；对于大小为 (1, 32, 129, 40) 的输入（32 个通道，X 维度 129，Y 维度 40）。
我不确定我对池化层和转换层的基础知识是否有错误的理解。有人可以帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/77652246/replacing-a-avg-pool-layer-with-a-conv-layer</guid>
      <pubDate>Wed, 13 Dec 2023 09:06:48 GMT</pubDate>
    </item>
    <item>
      <title>SEEM 模型在向其传递图像及其推理时面临的问题</title>
      <link>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</link>
      <description><![CDATA[我正在研究 SEEM 模型，这是一种可推广的交互式模型，用于一次性分割图像中任何地方的所有内容。由于资源有限，我在将图像传递给它及其推理时面临问题。我已经安装了所有依赖项并单独加载了 SEEM 模型。有谁对此有任何想法并相应地指导我。
我期待有人能够根据他们的知识指导我，我可以尽快解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</guid>
      <pubDate>Wed, 13 Dec 2023 04:53:29 GMT</pubDate>
    </item>
    <item>
      <title>尝试将自定义模型部署到终端节点时从 AWS Sagemaker 获取（超时）ModelError</title>
      <link>https://stackoverflow.com/questions/77649384/getting-timed-out-modelerror-from-aws-sagemaker-when-trying-to-deploy-a-custom</link>
      <description><![CDATA[我目前在使用 PyTorchModel 和我的自定义模型在 AWS SageMaker 上部署终端节点时遇到问题。尽管遵循 Amazon 官方网站（所有代码均可在一个 Github 上找到），我遇到以下错误：
&lt;块引用&gt;
sagemaker 调用 InvokeEndpoint 操作时发生错误 (ModelError)：从主容器收到服务器错误 (0)，并显示消息您的调用在等待容器主容器的响应时超时。检查 Amazon CloudWatch 中每个容器的延迟指标，解决问题，然后重试。

我尝试通过查看 Amazon CloudWatch 中的日志来解决该问题，但无法找到解决方案。我还将 SAGEMAKER_MODEL_SERVER_TIMEOUT 更改为 180，但它不起作用。请让我知道如何修复它。我已经尝试过 AWS 网站上的其他示例和文档，但没有一个对我有用。]]></description>
      <guid>https://stackoverflow.com/questions/77649384/getting-timed-out-modelerror-from-aws-sagemaker-when-trying-to-deploy-a-custom</guid>
      <pubDate>Tue, 12 Dec 2023 22:37:01 GMT</pubDate>
    </item>
    <item>
      <title>如何安装集群； AssertionError：错误：无法打开“optimum/version.py”，因为[Errno 2]没有这样的文件或目录：“optimum/version.py”</title>
      <link>https://stackoverflow.com/questions/77649233/how-to-install-swarms-assertionerror-error-could-not-open-optimum-version-py</link>
      <description><![CDATA[我正在尝试安装 swarms，但无法安装并收到此错误：
pip install swarms

收集蜂群
  使用缓存的 swarms-2.7.7-py3-none-any.whl.metadata (15 kB)
收集枕头（从蜂群中）
  使用缓存的 Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
收集 PyPDF2（从群中）
  使用缓存的 pypdf2-3.0.1-py3-none-any.whl (232 kB)
收集加速（来自蜂群）
  使用缓存的 Accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)
收集 asyncio（从群中）
...
使用缓存的optimum-0.1.1.tar.gz (17 kB)
  安装构建依赖项...完成
  获取制造轮子的要求...完成
  准备元数据 (pyproject.toml) ...完成
  使用缓存的optimum-0.1.0.tar.gz (16 kB)
  安装构建依赖项...完成
  获取构建轮子的要求...错误
  错误：子进程退出并出现错误
  
  × 获取构建 Wheel 的需求未成功运行。
  │ 退出代码：1
  ╰─&gt; [24行输出]
      回溯（最近一次调用最后一次）：
        文件“”，第 7 行，位于  中。
      FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;optimum/version.py&#39;
      
      在处理上述异常的过程中，又出现了一个异常：
      
      回溯（最近一次调用最后一次）：
        文件“/home/ubuntu/miniconda/envs/tree_of_thoughts/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py”，第 353 行，在  中
          主要的（）
        文件“/home/ubuntu/miniconda/envs/tree_of_thoughts/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py”，第 335 行，在 main 中
          json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
        文件“/home/ubuntu/miniconda/envs/tree_of_thoughts/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py”，第 118 行，在 get_requires_for_build_wheel 中
          返回钩子（config_settings）
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 325 行，在 get_requires_for_build_wheel 中
          返回 self._get_build_requires(config_settings, requests=[&#39;wheel&#39;])
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 295 行，位于 _get_build_requires 中
          self.run_setup()
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 480 行，在 run_setup 中
          超级（_BuildMetaLegacyBackend，自我）.run_setup（setup_script = setup_script）
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 311 行，在 run_setup 中
          执行（代码，局部变量（））
        文件“”，第 10 行，位于  中。
      AssertionError：错误：无法打开“optimum/version.py”，因为[Errno 2]没有这样的文件或目录：“optimum/version.py”
      
      [输出结束]
  
  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：子进程退出并出现错误

× 获取构建 Wheel 的需求未成功运行。
│ 退出代码：1
╰─&gt;请参阅上面的输出。

注意：此错误源自子进程，并且可能不是 pip 的问题。

如何解决这个问题？
交叉：https://discord.com/channels/999382051935506503/1184252377356836954]]></description>
      <guid>https://stackoverflow.com/questions/77649233/how-to-install-swarms-assertionerror-error-could-not-open-optimum-version-py</guid>
      <pubDate>Tue, 12 Dec 2023 21:58:14 GMT</pubDate>
    </item>
    <item>
      <title>数学图数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/77648552/math-graph-dataset</link>
      <description><![CDATA[我正在寻找包含通过某些方程获得的可能图形的任何数据集，因为我想制作和训练一个人工智能模型，当给定图像时，它将获取图像的轮廓，并返回一系列数学方程，当例如在 Desmos 图形计算器 中绘制的，给出图像的轮廓。
我尝试拍摄照片并单独标记每张照片，但这需要很长时间！我希望我能找到一个至少包含一些基本图表的数据集，我可以从那里继续。]]></description>
      <guid>https://stackoverflow.com/questions/77648552/math-graph-dataset</guid>
      <pubDate>Tue, 12 Dec 2023 19:20:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 openai 和 langchain 将已创建的 chromadb 集合与法学硕士一起使用？</title>
      <link>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</link>
      <description><![CDATA[我已经使用其文档和元数据创建了 chromadb 集合。
问题是当我想使用 langchain 创建 llm 并传递此 chromadb 集合以用作知识库时。
langchain_chroma = 色度(
客户端=持久客户端，
集合名称=集合.名称,
embedding_function = openai_ef，
）

llm_model =“gtp35turbo-最新”

llm = AzureChatOpenAI(
   api_key=openai_api_key,
   api_version=openai_api_version,
   azure_endpoint=openai_api_base,
   模型=llm_模型）

qa_chain = RetrievalQA.from_chain_type(
   嗯，
   检索器=langchain_chroma.as_retriever(),
   chain_type=&quot;精炼&quot;
）

当我想跑步时：
qa_chain.run(“对象检测问题需要多少数据科学家”)

我收到此错误：
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-81-3cdb65aeb43e&gt;在&lt;细胞系：1&gt;()
----&gt; 1 qa.run(“对象检测问题需要多少数据科学家”)

9帧
/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py 中相似性_search_with_score(self, query, k, filter, where_document, **kwargs)
    第430章）
    第431章：
--&gt;第432章
    第433章
    第434章

AttributeError：“OpenAIEmbeddingFunction”对象没有属性“embed_query”

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</guid>
      <pubDate>Mon, 11 Dec 2023 21:17:23 GMT</pubDate>
    </item>
    <item>
      <title>对包含 nan 元素的 xarray 数据执行 sklearn.linearmodel 岭回归</title>
      <link>https://stackoverflow.com/questions/77640756/performing-sklearn-linearmodel-ridge-regression-on-xarray-data-which-contains-na</link>
      <description><![CDATA[我正在尝试执行带有岭校正的多元线性回归，以确定 xarray 数据框中某些空间变量之间的关系。因为这些是观察到的数据，所以数据中偶尔会有 NaN 值，这是 sklearn 本身无法处理的。我尝试使用 data.interpolate_na(fill_value=&#39;extrapolate&#39;)，但这无法替换所有 NaN 值。一个可行的解决方案是使用 data.fillna(0) ，但这可能会出现问题，因为当插值或屏蔽之类的方法会更好时，我不希望从整个布料中“发明”数据。我的代码如下：
从 sklearn.linear_model 导入 Ridge
将 xarray 导入为 xr
将 pandas 导入为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 cartopy.crs 导入为 ccrs

def detrend_dim(da, dim, deg=1): # 从数据中删除（时间）趋势
    # 沿单一维度去趋势
    p = da.polyfit(dim=dim, deg=deg)
    fit = xr.polyval(da[dim], p.polyfit_coefficients)
    返回 da - 适合

#加载和预处理数据
data = xr.open_dataset(&#39;reanalysisdata.nc&#39;)
data2 = xr.open_dataset(&#39;satellitedata.nc&#39;)
土地 = xr.open_dataset(&#39;twopt Fivedeglandmask.nc&#39;)
data2.coords[&#39;mask&#39;] = ((&#39;lat&#39;, &#39;lon&#39;), land.FRLAND.mean(dim=&#39;time&#39;).data)
数据2 = 数据2.where(数据2.掩码== 0)
data.coords[&#39;mask&#39;] = ((&#39;lat&#39;, &#39;lon&#39;), land.FRLAND.mean(dim=&#39;time&#39;).data)
数据 = 数据.where(数据.掩码 == 0)

#尝试处理 NaN 值
数据 = data.fillna(0)
数据2 = 数据2.fillna(0)

#删除时间趋势
数据[&#39;x1&#39;] = detrend_dim(data.x1, &#39;时间&#39;)
数据[&#39;x2&#39;] = detrend_dim(data.x2, &#39;时间&#39;)
数据[&#39;x3&#39;] = detrend_dim(data.x3, &#39;时间&#39;)
data2[&#39;y&#39;] = detrend_dim(data2.y, &#39;时间&#39;)

#去除季节周期
dataM = data.groupby(&#39;时间.月份&#39;)
数据U = 数据M - 数据M.mean()
data2M = data2.groupby(&#39;时间.月份&#39;)
data2U = data2M - data2M.mean()

#执行回归
a = np.zeros((72,144,3))
对于范围内的 i(len(data.lat))：
    对于范围内的 j(len(data.lon))：
        a[i,j,:] = (Ridge().fit(np.array((dataU.isel(lev=2).x1.values[:,i,j].reshape(-1,1),
                    dataU.isel(lev=2).x2.values[:,i,j].reshape(-1,1),
                    dataU.isel(lev=2).x3.values[:,i,j].reshape(-1,1))).reshape(108,3),
                    data2U.y.values[:,i,j].reshape(108)).coef_)
dataU = data.assign_coords(varname=[&#39;x1&#39;,&#39;x2&#39;,&#39;x3&#39;])
dataU[&#39;multiple_reg_coeff&#39;] = ((&#39;lat&#39;,&#39;lon&#39;,&#39;varname&#39;), a)

我需要迭代检查每个变量的 NaN 吗？ sklearn.linear_model 中有一些回归本身可以处理 NaN，但我对它们背后的数学的理解不如岭回归。]]></description>
      <guid>https://stackoverflow.com/questions/77640756/performing-sklearn-linearmodel-ridge-regression-on-xarray-data-which-contains-na</guid>
      <pubDate>Mon, 11 Dec 2023 15:48:54 GMT</pubDate>
    </item>
    <item>
      <title>调整图像分割模型（来自 TF 教程）以进行二元掩蔽</title>
      <link>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</link>
      <description><![CDATA[我需要 Tensorflow 的图像分割模型。输入为图像和掩码（二进制、掩码或非掩码），输出为带有 0 和 1 的图像掩码。
我遵循了 https://www.tensorflow.org/tutorials/ 中的图像分割教程图像/分割
但现在我想在我的数据集上运行它的二进制掩码（没有边框类）
新数据集已准备好并输入到 model.fit 中。应该没问题吧。
如何将此模型更改为只有 2 个类（非屏蔽和屏蔽）？
base_model: keras.Model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)

# 使用这些层的激活
图层名称 = [
    &#39;block_1_expand_relu&#39;, # 64x64
    &#39;block_3_expand_relu&#39;, # 32x32
    &#39;block_6_expand_relu&#39;, # 16x16
    &#39;block_13_expand_relu&#39;, # 8x8
    &#39;block_16_project&#39;, # 4x4
]
base_model_outputs = [base_model.get_layer(name).layer_names 中名称的输出]

# 创建特征提取模型
down_stack = 模型（输入=base_model.输入，输出=base_model_outputs）

down_stack.trainable = False

上层堆栈 = [
    pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8
    pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16
    pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32
    pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
  输入 = 层.Input(形状=[128, 128, 3])

  # 通过模型进行下采样
  跳过= down_stack（输入）
  x = 跳过[-1]
  跳过 = 反转(跳过[:-1])

  # 上采样并建立跳跃连接
  对于 up，在 zip 中跳过（up_stack，skips）：
    x = 上(x)
    concat = 层.Concatenate()
    x = concat([x, 跳过])

  # 这是模型的最后一层
  最后=层.Conv2DTranspose(
      过滤器=output_channels，kernel_size=3，步长=2，
      padding=&#39;相同&#39;) #64x64 -&gt; 128x128

  x = 最后一个(x)

  返回模型（输入=输入，输出=x​​）

输出类 = 3

模型 = unet_model(output_channels=OUTPUT_CLASSES)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

当我将 OUTPUT_CLASSES 更改为 2 时，出现错误：
W tensorflow/core/kernels/data/generator_dataset_op.cc:108] 完成 GeneratorDataset 迭代器时发生错误：FAILED_PRECONDITION：Python 解释器状态未初始化。该过程可以被终止。

当OUTPUT_CLASSES为1时，预测掩码为空。
也许还必须改变其他东西？我还不熟悉神经网络架构，所以我可能看不到明显的东西。
编辑：
我已将activation=&#39;sigmoid&#39;添加到输出层
 最后 = tf.keras.layers.Conv2DTranspose(
      过滤器=output_channels，kernel_size=3，步长=2，
      填充 = &#39;相同&#39;, 激活 = &#39;sigmoid&#39;) #64x64 -&gt; 128x128

  x = 最后一个(x)

和OUTPUT_CLASSES = 1
奇怪的行为是下一个：
预期的掩模是当我在一个非常小的数据集上训练它时（该数据集中包含的测试的图片和掩模，只是为了测试它如何检测所看到的图像），我在第一个时期得到了一些东西。但纪元越多，结果越差。然而，准确度约为 0.99。
预期掩码：

预测掩码纪元 0：

如果打开图像，您可能会在预期的遮罩部分看到轻微的阴影。
预测掩码纪元1：

...
纪元 4：

所以每次迭代都会变得更糟。
数据集包含不应显示任何蒙版的图像。也许这就是问题所在？ （编辑：从数据集中排除没有掩码的数据 - 没有帮助）
编辑2：
x = tf.keras.layers.BatchNormalization()(x)

有帮助，虽然不完美，但是有所帮助]]></description>
      <guid>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</guid>
      <pubDate>Sun, 10 Dec 2023 13:55:04 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试从 Transformer 导入 Trainer 时，DLL 失败</title>
      <link>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</link>
      <description><![CDATA[我想在本地计算机上微调基于 Transformer 的模型，因此当我尝试导入训练器时
从 Transformers 导入 Trainer

出现此错误
导入错误：导入 lib 时 DLL 加载失败：找不到指定的过程。
运行时错误：由于以下错误，无法导入transformers.trainer（查找其回溯）：
导入 lib 时 DLL 加载失败：找不到指定的过程。
如何解决此错误？
环境
蟒蛇
库达12.3
Python 3.9.18
火炬2.1.0+cu118
火炬音频2.1.0+cu118
火炬视觉 0.16.0+cu118
变形金刚4.35.2

我尝试升级CUDA，升级和降级transformers库，torch及其子库，但没有帮助]]></description>
      <guid>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</guid>
      <pubDate>Sun, 10 Dec 2023 05:33:49 GMT</pubDate>
    </item>
    <item>
      <title>ValidationError：StuffDocumentsChain __root__ 出现 1 个验证错误</title>
      <link>https://stackoverflow.com/questions/76776695/validationerror-1-validation-error-for-stuffdocumentschain-root</link>
      <description><![CDATA[我收到此错误ValidationError：在 llm_chain input_variables 中找不到 StuffDocumentsChain __root__ document_variable_name 上下文的 1 个验证错误：[&#39;chat_history&#39;、&#39;user_query&#39;、&#39;relevant_context&#39;] (type=value_error)
在使用 load_qa_chain 时，我搜索了此错误，但没有找到与此相关的任何内容。谁能告诉我这里缺少什么。
代码：
template = &quot;&quot;&quot;您是一个正在与人类对话的聊天机器人。

给定长文档和问题的以下提取部分，创建最终答案。

{相关上下文}

{聊天记录}
人类：{user_query}
聊天机器人：“”“”

提示=提示模板(
input_variables=[“chat_history”, “user_query”, “relevant_context”],
模板=模板
）

内存 = ConversationBufferMemory(memory_key=“chat_history”, input_key=“user_query”)

llm = OpenAI()
llm_chain = LLMChain(
    llm=llm,
    提示=提示，
    内存=内存，
）

链 = load_qa_chain(
    llm, chain_type=“东西”, 内存=内存, 提示=提示
）
]]></description>
      <guid>https://stackoverflow.com/questions/76776695/validationerror-1-validation-error-for-stuffdocumentschain-root</guid>
      <pubDate>Thu, 27 Jul 2023 05:20:25 GMT</pubDate>
    </item>
    <item>
      <title>Google Colab 免费套餐：使用自定义数据集微调 LLAMA 2 时，代码停止在 51,000 个示例</title>
      <link>https://stackoverflow.com/questions/76765564/google-colab-free-tier-code-stops-at-51-000-examples-while-fine-tuning-llama-2</link>
      <description><![CDATA[我在使用自定义数据集在 Google Colab 上微调 Llama 2 时遇到问题。在训练过程中，代码恰好在 51,000 个示例处停止，尽管我的数据集包含 61,609 个示例。奇怪的是，当我使用更大的数据集测试代码时，它运行得非常好。我按照 YouTube 上的教程对 Llama 2 进行了微调，您可以在下面找到原始 Colab 和教程链接：
教程链接：YouTube 教程
原始 Colab：Google Colab
数据集链接：我的自定义数据集
代码：
!pip install -q -U trl 变压器加速 git+https://github.com/huggingface/peft.git
!pip install -q 数据集 BitsandBytes einops wandb

从数据集导入load_dataset
从 Transformer 导入 AutoTokenizer、TrainingArguments
从 peft 导入 LoraConfig，get_peft_model
从 trl 导入 SFTTrainer

# 加载数据集
dataset_name = &#39;harpyerr/merged-pf&#39;
数据集 = load_dataset(dataset_name, split=&quot;train&quot;)

# 定义model_name、lora_alpha、lora_dropout、lora_r等配置
model_name = “your_pretrained_model_name” # 替换为你的预训练模型的名称
劳拉阿尔法 = 16
劳拉_dropout = 0.1
劳拉_r = 64

# 初始化分词器
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token

# 定义 LoraConfig
peft_config = LoraConfig（
    劳拉_阿尔法=劳拉_阿尔法,
    lora_dropout=lora_dropout,
    r=劳拉_r,
    偏差=“无”，
    task_type=“CAUSAL_LM”
）

# 定义训练参数
输出目录=“./结果”
每个设备训练批次大小 = 4
梯度累积步数 = 4
optim = “paged_adamw_32bit”
保存步数 = 100
记录步骤 = 10
学习率 = 2e-4
最大梯度范数 = 0.3
最大步数 = 100
预热比率 = 0.03
lr_scheduler_type = “常量”

训练参数 = 训练参数（
    输出目录=输出目录，
    per_device_train_batch_size = per_device_train_batch_size，
    梯度累积步数=梯度累积步数，
    优化=优化，
    保存步骤=保存步骤，
    日志记录步骤=日志记录步骤，
    学习率=学习率，
    fp16=正确，
    max_grad_norm=max_grad_norm,
    最大步数=最大步数，
    Warmup_ratio=warmup_ratio,
    group_by_length=真，
    lr_scheduler_type = lr_scheduler_type，
）

# 初始化 SFTTrainer
最大序列长度 = 512
训练师 = SFTTrainer(
    型号=型号，
    train_dataset=数据集，
    pft_config=peft_config,
    dataset_text_field=&quot;文本&quot;,
    max_seq_length = max_seq_length，
    分词器=分词器，
    args=训练参数，
）

# 将所有标准化层转换为 float32
进口火炬
对于名称，trainer.model.named_modules() 中的模块：
    如果“正常”名称：
        模块 = module.to(torch.float32)

# 开始训练
训练师.train()

我尝试使用较大尺寸的不同数据集来检查问题是否特定于我的自定义数据集。令人惊讶的是，当我使用其他更大的数据集时，代码运行得非常好，没有任何停止问题。因此，我推断问题不在于代码或训练器，而可能与我的自定义数据集的具体特征有关。]]></description>
      <guid>https://stackoverflow.com/questions/76765564/google-colab-free-tier-code-stops-at-51-000-examples-while-fine-tuning-llama-2</guid>
      <pubDate>Tue, 25 Jul 2023 18:25:00 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace AutoModelForCasualLM “仅解码器架构”警告，即使在设置 padding_side='left' 后也是如此</title>
      <link>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</link>
      <description><![CDATA[我正在使用
AutoModelForCausalLM 和 AutoTokenizer 使用 DialoGPT 生成文本输出。
无论出于何种原因，即使使用 Huggingface 提供的示例，我也会收到此警告：
&lt;块引用&gt;
正在使用仅解码器架构，但检测到右填充！为了正确的生成结果，请在初始化分词器时设置 padding_side=&#39;left&#39;。

从变压器导入 AutoModelForCausalLM, AutoTokenizer
进口火炬


tokenizer = AutoTokenizer.from_pretrained(“microsoft/DialoGPT-medium”)
模型 = AutoModelForCausalLM.from_pretrained(“microsoft/DialoGPT-medium”)

# 我们聊5行吧
对于范围（5）中的步骤：
    # 对新的用户输入进行编码，添加 eos_token 并在 Pytorch 中返回一个张量
    new_user_input_ids = tokenizer.encode(input(“&gt;&gt;用户:”) + tokenizer.eos_token, return_tensors=&#39;pt&#39;)

    # 将新的用户输入标记附加到聊天历史记录中
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) 如果步骤 &gt; 0 其他 new_user_input_ids

    # 生成响应，同时将总聊天历史记录限制为 1000 个令牌，
    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)

    # 漂亮地打印机器人最后的输出令牌
    print(“DialoGPT: {}”.format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0],skip_special_tokens=True)))

代码由 微软在 Huggingface 的模型卡上
我尝试将 padding_side=&#39;left&#39; 添加到标记生成器中，但这不会改变任何内容。
显然（从一些阅读来看）DialoGPT 想要在右侧填充？
我无法弄清楚这一点，当我尝试谷歌搜索时几乎没有结果。
我能够像这样抑制警告：
from Transformers.utils 导入日志记录

记录.set_verbosity_info()

但这似乎不是最好的答案？]]></description>
      <guid>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</guid>
      <pubDate>Fri, 09 Dec 2022 20:39:39 GMT</pubDate>
    </item>
    </channel>
</rss>