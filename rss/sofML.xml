<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 17 Oct 2024 06:24:40 GMT</lastBuildDate>
    <item>
      <title>如何向 openvino 模型添加预处理和后处理</title>
      <link>https://stackoverflow.com/questions/79096498/how-to-add-pre-and-post-processing-to-openvino-model</link>
      <description><![CDATA[很可能我误解了一些东西。我有一个 Pytorch 模型（已转换为 onnx），想将其与 openVine 一起使用。我的模型用于图像分类。因此，我有几个问题：

最正确的预处理方法是什么？众所周知，该模型应该将图像 [255,255,255] 作为输入，而 openCV 形状有点不同，这是 pytorch 所必需的。我发现在使用 openVINO 中的 mo.py 优化模型时可以进行规范化。

mo --input_model test.onnx --mean_values [127.5, 127.5, 127.5] --scale 127.5

如何调整图像大小并更改视图？

我的模型返回原始值作为输出，因此，我必须将 softmax 函数应用于输出层。如何将其添加到 openvino 模型中？

主要思想应该是这样的：
原始图像（例如，(1520, 2688, 3)）-&gt; 模型（重塑、重新缩放、规范化、预测、输出、softmax）-&gt;分类概率
是否可以将此逻辑放入 openvino 模型中？
谢谢
我试图使用 OpenVine 中的 PostPreProcessing 类，但它看起来很混乱，不清楚如何将其实现到我的模型中（以及何时实现）]]></description>
      <guid>https://stackoverflow.com/questions/79096498/how-to-add-pre-and-post-processing-to-openvino-model</guid>
      <pubDate>Thu, 17 Oct 2024 04:43:29 GMT</pubDate>
    </item>
    <item>
      <title>如何将我的数据集不重复地分成测试和训练？</title>
      <link>https://stackoverflow.com/questions/79096421/how-to-split-my-dataset-into-test-and-train-without-repitition</link>
      <description><![CDATA[我正在开发一个 Python 脚本来测试一个算法。我有一个数据集，需要将其分成 80% 用于训练，20% 用于测试。但是，我想保存测试集以供进一步分析，确保与之前的测试集不重叠。
虽然我的代码总体运行良好，但我遇到了一个问题：由于随机选择过程，测试数据集有时包含之前测试运行中已经选择的记录。
在流程结束时，所有 100% 的记录都应在其中一次运行中进行测试
举个例子说明：

在第一次运行中，我的数据集 {0,1,2,3,4,5,6,7,8,9 被拆分为训练集 {0,1,2,4,5,7,8,9 和测试集 {3,6。
在第二次运行中，训练集为 {0,1,2,3,4,5,7,9，测试集为{6,8。

如您所见，记录 {6 被选中两次进行测试，我想避免这种情况。
我如何修改代码以确保每次随机选择 20% 的测试集，但排除任何之前选择的记录？
这是当前代码：
df = pd.read_csv(&quot;CustomersInfo.csv&quot;)
y = df[&#39;CustomerRank&#39;]
X = df.drop(&#39;CustomerRank&#39;, axis=1, errors=&#39;ignore&#39;)

#----------------------------------------------------------------------------------
#这是需要修复的部分
for RandStat in [11, 22, 33, 44, 55]:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RandStat)
#-------------------------------------------------------------------

clf = XGBClassifier(random_state=RandStat)
clf.fit(X_train, y_train)
fnStoreAnalyse(y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/79096421/how-to-split-my-dataset-into-test-and-train-without-repitition</guid>
      <pubDate>Thu, 17 Oct 2024 03:50:34 GMT</pubDate>
    </item>
    <item>
      <title>如何解读 Roboflow 训练指标？</title>
      <link>https://stackoverflow.com/questions/79096272/how-to-interpret-roboflow-train-metrics</link>
      <description><![CDATA[如何解释这样的结果？
Roboflow Train Metrics
很难找到一个好的参考资料来帮助我进行解释。
可以从图表中解释哪些信息？它们有什么用？

train/box_loss
train/cls_loss
train/dfl_loss
val/box_loss
val/cls_loss
val/dfl_loss
metrics/precision(B)
metrics/recall(B)
metrics/mAP50(B)
metrics/mAP50-95(B)
]]></description>
      <guid>https://stackoverflow.com/questions/79096272/how-to-interpret-roboflow-train-metrics</guid>
      <pubDate>Thu, 17 Oct 2024 02:15:21 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：将输入绑定到 tf.function 失败，无法将 input_tensor TensorSpec 转换为 TensorSpec</title>
      <link>https://stackoverflow.com/questions/79094829/typeerror-binding-inputs-to-tf-function-failed-can-not-cast-input-tensor-tenso</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79094829/typeerror-binding-inputs-to-tf-function-failed-can-not-cast-input-tensor-tenso</guid>
      <pubDate>Wed, 16 Oct 2024 15:43:54 GMT</pubDate>
    </item>
    <item>
      <title>构建用于字符识别的 9 轴 IMU 模拟器：需要指导</title>
      <link>https://stackoverflow.com/questions/79094646/building-a-9-axis-imu-simulator-for-character-recognition-guidance-needed</link>
      <description><![CDATA[我正在开展一个项目，该项目受到论文面向基于 IMU 的笔式在线手写识别器的启发，旨在构建一个用于字符识别的 9 轴 IMU 模拟器。
我正在寻找有关如何入门以及需要学习哪些关键概念或技术的建议。
具体来说，我想为每个角色模拟真实的运动模式，引入传感器噪声，并分割与不同角色手势相对应的时间序列数据。
目标是以 JSON 格式导出这些数据。
我希望得到以下方面的指导：

为此用例开发 9 轴 IMU 模拟器的关键起点是什么？
我应该关注哪些核心概念和技术（运动动力学、传感器建模等）？
如何模拟逼真的角色动作并结合噪声来模拟真实世界的 IMU 数据？
生成和处理角色手势时间序列数据的最佳方法是什么？
我应该使用 Python 还是 C 来实现，为什么？

我考虑过的工具：

MATLAB imuSensor：似乎有用，但已获得许可。
PyBullet：考虑用于物理模拟，但不清楚它是否适合这项特定任务。
CoppeliaSim (Coppelia Robotics)：评估传感器模拟，但不确定其是否与字符识别集成。

考虑到可用的工具，我正在考虑从头开始构建自定义 IMU 模拟器是否是该项目的更好选择。这有意义吗，还是我应该调整现有工具？]]></description>
      <guid>https://stackoverflow.com/questions/79094646/building-a-9-axis-imu-simulator-for-character-recognition-guidance-needed</guid>
      <pubDate>Wed, 16 Oct 2024 14:56:51 GMT</pubDate>
    </item>
    <item>
      <title>如何实现自动保存功能以及加载训练？</title>
      <link>https://stackoverflow.com/questions/79094181/how-to-implement-an-auto-save-feature-and-also-loading-for-training</link>
      <description><![CDATA[我住在一个每周停电 2-3 次的小镇。我正在训练一个手语识别模型，众所周知，它需要一些时间才能完成（我使用 RTX 2060 6gb VRAM）。我想实现一个保存和加载功能（当我恢复时），这样我就不会从头开始。
我试过 chatgpt（请不要评判我），但它没有用。它只是从顶部重新开始。
这是我的完整 python 代码的 url：
https://paste bin.com/raw/Z8iDS6fB]]></description>
      <guid>https://stackoverflow.com/questions/79094181/how-to-implement-an-auto-save-feature-and-also-loading-for-training</guid>
      <pubDate>Wed, 16 Oct 2024 13:05:20 GMT</pubDate>
    </item>
    <item>
      <title>在远程服务器上运行 ML 模型会引发错误，但在本地运行良好[重复]</title>
      <link>https://stackoverflow.com/questions/79093993/running-ml-model-on-remote-server-throws-error-works-fine-locally</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79093993/running-ml-model-on-remote-server-throws-error-works-fine-locally</guid>
      <pubDate>Wed, 16 Oct 2024 12:18:34 GMT</pubDate>
    </item>
    <item>
      <title>最近的 Windows 更新后，WSL 上的 H2O 出现连接被拒绝错误</title>
      <link>https://stackoverflow.com/questions/79091245/connection-refused-error-with-h2o-on-wsl-after-recent-windows-update</link>
      <description><![CDATA[在最近的 Windows 更新后，我在 Windows Subsystem for Linux (WSL) 上运行 H2O 时遇到了连接问题。以下是问题的详细分析以及我迄今为止采取的故障排除步骤：
系统信息：

操作系统：带有 WSL 的 Windows（Linux 内核版本 5.15.153.1-microsoft-standard-WSL2）
WSL 发行版：Ubuntu 24.04
Java 版本：Java 11.0.24
Python 版本：使用 Python 3.7、3.9、3.10、3.11 和 3.12 测试
Anaconda 版本：Anaconda3-2024.06-1-Linux-x86_64
H2O 版本：3.42.0.2 至 3.46.0.5

问题描述：
当我使用 Python 中的 h2o.init() 在 WSL 上启动 H2O 时，它会尝试形成一个大小为 2 的云，包括 10.255.255.254:54321 处的节点，但失败并出现“连接被拒绝”错误。此问题不会发生在装有 Ubuntu 操作系统的专用 PC 上。
采取的步骤：

强制本地连接：使用 h2o.init(ip=&quot;127.0.0.1&quot;, port=54321,
force_connect=True) 确保 H2O 仅在本地运行。没有成功。

网络配置：已验证没有防火墙设置阻止必要的端口。暂时禁用防火墙，但问题仍然存在。

WSL 配置：使用 wsl --update 确保 WSL 是最新的。
重新启动 WSL 和机器，但问题仍然存在。

H2O 配置：检查可能指示
H2O 连接到其他节点的配置。将 H2O 设置为仅使用本地 IP
127.0.0.1。

日志分析：查看了各种 H2O 日志，所有日志都表明与节点 10.255.255.254:54321 存在相同的连接错误。

连接测试：使用 python3 -m http.server
54321 测试了连接，并且能够从 WSL 外部访问服务器而不会出现问题。

与 Ubuntu 笔记本电脑的比较：在运行原生 Ubuntu 的笔记本电脑上，
H2O 运行正常，表明问题特定于 WSL。


附加信息：
直到 2024 年 5 月，H2O 在我的系统上运行良好。自上次运行以来，唯一的变化是保持 Windows 和 WSL 更新。该问题于 2024 年 9 月 20 日左右被发现。
什么原因可能导致此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79091245/connection-refused-error-with-h2o-on-wsl-after-recent-windows-update</guid>
      <pubDate>Tue, 15 Oct 2024 18:14:42 GMT</pubDate>
    </item>
    <item>
      <title>训练T5时如何添加EOS？</title>
      <link>https://stackoverflow.com/questions/79088393/how-to-add-eos-when-training-t5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79088393/how-to-add-eos-when-training-t5</guid>
      <pubDate>Tue, 15 Oct 2024 04:22:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ppo 加快 python 国际象棋机器人的训练时间？</title>
      <link>https://stackoverflow.com/questions/78337397/how-can-i-speed-up-my-training-time-for-a-python-chess-bot-using-ppo</link>
      <description><![CDATA[我正在尝试构建一个使用近端策略优化进行学习的国际象棋机器人。我目前使用 python-chess 库 (https://python-chess.readthedocs.io/en/latest/index.html#) 作为我的代理与自己对弈并学习的环境。我面临的问题是训练游戏速度极慢。每场游戏的移动限制为 200，我的机器人可以在大约 1 秒内与自己对弈 1 场。这 1 秒还包括训练的 PPO 部分，使用 GPU 平均需要 0.01 秒。
我正在使用 PyTorch，所以我已经将所有张量移至 GPU。除此以外，我还没有找到任何其他方法来加快执行时间。
我希望将玩游戏的执​​行时间缩短到每场游戏 0.5 秒或更短，但我还没有找到实现这一目标的方法。
如果有人知道可能的解决方案，我将非常感谢您的反馈和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78337397/how-can-i-speed-up-my-training-time-for-a-python-chess-bot-using-ppo</guid>
      <pubDate>Tue, 16 Apr 2024 21:27:24 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch transforms.Compose 在分割任务中用于图像对的用法</title>
      <link>https://stackoverflow.com/questions/66284850/pytorch-transforms-compose-usage-for-pair-of-images-in-segmentation-tasks</link>
      <description><![CDATA[我尝试在分割任务中使用 transforms.Compose()。但我不确定如何对图像和蒙版使用相同的（几乎）随机变换。
因此，在我的分割任务中，我有原始图片和相应的蒙版，我想生成更多随机变换的图像对来训练 popurse。这意味着如果我对原始图片进行一些变换，并且这种变换也应该发生在我的蒙版图片上，那么这对就可以进入我的 CNN。我的转换器是这样的：
train_transform = transforms.Compose([
transforms.Resize(512), # 调整大小，较小的边缘将被匹配。
transforms.RandomHorizo​​ntalFlip(p=0.5),
transforms.RandomVerticalFlip(p=0.5),
transforms.RandomRotation(90),
transforms.RandomResizedCrop(320,scale=(0.3, 1.0)),
AddGaussianNoise(0., 1.),
transforms.ToTensor(), # 将 PIL 图像或 ndarray 转换为张量。
transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # 标准化为 Imagenet 平均值和标准差
])

mask_transform = transforms.Compose([
transforms.Resize(512), # 调整大小，较小的边缘将被匹配。
transforms.RandomHorizo​​ntalFlip(p=0.5),
transforms.RandomVerticalFlip(p=0.5),
transforms.RandomRotation(90),
transforms.RandomResizedCrop(320,scale=(0.3, 1.0)),
##---------------------!------------------
transforms.ToTensor(), # 将 PIL 图像或 ndarray 转换为张量。
transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # 标准化为 Imagenet 平均值和标准差
])


请注意，在代码块中，我添加了一个可以向原始图像转换添加随机噪声的类，该类不在 mask_transformation 中，我希望我的蒙版图像遵循原始图像转换，但忽略随机噪声。那么这两个转换如何成对发生（具有相同的随机行为）？]]></description>
      <guid>https://stackoverflow.com/questions/66284850/pytorch-transforms-compose-usage-for-pair-of-images-in-segmentation-tasks</guid>
      <pubDate>Fri, 19 Feb 2021 20:52:30 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 中 model.eval() 起什么作用？</title>
      <link>https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch</link>
      <description><![CDATA[我什么时候应该使用 .eval()？我理解它应该允许我“评估我的模型”。我如何关闭它进行训练？
使用 .eval() 的示例训练代码。]]></description>
      <guid>https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch</guid>
      <pubDate>Sat, 01 Feb 2020 15:58:15 GMT</pubDate>
    </item>
    <item>
      <title>每个类别至少应该有多少张图像用于训练 YOLO？</title>
      <link>https://stackoverflow.com/questions/55356982/how-many-imagesminimum-should-be-there-in-each-classes-for-training-yolo</link>
      <description><![CDATA[我正在尝试在自定义数据集上实现 YOLOv2。每个类别所需的最低图像数量是多少？]]></description>
      <guid>https://stackoverflow.com/questions/55356982/how-many-imagesminimum-should-be-there-in-each-classes-for-training-yolo</guid>
      <pubDate>Tue, 26 Mar 2019 12:18:21 GMT</pubDate>
    </item>
    <item>
      <title>具有不同基础学习器的 AdaBoostClassifier</title>
      <link>https://stackoverflow.com/questions/18306416/adaboostclassifier-with-different-base-learners</link>
      <description><![CDATA[我尝试将 AdaBoostClassifier 与 DecisionTree 以外的基础学习器一起使用。我尝试过 SVM 和 KNeighborsClassifier，但出现错误。哪些分类器可以与 AdaBoostClassifier 一起使用？]]></description>
      <guid>https://stackoverflow.com/questions/18306416/adaboostclassifier-with-different-base-learners</guid>
      <pubDate>Mon, 19 Aug 2013 04:31:25 GMT</pubDate>
    </item>
    <item>
      <title>Python 中聊天机器人的数据库[关闭]</title>
      <link>https://stackoverflow.com/questions/13731441/db-for-chatbot-in-python</link>
      <description><![CDATA[我正在编写一个聊天机器人，试图模拟某种对话。作为 Python 新手，我目前依靠列表和字典来对一组标准查询做出一些标准响应。随着我学习的深入，我意识到列表/字典/函数是不够的，我必须使用某种数据库。目前，当我遇到用户的新问题时，我只是不断向列表/字典中添加项目。
我应该使用哪个数据库来存储/查询用户的数据？我浏览了这个及其后续链接，但在答案中，我没有找到使用哪个数据库的提及。（我的这个小项目旨在自学机器学习和 NLP 的概念）]]></description>
      <guid>https://stackoverflow.com/questions/13731441/db-for-chatbot-in-python</guid>
      <pubDate>Wed, 05 Dec 2012 20:02:56 GMT</pubDate>
    </item>
    </channel>
</rss>