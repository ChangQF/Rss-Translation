<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 30 Jul 2024 06:22:02 GMT</lastBuildDate>
    <item>
      <title>我想将一个预先训练好的 ANN 模型连接到另一个 ANN 模型，并循环一起训练它们</title>
      <link>https://stackoverflow.com/questions/78810038/i-want-to-connect-a-pre-trained-ann-model-to-another-ann-model-and-train-them-to</link>
      <description><![CDATA[我正在研究一个逆问题。我想将预训练的前向 ANN 模型与逆模型结合起来，以估计最佳设计参数（逆模型的输出）。
我知道逆模型的输出应该用作预训练的前向模型的输入，但我坚持固定前向模型的初始参数并同时训练两个模型。
我曾尝试分别设计两个模型，然后分别训练它们，这导致逆模型对设计参数的估计稀疏。]]></description>
      <guid>https://stackoverflow.com/questions/78810038/i-want-to-connect-a-pre-trained-ann-model-to-another-ann-model-and-train-them-to</guid>
      <pubDate>Tue, 30 Jul 2024 06:13:44 GMT</pubDate>
    </item>
    <item>
      <title>CVAE 合成数据分布范围过窄</title>
      <link>https://stackoverflow.com/questions/78809995/cvae-synthetic-data-distributed-too-narrowly</link>
      <description><![CDATA[我有一个包含三个特征的数据集，两个浮点特征和一个具有 33 个类别的分类特征。（此处称为 Float_A、Float_B 和 Cat_A）。
我正在尝试训练 CVAE 以生成合成数据。使用以下 sklearn 转换器转换数据：
df=df[[&quot;float_A&quot;,&quot;float_B&quot;,&quot;categorical_A&quot;]]

transformers=[(&#39;float_A&#39;,Pipeline(steps=[(&#39;imputer&#39;,SimpleImputer(strategy=&#39;mean&#39;,add_indicator=True)),
(&#39;scaler&#39;,RobustScaler(quantile_range=(5,95)))]),
[&#39;float_A&#39;]),
(&#39;float_B&#39;,
Pipeline( steps=[(&#39;imputer&#39;,SimpleImputer(strategy=&#39;mean&#39;,add_indicator=True)),
(&#39;scaler&#39;,MinMaxScaler())]),
[&#39;float_B&#39;]),
(&#39;cats&#39;,OneHotEncoder(),categorical_columns)]`

transformer=ColumnTransformer(transformers,remainder=&#39;passthrough&#39;)

transformed_df=transformer.fit_transform(df)

我的第二个浮点数有一个 S 形激活函数，声明如下：
`Def sample(self,z):
reconstructed=self.decoder(z)
# 将 S 形激活应用于浮点数特征。
reconstructed[:,self.float_B_idx]=torch.sigmoid(reconstructed[:,self.float_B_idx])
returnreconstructed

Def forward(self,x):
z_mean,z_log_var=torch.chunk(self.encoder(x),2,dim=1)
z=self.reparameterize(z_mean,z_log_var)
reconstructed=self.decoder(z)
#将 sigmoid 激活应用于浮点特征。
reconstructed[:,self.float_B_idx]=torch.sigmoid(reconstructed[:,self.float_B_idx])
return reconstructed,z_mean,z_log_var`

一旦 CVAE 经过训练（训练和验证损失似乎按应有的方式减少），我尝试使用以下方法生成随机样本：
random_latent_vectors=torch.randn(num_samples,latent_dim)

使用 torch.no_grad()：
gen_df=model.sample(random_latent_vectors).detach().cpu().numpy()


但是 gen_df 中的所有样本都非常“未展开”。
FloatA、FloatB、 Cat[0:2]…

[[0.11782782 0.286538 0.646666 0.266387 0.09747571]
[0.0963359 0.29775462 0.58443785 0.29296008 0.1101962]
[0.1300626 0.31274286 0.59086925 0.30710378 0.10169853]
[0.1232817 0.32317564 0.56470346 0.29102385 0.11446829]
[0.13240162 0.28100765 0.6230704 0.29497638 0.08924796]]

然后，当我在 gen_df 上调用 scaler.inverse_transform 时，我几乎在每一行上都得到了相同的结果。
我尝试了各种方法，我的一个类别非常占主导地位（~90%），因此使用 imblearn 进行了一些类别不平衡欠采样，使其仅占 50% 的主导地位，但仍然获得 100% 的样本。
我尝试为我的 CVAE 添加更多层和复杂性，但再次被证明是徒劳的。]]></description>
      <guid>https://stackoverflow.com/questions/78809995/cvae-synthetic-data-distributed-too-narrowly</guid>
      <pubDate>Tue, 30 Jul 2024 05:57:45 GMT</pubDate>
    </item>
    <item>
      <title>RNN 建模数据准备</title>
      <link>https://stackoverflow.com/questions/78809490/rnn-modelling-data-preparation</link>
      <description><![CDATA[我正在准备用于 rnn 模型的顺序数据，但我将时间数据放在不同的列中，其中天数格式为 0 表示工作日，1 表示周末。时间是否应采用单一数据格式列以用于模型？
此外，我应该如何准备数据以计算与传感器数据的距离。我添加了数据和距离问题的屏幕截图。
在此处输入图片说明在此处输入图片说明]]></description>
      <guid>https://stackoverflow.com/questions/78809490/rnn-modelling-data-preparation</guid>
      <pubDate>Tue, 30 Jul 2024 01:26:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么要将 TorchServe 或 NVIDIA Triton 与 AWS SageMaker 结合使用？</title>
      <link>https://stackoverflow.com/questions/78809430/why-use-torchserve-or-nvidia-triton-with-aws-sagemaker</link>
      <description><![CDATA[我正在研究不同的 ML 和深度学习模型部署策略。我的公司已经在使用 AWS SageMaker，我们正在寻找一种可以容纳深度学习模型集合的部署解决方案。
根据我的研究，SageMaker 似乎已经支持多模型端点、多容器端点等方法。SageMaker 还支持 TorchServe 和 NVIDIA Triton 服务器作为部署解决方案。
我的问题是...如果 SageMaker 已经提供了许多不同的方法，为什么有人会将 TorchServe 或 Triton 与 SageMaker 一起使用？我们用 PyTorch 编写所有内容，因此我们不需要 TensorFlow 支持。我公司的领导确信 NVIDIA Triton（带有 Merlin）是最佳选择，因为它具有强大的 API、清晰的集成文档以及与 NVIDIA GPS 配合使用的能力。我很难找到一个明确的“赢家”在所有这些不同的技术中（我也听说过 Cortex 和其他技术）。
有人能解释一下这些不同解决方案的优缺点吗？特别是，为什么除了使用 SageMaker 之外，还会有人使用 TorchServe 之类的东西？（或者除了 SageMaker 之外还会使用 Triton）。其中一种或另一种是否能更快地执行推理，等等。我已经对这个主题进行了大量研究，包括在这个网站上，但似乎没有什么确凿的数据表明这些选择中有一个“赢家”。]]></description>
      <guid>https://stackoverflow.com/questions/78809430/why-use-torchserve-or-nvidia-triton-with-aws-sagemaker</guid>
      <pubDate>Tue, 30 Jul 2024 00:44:48 GMT</pubDate>
    </item>
    <item>
      <title>TFLM“Interpreter->Invoke()”问题导致硬故障</title>
      <link>https://stackoverflow.com/questions/78808999/issues-with-tflm-interpreter-invoke-causing-hard-fault</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78808999/issues-with-tflm-interpreter-invoke-causing-hard-fault</guid>
      <pubDate>Mon, 29 Jul 2024 20:48:04 GMT</pubDate>
    </item>
    <item>
      <title>训练和验证拆分导致 PyTorch 数据集中某些类别的样本为零</title>
      <link>https://stackoverflow.com/questions/78808028/train-and-validation-splits-result-in-zero-samples-for-some-classes-in-pytorch-d</link>
      <description><![CDATA[我正在使用 PyTorch 进行图像分类。我的数据集是目录格式。我已经设置了数据增强管道和模型。当我将数据集拆分为训练和验证时，我遇到了一个问题，其中某些类在训练或验证拆分中都没有样本。以下是我通过扩展 PyTorch Dataset 类实现的 Dataset 类：
class CustomDataset(Dataset):
def __init__(self, root_dir, transform=None):
self.root_dir = root_dir
self.transform = transform
self.classes = os.listdir(root_dir)
self.image_paths = []
self.labels = []

for label, class_name in enumerate(self.classes):
class_dir = os.path.join(root_dir, class_name)
for img_path in glob.glob(os.path.join(class_dir, &#39;*.png&#39;)) + \
glob.glob(os.path.join(class_dir, &#39;*.jpg&#39;)) + \
glob.glob(os.path.join(class_dir, &#39;*.jpeg&#39;)):
self.image_paths.append(img_path)
self.labels.append(label)

def __len__(self):
return len(self.image_paths)

def __getitem__(self, idx):
img_path = self.image_paths[idx]
image = Image.open(img_path).convert(&#39;RGB&#39;)
label = self.labels[idx]

if self.transform:
image = self.transform(image)
else:
image = transforms.ToTensor()(image) # 如果未提供变换，则将 PIL 图像转换为张量

return image, label

class AugmentedDataset(Dataset):
def __init__(self, base_dataset, transforms_list):
self.base_dataset = base_dataset
self.transforms_list = transforms_list if isinstance(transforms_list, list) else [transforms_list]

def __len__(self):
return len(self.base_dataset) * len(self.transforms_list)

def __getitem__(self, idx):
base_idx = idx // len(self.transforms_list)
transform_idx = idx % len(self.transforms_list)

image, label = self.base_dataset[base_idx]
transform = self.transforms_list[transform_idx]

if transform:
image = transform(image)

return image, label

训练和测试拆分按如下方式完成：
base_dataset = CustomDataset(train_dir, v2.Compose(basic_transformations))

train_size = int(0.8 * len(base_dataset))
val_size = len(base_dataset) - train_size

train_base_dataset, val_dataset = random_split(base_dataset, [train_size, val_size])
train_dataset = AugmentedDataset(train_base_dataset, augmentations)
val_dataset = AugmentedDataset(train_base_dataset, v2.Compose(final_transformation))

trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

执行拆分后，我注意到某些类在训练或验证数据集中没有样本。

为什么 pytorch random_split 会出现这种情况方法？
有哪些最佳实践可以确保训练集和验证集中所有类别的平衡分割？
是否有任何特定技术或库可用于在分割期间保持类别平衡？

这是我的笔记本：EfficientNet with Augmentation]]></description>
      <guid>https://stackoverflow.com/questions/78808028/train-and-validation-splits-result-in-zero-samples-for-some-classes-in-pytorch-d</guid>
      <pubDate>Mon, 29 Jul 2024 15:51:51 GMT</pubDate>
    </item>
    <item>
      <title>Catboost 特征重要性计算</title>
      <link>https://stackoverflow.com/questions/78807931/catboost-feature-importance-calculation</link>
      <description><![CDATA[我仅用 3 棵树拟合了一个简单二分类模型，并想检查特征重要性结果是否与 Catboost 文档 (PredictionValuesChange) 中的公式相似。
训练模型后，我按照CatBoost JSON 模型教程中的步骤操作，并得到了以下树结构：
{
&quot;leaf_values&quot;: [
-0.13915912880676032,
0.1097787155963716
],
&quot;leaf_weights&quot;: [
2143.0251545906067,
2252.974784851074
],
&quot;splits&quot;: [
{
&quot;border&quot;: 3.5,
&quot;float_feature_index&quot;: 13,
&quot;split_index&quot;: 0,
&quot;split_type&quot;: &quot;FloatFeature&quot;
}
]
} 

模型中的每棵树只有深度 = 1，并且只有一棵树（索引 = 1）具有感兴趣的特征。我决定根据上述公式手动计算特征重要性，并将结果与​​ .get_feature_importance 方法进行比较。结果大不相同：

特征重要性：28.2947825
手动计算：68.06248029261762

以下是用于特征重要性计算的代码：
tree_indx = 1
v_1 = model[&#39;oblivious_trees&#39;][tree_indx][&#39;leaf_values&#39;][0]
v_2 = model[&#39;oblivious_trees&#39;][tree_indx][&#39;leaf_values&#39;][1]

c_1 = model[&#39;oblivious_trees&#39;][tree_indx][&#39;leaf_weights&#39;][0]
c_2 = model[&#39;oblivious_trees&#39;][tree_indx][&#39;leaf_weights&#39;][1]

avr = (v_1*c_1 + v_2*c_2)/(c_1+c_2)

fi = ((v_1 - avr)**2)*c_1 + ((v_2 - avr)**2)*c_2
print(fi)

我犯了错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78807931/catboost-feature-importance-calculation</guid>
      <pubDate>Mon, 29 Jul 2024 15:29:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 和计算机视觉检测图像中的人是否赤裸上身？[关闭]</title>
      <link>https://stackoverflow.com/questions/78806780/how-to-detect-if-a-person-is-shirtless-in-an-image-using-python-and-computer-vis</link>
      <description><![CDATA[我有一个数据集，其中包含一个人的多张自拍照，每张都是从胸部以上拍摄的，格式为自拍。我的目标是识别每张照片中的人是否赤裸上身。这些照片并不露骨，而是随意的自拍照，照片中的人可能穿着也可能没穿着衬衫。
由于我没有太多数据，我认为从头开始训练神经网络模型不是最好的选择——我的数据集不是那么大。
有什么指导或建议吗？
我曾尝试使用 Python 中的 NSFW-Detector 库（https://pypi.org/project/nsfw-detector/），但它没有太大帮助，因为它专注于检测露骨内容，而不是识别一个人是否赤裸上身。]]></description>
      <guid>https://stackoverflow.com/questions/78806780/how-to-detect-if-a-person-is-shirtless-in-an-image-using-python-and-computer-vis</guid>
      <pubDate>Mon, 29 Jul 2024 11:19:21 GMT</pubDate>
    </item>
    <item>
      <title>将 Onnx 模型与 javafx 集成 [关闭]</title>
      <link>https://stackoverflow.com/questions/78805706/integrating-onnx-model-with-javafx</link>
      <description><![CDATA[我试图将 onnx 模型集成到 javafx 中，我尝试连接从 scikit-learn 保存的 onnx 文件，但没有成功，一直提示找不到文件的错误
我尝试将 javafx 代码与调试器连接以验证文件是否可用，结果显示 onnx 文件存在。但如果我尝试运行应用程序，它会提示找不到 onnx 文件的错误[代码路径图像在这里][显示错误代码的图像]]]></description>
      <guid>https://stackoverflow.com/questions/78805706/integrating-onnx-model-with-javafx</guid>
      <pubDate>Mon, 29 Jul 2024 06:43:34 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降应用</title>
      <link>https://stackoverflow.com/questions/78804107/gradient-descent-application</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78804107/gradient-descent-application</guid>
      <pubDate>Sun, 28 Jul 2024 15:15:45 GMT</pubDate>
    </item>
    <item>
      <title>PipeOp classif.avg (mlr3) 错误：对“prob”的断言失败：包含缺失值（元素 1）</title>
      <link>https://stackoverflow.com/questions/78763091/error-with-pipeop-classif-avg-mlr3-assertion-on-prob-failed-contains-missi</link>
      <description><![CDATA[当我运行代码时，该代码在堆叠学习器（glmnet 和 rpart）上执行特征选择和超参数调整，我收到以下错误消息：
assert_binary(truth, prob = prob, positive = positive, na_value = na_value) 中出错：
“prob”上的断言失败：包含缺失值（元素 1）。
这发生在 PipeOp classif.avg 的 $train()

但是，当我使用 classif.debug 时，预测中没有 NA。任何建议都将不胜感激。
注意：我简化了要调整的参数数量和要选择的特征数量，以减少执行时间，现在使用 classif.debug 只需 15 秒。
这是我的数据：https://www.dropbox.com/scl/fi/hkjs79i89gjz0j5mjlbj8/Data.csv?rlkey=08yuzet3mjr9gcezkryo93vqm&amp;st=hfv2cbeo&amp;dl=0
这是我的代码：
set.seed(1)
data &lt;- read.csv(&quot;C:/Users/Marine/Downloads/Data.csv&quot;)
data &lt;- data[,c(&quot;x&quot;, &quot;y&quot;, &quot;presence&quot;, &quot;V01&quot;, &quot;V02&quot;)]
## dim(data)
data$presence &lt;- as.factor(data$presence)
##摘要（数据）
任务 &lt;- mlr3spatial::as_task_classif_st（x = 数据，目标 = “存在”，正 = “1”，坐标名称 = c（“x”，“y”），crs = “+proj=longlat +datum=WGS84 +no_defs +type=crs”）
摘要（任务）

learner_glmnet &lt;- mlr3::lrn（“classif.glmnet”，预测类型 = “prob”，s = 0.01）
learner_rpart &lt;- mlr3::lrn（“classif.rpart”，预测类型 = “prob”，cp = to_tune（1e-04，1e-1，对数尺度 = TRUE))
learner_glmnet_cv &lt;- mlr3pipelines::PipeOpLearnerCV$new(learner = learner_glmnet, id = &quot;glmnet_cv&quot;, param_vals = list(resampling.method = &quot;cv&quot;, resampling.folds = 2))
learner_rpart_cv &lt;- mlr3pipelines::PipeOpLearnerCV$new(learner = learner_rpart, id = &quot;rpart_cv&quot;, param_vals = list(resampling.method = &quot;cv&quot;, resampling.folds = 2))

learner_avg &lt;- mlr3pipelines::LearnerClassifAvg$new(id = &quot;classif.avg&quot;)
learner_avg$predict_type &lt;- &quot;prob&quot;
learner_avg$param_set$values$measure &lt;- &quot;classif.auc&quot;

learner_debug &lt;- lrn(&quot;classif.debug&quot;, predict_type = &quot;prob&quot;)

level_0_graph &lt;- mlr3pipelines::gunion(list(learner_glmnet_cv, learner_rpart_cv)) %&gt;&gt;% mlr3pipelines::po(&quot;featureunion&quot;)
level_0_and_1_graph &lt;- level_0_graph %&gt;&gt;% learner_avg
## level_0_and_1_graph &lt;- level_0_graph %&gt;&gt;% learner_debug
level_0_and_1_graph_learner &lt;- mlr3::as_learner(level_0_and_1_graph)

tuning &lt;- mlr3tuning::auto_tuner(tuner = mlr3tuning::tnr(&quot;grid_search&quot;), 
learner = level_0_and_1_graph_learner,
resampling = mlr3::rsmp(&quot;cv&quot;, folds = 2),
measure = mlr3::msr(&quot;classif.auc&quot;),
terminator = mlr3tuning::trm(&quot;evals&quot;, n_evals = 2, k = 0))

feature_selection &lt;- mlr3fselect::auto_fselector(fselector = mlr3fselect::fs(&quot;sequence&quot;, strategies = &quot;sfs&quot;, min_features = 2),
learner = tuning,
resampling = mlr3::rsmp(&quot;cv&quot;, folds = 2),
measure = mlr3::msr(&quot;classif.auc&quot;),
terminator = mlr3tuning::trm(&quot;evals&quot;, n_evals = 2, k = 0))

system.time(stacking &lt;- mlr3::resample(task = task, 
learner = feature_selection, 
resampling = mlr3::rsmp(&quot;cv&quot;, folds = 2),
store_models = TRUE))

测试 &lt;- as.data.table(stacking$prediction())
which(is.na(test))
测试 &lt;- as.data.table(stacking$predictions()[[1]])
which(is.na(test))
测试 &lt;- as.data.table(stacking$predictions()[[2]])
which(is.na(test))
]]></description>
      <guid>https://stackoverflow.com/questions/78763091/error-with-pipeop-classif-avg-mlr3-assertion-on-prob-failed-contains-missi</guid>
      <pubDate>Thu, 18 Jul 2024 07:56:11 GMT</pubDate>
    </item>
    <item>
      <title>Python OpenCV - 显示坏点检查测试</title>
      <link>https://stackoverflow.com/questions/75924341/python-opencv-display-bad-pixels-inspection-test</link>
      <description><![CDATA[我想找到显示器中存在的每个坏像素。坏像素可能是颜色不正确的像素，也可能是黑色的像素。显示器的尺寸为 160x320 像素。因此，如果显示器良好，则必须有 160*320 = 51200 像素。如果显示器没有 51200 像素，则为坏像素。另外，我想知道每个坏像素的位置。
一旦拍摄的图像太大，我将共享一个 Google Drive 共享文件夹，其中包含良好显示器和包含坏像素的坏显示器的示例。
显示图像
您能帮我怎么做吗？我想在 python 中使用 opencv 来做这件事。
提前感谢
我尝试通过检测到的物体的轮廓进行评估，并且只有在所有像素都存在的情况下才有效。如果缺少一个像素并且没有检测到轮廓，我可以知道缺少了一个像素，但我无法知道它的位置。
所以我认为最好的解决方案是跟踪网格并评估网格的每个单元。
这是我当前的代码：
import cv2
import numpy as np
import matplotlib.pyplot as plt

def getColor(area):
if area &gt; 70:
return (255, 0, 0)
if area &lt; 14:
返回 (0, 0, 255)
返回 (255, 255, 0)

def test_green_pattern():

mask = cv2.imread(&quot;masks/mask.bmp&quot;, 0)
green = cv2.imread(&quot;images/green-good.bmp&quot;)

green_W = cv2.addWeighted(green, 3, green, 0, 1)

gray = cv2.cvtColor(green_W, cv2.COLOR_BGR2GRAY)

masked = cv2.bitwise_and(gray, gray, mask=mask)
cv2.imwrite(&quot;try/green-masked.bmp&quot;, masked)
# 真实阈值 = 120
ret, thresh = cv2.threshold(masked, 120, 255，cv2.THRESH_BINARY)
cv2.imwrite(&quot;try/green-threshold.bmp&quot;, thresh)

轮廓，层次结构 = cv2.findContours(thresh，cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_NONE)
print(&quot;绿色图案像素：&quot;，len(轮廓))
区域 = []
周长 = []
坏 = 0
prob_double = 0
qtd = 0
对于 i，轮廓在枚举(轮廓)中：
区域 = 区域 = cv2.contourArea(轮廓)
区域.append(区域)
周长 = cv2.arcLength(轮廓，True)
周长.append(周长)
颜色 = getColor(区域)

如果区域 &lt; 14： 
bad += 1
qtd += 1
x, y, width, height = cv2.boundingRect(contour)
roi = green[y:y+height, x:x+width]
cv2.imwrite(&quot;try/temp/&quot;+str(i)+&quot;.bmp&quot;, roi) 
cv2.drawContours(green, contour, -1, color, 1)
cv2.drawContours(green_W, contour, -1, color, 1)
如果 area &gt; 90: 
prob_double += 1
qtd += 2
cv2.drawContours(green, contour, -1, color, 1)
cv2.drawContours(green_W, contour, -1, color, 1)
else:
qtd += 1
#get_statistics(areas, perimeters)
print(&quot;总计:&quot;,qtd)
print(&quot;可能是双像素:&quot;, prob_double)
print(&quot;坏像素:&quot;, bad)
cv2.imwrite(&quot;try/green-contours.bmp&quot;, green)
cv2.imwrite(&quot;try/green_w-contours.bmp&quot;, green_W)

test_green_pattern()
]]></description>
      <guid>https://stackoverflow.com/questions/75924341/python-opencv-display-bad-pixels-inspection-test</guid>
      <pubDate>Mon, 03 Apr 2023 23:06:55 GMT</pubDate>
    </item>
    <item>
      <title>Intel MacBook 上的 VNGeneratePersonSegmentationRequest 速度缓慢</title>
      <link>https://stackoverflow.com/questions/72810091/vngeneratepersonsegmentationrequest-slow-on-intel-macbooks</link>
      <description><![CDATA[我有一个非常简单的功能，它尝试使用 VNGeneratePersonSegmentationRequest 和 VNImageRequestHandler 从网络摄像头视频流中删除背景。
在配备 M1 处理器的 Mac 电脑上，效果很好（60-120 fps 没有任何问题）。在 MacBook Pro Intel i7 2.7GHz 和 Intel Iris Plus Graphics 655 上使用相同的代码/应用程序，性能只有 10 fps，低得多。
这是使用的代码：
let personSegmentationRequest = VNGeneratePersonSegmentationRequest()
personSegmentationRequest.qualityLevel = .balanced
let imageRequestHandler = VNImageRequestHandler(ciImage: ciImage) // 来自摄像头的一帧

尝试？ imageRequestHandler.perform([personSegmentationRequest])
guard let result = personSegmentationRequest.results?.first else {
return nil
}

有什么想法吗？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/72810091/vngeneratepersonsegmentationrequest-slow-on-intel-macbooks</guid>
      <pubDate>Thu, 30 Jun 2022 03:44:54 GMT</pubDate>
    </item>
    <item>
      <title>iOS 视觉框架 - 无法在 VNDetectHumanBodyPoseRequest 中设置请求</title>
      <link>https://stackoverflow.com/questions/70473725/ios-vision-framework-unable-to-setup-request-in-vndetecthumanbodyposerequest</link>
      <description><![CDATA[我使用 VNDetectHumanBodyPoseRequest 从 xcode 资源中的图像中检测身体（我从图像网站下载），但出现以下错误：

2021-12-24 21:50:19.945976+0800 Guess My Exercise[91308:4258893] [espresso] [Espresso::handle_ex_plan] exception=Espresso exception: &quot;I/O error&quot;: Missing weights path cnn_human_pose.espresso.weights status=-2
无法执行请求：错误域=com.apple.vis 代码=9 &quot;无法在 VNDetectHumanBodyPoseRequest 中设置请求&quot; UserInfo={NSLocalizedDescription=无法在 VNDetectHumanBodyPoseRequest 中设置请求}。

以下是我的代码：
 let image = UIImage(named: &quot;image2&quot;)
guard let cgImage = image?.cgImage else{return}

let requestHandler = VNImageRequestHandler(cgImage: cgImage)

let request = VNDetectHumanBodyPoseRequest(completionHandler: bodyPoseHandler)

do {
// 执行身体姿势检测请求。
try requestHandler.perform([request])
} catch {
print(&quot;无法执行请求：\(error).&quot;)
}

func bodyPoseHandler(request: VNRequest, error: Error?) {
guard let surveillance =
request.results as? [VNHumanBodyPoseObservation] else {
return
}

let poses = Pose.fromObservations(observations)

self.drawPoses(poses, onto: self.simage!)
// 处理每个观察结果以找到已识别的身体姿势点。
}
]]></description>
      <guid>https://stackoverflow.com/questions/70473725/ios-vision-framework-unable-to-setup-request-in-vndetecthumanbodyposerequest</guid>
      <pubDate>Fri, 24 Dec 2021 14:08:04 GMT</pubDate>
    </item>
    <item>
      <title>KerasRegressor 判定系数 R^2 得分</title>
      <link>https://stackoverflow.com/questions/45250100/kerasregressor-coefficient-of-determination-r2-score</link>
      <description><![CDATA[我正在 Keras 中构建一个用于回归任务的小型神经网络，我想使用与 scikit-learn RandomForestRegressor 相同的准确度指标：

系数 R^2 定义为 (1 - u/v)，其中 u 是回归平方和 ((y_true - y_pred) ** 2).sum()，v 是残差平方和 ((y_true - y_true.mean()) ** 2).sum()。

这是一个方便的指标，因为它显示的值高达 1.0（类似于分类中的百分比准确度）。我对 Keras 后端的使用是否正确，是否符合我想要的准确度指标？
def create_model():
model = Sequential()
model.add(Dense(10, input_dim=X.shape[1],activation=&quot;relu&quot;))
model.add(Dense(10,activation=&quot;relu&quot;))
model.add(Dense(1))

# 编译模型
model.compile(loss=&quot;mean_squared_error&quot;, optimizer=&quot;adam&quot;,metrics=[det_coeff])
return model

# 这是正确的计算吗？
def det_coeff(y_true, y_pred):
u = K.sum(K.square(y_true - y_pred))
v = K.sum(K.square(y_true - K.mean(y_true)))
return K.ones_like(v) - (u / v)

这似乎有效，因为没有任何错误，并且度量随着时间的推移而增加到 1，但我想确保我正确实施了度量。]]></description>
      <guid>https://stackoverflow.com/questions/45250100/kerasregressor-coefficient-of-determination-r2-score</guid>
      <pubDate>Sat, 22 Jul 2017 02:35:34 GMT</pubDate>
    </item>
    </channel>
</rss>