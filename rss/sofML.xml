<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 12 Feb 2025 12:33:10 GMT</lastBuildDate>
    <item>
      <title>Chatgpt 与 AI 代理的角色文件进行聊天 [关闭]</title>
      <link>https://stackoverflow.com/questions/79432203/chatgpt-chats-to-character-file-for-ai-agents</link>
      <description><![CDATA[我正在使用 Eliza 框架构建 AI 代理。有没有办法让我利用我的 chatgpt 聊天来创建角色文件或相应地训练代理。]]></description>
      <guid>https://stackoverflow.com/questions/79432203/chatgpt-chats-to-character-file-for-ai-agents</guid>
      <pubDate>Wed, 12 Feb 2025 06:57:36 GMT</pubDate>
    </item>
    <item>
      <title>在 Colab 中对大型数据集使用 train_test_split 时 RAM 崩溃</title>
      <link>https://stackoverflow.com/questions/79430737/ram-crash-when-using-train-test-split-on-large-dataset-in-colab</link>
      <description><![CDATA[我正在开展一个情绪分析项目，该项目有一个包含 160,000 行嵌入评论的大型数据集。
当我使用 sklearn.model_selection 中的 train_test_split() 时，Google Colab 中的 RAM 会被完全占用，并且会话会崩溃。
如何减少 RAM 使用量以防止崩溃？
是否有任何替代或优化的方法来拆分如此大的数据集？]]></description>
      <guid>https://stackoverflow.com/questions/79430737/ram-crash-when-using-train-test-split-on-large-dataset-in-colab</guid>
      <pubDate>Tue, 11 Feb 2025 16:47:15 GMT</pubDate>
    </item>
    <item>
      <title>如何从 PDF 中提取表格并将其转换为结构化 HTML (<table>、<tr>、<td>)，同时保持原始布局和格式？</title>
      <link>https://stackoverflow.com/questions/79430117/how-to-extract-tables-from-a-pdf-and-convert-them-into-structured-html-table</link>
      <description><![CDATA[1]Doc1 的原始页面包含 4 个表格
1]Doc1 的输出 .html 页面无法正确检测表格，有时会将表格中的文本提取为纯文本
2]Doc2 的原始页面在表格单元格中包含图像
2]Doc2 的输出 .html 页面，无法正确处理嵌入图像的复杂表格&amp; 有时，对于简单的表格，.html 文件中的结构也不正确
我正在从 PDF 文件中提取内容并将其转换为 HTML 格式，同时保持原始结构和格式。我为此使用了 Docling 库。
我在 .html 文件中获得了与原始 PDF 文件内容流相同的输出。但是，我在输出 HTML 文件中保留表格结构时遇到了问题。
我期望发生的情况：

从 PDF 中提取具有正确行和列结构的表格。

保留 &lt;table&gt;、&lt;tr&gt; 和 &lt;td&gt; HTML 标记中的表格布局。

保持 PDF 中显示的原始格式、对齐方式和单元格内容。


实际发生的情况：

表格检测不正确 - 表格数据显示在 &lt;p&gt; 标记内，而不是正确的 &lt;table&gt;结构。

表格未对齐 - 单元格内容拆分不正确，并且表格单元格内的图像出现在表格外部。

嵌入图像的复杂表格无法正确保存。


使用的代码：
来自 docling.document_converter 导入 DocumentConverter、PdfFormatOption
来自 docling.datamodel.pipeline_options 导入 PdfPipelineOptions
来自 docling.datamodel.base_models 导入 InputFormat
来自 docling_core.types.doc 导入 ImageRefMode
来自 pathlib 导入 Path
导入日志记录

# 设置日志记录
logging.basicConfig(level=logging.INFO)
log = logs.getLogger(__name__) # 已更正：_name_ ——&gt; __name__

# 配置图像设置
IMAGE_RESOLUTION_SCALE = 2.0

# PDF 文件的路径
source = Path(r&quot;C:\Users\Downloads\Journal.pdf&quot;)
output_path = Path(r&quot;C:\Users\Desktop\output20.html&quot;)

# 配置用于图像处理的管道选项
pipeline_options = PdfPipelineOptions()
pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE
pipeline_options.generate_page_images = True
pipeline_options.generate_picture_images = True

# 使用图像选项创建转换器实例
converter = DocumentConverter(
format_options={
InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
}
)

# 将 PDF 转换为文档
result = converter.convert(source)

# 保存嵌入图像的 HTML
result.document.save_as_html(output_path, image_mode=ImageRefMode.EMBEDDED)

log.info(f&quot;嵌入图像的 HTML 文件创建于：{output_path}&quot;)

我目前尝试过的方法：

检查提取的 HTML 输出 — 表格缺失或显示不正确。

尝试了 PdfPipelineOptions() 中的不同管道选项，看看它们是否影响表格提取。

将输出与文档智能库进行比较 — 它可以更好地提取页眉/页脚，但仍难以处理复杂的表格。


关键挑战：

表格未保留在 &lt;table&gt; 标签中。

单元格拆分问题 - 数据未对齐或拆分成多个部分。

表格内的图像位置错误（出现在上方/下方，而不是表格单元格内）。


其他观察：

提取的 HTML 文件中的内容流与原始 PDF 文件**匹配，但**表格结构格式不正确。

问题：
如何正确从 PDF 中提取表格并将其转换为结构化 HTML（&lt;table&gt;、&lt;tr&gt;、 &lt;td&gt;) 同时使用 Docling 库保持原有的布局和格式？]]></description>
      <guid>https://stackoverflow.com/questions/79430117/how-to-extract-tables-from-a-pdf-and-convert-them-into-structured-html-table</guid>
      <pubDate>Tue, 11 Feb 2025 13:21:50 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost bst.predict() 输出与二进制：逻辑案例的（文本）树模型的手动计算不匹配</title>
      <link>https://stackoverflow.com/questions/79430043/xgboost-bst-predict-output-not-matching-with-manual-calculation-from-the-text</link>
      <description><![CDATA[我试图验证 XGBoost 输出 (booster.predict) 的逻辑回归，以了解我对通过构建的树进行输出计算的理解。我发现所有结果的差异约为 -1.58 倍。下面分享我用来验证的代码。我肯定遗漏了一些东西，所以请求帮助我理解它是什么。
import xgboost as xgb
import pandas as pd
import numpy as np
import math
import random
np.random.seed(1)

data = pd.DataFrame(np.arange(100*4).reshape((100,4)), columns=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
label = pd.DataFrame(np.random.randint(2, size=(100,1)))
data = pd.concat([data,label], ignore_index=True, axis =1)
data = pd.DataFrame(np.arange(100*4).reshape((100,4)), columns=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;])
features = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]

dtrain = xgb.DMatrix(data, label=label)
param = {&quot;max_depth&quot;:2, &quot;base_score&quot;:0.2, &#39;objective&#39;: &#39;binary:logistic&#39;}
clf1 = xgb.train(param, dtrain, 2)
clf1.dump_model(&quot;base_score1.txt&quot;)

e = math.exp(-(-0.143835619-0.123642519+0.2))
print(clf1.predict(dtrain)[0],1/(1+e))
## 0.39109966 0.7583403831446165
## 理想情况下，e 的值应该是1.5568930331924702，而这里 e 是 0.31866905973448423

这是生成的树
booster[0]:
0:[a&lt;126] yes=1,no=2,missing=1
1:[a&lt;58] yes=3,no=4,missing=3
3:leaf=0.617647052
4:leaf=0.0483870991
2:leaf=0.691919208
booster[1]:
0:leaf=0.325955093

所以我的理解是 bst.predict() 输出应用于总和的 sigmoid tree_values 和 base_score，即 1/(1+math.exp(-sum))，其中 sum = base_score+sum_of_tree_values（即有多少棵树）。
我做错了什么？
这可能相关，但不确定使用 &quot;binary:logistic&quot; 时 XGBoost 中单个树的权重计算]]></description>
      <guid>https://stackoverflow.com/questions/79430043/xgboost-bst-predict-output-not-matching-with-manual-calculation-from-the-text</guid>
      <pubDate>Tue, 11 Feb 2025 12:55:07 GMT</pubDate>
    </item>
    <item>
      <title>我该如何解决“RuntimeError：张量 a（64）的大小必须与非单例维度 1 处的张量 b（6）的大小匹配”？</title>
      <link>https://stackoverflow.com/questions/79429107/how-can-i-resolve-runtimeerror-the-size-of-tensor-a-64-must-match-the-size-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79429107/how-can-i-resolve-runtimeerror-the-size-of-tensor-a-64-must-match-the-size-o</guid>
      <pubDate>Tue, 11 Feb 2025 06:48:18 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习和 NER 自动进行网页抓取以提取产品数据</title>
      <link>https://stackoverflow.com/questions/79426509/automating-web-scraping-with-machine-learning-and-ner-for-product-data-extractio</link>
      <description><![CDATA[我目前正在做数据和人工智能实习。我的工作是通过从制造商的网站上检索信息（产品名称、图片、描述、零件编号/SKU、技术规格、数据表等）来构建产品数据库。
挑战在于有超过 300 家不同的制造商，每家都有自己的网站和结构，这使得传统的网页抓取不切实际且难以维护。为了克服这个问题，我正在考虑使用人工智能和机器学习来使我的抓取代理能够适应每个页面 HTML 结构的变化。
我已经下载并手动标记了 50 个产品页面。以下是我的数据集：
 # 列 非空 计数 Dtype 
--- ------ -------------- ----- 
0 text 52 非空对象
1 product_name 49 非空对象
2 html_product_name 51 非空对象
3 image_url 50 非空对象
4 html_image_url 50 非空对象
5 description 32 非空对象
6 html_description 51 非空对象
7 part_number 35 非空对象
8 html_part_number 36 非空对象
9 html_specification 44 非空对象
10 datasheet_url 40 非空对象
11 html_datasheet_url 41 非空对象
12 specifications 2 非空对象

文本列包含产品页面的清理后的 HTML，而其他列则表示目标字段——需要识别和提取的 HTML 的特定部分。
这个问题看起来与命名实体识别 (NER) 非常相似。我如何训练机器学习模型以成功从原始 HTML 中提取这些字段？最好的方法是什么（例如，微调转换器模型、序列标记或其他方法）？
提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/79426509/automating-web-scraping-with-machine-learning-and-ner-for-product-data-extractio</guid>
      <pubDate>Mon, 10 Feb 2025 08:46:11 GMT</pubDate>
    </item>
    <item>
      <title>Deepseek huggingface 模型加载问题</title>
      <link>https://stackoverflow.com/questions/79424312/deepseek-huggingface-model-loading-issue</link>
      <description><![CDATA[我正在使用 huggingface 中的这段代码：
这段代码直接粘贴自 HuggingFace 网站的 deepseek 页面，应该是即插即用的代码：
from transformers import pipeline

messages = [
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Who are you?&quot;},
]
pipe = pipeline(&quot;text-generation&quot;, model=&quot;deepseek-ai/DeepSeek-R1&quot;, trust_remote_code=True)
pipe(messages)

但我无法加载模型。当我这样做时，我遇到了这个问题：
文件 &lt;...&gt;/site-packages/transformers/quantizers/auto.py&quot;，第 97 行，在 from_dict 中
raise ValueError(

ValueError：未知量化类型，获得 fp8 - 支持的类型是：
[&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39;, 
&#39;hqq&#39;, &#39;compressed-tensors&#39;, &#39;fbgemm_fp8&#39;, &#39;torchao&#39;, &#39;bitnet&#39;]

我尝试了不同的代码：
import torch
generate_text = pipeline(model=&quot;deepseek-ai/DeepSeek-R1&quot;,torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=&quot;auto&quot;)
generate_text(messages)

这会出现以下错误：
raise ValueError( ValueError: 未知量化类型，获得 fp8 - 支持的类型为：[&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39;, &#39;higgs&#39;, &#39;hqq&#39;, &#39;compressed-tensors&#39;, &#39;fbgemm_fp8&#39;, &#39;torchao&#39;, &#39;bitnet&#39;, &#39;vptq&#39;]
我能做什么做什么？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/deepseek-huggingface-model-loading-issue</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中U型网络上下采样阶段不同连接维数参数</title>
      <link>https://stackoverflow.com/questions/79422978/different-concate-dimension-parameters-in-the-up-and-down-sampling-phase-of-u-sh</link>
      <description><![CDATA[我得到的错误是
 文件 &quot;/media/xd/hdd/wxy/spectraldiff_diffusion-master/codes/unet3d.py&quot;，第 113 行，在正向
x = torch.cat((x, residual_x), dim=1) 
RuntimeError：除维度 1 外，张量的大小必须匹配。预期大小为 24，但列表中张量编号 1 的大小为 25。

模型输入的训练数据集为PaviaU。
调试后发现问题的输出向量如下：
down = torch.Size([4, 64, 25, 64, 64])
up = torch.Size([4, 64, 24, 64, 64])

整体代码如下：
def forward(self, x, timestep, feature=False):
# Embedd time
t = self.time_mlp(timestep)
# Initial conv
x = self.conv0(x)
# Unet
residual_inputs = []
for down in self.downs:
x = down(x, t)
residual_inputs.append(x)
for up in self.ups:
residual_x = residual_inputs.pop()
# print(&quot;down​​=&quot;,residual_x.shape, &quot;up=&quot;, x.shape)
# 将残差 x 添加为附加通道
x = torch.cat((x, residual_x), dim=1)* 
if feature:
self.features.append(x.detach().cpu().numpy())
x = up(x, t)
return self.output(x)
]]></description>
      <guid>https://stackoverflow.com/questions/79422978/different-concate-dimension-parameters-in-the-up-and-down-sampling-phase-of-u-sh</guid>
      <pubDate>Sat, 08 Feb 2025 10:14:34 GMT</pubDate>
    </item>
    <item>
      <title>为什么我必须将数据从 torch.Size([50]) 解压到 torch.Size([50, 1])</title>
      <link>https://stackoverflow.com/questions/79409149/why-do-i-have-to-unsqueeze-the-data-from-torch-size50-to-torch-size50-1</link>
      <description><![CDATA[我正在学习 FreeCodeCamp 的 PyTorch 深度学习课程，疑问是：
weight = 0.7
bias = 0.3
start = 0
end = 1
step = 0.02

X = torch.arange(start, end, step).unsqueeze(dim=1)
y=weight*X + bias
X[:10], y[:10]
train_split=int(0.8*len(X))
X_train, y_train = X[:train_split], y[:train_split]
X_test, y_test=X[train_split:], y[train_split:]

为什么使用 unsqueeze 函数生成大小为 [50, 1] 的张量，而不是 [50]？导师说这会导致错误，但我不知道为什么会发生错误？
你能用数学和基本原理回答这个问题吗？
尝试训练模型后，我收到此错误：
class LinearRegressionModelv2(nn.Module):
def __init__(self):
super().__init__()
self.linear_layer = nn.Linear(in_features=1, out_features=1)

def forward(self, x: torch.Tensor) -&gt; torch.Tensor:
return self.linear_layer(x)

torch.manual_seed(42)
model_v2 = LinearRegressionModelv2()

y_prediction = model_v2(X_train)
IndexError: 维度超出范围（预期在 [-1, 0] 范围内，但结果为 -2）]]></description>
      <guid>https://stackoverflow.com/questions/79409149/why-do-i-have-to-unsqueeze-the-data-from-torch-size50-to-torch-size50-1</guid>
      <pubDate>Mon, 03 Feb 2025 14:44:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么MobileNet V2模型（mobilenet_v2_1.4_224.tflite）的概率总是相同的？</title>
      <link>https://stackoverflow.com/questions/79281349/why-are-the-probabilities-always-the-same-with-mobilenet-v2-model-mobilenet-v2</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79281349/why-are-the-probabilities-always-the-same-with-mobilenet-v2-model-mobilenet-v2</guid>
      <pubDate>Sat, 14 Dec 2024 20:23:10 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：编码器要求其输入为统一的字符串或数字。得到 ['int', 'str']</title>
      <link>https://stackoverflow.com/questions/71193740/typeerror-encoders-require-their-input-to-be-uniformly-strings-or-numbers-got</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/71193740/typeerror-encoders-require-their-input-to-be-uniformly-strings-or-numbers-got</guid>
      <pubDate>Sun, 20 Feb 2022 11:04:02 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的数据注释</title>
      <link>https://stackoverflow.com/questions/61742408/data-annotation-for-machine-learning</link>
      <description><![CDATA[我将开发一个机器学习模型。我有大量数据集（文本）。我需要总体上更准确的 F1 分数等。我正在使用数据注释工具（Dataturks）。哪种方法适合将数据标记为每个实体单个标签或每个实体多个标签（例如有 5 次 GUI，因此我们必须标记 1 次或 5 次以获得更好的总体分数）。非常感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/61742408/data-annotation-for-machine-learning</guid>
      <pubDate>Tue, 12 May 2020 01:47:23 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归曲线不以我的数据为中心</title>
      <link>https://stackoverflow.com/questions/57862633/logistic-regression-curve-not-centered-with-my-data</link>
      <description><![CDATA[我正在做一个学校项目，使用逻辑回归进行二元分类，结果非常糟糕（准确率约为 50%）。我不得不从头开始进行分类，所以我担心我的实现存在问题。
我用一个预测变量拟合了一个模型，并绘制了得到的逻辑曲线，发现它以 0 为中心，超出了我的数据范围（预测变量范围为 50 - 90）。因此，只有逻辑曲线的渐近线在我的数据范围内，因此将所有示例归为同一类。
我以为使用截距权重可以解决这个问题，但在我的例子中并没有。我也考虑过将我的数据标准化并以 0 为中心，但我希望有更直接的方法。
有什么建议吗？
编辑 - 这是我的实现
class LogisticRegression: 

def __init__(self, alpha, iters, except=True): 
self.alpha = alpha 
self.iters = iters 
self.weights = None 
self.intercept = except 

def sigmoid(self, z): 
return 1.0 / (1 + np.exp(-z)) 

def add_intercept(self, X): 
except = np.ones((X.shape[0], 1)) 
return np.concatenate((intercept, X), axis=1) 

def cost(self, h, y): 
return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean() 

def fit(self, X, y): 

if self.intercept: 
X = self.add_intercept(X) 

self.weights = np.zeros(X.shape[1]) 

for i in range(self.iters): 
z = np.dot(X, self.weights) 
h = self.sigmoid(z) 
gradient = np.dot(X.T, (h - y)) / len(y) 
self.weights -= self.alpha * gradient 

编辑 - 数据链接：https://raw.githubusercontent.com/efosler/cse5522data/master/height_vs_weight.csv
目标是某人是否打篮球，而我用于单回归的特征是身高。
我现在认为无论如何我都必须规范化我的数据，因为在多元回归案例中，np.exp() 出现了一些溢出。]]></description>
      <guid>https://stackoverflow.com/questions/57862633/logistic-regression-curve-not-centered-with-my-data</guid>
      <pubDate>Tue, 10 Sep 2019 00:34:07 GMT</pubDate>
    </item>
    <item>
      <title>错误“无法将字符串转换为浮点数：‘INLAND’”</title>
      <link>https://stackoverflow.com/questions/55332339/error-could-not-convert-string-to-float-inland</link>
      <description><![CDATA[我正在做一个使用机器学习进行房价预测的项目，想提交给一家私人公司申请。
我正在为这个项目使用 Jupiter 笔记本，但我无法修复有关将字符串转换为数值数据的错误
from sklearn.model_selection import train_test_split
X_train,X_test, Y_train, Y_test= train_test_split(X,
Y,
test_size=0.2,
random_state=0)
from sklearn.preprocessing import StandardScaler
independent_scalar = StandardScaler()
X_train = independent_scalar.fit_transform (X_train) #fit 和 transform
X_test = independent_scalar.transform (X_test) # only transform
print(X_train)

我希望训练集数据完全是数值的]]></description>
      <guid>https://stackoverflow.com/questions/55332339/error-could-not-convert-string-to-float-inland</guid>
      <pubDate>Mon, 25 Mar 2019 06:33:59 GMT</pubDate>
    </item>
    <item>
      <title>新闻文章聚类</title>
      <link>https://stackoverflow.com/questions/25228219/clustering-of-news-articles</link>
      <description><![CDATA[我的情况很简单：我有一堆新闻文章（目前约 1k 篇），我知道其中一些文章涵盖了相同的故事/主题。我现在想根据共同的故事/主题对这些文章进行分组，即根据它们的相似性。
到目前为止，我所做的是应用基本的 NLP 技术，包括停用词删除和词干提取。我还计算了每篇文章的 tf-idf 向量，并且还可以基于这些 tf-idf 向量计算余弦相似度。但现在对文章进行分组有点困难。我看到了两种主要方法——可能相关——来做到这一点：
1) 机器学习/聚类：我已经对现有的聚类库进行了一些尝试，或多或少取得了成功；请参阅此处。一方面，k-means 等算法需要簇数作为输入，而我不知道。其他算法需要的参数也不直观（对我来说是这样）。
2) 图形算法：我可以将我的数据表示为图形，其中文章是节点，加权边表示文章之间的成对（余弦）相似性。例如，我可以先删除所有低于某个阈值的边，然后可以应用图形算法来寻找强连通子图。
简而言之，我不确定从这里开始最好去哪里——我在这个领域还很新。我想知道是否存在一些最佳实践，或者某些指导方针，说明哪些方法/算法可以（不）应用于某些场景。
（编辑：忘记链接到我的相关问题）]]></description>
      <guid>https://stackoverflow.com/questions/25228219/clustering-of-news-articles</guid>
      <pubDate>Sun, 10 Aug 2014 11:39:05 GMT</pubDate>
    </item>
    </channel>
</rss>