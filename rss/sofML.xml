<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 04 Jan 2024 21:13:07 GMT</lastBuildDate>
    <item>
      <title>如何使用带有 haar 级联的网络摄像头查找人员的参与度。我有一些材料可以找到它。需要帮助</title>
      <link>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades-i</link>
      <description><![CDATA[因此，我正在建立一个网站，在编写考试时跟踪用户，以了解他们的参与程度，并为此找到了这篇有趣的论文。
https://www.sciencedirect .com/science/article/pii/S0045790621002597?ref=cra_js_challenge&amp;fr=RR-1
我想使用 opencv 和 tensorflow 构建完全相同的模型。有人可以帮我完成模型吗？我是机器学习领域的新手。刚刚建立了一些回归和分类模型。任何帮助都会非常有帮助。我无法理解如何从上述论文中计算聚焦概率。我希望了解如何构建模型以及如何计算值的详细步骤。
数据集链接：
FER 2013：https://www.kaggle.com/datasets/msambare/fer2013&lt; /a&gt;
MES数据集：https://github.com/Harsh9524/MES-Dataset
我已经使用 haar 级联检测到人脸并且它正在工作。下一个问题是找出情绪，我也做到了！但问题在于寻找 MES 和焦点概率。请帮我解决一下。]]></description>
      <guid>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades-i</guid>
      <pubDate>Thu, 04 Jan 2024 20:42:19 GMT</pubDate>
    </item>
    <item>
      <title>SetFit 训练未完成评估步骤</title>
      <link>https://stackoverflow.com/questions/77760620/setfit-training-not-finishing-evaluation-step</link>
      <description><![CDATA[我正在尝试使用 SetFit 训练简单的二元分类，但我的库有问题。我使用 Huggingface 来管理我的数据集。数据集由文本和标签列组成。如果我打印我的数据集，它看起来像这样：
dataset = load_dataset(“&lt;我的数据集&gt;”)
打印（数据集）

输出：
DatasetDict({
    火车：数据集（{
        特征：[&#39;文本&#39;，&#39;标签&#39;]，
        行数：20
    })
    评估：数据集（{
        特征：[&#39;文本&#39;，&#39;标签&#39;]，
        行数：10
    })
    测试：数据集（{
        特征：[&#39;文本&#39;，&#39;标签&#39;]，
        行数：135
    })
})

这是我的培训代码：
# 使用预训练模型初始化 SetFit 模型并定义标签名称
模型 = SetFitModel.from_pretrained(
    “释义-多语言-mpnet-base-v2”，
    标签=[“阴性”,“阳性”],
）

# 定义训练参数
args = 训练参数(
    批量大小=32，
    num_epochs=8,
    evaluation_strategy=“纪元”，
    save_strategy=“纪元”,
    load_best_model_at_end=True
）

# 初始化训练器
教练=教练（
    型号=型号，
    参数=参数，
    train_dataset=数据集[“火车”],
    eval_dataset=数据集[“eval”],
    度量=“准确度”，
    column_mapping={&quot;text&quot;: &quot;text&quot;, &quot;label&quot;: &quot;label&quot;} # 将数据集列映射到训练器期望的文本/标签
）

# 训练模型
训练师.train()

但是我现在遇到的问题是训练行为非常奇怪。我没有受到任何培训或验证损失，评估步骤也没有完成。我不知道问题出在哪里。

另请注意，我稍微更改了参数以提高训练速度。它通常有更多的步骤等等。使用正常参数时它仍然表现得很奇怪。我还使用 SetFit 1.0.1 版本。我在 GitHub 存储库中没有发现任何与此相关的问题。]]></description>
      <guid>https://stackoverflow.com/questions/77760620/setfit-training-not-finishing-evaluation-step</guid>
      <pubDate>Thu, 04 Jan 2024 19:02:49 GMT</pubDate>
    </item>
    <item>
      <title>Juptyer spacy 未下载</title>
      <link>https://stackoverflow.com/questions/77760407/juptyer-spacy-not-downloading</link>
      <description><![CDATA[在此处输入图像描述我是个菜鸟，在下载时遇到问题Jupyter Notebook 中的宽敞库。
我已经运行 !pip install spacy 并不断收到此错误，类似于之后运行
!python3 -m spacy 下载 en_core_web_sm
请帮忙。
我尝试在网上寻找 Soultion，但 gpt 一直让我陷入困境]]></description>
      <guid>https://stackoverflow.com/questions/77760407/juptyer-spacy-not-downloading</guid>
      <pubDate>Thu, 04 Jan 2024 18:18:33 GMT</pubDate>
    </item>
    <item>
      <title>Cora 数据集中的节点特征</title>
      <link>https://stackoverflow.com/questions/77760163/node-features-in-the-cora-dataset</link>
      <description><![CDATA[我正在使用具有节点特征的 Cora 数据集。在这个数据集中，每个节点特征都是一个长度为1433的向量，表示字典中第i个单词是否出现在文档中的0-1热编码。
我已经打印出了几个节点（文档）有多少个 1（即出现了多少个不同的单词），而且数量相对较小，大约 18-20 个。

这是否意味着每个文档在字典中只有大约 20 个单词？我想知道节点特征是如何构造的以及这看起来是否正确。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77760163/node-features-in-the-cora-dataset</guid>
      <pubDate>Thu, 04 Jan 2024 17:31:58 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试训练 2D nn 和 1D nn 时出现错误。 Epoch 1/10，UnimplementedError：图形执行错误</title>
      <link>https://stackoverflow.com/questions/77760031/im-getting-an-error-when-i-try-to-train-my-2d-conv-nn-and-1d-conv-nn-epoch-1-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77760031/im-getting-an-error-when-i-try-to-train-my-2d-conv-nn-and-1d-conv-nn-epoch-1-1</guid>
      <pubDate>Thu, 04 Jan 2024 17:09:04 GMT</pubDate>
    </item>
    <item>
      <title>不完全理解梯度是如何计算的。我的计算（手工）和约定的梯度公式是不同的</title>
      <link>https://stackoverflow.com/questions/77759064/dont-fully-understand-how-gradients-are-to-be-calculated-my-calculation-by-ha</link>
      <description><![CDATA[我正在尝试实现一个多层感知器，而不使用任何外部库来获得反向传播的直觉。我现在可以自信地说我理解了这个算法。但问题是：我试图手动推导出所有梯度计算方程，但它们并不成立。他们错了。
为了获得更多上下文，我使用交叉熵损失。
例如：
loss = -np.sum(true_labels * np.log(outputs)) / m

然后我们计算这个损失相对于输出的梯度，如下所示：
&lt;预&gt;&lt;代码&gt;dz2 = (1/m) * (-标签/Z2)

但是我在任何地方看到这个特定的梯度都是由以下给出的：
dz2 = Z2 - 标签

我不会进入下一个渐变，因为我认为一旦我明白我在这里做错了什么，这将是解锁其余部分的关键。
更多背景信息：正在 MNIST 数据集、10 个类、1 个隐藏层上进行训练。]]></description>
      <guid>https://stackoverflow.com/questions/77759064/dont-fully-understand-how-gradients-are-to-be-calculated-my-calculation-by-ha</guid>
      <pubDate>Thu, 04 Jan 2024 14:36:45 GMT</pubDate>
    </item>
    <item>
      <title>将大型语料库中的 n 元模型加载到集合中时如何避免内存问题</title>
      <link>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</link>
      <description><![CDATA[我一直在尝试实现一种无监督学习算法，该算法根据从语料库中提取的特定特征来匹配相似性。一个用例是作者识别。该算法的工作方式是从训练语料库中提取不同类型的 n-gram，然后每个作者都会获得一个“指纹”。基于文章中出现的 n 元语法。
为此，我首先需要收集训练语料库中存在的所有 n 元语法。这就是我遇到内存问题的地方，我一直在使用 Yelp 评论数据，并且在某些时候我的程序由于内存限制而崩溃。我尝试过存储中间结果，然后将 n-gram 加载到最终集合中，以避免我的稀疏计算中出现任何潜在的内存泄漏问题，但这也失败了，看来该集合太大了。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</guid>
      <pubDate>Thu, 04 Jan 2024 12:00:51 GMT</pubDate>
    </item>
    <item>
      <title>输出 AR@0.5 和 AR@0.75</title>
      <link>https://stackoverflow.com/questions/77747981/output-ar0-5-and-ar0-75</link>
      <description><![CDATA[使用 pycocotools，当提供地面实况注释文件和预测边界框文件时，我们可以针对 AP@0.5 和 AP@0.75 等指标以及其他不同指标评估预训练模型的对象检测性能。但pycocotools不输出AR@0.5和AR@0.75。它输出不同的 AR 变体，但我特别需要这两个。是否有可以评估这些指标的代码或库？]]></description>
      <guid>https://stackoverflow.com/questions/77747981/output-ar0-5-and-ar0-75</guid>
      <pubDate>Tue, 02 Jan 2024 18:47:09 GMT</pubDate>
    </item>
    <item>
      <title>如何将 model.safetensor 转换为 pytorch_model.bin？</title>
      <link>https://stackoverflow.com/questions/77708996/how-to-convert-model-safetensor-to-pytorch-model-bin</link>
      <description><![CDATA[我正在微调预训练的 bert 模型，但遇到了一个奇怪的问题：
当我使用 CPU 进行微调时，代码会像这样保存模型：

使用“pytorch_model.bin”。但是当我使用 CUDA（我必须这样做）时，模型会像这样保存：

当我尝试加载这个“model.safetensors”时将来，它会引发错误“pytorch_model.bin”未找到。我使用两个不同的 venv 来测试 CPU 和 CUDA。
如何解决这个问题？是版本问题吗？
我正在使用sentence_transformers框架来微调模型。
这是我的训练代码：
检查点 = &#39;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#39;

word_embedding_model = models.Transformer(checkpoint,cache_dir=f&#39;model/{checkpoint}&#39;)
pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), pooling_mode=&#39;mean&#39;)
模型 = SentenceTransformer(模块=[word_embedding_model, pooling_model], device=&#39;cuda&#39;)


train_loss = 损失.CosineSimilarityLoss(模型)

evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(val_examples, name=&#39;sbert&#39;)

model.fit(train_objectives=[(train_dataloader, train_loss)]，epochs=5，evaluator=evaluator，show_progress_bar=True，output_path=f&#39;model_FT/{checkpoint}&#39;，save_best_model=True)

我确实在两个不同的环境中尝试了测试，我希望代码能够保存一个“pytorch_model.bin”文件。不是“model.safetensors”。
编辑：我真的还不知道，但似乎是新版本的 Transformer 库导致了这个问题。我发现使用拥抱脸可以加载安全张量，但使用句子转换器（我需要使用）则不能。]]></description>
      <guid>https://stackoverflow.com/questions/77708996/how-to-convert-model-safetensor-to-pytorch-model-bin</guid>
      <pubDate>Sat, 23 Dec 2023 20:43:20 GMT</pubDate>
    </item>
    <item>
      <title>MLFLOW 工件存储在 ftp 服务器上但未显示在 ui 中</title>
      <link>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</link>
      <description><![CDATA[我在远程跟踪服务器上训练期间使用 MLFLOW 存储一些参数和指标。现在我还尝试添加一个 .png 文件作为工件，但由于 MLFLOW 服务器远程运行，我将该文件存储在 ftp 服务器上。我通过以下方式提供了 ftp 服务器地址和 MLFLOW 路径：
mlflow 服务器 --backend-store-uri sqlite:///mlflow.sqlite --default-artifact-root ftp://user:password@1.2.3.4/artifacts/ --host 0.0.0.0 &amp;

现在我训练一个网络并通过运行来存储工件：
mlflow.set_tracking_uri(remote_server_uri)
mlflow.set_experiment(“默认”)
mlflow.pytorch.autolog()

使用 mlflow.start_run()：
    mlflow.log_params(flow_params)
    训练师.fit(模型)
    训练师.test()
    mlflow.log_artifact(“confusion_matrix.png”)
mlflow.end_run()

我将 .png 文件保存在本地，然后使用 mlflow.log_artifact(“confusion_matrix.png”) 将其记录到 ftp 服务器中与实验对应的右侧文件夹中。到目前为止，一切正常，只是该工件没有显示在在线 mlflow ui 中。记录的参数和指标正常显示。工件面板保持空白，仅显示
未记录任何工件
使用日志工件 API 存储 MLflow 运行的文件输出。

我发现了类似的线程，但仅限于在本地 mlflow 存储上遇到相同问题的用户。不幸的是，我无法将这些修复应用于我的问题。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</guid>
      <pubDate>Tue, 10 Aug 2021 14:15:42 GMT</pubDate>
    </item>
    <item>
      <title>这是one-hot编码吗？</title>
      <link>https://stackoverflow.com/questions/50579544/is-this-one-hot-encoding</link>
      <description><![CDATA[阅读：
http://scikit-learn.org/stable /modules/ generated/sklearn.preprocessing.LabelEncoder.html
它指出“使用 one-hot 又名 one-of-K 方案对分类整数特征进行编码。”
这是否也意味着它对单词列表进行一次性编码？
摘自维基百科定义 ( https://en.wikipedia.org/wiki/One-hot  ) 一种热门编码
“在自然语言处理中，one-hot 向量是一个 1 × N 矩阵（向量），用于区分词汇表中的每个单词和词汇表中的每个其他单词。该向量在所有单元格中均由 0 组成，除了单个单元格之外单元格中的 1 专门用于标识该单词。”
在下面运行代码，LabelEncoder 不是一种热编码的正确实现，而 OneHotEncoder 是一种正确的实现：
将 numpy 导入为 np
从 sklearn.preprocessing 导入 MultiLabelBinarizer
从 numpy 导入数组
从 numpy 导入 argmax
从 sklearn.preprocessing 导入 LabelEncoder
从 sklearn.preprocessing 导入 OneHotEncoder

# 定义示例
数据 = [&#39;w1 w2 w3&#39;, &#39;w1 w2&#39;]

值=数组（数据）
label_encoder = LabelEncoder()
integer_encoded = label_encoder.fit_transform(值)

# 二进制编码
onehot_encoder = OneHotEncoder（稀疏=假）
整数编码 = 整数编码.reshape(len(整数编码), 1)

mlb = MultiLabelBinarizer()

print(&#39;fit_transform\n&#39; , mlb.fit_transform(data))
print(&#39;\none hot\n&#39; , onehot_encoder.fit_transform(integer_encoded))

打印：

&lt;前&gt;&lt;代码&gt;fit_transform
 [[1 1 1 1 1]
 [1 1 1 0 1]]

一热
 [[0。 1.]
 [1. 0.]]

那么 LabelEncoder 不是 one-hot 编码，LabelEncoder 使用的编码类型是什么？ 
从上面的输出来看，OneHotEncoder 生成的向量比 LabelEncoder 的编码方案更密集。
更新：
如何决定使用 LabelEncoder 还是 OneHotEncoder 对机器学习算法的数据进行编码？]]></description>
      <guid>https://stackoverflow.com/questions/50579544/is-this-one-hot-encoding</guid>
      <pubDate>Tue, 29 May 2018 08:19:50 GMT</pubDate>
    </item>
    <item>
      <title>命名实体识别 (NER) 功能</title>
      <link>https://stackoverflow.com/questions/42001875/named-entity-recognition-ner-features</link>
      <description><![CDATA[我是命名实体识别的新手，在理解此任务使用哪些功能/如何使用功能时遇到一些困难。 
到目前为止我读过的一些论文提到了所使用的功能，但并没有真正解释它们，例如
CoNLL-2003共享任务简介：与语言无关的命名实体识别，具有以下功能提到：

&lt;块引用&gt;
  参与此次测试的十六个系统使用的主要功能
  CoNLL-2003 共享任务按英语测试数据的表现排序。
  Aff：词缀信息（n-gram）； bag：词袋； CAS：全球案例
  信息; chu：块标签； doc：全局文档信息；天然气：
  地名词典； lex：词汇特征； ort：正字法信息；拍：
  正交图案（如 Aa0）； pos：词性标签；前：
  先前预测的 NE 标签； quo：标记该词的签名
  引号之间； tri：触发词。

但是，我对其中的一些内容有点困惑。例如：

词袋不应该是一种生成特征（每个单词一个）的方法吗？ BOW 本身如何成为一个功能？或者这只是意味着除了提到的所有其他功能之外，我们还为 BOW 中的每个单词提供了一个功能？
地名词典如何成为一项功能？
POS标签到底如何作为特征使用？我们不是每个单词都有一个 POS 标签吗？每个对象/实例不都是一个“文本”吗？
什么是全局文档信息？
功能触发词是什么？

我认为我在这里所需要的只是查看一个示例表，其中每个功能都作为列，并查看它们的值以了解它们的实际工作原理，但到目前为止我还没有找到一个易于阅读的数据集。 
有人可以澄清或指出一些正在使用的功能的解释或示例吗？]]></description>
      <guid>https://stackoverflow.com/questions/42001875/named-entity-recognition-ner-features</guid>
      <pubDate>Thu, 02 Feb 2017 12:08:09 GMT</pubDate>
    </item>
    <item>
      <title>分类与回归？</title>
      <link>https://stackoverflow.com/questions/33908127/classification-vs-regression</link>
      <description><![CDATA[我不太清楚分类和回归之间有什么区别。
据我了解，分类是绝对的。要么是这个，要么是那个。
回归更多的是一种预测。


上面的两个问题都更像是回归问题，对吧？它都是使用学习算法来预测。谁能举一个分类与回归的例子吗？]]></description>
      <guid>https://stackoverflow.com/questions/33908127/classification-vs-regression</guid>
      <pubDate>Wed, 25 Nov 2015 03:41:55 GMT</pubDate>
    </item>
    <item>
      <title>处理来自不同文档的相同单词</title>
      <link>https://stackoverflow.com/questions/22159351/handling-same-words-but-from-different-documents</link>
      <description><![CDATA[我正在创建一个 python 类，它计算文档中每个单词的 tfidf 权重。现在我的数据集中有 50 个文档。在这些文档中，许多单词相交，因此具有多个相同的单词特征但具有不同的 tfidf 权重。所以问题是如何将所有权重汇总为一个单独的权重？]]></description>
      <guid>https://stackoverflow.com/questions/22159351/handling-same-words-but-from-different-documents</guid>
      <pubDate>Mon, 03 Mar 2014 22:58:00 GMT</pubDate>
    </item>
    <item>
      <title>文档特征向量表示</title>
      <link>https://stackoverflow.com/questions/12046213/document-features-vector-representation</link>
      <description><![CDATA[我正在构建一个文档分类器来对文档进行分类。
所以第一步是将每个文档表示为“特征向量”用于培训目的。
经过一些研究，我发现我可以使用词袋方法或 N-gram 方法将文档表示为向量。
每个文档（扫描的 pdf 和图像）中的文本都是使用 OCR 检索的，因此某些单词包含错误。而且我之前不了解这些文档中使用的语言（无法使用词干分析）。
据我所知，我必须使用 n-gram 方法。或者还有其他方法来表示文档？]]></description>
      <guid>https://stackoverflow.com/questions/12046213/document-features-vector-representation</guid>
      <pubDate>Mon, 20 Aug 2012 22:40:31 GMT</pubDate>
    </item>
    </channel>
</rss>