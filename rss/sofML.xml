<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 15 Apr 2024 18:17:10 GMT</lastBuildDate>
    <item>
      <title>深度学习训练准确率显着变化</title>
      <link>https://stackoverflow.com/questions/78330285/deep-learning-training-accuracy-changes-significantly</link>
      <description><![CDATA[在此处输入图像描述
我正在 DQN 中训练一个深度网络，用于使用 2 臂机器人投掷球。状态为（末端执行器位置、投掷角度、关节值）。这些动作以不同的值移动关节。网络参数为（L_r 0.003、no_layers 10、no_neurons 32、no_epochs 50）
无论我在训练中改变什么，损失函数和准确率总是这样（准确率不超过20%）。我改变了学习率，不行。层，没有神经元和纪元，但我仍然无法达到超过 20% 的准确率。我该如何改进？]]></description>
      <guid>https://stackoverflow.com/questions/78330285/deep-learning-training-accuracy-changes-significantly</guid>
      <pubDate>Mon, 15 Apr 2024 18:04:46 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的有效张量乘法</title>
      <link>https://stackoverflow.com/questions/78330216/effective-tensor-multiplication-in-pytorch</link>
      <description><![CDATA[有谁知道我如何有效地计算两个张量乘法 - 例如，我有两个形状为 (15, 256) 和 (112, 256) 的张量，它们的乘积为形状为 (15, 112) 的张量可以是以7微秒计算。但是，如果我有像 A - (15, 100, 256) 和 B - (112, 2000, 256) 这样的张量，并且我会做出像 C = (A.reshape(-1, 256) @ B.reshape(256, - 1).reshape(15, 100, 112, 2000).permute(0, 2, 1, 3).max(-1).values.sum(-1) 得到形状为(15, 112)的张量，需要 1000 倍的时间才能计算得更快吗？
我知道第二个计算应该比第一个计算大得多，但也许它需要的时间比我的实现要少]]></description>
      <guid>https://stackoverflow.com/questions/78330216/effective-tensor-multiplication-in-pytorch</guid>
      <pubDate>Mon, 15 Apr 2024 17:49:57 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的过度拟合故障排除：优化正则化和数据预处理</title>
      <link>https://stackoverflow.com/questions/78330178/troubleshooting-overfitting-in-neural-networks-optimizing-regularization-and-da</link>
      <description><![CDATA[我正在开展一个机器学习项目，并在神经网络的训练过程中遇到了问题。尽管使用了 dropout 和批量归一化等技术，我仍然观察到训练数据的过度拟合。这是否是由于我的正则化参数配置错误或数据预处理管道中的缺陷造成的？任何有关如何解决此问题的见解或建议将不胜感激。
在我的机器学习项目中，我使用 dropout 和批量归一化等先进技术实现了神经网络架构，以减轻过度拟合。然而，尽管做出了这些努力，我仍然在训练过程中观察到过度拟合行为。我怀疑该问题可能源于正则化参数的错误配置或数据预处理管道中的缺陷。我正在寻求有关如何有效排除和解决这个持续存在的过度拟合问题的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78330178/troubleshooting-overfitting-in-neural-networks-optimizing-regularization-and-da</guid>
      <pubDate>Mon, 15 Apr 2024 17:42:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有闪电模块的调度程序？</title>
      <link>https://stackoverflow.com/questions/78330089/how-do-i-use-a-scheduler-with-a-lightning-module</link>
      <description><![CDATA[非常不言自明，我正在尝试在我的闪电模块中使用ReduceLROnPlateau调度程序，但我似乎无法让它真正改变学习率。我故意将 lr 设置为 0.1，使其人为地变高，但它在整个训练过程中仍然保持不变。我还制作了一个仅包含 10 个样本的虚拟数据集，因此我可以运行 100 个时期。即使经过 100 个 epoch，lr 仍保持不变。感谢您提前提供的任何帮助。
类 STARCOP_module(L.LightningModule):

    def __init__(自我，模型)：
        超级().__init__()
        self.save_hyperparameters(ignore=[“模型”])
        self.model = 模型
        self.score = BinaryF1Score().to(设备)
        自我.lr = 0.1
        
    def Training_step（自身，批次，batch_idx）：
        #torch.cuda.empty_cache()
        X = 批次[“X”]
        目标=批次[“Y”]
        pred = self.model(X)
        损失 = F.binary_cross_entropy_with_logits(pred, 目标)
        F1_train = self.score(pred, 目标)
        self.log(“学习率”, self.lr)
        self.log(&quot;训练损失&quot;, loss, prog_bar=False)
        self.log(&quot;训练F1分数&quot;, F1_train)
        回波损耗
    
    defvalidation_step(self,batch,batch_idx):
        #torch.cuda.empty_cache()
        X = 批次[“X”]
        目标=批次[“Y”]
        pred = self.model(X)
        v_loss = F.binary_cross_entropy_with_logits(pred, 目标)
        F1_val = self.score(pred, 目标)
        self.log(&quot;验证损失&quot;, v_loss)
        self.log(&quot;验证F1分数&quot;, F1_val)
        返回v_loss
    
    def test_step（自身，批次，batch_idx）：
        #torch.cuda.empty_cache()
        X = 批次[“X”]
        目标=批次[“Y”]
        pred = self.model(X)
        t_loss = F.binary_cross_entropy_with_logits(pred, 目标)
        F1_test = self.score(pred, 目标)
        self.log(&quot;测试损失&quot;, t_loss)
        self.log(&quot;测试F1分数&quot;, F1_test)
        返回 t_loss
    
    def 前向（自身，输入）：
        pred = self.model(输入)
        返回（预测）
        
    def 配置_优化器（自身）：
        优化器 = torch.optim.Adam(self.parameters(), lr=self.lr)
        sched = {“调度程序”: torch.optim.lr_scheduler.ReduceLROnPlateau(优化器,
                                                               模式＝“分钟”，
                                                               系数=0.5，
                                                               耐心=1),
                 “监视器”:“训练损失”}
        return {“优化器”：优化器，“调度器”：sched}

此外，有谁知道一种方法，以便调度程序检查每个步骤而不是每个时期的平稳情况？]]></description>
      <guid>https://stackoverflow.com/questions/78330089/how-do-i-use-a-scheduler-with-a-lightning-module</guid>
      <pubDate>Mon, 15 Apr 2024 17:24:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 中的参考标记句子构建机器学习模型来标记相似的句子？</title>
      <link>https://stackoverflow.com/questions/78329937/building-a-machine-learning-model-to-tag-similar-sentences-using-a-reference-tag</link>
      <description><![CDATA[我是 NLP 新手，正在尝试构建一个 ML 模型来在 Python 中注释/标记类似的句子。
带注释的句子 - “please call [calling] john [name]”
类似的句子 - [“我想给拉姆打电话”、“你能打电话给杰克吗”、“给拉奎尔打电话”]。

我的目标是标记所有相似的句子。我已经拥有相似句子的列表以及每个列表中的一个标记句子。标签基本上是意图和实体。
对上述算法有什么建议吗？我正在使用Python。
注意-

对于建模，我们必须使用 BERT 模型，不能使用任何其他模型。
我已经从所有句子的句子转换器模型中嵌入了可以
如有必要，可重复使用。
]]></description>
      <guid>https://stackoverflow.com/questions/78329937/building-a-machine-learning-model-to-tag-similar-sentences-using-a-reference-tag</guid>
      <pubDate>Mon, 15 Apr 2024 16:53:47 GMT</pubDate>
    </item>
    <item>
      <title>更改pytorch中中毒的输入</title>
      <link>https://stackoverflow.com/questions/78329685/change-input-for-poisoning-in-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78329685/change-input-for-poisoning-in-pytorch</guid>
      <pubDate>Mon, 15 Apr 2024 16:00:49 GMT</pubDate>
    </item>
    <item>
      <title>了解各种 ML 导出格式</title>
      <link>https://stackoverflow.com/questions/78329031/understanding-the-various-ml-export-format</link>
      <description><![CDATA[在各种类型的 ML 导出格式中 - YAML、Pickle、ONNX 等 - 您使用哪一种？为什么？例如，选择 Pickle 而不是 ONNX 有什么好处吗？
我试图在网上寻找专家对此的意见，但没有任何结果。]]></description>
      <guid>https://stackoverflow.com/questions/78329031/understanding-the-various-ml-export-format</guid>
      <pubDate>Mon, 15 Apr 2024 14:16:33 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface 管道可用型号</title>
      <link>https://stackoverflow.com/questions/78328539/huggingface-pipeline-available-models</link>
      <description><![CDATA[我正在使用 Python 中的 Huggingface 来对特定的 LLM 文本生成模型进行推理。到目前为止，我使用这样的管道来初始化模型，然后插入用户的输入并检索响应：
导入火炬
从变压器进口管道
打印（火炬.cuda.is_available（））

生成器=管道（&#39;文本生成&#39;，模型=&#39;gpt2&#39;，设备=“cuda”）
#推理代码

但是，当我使用 google/gemma-2b-it 或其他一些模型更改 gpt2 时，它可能会要求身份验证，或者直接抛出一个错误来指示它´无法从 pipeline() 获得。
我知道某些模型需要特定的标记器和依赖项，但是，有没有办法列出 pipeline() 中的所有可用模型？有什么方法可以在 Pipeline() 中使用其他模型及其所有依赖项，而无需在脚本中导入或使用它们？]]></description>
      <guid>https://stackoverflow.com/questions/78328539/huggingface-pipeline-available-models</guid>
      <pubDate>Mon, 15 Apr 2024 12:54:43 GMT</pubDate>
    </item>
    <item>
      <title>预测模型 - Python - SARIMA</title>
      <link>https://stackoverflow.com/questions/78328211/forecast-model-python-sarima</link>
      <description><![CDATA[我在将 SARIMA 模型应用到 Python 中的数据集时遇到了问题 - 我正在使用百货商店的商店销售数据，并希望将明年分为几个季度进行预测。数据具有稳定性，我已将历史数据分成四分之一。数据来源截至2017年12月31日。
请参阅下面的 Python 代码和输出
从 statsmodels.tsa.statespace.sarimax 导入 SARIMAX


模型= SARIMAX（季度销售，订单=订单，季节性订单=季节性订单）
结果=模型。合身（）

预测 = results.get_forecast(steps=4)
Forecast_index = pd.date_range(start=&#39;2013-01-01&#39;, period=4, freq=&#39;Q&#39;)
Forecast_series = pd.Series(forecast.predicted_mean,index=forecast_index)


打印（预测_系列）

# 绘制历史季度销售数据
quarterly_sales.plot(kind=&#39;bar&#39;, Figsize=(10, 6), label=&#39;历史季度销售额&#39;)

# 检查预测指数是否与预期的未来季度一致
打印（预测系列.索引）

# 以更高的可见性覆盖预测销售额
plt.plot(forecast_series.index,forecast_series,color=&#39;red&#39;,marker=&#39;o&#39;,linestyle=&#39;dashed&#39;,linewidth=2,label=&#39;预测季度销售额&#39;)


plt.ylim(0, max(quarterly_sales.max(), Forecast_series.max()) * 1.1)


plt.title(&#39;季度销售额及预测&#39;)
plt.xlabel(&#39;季度&#39;)
plt.ylabel(&#39;销售&#39;)
plt.xticks（旋转=45）


plt.图例()

plt.show()


new_index = [f&quot;Q{date.quarter} {str(date.year)[-2:]}&quot;&quot;对于 Forecast_series.index 中的日期]
Forecast_series.index = new_index

将 matplotlib.pyplot 导入为 plt


Historical_index = [f&quot;Q{date.quarter} {str(date.year)[-2:]}&quot;&quot;对于quarterly_sales.index 中的日期]
季度销售指数 = 历史指数


quarterly_sales.plot(kind=&#39;bar&#39;, Figsize=(10, 6), label=&#39;历史季度销售额&#39;)


plt.plot(forecast_series.index,forecast_series,color=&#39;red&#39;,marker=&#39;o&#39;,linestyle=&#39;dashed&#39;,label=&#39;预测季度销售额&#39;)

plt.title(&#39;季度销售额及预测&#39;)
plt.xlabel(&#39;季度&#39;)
plt.ylabel(&#39;销售&#39;)
plt.xticks（旋转=45）


plt.图例()

plt.show()

如上所述，我已经尝试过，但我在可视化图表上看不到任何我对未来 12 个月的预测，尽管它显示在图例的屏幕截图中。]]></description>
      <guid>https://stackoverflow.com/questions/78328211/forecast-model-python-sarima</guid>
      <pubDate>Mon, 15 Apr 2024 11:57:06 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Streamlit 中使推荐的书籍可点击以触发新的推荐？</title>
      <link>https://stackoverflow.com/questions/78328128/how-to-make-a-recommended-book-clickable-to-trigger-new-recommendations-in-strea</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78328128/how-to-make-a-recommended-book-clickable-to-trigger-new-recommendations-in-strea</guid>
      <pubDate>Mon, 15 Apr 2024 11:42:56 GMT</pubDate>
    </item>
    <item>
      <title>不标准化所有特征（回归）是不是很糟糕？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78328094/is-it-bad-not-to-standardize-all-features-regression</link>
      <description><![CDATA[我正在使用具有两个隐藏层的神经网络来执行回归任务。我的训练集输出值从 0 到 2000 变化，测试集输出值从 0 到 600 变化。我的主要问题是过度拟合。
我标准化了一些具有更大值的输入特征（StandardScaler），但我没有标准化那些值在 -6 到 10 范围内的特征，因为我认为它们足够小，不会引起问题。

这是错误的吗？这会增加过度拟合吗？

我目前正在测试具有负斜率 (0.01) 的 ReLu，以某种方式考虑负输入（标准化或非标准化）。是否有更好的方法或更好的标准化激活函数组合来实现最佳测试集预测？


如果有任何解释或想法，我将不胜感激。
提前非常感谢您。]]></description>
      <guid>https://stackoverflow.com/questions/78328094/is-it-bad-not-to-standardize-all-features-regression</guid>
      <pubDate>Mon, 15 Apr 2024 11:34:22 GMT</pubDate>
    </item>
    <item>
      <title>句子相似度的加权输入</title>
      <link>https://stackoverflow.com/questions/78327620/weighted-input-for-sentence-similarity</link>
      <description><![CDATA[我正在使用点分数构建句子相似性的语言模型。目前，我正在使用 gte-large来自 Hugging Face 的语言模型。
我想知道是否有一种方法可以对文本进行加权输入。例如输入句子
蟋蟀昆虫
有没有办法在这里给予昆虫更多的权重，以便与大量的单词相比，它与昆虫比板球这项运动显示出更多的相似性？]]></description>
      <guid>https://stackoverflow.com/questions/78327620/weighted-input-for-sentence-similarity</guid>
      <pubDate>Mon, 15 Apr 2024 10:09:50 GMT</pubDate>
    </item>
    <item>
      <title>了解梯度提升中的模型选择</title>
      <link>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</link>
      <description><![CDATA[包含问题的图片
我目前正在研究梯度增强模型，并且遇到了一种我不确定的情况。在我的模型的第一阶段，拟合了决策树，这由模型的阶跃函数外观表示。
但是，当我检查第一阶段的残差时，它们似乎表现出二次模式。这促使我考虑在第二阶段使用 2 次多项式模型。
但我很困惑，因为问题陈述建议在第二阶段使用与第一阶段相同类型的模型（即决策树）。
决策树能否捕获残差中的二次模式？或者，尽管问题陈述提出了建议，但我应该在第二阶段考虑不同类型的模型？
任何关于如何处理这种情况的澄清将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</guid>
      <pubDate>Sat, 13 Apr 2024 23:38:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pytest 和假设进行可视化</title>
      <link>https://stackoverflow.com/questions/78321735/using-pytest-and-hypothesis-for-visualization</link>
      <description><![CDATA[我正在使用albumentation库进行图像增强，我也在为每个类似的旋转编写测试用例应该在50 - 90度之内，Blur=blur_limit min：3 max：99，我如何可视化我的测试用例在哪里假设失败
带有假设可视化的 pytest]]></description>
      <guid>https://stackoverflow.com/questions/78321735/using-pytest-and-hypothesis-for-visualization</guid>
      <pubDate>Sat, 13 Apr 2024 19:08:00 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在同一个 Azure 机器学习管道中使用经典组件和自定义组件？</title>
      <link>https://stackoverflow.com/questions/78274833/is-there-any-way-to-use-classic-and-custom-components-in-the-same-azure-machine</link>
      <description><![CDATA[我正在尝试将管道从 Microsoft 机器学习工作室经典迁移到 Azure 机器学习。我的管道实际上在 Machine Learning Studio Classic 上运行，由以下经典和自定义组件组成。输入数据有 6 个，是使用导入数据组件从 Blob 存储帐户收集的。它们主要是 csv 文件，我使用一个自定义组件（R 脚本）来清理输入数据。这是因为“执行 R 脚本”只允许 2 个输入，但我需要 6 个输入，因为我有 6 个输入文件。之后，使用称为导出数据的组件将 csv 文件写入同一 Blob 存储帐户，但写入另一个文件夹中。我想在 Azure 机器学习中构建相同的管道，我可以在同一管道中使用自定义组件和默认组件吗？
如果我尝试使用经典组件创建管道，显然我无法使用我的自定义组件（又名 R 脚本），并且当我尝试创建自定义管道时，我无法使用经典组件，显然没有办法在我的自定义组件清理输入数据后创建自定义管道时导出我的数据。]]></description>
      <guid>https://stackoverflow.com/questions/78274833/is-there-any-way-to-use-classic-and-custom-components-in-the-same-azure-machine</guid>
      <pubDate>Thu, 04 Apr 2024 15:14:48 GMT</pubDate>
    </item>
    </channel>
</rss>