<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 31 Jan 2025 01:14:27 GMT</lastBuildDate>
    <item>
      <title>从蒙版风力涡轮机图像中提取叶片尖端坐标的想法[关闭]</title>
      <link>https://stackoverflow.com/questions/79400379/ideas-for-extracting-blade-tip-coordinates-from-masked-wind-turbine-image</link>
      <description><![CDATA[我正在寻找 Python 中的图像处理工具来获取风力涡轮机叶片尖端的坐标，在本例中是小型模型。叶片已经由 yoloV8 分割模型分割，现在我想使用该图像获取尖端的 xy 坐标。示例图像：
风能涡轮机的蒙版机翼。
有人可以推荐一些关于如何做到这一点的想法吗？转子可以旋转，因此三个尖端可以位于椭圆上的任何位置。
我已经尝试训练 yolo-pose 模型进行关键点检测，但它没有给出足够精确的结果。我将使用这些坐标来计算转子盘的偏心率，因此这些点需要相当精确。]]></description>
      <guid>https://stackoverflow.com/questions/79400379/ideas-for-extracting-blade-tip-coordinates-from-masked-wind-turbine-image</guid>
      <pubDate>Thu, 30 Jan 2025 15:27:02 GMT</pubDate>
    </item>
    <item>
      <title>模仿单个个体的合成数据</title>
      <link>https://stackoverflow.com/questions/79400139/synthetic-data-whic-mimics-a-single-individual</link>
      <description><![CDATA[传统 GAN 生成的合成数据集与原始数据集来自同一分布。是否有任何实例可以使用整个数据集中的单个样本来创建唯一的合成数据样本？]]></description>
      <guid>https://stackoverflow.com/questions/79400139/synthetic-data-whic-mimics-a-single-individual</guid>
      <pubDate>Thu, 30 Jan 2025 13:56:09 GMT</pubDate>
    </item>
    <item>
      <title>Whisper 模型实时端点容器部署在 Azure ML 上失败</title>
      <link>https://stackoverflow.com/questions/79399452/whisper-model-real-time-endpoint-container-deployment-failed-on-azure-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79399452/whisper-model-real-time-endpoint-container-deployment-failed-on-azure-ml</guid>
      <pubDate>Thu, 30 Jan 2025 09:50:51 GMT</pubDate>
    </item>
    <item>
      <title>在使用 YOLO v8 DETECT TRAIN 进行对象检测时，如何在每个时期提取验证集上的预测？</title>
      <link>https://stackoverflow.com/questions/79398928/how-to-extract-the-predictions-on-the-validation-set-at-each-epoch-when-using-y</link>
      <description><![CDATA[我使用的是 yolo 模型 yolov8l.pt 的 CLI 版本（可通过下面的 WEIGHTS 参数访问）：
!yolo detect train model={WEIGHTS} data=&#39;data/tvt3_data_v8.yaml&#39; single_cls imgsz={IMG_SIZE} batch={BATCH_SIZE} epochs={3}

当前工作原理
在训练期间，在每个时期：

计算训练损失
计算验证损失和验证召回率、准确率和 mAP

在训练结束时，选择最佳 .pt 模型并在验证集上进行评估。
我需要从脚本中获得什么
在每个epoch，我想提取在 VALIDATION 数据集上做出的预测
我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/79398928/how-to-extract-the-predictions-on-the-validation-set-at-each-epoch-when-using-y</guid>
      <pubDate>Thu, 30 Jan 2025 06:02:26 GMT</pubDate>
    </item>
    <item>
      <title>dsac_tools（使用 pytorch 计算本质矩阵）计算问题</title>
      <link>https://stackoverflow.com/questions/79398453/dsac-toolscalculate-essential-matrix-using-pytorch-computational-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79398453/dsac-toolscalculate-essential-matrix-using-pytorch-computational-problem</guid>
      <pubDate>Wed, 29 Jan 2025 23:36:30 GMT</pubDate>
    </item>
    <item>
      <title>具有 40,000 个状态和 81 个动作的 Q 学习是否可行？</title>
      <link>https://stackoverflow.com/questions/79398056/is-q-learning-feasible-with-40-000-states-and-81-actions</link>
      <description><![CDATA[我正在使用 Q-learning 解决一个问题，其中状态数为 40,000，操作数为 81，因此 Q 表大小为 3,240,000 个条目。使用 Q-learning 处理如此大的数据集是否可行，还是需要额外的技术来优化学习过程？]]></description>
      <guid>https://stackoverflow.com/questions/79398056/is-q-learning-feasible-with-40-000-states-and-81-actions</guid>
      <pubDate>Wed, 29 Jan 2025 20:01:22 GMT</pubDate>
    </item>
    <item>
      <title>在 GPU 上进行 PyWavelets 计算</title>
      <link>https://stackoverflow.com/questions/79396894/doing-pywavelets-calculation-on-gpu</link>
      <description><![CDATA[目前正在使用 PyWavelets 进行分类器工作，这是我的计算块：
class WaveletLayer(nn.Module):
def __init__(self):
super(WaveletLayer, self).__init__()

def forward(self, x):
def wavelet_transform(img):
coeffs = pywt.dwt2(img.cpu().numpy(), &quot;haar&quot;)
LL, (LH, HL, HH) = coeffs
return (
torch.from_numpy(LL).to(img.device),
torch.from_numpy(LH).to(img.device),
torch.from_numpy(HL).to(img.device),
torch.from_numpy(HH).to(img.device),
)

# 将小波变换分别应用于每个通道
LL, LH, HL, HH = zip(
*[wavelet_transform(x[:, i : i + 1]) for i in range(x.shape[1])]
)

# 连接结果
LL = torch.cat(LL, dim=1)
LH = torch.cat(LH, dim=1)
HL = torch.cat(HL, dim=1)
HH = torch.cat(HH, dim=1)

return torch.cat([LL, LH, HL, HH], dim=1)


此模块的输出将进入 resnet 块进行学习，在此过程中，我发现 CPU 堵塞，从而减慢了训练过程
我正在尝试使用 GPU 进行这些计算。]]></description>
      <guid>https://stackoverflow.com/questions/79396894/doing-pywavelets-calculation-on-gpu</guid>
      <pubDate>Wed, 29 Jan 2025 13:26:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Spark 中重现 ML 模型的结果？[重复]</title>
      <link>https://stackoverflow.com/questions/79396752/how-to-reproduce-the-results-of-an-ml-model-in-spark</link>
      <description><![CDATA[我正在 Spark (Pyspark) 中创建一个机器学习模型（随机森林），并进行交叉验证和网格搜索。我有两个数据框：一个用于训练，一个用于测试，均存储在 Parquet 中。
在运行整个管道进行模型的训练和验证以及测试后，我确认实验的可重复性无法得到保证，也就是说，即使在所有允许此参数的函数中为“种子”定义一个固定值，在创建新的 Spark 会话并重新运行管道时，我也无法获得完全相同的结果。
使用不同的数据库执行此测试，我确认在某些情况下，在某些执行中可以获得相同的混淆矩阵，但分数不一样，交叉验证结果（AUC ROC）也不一样。代码总是一样的。相同的 Spark 配置。这对决策树、随机森林和梯度提升都有效。这些模型通过精度、召回率、f1 分数、准确率、auc roc 和 auc pr 进行了评估，并被证明是非确定性的。
我的问题是：如何确保在两次或多次执行模型管道的相同代码时，我可以获得相同的结果？如果不可能，为什么不可能？
我为所有允许使用它的函数定义了一个固定种子。
我重复执行了几十次，始终使用相同的数据、相同的设置和相同的测试参数。
以下是实验的片段：
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator

# spark session

# read dataframe training_data

random_forest = RandomForestClassifier(seed=42, labelCol=&quot;label&quot;, featuresCol=&quot;features&quot;)

param_grid = ParamGridBuilder()\
.addGrid(random_forest.numTrees, [10, 50])\
.addGrid(random_forest.maxDepth, [5, 10])\
.build()

evaluator = BinaryClassificationEvaluator(metricName=&quot;areaUnderROC&quot;, labelCol=&quot;label&quot;)

cross_validator = CrossValidator(estimator=random_forest, 
estimatorParamMaps=param_grid, 
evaluator=evaluator, 
numFolds=5, 
seed=42)

cv_model = cross_validator.fit(training_data)

best_model = cv_model.bestModel

predictions = best_model.transform(test_data)
predictions.select(&quot;features&quot;, &quot;label&quot;, &quot;probability&quot;, &quot;prediction&quot;).show()

auc_roc = evaluator.evaluate(best_model.transform(test_data))

print(&quot;AUC-ROC:&quot;, auc_roc)
]]></description>
      <guid>https://stackoverflow.com/questions/79396752/how-to-reproduce-the-results-of-an-ml-model-in-spark</guid>
      <pubDate>Wed, 29 Jan 2025 12:40:12 GMT</pubDate>
    </item>
    <item>
      <title>使用输入层作为第二个输入层的权重</title>
      <link>https://stackoverflow.com/questions/79396213/using-an-input-layer-as-a-weight-to-a-second-input-layer</link>
      <description><![CDATA[我有两个输入结构，其中第二个输入中的每个特征都使用输入 1 的值来计算每个特征。然后，第二个输入层连接到隐藏层，最后连接到单个输出层。因此，假设我在第一个输入中有 A、B、C，在第二个输入中有 G M N O，其中例如 G 被计算为总和（A 到 C），并且 G M N O 连接到隐藏层。如何使用 tensorflow keras 实现这一点？ G M N O 是连接到隐藏层的输入层。
input_elements = Input(shape=(4,), name=&quot;Elemental_Composition&quot;)
input_descriptors = Input(shape=(7,), name=&quot;Descriptors&quot;)

combined = concatenate([input_elements, input_descriptors])
hidden = Dense(64,activation=&quot;relu&quot;)(combined)
output = Dense(1,activation=&quot;linear&quot;)(hidden)
]]></description>
      <guid>https://stackoverflow.com/questions/79396213/using-an-input-layer-as-a-weight-to-a-second-input-layer</guid>
      <pubDate>Wed, 29 Jan 2025 09:17:34 GMT</pubDate>
    </item>
    <item>
      <title>自定义字母表的文本识别</title>
      <link>https://stackoverflow.com/questions/79394460/text-recogniton-for-custom-alphabet</link>
      <description><![CDATA[我有一个虚构的字母表，由大约 20 种形状和字母组成，它们与希腊字母和西里尔字母相似。
它们是作为资产生成的，我为它们每个都制作了 30 x 30 的图像。我想创建一个特殊的图像处理工具来实时翻译它们。
它们总是打印在黑色多边形上。
所以我尝试使用通用 opencv2 方法使用黑色多边形进行检测，并且成功了。
为了扫描和检测字母，我尝试了 ORB 特征提取和匹配，但没有成功。由于相似的符文形状，它在整个字母中都发现了特征。
我曾尝试使用 Yolo11 训练对象检测模型，但由于数据量少（我没有已打印的示例，我尝试生成具有不同角度的模拟图像），它成本高且表现不佳。
我没有足够的数据来训练 HOG。
是否有一个简单的 Python 模式匹配算法，可以考虑现实生活中相机的小倾斜平移和滚动，因此仍然可以检测字母？
编辑 -&gt;
以下是我拥有的一些字母示例

]]></description>
      <guid>https://stackoverflow.com/questions/79394460/text-recogniton-for-custom-alphabet</guid>
      <pubDate>Tue, 28 Jan 2025 16:02:10 GMT</pubDate>
    </item>
    <item>
      <title>EfficientNetB3模型识别脑肿瘤准确率极低及学习停滞问题</title>
      <link>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</guid>
      <pubDate>Mon, 27 Jan 2025 11:58:17 GMT</pubDate>
    </item>
    <item>
      <title>无法访问自由变量“fig”，因为它与封闭范围内的值没有关联</title>
      <link>https://stackoverflow.com/questions/79270292/cannot-access-free-variable-fig-where-it-is-not-associated-with-a-value-in-enc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79270292/cannot-access-free-variable-fig-where-it-is-not-associated-with-a-value-in-enc</guid>
      <pubDate>Wed, 11 Dec 2024 02:04:10 GMT</pubDate>
    </item>
    <item>
      <title>训练损失随着训练次数的增加而不减少</title>
      <link>https://stackoverflow.com/questions/73811288/training-loss-increases-instead-of-decrease-with-epochs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/73811288/training-loss-increases-instead-of-decrease-with-epochs</guid>
      <pubDate>Thu, 22 Sep 2022 08:10:36 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark 错误-在 pandas_udf 内部实现时参数无效，不是字符串或列</title>
      <link>https://stackoverflow.com/questions/73032656/pyspark-error-invalid-argument-not-a-string-or-column-while-implementing-insi</link>
      <description><![CDATA[此代码在 pandas_udf 之外运行良好，但在尝试在 udf 内部实现相同代码时出现此错误。为了避免 pyspark 和 python 函数名称之间的冲突，我已明确从 pyspark 导入特定函数。使用 fuzzywuzzy 进行字符串匹配，并使用 nltk 根据 ngram 技术将字符串划分为子字符串。这段代码在没有 udf 的情况下运行时间太长，所以决定使用 pandas_udf，但不知道为什么会出现这个错误。
import json
from pyspark.sql.types import StringType, StructField, StructType
from pyspark.sql.functions import pandas_udf, PandasUDFType

from nltk.util import ngrams, everygrams
from fuzzywuzzy import process, fuzz

model_results_schema = StructType(
[StructField(&quot;Output&quot;, StringType(), True)]
)

@pandas_udf( model_results_schema, PandasUDFType.GROUPED_MAP )
def get_ccep_results( model_input ):

def ngram_filter(list1, list2):
sorted_list1 = sorted(list1, key = lambda a: (a[1], len(a[0])), reverse =True)
sorted_list2 = sorted(list2, key = lambda a: (a[1], len(a[0])), reverse =True)
rslt1 =list(filter(lambda t: t[1]&gt;58, sorted_list1))#根据需求改变阈值
rslt2 =list(filter(lambda t: t[1]&gt;58, sorted_list2))#根据需求改变阈值
if len(rslt1)!=0:
a = rslt1[0][0]
else:
a =&#39;&#39;
if len(rslt2)!=0:
b = rslt2[0][0]
else:
b =&#39;&#39;
return a, b

def ngram_fuzzy_match(n_gram, attribute):
list_res=[]
for i in n_gram:
r = process.extract(i, attribute)
list_res.append(r)
flat_list = [x for xs in list_res for x in xs] 
sorted_list = sorted(flat_list,key = lambda x: x[1], reverse=True )
list_br =[]
for j in attribute:
p = process.extract(j, n_gram)
list_br.append(p)
flat_list1 = [x for xs in list_br for x in xs] 
sorted_list1 = sorted(flat_list1,key =lambda x: x[1] , reverse=True )
attribute_value, n_gram_value = ngram_filter(flat_list, flat_list1)
return attribute_value, n_gram_value

def ngrams_prod_desc(prod_desc, internal_att_list):
prod_desc_temp = prod_desc
temp_dict ={x:[] for x in range(0,len(internal_att_list))}
for ind, x in enumerate(internal_att_list):

list1 = list(everygrams(prod_desc_temp.split())) #为每个描述创建 n-gram
res = [&#39; &#39;.join(tups) for tups in list1]
if len(res)!=0:
r,ngram_candidate = ngram_fuzzy_match(res, x) #此函数执行 n-gram 和之间的模糊匹配属性

temp_dict[ind].append(r) # 此处出错
prod_desc_temp=prod_desc_temp.replace(ngram_candidate, &#39;&#39;).strip()
else:
temp_dict[ind].append(None)

return json.dumps(temp_dict)

dictionary = model_input[&#39;cleaned_external&#39;].apply(lambda x: ngrams_prod_desc(x, attribute_list))
result = pd.DataFrame([dictionary])

return result

model_output = (frame_combined.groupby([&#39;prod_id&#39;]).apply(get_ccep_results)) # 此处出错

frame_combined -

更新 -
尝试了这个并得到异常 -

try:
model_output = (frame_combined.groupby([&#39;prod_id&#39;]).apply(get_ccep_results))
except Exception as e:
print(e)
]]></description>
      <guid>https://stackoverflow.com/questions/73032656/pyspark-error-invalid-argument-not-a-string-or-column-while-implementing-insi</guid>
      <pubDate>Tue, 19 Jul 2022 07:18:33 GMT</pubDate>
    </item>
    <item>
      <title>宏观 VS 微观 VS 加权 VS 样本 F1 分数</title>
      <link>https://stackoverflow.com/questions/55740220/macro-vs-micro-vs-weighted-vs-samples-f1-score</link>
      <description><![CDATA[在 sklearn.metrics.f1_score 中，f1 分数有一个名为“平均值”的参数。宏、微、加权和样本是什么意思？请详细说明，因为在文档中，没有正确解释。或者简单地回答以下问题：

为什么“样本”是多标签分类的最佳参数？
为什么微最适合不平衡的数据集？
加权和宏有什么区别？
]]></description>
      <guid>https://stackoverflow.com/questions/55740220/macro-vs-micro-vs-weighted-vs-samples-f1-score</guid>
      <pubDate>Thu, 18 Apr 2019 06:26:25 GMT</pubDate>
    </item>
    </channel>
</rss>