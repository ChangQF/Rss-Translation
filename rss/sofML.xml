<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 09 May 2024 01:00:44 GMT</lastBuildDate>
    <item>
      <title>即使遵循示例 3：分类的文档代码，PyKan 代码也无法工作</title>
      <link>https://stackoverflow.com/questions/78451382/pykan-code-not-working-even-after-following-the-documentation-code-for-example-3</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78451382/pykan-code-not-working-even-after-following-the-documentation-code-for-example-3</guid>
      <pubDate>Wed, 08 May 2024 22:17:49 GMT</pubDate>
    </item>
    <item>
      <title>利用额外数据增强文本聚类</title>
      <link>https://stackoverflow.com/questions/78451342/leveraging-extra-data-to-enhance-text-clustering</link>
      <description><![CDATA[我想要对数千个文本数据（称为语料库 A）进行聚类，并为每个聚类找到一个标签。聚类的准确性非常重要，因为我想使用文本及其标签来训练生成模型。
我使用轮廓分数来衡量聚类性能，但它看起来不太好。它低于 0.1，看起来前景并不乐观。另一方面，我对每个文本都有一些抽象描述（称为语料库 B）。但是，它们不能用作标签。因为两个相似的文本，可以有相同含义的不同描述。例如，两个描述是：
&lt;块引用&gt;
重点关注机器学习中使用的算法

&lt;块引用&gt;
探索自然语言处理技术

这些描述与谈论人工智能的两个不同文本相关。请注意，由于文本数据量巨大，无法由人工检查聚类结果。
现在，我的问题是我可以使用这些描述 (B) 来改进聚类吗？
此外，您认为使用语料库 B 来评估 ML（聚类或任何其他算法）模型是一个好主意吗？例如，在超参数调优中，计算语料库B上的帧内和帧间余弦相似度？]]></description>
      <guid>https://stackoverflow.com/questions/78451342/leveraging-extra-data-to-enhance-text-clustering</guid>
      <pubDate>Wed, 08 May 2024 22:05:07 GMT</pubDate>
    </item>
    <item>
      <title>对于我使用 GB、树和随机森林对房价进行的数据分析，我的 MSE 太高</title>
      <link>https://stackoverflow.com/questions/78451297/for-my-data-analysis-on-house-prices-with-gb-tree-and-random-forest-my-mse-is</link>
      <description><![CDATA[我尝试过使用所有变量，也尝试过选择某些变量，但 MSE 仍然很高。我想知道我的代码是否有错误。我还尝试添加一些功能工程，但暂时将其注释掉，因为它使我的 MSE 变得更糟。
 #kaggle：房价 - 高级回归技术
    将 pandas 导入为 pd
    将 numpy 导入为 np
    导入sklearn.model_selection
    将 matplotlib.pyplot 导入为 plt
    将 sklearn 导入为 sk
    导入sklearn.tree
    导入 sklearn.ensemble
    
    df = pd.read_csv(&#39;/Users/andrewhasushush/Downloads/house-prices-advanced-regression-techniques/train.csv&#39;)
    df_test = pd.read_csv(&#39;/Users/andrewhashush/Downloads/house-prices-advanced-regression-techniques/test.csv&#39;)
    
    打印（df.head（））
    打印（df.info（））
    
    #selected_features = [&#39;OverallQual&#39;, &#39;YearBuilt&#39;, &#39;TotalBsmtSF&#39;, &#39;1stFlrSF&#39;, &#39;GrLivArea&#39;,
    # &#39;GarageCars&#39;, &#39;GarageArea&#39;, &#39;MSZoning&#39;, &#39;邻里&#39;,
    # &#39;KitchenQual&#39;, &#39;CentralAir&#39;, &#39;LotArea&#39;, &#39;MSSubClass&#39;, &#39;LotFrontage&#39;,
    # &#39;街道&#39;, &#39;LandContour&#39;, &#39;公用设施&#39;, &#39;OverallCond&#39;, &#39;RoofStyle&#39;,
    # &#39;RoofMatl&#39;, &#39;BsmtQual&#39;, &#39;SaleCondition&#39;, &#39;SaleType&#39;, &#39;YrSold&#39;, &#39;MoSold&#39;,
    # &#39;泳池区&#39;]
    
    选定的特征 = [
        &#39;LotFrontage&#39;，&#39;OverallQual&#39;，&#39;OverallCond&#39;，&#39;MasVnrArea&#39;，&#39;HalfBath&#39;，
        &#39;BedroomAbvGr&#39;、&#39;KitchenAbvGr&#39;、&#39;GarageCars&#39;、&#39;WoodDeckSF&#39;、
        &#39;OpenPorchSF&#39;、&#39;MoSold&#39;、&#39;YrSold&#39;、&#39;MSZoning&#39;、&#39;小巷&#39;、
        &#39;LotShape&#39;，&#39;LandContour&#39;，&#39;LotConfig&#39;，&#39;LandSlope&#39;，&#39;邻里&#39;，
        &#39;Condition1&#39;, &#39;BldgType&#39;, &#39;HouseStyle&#39;, &#39;RoofStyle&#39;, &#39;Exterior1st&#39;,
        &#39;Exterior2nd&#39;、&#39;MasVnrType&#39;、&#39;ExterQual&#39;、&#39;ExterCond&#39;、&#39;基础&#39;、
        &#39;BsmtQual&#39;，&#39;BsmtCond&#39;，&#39;BsmtExposure&#39;，&#39;BsmtFinType1&#39;，&#39;BsmtFinType2&#39;，
        &#39;供暖&#39;、&#39;HeatingQC&#39;、&#39;CentralAir&#39;、&#39;电气&#39;、&#39;KitchenQual&#39;、
        &#39;功能&#39;，&#39;FireplaceQu&#39;，&#39;GarageType&#39;，&#39;GarageFinish&#39;，&#39;GarageQual&#39;，
        &#39;GarageCond&#39;、&#39;PavedDrive&#39;、&#39;PoolQC&#39;、&#39;Fence&#39;、&#39;MiscFeature&#39;、
        &#39;销售类型&#39;，&#39;销售条件&#39;
    ]
    
    #特征工程
    #df[&#39;质量条件&#39;] = df[&#39;OverallQual&#39;] * df[&#39;OverallCond&#39;]
    #df[&#39;Age_at_Sale&#39;] = df[&#39;YrSold&#39;] - df[&#39;YearBuilt&#39;]
    #selected_features += [&#39;Quality_Condition&#39;, &#39;Age_at_Sale&#39;]
    
    X = df[选定的特征]
    打印（X.head（））
    
    对于 X.columns 中的列：
        Missing_data = df[列].isnull().sum()
        print(f&quot;{列}: {missing_data}&quot;)
      
    categorical_vars = X.select_dtypes(include=&#39;object&#39;).columns.tolist()
    numeric_vars = X.select_dtypes(exclude=&#39;object&#39;).columns.tolist()
    
    print(“分类变量：”, categorical_vars)
    打印（）
    print(&quot;数值变量：&quot;, numeric_vars)
    
    
    #%%
    
    #用众数填充缺失的分类值
    对于 categorical_vars 中的 var：
        mode_value = X[var].mode()[0]
        # X[var] = X[var].fillna(mode_value)
        # X.loc[:, var] = X.loc[:, var].fillna(mode_value)
        X.loc[:, var] = X[var].fillna(mode_value)
    
    #用中位数填充缺失的数值
    对于 numeric_vars 中的 var：
        中值 = X[var].median()
        X.loc[:, var] = X[var].fillna(median_value)
    
    #检查一下
    对于 X.columns 中的列：
        Missing_data = X[列].isnull().sum()
        print(f&quot;{列}: {missing_data}&quot;)
    
    #one 热编码
    X = pd.get_dummies(X, columns=categorical_vars)
    y = df[&#39;销售价格&#39;]
    
    #分割数据
    X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X,y, train_size =.8, random_state= 123)
    
    dt_model = sklearn.tree.DecisionTreeRegressor(max_深度=5, random_state=123)
    dt_model.fit(X_train, y_train)
    y_pred = dt_model.predict(X_val)
    mse_val = np.mean((y_pred - y_val)**2)
    print(f&quot;MSE: {mse_val}&quot;)
    
    # 随机森林回归器
    rf_model = sklearn.ensemble.RandomForestRegressor(n_estimators=100, random_state=123)
    rf_model.fit(X_train, y_train)
    y_pred1 = rf_model.predict(X_val)
    mse_val1 = np.mean((y_pred1 - y_val)**2)
    print(f&quot;MSE: {mse_val1}&quot;)
    
    # 梯度增强回归器
    gb_model = sklearn.ensemble.GradientBoostingRegressor(n_estimators=100，learning_rate=0.1，random_state=123)
    gb_model.fit(X_train, y_train)
    y_pred2 = gb_model.predict(X_val)
    mse_val2 = np.mean((y_pred2 - y_val)**2)
    print(f&quot;MSE: {mse_val2}&quot;)

&lt;前&gt;&lt;代码&gt;MSE：1451852149.6361678
微信：944388532.5714014
微信：755815420.2686024
]]></description>
      <guid>https://stackoverflow.com/questions/78451297/for-my-data-analysis-on-house-prices-with-gb-tree-and-random-forest-my-mse-is</guid>
      <pubDate>Wed, 08 May 2024 21:49:52 GMT</pubDate>
    </item>
    <item>
      <title>准确度 = 1？在评论上训练随机森林模型时[关闭]</title>
      <link>https://stackoverflow.com/questions/78451179/accuracy-1-when-training-random-forest-model-on-reviews</link>
      <description><![CDATA[我正在尝试在 R 中训练随机森林模型以进行情感分析。
该模型使用 tf-idf 矩阵，并从中学习如何对评论进行正面或负面分类。
正的被分类为标签1，负的被分类为标签0。
我在 R 中创建了一个代码，其逻辑是训练一个模型，将给定的 2 个标签转换为因子，然后将数据库划分为训练数据集和测试数据集。
类似的代码逻辑对于朴素贝叶斯来说效果很好，但是对于 RF 来说似乎存在问题。
我想知道问题是否出在代码的算法上，因为我是 R 新手，我不确定我是否使用了正确的代码。
# 加载必要的库
库（随机森林）
库（readxl）
库（插入符号）
图书馆(e1071)

# 加载带有标签的原始DataFrame
df &lt;- read_excel(&#39;~/Downloads/tfidf_r.xlsx&#39;)
df$label...2 &lt;- as.factor(df$label...2)

# 将数据分为训练集和测试集
设置.种子(42)
train_indices &lt;- createDataPartition(df$review_id, p = 0.7, list = FALSE)
train_data &lt;- df[train_indices, ]
test_data &lt;- df[-train_indices, ]

# 使用正则化初始化并训练随机森林分类器
random_forest_model &lt;- train(label...2 ~ ., data = train_data, method = &quot;rf&quot;,
                             trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 10))

# 打印模型
打印（随机森林模型）

# 对测试数据进行预测
y_pred &lt;- 预测（random_forest_model，newdata = test_data）

令我怀疑的是，我在这段代码中没有看到任何具有超参数的理由。
在这里您可以看到输出：
准确度：1
                 95% 置信区间：(0.9757, 1)
    无信息率：0.6067
    P值[Acc&gt; NIR]：&lt; 2.2e-16
]]></description>
      <guid>https://stackoverflow.com/questions/78451179/accuracy-1-when-training-random-forest-model-on-reviews</guid>
      <pubDate>Wed, 08 May 2024 21:13:51 GMT</pubDate>
    </item>
    <item>
      <title>NER 模型训练中具有波动损失的恒定评估指标：模型是否能学到任何东西？</title>
      <link>https://stackoverflow.com/questions/78450933/constant-evaluation-metrics-with-fluctuating-loss-in-ner-model-training-is-the</link>
      <description><![CDATA[我正在使用预训练的 BERT 模型 (BertForTokenClassification) 来训练 NER 任务。我使用准确度和 F1_score 作为我的评估指标。主要问题是该模型在每个时期都显示相同的分数，表明它没有学习。但训练损失和分数在各个时期也不是恒定的。什么可能导致此问题？
训练函数
评估函数
训练循环
结果
我检查了模型的参数是否可训练（requires_grad =True），但没有帮助。另外，我尝试了几种学习率的尺度，但它以相同的态度给了我不同的结果（在不同时期保持不变）。我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78450933/constant-evaluation-metrics-with-fluctuating-loss-in-ner-model-training-is-the</guid>
      <pubDate>Wed, 08 May 2024 20:07:15 GMT</pubDate>
    </item>
    <item>
      <title>生成随机字符串的预训练模型</title>
      <link>https://stackoverflow.com/questions/78448547/pretrained-models-generating-a-random-strings</link>
      <description><![CDATA[我正在尝试使用 ollama 包装器来玩一些现成的模型，实际上效果很好。但是，当我尝试解码它们的输出时，我使用的拥抱脸部模型中很少有它是一些随机的混乱字母串，对我来说没有任何意义。现在我只想知道我是否错过了进一步调整模型之类的东西，或者我可能以错误的方式进行了操作。
我尝试过 HuggingFace 上提供的一些预训练医学模型，例如 https://huggingface.co /UFNLP/gatortron-base 还有一些其他生物 llms。]]></description>
      <guid>https://stackoverflow.com/questions/78448547/pretrained-models-generating-a-random-strings</guid>
      <pubDate>Wed, 08 May 2024 12:33:28 GMT</pubDate>
    </item>
    <item>
      <title>如何使用神经网络进行PCB差异检测（黄金样本与实际样本）？</title>
      <link>https://stackoverflow.com/questions/78448316/how-to-use-neural-networks-for-pcb-difference-detection-golden-sample-vs-actua</link>
      <description><![CDATA[我正在开展一个项目，需要检测两块印刷电路板 (PCB) 之间的差异：一个黄金样本（参考）和一个实际样本。我想利用神经网络完成这项任务，但需要有关具体技术和方法的指导。
以下是我的项目详情：

我有黄金样本和实际样本 PCB 的图像或扫描图。目标是自动识别并突出显示这两个 PCB 之间的差异。

具体来说，我正在寻找以下方面的建议：

哪种类型的神经网络架构适合此图像比较任务？
我应该如何构建数据集来训练神经网络？我应该使用带有标记差异的图像对（黄金样本、实际样本）吗？
在将 PCB 图像输入神经网络之前，建议采取哪些预处理步骤来准备 PCB 图像？还有其他考虑因素
或最佳实践可以有效实施这样的系统吗？

有任何见解、教程或代码示例吗？]]></description>
      <guid>https://stackoverflow.com/questions/78448316/how-to-use-neural-networks-for-pcb-difference-detection-golden-sample-vs-actua</guid>
      <pubDate>Wed, 08 May 2024 11:53:48 GMT</pubDate>
    </item>
    <item>
      <title>多标签分类得分</title>
      <link>https://stackoverflow.com/questions/78446615/multi-label-classification-score</link>
      <description><![CDATA[我正在开展一个多标签分类项目，其中包含诸如“团队的惊人支持”之类的短语。被分为诸如“支持”等类别。和“团队”。我已经为此任务训练了一个模型。
我正在寻求有关使用 Langsmith 评估模型性能的最佳方法的建议。具体来说，我想实现一个评分系统：
部分匹配（例如，识别“支持”而不是“团队”）得分一定的值，
完美匹配(例如，识别“支持”和“团队”)得分1，
不相关或不正确的分类会获得不同的指定值。
Langsmith 是否提供可以处理此类评分的内置评估器？如果没有，建议采用什么方法来定制我们的评估指标以适应这些标准？
我尝试了 cot_qa 评估器，但它没有给出部分匹配所需的分数。]]></description>
      <guid>https://stackoverflow.com/questions/78446615/multi-label-classification-score</guid>
      <pubDate>Wed, 08 May 2024 07:03:04 GMT</pubDate>
    </item>
    <item>
      <title>我使用 Ultralytics AI 的代码缓慢且滞后</title>
      <link>https://stackoverflow.com/questions/78446384/my-code-using-ultralytics-ai-is-slow-and-laggy</link>
      <description><![CDATA[我正在使用 OpenCV 开发石头、剪刀、布游戏，但是当我在网络摄像头上本地尝试时，加载时间大约需要 2 分钟，当我看到网络摄像头时，速度非常慢且滞后。我想知道如何解决这个问题。我计划使用 React.js 前端和 Django 或 Flask 后端。我在脚本中做错了什么，或者在添加前端和后端时是否必须更改架构。或者是否有地方可以托管前端和后端以更快地计算并解决问题？或者我应该使用什么工具来代替 OpenCV？
从 ultralytics 导入 YOLO
导入CV2
随机导入
导入时间
从 ultralytics.utils.plotting 导入注释器

# 初始化YOLO模型
模型 = YOLO(&#39;runs\\detect\\train6\\weights\\best.pt&#39;)

# 初始化网络摄像头
上限 = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # 设置帧宽度
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # 设置框架高度
cap.set(cv2.CAP_PROP_FPS, 15) # 限制每秒帧数以减少处理负载

玩家得分 = 0
cpu_分数 = 0

def确定_获胜者（玩家，CPU）：
    全局玩家分数、cpu_分数
    如果玩家==CPU：
        返回“平局！”
    elif (player == &#39;rock&#39; and cpu == &#39;scissors&#39;) 或 \
         (player == &#39;剪刀&#39; and cpu == &#39;布&#39;) 或 \
         （玩家 == &#39;纸&#39; 和 cpu == &#39;石头&#39;）：
        玩家得分 += 1
        返回“玩家获胜！”
    别的：
        cpu_score += 1
        返回“CPU 获胜！”

options = [&#39;石头&#39;, &#39;布&#39;, &#39;剪刀&#39;]

而真实：
    ret, img = cap.read()
    如果不转：
        break # 如果没有捕获到帧则退出循环

    # 使用模型进行预测
    结果 = model.predict(img)
    注释器 = 注释器(img, line_width=2, example_text=&#39;&#39;)

    # 显示倒计时
    [“Rock”、“Paper”、“Shoot!”] 中的倒计时：
        cv2.putText(img, 倒计时, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow(&#39;YOLO V8 检测&#39;, img)
        cv2.waitKey(1000) # 每个倒计时步骤等待 1 秒

    cpu_choice = random.choice(选择)
    玩家选择=无

    如果结果：
        对于结果中的 r：
            盒子 = r.盒子
            对于盒中盒：
                b = 盒子.xyxy[0]
                c = 盒子.cls
                玩家选择 = model.names[int(c)]
                annotator.box_label(b, f&quot;{player_choice} vs CPU: {cpu_choice}&quot;)

    如果玩家选择：
        游戏结果=确定获胜者（玩家选择，CPU选择）
        cv2.putText(img, game_result, (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(img, f&quot;玩家: {player_score} CPU: {cpu_score}&quot;, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

    # 显示带有注释的最终帧
    img = 注释器.result()
    cv2.imshow(&#39;YOLO V8 检测&#39;, img)
    cv2.waitKey(5000) # 显示结果后等待5秒

    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39; &#39;):
        休息

cap.release()
cv2.destroyAllWindows()

我尝试了多线程处理并试图提高循环效率，但没有效果。]]></description>
      <guid>https://stackoverflow.com/questions/78446384/my-code-using-ultralytics-ai-is-slow-and-laggy</guid>
      <pubDate>Wed, 08 May 2024 06:11:12 GMT</pubDate>
    </item>
    <item>
      <title>反向传播中权重按什么顺序更新</title>
      <link>https://stackoverflow.com/questions/78445209/in-what-order-are-weights-updated-in-backpropagation</link>
      <description><![CDATA[假设我有一个像这样的神经网络：
3 个输入节点，
3个隐藏节点，
3个输出节点
我想用反向传播来训练它，假设我已经计算了所有权重的负梯度
但如果我更新 1 个权重，那么负梯度结果就会改变。
如果我先将输入节点 1 的权重更新到隐藏节点 1，会不会是错误的？或者顺序并不重要。
或者我是否必须先更新隐藏层到输出层的权重，然后更新输入层到隐藏层的权重，或者这并不重要]]></description>
      <guid>https://stackoverflow.com/questions/78445209/in-what-order-are-weights-updated-in-backpropagation</guid>
      <pubDate>Tue, 07 May 2024 21:41:36 GMT</pubDate>
    </item>
    <item>
      <title>如何将 QLoRA 微调的 Llama-3-8B 模型保存在磁盘上并使用它，而无需再次下载基本模型</title>
      <link>https://stackoverflow.com/questions/78445069/how-to-save-qlora-fine-tuned-llama-3-8b-model-on-disk-and-use-it-without-the-nee</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78445069/how-to-save-qlora-fine-tuned-llama-3-8b-model-on-disk-and-use-it-without-the-nee</guid>
      <pubDate>Tue, 07 May 2024 21:08:50 GMT</pubDate>
    </item>
    <item>
      <title>训练网络不兼容的 Seq2Seq 问题</title>
      <link>https://stackoverflow.com/questions/78444834/seq2seq-issue-with-training-network-incompatibility</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78444834/seq2seq-issue-with-training-network-incompatibility</guid>
      <pubDate>Tue, 07 May 2024 20:06:16 GMT</pubDate>
    </item>
    <item>
      <title>需要使用 Rand_forest 和 h2o 进行预测的指导</title>
      <link>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</link>
      <description><![CDATA[我有一个随机森林模型，我正在尝试更好地理解它。
为了举例，假设我们有一片蓝莓灌木丛。我们感兴趣的是预测特定灌木丛中腐烂蓝莓的产量以及各个灌木丛中所有蓝莓的收获量。
每个灌木都有一个识别名称：bush_name，例如&#39;bush001&#39;，我们希望根据每个单独的灌木进行预测。例如，我想知道 Bush025 是否在 2/2/22 生产了腐烂的浆果。
为了本示例，输入位于具有以下虚拟结构的 df 中：
train_data &lt;- data.frame(date = c(&quot;2022-01-01&quot;, &quot;2022-01-07&quot;, &quot;2022-02-09&quot;, &quot;2022-05&quot; -01”、“2022-11-01”、“2022-11-02”)、
                   Bush_name = c(“bush001”、“bush001”、“bush001”、“bush043”、“bush043”、“bush043”),
                   错误 = c(2, 0, 1, 0, 3, 1),
                   有腐烂的浆果 = c(1, 0, 0, 1, 1, 0),
                   浆果计数 = c(12, 1, 7, 100, 14, 4),
                   天气 = c(1, 0, 2, 0, 1, 1))

我已经建立了一个随机森林模型，并进行了以下高级设置：
库(agua)
图书馆（防风草）
图书馆（水）

h2o.init(n线程 = -1)

model_fit &lt;- rand_forest(mtry = 10, trees = 100) %&gt;%
  set_engine(“h2o”) %&gt;%
  set_mode(“分类”) %&gt;%
  适合（has_rotten_berry ~ .,
      数据 = train_data) %&gt;%
  step_dummy(灌木名称) %&gt;%
  step_zv(all_predictors()) %&gt;%
  step_normalize(all_predictors())

训练后我确实收到了这条消息：
警告消息：
在 .h2o.processResponseWarnings(res) 中：
  删除坏列和常量列：[bush_name]。

我想知道的是：
当我尝试预测训练模型中的新数据时，似乎我只能使用我已经训练过的灌木丛的 Bush_names 输入新的测试数据。 我假设该模型正在创建特定于灌木丛的预测是否正确？因此必须在训练中输入新的灌木丛信息才能输出这些新灌木丛的未来预测？
示例：我种植了一棵新灌木，bush700，它不存在于原始训练数据集中。如果我尝试使用新的灌木丛数据进行预测，但训练数据中不存在该数据，则会向我传达一条消息：数据中有新的级别。所以我假设因为这些预测似乎是特定于灌木丛的，并且我们无法为新添加的灌木丛获得任何新的灌木丛预测。
这个假设正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</guid>
      <pubDate>Tue, 07 May 2024 16:58:00 GMT</pubDate>
    </item>
    <item>
      <title>最适合实时季节性数据峰值检测的 ML 模型或统计指标是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/78442853/what-are-the-most-suited-ml-models-or-statistical-indicators-for-peak-detection</link>
      <description><![CDATA[我正在尝试创建一种用于实时功耗数据分析的算法。目标很简单：实时检测建筑物中的功耗峰值/尖峰，并采取必要的措施吸收峰值。
数据以功率值 (kW) 流的形式出现，每 10 分钟采样一次。我有一年多的功耗数据集。
数据具有很强的季节性，建筑物的耗电量根据天气、人流量、节假日的不同而变化很大：许多未知参数。
我可以将功率峰值定义为相对值功率的快速激增，与建筑物的季节性趋势无关，持续时间不会超过一个小时（例如：超出正常值的异常）。
这个定义是非常相对的。在图表上，很容易区分峰值。有了数学规则，它就会变得更加复杂，特别是考虑到单个阈值或标准差。
这是两天的数据图表。蓝色部分为功耗。红色表示手动解释的峰值。
正如您所看到的，定义峰值比定义常态或“季节性”更难。一月的峰值与七月的峰值不同。它们没有相同的价值，也没有相同的起源。
这使得很难使用标准差、平均值或阈值等基本工具进行识别。
有几种检测峰值的方法，基于统计和机器学习。我尝试了两者，但我有点迷失了。
第一种方法是我所说的统计方法：比较一个样本的标准差（z 分数）、高于平均值或指数平均值的阈值。 （例如：此处）
那里的问题是不可避免地引入滞后，这使得模型对功耗的快速但季节性的增加以及对“噪声”的敏感性敏感。以及所述峰值对均值的不良影响。基本上，它无法处理建筑物的基本行为。
机器学习对于应对趋势很有用。这让我想到了异常检测模型。乍一看，他们可以了解什么是正常行为并检测异常值+他们大多不受监督，当现实生活中异常值的定义很粗略时，这是一件好事。
当然，我尝试了一下。我使用了 PySad 库并开始尝试以下模型 指南。到目前为止，移动窗口上的 IForest 模型似乎工作得最好，AUROC 分数接近 1。（如果该值低于样本平均值，我通过清空异常分数来消除坑）。
我还尝试了 LOFP 和 KNNCAD，但结果很差。
这里的问题是模型的准确度根据数据集的不同而变化很大，在不太明显的峰值上低至 (AUROC)0,65。
我现在的问题如下：您对用于实时准确检测峰值的合适的 ML 模型或统计方法有什么见解或想法吗？ （自动编码器、CWT、LOF、SVM？）或者您知道更好的方法吗？
我计划结合多种方法，但我觉得将方法准确性的随机性放在一起不会给我带来更好的结果。
我还必须考虑到调整 SARIMA 等高级模型的超参数是不可能的，因为使用该算法的人不是机器学习专家或数据分析师。]]></description>
      <guid>https://stackoverflow.com/questions/78442853/what-are-the-most-suited-ml-models-or-statistical-indicators-for-peak-detection</guid>
      <pubDate>Tue, 07 May 2024 13:26:16 GMT</pubDate>
    </item>
    <item>
      <title>将自定义元数据（边界框）嵌入到 HLS 视频流中</title>
      <link>https://stackoverflow.com/questions/69728455/embed-custom-meta-data-bounding-boxes-into-hls-video-stream</link>
      <description><![CDATA[我想将边界框、标签等嵌入到实时视频流中，然后可以选择在网络浏览器的客户端上绘制它们，并寻找一种方法。 
您能否给我一个提示，告诉我如何“动态”插入元数据？可以使用哪个播放器？]]></description>
      <guid>https://stackoverflow.com/questions/69728455/embed-custom-meta-data-bounding-boxes-into-hls-video-stream</guid>
      <pubDate>Tue, 26 Oct 2021 18:47:39 GMT</pubDate>
    </item>
    </channel>
</rss>