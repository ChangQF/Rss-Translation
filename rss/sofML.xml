<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Sep 2024 06:25:12 GMT</lastBuildDate>
    <item>
      <title>机器学习模型预测训练标签本身的结果</title>
      <link>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</link>
      <description><![CDATA[我正在尝试根据具有“消息”、“尾巴”和“手指”特征的数据构建一个模型来预测“物种”，并标记“物种”（参见下面 data.csv 的前几行）：



消息
手指
尾巴
物种




pluvia arbor aquos
4
no
Aquari


cosmix xeno nebuz odbitaz
5
是
Zorblax


solarix glixx novum galaxum quasar
5
是
Zorblax


arborsectus pesros ekos dootix nimbus
2
是
Florian



我的代码是：
import warnings
warnings.simplefilter(&quot;ignore&quot;)
import pandas as pd
import numpy as np
将 matplotlib.pyplot 导入为 plt
从 sklearn.preprocessing 导入 LabelEncoder
从 sklearn.feature_extraction.text 导入 CountVectorizer
从 sklearn.naive_bayes 导入 MultinomialNB

df = pd.read_csv(&quot;data.csv&quot;)
X = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
X = [str (item) for item in X]
y = df[&quot;species&quot;]

le = LabelEncoder()
y = le.fit_transform(y)

cv = CountVectorizer()
X = cv.fit_transform(X).toarray()

model = MultinomialNB()
model.fit(X, y)

test_data = pd.read_csv(&#39;test.csv&#39;)
test_data_array = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
test_data_array = [str (item) for item in test_data_array]
test_data_array = cv.fit_transform(test_data_array).toarray()

y_prediction = model.predict(test_data_array)
y_prediction = le.inverse_transform(y_prediction)

print(y_prediction)

我按照本教程进行操作一样。
问题是，当我尝试运行它时，除了一些差异外，它只是逐字逐句地输出原始训练数据的物种列（有 493 个结果，而测试数据包含 299 个条目，训练数据包含 500 个条目）。它实际上并没有为测试数据预测任何内容。我不明白为什么代码不起作用。有人能帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</guid>
      <pubDate>Tue, 24 Sep 2024 04:08:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 smote 将过采样数据存储在单独的变量中？</title>
      <link>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</link>
      <description><![CDATA[如何使用 smote 在单独的变量中存储过采样数据？
import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
dataset = pd.read_csv(&#39;https://archive.ics.uci.edu/static/public/17/data.csv&#39;)
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values
le = LabelEncoder()
y = le.fit_transform(y)
smt = SMOTE()
X1, y1 = smt.fit_resample(X, y)
#使用 smote 在单独的变量中过采样数据
#X2 = ?
#y2 = ?

]]></description>
      <guid>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</guid>
      <pubDate>Tue, 24 Sep 2024 04:07:41 GMT</pubDate>
    </item>
    <item>
      <title>CRM潜在客户评分机器学习模型</title>
      <link>https://stackoverflow.com/questions/79016613/crm-lead-scoring-machine-learning-model</link>
      <description><![CDATA[Crm 初创企业潜在客户评分模型。
我们正在开发一个 crm 工具，下面是挑战。
我正在研究 ml 部分，我们有一系列
要实施的事情，其中​​首先是潜在客户评分，然后是客户细分、客户流失预测和销售预测。

冷启动，我们没有任何历史数据。
在这里，我们正在开发一种工具，该工具应该服务于不同领域的不同客户。所以我们可以使用一个单一的模型，还是我们需要为每个客户开发单独的模型。

如果我们对所有客户使用一个大型模型，请推荐使用哪些模型。]]></description>
      <guid>https://stackoverflow.com/questions/79016613/crm-lead-scoring-machine-learning-model</guid>
      <pubDate>Tue, 24 Sep 2024 00:20:12 GMT</pubDate>
    </item>
    <item>
      <title>在语言检测中使用数组作为特征时出现 KeyError</title>
      <link>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</link>
      <description><![CDATA[我正在按照此教程使用机器学习进行语言检测。然而，在我使用的数据集中，有多个变量作为特征。我尝试用 X = data[&quot;Text&quot;] 代替 X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]（message、fingers 和 tail 是我正在使用的三个特征变量），但它会抛出 KeyError；
Traceback（最近一次调用最后一次）：
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;，第 3805 行，在 get_loc
return self._engine.get_loc(casted_key)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;index.pyx&quot;，第 167 行，在pandas._libs.index.IndexEngine.get_loc
文件“index.pyx”，第 196 行，位于 pandas._libs.index.IndexEngine.get_loc
文件“pandas\\_libs\\hashtable_class_helper.pxi”，第 7081 行，位于 pandas._libs.hashtable.PyObjectHashTable.get_item
文件“pandas\\_libs\\hashtable_class_helper.pxi”，第 7089 行，位于 pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

上述异常是导致以下异常的直接原因：

回溯（最近一次调用）：
文件&lt;module&gt; 中的 &quot;c:\Users\usr\Downloads\thecode.py&quot;，第 13 行
X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]
~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py&quot;, 第 4102 行, 位于 __getitem__
indexer = self.columns.get_loc(key)
^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;, 第 3812 行, 位于 get_loc
引发 KeyError(key) err
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

我应该如何实现代码才能使用所有功能而不抛出错误？]]></description>
      <guid>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</guid>
      <pubDate>Mon, 23 Sep 2024 22:15:21 GMT</pubDate>
    </item>
    <item>
      <title>使用斑点检测/openCV 计算黑色圆形种子数量</title>
      <link>https://stackoverflow.com/questions/79016356/counting-black-round-seeds-with-blob-detection-opencv</link>
      <description><![CDATA[我没有接受过 CV 方面的培训，但我想尝试一下 OpenCV 或类似技术，以便能够计算简单的黑色球体（种子，在本例中为拟花椒）。
其他时候，种子中间的白色反射较少，但主要特征是它是“圆形”的、黑色的，几乎总是具有相同的尺寸，并且可以（或有时没有）一个白色的小斑点。





我应该从哪里开始才能让 5 张照片的种子数量大致相同（或者最好是完全相同）？（种子数量相同，我只是在拍摄照片之间摇晃了一下容器）
CV 还是 ML？从哪里开始？
附言：如果有帮助，我也可以尝试物理去除较小的黑色棍子和不好的种子……但理论上，如果可以有可靠的方法可以忽略这些小的“非种子”暗元素，那就太好了……
附言：如果这也能有帮助，我还可以修改拍照的方式……]]></description>
      <guid>https://stackoverflow.com/questions/79016356/counting-black-round-seeds-with-blob-detection-opencv</guid>
      <pubDate>Mon, 23 Sep 2024 21:30:43 GMT</pubDate>
    </item>
    <item>
      <title>通过模型大规模测试预测毒性测定</title>
      <link>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</link>
      <description><![CDATA[我目前正在创建一个模型来预测污染对生物体的毒性测定。
由于没有合适的数据集，所以还没有尝试。我只是想问问我的代码是否合适。欢迎提出批评。此外，如果我遗漏了什么或应该包括什么，请告诉我。
此外，我正在考虑更多模型，例如 RandomForestRegressor、Boosting（AdaBoost、GradientBoost）。我应该考虑这些吗？此外，当我最终获得数据时，是否有任何模型我应该从测试中删除？
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv(&#39;&#39;) # 包含数据的 csv 文件（浓度和死亡率）

# 基本图表
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;Mortality&#39;) 

# 训练与测试的基本划分
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=101) 

# 线性模型
from sklearn.linear_model import LinearRegression 
lr_model = LinearRegression()
lr_model.fit(X_train,y_train)
lr_preds = lr_model.predict(X_test)
from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_absolute_error(y_test, lr_preds)
np.sqrt(mean_absolute_error(y_test, lr_preds))
concentration_range = np.arange(0,100) # 根据最小/最大浓度调整
concentration_preds = lr_model.predict(concentration_range.reshape(-1,1))
plt.figure(figsize = (12,6),dpi = 200)
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;信号&#39;)
plt.plot(concentration_range,concentration_preds)

# 多项式模型
# 用于测试模型的函数
def run_model(model, X_train, y_train, X_test, y_test):
# 拟合模型
model.fit(X_train,y_train)

# 获取指标
preds = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test,preds))
mae = mean_absolute_error(y_test, preds)
print(f&#39;MAE: {mae}&#39;)
print(f&#39;RMSE: {rmse}&#39;)

# 绘制结果模型信号范围
density_range = np.arange(0,100) # 再次调整
density_preds = model.predict(concentration_range.reshape(-1,1))

plt.figure(figsize = (12,8), dpi = 200)
sns.scatterplot(x = &#39;Concentration&#39;, y = &#39;Mortality&#39;, data = df, color = &#39;black&#39;)
plt.plot(concentration_range, density_preds)

来自 sklearn.pipeline 导入 make_pipeline
来自 sklearn.preprocessing 导入 PolynomialFeatures

pipe = make_pipeline(PolynomialFeatures(degree = 2),LinearRegression()) # degree 可调整
run_model(pipe, X_train, y_train, X_test, y_test)

# K-Nearest Neighbors 模型
来自 sklearn.neighbors 导入 KNeighborsRegressor
k_values = [1,2,3,4,5,6,7,8,9,10]
for k in k_values:

model = KNeighborsRegressor(n_neighbors=k)
run_model(model, X_train,y_train,X_test, y_test)

# 决策树模型
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor()
run_model(model, X_train, y_train, X_test, y_test)

# SVR 模型
from sklearn.svm import SVR # 支持向量回归
from sklearn.model_selection import GridSearchCV
svr = SVR()
param_grid = {&#39;C&#39;:[0.01,0.1,1,5,10,100,1000],
&#39;gamma&#39;:[&#39;auto&#39;,&#39;scale&#39;]}

grid = GridSearchCV(svr, param_grid)
run_model(grid, X_train,y_train,X_test, y_test)
]]></description>
      <guid>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</guid>
      <pubDate>Mon, 23 Sep 2024 21:25:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 llm 对象通过单个脚本使用 vLLM 在多个 gpu 上加载多个模型？</title>
      <link>https://stackoverflow.com/questions/79016077/how-does-one-load-multiple-models-on-multiple-gpus-with-vllm-with-a-single-scrip</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79016077/how-does-one-load-multiple-models-on-multiple-gpus-with-vllm-with-a-single-scrip</guid>
      <pubDate>Mon, 23 Sep 2024 19:45:51 GMT</pubDate>
    </item>
    <item>
      <title>量化和混合精度训练</title>
      <link>https://stackoverflow.com/questions/79016046/quantization-and-mixed-precision-training</link>
      <description><![CDATA[如果我使用 bitsandbytes 加载 4 位量化模型，那么使用 fp16 的混合精度训练是否有用，因为我认为混合精度训练会将我的 4 位量化权重膨胀为 16 位精度？如何并行使用量化和混合精度训练？
我尝试使用 fp16 的混合精度训练进行 4 位量化。我这样做的目的是在内存有限的环境中微调 colab 中的 LLM]]></description>
      <guid>https://stackoverflow.com/questions/79016046/quantization-and-mixed-precision-training</guid>
      <pubDate>Mon, 23 Sep 2024 19:33:46 GMT</pubDate>
    </item>
    <item>
      <title>如何实现多元 N 节拍模型</title>
      <link>https://stackoverflow.com/questions/79015943/how-to-implement-multivariate-n-beats-model</link>
      <description><![CDATA[对于基于日期和一个特征的单变量，我们可以创建，但我有 6 个特征，如何将它们实现到单个 N 节拍模型中
我有库存特征，6 个特征和一个目标变量。我应该怎么做，如何训练？]]></description>
      <guid>https://stackoverflow.com/questions/79015943/how-to-implement-multivariate-n-beats-model</guid>
      <pubDate>Mon, 23 Sep 2024 18:52:34 GMT</pubDate>
    </item>
    <item>
      <title>我们如何计算 R 中一个数据集中的一条记录与第二个数据集中的所有记录之间的 Gower 距离？[迁移]</title>
      <link>https://stackoverflow.com/questions/79015729/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</link>
      <description><![CDATA[我想计算数据集 1 的一条记录与数据集 2 的所有记录之间的 Gower 距离。第一种方法如下
library(gower)

data(iris)
dat1 &lt;- iris[1:10,]
dat2 &lt;- iris[11:30,]

# 第一种方法
gower::gower_dist(dat1[1,], dat2)

这给了我长度为 20 的结果。
0.09079365 0.09873016 0.16142857 0.29476190 0.20920635 0.33079365 
0.21936508 0.05000000 0.23952381 0.11507937 0.12095238 0.15079365 
0.16984127 0.24523810 0.16539683 0.12920635 0.17206349 0.03555556 
0.02761905 0.14063492

我可以将第一个值解释为 dat1[1,] 和 dat2[1,] 之间的 gower 距离，将第二个值解释为 dat1[1,] 和 dat2[2,] 之间的 gower 距离，依此类推吗？
让我感到困惑的是，如果我计算
gower::gower_dist(dat1[1,],dat2[1,])

这给了我
0.75

这与 0.09079365 不同。最终，我想计算 dat1 中每个观测值与 dat2 中每个观测值的 Gower 距离。如果我使用第二种方法，我将需要在 dat2 中的所有观测值上添加一个 for 循环，如下所示。
# 第二种方法
for(i in 1:nrow(dat2)) {
print(gower::gower_dist(dat1[1,],dat2[i,]))
}

由于这两种方法给出的结果不同，我应该使用哪一种方法来实现目的？]]></description>
      <guid>https://stackoverflow.com/questions/79015729/how-do-we-calculate-the-gower-distance-between-one-record-in-one-dataset-and-all</guid>
      <pubDate>Mon, 23 Sep 2024 17:37:36 GMT</pubDate>
    </item>
    <item>
      <title>图像拼接中的泊松混合导致图像模糊、鬼影重重</title>
      <link>https://stackoverflow.com/questions/79014990/poisson-blending-in-image-stitching-results-in-blurred-ghostly-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79014990/poisson-blending-in-image-stitching-results-in-blurred-ghostly-images</guid>
      <pubDate>Mon, 23 Sep 2024 14:11:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 tch-rs 在 rust 中实现残差神经网络</title>
      <link>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</link>
      <description><![CDATA[我正在尝试使用 tch-rs (Torch) 在 rust 中实现前馈残差神经网络。
到目前为止，这是我的代码：（这是一个最小的可重现示例）
use tch::{nn::{self, batch_norm1d, layer_norm, BatchNormConfig, ConvConfigND, LayerNormConfig, Module, ModuleT}, Tensor};
const NUM_HIDDEN: i64 = 10;

fn res_block(vs: &amp;nn::Path) -&gt; impl ModuleT {
let mut default = ConvConfigND::default();
default.padding = 1;
let conv1 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn1 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
让 conv2 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn2 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
nn::func_t(|x,train| {
let mut residual = Tensor::new();
x.clone(&amp;residual);
let x = bn1.forward_t(&amp;conv1.forward(x),train).relu();
let x = bn2.forward_t(&amp;conv2.forward(&amp;x),train);
let x = x + residual;
return x.relu();
})
}

当我编译此代码时，出现此错误：
`*mut torch_sys::C_tensor` 无法在线程之间安全地共享
在 `BatchNorm` 中，`*mut torch_sys::C_tensor` 未实现特征 `Sync`，而这是 `{closure@src\nn.rs:11:16: 所要求的11:25}：`&amp;BatchNorm` 实现 `Send` 所需的 Send

当我将 forward_t 行放入 func_t 中时，会发生此问题。
我该如何让它工作？
我也尝试使用顺序网络，但它们无法进一步传递残差变量。有没有办法让它工作？还是我需要做其他事情？]]></description>
      <guid>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</guid>
      <pubDate>Fri, 20 Sep 2024 09:07:36 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：参数 clone_function 和 input_tensors 仅支持顺序模型或功能模型</title>
      <link>https://stackoverflow.com/questions/78796155/valueerror-arguments-clone-function-and-input-tensors-are-only-supported-for-se</link>
      <description><![CDATA[我正在使用Quantization perceived training，参考网上的lstm代码，想把QAT放进lstm，结果遇到了ValueError。
ValueError Traceback (most recent call last)
&lt;ipython-input-11-00669bb76f9d&gt; in &lt;cell line: 6&gt;()
4 return layer
5 
----&gt; 6 annotated_model = tf.keras.models.clone_model(
7 model,
8 clone_function=apply_quantization_to_dense,

/usr/local/lib/python3.10/dist-packages/tf_keras/src/models/cloning.py in clone_model(model, input_tensors, clone_function)
544 # 自定义模型类的情况
545 if clone_function or input_tensors:
--&gt; 546 raise ValueError(
547 &quot;参数 clone_function 和 input_tensors &quot;
548 &quot;仅支持 Sequential 模型 &quot;

ValueError: 参数 clone_function 和 input_tensors 仅支持 Sequential 模型或 Functional 模型。收到类型为“Sequential”的模型，其中 clone_function=&lt;function apply_quantization_to_dense 位于0x78b727ec4040&gt; 和 input_tensors=None

这是我的代码
import keras
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dense、Activation
从 keras.datasets 导入 mnist
从 keras.models 导入 Sequential
从 keras.optimizers 导入 Adam

learning_rate = 0.001
training_iters = 20
batch_size = 128
display_step = 10

n_input = 28
n_step = 28
n_hidden = 128
n_classes = 10

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(-1, n_step, n_input)
x_test = x_test.reshape(-1, n_step, n_input)
x_train = x_train.astype(&#39;float32&#39;)
x_test = x_test.astype(&#39;float32&#39;)
x_train /= 255
x_test /= 255

y_train = keras.utils.to_categorical(y_train, n_classes)
y_test = keras.utils.to_categorical(y_test, n_classes)

model = Sequential()
model.add(LSTM(n_hidden,
batch_input_shape=(None, n_step, n_input),
unroll=True))

model.add(Dense(n_classes))
model.add(Activation(&#39;softmax&#39;))

adam = Adam(lr=learning_rate)
model.summary()
model.compile(optimizer=adam,
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

model.fit(x_train, y_train,
batch_size=batch_size,
epochs=training_iters,
verbose=1,
validation_data=(x_test, y_test))

scores = model.evaluate(x_test, y_test, verbose=0)
print(&#39;LSTM 测试分数：&#39;, scores[0])
print(&#39;LSTM 测试准确率：&#39;, scores[1])

def apply_quantization_to_dense(layer):
if isinstance(layer, tf.keras.layers.LSTM):
return tfmot.quantization.keras.quantize_annotate_layer(layer)
return layer

annotated_model = tf.keras.models.clone_model(
模型，
clone_function=apply_quantization_to_dense，
)
]]></description>
      <guid>https://stackoverflow.com/questions/78796155/valueerror-arguments-clone-function-and-input-tensors-are-only-supported-for-se</guid>
      <pubDate>Fri, 26 Jul 2024 03:41:57 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：多标签指示器不支持混淆矩阵</title>
      <link>https://stackoverflow.com/questions/76635503/valueerror-multilabel-indicator-is-not-supported-confusion-matrix</link>
      <description><![CDATA[我尝试运行时收到的错误消息是“multilabel-indicator 不受支持”：
您能给我任何解决方案或提示吗？
import seaborn as sns
sns.heatmap(confusion_matrix(y_test, y_pred), annot = True)

ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-21-ee6823d584e9&gt; in &lt;cell line: 1&gt;()
----&gt; 1 sns.heatmap(confusion_matrix(y_test, y_pred), annot = True)

/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py infusion_matrix(y_true, y_pred, labels, sample_weight, normalize)
317 y_type, y_true, y_pred = _check_targets(y_true, y_pred)
318 if y_type not in (&quot;binary&quot;, &quot;multiclass&quot;):
--&gt; 319 raise ValueError(&quot;%s is not supports&quot; % y_type)
320 
321 if labels is None:

ValueError: multilabel-indicator is not supports
]]></description>
      <guid>https://stackoverflow.com/questions/76635503/valueerror-multilabel-indicator-is-not-supported-confusion-matrix</guid>
      <pubDate>Fri, 07 Jul 2023 09:06:01 GMT</pubDate>
    </item>
    <item>
      <title>面临 ValueError：目标是多类但平均值='二进制'</title>
      <link>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</link>
      <description><![CDATA[我正在尝试对我的数据集使用朴素贝叶斯算法。我能够找出准确率，但试图找出相同的精确度和召回率。但是，它抛出了以下错误：
ValueError：目标是多类，但平均值=&#39;binary&#39;。请选择其他平均设置。

有人可以建议我如何继续吗？我尝试在精确度和召回率分数中使用average =&#39;micro&#39;。它没有任何错误，但它给出了相同的准确度、精确度和召回率分数。
我的数据集：
train_data.csv：
review,label
颜色和清晰度极佳，正面
可惜图片不如我的 40 英寸三星清晰明亮，负面

test_data.csv：
review,label
图片清晰漂亮，正面
图片不清晰，负面

我的代码：
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confused_matrix

X_train, y_train = pd.read_csv(&#39;train_data.csv&#39;)
X_test, y_test = pd.read_csv(&#39;test_data.csv&#39;)

vec = CountVectorizer() 
X_train_transformed = vec.fit_transform(X_train) 
X_test_transformed = vec.transform(X_test)

clf = MultinomialNB()
clf.fit(X_train_transformed, y_train)

score = clf.score(X_test_transformed, y_test)

y_pred = clf.predict(X_test_transformed)
cm = confused_matrix(y_test, y_pred)

precision = precision_score(y_test, y_pred, pos_label=&#39;positive&#39;)
recall = recall_score(y_test, y_pred, pos_label=&#39;positive&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</guid>
      <pubDate>Tue, 11 Sep 2018 05:28:04 GMT</pubDate>
    </item>
    </channel>
</rss>