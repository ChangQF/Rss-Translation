<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 09 Jan 2025 15:17:55 GMT</lastBuildDate>
    <item>
      <title>请帮我找到 KAN 模型的正确代码[关闭]</title>
      <link>https://stackoverflow.com/questions/79342506/please-help-me-with-the-correct-code-for-the-kan-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79342506/please-help-me-with-the-correct-code-for-the-kan-model</guid>
      <pubDate>Thu, 09 Jan 2025 11:59:08 GMT</pubDate>
    </item>
    <item>
      <title>使用 lgbm 回归器进行交叉验证</title>
      <link>https://stackoverflow.com/questions/79341444/cross-validation-with-lgbm-regressor</link>
      <description><![CDATA[当我使用 lgbm 回归器的交叉验证时，
它仅用于查找 best_num_round
我说得对吗？
与 lgbm 一起使用时，我找不到它的其他用处
我用它训练模型，除了 num boost round 之外找不到其他用处
但我们可以使用早期停止技术来代替它]]></description>
      <guid>https://stackoverflow.com/questions/79341444/cross-validation-with-lgbm-regressor</guid>
      <pubDate>Thu, 09 Jan 2025 05:23:42 GMT</pubDate>
    </item>
    <item>
      <title>Azure AutoML 图像分类作业</title>
      <link>https://stackoverflow.com/questions/79341200/azure-automl-image-classification-job</link>
      <description><![CDATA[我在尝试为 Azure ML 中的数据集创建 MLTable YAML 文件时遇到问题。
我的工作区中有一个默认数据存储，其中包含两个带有图像的文件夹（OK 和 NOK）。我的目标是读取所有图像并使用文件夹名称作为每幅图像的标签。
以下是我到目前为止尝试过的方法：
mltable_yaml = &quot;&quot;&quot;
type: mltable
paths:
- file: ./OK 
- file: ./NOK 
transformations:
- read_from_directory:
image_column: image_url 
folder_column: label 
recursive: true 
&quot;&quot;&quot;

# 创建目录并保存 MLTable
mltable_dir = &quot;image_data&quot;
os.makedirs(mltable_dir, exist_ok=True)
with open(os.path.join(mltable_dir, &quot;MLTable&quot;), &quot;w&quot;) as f:
f.write(mltable_yaml)

training_data = Input(
type=&quot;mltable&quot;,
path=mltable_dir
)

但是，当我运行实验时，我遇到了以下错误：
MLTable 输入无效。UserErrorException：
消息：从数据集获取数据时遇到用户错误。错误：UserErrorException：
消息：MLTable yaml 架构无效：
错误代码：ScriptExecution.Validation
验证错误代码：无效
验证目标：脚本
本机错误：数据流脚本错误：InvalidScriptElement(&quot;read_from_directory&quot;)
ScriptError(InvalidScriptElement(&quot;read_from_directory&quot;))
=&gt; 脚本元素&quot;read_from_directory&quot;无效
InvalidScriptElement(&quot;read_from_directory&quot;)
错误消息：Yaml 脚本无效：InvalidScriptElement(&quot;read_from_directory&quot;)。| session_id=1a30b15a-7e85-498b-b735-2348bfe0625b
InnerException None
ErrorResponse 
{
&quot;error&quot;: {
&quot;code&quot;: &quot;UserError&quot;,
&quot;message&quot;: &quot;MLTable yaml 模式无效:\n错误代码：ScriptExecution.Validation\n验证错误代码：无效\n验证目标：脚本\n本机错误：数据流脚本错误：InvalidScriptElement(\&quot;read_from_directory\&quot;)\n\tScriptError(InvalidScriptElement(\&quot;read_from_directory\&quot;))\n=&gt;无效的脚本元素 \&quot;read_from_directory\&quot;\n\tInvalidScriptElement(\&quot;read_from_directory\&quot;)\n错误消息：Yaml 脚本无效：InvalidScriptElement(\&quot;read_from_directory\&quot;)。| session_id=1a30b15a-7e85-498b-b735-2348bfe0625b&quot;
}
}
InnerException UserErrorException:
消息：MLTable yaml 架构无效：
错误代码：ScriptExecution.Validation
验证错误代码：无效
验证目标：脚本
本机错误：数据流脚本错误：InvalidScriptElement(&quot;read_from_directory&quot;)
ScriptError(InvalidScriptElement(&quot;read_from_directory&quot;))
=&gt; 无效的脚本元素 &quot;read_from_directory&quot;
InvalidScriptElement(&quot;read_from_directory&quot;)
错误消息：Yaml 脚本无效：InvalidScriptElement(&quot;read_from_directory&quot;)。| session_id=1a30b15a-7e85-498b-b735-2348bfe0625b
InnerException None
ErrorResponse 
{
&quot;error&quot;: {
&quot;code&quot;: &quot;UserError&quot;,
&quot;message&quot;: &quot;MLTable yaml 架构无效：\n错误代码：ScriptExecution.Validation\n验证错误代码：无效\n验证目标：脚本\n本机错误：数据流脚本错误：InvalidScriptElement(\&quot;read_from_directory\&quot;)\n\tScriptError(InvalidScriptElement(\&quot;read_from_directory\&quot;))\n=&gt;无效的脚本元素 \&quot;read_from_directory\&quot;\n\tInvalidScriptElement(\&quot;read_from_directory\&quot;)\n错误消息：Yaml 脚本无效：InvalidScriptElement(\&quot;read_from_directory\&quot;)。| session_id=1a30b15a-7e85-498b-b735-2348bfe0625b&quot;
}
}
ErrorResponse 
{
&quot;error&quot;: {
&quot;code&quot;: &quot;UserError&quot;,
&quot;message&quot;: &quot;从数据集获取数据时遇到用户错误。错误：UserErrorException:\n\t消息：MLTable yaml 架构无效:\n错误代码：ScriptExecution.Validation\n验证错误代码：无效\n验证目标：脚本\n本机错误：数据流脚本错误：InvalidScriptElement(\&quot;read_from_directory\&quot;)\n\tScriptError(InvalidScriptElement(\&quot;read_from_directory\&quot;))\n=&gt; 无效脚本元素 \&quot;read_from_directory\&quot;\n\tInvalidScriptElement(\&quot;read_from_directory\&quot;)\n错误 M

从错误详细信息来看，似乎无法识别 read_from_directory 元素，但我不确定如何构造 YAML 以正确将文件夹名称映射到标签。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79341200/azure-automl-image-classification-job</guid>
      <pubDate>Thu, 09 Jan 2025 02:14:54 GMT</pubDate>
    </item>
    <item>
      <title>生物信息学中的分类方法[关闭]</title>
      <link>https://stackoverflow.com/questions/79340781/classification-methods-in-bioinformatic</link>
      <description><![CDATA[生物信息学中序列分类的最佳分类方法是什么：SVM、kNN 还是其他方法？
以下是有关我的任务的一些详细信息：

输入数据由以字母字符串表示的生物序列组成。
我有一个带标签的数据集，其中包含大量样本（约 1200 个序列），但数据集的类别之间可能存在一些不平衡。
最终目标是将序列分类为预定义的类别，例如进化枝。
我可以使用计算资源，但我想平衡性能和计算成本。

我的问题是：

在 SVM 和 kNN 之间，哪一个在生物信息学的序列分类任务中表现更好，在什么条件下？
还有其他方法吗（例如决策树、随机森林或深度学习模型）可能为此类数据提供更好的准确性？
特征表示对这些方法有多重要，我应该优先考虑哪些特定的特征工程或预处理步骤？
]]></description>
      <guid>https://stackoverflow.com/questions/79340781/classification-methods-in-bioinformatic</guid>
      <pubDate>Wed, 08 Jan 2025 21:22:37 GMT</pubDate>
    </item>
    <item>
      <title>在网格搜索中使用 sklearn 特征选择器来评估所有特征的有用性的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/79337434/whats-the-best-way-to-use-a-sklearn-feature-selector-in-a-grid-search-to-evalu</link>
      <description><![CDATA[我正在训练一个 sklearn 分类器，并在管道中插入一个特征选择步骤。通过网格搜索，我想确定允许我最大化性能的特征数量。不过，我想在网格搜索中探索没有特征选择，只有&quot;passthrough&quot; 的可能性步骤，是最大化性能的最佳选择。
这是一个可重现的示例：
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SequentialFeatureSelector
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer

# 加载泰坦尼克号数据集
titanic = sns.load_dataset(&#39;titanic&#39;)

# 选择特征和目标
features = [&#39;age&#39;, &#39;fare&#39;, &#39;sex&#39;]
X = titanic[features]
y = titanic[&#39;survived&#39;]

# 预处理管道数字和分类特征
numeric_features = [&#39;age&#39;, &#39;fare&#39;]
numeric_transformer = Pipeline(steps=[
(&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;)),
(&#39;scaler&#39;, StandardScaler())
])

categorical_features = [&#39;sex&#39;]
categorical_transformer = Pipeline(steps=[
(&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;)),
(&#39;onehot&#39;, OneHotEncoder(drop=&#39;first&#39;))
])

# 合并预处理步骤
preprocessor = ColumnTransformer(transformers=[
(&#39;num&#39;, numeric_transformer, numeric_features),
(&#39;cat&#39;, categorical_transformer, categorical_features)
])

# 初始化分类器和特征选择器
clf = LogisticRegression(max_iter=1000,solver=&#39;liblinear&#39;)
sfs = SequentialFeatureSelector(clf, direction=&#39;forward&#39;)

# 创建一个包含预处理、特征选择和分类的管道
pipeline = Pipeline(steps=[
(&#39;preprocessor&#39;, preprocessor),
(&#39;feature_selection&#39;, sfs),
(&#39;classifier&#39;, clf)
])

# 定义要搜索的参数网格
param_grid = {
&#39;feature_selection__n_features_to_select&#39;: [2],
&#39;classifier__C&#39;: [0.1, 1.0, 10.0], # 正则化强度
}

# 创建并运行网格搜索
grid_search = GridSearchCV(pipeline, param_grid, cv=5)
grid_search.fit(X, y)

# 输出最佳参数和分数
print(&quot;找到最佳参数：&quot;, grid_search.best_params_)
print(&quot;最佳交叉验证分数：&quot;, grid_search.best_score_)

X 此处有三个特征（即使在 预处理器 步骤之后），但上面的网格搜索代码不允许探索使用所有 3 个特征的模型，因为设置
feature_selection__n_features_to_select: [2,3]

将给出 ValueError: n_features_to_select 必须是 &lt; n_features。
这里的障碍是 SequentialFeatureSelector 不将所有特征的选择（又名直通选择器）视为有效的特征选择。
换句话说，我想运行网格搜索，同时考虑
(&#39;feature_selection&#39;, &#39;passthrough&#39;)

在可能的管道配置空间中的设置。有没有一种惯用的/好的方法可以做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/79337434/whats-the-best-way-to-use-a-sklearn-feature-selector-in-a-grid-search-to-evalu</guid>
      <pubDate>Tue, 07 Jan 2025 21:39:17 GMT</pubDate>
    </item>
    <item>
      <title>如何从物理信息神经网络 (PINN) 获取具有初始和边界条件的 PDE 的单一解？</title>
      <link>https://stackoverflow.com/questions/79329941/how-to-get-a-single-solution-from-a-physics-informed-neural-network-pinn-for-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79329941/how-to-get-a-single-solution-from-a-physics-informed-neural-network-pinn-for-a</guid>
      <pubDate>Sun, 05 Jan 2025 01:01:10 GMT</pubDate>
    </item>
    <item>
      <title>关于论文“RL CQL”和“Cal-QL：经过校准的离线 RL 预训练以实现高效的在线微调”的困惑 [关闭]</title>
      <link>https://stackoverflow.com/questions/79310839/confusion-about-papers-rl-cql-and-cal-ql-calibrated-offline-rl-pre-training</link>
      <description><![CDATA[最近看了两篇论文，包括《Conservative Q-Learning for Offline Reinforcement Learning》和《Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning》。
根据CQL的论文，我认为如果一个状态-动作对存在于行为策略收集到的数据集中，那么在训练时就不会受到惩罚（正则项为零）。
因为惩罚项的两个子项抵消了。或者如果它不在数据集中，就会受到第一个子项的惩罚，如下图1所示
（正则项以蓝色突出显示）。因为如果状态-动作对不在数据集中，惩罚项的第二个子项就会为零。所以对于行为策略收集到的状态-动作对，可能由于最大化和引导训练而被高估。因为即使使用目标网络，也只能缓解高估问题。
因此，CQL的估计值与真实值之间的关系可能如图2所示。我上面说的对吗？
图1：
在此处输入图像描述
图2：
在此处输入图像描述
但在Cql-QL中，我们可以看到CQL的估计值明显低于真实值，如图3所示。
图3：
在此处输入图像描述
在论文CQL和Cql-QL中，对CQL估计值与真值关系的描述存在矛盾。
如何理解？我上面的描述对吗？
非常感谢您的回答。
如何理解？我上面的描述对吗？RL专家能给我一个答案吗？]]></description>
      <guid>https://stackoverflow.com/questions/79310839/confusion-about-papers-rl-cql-and-cal-ql-calibrated-offline-rl-pre-training</guid>
      <pubDate>Fri, 27 Dec 2024 03:20:54 GMT</pubDate>
    </item>
    <item>
      <title>如何在调用 MessageGraph 期间传递多个输入？</title>
      <link>https://stackoverflow.com/questions/78907608/how-to-pass-multiple-inputs-during-invoke-to-a-messagegraph</link>
      <description><![CDATA[我们有一个用于 LLMCompiler 实现的 MessageGraph，并且正如预期的那样，我们在运行调用时将用户的问题作为 HumanMessage 对象列表传递（这些对象映射到默认的&quot;messages&quot; 键并传递给提示模板），这对于简单的用例来说工作得很好，但现在我们需要在调用时（而不是在构建图形时）传递额外的信息/上下文，我们对 React 代理做了类似的事情，并且传递类似于 invoke({&quot;messages&quot;:input, &quot;context&quot;:context}) 的字典非常容易。但对于 MessageGraph，这不起作用，看起来运行 invoke(messages) 时传递的消息列表会在提示中自动映射到&quot;messages&quot;键，无法添加其他输入，我尝试传递一个字典 invoke({&quot;messages&quot;:messages, &quot;context&quot;:context})，但没有成功，错误失败：

消息字典必须包含“role”和“content”键，得到
{&quot;messages&quot;:messages,&quot;context&quot;:context
]]></description>
      <guid>https://stackoverflow.com/questions/78907608/how-to-pass-multiple-inputs-during-invoke-to-a-messagegraph</guid>
      <pubDate>Fri, 23 Aug 2024 21:30:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么 RAG 比 LLM 慢？</title>
      <link>https://stackoverflow.com/questions/78432197/why-rag-is-slower-than-llm</link>
      <description><![CDATA[我使用 RAG 和 LLAMA3 来做 AI 机器人。我发现 RAG 和 chromadb 比调用 LLM 本身慢得多。
根据测试结果，仅一个约 1000 个单词的简单网页，检索就需要 2 秒以上：
检索所用时间：2.245511054992676
LLM 所用时间：2.1182022094726562

这是我的简单代码：
embeddings = OllamaEmbeddings(model=&quot;llama3&quot;)
vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
retriever = vectorstore.as_retriever()
question = &quot;什么是 COCONut？&quot;
start = time.time()
retrieved_docs = withdrawer.invoke(question)
formatted_context = Combine_docs(retrieved_docs)
end = time.time()
print(f&quot;检索所用时间：{end - start}&quot;)

start = time.time()
answer = ollama_llm(question, formatted_context)
end = time.time()
print(f&quot;LLM 所用时间：{end - start}&quot;)

我发现当我的 chromaDB 大小只有 1.4M 左右时，检索需要 20 多秒，而 LLM 仍然只需要 3 或 4 秒。我遗漏了什么吗？还是 RAG 技术本身就很慢？]]></description>
      <guid>https://stackoverflow.com/questions/78432197/why-rag-is-slower-than-llm</guid>
      <pubDate>Sun, 05 May 2024 12:28:52 GMT</pubDate>
    </item>
    <item>
      <title>对包含文本和图像的 PDF 进行大型语言模型微调</title>
      <link>https://stackoverflow.com/questions/78251401/fine-tuning-large-language-model-on-pdfs-containing-text-and-images</link>
      <description><![CDATA[我需要对自定义数据集上的 LLM 进行微调，该数据集包含从 PDF 中提取的文本和图像。
对于文本部分，我已成功提取整个文本数据并使用 OpenAI API 生成 JSON/CSV 格式的问题和答案。这种方法对于基于文本的微调非常有效。
但是，我不确定如何处理图像。有人可以建议一种方法或库来帮助我处理图像并将其纳入微调过程吗？
然后稍后，使用微调后的模型进行问答。此外，我不知道该使用哪种模型来完成这项任务。
任何指导、资源或见解都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78251401/fine-tuning-large-language-model-on-pdfs-containing-text-and-images</guid>
      <pubDate>Sun, 31 Mar 2024 13:04:38 GMT</pubDate>
    </item>
    <item>
      <title>predict_proba 如何与交叉验证一起工作？</title>
      <link>https://stackoverflow.com/questions/72638981/how-does-predict-proba-work-with-cross-validation</link>
      <description><![CDATA[使用 5 倍交叉验证创建模型时，会创建 5 个不同的模型。最终模型的选择可能会有所不同：

5 倍创建的模型中估计最佳（或其他标准）的模型或
在所有数据集上训练后创建的模型。

我理解交叉验证用于模型检查，而不是用于模型构建。因此，当在模型上使用 predict_proba 时，这个概率是如何定义的？您能否分享一些论文或文章，讨论如何使用交叉验证在 R 中的插入符号和 Python 中的 sklearn 中进行预测？]]></description>
      <guid>https://stackoverflow.com/questions/72638981/how-does-predict-proba-work-with-cross-validation</guid>
      <pubDate>Wed, 15 Jun 2022 23:47:57 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证的实现</title>
      <link>https://stackoverflow.com/questions/60231102/implementation-of-cross-validation</link>
      <description><![CDATA[我很困惑，因为许多人都有自己的方法来应用交叉验证。例如，有些人将它应用于整个数据集，有些人将它应用于训练集。 
我的问题是，下面的代码是否适合实现交叉验证，并在应用交叉验证的情况下从此类模型进行预测？
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import KFold

model= GradientBoostingClassifier(n_estimators= 10,max_depth = 10, random_state = 0)#sepcifying the model
cv = KFold(n_splits=5, shuffle=True)

from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_val_score

#X - 整个数据集
#y - 整个数据集但仅目标属性

y_pred = cross_val_predict(model, X, y, cv=cv)
scores = cross_val_score(模型，X，y，cv=cv)
]]></description>
      <guid>https://stackoverflow.com/questions/60231102/implementation-of-cross-validation</guid>
      <pubDate>Fri, 14 Feb 2020 17:37:27 GMT</pubDate>
    </item>
    <item>
      <title>如何计算神经网络预测的置信度分数</title>
      <link>https://stackoverflow.com/questions/59851961/how-to-calculate-confidence-score-of-a-neural-network-prediction</link>
      <description><![CDATA[我正在使用深度神经网络模型（在 keras 中实现）进行预测。类似这样的代码：
def make_model():
model = Sequential() 
model.add(Conv2D(20,(5,5),activation = &quot;relu&quot;))
model.add(MaxPooling2D(pool_size=(2,2))) 
model.add(Flatten())
model.add(Dense(20,activation = &quot;relu&quot;))
model.add(Lambda(lambda x: tf.expand_dims(x, axis=1)))
model.add(SimpleRNN(50,activation=&quot;relu&quot;))
model.add(Dense(1,activation=&quot;sigmoid&quot;)) 
model.compile(loss = &quot;binary_crossentropy&quot;,optimizer = adagrad,metrics = [&quot;accuracy&quot;])

返回模型

model = make_model()
model.fit(x_train, y_train, validation_data = (x_validation,y_validation), epochs = 25, batch_size = 25, verbose = 1)

##预测：
prediction = model.predict_classes(x)
probabilities = model.predict_proba(x) #我假设这些是被预测的类的概率

我的问题是分类（二元）问题。我希望计算每个预测的置信度分数，即我想知道 - 我的模型是否 99% 确定它是“0”或 58% 是“0”。
我找到了一些关于如何做到这一点的观点，但无法实现它们。我希望遵循的方法是：“使用分类器，当你输出时，你可以将值解释为属于每个特定类别的概率。你可以使用它们的分布作为你对观察结果属于该类别的信心的粗略衡量标准。”
我应该如何使用类似上述模型的东西进行预测，以便获得对每个预测的信心？我希望有一些实际的例子（最好是在 Keras 中）。]]></description>
      <guid>https://stackoverflow.com/questions/59851961/how-to-calculate-confidence-score-of-a-neural-network-prediction</guid>
      <pubDate>Wed, 22 Jan 2020 02:52:32 GMT</pubDate>
    </item>
    <item>
      <title>验证集上的验证程序</title>
      <link>https://stackoverflow.com/questions/56270679/validation-procedure-on-validation-set</link>
      <description><![CDATA[我很难理解验证步骤；当我不想使用 k 倍交叉验证而只想使用验证集时，我也想得到一些建议。我一直在阅读，但似乎无法正确掌握 k 倍交叉验证：

我是否将初始数据分成 k 倍，然后在 k-1 上进行训练并在剩下的 1 上进行测试，然后继续旋转 - 因此每个折叠都用于测试等。

或者我是否将初始数据分成训练和测试数据 - 然后将训练数据分成 k 倍并进行交叉验证，然后最后在看不见的测试数据上测试准确性？

在 k 倍交叉验证期间如何选择最佳参数？
cross_val_score 在返回分数列表后，是否会在准确率最高的验证步骤中应用最佳参数？ （代码如下）


model = svm.SVC(kernel=&#39;linear&#39;, C=1)
scores = cross_val_score(model, X, y, cv=5)

或者这一步应该手动完成（由我完成）？使用 gridsearchcv 等？

就我而言，我有一个初始数据集，其中包含 400.000 个样本（行）和大约 70 个特征（列）。对我的数据集执行 k 折交叉验证需要很长时间（据我所知，它主要用于较小的数据集），相反，我希望有 3 组数据：训练（90%）验证（5%）和测试（5%）- 对那 5% 进行验证并在该步骤中调整我的模型参数，最后检查测试集的准确性。应该怎么做？
]]></description>
      <guid>https://stackoverflow.com/questions/56270679/validation-procedure-on-validation-set</guid>
      <pubDate>Thu, 23 May 2019 08:05:08 GMT</pubDate>
    </item>
    <item>
      <title>keras：model.predict 和 model.predict_proba 之间有什么区别</title>
      <link>https://stackoverflow.com/questions/40747679/keras-what-is-the-difference-between-model-predict-and-model-predict-proba</link>
      <description><![CDATA[我发现 model.predict 和 model.predict_proba 都给出了相同的二维矩阵，表示每行每个类别的概率。
这两个函数有什么区别？]]></description>
      <guid>https://stackoverflow.com/questions/40747679/keras-what-is-the-difference-between-model-predict-and-model-predict-proba</guid>
      <pubDate>Tue, 22 Nov 2016 17:06:16 GMT</pubDate>
    </item>
    </channel>
</rss>