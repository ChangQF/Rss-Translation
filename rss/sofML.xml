<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 19 Jan 2025 09:15:29 GMT</lastBuildDate>
    <item>
      <title>我无法通过 HuggingFace 教程训练“翻译”模型</title>
      <link>https://stackoverflow.com/questions/79367581/i-cant-train-a-model-from-a-huggingface-tutorial-for-translation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79367581/i-cant-train-a-model-from-a-huggingface-tutorial-for-translation</guid>
      <pubDate>Sat, 18 Jan 2025 16:46:20 GMT</pubDate>
    </item>
    <item>
      <title>如何将样本权重传递给 Keras 多输出模型</title>
      <link>https://stackoverflow.com/questions/79367409/how-to-pass-sample-weights-to-keras-multi-output-model</link>
      <description><![CDATA[我有混合类型多输出（一个回归和一个分类）Keras 模型。我正在尝试为两个输出传递相同的样本权重，如下所示。
import numpy as np
import tensorflow as tf
from tensorflow import keras

# 生成一些样本数据
np.random.seed(42)
X = np.random.rand(1000, 10) # 1000 个样本，10 个特征
y_regression = X.sum(axis=1) + np.random.normal(0, 0.1, 1000) # 回归目标
y_classification = (X.sum(axis=1) &gt; 5).astype(int) # 分类目标（二进制）

# 创建样本权重
sample_weights = np.random.rand(1000)

# 定义具有混合输出的模型
def create_model():
input_layer = keras.layers.Input(shape=(10,))
dense1 = keras.layers.Dense(64,activation=&#39;relu&#39;)(input_layer)
dense2 = keras.layers.Dense(32,activation=&#39;relu&#39;)(dense1)

# 回归输出
regression_output = keras.layers.Dense(1,name=&#39;regression_output&#39;)(dense2)

# 分类输出
classification_output = keras.layers.Dense(1,activation=&#39;sigmoid&#39;,name=&#39;classification_output&#39;)(dense2)

model = keras.Model(inputs=input_layer,outputs=[regression_output,classification_output])

返回模型

model = create_model()

# 使用适当的损失和指标为每个输出编译模型
model.compile(
optimizer=&#39;adam&#39;,
loss={&#39;regression_output&#39;: &#39;mse&#39;, &#39;classification_output&#39;: &#39;binary_crossentropy&#39;},
metrics={&#39;regression_output&#39;: &#39;mae&#39;, &#39;classification_output&#39;: &#39;accuracy&#39;},
)

# 使用样本权重训练模型
history = model.fit(
X,
{&#39;regression_output&#39;: y_regression, &#39;classification_output&#39;: y_classification},
epochs=10,
batch_size=32,
sample_weight=sample_weights,
)

还尝试为每个输出指定权重
history = model.fit(
X,
{&#39;regression_output&#39;: y_regression, &#39;classification_output&#39;: y_classification},
epochs=10,
batch_size=32,
sample_weight={&#39;regression_output&#39;: sample_weights, &#39;classification_output&#39;: sample_weights}, 
)

然而在这两种情况下我都得到了下面的错误，这通常表示 sample_weight 数组的形状和输入数据的形状不匹配，尽管这里不是这种情况。在多输出模型中传递 sample_weight 的正确方法是什么？
KeyError Traceback (most recent call last)
Cell In[18], line 58
49 model.compile(
50 optimizer=&#39;adam&#39;,
51 loss={&#39;regression_output&#39;: &#39;mse&#39;, &#39;classification_output&#39;: &#39;binary_crossentropy&#39;},
52 metrics={&#39;regression_output&#39;: &#39;mae&#39;, &#39;classification_output&#39;: &#39;accuracy&#39;},
53 )
57 # 使用样本权重训练模型
---&gt; 58 history = model.fit(
59 X,
60 {&#39;regression_output&#39;: y_regression, &#39;classification_output&#39;: y_classification},
61 epochs=20,
62 batch_size=32,
63 sample_weight=sample_weights,
64 )

文件 /opt/jupyter/notebooks-generic/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
123 finally:
124 delfiltered_tb

文件 /opt/jupyter/notebooks-generic/.venv/lib/python3.9/site-packages/keras/src/trainers/compile_utils.py:785，位于 CompileLoss.call.&lt;locals&gt;.resolve_path(path, object)
783 def resolve_path(path, object):
784 for _path in path:
--&gt; 785 object = object[_path]
786 return object

KeyError: 0
]]></description>
      <guid>https://stackoverflow.com/questions/79367409/how-to-pass-sample-weights-to-keras-multi-output-model</guid>
      <pubDate>Sat, 18 Jan 2025 15:24:11 GMT</pubDate>
    </item>
    <item>
      <title>在搜索特定对象时，对为 YOLOv5 训练提供哪些图像存在误解 [关闭]</title>
      <link>https://stackoverflow.com/questions/79367331/misunderstanding-of-what-images-to-provide-for-yolov5-training-when-searching-fo</link>
      <description><![CDATA[我有很多要搜索的螺丝示例图像，我有很多问题，而教程似乎没有回答这些问题，他们只是使用现成的数据集完成整个过程，并没有解释任何细微差别。
这些是我的螺丝示例图像，大约有 50 张。如果有必要，我可能会生成更多，但现在让我们保持这种状态。
     
我想在 3840x1960 图像中检测这些对象。显然，我给每幅图像都添加了一个文本文件“0 0.5 0.5 1 1”，因为每幅正片都是一颗螺丝。
但我误解了我还应该提供什么？有些指南说是负片？这是什么意思？我没在寻找其他任何东西。要添加什么？随机的东西？一张纸，上面写着这些螺丝的位置？如果我提供什么都没有的图像，它们应该是什么尺寸？我会查看 3840x1960 图像，但 yolo 无论如何都会调整它们的大小，我应该提供整个背景，好像没有螺丝，还是只是随机的图片？
yolo 模型还会将所有图像调整为相同大小吗？如果将螺丝大小调整为 96x96，而图像中的螺丝大小为 200x200，会怎么样？150x150？训练会考虑到这一点吗？
请指导我并告诉我我的数据集应该是什么样的]]></description>
      <guid>https://stackoverflow.com/questions/79367331/misunderstanding-of-what-images-to-provide-for-yolov5-training-when-searching-fo</guid>
      <pubDate>Sat, 18 Jan 2025 14:39:23 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“torch”（未知位置）导入名称“Tensor”</title>
      <link>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</link>
      <description><![CDATA[我尝试从 PyTorch 导入 Tensor：
从 torch 导入 Tensor

但我一直收到此错误：
ImportError：无法从“torch”（未知位置）导入名称“Tensor”

我尝试过的方法：

检查 PyTorch 是否已安装（pip show torch），我使用的是版本 2.5.1。
重新安装 PyTorch：
pip uninstall torch
pip install torch


在 Python shell 中测试了导入，但错误依然存在。

环境：

Python版本：3.10
PyTorch 版本：2.5.1
操作系统：Windows 10
虚拟环境：是

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</guid>
      <pubDate>Sat, 18 Jan 2025 13:04:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不屏蔽 transformer 中除了多头注意力之外的其他层？[关闭]</title>
      <link>https://stackoverflow.com/questions/79366294/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</link>
      <description><![CDATA[通常在训练 NLP 任务时，我们需要将序列填充到 max_len，以便可以以批处理方式高效处理它们。但是，这些填充的标记不应影响训练（模型参数的更新），因为它们是“虚构的”。
每个人都在谈论掩盖注意力操作的必要性。这是有道理的，因为有效标记不应该关注虚拟标记。但是，我们仍然需要考虑所有其他层（例如 FF 中的线性层、规范化层等）不受填充的影响。
为了简单起见，考虑单个 Transformer-Encoder 层：

从图中可以清楚地看出，FF 和最后的规范化层将填充的标记视为其他每个标记。为了正确屏蔽所有层，我们应该屏蔽损失吗？
例如，假设我们想使用 Transformer 编码器对序列进行分类。我们传递一个形状为 (B, N, E) 的输入 x，其中 B 是批量大小，N 是最大序列长度，E 是嵌入维度。输出具有相同的形状，我们将使用它进行分类。我们可以通过为每个序列提取一个“全局”向量来实现，然后将其传递给特定于任务的头部，如下所示：
x =coder_layer(x)
x = x.mask_fill(mask, -torch.inf) # 在最大操作期间屏蔽填充。
x = torch.max(x, dim=1)[0] # 忽略索引，简化为形状 (B, E)。
loss = loss_fn(cls_head(x), y)

由于 max 操作对任何未选定元素返回 0 梯度，因此所有参数都不会受到填充的影响。我的理解正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/79366294/why-we-dont-mask-other-layers-besides-the-multihead-attention-in-transformers</guid>
      <pubDate>Fri, 17 Jan 2025 23:05:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 3.11.11 中安装 tfx</title>
      <link>https://stackoverflow.com/questions/79365624/how-to-install-tfx-in-python-3-11-11</link>
      <description><![CDATA[我在 Google Colab 上安装 TFX 时遇到了问题，而其他组件如

tensorflow_model_analysis
tensorflow_data_validation
tensorflow_transform
tensorflow_transform.beam

现在可以安装了
只需安装 TFX，它还不起作用
来自 tfx.components 导入 CsvExampleGen、StatisticsGen、SchemaGen、ExampleValidator、Transform、Trainer、Tuner、Evaluator、Pusher
来自 tfx.proto 导入 example_gen_pb2
来自 tfx.orchestration.experimental.interactive.interactive_context 导入 InteractiveContext
来自 tfx.dsl.components.common.resolver 导入 Resolver
来自tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy
from tfx.types import Channel
from tfx.types.standard_artifacts import Model, ModelBlessing

安装 TFX 时出现以下错误

请帮忙，我应该修复哪些错误？]]></description>
      <guid>https://stackoverflow.com/questions/79365624/how-to-install-tfx-in-python-3-11-11</guid>
      <pubDate>Fri, 17 Jan 2025 17:28:55 GMT</pubDate>
    </item>
    <item>
      <title>如何利用多个 CPU 进行 YOLO 训练？</title>
      <link>https://stackoverflow.com/questions/79365374/how-to-utilize-multiple-cpus-for-training-of-yolo</link>
      <description><![CDATA[我可以访问一个没有 GPU 的大型 CPU 集群。通过在多个 CPU 节点之间并行化，是否可以加快 YOLO 训练速度？
文档说 device 参数指定用于训练的计算设备：单个 GPU（device=0）、多个 GPU（device=0,1）、CPU（device=cpu）或 Apple 芯片的 MPS（device=mps）。
那么多个 CPU 呢？]]></description>
      <guid>https://stackoverflow.com/questions/79365374/how-to-utilize-multiple-cpus-for-training-of-yolo</guid>
      <pubDate>Fri, 17 Jan 2025 16:05:46 GMT</pubDate>
    </item>
    <item>
      <title>将 Tensorflow 模型工件部署到 Sagemaker</title>
      <link>https://stackoverflow.com/questions/79363695/deploying-a-tensorflow-model-artifact-to-sagemaker</link>
      <description><![CDATA[我正在尝试将 TensorFlow 模型部署到 Sagemaker 端点。我在 generic_graph.pb 处有模型工件，在 labels.txt 处有模型标签。
我首先创建了一个包含以下内容的 tar 文件：
# #model 目录结构 
# #model.tar.gz
# └── &lt;model_name&gt;
# └── &lt;version_number&gt;
# ═── saved_model.pb
# └── 变量
# ═── labels.txt

我将文件上传到 S3 中的存储桶。然后，我尝试使用以下代码部署模型：
sagemaker_session = sagemaker.Session()
role = &#39;my-role&#39;

model = TensorFlowModel(model_data=&#39;s3://my-bucket/model.tar.gz&#39;,
role=role,
framework_version=&#39;2.3.0&#39;)

predictor = model.deploy(initial_instance_count=1, instance_type=&#39;ml.m5.large&#39;)

我的 cloudwatch 日志中不断出现以下错误：
ValueError: 未找到 SavedModel 包！

不确定还能尝试什么。]]></description>
      <guid>https://stackoverflow.com/questions/79363695/deploying-a-tensorflow-model-artifact-to-sagemaker</guid>
      <pubDate>Fri, 17 Jan 2025 05:19:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 AI 在 GPU 上的训练比 CPU 慢很多</title>
      <link>https://stackoverflow.com/questions/79362113/why-is-my-ai-training-on-gpu-is-a-lot-slower-than-cpu</link>
      <description><![CDATA[我目前正在训练我的简单预测 AI，但我的 GPU 训练速度为每 epoch 40S，而我的 CPU 训练速度为每 epoch 9S
我的 CPU 是 i7-4720HQ，我的 GPU 是 Nvidia 950m
这是我的代码
`import tensorflow as tf
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

df = pd.read_csv(&#39;Updated_Train.csv&#39;)
df = df.drop(columns=&#39;date&#39;)
df = df.drop(columns=&#39;id&#39;)
label_encoder = LabelEncoder()

df[&#39;Country&#39;] = label_encoder.fit_transform(df[&#39;Country&#39;])
df[&#39;Store&#39;] = label_encoder.fit_transform(df[&#39;Store&#39;])
df[&#39;Product&#39;] = label_encoder.fit_transform(df[&#39;Product&#39;])

x = df.iloc[:, :-1]
y = df.iloc[:, -1]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = (
train_dataset
.shuffle(buffer_size=1000) # 打乱数据
.batch(32) # 批次大小为 32
.prefetch(tf.data.AUTOTUNE) # 预取以提高管道性能
)

test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)
with tf.device(&#39;/CPU:0&#39;):
输入 = tf.keras.layers.Input(shape=(3,))
m = tf.keras.layers.Dense(32,activation=&#39;relu&#39;)(输入)
m = tf.keras.layers.Dense(16,activation=&#39;relu&#39;)(m)
m = tf.keras.layers.Dense(8,activation=&#39;relu&#39;)(m)
m = tf.keras.layers.Dense(8,activation=&#39;relu&#39;)(m)
输出 = tf.keras.layers.Dense(1)(m)

model = tf.keras.models.Model(inputs=Input, output=output)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
loss=&#39;mse&#39;)

history = model.fit(train_dataset,
epochs=100,
validation_data=test_dataset)

model.save(&#39;Sticker.keras&#39;)

plt.plot(history.history[&#39;loss&#39;], label=&#39;Training Loss&#39;)
plt.plot(history.history[&#39;val_loss&#39;], label=&#39;Validation Loss&#39;)
plt.xlabel(&#39;Epochs&#39;)
plt.ylabel(&#39;Loss&#39;)
plt.title(&#39;Loss Over时间&#39;)
plt.legend()
plt.show()

`

我的数据有 3 个输入列和 1 个输出列，共 230129 行
我询问了 gpt，他们让我改进数据管道，我照做了，但我的 GPU 每个时期仍然需要 40 秒]]></description>
      <guid>https://stackoverflow.com/questions/79362113/why-is-my-ai-training-on-gpu-is-a-lot-slower-than-cpu</guid>
      <pubDate>Thu, 16 Jan 2025 15:11:47 GMT</pubDate>
    </item>
    <item>
      <title>通过手动汇总值来重现 LGBMRegressor 预测</title>
      <link>https://stackoverflow.com/questions/79361226/reproduce-lgbmregressor-predictions-by-manually-aggregate-the-values</link>
      <description><![CDATA[我正在尝试自己重现 LGBMRegressor 预测，因此当我成功时，我会将平均值转换为中位数。但目前看来我做不到。
这是我为检查是否可以重现结果而创建的简单脚本。
我需要 reg_y_hat 与 self_y_hat 相同。
我遗漏了什么？如果我知道训练中的哪些样本落到每个叶子上，我就可以自己汇总预测...
 import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split

# 生成一些随机回归数据
np.random.seed(42)
X = np.random.rand(100, 5)
y = 4 * X[:, 0] - 2 * X[:, 1] + np.random.rand(100) * 0.1

# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练 LGBMRegressor
model = lgb.LGBMRegressor(objective=&#39;regression&#39;, n_estimators=2, learning_rate=0.1, random_state=42)
model.fit(X_train, y_train)

# 常规预测：
reg_y_hat = model.predict(X_test)

# 获取初始预测（y_train 的平均值）
init_pred = np.mean(y_train)

# 获取训练叶子值
train_leaf_indices = model.predict(X_train, pred_leaf=True)
leaf_samples = {(i, leaf_id): [] for i in range(model.n_estimators) for leaf_id in np.unique(train_leaf_indices[:, i])}

# 存储每个叶子的相应目标值
for i, row in enumerate(train_leaf_indices):
for j, leaf_id in enumerate(row):
leaf_samples[(j, leaf_id)].append(y_train[i])

#计算每个叶子的平均值：
leaf_agg = {}
for key, values in leaf_samples.items():
leaf_agg[key] = np.mean(values)

# 通过聚合平均值并添加初始预测进行预测：
preds = []
test_leaf_indices = model.predict(X_test, pred_leaf=True)
for row_indices in test_leaf_indices:
row_pred = init_pred
for i, leaf_index in enumerate(row_indices):
row_pred += model.learning_rate * (leaf_agg[(i, leaf_index)] - init_pred) # 仅初始预测后叶子的残差贡献
preds.append(row_pred)
self_y_hat = np.array(preds)

# 验证结果
print(&#39;reg_y_hat 之间的差异和 self_y_hat:&#39;, np.abs(reg_y_hat - self_y_hat).sum())
]]></description>
      <guid>https://stackoverflow.com/questions/79361226/reproduce-lgbmregressor-predictions-by-manually-aggregate-the-values</guid>
      <pubDate>Thu, 16 Jan 2025 10:39:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 MAPIE 进行共形预测时，当 alpha 较大时，我会得到空的预测集</title>
      <link>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</guid>
      <pubDate>Thu, 28 Mar 2024 20:28:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Pytorch 中的 KL 散度为负？</title>
      <link>https://stackoverflow.com/questions/78008233/why-kl-divergence-is-negative-in-pytorch</link>
      <description><![CDATA[我尝试使用 Pytorch 获取 2 个分布之间的 KL 散度，但输出通常为负，不应该如此:
import torch 
import torch.nn. functional as F

x_axis_kl_div_values = []
for epoch in range(200):
# 每个 epoch 生成 2 个不同的分布
input_1 = torch.empty(10).normal_(mean=torch.randint(1,50,(1,)).item(),std=0.5).unsqueeze(0)
input_2 = torch.empty(10).normal_(mean=torch.randint(1,50,(1,)).item(),std=0.5).unsqueeze(0)

kl_divergence = F.kl_div(input_1.log(), input_2, reduction=&#39;batchmean&#39;)
x_axis_kl_div_values.append(kl_divergence.item())

x_axis_kl_div_values 
&gt;&gt;&gt; 
[324.4713134765625,
-69.10758972167969,
-92.42606353759766,

我在 Pytorch 论坛上找到了这个，其中提到他们的问题是输入不是适当的分布，而我的代码中并非如此，因为我正在创建正态分布。从这个 SO 线程来看，他们的问题似乎是 nn.KLDivLoss 期望输入是对数概率，但同样，我在代码中这样做了。所以我不确定我遗漏了什么]]></description>
      <guid>https://stackoverflow.com/questions/78008233/why-kl-divergence-is-negative-in-pytorch</guid>
      <pubDate>Fri, 16 Feb 2024 14:58:47 GMT</pubDate>
    </item>
    <item>
      <title>如何获取 mlflow 记录工件的 url？</title>
      <link>https://stackoverflow.com/questions/73815787/how-to-get-url-of-mlflow-logged-artifacts</link>
      <description><![CDATA[我正在运行 ML 管道，在其末尾我使用 mlflow 记录某些信息。我主要在学习 Databricks 的官方 mlflow 跟踪教程。
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

with mlflow.start_run():
n_estimators = 100
max_depth = 6
max_features = 3
# 创建并训练模型
rf = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)
rf.fit(X_train, y_train)
# 进行预测
predictions = rf.predict(X_test)

# 记录参数
mlflow.log_param(&quot;num_trees&quot;, n_estimators)
mlflow.log_param(&quot;maxdepth&quot;, max_depth)
mlflow.log_param(&quot;max_feat&quot;, max_features)

# 记录模型
mlflow.sklearn.log_model(rf, &quot;random-forest-model&quot;)

# 创建指标
mse = mean_squared_error(y_test, predictions)

# 记录指标
mlflow.log_metric(&quot;mse&quot;, mse)

当我在 Databricks 笔记本中运行上述代码块时，会显示以下状态消息：
(1) MLflow 运行
在 MLflow 中记录了 1 次实验运行。了解更多

我可以通过单击 &quot;1 run&quot; 查看记录的信息。
但是，我想自动检索此链接。特别是，我需要指向存储工件的 mlflow uri 的链接。此链接的格式如下：
https://mycompany-dev.cloud.databricks.com/?o=&lt;ID_1&gt;#mlflow/experiments/&lt;ID_2&gt;/runs/&lt;ID_3&gt;

我尝试调查 URL，并通过打印以下信息来查找其中存在的各种 ID 代码：
print(&quot;Tracking URI: &quot;, mlflow.get_tracking_uri())
print(&quot;Run id:&quot;, run.info.run_id)
print(&quot;Experiment:&quot;, run.info.experiment_id)

我发现上面链接中的 &lt;ID_2&gt; 是 experiment_id，而 &lt;ID_3&gt; 是 run_id。但我不知道 &lt;ID_1&gt; 代表什么。此外，我相信应该有一个内置功能来检索已保存工件的链接，而不必手动从各个部分构建链接。但是，到目前为止，我还没有在文档中找到这样的功能。
编辑：现在我发现 &lt;ID_1&gt; 是 Databricks 工作区 ID，我可以轻松访问它。
编辑 2：
但如何以编程方式访问整个 URL 仍然是一个问题，而不必通过在代码中对 URL 的各个部分进行硬编码来逐个构建它。]]></description>
      <guid>https://stackoverflow.com/questions/73815787/how-to-get-url-of-mlflow-logged-artifacts</guid>
      <pubDate>Thu, 22 Sep 2022 13:46:21 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何分类器能够非常快速地做出决策？</title>
      <link>https://stackoverflow.com/questions/34311785/is-there-any-classifier-which-is-able-to-make-decisions-very-fast</link>
      <description><![CDATA[大多数分类算法都是为了提高训练速度而开发的。然而，有没有一个分类器或算法专注于决策速度（计算复杂度低，可实现结构简单）？我可以得到足够的训练数据，并忍受较长的训练时间。]]></description>
      <guid>https://stackoverflow.com/questions/34311785/is-there-any-classifier-which-is-able-to-make-decisions-very-fast</guid>
      <pubDate>Wed, 16 Dec 2015 12:15:26 GMT</pubDate>
    </item>
    <item>
      <title>C++ 决策树实现问题：用代码思考</title>
      <link>https://stackoverflow.com/questions/5646120/c-decision-tree-implementation-question-think-in-code</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/5646120/c-decision-tree-implementation-question-think-in-code</guid>
      <pubDate>Wed, 13 Apr 2011 08:01:29 GMT</pubDate>
    </item>
    </channel>
</rss>