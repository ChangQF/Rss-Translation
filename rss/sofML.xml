<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 01 May 2024 18:17:59 GMT</lastBuildDate>
    <item>
      <title>如何微调代码bert模型/建议可以生成yaml代码的模型</title>
      <link>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</link>
      <description><![CDATA[任何人都可以建议我如何微调 Codebert 模型。有相关文件吗？请给我一些建议。
我想知道 codebert 是开源的，我们可以使用 cpu 运行它吗？可以生成 ymal 代码吗？或者请推荐适合生成ymal代码的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</guid>
      <pubDate>Wed, 01 May 2024 17:45:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 torch autograd 与 functorch 计算的梯度之间存在微小差异？</title>
      <link>https://stackoverflow.com/questions/78414800/why-is-there-a-small-difference-between-gradients-calculated-using-torch-autogra</link>
      <description><![CDATA[我正在使用这个链接解决方案来自上一个问题，比手动循环更有效地计算梯度。
我注意到使用两种方法计算的梯度存在一些细微差别（即 torch.abs(grads_torch - grads_func).sum() 返回 ~10e-06）。什么可以解释这种差异？一种解决方案比另一种更正确吗？
MWE
导入火炬
从torchvision导入数据集，转换
将 torch.nn 导入为 nn

＃＃＃＃＃＃ 设置 ＃＃＃＃＃＃

类 MLP(nn.Module):
    def __init__(自身，输入大小，隐藏大小，输出大小)：
        超级（MLP，自我）.__init__()
        self.fc1 = nn.Linear(输入大小，隐藏大小)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(隐藏大小, 输出大小)
        
    def 前向（自身，x）：
        h = self.fc1(x)
        pred = self.fc2(self.relu(h))
        返回预测值
    
train_dataset = datasets.MNIST(root=&#39;./data&#39;, train=True, download=True,
                            变换=变换.Compose(
                                [transforms.ToTensor(),
                                    变换.Normalize((0.5,),(0.5,))
        ]))

train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=2,shuffle=False)

X, y = next(iter(train_dataloader)) # 随机获取一批数据

net = MLP(28*28, 20, 10) # 定义一个网络


###### 使用 Torch AUTOGRAD GRAD 计算梯度 ######
def计算梯度（模型，X）：
    # 创建一个张量来保存梯度
    梯度 = torch.zeros(X.shape[0], 10, sum(p.numel() for p in model.parameters()))

    # 计算每个输入和目标维度的梯度
    对于范围内的 i(X.shape[0])：
        对于范围 (10) 内的 j：
            model.zero_grad()
            输出 = 模型(X[i])
            # 计算梯度
            grads = torch.autograd.grad(输出[j], model.parameters())
            # 压平梯度并存储它们
            梯度[i, j, :] = torch.cat([g.view(-1) for g in grads])
            
    返回梯度

grads_torch =calculate_gradients(net, X.view(X.shape[0], -1))

###### 现在使用 FUNCTORCH 计算相同的梯度 ######
# 提取函数调用的参数和缓冲区
params = {k: v.detach() for k, v in net.named_pa​​rameters()}
buffers = {k: v.detach() for k, v in net.named_buffers()}

def one_sample(样本):
    # 这将计算单个样本的梯度
    # 我们希望每个输出的梯度与参数相关
    # 这与网络参数的雅可比矩阵相同

    # 定义一个函数，以输入作为返回网络的输出
    call = lambda x: torch.func.function_call(net, (x, 缓冲区), 样本)
    
    # 计算网络与参数的雅可比矩阵
    J = torch.func.jacrev(call)(params)
    
    # J 是一个字典，其中键为参数名称，值为梯度
    # 我们想要一个张量
    grads = torch.cat([v.flatten(1) for v in J.values()],-1)
    返回毕业生

# 不，我们可以使用 vmap 一次性计算所有样本的梯度
grads_func = torch.vmap(one_sample)(X.flatten(1))

print(torch.allclose(grads_torch, grads_func)) # 返回 True
print(torch.abs(grads_torch - grads_func).sum()) # 返回张量(1.4454e-05)
]]></description>
      <guid>https://stackoverflow.com/questions/78414800/why-is-there-a-small-difference-between-gradients-calculated-using-torch-autogra</guid>
      <pubDate>Wed, 01 May 2024 16:14:45 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“ParticleSwarmOptimization”对象没有属性“global_best_fitnes”</title>
      <link>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</link>
      <description><![CDATA[用于特征选择的执行代码 PSO 出错
def 健身（位置）：
    selected_features = np.array(位置, dtype=bool)
    X_selected = X.iloc[:, selected_features]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    分类器 = KNeighborsClassifier()
    分类器.fit(X_train, y_train)
    y_pred = 分类器.预测(X_test)
    准确度=准确度_得分(y_test, y_pred)
    返回精度

将 numpy 导入为 np

粒子群优化类：
    def __init__(自身、n_粒子、n_特征、n_迭代、fitness_function、w=0.5、c1=1、c2=2)：
        self.n_粒子 = n_粒子
        self.n_features = n_features
        self.n_iterations = n_iterations
        self.fitness_function = 健身函数
        自我.w = w
        自身.c1 = c1
        自身.c2 = c2

    def 初始化粒子（自身）：
        返回 np.random.choice([0, 1], size=(self.n_articles, self.n_features))

    def update_velocity(自身、速度、个人最佳、全局最佳、位置)：
        认知 = self.c1 * np.random.rand() * (personal_best - 位置)
        社会 = self.c2 * np.random.rand() * (global_best - 位置)
        返回 self.w * 速度 + 认知 + 社交

    def update_position（自身，位置，速度）：
        返回 np.round(1 / (1 + np.exp(-velocity))).astype(int)

    def 优化（自我）：
        self.best_fitness_history = [] # 添加此行来存储健身历史记录

        # 初始化粒子
        位置 = self.initialize_articles()
        速度 = np.zeros((self.n_articles, self.n_features))

        个人最佳 = 位置.copy()
        Personal_best_fitness = np.array([self.fitness_function(pos) for pos in individual_best])

        self.global_best = individual_best[np.argmax(personal_best_fitness)]
        self.global_best_fitness = np.max(personal_best_fitness)

        对于范围内的迭代（self.n_iterations）：
            对于范围内的 i(self.n_articles)：
                # 更新速度和位置
                速度[i] = self.update_velocity(速度[i], individual_best[i], self.global_best, 位置[i])
                位置[i] = self.update_position(位置[i], 速度[i])

                # 更新个人最好成绩
                current_fitness = self.fitness_function(position[i])
                如果 current_fitness &gt;个人最佳健身[i]：
                    个人最佳[i] = 位置[i].copy()
                    个人最佳健康度[i] = 当前健康度

                    # 更新全局最佳值
                    如果 current_fitness &gt; self.global_best_fitness：
                        self.global_best = 位置[i].copy()
                        self.global_best_fitness = current_fitness
                        
                        self.best_fitness_history.append(self.global_best_fitness)

        返回 self.global_best, self.global_best_fitnes
]]></description>
      <guid>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</guid>
      <pubDate>Wed, 01 May 2024 13:57:37 GMT</pubDate>
    </item>
    <item>
      <title>尝试将 DETR 模型转换为 Tensorflow Lite</title>
      <link>https://stackoverflow.com/questions/78413651/trying-to-convert-a-detr-model-to-tensorflow-lite</link>
      <description><![CDATA[我正在尝试使用 Android 应用程序的 Optimum 将 DETR 拥抱脸部模型转换为 Tensorflow Lite 模型。我安装了要求：
!pip install optimization
!pip 安装最佳[exporters-tf]

然后我尝试了一个转换预训练模型的示例，它可以工作，但在我的模型上：
!optimum-cli export tflite --model /content/drive/MyDrive/Modele/model-litter --sequence_length 128 --task 对象检测 Model_Litter/

Transformer 模块发生错误，原因是没有名为 TFAutoModelForObjectDetection 的属性
2024-05-01 11:53:55.895865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT 警告：找不到 TensorRT
2024-05-01 11:54:01.347392：W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT 警告：找不到 TensorRT
回溯（最近一次调用最后一次）：
  文件“/usr/lib/python3.10/runpy.py”，第 196 行，在 _run_module_as_main 中
    返回_run_code（代码，main_globals，无，
  文件“/usr/lib/python3.10/runpy.py”，第 86 行，在 _run_code 中
    执行（代码，run_globals）
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tflite/__main__.py”，第 148 行，在  中
    主要的（）
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tflite/__main__.py”，第 61 行，在 main 中
    模型 = TasksManager.get_model_from_task(
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py”，第 1905 行，在 get_model_from_task 中
    model_class = TasksManager.get_model_class_for_task(
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py”，第 1375 行，在 get_model_class_for_task 中
    返回 getattr(loaded_library, model_class_name)
  文件“/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py”，第 1503 行，在 __getattr__ 中
    raise AttributeError(f&quot;模块 {self.__name__} 没有属性 {name}&quot;)
AttributeError：模块转换器没有属性 TFAutoModelForObjectDetection
回溯（最近一次调用最后一次）：
  文件“/usr/local/bin/optimum-cli”，第 8 行，在  中。
    系统退出（主（））
  文件“/usr/local/lib/python3.10/dist-packages/optimum/commands/optimum_cli.py”，第 163 行，在 main 中
    服务.run()
  文件“/usr/local/lib/python3.10/dist-packages/optimum/commands/export/tflite.py”，第 243 行，运行中
    subprocess.run(full_command, shell=True, check=True)
  文件“/usr/lib/python3.10/subprocess.py”，第 526 行，运行中
    引发 CalledProcessError(retcode, process.args,
subprocess.CalledProcessError：命令&#39;python3 -moptimum.exporters.tflite --model /content/drive/MyDrive/Modele/model-litter --sequence_length 128 --task object-detection Model_Litter/&#39;返回非零退出状态1

我在一些论坛上看到这个错误可能是因为我没有更新 Transformer 模块，但即使我更新了模块，错误仍然发生。]]></description>
      <guid>https://stackoverflow.com/questions/78413651/trying-to-convert-a-detr-model-to-tensorflow-lite</guid>
      <pubDate>Wed, 01 May 2024 12:09:14 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch YoloV5 模型无法识别物体</title>
      <link>https://stackoverflow.com/questions/78413618/pytorch-yolov5-model-does-not-recognize-objects</link>
      <description><![CDATA[我正在尝试使用模型汽车的部件构建 yolov5 对象检测模型。我为每个部分拍摄了 200 张照片，对其进行了注释，并对模型进行了 50 轮训练。现在，模型根本无法很好地识别零件，我不知道为什么。
奇怪的是，我之前训练的图像总共只少了 111 张，而且模型当时效果很好（除了一个汽车部件）。我可以做些什么来改善结果？
这是代码：
导入火炬
导入CV2
将 numpy 导入为 np

model = torch.hub.load(&#39;ultralytics_yolov5_master&#39;, &#39;custom&#39;, path=&#39;ultralytics_yolov5_master/runs/train/exp3/weights/best.pt&#39;, source=&#39;local&#39;, force_reload=True)
上限 = cv2.VideoCapture(0)
而 cap.isOpened():
    ret, 框架 = cap.read()
    结果=模型（框架）
    cv2.imshow(“YOLO”, np.squeeze(results.render()))

    如果 cv2.waitKey(10) &amp; 0xFF == ord(“q”)：
        休息
cap.release()
cv2.destroyAllWindows()

这些是一些示例训练图像：

结果如下：
]]></description>
      <guid>https://stackoverflow.com/questions/78413618/pytorch-yolov5-model-does-not-recognize-objects</guid>
      <pubDate>Wed, 01 May 2024 12:03:13 GMT</pubDate>
    </item>
    <item>
      <title>移动网络准确率较高，但 val_accuracy 趋于稳定</title>
      <link>https://stackoverflow.com/questions/78412765/mobile-net-high-accuracy-but-val-accuracy-is-plateauing</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78412765/mobile-net-high-accuracy-but-val-accuracy-is-plateauing</guid>
      <pubDate>Wed, 01 May 2024 08:33:18 GMT</pubDate>
    </item>
    <item>
      <title>如何将职位名称映射到广泛的类别[关闭]</title>
      <link>https://stackoverflow.com/questions/78412571/how-to-map-the-job-titles-into-broad-categories</link>
      <description><![CDATA[如果有3个人：A、B、C
A 就读于 IIM A，先后担任会计师、财务分析师、CFO
在IIM B学习的人B曾担任税务审计师、税务顾问、特许会计师、首席财务官
在IIM A学习的C人担任过产品设计师、营销顾问、CMO
然后我们需要根据角色的功能对角色进行分类，以识别模式。
例如：CFO、CMO 都是管理角色
而会计师、税务审计员、税务顾问等可以被标记为财务角色]]></description>
      <guid>https://stackoverflow.com/questions/78412571/how-to-map-the-job-titles-into-broad-categories</guid>
      <pubDate>Wed, 01 May 2024 07:38:06 GMT</pubDate>
    </item>
    <item>
      <title>ValueError（不匹配的列）持续存在</title>
      <link>https://stackoverflow.com/questions/78410491/valueerrormismatched-columns-is-persisting</link>
      <description><![CDATA[在我的代码中，我尝试使用以下代码将数据从数据表放入 df 表（最初为空，仅包含代码定义的 header_row）：
 df = pd.DataFrame(columns=[&#39;time&#39;] + list(map(str, range(30))))
    对于 i，enumerate(sorted(set(data.index.time))) 中的时间：
     df.loc[i] = [time.strftime(format=&#39;%H:%M:%S&#39;)] + list(data.at_time(time)[&#39;load&#39;].values)[:31]

现在数据表看起来（类似地有 30 天的数据）：
导入请求
导入 csv
导入操作系统
从 bs4 导入 BeautifulSoup
从日期时间导入日期时间，时间增量

def get_load_data(日期):
    url = &#39;http://www.delhisldc.org/Loaddata.aspx?mode=&#39;
    print(&#39;抓取&#39;, 日期)
    resp = requests.get(url+date) # 向url发送get请求，获取响应
    soup = BeautifulSoup(resp.text, &#39;lxml&#39;) # 美味的 HTML 汤
    table = soup.find(&#39;table&#39;, {&#39;id&#39;:&#39;ContentPlaceHolder3_DGGridAv&#39;}) # 从html中获取表格
    trs = table.findAll(&#39;tr&#39;) # 提取表的所有行
    if len(trs[1:])!=0: # 如果没有数据，则无需创建 2017 年 8 月的 csv 文件
        csv_filename = &#39;月份数据.csv&#39;
        将 open(csv_filename, &#39;a&#39;) 作为 f：
            作家 = csv.writer(f)
            计数=0
            对于 trs[1:] 中的 tr：
                时间，德里 = tr.findChildren(&#39;font&#39;)[:2]
                writer.writerow([日期+&#39; &#39;+时间.文本, 德里.文本])
                计数+=1
    如果计数！= 288：
        print(&#39;某些负载值丢失..&#39;)
    别的：
        打印（&#39;完成&#39;）

# 日期 = 日期.split(&#39;/&#39;)
# 日期.reverse()
&#39;&#39;.加入（日期）
对于范围 (31, 0, -1) 内的 i：
    昨天 = datetime.today() - timedelta(i)
    昨天 = 昨天.strftime(&#39;%d/01/2023&#39;) #在这里你可以更改日期。到你的数据
    获取加载数据（昨天）


!head 月数据.csv
数据= pd.read_csv（&#39;monthdata.csv&#39;，标题=无，名称= [&#39;日期时间&#39;，&#39;加载&#39;]，index_col = [0]，parse_dates = [0]，infer_datetime_format = True）

现在我希望 df 是这样的（header_row 代表一个月的时间和日期）：

现在，即使 df 和列表（日期+1）具有相同的列，我也不知道为什么会出现此错误（对于本文中的第一个代码块）：
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-165-10ddc3e7faf7&gt;在&lt;细胞系：2&gt;()
      1 df = pd.DataFrame(columns=[&#39;时间&#39;] + list(map(str, range(30))))
      2 对于 i，enumerate(sorted(set(data.index.time))) 中的时间：
----&gt; 3 df.loc[i] = [time.strftime(format=&#39;%H:%M:%S&#39;)] + list(data.at_time(time)[&#39;load&#39;].values)[:31]
      4 # # data.at_time(time).plot()
      5 # # 如果 idx&gt;10: 中断

2帧
_setitem_with_indexer_missing 中的/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py（自身，索引器，值）
   第2156章
   第2157章
-&gt;第2158章
   2159
   第2160章

ValueError：无法设置列不匹配的行

提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78410491/valueerrormismatched-columns-is-persisting</guid>
      <pubDate>Tue, 30 Apr 2024 18:40:39 GMT</pubDate>
    </item>
    <item>
      <title>Google Ads 数据的数据科学/机器学习分析 [关闭]</title>
      <link>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</link>
      <description><![CDATA[我们希望对 Google Ads 数据进行一些机器学习分析，以微调我们的营销效果。有人对方法有什么建议吗？
是否有严肃的 DS/ML 从业者的现有资源正在使用来自 Google Ads 的数据，或许还可以通过其他来源（YouTube 等）进行增强，以生成预测分析以最大化转化价值。
我们正在考虑：
识别并调整不同的关键字值
识别每个营销活动或广告中可能解释效果的不同特征
通过识别“趋势”主题、主题标签等而不是被动方法来探索“套利”关键字值的可能性
生成因果发现/因果推理分析来解释事件之间关系的强度
我们理想地寻找可以向我们展示该领域现有思维的最佳实践/权威分析师/资源。任何提供分析方法的 GitHub 存储库的建议将不胜感激。
我们从“Google Ads”的角度在 google 上搜索了这个问题，并查看了 Reddit，但存在很多噪音和“黑匣子”解决方案，因此我们决定从认真的 DS 从业者的角度来解决这个问题...希望您能帮助。
我们已经通过 PyCaret ML 回归分析对 Google Ads 广告系列、广告和关键字数据进行了分析，并获得了一些基础结果，但我们现在正在寻求有关如何推进这一工作的指导。]]></description>
      <guid>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</guid>
      <pubDate>Tue, 30 Apr 2024 16:38:08 GMT</pubDate>
    </item>
    <item>
      <title>如何解释每个批次预测的相同类别</title>
      <link>https://stackoverflow.com/questions/78406828/how-to-interpret-that-for-each-batch-the-same-class-is-predicted</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78406828/how-to-interpret-that-for-each-batch-the-same-class-is-predicted</guid>
      <pubDate>Tue, 30 Apr 2024 07:12:44 GMT</pubDate>
    </item>
    <item>
      <title>当时间序列元数据变化时如何构建多元时间序列</title>
      <link>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</link>
      <description><![CDATA[我正在根据多变量、地理时间序列进行预测。
我的数据包括每种产品的历史价格和生产数量，不同的地方生产和销售不同的产品组合。例如：



旧金山
第 1 个月
第 2 个月
第 3 个月




小麦





价格（美元）
3
4
3


生产数量T
200
100
150


苹果





价格 美元
1
2
0.8


生产数量 T
20
10
50






布里斯班
第 1 个月
第 2 个月
第 3 个月




大米





价格 美元
3
4
3


生产数量T
200
100
150


香蕉





价格（美元）
5
4
3


生产数量 T
200
300
450



每个地点的产品清单都不同（日期范围和长度也不同，但这些问题的解决方案都有据可查）。我希望检测异常并预测消费类别。我应该如何构建这个结构以进行训练和预测？

我的猜测（您可能可以在这里停止阅读，因为这是新手的猜测，但 SO 建议包括迄今为止所做的工作）：
我可以使用的一种方法是对所有价格进行标准化和平均化。（收集每个地区最重要产品的价格。）但这会删除很多细节。我可以通过种植数量来猜测每种产品的重要性，但这通常会产生误导。价格和产量之间的关系和紧张关系很重要。
我猜蛮力方法是让每个示例中都有每种产品，并为未在某个地区交易的任何产品的时间序列提供一个空标记。不过，那将是一个非常稀疏且庞大的数据集。
我是否可以说 product1=&quot;rice w2v embedding&quot;, product2=&quot;banana w2v embedding&quot;, price_timeseries1=[rice prices], price_timeseries2=[banana prices]（加上生产，在另一个例子中，小麦和苹果也是一样）？有任何模型可以理解这一点吗？
我最好的猜测是将产品分类，例如，将大米和小麦分为“碳水化合物”，然后对每个类别的产品进行标准化，然后取平均值。（我确实有一个层次结构，但有没有办法可以推导或学习分类？）这在统计上有效吗？
源地理数据以行政单位（城镇边界多多边形）为单位。我在考虑两种选择：(a) 将所有内容转换为 100 平方公里的网格，或 (b) 形状质心经度/纬度的 cos(lat).cos(lon), cos(lat).sin(lon), sin(lat)，以获取 3D 中的（缩放）坐标以及面积。选项 (b) 更简单，但管理单位会随时间变化，因此我必须将较旧的数字重新分配到最新的边界。
（我还将添加位置元数据，例如国家、人口、季节时间序列等）
有什么建议/猜测吗？或者只是从单变量开始构建？
我（也许天真地）正在考虑 ARIMA、XGBoost、LSTM、时间序列转换器，也许还有 Mamba（如果相关）。鉴于我完全缺乏经验，我怀疑 XGBoost 可能是复杂性/能力和新手超参数调整技能的最佳结合点，尽管我会尝试更复杂的架构，因为我知道树会错过生产和价格之间的相互作用，这在这里很重要。
非常感谢您的任何提示。]]></description>
      <guid>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</guid>
      <pubDate>Tue, 30 Apr 2024 05:08:43 GMT</pubDate>
    </item>
    <item>
      <title>通过 Keras 训练同时检查不同类型的数据</title>
      <link>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</link>
      <description><![CDATA[在回归任务中，我得到以下数据：

具有已知标签的输入向量。 MSE损失应该用在预测和标签之间。
没有标签的输入向量对，已知模型应给出相似的结果。应在两个预测之间使用 MSE 损失。

同时将这两种数据拟合 Keras 模型的正确方法是什么？
理想情况下，我希望火车循环以交错的方式迭代这两种类型 - 一个有监督的（1）批次，然后是一个自我监督的（2）批次，然后再次监督，等等。
如果重要的话，我正在使用 Jax 后端。 Keras 版本 3.2.1。]]></description>
      <guid>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</guid>
      <pubDate>Thu, 18 Apr 2024 16:05:11 GMT</pubDate>
    </item>
    <item>
      <title>训练精度高 测试精度差</title>
      <link>https://stackoverflow.com/questions/61464796/high-train-accuracy-poor-test-accuracy</link>
      <description><![CDATA[我有一个对 3 个输出进行分类的神经网络。我的数据集非常小，我有 340 张图像用于训练，60 张图像用于测试。我构建了一个模型，当我编译时，结果是这样的：
&lt;前&gt;&lt;代码&gt;纪元 97/100
306/306 [================================] - 46s 151ms/步 - 损失：0.2453 - 准确度：0.8824 - val_loss ：0.3557 - val_accuracy：0.8922
98/100 纪元
306/306 [==============================] - 47s 152ms/步 - 损失：0.2096 - 准确度：0.9031 - val_loss ：0.3795 - val_accuracy：0.8824
99/100 纪元
306/306 [==============================] - 47s 153ms/步 - 损失：0.2885 - 准确度：0.8627 - val_loss ：0.4501 - val_accuracy：0.7745
纪元 100/100
306/306 [================================] - 46s 152ms/步 - 损失：0.1998 - 准确度：0.9150 - val_loss ：0.4586 - val_accuracy：0.8627

当我预测测试图像时，测试精度很差。
我应该怎么办 ？我也使用 ImageDatagenerator 进行数据增强，但结果是相同的。是否因为我的数据集较小。]]></description>
      <guid>https://stackoverflow.com/questions/61464796/high-train-accuracy-poor-test-accuracy</guid>
      <pubDate>Mon, 27 Apr 2020 17:31:25 GMT</pubDate>
    </item>
    <item>
      <title>如何暂时禁用MLFlow？</title>
      <link>https://stackoverflow.com/questions/61088651/how-to-disable-mlflow-temporarily</link>
      <description><![CDATA[是否可以暂时禁用 MLFlow 以调试代码或添加新功能？如果不禁用它，它会保存一堆实际上没有用的执行或未完成的执行。
或者是使用不调用 mlflow.start_run() 的类似代码的最佳策略？]]></description>
      <guid>https://stackoverflow.com/questions/61088651/how-to-disable-mlflow-temporarily</guid>
      <pubDate>Tue, 07 Apr 2020 20:14:15 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归和softmax回归之间的区别</title>
      <link>https://stackoverflow.com/questions/36051506/difference-between-logistic-regression-and-softmax-regression</link>
      <description><![CDATA[我知道逻辑回归用于二分类，而 softmax 回归用于多分类问题。如果我用相同的数据训练几个逻辑回归模型并规范化它们的结果以获得多类分类器，而不是使用一个 softmax 模型，会有什么不同吗？我假设结果是相同的。我可以说：“所有多类分类器都是二分类器的级联结果”。（除了神经元网络）]]></description>
      <guid>https://stackoverflow.com/questions/36051506/difference-between-logistic-regression-and-softmax-regression</guid>
      <pubDate>Thu, 17 Mar 2016 04:08:48 GMT</pubDate>
    </item>
    </channel>
</rss>