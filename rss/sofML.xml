<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 05 Feb 2024 06:18:19 GMT</lastBuildDate>
    <item>
      <title>如何反转输出顺序（javascript、html）</title>
      <link>https://stackoverflow.com/questions/77938868/how-to-reverse-the-output-order-javascript-html</link>
      <description><![CDATA[我想按照输入的顺序输出结果。例如，如果输入的顺序为 abcd，我希望输出也为 abcd。然而，我的代码的问题是它不断改变顺序并将其输出为 dcba。如何反转输出顺序？抱歉我的英语不好..
;

&lt;头&gt;
  &lt;元字符集=“UTF-8”&gt;
  &lt;元名称=“视口”内容=“宽度=设备宽度，初始比例=1.0”&gt;
  &lt;标题&gt;지화 번역기&lt;/title&gt;
  &lt;脚本 src=“https://cdn.jsdelivr.net/npm/@tensorflow/tfjs”&lt;/script&gt;
  &lt;script src=&quot;https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd&quot;&gt;&lt;/script&gt;
&lt;/头&gt;
&lt;正文&gt;
  &lt;h1&gt;지화 번역&lt;/h1&gt;
  &lt;视频 id=“网络摄像头”;宽度＝“640”高度＝“480”自动播放&gt;
  

  &lt;脚本&gt;
    异步函数 setupCamera() {
      const video = document.getElementById(&#39;网络摄像头&#39;);
      const Stream =等待 navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = 流；

      返回新的 Promise((resolve) =&gt; {
        video.onloadedmetadata = () =&gt;; {
          解决（视频）；
        };
      });
    }

    异步函数 loadTeachableMachineModel() {
      const model = wait tf.loadLayersModel(&#39;https://teachablemachine.withgoogle.com/models/o49biL0_D/model.json&#39;);
      返回模型；
    }

    异步函数 PredictWithTeachableMachineModel(模型, 视频) {
      setInterval(async() =&gt; {
        const webcamImage = tf.browser.fromPixels(video);
        const resizedImage = tf.image.resizeBilinear(webcamImage, [224, 224]);
        const normalizedImage = resizedImage.div(255.0);
        const batchedImage = normalizedImage.expandDims(0);

        const 预测 = 等待 model.predict(batchedImage);
        const classId = Predictions.argMax(1).dataSync()[0];
        const className = 等待 getClassLabel(classId);

        显示结果(类名);

        webcamImage.dispose();
        resizedImage.dispose();
        标准化图像.dispose();
        batchedImage.dispose();
        预测.dispose();
      }, 5000);
    }

    异步函数 getClassLabel(classId) {
      const 标签 = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;, &#39;k&#39;, &#39;l &#39;、&#39;m&#39;、&#39;n&#39;、&#39;o&#39;、&#39;p&#39;、&#39;q&#39;、&#39;r&#39;、&#39;s&#39;、&#39;t&#39;、&#39;u&#39;、&#39;v&#39;、&#39;w&#39;、&#39;x&#39;、 &#39;y&#39;, &#39;z&#39;]; // 클래스 레블 목록
      返回标签[classId]；
    }

    函数显示结果（结果）{
      const resultDiv = document.getElementById(&#39;结果&#39;);

      // 5초에 한 번 결과 추у
      resultDiv.innerHTML = `${result}${resultDiv.innerHTML}`;
    }

    异步函数 init() {
      const video = 等待 setupCamera();
      const 模型 = 等待 loadTeachableMachineModel();
      预测WithTeachableMachineModel（模型，视频）；
    }

    在里面（）;
  &lt;/脚本&gt;
&lt;/正文&gt;
&lt;/html&gt;```
]]></description>
      <guid>https://stackoverflow.com/questions/77938868/how-to-reverse-the-output-order-javascript-html</guid>
      <pubDate>Mon, 05 Feb 2024 05:53:23 GMT</pubDate>
    </item>
    <item>
      <title>视觉变换器（ViT）总是比 CNN 更好吗？</title>
      <link>https://stackoverflow.com/questions/77938840/is-vision-transformer-vit-always-better-than-cnn</link>
      <description><![CDATA[论文 - AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE 提出了视觉 Transformer并且在许多情况下优于基于 CNN 的模型。
当涉及到序列数据时，我们通常使用 Transformer 模型来代替 RNN、LSTM 等循环模型。
使用 ViT 而不是 CNN 的图像也是同样的情况吗？]]></description>
      <guid>https://stackoverflow.com/questions/77938840/is-vision-transformer-vit-always-better-than-cnn</guid>
      <pubDate>Mon, 05 Feb 2024 05:44:29 GMT</pubDate>
    </item>
    <item>
      <title>存储大量时间序列数据 - 架构和数据策略</title>
      <link>https://stackoverflow.com/questions/77938829/storing-high-volume-time-series-data-schema-and-data-strategy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77938829/storing-high-volume-time-series-data-schema-and-data-strategy</guid>
      <pubDate>Mon, 05 Feb 2024 05:41:02 GMT</pubDate>
    </item>
    <item>
      <title>将机器学习模型部署到云上的工具和技术。使用微软Azure</title>
      <link>https://stackoverflow.com/questions/77938824/tools-technique-to-deploy-ml-models-onto-the-cloud-using-microsoft-azure</link>
      <description><![CDATA[我正在寻找有关在 Microsoft Azure 上部署机器学习模型的指南。具体来说，我想知道针对此任务推荐哪些工具和技术。任何有关最佳实践的建议将不胜感激。

在 Microsoft Azure 上部署机器学习模型的推荐工具和技术是什么？

我应该遵循哪些最佳实践来确保顺利部署以及与其他 Azure 服务集成？

如何监控和管理已部署的模型以确保最佳性能和可靠性？

您是否有推荐的教程或资源来帮助您开始在 Azure 上部署机器学习模型？


我使用 Python 和 TensorFlow 或 Scikit-learn 等流行库开发了一个机器学习模型。现在，我需要将此模型部署到 Microsoft Azure 上，以便其他应用程序和服务可以访问和使用它。
任何见解或建议将不胜感激！预先感谢您。]]></description>
      <guid>https://stackoverflow.com/questions/77938824/tools-technique-to-deploy-ml-models-onto-the-cloud-using-microsoft-azure</guid>
      <pubDate>Mon, 05 Feb 2024 05:39:56 GMT</pubDate>
    </item>
    <item>
      <title>预处理新数据以根据 PyCaret 中的现有模型进行预测</title>
      <link>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</link>
      <description><![CDATA[我在 PyCaret 中有一个经过训练的模型，并且我能够在 setup() 期间对原始训练/测试拆分的测试数据进行预测。我还知道 Predict_model() 的“data”参数用于传递新的/未见过的数据。
我遇到的问题是：看不见的数据的列结构与模型预期的不同，因为模型执行了许多特征转换和编码。我正在尝试弄清楚如何通过相同的预处理步骤运行我的新的未见数据，以便预测 1) 可能，2) 有意义。
预先感谢您的任何见解！！
我尝试过跑步
predict_model（最佳，数据= new_test_data）
我收到KeyErrors：
KeyError：“[&#39;某些功能 1&#39;] 不在索引中”
我已经阅读了有关 get_config 的文档，也许还阅读了 transform() 成员函数，但尚未成功确保对 new_test_data 执行相同的预处理步骤，以便可以使用现有模型对其进行预测。&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</guid>
      <pubDate>Mon, 05 Feb 2024 03:32:23 GMT</pubDate>
    </item>
    <item>
      <title>当原始 ia 约为 %70 时，为什么我的 tf.lite 转换很糟糕？</title>
      <link>https://stackoverflow.com/questions/77938284/why-my-tf-lite-conversion-is-bad-when-the-original-ia-is-about-70</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77938284/why-my-tf-lite-conversion-is-bad-when-the-original-ia-is-about-70</guid>
      <pubDate>Mon, 05 Feb 2024 01:52:54 GMT</pubDate>
    </item>
    <item>
      <title>RNN 的训练循环在每个 epoch 后返回相同的损失</title>
      <link>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</link>
      <description><![CDATA[我正在尝试借助此存储库从头开始构建 RNN (https: //github.com/nicklashansen/rnn_lstm_from_scratch/tree/master），但每个时期后的训练损失保持不变。训练循环的代码如下：
# 超参数
纪元数 = 1000

# 初始化一个新网络
参数 = init_rnn(hidden_​​size=hidden_​​size, vocab_size=vocab_size)

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 轨迹丢失
训练损失、验证损失 = []、[]

def check_if_params_updated(old_params, new_params):
    # 该函数检查两组参数是否不同
    对于 zip 中的 old_param、new_param(old_params, new_params)：
        如果不是 np.array_equal(old_param, new_param):
            return True # 参数已更新
    return False # 参数尚未更新


# 对于每个纪元
对于范围内的 i（num_epochs）：
    
    # 轨迹丢失
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
     # 对于验证集中的每个句子
    对于输入，val_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，_=backward_pass（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        
        # 更新损失
        epoch_validation_loss += 损失
    
    # 对于训练集中的每个句子
    对于输入，train_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，梯度=backward_pass（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        打印（inputs_one_hot.shape）
        
        如果 np.isnan(损失):
            raise ValueError(&#39;梯度消失/爆炸！&#39;)
        
        # 更新参数
        params = update_parameters(params, grads, lr=1e-3)
        
        # 更新损失
        epoch_training_loss += 损失
        
    # 保存绘图损失
    Training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # 每 100 个 epoch 打印损失
    如果我％100==0：
        print(f&#39;Epoch {i}, 训练损失: {training_loss[-1]}, 验证损失: {validation_loss[-1]}&#39;)


# 获取测试集中的第一个句子
输入，目标 = test_set[1]

# One-hot 编码输入和目标序列
input_one_hot = one_hot_encode_sequence（输入，vocab_size）
target_one_hot = one_hot_encode_sequence（目标，vocab_size）

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 前向传递
输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）
output_sentence = [idx_to_word[np.argmax(output)] 用于输出中的输出]
print(&#39;输入句子：&#39;)
打印（输入）

print(&#39;\n目标序列:&#39;)
打印（目标）

print(&#39;\n预测序列:&#39;)
print([idx_to_word[np.argmax(output)] 用于输出中的输出])

# 绘制训练和验证损失图
纪元 = np.arange(len(training_loss))
plt.figure()
plt.plot(epoch, Training_loss, &#39;r&#39;, label=&#39;训练损失&#39;,)
plt.plot(epoch,validation_loss,&#39;b&#39;,label=&#39;验证损失&#39;)
plt.图例()
plt.xlabel(&#39;Epoch&#39;), plt.ylabel(&#39;NLL&#39;)
plt.show()

我尝试检查我的参数是否正在更新，它们确实更新了，还尝试检查梯度，它们并不是指数小。每次迭代后损失都会减少，但总纪元的损失保持不变。您可以在存储库中找到完整的代码，其中包括前向和后向传递(https://github.com/危险dude237/RNN_From_Scratch）。]]></description>
      <guid>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</guid>
      <pubDate>Mon, 05 Feb 2024 00:28:27 GMT</pubDate>
    </item>
    <item>
      <title>在Mini Batch梯度下降中应用StandardScaler，应用错误</title>
      <link>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</link>
      <description><![CDATA[ValueError：需要 2D 数组，却得到 1D 数组：
数组=[0。 0. 0. ... 0. 0. 1.]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

当我尝试运行代码时，我不断收到此错误：
# 分离特征 (X) 和目标变量 (y)
X = np.array(df[&#39;默认&#39;])
y = np.array(df[&#39;默认&#39;])
l = len(X)

# 将数据分为训练集和测试集

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 添加特征标量器 Z 分数标准化

定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)


# 实现小批量梯度

类 mini_batch_gradient_descent:
    
    def create_batch(self,X_train,y_train,batch_size):
        小批量=[]
        数据=np.stack((X_train,y_train),轴=1)
        np.random.shuffle(数据)
        batches=X_train.shape[0]//batch_size
        对于范围内的 i（批次）：
            mini_batch=数据[i*batch_size:(i+1)*batch_size]
            mini_batches.append((mini_batch[:,0], mini_batch[:,1]))
        如果 X_train.shape[0]/batch_size!=0:
            mini_batch=数据[i*batch_size:]
            mini_batches.append((mini_batch[:, 0], mini_batch[:,1]))
        返回小批量
    
    def fit(self,X_train,y_test,alpha,epochs,batch_size):
        self.m=np.random.randn(1,1)
        self.c=np.random.randn(1,1)
        l=len(X_train)
        对于范围内的 i（纪元）：
            批次= self.create_batch（X_train，y_train，batch_size）
            对于批量批次：
                xb=批次[0]
                yb=批次[1]
                xb=xb.reshape(1, xb.shape[0])
                截距=np.sum((np.dot(self.m,xb)+self.c)-yb)
                斜率=np.sum((np.dot(self.m,xb)+self.c)-yb)
                self.m=self.m-alpha*(斜率/l)
                self.c=self.c-alpha*(斜率/l)
    
    def 斜率截距():
        print(f&quot;斜率为 {self.m[0][0]}&quot;)
        print(f&quot;截距为 {self.c[0][0]}&quot;)
        
    
    def 预测（自我，X_test）：
        X_test=X_test.reshape(X_test.shape[0],1)
        self.m=self.m.reshape(self.m.shape[1],self.m.shape[0])
        结果=np.dot(X_test, self.m)+self.c
        返回结果

我尝试使用 loc/iloc，但它一直收到错误。
我正在使用数据帧，然后转换为 np.array 来运行程序。它可以在没有功能缩放器的情况下工作，但当我尝试实现缩放器时，它开始给我错误。不确定在功能扩展方面我还有什么其他选择。]]></description>
      <guid>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</guid>
      <pubDate>Sun, 04 Feb 2024 23:19:53 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 ADNI 分类器将字符串转换为浮点型</title>
      <link>https://stackoverflow.com/questions/77937811/could-not-convert-string-to-float-w-adni-classifier</link>
      <description><![CDATA[导入 pandas 作为 pd
将 numpy 导入为 np
从张量流导入keras
从tensorflow.keras导入层

# 加载数据
数据 = pd.read_csv(“/content/ADNI1_Complete_3Yr_3T_1_31_2024.csv”)

# 将数据拆分为特征和标签
X = data.drop(“组”, axis=1).values
y = 数据[“组”].值

# 对标签进行编码
从 sklearn.preprocessing 导入 LabelEncoder
编码器 = LabelEncoder()
y = 编码器.fit_transform(y)

# 将数据分为训练集和测试集
从 sklearn.model_selection 导入 train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 标准化数据
X_train = X_train.astype(“float32”) / 255.0
X_test = X_test.astype(“float32”) / 255.0

# 重塑数据以包含通道
X_train = np.expand_dims(X_train, -1)
X_test = np.expand_dims(X_test, -1)

# 定义CNN模型
模型 = keras.Sequential([
    层.Conv2D(32, (3, 3), 激活=“relu”, input_shape=(X_train.shape[1], X_train.shape[2], 1)),
    层.MaxPooling2D((2, 2)),
    层.Conv2D(64, (3, 3), 激活=“relu”),
    层.MaxPooling2D((2, 2)),
    层.Conv2D(128, (3, 3), 激活=“relu”),
    层.MaxPooling2D((2, 2)),
    层.Flatten(),
    层.密集（128，激活=“relu”），
    层.密集（3，激活=“softmax”），
]）

# 编译模型
model.compile(loss=“sparse_categorical_crossentropy”，optimizer=“adam”，metrics=[“accuracy”])
model.fit(X_train, y_train)

此 CNN 输出 ValueError 无法将字符串转换为浮点数：&#39;I120798&#39;。我正在使用 ADNI 数据集。数据归一化部分输出错误。我预计这将开始训练 CNN。我应该在此代码中更改哪些内容才能开始使用数据集训练 CNN。]]></description>
      <guid>https://stackoverflow.com/questions/77937811/could-not-convert-string-to-float-w-adni-classifier</guid>
      <pubDate>Sun, 04 Feb 2024 22:20:09 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch ArrayRef 线性神经网络的无效索引问题</title>
      <link>https://stackoverflow.com/questions/77937339/pytorch-arrayref-invalid-index-problem-with-linear-nn</link>
      <description><![CDATA[我头疼，下面的代码让我晚上睡不着觉：
1 导入火炬
  2 导入torch.nn为nn
  3 导入torch.optim作为optim
  4 将numpy导入为np
  6 个样本 = torch.linspace(0, 100,100) # 生成集合
  7 train_split = int(len(样本)*0.8)
  8 x_train, x_test = 样本[:train_split], 样本[train_split:]
  9 y_labels = 2*samples-4 # 定义函数
 10 y_labels += torch.tensor(np.random.normal(0, 5, len(samples))) # 添加噪声
 13类神经网络（nn.Module）：
 14 def __init__(自我):
 15 超级().__init__()
 16 self.fc1 = nn.Linear(1, 1)
 17 def 向前（自身，x）：
 18 返回 self.fc1(x)
 19 模型 = NeuralNetwork()
 20 loss_func = nn.MSELoss()
 21 优化器 = optim.Adam(model.parameters(), lr=0.001)
 22 num_epochs = 50
 23 代表纪元范围（num_epochs）：
 24 用于输入，zip(x_train, y_labels[:train_split]) 中的标签：
 25
 26 y_pred = model(inputs) # 文件“.../torch/nn/modules/linear.py”，第 116 行，向前
    返回 F.线性(输入, self.weight, self.bias)
运行时错误：ArrayRef：无效索引索引= 18446744073709551615；长度 = 0
 27 损失 = loss_func(y_pred, 标签)
 28 优化器.zero_grad()
 29 损失.backward()
 30 优化器.step()
 31 print(&quot;纪元 %d - 损失: %.4f%&quot; % (纪元, 损失))



这是一个简单的单层事情，而且我做得很直观，所以没有必要称我为傻瓜。
我在几台机器上运行它，没有区别......
附注任何有关进一步改进这些野兽的编写过程的建议将不胜感激！！！]]></description>
      <guid>https://stackoverflow.com/questions/77937339/pytorch-arrayref-invalid-index-problem-with-linear-nn</guid>
      <pubDate>Sun, 04 Feb 2024 19:40:19 GMT</pubDate>
    </item>
    <item>
      <title>比较不同模型的 F1 分数的概率阈值图</title>
      <link>https://stackoverflow.com/questions/77935679/comparing-probability-threshold-graphs-for-f1-score-for-different-models</link>
      <description><![CDATA[下面是两个并排的图，针对不平衡的数据集。

我们有一个非常大的不平衡数据集，我们正在以不同的方式处理/转换。每次转换后，我们都会对其运行 xgboost 估计器。
左侧是三个 xgboost 模型在三个不同转换数据集上的 PR 曲线。从左图可以看出，3条PR曲线全部重叠；事实上，其中两个（红色和绿色）曲线下的面积是相同的。
右侧是来自相同三个模型但在不同概率阈值下的 F1 分数（根据测试数据计算）的图。左右图中模型的颜色匹配。红色和绿色模型在不同概率阈值下的峰值 F1 分数大致相同。蓝色模型的峰值 F1 分数略低于其他两个模型的峰值 F1 分数。我的问题是：
&lt;块引用&gt;
a.我可以说，绿色模型比红色模型“远”好，因为它的 F1 分数在很大的概率阈值范围内相当稳定，而红色模型的 F1 分数随着概率阈值的微小变化而迅速下降。概率阈值。
b.红色和蓝色这两种型号中，哪一种更好，为什么？

如果您能给出合理的答复，我将不胜感激，因为它可能对我的工作有所帮助。顺便说一句，我已经进行了大量关于 F1 分数、AUC 和 PR 曲线的讨论，包括这个。
简单地说，这个问题涉及如何解释不同模型的 F1 分数阈值图，因为 PR 曲线没有得出结论。]]></description>
      <guid>https://stackoverflow.com/questions/77935679/comparing-probability-threshold-graphs-for-f1-score-for-different-models</guid>
      <pubDate>Sun, 04 Feb 2024 11:59:48 GMT</pubDate>
    </item>
    <item>
      <title>更改房间图像中的地板纹理[关闭]</title>
      <link>https://stackoverflow.com/questions/77935330/change-the-floor-texture-in-a-room-image</link>
      <description><![CDATA[我正在尝试创建一个房间可视化工具，用户可以在其中上传他们的房间图像，并可以将不同的纹理应用到地板上。我成功地使用 roboflow 中的地板分割模型提取图像中的地板坐标，并将纹理图像应用到坐标上，现在的问题是纹理在某些图像上看起来很好，但在某些图像上看起来更糟。我知道我做错了什么，任何人都可以建议一种方法来处理分段蒙版上的纹理应用程序。我正在附加我得到的输出图像  
这是我现在实际做的事情的逻辑
 来自 PIL 导入图像
    将 numpy 导入为 np
    将 matplotlib.pyplot 导入为 plt
    从 io 导入 BytesIO
    导入base64
    从 roboflow 导入 Roboflow
    
    rf = Roboflow(api_key=&quot;key&quot;)
    项目 = rf.workspace().project(“名称”)
    模型 = 项目.版本(1).模型
    
    # 推断本地图像
    # print(model.predict(“room3.jpg”).json())
    
    # 加载房间和纹理图像
    room_image_path = &#39;newwww.jpg&#39;
    纹理图像路径 = &#39;tex3.jpg&#39;
    房间图像 = Image.open(房间图像路径)
    纹理图像 = Image.open(纹理图像路径)
    
    # 显示房间图像
    # plt.imshow(房间图像)
    # plt.title(&#39;房间图片&#39;)
    # plt.axis(&#39;关闭&#39;)
    # plt.show()
    
    # 显示纹理图像
    # plt.imshow(纹理图像)
    # plt.title(&#39;纹理图像&#39;)
    # plt.axis(&#39;关闭&#39;)
    # plt.show()
    
    # JSON 数据
    json_data = model.predict(“newwww.jpg”).json()
    
    # 提取楼层坐标
    Floor_data = json_data[&#39;预测&#39;][0]
    Floor_points = Floor_data[&#39;点&#39;]
    
    # 创建点的元组列表
    Floor_coordinates = [(point[&#39;x&#39;], point[&#39;y&#39;]) for Floor_points 中的点]
    
    # 打印提取的楼层坐标
    print(&#39;提取的楼层坐标：&#39;)
    打印（地板坐标）
    
    
    # 根据地板坐标创建遮罩的函数
    从 matplotlib.path 导入路径
    
    def create_mask_from_points(image_size, 点):
        # 创建点网格
        y, x = np.mgrid[:image_size[1], :image_size[0]]
        点 = np.array(点)
        路径=路径（点）
        mask = path.contains_points(np.vstack((x.ravel(), y.ravel())).T)
        mask = mask.reshape((image_size[1], image_size[0]))
        返回掩码
    
    # 为地板创建遮罩
    mask = create_mask_from_points(room_image.size, 地板坐标)
    
    # 将纹理叠加在房间图像上
    # 为简单起见，调整纹理大小以匹配房间图像大小
    调整大小的纹理=纹理图像.调整大小（房间图像.大小）
    
    # 使用遮罩来组合图像
    room_with_texture = np.array(room_image)
    room_with_texture[掩码] = np.array(resized_texture)[掩码]
    
    # 转换回图像
    room_with_texture_image = Image.fromarray(room_with_texture)
    
    # 保存结果
    输出图像路径 = &#39;final2.jpg&#39;
    room_with_texture_image.save（输出图像路径）
    
    # 显示结果
    plt.imshow(room_with_texture_image)
    plt.title(&#39;带有纹理叠加的房间&#39;)
    plt.axis(&#39;关闭&#39;)
    plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/77935330/change-the-floor-texture-in-a-room-image</guid>
      <pubDate>Sun, 04 Feb 2024 10:08:55 GMT</pubDate>
    </item>
    <item>
      <title>WEKA凯姆包</title>
      <link>https://stackoverflow.com/questions/77934889/weka-caim-package</link>
      <description><![CDATA[在网络搜索中找不到任何用于 CAIM 离散化的 WEKA 包。我需要 WEKA v3 的软件包。
在 google 上搜索 WEKA 软件包，但没有找到任何内容，但一些文档 说它存在。
谁能提供 WEKA 的 CAIM 包的工作链接吗？]]></description>
      <guid>https://stackoverflow.com/questions/77934889/weka-caim-package</guid>
      <pubDate>Sun, 04 Feb 2024 07:13:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 M3 Mac 上安装 ML-Agents：Onnx 和 Protobuf 问题</title>
      <link>https://stackoverflow.com/questions/77934861/how-to-install-ml-agents-on-m3-mac-onnx-protobuf-issues</link>
      <description><![CDATA[我正在尝试使用 conda 在我的 M3 Mac 上安装 ML-Agents。我按照网络文档中列出的说明进行操作（https://unity-technologies。 github.io/ml-agents/Installation/），但我遇到了 protobuf 版本的问题。我将其更改为 3.6，但这不适用于 onnx，它似乎需要 4.25。我真的不确定如何解决这个问题，如果有任何帮助，我将不胜感激！
以下是我为实现这一点而运行的命令：

conda create -n mlagents python=3.10.12 &amp;&amp; conda 激活 magents
git clone --branch release_21 https://github.com/Unity-Technologies /ml-agents.git
python -m pip install ./ml-agents-envs（已工作）
python -m pip install ./ml-agents
]]></description>
      <guid>https://stackoverflow.com/questions/77934861/how-to-install-ml-agents-on-m3-mac-onnx-protobuf-issues</guid>
      <pubDate>Sun, 04 Feb 2024 06:53:10 GMT</pubDate>
    </item>
    <item>
      <title>拟合和评估模型需要多少时间？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77907135/how-much-time-is-required-to-fit-and-evaluate-a-model</link>
      <description><![CDATA[我想计算每个模型的时间复杂度（LR，DS，k-NN，SVM 和 ANN）找出与时间相比精度最高的最佳模型。为此，我实现了代码。
start_time = perf_counter()
logModel = LogisticRegression()
logModel.fit(X_train, Y_train)

# 训练数据的准确性
x_train_prediction = logModel.predict(X_train)
训练数据准确度 = 准确度得分（x_train_预测，Y_train）
print(&#39;训练数据的准确性:,&#39;,training_data_accuracy)

# 测试数据的准确性
x_test_prediction = logModel.predict(X_test)
test_data_accuracy = precision_score(x_test_prediction, Y_test)
print(&#39;测试数据的准确率得分：&#39;, test_data_accuracy)
生成_模型_报告（Y_测试，x_测试_预测）
结束时间 = perf_counter()
经过时间 = 结束时间 - 开始时间

print(&quot;经过时间：&quot;, elapsed_time)

在此代码中，我在这里使用elapsed_time来计算所需的时间逻辑回归模型。我的代码可以计算时间吗？]]></description>
      <guid>https://stackoverflow.com/questions/77907135/how-much-time-is-required-to-fit-and-evaluate-a-model</guid>
      <pubDate>Tue, 30 Jan 2024 14:33:04 GMT</pubDate>
    </item>
    </channel>
</rss>