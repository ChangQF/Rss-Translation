<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 08 Jan 2024 18:18:38 GMT</lastBuildDate>
    <item>
      <title>尽管进行了学习率调整和正则化，为什么我的模型对 t1、t2、t3 的实时推理预测仍保持静态？</title>
      <link>https://stackoverflow.com/questions/77782249/why-does-my-models-live-inference-prediction-for-t1-t2-t3-remain-static-despi</link>
      <description><![CDATA[我的模型一直遇到一个问题，即时间步 t1、t2 和 t3 的预测在实时推理期间保持停滞或仅在小数点后第 8 或第 9 位发生变化。尽管调整了学习率并实施了 L1 和 L2 正则化，问题仍然存在。我有超过 200 万行数据和 10 多个特征
我正在寻求有关确定此问题的根本原因以及解决该问题的有效解决方案的建议。是什么导致预测缺乏可变性？是否有任何其他步骤或技术可以帮助提高模型在实时推理过程中的性能？
任何见解或建议将不胜感激！
我已经调整了批量大小、学习率，多次使用不同的组合添加正则化器，但仍然没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77782249/why-does-my-models-live-inference-prediction-for-t1-t2-t3-remain-static-despi</guid>
      <pubDate>Mon, 08 Jan 2024 17:34:24 GMT</pubDate>
    </item>
    <item>
      <title>Python LightGBM 错误：joblib.externals.loky.process_executor.TermulatedWorkerError {SIGSEGV(-11)}</title>
      <link>https://stackoverflow.com/questions/77781970/python-lightgbm-error-joblib-externals-loky-process-executor-terminatedworkerer</link>
      <description><![CDATA[我正在开发一个利用 Microsoft 的 lightgbm (lgbm) 库的 python 脚本。虽然我的 lgbm 脚本与 xgboost 和随机森林的脚本非常相似（两者都工作正常），但在使用 lgbm 时，我似乎在 Mac Book Pro 和 MacStudios（带有 M1 芯片）上始终收到以下错误：
joblib.externals.loky.process_executor.TermminateWorkerError：执行程序管理的工作进程意外终止。这可能是由于调用函数时出现分段错误或内存使用过多导致操作系统杀死工作线程造成的。
worker 的退出代码为 {SIGSEGV(-11)}
相关代码：
_train_x、_val_x、_train_y、_val_y = train_test_split(_train_x、_train_y、test_size = 0.2)
    
lgbm_model = LGBMClassifier（bagging_fraction = 0.75，bagging_freq = 5，random_state = 42，verbose = -1，force_col_wise = True）
    
kfoldcv = StratifiedKFold(n_splits=3, shuffle=True, random_state=7)
    
lgbm_random_search = RandomizedSearchCV(估计器 = lgbm_model, param_distributions = self._param_dict, n_iter = self.num_searches, cv = kfoldcv, verbose=2, random_state=42, n_jobs=-1)
    
lgbm_random_search.fit(_train_x, _train_y)

self._CrossVal_largest_accscore = lgbm_random_search.best_score_
    
lgbm_model = LGBMClassifier(n_jobs=-1，verbose=-1，force_col_wise=True，bagging_fraction = 0.75，bagging_freq = 5，**lgbm_random_search.best_params_)

lgbm_model.fit(_train_x, _train_y, 回调=[early_stopping(50), log_evaluation(50)], eval_set=[(_val_x,_val_y)])

注意，当我简单地删除子句 njobs=-1 时，我的程序在运行以下行时就会终止：
lgbm_random_search.fit(_train_x, _train_y)
环境：
系统软件概述：
系统版本：macOS 14.0 (23A344)
内核版本：Darwin 23.0.0
启动卷：Macintosh
HD启动模式：正常
安全虚拟内存：已启用
系统完整性保护：已启用

硬件概述：
&lt;预&gt;&lt;代码&gt; 型号名称：MacBook Pro
  型号：MK1F3B/A
  芯片：苹果M1 Pro
  核心总数：10（8 个性能和 2 个效率）
  内存：16GB
  系统固件版本：10151.1.1
  操作系统加载程序版本：10151.1.1
  激活锁状态：已启用

应用软件
Visual Studio 代码==1.72.2
蟒蛇==3.10.121

Python 包
&lt;小时/&gt;
anaconda-client==1.12.0
anaconda-navigator==2.4.2
康达==23.7.2
conda-build==3.26.0
joblib==1.3.0
光GBM==4.0.0
matplotlib==3.7.1
matplotlib-内联==0.1.6
numpy==1.23.5
熊猫==2.0.3
scikit-image==0.20.0
scikit学习==1.3.0
scipy==1.11.1
统计模型==0.14.0
sympy==1.12
xgboost==2.0.0

感谢您的宝贵时间和任何帮助，非常感谢
我已经审查并尝试了以下网站中的一些建议解决方案，但无济于事（例如删除 njobs 参数；添加 &#39;pre_dispatch=2&#39; 参数；重新安装 anaconda、lightgbm、joblib；使用较少数量的估计器 30 到 300等）：

n_jobs=-1 的 GridSearchCV 不适用于决策树/随机森林分类

如何修复/调试 scikit learn 中引发的多进程终止工作错误

GridSearch 中的 TermatedWorkerError

由执行器意外终止

如何修复/调试 scikit learn 中抛出的多进程终止工作错误

TermatedWorkerError：托管工作进程执行者意外终止

使用 RandomizedSearchCV 时的多个作业问题&lt; /p&gt;

]]></description>
      <guid>https://stackoverflow.com/questions/77781970/python-lightgbm-error-joblib-externals-loky-process-executor-terminatedworkerer</guid>
      <pubDate>Mon, 08 Jan 2024 16:42:21 GMT</pubDate>
    </item>
    <item>
      <title>带有我自己的预训练模型的 Sagemaker 批处理变压器</title>
      <link>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:54:18 GMT</pubDate>
    </item>
    <item>
      <title>哪种机器学习模型可用于稀疏时间序列的冷启动预测？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77781715/which-machine-learning-model-for-cold-start-forecasting-on-sparse-time-series</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781715/which-machine-learning-model-for-cold-start-forecasting-on-sparse-time-series</guid>
      <pubDate>Mon, 08 Jan 2024 15:50:08 GMT</pubDate>
    </item>
    <item>
      <title>BayesSearchCV 与 KerasClassifier：调整超参数时出现“无效参数”错误</title>
      <link>https://stackoverflow.com/questions/77781577/bayessearchcv-with-kerasclassifier-invalid-parameter-error-when-tuning-hyperp</link>
      <description><![CDATA[我正在尝试使用 Scikit-Optimize 中的“BayesSearchCV”和 SciKeras 中的“KerasClassifier”来调整 Keras 模型的超参数。但是，我遇到了“ValueError”，指出超参数是“KerasClassifier”的无效参数。
我的代码结构如下：
# 导入必要的库
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入LSTM，Dropout，密集
从tensorflow.keras.optimizers导入Adam、SGD、RMSprop
从tensorflow.keras.wrappers.scikit_learn导入KerasClassifier
从 skopt 导入 BayesSearchCV
from skopt.space import 实数、分类、整数
将 numpy 导入为 np

# 模型构建函数
def create_model（神经元，dropout，优化器，learning_rate，num_features）：
    模型=顺序（）
    model.add(LSTM(神经元, input_shape=(None, num_features), return_sequences=True))
    model.add(Dropout(dropout))
    model.add(LSTM(神经元, return_sequences=False))
    model.add(Dropout(dropout))
    model.add（密集（1，激活=&#39;sigmoid&#39;））
    opt = get_optimizer(优化器, 学习率)
    model.compile(loss=&#39;binary_crossentropy&#39;, 优化器=opt, 指标=[&#39;准确性&#39;])
    返回模型

# 超参数空间
参数 = {
    &#39;神经元&#39;: 整数(25, 200),
    “辍学”：真实（0.1，0.6），
    &#39;优化器&#39;：分类（[&#39;Adam&#39;，&#39;SGD&#39;，&#39;RMSprop&#39;]），
    &#39;学习率&#39;：真实（0.0001，0.5）
}

# 初始化 KerasClassifier
分类器 = KerasClassifier(build_fn=create_model)

# 设置 BayesSearchCV
bayes_search = BayesSearchCV(
    估计器=分类器，
    搜索空间=参数，
    n_iter=50,
    简历=4，
    详细=10，
    n_职位=-1
）

# 拟合过程中出现错误
bayes_search_result = bayes_search.fit(X_train, Y_train)

运行此代码时，我遇到以下错误：
ValueError：估计器 KerasClassifier 的参数丢失无效。这个问题可以通过在 KerasClassifier 构造函数中设置此参数来解决：“KerasClassifier(dropout=0.4380397544384568)”使用“estimator.get_params().keys()”检查可用参数列表

似乎BayesSearchCV正在尝试直接在dropout参数&gt;KerasClassifier，它与 Keras 模型中处理超参数的方式不兼容。
对于如何使用 BayesSearchCV 和 KerasClassifier 为 Keras 模型正确设置超参数调整的任何见解或建议，我将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77781577/bayessearchcv-with-kerasclassifier-invalid-parameter-error-when-tuning-hyperp</guid>
      <pubDate>Mon, 08 Jan 2024 15:25:28 GMT</pubDate>
    </item>
    <item>
      <title>如何构建多输出回归模型的目标变量？</title>
      <link>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</link>
      <description><![CDATA[我想使用 XGBoost 构建一个多输出模型，其中输出是联系客户时预测的销售情况，例如：

output1 是联系后的预测销售额
output2 是未联系情况下的预测销售额。

我的数据如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

区域
销售类别
在线客户
已联系
促销


&lt;正文&gt;

北
3
1
1
1000


北
2
0
0
600


东
2
0
1
500




我打算将“Contacted”和“Sales”合并在一起，形成两个目标列，如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

区域
销售类别
在线客户
Contacted_Sale
NonContacted_Sale


&lt;正文&gt;

北
3
1
1000
0


北
2
0
0
600


东
2
0
500
0




这是正确的方法吗？零会扰乱模型训练并降低模型的准确性吗？将模型与一个预测联系销售和一个预测非接触销售分开的更好方法是吗？]]></description>
      <guid>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:05:39 GMT</pubDate>
    </item>
    <item>
      <title>在 Evotorch 中使用 CMA-ES 进行量子电路综合时的输出结构</title>
      <link>https://stackoverflow.com/questions/77781395/output-structure-when-using-cma-es-for-quantum-circuit-synthesis-in-evotorch</link>
      <description><![CDATA[我正在尝试了解 CMA-ES 的代码结构，以便可以将其用于我的项目，但在输入/输出方面存在问题，以及如何正确实现我的问题，以便可以对其进行解释/优化。
基本思想是生成一堆随机电路，检查哪些电路最接近目标输入/最小门成本，并据此对它们进行排名。
我有一个可修改的电路生成器，用于初始群体或任何需要的新随机电路。
我知道如何将电路与目标输出进行比较，以便我可以对不同电路进行评级。
问题是我很难实现一个可以使用这些函数的更复杂的模型，我以前没有任何使用 Evotorch/ES 的经验，所以文档没有给出我正在尝试的答案从中挤出来。
我主要寻找具有使用 CMA-ES/Evotorch 实现复杂结构经验的人员，因为我对项目的 pennylane 部分充满信心。
我尝试只是生成输入，但已经在努力解决如何将电路提供给 CMA-ES 的问题，所以我一开始就失败了]]></description>
      <guid>https://stackoverflow.com/questions/77781395/output-structure-when-using-cma-es-for-quantum-circuit-synthesis-in-evotorch</guid>
      <pubDate>Mon, 08 Jan 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>向 ML.NET 图像分类训练器添加更多功能</title>
      <link>https://stackoverflow.com/questions/77781236/add-more-features-to-ml-net-image-classification-trainer</link>
      <description><![CDATA[我们正在使用 ML.NET 对图像进行分类。每个图像都应该属于多个类别之一。
这些图像包含产品的不同变体。这些产品的变体有很多相似之处，但也有一些独特的特征。
是否可以将产品的变体作为特征添加到学习算法中，然后将其传递给预测函数？因此，训练可以利用不同产品变体之间的相似性，但我们仍然可以为预测提供提示，因为我们事先知道正在预测哪个产品变体？
或者我是否必须为产品的每个变体训练一个单独的模型？我现在正在这样做，因为我还没有弄清楚如何传递图像数据之外的其他功能。
图像分类任务文档 建议 特征列必须是可变大小的字节向量。.
有关如何改进模型的文档建议 向数据添加上下文。
是否可以添加额外的特征列以及图像数据，或者这对于 ML.NET（或一般情况？）来说是不可能的。]]></description>
      <guid>https://stackoverflow.com/questions/77781236/add-more-features-to-ml-net-image-classification-trainer</guid>
      <pubDate>Mon, 08 Jan 2024 14:35:01 GMT</pubDate>
    </item>
    <item>
      <title>语义消歧（自然语言处理）[关闭]</title>
      <link>https://stackoverflow.com/questions/77780909/semantic-disambiguation-natural-language-processing</link>
      <description><![CDATA[如何创建一个程序来消除文本中的语义歧义？使用预训练的 Bert 模型可以吗？]]></description>
      <guid>https://stackoverflow.com/questions/77780909/semantic-disambiguation-natural-language-processing</guid>
      <pubDate>Mon, 08 Jan 2024 13:56:55 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用强化学习为一款严肃的游戏制作一个Python聊天机器人，我如何将它链接到一个统一的2D游戏[关闭]</title>
      <link>https://stackoverflow.com/questions/77780729/i-am-making-a-python-chatbot-for-a-serious-game-using-reinforcement-learning-ho</link>
      <description><![CDATA[我正在开发一个项目来创建一个教育游戏，我希望将一个Python聊天机器人连接到我的游戏中，作为一个自适应NPC来教授这个主题，假设我有Python脚本来运行这个游戏，我会这样做吗？程序
我尝试过机器学习代理，但它们并不完全是我想要的，它们更多的是针对角色的自适应动作，我想要一个用于对话的聊天机器人，另外有些人给了我连接到 chatgpt api 的链接，但我想制作一个离线游戏，在游戏内使用 json 文件存储数据，所以如果有人可以指导我该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/77780729/i-am-making-a-python-chatbot-for-a-serious-game-using-reinforcement-learning-ho</guid>
      <pubDate>Mon, 08 Jan 2024 13:43:00 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow 中加载数据时的内存限制</title>
      <link>https://stackoverflow.com/questions/77780671/memory-limit-while-loading-data-in-tensorflow</link>
      <description><![CDATA[我使用 mobilenet 从 UCF-Anomaly 数据集的视频中提取特征，并将特征保存为 numpy 数组。这些 numpy 数组的总大小约为 45GB。假设我有一个以下模型。我如何加载该数据进行训练。我看到了与张量流管道相关的帖子和​​文档，但无法理解任何内容。我是机器学习的初学者。
模型 = 顺序 (...)
我尝试一次加载所有数据，但我的计算机崩溃了。]]></description>
      <guid>https://stackoverflow.com/questions/77780671/memory-limit-while-loading-data-in-tensorflow</guid>
      <pubDate>Mon, 08 Jan 2024 13:38:48 GMT</pubDate>
    </item>
    <item>
      <title>我使用 XGB 分类器训练了数据集</title>
      <link>https://stackoverflow.com/questions/77776124/ive-trained-dataset-using-xgb-classifier</link>
      <description><![CDATA[我从我的队友那里得到了我们项目的这部分代码，我在本地遇到了这个错误，我已经使用 XGB 分类器训练了数据集。
我的代码是：
# XGBoost 分类器模型
从 xgboost 导入 XGBClassifier

# 实例化模型
xgb = XGBClassifier()

# 拟合模型
xgb.fit(X_train,y_train)

然后我得到了这个错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
[70] 中的单元格，第 8 行
      5 xgb = XGBClassifier()
      7#拟合模型
----&gt; 8 xgb.fit(X_train,y_train)

文件 ~/anaconda3/envs/project/lib/python3.10/site-packages/xgboost/core.py:730，在 require_keyword_args..throw_if..inner_f(*args, **kwargs ）
    728 k, arg in zip(sig.parameters, args)：
    第729章
--&gt;第730章

文件〜/anaconda3/envs/project/lib/python3.10/site-packages/xgboost/sklearn.py:1471，在XGBClassifier.fit（self，X，y，sample_weight，base_margin，eval_set，eval_metric，early_stopping_rounds，verbose， xgb_model、sample_weight_eval_set、base_margin_eval_set、feature_weights、回调）
   第1466章
   第1467章
   第1468章
   第1469章
   第1470章
-&gt;第1471章
   攀上漂亮女局长之后1472 ”
   第1473章
   第1474章
   第1476章
   第1478章

ValueError：从“y”的唯一值推断出无效的类。

预期：[0 1]，得到[-1 1]，，我听说 y_train 必须在较新的更新中进行编码，但我对这些事情有点陌生，我也不知道如何做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/77776124/ive-trained-dataset-using-xgb-classifier</guid>
      <pubDate>Mon, 08 Jan 2024 03:09:32 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 模型不适用于不同宽高比的图片</title>
      <link>https://stackoverflow.com/questions/77774178/tensorflow-model-not-working-with-pics-of-different-aspect-ratios</link>
      <description><![CDATA[在我的模型训练中，我遇到了两个问题：

我的模型只能接受 32x32 图像。
我的模型给出了类似“Class 99”的输出当给定 32x32 图像时。它将狗、汽车和飞机的 32x32 图片都分类为 99 类，而我需要一个清晰的标签。

这是两个问题的图像和代码。
99 级
不同的宽高比
导入tensorflow为tf

提前停止 = tf.keras.callbacks.EarlyStopping(
    监视器=“丢失”，
    最小增量=0，
    耐心=10，
    详细=1，
    模式=“自动”，
    基线=无，
    Restore_best_weights=真，
    从纪元开始=10，
）

与 tf.device(&#39;GPU:0&#39;):
    cifar = tf.keras.datasets.cifar100
    (x_train, y_train), (x_test, y_test) = cifar.load_data()
    模型 = tf.keras.applications.ResNet50(
        include_top=真，
        权重=无，
        输入形状=(32, 32, 3),
        班级=100）

    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)
    model.compile(optimizer=“adam”,loss=loss_fn,metrics=[“accuracy”])
    model.fit（x_train，y_train，epochs = 100，batch_size = 64，callbacks = [earlystopping]）

我不知道在哪里将训练标签放入我的代码中，而且我也不知道如何使其在不拉伸或挤压的情况下以不同的纵横比工作（按原样处理图像）。]]></description>
      <guid>https://stackoverflow.com/questions/77774178/tensorflow-model-not-working-with-pics-of-different-aspect-ratios</guid>
      <pubDate>Sun, 07 Jan 2024 17:51:31 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中使用 WeightedRandomSampler</title>
      <link>https://stackoverflow.com/questions/60812032/using-weightedrandomsampler-in-pytorch</link>
      <description><![CDATA[我需要在 PyTorch 中实现多标签图像分类模型。但是我的数据不平衡，因此我使用 PyTorch 中的 WeightedRandomSampler 来创建自定义数据加载器。但是当我迭代自定义数据加载器时，出现错误：IndexError：列表索引超出范围 
使用此链接实现了以下代码：https://discuss.pytorch.org/t/balanced-sampling- Between-classes-with-torchvision-dataloader/2703/3?u=surajsubramanian
def make_weights_for_balanced_classes(images, nclasses):
    计数 = [0] * n 类
    对于图像中的项目：
        计数[项目[1]] += 1
    每个类别的权重 = [0.] * n 个类别
    N = 浮点（总和（计数））
    对于范围内的 i (nclasses)：
        每类权重[i] = N/float(count[i])
    重量 = [0] * len(图像)
    对于 idx，枚举（图像）中的 val：
        权重[idx] =weight_per_class[val[1]]
    返回重量

权重 = make_weights_for_balanced_classes(train_dataset.imgs, len(full_dataset.classes))
权重 = torch.DoubleTensor(权重)
采样器 = WeightedRandomSampler(权重, len(权重))

train_loader = DataLoader（train_dataset，batch_size = 4，采样器=采样器，pin_memory = True）

根据https://stackoverflow.com/a/60813495/10077354中的答案，以下是我的更新的代码。但是当我创建数据加载器时：loader = DataLoader(full_dataset, batch_size=4, Sampler=sampler)，len(loader) 返回 1。
class_counts = [1691, 743, 2278, 1271]
num_samples = np.sum(class_counts)
labels = [_ 的标签，full_dataset.imgs 中的标签]

class_weights = [num_samples/class_counts[i] for i in range(len(class_counts)]
权重 = [class_weights[labels[i]] for i in range(num_samples)]
采样器 = WeightedRandomSampler(torch.DoubleTensor(权重), num_samples)

提前非常感谢！
我根据下面接受的答案添加了一个实用函数：
def Sampler_（数据集）：
    dataset_counts = imageCount(数据集)
    num_samples = sum(数据集计数)
    labels = [_的标签，数据集中的标签]

    class_weights = [num_samples/dataset_counts[i] for i in range(n_classes)]
    权重 = [class_weights[labels[i]] for i in range(num_samples)]
    采样器 = WeightedRandomSampler(torch.DoubleTensor(权重), int(num_samples))
    返回采样器

imageCount 函数查找数据集中每个类别的图像数量。数据集中的每一行都包含图像和类，因此我们考虑元组中的第二个元素。
def imageCount(数据集):
    image_count = [0]*(n_classes)
    对于数据集中的 img：
        图像计数[img[1]] += 1
    返回图像数量
]]></description>
      <guid>https://stackoverflow.com/questions/60812032/using-weightedrandomsampler-in-pytorch</guid>
      <pubDate>Mon, 23 Mar 2020 10:45:53 GMT</pubDate>
    </item>
    </channel>
</rss>