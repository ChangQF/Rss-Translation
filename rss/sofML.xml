<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 20 Dec 2023 15:11:52 GMT</lastBuildDate>
    <item>
      <title>Python，分层抽样</title>
      <link>https://stackoverflow.com/questions/77692098/python-stratified-sampling</link>
      <description><![CDATA[我正在使用规范建模框架。
我有 791 个受试者的样本。我有关于年龄、性别和站点（站点 1 或 2）的数据。我想使用 Python 提取大约 50% 的受试者子样本，涵盖整个年龄和性别范围。我的子样本应反映原始样本的位点 1：位点 2 比例。
我希望我已经说清楚了。
预先感谢您
我尝试使用sklearn train_test_split，但有些分层 2.]]></description>
      <guid>https://stackoverflow.com/questions/77692098/python-stratified-sampling</guid>
      <pubDate>Wed, 20 Dec 2023 13:54:53 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch中的动态量化量化后开始随机训练</title>
      <link>https://stackoverflow.com/questions/77692089/dynamic-quantization-in-pytorch-starts-random-training-after-quantization</link>
      <description><![CDATA[当我运行以下动态量化代码时，它开始使用一些随机自然图像进行 100 个时期的训练，我不想再次进行训练。我有预训练的权重，我只是想量化我的预训练的权重以减少推理时间：
`从ultralytics导入YOLO
进口火炬
导入 torch.quantization
model=YOLO(&#39;pre_trained_weights.pt&#39;)
model.load_state_dict(torch.load(&#39;checkpoint.pth&#39;)) #不知道这一步是否必要
qmodel = torch.quantization.quantize_dynamic(model, dtype = torch.quint8)`
我尝试了上面的代码，我希望我只是想量化我的预训练权重以减少推理时间]]></description>
      <guid>https://stackoverflow.com/questions/77692089/dynamic-quantization-in-pytorch-starts-random-training-after-quantization</guid>
      <pubDate>Wed, 20 Dec 2023 13:53:49 GMT</pubDate>
    </item>
    <item>
      <title>_pickle.UnpicklingError：无效的加载键，“v”</title>
      <link>https://stackoverflow.com/questions/77691997/pickle-unpicklingerror-invalid-load-key-v</link>
      <description><![CDATA[最近在 netify 应用上部署我的项目时遇到此错误
6:39:50 PM：4秒内添加了329个包，审核了330个包
6:39:50 PM：107 个包裹正在寻求资金
6:39:50 PM：运行“npmfund”了解详细信息
6:39:50 PM：1 个中等严重程度的漏洞
6:39:50 PM：要解决所有问题，请运行：
6:39:50 PM：npm 审核修复
6:39:50 PM：运行“npmaudit”以获取详细信息。
下午 6:39:50：&gt; movie@0.0.0 构建
下午 6:39:50：&gt;维特构建
6:39:50 PM：vite v5.0.2 构建生产...
6:39:50 PM：转变...
6:39:52 PM：✓ 52 个模块已完成转换。
6:39:52 PM：渲染块...
6:39:52 PM：计算 gzip 大小...
6:39:52 PM: dist/index.html 0.53 kB │ gzip: 0.33 kB
6:39:52 PM：dist/assets/back-dm-GU_Ur.jpg 514.14 kB
6:39:52 PM: dist/assets/index-CLk4a_k1.css 12.90 kB │ gzip: 3.41 kB
6:39:52 PM: dist/assets/index-3jaT-T7k.js 209.08 kB │ gzip: 68.51 kB
6:39:52 PM：✓ 内置 1.60 秒
6:39:52 PM：加载数据--------------------
6:39:52 PM：回溯（最近一次调用）：
6:39:52 PM：文件“app.py”，第 12 行，在  中
6:39:52 PM：电影 = load_data.load_movies()
6:39:52 PM：文件“/opt/build/repo/utils/load_data.py”，第 7 行，在 load_movies 中
6:39:52 PM：返回 pkl.load(open(&quot;./data/movies.pkl&quot;,&quot;rb&quot;))
6:39:52 PM：_pickle.UnpicklingError：无效的加载密钥，“v”。
下午 6:39:52：​
6:39:52 PM：“build.command”失败的
6:39:52 下午：────────────────────────────────────────────── ──────────────────────
下午 6:39:52：​
6:39:52 PM：错误消息
6:39:52 PM：命令失败，退出代码 1：cd client &amp;&amp; npm 安装&amp;&amp; npm run build &amp;&amp; cd ..&amp;&amp; python app.py (https://ntl.fyi/exit-code-1)
下午 6:39:52：​
6:39:52 PM：位置错误
6:39:52 PM：在 Netlify 应用程序的构建命令中：
6:39:52 PM：cd 客户端 &amp;&amp; npm 安装&amp;&amp; npm run build &amp;&amp; cd ..&amp;&amp;蟒蛇应用程序.py
下午 6:39:52：​
6:39:52 PM：已解决的配置
6:39:52 PM：构建：
6:39:52 PM：基础：/opt/build/repo
6:39:52 PM：命令：cd client &amp;&amp; npm 安装&amp;&amp; npm run build &amp;&amp; cd ..&amp;&amp;蟒蛇应用程序.py
6:39:52 PM：命令来源：ui
6:39:52 PM：发布：/opt/build/repo
6:39:52 PM：发布来源：默认
6:39:53 PM：由于用户错误，构建失败：构建脚本返回非零退出代码：2
6:39:53 PM：构建失败：无法构建网站
6:39:53 PM：在 24.831 秒内完成处理构建请求
6:39:53 PM：“构建站点”阶段失败：构建脚本返回非零退出代码：2

构建命令
pip install -r requests.txt ；光盘客户端； npm 安装； npm 运行构建；光盘 .. ; python app.py
主要目标
在后端（flask）中使用 pkl 模型来预测前端用户的类似电影（react）
我已经使用 git lfs 在 github 上部署了 pkl 文件
主要目标
在后端（flask）中使用 pkl 模型来预测前端用户的类似电影（react）
我已经使用 git lfs 在 github 上部署了 pkl 文件]]></description>
      <guid>https://stackoverflow.com/questions/77691997/pickle-unpicklingerror-invalid-load-key-v</guid>
      <pubDate>Wed, 20 Dec 2023 13:38:05 GMT</pubDate>
    </item>
    <item>
      <title>端到端 ML 项目上的模型训练器问题 - ValueError：至少需要一个数组或数据类型</title>
      <link>https://stackoverflow.com/questions/77691153/model-trainer-issue-on-end-to-end-ml-project-valueerror-at-least-one-array-or</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77691153/model-trainer-issue-on-end-to-end-ml-project-valueerror-at-least-one-array-or</guid>
      <pubDate>Wed, 20 Dec 2023 11:18:04 GMT</pubDate>
    </item>
    <item>
      <title>如何训练 Yolo 识别训练数据集中没有的类？</title>
      <link>https://stackoverflow.com/questions/77690929/how-to-train-yolo-to-recognize-classes-that-are-not-in-the-training-dataset</link>
      <description><![CDATA[我最近开始研究计算机视觉。有一家企业需要摄像头判断员工是否佩戴个人防护用品。不幸的是，绝对不可能在违规者的数据中组装这些摄像机的训练数据集，因为每个人都遵守安全规则。训练后，模型将只能识别穿着个人防护装备（头盔、手套等）的人。如何训练 Yolo 以便她能够识别违规行为？请提出任何解决此问题的方法。
根据我的想法，第一个是使用隔离森林，但我必须将图像转换为向量空间，或者以某种方式使用 IoU。]]></description>
      <guid>https://stackoverflow.com/questions/77690929/how-to-train-yolo-to-recognize-classes-that-are-not-in-the-training-dataset</guid>
      <pubDate>Wed, 20 Dec 2023 10:43:43 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何开始电子邮件解析[关闭]</title>
      <link>https://stackoverflow.com/questions/77690876/how-i-should-start-email-parsing</link>
      <description><![CDATA[我想问一下如何开始电子邮件解析。我曾想过用 Spacy 开始电子邮件解析，但现在我感到很困惑。我还想知道我们是否可以为此使用深度学习或机器学习中的任何其他技术。]]></description>
      <guid>https://stackoverflow.com/questions/77690876/how-i-should-start-email-parsing</guid>
      <pubDate>Wed, 20 Dec 2023 10:34:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyG 时视频数据集的过度拟合问题</title>
      <link>https://stackoverflow.com/questions/77690723/overfitting-issue-with-video-dataset-while-using-pyg</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77690723/overfitting-issue-with-video-dataset-while-using-pyg</guid>
      <pubDate>Wed, 20 Dec 2023 10:11:21 GMT</pubDate>
    </item>
    <item>
      <title>RAM 在 2 到 3 次加载后没有释放</title>
      <link>https://stackoverflow.com/questions/77690323/ram-did-not-free-after-2-to-3-load</link>
      <description><![CDATA[Python 模型权重和整个应用程序部署在一个虚拟机中，我们已经将其用于释放内存的目的。
gc.collect()
torch.cuda.empty_cache()
型号 = 无
德尔模型

但是 RAM 没有释放。
在发出释放内存请求后。]]></description>
      <guid>https://stackoverflow.com/questions/77690323/ram-did-not-free-after-2-to-3-load</guid>
      <pubDate>Wed, 20 Dec 2023 09:03:17 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MALLET Java API 运行 DMR 主题模型？</title>
      <link>https://stackoverflow.com/questions/77689759/how-can-i-run-dmr-topic-model-using-mallet-java-api</link>
      <description><![CDATA[我必须数据集text.txt和另一个metadata.txt。我将数据格式化为每行一个文档。我想将 MALLET Java Api 用于 DMR 主题模型。但是，我无法这样做。我对 Java 和这种复杂的建模完全陌生。另外，我对主题建模没有任何先验知识。我在这里寻找专业知识。你能帮我解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77689759/how-can-i-run-dmr-topic-model-using-mallet-java-api</guid>
      <pubDate>Wed, 20 Dec 2023 07:05:09 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何在机器学习中正确使用交叉验证技术（cross_val_score）？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77689532/how-should-i-use-cross-validation-technique-cross-val-score-in-machine-learnin</link>
      <description><![CDATA[我很难理解应该如何正确使用交叉验证技术（在本例中为cross_val_score）。
我正在研究机器学习回归问题。所有预处理步骤（插补、变换、缩放、编码等）均已完成。现在我需要决定使用哪种机器学习回归算法。
数据由 2 个文件组成：

train.csv - 独立特征 + 目标（1460 行）
test.csv - 仅独立特征（1459 行）

我的想法是使用 cross_val_score 选择最佳基础回归模型，然后在最佳基础模型上使用 GridSearchCV 来找到它的最佳超参数。
1) 如果我想使用 cross_val_scrore，我应该使用 train_test_split 分割 train.csv 数据并使用 X_train 和 y_train （1168 行）还是可以使用 X_train_full 和 y_train_full （1460 行）？&lt; /p&gt;
train_df = pd.read_csv(&#39;train.csv&#39;)

X_train_full = train_df.drop(&#39;目标&#39;), 轴 = 1
y_train_full = train_df[&#39;目标&#39;]

X_train，X_holdout，y_train，y_holdout = train_test_split（X_train_full，y_train_full，test_size = 0.2，random_state = 22）

2) 下面是我用来决定需要使用哪种基本回归机器学习模型的代码。我使用了 X_train 和 y_train，认为我应该以某种方式使用 X_holdout 和 y_holdout 来验证/确认决定，但我不知道这是否是正确的方法以及在这种情况下下一步该怎么做。
base_models = [

    (“线性回归”, LinearRegression()),
    (“岭回归”，Ridge())，
    (“套索回归”，Lasso())，
    （“弹性网络回归”，ElasticNet()），
    (“决策树”，DecisionTreeRegressor())，
    (“KNN 回归器”，KNeighborsRegressor())，
    (“SVR”，SVR())，
    （“随机森林”，RandomForestRegressor（）），
    (“额外树回归器”，ExtraTreesRegressor())，
    (“AdaBoost回归器”，AdaBoostRegressor())，
    (“梯度增强回归器”，GradientBoostingRegressor())，
    (“XGBoost”, XGBRegressor()),
    (“LightGBM”，LGBMRegressor())，
    (“CatBoost”，CatBoostRegressor(loss_function=&#39;RMSE&#39;，logging_level=&#39;Silent&#39;))

    ]

# 初始化列表来存储数据

基本模型名称 = []
base_model_rmse_scores = []

# 初始化各个交叉验证折叠分数的列表

cv_fold_scores = [[] for _ in range(10)] # 假设折叠 10 次

# 迭代模型并附加到列表

对于名称，base_models 中的模型：

    # 获取每次折叠的交叉验证分数

    分数 = np.sqrt(-cross_val_score(模型, X_train, y_train, 评分=“neg_mean_squared_error”, cv=10, n_jobs = -1))

    # 附加模型名称

    base_model_names.append(名称)

    # 添加跨折叠的均方根误差 (RMSE)

    base_model_rmse_scores.append(np.mean(分数))

    # 附加单独的折叠分数

    对于 i，枚举中的分数（分数）：
        cv_fold_scores[i].append(分数)

    # 从列表创建 DataFrame

    base_models_results_df = pd.DataFrame({“模型”: base_model_names, “Mean_RMSE”: base_model_rmse_scores})

    # 添加各个交叉验证折叠分数的列

    对于我，枚举中的fold_scores（cv_fold_scores）：
        base_models_results_df[f&quot;Fold_{i+1}_RMSE&quot;] = Fold_scores

    # 设置“模型”列作为索引

    base_models_results_df = base_models_results_df.set_index(“模型”)

    # 按均方根误差 (RMSE) 升序对 DataFrame 进行排序

    base_models_results_df = base_models_results_df.sort_values（by=“Mean_RMSE”，升序=True）

    基础模型结果df


从上图可以看出，CatBoost 是最好的基础模型，其平均 RMSE 为 0.319293。
3) 我可以做些什么来确保这个特定模型最适合使用吗？是否可以过度拟合或不足？我可以使用 X_holdout 和 y_holdout 集以某种方式验证它吗？如果我需要使用 X_train_full 和 y_train_full，这种情况下该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/77689532/how-should-i-use-cross-validation-technique-cross-val-score-in-machine-learnin</guid>
      <pubDate>Wed, 20 Dec 2023 06:11:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么我在安装requirements.txt时收到此错误？</title>
      <link>https://stackoverflow.com/questions/77689351/why-am-i-getting-this-error-while-installing-requirements-txt</link>
      <description><![CDATA[PS C:\Users\SAI BHUVAN\Documents\EndToEndMLProject&gt; pip install -r 要求.txt
获取文件:///C:/Users/SAI%20BHUVAN/Documents/EndToEndMLProject（来自-rrequirements.txt（第10行））
  安装构建依赖项...完成
  检查构建后端是否支持 build_editable ...完成
  获取构建可编辑的需求...完成
  准备可编辑元数据 (pyproject.toml) ...错误
  错误：子进程退出并出现错误

  × 准备可编辑元数据 (pyproject.toml) 未成功运行。
  │ 退出代码：1
  ╰─&gt; [21行输出]
      回溯（最近一次调用最后一次）：
        文件“C:\Users\SAI BHUVAN\AppData\Local\Programs\Python\Python311\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 353 行，在  中
          主要的（）
        文件“C:\Users\SAI BHUVAN\AppData\Local\Programs\Python\Python311\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 335 行，在 main 中
          json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C：\ Users \ SAI BHUVAN \ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ pip \ _vendor \ pyproject_hooks \ _in_process \ _in_process.py”，第181行，在prepare_metadata_for_build_editable中
          返回钩子（元数据目录，配置设置）
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C：\ Users \ SAI BHUVAN \ AppData \ Local \ Temp \ pip-build-env-fmoiyisg \ overlay \ Lib \ site-packages \ setuptools \ build_meta.py”，第446行，在prepare_metadata_for_build_editable中
          返回 self.prepare_metadata_for_build_wheel(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Users\SAI BHUVAN\AppData\Local\Temp\pip-build-env-fmoiyisg\overlay\Lib\site-packages\setuptools\build_meta.py”，第368行，在prepare_metadata_for_build_wheel中
          self._bubble_up_info_directory(metadata_directory, “.egg-info”)
        文件“C:\Users\SAI BHUVAN\AppData\Local\Temp\pip-build-env-fmoiyisg\overlay\Lib\site-packages\setuptools\build_meta.py”，第 337 行，位于 _bubble_up_info_directory 中
          info_dir = self._find_info_directory(元数据目录, 后缀)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^
        文件“C:\Users\SAI BHUVAN\AppData\Local\Temp\pip-build-env-fmoiyisg\overlay\Lib\site-packages\setuptools\build_meta.py”，第 348 行，位于 _find_info_directory 中
          assert len(candidates) == 1, f“找到多个 {suffix} 目录”
                 ^^^^^^^^^^^^^^^^^^^^^^
      AssertionError：找到多个 .egg-info 目录
      [输出结束]

  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：元数据生成失败

× 生成包元数据时遇到错误。
╰─&gt;输出见上文。

注意：这是上面提到的包的问题，​​而不是 pip 的问题。
提示：详细信息请参见上文。

我尝试解决这个问题，但无法解决。]]></description>
      <guid>https://stackoverflow.com/questions/77689351/why-am-i-getting-this-error-while-installing-requirements-txt</guid>
      <pubDate>Wed, 20 Dec 2023 05:19:33 GMT</pubDate>
    </item>
    <item>
      <title>找不到满足张量流要求的版本（来自版本：无）没有找到张量流的匹配分布</title>
      <link>https://stackoverflow.com/questions/77689277/could-not-find-a-version-that-satisfies-the-requirement-tensorflow-from-version</link>
      <description><![CDATA[即使我已经升级了我的 python 及其 64 位，我仍然遇到这个问题。
错误：找不到满足张量流要求的版本（来自版本：无）
错误：找不到张量流的匹配分布

我的 python 是最新的（3.12.1）。
我已尝试更新 Python，但仍然遇到有关 Tensorflow 安装的问题。如何解决这个问题？我什至安装了 C++ vc_redist.x64.exe]]></description>
      <guid>https://stackoverflow.com/questions/77689277/could-not-find-a-version-that-satisfies-the-requirement-tensorflow-from-version</guid>
      <pubDate>Wed, 20 Dec 2023 04:55:01 GMT</pubDate>
    </item>
    <item>
      <title>回归任务的误差分析应该应用于测试部分还是训练部分？</title>
      <link>https://stackoverflow.com/questions/77688075/error-analysis-of-a-regression-task-should-apply-on-test-or-train-part</link>
      <description><![CDATA[我已经实现了一个回归任务模型来预测参数（如成本）；现在我有了观察预测图，也是为了展示我的模型，我想要进行误差分析，例如误差的QQ图、误差分布、相关性、杜宾-沃森检验和其他方法。现在的问题是，这种方法标准应该应用于测试或训练或两者？以显示我的模型性能。
我希望这些方法应该应用于测试部分以显示我的模型的性能。]]></description>
      <guid>https://stackoverflow.com/questions/77688075/error-analysis-of-a-regression-task-should-apply-on-test-or-train-part</guid>
      <pubDate>Tue, 19 Dec 2023 21:25:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么 MLNet 没有得出合理的结论 [关闭]</title>
      <link>https://stackoverflow.com/questions/77687481/why-is-mlnet-not-coming-to-reasonable-conclusions</link>
      <description><![CDATA[我有一个模型，它目前基于合理的推理，然后对其进行测试来支持它。问题是预测多人游戏中的获胜者。
所以我希望使用一些机器学习来改进它。第一次尝试是做大小玩家的游戏，数据如下col0[标签],col1-col10[玩家一数据],col11-20[玩家二数据]...
数据是平衡的，因此每个类别的可能性与其他类别的可能性相同。
当样本用完时，这能够以 24% 的准确率进行预测，但问题是我知道，如果你只按每个玩家的第一个列排序，你会在样本中获得 27% 的准确率（并且你需要向你的老板为什么会这样）。我还知道所有其他数据都具有预测能力，可以解释原因并通过回归证明这一点，并且它们都在现实世界中发挥了与测试相同的准确性。
我尝试简化 MLNet 的问题，将其变成二元分类问题，并让它预测两个玩家的相对成功，数据再次平衡。这与第一列的执行方式几乎相同，但我可以看到它使用其他参数，如果我使用它们，我会得到比这产生的更好的结果。
经过几个小时的训练，我终于有了一个 6 人游戏的模型，它与第一个排序排序达到了同等水平，但我觉得我不能相信它，因为它无意中接触到了样本外的数据适者生存，淘汰在样本外表现不佳的模型。
我使用“Microsoft.ML”在本地运行了这个但我尝试过不同的自动化机器学习提供商 azure、amazon、google，但它们都未能产生更好的结果。当人们不断告诉我 ML 很棒，你可以向其扔数据，但就这个问题而言，它只是不如人类洞察力时，我是否遗漏了一些东西。
请注意，六人游戏有 1,000,000 条记录，我将其分解为两人游戏的 10,000,000 条记录。
关于提高性能有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77687481/why-is-mlnet-not-coming-to-reasonable-conclusions</guid>
      <pubDate>Tue, 19 Dec 2023 19:11:11 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace AutoModelForCasualLM “仅解码器架构”警告，即使在设置 padding_side='left' 后也是如此</title>
      <link>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</link>
      <description><![CDATA[我正在使用
AutoModelForCausalLM 和 AutoTokenizer 使用 DialoGPT 生成文本输出。
无论出于何种原因，即使使用 Huggingface 提供的示例，我也会收到此警告：
&lt;块引用&gt;
正在使用仅解码器架构，但检测到右填充！为了正确的生成结果，请在初始化分词器时设置 padding_side=&#39;left&#39;。

从变压器导入 AutoModelForCausalLM, AutoTokenizer
进口火炬


tokenizer = AutoTokenizer.from_pretrained(“microsoft/DialoGPT-medium”)
模型 = AutoModelForCausalLM.from_pretrained(“microsoft/DialoGPT-medium”)

# 我们聊5行吧
对于范围（5）中的步骤：
    # 对新的用户输入进行编码，添加 eos_token 并在 Pytorch 中返回一个张量
    new_user_input_ids = tokenizer.encode(input(“&gt;&gt;用户:”) + tokenizer.eos_token, return_tensors=&#39;pt&#39;)

    # 将新的用户输入标记附加到聊天历史记录中
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) 如果步骤 &gt; 0 其他 new_user_input_ids

    # 生成响应，同时将总聊天历史记录限制为 1000 个令牌，
    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)

    # 漂亮地打印机器人最后的输出令牌
    print(“DialoGPT: {}”.format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0],skip_special_tokens=True)))

代码由 微软在 Huggingface 的模型卡上
我尝试将 padding_side=&#39;left&#39; 添加到标记生成器，但这不会改变任何内容。
显然（从一些阅读来看）DialoGPT 无论如何都希望在右侧填充？
我无法弄清楚这一点，当我尝试谷歌搜索时几乎没有结果。
我能够像这样抑制警告：
from Transformers.utils 导入日志记录

记录.set_verbosity_info()

但这似乎不是最好的答案？]]></description>
      <guid>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</guid>
      <pubDate>Fri, 09 Dec 2022 20:39:39 GMT</pubDate>
    </item>
    </channel>
</rss>