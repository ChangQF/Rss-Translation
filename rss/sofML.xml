<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 11 Dec 2023 01:01:53 GMT</lastBuildDate>
    <item>
      <title>发生错误：需要 2D 数组，却得到 1D 数组：</title>
      <link>https://stackoverflow.com/questions/77636896/an-error-occurred-expected-2d-array-got-1d-array-instead</link>
      <description><![CDATA[在这一行中：stacked_predictions_2d = ensemble_predictions(X_test, X_train, y_test, y_train, rf_model, svm_model, gru_model, lstm_model, xgb_model, Neural_network_model)
我遇到这个问题：
&lt;块引用&gt;
发生错误：需要二维数组，却得到一维数组：
数组=[4.185 4.22 3.975 4.055 4.0475 4.015 4.0925 4.28 4.3375
4.4175
4.46 4.1675 4.145 4.1525 4.0525 4.1375 4.1 4.05 4.2125 4.21
4.1575 4.165 4.2925 4.23 4.3875 4.3975 4.2975 4.3125 4.29 4.44
4.525 4.365 4.3125 4.3825 4.4725 4.3225 4.335 4.335 4.39 4.4075
4.35 4.305 4.37 4.2625 4.29 4.22 4.2475 4.325 4.415 4.47
4.5025 4.265 4.245 4.26 4.15 4.1675 4.11 4.15 4.0325 4.04
4.1625 3.9275 3.885 3.6875 3.625 3.55 3.49 3.64 3.6 3.67]。如果您的数据使用 array.reshape(-1, 1) 重塑您的数据
具有单个特征或 array.reshape(1, -1) 如果它包含单个
样本。

我不知道为什么会遇到这个问题，也不知道为什么它不告诉我问题出在哪个数组中。
X_TRAIN 的形状：(70, 17)
X_TEST 的形状：(30, 17)
Y_TRAIN 的形状：(70,)
Y_TEST 的形状：(30,)
累积特征的形状 (1, 19)

y 测试和训练应该是 1d，因为它们只包含样本。我不知道问题出在哪个数组中，但我确实知道这不是训练或测试，因为他们正在预测此数据时价值 400 美元的股票的股价。
问题可能是什么以及如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77636896/an-error-occurred-expected-2d-array-got-1d-array-instead</guid>
      <pubDate>Mon, 11 Dec 2023 00:03:35 GMT</pubDate>
    </item>
    <item>
      <title>在google colab上安装cuML时出现问题</title>
      <link>https://stackoverflow.com/questions/77636413/problem-when-installing-cuml-on-google-colab</link>
      <description><![CDATA[我在 google colab 上安装 RAPIDS 和 cuML 时遇到此错误：https://i。 stack.imgur.com/7Q12u.png
我按照此链接的说明进行操作：https://docs.rapids .ai/deployment/stable/platforms/colab/
我检查过，我已连接到 T4 GPU，并且我也尝试使用其他 GPU：
https://i.stack.imgur.com/BszUI.png
我的python版本似乎没问题，我使用的是python 3.10.12
我尝试使用--no-cache-dir选项，但它似乎没有改变任何东西。
我还尝试按照说明使用 conda 安装 RAPIDS，但在安装 cuml 时遇到了同样的问题]]></description>
      <guid>https://stackoverflow.com/questions/77636413/problem-when-installing-cuml-on-google-colab</guid>
      <pubDate>Sun, 10 Dec 2023 20:54:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit-learn 在没有预先存在标签的评论中进行情感分类的策略 [关闭]</title>
      <link>https://stackoverflow.com/questions/77635747/strategies-for-emotion-classification-in-comments-without-pre-existing-labels-us</link>
      <description><![CDATA[我正在开发一个项目，涉及使用 Python 和 scikit-learn 对文本评论中的情感进行分类。但是，我的数据集没有预先存在的情绪标签。
我正在寻求有关在没有预先存在的标签的情况下进行情绪分类的可能策略的建议。如何定义情绪类别？我可以使用哪些类型的特征或文本表示方法来捕捉评论中的情感方面？
有任何代码示例、推荐的库或经过验证的方法的参考吗？]]></description>
      <guid>https://stackoverflow.com/questions/77635747/strategies-for-emotion-classification-in-comments-without-pre-existing-labels-us</guid>
      <pubDate>Sun, 10 Dec 2023 17:29:53 GMT</pubDate>
    </item>
    <item>
      <title>我的 GAN 项目正在生成噪声图像</title>
      <link>https://stackoverflow.com/questions/77635721/my-gan-project-is-generating-noisy-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77635721/my-gan-project-is-generating-noisy-images</guid>
      <pubDate>Sun, 10 Dec 2023 17:22:47 GMT</pubDate>
    </item>
    <item>
      <title>客户购买倾向模型，我该怎么做？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77635210/customer-propensity-to-purchase-model-how-do-i-go-about-it</link>
      <description><![CDATA[所以我有这个数据集，其中包括时间戳、购买的产品类别以及有关用户在电子商务平台上的行为的其他信息，例如：他们购买的频率、来自哪个类别、imp 评论如何、添加到购物车、购物车放弃，保存以供稍后使用，等等以及所有详细信息。
现在我想训练一个模型，然后为客户进行这个虚拟电子商务模拟，他们执行的某些操作将被添加到实时数据库中（客户可能存在多个会话，其中日期也是分析），模型可以对其进行处理，然后仪表板可以显示他们在接下来的几周/几个月内购买特定产品类别的可能性。
我已经使用过ml和dl，但我对它还很陌生，所以如果这是愚蠢的事情，我提前道歉，但我很困惑，就像我错过了一些关于如何创建它并制作它的细节它有效。
有什么建议吗？请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/77635210/customer-propensity-to-purchase-model-how-do-i-go-about-it</guid>
      <pubDate>Sun, 10 Dec 2023 14:44:02 GMT</pubDate>
    </item>
    <item>
      <title>调整图像分割模型（来自 TF 教程）以进行二元掩蔽</title>
      <link>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</link>
      <description><![CDATA[我需要 Tensorflow 的图像分割模型。输入为图像和掩码（二进制、掩码或非掩码），输出为带有 0 和 1 的图像掩码。
我遵循了 https://www.tensorflow.org/tutorials/ 中的图像分割教程图像/分割
但现在我想在我的数据集上运行它的二进制掩码（没有边框类）
新数据集已准备好并输入到 model.fit 中。应该没问题吧。
如何将此模型更改为只有 2 个类（非屏蔽和屏蔽）？
base_model: keras.Model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)

# 使用这些层的激活
图层名称 = [
    &#39;block_1_expand_relu&#39;, # 64x64
    &#39;block_3_expand_relu&#39;, # 32x32
    &#39;block_6_expand_relu&#39;, # 16x16
    &#39;block_13_expand_relu&#39;, # 8x8
    &#39;block_16_project&#39;, # 4x4
]
base_model_outputs = [base_model.get_layer(name).layer_names 中名称的输出]

# 创建特征提取模型
down_stack = 模型（输入=base_model.输入，输出=base_model_outputs）

down_stack.trainable = False

上层堆栈 = [
    pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8
    pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16
    pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32
    pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
  输入 = 层.Input(形状=[128, 128, 3])

  # 通过模型进行下采样
  跳过= down_stack（输入）
  x = 跳过[-1]
  跳过 = 反转(跳过[:-1])

  # 上采样并建立跳跃连接
  对于 up，在 zip 中跳过（up_stack，skips）：
    x = 上(x)
    concat = 层.Concatenate()
    x = concat([x, 跳过])

  # 这是模型的最后一层
  最后=层.Conv2DTranspose(
      过滤器=output_channels，kernel_size=3，步幅=2，
      padding=&#39;相同&#39;) #64x64 -&gt; 128x128

  x = 最后一个(x)

  返回模型（输入=输入，输出=x​​）

输出类 = 3

模型 = unet_model(output_channels=OUTPUT_CLASSES)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

当我将 OUTPUT_CLASSES 更改为 2 时，出现错误：
W tensorflow/core/kernels/data/generator_dataset_op.cc:108] 完成 GeneratorDataset 迭代器时发生错误：FAILED_PRECONDITION：Python 解释器状态未初始化。该过程可以被终止。

当OUTPUT_CLASSES为1时，预测掩码为空。
也许还必须改变其他东西？我还没有进入神经网络架构，所以我可能看不到明显的东西。]]></description>
      <guid>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</guid>
      <pubDate>Sun, 10 Dec 2023 13:55:04 GMT</pubDate>
    </item>
    <item>
      <title>想要使用监督或无监督构建建议模型吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</link>
      <description><![CDATA[假设我们从一个巨大的区域开始，想要建立一个模型来建议是否建议在 latlon 的每个点放置多少新信号发射器。
第一步：在边界区域（100m 网格）内创建所有可能的 latlon
第二步：创建所有相关功能，例如
-最近的现有发射器距离
- 该点的当前信号电平（在此示例 latlon 中）
- 使用最接近该点的现有发射器的使用量（在此示例 latlon 中）
-当前点使用信号的用户数量
问题

如果我选择 NNet 模型，我需要提出评分函数来计算每个特征向量的合适分数。因为它是有监督模型，所以需要用该模型进行训练，如何找到合适的评分函数？当我找到分数函数时，我是否需要考虑特定特征的异常值？

如果我可以拥有标记数据，那么 ML 模型的好处是什么，因为我可以使用此评分函数与自动化的传统软件来生成点列表的排名。

如果我使用无监督方法，它只会根据特征对相似的特征点进行分组，但是如何对这个点进行排序，不知何故，我需要教育模型每个特征，较高的值意味着好，或者更高的值意味着不好，对吗？

有什么建议或更好的型号选择吗？


我试图概述脚趾步骤，但我有疑问，因为该方法听起来并不优于传统的自动化软件。]]></description>
      <guid>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</guid>
      <pubDate>Sun, 10 Dec 2023 07:29:16 GMT</pubDate>
    </item>
    <item>
      <title>Visual Studio 在 yolo7v 上训练时找不到 cuda 错误</title>
      <link>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</link>
      <description><![CDATA[当我尝试在 yolo v7 上训练时，出现此错误：
文件“train.py”，第 595 行，在  中
    设备= select_device(opt.device,batch_size=opt.batch_size)
  文件“C:\Users\96Crori\Desktop\yolov7_custom_training\yolov7\utils\torch_utils.py”，第 71 行，位于 select_device
    断言 torch.cuda.is_available(), f&#39;CUDA 不可用，请求的设备 {device} 无效&#39; # 检查可用性
AssertionError：CUDA 不可用，请求的设备 0 无效

我安装了cuda版本11.3，但我不知道为什么Visual Studios找不到它]]></description>
      <guid>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</guid>
      <pubDate>Sun, 10 Dec 2023 02:39:08 GMT</pubDate>
    </item>
    <item>
      <title>具有不同输入形状的 3D 深度学习输入 [关闭]</title>
      <link>https://stackoverflow.com/questions/77602918/3d-deep-learning-input-with-varying-input-shapes</link>
      <description><![CDATA[如何将可变维度的数据集输入到深度学习模型中。
我正在使用可变切片进行 3D 医学成像，我使用了 PCA 和其他切片选择技术以及填充以使模型具有相同的形状
但我想知道是否有任何用于深度学习模型的可变输入形状的技术。
下面是代码：
来自tensorflow.keras导入层

#输入形状 = (200, 200, 60, 1)
输入形状=像素数组[1:]
输入 = keras.Input(shape=(pixel_arrays.shape[1:]))
x=layers.Conv3D(filters=16,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(输入)
x=layers.Conv3D(filters=32,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(x)
x=layers.Conv3D(filters=64,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(x)
#x = 层.Conv3D(filters=32, kernel_size=3, 激活=&#39;relu&#39;, padding=&#39;same&#39;)(x)
]]></description>
      <guid>https://stackoverflow.com/questions/77602918/3d-deep-learning-input-with-varying-input-shapes</guid>
      <pubDate>Mon, 04 Dec 2023 22:33:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在colab中查找数据集的列中有多少个不同的数据[关闭]</title>
      <link>https://stackoverflow.com/questions/77599408/how-to-find-how-many-different-data-are-in-a-column-of-a-data-set-in-colab</link>
      <description><![CDATA[我有一个大约由 400000 行和 8 列组成的数据集，我只想知道一列中有多少种不同类型的数据，我该怎么做？列中的数据是字符串的形式，我需要给它们分配数字，所以我需要找出该列中有多少个不同的单词。我不知道我应该做什么]]></description>
      <guid>https://stackoverflow.com/questions/77599408/how-to-find-how-many-different-data-are-in-a-column-of-a-data-set-in-colab</guid>
      <pubDate>Mon, 04 Dec 2023 12:22:17 GMT</pubDate>
    </item>
    <item>
      <title>如何修复我的感知器来识别数字？</title>
      <link>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</guid>
      <pubDate>Sun, 03 Dec 2023 14:03:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 tidymodels 进行特征消除以筛选多个模型</title>
      <link>https://stackoverflow.com/questions/72896969/feature-elimination-to-screen-for-multiple-models-using-tidymodels</link>
      <description><![CDATA[我目前正在执行回归建模，数据集的特征数量 (p) 高于观测值 (n)。
通常为 p = 10000 和 n = 30。此外，我想测试许多模型并找到最好的一个。
我现在要做的就是首先消除这些功能。将其从 10K 减少到 20-30，使用
step_select_mrmr() 或 step_select_vip()。我通过将其放在管道的顶部来实现这一目标。
然后我会继续测试许多模型。
这种做法合理吗？]]></description>
      <guid>https://stackoverflow.com/questions/72896969/feature-elimination-to-screen-for-multiple-models-using-tidymodels</guid>
      <pubDate>Thu, 07 Jul 2022 11:23:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使用ML模型和FastAPI处理多个用户的请求？</title>
      <link>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</link>
      <description><![CDATA[我正在研究通过FastAPI分发人工智能模块的过程。
我创建了一个 FastAPI 应用，它使用预先学习的机器学习模型来回答问题。
这种情况下，一个用户使用没有问题，但多个用户同时使用时，响应可能会太慢。
那么，当多个用户输入问题时，有没有办法一次性复制模型并加载进去呢？
类句子bert_ai()：
    def __init__(self) -&gt;; __init__(self) -&gt;没有任何：
        超级().__init__()

 def Ask_query(自我,查询,topN):
        开始 = 时间.time()

        询问结果 = []
        分数 = []
        结果值 = []
        嵌入器 = torch.load(model_path)
        corpus_embeddings = embedder.encode（语料库，convert_to_tensor=True）
        query_embedding = embedder.encode（查询，convert_to_tensor=True）
        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0] #torch.Size([121])121개의 말뭉치에 대한 코사인 유사도 값ה다.
        cos_scores = cos_scores.cpu()

        top_results = np.argpartition(-cos_scores, range(topN))[0:topN]

        对于 top_results[0:topN] 中的 idx：
            Ask_result.append(corpusid[idx].item())
            #.item()으로 접근하는 유는 张量(5)에서 해당 숫자에 접근하기 위한 방식다.
            分数.append(round(cos_scores[idx].item(),3))

        #서버에 json array 형태로 내보내기 위한 작업
        对于 zip 中的 i,e(ask_result,score)：
            result_value.append({“pred_id”:i,“pred_weight”:e})
        结束 = 时间.time()
        print(&#39;시간체크&#39;,endd-startt)
        返回结果值
        # return &#39;,&#39;.join(str(e) for e in Ask_result),&#39;,&#39;.join(str(e) for e in Score)



类 Item_inference(BaseModel):
    文本：str
    topN : 可选[int] = 1

@app.post(&quot;/retrieval&quot;,tags=[&quot;知识推荐&quot;])
异步 def Knowledge_recommendation(item: Item_inference):
  
    # db.append(item.dict())
    item.dict()
    结果 = _ai.ask_query(item.text, item.topN)

    返回结果


如果 __name__ == “__main__”：
    解析器 = argparse.ArgumentParser()
    parser.add_argument(&quot;--port&quot;, default=&#39;9003&#39;, type=int)
    # parser.add_argument(&quot;--mode&quot;, default=&#39;cpu&#39;, type=str, help=&#39;cpu 表示 CPU 模式，gpu 表示 GPU 模式&#39;)
    args = parser.parse_args()

    _ai = 句子bert_ai()
    uvicorn.run（应用程序，主机=“0.0.0.0”，端口=args.port，workers=4）

修正版本
@app.post(&quot;/aaa&quot;) def your_endpoint(request: Request, item:Item_inference): start = time.time() model = request. app.state.model item.dict() #커널 실행시 필요 _ai = Sentencebert_ai() results = _ai.ask_query(item.text, item.topN,model) end = time.time() print(end-start) return结果```
]]></description>
      <guid>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</guid>
      <pubDate>Fri, 25 Mar 2022 07:13:32 GMT</pubDate>
    </item>
    <item>
      <title>Python：如何从 Optuna LightGBM 研究中检索最佳模型？</title>
      <link>https://stackoverflow.com/questions/62144904/python-how-to-retrieve-the-best-model-from-optuna-lightgbm-study</link>
      <description><![CDATA[我希望获得最佳模型，以便稍后在笔记本中使用，以使用不同的测试批次进行预测。
可重现的示例（取自 Optuna Github）：
导入 lightgbm 为 lgb
将 numpy 导入为 np
导入 sklearn.datasets
导入 sklearn.metrics
从 sklearn.model_selection 导入 train_test_split

导入奥图纳


# 仅供参考：目标函数可以接受额外的参数
#（https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args）。
定义目标（试用）：
    数据，目标 = sklearn.datasets.load_breast_cancer(return_X_y=True)
    train_x、valid_x、train_y、valid_y = train_test_split（数据、目标、test_size=0.25）
    dtrain = lgb.Dataset(train_x, label=train_y)
    dvalid = lgb.Dataset(valid_x, label=valid_y)

    参数 = {
        “目标”：“二进制”，
        “公制”：“auc”，
        “详细程度”：-1，
        &quot;boosting_type&quot;: &quot;gbdt&quot;,
        &quot;lambda_l1&quot;: Trial.suggest_loguniform(&quot;lambda_l1&quot;, 1e-8, 10.0),
        &quot;lambda_l2&quot;: Trial.suggest_loguniform(&quot;lambda_l2&quot;, 1e-8, 10.0),
        &quot;num_leaves&quot;: Trial.suggest_int(&quot;num_leaves&quot;, 2, 256),
        &quot;feature_fraction&quot;: Trial.suggest_uniform(&quot;feature_fraction&quot;, 0.4, 1.0),
        &quot;bagging_fraction&quot;: Trial.suggest_uniform(&quot;bagging_fraction&quot;, 0.4, 1.0),
        &quot;bagging_freq&quot;: Trial.suggest_int(&quot;bagging_freq&quot;, 1, 7),
        &quot;min_child_samples&quot;: Trial.suggest_int(&quot;min_child_samples&quot;, 5, 100),
    }

    # 添加用于修剪的回调。
    pruning_callback = optuna.integration.LightGBMPruningCallback（试用版，“auc”）
    gbm = lgb.train(
        参数，dtrain，valid_sets = [dvalid]，verbose_eval = False，callbacks = [pruning_callback]
    ）

    preds = gbm.predict(valid_x)
    pred_labels = np.rint(preds)
    准确度 = sklearn.metrics.accuracy_score(valid_y, pred_labels)
    返回精度


我的理解是，下面的研究将调整准确性。我想以某种方式从研究中检索最佳模型（不仅仅是参数）而不将其保存为泡菜，我只想在笔记本中的其他地方使用该模型。 

&lt;前&gt;&lt;代码&gt;
如果 __name__ == &quot;__main__&quot;:
    研究 = optuna.create_study(
        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)，方向=“最大化”
    ）
    研究.优化（目标，n_Trials=100）

    print(&quot;最佳试用：&quot;)
    试验 = 研究.best_试验

    print(&quot; 参数: &quot;)
    对于 Trial.params.items() 中的键、值：
        print(&quot; {}: {}&quot;.format(key, value))


期望的输出是
best_model = ~上面的模型~
new_target_pred = best_model.predict(new_data_test)
指标.accuracy_score(new_target_test, new__target_pred)

]]></description>
      <guid>https://stackoverflow.com/questions/62144904/python-how-to-retrieve-the-best-model-from-optuna-lightgbm-study</guid>
      <pubDate>Tue, 02 Jun 2020 04:35:05 GMT</pubDate>
    </item>
    <item>
      <title>如何检测身份证上的全息图覆盖层？</title>
      <link>https://stackoverflow.com/questions/52887039/how-to-detect-hologram-overlays-like-the-ones-in-id-cards</link>
      <description><![CDATA[有什么好的方法可以检测身份证等安全文件中的全息图吗？我已经尝试了很多方法，例如索贝尔滤波器、拉普拉斯算子等，但仍然很难判断卡片上是否有全息图。
原始图像

从左到右：拉普拉斯算子、SobelX、SobelY
]]></description>
      <guid>https://stackoverflow.com/questions/52887039/how-to-detect-hologram-overlays-like-the-ones-in-id-cards</guid>
      <pubDate>Fri, 19 Oct 2018 06:41:29 GMT</pubDate>
    </item>
    </channel>
</rss>