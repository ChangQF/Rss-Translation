<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 24 Jul 2024 21:15:05 GMT</lastBuildDate>
    <item>
      <title>如何追踪之前图像的轮廓？</title>
      <link>https://stackoverflow.com/questions/78790401/how-do-i-track-a-contour-from-my-previous-image</link>
      <description><![CDATA[我有一个细菌细胞移动的视频，我将其转换为帧。现在我想找到每个细菌细胞的瞬时速度。为此，我感兴趣的是找出细菌细胞移动了多少，但我不知道如何告诉我的程序准确识别这种特定的细菌移动了。例如，假设我只有两张图像。对于每张图像，我都有每种细菌的 COM 坐标。现在我如何关联这些数据。我如何让我的程序准确识别这种特定细菌的 COM 变化量。我已将两张图片附上以供参考。


我想到的一个方法是给每个轮廓一个唯一的 id，并将该轮廓的特征与该唯一 id 关联起来。例如它的长轴和短轴长度。这样我就可以关联轮廓的初始和最终 COM。但是这个想法假设所有细菌细胞都是独一无二的，并且我的代码可以准确而精确地识别每个细菌细胞的轮廓，但事实并非如此。如果您感兴趣，我还附上了查找每个细菌细胞轮廓的代码。有人可以提出一些更好的想法吗？非常感谢。
import cv2 as cv
import numpy as np
from numpy.typing import NDArray
import math

def gaussian_filter_multiscale_retinex(image: NDArray, sigmas: list[float], weights: list[float]) -&gt;; NDArray:
img32 = image.astype(&#39;float32&#39;) / 255

img32_log = cv.log(img32 + 1)

msr = np.zeros(image.shape, np.float32)
对于 zip(sigmas, weights) 中的 sigma、weight:

blur = cv.GaussianBlur(img32, ksize=(0, 0), sigmaX=sigma)
blur_log = cv.log(blur + 1)
ssr = cv.subtract(img32_log, blur_log)
ssr = cv.multiply(ssr, weight)

msr = cv.add(msr, ssr)

msr = cv.divide(msr, sum(weights))

msr = cv.normalize(msr, None, 0, 255, cv.NORM_MINMAX, cv.CV_8U)
返回 msr
def calculate_ellipse_area(椭圆):

(cx, cy), (a, b), 角度 = 椭圆
半长轴 = a / 2
半短轴 = b / 2
面积 = math.pi * 半长轴 * 半短轴
返回面积，角度

def process_image(img, size_threshold):
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
rtnx = gaussian_filter_multiscale_retinex(gray, sigmas=[15, 55, 185], weights=[10, 5, 1])
阈值 = cv.adaptiveThreshold(rtnx, 255,自适应方法 = cv.ADAPTIVE_THRESH_GAUSSIAN_C，
阈值类型 = cv.THRESH_BINARY，blockSize = 7，C = -7)
nb_components，输出，统计，_ = cv.connectedComponentsWithStats（阈值，连通性 = 8）
大小 = 统计 [1：，-1]
new_img = np.zeros_like（阈值）
对于 i 在范围内（0，nb_components - 1）：
如果sizes [i]＆gt; = size_threshold：
new_img [输出 == i + 1] = 255
connected_components = cv.connectedComponentsWithStats（new_img）
（numLabels，标签，统计，质心）=connected_components

result_image = np.ones_like（img）* 255
对于 i 在范围内（1， numLabels):
componentMask = (labels == i).astype(&#39;uint8&#39;)
contours, _ = cv.findContours(componentMask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
if len(contours) &gt; 0:
cnt = contours[0]
if len(cnt) &gt;= 5:
ellipse = cv.fitEllipse(cnt)
area, angle = calculate_ellipse_area(ellipse)
if area &lt; 250:
cv.ellipse(result_image, ellipse, (0, 0, 0), 1) # 在白色背景上绘制黑色轮廓
return result_image
img1path = &quot;/Users/yahya2/Desktop/1.png&quot;
img = cv.imread(img1path)
size_threshold = 16
result_image = process_image(img, size_threshold)

cv.imshow(&#39;轮廓&#39;, result_image)
cv.waitKey(0)
cv.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78790401/how-do-i-track-a-contour-from-my-previous-image</guid>
      <pubDate>Wed, 24 Jul 2024 20:14:25 GMT</pubDate>
    </item>
    <item>
      <title>我已经成功安装了 pypdf2，但无法将其导入到我的 python 文件中</title>
      <link>https://stackoverflow.com/questions/78790198/i-have-successfully-installed-the-pypdf2-but-not-able-to-import-it-into-my-pytho</link>
      <description><![CDATA[我已成功安装 pypdf2 模块，但在导入时，我发现缺少此模块。
我尝试使用导入
from PyPDF2 import PdfReader

但它不起作用
此问题有哪些解决方案？]]></description>
      <guid>https://stackoverflow.com/questions/78790198/i-have-successfully-installed-the-pypdf2-but-not-able-to-import-it-into-my-pytho</guid>
      <pubDate>Wed, 24 Jul 2024 19:17:59 GMT</pubDate>
    </item>
    <item>
      <title>Keras CNN 模型对同一输入给出不同的输出预测</title>
      <link>https://stackoverflow.com/questions/78789559/keras-cnn-model-gives-different-output-predictions-for-the-same-input</link>
      <description><![CDATA[嗨，我用 keras 训练了一个 CNN 模型，类似于他们在网站上使用的示例模型，但层数略小，最后还有一个额外的 dropout 层。模型构建函数看起来有点像这样：
&quot; --------- 模型参数 ---------&quot;

epochs = 800
image_size = (384, 256)
batch_size = 128
number_of_layers = 4
drop_out = 0.25
num_dropouts = 2
learn_rate = 0.00001
layer_sizes = [64, 128, 256, 512, 728]
class_weight = {0:1, 1:3}
image_rotation = 0.1

def make_model(input_shape, num_classes, layer_num=3, drop_out=0.25, dropouts=1):
inputs = keras.Input(shape=input_shape)

# 输入块
x = layer.Rescaling(1.0 / 255)(inputs)
x = layer.Conv2D(128, 3, strides=2, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)
x = layer.Activation(&quot;relu&quot;)(x)

previous_block_activation = x # 留出残差

layer_use = []
for i in range(layer_num): layer_use.append(layer_sizes[i])

for size in layer_use:
x = layer.Activation(&quot;relu&quot;)(x)
x = layer.SeparableConv2D(size, 3, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)

x = layer.Activation(&quot;relu&quot;)(x)
x = layer.SeparableConv2D(size, 3, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)

x = layer.MaxPooling2D(3, strides=2, padding=&quot;same&quot;)(x)

# 投影残差
residual = layer.Conv2D(size, 1, strides=2, padding=&quot;same&quot;)(
previous_block_activation
)
x = layer.add([x, residual]) # 添加回残差
previous_block_activation = x # 留出下一个残差

x = layer.SeparableConv2D(1024, 3, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)
x = layer.Activation(&quot;relu&quot;)(x)

x = layer.GlobalAveragePooling2D()(x)
if num_classes == 2:
unit = 1
else:
unit = num_classes

if dropouts == 1:
x = layer.Dropout(drop_out)(x)
# 我们指定activation=None以便返回logits
outputs = layer.Dense(units,activation=None)(x)
elif dropouts == 2:
x = layer.Dropout(0.2)(x)
x = layer.Dropout(units,activation=None)(x)
outputs = layer.Dropout(drop_out)(x)

返回keras.Model(inputs,outputs)

model = make_model(input_shape=image_size + (3,),num_classes=2,layer_num=number_of_layers,
drop_out=drop_out,dropouts=num_dropouts)

model.compile(
optimizer=keras.optimizers.Adam(learning_rate=learn_rate),
loss=keras.losses.BinaryCrossentropy(from_logits=True),
metrics=[keras.metrics.BinaryAccuracy(name=&quot;acc&quot;)],
)

model.fit(
train_ds,
epochs=epochs,
callbacks=callbacks,
validation_data=val_ds,
class_weight=class_weight
)

模型训练良好 - 达到约 97% 的验证准确率。使用预测函数时，模型通常会根据我提供的输入数据给出合理的输出。我遇到的问题是，使用 predict_on_batch 函数时的输出预测并不相同，如果使用相同的输入数据重复，通常会相差 +-0.15。这是什么原因造成的，一旦模型经过训练并用于预测，对于相同的输入数据，预测难道不应该相同吗？]]></description>
      <guid>https://stackoverflow.com/questions/78789559/keras-cnn-model-gives-different-output-predictions-for-the-same-input</guid>
      <pubDate>Wed, 24 Jul 2024 16:36:55 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Kubeflow Pipelines 中设置启动器和驱动程序映像</title>
      <link>https://stackoverflow.com/questions/78789198/how-to-set-launcher-and-driver-image-in-kubeflow-pipelines</link>
      <description><![CDATA[我正在为我的企业运行 Kubeflow 管道，我们无法使用公共映像。目前，当我运行 Kubeflow Pieplines 时，它会自动转到 gcr.io/ml-pipeline/kfp-driver@sha256:0ce9bf20ac9cbb21e84ff0762d5ae508d21e9c85fde2b14b51363bd1b8cd7528 获取 kfp 驱动程序映像。有没有办法用 KFP SDK 覆盖它？
我看到这个问题已经解决了，但不知道该如何实现。
https://github.com/kubeflow/pipelines/issues/7225]]></description>
      <guid>https://stackoverflow.com/questions/78789198/how-to-set-launcher-and-driver-image-in-kubeflow-pipelines</guid>
      <pubDate>Wed, 24 Jul 2024 15:12:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在窗口上聚合 RESNET50 全局特征？</title>
      <link>https://stackoverflow.com/questions/78788243/how-to-aggregate-resnet50-global-features-over-a-window</link>
      <description><![CDATA[我必须通过时间序列凝视数据集进行人员识别。我有正在观看视频的人的凝视信息，并且对于每个时间戳，我都会从视频中获取裁剪的帧以了解人员正在看哪里，然后将其提供给 RESNET-50 预训练模型以提取其特征。从模型中删除最后一个分类层，以便我获得每个图像的 2048 维向量。
最后，我有一个带有时间戳的时间序列数据，对于每一行，凝视信息 + 2048 个来自 RESNET 模型的特征。我的目标是使用凝视特征进行人员识别，并在这些凝视特征之上，输出 RESNET 特征。
现在，我想进行特征聚合，可能在窗口大小上进行。我一直在研究像 Fischer 向量这样的局部特征聚合方法，但我拥有的是图像的全局特征。
TL;DR，有没有一种好的方法可以在窗口大小上聚合 RESNET-50 特征？
我尝试过使用常见的聚合方法，如均值和方差、最大最小值等，但不确定聚合结果是否对应有意义的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78788243/how-to-aggregate-resnet50-global-features-over-a-window</guid>
      <pubDate>Wed, 24 Jul 2024 12:07:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 SHAP 值生成的蜂群图中点的可见性问题</title>
      <link>https://stackoverflow.com/questions/78788072/issue-with-visibility-of-points-in-beeswarm-plot-generated-using-shap-values</link>
      <description><![CDATA[我理解，在蜂群图中，实例以点/点来表示。因此，人们可以根据 SHAP 值找到水平分布（沿 x 轴）的点簇，当 SHAP 值密度较高时，这些点簇垂直堆叠（沿 y 轴）。
在大多数文档中，我看到蜂群图看起来像这样（https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/）：

创建蜂群图后，我无法清晰地看到这些点。我注意到形状点的边缘形成了更平滑的表面。我不确定我做对了什么或做错了什么，如果您能帮助我改变这一点，我将不胜感激。
这是我运行的代码。
shap_values = explainer.shap_values(X.iloc[0:N_VAL,:], nsamples=NSHAP_SAMPLES)

shap.summary_plot(shap_values, X.iloc[:N_VAL, :], plot_type=&quot;violin&quot;, max_display=21, show=False)

# 调整图形大小以确保所有内容都适合
plt.gcf().set_size_inches(15, 10) # 根据需要调整大小

# 显示图表
plt.show()

代码生成下面的图表

如果您能帮助我了解这里发生了什么以及如何处理这个问题，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78788072/issue-with-visibility-of-points-in-beeswarm-plot-generated-using-shap-values</guid>
      <pubDate>Wed, 24 Jul 2024 11:33:37 GMT</pubDate>
    </item>
    <item>
      <title>数据交叉验证[关闭]</title>
      <link>https://stackoverflow.com/questions/78787891/cross-validation-on-data</link>
      <description><![CDATA[我有两个文件，一个是 train.csv，另一个是 test.csv。test.csv 是看不见的数据，我们不会在训练中使用它。所以我使用 train.csv，我使用训练分割将其进一步分割为 train_1 和验证集。我想应用交叉验证 (K-Fold)。我应该对 train_1 还是对整个训练数据（即 train.csv）应用交叉验证？我很困惑。关于超参数调整还有一件事。我正在使用 RandomizedSerachCV，如果我想给出 cv=None，那么没问题，因为我不想再次应用交叉验证。
我正在尝试检查模型的稳健性并进行一些超参数调整。]]></description>
      <guid>https://stackoverflow.com/questions/78787891/cross-validation-on-data</guid>
      <pubDate>Wed, 24 Jul 2024 10:50:12 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的空间数据框中识别横断面上的点</title>
      <link>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</link>
      <description><![CDATA[我有调查数据，沿着与海岸垂直的平行横断面每隔 1 海里记录一次。对于每条记录，我都有纬度和经度、速度、方位等信息。沿着横断面，速度约为 10 节。我还在样条间（速度可能不同，方位肯定不同）处有一些点，如果进行了拖网，我还在样条外有一些点。
我想要做的是将属于同一样条的所有点分组（例如，参见图）：

这只是使用 1 NM 点间距离完成的，正如您在图中看到的那样，这实际上不起作用，因为只要有样条间（如样条 5），它就会与样条本身分组在一起。此外，在横断面 13 中，由于某种原因，2 个后续记录之间的距离略大于 1 海里，因此这些点被分成 2 个横断面（您可以看到颜色略有不同）。
此处显示的数据框示例：
 |year |datetime |xkm |ykm |logdiff |time_diff |distance |bearing |speed |
|&lt;dbl&gt; |&lt;dttm&gt; |&lt;dbl&gt; |&lt;dbl&gt; |&lt;dbl&gt;| &lt;dbl&gt;| &lt;drtn&gt; | &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;|
|------|---------- |------|-----|--------|------ --|---------|--------|------|
|2023 |2023-09-26 15:03:00 |221. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:08:00 |223. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:14:00 |225. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:19:00 |227. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:25:00 |229. |1606.| 1| 360 秒 | 1| -1.84| 10|
|2023 |2023-09-26 15:30:00 |231. |1606.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:36:00 |233. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:41:00 |234. |1605.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:47:00 |236. |1605.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:52:00 |238. |1605.| 1| 300 秒 | 1| -1.58| 12|

在 R 中解决这个问题的最佳方法是什么？我考虑过一些无监督的机器学习算法，比如使用 dbscan 进行聚类，但我不确定我是否正确使用了它。除了点之间的距离，我还想使用其他参数来对点是否属于横断面进行分类（例如方位和速度）。
我的尝试：
# 准备聚类数据
clustering_data &lt;- df %&gt;% select(year, speed, bearing, xkm, ykm)

# 应用 DBSCAN 聚类
set.seed(123)
db &lt;- dbscan(clu​​stering_data, eps = 1.8, minPts = 5)


有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</guid>
      <pubDate>Wed, 24 Jul 2024 10:33:52 GMT</pubDate>
    </item>
    <item>
      <title>如何创建数据集以使用 Tensorflow 进行文本生成</title>
      <link>https://stackoverflow.com/questions/78787403/how-to-create-the-dataset-to-use-tensorflow-for-text-generation</link>
      <description><![CDATA[我正在构建一个 Tensorflow 模型，根据项目名称生成文本。但是，我不知道如何为此目的创建数据集。
我的数据集中有三个特征，将根据这些特征创建文本。那么我该怎么办？
此外，我如何增加模型生成的文本的长度。
我已经创建了大约 18000 行的数据集，其中第一个特征有 12 个类别，第二个特征有 2 个类别，第三个特征有 78 个类别。目标列是与特征相关的测试，经过训练后，将预测模型中的文本生成。
由此，我希望输入将给出 3 个特征，并基于这些输入生成文本，但语言变化和修改与训练数据不完全相同。]]></description>
      <guid>https://stackoverflow.com/questions/78787403/how-to-create-the-dataset-to-use-tensorflow-for-text-generation</guid>
      <pubDate>Wed, 24 Jul 2024 09:15:38 GMT</pubDate>
    </item>
    <item>
      <title>在 keras.metrics.TruePositives 中，TruePositive 怎么会是十进制数？</title>
      <link>https://stackoverflow.com/questions/78787112/how-can-truepositive-be-a-decimal-number-in-keras-metrics-truepositives</link>
      <description><![CDATA[我正在尝试在图像数据集上训练 CNN 模型，但是我无法获得 TruePositives、TrueNegatives、FalsePositives 和 FalseNegatives 的十进制值。这怎么可能呢？
ERROR sample
Epoch 1/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━ 69s 2s/step - false_negatives: 30.1351 - false_positives: 35.3784 - loss: 2.1995 - true_negatives: 389.0540 - true_positives: 437.6487


有一些（tp+tn+fp+tn）不等于样本总数。
完整代码

import pandas as pd
将 tensorflow 导入为 tf
从 tensorflow.keras.preprocessing.image 导入 ImageDataGenerator

从 tensorflow.keras.layers 导入 Dense、Flatten、InputLayer、Conv2D、MaxPooling2D、Concatenate、Input、BatchNormalization
从 tensorflow.keras.models 导入 Sequential、Model
从 tensorflow.keras.losses 导入 BinaryCrossentropy、CategoricalCrossentropy
从 tensorflow.keras.optimizers 导入 Adam
将 matplotlib.pyplot 导入为 plt
从 tensorflow.keras.models 导入 Model
从 sklearn.metrics 导入 Classification_report
从 tensorflow.keras.callbacks 导入EarlyStopping

datagen=ImageDataGenerator(rescale=1.0/255.0)
train_gen=datagen.flow_from_directory(&#39;train&#39;,class_mode=&#39;binary&#39;,
target_size=(224,224),batch_size=32,shuffle=True)


输出：

找到属于 2 个类别的 1146 张图像。

tp = tf.keras.metrics.TruePositives()
tn = tf.keras.metrics.TrueNegatives()
fp = tf.keras.metrics.FalsePositives()
fn = tf.keras.metrics.FalseNegatives()
tp.update_state([0.4, .9, .7, .8], [1.0, 0.0, 1.0, 1.0])
tp.result()

输出
&lt;tf.Tensor: shape=(), dtype=float32, numpy=3.0&gt;

model_input=Input(shape=(224,224,3))

x=Conv2D(filters=32, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(model_input)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=Conv2D(filters=64, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(x)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=BatchNormalization()(x)
x=Conv2D(filters=64, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(x)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=BatchNormalization()(x)
x=Flatten()(x)
x=Dense(units=1000,activation=&#39;relu&#39;)(x)
output=Dense(units=1,activation=&#39;sigmoid&#39;)(x)
model=Model(inputs=model_input,outputs=output)

model.compile(optimizer=Adam(),loss=BinaryCrossentropy(),metrics=[tp,fp,fn,tn])
early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, waiting=2,restore_best_weights=True)

history=model.fit(x=train_gen,epochs=3,callbacks=[early_stopping])

十进制值错误
Epoch 1/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━━ 69s 2s/step - false_negatives: 30.1351 - false_positives: 35.3784 - loss: 2.1995 - true_negatives: 389.0540 - true_positives: 437.6487
Epoch 2/3
36/36 ━━━━━━━━━━━━━━━━━━━━━ 61s 2s/步 - 假阴性：7.8378 - 假阳性：13.5135 - 损失：0.1692 - 真阴性：283.1081 - 真阳性：300.4054
Epoch 3/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━━ 65s 2s/步 - 假阴性： 2.3243 - 假阳性：3.0811 - 损失：0.0546 - 真阴性：289.8108 - 真阳性：308.3513

]]></description>
      <guid>https://stackoverflow.com/questions/78787112/how-can-truepositive-be-a-decimal-number-in-keras-metrics-truepositives</guid>
      <pubDate>Wed, 24 Jul 2024 08:14:02 GMT</pubDate>
    </item>
    <item>
      <title>安装 tf-models-official 时出现元数据生成失败</title>
      <link>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</link>
      <description><![CDATA[我尝试使用 !pip install tf-models-official 安装 tf-models-official，当它开始收集 kaggle&gt;=1.3.9 时，它返回以下错误：
收集 kaggle&gt;=1.3.9（来自 tf-models-official）
使用缓存的 kaggle-1.6.15.tar.gz (9.1 kB)
安装构建依赖项...完成
获取构建 wheel 的要求...完成
准备元数据（pyproject.toml）...错误
错误：子进程退出并出现错误

× 准备元数据（pyproject.toml）未成功运行。
│ 退出代码：1
╰─&gt; [35 行输出]
回溯（最近一次调用）：
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 353 行，位于 &lt;module&gt;
main()
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 335 行，在 main 中
json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 152 行，在 prepare_metadata_for_build_wheel 中
whl_basename = backend.build_wheel(metadata_directory, config_settings)
文件&quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/build.py&quot;，第 58 行，在 build_wheel 中
return os.path.basename(next(builder.build(directory=wheel_directory,versions=[&#39;standard&#39;])))
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;，第 155 行，在 build 中
artifact = version_api[version](directory,**build_data)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 475 行，在build_standard
for included_file in self.recurse_included_files():
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 176, in recurse_included_files
Yield from self.recurse_selected_project_files()
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 180, in recurse_selected_project_files
if self.config.only_include:
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/config.py&quot;，第 806 行，在 only_include 中
only_include = only_include_config.get(&#39;only-include&#39;, self.default_only_include()) 或 self.packages
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 260 行，在 default_only_include 中
return self.default_file_selection_options.only_include
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/functools.py&quot;，第 981 行，在__get__
val = self.func(instance)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 248 行，位于 default_file_selection_options
raise ValueError(message)
ValueError：无法使用以下启发式方法确定要将哪些文件发送到 wheel 内：https://hatch.py​​pa.io/latest/plugins/builder/wheel/#default-file-selection

最可能的原因是没有与您的项目 (kaggle) 名称匹配的目录。

必须在 `tool.hatch.build.targets.wheel` 表中定义至少一个文件选择选项，请参阅：https://hatch.py​​pa.io/latest/config/build/

例如，如果您打算发送一个名为 `foo` 的目录，该目录位于项目根目录的 `src` 目录中，则可以定义以下内容：

[tool.hatch.build.targets.wheel]
packages = [&quot;src/foo&quot;]
[输出结束]

注意：此错误源自子进程，可能不是 pip 的问题。
错误：metadata-generation-failed

× 生成包元数据时遇到错误。
╰─&gt; 请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip。
提示：请参阅上文了解详情。

我能够在 2 周前安装，现在在新的 jupyter 笔记本内核上突然无法安装。我尝试在旧内核上重新安装，也出现了同样的错误。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</guid>
      <pubDate>Wed, 24 Jul 2024 07:02:59 GMT</pubDate>
    </item>
    <item>
      <title>即使管道运行正常，管道输出仍为空</title>
      <link>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</link>
      <description><![CDATA[以下代码模拟了一个简单的 TFX 管道，它提取 CSV 文件并将其转换为 TFRecord。
您还可以查看相应的笔记本：https://colab.research.google.com/drive/1GEytZjnNZZ7r_f9QQ9FbauohKNLGSooC?usp=sharing
output_config = example_gen_pb2.Output(split_config=
example_gen_pb2.SplitConfig(splits=[
example_gen_pb2.SplitConfig.Split(name=&#39;train&#39;, hash_buckets=8),
example_gen_pb2.SplitConfig.Split(name=&#39;eval&#39;, hash_buckets=2)
])
)

example_gen = CsvExampleGen(
input_base=&#39;data&#39;,
output_config=output_config
)

pipeline_root = &#39;artifacts&#39;

pipeline = Pipeline(
pipeline_name=&#39;testing pipeline&#39;,
pipeline_root=pipeline_root,
components=[example_gen],
enable_cache=True,
metadata_connection_config=metadata.sqlite_metadata_connection_config(
os.path.join(&#39;artifacts&#39;, &#39;metadata.sqlite&#39;)
)
)

LocalDagRunner().run(pipeline)

我已手动验证 TFRecord 已正确生成。但是，管道的输出字典是空的。
print(pipeline.outputs)
# output: {}
print(example_gen.outputs[&#39;examples&#39;].get())
# output: []

此问题在 .ipynb 笔记本和 .py 文件中都存在。
有趣的是，InteractiveContext 没有这个问题。
是什么原因造成的？]]></description>
      <guid>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</guid>
      <pubDate>Sun, 23 Jun 2024 14:03:09 GMT</pubDate>
    </item>
    <item>
      <title>我不明白 sckit-learn 的 tfidfvectorizer 的工作原理</title>
      <link>https://stackoverflow.com/questions/77541978/i-do-not-understand-the-working-of-tfidfvectorizer-of-sckit-learn</link>
      <description><![CDATA[我知道的计算 tf-idf 的公式是 TF * IDF，其中 TF 是该词在文档 D 中出现的次数，IDF 是文档数/包含该词的文档数 + 1。
这是我的数据集。
corpus = [ &#39;这是第一个文档。&#39;, &#39;这个文档是第二个文档。&#39;, &#39;这是第三个文档。&#39;, &#39;这是第一个文档吗？&#39;, ]
现在我计算了文档 1 中单词“document”的 td-idf，输出为 0.22。
但是当我使用 sckit 的 tfidf 矢量化器时，输出为：
1.22314355
我使用的矢量化器具有以下参数：
vectorizer = TfidfVectorizer(norm=None) 
请解释为什么答案不同。]]></description>
      <guid>https://stackoverflow.com/questions/77541978/i-do-not-understand-the-working-of-tfidfvectorizer-of-sckit-learn</guid>
      <pubDate>Fri, 24 Nov 2023 09:16:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 LeaveOneOut() 的 cross_val_score 会导致 nan validationscore？</title>
      <link>https://stackoverflow.com/questions/76537113/why-cross-val-score-using-leaveoneout-leads-to-nan-validationscore</link>
      <description><![CDATA[我试图在sklearn的iris数据集中适应不同的cross_val_score类型（k-fold（），LeaveOneOut（），LeavepOut（））。但是LeaveOneOut（）导致nan分数列表。为什么会发生这种情况？任何人都可以解释？让我在这里附上我的部分代码==&gt;
kfindex=LeaveOneOut()
模型=线性回归()
分数=cross_val_score(模型,iris.data,iris.target,cv=kfindex)
打印(scores.mean(),scores.shape,scores)

输出==&gt;（分数）
[在(150,)[在in in in in in in in in in in in in in in in
里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里
里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里
里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里
里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里
里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里
里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里
里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里里
中中中中]]
我手动尝试了 cross_val_score，它也会导致相同的输出
&lt;前&gt;&lt;代码&gt;i=0
分数=[]
对于 kfindex.split(iris.data) 中的 train_x_indices、test_x_indeces：
    xtrain,xtest=iris.data[train_x_indices],iris.data[test_x_indices]
    ytrain,ytest=iris.target[train_x_indices],iris.target[test_x_indices]
# 打印(xtrain.shape)
    我+=1

    model.fit(xtrain,ytrain)
    a=model.score(xtest,ytest)
    分数.append(a)
印刷）
打印（分数，np.mean（分数））

有很多问题与 cross_val_score 的值有关。但没有一个问题能导致我的解决方案。请有人帮忙]]></description>
      <guid>https://stackoverflow.com/questions/76537113/why-cross-val-score-using-leaveoneout-leads-to-nan-validationscore</guid>
      <pubDate>Fri, 23 Jun 2023 04:39:09 GMT</pubDate>
    </item>
    <item>
      <title>没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块</title>
      <link>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</link>
      <description><![CDATA[代码下方
import numpy as np
np.random.seed(0)
from sklearn import datasets
import matplotlib.pyplot as plt
%matplotlib inline
%config InlineBackend.figure_format =&#39;retina&#39;

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD

错误消息下方
-------------------------------------------------------------------------------
ModuleNotFoundError Traceback (most recent call last)
~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
2 try:
----&gt; 3 from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
4 except ImportError:

ModuleNotFoundError: 没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块

在处理上述异常期间，发生了另一个异常：

ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-5-943507dd87a6&gt; in &lt;module&gt;
6 get_ipython().run_line_magic(&#39;config&#39;, &quot;InlineBackend.figure_format =&#39;retina&#39;&quot;)
7 
----&gt; 8 从 keras.models 导入 Sequential
9 从 keras.layers 导入 Dense
10 从 keras.optimizers 导入 SGD

~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
4 except ImportError:
5 raise ImportError(
----&gt; 6 &#39;Keras 需要 TensorFlow 2.2 或更高版本。&#39;
7 &#39;通过 `pip install tensorflow`&#39; 安装 TensorFlow)
8 

ImportError: Keras 需要 TensorFlow 2.2 或更高版本。通过 `pip install tensorflow` 安装 TensorFlow

注意：`我认为，主要问题是 Tensorflow 版本。我使用了一些命令，如下所示，
conda create -n tf tensorflow
conda activate tf

我还使用了以下命令
conda create -n tf-gpu tensorflow-gpu
conda activate tf-gpu

但是它不起作用，请帮助解决错误。]]></description>
      <guid>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</guid>
      <pubDate>Sun, 23 Aug 2020 02:18:29 GMT</pubDate>
    </item>
    </channel>
</rss>