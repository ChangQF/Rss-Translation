<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 24 Jun 2024 12:28:47 GMT</lastBuildDate>
    <item>
      <title>如何将 JSON 中的标记坐标叠加到 JPG 图像中以进行 CNN 训练？</title>
      <link>https://stackoverflow.com/questions/78661583/how-to-overlay-labeled-coordinates-from-json-into-jpg-images-for-cnn-training</link>
      <description><![CDATA[我正在开展一个计算机视觉项目，该项目涉及检测和分割 MRI 扫描中的骨折。作为该项目的一部分，我让专家直接在图像上标记骨折区域。此过程会生成一个 JSON 文件，其中包含以下信息：

标记区域的坐标
标记区域的名称
标记图像的名称

我面临的挑战是将这些坐标从 JSON 文件转移到相应的 JPG 图像上，以准备进行 CNN 训练。
以下是我的 JSON 文件结构示例：
&quot;item&quot;: {
&quot;name&quot;: &quot;img-00003-00082.jpg&quot;,
&quot;team&quot;: {
&quot;name&quot;: &quot;Mask&quot;,
&quot;slug&quot;: &quot;mask&quot;
&quot;file_name&quot;: &quot;img-00003-00082.jpg&quot;,
&quot;annotations&quot;: [
{
&quot;bounding_box&quot;: {
&quot;h&quot;: 142.16649999999993,
&quot;w&quot;: 124.14549999999997,
&quot;x&quot;: 679.8006,
&quot;y&quot;: 425.7789
},
&quot;name&quot;: &quot;Broken&quot;,
&quot;polygon&quot;: {
&quot;paths&quot;: [
[
{
&quot;x&quot;: 695.1519,
&quot;y&quot;: 567.9454
},
{
&quot;x&quot;: 679.8006,
&quot;y&quot;: 530.5683
},


到目前为止，我已经设法从 JSON 文件中提取了必要的坐标。但是，我很难将这些坐标叠加到 JPG 图像上以生成 CNN 的训练数据。
我的问题：

如何准确地将 JSON 文件中的坐标叠加到相应的 JPG 图像上？
是否有任何推荐的 Python 库或方法专门适合此任务？
]]></description>
      <guid>https://stackoverflow.com/questions/78661583/how-to-overlay-labeled-coordinates-from-json-into-jpg-images-for-cnn-training</guid>
      <pubDate>Mon, 24 Jun 2024 09:29:08 GMT</pubDate>
    </item>
    <item>
      <title>与前一天相比，同一特征的 MSE 的负和正百分比增加</title>
      <link>https://stackoverflow.com/questions/78660957/negative-and-positive-increase-in-mse-for-a-same-feature-over-previous-day</link>
      <description><![CDATA[我有一个包含过去几天的数据和当天数据的数据框。
示例列 [cases、mobility、temp、rh、cases_1、mobility_1、temp_1、rh_1、cases_2、mobility_2、temp_2、rh_2 等。。]。我的目标列 (Y) 是“cases”，col_i 表示当前日期前 i 天的参数。
%inc mse 的代码如下所示。这会导致某些特征（如 temp）具有正值，而 temp_1 具有负值，temp_2 也可以具有正值或负值，其他特征也是如此。我该如何解释这些结果并找到过去几天的列的综合累积效应？
from tabulate import tabulate
feature_importance_df = pd.DataFrame({&#39;Feature Name&#39;: X_pastdays_test.columns}) 

y_pred_baseline = rf_regressor.predict(X_pastdays_test)
baseline_mse = mean_squared_error(y_test, y_pred_baseline)

percent_inc_mse_list = []
for feature_name in X_pastdays_test.columns:
# 排列测试数据中特征的值
x_test_perturbed = X_pastdays_test.copy()
x_test_perturbed[feature_name] = np.random.permutation(x_test_perturbed[feature_name])

# 使用扰动数据进行预测数据
y_pred_perturbed = rf_regressor.predict(x_test_perturbed)

# 使用扰动数据计算均方误差
perturbed_mse = mean_squared_error(y_test, y_pred_perturbed)

# 将 %Inc MSE 计算为 MSE 的百分比增加
percent_inc_mse = ((perturbed_mse - baseline_mse) / baseline_mse) * 100
percent_inc_mse_list.append(percent_inc_mse)

feature_importance_df[&#39;%Inc MSE&#39;] = percent_inc_mse_list

feature_importance_df = feature_importance_df.sort_values(by=&#39;%Inc MSE&#39;, accending=False)

print(feature_importance_df)
]]></description>
      <guid>https://stackoverflow.com/questions/78660957/negative-and-positive-increase-in-mse-for-a-same-feature-over-previous-day</guid>
      <pubDate>Mon, 24 Jun 2024 07:02:32 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 时，损失为 Nan</title>
      <link>https://stackoverflow.com/questions/78660903/loss-is-nan-with-tensorflow</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78660903/loss-is-nan-with-tensorflow</guid>
      <pubDate>Mon, 24 Jun 2024 06:50:02 GMT</pubDate>
    </item>
    <item>
      <title>当模型在高度不平衡的数据集上进行训练时，其性能如何[关闭]</title>
      <link>https://stackoverflow.com/questions/78660719/how-is-the-performance-of-a-model-when-its-trained-on-highly-unbalanced-dataset</link>
      <description><![CDATA[假设我们有 1000 个 1 类样本和 1000 个 2 类样本。我们用这个数据训练了一个模型，发现模型的性能很好。如果用 10000 个 1 类样本和 90000 个 2 类样本的数据训练模型，模型的性能会发生什么变化？
我认为模型过度拟合了 2 类数据，性能会下降。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/78660719/how-is-the-performance-of-a-model-when-its-trained-on-highly-unbalanced-dataset</guid>
      <pubDate>Mon, 24 Jun 2024 05:43:12 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型的评估结果为损失 = 68（大于 1）</title>
      <link>https://stackoverflow.com/questions/78660583/evaluation-of-keras-model-gets-me-a-loss-68-greater-than-1</link>
      <description><![CDATA[我按照书中的示例，使用时尚 MNIST
我的代码如下：
\`import tensorflow as tf
from tensorflow import keras
fashion_mnist = keras.datasets.fashion_mnist
(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()
X_valid, X_train = X_train_full\[:5000\] / 255.0, X_train_full\[5000:\] / 255.0
y_valid, y_train = y_train_full\[:5000\], y_train_full\[5000:\]

class_names = \[&quot;T-shirt/top&quot;, &quot;Trouser&quot;, “套头衫”、“连衣裙”、“外套”、“凉鞋”、“衬衫”、“运动鞋”、“包”、“踝靴”\]

#构建神经网络模型
model = keras.models.Sequential() 
model.add(keras.layers.Flatten(input_shape=\[28, 28\]))
model.add(keras.layers.Dense(300,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(100,activation=&quot;relu&quot;))
model.add(keras.layers.Dense(10,激活=&quot;softmax&quot;))

model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=&quot;sgd&quot;, metrics=\[&quot;accuracy&quot;\])

history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))

model.evaluate(X_test, y_test)\`

我这次评估的输出是这样的
313/313 [===============================] - 1s 3ms/step - 损失：68.7269 - 准确率：0.8385
[68.72686004638672, 0.8385000228881836]
使用 .fit 方法后，我得到了以下结果：
Epoch 30/30
1719/1719 [==============================] - 9s 5ms/step - 损失：0.2115 - 准确度：0.9236 - val_loss：0.2171 - val_accuracy：0.9209
我还在学习，我不知道该怎么做才能解决这个问题，我也不知道我可能哪里做错了……]]></description>
      <guid>https://stackoverflow.com/questions/78660583/evaluation-of-keras-model-gets-me-a-loss-68-greater-than-1</guid>
      <pubDate>Mon, 24 Jun 2024 04:51:24 GMT</pubDate>
    </item>
    <item>
      <title>这个销售问题应该使用什么机器学习模型？我是新手，很困惑 [关闭]</title>
      <link>https://stackoverflow.com/questions/78660178/what-machine-learning-model-should-be-used-in-this-sales-problem-im-new-and-c</link>
      <description><![CDATA[我在这个领域很新，最近我有一个建立模型的练习。我很困惑是建立回归模型还是分类模型。我应该怎么做，我应该继续使用这个模型还是建立一个新模型？如果我继续，应该改进什么？
数据集链接
我尝试建立一个随机森林模型，并获得 0.5 的准确度得分和 f1 得分。特征包括地区、国家、商品类型、销售渠道、订单优先级，目标是销售单位。我试图将每个特征对销售单位的重要性包括在内。]]></description>
      <guid>https://stackoverflow.com/questions/78660178/what-machine-learning-model-should-be-used-in-this-sales-problem-im-new-and-c</guid>
      <pubDate>Mon, 24 Jun 2024 00:37:32 GMT</pubDate>
    </item>
    <item>
      <title>System.AccessViolationException：尝试在 TorchSharp.PInvoke.LibTorchSharp.THSGenerator_manual_seed 读取或写入受保护的内存</title>
      <link>https://stackoverflow.com/questions/78660054/system-accessviolationexception-attempted-to-read-or-write-protected-memory-at</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78660054/system-accessviolationexception-attempted-to-read-or-write-protected-memory-at</guid>
      <pubDate>Sun, 23 Jun 2024 23:08:49 GMT</pubDate>
    </item>
    <item>
      <title>我正在做一个足球分析跟踪机器学习项目，我得到了速度和距离估计器的导入错误</title>
      <link>https://stackoverflow.com/questions/78659710/i-am-making-a-football-analysis-tracking-machine-learning-project-i-am-getting-i</link>
      <description><![CDATA[ImportError: 无法从 
&#39;speed_and_distance_estimator.speed_and_distance_estimator&#39; 
(c:\Users...\Football analysis\speed_and_distance_estimator\speed_and_distance_estimator.py) 导入名称 &#39;Speed_and_Distance_Estimator&#39;

在我的文件 speed_and_distance_estimator.py 中
sys.path.append(&#39;../&#39;)
from utils import measure_distance, get_foot_position

class Speed_and_Distance_Estimator:
pass

在我的 init.py 中
from .speed_and_distance_estimator import Speed_and_Distance_Estimator

我预计我的 main.py 中不会出现任何错误
from utils import read_video, save_video
from trackers import Tracker
import cv2
import numpy as np
from team_assigner import TeamAssigner
from player_ball_assigner import PlayerBallAssigner
from camera_movement_estimator import CameraMovementEstimator
from view_transformer import ViewTransformer
from speed_and_distance_estimator import Speed_and_Distance_Estimator

def main():
# 读取视频
video_frames = read_video(&#39;input_videos/08fd33_4.mp4&#39;)

# 初始化跟踪器
tracker = Tracker(&#39;models/best.pt&#39;)

tracks = tracker.get_object_tracks(video_frames,
read_from_stub=True,
stub_path=&#39;stubs/track_stubs.pkl&#39;)
# 获取对象位置 
tracker.add_position_to_tracks(tracks)

# 相机运动估计器
camera_movement_estimator = CameraMovementEstimator(video_frames[0])
camera_movement_per_frame = camera_movement_estimator.get_camera_movement(video_frames,
read_from_stub=True,
stub_path=&#39;stubs/camera_movement_stub.pkl&#39;)
camera_movement_estimator.add_adjust_positions_to_tracks(tracks,camera_movement_per_frame)

# 视图转换器
view_transformer = ViewTransformer()
view_transformer.add_transformed_position_to_tracks(tracks)

# 插入球位置
tracks[&quot;ball&quot;] = tracker.interpolate_ball_positions(tracks[&quot;ball&quot;])

# 速度和距离估算器
speed_and_distance_estimator = Speed_and_Distance_Estimator()
speed_and_distance_estimator.add_speed_and_distance_to_tracks(tracks)

# 分配球员队伍
team_assigner = TeamAssigner()
team_assigner.assign_team_color(video_frames[0], 
tracks[&#39;players&#39;][0])

for frame_num, player_track in enumerate(tracks[&#39;players&#39;]):
for player_id, track in player_track.items():
team = team_assigner.get_player_team(video_frames[frame_num], 
track[&#39;bbox&#39;],
player_id)
tracks[&#39;players&#39;][frame_num][player_id][&#39;team&#39;] = team 
tracks[&#39;players&#39;][frame_num][player_id][&#39;team_color&#39;] = team_assigner.team_colors[team]

# 分配球获取
player_assigner =PlayerBallAssigner()
team_ball_control= []
for frame_num, player_track in enumerate(tracks[&#39;players&#39;]):
ball_bbox = tracks[&#39;ball&#39;][frame_num][1][&#39;bbox&#39;]
assigned_player = player_assigner.assign_ball_to_player(player_track, ball_bbox)

if assignment_player != -1:
tracks[&#39;players&#39;][frame_num][assigned_player][&#39;has_ball&#39;] = True
team_ball_control.append(tracks[&#39;players&#39;][frame_num][assigned_player][&#39;team&#39;])
else:
team_ball_control.append(team_ball_control[-1])
team_ball_control= np.array(team_ball_control)

# 绘制输出 
## 绘制对象轨迹
output_video_frames = tracker.draw_annotations(video_frames, tracks,team_ball_control)

## 绘制摄像机运动
output_video_frames = camera_movement_estimator.draw_camera_movement(output_video_frames,camera_movement_per_frame)

## 绘制速度和距离
speed_and_distance_estimator.draw_speed_and_distance(output_video_frames,tracks)

# 保存视频
save_video(output_video_frames, &#39;output_videos/output_video.avi&#39;)

if __name__ == &#39;__main__&#39;:
main()
]]></description>
      <guid>https://stackoverflow.com/questions/78659710/i-am-making-a-football-analysis-tracking-machine-learning-project-i-am-getting-i</guid>
      <pubDate>Sun, 23 Jun 2024 20:05:06 GMT</pubDate>
    </item>
    <item>
      <title>为训练、验证和测试分割创建 LMDB 文件 [关闭]</title>
      <link>https://stackoverflow.com/questions/78659680/create-lmdb-files-for-train-validation-and-test-splits</link>
      <description><![CDATA[为训练、验证和测试分割创建 LMDB 文件。
python tools/create_dataset.py --root_dir &lt;dataset_dir&gt; --save &lt;lmdb_dst_path&gt;

数据集文件夹应遵循与 IIIT-INDIC-HW-WORDS 结构相同的结构。
生成一个包含用于预测的 Unicode 符号/字符的文件。将此文件移动到 alphabet/ 文件夹。此 repo 已包含 alphabet/ 文件夹中印度语脚本的排序字母表列表。
python tools/create_dataset.py --root_dir /Users/armanmansury/Developer/Work/indic-htr-main/tools/create_dataset.py --save /Users/armanmansury/Developer/Work/indic-htr-main
]]></description>
      <guid>https://stackoverflow.com/questions/78659680/create-lmdb-files-for-train-validation-and-test-splits</guid>
      <pubDate>Sun, 23 Jun 2024 19:50:33 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch Vision Transformer 模型中的异常、验证损失、测试准确度和正常准确度计算 [关闭]</title>
      <link>https://stackoverflow.com/questions/78659312/anomaly-in-pytorch-vision-transformer-model-validation-loss-testing-accuracy-a</link>
      <description><![CDATA[我正在尝试使用 PyTorch 为我的个人项目创建一个视觉变换模型。
问题是，当我运行测试代码时，我不确定我是否正确计算了训练损失、验证损失、训练准确率和测试（+ 前 2 名测试）准确率。
这是我的代码：
criterion = nn.CrossEntropyLoss()
optimizer = AdamW(vit.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)

# 训练循环
train_losses, val_losses, accuracies, top2_accuracies= [], [], [], []
training_start = time.time()

for epoch in range(NUM_EPOCHS):
log_str = write_and_print_str(log_str, f&quot;EPOCH [{epoch+1}/{NUM_EPOCHS}]&quot;)
start = time.time()
vit.train()
running_loss = []
for images, labels in train_dataloader:
images, labels = images.to(device), labels.to(device)
optimizer.zero_grad()
output = vit(images)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()
running_loss.append(loss.item())

avg_train_loss = sum(running_loss) / len(running_loss)
train_losses.append(avg_train_loss)
log_str = write_and_print_str(log_str, f&#39;Loss: {avg_train_loss}&#39;)

vit.eval()
val_loss = []
correct = 0
top2_correct = 0
total = 0
with torch.no_grad():
for images, labels in test_dataloader:
images, labels = images.to(device), labels.to(device)
output = vit(images)
loss = criterion(outputs, labels)
val_loss.append(loss.item())
_, predicted = torch.max(outputs.data, 1)
total += labels.size(0)
correct += (predicted == labels).sum().item()

# 计算 top-2 准确率
top2_pred = torch.topk(outputs, 2, dim=1).indices
top2_correct += (top2_pred == labels.unsqueeze(1)).sum().item()
end = time.time()
avg_val_loss = sum(val_loss) / len(val_loss)
accuracy = 100 * correct / total
top2_accuracy = 100 * top2_correct / total

val_losses.append(avg_val_loss)
accuracies.append(accuracy)
top2_accuracies.append(top2_accuracy)

log_str = write_and_print_str(log_str, f&#39;验证损失：{avg_val_loss}，\n准确率：{accuracy}%，\nTop-2 准确率：{top2_accuracy}%\n时间：{round(end-start, 2)}\n\n&#39;)

training_end = time.time()

log_str = write_and_print_str(log_str, f&#39;训练持续时间：{round(training_end - training_start, 2)}\n&#39;)

print(&quot;EPOCHS 已成功保存到文件中&quot;)


我运行了 20 多次，并记录了所有运行广泛的方法。
在所有结果中，验证损失开始超过 1并降低到 0.20。但问题是在这些情况下我的准确率约为 90%，所以我认为我的代码在计算方面出了问题。
为了更详细地说明准确率和损失的数值，以下是我的一些 EPOCH 结果
EPOCH [1/50]
损失：1.4692728799123032
验证损失：1.1625839814995274，
准确率：49.58932238193019%，
Top-2 准确率：75.77002053388091%
时间：29.71

EPOCH [10/50]
损失：0.1079550055715327
验证损失： 0.5106942771059094，
准确率：83.26488706365502%，
Top-2 准确率：97.53593429158111%
时间：25.86

EPOCH [20/50]
损失：0.037730065656293076
验证损失：0.4059527646185774，
准确率：89.52772073921972%，
Top-2 准确率：97.94661190965093%
时间：26.12

EPOCH [30/50]
损失： 0.00011380775267753052
验证损失：0.22308006276955095，
准确率：94.6611909650924%，
Top-2 准确率：99.48665297741273%
时间：24.41

EPOCH [40/50]
损失：3.5449059315886606e-05
验证损失：0.23672400451808548，
准确率：94.76386036960986%，
Top-2 准确率：99.48665297741273%
时间：25.46

EPOCH [50/50]
损失：1.367992779425829e-05
验证损失：0.24671741761443572，
准确率：94.6611909650924%，
Top-2 准确率：99.48665297741273%
时间：25.66

希望您能帮我解决这个问题。我只是需要澄清一下]]></description>
      <guid>https://stackoverflow.com/questions/78659312/anomaly-in-pytorch-vision-transformer-model-validation-loss-testing-accuracy-a</guid>
      <pubDate>Sun, 23 Jun 2024 16:52:16 GMT</pubDate>
    </item>
    <item>
      <title>即使管道运行正常，管道输出仍为空</title>
      <link>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</link>
      <description><![CDATA[以下代码模拟了一个简单的 TFX 管道，它提取 CSV 文件并将其转换为 TFRecord。
您还可以查看相应的笔记本：https://colab.research.google.com/drive/1GEytZjnNZZ7r_f9QQ9FbauohKNLGSooC?usp=sharing
output_config = example_gen_pb2.Output(split_config=
example_gen_pb2.SplitConfig(splits=[
example_gen_pb2.SplitConfig.Split(name=&#39;train&#39;, hash_buckets=8),
example_gen_pb2.SplitConfig.Split(name=&#39;eval&#39;, hash_buckets=2)
])
)

example_gen = CsvExampleGen(
input_base=&#39;data&#39;,
output_config=output_config
)

pipeline_root = &#39;artifacts&#39;

pipeline = Pipeline(
pipeline_name=&#39;testing pipeline&#39;,
pipeline_root=pipeline_root,
components=[example_gen],
enable_cache=True,
metadata_connection_config=metadata.sqlite_metadata_connection_config(
os.path.join(&#39;artifacts&#39;, &#39;metadata.sqlite&#39;)
)
)

LocalDagRunner().run(pipeline)

我已手动验证 TFRecord 已正确生成。但是，管道的输出字典是空的。
print(pipeline.outputs)
# output: {}
print(example_gen.outputs[&#39;examples&#39;].get())
# output: []

此问题在 .ipynb 笔记本和 .py 文件中都存在。
有趣的是，InteractiveContext 没有这个问题。
是什么原因造成的？]]></description>
      <guid>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</guid>
      <pubDate>Sun, 23 Jun 2024 14:03:09 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MASK R_CNN 通过 OpenCV 提取图像中的精确区域？</title>
      <link>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</link>
      <description><![CDATA[我有一个医疗项目，需要提取一个特殊部分（结膜眼球）

自动提取眼睛图像而不了解其坐标，而不是手动提取，而且这个所需区域的坐标也在变化，因为我从许多患者那里捕捉到了图像，我认为必须找到它的形状。我的目标是通过计算结膜眼球中的红色像素来确定贫血和非贫血。我使用掩蔽方法（k 均值）来做到这一点，但我希望可以先直接提取结膜眼球，然后使用 k 均值掩蔽图像并查找，因为我的结果会更准确。当我使用图像分割中的 k 均值时，我发现另一个重叠的红色像素破坏了我的准确性。
。我也听说过机器学习，但在使用机器学习找到患者图像中的邻近区域后，我需要提取结膜髓核。所以我需要代码来仅提取结膜髓核。
我尝试了 k_means 和 kernel，但又添加了一个不需要的红色像素。我听说过实例分割和MASK RCNN。您假设我有我想要的区域，如上图所示，它是 CNN 的数据，那么如何将其用于我的项目。
import cv2
import numpy as np

# 读取图像
image = cv2.imread(&#39;c:/users/stk/desktop/d.png&#39;)

# 将图像转换为 HSV
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# 定义红色的下限和上限
lower_red = np.array([0, 120, 70])
upper_red = np.array([10, 255, 255])

# 为红色创建蒙版
mask1 = cv2.inRange(hsv, lower_red, upper_red)

# 定义红色的下限和上限
lower_red = np.array([170, 120, 70])
upper_red = np.array([180, 255, 255])

# 为红色创建蒙版
mask2 = cv2.inRange(hsv, lower_red, upper_red)

# 合并两个蒙版
mask = mask1 + mask2

# 为形态学操作创建内核
kernal = np.ones((5, 5), np.uint8)

# 执行形态学操作
mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernal)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernal)

# 将蒙版应用于原始图像
result = cv2.bitwise_and(image, image, mask = mask)

# 保存result
cv2.imwrite(&#39;extracted_red_object.png&#39;, result)

# 显示结果
cv2.imshow(&#39;EXTRACTED RED OBJECT&#39;, result)
cv2.waitKey(0)
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78657727/how-do-i-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</guid>
      <pubDate>Sun, 23 Jun 2024 03:58:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用训练有素的 YOLO-V8 实例分割模型进行预测时将边界框值添加到标签文本文件中？</title>
      <link>https://stackoverflow.com/questions/78649611/how-to-add-the-bounding-box-values-to-the-labels-text-files-during-prediction-wi</link>
      <description><![CDATA[我训练了一个 YOLO-V8 实例分割模型来分割类标签为 0 的对象。我使用 CLI 实例化训练后的模型并根据测试数据进行预测。
!yolo task=segment mode=predict model=&#39;/weights/best.pt&#39; conf=0.25 source=&#39;/test/images&#39; imgsz=1024 save=True save_txt=True save_conf=True

预测后，标签文件将以 .txt 格式存储。这些标签文件包含类索引，后跟多边形坐标，最后是边界框预测的置信度分数。但是，边界框坐标（即 x 中心、y 中心、宽度、高度）不包含在标签文件中。我还想将这些边界框坐标包含到每个标签文件中，因为我想稍后使用这些边界框坐标进行后期处理。示例标签文件内容如下所示：
0 0.21582 0.0898438 0.214844 0.0908203 0.213867 0.0908203 0.210938 0.09375 0.210938 0.0947266 0.203125 0.102539 0.203125 0.103516 0.201172 0.105469 0.200195 0.105469 0.199219 0.106445 0.199219 0.113281 0.200195 0.114258 0.200195 0.115234 0.203125 0.115234 0.204102 0.116211 0.223633 0.116211 0.224609 0.117188 0.227539 0.117188 0.228516 0.118164 0.230469 0.118164 0.231445 0.119141 0.234375 0.119141 0.235352 0.120117 0.248047 0.120117 0.249023 0.121094 0.251953 0.121094 0.25293 0.12207 0.254883 0.0927734 0.260742 0.0917969 0.256836 0.0917969 0.255859 0.0908203 0.233398 0.0908203 0.232422 0.0898438 0.910849

我没有将预测保存到任何“结果”变量中，并且我只在 CLI 中运行预测。]]></description>
      <guid>https://stackoverflow.com/questions/78649611/how-to-add-the-bounding-box-values-to-the-labels-text-files-during-prediction-wi</guid>
      <pubDate>Thu, 20 Jun 2024 21:15:36 GMT</pubDate>
    </item>
    <item>
      <title>所有时期的损失和准确率相同</title>
      <link>https://stackoverflow.com/questions/78645720/same-loss-and-accuracy-for-all-epochs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78645720/same-loss-and-accuracy-for-all-epochs</guid>
      <pubDate>Thu, 20 Jun 2024 06:01:17 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 Huggingface 训练器的学习率？</title>
      <link>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</link>
      <description><![CDATA[我正在使用以下参数训练模型：
Seq2SeqTrainingArguments(
output_dir = &quot;./out&quot;, 
overwrite_output_dir = True,
do_train = True,
do_eval = True,

per_device_train_batch_size = 2, 
gradient_accumulation_steps = 4,
per_device_eval_batch_size = 8, 

learning_rate = 1.25e-5,
warmup_steps = 1,

save_total_limit = 1,

evaluation_strategy = &quot;epoch&quot;,
save_strategy = &quot;epoch&quot;,
logs_strategy = &quot;epoch&quot;, 
num_train_epochs = 5, 

gradient_checkpointing = True,
fp16 = True, 

predict_with_generate = True,
generation_max_length = 225,

report_to = [&quot;tensorboard&quot;],
load_best_model_at_end = True,
metric_for_best_model = &quot;wer&quot;,
greater_is_better = False,
push_to_hub = False,
)

我假设 warmup_steps=1 固定了学习率。
但是，训练结束后，我查看文件 trainer_state.json，发现学习率似乎没有固定。
以下是 learning_rate 和 step 的值：
learning_rate，steps
1.0006 e-05 1033
7.5062 e-06 2066
5.0058 e-06 3099
2.5053 e-06 4132
7.2618 e-09 5165

学习率似乎没有固定在 1.25e-5（步骤 1 之后）。我遗漏了什么？如何修复学习率。]]></description>
      <guid>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</guid>
      <pubDate>Wed, 10 Jan 2024 09:14:26 GMT</pubDate>
    </item>
    </channel>
</rss>