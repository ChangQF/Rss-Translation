<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 28 Nov 2023 21:13:09 GMT</lastBuildDate>
    <item>
      <title>Google Colab 上的 PyCaret：覆盖推断的数据类型不起作用？</title>
      <link>https://stackoverflow.com/questions/77567102/pycaret-on-google-colab-overriding-inferred-data-types-is-not-working</link>
      <description><![CDATA[我正在尝试初始化指定 categorical_features 和 numeric_features 的 setup() 函数，以防止算法自动将我的某些列推断为序数特征。
然而，setup() 函数的输出仍然为我提供了与序数特征相同数量的列。
有谁知道如何成功覆盖这些数据类型？我担心这是我使用 Google Colab 所特有的情况。
代码如下：
来自 pycaret.classification 导入 *
data2pycaret = df.join(df_cat)
#temp = df_cat.drop[列 = &#39;目标&#39;]
cat_list = df_cat.drop(columns = &#39;TARGET&#39;).columns.tolist()
num_list = df.columns.tolist()
打印（猫列表）
打印（数字列表）
s = 设置（data2pycaret，目标 = &#39;目标&#39;，session_id = 125，
          预处理=真，
          特征选择=真，
          修复不平衡=真，
          标准化=真，
          分类特征 = cat_list,
          numeric_features = num_list,
          最大编码ohe = 25）

这是输出：
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/77567102/pycaret-on-google-colab-overriding-inferred-data-types-is-not-working</guid>
      <pubDate>Tue, 28 Nov 2023 20:56:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 PHQ 和 DASS 数据集的机器学习来检测抑郁症的步骤是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77566893/what-would-be-your-steps-for-detecting-depression-using-machine-learning-with-ph</link>
      <description><![CDATA[我有一个项目，其中向我提供了 PHQ 和 DASS 响应作为我的数据集。我对应该如何处理这个问题感到有点困惑。
聊天机器人会向用户询问大约 30 个问题，用户将从 o-3 中给出答案，其中
0 - 根本不适用于我
1 - 在某种程度上或有时适用于我
2 - 在很大程度上或大部分时间适用于我
3 - 非常或大部分时间适用于我
这是不同类别的计算，显示抑郁程度
1-4 最小程度的抑郁
10-14 中度抑郁症
15-19 中重度抑郁症
20-27 严重抑郁症
我所知道的是，问题将是特征，诊断将是目标变量，但我不明白我在 EDA 中做什么，因为每个特征都与目标、变量以及我下一步做什么有关。到目前为止，我所做的就是为目标变量标记热编码，仅此而已。]]></description>
      <guid>https://stackoverflow.com/questions/77566893/what-would-be-your-steps-for-detecting-depression-using-machine-learning-with-ph</guid>
      <pubDate>Tue, 28 Nov 2023 20:10:52 GMT</pubDate>
    </item>
    <item>
      <title>形状错误：TreeExplainer 中的可加性检查失败</title>
      <link>https://stackoverflow.com/questions/77566228/shap-error-additivity-check-failed-in-treeexplainer</link>
      <description><![CDATA[我尝试使用 shap 作为可解释的人工智能并绘制摘要，但它不断给出错误：
ExplainerError：TreeExplainer 中的可加性检查失败！请确保您传递给解释器的数据矩阵与模型训练时的形状相同。如果您的数据形状正确，请在 GitHub 上报告此情况。此检查失败，因为其中一个样本的 SHAP 值总和为 0.732971，而模型输出为 0.706032。如果这种差异可以接受，您可以设置 check_additivity=False 来禁用此检查。

这是我使用的代码：
model = ModelPipeline.named_steps[&#39;clf&#39;]
预处理 = ModelPipeline.named_steps[&#39;预处理&#39;]

x_test_pre = 预处理.transform(x_test)

model.fit(x_test_pre, y_test)

shap_values = shap.TreeExplainer(
    模型，
    数据=x_test_pre，
    model_output=&#39;原始&#39;,
    feature_perturbation=&#39;干预&#39;
).shap_values(x_test_pre)

shap.summary_plot(shap_values, x_test_pre, feature_names=preprocess.get_feature_names_out())

我在此代码中使用的模型是随机森林分类器，它具有不平衡目标数据，其管道如下所示。
ModelPipeline = imPipeline([
            (&#39;预处理&#39;, finTransformer),
            (&#39;采样&#39;,RandomUnderSampler(random_state=48)),
            (&#39;clf&#39;, finModel)
        ]）

我错过了什么步骤吗？
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/77566228/shap-error-additivity-check-failed-in-treeexplainer</guid>
      <pubDate>Tue, 28 Nov 2023 18:12:30 GMT</pubDate>
    </item>
    <item>
      <title>我在代码中找不到解决方案，它总是显示 {"error":"('count', 'None')"}</title>
      <link>https://stackoverflow.com/questions/77566027/i-cant-find-solution-in-my-code-it-always-shows-errorcount-none</link>
      <description><![CDATA[我正在为我的角度前端创建基于内容的算法，但“错误”：“(&#39;count&#39;, None)”当我试图在邮递员或卷曲上测试它时总是显示。我使用了来自supabase的正确的url和密钥，我找不到错误到底在哪里。我将调试器添加到代码中，但当我尝试发送 {“cName” : 邮递员中的“aq”}。 Clinic_tbl 也不为空。这是代码
&lt;前&gt;&lt;代码&gt;
从烧瓶导入烧瓶，jsonify，请求
从supabase导入create_client
将 pandas 导入为 pd
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
从 sklearn.metrics.pairwise 导入 Linear_kernel


应用程序=烧瓶（__名称__）

supabase_url = &#39;url-此处&#39;
supabase_key = &#39;此处为密钥&#39;
supabase = create_client（supabase_url，supabase_key）

def get_recommendations(selected_clinic, df, cosine_sim):

    idx = df[df[&#39;cName&#39;] == selected_clinic].index[0]

    sim_scores = 列表（枚举（cosine_sim[idx]））

    sim_scores = 排序（sim_scores，key=lambda x：x[1]，reverse=True）

    sim_scores = sim_scores[1:6]

    Clinic_indices = [i[0] for i in sim_scores]

    返回 df[&#39;cName&#39;].iloc[clinic_indices].tolist()

@app.route(&#39;/api/recommendations&#39;,methods=[&#39;GET&#39;, &#39;POST&#39;])
def 推荐():
    尝试：
        响应，错误=supabase.from_(&#39;clinic_tbl&#39;).select(&#39;*&#39;).execute()

        如果错误：
            返回 jsonify({&#39;error&#39;: str(error)})

        如果“数据”未响应或未响应[“数据”]：
            return jsonify({&#39;error&#39;: &#39;没有可用的诊所&#39;})

        数据 = {
            &#39;cName&#39;: [],
            &#39;c地址&#39;: [],
            &#39;cNumber&#39;: [],
            &#39;c电子邮件&#39;: [],
            &#39;cVet&#39;: [],
            &#39;cService&#39;：[]，
            &#39;cHealthcare&#39;：[]，
            &#39;cSchedule&#39;: [],
        }

        对于响应[&#39;data&#39;]中的行：
            data[&#39;cName&#39;].append(row.get(&#39;cName&#39;, &#39;&#39;))
            data[&#39;cAddress&#39;].append(row.get(&#39;cAddress&#39;, &#39;&#39;))
            data[&#39;cNumber&#39;].append(row.get(&#39;cNumber&#39;, &#39;&#39;))
            数据[&#39;cEmail&#39;].append(row.get(&#39;cEmail&#39;, &#39;&#39;))
            数据[&#39;cVet&#39;].append(row.get(&#39;cVet&#39;, &#39;&#39;))
            数据[&#39;cService&#39;].append(row.get(&#39;cService&#39;, &#39;&#39;))
            数据[&#39;cHealthcare&#39;].append(row.get(&#39;cHealthcare&#39;, &#39;&#39;))
            数据[&#39;cSchedule&#39;].append(row.get(&#39;cSchedule&#39;, &#39;&#39;))

        df = pd.DataFrame(数据)

        如果 df.empty:
            return jsonify({&#39;error&#39;: &#39;没有可用的诊所&#39;})

        df[&#39;内容&#39;] = df[&#39;cName&#39;] + &#39; &#39; + df[&#39;cAddress&#39;] + &#39; &#39; + df[&#39;cNumber&#39;] + &#39; &#39; + df[&#39;cEmail&#39;] + &#39; &#39; + df[&#39; cVet&#39;] + &#39; &#39; + df[&#39;cService&#39;] + &#39; &#39; + df[&#39;cHealthcare&#39;] + &#39; &#39; + df[&#39;cSchedule&#39;]

        tfidf_vectorizer = TfidfVectorizer(stop_words=&#39;英语&#39;)

        tfidf_matrix = tfidf_vectorizer.fit_transform(df[&#39;内容&#39;])

        cosine_sim = Linear_kernel(tfidf_matrix, tfidf_matrix)

        selected_clinic_name = request.json.get(&#39;clinic_name&#39;, &#39;&#39;)

        推荐 = get_recommendations(selected_clinic_name, df, cosine_sim)

        返回 jsonify({&#39;推荐&#39;: 推荐})

    除了异常 e：
        返回 jsonify({&#39;error&#39;: str(e)})

如果 __name__ == &#39;__main__&#39;:
    应用程序运行（调试=真）


我想解决 {&quot;error&quot;: &quot;(&#39;count&#39;, None)&quot;} 问题
你能找到这段代码的错误吗]]></description>
      <guid>https://stackoverflow.com/questions/77566027/i-cant-find-solution-in-my-code-it-always-shows-errorcount-none</guid>
      <pubDate>Tue, 28 Nov 2023 17:40:06 GMT</pubDate>
    </item>
    <item>
      <title>DqnAgent.train()：损失为 inf 或 nan</title>
      <link>https://stackoverflow.com/questions/77565764/dqnagent-train-loss-is-inf-or-nan</link>
      <description><![CDATA[问题：
我正在尝试按照本教程使用 tf 代理来训练 DQN 代理 在使用我的自定义 PyEnvironment 时，并以某种方式给出以下代码：
对于范围内的 i（num_iterations）：

  # 收集一些步骤并保存到重放缓冲区。
  time_step, _ =collect_driver.run(time_step)
  # 打印（时间步长）

  # 从缓冲区中采样一批数据并更新代理的网络。
  经验，unused_info = next(iterator)
  # 打印（一）
  # 打印（经验）
  train_loss = agent.train(experience) # &lt;-- 此行错误
  训练损失 = 训练损失.损失
  # 打印（训练损失）
  ＃ 休息

  步骤 = agent.train_step_counter.numpy()

  如果步骤 % log_interval == 0:
    print(&#39;step = {0}: loss = {1}&#39;.format(step, train_loss))

  如果步骤 % eval_interval == 0:
    avg_return =compute_avg_return(eval_env, agent.policy, num_eval_episodes)
    print(&#39;step = {0}: 平均回报 = {1}&#39;.format(step, avg_return))
    returns.append(avg_return)
    train_checkpointer.save(global_step)

我总是收到错误
损失为 inf 或 nan ：张量具有 NaN 值
[[{{节点CheckNumerics}}]] [操作：__inference_train_3344]

经过约 2 次火车循环后
我尝试过的：
我研究了这些类似的问题：
https://github.com/tensorflow/agents/issues/589 
Tensorflow NaN 错误？
我尝试了里面提到的大部分方法，但没有一个有效。
我确信我的自定义环境的输出不包含 nan 或 inf 输入。
我尝试大幅降低学习率以达到 1e-12 的效果。
我尝试打印出根据 tf 代理库代码计算出的损失值，但它们隐藏在张量后面，因此找不到太多内容。只发现错误是由DqnAgent中_train()内部的tf.debugging.check_numerics()引发的，检查目标是根据tf_agent计算的Tensor值_loss() 内的 .utils.common.aggregate_losses()
我的代码与上面提到的教程几乎相同，只是我更改了使用的环境并将 fc_layer_params 更改为 (512, 256, 128, 64, 32, 16)。
我可能会错过什么？]]></description>
      <guid>https://stackoverflow.com/questions/77565764/dqnagent-train-loss-is-inf-or-nan</guid>
      <pubDate>Tue, 28 Nov 2023 16:58:36 GMT</pubDate>
    </item>
    <item>
      <title>寻求用于 .mov 视频插值的机器学习/人工智能框架 [关闭]</title>
      <link>https://stackoverflow.com/questions/77565571/seeking-a-machine-learning-ai-framework-for-mov-video-interpolation</link>
      <description><![CDATA[我目前正在开发一个需要对 .mov 视频进行帧插值的项目。目标是在现有帧之间添加额外的“人工”帧，以丰富观看体验，并通过创建更丰富的帧输出来实现详细的慢动作效果。
我正在专门寻找一种 AI/ML 训练系统，该系统可以接受 .mov 视频文件作为输入，执行所需的帧插值，并由于额外的帧而输出“较重”的 .mov 文件。
此外，我对从现有帧进行推断很感兴趣，主要目的是延长视频的长度。我的最终目标是自己开发这些能力。
到目前为止，我发现的唯一工具是将 mp4 文件转换为图像，然后创建低质量的 GIF。这些工具达不到我的目的，主要是因为它们丧失了 .mov 文件提供的高级控制功能，例如独立处理视频层和声音，而不是更紧凑的文件大小。
如果有任何关于 AI/ML 工具或库的建议，我将不胜感激，这些工具或库可以迭代 .mov 文件的每一帧，执行帧插值和外推，并保持 .mov 所特有的对视频和音频层的异步控制格式。
有人知道我可以使用或可能根据我的需求定制这样的工具或库吗？]]></description>
      <guid>https://stackoverflow.com/questions/77565571/seeking-a-machine-learning-ai-framework-for-mov-video-interpolation</guid>
      <pubDate>Tue, 28 Nov 2023 16:28:32 GMT</pubDate>
    </item>
    <item>
      <title>修改 tidytext get_sentiments() 中某些单词的情感</title>
      <link>https://stackoverflow.com/questions/77563423/modifying-the-sentiment-of-certain-words-in-tidytext-get-sentiments</link>
      <description><![CDATA[我正在尝试修改 df 中一些特定单词的情绪，使它们更适合我的上下文，这些单词在我的上下文中使用时带有负面含义，但已被归类为具有积极情绪。这两个字就是“人才”。和“更喜欢”。
这是我的代码：
#加载包
图书馆（dplyr）
库（ggplot2）
需要（读xl）
图书馆（整洁的文本）
需要（writexl）

数据示例：
dput(sentiment_words[1:20,c(7,8,9)])

数据输出：
struction(list(word = c(“天赋”, “更喜欢”, “谎言”, “困难”, “更糟”,
“瘾君子”、“令人讨厌的”、“难以忍受的”、“令人作呕的”、“令人恼火的”、
“奇怪”、“不体贴”、“奇怪”、“压倒性”、“问题”、“投诉”、
“受限”、“爱”、“受限”、“白痴”)、情绪 = c(“积极”、
“阳性”、“阴性”、“阴性”、“阴性”、“阴性”、“阴性”、
“阴性”、“阴性”、“阴性”、“阴性”、“阴性”、“阴性”、
“阴性”、“阴性”、“阴性”、“阴性”、“阳性”、“阴性”、
“负”)，计数＝c(79L，3L，53L，316L，2L，2L，3L，2L，2L，
7L、24L、2L、24L、2L、198L、21L、4L、52L、4L、19L))，类别=c(“grouped_df”，
“tbl_df”、“tbl”、“data.frame”)、row.names = c(NA，-20L)、groups = 结构(列表(
    word = c(“瘾君子”, “抱怨”, “禁闭”, “ftw”, “困难”,
    “白痴”、“不体贴”、“令人恼火”、“问题”、“谎言”、
    “迷失”、“爱”、“讨厌”、“压倒性”、“令人作呕”、
    “难以忍受”、“奇怪”、“更糟”), .rows = Structure(list(
        6L、16L、C(17L、19L)、2L、4L、20L、12L、10L、15L、3L、
        1L、18L、7L、14L、9L、8L、c(11L、13L)、5L)，ptype = 整数(0)，类 = c(“vctrs_list_of”，
    “vctrs_vctr”，“列表”)))，class = c(“tbl_df”，“tbl”，“data.frame”)
), row.names = c(NA, -18L), .drop = TRUE))

 ###### Word 情感分析 ######
## 使用“TIDYTEXT”情感词典
情感词&lt;- df |&gt;
  tidytext::unnest_tokens(输出=“单词”，输入=“帖子”) |&gt;
  dplyr::anti_join(tidytext::stop_words)|&gt;
  dplyr::inner_join(tidytext::get_sentiments(“bing”))

情感词%&gt;%
  计数（单词，排序= TRUE）

# 检查最常见的正面和负面词
情感词&lt;-
情感词 %&gt;% group_by(word) %&gt;% mutate(count = n())
 
bing_word_counts &lt;-情感词 %&gt;%
  dplyr::inner_join(tidytext::get_sentiments(“bing”) %&gt;%
  计数（单词、情感、排序 = TRUE））
]]></description>
      <guid>https://stackoverflow.com/questions/77563423/modifying-the-sentiment-of-certain-words-in-tidytext-get-sentiments</guid>
      <pubDate>Tue, 28 Nov 2023 11:13:39 GMT</pubDate>
    </item>
    <item>
      <title>如何实现基于内容的语音搜索过滤？</title>
      <link>https://stackoverflow.com/questions/77562907/how-to-implement-content-based-filtering-for-voice-search</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77562907/how-to-implement-content-based-filtering-for-voice-search</guid>
      <pubDate>Tue, 28 Nov 2023 10:01:16 GMT</pubDate>
    </item>
    <item>
      <title>用于线性回归的随机梯度下降算法的意外输出</title>
      <link>https://stackoverflow.com/questions/77560377/unexpected-output-with-stochastic-gradient-descent-algorithm-for-linear-regressi</link>
      <description><![CDATA[在为我的 ML 作业实现 SGD 算法时，我得到了意外的输出。
这是我的训练数据的一部分，通常有 320 行：

我的数据集：https://github.com/Jangrae/csv/ blob/master/carseats.csv
我首先做了一些数据预处理：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 StandardScaler
将 numpy 导入为 np

train_data = pd.read_csv(&#39;carseats_train.csv&#39;)
train_data.replace({&#39;是&#39;: 1, &#39;否&#39;: 0}, inplace=True)
onehot_tr = pd.get_dummies(train_data[&#39;ShelveLoc&#39;], dtype=int, prefix_sep=&#39;_&#39;, prefix=&#39;ShelveLoc&#39;)
train_data = train_data.drop(&#39;ShelveLoc&#39;, axis=1)
train_data = train_data.join(onehot_tr)


train_data_Y = train_data.iloc[:, 0]
train_data_X = train_data.drop(&#39;销售额&#39;, axis=1)


然后实现这样的算法：
&lt;前&gt;&lt;代码&gt;学习率 = 0.01
epoch_num = 50
初始w = 0.1
截距 = 0.1
w_matrix = np.ones((12, 1)) * 初始w

对于范围内的 e（epoch_num）：
    对于范围内的 i(len(train_data_X))：

        x_i = train_data_X.iloc[i].to_numpy()
        y_i = train_data_Y.iloc[i]
        
        y_估计 = np.dot(x_i, w_matrix) + 截距
        
        grad_w = x_i.reshape(-1, 1) * (y_i - y_估计)
    
        grad_intercept = (y_i - y_估计)
        
       
        w_matrix = w_matrix - 2 * 学习率 * grad_w
        截距 = 截距 - 2 * 学习率 * 梯度截距
        
        

print(&quot;最终权重：\n&quot;, w_matrix)
print(&quot;最终拦截：&quot;,拦截)

但是输出是
最终权重：
 [[南]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]]
最终截距：[nan]

我用不同的学习率运行它，我也尝试了收敛阈值，但仍然得到相同的结果..我不明白为什么我的代码给了我nans..
有人能看到这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77560377/unexpected-output-with-stochastic-gradient-descent-algorithm-for-linear-regressi</guid>
      <pubDate>Mon, 27 Nov 2023 22:46:46 GMT</pubDate>
    </item>
    <item>
      <title>如何防止过度拟合并获得更高的准确率？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77559565/how-do-i-prevent-overfitting-and-get-a-higher-accuracy</link>
      <description><![CDATA[我正在进行基于方面的情感分析，目前我的模型在拟合时的验证损失和准确性高于训练，但随后它发生翻转，训练表现要好得多。不过，运行 epoch 后，我得到的准确率约为 52%，比我的训练准确率低 10%。这是我的模型：
&lt;前&gt;&lt;代码&gt;vocab_size = 6643
嵌入尺寸 = 300
lstm_单位 = 256

模型=顺序（[
    嵌入（vocab_size，embedding_dim，权重= [embedding_matrix_vocab]，input_length = max_seq_length，可训练= False），
    双向（LSTM（lstm_units，return_sequences = False）），
    辍学（0.1），
    批量归一化(),
    密集（128，激活=&#39;relu&#39;，activity_regularizer=tf.keras.regularizers.L2（0.0001）），
    辍学（0.1），
    批量归一化(),
    密集（128，激活=&#39;relu&#39;，activity_regularizer=tf.keras.regularizers.L2（0.0001）），
    辍学（0.1），
    批量归一化(),
    密集（128，激活=&#39;relu&#39;），
    密集（3，激活=&#39;softmax&#39;）
]）

我正在使用稀疏分类交叉熵。]]></description>
      <guid>https://stackoverflow.com/questions/77559565/how-do-i-prevent-overfitting-and-get-a-higher-accuracy</guid>
      <pubDate>Mon, 27 Nov 2023 19:50:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 BERT 预测推文用户参与度</title>
      <link>https://stackoverflow.com/questions/77555258/predicting-tweet-user-engagement-with-bert</link>
      <description><![CDATA[根据推文内容和发布时间，我可以预测用户参与度。我最初的方法是在推文内容的 BERT 嵌入上使用回归模型。然而，该推文的发布时间也包含有关该推文的有价值的信息。我如何也包括“时间”训练回归模型的信息？]]></description>
      <guid>https://stackoverflow.com/questions/77555258/predicting-tweet-user-engagement-with-bert</guid>
      <pubDate>Mon, 27 Nov 2023 07:50:23 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Hugging Face 转换器进行文本匿名化？</title>
      <link>https://stackoverflow.com/questions/77553670/how-to-do-text-anonymization-using-hugging-face-transformers</link>
      <description><![CDATA[我刚刚遵循了本指南https://medium .com/@luccailliau/text-anonymization-using-hugging-face-transformers-75b5d7392833 但代码不起作用并返回
TypeError：“BatchEncoding”对象不是迭代器

上一个主题中给出的答案不充分，因为匿名功能已被删除。我的最终目标是获得像这样的修改后的文本输出，例如：
“彼得在米兰工作” ---&gt; “PER 在 LOC 中起作用”。

如何解决这个问题？
完整代码在这里：
导入火炬
从转换器导入 AutoTokenizer、AutoModelForTokenClassification
从 Transformers.pipelines.token_classification 导入 TokenClassificationPipeline

model_checkpoint = “Davlan/bert-base-multilingual-cased-ner-hrl”

tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
模型 = AutoModelForTokenClassification.from_pretrained(model_checkpoint)

类 TokenClassificationChunkPipeline(TokenClassificationPipeline):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

def 预处理（自身，句子，offset_mapping=None）：
    model_inputs = self.tokenizer(
        句子，
        return_tensors =“pt”，
        截断=真，
        return_special_tokens_mask=真，
        return_offsets_mapping=真，
        return_overflowing_tokens=True, # 返回多个块
        max_length=self.tokenizer.model_max_length,
        填充=真
    ）
    如果偏移映射：
        model_inputs[“offset_mapping”] = offset_mapping

    model_inputs[“句子”] = 句子

    返回模型输入

def _forward（自身，模型输入）：
    Special_tokens_mask = model_inputs.pop(“special_tokens_mask”)
    offset_mapping = model_inputs.pop(“offset_mapping”, None)
    句子 = model_inputs.pop(“句子”)
    Overflow_to_sample_mapping = model_inputs.pop(“overflow_to_sample_mapping”)

    all_logits = torch.Tensor()
    num_chunks = len(model_inputs[“input_ids”])

    # 一次将一个块传递给模型并连接结果
    对于范围内的 i（num_chunks）：
        model_input = {k: torch.unsqueeze(v[i], dim=0) for k, v in model_inputs.items()}
        logits = 模型(**model_input)[0]
        all_logits = torch.cat((all_logits, logits), dim=1)

    模型输出 = {
        “logits”：all_logits，
        “special_tokens_mask”：special_tokens_mask，
        “offset_mapping”：offset_mapping，
        “句子”：句子，
        “overflow_to_sample_mapping”：overflow_to_sample_mapping，
        **模型_输入，
    }

    # 我们重塑输出以适应后处理输入
    model_outputs[“input_ids”] = torch.reshape(model_outputs[“input_ids”], (1, -1))
    model_outputs[“token_type_ids”] = torch.reshape(model_outputs[“token_type_ids”], (1, -1))
    model_outputs[“attention_mask”] = torch.reshape(model_outputs[“attention_mask”], (1, -1))
    model_outputs[“special_tokens_mask”] = torch.reshape(model_outputs[“special_tokens_mask”], (1, -1))
    model_outputs[“offset_mapping”] = torch.reshape(model_outputs[“offset_mapping”], (1, -1, 2))
    返回模型输出

管道 = TokenClassificationChunkPipeline(model=model, tokenizer=tokenizer,aggregation_strategy=“简单”)

# 替换实体
def 匿名（文本）：
    ents = 管道（文本）
    split_text = 列表（文本）
    对于 ent 中的 ent：
        split_text[ent[&#39;start&#39;]] = f&quot;[{ent[&#39;entity_group&#39;]}]&quot;&quot;
        对于范围内的 i(ent[&#39;start&#39;] + 1, ent[&#39;end&#39;]):
            split_text[i] = &quot;&quot;;

    返回“”.join(split_text)


text =“伯纳德在巴黎的法国巴黎银行工作。”
anonymized_text = 匿名化（文本）
打印（匿名文本）
]]></description>
      <guid>https://stackoverflow.com/questions/77553670/how-to-do-text-anonymization-using-hugging-face-transformers</guid>
      <pubDate>Sun, 26 Nov 2023 22:11:26 GMT</pubDate>
    </item>
    <item>
      <title>X 有 95812 个特征，但 RandomForestClassifier 期望有 178341 个特征作为输入 [重复]</title>
      <link>https://stackoverflow.com/questions/77553577/x-has-95812-features-but-randomforestclassifier-is-expecting-178341-features-as</link>
      <description><![CDATA[我有一个使用文本数据的随机森林模型。但是，当我在新数据（测试集）上尝试该模型时，训练集和测试集之间的特征数量不兼容。另外，测试集上的转换有时会给我带来错误：
sklearn.exceptions.NotFittedError：此 ColumnTransformer 实例尚未安装。在使用此估计器之前，请使用适当的参数调用“fit”。

这是我的代码：
featurizer = ColumnTransformer(
    变压器=[(“矢量化标题”, TfidfVectorizer(), “过滤标题”),
                  (“vectorized_author”,TfidfVectorizer(),“filtered_author”),
                  (“vectorized_abstract”，TfidfVectorizer()，“filtered_abstract”)，
                  (“encoded_publisher”,OneHotEncoder(),[“发布者”]),
                  (“encoded_entrytype”,OneHotEncoder(),[“ENTRYTYPE”]),
                  ],
    余数=&#39;丢弃&#39;）

使用 open(&#39;featurizer.pkl&#39;, &#39;wb&#39;) 作为 featurizer_file：
    pickle.dump（特征器，特征器文件）

X_transformed = featurizer.fit_transform(new_df)

使用 open(&#39;featurizer.pkl&#39;, &#39;rb&#39;) 作为 featurizer_file：
    load_featurizer = pickle.load(featurizer_file)

X_test_transformed = returned_featurizer.transform(test_df)

y_pred = rf_model.predict(X_test_transformed)

我尝试将 transform 部分更改为 fit_transform （我知道这对于测试集来说是不正确的）。两个数据集中的列数和列顺序相同。训练集和测试集的特征名称不同。]]></description>
      <guid>https://stackoverflow.com/questions/77553577/x-has-95812-features-but-randomforestclassifier-is-expecting-178341-features-as</guid>
      <pubDate>Sun, 26 Nov 2023 21:40:37 GMT</pubDate>
    </item>
    <item>
      <title>Fairseq 自定义模型训练错误：使用简单 LSTM 架构运行 fairseq-train 时出现问题</title>
      <link>https://stackoverflow.com/questions/77117619/fairseq-custom-model-training-error-issues-running-fairseq-train-with-simple-ls</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77117619/fairseq-custom-model-training-error-issues-running-fairseq-train-with-simple-ls</guid>
      <pubDate>Sat, 16 Sep 2023 11:41:22 GMT</pubDate>
    </item>
    <item>
      <title>PySpark 上分类输入的随机森林回归</title>
      <link>https://stackoverflow.com/questions/46372562/random-forest-regression-for-categorical-inputs-on-pyspark</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/46372562/random-forest-regression-for-categorical-inputs-on-pyspark</guid>
      <pubDate>Fri, 22 Sep 2017 20:13:02 GMT</pubDate>
    </item>
    </channel>
</rss>