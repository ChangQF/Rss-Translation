<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 19 May 2024 18:17:47 GMT</lastBuildDate>
    <item>
      <title>文本到 Openpose 和奇怪的 RNN 错误</title>
      <link>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</link>
      <description><![CDATA[我想创建一个人工智能，它可以根据文本描述生成 openpose，例如，如果输入“a man running”输出将类似于我提供的图像有没有为我推荐的模型架构？
我的数据状况是

canvas_width：900px
canvas_height：300px
帧数：5（5 人）

预期输出
我尝试训练 RNN 来完成此任务，并使用句子转换器来嵌入文本，然后传递给 RNN，损失如下图所示
from Sentence_transformers import SentenceTransformer
Sentence_model = SentenceTransformer(“all-MiniLM-L6-v2”)
text = “一个男人在奔跑”
text_input = torch.tensor(sentence_model.encode(text), dtype=torch.float)

损失图像，num_layers=3
我的 RNN 设置
&lt;前&gt;&lt;代码&gt;embedding_dim = 384
隐藏暗淡 = 512
层数 = 3
输出暗度 = 180
纪元数 = 100
学习率 = 0.001
rnn_model = RNN(embedding_dim,hidden_​​dim,num_layers,output_dim)

但问题是无论我输入什么，输出每次都是一样的！但是当我尝试将 num_layers 更改为 1 并保持其他设置相同时，如下所示
&lt;前&gt;&lt;代码&gt;embedding_dim = 384
隐藏暗淡 = 512
层数 = 1
输出暗度 = 180
纪元数 = 100
学习率 = 0.001
rnn_model = RNN(embedding_dim,hidden_​​dim,num_layers,output_dim)

损失现在看起来像这样
损失图像 num_layers=1
现在问题消失了！！
我还尝试检查“每次输出都相同”的原因问题我检查了数据加载器和其他代码，但没有发现问题，只有 num_layers=3 导致问题 num_layers=1 修复了它
这是我的训练循环
标准 = nn.MSELoss()
优化器 = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)

trainingEpoch_loss = []
validepoch_loss = []

对于范围内的纪元（num_epochs）：
步骤损失=[]
rnn_model.train()
对于 idx，枚举中的 train_inputs(train_dataloader)：
优化器.zero_grad()
输出 = rnn_model(torch.unsqueeze(train_inputs[&#39;text&#39;], dim=0))
训练损失 = 标准（输出，train_inputs[&#39;poses&#39;]）
Training_loss.backward()
优化器.step()
step_loss.append(training_loss.item())

if (idx+1) % 1 == 0: print (f&#39;Epoch [{epoch+1}/{num_epochs}], 步骤 [{idx+1}/{len(train_dataloader)}], 损失: {training_loss.项目():.4f}&#39;)
TrainingEpoch_loss.append(np.array(step_loss).mean())

rnn_model.eval()
对于 idx，枚举中的 val_inputs(val_dataloader)：
验证步骤损失 = []
输出 = rnn_model(torch.unsqueeze(val_inputs[&#39;text&#39;], dim=0))
val_loss = 标准(输出, val_inputs[&#39;poses&#39;])
validStep_loss.append(val_loss.item())
validationEpoch_loss.append(np.array(validationStep_loss).mean())

这是我的推论
text = “一个男人正在奔跑”
processed_text = torch.tensor(sentence_model.encode(text), dtype=torch.float)
output_poses = rnn_model(processed_text.unsqueeze(0))
print(output_poses.shape) #shape=(1, 180) 1 人是 36 （1 人的原始数据是 54，但我改为 36，因为我只想要 x 和 y 而不是 z，所以剪掉 z 轴）并且有5 人所以 5*36 = 180

我的问题是

除了 RNN 之外，还有适合此任务的任何模型架构推荐吗？
为什么无论我输入什么，每次 num_layers=3 时输出都是相同的，我很困惑，因为如果模型给出相同的输出，损失不会下降，对吗？这意味着它在推理阶段给出相同的输出

预期答案

最适合我的任务的模型架构，任何与我相关的论文或 github 存储库都将受到赞赏
回答为什么当 num_layers=3 时，无论我输入什么，每次输出都是相同的
]]></description>
      <guid>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</guid>
      <pubDate>Sun, 19 May 2024 17:37:20 GMT</pubDate>
    </item>
    <item>
      <title>'无法解析方法'startActivity(Intent)''和'无法解析 MainActivity 上的构造函数'Intent(MainActivity, Class<CombineLettersActivity>)'' [重复]</title>
      <link>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</link>
      <description><![CDATA[我正在按照此播放列表开发手语翻译应用。
我遇到以下错误：
无法解析方法“startActivity(Intent)”
无法解析构造函数“Intent（MainActivity，Class）”
无法解析构造函数“Intent（MainActivity，Class）”
以下是相关代码片段：
&lt;前&gt;&lt;代码&gt;@Override
protected void onCreate(Bundle savingInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    camera_button = findViewById(R.id.camera_button);
    camera_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看v）{
            startActivity(new Intent(MainActivity.this, CameraActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });

    merge_letter_button = findViewById(R.id.combine_letter_button);
    merge_letter_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看视图）{
            startActivity(new Intent(MainActivity.this，CombineLettersActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });
}


我尝试更改 Gradle 和 JDK 版本，但问题仍然存在。与我一起参与该项目的一位朋友也尝试解决该问题，但我们尚未成功。
任何帮助将不胜感激。感谢您的时间和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</guid>
      <pubDate>Sun, 19 May 2024 15:03:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 CoLab 中仅运行部分代码</title>
      <link>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</link>
      <description><![CDATA[我目前正在做一个图像识别项目，模型执行之前的预处理步骤需要相当长的时间。当模型出现错误时，我必须从头开始重新运行所有内容，这是非常耗时的。有没有办法避免从头开始运行整个流程而只执行模型部分？
如果代码没有从头开始执行，则初始部分中的包安装和标签部分将无法正常运行。]]></description>
      <guid>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</guid>
      <pubDate>Sun, 19 May 2024 14:37:50 GMT</pubDate>
    </item>
    <item>
      <title>如何判断我的 Datasat 是否服从高斯分布？</title>
      <link>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</link>
      <description><![CDATA[我正在遵循一些关于进行线性回归的教程，并且在构建笔记本时，我正在研究异常值检测，并且在用于进行异常值检测的技术中，其中之一涉及计算标准偏差，但是对于我需要知道我的列是否属于高斯分布。我知道有不同的技术，例如：
直方图
KDE 图
Q-Q图
科洛莫戈洛夫-斯米尔诺夫检验
夏皮罗-威尔克检验
达戈斯蒂诺和皮尔逊检验
我敢打赌还有更多。那么最好使用哪一种呢？我想直方图只是提供了线索，但并没有显示真正的意图。识别数据集是否为高斯分布的标准做法是什么？例如，我绘制了波士顿数据集和 RM 列的直方图（每间住宅的平均房间数），我发现它是高斯分布：

但是当我使用 shapiro 和 kstest 时，它说 RM 不是高斯！
对于 X.columns 中的 i：
    print(f&#39;{i}: {“非高斯” if shapiro(X[i])[1]&lt;0.05 else “高斯”} {shapiro(X[i])}&#39;)
    print(f&#39;{i}: {“非高斯” if kstest(X[i].values,“范数”)[1]&lt;0.05 else “高斯”} {kstest(X[i].values) ,“标准”)}&#39;)

上面的代码打印：
RM：非高斯 ShapiroResult（统计=0.9608722575483464，pvalue=2.411976537849353e-10）
RM：非高斯 KstestResult（统计=0.9998152774582629，pvalue=0.0，statistic_location=3.561，statistic_sign=-1）

怎么会这样呢？我应该相信什么？]]></description>
      <guid>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</guid>
      <pubDate>Sun, 19 May 2024 14:15:12 GMT</pubDate>
    </item>
    <item>
      <title>如何解决pickle.load()中的内存错误？</title>
      <link>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</link>
      <description><![CDATA[with open(r&#39;..\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
    glove_embedding = pickle.load（fp）

回溯（最近一次调用最后一次）
    [39] 中的单元格，第 2 行
          1 以 open(r&#39;D:\NuVision\Sentiment Analysis\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
    ----&gt; 2 glove_embedding = pickle.load(fp)
    
    内存错误：

glove.pkl 大约有 3 GB，如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</guid>
      <pubDate>Sun, 19 May 2024 13:24:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 的简单 QA 模型中的运行时错误</title>
      <link>https://stackoverflow.com/questions/78501874/runtimeerror-in-a-simple-qa-model-using-transformer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501874/runtimeerror-in-a-simple-qa-model-using-transformer</guid>
      <pubDate>Sun, 19 May 2024 07:28:22 GMT</pubDate>
    </item>
    <item>
      <title>名称特征不匹配 ML</title>
      <link>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</guid>
      <pubDate>Sun, 19 May 2024 05:37:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在训练模型时修复此 KeyError？</title>
      <link>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</guid>
      <pubDate>Sun, 19 May 2024 00:36:44 GMT</pubDate>
    </item>
    <item>
      <title>标准化将 NaN 值插入到我的数据框中</title>
      <link>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</guid>
      <pubDate>Sat, 18 May 2024 23:40:21 GMT</pubDate>
    </item>
    <item>
      <title>GflowNet 无法学习某些奖励</title>
      <link>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</link>
      <description><![CDATA[我尝试将问题简化为以下代码：
# 图表上的转换
转换 = {
    # 0：无操作
    ＃1：N
    ＃2：S
    ＃3：W
    ＃4：E
    1：{0：1、1：2、2：1、3：3、4：1}，
    2：{0：2、1：12、2：1、3：2、4：2}，
    3：{0：3、1：3、2：3、3：4、4：1}，
    4：{0：4、1：5、2：4、3：6、4：3}，
    5: {0: 5, 1: 13, 2: 4, 3: 5, 4: 5},
    6: {0: 6, 1: 6, 2: 6, 3: 7, 4: 4},
    7: {0: 7, 1: 8, 2: 7, 3: 9, 4: 6},
    8: {0: 8, 1: 14, 2: 7, 3: 8, 4: 8},
    9: {0: 9, 1: 9, 2: 9, 3: 10, 4: 7},
    10: {0: 10, 1: 11, 2: 10, 3: 10, 4: 9},
    11: {0: 11, 1: 15, 2: 10, 3: 16, 4: 11},
    12: {0: 12, 1: 18, 2: 2, 3: 12, 4: 12},
    13: {0: 13, 1: 19, 2: 5, 3: 13, 4: 13},
    14: {0: 14, 1: 20, 2: 8, 3: 14, 4: 14},
    15: {0: 15, 1: 21, 2: 11, 3: 17, 4: 15},
    16: {0: 16, 1: 17, 2: 16, 3: 16, 4: 11},
    17: {0: 17, 1: 22, 2: 16, 3: 23, 4: 15},
    18: {0: 18, 1: 18, 2: 12, 3: 25, 4: 18},
    19: {0: 19, 1: 19, 2: 13, 3: 26, 4: 25},
    20: {0: 20, 1: 20, 2: 14, 3: 27, 4: 26},
    21: {0: 21, 1: 21, 2: 15, 3: 22, 4: 27},
    22: {0: 22, 1: 22, 2: 17, 3: 24, 4: 21},
    23: {0: 23, 1: 24, 2: 17, 3: 23, 4: 17},
    24: {0: 24, 1: 22, 2: 23, 3: 24, 4: 22},
    25: {0: 25, 1: 25, 2: 25, 3: 19, 4: 18},
    26: {0: 26, 1: 26, 2: 26, 3: 20, 4: 19},
    27: {0: 27, 1: 27, 2: 27, 3: 21, 4: 20}
}

＃ 模型
类 TBModel(nn.Module):
  def __init__(self, num_hid):
    超级().__init__()

    self.mlp_forward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                     nn.LeakyReLU(),
                                     nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.mlp_backward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                      nn.LeakyReLU(),
                                      nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.logZ = nn.Parameter(torch.ones(1))

  def 前向（自身，x）：
    P_F = self.mlp_forward(x)
    返回P_F
  
  def向后（自身，x）：
    P_B = torch.tensor([(1/INPUT_DIMS)]*INPUT_DIMS)#self.mlp_backward(x)

    返回P_B

# 奖励函数
def奖励_that_model_does_not_learn（轨迹）：
  目标轨迹 = [21, 27, 20, 14, 8]
  奖励=0
  对于范围内的 i(len(轨迹))：
    如果轨迹[i] == goal_trajectory[i]：
      奖励=奖励+1
  返回 torch.tensor(奖励)

def奖励_that_model_learns（轨迹）：
  如果轨迹 == [21, 27, 20, 14, 8]：
    返回 torch.tensor([1])
  返回 torch.tensor([0])


模型 = TBModel(512)
opt = torch.optim.Adam(model.parameters(), 3e-4)

tb_losses = []
tb_奖励 = []
logZs = []
小批量损失= 0
小批量奖励 = 0

对于 tqdm.tqdm 中的剧集（范围（NUM_EPOCHS），ncols = 40）：
  
  gflow_state = torch.zeros(TRAJECTORY_LENGTH)
  状态 = 起始节点
  总计_P_F = 0
  总P_B = 0
  轨迹=[]

  对于范围内的 t（TRAJECTORY_LENGTH）：
    轨迹.append(状态)
    P_F_s = model.forward(gflow_state)
    P_B_s = torch.tensor([(1/5)])

    猫=分类（logits=P_F_s）
    动作 = cat.sample()
    _gflow_state = gflow_state.clone()
    _gflow_state[t] = 操作
    gflow_state = _gflow_state.clone()

    new_state = 转换[状态][action.item()]
    Total_P_F += cat.log_prob(动作)
    Total_P_B += torch.log(P_B_s)

    状态 = 新状态

  奖励=reward_that_model_does_not_learn（轨迹）

  损失 = (model.logZ +total_P_F - torch.log(reward).clip(-20) -total_P_B).pow(2)
  
  minibatch_loss += 损失
  minibatch_reward += 奖励

  if (episode + 1) % BATCH_SIZE == 0:
    wandb.log({
      “损失”：minibatch_loss.item(),
      “奖励”：minibatch_reward.item()/BATCH_SIZE,
      “Z”：model.logZ.item()
    })
    minibatch_loss.backward()
    opt.step()
    opt.zero_grad()
    小批量损失= 0
    小批量奖励 = 0

这是我对 GFlowNet 的实现。我正在使用此模型引导代理通过具有 27 个节点的地图，如转换所述。 GFlowNet 对动作排列进行采样，这些动作将使代理在地图上移动。在轨迹结束时，将为代理计算奖励。该模型能够通过奖励reward_that_model_learns来学习明确的轨迹。然而，代理学习优化由 reward_that_model_does_not_learn 定义的奖励要困难得多。两者之间的唯一区别是，一个得分为全有或全无，而另一种则对轨迹给予部分评分。我不明白为什么该模型可以与一个模型斗争，但可以学习另一个模型，因为在这两种情况下，它都处理相同的状态空间（动作的排列）。如果能够从理论上理解为什么某些奖励更难学习以及如何继续前进，那就太好了，谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</guid>
      <pubDate>Sat, 18 May 2024 21:22:00 GMT</pubDate>
    </item>
    <item>
      <title>感知器的图像识别不起作用</title>
      <link>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</link>
      <description><![CDATA[我必须调整我的图像识别代码，以便它使用感知器来代替分类器进行图像识别。我按照讲师提供的示例执行了所有操作（并且我正在使用他们的感知器代码）。使用分类器，我的图像识别工作完美，没有出错，但是当我用感知器替换这些分类器时，无论我使用什么图像，它总是被识别为第二种类型。
我的图像识别代码：
folder_names=[“First_type”] 、“第二类型”、“第三类型”]
images_in_folder=[25, 25, 25]
标签=[]
学习矩阵 = []

网络=感知器.PerceptronNetwork(6000,1)
label_matrix=[[0],[1],[2]]*25
大小=75,6000
Learning_matrix=np.zeros(大小，dtype=np.float32)

def GaborFilter(image_name):
    k大小 = 31
    西格玛 = 5
    theta_range = np.array([0, np.pi/4, np.pi/2])
    
    频率 = np.array([1.1, 2.1, 3.1, 4.1, 5.1])
    相位=0
    gabor_filter_points = []
    
    原始图像 = cv2.imread(图像名称, cv2.IMREAD_GRAYSCALE)
    调整大小的图像 = cv2.resize(原始图像, (1000, 1000))
    
    step_size_height = resized_image.shape[1] // 20
    step_size_width = resized_image.shape[0] // 20

    对于 theta_range 中的 theta：
        对于频率中的 freq：
            过滤器= cv2.getGaborKernel（（ksize，ksize），西格玛，西塔，频率，相位）
            filtered_image=cv2.filter2D（src=resized_image，d深度=-1，kernel=filter）
            对于范围内的 x（0，resized_image.shape[0]，step_size_width）：
                对于范围内的 y(0, resized_image.shape[1], step_size_height):
                    gabor_filter_points.append(filtered_image[x][y]/255)
    返回 gabor_filter_points

gabor_attributes=[]

对于范围（25）内的 image_nr：
    对于folder_index，枚举中的num_of_images（images_in_folder）：
        文件夹名称 = 文件夹名称[文件夹索引]
        image_path = os.path.join(folder_name, str(image_nr + 1) + &quot;.jpg&quot;)
        gabor_attr_for_image = GaborFilter(图像路径)
        gabor_attributes.append(gabor_attr_for_image)

学习矩阵=gabor_attributes
纪元数=0
对于范围（100）内的纪元：
    总错误数=0
    对于范围 (75) 内的 i：
        error_in_network=network.teachNetwork(learning_matrix[i],label_matrix[i])
        总错误数+=网络中的错误数
    number_of_epochs+=1
    如果总错误数==0：
        休息;

识别矩阵=[]
recognize_matrix=(GaborFilter(“Test.jpg”))
雷兹=[10]
网络.giveNetworkAnswer(recognition_matrix, rez)

如果 rez[0]==0:
    print(&quot;第一种类型&quot;)
elif rez[0]==1:
    print(&quot;第二个管子&quot;)
elif rez[0]==2:
    print(&quot;第三种类型&quot;)
别的：
    print(&quot;错误：&quot;+str(rez[0]))

感知器代码，由我的讲师提供：
### 单独的神经元（感知器）类###
神经元类：
    利亚姆达 = 0.001
    def __init__(this, input_nr):
        this.input_number = input_nr
        this.权重 = []

        对于范围内的 i（this.input_number）：
            this.weights.append(np.random.normal(0, 0.01))
        this.threshold = np.random.normal(0, 0.01)
        
    def 响应（此，输入信号）：
        总和 = 0
        对于范围内的 i（this.input_number）：
            sum += inputSignal[i] * this.weights[i]
        sum -= this.threshold
        如果总和 &gt; 返回 1 0 否则 0
            
    def changeWeights(this, inputSignal, targetResponse):
        实际响应 = this.response(inputSignal)
        错误 = 目标响应 - 实际响应
        
        如果错误！= 0：
            对于范围内的 i（this.input_number）：
                deltaSvoris = this.liambda * inputSignal[i] * 错误
                this.weights[i] += deltaSvoris
            this.threshold += this.liambda * 错误
        返回错误
           
########## 感知器 ANN 类 ############
类感知器网络：
    def __init__(this, 输入_nr, 输出_nr):
        this.input_number = input_nr
        this.neuronNumber = 输出编号
        this.outputLayer = []
        对于范围内的 i(this.neuronNumber)：
            神经元 = 神经元(this.input_number)
            this.outputLayer.append(神经元)

    def示教网络（这个，输入向量，输出向量）：
        错误编号输入输出 = 0
        对于范围内的 i(this.neuronNumber)：
            神经响应 = this.outputLayer[i].response(inputVector)
            如果神经元响应！= 输出向量[i]：
                错误= this.outputLayer [i] .changeWeights（inputVector，outputVector [i]）
                错误编号输入输出+=abs(错误)
        返回错误编号输入输出
    
    def GiveNetworkAnswer(this, inputVector, networkResponse):
        对于范围内的 i(this.neuronNumber)：
            networkResponse[i] = this.outputLayer[i].response(inputVector)
            打印（f“{networkResponse}”）

我尝试更改纪元数，打印出一些值以查看我使用的数据是否存在错误，但没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</guid>
      <pubDate>Sat, 18 May 2024 18:12:53 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中运行不佳 [关闭]</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 python 写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def 预处理图像（图像路径）：
    # 想象中的卡里卡
    img = Image.open(图像路径)
    # 在 scala di grigi 中进行想象和转换
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将 l&#39;immagine 转换为 un array numpy 并将 Ridimensiona 转换为 un unico vettare
    img_array = np.array(img).reshape(1, -1)
    返回img_array
*强调文字*
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;成功模型&quot;)
    # 模型用途
    # Carica e pre-elabora un&#39;immagine
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # Prevedere la classe del nuovo esempio
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

在橙色工作流程中，我使用了逻辑回归，该模型的准确性相当高。在图像嵌入中我使用了 Inception v3。 这是我获取数据集的位置。我认为我预处理图像的方式有问题，也许它与Orange方法不同，但我无法解决问题 这是橙色工作流程的图像。
编辑：我还尝试在输入中提供一个图像文件夹，结果并不总是相同，但在包含 500 张猫和狗照片的文件夹中，模型只能识别 10 只狗（对绝大多数狗进行错误分类）]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    <item>
      <title>为工作推荐系统选择正确的集成方法[关闭]</title>
      <link>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</link>
      <description><![CDATA[我正在开发机器学习职位推荐系统，并且正在考虑使用集成学习方法。我使用的数据集很全面，包括各种属性，例如职位、职位描述、工资、地点和公司详细信息。它包含数字、分类和文本数据的混合。
我计划使用结合多种模型和技术的混合方法来提高其性能：
协作过滤或矩阵分解来捕获用户和职位发布之间的交互。
神经网络用于处理复杂的数据类型，例如职位描述中的文本。
决策树或随机森林具有可解释性以及处理数字和分类数据混合的能力。
我正在寻找关于哪种集成方法最适合此任务的建议。我希望模型能够很好地过滤、灵活地处理数据类型、在训练和时间上具有良好的性能，并提供可解释性。
我还没有开始，但我会考虑尝试任何合理的方法！]]></description>
      <guid>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</guid>
      <pubDate>Fri, 10 May 2024 17:51:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将FastAI分类器集成到sklearn VotingClassifier中？</title>
      <link>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</link>
      <description><![CDATA[我有一堆表格数据，我设法用它们训练了一个 RandomForestClassifier、一个 GradientBoostingClassifier 和一个深度学习模型（来自 fastai 的表格学习器）。我在结果中注意到，每个模型在特定标签上的表现都比其他模型要好，每个模型都不一样。我想知道我是否可以将所有模型放入 VotingClassifier（来自 sklearn 的模型）。我对 RandomForestClassifier 和 GradientBoostingClassifier 没有问题，但我没有找到有关将表格学习器放入 VotingClassifier 中的内容。可以这样做吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</guid>
      <pubDate>Mon, 06 May 2024 07:21:01 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块'numpy.linalg._umath_linalg'没有属性'_ilp64'</title>
      <link>https://stackoverflow.com/questions/77451004/attributeerror-module-numpy-linalg-umath-linalg-has-no-attribute-ilp64</link>
      <description><![CDATA[在 google colab 上运行此代码块。 “导入nltk”导致了这个问题。
错误说明：
/usr/local/lib/python3.10/dist-packages/numpy/testing/_private/utils.py 在  中
     55 IS_PYSTON = hasattr(sys, “pyston_version_info”)
     56 HAS_REFCOUNT = getattr(sys, &#39;getrefcount&#39;, None) 不是 None 也不是 IS_PYSTON
---&gt; 57 HAS_LAPACK64 = numpy.linalg._umath_linalg._ilp64
     58
     59 _OLD_PROMOTION = lambda: np._get_promotion_state() == &#39;旧版&#39;

**属性错误：模块“numpy.linalg._umath_linalg”没有属性“_ilp64”**

导入系统
将 numpy 导入为 np
#!pip uninstall -y numpy
#!pip 安装 numpy
!pip 安装安装工具
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
进口警告
导入 csv
导入 urllib.parse 作为解析
进口泡菜
!pip卸载-y nltk
!pip 安装 nltk
导入nltk
nltk.download(&#39;punkt&#39;)
从 nltk.tokenize 导入 word_tokenize
从 urllib.parse 导入取消引用

如何纠正同样的问题？
我尝试卸载并重新安装 numpy 和 nltk。我也尝试升级它们，但同样的错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/77451004/attributeerror-module-numpy-linalg-umath-linalg-has-no-attribute-ilp64</guid>
      <pubDate>Thu, 09 Nov 2023 06:45:03 GMT</pubDate>
    </item>
    </channel>
</rss>