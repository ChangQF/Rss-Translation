<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sat, 15 Feb 2025 01:15:23 GMT</lastBuildDate>
    <item>
      <title>随着神经网络的训练，权重方差如何变化？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79440406/how-does-the-variance-of-weights-change-as-the-neural-network-is-trained</link>
      <description><![CDATA[变化在不同的ANN体系结构中会有所不同吗？
当我培训MLP网络时，我发现训练后的权重比训练之前大。标准偏差的增加是典型发生的吗？]]></description>
      <guid>https://stackoverflow.com/questions/79440406/how-does-the-variance-of-weights-change-as-the-neural-network-is-trained</guid>
      <pubDate>Fri, 14 Feb 2025 19:31:29 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降的theta值不连贯</title>
      <link>https://stackoverflow.com/questions/79440021/theta-values-for-gradient-descent-not-coherent</link>
      <description><![CDATA[我制作了梯度下降代码，但似乎效果很好
 导入numpy作为NP
从随机导入兰特，随机
导入matplotlib。 pyplot作为plt


def calculh（theta，x）：
    h = 0
    h+= theta [0]*x＃w*x
    h += theta [-1]＃ +b
    返回h


Def Calculy（Sigma，h）：
    返回Sigma（H）＃Sigma Peut-Etre Tanh，Signoide等。


Def Erreurj（Sigma Theta）：
    somme = 0
    somme = 1/4*（sigma（theta [1]）** 2+sigma（theta [0]+theta [1]）** 2）
    返回索姆


def梯度（x，y，ysol，sigmaprime，h）：
    返回（（y-ysol）*sigmaprime（h）*x，（y-ysol）*sigmaprime（h）*1）
def Grad（theta）：
    w，b = theta [0]，theta [1]
    #print（theta）
    返回[2*b ** 3+3*b ** 2*w+3*b*w ** 2-2*b+w ** 3-w，b ** 3+3*b ** 2* W+3*B*W ** 2-B+W ** 3-W]
＃ *X对应A 0 OU 1：NOS 2Entrées; *1对应A de b

Def Pasfixe（Theta，Eta，Epsilon，X，Y，YSOL，Sigma，Sigmaprime，H）：
    n = 0
    而np.linalg.norm（渐变（x，y，ysol，sigmaprime，h））＆gt; Epsilon和N＆lt; 10000：
        对于我的范围（len（theta））：
            theta [i] = theta [i]  -  eta*渐变（x，y，ysol，sigmaprime，h）[i]
            h = calculh（theta，x）
            Y = Calculy（Sigma，h）
            n+= 1
            如果theta [i]＆gt; 100：### cas de Divergence
                返回[100,100]，y
    返回Theta，Y

Sigma = Lambda Z：Z ** 2-1
sigmaprime = lambda z：2*z
ETA = 0.1

x = 1
ysol = 0
Listey = []
ListEtheta = []
lst = [[3*random（）*（ -  1）** randint（0,1），3*random（）*（ -  1）** randint（0,1）]在范围内（5000）]
NB = 0
因为我在LST：
        NB+= 1
        如果NB％50 == 0：
            打印（NB）
        theta = i [：]
        h = calculh（theta，x）
        Y = Calculy（Sigma，h）
        calcultheta = pasfixe（theta，eta，10 ** -4，x，y，ysol，sigma，sigmaprime，h）
        listetheta.append（calcultheta [0]）
        listey.append（calcultheta [1]）


对于我的范围（Len（Listey））：
          Listey [i] = round（Listey [i]，2）
打印（Listey）

对于我的范围（Len（ListEtheta））：
      对于J范围（2）的J：
          listetheta [i] [j] = round（listetheta [i] [j]，2）
打印（ListEtheta）

对于我的范围（LEN（LST））：
    如果[[-2,1]]中的[int（listetheta [i] [0]），int（listetheta [i] [1]）]：
        plt.plot（lst [i] [0]，lst [i] [1]
    elif [int（listEtheta [i] [0]），int（listetheta [i] [1]）在[[[2，-1]]中：
        plt.plot（lst [i] [0]，lst [i] [1]
    elif [int（listEtheta [i] [0]），int（listetheta [i] [1]）在[[[0，-1]]中：
        plt.plot（lst [i] [0]，lst [i] [1]
    elif [int（listEtheta [i] [0]），int（listEtheta [i] [1]）在[[[0,1]]中：
        plt.plot（lst [i] [0]，lst [i] [1]
    elif int（listetheta [i] [0]）** 2 +int（listEtheta [i] [1]）** 2＆gt; = 10：
        plt.plot（lst [i] [0]，lst [i] [1]

plt.show（）
 
最后，i做一个具有偏差和权重值的图形，每个点在循环开始时给出的theta（重量，偏置）值的功能都呈上色。
我应该具有 的图形
我试图自己计算梯度，但也没有起作用。我应该得到这样的图]]></description>
      <guid>https://stackoverflow.com/questions/79440021/theta-values-for-gradient-descent-not-coherent</guid>
      <pubDate>Fri, 14 Feb 2025 16:41:23 GMT</pubDate>
    </item>
    <item>
      <title>将数据分类为多个独立类的最佳策略[封闭]</title>
      <link>https://stackoverflow.com/questions/79439543/optimal-strategy-for-classification-data-into-multiple-independent-set-of-classe</link>
      <description><![CDATA[需要分类的数据属于两个独立的类。为简单起见，让我们想象一个可以具有 Shape&gt; Shape 和 color 的项目。形状可以是 square ， circle  三角形，而颜色可以是 red ，绿色或蓝色。每个项目都完全属于这两组类之一（即一个可以具有蓝色三角形）。
问题是，通过机器学习对此类数据进行分类的最佳策略是什么。到目前为止，我可以看到三种方法：

  两个独立的神经网络 
这很简单。一个网络将对形状进行分类，而另一个网络为颜色。但是，这看起来有些效率。

  多类分类 
在这里，网络的输出将是矩阵3x3（形状次数的颜色数），作为所有可能组合的产物。 （单个）结果将确定特定类别作为对这两个正交碱基的投影。这里的问题是，必须拥有非独立的NXM输出类，因此问题不必要。

  多标签分类 
在这里，输出将是向量3+3，并且将允许网络选择多个输出。虽然问题的维度现在要低得多，但通过允许模型选择多种形状和/或多种颜色，我们使模型可以预测无法发生的情况。


因此，问题仍然存在，在这种情况下的最佳策略是什么？是否有一些对这种问题最佳的混合范式？]]></description>
      <guid>https://stackoverflow.com/questions/79439543/optimal-strategy-for-classification-data-into-multiple-independent-set-of-classe</guid>
      <pubDate>Fri, 14 Feb 2025 13:33:46 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同的数据范围内训练Sklearn模型？</title>
      <link>https://stackoverflow.com/questions/79439462/how-to-train-sklearn-model-in-different-dataframes</link>
      <description><![CDATA[我有一个用“ knn”制作的ML模型在Scikit-Learn中，注意到我的数据越多，我的模型就会越准确地说服它的预测。问题是，我有很多数据框架显示了我想预测的同一系统的不同情况。是否可以在那些不同的数据范围内训练模型？因为如果我致电.fit（），则将重置它是以前的培训。
  x_cleaned = x.dropna（）
y_cleaned = y [x_cleaned.index]
x_training，x_test，y_training，y_test = train_test_split（x_cleaned，y__cleaned，test_size = 0.15，Random_State = 0）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79439462/how-to-train-sklearn-model-in-different-dataframes</guid>
      <pubDate>Fri, 14 Feb 2025 13:01:45 GMT</pubDate>
    </item>
    <item>
      <title>python中的AI-添加更多的时间段使我的模型“失败”</title>
      <link>https://stackoverflow.com/questions/79438720/ai-in-python-adding-more-timesteps-makes-my-model-fail</link>
      <description><![CDATA[    
嗨！我刚刚在Python中使用Pygame制作了我的第一个模型。该游戏大约是一个球的最高平台。 
我设法使模型学习如何到达那里。但是到达第三个平台后，它掉下来并留在地面上。我想训练一个可以解决这个问题的新模型，但令我惊讶的是，将总计timesteps增加到500_000完全失败了测试 - 球只是一个地方跳跃，而型号却少得多-150_000到达最高的平台！
为什么是？
不应该更多地汇聚更多地融入到最高平台上而不是掉落的时间？？
这是我的呼叫功能
 @Edit
我认为有时该模型即使时间段〜= 15_000都学会了如何到达那里。
可能是因为纯粹的运气 +熵吗？
如果是这样，我可以为球实施哪些超参数/更好的奖励系统？
这是我的奖励功能：
 奖励= -1＃默认奖励
         
    ＃向目标平台迈进的奖励
    dist_reward = int（（1/self.goal_distance） * 10000）
    奖励 += dist_reward

         ＃空降的奖励
    如果self.y_acc！= 0和self.ball.player_pos.y＆lt;地面_y：
         奖励 += 10

         ＃向右移动/向左移动的奖励
    如果self.x_velocity！= 0：
        奖励 += 1

    如果（collision_plat0不是一个
        ＃击中地板的否定奖励
        奖励 -  = 50
    如果（collision_plat1不是一个
        ＃到达第一个平台的奖励
        奖励 += 2
    elif（collision_plat2不是一个
        ＃到达第二个平台的奖励
        奖励 += 3
    elif（collision_plat3不是一个
        ＃到达第三个平台的奖励
        奖励 += 30000000
 
有我的移动代码是否可以有用：
 如果动作不是没有：
    ＃处理运动
    如果动作== 0：＃向左移动
        self.ball.player_pos.x- = 5
        self.x_velocity = -5
        #reward = 0.001
    Elif Action == 1：＃向右移动
        self.ball.player_pos.x += 5
        self.x_velocity = 5
        #reward = 0.001

collision_top = false
对于我，枚举中的平台（self.platforms）：
    collision = check_collision_ball_rect（self.ball，平台）
    如果发生碰撞：
        如果碰撞[top＆quot&#39;]：
            collision_top = true
            self.y_acc = 0
            如果动作== 2：
                self.y_acc = 20
            别的：
                self.ball.player_pos.y = platform.top- self.ball.radius
        如果碰撞[底部；]：
            self.ball.player_pos.y = platform.bottom + self.ball.radius
        如果碰撞[＆quot&#39;＆quot;]和动作== 1：
            self.ball.player_pos.x = platform.left- self.ball.radius
            self.x_velocity = 0
        如果Collision [＆quot&#39;right＆quot＆quot == 0：
            self.ball.player_pos.x = platform.right + self.ball.radius
            self.x_velocity = 0

如果self.y_acc＆gt; 0或不collision_top：
    self.y_acc- = 1

＃应用重力
self.ball.player_pos.y +=重力 -  self.y_acc
 
我基本上移动球5 px/框架右或左 +它可以加速加速使用重力（我还检查与矩形的碰撞）。]]></description>
      <guid>https://stackoverflow.com/questions/79438720/ai-in-python-adding-more-timesteps-makes-my-model-fail</guid>
      <pubDate>Fri, 14 Feb 2025 08:12:23 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow的性能问题</title>
      <link>https://stackoverflow.com/questions/79437180/tensorflow-perfomance-issue</link>
      <description><![CDATA[我正在尝试在TensorFlow上进行非常原始的增强学习模型。尽管它相对较小，但单个迭代需要约6-7秒。
  def build_model（）：
    模型= keras。
        层。输入（shape =（400，）），
        layers.dense（128，激活=; relu; quot;），，
        layers.dense（128，激活=; relu; quot;），，
        层。密度（3）
    ）））
    model.compile（优化器= keras.optimizers.adam（Learning_rate = 0.001），Loss =＆quot; quot;
    返回模型

dqnagent类：
    def __init __（自我）：
        self.model = build_model（）
        self.target_model = build_model（）
        self.target_model.set_weights（self.model.get_weights（））

        self.memory = Deque（Maxlen = 1000）
        self.epsilon = 1.0
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.gamma = 0.95
        self.batch_size = 32

    def select_action（self，state）：
        如果np.random.rand（）＆lt; self.epsilon：
            返回随机选择（[0，1，2]）
        q_values = self.model.model.predict（np.array（[state]），详细= 0）
        返回np.argmax（q_values [0]）

    def记住（自我，状态，行动，奖励，next_state，完成）：
        self.memory.append（（（状态，行动，奖励，next_state，Done完成）））

    def火车（自我）：
        如果Len（self.memory）＆lt; self.batch_size：
            返回
        batch =随机。样本（self.memory，self.batch_size）
        状态，目标= []，[]

        对于状态，行动，奖励，next_state，在批处理中完成：
            目标=奖励
            如果没有完成：
                target += self.gamma * np.max（self.target_model.predict（np.array（[[next_state]）），verbose = 0））

            q_values = self.model.model.predict（np.array（[state]），详细= 0）
            q_values [0] [action] =目标

            states.append（状态）
            targets.append（q_values [0]）

        self.model.fit（np.Array（states），np.Array（targets），Epochs = 1，冗长= 0）

        如果self.epsilon＆gt; self.epsilon_min：
            self.epsilon *= self.epsilon_decay

    def Update_target_model（self）：
        self.target_model.set_weights（self.model.get_weights（））
 
分析了所有给定代码后，我看到 model.predict（）花费了很多时间来完成：
 profiler result   
最初，我以为我只需要在GPU上计算，但是两天后尝试这样做，没有真正改变。
真的花了很多时间，还是我在代码中搞砸了？
  gpu：geforce 2060，
CPU：Intel Core i7， 
Windows 11，
Python：3.10
TensorFlow：2.10
 ]]></description>
      <guid>https://stackoverflow.com/questions/79437180/tensorflow-perfomance-issue</guid>
      <pubDate>Thu, 13 Feb 2025 17:07:09 GMT</pubDate>
    </item>
    <item>
      <title>Tweedie回归：功率> = 2'“ Y的某些值超出了损失的有效范围”，但Y值不是</title>
      <link>https://stackoverflow.com/questions/79437039/tweedie-regression-power-2-some-values-of-y-are-out-of-the-valid-range-o</link>
      <description><![CDATA[我正在运行Tweedie回归，对于Powers＆gt; = 2，我遇到了一个错误，告诉我我的y值超出了半weedeieloss的范围。我了解Y损失的有效范围为0。  我所有的y值都是＆gt; 0 and＆lt; 1，但我仍然会遇到这个错误。我不知道为什么。
 Sklearn版本1.3.0 
 i消除了所有行，并用y＆lt; = 0的值和double检查了一个描述。我期望回归器合适，并给我一个更好的理由，尤其是因为我的y值都大于0。我知道伽玛不是我的数据的出色分配，但我希望尝试尝试power = 3（逆高斯），这也是不可能的。
 power = 0和1都可以正常工作（正常和泊松）。
这是我培训y数据的描述（ cv_y ）：
 计数|   616420.000000  
平均|        0.955883  
std |        0.021402  
最小|        0.700465  
25％|        0.937018  
50％|        0.954769  
75％|        0.975716  
最大|        0.990000  
 
这是我的代码的重要元素
  glr = tweedieregressor（）＃广义线性回归模型
x_pipeline = pipeline（[（（＆quot; preprocessor&#39;&#39;，x_transformer），（&#39;Model; quode; glr）]）
esteNator = transformedTargetRegressor（recressor = x_pipeline，变压器= y_transformer）
家庭=“ Tweedie”
链接=“自动”
n_splits = 5
tscv = timeseriessplit（gap = 20，n_splits = n_splits）

param_grid = {
        &#39;recressor__preprocessor__x_pca__whiten&#39;：[true，false]，
        “回归器__model__power”：[0,1,2]，，
        &#39;Recressor__model__alpha&#39;：[0.5]，，，
        &#39;recressor__model__fit_intercept&#39;：[true]，
        “回归器__model__link”：[link]，，，
        &#39;Recressor__model__solver&#39;：[&#39;Newton-Cholesky&#39;]，
        &#39;Recressor__model__max_iter&#39;：[5,10]，，
        &#39;Recressor__model__tol&#39;：[1E-5]，，
        “回归器__model__verbose”：[1]
}

GS = GridSearchCV（
            估算器=估算器，
            param_grid = param_grid，
            得分=得分，
            n_jobs = -1，
            refit = reutit_strategy，
            CV = TSCV，
            详细= 3，
            pre_dispatch = 10，
            ERROR_SCORE =&#39;RAIND&#39;
）

型号= gs.fit（cv_x，cv_y）



 ]]></description>
      <guid>https://stackoverflow.com/questions/79437039/tweedie-regression-power-2-some-values-of-y-are-out-of-the-valid-range-o</guid>
      <pubDate>Thu, 13 Feb 2025 16:29:26 GMT</pubDate>
    </item>
    <item>
      <title>保存到磁盘中的磁盘时会遇到Unicode错误</title>
      <link>https://stackoverflow.com/questions/79436672/getting-unicode-error-while-saving-to-disk-in-distiset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79436672/getting-unicode-error-while-saving-to-disk-in-distiset</guid>
      <pubDate>Thu, 13 Feb 2025 15:04:10 GMT</pubDate>
    </item>
    <item>
      <title>Yolov9e-Seg在6 A100-80G上进行培训，并试图尽可能优化，但是在验证阶段之后，CUDA出现了失误错误</title>
      <link>https://stackoverflow.com/questions/79436107/yolov9e-seg-training-on-6-a100-80g-and-tried-to-optimize-as-much-as-i-could-but</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79436107/yolov9e-seg-training-on-6-a100-80g-and-tried-to-optimize-as-much-as-i-could-but</guid>
      <pubDate>Thu, 13 Feb 2025 12:12:17 GMT</pubDate>
    </item>
    <item>
      <title>ValueRror：X具有7个功能，但ColumnTransFormer期望13个功能</title>
      <link>https://stackoverflow.com/questions/79434756/valueerror-x-has-7-features-but-columntransformer-expects-13-features</link>
      <description><![CDATA[我有以下代码，我尝试预测使用泊松回归的工具价格。
 ＃---加载并准备数据---
y =火车[&#39;priceToday&#39;]
x = train.drop（columns = [&#39;pricetoday&#39;]）

＃定义非标准类型
non_standard_types = [&#39;nar;

＃为非标准创建标志功能
x [&#39;non_standard_flag;]

＃确定数值和分类列
num_features = [&#39;age&#39;&#39;&#39;
cat_features = [&#39;country; country; quot&#39;final_trans;]

＃定义预处理管道
预处理器= columntransformer（
    变形金刚= [
        （&#39;num&#39;，StandardScaler（），num_features），
        （&#39;cat&#39;，onehotencoder（handle_unknown =&#39;ignore&#39;），cat_features）
    ]，剩余=; drop; quot;
）

＃---火车/测试拆分---
＃创建一个重量列
train [sample_weight; quight&#39;&#39;] = train [type; type_ls; quot;]。应用（lambda x：1如果x == x ==;

火车[stratify_group&#39;&#39;]
x_train，x_val，y_train，y_val，train_weights，val_weights = train_test_split（
    x，y，train [sample_weight&#39;]，test_size = 0.2，andural_state = 42，stratefify = train [＆quot; stratify_group＆quort＆quort;
）
＃将预处理器安装在培训数据上一次
x_train_preprocessed = preprocessor.fit_transform（x_train）
x_val_preprocessed = preprocessor.transform（x_val）

＃定义模型
模型= {
    ＆quot“ poisson”：poissonRegressor（alpha = 0.01）
}

＃火车和评估模型
model_results = {}

对于model_name，model.items（）中的型号：
    model.fit（x_train_preprocessed，y_train，sample_weight = train_weights）

    ＃预测
    预测= model.predict（x_val_preprocessed）
    ＃计算指标
    r2 = r2_score（y_val，预测）

    model_results [model_name] = {
        “型号”：模型，
        ＆quot“ R2”：R2
    }
 
我有一个测试数据，我想将其价格与模型的预测价格进行比较。
我的测试数据是这样的：
 ＃确保新数据具有正确的格式
new_data = pd.dataframe（{{
    ＆quot;：：[12，24，36，48，60，72，84，12，24，36，48，60，60，72，84]，
    ＆quot”小时：[500，1000，1500，2000，2500，3000，3500，3500，500，1000，1500，2000，2500，2500，3000，3500]，
    ＆quot“ brand;
    ＆quot&#39;power＆quot; [150] * 7 + [80] * 7，
    ＆quot“ final_trans＆quot”：[＆quot; cv; quot&#39;] * 14，，
    ＆quot“ country”：[deu＆quot;] * 14，，
    &#39;type_ls＆quot;：[NAR，NAR，NAR，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST] 
    ＆quot&#39;current_pred＆quot;：[105614，96681，88504，81018，74165，67892，62150，42608，39728，37043，37043，34540，32206，32206，30029，28000]
}））
 
我的代码是：
  new_df = pd.dataframe（new_data）
＃创建&#39;non_standard_flag&#39;
new_df [&#39;non_standard_flag;] = new_df [type; type_ls; quot;]。isin（non_standard_types）.astype（int）

＃选择预处理器所需的列
x_new = new_df [[&#39;age&#39;，&#39;power&#39;，&#39;小时&#39;，&#39;non_standard_flag&#39;，&#39;brand&#39;，&#39;country&#39;，&#39;final_trans&#39;]]]

x_new_preprocessed = preprocessor.transform（x_new） 

＃从培训数据中进行单次编码后获取列名
ohe = preprocessor.named_transformers _ [&#39;cat&#39;]
encoded_cat_columns = ohe.get_feature_names_out（cat_features）

＃创建数字功能的列名称
num_columns = num_features

＃组合列名称
all_columns = num_columns + list（encoded_cat_columns）

＃从预处理数据中创建数据框
x_new_preprocessed_df = pd.dataframe（x_new_preprocessed，columns = all_columns）

＃---用泊松模型预测---
poisson_model = model_results [＆quot; poisson; quot; quote; quode;]＃访问训练有素的泊松模型
predicted_prices = poisson_model.predict（x_new_preprocessed_df）

＃比较和存储结果---
new_df [&#39;prediction_price&#39;] = predicted_prices

＃计算预测和当前价格之间的差异
new_df [&#39;Price_difference&#39;] = new_df [&#39;Predicted_price&#39;]  -  new_df [&#39;current_pred&#39;]
 
但是，在这样做之后，我会出现错误：
  X具有7个功能，但是ColumnTransFormer期望13个功能
 
我有相同数量的列，所以我不明白为什么我有这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/79434756/valueerror-x-has-7-features-but-columntransformer-expects-13-features</guid>
      <pubDate>Wed, 12 Feb 2025 23:51:03 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“ RuntimeRorr：张量A（64）的大小必须匹配非辛格尔顿尺寸1”的张量B（6）？</title>
      <link>https://stackoverflow.com/questions/79429107/how-can-i-resolve-runtimeerror-the-size-of-tensor-a-64-must-match-the-size-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79429107/how-can-i-resolve-runtimeerror-the-size-of-tensor-a-64-must-match-the-size-o</guid>
      <pubDate>Tue, 11 Feb 2025 06:48:18 GMT</pubDate>
    </item>
    <item>
      <title>从简历中的R平方比XGBoost中的CV高[关闭]</title>
      <link>https://stackoverflow.com/questions/79320673/r-squared-from-cv-is-way-higher-than-without-cv-in-xgboost</link>
      <description><![CDATA[我有XGBoost模型的此代码：
  temp_dataset_pos = dataset_vehicle_pos.copy（）
＃temp_dataset_pos = temp_dataset_pos.drop（[&#39;sum_passenger&#39;]，axis = 1）
＃temp_dataset_pos = temp_dataset_pos [[&#39;湿度&#39;，&#39;温度&#39;，&#39;warter_avg_speed_pos&#39;]]]

x_pos = temp_dataset_pos.drop（&#39;warter_avg_speed_pos&#39;，axis = 1）
y_pos = temp_dataset_pos [&#39;warter_avg_speed_pos&#39;]

＃将数据分为火车和测试集
x_train，x_test，y_train，y_test = train_test_split（x_pos，y_pos，test_size = 0.20，andury_state = 42）

＃创建XGBoost模型
xgboost_model = xgb.xgbregressor（objective =&#39;reg：squaredError&#39;，andury_state = 42）＃您可以调整HyperParameters

＃适合模型
xgboost_model.fit（x_train，y_train）
＃确保预测的数据与测试集对齐
x_test [&#39;warter_count_pos&#39;] = prediction_vehicle_count_pos [&#39;predicted_vehicle_count_pos&#39;]

＃对测试集进行预测
y_pred_xgboost = xgboost_model.predict（x_test）

＃将预测的值舍入整数
y_pred_rounded = y_pred_xgboost.Round（）。astype（int）

＃评估模型
mse_xgboost = mean_squared_error（y_test，y_pred_rounded）
打印（f&#39;mean Squared错误（XGBOOST）：{MSE_XGBOOST}&#39;）
r2_xgboost = r2_score（y_test，y_pred_rounded）
打印（&#39;r平方值：&#39;，r2_xgboost）
重要性= xgboost_model.feature_importances_


＃创建XGBoost模型
xgboost_model = xgb.xgbregressor（objective =&#39;reg：squaredError&#39;，andury_state = 42）＃您可以调整HyperParameters

＃定义k折的交叉验证器
kf = kfold（n_splits = 5，shuffle = true，andury_state = 42）

＃根据平方误差定义得分手
mse_scorer = make_scorer（mean_squared_error，greate_is_better = false）

＃执行交叉验证并计算MSE
mse_scores = cross_val_score（xgboost_model，x_pos，y_pos，评分= mse_scorer，cv = kf）

＃将MSE分数转换为正； cross_val_score返回&#39;greate_is_better = false的负值&#39;
MSE_SCORES = -MSE_SCORES

＃计算MSE的平均值和标准偏差
MANE_MSE = np.Mean（MSE_SCORES）
std_mse = NP.STD（MSE_SCORES）

print（f&#39;mean MSE来自CV：{mean_mse}&#39;）
print（cv：{std_mse} \ n&#39;）

＃如果您还想在结果摘要中包含R平方
r2_scorer =&#39;r2&#39;
r2_scores = cross_val_score（xgboost_model，x_pos，y_pos，评分= r2_scorer，cv = kf）

平均_r2 = np.mean（r2_scores）
std_r2 = np.std（r2_scores）

print（f&#39;mean r平方从CV：{mean_r2}&#39;）
print（f&#39;std r平方从cv：{std_r2}&#39;）
打印（&#39;\ n&#39;）
 
我得到了这些结果：
平均误差（XGBoost）：395.3362869635255 
 R平方值：0.37072522417952525  
 CV的平均MSE：6.902625450153782 
CV的STD MSE：0.8885273860917627 
平均R平方从CV：0.990070278719086 &lt; /strong&gt; 
CV的STD R平方：0.000623638887270274 
 R平方如何在有或没有简历的情况下如此不同？
我是否缺少代码中的东西？]]></description>
      <guid>https://stackoverflow.com/questions/79320673/r-squared-from-cv-is-way-higher-than-without-cv-in-xgboost</guid>
      <pubDate>Tue, 31 Dec 2024 19:21:35 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost/ LightGBM中多级分类中的自定义标签</title>
      <link>https://stackoverflow.com/questions/79309001/custom-labelling-in-multi-class-classification-in-xgboost-lightgbm</link>
      <description><![CDATA[我有以下数据框1,2,3,4在不同类别（ class_id ），我想使用这些功能来预测谁将毕业他们的同类顶部（ top ）&lt; /p&gt;
  class_id iq_1 IQ_2 IQ_3 IQ_3 IQ_4小时_1小时_2小时_3小时_4 score_1 score_2 score_3 score_4 pot_4
1 101 99 130 100 10 19 3 12 98 80 95 88 3     
2 93 103 112 200 5 9 12 10 50 88 99 100 1
3 100 102 101 102 12 13 17 9 84 88 89 98 4
 
为此，我使用XGBoost库中的多类分类（其中类是 1,2,3,4 ）。但是，由于该人最终在课堂上排名第二，但是在训练中，他/她无论如何都会获得0，因此更好的训练计划是奖励最高得分的顶级人士，而第二个人则是得分像底部的人一样给它0。因此，我想在XGBoost中问，无论如何是否可以进行自定义标签，例如：
  class_id iq_1 IQ_2 IQ_3 IQ_3 IQ_4小时_1小时_2小时_3小时_4 score_1 score_2 score_2 score_3 scust_4 Student_1 Student_2 Student_3 Student_3 Student_4
1 101 99 130 100 10 19 3 12 98 80 95 88 0 0.3 0.7 0 0
2 93 103 112 200 5 9 12 10 50 88 99 100 0.7 0 0.3 0
3 100 102 101 102 12 13 17 9 84 88 89 98 0 0.3 0 0.7
 
即。我们奖励班级0.7的顶部和第0.3类（ [0，0.3，0.7，0] 的第二类，而不是 [0,0,1， 0] 在原始标签中？）
如果Xgboost没有这种自定义标签，我们可以在类似的包装中这样做吗？？]]></description>
      <guid>https://stackoverflow.com/questions/79309001/custom-labelling-in-multi-class-classification-in-xgboost-lightgbm</guid>
      <pubDate>Thu, 26 Dec 2024 08:18:15 GMT</pubDate>
    </item>
    <item>
      <title>在CIFAR-10上的Keras中实施Alexnet的准确性差</title>
      <link>https://stackoverflow.com/questions/51403712/implementation-of-alexnet-in-keras-on-cifar-10-gives-poor-accuracy</link>
      <description><![CDATA[我尝试实现视频。请原谅我，如果我实施了错误，这是我在keras中实现的代码。
编辑：cifar-10 imagedatagenerator 
  cifar_generator = imagedatagenerator（）

cifar_data = cifar_generator.flow_from_directory（&#39;dataSets/cifar-10/train&#39;， 
                                                 batch_size = 32， 
                                                 target_size = input_size， 
                                                 class_mode =&#39;分类&#39;）
 
 Keras中描述的模型：

在

ADD（卷积2d（过滤器= 96，kernel_size =（11，11），input_shape =（227，227，3），步幅= 4，激活=&#39;relu&#39;））））
model.Add（maxpool2d（pool_size =（3，3），步幅= 2））

ADD（卷积2d（过滤器= 256，kernel_size =（5，5），步幅= 1，padding =&#39;same&#39;，activation =&#39;relu&#39;））
model.Add（maxpool2d（pool_size =（3，3），步幅= 2））

ADD（卷积2d（过滤器= 384，kernel_size =（3，3），步幅= 1，填充=&#39;same&#39;，activation =&#39;relu&#39;））））
ADD（卷积2d（过滤器= 384，kernel_size =（3，3），步幅= 1，填充=&#39;same&#39;，activation =&#39;relu&#39;））））
model.Add（卷积2d（滤波器= 256，kernel_size =（3，3），步幅= 1，padding =&#39;same&#39;，activation =&#39;relu&#39;））

model.Add（maxpool2d（pool_size =（3，3），步幅= 2））

模型add（Flatten（））
model.Add（密集（单位= 4096））
model.Add（密集（单位= 4096））
model.Add（密度（单位= 10，activation =&#39;softmax&#39;））

model.compile（优化器=&#39;adam&#39;，loss =&#39;apcorical_crossentropopy&#39;，量表= [&#39;准确性&#39;]）
 
我已经使用Imagedatagenerator在CIFAR-10数据集上训练该网络。但是，我只能获得大约.20的准确性。我无法弄清楚我做错了什么。]]></description>
      <guid>https://stackoverflow.com/questions/51403712/implementation-of-alexnet-in-keras-on-cifar-10-gives-poor-accuracy</guid>
      <pubDate>Wed, 18 Jul 2018 13:47:55 GMT</pubDate>
    </item>
    <item>
      <title>返回标签及其在Sklearn LabelenCoder中的编码值</title>
      <link>https://stackoverflow.com/questions/48938905/return-the-labels-and-their-encoded-values-in-sklearn-labelencoder</link>
      <description><![CDATA[我正在使用  labelencoder  和  oneHotEncoder       sklearn  在机器学习项目中，用于编码数据集中的标签（国家名称）。一切都很好，我的模型运行得很好。该项目是根据包括客户国家在内的多个功能（数据）来对银行客户的持续或离开银行的分类。 
当我想预测（分类）新客户（仅一个）时，我的问题就会出现。新客户的数据仍未预处理（即，未编码国家名称）。如下：
  new_customer = np.array（[[[&#39;france&#39;，600，&#39;男性&#39;，40，3，60000，2，1,1，50000]]）
 
在我学习机器学习的在线课程中，讲师打开了包括编码数据的预处理数据集， 手动   检查了法国的代码并更新了它在 new_customer 中，如下：
  new_customer = np.Array（[[[0，0，600，&#39;Male&#39;，40，3，60000，2，1,1，50000]]）
 
我相信这是不切实际的，必须有一种方法可以自动编码法国在原始数据集中使用的相同代码，或者至少是返回国家列表及其编码值的方法。手动编码标签似乎乏味且容易出错。那么，如何自动化此过程或生成标签代码？提前致谢。 ]]></description>
      <guid>https://stackoverflow.com/questions/48938905/return-the-labels-and-their-encoded-values-in-sklearn-labelencoder</guid>
      <pubDate>Thu, 22 Feb 2018 23:28:02 GMT</pubDate>
    </item>
    </channel>
</rss>