<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 08 Jan 2024 15:14:32 GMT</lastBuildDate>
    <item>
      <title>如何构建多输出回归模型的目标变量？</title>
      <link>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</link>
      <description><![CDATA[我想使用 XGBoost 构建一个多输出模型，其中输出是联系客户时预测的销售情况，例如：

output1 是联系后的预测销售额
output2 是未联系情况下的预测销售额。

我的数据如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

X_variables
已联系
促销


&lt;正文&gt;

1
1
1000


2
0
600


3
1
500




我打算将 Contacted 和 Sales 组合在一起，形成两个目标列，如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

X_variables
Contacted_Sale
NonContacted_Sale


&lt;正文&gt;

1
1000
0


2
0
600


3
500
0




这是正确的方法吗？零会扰乱模型训练并降低模型的准确性吗？将模型与一个预测联系销售和一个预测非接触销售分开的更好方法是吗？]]></description>
      <guid>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:05:39 GMT</pubDate>
    </item>
    <item>
      <title>在 Evotorch 中使用 CMA-ES 进行量子电路综合时的输出结构</title>
      <link>https://stackoverflow.com/questions/77781395/output-structure-when-using-cma-es-for-quantum-circuit-synthesis-in-evotorch</link>
      <description><![CDATA[我正在尝试了解 CMA-ES 的代码结构，以便可以将其用于我的项目，但在输入/输出方面存在问题，以及如何正确实现我的问题，以便可以对其进行解释/优化。
基本思想是生成一堆随机电路，检查哪些电路最接近目标输入/最小门成本，并据此对它们进行排名。
我有一个可修改的电路生成器，用于初始群体或任何需要的新随机电路。
我知道如何将电路与目标输出进行比较，以便我可以对不同电路进行评级。
问题是我很难实现一个可以使用这些函数的更复杂的模型，我以前没有任何使用 Evotorch/ES 的经验，所以文档没有给出我正在尝试的答案从中挤出来。
我主要寻找具有使用 CMA-ES/Evotorch 实现复杂结构经验的人员，因为我对项目的 pennylane 部分充满信心。
我尝试只是生成输入，但已经在努力解决如何为 CMA-ES 提供电路的问题，所以我一开始就失败了]]></description>
      <guid>https://stackoverflow.com/questions/77781395/output-structure-when-using-cma-es-for-quantum-circuit-synthesis-in-evotorch</guid>
      <pubDate>Mon, 08 Jan 2024 15:00:15 GMT</pubDate>
    </item>
    <item>
      <title>向 ML.NET 图像分类训练器添加更多功能</title>
      <link>https://stackoverflow.com/questions/77781236/add-more-features-to-ml-net-image-classification-trainer</link>
      <description><![CDATA[我们正在使用 ML.NET 对图像进行分类。每个图像都应该属于多个类别之一。
这些图像包含产品的不同变体。这些产品的变体有很多相似之处，但也有一些独特的特征。
是否可以将产品的变体作为特征添加到学习算法中，然后将其传递给预测函数？因此，训练可以利用不同产品变体之间的相似性，但我们仍然可以为预测提供提示，因为我们事先知道正在预测哪个产品变体？
或者我是否必须为产品的每个变体训练一个单独的模型？我现在正在这样做，因为我还没有弄清楚如何传递图像数据之外的其他功能。
图像分类任务文档 建议 特征列必须是可变大小的字节向量。.
有关如何改进模型的文档建议 向数据添加上下文。
是否可以添加额外的特征列以及图像数据，或者这对于 ML.NET（或一般情况？）来说是不可能的。]]></description>
      <guid>https://stackoverflow.com/questions/77781236/add-more-features-to-ml-net-image-classification-trainer</guid>
      <pubDate>Mon, 08 Jan 2024 14:35:01 GMT</pubDate>
    </item>
    <item>
      <title>语义消歧（自然语言处理）[关闭]</title>
      <link>https://stackoverflow.com/questions/77780909/semantic-disambiguation-natural-language-processing</link>
      <description><![CDATA[如何创建一个程序来消除文本中的语义歧义？使用预训练的 Bert 模型可以吗？]]></description>
      <guid>https://stackoverflow.com/questions/77780909/semantic-disambiguation-natural-language-processing</guid>
      <pubDate>Mon, 08 Jan 2024 13:56:55 GMT</pubDate>
    </item>
    <item>
      <title>机器学习训练数据</title>
      <link>https://stackoverflow.com/questions/77780893/machine-learning-training-data</link>
      <description><![CDATA[我有一个机器学习多输出分类器，可以预测用户在时尚应用程序中的偏好。我有一个包含多个用户偏好的数据集，因此我可以预测他们的偏好。我很困惑是否需要为每个用户单独分离数据集，还是将它们全部放在一起？它对新用户有何作用？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77780893/machine-learning-training-data</guid>
      <pubDate>Mon, 08 Jan 2024 13:56:01 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用强化学习为一款严肃的游戏制作一个Python聊天机器人，我如何将它链接到一个统一的2D游戏[关闭]</title>
      <link>https://stackoverflow.com/questions/77780729/i-am-making-a-python-chatbot-for-a-serious-game-using-reinforcement-learning-ho</link>
      <description><![CDATA[我正在开发一个项目来创建一个教育游戏，我希望将一个Python聊天机器人连接到我的游戏中，作为一个自适应NPC来教授这个主题，假设我有Python脚本来运行这个游戏，我会这样做吗？程序
我正在尝试学习这个概念，但不知道从哪里开始，我尝试了机器学习代理，但它们并不完全是我想要的，它们更多的是一种自适应动作，我想要一个用于对话的聊天机器人，另外有些人给了我链接连接到 chatgpt api，但我想制作一个离线游戏，在游戏内使用 json 文件存储数据，以便有人可以指导我该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/77780729/i-am-making-a-python-chatbot-for-a-serious-game-using-reinforcement-learning-ho</guid>
      <pubDate>Mon, 08 Jan 2024 13:43:00 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow 中加载数据时的内存限制</title>
      <link>https://stackoverflow.com/questions/77780671/memory-limit-while-loading-data-in-tensorflow</link>
      <description><![CDATA[我使用 mobilenet 从 UCF-Anomaly 数据集的视频中提取特征，并将特征保存为 numpy 数组。这些 numpy 数组的总大小约为 45GB。假设我有一个以下模型。我如何加载该数据进行训练。我看到了与张量流管道相关的帖子和​​文档，但无法理解任何内容。我是机器学习的初学者。
模型 = 顺序 (...)
我尝试一次加载所有数据，但我的计算机崩溃了。]]></description>
      <guid>https://stackoverflow.com/questions/77780671/memory-limit-while-loading-data-in-tensorflow</guid>
      <pubDate>Mon, 08 Jan 2024 13:38:48 GMT</pubDate>
    </item>
    <item>
      <title>如何从时间序列中消除季节性？</title>
      <link>https://stackoverflow.com/questions/77780144/how-to-remove-seasonality-from-time-series</link>
      <description><![CDATA[我想在 Python 中对时间序列进行建模以进行空气质量预测。我的数据集有两列：date_time 和 aqi，并包含 AQI 的每小时测量值。数据具有季节性，但并非完全季节性，因为 AQI 值会波动。
我想创建 ARIMA 或 SARIMA 模型来预测未来值。
SARIMA 是一个不错的选择，因为数据是季节性的，但它的季节性非常高（8760），因此训练这个模型是不可行的。如果将数据重新采样为每日季节性，对于训练 SARIMA m=365 来说仍然太高。
如果我想制作 ARIMA 模型，我需要使数据平稳，但它非常复杂，无论我尝试什么，我都无法消除季节性。我尝试了差分、多重差分（最多 10 个）、季节性差分、时间序列分解和删除季节性分量、对数变换、归一化、从当前值减去该周值的平均值，...但结果始终是季节性的。下图显示：时间序列分解、每日时间序列和季节差异（结果不是平稳的）。
如何使这个时间序列平稳？如何消除季节性？当数据具有很高的季节性时，如何在Python中创建SARIMA模型？
分解时间序列
时间序列和季节差异时间序列]]></description>
      <guid>https://stackoverflow.com/questions/77780144/how-to-remove-seasonality-from-time-series</guid>
      <pubDate>Mon, 08 Jan 2024 12:38:36 GMT</pubDate>
    </item>
    <item>
      <title>mlr3 (R) 管道 |泰坦尼克号宇宙飞船 Kaggle</title>
      <link>https://stackoverflow.com/questions/77779659/mlr3-r-pipelines-spaceship-titanic-kaggle</link>
      <description><![CDATA[我正在尝试在 R 中复制此 python 代码：
从 sklearn.pipeline 导入管道
从 sklearn.impute 导入 SimpleImputer
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.compose 导入 ColumnTransformer
从 sklearn.preprocessing 导入 OrdinalEncoder
从 sklearn.preprocessing 导入 OneHotEncoder

num_pipeline = 管道([
    (&#39;imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)),
    (&#39;std_scaler&#39;, StandardScaler())
]）

cat_pipeline = 管道([
    (&#39;oh_encoder&#39;, OneHotEncoder())
]）

full_pipeline = ColumnTransformer([
    (&#39;num&#39;, num_pipeline, num_attribs),
    （&#39;猫&#39;，cat_pipeline，cat_attribs）
]）

# 未选择的列，例如“PassengerId”和“Cabin”将被
# 通过列变压器后掉落
X_train_copy_transformed = df_transform(X_train_copy)
打印（X_train_copy_transformed.columns）
X_train_copy_prepared = full_pipeline.fit_transform(X_train_copy_transformed)
打印（X_train_copy_prepared[0]）

这是我到目前为止所做的事情：
库(mlr3)
库（mlr3pipelines）

num_pipeline &lt;- po(“imputemedian”) %&gt;&gt;% po(“scale”，center = TRUE，scale = TRUE)
cat_pipeline &lt;- po(“编码”, method = “one-hot”)

完整管道&lt;-

X_train_copy_transformed &lt;- df_transform(X_train_copy)
打印（列名（X_train_copy_transformed））
X_train_copy_prepared &lt;- full_pipeline$train(列表(数据 = 列表(x = X_train_copy_transformed)))$预测(列表(x = X_train_copy_transformed))
打印（X_train_copy_prepared[1，]）

我不知道如何解决这个问题。这是整个笔记本供您使用数据：
https://www.kaggle.com/code/paulitos/保罗斯号泰坦尼克号宇宙飞船
我已阅读文档，但不太明白。任何帮助将不胜感激。我什至不知道 X_train_copy_transformed 的定义是否做得好。
这里是Python中的原始笔记本，我正在尝试在R中执行此操作：https://www.kaggle.com/code/oscardata963/spaceship-titanic-notebook
我已经在上一个单元格中说过了。我正在使用 mlr3，并且尝试使用 recipes 和 caret 执行此操作，但没有成功。我认为 mlr3 是一个与 R 中的 scikit-learn 更相似的库。我已经阅读了文档并尝试了 “select”和其他人但没有成功。另外，显然也尝试过向其他地方询问，ChatGPT、BingAI 和 AI Converters。]]></description>
      <guid>https://stackoverflow.com/questions/77779659/mlr3-r-pipelines-spaceship-titanic-kaggle</guid>
      <pubDate>Mon, 08 Jan 2024 11:44:44 GMT</pubDate>
    </item>
    <item>
      <title>如何进行AI项目？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77779505/how-to-proceed-with-a-ai-project</link>
      <description><![CDATA[我对人工智能还很陌生。目前我有一项服务可以生成日志，现在可以是信息或错误。如果出现错误，我的项目应该向我提供解决错误的建议。
日志基本上包含许多不必要和必要的内容，其中包括错误代码、异常或当前服务行为的简单信息。
一些错误解决方案可以在互联网上找到，而另一些则非常特定于与服务相关的错误。
我认为 gen AI 可以在我使用服务日志训练模型时提供帮助，因为它有点类似于 NLP。并根据上下文，它发现错误。在一个非常高的水平上。但我从一些人那里听到关于训练一个已经拥有文字知识的 llama 模型，并使用服务数据日志训练该模型，并运行一个 azure databricks 作业来检查错误日志并将上下文发送到模型以获取建议。有人提到使用矢量数据库。但我不确定这些建议有多准确。
所以，我真的很困惑如何继续解决这个问题...任何帮助或文档链接都会对我有很大帮助...谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77779505/how-to-proceed-with-a-ai-project</guid>
      <pubDate>Mon, 08 Jan 2024 11:28:19 GMT</pubDate>
    </item>
    <item>
      <title>训练时在 pytorch 中没有出现 grad set 错误</title>
      <link>https://stackoverflow.com/questions/77777706/getting-no-grad-set-error-in-pytorch-while-traning</link>
      <description><![CDATA[运行时错误：张量的元素 0 不需要 grad 并且没有 grad_fn 
我在以下训练循环中遇到此错误，梯度必须由顺序本身设置，但它说没有梯度。
“”“培训”“”
纪元 = 100


对于范围内的历元（Epochs）：
    模型.train()

    train_logits = 模型(X_train)
    train_preds_probs = torch.softmax(train_logits,dim=1).argmax(dim=1).type(torch.float32)
    损失 = loss_fn(train_preds_probs,y_train)
    train_accu = 准确率(y_train,train_preds_probs)
    打印（train_preds_probs）
    优化器.zero_grad()

    loss.backward()

    优化器.step()

    ＃训练
    模型.eval()
    使用 torch.inference_mode()：
        test_logits = 模型(X_test)
        test_preds = torch.softmax(test_logits.type(torch.float32),dim=1).argmax(dim=1)
        test_loss = loss_fn(test_preds,y_train)
        test_acc = 准确度(y_test,test_preds)

    
    如果纪元％10 == 0：
        print(f&#39;Epoch:{epoch} | 训练损失: {loss} |泰宁 acc:{train_accu} | 测试损失: {test_loss} | 测试acc: {test_acc}&#39;)






我尝试上网冲浪，但没有得到解决方案。
感谢任何帮助！]]></description>
      <guid>https://stackoverflow.com/questions/77777706/getting-no-grad-set-error-in-pytorch-while-traning</guid>
      <pubDate>Mon, 08 Jan 2024 07:51:44 GMT</pubDate>
    </item>
    <item>
      <title>我使用 XGB 分类器训练了数据集</title>
      <link>https://stackoverflow.com/questions/77776124/ive-trained-dataset-using-xgb-classifier</link>
      <description><![CDATA[我从我的队友那里得到了我们项目的这部分代码，我在本地遇到了这个错误，我已经使用 XGB 分类器训练了数据集。
我的代码是：
# XGBoost 分类器模型
从 xgboost 导入 XGBClassifier

# 实例化模型
xgb = XGBClassifier()

# 拟合模型
xgb.fit(X_train,y_train)

然后我得到了这个错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
[70] 中的单元格，第 8 行
      5 xgb = XGBClassifier()
      7#拟合模型
----&gt; 8 xgb.fit(X_train,y_train)

文件 ~/anaconda3/envs/project/lib/python3.10/site-packages/xgboost/core.py:730，在 require_keyword_args.. throw_if..inner_f(*args, **kwargs ）
    728 k, arg in zip(sig.parameters, args)：
    第729章
--&gt;第730章

文件〜/anaconda3/envs/project/lib/python3.10/site-packages/xgboost/sklearn.py:1471，在XGBClassifier.fit（self，X，y，sample_weight，base_margin，eval_set，eval_metric，early_stopping_rounds，verbose， xgb_model、sample_weight_eval_set、base_margin_eval_set、feature_weights、回调）
   第1466章
   第1467章
   第1468章
   第1469章
   第1470章
-&gt;第1471章
   攀上漂亮女局长之后1472 ”
   第1473章
   第1474章
   第1476章
   第1478章

ValueError：从“y”的唯一值推断出无效的类。

预期：[0 1]，得到[-1 1]，，我听说 y_train 必须在较新的更新中进行编码，但我对这些事情有点陌生，我也不知道如何做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/77776124/ive-trained-dataset-using-xgb-classifier</guid>
      <pubDate>Mon, 08 Jan 2024 03:09:32 GMT</pubDate>
    </item>
    <item>
      <title>将自定义张量流模型加载到展会托管应用程序中</title>
      <link>https://stackoverflow.com/questions/77774973/loading-custom-tensor-flow-model-into-expo-managed-app</link>
      <description><![CDATA[我在 python 中使用张量流创建了一个简单的分类器并像这样保存
category = to_categorical(labels, num_classes=np.max(labels)+1)
model.fit(数据、类别、epochs=10、batch_size=16、validation_split=0.2)
tfjs.converters.save_keras_model(模型, &#39;./js-model&#39;)

我现在有 2 个模型文件，model.json 和 group1-shard1of1.bin
我在 Metro 配置中添加了 .bin 扩展名
但是每当我导入 bin 文件时，const bin = require(&quot;./js-model/group1-shard1of1.bin&quot;);
捆绑时出现此错误
错误：语法错误：/src/screens/session-screen/js-model/group1-shard1of1.bin：意外字符“�”。 (1:1)
@acme/世博会：开发：
@acme/expo:dev：&gt; 1 | a�5�:�
看来 Metro/react-native 不知道 bin 文件的编码/格式。
对此有什么建议吗？这是我的依赖项
&lt;预&gt;&lt;代码&gt;“@clerk/clerk-expo”：“0.11.3”，
    “@expo/config-plugins”：“5.0.2”，
    “@react-native-async-storage/async-storage”：“^1.21.0”，
    “@react-navigation/bottom-tabs”：“^6.5.7”，
    “@react-navigation/native”：“^6.0.11”，
    “@react-navigation/native-stack”：“^6.7.0”，
    “@react-navigation/stack”：“^6.2.2”，
    “@shopify/flash-list”：“1.3.1”，
    “@tanstack/react-query”：“^4.16.1”，
    “@tensorflow/tfjs”：“^4.15.0”，
    “@tensorflow/tfjs-react-native”：“^1.0.0”，
    “@trpc/client”：“^10.1.0”，
    “@trpc/react-query”：“^10.1.0”，
    “@trpc/server”：“^10.1.0”，
    “世博会”：“~47.0.14”，
    “expo-auth-session”：“~3.8.0”，
    “expo-build-properties”：“~0.4.1”，
    “expo-camera”：“~13.1.0”，
    “曝光常数”：“~14.0.2”，
    “expo-font”：“11.0.1”，
    “expo-gl”：“~12.0.1”，
    “expo-gl-cpp”：“^11.4.0”，
    “博览会链接”：“~3.3.1”，
    “expo-modules-autolinking”：“~1.0.0”，
    “博览会随机”：“~13.0.0”，
    “expo-secure-store”：“~12.0.0”，
    “expo-splash-screen”：“~0.17.5”，
    “博览会状态栏”：“~1.4.2”，
    “博览会更新”：“~0.15.6”，
    “expo-web-browser”：“12.0.0”，
    “javascript-time-ago”：“^2.5.9”，
    “nativewind”：“^2.0.11”，
    “反应”：“18.1.0”，
    “react-dom”：“18.1.0”，
    “反应本机”：“0.70.8”，
]]></description>
      <guid>https://stackoverflow.com/questions/77774973/loading-custom-tensor-flow-model-into-expo-managed-app</guid>
      <pubDate>Sun, 07 Jan 2024 21:27:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用GAN生成拉曼光谱的合成数据样本？</title>
      <link>https://stackoverflow.com/questions/76906588/how-to-generate-synthetic-data-samples-of-raman-spectroscopy-by-using-gan</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76906588/how-to-generate-synthetic-data-samples-of-raman-spectroscopy-by-using-gan</guid>
      <pubDate>Tue, 15 Aug 2023 14:05:29 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中使用 WeightedRandomSampler</title>
      <link>https://stackoverflow.com/questions/60812032/using-weightedrandomsampler-in-pytorch</link>
      <description><![CDATA[我需要在 PyTorch 中实现多标签图像分类模型。但是我的数据不平衡，因此我使用 PyTorch 中的 WeightedRandomSampler 来创建自定义数据加载器。但是当我迭代自定义数据加载器时，出现错误：IndexError：列表索引超出范围 
使用此链接实现了以下代码：https://discuss.pytorch.org/t/balanced-sampling- Between-classes-with-torchvision-dataloader/2703/3?u=surajsubramanian
def make_weights_for_balanced_classes(images, nclasses):
    计数 = [0] * n 类
    对于图像中的项目：
        计数[项目[1]] += 1
    每个类别的权重 = [0.] * n 个类别
    N = 浮点（总和（计数））
    对于范围内的 i (nclasses)：
        每类权重[i] = N/float(count[i])
    重量 = [0] * len(图像)
    对于 idx，枚举（图像）中的 val：
        权重[idx] =weight_per_class[val[1]]
    返回重量

权重 = make_weights_for_balanced_classes(train_dataset.imgs, len(full_dataset.classes))
权重 = torch.DoubleTensor(权重)
采样器 = WeightedRandomSampler(权重, len(权重))

train_loader = DataLoader（train_dataset，batch_size = 4，采样器=采样器，pin_memory = True）

根据https://stackoverflow.com/a/60813495/10077354中的答案，以下是我的更新的代码。但是当我创建数据加载器时：loader = DataLoader(full_dataset, batch_size=4, Sampler=sampler)，len(loader) 返回 1。
class_counts = [1691, 743, 2278, 1271]
num_samples = np.sum(class_counts)
labels = [_ 的标签，full_dataset.imgs 中的标签]

class_weights = [num_samples/class_counts[i] for i in range(len(class_counts)]
权重 = [class_weights[labels[i]] for i in range(num_samples)]
采样器 = WeightedRandomSampler(torch.DoubleTensor(权重), num_samples)

提前非常感谢！
我根据下面接受的答案添加了一个实用函数：
def Sampler_（数据集）：
    dataset_counts = imageCount(数据集)
    num_samples = sum(数据集计数)
    labels = [_的标签，数据集中的标签]

    class_weights = [num_samples/dataset_counts[i] for i in range(n_classes)]
    权重 = [class_weights[labels[i]] for i in range(num_samples)]
    采样器 = WeightedRandomSampler(torch.DoubleTensor(权重), int(num_samples))
    返回采样器

imageCount 函数查找数据集中每个类别的图像数量。数据集中的每一行都包含图像和类，因此我们考虑元组中的第二个元素。
def imageCount(数据集):
    image_count = [0]*(n_classes)
    对于数据集中的 img：
        图像计数[img[1]] += 1
    返回图像数量
]]></description>
      <guid>https://stackoverflow.com/questions/60812032/using-weightedrandomsampler-in-pytorch</guid>
      <pubDate>Mon, 23 Mar 2020 10:45:53 GMT</pubDate>
    </item>
    </channel>
</rss>