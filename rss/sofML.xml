<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 15 Mar 2024 03:17:50 GMT</lastBuildDate>
    <item>
      <title>如何绘制与图片类似的所有标签，每个标签在混淆矩阵中自己的框中？</title>
      <link>https://stackoverflow.com/questions/78163734/how-to-plot-all-labels-similar-to-the-picture-with-each-label-in-its-own-box-in</link>
      <description><![CDATA[我不明白为什么我的代码会生成一个看起来复杂且难以理解的图表。如何调整我的代码，以便它绘制类似于图片的内容，但不仅仅是“3”和“5”，我想绘制混淆矩阵中的所有数字。
我的总体目标是对 0 到 9 的数字进行分类，因此我想在混淆矩阵中显示 0-9 的所有数字，以显示决策树算法是否成功。
我想要实现的目标的图片
以下代码的输出
# 定义所有可能的类（数字0-9）
类 = np.arange(10)

# 初始化一个图形来绘制混淆矩阵
尺寸 = 5
垫= 0.2
Fig6,ax6 = plt.subplots(figsize=(大小, 大小), 布局=&#39;约束&#39;)

# 循环所有真实标签和预测标签对
对于类中的 true_label：
    对于类中的 pred_label：
        # 提取真实标签为 true_label 且预测标签为 pred_label 的示例
        示例 = X_test[(y_test == str(true_label)) &amp; (y_pred_dt == str(pred_label))]
        
        # 绘制示例
        对于 idx，枚举中的 image_data(示例[:size*size])：
            x = idx % 大小 + pred_label * (大小 + pad)
            y = idx // 尺寸 + true_label * (尺寸 + pad)
            ax6.imshow(image_data.reshape(28, 28), cmap=“二进制”,
                       范围=(x, x + 1, y, y + 1))

# 设置刻度和标签
ax6.set_xticks([size / 2 + i * (size + pad) for i in range(len(classes))], labels=classes)
ax6.set_yticks([size / 2 + i * (size + pad) for i in range(len(classes))], labels=classes)

# 显示网格线
ax6.plot([尺寸 + 焊盘 / 2, 尺寸 + 焊盘 / 2], [0, len(类) * (尺寸 + 焊盘)], &quot;k:&quot;)
ax6.plot([0, len(classes) * (size + pad)], [size + pad / 2, size + pad / 2], &quot;k:&quot;)

# 设置轴限制
ax6.axis([0, len(类) * (大小 + 垫), 0, len(类) * (大小 + 垫)])

# 设置轴标签
ax6.set_xlabel(“预测标签”)
ax6.set_ylabel(“真实标签”)

# 显示情节
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78163734/how-to-plot-all-labels-similar-to-the-picture-with-each-label-in-its-own-box-in</guid>
      <pubDate>Thu, 14 Mar 2024 22:22:08 GMT</pubDate>
    </item>
    <item>
      <title>揭示高价值客户：识别和定位高 CLV 客户的机器学习方法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78163615/unveiling-high-value-customers-a-machine-learning-approach-to-identify-and-targ</link>
      <description><![CDATA[对于零售商，我拥有客户数据，其中包含性别、年龄、距最近零售商的距离、销售人员等以及个人 CLV（客户生命周期价值）
我想了解构成我的最高 CLV 客户的固有特征。目标是寻找并获取具有相似特征的其他客户。
我应该使用什么机器学习算法？
一方面，我在想，“高 CLV 的预测因子是什么”听起来像是一个监督模型。
另一方面，这听起来也像是一个分割问题。关于“Meta (Facebook/instagram) 上最适合定位的细分市场”
在营销方面具有数据分析经验的人可以参与进来并提供一些指导吗？
（顺便说一句，我正在使用 R 工作）]]></description>
      <guid>https://stackoverflow.com/questions/78163615/unveiling-high-value-customers-a-machine-learning-approach-to-identify-and-targ</guid>
      <pubDate>Thu, 14 Mar 2024 21:43:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78163556/machine-learning-algorithms</link>
      <description><![CDATA[主要目标保持不变：通过将各种机器学习模型应用于二元分类问题（泰坦尼克号的生存预测）来获得各种机器学习模型的实践经验，并根据准确性和其他相关指标评估每个模型的性能。 
泰坦尼克号数据集包含有关泰坦尼克号乘客以及他们是否生还的信息。它包括数值变量和分类变量，使其适合该任务。]]></description>
      <guid>https://stackoverflow.com/questions/78163556/machine-learning-algorithms</guid>
      <pubDate>Thu, 14 Mar 2024 21:29:07 GMT</pubDate>
    </item>
    <item>
      <title>如何在普通电脑上实际运行大数据[关闭]</title>
      <link>https://stackoverflow.com/questions/78163349/how-to-actually-run-big-data-on-normal-pc</link>
      <description><![CDATA[我有一个大约 100GB 的数据集，我一直在尝试处理它，但我厌倦的所有解决方案在我的案例中都失败了。
我的 csv 数据集位于连接到我的电脑的外部硬盘上。我的电脑有 jupyter，但我尝试运行它，甚至只运行了 33%，它就崩溃了。我已经尝试过 jupyter lab 但还是不行。我尝试使用 SPLUNK 中的 jupyter，但无法将一个连接到另一个。
我有数据科学经验，但从未经历过这么大的事情。我的问题基本上是如何/在哪里分析如此大的数据集。我以为我可以使用我习惯的东西，但一切都失败了。]]></description>
      <guid>https://stackoverflow.com/questions/78163349/how-to-actually-run-big-data-on-normal-pc</guid>
      <pubDate>Thu, 14 Mar 2024 20:39:08 GMT</pubDate>
    </item>
    <item>
      <title>由于 ValueError，autoencoder.fit 不起作用</title>
      <link>https://stackoverflow.com/questions/78163348/autoencoder-fit-doesnt-work-becaue-of-a-valueerror</link>
      <description><![CDATA[我不明白我的问题是什么。它应该可以工作，只是因为它是张量流文档中的标准自动编码器。
这是错误
第 64 行，通话中
    解码 = self.decoder(编码)
ValueError：调用 Autoencoder.call() 时遇到异常。

无效的数据类型：&lt;0x7fb471cc1c60 处的属性对象&gt;

Autoencoder.call() 收到的参数：
  x=tf.Tensor(形状=(32,28,28),dtype=float32)

这是我的代码
(x_train, _), (x_test, _) = Fashion_mnist.load_data()

x_train = x_train.astype(&#39;float32&#39;) / 255.
x_test = x_test.astype(&#39;float32&#39;) / 255.

打印（x_train.shape）
打印（x_test.shape）

类自动编码器（模型）：
  def __init__(自身，latent_dim，形状)：
    super(自动编码器, self).__init__()
    self.latent_dim = Latent_dim
    self.shape = 形状
    self.encoder = tf.keras.Sequential([
      层.Flatten(),
      层.Dense（latent_dim，激活=&#39;relu&#39;），
    ]）
    self.decoder = tf.keras.Sequential([
      层.Dense（tf.math.reduce_prod（形状），激活=&#39;sigmoid&#39;），
      图层.重塑（形状）
    ]）

  def 调用（自身，x）：
    编码 = self.encoder(x)
    打印（编码）
    解码 = self.decoder(编码)
    打印（解码）
    返回解码后的内容


形状 = x_test.shape[1:]
潜伏暗度 = 64
自动编码器 = 自动编码器（latent_dim，形状）

autoencoder.compile(optimizer=&#39;adam&#39;, loss=losses.MeanSquaredError())

自动编码器.fit(x_train, x_train,
                纪元=10，
                随机播放=真，
                验证数据=（x_test，x_test））

我尝试更改数据库并尝试了不同的形状]]></description>
      <guid>https://stackoverflow.com/questions/78163348/autoencoder-fit-doesnt-work-becaue-of-a-valueerror</guid>
      <pubDate>Thu, 14 Mar 2024 20:39:06 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习预测未来股票价格[关闭]</title>
      <link>https://stackoverflow.com/questions/78163298/predicting-future-stock-prices-using-machine-learning</link>
      <description><![CDATA[我正在尝试用 python 训练机器学习模型（xgb）来预测股票价格。我首先获取股票价格，然后计算技术指标以用作特征。然后，我将数据拆分为训练集和测试集，其中特征（modeling_df）为 X，收盘价（closes）为 Y。
我的问题是，我不确定该模型实际上是根据过去的价格来预测价格，但模型是通过查看当前时间的特征来预测价格。我还想确保它使用“滚动窗口”，因此，如果有 30 个值，则值 11-20 应基于 0-10，而 21-30 应基于 0- 20.
如果有人知道神经网络的解决方案是否不同，那么我们也将不胜感激！
scaled_features = scaler.fit_transform(modeling_df)

X = 缩放特征
Y = 关闭

x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.05,shuffle=False)

然后我使用：
final_model = xgb.XGBRegressor(**best_params)
Final_model.fit(x_train,y_train, )

预测 = Final_model.predict(x_test)

然后我使用 matplotlib 显示它。
我尝试将整个数据集移动 10（和其他值），以尝试预测未来的 10 个数据点，但我不确定如何验证它是否确实有效。
这是我的图表（数据集没有被移动）。
烛台 + 蓝线 = 实际价格
紫色线 = 预测价格
图表：
]]></description>
      <guid>https://stackoverflow.com/questions/78163298/predicting-future-stock-prices-using-machine-learning</guid>
      <pubDate>Thu, 14 Mar 2024 20:30:48 GMT</pubDate>
    </item>
    <item>
      <title>使用convert_marian_to_pytorch.py​​脚本转换opus mt模型后出现的问题</title>
      <link>https://stackoverflow.com/questions/78163296/problem-after-using-convert-marian-to-pytorch-py-script-to-convert-opus-mt-model</link>
      <description><![CDATA[利用convert_marian_pytorch.py​​ 脚本将 OPUS 转换模型转换为与 Hugging Face Transformers 兼容的格式后，我将生成的模型上传到 Hugging Face 的模型中心 此处。然而，经过测试，模型的翻译输出似乎是一堆随机单词，缺乏连贯性。
我正在寻求帮助来解决此问题或探索替代方法来直接在 Python 中使用 Marian 模型，而不依赖 OPUS cat mt 引擎。
经测试，模型的翻译输出似乎是一堆随机单词，缺乏连贯性。]]></description>
      <guid>https://stackoverflow.com/questions/78163296/problem-after-using-convert-marian-to-pytorch-py-script-to-convert-opus-mt-model</guid>
      <pubDate>Thu, 14 Mar 2024 20:30:25 GMT</pubDate>
    </item>
    <item>
      <title>CNN中的核运动与图像处理中的卷积运算相同吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78162534/kernel-movement-in-cnn-is-same-as-convolution-operation-in-image-processing</link>
      <description><![CDATA[我们都知道图像处理中的卷积运算：

翻转蒙版并进行关联。
一维掩模水平翻转，因为只有一行。
2D 蒙版垂直和水平翻转。
遮罩在图像矩阵上从左向右滑动。
当蒙版悬停在图像上时，蒙版和图像的相应元素会相乘并添加产品。

但是在 CNN 中，我们通常不会执行，因为我们仅从左到右水平滑动内核并移动到下一行，并简单地对具有相应内核值的图像像素执行点积，这里我们只执行相关运算而不是卷积。
请解答我的疑问]]></description>
      <guid>https://stackoverflow.com/questions/78162534/kernel-movement-in-cnn-is-same-as-convolution-operation-in-image-processing</guid>
      <pubDate>Thu, 14 Mar 2024 17:57:13 GMT</pubDate>
    </item>
    <item>
      <title>将低秩近似应用于可学习参数</title>
      <link>https://stackoverflow.com/questions/78158096/applying-low-rank-approximation-to-learnable-parameters</link>
      <description><![CDATA[我试图了解将低秩近似应用于类中的可学习参数是否有意义。目标是减少参数数量。
我有以下自定义模块：
类 CustomPara(nn.Module):
    
    def __init__(self, num_blocks, in_planes, out_planes, kernel_size):
        super(CustomPara, self).__init__()
        self.coefficient_shape = (num_blocks,1,1,1,1)
        块 = [torch.Tensor(out_planes, in_planes, kernel_size, kernel_size) for _ in range(num_blocks)]
        对于范围内的 i(num_blocks): init.kaiming_normal_(blocks[i])
        self.blocks = nn.Parameter(torch.stack(blocks)) # 这是我们稍后将冻结的内容

    def 前向（自身，系数）：
        Final_blocks = (self.blocks*系数).sum(0)
        返回final_blocks

是否可以使用 blocks 参数上的低秩自适应来减少此处可学习参数的数量？]]></description>
      <guid>https://stackoverflow.com/questions/78158096/applying-low-rank-approximation-to-learnable-parameters</guid>
      <pubDate>Thu, 14 Mar 2024 04:22:39 GMT</pubDate>
    </item>
    <item>
      <title>在设置依赖项时如何修复此错误？</title>
      <link>https://stackoverflow.com/questions/78155493/how-can-i-fix-this-error-while-i-was-setting-up-dependencies</link>
      <description><![CDATA[我只是想为我的机器学习作业设置依赖关系
!apt-get install -y xvfb python-opengl &gt; /dev/null 2&gt;&amp;1
！pip installgym pyvirtualdisplay&gt; /dev/null 2&gt;&amp;1
！pip installgym pyvirtualdisplay&gt; /dev/null 2&gt;&amp;1
!apt-get install -y xvfb python-opengl ffmpeg &gt; /dev/null 2&gt;&amp;1
!pip 安装gym[classic_control]
!apt-get 更新 &gt; /dev/null 2&gt;&amp;1
!apt-get install cmake &gt; /dev/null 2&gt;&amp;1
!pip install --upgrade setuptools 2&gt;&amp;1
!pip install ez_setup &gt; /dev/null 2&gt;&amp;1

我收到此错误输出，显示某些安装正确，但有很多“系统找不到指定的路径。”
系统找不到指定的路径。

还有另一个错误
错误：子进程退出并出现错误
  
  python setup.py Egg_info 未成功运行。
  退出代码：1
  
  [77行输出]
  
  
  警告，没有“设置”文件存在，正在运行“buildconfig/config.py”
  使用WINDOWS配置...
  
 
  未找到 FREETYPE 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  找不到 PNG 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  未找到 JPEG 的路径。
  ...在 prebuilt-x64 中发现包含目录但没有库目录。
  freetype 的 DLL：prebuilt-x64/SDL2_ttf-2.0.15/lib/x64/libfreetype-6.dll
  
  ---
  如需编译帮助，请参阅：
      https://www.pygame.org/wiki/CompileWindows
  要为 pygame 开发做出贡献，请参阅：
      https://www.pygame.org/contribute.html
  ---
  
  [输出结束]
  
  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：元数据生成失败

生成包元数据时遇到错误。

请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip 的问题。
提示：详细信息请参见上文。

我尝试在谷歌上搜索答案，也尝试过 chatgpt，但没有一个能给我答案。]]></description>
      <guid>https://stackoverflow.com/questions/78155493/how-can-i-fix-this-error-while-i-was-setting-up-dependencies</guid>
      <pubDate>Wed, 13 Mar 2024 16:44:29 GMT</pubDate>
    </item>
    <item>
      <title>在python中创建线性回归模型的问题</title>
      <link>https://stackoverflow.com/questions/78152862/problem-with-creating-a-linear-regression-model-in-python</link>
      <description><![CDATA[我有一个数据库，其中包含一个城市的多个属性：
该数据库中保存了各种属性（约 19,000 个）。每个房产都有一些特征，例如：销售价格、房产面积、浴室数量、建造年份、上市天数......
我是机器学习算法编程的新手，希望首先编写一个简单的线性回归模型，该模型可以根据其他数据预测该房产的上市天数。
数据保存在Excel中。
这就是我所做的：
从 sklearn.linear_model 导入 LinearRegression
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.metrics 导入mean_squared_error, r2_score
从 sklearn.model_selection 导入 train_test_split
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd
导入请求


模型=线性回归()
data=pd.read_excel(r“C:\Users....”)

X=np.array(data.drop([“daysOnMarket”], axis=1))
Y=np.array(数据[“daysOnMarket”])
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)
model.fit(x_train, y_train)
y_pred=模型.预测(x_test)
print(model.score(x_test, y_test))
打印（均方误差（y_test，y_pred））

现在让我觉得我做错了的是，我得到的分数是 0.9999852324248868，均方误差是 0.07659752059595726
现在我不明白这是一个过度拟合问题还是我只是在编程中做错了什么。
谁能帮我找出问题出在哪里吗？
这是我的数据示例：
]]></description>
      <guid>https://stackoverflow.com/questions/78152862/problem-with-creating-a-linear-regression-model-in-python</guid>
      <pubDate>Wed, 13 Mar 2024 10:06:17 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试通过训练迭代计算余弦相似度时，如何选择模型权重[关闭]</title>
      <link>https://stackoverflow.com/questions/78152246/how-do-i-select-model-weights-when-i-try-to-calculate-cosine-similarity-though-t</link>
      <description><![CDATA[我正在尝试计算“t”步骤的权重值和“t-1”步骤的权重值之间的余弦相似度。
我正在使用 LSTM 网络 &amp; 2FC层。
我想检查训练期间的体重差异。
但是如果我想检查这些事情，我想知道我是只选择 LSTM 层的权重还是全部（LSTM，2FC 权重）或最终层的权重（FC_2 权重）
我不知道如何在余弦相似条件下优化选择图层的最佳解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78152246/how-do-i-select-model-weights-when-i-try-to-calculate-cosine-similarity-though-t</guid>
      <pubDate>Wed, 13 Mar 2024 08:34:22 GMT</pubDate>
    </item>
    <item>
      <title>提高特殊神经网络的准确性</title>
      <link>https://stackoverflow.com/questions/78151448/increase-accuracy-in-a-special-neural-network</link>
      <description><![CDATA[我正在训练一个神经网络来玩 2048 游戏，并且大多数时候都能达到 2048。
首先，我收集了近 30,000 个游戏的数据集，在 csv 文件中达到 2048 个。每个游戏包含大约 1000 个棋盘游戏状态，可以说我的数据集中有 3000 万个棋盘状态。实际上有 3000 万行，如下图所示。

正如你所见，我每行有 17 列。前 16 列显示每个图块值的 2 的幂（预计 0 表示该图块中没有任何内容）。
最后一列是它根据这个棋盘游戏移动的方向
方向帮助-&gt; （0：上，1：右，2：下，3：左）

例如上图显示了董事会的这种状态：
&lt;前&gt;&lt;代码&gt; 32 64 128 32
 8 32 8 2
 8 0 0 0
 0 2 0 0

该状态的方向为 0，等于向上
所以我创建了一个具有 16 个输入的神经网络（当然我将其更改为 16*11 输入并将输入作为 one-hot 编码传递）、一些隐藏层和 4 个输出。
我在超参数和改变层结构方面进行了很多尝试和错误。
最后我得到了这样的结果。
导入 pandas 作为 pd
从 keras.models 导入顺序
从 keras.layers 导入密集、批量标准化、激活
从 keras.optimizers 导入 Adam
从 keras.callbacks 导入 EarlyStopping
从 sklearn.preprocessing 导入 OneHotEncoder
将 numpy 导入为 np

# 加载你的数据集
数据 = pd.read_csv(&#39;mainDataSet.csv&#39;)

# 分离输入 (X) 和输出 (y)
X = data.iloc[:, 0:16] # 输入特征
y = pd.get_dummies(data.iloc[:, -1]) # 将输出转换为 one-hot 编码

# 定义 one-hot 编码的类别（标签从 0 到 10）
类别 = [i for i in range(11)]

# 对每个输入列应用 one-hot 编码
X_encoded = pd.concat([pd.get_dummies(pd.Categorical(X[col],categories=categories), prefix=col,
prefix_sep=&#39;_&#39;) 对于 X] 中的列，轴=1)



# 定义模型
模型=顺序（）
model.add(Dense(16*11, input_dim=16*11,activation=&#39;relu&#39;)) # 默认包含偏差
model.add(BatchNormalization()) # 添加批量归一化层
model.add(Dense(256,activation=&#39;relu&#39;)) # 默认情况下包含偏差
model.add(BatchNormalization()) # 添加批量归一化层
model.add(Dense(256,activation=&#39;relu&#39;)) # 默认情况下包含偏差
model.add(BatchNormalization()) # 添加批量归一化层
model.add(Dense(256,activation=&#39;relu&#39;)) # 默认情况下包含偏差
model.add(BatchNormalization()) # 添加批量归一化层
model.add(Dense(256,activation=&#39;relu&#39;)) # 默认情况下包含偏差
model.add(BatchNormalization()) # 添加批量归一化层d
model.add(Dense(4,activation=&#39;softmax&#39;)) # 具有 4 个方向节点的输出层

# 定义提前停止回调，以在验证损失停止改善时停止训练
Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

# 使用 Adam 优化器和默认学习率编译模型
model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=&#39;adam&#39;, 指标=[&#39;accuracy&#39;])

# 使用小批量梯度下降和附加回调来训练模型
model.fit（X_encoded，y，epochs = 100，batch_size = 64，validation_split = 0.2，callbacks =
[早停]）

model.save(&#39;2048_model.h5&#39;)

最终它给了我 88% 的准确度和 90% 的验证准确度，但这对于我正在做的事情来说还不够。
您建议采取哪些方法让我的模型在预测方面表现更好？
或者甚至您可以对我的神经网络进行哪些更改以使其更加高效？]]></description>
      <guid>https://stackoverflow.com/questions/78151448/increase-accuracy-in-a-special-neural-network</guid>
      <pubDate>Wed, 13 Mar 2024 05:36:20 GMT</pubDate>
    </item>
    <item>
      <title>Amazon Sagemaker 在后台从 jupyter 笔记本运行代码</title>
      <link>https://stackoverflow.com/questions/78149372/amazon-sagemaker-run-code-from-jupyter-notebook-in-background</link>
      <description><![CDATA[我正在 Amazon Sagemkaer 笔记本实例上运行代码（在普通的 jupyter 笔记本中，而不是 jupyterLab）。

如何在后台运行代码并关闭浏览器选项卡？当我关闭 jupyter 笔记本选项卡时，程序停止，我想避免这种情况。我读到我不应该在笔记本本身中进行处理，而应该使用 Sagemaker 处理作业。如何在更高的 i 上运行如下所示的简单代码单元

df_new[&#39;predicted_values&#39;] = df_original.progress_apply(lambda x: LLM_pretrained_model.predict( x[&#39;comment_body&#39;] )


12 小时后，内核崩溃，提示我需要再次登录。我怎样才能避免这种情况？由于我的数据量较大，程序至少需要 28 小时才能运行

是否可以从 sagemaker jupyter 笔记本（不是 jupyterLab 笔记本）将代码推送到 GitHub？

]]></description>
      <guid>https://stackoverflow.com/questions/78149372/amazon-sagemaker-run-code-from-jupyter-notebook-in-background</guid>
      <pubDate>Tue, 12 Mar 2024 18:39:54 GMT</pubDate>
    </item>
    <item>
      <title>宏观 VS 微观 VS 加权 VS 样本 F1 分数</title>
      <link>https://stackoverflow.com/questions/55740220/macro-vs-micro-vs-weighted-vs-samples-f1-score</link>
      <description><![CDATA[在sklearn.metrics.f1_score中，f1分数有一个名为“average”的参数。宏观、微观、加权和样本是什么意思？请详细说明，因为在文档中没有正确解释。或者简单地回答以下问题：

为什么“样本”是多标签分类的最佳参数？ 
为什么微观最适合不平衡的数据集？ 
加权和宏之间有什么区别？
]]></description>
      <guid>https://stackoverflow.com/questions/55740220/macro-vs-micro-vs-weighted-vs-samples-f1-score</guid>
      <pubDate>Thu, 18 Apr 2019 06:26:25 GMT</pubDate>
    </item>
    </channel>
</rss>