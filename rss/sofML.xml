<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 12 Mar 2024 00:57:02 GMT</lastBuildDate>
    <item>
      <title>改进多模态检测模型指标</title>
      <link>https://stackoverflow.com/questions/78143946/improving-multimodal-detection-model-metrics</link>
      <description><![CDATA[我正在尝试建立一个多模态模型来检测言语中的抑郁症。我使用 opensmile 从语音文件中提取了音频特征（这是必需的），并在文本文件上使用了 bert 嵌入。然后我将它们都输入到 LSTM-CNN 模型中
def create_fused_model(audio_input_shape, text_input_shape, dropout_rate=0.3, l2_reg= 0.01):
        # 音频输入和 LSTM 处理
    音频输入=输入（形状=（音频输入形状，1），名称=&#39;音频输入&#39;）
    lstm_audio = LSTM(32, return_sequences=True, kernel_regularizer=l2(l2_reg))(audio_input)
    lstm_audio2 = LSTM(16, return_sequences=True, kernel_regularizer=l2(l2_reg))(lstm_audio)
    lstm_audio2 = 辍学（dropout_rate）（lstm_audio2）
    lstm_audio_pooled = GlobalAveragePooling1D()(lstm_audio2)
    
    # 文本输入和CNN处理
    文本输入=输入（形状=（文本输入形状，1），名称=&#39;文本输入&#39;）
    conv_text = Conv1D(filters=32，kernel_size=3，activation=&#39;relu&#39;，strides=1，padding=&#39;same&#39;，kernel_regularizer=l2(l2_reg))(text_input)
    conv_text2 = Conv1D(filters=16，kernel_size=3，activation=&#39;relu&#39;，strides=1，padding=&#39;same&#39;，kernel_regularizer=l2(l2_reg))(conv_text)
    conv_text2 = Dropout(dropout_rate)(conv_text2)
    conv_text_pooled = GlobalAveragePooling1D()(conv_text2)
    
    # Fusion - 门控机制
    ated_layer = Multiply()([lstm_audio_pooled, conv_text_pooled])
    
    # 用于分类的密集层
    密集层=密集（64，激活=&#39;relu&#39;，kernel_regularizer=l2（l2_reg））（gate_layer）
    dropout_layer = Dropout(dropout_rate)(dense_layer)
    输出层=密集（1，激活=&#39;sigmoid&#39;，名称=&#39;输出&#39;）（dropout_layer）
    
    # 模型编译
    模型=模型（输入=[音频输入，文本输入]，输出=输出层）
    model.compile(优化器=Adam(learning_rate=0.001),loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
    
    返回模型

我无法获得超过 67% 的准确率。我尝试过更改所使用的模型、超参数调整以及对 txt 文件使用不同的特征提取技术。]]></description>
      <guid>https://stackoverflow.com/questions/78143946/improving-multimodal-detection-model-metrics</guid>
      <pubDate>Mon, 11 Mar 2024 23:45:24 GMT</pubDate>
    </item>
    <item>
      <title>来自 scikit-optimize 的 BayesSearchCV，作者是谁？</title>
      <link>https://stackoverflow.com/questions/78143727/bayessearchcv-from-scikit-optimize-who-is-the-author</link>
      <description><![CDATA[我在我的手稿中使用了 scikit-optimize 的 BayesSearchCV。我在网上搜索过，但没有找到合适的引用。]]></description>
      <guid>https://stackoverflow.com/questions/78143727/bayessearchcv-from-scikit-optimize-who-is-the-author</guid>
      <pubDate>Mon, 11 Mar 2024 22:33:09 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助来理解 SHAP 瀑布图</title>
      <link>https://stackoverflow.com/questions/78143713/need-help-in-understanding-shap-waterfall-chart</link>
      <description><![CDATA[我对 SHAP 还很陌生，所以如果这是一个愚蠢的问题，请原谅我。
我正在使用一个包含大约 72 个特征的数据集。我试图预测客户是否会流失，所以我的目标变量有 2 个类别：0 - 客户和 1 - 前客户（意味着他们会流失）
我使用此代码生成了 SHAP 瀑布图，并注意到 f(x) = 0.1
但是，当我将 sv[:,:,1], sv.base_values[:,1] 中的 1 替换为 0 时，我得到 f(x) = 0.9
为什么该特定指数的概率会发生变化？我假设概率越高，流失的可能性就越大，但现在我很困惑。
解释器 = 解释器(rf)
sv = 解释器(Train_X)

exp = 解释(sv[:,:,1], sv.base_values[:,1],Train_X, feature_names=None)

idx = 16 # 解释的数据点
瀑布图（exp[idx]，max_display=10）
]]></description>
      <guid>https://stackoverflow.com/questions/78143713/need-help-in-understanding-shap-waterfall-chart</guid>
      <pubDate>Mon, 11 Mar 2024 22:30:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么 plt.show() 不能与 plt.plot 一起使用？ （展示模型训练和测试结果时）</title>
      <link>https://stackoverflow.com/questions/78143385/why-isnt-plt-show-working-with-plt-plot-when-showing-model-training-and-test</link>
      <description><![CDATA[我已经训练了 CNN 模型并正在尝试显示结果。然而，尽管下面的代码没有错误（这是我用 matplotlib 显示图形的代码块），但没有显示图形。我已经看过很多教程，但似乎没有一个有帮助？
这是代码：
 defplot_accuracies(历史):
        ”“”绘制精度历史记录“”
        准确度 = [x[&#39;val_acc&#39;] for x in历史]
        plt.plot(准确度, &#39;-x&#39;)
        plt.xlabel(&#39;纪元&#39;)
        plt.ylabel(&#39;准确度&#39;)
        plt.title(&#39;准确率与纪元数&#39;);
    
    
    情节准确度（历史）
    
    
    defplot_losses（历史）：
        ”“”绘制每个时期的损失“”
        train_losses = [x.get(&#39;train_loss&#39;) for x in历史]
        val_losses = [x[&#39;val_loss&#39;] 对于历史中的 x]
        plt.plot(train_losses, &#39;-bx&#39;)
        plt.plot(val_losses, &#39;-rx&#39;)
        plt.xlabel(&#39;纪元&#39;)
        plt.ylabel(&#39;损失&#39;)
        plt.legend([&#39;训练&#39;, &#39;验证&#39;])
        plt.title(&#39;损失与历元数&#39;);
    
    
    情节损失（历史）
    
    plt.show()

任何帮助都会很棒！]]></description>
      <guid>https://stackoverflow.com/questions/78143385/why-isnt-plt-show-working-with-plt-plot-when-showing-model-training-and-test</guid>
      <pubDate>Mon, 11 Mar 2024 20:57:11 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络节点迭代更新时输入输出维度的一致性</title>
      <link>https://stackoverflow.com/questions/78143339/graph-neural-network-nodes-input-and-output-dimension-consistency-amid-iterativ</link>
      <description><![CDATA[我试图弄清楚使用图神经网络学习嵌入后节点的输入维度（n）和输出维度（m）是否可以不同，我想是的。但是，我正在努力弄清楚这是如何实现的，如下所示：
一般在迭代步骤中：
h_u^(k+1) = update(h_u^(k) + 聚合({h_v^(k) | u 的 v 邻居})
现在，h_u(0) 的维度是输入维度，因此在生成 h_u(1) 时，聚合函数和更新函数的输入是 n 的向量，这里的输出具有维度 m（主要是矩阵乘法和完成加权求和类型的聚合，并将维度调整为 m)，那么从下一次迭代开始，如何通过相同的函数或矩阵来处理维度 m（而不是 n）的向量进行更新？
我恳请 AI-ML 社区提供解释。]]></description>
      <guid>https://stackoverflow.com/questions/78143339/graph-neural-network-nodes-input-and-output-dimension-consistency-amid-iterativ</guid>
      <pubDate>Mon, 11 Mar 2024 20:47:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 python 中的 Brian2 模拟器实现液体状态机用于分类任务？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78141953/how-to-implement-liquid-state-machine-for-a-classification-task-using-brian2-sim</link>
      <description><![CDATA[我是一名正在攻读本科生的学生，目前正在研究用于分类相关任务的液态机。但是，即使花了几天时间研究 LSM，我也无法找到如何实现它们进行分类的良好开端。
如果没有适当的资源，学习概念也非常困难。那么，有人可以帮助我进行研究吗？]]></description>
      <guid>https://stackoverflow.com/questions/78141953/how-to-implement-liquid-state-machine-for-a-classification-task-using-brian2-sim</guid>
      <pubDate>Mon, 11 Mar 2024 15:53:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 Power Automate 将我的 Excel 输入连接到 Azure ML Studio API 端点并进行预测</title>
      <link>https://stackoverflow.com/questions/78140665/using-power-automate-to-connect-my-excel-inputs-to-azure-ml-studio-api-endpoint</link>
      <description><![CDATA[我正在研究如何使用 Power Automate 配置一个流程，该流程可以将我的 Excel 文件输入与我的 Azure ML Studio API 端点连接起来。理想情况下，当添加或修改 Excel 中的某一列值时，将触发此流程。

基于 iris 数据集，我在 Azure ML Studio 中使用 API 端点创建了一个简单的机器学习模型。该模型需要 4 个输入，并根据这些输入返回预测标签。

我创建了一个 Excel 文件，其中有 4 列（sepal_length、sepal_width、petal_length、petal_width），每列都包含一个值，如 Excel 输入屏幕截图中所示。
在 Power Automate 中，我能够使用“列出表中存在的行”操作连接到我的 Excel 文件。在此操作中，我可以找到我的表“Table1”。
我应该在 Power Automate 中采取哪些后续步骤来连接到 API 并能够接收预测结果？
这就是我的流程当前的样子。

因此，我在将输入数据转换为可以作为 API 输入提供的格式时遇到了一些困难。下面的屏幕截图显示了我如何使用 Bearer 令牌和特定 URI 连接到我的 API。
]]></description>
      <guid>https://stackoverflow.com/questions/78140665/using-power-automate-to-connect-my-excel-inputs-to-azure-ml-studio-api-endpoint</guid>
      <pubDate>Mon, 11 Mar 2024 12:36:57 GMT</pubDate>
    </item>
    <item>
      <title>将 Android ML-Kit 鸟类分类器与 Python 结合使用</title>
      <link>https://stackoverflow.com/questions/78139883/using-android-ml-kit-bird-classifier-with-python</link>
      <description><![CDATA[我测试了 ML Kit 中的 Android Vision 快速入门应用程序。正如您在图片中看到的，这里可以进行对象跟踪。现在我正在使用 Python 尝试相同的模型 (bird_classifier.tflite)。这非常有效，但是我如何在这里获取边界框呢？无论我做什么，反馈都是：该模型仅包含一个张量。但为什么它可以在 Android 应用程序中运行呢？
有人可以给我看一个代码示例吗？
测试图片
image = Image.fromarray(screenshot)
image_pred = image.resize((宽度,高度), Image.ANTIALIAS)
结果=classify_image(interpreter, image_pred)
# TrackingID = results[i0][0]
# 分数 = 结果[i0][1]
# Boxes = ?]]></description>
      <guid>https://stackoverflow.com/questions/78139883/using-android-ml-kit-bird-classifier-with-python</guid>
      <pubDate>Mon, 11 Mar 2024 10:19:20 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法直接在windows下使用Nvidia Rapids？</title>
      <link>https://stackoverflow.com/questions/78136820/a-way-to-use-nvidia-rapids-in-windows-directly</link>
      <description><![CDATA[我想知道有没有办法直接在 Windows 11 中安装 Nvidia Rapids 并使用它，而不是与 wsl2 或 docker 一起使用？或者有没有办法将 jupyter lab 主机连接到 dataspell？
我尝试通过 github 将 cuMl 直接安装到 Windows，但每次都失败。我想在 jetbrains dataspell 中使用 cuml，这就是寻求帮助的原因。]]></description>
      <guid>https://stackoverflow.com/questions/78136820/a-way-to-use-nvidia-rapids-in-windows-directly</guid>
      <pubDate>Sun, 10 Mar 2024 17:30:40 GMT</pubDate>
    </item>
    <item>
      <title>持久化模型如何提高准确性？</title>
      <link>https://stackoverflow.com/questions/78127879/how-does-persisting-the-model-increase-accuracy</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入 precision_score, f1_score

Whitewine_data = pd.read_csv(&#39;winequality-white.csv&#39;,
分隔符=&#39;;&#39;)

变量= [&#39;alcohol_cat&#39;, &#39;酒精&#39;, &#39;硫酸盐&#39;, &#39;密度&#39;,
“总二氧化硫”、“柠檬酸”、“挥发性酸度”、
‘氯化物’]

X = Whitewine_data[变量]
y = Whitewine_data[&#39;质量&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y,
测试大小=0.2）

模型 = DecisionTreeClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
准确度=准确度_得分(y_test, y_pred)
f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)

预测 = model.predict([[0.27, 0.36, 0.045, 170, 1.001,
0.45, 8.9, 0]])
print(f&#39;预测输出：{预测}&#39;)
print(f&#39;准确率: {准确率 * 100}%&#39;)
print(f&#39;F1 分数: {f1 * 100}% &#39;)

这个初始模型的准确度得分为 57%
================================================== ===============
whitewine_data = pd.read_csv(&#39;winequality-white.csv&#39;,
分隔符=&#39;;&#39;)

# 要从数据集中删除的变量 - 不是输入
变量
变量 = [&#39;固定酸度&#39;,&#39;残留糖&#39;,&#39;游离硫
二氧化硫&#39;, &#39;pH&#39;, &#39;质量&#39;, &#39;isSweet&#39;]

X = Whitewine_data.drop(变量，轴=1)
y = Whitewine_data[&#39;质量&#39;]

X_train, X_test, y_train, y_test = train_test_split(X, y,
测试大小=0.2）

模型 = DecisionTreeClassifier()
model.fit(X_train, y_train)

joblib.dump(模型, &#39;WhiteWine_Quality_Predictor.joblib&#39;)

创建保存的模型
================================================== ===============
whitewine_data = pd.read_csv(&#39;winequality-white.csv&#39;,
分隔符=&#39;;&#39;)

变量 = [&#39;挥发酸度&#39;, &#39;柠檬酸&#39;, &#39;氯化物&#39;,
&#39;二氧化硫总量&#39;、&#39;密度&#39;、&#39;硫酸盐&#39;、&#39;酒精&#39;、
&#39;酒精_猫&#39;]

X_test = Whitewine_data[变量]
y_test = Whitewine_data[&#39;质量&#39;]

模型 = joblib.load(&#39;WhiteWine_Quality_Predictor.joblib&#39;)

y_pred = model.predict(X_test)

f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)
准确度=准确度_分数（y_test，y_pred）
预测 = model.predict([[0.27, 0.36, 0.045, 170, 1.001,
0.45, 10.9, 3]])

print(f&#39;F1分数: {f1 * 100}%&#39;)
print(f&#39;模型精度: {accuracy * 100}%&#39;)
print(f&#39;预测输出：{预测}&#39;)

调用保存的模型现在的准确率达到 92%
问题：调用已保存的模型如何导致增加
我看到的准确性]]></description>
      <guid>https://stackoverflow.com/questions/78127879/how-does-persisting-the-model-increase-accuracy</guid>
      <pubDate>Fri, 08 Mar 2024 13:07:01 GMT</pubDate>
    </item>
    <item>
      <title>Pytroch 分割模型(.pt) 未转换为 CoreML</title>
      <link>https://stackoverflow.com/questions/78091161/pytroch-segmentation-model-pt-not-converting-to-coreml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78091161/pytroch-segmentation-model-pt-not-converting-to-coreml</guid>
      <pubDate>Sat, 02 Mar 2024 01:26:48 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 实验跟踪重复</title>
      <link>https://stackoverflow.com/questions/76821347/sagemaker-experiment-tracking-duplication</link>
      <description><![CDATA[我正在尝试通过 AWS SageMaker 使用脚本模式训练模型。
我想使用 AWS SageMaker Experiments 以及训练作业中的一些计算指标来跟踪此训练作业。当我开始训练作业时，会成功创建一个新的实验运行，该实验运行跟踪所有提供的超参数（例如，nesimators）。
但是，如前所述，此外，我还想跟踪自定义脚本中的其他指标（例如准确性）。在这里，我在拟合模型之前使用 load_run()，然后使用 run.log_metric() 记录指标。但是，当我这样做时，SageMaker 会在 UI 中创建一个新的单独实验条目，这意味着我的超参数和指标单独存储在两个单独的实验运行中：

我希望在一次实验运行中看到所有指标和超参数的组合。我做错了什么？
这是我用来启动训练过程的缩写代码：
&lt;前&gt;&lt;代码&gt;
exp_name = “sklearn-脚本模式-实验”

与运行（
    实验名称=实验名称，
    sagemaker_session=sess,
）运行时：

    sklearn_estimator = SKLearn(&#39;train.py&#39;,
                                    instance_type=&#39;ml.m5.large&#39;,
                                    Framework_version=&#39;1.0-1&#39;,
                                    role=“arn:aws:iam:::role/service-role/AmazonSageMaker-ExecutionRole-”,
                                    超参数={&#39;nestimators&#39;: 100},
                                    环境={“区域”：区域})

    sklearn_estimator.fit({&#39;train&#39;: f&#39;s3://{BUCKET}/{S3_INPUT_PATH}&#39;})

这是缩写的train.py：
 #在这里解析参数...等等...


    模型 = RandomForestClassifier(n_estimators=args.nesimators,
                                   最大深度=5，
                                   随机状态=1）

    使用 load_run(sagemaker_session=sagemaker_session) 作为运行：

        模型.fit(X, y)

        run.log_metric(name = &quot;最终测试损失&quot;, value = 0.9)
]]></description>
      <guid>https://stackoverflow.com/questions/76821347/sagemaker-experiment-tracking-duplication</guid>
      <pubDate>Wed, 02 Aug 2023 15:20:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 numpy python 读取多个 3D 图像并将它们存储在 4D 数组中？</title>
      <link>https://stackoverflow.com/questions/72667735/how-to-read-multiple-3d-images-and-store-them-in-4d-array-using-numpy-python</link>
      <description><![CDATA[我使用下面的代码为 3 个图像创建了一个形状为 (2, 3, 365, 256, 256) (2, 365, 256, 256) 的数组，但是我需要我的形状为 (2,365, 256, 256, 3) (2, 365, 256, 256) 让我的模型运行，有什么提示吗？
def Load_function(路径):
  f_img= nib.load(路径)
  img_data= f_img.get_fdata()
返回img_data


 def __load__(self, id_name):

    image_path = os.path.join(self.path, id_name)
    ## 读取图像
    图像 = np.empty((0,365, 256, 256))

    对于 [“image2B.nii.gz”、“image1to2_nlB.nii.gz”、“diffFSL.nii.gz”] 中的 imname：
        img = Load_function(os.path.join(image_path,imname))

        img = 调整大小_数据(img)
        
        ## 标准化
        img = img/np.percentile(img,99.5)
        #images.append(img)
        #images.append(img)
    ## 存储到您在上面创建的 4D 数组中（这将保存您想要的一个主题的所有图像）
        image = np.append(img[np.newaxis, ...],image, axis=0) # 为每个图像添加一个新轴并将其附加到结果中
          
    ## 阅读面具
    mask = Load_function(os.path.join(image_path, “ground_truth.nii.gz”))
    掩码 = resize_data(掩码)
    
    返回图像，掩码
]]></description>
      <guid>https://stackoverflow.com/questions/72667735/how-to-read-multiple-3d-images-and-store-them-in-4d-array-using-numpy-python</guid>
      <pubDate>Sat, 18 Jun 2022 08:12:16 GMT</pubDate>
    </item>
    <item>
      <title>种子在随机森林中起什么作用？</title>
      <link>https://stackoverflow.com/questions/36307429/what-does-seed-do-in-random-forest</link>
      <description><![CDATA[我知道通常使用种子设置，以便我们可以重现相同的结果。但是，在随机森林部分中设置种子实际上是做什么的。它是否会更改 R 中 randomForest() 函数的任何参数，例如 nTree 或 sampSize。 
我每次都为随机森林模型使用不同的种子，但想知道不同的种子如何影响随机森林模型。]]></description>
      <guid>https://stackoverflow.com/questions/36307429/what-does-seed-do-in-random-forest</guid>
      <pubDate>Wed, 30 Mar 2016 11:26:58 GMT</pubDate>
    </item>
    <item>
      <title>randomForest R 包的奇怪结果</title>
      <link>https://stackoverflow.com/questions/27324066/weird-results-with-the-randomforest-r-package</link>
      <description><![CDATA[我有一个包含 10,000 行和两列的数据框、段（具有 32 个值的因子）和目标（具有两个值“是”和“否”的因子，每个值 5,000 个）。我正在尝试使用随机森林来使用分段作为特征对目标进行分类。
训练随机森林分类器后：
&lt;前&gt;&lt;代码&gt;&gt;森林 &lt;- randomForest(目标 ~ 段，数据)

混淆矩阵强烈偏向“否”：
&lt;前&gt;&lt;代码&gt;&gt;打印（森林$混乱）

      否 是 类错误
无 4872 76 0.01535974
是 5033 19 0.99623911

在 10,000 行中，不到 100 行被分类为“是”（即使原始计数为 50/50）。如果我切换标签的名称，我会得到相反的结果：
&lt;前&gt;&lt;代码&gt;&gt; data$target &lt;- as.factor(ifelse(data$target == &#39;是&#39;, &#39;否&#39;, &#39;是&#39;))
&gt;森林 &lt;- randomForest(目标 ~ 段，数据 = 数据)
&gt;打印（森林$混乱）

      否 是 类错误
无 4915 137 0.02711797
是 4810 138 0.97210994

所以这不是一个真正的信号...而且，原始的交叉表是相对平衡的：
&lt;前&gt;&lt;代码&gt;&gt;表（数据$目标，数据$段）
 
         1 10 11 12 13 14 15 16 17 18 19 2 20 21 22 23 24 25 26 27 28 29 3 30 31 32 4 5 6 7 8 9
  否 1074 113 121 86 68 165 210 70 120 127 101 132 90 108 171 122 95 95 76 72 105 71 234 58 83 72 290 162 262 192 64 139
  是 1114 105 136 120 73 201 209 78 130 124 90 145 81 104 155 128 79 85 83 70 93 78 266 70 93 76 291 160 235 194 49 137

看起来 randomForest 采用第一个标签，并且几乎总是为其分配点。澄清一下，数据框是具有更多功能的更大表格的子集 - 我刚刚发现这个特定功能以某种方式导致了这个结果，无论包含多少其他功能。我想知道我是否遗漏了随机森林分类器的一些基本知识，或者是否存在一些编码问题或其他错误导致了这个奇怪的结果。
原始数据集可在此处作为 RDS 获取：
https://www.dropbox.com/s/rjq6lmvd78d6aot /weird_random_forest.RDS?dl=0]]></description>
      <guid>https://stackoverflow.com/questions/27324066/weird-results-with-the-randomforest-r-package</guid>
      <pubDate>Fri, 05 Dec 2014 20:21:16 GMT</pubDate>
    </item>
    </channel>
</rss>