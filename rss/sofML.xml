<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 23 Jul 2024 21:17:23 GMT</lastBuildDate>
    <item>
      <title>为什么我的 RNN 不能收敛到一个简单的任务？</title>
      <link>https://stackoverflow.com/questions/78784723/why-my-rnn-does-not-converge-to-a-simple-task</link>
      <description><![CDATA[我想创建一个递归模型来解决我所知道的最简单的序列，算术级数。以 a 为基数，以 d 为步长，序列如下：
a、a+d、a+2d、a+3d、a+4d、...
为了解决这个问题，将隐藏状态表示为 h，模型必须学习一个简单的 2*2 矩阵。这实际上是设置 h1 = t0。

换句话说，你也可以这样看：

所以这个带有 2*2 全连接层的模型应该能够学习这个矩阵：
class Model(nn.Module):
def __init__(self):
super(Model, self).__init__()
self.fc1 = nn.Linear(2, 2, bias=False)

def forward(self, x):
x = self.fc1(x)
return x

但令我惊讶的是它并没有收敛！我的设置应该有问题。如果你能帮我找到它，我将不胜感激。我怀疑问题应该出在我的训练循环中。
附言：我现在故意将批处理大小设置为 1。我想稍后再处理输入数据。无论如何，模型应该可以在没有批次的情况下进行学习。
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np

class CustomDataset(Dataset):
def __init__(self, size):
self.size = size

def __len__(self):
return self.size

def __getitem__(self, index):
a0 = (np.random.rand() - 0.5) * 200
d = (np.random.rand() - 0.5) * 40
length = np.random.randint(2, MAX_Length_sequence + 1)

serial = np.arange(length) * d + a0
next_number = serial[-1] + d

return length, torch.tensor(sequence, dtype=torch.float32), torch.tensor(next_number, dtype=torch.float32)

class Model(nn.Module):
def __init__(self):
super(Model, self).__init__()
self.fc1 = nn.Linear(2, 2, bias=False)

def forward(self, x):
x = self.fc1(x)
return x

# 超参数
EPOCHS = 10
BATCH_SIZE = 1
LEARNING_RATE = 0.001
DATASET_SIZE = 10000
criterion = nn.MSELoss()

# 模型
model = Model()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)


我的训练循环：
for epoch in范围（EPOCHS）：
数据集 = CustomDataset（DATASET_SIZE）
数据加载器 = DataLoader（数据集，batch_size=BATCH_SIZE）
模型。训练（）
总损失 = 0

对于长度、序列、数据加载器中的下一个编号：
优化器。zero_grad（）
损失 = 0
h = torch.zeros（BATCH_SIZE）

对于范围（长度）中的 i：
x = torch.cat（[h，sequence[0，i].unsqueeze(0)])
y = 序列[0，i + 1] 如果 i != length - 1 else next_number[0]

输出 = 模型（x）
h，y_hat = output[0].unsqueeze(0), output[1]

损失 += 标准（y_hat，y）

损失。backward（）
优化器。step（）
总损失 += 损失。item（）

打印（f&#39;Epoch {epoch+1}，损失：{total_loss/len(dataloader)}&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78784723/why-my-rnn-does-not-converge-to-a-simple-task</guid>
      <pubDate>Tue, 23 Jul 2024 16:59:29 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型根据饮食日志预测营养缺乏症 [关闭]</title>
      <link>https://stackoverflow.com/questions/78784634/machine-learning-model-to-predict-nutritional-deficiencies-from-dietary-logs</link>
      <description><![CDATA[开发一个机器学习模型，整合饮食数据，及时预测营养缺乏症。这是我正在研究的事情，我认为它很有潜力。我需要两方面的帮助。首先，我能否找到一个可以重新利用的基本 ML 模型，以及我可以从哪里获得数据来训练 ML。
我确实找到了一份数据，其中记录了患者被给予的实际食物、分类数据和他们所患的疾病。但我似乎找不到一个模型和方法来整合这些数据。]]></description>
      <guid>https://stackoverflow.com/questions/78784634/machine-learning-model-to-predict-nutritional-deficiencies-from-dietary-logs</guid>
      <pubDate>Tue, 23 Jul 2024 16:34:21 GMT</pubDate>
    </item>
    <item>
      <title>HPCC 系统 ECL：使用 LinearRegression 时出现访问权限不足错误</title>
      <link>https://stackoverflow.com/questions/78784047/hpcc-systems-ecl-insufficient-access-rights-error-using-linearregression</link>
      <description><![CDATA[我正在使用 HPCC Systems 和 ECL 进行机器学习项目以执行线性回归。我的数据集包含心理健康患病率数据。在尝试使用 LinearRegression.OLS 训练我的模型时，我遇到了以下错误：
错误：访问权限不足，无法使用嵌入代码（125，34 - C:\Users\LENOVO\AppData\Roaming\HPCCSystems\bundles_versions\PBblas\V3_0_2\PBblas\internal\Converted.ecl）
这意味着包含在 ECL 脚本中的代码需要特殊权限或访问级别才能运行。
错误指向 HPCC Systems 安装中的特定文件，在本例中是 PBblas 库 (Converted.ecl) 的一部分。
我的代码：
``IMPORT ML_Core;
IMPORT LinearRegression;
IMPORT $;

// 输入数据集的记录结构
MentalHealthRecord := RECORD
STRING Entity;
STRING Code;
INTEGER Year;
REAL8 Schizophrenia;
REAL8 Depression;
REAL8 Anxiety;
REAL8 Bipolar;
REAL8 EatingDisorders;
END;

// 根据记录输入数据集
MentalHealthDs := DATASET(&#39;~asn::testing::1-mental-illnesses-prevalence.csv&#39;,
MentalHealthRecord,
CSV(HEADING(1),
SEPARATOR(&#39;,&#39;),
TERMINATOR([&#39;\n&#39;, &#39;\r\n&#39;, &#39;\n\r&#39;])));

OUTPUT(MentalHealthDs, NAMED(&#39;InputDataset&#39;));

// 数据集中的记录数。训练：测试的分割比率，以小数表示。
recordCount := COUNT(MentalHealthDs);
splitRatio := 0.8; // 80% 用于训练，20% 用于测试

// 继承包含随机数的数据集记录的记录结构
Shuffler := RECORD
MentalHealthRecord;
UNSIGNED4 rnd; // 随机数
END;

// 向包含随机数的数据添加属性
newDs := PROJECT(MentalHealthDs, TRANSFORM(Shuffler, SELF.rnd := RANDOM(), SELF := LEFT));

// 根据随机数对数据集进行排序，进行随机排序
shuffledDs := SORT(newDs, rnd);

// 分割训练和测试数据集，同时仅采用输入记录属性
TrainDs := PROJECT(shuffledDs[1..(recordCount * splitRatio)], RECORDOF(MentalHealthDs));
TestDs := PROJECT(shuffledDs[(recordCount * splitRatio + 1)..recordCount], RECORDOF(MentalHealthDs));

OUTPUT(TrainDs, NAMED(&#39;TrainDataset&#39;));
OUTPUT(TestDs, NAMED(&#39;TestDataset&#39;));

// 将顺序 ID 附加到训练和测试数据集
ML_Core.AppendSeqID(TrainDs, id, newTrain);
ML_Core.AppendSeqID(TestDs, id, newTest);

OUTPUT(newTrain, NAMED(&#39;TrainDatasetID&#39;));
OUTPUT(newTest, NAMED(&#39;TestDatasetID&#39;));

// 将数据集转换为数字字段以进行训练
ML_Core.ToField(newTrain, TrainNF);
ML_Core.ToField(newTest, TestNF);

OUTPUT(TrainNF, NAMED(&#39;TrainNumericField&#39;));
OUTPUT(TestNF, NAMED(&#39;TestNumericField&#39;));

// 根据独立列的数量拆分转换后的数字字段数据集以获取用于训练的 X 和 Y 
independent_cols := 4; // 精神分裂症、焦虑症、躁郁症、饮食失调

X_train := TrainNF(number &lt; independent_cols + 1);
y_train := PROJECT(TrainNF(number = independent_cols + 1), TRANSFORM(RECORDOF(LEFT), SELF.number := 1, SELF := LEFT));

X_test := TestNF(number &lt; independent_cols + 1);
y_test := PROJECT(TestNF(number = independent_cols + 1), TRANSFORM(RECORDOF(LEFT), SELF.number := 1, SELF := LEFT));

OUTPUT(y_test, NAMED(&#39;ActualY&#39;));

// 通过拟合模型构建回归器并使用测试数据集进行预测
regressor := LinearRegression.OLS(X_train, y_train).GetModel;
predicted := LinearRegression.OLS().Predict(X_test, regressor);

OUTPUT(predicted, NAMED(&#39;PredictedY&#39;));
``

我已检查我的访问权限，但问题仍然存在。
我希望了解为什么我会收到“访问权限不足”错误以及如何解决它。
如何正确使用 LinearRegression.OLS 来训练模型？
HPCC Systems ECL 中是否有其他方法或配置可以执行线性回归而不会遇到访问权限问题？
如果有人可以指导我完成这项工作，那将是一个很大的帮助。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78784047/hpcc-systems-ecl-insufficient-access-rights-error-using-linearregression</guid>
      <pubDate>Tue, 23 Jul 2024 14:29:53 GMT</pubDate>
    </item>
    <item>
      <title>pointnet++的实现</title>
      <link>https://stackoverflow.com/questions/78783587/implementation-of-pointnet</link>
      <description><![CDATA[这是我的错误。我已经实现了所有代码，但得到的结果是这样的。掩码张量的形状与被索引的张量的形状不匹配。具体来说，掩码张量的形状为 [8, 512, 3]，而被索引的张量的形状为 [8, 512, 16]。我不知道如何解决这个问题。请给我一些逻辑，或者我应该如何继续，因为我已经使用了 chatgpt，但我也找不到答案
/usr/bin/python3.10 /home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/centerline_pn.py 
回溯（最近一次调用最后一次）：
文件“/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/centerline_pn.py”，第 265 行，位于 &lt;module&gt;
main()
文件 &quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/centerline_pn.py&quot;，第 217 行，在 main
输出，_ = model(points)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1532 行，在 _wrapped_call_impl
返回 self._call_impl(*args, **kwargs)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1541 行，在 _call_impl
返回 forward_call(*args, **kwargs)
文件&quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/models/pointnet2_cls_msg.py&quot;，第 32 行，在 forward 中
l1_xyz, l1_points = self.sa1(xyz, norm)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1532 行，在 _wrapped_call_impl 中
return self._call_impl(*args, **kwargs)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1541 行，在 _call_impl 中
return forward_call(*args, **kwargs)
文件&quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/models/pointnet2_utils.py&quot;，第 283 行，在 forward 中
group_idx = query_ball_point(radius, K, xyz, new_xyz)
文件 &quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/models/pointnet2_utils.py&quot;，第 148 行，在 query_ball_point 中
group_idx[mask] = group_first[mask]
IndexError：索引 2 处的掩码 [8, 512, 3] 的形状与索引 2 处的索引张量 [8, 512, 16] 的形状不匹配

进程以退出代码 1 结束


def query_ball_point(radius, nsample, xyz, new_xyz):
&quot;&quot;&quot;
输入：
radius：局部区域半径
nsample：局部区域最大样本数
xyz：所有点，[B, N, 3]
new_xyz：查询点，[B, S, 3]
返回：
group_idx：分组点索引，[B, S, nsample]
&quot;&quot;&quot;
device = xyz.device
B, N, C = xyz.shape
_, S, _ = new_xyz.shape
group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])
sqrdists = square_distance(new_xyz, xyz)
group_idx[sqrdists &gt; radius ** 2] = N
group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]
group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])
mask = group_idx == N
group_idx[mask] = group_first[mask]
return group_idx

def square_distance(src, dst):
&quot;&quot;&quot;
计算每两点之间的欧几里得距离。

src^T * dst = xn * xm + yn * ym + zn * zm；
sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;
sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;
dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2
= sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst

输入：
src：源点，[B, N, C]
dst：目标点，[B, M, C]
输出：
dist：每个点的平方距离，[B, N, M]
&quot;&quot;&quot;
B, N, _ = src.shape
_, M, _ = dst.shape
dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))
dist += torch.sum(src ** 2, -1).view(B, N, 1)
dist += torch.sum(dst ** 2, -1).view(B, 1, M)
返回 dist

]]></description>
      <guid>https://stackoverflow.com/questions/78783587/implementation-of-pointnet</guid>
      <pubDate>Tue, 23 Jul 2024 12:58:50 GMT</pubDate>
    </item>
    <item>
      <title>多输出回归可根据 ROAS 和其他功能预测成本和收入</title>
      <link>https://stackoverflow.com/questions/78783100/multi-output-regression-to-predict-cost-and-revenue-from-roas-and-other-features</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78783100/multi-output-regression-to-predict-cost-and-revenue-from-roas-and-other-features</guid>
      <pubDate>Tue, 23 Jul 2024 11:10:59 GMT</pubDate>
    </item>
    <item>
      <title>将图像缓存到 RAM 中并使用并行化将图像解码为张量以快速加载数据的最快方法是什么？</title>
      <link>https://stackoverflow.com/questions/78782747/fastest-way-to-cache-images-into-ram-and-use-parallelization-to-decode-images-as</link>
      <description><![CDATA[我有一个包含 8000 张图像的大数据集，磁盘上大约有 1 GB，我正在加载一些数据来训练图像模型
但是，当您将它们转换为图像张量时，图像现在会占用大量内存（例如，100 张高清图像作为 float32 pytorch 张量占用 24GB）。
如果您将它们保存为磁盘，数据加载器每次都必须从磁盘读取，这在我的用例中是一个巨大的时间消耗。 （要形成一批 100 张图像，在我的设置下从磁盘读取大约需要 700 毫秒，但理想情况下我需要将此时间缩短至少 50%）
我想将这些 jpeg 缓存到 RAM，然后使用多个并行工作器对它们进行解码以形成图像批次，将磁盘密集型任务转移到 CPU 绑定的图像解码（由于存在多处理，因此生成图像批次的速度会快得多）
我当前的解决方案如下：
在我的数据集类中，子类化 torch.utils.data.Dataset，在构造函数 init 方法中，我使用以下命令打开了每个图像文件：
for image_filename in image_filenames:
with open(image_filename, &#39;rb&#39;) as f:
self.binary_images.append(io.BytesIO(f.read()))

然后我的__get_item__(image_idx) 方法使用 PIL 的
Image.open(binary_images[image_idx])

打开文件，然后将其转换为 numpy 张量，然后使用 torch.from_numpy 返回张量
这个想法是否正确实现？我实际上没有注意到任何令人担忧的速度提升......此外，我的 1 GB 图像 jpeg 是否以 1 GB 的总容量加载到 RAM 中（使用此二进制字符串方法不会消耗过多的 RAM），还有哪些其他方法可以加快速度？
注意：请不要让我使用 FFCV，因为我有一个非常独特的问题，无法用 ffcv 解决]]></description>
      <guid>https://stackoverflow.com/questions/78782747/fastest-way-to-cache-images-into-ram-and-use-parallelization-to-decode-images-as</guid>
      <pubDate>Tue, 23 Jul 2024 09:45:50 GMT</pubDate>
    </item>
    <item>
      <title>MediaPipe 手势检测中的抖动</title>
      <link>https://stackoverflow.com/questions/78782336/jitter-in-mediapipe-hand-pose-detection</link>
      <description><![CDATA[使用 Python、OpenCV 和 MediaPipe，我编写了以下代码：
import mediapipe as mp
import cv2

# 初始 MediaPipe 手部检测
mp_hand = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hand.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)

# 初始网络摄像头读取
cap = cv2.VideoCapture(0)
assert cap.isOpened(), &quot;Camera not found&quot;

while cap.isOpened():
# 从网络摄像头读取图像
成功，img = cap.read()
如果失败：
break

# 将图像颜色从 BGR 转换为 RGB
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# 通过 MediaPipe 检测手
results = hands.process(img_rgb)

# 绘制手部标志
if results.multi_hand_landmarks:
for hand_landmarks in results.multi_hand_landmarks:
mp_drawing.draw_landmarks(img, hand_landmarks, mp_hand.HAND_CONNECTIONS)

# 显示结果
cv2.imshow(&#39;webcam&#39;, img)

if cv2.waitKey(1) &amp; 0xff == ord(&#39;q&#39;):
break

# 释放资源
cap.release()
cv2.destroyAllWindows()

输出：

我想在检测过程中防止这种轻微的振动。我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/78782336/jitter-in-mediapipe-hand-pose-detection</guid>
      <pubDate>Tue, 23 Jul 2024 08:18:46 GMT</pubDate>
    </item>
    <item>
      <title>使用数组作为特征/独立变量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78781575/using-an-array-as-a-feature-independent-variable</link>
      <description><![CDATA[假设我有一个数据框：

主题 ID (int)
年龄 (int)
性别 (int 1- 代表男性，2- 代表女性)
Pearson CC 表示功能网络 (矩阵)

这意味着我有一个 PearsonCC 数组数组。例如：



p_id
性别
PearsonCorrelationCoefficient




128_S_0200
M
[0.5052435694128596, 0.3375816208945487, 0.206...


003_S_0908
F
[-0.18955977794142087, 0.01652734870786999, -0...


141_S_1052
F
[0.0562331642358682, 0.5698911953687733, -0.17... -0...



所以我明白我们需要展平矩阵/矢量化上三角以将数据处理成一维数组。但是，有没有什么方法可以将这个一维数组用作我的 ML 模型的特征/预测器？
我知道我们可以将一维数组转换为单独的列，但这会导致近 5000 列（矢量化矩阵的每个数组长度为 4950）。我也知道我们可以通过 PCA 等技术降低维数，但我不太确定是否要摆脱原始矩阵中的重要连接。
还有其他方法可以解决这个问题吗？
任何帮助都将不胜感激！
如果我使用 sklearn 的 Logistic 回归：
model = LogisticRegression(max_iter=1000)
model.fit(X_train_final, y_train)
我收到一个错误，表明 PearsonCC 列可能不被接受为数组 &amp;只能是 int/float 才能适合：
TypeError Traceback（最近一次调用最后一次）
TypeError：只有 size-1 数组才能转换为 Python 标量
]]></description>
      <guid>https://stackoverflow.com/questions/78781575/using-an-array-as-a-feature-independent-variable</guid>
      <pubDate>Tue, 23 Jul 2024 04:35:17 GMT</pubDate>
    </item>
    <item>
      <title>更改 YoloV8 分割颜色</title>
      <link>https://stackoverflow.com/questions/78776522/change-yolov8-segmentation-color</link>
      <description><![CDATA[我是 YoloV8 训练任务的新手，想了解如何更改模型执行的分割颜色。
如果有人有一些代码示例并可以分享，请分享。
任何帮助指导我的帮助都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78776522/change-yolov8-segmentation-color</guid>
      <pubDate>Sun, 21 Jul 2024 23:11:03 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark MLlib 自定义 Transformer 类 -AttributeError:'DummyMod' 对象没有属性 'MyTransformer'</title>
      <link>https://stackoverflow.com/questions/78665992/pyspark-mllib-custom-transformer-class-attributeerror-dummymod-object-has-no</link>
      <description><![CDATA[我正在尝试创建一个自定义转换器作为管道中的一个阶段。一些转换我通过 SparkNLP 进行，接下来的几个转换使用 MLlib。要将某个阶段的 SparkNLP 转换结果传递给下一个 MLlib 转换，我需要提取 spark_nlp_col.result 列并传递它，为此我使用了自定义转换阶段。
在我安装好管道后，我可以将其持久化，但当我再次加载它时，我收到错误：
AttributeError：&#39;DummyMod&#39; 对象没有属性 &#39;MyTransformer&#39;
这是我的课程：
从 pyspark.ml 导入 Transformer
从 pyspark.ml.param.shared 导入 Param、Params、TypeConverters

class MyTransformer(Transformer、DefaultParamsWritable、DefaultParamsReadable):
inputCol = Param(Params._dummy(), &quot;inputCol&quot;, &quot;&quot;,TypeConverters.toString)
outputCol = Param(Params._dummy(), &quot;outputCol&quot;, &quot;&quot;,TypeConverters.toString)

def __init__(self,inputCol=None,outputCol=None):
super(MyTransformer, self).__init__()
self._setDefault(inputCol=None)
self._set(inputCol = inputCol)
self._setDefault(outputCol=None)
self._set(outputCol = outputCol)

def getInputCol(self):
return self.getOrDefault(self.inputCol)

def setInputCol(self, inputCol):
self._set(inputCol=inputCol)

def getOutputCol(self):
return self.getOrDefault(self.outputCol)

def setOutputCol(self, outputCol):
self._set(outputCol=outputCol)

def _transform(self, dataset):
in_col = self.getInputCol()
out_col = self.getOutputCol()

final_in_col = in_col+&quot;.result&quot;
result = dataset.withColumn(out_col, dataset[final_in_col])
返回结果

我已在其上创建了一个简单的包装函数以进行标准化，然后使用它来创建管道、拟合并保存它：
def extract_col(cols, in_suffix, out_suffix):
return [MyTransformer(inputCol=col+in_suff, outputCol=col+out_suffix) for col in cols]

自定义转换器之前的阶段数

extractors = extract_col(cols, &quot;_in&quot;, &quot;_out&quot;)

自定义转换器之后的阶段数

stages = s1 + s2 + .. + extractors + .. + snlast + sn
pipeline = Pipeline(stages = periods)
fit_pipeline = pipeline.fit(data)
fit_pipeline.write().overwrite().save(&quot;path_to_store_at&quot;)

我如何读回它：
saved_pipeline = PipelineModel.load(&quot;path_where_stored&quot;)

然后我遇到了错误。
我尝试了多种编写自定义类的方法，使用 HasInputCol、HasOutputCol 等，但到目前为止都没有效果。
有什么想法可以解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/78665992/pyspark-mllib-custom-transformer-class-attributeerror-dummymod-object-has-no</guid>
      <pubDate>Tue, 25 Jun 2024 07:42:56 GMT</pubDate>
    </item>
    <item>
      <title>Visual Studio Code 中的 PyLance 无法识别 TensorFlow.keras 命名空间</title>
      <link>https://stackoverflow.com/questions/78419755/tensorflow-keras-namespace-not-recognized-by-pylance-in-visual-studio-code</link>
      <description><![CDATA[我在 Visual Studio Code 中使用 PyLance 时遇到问题，无法识别 tensorflow.keras 命名空间，导致 IntelliSense 和自动完成不完整。这个问题似乎源于 TensorFlow 使用的延迟加载功能 (_KerasLazyLoader)，用于推迟加载不必要的包，直到需要它们为止。
我搜索了有关此主题的现有问题，但我发现的最新讨论可以追溯到 2023 年末。此外，提出的解决方案主要涉及可能长期不可靠的解决方法。
是否有官方解决方案可以确保 PyLance 正确识别 tensorflow.keras 命名空间？我无法想象延迟加载通常会破坏 VSCode intellisense（尽管我肯定可能是错的）。或者，是否有任何强大的解决方法不太可能在未来的更新中中断？如有任何见解或指导，我们将不胜感激。
软件：
MacOS Sonoma 14.1.2
Python 3.12
tensorflow 2.16.1
对之前发布的问题/问题的引用：

https://github.com/microsoft/pylance-release/issues/3249
VSCode 自动完成和建议（IntelliSense）不适用于 Tensorflow 和 Keras 库？
https://community.deeplearning.ai/t/unable-to-import-tensorflow-keras-pylinte0401-import-error-in-visual-studio-code/512586
https://jagaimox.wordpress.com/2020/12/28/configure-python-intellisense-on-vscode-for-tensorflow-1-14-or-1-15/ (tensorflow 1.14/1.15)

我尝试了上述链接中的几个解决方案，但它们对我来说不起作用。其中一些可能需要一些额外的配置，而我并没有这样做（例如，一个在 tensorflow.init 中引用了 _typing，但尚未定义 _typing - 可能已过时）。]]></description>
      <guid>https://stackoverflow.com/questions/78419755/tensorflow-keras-namespace-not-recognized-by-pylance-in-visual-studio-code</guid>
      <pubDate>Thu, 02 May 2024 14:11:58 GMT</pubDate>
    </item>
    <item>
      <title>这个 elasticsearch 设置甚至使用 ML 节点吗？</title>
      <link>https://stackoverflow.com/questions/77923033/does-this-elasticsearch-setup-even-use-ml-node</link>
      <description><![CDATA[我按照此示例设置了 Elasticsearch 集群以进行图像相似性搜索：https://github.com/radoondas/flask-elastic-image-search
由于不熟悉 elasticsearch，我盲目地遵循了这个示例，其中包括一个带有预训练模型的 ML 节点。它运行良好。但是，我怀疑我们实际上并没有使用 ML 节点。
我提取应用程序中的密集向量，然后对它们进行索引，并且在查询时也提取应用程序中的向量。我不使用 elasticsearch 来提取密集向量。
当我索引密集向量或执行 KNN 查询时，是否有任何“魔法”可以让 elasticsearch 在后台使用预训练模型？或者预训练模型和 ML 节点都是我们实现中不需要的额外东西？]]></description>
      <guid>https://stackoverflow.com/questions/77923033/does-this-elasticsearch-setup-even-use-ml-node</guid>
      <pubDate>Thu, 01 Feb 2024 20:00:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Tensorflow/keras 上添加 InstanceNormalization</title>
      <link>https://stackoverflow.com/questions/68088889/how-to-add-instancenormalization-on-tensorflow-keras</link>
      <description><![CDATA[我是 TensorFlow 和 Keras 的新手，我一直在制作扩张的 resnet，并想在层上添加实例规范化，但我做不到，因为它一直抛出错误。
我正在使用 tensorflow 1.15 和 keras 2.1。我注释掉了可以工作的 BatchNormalization 部分，并尝试添加实例规范化，但找不到模块。
非常感谢您的建议


来自 keras.layers 导入 Conv2D
来自 keras.layers.normalization 导入 BatchNormalization
来自 keras.optimizers 导入 Nadam、Adam
来自 keras.layers 导入 Input、Dense、Reshape、Activation、Flatten、Embedding、Dropout、Lambda、add、concatenate、Concatenate、ConvLSTM2D、LSTM、average、MaxPooling2D、multiply、MaxPooling3D
来自 keras.layers 导入 GlobalAveragePooling2D、Permute
来自 keras.layers.advanced_activations 导入 LeakyReLU、PReLU
来自 keras.layers.convolutional 导入 UpSampling2D、Conv2D、 Conv1D
从 keras.models 导入 Sequential、Model
从 keras.utils 导入 multi_gpu_model
从 keras.utils.generic_utils 导入 Progbar
从 keras.constraints 导入 maxnorm
从 keras.activations 导入 tanh、softmax
从 keras 导入 metrics、initializers、utils、regularizers
将 tensorflow 导入为 tf
将 numpy 导入为 np
导入 math
导入 os
导入 sys
导入 random
将 keras.backend 导入为 K
epsilon = K.epsilon()

def basic_block_conv2D_norm_elu(filters、kernel_size、kernel_regularizer=regularizers.l2(1e-4)、act_func=&quot;elu&quot;、normalize=&quot;Instance&quot;、dropout=&#39;0.15&#39;,
strides=1、use_bias = True,kernel_initializer = &quot;he_normal&quot;,_dilation_rate=0):
def f(input):
if kernel_regularizer == None:
if _dilation_rate == 0:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
padding=&quot;same&quot;, use_bias=use_bias)(input)
else:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
padding=&quot;same&quot;, use_bias=use_bias,dilation_rate=_dilation_rate)(input)
else:
if _dilation_rate == 0:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
kernel_initializer=kernel_initializer, padding=&quot;same&quot;, use_bias=use_bias,
kernel_regularizer=kernel_regularizer)(输入)
else:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
kernel_initializer=kernel_initializer, padding=&quot;same&quot;, use_bias=use_bias,
kernel_regularizer=kernel_regularizer, dilation_rate=_dilation_rate)(输入)
if dropout != None:
dropout_layer = Dropout(0.15)(conv)

if normalize == None 且 dropout != None:
norm_layer = conv(dropout_layer)
else:
norm_layer = InstanceNormalization()(dropout_layer)
# norm_layer = BatchNormalization()(dropout_layer)
return激活（act_func）（norm_layer）
返回 f
]]></description>
      <guid>https://stackoverflow.com/questions/68088889/how-to-add-instancenormalization-on-tensorflow-keras</guid>
      <pubDate>Tue, 22 Jun 2021 18:14:05 GMT</pubDate>
    </item>
    <item>
      <title>没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块</title>
      <link>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</link>
      <description><![CDATA[代码下方
import numpy as np
np.random.seed(0)
from sklearn import datasets
import matplotlib.pyplot as plt
%matplotlib inline
%config InlineBackend.figure_format =&#39;retina&#39;

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD

错误消息下方
-------------------------------------------------------------------------------
ModuleNotFoundError Traceback (most recent call last)
~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
2 try:
----&gt; 3 from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
4 except ImportError:

ModuleNotFoundError: 没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块

在处理上述异常期间，发生了另一个异常：

ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-5-943507dd87a6&gt; in &lt;module&gt;
6 get_ipython().run_line_magic(&#39;config&#39;, &quot;InlineBackend.figure_format =&#39;retina&#39;&quot;)
7 
----&gt; 8 从 keras.models 导入 Sequential
9 从 keras.layers 导入 Dense
10 从 keras.optimizers 导入 SGD

~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
4 except ImportError:
5 raise ImportError(
----&gt; 6 &#39;Keras 需要 TensorFlow 2.2 或更高版本。&#39;
7 &#39;通过 `pip install tensorflow`&#39; 安装 TensorFlow)
8 

ImportError: Keras 需要 TensorFlow 2.2 或更高版本。通过 `pip install tensorflow` 安装 TensorFlow

注意：`我认为，主要问题是 Tensorflow 版本。我使用了一些命令，如下所示，
conda create -n tf tensorflow
conda activate tf

我还使用了以下命令
conda create -n tf-gpu tensorflow-gpu
conda activate tf-gpu

但是它不起作用，请帮助解决错误。]]></description>
      <guid>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</guid>
      <pubDate>Sun, 23 Aug 2020 02:18:29 GMT</pubDate>
    </item>
    <item>
      <title>在 MultiLabelBinarizer 中获取计数</title>
      <link>https://stackoverflow.com/questions/56372324/getting-counts-in-multilabelbinarizer</link>
      <description><![CDATA[如何获取 MultiLabelBinarizer 中的项目数？
import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
mlb = MultiLabelBinarizer()

pd.DataFrame(mlb.fit_transform([(1,1,2), (3,3,2,5)]),columns=mlb.classes_)

Out[0]: 
1 2 3 5
0 1 1 0 0
1 0 1 1 1

与此相反，我想要获取
Out[0]: 
1 2 3 5
0 2 1 0 0
1 0 1 2 1

因为 1 在第 1 行重复 2 次，而 3 在第 1 行重复 2 次]]></description>
      <guid>https://stackoverflow.com/questions/56372324/getting-counts-in-multilabelbinarizer</guid>
      <pubDate>Thu, 30 May 2019 05:47:14 GMT</pubDate>
    </item>
    </channel>
</rss>