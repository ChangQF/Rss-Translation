<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 03 Dec 2023 15:12:53 GMT</lastBuildDate>
    <item>
      <title>如何修复我的感知器来识别数字？</title>
      <link>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</guid>
      <pubDate>Sun, 03 Dec 2023 14:03:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 svm 进行高光谱图像分类</title>
      <link>https://stackoverflow.com/questions/77594411/hyperspectral-image-classification-using-svm</link>
      <description><![CDATA[Google 协作文件链接 -
导入 pandas 作为 pd
将 numpy 导入为 np
导入操作系统
从 sklearn.impute 导入 SimpleImputer
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 precision_score
从 imblearn.over_sampling 导入 SMOTE
从 imblearn.under_sampling 导入 RandomUnderSampler



# CSV 文件所在的目录
目录 = &#39;驱动器/我的驱动器/StO2_mat(size513_911)/&#39;

# 初始化空列表来存储数据和文件名
数据数组 = []
文件名 = []

# 循环遍历目录下的所有CSV文件
对于 os.listdir（目录）中的文件名：
    if filename.endswith(&#39;.csv&#39;):
        file_path = os.path.join(目录, 文件名)
        df = pd.read_csv(文件路径)
        data_array = df.values.ravel()
        data_arrays.append(data_array)
        file_names.append(文件名)

# 从一维 NumPy 数组列表创建一个 DataFrame
数据 = pd.DataFrame(data_arrays)

# 添加“目标列”包含原始文件名
数据[&#39;目标列&#39;] = 文件名

# 检查是否有足够的唯一样本用于分割
if len(data[&#39;target_column&#39;].unique()) &lt;= 1:
    print(“没有足够的唯一样本用于训练-测试分割。”)
别的：
    # 分离非数字和数字数据列
    non_numeric_data = data.select_dtypes(&#39;字符串&#39;)
    numeric_data = data.select_dtypes(include=[&#39;number&#39;])

    # 估算数值数据中的缺失值
    imputer = SimpleImputer(策略=&#39;均值&#39;)
    numeric_data_impulated = imputer.fit_transform(numeric_data)
    numeric_data_impulated_df = pd.DataFrame(numeric_data_impulated)

    # 合并非数值数据和估算数值数据
    impulated_data = pd.concat([non_numeric_data, numeric_data_impulated_df], axis=1)

    # 将数据分为训练集和测试集
    X_train, X_test, y_train, y_test = train_test_split(impulated_data.drop(&#39;target_column&#39;, axis=1), impulated_data[&#39;target_column&#39;], test_size=0.1, random_state=42)

   # 将 SMOTE 应用于训练数据
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

    # 使用 RandomForestClassifier （如您的示例中所示）
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train_resampled, y_train_resampled)

    # 对测试数据进行预测
    y_pred = clf.predict(X_test)

    # 评估模型性能
    准确度=准确度_得分(y_test, y_pred)
    print(&#39;准确度：&#39;, 准确度)

对于此代码，我遇到错误，没有足够独特的样本用于训练测试分割。如何解决此问题。
我尝试了欠采样、不同的ckassifiers，如svm、knn和随机森林分类器（对数据imabalance不太敏感）。仍然无法解决该错误。]]></description>
      <guid>https://stackoverflow.com/questions/77594411/hyperspectral-image-classification-using-svm</guid>
      <pubDate>Sun, 03 Dec 2023 13:04:03 GMT</pubDate>
    </item>
    <item>
      <title>代理收集 10 个产品并返回 12x11 矩阵中的起点时出现问题</title>
      <link>https://stackoverflow.com/questions/77594273/issue-with-agent-collecting-10-products-and-returning-to-starting-point-in-a-12x</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594273/issue-with-agent-collecting-10-products-and-returning-to-starting-point-in-a-12x</guid>
      <pubDate>Sun, 03 Dec 2023 12:24:25 GMT</pubDate>
    </item>
    <item>
      <title>人工智能-儿童人工智能[关闭]</title>
      <link>https://stackoverflow.com/questions/77594032/artificial-intelligence-child-ais</link>
      <description><![CDATA[一个人工智能可以构建另一个人工智能——子人工智能吗？
自动化机器学习
是的，人工智能可以被编程来生成代码或设计另一个人工智能系统。此过程涉及使用自动代码生成、机器学习和神经架构搜索等技术。自动代码生成涉及编写算法或使用模板来创建新程序或模型。机器学习可用于训练模型，该模型可以根据现有代码库中的模式和示例生成代码。
神经架构搜索 (NAS) 是一种特定方法，其中人工智能算法用于探索和发现给定任务的最佳神经网络架构。 NAS 可以自动化神经网络的设计，神经网络是人工智能系统的关键组成部分。
总之，通过采用各种编程和机器学习技术，可以开发一个人工智能来构建另一个人工智能。然而，值得注意的是，虽然人工智能可以协助创建新的人工智能系统，但通常需要人类专业知识来定义正在生成的人工智能的目标、约束和参数，以及评估和完善结果。&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77594032/artificial-intelligence-child-ais</guid>
      <pubDate>Sun, 03 Dec 2023 11:16:35 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：这两个结构没有相同的嵌套结构。加载 roberta 模型时</title>
      <link>https://stackoverflow.com/questions/77593802/valueerror-the-two-structures-dont-have-the-same-nested-structure-while-loadi</link>
      <description><![CDATA[我使用了以下罗伯塔情感模型，并将其微调到我的文本数据。
roberta_model = TFAutoModelForSequenceClassification.from_pretrained(&#39;cardiffnlp/twitter-roberta-base-sentiment&#39;)

tokenizer = AutoTokenizer.from_pretrained(&#39;cardiffnlp/twitter-roberta-base-sentiment&#39;)
tokenized_data = tokenizer(list(df[&#39;text&#39;]), padding=True, return_tensors=&#39;np&#39;)
tokenized_data = dict(tokenized_data)

def get_model(罗伯塔_模型):
  input_ids = 输入（形状=（无，），dtype=&#39;int32&#39;，名称=&#39;input_ids&#39;）
  注意掩码=输入（形状=（无，），dtype=&#39;int32&#39;，名称=&#39;注意掩码&#39;）
  罗伯塔输出=罗伯塔模型（输入ID，注意掩码=注意掩码）[0]
  输出=密集（32，激活=&#39;relu&#39;）（roberta_outputs）
  输出=密集（3，激活=&#39;softmax&#39;）（输出）
  模型= tf.keras.Model（输入= [input_ids，attention_mask]，输出=输出）
  返回模型

模型 = get_model(罗伯塔_模型)
model.compile(优化器=Adam(3e-5)，指标= [&#39;准确性&#39;]，损失=&#39;sparse_categorical_crossentropy&#39;)
历史= model.fit（tokenized_data，y，validation_split = 0.2，epochs = 5）

当我使用以下方式保存模型时：
model.save(&#39;/content/mymodel&#39;)

并使用以下命令重新加载模型：
model = keras.models.load_model(&#39;/content/mymodel&#39;)

它显示此错误：
ValueError：两个结构没有相同的嵌套结构。

我尝试过将其保存为 h5 和 keras 格式。上述问题是当前的问题。有时在它给我一个错误 str object is not callable 之前。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77593802/valueerror-the-two-structures-dont-have-the-same-nested-structure-while-loadi</guid>
      <pubDate>Sun, 03 Dec 2023 10:04:12 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：“decode_predictions”需要一批预测（即形状的二维数组（样本，1000））。找到形状数组：（无，4）[关闭]</title>
      <link>https://stackoverflow.com/questions/77591793/valueerror-decode-predictions-expects-a-batch-of-predictions-i-e-a-2d-array</link>
      <description><![CDATA[当我通过decode_prediction时，它返回数组形状
从 keras.applications.vgg16 导入 preprocess_input,decode_predictions
预测 = vgg16model.predict(preprocessed_image)
decoded_predictions=decode_predictions(预测, top=3)[0]]]></description>
      <guid>https://stackoverflow.com/questions/77591793/valueerror-decode-predictions-expects-a-batch-of-predictions-i-e-a-2d-array</guid>
      <pubDate>Sat, 02 Dec 2023 19:01:27 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在没有 pytorch 包的环境中保存 pytorch 模型？</title>
      <link>https://stackoverflow.com/questions/77591558/is-there-a-way-to-save-the-pytorch-model-for-environment-without-pytorch-package</link>
      <description><![CDATA[我们正在训练一个小型最小依赖软件的模型。开发人员拒绝将 PyTorch 纳入其独立性中。
有没有一种方法可以保存 pytorch 模型，以便他们可以在没有 PyTorch 的情况下加载模型？或者将模型编译成静态/动态库？
训练部分
导入火炬
将 torch.nn 导入为 nn

load_build_dataset()
火车（）
torch.save(&#39;MLmodel.a&#39;) # 伪代码。


推理部分
&lt;前&gt;&lt;代码&gt;
# PyBind11 C++
导入机器学习模型

A =np.array([...,])

结果 = MLmodel.predict(A)

]]></description>
      <guid>https://stackoverflow.com/questions/77591558/is-there-a-way-to-save-the-pytorch-model-for-environment-without-pytorch-package</guid>
      <pubDate>Sat, 02 Dec 2023 17:53:46 GMT</pubDate>
    </item>
    <item>
      <title>寻求学校项目综合车辆属性数据集的指导[关闭]</title>
      <link>https://stackoverflow.com/questions/77591553/seeking-guidance-on-comprehensive-vehicle-attribute-datasets-for-school-project</link>
      <description><![CDATA[我正在开展一个学校项目，需要一个全面的车辆属性数据集，其中包括类型、型号、车牌、颜色、品牌和可能的图像等信息。我搜索了各种平台，但只找到了属性有限的数据集。您能否提供有关在哪里可以找到此类数据集的建议，或者提供有关使用其他属性增强现有数据集的指导？
我已经探索过 Kaggle 和 UCI 机器学习存储库上的数据集，但尚未找到满足我的特定要求的数据集。我愿意接受有关如何应对这一挑战的任何建议或建议。]]></description>
      <guid>https://stackoverflow.com/questions/77591553/seeking-guidance-on-comprehensive-vehicle-attribute-datasets-for-school-project</guid>
      <pubDate>Sat, 02 Dec 2023 17:52:45 GMT</pubDate>
    </item>
    <item>
      <title>对成本函数的绘制方式感到困惑[关闭]</title>
      <link>https://stackoverflow.com/questions/77590637/confused-about-how-a-cost-function-is-graphed</link>
      <description><![CDATA[我目前正在学习梯度下降，但我对成本函数的绘制方式感到困惑。
我理解均方误差平均和的公式，但是如何在图表上绘制各个点？
在添加到总和之前是否将每个错误绘制在图表上？]]></description>
      <guid>https://stackoverflow.com/questions/77590637/confused-about-how-a-cost-function-is-graphed</guid>
      <pubDate>Sat, 02 Dec 2023 13:57:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 IVY 框架，我得到--------ValueError: 分类指标无法处理多类和多标签指标目标的混合</title>
      <link>https://stackoverflow.com/questions/77587144/using-ivy-framework-i-am-getting-valueerror-classification-metrics-cant</link>
      <description><![CDATA[我正在尝试实现一个 Ivy 框架来使用 kdd 修改模型
数据集
这是代码
导入ivy； ivy.set_backend(“jax”)
导入jax； jax.config.update(“jax_enable_x64”, True)
从 sklearn.preprocessing 导入 LabelEncoder
导入 ivy.function.frontends.xgboost 作为 xgb_frontend
从 sklearn.metrics 导入分类报告
从 sklearn.model_selection 导入 train_test_split
从 sklearn.datasets 导入 load_breast_cancer
将 matplotlib.pyplot 导入为 plt
从 timeit 导入 timeit
将 xgboost 导入为 xgb
将 pandas 导入为 pd
导入函数工具
导入ipytest； ipytest.autoconfig()
从 tqdm 导入 tqdm_notebook 作为 tqdm
ivy.set_soft_device_mode(真)
def load_data(路径):
    从 sklearn.preprocessing 导入 StandardScaler

    数据= pd.read_csv（路径，分隔符=“，”）
    columns = ([&#39;duration&#39;,&#39;protocol_type&#39;,&#39;service&#39;,&#39;flag&#39;,&#39;src_bytes&#39;,&#39;dst_bytes&#39;,&#39;land&#39;,&#39;wrong_fragment&#39;,&#39;urgent&#39;,&#39;hot&#39;,&#39;num_failed_logins&#39;,&#39;logged_in &#39;,&#39;num_compromished&#39;,&#39;root_shell&#39;,&#39;su_attempted&#39;
    ,&#39;num_root&#39;,&#39;num_file_creations&#39;,&#39;num_shells&#39;,&#39;num_access_files&#39;,&#39;num_outbound_cmds&#39;,&#39;is_host_login&#39;,&#39;is_guest_login&#39;,&#39;count&#39;,&#39;srv_count&#39;,&#39;serror_rate&#39;,&#39;srv_serror_rate&#39;,&#39;rerror_rate&#39;,&#39; srv_rerror_rate&#39;,&#39;same_srv_rate&#39;,&#39;diff_srv_rate&#39;
    ,&#39;srv_diff_host_rate&#39;,&#39;dst_host_count&#39;,&#39;dst_host_srv_count&#39;,&#39;dst_host_same_srv_rate&#39;,&#39;dst_host_diff_srv_rate&#39;,&#39;dst_host_same_src_port_rate&#39;,&#39;dst_host_srv_diff_host_rate&#39;,&#39;dst_host_serror_rate&#39;,
    &#39;dst_host_srv_serror_rate&#39;,&#39;dst_host_rerror_rate&#39;,&#39;dst_host_srv_rerror_rate&#39;,&#39;攻击&#39;,&#39;级别&#39;])
    数据.列 = 列
    数据 = data.drop(&#39;级别&#39;, 轴=1)
    le = 标签编码器()
    数据[&#39;协议类型&#39;] = le.fit_transform(数据[&#39;协议类型&#39;])
    数据[&#39;服务&#39;] = le.fit_transform(数据[&#39;服务&#39;])
    数据[&#39;标志&#39;] = le.fit_transform(数据[&#39;标志&#39;])
    数据[&#39;攻击&#39;] = le.fit_transform(数据[&#39;攻击&#39;])
    X = data.drop([&#39;攻击&#39;], 轴=1)
    y = 数据[&#39;攻击&#39;]

    sc = 标准缩放器()
    X = sc.fit_transform(数据)
    返回 X, y

def 准备数据（数组）：
    if isinstance(数组，元组)：
        数组=列表（数组）

    对于范围内的 i（len（数组））：
        如果 len(arrays[i].shape) == 1:
            arrays[i] = ivy.expand_dims(arrays[i], axis=1).astype(ivy.float32)
        别的：
            数组[i] = ivy.array(数组[i], dtype=ivy.float32)
    返回数组

下面是拆分查找准确率和分类报告的代码；
我在最后一行收到此错误：
分类指标无法处理多类和多标签指标目标的混合

有什么问题吗？
X, y =prepare_data(load_data(“/content/data/KDDTrain+.txt”))
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=15)

参数 = {
    “目标”：“多重：softmax”，
    “助推器”：“gb线性”，
    “n_估计器”：100，
    “学习率”：0.1，
    “reg_lambda”：0.1，
    “reg_alpha”：0.1，
    “base_margin”：无
}

xgb_cls = xgb.XGBClassifier(**参数)

ivy_cls = xgb_frontend.XGBClassifier(**参数)
ivy_cls.compile(X_train, y_train)
ivy_cls.fit(X_train, y_train)

ivy_pred = ivy_cls.predict(X_test)

准确度 = precision_score(y_test, ivy_pred) #获取该行的错误

]]></description>
      <guid>https://stackoverflow.com/questions/77587144/using-ivy-framework-i-am-getting-valueerror-classification-metrics-cant</guid>
      <pubDate>Fri, 01 Dec 2023 17:44:35 GMT</pubDate>
    </item>
    <item>
      <title>如何解决训练自己的 DDSP-VST 模型的官方示例中 Google collab 上的（依赖）错误？</title>
      <link>https://stackoverflow.com/questions/77216743/how-to-solve-dependency-error-on-google-collab-in-official-example-for-trainin</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77216743/how-to-solve-dependency-error-on-google-collab-in-official-example-for-trainin</guid>
      <pubDate>Mon, 02 Oct 2023 15:30:02 GMT</pubDate>
    </item>
    <item>
      <title>将 llama_index 与 mac m1 一起使用</title>
      <link>https://stackoverflow.com/questions/75979420/using-llama-index-with-mac-m1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75979420/using-llama-index-with-mac-m1</guid>
      <pubDate>Mon, 10 Apr 2023 17:46:58 GMT</pubDate>
    </item>
    <item>
      <title>用于调整 XGBoost 超参数的 PySpark MLlib 交叉验证</title>
      <link>https://stackoverflow.com/questions/75556588/pyspark-mllib-cross-validation-for-hyperparameter-tuning-a-xgboost</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75556588/pyspark-mllib-cross-validation-for-hyperparameter-tuning-a-xgboost</guid>
      <pubDate>Fri, 24 Feb 2023 12:29:51 GMT</pubDate>
    </item>
    <item>
      <title>如何将极坐标数据框与 scikit-learn 一起使用？</title>
      <link>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</link>
      <description><![CDATA[我无法将极坐标数据帧与 scikitlearn 一起使用进行机器学习训练。
目前，我正在极坐标中进行所有数据帧预处理，在模型训练期间，我将其转换为 pandas 数据帧以使其正常工作。
是否有任何方法可以直接使用 Polars 数据帧进行 ML 训练而不将其更改为 pandas？]]></description>
      <guid>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</guid>
      <pubDate>Fri, 11 Nov 2022 05:59:55 GMT</pubDate>
    </item>
    <item>
      <title>什么是差、不错、好和优秀的 F1 测量范围？</title>
      <link>https://stackoverflow.com/questions/36706453/what-is-a-bad-decent-good-and-excellent-f1-measure-range</link>
      <description><![CDATA[我理解 F1-measure 是精确率和召回率的调和平均值。但是什么值定义了 F1 度量的好坏呢？我似乎找不到任何参考文献（谷歌或学术）来回答我的问题。]]></description>
      <guid>https://stackoverflow.com/questions/36706453/what-is-a-bad-decent-good-and-excellent-f1-measure-range</guid>
      <pubDate>Tue, 19 Apr 2016 00:23:50 GMT</pubDate>
    </item>
    </channel>
</rss>