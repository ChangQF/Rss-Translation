<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 26 Aug 2024 15:16:26 GMT</lastBuildDate>
    <item>
      <title>我想要一个包含文本和盲文的数据集</title>
      <link>https://stackoverflow.com/questions/78915000/i-want-a-dataset-contains-text-and-braille-language</link>
      <description><![CDATA[所以，我正在做一个将语音转换为文本的机器学习模型，然后我正在制作另一个将文本转换为盲文的模型，但我找不到任何同时包含文本和盲文的数据集。
我在 Kaggle 中查找过，但找不到任何数据集，有人可以看看链接或帮我找一个开源数据集吗？
谢谢&lt;3]]></description>
      <guid>https://stackoverflow.com/questions/78915000/i-want-a-dataset-contains-text-and-braille-language</guid>
      <pubDate>Mon, 26 Aug 2024 14:38:17 GMT</pubDate>
    </item>
    <item>
      <title>模型训练时的输入形状问题</title>
      <link>https://stackoverflow.com/questions/78914400/input-shape-problem-during-model-training</link>
      <description><![CDATA[大家好，我的代码中出现了这个问题，你能帮我吗？
ValueError: 输入 0 层“ functional”与层不兼容：预期形状=（None，4096），发现形状=（None，64，4096）
代码：
def generator_output_signature():
return (
(
tf.TensorSpec(shape=[batch_size, 4096], dtype=tf.float32), # X1 具有很多维度
tf.TensorSpec(shape=[batch_size, max_length], dtype=tf.int32) # X2 具有很多维度
),
tf.TensorSpec(shape=[batch_size, vocab_size], dtype=tf.float32) # y 具有很多维度
)
train_dataset = tf.data.Dataset.from_generator(
lambda: data_generator(train_ids, mining, features, tokenizer, max_length, vocab_size, batch_size),
output_signature=generator_output_signature()
)
train_dataset = train_dataset.batch(batch_size).p​​refetch(tf.data.AUTOTUNE)
image_input = 输入(shape=(4096,))
caption_input = 输入(shape=(max_length,))
x = Embedding(vocab_size, 256)(caption_input) # 输出形状：(None, max_length, 256)
x = LSTM(256)(x) # 输出形状：(None, 256)
image_features = Dense(256,activation=&#39;relu&#39;)(image_input) # 输出形状：(None, 256)
x = Add()([x, image_features])
x = Dense(vocab_size,activation=&#39;softmax&#39;)(x) # 输出形状：(None,vocab_size)
model = Model(inputs=[image_input,caption_input],outputs=x)
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;)
print(model.summary())
我试图删除额外的维度，但这是不可能的，所以我无法训练我的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78914400/input-shape-problem-during-model-training</guid>
      <pubDate>Mon, 26 Aug 2024 12:28:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Stable Baselines3 中改变 TD3 模型的输出激活函数？</title>
      <link>https://stackoverflow.com/questions/78914358/how-to-change-the-output-activation-function-of-the-td3-model-in-stable-baseline</link>
      <description><![CDATA[我正在使用 Stable Baselines3 库进行强化学习，并想修改 TD3 模型。具体来说，我想更改 TD3 模型输出层中使用的激活函数。
我该如何实现？
我尝试修改 Stable Baselines3 库中 TD3 模型的输出激活函数。具体来说，我想用不同的激活函数替换默认的 tanh 激活函数。]]></description>
      <guid>https://stackoverflow.com/questions/78914358/how-to-change-the-output-activation-function-of-the-td3-model-in-stable-baseline</guid>
      <pubDate>Mon, 26 Aug 2024 12:16:40 GMT</pubDate>
    </item>
    <item>
      <title>每个时期后根据补丁重建图像</title>
      <link>https://stackoverflow.com/questions/78914175/reconstruct-images-from-patches-after-every-epoch</link>
      <description><![CDATA[我有一张大图像，我将其分割成大小相等的小块。我将这些小块加载到模型中。预测后，我尝试重建补丁以形成输入图像的形状。
batch_size = 20 # 选择补丁数量
epochs = 15

for epoch in range(epochs):

label_as_fake = np.zeros((batch_size, 1)) 
label_as_real = np.ones((batch_size,1)) 

for ii in tqdm(range(len(train_hr_batches))): #总补丁数，100
lr_imgs = train_lr_batches[ii] 
hr_imgs = train_hr_batches[ii] 

generated_pa​​tches = generator.predict_on_batch(lr_imgs)

调用重建函数保存图像
if (epoch+1) % 1 ==0:
reconstructed_sr = reconstruct_patches(generated_pa​​tches, image_height, image_width, patch_height, patch_width) 
save_images(reconstructed_sr, f&#39;reconstructed_sr_epoch_{epoch+1}.TIF&#39;)


我可以在一个 epoch 之后保存 100 个生成的补丁。但是，当我尝试将补丁组合在一起以将图像重建为输入图像的形状时，会出现错误，提示模型正在尝试在一次迭代后（即 20 个补丁后）重建图像。在尝试重建图像之前，如何修改代码以对 100 个补丁进行完整运行？
Cell In[39]，第 7 行
reconstructed_sr = reconstruct_patches(generated_images, image_height, image_width, patch_height, patch_width)

Cell In[37]，reconstruct_patches 中的第 12 行
raise ValueError(f&quot;expected {expected_num_patches} patches but found {actual_num_patches} patches&quot;)

ValueError: expected 100 patches but found 20 patches

代码仅在定义的 batch_size 结束后尝试重建图像]]></description>
      <guid>https://stackoverflow.com/questions/78914175/reconstruct-images-from-patches-after-every-epoch</guid>
      <pubDate>Mon, 26 Aug 2024 11:36:54 GMT</pubDate>
    </item>
    <item>
      <title>由于尺寸不相等，处理化学分子原子时出现批处理错误</title>
      <link>https://stackoverflow.com/questions/78913966/batching-error-when-processing-chemical-molecule-atoms-because-sizes-not-equal</link>
      <description><![CDATA[我目前正在设计一个可以根据节点特征、边缘特征预测属性的神经网络。但是，当我尝试将批处理大小设置为大于 1 时，事情就出错了。分子中的原子数不同，因此在将多个分子批处理在一起时会导致错误。更具体地说，将出现错误：
RuntimeError：堆栈期望每个张量大小相等，但在条目 0 处得到 [6, 25]，在条目 1 处得到 [8, 25]
。6 和 8 表示该分子中有 6/8 个原子，25 表示每个原子有 25 个特征。有没有比根据另一个类似问题添加零来调整大小更好的解决方案，因为分子的大小可能高达 30 或更大。]]></description>
      <guid>https://stackoverflow.com/questions/78913966/batching-error-when-processing-chemical-molecule-atoms-because-sizes-not-equal</guid>
      <pubDate>Mon, 26 Aug 2024 10:39:01 GMT</pubDate>
    </item>
    <item>
      <title>GIT 分支策略 [关闭]</title>
      <link>https://stackoverflow.com/questions/78913825/git-branching-strategies</link>
      <description><![CDATA[我需要分析所有存储库的提交历史并确定分支策略。我们如何确定它们是否遵循特定的分支策略
以下是我尝试过的方法，但它仅涵盖基于主干的开发。通过查看生成工件的分支，尝试将其标记为 TBD。我可以访问 github api 以及工件、存储库、组织的映射
我需要一个万无一失的算法来确定给定存储库上遵循了哪些分支实践。]]></description>
      <guid>https://stackoverflow.com/questions/78913825/git-branching-strategies</guid>
      <pubDate>Mon, 26 Aug 2024 10:04:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorRT 10.3 进行转换和推理</title>
      <link>https://stackoverflow.com/questions/78913648/conversion-and-inference-with-tensorrt-10-3</link>
      <description><![CDATA[我正在尝试使用 .onnx 模型并使用 TensorRT 加快其推理速度。我已经安装了所有东西，并且我非常有信心一切都正确完成，并且没有版本冲突或类似问题。
我对大量关于如何使用 TensorRT 实现推理的文章和指南感到困惑，我似乎无法让其中任何一个发挥作用！我使用 TensorRT 10.3，据我所知，与以前的版本相比，它有很多变化和重构。
此外，我看到了同一事物的不同版本，我不知道该遵循哪一个……NVIDIA 的文档没有我希望的那么有用，而且我手头有一个特殊案例，因为我尝试转换的模型有多个输入（更具体地说，两个输入，比如形状为 (none, H, W, C) 的“input_0”和形状为 (none, H, W, C) 的“input_1”）。
有人可以提供一些帮助，或者提供关于如何转换模型并将其用于推理的最新指南吗？如果能提供关于这种多输入情况的任何其他说明，我将不胜感激，我已经画了好几天的圆圈了。]]></description>
      <guid>https://stackoverflow.com/questions/78913648/conversion-and-inference-with-tensorrt-10-3</guid>
      <pubDate>Mon, 26 Aug 2024 09:15:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 CLIP Vision Encoder 创建自定义对象检测模型</title>
      <link>https://stackoverflow.com/questions/78913273/create-a-custom-object-detection-model-with-clip-vision-encoder</link>
      <description><![CDATA[我目前想知道是否可以仅使用剪辑图像编码器来创建我自己的自定义对象检测模型？
我曾尝试从 CLIP 图像编码器中提取图像的嵌入。我想尝试将其提供给一些现有的对象检测模型，例如 YOLOv5 等，其中 CLIP 图像编码器是特征提取器。然而，我无法理解，我该如何继续这个想法。这可能吗？如果是，建议如何继续？]]></description>
      <guid>https://stackoverflow.com/questions/78913273/create-a-custom-object-detection-model-with-clip-vision-encoder</guid>
      <pubDate>Mon, 26 Aug 2024 07:30:04 GMT</pubDate>
    </item>
    <item>
      <title>Python文本检测OpenCV+Roboflow OCR相机性能非常滞后问题</title>
      <link>https://stackoverflow.com/questions/78913244/python-text-detection-opencvroboflow-ocr-camera-performance-very-lag-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78913244/python-text-detection-opencvroboflow-ocr-camera-performance-very-lag-problem</guid>
      <pubDate>Mon, 26 Aug 2024 07:22:14 GMT</pubDate>
    </item>
    <item>
      <title>Yolov8 推理在 Mac 上运行良好，但在 Windows 上运行不佳 [重复]</title>
      <link>https://stackoverflow.com/questions/78911914/yolov8-inference-working-on-mac-but-not-windows</link>
      <description><![CDATA[我在 pycharm 中使用 ultralytics 中的 Yolo v8 对我训练的模型进行推理，当我在 macbook 上运行它时，它运行良好，但在我的 windows 笔记本电脑上，尽管我使用的是相同的 best.pt 文件和相同的代码，但我到处都得到了大量置信度得分为 1 的边界框：
正在发生的事情的示例
from ultralytics import YOLO
from ultralytics.utils.benchmarks import benchmark

model = YOLO(&quot;best.pt&quot;)
# model = YOLO(&quot;yolov8m.pt&quot;)

results = model(source=0, show=True, conf=0.6, save=True)
# results = model.track(source=0, show=True, conf=0.6, tracker=&quot;bytetrack.yaml&quot;)

我之前也遇到过类似（但不完全相同）的问题，与下面链接的问题类似，pycharm 无法检测到 pytorch，每次导入时都会出错：
import torch：如何修复 OSError WinError 126，加载 fbgemm.dll 或依赖项时出错
我使用用户提供的 libomp140.x86_64.dll 文件并将其放在 C:\Windows\System32 中修复了它，这可能是问题所在吗？
我已经尝试过的方法：
我尝试重新安装 ultralytics和 pytorch 库和 pycharm，以为是它们的安装问题，但什么都没改变。
编辑：通过将 ultralytics 版本降级到 8.2.60 解决了这个问题，感谢 Christoph Rackwitz 指出它与此帖子类似：
使用 YOLOv8 进行大量不正确的检测
降级 torch 版本也可能有效，下次我一定会检查 github 上的已知问题。]]></description>
      <guid>https://stackoverflow.com/questions/78911914/yolov8-inference-working-on-mac-but-not-windows</guid>
      <pubDate>Sun, 25 Aug 2024 18:16:41 GMT</pubDate>
    </item>
    <item>
      <title>将具有大内核的 maxpool 转换为具有小内核的 maxpool 的等效堆栈[关闭]</title>
      <link>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</link>
      <description><![CDATA[我有一个 onnx 模型，它有一些这样的 MaxPool 层：

我无法使用这些内核形状，因为我只能从 1x1 变为 3x3。 4x4 被认为不是最佳的，但我可以使用它。
我尝试用一​​堆 3x3 内核替换它们，如下所示：

我错误计算了此图像中的输出形状，但我会修复它。
我的疑问是，即使我修复了 MaxPool 层，输出是否会与具有更大内核的原始输出相似？我无法弄清楚应该使用什么组合才能使输出与原始内核相似或最接近。]]></description>
      <guid>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</guid>
      <pubDate>Wed, 21 Aug 2024 06:09:06 GMT</pubDate>
    </item>
    <item>
      <title>DaskLGBMClassifier.fit() 错误：“Future”对象没有属性“get_params”</title>
      <link>https://stackoverflow.com/questions/73209365/dasklgbmclassifier-fit-error-future-object-has-no-attribute-get-params</link>
      <description><![CDATA[我正在尝试 LGBM 的 Dask API，当我安装 DaskLGBMClassifier 时，我收到以下错误：
&#39;Future&#39; 对象没有属性 &#39;get_params&#39;
我尝试在原始代码上对其进行调试。您可以在错误参考中看到的变量模型，Colab 应该是类 LGBMModel 的一个实例，它似乎具有方法 get_params()。
为什么它说 get_params 是一个属性？什么是“Future”对象？
这是错误 错误图像，这是 model=_train，这是 _train 函数，这是 LGBMModel，最后是 获取参数函数。]]></description>
      <guid>https://stackoverflow.com/questions/73209365/dasklgbmclassifier-fit-error-future-object-has-no-attribute-get-params</guid>
      <pubDate>Tue, 02 Aug 2022 14:33:55 GMT</pubDate>
    </item>
    <item>
      <title>对于小型神经网络，激活函数的最佳选择是什么</title>
      <link>https://stackoverflow.com/questions/69240517/what-is-the-best-choice-for-an-activation-function-in-case-of-small-sized-neural</link>
      <description><![CDATA[我正在使用 pytorch 和 autograd 来构建我的神经网络架构。它是一个具有单个输入和输出的小型 3 层网络。假设我必须根据一些初始条件预测一些输出函数，并且我正在使用自定义损失函数。
我面临的问题是：

我的损失最初收敛，但梯度最终消失。

我尝试过 S 型激活和 tanh。tanh 在损失收敛方面给出了稍好的结果。

我尝试过使用 ReLU，但由于我的神经网络中没有太多权重，权重变得无效，并且无法给出良好的结果。


除了 S 型和 tanh 之外，还有其他激活函数可以很好地处理小型神经网络的梯度消失问题吗？还有什么建议我可以尝试吗？]]></description>
      <guid>https://stackoverflow.com/questions/69240517/what-is-the-best-choice-for-an-activation-function-in-case-of-small-sized-neural</guid>
      <pubDate>Sun, 19 Sep 2021 05:20:49 GMT</pubDate>
    </item>
    <item>
      <title>ReLU 何时会杀死神经元？</title>
      <link>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</link>
      <description><![CDATA[我对 ReLU 死亡问题感到困惑。ReLU 只会在前向传递期间杀死神经元吗？还是在后向传递期间也会杀死神经元？]]></description>
      <guid>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</guid>
      <pubDate>Tue, 15 May 2018 11:35:06 GMT</pubDate>
    </item>
    <item>
      <title>阶跃函数计算限制</title>
      <link>https://stackoverflow.com/questions/28462891/step-function-computational-limitations</link>
      <description><![CDATA[阶跃函数作为神经网络的激活函数有哪些局限性？
我听说非线性函数需要具有普遍性，但阶跃函数在这方面处于什么位置？它们是否与线性激活函数一样有限？它们会被归类为线性函数吗？]]></description>
      <guid>https://stackoverflow.com/questions/28462891/step-function-computational-limitations</guid>
      <pubDate>Wed, 11 Feb 2015 19:30:18 GMT</pubDate>
    </item>
    </channel>
</rss>