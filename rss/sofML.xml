<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 08 Sep 2024 21:14:43 GMT</lastBuildDate>
    <item>
      <title>使用 Raspberry Pi 5 在 Edge TPU 上运行 YOLOv8 分割模型时出现 KeyError</title>
      <link>https://stackoverflow.com/questions/78963308/keyerror-when-running-yolov8-segmentation-model-on-edge-tpu-with-raspberry-pi-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78963308/keyerror-when-running-yolov8-segmentation-model-on-edge-tpu-with-raspberry-pi-5</guid>
      <pubDate>Sun, 08 Sep 2024 21:01:01 GMT</pubDate>
    </item>
    <item>
      <title>在 ML 心理健康应用程序中集成多模态数据和实时处理 [关闭]</title>
      <link>https://stackoverflow.com/questions/78962995/integrating-multimodal-data-and-real-time-processing-in-ml-mental-health-app</link>
      <description><![CDATA[我正在做一个大学项目，从头开始构建一个应用程序，使用机器学习提供实时心理健康干预。该项目名为WellnessWave，其目标是根据用户的言语、面部表情和文本输入为他们提供个性化的治疗方案。这些治疗方案包括简单的活动，如呼吸练习、冥想技巧和轻度体育锻炼，用户可以实施这些活动来改善他们的心理健康。
我已经为该应用创建了网页设计，您可以通过描述中包含的CodeSandbox链接查看。该项目的重点是：

实时数据收集：

使用 OpenCV（用于视频捕获）等工具和用于语音和文本数据的外部库捕获语音、面部表情和文本输入。
这些数据存储在 speech_clips/、facial_expression_images/ 和 text_inputs/ 等目录结构中。


预处理：

使用 tensorflow、mediapipe、soundfile 等库将收集的数据转换为有意义的特征，以进行模型训练和预测scikit-learn。


多模式机器学习：

使用 Keras 为语音识别、面部表情分析和文本情感分析构建单独的模型。这些模型结合在多模式融合框架中，以创建实时、个性化的心理健康建议。


实时处理：

我需要帮助有效地实时结合语音、面部表情和文本数据以提供即时建议。
我正在努力优化数据管道以确保低延迟处理。


自适应学习和反馈：

该应用程序包含一个反馈机制，用户可以对建议进行评分，这应该有助于模型随着时间的推移进行适应和改进。我正在寻找有关如何最好地实施此反馈系统以改进模型建议的指导。



挑战和所需帮助：

我需要帮助将这些不同的数据流（语音、面部表情和文本）集成到有凝聚力的实时机器学习管道中。
非常感谢根据用户反馈改进自适应学习机制的建议。
我也正在从头开始构建整个应用程序，因此有关后端设计、实时处理或模型部署的任何建议都将非常有帮助。

库和工具：

tensorflow、opencv-python、mediapipe、soundfile、scikit-learn 和 joblib 用于保存/加载模型。
CodeSandbox 链接和网页设计的演示视频包含在描述中以供参考。

我非常感谢任何见解、建议或帮助，因为这是我们大学项目的关键部分。请随意查看网页设计，并让我知道我可以如何优化或改进从头开始构建应用程序的方法。
Github 链接：https://github.com/GitNinja4988/Ml-Projects/blob/main/README.md
Github 存储库链接：https://github.com/GitNinja4988/Ml-Projects
您可以下载存储库代码并查看网站详细信息，进行更改并在此处更新我
]]></description>
      <guid>https://stackoverflow.com/questions/78962995/integrating-multimodal-data-and-real-time-processing-in-ml-mental-health-app</guid>
      <pubDate>Sun, 08 Sep 2024 17:57:14 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tensorflow 权重文件夹（包含.data、.index 和另一个未知文件名检查点）转换为.pb 格式和.tflite？</title>
      <link>https://stackoverflow.com/questions/78962022/how-to-convert-a-tensorflow-weights-folder-containing-data-index-and-another</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78962022/how-to-convert-a-tensorflow-weights-folder-containing-data-index-and-another</guid>
      <pubDate>Sun, 08 Sep 2024 09:39:58 GMT</pubDate>
    </item>
    <item>
      <title>如何根据多项评估对推荐路线与实际路线的相似度进行分类？[关闭]</title>
      <link>https://stackoverflow.com/questions/78962013/how-to-classify-the-similarity-between-a-recommended-and-an-actual-route-based-o</link>
      <description><![CDATA[我需要对应用程序推荐的路线和司机所走的路线是否相似进行分类。
我有一个包含以下变量的数据集：

id_viaje（行程 ID）
evaluador（评估者）——有 8 个不同的评估者
evaluacion（评估）——评估者的判断：相似、不相似或不确定
ruta_real（实际路线的点集）
ruta_estimada（估计路线的点集）

我已经做了一些探索性数据分析，以下是一些观察结果：

同一个评估者有时会对同一次行程进行两次评估，并给出相互矛盾的结果（一次说路线相似，另一次说不相似）。
在某些情况下在某些情况下，他们说他们不确定，但当我可视化路线时，它们实际上是相同的。
对于同一次旅行，有时不同的评估者会有相互矛盾的意见。

我对如何处理这个问题有些疑问：
对于评估者说“不确定”的情况，我计划为“相似”和“不相似”分配 0.5 的权重。 （或者，我可以忽略这些，或者先建立一个初始模型对这些情况进行分类，然后使用包含所有数据的最终模型。）
由于该任务似乎涉及对实际路线和拟议路线之间的相似性进行分类，而不是建立传统模型，因此似乎基于距离进行分类是最好的方法。
关于如何处理这些情况或计算路线相似度有什么建议吗？
我有这种数据
{&#39;journey_id&#39;: &#39;9cd6cd52-54c5-11ec-ae0a-0d030544d074&#39;,
&#39;annotator&#39;: 3,
&#39;annotation&#39;: &#39;两者相同&#39;,
&#39;estimated_route&#39;: [[-21.11149, -60.21455],
[-12.11145, -77.04671],
[-12.11139, -77.04664],
[-12.11134, -77.04659]
...],
&#39;real_route&#39;: 
[[-21.77149, -60.17455],
[-12.11139, -77.04659],
[-12.11139, -77.04671]]}

实际路线和估算路线并不总是具有相同长度的点]]></description>
      <guid>https://stackoverflow.com/questions/78962013/how-to-classify-the-similarity-between-a-recommended-and-an-actual-route-based-o</guid>
      <pubDate>Sun, 08 Sep 2024 09:35:49 GMT</pubDate>
    </item>
    <item>
      <title>什么是局部梯度错位？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78961861/what-is-local-gradient-misalignment</link>
      <description><![CDATA[我在阅读FedPRoto相关论文时，文章中提到了这个概念，但是我却无法理解它的具体定义。
但是我似乎无法从如此少的信息中找到明确的答案。]]></description>
      <guid>https://stackoverflow.com/questions/78961861/what-is-local-gradient-misalignment</guid>
      <pubDate>Sun, 08 Sep 2024 07:57:37 GMT</pubDate>
    </item>
    <item>
      <title>Python-NEAT 算法的配置</title>
      <link>https://stackoverflow.com/questions/78961771/configuration-of-python-neat-algorithm</link>
      <description><![CDATA[我正在使用 NEAT 算法根据十字路口四个方向的队列长度等输入来优化交通信号时序。目标是生成最佳信号时序作为输出。但是，我在实现中遇到了激活函数的持续问题。
我使用 Python-NEAT 进行交通信号优化，其中：
输入：交叉路口四个方向的队列长度。
输出：每个方向的信号时序。

以下是我在使用不同激活函数时遇到的问题的描述：
ReLU：不断将输出值增加到非常大的数字，然后变得无法运行。
Sigmoid：虽然它给出的值从 0 到 1，但我通过将其乘以 10 来放大它，但问题是它对所有输出都卡在 1，无论输入如何，它都会不断给出 [1.0, 1.0, 1.0, 1.0]值。
tanh：与 sigmoid 有同样的问题。
sin：与 sigmoid 有同样的问题。
Softplus：对所有信号时序输出一个常数值 12。
我最初认为运行该算法多代可能会解决这个问题。所以，我让它用 Sigmoid 之类的函数运行了一整夜，结果醒来后发现适应度值已经暴跌到负数十亿。
我正在按如下方式评估我的适应度值：
ifqueue_length_north_avg &gt; 15:
fitness_N += 队列长度_北_avg + ((队列长度_北_avg - 15) ** 2)
else:
fitness_N += 队列长度_北_avg

然后将所有方向的适应度相加并从基因组中减去，如下所示：
 fitness = fitness_N + fitness_S + fitness_E + fitness_W / 4
基因组.fitness -= fitness

我的问题是，是什么原因导致我的 NEAT 实现中的激活函数出现这些问题，我如何配置算法以产生更稳定的输出，从而实现信号时序的有意义的优化？
是否可以为所有四个方向输入不同的适应度？这会有帮助吗？
我的配置文件如下：
*
[NEAT]
fitness_criterion = max
fitness_threshold = 1
pop_size = 30
reset_on_extinction = False

[DefaultGenome]
#compatibility_weight_coefficient = 1.0
activation_default = softplus
activation_mutate_rate = 0.0
activation_options = softplus

aggregation_default = sum
aggregation_mutate_rate = 0.0
aggregation_options = sum

bias_init_mean = 0.0
bias_init_stdev = 1.0
bias_max_value = 10.0
bias_min_value = 0.0
bias_mutate_power = 0.5
bias_mutate_rate = 0.4
bias_replace_rate = 0.1

compatibility_disjoint_coefficient = 1.0
compatibility_weight_coefficient = 1.0

conn_add_prob = 0.5
conn_delete_prob = 0.5

enabled_default = True
enabled_mutate_rate = 0.01

feed_forward = True
initial_connection = full_direct

node_add_prob = 0.2
node_delete_prob = 0.2

num_hidden = 4
num_inputs = 4
num_outputs = 4

response_init_mean = 1.0
response_init_stdev = 0.1
response_max_value = 10.0
response_min_value = 0.0
response_mutate_power = 0.1
response_mutate_rate = 0.1
response_replace_rate = 0.05

weight_init_mean = 0.0
weight_init_stdev = 0.5
weight_max_value = 10
weight_min_value = 0.0
weight_mutate_power = 0.5
weight_mutate_rate = 0.4
weight_replace_rate = 0.1

[DefaultSpeciesSet]
compatibility_threshold = 3.0

[DefaultStagnation]
species_fitness_func = max
max_stagnation = 20
species_elitism = 2

[DefaultReproduction]
elitism = 2
survival_threshold = 0.3*
]]></description>
      <guid>https://stackoverflow.com/questions/78961771/configuration-of-python-neat-algorithm</guid>
      <pubDate>Sun, 08 Sep 2024 06:48:43 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 2.1 Keras 错误，度量尚未建立</title>
      <link>https://stackoverflow.com/questions/78961753/tensorflow-2-1-keras-error-the-metric-has-not-yet-been-built</link>
      <description><![CDATA[我正在堆叠 5 个预训练模型，有点像迁移学习。
我遇到了有关度量尚未构建错误的问题，我不知道如何解决它。
我正在使用 tensorflow 2.17 版本。我检查了所有模型的构建状态，并且度量是正确的。我还确保所有模型输入和输出形状都兼容。
以下是我的代码和错误消息。
来自 sklearn.datasets 导入 make_blobs
来自 sklearn.metrics 导入 accuracy_score
导入 tensorflow 作为 tf
来自 tensorflow.keras.utils 导入 plot_model
来自 tensorflow.keras.models 导入 Model, load_model
来自 tensorflow.keras.layers 导入 Input, Dense, Concatenate
来自 tensorflow.keras.utils 导入 to_categorical
来自 numpy 导入 argmax
导入 IPython

print(tf.__version__)

def define_stacked_model():
ensemble_visible = []
ensemble_outputs = []
for i in range(5):
filename = &#39;models/model_&#39; + str(i + 1) + &#39;.keras&#39;
model = load_model(filename)
for layer in model.layers:
layer.trainable = False
input = 输入(shape=(model.input_shape[-1],), name=f&#39;ensemble_input_{i+1}&#39;)
ensemble_visible.append(input)
output = model(input)
ensemble_outputs.append(output)

merge = 连接(axis=-1, name=&#39;merge_layer&#39;)(ensemble_outputs)
hidden = 密集(10, 激活=&#39;relu&#39;, name=&#39;hidden_​​layer&#39;)(合并)
output = 密集(3, 激活=&#39;softmax&#39;, name=&#39;output_layer&#39;)(隐藏)

final_model = 模型(输入=ensemble_visible, 输出=输出, name=&#39;stacked_model&#39;)
final_model.build(输入形状=ensemble_visible)
final_model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;categorical_accuracy&#39;])
plot_model(final_model, to_file=&#39;stacked_model_plot.png&#39;, show_shapes=True, show_layer_names=True, expand_nested=True)
IPython.display.display(IPython.display.Image(&quot;stacked_model_plot.png&quot;))
return final_model

stacked_model = define_stacked_model()

def fit_stacked_model(model, inputX, inputy):
X = [inputX for _ in range(len(model.input_shape))]
inputy_enc = to_categorical(inputy)
model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;categorical_accuracy&#39;])
model.fit(X, inputy_enc, epochs=300, verbose=0)

def predict_stacked_model(model, inputX):
X = [inputX for _ in range(len(model.input_shape))]
return model.predict(X, verbose=0)

X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)
n_train = 100
trainX, testX = X[:n_train, :], X[n_train:, :]
trainy, testy = y[:n_train], y[n_train:]

fit_stacked_model(stacked_model, trainX, trainy)

------------------------------------------------------------------------------------------
ValueError Traceback （最近一次调用最后一次）
单元格 In[37]，第 55 行
52 trainX, testX = X[:n_train, :], X[n_train:, :]
53 trainy, testy = y[:n_train], y[n_train:]
---&gt; 55 fit_stacked_model(stacked_model, trainX, trainy)
56 yhat = predict_stacked_model(stacked_model, testX)
57 yhat = argmax(yhat, axis=1)

单元格 In[37]，第 44 行，在 fit_stacked_model(model, inputX, inputy) 中
42 inputy_enc = to_categorical(inputy)
43 model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;categorical_accuracy&#39;])
---&gt; 44 model.fit(X, inputy_enc, epochs=300, verbose=0)

文件 ~\Anaconda\envs\pytorch-gpu\Lib\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
123 finally:
124 delfiltered_tb

文件 ~\Anaconda\envs\pytorch-gpu\Lib\site-packages\keras\src\trainers\compile_utils.py:356，位于 CompileMetrics.result(self)
354 def result(self):
355 if not self.built:
--&gt; 356 引发 ValueError(
357 &quot;无法获取 result()，因为尚未构建度量。&quot;
358 )
359 results = {}
360 unique_name_counters = {}

ValueError: 无法获取 result()，因为尚未构建度量。

我尝试使其从旧版本 keras 运行到 tensorflow 2.1]]></description>
      <guid>https://stackoverflow.com/questions/78961753/tensorflow-2-1-keras-error-the-metric-has-not-yet-been-built</guid>
      <pubDate>Sun, 08 Sep 2024 06:36:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 imageDataGenerator 对象执行 Keras model.fit 时出错[关闭]</title>
      <link>https://stackoverflow.com/questions/78960164/error-while-executing-keras-model-fit-with-imagedatagenerator-object</link>
      <description><![CDATA[在使用 Cats &amp; 时执行以下代码行时出现错误狗数据集。
EPOCHS = 100
history = model.fit(
train_data_gen,
steps_per_epoch=int(np.ceil(2000 / float(BATCH_SIZE))),
epochs=EPOCHS,
validation_data=val_data_gen,
validation_steps=int(np.ceil(1000 / float(BATCH_SIZE)))
)

错误
Epoch 1/100
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: 您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。 `**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。不要将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()
20/20 ━━━━━━━━━━━━━━━━━━━━━━━ 17s 311ms/step - 准确度：0.4858 - 损失：0.7865 - val_accuracy：0.5000 - val_loss：0.6925
Epoch 2/100
/usr/lib/python3.10/contextlib.py:153：UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 `steps_per_epoch * epochs` 批次。构建数据集时，您可能需要使用 `.repeat()` 函数。
self.gen.throw(typ, value, traceback)
---------------------------------------------------------------------------
AttributeError Traceback (most recent call last)
&lt;ipython-input-22-f495897bdf8d&gt; in &lt;cell line: 2&gt;()
1 EPOCHS = 100
----&gt; 2 history = model.fit(
3 train_data_gen,
4 steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
5 epochs=EPOCHS,

1 帧
/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)
352 )
353 val_logs = {
--&gt; 354 &quot;val_&quot; + name: val for name, val in val_logs.items()
355 }
356 epoch_logs.update(val_logs)

AttributeError: &#39;NoneType&#39; 对象没有属性 &#39;items&#39;

错误提到输入用尽数据，但步骤大小对于训练和验证数据集都是正确的。
我找到了一些使用 fit_generator 的示例，但该方法在 tensorflow 2.1.0 中已弃用。
有什么解决该问题的建议吗？
使用以下代码解决问题
EPOCHS = 100
history = model.fit(
train_data_gen,
batch_size = BATCH_SIZE,
epochs=EPOCHS,
validation_data=val_data_gen
)
]]></description>
      <guid>https://stackoverflow.com/questions/78960164/error-while-executing-keras-model-fit-with-imagedatagenerator-object</guid>
      <pubDate>Sat, 07 Sep 2024 12:52:02 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 中的 Autograd Trainstep 中的 Lightning</title>
      <link>https://stackoverflow.com/questions/78956646/autograd-in-pytorch-lightning-in-trainstep</link>
      <description><![CDATA[我想实现一个基于 Pytorch Lightning 的 ML 训练，其中我使用 autograd 功能进行训练损失计算：
def training_step(self, batch, batch_idx):
x, y = batch
y_hat = self(x)
loss = self.loss_function(y_hat, y)
return loss

X 的每个样本 x 都是一个二维向量 x = [v, a]。
在训练步骤中，我想计算 y_hat 相对于 的梯度。到 v。
损失进一步通过以下方式计算：
loss = mse(y,y_hat) + mse(gradient,gradient_hat)

其中给出了（真实）梯度。
到目前为止，尝试了 y_hat.backward() 的（典型）方法，但无法使其工作：
def training_step(self, batch, batch_idx):
x, y = batch
x.requires_grad_(True) # 确保我们跟踪 x 的梯度
y_hat = self(x)

# 计算 y_hat 相对于 v 的梯度（x[:, 0]）
v = x[:, 0]
grads = torch.autograd.grad(y_hat, v, grad_outputs=torch.ones_like(y_hat), create_graph=True)[0] # ...
]]></description>
      <guid>https://stackoverflow.com/questions/78956646/autograd-in-pytorch-lightning-in-trainstep</guid>
      <pubDate>Fri, 06 Sep 2024 10:08:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras 中使用 flow_from_directory 和多个目录实现多输出神经网络</title>
      <link>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</link>
      <description><![CDATA[我需要使用 Keras 中的 flow_from_directory 从多个目录加载图像。我的目录结构如下：
Images_folder/ 
═── Carpet_1/ 
│ ═── training/ 
│ │ ═── class_1/ 
│ │ ═── class_2/ 
│ ═── validation/ 
═── Carpet_2/ 
│ ═── training/ 
│ │ ═── class_1/ 
│ │ ═── class_2/ 
│ ═── validation/ 
...

每个“Carpet”目录（例如 Carpet_1、Carpet_2）包含相同的一组类（class_1、class_2 等）。我想使用来自所有这些目录的图像来训练 CNN。我的目标是构建一个多输出神经网络，其中一个输出预测“Carpet”数字（1、2、3、...），另一个输出预测该地毯内的类别。
鉴于这种结构，我如何使用 ImageDataGenerator 或 Keras 中的任何其他方法来加载和预处理这些图像？有没有办法将所有这些目录中的图像组合成一个生成器，同时仍然允许我区分不同的地毯？]]></description>
      <guid>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</guid>
      <pubDate>Thu, 05 Sep 2024 07:56:05 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用 Google Teachable 机器模型作为对象检测模型吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78951811/can-i-use-google-teachable-machine-model-as-object-detection-model</link>
      <description><![CDATA[我正在开发一款带有对象检测功能的移动自动收银应用程序。我面临的问题是，自定义项目的变体太多了（大约 250 个类别）。如果我要对以前的模型（如 MobileNet 或 YOLO）进行微调，这将花费太多时间，因为我仍然需要创建 POS、数据库和集成热敏打印机。
那么，我是否可以只使用 Google Teachable Machine 来处理我的对象检测数据集（假设背景相同），而不是对以前的模型进行微调？
应用程序的工作方式是，收银员将在白色背景上拍摄买家想要购买的商品的照片，然后应用程序将自动检测出哪些商品在画面中（使用 Google Teachable Machine .tflite 模型）。
Teachable Machine .tflite 模型是否可以替换下面代码中的 modelPath？
private fun runObjectDetection(bitmap: Bitmap) {
// 步骤 1：创建 TFLite 的 TensorImage 对象
val image = TensorImage.fromBitmap(bitmap)

// 步骤 2：初始化检测器对象
val options = ObjectDetector.ObjectDetectorOptions.builder()
.setMaxResults(5)
.setScoreThreshold(0.5f)
.build()
val detector = ObjectDetector.createFromFileAndOptions(
this, // 应用程序上下文
**&quot;model.tflite&quot;, **
options
)
// 步骤 3：将给定的图像输入模型并打印检测结果
val results = detector.detect(image)

// 步骤 4：解析检测结果并显示
debugPrint(results)

val resultToDisplay = results.map {
// 获取 top-1 类别并制作显示文本
val category = it.categories.first()
val text = &quot;${category.label}, ${category.score.times(100).toInt()}%&quot;

// 创建数据对象，用于显示检测结果
DetectionResult(it.boundingBox, text)
}

// 将检测结果绘制到位图上并显示。
val imgWithResult = drawDetectionResult(bitmap, resultToDisplay)
runOnUiThread {
inputImageView.setImageBitmap(imgWithResult)
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/78951811/can-i-use-google-teachable-machine-model-as-object-detection-model</guid>
      <pubDate>Thu, 05 Sep 2024 07:38:34 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络将输入分成几组[关闭]</title>
      <link>https://stackoverflow.com/questions/78950639/using-a-neural-network-to-separate-inputs-into-groups</link>
      <description><![CDATA[原始问题如下：
许多粒子撞击某些探测器，我们从这些事件中获得的信息是每次激活的坐标。探测器层层相继，我们可以为每个粒子绘制一些轨迹，只知道它经过的几个有探测器的坐标。
现在神经网络的问题是向它提供一段时间内发生的所有撞击坐标，并让它返回哪些撞击属于一个粒子，哪些属于另一个粒子
我对输出的唯一想法是给遵循相同轨迹的每个撞击系列编号，编号相同，最后得到一个向量“命名”每个输入坐标。我怀疑神经网络是否可以“即兴”这样的标签，因为理论上它应该迭代的每个数字不一定与任何可能的输入有联系，唯一的条件是当它们不属于同一个粒子时，它们彼此不同。
有没有更好的方法可以做到这一点？这是否可以作为解决问题的合理方法？]]></description>
      <guid>https://stackoverflow.com/questions/78950639/using-a-neural-network-to-separate-inputs-into-groups</guid>
      <pubDate>Wed, 04 Sep 2024 21:41:04 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 尽管进行了子采样并且没有设置种子，仍然表现确定性吗？</title>
      <link>https://stackoverflow.com/questions/76691875/xgboost-behaving-deterministically-despite-subsampling-and-not-setting-seed</link>
      <description><![CDATA[据我所知，XGBoost（版本 1.7.4）中的子采样是随机进行的，因此应该将随机行为引入 xgboost - 随机梯度下降也应如此。但是，当我在相同的数据分割上训练/测试 xgboost 时，尽管没有在任何地方设置随机状态，但我总是得到相同的结果，这是为什么？
在定义 XGBoostRegressor 时，我尝试在有和没有 seed=42 的情况下运行代码。我为精心挑选的数据做了这件事，这样我就会知道随机行为只能源自 XGBoost 模型本身，而不是来自变量数据分割。]]></description>
      <guid>https://stackoverflow.com/questions/76691875/xgboost-behaving-deterministically-despite-subsampling-and-not-setting-seed</guid>
      <pubDate>Sat, 15 Jul 2023 01:24:32 GMT</pubDate>
    </item>
    <item>
      <title>预测黄瓜产量</title>
      <link>https://stackoverflow.com/questions/59382497/predicting-cucumber-harvest</link>
      <description><![CDATA[我正在尝试预测温室中黄瓜的收获量。我测量了有关湿度、温度、人造光、阳光和二氧化碳的数据。每天收获的黄瓜数量以公斤为单位。
由于黄瓜需要大约 14 天才能生长，因此前 14 天的测量数据会影响特定日期收获的黄瓜的实际数量。我已经通过将前 14 天的平均测量数据与给定日期的每个收获结果相关联来创建数据集，并使用该数据集训练预测模型。这已经给了我有希望的结果。
现在我想改进系统。我不想对前 14 天的数据取平均值并假设每一天的影响为 1/14，而是想找出对收获结果的实际影响（经验法则表明，收获前 1 天测量的数据对实际收获的黄瓜数量有 50% 的影响；我的目标是验证或改进该规则）。 有什么想法可以实现吗？]]></description>
      <guid>https://stackoverflow.com/questions/59382497/predicting-cucumber-harvest</guid>
      <pubDate>Tue, 17 Dec 2019 21:38:54 GMT</pubDate>
    </item>
    <item>
      <title>机器学习：使用卷积神经网络将图像分为 3 类（狗、猫或非猫）</title>
      <link>https://stackoverflow.com/questions/40853349/machine-learning-image-classification-into-3-classes-dog-or-cat-or-neither-us</link>
      <description><![CDATA[如果您能帮我仔细思考一下，我将不胜感激。我有一个分类器，可以成功地将图像分类为狗或猫，并且准确度很高。我有一个很好的数据集来训练分类器。到目前为止没有问题。
我有大约 20,000 张狗和 20,000 张猫的图像。
但是，当我尝试呈现其他图像（如汽车、建筑物或老虎）时，这些图像中既没有狗也没有猫，我希望分类器的输出为“既不是”。现在，分类器显然试图将所有东西都分类为狗或猫，这是不正确的。
问题 1：
我该如何实现这一点？我是否需要有第三组不包含狗或猫的图像，并在这些额外的图像上训练分类器以将其他所有图像识别为“既不”？
大致来说，我需要多少张非狗/猫类别的图像才能获得良好的准确率？由于非狗/猫图像域非常大，大约 50,000 张图像就可以了？或者我是否需要更多图像？
问题 2：
我可以使用 Imagenet 训练的 VGG16 Keras 模型作为初始层，并在顶部添加 DOG/CAT/Neither 分类器作为全连接层，而不是使用自己的图像数据训练自己的分类器？
查看此示例以加载预先训练的 imagenet 模型
非常感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/40853349/machine-learning-image-classification-into-3-classes-dog-or-cat-or-neither-us</guid>
      <pubDate>Mon, 28 Nov 2016 20:58:33 GMT</pubDate>
    </item>
    </channel>
</rss>