<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 02 Jan 2024 15:15:46 GMT</lastBuildDate>
    <item>
      <title>加载屏幕停留在“Building editable for Judgelm (pyproject.toml) ... /”</title>
      <link>https://stackoverflow.com/questions/77746734/loading-screen-stays-on-building-editable-for-judgelm-pyproject-toml</link>
      <description><![CDATA[我试图通过 GitHub 将 LLM 模型安装到我的电脑上，在 anaconda 命令 shell 上安装软件包时，加载屏幕很长一段时间没有改变。而且我也没有收到任何错误。
我读到pip升级可能会导致这种情况。然后我升级了 pip 但这个屏幕仍然保持在同一行。 文本
您可以通过此链接查看LLM模型。]]></description>
      <guid>https://stackoverflow.com/questions/77746734/loading-screen-stays-on-building-editable-for-judgelm-pyproject-toml</guid>
      <pubDate>Tue, 02 Jan 2024 14:39:07 GMT</pubDate>
    </item>
    <item>
      <title>Anaconda 键盘快捷键</title>
      <link>https://stackoverflow.com/questions/77746551/anaconda-keyboard-shortcut</link>
      <description><![CDATA[我可以使用哪个键盘快捷键在 Jupiter Anaconda 中显示以下面板（机器学习）？
在此处输入图像描述
我可以使用哪个键盘快捷键在 Jupiter Anaconda 中显示以下面板（机器学习）？
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/77746551/anaconda-keyboard-shortcut</guid>
      <pubDate>Tue, 02 Jan 2024 14:02:05 GMT</pubDate>
    </item>
    <item>
      <title>猜几个变量之和是一个固定值，如何预测这个固定值？</title>
      <link>https://stackoverflow.com/questions/77746513/guess-the-sum-of-several-variables-is-a-fixed-value-how-to-predict-this-fixed-v</link>
      <description><![CDATA[我知道数据框有三列（名为 A、B 和 C），现在我想预测
k1×A+k2×B+k3×C = 固定值D
A、B、C已知，k1、k2、k3、D未知（需要预测）。
如何预测这三个系数和这个固定值？
详情如下：
file_path = &#39;输入/CharacterData.xlsx&#39;
df = pd.read_excel(文件路径)
Five_star_data = df[df[&#39;star&#39;] == 5] # 选择五星级人物
X = Five_star_data[[&#39;生命值&#39;, &#39;攻击力&#39;, &#39;防御力&#39;]] # 这里我选择了关于五星级人物的三个三维度。而“生命值”、“攻击力”、“防御力”在英文中分别表示HP、ATK、DEF


我想预测：
k1×HP +k2×ATK +k3×DEF = 固定值D
肯定有误差，如何判断误差是大还是小？
另外，请原谅我的英语能力和机器学习水平不是很好。
首先，我尝试将 D 设置为固定值 1：
X = Five_star_data[[&#39;生命值&#39;, &#39;攻击力&#39;, &#39;防御力&#39;]]
y 值 = 1
y = pd.DataFrame(np.full((X.shape[0], 1), y_value))
lin_reg = 线性回归()
lin_reg.fit(X, y)
print(lin_reg.intercept_) # [1.]
打印（lin_reg.coef_）# [[0。 0.0.]]

我认为，因为X(HP,ATK,DEF)改变了，但y是固定的。所以线性回归模型认为A,B,C的系数应该为0，截距正好为1。
其次，我选择 HP(&#39;生命值&#39;) 作为 y，并将 HP 降低到 X。像这样：
X = Five_star_data[[&#39;生命值&#39;, &#39;攻击力&#39;, &#39;防御力&#39;]]
X_1 = X.drop([“生命值”], axis=1)
y = Five_star_data[&#39;生命值&#39;]
y = -y
lin_reg = 线性回归()
lin_reg.fit(X_1, y)
打印（lin_reg.intercept_）＃-9252.295197338677
打印（lin_reg.coef_）＃[5.60260844-6.41900625]

可以得到结果，但不知道是否合适。
是的，我将问题更改为：
-HP = k1×ATK + K2×EF + D。
我觉得可以改成原来的问题：
HP + k1×ATK + K2×DEF = -D。
感谢您给我一些帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77746513/guess-the-sum-of-several-variables-is-a-fixed-value-how-to-predict-this-fixed-v</guid>
      <pubDate>Tue, 02 Jan 2024 13:53:56 GMT</pubDate>
    </item>
    <item>
      <title>汇编语言 - 构造符号并查找地址[关闭]</title>
      <link>https://stackoverflow.com/questions/77746138/assembly-language-construct-the-symbol-find-the-address</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;.ORIG x3000
LEA R2，字符串
LD R3，编号
此处添加 R1、R2、R3
添加 R2、R1、#0
LDR R0、R1、#0
BRz 完成
出去
在这里
这个.BLKW 6
STRING .STRINGZ “2down_3to_go”
数字.填充 x4
完成暂停
。结尾

构建程序的符号表&amp;找到地址

&lt;表类=“s-表”&gt;
&lt;标题&gt;

符号
地址


&lt;正文&gt;

这里
x3002


这个



字符串



数量



完成





尝试评估说明，但并不真正了解如何查找地址]]></description>
      <guid>https://stackoverflow.com/questions/77746138/assembly-language-construct-the-symbol-find-the-address</guid>
      <pubDate>Tue, 02 Jan 2024 12:42:14 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Keras ValueError：“predict_function”的意外结果（空batch_outputs）</title>
      <link>https://stackoverflow.com/questions/77745874/tensorflow-keras-valueerror-unexpected-result-of-predict-function-empty-batc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77745874/tensorflow-keras-valueerror-unexpected-result-of-predict-function-empty-batc</guid>
      <pubDate>Tue, 02 Jan 2024 11:47:52 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML (TensorFlow-Pytorch) 中几乎没有要预测的列，是否有一个库可以以人工方式创建“人工”列？</title>
      <link>https://stackoverflow.com/questions/77745811/i-have-few-columns-to-predict-in-my-ml-tensorflow-pytorch-is-there-a-library</link>
      <description><![CDATA[我在 ML 中几乎没有要预测的列。
我想要：

生成额外的列（正弦、平均值等）。

应该评估这些额外的列（无论它是否改进模型）。


我的 ML 中需要更多数据来预测的列很少。例如，我有一个以度为单位的角度数据，我取了正弦、余弦和正切值。
我想要所有类型的统计数据（对机器学习有效，即前瞻性），以及任何类型的“阿里”数据。 自动为提供数据机器学习模型 (TensorFlow-Pytorch)。提供到具有这些功能的库的链接，以生成“人工”文件。数据或机器学习。 （我不是在寻找 SMOTE）
额外，如果它会为我评估它们??？了解使用哪些输入 fit()。]]></description>
      <guid>https://stackoverflow.com/questions/77745811/i-have-few-columns-to-predict-in-my-ml-tensorflow-pytorch-is-there-a-library</guid>
      <pubDate>Tue, 02 Jan 2024 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>数字预测的准确度为 0%</title>
      <link>https://stackoverflow.com/questions/77744924/digit-predication-give-0-accuracy</link>
      <description><![CDATA[我需要使用袖珍算法制作一个数字分类器进行二元分类。因为这是一个 10 位数字的问题，所以我需要使用一对一的方法。我已经实现了基本的学习算法来找到每个分类器的权重。我对所有数字的准确率约为 98%

现在，当我运行测试数据时，我得到了 0.3% 的准确度，甚至没有 1 个正确的预测。我不太确定哪里出了问题，因为看起来每个数字的准确度有点高。如果有人能指出我的错误在哪里或者我做错了什么，那就太好了。
这是代码：
将 numpy 导入为 np
# 获取mnist数据
从 sklearn.datasets 导入 fetch_openml
从 sklearn.model_selection 导入 train_test_split

mnist = fetch_openml(&#39;mnist_784&#39;, 版本=1)
x, y = mnist[&#39;数据&#39;], mnist[&#39;目标&#39;]
x = x / 255.0 # 标准化数据


# 添加偏差的函数
def add_bias(x):
    偏差 = np.ones((x.shape[0], 1))
    返回 np.concatenate((偏差, x), 轴=1)


# 返回点积的符号。用作谓词
def 预测（权重，x）：
    返回 np.sign(np.dot(x, 权重))


def update_weights(权重, x, y):
    对于范围内的 i(len(x))：
        预测 = 预测（权重，x[i]）
        if y[i] * 预测 &lt;= 0: # 错误分类
            权重 = 权重 + y[i] * x[i]
    返回权重


# 确定权重准确性的函数
def calc_acc(权重, x, y):
    预测=预测（权重，x）
    正确 = sum(预测 == y)
    返回正确的/len(y)


def Predict_all_classifiers（分类器，样本）：
    # 将每个分类器应用于样本
    预测 = [np.dot(样本, 分类器[数字]) 对于范围(10) 中的数字]
    # 选择输出值最高的分类器
    返回 np.argmax(预测)


digital_classifier = {} # 字典来存储每个分类器的权重
y = y.astype(int) # 将数据转换为整数
对于范围 (10) 中的数字：
    # 准备数据：
    y_binary = (y == digital).astype(int) * 2 - 1 # 创建二进制目标数组
    # 将数据分割为 60K 用于训练，10K 用于测试
    X_train，X_test，y_train，y_test = train_test_split（x，y_binary，train_size = 60000，test_size = 10000，random_state = 42）
    X_train = X_train.值
    X_test = X_test.值
    y_train = y_train.值
    y_test = y_test.值

    # 初始化权重向量
    权重 = np.zeros(785) # 权重向量
    X_train_bias = add_bias(X_train) # 添加偏差值
    X_test_bias = add_bias(X_test) # 添加偏差值
    pocket_weights = np.copy(权重)

    # 使用袖珍算法训练分类器 1000 个时期
    历元 = 1000
    最佳_acc = 0.0

    对于范围内的纪元（纪元）：
        curr_weights = update_weights(np.copy(pocket_weights), X_train_bias, y_train)
        curr_acc = calc_acc(curr_weights, X_train_bias, y_train)
        如果 curr_acc &gt;最佳_ACC：
            最佳_acc = 当前_acc
            pocket_weights = np.copy(curr_weights)

    print(&quot;数字的最佳准确度：&quot; + str(digit) + &quot; 是：&quot; + str(best_acc))
    digital_classifier[digit] = pocket_weights # 将分类器添加到字典中

    # 根据测试数据进行预测和评估
    正确预测 = 0
    对于范围内的 i(len(X_test_bias))：
        # 预测数字
        Predicted_digit = Predict_all_classifiers(digit_classifier, X_test_bias[i])

        # 检查预测是否正确
        如果预测数字 == y_test[i]：
            正确预测 += 1

    # 计算准确率
    准确度 = Correct_predictions / len(X_test)
    print(f&quot;测试数据的准确度：{accuracy * 100}%&quot;)

1： ]]></description>
      <guid>https://stackoverflow.com/questions/77744924/digit-predication-give-0-accuracy</guid>
      <pubDate>Tue, 02 Jan 2024 08:35:38 GMT</pubDate>
    </item>
    <item>
      <title>加载 pcapng 文件时出现“ValueError：文件未以正确的节标题开头”</title>
      <link>https://stackoverflow.com/questions/77744885/valueerror-file-not-starting-with-a-proper-section-header-while-loading-pcapn</link>
      <description><![CDATA[代码快照
我正在尝试从 5G-DAD 数据集加载 pcapng 文件。请帮我解决错误
数据集提供者的代码
数据集提供者的github上已经给出了数据准备的代码，但是代码显示错误“Not asupported capture file”
相同代码但有错误]]></description>
      <guid>https://stackoverflow.com/questions/77744885/valueerror-file-not-starting-with-a-proper-section-header-while-loading-pcapn</guid>
      <pubDate>Tue, 02 Jan 2024 08:28:03 GMT</pubDate>
    </item>
    <item>
      <title>将 Yolov8 模型转换为 Onnx 并在 OpenCV 中使用它 [IndexError：标量变量的索引无效]</title>
      <link>https://stackoverflow.com/questions/77744584/converting-yolov8-model-to-onnx-and-used-it-in-opencv-indexerror-invalid-index</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;导入cv2
将 numpy 导入为 np

# 加载 ONNX 模型
模型 = cv2.dnn.readNetFromONNX(“best.onnx”)

# 从数据集中加载图像
image = cv2.imread(“image3.jpg”)

# 根据YOLOv8的要求对图像进行预处理（调整大小、标准化等）
# 您可能需要根据您的YOLOv8模型的具体要求调整这些预处理步骤
调整大小的图像 = cv2.resize(图像, (640, 640))
调整大小的图像 = 调整大小的图像.astype(np.float32) / 255.0
调整大小的图像 = np.transpose(调整大小的图像, (2, 0, 1))
调整大小的图像 = np.expand_dims(调整大小的图像，轴=0)

# 将预处理后的图像设置为模型的输入
model.setInput(调整大小的图像)

# 进行推理
输出 = model.forward()

# YOLOv8 输出格式通常是检测列表，其中每个检测都有：
# - 类别概率（索引 5 到末尾）
# - 客观性得分（索引 4）
# - 边界框坐标（索引 0 到 3）

# 循环检测
用于输出[0, 0]中的检测：
    Scores = detector[5:] # 获取类别概率
    class_id = np.argmax(scores) # 获取概率最大的类
    置信度 = 分数[class_id]

    # 检查头盔类别（假设头盔的类别 ID 0）和置信度阈值
    如果 class_id == 0 且置信度 &gt; 0.5: # 根据需要调整置信度阈值
        x, y, w, h = (检测[0:4] * np.array([image.shape[1], image.shape[0], image.shape[1], image.shape[0]]) ).astype(int)

        # 绘制边界框
        cv2.矩形(图像, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(图像, &quot;头盔&quot;, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# 显示或保存带有边界框的图像
cv2.imshow(“头盔检测”, 图片)
cv2.waitKey(0)
cv2.destroyAllWindows()

我正在使用我的头盔检测模型权重来使用 opencv 来预测图片周围的类标签和边界框，但它给了我一个错误：
回溯（最近一次调用最后一次）：
文件“/home/arhamriaz/Desktop/opencvmodel/main.py”，第 30 行，位于
Scores = detector[5:] # 获取类别概率
IndexError：标量变量的索引无效。]]></description>
      <guid>https://stackoverflow.com/questions/77744584/converting-yolov8-model-to-onnx-and-used-it-in-opencv-indexerror-invalid-index</guid>
      <pubDate>Tue, 02 Jan 2024 07:08:55 GMT</pubDate>
    </item>
    <item>
      <title>像耳语这样的语音转文本 API 有哪些？</title>
      <link>https://stackoverflow.com/questions/77744493/what-are-the-speech-to-text-apis-like-whisper</link>
      <description><![CDATA[所以我需要为我的项目提供语音转文本功能。它需要是多语言的（特别是印地语和英语）
我尝试过耳语 - openAI 和它的拥抱版本。基础版本和中等版本效果最好，因为我需要高精度和快速响应，但问题是，当我使用 ai 时，基础版本比我想要的更不准确英语以外的语言。另一方面，Medium 具有出色的准确性，但需要的时间太长。还有哪些其他 API 可以替代 Whisper ??]]></description>
      <guid>https://stackoverflow.com/questions/77744493/what-are-the-speech-to-text-apis-like-whisper</guid>
      <pubDate>Tue, 02 Jan 2024 06:42:29 GMT</pubDate>
    </item>
    <item>
      <title>Model.predict() 给出相同的值 [-2147483648]</title>
      <link>https://stackoverflow.com/questions/77743313/model-predict-give-same-value-2147483648</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77743313/model-predict-give-same-value-2147483648</guid>
      <pubDate>Mon, 01 Jan 2024 20:52:09 GMT</pubDate>
    </item>
    <item>
      <title>正确处理具有可选成员（可以没有）的模型？</title>
      <link>https://stackoverflow.com/questions/77743228/handling-models-with-optional-members-can-be-none-properly</link>
      <description><![CDATA[我有 torch.nn.Module 的子类，其初始化程序具有以下形式：
（A类）
def __init__(self,additional_layer=False):
    ...
    如果附加层：
        self.additional = nn.Sequential(nn.Linear(8,3)).to(self.device)
    别的：
        self.additional = 无
    ...
    ...

我使用additional_layer=True 进行训练，并使用torch.save 保存模型。我保存的对象是model.state_dict()。然后我加载模型进行推理。但后来我收到以下错误：
model.load_state_dict(best_model[“my_model”])

RuntimeError：加载 A 的 state_dict 时出错：
        state_dict 中出现意外的键：“additional.0.weight”

是否使用了不允许为 None 的可选字段？如何正确处理这个问题？ [还发布在此处]]]></description>
      <guid>https://stackoverflow.com/questions/77743228/handling-models-with-optional-members-can-be-none-properly</guid>
      <pubDate>Mon, 01 Jan 2024 20:21:44 GMT</pubDate>
    </item>
    <item>
      <title>使用有限数量的直线重建图像的误差函数</title>
      <link>https://stackoverflow.com/questions/77740980/error-function-to-reconstruct-an-image-using-limited-number-of-straight-lines</link>
      <description><![CDATA[我目前正在从事一个项目，我想使用直线重建黑白图像。
图像经过充分预处理，因此没有大的黑色区域。图像大多是带有曲线的白色画布。您可以在边缘检测算法之后思考类似图像的情况。我的目的是仅使用 N 条直线重建图像。 N 将是一个很小的数字，比如说 100。所以基本上，这就像尝试将图像还原为可以用少量线条绘制的非常合成的版本。
我的主要挑战在于确定合适的方法或损失函数来准确比较原始图像与其重建图像。由于我使用直线来近似图像中存在的复杂形状和细节，均方误差 (MSE) 或平均绝对误差 (MAE) 等标准指标可能无法充分捕捉两种表示之间的相似性。
有人可以推荐一种更合适的损失函数或评估方法来衡量原始图像与其基于线的重建之间的保真度吗？我对解释用直线近似弯曲或复杂形状的性质的方法特别感兴趣。
此外，如果有人对通常用于使用线条进行图像近似的特定技术或算法有经验或知识，我将非常感谢任何相关资源的指示或参考。我找到了 这篇 codegolf 帖子，但方法不同。在那里，他们用颜色和线条重建了整个图像。
我想要使用的示例图像如下：

]]></description>
      <guid>https://stackoverflow.com/questions/77740980/error-function-to-reconstruct-an-image-using-limited-number-of-straight-lines</guid>
      <pubDate>Mon, 01 Jan 2024 04:39:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么“sklearn.svm.LinearSVC”的执行时间比“sklearn.svm.SVC”要长？ [复制]</title>
      <link>https://stackoverflow.com/questions/77731956/why-is-sklearn-svm-linearsvc-taking-longer-to-execute-than-sklearn-svm-svc</link>
      <description><![CDATA[我正在使用 scikit-learn 中的 LinearSVC 和 SVC 类执行超参数调整，尽管我使用  执行的搜索量增加了 10 倍SVC类比LinearSVC执行时间短很多，可能是什么原因呢？我认为 LinearSVC 更优化。
我正在使用 Olivetti 面孔数据集
这是我正在执行的两个搜索：
从 sklearn.svm 导入 LinearSVC
从 sklearn.svm 导入 SVC
从 sklearn.model_selection 导入 GridSearchCV

#LinearSVC超参数调优------------------------
参数网格 = [
    {&#39;svc__C&#39;: np.logspace(-3,3, num=10)}
]

full_pipeline = 管道([
    (“预处理”, StandardScaler(with_mean=False)),
    (“svc”,LinearSVC(random_state=0))
    ]）

svc_rnd_search = GridSearchCV(full_pipeline, param_grid=param_grid, cv=10,
                           评分=&#39;准确度&#39;,n_jobs=-1)

# 测量执行时间
开始时间 = 时间()

#运行搜索
svc_rnd_search.fit(X_train, y_train)

# 计算执行时间
结束时间 = 时间()
执行时间毫秒 = (结束时间 - 开始时间) * 1000
print(f&quot;执行时间: {execution_time_ms:.3f}ms&quot;)

#SVC超参数调优------------------------------------------------
参数网格 = [
    {&#39;svc__C&#39;: np.logspace(-2,3, num=10),
     &#39;svc__gamma&#39;: np.logspace(-5,1, num=10),
     &#39;svc__kernel&#39;: [&#39;rbf&#39;]}
]

full_pipeline = 管道([
    (“预处理”, StandardScaler(with_mean=False)),
    (“svc”,SVC())
    ]）

svc_rnd_search = GridSearchCV(full_pipeline, param_grid=param_grid, cv=10,
                           评分=&#39;准确度&#39;,n_jobs=-1)

# 测量执行时间
开始时间 = 时间()

#运行搜索
svc_rnd_search.fit(X_train, y_train)

# 计算执行时间
结束时间 = 时间()
执行时间毫秒 = (结束时间 - 开始时间) * 1000
print(f&quot;执行时间: {execution_time_ms:.3f}ms&quot;)

第一个代码块 (LinearSVC) 的执行时间为 1087635 毫秒，而 SVC 类的执行时间为 36961 毫秒。]]></description>
      <guid>https://stackoverflow.com/questions/77731956/why-is-sklearn-svm-linearsvc-taking-longer-to-execute-than-sklearn-svm-svc</guid>
      <pubDate>Fri, 29 Dec 2023 12:18:51 GMT</pubDate>
    </item>
    <item>
      <title>预测后如何取消数据缩放？</title>
      <link>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</link>
      <description><![CDATA[我有一个具有 2 个特征（价格和数量）的数据集1 个预测变量（价格），并使用 LTSM 模型根据前一组价格预测下一个价格。
首先我缩放数据集：
#缩放数据
缩放器 = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(数据集)

最后我想取消缩放：
#获取模型预测价格值
预测 = model.predict(x_test)
预测=scaler.inverse_transform(预测)

但这不起作用，我收到此错误：
ValueError：形状为 (400,1) 的不可广播输出操作数与广播形状 (400,2) 不匹配
]]></description>
      <guid>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</guid>
      <pubDate>Wed, 12 Aug 2020 16:20:50 GMT</pubDate>
    </item>
    </channel>
</rss>