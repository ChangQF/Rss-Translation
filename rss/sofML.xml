<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 18 Nov 2024 12:35:34 GMT</lastBuildDate>
    <item>
      <title>带有 Weka Predictions 的 Spring Boot 应用程序在构建后的第一天运行正常，但随后几天出现故障</title>
      <link>https://stackoverflow.com/questions/79198921/spring-boot-application-with-weka-predictions-works-on-the-first-day-after-build</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79198921/spring-boot-application-with-weka-predictions-works-on-the-first-day-after-build</guid>
      <pubDate>Mon, 18 Nov 2024 06:46:44 GMT</pubDate>
    </item>
    <item>
      <title>如何提高扫描文档的 OCR 准确率？[关闭]</title>
      <link>https://stackoverflow.com/questions/79198907/how-to-improve-ocr-accuracy-on-scanned-document</link>
      <description><![CDATA[我正在构建一个应用程序，它将从扫描的格式化文档中提取信息。该文档是计算机生成的，带有一些人工注释，但我们只需要关注计算机生成的信息。
解决方案需要完全离线，模型必须能够在 4 核 CPU Windows 服务器上运行。
我当前的解决方案

检测文档的格式：我正在使用模式匹配来匹配徽标是否出现在文档中。
每个文档都有一组固定的矩形，我将根据文档格式将它们裁剪掉。 [(field, (x1, y1, w, h)), ...]
裁剪后，我使用 tesseract-ocr api 识别裁剪矩形中的文本。
映射回去构造一个 json。

问题

固定的矩形集不起作用，因为不同扫描仪扫描的文档会有不同的偏移量。文档可能会溢出，导致新的换行符。
tesseract-ocr 识别文本的准确率只有 80%。

我已经使用指定的字体和常用词对 tesseract-ocr 模型进行了微调。它确实将准确率从 50% 提高到了 80%。但之后就没那么好了。
我期望文本识别的准确率达到 99%。]]></description>
      <guid>https://stackoverflow.com/questions/79198907/how-to-improve-ocr-accuracy-on-scanned-document</guid>
      <pubDate>Mon, 18 Nov 2024 06:42:40 GMT</pubDate>
    </item>
    <item>
      <title>EOFError：输入不足 - Pickle</title>
      <link>https://stackoverflow.com/questions/79198550/eoferror-ran-out-of-input-pickle</link>
      <description><![CDATA[当我尝试以 pickle 格式加载机器学习模型以便它在 Web 应用程序中运行时，我收到此错误，路径显然是正确的，我的所有文件都位于同一文件夹中。但是，错误始终存在，非常感谢您的宝贵帮助

df = pd.DataFrame.from_dict(user_values, orient=&quot;index&quot;).T

with open(&quot;classifier.pkl&quot;, &quot;rb&quot;) as file:
loaded_model = pickle.load(file)

prediction = loaded_model.predict(df)[0][0]

else:
prediction = None

return render_template(&quot;index.html&quot;, prediction=prediction)

if __name__ == &quot;__main__&quot;:
app.run(debug=True)

]]></description>
      <guid>https://stackoverflow.com/questions/79198550/eoferror-ran-out-of-input-pickle</guid>
      <pubDate>Mon, 18 Nov 2024 02:30:01 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到用于基于 AI 的骨折检测的 X 射线图像医学数据集？[关闭]</title>
      <link>https://stackoverflow.com/questions/79198520/where-can-i-find-a-medical-dataset-of-x-ray-images-for-ai-based-bone-fracture-de</link>
      <description><![CDATA[我正在开展一个 AI 项目，该项目专注于骨折检测，以提高老年人的安全性。为此，我需要一个公开可用的数据集，其中包含骨骼（有骨折和无骨折）的 X 射线图像，以训练和评估深度学习模型。
以下是我在数据集中寻找的具体标准：
• 应包括带标签的 X 射线图像（骨折和非骨折病例）。
• 最好包含元数据，例如患者年龄或骨骼类型（例如手臂、腿、臀部）。
• 理想情况下，数据集应具有足够的样本进行训练（至少 1,000 张或更多图像）。
我已经检查过 Kaggle 和开放获取生物医学图像搜索引擎 (OASIS) 等来源，但找不到适合特定于骨折的数据集。
还有其他资源、存储库或数据集符合这些要求吗？任何建议都将不胜感激！
我在 Kaggle 和开放获取生物医学图像搜索引擎 (OASIS) 等平台上搜索了包含带标签的骨折 X 射线图像的数据集，但找不到符合我的项目要求的数据集。
我希望找到一个带有带标签图像（骨折和非骨折骨骼）和足够元数据（例如患者年龄或骨骼类型）的数据集，用于我的基于 AI 的骨折检测项目。
我找到的数据集要么太小，要么不包含带标签的图像，要么缺少必要的元数据]]></description>
      <guid>https://stackoverflow.com/questions/79198520/where-can-i-find-a-medical-dataset-of-x-ray-images-for-ai-based-bone-fracture-de</guid>
      <pubDate>Mon, 18 Nov 2024 02:00:57 GMT</pubDate>
    </item>
    <item>
      <title>惩罚逻辑回归的 F 分数、精度和召回率指标</title>
      <link>https://stackoverflow.com/questions/79198299/f-score-precision-and-recall-metrics-for-a-penalized-logistic-regression</link>
      <description><![CDATA[我正在尝试对我制作的惩罚逻辑回归模型进行交叉验证。
我还注意到，互联网上的一些示例假设我只是手动输入完整数据集中的实际数字和预测数字数组（谁有时间做这个哈哈？）。
我之前使用 JuliusAI 是因为它可以开箱即用地报告这些内容，但我又回到了 R，因为我现在不相信 Julius 的可重复性（为了全面披露），并且停止使用它，尽管按钮分析很有诱惑力。我希望能够自己忠实地计算这些指标，并且是使用 R 中的交叉验证的新手（通常已经完成了 AIC 和重要性统计）。但关于 JuliusAI 就说这么多。
问题就在这里。我有一个数据集（n=32），我使用 80/20 分割来训练和测试。那部分没问题。我的预测变量是二进制的。训练数据集称为 train（25 行），测试称为 test（有 7 行）。惩罚逻辑回归模型有 3 个预测变量，结果为失败或不失败。回归过程运行良好，因此我添加了混淆矩阵来获得所需的结果。
我一直在尝试使用 ConfusionMatrix 命令，但一直收到“混淆矩阵中的错误：数据和参考因素必须具有相同数量的级别”。
这是我使用的：
 library(rsample)
library(caret)
library(logistf)
split &lt;- initial_split(newdata1, prop = .8)
train &lt;- training(split)
test &lt;- testing(split)
fit &lt;- logistf(data=train, newdata1$`Fail (1=yes)`~ 
newdata1$`rev`+newdata1$`totassets`+newdata1$`totliab`)
prediction &lt;- predict(fit, data = test, type = &#39;response&#39;)
pred &lt;- factor(ifelse(prediction &lt;= 0.5,0,1))
result &lt;- caret::confusionMatrix(pred,test$`Fail (1=yes)`)

于是，我尝试：
 cm &lt;- chaosMatrix(pred, as.factor(test$`Fail (1=yes)`)

结果为“error in chaosMatrix.default(pred, as.factor(test$Fail (1=yes))) :
数据不能比参考值有更多级别”
chaosMatrix(pred,as.factor(test$Fail (1=yes)))
confusionMatrix.default(pred, as.factor(test$Fail (1=yes))) 中的错误：
数据不能比参考值具有更多级别
有没有更直接的方法来执行此操作并获取指标？我以为有一个 F1 分数命令，但似乎这需要一个 y_pred，我不知道如何生成或访问它（除非通过 predict()）。
可能是因为我的数据集有 10 个变量，而我使用了其中的 3 个，还是因为拆分？我该如何解决这个问题？
你的建议？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79198299/f-score-precision-and-recall-metrics-for-a-penalized-logistic-regression</guid>
      <pubDate>Sun, 17 Nov 2024 22:38:11 GMT</pubDate>
    </item>
    <item>
      <title>项目 ML 预测设置 [关闭]</title>
      <link>https://stackoverflow.com/questions/79197789/project-ml-forecasting-setup</link>
      <description><![CDATA[我是数据科学的新手，目前正在从事一个预测来年产品销售的项目。我有过去三年中每种产品的每日历史销售数据。
我的目标是使用预测模型（如随机森林）预测明年全年的销售额。但是，我很难理解如何在没有任何实际销售数据的情况下对未来时期进行预测。
我当前的数据集（基表）包括以下特征：

product_id
purchase_date
purchase_year
purchase_month
sales（目标变量）
product_category
滞后特征（例如前几天或前几周的销售额）

我不确定如何根据这些数据预测未来的销售额。您能否帮助我了解该过程并帮助我如何为该任务设置模型和基表（高级）？重要的一点是，预测应按年度针对每个产品进行。]]></description>
      <guid>https://stackoverflow.com/questions/79197789/project-ml-forecasting-setup</guid>
      <pubDate>Sun, 17 Nov 2024 17:42:37 GMT</pubDate>
    </item>
    <item>
      <title>有条件地更改 RGB 图像中的像素值，然后删除通道</title>
      <link>https://stackoverflow.com/questions/79196999/conditionally-changing-the-pixel-values-in-an-rgb-image-then-removing-the-chann</link>
      <description><![CDATA[我只想比较图像的像素，如果这个像素是粉红色（R 值 = 0.502、G 值 = 0.0、B 值 = 0.502）则将其更改为黑色，否则将其更改为白色。在此之后，我想删除通道，只得到一个 (512,512,) 形状的张量。
此 getitem 位于我的数据集类中。
代码：
 def __getitem__(self, index):
img = Image.open(self.images[index]).convert(&quot;RGB&quot;) # 这是一张图像
mask = Image.open(self.masks[index]).convert(&quot;RGB&quot;) # 这是相应的掩码
mask = self.transform_tensor(mask) # 张量为 (3,512,512) 形状
mask = torch.where((mask[0, :, :] == 0.502) &amp; (mask[1, :, :] == 0.0) &amp; (mask[2, :, :] == 0.502), torch.tensor([0.0, 0.0, 0.0]), torch.tensor([1.0, 1.0, 1.0])) # 错误
mask = self.transform_to_image(mask)
mask.show()
return self.transform_image(img), self.transform_mask(mask)


RuntimeError: 张量 a (512) 的大小必须与非单例维度 1 上的张量 b (3) 的大小匹配
错误：意外类型：(bool, Tensor, Tensor)]]></description>
      <guid>https://stackoverflow.com/questions/79196999/conditionally-changing-the-pixel-values-in-an-rgb-image-then-removing-the-chann</guid>
      <pubDate>Sun, 17 Nov 2024 10:36:45 GMT</pubDate>
    </item>
    <item>
      <title>ResNet50 模型在测试集上具有较高的准确率，但在手动测试时在同一组上表现不佳</title>
      <link>https://stackoverflow.com/questions/79196985/resnet50-model-has-high-accuracy-on-test-set-but-performs-poorly-on-the-same-set</link>
      <description><![CDATA[我是机器学习的新手，我正在尝试在约 100 个类别的数据集上训练 ResNet50 模型。
为此，我首先使用 splitfolders 将数据拆分为训练集、验证集和测试集，然后将这些集保存在单独的文件夹中。然后我预处理数据，定义我的特定模型并在训练集上对其进行训练。随后，我保存模型并在测试集上对其进行评估。到目前为止，一切似乎都运行良好，我在测试集上的准确率约为 0.89。
但是，然后我尝试在同一个测试集上手动测试模型。我从最大的类开始，它运行良好。然而，对于较小的类，所有预测都是错误的。奇怪的是，大多数这些错误的预测都是相同的，例如。 63 类中的大多数图像被预测为 62 类，15 类中的大多数图像被预测为 7 类等等……所以在我看来，该模型实际上可能做出了正确的预测，但将它们与错误的类别相关联……总而言之，有太多错误的预测无法达到 0.89 的准确率。
我想我可能犯了一些相当愚蠢的错误，因为我的手动测试导致的结果与模型的先前评估如此不同，这毫无道理？有人知道这里可能是什么问题吗？
我用来手动测试测试集中文件夹的预测的代码如下：
# 遍历文件夹中的所有图像
for img_file in os.listdir(folder_path):
img_path = os.path.join(folder_path, img_file)

# 加载并预处理图像
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = tf.keras.applications.resnet50.preprocess_input(img_array)

# 进行预测
predictions = model.predict(img_array)
prediction_class = np.argmax(predictions)

print(f&quot;图像：{img_file} - 预测的类：{predicted_class}&quot;)

将上述代码循环遍历所有类文件夹，并在每次预测后更新准确率：
total_samples = 0
correct_predictions = 0

# 遍历代表类的每个子文件夹
for class_folder in os.listdir(parent_folder_path):
class_folder_path = os.path.join(parent_folder_path, class_folder)

# 遍历类文件夹中的所有图像
for img_file in os.listdir(class_folder_path):
img_path = os.path.join(class_folder_path, img_file)

# 加载并预处理图像
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0)
img_array = tf.keras.applications.resnet50.preprocess_input(img_array)

# 进行预测
predictions = model.predict(img_array)
predict_class = np.argmax(predictions)

total_samples += 1
if predict_class == int(class_folder): #文件夹名称由代表类别的数字组成
correct_predictions += 1

current_accuracy = correct_predictions/ total_samples * 100

print(f&quot;图像：{img_file} - 预测类别：{predicted_class} - 实际类别：{int(class_folder)} -正确预测：{correct_predictions} - 总样本数：{total_samples} - 当前准确率：{current_accuracy:.2f}%&quot;)

我用来评估模型的代码如下：
test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)

test_generator = test_datagen.flow_from_directory(
test_data_dir,
target_size=(img_height, img_width),
batch_size=1,
class_mode=&quot;categorical&quot;
)

test_loss, test_acc = model.evaluate(test_generator, verbose=2)
print(&quot;\nTest accuracy:&quot;, test_acc)
]]></description>
      <guid>https://stackoverflow.com/questions/79196985/resnet50-model-has-high-accuracy-on-test-set-but-performs-poorly-on-the-same-set</guid>
      <pubDate>Sun, 17 Nov 2024 10:29:27 GMT</pubDate>
    </item>
    <item>
      <title>XGBRegressor 模型在时间序列模型中欠拟合</title>
      <link>https://stackoverflow.com/questions/79196179/xgbregressor-model-underfitting-in-time-series-model</link>
      <description><![CDATA[编辑：添加 10 个数据点的 repex。
data = {
&quot;time&quot;: [327, 330, 333, 336, 339, 342, 345, 348, 351, 354],
&quot;resistance&quot;: [140000.0, 139000.0, 137000.0, 136000.0, 134000.0,
134000.0, 133000.0, 132000.0, 132000.0, 131000.0]
}
df = pd.DataFrame(data)

我正在尝试拟合 XGBRegressor 来预测传感器的未来行为。数据具有 6 个周期的季节性。当我拟合数据时，训练的 RMSE 会下降，而测试的 RMSE 不会下降太多并开始上升。如果我将学习率改为 1，将最大深度改为 3，它会在训练数据上过度拟合，但在测试上是一条直线。以下是模型的代码训练数据预测
from xgboost import XGBRegressor
model = XGBRegressor(n_estimators = 1000, early_stopping_rounds = 50,
learning_rate = 0.01, max_depth = 5)
model.fit(X_train, Y_train, 
eval_set = [(X_train, Y_train), (X_test, Y_test)],
verbose = 10)

# 对训练数据进行预测
Y_train_pred = model.predict(X_train)

供参考：X 有 3 个特征是时间（每个点为 3 秒），其他 2 个是
sin_time = 0.5 * np.sin(time) * 2 * np.sin(time) * time 
sin_2pi_time = np.sin(2 * np.pi * time)

Y 是阻力
尝试更改参数，但没有成功，即使我过度拟合模型，训练数据预测也是一条直线 测试数据预测
这是 graphviz 可视化的 5 个最大深度的决策树 tree
此外，这是 打印的 3 个特征的重要性特征重要性
[9.9349368e-01 5.7454295e-03 7.6084811e-04]]]></description>
      <guid>https://stackoverflow.com/questions/79196179/xgbregressor-model-underfitting-in-time-series-model</guid>
      <pubDate>Sat, 16 Nov 2024 22:36:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中为 Nvidia GeForce RTX 3050 Ti 启用 CUDA？</title>
      <link>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</link>
      <description><![CDATA[我想在我的显卡（Nvidia GeForce RTX 3050 Ti）上运行 PyTorch 库（我在 PyCharm 的虚拟环境中运行该库）。但是，它在 CPU 上运行，每当我使用命令 import torch 和 print(&quot;cuda is available:&quot;, torch.cuda.is_available()) 时，它总是返回 False。
我安装了 CUDA 版本 12.6。我还安装了 PyTorch for CUDA 版本 12.4，因为它是 PyTorch 网站上可用的最新版本。考虑到我的显卡类型，我应该安装什么？]]></description>
      <guid>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</guid>
      <pubDate>Thu, 07 Nov 2024 04:30:29 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 中的眼睛标志模型无法跟踪看不见的数据</title>
      <link>https://stackoverflow.com/questions/79149930/eye-landmark-model-in-tensorflow-not-tracking-with-unseen-data</link>
      <description><![CDATA[我一直在使用 UTKFace 数据集创建一个模型，该模型将绘制图像中眼睛周围的点。我使用的训练集大小约为 40000 张图像，包含缩放、旋转和平移的增强图像。它与训练集和验证集配合得很好。但当我用该集中的新增强图像测试它时，它不起作用。我尝试过稍微调整一些参数和训练时间，但结果并没有发生很好的变化。
我的层目前看起来像这样：


inputs = tf.keras.layers.Input(shape=(200, 200, 1))
x = tf.keras.layers.Conv2D(32, kernel_size=(5, 5))(inputs)
x = tf.keras.layers.ReLU()(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)

x = tf.keras.layers.Conv2D(64, kernel_size=(3, 3))(x)
x = tf.keras.layers.ReLU()(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)

x = tf.keras.layers.Conv2D(128, kernel_size=(3, 3))(x)
x = tf.keras.layers.ReLU()(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)

x = tf.keras.layers.Conv2D(256, kernel_size=(3, 3))(x)
x = tf.keras.layers.ReLU()(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)

x = tf.keras.layers.Conv2D(512, kernel_size=(3, 3))(x)
x = tf.keras.layers.ReLU()(x)
x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)

# 线性层。
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(units=256, kernel_regularizer=tf.keras.regularizers.l2(0.1))(x)
x = tf.keras.layers.ReLU()(x)
x = tf.keras.layers.Dense(units=24)(x)




这是训练后验证集的样例输出，这就是我想要的结果。

这是来自验证集的图像。这也是正确的。

这是同一幅图像，但略有增强，但眼睛没有被跟踪。

我很感激任何关于我可以做些什么来改善我的结果的想法。
编辑：自发布以来，我已经设法通过增加 kernel_size 和利用每个时期的数据集生成器来改善结果。]]></description>
      <guid>https://stackoverflow.com/questions/79149930/eye-landmark-model-in-tensorflow-not-tracking-with-unseen-data</guid>
      <pubDate>Sat, 02 Nov 2024 03:49:47 GMT</pubDate>
    </item>
    <item>
      <title>使用没有跳跃连接的 U-Net 进行图像到图像处理。这是真的吗？</title>
      <link>https://stackoverflow.com/questions/79132335/image-to-image-with-u-net-with-no-skip-connections-is-it-real</link>
      <description><![CDATA[一般来说，需要 U-Net 来创建另一种风格的图像，但保留结构。例如，从草图中绘制完整的图画。对吗？
我想保留风格，但改变结构。例如，我想拍一张皱巴巴的布料的照片，然后拍下展开的布料。但我不想使用 GAN。为此，我决定从 U-Net 中删除 Skip 连接器以保留结构。而且，我像在 GAN 中一样将输入图像卷积到风格向量。对吗？
问题是，此代码训练成功，但前提是训练数据库中没有增强。一旦我向输入图像添加 +/- 5、10 和 15 度的角度增强（仅向输入添加，因为输出应该保持不变），那么我得到的不是结果，而是一些噪音。如果我开始在包含多个示例的数据集上进行训练，那么应用增强后的结果是正确的。但随着数据集中示例数量的增加，结果会变得更糟。
但无论如何，我的曲线（损失：MSE）是完美的）））我的意思是，即使我得到一些噪音（图像），我的曲线看起来也像我得到了一个完美的结果。只是下降的曲线。这是最让我恼火的。我不明白这是怎么可能的。即使我得到一些噪音（图像）曲线也在下降，就像一切都很好一样。大约 0.09/0.05/0.02/0.01/.... 我称之为过度拟合只是因为我不知道它是什么。我的意思是，当我没有得到正确的结果但你得到下降的损失曲线时，这被称为过度拟合。对吗？
关于我的模型的容量。当然，我考虑过这个问题，改变了层数、层中的过滤器和密集层中的神经元，但无济于事。所以我认为这里有一些概念问题。
我使用训练数据集中的一些示例作为验证，因为我想确保这个模型至少可以正确处理我的训练数据。但是，正如我之前所说，通过增强，我得到了一些噪音，损失（MSE）完美。无论我使用多少个时期 - 结果都是垃圾，曲线是完美的。学习率 = 0.00006 * K（K = 5,4,3,2,1）。输入/输出 - 图像（2562563）。亚当。
l2_reg = regularizers.l2(1e-6)
initializer = initializers.he_normal()

def build_unet(input_shape=(256, 256, 3)):
输入 = 图层。输入(shape=input_shape)

c = 图层。Conv2D(16, kernel_size=4, strides=2, padding=&quot;same&quot;)(输入)
c = 图层。LeakyReLU(negative_slope=0.2)(c) 

c = 图层。Conv2D(32, kernel_size=4, strides=2, padding=&quot;same&quot;)(c)
c = 图层。LeakyReLU(negative_slope=0.2)(c)

c = 图层。Conv2D(64, kernel_size=4, strides=2, padding=“相同”(c)
c = 层。LeakyReLU(负斜率=0.2)(c)

c = 层。Conv2D(128, kernel_size=4, strides=2, padding=“相同”(c)
c = 层。LeakyReLU(负斜率=0.2)(c)

c = 层。Conv2D(256, kernel_size=4, strides=2, padding=“相同”(c)
c = 层。LeakyReLU(负斜率=0.2)(c)

c = 层。Conv2D(512, kernel_size=4, strides=2, padding=“相同”(c)
c = 层。LeakyReLU(负斜率=0.2)(c)

# 瓶颈
b = InstanceNormalization()(c)

b = 图层。Reshape((-1,))(b)
b = 图层。Dense(1024, kernel_regularizer=l2_reg,)(b)
b = 图层。LeakyReLU(negative_slope=0.2)(b)

b = 图层。Dropout(0.2)(b)

b = 图层。Dense(1024*4*4, kernel_regularizer=l2_reg,)(b)
b = 图层。LeakyReLU(negative_slope=0.2)(b)
b = 图层。Reshape((4,4,1024))(b)

# 代码
d = 图层。Conv2DTranspose(512, kernel_size=4, strides=2, padding=&quot;same&quot;)(b)
d =层。LeakyReLU（负斜率=0.2）（d）

d = 层。Conv2DTranspose（256，kernel_size=4，strides=2，padding=“相同”）（d）

d = 层。LeakyReLU（负斜率=0.2）（d）

d = 层。Conv2DTranspose（128，kernel_size=4，strides=2，padding=“相同”）（d）

d = 层。LeakyReLU（负斜率=0.2）（d）

d = 层。Conv2DTranspose（64，kernel_size=4，strides=2，padding=“相同”）（d）

d = 层。LeakyReLU（负斜率=0.2）（d）

d = 层。Conv2DTranspose（32， kernel_size=4, strides=2, padding=&quot;same&quot;)(d)
d = layer.LeakyReLU(negative_slope=0.2)(d)

d = layer.Conv2DTranspose(16, kernel_size=4, strides=2, padding=&quot;same&quot;)(d)
d = layer.LeakyReLU(negative_slope=0.2)(d)

output = layer.Conv2D(3, kernel_size=3, padding=&quot;same&quot;, activated=&quot;tanh&quot;)(d)

model = models.Model(inputs=inputs, output=outputs, name=&quot;build_unet&quot;)
return model

unet = build_unet()

adam_optimizer = Adam(
learning_rate=0.00006*K,
)

unet.compile(optimizer=adam_optimizer, loss=&#39;mse&#39;, metrics= None)
]]></description>
      <guid>https://stackoverflow.com/questions/79132335/image-to-image-with-u-net-with-no-skip-connections-is-it-real</guid>
      <pubDate>Mon, 28 Oct 2024 07:00:00 GMT</pubDate>
    </item>
    <item>
      <title>在小型训练数据集上训练的文本转语音模型</title>
      <link>https://stackoverflow.com/questions/77406851/text-to-speech-model-that-trains-on-small-training-dataset</link>
      <description><![CDATA[我需要一个可以使用包含最多 20 个句子的成绩单和 wav 文件的数据集进行训练的模型。
我尝试在这样的数据集上训练 https://github.com/coqui-ai/TTS，但训练效果并不好。推断只是噪音而不是单词。
我正在研究https://github.com/microsoft/SpeechT5/tree/main/SpeechLM#pre-trained-and-fine-tuned-models，但他们使用的微调数据集似乎也有超过 100 小时的音频内容。
解决这个问题的最佳研究模型是什么？]]></description>
      <guid>https://stackoverflow.com/questions/77406851/text-to-speech-model-that-trains-on-small-training-dataset</guid>
      <pubDate>Thu, 02 Nov 2023 04:00:19 GMT</pubDate>
    </item>
    <item>
      <title>合并数据框时出现“KeyError”</title>
      <link>https://stackoverflow.com/questions/75846053/keyerror-when-merging-dataframes</link>
      <description><![CDATA[尝试对我玩的视频游戏进行机器学习，以预测即将到来的价格，从而了解它是否值得保留
import 请求
import pandas as pd

headers = {&quot;User-Agent&quot;: &quot;Hohman#4134 - ML project&quot;}
prices_url = &quot;https://prices.runescape.wiki/api/v1/osrs/latest&quot;

尝试：
prices_response = 请求。获取（prices_url，headers=headers）
prices_response.raise_for_status（）
prices_data = prices_response.json（）
prices_data_df = pd.DataFrame（prices_data）

除了requests.exceptions.HTTPError：
print（“错误：无法检索价格数据。请检查您的用户代理。”）
prices_data_df = pd.DataFrame（）

ids_url = “https://prices.runescape.wiki/api/v1/osrs/mapping”

尝试：
ids_response = 请求。获取（ids_url，headers=headers）
ids_response.raise_for_status()
ids_data = ids_response.json()
ids_dict = {}
对于 ids_data 中的项目：
ids_dict[item[&#39;id&#39;]] = item[&#39;name&#39;]

ids_data_df = pd.DataFrame.from_dict(ids_dict, orient=&#39;index&#39;, columns=[&#39;name&#39;])

除了请求。exceptions.HTTPError：
print(&quot;错误：无法检索 ID 数据。请检查您的用户代理。&quot;)
ids_data_df = pd.DataFrame()

merged_df = pd.merge(prices_data_df, ids_data_df, left_on=&#39;id&#39;, right_index=True)

item_name = input(&quot;输入商品名称：&quot;)
item_data = merged_df[merged_df[&#39;name&#39;].str.contains(item_name, case=False)]
latest_price = item_data[&#39;high&#39;].iloc[0]

print(f&quot;{item_name} 的预测价格为 {latest_price} GP。&quot;)

这是错误
 第 33 行，位于 &lt;module&gt;
merged_df = pd.merge(prices_data_df, ids_data_df, left_on=&#39;id&#39;, right_index=True)
第 110 行，在 merge 中
op = _MergeOperation(
第 703 行，在 
) = self._get_merge_keys()
第 1195 行，在 _get_merge_keys 中
left_keys.append(left._get_label_or_level_values(k))
第 1850 行，在 _get_label_or_level_values 中
raise KeyError(key)
KeyError: &#39;id&#39;**

我试过了，但得到了相同的结果，当时只是命名了 name。我不知道发生了什么。
merged_df = pd.merge(prices_data_df, ids_data_df, left_on=&#39;name&#39;, right_on=&#39;name&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/75846053/keyerror-when-merging-dataframes</guid>
      <pubDate>Sun, 26 Mar 2023 05:33:41 GMT</pubDate>
    </item>
    <item>
      <title>用于异常检测的孤立森林</title>
      <link>https://stackoverflow.com/questions/60209411/isolation-forest-for-anomaly-detection</link>
      <description><![CDATA[在此 示例 中，IsolationForest 用于异常检测：
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest

rng = np.random.RandomState(42)

# 生成训练数据
X = 0.3 * rng.randn(100, 2)
X_train = np.r_[X + 2, X - 2]
# 生成一些常规的新观察值
X = 0.3 * rng.randn(20, 2)
X_test = np.r_[X + 2, X - 2]
# 生成一些异常的新观察值
X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))

# 拟合模型
clf = IsolationForest(max_samples=100, random_state=rng)
clf.fit(X_train)
y_pred_train = clf.predict(X_train)
y_pred_test = clf.predict(X_test)
y_pred_outliers = clf.predict(X_outliers)

我相信此代码中的异常值是随机引入的。
但是，如果我使用真实数据进行异常检测，那么：

我该如何推进？

如果我已经有数据集，如何识别异常？
我正在尝试使用联合循环发电厂数据集。
或者，如果您有任何其他好的异常检测实践数据集，请提供一些链接！

]]></description>
      <guid>https://stackoverflow.com/questions/60209411/isolation-forest-for-anomaly-detection</guid>
      <pubDate>Thu, 13 Feb 2020 13:49:38 GMT</pubDate>
    </item>
    </channel>
</rss>