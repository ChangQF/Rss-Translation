<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 13 Jan 2025 15:19:15 GMT</lastBuildDate>
    <item>
      <title>如何使用 Python 为 UNO 纸牌游戏创建 AI 玩家？</title>
      <link>https://stackoverflow.com/questions/79352641/how-do-i-create-an-ai-player-for-uno-card-game-in-python</link>
      <description><![CDATA[我熟悉 Python 的基础知识，我想创建一个 UNO 纸牌游戏，让 AI 与用户竞争。我唯一的经验是使用 Python 中的 minimax 算法制作井字游戏机器人。
我读过 minimax 是不可行的，因为 UNO 有更大的移动范围。我读过一些关于蒙特卡洛树搜索、深度强化学习、神经网络等的文章。对于 1v1（AI 与玩家）的 UNO 游戏，哪种方法更容易实现？
我应该查看哪些库或其他算法来开始这个项目？
我读过的一点资料建议在纸牌游戏中使用蒙特卡洛算法。我想知道这里的情况是否如此，这是否确实是最佳方法。]]></description>
      <guid>https://stackoverflow.com/questions/79352641/how-do-i-create-an-ai-player-for-uno-card-game-in-python</guid>
      <pubDate>Mon, 13 Jan 2025 15:15:46 GMT</pubDate>
    </item>
    <item>
      <title>尽管将 .mlmodel 添加到 Build Phases，但为什么 Xcode 中的自动链接不起作用？（找不到范围）</title>
      <link>https://stackoverflow.com/questions/79352561/why-is-auto-linking-of-mlmodel-not-working-in-xcode-despite-adding-it-to-build</link>
      <description><![CDATA[我正在开发一个使用 .mlmodel 文件的 Xcode 项目。我通过 Build Phases &gt; 添加了该文件复制资源，但自动链接似乎不起作用。
我到目前为止尝试过的：

确保 .mlmodel 文件已添加到目标成员资格下。
验证文件是否存在并可从其原始位置访问。
清理构建文件夹（Cmd + Shift + K）并删除 DerivedData 文件夹。
验证构建设置中的 CoreML 模型编译设置已启用。


任何帮助都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/79352561/why-is-auto-linking-of-mlmodel-not-working-in-xcode-despite-adding-it-to-build</guid>
      <pubDate>Mon, 13 Jan 2025 14:50:23 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：'RasterIOSource'对象没有属性'urlpath'[关闭]</title>
      <link>https://stackoverflow.com/questions/79352075/attributeerror-rasteriosource-object-has-no-attribute-urlpath</link>
      <description><![CDATA[我正在运行一个使用detectron2和zenodo库检测树冠的代码。
print(cat_tc[&#39;sepilok_rgb&#39;]) # 打印目录条目详细信息
print(&quot;URL Path:&quot;, cat_tc[&#39;sepilok_rgb&#39;].urlpath) # 打印urlpath

# 使用rioxarray直接从urlpath打开数据集
tc_rgb = rioxarray.open_rasterio(cat_tc[&#39;sepilok_rgb&#39;].urlpath)

print(&#39;dims =&#39;, tc_rgb.dims, &#39;, number of bands =&#39;, len(tc_rgb.data_vars), &#39;, crs =&#39;, tc_rgb.rio.crs)

我想打印url路径，但我收到属性错误]]></description>
      <guid>https://stackoverflow.com/questions/79352075/attributeerror-rasteriosource-object-has-no-attribute-urlpath</guid>
      <pubDate>Mon, 13 Jan 2025 11:46:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 FLOPS 和 FLOP 计算 GPU 执行时间</title>
      <link>https://stackoverflow.com/questions/79351271/calculate-gpu-excution-time-with-flops-and-flops</link>
      <description><![CDATA[我正在对深度学习模型进行性能分析，并想验证以下计算执行时间的公式：
公式：时间（秒）= 模型 FLOP/GPU FLOP 每秒
上下文：
我有一个总共 24,029,362,176 FLOP 的模型。
我正在两个不同的 GPU 上对其进行测试：

NVIDIA A100 (80 GB)，峰值性能为 312 TFLOP（FP32）。
NVIDIA Tesla T4（Colab GPU），峰值性能为 8.1 TFLOP（FP32）。

使用该公式，我计算了这些 GPU 的执行时间。但是，我想确认一下这个公式是否适用于估算比较 2 个 GPU 的执行时间。
这个公式对于估算执行时间模型是否准确？
]]></description>
      <guid>https://stackoverflow.com/questions/79351271/calculate-gpu-excution-time-with-flops-and-flops</guid>
      <pubDate>Mon, 13 Jan 2025 05:53:50 GMT</pubDate>
    </item>
    <item>
      <title>使用矩阵在 PyTorch 上计算公式</title>
      <link>https://stackoverflow.com/questions/79350403/calculate-formulas-on-pytorch-using-matrix</link>
      <description><![CDATA[我有方程式：
$e_{ij} = \frac{X_i W^Q (X_j W^K + A^K_{ij}) }{\sqrt{D_z}}$
$\alpha_{ij} = softmax(e_{ij})$
$z_{i} = \sum_j \alpha_{ij} (X_j W^V + A^V_{ij})$

其中大小：
X：[B，S，H，D]
每个 W：[H，D，D]
每个 A：[S，S，H，D]

我如何通过矩阵运算计算它？
我有一个部分解决方案
import torch
import torch.nn. functional as F

B, S, H, D = X.shape
d_z = D # 为简单起见，假设 d_z 等于 D

W_Q = torch.randn(H, D, D)
W_K = torch.randn(H, D, D)
W_V = torch.randn(H, D, D)

a_K = torch.randn(S, S, H, D)
a_V = torch.randn(S, S, H, D)
}
XW_Q = torch.einsum(&#39;bshd,hde-&gt;bshe&#39;, X, W_Q) # [B, S, H, D] @ [H, D, D] -&gt; [B，S，H，D]
XW_K = torch.einsum(&#39;bshd,hde-&gt;bshe&#39;, X, W_K) # [B，S，H，D] @ [H，D，D] -&gt; [B，S，H，D]

e_ij_numerator = XW_Q.unsqueeze(2) @ (XW_K.unsqueeze(1) + a_K).transpose(-1, -2) # [B，S，1，H，D] @ [B，1，S，H，D] -&gt; [B，S，S，H，D]
e_ij = e_ij_numerator / torch.sqrt(torch.tensor(d_z, dtype=torch.float32)) # [B，S，S，H，D]

XW_V = torch.einsum(&#39;bshd,hde-&gt;bshe&#39;, X, W_V) # [B，S，H，D] @ [H，D，D] -&gt; [B，S，H，D]
alpha = F.softmax(e_ij, dim=2) # [B，S，S，H，D]

z_i = torch.einsum(&#39;bshij,bshjd-&gt;bshid&#39;, alpha, XW_V.unsqueeze(1) + a_V) # [B，S，S，H，D] @ [B，1，S，H，D] -&gt; [B, S, S, H, D]

但 z 应该是 [B, S, H,D]]]></description>
      <guid>https://stackoverflow.com/questions/79350403/calculate-formulas-on-pytorch-using-matrix</guid>
      <pubDate>Sun, 12 Jan 2025 17:48:23 GMT</pubDate>
    </item>
    <item>
      <title>如何实现巴特沃斯滤波器</title>
      <link>https://stackoverflow.com/questions/74003337/how-to-implement-a-butterworth-filter</link>
      <description><![CDATA[我正在尝试使用 python 实现 butterworthfilter
数据来自 CSV 文件，名为 Samples.csv，如下所示
998,4778415
1009,209592
1006,619094
1001,785406
993,9426543
990,1408991
992,736118
995,8127334
...

该列调用欧几里得范数。数据范围从 0 到 1679.286158，共有 1838 行。
这是我使用的代码：
from scipy.signal import filtfilt
from scipy import stats

import csv
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import scipy
def plot():
data=pd.read_csv(&#39;Samples.csv&#39;,sep=&quot;;&quot;, decimal=&quot;,&quot;)
sensor_data=data[[&#39;Euclidian Norm&#39;]]
sensor_data=np.array(sensor_data)

time=np.linspace(0,1679.286158,1838)
plt.plot(time,sensor_data)
plt.show()

filtered_signal=bandPassFilter(sensor_data)
plt.plot(time,sensor_data)
plt.show()

def bandPassFilter(signal):
fs = 4000.0
lowcut=20.0
highcut=50.0

nyq=0.5*fs
low=lowcut/nyq
high=highcut/nyq

order =2

b,a=scipy.signal.butter(order,[low,high],&#39;bandpass&#39;,analog=False)

y=scipy.signal.filtfilt(b,a,signal,axis=0)

return(y)

plot()


我的问题是我的数据没有任何变化。它没有过滤我的数据。过滤数据的图表与源数据相同。有人知道哪里出了问题吗？
第一个图表是源数据，第二个图表是过滤后的图表，在我看来，它们看起来像是同一张图表。
]]></description>
      <guid>https://stackoverflow.com/questions/74003337/how-to-implement-a-butterworth-filter</guid>
      <pubDate>Sun, 09 Oct 2022 08:49:34 GMT</pubDate>
    </item>
    <item>
      <title>验证准确率非常低但训练准确率很高</title>
      <link>https://stackoverflow.com/questions/73410090/very-low-validation-accuracy-but-high-training-accuracy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/73410090/very-low-validation-accuracy-but-high-training-accuracy</guid>
      <pubDate>Thu, 18 Aug 2022 22:32:25 GMT</pubDate>
    </item>
    <item>
      <title>Azure 数据集 .to_pandas_dataframe() 错误</title>
      <link>https://stackoverflow.com/questions/71939604/azure-dataset-to-pandas-dataframe-error</link>
      <description><![CDATA[我正在 udemy 上学习 azure ml 课程，但无法解决以下错误：
Dataset(id=&#39;id&#39;, name=&#39;Loan Applications Using SDK&#39;, version=1, error_code=None, exception_type=PandasImportError) 的操作“to_pandas_dataframe”执行失败
以下是提交脚本的代码：
from azureml.core import Workspace, Experiment, ScriptRunConfig, 
Environment

ws = Workspace.from_config(path=&quot;./config&quot;)

new_experiment = Experiment(workspace=ws,
name=&quot;Loan_Script&quot;)

script_config = ScriptRunConfig(source_directory=&quot;.&quot;,
script=&quot;180 - Script to Run.py”）

script_config.framework = “python”
script_config.environment = Environment(&quot;conda_env&quot;)

new_run = new_experiment.submit(config=script_config)

这是正在运行的脚本：
from azureml.core import Workspace, Datastore, Dataset, 
Experiment

from azureml.core import Run

ws = Workspace.from_config(path=&quot;./config&quot;)
az_store = Datastore.get(ws, &quot;bencouser_sdk_blob01&quot;)
az_dataset = Dataset.get_by_name(ws, name=&#39;Loan Applications Using SDK&#39;)
az_default_store = ws.get_default_datastore()

#%%----------------------------------------------------
# 获取运行的上下文
#------------------------------------------------------

new_run = Run.get_context()

#%%----------------------------------------------------
# 将记录的内容
#------------------------------------------------------

df = az_dataset.to_pandas_dataframe()

total_observations = len(df)

nulldf = df.isnull().sum()

#%%----------------------------------------------------
# 完成实验
#---------------------------------------------------

new_run.log(&quot;Total Observations:&quot;, total_observations)

for columns in df.columns:
new_run.log(columns, nulldf[columns])

new_run.complete()

我在实验之外运行了 .to_pandas_dataframe() 部分，并且没有出现错误。我还尝试了以下操作（驱动程序日志中推荐的操作）：
InnerException 无法导入 pandas。通过运行以下命令确保安装了兼容版本：pip install azureml-dataprep[pandas]
我之前见过有人遇到过这种情况，但我找不到解决方案，任何帮助都值得感激。]]></description>
      <guid>https://stackoverflow.com/questions/71939604/azure-dataset-to-pandas-dataframe-error</guid>
      <pubDate>Wed, 20 Apr 2022 12:24:54 GMT</pubDate>
    </item>
    <item>
      <title>使用支持向量回归进行预测</title>
      <link>https://stackoverflow.com/questions/51350585/predictions-using-support-vector-regression</link>
      <description><![CDATA[我的问题中有四个特征 (X)；a、b、c、d 和两个从属项 (Y)；e、f。我手头有一个数据集，其中包含所有这些变量的一组值。当给出新的 a,b,c,d 值时，如何使用 scikit-learn 通过支持向量回归预测 e,f 变量的值？
我发现很难遵循 scikit-learn 文档中的 SVR。
这是我在 sklearn 文档中的示例的帮助下到目前为止所做的。
train = pd.read_csv(&#39;/Desktop/test.csv&#39;)
X = train.iloc[:, 4]
y = train.iloc[:, 4:5]

svr_rbf = SVR(kernel=&#39;rbf&#39;, C=1e3, gamma=0.1)
y_rbf = svr_rbf.fit(X, y).predict(X)
lw = 2
plt.scatter(X, y, color=&#39;darkorange&#39;, label=&#39;data&#39;)
plt.plot(X, y_rbf, color=&#39;navy&#39;, lw=lw, label=&#39;RBF model&#39;)
plt.xlabel(&#39;data&#39;)
plt.ylabel(&#39;target&#39;)
plt.title(&#39;支持向量回归&#39;)
plt.legend()
plt.show()

这会出现错误，
ValueError: 预期为 2D 数组，但得到的却是 1D 数组：
:
如果您的数据只有一个特征，则使用 array.reshape(-1, 1) 重塑数据，如果数据包含单个样本，则使用 array.reshape(1, -1)。
 ]]></description>
      <guid>https://stackoverflow.com/questions/51350585/predictions-using-support-vector-regression</guid>
      <pubDate>Sun, 15 Jul 2018 17:31:02 GMT</pubDate>
    </item>
    <item>
      <title>在 sklearn 中预测训练数据</title>
      <link>https://stackoverflow.com/questions/43210970/predict-training-data-in-sklearn</link>
      <description><![CDATA[我这样使用 scikit-learn 的 SVM：
clf = svm.SVC()
clf.fit(td_X, td_y) 

当我使用分类器预测训练集成员的类别时，即使在 scikit-learn 实现中，分类器也会出错吗（例如 clf.predict(td_X[a])==td_Y[a]）？]]></description>
      <guid>https://stackoverflow.com/questions/43210970/predict-training-data-in-sklearn</guid>
      <pubDate>Tue, 04 Apr 2017 15:04:36 GMT</pubDate>
    </item>
    <item>
      <title>weka 对旋转森林方法中的分类属性做了什么？</title>
      <link>https://stackoverflow.com/questions/29838606/what-does-weka-do-for-categorical-attributes-in-rotation-forest-method</link>
      <description><![CDATA[我有一个包含数值和分类属性的数据集。我正在 Weka 中通过旋转森林进行分类。我知道旋转森林只适用于数值属性，因为它计算 PCA 和其他东西。
我的期望是 Weka 忽略分类属性，但当我使用整个数据集进行分类时和从数据集中删除分类属性时，性能结果不同。
Weka 在旋转森林方法中对分类属性做了什么？]]></description>
      <guid>https://stackoverflow.com/questions/29838606/what-does-weka-do-for-categorical-attributes-in-rotation-forest-method</guid>
      <pubDate>Fri, 24 Apr 2015 04:16:31 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类 weka</title>
      <link>https://stackoverflow.com/questions/18854599/randomforest-classification-weka</link>
      <description><![CDATA[csv 文件中的属性被保存在 11 列中。如果列的顺序发生变化，Randomforest 和 RandomTree 每次给出的准确率是否不同？]]></description>
      <guid>https://stackoverflow.com/questions/18854599/randomforest-classification-weka</guid>
      <pubDate>Tue, 17 Sep 2013 16:03:37 GMT</pubDate>
    </item>
    <item>
      <title>分类器 weka 的组合</title>
      <link>https://stackoverflow.com/questions/18854042/combination-of-classifiers-weka</link>
      <description><![CDATA[我已基于每个阶段的 107 个实例、11 个特征和 2 个类别构建了三个分类器。Weka 用作机器学习工具。

第一个分类器预测类别 0 和类别 1-2-3。（所有 107 个实例均用于交叉验证方法中的训练和测试）
第二个分类器预测类别 1 和类别 2-3。（移除类别 0 的实例以进行训练和测试）
第三个分类器预测类别 2 和类别 3。（移除类别 1 的实例以进行训练和测试）

每个分类器均应用了 Randoforest。有人知道我该如何组合这三个分类器吗？]]></description>
      <guid>https://stackoverflow.com/questions/18854042/combination-of-classifiers-weka</guid>
      <pubDate>Tue, 17 Sep 2013 15:34:25 GMT</pubDate>
    </item>
    <item>
      <title>如何在weka中表示文本以进行分类？</title>
      <link>https://stackoverflow.com/questions/8313426/how-to-represent-text-for-classification-in-weka</link>
      <description><![CDATA[如何在 weka 中表示文本分类的属性或类别？使用什么属性可以进行分类，词频还是仅单词？ARFF 格式的可能结构是什么？您能给我几行该结构的示例吗？]]></description>
      <guid>https://stackoverflow.com/questions/8313426/how-to-represent-text-for-classification-in-weka</guid>
      <pubDate>Tue, 29 Nov 2011 15:32:02 GMT</pubDate>
    </item>
    <item>
      <title>weka java api stringtovector 异常</title>
      <link>https://stackoverflow.com/questions/6644191/weka-java-api-stringtovector-exception</link>
      <description><![CDATA[所以我有这个使用 Weka 的 Java API 的代码：
 String html = &quot;blaaah&quot;;
Attribute input = new Attribute(&quot;html&quot;,(FastVector) null);

FastVector inputVec = new FastVector();
inputVec.addElement(input);

Instances htmlInst = new Instances(&quot;html&quot;,inputVec,1);
htmlInst.add(new Instance(1)); 
htmlInst.instance(0).setValue(0, html);

System.out.println(htmlInst);

StringToWordVector filter = new StringToWordVector();
filter.setInputFormat(htmlInst);
Instances dataFiltered = Filter.useFilter(htmlInst, filter);

但是在 filter.setInputFormat(htmlInst) 行上，Java 抱怨该函数抛出了未处理的异常...
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/6644191/weka-java-api-stringtovector-exception</guid>
      <pubDate>Sun, 10 Jul 2011 22:35:28 GMT</pubDate>
    </item>
    </channel>
</rss>