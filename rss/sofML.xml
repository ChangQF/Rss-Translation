<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 06 Apr 2024 06:16:40 GMT</lastBuildDate>
    <item>
      <title>在一组用户数据上训练 ML 模型</title>
      <link>https://stackoverflow.com/questions/78283322/train-an-ml-model-on-group-of-user-data</link>
      <description><![CDATA[我需要建立用户支付交易的欺诈检测。
与之前用户的交易历史记录相比，我需要在用户交易中定义一些独特的模式。
我需要在每个用户数据集上训练模型吗？
在这种情况下，我最终会得到大量模型。
请提出正确的方法。
我觉得这是一种推荐系统，其中用户是根据用户之前的历史推荐的。但我不知道他们是如何实现这一目标的。
请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/78283322/train-an-ml-model-on-group-of-user-data</guid>
      <pubDate>Sat, 06 Apr 2024 05:22:34 GMT</pubDate>
    </item>
    <item>
      <title>使用我尝试从头开始构建的神经网络时出现问题</title>
      <link>https://stackoverflow.com/questions/78283274/problem-with-using-a-neural-network-i-tried-to-build-from-scratch</link>
      <description><![CDATA[代码：
&lt;前&gt;&lt;代码&gt;
随机导入
导入数学
将 numpy 导入为 np
类值：
  
  def __init__(self, data, _children=(), _op=&#39;&#39;, label=&#39;&#39;):
    self.data = 数据
    自我毕业= 0.0
    self._backward = lambda: 无
    self._prev = 设置(_children)
    self._op = _op
    self.label = 标签

  def __repr__(自我):
    return f“值(data={self.data})”
  
  def __add__(自己，其他)：
    other = other if isinstance(other, Value) else Value(other)
    out = Value(self.data + other.data, (self, other), &#39;+&#39;)
    
    def _backward():
      自我.grad += 1.0 * 输出.grad
      其他.grad += 1.0 * out.grad
    输出._backward = _backward
    
    返回

  def __mul__(自己，其他)：
    other = other if isinstance(other, Value) else Value(other)
    out = Value(self.data * other.data, (self, other), &#39;*&#39;)
    
    def _backward():
      self.grad += other.data * out.grad
      other.grad += self.data * out.grad
    输出._backward = _backward
      
    返回
  
  def __pow__(自己，其他)：
    assert isinstance(other, (int, float)), “目前仅支持 int/float 幂”
    out = Value(self.data**other, (self,), f&#39;**{other}&#39;)

    def _backward():
        self.grad += 其他 * (self.data ** (其他 - 1)) * out.grad
    输出._backward = _backward

    返回
  
  def __rmul__(self, other): # 其他 * self
    返回自己*其他

  def __truediv__(self, other): # 自己 / 其他
    返回自己 * 其他**-1

  def __neg__(self): # -self
    返回自身 * -1

  def __sub__(self, other): # self - other
    返回自我+（-其他）

  def __radd__(self, other): # 其他 + self
    返回自己+他人

  def tanh(自身):
    x = 自身数据
    t = np.tanh(x)
    输出 = 值(t, (self, ), &#39;tanh&#39;)

    def _backward():
        self.grad += (1 - t**2) * out.grad
    输出._backward = _backward

    返回

  def exp(自身):
    x = 自身数据
    out = Value(math.exp(x), (self, ), &#39;exp&#39;)
    
    def _backward():
      self.grad += out.data * out.grad # 注意：在视频中我错误地使用了 = 而不是 +=。固定在这里。
    输出._backward = _backward
    
    返回
  
  
  def向后（自身）：
    
    拓扑 = []
    访问过=设置（）
    def build_topo(v):
      如果 v 不在访问中：
        访问过.add(v)
        对于 v._prev 中的孩子：
          构建拓扑（子）
        拓扑.append(v)
    构建拓扑（自身）
    
    自我毕业= 1.0
    对于反向节点（topo）：
      节点._backward()



神经元类：
  
  def __init__(self, nin):
    self.w = [值(random.uniform(-1,1)) for _ in range(nin)]
    self.b = Value(随机.uniform(-1,1))
  
  def __call__(自身，x)：
    # w * x + b
    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)
    输出 = act.tanh()
    返回
  
  def 参数（自身）：
    返回 self.w + [self.b]

类层：
  
  def __init__(self, nin, noout):
    self.neurons = [神经元(nin) for _ in range(nout)]
  
  def __call__(自身，x)：
    outs = [n(x) for n in self.neurons]
    返回 outs[0] 如果 len(outs) == 1 否则 outs
  
  def 参数（自身）：
    return [p 代表 self.neurons 中的神经元，代表神经元中的 p.parameters()]

MLP 类：
  
    def __init__(self, nin, nouts):
        sz = [nin] + nouts
        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]
  
    def __call__(自身，x)：
        对于 self.layers 中的图层：
            x = 层(x)
        返回x
  
    def 参数（自身）：
        return [p for self.layers 中的层 for p in layer.parameters()]

现在用这个东西来预测东西：
随机导入

# 初始化神经网络
n = MLP(nin=2, nouts=[4, 1])

学习率 = 0.1

# 训练循环
对于范围 (200) 内的 k：
    # 生成随机输入数据点
    xs = [[random.uniform(0, 1001), random.uniform(0, 1)] for _ in range(100)]
    ys = [Value(5 + 3*x[0] + x[1]) for x in xs] # 使用 Value 类来表示真实输出
    
    # 前向传递
    ypred = [n(x) for x in xs]
    loss = sum((ygt - yout)**2 for ygt, yout in zip(ys, ypred)) / len(xs) # 计算均方误差
    
    # 向后传递
    对于 n.parameters() 中的 p：
        p.grad = 0.0
    loss.backward()
    
    # 更新权重和偏差
    对于 n.parameters() 中的 p：
        p.data += -learning_rate * p.grad
    
    print(k, 损失.数据)

我试图从函数 y=5+3x+i 预测 y 的值，x 的范围从 0 到 1001，i 的范围从 0 到 1，尝试仅使用 x 来预测，但没有成功，它无法仅使用 x 来完成此操作，给出了无法迭代它的错误。
ypred 搞砸了，它的所有值都是 1.0，我是在做一些非常愚蠢的事情还是因为这件事似乎不起作用，我尝试了 chatgpt，它失败了。
我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78283274/problem-with-using-a-neural-network-i-tried-to-build-from-scratch</guid>
      <pubDate>Sat, 06 Apr 2024 04:49:13 GMT</pubDate>
    </item>
    <item>
      <title>相似性搜索和文本分类</title>
      <link>https://stackoverflow.com/questions/78283251/similarity-search-and-text-classification</link>
      <description><![CDATA[我有一个任务，我想根据收到的文本使用两种不同的机器学习模型？ （计划使用语音到文本的转换）。如果接收到的文本与有关急救箱的数据集匹配，那么我们将使用急救箱模型，如果它与疾病数据集更匹配，我们将使用疾病数据集，另外在分类之后，“症状”将被使用。或输入标签必须从文本中提取。我应该如何进行？
我有几个问题，例如我应该创建整个数据库的矢量数据库吗？或者只是输入标签？我应该首先识别然后用于计算向量距离的实体吗？或者我应该匹配整个句子？
急救数据库是一个输入标签，其中包括割伤、烧伤等紧急情况，而疾病数据库只是用于分类的正常数据集。急救箱数据集包含关于如何处理每次伤害的说明，我应该使用决策模型并打印决策还是构建语言模型？对于疾病数据集，我有一个额外的数据集，其中包含有关如何“治疗”疾病的信息。这些疾病，我计划将最终的疾病决策与该数据集相匹配，在这里，是使用语言模型更好还是只打印出决策更好？请指导我。
我还没有尝试过任何东西，因为最初我计划使用较小的 llms 并简化问题，但是我被告知要使其易于运行，但我不能牺牲性能，我仍然希望它输出可行的语言。]]></description>
      <guid>https://stackoverflow.com/questions/78283251/similarity-search-and-text-classification</guid>
      <pubDate>Sat, 06 Apr 2024 04:34:00 GMT</pubDate>
    </item>
    <item>
      <title>微调t5变压器产生重复输出</title>
      <link>https://stackoverflow.com/questions/78283102/fine-tuned-t5-transformer-generates-repetitive-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78283102/fine-tuned-t5-transformer-generates-repetitive-output</guid>
      <pubDate>Sat, 06 Apr 2024 03:13:49 GMT</pubDate>
    </item>
    <item>
      <title>编写成本/损失函数[关闭]</title>
      <link>https://stackoverflow.com/questions/78282847/writing-the-cost-lost-function</link>
      <description><![CDATA[我有以下训练数据集代码：
# 数组格式的数据
train_data = [[3370,4.5,1],[2949,5.4,1],[4020,5.5,1],[4337,4.7,1],[2519,3.6,1],[4461,5.4,1] ,[2755,5.1,1],[3317,3.2,1],[2672,4.3,1],[2854,4.7,1],
 [3663,2.6,1],[3497,3.2,1],[4603,8.2,1],[2780,3.4,1],[5074,2.5,1],[3354,4.9,1],[4732 ,2.7,1],[5506,3.3,1],[4091,5.6,1],[2890,3.4,1],
  [5873,3.2,0],[5400,3.3,0],[5707,2.2,0],[6408,1.5,0],[8019,1.9,0],[7319,1.9,0],[6212 ,3.6,0],[5918,2.7,0],[8621,3.4,0],[8967,1.7,0],
   [4976,2.1,0],[5477,3.6,0],[5302,5.6,0],[7450,4.0,0],[8580,2.3,0],[7496,3.8,0],[6444 ,3.5,0],[5087,2.7,0],[5791,2.7,0],[4812,2.4,0]]
# pytorch 张量格式的数据
train_X, train_y = torch.tensor(train_data)[:,:2], torch.tensor(train_data)[:,2:3]

绘图数据（train_X，train_y）

现在我不知道如何用这个函数编写成本/损失函数
def J(X, y, w, b):

任何人都可以帮我使用 pytorch 编写代码吗？非常感谢
我可以得到代码]]></description>
      <guid>https://stackoverflow.com/questions/78282847/writing-the-cost-lost-function</guid>
      <pubDate>Sat, 06 Apr 2024 00:37:40 GMT</pubDate>
    </item>
    <item>
      <title>验证的准确性比测试更高</title>
      <link>https://stackoverflow.com/questions/78282544/higher-accuracy-in-validation-that-test</link>
      <description><![CDATA[我使用 80/10/10 分割规则训练了一个模型。我的验证准确度约为 80%（皮尔逊相关），我的测试数据集的准确度约为 83%。这样可以吗？
我尝试了不同的正则化技术来从验证数据集中获得最佳结果，但是，我也不期望在测试数据集中获得更高的准确性]]></description>
      <guid>https://stackoverflow.com/questions/78282544/higher-accuracy-in-validation-that-test</guid>
      <pubDate>Fri, 05 Apr 2024 22:12:48 GMT</pubDate>
    </item>
    <item>
      <title>如何提高基于 Keras 的 CNN 眼底图像分类的训练和测试准确性？</title>
      <link>https://stackoverflow.com/questions/78281500/how-can-i-improve-my-keras-based-cnns-training-and-testing-accuracy-for-fundus</link>
      <description><![CDATA[``我一直致力于使用包含 400 张图像的眼底图像集（来自 MESSIDOR）创建糖尿病视网膜病变分类模型，分级范围为 0-3（4 个类别）。我尝试过使用增强、dropout 和正则化器来更改模型架构、复杂性、输出特征，但我的模型训练和验证准确度似乎无法超过 50%。
这是我的代码：&#39;`
#将数据拆分为训练集和验证集X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)
#定义模型结构
&lt;前&gt;&lt;代码&gt;模型 = 顺序()

#转换层
model.add(Conv2D(64, kernel_size=(3, 3), activate=&#39;relu&#39;, input_shape=(250, 250, 3), kernel_regularizer=regularizers.l2(0.0001)))#输出滤波器为 32)
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, (3, 3), 激活=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.001)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(256, (3, 3), 激活=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.001)))
model.add(MaxPooling2D(pool_size=(2, 2)))
模型.add(压平())
#密集层
model.add（密集（64，激活=&#39;relu&#39;））
模型.add(Dropout(0.45))
model.add（密集（4，激活=&#39;softmax&#39;））

`**# 编译模型
**`opt = keras.optimizers.Adam(learning_rate=0.00001)
model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=opt, 指标=[&#39;accuracy&#39;])

打印（模型.摘要（））

`***# 数据增强
**`数据生成=图像数据生成器（
    旋转范围=30，
    宽度偏移范围=0.2，
    height_shift_range=0.2，
    水平翻转=真，
    fill_mode=&#39;最近&#39;
）

历史= model.fit（datagen.flow（X_train，y_train，batch_size = 2），epochs = 30，validation_data
（X_测试，y_测试），随机播放=真）

model.evaluate(X_test, y_test)



所附图像的准确性和丢失结果[在此处输入图像描述](https://i.stack.imgur.com/dgbal.png&lt; /a&gt;)]]></description>
      <guid>https://stackoverflow.com/questions/78281500/how-can-i-improve-my-keras-based-cnns-training-and-testing-accuracy-for-fundus</guid>
      <pubDate>Fri, 05 Apr 2024 17:25:53 GMT</pubDate>
    </item>
    <item>
      <title>如何解释神经网络中的分布式表示（隐藏神经元的输出）？</title>
      <link>https://stackoverflow.com/questions/78281488/how-to-interpret-distributed-representationsoutputs-of-the-hidden-neurons-in-a</link>
      <description><![CDATA[训练具有 1 个隐藏层（由 2 个神经元组成）的 FNN：
模型 = train1([2])
绘制每个隐藏神经元的拟合以及输出：
plot1(X1, y1, label=&quot;train&quot;)
图1（X1测试，y1测试，标签=“测试”）
plot1fit(torch.linspace(0, 13, 500).unsqueeze(1), 模型, 隐藏=True, 比例=False)

输出如下：

当使用 3 个隐藏神经元进行训练时：

如何解释图表和每个隐藏神经元的输出的拟合情况？将上述视为分布式表示/嵌入，它真的很直观吗？]]></description>
      <guid>https://stackoverflow.com/questions/78281488/how-to-interpret-distributed-representationsoutputs-of-the-hidden-neurons-in-a</guid>
      <pubDate>Fri, 05 Apr 2024 17:23:10 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 TF-IDF 功能和微调嵌入模型复制 PECOS XR-Linear 性能</title>
      <link>https://stackoverflow.com/questions/78278617/cannot-replicate-pecos-xr-linear-performance-with-tf-idf-features-and-a-fine-tun</link>
      <description><![CDATA[我正在尝试使用 TFIDF 和 BGE 模型中的预训练嵌入来复制 XR-Linear。
parsed_result = Preprocessor.load_data_from_file(input_text_path, output_text_path)
Y = parsed_result[“label_matrix”]
语料库 = parsed_result[“语料库”]

预处理器 = Preprocessor.train(corpus, {&quot;type&quot;: &quot;tfidf&quot;})
tfidf_X = 预处理器.预测(语料库)

从句子转换器导入句子转换器
模型 = SentenceTransformer(&#39;BAAI/bge-small-en-v1.5&#39;)
嵌入= model.encode（data.query_string.values，show_progress_bar = True，batch_size = 2048）
打印（嵌入.形状）

我将 TFIDF 特征与 BGE 嵌入水平连接起来，如下所示：
X = scipy.sparse.csr_matrix(scipy.sparse.hstack((tfidf_X,embeddings)))

模型训练：
label_feat = LabelEmbeddingFactory.create(Y, X, method=“pifa”)
cluster_chain = Indexer.gen(label_feat, nr_splits=4)
xlinear_model = XLinearModel.train(X, Y, C=cluster_chain,negative_sampling_scheme=“tfn”)

预测：
def process_query_and_predict（查询，use_cpu_threads）：
    tfidf_vector = 预处理器.predict(查询)
    bge_embedding = model.encode(查询)
    pred_X = scipy.sparse.csr_matrix(scipy.sparse.hstack((tfidf_vector,bge_embedding)))
    Y_pred = xlinear_model.predict(pred_X)
    返回 smat_util.sorted_csr(Y_pred)

但是，令人惊讶的是，与在独立 TF-IDF 向量上训练的模型相比，模型的表现相当差。我看到了 PECOS XR-Linear。我试图复制所执行的过程。我想通过 BGE 模型引入语义功能，而不是 AttnXML。

我哪里出错了？如何将 tf-idf 特征与 BGE 嵌入合并。]]></description>
      <guid>https://stackoverflow.com/questions/78278617/cannot-replicate-pecos-xr-linear-performance-with-tf-idf-features-and-a-fine-tun</guid>
      <pubDate>Fri, 05 Apr 2024 08:22:32 GMT</pubDate>
    </item>
    <item>
      <title>如何找到不同公司竞争对手产品矩阵与特定品牌数据集的相关性？有机器学习来预测适合度吗？</title>
      <link>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</link>
      <description><![CDATA[我试图找到一个数据集（矩阵）的相关性，该数据集（矩阵）包含行上的客户和他们按列拥有的竞争对手产品（拥有=&#39;是&#39;，不拥有=&#39;否&#39;）和另一个客户数据集拥有我们的品牌（拥有=1，不拥有=0）。请记住，我们品牌数据集中的所有零值都是潜在客户。
我尝试了随机森林，但我们对拥有我们品牌的客户的所有价值观都是积极的，我如何根据所有积极的价值观来预测适合度？]]></description>
      <guid>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</guid>
      <pubDate>Fri, 05 Apr 2024 00:53:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 MAPIE 进行保形预测，当 alpha 很大时，我得到空的预测集</title>
      <link>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</guid>
      <pubDate>Thu, 28 Mar 2024 20:28:12 GMT</pubDate>
    </item>
    <item>
      <title>如何为自定义变压器创建 pandas 输出？</title>
      <link>https://stackoverflow.com/questions/75026592/how-to-create-pandas-output-for-custom-transformers</link>
      <description><![CDATA[scikit-learn 1.2.0 中有很多变化，它支持所有变压器的 pandas 输出，但如何在自定义变压器中使用它？
在[1]中：这是我的自定义转换器，它是一个标准缩放器：
从 sklearn.base 导入 BaseEstimator、TransformerMixin
将 numpy 导入为 np

类 StandardScalerCustom（BaseEstimator，TransformerMixin）：
    def fit(self, X, y=None):
        self.mean = np.mean(X, 轴=0)
        self.std = np.std(X, 轴=0)
        返回自我

    def 变换（自身，X）：
        返回 (X - self.mean) / self.std

在 [2] 中：创建了特定的规模管道
scale_pipe = make_pipeline(StandardScalerCustom())

在[3]中：添加到完整的管道中，它可能与缩放器、输入器、编码器等混合。
full_pipeline = ColumnTransformer([
    (“imputer”, impute_pipe, [&#39;column_1&#39;])
    （“缩放器”，scale_pipe，[&#39;column_2&#39;]）
]）

# 来自文档
full_pipeline.set_output(transform=&quot;pandas&quot;)

出现此错误：
ValueError：无法配置 StandardScalerCustom() 的输出，因为 set_output 不可用。
&lt;小时/&gt;
有一个解决方案，它可以是：
set_config(transform_output=&quot;pandas&quot;) 
但是在具体情况的基础上，如何在 StandardScalerCustom() 类中创建一个可以修复上述错误的函数？]]></description>
      <guid>https://stackoverflow.com/questions/75026592/how-to-create-pandas-output-for-custom-transformers</guid>
      <pubDate>Fri, 06 Jan 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>如何将极坐标数据框与 scikit-learn 一起使用？</title>
      <link>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</link>
      <description><![CDATA[我无法将极坐标数据帧与 scikitlearn 一起使用进行机器学习训练。
目前，我正在极坐标中进行所有数据帧预处理，在模型训练期间，我将其转换为 pandas 数据帧以使其正常工作。
是否有任何方法可以直接使用 Polars 数据帧进行 ML 训练而不将其更改为 pandas？]]></description>
      <guid>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</guid>
      <pubDate>Fri, 11 Nov 2022 05:59:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 Conda + Poetry 有意义吗？</title>
      <link>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</link>
      <description><![CDATA[在机器学习项目中使用 Conda + Poetry 有意义吗？让我分享一下我（新手）的理解，请指正或赐教：
据我了解，Conda 和 Poetry 有不同的目的，但很大程度上是多余的：

Conda 主要是一个环境管理器（实际上不一定是 Python），但它也可以管理包和依赖项。
Poetry 主要是一个 Python 包管理器（例如，pip 的升级版），但它也可以创建和管理 Python 环境（例如，Pyenv 的升级版） .

我的想法是同时使用两者并划分它们的角色：让 Conda 担任环境管理器，让 Poetry 担任包管理器。我的推理是（听起来）Conda 最适合管理环境，可用于编译和安装非 python 包，尤其是 CUDA 驱动程序（用于 GPU 功能），而 Poetry 作为 Python 包管理器比 Conda 更强大。 
通过在 Conda 环境中使用 Poetry，我成功地相当轻松地完成了这项工作。诀窍是不使用 Poetry 来管理 Python 环境：我没有使用诸如 poetry shell 或 poetry run 这样的命令，只使用 poetry init 、poetry install 等（激活Conda环境后）。
为了充分披露，我的 environment.yml 文件（针对 Conda）如下所示：
&lt;前&gt;&lt;代码&gt;名称：N

渠道：
  - 默认值
  - 康达锻造

依赖项：
  - 蟒蛇=3.9
  -cuda工具包
  - 库德恩

我的poetry.toml文件看起来像这样：
&lt;前&gt;&lt;代码&gt;[工具.诗歌]
名称=“N”
作者 = [“B”]

[工具.诗歌.依赖项]
蟒蛇=“3.9”
火炬 =“^1.10.1”

[构建系统]
需要= [“诗歌核心&gt;=1.0.0”]
构建后端=“poetry.core.masonry.api”

说实话，我这样做的原因之一是我在没有 Conda 的情况下很难安装 CUDA（用于 GPU 支持）。
您认为这个项目设计合理吗？]]></description>
      <guid>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</guid>
      <pubDate>Tue, 25 Jan 2022 15:09:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我创建新项目时，Unity Visual Studio 无法识别“使用 MlAgents”，但可以在演示项目中识别它？</title>
      <link>https://stackoverflow.com/questions/57019163/why-unity-visual-studio-doesnt-recognise-using-mlagents-when-i-create-a-new-p</link>
      <description><![CDATA[我一直在尝试在我的系统上安装 Unity 的 MLAgents。
阅读详细指南后“https:// /github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation-Windows.md”我成功地让“3D Ball”等演示项目成功运行和训练。
我的问题是，当我创建一个新项目时，当我包含“使用 MlAgents”时，会突出显示一个错误，其中指出“找不到命名空间名称“mlagents”的类型”。
我对 Unity 没有太多经验，所以我希望这是我错过的一件愚蠢的事情，例如您可能必须导入包，但我不知道如何导入？
我发现的所有教程都已经过时了，所以这是我最后的手段。如有任何帮助或建议，我们将不胜感激。
我不明白演示项目如何在“使用 mlagents”时没有错误，但新项目却有错误。]]></description>
      <guid>https://stackoverflow.com/questions/57019163/why-unity-visual-studio-doesnt-recognise-using-mlagents-when-i-create-a-new-p</guid>
      <pubDate>Sat, 13 Jul 2019 12:27:17 GMT</pubDate>
    </item>
    </channel>
</rss>