<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Jun 2024 06:20:47 GMT</lastBuildDate>
    <item>
      <title>Azure ML-如何从 Blob 容器注册模型？</title>
      <link>https://stackoverflow.com/questions/78584772/azure-ml-how-to-register-model-from-blob-container</link>
      <description><![CDATA[我有预定义的模型并存储在 blob 存储中。现在我想注册模型并部署它，并在 Azure ML 中启用端点。我使用了以下代码
from azureml.core import Model
from azureml.core import Workspace

subscription_id = &#39;mysub
resource_group = &#39;my_resource_group&#39;
workspace_name = &#39;my_ws_name&#39;

ws = Workspace(subscription_id, resource_group, working_name)

model_path = &#39;my_model.joblib&#39;

container = &#39;mycontainer&#39;

model_name = &#39;my_model_v1&#39;

model = Model.register(workspace=ws,
model_name=model_name,
model_path=model_path,
description=&quot;Test_Model&quot;,
tags={&#39;area&#39;: &quot;emotion detection&quot;},
model_framework=Model.Framework.SCIKITLEARN,
model_framework_version=&#39;0.24.1&#39;,
resource_configuration=None,
container_registry=None,
properties=None,
sample_input_dataset=None,
sample_output_dataset=None,
datasets=None,
model_url=f&#39;https://mystorage.blob.core.windows.net/{container}/{model_path}&#39;)
print(&quot;Ws object created&quot;)

但下面的代码返回错误
TypeError: register() 得到了一个意外的关键字参数 &#39;container_registry&#39;

有没有什么解决办法或者其他方法？]]></description>
      <guid>https://stackoverflow.com/questions/78584772/azure-ml-how-to-register-model-from-blob-container</guid>
      <pubDate>Thu, 06 Jun 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>使用前向验证时，时间序列数据的 LSTM 性能急剧下降</title>
      <link>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</guid>
      <pubDate>Thu, 06 Jun 2024 06:12:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么偏差的导数是对所有数据点求和而不是平均值</title>
      <link>https://stackoverflow.com/questions/78584207/why-is-derviative-of-bias-summed-across-all-data-points-dout-and-not-average</link>
      <description><![CDATA[我有一个基本的仿射层，即，我有 out=X@W+bias，其中 X@W 的形状为 (N,C)，b 的形状为 (C,)。如果我有损失的导数，wrt out 为 dout，形状为 (N.C)，为什么 db=dout 所有行的总和？为什么不是平均值之类的东西？]]></description>
      <guid>https://stackoverflow.com/questions/78584207/why-is-derviative-of-bias-summed-across-all-data-points-dout-and-not-average</guid>
      <pubDate>Thu, 06 Jun 2024 02:19:01 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 detector2 中语义分割的每个类的像素总数</title>
      <link>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</link>
      <description><![CDATA[我想计算每个分割类的总像素数，我只需要每个一般对象的计数，例如每辆车一个类，每个人一个类等等。出于这个原因，我使用语义分割而不是实例分割（实例分割会分别考虑每个车辆或人员实例）。但detectron2中语义分割的输出没有二进制掩码。
我知道实例分割的输出是二进制掩码，可以使用以下代码获取像素数：
masks = output[&#39;instances&#39;].pred_masks 
results = torch.sum(torch.flatten(masks, start_dim=1),dim=1)

这给出了像素数，但分别考虑了每个车辆实例，这是我不想要的。
但是语义分割的输出是字段“sem_seg”，其中包含每个一般类的预测类概率而不是二元掩码，我怎样才能继续获取语义分割中每个类的像素数？]]></description>
      <guid>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</guid>
      <pubDate>Wed, 05 Jun 2024 22:40:27 GMT</pubDate>
    </item>
    <item>
      <title>使用同一模型问题预测时间序列中多个实例的未来 CPU 使用率 [关闭]</title>
      <link>https://stackoverflow.com/questions/78583575/predicting-future-cpu-usage-in-time-series-with-multiple-instances-with-the-same</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78583575/predicting-future-cpu-usage-in-time-series-with-multiple-instances-with-the-same</guid>
      <pubDate>Wed, 05 Jun 2024 21:27:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python tensorflow 图像回归模型中增加我的 MAE 损失函数[关闭]</title>
      <link>https://stackoverflow.com/questions/78583554/how-to-increase-my-mae-loss-function-in-python-tensorflow-image-regression-model</link>
      <description><![CDATA[我有 8000 张黑色背景上的圆圈图像。每个标签都是圆圈的 x 坐标。每张图片的尺寸为 (128,128,3)。我的训练损失从 2000 开始，到 10 结束，而验证损失保持在 200 左右。另外，我通过将每幅图像除以 255 来对其进行标准化。
images_array 的形状为：(8000,128,128,3)
y 的形状为：(8000,1)
这是我的代码：
from sklearn.model_selection import train_test_split
X_train, X_temp, y_train, y_temp = train_test_split(images_array, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

import tensorflow as tf
X_train = tf.convert_to_tensor(X_train)
y_train = tf.convert_to_tensor(y_train)

从 tensorflow 导入 keras
从 tensorflow.keras 导入层，模型
从 tensorflow.keras.models 导入顺序

输入 = keras.Input(shape=(128, 128, 3))

# 定义层

x = 层。Conv2D(8, 3, 激活=&#39;relu&#39;)(输入)
x = 层。MaxPooling2D(2)(x)
x = 层。Conv2D(16, 3, 激活=&#39;relu&#39;)(x)
x = 层。MaxPooling2D(2)(x)
x=层。Flatten()(x)
x = 层。Dense(128, 激活=&#39;relu&#39;)(x)
output_x = 层。Dense(1, 激活 = &#39;linear&#39;, 名称 = &quot;y1_output&quot;)(x)

model = Model(inputs = input, output = output_x)
model.summary()


我可以做些什么来显著改善我的损失？
我尝试了不同的激活函数和不同的优化器。]]></description>
      <guid>https://stackoverflow.com/questions/78583554/how-to-increase-my-mae-loss-function-in-python-tensorflow-image-regression-model</guid>
      <pubDate>Wed, 05 Jun 2024 21:21:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 模型或其他实践在大型数据集中识别名字和姓氏的最佳做法是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</guid>
      <pubDate>Wed, 05 Jun 2024 20:00:15 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的残差</title>
      <link>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</link>
      <description><![CDATA[假设我们有一个线性模型，该模型适用于某些数据，其残差呈正态分布。我要问的问题是，我们能否在建模方面做得更好？有没有比这个线性模型更好的模型？
由于残差是 ND，因此没有模式可学习，因此线性模型是最好的。你对此有什么看法？
谢谢
我试图找到我的主张的严格证据]]></description>
      <guid>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</guid>
      <pubDate>Wed, 05 Jun 2024 15:14:26 GMT</pubDate>
    </item>
    <item>
      <title>将图像置于中心并在导出时添加背景</title>
      <link>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</link>
      <description><![CDATA[我想自动完成所有这些操作：

选择图像中的对象
在此对象上裁剪我的图像
裁剪为 1:1 的宽高比，在此对象周围留出一点空隙
以 800x800px 的 JPG 格式导出我的图像，我的对象位于图像中心，背景为白色。

我在 win11 64 位上
我做了什么：

安装 Python 并创建环境
安装opencv-python-headless、pillow、numpy、Pytorch以用于 CUDA 11.8
克隆存储库 segment-anything.git 并使用 PIP 安装它
下载sam_vit_b_01ec64.pth

像这样对 py 文件进行编码：
import os
import cv2
import numpy as np
from PIL import Image
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator

def load_image(image_path):
return cv2.imread(image_path)

def save_image(image, path):
cv2.imwrite(path + &#39;.jpg&#39;, image)

def select_object(image):
sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;sam_vit_b_01ec64.pth&quot;)
mask_generator = SamAutomaticMaskGenerator(sam)
mask = mask_generator.generate(image)
largest_mask = max(masks, key=lambda x: x[&#39;area&#39;])
返回 largest_mask[&#39;segmentation&#39;]

def crop_to_object(image, mask):
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
padding = 5
x = max(0, x - padding)
y = max(0, y - padding)
w = min(image.shape[1] - x, w + 2 * padding)
h = min(image.shape[0] - y, h + 2 * padding)

cropped_image = image[y:y+h, x:x+w]
返回 cropped_image

def resize_to_square(image, size=800):
h, w = image.shape[:2]
scale = size / max(h, w)
new_h, new_w = int(h * scale), int(w * scale)
resized_image = cv2.resize(image, (new_w, new_h), 插值=cv2.INTER_LANCZOS4)

new_image = np.ones((size, size, 3), dtype=np.uint8) * 255

top = (size - new_h) // 2
left = (size - new_w) // 2
bottom = top + new_h
right = left + new_w

new_image[top:top+new_h, left:left+new_w] = resized_image

return new_image

def process_image(image_path, output_path):

image = load_image(image_path)
mask = select_object(image)
cropped_image = crop_to_object(image, mask)
final_image = resize_to_square(cropped_image, 800)
save_image(final_image, output_path + &#39;.jpg&#39;)

def process_folder(input_folder, output_folder):

如果 os.path.exists(output_folder):
os.makedirs(output_folder)

对于 root、_、os.walk(input_folder) 中的文件：
对于 filename in files:
如果 filename.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;, &#39;.bmp&#39;, &#39;.tiff&#39;)):
input_path = os.path.join(root, filename)

relative_path = os.path.relpath(input_path, input_folder)
output_path = os.path.join(output_folder,relative_path)

output_dir = os.path.dirname(output_path)
如果 os.path.exists(output_dir):
os.makedirs(output_dir)

尝试：
process_image(input_path, output_path)
print(f&quot;已处理 {input_path}&quot;)
except Exception as e:
print(f&quot;无法处理 {input_path}：{e}&quot;)

if __name__ == &quot;__main__&quot;:
input_folder = &quot;&quot;
output_folder = &quot;&quot;
process_folder(input_folder, output_folder)

发生了什么：
我导入了基本图像，我想要预期结果，并且我获得了结果
有人能帮我理解我错过了什么吗？
提前谢谢，
Cyril]]></description>
      <guid>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</guid>
      <pubDate>Wed, 05 Jun 2024 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>llama-index、uncharted 和 llama2:7b 在本地运行以生成索引</title>
      <link>https://stackoverflow.com/questions/78581041/llama-index-uncharted-and-llama27b-run-locally-to-generate-index</link>
      <description><![CDATA[我想在本地使用 llama-index 和 ollama 以及 llama3:8b 来索引 utf-8 json 文件。我没有 gpu。我使用 uncharted 将文档转换为 json。现在，如果没有 GPU 就无法在本地使用 llama-index，我想使用 hugging face 推理 API。但我不确定它是否免费。有人能建议一种方法吗？
这是我的 python 代码：


from llama_index.core import Document, SimpleDirectoryReader, VectorStoreIndex
from llama_index.llms.ollama import Ollama
import json
from llama_index.core import Settings

# 将 JSON 文档转换为 LlamaIndex Document 对象
with open(&#39;data/UBER_2019.json&#39;, &#39;r&#39;,encoding=&#39;utf-8&#39;) as f:
json_doc = json.load(f)
documents = [Document(text=str(doc)) for doc in json_doc]

# 使用本地 LLM 初始化 Ollama
ollama_llm = Ollama(model=&quot;llama3:8b&quot;)
Settings.llm = ollama_llm

# 使用本地 LLM 创建索引
index = VectorStoreIndex.from_documents(documents)#, llm=ollama_llm)


但我一直收到没有 OPENAI 密钥的错误。我想使用 llama2，这样就不需要 OPENAI 密钥了
有人能指出我做错了什么吗？我还可以免费使用 huggingfaceinference API 对本地 json 文件进行索引吗？]]></description>
      <guid>https://stackoverflow.com/questions/78581041/llama-index-uncharted-and-llama27b-run-locally-to-generate-index</guid>
      <pubDate>Wed, 05 Jun 2024 12:38:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 logistf 包在 R 中计算 Firth 模型非收敛误差</title>
      <link>https://stackoverflow.com/questions/78579401/firths-model-non-converge-error-in-r-using-the-logistf-package</link>
      <description><![CDATA[这是示例数据的链接（示例数据不大 - 只有 23 kb，但可能是导致错误的原因）：

https://drive.google.com/file/d/1TWkFIKhq9VZkFnhUrt6LxYmab54ouODd/view?usp=sharing

这是我运行 firth 模型的代码。我在不同的运行中遇到了不同的错误（重新启动 r 或 r 会话），有时程序似乎卡住了（但是，活动监视器显示 CPU 使用率为 99%），其他时候我遇到了诸如不收敛之类的错误，并建议我增加迭代次数，但这并没有真正帮助。
library(caret)
library(logistf)
library(data.table)

# 定义训练控制
train_control &lt;- trainControl(method = &quot;repeatedcv&quot;, 
number = 3, repeats = 3,
savePredictions = TRUE,
classProbs = TRUE)

# 定义自定义模型函数
firth_model &lt;- list(
type = &quot;Classification&quot;,
library = &quot;logistf&quot;,
loop = NULL,
parameters = data.frame(parameter = c(&quot;none&quot;), class = c(&quot;character&quot;), label = c(&quot;none&quot;)),
grid = function(x, y, len = NULL, search = &quot;grid&quot;) {
data.frame(none = &quot;none&quot;)
},
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
data &lt;- as.data.frame(x)
data$group &lt;- y
logistf(group ~ ., data = data, control = logistf.control(maxit = 100), ...)
},
predict = function(modelFit, newdata, submodels = NULL) {
as.factor(ifelse(predict(modelFit, newdata, type = &quot;response&quot;) &gt; 0.5, &quot;AD&quot;, &quot;control&quot;))
},
prob = function(modelFit, newdata, submodels = NULL) {
preds &lt;- predict(modelFit, newdata, type = &quot;response&quot;)
data.frame(control = 1 - preds, AD = preds)
}
)

train_proc &lt;- fread(&quot;train_proc.csv&quot;)

# 训练模型
set.seed(123)
firth.logist.model &lt;- train(train_proc[, .SD, .SDcols = !c(&quot;group&quot;)],
train_proc$group,
method = firth_model,
trControl = train_control)

print(firth.logist.model)


这是最新的错误
logistf(group ~ ., data = data, control = logistf.control(maxit = 100), 中出现警告：
未收敛的 PL 置信限度：变量的最大迭代次数：（截距）、x1、x2、x3、x4、x5、x6、x7、x8、x9、x10、x11、x12、x13、x14、x15、x16、x17、x18、x19、x20、x21、x22、x23、x24 超出。尝试通过将“logistpl.control(maxit=...)”传递给参数 plcontrol 来增加迭代次数

相同的代码似乎在某些数据集上运行，但在其他数据集上运行不起来。但这也可能是由于我的函数无法针对特定数据集进行自定义。我遇到了许多不同类型的错误，我开始怀疑 logistf 包本身是否不稳定。
为了提供更多信息，这是我的 r 版本：
R.version
_ 
platform aarch64-apple-darwin20 
arch aarch64 
os darwin20 
system aarch64, darwin20 
status 
major 4 
minor 3.2 
year 2023 
month 10 
day 31 
svn rev 85441 
language R 
version.string R version 4.3.2 (2023-10-31)
nickname Eye Holes 

这是我的包版本：
&gt; packageVersion(&quot;caret&quot;)
[1] ‘6.0.94’
&gt; packageVersion(&quot;logistf&quot;)
[1] ‘1.26.0’
&gt; packageVersion(&quot;data.table&quot;)
[1] ‘1.14.10’
]]></description>
      <guid>https://stackoverflow.com/questions/78579401/firths-model-non-converge-error-in-r-using-the-logistf-package</guid>
      <pubDate>Wed, 05 Jun 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>Julia MLJ Forest Load：错误：MethodError：没有与 BetaML.Bmlj.RandomForestRegressor() 匹配的方法</title>
      <link>https://stackoverflow.com/questions/78577415/julia-mlj-forest-loaderror-methoderror-no-method-matching-betaml-bmlj-randomf</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78577415/julia-mlj-forest-loaderror-methoderror-no-method-matching-betaml-bmlj-randomf</guid>
      <pubDate>Tue, 04 Jun 2024 19:40:11 GMT</pubDate>
    </item>
    <item>
      <title>微调模型时内存不足</title>
      <link>https://stackoverflow.com/questions/78542429/running-out-of-ram-when-finetuning-model</link>
      <description><![CDATA[我目前正在尝试微调 Wav2Vec2 模型：https://huggingface.co/dima806/bird_sounds_classification。但是我的 RAM 使用率超过了 Google Colab 的免费套餐。
以下是我的代码：
from transformers import TrainingArguments, Trainer

# 使用 ignore_mismatched_sizes=True 加载模型
model = Wav2Vec2ForSequenceClassification.from_pretrained(
&quot;dima806/bird_sounds_classification&quot;,
num_labels=len(label2id),
ignore_mismatched_sizes=True
)

# 使用梯度累积设置训练
batch_size = 1 # 减少批次大小以管理内存
accumulation_steps = 4 # 在 4 个步骤中累积梯度

training_args = TrainingArguments(
output_dir=&quot;./results&quot;,
evaluation_strategy=&quot;epoch&quot;,
learning_rate=2e-5,
per_device_train_batch_size=batch_size,
per_device_eval_batch_size=batch_size,
gradient_accumulation_steps=accumulation_steps, # 梯度累积
num_train_epochs=3,
weight_decay=0.01,
fp16=True, # 启用混合精度训练
)

trainer = Trainer(
model=model,
args=training_args,
train_dataset=train_dataset,
eval_dataset=val_dataset,
tokenizer=feature_extractor,
)

# 训练模型
trainer.train()

RAM 超过 12.7GB 的原因可能是什么？我的数据集只包含 20 个项目。我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78542429/running-out-of-ram-when-finetuning-model</guid>
      <pubDate>Tue, 28 May 2024 07:10:21 GMT</pubDate>
    </item>
    <item>
      <title>训练 DL 模型时，本地会合中止，状态为：OUT_OF_RANGE：序列结束</title>
      <link>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</link>
      <description><![CDATA[我正在创建一个植物疾病识别模型。我有一个包含 38 种疾病的数据集，每种疾病大约有 2000 张图像。但在训练模型时，由于某些 OUT_OF_RANGE 错误，一些时期被跳过。有人能帮我解决这个问题吗？
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input

train_dir = &#39;dataset/train&#39;
valid_dir = &#39;dataset/valid&#39;
batch_size = 32

train_datagen = ImageDataGenerator(
rescale=1./255,
rotation_range=40,
width_shift_range=0.2,
height_shift_range=0.2,
sher_range=0.2,
zoom_range=0.2,
Horizo​​ntal_flip=True,
fill_mode=&#39;nearest&#39;
)

valid_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
train_dir,
target_size=(150, 150),
batch_size=batch_size,
class_mode=&#39;categorical&#39;
)

valid_generator = valid_datagen.flow_from_directory(
valid_dir,
target_size=(150, 150),
batch_size=batch_size,
class_mode=&#39;categorical&#39;
)

model = Sequential([
输入(shape=(150, 150, 3)),
Conv2D(32, (3, 3), 激活=&#39;relu&#39;),
MaxPooling2D(2, 2),
Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
MaxPooling2D(2, 2),
Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
MaxPooling2D(2, 2),
Flatten(),
Dense(512,activation=&#39;relu&#39;),
Dense(38,activation=&#39;softmax&#39;) # 根据疾病类别数量调整输出单元
])

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

history = model.fit(
train_generator,
steps_per_epoch=train_generator.samples //batch_size,
epochs=10,
validation_data=valid_generator,
validation_steps=valid_generator.samples //batch_size
)

model.save(&#39;plant_disease_model.h5&#39;)

class_indices = train_generator.class_indices
disease_names = list(class_indices.keys())
print(&quot;类别索引到疾病名称的映射：&quot;, class_indices)

终端：
找到属于 38 个类别的 70295 张图像。
找到属于 38 个类别的 17572 张图像。
2024-04-23 19:50:32.085744：I tensorflow/core/platform/cpu_feature_guard.cc:210] 此 TensorFlow 二进制文件经过优化，可在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：AVX2 FMA，在其他操作中，请使用适当的编译器标志重建 TensorFlow。
纪元 1/10
\.venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.p
y:120：UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_m
ultiprocessing`、`max_queue_size`。请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()
←[1m2196/2196←[0m ←[32m━━━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m905s←[0m 411ms/step - 准确度：0.4608 - 损失：1.8737 - val_accuracy：0.7432 - val_
loss：0.8556
Epoch 2/10
←[1m 1/2196←[0m ←[37m━━━━━━━━━━━━━━━━━━━━━←[0m ←[1m12:02←[0m 329ms/step - 准确度：0.6875 - 损失：0.78202024-04-23 20:05:37.996528：W tensorfl
ow/core/framework/local_rendezvous.cc:404] 本地会合正在中止，状态为：OUT_OF_RANGE：序列结束
[[{{node IteratorGetNext}}]]
C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py:155：UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 `steps_per_epoch * epochs` 个批次。您可能需要在构建数据集时使用 `.repeat()` 函数。
self.gen.throw(typ, value, traceback)
2024-04-23 20:05:38.068817: W tensorflow/core/framework/local_rendezvous.cc:404] 本地会合正在中止，状态为：OUT_OF_RANGE：序列结束
[[{{node IteratorGetNext}}]]
←[1m2196/2196←[0m ←[32m━━━━━━━━━━━━━━━━━━━━━←[0m←[37m←[0m ←[1m0s←[0m 49us/step - 精度：0.6875 - 损失：0.7820 - val_accuracy： 0.7500 - val_los
s: 0.2462

如上所示，epoch 1 成功完成，但 epoch 2 因某些错误而终止。同样，epoch 3、5、7、9 成功完成，但 epoch 4、6、8、10 出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</guid>
      <pubDate>Wed, 24 Apr 2024 06:27:20 GMT</pubDate>
    </item>
    <item>
      <title>错误 conda.core.link:_execute(698): 安装包“defaults::icu-58.2-ha925a31_3”时发生错误</title>
      <link>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</link>
      <description><![CDATA[我使用 anaconda prompt conda create -n talkingbot python=3.5 创建了环境，然后安装了 pip install tensorflow==1.0.0（遵循与 udemy 课程中使用的相同命令），但是当我尝试使用 conda install spyder 安装 spyder 时，它给了我这个错误：
准备交易：完成
验证交易：完成
执行交易：完成
错误 conda.core.link:_execute(698)：安装包“defaults::icu-58.2-ha925a31_3”时发生错误。
回滚事务：完成

[Errno 13] 权限被拒绝：&#39;C:\\Users\\Lenovo\\anaconda3\\envs\\talkingbot\\Library\\bin\\icudt58.dll&#39;
()

然后我尝试使用 anaconda navigator 安装 spyder，但 spyder 也未安装。
帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</guid>
      <pubDate>Sun, 13 Sep 2020 13:42:24 GMT</pubDate>
    </item>
    </channel>
</rss>