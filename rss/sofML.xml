<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 06 Dec 2023 01:01:42 GMT</lastBuildDate>
    <item>
      <title>无法让我的逻辑回归算法显示任何图</title>
      <link>https://stackoverflow.com/questions/77609888/cant-get-my-logistic-regression-algorithm-to-display-any-of-the-plots</link>
      <description><![CDATA[这是我的逻辑回归项目的代码。我没有错误并且程序运行，但是一旦运行完成，它只显示进程完成退出代码0。它应该显示诸如我的成本函数和 thetas 以及所有常见的机器学习信息之类的内容，但我一生都无法让它显示。
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np
将 pandas 导入为 pd
从 numpy 导入日志、点、exp、形状
从 sklearn.linear_model 导入 LogisticRegression
从 sklearn.model_selection 导入 train_test_split


def标准化（x_tr）：
    对于范围内的 i(shape(x_tr)[1])：
        x_tr[:, i] = (x_tr[:, i] - np.mean(x_tr[:, i])) / np.std(x_tr[:, i])
    返回x_tr


定义 sigmoid(z):
    sig = 1 / (1 + exp(-z))
    返回信号


定义成本（theta，x，y）：
    z = 点(x, θ)
    cost0 = y.T.dot(log(sigmoid(z)))
    成本1 = (1 - y).T.dot(log(1 - sigmoid(z)))
    成本 = -(成本1 + 成本0) / len(y)
    退货成本


def 初始化（x，y）：
    thetas = np.zeros((shape(x)[1] + 1, len(np.unique(y))))
    x = np.c_[np.ones((形状(x)[0], 1)), x]
    返回 θ，x


def fit(x, y, alpha=0.001, 迭代=400):
    θ，x = 初始化（x，y）
    cost_list = np.zeros(迭代, )

    对于范围内的 i（迭代）：
        对于范围内的 c(len(np.unique(y)))：
        y_temp = np.where(y == c, 1, 0)
        thetas[:, c] = thetas[:, c] - alpha * dot(x.T, (sigmoid(dot(x, thetas[:, c])) - y_temp))
        cost_list[i] += cost(thetas[:, c], x, y_temp)

    返回cost_list，thetas


def 预测（x，thetas）：
    x = np.c_[np.ones((形状(x)[0], 1)), x]
    z = 点(x, θ)
    sig = sigmoid(z)
    返回 np.argmax(sig, axis=1)


def 比较（y_test，y_pred，y_pred1）：
    正确分类 = np.sum(y_test == y_pred)
    正确分类1 = np.sum(y_test == y_pred1)

print(“我们的模型测试集的准确度：”, (rightly_classified / len(y_test)) * 100)
print(“sklearn 模型测试集的准确度：”, (rightly_classified1 / len(y_test)) * 100)


def main():
df = pd.read_csv(&#39;Iris.csv&#39;) # 使用正确的文件名更新文件名
x = df.iloc[:, :-1].values
y = df.iloc[:, -1].值

# 将分类值转换为数值
df[&#39;物种&#39;].replace(&#39;Iris-setosa&#39;, 0, inplace=True)
df[&#39;物种&#39;].replace(&#39;杂色鸢尾&#39;, 1, inplace=True)
df[&#39;物种&#39;].replace(&#39;维吉尼亚鸢尾&#39;, 2, inplace=True)

x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size=0.3, random_state=0)
x_tr = 标准化(x_tr)

cost_list, thetas = fit(x_tr, y_tr)
plt.scatter(range(len(cost_list)), cost_list, c=“蓝色”)
plt.show()

y_pred = 预测（x_te，thetas）
模型1 = 逻辑回归()
model1.fit(x_tr, y_tr)
y_pred1 = model1.预测(x_te)

比较（y_te，y_pred，y_pred1）

主要的（）
]]></description>
      <guid>https://stackoverflow.com/questions/77609888/cant-get-my-logistic-regression-algorithm-to-display-any-of-the-plots</guid>
      <pubDate>Wed, 06 Dec 2023 00:03:09 GMT</pubDate>
    </item>
    <item>
      <title>数百个时间序列的需求预测方法</title>
      <link>https://stackoverflow.com/questions/77609637/demand-forecasting-methods-for-hundreds-of-time-series</link>
      <description><![CDATA[我有 TFL 骑行数据集时间段从 2023 年 1 月到 2023 年 6 月。我想预测需求或预期数量。一天中每个小时每个车站的班次。
发布一些数据处理，下面是我的预测变量 -
起始站号
自行车型号
开始时间
一周开始日
开始月份
trip_duration_bins
我基本上会预测每个车站每天每小时的可能行程数量，这些行程属于 &lt;30 分钟、30-60 分钟和超过 1 小时的行程持续时间类别。

我不清楚是否可以只使用线性回归、基于树的回归方法等，或者是否必须单独使用时间序列方法。

如果我可以使用任何回归方法，我可以将数据拆分为训练和验证吗？还是必须按时间序列拆分？

如果我必须使用时间序列方法（我对此了解不多），我该怎么做？我很困惑，因为感觉就像没有。随着时间的推移，每个车站的旅程将成为一个时间序列，由于车站有很多，我们有数百个时间序列。

如果每个车站每小时的出行是一个时间序列，那么如何对数百个时间序列去除季节性并找到它们的模型顺序？


可能是愚蠢的问题，因为我对这些东西很陌生。但是，提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/77609637/demand-forecasting-methods-for-hundreds-of-time-series</guid>
      <pubDate>Tue, 05 Dec 2023 22:45:16 GMT</pubDate>
    </item>
    <item>
      <title>训练 CNN 时如何绘制学习率和 Epoch？</title>
      <link>https://stackoverflow.com/questions/77609614/how-to-plot-learning-rate-and-epoch-when-training-a-cnn</link>
      <description><![CDATA[我正在尝试使用基于余弦的衰减时间表来提高 CNN 的准确性。我希望直观地看到整个训练过程中此计划对模型学习率造成的变化。
如何在 R 中绘制学习率曲线，其中 y 轴为学习率，x 轴为步长？这里提供了来自其他来源的示例曲线：https://i.stack.imgur.com/ q7d1q.png
参见下面的代码：
# 1.学习率设置
Learning_rate_schedule_cosine_decay（initial_learning_rate = 0，decay_steps = 1000，alpha = 0，name = &#39;余弦衰减&#39;）
lr_decayed_fn &lt;-learning_rate_schedule_cosine_decay（initial_learning_rate = 0.0001，decay_steps = 1000）

# 2.模型编译
模型 &lt;- keras_model_sequential()
型号%&gt;%
  layer_conv_2d(滤波器 = 32, kernel_size = c(3,3), 激活 = &#39;relu&#39;, input_shape = c(256, 256, 3))%&gt;%
  layer_conv_2d（过滤器= 32，kernel_size = c（3,3），激活=&#39;relu&#39;）％&gt;％
  Layer_max_pooling_2d(pool_size = c(2,2))%&gt;%
  layer_dropout(rate = 0.25)%&gt;%
  layer_conv_2d（过滤器= 64，kernel_size = c（3,3），激活=&#39;relu&#39;）％&gt;％
  layer_conv_2d（过滤器= 64，kernel_size = c（3,3），激活=&#39;relu&#39;）％&gt;％
  Layer_dropout(率 = 0.25) %&gt;%
  Layer_flatten()%&gt;%
  Layer_dense(单位 = 256, 激活 = &#39;relu&#39;)%&gt;%
  layer_dropout(rate = 0.25)%&gt;%
  Layer_dense(单位 = 128, 激活 = &#39;relu&#39;)%&gt;%
  layer_dropout(rate = 0.25)%&gt;%
  Layer_dense(单位 = 4, 激活 = &#39;softmax&#39;)%&gt;%
  编译（损失=&#39;分类交叉熵&#39;，
          优化器 = optimizer_adam(lr = lr_decayed_fn, name = &#39;Adam&#39;),
          指标 = c(&#39;准确度&#39;))
摘要（模型）


# 适合模型
历史记录&lt;-模型%&gt;%
  适合（训练x，
      火车标签，
      历元 = 30,
      批量大小=32，
      验证分割= 0.2）
情节（历史）
]]></description>
      <guid>https://stackoverflow.com/questions/77609614/how-to-plot-learning-rate-and-epoch-when-training-a-cnn</guid>
      <pubDate>Tue, 05 Dec 2023 22:38:48 GMT</pubDate>
    </item>
    <item>
      <title>HMM R 包 if (d < delta) { 中的错误：缺少 TRUE/FALSE 需要的值</title>
      <link>https://stackoverflow.com/questions/77609409/hmm-r-package-error-in-if-d-delta-missing-value-where-true-false-needed</link>
      <description><![CDATA[我正在尝试在 R 中使用 HMM 包。
我想要 4 个隐藏状态，我的观察值范围为 2 到 15。
我可以毫无问题地初始化隐藏模型：
if (!require(HMM, 悄悄地 = TRUE)) {
  install.packages(“HMM”)
  图书馆（隐马尔可夫模型）
} 别的 {
  图书馆（隐马尔可夫模型）
}

# 加载数据
url &lt;-“https://raw.githubusercontent.com/luancvieira/HMM/main/ottawa_2010-2012.csv”
df &lt;- read.csv(url)

观察到的数据 &lt;- df$AvgTemperature

# 定义状态的数量和名称
n_states &lt;- 4
state_names &lt;-paste0(“州”, 1:n_states)

# 对符号进行排序
symbol_names &lt;- as.character(sort(unique(observed_data)))
observed_data &lt;- as.character(observed_data)

# 用随机概率初始化HMM模型
start_probs &lt;- runif(n_states)
trans_probs &lt;- 矩阵(runif(n_states * n_states),
               nrow = n_states, ncol = n_states)
emission_probs &lt;- 矩阵(runif(n_states * length(symbol_names)),
                  nrow = n_states, ncol = 长度(symbol_names))

# 标准化行以确保概率总和为 1
start_probs &lt;- start_probs / sum(start_probs)
trans_probs &lt;- trans_probs / rowSums(trans_probs)
Emission_probs &lt;- Emission_probs / rowSums(emission_probs)

# 初始化HMM模型
hmm_model &lt;- initHMM(States = state_names,
                     符号 = 符号名称，
                     起始概率=起始概率，
                     反式概率=反式概率，
                     排放概率 = 排放概率）

# 打印初始化的模型
打印（嗯_模型）


但是，当我尝试运行它时：
bw = baumWelch(hmm = hmm_model,观察=observed_data,
               最大迭代次数 = 100，增量 = 0.001)

我明白了
if (d &lt; delta) { 中的错误：缺少 TRUE/FALSE 需要的值。

如果我将迭代次数减少到 10 次，它运行时不会出现问题，但 10 次迭代不足以收敛。 delta 是算法的停止标准，如下所示： https:// /cran.r-project.org/web/packages/HMM/HMM.pdf。 delta 的默认值为 1e-9，因此即使没有指定 delta，在运行更多次迭代时仍然会返回错误。]]></description>
      <guid>https://stackoverflow.com/questions/77609409/hmm-r-package-error-in-if-d-delta-missing-value-where-true-false-needed</guid>
      <pubDate>Tue, 05 Dec 2023 21:45:12 GMT</pubDate>
    </item>
    <item>
      <title>一个张量流管道，输入 shape=(256, 256, 3), dtype=tf.float32 图像，使用 MTCNN() 提取人脸。我就是无法完成这件事</title>
      <link>https://stackoverflow.com/questions/77608982/a-tensorflow-pipeline-that-inputs-shape-256-256-3-dtype-tf-float32-image</link>
      <description><![CDATA[张量流 2.15 管道采用两个 256X256X3、uint8 图像...&#39;input_image&#39;、“real_image”，来自之前的 tf.data.Dataset 类型管道，使用 MTCNN.detect_faces() 从 input_image 中提取面部，并在图像上绘制面加上 5% 额外的有界框作为相同大小的输入图像，并返回 input_image 和 real_image 而不更改 real_image
。
..
...
....
def extract_faces_from_tensors(input_image, real_image, margin_percent=5, required_size=(256, 256)):
# 将输入图像张量转换为 NumPy 数组
input_image = input_image.numpy()
# 检测人脸
检测器 = MTCNN()
faces = detector. detector_faces(input_image)

脸部图像 = []
真实图像 = 真实图像.numpy()

如果面临：
    对于面孔中的面孔：
        # 从请求的面中提取带有边距的边界框
        x, y, 宽度, 高度 = 面[&#39;box&#39;]
        边距 = int(min(宽度, 高度) * (margin_percent / 100.0))
        x1, y1 = max(x - 边距, 0), max(y - 边距, 0)
        x2, y2 = x + 宽度 + 边距, y + 高度 + 边距

        # 提取有边缘的脸
        面边界 = 输入图像[y1:y2, x1:x2]

        # 在创建 PIL 图像之前转换为 uint8
        面边界 = np.uint8(面边界)

        # 从数组创建一个 PIL 图像
        face_image = Image.fromarray(face_boundary)

        # 将像素大小调整为所需的大小
        面部图像 = 面部图像.调整大小(required_size)
        
        # 转换为 float32 并标准化为范围 [0, 1]
        face_array = tf.cast(np.array(face_image), tf.float32) / 255.0
        真实图像 = tf.cast(真实图像, tf.float32)/255.0
        face_images.append(face_array)
        输入图像=人脸图像

返回输入图像、真实图像

tr_data = tr_data.map(extract_faces_from_tensors, num_parallel_calls=tf.data.AUTOTUNE)
tr_数据
。
..
...
属性错误：在用户代码中：
文件“/tmp/ipykernel_47/4070542639.py”，第 3 行，位于 extract_faces_from_tensors *
    输入图像 = 输入图像.numpy()

AttributeError：“SymbolicTensor”对象没有属性“numpy”

过去两天我一直陷入这个问题，已经尝试了 gpt、co-pilot 一切。
请大家帮忙]]></description>
      <guid>https://stackoverflow.com/questions/77608982/a-tensorflow-pipeline-that-inputs-shape-256-256-3-dtype-tf-float32-image</guid>
      <pubDate>Tue, 05 Dec 2023 20:05:29 GMT</pubDate>
    </item>
    <item>
      <title>我有 300 个课程标题，需要将它们分组为未知数量的主题。这项作业推荐使用什么无监督学习方法[关闭]</title>
      <link>https://stackoverflow.com/questions/77608183/i-have-300-course-titles-and-need-to-group-them-into-an-unknown-number-of-topics</link>
      <description><![CDATA[此问题涉及将 300 个课程标题分类为几个总体主题，而事先不知道这些主题的数量或性质。挑战在于确定这些主题的数量和内容。在此背景下，我们正在寻找一种合适的无监督学习方法来完成这一任务。
我很困惑，不知道该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/77608183/i-have-300-course-titles-and-need-to-group-them-into-an-unknown-number-of-topics</guid>
      <pubDate>Tue, 05 Dec 2023 17:31:29 GMT</pubDate>
    </item>
    <item>
      <title>缺陷的时间演变：预测剩余缺陷</title>
      <link>https://stackoverflow.com/questions/77607265/temporal-evolution-of-defects-predicting-remaining-defect</link>
      <description><![CDATA[我在一家公司的人工智能论文是预测 10 分钟或 Xtime 后纸张上剩余的缺陷

墨水印刷在金属板上
打印后直接出现一些缺陷（打印步骤后1秒拍照）
但一段时间后，一些缺陷消失了，一些缺陷仍然存在

我的目标是打印一张新纸张并拍摄即时照片后：使用机器/深度学习预测 10 分钟或 Xtime 后剩余的缺陷
说明（涂上墨水后涂抹更多并覆盖疤痕等缺陷）
我有多种资源，如相机、机器等
我愿意接受任何想法]]></description>
      <guid>https://stackoverflow.com/questions/77607265/temporal-evolution-of-defects-predicting-remaining-defect</guid>
      <pubDate>Tue, 05 Dec 2023 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助......Apple ML 给出奇怪的结果[关闭]</title>
      <link>https://stackoverflow.com/questions/77607078/need-help-apple-ml-giving-out-weird-results</link>
      <description><![CDATA[我的目标是使用 WLASL 数据集创建一个将手语转换为文本的模型。现在，从一开始就从 Kaggle 下载这个模型，虽然数据集看起来相当全面，但每个类别的视频数量从 5-13 个不等，这显然需要训练的内容相当少。我决定尝试 Apple Create ML，而不是像 Tensorflow 或更复杂的深度学习框架，因为这样会简单得多。由于数据集在每个类别的视频方面非常有限，因此我在“手部动作分类器”中使用了所有 6 个数据增强。 （水平翻转、旋转、平移、缩放、插帧、丢帧）。虽然我知道这无法保存模型，但它肯定会大大提高准确性。请注意，我没有使用数据集中的所有 2000 个类（单词），而是仅使用了 300 个类的子集。我获得了 16% 的验证准确率，以及 90% 的所有增强训练准确率，因此我的模型显然过度拟合。所以我对 25 个类进行了同样的尝试，这次我获得了 42% 的验证准确率，以及 100% 的训练准确率。再次，过度拟合。我进入实时预览，几乎我尝试的每个迹象都被预测为错误。
现在，我决定使用“模型源”在侧边栏中。我不太确定它们的用途，但这是我尝试过的：
我将数据子集分成 2 个单独的模型源（16 个类，但数量仍然很高），分别获得了 83% 的验证准确率和 90% 的验证准确率。这两个模型源都使用所有数据增强。我的模型显然过度拟合，在两个来源中都有 100% 的训练准确度，但将其分成两个模型显然提高了我的准确度，当我在“实时预览”中测试这一点时，我自己做的每个 ASL 标志都能够以超过 90% 的置信度准确猜出每个单词。
所以我的问题是，即使我的数据有限（虽然增强确实增加了很多，但显然性能差异不应该这么大），我的模型如何表现得这么好？此外，将一个模型拆分为单独的模型源是否可行？我不确定“模型来源”有什么用？甚至是，所以我尝试了这个，不知怎的，我得到了更好的结果。如果可行，我如何将它们实现到一个快速应用程序中。我现在有点困惑，所以希望有人能告诉我发生了什么事。如果这不是一个可行的解决方案，有人可以提供另一个解决方案来说明我如何使用这个数据集吗？事先了解它会非常有帮助，但即使你不知道，你能帮助我吗？
Kaggle链接：https://www.kaggle.com/datasets/risangbaskoro/ wlasl 处理
原始论文github页面：https://github.com/dxli94/WLASL]]></description>
      <guid>https://stackoverflow.com/questions/77607078/need-help-apple-ml-giving-out-weird-results</guid>
      <pubDate>Tue, 05 Dec 2023 14:43:09 GMT</pubDate>
    </item>
    <item>
      <title>端到端 ML 项目上的模型训练器问题 - TypeError：__init__() 获得意外的关键字参数“trained_model_file_path”</title>
      <link>https://stackoverflow.com/questions/77606532/model-trainer-issue-on-end-to-end-ml-project-typeerror-init-got-an-unex</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77606532/model-trainer-issue-on-end-to-end-ml-project-typeerror-init-got-an-unex</guid>
      <pubDate>Tue, 05 Dec 2023 13:22:19 GMT</pubDate>
    </item>
    <item>
      <title>spaCy 值错误：[E1041] 需要字符串、文档或字节作为输入，但得到：<class 'float'></title>
      <link>https://stackoverflow.com/questions/77596731/spacy-value-error-e1041-expected-a-string-doc-or-bytes-as-input-but-got</link>
      <description><![CDATA[我正在尝试使用 spaCy 对中文输入进行矢量化。
我的代码如下：


nlp = spacy.load(&#39;zh_core_web_md&#39;)

def tokenize_and_vectorize_textZH(文本):
    clean_tokensZH = []
    对于 nlp(text) 中的标记：
        if (不是 token.is_stop) &amp; (token.lemma_ != &#39;-PRON-&#39;) &amp; （不是 token.is_punct）：
          # -PRON- 是一个特殊的全包“引理” spaCy 用于任何代词，我们要排除这些
            if (len(token.vector) != 300):
              打印（令牌）
            clean_tokensZH.append(token.vector)
    返回 np.array(clean_tokensZH)
    
    
all_summmed_vecsZH = []

def sum_vecsZH(输入):
  tokenized_vectorsZH = input.apply(tokenize_and_vectorize_textZH)
  tokenized_vectorZH = tokenized_vectorsZH.to_numpy()

  打印（len（tokenized_vectorsZH））
  #print(类型(标记化向量))

  对于 tokenized_vectorsZH 中的行：

    #打印（行）

    summed_vecZH = [0]*300 # 从 300 个零的列表开始

    for vec in row: # 循环遍历与行中每个标记对应的每个向量
      #if (len(vec) != 300):
        #打印（向量）
      summed_vecZH += vec

    all_summmed_vecs.append(summed_vecZH)

  #print(tokenized_vectors[0][0].向量)
  
  
#@title 应用矢量化
sum_vecsZH(X_trainZH)
打印（all_summmed_vecs）

sum_vecsZH(y_trainZH)
打印（all_summmed_vecs）

sum_vecsZH(X_testZH)
打印（all_summmed_vecs）

sum_vecsZH(y_testZH)
打印（all_summmed_vecs）



最后 8 行的预期输出应与此类似：
33384
33384
14308
14308
这是我的数据集的照片：https://i.stack。 imgur.com/lJVJo.png
这个错误的原因是什么？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77596731/spacy-value-error-e1041-expected-a-string-doc-or-bytes-as-input-but-got</guid>
      <pubDate>Mon, 04 Dec 2023 00:59:14 GMT</pubDate>
    </item>
    <item>
      <title>如何修复我的感知器来识别数字？</title>
      <link>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</guid>
      <pubDate>Sun, 03 Dec 2023 14:03:49 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow JS学习数据太大，内存一次装不下，如何学习？</title>
      <link>https://stackoverflow.com/questions/76615356/tensorflow-js-learning-data-too-big-to-fit-in-memory-at-once-how-to-learn</link>
      <description><![CDATA[我遇到的问题是，我的数据集变得太大，无法立即装入内存。从所有数据条目中学习什么好的解决方案？我的数据来自mongodb实例，需要异步加载。
我尝试使用生成器函数，但还无法让异步生成器工作。我也在想也许可以批量地将模型拟合到数据上？
如果有人能为我提供一个关于如何适应通过批处理或数据库游标异步加载的数据的最小示例，那就太好了。
例如，当尝试从生成器返回承诺时，我收到打字稿错误。
 constgenerate = function* () {
        产生新的 Promise(() =&gt; {});
    };

    tf.data.generator(生成);

&#39;() =&gt; 类型的参数生成器，无效，未知&gt;&#39;不可分配给 &#39;() =&gt; 类型的参数迭代器 | Promise&gt;&#39;。
&lt;小时/&gt;
使用异步生成器也不起作用：
异步生成器导致类型错误
tf.data.generator(异步函数* () {})

抛出
&#39;() =&gt; 类型的参数AsyncGenerator&lt;任何、无效、未知&gt;&#39;不可分配给 &#39;() =&gt; 类型的参数迭代器 | Promise&gt;&#39;。]]></description>
      <guid>https://stackoverflow.com/questions/76615356/tensorflow-js-learning-data-too-big-to-fit-in-memory-at-once-how-to-learn</guid>
      <pubDate>Tue, 04 Jul 2023 19:15:23 GMT</pubDate>
    </item>
    <item>
      <title>SHAP中的Explainer和Kernelexplainer有什么区别？</title>
      <link>https://stackoverflow.com/questions/74251331/what-is-difference-between-explainer-and-kernelexplainer-in-shap</link>
      <description><![CDATA[我对可解释的人工智能很陌生。我开始研究 SHAP。当我查看代码时，我很困惑。该网站是 https:// /towardsdatascience.com/using-shap-v​​alues-to-explain-how-your-machine-learning-model-works-732b3f40e137
您可以看到下面的代码：
# 适合解释器
解释器 = shap.Explainer(model.predict, X_test)
# 计算 SHAP 值 - 需要一些时间
shap_values = 解释器(X_test)

另一个网站是 https://snyk.io/advisor/python /shap/functions/shap.KernelExplainer
您可以看到下面的代码：
 # 使用 Kernel SHAP 解释测试集预测
    解释器 = shap.KernelExplainer(svm.predict_proba, X_train, nsamples=100, link=“logit”)
    shap_values = 解释器.shap_values(X_test)

有什么区别？哪一个是真的？在第一个代码中，X_test 用于解释器。在第二个代码中，X_train 用于 kernelexplainer。为什么？]]></description>
      <guid>https://stackoverflow.com/questions/74251331/what-is-difference-between-explainer-and-kernelexplainer-in-shap</guid>
      <pubDate>Sun, 30 Oct 2022 07:48:03 GMT</pubDate>
    </item>
    <item>
      <title>训练+测试集是否必须与预测集不同（以便您需要对所有列应用时移）？ （没有时间序列！）[关闭]</title>
      <link>https://stackoverflow.com/questions/59210109/does-the-trainingtesting-set-have-to-be-different-from-the-predicting-set-so-t</link>
      <description><![CDATA[TLDR：
这个问题与经典的机器学习时间序列分析无关，而是试图将每月的列作为纯粹的特征来处理，就像任何永恒的特征一样。我分享了这个问题，因为我在工作中遇到了这个挑战，最后，该模型在这种设置下运行良好，将非每月（永恒）功能与每月功能混合在一起。因此，这只是一个使用每月数据列作为特征的问题，模型并不关心是12月还是6月，它只关心这些特征是过去多少个月，以便它从模式中学习大约 x 个月前的数据。这些特征不是按月份名称来命名的，而是按它们回溯到过去的月份来命名的，例如，reality_month_1、reality_month_2 表示回溯 1 或 2 个月的财富。
&lt;小时/&gt;
我知道我们应该仅在测试集上测试经过训练的分类器的一般规则。
但现在出现了问题：当我准备好经过训练和测试的分类器时，我可以将其应用到作为训练和测试集基础的同一数据集吗？&lt; /em&gt; 或者我是否必须将其应用于与训练+测试集不同的新预测集？
如果我预测时间序列的标签列怎么办（稍后编辑：我并不是想在这里创建经典的时间序列分析，而是只是从典型数据库中广泛选择列，每周、每月或随机存储的数据，我将其转换为单独的特征列，每个特征列为一周/一个月/一年...），我是否必须转移全部将训练+测试集的特征（不仅是时间序列标签列的过去列，还包括所有其他正常特征）设置回数据没有“知识”的时间点与预测集的拦截？
然后，我将根据过去 n 个月的特征来训练和测试分类器，针对未移动且最新的标签列进行评分，然后根据最近未移动的特征进行预测。移位和未移位的特征具有相同的列数，我通过将移位特征的列名称分配给未移位的特征来对齐移位和未移位的特征。
附注：
p.s.1：https://en.wikipedia.org/wiki/Dependent_and_independent_variables&lt;的一般方法/a&gt;
在数据挖掘工具（用于多元统计和机器学习）中，因变量被分配为目标变量（或在某些工具中为标签属性），而自变量可能被分配为常规变量。[ 8]为训练数据集和测试数据集提供了目标变量的已知值，但应对其他数据进行预测。
p.s.2：在这个基本教程中，我们可以看到预测集有所不同：https://scikit-learn.org/stable/tutorial/basic/tutorial.html
我们使用 [:-1] Python 语法选择训练集，它会生成一个包含所有 &gt; 的新数组。但digits.data 中的最后一项：[…] 现在您可以预测新值。在这种情况下，您将使用digits.data [-1:]中的最后一个图像进行预测。通过预测，您将从训练集中确定与最后一个图像最匹配的图像。]]></description>
      <guid>https://stackoverflow.com/questions/59210109/does-the-trainingtesting-set-have-to-be-different-from-the-predicting-set-so-t</guid>
      <pubDate>Fri, 06 Dec 2019 09:16:37 GMT</pubDate>
    </item>
    <item>
      <title>正则化参数在正则化中如何工作？</title>
      <link>https://stackoverflow.com/questions/44742122/how-does-regularization-parameter-work-in-regularization</link>
      <description><![CDATA[在机器学习成本函数中，如果我们想最小化两个参数（例如 theta3 和 theta4）的影响，似乎我们必须给出一个较大的正则化参数值，如下式所示。

我不太清楚为什么更大的正则化参数会减少而不是增加影响。这个功能是如何工作的？]]></description>
      <guid>https://stackoverflow.com/questions/44742122/how-does-regularization-parameter-work-in-regularization</guid>
      <pubDate>Sun, 25 Jun 2017 00:26:41 GMT</pubDate>
    </item>
    </channel>
</rss>