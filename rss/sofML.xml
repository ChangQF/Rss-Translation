<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sat, 12 Apr 2025 06:23:34 GMT</lastBuildDate>
    <item>
      <title>预测时TensorFlow给出了错误：输入形状的预期轴-1具有值2034，但以形状接收到输入（无，118336）</title>
      <link>https://stackoverflow.com/questions/79569631/tensorflow-gives-error-when-predicting-expected-axis-1-of-input-shape-to-have</link>
      <description><![CDATA[我一直在尝试创建一个可以识别图像的神经网络，但是当我尝试适合我的模型时，我会收到以下错误：
  valueerror：调用sequenty.call（）时遇到异常。 
输入0层“密度_82”与该层不兼容：预期轴-1 
具有值2304的输入形状，但以形状接收到输入（无，118336）
 
我正在通过合作构建它，我正在使用的代码如下：
 导入numpy作为NP
导入matplotlib.pyplot作为PLT
导入TensorFlow作为TF
来自tensorflow.keras.models导入顺序
来自tensorflow.keras.layers导入conv2d，maxpooling2d，扁平，密集
来自Tensorflow.keras.utils导入到_categorical

从Google.Colab Import Drive
从google.colab.patches导入cv2_imshow
drive.mount（&#39;/content/drive&#39;）


img_height = 180
img_width = 180

normalization_layer = tf.keras.layers.Rescaling（1./255）
normalized_ds = triending.map（lambda x，y ：（ a rustaranization_layer（x），y​​））

autotune = tf.data.autotune

训练=训练。
testing = testing.cache（）。prefetch（buffer_size = autotune）

num_classes = 9

模型=顺序（[
  conv2d（32，（3，3），激活=&#39;relu&#39;，input_shape =（32，32，3）），
  maxpooling2d（2，2），
  conv2d（64，（3，3），激活=&#39;relu&#39;），，
  maxpooling2d（2，2），
  flatten（），
  密集（128，激活=&#39;relu&#39;），
  密集（num_classes，激活=&#39;softmax&#39;）
）））

model.compile（优化器=&#39;adam&#39;，loss =&#39;apcorical_crossentropopy&#39;，量表= [&#39;准确性&#39;]）

model.summary（）

历史= model.fit（训练，batch_size = 64，epochs = 20，验证_data =测试）
 
训练和测试变量是使用创建的预取介台
  tf.keras.utils.image_dataset_from_directory
 
如何解决此错误。]]></description>
      <guid>https://stackoverflow.com/questions/79569631/tensorflow-gives-error-when-predicting-expected-axis-1-of-input-shape-to-have</guid>
      <pubDate>Fri, 11 Apr 2025 20:02:06 GMT</pubDate>
    </item>
    <item>
      <title>如何根据命名级别设计卷积神经网络[封闭]</title>
      <link>https://stackoverflow.com/questions/79569309/how-to-design-a-convolutional-neural-network-based-on-the-nomenclatural-rank</link>
      <description><![CDATA[我正在尝试弄清楚如何设计CNN结构，该体系结构可以使用其命名级别的等级对超过2,000种动物进行分类。这意味着我的模型将在分类层次结构的每个级别上预测图像的类别，从而逐渐缩小分类。例如，如果我有一张猫的图片，我的模型将首先将其分类为属于门的门，然后将其缩小到哺乳动物类，然后是食肉动物的顺序，依此类推，直到达到最终水平，即物种。我最初的想法是为每个级别创建多个CNN模型，但事实证明这很耗时。有人对我如何创建这种体系结构有任何想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79569309/how-to-design-a-convolutional-neural-network-based-on-the-nomenclatural-rank</guid>
      <pubDate>Fri, 11 Apr 2025 16:20:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使用随机森林来预测数据集中的空白？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79567319/how-do-i-use-a-random-forest-to-predict-gaps-in-a-dataset</link>
      <description><![CDATA[我有一个用来制作一个随机森林的数据集（分为测试和培训数据）。我已经做了随机的森林并产生了预测（下面的代码），但是我不知道如何进行这些预测并使用它们来生成一个完整的数据表，其中包含缝隙填充值。
  #DATA表头
时间戳＆lt;  -  c（2019-05-31 17：00：00：00：00 2019-05-31 17：30：00：00 2019-05-31 18：00：00：00：00：00：00：00：00：00：00：00 2019-05-31 18：00：30：00：00：00：00：00＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot 2019-05-31 19：30：00； 2019-05-31 20：00：00：00：00 2019-05-31 20：30：30：00 2019-05-05-05-31 21：00：00：00：00：00：00：00：00;
RH＆LT; -c（38、40、41、42、44、49、65、72、74、77）
FCH4＆lt;  -  C（0.045，-0.002，0.001，0.004，0，-0.013，0.004，-0.003，-0.001，-0.002）
距离＆lt;  -  c（1000,1000,180,125.35,1000,180,1000,5.50,180,1000）
ta＆lt; -c（29.52，29.01，29.04，28.39，27.87，26.68，23.28，21.16，19.95，19.01）
fe＆lt;  -  c（95.16，68.95，68.62，39.24，35.04，27.26，-2.60，5.09,7.28，2.08）

dd＆lt;  -  data.Frame（Timestamp，RH，FCH4，距离，TA，FE）

＃制造RF和预测
set.seed（1）
Intraining＆lt;  -  CreateTataPartition（DD $ FCH4，P = 0.65，List = false）
训练＆lt;  -  dd [intraining，]
测试＆lt;  -  dd [ -  intraining，]

set.seed（1）
pfpfit＆lt;  -  Randomforest（FCH4〜。，训练，NTREE = 500，type =＆quot&#39;回归＆quot;）
预测＆lt;  - 预测（pfpfit，newdata =测试）
 
因此，对于上述代码，我有预测模型，但是我不知道如何将其应用于我已经拥有差距的数据集（下面）。我也不知道在变量中差距不是我要差距填充的变量（我想差距填充FCH4）是否有问题，但是我也有FE和TA的空白）。
我想差距填充数据集的一个示例如下：
  #DATA表头
    时间戳＆lt;  -  c（2019-05-31 17：00：00：00：00 2019-05-31 17：30：00：00 2019-05-31 18：00：00：00：00：00：00：00：00：00：00：00 2019-05-31 18：00：30：00：00：00：00：00＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot 2019-05-31 19：30：00； 2019-05-31 20：00：00：00：00 2019-05-31 20：30：30：00 2019-05-05-05-31 21：00：00：00：00：00：00：00：00;
    RH＆LT; -c（38、40、41、42、44、49、65、72、74、77）
    FCH4＆lt; -c（Na，-0.002，0.001，0.004，Na，-0.013，0.004，Na，-0.001，-0.002）
    距离＆lt;  -  c（1000,1000,180,125.35,1000,180,1000,5.50,180,1000）
    ta＆lt; -c（29.52，29.01，NA，28.39，27.87，26.68，23.28，NA，19.95，19.01）
    fe＆lt; -c（Na，Na，68.62，39.24，35.04，27.26，-2.60，Na，7.28，2.08）
dd＆lt;  -  data.Frame（Timestamp，RH，FCH4，距离，TA，FE）
 
我希望填充的数据集看起来像这样：
  #DATA表头
    时间戳＆lt;  -  c（2019-05-31 17：00：00：00：00 2019-05-31 17：30：00：00 2019-05-31 18：00：00：00：00：00：00：00：00：00：00：00 2019-05-31 18：00：30：00：00：00：00：00＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quot 2019-05-31 19：30：00； 2019-05-31 20：00：00：00：00 2019-05-31 20：30：30：00 2019-05-05-05-31 21：00：00：00：00：00：00：00：00;
    RH＆LT; -c（38、40、41、42、44、49、65、72、74、77）
    FCH4＆lt;  -  C（0.045，-0.002，0.001，0.004，0，-0.013，0.004，-0.003，-0.001，-0.002）
    距离＆lt;  -  c（1000,1000,180,125.35,1000,180,1000,5.50,180,1000）
    ta＆lt; -c（29.52，29.01，29.04，28.39，27.87，26.68，23.28，21.16，19.95，19.01）
    fe＆lt;  -  c（95.16，68.95，68.62，39.24，35.04，27.26，-2.60，5.09,7.28，2.08）
dd＆lt;  -  data.Frame（Timestamp，RH，FCH4，距离，TA，FE）
 
（我意识到这三个数据集大多是相同的，并且您不应该在与培训数据相同的数据上测试。这仅仅是为了使某些内容运行。我可以自己完善它。））]]></description>
      <guid>https://stackoverflow.com/questions/79567319/how-do-i-use-a-random-forest-to-predict-gaps-in-a-dataset</guid>
      <pubDate>Thu, 10 Apr 2025 18:12:26 GMT</pubDate>
    </item>
    <item>
      <title>如何将不同长度的多视图特征融合以进行关系提取（例如，生物Biobert +其他功能）？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79567194/how-to-fuse-multi-view-features-of-different-lengths-for-relation-extraction-e</link>
      <description><![CDATA[我正在研究一项关系提取任务，特别是药物 - 药物相互作用（DDI）提取。我从多个功能来源提取了嵌入：

  biobert嵌入式（令牌级，可变长度取决于句子）

 其他功能（例如，POS标签，依赖关系路径或N-gram功能），其长度可能与Biobert输出不同。


我尝试了一种简单的技术，在汇总生物伯特和其他功能之后，我只是串联了这些功能。然后，我将合并的向量传递给多层感知器（MLP）进行分类，但并不能提高性能。
我相信这可能是由于不正确的对准或融合策略不佳所致。
我的问题是：从不同视图（和长度）中融合功能的某些常见或最佳实践技术以进行此类关系提取任务？]]></description>
      <guid>https://stackoverflow.com/questions/79567194/how-to-fuse-multi-view-features-of-different-lengths-for-relation-extraction-e</guid>
      <pubDate>Thu, 10 Apr 2025 16:43:17 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个数据集和配对的自上而下的图像，用于分割可用的土地以进行施工？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79566478/is-there-a-dataset-with-paired-top-down-images-for-segmenting-available-land-for</link>
      <description><![CDATA[我正在寻找一个免费的开源数据集，可以下载该数据集以进行细分任务。具体来说，我想检测到没有建筑物或道路的顶视图像中的区域。
目的是测量我们将来可以建造建筑物的可用区域。诸如Inria航空图像标签数据集和空间等数据集对我无济于事，因为它们专注于检测建筑物，这不是我的目标。
 以下是我要实现的视觉示例。  ]]></description>
      <guid>https://stackoverflow.com/questions/79566478/is-there-a-dataset-with-paired-top-down-images-for-segmenting-available-land-for</guid>
      <pubDate>Thu, 10 Apr 2025 11:15:56 GMT</pubDate>
    </item>
    <item>
      <title>我刚刚训练，使用keras image_from_dataset训练的事实会影响我的指标</title>
      <link>https://stackoverflow.com/questions/79566385/does-the-fact-that-i-have-just-train-test-split-using-keras-image-from-dataset</link>
      <description><![CDATA[我一直在试图弄清楚为什么训练后我的指标很低。我的F1得分为75％，这根本不是我所期望的。我审查了代码，我怀疑问题是火车，验证拆分，但我正在评估验证集的模型 y_pred =（model.predict（val_ds）＆gt; 0.5）.astype（int）（int）。我阅读了KERAS文档，以查看我是否犯了错误，或者是否有办法将数据集拆分为火车，验证，测试拆分，但我找不到任何可能指出是否犯错的东西。这是我的代码：
 将TensorFlow导入为TF
来自Tensorflow.keras.applications导入Densenet169
来自tensorflow.keras.layers导入密集，globalaveration -pooling2d，Randomflip，RandomRotation，辍学
来自Tensorflow.keras.models导入模型，顺序
来自Tensorflow.keras.optimizer导入Adam
从tensorflow.keras.regulinizer导入l2
来自tensorflow.keras.applications.densenet导入preprocess_input
来自sklearn.metrics导入混淆_matrix，f1_score
导入numpy作为NP

＃定义常数
img_size =（224，224）＃匹配densenet169输入大小
batch_size = 32
时代= 15
data_dir =＆quot; colon_images＆quot;
class_names = [＆quast; cancyous&#39;&#39;正常＆quot;]
split_ratio = 0.2

＃直接加载数据集在224x224
def create_dataset（子集）：
    返回tf.keras.utils.image_dataset_from_directory（
        data_dir，
        验证_split = split_ratio，
        子集=子集
        种子= 42，
        image_size = img_size，＃直接以目标大小加载
        batch_size = batch_size，
        label_mode =&#39;binary&#39;
    ）

train_ds = create_dataset（“训练”）
val_ds = create_dataset（&#39;验证＆quot;）

＃通过增强进行预处理（仅在培训期间活跃）
预处理=顺序（[
    Randomflip（“水平”，“），
    随机旋转（0.1），
    tf.keras.layers.lambda（preprocess_input）＃正确归一化
）））

＃构建模型
base_model = densenet169（
    权重=&#39;Imagenet&#39;，
    include_top = false，
    input_shape = img_size +（3，）
）

输入= tf.keras.input（shape = img_size +（3，））
X =预处理（输入）
x = base_model（x）
x = globalaveragepooling2d（）（x）
x =密集（512，激活=&#39;relu&#39;，kernel_regularizer = l2（0.01））（x）
x =辍学（0.5）（x）＃正则化
输出=密集（1，激活=&#39;Sigmoid&#39;）（x）
模型=模型（输入，输出）

＃阶段1：火车顶层
base_model.trainable = false
model.compile（
    优化器= ADAM（1E-3），
    损失=&#39;binary_crossentropy&#39;，
    量表= [&#39;fecycy&#39;，tf.keras.metrics.auc（name =&#39;auc&#39;），
             tf.keras.metrics.precision（name =&#39;precision&#39;），
             tf.keras.metrics.Recall（name =&#39;recember&#39;）]
）

＃用回调监视AUC的火车
早期_stop = tf.keras.callbacks.earlystopping（
    Monitor =&#39;Val_auc&#39;，耐心= 3，模式=&#39;max&#39;，详细= 1
）
检查点= tf.keras.callbacks.modelcheckpoint（
    &#39;best_model.h5&#39;，save_best_only = true，monitor =&#39;val_auc&#39;，mode =&#39;max&#39;
）

历史= model.fit（
    train_ds，
    验证_data = val_ds，
    时代= epochs，
    回调= [早期_STOP，检查点]
）

＃阶段2：微调整个模型
base_model.trainable = true
model.compile（
    优化器= ADAM（1E-5），＃非常低的学习率
    损失=&#39;binary_crossentropy&#39;，
    量表= [&#39;facer&#39;，tf.keras.metrics.auc（name =&#39;auc&#39;）]
）

history_fine = model.fit（fit）（
    train_ds，
    验证_data = val_ds，
    时代= epochs，
    onirome_epoch = history.epoch [-1]，
    回调= [早期_STOP，检查点]
）

＃ 评估
y_pred =（model.predict（val_ds）＆gt; 0.5）.astype（int）
y_true = np.concatenate（[y for _，y in val_ds]，axis = 0）

打印（f＆quot f1分数：{f1_score（y_true，y_pred）：。3f}＆quot;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79566385/does-the-fact-that-i-have-just-train-test-split-using-keras-image-from-dataset</guid>
      <pubDate>Thu, 10 Apr 2025 10:29:08 GMT</pubDate>
    </item>
    <item>
      <title>生成partialdependedateata函数在用于多类分类模型时返回错误</title>
      <link>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</link>
      <description><![CDATA[我已经使用MLR构建了XGBoost多类分类模型，我想为某些功能可视化部分依赖性。但是，如果我尝试使用 generatePartialDependedAta（）我会收到以下错误：

 Melt.data.table中的错误（AS.Data.table（OUT），MEATH.VARS = target，variable.name = if（td $ type ===：&#39;METAY.VARS&#39;中的一个或多个值无效。

我已经检查了 task.desc 在 task&gt; task 对象和 factor.levels.levels.levels 中的差异。此外，我毫不费力地使用相同的函数生成具有不同目标变量的回归XGBoost的数据。
我的目的是有问题，还是这是一个错误？
这是使用 palmerpenguins 数据集的示例：
 ＃库
图书馆（整洁）
图书馆（Caret）
图书馆（MLR）

Peng＆lt;  -  Palmerpenguins ::企鹅

＃数据分区
set.seed（1234）
Intrain＆lt ;-创建Atapartition（
  y =彭$种，
  p = 0.7，
  列表= f
）

＃构建任务
train_class＆lt;  -  peng [intrain，]％＆gt;％select（-sex，-year）％＆gt;％ 
  CreateMummyFeatures（target =;物种＆quots; cols =;岛; 
  makeClassIftask（data =。，target =;物种；）

＃建立学习者
xgb_class_learner＆lt;  -  makelearner（
  ＆quot“ classif.xgboost”
  predict.type =&#39;响应;
）

＃构建模型
XGB_CLASS＆lt;  - 火车（XGB_CLASS_LEARNER，TRAIN_CLASS）

＃产生部分依赖性
GeneratePartialDependedateData（XGB_Class，Train_class）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</guid>
      <pubDate>Mon, 10 Mar 2025 18:27:01 GMT</pubDate>
    </item>
    <item>
      <title>批发归一化，是还是否？</title>
      <link>https://stackoverflow.com/questions/58612783/batch-normalization-yes-or-no</link>
      <description><![CDATA[我使用TensorFlow 1.14.0和Keras 2.2.4。以下代码实现了一个简单的神经网络：
 导入numpy作为NP
np.random.seed（1）
导入随机
随机。种子（2）
导入TensorFlow作为TF
tf.set_random_seed（3）

来自Tensorflow.keras.models导入模型，顺序
来自tensorflow.keras.layers导入输入，密集，激活


x_train = np.random.normal（0,1，（100,12））

型号=顺序（）
ADD（密集（8，Input_Shape =（12，））））
＃model.add（tf.keras.layers.batchnormalization（））
ADD（激活（&#39;Linear&#39;））
型号（密集（12））
ADD（激活（&#39;Linear&#39;））
model.compile（优化器=&#39;adam&#39;，loss =&#39;mean_squared_error&#39;）
model.fit（x_train，x_train，epochs = 20，验证_split = 0.1，shuffle = false，derbose = 2）
 
 20个时期后的最终val_loss为0.7751。当我删除添加批处理标准化层的唯一评论行时，val_loss更改为1.1230。
我的主要问题更为复杂，但是发生同样的事情。由于我的激活是线性的，因此是否在激活之后或之前将批处理归一化都无关紧要。 
 问题：为什么批处理归一化无济于事？我有什么可以更改的，以便批处理归一化可以改善结果而不更改激活功能？
 发表评论后更新： 
一个带有一个隐藏层和线性激活的NN有点像PCA。有很多论文。对我来说，此设置在隐藏层和输出的激活函数的所有组合中给出了最小的MSE。
一些陈述线性激活的资源是指PCA：
  https://arxiv.org/pdf/pdf/1702.07800.pdf    
   https：////www.quora.com/www.quora.com/www.quora.com/www.quora/]]></description>
      <guid>https://stackoverflow.com/questions/58612783/batch-normalization-yes-or-no</guid>
      <pubDate>Tue, 29 Oct 2019 17:38:38 GMT</pubDate>
    </item>
    <item>
      <title>如何使用XGBOOST中的每个班级中的每个班级的特征重要性？</title>
      <link>https://stackoverflow.com/questions/58603632/how-to-get-feature-importance-for-each-class-in-mutliclass-classification-with-x</link>
      <description><![CDATA[我有6种不同的类，我正在使用XGBoost和Randomforest进行多类分类。
我想要的是分析哪些功能对于属于每个类的样本最重要。
我知道使用XGBoost有两种不同的方法来获得该功能的重要性。首先，内置的 feature_importances _ 变量返回具有所有功能的重要性得分的数组。 
另一种方法是从xgboost导入plot_importance ，您可以使用来提供绘图

  plot_importance（model = xgb，max_num_features = 20）
 
但是所有这些方法仅返回最重要的功能，而无需尊重类。 
有没有办法获得属于每个类的样本的最重要功能？
或解决方案是创建6种不同的二进制分类器并尝试分析这些特征重要性？]]></description>
      <guid>https://stackoverflow.com/questions/58603632/how-to-get-feature-importance-for-each-class-in-mutliclass-classification-with-x</guid>
      <pubDate>Tue, 29 Oct 2019 08:25:17 GMT</pubDate>
    </item>
    <item>
      <title>何时需要替换实体提取？</title>
      <link>https://stackoverflow.com/questions/52580818/when-is-entity-replacement-necessary-for-relation-extraction</link>
      <description><![CDATA[在此中作者确实更换实体，因为“我们不希望模型根据特定实体名称学习，但我们希望它根据文本的结构学习”。
这通常是正确的，还是取决于数据集或使用的模型？]]></description>
      <guid>https://stackoverflow.com/questions/52580818/when-is-entity-replacement-necessary-for-relation-extraction</guid>
      <pubDate>Sun, 30 Sep 2018 18:22:13 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们需要时代？</title>
      <link>https://stackoverflow.com/questions/42716181/why-do-we-need-epochs</link>
      <description><![CDATA[在课程中没有任何关于时代的信息，但实际上它们无处不在。
如果优化器在一次通过中找到最佳的重量，为什么我们需要它们。为什么该模型改进？]]></description>
      <guid>https://stackoverflow.com/questions/42716181/why-do-we-need-epochs</guid>
      <pubDate>Fri, 10 Mar 2017 10:33:20 GMT</pubDate>
    </item>
    <item>
      <title>分类和聚类的特征之间的关系[封闭]</title>
      <link>https://stackoverflow.com/questions/42172920/relation-between-features-for-classification-and-clustering</link>
      <description><![CDATA[假设我已经对某些数据实现了分类算法，并确认了分类算法的最佳功能组合。如果有一天我从同一资源中获取数据，而这些数据缺乏以前的分类任务中的目标功能，我可以将功能的最佳组合直接用于聚类任务吗？ （我知道我可以使用我训练的模型来预测数据的目标，但是我只想知道分类和聚类算法之间的最佳功能组合是否相同）
我已经搜索了网站和我所知道的任何资源，但是我找不到问题的答案。有人可以告诉我还是只是给我一个链接？]]></description>
      <guid>https://stackoverflow.com/questions/42172920/relation-between-features-for-classification-and-clustering</guid>
      <pubDate>Sat, 11 Feb 2017 06:13:45 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络中的分批归一化[封闭]</title>
      <link>https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network</link>
      <description><![CDATA[我想知道有关在CNN中应用批处理标准化的一些细节。
I read this paper https://arxiv.org/pdf/1502.03167v3.pdf and could understand the BN algorithm applied on a data but in the end they mentioned that a将应用于CNN时需要轻微的修改：

对于卷积层，我们还希望归一化遵守卷积特性 - 以便以相同的方式将同一特征图的不同元素（在不同位置）进行标准化。为了实现这一目标，我们将所有位置的小批次中的所有激活共同标准化。在alg。 1，我们让b是小批量和空间位置的两个元素的特征映射中的所有值集 - 因此，对于MINI尺寸m和大小p×Q的特征映射，我们使用尺寸m&#39;= | b |的有效的小批量的小批量。 = M·Pq。我们每个特征图学习一对参数γ（k）和β（k），而不是每个激活。 alg。 2进行了类似的修改，因此在推断中，BN转换在给定特征映射中适用于每个激活的相同线性变换。

当他们说时，我完全感到困惑

使得在不同位置的同一特征图的不同元素以相同的方式归一化

我知道特征映射的含义，不同的元素是每个功能映射中的权重。但是我不明白位置或空间位置的含义。
我根本无法理解以下句子：

在ALG中。 1，我们让b为小批次和空间位置的两个元素的元素中的特征图中的所有值集

有人可以在更简单的任期内详细说明我吗？]]></description>
      <guid>https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network</guid>
      <pubDate>Sun, 24 Jul 2016 15:54:58 GMT</pubDate>
    </item>
    <item>
      <title>理解RandomForestRegressor中的Max_features参数</title>
      <link>https://stackoverflow.com/questions/23939750/understanding-max-features-parameter-in-randomforestregressor</link>
      <description><![CDATA[使用自举样品在随机森林中构造每个树时，对于每个终端节点，我们从P变量中随机选择M变量以找到最佳的拆分（P是数据中的特征总数）。我的问题（对于RandomForestRegressor）是：
 1）max_features与（m或p或其他东西）相对应的是什么？
 2）是否从max_features变量随机选择M变量（m的值是多少）？
 3）如果max_features对应于M，那么为什么我要将其设置为回归（默认）的P等于P（默认值）？这种设置的随机性在哪里（即，它与包装有何不同）？
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/23939750/understanding-max-features-parameter-in-randomforestregressor</guid>
      <pubDate>Thu, 29 May 2014 17:52:56 GMT</pubDate>
    </item>
    <item>
      <title>使用翻转图像进行机器学习数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/11780650/using-flipped-images-for-machine-learning-dataset</link>
      <description><![CDATA[我有一个二进制分类问题。我正在尝试训练神经网络以识别图像的对象。目前，我大约有1500个50x50图像。
问题是，通过水平翻转相同图像设置的我目前的训练是否是个好主意？ （图像不是对称的）]]></description>
      <guid>https://stackoverflow.com/questions/11780650/using-flipped-images-for-machine-learning-dataset</guid>
      <pubDate>Thu, 02 Aug 2012 15:16:47 GMT</pubDate>
    </item>
    </channel>
</rss>