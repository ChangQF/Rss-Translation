<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 18 Dec 2023 12:26:18 GMT</lastBuildDate>
    <item>
      <title>使用YOLOv5旧模型进行预测</title>
      <link>https://stackoverflow.com/questions/77678969/using-yolov5-old-models-to-make-a-prediction</link>
      <description><![CDATA[我目前正在尝试使用 .pt 文件作为 YOLOv5 模型，该模型是在 2 年前训练的，每当我尝试这样做时，我都会收到以下错误。
运行时错误：PytorchStreamReader 读取 zip 存档失败：找不到中心目录。
每次我尝试使用不同的 model.pt 文件时，它都会下载最新版本（例如：yolov5mu.pt）。
我在 VSCode 和 anaconda 提示符下运行类似的命令：
yolo 检测预测模型=yolov5/yolov5m.pt source=&#39;datasets\Testing_images\20210823_112536.jpg&#39;，在 VSCode 上。
yolo task=detect mode=predict model=ganuza.pt source=&#39;test1.jpg&#39; show=True，在 anaconda 提示符下。
我按照教程进行操作，文件夹组织看起来不错。如果我使用另一种模型（例如它下载的模型），它就可以正常工作。
有谁知道发生了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/77678969/using-yolov5-old-models-to-make-a-prediction</guid>
      <pubDate>Mon, 18 Dec 2023 12:06:31 GMT</pubDate>
    </item>
    <item>
      <title>将问题标记为简单、中等和困难 [关闭]</title>
      <link>https://stackoverflow.com/questions/77678858/labelling-questions-as-easy-medium-and-hard</link>
      <description><![CDATA[我目前正在从事一个机器学习项目，专注于开发问题标签模型。 挑战在于确定如何将问题分类为“简单”、“中等”或“困难”。更具体地说，我正在寻求有关哪些指标可以准确确定问题难度级别的指导简单、中等或困难。如果有人有机器学习经验，我们将不胜感激您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77678858/labelling-questions-as-easy-medium-and-hard</guid>
      <pubDate>Mon, 18 Dec 2023 11:44:50 GMT</pubDate>
    </item>
    <item>
      <title>将变量从一个模块导入到另一个模块</title>
      <link>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</guid>
      <pubDate>Mon, 18 Dec 2023 10:44:18 GMT</pubDate>
    </item>
    <item>
      <title>模型评估中端到端 MLops 项目出现错误</title>
      <link>https://stackoverflow.com/questions/77678457/error-on-end-to-end-mlops-project-in-model-evaluation</link>
      <description><![CDATA[我正在遵循端到端 MLOPS 数据科学项目实施与部署中显示的流程 在 Krish Naik 的频道上。
我在 05_model_evaluation 上运行此模型评估管道单元.ipynb
&lt;前&gt;&lt;代码&gt;尝试：
    配置=配置管理器()
    model_evaluation_config = config.get_model_evaluation_config()
    model_evaluation_config = ModelEvaluation(config=model_evaluation_config)
    model_evaluation_config.log_into_mlflow()
除了异常 e：
    提高e

我收到此错误：
FileNotFoundError: [Errno 2] 没有这样的文件或目录: &#39;config\\config.yaml&#39;

这是回溯：
FileNotFoundError Traceback（最近一次调用最后一次）
c:\Users\HP\Desktop\livesitter demo\MLops\research\05_model_evaluation.ipynb 单元格 11 第 7 行
      5 model_evaluation_config.log_into_mlflow()
      6 除了异常 e：
----&gt; 7 提高 e

c:\Users\HP\Desktop\livesitter demo\MLops\research\05_model_evaluation.ipynb 单元 11 第 2 行
      1 次尝试：
----&gt; 2 配置=配置管理器（）
      3 model_evaluation_config = config.get_model_evaluation_config()
      4 model_evaluation_config = ModelEvaluation(config=model_evaluation_config)

c:\Users\HP\Desktop\livesitter demo\MLops\research\05_model_evaluation.ipynb 单元 11 第 8 行
      2 def __init__（
      3 自我,
      4 config_filepath = CONFIG_FILE_PATH,
      5 params_filepath = PARAMS_FILE_PATH,
      6 schema_filepath = SCHEMA_FILE_PATH):
----&gt; 8 self.config = read_yaml(config_filepath)
      9 self.params = read_yaml(params_filepath)
     10 self.schema = read_yaml(schema_filepath)

文件 c:\Users\HP\AppData\Local\Programs\Python\Python311\Lib\site-packages\ensure\main.py:849，在 WrappedFunctionReturn.__call__(self, *args, **kwargs)
    第841章
...
---&gt; 29 将 open(path_to_yaml) 作为 yaml_file：
     30 内容 = yaml.safe_load(yaml_file)
     31 logger.info(f&quot;yaml 文件: {path_to_yaml} 加载成功&quot;)

FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;config\\config.yaml&#39;
输出被截断。作为可滚动元素查看或在文本编辑器中打开。调整单元格输出设置...
]]></description>
      <guid>https://stackoverflow.com/questions/77678457/error-on-end-to-end-mlops-project-in-model-evaluation</guid>
      <pubDate>Mon, 18 Dec 2023 10:29:06 GMT</pubDate>
    </item>
    <item>
      <title>LLava AI 在本地主机上运行 - 说 {"detail":"Not Found"}</title>
      <link>https://stackoverflow.com/questions/77678285/llava-ai-running-on-localhost-says-detailnot-found</link>
      <description><![CDATA[我克隆了这个项目https://github.com/haotian-liu/LLaVA ，并尝试让它运行。
但是，我在本地主机上收到的唯一消息是此窗口显示 {“detail”：“Not Found”}

我已正确安装最新的 CUDA 驱动程序（GPU 可与 PrivateGPT 配合使用），并确保我已在 conda 中激活 llava 环境。
这里是分别运行的控制器、Gradio Web 服务器和模型：
控制器：

广播：

型号：

什么可能导致此问题？]]></description>
      <guid>https://stackoverflow.com/questions/77678285/llava-ai-running-on-localhost-says-detailnot-found</guid>
      <pubDate>Mon, 18 Dec 2023 10:00:59 GMT</pubDate>
    </item>
    <item>
      <title>分割模型推理延迟问题</title>
      <link>https://stackoverflow.com/questions/77678168/segmentation-model-inference-latency-issue</link>
      <description><![CDATA[我使用了 pyannote 的开源分割模型和 Diart diarization 的说话者二值化存储库，使用 diart==0.5.1，
在 diart/blocks/segmentation.py 中，我进行了以下更改::
 与 torch.no_grad()：
        wave=rearrange(self.formatter.cast(waveform),“批量采样通道-&gt;批量通道采样”)
        # 波火炬.Tensor (1, 1, 80000)
        打印（wave.get_device（））
        开始 = 时间.time()
        输出 = self.model(wave.to(self.device)).cpu()
        停止=时间.time()
        print(&#39;分段时间:&#39;)
        打印（停止-开始）
        # 输出：torch.Tensor (1, 293, 3)
    返回 self.formatter.restore_type(输出)

在输出中，seg timeL 0.4s
但是如果我尝试在 diart 存储库之外进行推断（在独立的存储库中）：
defegmentation_model(self,batch:np.ndarray) -&gt;; np.ndarray：
    块 = torch.tensor(batch)
    print(chunks.get_device()) # -1

    使用 torch.no_grad()：
        尝试：
            打印（块.形状）
            输出 = self.model(chunks.to(self.device)).cpu()
        除了 RuntimeError 作为例外：
            如果 is_oom_error（异常）：
                引发内存错误（
                    f&quot;batch_size ({self.batch_size: d}) 可能太大。 ”
                    f“尝试使用较小的值，直到内存错误消失。”
                ）
            别的：
                引发异常

    返回输出.numpy()

此处分段时间：10s
资源、输入格式、形状、类型一切都是相同的
为什么延迟不同？
期望延迟相同]]></description>
      <guid>https://stackoverflow.com/questions/77678168/segmentation-model-inference-latency-issue</guid>
      <pubDate>Mon, 18 Dec 2023 09:38:17 GMT</pubDate>
    </item>
    <item>
      <title>运行 fmri 深度学习模型时出现错误</title>
      <link>https://stackoverflow.com/questions/77677389/getting-error-while-running-fmri-deep-learning-model</link>
      <description><![CDATA[我正在处理 fmri 数据，我有两组数据集疾病和正常数据的形状是正常数据形状：(91, 109, 91, 1200)
疾病数据形状：(91, 109, 91, 210)
我已经写了Python脚本
 将 numpy 导入为 np
将 nibabel 导入为 nib
从 sklearn.model_selection 导入 train_test_split
从 keras.models 导入顺序
从 keras.layers 导入 Conv3D、MaxPooling3D、Flatten、Dense
从 keras.optimizers 导入 Adam
从 keras.layers 导入密集、激活、Dropout、Flatten、Conv3D、MaxPooling3D

# 定义正常和疾病数据文件夹的路径
疾病数据路径 = glob(&#39;/media/aish/Backup Plus1/ABIDE/scan_data001/**/**/**/**/**/**/**/**/swa*&#39;)
Normal_data_path = glob(&#39;/media/aish/rs2/hcp/s*&#39;)

# 加载正常和疾病数据
正常数据 = []
疾病数据 = []
对于normal_data_path[0:400]中的文件：
    Normal_data.append(nib.load(file).get_data())
对于疾病数据路径中的文件：
    疾病数据.append(nib.load(文件).get_data())

    
    
print(“正常数据形状：”, normal_data[1].shape)
print(“疾病数据形状：”,疾病数据[1].shape)



# 创建标签
标签 = np.concatenate((np.zeros(len(normal_data)), np.ones(len(disease_data))))

# 将数据分为训练集和测试集
X_train，X_test，y_train，y_test = train_test_split（np.array（正常数据+疾病数据），标签，test_size = 0.2，random_state = 42）

# 定义CNN模型
模型=顺序（）
model.add(Conv3D(32, (3, 3, 3), 激活=&#39;relu&#39;, input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)))
模型.add(MaxPooling3D((2,2,2)))
model.add(Conv3D(64, (3, 3, 3), 激活=&#39;relu&#39;))
模型.add(MaxPooling3D((2,2,2)))
模型.add(压平())
model.add（密集（128，激活=&#39;relu&#39;））
model.add（密集（2，激活=&#39;softmax&#39;））

# 编译模型
model.compile(优化器=Adam(lr=0.001)，损失=&#39;sparse_categorical_crossentropy&#39;，指标=[&#39;准确性&#39;])

# 训练模型
model.fit(X_train, y_train, epochs=10)

# 评估模型
model.evaluate(X_test, y_test)

# 保存模型
model.save(&#39;fmri_model.h5&#39;)

但是我收到错误
完整错误是
ValueError Traceback（最近一次调用最后一次）
[7]，第 32 行中的单元格
     29 个标签 = np.concatenate((np.zeros(len(normal_data)), np.ones(len(disease_data))))
     31 # 将数据分为训练集和测试集
---&gt; 32 X_train，X_test，y_train，y_test = train_test_split（np.array（正常数据+疾病数据），标签，test_size = 0.2，random_state = 42）
     34 # 定义CNN模型
     35 模型 = 顺序()

ValueError：无法将输入数组从形状 (91,109,91,1200) 广播到形状 (91,109,91)

我无法解决此错误]]></description>
      <guid>https://stackoverflow.com/questions/77677389/getting-error-while-running-fmri-deep-learning-model</guid>
      <pubDate>Mon, 18 Dec 2023 06:53:58 GMT</pubDate>
    </item>
    <item>
      <title>如何避免非终端深度 Q 学习中每个动作的无限变化</title>
      <link>https://stackoverflow.com/questions/77676680/how-to-avoid-infinite-changes-per-action-in-non-terminal-deep-q-learning</link>
      <description><![CDATA[据我所知，梯度下降的 Deep Q 学习遵循以下过程：

初始化随机权重和偏差

从起始状态开始执行操作

确定奖励

通过梯度下降根据当前时间步长更改权重和偏差

通过梯度下降根据之前的时间步长来更改权重和偏差，但使用奖励 * 折扣因子 ^ 步数而不仅仅是奖励。

重复第 2 步


在无限的时间段内，这应该导致每一步都会导致权重和偏差发生变化，目标是梯度下降的当前奖励+预期未来回报*折扣因子，与贝尔曼匹配方程。然而，根据这种方法，在每个步骤中，我们需要进行与包含该步骤及其之前的每个步骤相同的更改量。在深度 Q 学习的非终结情况下，（据我所知）这应该会导致无限量的所需处理时间。
在我目前的案例中，我正在尝试在恐龙游戏上运行深度 Q 学习，并且假设恐龙可能永远不会死亡，因此可能会导致上述问题。
当折扣因子^步骤低于某个阈值时，潜在的解决方案可能只是简单地舍入为0，或者在某个点任意终止情节并重新开始，但这两种解决方案都没有似乎不完全正确。
Atari DQN 研究论文
在 Atari 论文中，他们似乎使用有限的内存大小来保存所需的所有状态，然后仅随机选择一个状态来执行梯度下降。这是正确的解释吗？这可能是我面临的问题的解决方案吗？还有其他可能的解决方案吗？
编辑：
看来我们的梯度下降标签是立即奖励+未来回报，但我们不是通过继续玩这一集来寻找未来回报，而是使用当前的 Q 函数估计来寻找未来返回。这似乎仍然有点违反直觉，因为我们部分地使用自己的函数作为梯度下降的目标，但即时奖励的知识似乎使函数收敛于解决方案。
来源：
https://youtu.be/rFwQDDbYTm4?t=1394]]></description>
      <guid>https://stackoverflow.com/questions/77676680/how-to-avoid-infinite-changes-per-action-in-non-terminal-deep-q-learning</guid>
      <pubDate>Mon, 18 Dec 2023 02:35:47 GMT</pubDate>
    </item>
    <item>
      <title>在电脑上训练我的模型，然后在微控制器上使用它[关闭]</title>
      <link>https://stackoverflow.com/questions/77675723/train-my-model-on-pc-then-use-it-on-microcontroller</link>
      <description><![CDATA[如果我想在我的 PC 上训练一个模型（无论是 ML、NN 还是 CNN），因为我有强大的 GPU，是否可以在 Arduino 或 Raspberry Pi Pico 等微控制器上导出或保存这个训练模型以直接使用它？或者我需要从头开始重新训练这些模型？]]></description>
      <guid>https://stackoverflow.com/questions/77675723/train-my-model-on-pc-then-use-it-on-microcontroller</guid>
      <pubDate>Sun, 17 Dec 2023 19:33:23 GMT</pubDate>
    </item>
    <item>
      <title>根据新数据训练 NLP 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/77674787/training-nlp-model-on-new-data</link>
      <description><![CDATA[我正在开发一个 NLP 模型（使用 LSTM），该模型接收文本句子（例如谷歌地图评论）并预测星级评分。
我掌握了拥有超过 600 万条评论的 yelp 数据集，我正在用它来训练我的模型。数据集太大，导致我分批训练模型（10K 批审核）。
假设我完成了训练并且取得了合理的表现。随后，Yelp 发布了 100 万条新评论。如何在新数据上训练模型？
1- 我应该仅根据新数据训练模型吗？
或者
2- 将新数据与旧数据结合并重新训练模型？
3-如何避免灾难性遗忘？]]></description>
      <guid>https://stackoverflow.com/questions/77674787/training-nlp-model-on-new-data</guid>
      <pubDate>Sun, 17 Dec 2023 14:36:08 GMT</pubDate>
    </item>
    <item>
      <title>端到端 ML 项目的模型训练器问题 - TypeError：initiate_model_training() 缺少 4 个必需的位置参数</title>
      <link>https://stackoverflow.com/questions/77673255/model-trainer-issue-on-end-to-end-ml-project-typeerror-initiate-model-trainin</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673255/model-trainer-issue-on-end-to-end-ml-project-typeerror-initiate-model-trainin</guid>
      <pubDate>Sun, 17 Dec 2023 03:50:40 GMT</pubDate>
    </item>
    <item>
      <title>不使用 OpenAI Gym 环境的近端策略优化代码 [关闭]</title>
      <link>https://stackoverflow.com/questions/77641484/proximal-policy-optimization-code-without-using-openai-gym-environments</link>
      <description><![CDATA[我必须在 Python 中对使用在线物理系统收集的数据实施近端策略优化。我见过的所有示例都使用 OpenAI 的 Gym 环境。我将如何修改/设置使用来自我的收集系统的数据而不是健身房环境数据的实现？]]></description>
      <guid>https://stackoverflow.com/questions/77641484/proximal-policy-optimization-code-without-using-openai-gym-environments</guid>
      <pubDate>Mon, 11 Dec 2023 17:58:03 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 中的数据采样方法</title>
      <link>https://stackoverflow.com/questions/77578111/data-sample-methods-in-lightgbm</link>
      <description><![CDATA[我的问题
我不太清楚所有参数的用法以及它们如何相互交互（或应该使用）。
我所知道的
据我了解，LightGBM中有3种算法：

GBDT，默认的，使用 boosting
DART 是一种带有 dropout 的 boosting 算法
随机森林，不使用增强（确实如此，但仅在一次迭代中）

并且有两种数据采样策略：

Bagging，默认设置，用于集成学习
GOSS 选择更多对误差梯度贡献最大的数据（我们的想法是，我们需要对远离基线的数据进行更多训练），而对“弱”数据则选择更少。数据点（对误差梯度贡献较小的数据点）。

问题
所以我的问题如下：

为什么 Bagging 和 GOSS 不兼容？它们似乎不会影响同一件事。
LightGBM 的主要创新似乎是 GOSS，但它并不是默认选择，这样做的动机是什么？
最后，我们能够将 boosting_type=goss 作为参数传递。当我们这样做时会发生什么？算法会是GBDT，而数据样本策略是goss吗？

非常感谢您抽出时间。
祝你有美好的一天。]]></description>
      <guid>https://stackoverflow.com/questions/77578111/data-sample-methods-in-lightgbm</guid>
      <pubDate>Thu, 30 Nov 2023 11:34:21 GMT</pubDate>
    </item>
    <item>
      <title>langchain CharacterTextSplitter 的 chunk_size 参数有什么作用？</title>
      <link>https://stackoverflow.com/questions/76633836/what-does-langchain-charactertextsplitters-chunk-size-param-even-do</link>
      <description><![CDATA[我的默认假设是 chunk_size 参数将为 split_text 方法产生的块/分割的大小设置上限，但这显然是不对的：
from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter

块大小 = 6
块重叠 = 2

c_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)

文本 = &#39;abcdefghijklmnopqrstuvwxyz&#39;

c_splitter.split_text(文本)

打印：[&#39;abcdefghijklmnopqrstuvwxyz&#39;]，即比chunk_size=6大得多的单个块。
所以我知道它没有将文本分割成块，因为它从未遇到分隔符。但问题是 chunk_size 到底在做什么？
我检查了 langchain.text_splitter.CharacterTextSplitter 的文档页面 这里但没有看到这个问题的答案。我问“可修复的”？ chat-with-langchain-docs 搜索功能，但得到了答案“CharacterTextSplitter 的 chunk_size 参数确定每个文本块中的最大字符数。”...这不是真的，如上面的代码示例所示.]]></description>
      <guid>https://stackoverflow.com/questions/76633836/what-does-langchain-charactertextsplitters-chunk-size-param-even-do</guid>
      <pubDate>Fri, 07 Jul 2023 03:50:27 GMT</pubDate>
    </item>
    <item>
      <title>Perzeptron 算法 - 代码错误 - Python 3 [重复]</title>
      <link>https://stackoverflow.com/questions/51912598/perzeptron-algorithm-code-error-python-3</link>
      <description><![CDATA[我正在阅读德语书籍“Machine Learning with Python”作者：塞巴斯蒂安·拉什卡。
我在 Windows 机器上使用 anaconda 和spyder（包括 ipython 控制台）。
在第 3 章中，他依赖于基于“Perzeptron 模型”的算法。
按照作者的指示，代码应如下所示：
从sklearn.metrics导入accuracy_score
print(&#39;Korrektklassifizierungsrate: %.2f&#39; % precision_score(y_test, y_pred))

从 matplotlib.colors 导入 ListedColormap
defplot_decision_region(X, y, 分类器, 分辨率=0.02):
    
    # Markierungen 和 Farben einstellen
    标记 = (&#39;s&#39;, &#39;x&#39;, &#39;o&#39;, &#39;^&#39;, &#39;v&#39;)
    颜色 = (&#39;红色&#39;, &#39;蓝色&#39;, &#39;浅绿色&#39;, &#39;灰色&#39;, &#39;青色&#39;)
    cmap = ListedColormap(颜色[:len(np.unique(y))])
    
    #Plotten der Entscheidungsgrenze
    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, \
         分辨率），np.arange（x2_min，x2_max，分辨率））
    Z = classifier.predict(np.array([xx1.ravel(), \
                                     xx2.ravel()]).T)
    
    Z = Z.reshape(xx1.shape)
                  plt.contourf(xx1,xx2,Z,alpha=0.4,cmap=cmap),
                  plt.xlim(xx1.min(), xx1.max())
                  plt.ylim(xx2.min(), xx2.max())
    
    #Plotten aller 示例
    对于 idx，枚举中的 cl(np.unique(y))：
        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],
                    α=0.8，c=cmap(idx)，
                    标记=标记[idx]，标签=cl)
    
    #Examplare Testdatenmenge hervorheben
    如果测试idx：
        X_test, y_test = X[test_idx, :], y[test_idx]
        plt.scatter(X_test[:, 0], X_test[:, 1], c=&#39;&#39;,
                    alpha=1.0，线宽=1，标记=&#39;o&#39;s=55，标签=&#39;测试集&#39;）
        
X_combined_std = np.vstack((X_train_std, X_test_std))
y_combined = np.hstack((y_train, y_test))
plot_decision_regions(X=X_combined_std,
                      y=y_组合，
                      分类器=ppn,
                      test_idx=范围(105,150))
plt.xlabel(&#39;Länge des Blütenblatts [standardisiert]&#39;)
plt.ylabel(&#39;Breite des Blütenblatts [standardisiert]&#39;)
plt.legend(loc=&#39;左上&#39;)
plt.show()

 文件“”，第 19 行
    plt.contourf(xx1,xx2,Z,alpha=0.4,cmap=cmap),
    ^
IndentationError：意外缩进

所以，我不确定默认值是什么。我真的很想理解这个错误，如果有人能帮助我，我将不胜感激。难道，它与方程 cmap=cmap 有关吗？]]></description>
      <guid>https://stackoverflow.com/questions/51912598/perzeptron-algorithm-code-error-python-3</guid>
      <pubDate>Sat, 18 Aug 2018 21:13:42 GMT</pubDate>
    </item>
    </channel>
</rss>