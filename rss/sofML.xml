<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 21 Jan 2025 18:22:58 GMT</lastBuildDate>
    <item>
      <title>训练 Hugging Face Transformer 期间 GPU 利用率几乎始终为 0</title>
      <link>https://stackoverflow.com/questions/79375287/gpu-utilization-almost-always-0-during-training-hugging-face-transformer</link>
      <description><![CDATA[我正在使用我的发票数据对 Donut Cord-v2 模型进行微调，该发票数据在预处理并作为数据集保存在磁盘上时大小约为 360 GB。我几乎完全按照这个笔记本进行操作，只是我有 6 个训练周期而不是 3 个。
我在单个 Nvidia H100 SXM GPU / Intel Xeon® Gold 6448Y / 128 GB RAM 上进行训练。
每当我开始训练并使用 htop 和 nvidia-smi 检查 CPU 和 GPU 利用率时，我都会看到 CPU 始终处于 100%，由 python 使用，GPU 内存几乎始终被填充 90%，但 GPU 利用率几乎始终为 0。如果我不断刷新 nvidia-smi 的输出，则每 10-12 秒一次，利用率将跳至 100%，然后立即返回到 0。我不禁感觉到我的 CPU 和 GPU 之间存在瓶颈，CPU 尝试不断处理数据并将其发送到 GPU，GPU 处理速度非常快，并且只是闲置，等待来自 CPU 的下一批数据。我的数据集已完全加载到内存中，并且在训练时没有进行任何预处理：
from datasets import load_from_disk
processed_dataset = load_from_disk(r&quot;/dataset/dataset_final&quot;)

我的处理器配置如下：
from transformers import DonutProcessor

new_special_tokens = [] # 将添加到 tokenizer 的新 token
task_start_token = &quot;&lt;s&gt;&quot; # 任务 token 的启动
eos_token = &quot;&lt;/s&gt;&quot; # tokenizer 的 eos token

processor = DonutProcessor.from_pretrained(&quot;naver-clova-ix/donut-base-finetuned-cord-v2&quot;)

# 向 tokenizer 添加新的特殊 token
processor.tokenizer.add_special_tokens({&quot;additional_special_tokens&quot;: new_special_tokens + [task_start_token] + [eos_token]})

# 我们更新了一些与预训练不同的设置；即图像的大小 + 无需旋转
processor.feature_extractor.size = [1200,1553] # 应为 (宽度, 高度)
processor.feature_extractor.do_align_long_axis = False

我的模型配置是：
import torch
from transformers import VisionEncoderDecoderModel, VisionEncoderDecoderConfig

#print(torch.cuda.is_available())

# 从 huggingface.co 加载模型
model = VisionEncoderDecoderModel.from_pretrained(&quot;naver-clova-ix/donut-base-finetuned-cord-v2&quot;)

# 调整嵌入层的大小以匹配词汇表大小
new_emb = model.decoder.resize_token_embeddings(len(processor.tokenizer))
print(f&quot;新嵌入大小： {new_emb}&quot;)
# 调整我们的图像大小和输出序列长度
model.config.encoder.image_size = process.feature_extractor.size[::-1] # (height, width)
model.config.decoder.max_length = len(max(processed_dataset[&quot;train&quot;][&quot;labels&quot;], key=len))

# 添加解码器启动的任务令牌
model.config.pad_token_id = process.tokenizer.pad_token_id
model.config.decoder_start_token_id = process.tokenizer.convert_tokens_to_ids([&#39;&lt;s&gt;&#39;])[0]

我的训练代码是：
import gc
gc.collect()

torch.cuda.empty_cache()

from transformers import Seq2SeqTrainingArguments，Seq2SeqTrainer

导入日志记录
logging.basicConfig(level=logging.INFO)

# 训练参数
training_args = Seq2SeqTrainingArguments(
output_dir=r&quot;/trained&quot;, # 指定本地目录保存模型
num_train_epochs=6,
learning_rate=2e-5,
per_device_train_batch_size=8,
weight_decay=0.01,
fp16=True,
logs_steps=50,
save_total_limit=2,
evaluation_strategy=&quot;no&quot;,
save_strategy=&quot;epoch&quot;,
predict_with_generate=True,
report_to=&quot;none&quot;,
# 禁用推送到集线器
push_to_hub=False

)

# 创建训练器
trainer = Seq2SeqTrainer(
model=model,
args=training_args,
train_dataset=processed_dataset[&quot;train&quot;],
)

# 开始训练
trainer.train()

使用 360 GB 数据集完成 6 个 epoch 的训练预计需要 54 小时。当我在装有 Intel i9 11900KF / RTX 3050 的 PC 上运行完全相同的代码时，我发现 GPU 利用率一直保持在 100%。我的代码中是否存在瓶颈？为什么 CPU 会在已经预处理的数据集上继续处理这么多内容？Cuda 12.6]]></description>
      <guid>https://stackoverflow.com/questions/79375287/gpu-utilization-almost-always-0-during-training-hugging-face-transformer</guid>
      <pubDate>Tue, 21 Jan 2025 17:09:03 GMT</pubDate>
    </item>
    <item>
      <title>我们可以通过编程找出 Android 设备使用的 NPU 吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/79374045/can-we-find-out-the-npu-used-by-the-android-device-programatically</link>
      <description><![CDATA[是否有任何基于 C/C++ 或 Java 的 API 来查明设备是否具有 NPU？]]></description>
      <guid>https://stackoverflow.com/questions/79374045/can-we-find-out-the-npu-used-by-the-android-device-programatically</guid>
      <pubDate>Tue, 21 Jan 2025 10:31:12 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 分类器中获取属性错误</title>
      <link>https://stackoverflow.com/questions/79374019/getting-attribute-error-in-keras-classifier</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79374019/getting-attribute-error-in-keras-classifier</guid>
      <pubDate>Tue, 21 Jan 2025 10:21:29 GMT</pubDate>
    </item>
    <item>
      <title>在保持批量大小、损失函数、架构、度量、数据、优化器的同时，TensorFlow 和 PyTorch 之间的差异</title>
      <link>https://stackoverflow.com/questions/79373655/discrepancies-between-tensorflow-and-pytorch-while-maintaining-batch-size-loss</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79373655/discrepancies-between-tensorflow-and-pytorch-while-maintaining-batch-size-loss</guid>
      <pubDate>Tue, 21 Jan 2025 08:27:06 GMT</pubDate>
    </item>
    <item>
      <title>Kubernetes MPIJob 在 3-GPU 集群上进行分布式推理时出现静默故障</title>
      <link>https://stackoverflow.com/questions/79373629/silent-failure-in-kubernetes-mpijob-for-distributed-inference-on-3-gpu-cluster</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79373629/silent-failure-in-kubernetes-mpijob-for-distributed-inference-on-3-gpu-cluster</guid>
      <pubDate>Tue, 21 Jan 2025 08:18:37 GMT</pubDate>
    </item>
    <item>
      <title>您会推荐哪个云服务器来设置我的应用程序？[关闭]</title>
      <link>https://stackoverflow.com/questions/79372975/which-cloud-server-would-you-recommend-for-my-app-setup</link>
      <description><![CDATA[我正在开发一个个人项目，它是一个 webapp。我想知道部署最好的远程服务器解决方案是什么。我的堆栈是：

python 后端，react 前端。容器单独打包
并相互通信
使用 github 作为代码存储库
使用 github 操作/工作流进行自动部署
使用 JFrog 作为 docker 容器注册表
该应用程序使用 sql 数据库存储用户数据，使用对象存储存储图像和视频。
该应用程序使用 ML 模型

传统模型，如 XGBoost，在本地训练小型
开源 LLM 模型


目前我不使用 kubernetes，但将来我可能会使用


我希望应用程序全天候可用。我预计每天最多会有几百个后端请求。
我的问题是：

对我的 DevOps 流程有什么建议吗？
我应该使用哪种云服务来托管此应用程序？
推荐的 ML 模型注册表和主机是什么？

过去，在类似的设置但没有 ML 模型的情况下，我使用过 AWS EC2、S3 和 RDS。那时我只知道一些 Docker 命令，因此在本地打包了一个映像，上传到我的 Docker Hub，并将容器拉到 EC2 并手动运行 docker run 命令。我在 RDS（分离的 EC2 实例）上创建了一个 PostgreSql，并打开了一个通信端口来与应用程序通信。但说实话，这很复杂，因为我必须在 EC2 上安装很多东西（docker、git 等），而且一开始成本也很昂贵。现在，我知道如何使用 GitHub 操作，我对 Terraform 有所了解，我还知道如何使用 kubernetes 以及如何编写 helm 图表。所以我想就哪些解决方案可用以及推荐给我提出建议。
我的个人资料是数据科学家，我正在学习 CI/CD 和 DevOps。谢谢 :)]]></description>
      <guid>https://stackoverflow.com/questions/79372975/which-cloud-server-would-you-recommend-for-my-app-setup</guid>
      <pubDate>Tue, 21 Jan 2025 01:05:53 GMT</pubDate>
    </item>
    <item>
      <title>合并两个图像数据集</title>
      <link>https://stackoverflow.com/questions/79372667/combining-two-image-dataset</link>
      <description><![CDATA[我有 6 个图像数据集，一个来自 Kaggle，其他来自 Roboflow。我想使用所有 6 个数据集在 Google Colab 中训练模型。我可以在 Google Colab 中正常使用它们吗？处理和组合这些数据集进行训练的最佳实践是什么？
我还没有尝试任何方法，但我已经搜索过了，仍然没有得到问题的答案]]></description>
      <guid>https://stackoverflow.com/questions/79372667/combining-two-image-dataset</guid>
      <pubDate>Mon, 20 Jan 2025 21:17:58 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV 中的 ML 模型输出[关闭]</title>
      <link>https://stackoverflow.com/questions/79372362/ml-model-output-in-opencv</link>
      <description><![CDATA[在此处输入图片描述
我使用 c++ 和 OpenCV 制作了一个 ML 模型。我想知道 xml 输出文件中的参数 min_val 和 max_val 是什么意思，以及如何在模型中更改它们？
我尝试在网上搜索解决方案。我想将参数设置为 [-1, 1]]]></description>
      <guid>https://stackoverflow.com/questions/79372362/ml-model-output-in-opencv</guid>
      <pubDate>Mon, 20 Jan 2025 18:42:23 GMT</pubDate>
    </item>
    <item>
      <title>开发机器学习管道的想法[关闭]</title>
      <link>https://stackoverflow.com/questions/79372212/ideas-for-developing-a-machine-learning-pipeline</link>
      <description><![CDATA[我目前正在开展一个项目，该项目将融合来自时间序列生物信号和图像的数据，以预测心理评分。
有很多方法可以解决这个问题，我正在寻找有关各种可能性的想法。
其中一个生物信号被认为几乎瞬时与大脑活动相关（想想 EEG，但它不是 EEG），第二个生物信号相当慢，形成时间超过 30 秒（滞后指标）。这些信号将在用户检查照片时收集。我可以量化他们正在看的地方。我还能够在监督环境中处理标记数据。我们可以使用独立测量（不会集成到管道中）来确定此任务的用户心理分数，但这对于监督学习很有用。
对于此应用程序，我无法访问大量用户数据，并且需要依赖管道某些组件的预训练模型。
我相信生物信号中事件的顺序很重要，因此我认为我只能使用 RNN（非常慢）或 transformer。
如果您正在开发这样的系统，您的管道会是什么样子，您会关注哪些主要活动？]]></description>
      <guid>https://stackoverflow.com/questions/79372212/ideas-for-developing-a-machine-learning-pipeline</guid>
      <pubDate>Mon, 20 Jan 2025 17:38:23 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“torch”（未知位置）导入名称“Tensor”</title>
      <link>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</link>
      <description><![CDATA[我尝试从 PyTorch 导入 Tensor：
从 torch 导入 Tensor

但我一直收到此错误：
ImportError：无法从“torch”（未知位置）导入名称“Tensor”

我尝试过的方法：

检查 PyTorch 是否已安装（pip show torch），我使用的是版本 2.5.1。
重新安装 PyTorch：
pip uninstall torch
pip install torch


在 Python shell 中测试了导入，但错误依然存在。

环境：

Python版本：3.10
PyTorch 版本：2.5.1
操作系统：Windows 10
虚拟环境：是

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</guid>
      <pubDate>Sat, 18 Jan 2025 13:04:35 GMT</pubDate>
    </item>
    <item>
      <title>stable_baselines3：为什么比较 ep_info_buffer 与评估时奖励不匹配？</title>
      <link>https://stackoverflow.com/questions/79353843/stable-baselines3-why-the-reward-does-not-match-comparing-ep-info-buffer-vs-eva</link>
      <description><![CDATA[我正在使用 stable_baselines3 库，这时我发现了一些意想不到的东西。
这里有一个简单的代码来重现这个问题：
import gymnasium as gym

from stable_baselines3 import DQN

env = gym.make(&quot;CartPole-v1&quot;)

model = DQN(&quot;MlpPolicy&quot;, env, verbose=0, stats_window_size=100_000)
model.learn(total_timesteps=100_000)

看看最后一集的奖励：
print(model.ep_info_buffer[-1])


{&#39;r&#39;: 409.0, &#39;l&#39;: 409, &#39;t&#39;: 54.87983

但是如果我使用以下代码评估模型：
obs, info = env.reset()
total_reward = 0
while True:
action, _states = model.predict(obs, deterministic=True)
obs, reward, termed, truncated, info = env.step(action)
total_reward = total_reward + reward
if termed or truncated:
obs, info = env.reset()
break

print(&quot;total_reward {}&quot;.format(total_reward))


total_reward 196.0

我得到了不同的奖励，这是我没有预料到的。
我预计会得到与 409 相同的奖励model.ep_info_buffer[-1]。
为什么会有这种差异？.ep_info_buffer 与每集奖励不同吗？]]></description>
      <guid>https://stackoverflow.com/questions/79353843/stable-baselines3-why-the-reward-does-not-match-comparing-ep-info-buffer-vs-eva</guid>
      <pubDate>Tue, 14 Jan 2025 02:14:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在处理 EOS 代币时计算拥抱人脸模型的教师强制准确度 (TFA)？</title>
      <link>https://stackoverflow.com/questions/79209319/how-to-compute-teacher-forced-accuracy-tfa-for-hugging-face-models-while-handl</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79209319/how-to-compute-teacher-forced-accuracy-tfa-for-hugging-face-models-while-handl</guid>
      <pubDate>Thu, 21 Nov 2024 00:25:48 GMT</pubDate>
    </item>
    <item>
      <title>VSCode 安装 hugginface relik 库时出错</title>
      <link>https://stackoverflow.com/questions/79182549/vscode-install-error-for-the-hugginface-relik-library</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79182549/vscode-install-error-for-the-hugginface-relik-library</guid>
      <pubDate>Tue, 12 Nov 2024 19:53:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 OvO 和 OvR 返回相同的结果？</title>
      <link>https://stackoverflow.com/questions/70981876/why-does-ovo-and-ovr-return-the-same-result</link>
      <description><![CDATA[我正在使用 scikit-learn 的 roc_auc_score() 函数来解决多类分类问题。对于具有三个标签（和另一个数据集）的鸢尾花，当我使用一对一和一对其余时，我得到完全相同的输出。有人知道为什么会这样吗？这是我的代码：
从 sklearn 导入数据集
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.metrics 导入 roc_auc_score
从 sklearn.model_selection 导入 train_test_split
从 sklearn.tree 导入 DecisionTreeClassifier

iris = datasets.load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)
clf = DecisionTreeClassifier(random_state=0)
clf = clf.fit(X_train, y_train)
y_pred = clf.predict_proba(X_test)
auc_ovr = roc_auc_score(y_test, y_pred, average=&#39;macro&#39;, multi_class=&#39;ovr&#39;)
auc_ovo = roc_auc_score(y_test, y_pred, average=&#39;macro&#39;, multi_class=&#39;ovo&#39;)
print(f&#39;OVR: {auc_ovr}, OVO: {auc_ovo}&#39;)


最后一行的输出是：
OVR: 0.9833333333333334, OVO: 0.9833333333333334
]]></description>
      <guid>https://stackoverflow.com/questions/70981876/why-does-ovo-and-ovr-return-the-same-result</guid>
      <pubDate>Fri, 04 Feb 2022 05:35:38 GMT</pubDate>
    </item>
    <item>
      <title>KD树最近邻搜索如何工作？</title>
      <link>https://stackoverflow.com/questions/4418450/how-does-the-kd-tree-nearest-neighbor-search-work</link>
      <description><![CDATA[我正在查看 KD 树的 Wikipedia 页面。例如，我在 Python 中实现了列出的构建 KD 树的算法。
但是，使用 KD 树进行 KNN 搜索的算法会切换语言，并且并不完全清楚。英语解释开始有意义，但其中的部分（例如他们“展开递归”以检查其他叶节点的区域）对我来说真的没有任何意义。
这是如何工作的，以及如何在 Python 中使用 KD 树进行 KNN 搜索？这并不是一个“给我发代码！”类型的问题，我也不指望这样。请简单解释一下 :)]]></description>
      <guid>https://stackoverflow.com/questions/4418450/how-does-the-kd-tree-nearest-neighbor-search-work</guid>
      <pubDate>Sat, 11 Dec 2010 19:14:25 GMT</pubDate>
    </item>
    </channel>
</rss>