<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 26 Nov 2024 12:35:13 GMT</lastBuildDate>
    <item>
      <title>构建 Python ML 项目目录的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/79226565/what-is-the-best-way-to-structure-the-directories-a-python-ml-project</link>
      <description><![CDATA[我想知道为 ML Python 项目构建目录的适当方法；以使项目易于阅读、维护并使包的导入正常工作。（即，从命令行和 IDE 运行时导入都能顺利运行，而无需在 PYTHONPATH 或类似的东西中硬编码更改）
我对此很陌生，我已经搜索过但还没有找到标准方法。
例如，我将以这种方式构建一个项目：（注意：这只是一个示例，用于提供想法，文件夹可能包含更多 .py 文件、具有类定义的文件......）
+---configuration_files
+---data
+---models
+---README.md
+---report.md
+---requirements.txt
+---shell_scripts
\---src
|数据清理.py
| 数据预处理.py
| 预处理数据分析.py
| 原始数据分析.py
| 测试.py
| 训练.py
|
\---模块
| __init__.py
|
+---数据分析
| 数据分析实用程序.py
| __init__.py
|
+---数据处理
| 数据加载器.py
| __init__.py
|
+---数据预处理
| 数据预处理实用程序.py
| __init__.py
|
+---通用实用程序
| 通用实用程序.py
| __init__.py
|
+---测试
| 测试实用程序.py
| __init__.py
| \---train
trainer.py.py
train_functions_1.py
train_functions_2.py
__init__.py

您对此有何看法？
例如，将必须直接运行的脚本放在 src 目录中，使导入更容易；
但是我觉得将它们放在 data_preprocessing、data_analysis、train、test 等文件夹中，每个文件夹都有各自的包和模块，这样会更简洁。但是，这会在从应该由所有人共享的 general_utils 包导入时引入问题。
此外，src、modules、utils 等使用名称的约定是什么？我应该有一个 main.py  脚本吗？ （即使我有不同的阶段）
一般来说，在行业中，构建此类项目的最有效和最广泛使用的方式是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79226565/what-is-the-best-way-to-structure-the-directories-a-python-ml-project</guid>
      <pubDate>Tue, 26 Nov 2024 11:44:32 GMT</pubDate>
    </item>
    <item>
      <title>对患者同时发生的医学症状进行聚类[关闭]</title>
      <link>https://stackoverflow.com/questions/79226363/clustering-co-occuring-medical-symptoms-for-patients</link>
      <description><![CDATA[我获得了一个数据集，其中跟踪了不同患者的 48 种不同医学症状。这些症状每天都会记录下来，每天的严重程度评级为 0-4。
我需要将一年中不同时间点同时出现的症状聚集在一起。
哪个无监督模型能够按时间拆分数据并提供输出来解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79226363/clustering-co-occuring-medical-symptoms-for-patients</guid>
      <pubDate>Tue, 26 Nov 2024 10:50:08 GMT</pubDate>
    </item>
    <item>
      <title>我怎样才能使我的扩散模型表现更好？</title>
      <link>https://stackoverflow.com/questions/79226290/how-can-i-make-my-diffusion-model-perform-better</link>
      <description><![CDATA[我一直在研究一个受 2020 年 DDPM 论文启发的扩散模型。它运行良好，但我不明白为什么它没有表现得更好。
情况如下：

在 MNIST 上，该模型的 FID 达到 15 左右，您可以识别这些数字。
在 CIFAR-10 上，大多数时候很难分辨出生成了什么。
在 CelebA 上，有些脸还可以，但大多数最终看起来像扭曲的怪物。

我尝试调整学习率、批量大小和其他超参数，但没有产生显着的变化。我从头开始构建了 UNet 架构和 loss+sample 函数，因此我怀疑那里可能存在问题，但经过几个小时的调试，我仍然找不到任何明显的东西。
我的模型应该表现得比这更好吗？我应该专注于进一步调整或调试哪些特定领域？有人可以看看我的代码并提供反馈或建议吗？
这是 github 上项目的链接：https://github.com/juliuseg/Diffusion_plz_help]]></description>
      <guid>https://stackoverflow.com/questions/79226290/how-can-i-make-my-diffusion-model-perform-better</guid>
      <pubDate>Tue, 26 Nov 2024 10:30:59 GMT</pubDate>
    </item>
    <item>
      <title>如何为 LSTM 模型使用分类数据和数值数据对数据集进行窗口化？</title>
      <link>https://stackoverflow.com/questions/79225304/how-to-window-a-dataset-with-categorical-and-numerical-data-for-lstm-model</link>
      <description><![CDATA[我有一个包含 3 列的数据集：时间戳 (字符串)、Inverter_Key (字符串)（我的情况是 21 个逆变器）、能量 (整数)、温度 (整数)。我尝试创建 LSTM 模型来预测每个逆变器的能量和温度。为了提高模型的速度，请改为获取输入形状 (96,66)。我将训练和测试的数据集合并起来，使数据集为 (96,4)。但是，测试时预测与实际数据不匹配。我相信这是由于窗口化造成的，因为我已经检查了异常值和相关关系。关系显示能量和温度具有线性关系 0.78，非线性关系为 0.8。我还缩放了我的能量数据以使其变小。因此，这一定是我窗口化数据的方式。
对于数据，能量和温度将每 15 分钟记录一次。例如
时间戳、逆变器密钥、能量、温度
12/12/2022 10:15，KU，2，22
12/12/2022 10:15，KS，4，22
12/12/2022 10:30，KU，4，21
12/12/2022 10:30，KS，5，21

我使用标记技术来标记时间，编码热代码以将逆变器密钥也标记为整数。
这是我的窗口化方式：
def windowed_dataset(data, window_size=96, batch_size=128, shuffle_buffer=1000):

数据集 = tf.data.Dataset.from_tensor_slices(data) 
dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)
dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))
dataset = dataset.shuffle(shuffle_buffer)
dataset = dataset.map(lambda window: (window[:-1], window[-1]))
dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(tf.data.AUTOTUNE)

返回数据集

如何创建模型并拟合模型：
def create_M_LSTM_model():
model_m_lstm = tf.keras.models.Sequential([

tf.keras.layers.LSTM(64,return_sequences=True,input_shape = input_data_shape),
#tf.keras.layers.Dropout(0.2),
tf.keras.layers.LSTM(32,return_sequences=True),
tf.keras.layers.LSTM(16,return_sequences=True),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(6),
])
return model_m_lstm

def create_model_M_LSTM():
tf.random.set_seed(51) # 设置可重复性的种子

model_create = create_M_LSTM_model() # 创建模型
model_create.compile(
loss=tf.keras.losses.Huber(), # 损失函数
optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), # 优化器
metrics=[&quot;mae&quot;] # 度量
)
return model_create

# 创建并总结模型
model_create_m_lstm = create_model_M_LSTM()

# 打印模型总结
model_create_m_lstm.summary()

is_train = True
if is_train:
model_create_m_lstm.fit(train_dataset, epochs=20)

如何对包含分类数据和数值数据的数据集进行窗口训练？预期数据集是，当我从预测中提取 KU 逆变器的数据时，它将与测试数据集的 KU 逆变器数据相匹配。]]></description>
      <guid>https://stackoverflow.com/questions/79225304/how-to-window-a-dataset-with-categorical-and-numerical-data-for-lstm-model</guid>
      <pubDate>Tue, 26 Nov 2024 04:13:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 opencv 和 tensorflow 解决数字验证码</title>
      <link>https://stackoverflow.com/questions/79225295/solve-a-number-captcha-with-opencv-and-tensorflow</link>
      <description><![CDATA[我正在开展一个使用 OpenCV 进行图像预处理的项目。下面是我对图像进行预处理的代码：
def preprocess_with_opencv(img):
img = img.numpy()

# 调整大小
img = cv2.resize(img, (img_width, img_height), interpolation=cv2.INTER_AREA)

# 高斯模糊
img = cv2.GaussianBlur(img, (3, 3), 0)

# 自适应阈值
img = cv2.adaptiveThreshold(
img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
)

# 更改
img = img.astype(&quot;float32&quot;) / 255.0
img = np.expand_dims(img, axis=-1)

return img

预处理后，我使用以下函数对图像进行编码以便进一步处理：
def encode_single_sample(img_path, label):
# 1. 解码
img = tf.io.read_file(img_path)

# 2. 解码图像（灰度）
img = tf.io.decode_png(img, channels=1)

# 3. 使用 OpenCV 进行转换
img = tf.py_function(preprocess_with_opencv, [img], Tout=tf.float32)

# 4. 转置问题解决
img = tf.transpose(img, perm=[1, 0, 2])

# 5. 转换 dictionary (image, label)
return {&quot;image&quot;: img, &quot;label&quot;: label}

原始图像如下所示：

但是，使用 encode_single_sample 函数处理图像后，数据似乎不正确，输出图像不清晰。如何解决此问题并确保处理后的图像准确清晰？]]></description>
      <guid>https://stackoverflow.com/questions/79225295/solve-a-number-captcha-with-opencv-and-tensorflow</guid>
      <pubDate>Tue, 26 Nov 2024 04:08:47 GMT</pubDate>
    </item>
    <item>
      <title>在 Databricks 中使用 MLflow 记录模型时排除私有包依赖关系</title>
      <link>https://stackoverflow.com/questions/79224603/exclude-private-package-dependency-when-logging-model-with-mlflow-in-databricks</link>
      <description><![CDATA[我正在使用 Databricks Asset Bundles (DAB) 部署 Databricks 工作流。我的集群上安装了一个自定义包 (mypackage)，其中包含用于不同工作流的多个 CLI 命令。此包包含我的工作流所需的所有依赖项。请注意，mypackage 是一个私有 PyPI 存储库，无法从外部访问。
当我使用 mlflow.pyfunc.log_model() 记录我的模型时，MLflow 会自动检测并将 mypackage.submodule 作为模型的依赖项。这会导致问题，因为：

mypackage 是私有的，无法从外部环境安装。
该模型实际上不需要 mypackage 或其依赖项进行推理 - 它只需要 PyTorch 和 Pandas 等标准库。

这是我的代码的简化版本：
import mlflow.pyfunc
from mypackage.submodule import MyModelClass

model = MyModelClass()

mlflow.pyfunc.log_model(
python_model=model,
artifact_path=&quot;my_model&quot;,
# 其他参数
)

问题：

如何使用 mlflow.pyfunc.log_model() 记录我的模型，而不包括mypackage 作为依赖项？

是否有 MLflow 原生方法可以防止某些包包含在模型环境中？

是否有最佳实践来处理训练环境包含不应成为序列化模型依赖项的包的情况？


其他上下文：

我正在使用 Databricks 和 Databricks Asset Bundles 进行部署。
该模型使用推理所需的标准库（例如 PyTorch、Pandas）。
mypackage 仅在训练和工作流程编排期间使用，但不需要用于模型推理。


我尝试过的：
作为解决方法是，我尝试了一种破解方法，在 __main__ 模块中重新定义我的模型类，并使用 cloudpickle 对其进行序列化，本质上是删除对 mypackage 的引用。这是我所做的片段：
import inspect
import cloudpickle

# 提取模型类的源代码
model_source = inspect.getsource(MyModelClass)

# 创建主命名空间并在 __main__ 中重新定义类
main_namespace = {
&#39;__name__&#39;: &#39;__main__&#39;,
# 包含其他必要的导入
}
exec(model_source, main_namespace)

# 访问重新定义的类
MyModelClassMain = main_namespace[&#39;MyModelClass&#39;]
model = MyModelClassMain()

# 序列化模型
with open(&quot;model.pkl&quot;, &quot;wb&quot;) as f:
cloudpickle.dump(model, f)

# 记录模型而不包括“mypackage”
mlflow.pyfunc.log_model(
python_model=model,
articulate_path=&quot;my_model&quot;,
artifacts={&quot;model.pkl&quot;: &quot;model.pkl&quot;},
pip_requirements=[&quot;torch&quot;, &quot;pandas&quot;, &quot;cloudpickle&quot;],
# 其他参数
)

虽然这种方法有效，但感觉像是一种黑客解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/79224603/exclude-private-package-dependency-when-logging-model-with-mlflow-in-databricks</guid>
      <pubDate>Mon, 25 Nov 2024 21:09:57 GMT</pubDate>
    </item>
    <item>
      <title>弹性净惩罚分位数回归性能不佳的原因及潜在解决方案[关闭]</title>
      <link>https://stackoverflow.com/questions/79224486/reasons-and-potential-solutions-for-poor-performance-of-elastic-net-penalized-qu</link>
      <description><![CDATA[我正在对我的数据集执行弹性净惩罚分位数回归 (EN-QR)，该数据集有 6,782 行和 227 列（即预测因子）。其中 195 个预测因子是代谢物，我的目标是找出哪些代谢物与接触空气污染物 PM2.5 有关。我选择执行 QR 而不是线性回归，因为 PM2.5 数据存在偏差且不呈正态分布，即使在执行对数转换和标准化之后也是如此。我将数据集按 70:30 的比例分为训练集 (n = 4,747) 和测试集 (n = 2,035)。
我遇到的问题是，当我将训练集中的 EN-QR 对象应用到测试集以预测 PM2.5 值（下图）时，我得到了一个奇怪的多峰分布，它与测试集中的实际 PM2.5 值不符（上图）。我已将这些分布的屏幕截图附在下面。

我不一定在寻找可以解决这个问题的人，但我想知道是否有人对此有解决问题的建议。模型会分裂成多峰分布而不是（近似）正态分布的一些潜在原因是什么？有没有我没有考虑包含在训练集模型中的东西？我是否应该研究其他策略来实现我的变量选择目标？理想情况下，我希望 EN-QR 模型能够发挥作用，因为它为我的研究问题提供了最多的信息。
我尝试根据数据属于多峰分布的哪个模式将数据分成四个集群。我发现美国人口普查区域与预测的 PM2.5 值的模式之间存在关系。例如，几乎所有 z 得分最低的模式中的人都来自南部，而几乎所有 z 得分最高的模式中的人都来自中西部。我觉得这很奇怪，因为美国人口普查区域被纳入为协变量，因此模型不应该按地区分层。我在下面附上了这张图片和表格。

这是我用来在训练集上执行 EN-QR 的 R 聊天。 Behat 是我用来预测测试集中 PM2.5 值的代码。
trainingset.ENQR &lt;- rq.pen.cv(
x = as.matrix(trainingset[, c(4:5, 27, 29:251)]),
y = trainingset[, 18],
tau = c(0.1, 0.5, 0.9),
penalty = &quot;ENet&quot;,
a = c(0.50, 0.75, 0.90),
nfolds = 10,
printProgress = TRUE,
penalty.factor = c(rep(0, 32), rep(1, 194))
)

lambda.min.training &lt;- trainingset.ENQR$gtr$lambda1se[2]

testingset.ENQR.50 &lt;- rqPen:::predict.rq.pen.seq.cv(object = trainingset.ENQR,
newx = as.matrix(testingset[, c(4:5, 27, 29:251)]),
tau = 0.50,
a = 0.50,
lambda = lambda.min.training,
cvmin = FALSE)
]]></description>
      <guid>https://stackoverflow.com/questions/79224486/reasons-and-potential-solutions-for-poor-performance-of-elastic-net-penalized-qu</guid>
      <pubDate>Mon, 25 Nov 2024 20:14:44 GMT</pubDate>
    </item>
    <item>
      <title>统计学习混淆表变量</title>
      <link>https://stackoverflow.com/questions/79224395/statistical-learning-confusion-table-variable</link>
      <description><![CDATA[我的混淆表中出现了一个额外的变量，不知道它从何而来。
数据集“默认”具有以下列：默认、学生、收入、余额
变量“默认”具有两个值：“是”和“否”
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
from ISLP import load_data
from ISLP.models import (ModelSpec as MS,
summary,
poly)
from ISLP import chaos_table

Default = load_data(&#39;Default&#39;)
vars = Default.columns.drop([&#39;default&#39;])
y = Default[&#39;default&#39;] == &#39;是&#39;
design = MS(vars)
X = design.fit_transform(Default)
glm = sm.GLM(y,
X,
family = sm.families.Binomial())
results = glm.fit()
summarize(results)
probs = results.predict()
labels = np.array([&#39;No&#39;]*10000)
labels[probs&gt;0.5] = &#39;Yes&#39;
confusion_table(labels,Default.default)

在输出中，我得到一个 3x3 表，其中包含变量“No”、“Yes”和“Ye”
我希望混淆表值仅为“Yes”和“No”。不知何故，numpy.array“labels”设置为“Ye”而不是“Yes”。]]></description>
      <guid>https://stackoverflow.com/questions/79224395/statistical-learning-confusion-table-variable</guid>
      <pubDate>Mon, 25 Nov 2024 19:35:27 GMT</pubDate>
    </item>
    <item>
      <title>当我 pickle ML 模型并将其注释掉时出现 FileNotFoundError</title>
      <link>https://stackoverflow.com/questions/79224304/filenotfounderror-when-i-pickle-my-ml-model-and-comment-it-out</link>
      <description><![CDATA[尝试为数据项目加载 pickle ML 模型时，我收到一条错误消息。如何解决？
我有正确的文件路径，并且已经确认了路径“/home/jovyan/work”，并且之前加载了 pickle。
我不知道这是否是云问题，但是当我单独注释掉 pickle 的写入时，或者如果我注释掉 pickle 的写入和模型的拟合...出于某种原因，我无法简单地加载 pickle。这就是我每次都要对模型进行 pickle 处理，而不必拟合模型的原因。
这些是我正在使用的函数：
def write_pickle(path, model_object, save_as:str): 

with open(path + save_as + &quot;.pickle&quot;, &quot;wb&quot;) as to_write: 

pickle.dump(model_object, to_write)

def read_pickle(path, saved_model_name:str):

with open(path + saved_model_name + &#39;.pickle&#39;, &#39;rb&#39;) as to_read:

model = pickle.load(to_read)

return model

这些函数适用于文件路径和所有内容，但当我注释掉 pickle 的写入或注释掉 ML 模型的拟合时……我收到了 FileNotFoundError。我不知道问题可能出在哪里。如果我不能弄清楚，那么我甚至连 pickle 模型都无用了。]]></description>
      <guid>https://stackoverflow.com/questions/79224304/filenotfounderror-when-i-pickle-my-ml-model-and-comment-it-out</guid>
      <pubDate>Mon, 25 Nov 2024 19:00:17 GMT</pubDate>
    </item>
    <item>
      <title>Python scorecardpy：UnboundLocalError：赋值前引用了局部变量“card_df”</title>
      <link>https://stackoverflow.com/questions/79219306/python-scorecardpy-unboundlocalerror-local-variable-card-df-referenced-befor</link>
      <description><![CDATA[我使用 scorecardpy 函数来获取模型：
import scorecardpy as ac
card=sc.scorecard(bins_adj, lr, X_train.columns)

然后我尝试使用以下代码保存此模型：
import numpy as np
np.save(&#39;card.npy&#39;,card)

之后我尝试重新加载此模型：
card=np.load(&#39;card.npy&#39;,allow_pickle=True)

然后我想使用该模型获取分数：
score=sc.scorecard_ply(data_train, card, print_step=0)

但它给出了错误：
UnboundLocalError Traceback（最近一次调用最后一次）
单元格在 [91]，第 1 行
score=sc.scorecard_ply(data_train, card, print_step=0)

文件 ~/.local/lib/python3.9/site-packages/scorecardpy/scorecard.py:330，在 scorecard_ply(dt, card, only_total_score, print_step, replace_blank_na, var_kp)
card_df=card.copy(deep=True)
# x 变量
xs=card_df.loc[card_df.variable != &#39;basepoints&#39;, &#39;variable&#39;].unique()
# x 变量的长度
xs_len=len(xs)

UnboundLocalError：局部变量“card_df”在赋值前被引用

如何解决此问题有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/79219306/python-scorecardpy-unboundlocalerror-local-variable-card-df-referenced-befor</guid>
      <pubDate>Sun, 24 Nov 2024 04:16:39 GMT</pubDate>
    </item>
    <item>
      <title>如何让这个图看起来更整洁一点？</title>
      <link>https://stackoverflow.com/questions/79218937/how-to-make-this-graph-look-a-bit-neater</link>
      <description><![CDATA[import math
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import datetime

# 加载特斯拉数据集
tesla_stock = pd.read_csv(&#39;C:/Users/Admin/Downloads/AI/Tesla.csv&#39;)

# 动态处理缺失或重命名的“收盘价”列
possible_target_columns = [&#39;Close&#39;, &#39;Last&#39;, &#39;Price&#39;, &#39;Adjusted Close&#39;, &#39;VWAP&#39;, 
&#39;Close/Last&#39;]
target_column = None

# 打印可用列以进行调试
print(&quot;数据集中可用的列：&quot;, tesla_stock.columns)

for col in possible_target_columns:
if col in tesla_stock.columns:
target_column = col
print(f&quot;使用 &#39;{col}&#39; 作为预测的目标列。&quot;)
break

# 处理未找到合适列的情况
if target_column is None:
print(&quot;未找到合适的预测列。请检查数据集。&quot;)
raise KeyError(&quot;确保数据集包含带有股票价格的列（例如，&#39;Close&#39;、
&#39;Close/Last&#39;）。&quot;)

# 清理数字列（删除 &#39;$&#39; 并转换为浮点数）
for column in [&#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Close/Last&#39;, &#39;Volume&#39;]:
if column in tesla_stock.columns:
tesla_stock[column] = tesla_stock[column].replace(&#39;[\$,]&#39;, &#39;&#39;, 
regex=True).astype(float)

# 将“日期”转换为日期时间并设置为索引
tesla_stock[&#39;Date&#39;] = pd.to_datetime(tesla_stock[&#39;Date&#39;])
tesla_stock.set_index(&#39;Date&#39;, inplace=True)

# 定义特征和目标变量
features = [&#39;Open&#39;, &#39;High&#39;, &#39;Low&#39;, &#39;Volume&#39;]
X = tesla_stock[features]
y = tesla_stock[target_column]

# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)

# 训练线性回归模型
model = LinearRegression()
model.fit(X_train, y_train)

# 进行预测
predicted = model.predict(X_test)

# 评估模型
print(&quot;模型得分 (R²)：&quot;, model.score(X_test, y_test))
print(&quot;平均绝对误差：&quot;, metrics.mean_absolute_error(y_test, predicted))
print(&quot;均方误差：&quot;, metrics.mean_squared_error(y_test, predicted))
print(&quot;均方根误差：&quot;, math.sqrt(metrics.mean_squared_error(y_test, 
predicted)))

# 绘制测试集的实际价格与预测价格
dfr = pd.DataFrame({&#39;Actual&#39;: y_test, &#39;Predicted&#39;: predicted})
plt.figure(figsize=(14, 8))
dfr.head(25).plot(kind=&#39;bar&#39;, figsize=(14, 8))
plt.title(&quot;实际价格与预测价格&quot;)
plt.xlabel(&quot;样本&quot;)
plt.ylabel(&quot;价格 (USD)&quot;)
plt.xticks(rotation=45, ha=&quot;right&quot;)
plt.tight_layout()
plt.show()

# 预测未来 30 天
last_date = tesla_stock.index[-1] # 历史数据中的最后一个日期
last_price = tesla_stock[target_column].iloc[-1] # 历史数据中的最后一个价格
future_dates = [last_date + datetime.timedelta(days=i) for i in range(1, 31)] # 
生成未来 30 天

# 创建占位符 DataFrame用于未来特征
future_features = pd.DataFrame(index=future_dates)
for feature in features:
if feature in tesla_stock.columns:
future_features[feature] = tesla_stock[feature].mean() # 使用每个特征的平均值

# 使用训练模型预测未来价格
future_predictions = model.predict(future_features)

# 结合历史和未来数据，绘制无缝图
all_dates = list(tesla_stock.index) + list(future_dates) # 结合历史和未来日期
all_prices = list(tesla_stock[target_column]) + list(future_predictions) # 结合历史和预测价格

# 绘制历史数据和未来预测
plt.figure(figsize=(14, 8))
plt.plot(tesla_stock.index, tesla_stock[target_column], label=&#39;历史价格&#39;, 
color=&#39;blue&#39;)
plt.plot(future_dates, future_predictions, label=&#39;30 天未来预测&#39;, 
color=&#39;red&#39;)
plt.title(&#39;特斯拉未来 30 天股价预测&#39;)
plt.xlabel(&#39;日期&#39;)
plt.ylabel(&#39;价格 (美元)&#39;)
plt.legend()
plt.xticks(rotation=45)
plt.show()

# 显示未来预测
future_features[&#39;Predicted_Close&#39;] = future_predictions
print(future_features[[&#39;Predicted_Close&#39;]])

输入图片描述在这里
我试图让红线连接到图表的末端，然后弯曲到它所在的位置。而不是一开始就只是一条随机的短红线，因为它看起来有点混乱。我一直在尝试这样做，但我真的很难做到。怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/79218937/how-to-make-this-graph-look-a-bit-neater</guid>
      <pubDate>Sat, 23 Nov 2024 22:00:52 GMT</pubDate>
    </item>
    <item>
      <title>抱抱脸生成方法后内存增加</title>
      <link>https://stackoverflow.com/questions/79218644/memory-increasing-after-hugging-face-generate-method</link>
      <description><![CDATA[我想使用 huggingface 中的 codegemma 模型进行推理，但当我使用 model.generate(**inputs) 方法时，无论 max_token_len 数量是多少，使用 torch profiler 时，GPU 内存成本在峰值使用量中都会从 39 GB 增加到 49 GB。我理解我们需要在推理和上下文中保存模型的激活，例如 4096 个输入标记，但我不敢相信它可以增加 10 GB 的推理内存使用量。有人能解释一下这是怎么回事吗？
]]></description>
      <guid>https://stackoverflow.com/questions/79218644/memory-increasing-after-hugging-face-generate-method</guid>
      <pubDate>Sat, 23 Nov 2024 19:21:47 GMT</pubDate>
    </item>
    <item>
      <title>错误：TypeError：无法将 cuda:0 设备类型张量转换为 numpy。首先使用 Tensor.cpu() 将张量复制到主机内存</title>
      <link>https://stackoverflow.com/questions/79218508/error-typeerror-cant-convert-cuda0-device-type-tensor-to-numpy-use-tensor-c</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79218508/error-typeerror-cant-convert-cuda0-device-type-tensor-to-numpy-use-tensor-c</guid>
      <pubDate>Sat, 23 Nov 2024 18:04:55 GMT</pubDate>
    </item>
    <item>
      <title>如何在处理 EOS 代币时计算拥抱人脸模型的教师强制准确度 (TFA)？</title>
      <link>https://stackoverflow.com/questions/79209319/how-to-compute-teacher-forced-accuracy-tfa-for-hugging-face-models-while-handl</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79209319/how-to-compute-teacher-forced-accuracy-tfa-for-hugging-face-models-while-handl</guid>
      <pubDate>Thu, 21 Nov 2024 00:25:48 GMT</pubDate>
    </item>
    <item>
      <title>xgboost.plot_tree：二元特征解释</title>
      <link>https://stackoverflow.com/questions/52314401/xgboost-plot-tree-binary-feature-interpretation</link>
      <description><![CDATA[我构建了一个 XGBoost 模型，并试图检查各个估计量。作为参考，这是一个二元分类任务，具有离散和连续输入特征。输入特征矩阵是 scipy.sparse.csr_matrix。
然而，当我去检查一个单独的估计量时，我发现很难解释二元输入特征，例如下面的 f60150。最底部图表中的实值 f60150 很容易解释 - 其标准在该特征的预期范围内。但是，对二元特征 &lt;X&gt; &lt; -9.53674e-07 进行的比较没有意义。这些特征中的每一个要么是 1，要么是 0。-9.53674e-07 是一个非常小的负数，我想这只是 XGBoost 或其底层绘图库中的一些浮点特性，但当特征始终为正时使用这种比较是没有意义的。有人能帮我理解哪个方向（即 是、缺失 与 否 对应这些二进制特征节点的哪一侧为真/假吗？
这是一个可重现的示例：
import numpy as np
import scipy.sparse
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer
from xgboost import plot_tree, XGBClassifier
import matplotlib.pyplot as plt

def booleanize_csr_matrix(mat):
&#39;&#39;&#39; 将具有正整数元素的稀疏矩阵转换为 1 &#39;&#39;&#39;
nnz_inds = mat.nonzero()
keep = np.where(mat.data &gt; 0)[0]
n_keep = len(keep)
result = scipy.sparse.csr_matrix(
(np.ones(n_keep), (nnz_inds[0][keep], nnz_inds[1][keep])),
shape=mat.shape
)
返回结果

### 设置数据集
res = fetch_20newsgroups()

text = res.data
outcome = res.target

### 使用 CountVectorizer 的默认参数创建初始计数矩阵
vec = CountVectorizer()
X = vec.fit_transform(text)

# 是否“布尔化”输入矩阵
booleanize = True

# 是否在“布尔化”之后将数据类型转换为与 `vec.fit_transform(text)` 返回的内容相匹配
to_int = True

如果 booleanize 和 to_int:
X = booleanize_csr_matrix(X)
X = X.astype(np.int64)

# 使其成为二元分类问题
y = np.where(outcome == 1, 1, 0)

# 随机状态确保我们能够一致地比较树及其特征
model = XGBClassifier(random_state=100)
model.fit(X, y)

plot_tree(model, rankdir=&#39;LR&#39;); plt.show()

将 booleanize 和 to_int 设置为 True 并运行上述程序，将生成以下图表：

将 booleanize 和 to_int 设置为 False 并运行上述程序，将生成以下图表：

哎呀，即使我做了一个非常简单的例子，我也会得到“正确”的结果，无论 X 或 y 是整数还是浮点类型。
X = np.matrix(
[
[1,0],
[1,0],
[0,1],
[0,1],
[1,1],
[1,0],
[0,0],
[0,0],
[1,1],
[0,1]
]
)

y = np.array([1,0,0,0,1,1,1,0,1,1])

model = XGBClassifier(random_state=100)
model.fit(X, y)

plot_tree(model, rankdir=&#39;LR&#39;); plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/52314401/xgboost-plot-tree-binary-feature-interpretation</guid>
      <pubDate>Thu, 13 Sep 2018 13:06:06 GMT</pubDate>
    </item>
    </channel>
</rss>