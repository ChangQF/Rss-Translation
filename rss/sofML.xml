<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 20 May 2024 01:02:26 GMT</lastBuildDate>
    <item>
      <title>我想将分位数回归转换为线性规划问题，我该如何解决这个问题</title>
      <link>https://stackoverflow.com/questions/78504275/i-want-to-convert-quantile-regression-into-a-linear-programming-problem-how-can</link>
      <description><![CDATA[我想要分位数回归（转换为线性规划问题，使用sklearn方法解决，但不使用sklearn代码，需要重写，并且不能使用库）代码，klearn是一个软件的界面来解决，有什么解决办法吗？
我尝试使用sklean中的代码，但发现最后是用软件解决的，而且没有解决的代码]]></description>
      <guid>https://stackoverflow.com/questions/78504275/i-want-to-convert-quantile-regression-into-a-linear-programming-problem-how-can</guid>
      <pubDate>Mon, 20 May 2024 00:41:50 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析是否适用于 HU 矩特征</title>
      <link>https://stackoverflow.com/questions/78504177/is-principal-component-analysis-applicable-to-hu-moments-features</link>
      <description><![CDATA[我试图改进使用 Hue 矩作为特征的图像分类应用程序的结果，但是当我应用 pca 时，只有一个特征可以弥补方差的 0.95。
我执行了以下步骤以原始 Hu 特征来查找投影矩阵：

标准化
计算协方差
使用 Eigen 库查找特征向量和值
选择构成方差 0.8 的特征向量并丢弃其余部分。
结果是一个 1 到 X 矩阵（只有一个特征覆盖方差的 0.98）
]]></description>
      <guid>https://stackoverflow.com/questions/78504177/is-principal-component-analysis-applicable-to-hu-moments-features</guid>
      <pubDate>Sun, 19 May 2024 23:29:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么在多元线性回归中计算梯度时要对矩阵进行转置？</title>
      <link>https://stackoverflow.com/questions/78504139/why-is-the-matrix-transposed-when-calculating-the-gradient-in-a-multiple-linear</link>
      <description><![CDATA[我正在参加在线机器学习课程，在谈论多元线性回归时，他们使用以下函数来计算梯度：
def 渐变(X, Y, w):
   返回 2 * np.matmul(X.T, (预测(X, w) - Y)) / X.shape[0]

X 是包含数据的矩阵，Y 是包含结果的单列矩阵，w 是包含权重的单列矩阵。 Predict(W, w) 返回模型在当前权重下的预测，其格式与 Y 相同。
我熟悉使用函数的偏导数来查找模型与该权重的局部最小值的接近程度的想法，但我无法理解为什么需要对 X 矩阵进行转置表格来进行此计算。我可以计算每个偏导数并将其用作单独的梯度吗？]]></description>
      <guid>https://stackoverflow.com/questions/78504139/why-is-the-matrix-transposed-when-calculating-the-gradient-in-a-multiple-linear</guid>
      <pubDate>Sun, 19 May 2024 23:04:23 GMT</pubDate>
    </item>
    <item>
      <title>没有数据标准化的PCA比标准化后的性能更好，为什么？</title>
      <link>https://stackoverflow.com/questions/78504113/pca-without-data-normalization-performes-better-than-after-normalization-why</link>
      <description><![CDATA[我有这个 spotify 数据集，其中包含大约 100k 条记录和 28 个数字（离散和连续）和二进制混合的特征，一些数字变量具有如此多的零值。
我想执行机器学习分类，对 113 个流派进行分类，这太多了。我想使用强大的主成分分析来改进我的模型。但我很困惑为什么标准化数据（我使用 Standard Scaler）的准确率比未标准化的数据差得多。
首先，在数据预处理之后，我执行简单的决策树分类器（在超参数调整之后）并获得 43% 的准确率。

然后我执行主成分分析 (PCA) 以减少特征数量，这样我就可以对数据进行聚类以减少类的数量，并更轻松地检测和可视化异常值。

据我所知，在部署 PCA 之前，我的数据需要进行标准化（我在这里使用了 StandardScaler）。然而我发现，如果不进行归一化，我的决策树分类器使用 1 维 PCA 的性能可以提高到 51%。相反，如果进行归一化，2 维的准确率会降低到只有 5%，这里我需要进行归一化。


这怎么可能呢？我如何提高算法性能？
我的代码

pca = PCA(n_components=20) # 我在这里尝试了许多值，因为随着组件数量的增加，准确率会提高
pca.fit(X_train_norm)
X_train_pca = pca.transform(X_train_norm)

# 决策树
X_test_pca = pca.transform(X_test_norm)

dt = DecisionTreeClassifier(min_samples_leaf = 3,random_state=42)
dt.fit(X_train_pca, y_train)

y_pred = dt.predict(X_test_pca)

print(&#39;Accuracy %s&#39; % accuracy_score(y_test, y_pred))
print(&#39;F1-score %s&#39; % f1_score(y_test, y_pred, average=None))
print(classification_report(y_test, y_pred))

pca_all = PCA(n_components=25)
pca_all.fit(X_train_norm)
X_train_pca = pca_all.transform(X_train_norm)
explained_variance = pca_all.explained_variance_ratio_

plt.figure(figsize=(10, 6))
plt.bar(range(len(explained_variance)), explained_variance, alpha=0.7, align=&#39;center&#39;, 
label=&#39;个体解释方差&#39;)
plt.step(range(len(explained_variance)), np.cumsum(explained_variance), where=&#39;mid&#39;, 
label=&#39;累积解释方差&#39;)
plt.xlabel(&#39;主成分索引&#39;)
plt.ylabel(&#39;解释方差比&#39;)
plt.legend(loc=&#39;best&#39;)
plt.title(&#39;经过归一化后的主成分解释方差&#39;)
plt.grid()
plt.show()


我附上了标准化后（圆形）和未标准化（肘形）的 pca 数据分布。颜色代表流派。另外，我的 PCA 的方差可解释性 [pca_without_normalization](https://i.sstatic.net/HaDoNROy.png)pca_with_normalizationpca_explanability_without_normalization]]></description>
      <guid>https://stackoverflow.com/questions/78504113/pca-without-data-normalization-performes-better-than-after-normalization-why</guid>
      <pubDate>Sun, 19 May 2024 22:44:16 GMT</pubDate>
    </item>
    <item>
      <title>定义数字手写识别问题的自动机[关闭]</title>
      <link>https://stackoverflow.com/questions/78504083/defining-an-automata-for-the-digits-handwritten-recognition-problem</link>
      <description><![CDATA[大家好，你们能帮帮我吗？我仍然不知道如何定义我的自动机，以及它与手写识别过程之间的关系是什么？基本上，我在定义转换、状态和字母方面遇到了问题。
这是使用 tensorflow 和 MNIST 数据集进行手写数字识别的代码，但如何定义我的自动机呢？
`import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = tf.keras.utils.normalize(x_train, axis=1)
x_test = tf.keras.utils.normalize(x_test, axis=1)

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))
model.add(tf.keras.layers.Dense(128, 激活=tf.nn.relu))
model.add(tf.keras.layers.Dense(128, 激活=tf.nn.relu))
model.add(tf.keras.layers.Dense(128, 激活=tf.nn.relu))
model.add(tf.keras.layers.Dense(10, 激活=tf.nn.softmax))
model.compile(optimizer=&#39;adam&#39;,
loss=&#39;sparse_categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])
model.fit(x_train, y_train, epochs=20)
model.save(&#39;handwritten.model&#39;)

model = tf.keras.models.load_model(&#39;handwritten.model&#39;)
loss, accuracy = model.evaluate(x_test, y_test)`
print(loss)
print(accuracy)

img = cv2.imread(&#39;img.5.png&#39;)[:,:,0]
img = cv2.resize(img, (28, 28))
img = np.invert(np.array([img]))
prediction = model.predict(img)
print(f&quot;该数字可能是 {np.argmax(prediction)}&quot;)
plt.imshow(img[0], cmap=plt.cm.binary)
plt.show()`
]]></description>
      <guid>https://stackoverflow.com/questions/78504083/defining-an-automata-for-the-digits-handwritten-recognition-problem</guid>
      <pubDate>Sun, 19 May 2024 22:26:28 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型的小批量实现的奇怪情节模式</title>
      <link>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</guid>
      <pubDate>Sun, 19 May 2024 19:05:35 GMT</pubDate>
    </item>
    <item>
      <title>文本到 Openpose 和奇怪的 RNN 错误</title>
      <link>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</link>
      <description><![CDATA[我想创建一个人工智能，它可以根据文本描述生成 openpose，例如，如果输入“a man running”输出将类似于我提供的图像有没有为我推荐的模型架构？
我的数据状况是

canvas_width：900px
canvas_height：300px
帧数：5（5 人）

预期输出
我尝试训练 RNN 来完成此任务，并使用句子转换器来嵌入文本，然后传递给 RNN，损失如下图所示
from Sentence_transformers import SentenceTransformer
Sentence_model = SentenceTransformer(“all-MiniLM-L6-v2”)
text = “一个男人在奔跑”
text_input = torch.tensor(sentence_model.encode(text), dtype=torch.float)

损失图像，num_layers=3
我的 RNN 设置
&lt;前&gt;&lt;代码&gt;embedding_dim = 384
隐藏暗淡 = 512
层数 = 3
输出暗度 = 180
纪元数 = 100
学习率 = 0.001
rnn_model = RNN(embedding_dim,hidden_​​dim,num_layers,output_dim)

但问题是无论我输入什么，输出每次都是一样的！但是当我尝试将 num_layers 更改为 1 并保持其他设置相同时，如下所示
&lt;前&gt;&lt;代码&gt;embedding_dim = 384
隐藏暗淡 = 512
层数 = 1
输出暗度 = 180
纪元数 = 100
学习率 = 0.001
rnn_model = RNN(embedding_dim,hidden_​​dim,num_layers,output_dim)

损失现在看起来像这样
损失图像 num_layers=1
现在问题消失了！！
我还尝试检查“每次输出都相同”的原因问题我检查了数据加载器和其他代码，但没有发现问题，只有 num_layers=3 导致问题 num_layers=1 修复了它
这是我的训练循环
标准 = nn.MSELoss()
优化器 = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)

trainingEpoch_loss = []
validepoch_loss = []

对于范围内的纪元（num_epochs）：
步骤损失=[]
rnn_model.train()
对于 idx，枚举中的 train_inputs(train_dataloader)：
优化器.zero_grad()
输出 = rnn_model(torch.unsqueeze(train_inputs[&#39;text&#39;], dim=0))
训练损失 = 标准（输出，train_inputs[&#39;poses&#39;]）
Training_loss.backward()
优化器.step()
step_loss.append(training_loss.item())

if (idx+1) % 1 == 0: print (f&#39;Epoch [{epoch+1}/{num_epochs}], 步骤 [{idx+1}/{len(train_dataloader)}], 损失: {training_loss.项目():.4f}&#39;)
TrainingEpoch_loss.append(np.array(step_loss).mean())

rnn_model.eval()
对于 idx，枚举中的 val_inputs(val_dataloader)：
验证步骤损失 = []
输出 = rnn_model(torch.unsqueeze(val_inputs[&#39;text&#39;], dim=0))
val_loss = 标准(输出, val_inputs[&#39;poses&#39;])
validStep_loss.append(val_loss.item())
validationEpoch_loss.append(np.array(validationStep_loss).mean())

这是我的推论
text = “一个男人正在奔跑”
processed_text = torch.tensor(sentence_model.encode(text), dtype=torch.float)
output_poses = rnn_model(processed_text.unsqueeze(0))
print(output_poses.shape) #shape=(1, 180) 1 人是 36 （1 人的原始数据是 54，但我改为 36，因为我只想要 x 和 y 而不是 z，所以剪掉 z 轴）并且有5 人所以 5*36 = 180

我的问题是

除了 RNN 之外，还有适合此任务的任何模型架构推荐吗？
为什么无论我输入什么，每次 num_layers=3 时输出都是相同的，我很困惑，因为如果模型给出相同的输出，损失不会下降，对吗？这意味着它在推理阶段给出相同的输出

预期答案

最适合我的任务的模型架构，任何与我相关的论文或 github 存储库都将受到赞赏
回答为什么当 num_layers=3 时，无论我输入什么，每次输出都是相同的
]]></description>
      <guid>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</guid>
      <pubDate>Sun, 19 May 2024 17:37:20 GMT</pubDate>
    </item>
    <item>
      <title>'无法解析方法'startActivity（Intent）''和'无法解析MainActivity上的构造函数'Intent（MainActivity，Class<CombineLettersActivity>）''[重复]</title>
      <link>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</link>
      <description><![CDATA[我正在按照此播放列表开发手语翻译应用。
我遇到以下错误：
无法解析方法“startActivity(Intent)”
无法解析构造函数“Intent（MainActivity，Class）”
无法解析构造函数“Intent（MainActivity，Class）”
以下是相关代码片段：
&lt;前&gt;&lt;代码&gt;@Override
protected void onCreate(Bundle savingInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    camera_button = findViewById(R.id.camera_button);
    camera_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看v）{
            startActivity(new Intent(MainActivity.this, CameraActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });

    merge_letter_button = findViewById(R.id.combine_letter_button);
    merge_letter_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看视图）{
            startActivity(new Intent(MainActivity.this，CombineLettersActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });
}


我尝试更改 Gradle 和 JDK 版本，但问题仍然存在。与我一起参与该项目的一位朋友也尝试解决该问题，但我们尚未成功。
任何帮助将不胜感激。感谢您的时间和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</guid>
      <pubDate>Sun, 19 May 2024 15:03:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 CoLab 中仅运行部分代码</title>
      <link>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</link>
      <description><![CDATA[我目前正在做一个图像识别项目，模型执行之前的预处理步骤需要相当长的时间。当模型出现错误时，我必须从头开始重新运行所有内容，这是非常耗时的。有没有办法避免从头开始运行整个流程而只执行模型部分？
如果代码没有从头开始执行，则初始部分中的包安装和标签部分将无法正常运行。]]></description>
      <guid>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</guid>
      <pubDate>Sun, 19 May 2024 14:37:50 GMT</pubDate>
    </item>
    <item>
      <title>如何判断我的数据是否服从高斯分布？[关闭]</title>
      <link>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</link>
      <description><![CDATA[我正在遵循一些有关进行线性回归的教程，并且在构建笔记本时，我正在研究异常值检测，并且在用于进行异常值检测的技术中，其中之一涉及计算标准偏差，但是对于我需要知道我的列是否属于高斯分布。我知道有不同的技术，例如：
直方图
KDE 图
Q-Q图
科洛莫戈洛夫-斯米尔诺夫检验
夏皮罗-威尔克检验
达戈斯蒂诺和皮尔逊检验
我敢打赌还有更多。那么什么是最好用的呢？我想直方图只是提供了线索，但并没有显示出真正的意图。识别数据集是否为高斯分布的标准做法是什么？例如，我绘制了波士顿数据集和 RM 列的直方图（每个住宅的平均房间数），我发现它是高斯分布：

但是当我使用 shapiro 和 kstest 时，它说 RM 不是高斯！
对于 X.columns 中的 i：
    print(f&#39;{i}: {“非高斯” if shapiro(X[i])[1]&lt;0.05 else “高斯”} {shapiro(X[i])}&#39;)
    print(f&#39;{i}: {“非高斯” if kstest(X[i].values,“范数”)[1]&lt;0.05 else “高斯”} {kstest(X[i].values) ,“标准”)}&#39;)

上面的代码打印：
RM：非高斯 ShapiroResult（统计=0.9608722575483464，pvalue=2.411976537849353e-10）
RM：非高斯 KstestResult（统计=0.9998152774582629，pvalue=0.0，statistic_location=3.561，statistic_sign=-1）

怎么会这样呢？我应该相信什么？]]></description>
      <guid>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</guid>
      <pubDate>Sun, 19 May 2024 14:15:12 GMT</pubDate>
    </item>
    <item>
      <title>如何解决pickle.load()中的内存错误？</title>
      <link>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</link>
      <description><![CDATA[with open(r&#39;..\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
    glove_embedding = pickle.load（fp）

回溯（最近一次调用最后一次）
    [39] 中的单元格，第 2 行
          1 以 open(r&#39;D:\NuVision\Sentiment Analysis\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
    ----&gt; 2 glove_embedding = pickle.load(fp)
    
    内存错误：

glove.pkl 大约有 3 GB，如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</guid>
      <pubDate>Sun, 19 May 2024 13:24:24 GMT</pubDate>
    </item>
    <item>
      <title>名称特征不匹配 ML</title>
      <link>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</guid>
      <pubDate>Sun, 19 May 2024 05:37:27 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中却不行 [关闭]</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 python 写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def preprocess_image(image_path):
    # 想象中的卡里卡
    img = Image.open(图像路径)
    # 在 scala di grigi 中进行想象和转换
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将 l&#39;immagine 转换为 un array numpy 并将 Ridimensiona 转换为 un unico vettare
    img_array = np.array(img).reshape(1, -1)
    返回img_array
*强调文字*
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;成功模型&quot;)
    # 模型用途
    # Carica e pre-elabora un&#39;immagine
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # Prevedere la classe del nuovo esempio
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

在橙色工作流程中，我使用了逻辑回归，该模型的准确性相当高。在图像嵌入中我使用了 Inception v3。 这是我获取数据集的位置。我认为我预处理图像的方式有问题，也许它与Orange方法不同，但我无法解决问题 这是橙色工作流程的图像。
编辑：我还尝试在输入中提供一个图像文件夹，结果并不总是相同，但在包含 500 张猫和狗照片的文件夹中，模型只能识别 10 只狗（对绝大多数狗进行错误分类）]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    <item>
      <title>使用梯度下降时，线性回归模型的训练误差和测试误差非常相似[关闭]</title>
      <link>https://stackoverflow.com/questions/78480089/the-training-error-and-testing-error-is-very-similiar-for-linear-regression-mode</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78480089/the-training-error-and-testing-error-is-very-similiar-for-linear-regression-mode</guid>
      <pubDate>Tue, 14 May 2024 18:43:35 GMT</pubDate>
    </item>
    <item>
      <title>如何将FastAI分类器集成到sklearn VotingClassifier中？</title>
      <link>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</link>
      <description><![CDATA[我有一堆表格数据，我成功地训练了一个 RandomForestClassifier、一个 GradientBoostingClassifier 和一个深度学习模型（来自 fastai 的表格学习器代码&gt;) 与他们一起。我在结果中注意到，每个模型在特定标签上都比其他模型做得更好，每个模型都不同。我想知道是否可以将所有模型放入 VotingClassifier （来自 sklearn 的模型）。我对 RandomForestClassifier 和 GradientBoostingClassifier 没有任何问题，但我没有找到任何有关将表格学习器放入 VotingClassifier 中的信息。可以这样做吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</guid>
      <pubDate>Mon, 06 May 2024 07:21:01 GMT</pubDate>
    </item>
    </channel>
</rss>