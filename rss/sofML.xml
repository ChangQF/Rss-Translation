<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 14 Dec 2023 21:12:01 GMT</lastBuildDate>
    <item>
      <title>使用 Keras/Tensorflow 约束神经网络损失函数</title>
      <link>https://stackoverflow.com/questions/77662709/constraint-a-neural-network-loss-function-with-keras-tensorflow</link>
      <description><![CDATA[我想创建一个具有多变量结果的神经网络来预测单变量目标。损失函数是指向目标的每个网络结果的均方根之和。我想施加一个正交约束，即每个网络结果必须与所有其他网络结果和目标变量之间的误差正交。我构建了一个自定义损失函数（具有两个网络结果的示例：
def custom_loss(y_true, y_pred):
    # 每个结果的均方误差
    mse1 = tf.keras.losses.mean_squared_error(y_true, y_pred[0])
    mse2 = tf.keras.losses.mean_squared_error(y_true, y_pred[1])


    ortho_loss = K.mean( (y_pred[1] - K.mean(y_pred[1])) * ((y_pred[0] - y_true) - K.mean(y_pred[0] - y_true)) )





    ＃ 总体损耗
    总损失 = mse1 + mse2 + K.mean(1*tf.keras.activations.relu(ortho_loss - 0)) + K.mean(1*tf.keras.activations.relu(-ortho_loss + 0))

    返回总损失

但它没有提供令人满意的结果。如果这可行的话有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77662709/constraint-a-neural-network-loss-function-with-keras-tensorflow</guid>
      <pubDate>Thu, 14 Dec 2023 19:48:13 GMT</pubDate>
    </item>
    <item>
      <title>决策树中的成本复杂性修剪</title>
      <link>https://stackoverflow.com/questions/77662692/cost-complexity-pruning-in-decision-tree</link>
      <description><![CDATA[修剪
您好，在决策尝试的背景下，特别是在成本复杂性修剪中，在下面的演示中（如图所示），我不明白为什么我们用 R 替换 R(T−Tt) − R(T) (t)−R(Tt) 以及为什么我们替换 |f(T−Tt)| - |f(T)| 1 − |f(Tt)|
非常感谢！
我试图理解替换，但没有找到答案。]]></description>
      <guid>https://stackoverflow.com/questions/77662692/cost-complexity-pruning-in-decision-tree</guid>
      <pubDate>Thu, 14 Dec 2023 19:45:36 GMT</pubDate>
    </item>
    <item>
      <title>寻求在大学环境中实施上下文感知聊天机器人的建议[关闭]</title>
      <link>https://stackoverflow.com/questions/77662419/seeking-advice-for-implementing-a-context-aware-chatbot-in-a-university-setting</link>
      <description><![CDATA[我正在深入研究为我的大学创建上下文感知聊天机器人的世界，利用包含常见问题解答和大学信息的小型 QA 数据集。
我遇到了各种方法，并且正在寻求社区的建议。以下是我正在考虑的一些选择：

NLP 库
AIML
信息检索
文档索引
NER（命名实体识别）
针对质量检查微调预训练的 BERT
序列到序列模型
TF-IDF
弹性搜索
Rasa 聊天机器人框架
机器学习（SVM、NN 等）
深度学习（RNN、BiLSTM、LSTM 或 GRU）
管道方法

此外，我有兴趣开发一种架构，使我能够在部署后轻松添加新的问答或更新现有的问答。我还希望聊天机器人能够从用户交互中学习，包括积极和消极的反应。
您的见解和经验非常宝贵！请分享您的提示和建议。]]></description>
      <guid>https://stackoverflow.com/questions/77662419/seeking-advice-for-implementing-a-context-aware-chatbot-in-a-university-setting</guid>
      <pubDate>Thu, 14 Dec 2023 18:41:46 GMT</pubDate>
    </item>
    <item>
      <title>提高 Keras 中预测比特币价格趋势的 LSTM 模型准确性</title>
      <link>https://stackoverflow.com/questions/77662382/improving-lstm-model-accuracy-for-predicting-bitcoin-price-trends-in-keras</link>
      <description><![CDATA[我目前正在开展一个项目，在该项目中，我使用 Keras 中的 LSTM（长短期记忆）模型来预测比特币价格的趋势。然而，我正在努力解决模型的准确性，尽管尝试了各种超参数，但似乎无法提高它。
这是我的模型的结构：
从 keras.models 导入顺序
从 keras.layers 导入 LSTM，密集

模型=顺序（）
model.add(LSTM(50, 激活=&#39;relu&#39;, input_shape=(n_steps, n_features)))
model.add(密集(1))
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)

# n_steps和n_features是根据历史比特币价格数据定义的

我使用历史比特币价格数据（在 0 和 1 之间标准化）进行训练。
尽管尝试了不同数量的神经元、添加层并尝试各种激活函数，但模型的损失并未按预期减少，并且对价格趋势的预测也不准确。
我想知道在我为预测比特币价格趋势的特定应用构建 LSTM 的方式中是否缺少一些基本的东西。这可能是我预处理数据的方式有问题，还是有更适合这种时间序列预测的模型架构或超参数集？
任何有关提高模型准确性或调试此性能问题的意见或建议将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77662382/improving-lstm-model-accuracy-for-predicting-bitcoin-price-trends-in-keras</guid>
      <pubDate>Thu, 14 Dec 2023 18:34:02 GMT</pubDate>
    </item>
    <item>
      <title>即使使用 IQR 方法去除异常值。数据中仍然存在异常值</title>
      <link>https://stackoverflow.com/questions/77662142/even-though-removing-the-outliers-using-the-iqr-method-the-outliers-are-still-p</link>
      <description><![CDATA[我使用箱线图方法找到了数据中的异常值。
在此处输入图像描述应用 IQR 方法之前的箱形图
&lt;前&gt;&lt;代码&gt;file1.shape
# (457, 11)

我已对数据应用了 IQR 方法。
q1, q2, q3 = file1[&#39;工资&#39;].quantile([0.25, 0.5, 0.75])
IQR = q3 - q1
f_data = file1[(file1[&#39;工资&#39;] &gt; lower_bound) &amp; (file1[&#39;工资&#39;] &lt; upper_bound)]

我删除了一些数据点。
&lt;前&gt;&lt;代码&gt;f_data.shape
# (420, 11)

但是，在使用箱线图查看过滤后的数据后，我仍然在数据中发现了一些异常值。
在此处输入图像描述应用 IQR 方法后的箱线图。
我现在应该做什么。
我是否必须对过滤后的数据再次执行 IQR 方法？
薪资数据是右偏数据。其偏差值约为 1.5
或者我应该减少倾斜值。就像使用 log、power 方法一样。]]></description>
      <guid>https://stackoverflow.com/questions/77662142/even-though-removing-the-outliers-using-the-iqr-method-the-outliers-are-still-p</guid>
      <pubDate>Thu, 14 Dec 2023 17:45:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorFlow.js，我无法通过 model.fit 检查输入时出现错误：预期密集_Dense1_输入具有 3 个维度</title>
      <link>https://stackoverflow.com/questions/77661932/using-tensorflow-js-i-cant-get-through-model-fit-error-when-checking-input-exp</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77661932/using-tensorflow-js-i-cant-get-through-model-fit-error-when-checking-input-exp</guid>
      <pubDate>Thu, 14 Dec 2023 17:09:40 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中面临的困难[关闭]</title>
      <link>https://stackoverflow.com/questions/77661689/facing-difficulty-in-ml</link>
      <description><![CDATA[请帮助我，我在机器学习概念方面遇到困难
希望这个社区的人们能够支持
请帮助我，我在 ML 概念方面遇到困难
希望这个社区的人们能够支持
请帮助我，我在 ML 概念方面遇到困难
期望这个社区的人们支持]]></description>
      <guid>https://stackoverflow.com/questions/77661689/facing-difficulty-in-ml</guid>
      <pubDate>Thu, 14 Dec 2023 16:32:46 GMT</pubDate>
    </item>
    <item>
      <title>获取构建轮子的要求...错误</title>
      <link>https://stackoverflow.com/questions/77661546/getting-requirements-to-build-wheel-error</link>
      <description><![CDATA[我正在尝试安装这个：
https://huggingface.co/microsoft/speecht5_tts
我成功地成功了（费了很大的劲才安装了变压器库）。
但现在当我运行这个命令时：
pip install --upgrade Transformers Sentpiece 数据集[音频]

我收到此错误：
收集句子
  使用缓存的 Sentpiece-0.1.99.tar.gz (2.6 MB)
  安装构建依赖项...完成
  **获取构建轮子的要求...错误**
  错误：子进程退出并出现错误
  
  × 获取构建 Wheel 的需求未成功运行。
  │ 退出代码：1
  ╰─&gt; [31行输出]
      回溯（最近一次调用最后一次）：
        文件“C:\Projects\TerrainGenerator\My project\Assets\StreamingAssets\python\.venv\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 353 行，在  中
          主要的（）
        文件“C:\Projects\TerrainGenerator\My project\Assets\StreamingAssets\python\.venv\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 335 行，在 main 中
          json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Projects\TerrainGenerator\My project\Assets\StreamingAssets\python\.venv\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 118 行，位于 get_requires_for_build_wheel
          返回钩子（config_settings）
                 ^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 325 行，在 get_requires_for_build_wheel 中
          返回 self._get_build_requires(config_settings, requests=[&#39;wheel&#39;])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 295 行，位于 _get_build_requires 中
          self.run_setup()
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 480 行，在 run_setup 中
          超级（_BuildMetaLegacyBackend，自我）.run_setup（setup_script = setup_script）
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 311 行，在 run_setup 中
          执行（代码，局部变量（））
        文件“”，第 126 行，在  中。
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 408 行，在 check_call 中
          retcode = 调用(*popenargs, **kwargs)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 389 行，调用中
          将 Popen(*popenargs, **kwargs) 作为 p：
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 1026 行，位于 __init__ 中
          self._execute_child(args, 可执行文件, preexec_fn, close_fds,
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 1538 行，位于 _execute_child
          hp, ht, pid, tid = _winapi.CreateProcess(可执行文件, args,
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      FileNotFoundError: [WinError 2] 系统找不到指定的文件
      [输出结束]

  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：子进程退出并出现错误

我使用以下命令安装了wheel：pip installwheel，它表示成功。
我正在 Windows 上的 VS Code 中尝试。]]></description>
      <guid>https://stackoverflow.com/questions/77661546/getting-requirements-to-build-wheel-error</guid>
      <pubDate>Thu, 14 Dec 2023 16:10:36 GMT</pubDate>
    </item>
    <item>
      <title>如何为此模型创建 Sagemaker 端点？</title>
      <link>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-model</link>
      <description><![CDATA[我创建了一个 VectorDB (FAISS) 并将 PDF 输入到其中。然后我使用 AWS Bedrock 的 Langchain 包装器来调用它。我知道现在存在 Kowledge Base，但至少在 SageMaker 笔记本中，我有更多的控制权。该模型在 SageMaker Notebook 中完美运行，当我提出问题时，它会返回答案。
我想做的是创建一个小网页（并通过 HTTP/REST API），只需在文本字段中提交问题并在文本字段中接收答案。我猜如果链中某个地方没有 Lambda 函数，这很难做到，或者也许不是？
当我查看 Sagemaker 控制台的推理选项卡时，没有模型或端点或端点配置（因为我没有从 Sagemaker 选择模型，我只是使用 langchain LLM 和Python 笔记本中的基岩如下）。
如何创建 Sagemaker 端点（然后将 Lambda 函数和 API 网关指向）才能提供问题并返回以下问题的答案：
&lt;前&gt;&lt;代码&gt;导入boto3
导入 json

bedrock = boto3.client(service_name=&quot;bedrock&quot;)
bedrock_runtime = boto3.client(service_name=“bedrock-runtime”)



从 langchain.llms.bedrock 导入 Bedrock
从 langchain.chains 导入 RetrievalQA
从 langchain.prompts 导入 PromptTemplate

嵌入 = BedrockEmbeddings(model_id=“amazon.titan-embed-text-v1”,
                               客户端=bedrock_runtime）

最终我将文档嵌入到 FAISS Vector 数据库中，我查询的就是这个数据库
db = FAISS.from_documents（文档，嵌入）


模型泰坦 = {
    “最大令牌计数”：512，
    “停止序列”：[]，
    “温度”：0.0，
    “顶部P”：0.5
}

# 亚马逊泰坦模型
llm = 基岩(
    model_id=&quot;amazon.titan-text-express-v1&quot;,
    客户端=bedrock_runtime，
    model_kwargs=model_titan,
）

然后定义一个提示......
提示 = 提示模板(
    template=prompt_template, input_variables=[“上下文”, “问题”]
）

并查询数据库：
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type=“东西”，
    检索器=db.as_retriever(
        search_type=“相似度”，
    ),
    return_source_documents=真，
    chain_type_kwargs={“提示”: 提示},
）



query =“未来的技术是什么样的？”

结果 = qa({“查询”: 查询})

print(f&#39;查询: {结果[“查询”]}\n&#39;)
print(f&#39;结果: {结果[“结果”]}\n&#39;)
print(f&#39;上下文文档：&#39;)
对于结果 [“source_documents”] 中的 srcdoc：
      打印（f&#39;{srcdoc}\n&#39;）

这恰好返回了我在 Sagemaker 中需要的内容，我只需要从外部查询数据库即可。]]></description>
      <guid>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-model</guid>
      <pubDate>Thu, 14 Dec 2023 14:49:20 GMT</pubDate>
    </item>
    <item>
      <title>稀疏的专家组合如何将每个令牌分别路由给专家？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77660328/how-does-a-sparse-mixture-of-experts-route-each-token-separately-to-an-expert</link>
      <description><![CDATA[据我所知，稀疏门控混合专家层中的路由机制&lt; /a&gt; 将每个标记路由到其自己的专家。考虑到注意力层的输出是一个三维张量（batch_size、seq_len、embd_dim），特别是考虑到每个批次都应该独立处理，这个路由是如何发生的？
据我所知，稀疏门控混合专家层中的路由机制&lt; /a&gt; 将每个标记路由到其自己的专家。考虑到注意力层的输出是一个三维张量（batch_size、seq_len、embd_dim），特别是考虑到每个批次都应该独立处理，这个路由是如何发生的？
由于序列长度未预先确定，如何才能运行这种类型的路由？]]></description>
      <guid>https://stackoverflow.com/questions/77660328/how-does-a-sparse-mixture-of-experts-route-each-token-separately-to-an-expert</guid>
      <pubDate>Thu, 14 Dec 2023 12:58:02 GMT</pubDate>
    </item>
    <item>
      <title>当使用人工智能模型预测某些东西时，是否可以使用用户输入的特征值进行预测？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77659839/when-predict-something-using-ai-model-is-it-possible-to-predict-with-user-input</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.ensemble 导入 RandomForestRegressor

# 读取Excel文件
data = pd.read_excel(“input.xlsx”)

# 房屋特征数据
X_train = data.iloc[1:57, 0:6].values # 第 2 行到第 57 行第 1 到第 6 列的特征数据
y_train = data.iloc[1:57, 6].values # 第 7 列第 2 行到第 57 行的因变量

# 创建随机森林回归模型
模型 = RandomForestRegressor()

# 训练模型
model.fit(X_train, y_train)

# 获取用户输入的外壳规格
sd = float(input(&quot;请输入到地铁的距离：&quot;))
Fp = float(input(&quot;请输入高楼层的溢价：&quot;))
Aa = float(input(&quot;请输入专属区域：&quot;))
Ba = float(input(&quot;请输入土地面积：&quot;))
Rp = float(input(&quot;请输入实际成交价格：&quot;))
O = float(input(&quot;请输入房屋年龄：&quot;))

# 预测房屋的合理价格
X_new = [[Ba, Aa, Sd, Rp, O, Fp]]
预测价格 = model.predict(X_new)

# 显示预测的合理价格
print(&quot;房屋的预测合理价格：&quot;,predicted_price)


这是 input.xlsx 文件的示例。
通常，在使用 AI 模型时，众所周知，会将数据分为训练集和测试集，利用训练数据来预测测试数据的值。
但是，我希望用户直接输入特征值，以便 AI 模型可以预测目标值。这可能吗？
而且，如果只输入六个特征中的三个，会起作用吗？
因为当有人输入他想要的特征值时，他通常不太了解土地面积、高层溢价等信息，...
预处理是否必要？]]></description>
      <guid>https://stackoverflow.com/questions/77659839/when-predict-something-using-ai-model-is-it-possible-to-predict-with-user-input</guid>
      <pubDate>Thu, 14 Dec 2023 11:33:45 GMT</pubDate>
    </item>
    <item>
      <title>使用回归分析图像的相似度百分比</title>
      <link>https://stackoverflow.com/questions/77658841/similarity-percentage-on-images-using-regression</link>
      <description><![CDATA[我正在开发一个项目，该项目对包含两种花卉的数据集使用分类和回归：雏菊和向日葵。我已经成功地应用随机森林分类来找到每个测试图像的类别，但我的问题是如何使用回归来显示图像与每个类别共享的相似度百分比？（例如雏菊图片为 87%雏菊和 13% 向日葵）。我知道回归不是最好的方法，但我将其作为一项作业来做，所以我必须这样做。
我尝试过随机森林回归器和 scikit-learn predict_proba 东西，但我的程序完全冻结了，所以我猜我做错了什么。
这是与我的问题相关的代码片段：
# 将列表转换为 numpy 数组
test_images = np.array(test_images)
test_labels = np.array(test_labels)
test_probabilities = classifier.predict_proba(test_images)

# 为测试集创建交互式图像查看器
图像查看器类：
    def __init__(自身、图像、真实标签、预测概率):
        self.images = 图像
        self.true_labels = true_labels
        自我预测概率 = 预测概率
        自我索引 = 0

        self.fig, self.ax = plt.subplots()
        self.display_image()

        self.next_button = 按钮(plt.axes([0.7, 0.02, 0.1, 0.05]), &#39;下一个&#39;)
        self.next_button.on_clicked(self.next_image)

        plt.show()

    def display_image(自身):
        img = self.images[self.index].reshape(256, 256, 3)
        true_class = self.true_labels[self.index]
        预测概率=自我.预测概率[自我.索引]

        self.ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        self.ax.set_title(f&quot;真: {true_class}\n预测概率: {predicted_probs}&quot;)
        self.ax.axis(&#39;关闭&#39;)

    def next_image(自身, 事件):
        self.index = (self.index + 1) % len(self.images)
        self.display_image()
        plt.draw()

# 初始化测试集的图像查看器
test_image_viewer = ImageViewer（测试图像，测试标签，测试概率）

这段代码不显示任何内容，正如我所说，我也在同一个程序中使用分类，但它工作正常，直到我添加回归。另外，我显示图像的方式有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77658841/similarity-percentage-on-images-using-regression</guid>
      <pubDate>Thu, 14 Dec 2023 08:55:16 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow_federated.python.simulation”没有属性“from_clients_and_fn”</title>
      <link>https://stackoverflow.com/questions/77657875/attributeerror-module-tensorflow-federated-python-simulation-has-no-attribute</link>
      <description><![CDATA[&lt;块引用&gt;
将 pandas 导入为 pd
将tensorflow_federated导入为tff
df = pd.DataFrame({
&#39;用户 ID&#39;: [1, 1, 2, 3],
&#39;产品 ID&#39;: [2, 3, 1, 2],
&#39;购买&#39;: [1, 0, 1, 0],
&#39;浏览&#39;: [0, 1, 0, 1]
})
数据 = {}
对于 df.groupby(“user_id”) 中的 user_id、user_data：
购买 = user_data[user_data[“购买”] == 1][“product_id”].tolist()
browsers = user_data[user_data[“browse”] == 1][“product_id”].tolist()
data[user_id] =（购买、浏览）
client_data = [data[user_id] for data中的user_id]
client_ids = [str(i) for i in range(len(client_data))]
tff_data = tff.simulation.datasets.TestClientData(client_data, client_ids)
数据集 = tff_data.create_tf_dataset_for_client(tff_data.client_ids[0])
我在最后一步中遇到问题，AttributeError: module &#39;tensorflow_federated.python.simulation&#39; has no attribute &#39;from_clients_and_fn&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/77657875/attributeerror-module-tensorflow-federated-python-simulation-has-no-attribute</guid>
      <pubDate>Thu, 14 Dec 2023 05:05:24 GMT</pubDate>
    </item>
    <item>
      <title>根据提示对 NLP 任务进行分类？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77657539/classifying-nlp-tasks-based-on-prompts</link>
      <description><![CDATA[我正在致力于创建一个聊天机器人。我被分配的任务是“根据提示对 NLP 任务进行分类”。例如确定用户请求是总结文本还是翻译段落。
我在 Google 上搜索过，但没有找到明确的答案。您能否建议如何完成这项任务或分享任何相关的研究资源？]]></description>
      <guid>https://stackoverflow.com/questions/77657539/classifying-nlp-tasks-based-on-prompts</guid>
      <pubDate>Thu, 14 Dec 2023 02:48:18 GMT</pubDate>
    </item>
    <item>
      <title>SEEM 模型在向其传递图像及其推理时面临的问题</title>
      <link>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</link>
      <description><![CDATA[我正在研究 SEEM 模型，这是一种可推广的交互式模型，用于一次性分割图像中任何地方的所有内容。由于资源有限，我在将图像传递给它及其推理时面临问题。我已经安装了所有依赖项并单独加载了 SEEM 模型。有谁对此有任何想法并相应地指导我。
我期待有人可以根据他们的知识指导我，我可以解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</guid>
      <pubDate>Wed, 13 Dec 2023 04:53:29 GMT</pubDate>
    </item>
    </channel>
</rss>