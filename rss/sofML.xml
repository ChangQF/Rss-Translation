<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 01 Jan 2024 21:12:36 GMT</lastBuildDate>
    <item>
      <title>正确处理具有可选成员（可以没有）的模型？</title>
      <link>https://stackoverflow.com/questions/77743228/handling-models-with-optional-members-can-be-none-properly</link>
      <description><![CDATA[我有 torch.nn.Module 的子类，其初始化程序具有以下形式：
（A类）
def __init__(self,additional_layer=False):
    ...
    如果附加层：
        self.additional = nn.Sequential(nn.Linear(8,3)).to(self.device)
    别的：
        self.additional = 无
    ...
    ...

我使用additional_layer=True 进行训练，并使用torch.save 保存模型。我保存的对象是model.state_dict()。然后我加载模型进行推理。但后来我收到以下错误：
model.load_state_dict(best_model[“my_model”])

RuntimeError：加载 A 的 state_dict 时出错：
        state_dict 中出现意外的键：“additional.0.weight”

是否使用了不允许为 None 的可选字段？如何正确处理这个问题？ [还发布在此处]]]></description>
      <guid>https://stackoverflow.com/questions/77743228/handling-models-with-optional-members-can-be-none-properly</guid>
      <pubDate>Mon, 01 Jan 2024 20:21:44 GMT</pubDate>
    </item>
    <item>
      <title>输入类型不支持 ufunc“isnan”，并且根据转换规则“安全”，无法将输入安全地强制为任何受支持的类型</title>
      <link>https://stackoverflow.com/questions/77743214/ufunc-isnan-not-supported-for-the-input-types-and-the-inputs-could-not-be-safe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77743214/ufunc-isnan-not-supported-for-the-input-types-and-the-inputs-could-not-be-safe</guid>
      <pubDate>Mon, 01 Jan 2024 20:14:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么 GridSearchCV 无法搜索最佳参数？</title>
      <link>https://stackoverflow.com/questions/77743145/why-gridsearchcv-cant-search-best-param</link>
      <description><![CDATA[我开始创建我的 KNN 分类器模型机器学习，并且我使用 GridSearchCV 来搜索最佳邻居数量
knn = KNeighborsClassifier()
grid_params = {&#39;n_neighbors&#39;: 范围(1,30)}
网格 = GridSearchCV(估计器=knn, param_grid=grid_params, cv=5, 评分=&#39;准确度&#39;)
grid.fit(X_train, y_train)
#------------------------
model_knn = grid.best_estimator_
model_knn.fit(X_train, y_train)
pred_knn = model_knn.predict(X_test)
print(&#39;param&#39;, grid.best_params_)
print(&#39;准确度&#39;,准确度(y_test, pred_knn))

输出：
参数5
准确度0.66
但是
如果我将邻居编号为 22，则准确度将为 71。
有人可以告诉我为什么吗？为什么 GridSearchCV 无法搜索最佳参数？
我已经尝试了所有方法，但 GridSearch 不起作用]]></description>
      <guid>https://stackoverflow.com/questions/77743145/why-gridsearchcv-cant-search-best-param</guid>
      <pubDate>Mon, 01 Jan 2024 19:47:15 GMT</pubDate>
    </item>
    <item>
      <title>有哪些语音转文本 API（例如耳语）？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77742951/what-are-some-speech-to-text-apis-like-whisper</link>
      <description><![CDATA[所以我需要为我的项目提供语音转文本功能。它需要是多语言的（特别是印地语和英语）
我尝试过耳语 - openAI 和它的拥抱版本。基础版本和中等版本效果最好，因为我需要高精度和快速响应。但问题是，当我使用英语以外的语言时，基础版本比我想要的更不准确。另一方面，Medium 具有出色的准确性，但需要的时间太长。还有哪些其他 API 可以替代 Whisper ??]]></description>
      <guid>https://stackoverflow.com/questions/77742951/what-are-some-speech-to-text-apis-like-whisper</guid>
      <pubDate>Mon, 01 Jan 2024 18:36:34 GMT</pubDate>
    </item>
    <item>
      <title>每当我将其输入到从终端打开的 Jupyter Notebook 中时，它都会返回错误，提示 fastbook 不存在</title>
      <link>https://stackoverflow.com/questions/77742926/whenever-i-type-this-into-my-jupyter-notebook-opened-from-my-terminal-it-return</link>
      <description><![CDATA[当我输入以下内容时：
&lt;前&gt;&lt;代码&gt;
＃隐藏
！ [ -e /内容 ] &amp;&amp; pip install -Uqq fastbook
导入快本
fastbook.setup_book()


它返回到我的 jupyter 笔记本中
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ModuleNotFoundError Traceback（最近一次调用最后一次）
第 3 行 [4] 中的单元格
      1 #隐藏
      2 get_ipython().system(&#39;[ -e /content ] &amp;&amp; pip install -Uqq fastbook&#39;)
----&gt; 3 导入快本
      4 fastbook.setup_book()

ModuleNotFoundError：没有名为“fastbook”的模块

我该怎么办
我在 Kaggle 或 colab 上尝试过，但发生了同样的事情。]]></description>
      <guid>https://stackoverflow.com/questions/77742926/whenever-i-type-this-into-my-jupyter-notebook-opened-from-my-terminal-it-return</guid>
      <pubDate>Mon, 01 Jan 2024 18:28:57 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器重建效果更好，但 AUC 分数更差 [关闭]</title>
      <link>https://stackoverflow.com/questions/77742912/autoencoder-better-reconstruction-but-worse-auc-score</link>
      <description><![CDATA[我编写了两个用于 Jet 重建的自动编码器，一个 MLP 和一个 CNN。在一半数据集（标签 = 0）上训练网络并将测试样本传递到经过训练的网络后，CNN 在每个测试样本上的 MSE 比 MLP 网络低得多。然而，在测试 AUC 分数时，MLP 可以更好地区分样本。 AUC 分数约为。 MLP 的 AUC 分数约为 0.8，而 CNN 的 AUC 分数约为 0.8。 0.5。
我不太确定如何解释这一点。我将其解释为 CNN 擅长重建两个数据集，即使只接受了一种类型的训练，因此它是一个糟糕的分类器。另一方面，MLP 在未经训练的数据集上重建效果较差，因此它可以更好地区分两个数据集。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/77742912/autoencoder-better-reconstruction-but-worse-auc-score</guid>
      <pubDate>Mon, 01 Jan 2024 18:20:46 GMT</pubDate>
    </item>
    <item>
      <title>关于python包tensorflow和keras [关闭]</title>
      <link>https://stackoverflow.com/questions/77741657/about-python-packages-tensorflow-and-keras</link>
      <description><![CDATA[从tensorflow.keras.models导入顺序。即使我安装了tensorflow和keras也无法导入Sequential
尝试解决问题任何人都可以帮助我解决问题
错误是tensorflow.keras.models无法解析]]></description>
      <guid>https://stackoverflow.com/questions/77741657/about-python-packages-tensorflow-and-keras</guid>
      <pubDate>Mon, 01 Jan 2024 10:50:42 GMT</pubDate>
    </item>
    <item>
      <title>“DataFrame”对象没有属性“c”</title>
      <link>https://stackoverflow.com/questions/77741177/dataframe-object-has-no-attribute-c</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77741177/dataframe-object-has-no-attribute-c</guid>
      <pubDate>Mon, 01 Jan 2024 06:55:48 GMT</pubDate>
    </item>
    <item>
      <title>Python 将结果转换为可下标的问题[关闭]</title>
      <link>https://stackoverflow.com/questions/77740671/trouble-with-python-converting-result-to-subscriptable</link>
      <description><![CDATA[我正在尝试使用转换 API 将 PDF 转换为图像，然后遇到可下标的错误。
这是一个深度学习应用
from dotenv import load_dotenv
将streamlit导入为st
从 PIL 导入图像
将 google.generativeai 导入为 genai
导入convertapi
导入操作系统
导入io
导入临时文件

Convertapi.api_secret = &#39;秘密密钥&#39;
genai.configure(api_key=&#39;秘密密钥&#39;)

def get_gemini_response_from_pdf(input_prompt, pdf_images, input2):
    model2 = genai.GenerativeModel(&#39;gemini-pro-version&#39;)
    响应2 = model2.generate_content([input_prompt, pdf_images[0], input2])
    返回response2.text

def Convert_pdf_to_images(上传文件):
    尝试：
        temp_file = f“tmp{uploaded_file.name}”
        以 open(temp_file, &#39;wb&#39;) 作为文件：
            文件.write(uploaded_file.read())

        结果 = Convertapi.convert(&#39;jpg&#39;, {&#39;文件&#39;: temp_file}, from_format=&#39;pdf&#39;)
        if result[&#39;response&#39;][&#39;status&#39;] == &#39;Ok&#39;:
            返回结果[&#39;文件&#39;]
        别的：
            st.write(f&quot;转换失败: {result[&#39;response&#39;][&#39;message&#39;]}&quot;)
            返回 []
    除了异常 e：
        st.write(f“将 PDF 转换为图像时出错：{e}”)
        返回 []

st.set_page_config(page_title=&quot;使用人工智能的文档阅读器&quot;)
st.header(“这是我使用人工智能的文档阅读器”)

input_prompt2 = “””
               您是理解护照、银行对账单和资产金融投资等文件的专家。
               您将收到护照、银行对账单、发票以及资产和金融投资的输入 pdf 文件。
               您必须根据输入图像回答问题
               ”“”
input2 = st.text_input(&quot;PDF文档输入提示：&quot;, key=&quot;input2&quot;)
uploaded_file2 = st.file_uploader(&quot;上传 PDF 文件&quot;, type=&quot;pdf&quot;)
pdf_图像 = []

如果 uploaded_file2 不是 None：
    pdf_images = 转换 pdf_to_images(uploaded_file2)
    对于 pdf_images 中的 img_data：
        img_bytes = img_data[&#39;数据&#39;]
        图像 = Image.open(io.BytesIO(img_bytes))
        st.image(图像, 标题=“转换后的图像”, use_column_width=True)
    
    Submit_pdf = st.button(“生成 Pdf 响应”)
    如果提交_pdf：
        响应2 = get_gemini_response_from_pdf(input_prompt2, pdf_images, input2)
        st.subheader(“响应是”)
        st.write(响应2)

我不确定，我确实尝试过解决它的方法，例如使用不同的库，但它只是在处理过程中陷入困境
由于某种原因我面临同样的问题]]></description>
      <guid>https://stackoverflow.com/questions/77740671/trouble-with-python-converting-result-to-subscriptable</guid>
      <pubDate>Mon, 01 Jan 2024 00:17:09 GMT</pubDate>
    </item>
    <item>
      <title>splitfolders python库仅创建文件夹-里面没有内容</title>
      <link>https://stackoverflow.com/questions/77739197/splitfolders-python-library-only-creating-folders-no-content-inside</link>
      <description><![CDATA[我正在尝试创建瑜伽姿势预测
我的数据集文件夹结构是
数据集：

1级
---img1
---img2
2 级

导入分割文件夹
input_folders =“/数据集”
输出文件夹=“/Spilted_Dataset”
splitfolders.ratio（输入=输入文件夹，输出=输出文件夹，种子= 1337，比率=（.8，.1，.1），group_prefix =无）

但是创建的文件夹只有子文件夹train、test、valid
里面没有图片
我想要文件夹 train 、 test 、 valid 以及特定类中的图像]]></description>
      <guid>https://stackoverflow.com/questions/77739197/splitfolders-python-library-only-creating-folders-no-content-inside</guid>
      <pubDate>Sun, 31 Dec 2023 12:54:47 GMT</pubDate>
    </item>
    <item>
      <title>我无法解决数据科学案例研究[关闭]</title>
      <link>https://stackoverflow.com/questions/77737223/i-cant-solve-data-science-case-study</link>
      <description><![CDATA[我正在尝试为 nlp 预处理数据。它说
使用可迭代设置时必须具有相同的 len 键和值
 filter_sentence.append(lemmatizer.lemmatize(word)) print(filter_sentence) df.loc[index,&#39;Negative_Review&#39;]= filter_sentence]]></description>
      <guid>https://stackoverflow.com/questions/77737223/i-cant-solve-data-science-case-study</guid>
      <pubDate>Sat, 30 Dec 2023 19:51:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的决策树只有一个节点？</title>
      <link>https://stackoverflow.com/questions/77737156/why-does-my-decision-tree-just-have-one-node</link>
      <description><![CDATA[我必须使用 R 创建决策树。
您可以在这里找到我正在使用的数据集 - https:/ /www.kaggle.com/datasets/iamsouravbanerjee/customer-shopping-trends-dataset
清理数据集后，这些是我在项目中使用的变量。这个新数据集被称为“GroupAgrePref”。 （附图）。

变量“颜色”创建它的目的是为了替换之前仅 3 个类别“暖色”、“中性”、“冷色”中存在的所有不同颜色。
变量“AgeGroup”也是如此。我创建了将所有年龄段分为“青少年”、“成人”、“老年人”3 个类别的方法。使用以下公式：
subdata$Group.Age &lt;- cut(subdata$Age, Breaks = c(17,30,50,71),labels = c(“青少年”,“成人”,“老年人” ;))

所有变量都是因素。
下一步是创建训练数据集：
train &lt;- GroupAgePref[sample(1:nrow(GroupAgePref),3120),]

然后是决策树：
Tree_1 &lt;- rpart(公式 = 类别 ~ ., 数据 = 训练)

但是当我想用 rpart.plot 以图形方式查看它时，就会发生这种情况：
rpart.plot(arbol_1, box.palette = “红色”)


为什么会发生这种情况？
我正在尝试预测“类别”根据性别、季节、年龄组和颜色购买的衣服。]]></description>
      <guid>https://stackoverflow.com/questions/77737156/why-does-my-decision-tree-just-have-one-node</guid>
      <pubDate>Sat, 30 Dec 2023 19:24:21 GMT</pubDate>
    </item>
    <item>
      <title>媒体管道是否与深脸一起使用进行人脸识别以获得更好的准确性</title>
      <link>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</link>
      <description><![CDATA[我使用深脸进行识别，但准确性不好，所以我尝试实现媒体管道，在​​其中提取地标，因此我将其交给深脸以获得更好的准确性。有什么办法可以做到这一点吗？
我从媒体管道中提取特征向量，但如何将其传递到深层脸部？有什么可行的方法吗？
是否使用媒体管道地标进行深度面部识别以提高准确性？]]></description>
      <guid>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</guid>
      <pubDate>Thu, 28 Dec 2023 09:38:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 mediapipe 进行实时手语翻译</title>
      <link>https://stackoverflow.com/questions/77537666/real-time-sign-language-translator-with-mediapipe</link>
      <description><![CDATA[所以，我正在用 mediapipe 制作一个手语翻译器，它工作正常，直到我举起双手，它给出以下错误：“X 有 84 个特征，但 RandomForestClassifier 期望 42 个特征作为输入” ;.我尝试了很多不同的解决方案，但到目前为止没有一个有效。
这是我正在运行的代码：
导入pickle
导入CV2
将 mediapipe 导入为 mp
将 numpy 导入为 np

model_dict = pickle.load(open(&#39;./model.p&#39;, &#39;rb&#39;))
模型 = model_dict[&#39;模型&#39;]

上限 = cv2.VideoCapture(0)

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles

手 = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)

labels_dict = {0：&#39;A&#39;，1：&#39;B&#39;，2：&#39;C&#39;，3：&#39;D&#39;，4：&#39;E&#39;，5：&#39;F&#39;，6：&#39;G&#39;，7：&#39;H&#39; , 8: &#39;I&#39;, 9: &#39;J&#39;, 10: &#39;K&#39;, 11: &#39;L&#39;,
               12：“M”、13：“N”、14：“O”、15：“P”、16：“Q”、17：“R”、18：“S”、19：“T”、20： &#39;U&#39;, 21: &#39;V&#39;, 22: &#39;W&#39;,
               23: &#39;X&#39;, 24: &#39;Y&#39;, 25: &#39;Z&#39;, 26: &#39;Middelvinger&#39;, 27: &#39;Dikke vette duim&#39;}

current_char =“niks”； # 循环中当前字符的初始化

而真实：
    尝试：
        # 初始化规则和协调
        数据辅助 = []
        x_ = []
        y_ = []

        # Lees een 框架范德网络摄像头
        ret, 框架 = cap.read()

        # Haal de hoogte，breedte en kanalen van het 框架操作
        H、W、_ = 框架.形状

        # 转换 het 帧 naar RGB 格式
        frame_rgb = cv2.cvtColor(帧, cv2.COLOR_BGR2RGB)

        # Verwerk de handen 在 het 框架中遇见了 behulp van MediaPipe Hands
        结果=手.process(frame_rgb)

        # het 框架中 handen zijn gedetecteerd 的 Controleer
        如果结果.multi_hand_landmarks：
            # 循环遍历 het 帧中的所有 geDetecteerde handen
            对于 results.multi_hand_landmarks 中的 hand_landmarks：
                # 框架内的地标设计
                mp_drawing.draw_landmarks(
                    框架，#afbeelding om opt tekenen
                    hand_landmarks, # 模型输出
                    mp_hands.HAND_CONNECTIONS, # 绑定slijnen
                    mp_drawing_styles.get_default_hand_landmarks_style(),
                    mp_drawing_styles.get_default_hand_connections_style())

            # 循环遍历 het 帧中的所有 geDetecteerde handen
            对于 results.multi_hand_landmarks 中的 hand_landmarks：
                # 遍历所有地标 (puntcoördinaten) van de hand
                对于范围内的 i(len(hand_landmarks.landmark))：
                    x = hand_landmarks.landmark[i].x
                    y = hand_landmarks.landmark[i].y

                    # Voeg de x- en y-coördinaten toe aan derespectievelijke lijsten
                    x_.append(x)
                    y_.append(y)

                # 最小 X 门协调标准化器 - en y-waarden af te trekken
                对于范围内的 i(len(hand_landmarks.landmark))：
                    x = hand_landmarks.landmark[i].x
                    y = hand_landmarks.landmark[i].y
                    data_aux.append(x - min(x_))
                    data_aux.append(y - min(y_))

            # 请注意以下事项
            x1 = int(min(x_) * W) - 10
            y1 = int(min(y_) * H) - 10

            # Voorspel het karakter met behulp van het getrainde 模型
            预测 = model.predict([np.asarray(data_aux)])
            预测字符 = labels_dict[int(预测[0])]

            # Haal de waarschijnlijkheid van de voorspelling op
            prob = model.predict_proba([np.asarray(data_aux)])
            准确度百分比 = 最大值(概率[0]) * 100

            # Toon het voorspelde karakter en de nauwkeurigheid in de linkerbovenhoek
            cv2.putText(frame, f&quot;{predicted_character} {accuracy_percentage:.2f}%&quot;, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 3, cv2.LINE_AA)

            # het karakter 的控制者是 veranderd
            如果预测字符！=当前字符：
                print(f&quot;{accuracy_percentage:.2f}% zekerheid dat het {predicted_character} is&quot;)
                当前字符 = 预测字符

        # 卡通框架在 voorspellingen 中得到了处理
        cv2.imshow(&#39;框架&#39;, 框架)
        cv2.waitKey(1)`你的文本`

    除了异常 e：
        print(f&quot;输出代码：{e}&quot;)

cap.release()
cv2.destroyAllWindows()

你们中有人知道如何解决我的问题吗？
提前致谢
我尝试了很多不同的解决方案，但到目前为止没有一个有效。我希望该程序能够同时扫描和翻译我的双手]]></description>
      <guid>https://stackoverflow.com/questions/77537666/real-time-sign-language-translator-with-mediapipe</guid>
      <pubDate>Thu, 23 Nov 2023 14:30:11 GMT</pubDate>
    </item>
    <item>
      <title>imagedatagenorator 的 .classes 方法是否已排序？</title>
      <link>https://stackoverflow.com/questions/74367878/is-the-classes-method-of-a-imagedatagenorator-sorted</link>
      <description><![CDATA[我正在尝试创建一个 CM，我已经有了 y_pred，显然我需要我的基本事实，或者我正在尝试使用 testdata.classes （这是他们在网上所做的，testdata 是 imagedatagenerator 的实例）。 
但是 .classes 似乎只是返回我所有类的排序列表，而不是与我的预测相对应的类列表。因此，我认为我得到的 CM 非常不准确。我怎样才能得到我的预测的基本事实？
下面是我对 .class 的理解的一个示例，该列表仅按 0-15 的顺序排列。顺便说一句，我的模型准确率为 95%，因此我希望它们能够更好地对齐。
我希望 y_pred 和 dataset.classes 在 95% 的情况下是相同的。
]]></description>
      <guid>https://stackoverflow.com/questions/74367878/is-the-classes-method-of-a-imagedatagenorator-sorted</guid>
      <pubDate>Tue, 08 Nov 2022 22:31:07 GMT</pubDate>
    </item>
    </channel>
</rss>