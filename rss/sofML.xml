<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 15 Jun 2024 01:04:13 GMT</lastBuildDate>
    <item>
      <title>高验证准确度 + 高损失分数和高训练准确度 + 低损失分数？</title>
      <link>https://stackoverflow.com/questions/78625247/high-validation-accuracy-high-loss-score-and-high-training-accuracy-low-loss</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78625247/high-validation-accuracy-high-loss-score-and-high-training-accuracy-low-loss</guid>
      <pubDate>Fri, 14 Jun 2024 23:05:46 GMT</pubDate>
    </item>
    <item>
      <title>训练期间存在 EarlyStopping 回调时 Keras 中的 ReduceLROnPlateau 流程图</title>
      <link>https://stackoverflow.com/questions/78624879/flowchart-of-reducelronplateau-in-keras-during-training-while-there-is-earlystop</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78624879/flowchart-of-reducelronplateau-in-keras-during-training-while-there-is-earlystop</guid>
      <pubDate>Fri, 14 Jun 2024 20:29:11 GMT</pubDate>
    </item>
    <item>
      <title>模型不适用于多类分割</title>
      <link>https://stackoverflow.com/questions/78624691/model-not-working-for-multiclass-segmentation</link>
      <description><![CDATA[我正在训练一个用于多类分割问题的模型。我有 3 个类，图像大小为 512x512 和 1 个通道。我的数据集中的类别不平衡。问题是该模型在多类分割方面表现不佳。
我尝试过交叉熵损失、Dice 损失、Jaccard 损失和损失组合（Jaccard + Focal）。
交叉熵工作正常，但结果并不令人满意。
我应该在其中进行哪些更改？
以下是模型的代码
class AxialDW(nn.Module):
def __init__(self, dim, mixer_kernel, dilation=1):
super().__init__()
h, w = mixer_kernel
self.dw_h = nn.Conv2d(dim, dim, kernel_size=(h, 1), padding=(max(h // 2, dilation), 0), groups=dim, dilation=dilation)
self.dw_w = nn.Conv2d(dim, dim, kernel_size=(1, w), padding=(0, max(w // 2, dilation)), groups=dim, dilation=dilation)

def forward(self, x):
x = x + self.dw_h(x) + self.dw_w(x)
返回 x

class EncoderBlock(nn.Module):
&quot;&quot;&quot;编码然后下采样&quot;&quot;&quot;

def __init__(self, in_c, out_c, mixer_kernel=(7, 7)):
super().__init__()
self.dw = AxialDW(in_c, mixer_kernel=(7, 7))
self.bn = nn.BatchNorm2d(in_c)
self.pw = nn.Conv2d(in_c, out_c, kernel_size=1)
self.down = nn.MaxPool2d((2, 2))
self.act = nn.GELU()

def forward(self, x):
skip = self.bn(self.dw(x))
x = self.act(self.down(self.pw(skip)))
return x, skip

class DecoderBlock(nn.Module):
&quot;&quot;&quot;上采样然后解码&quot;&quot;&quot;

def __init__(self, in_c, out_c, mixer_kernel=(7, 7)):
super().__init__()
self.up = nn.Upsample(scale_factor=2)
self.pw = nn.Conv2d(in_c + out_c, out_c, kernel_size=1)
self.bn = nn.BatchNorm2d(out_c)
self.dw = AxialDW(out_c, mixer_kernel=(7, 7))
self.act = nn.GELU()
self.pw2 = nn.Conv2d(out_c, out_c, kernel_size=1)

def forward(self, x, skip):
x = self.up(x)
x = torch.cat([x, skip], dim=1)
x = self.act(self.pw2(self.dw(self.bn(self.pw(x)))))
return x

class BottleNeckBlock(nn.Module):
&quot;&quot;&quot;轴向扩张 DW 卷积&quot;&quot;&quot;

def __init__(self, dim):
super().__init__()

gc = dim // 4
self.pw1 = nn.Conv2d(dim, gc, kernel_size=1)
self.dw1 = AxialDW(gc, mixer_kernel=(3, 3), dilation=1)
self.dw2 = AxialDW(gc, mixer_kernel=(3, 3), dilation=2)
self.dw3 = AxialDW(gc, mixer_kernel=(3, 3), dilation=3)

self.bn = nn.BatchNorm2d(4 * gc)
self.pw2 = nn.Conv2d(4 * gc, dim, kernel_size=1)
self.act = nn.GELU()

def forward(self, x):
x = self.pw1(x)
x = torch.cat([x, self.dw1(x), self.dw2(x), self.dw3(x)], 1)
x = self.act(self.pw2(self.bn(x)))
return x

class ULite(nn.Module):
def __init__(self, freeze_model, num_classes=3):
super().__init__()

&quot;&quot;&quot;Encoder&quot;&quot;&quot;
self.conv_in = nn.Conv2d(1, 16, kernel_size=7, padding=3)
self.e1 = EncoderBlock(16, 32)
self.e2 = EncoderBlock(32, 64)
self.e3 = EncoderBlock(64, 128)
self.e4 = EncoderBlock(128, 256)
self.e5 = EncoderBlock(256, 512)

“瓶颈”
self.b5 = BottleNeckBlock(512)

“解码器”
self.d5 = DecoderBlock(512, 256)
self.d4 = DecoderBlock(256, 128)
self.d3 = DecoderBlock(128, 64)
self.d2 = DecoderBlock(64, 32)
self.d1 = DecoderBlock(32, 16)
self.conv_out = nn.Conv2d(16, num_classes, kernel_size=1)

if freeze_model:
self.freeze_model()

def forward(self, x):
&quot;&quot;&quot;编码器&quot;&quot;&quot;
x = self.conv_in(x)
x, skip1 = self.e1(x)
x, skip2 = self.e2(x)
x, skip3 = self.e3(x)
x, skip4 = self.e4(x)
x, skip5 = self.e5(x)

“瓶颈” “” “”
x = self.b5(x) # (512, 8, 8)

“解码器” “” “”
x = self.d5(x, skip5)
x = self.d4(x, skip4)
x = self.d3(x, skip3)
x = self.d2(x, skip2)
x = self.d1(x, skip1)
x = self.conv_out(x)

# 应用 softmax 进行多类分类
x = F.softmax(x, dim=1)
return x

def freeze_model(self):
for name, param in self.named_pa​​rameters():
param.requires_grad = False

Jaccard + Focal Loss
Loss Image
Jaccard Loss
丢失图片]]></description>
      <guid>https://stackoverflow.com/questions/78624691/model-not-working-for-multiclass-segmentation</guid>
      <pubDate>Fri, 14 Jun 2024 19:30:25 GMT</pubDate>
    </item>
    <item>
      <title>“利用计算机视觉技术创建高效的实时人脸检测系统” [关闭]</title>
      <link>https://stackoverflow.com/questions/78624565/creating-an-efficient-real-time-face-detection-system-using-computer-vision-tec</link>
      <description><![CDATA[“如何使用现代计算机视觉技术和框架，从实时视频中创建实时人脸检测系统，确保准确性和效率？”
我期待一个结构良好的答案来消除我的疑虑，我需要任何链接供我参考。]]></description>
      <guid>https://stackoverflow.com/questions/78624565/creating-an-efficient-real-time-face-detection-system-using-computer-vision-tec</guid>
      <pubDate>Fri, 14 Jun 2024 18:51:33 GMT</pubDate>
    </item>
    <item>
      <title>是否有针对不平衡数据集的 ML 算法？</title>
      <link>https://stackoverflow.com/questions/78623027/is-there-an-ml-algorithm-for-imbalanced-dataset</link>
      <description><![CDATA[我有 3 个标签，分别是正面、负面和中性。此 ML 模型的数据是流式/批处理的。假设每个批次包含 100 个样本（batch_size=100）。我可以清楚地看到这是一个在线/增量学习问题。我的批次也有可能获得不平衡/倾斜的数据样本。例如，B1-B4 可能包含所有正面数据，B5-B10 可能包含所有负面数据，B11-B15 可能包含所有中性数据样本...
在了解用例并进行一些基础研究后，我想到在 partial_fit () 上使用 SGDClassifier 可以很好地解决我的问题。
我面临的实际困难是，在完成 15 个批次的训练（每个标签 5 个批次）后，我的模型将所有推理数据预测为最新标签。在找到根本原因后，我发现模型在最近几批训练中对最近的批次（中性样本）进行了训练，因此一切都被预测为中性。
鉴于这个困难，我还有另一个困难。我无法执行数据平衡技术，如 SMOTE、欠采样、过采样等，因为我没有接触过完整的数据集。在任何给定的时间实例中，我只能访问当前批次数据（100 个样本）和在先前批次上训练的模型（partial_fit () 模型）。
start_timer = time.time()
column_classes_lists = [np.array(sgd_model[PIPELINE_MODEL_CONSTANTS.META][PIPELINE_MODEL_CONSTANTS.CLASSES].get(key)) for key in sgd_model[PIPELINE_MODEL_CONSTANTS.META][PIPELINE_MODEL_CONSTANTS.CLASSES].keys()]

if data is not None:
kf = KFold(n_splits = PREDICTOR_CONSTANTS.NUM_FOLDS)
y_predictions, y_actual = [], []
# target_df = pd.DataFrame(target)

for train_index, val_index in kf.split(data):
X_train_fold, X_val_fold = [data[idx] for idx in train_index], [data[idx] for idx in val_index]
y_train_fold = [[target[col][idx][0] for col in target.keys()] for idx in train_index]
y_val_fold = [[target[col][idx][0] for col in target.keys()] for idx in val_index]

sgd_model[PIPELINE_MODEL_CONSTANTS.MODEL].partial_fit(np.array(X_train_fold), y_train_fold, classes = column_classes_lists)

y_predictions.extend(sgd_model[PIPELINE_MODEL_CONSTANTS.MODEL].predict(X_val_fold))

y_actual.extend(y_val_fold)

Utils.calculate_prediction_metrics(sgd_model, target, y_actual, y_predictions, column_classes_lists, meta)
else:
Utils.calculate_prediction_metrics(sgd_model, target, None, None, column_classes_lists, meta)

logger.warning(f&quot;SGDModel 在 {time.time() - start_timer} 秒内成功训练了 id: {id}，得分指标为：{sgd_model[PIPELINE_MODEL_CONSTANTS.META][PIPELINE_MODEL_CONSTANTS.SCORES]}&quot;)
return sgd_model


除此之外，在我的训练过程中的任何时间点都可能出现新的标签。对于 partial_fit()，我们需要在第一次训练调用中传递所有可能的标签。因此，我猜 sklearn 的 partial_fit() 可能不太适合我的情况...
你能帮我找到一个用 Python 实现的针对这种情况的最佳解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/78623027/is-there-an-ml-algorithm-for-imbalanced-dataset</guid>
      <pubDate>Fri, 14 Jun 2024 12:40:42 GMT</pubDate>
    </item>
    <item>
      <title>直接在 gpu 上加载并生成 Qwen2</title>
      <link>https://stackoverflow.com/questions/78622820/direct-loading-and-generation-qwen2-on-gpu</link>
      <description><![CDATA[我想在挖矿机上部署 LLM 模型 Qwen2-7b-instruct，但由于内存存储量低（4GB RAM）和处理能力有限（2 核奔腾）等限制，我无法做到这一点。
另一方面，我的电脑不支持 CUDA 和 ROCM 技术。
矿机规格：
4x amd rx580 8GB]]></description>
      <guid>https://stackoverflow.com/questions/78622820/direct-loading-and-generation-qwen2-on-gpu</guid>
      <pubDate>Fri, 14 Jun 2024 11:58:01 GMT</pubDate>
    </item>
    <item>
      <title>在机器学习中，什么时候会对数据进行欠采样/过采样？</title>
      <link>https://stackoverflow.com/questions/78622628/at-what-point-do-you-undersample-oversample-data-in-machine-learning</link>
      <description><![CDATA[我有一个问题，关于在机器学习过程中何时应该对数据集进行欠采样或过采样。我正在处理一个包含 NaN 值的不平衡数据集（约 5% 的阳性情况）。接下来的步骤应该如何衔接？这有一般规则吗？我应该填写缺失值、重新采样数据并继续删除异常值吗？]]></description>
      <guid>https://stackoverflow.com/questions/78622628/at-what-point-do-you-undersample-oversample-data-in-machine-learning</guid>
      <pubDate>Fri, 14 Jun 2024 11:13:18 GMT</pubDate>
    </item>
    <item>
      <title>Vitas AI - AttributeError：在模型量化期间无法设置属性</title>
      <link>https://stackoverflow.com/questions/78621742/vitas-ai-attributeerror-cant-set-attribute-during-quantization-of-model</link>
      <description><![CDATA[我有一个 Python 版的 LSTM 模型，我正在尝试使用 Vitis AI (Pytorch) 将其部署到 ZCU104 板上。我在量化模型时遇到错误。我收到以下行的错误：
quantizer.export_xmodel(output_dir=&quot;quantize_result&quot;, deploy_check=True)

错误是：
[VAIQ_NOTE]: =&gt;Converting to xmodel ...

回溯（最近一次调用最后一次）：

文件“lstm_quant.py”，第 118 行，位于 &lt;module&gt;

main(args)

文件“lstm_quant.py”，第 107 行，在 main 中

quantizer.export_xmodel(output_dir=“quantize_result”，deploy_check=True)

文件“/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/apis.py”，第 148 行，在 export_xmodel 中

self.processor.export_xmodel(output_dir, deploy_check, dynamic_batch)

文件“/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/base.py”，第 368 行，在 export_xmodel 中

dump_xmodel(output_dir, deploy_check, self._lstm_app)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/base.py&quot;，第 505 行，位于 dump_xmodel

deploy_graphs, _ = get_deploy_graph_list(quantizer.quant_model, quantizer.Nndctgraph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/utils.py&quot;，第 463 行，位于 get_deploy_graph_list

return _deploy_optimize(quant_model, nndct_graph, need_pa​​rtition)

文件&quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/utils.py&quot;，第 419 行，在 _deploy_optimize

g_optmizer = DevGraphOptimizer(nndct_graph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/compile/deploy_optimizer.py&quot;，第 92 行，在 __init__

self._dev_graph.clone_from(nndct_graph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_graph.py&quot;，第133，在 clone_from 中

self._top_block.clone_from(src_graph.block, local_map, converted_nodes)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_block.py&quot;，第 47 行，在 clone_from 中

self.append_node(self.owning_graph.create_node_from(node, local_map, converted_nodes))

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_graph.py&quot;，第 161 行，在 create_node_from 中

node.clone_from(src_node, local_map)

文件&quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_node.py&quot;，第 120 行，在 clone_from 中

self.op.clone_from(src_node.op, local_map)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_operator.py&quot;，第 214 行，在 clone_from 中

setattr(self, config, new_value)

AttributeError：无法设置属性

在以下 Google 链接中附加完整错误、模型代码和量化脚本：
量化脚本：
https://docs.google.com/document/d/1jRYmPH2z70ovpc_FJIBpUQaTHUPRrTgnPVxlQJ1JLug/edit?usp=sharing
模型脚本：
https://docs.google.com/document/d/1OBZw4XhdHpVhA0gKcJn2NzR_WA7ZczQ3hL42f_sMKug/edit?usp=sharing
完整错误：
https://docs.google.com/document/d/1kI1WJqq9pp3aSsGLpNGjf22mzK6swIiZbIXwfUeTGto/edit?usp=sharing
尝试更改 base_operator.py，但没有成功。也尝试简化模型，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78621742/vitas-ai-attributeerror-cant-set-attribute-during-quantization-of-model</guid>
      <pubDate>Fri, 14 Jun 2024 08:00:33 GMT</pubDate>
    </item>
    <item>
      <title>未找到 keras.utils.PyDataset</title>
      <link>https://stackoverflow.com/questions/78621236/keras-utils-pydataset-not-found</link>
      <description><![CDATA[class BatchedDataset(tf.keras.utils.PyDataSet):
使用 keras PyDataset 时，我不断收到此错误。我尝试更新 tensorflow 并使用 tf.keras.api._v2。这些都不起作用
我正在使用 google colab
]]></description>
      <guid>https://stackoverflow.com/questions/78621236/keras-utils-pydataset-not-found</guid>
      <pubDate>Fri, 14 Jun 2024 05:43:38 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯优化中的探索与利用权衡[关闭]</title>
      <link>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</link>
      <description><![CDATA[我一直在研究贝叶斯优化，但有些事情我不太明白。我知道 BO 使用获取函数来平衡探索和利用。我们可以添加一个参数（epsilon）来调整我们想要更多的探索还是利用。但参数是如何做到的？就像 PI 和 EI 获取函数一样，为什么大的 epsilon 可以使算法更具探索性，反之亦然？]]></description>
      <guid>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</guid>
      <pubDate>Fri, 14 Jun 2024 04:07:57 GMT</pubDate>
    </item>
    <item>
      <title>在不同的 Python 环境中训练的相同 XGBClassifier 模型得出的预测结果明显不同</title>
      <link>https://stackoverflow.com/questions/78619966/the-same-xgbclassifier-model-trained-in-different-python-environment-made-notice</link>
      <description><![CDATA[我尝试将在旧的 Python 环境中训练的 XGBClassifier 模型转移到新的环境中。
以下是新旧环境中关键软件包的版本信息。
旧环境

python=3.6.0
scikit-learn==0.22.2.post1
xgboost==0.90
pickleshare==0.7.5
numpy==1.18.1

新环境

python=3.11.9
scikit-learn==1.4.2
xgboost==2.0.3
pickleshare==0.7.5
numpy==1.26.4

在新旧环境中分别使用同一组超参数和相同的数据，预测的概率明显不同。
我还注意到，拟合管道对象的大小以及训练模型所需的时间发生了显着变化。
拟合管道对象的大小旧版与新版：30 MB vs. 7 MB
训练时间旧版与新版：4:38:46 vs. 0:06:40
对于我在旧环境中训练的模型和新环境中训练的模型之间的差异，您有什么看法？
以下是我用来训练模型的关键python代码。
def create_pipeline(model_params, cat_indices):
&quot;&quot;&quot;
创建管道
:param model_params：管道中 XGBoost 分类器的模型参数
:param cat_indices：X 中分类特征的索引
&quot;&quot;&quot;

cat_transformer = Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;, fill_value=&#39;missing&#39;)),
(&#39;one_hot_encoder&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))])

preprocessor = ColumnTransformer(
transformers=[(&#39;cat&#39;, cat_transformer, cat_indices)],
remainder=&#39;passthrough&#39;)

xgb = XGBClassifier(objective=&quot;binary:logistic&quot;, eval_metric=&quot;auc&quot;, missing=np.nan, use_label_encoder=False)
xgb.set_params(**model_params)

full_pipeline_model = Pipeline(steps=[(&#39;preprocessor&#39;, preprocessor),
(&#39;model&#39;, xgb)])
return full_pipeline_model

model_params = {
&#39;n_estimators&#39;: 500,
&#39;alpha&#39;: 9.73974803929248e-06,
&#39;gamma&#39;: 19,
&#39;lambda&#39;: 0.557185777864069,
&#39;learning_rate&#39;: 0.029438952461179668,
&#39;max_depth&#39;: 13,
&#39;scale_pos_weight&#39;: 5,
&#39;subsample&#39;: 0.687206238714661
}

cat_indices = [X.columns.get_loc(col) for col in cat_cols]

fitted_pipeline = create_pipeline(model_params, cat_indices).fit(X.values, y.values)
pickle.dump(fitted_pipeline, open(&quot;fitted_pipeline_final1.pkl&quot;, &quot;wb&quot;))

我预计从两个模型获得的预测概率非常相似，因为我使用了相同的超参数集和相同的数据。预测概率明显不同的原因可能是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78619966/the-same-xgbclassifier-model-trained-in-different-python-environment-made-notice</guid>
      <pubDate>Thu, 13 Jun 2024 20:07:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 detector2 区分灰度图像中的两种颜色并掩盖它们？</title>
      <link>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</link>
      <description><![CDATA[我的项目包括使用detectron2模型来区分灰度图像中的物体。该图像由形状奇怪的灰色细胞组成，而其余空间为黑色。我的任务是使用该模型并描绘出灰色细胞的形状。
示例图像：
细胞的灰度图像
我曾尝试使用预先存在的模型来解决这个问题，但它们无法识别物体的存在。解决这个问题的最佳方法是什么？
此外，我愿意使用不同的机器学习模型。我只是想找到一种区分灰色和黑色的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</guid>
      <pubDate>Thu, 13 Jun 2024 17:36:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个 AMD GPU 运行 Ollama [关闭]</title>
      <link>https://stackoverflow.com/questions/78618964/how-to-run-ollama-with-multiple-amd-gpus</link>
      <description><![CDATA[我尝试在配备多个 AMD GPU 的系统上运行 Ollama，但在正确使用所有 GPU 时遇到了困难。
设置详细信息：

操作系统：RedHat
GPU：MI210 x 4
Ollama 版本：0.1.42
ROCm

面临的问题：

似乎只使用了一个 GPU，或者没有明显的性能改进。
[watch -n 0.1 /opt/rocm/bin/rocm-smi]
0 2 0x740f，30145 63.0°C 253.0W N/A，N/A，0 1700Mhz 1600Mhz 0% 自动 300.0W 60% 100%
1 3 0x740f，41677 28.0°C 41.0W N/A，N/A，0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%
2 4 0x740f，39309 31.0°C 40.0W N/A，N/A，0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%
3 5 0x740f, 50825 35.0°C 40.0W N/A, N/A, 0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%

问题：

我是否缺少在 Ollama 中启用多 GPU 支持的特定步骤？
在 Ollama 中，多 GPU 设置是否需要任何其他配置设置？

是否有任何指导或详细步骤可以正确设置和验证 Ollama 是否使用多个 AMD GPU？
我尝试过 /set 参数 num_gpu 12，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/78618964/how-to-run-ollama-with-multiple-amd-gpus</guid>
      <pubDate>Thu, 13 Jun 2024 15:56:57 GMT</pubDate>
    </item>
    <item>
      <title>尝试将 Kaggle 笔记本提交到 GitHub 存储库时出现错误</title>
      <link>https://stackoverflow.com/questions/78618684/getting-error-while-trying-to-commit-a-kaggle-notebook-to-a-github-repository</link>
      <description><![CDATA[提交内核时发生错误：ConcurrencyViolation 序列号必须匹配草稿记录：KernelId=59714315，ExpectedSequence=43，
ActualSequence=42，AuthorUserId=16388128

这是什么意思？
当我尝试将笔记本从 kaggle 提交到 github 时出现此错误。我该如何解决这个问题？
我原本以为它会直接提交到 github 而不会遇到任何问题]]></description>
      <guid>https://stackoverflow.com/questions/78618684/getting-error-while-trying-to-commit-a-kaggle-notebook-to-a-github-repository</guid>
      <pubDate>Thu, 13 Jun 2024 15:06:29 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 将特征重要性作为列表而不是绘图</title>
      <link>https://stackoverflow.com/questions/63060367/xgboost-get-feature-importance-as-a-list-of-columns-instead-of-plot</link>
      <description><![CDATA[我想知道是否可以将特征重要性作为列表而不是图表来获取。这就是我所拥有的
xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)
import matplotlib.pyplot as plt

xgb.plot_importance(xg_reg)
plt.rcParams[&#39;figure.figsize&#39;] = [5,5]
plt.show()

这给了我这个图

我想只获取主要特征的列表，因为我有超过 800 个不同的特征。]]></description>
      <guid>https://stackoverflow.com/questions/63060367/xgboost-get-feature-importance-as-a-list-of-columns-instead-of-plot</guid>
      <pubDate>Thu, 23 Jul 2020 17:57:31 GMT</pubDate>
    </item>
    </channel>
</rss>