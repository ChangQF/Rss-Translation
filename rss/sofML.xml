<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 07 Mar 2024 06:19:25 GMT</lastBuildDate>
    <item>
      <title>测试时无法扩展自定义环境</title>
      <link>https://stackoverflow.com/questions/78119078/cant-scale-custom-environment-when-testing</link>
      <description><![CDATA[我正在 Open AI Gym 中制作一个具有稳定基线 3 的自定义 Boid 植绒环境。
错误1：
我已经创建了环境并测试了 3 个 boids，但是当我测试 10 个 boids 时，它给出了错误：
形状错误
我从未对 boids 的数量进行硬编码，也没有其他明显的问题。
错误2：
我用 20 个不同的初始化位置测试了模型，但对于大多数情况，我得到了奖励 600200，并且它们按照预期移动。
但是，当我重新训练模型时，它的表现不佳，参数完全相似。这是一个训练有素的模型，侥幸还是过度拟合？
已测试剧集
使用不同数量的 boids 进行测试以验证错误 1。]]></description>
      <guid>https://stackoverflow.com/questions/78119078/cant-scale-custom-environment-when-testing</guid>
      <pubDate>Thu, 07 Mar 2024 06:04:41 GMT</pubDate>
    </item>
    <item>
      <title>将数据帧写入功能存储时出现 ConcurrentAppendException</title>
      <link>https://stackoverflow.com/questions/78118939/concurrentappendexception-while-writing-dataframe-to-feature-store</link>
      <description><![CDATA[我正在尝试将 Spark(pyspark) 数据帧写入特征存储
fs = FeatureStoreClient()

    尝试：
        fs.get_table(fs_name)
    除了值错误：
        fs.create_table(
            名称=文件系统名称，
            Primary_keys=pri_key_cols,
            df=df,
            时间戳_键=时间戳_列，
            描述=表描述，
            标签=tags_dict，
        ）
    别的：
        fs.write_table(name=fs_name, mode=“覆盖”, df=df)

此 Databricks 笔记本附加到 ADF 管道，当它运行时有时会出现异常并且管道失败。
ConcurrentAppendException：文件已通过并发更新添加到表的根中。请重试该操作。
冲突的提交：
]]></description>
      <guid>https://stackoverflow.com/questions/78118939/concurrentappendexception-while-writing-dataframe-to-feature-store</guid>
      <pubDate>Thu, 07 Mar 2024 05:23:31 GMT</pubDate>
    </item>
    <item>
      <title>运行带有校准的构建模型后，如何在 H2o Flow 中找到校准概率、绘图、brier 分数？</title>
      <link>https://stackoverflow.com/questions/78118859/how-can-i-find-the-calibration-probabilities-plot-brier-score-in-h2o-flow-afte</link>
      <description><![CDATA[指定在单独的校准集上使用 platt 来校准模型，但我在输出中没有看到任何与校准相关的内容。 H2o Flow 中不存在这个吗？
查看了交叉验证输出和预测输出]]></description>
      <guid>https://stackoverflow.com/questions/78118859/how-can-i-find-the-calibration-probabilities-plot-brier-score-in-h2o-flow-afte</guid>
      <pubDate>Thu, 07 Mar 2024 04:53:57 GMT</pubDate>
    </item>
    <item>
      <title>加载图像边界框输出相同大小的错误</title>
      <link>https://stackoverflow.com/questions/78118283/loading-image-bounding-boxes-outputs-equal-size-error</link>
      <description><![CDATA[这是我在这里发表的第一篇文章，如果我需要更多数据或解释，请告诉我。
我正在尝试为我的数据集创建一个 PyTorch 数据加载器。每个图像都有一定数量的汽车和每个汽车的边界框，但并非所有图像都具有相同数量的边界框。
您可能无法运行它，但这里有一些信息。
这是我的数据加载器
类 AGR_Dataset（数据集）：
    def __init__(self,annotations_root,img_root,transform=None):
        ”“”
        论据：
            annotations_root（字符串）：带有注释的 csv 文件的路径。
            img_root（字符串）：包含所有图像的目录。
            变换（可调用，可选）：要应用的可选变换
                在样品上。
        ”“”
        self.annotations_root = 注释_root
        self.img_root = img_root
        self.transform = 变换

    def __len__(自身):
        返回 len(self.annotations_root)
    
    def __getitem__(self, idx):
        # idx 可能是索引或图像名称，我认为图像 naem
        如果 torch.is_tensor(idx):
            idx = idx.tolist()
        
        idx_name = os.listdir(self.img_root)[idx]
        # 打印(idx_name)
        
        img_name = os.path.join(self.img_root, idx_name)
        Comments_data = os.path.join(self.annotations_root, f&quot;{idx_name.removesuffix(&#39;.jpg&#39;)}.txt&quot;)
        # print(img_name, 注释数据)

        图像 = io.imread(img_name)

        以 open(annotation_data, &#39;r&#39;) 作为文件：
            行= file.readlines()
            图像数据 = []
            img_标签 = []
            对于行中行：
                line = line.split(&#39;,&#39;)
                line = [i.strip() for i in line]
                line = [float(num) for num in line[0].split()]
                img_labels.append(int(行[0]))
                img_data.append(行[1:])

        框 = tv_tensors.BoundingBoxes(img_data, format=&#39;CXCYWH&#39;, canvas_size=(image.shape[0], image.shape[1]))

        # 样本 = {&#39;image&#39;: 图像, &#39;bbox&#39;: 盒子, &#39;labels&#39;: img_labels}
        样本= {&#39;image&#39;：图像，&#39;bbox&#39;：盒子}

        如果自我变换：
            样本 = self.transform(样本)

        打印（样本[&#39;图像&#39;].shape）
        打印（样本[&#39;bbox&#39;].shape）
        # print(样本[&#39;标签&#39;].shape)
        返回样品

我运行转换并创建数据加载器
data_transform = v2.Compose([
    v2.ToImage(),
    # v2.调整大小(680),
    v2.RandomResizedCrop(大小=(680, 680), 抗锯齿=True),
    # v2.ToDtype(torch.float32,scale=True),
    v2.ToTensor()
]）

Transformed_dataset = AGR_Dataset(f&#39;{annotations_path}/test/&#39;,
                        f&#39;{img_path}/测试/&#39;,
                        变换=数据变换）

数据加载器=数据加载器(transformed_dataset,batch_size=2,
                        洗牌=假，num_workers=0）

然后我尝试用它迭代它，并最终使用边界框查看和图像。
对于 i，枚举中的示例（dataloader）：
    打印（我，样本）
    print(i, 样本[&#39;image&#39;].size(), 样本[&#39;bbox&#39;].size())

    如果我==4：
        休息

批处理大小为 1 时，它运行正常，批处理大小为 2 时，出现此错误
torch.Size([3, 680, 680])
火炬.Size([12, 4])

火炬.Size([3, 680, 680])
火炬.Size([259, 4])

RuntimeError: 堆栈期望每个张量大小相等，但在条目 0 处得到 [12, 4]，在条目 1 处得到 [259, 4]


我认为这是由于边界框的数量不相等造成的，但如何克服这个问题？
我的变换中需要 ToTensor 吗？我开始认为我不这样做，因为 v2 使用 ToImage()，并且 ToTensor 正在被贬值。

如有任何其他意见或帮助，我们将不胜感激。
我不确定如何创建一个工作示例，我会继续尝试。
我尝试过的
我尝试通过注释数据加载器中的 tv_tensors.BoundingBoxes 行来不将边界框加载为张量，但由于某种原因，我的调整大小无法正常工作。
我刚刚尝试在数据加载器中像这样分割框和图像
样本 = 图像
    目标= {&#39;bbox&#39;：盒子，&#39;标签&#39;：img_labels}

运气不好]]></description>
      <guid>https://stackoverflow.com/questions/78118283/loading-image-bounding-boxes-outputs-equal-size-error</guid>
      <pubDate>Thu, 07 Mar 2024 01:30:38 GMT</pubDate>
    </item>
    <item>
      <title>TypeError: fit() 缺少 1 个必需的位置参数 Y [关闭]</title>
      <link>https://stackoverflow.com/questions/78118068/typeerror-fit-missing-1-required-positional-argument-y</link>
      <description><![CDATA[代码：
def _forward(self, x):
    self.trained_model = self.model.fit(x)
    返回 self.trained_model.labels_

我在这个项目中使用了很多模型，代码与 minibatchkmeans 和birthch 完美配合，但是在添加 kneighborclassifier 后，它开始显示错误消息，如下所示：
回溯（最近一次调用最后一次）：
  文件“E:\Desktop\customer_analysis\customer_analysis-main\main.py”，第 39 行，位于  中。
    主要的（）
  文件“E:\Desktop\customer_analysis\customer_analysis-main\main.py”，第 15 行，在 main 中
    预测标签 = cluster_model._forward(data_array)
  文件“E:\Desktop\customer_analysis\customer_analysis-main\dnn_module\dnn_model.py”，第 193 行，位于 _forward
    self.trained_model = self.model.fit(x)
类型错误：fit() 缺少 1 个必需的位置参数：&#39;y&#39;

如果我添加更多参数，例如纪元和批量大小，它会显示：
类型错误：fit() 获得意外的关键字参数“batch_size”

如果我添加另一个参数，例如 []：
self.trained_model = self.model.fit(x, [])

它会导致值错误。]]></description>
      <guid>https://stackoverflow.com/questions/78118068/typeerror-fit-missing-1-required-positional-argument-y</guid>
      <pubDate>Thu, 07 Mar 2024 00:06:38 GMT</pubDate>
    </item>
    <item>
      <title>训练预训练 CNN 模型时出现矩阵大小不兼容错误</title>
      <link>https://stackoverflow.com/questions/78116865/matrix-size-incompatible-error-while-training-a-pretrained-cnn-model</link>
      <description><![CDATA[矩阵大小不兼容：In[0]：[32,7776]，In[1]：[18816,512]
[[{{节点顺序_1/activation_1/aiRelu}}]]
[操作：__inference_train_function_3421]

值得注意的是，理解这个错误它可以在更少的数据集和更少的类的情况下顺利运行
# # 建模开始使用 CNN。

模型=顺序（）
model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = &#39;相同&#39;,activation =&#39;relu&#39;, input_shape = (224,224,3)))
model.add(MaxPooling2D(pool_size=(2,2)))


model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = &#39;相同&#39;,activation =&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))


model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = &#39;相同&#39;,activation = &#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = &#39;相同&#39;,activation =&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

模型.add(压平())
模型.add（密集（512））
model.add(激活(&#39;relu&#39;))
model.add（密集（5，激活=“softmax”））

文本]]></description>
      <guid>https://stackoverflow.com/questions/78116865/matrix-size-incompatible-error-while-training-a-pretrained-cnn-model</guid>
      <pubDate>Wed, 06 Mar 2024 19:09:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的训练损失和验证损失非常低，但新数据集的均方误差却很高？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78116573/why-my-training-loss-and-validation-loss-very-low-but-the-mse-for-a-new-dataset</link>
      <description><![CDATA[来自tensorflow.keras导入层
从tensorflow.keras.layers导入Dense
从tensorflow.keras.layers导入LSTM
从tensorflow.keras.models导入顺序
从tensorflow.keras导入正则化器

模型=顺序（[
       LSTM(单位=64, input_shape=(len(x.columns),1),
       kernel_regularizer=regularizers.l2(0.01)),
       密集(1)
     ]）
model.compile(loss=tf.keras.losses.MeanSquaredError(),optimizer=tf.keras.optimizers.Adam())
历史= model.fit（x_train，y_train，validation_data =（x_val，y_val），epochs = 100，verbose = 1，batch_size = 32）

mse=model.evaluate(x_test, y_test)
打印（毫秒）

这是我得到的损失图：

我得到的新数据集的 MSE 值非常高 (30.2344)。代码中可能存在什么问题。是否过度拟合？建议进行一些更改。]]></description>
      <guid>https://stackoverflow.com/questions/78116573/why-my-training-loss-and-validation-loss-very-low-but-the-mse-for-a-new-dataset</guid>
      <pubDate>Wed, 06 Mar 2024 18:14:44 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 与 RTX 4090 在训练时间上存在巨大差异 [关闭]</title>
      <link>https://stackoverflow.com/questions/78116561/pytorch-with-rtx-4090-huge-difference-in-training-time</link>
      <description><![CDATA[我在大学计算机上用 PyTorch 训练了一个模型 48 个 epoch，大约需要 8 分钟。
我现在在家装了一台新电脑，但训练时间明显更长，48 个 epoch 大约需要 17.5 分钟。
规格：

大学：

RTX 4090
i9-13900KF
64GB 内存


首页：

RTX 4090
i9-14900KF
48GB 内存



我在两者上使用相同的代码，并且没有更改训练的任何其他参数。
目前我已经安装：

CUDA 版本 12.4
驱动程序版本 551.61
火炬版本2.2.1+cu121
Python 3.11

在训练期间，没有一个组件得到充分利用：

内存 20/48GB
CPU 33%（70°C）
光盘 1%
GPU 50% (40°C)
显存 3.2/24GB

我使用 Cinebench、MemTest86 和 3DMark 测试了我的 CPU、GPU 和 RAM，所有测试结果均符合预期，因此硬件应该可以正常工作。游戏过程中的表现也符合预期。温度也还可以。
除了 PyCharm 之外，只有 Discord 和 Opera 正在运行，这不会显着降低训练速度。
我认为驱动程序可能存在问题，或者 torch、cuda 和驱动程序版本之间的兼容性有问题？
我还在两个系统上都做了测试，仅使用cpu进行训练。在这种情况下，我的计算机速度更快，大约为 5.5 次迭代/秒，而大学计算机大约为 2.3 次迭代/秒。那么问题一定出在 GPU 的某个地方？
您可以在此处访问测试代码。
训练在train.py中开始。]]></description>
      <guid>https://stackoverflow.com/questions/78116561/pytorch-with-rtx-4090-huge-difference-in-training-time</guid>
      <pubDate>Wed, 06 Mar 2024 18:12:11 GMT</pubDate>
    </item>
    <item>
      <title>强化学习神经网络概率没有改变</title>
      <link>https://stackoverflow.com/questions/78116374/reinforcement-learning-neural-network-probabilities-arent-changing</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78116374/reinforcement-learning-neural-network-probabilities-arent-changing</guid>
      <pubDate>Wed, 06 Mar 2024 17:35:37 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程数据错误</title>
      <link>https://stackoverflow.com/questions/78115412/gaussian-process-data-errors</link>
      <description><![CDATA[如何在ma​​tlab的fitrgp函数中插入误差数组来进行高斯过程回归？我有一个数组 x、其他数组 y 以及与 y 关联的标准差数组 delta_y。
只有 x 和 y，我可以使用 gprMdl = fitrgp(x,y)，但是如何添加delta_y作为y的错误栏？]]></description>
      <guid>https://stackoverflow.com/questions/78115412/gaussian-process-data-errors</guid>
      <pubDate>Wed, 06 Mar 2024 15:02:10 GMT</pubDate>
    </item>
    <item>
      <title>我的感知器算法总是给我错误的线来分离二维线性可分离数据</title>
      <link>https://stackoverflow.com/questions/78112634/my-perceptron-algorithm-keeps-giving-me-the-wrong-line-for-separating-2d-linearl</link>
      <description><![CDATA[我正在为虚拟 2D 数据实现感知器模型。以下是我生成数据的方式
&lt;前&gt;&lt;代码&gt;#numpoint
n = 15
#f(x) = w0 + ax1 + bx2
#那么如果f(x) = 0
#x2 = (-w0 - ax1)/b
截距 = 30
一个= 4
b = 2
#生成0-20之间的随机点
x1 = np.random.uniform(-20, 20, n) #返回一个np数组
x2 = np.random.uniform(-20, 20, n)
y = []
#绘制f(x)
plt.plot(x1, (-截距 - a*x1)/b, &#39;k-&#39;)
plt.ylabel(“x2”)
plt.xlabel(“x1”)

#绘制彩色点
对于范围内的 i(0, len(x1))：
    f = 截距 + a * x1[i] + b * x2[i]
    如果（f &lt;= 0）：
        plt.plot(x1[i], x2[i], &#39;ro&#39;)
        y.追加(-1)
    如果（f&gt;0）：
        plt.plot(x1[i], x2[i], &#39;bo&#39;)
        y.追加(1)
y = np.array(y)
# 添加x0作为阈值
x0 = np.ones(n)
stacked_x = np.stack((x0,x1,x2))
堆叠_x

这是数据的可视化
在此处输入图像描述
这是我的感知器模型
类 PLA():
    def __init__(self, numPredictors):
        self.w = np.random.rand(1,numPredictors+1) #(1, numPredictors+1)
        self.iter = 0
    def fitModel（自身，xData，yData）：
        而（真）：
            yhat = np.matmul(self.w, xData).squeeze() #从(1,n)到(,n)
            比较 = np.sign(yhat) == yData
            ind = [i for i in range(0,len(compare)) if Compare[i] == False] #分类错误的索引
            打印（长度（ind））
            如果 len(ind) == 0:
                休息
            对于 ind 中的 i：
                update = yData[i]* xData[:, i] #1d 数组
                self.w = self.w + np.transpose(update[:,np.newaxis]) #转置以匹配权重的形状
            self.iter += 1

当我可视化模型时
&lt;前&gt;&lt;代码&gt;pla1 = PLA(2)
pla1.fitModel(stacked_x, y)
#绘制彩色点
对于范围内的 i(0, len(x1))：
    如果（y[i]==-1）：
        plt.plot(x1[i], x2[i], &#39;ro&#39;)
    如果（y[i]==1）：
        plt.plot(x1[i], x2[i], &#39;bo&#39;)
plt.plot(x1, (-pla1.w[0][0] - pla1.w[0][1]*x1)/(pla1.w[0][1]), &#39;g-&#39;, 标签 = “解放军”）
plt.plot(x1, (-截距 - a*x1)/b, &#39;k-&#39;, label = &quot;f(x)&quot;)
plt.xlabel(“x1”)
plt.ylabel(“x2”)
plt.图例()

我从感知器算法得到的线是不正确的
在此处输入图像描述
这是使用不同数据参数和样本大小的另一次运行 (n = 30)
在此处输入图像描述
我尝试在每次迭代时打印出更新，它按照我的预期工作。我不确定是什么导致我的算法停止，即使仍然存在错误分类的点。我已经被这个问题困扰了几天了。我非常感谢任何意见。]]></description>
      <guid>https://stackoverflow.com/questions/78112634/my-perceptron-algorithm-keeps-giving-me-the-wrong-line-for-separating-2d-linearl</guid>
      <pubDate>Wed, 06 Mar 2024 07:53:35 GMT</pubDate>
    </item>
    <item>
      <title>torchserve ：即使 config.properties 指定其他值，batch_size 也始终为 1</title>
      <link>https://stackoverflow.com/questions/78111173/torchserve-batch-size-is-always-1-even-config-properties-specify-other-value</link>
      <description><![CDATA[我认为我的 torchserve 正确加载了 config.properties，因为我设置的工作人员数量是 2。但batch_size是1而不是20。
任何人都知道可能会出现什么问题吗？谢谢！
我已经检查并torchserve正确加载config.properties，可惜它忽略了config.properties中指定的batch_size和max_batch_delay。
这是我的 config.properties 供参考
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
log_file=/ml_server/logs/torchserve.log
default_workers_per_model=2
number_of_netty_threads=32
作业队列大小=1000
批量大小=20
最大批量延迟=10

下面是日志，worker的batchSize：1
ml-server | 2024-03-06T00：11：11,091 [信息] W-9001-model_1.0-stdout MODEL_LOG - model_name：_model，batchSize：1
机器学习服务器 | 2024-03-06T00：11：11,091 [信息] W-9000-model_1.0-stdout MODEL_LOG - model_name：_model，batchSize：1
]]></description>
      <guid>https://stackoverflow.com/questions/78111173/torchserve-batch-size-is-always-1-even-config-properties-specify-other-value</guid>
      <pubDate>Wed, 06 Mar 2024 00:19:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在 ADBench 中集成其他自定义算法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78008005/how-do-i-integrate-other-custom-algorithms-in-adbench</link>
      <description><![CDATA[我想测试不同的隔离林类型。但是，考虑到拟合/模型和运行文件，我不太明白如何将其集成到 ADB 中。特别是算法的哪一部分应该放入文件中。
有人可以给我建议或解决方案吗？
我尝试使用扩展隔离林https://github.com/ sahandha/eif/blob/master/eif_old.py。为此，我使用旧的（非 cython）版本并将其放入模型中。但是，我不确定要在运行和拟合文件中放入什么内容......]]></description>
      <guid>https://stackoverflow.com/questions/78008005/how-do-i-integrate-other-custom-algorithms-in-adbench</guid>
      <pubDate>Fri, 16 Feb 2024 14:21:16 GMT</pubDate>
    </item>
    <item>
      <title>使用记分器实现 GridSearchCV 进行留一交叉验证</title>
      <link>https://stackoverflow.com/questions/60851884/implementing-gridsearchcv-with-scorer-for-leave-one-out-cross-validation</link>
      <description><![CDATA[我正在尝试实现 scikit-learn 的 GridSearchCV 用于高斯过程回归 (GPR)。我正在使用大约 200 个点的小数据集，并且希望使用 LOOCV 作为我的模型的性能评估器。我的设置是：
来自 sklearn.model_selection 导入 *
从 sklearn.ensemble 导入 *
从 sklearn.gaussian_process 导入 *

参数网格 = {
    &#39;内核&#39;:[kernels.RBF(),kernels.Matern(length_scale=0.1)],
    &#39;n_restarts_optimizer&#39;:[5,10,20,25],
    “随机状态”：[30]
}
res_GPR = GridSearchCV(估计器=GaussianProcessRegressor(),param_grid=param_grid,cv=LeaveOneOut(),verbose=20,n_jobs=-1)
res_GPR.fit(X,y)

其中 X 和 y 分别是我的数据点和目标值。
我知道 GPR 返回的评分方法是 r^2，这对于 LOOCV 情况是无法定义的（因为只有一个测试元素） - 这是通过获取拟合模型的 .best_score_ 属性的 NaN 来验证的。
因此，我希望仅使用每个测试用例的均方根误差 (RMSE) 对模型进行评分，并对所有迭代进行平均。我怎样才能做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/60851884/implementing-gridsearchcv-with-scorer-for-leave-one-out-cross-validation</guid>
      <pubDate>Wed, 25 Mar 2020 15:22:44 GMT</pubDate>
    </item>
    <item>
      <title>如何根据组 ID 生成训练-测试-分割？</title>
      <link>https://stackoverflow.com/questions/54797508/how-to-generate-a-train-test-split-based-on-a-group-id</link>
      <description><![CDATA[我有以下数据：
 Group_ID Item_id 目标
0 1 1 0
1 1 2 0
2 1 3 1
3 2 4 0
4 2 5 1
5 2 6 1
6 3 7 0
7 4 8 0
8 5 9 0
9 5 10 1

我需要根据“Group_ID”将数据集分成训练集和测试集。这样 80% 的数据进入训练集，20% 进入测试集。
也就是说，我需要我的训练集看起来像：
 Group_ID Item_id 目标
0 1 1 0
1 1 2 0
2 1 3 1
3 2 4 0
4 2 5 1
5 2 6 1
6 3 7 0
7 4 8 0

和测试集：
 Group_ID Item_id 目标
8 5 9 0
9 5 10 1

最简单的方法是什么？据我所知，sklearn 中的标准 test_train_split 函数不支持按组拆分，而我也可以指示拆分的大小（例如 80/20）。]]></description>
      <guid>https://stackoverflow.com/questions/54797508/how-to-generate-a-train-test-split-based-on-a-group-id</guid>
      <pubDate>Thu, 21 Feb 2019 00:45:21 GMT</pubDate>
    </item>
    </channel>
</rss>