<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 15 Apr 2024 06:19:18 GMT</lastBuildDate>
    <item>
      <title>如何找到 RBF 核 SVM 的准确性？</title>
      <link>https://stackoverflow.com/questions/78325995/how-can-i-find-accuracy-in-rbf-kernal-svm</link>
      <description><![CDATA[我正在尝试使用 SVM 实现人体检测。我正在使用 HOG 特征提取，然后对其应用 SVM。当我应用线性 SVM 时，我会得到图像的分数，但在 RBF kernal SVM 中我只能得到 0 和 1。无论如何我可以获得检测分数吗？我怎样才能像线性SVM一样看到RBF核的系数？
我尝试了Python提供的SVM库。]]></description>
      <guid>https://stackoverflow.com/questions/78325995/how-can-i-find-accuracy-in-rbf-kernal-svm</guid>
      <pubDate>Mon, 15 Apr 2024 03:45:27 GMT</pubDate>
    </item>
    <item>
      <title>在 VSCode 终端中卡住“git init”</title>
      <link>https://stackoverflow.com/questions/78325941/stuck-with-git-init-in-vscode-terminal</link>
      <description><![CDATA[我开始学习 ML，为此我使用 anaconda 提示符和 vscode 终端创建了一个 conda 环境。但是，当尝试将其链接到我的 github 存储库时，出现以下错误。这是错误运行“git init”时。
我尝试检查系统中的 PATH 变量，并且 git 已添加到路径中。想不出其他什么了。任何进一步的内容都会有很大帮助，谢谢！！]]></description>
      <guid>https://stackoverflow.com/questions/78325941/stuck-with-git-init-in-vscode-terminal</guid>
      <pubDate>Mon, 15 Apr 2024 03:21:57 GMT</pubDate>
    </item>
    <item>
      <title>torch.nn.function.binary_cross_entropy 如何处理大小为 N x 2 的输出和标签？</title>
      <link>https://stackoverflow.com/questions/78325848/how-does-torch-nn-functional-binary-cross-entropy-treat-outputs-and-labels-of-si</link>
      <description><![CDATA[分类器模型输出 N x 2 数组，同样数据集的标签具有相同的形状，每一行 [-ve, +ve] 代表一个分类实例，因此如果该行是，则数组中的左列有 1真负数，右边为零&amp;反之亦然。
使用torch.nn.function.binary_cross_entropy，但我需要使用权重参数，因为这些类非常不平衡13:1 -ve:+ve。我正在使用权重数组 torch.tensor([1.,13.]) 权重 13 是否应用于数组右列的所有条目或具有 1 的所有条目与列无关？文档中不清楚实现细节。]]></description>
      <guid>https://stackoverflow.com/questions/78325848/how-does-torch-nn-functional-binary-cross-entropy-treat-outputs-and-labels-of-si</guid>
      <pubDate>Mon, 15 Apr 2024 02:35:47 GMT</pubDate>
    </item>
    <item>
      <title>在测试数据集上进行评估时，模型显示零准确度和几乎零损失？</title>
      <link>https://stackoverflow.com/questions/78325622/model-showing-zero-accuracy-and-almost-zero-loss-when-evaluated-on-the-testing-d</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78325622/model-showing-zero-accuracy-and-almost-zero-loss-when-evaluated-on-the-testing-d</guid>
      <pubDate>Mon, 15 Apr 2024 00:22:30 GMT</pubDate>
    </item>
    <item>
      <title>如何结合2种模型机器学习？</title>
      <link>https://stackoverflow.com/questions/78325594/how-to-combine-2-model-machine-learning</link>
      <description><![CDATA[我是机器学习的初学者。我有 2 个用于预测水可饮用性的机器学习模型，模型 1 使用决策树，模型 2 使用随机森林。那么如何组合该模型来制作新模型呢？我可以用它制作一个新模型吗？我使用Python编程。
组合 2 个模型来制作一个新模型。]]></description>
      <guid>https://stackoverflow.com/questions/78325594/how-to-combine-2-model-machine-learning</guid>
      <pubDate>Mon, 15 Apr 2024 00:09:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么混淆矩阵只有一个条目作为输出？</title>
      <link>https://stackoverflow.com/questions/78325205/why-is-there-one-entry-as-output-in-confusion-matrix</link>
      <description><![CDATA[我正在仅包含 10 个样本的简单数据集上应用简单的 SVM 和逻辑回归。我正在尝试打印混淆矩阵，但它只给出“array([[2]])”作为输出。
这是代码：
sc = StandardScaler()
X_scaled = sc.fit_transform(X)
X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.2,random_state=42)
LR.fit(X_train,y_train)
y_pred=LR.predict(X_test)
print(accuracy_score(y_test,y_pred))//1.0 输出
con= fusion_matrix(y_test,y_pred) //array([[2]]) 输出
con.shape//(1, 1)
我的数据集是一个二元分类问题。 （0 或 1）]]></description>
      <guid>https://stackoverflow.com/questions/78325205/why-is-there-one-entry-as-output-in-confusion-matrix</guid>
      <pubDate>Sun, 14 Apr 2024 20:43:28 GMT</pubDate>
    </item>
    <item>
      <title>预期类型为“MyEnv”，却得到“Env”</title>
      <link>https://stackoverflow.com/questions/78324963/expected-type-myenv-got-env-instead</link>
      <description><![CDATA[我已经从 OpenGym 创建了自定义环境，并且我在这一行收到了之前的警告：
env: MyEnv=gym.make(&#39;gym_envs/MyEnv-v0&#39;)

当我删除 MyEnv 时，我没有收到警告，但随后我收到警告“类‘MyEnv’的未解析属性引用‘action_type’”在下面一行：
agent = QLearningAgent(env.action_space, env.observation_space.n, env.action_type.n)

知道如何消除警告吗？
我尝试编写一个包装器来返回 ATMEnv 对象而不是 Env，但它没有解决问题]]></description>
      <guid>https://stackoverflow.com/questions/78324963/expected-type-myenv-got-env-instead</guid>
      <pubDate>Sun, 14 Apr 2024 19:12:45 GMT</pubDate>
    </item>
    <item>
      <title>Sklearm FeatureHasher 无法处理数据框中的单个列</title>
      <link>https://stackoverflow.com/questions/78324647/sklearm-featurehasher-not-working-on-a-single-column-in-a-dataframe</link>
      <description><![CDATA[我尝试在数据框中的单个列上执行特征哈希器，但它不断给出错误：
&lt;块引用&gt;
ValueError：样本不能是单个字符串。输入必须是字符串可迭代对象上的可迭代对象。

from sklearn.feature_extraction import FeatureHasher

哈希向量大小 = 50
fh = FeatureHasher(n_features=hash_vector_size, input_type=&#39;string&#39;)
hashed_df = pd.DataFrame(fh.transform(X_train[“Item_Identifier”]).toarray(),
                         columns=[&#39;H&#39;+str(i) for i in range (hash_vector_size)])

我期望一个包含 50 列的数据框，其中的数据将被散列]]></description>
      <guid>https://stackoverflow.com/questions/78324647/sklearm-featurehasher-not-working-on-a-single-column-in-a-dataframe</guid>
      <pubDate>Sun, 14 Apr 2024 17:20:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 Eigen 执行步长卷积</title>
      <link>https://stackoverflow.com/questions/78324587/using-eigen-to-perform-a-convolution-with-stride</link>
      <description><![CDATA[我试图让 Eigen 以跨步执行卷积运算（对于卷积神经网络）。我知道 Eigen 有一个可以在张量上执行的卷积函数：
input.convolve（过滤器，尺寸）

没有参数可以提供步幅值。
我知道 Eigen 还有一个步幅函数，它返回应用特定步幅的张量的视图。然而，这与（我不认为）对卷积应用步幅相同。我想知道是否可以将 stride 函数应用于输入，然后调用 convolve，但我认为这不会导致与 stride 的正确卷积。
有谁知道如何应用步幅卷积（除了手动编写卷积函数而不是依赖 Eigen 的卷积函数）？
我注意到有一个“extract_image_patches”返回输入区域列表的函数 - 这是用来代替卷积函数吗？
谢谢
我查看了 Stackoverflow 和 Cross Validated，但在任何地方都看不到这个答案。 此处提出了类似的问题，但没有得到解答。]]></description>
      <guid>https://stackoverflow.com/questions/78324587/using-eigen-to-perform-a-convolution-with-stride</guid>
      <pubDate>Sun, 14 Apr 2024 16:57:29 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 pytorch 训练机器学习多项式回归模型，在尝试绘制预测结果时出现错误</title>
      <link>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch-an</link>
      <description><![CDATA[我想将数据绘制成 plt.scatter 表单，但是当我尝试填充它时，它只是说 x 和 y 的大小不同，而且我还挤压了它们仅一维，以便更容易绘制，但仍然不起作用。
这是情节机制：
#使用 matplotlib.pyplot 中的散点图 (x,y) 可视化数据
defplot_predictions(train_features=X_train,
                     train_labels=y_train,
                     test_features=X_test,
                     测试标签=y_测试，
                     预测=无）：
    plt.figure(figsize= (10,7))

    plt.scatter(X_train, y_train, c=“g”, label=“训练数据”)

    plt.scatter(X_test, y_test, c=“b”, label=“测试数据”)

    如果预测不是 None：
        plt.scatter（test_features，预测，c =“r”，标签=“预测”）

    plt.legend(prop={“大小”: 14})

绘图预测（）

#这里检查是否存在不匹配的形状
X_train.shape、y_train.shape、y_preds.shape

#output (torch.Size([24, 1]), torch.Size([24, 1]), torch.Size([24, 1]))
#这里尝试解决问题
Predictions_reshape=y_preds.squeeze(dim=1)
labels_reshape=y_train.squeeze(dim=1)
打印（len（y_train），len（y_preds））
打印（labels_reshape.shape，predictions_reshape.shape）

＃输出
#24 24
#torch.Size([24]) torch.Size([24])
#torch.Size([6, 1]) torch.Size([6, 1])


labels_reshape=y_train.detach().numpy()
Predictions_reshape=y_preds.detach().numpy()
图_预测（标签_重塑，预测=预测_重塑）

&lt;块引用&gt;
ValueError：x 和 y 的大小必须相同

我尝试压缩张量，使它们只有一个暗淡，并且我还检查了镜头是否相同，确实如此。]]></description>
      <guid>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch-an</guid>
      <pubDate>Sat, 13 Apr 2024 20:23:01 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在随机森林的核心中使用 adaBoosting 而不是 bootstrap？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</link>
      <description><![CDATA[随机森林使用 Bagging（Bootstrapping）为其每棵树选择样本，对吗？是否可以使用 adaBoosting 代替？有什么优点和优点？缺点？为什么我没看到这个？
我看到 Sci-kit learn 中的 RandomForestClassifier 允许启用/禁用引导程序，否则没有选项可以用 boosting 替换它。
我这么问是因为我在大学里学过，在选择样本来创建树时，装袋和提升是两种可能的选择，但到目前为止我发现的似乎与此相反。]]></description>
      <guid>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</guid>
      <pubDate>Sat, 13 Apr 2024 04:19:58 GMT</pubDate>
    </item>
    <item>
      <title>识别随机森林中错误分类的样本</title>
      <link>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</link>
      <description><![CDATA[我正在 RStudio 中执行随机森林分析，我可以使用下面的代码提取混淆矩阵。我可以看到有多少样本被错误分类，但是我可以使用什么代码来识别哪些特定样本被错误分类？
库（随机森林）
库（rfPermute）

rfmetrics &lt;- randomForest(x, y, ntree=ntree,重要性=T)
打印（rfmetrics）

称呼：
 randomForest(x = x, y = y, ntree = ntree, 重要性 = T)
               随机森林类型：分类
                     树木数量：1999
每次分割尝试的变量数量：25

        OOB 估计错误率：56.88%
混淆矩阵：
  1 2 3 4 类.错误
1 8 7 7 4 0.6923077
2 4 19 2 4 0.3448276
3 3 3 15 6 0.4444444
4 3 9 10 5 0.8148148
]]></description>
      <guid>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</guid>
      <pubDate>Wed, 10 Apr 2024 19:44:24 GMT</pubDate>
    </item>
    <item>
      <title>我可以重新训练 AutoModelForSequenceClassification 以生成文本吗？</title>
      <link>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</link>
      <description><![CDATA[我的目标是微调 Mistral 7b 以编写短意识流（文本完成，而不是遵循指令）。
我有一个大型数据库（100 万行），其中包含从互联网上抓取的短文本。我手动将 15k 行标记为 good (1k) 和 bad（其余 14k）示例。我的计划是训练 AutoModelForSequenceClassification在这些示例上标记其他 985k 行。
通过这种方式，我希望收集大约 20k 意识流的好例子来微调 Mistral 7b。
但仅对good示例进行微调并不会使用bad示例中的信息，这些示例的数量要多得多。因此，我正在考虑使用 Mistral 7b 作为 AutoModelForSequenceClassification 的基本模型（遵循 这篇 Medium 文章），然后重新训练生成的 AutoModelForSequenceClassification 以进行文本补全。这需要移除分类头并添加新的/重新训练的 LoRA 组件。
您认为这可行吗？这是否会削弱模型（例如，需要重新学习语法），或者这是否是将坏反例的信息合并到文本生成中的有效方法？或者至少为 LoRA 文本生成微调提供一个良好的初始化点？]]></description>
      <guid>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</guid>
      <pubDate>Sat, 06 Apr 2024 11:32:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 max_new_tokens 的 LLM 输出不完整</title>
      <link>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</link>
      <description><![CDATA[我正在尝试 Huggingface LLM 模型。
我注意到的一个问题是模型的输出突然结束，我理想地希望它完成其之间的段落/句子/代码。 （或者完全尝试在一些固定数量的标记内完成答案）
虽然我已经提供了 max_new_tokens = 300 并且在提示中我写道：
“输出最多应为 300 个字。”
响应总是不完整并且突然结束。我可以通过什么方式要求在所需数量的输出令牌内获得完整的输出？
代码：
检查点=“HuggingFaceH4/starchat-alpha”
设备=“cuda”； if torch.cuda.is_available() else “cpu”
StarCoderModel 类：
  def __init__(自身):
    self.tokenizer = AutoTokenizer.from_pretrained(检查点)
    # 如果需要 GPU，请确保 docker run 命令中提供了 `--gpus all`
    self.model = AutoModelForCausalLM.from_pretrained(检查点, device_map=&#39;auto&#39;)

  def infer(self, input_text, token_count):
    输入 = self.tokenizer.encode(input_text, return_tensors=“pt”).to(device)
    输出 = self.model.generate(输入, max_new_tokens=token_count, pad_token_id=self.tokenizer.eos_token_id)
    返回 self.tokenizer.decode(outputs[0])[len(input_text):]

样本输出：
私有数据类型FuntionName(String someId) {
    // TODO：替换为利用 someId 获取信息的实现
    返回数据类型.Value；
}


评论：

- 如果代码中存在 someId，则使用 Client 的 getAPI 以 someId 作为参数来获取一些信息。
- 如果

]]></description>
      <guid>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</guid>
      <pubDate>Thu, 07 Sep 2023 18:02:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 bootstrap 方法得出置信区间 AUC</title>
      <link>https://stackoverflow.com/questions/75309099/confidence-interval-auc-with-the-bootstrap-method</link>
      <description><![CDATA[今天我尝试制作一个 bootstrap 来获取各种不同 ML 算法 AUC 的区间置信度。
我使用了我的个人医疗数据集，其中包含 61 个特征，格式如下：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

年龄
女性


&lt;正文&gt;

65
1


45
0




例如，我使用了这种类型的算法：
X = data_sevrage.drop([&#39;Echec_sevrage&#39;], axis=1)

y = data_sevrage[&#39;Echec_sevrage&#39;]

X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25, random_state=0)

lr = LogisticRegression(C=10 ,penalty=&#39;l1&#39;,solver=&#39;saga&#39;, max_iter=500).fit(X_train,y_train)
分数=roc_auc_score(y_test,lr.predict_proba(X_test)[:,1])
精度、召回率、阈值 = precision_recall_curve(y_test, lr.predict_proba(X_test)[:,1])
auc_ precision_recall = Metrics.auc(召回率, 精度)
y_pred = lr.predict(X_test)
print(&#39;ROC AUC 分数:&#39;,分数)
print(&#39;auc_ precision_recall :&#39;,auc_ precision_recall)

最后，当我使用 boostrap 方法获取置信区间时（我从其他主题获取代码：如何在Python中比较不同二元分类器的ROC AUC分数并评估统计显着性？）
def bootstrap_auc(clf, X_train, y_train, X_test, y_test, nsamples=1000):
    auc_值 = []
    对于范围内的 b（n 个样本）：
        idx = np.random.randint(X_train.shape[0], size=X_train.shape[0])
        clf.fit(X_train[idx], y_train[idx])
        pred = clf.predict_proba(X_test)[:, 1]
        roc_auc = roc_auc_score(y_test.ravel(), pred.ravel())
        auc_values.append(roc_auc)
    返回 np.percentile(auc_values, (2.5, 97.5))

bootstrap_auc(lr, X_train, y_train, X_test, y_test, nsamples=1000)

我有这个错误：
&lt;块引用&gt;
“没有 [Int64Index([21, 22, 20, 31, 30, 13, 22, 1, 31, 3, 2, 9, 9, 18, 29, 30, 31,\n 31, 16 , 11, 23, 7, 19, 10, 14, 5, 10, 25, 30, 24, 8, 20],\n dtype=&#39;int64&#39;)] 在[列]中”

我使用了另一种方法，并且出现了几乎相同的错误：
&lt;前&gt;&lt;代码&gt; n_bootstraps = 1000
rng_seed = 42 # 控制再现性
bootstrapped_scores = []

rng = np.random.RandomState(rng_seed)
对于范围内的 i(n_bootstraps)：
    # 通过对预测索引进行替换采样来引导
    索引 = rng.randint(0, len(y_pred), len(y_pred))
    if len(np.unique(y_test[索引])) &lt; 2：
        # ROC AUC 至少需要 1 个正样本和 1 个负样本
        # 待定义：拒绝样本
        继续

    分数 = roc_auc_score(y_test[索引], y_pred[索引])
    bootstrapped_scores.append(分数)
    print(&quot;Bootstrap #{} ROC 区域: {:0.3f}&quot;.format(i + 1, Score))

&lt;块引用&gt;
“[6, 3, 12, 14, 10, 7, 9] 不在索引中”

你能帮我一下吗？我测试了很多解决方案，但每次都会出现此错误。
谢谢！
机器学习算法上 AUC 置信区间的 Bootstrap 方法。]]></description>
      <guid>https://stackoverflow.com/questions/75309099/confidence-interval-auc-with-the-bootstrap-method</guid>
      <pubDate>Wed, 01 Feb 2023 10:51:08 GMT</pubDate>
    </item>
    </channel>
</rss>