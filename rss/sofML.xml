<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 17 Jun 2024 06:22:22 GMT</lastBuildDate>
    <item>
      <title>点或叉（关于使用链式法则计算矩阵的梯度）</title>
      <link>https://stackoverflow.com/questions/78630853/dot-or-crossregarding-calculation-of-gradients-of-matrices-using-chain-rule</link>
      <description><![CDATA[在学习如何训练神经网络时遇到了一个问题。在此代码中，令人困惑的是如何理解何时使用“*”以及何时“使用np.dot()”进行乘法
def loss_gradients(forward_info: Dict[str, ndarray],
weights: Dict[str, ndarray]) -&gt; Dict[str, ndarray]:
&#39;&#39;&#39;
计算损失对神经网络中每个参数的偏导数。
&#39;&#39;&#39;
dLdP = -(forward_info[&#39;y&#39;] - forward_info[&#39;P&#39;])
dPdM2 = np.ones_like(forward_info[&#39;M2&#39;])

dLdM2 = dLdP * dPdM2

dPdB2 = np.ones_like(weights[&#39;B2&#39;])

dLdB2 = (dLdP * dPdB2).sum(axis=0)

dM2dW2 = np.transpose(forward_info[&#39;O1&#39;], (1, 0))

dLdW2 = np.dot(dM2dW2, dLdP)

dM2dO1 = np.transpose(weights[&#39;W2&#39;], (1, 0)) 

dLdO1 = np.dot(dLdM2, dM2dO1)

dO1dN1 = sigmoid(forward_info[&#39;N1&#39;]) * (1- sigmoid(forward_info[&#39;N1&#39;]))

dLdN1 = dLdO1 * dO1dN1

dN1dB1 = np.ones_like(weights[&#39;B1&#39;])

dN1dM1 = np.ones_like(forward_info[&#39;M1&#39;])

dLdB1 = (dLdN1 * dN1dB1).sum(axis=0)

dLdM1 = dLdN1 * dN1dM1

dM1dW1 = np.transpose(forward_info[&#39;X&#39;], (1, 0)) 

dLdW1 = np.dot(dM1dW1, dLdM1)

loss_gradients: Dict[str, ndarray] = {}
loss_gradients[&#39;W2&#39;] = dLdW2
loss_gradients[&#39;B2&#39;] = dLdB2.sum(axis=0)
loss_gradients[&#39;W1&#39;] = dLdW1
loss_gradients[&#39;B1&#39;] = dLdB1.sum(axis=0)

return loss_gradients

我们的想法是，知道何时使用哪个是至关重要的，因为输出不同]]></description>
      <guid>https://stackoverflow.com/questions/78630853/dot-or-crossregarding-calculation-of-gradients-of-matrices-using-chain-rule</guid>
      <pubDate>Mon, 17 Jun 2024 04:06:38 GMT</pubDate>
    </item>
    <item>
      <title>留一交叉验证来进行模型评估</title>
      <link>https://stackoverflow.com/questions/78630776/leave-one-out-cross-validation-for-model-evaluation</link>
      <description><![CDATA[# RF 
rf_optimal = RandomForestRegressor(**best_params, random_state=42)

# 留一交叉验证
loo = LeaveOneOut()
r2_train_scores = []
rmse_train_scores = []
y_test_true = []
y_test_pred = []

for train_index, test_index in loo.split(X_train):
X_train_fold, X_test_fold = X_train.values[train_index], X_train.values[test_index]
y_train_fold, y_test_fold = y_train.values[train_index], y_train.values[test_index]

rf_optimal1 = RandomForestRegressor(**best_params, random_state=42)
rf_optimal1.fit(X_train_fold, y_train_fold)
y_train_pred_fold = rf_optimal1.predict(X_train_fold)
y_test_pred_fold = rf_optimal1.predict(X_test_fold)

r2_train = r2_score(y_train_fold, y_train_pred_fold)
rmse_train = np.sqrt(mean_squared_error(y_train_fold, y_train_pred_fold))

r2_train_scores.append(r2_train)
rmse_train_scores.append(rmse_train)
y_test_true.append(y_test_fold[0])
y_test_pred.append(y_test_pred_fold[0])

r2_cal = np.mean(r2_train_scores)
rmse_cal = np.mean(rmse_train_scores)
r2_cv = r2_score(y_test_true,y_test_pred)
rmse_cv = np.sqrt(mean_squared_error(y_test_true,y_test_pred))

print(f&quot;Rc²: {r2_cal}, RMSEc: {rmse_cal}&quot;)
print(f&quot;Rcv²: {r2_cv}, RMSEcv: {rmse_cv}&quot;)

# 在整个训练数据集上进行训练，并在测试数据集上进行测试
rf_optimal.fit(X_train.values, y_train.values)
y_test_pred = rf_optimal.predict(X_test.values)

我正在尝试使用 LeaveOneOut() 评估 rf 模型。因此，我的令人困惑的是，我是否应该在新的 loo.split 中定义一个新的 RandomForestRegressor 并与整个训练数据集进行拟合，然后使用在 loo.split 之外定义的回归器预测测试数据集？我想要获得 Rc2、Rcv2 和 Rp2。]]></description>
      <guid>https://stackoverflow.com/questions/78630776/leave-one-out-cross-validation-for-model-evaluation</guid>
      <pubDate>Mon, 17 Jun 2024 03:11:20 GMT</pubDate>
    </item>
    <item>
      <title>我尝试手动应用梯度下降，但遇到了一个问题</title>
      <link>https://stackoverflow.com/questions/78630596/i-was-trying-to-apply-gradient-descent-manually-but-facing-a-problem</link>
      <description><![CDATA[import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
#创建随机 X 和 Y 值
np.random.seed(405)
X = 6*np.random.rand(100,1)-3
Y = 0.8*(X**2) + 0.9*X + 2 + np.random.randn(100,1)
Y = Y.reshape(-1,1)
X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=2)
poly = PolynomialFeatures(degree=2,include_bias=False)
X_train_trans = poly.fit_transform(X_train)
X_test_trans = poly.transform(X_test)
model = LinearRegression()
model.fit(X_train_trans,y_train)
y_pred = model.predict(X_test_trans)
print(model.intercept_)
print(model.coef_)
n = len(X_train_trans)
β0 = 0
β1 = 1
β2 = 2
learning_rate = 0.0001 # 调整学习率
num_iterations = 50000 # 增加迭代次数
n = len(X_train_trans)
for iteration in range(num_iterations):
# 计算预测
y_prediction = β0 + β1 * X_train_trans[:, 0] + β2 * X_train_trans[:, 1]

# 计算损失（均方误差）
loss = (1/(2*n)) * np.sum((y_train - y_prediction)**2)

# 计算梯度
d_β0 = -(1 / n) * np.sum(y_train - y_prediction)
d_β1 = -(1 / n) * np.sum((y_train - y_prediction) * X_train_trans[:, 0])
d_β2 = -(1 / n) * np.sum((y_train - y_prediction) * X_train_trans[:, 1])

# 更新参数
β0 -= learning_rate * d_β0
β1 -= learning_rate * d_β1
β2 -= learning_rate * d_β2

# 定期打印损失和参数
if iteration % 1000 == 0:
print(f&quot;Iteration {iteration}: Loss = {loss}&quot;)

print(f&quot;最终参数（梯度下降）：β0 = {β0}, β1 = {β1}, β2 = {β2}&quot;)

/// 问题是每次我从线性回归模型和我手动应用的模型中获得不同的系数值时，我都无法理解原因。我也尝试过改变学习率和迭代次数，但我无法获得相同的值。你能帮我吗？
我有一个关于多项式回归梯度下降的问题。如果可能的话，我想要答案。]]></description>
      <guid>https://stackoverflow.com/questions/78630596/i-was-trying-to-apply-gradient-descent-manually-but-facing-a-problem</guid>
      <pubDate>Mon, 17 Jun 2024 01:09:36 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 CNN 回归问题中每个预测值的置信度分数？</title>
      <link>https://stackoverflow.com/questions/78630404/how-to-calculate-confidence-score-for-each-prediction-value-in-cnn-regression-pr</link>
      <description><![CDATA[在回归中，假设我正在使用 CNN 进行预测，如果我必须回答每个预测的置信度值，那么在回归问题中，应该如何计算每个预测值的置信度？与分类一样，您可以抛出概率值，但对于回归，应该如何做到这一点？任何帮助都值得感激]]></description>
      <guid>https://stackoverflow.com/questions/78630404/how-to-calculate-confidence-score-for-each-prediction-value-in-cnn-regression-pr</guid>
      <pubDate>Sun, 16 Jun 2024 22:34:16 GMT</pubDate>
    </item>
    <item>
      <title>引导成本学习中每场游戏的平均成本</title>
      <link>https://stackoverflow.com/questions/78630010/mean-cost-per-game-in-guided-cost-learning</link>
      <description><![CDATA[在此算法中，它是 Chelsea Finn、Sergey Levine 和 Pieter Abbeel 的论文“引导成本学习：通过策略优化进行深度逆最优控制”的实现，为什么每场比赛的平均成本在增加而不是减少？我找过了，但还是没搞明白。
成本在这个类中计算：
class CostNN(nn.Module):
def __init__(
self, 
state_dim,
hidden_​​dim1 = 128, 
out_features = 1, 
):
super(CostNN, self).__init__()
self.net = nn.Sequential(
nn.Linear(state_dim, hidden_​​dim1),
nn.ReLU(),
nn.Linear(hidden_​​dim1, out_features),
)
def forward(self, x):
return self.net(x)

结果

但无法弄清楚这种行为是“正常的”]]></description>
      <guid>https://stackoverflow.com/questions/78630010/mean-cost-per-game-in-guided-cost-learning</guid>
      <pubDate>Sun, 16 Jun 2024 19:04:49 GMT</pubDate>
    </item>
    <item>
      <title>在 MNIST 数据集上训练的 MLP 神经网络的错误</title>
      <link>https://stackoverflow.com/questions/78629622/errors-with-mlp-neural-network-made-from-scratch-trained-on-mnist-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78629622/errors-with-mlp-neural-network-made-from-scratch-trained-on-mnist-dataset</guid>
      <pubDate>Sun, 16 Jun 2024 16:22:57 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 车牌识别 [关闭]</title>
      <link>https://stackoverflow.com/questions/78629315/ml-net-licences-plate-recognition</link>
      <description><![CDATA[我想创建一个 .NET MAUI 应用程序，该应用程序能够使用移动设备的摄像头检测车牌。如果检测到车牌，我想从车牌中提取文本。
（一切都应该在本地工作，无需互联网连接！）
现在我的问题是：哪个是最适合选择的 ML.NET 场景？ （如果 ML.NET 不是适合此目的的框架，请告诉我替代方案。）
以下是 Visual Studio 提供的所有 ML.NET 场景：

数据分类
价值预测
推荐
预测
图像分类
对象检测
文本分类
句子相似度
问答
命名实体识别
]]></description>
      <guid>https://stackoverflow.com/questions/78629315/ml-net-licences-plate-recognition</guid>
      <pubDate>Sun, 16 Jun 2024 13:55:15 GMT</pubDate>
    </item>
    <item>
      <title>不切实际的完美测试成绩：诊断和解决 100% 准确率问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78629141/unrealistically-perfect-testing-scores-diagnosing-and-addressing-100-accuracy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78629141/unrealistically-perfect-testing-scores-diagnosing-and-addressing-100-accuracy</guid>
      <pubDate>Sun, 16 Jun 2024 12:39:05 GMT</pubDate>
    </item>
    <item>
      <title>在 AWS Sagemaker 中训练线性模型时出现 UnexpectedStatusException？</title>
      <link>https://stackoverflow.com/questions/78628328/getting-unexpectedstatusexception-while-training-linear-model-in-aws-sagemaker</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78628328/getting-unexpectedstatusexception-while-training-linear-model-in-aws-sagemaker</guid>
      <pubDate>Sun, 16 Jun 2024 05:27:48 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：list.remove（x）：在进行模型构建时 x 不在列表中 - 特征选择的逐步选择</title>
      <link>https://stackoverflow.com/questions/78626417/valueerror-list-removex-x-not-in-list-while-doing-model-building-stepwise</link>
      <description><![CDATA[我正在使用 statsmodels.api 作为 sm 进行逐步选择以进行特征选择，并且在运行代码时出现此错误
ValueError：list.remove(x)：x 不在列表中
对于下面的代码片段
def stepwise_selection(x, y,
initial_list=[&#39;discount&#39;, &#39;sla&#39;,&#39;product_procurement_sla&#39;, &#39;order_payment_type&#39;,
&#39;online_order_perc&#39;, &#39;TV_ads&#39;,&#39;Sponsorship_ads&#39;, &#39;Content_marketing_ads&#39;, &#39;Online_marketing_ads&#39;,
&#39;NPS&#39;, &#39;Stock_Index&#39;, &#39;Special_sales&#39;, &#39;Payday&#39;, &#39;heat_deg_days&#39;, &#39;cool_deg_days&#39;, 
&#39;total_rain_mm&#39;, &#39;total_snow_cm&#39;,&#39;snow_on_grnd_cm&#39;, &#39;MA4_listed_price&#39;,
&#39;MA2_discount_offer&#39;],
threshold_in=0.01,threshold_out = 0.05, verbose=True):

included = list(initial_list)
while True:
changed=False
###前进步骤
excluded = list(set(x.columns)-set(included))
new_pval = pd.Series(index=excluded)
for new_column in excluded:
model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included+[new_column]]))).fit()
new_pval[new_column] = model.pvalues[new_column]
best_pval = new_pval.min()
if best_pval &lt; Threshold_in:
best_feature = new_pval.argmin()
included.append(best_feature)
changed=True
if verbose:
print(&#39;添加 {:30}，p 值 {:.6}&#39;.format(best_feature, best_pval))

###后退步骤
model = sm.OLS(y, sm.add_constant(pd.DataFrame(x[included ]))).fit()
###使用除截距之外的所有系数
pvalues = model.pvalues.iloc[1:]
greatest_pval = pvalues.max() ###如果 pvalues 为空，则为 null
if greatest_pval &gt; Threshold_out:
changed=True
worst_feature = pvalues.argmax()
included.remove(worst_feature)
if verbose:
print(&#39;Drop {:30} with p-value {:.6}&#39;.format(worst_feature, greatest_pval))
if notchanged:
break
return included

import statsmodels.api as sm

final_features = stepwise_selection(x, y)

print(&quot;\n&quot;,&quot;final_selected_features:&quot;,final_features)

at line
included.remove(worst_feature)

我尝试使用 del 函数，但预期错误不同]]></description>
      <guid>https://stackoverflow.com/questions/78626417/valueerror-list-removex-x-not-in-list-while-doing-model-building-stepwise</guid>
      <pubDate>Sat, 15 Jun 2024 11:01:41 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“ValueError：找到具有 0 个样本的数组（shape=(0, 5)），而 LinearRegression 至少需要 1 个。”</title>
      <link>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</guid>
      <pubDate>Sat, 15 Jun 2024 10:53:01 GMT</pubDate>
    </item>
    <item>
      <title>将模型正确预测的图像传回模型进行训练是否会对我们有用？[关闭]</title>
      <link>https://stackoverflow.com/questions/78625950/would-passing-correctly-predicted-images-by-a-model-back-to-the-model-for-traini</link>
      <description><![CDATA[我没有所需的技术知识来尝试测试模型的指标以比较结果和假设，因此我依靠社区的智慧。
我试图寻找答案，但没有找到任何有用的东西（也许我的问题措辞不正确）。
关于上述主题有什么指导吗？
尝试谷歌搜索，期望找到一篇文章或一些答案，但没有找到任何东西。]]></description>
      <guid>https://stackoverflow.com/questions/78625950/would-passing-correctly-predicted-images-by-a-model-back-to-the-model-for-traini</guid>
      <pubDate>Sat, 15 Jun 2024 07:41:59 GMT</pubDate>
    </item>
    <item>
      <title>如何为输入形状为 (n, 3) 和 (n, 2) 的数据集实现回归模型？</title>
      <link>https://stackoverflow.com/questions/78625334/how-can-i-implement-a-regression-model-for-a-dataset-with-inputs-in-the-shape-n</link>
      <description><![CDATA[我正在尝试为这种形式的数据集实现回归模型：

我遇到问题的部分是：对于数据集中的每个条目，输入 1 的形状为 (n, 3)，输入 2 的形状为 (n, 2) - 我不知道如何将模型塑造成可以使用回归模型的方式，因为我试图使每个条目的每个输入大小相同。我对这些数据完全没有背景信息，只是给出了数据并需要构建回归模型。
我尝试过以这种方式对所有输入求平均值：
取输入 1 并按索引沿每个向量求平均值，如下所示，[[2, 3, 4], [1, 2, 3]] -&gt; [1.5, 2.5, 3.5]
取输入 2 并按索引沿每个向量求平均值，如下所示，[[2, 45], [1, 45]] -&gt; [1.5, 45]
然后合并以获得长度为 5 的数组作为数据集中每个条目的输入，因此 [[2, 3, 4], [1, 2, 3]] 作为输入 1 和 [[2, 45], [1, 45]] 作为输入 2 将转换为 [1.5, 2.5, 3.5, 1.5, 45]。
然后我缩放了数据并使用了 Scikit 中的 MLPRegressor，但数字相差甚远。我尝试查看相关矩阵，如上所示，在平均输入得到的 5 个维度中都没有线性相关性。
我现在认为像我所做的那样平均输入并不是正确的处理方式。如何处理这样的数据集？]]></description>
      <guid>https://stackoverflow.com/questions/78625334/how-can-i-implement-a-regression-model-for-a-dataset-with-inputs-in-the-shape-n</guid>
      <pubDate>Sat, 15 Jun 2024 00:07:48 GMT</pubDate>
    </item>
    <item>
      <title>使用计算机视觉技术创建高效的实时人脸检测系统 [关闭]</title>
      <link>https://stackoverflow.com/questions/78624565/creating-an-efficient-real-time-face-detection-system-using-computer-vision-tech</link>
      <description><![CDATA[如何使用现代计算机视觉技术和框架从实时视频中创建实时人脸检测系统，确保准确性和效率？
我期待一个结构良好的答案来消除我的疑虑，我需要任何链接供我参考。]]></description>
      <guid>https://stackoverflow.com/questions/78624565/creating-an-efficient-real-time-face-detection-system-using-computer-vision-tech</guid>
      <pubDate>Fri, 14 Jun 2024 18:51:33 GMT</pubDate>
    </item>
    <item>
      <title>准确度得分值错误：无法处理二进制和连续目标的混合</title>
      <link>https://stackoverflow.com/questions/38015181/accuracy-score-valueerror-cant-handle-mix-of-binary-and-continuous-target</link>
      <description><![CDATA[我使用 scikit-learn 中的 linear_model.LinearRegression 作为预测模型。它很有效，而且很完美。我在使用 accuracy_score 指标评估预测结果时遇到问题。
这是我的真实数据：
array([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0])

我的预测数据：
array([ 0.07094605, 0.1994941 , 0.19270157, 0.13379635, 0.04654469,
0.09212494, 0.19952108, 0.12884365, 0.15685076, -0.01274453,
0.32167554, 0.32167554, -0.10023553, 0.09819648, -0.06755516,
0.25390082, 0.17248324])

我的代码：
accuracy_score(y_true, y_pred, normalize=False)

错误消息：
ValueError：无法处理二进制和连续目标的混合
]]></description>
      <guid>https://stackoverflow.com/questions/38015181/accuracy-score-valueerror-cant-handle-mix-of-binary-and-continuous-target</guid>
      <pubDate>Fri, 24 Jun 2016 13:57:17 GMT</pubDate>
    </item>
    </channel>
</rss>