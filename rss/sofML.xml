<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 17 Jan 2024 01:02:30 GMT</lastBuildDate>
    <item>
      <title>如何在 scikit-learn 中对线性回归模型使用交叉验证</title>
      <link>https://stackoverflow.com/questions/77829091/how-to-use-cross-validation-on-linear-regression-model-in-scikit-learn</link>
      <description><![CDATA[我想在 scikit learn 中使用网格搜索交叉验证进行训练线性回归模型可以说是 10 倍，就像我分享的图像中一样。
但是当我这样做时，我得到：
spipe = 管道([
    （&#39;缩放&#39;，StandardScaler（）），
    (&#39;模型&#39;, 线性回归())
]）

网格 = GridSearchCV(
    估计器=管道，
    简历=4
）

网格.fit(X,Y)

类型错误：GridSearchCV.__init__() 缺少 1 个必需参数：&#39;param_grid&#39;

所以我的理解是它想要迭代 LinearRegression 模型的可能参数，我应该将它们放入 param_grid 中。
但我不想为每次折叠调整参数。相反，我想简单地按照照片所示进行操作：进行 10 次折叠并对其进行 10 次训练和验证，以便模型微调 1 个线性回归多项式（我想这就是模型内部发生的情况）。
我尝试使用cross_val_score，但它似乎在 10 次折叠上训练 10 次，因为它返回 10 个分数而不是 1 个分数（所以我猜测 10 个线性回归多项式，每个折叠 1 个）。 
总而言之，如何将折叠交叉验证方法与线性回归结合使用？
如果有人需要，这里是设置：
从 sklearn.linear_model 导入 LinearRegression
从 sklearn.datasets 导入 fetch_california_housing
将 pandas 导入为 pd
从 sklearn.pipeline 导入管道
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.model_selection 导入 GridSearchCV

加利福尼亚州 = fetch_california_housing()

pd.set_option(&#39;显示.精度&#39;, 4)
pd.set_option(&#39;display.max_columns&#39;, 9)
pd.set_option(&#39;display.width&#39;, None)
california_df = pd.DataFrame(california.data,
                             列=加利福尼亚.feature_names）
california_df[&#39;MedHouseValue&#39;] = pd.Series(california.target)
X = 加利福尼亚州. 数据
Y = 加利福尼亚.目标
]]></description>
      <guid>https://stackoverflow.com/questions/77829091/how-to-use-cross-validation-on-linear-regression-model-in-scikit-learn</guid>
      <pubDate>Tue, 16 Jan 2024 22:44:50 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow ImportError：无法导入名称“dtensor”</title>
      <link>https://stackoverflow.com/questions/77828746/tensorflow-importerror-cannot-import-name-dtensor</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77828746/tensorflow-importerror-cannot-import-name-dtensor</guid>
      <pubDate>Tue, 16 Jan 2024 21:13:45 GMT</pubDate>
    </item>
    <item>
      <title>像 smote 或 adasyn 这样的过采样技术是否会将所有数据转换为单个类标签？</title>
      <link>https://stackoverflow.com/questions/77828073/does-a-oversampling-technique-like-smote-or-adasyn-convert-all-data-to-a-single</link>
      <description><![CDATA[我正在研究使用图像数据的深度学习模型。我的过采样器正在将所有样本转换为单个类。
最初我有 7909 个图像、2480 个 0 类图像和 5429 个 1 类图像。应用 smote 后（下面的代码）
#合成少数过采样技术
sm = SMOTE(采样策略=&#39;自动&#39;,random_state=56)

train_data_resampled, train_labels_resampled = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)

打印（train_data_resampled.shape，train_labels_resampled.shape）

我也尝试了adasyn（下面的代码）
从 imblearn.over_sampling 导入 ADASYN

adasyn = ADASYN(sampling_strategy=&#39;少数&#39;, random_state=89, n_neighbors=5)

train_data_resampled, train_labels_resampled = adasyn.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)

打印（train_data_resampled.shape，train_labels_resampled.shape）

我的所有 train_labels 都转换为单类标签，即 0 类。任何人都可以帮忙吗？我正在 Kaggle 中编写我的代码。]]></description>
      <guid>https://stackoverflow.com/questions/77828073/does-a-oversampling-technique-like-smote-or-adasyn-convert-all-data-to-a-single</guid>
      <pubDate>Tue, 16 Jan 2024 18:45:59 GMT</pubDate>
    </item>
    <item>
      <title>仅支持一维向量将 MATLAB“double”转换为 Python</title>
      <link>https://stackoverflow.com/questions/77827946/converting-matlab-double-to-python-is-only-supported-for-1-dimensional-vectors</link>
      <description><![CDATA[源代码如下：
导入 py.sklearn.linear_model.LogisticRegression
导入 py.numpy.asarray


X = randn(100, 2);
Y = 兰迪([0, 1], 100, 1);

LR = py.sklearn. Linear_model.LogisticRegression(pyargs(&#39;class_weight&#39;, &#39;balanced&#39;, &#39;random_state&#39;, int64(0)));

模型 = LR.fit(X, Y);

错误：
使用 py.sklearn.linear_model._logistic.LogisticRegression/fit 时出错
仅支持一维向量将 MATLAB“double”转换为 Python。

错误 Untitled4（第 15 行）
模型 = LR.fit(X, Y);

如何在matlab中调用LR模型的拟合函数？]]></description>
      <guid>https://stackoverflow.com/questions/77827946/converting-matlab-double-to-python-is-only-supported-for-1-dimensional-vectors</guid>
      <pubDate>Tue, 16 Jan 2024 18:24:10 GMT</pubDate>
    </item>
    <item>
      <title>如何仅使用组件在 azure ml Designer 中训练和部署 ml 模型？</title>
      <link>https://stackoverflow.com/questions/77827691/how-to-train-and-deploy-ml-models-in-azure-ml-designer-just-using-components</link>
      <description><![CDATA[我在 azure ml Designer 中创建了一个训练管道。现在，我需要通过添加用于注册和部署的组件来部署此模型。我想我可以使用“执行 python 脚本”组件来执行此操作。但是我不知道如何将“训练的最佳模型”（“调整模型超参数”组件的输出）与“执行 python 脚本”组件连接起来。那么，知道如何完成这项任务吗？我将非常感谢您的帮助。
这是我的管道：
训练管道]]></description>
      <guid>https://stackoverflow.com/questions/77827691/how-to-train-and-deploy-ml-models-in-azure-ml-designer-just-using-components</guid>
      <pubDate>Tue, 16 Jan 2024 17:39:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在提供 customGPT 之前处理大型 PDF 文件并构建数据 [关闭]</title>
      <link>https://stackoverflow.com/questions/77827516/how-to-process-large-pdf-file-and-structure-the-data-before-feeding-customgpt</link>
      <description><![CDATA[我正在学习机器学习和人工智能。我有大量 pdf、研究论文和书籍，我想将它们提供给 customGPT。我正在学习自然语言处理、标记化、词干提取等
我认为所有这些都可以通过编程方式完成，但我真正的问题是 - 在提取为“文本”后执行这些 PDF 文件吗？只有文件需要人工干预吗？我无法想象自己会浏览数千页，所以我对此表示怀疑。]]></description>
      <guid>https://stackoverflow.com/questions/77827516/how-to-process-large-pdf-file-and-structure-the-data-before-feeding-customgpt</guid>
      <pubDate>Tue, 16 Jan 2024 17:09:25 GMT</pubDate>
    </item>
    <item>
      <title>max在遗传算法中起什么作用？</title>
      <link>https://stackoverflow.com/questions/77826027/what-role-does-max-play-in-genetic-algorithms</link>
      <description><![CDATA[在网上找到了一个遗传算法代码，求解的是f(x)=2*sin(x) + cos(x)的最大值，但是我发现代码中有一个参数max_value，并且不知道有什么作用。
GA代码如下：
随机导入
导入数学
将 matplotlib.pyplot 导入为 plt


def 物种起源（种群大小，染色体长度）：
    人口=[[]]
    对于范围内的 i（population_size）：
        临时=[]
        对于范围内的 j（染色体长度）：
            临时.append(随机.randint(0, 1))
        人口.追加（临时）
    返回人口[1:]


def 翻译（人口，染色体长度）：
    临时=[]
    对于范围内的 i(len(population))：
        总计 = 0
        对于范围内的 j（染色体长度）：
            总计 = 总计 + 人口[i][j] * (math.pow(2, j))
        临时.追加（总计）
    暂时返回


def 函数（群体、染色体长度、最大值）：
    临时=[]
    函数1 = []
    临时=翻译（人口，染色体长度）
    对于范围内的 i(len(临时))：
        x = 临时[i] * max_value / (math.pow(2, chtomosome_length) - 1)
        function1.append(2 * math.sin(x) + math.cos(x))
    返回函数1

def 健身（功能1）：
    健身1 = []
    最小适应度 = mf = 0
    对于范围内的 i(len(function1))：
        如果（函数 1[i] + mf &gt; 0）：
            临时 = mf + 函数 1[i]
        别的：
            临时 = 0.0
        Fitness1.append（临时）
    返回健身1


def sum(fitness1):
    总计 = 0
    对于范围内的 i(len(fitness1))：
        总计 += 适应度1[i]
    返回总计

# https://blog.csdn.net/weixin_39068956/article/details/105121469
def cumsum(健身1):
    对于范围内的 i(len(fitness1) - 2, -1, -1)：
        总计 = 0
        j = 0
        而（j &lt;= i）：
            总计 += 适应度1[j]
            j += 1
        适应度1[i] = 总计
        健身1[len(健身1) - 1] = 1


def选择（人口，适应度1）：
    新健身=[]
    总适应度=总和（适应度1）
    对于范围内的 i(len(fitness1))：
        new_fitness.append(fitness1[i]/total_fitness)


    cumsum(new_fitness)

    毫秒 = []
    人口长度 = pop_len = len(人口)
    对于范围内的 i(pop_len)：
        ms.append(随机.随机())
    ms.sort()

    适应= 0
    纽因 = 0
    新人口 = 新人口 = 人口

    而纽因 &lt;流行长度：
        if (ms[newin] &lt; new_fitness[fitin]):
            new_pop[newin] = 人口[fitin]
            纽因 += 1
        别的：
            适合+= 1
    人口=新人口


def 交叉（人口，pcB00）：
    pop_len = len(人口)

    对于范围内的 i(pop_len - 1)：
        cpoint = random.randint(0, len(population[0]))
        临时1 = []
        临时2 = []

        临时1.extend(人口[i][0:cpoint])
        临时1.extend(population[i + 1][cpoint:len(population[i])])

        临时2.extend(人口[i + 1][0:cpoint])
        临时2.extend(population[i][cpoint:len(population[i])])

        人口[i] = 临时1
        人口[i + 1] = 临时2


def 突变（群体，pm）：
    px = len(人口)
    py = len(人口[0])

    对于范围内的 i（px）：
        if (random.random() &lt; pm):
            mpoint = random.randint(0, py - 1)
            if (人口[i][mpoint] == 1):
                人口[i][m点] = 0
            别的：
                人口[i][m点] = 1


def b2d(b, 最大值, 染色体长度):
    总计 = 0
    对于范围内的 i(len(b))：
        总计 = 总计 + b[i] * math.pow(2, i)
    总计 = 总计 * max_value / (math.pow(2, 染色体长度) - 1)
    返回总计


def best（人口，健身1）：
    px = len(人口)
    最佳个人=[]
    最佳适应度 = 适应度1[0]

    对于范围 (1, px) 内的 i：
        if (fitness1[i] &gt; bestfitness):
            最佳适应度 = 适应度1[i]
            最佳个体 = 总体[i]

    返回[最佳个体，最佳适应度]

＃ 主要的
人口规模 = 500
最大值 = 10
染色体长度 = 10
个人计算机=0.6
下午 = 0.01
结果=[[]]
健身1 = []
拟合平均值 = []

人口=流行=物种起源（人口大小，染色体长度）


对于范围内的 i（population_size）：
    函数 1 = 函数（群体、染色体长度、最大值）
    适应度1 = 适应度(函数1)
    best_individual, best_fitness = best(人口, 健身1)
    results.append([best_fitness, b2d(best_individual, max_value, 染色体长度)])

    选择（人口，适应度1）
    交叉（人口，个人电脑）
    突变（群体，pm）

结果=结果[1:]
结果.sort()
X = []
Y = []
对于范围（500）内的 i：
    X.追加(i)
    Y.append(结果[i][0])
plt.plot(X, Y)
plt.show()

我尝试调整max_value的值，发现对结果影响很大，这让我很困惑。]]></description>
      <guid>https://stackoverflow.com/questions/77826027/what-role-does-max-play-in-genetic-algorithms</guid>
      <pubDate>Tue, 16 Jan 2024 13:20:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在多维复杂数据上训练模型？</title>
      <link>https://stackoverflow.com/questions/77825016/how-to-train-a-model-on-multidimensional-complex-data</link>
      <description><![CDATA[我有一个输入数据数组，它们是 5 个不同长度的数组。如何构建正确的张量和形式进行训练？
&lt;前&gt;&lt;代码&gt;[
[
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ],],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]],
[
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2 ], [ 1, 2 ] ],
  [ [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ], [ 1, 2, 3, 4, 5 ],],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]],
  [ [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]
],
...
],
]
]]></description>
      <guid>https://stackoverflow.com/questions/77825016/how-to-train-a-model-on-multidimensional-complex-data</guid>
      <pubDate>Tue, 16 Jan 2024 10:22:33 GMT</pubDate>
    </item>
    <item>
      <title>是否建议对经过one-hot编码的数据进行主成分分析（PCA）</title>
      <link>https://stackoverflow.com/questions/77824892/is-it-recommended-to-perform-principal-component-analysis-pca-on-data-that-has</link>
      <description><![CDATA[我正在做一个项目，虽然机器学习模型做得还不错，但我觉得它还可以更好。该模型可以很好地预测多数类别，但不能很好地预测少数类别。多数类的召回率和精度分别为 84% 和 82%，少数类的召回率和精度分别为 39% 和 52%。
我向数据中添加了更多特征，并使用 SMOTE 来平衡数据的分布，少数类别的召回率和精度分别提高到 54% 和 52%，这是一个显着的结果，但是少数类别的召回率和精度多数阶层仍分别保持在 84% 和 82%。
我希望少数类的查全率和查准率都在 70% 以上，我想尝试的一种方法是对数据进行 one-hot 编码，然后使用主成分分析 (PCA) 来减小特征空间的大小同时保留尽可能多的信息，但我不知道是否建议这样做。
那么有谁知道是否建议对经过 one-hot 编码的数据执行主成分分析（PCA）？]]></description>
      <guid>https://stackoverflow.com/questions/77824892/is-it-recommended-to-perform-principal-component-analysis-pca-on-data-that-has</guid>
      <pubDate>Tue, 16 Jan 2024 10:02:11 GMT</pubDate>
    </item>
    <item>
      <title>尝试运行 SVC 分类模型，花了一个小时但没有响应</title>
      <link>https://stackoverflow.com/questions/77822664/trying-to-run-a-classification-model-for-svc-taking-hour-and-not-responding</link>
      <description><![CDATA[我已经尝试运行 SVC 分类模型三天了，但该模型没有响应。我检查了我的数据、标准缩放器、训练测试拆分和所有必要的库，所有这些都已正确应用和工作。我运行随机森林分类器模型，该模型运行成功，但存在良好的准确度分数（F1 分数）。但是 SVC 不工作，可能是什么问题？
我尝试过 RandomForest，效果很好，但 SVC 从未起作用。可能是什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77822664/trying-to-run-a-classification-model-for-svc-taking-hour-and-not-responding</guid>
      <pubDate>Mon, 15 Jan 2024 22:38:54 GMT</pubDate>
    </item>
    <item>
      <title>检测哪个图像不属于任何类 - 异常值 - Python</title>
      <link>https://stackoverflow.com/questions/77815892/detect-which-image-doesnt-belong-to-any-class-outlier-python</link>
      <description><![CDATA[我正在尝试用 python 编写一个程序，该程序将检测给定数据集中的哪个图像不属于任何类。
假设我们有一个包含 5 个类的数据集，每个类大约有 10 张图像：

汽车
城堡
数字
人
鱼

现在，在此数据集中有 3 个不属于任何类别的隐藏图像：

狗
球
坚持

我怎样才能制作一个程序来显示这三张图像？
我想就如何解决这个问题寻求建议。我不知道哪些 python 库可能有用，或者如果所使用的数据集中不存在这些类，我该如何创建自己的类？
这些类/图像可能不同，我只是给它们来解释问题。
我尝试基于 cifar10、cifar100 和 imagenet 制作自己的神经网络，但我发现它们给了我不需要的类，例如：我有 3 或 4 种不同类型的鱼，而不是 1 个名为“的类”鱼&#39;。
我了解到有一种叫做“异常值”的东西。我相信可以用非常不同的方式解决这个问题，但是我在互联网上没有找到任何对我有帮助的材料。]]></description>
      <guid>https://stackoverflow.com/questions/77815892/detect-which-image-doesnt-belong-to-any-class-outlier-python</guid>
      <pubDate>Sun, 14 Jan 2024 16:51:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 3.12.1 上安装 PyTorch</title>
      <link>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</link>
      <description><![CDATA[我正在安装 DARTS TimeSeries 库 (https: //github.com/unit8co/darts/blob/master/INSTALL.md#enabling-Optional-dependencies），但我遇到了依赖项安装问题。在 DARTS 安装指南中，它说如果我们遇到这个问题，我们必须参考 PyTorch 的官方安装指南，然后尝试再次安装 Darts。然后，当我尝试在 python 3.12.1 上安装 torch 时，我遇到了这个错误：
&lt;块引用&gt;
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版。

如何解决？
我使用 PyCharm 作为 Python 代码编辑器。
我尝试了pip install darts，但它没有安装所有软件包并遇到此错误错误：subprocess-exited-with-error
 用于安装构建依赖项的 pip 子进程未成功运行。
  │ 退出代码：1
  ╰─&gt; 【136行输出】
      正在收集setuptools&gt;=64.0
        从 https://files.pythonhosted.org/packages 获取 setuptools&gt;=64.0 的依赖信息

然后，我尝试使用 pip install torch 安装 torch 并遇到此错误
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版]]></description>
      <guid>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</guid>
      <pubDate>Wed, 10 Jan 2024 10:16:06 GMT</pubDate>
    </item>
    <item>
      <title>来自不同包的相同算法会生成完全不同的模型？</title>
      <link>https://stackoverflow.com/questions/77415335/same-algorithm-from-different-packages-generates-completely-different-model</link>
      <description><![CDATA[我正在分别使用两个包训练线性模型。
但是，我意识到这两个结果在变量系数方面存在巨大差异。
def 测试（x，y，模型）：
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=101)
    regr = Linear_model.LinearRegression()
    regr.fit(x_train, y_train)
    
    lr = sm.OLS(y_train, x_train).fit()
    打印（lr.params）
    
    打印（regr.coef_）

上面是我使用的代码。令人惊讶的是，系数差异如此之大，以至于给出了完全不同的预测。
两个模型都以相同的顺序列出变量，所以我现在真的很困惑。知道出了什么问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77415335/same-algorithm-from-different-packages-generates-completely-different-model</guid>
      <pubDate>Fri, 03 Nov 2023 08:58:30 GMT</pubDate>
    </item>
    <item>
      <title>InvalidArgumentError：无法计算 MatMul，因为输入 #0（从零开始）预计是浮点张量，但实际上是双张量 [Op:MatMul]</title>
      <link>https://stackoverflow.com/questions/54255431/invalidargumenterror-cannot-compute-matmul-as-input-0zero-based-was-expected</link>
      <description><![CDATA[有人可以解释一下，TensorFlow 的 eager 模式是如何工作的吗？我正在尝试构建一个简单的回归，如下所示：
将张量流导入为 tf
将 numpy 导入为 np

tfe = tf.contrib.eager
tf.enable_eager_execution()

def make_model():
    net = tf.keras.Sequential()
    net.add(tf.keras.layers.Dense(4, 激活=&#39;relu&#39;))
    net.add(tf.keras.layers.Dense(1))
    回网

def计算损失（预测，实际）：
    返回 tf.reduce_mean(tf.square(tf.subtract(pred,actual)))

defcompute_gradient（模型，预测，实际）：
    “”“”用给定的噪声和输入“”“计算梯度”
    使用 tf.GradientTape() 作为磁带：
        损失=计算损失（预测，实际）
    grads = Tape.gradient(loss, model.variables)
    返回毕业生，损失

def apply_gradients（优化器，梯度，model_vars）：
    优化器.apply_gradients(zip(grads, model_vars))
    
模型 = make_model()
优化器 = tf.train.AdamOptimizer(1e-4)

x = np.linspace(0,1,1000)
y = x + np.random.normal(0,0.3,1000)
y = y.astype(&#39;float32&#39;)
train_dataset = tf.data.Dataset.from_tensor_slices((y.reshape(-1,1)))

纪元 = 2# 10
批量大小 = 25
itr = y.shape[0] # 批量大小
对于范围内的纪元（纪元）：
    对于 tf.contrib.eager.Iterator(train_dataset.batch(25)) 中的数据：
        preds = 模型（数据）
        梯度，损失=compute_gradient（模型，preds，数据）
        apply_gradients（优化器，梯度，模型.变量）
# 梯度输出：[无，无，无，无，无，无]

错误如下：
------------------------------------------------ ------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-a589b9123c80&gt;在&lt;模块&gt;中
     35 梯度，损失=compute_gradient（模型，preds，数据）
     36 打印（渐变）
---&gt; 37 apply_gradients（优化器，梯度，模型.变量）
     38 # 用 tf.GradientTape() 作为磁带：
     39 # 损失 = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(preds, data))))

&lt;ipython-input-3-a589b9123c80&gt;在 apply_gradients（优化器，梯度，model_vars）
     17 号
     18 def apply_gradients（优化器，梯度，model_vars）：
---&gt; 19 优化器.apply_gradients(zip(grads, model_vars))
     20
     21 模型 = make_model()

〜/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py 在 apply_gradients(self, grads_and_vars, global_step, name)
    第589章
    590 raise ValueError(“没有为任何变量提供梯度：%s。”%
--&gt;第591章
    第592章
    第593章

ValueError：没有为任何变量提供渐变：

编辑
我更新了我的代码。现在，问题出现在梯度计算中，它返回零。我检查过损失值不为零。]]></description>
      <guid>https://stackoverflow.com/questions/54255431/invalidargumenterror-cannot-compute-matmul-as-input-0zero-based-was-expected</guid>
      <pubDate>Fri, 18 Jan 2019 13:52:51 GMT</pubDate>
    </item>
    <item>
      <title>R 中奇怪的 svm 行为 (e1071)</title>
      <link>https://stackoverflow.com/questions/51852415/weird-svm-behavior-in-r-e1071</link>
      <description><![CDATA[我在 R（第一个示例）和 Python（第二个示例）中使用 SVM 运行了以下代码来执行二元分类任务。 
给定随机生成的数据(X)和响应(Y)，此代码执行离开组交叉验证 1000 次。因此，Y 的每个条目都是 CV 迭代预测的平均值。 
曲线下的计算面积应为 ~0.5，因为 X 和 Y 是完全随机的。然而，这并不是我们所看到的。曲线下面积通常显着高于 0.5。 X 的行数非常少，这显然会导致问题。 
知道这里会发生什么吗？我知道我可以增加 X 的行数或减少列数来解决问题，但我正在寻找其他问题。 
Y=as.factor(rep(c(1,2), times=14))
X=矩阵(runif(长度(Y)*100), nrow=长度(Y))

图书馆(e1071)
库（pROC）

列名(X)=1:ncol(X)
迭代=1000
ansMat=矩阵(NA,长度(Y),iter)
for(i in seq(iter)){
    #搭火车

    训练=样本(seq(长度(Y)),0.5*长度(Y))
    if(min(表(Y[train]))==0)
    下一个

    #从火车上测试
    测试=seq(长度(Y))[-train]

    #训练模型
    XX=X[火车,]
    YY=Y[火车]
    mod=svm(XX,YY,概率=FALSE)
    XXX=X[测试,]
    predVec=预测(mod,XXX)
    RFans=attr(predVec,&#39;decision.values&#39;)
    ansMat[测试，i]=as.numeric(predVec)
}

ans=rowMeans(ansMat,na.rm=TRUE)

r=roc(Y,ans)$auc
打印(r)

同样，当我在 Python 中实现相同的事情时，我得到了类似的结果。 
Y = np.array([1, 2]*14)
X = np.random.uniform(size=[len(Y), 100])
n_iter = 1000
ansMat = np.full((len(Y), n_iter), np.nan)
对于范围内的 i(n_iter)：
    # 获取训练/测试索引
    火车= np.random.choice（范围（len（Y）），大小= int（0.5 * len（Y）），替换= False，p =无）
    如果 len(np.unique(Y)) == 1:
        继续
    test = np.array([i for i in range(len(Y)) if i not in train])
    # 训练模型
    mod = SVC(概率=假)
    mod.fit(X=X[火车, :], y=Y[火车])
    # 预测并收集答案
    ansMat[测试，i] = mod.predict(X[测试，:])
ans = np.nanmean(ansMat, 轴=1)
fpr、tpr、阈值 = roc_curve(Y、ans、pos_label=1)
打印（auc（fpr，tpr））`
]]></description>
      <guid>https://stackoverflow.com/questions/51852415/weird-svm-behavior-in-r-e1071</guid>
      <pubDate>Wed, 15 Aug 2018 03:06:09 GMT</pubDate>
    </item>
    </channel>
</rss>