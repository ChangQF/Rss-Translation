<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 28 May 2024 01:02:44 GMT</lastBuildDate>
    <item>
      <title>无法在 Kaggle 上以 .h5 格式保存深度学习模型</title>
      <link>https://stackoverflow.com/questions/78541201/unable-to-save-deep-learning-model-in-h5-format-on-kaggle</link>
      <description><![CDATA[我在尝试在 Kaggle 上以 .h5 格式保存深度学习模型时遇到问题。尽管遵循标准程序，保存过程始终失败。 在此处输入图像描述我已经添加了代码和面临的问题。
在此处输入图片描述
我将格式指定为.keras，但模型无法保存。不过，该代码在 Google Colab 上运行良好。不幸的是，Google Colab 的内存不足以有效运行我的代码。
如何解决此问题并确保我的模型在 Kaggle 平台上成功保存为 .h5 格式？]]></description>
      <guid>https://stackoverflow.com/questions/78541201/unable-to-save-deep-learning-model-in-h5-format-on-kaggle</guid>
      <pubDate>Mon, 27 May 2024 21:49:55 GMT</pubDate>
    </item>
    <item>
      <title>即使经过 500 个 epoch，结果也没有改善 - 使用 Tensorflow 的隐形隐写术</title>
      <link>https://stackoverflow.com/questions/78540839/results-not-improving-even-after-500-epochs-invisible-steganography-using-tens</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78540839/results-not-improving-even-after-500-epochs-invisible-steganography-using-tens</guid>
      <pubDate>Mon, 27 May 2024 19:40:59 GMT</pubDate>
    </item>
    <item>
      <title>这个架构好不好？如果没有，我能做些什么来让它变得更好？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78540729/is-this-architecture-good-if-not-what-can-i-do-to-make-it-better</link>
      <description><![CDATA[!pip install keras-tuner

def build_model（马力）：
模型=顺序（）

# 转换块 1
模型.add(Conv2D(
    过滤器=hp.Int(&#39;conv_1_filter&#39;, min_value=32, max_value=128, step=16),
    kernel_size=hp.Choice(&#39;conv_1_kernel&#39;, 值=[3, 5]),
    填充=&#39;相同&#39;，
    激活=&#39;relu&#39;,
    输入形状=(224,224,3)
））
模型.add(Conv2D(
    过滤器=hp.Int（&#39;conv_1_filter&#39;，min_value = 32，max_value = 128，step = 16），
    kernel_size=hp.Choice(&#39;conv_1_kernel&#39;, 值=[3, 5]),
    激活=&#39;relu&#39;
））
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))

# 转换块 2
模型.add(Conv2D(
    过滤器=hp.Int（&#39;conv_2_filter&#39;，min_value = 32，max_value = 128，step = 16），
    kernel_size=hp.Choice(&#39;conv_2_kernel&#39;, 值=[3, 5]),
    填充=&#39;相同&#39;，
    激活=&#39;relu&#39;
））
模型.add(Conv2D(
    过滤器=hp.Int（&#39;conv_2_filter&#39;，min_value = 32，max_value = 128，step = 16），
    kernel_size=hp.Choice(&#39;conv_2_kernel&#39;, 值=[3, 5]),
    激活=&#39;relu&#39;
））
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))

# 转换块 3
模型.add(Conv2D(
    过滤器=hp.Int(&#39;conv_3_filter&#39;, min_value=64, max_value=256, step=32),
    kernel_size=hp.Choice(&#39;conv_3_kernel&#39;, 值=[3, 5]),
    填充=&#39;相同&#39;，
    激活=&#39;relu&#39;
））
模型.add(Conv2D(
    过滤器=hp.Int（&#39;conv_3_filter&#39;，min_value = 64，max_value = 256，step = 32），
    kernel_size=hp.Choice(&#39;conv_3_kernel&#39;, 值=[3, 5]),
    激活=&#39;relu&#39;
））
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))


# 转换块 3
模型.add(Conv2D(
    过滤器=hp.Int（&#39;conv_3_filter&#39;，min_value = 64，max_value = 256，step = 32），
    kernel_size=hp.Choice(&#39;conv_3_kernel&#39;, 值=[3, 5]),
    填充=&#39;相同&#39;，
    激活=&#39;relu&#39;
））
模型.add(Conv2D(
    过滤器=hp.Int(&#39;conv_3_filter&#39;, min_value=64, max_value=256, step=32),
    kernel_size=hp.Choice(&#39;conv_3_kernel&#39;, 值=[3, 5]),
    激活=&#39;relu&#39;
））
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))


# 转换块 4
模型.add(Conv2D(
    过滤器=hp.Int（&#39;conv_4_filter&#39;，min_value = 64，max_value = 256，step = 32），
    kernel_size=hp.Choice(&#39;conv_4_kernel&#39;, 值=[3, 5]),
    填充=&#39;相同&#39;，
    激活=&#39;relu&#39;
））
模型.add(Conv2D(
    过滤器=hp.Int（&#39;conv_4_filter&#39;，min_value = 64，max_value = 256，step = 32），
    kernel_size=hp.Choice(&#39;conv_4_kernel&#39;, 值=[3, 5]),
    激活=&#39;relu&#39;
））
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))

模型.add(压平())

# 全连接层
模型.add(密集(
    单位=hp.Int(&#39;dense_units&#39;, min_value=64, max_value=512, step=32),
    激活=&#39;relu&#39;
））

模型.add(密集(
    单位=hp.Int(&#39;additional_dense_units&#39;, min_value=64, max_value=256, step=32),
    激活=&#39;relu&#39;
））
model.add(Dropout(rate=hp.Float(&#39;dropout_rate&#39;, min_value=0.1, max_value=0.5, step=0.1)))

model.add（密集（3，激活=&#39;softmax&#39;））


模型.编译(
    优化器=keras.optimizers.Adam(hp.Choice(&#39;learning_rate&#39;,values=[1e-2,1e-3,1e-4])),
    损失=&#39;分类交叉熵&#39;，
    指标=[&#39;准确性&#39;]
）

返回模型

train_datagen = 图像数据生成器(
重新缩放=1./255，
旋转范围=20，
宽度偏移范围=0.2，
height_shift_range=0.2，
水平翻转=真，
缩放范围=0.5
）

train_generator = train_datagen.flow_from_directory(
&#39;/内容/驱动器/MyDrive/DataSet/train&#39;,
目标大小=(224,224),
color_mode=&#39;rgb&#39;,
批量大小=32，
随机播放=真
）

validation_datagen = ImageDataGenerator（重新缩放=1./255）

validation_generator =validation_datagen.flow_from_directory(
&#39;/content/drive/MyDrive/DataSet/val&#39;,
目标大小=(224,224),
color_mode=&#39;rgb&#39;,
批量大小=32，
随机播放=真
）

调谐器 = kt.RandomSearch(
构建模型，
目标=&#39;val_accuracy&#39;,
最大试验次数=5,
目录=&#39;输出&#39;,
project_name=&#39;Image_Classification_Tuning&#39;
）

Tuner.search（train_generator，epochs = 5，validation_data = validation_generator）

# 获取最佳模型
best_model =tuner.get_best_models(num_models=1)[0]

best_model.summary()

# 训练最佳模型
历史记录 = best_model.fit(
x=火车生成器，
纪元=20，
验证数据=验证生成器
)` 

这是我的皮肤病预测代码，它有 3 个类别，我将数据集分为 80% 用于训练，其中有 2307 张图像，10% 进行验证，其中有 657 张图像，10% 用于测试，但我的准确性是没有增加，在70%到75%之间。我可以做什么来增加它？]]></description>
      <guid>https://stackoverflow.com/questions/78540729/is-this-architecture-good-if-not-what-can-i-do-to-make-it-better</guid>
      <pubDate>Mon, 27 May 2024 19:06:26 GMT</pubDate>
    </item>
    <item>
      <title>训练 GPT-2 模型时，价值在管道中丢失</title>
      <link>https://stackoverflow.com/questions/78540598/value-getting-lost-in-the-pipeline-while-training-a-gpt-2-model</link>
      <description><![CDATA[我正在编写一个项目来训练 GPT-2 模型，由于数据集的结构及其包含负面示例，因此必须稍微修改传递的数据，以便“负面”模型能够被显示出来。所有条目都存在标志。变量 negative_mask 被赋予 nagtive 标志设置为 true 的数据集条目。
数据集类是：
类 CustomTextDataset(数据集):
    def __init__(self, 分词器, 示例, block_size=128):
        self.examples = 示例
        self.tokenizer = 分词器
        self.块大小 = 块大小

        texts = [example[&#39;text&#39;] 例如在示例中]
        negative_masks = [例如示例中的示例[&#39;负&#39;]]

        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=self.block_size, return_tensors=&#39;pt&#39;)
        self.负掩码 = torch.tensor(负掩码, dtype=torch.float)

        print(f&quot;编码：{self.encodings}&quot;)
        print(f&quot;负掩码: {self. Negative_masks}&quot;)

    def __getitem__(self, idx):
        item = {key: val[idx] for key, val in self.encodings.items()}
        item[&#39;负掩码&#39;] = self.负掩码[idx]

        如果“负掩码”不在项目中：#debug，已通过
            print(f“错误：数据集项 {idx} 中缺少 negative_mask”)
        print(f&quot;数据集项 {idx}: {item}&quot;)
        归还物品

    def __len__(自身):
        返回 len(self.encodings[&#39;input_ids&#39;])

调试行支持存在 negative_mask，根据调试行：
负掩码：tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0. , 0., 0., 0., 0., 0.,
        0.、0.、0.、0.、0.、0.、0.、1.、1.、1.、1.、1.、1.、1.、0.、0.、0. , 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0. , 0.,
        0.、0.、0.、1.、1.、1.、1.、1.、1.、1.、0.、0.、0.、0.、0.、0.、0. , 0.,

但是当我们到达数据收集器类时：
类 CustomDataCollat​​or：
    def __init__(self, tokenizer, mlm=False, mlm_probability=0.15):
        self.tokenizer = 分词器
        自我传销 = 传销
        self.mlm_概率 = mlm_概率
        self.data_collat​​or = DataCollat​​orForLanguageModeling（tokenizer=tokenizer，mlm=mlm，mlm_probability=mlm_probability）
        
    def __call__(自我，特征)：
        print(“CustomDataCollat​​or 收到的功能：”, features)
        对于我来说，枚举中的功能（功能）：#debug， 
            如果“负掩码”不在功能中：
                print(f&quot;特征{i}缺少负掩码：{feature}&quot;)
                raise ValueError(f“feature {i}: {feature}”中缺少 negative_mask) # 此处引发 -----

        input_ids = torch.stack([f[&#39;input_ids&#39;] for f in features])
        focus_mask = torch.stack([f[&#39;attention_mask&#39;] for f in features])
        negative_mask = torch.tensor([f[&#39;negative_mask&#39;] for f in features], dtype=torch.float)

        批次={
            &#39;input_ids&#39;：input_ids，
            &#39;注意掩码&#39;：注意掩码，
            &#39;负掩码&#39;：负掩码
        }

        如果特征[0]中的“标签”：
            batch[&#39;labels&#39;] = torch.stack([f[&#39;labels&#39;] for f in features])

        print(f&quot;在 CustomDataCollat​​or 中准备的批次：{batch}&quot;)
        退货批次

line: raise ValueError(f“feature {i}: {feature}”中缺少 negative_mask) # raise ，每次指示管道中的某个位置时都会引发 negative_mask 正在被删除，由异常支持，negative_mask 似乎神奇地消失了：
ValueError: 功能 0 中缺少 negative_mask: {&#39;input_ids&#39;: 张量([ 70, 4024, 10163, 11, 23624, 6188, 25, 1210, 826, 9087,
        20064、11、5529、1944、20334、685、45、7156、37045、60、
        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]), &#39;attention_mask&#39;: 张量([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 , 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0])}

我尝试在数据流的每个点添加调试行，以确保存在 negative_mask，我已将故障点缩小到 CustomDataCollector 类和 &lt; code&gt;CustomTextDataset 类，但我没有解释为什么标签丢失。]]></description>
      <guid>https://stackoverflow.com/questions/78540598/value-getting-lost-in-the-pipeline-while-training-a-gpt-2-model</guid>
      <pubDate>Mon, 27 May 2024 18:27:17 GMT</pubDate>
    </item>
    <item>
      <title>我有一个问题“NoneType”对象没有属性“download_as_string”[关闭]</title>
      <link>https://stackoverflow.com/questions/78540003/i-have-a-problem-with-nonetype-object-has-no-attribute-download-as-string</link>
      <description><![CDATA[
1-逐行查看代码
2- firebase 存储以及它是否有效
3-在 pip $ /path/to/venv/bin/pip install -U requests 中下载我的需求]]></description>
      <guid>https://stackoverflow.com/questions/78540003/i-have-a-problem-with-nonetype-object-has-no-attribute-download-as-string</guid>
      <pubDate>Mon, 27 May 2024 15:41:23 GMT</pubDate>
    </item>
    <item>
      <title>无法从 feature_extractor 获取正确的输入形状</title>
      <link>https://stackoverflow.com/questions/78539772/unable-to-get-correct-shape-of-input-from-feature-extractor</link>
      <description><![CDATA[我尝试从音频片段中提取特征。现在我有 90 个段，它们已填充到相同的长度 48000。所以形状是 (90, 48000)。但是，当我尝试将其输入 feature_extractor 时，出现错误：
运行时错误：需要 2D（未批处理）或 3D（批处理）输入到 conv1d，但得到的输入大小为：[1, 1, 90, 48000]
另外生成了两个维度。有人能帮我吗？谢谢！
processor = AutoProcessor.from_pretrained(“microsoft/wavlm-base-plus-sd”)
使用 autocast()、torch.no_grad()：
                word_wavs = pad_sequence(word_wavs, batch_first=True, padding_value=0) # 90(6windowsize*15words) x 48000(16k*3s)
                word_lens = torch.stack(word_lens)
                输入=处理器（word_wavs，return_tensors =&#39;pt&#39;，sampling_rate = sr，padding = True）

我打印出了输入的形状，注意掩模的形状为 (1, 90)，input_values 的形状为 (1, 90, 48000)。]]></description>
      <guid>https://stackoverflow.com/questions/78539772/unable-to-get-correct-shape-of-input-from-feature-extractor</guid>
      <pubDate>Mon, 27 May 2024 14:51:02 GMT</pubDate>
    </item>
    <item>
      <title>监督异常检测问题中的平衡和不平衡</title>
      <link>https://stackoverflow.com/questions/78539548/balancing-and-imbalancing-in-supervised-anomaly-detection-probelm</link>
      <description><![CDATA[我正在处理一个监督异常检测问题，其中标签为 0 表示正常，1 表示异常。数据集的默认分布高度不平衡，正常和异常的比例分别为 96:4。
因此，我应用随机欠采样将正常和异常的比率降低到 55:45。现在，准确度为 98%，如下面还提供的其他指标所示。这个概念是正确的还是我错了？
准确度：0.98467329
精度：0.98027553
召回率：0.98755102
F1-分数：0.98389996
曲线下面积：0.98500429
卡帕：0.97917268
]]></description>
      <guid>https://stackoverflow.com/questions/78539548/balancing-and-imbalancing-in-supervised-anomaly-detection-probelm</guid>
      <pubDate>Mon, 27 May 2024 14:03:46 GMT</pubDate>
    </item>
    <item>
      <title>在与我之前训练的数据集不同的数据集上训练 yolov8 变得非常慢</title>
      <link>https://stackoverflow.com/questions/78539266/training-yolov8-on-a-different-data-set-than-i-had-previously-trained-it-on-beca</link>
      <description><![CDATA[我正在尝试在与我之前训练过的数据集不同的数据集上训练 yolov8。尽管这是一个较小的数据集，但即使 1 个 epoch 也需要极长的时间才能完成。还有其他人遇到这个问题吗？我可能哪里出错了？
我正在尝试在与我之前训练过的数据集不同的数据集上训练 yolov8。尽管这是一个较小的数据集，但即使 1 个 epoch 也需要非常长的时间才能完成。]]></description>
      <guid>https://stackoverflow.com/questions/78539266/training-yolov8-on-a-different-data-set-than-i-had-previously-trained-it-on-beca</guid>
      <pubDate>Mon, 27 May 2024 13:08:40 GMT</pubDate>
    </item>
    <item>
      <title>我有 3 个特征的数据集，2 个输入特征（一个 2D 图像和一个文本）和输出特征（一个 2D 图像），我应该如何训练这个模型？</title>
      <link>https://stackoverflow.com/questions/78537387/i-have-data-set-of-3-features-2-input-features-a-2d-image-and-a-text-and-outp</link>
      <description><![CDATA[我有 3 个特征、2 个输入特征（一个 2D 图像和一个文本）和一个输出特征（2D 图像）的数据集，我应该如何训练这个模型，以便它理解模式，以及当我给出新的 2D 时带有文本的图像，它应该给我一个适当的图像。感谢任何提示、代码、来源。
我尝试使用卷积神经网络（CNN）将输入图像转换为向量，并将文本输入为向量，所以基本上它们被编码，但又卡在解码它们，不知道这种方法是否真的有效。]]></description>
      <guid>https://stackoverflow.com/questions/78537387/i-have-data-set-of-3-features-2-input-features-a-2d-image-and-a-text-and-outp</guid>
      <pubDate>Mon, 27 May 2024 05:59:24 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试从 Huggingface 转换器导入 AutoProcessor、AutoModel 时退出，代码为 null</title>
      <link>https://stackoverflow.com/questions/78534800/exiting-with-code-null-when-i-try-importing-autoprocessor-automodel-from-huggin</link>
      <description><![CDATA[我正在尝试使用 GIT（生成图像到文本转换器）来执行图像字幕任务。但是，由于某种原因，当我尝试从转换器导入 AutoProcessor 和 AutoModel 时，我的代码不断退出并显示 code=null。
从转换器导入 AutoProcessor、AutoModel

我卸载了 pytorch 和转换器，并将其重新安装在虚拟环境中，检查是否存在任何冲突的依赖项，但每次运行以下代码时，我都会以 code = null 退出。知道我该如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78534800/exiting-with-code-null-when-i-try-importing-autoprocessor-automodel-from-huggin</guid>
      <pubDate>Sun, 26 May 2024 09:20:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在暗网中预测多图像txt？</title>
      <link>https://stackoverflow.com/questions/78533567/how-to-predict-multi-image-txt-in-darknet</link>
      <description><![CDATA[在 Yolov7 中，我使用此代码来测试整个文件夹图像：
python test.py --save-txt --data data/coco.yaml --save-conf --conf 0.1 --weights yolov7_20240316best.pt --task test --name 0316conf01

现在我需要在yolov4中预测test.txt（包括所有图像路径）。
我尝试了这个命令，但没有成功：
暗网探测器测试数据/obj.data cfg/yolo-obj.cfg backup/yolo-obj_best.weights -thresh 0.9 -dont_show data/test.txt result.txt
]]></description>
      <guid>https://stackoverflow.com/questions/78533567/how-to-predict-multi-image-txt-in-darknet</guid>
      <pubDate>Sat, 25 May 2024 19:51:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用权重和偏差 wandb 扫描实现多处理以实现最大并行化，特别是计数变量在此设置中如何工作？</title>
      <link>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</guid>
      <pubDate>Thu, 23 May 2024 05:25:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Batch Norm 训练中的平均值和标准差？</title>
      <link>https://stackoverflow.com/questions/69846779/how-does-one-use-the-mean-and-std-from-training-in-batch-norm</link>
      <description><![CDATA[我想使用训练中的标准，而不是批量统计数据，因为如果我使用批量统计数据，我的模型似乎会发散（如此处概述使用 PyTorch 高级库执行 MAML 时应何时调用 .eval() 和 .train()？ ）。如何做到这一点？
我之所以这么问，是因为尽管尚未进行任何训练，但我的模型似乎将它们设置为零：
Out[1]：BatchNorm2d(32，eps=0.001，动量=0.95，仿射=True，track_running_stats=True)
args.base_model.model.features.norm1.running_mean
输出[2]： 
张量([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0. , 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.])

训练后这些不是保存在ckpt中吗？他们应该被拯救吗？
文档说他们应该有（https:/ /pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm2d，https://pytorch.org/docs/stable/ generated/torch.nn.BatchNorm2d.html):
&lt;块引用&gt;
同样默认情况下，在训练期间，该层会持续运行其计算平均值和方差的估计，然后在评估期间将其用于标准化。

通过运行意味着向量为零...:/ ?
&lt;小时/&gt;
相关：

https://discuss.pytorch.org/t/how-does-one-use-the-mean-and-std-from-training-in-batch-norm/136029
]]></description>
      <guid>https://stackoverflow.com/questions/69846779/how-does-one-use-the-mean-and-std-from-training-in-batch-norm</guid>
      <pubDate>Thu, 04 Nov 2021 22:56:36 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyTorch 高级库执行 MAML 时，何时应该调用 .eval() 和 .train() ？</title>
      <link>https://stackoverflow.com/questions/69845469/when-should-one-call-eval-and-train-when-doing-maml-with-the-pytorch-highe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/69845469/when-should-one-call-eval-and-train-when-doing-maml-with-the-pytorch-highe</guid>
      <pubDate>Thu, 04 Nov 2021 20:30:16 GMT</pubDate>
    </item>
    <item>
      <title>如何从头开始训练 gpt 2？</title>
      <link>https://stackoverflow.com/questions/59327637/how-do-i-train-gpt-2-from-scratch</link>
      <description><![CDATA[我想从头开始训练 GPT 2，但我发现文章中只有基于预训练模型的微调方法。
我已使用此 https://github.com/nshepperd/gpt-2 来训练现有模型。我应该编辑这些 Python 脚本以从头开始训练吗？]]></description>
      <guid>https://stackoverflow.com/questions/59327637/how-do-i-train-gpt-2-from-scratch</guid>
      <pubDate>Fri, 13 Dec 2019 17:57:46 GMT</pubDate>
    </item>
    </channel>
</rss>