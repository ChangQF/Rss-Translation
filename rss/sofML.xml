<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Mon, 24 Mar 2025 18:25:10 GMT</lastBuildDate>
    <item>
      <title>CATBOOST模型的串联TF-IDF数据和分类数据</title>
      <link>https://stackoverflow.com/questions/79531266/concatenating-tf-idf-data-and-categorical-data-for-catboost-model</link>
      <description><![CDATA[我一直在尝试将TF-IDF数据与分类数据相连。但是，当串联时，默认情况下，分类数据会自动转换为float。由于catboost不支持分类特征的浮动，因此由于不再被认为是分类数据而导致稀疏数据的错误。
有解决这个问题的解决方案吗？请在下面找到我的代码以供参考：
 导入numpy作为NP
导入大熊猫作为pd
来自Catboost Import CatboostClassifier
来自sklearn.feature_extraction.text导入tfidfvectorizer
从Sklearn.Preprocessing Import LabElenCoder
来自scipy.sparse导入hstack，csr_matrix

text_data = [
    “我喜欢机器学习和数据科学”
    “深度学习是机器学习的子集”
    “自然语言处理是惊人的”
    “ AI正在改变世界”
    “大数据和AI正在彻底改变行业”。
这是给出的

pecorical_data = {
    “ cantory”：“ tech; quot” tech&#39;tech&#39;nlp’s&#39;&#39;
    “地区”：“欧洲”，“亚洲”欧洲“欧洲”
}

y = np.Array（[0，1，0，1，1]）

df_cat = pd.dataframe（centorical_data）

vectorizer = tfidfvectorizer（）
x_tfidf = vectorizer.fit_transform（text_data）

df_cat_encoded = df_cat.apply（labelencoder（）。fit_transform）

x_categorical = csr_matrix（df_cat_encoded.values）

x_combind = hstack（[x_tfidf，x_categorical]）

model = catboostClassifier（迭代= 100，Learning_rate = 0.1，深度= 5，冗长= 0）

model.fit（x_combined，y，cat_features = [x_tfidf.shape [1]，x_tfidf.shape [1] + 1]）

预测= model.predict（x_combined）

打印（预测）
 
错误：
  catboostror：&#39;data&#39;是scipy.sparse.spmatrix floating Point数值类型， 
这意味着没有分类功能，但是“ cat_features”参数指定非零 
分类功能的数量
 ]]></description>
      <guid>https://stackoverflow.com/questions/79531266/concatenating-tf-idf-data-and-categorical-data-for-catboost-model</guid>
      <pubDate>Mon, 24 Mar 2025 13:53:36 GMT</pubDate>
    </item>
    <item>
      <title>TABPFN功能选择提高了keyError（f“ [{key}]中的一个都不在[{axis_name}]中</title>
      <link>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</guid>
      <pubDate>Sun, 23 Mar 2025 22:59:22 GMT</pubDate>
    </item>
    <item>
      <title>DUAT息肉细分模型未开箱即用[关闭]</title>
      <link>https://stackoverflow.com/questions/79529461/duat-polyp-segmentation-model-not-working-out-of-the-box</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79529461/duat-polyp-segmentation-model-not-working-out-of-the-box</guid>
      <pubDate>Sun, 23 Mar 2025 18:24:52 GMT</pubDate>
    </item>
    <item>
      <title>回归失败，初始猜测很差[关闭]</title>
      <link>https://stackoverflow.com/questions/79528937/regression-fails-with-poor-initial-guess</link>
      <description><![CDATA[考虑模型参数在大小上有显着差异的回归任务，例如：
  def func（x，p）：
    P1，P2，P3 = P
    返回np.sin（p1 * x） * np.exp（p2 * x） * p3

＃真参数：
P1，P2，P3 = NP.PI/0.01，-1.25，1.2356＃314.1592，-1.25，1.2356
 
系统需要一个可行的初始猜测才能收敛到正确的解决方案，例如：
  p0 = [np.pi/0.01-80，-1.25-1，1.2356-1]
 
但是，如果最初的猜测离真解决方案太远，则回归可能无法收敛。例如，以下初始猜测可能行不通：
  p0 = [np.pi/0.02-10，-1.25-1，1.2356-1]
 
可重复的代码如下：
 导入numpy作为np
从scipy.ptimize导入至少_squares
导入matplotlib.pyplot作为PLT

def func（x，p）：
    P1，P2，P3 = P
    返回np.sin（p1 * x） * np.exp（p2 * x） * p3

def残差（p，y，x）：
    返回Y-弹药（x，p）

x = np.linspace（0，0.05，50）
P1，P2，P3 = NP.PI/0.01，-1.25，1.2356
y0 = func（x，[p1，p2，p3]）
y = y0 + np.random.randn（len（x）） * 0.05

p0 = [np.pi/0.02-10，-1.25-1，1.2356-1]

结果=最差_squares（残差，p0，args =（y，x））

打印（“ true参数：＆quot” [P1，P2，P3]）
打印（“近似参数：＆quort; result.x）

x_test = np.linspace（0，0.05，200）
y_test = func（x_test，result.x）
y_real = func（x_test，[p1，p2，p3]）
plt.plot（x_test，y_test，label =; precept; quot; quot;
plt.plot（x，y，&#39;.r&#39;，label =&#39;real＆quot;）
 
或这是一个pytorch版本：
 导入numpy作为np
导入火炬
从火炬进口
导入matplotlib.pyplot作为PLT

类Guesseq（nn.Module）：
    def __init __（自我）：
        super（gueseq，self）.__ INIT __（）
        self.params = nn.parameter（torch.tensor（[[np.pi/0.01-10，-1.25+1，1.2356-1]）））））））））））
    
    def向前（self，x）：
        out = torch.sin（self.params [0] * x） * \
            TORCH.EXP（-self.params [1] * x） * \
            self.params [2]
        返回

x = np.linspace（0，0.05，100）
y = np.sin（np.pi/0.01 * x） * np.exp（-1.25 * x） * 1.2356 + np.random.rand（x.Shape [0]） * 0.05

x = torch.tensor（x，dtype = turch.float32）
Y = TORCH.TENSOR（Y，DTYPE = TORCH.FLOAT32）
x = x.Reshape（（ -  1，1））
y = y.Reshape（（ -  1，1））

型号= gueseq（）
优化器= torch.optim.adam（model.parameters（），lr = 0.01）
mse = nn.mseloss（）
对于范围的我（2000年）：
    优化器.zero_grad（）
    y_pred =模型（x）
    损失= TORCH.MEAN（TORCH.SQUARE（Y_PRED -y））
    loss.backward（）
    如果我％100 == 0：
        打印（损失）
    优化器.step（）

x_test = torch.linspace（0，0.05，200）.RESHAPE（（ -  1，1））
y_test =模型（x_test）
print（＆quot; true参数：[{} {} {}]＆quort; .format（np.pi/0.01，-1.25，1.2356））
print（&#39;近似参数：{}＆quort; format（model.params.detach（）。numpy（）））
plt.plot（x_test.detach（）。cpu（）。numpy（）。flatten（），y_test.detach（）。cpu（）。
plt.plot（x.detach（）。cpu（）。numpy（）。flatten（），y.detach（）。cpu（）。
plt.legend（）
plt.show（）
 
当初始猜测远离真正的解决方案时，或者没有初始猜测之前，如何解决问题？]]></description>
      <guid>https://stackoverflow.com/questions/79528937/regression-fails-with-poor-initial-guess</guid>
      <pubDate>Sun, 23 Mar 2025 12:22:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么SeceentialFeaturesElector最多返回“ N_features_in_ -1”预测变量？</title>
      <link>https://stackoverflow.com/questions/79528929/why-does-sequentialfeatureselector-return-at-most-n-features-in-1-predictor</link>
      <description><![CDATA[我有一个具有六个功能的培训数据集，我正在使用 sequentialFeaturesElector 查找“最佳”线性回归模型的特征子集。以下代码返回三个功能，我将调用 x1，x2，x3 。
  sfs = sequentialFeaturesElector（linearregression（），n_features_to_select =&#39;auto&#39;， 
                                tol = 0.05，方向=&#39;正向&#39;， 
                                评分=&#39;neg_root_mean_squared_error&#39;，cv = 8）
sfs.fit_transform（x_train，y_train）
 
要检查结果，我决定使用功能的子集 x1，x2，x3 而不是 x_train 来运行相同的代码。我期望看到功能 x1，x2，x3 再次返回，但仅是功能 x1，x2 。同样，在同一代码中再次使用这两个功能仅返回 x1 。看来 sfs 的行为始终始终返回输入功能的适当子集，最多使用 n_features_in_-1 列，但是我似乎无法在 scikit-learn docs 。这是正确的吗？如果是这样，不允许的理由是什么
 sfs 返回完整的功能？
我还检查了使用向后选择是否会返回完整功能集。
  sfs = sequentialFeaturesElector（linearregression（），n_features_to_select =&#39;auto&#39;， 
                                tol = 1000，方向=&#39;向后&#39;， 
                                评分=&#39;neg_root_mean_squared_error&#39;，cv = 8）
sfs.fit_transform（x_train，y_train）
 
我将阈值设置为是一个很大的值，希望从 x_train 的完整功能中没有令人满意的改进。但是，它没有返回六个原始功能，而是返回了五个。文档只是说明

如果10分在两个连续的特征添加或删除之间至少会增加分数，请停止添加或删除。

因此，在交叉验证期间似乎没有考虑完整的功能集，并且在远期选择的末尾或在向后选择的开始时， sfs 的行为是不同的。如果完整的功能超过了功能的任何适当子集，那么我们不希望 sfs 返回这种可能性吗？是否有标准方法可以比较选定的特征的适当子集以及使用交叉验证的完整功能？]]></description>
      <guid>https://stackoverflow.com/questions/79528929/why-does-sequentialfeatureselector-return-at-most-n-features-in-1-predictor</guid>
      <pubDate>Sun, 23 Mar 2025 12:16:03 GMT</pubDate>
    </item>
    <item>
      <title>当训练模型使用KAFKA和RDL索引4096训练模型时的错误是否超出了尺寸4096的轴0</title>
      <link>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</guid>
      <pubDate>Sat, 22 Mar 2025 05:30:38 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Codebert嵌入识别类似的代码零件？</title>
      <link>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</link>
      <description><![CDATA[我正在使用Codebert比较两个代码的相似性。例如：
 ＃代码1
def calculate_area（半径）：
返回3.14 *半径 *半径
 
 ＃代码2
def Compute_circle_area（R）：
返回3.14159 * r * r
 
 Codebert创建“嵌入”就像对代码的详细描述为数字。然后，我比较这些数值描述，以查看代码的相似之处。这对于告诉我多少代码是相似的。
但是，我无法分辨Codebert认为哪些部分相似。因为“嵌入”很复杂，我无法轻易看到Codebert的重点。比较逐字代码在这里不起作用。
我的问题是：我如何找出两个代码段的哪些特定部分Codebert认为相似，而不仅仅是获得一般相似性得分？
我尝试了简单的DIFF方法，但这违反了纯粹使用Codebert的目的。
我想知道是否可以单独使用Codebert。]]></description>
      <guid>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</guid>
      <pubDate>Thu, 20 Mar 2025 14:30:35 GMT</pubDate>
    </item>
    <item>
      <title>面对ModulenotFoundError：没有名为“ ragas.metrics.critique”的模块</title>
      <link>https://stackoverflow.com/questions/79512981/facing-modulenotfounderror-no-module-named-ragas-metrics-critique</link>
      <description><![CDATA[在AWS Sagemaker Jupyterlab笔记本中运行代码段时，我的错误低于错误：

 modulenotfounderror：没有名为&#39;ragas.metrics.critique&#39;的模块

 导入警告
警告。FilterWarnings（“忽略”）＃忽略与Pydantic V1到V2迁移有关的警告

来自拉加斯进口评估
从ragas.metrics导入（
    忠诚，
    答案_relevancy，
    context_recall，
    context_precision，
    context_entity_recall，
    答案_象征性，
    答案_校正
）

来自ragas.metrics.Critique Import（
有害， 
恶意， 
连贯性， 
正确性， 
简明
）

＃在此处指定指标
指标= [
        忠诚，
        答案_relevancy，
        context_precision，
        context_recall，
        context_entity_recall，
        答案_象征性，
        wonse_correctness，
        有害， 
        恶意， 
        连贯性， 
        正确性， 
        简明
    这是给出的

结果=评估（
    数据集=数据集， 
    指标=指标，
    llm = llm_for_evaluation，
    嵌入= bedrock_embeddings，
）

df = result.to_pandas（）
 
我试图通过使用命令“ PIP install ragas”来重新安装拉加斯。并且仍然面临同一问题。
当我检查ragas时，它似乎已经正确安装了。
 pip显示ragas 
 名称：ragas
版本：0.2.14
概括： 
主页： 
作者： 
作者 - 邮件： 
执照： 
位置：/opt/conda/lib/python3.11/site-packages
要求：AppDirs，数据集，Diskcache，Langchain，Langchain-Community，Langchain-core，Langchain_openai，Nest-Asyncio，Numpy，Numpy，Openai，Openai，Pydantic，Tiktoken，Tiktoken
要求： 
注意：您可能需要重新启动内核才能使用更新的软件包。
 
如何解决这个问题？
 更新----  
我能够通过安装0.1.16版本的Ragas的以下步骤来解决上述问题，但是当我运行上述代码部分时，我会收到一个新问题（如下所述）。。
％pip安装ragas == 0.1.16 

  Importerror Trackback（最近的最新通话）
[27]中的细胞17
4来自拉加斯进口评估
5来自ragas.metrics进口（
6忠诚，
7 wonse_relevancy，
（...）
12个答案_校正
13）
---＆gt; 17来自ragas.metrics.Critique Importique（
18有害，
19恶意，
20连贯性，
21正确性，
22简洁
23）
25＃在这里指定指标
26指标= [
27忠诚，
28答案_relevancy，
（...）
38简洁
39]

file/opt/conda/lib/python3.11/site-packages/ragas/metrics/critique.py:13
11来自ragas.llms.output_parser导入ragasoutputparser，get_json_format_instructions
12来自ragas.llms.prompt进口提示
---＆gt; 13摘自ragas.metrics.base Import EvaluationMode，metricwithllm
15如果t.type_checking：
16来自langchain_core.callbacks.base导入回调

Importerror：无法从&#39;ragas.metrics.base&#39;（/opt/conda/lib/python3.11/site-packages/ragas/ragas/metrics/base.py）导入名称&#39;evaluationMode&#39;
 ]]></description>
      <guid>https://stackoverflow.com/questions/79512981/facing-modulenotfounderror-no-module-named-ragas-metrics-critique</guid>
      <pubDate>Sun, 16 Mar 2025 17:49:25 GMT</pubDate>
    </item>
    <item>
      <title>神经网络不确定的乳腺癌数据集</title>
      <link>https://stackoverflow.com/questions/52358505/neural-network-undefitting-breast-cancer-dataset</link>
      <description><![CDATA[我正在尝试在乳腺癌数据集上创建一个用于二进制分类的神经网络：
  https://wwwww.kaggle.com/uciml/uciml/uciml/breast-cancer-cancer-wisconsin-data-data-data-data-data-data 
我的神经网络由3层组成（不包括输入层）：

 第一层：6个带有Tanh激活的神经元。

 第二层：6个带有Tanh激活的神经元。

 最终层：1个神经元，带有Sigmoid激活。


不幸的是，我在训练示例中仅获得约44％的精度，在测试示例中的精度约为23％。
这是我的python代码：
 导入numpy作为NP
导入大熊猫作为pd
导入matplotlib.pyplot作为PLT

data = pd.read_csv（&#39;data.csv; quot;）
data = data.drop（[&#39;id&#39;]，轴= 1）
data = data.drop（data.columns [31]，轴= 1）
data = data.replace（{&#39;m&#39;：1，&#39;b&#39;：0}）

x =数据
x = x.drop（[&#39;诊断&#39;]，轴= 1）
x = np.array（x）

x_mean = np.mean（x，axis = 1，keepdims = true）
x_std = np.std（x，axis = 1，keepdims = true）
x_n =（x -x_mean） / x_std
y = np.array（数据[&#39;诊断&#39;]）
y = y.Reshape（569，1）
M = 378
y_train = y [：m，：]
y_test = y [m：，：]

x_train = x_n [：M，：]
x_test = x_n [m :，：]

Def Sigmoid（Z）：
  返回1 /（1 + np.exp（-z））

def dsigmoid（z）：
  返回np.multiply（z，（1 -z））

def tanh（z）：
  返回（np.exp（z）-np.exp（-z）） /（np.exp（z） + np.exp（-z））

def dtanh（z）：
  返回1 -np.square（tanh（z））

def成本（a，y）：
  m = y.形[0]
  返回 - （1.0/m） *np.sum（np.dot（y.t，np.log（a）） + np.dot（（（1 -y）.t，np，np.log（1 -a）））

def train（x，y，型号，epocs，a）：
  W1 =模型[&#39;W1&#39;]
  W2 =模型[&#39;W2&#39;]
  W3 =模型[&#39;W3&#39;]
  
  B1 =模型[&#39;B1&#39;]
  B2 =模型[&#39;B2&#39;]
  B3 =模型[&#39;B3&#39;]
  
  费用= []
  
  对于我的范围（EPOC）：
    
    ＃前传播

    z1 = np.dot（x，w1） + b1
    a1 = tanh（z1）

    z2 = np.dot（a1，w2） + b2
    a2 = tanh（z2）

    z3 = np.dot（a2，w3） + b3
    A3 = Sigmoid（Z3）
    
    costs.append（成本（A3，y））

    #back繁殖
    
    dz3 = z3 -y
    d3 = np.multiply（dz3，dsigmoid（z3））
    dw3 = np.dot（a2.t，d3）
    db3 = np.sum（d3，axis = 0，keepdims = true）

    d2 = np.multiply（np.dot（d3，w3.t），dtanh（z2））
    dw2 = np.dot（a1.t，d2）
    db2 = np.sum（d2，轴= 0，keepdims = true）

    d1 = np.multiply（np.dot（d2，w2.t），dtanh（z1））
    dw1 = np.dot（x.T，d1）
    db1 = np.sum（d1，axis = 0，keepdims = true）

    W1  -  =（A / M） * DW1
    W2- =（A / M） * DW2
    w3- =（a / m） * dw3

    B1  -  =（A / M） * DB1
    b2  -  =（a / m） * db2
    B3  -  =（A / M） * DB3
    
  cache = {&#39;w1&#39;：w1，&#39;w2&#39;：w2，&#39;w3&#39;：w3，&#39;b1&#39;：b1&#39;：b1，&#39;b2&#39;：b2，&#39;b3&#39;：b3}
  返回缓存，成本

np.random.seed（0）

型号= {&#39;w1&#39;：np.random.rand（30，6） * 0.01，&#39;w2&#39;：np.random.rand（6，6） * 0.01，&#39;w3&#39;：np.random.rand（6，1） &#39;b3&#39;：np.random.rand（1，1）}

型号，成本=火车（x_train，y_train，型号，1000，0.1）

plt.plot（[i在范围内（1000）]，费用）
打印（费用[999]）
plt.show（）



def预测（x，y，模型）：
  W1 =模型[&#39;W1&#39;]
  W2 =模型[&#39;W2&#39;]
  W3 =模型[&#39;W3&#39;]
  
  B1 =模型[&#39;B1&#39;]
  B2 =模型[&#39;B2&#39;]
  B3 =模型[&#39;B3&#39;]
  
  z1 = np.dot（x，w1） + b1
  a1 = tanh（z1）

  z2 = np.dot（a1，w2） + b2
  a2 = tanh（z2）

  z3 = np.dot（a2，w3） + b3
  A3 = Sigmoid（Z3）
  
  m = a3.形[0]
  y_predict = np.zeros（（M，1））
  
  对于我的范围（m）：
    y_predict = 1如果a3 [i，0]＆gt; 0.5其他0
  返回y_predict
 ]]></description>
      <guid>https://stackoverflow.com/questions/52358505/neural-network-undefitting-breast-cancer-dataset</guid>
      <pubDate>Sun, 16 Sep 2018 21:24:54 GMT</pubDate>
    </item>
    <item>
      <title>训练模型以识别句子中出现的名称</title>
      <link>https://stackoverflow.com/questions/51476682/training-a-model-to-identify-names-appearing-in-a-sentence</link>
      <description><![CDATA[我有一个数据集，其中包含大约238583人的名称。名称可以包含多个单词：例如：
  Willie Enriquez，James J Johnson，D.J。 khaled 。
 我的问题是在句子中出现这些名称时识别这些名称。我正在尝试创建一个机器学习模型，该模型可以识别输入是否为名称。我的麻烦是找出该模型的输入和输出。由于我有一堆名称，因此我可以训练一个模型，该模型可以识别输入是一个名称时的名称，但是该句子中的其他单词又如何。该模型还应该能够识别不是名称的单词。假设句子中有任何其他单词，那么为此目的的理想数据集是什么？在随机的单词上训练模型并将其标记为非名称是有意义的吗？
（名称出现的整个句子不可用。用户可以绝对键入他/她想要的任何内容）
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/51476682/training-a-model-to-identify-names-appearing-in-a-sentence</guid>
      <pubDate>Mon, 23 Jul 2018 10:30:30 GMT</pubDate>
    </item>
    <item>
      <title>神经网络收敛到零输出</title>
      <link>https://stackoverflow.com/questions/44213659/neural-network-converging-to-zero-output</link>
      <description><![CDATA[我正在尝试训练这个神经网络以对某些数据进行预测。
我在一个小数据集（大约100个记录）上尝试了它，它像魅力一样工作。然后，我插入了新数据集，发现NN收敛到0输出，并且错误收敛于正面示例数量和示例总数之间的比率。
我的数据集由是/否特征（1.0/0.0）组成的，地面真相是/否。
我的假设：
1）有一个本地最小值，输出0（但是我尝试了许多学习率和初始权重的值，它似乎总是在那里收敛）
2）我的体重更新是错误的（但对我来说看起来不错）
3）这只是一个输出缩放问题。我试图扩展输出（即输出/最大（输出）和输出/平均值（输出）），但是结果不如下面提供的代码中看到。我应该以不同的方式扩展它吗？ Softmax？ 
这是代码：
 将大熊猫作为pd导入
导入numpy作为NP
进口泡菜
导入随机
从集合导入违约

alpha = 0.1
n_layers = 10
n_iter = 10
#N_Features = 8
init_scale = 1.0

train = pd.read_csv（“ ./ data/data/prediction.csv”）

y = train [&#39;y_true&#39;]。as_matrix（）
y = np.vstack（y）.astype（float）
ytest = y [18000：]
y = y [：18000]

x = train.drop（[&#39;y_true&#39;]，axis = 1）.as_matrix（）
xtest = x [18000：]。astype（float）
x = x [：18000]

def tanh（x，deriv = false）：
    如果（deriv == true）：
        返回（1 -np.tanh（x）** 2）*alpha
    别的：
        返回np.tanh（x）

def sigmoid（x，deriv = false）：
    如果（deriv == true）：
        返回x*（1-x）
    别的：
        返回1/（1+NP.EXP（-X））

def relu（x，deriv = false）：
    如果（deriv == true）：
        返回0.01 + 0.99*（x＆gt; 0）
    别的：
        返回0.01*x + 0.99*x*（x＆gt; 0）

np.random.seed（）

syn = defaultdict（np.array）

对于我的范围（n_layers-1）：
    syn [i] = init_scale * np.random.random（（len（x [0]），len（x [0]））） -  init_scale/2
syn [n_layers -1] = init_scale * np.random.random（（len（x [0]），1）） -  init_scale/2

l = defaultdict（np.array）
delta = defaultdict（np.array）

对于Xrange（n_iter）中的j
    l [0] = x
    对于我的范围（1，n_layers+1）：
        l [i] = relu（np.dot（l [i-1]，syn [i-1]）））

    错误=（y -l [n_layers]）

    e = np.mean（np.abs（error））
    如果（J％1）== 0：
        打印“ \ niteration” + str（j） +“” + str（n_iter）
        打印“错误：” + str（e）

    delta [n_layers] = error * relu（l [n_layers]，deriv = true） * alpha
    对于我的范围（n_layers-1,0，-1）：
        错误= delta [i+1] .dot（syn [i] .t）
        delta [i] = error * relu（l [i]，deriv = true） * alpha

    对于我的范围（n_layers）：
        syn [i] += l [i] .t.dot（delta [i +1]）



pickle.dump（syn，open（&#39;neural_weights.pkl&#39;，&#39;wb&#39;））

＃用F1量测试
＃回忆= true积极 /（真正的阳性 +虚假负面）
＃precision = true阳性 /（true积极 +误报）

l [0] = xtest
对于我的范围（1，n_layers+1）：
    l [i] = relu（np.dot（l [i-1]，syn [i-1]）））

out = l [n_layers]/max（l [n_layers]）

tp = float（0）
fp = float（0）
fn = float（0）
tn = float（0）

对于l [n_layers] [：50]：
    打印i

对于我的范围（len（ytest））：
    如果出去[i]＆gt; 0.5和ytest [i] == 1：
        TP += 1
    如果输出[i]＆lt; = 0.5和ytest [i] == 1：
        fn += 1
    如果出去[i]＆gt; 0.5和ytest [i] == 0：
        FP += 1
    如果输出[i]＆lt; = 0.5和ytest [i] == 0：
        TN += 1

打印“ TP：” + Str（TP）
打印“ fp：” + str（fp）
打印“ TN：” + Str（TN）
打印“ fn：” + str（fn）

打印“ \ nprecision：” + str（tp/（tp + fp））
打印“回忆：” + str（tp/（tp + fn））

f1 = 2 * tp /（2 * tp + fn + fp）
打印“ \ nf1-measure：” + str（f1）
 
这是输出：
 迭代10 of 10
错误：0.222500767998

迭代1 of 10
错误：0.222500771157

迭代2共10
错误：0.222500774321

迭代3 of 10
错误：0.22250077749

迭代4，共10个
错误：0.222500780663

迭代5 of 10
错误：0.222500783841

迭代6 of 10
错误：0.222500787024

迭代7 of 10
错误：0.222500790212

迭代第8次
错误：0.222500793405

迭代9 of 10
错误：0.222500796602


[0.]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[0.]
[0.]
[4.62182626E-06]
[0.]
[0.]
[0.]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[0.]
[4.62182626E-06]
[0.]
[0.]
[5.04501079E-10]
[5.58610895E-06]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[5.04501079E-10]
[0.]
[0.]
[4.62182626E-06]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[5.58610895E-06]
[0.]
[1.31432294E-05]

TP：28.0
FP：119.0
TN：5537.0
FN：1550.0

精度：0.190476190476
召回：0.0177439797212

F1量表：0.0324637681159
 ]]></description>
      <guid>https://stackoverflow.com/questions/44213659/neural-network-converging-to-zero-output</guid>
      <pubDate>Sat, 27 May 2017 06:21:36 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow拆分培训数据批量</title>
      <link>https://stackoverflow.com/questions/42613747/tensorflow-splitting-training-data-to-batches</link>
      <description><![CDATA[我有一个图像数据集作为一个数组。 （图像数量，长度，宽度，颜色范围）我想将其拆分为批处理并进食张量。做什么的好方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/42613747/tensorflow-splitting-training-data-to-batches</guid>
      <pubDate>Sun, 05 Mar 2017 20:44:14 GMT</pubDate>
    </item>
    <item>
      <title>对神经网络的输入类型很重要？</title>
      <link>https://stackoverflow.com/questions/37438078/does-type-of-input-to-the-neural-network-matter</link>
      <description><![CDATA[我正在做视频分类。
我有一个神经网络，我必须使用视频（图像组）训练。
我可以选择从几个选项更改网络输入的形状。
在所有情况下，我都认为网络体系结构（排列和层数）＆amp;学习参数（LR/Decay/正则化/等）是恒定的。
例如，我可以选择将网络输入作为以下内容之一。

  batch_size x（no_of_imgs*no_of_channels）x高度x宽度{3尺寸输入} 

  batch_size x no_of_imgs x no_of_channels x高度x宽度{4尺寸输入} 

  batch_size x no_of_channels x no_of_imgs x高度x宽度{4尺寸输入} 


输入形状将如何影响网络的准确性？]]></description>
      <guid>https://stackoverflow.com/questions/37438078/does-type-of-input-to-the-neural-network-matter</guid>
      <pubDate>Wed, 25 May 2016 13:04:48 GMT</pubDate>
    </item>
    <item>
      <title>R-鼠标 - 机器学习：从火车到测试集的重复使用插补计划</title>
      <link>https://stackoverflow.com/questions/33500047/r-mice-machine-learning-re-use-imputation-scheme-from-train-to-test-set</link>
      <description><![CDATA[我正在建立一个预测模型，并且正在使用小鼠软件包在我的培训集中插入NAS。由于我需要为测试集重新使用相同的插补方案，因此如何将其重新应用于测试数据？
 ＃生成示例数据
set.seed（333）
mydata＆lt;  -  data.frame（a = as.logical（rbinom（100，1，0.5））），
                     b = as.logical（rbinom（100，1，0.2）），
                     c = as.logical（rbinom（100，1，0.8）），
                     y = as.logical（rbinom（100，1，0.6）））

na_a＆lt;  -  as.logical（rbinom（100，1，0.3））
na_b＆lt;  -  as.logical（rbinom（100，1，0.3））
na_c＆lt;  -  as.logical（rbinom（100，1，0.3））
mydata $ a [na_a]＆lt;  -  na
mydata $ b [na_b]＆lt;  -  na
mydata $ c [na_c]＆lt;  -  na

＃创建火车/测试集
图书馆（Caret）
Intrain＆lt;  -  createAtapartition（mydata $ y，p = .8，list = false）
train＆lt;  -  mydata [intrain，] 
测试＆lt;  -  mydata [-intrain，]

＃将NAS插入火车套装
图书馆（小鼠）
imp＆lt;  - 小鼠（火车，方法=“ logreg”）
Train_imp＆lt;  - 完整（IMP）

＃将插补方案应用于测试集
test_imp＆lt;  -  unknown_function（test，imp $ unknown_data）
 ]]></description>
      <guid>https://stackoverflow.com/questions/33500047/r-mice-machine-learning-re-use-imputation-scheme-from-train-to-test-set</guid>
      <pubDate>Tue, 03 Nov 2015 13:12:09 GMT</pubDate>
    </item>
    <item>
      <title>确定这两个类是可分开的（在2D中算法）</title>
      <link>https://stackoverflow.com/questions/9779179/determine-whether-the-two-classes-are-linearly-separable-algorithmically-in-2d</link>
      <description><![CDATA[有两个类，我们称其为X和O。属于这些类别的许多元素都在XY平面中分布。这是一个示例，其中两个类不可分离。不可能绘制一条直线，完美地将XS和操作系统分开。 
  
 通常如何确定两个类别是否线性分离？。我对一种算法感兴趣，该算法没有对元素数量或它们的分布做出任何假设。 最低计算复杂性的算法当然是首选的。]]></description>
      <guid>https://stackoverflow.com/questions/9779179/determine-whether-the-two-classes-are-linearly-separable-algorithmically-in-2d</guid>
      <pubDate>Mon, 19 Mar 2012 22:58:01 GMT</pubDate>
    </item>
    </channel>
</rss>