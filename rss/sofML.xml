<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 06 Mar 2024 03:13:52 GMT</lastBuildDate>
    <item>
      <title>无法使用keras load_model方法加载模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78111286/unable-to-load-a-model-using-keras-load-model-method</link>
      <description><![CDATA[我正在尝试使用 Flask 将我的 keras 构建的机器学习模型部署到 Web 应用程序上。在我正在观看的教程中，他们通过 keras 导入了模型。由于我有一个在 colabs 中构建的实际模型，因此我需要下载自己的模型并将其放入 pycharm 中。
我到目前为止所尝试的是使用 save_model 方法将模型保存在 colabs 中，并将该 .keras 文件保存到“模型”中。文件夹。然后我将该文件夹导入到我在 pycharm 中工作的目录中。我继续使用 load_model 方法加载模型，但终端不断抛出以下错误消息：
2024-03-05 19:49:31.162551：我tensorflow/core/util/port.cc:113] oneDNN自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量“TF_ENABLE_ONEDNN_OPTS=0”。
2024-03-05 19:49:31.849458：我tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量“TF_ENABLE_ONEDNN_OPTS=0”。
回溯（最近一次调用最后一次）：
  文件“C:\Science Fair\Flask Science Fair\app.py”，第 10 行，在  中
    模型 = load_model(&#39;convlstm_model_saved.keras&#39;)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Python\Lib\site-packages\keras\src\ saving\ saving_api.py”，第 185 行，在 load_model 中
    引发值错误（
ValueError：找不到文件：filepath=convlstm_model_saved.keras。请确保该文件是可访问的“.keras”zip 文件。

我需要 load_model 方法将我的模型分配给稍后代码使用的变量，但目前似乎无法找到该文件。我尝试在 colab 中运行相同的代码，似乎工作正常，但我无法在该项目中使用 colab。]]></description>
      <guid>https://stackoverflow.com/questions/78111286/unable-to-load-a-model-using-keras-load-model-method</guid>
      <pubDate>Wed, 06 Mar 2024 00:59:27 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 中创建一个自定义激活函数，要求将张量 x 提升到小数点</title>
      <link>https://stackoverflow.com/questions/78110583/create-a-custom-activation-function-in-keras-that-requeris-elevating-tensor-x-to</link>
      <description><![CDATA[我正在尝试在 Keras 中实现自定义激活函数，修改 sigmoid 函数如下：

该函数将 X 进行“a”次幂（必须是小数点，例如 0.3）在密集层中，使用 keras 后端解决回归问题。出现的问题是，当我应用服装函数时，它仅在值为整数时生成结果，当值为小数时，回归会生成 NaN。我实现这个方程的方法如下：
将 numpy 导入为 np
将 pandas 导入为 pd
从 keras.models 导入顺序
从 keras.layers 导入密集
将 matplotlib.pyplot 导入为 plt
从 scikeras.wrappers 导入 KerasRegressor
从 sklearn.model_selection 导入 KFold
从 sklearn.model_selection 导入 cross_val_score
从 sklearn.preprocessing 导入 MinMaxScaler
将张量流导入为 tf
从 keras 导入后端为 K

def 自定义激活(x):
    return (1 / (1 + K.exp((-x)**0.5)))) #在此示例中 a=0.5 和 b=1

dataframe = pd.read_csv(“housing.csv”, delim_whitespace=True, header=None)
数据集 = dataframe.values

X = 数据集[:, :13]
Y = 数据集[:, 13]

缩放器 = MinMaxScaler(feature_range=(0.1, 0.9))

X_归一化 = 缩放器.fit_transform(X)
y_normalized = scaler.fit_transform(Y.reshape(-1, 1))

模型=顺序（）
model.add(密集(100,input_shape=(13,),激活=custom_activation))
model.add（密集（1，激活=&#39;线性&#39;））
model.compile(loss=&#39;mean_squared_error&#39;, 优化器=&#39;adam&#39;)

a = model.fit(X_normalized, y_normalized,epochs=100, batch_size=102, verbose=0)
y_hat = model.predict(X_normalized)

文本
我尝试通过进行多次测试来解决这个细节，检查 Keras 是否可以将 X 提高到小数。考虑到要提高的值是 1/2（平方根），我复制了这个案例，我还实现了函数 relu 和 squared，向我展示了它们给出的结果：
def custom_activation(x):
   return (1 / (1 + K.exp((*K.sqrt(-x))))) #b=1

def custom_activation(x)
   return (1 / (1 + K.exp((*K.relu(-x))**0.2))) #b=1

不幸的是，我没有在 keras 后端找到类似于 relu 的东西，但用于线性输出。我观察到的另一个问题是方程 y&#39;=(-x)^(a-1)by(1-y) 的导数，其中元素 (-x)^(a-1 ）在我看来这可能会导致冲突，但是我也不知道如何制作自定义衍生产品。]]></description>
      <guid>https://stackoverflow.com/questions/78110583/create-a-custom-activation-function-in-keras-that-requeris-elevating-tensor-x-to</guid>
      <pubDate>Tue, 05 Mar 2024 21:13:35 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器模型错误？</title>
      <link>https://stackoverflow.com/questions/78110545/wrong-autoencoder-model</link>
      <description><![CDATA[我正在尝试使用张量流创建一个用于异常检测的自动编码器，该模型可以运行，但仅此而已。
这是模型：
int_vectorizer=layers.TextVectorization(
    最大令牌=10000,
    输出模式=&#39;int&#39;,
    输出序列长度=140
）
int_vectorizer.adapt(adapt_data)

模型 = tf.keras.Sequential([
    int_向量化器，
    层.密集（256，激活=“relu”），
    层.密集（128，激活=“relu”），
    层.密集（64，激活=“relu”），
    层.密集（32，激活=“relu”），
    层.密集（64，激活=“relu”），
    层.密集（128，激活=“sigmoid”），`
]）

label_converter=layers.StringLookup(output_mode=“int”)
label_converter.adapt(数据)

model.compile(optimizer=&#39;adam&#39;, loss=“mae”)
model.fit(数据, label_converter(数据), epochs=200)

测试时，我得到以下 2 个输入的相同百分比水平：
Inpus
我尝试更改层、节点数量、单元数量和不同的激活。]]></description>
      <guid>https://stackoverflow.com/questions/78110545/wrong-autoencoder-model</guid>
      <pubDate>Tue, 05 Mar 2024 21:05:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 LSTM 的多变量时间序列</title>
      <link>https://stackoverflow.com/questions/78110519/multiple-multipvariate-time-series-with-lstm</link>
      <description><![CDATA[我正在处理的数据集可以在下面找到。
https://www.kaggle.com/datasets/behrad3d/nasa -cmaps/数据
数据是多个多元时间序列数据。该数据集跟踪发动机整个生命周期的 26 个特征，直至发生故障。它为 100 种不同的引擎执行此操作。有一个时间周期功能，它记录直到故障为止的时间周期数，从 1 开始。在我们的训练集中，我们可以从引擎当前的生命周期中减去引擎的最大时间周期，以获得 RUL，剩余可用生命周期，即我们将预测的功能。我们的测试集不包含 100 个引擎的完整生命周期数据。模型必须利用有限的数据来预测发动机的RUL。
我的数据集的当前形状是 20631, 126（我进行了特征工程，得到了 126 个特征）。这 20631 行包含 100 个引擎的时间序列数据。我知道如何将它们分成训练集和测试集，同时保持每个引擎数据的时间顺序。但需要注意的一件事是，引擎没有相同数量的 Time_Cycle。
我应该如何训练我的 LSTM，使其将每个引擎视为多元时间序列，并训练我将用于对所有 100 个引擎进行预测的模型？
下面是我编写的代码，但我认为它对数据的训练就好像它是一个引擎一样。我需要重塑我的输入吗？或者添加更多层？
从 keras.models 导入顺序
从 keras.layers 导入 LSTM，密集
从 keras.optimizers 导入 Adam
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.model_selection 导入 train_test_split
将 numpy 导入为 np

# 将训练数据分为训练数据和测试数据
train_diff = train_diff.fillna(method=&#39;backfill&#39;)
如果 test_diff.columns 中为“RUL_pred”：
    test_diff = test_diff.drop(列=[&#39;RUL_pred&#39;])
test_diff = test_diff.fillna(method=&#39;backfill&#39;)

np.随机.种子(42)
random_indices = np.random.choice（列表（范围（1,101）），大小= 30，替换= False）

X_train = train_diff[~train_diff[&#39;unit_number&#39;].isin(random_indices)]
X_test = train_diff[train_diff[&#39;unit_number&#39;].isin(random_indices)]

Y_train = X_train[&#39;RUL&#39;]
Y_test = X_test[&#39;RUL&#39;]

X_train = X_train.drop(列=[&#39;RUL&#39;])
X_test = X_test.drop(列=[&#39;RUL&#39;])

缩放器 = MinMaxScaler()
缩放器.fit(X_train)
X_train_s = 缩放器.transform(X_train)
X_test_s = 缩放器.transform(X_test)
test_diff_s = 缩放器.transform(test_diff)

# 定义LSTM模型架构
模型=顺序（）
model.add(LSTM(units=64, input_shape=(X_train_s.shape[1], 1))) # 假设 X_train_s 已缩放
model.add(密集(单位=1))

# 编译模型
model.compile(optimizer=Adam(), loss=&#39;mean_squared_error&#39;)

# 重塑 LSTM 输入的数据（假设 X_train_s 和 X_test_s 已缩放）
X_train_s_lstm = np.reshape(X_train_s, (X_train_s.shape[0], X_train_s.shape[1], 1))
X_test_s_lstm = np.reshape(X_test_s, (X_test_s.shape[0], X_test_s.shape[1], 1))

# 训练 LSTM 模型
历史= model.fit（X_train_s_lstm，Y_train，epochs = 100，batch_size = 32，validation_split = 0.2）

# 对测试数据进行预测
y_lstm_pred = model.predict(X_test_s_lstm)

]]></description>
      <guid>https://stackoverflow.com/questions/78110519/multiple-multipvariate-time-series-with-lstm</guid>
      <pubDate>Tue, 05 Mar 2024 20:58:38 GMT</pubDate>
    </item>
    <item>
      <title>改进的模糊 c 均值算法将簇收敛到相同的坐标</title>
      <link>https://stackoverflow.com/questions/78110231/modified-fuzzy-c-means-algorithm-converges-clusters-to-same-coordinates</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78110231/modified-fuzzy-c-means-algorithm-converges-clusters-to-same-coordinates</guid>
      <pubDate>Tue, 05 Mar 2024 19:50:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLO 进行预测模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/78110123/prediction-model-with-yolo</link>
      <description><![CDATA[我想知道是否可以使用 yolo 模型，并对其进行更改，使其成为实时图像输入的预测模型，并使用我自己的图像数据集训练模型。最终应该是一个具有实时图像输入的模型，使用我的数据集进行训练，并输出最有可能的百分比。]]></description>
      <guid>https://stackoverflow.com/questions/78110123/prediction-model-with-yolo</guid>
      <pubDate>Tue, 05 Mar 2024 19:26:48 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 自定义和默认目标和评估函数</title>
      <link>https://stackoverflow.com/questions/78109955/xgboost-custom-default-objective-and-evaluation-functions</link>
      <description><![CDATA[我正在训练 BDT 以进行信号/背景的二元分类（我从事粒子物理学工作）。我的模型（用 python 实现）如下所示：
导入 xgboost 为 xgb
train = xgb.DMatrix(data=train_df[特征],label=train_df[“标签”],
                    缺失=“inf”，feature_names=特征，权重=(np.array(train_df[&#39;label&#39;].array)*-0.99+1))
测试= xgb.DMatrix(数据=test_df[特征],标签=test_df[“标签”],
                   缺失=“inf”，feature_names=特征，权重=(np.array(test_df[&#39;label&#39;].array) *-0.99+1))

参数 = {}


# 助推器参数
param[&#39;eta&#39;] = 0.1 # 学习率
param[&#39;max_depth&#39;] = 10 # 树的最大深度
param[&#39;subsample&#39;] = 0.5 # 训练树的事件分数
param[&#39;colsample_bytree&#39;] = 0.5 # 训练树的特征分数

# 学习任务参数
param[&#39;objective&#39;] = &#39;binary:logistic&#39; # 目标函数
param[&#39;eval_metric&#39;] = &#39;error&#39; # 交叉验证的评估指标
param = list(param.items()) + [(&#39;eval_metric&#39;, &#39;logloss&#39;)] + [(&#39;eval_metric&#39;, &#39;rmse&#39;)]


num_trees = 50 # 要制作的树的数量
booster = xgb.train(参数,train,num_boost_round=num_trees)

该模型表现良好，但我想稍微修改一下成本/损失函数，以便误报比真报受到更多惩罚。我正在寻找背景事件尽可能少的选择，即使这意味着牺牲信号的很大一部分。
根据自定义目标和评估函数的文档，我成功添加教程案例。
哪些是标准目标和评估函数（或者我可能已经在模型中实现的函数）？
由于模型已经表现良好，我只想为已经实现的功能添加一个额外的术语。
作为参考，我正在使用的软件包版本：
python 版本：3.10.12（主要，2023 年 11 月 20 日，15:14:05）[GCC 11.4.0]
XGBoost版本：2.0.2
熊猫版本：2.1.4
Numpy 版本：1.26.2
]]></description>
      <guid>https://stackoverflow.com/questions/78109955/xgboost-custom-default-objective-and-evaluation-functions</guid>
      <pubDate>Tue, 05 Mar 2024 18:53:51 GMT</pubDate>
    </item>
    <item>
      <title>为什么epoch02这么慢？</title>
      <link>https://stackoverflow.com/questions/78109909/why-is-epoch02-so-slow</link>
      <description><![CDATA[我正在 Mac M2 芯片上训练 YOLOV9。第一个 epoch 花了 7 分钟，但第二个 epoch 花了 2 小时。为什么两个 epoch 的训练时间相差这么大？
我的代码
# DDP模式
如果不是 torch.backends.mps.is_available():
    如果不是 torch.backends.mps.is_built():
        print(“MPS 不可用，因为当前 PyTorch 安装不是”
              “在启用 MPS 的情况下构建。”）
    别的：
        print(&quot;MPS 不可用，因为当前的 MacOS 版本不是 12.3+ &quot;
              “和/或您在此计算机上没有支持 MPS 的设备。”）
    设备= select_device(opt.device,batch_size=opt.batch_size)
别的：
    device = torch.device(“mps”)
如果 LOCAL_RANK ！= -1：
    msg = &#39;与 YOLO 多 GPU DDP 训练不兼容&#39;
    断言不是 opt.image_weights, f&#39;--image-weights {msg}&#39;
    断言不是 opt.evolve, f&#39;--evolve {msg}&#39;
    断言 opt.batch_size != -1, f&#39;AutoBatch with --batch-size -1 {msg}，请传递有效的 --batch-size&#39;
    断言 opt.batch_size % WORLD_SIZE == 0, f&#39;--batch-size {opt.batch_size} 必须是 WORLD_SIZE&#39; 的倍数
    断言 torch.backends.mps.is_available(),“MPS 不可用。检查 PyTorch 版本、macOS 版本和硬件”
    # 断言 torch.cuda.device_count() &gt; LOCAL_RANK，“用于 DDP 命令的 CUDA 设备不足”
    device = torch.device(“mps”)
    dist.init_process_group(backend=“nccl” if dist.is_nccl_available() else “gloo”)

批量大小 = 8
我将批量大小设置为 8。
您可以看到GPU确实正在被使用。
在此处输入图片描述
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78109909/why-is-epoch02-so-slow</guid>
      <pubDate>Tue, 05 Mar 2024 18:43:43 GMT</pubDate>
    </item>
    <item>
      <title>Accuracy_score 出现错误</title>
      <link>https://stackoverflow.com/questions/78109873/erroring-in-accuracy-score</link>
      <description><![CDATA[我想在 jupyter 笔记本的数据框中使用 precision_score 但出现此错误：
ValueError：不支持连续

我写道：
从sklearn.metrics导入accuracy_score
train_prediction = model.predict(X_train)
训练准确度=准确度得分（y_train，train_prediction）
]]></description>
      <guid>https://stackoverflow.com/questions/78109873/erroring-in-accuracy-score</guid>
      <pubDate>Tue, 05 Mar 2024 18:38:58 GMT</pubDate>
    </item>
    <item>
      <title>对于具有协变量和缺失日期的多元时间序列插补，我应该选择哪种模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78109616/which-model-should-i-select-for-a-multivariate-time-series-imputation-where-i-ha</link>
      <description><![CDATA[我有两年时间范围内商店的销售数据。样本数据：

&lt;标题&gt;

日期
目标商店销售额
目标商店促销
Sales_Store1
Promotion_Store1
Sales_Store2
Promotion_Store1


&lt;正文&gt;

2022-06-27
30.0
否
29.0
是
34.0
是


2022-06-28
42.0
否
空
否
39.0
否


2022-06-29
37.0
否
26.0
是
37.0
是


2022-07-02
45.0
否
44.0
否
空
否


2022-07-03
29.0
否
空
是
24.0
是


2022-07-05
34.0
否
40.0
否
42.0
否



为了扩展我的（希望是正确的）问题标题，我想做的是使用上表作为我的训练集来预测我的 Target 商店销售额的基线，希望找到特定促销的提升。该表已根据“目标商店促销”列进行筛选，因此它仅包含没有促销的日期。促销活动每天进行。 Sales_Store1和Promotion_Store1包含类似商店的销售和促销状态。我对他们的选择相当有信心。
示例表的其余部分如下：

&lt;标题&gt;

日期
目标商店销售额
目标商店促销
Sales_Store1
Promotion_Store1
Sales_Store2
Promotion_Store1


&lt;正文&gt;

2022-06-30
55.0
是
34.0
是
67.0
是


2022-07-04
47.0
是
66.0
否
55.0
是



数据具有很强的季节性，但目标商店和所使用的类似商店也有许多缺失值。商店的销售天数约为 600 天。
此外，值得注意的是，使用综合控制的 A/B 测试在这里会失败，因为促销在商店之间是高度同步的。也就是说，如果我的目标商店有正在进行的促销活动，那么很有可能类似的商店也会这样做。 （但不一定）
我希望结果表看起来像这样：

&lt;标题&gt;

日期
目标商店销售额
没有促销的目标商店销售额
目标商店促销
Sales_Store1
Promotion_Store1
Sales_Store2
Promotion_Store1


&lt;正文&gt;

2022-06-30
55.0
45.0
是
34.0
是
67.0
是


2022-07-04
47.0
32.0
是
66.0
否
55.0
是



您知道哪种模型或技术可以帮助我预测此基线吗？我正在研究新的 Tide，但在深入研究之前并尝试使用它，我想我应该问问是否有人遇到过类似的挑战。预先感谢！
我最初尝试了典型的 A/B 测试，同时消除协变量，但剩余的数据样本太少了。正如我提到的，大多数促销活动在各商店同时进行。
我尝试使用上述功能（以及月份和工作日等功能）训练 XGBoost 回归器，希望能够捕获季节性，但结果平庸，MAPE 约为 0.15。]]></description>
      <guid>https://stackoverflow.com/questions/78109616/which-model-should-i-select-for-a-multivariate-time-series-imputation-where-i-ha</guid>
      <pubDate>Tue, 05 Mar 2024 17:48:57 GMT</pubDate>
    </item>
    <item>
      <title>修改ML预处理函数以在Google Cloud TPU上进行训练</title>
      <link>https://stackoverflow.com/questions/78109089/modify-ml-preprocessing-function-to-train-on-google-cloud-tpu</link>
      <description><![CDATA[在此处输入图像描述
请帮助我提高 TPU 上的 CPU 使用率。
目前仅使用了 0.5%（附截图）
&lt;前&gt;&lt;代码&gt;最大输入长度 = 128
最大目标长度 = 128

source_lang = &quot;en&quot;;
target_lang =“嗨”

def preprocess_function（示例）：
输入 = \[ex\[source_lang\] 示例中的 ex\[“翻译”\]\]
目标 = \[ex\[target_lang\] 示例中的 ex\[“翻译”\]\]
model_inputs = tokenizer(输入, max_length=max_input_length, 截断=True)

# 为目标设置标记器
使用 tokenizer.as_target_tokenizer()：

标签=分词器（目标，max_length = max_target_length，截断= True）

model_inputs[“labels”] = labels[“input_ids”]
返回模型输入

我尝试增加批处理大小，但 RAM 使用量只会增加。
训练时间保持不变且没有减少。]]></description>
      <guid>https://stackoverflow.com/questions/78109089/modify-ml-preprocessing-function-to-train-on-google-cloud-tpu</guid>
      <pubDate>Tue, 05 Mar 2024 16:13:37 GMT</pubDate>
    </item>
    <item>
      <title>我无法使用 DiscreteDistribution 函数 [重复]</title>
      <link>https://stackoverflow.com/questions/78108981/i-am-not-able-use-discretedistribution-function</link>
      <description><![CDATA[a = DiscreteDistribution({&#39;1&#39;: 1./10, &#39;0&#39;: 9./10})

在这一行中，代码不断抛出错误，在您说“是”之前，我已经安装了石榴并且也导入了它，但仍然显示此错误。我问过 chatgpt，据它说我的代码完全没问题。您认为问题出在哪里？石榴的版本会影响我的代码吗？
我试图创建贝叶斯网络，并且试图获得简单图的概率。我在第一行写了：from pomegranate import *。
NameError：名称“DiscreteDistribution”未定义

这是错误。]]></description>
      <guid>https://stackoverflow.com/questions/78108981/i-am-not-able-use-discretedistribution-function</guid>
      <pubDate>Tue, 05 Mar 2024 15:53:30 GMT</pubDate>
    </item>
    <item>
      <title>尝试建立一个lstm模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78108041/trying-to-build-an-lstm-model</link>
      <description><![CDATA[我正在构建一个 lstm 模型并出现形状错误
&lt;前&gt;&lt;代码&gt;模型 = 顺序()
词汇大小 = 10000
嵌入尺寸 = 100
最大序列长度 = 21
model.add(嵌入(input_dim=vocab_size,
output_dim=embedding_dim))
model.add(LSTM(单位=50,return_sequences=False))
model.add（密集（单位= 1，激活=&#39;sigmoid&#39;））
model.compile(loss=&#39;binary_crossentropy&#39;, 优化器=&#39;adam&#39;,
指标=[&#39;准确性&#39;])
模型.summary()

错误：
输入张量的输入形状无效(“sequential_4_1/Cast:0”,
形状=（无，21），dtype=float32）。预期形状（无、9144、
21)，但输入的形状不兼容（无，21）
Sequential.call() 收到的参数：
输入=tf.Tensor（形状=（无，21），dtype=int64）
• 训练=真
• 掩码=无
]]></description>
      <guid>https://stackoverflow.com/questions/78108041/trying-to-build-an-lstm-model</guid>
      <pubDate>Tue, 05 Mar 2024 13:22:01 GMT</pubDate>
    </item>
    <item>
      <title>尝试训练 Tensorflow.Net 模型时，未将对象引用设置为对象的实例[重复]</title>
      <link>https://stackoverflow.com/questions/78107434/object-reference-not-set-to-an-instance-of-an-object-when-attempting-to-train-te</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78107434/object-reference-not-set-to-an-instance-of-an-object-when-attempting-to-train-te</guid>
      <pubDate>Tue, 05 Mar 2024 11:37:44 GMT</pubDate>
    </item>
    <item>
      <title>我在使用石榴时遇到问题，它不允许我使用 DiscreteDistribution [关闭]</title>
      <link>https://stackoverflow.com/questions/78100004/i-had-a-problem-using-pomegranate-that-it-wont-let-me-use-discretedistribution</link>
      <description><![CDATA[a = DiscreteDistribution({&#39;1&#39;: 1./10, &#39;0&#39;: 9./10})

在这一行中，代码不断抛出错误，在您说“是”之前，我已经安装了石榴并且也导入了它，但仍然显示此错误。我问过 chatgpt，据它说我的代码完全没问题。您认为问题出在哪里？石榴的版本会影响我的代码吗？我是菜鸟，这些东西我都不懂。
我试图创建贝叶斯网络，并且我试图获得一个简单图的概率。我在第一行写了： from pomegranate import * 。
NameError：名称“DiscreteDistribution”未定义

这是错误。]]></description>
      <guid>https://stackoverflow.com/questions/78100004/i-had-a-problem-using-pomegranate-that-it-wont-let-me-use-discretedistribution</guid>
      <pubDate>Mon, 04 Mar 2024 08:55:30 GMT</pubDate>
    </item>
    </channel>
</rss>