<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 08 Feb 2024 15:14:40 GMT</lastBuildDate>
    <item>
      <title>如何将 pytorch 模型转换为 ONNX</title>
      <link>https://stackoverflow.com/questions/77962736/how-to-convert-a-pytorch-model-to-onnx</link>
      <description><![CDATA[我想将 pytorch 模型转换为 ONNX，因为我需要使用 STM32CubeIDE 将模型移植到嵌入式平台上。
Python 代码：
cp = torch.load(&#39;bestmodelw.pth&#39;)
mymodel.load_state_dict(cp[&#39;state_dict&#39;])
mymodel.eval()

示例 = torch.randn(1, 4, 128)
torch.onnx.export（我的模型，
                  例子，
                  在nx路径上，
                  输入名称 = [&#39;输入&#39;],
                  输出名称 = [&#39;输出&#39;],
                  导出参数=真，
                  详细=真实，
                  opset_版本 = 15)

我获得了 .onnx 文件，但如果我使用 Netron 打开模型，我可以看到每个卷积层都有 2 个输入。 STM32CubeIDE 不支持具有 2 个输入的卷积层，因此我无法使用此模型。
有人可以帮我吗？
STM32CubeIDE 还支持 .h5 文件，因此我尝试将 .onnx 转换为 keras 模型 (.h5)，但出现此错误消息发生KeyError：&#39;ReduceMin&#39;。]]></description>
      <guid>https://stackoverflow.com/questions/77962736/how-to-convert-a-pytorch-model-to-onnx</guid>
      <pubDate>Thu, 08 Feb 2024 15:09:57 GMT</pubDate>
    </item>
    <item>
      <title>数组重塑问题</title>
      <link>https://stackoverflow.com/questions/77962428/issue-with-array-reshape</link>
      <description><![CDATA[将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
从 pandas 导入 read_csv
将张量流导入为 tf
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从tensorflow.keras.layers导入LSTM
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.metrics 导入mean_squared_error
# 将值数组转换为数据集矩阵
def create_dataset(数据集,look_back=1):
    数据X，数据Y = []，[]
    对于范围内的 i（len（数据集）-look_back-1）：
        a = 数据集[i:(i + Look_back),0]
        dataX.append(a)
        dataY.append(数据集[i + Look_back, 0])
    返回 np.array(dataX), np.array(dataY)
# 修复随机种子以提高可重复性
tf.random.set_seed(7)
# 加载数据集
dataframe = read_csv(&#39;airline-passengers.csv&#39;, engine=&#39;python&#39;)
数据集 = dataframe.values
数据集 = dataset.astype(&#39;float32&#39;)
# 标准化数据集
缩放器 = MinMaxScaler(feature_range=(0, 1))
数据集=scaler.fit_transform（数据集）
# 分为训练集和测试集
train_size = int(len(数据集) * 0.67)
test_size = len(数据集) - train_size
训练，测试=数据集[0：train_size，：]，数据集[train_size：len（数据集），：]
# 重塑为 X=t 和 Y=t+1
回望 = 1
trainX，trainY = create_dataset（火车，look_back）
testX，testY = create_dataset（测试，look_back）
# 将输入重塑为[样本、时间步长、特征]
trainX = np.reshape(trainX, (trainX.shape[0],1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0],1, testX.shape[1]))
# 创建并拟合 LSTM 网络
模型=顺序（）
model.add(LSTM(4, input_shape=(look_back, 1)))
model.add(密集(1))
model.compile(loss=&#39;mean_squared_error&#39;, 优化器=&#39;adam&#39;)
model.fit(trainX,trainY,epochs=100,batch_size=1,verbose=2)
＃ 作出预测
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
# 反转预测（确保 inverse_transform 的形状一致）
trainPredict = scaler.inverse_transform(trainPredict.reshape(-1, 1))

我正在获取
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-804718ba5c36&gt;在&lt;细胞系：54&gt;()
     52 testPredict = 模型.predict(testX)
     53 # 反转预测（确保 inverse_transform 的形状一致）
---&gt; 54 trainPredict =scaler.inverse_transform(trainPredict.reshape(-1, 1))
     55 trainY = 缩放器.inverse_transform(trainY.reshape(-1, 1))
     56 testPredict = 缩放器.inverse_transform(testPredict.reshape(-1, 1))

inverse_transform(self, X) 中的 /usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py
    第539章）
    540
--&gt;第541章
    第542章
    第543章

ValueError：形状为 (94,1) 的不可广播输出操作数与广播形状 (94,2) 不匹配

这是我的代码和 r.我的数据库由两列组成，包括月份和乘客数量。我在重塑数组时遇到错误。请帮助我找到此错误的解决方案。顺便说一句，我是个新手。”“”“”“”“”“”“”“”“”“”“”“” ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` &#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;]]></description>
      <guid>https://stackoverflow.com/questions/77962428/issue-with-array-reshape</guid>
      <pubDate>Thu, 08 Feb 2024 14:25:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在简单的 Pytorch 模型中实现所有可能的快捷方式连接</title>
      <link>https://stackoverflow.com/questions/77962181/how-to-implement-all-possible-shortcut-connections-in-a-simple-pytorch-model</link>
      <description><![CDATA[我正在尝试重现论文中的结果
PROBEN1 - 一组神经网络基准问题和基准规则 1994 年，Luttz Prechelt 与数据集 cancer1
他们描述的架构具有“所有可能的前馈连接”。
有了 2 个隐藏层和一个标准神经网络，这意味着添加连接：
输入到H2
输入到输出
H1 到输出？
隐藏激活函数是S形的，输出激活函数是线性的。
如果是这样，我该怎么做？
这是我的模型：
类 PROBEN1(nn.Module):
    def __init__(自身, in_features=9, hl1=4, hl2=2, out_features=2):
        超级().__init__()
        self.hidden1 = nn.Linear(in_features, hl1)
        self.act1 = nn.Sigmoid()
        self.hidden2 = nn.Linear(hl1, hl2)
        self.act2 = nn.Sigmoid()
        self.output = nn.Linear(hl2, out_features)
        self.double()
    def 前向（自身，x）：
        x = self.hidden1(x)
        x = self.act1(x)
        x = self.hidden2(x)
        x = self.act2(x)
        返回x

我尝试在前向函数中连接 act2 的输入，但尺寸不正确。这也是我在网上看到的。然而，有了 x 个新连接，我们就会有 x 个新权重，并且此方法不会添加任何我觉得令人困惑的参数。]]></description>
      <guid>https://stackoverflow.com/questions/77962181/how-to-implement-all-possible-shortcut-connections-in-a-simple-pytorch-model</guid>
      <pubDate>Thu, 08 Feb 2024 13:45:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在 VotingRegressor 中添加带有回归模型的 Prophet？</title>
      <link>https://stackoverflow.com/questions/77962030/how-to-add-a-prophet-with-regressor-models-in-votingregressor</link>
      <description><![CDATA[我正在尝试制作 3 个模型的集成：Prophet、XGBoost 和 Support Vector Regressor。
但是，XGBoost 和 支持向量机 是回归模型，而 Prophet 是估计器。
当我尝试将 3 个模型组合在一起时：
ensemble_model = VotingRegressor([
     (&#39;先知&#39;, model_prod_prophet),
     （&#39;XGBoost&#39;，model_prod_xgb），
     (&#39;SVR&#39;, model_prod_svr)])

我发现错误：
ValueError：估计器 Prophet 应该是回归器。

如何修复这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/77962030/how-to-add-a-prophet-with-regressor-models-in-votingregressor</guid>
      <pubDate>Thu, 08 Feb 2024 13:22:58 GMT</pubDate>
    </item>
    <item>
      <title>无法为 HeteroData 创建 NeighborLoader：“EdgeStorage”对象没有属性“num_nodes”</title>
      <link>https://stackoverflow.com/questions/77961450/cant-create-a-neighborloader-for-heterodata-edgestorage-object-has-no-attrib</link>
      <description><![CDATA[当我尝试为我的数据创建 NeighborLoader 时，出现以下错误。
AttributeError：“EdgeStorage”对象没有属性“num_nodes”

我加载图表并使用 RandomNodeSplit 将其拆分为训练/测试/验证，然后，我尝试将拆分数据传递到 NeighborLoader 中并得到上面的错误。
使用的代码：
data = torch.load(training_config[&#39;data_file&#39;])
目标 = pd.read_pickle(training_config[&#39;targets_file&#39;])
打印（类型（数据））

# 创建训练、测试和 VAL 掩码
split = T.RandomNodeSplit(num_val=training_config[&#39;validation_split&#39;], num_test=training_config[&#39;test_split&#39;])
data_split = 分割（数据）
data_split.num_nodes = data.num_nodes
打印（数据分割）
打印（类型（数据分割））
采样器 = ImbalancedSampler(data_split[&#39;word&#39;].y, input_nodes=data_split[&#39;word&#39;].train_mask)

train_loader = NeighborLoader(
    数据分割，
    num_neighbors=[10] * 2,
    batch_size=training_config[&#39;batch_size&#39;],
    input_nodes=data_split[&#39;word&#39;].train_mask,
    采样器=采样器
）

这是这些打印语句的结果：
&lt;类&#39;torch_geometric.data.hetero_data.HeteroData&#39;&gt;

异质数据（
  num_classes=2,
  num_nodes=59565,
  字={
    y=[39566],
    x=[39566, 2],
    train_mask=[39566],
    val_mask=[39566],
    test_mask=[39566],
  },
  句子={ x=[19999, 1] },
  (word, depGraph, word)={ edge_index=[2, 934] },
  (词, 头, 词)={ edge_index=[2, 934] },
  (单词, previousWord, 单词)={ edge_index=[2, 842] },
  (单词, fromSentence, 句子)={ edge_index=[2, 574] },
  (单词, 下一个单词, 单词)={ edge_index=[2, 842] },
  (word, pos, pos)={ edge_index=[2, 39566] },
  (字, 边, 边)={ edge_index=[2, 39566] },
  (word, feat_aspect, feat_aspect)={ edge_index=[2, 1318] },
  (word, feat_case, feat_case)={ edge_index=[2, 1251] },
  (word, feat_conjtype, feat_conjtype)={ edge_index=[2, 708] },
  (word, feat_definite, feat_definite)={ edge_index=[2, 5349] },
  (单词, feat_ Degree, feat_ Degree )={ edge_index=[2, 2735] },
  (单词, feat_foreign, feat_foreign)={ edge_index=[2, 19] },
  (单词, feat_gender, feat_gender)={ edge_index=[2, 169] },
  (单词, feat_mood, feat_mood)={ edge_index=[2, 307] },
  (单词, feat_number, feat_number)={ edge_index=[2, 14435] },
  (word, feat_numtype, feat_numtype)={ edge_index=[2, 1588] },
  (word, feat_person, feat_person)={ edge_index=[2, 1713] },
  (单词, feat_polity, feat_polarity)={ edge_index=[2, 35] },
  (word, feat_poss, feat_poss)={ edge_index=[2, 142] },
  (单词, feat_prontype, feat_prontype)={ edge_index=[2, 7914] },
  (word, feat_punctside, feat_punctside)={ edge_index=[2, 1344] },
  (单词, feat_puncttype, feat_puncttype)={ edge_index=[2, 3603] },
  (word, feat_tense, feat_tense)={ edge_index=[2, 1895] },
  (单词, feat_verbform, feat_verbform)={ edge_index=[2, 2457] },
  (句子, 下一个句子, 句子)={ edge_index=[2, 39996] }
）

&lt;类“torch_geometric.data.hetero_data.HeteroData”&gt;

所以类型是 HeteroData，但是，NeighborLoader 在某处获取 EdgeStorage，而我无法使用它来批处理我的数据？我可以尝试解决此问题吗？
我可以在不进行批处理的情况下训练 SageConv，但是，我想尝试一下，看看它如何影响我的结果。]]></description>
      <guid>https://stackoverflow.com/questions/77961450/cant-create-a-neighborloader-for-heterodata-edgestorage-object-has-no-attrib</guid>
      <pubDate>Thu, 08 Feb 2024 11:53:39 GMT</pubDate>
    </item>
    <item>
      <title>GitHub CoPilot 引用自定义库代码</title>
      <link>https://stackoverflow.com/questions/77961323/github-copilot-referring-custom-library-code</link>
      <description><![CDATA[我们希望将自定义开源库（来自 GitHub Repo 的 CSS 样式、React 组件、Typescript 规则等）包含到我们的代码生成过程中。我们如何将其添加到 GitHub Copilot 以供代码生成时参考？这将使我们能够生成我们的库固有的定制代码。我们知道不可能为我们的项目需求培训法学硕士。然而，还有其他方法吗？我们使用的是商业版。
我们从 CoPilot 那里得到了针对同一问题的以下回复。但是，我们不确定给定的提示是否合适。
&lt;块引用&gt;
截至目前，GitHub Copilot 不支持在其代码生成过程中包含来自特定 GitHub 存储库的自定义库或代码。它接受过广泛的公共代码的训练，但它不了解特定的代码库、库或框架。它无法访问或引用特定存储库或库来生成代码。它根据训练期间学到的模式生成建议。
]]></description>
      <guid>https://stackoverflow.com/questions/77961323/github-copilot-referring-custom-library-code</guid>
      <pubDate>Thu, 08 Feb 2024 11:33:08 GMT</pubDate>
    </item>
    <item>
      <title>我使用 OpenCV Python 库在 python 中运行代码时遇到问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/77961054/i-have-a-problem-running-a-code-in-python-using-opencv-python-library</link>
      <description><![CDATA[我正在使用 OpenCV Python 库使用 jubyter 创建图像分类器模型，问题是代码是正确的，但库中的函数仍然存在问题，我不知道问题是否出在 OpenCV 版本中或别的东西
错误群发
我正在编写图像分类器代码，并且此单元格中发生了错误
这是错误消息中的函数]]></description>
      <guid>https://stackoverflow.com/questions/77961054/i-have-a-problem-running-a-code-in-python-using-opencv-python-library</guid>
      <pubDate>Thu, 08 Feb 2024 10:53:03 GMT</pubDate>
    </item>
    <item>
      <title>机器学习训练缓慢</title>
      <link>https://stackoverflow.com/questions/77960959/machine-learning-training-slowly</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77960959/machine-learning-training-slowly</guid>
      <pubDate>Thu, 08 Feb 2024 10:38:26 GMT</pubDate>
    </item>
    <item>
      <title>是否有一种工具或强大的应用程序技术可以让我们根据数据集自动填充 Excel 工作表中问题的答案？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77959600/is-there-a-tool-or-power-apps-technique-where-we-can-auto-populate-the-responses</link>
      <description><![CDATA[是否有一种工具或强大的应用程序技术可以让我们根据数据集自动填充 Excel 工作表中问题的答案？
示例 - 我们有一个包含 200 个问题和答案的数据集，我们必须根据工作表中提出的 20 个问题自动用答案填充 Excel 工作表。这应该是一个自动化的过程。
请告诉我市场上是否有可用的工具或我们可以使用的技术。
我尝试了 copilot，我们可以单独获得响应，但需要更加自动化和快速的流程。]]></description>
      <guid>https://stackoverflow.com/questions/77959600/is-there-a-tool-or-power-apps-technique-where-we-can-auto-populate-the-responses</guid>
      <pubDate>Thu, 08 Feb 2024 06:14:52 GMT</pubDate>
    </item>
    <item>
      <title>就地修剪 nn.Linear 权重会导致意外错误，需要稍微奇怪的解决方法。需要解释</title>
      <link>https://stackoverflow.com/questions/77959410/pruning-nn-linear-weights-inplace-causes-unexpected-error-requires-slightly-wei</link>
      <description><![CDATA[失败
导入火炬

def 测试1():
  层 = nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试1()

有错误
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
RuntimeError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-bb36a010bd86&gt;在&lt;细胞系：10&gt;()
      8 x = 5 - torch.sum(layer(torch.ones(90)))
      9 x.backward()
---&gt; 10 测试1()
     11 # 这也有效
     12

2帧
/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py 向后（张量，grad_tensors，retain_graph，create_graph，grad_variables，输入）
    249 # 一些 Python 版本打印多行函数的第一行
    [第 250 章]
--&gt; 251 Variable._execution_engine.run_backward( # 调用 C++ 引擎来运行向后传递
    252个张量，
    第253章

RuntimeError: 函数 TBackward0 在索引 0 返回无效渐变 - 得到 [10, 90] 但预期形状与 [10, 100] 兼容

这有效
导入火炬

def test2():
  层 = torch.nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  del x #主要变化
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试2()

这也有效
导入火炬
def test3():
  层 = torch.nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  layer.weight = torch.nn.Parameter(layer.weight) #主要变化
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试3()

我在尝试实现一篇关于模型修剪的论文时遇到了这个问题。我相信这与 autograd 图有关，但我不确定到底发生了什么。有什么解释为什么这些几乎相同的代码片段有效或失败？]]></description>
      <guid>https://stackoverflow.com/questions/77959410/pruning-nn-linear-weights-inplace-causes-unexpected-error-requires-slightly-wei</guid>
      <pubDate>Thu, 08 Feb 2024 05:17:32 GMT</pubDate>
    </item>
    <item>
      <title>错误：OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: 错误：(-215:断言失败) !_src.empty() 在函数“cvtColor”中</title>
      <link>https://stackoverflow.com/questions/77957561/error-opencv4-8-0-io-opencv-modules-imgproc-src-color-cpp182-error-215</link>
      <description><![CDATA[augmented_yes = &#39;/content/drive/MyDrive/脑肿瘤检测/augmented-images/yes&#39;
Augmented_no = &#39;/content/drive/MyDrive/脑肿瘤检测/augmented-images/no&#39;

IMG_宽度、IMG_高度 = (240, 240)

X, y = load_data([augmented_yes,augmented_no], (IMG_WIDTH, IMG_HEIGHT))

我正在运行上面的代码，它给了我这个错误：
错误回溯（最近一次调用最后一次）
&lt;ipython-input-32-c5b21f394fc2&gt;在&lt;细胞系：6&gt;()
      4 IMG_宽度、IMG_高度 = (240, 240)
      5
----&gt; 6 X, y = load_data([augmented_yes,augmented_no], (IMG_WIDTH, IMG_HEIGHT))

1 帧
&lt;ipython-input-15-acac6ff41d23&gt;在crop_brain_contour（图像，绘图）中
      6
      7 # 将图像转为灰度图，并稍微模糊一下
----&gt; 8 灰度 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)
      9 灰色 = cv2.GaussianBlur(灰色, (5, 5), 0)
     10

错误：OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: 错误：(-215:断言失败) !_src.empty() 在函数“cvtColor”中

这是load_data()函数：
def load_data(dir_list, image_size):
    ”“”
    读取图像，调整大小并标准化它们。
    论据：
        dir_list：表示文件目录的字符串列表。
    返回：
        X：形状 = (#_examples, image_width, image_height, #_channels) 的 numpy 数组
        y：形状 = (#_examples, 1) 的 numpy 数组
    ”“”

    # 加载目录下的所有图片
    X = []
    y = []
    图像宽度、图像高度 = 图像大小

    对于 dir_list 中的目录：
        对于 listdir（目录）中的文件名：
            # 加载图像
            image = cv2.imread(目录 + &#39;\\&#39; + 文件名)
            # 裁剪大脑并忽略图像中不必要的其余部分
            图像=crop_brain_contour（图像，图=假）
            # 调整图像大小
            图像 = cv2.resize(图像, dsize=(image_width, image_height), 插值=cv2.INTER_CUBIC)
            # 标准化值
            图像=图像/255。
            # 将图像转换为 numpy 数组并将其附加到 X
            X.append(图像)
            # 如果图像为目标数组，则将值 1 附加到目标数组
            # 位于名为“yes”的文件夹中，否则附加 0。
            如果目录[-3:] == &#39;是&#39;:
                y.追加([1])
            别的：
                y.追加([0])

    X = np.array(X)
    y = np.array(y)

    # 打乱数据
    X, y = 随机播放(X, y)

    print(f&#39;示例数量为：{len(X)}&#39;)
    print(f&#39;X 形状是：{X.shape}&#39;)
    print(f&#39;y 形状是: {y.shape}&#39;)

    返回 X, y

这是crop_brain_contour()函数：
defcrop_brain_contour（图像，plot=False）：

    #导入imutils
    #导入CV2
    #从 matplotlib 导入 pyplot 作为 plt

    # 将图像转为灰度图，并稍微模糊一下
    灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

    灰色 = cv2.GaussianBlur(灰色, (5, 5), 0)

    # 对图像设置阈值，然后执行一系列腐蚀 +
    # 膨胀以消除任何小噪声区域
    阈值 = cv2.threshold(灰色, 45, 255, cv2.THRESH_BINARY)[1]
    thresh = cv2.erode(thresh, 无, 迭代=2)
    thresh = cv2.dilate(thresh, 无, 迭代=2)

    # 在阈值图像中找到轮廓，然后抓取最大的轮廓
    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv2.contourArea)


    # 找到极值点
    extLeft = tuple(c[c[:, :, 0].argmin()][0])
    extRight = tuple(c[c[:, :, 0].argmax()][0])
    extTop = 元组(c[c[:, :, 1].argmin()][0])
    extBot = tuple(c[c[:, :, 1].argmax()][0])

    # 使用四个极值点（左、右、上、下）从原始图像中裁剪出新图像
    new_image = 图像[extTop[1]:extBot[1], extLeft[0]:extRight[0]]

    如果情节：
        plt.figure()

        plt. 子图(1, 2, 1)
        plt.imshow(图像)

        plt.tick_params(axis=&#39;两者&#39;,which=&#39;两者&#39;,
                        上=假，下=假，左=假，右=假，
                        labelbottom=False、labeltop=False、labelleft=False、labelright=False)

        plt.title(&#39;原图&#39;)

        plt. 子图(1, 2, 2)
        plt.imshow(new_image)

        plt.tick_params(axis=&#39;两者&#39;,which=&#39;两者&#39;,
                        上=假，下=假，左=假，右=假，
                        labelbottom=False、labeltop=False、labelleft=False、labelright=False)

        plt.title(&#39;裁剪后的图像&#39;)

        plt.show()

    返回新图像

检查我正在进行的脑肿瘤检测项目的错误在哪里。]]></description>
      <guid>https://stackoverflow.com/questions/77957561/error-opencv4-8-0-io-opencv-modules-imgproc-src-color-cpp182-error-215</guid>
      <pubDate>Wed, 07 Feb 2024 19:52:57 GMT</pubDate>
    </item>
    <item>
      <title>了解变量选择和调整后的 randomForestSRC 行为 [关闭]</title>
      <link>https://stackoverflow.com/questions/77954827/understanding-randomforestsrc-behaviour-after-variable-selection-and-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77954827/understanding-randomforestsrc-behaviour-after-variable-selection-and-tuning</guid>
      <pubDate>Wed, 07 Feb 2024 12:43:24 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Kaggle 中使用 python 版本 3.7.1</title>
      <link>https://stackoverflow.com/questions/77537786/how-do-i-use-python-version-3-7-1-in-kaggle</link>
      <description><![CDATA[我正在尝试训练用 python 版本 3.7.1 编写的 TensorFlow ML 模型。然而kaggle中的python版本是3.10.2。有什么方法可以使用 python 3.7 环境并且可以将其设为默认环境吗？]]></description>
      <guid>https://stackoverflow.com/questions/77537786/how-do-i-use-python-version-3-7-1-in-kaggle</guid>
      <pubDate>Thu, 23 Nov 2023 14:49:38 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch RuntimeError：CUDA 内存不足且有大量可用内存</title>
      <link>https://stackoverflow.com/questions/71498324/pytorch-runtimeerror-cuda-out-of-memory-with-a-huge-amount-of-free-memory</link>
      <description><![CDATA[在训练模型时，我遇到了以下问题：
运行时错误：CUDA 内存不足。尝试分配 304.00 MiB（GPU 0；8.00 GiB 总容量；已分配 142.76 MiB；6.32 GiB 空闲；PyTorch 总共保留 158.00 MiB）分配的内存尝试设置 max_split_size_mb 以避免碎片。请参阅内存管理和 PYTORCH_CUDA_ALLOC_CONF 的文档
正如我们所看到的，当尝试分配 304 MiB 内存时会发生错误，而 6.32 GiB 是空闲的！问题是什么？正如我所看到的，建议的选项是设置 max_split_size_mb 以避免碎片。它会有帮助吗？如何正确地做到这一点？
这是我的 PyTorch 版本：
火炬==1.10.2+cu113
火炬视觉==0.11.3+cu113
火炬音频===0.10.2+cu113]]></description>
      <guid>https://stackoverflow.com/questions/71498324/pytorch-runtimeerror-cuda-out-of-memory-with-a-huge-amount-of-free-memory</guid>
      <pubDate>Wed, 16 Mar 2022 13:53:45 GMT</pubDate>
    </item>
    </channel>
</rss>