<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 18 Jan 2024 01:01:18 GMT</lastBuildDate>
    <item>
      <title>NER 模型表现不佳</title>
      <link>https://stackoverflow.com/questions/77836231/ner-model-not-performing-adequately</link>
      <description><![CDATA[我正在为以下标签构建 NER 模型：ACQUIREE_COMPANY 和 ACQUIROR_COMPANY。培训数据基于宣布被收购方和收购方公司合并和收购的新闻稿。我使用 ChatGPT-4 注释了大约 18,000 个示例。我使用 Prodigy 训练模型，使用基本模型 (en_core_web_lg) 和不使用基本模型时的分割率为 80%（训练）-20%（评估）。使用基本模型训练的模型的准确率没有超过大约 70%，而没有基本模型训练的模型的准确率则没有超过 67%。
没有基本模型的训练运行统计数据为：
E # 损失 TOK2VEC 损失 NER ENTS_F ENTS_P ENTS_R SCORE
&lt;小时/&gt;
...
0 3400 236.99 870.02 67.13 68.91 65.44 0.67
...
0 4600 31159.08 946.75 67.07 73.73 61.52 0.67
...
0 5000 581.26 919.93 64.44 62.43 66.58 0.64
✔ 将管道保存到输出目录
使用 en_core_web_lg 作为基本模型进行训练的统计数据为：
E # 丢失 TOK2VEC 丢失 NER ENTS_F ENTS_P ENTS_R 速度分数
&lt;小时/&gt;
...
3 19000 0.00 3564.10 72.53 74.67 70.50 6875.54 0.73
3 20000 0.00 3647.85 72.67 74.46 70.96 7190.40 0.73
...
5 25000 0.00 3639.24 72.75 74.55 71.03 7433.97 0.73
5 26000 0.00 3409.12 72.74 74.67 70.91 7425.77 0.73
✔ 将管道保存到输出目录
我们将非常感谢有关如何提高准确性的一些指导。
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/77836231/ner-model-not-performing-adequately</guid>
      <pubDate>Thu, 18 Jan 2024 00:25:16 GMT</pubDate>
    </item>
    <item>
      <title>张量卷积运算的视觉表示</title>
      <link>https://stackoverflow.com/questions/77836166/visual-representation-of-convolution-operation-on-tensor</link>
      <description><![CDATA[当应用的滤波器数量等于输入张量？
]]></description>
      <guid>https://stackoverflow.com/questions/77836166/visual-representation-of-convolution-operation-on-tensor</guid>
      <pubDate>Wed, 17 Jan 2024 23:52:45 GMT</pubDate>
    </item>
    <item>
      <title>感知器算法未收敛于线性可分离数据</title>
      <link>https://stackoverflow.com/questions/77836071/perceptron-algorithm-not-converging-on-linearly-separable-data</link>
      <description><![CDATA[我正在研究感知器问题，我制作了一些假数据，当数据线性可分时，感知器算法不会收敛。
这是线性可分的假数据。
np.random.seed(42)
Linear_df = pd.DataFrame({
    &#39;X1&#39;：np.round（np.concatenate（[np.random.uniform（低= 0，高= 5，大小= 4），np.random.uniform（低= 8，高= 12，大小= 4） ]), 1),
    &#39;X2&#39;：np.round（np.concatenate（[np.random.uniform（低= 0，高= 5，大小= 4），np.random.uniform（低= 8，高= 12，大小= 4） ]),1),
    &#39;Y&#39;: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]
})

然后我在上面运行感知器
clf = 感知器（详细=1，max_iter=1000）
X = Linear_df[[&#39;X1&#39;, &#39;X2&#39;]]
y = 线性_df[&#39;Y&#39;]
clf.fit(X, y)
线性系数 = clf.coef_
线性偏差 = clf.intercept_[0]
打印（clf.coef_）
打印（clf.intercept_）
打印（clf.score（X，y））

8 个 epoch 后的收敛时间为 0.00 秒
[[ 2.3 -2.6]]
[17.]
0.5
但它说它在 8 个 Epoch 后收敛，并且没有产生正确的输出。这是情节
感知器图
任何想法都会非常有用，谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77836071/perceptron-algorithm-not-converging-on-linearly-separable-data</guid>
      <pubDate>Wed, 17 Jan 2024 23:19:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在物理信息神经网络的背景下实现虚拟工作的原理？</title>
      <link>https://stackoverflow.com/questions/77835857/how-can-the-principle-of-virtual-work-be-implemented-in-the-context-of-a-physics</link>
      <description><![CDATA[我需要解决加载垂直载荷 q 的板的结构问题。我想实现一个考虑物理问题的神经网络，即所谓的物理通知神经网络。我不想使用问题的强形式（因此求解以下方程来更新网络：EJw,xxxx=q，其中 w,xxxx 是垂直位移的四阶导数，EJ 是本构关系，q 是载荷）使用弱形式公式，因此 dW_int=d_W_ext 或 Pi=U+Wext 是可能的最小值，其中 Pi 是总势能，U 是应变能，W_ext 是外力功（在本例中为 q）以及dW_int是虚拟内部工作。你会如何实现它？
我创建了一个神经网络，并考虑了域内的 900 个搭配点来恢复垂直位移。然后我构造一个 hiddel 层矩阵，其尺寸为 900 x 500，其中 500 是神经元数量，900 是搭配点。从这个隐藏层矩阵中，我恢复了应变能和外部功，但随后对其进行积分，矩阵的尺寸与我认为上传网络的正确性不再一致。 PVW 方程的分辨率应该给我一个 500x1 的向量，它更新系统的权重]]></description>
      <guid>https://stackoverflow.com/questions/77835857/how-can-the-principle-of-virtual-work-be-implemented-in-the-context-of-a-physics</guid>
      <pubDate>Wed, 17 Jan 2024 22:19:35 GMT</pubDate>
    </item>
    <item>
      <title>批次和图层归一化差异</title>
      <link>https://stackoverflow.com/questions/77835832/batch-and-layer-normalization-difference</link>
      <description><![CDATA[
在批量归一化中，均值和标准差是按特征计算的，归一化步骤是按实例完成的，在层归一化中，均值和标准差是按实例计算的，归一化步骤是按特征完成的；这对不对？

“批次”有什么用？在批量归一化中？在神经网络中完成第一遍后，我们是否要向网络提供第二批数据？


我找不到任何关于这方面的好的资源，而且定义似乎很难理解。]]></description>
      <guid>https://stackoverflow.com/questions/77835832/batch-and-layer-normalization-difference</guid>
      <pubDate>Wed, 17 Jan 2024 22:14:25 GMT</pubDate>
    </item>
    <item>
      <title>DataLoader 类拾取父文件夹</title>
      <link>https://stackoverflow.com/questions/77835828/dataloader-class-picking-up-parent-folder</link>
      <description><![CDATA[我正在尝试在图像分类任务上训练卷积神经网络。由于某种原因，我的数据加载器类正在获取父文件夹，我怀疑这在尝试训练模型时会导致问题，因为它给我一个错误“运行时错误：应该为所有 64 个类定义权重张量或不定义任何类，但是得到形状的权重张量：[99]”
这是我的代码：
导入 torch.nn 作为 nn
导入 torch.optim 作为 optim
从 torch.optim 导入 lr_scheduler
从 torch.utils.data 导入 DataLoader、数据集、random_split
导入火炬视觉
从 torchvision 导入数据集、模型、转换
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
导入操作系统
从 PIL 导入图像


data_path = &#39;/kaggle/input/facial-age/face_age&#39;

类 CustomImageFolder（数据集）：
    def __init__(self, root_dir, 变换=无):
        self.root_dir = root_dir
        self.transform = 变换
        self.images = []
        self.标签 = []

        # 遍历所有子目录
        对于排序中的标签（os.listdir（root_dir））：
            如果标签==&#39;face_age&#39;：
                继续
            label_path = os.path.join(root_dir, 标签)
            如果 os.path.isdir(label_path):
                对于 os.listdir(label_path) 中的 img_file：
                    img_path = os.path.join(label_path, img_file)
                    如果 os.path.isfile(img_path):
                        self.images.append(img_path)
                        self.labels.append(标签)

    def __len__(自身):
        返回 len(self.images)

    def __getitem__(self, idx):
        img_path = self.images[idx]
        图像 = Image.open(img_path).convert(&#39;RGB&#39;)
        标签 = self.labels[idx]

        如果自我变换：
            图像 = self.transform(图像)

        返回图像，int(标签)

# 定义变换
变换 = Transforms.Compose([transforms.ToTensor()])

# 创建自定义数据集
数据集 = CustomImageFolder(root_dir=data_path, 变换=变换)

# 检查前几项
对于范围（5）内的 i：
    图像，标签=数据集[i]
    print(f&#39;标签: {label}, 图像形状: {image.shape}&#39;)


train_size = int(0.8 * len(数据集))
test_size = len(数据集) - train_size
train_dataset, test_dataset = random_split(数据集, [train_size, test_size])

# 创建数据加载器
train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)
test_loader = DataLoader(test_dataset,batch_size=64,shuffle=False)


数据集 = datasets.ImageFolder(root=data_path)
打印（数据集.class_to_idx）
打印（len（数据集.class_to_idx））

最后一个单元格输出父文件夹及其内部的所有文件夹。这没有任何意义。
这是使用的数据集：https://www.kaggle.com/datasets/ frabbisw/面部年龄]]></description>
      <guid>https://stackoverflow.com/questions/77835828/dataloader-class-picking-up-parent-folder</guid>
      <pubDate>Wed, 17 Jan 2024 22:13:35 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 前向传播速度取决于变量</title>
      <link>https://stackoverflow.com/questions/77835175/pytorch-forward-pass-speed-depending-on-variables</link>
      <description><![CDATA[为什么前向传递通过 MLP 模型的时间取决于输入数据的大小（在采样和创建较小批次之前）？
例如，如果我从大小为 100（整个数据大小）的原始数据集中选择 10（批量大小）数据，则前向传递所需的时间不应取决于 100，而是取决于 10。
我发现，当我增加批次大小时，前向传递时间也会增加。但是，当我增加总数据集的数量时，也会发生同样的情况。
我有一个模型，可以训练一定批量大小的输入（在本例中为 100），这些输入是从连续整数数组中采样的，其形式为，
# 生成输入
时间0 = 时间.time()

input_data = np.zeros([n,1]).astype(np.float64)

对于范围内的 i(len(input_array))：
    输入数据[i, 0] = -1.5 + 3 / (n-1) * i

时间1 = 时间.time()



＃ 火车
批量大小 = 100

对于范围（1000）内的train_step：
   indexTotal = [num for num in range(n)]
   batchIndices = random.sample(indexTotal, batchSize)
   input_data_0 = input_data[batchIndices, :] # 样本数据

   input_data_combined = np.concatenate([input_data_0] * 3, axis=0) # 合并数据
   input_data_combined = input_data_combined + shiftMat # 添加偏差
   input_data_combined = torch.tensor(input_data_combined, require_grad=True, device=device) # 转换为张量
   时间2 = 时间.时间()

   output_combined = model(input_data_combined) # 前向传递
   time3 = time.time()
   
   # 反向传播

基本上，它将多个 numpy 数组组合成一个数组，添加一个偏差（也是一个 numpy 数组），然后转发到模型。该模型是一个简单的 MLP 模型，其条件是如果接收到的张量在特定边界内，则返回零。
# 定义神经网络
类 myModel(nn.Module):
    def __init__(自身):
        超级（myModel，自我）.__init__()
        self.fc1 = nn.Linear(1, 31) # (x, y) 输入
        self.fc2 = nn.Linear(31, 31)
        self.fc3 = nn.Linear(31, 1)

    def 前向（自身，x）：
        # 检查每一行是否在 epsilon (=0.01) 内接近 [1.1, 0]
        ε = 0.01
        isClose2Target = torch.all(torch.abs(x - torch.tensor([1.1, 0], device=device)) &lt; epsilon, dim=1)
        
        x = self.fc1(x)
        x = 火炬.tanh(x)
        x = self.fc2(x)
        x = 火炬.tanh(x)
        x = self.fc3(x)

        # 对于接近 [1.1, 0] 的行，将输出设置为 0
        x[isClose2Target] = torch.tensor([0])

        return x # 单个 Eb 输出

如果增加batchSize，前向传递所需的时间就会增加。当前的问题是，如果我增加 n （完整数据集的大小），前向传递时间也会增加，这是没有意义的（因为模型接收到 batchSize 的输入大小，不是n）。
我认为这可能是 random.sample() 函数的问题，它可能存储有关 n 的信息，但我不确定......
哪部分代码可能会导致这个问题？
我在 GPU 和 CPU 上都进行了尝试，但它们都给了我相同的结果，其中前向传递速度取决于 n 和 batchSize。
我目前正在使用时间模块 time.time() 测量时间，如上面代码中所写。]]></description>
      <guid>https://stackoverflow.com/questions/77835175/pytorch-forward-pass-speed-depending-on-variables</guid>
      <pubDate>Wed, 17 Jan 2024 19:56:39 GMT</pubDate>
    </item>
    <item>
      <title>测试数据集的最佳数量是多少</title>
      <link>https://stackoverflow.com/questions/77834854/what-is-the-optimal-number-of-testing-dataset</link>
      <description><![CDATA[我从事胶质瘤相关研究。尽管采用了 SMOTE、RUS 或 ROS 等各种技术，但我的机器学习模型的结果似乎偏向于多数类别。鉴于模型是在不平衡数据集上训练的，这个问题可能是预料之中的。但是，我不确定问题是否出在所使用的技术上，或者是否是由于测试数据集不足造成的。
分割我的训练集和测试/验证集是否是一个可行的解决方案，特别是考虑到我的数据集的大小有限？作为上下文，我的数据由 19 名患者的 MRI 图像组成，每个患者 15 张图像。我使用 15 张图像进行训练，使用 4 张图像进行测试。]]></description>
      <guid>https://stackoverflow.com/questions/77834854/what-is-the-optimal-number-of-testing-dataset</guid>
      <pubDate>Wed, 17 Jan 2024 18:53:39 GMT</pubDate>
    </item>
    <item>
      <title>在多类分类上训练模型时出现 XGboost 错误“SoftmaxMultiClassObj：标签必须位于 [0, num_class)”</title>
      <link>https://stackoverflow.com/questions/77834714/xgboost-error-while-training-a-model-on-multi-class-classification-softmaxmulti</link>
      <description><![CDATA[我正在使用 dask XGboost 库 (xgboost.dask.DaskXGBClassifier) 在具有多个类的数据上训练模型。这些类如下：{1,2,3,4,5,6,21,25}。在使用 multi:softprob 目标拟合分类器时，我收到以下错误 SoftmaxMultiClassObj：标签必须位于 [0, num_class)。有趣的是，我之前也用 xgboost 分类器训练过模型，但没有使用 dask (xgboost.XGBClassifier)，但没有出现这个问题。可能是什么原因？ [我使用的是xgboost==1.5.0版本]
我使用编码将标签保持在 [0, num_class) 内，但我有巨大的数据集，我认为将数据加载到内存中并对标签进行编码将导致我想避免的内存问题，这是唯一的原因我正在与 dask 库对齐。
如何解决这个问题？
以下是示例代码
def main(客户端):
    将 dask.dataframe 导入为 dd
    ddf = dd.read_csv(df_path)

    # 删除非数值数据、NaN、Inf 和位置特定数据
    数据= ddf.drop（discarded_columns，轴= 1，错误=&#39;忽略&#39;）
    
    数据 = data.replace([np.inf, -np.inf], np.nan).dropna()

    train_x = data.drop([&#39;预测&#39;], axis=1)
    train_y = 数据[&#39;预测&#39;]

    从 dask_ml.model_selection 导入 train_test_split
    (train_x, test_x, train_y, test_y) = train_test_split(
        train_x，train_y，test_size=TEST_SIZE，
        random_state=RANDOM_STATE
    ）

    尝试：
        将 xgboost 导入为 xgb
        print(&quot;创建分类器：&quot;)
        
        分类器= xgb.dask.DaskXGBClassifier（客户端，random_state=RANDOM_STATE，n_jobs=-1，详细程度=1）

        # 预定义的调整超参数
        调整参数 = {
            &#39;colsample_bytree&#39;：0.8，&#39;eval_metric&#39;：&#39;mlogloss&#39;，&#39;伽玛&#39;：0，
            “学习率”：0.15，“最大深度”：8，“最小儿童权重”：1，
            &#39;n_estimators&#39;：800，&#39;目标&#39;：&#39;multi：softprob&#39;，&#39;tree_method&#39;：&#39;hist&#39;}
        print(&quot;设置参数：&quot;)
        classifier.set_params(**tuned_pa​​rams)
        分类器.client = 客户端
        print(“拟合模型：”)
        classifier.fit(train_x, train_y, eval_set=[(train_x, train_y)])
        bst = classifier.get_booster()
        历史 = classifier.evals_result()

        print(&quot;评估历史记录：&quot;, History)

    除了异常 e：
        打印(e)


如果 __name__ == “__main__”：
    从 dask.distributed 导入客户端、LocalCluster
    以 LocalCluster() 作为集群：
        以客户端（集群）作为客户端：
            主要（客户端）
]]></description>
      <guid>https://stackoverflow.com/questions/77834714/xgboost-error-while-training-a-model-on-multi-class-classification-softmaxmulti</guid>
      <pubDate>Wed, 17 Jan 2024 18:25:07 GMT</pubDate>
    </item>
    <item>
      <title>人工智能日历的算法建议利用机器学习和自动化来优化日历，就像 trevorai 和 reclaim 所做的那样？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77834687/algorithm-suggestions-for-an-ai-calendar-utilizing-machine-learning-and-automati</link>
      <description><![CDATA[我们计划创建一个关于个性化人工智能调度程序/日历应用程序的有趣的业余项目，该应用程序利用机器学习和自动化来优化调度。想想 reclaim.ai、motion、顺时针、trevorai 等，但都是在移动设备上由学生制作的，哈哈。您能否建议我们可以在项目中使用的算法，尤其是 ML 算法，或者您是否认为除了 ML 之外还有更好的方法？
例如，我要求 AI 将我的会议从下午 4 点开始移至第二天，然后 AI 会检查日历，如果第二天下午 4 点有活动，如果有，则会将其移到第二天下午 4 点。或者，人工智能可以添加建议事件，例如为第二天即将举行的考试而学习，您可以选择接受或不接受建议。诸如此类的事情。
根据我的研究，我发现了调度算法、自动化的使用、遗传算法、优化算法，但没有一个适合我的特定应用程序。]]></description>
      <guid>https://stackoverflow.com/questions/77834687/algorithm-suggestions-for-an-ai-calendar-utilizing-machine-learning-and-automati</guid>
      <pubDate>Wed, 17 Jan 2024 18:19:48 GMT</pubDate>
    </item>
    <item>
      <title>召回分数！=使用confusion_matrix手动计算</title>
      <link>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</link>
      <description><![CDATA[我遇到了一个问题，即使用 recall_score(y, y_pred) 获得的召回分数与使用 confusion_matrix 手动计算的值不匹配。
不仅如此，召回率与特异性的值完全相同，我也在下面手动计算了该值。
这是我正在使用的相关代码：
recall = recall_score(y, y_pred) # &lt;-- 不同的分数

conf_matrix = fusion_matrix(y, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()
Manual_recall = tp / (tp + fn) # &lt;-- 达到这个分数
特异性 = tn / (tn + fp) # &lt;-- 与上面的分数相同

这是发生这种情况的终端中打印的混淆矩阵的示例：
&lt;前&gt;&lt;代码&gt;[[34 6]
 [20 20]]

科学套件召回：0.85
手动召回：0.5
或
&lt;前&gt;&lt;代码&gt;[[29 11]
 [9 31]]

科学套件召回：0.725
手动召回：0.775
问题：
scikit-learn 返回的召回和手动召回不会产生相同的值。
问题：
为什么recall_score和使用confusion_matrix的手动计算可能会产生不同的召回分数结果？
更多信息...

这是一个二元分类问题。

我正在使用 recall_score 的默认阈值。

我尝试确定混淆表是否准确（确实如此）。

]]></description>
      <guid>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</guid>
      <pubDate>Wed, 17 Jan 2024 18:08:23 GMT</pubDate>
    </item>
    <item>
      <title>如何仅使用组件在 azure ml Designer 中训练和部署 ml 模型？</title>
      <link>https://stackoverflow.com/questions/77827691/how-to-train-and-deploy-ml-models-in-azure-ml-designer-just-using-components</link>
      <description><![CDATA[我在 azure ml Designer 中创建了一个训练管道。现在，我需要通过添加用于注册和部署的组件来部署此模型。我想我可以使用“执行 python 脚本”组件来执行此操作。但是我不知道如何将“训练的最佳模型”（“调整模型超参数”组件的输出）与“执行 python 脚本”组件连接起来。那么，知道如何完成这项任务吗？我将非常感谢您的帮助。
这是我的管道：
训练管道]]></description>
      <guid>https://stackoverflow.com/questions/77827691/how-to-train-and-deploy-ml-models-in-azure-ml-designer-just-using-components</guid>
      <pubDate>Tue, 16 Jan 2024 17:39:49 GMT</pubDate>
    </item>
    <item>
      <title>在微调期间如何正确设置 pad token（不是 eos）以避免模型无法预测 EOS？</title>
      <link>https://stackoverflow.com/questions/76633368/how-does-one-set-the-pad-token-correctly-not-to-eos-during-fine-tuning-to-avoi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76633368/how-does-one-set-the-pad-token-correctly-not-to-eos-during-fine-tuning-to-avoi</guid>
      <pubDate>Fri, 07 Jul 2023 01:11:24 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 FB Prophet 进行多元多步预测？</title>
      <link>https://stackoverflow.com/questions/54544285/is-it-possible-to-do-multivariate-multi-step-forecasting-using-fb-prophet</link>
      <description><![CDATA[我正在研究一个多变量（100+ 个变量）多步骤（t1 到 t30）预测问题，其中时间序列频率为每 1 分钟一次。该问题需要预测 100 多个变量之一作为目标。
我很想知道是否可以使用 FB Prophet 的 Python API 来完成此操作。我能够仅使用目标变量和日期时间变量以单变量方式完成此操作。任何帮助和指导表示赞赏。如果问题需要进一步的意见或澄清，请告诉我。]]></description>
      <guid>https://stackoverflow.com/questions/54544285/is-it-possible-to-do-multivariate-multi-step-forecasting-using-fb-prophet</guid>
      <pubDate>Tue, 05 Feb 2019 22:54:42 GMT</pubDate>
    </item>
    <item>
      <title>Precision、Recall 和 F1 可以是相同的值吗？</title>
      <link>https://stackoverflow.com/questions/54068401/can-the-precision-recall-and-f1-be-the-same-value</link>
      <description><![CDATA[我正在研究 ML 分类问题，并使用 sklearn 库的以下导入和相应代码来计算精度、召回率和 F1，如下所示。
从 sklearn.metrics 导入 precision_recall_fscore_support

打印（ precision_recall_fscore_support（y_test，prob_pos，average =&#39;加权&#39;））

结果
&lt;预&gt;&lt;代码&gt;0.8806451612903226、0.8806451612903226、0.8806451612903226

机器学习分类问题的精确率、召回率和 F1 这三项是否有可能获得相同的值？]]></description>
      <guid>https://stackoverflow.com/questions/54068401/can-the-precision-recall-and-f1-be-the-same-value</guid>
      <pubDate>Mon, 07 Jan 2019 03:58:04 GMT</pubDate>
    </item>
    </channel>
</rss>