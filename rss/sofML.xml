<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 08 Jul 2024 18:20:18 GMT</lastBuildDate>
    <item>
      <title>scikit学习交叉验证分数负值</title>
      <link>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</link>
      <description><![CDATA[我试图建立一个线性回归模型来预测房价，以便从机器学习开始，但在使用以下代码中的交叉验证时遇到负分数值：
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
x = df.drop([&#39;MedHouseVal&#39;], axis=1)
y = df[&#39;MedHouseVal&#39;]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
model = LinearRegression()
model.fit(x_train, y_train)
model.score(x_test, y_test)
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=100)
plt.plot(scores)

我注意到，随着 cv 的增加，平均分数下降。因此，我决定绘制它，并意识到分数在某些时候会呈现负值，但真实预测/样本大小怎么会是负数呢？它是用 (TP + TN - FP - FN)/样本大小计算的吗？提前谢谢。
在此处输入图片描述
抱歉我的英语不好 (; ))]]></description>
      <guid>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</guid>
      <pubDate>Mon, 08 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>有人能帮助我解决 jupyter notebook 运行时溢出的问题吗</title>
      <link>https://stackoverflow.com/questions/78721859/can-someone-help-me-with-the-problem-of-runtime-overflow-in-jupyter-notebook</link>
      <description><![CDATA[我在计算梯度下降时遇到了这个问题
RuntimeWarning: 在 add theta1_slope = (-2/n) + sum(y - thetas[1]*x)*x) 时遇到溢出
我不知道该怎么做，因为我对编程和机器学习还不熟悉]]></description>
      <guid>https://stackoverflow.com/questions/78721859/can-someone-help-me-with-the-problem-of-runtime-overflow-in-jupyter-notebook</guid>
      <pubDate>Mon, 08 Jul 2024 15:58:56 GMT</pubDate>
    </item>
    <item>
      <title>如何定义/改变非分类卷积神经网络的准确性？</title>
      <link>https://stackoverflow.com/questions/78721703/how-do-i-define-change-the-accuracy-for-a-non-classification-convolutional-neura</link>
      <description><![CDATA[我目前正在使用 Keras 制作一个预测模型。它接受两个时间序列并输出一个介于 0 和 1 之间的数字。目前，我的准确度非常低，因为只有当模型得到准确的数字时，它才被认为是“正确的”。例如，正确的数字是 0.34，如果它预测 0.35，则会被视为不正确。我希望能够将范围内的所有数字视为正确的，例如：在真实值的 0.05 以内。另一个选择可能是四舍五入，但我遇到了输出 6 位小数的问题。

我如何将范围内的所有数字视为“正确的”准确率是多少？
我该如何对 CNN 的输出进行四舍五入？

这是我的 CNN 代码：
def networkModel():
model = tf.keras.Sequential([
tf.keras.layers.Conv2D(filters = 16, kernel_size=(2, 2),activation=&#39;relu&#39;,padding=&#39;same&#39;),
tf.keras.layers.Conv2D(filters = 9, kernel_size=(2, 2),activation=&#39;relu&#39;,padding=&#39;same&#39;),
tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(256,activation=&#39;relu&#39;),
tf.keras.layers.Dense(1,激活=&#39;sigmoid&#39;)

])

model.compile(optimizer=&#39;adam&#39;,
loss = tf.keras.losses.BinaryCrossentropy(),
metrics=[&#39;accuracy&#39;])

返回模型
]]></description>
      <guid>https://stackoverflow.com/questions/78721703/how-do-i-define-change-the-accuracy-for-a-non-classification-convolutional-neura</guid>
      <pubDate>Mon, 08 Jul 2024 15:24:04 GMT</pubDate>
    </item>
    <item>
      <title>深度学习回归——即使增加复杂性也无法减少损失？</title>
      <link>https://stackoverflow.com/questions/78721266/deep-learning-regression-cant-decrease-loss-even-after-increasing-complexity</link>
      <description><![CDATA[我正在研究回归任务，目标是预测一个目标变量。我有 37 个输入特征和 6700 个数据点。
我预处理了数据并开发了一个 3 层神经网络，分别有 64、32 和 16 个节点。使用 SGD+Momentum、L2 正则化、relu 激活、1000 个 epoches 和 0.000001 的学习率 - 我能够获得 2.36 的 RMSE 和 0.73 的 r2 分数。我的目标是让 r2 分数高于 0.9。我尝试了许多组合来达到这个分数。我还应该尝试什么？]]></description>
      <guid>https://stackoverflow.com/questions/78721266/deep-learning-regression-cant-decrease-loss-even-after-increasing-complexity</guid>
      <pubDate>Mon, 08 Jul 2024 14:00:08 GMT</pubDate>
    </item>
    <item>
      <title>我的模型的验证准确率图形状很奇怪</title>
      <link>https://stackoverflow.com/questions/78721149/validation-accuracy-graph-for-my-model-has-an-odd-shape</link>
      <description><![CDATA[我一直在训练一个模型，并取得了相当不错的结果（超过 80%）。然而，准确率图形状很奇怪。例如，训练和验证曲线甚至没有相同的起点。这是我的模型的问题吗？如果是，有人知道如何解决吗？
这些是图表：

这是每个时期的输出：
训练第 2 倍...
时期 1/50
62/62 [===============================] - 7s 112ms/step - 损失：0.5552 - 准确度：0.7826 - val_loss：0.3906 - val_accuracy： 0.8540 - lr：1.0000e-04
Epoch 2/50
62/62 [==============================] - 6s 99ms/step - 损失：0.5466 - 准确度：0.7907 - val_loss：0.3980 - val_accuracy：0.8398 - lr：1.0000e-04
Epoch 3/50
62/62 [==============================] - 6s 99ms/step - 损失：0.5266 - 准确度：0.7978 - val_loss：0.3989 - val_accuracy：0.8398 - lr：1.0000e-04
Epoch 4/50
62/62 [==============================] - 6s 100ms/步 - 损失：0.5379 - 准确度：0.7912 - val_loss：0.4070 - val_accuracy：0.8418 - lr：1.0000e-04
Epoch 5/50
62/62 [==============================] - 6s 99ms/步 - 损失：0.5377 - 准确度：0.7846 - val_loss：0.4068 - val_accuracy：0.8398 - lr： 1.0000e-04
Epoch 6/50
62/62 [==============================] - 6s 104ms/step - 损失：0.5284 - 准确度：0.7937 - val_loss：0.4077 - val_accuracy：0.8418 - lr：1.0000e-04
第 2 倍的验证分数：损失为 0.39055174589157104；准确度为 0.8539553880691528
16/16 [================================] - 1s 66ms/step 。
]]></description>
      <guid>https://stackoverflow.com/questions/78721149/validation-accuracy-graph-for-my-model-has-an-odd-shape</guid>
      <pubDate>Mon, 08 Jul 2024 13:35:45 GMT</pubDate>
    </item>
    <item>
      <title>经过微调的 Mask2Former 模型在训练后仅返回空张量</title>
      <link>https://stackoverflow.com/questions/78721111/fine-tuned-mask2former-model-only-returning-null-tensors-after-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78721111/fine-tuned-mask2former-model-only-returning-null-tensors-after-training</guid>
      <pubDate>Mon, 08 Jul 2024 13:25:50 GMT</pubDate>
    </item>
    <item>
      <title>标题：寻求指导：平衡机器学习和移动应用程序开发 [关闭]</title>
      <link>https://stackoverflow.com/questions/78720753/title-seeking-guidance-balancing-machine-learning-and-mobile-app-development</link>
      <description><![CDATA[我目前在基督大学攻读计算机应用学士学位 (BCA) 的第二年。在探索了技术领域的各个领域后，我对移动应用开发和机器学习产生了浓厚的兴趣。
我陷入了两难境地，希望社区能就以下问题提供一些指导：
重点决策：同时追求机器学习和移动应用开发的专业知识是否可行且实用？还是专注于一个领域以最大限度地提高熟练程度和职业前景会更有益？
学习路径：如果建议平衡两个领域，我应该从使用 Android Studio 和 Kotlin 进行原生 Android 开发开始，还是从 Flutter 开始更有益？
过渡到 Flutter：如果我从原生开发开始，过渡到 Flutter 有多顺利？行业内是否普遍存在先从原生开发开始，然后转向 Flutter 的情况，还是专业人士经常直接从 Flutter 开始？
对 Flutter 的需求：行业内目前对 Flutter 开发人员的需求如何？Flutter 专业知识是否有重大的机会和增长前景，尤其是与原生 Android 开发相比？
实习策略：考虑到需要获得实习机会，先专注于一个领域，然后再扩展到另一个领域是否有利？如果是这样，您建议优先考虑哪个领域以获得更好的实习机会和职业发展？
您的见解和建议将非常宝贵，可以帮助我做出明智的决定，决定我的学习路径和职业轨迹。提前感谢您的时间和指导。
我尝试了一切，但仍然陷入困境]]></description>
      <guid>https://stackoverflow.com/questions/78720753/title-seeking-guidance-balancing-machine-learning-and-mobile-app-development</guid>
      <pubDate>Mon, 08 Jul 2024 12:05:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用预训练模型改进森林卫星图像中的树木检测和计数？</title>
      <link>https://stackoverflow.com/questions/78720461/how-to-improve-tree-detection-and-counting-in-forest-satellite-imagery-using-pre</link>
      <description><![CDATA[我正在开发一个人工智能林业管理系统，使用来自 Google Earth 的卫星图像来监测和分析树木种群。主要目标是准确计数树木并识别濒危或本土物种。我已经实施了一个用于图像分割的 U-Net 模型，但准确性并不令人满意，许多树木被遗漏或错误计数。
我当前的工作流程：

数据采集：从 Google Earth 收集卫星图像。
预处理：规范化和增强图像。
图像分割：使用 U-Net 进行初始树冠分割。
树木计数：应用轮廓检测​​来计数树木。
物种识别：旨在根据分割区域对树种进行分类（尚未实施）。

我面临的问题

准确性：U-Net 模型无法准确检测和计数树木。

我尝试过的方法：

实施 U-Net 进行分割。
尝试使用来自segmentation_models 库的预训练 U-Net 模型，但面临层形状和输入维度错误。

问题：

预训练模型：可用于卫星图像中树木检测的最佳预训练模型有哪些，我如何有效地将它们集成到我的项目中？
在哪里可以找到高质量的数据集用于卫星或航空图像中的树木检测和物种识别？
我可以采取哪些技术或其他预处理步骤来提高树木检测和计数的准确性？

其他信息：

我正在使用 Python 和 TensorFlow、Keras 和 OpenCV 等库。

该项目对我的毕业至关重要，任何详细指导或相关教程或资源的参考都将不胜感激。

我已经探索了各种数据集，但不确定哪些数据集对于训练稳健模型最有效。

]]></description>
      <guid>https://stackoverflow.com/questions/78720461/how-to-improve-tree-detection-and-counting-in-forest-satellite-imagery-using-pre</guid>
      <pubDate>Mon, 08 Jul 2024 11:02:08 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret plot_model() 在关闭绘图后崩溃</title>
      <link>https://stackoverflow.com/questions/78720455/pycaret-plot-model-crashing-after-closing-plot</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78720455/pycaret-plot-model-crashing-after-closing-plot</guid>
      <pubDate>Mon, 08 Jul 2024 11:00:51 GMT</pubDate>
    </item>
    <item>
      <title>我在数据模型预测方面遇到了一个 Python 问题</title>
      <link>https://stackoverflow.com/questions/78720086/i-have-a-python-problem-in-case-of-data-model-predictions</link>
      <description><![CDATA[我有一段代码无法正常工作，在训练数据集并完成所有需要的操作后，我的口罩检测系统无法检测用户何时戴口罩
我尝试使用不同的数据集并更改最初使用的方法，但没有任何效果]]></description>
      <guid>https://stackoverflow.com/questions/78720086/i-have-a-python-problem-in-case-of-data-model-predictions</guid>
      <pubDate>Mon, 08 Jul 2024 09:35:42 GMT</pubDate>
    </item>
    <item>
      <title>术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可运行程序的名称</title>
      <link>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</link>
      <description><![CDATA[当我运行此最终命令时，我在本地笔记本电脑上执行自定义数据集上的 yolov3 操作，所有操作均已完成
./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg darknet53.conv.74
当我使用 Windows Power Shell 时，出现错误，
./darknet：术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可操作程序的名称。请检查名称的拼写，或者如果包含路径，请验证路径是否正确，然后重试。
在第 1 行，字符：1
+ ./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg darknet5 ...
+ ~~~~~~~~~
+ CategoryInfo : ObjectNotFound: (./darknet:String) [], CommandNotFoundException
+ FullyQualifiedErrorId : CommandNotFoundException

那么我该如何解决此错误
我尝试更改系统环境变量路径，也尝试运行某些命令，但仍然抛出相同的错误，那么我应该尝试什么呢]]></description>
      <guid>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</guid>
      <pubDate>Mon, 08 Jul 2024 08:00:10 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型输入形状与层不兼容（尽管是兼容形状）</title>
      <link>https://stackoverflow.com/questions/78719585/keras-model-input-shapes-are-incompatible-with-the-layer-despite-being-a-compat</link>
      <description><![CDATA[为了解决这个问题，我在过去两天里费尽心机。我创建了一个文件 test.py，通过预测单个样本来测试我的模型：
import os
import keras
import numpy as np
import tensorflow as tf
from main_copy import path_to_fft

model = keras.models.load_model(os.path.join(os.getcwd(), &quot;model.keras&quot;))

model.summary()
model.summary(expand_nested=True)

first_sample = path_to_fft(os.path.join(os.getcwd(), &#39;Sounds&#39;, &#39;Thomas&#39;, &#39;thomas_original.wav&#39;))
second_sample = path_to_fft(os.path.join(os.getcwd(), &#39;Sounds&#39;, &#39;Thomas&#39;, &#39;thomas_original.wav&#39;))

print(&quot;First: &quot;, first_sample.shape)

print(&quot;Second: &quot;, second_sample.shape)

prediction = model.predict([first_sample, second_sample])
print(prediction)

path_to_fft 函数解码 .wav 文件并应用快速傅里叶变换，然后返回该变换的前半部分正频率，将 5 秒 16kHz 音频从形状 (80000, 1) 转换为 (40000, 1)，这是我的模型的正确大小。但是，当我尝试使用 model.predict 预测两个样本之间的距离时，我收到此错误消息：
Model: &quot; functional&quot;
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ ━ ...�
┃ 层（类型） ┃ 输出形状 ┃ 参数编号 ┃ 连接到┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━ ━━━━━━━╇━ ...输入A (输入层) │ (无，40000，1) │ 0 │ - │
│ ...输入A[0][0]，输入B[0][0] │
═──────────────────────────────┼──────────────────────────┼──────────────────────┼──────────────────────────┤
│ lambda (Lambda) │ (None, 1) │ 0 │ SiameseBranch[0][0]，│
│ │ │ │ SiameseBranch[1][0] │
└────────────────────────────┴────────────────────────┴──────────────────────┴────────────────────────┘

层“SiameseBranch”的输入 0与层不兼容：预期形状=(None, 40000, 1)，发现形状=(32, 1)

Functional.call() 接收的参数：
• 输入=(&#39;tf.Tensor(shape=(32, 1), dtype=float32)&#39;, &#39;tf.Tensor(shape=(32, 1), dtype=float32)&#39;)
• 训练=False
• 掩码=(&#39;None&#39;, &#39;None&#39;)

向上滚动时，我看到 Tensorflow 生成了三个 (?????) 参数：
级别 1：tensorflow：为 Python 函数 &lt;function StructuredFunctionWrapper.__init__.&lt;locals&gt;.trace_tf_function.&lt;locals&gt;.wrapped_fn at 创建新的 FuncGraph 0x0000027A795AE480&gt; (key: FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0), scope_type=&lt;ScopeType.VARIABLE_CREATION: 2&gt;), 输入参数:
args_0 (POSITIONAL_ONLY): TensorSpec(shape=(32,), dtype=tf.int64, name=None)
args_1 (POSITIONAL_ONLY): TensorSpec(shape=(40000, 1), dtype=tf.float32, name=None)
args_2 (POSITIONAL_ONLY): TensorSpec(shape=(40000, 1), dtype=tf.float32, name=None)
输出类型:
无
捕获:
无)

我完全不知道该做什么或如何处理这些错误日志。这是我第一次使用已保存为文件的模型，这绝对是一场噩梦。
作为参考，这里是 GitHub 存储库的链接（包含 path_to_fft 函数和用于拟合模型的代码以及模型本身）：https://github.com/brainage04/WestpacHackathon
这是运行 test.py 函数的完整错误日志，从头到尾：https://pastebin.com/iVZ7dUWn]]></description>
      <guid>https://stackoverflow.com/questions/78719585/keras-model-input-shapes-are-incompatible-with-the-layer-despite-being-a-compat</guid>
      <pubDate>Mon, 08 Jul 2024 07:30:43 GMT</pubDate>
    </item>
    <item>
      <title>eval（predvars、data、env）中出现错误：未找到对象“s_id”</title>
      <link>https://stackoverflow.com/questions/78715689/error-in-evalpredvars-data-env-object-s-id-not-found</link>
      <description><![CDATA[我正在尝试使用 tidymodels 拟合多层模型。当我拟合单个模型时，我没有遇到问题，但当我将它们组合到工作流集中时，我得到了这些错误。
我看到过有类似错误的帖子，并尝试更新我的代码，但似乎仍然不起作用。
当我在应用配方后查看训练和验证集时，我确实在数据框中找到所有列。不确定为什么错误仍然存​​在。当我使用非多级算法时，不会出现此错误。
我希望有人可以帮助解决此错误：
pacman::p_load(labelled,forcats,rstanarm,tidymodels,dplyr,parsnip,baguette,future,finetune,rules,rsample,
multilevelmod,ranger,earth,readr,stacks)

plan(multisession)

load(url(&quot;http://alecri.github.io/downloads/data/dental.RData&quot;))

dental_long &lt;- pivot_longer(dental, cols = starts_with(&quot;y&quot;), 
names_to = &quot;measurement&quot;, values_to = &quot;distance&quot;) %&gt;% 
mutate(
age = parse_number(measurement),
measure = fct_inorder(paste(&quot;测量年龄&quot;, age)),
s_id=as.factor(id)
) %&gt;% 
set_variable_labels(
age = &quot;测量时孩子的年龄&quot;,
measure = &quot;时间测量标签&quot;,
distance = &quot;测量值&quot;
) %&gt;% select(-measurement,-id)

#将数据拆分为训练集、验证集和测试集
set.seed(11)
splitsx &lt;- group_initial_split(dental_long, group = s_id,prop = 0.8)

dental_train &lt;- training(splitsx)
dental_val &lt;- testing(splitsx)

#创建交叉验证折叠
foldsx &lt;- group_vfold_cv(dental_train, v = 3,group = s_id,repeats = 3)

#创建简单的建模配方
simple_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
update_role(s_id,new_role = &#39;id&#39;)

#带有多项式项的配方
poly_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
update_role(s_id,new_role = &#39;id&#39;) %&gt;%
step_scale(all_numeric_predictors()) %&gt;%
step_poly(all_numeric_predictors(),degree = 2,keep_original_cols = F) %&gt;%
step_dummy(all_nominal_predictors()) %&gt;% 
step_interact(~all_numeric_predictors():all_numeric_predictors())

mixed_basic_recipex &lt;- recipe(distance ~ ., data = dental_train)

mixed_poly_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
step_scale(all_numeric_predictors()) %&gt;%
step_poly(all_numeric_predictors(),degree = 2,keep_original_cols = F) %&gt;%
step_dummy(all_nominal_predictors() &amp; !matches(&#39;s_id&#39;)) #%&gt;% 
# step_interact(~all_numeric_predictors():all_numeric_predictors() )

# df1 &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

#mixed model
lmer_specx &lt;-
linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;lmer&quot;)

bayes_specx &lt;- linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;stan_glmer&quot;)

fullx &lt;- 
workflow_set(
preproc = list(mixed_poly = poly_recipex
), 
models = list(bayesMixed = bayes_specx,lmmixed = lmer_specx

)
)

#贝叶斯调整和度量的设置
bayes_ctrl &lt;-
control_bayes(
save_pred = TRUE,
parallel_over = &quot;everything&quot;,
save_workflow = TRUE,
verbose = TRUE,
no_improve = 20
)
rmse_res &lt;- metric_set(rmse,rsq)

basicbkx &lt;- prep(mixed_basic_recipex) %&gt;% bake(dental_train)
polybkx &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

polyform &lt;- reformulate(c(setdiff(colnames(polybkx), c(&quot;距离&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)
basicform &lt;- reformulate(c(setdiff(colnames(basicbkx), c(&quot;distance&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)

all_wfx1 &lt;- fullx %&gt;% 
# update_workflow_model(id=&#39;basic_bayesMixed&#39;,spec=bayes_specx,
# formula = basicform) %&gt;% 
update_workflow_model(id=&#39;mixed_poly_bayesMixed&#39;,spec=bayes_specx,
formula = polyform) %&gt;%
# update_workflow_model(id=&#39;basic_lmmixed&#39;,spec=lmer_specx,
# formula = basicform) %&gt;%
update_workflow_model(id=&#39;mixed_poly_lmmixed&#39;,spec=lmer_specx,
formula = polyform)

test_results &lt;-
all_wfx1 %&gt;%
working_map(
&quot;tune_bayes&quot;,
seed = 10,
resamples = foldsx,
control = bayes_ctrl
)
]]></description>
      <guid>https://stackoverflow.com/questions/78715689/error-in-evalpredvars-data-env-object-s-id-not-found</guid>
      <pubDate>Sat, 06 Jul 2024 19:11:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么用于检测图像旋转的卷积模型对每张图片都预测相同的类别？</title>
      <link>https://stackoverflow.com/questions/58729151/why-is-my-convolutional-model-for-detecting-image-rotation-predicting-the-same-c</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/58729151/why-is-my-convolutional-model-for-detecting-image-rotation-predicting-the-same-c</guid>
      <pubDate>Wed, 06 Nov 2019 11:29:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit-learn 对文本进行标记</title>
      <link>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</link>
      <description><![CDATA[我有以下代码从一组文件（文件夹名称是类别名称）中提取特征以进行文本分类。
import sklearn.datasets
from sklearn.feature_extraction.text import TfidfVectorizer

train = sklearn.datasets.load_files(&#39;./train&#39;, description=None, categories=None, load_content=True, shuffle=True, encoding=None, decrypt_error=&#39;strict&#39;, random_state=0)
print len(train.data)
print train.target_names

vectorizer = TfidfVectorizer()
X_train = vectorizer.fit_transform(train.data)

它抛出以下堆栈跟踪：
回溯（最近一次调用最后一次）：
文件“C:\EclipseWorkspace\TextClassifier\main.py”，第 16 行，位于&lt;module&gt;
X_train = vectorizer.fit_transform(train.data)
文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 1285 行，位于 fit_transform
X = super(TfidfVectorizer, self).fit_transform(raw_documents)
文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 804 行，位于 fit_transform
self.fixed_vocabulary_)
文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 739 行，位于 _count_vocab
for feature in analyze(doc):
文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 236 行，位于 &lt;lambda&gt;
tokenize(preprocess(self.decode(doc))), stop_words)
文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 113 行，在解码中
doc = doc.decode(self.encoding, self.decode_error)
文件“C:\Python27\lib\encodings\utf_8.py”，第 16 行，在解码中
return codecs.utf_8_decode(input, errors, True)
UnicodeDecodeError: &#39;utf8&#39; 编解码器无法解码位置 32054 中的字节 0xff：起始字节无效

我运行的是 Python 2.7。我该如何让它工作？
编辑：
我刚刚发现，这对于使用 utf-8 编码的文件非常有效（我的文件是 ANSI 编码）。有什么方法可以让 sklearn.datasets.load_files() 使用 ANSI 编码吗？]]></description>
      <guid>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</guid>
      <pubDate>Fri, 01 May 2015 00:39:09 GMT</pubDate>
    </item>
    </channel>
</rss>