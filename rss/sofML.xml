<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 21 Apr 2024 09:14:55 GMT</lastBuildDate>
    <item>
      <title>如何将我的 ML 模型从 Google Drive 集成到生产后端？</title>
      <link>https://stackoverflow.com/questions/78360641/how-can-i-integrate-my-ml-model-from-google-drive-to-the-production-backend</link>
      <description><![CDATA[我遇到了一个问题，即我的模型尺寸很大，因此我使用 dvc 对其进行跟踪。现在我想直接从云平台使用它，所以我将模型推送到谷歌驱动器。但是我怎样才能直接从谷歌驱动器使用它而不需要下载呢？如果不是比任何其他免费平台我可以存储模型并直接使用它？
我尝试了 chatgpt 但失败了：
drive_link = &#39;https://drive.google.com/file/d/1ofu7smGB7D2rwce_-1Tiz4tk8Wfwjpqn/view?usp=sharing&#39;
model_path = get_file(&#39;model.h5&#39;,drive_link,cache_dir=&#39;./&#39;)
模型 = tf.keras.models.load_model(model_path)]]></description>
      <guid>https://stackoverflow.com/questions/78360641/how-can-i-integrate-my-ml-model-from-google-drive-to-the-production-backend</guid>
      <pubDate>Sun, 21 Apr 2024 06:44:41 GMT</pubDate>
    </item>
    <item>
      <title>像宠物一样的健身功能[关闭]</title>
      <link>https://stackoverflow.com/questions/78360524/fitness-function-to-be-like-a-pet</link>
      <description><![CDATA[我想对一个应该像宠物一样行动的机器人使用强化学习。健身函数基本上是什么样子的（不需要精确的代码）？你很难衡量宠物对主人产生的感受。如果有关于这个主题的任何科学研究，如果有人能给我一个链接就好了，因为我还没有发现任何东西？]]></description>
      <guid>https://stackoverflow.com/questions/78360524/fitness-function-to-be-like-a-pet</guid>
      <pubDate>Sun, 21 Apr 2024 05:42:20 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：float() 参数必须是字符串或实数，而不是“方法”[关闭]</title>
      <link>https://stackoverflow.com/questions/78360484/typeerror-float-argument-must-be-a-string-or-a-real-number-not-method</link>
      <description><![CDATA[我正在对泰坦尼克号数据集进行决策树分类。
&lt;前&gt;&lt;代码&gt;代码：
`model.fit(X_train,y_train)`
输出 ：
TypeError Traceback（最近一次调用最后一次）
〜\ AppData \ Local \ Temp \ ipykernel_19572 \ 2721349307.py 在？（）
----&gt; 1 model.fit(X_train,y_train)

c:\Users\Dell\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py 中？（估计器，*args，**kwargs）
   第1470章
   第1471章
   第1472章
   第1473章
-&gt;第1474章

c:\Users\Dell\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\tree\_classes.py 中？(self、X、y、sample_weight、check_input)
   1005 self：决策树分类器
   1006 拟合估计器。
   第1007章
   1008
-&gt;第1009章
   1010X，
   1011 年，
   第1012章

c:\Users\Dell\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\tree\_classes.py 中？(self、X、y、sample_weight、check_input、missing_values_in_feature_mask)
    第248章
    249 dtype=DTYPE，accept_sparse=“csc”，force_all_finite=False
...
   第2154章
   第2155章
   第2156章

类型错误：float() 参数必须是字符串或实数，而不是“方法”
输出被截断。作为可滚动元素查看或在文本编辑器中打开。调整单元格输出设置...

我期待正确的输出。]]></description>
      <guid>https://stackoverflow.com/questions/78360484/typeerror-float-argument-must-be-a-string-or-a-real-number-not-method</guid>
      <pubDate>Sun, 21 Apr 2024 05:18:20 GMT</pubDate>
    </item>
    <item>
      <title>Python-KNN预测误差和数据标准化</title>
      <link>https://stackoverflow.com/questions/78360476/python-knn-predict-error-and-data-normalization</link>
      <description><![CDATA[我是机器学习初学者，正在做我的第一项作业。即使执行教程指示的所有操作，我也无法使预测正常工作。
从 sklearn.neighbors 导入 KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=3, metric=&#39;euclidean&#39;)
knn_model.fit(train_val_process, merge_labels.label)
y_pred_knn = knn.predict(test_data_process)
准确度=metrics.accuracy_score(y_test, y_pred_knn)
print(&#39;准确度报告：&#39;, 准确度)

错误如下：
类型错误：KNeighborsClassifier.predict() 缺少 1 个必需的位置参数：&#39;X&#39;
我应该将数据均值标准化为 1 std 0。这样好吗？
from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(pd.concat([train_data, val_data])) train_data_process = pd.DataFrame(scaler.transform(train_data), columns=train_data.columns ) val_data_process = pd.DataFrame(scaler.transform(val_data), columns=val_data.columns) train_val_process = pd.concat([train_data, val_data]) test_data_process = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns ) y_test = test_labels.label
我期待它能够预测并完成这项工作。感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78360476/python-knn-predict-error-and-data-normalization</guid>
      <pubDate>Sun, 21 Apr 2024 05:13:50 GMT</pubDate>
    </item>
    <item>
      <title>如何将机器学习融入我的个人财务管理？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78360262/how-can-i-incorporate-machine-learning-into-my-personal-finance-management</link>
      <description><![CDATA[我有兴趣利用机器学习技术来优化我的个人财务管理。是否有专门为此目的而定制的现有工具、库或框架？此外，将机器学习算法应用于预算、费用跟踪、投资组合管理或个人理财风险评估等任务时，有哪些关键考虑因素或最佳实践？任何指导或建议将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78360262/how-can-i-incorporate-machine-learning-into-my-personal-finance-management</guid>
      <pubDate>Sun, 21 Apr 2024 02:55:48 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能驱动的机制和 2D/3D 图形开发游戏需要采取什么学习路径？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78359667/what-learning-path-to-take-to-develop-a-game-with-ai-powered-mechanics-and-2d-3d</link>
      <description><![CDATA[我是一名初级/中级软件开发人员，专门从事全栈开发（TS），我很长时间以来一直有一个游戏想法并想开始开发它。这将是一款人工智能驱动的模拟游戏，但我在游戏开发或机器学习方面没有经验或知识。我正在寻找开始开发这款游戏的学习路径。我希望得到社区的一些建议。
我的主要问题是：

我应该使用什么技术堆栈来开发这个游戏？ （我知道游戏开发的最佳选择是C++/C#，但由于我的背景，我决定暂时使用网页版，也许稍后我会学习C++并开发移动版）
采取什么学习路径？ （游戏将有 2D 和 3D 图形（我将从 2D 版本开始）以及许多动画和 AI 驱动的机制）
]]></description>
      <guid>https://stackoverflow.com/questions/78359667/what-learning-path-to-take-to-develop-a-game-with-ai-powered-mechanics-and-2d-3d</guid>
      <pubDate>Sat, 20 Apr 2024 20:49:10 GMT</pubDate>
    </item>
    <item>
      <title>快速衡量某个值与许多其他值相比的新颖性</title>
      <link>https://stackoverflow.com/questions/78359547/fast-measuring-the-novelty-of-a-value-compared-to-many-others</link>
      <description><![CDATA[我目前正在训练 ki 模型在迷宫中移动。每个模型都会选择随后获得奖励的行动。最后，这会产生一个数值列表，我想将其与其他数值进行比较。
目的是衡量列表的相似程度。但不仅仅是与其中一个比较，而是与所有这些比较。
但是，必须确保距离在总计算中不会相互抵消。如果一个动作列表位于另外两个动作列表之间，那么这两个动作列表可能会相互抵消并且距离为零。这绝不能发生。另外，计算的数值应该与下一个列表有 2 的位置处的列表中是否有 0 或 1 无关。因此，Levensthein 距离不起作用。
或者Python中有一个库可以完成此类任务吗？
第二件事是速度（我知道 python 并不快，但对于我的任务来说它是无法替代的）：有人可以向我展示 shcnipsel 代码如何在 python 中有效地进行这种新颖的测量。
顺便说一句，对于我来说，是否为一系列操作列表计算排名列表并将其与已执行的操作进行比较，或者是否为每个操作列表计算单独的值，对我来说并不重要。]]></description>
      <guid>https://stackoverflow.com/questions/78359547/fast-measuring-the-novelty-of-a-value-compared-to-many-others</guid>
      <pubDate>Sat, 20 Apr 2024 19:53:17 GMT</pubDate>
    </item>
    <item>
      <title>教KI变得可爱（对于机器人宠物）[关闭]</title>
      <link>https://stackoverflow.com/questions/78359248/teach-ki-to-be-cute-for-a-robot-pet</link>
      <description><![CDATA[强化学习通常用于训练机器人。一般来说，可以确定一个简单的适应度函数（当然，可以进行许多改进）。对于要送货的机器人，您可以使用机器人所花费的时间。
但是，我想训练一个机器人来代替宠物。我想使用机器学习（我最喜欢的任务是强化学习）。不，将人类的所有反应写入代码中并不是一种选择。机器人应该尽可能独立地学习，甚至是全新的行为。
一个好的健身功能应该是什么样的？您无法测试每个模型的甜度。
我只是要求健身功能。其他代码我已经写好了。
适应度函数的结果应该是一个人工智能模型，该模型可以控制机器人，使其对与之交互的人来说尽可能逼真和卡哇伊。换句话说，是真正的宠物。]]></description>
      <guid>https://stackoverflow.com/questions/78359248/teach-ki-to-be-cute-for-a-robot-pet</guid>
      <pubDate>Sat, 20 Apr 2024 18:12:16 GMT</pubDate>
    </item>
    <item>
      <title>多类问题的层次分类方法</title>
      <link>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</link>
      <description><![CDATA[有一个多类分类任务。我的目标是使用每父节点本地分类器 (LCPN) 方法来解决这个问题。
让我解释一下如何使用 MWE。
假设我有这个虚拟数据集：
将 numpy 导入为 np
从 sklearn.datasets 导入 make_classification
从 scipy.cluster 导入层次结构

X, y = make_classification(n_samples=1000, n_features=10, n_classes=5,
                             n_信息=4）

我想出了这些类之间的距离矩阵：
d = np.array(
[[ 0.、201.537、197.294、200.823、194.517]、
 [201.537, 0., 199.449, 202.941, 196.703],
 [197.294, 199.449, 0., 198.728, 192.354],
 [200.823, 202.941, 198.728, 0., 195.972],
[[194.517, 196.703, 192.354, 195.972, 0.]]
）

因此，我确定了类层次结构，如下所示：
hc = hierarchy.linkage(d, method=&#39;complete&#39;)

得到的树状图如下：
dendrogram = hierarchy.dendrogram(hc, labels=[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;, &#39;D&#39;, &#39;F&#39;])
树状图


我使用hierarchy.to_tree()以树状结构进行说明：

我的问题：
如何按照 LCPN 方法在每个内部节点（包括根）处安装分类器，例如 DecisionTreeClassifier 或 SVM，以像在树中一样进行上图？]]></description>
      <guid>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</guid>
      <pubDate>Sat, 20 Apr 2024 14:08:05 GMT</pubDate>
    </item>
    <item>
      <title>如何进行标准化我无法理解为什么平均值和方差没有得到应用</title>
      <link>https://stackoverflow.com/questions/78358310/how-to-do-normalization-i-am-failing-to-understand-why-the-mean-and-variance-are</link>
      <description><![CDATA[代码应该如何工作
我的代码：
从tensorflow.keras.layers导入标准化
标准化器 = 标准化(均值= 5 , 方差= 4) # 标准化对象
Normalized_tns1 = tf.constant([[3,4,5,6,7]])
打印（归一化_tns1.shape）
print(&quot;\n输出:\n&quot;)
归一化器（归一化_tns1）

我正在做的事情与上图相同，但是当我这样做时，我收到了重塑错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
InvalidArgumentError Traceback（最近一次调用最后一次）
[88] 中的单元格，第 7 行
      5 打印（归一化_tns1.shape）
      6 print(&quot;\n输出:\n&quot;)
----&gt; 7 标准化器(normalized_tns1)

文件 c:\Users\Sujal07\anaconda3\Lib\site-packages\keras\src\utils\traceback_utils.py:122，位于filter_traceback..error_handler(*args, **kwargs)
    第119章
    120 # 要获取完整的堆栈跟踪，请调用：
    121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
    123最后：
    124 删除filtered_tb

文件c:\Users\Sujal07\anaconda3\Lib\site-packages\tensorflow\python\eager\execute.py:53，在quick_execute（op_name，num_outputs，输入，attrs，ctx，名称）中
     51 尝试：
     52 ctx.ensure_initialized()
---&gt; 53 张量 = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     54 个输入、属性、输出数）
     55 除了 core._NotOkStatusException 为 e：
     56 如果名称不是 None：

InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} 重塑的输入是一个值为 1 的张量，但请求的形状有 5 [Op:Reshape]

重塑可以工作，但我不想随着矩阵的变化而这样做]]></description>
      <guid>https://stackoverflow.com/questions/78358310/how-to-do-normalization-i-am-failing-to-understand-why-the-mean-and-variance-are</guid>
      <pubDate>Sat, 20 Apr 2024 13:00:57 GMT</pubDate>
    </item>
    <item>
      <title>如何计算尖峰神经网络电路实现中的“每个尖峰能量”？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78358095/how-to-calculate-energy-per-spike-in-spiking-neural-networks-circuit-implemen</link>
      <description><![CDATA[在一些科学文献中（例如this和this) 关于 LIF（一种尖峰神经网络）的模拟电路实现，作者提到了“每尖峰能量”和“每个概要的能量”作为评价参数之一。如何从电路级实现中计算出来？]]></description>
      <guid>https://stackoverflow.com/questions/78358095/how-to-calculate-energy-per-spike-in-spiking-neural-networks-circuit-implemen</guid>
      <pubDate>Sat, 20 Apr 2024 11:56:58 GMT</pubDate>
    </item>
    <item>
      <title>在keras中，虽然模型拟合epochs = 5000，但代码看起来非常巨大[关闭]</title>
      <link>https://stackoverflow.com/questions/78358018/in-keras-while-model-fitting-with-epochs-5000-the-code-looks-so-huge</link>
      <description><![CDATA[所以，我正在尝试深度学习中的梯度下降。代码是这样的。
model=keras.Sequential([keras.layers.Dense(1, input_shape= (2,),activation=&#39;sigmoid&#39;, kernel_initializer=&#39;ones&#39;,bias_initializer=&#39;zeros&#39;)])

model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

model.fit(x_train_scaled,y_train, epochs=5000)

使用epochs=5000，我应该能获得约 90% 的准确率。但它在 jupyter 中占有重要地位。
我试图在较短的空间内达到 90% 的准确率。因为当我想引用上面的代码时，有很多东西需要滚动。]]></description>
      <guid>https://stackoverflow.com/questions/78358018/in-keras-while-model-fitting-with-epochs-5000-the-code-looks-so-huge</guid>
      <pubDate>Sat, 20 Apr 2024 11:30:52 GMT</pubDate>
    </item>
    <item>
      <title>在weka中重新采样过滤器</title>
      <link>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</link>
      <description><![CDATA[我的数据集中的数据实例数量很少。所以，我尝试了“重新采样” Weka中的过滤器可以增加数据量，从而提高模型性能。样本量百分比设置为200可以吗？因为那时我在交叉验证测试中获得了良好的相关系数。
我想知道将样本大小百分比设置为 200 时，重新采样过滤器是否工作正常。
使用此过滤器后，我的模型会准确预测吗？
由于数据量较少，是否有其他增强方法可以增强模型的性能？]]></description>
      <guid>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</guid>
      <pubDate>Sat, 20 Apr 2024 04:29:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 ffmpeg 或 Python 从视频中删除随机背景</title>
      <link>https://stackoverflow.com/questions/55916977/remove-random-background-from-video-using-ffmpeg-or-python</link>
      <description><![CDATA[我想使用 ffmpeg 或 Python 从某人的视频中删除背景。如果我在任何地方录制视频，请检测视频中的人，然后删除除该人之外的所有内容。不要求绿色或单色背景，因为这可以通过色度键来完成，我不寻找这样的背景。
我已经尝试过这个（https:// tryolabs.com/blog/2018/04/17/announcing-luminoth-0-1/）方法，但它给了我矩形框的输出。由于要探索的区域足够窄，因此它提供了足够的信息，但仍然需要消除总体背景。
我还尝试了 grabcut (https: //docs.opencv.org/4.1.0/d8/d83/tutorial_py_grabcut.html），但需要用户交互，否则结果不太好。
我还尝试使用 ffmpeg 并找到了这个示例（http://oioiiooixiii.blogspot.com/2016/09/ffmpeg-extract-foreground-moving.html），但它需要静态图像，所以我尝试在录制视频之前拍摄背景图片一个人，但要区分背景图像和视频帧需要很多东西。
对于opencv方法，我已经尝试过了。
img = cv.imread(&#39;pic.png&#39;)
mask = np.zeros(img.shape[:2], np.uint8)
bgdModel = np.zeros((1, 65), np.float64)
fgdModel = np.zeros((1, 65), np.float64)
直角 = (39, 355, 1977, 2638)
cv.grabCut（img，掩码，矩形，bgdModel，fgdModel，5，cv.GC_INIT_WITH_RECT）
mask2 = np.where((mask==2)|(mask==0), 0, 1).astype(&#39;uint8&#39;)
img = img*mask2[:, :, np.newaxis]
plt.imshow(img)、plt.colorbar()、plt.show()

但它也消除了人的一些部分。
还尝试了 ffmpeg 方式，但效果不佳。
ffmpeg -report -y -i &quot;img.jpg&quot; -i &quot;vid.mov&quot; -filter_complex &quot;[1:v]format=yuva444p,lut=c3=128[video2withAlpha],[0:v ][video2withAlpha]blend=all_mode=difference[out]&quot; -map &quot;[out]&quot; &quot;output.mp4&quot;

我所需要的只是一个人在任何正常背景下拍摄的图像/视频，无需用户交互，例如区域选择或任何其他类似的事情。 Luminoth 有经过训练的数据，但是给出的人框不是确切的人，以便我可以删除。任何有关删除背景的帮助或指导将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/55916977/remove-random-background-from-video-using-ffmpeg-or-python</guid>
      <pubDate>Tue, 30 Apr 2019 08:39:08 GMT</pubDate>
    </item>
    <item>
      <title>在决策树 ID3 算法中选择分区背后的直觉</title>
      <link>https://stackoverflow.com/questions/36105633/intuition-behind-choosing-partition-in-decision-tree-id3-algorithm</link>
      <description><![CDATA[我试图理解机器学习中决策树分类器背后的直觉。我知道决策树中每个节点的目标是进一步划分可能标签的当前空间，以便根据该节点给定问题的答案消除尽可能多的候选标签。但这与根据最小化分区“熵”的属性选择分区有什么关系呢？其中“熵”定义如下：
H(S) = −p_1*log2(p_1) −... −p_n*log2(p_n)

和分区熵：

&lt;前&gt;&lt;代码&gt;H = q_1*H(S_1) +...+ q_m*H(S_m)

其中 H(S)：给定子集的熵
     H：分区熵
     p_i&#39;s：属于 i 类的数据比例
     q_i&#39;s：基于给定分区属于子集 i 的数据比例

此外，每个节点的“问题”是否必须是是/否问题，从而将当前标签空间分成 2 个？而不是 3 个或更多子集？任何清晰的例子将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/36105633/intuition-behind-choosing-partition-in-decision-tree-id3-algorithm</guid>
      <pubDate>Sat, 19 Mar 2016 18:41:37 GMT</pubDate>
    </item>
    </channel>
</rss>