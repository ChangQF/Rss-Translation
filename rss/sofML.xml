<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 05 Jan 2024 06:18:16 GMT</lastBuildDate>
    <item>
      <title>无论输入图像如何，具有 TensorFlow Lite 模型的 Flask API 始终预测相同的类别</title>
      <link>https://stackoverflow.com/questions/77762697/flask-api-with-tensorflow-lite-model-always-predicts-the-same-class-regardless</link>
      <description><![CDATA[我正在开发 Flask API，以使用 TensorFlow Lite 模型执行推理，该模型是在阿尔茨海默氏症 5 类图像数据集上训练的，这些图像是 [“AD - 阿尔茨海默病”、“CN - 认知正常”、“EMCI - 早期轻度”认知障碍”、“LMCI - 晚期轻度认知障碍”、“MCI - 轻度认知障碍”]。
该模型在我的训练环境中运行良好，但当我将其部署到 Flask API 中时，出现了问题。 API 一致地为每张图像预测相同的类别（“MCI - 轻度认知障碍”），而在我的 Colab 笔记本中训练的模型则准确地预测各种类别。该 API 稍后将与 React Native App 集成。
使用不同的数据集训练模型两次，但问题仍然存在。我现在已经走进了死胡同，不知道如何解决它。
任何帮助将不胜感激。
TFLite 模型代码：
https://colab.research.google.com/drive/1xxW8v5ZBKLvlGrofL2fBy9WYk_Fn5Dj_?usp=分享
FlaskAPI 代码：
` from Flask import Flask, request, jsonify
将张量流导入为 tf
导入CV2
将 numpy 导入为 np
从 PIL 导入图像
导入io
app = Flask(__name__)

解释器 = tf.lite.Interpreter(model_path=“latest_model.tflite”)
解释器.allocate_tensors()

class_names = [“CN-认知正常”、“AD-阿尔茨海默病”、“EMCI-早期轻度认知障碍”、“MCI-轻度认知障碍”、“LMCI-晚期轻度认知障碍”]

def preprocess_image(图像):
    图像 = cv2.resize(图像, (150, 150))
    图像 = image.astype(&#39;float32&#39;) / 255.0
    图像 = np.expand_dims(图像, 轴=0)
    返回图像


@app.route(&#39;/predict&#39;,methods=[&#39;POST&#39;])
def 预测（）：
    尝试：
        文件 = request.files[&#39;文件&#39;]
        image_file = Image.open(io.BytesIO(file.read()))
        图像 = cv2.cvtColor(np.array(image_file), cv2.COLOR_RGB2BGR)

    
        如果不是（image.shape[0] &gt;= 150 且 image.shape[1] &gt;= 150 且 image.shape[2] == 3）：
        return jsonify({&quot;error&quot;: &quot;无效的图像形状&quot;})


        图像 = image.astype(&#39;float32&#39;) / 255.0

        预处理图像 = 预处理图像（图像）

        terpreter.set_tensor(interpreter.get_input_details()[0][&#39;index&#39;], preprocessed_image)
        解释器.invoke()

        output_tensor =terpreter.get_tensor(interpreter.get_output_details()[0][&#39;index&#39;])
        Predicted_class_index = np.argmax(output_tensor, axis=1)[0]
        预测类名称 = 类名称[预测类索引]

        结果 = {“预测”：预测类名称，“输出张量”：output_tensor.tolist()}
        返回 jsonify(结果)
    除了异常 e：
       返回 jsonify({“错误”: str(e)})

如果 __name__ == &#39;__main__&#39;:
应用程序运行（调试=真）

`
尝试记录输出张量，但这是我从 Flask API 获得的输出。知道输出张量表明偏向于 MCI 类，但如果是这种情况，为什么它在 colab 环境中完美运行，而不是在 Flask API 中运行？
` {
&lt;前&gt;&lt;代码&gt;“输出张量”：[

[

0.0004518234636634588,

0.0004140451201237738,

0.002781340153887868,

0.7277416586875916,

0.2686111330986023

]

],

“预测”：“MCI-轻度认知障碍”

}`
]]></description>
      <guid>https://stackoverflow.com/questions/77762697/flask-api-with-tensorflow-lite-model-always-predicts-the-same-class-regardless</guid>
      <pubDate>Fri, 05 Jan 2024 05:43:52 GMT</pubDate>
    </item>
    <item>
      <title>TF Transformer 模型永远不会过拟合，只会停滞不前：训练曲线的解读和改进建议</title>
      <link>https://stackoverflow.com/questions/77762264/tf-transformer-model-never-overfits-and-just-plateaus-interpretation-of-this-tr</link>
      <description><![CDATA[此训练曲线适用于处理 2D（不包括批次）顺序信号并使用 Adam 优化器、32 批次大小和学习率的 Transformer 模型：一个自定义 LR 调度程序，它复制在“注意是”中使用的预热调度程序所有你需要的&#39;纸。训练曲线如下所示，最终训练损失略低于验证损失，但训练损失永远不会开始回升，我将其解释为模型永远不会开始过度拟合，只是在 90 纪元后停止重新调整权重。
更好的解释和解决方案来改进这个模型？

下面是我的简短的可重现代码：
x_train = np.random.normal(size=(32, 512, 512))
批量大小 = 32
H, W = x_train.shape
行，列= np.indices（（H，W），稀疏= True）
padding_mask_init = np.zeros((H, W, W), dtype=np.bool_)
padding_mask_init[行，1：，列] = 1
padding_mask = padding_mask_init[:batch_size]
嵌入尺寸 = 512
密集_暗 = 2048
头数 = 2
形状 = (batch_size, embed_dim, 512) #(32, 512, 512)
解码器_输入=层.输入（batch_input_shape=形状，dtype=tensorflow.float16）
mha_1 = 层.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
mha_2 = 层.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
Layernorm_1 = 层.LayerNormalization()

Z = 解码器输入
Z = mha_1(查询=Z、值=Z、键=Z、use_causal_mask=True、attention_mask=padding_mask)
Z = layernorm_1(Z + 解码器输入)
Z = mha_2(查询=Z，值=解码器输入，键=解码器输入，attention_mask=padding_mask)
输出=layers.TimeDistributed（keras.layers.Dense（embed_dim，激活=“softmax”））（Z）

模型 = keras.Model(decoder_inputs, 输出)
model.compile（损失=“mean_squared_error”，optimizer=tf.keras.optimizers.Adam（learning_rate=lr_schedule（embed_dim，3000），beta_1=0.9，beta_2=0.98，epsilon=1.0e-9），metrics=[&quot; “准确度”]）

历史= model.fit（数据集，epochs = 200，validation_data = val_dataset）
]]></description>
      <guid>https://stackoverflow.com/questions/77762264/tf-transformer-model-never-overfits-and-just-plateaus-interpretation-of-this-tr</guid>
      <pubDate>Fri, 05 Jan 2024 02:47:25 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到机器学习项目的 CSV 数据库？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77762128/where-to-find-csv-databases-for-machine-learning-projects</link>
      <description><![CDATA[我想创建一个项目，旨在根据时间序列数据集来预测健康食品或类似食品的消费趋势。我考虑在 Euromonitor 网站上搜索数据集，并找到了很多有关该主题的信息（下面提供了其中一个链接），但我找不到，也不知道是否可以使用 下载任何文件例如，CSV 数据库。有谁知道我在哪里以及如何下载涵盖这个食物主题的数据库，以便我可以构建一个机器学习项目，例如考虑时间序列？我尝试在 Kaggle 上搜索，但没有找到满意的数据库。
主题示例：
https://www.euromonitor.com /文章/正念饮食和新食物信念
https://www.euromonitor.com/article/consumers-想要更健康的包装食品]]></description>
      <guid>https://stackoverflow.com/questions/77762128/where-to-find-csv-databases-for-machine-learning-projects</guid>
      <pubDate>Fri, 05 Jan 2024 01:57:36 GMT</pubDate>
    </item>
    <item>
      <title>想知道如何提高这个使用机器学习预测癌症复发的模型的 79% 准确度</title>
      <link>https://stackoverflow.com/questions/77762092/wondering-how-to-improve-79-accuracy-of-this-model-that-uses-ml-to-predict-canc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77762092/wondering-how-to-improve-79-accuracy-of-this-model-that-uses-ml-to-predict-canc</guid>
      <pubDate>Fri, 05 Jan 2024 01:43:16 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何卡纳达产品评论数据集可用于情感分析项目</title>
      <link>https://stackoverflow.com/questions/77761252/are-there-any-datasets-of-kannada-product-reviews-available-for-sentiment-analys</link>
      <description><![CDATA[我正在尝试构建一个情感分析模型，该模型使用卡纳达文本产品评论作为输入并分析评论的情感
我尝试在所有可能的开源数据集网站（例如 Google 数据集 kaggle 等）中搜索数据集，但只能找到卡纳达语电影评论数据集，而找不到卡纳达语移动评论数据集。]]></description>
      <guid>https://stackoverflow.com/questions/77761252/are-there-any-datasets-of-kannada-product-reviews-available-for-sentiment-analys</guid>
      <pubDate>Thu, 04 Jan 2024 21:16:28 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 haar 级联找到使用网络摄像头的人的参与度？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades</link>
      <description><![CDATA[我正在建立一个网站，在编写考试时跟踪用户以了解他们的参与程度，并为此找到了这篇有趣的论文。
https://www.sciencedirect .com/science/article/pii/S0045790621002597?ref=cra_js_challenge&amp;fr=RR-1
我想使用 opencv 和 tensorflow 构建完全相同的模型。有人可以帮我完成模型吗？我是机器学习领域的新手。刚刚建立了一些回归和分类模型。任何帮助都会非常有帮助。我无法理解如何从上述论文中计算聚焦概率。我希望了解如何构建模型以及如何计算值的详细步骤。
数据集链接：
FER 2013：https://www.kaggle.com/datasets/msambare/fer2013&lt; /a&gt;
MES数据集：https://github.com/Harsh9524/MES-Dataset
我已经使用 haar 级联检测到人脸并且它正在工作。下一个问题是找出情绪，我也做到了！但问题在于寻找 MES 和焦点概率。请帮我解决一下。]]></description>
      <guid>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades</guid>
      <pubDate>Thu, 04 Jan 2024 20:42:19 GMT</pubDate>
    </item>
    <item>
      <title>输出 AR@0.5 和 AR@0.75 [关闭]</title>
      <link>https://stackoverflow.com/questions/77747981/output-ar0-5-and-ar0-75</link>
      <description><![CDATA[使用 pycocotools，当提供地面实况注释文件和预测边界框文件时，我们可以针对 AP@0.5 和 AP@0.75 等指标以及其他不同指标评估预训练模型的对象检测性能。但pycocotools不输出AR@0.5和AR@0.75。它输出不同的 AR 变体，但我特别需要这两个。是否有可以评估这些指标的代码或库？]]></description>
      <guid>https://stackoverflow.com/questions/77747981/output-ar0-5-and-ar0-75</guid>
      <pubDate>Tue, 02 Jan 2024 18:47:09 GMT</pubDate>
    </item>
    <item>
      <title>Langchain AgentExecutor 不会使用任何工具</title>
      <link>https://stackoverflow.com/questions/76886176/langchain-agentexecutor-wont-use-any-tools</link>
      <description><![CDATA[我正在使用 tiiuae/falcon-40b-instruct 关闭 HF，并尝试将其与 LangChain ReAct 合并。我使用的是带有 StringPromptTemplate 的常规 LLMChain，它只是标准的思想/动作/动作输入/观察提示，并包含一些示例（我已经尝试过使用和不使用示例，但似乎两种方式都不起作用） 。 LLMChain 是 LLMSingleActionAgent 的一部分，然后由 AgentExecutor 运行。
问题是，执行者似乎无法使用任何工具。大多数时候，它能够选择正确的工具，但只会产生工具的输出结果。打开调试模式后，很明显，大多数时候它实际上并没有进入工具/开始或工具/结束链。之前一些关于类似问题的帖子建议提高模型的温度。随着温度的升高，可能有 5%-10% 的时间会进入工具链，但唯一返回的就是无效或不完整的响应。
我不太清楚哪里可能出了问题，但这里是我的链和代理的定义方式，作为任何感兴趣的人的起点，以及包含完整代码的 Github 存储库 此处：
# 由 LLM 和提示符组成的 LLM 链
llm_chain = LLMChain(llm=local_llm, 提示=提示)

tool_names = [工具中工具的工具名称]

代理 = LLMSingleActionAgent(
    llm_链=llm_链,
    output_parser=自定义输出解析器(),
    stop=[“\n观察结果：”],
    allowed_tools=工具名称
）
#handle_parsing_errors=“检查你的输出并确保它符合要求！”
agent_executor = AgentExecutor.from_agent_and_tools(agent=agent,
                                                    工具=工具，
                                                    详细=真）

我尝试过使用结构化工具并调整提示。然而，执行者只是不使用可用的工具，就会发生同样的错误。我已在此处附加了错误的图像。模型产生幻觉并且不使用工具。 ]]></description>
      <guid>https://stackoverflow.com/questions/76886176/langchain-agentexecutor-wont-use-any-tools</guid>
      <pubDate>Fri, 11 Aug 2023 19:06:43 GMT</pubDate>
    </item>
    <item>
      <title>具有 1D 数据和 Ghost Dimension 的 TF.MultiHeadAttention</title>
      <link>https://stackoverflow.com/questions/76520092/tf-multiheadattention-with-1d-data-and-ghost-dimension</link>
      <description><![CDATA[背景：
我的数据的形状为 (batch_size, data_length) 并且尺寸似乎与内部 MultiHeadAttention 操作不兼容，尤其是 softmax。有人善意地建议我应该使用尺寸为 1 的幽灵维度作为最后一个维度。
我收到的错误消息：
&lt;前&gt;&lt;代码&gt;(32, 512, 1)
纪元 1/200

-------------------------------------------------- ------------------------

ValueError Traceback（最近一次调用最后一次）

&lt;ipython-input-7-870abeaa4b93&gt;在&lt;细胞系：281&gt;()
    279 model.compile（损失=“均方误差”，优化器=“rmsprop”，指标=[“准确性”]）
    280
--&gt; [第 281 章]

1 帧

tf__train_function（迭代器）中的/usr/local/lib/python3.10/dist-packages/keras/engine/training.py
     13 尝试：
     14 do_return =真
---&gt; 15 retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(迭代器)), 无, fscope)
     16 除外：
     17 do_return = 假

ValueError：在用户代码中：

    文件“/usr/local/lib/python3.10/dist-packages/keras/engine/training.py”，第 1284 行，train_function *
        返回step_function（自身，迭代器）
    文件“/usr/local/lib/python3.10/dist-packages/keras/engine/training.py”，第 1268 行，在 step_function **
        输出 = model.distribute_strategy.run(run_step, args=(data,))
    文件“/usr/local/lib/python3.10/dist-packages/keras/engine/training.py”，第 1249 行，在 run_step **
        输出 = model.train_step(数据)
    文件“/usr/local/lib/python3.10/dist-packages/keras/engine/training.py”，第 1050 行，在 train_step 中
        y_pred = self(x, 训练=True)
    文件“/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py”，第 70 行，在 error_handler 中
        从 None 引发 e.with_traceback(filtered_tb)

    ValueError：调用层“查询”（类型 EinsumDense）时遇到异常。
    
    维度必须相等，但对于 &#39;{{node model/multi_head_attention/query/einsum/Einsum}} = Einsum[N=2, T=DT_HALF,equation=“abc,cde-&gt;abde”] 为 1 和 512 (model/Cast, model/multi_head_attention/query/einsum/Einsum/Cast)&#39;，输入形状：[32,512,1]，[512,2,512]。
    
    调用层“query”接收的参数（类型 EinsumDense）：
      • 输入=tf.Tensor(形状=(32, 512, 1), dtype=float16)
]]></description>
      <guid>https://stackoverflow.com/questions/76520092/tf-multiheadattention-with-1d-data-and-ghost-dimension</guid>
      <pubDate>Wed, 21 Jun 2023 05:04:04 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 自定义学习率调度程序给出意外的 EagerTensor 类型错误</title>
      <link>https://stackoverflow.com/questions/76511182/tensorflow-custom-learning-rate-scheduler-gives-unexpected-eagertensor-type-erro</link>
      <description><![CDATA[下面是我的自定义LR调度程序，它是tensorflow.keras.optimizers.schedules.LearningRateSchedule的子类，出现错误TypeError：无法将-0.5转换为dtype int64的EagerTensor。真的很困惑为什么 Eagertensor 与此自定义类的返回调用的简单平方反比计算相关。
class lr_schedule(tensorflow.keras.optimizers.schedules.LearningRateSchedule)：
    def __init__(自身、dim_embed、warmup_steps):
        self.dim_embed = dim_embed
        self.warmup_steps = 预热步骤
    def __call__(自我，步骤)：
        返回（self.dim_embed ** -0.5）* min（（步骤** -0.5），步骤*（self.warmup_steps ** -1.5））

与此错误没有特别相关，但这是一个自定义 LR 调度程序，它复制“Attention is All You Need”论文中使用的预热调度程序。]]></description>
      <guid>https://stackoverflow.com/questions/76511182/tensorflow-custom-learning-rate-scheduler-gives-unexpected-eagertensor-type-erro</guid>
      <pubDate>Tue, 20 Jun 2023 03:08:43 GMT</pubDate>
    </item>
    <item>
      <title>NEAT 的类型错误</title>
      <link>https://stackoverflow.com/questions/68248850/typeerror-with-neat</link>
      <description><![CDATA[我在尝试制作蛇 AI 时遇到 NEAT 类型错误：
node_inputs.append(self.values[i] * w)
类型错误：无法将序列乘以“float”类型的非 int

代码
类 SnakeGame(对象):
    def __init__(自身、基因组、配置):
    self.genome = 基因组
        self.nets = []

        对于 id，self.genomes 中的 g：
            净=整洁.nn.FeedForwardNetwork.create（g，配置）
            self.nets.append(net)
            g.适应度 = 0
 

在同一个类的另一个函数中的代码
def 游戏（自身）：
    而真实：
        对于 pg.event.get() 中的事件：
            如果 event.type == pg.QUIT：
                pg.quit()
        数据 = self.nets[0].activate(self.getData())
        输出 = data.index(max(data))

函数 getData 是什么样的
def getData(self):
    数据 = [self.x_position, self.y_position, self.food_x, self.food_y, self.snakeLength]
    返回数据

config-feedforward.txt 的部分代码
&lt;前&gt;&lt;代码&gt;[整洁]
健身标准 = 最大值
健身阈值 = 1000
弹出大小 = 2
灭绝时重置=真
]]></description>
      <guid>https://stackoverflow.com/questions/68248850/typeerror-with-neat</guid>
      <pubDate>Sun, 04 Jul 2021 21:19:36 GMT</pubDate>
    </item>
    <item>
      <title>shap 错误 - AttributeError：模块“shap”没有属性“TreeExplainer”</title>
      <link>https://stackoverflow.com/questions/65643941/error-in-shap-attributeerror-module-shap-has-no-attribute-treeexplainer</link>
      <description><![CDATA[当我使用时：
gb_explainer = shap.TreeExplainer

我收到此错误：
 AttributeError：模块“shap”没有属性“TreeExplainer”

完整代码：
 def create_shap_tree_explainer(self):

        self.gb_explainer = shap.TreeExplainer(self.gb_model)
        self.shap_values_X_test = self.gb_explainer.shap_values(self.X_test)
        self.shap_values_X_train = self.gb_explainer.shap_values(self.X_train)

梯度提升分类器模型是：
 gbc_model = Create_Gradient_Boosting_Classifier(X_train, y_train, ps)
]]></description>
      <guid>https://stackoverflow.com/questions/65643941/error-in-shap-attributeerror-module-shap-has-no-attribute-treeexplainer</guid>
      <pubDate>Sat, 09 Jan 2021 14:45:38 GMT</pubDate>
    </item>
    <item>
      <title>如何将两个不同训练的 ML 模型合并为一个？</title>
      <link>https://stackoverflow.com/questions/64801479/how-to-combine-two-different-trained-ml-models-as-one</link>
      <description><![CDATA[我已经根据两个不同的数据集训练了两个机器学习模型。然后我将它们保存为 model1.pkl 和 model2.pkl 。有两个用户输入（不是模型的输入数据），例如 x=0 和 x=1，如果 x=0 我必须使用 model1.pkl 进行预测，否则我必须使用 model2.pkl 进行预测。我可以使用 if 条件来完成它们，但我的问题是我必须知道是否有可能将其保存为 model.pkl ，包括此条件语句。如果我将它们组合起来并另存为模型，那么就可以很容易地在其他 IDE 中加载。]]></description>
      <guid>https://stackoverflow.com/questions/64801479/how-to-combine-two-different-trained-ml-models-as-one</guid>
      <pubDate>Thu, 12 Nov 2020 09:44:27 GMT</pubDate>
    </item>
    <item>
      <title>“ ValueWarning：没有可用的受支持索引。预测结果将使用从“start”开始的整数索引给出”</title>
      <link>https://stackoverflow.com/questions/62682342/valuewarning-no-supported-index-is-available-prediction-results-will-be-give</link>
      <description><![CDATA[为什么当我们使用 Statsmodels 进行预测时会出现此错误” SARIMAX”？。
我只是传递索引的开始和结束以及需要考虑的步骤。
使用以下行来执行：

结果 = model.fit()
预测=结果.预测（开始=train_size，结束=train_size+test_size+（步数）-1）
（或者）
Forecast_= results.forecast(steps=test_size-1)

有什么正确的方法可以忽略警告消息吗？
**
想要详细了解警告。希望能得到它。
**。]]></description>
      <guid>https://stackoverflow.com/questions/62682342/valuewarning-no-supported-index-is-available-prediction-results-will-be-give</guid>
      <pubDate>Wed, 01 Jul 2020 17:33:26 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中使用 WeightedRandomSampler</title>
      <link>https://stackoverflow.com/questions/60812032/using-weightedrandomsampler-in-pytorch</link>
      <description><![CDATA[我需要在 PyTorch 中实现多标签图像分类模型。但是我的数据不平衡，因此我使用 PyTorch 中的 WeightedRandomSampler 来创建自定义数据加载器。但是当我迭代自定义数据加载器时，出现错误：IndexError：列表索引超出范围 
使用此链接实现了以下代码：https://discuss.pytorch.org/t/balanced-sampling- Between-classes-with-torchvision-dataloader/2703/3?u=surajsubramanian
def make_weights_for_balanced_classes(images, nclasses):
    计数 = [0] * n 类
    对于图像中的项目：
        计数[项目[1]] += 1
    每个类别的权重 = [0.] * n 个类别
    N = 浮点（总和（计数））
    对于范围内的 i (nclasses)：
        每类权重[i] = N/float(count[i])
    重量 = [0] * len(图像)
    对于 idx，枚举（图像）中的 val：
        权重[idx] =weight_per_class[val[1]]
    返回重量

权重 = make_weights_for_balanced_classes(train_dataset.imgs, len(full_dataset.classes))
权重 = torch.DoubleTensor(权重)
采样器 = WeightedRandomSampler(权重, len(权重))

train_loader = DataLoader（train_dataset，batch_size = 4，采样器=采样器，pin_memory = True）

根据https://stackoverflow.com/a/60813495/10077354中的答案，以下是我的更新的代码。但是当我创建数据加载器时：loader = DataLoader(full_dataset, batch_size=4, Sampler=sampler)，len(loader) 返回 1。
class_counts = [1691, 743, 2278, 1271]
num_samples = np.sum(class_counts)
labels = [_ 的标签，full_dataset.imgs 中的标签]

class_weights = [num_samples/class_counts[i] for i in range(len(class_counts)]
权重 = [class_weights[labels[i]] for i in range(num_samples)]
采样器 = WeightedRandomSampler(torch.DoubleTensor(权重), num_samples)

提前非常感谢！
我根据下面接受的答案添加了一个实用函数：
def Sampler_（数据集）：
    dataset_counts = imageCount(数据集)
    num_samples = sum(数据集计数)
    labels = [_的标签，数据集中的标签]

    class_weights = [num_samples/dataset_counts[i] for i in range(n_classes)]
    权重 = [class_weights[labels[i]] for i in range(num_samples)]
    采样器 = WeightedRandomSampler(torch.DoubleTensor(权重), int(num_samples))
    返回采样器

imageCount 函数查找数据集中每个类别的图像数量。数据集中的每一行都包含图像和类，因此我们考虑元组中的第二个元素。
def imageCount(数据集):
    image_count = [0]*(n_classes)
    对于数据集中的 img：
        图像计数[img[1]] += 1
    返回图像数量
]]></description>
      <guid>https://stackoverflow.com/questions/60812032/using-weightedrandomsampler-in-pytorch</guid>
      <pubDate>Mon, 23 Mar 2020 10:45:53 GMT</pubDate>
    </item>
    </channel>
</rss>