<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 11 Dec 2023 18:18:01 GMT</lastBuildDate>
    <item>
      <title>关于使用从用户交互的物理设置中提取的数据设置近端策略优化代码的建议</title>
      <link>https://stackoverflow.com/questions/77641484/advice-on-setting-up-a-code-for-proximal-policy-optimization-using-data-pulled-f</link>
      <description><![CDATA[对于一个项目，我使用 PyTorch 在 Python 中设置近端策略优化算法 (PPO)，为用户定制振动反馈策略。我的项目是对用户肘部角度位置的一维跟踪。该系统的目标是提供振动反馈，描述肘部相对于目标位置的当前角度位置。我正在努力寻找一种在使用从现实世界传感器而不是模拟环境收集的数据的场景中实现 PPO 的方法。
我浏览了多个设置 PPO 的示例（例如这个 https ://github.com/ericyangyu/PPO-for-Beginners/tree/master）；然而，许多人依赖使用 OpenAI 健身房环境来创建模拟。我已经找到了如何根据我的项目创建自定义环境，但我似乎找不到一种可以处理从物理传感器收集的数据的方法。我也尝试过修改这些例子；但是，我找不到任何方法来推进训练过程，因为每个步骤都需要来自传感器的数据。
如果有人能够提供一些关于如何设置 PPO 算法以使用通过 OpenAI 环境或不通过 OpenAI 环境从物理传感器收集的数据的建议或示例，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77641484/advice-on-setting-up-a-code-for-proximal-policy-optimization-using-data-pulled-f</guid>
      <pubDate>Mon, 11 Dec 2023 17:58:03 GMT</pubDate>
    </item>
    <item>
      <title>我们如何从图中知道训练模型是否良好？</title>
      <link>https://stackoverflow.com/questions/77641405/how-do-we-know-if-training-model-is-considered-good-from-the-graph</link>
      <description><![CDATA[所以我一直在使用 TensorFlow 训练模型。数据有6列，输出为1列（分类为6）。我想知道我的训练是否符合图表的外观。
我尝试了几种不同的模型，并且我保存了 2 个训练图。其中之一具有更好的验证损失，但图表看起来有点不稳定（？）。第二个的验证损失更严重，但图表比第一个更不摇晃。哪一个更好？

]]></description>
      <guid>https://stackoverflow.com/questions/77641405/how-do-we-know-if-training-model-is-considered-good-from-the-graph</guid>
      <pubDate>Mon, 11 Dec 2023 17:41:34 GMT</pubDate>
    </item>
    <item>
      <title>确定特征是连续的还是分类的</title>
      <link>https://stackoverflow.com/questions/77641331/determining-if-feature-is-continuous-or-categorical</link>
      <description><![CDATA[我有一个包含 50 个特征和 2000 个样本的数据集。我需要确定每个特征是分类特征还是连续特征。在这两种情况下，特征值都是整数。我有一个列表，其中包含每个功能的唯一值的数量：
[10, 7, 10, 16, 6, 7, 14, 6, 5, 2, 2, 2, 7, 37, 10, 6, 7, 13, 9, 6, 10, 9, 7, 14, 8 , 8, 12, 11, 6, 6, 6, 10, 9, 11, 7, 8, 9, 6, 10, 10, 8, 8, 12, 11, 4, 11, 11, 7, 7, 6 , 2]
确定特征是连续的还是分类的阈值应该是多少？
我发现这个阈值通常是10或15个不同的值，但在这种情况下似乎阈值应该更高（所以只有具有37个不同值的特征是连续的）？]]></description>
      <guid>https://stackoverflow.com/questions/77641331/determining-if-feature-is-continuous-or-categorical</guid>
      <pubDate>Mon, 11 Dec 2023 17:26:03 GMT</pubDate>
    </item>
    <item>
      <title>通过FAST API调用深度学习模型</title>
      <link>https://stackoverflow.com/questions/77641249/deep-learning-model-calling-through-fast-api</link>
      <description><![CDATA[是否可以通过 Fast API 制作的 api 来调用处理数 GB 图像数据的深度学习模型？或者 DjangoREST 或 Flask 是更好的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77641249/deep-learning-model-calling-through-fast-api</guid>
      <pubDate>Mon, 11 Dec 2023 17:09:12 GMT</pubDate>
    </item>
    <item>
      <title>如何创建实时预测代码？</title>
      <link>https://stackoverflow.com/questions/77641103/how-do-i-create-a-real-time-prediction-code</link>
      <description><![CDATA[我想创建一个实时基本手语翻译器来翻译字母和数字。我使用 CNN 完成了训练，我可以通过将新图像放入文件并运行比较来测试新图像。我如何使其实时？
我尝试了网上建议的一些步骤，但相机似乎没有检测到我的手，而且准确性很糟糕


导入操作系统
将张量流导入为 tf
将 numpy 导入为 np
导入路径库
导入 json

使用 open(&quot;model_arch.json&quot;, &quot;r&quot;) 作为 json_file：
    model_json = json_file.read()

模型 = tf.keras.models.model_from_json(model_json)
model.load_weights(&quot;model_weights.h5&quot;)

data_dir = pathlib.Path(&#39;C:\\Users\\User\\Documents\\FYP\\FYP\\data&#39;)
图像高度 = 180
图像宽度 = 180

train_ds = tf.keras.utils.image_dataset_from_directory(
    数据目录，
    验证分割=0.2，
    子集=“训练”，
    种子=123，
    图像大小=（img_高度，img_宽度），
    批量大小=32
）

类名=train_ds.类名

test_directory = &quot;C:\\Users\\User\\Documents\\FYP\\FYP\\test&quot;
image_count = len(列表(data_dir.glob(&#39;*/*.jpeg&#39;)))
test_image_paths = [os.path.join(test_directory, f) for f in os.listdir(test_directory) if f.lower().endswith(&#39;.jpeg&#39;)]

如果不是 test_image_paths：
    print(&quot;在指定的测试目录中找不到 JPEG 图像。&quot;)
    出口（）

对于 test_image_paths 中的 test_image_path：
    尝试：
        img = tf.keras.utils.load_img(
            test_image_path, target_size=(img_height, img_width)
        ）
    除了异常 e：
        print(f&quot;加载图像 {test_image_path} 时出错：{e}&quot;)
        继续

    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    预测 = model.predict(img_array)
    分数 = tf.nn.softmax(预测[0])

    预测类别 = 类别名称[np.argmax(分数)]
    置信度 = 100 * np.max(分数)

    打印（
        f“该图像很可能属于 {predicted_class} 类，置信度为 {confidence:.2f}%。”
    ）


]]></description>
      <guid>https://stackoverflow.com/questions/77641103/how-do-i-create-a-real-time-prediction-code</guid>
      <pubDate>Mon, 11 Dec 2023 16:43:36 GMT</pubDate>
    </item>
    <item>
      <title>深度学习模型的结构是如何设计的？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77641031/how-structures-of-deep-learning-models-are-designed</link>
      <description><![CDATA[AI工程师或研究人员如何设计深度学习模型的结构？我知道需要调整超参数。
然而，我认为有一些技巧或思维方式可以从数据或手头的问题中猜测出一个好的设计。
例如，我正在研究机器学习来预测白菜价格，一篇论文使用了一个具有 LSTM 两条路径的模型，并将它们连接起来以获得输出。
我应该考虑什么才能提出机器学习（尤其是深度学习）结构的粗略想法？]]></description>
      <guid>https://stackoverflow.com/questions/77641031/how-structures-of-deep-learning-models-are-designed</guid>
      <pubDate>Mon, 11 Dec 2023 16:33:54 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么来为我的测试数据添加 20% 的噪声</title>
      <link>https://stackoverflow.com/questions/77639239/what-should-i-use-to-add-20-noise-to-my-test-data</link>
      <description><![CDATA[我想向我的测试数据添加 20% 的噪声，但我不知道如何做到这一点，因为我不知道 np.random 函数实际上是如何工作的。
我应该使用类似的东西吗：
x_test_noise = x_test * np.random.uniform(0.8, 1.2, size=x_test.shape)

或者类似的东西：
x_test_noise=pd.DataFrame()
对于范围内的 i (len(x_test))：
    对于范围内的 j(len(x_test.columns))：
        x_test_noise=x_test*np.random.uniform(0.8,1.2)

我主要关心的是，我希望 x_test 的每个值都乘以从随机分布中提取的不同值。第一个语法是要执行此操作还是要将 x_test 的每个值与从随机分布中抽取的相同值相乘？]]></description>
      <guid>https://stackoverflow.com/questions/77639239/what-should-i-use-to-add-20-noise-to-my-test-data</guid>
      <pubDate>Mon, 11 Dec 2023 11:30:32 GMT</pubDate>
    </item>
    <item>
      <title>我在尝试运行决策树模型时遇到错误[关闭]</title>
      <link>https://stackoverflow.com/questions/77638235/i-have-an-error-when-trying-to-run-the-decision-tree-model</link>
      <description><![CDATA[我有一个学校机器学习小组项目，它是关于在 NSL-KDD 数据集上重现入侵检测系统研究的结果，我得到了分类部分
我试图实施决策树模型，但我得到了一个 ValueError

该错误与项目的数据准备部分有关吗？
pca部分的代码有一些错误
这是 x_train 数据的示例
]]></description>
      <guid>https://stackoverflow.com/questions/77638235/i-have-an-error-when-trying-to-run-the-decision-tree-model</guid>
      <pubDate>Mon, 11 Dec 2023 08:18:07 GMT</pubDate>
    </item>
    <item>
      <title>使用形状值分析模型时刻度标签中的字形错误</title>
      <link>https://stackoverflow.com/questions/77637695/glyph-errors-in-tick-labels-when-using-shap-values-to-analysis-my-model</link>
      <description><![CDATA[我正在 python 中使用 shap 包为我的模型重新创建一些图表。其中之一是瀑布图，来自 手册我按照使用以下代码生成的（完整代码太长，请查看手册）。
shap.waterfall_plot(shap_explainer_values[4652]) 
但是，我的图表的减号缺失，并出现警告消息“当前字体中缺少 Glyph 8722 (\N{MINUS SIGN})”。

stackoverflow上有很多与这个问题相关的问题，都可以通过来解决
plt.rcParams[&#39;axes.unicode_minus&#39;] = False

但是，我的却不能。有人能帮忙解决这个问题吗？
我也尝试了shutil.rmtree(matplotlib.get_cachedir())。]]></description>
      <guid>https://stackoverflow.com/questions/77637695/glyph-errors-in-tick-labels-when-using-shap-values-to-analysis-my-model</guid>
      <pubDate>Mon, 11 Dec 2023 05:54:34 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow 中组合图像和表格数据</title>
      <link>https://stackoverflow.com/questions/77637432/combining-image-and-tabular-data-in-tensorflow</link>
      <description><![CDATA[我一直在尝试将图像（胸部 X 光）和表格数据（年龄、性别、BMI 等）结合起来形成二元预测模型（疾病：0 或 1）。我有使用顺序的 2D-CNN，但在合并表格数据时遇到困难。我在网上探索了一些资源（例如 https://machinelearningmastery.com/keras-function -api-deep-learning/），但大多数都已经过时了 - 我还没有找到任何好的例子。 函数式 API 是最好的方法吗？您能否指导我如何针对下面的数据处理此问题？
导入tensorflow为tf
从tensorflow.keras.layers导入输入、Conv2D、MaxPooling2D、展平、密集、连接
从tensorflow.keras.models导入模型

label_encoder = LabelEncoder()
df[&#39;疾病&#39;] = label_encoder.fit_transform(df[&#39;疾病&#39;]).astype(str)

# 将 DataFrame 拆分为训练集和测试集
train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df[&#39;疾病&#39;])

# 图像数据生成器
image_datagen = ImageDataGenerator（重新缩放=1/255）

# 训练图像生成器
train_image_generator = image_datagen.flow_from_dataframe(
    训练数据，
    x_col=&#39;文件名&#39;,
    y_col=&#39;疾病&#39;,
    目标大小=(224, 224),
    批量大小=32，
    class_mode=&#39;二进制&#39;,
    dtype=&#39;float32&#39;
）

# 测试图像生成器
test_image_generator = image_datagen.flow_from_dataframe(
    测试数据，
    x_col=&#39;文件名&#39;,
    y_col=&#39;疾病&#39;,
    目标大小=(224, 224),
    批量大小=32，
    class_mode=&#39;二进制&#39;,
    dtype=&#39;float32&#39;
）

# 将“性别”特征转换为数值
train_data[&#39;性别&#39;] = train_data[&#39;性别&#39;].map({&#39;F&#39;: 0, &#39;M&#39;: 1})
test_data[&#39;性别&#39;] = test_data[&#39;性别&#39;].map({&#39;F&#39;: 0, &#39;M&#39;: 1})

# 用于训练的表格特征
train_tabular_features = train_data[[&#39;年龄&#39;, &#39;性别&#39;, &#39;身高&#39;, &#39;体重&#39;]].values.astype(float)

# 用于测试的表格特征
test_tabular_features = test_data[[&#39;年龄&#39;, &#39;性别&#39;, &#39;身高&#39;, &#39;体重&#39;]].values.astype(float)

# 定义图像输入层
img_input = 输入(形状=(224, 224, 3), 名称=&#39;image_input&#39;)
x1 = Conv2D(16, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;)(img_input)
x1 = MaxPooling2D()(x1)
x1 = Conv2D(32, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;)(x1)
x1 = MaxPooling2D()(x1)
x1 = 展平()(x1)

# 定义表格输入层
tabular_input = 输入(形状=(4,), name=&#39;tabular_input&#39;)
x2 = 密集（16，激活=&#39;relu&#39;）（tabular_input）
x2 = 密集(32, 激活=&#39;relu&#39;)(x2)
x2 = 展平()(x2)

# 连接图像和表格分支的输出
连接=连接（[x1，x2]）

# 组合特征的公共层
x = 密集（128，激活=&#39;relu&#39;）（连接）
输出层=密集（1，激活=&#39;sigmoid&#39;，名称=&#39;输出&#39;）（x）

# 创建模型
模型 = 模型(输入=[img_input, tabular_input], 输出=output_layer)

# 编译模型
模型.编译(
    优化器=&#39;亚当&#39;,
    损失=&#39;binary_crossentropy&#39;,
    指标=[&#39;准确性&#39;]
）

历史=模型.fit(
    x={
        &#39;image_input&#39;：train_image_generator，
        &#39;表格输入&#39;：train_tabular_features
    },
    y=训练标签，
    纪元=20，
    验证数据=(
        {
            &#39;图像输入&#39;：测试图像生成器，
            &#39;tabular_input&#39;：test_tabular_features
        },
        测试标签
    ）
）


我在处理问题的方式中遇到了各种错误，主要是以下错误。我相信我的方法是错误的，因此寻找任何资源或指南。]]></description>
      <guid>https://stackoverflow.com/questions/77637432/combining-image-and-tabular-data-in-tensorflow</guid>
      <pubDate>Mon, 11 Dec 2023 04:05:29 GMT</pubDate>
    </item>
    <item>
      <title>调整图像分割模型（来自 TF 教程）以进行二元掩蔽</title>
      <link>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</link>
      <description><![CDATA[我需要 Tensorflow 的图像分割模型。输入为图像和掩码（二进制、掩码或非掩码），输出为带有 0 和 1 的图像掩码。
我遵循了 https://www.tensorflow.org/tutorials/ 中的图像分割教程图像/分割
但现在我想在我的数据集上运行它的二进制掩码（没有边框类）
新数据集已准备好并输入到 model.fit 中。应该没问题吧。
如何将此模型更改为只有 2 个类（非屏蔽和屏蔽）？
base_model: keras.Model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)

# 使用这些层的激活
图层名称 = [
    &#39;block_1_expand_relu&#39;, # 64x64
    &#39;block_3_expand_relu&#39;, # 32x32
    &#39;block_6_expand_relu&#39;, # 16x16
    &#39;block_13_expand_relu&#39;, # 8x8
    &#39;block_16_project&#39;, # 4x4
]
base_model_outputs = [base_model.get_layer(name).layer_names 中名称的输出]

# 创建特征提取模型
down_stack = 模型（输入=base_model.输入，输出=base_model_outputs）

down_stack.trainable = False

上层堆栈 = [
    pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8
    pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16
    pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32
    pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
  输入 = 层.Input(形状=[128, 128, 3])

  # 通过模型进行下采样
  跳过= down_stack（输入）
  x = 跳过[-1]
  跳过 = 反转(跳过[:-1])

  # 上采样并建立跳跃连接
  对于 up，在 zip 中跳过（up_stack，skips）：
    x = 上(x)
    concat = 层.Concatenate()
    x = concat([x, 跳过])

  # 这是模型的最后一层
  最后=层.Conv2DTranspose(
      过滤器=output_channels，kernel_size=3，步幅=2，
      padding=&#39;相同&#39;) #64x64 -&gt; 128x128

  x = 最后一个(x)

  返回模型（输入=输入，输出=x​​）

输出类 = 3

模型 = unet_model(output_channels=OUTPUT_CLASSES)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

当我将 OUTPUT_CLASSES 更改为 2 时，出现错误：
W tensorflow/core/kernels/data/generator_dataset_op.cc:108] 完成 GeneratorDataset 迭代器时发生错误：FAILED_PRECONDITION：Python 解释器状态未初始化。该过程可以被终止。

当OUTPUT_CLASSES为1时，预测掩码为空。
也许还必须改变其他东西？我还不熟悉神经网络架构，所以我可能看不到明显的东西。
编辑：
我已将activation=&#39;sigmoid&#39;添加到输出层
 最后 = tf.keras.layers.Conv2DTranspose(
      过滤器=output_channels，kernel_size=3，步幅=2，
      填充 = &#39;相同&#39;, 激活 = &#39;sigmoid&#39;) #64x64 -&gt; 128x128

  x = 最后一个(x)

和OUTPUT_CLASSES = 1
奇怪的行为是下一个：
预期的掩模是当我在一个非常小的数据集上训练它时（该数据集中包含的测试的图片和掩模，只是为了测试它如何检测所看到的图像），我在第一个时期得到了一些东西。但纪元越多，结果越差。然而，准确度约为 0.99。
预期掩码：

预测掩码纪元 0：

如果打开图像，您可能会在预期的遮罩部分看到轻微的阴影。
预测掩码纪元1：

...
纪元 4：

所以每次迭代都会变得更糟。
数据集包含不应显示任何蒙版的图像。也许这就是问题所在？ （编辑：从数据集中排除没有掩码的数据 - 没有帮助）
编辑2：
x = tf.keras.layers.BatchNormalization()(x)

有帮助，虽然不完美，但是有所帮助]]></description>
      <guid>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</guid>
      <pubDate>Sun, 10 Dec 2023 13:55:04 GMT</pubDate>
    </item>
    <item>
      <title>与最相似的词混淆？</title>
      <link>https://stackoverflow.com/questions/77600726/confusing-with-most-similar-word</link>
      <description><![CDATA[我正在研究来自 nlp.stanford.edu/projects/glove (glove.6B.50d.txt) 预训练向量的类比（著名的“国王 - 女人 + 男人 = 女王”） ），但我得到了令人困惑的结果：
类比（感谢@gojomo）
与“king”最相似的词是是“王”吗？？
第二个相似度是“queen”（正如我所料：）但为什么只有 86%？我预计〜90-95%，这只是数学（欧几里得距离），对吗？
也许，相似性取决于维数（与 100/200 维的“queen”更相似）？？
非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77600726/confusing-with-most-similar-word</guid>
      <pubDate>Mon, 04 Dec 2023 15:39:42 GMT</pubDate>
    </item>
    <item>
      <title>使用语言模型从文本中提取名称和相关标签</title>
      <link>https://stackoverflow.com/questions/77438653/extracting-names-and-associated-labels-from-text-with-language-model</link>
      <description><![CDATA[我正在尝试从有关微藻的科学文献中提取信息，我需要能够扫描文本中的各种名称并找到其相应的类别。
举个简单的例子，假设我有 3 个名字（Peter、John、Linda），我想从这个头衔列表中找到他们的职位（木匠、渔夫、忍者），文本如下：
“彼得住在他自己建造的房子里，他是一位伟大的木匠。琳达在不忙于经营自己的生意时喜欢跑马拉松。约翰 40 岁，靠捕鱼为生”
我想要这样的回复（彼得 = 木匠，约翰 = 渔夫，琳达 = NA）。
目前我正在尝试 bert，但只能找到一种从文本中提取单个标签的方法，而且我无法找到一种方法将其与相关人员联系起来。
有人对如何解决这个问题有建议吗？
（更新）更具体的示例是使用以下文本：
“微绿藻属 gaditana 属于微绿藻属，包括六个已知物种，所有物种都是单细胞动物。与这些物种不同，节旋藻属中的所有物种都是丝状的，例如钝顶节旋藻。”
在这里我需要提取：Nannocholpsis gaditana = 单细胞，Arthrospiraplatensis = 丝状。]]></description>
      <guid>https://stackoverflow.com/questions/77438653/extracting-names-and-associated-labels-from-text-with-language-model</guid>
      <pubDate>Tue, 07 Nov 2023 13:34:55 GMT</pubDate>
    </item>
    <item>
      <title>使用“ pip install catboost ”时出错：catboost 构建轮失败</title>
      <link>https://stackoverflow.com/questions/77133321/error-while-using-pip-install-catboost-failed-building-wheel-for-catboost</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77133321/error-while-using-pip-install-catboost-failed-building-wheel-for-catboost</guid>
      <pubDate>Tue, 19 Sep 2023 09:28:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 和 numpy 进行梯度下降</title>
      <link>https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy</link>
      <description><![CDATA[def 梯度(X_norm,y,theta,alpha,m,n,num_it):
    temp=np.array(np.zeros_like(theta,float))
    对于范围内的 i(0,num_it)：
        h=np.dot(X_norm,theta)
        #temp[j]=theta[j]-(alpha/m)*( np.sum( (h-y)*X_norm[:,j][np.newaxis,:] ) )
        temp[0]=theta[0]-(alpha/m)*(np.sum(h-y))
        temp[1]=theta[1]-(alpha/m)*(np.sum((h-y)*X_norm[:,1]))
        θ=温度
    返回θ



X_norm,平均值,std=featureScale(X)
#X 的长度（行数）
m=len(X)
X_norm=np.array([np.ones(m),X_norm])
n,m=np.shape(X_norm)
数量=1500
阿尔法=0.01
theta=np.zeros(n,float)[:,np.newaxis]
X_norm=X_norm.transpose()
θ=梯度(X_norm,y,θ,alpha,m,n,num_it)
打印θ

上面代码中我的 theta 是 100.2 100.2，但在 matlab 中应该是 100.2 61.09，这是正确的。]]></description>
      <guid>https://stackoverflow.com/questions/17784587/gradient-descent-using-python-and-numpy</guid>
      <pubDate>Mon, 22 Jul 2013 09:55:30 GMT</pubDate>
    </item>
    </channel>
</rss>