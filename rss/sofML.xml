<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 13 Apr 2024 09:11:23 GMT</lastBuildDate>
    <item>
      <title>错误：尝试量化模型时，“tf.TensorListSetItem”操作既不是自定义操作也不是弹性操作</title>
      <link>https://stackoverflow.com/questions/78319798/error-tf-tensorlistsetitem-op-is-neither-a-custom-op-nor-a-flex-op-while-tryi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78319798/error-tf-tensorlistsetitem-op-is-neither-a-custom-op-nor-a-flex-op-while-tryi</guid>
      <pubDate>Sat, 13 Apr 2024 07:02:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练 nn 的准确率没有提高并且损失值如此之高？</title>
      <link>https://stackoverflow.com/questions/78319532/why-when-train-nn-accuracy-doesnt-improve-and-loss-value-is-so-high</link>
      <description><![CDATA[我正在尝试根据 Kaggle 的数据集使用 TensorFlow 创建一个简单的神经网络来查找债务余额；然而，我尝试的每种方法都会导致相同的结果 = 疯狂的损失（有时甚至是负数）和固定的低准确度。
# 将日期分配给 X 和 y
X = pd.read_csv(&#39;Train_Features.csv&#39;)
y = pd.read_csv(&#39;Train_Output.csv&#39;)

# 删除索引
X = X.drop(&#39;索引&#39;, 轴= 1)
y = y.drop(&#39;索引&#39;, 轴= 1)

# 将 Yes 和 No 转换为整数的时间

# 带有“是”/“否”的列列表
columns_to_convert = [&#39;自己的&#39;、&#39;学生&#39;、&#39;已婚&#39;]

# 转换“是”和“否”
X[columns_to_convert] = X[columns_to_convert].map(lambda x: 1 if x == &#39;Yes&#39; else 0)

features_num = [&#39;收入&#39;, &#39;限额&#39;, &#39;评级&#39;, &#39;卡&#39;, &#39;年龄&#39;, &#39;教育&#39;, &#39;拥有&#39;, &#39;学生&#39;, &#39;已婚&#39;]
features_cat = [&#39;区域&#39;]

# 特征的预处理器设置
预处理器 = make_column_transformer(
    (MinMaxScaler(), features_num), # 最小-最大缩放到数字特征
    （OneHotEncoder（），features_cat），
）

# 分割数据
X_train, X_valid, y_train, y_valid = train_test_split(X, y,random_state=42)

# 处理特征
X_train = 预处理器.fit_transform(X_train)
X_valid = 预处理器.transform(X_valid)

# 使用最小-最大缩放来缩放 y(Balance)
y_scaler = MinMaxScaler()
y_train = y_scaler.fit_transform(y_train)
y_valid = y_scaler.transform(y_valid)

输入 = [X_train.shape[1]]

# 构建模型架构
模型 = keras.Sequential([
    层.BatchNormalization(input_shape=input),
    层.Dense(256, 激活=&#39;relu&#39;),
    层.BatchNormalization(),
    层.Dense(256, 激活=&#39;relu&#39;),
    层.BatchNormalization(),
    层.密集(1),
]）

# 编译模型
模型.编译(
    优化器=&#39;亚当&#39;,
    损失=&#39;mse&#39;,
    指标=[&#39;准确性&#39;],
）

# 提前停止以防止过度拟合
Early_stopping = keras.callbacks.EarlyStopping(
    耐心=8，
    最小增量=0.001，
    Restore_best_weights=真，
）

# 训练模型
历史=模型.fit(
    X_列车，y_列车，
    验证数据=（X_有效，y_有效），
    批量大小=512，
    纪元=100，
    回调=[early_stopping],
）

# 将历史记录转换为 DataFrame 以进行绘图
History_df = pd.DataFrame(history.history)
History_df.loc[:, [&#39;loss&#39;, &#39;val_loss&#39;]].plot(title=“交叉熵”)
History_df.loc[:, [&#39;准确度&#39;, &#39;val_accuracy&#39;]].plot(title=&quot;准确度&quot;)

编辑：我找出了导致高损失值的原因。事实证明，这是由于一些诸如“平衡”之类的价值观造成的。太高了，并且模型不是使用归一化集，而是使用梯度，这不好。然而，准确性问题仍然存在
数据展望




]]></description>
      <guid>https://stackoverflow.com/questions/78319532/why-when-train-nn-accuracy-doesnt-improve-and-loss-value-is-so-high</guid>
      <pubDate>Sat, 13 Apr 2024 04:33:34 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在随机森林的核心中使用 adaBoosting 而不是 bootstrap？</title>
      <link>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</link>
      <description><![CDATA[随机森林使用 Bagging（Bootstrapping）为其每棵树选择样本，对吗？是否可以使用 adaBoosting 代替？有什么优点和优点？缺点？为什么我没看到这个？
我看到 Sci-kit learn 中的 RandomForestClassifier 允许启用/禁用引导程序，否则没有选项可以用 boosting 替换它。]]></description>
      <guid>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</guid>
      <pubDate>Sat, 13 Apr 2024 04:19:58 GMT</pubDate>
    </item>
    <item>
      <title>拟合投票回归器中权重的估计器预测[关闭]</title>
      <link>https://stackoverflow.com/questions/78318639/fitting-estimator-predictions-for-weights-in-the-voting-regressor</link>
      <description><![CDATA[投票回归器所做的似乎就是取平均值，除非您手动输入一些权重，但这看起来并不有效。对 x 和 y 中的所有预测进行线性拟合是否有意义以及它会是什么样子。我假设有一些限制的一阶线性拟合。
我尝试为其编写一些代码，这不是一项艰巨的任务，但我更好奇第二次拟合的统计实现，因为它感觉不“真实”。]]></description>
      <guid>https://stackoverflow.com/questions/78318639/fitting-estimator-predictions-for-weights-in-the-voting-regressor</guid>
      <pubDate>Fri, 12 Apr 2024 20:45:00 GMT</pubDate>
    </item>
    <item>
      <title>在用于大数据分析的 PySpark 中，面临使用哈希转换字符串特征的问题。有什么解决办法吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78317805/in-pyspark-for-big-data-analytics-facing-issues-converting-string-features-usin</link>
      <description><![CDATA[我是大数据分析新手，目前正在使用 PySpark 处理大数据机器学习任务，特别是信用卡欺诈检测。然而，我遇到了障碍。在我的数据集中，我有两个字符串特征，需要在构建模型之前将其转换为数值。我尝试过各种方法，例如one-hot编码和散列，但没有成功。下面，我提供我最近遇到的错误。您能否建议如何解决这个问题，或者是否有更好的方法来解决这个问题？如果需要，请随时询问任何其他信息，例如代码片段或其他信息。


大多数时候我都会面临这个错误和缓冲区溢出！

如果有人可以帮助我解决这种情况，请告诉我。几天来我尝试了不同的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78317805/in-pyspark-for-big-data-analytics-facing-issues-converting-string-features-usin</guid>
      <pubDate>Fri, 12 Apr 2024 17:09:42 GMT</pubDate>
    </item>
    <item>
      <title>如何修改我的代码，以便它可以使用网络摄像头正确预测</title>
      <link>https://stackoverflow.com/questions/78317359/how-to-modify-my-code-so-it-can-correctly-predict-using-the-webcam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78317359/how-to-modify-my-code-so-it-can-correctly-predict-using-the-webcam</guid>
      <pubDate>Fri, 12 Apr 2024 15:39:17 GMT</pubDate>
    </item>
    <item>
      <title>一些训练记录，以及训练后的一份记录 [关闭]</title>
      <link>https://stackoverflow.com/questions/78316879/a-few-records-for-training-and-one-record-after-training</link>
      <description><![CDATA[我尝试做一些信用评分任务。我陷入了概念问题。
有：
train_data（62 列、10339239 行、1250000 个唯一 ID 值 [0 - 1249999]（[最小-最大] ID 值） ),
test_data（62 列、4724601 行、500000 个唯一 ID 值 [3000000 - 3499999]（[最小-最大] ID 值） ),
train_target.csv（2列：ID和flag（flag是目标变量，必须预测)，有 361870 行，全部具有唯一的 ID，[0 - 361869]([min-max] ID 值)) ,
test_target.csv（1 列：ID，500000 行，所有 ID 都是唯一的，[3000000 - 3499999]([min- max] ID 值)) 。
需要为 test_target.csv 获取 [0,1] 范围内的分数。
train_data 和 test_data 有 62 列，ID、RN，...。两者都是对应的时间（如果日期时间较大，则 RN 的 ID 值会更大）。 ID表示信用/贷款请求，RN表示信用记录中的信用/贷款数量。 train_target.csv 中的 FLAG 表示：1-默认/破产。
我不知道如何针对这些数据训练模型。我尝试使用XGBoost。训练后的模型必须采用具有相同 ID 的 RN 排序的几条记录，并给出 [0, 1] 范围内的一个 FLAG 答案。如何才能做到这一点？ XGB分类器？或回归器？通过train_test_split还是TimeSeriesSplit？请问您能给我建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78316879/a-few-records-for-training-and-one-record-after-training</guid>
      <pubDate>Fri, 12 Apr 2024 14:19:39 GMT</pubDate>
    </item>
    <item>
      <title>重新称重预处理技术与 AdaBoost 的结合</title>
      <link>https://stackoverflow.com/questions/78316838/combination-of-reweighing-as-pre-processing-technique-and-adaboost</link>
      <description><![CDATA[我使用了预处理技术“重新称重”来消除数据集的偏差。该技术为我提供了一个列，其中包含每个实例的权重。对于重新称重，我使用了 AIF 360。
对于模型，我想使用 sklearn 的 AdaBoost 分类器。
将 .fit() 方法中的预处理技术的权重移交给 AdaBoost 分类器是否有意义？该参数为sample_weight。
有点不清楚我是否应该使用 class_weight 还是sample_weight。
我已经研究了应该使用什么参数，或者将权重交给 AdaBoost 是否有意义。然而，我觉得这项研究让我更加不清楚了。我知道 sklearn 的 AdaBoost 分类器没有 class_weight 参数。但如果将权重交给 AdaBoost 有意义的话，也许专家可以帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78316838/combination-of-reweighing-as-pre-processing-technique-and-adaboost</guid>
      <pubDate>Fri, 12 Apr 2024 14:11:12 GMT</pubDate>
    </item>
    <item>
      <title>这是对不平衡数据集进行过采样交叉验证的正确方法吗？</title>
      <link>https://stackoverflow.com/questions/78316022/is-this-the-right-way-to-do-cross-validation-with-oversampling-on-imbalance-data</link>
      <description><![CDATA[def stratified_cross_validation_metrics(模型, X, y, method=&#39;&#39;):
    指标={
        &#39;准确性&#39;： []，
        &#39;精确&#39;： []，
        &#39;记起&#39;： []，
        &#39;f1_score&#39;：[]
    }
    
    kf = StratifiedKFold(n_splits=10, shuffle=False)
    
    对于 kf.split(X, y) 中的 train_index、test_index：
        X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]
        y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]
        
        if method.lower() == &#39;adasyn&#39;:
            X_train_cv, y_train_cv = adasyn.fit_resample(X_train_cv, y_train_cv)
            X_test_cv, y_test_cv = adasyn.fit_resample(X_test_cv, y_test_cv)
        elif method.lower() == &#39;smote&#39;:
            X_train_cv, y_train_cv = smote.fit_resample(X_train_cv, y_train_cv)
            X_test_cv, y_test_cv = smote.fit_resample(X_test_cv, y_test_cv)
        
        model.fit(X_train_cv, y_train_cv)

        y_pred_cv = model.predict(X_test_cv)

        准确度=准确度_分数（y_test_cv，y_pred_cv）
        精度 = precision_score(y_test_cv, y_pred_cv, 平均值=&#39;加权&#39;)
        召回率=召回率（y_test_cv，y_pred_cv，平均值=&#39;加权&#39;）
        f1 = f1_score(y_test_cv, y_pred_cv, 平均值=&#39;加权&#39;)

        指标[&#39;准确度&#39;].append(准确度)
        指标[&#39;精度&#39;].append(精度)
        指标[&#39;recall&#39;].append(recall)
        指标[&#39;f1_score&#39;].append(f1)

    print(&quot;10 倍分层交叉验证的平均指标：&quot;)
    print(&quot;准确率：&quot;, np.mean(metrics[&#39;accuracy&#39;]))
    print(&quot;精度：&quot;, np.mean(metrics[&#39;精度&#39;]))
    print(&quot;召回率：&quot;, np.mean(metrics[&#39;recall&#39;]))
    print(&quot;F1 分数：&quot;, np.mean(metrics[&#39;f1_score&#39;]))

    df = pd.DataFrame(指标)
    
    返回df

我读到，当你使用过采样方法进行交叉验证时，你不应该首先过采样，这样它就不会泄漏到测试数据，所以我按照所示的方式执行函数，这是正确的方法还是我做错了什么？
对于不平衡数据集使用什么指标平均值比较好？]]></description>
      <guid>https://stackoverflow.com/questions/78316022/is-this-the-right-way-to-do-cross-validation-with-oversampling-on-imbalance-data</guid>
      <pubDate>Fri, 12 Apr 2024 11:37:37 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：操作数无法与形状一起广播 (10,1024) (1024,1) [关闭]</title>
      <link>https://stackoverflow.com/questions/78316002/valueerror-operands-could-not-be-broadcast-together-with-shapes-10-1024-1024</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78316002/valueerror-operands-could-not-be-broadcast-together-with-shapes-10-1024-1024</guid>
      <pubDate>Fri, 12 Apr 2024 11:33:12 GMT</pubDate>
    </item>
    <item>
      <title>根据之前的元素，甚至不基于之前的元素，使用 LSTM 预测下一个元素</title>
      <link>https://stackoverflow.com/questions/78315830/predicting-next-elements-with-an-lstm-based-on-previous-ones-or-even-based-on</link>
      <description><![CDATA[我有一个时间序列问题，其中包括使用 LSTM 预测价格。该数据集是从 Python 库 yfinance 导入的。我在内置的极客教程中使用了示例代码Pytorch，并设法理解一切。我认为我不明白的唯一具体部分可以在这段代码片段中看到：
# 定义要预测的未来时间步数
预测步数 = 30

# 转换为 NumPy 并删除单一维度
sequence_to_plot = X_test.squeeze().cpu().numpy()

# 使用最后 30 个数据点作为起点
历史数据=序列到图[-1]
打印（历史数据.形状）

# 初始化一个列表来存储预测值
预测值 = []

# 使用训练好的模型来预测未来值
使用 torch.no_grad()：
    对于 _ 在范围内（num_forecast_steps*2）：
        # 准备历史数据张量
        历史数据张量 = torch.as_tensor(历史数据).view(1, -1, 1).float().to(设备)
        # 使用模型预测下一个值
        预测值 = 模型(历史数据张量).cpu().numpy()[0, 0]

        # 将预测值添加到forecasted_values列表中
        Forecasted_values.append(predicted_value[0])

        # 通过删除最旧的值并添加预测值来更新历史数据序列
        历史数据 = np.roll(历史数据, 移位=-1)
        历史数据[-1] = 预测值

        
# 生成未来日期
最后日期 = test_data.index[-1]

# 生成接下来的 30 个日期
future_dates = pd.date_range(start=last_date + pd.DateOffset(1), period=30)

# 将原始索引与未来日期连接起来
组合索引 = test_data.index.append(future_dates)

根据教程内容，使用滚动预测。这意味着，如果我是对的，带有输入元素的数组将用作预测下一个元素的窗口，该窗口将附加到窗口，以预测下一个元素，依此类推。我的问题可能与概念或代码的其他部分有关，但我不太理解这行代码：
# 将预测值追加到 Forecasted_values 列表中
Forecasted_values.append(predicted_value[0])

如果我想根据之前的 30 个元素来预测下一个元素，为什么我应该采用预测数组的第一个预测元素？ （对我来说，这意味着前 30 个输入序列的第二个元素）。如果我需要基于动态生成的值构建一个序列窗口，并且之前没有先前的元素，我该如何修改此示例？]]></description>
      <guid>https://stackoverflow.com/questions/78315830/predicting-next-elements-with-an-lstm-based-on-previous-ones-or-even-based-on</guid>
      <pubDate>Fri, 12 Apr 2024 11:01:41 GMT</pubDate>
    </item>
    <item>
      <title>Numpy reshape() 以编程方式以 3D 方式显示 2D 数组</title>
      <link>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</link>
      <description><![CDATA[示例数据
我有一系列经纬度的天气数据，其形状如下：(1038240,4)（有关示例数据，请参阅照片）
我想将其重塑为形状 (4,721,1440)，这将是 721 x 1440 地球图像上的四个天气变量（&amp; lat/lon）。
我已经尝试过：
newarr = t_new.reshape(4,721,1440)

这会将其置于正确的形状，但与前两个纬度/经度坐标与以下首选格式不匹配：
对于上图中的 (6,4) 示例数据，此操作看起来像下面的 (2,3,2) 数组：
所需输出示例
newarr = t_new.reshape(4,721,1440)
]]></description>
      <guid>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</guid>
      <pubDate>Thu, 11 Apr 2024 06:06:56 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow federated 中工作时遇到“学习属性”错误</title>
      <link>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</guid>
      <pubDate>Thu, 14 Mar 2024 05:35:24 GMT</pubDate>
    </item>
    <item>
      <title>Adam 优化器在 PyTorch 上进行预热</title>
      <link>https://stackoverflow.com/questions/65343377/adam-optimizer-with-warmup-on-pytorch</link>
      <description><![CDATA[在论文Attention is all you need中，在在5.3节中，作者建议线性增加学习率，然后与步长的平方根倒数成比例地减少。

我们如何使用 Adam 优化器在 PyTorch 中实现这一点？最好没有额外的软件包。]]></description>
      <guid>https://stackoverflow.com/questions/65343377/adam-optimizer-with-warmup-on-pytorch</guid>
      <pubDate>Thu, 17 Dec 2020 15:12:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使用变分推理来拟合分布</title>
      <link>https://stackoverflow.com/questions/59276428/how-to-use-variational-inference-to-fit-a-distribution</link>
      <description><![CDATA[假设我有 gamma=10 的泊松分布。我想拟合一个高斯分布，它可以最小化泊松分布的 KL 散度。这可以通过变分推理来实现。我如何使用 Stan 进行此优化？
参考手册有一个关于 VI 的章节，但仅提供了有关如何在内部实现的一些高级信息，而不是如何使用它。
用户指南在章节中提到了 VI 22.2，但仅对其效率进行了一些一般性评论。
关于 SO 的相关问题可能是：PyStan API 中的变分推理？ 
但这只是询问 advi 是否已在 PyStan 中实现（它已经实现）。没有其他信息。]]></description>
      <guid>https://stackoverflow.com/questions/59276428/how-to-use-variational-inference-to-fit-a-distribution</guid>
      <pubDate>Tue, 10 Dec 2019 22:43:29 GMT</pubDate>
    </item>
    </channel>
</rss>