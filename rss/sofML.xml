<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 27 Jan 2024 15:11:52 GMT</lastBuildDate>
    <item>
      <title>为什么随机森林无法预测模型中的高值（稀有值）？</title>
      <link>https://stackoverflow.com/questions/77891522/why-the-random-forest-can-not-predict-the-high-values-rare-values-in-my-model</link>
      <description><![CDATA[我最近开始使用随机森林，并且遇到了一个问题：模型无法预测大部分数据的值。相反，尽管模型没有表现出过度拟合的迹象，但预测值似乎保持不变。任何见解或建议将不胜感激。
在此处输入图像描述
我希望模型也能够预测稀有数据？]]></description>
      <guid>https://stackoverflow.com/questions/77891522/why-the-random-forest-can-not-predict-the-high-values-rare-values-in-my-model</guid>
      <pubDate>Sat, 27 Jan 2024 14:24:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 sympy 时消除格式字符串冲突</title>
      <link>https://stackoverflow.com/questions/77891386/get-rid-of-format-string-conflict-when-using-sympy</link>
      <description><![CDATA[我正在学习用于机器学习的 Python 编码。当我尝试使用 sympy 求损失函数的导数时，它会与格式字符串发生冲突。
将 numpy 导入为 np
将 sympy 导入为 sp

def 预测（X，w，b）：
    返回 np.dot(X, w) + b

def 损失(X, w, b, Y):
    返回 np.mean((预测(X, w, b) - Y) ** 2)

X, Y = np.loadtxt(“code/02_first/pizza.txt”，unpack=True，skiprows=1)

# 将 X 和 Y 转换为 sympy 符号
X, w, b, Y = sp.symbols(“X w b Y”)

def 梯度(X, w, b, Y):
    loss_expr = 损失(X, w, b, Y)
    dw_dX = sp.diff(loss_expr, w)
    db_dX = sp.diff(loss_expr, b)
    返回 dw_dX, db_dX

def train(X, Y, 迭代, lr):
    w = sp.symbols(&#39;w&#39;)
    b = sp.symbols(&#39;b&#39;)
    
    对于范围内的 i（迭代）：
        损失值 = 损失(X, w, b, Y)
        print(f&quot;迭代: {i:4d}, 损失: {loss_value:.10f}&quot;)
        dw_dX, db_dX = 梯度(X, w, b, Y)
        w -= dw_dX * lr
        b -= db_dX * lr
    返回w,b

w, b = 训练(X, Y, 迭代=20000, lr=0.001)

print(f&quot;\nw = {w:.10f}, b = {b:.10f}&quot;)
print(f&quot;预测: x = 20 ==&gt; y = {predict(20, w, b):.2f}&quot;)

类型错误：传递给 Pow.__format__ 的格式字符串不受支持

我可以只使用numpy，但这样做我需要自己计算损失函数，这不是有效的（并且很容易用括号引发错误）。
如果您能解释该错误以及为什么 sympy 与格式字符串不兼容，我们将不胜感激。另外，如何使用 sympy 生成正确的脚本？
提前非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77891386/get-rid-of-format-string-conflict-when-using-sympy</guid>
      <pubDate>Sat, 27 Jan 2024 13:35:43 GMT</pubDate>
    </item>
    <item>
      <title>如何将对象检测数据集转换为 Tensorflow 数据集</title>
      <link>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</link>
      <description><![CDATA[我正在尝试使用 keras 在张量流上建立一个对象检测模型，但我一直遇到困难。我自动执行了查找训练图像的边界框的任务（训练数据集是游戏的），然后将所有内容转储到包含与其相关的所有数据的 .csv 文件中：对象出现的帧、边界框的坐标、和对象的类。即使同一帧上出现多个边界框，每个边界框在数据集上都有不同的行。
我正在尝试使用此函数将我的数据集导入 Tensorflow：
def Data_Loader(annotation_file):
    数据=pd.read_csv（注释文件）
    data_groups=data.groupby(&#39;文件名&#39;)

    数据集={&#39;images&#39;:[],&#39;bounding_boxes&#39;:[]}
    ngroups=data_groups.ngroups

    对于 image_name，data_groups 中的组：

        BBoxes={&#39;类&#39;:[],&#39;盒子&#39;:[]}
        对于 _，group.iterrows() 中的行：
            BBoxes[&#39;boxes&#39;].append(Get_BBOX(行))
            BBoxes[&#39;classes&#39;].append(class_ids.index(row[&#39;class&#39;]))

       
        数据集[&#39;bounding_boxes&#39;].append(tf.data.Dataset.from_tensor_slices(BBoxes))
        图像=load_img(图像名称,(224, 224))
        数据集[&#39;images&#39;].append(tf.constant(image))
 

    数据集=tf.data.Dataset.from_tensor_slices(数据集)

    返回（数据集）


以下是边界框的加载方式：
def Get_BBOX(行):
    xmin=int(行[&#39;xmin&#39;])
    ymin=int(行[&#39;ymin&#39;])
    xmax=int(行[&#39;xmax&#39;])
    ymax=int(行[&#39;ymax&#39;])

    bbox=np.array([xmin, ymin, xmax, ymax])

    返回bbox


图像加载如下：
def load_img(文件名, target_size):
    img = tf.keras.utils.load_img(文件名, target_size=target_size)
    img = tf.keras.utils.img_to_array(img)

    返回（图片）


我正在使用 Keras 的本教程来指导自己
但是每当我到达教程中将地图应用于数据的部分时，我都会收到以下错误消息：
“_VariantDataset”对象不可下标

有人知道我可能做错了什么以及如何解决它吗？
我多次尝试进行多次类型转换，从包含列表的字典更改为字典列表和所有其他类型的内容。这些都没有产生任何结果。]]></description>
      <guid>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</guid>
      <pubDate>Sat, 27 Jan 2024 12:55:36 GMT</pubDate>
    </item>
    <item>
      <title>对 MLH 奖学金代码示例有什么建议吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77890706/any-suggestions-for-mlh-fellowship-code-sample</link>
      <description><![CDATA[我计划今年申请 MLH 奖学金，我想展示一个强大的代码示例来展示我的全栈开发技能。我正在考虑的项目是任务管理器 Web 应用程序。该应用程序将包括用户身份验证、任务创建/编辑/删除、数据库集成、响应式用户界面和部署等功能。
我希望获得有关如何有效实施该项目的建议，以及能够给评选委员会留下深刻印象的任何具体技术或框架。此外，我们将非常感谢有关确保代码质量、安全实践以及任何可以使我的项目脱颖而出的额外功能的指导。
我的目标不仅仅是满足奖学金的要求，而是提供一个全面且精心制作的代码示例，反映我作为全栈开发人员的能力。经历过类似申请流程的经验丰富的开发人员提供的任何见解、技巧或建议都会非常有帮助。
提前感谢您的指导！]]></description>
      <guid>https://stackoverflow.com/questions/77890706/any-suggestions-for-mlh-fellowship-code-sample</guid>
      <pubDate>Sat, 27 Jan 2024 09:45:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么 DecisionTreeClassifier 会按照指定的标准错误地分割数据？</title>
      <link>https://stackoverflow.com/questions/77890508/why-decisiontreeclassifier-split-wrongly-the-data-with-the-specified-criterion</link>
      <description><![CDATA[在第一次使用 DecisionTreeClassifier 时，我们得到了样本数为 192 和 346 的两个子树，但是当我们使用文件 Counter 并在 Treeclassifier 决策中设置与分离相同的条件时，我们得到了样本数 171 和 367。这种差异的标志是什么？
DecisionTreeClassifier 代码块：
导入 pandas 作为 pd
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn 导入树
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
数据 = pd.read_csv(r“PCOS.csv”)
X = data.drop(“PCOS (Y/N)”, axis=1)
y = 数据[“PCOS (Y/N)”]
模型= DecisionTreeClassifier（max_深度= 2，标准=“基尼”）
模型.fit(X, y)

树.plot_tree(模型)
fn = 数据.列

标签 = [“0”,“1”]
图，轴 = plt.subplots()
tree.plot_tree(模型，feature_names=fn，class_names=label，filled=True)
Fig.savefig(&#39;imagenae.png&#39;)


计数器代码块：
导入 pandas 作为 pd


def 子树（数据，列）：
    第一个列表 = []
    秒列表 = []
    对于范围内的 i（len（数据））：
        如果数据[col][i] &lt;= 7.5：
            first_list.append(data.loc[i, :].values)
        别的：
            sec_l​​ist.append(data.loc[i, :].values)
    基尼系数（第一个列表）
    基尼系数（秒列表）


定义基尼系数（数据）：
    a, b= 0, 0
    对于数据中的 i：
        如果 i[-1] == 0:
            一个+= 1
        别的：
            b+=1
    print(&quot;标签 0 :&quot;, a)
    print(&quot;标签 1 :&quot;, b)


col = [&#39;皮肤变黑(Y/N)&#39;, &#39;毛发生长(Y/N)&#39;, &#39;体重增加(Y/N)&#39;, &#39;周期(R/I)&#39;, &#39;毛囊编号(R)&#39; ,
       &#39;快餐（Y/N）&#39;、&#39;卵泡编号（L）&#39;、&#39;PCOS（Y/N）&#39;]

数据 = pd.read_csv(“PCOS.csv”)[col]

X = data.drop(“PCOS (Y/N)”, axis=1)
y = 数据[[“PCOS（是/否）”]]

subtree(data, &#39;毛囊编号 (L)&#39;)

结果决策树分类器：
192 和 346
结果计数器：
171 和 367
数据库：
数据库
可视化决策树：
可视化决策树]]></description>
      <guid>https://stackoverflow.com/questions/77890508/why-decisiontreeclassifier-split-wrongly-the-data-with-the-specified-criterion</guid>
      <pubDate>Sat, 27 Jan 2024 08:24:18 GMT</pubDate>
    </item>
    <item>
      <title>两阶段推荐系统中的top-K推荐</title>
      <link>https://stackoverflow.com/questions/77890505/top-k-recommendations-in-two-stage-recommendation-system</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77890505/top-k-recommendations-in-two-stage-recommendation-system</guid>
      <pubDate>Sat, 27 Jan 2024 08:22:43 GMT</pubDate>
    </item>
    <item>
      <title>我尝试使用 (pip install pickle5) 安装 Python 的 pickle 包，但安装包失败</title>
      <link>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</link>
      <description><![CDATA[这是我尝试过的：
pip install pickle5

这是包含错误消息的快照。
这也是我得到的错误：
错误：无法为 pickle5 构建轮子，这是安装基于 pyproject.toml 的项目所必需的
我尝试按照其他一些帖子中的建议安装并重新安装 Microsoft Visual C++，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-and</guid>
      <pubDate>Sat, 27 Jan 2024 05:36:19 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：编译神经网络进行情感分析时，模块“keras.src.backend”没有属性“floatx”</title>
      <link>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</link>
      <description><![CDATA[从tensorflow.keras.models导入顺序
从tensorflow.keras导入层

# 设置嵌入维度
嵌入尺寸 = 100

# 创建模型
模型=顺序（[
    层.Embedding(max_words, embedding_dim, input_length=max_length),
    层.LSTM(64),
    层.Dense(1, 激活=&#39;sigmoid&#39;)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

# 打印模型摘要
打印（模型.摘要（））

我尝试使用 Jupyter Notebook (.ipynb) 在 VSCode 中编译上述模型，但遇到以下错误：
AttributeError：模块“keras.src.backend”没有属性“floatx”
最初，我成功地编译了模型，但在拟合模型时导致 VScode 崩溃。重新加载 VSCode 后，我收到此错误。
为了解释上下文，我正在尝试构建一个非常基本的 NLP 模型，以根据情绪对亚马逊评论进行分类。我也在使用 Python 3.11 和 Tensorflow 版本 2.15
首先我尝试了以下方法：
导入keras.backend为K
K.set_floatx(&#39;float32&#39;)

但是我遇到了同样的错误。然后我尝试重置 VSCode 并再次运行笔记本，但仍然遇到相同的错误？]]></description>
      <guid>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</guid>
      <pubDate>Sat, 27 Jan 2024 04:41:13 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 部署到 sagemaker</title>
      <link>https://stackoverflow.com/questions/77889951/pytorch-deployment-to-sagemaker</link>
      <description><![CDATA[我已压缩并保存到 s3，如下所示：
导入 tar 文件
使用 tarfile.open(&#39;model.tar.gz&#39;, mode=&#39;w:gz&#39;) 作为存档：
archive.add(&#39;Model&#39;, recursive=True)
导入Sagemaker
sagemaker_session = sagemaker.Session()
输入= sagemaker_session.upload_data(path=&#39;model.tar.gz&#39;, key_prefix=&#39;model&#39;)
尝试像这样部署：
从 sagemaker 导入 get_execution_role
从 sagemaker.pytorch.model 导入 PyTorchModel
角色 = get_execution_role()
pytorch_model = PyTorchModel(model_data= &#39;s3://&#39; + sagemaker_session.default_bucket() + &#39;/model/model.tar.gz&#39;, role=role,
Entry_point=&#39;inference.py&#39;,framework_version=&#39;2.1&#39;,py_version=&#39;py310&#39;)
预测器= pytorch_model.deploy（instance_type=&#39;ml.p3.2xlarge&#39;，initial_instance_count=1）
但我收到一个错误：
FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;inference.py&#39;
我尝试了上面解释的所有内容]]></description>
      <guid>https://stackoverflow.com/questions/77889951/pytorch-deployment-to-sagemaker</guid>
      <pubDate>Sat, 27 Jan 2024 03:20:13 GMT</pubDate>
    </item>
    <item>
      <title>安装斗争</title>
      <link>https://stackoverflow.com/questions/77889759/installation-struggle</link>
      <description><![CDATA[我们正在使用 Qiskit 工具包进行一个量子计算项目。但我们在导入或安装软件包和库时遇到了困难。在 Qiskit 中我们如何导入库和包？
澄清如何从外包安装库的疑问。]]></description>
      <guid>https://stackoverflow.com/questions/77889759/installation-struggle</guid>
      <pubDate>Sat, 27 Jan 2024 01:36:23 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 前向返回张量与标量</title>
      <link>https://stackoverflow.com/questions/77889711/pytorch-forward-return-tensor-versus-scalar</link>
      <description><![CDATA[假设我有一个具有以下前向函数的 Pytorch 模型：
defforward(self, input_tensors):
    ”“”
    所有变量的维度：
    - input_tensors：（头、批次、feature_dim）
    - self.w：（头，feature_dim，1）
    - self.b: (头, 1, 1)
    ”“”

    out = torch.bmm(input_tensor, self.w) + self.b # (头数, 批次, 1)
    out = out.transpose(0, 1).squeeze(2) # （批次，头）
    标签 = torch.ones([批次, 头]) # (批次, 头
    logloss = SOMELOSSFUNC(logits=logits, labels=labels) # 输出可以是 [heads] 维度的标量或张量

    返回对数损失

如果对数损失是标量，则模型会针对一个值进行优化。如果对数损失是 [heads] 维度的张量怎么办？这是否意味着我正在独立优化每个头的 w 和 b ？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77889711/pytorch-forward-return-tensor-versus-scalar</guid>
      <pubDate>Sat, 27 Jan 2024 01:18:12 GMT</pubDate>
    </item>
    <item>
      <title>(Keras) 尝试加载以数组形式保存的优化器权重，但不断遇到问题</title>
      <link>https://stackoverflow.com/questions/77889525/keras-trying-to-load-in-saved-optimizer-weights-that-are-in-the-form-of-an-arr</link>
      <description><![CDATA[我很久以前训练了一个模型，当时我无法使用任何内置的 keras 函数保存模型或优化器权重，因为它不断抛出错误，所以我将权重保存为数组。&lt; /p&gt;
现在我尝试再次加载它，但在加载优化器权重时我不断遇到错误。我 100% 确定我正确保存了权重，并且模型架构是正确的，因为我使用了
my_model.optimizer.get_weights()
保存权重（尽管该行代码现在不起作用，因为它说“&#39;Adam&#39;对象没有属性&#39;get_weights&#39;”），我基本上复制粘贴了模型架构。
所以首先，我尝试简单地加载优化器权重，就像使用
my_model.optimizer.set_weights(saved_optimizer_weights)
但我收到以下错误
“您正在对尚未构建的优化器调用“set_weights()”。请在调用“set_weights()”之前调用“optimizer.build(trainable_variables)”创建优化器权重。
我认为“trainable_variables”指的是my_model.trainable_variables，所以我跑了
my_model.optimizer.build(my_model.trainable_variables)
并且成功了。但当我尝试时
my_model.optimizer.set_weights(saved_optimizer_weights)
我再次收到以下错误
“优化器变量 v/top_conv/kernel_25469 的形状 (1, 1, 352, 1408) 与提供的权重形状 (1408,) 不兼容。”
我不太确定从这里该去哪里。]]></description>
      <guid>https://stackoverflow.com/questions/77889525/keras-trying-to-load-in-saved-optimizer-weights-that-are-in-the-form-of-an-arr</guid>
      <pubDate>Fri, 26 Jan 2024 23:53:24 GMT</pubDate>
    </item>
    <item>
      <title>将从 keras YOLOV8Detector 获取的模型更新到 Apple MLPackage/CoreML</title>
      <link>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</link>
      <description><![CDATA[我按照 KerasCV 上的教程使用 YOLOV8 和 KerasCV 进行高效目标检测，并在 不同的数据集
一段时间后，我能够获得预测并将其可视化，如教程中所述：
&lt; /p&gt;
我想在苹果 iOS 应用程序中使用这个模型，所以我使用了 coremltools 包来转换它。然而，“输出”似乎是这样的。 kerascv 制作的产品并不完全是苹果界所期望的。
模型训练完成后，我可以要求进行预测：
 图像，y_true = next(iter(dataset.take(1)))
 y_pred = model.predict(images) // y_pred 是一个字典

y_pred 是包含这些键的字典 [&#39;boxes&#39;, &#39;confidence&#39;, &#39;classes&#39;, &#39;num_detections&#39;]
使用Netron，我可以看看苹果世界所期待的模型的形状
&lt;img alt=&quot; “ src =“https://github.com/keras-team/keras-cv/assets/170917/5fae9594-694a-477c-a7a2-3c4419e3b98a”/&gt;
如何修改/重塑从 kerascv 生成的模型，这样我就可以拥有一个将置信度和坐标答案作为两个单独的输出输出的模型，而不是输出字典？]]></description>
      <guid>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</guid>
      <pubDate>Fri, 26 Jan 2024 13:00:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么在小数据集上微调 MLP 模型，仍然保持与预训练权重相同的测试精度？</title>
      <link>https://stackoverflow.com/questions/77885918/why-finetuning-mlp-model-on-a-small-dataset-still-keeps-the-test-accuracy-same</link>
      <description><![CDATA[我设计了一个简单的 MLP 模型，在 6k 数据样本上进行训练。
类 MLP(nn.Module)：
    def __init__(自身,input_dim=92,hidden_​​dim=150,num_classes=2):
        超级().__init__()
        self.input_dim = input_dim
        self.num_classes = num_classes
        self.hidden_​​dim = 隐藏_dim
        #self.softmax = nn.Softmax(dim=1)

        self.layers = nn.Sequential(
            nn.Linear(self.input_dim, self.hidden_​​dim),
            ReLU(),
            nn.Linear(self.hidden_​​dim, self.hidden_​​dim),
            ReLU(),
            nn.Linear(self.hidden_​​dim, self.hidden_​​dim),
            ReLU(),
            nn.Linear(self.hidden_​​dim, self.num_classes),

        ）

    def 前向（自身，x）：
        x = self.layers(x)
        返回x

并且模型已实例化
model = MLP(input_dim=input_dim,hidden_​​dim=hidden_​​dim,num_classes=num_classes).to(设备)

优化器= Optimizer.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-4)
标准 = nn.CrossEntropyLoss()

和超参数：
num_epoch = 300 # 200e3//len(train_loader)
学习率 = 1e-3
批量大小 = 64
设备 = torch.device(“cuda”)
种子 = 42
火炬.manual_seed(42)

我的实现主要遵循这个问题。我将模型保存为预训练权重 model_weights.pth。
测试数据集上模型的准确率为96.80%。
然后，我还有另外 50 个样本（在 finetune_loader 中），我正在尝试在这 50 个样本上微调模型：
model_finetune = MLP()
model_finetune.load_state_dict(torch.load(&#39;model_weights.pth&#39;))
model_finetune.to（设备）
model_finetune.train()
# 训练网络
对于 t in tqdm(范围(num_epoch))：
  对于 i，enumerate(finetune_loader, 0) 中的数据：
    #def 闭包():
      # 获取并准备输入
      输入、目标 = 数据
      输入，目标=输入.float(), 目标.long()
      输入，目标 = 输入.to(设备), 目标.to(设备)
      
      # 将梯度归零
      优化器.zero_grad()
      # 执行前向传递
      输出 = model_finetune(输入)
      # 计算损失
      损失=标准（输出，目标）
      # 执行向后传递
      loss.backward()
      #回波损耗
      优化器.step() # a

model_finetune.eval()
使用 torch.no_grad()：
    输出2 = model_finetune(测试数据)
    #predicted_labels =outputs.squeeze().tolist()

    _, preds = torch.max(输出2, 1)
    Prediction_test = np.array(preds.cpu())
    准确度测试微调 = 准确度得分（y_测试，预测测试）
    精度测试微调
    
    输出：0.9680851063829787

我检查过，精度与将模型微调到 50 个样本之前保持不变，并且输出概率也相同。
可能是什么原因？我在微调代码中是否犯了一些错误？]]></description>
      <guid>https://stackoverflow.com/questions/77885918/why-finetuning-mlp-model-on-a-small-dataset-still-keeps-the-test-accuracy-same</guid>
      <pubDate>Fri, 26 Jan 2024 11:32:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pre-Train Bert 进行二元分类的 Shap 值：如何提取摘要图？</title>
      <link>https://stackoverflow.com/questions/77785423/shap-value-for-binary-classification-using-pre-train-bert-how-to-extract-summar</link>
      <description><![CDATA[我使用预训练 bert 模型进行二元分类。用小数据训练我的模型后，我想提取这样的摘要图 我想要的图&lt; /a&gt;.然而，我想用文字来代替这些重要的特征。
但是，我不确定一切都好，因为 shap_value 的形状只是二维的。其实，这是有道理的。尽管如此，我没有得到图表，因为如果我使用这段代码，我遇到了两个问题：
shap.summary_plot(shap_values[:,:10],feature_names=feature_importance[&#39;features&#39;].tolist(),features=comments_text)`

问题太不明智了：如果我用 shap_values 或 shap_values[0] 或  更改 shap_values[:,:10] shap_values.values vb.我总是遇到
516：断言 len(shap_values.shape) != 1，“汇总图需要一个矩阵
shap_values，而不是向量。” ==&gt; AssertionError：摘要图需要一个矩阵
shap_values，不是向量。

（拳头问题）
顺便说一句，我的 shap_value 由 10 个输入（shape_value.shape）组成。如果我选择范围从 1 到 147 的最大值，那么绘制图表就一切顺利。然而，此时，该图不合适：我的图仅由蓝点组成（-第二个问题-）。像这样只有蓝色。
注意：shap_values[:,:10]如果数字（10）改变不同的数字，图表显示不同的单词，但图表的总数相同（最多 20）。只有部分词序可以改变。
最小可重现示例：
&lt;前&gt;&lt;代码&gt;导入nlp
将 numpy 导入为 np
将 pandas 导入为 pd
将 scipy 导入为 sp
进口火炬
进口变压器
进口火炬
导入形状

# 加载 BERT 情感分析模型
tokenizer = Transformers.DistilBertTokenizerFast.from_pretrained(
    “distilbert-base-uncased”
）
模型 = Transformers.DistilBertForSequenceClassification.from_pretrained(
    “distilbert-base-uncased-finetuned-sst-2-english”
).cuda()


如果 torch.cuda.is_available():
    设备 = torch.device(“cuda”)
    print(&#39;我们将使用 GPU:&#39;, torch.cuda.get_device_name(0))

别的：
    print(&#39;没有可用的 GPU，请使用 CPU。&#39;)
    设备 = torch.device(“CPU”)

定义 f(x):
    # 对批量句子进行编码
    输入 = tokenizer.batch_encode_plus(x.tolist(), max_length=450,add_special_tokens=True, return_attention_mask=True,padding=&#39;max_length&#39;,truncation=True,return_tensors=&#39;pt&#39;)

    # 将张量发送到与模型相同的设备
    input_ids = 输入[&#39;input_ids&#39;].to(设备)
    注意掩码 = 输入[&#39;注意掩码&#39;].to(设备)
    ＃ 预测
    使用 torch.no_grad()：
        输出=模型（input_ids，attention_mask=attention_masks）[0].detach（）.cpu（）.numpy（）
    分数 = (np.exp(输出).T / np.exp(输出).sum(-1)).T
    val = sp.special.logit(scores[:, 1]) # 使用 1 与其余 logit 单位
    返回值
# 使用 token masker 构建一个解释器
解释器 = shap.Explainer(f, tokenizer )

imdb_train = nlp.load_dataset(“imdb”)[“火车”]
shap_values = 解释器(imdb_train[:10],fixed_context=1,batch_size=16)
队列 = {“”：shap_values}
team_labels = 列表(cohorts.keys())
team_exps = 列表(cohorts.values())
对于范围内的 i(len(cohort_exps))：
    如果 len(cohort_exps[i].shape) == 2:
        队列_exps[i] = 队列_exps[i].abs.mean(0)
特征=cohort_exps[0].data
特征名称=同类群组表达式[0].特征名称
#values = np.array([cohort_exps[i].values for i in range(len(cohort_exps))], dtype=object)
值 = np.array([cohort_exps[i].i 在范围内的值(len(cohort_exps))])
feature_importance = pd.DataFrame(list(zip(feature_names, sum(values))), columns=[&#39;features&#39;, &#39;importance&#39;])
feature_importance.sort_values(by=[&#39;重要性&#39;], 升序=False, inplace=True)
shap.summary_plot(shap_values[:,:10],feature_names=feature_importance[&#39;features&#39;].tolist(),features=imdb_train[&#39;text&#39;][10:20],show=False)


上面的代码产生相同的结果。我花了大约200台电脑，但没有成功:(。我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/77785423/shap-value-for-binary-classification-using-pre-train-bert-how-to-extract-summar</guid>
      <pubDate>Tue, 09 Jan 2024 08:49:10 GMT</pubDate>
    </item>
    </channel>
</rss>