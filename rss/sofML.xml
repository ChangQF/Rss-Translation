<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Jan 2024 06:19:20 GMT</lastBuildDate>
    <item>
      <title>数据帧和多变量标签的嵌套目录上的多视图谱聚类</title>
      <link>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</guid>
      <pubDate>Thu, 11 Jan 2024 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到<类'NoneType'></title>
      <link>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</link>
      <description><![CDATA[我正在尝试对我的数据运行深度学习代码；但是，由于输入数据中缺少数据集，我遇到了问题。作为一个新人，我不知道如何解决这个问题。我正在努力解决下面给出的这个错误，下面还提供了输入链接。
python3 Validation2co.py
BP_benchmarkSet_2.csv
BP seqmodel 启动
序列模块（
  (seq_CNN): 顺序(
    (0): Conv1d(100, 64, kernel_size=(16,), stride=(1,), padding=(8,))
    (1): ReLU(原地=True)
    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv1d(64, 32, kernel_size=(16,), stride=(1,), padding=(8,))
    (4): ReLU(inplace=True)
    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv1d(32, 16, kernel_size=(16,), stride=(1,), padding=(8,))
    (7): ReLU(原地=True)
    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  ）
  （seq_FClayer）：线性（in_features = 3008，out_features = 1024，偏差= True）
  （seq_outlayer）：线性（in_features = 1024，out_features = 491，偏差= True）
）
batch_size_32，learning_rate_0.0001，epoch_time_30
selected_208964_ Protein_score.csv
selected_208964_ Protein_score.csv
警告：iprID Q9HTQ2 数据丢失。跳过...
警告：iprID Q9I559 数据丢失。跳过...
警告：iprID Q9HT21 数据丢失。跳过...
警告：iprID Q9I0Q1 数据丢失。跳过...
警告：iprID Q9HVI7 数据丢失。跳过...
警告：iprID Q9I422 数据丢失。跳过...
警告：iprID Q9I2V9 数据丢失。跳过...
警告：iprID Q9HWB6 数据丢失。跳过...
警告：iprID Q9HVT7 数据丢失。跳过...
警告：iprID Q9I3I5 数据丢失。跳过...
警告：iprID Q9I4C1 数据丢失。跳过...
警告：iprID Q9I5K0 数据丢失。跳过...
警告：iprID P26995 数据丢失。跳过...
警告：iprID Q9I1Y7 数据丢失。跳过...
警告：iprID Q9I316 数据丢失。跳过...
警告：iprID Q9I299 数据丢失。跳过...
警告：iprID Q9I2Q4 数据丢失。跳过...
警告：iprID Q9HT20 数据丢失。跳过...
警告：iprID Q9HV34 数据丢失。跳过...
警告：iprID Q9HX99 数据丢失。跳过...
警告：iprID Q9HZK1 数据丢失。跳过...
警告：iprID Q9HXG5 数据丢失。跳过...
警告：iprID Q9I3F5 数据丢失。跳过...
警告：iprID Q9HV44 数据丢失。跳过...
警告：iprID Q9HY92 数据丢失。跳过...
警告：iprID Q9HVX9 数据丢失。跳过...
警告：iprID Q9I6Z3 数据丢失。跳过...
警告：iprID Q9HU16 数据丢失。跳过...
警告：iprID Q9HYL8 数据丢失。跳过...
警告：iprID Q9HI37 数据丢失。跳过...
警告：iprID Q9I1Y4 数据丢失。跳过...
警告：iprID Q9HW04 数据丢失。跳过...
回溯（最近一次调用最后一次）：
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 990 行，在  中。
    验证（条款[0], 5）
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 972 行，验证中
    每个_fold_scores = Main(train_set, test_set, func=func)
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 831 行，位于 Main 中
    seq_train_out, seq_test_out, seq_t = Seq_train(0.0001, 16, train_benchmark, test_benchmark, 30, func) # 15
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 408 行，Seq_train
    对于batch_idx，枚举（train_data_loader）中的（seqMatrix，domainStence，ppiVect，GO_annotiations）：
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 681 行，位于 __next__
    数据 = self._next_data()
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 721 行，位于 _next_data
    data = self._dataset_fetcher.fetch(index) # 可能会引发 StopIteration
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py​​”，第 52 行，在 fetch 中
    返回 self.collat​​e_fn(数据)
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/collat​​e.py”，第 183 行，在 default_collat​​e 中
    引发 TypeError(default_collat​​e_err_msg_format.format(elem_type))
**类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到**
]]></description>
      <guid>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</guid>
      <pubDate>Thu, 11 Jan 2024 04:55:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 AWS Sagemaker 向 50 名学生教授数据科学和机器学习？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77797651/how-to-use-aws-sagemaker-for-teaching-data-science-and-machine-learning-to-50-st</link>
      <description><![CDATA[我想为 50 名学生提供数据科学和机器学习方面的培训。我的客户不被允许使用任何 Google 产品，例如 Kaggle 或 Google Colab。因此，我计划使用 AWS，学生可以在 amazon sagemaker ipynb 中运行代码。
有没有什么方法可以让每个学生独立运行他们的笔记本并在 AWS 中进行他们想要的实验，并且我可以监控他们？
我有一个 AWS 组织账户。
我怎样才能做到这一点？
我尝试创建具有 50 个子用户的 IAM 用户，但在笔记本中进行更改后，它会自动反映在另一个子帐户中]]></description>
      <guid>https://stackoverflow.com/questions/77797651/how-to-use-aws-sagemaker-for-teaching-data-science-and-machine-learning-to-50-st</guid>
      <pubDate>Thu, 11 Jan 2024 04:17:42 GMT</pubDate>
    </item>
    <item>
      <title>回归任务中日志转换后的指标解释问题</title>
      <link>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</link>
      <description><![CDATA[我目前正在研究房价预测任务，由于目标变量（价格）的非正态分布，我对它进行了对数转换。我使用 RMSE、MAE 和 MAPE 等指标，并且对于模型训练，我使用了 cross_val_score。
获得预测后，我采用 MAE 和 MAPE 指标的指数将其恢复到原始规模。然而，我遇到了意想不到的小值；两个指标都等于 1。我怀疑这些值不正确。
kf = KFold(n_splits=5, random_state=42, shuffle=True)

def rmse_cv（模型）：
    mse_scorer = make_scorer(mean_squared_error)
    rmse = np.sqrt(cross_val_score(模型, 训练, y_train, 评分=mse_scorer, cv=kf))
    返回均方根误差

def mae_cv（模型）：
    mae_scorer = make_scorer(mean_absolute_error)
    mae = cross_val_score(模型, 训练, y_train, 评分=mae_scorer, cv=kf)
    返回梅

def mape_cv（模型）：
    mape_scorer = make_scorer(mean_absolute_percentage_error)
    mape = cross_val_score(模型, 训练, y_train, 评分=mape_scorer, cv=kf)
    返回马普

lightgbm = LGBMRegressor(num_leaves=6, max_depth=7, random_state=42, n_estimators=500, Objective=&#39;回归&#39;)

rmse = rmse_cv(lightgbm)
mae = mae_cv(lightgbm)
映射 = 映射_cv(lightgbm)
print(&#39;Lightgbm rmse %.4f&#39; % (rmse.mean()))
print(&#39;Lightgbm mae %.4f&#39; % (mae.mean()))
print(&#39;Lightgbm mape %.4f&#39; % (mape.mean()))

Lightgbm rmse 0.1331
Lightgbm mae 0.0874
Lightgbm 映射 0.0073

我希望获得合理且可解释的值，以反映模型在原始规模上的性能。然而，这两个指标都得出了意想不到的小值 1，这似乎不准确。我期望在原始价格范围内能够更有意义地表示模型误差。]]></description>
      <guid>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</guid>
      <pubDate>Thu, 11 Jan 2024 03:13:07 GMT</pubDate>
    </item>
    <item>
      <title>是否可以找到特定日期股票的平均值（Mathematica）？</title>
      <link>https://stackoverflow.com/questions/77797312/is-is-possible-to-find-the-average-value-of-a-stock-on-a-specific-date-mathemat</link>
      <description><![CDATA[我正在尝试使用 Mathematica 的机器学习工具创建一个模型，该模型使用股票的不同特征（包括 6 个月的价值变化）进行半准确的股市预测。我需要特定日期的值来计算 6 个月期间的百分比差异。
我尝试使用财务数据并将开始和结束设置为同一天，但它返回一个错误，指出它们不能相同。检查了文档，找不到其他方法来查找给定时间间隔内股票价值的变化。
如果 Mathematica 无法做到这一点，它是否可以与 R 或 MatLab 等替代编程语言一起使用？我偏爱 Mathematica，但总体来说我很灵活。]]></description>
      <guid>https://stackoverflow.com/questions/77797312/is-is-possible-to-find-the-average-value-of-a-stock-on-a-specific-date-mathemat</guid>
      <pubDate>Thu, 11 Jan 2024 02:10:59 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和语言处理[关闭]</title>
      <link>https://stackoverflow.com/questions/77796617/ai-and-language-processing</link>
      <description><![CDATA[在开发人工智能应用程序来分析和减轻社交媒体声明中的声誉风险的背景下，检测潜在攻击性或文化不敏感内容的最有效的自然语言处理技术是什么？
我在 Huggingface 等网站上研究过法学硕士。然而，这种方法似乎有点碰运气，大多数法学硕士都需要进一步的培训。]]></description>
      <guid>https://stackoverflow.com/questions/77796617/ai-and-language-processing</guid>
      <pubDate>Wed, 10 Jan 2024 22:00:34 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型是否有可能通过将其概率指定为“两者都不”来预测新数据不适合用于训练的任何类别？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77796241/is-it-possible-for-an-ml-model-to-predict-that-new-data-doesnt-fit-any-of-the-c</link>
      <description><![CDATA[我正在 python 中使用 sklearn.ensemble 中的 RandomForestClassifier 来训练 ML 模型。我有 2 个类/模型（比如 A 和 B）可以生成曲线。在输入中，每行代表一条曲线，每列给出不同 x 值的 y 值。这些值是从 .txt 文件中读取的。
我想训练 ML 模型，以便当我向它提供新曲线时，它可以预测新曲线属于模型 A、模型 B 或两者都不属于的概率。例如如果我提供一条假曲线（不属于任何模型），我希望将其标记为“两者都不是”或类似的内容。
我面临的问题是，使用 Predict.proba() 的两个类（A 和 B）的概率总和为 1，即随机森林将每条新曲线分配给模型，而我无法得到新曲线不属于任何一个的情况。在上述情况下有没有办法执行此操作？或者是否可以使用随机森林以外的其他东西？
下面是代码的工作示例：
导入 pandas 作为 pd
将 numpy 导入为 np
从 sklearn.ensemble 导入 RandomForestClassifier


X_train = pd.read_csv(‘training_dataset.txt’)
X_test = pd.read_csv(&#39;test_dataset.txt&#39;)
y_train = pd.read_csv(&#39;training_dataset_label.txt&#39;)
y_test = pd.read_csv(&#39;test_dataset_label.txt&#39;)

X_train1 = X_train.值
X_test1 = X_test.值

y_train1 = y_train.值
y_test1 = y_test.值

模型 = RandomForestClassifier()
model.fit(X_train1, y_train1.ravel())
预测 = model.predict(X_test1)
概率 = model.predict_proba(X_test1)

这是我得到的输出，其中每一行给出新曲线属于 A 或 B 的概率

&lt;表类=“s-表”&gt;
&lt;标题&gt;

一个
B


&lt;正文&gt;

0.94
0.06


0.14
0.86


1.00
-


0.41
0.59


0.15
0.85


0.83
0.17


0.77
0.23


0.65
0.35


0.99
0.01




如果新曲线不属于任何一个，我预计 A 和 B 的输出（预测概率）均为 0。]]></description>
      <guid>https://stackoverflow.com/questions/77796241/is-it-possible-for-an-ml-model-to-predict-that-new-data-doesnt-fit-any-of-the-c</guid>
      <pubDate>Wed, 10 Jan 2024 20:38:53 GMT</pubDate>
    </item>
    <item>
      <title>制作 XGBoost AOC 曲线时出现错误 [关闭]</title>
      <link>https://stackoverflow.com/questions/77795107/getting-an-error-when-making-xgboost-aoc-curve</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77795107/getting-an-error-when-making-xgboost-aoc-curve</guid>
      <pubDate>Wed, 10 Jan 2024 16:57:58 GMT</pubDate>
    </item>
    <item>
      <title>我应该在合并数据集之前还是合并数据集之后删除异常值？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77795045/should-i-remove-outliers-before-combining-the-dataset-or-after-combining-the-dat</link>
      <description><![CDATA[我正在对自定义数据集进行一些探索性数据分析。我有 3 个不同的数据框：

df1 属于 0 类。
df2 属于类别 1。
df3 属于 2 类。

我正在组合数据帧上进行 k 均值聚类（通过组合 df1、df2、df3）。我应该在组合数据帧之前还是组合数据帧之后删除异常值？
我正在使用 IQR 技术删除异常值。在组合数据框之前我一直在这样做，但我想知道这是否是正确的方法。]]></description>
      <guid>https://stackoverflow.com/questions/77795045/should-i-remove-outliers-before-combining-the-dataset-or-after-combining-the-dat</guid>
      <pubDate>Wed, 10 Jan 2024 16:50:30 GMT</pubDate>
    </item>
    <item>
      <title>是什么导致 keras.model.evaluate 出现错误？不兼容的形状：[32] 与 [32,3]，并且“输出”必须具有等级 (ndim)“target.ndim - 1”</title>
      <link>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</guid>
      <pubDate>Wed, 10 Jan 2024 16:47:49 GMT</pubDate>
    </item>
    <item>
      <title>SHAP KernelExplainer 不接受 DMatrix 也不接受 numpy 数组</title>
      <link>https://stackoverflow.com/questions/77794688/shap-kernelexplainer-not-accepting-a-dmatrix-nor-a-numpy-array</link>
      <description><![CDATA[我正在尝试绘制我训练的 XGBoost 模型的 SHAP 分析图。类似于这个.
但是，我使用了 Dart booster，所以 shap.TreeExplainer 不起作用。然后，我尝试使用应该对我有用的 shap.KernelExplainer 。但是，它不接受任何常见类型的输入。
我的代码是这样的：
第一次尝试
# 要预测的数据
full_data = xgb.DMatrix(full_X, label=full_y, feature_names=feature_names)

# 使用 DART booster 预训练的 XGB 模型
loaded_model.set_param({“device”:“cuda”})


xgb_predict = lambda x:loaded_model.predict(x)
解释器 = shap.KernelExplainer(xgb_predict, full_data)

我得到：
TypeError：作为数据对象传递的未知类型：

第二次尝试
我还尝试提供一个 numpy 数组：
X_np = np.array(full_X)

解释器 = shap.KernelExplainer(xgb_predict, X_np)

但它也会返回一个错误：
TypeError: (&#39;期望数据是 DMatrix 对象，得到：&#39;, )

我使用的是 shap 0.44.0 和 xgboost 2.0.2
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77794688/shap-kernelexplainer-not-accepting-a-dmatrix-nor-a-numpy-array</guid>
      <pubDate>Wed, 10 Jan 2024 15:55:55 GMT</pubDate>
    </item>
    <item>
      <title>CNN 最后一层的 SVR [关闭]</title>
      <link>https://stackoverflow.com/questions/77794156/svr-on-the-last-layer-of-cnn</link>
      <description><![CDATA[我正在尝试创建 CNN + SVR 模型来猜测手稿的制作日期。我正在使用 CNN 的 google 架构，现在如何将 SVR 添加到 CNN 的全连接层来猜测这个日期？
这是我对谷歌架构模型的修改版本：
在此处输入图片描述
嗯，我的第一个想法是提取特征向量，因为最后一层的 CNN 给了我 1x1x1024“图像”最后，但是支持向量回归真的接受特征向量吗？
这里的旁注是我的数据库包含 1300-1600 年时期的拉丁手稿（遗憾的是并不是每年都会给出）。我尝试使用 SVR，因为我的模型应该允许 +-10 年的错误，因为显然很难猜测确切的年份]]></description>
      <guid>https://stackoverflow.com/questions/77794156/svr-on-the-last-layer-of-cnn</guid>
      <pubDate>Wed, 10 Jan 2024 14:33:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 1 或 3 通道灰度图像的 CNN 基准</title>
      <link>https://stackoverflow.com/questions/77793280/cnn-benchmark-on-using-grayscale-images-with-1-or-3-channels</link>
      <description><![CDATA[我目前使用的 cnn（MANet、带有 imagenet 权重的 effectivenet b-3）不是由我开发的，是在彩色 Bing 卫星图像上进行训练的，因此第一个模型配置引用了 3 通道图像，但是还有第二个模型配置使用 2 个图像和 6 个通道（一张卫星图像、当前的 Bing 地图和一张来自 Corona 数据集的 60 年代至 70 年代）。
我对它的使用纯粹局限于特定的地理区域，因此我的任务是微调来自不同地理区域的 300-400 张图像（其中我可以获取当前的 Bing 图像和来自 Corona 数据集的灰度图像）并分析结果。
第一个问题是关于通道数量的；由于第二张图像 Corona 是灰度图像，那么输入通道总数不应该是 4 吗？
然而，模型的架构对微调施加了限制，正因为如此，我的想法是，可能选择 6 作为输入通道的数量，以便将灰度图像视为 RGB，并且在用法，这可能吗？
在线搜索，我发现这个非常好的指南灰度图像上的迁移学习 最后提出了一种灰度图像的各种用途和微调类型之间的比较研究，你知道是否有有什么学术层面的内容吗（论文、谷歌学术链接）？
最后一件事，在上面链接的指南中，使用 3 个通道的性能下降没有量化，让我更好地解释一下，因为我必须首先从头开始训练模型，然后进行微调，训练过程是在5000 张 2k 图像，在没有任何特殊安排的情况下，我将 Colab 上提供的 15gb RAM 饱和，假设使用 4 个通道而不是 6 个通道，我能够在空间和时间方面获得多少收益？
非常感谢您的回答，希望我的回答尽可能清楚。]]></description>
      <guid>https://stackoverflow.com/questions/77793280/cnn-benchmark-on-using-grayscale-images-with-1-or-3-channels</guid>
      <pubDate>Wed, 10 Jan 2024 12:14:35 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 3.12.1 上安装 PyTorch</title>
      <link>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</link>
      <description><![CDATA[我正在安装 DARTS TimeSeries 库 (https: //github.com/unit8co/darts/blob/master/INSTALL.md#enabling-Optional-dependencies），但我遇到了依赖项安装问题。在 DARTS 安装指南中，它说如果我们遇到这个问题，我们必须参考 PyTorch 的官方安装指南，然后尝试再次安装 Darts。然后，当我尝试在 python 3.12.1 上安装 torch 时，我遇到了这个错误：
&lt;块引用&gt;
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版。

如何解决？
我使用 PyCharm 作为 Python 代码编辑器。
我尝试了pip install darts，但它没有安装所有软件包并遇到此错误错误：subprocess-exited-with-error
 用于安装构建依赖项的 pip 子进程未成功运行。
  │ 退出代码：1
  ╰─&gt; 【136行输出】
      正在收集setuptools&gt;=64.0
        从 https://files.pythonhosted.org/packages 获取 setuptools&gt;=64.0 的依赖信息

然后，我尝试使用 pip install torch 安装 torch 并遇到此错误
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版]]></description>
      <guid>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</guid>
      <pubDate>Wed, 10 Jan 2024 10:16:06 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归和决策树之间的区别</title>
      <link>https://stackoverflow.com/questions/76161673/difference-between-logistic-regression-and-decision-trees</link>
      <description><![CDATA[我正在研究决策树，并了解到它通常用于分类问题。
但逻辑回归也仅用于分类问题。
于是我在网上到处搜索，但没有得到满意的结果。我真的很困惑我们什么时候应该使用什么，或者给我一些用例，其中任何一个都可以更好地工作]]></description>
      <guid>https://stackoverflow.com/questions/76161673/difference-between-logistic-regression-and-decision-trees</guid>
      <pubDate>Wed, 03 May 2023 08:04:30 GMT</pubDate>
    </item>
    </channel>
</rss>