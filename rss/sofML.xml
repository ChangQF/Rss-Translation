<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 31 Dec 2023 21:12:15 GMT</lastBuildDate>
    <item>
      <title>arduino：如何在arduino中读取csv文件</title>
      <link>https://stackoverflow.com/questions/77740390/arduino-how-to-read-a-csv-file-in-arduino</link>
      <description><![CDATA[我正在尝试建造一个跟随我的脸的简单炮塔。对于面部跟踪功能，我使用 Python OpenCV 来跟踪我的面部并将 X 和 Y 坐标存储在 CSV 文件中。我如何在 Arduino 中读取该 CSV 文件？
另一个问题：我解决这个问题的方法是个好主意，还是有更好的方法来解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77740390/arduino-how-to-read-a-csv-file-in-arduino</guid>
      <pubDate>Sun, 31 Dec 2023 21:09:35 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中如何进行特征提取</title>
      <link>https://stackoverflow.com/questions/77740251/how-to-feature-extract-in-the-machine-learning</link>
      <description><![CDATA[我是机器学习领域的新手。下面提到我的数据集。
数据集
我做了吸引人的部分和数据可视化部分。下面提到我的编码。
 导入数学
    将 pandas 导入为 pd
    将 numpy 导入为 np
    将 matplotlib.pyplot 导入为 plt
    从 sklearn.preprocessing 导入 MinMaxScaler
    从 sklearn.metrics 导入mean_squared_error
    从 keras.models 导入顺序
    从 keras.layers 导入密集、LSTM、Dropout

    df = pd.read_csv(&#39;sample_data/covid19_full_data.csv&#39;)
    df

    df.isnull().sum()

    print(&#39;删除空值之前的数据集长度&#39;)
    长度（df）

    df[&#39;日期&#39;] = pd.to_datetime(df[&#39;日期&#39;])

    aggregate_data = df.groupby(&#39;日期&#39;).agg({
    &#39;new_cases&#39;: &#39;总和&#39;,
    &#39;new_deaths&#39;: &#39;总和&#39;,
    &#39;total_cases&#39;: &#39;总和&#39;,
    &#39;total_deaths&#39;: &#39;总和&#39;
    }).reset_index()
    聚合数据

    # 绘制随时间变化的 new_cases
    plt.figure(figsize=(14, 7))
    plt.plot(aggreerated_data[&#39;date&#39;],aggregate_data[&#39;new_cases&#39;], label=&#39;新案例&#39;)
    plt.title(&#39;随着时间的推移新的 COVID-19 病例&#39;)
    plt.xlabel(&#39;日期&#39;)
    plt.ylabel(&#39;新增病例数&#39;)
    plt.图例()
    plt.show()

    plt.figure(figsize=(14, 7))
    plt.plot(aggreerated_data[&#39;date&#39;],aggregate_data[&#39;new_deaths&#39;], label=&#39;新死亡&#39;, color=&#39;red&#39;)
    plt.title(&#39;随着时间的推移新的 COVID-19 死亡人数&#39;)
    plt.xlabel(&#39;日期&#39;)
    plt.ylabel(&#39;新增死亡人数&#39;)
    plt.图例()
    plt.show()

    plt.figure(figsize=(14, 7))
    plt.plot(aggregate_data[&#39;date&#39;],aggregate_data[&#39;total_cases&#39;],label=&#39;总病例数&#39;,color=&#39;绿色&#39;)
    plt.title(&#39;一段时间内的 COVID-19 病例总数&#39;)
    plt.xlabel(&#39;日期&#39;)
    plt.ylabel(&#39;案例总数&#39;)
    plt.图例()
    plt.show()

    plt.figure(figsize=(14, 7))
    plt.plot(aggreerated_data[&#39;date&#39;],aggregate_data[&#39;total_deaths&#39;], label=&#39;总死亡人数&#39;, color=&#39;黑色&#39;)
    plt.title(&#39;一段时间内的 COVID-19 死亡总数&#39;)
    plt.xlabel(&#39;日期&#39;)
    plt.ylabel(&#39;死亡总数&#39;)
    plt.图例()
    plt.show()

如何对我的方法进行特征提取部分。请编写特征提取部分的代码并解释每个步骤。]]></description>
      <guid>https://stackoverflow.com/questions/77740251/how-to-feature-extract-in-the-machine-learning</guid>
      <pubDate>Sun, 31 Dec 2023 19:50:12 GMT</pubDate>
    </item>
    <item>
      <title>C++神经网络中softmax层的问题</title>
      <link>https://stackoverflow.com/questions/77739953/problem-with-softmax-layer-in-c-neural-network</link>
      <description><![CDATA[我用 C++ 实现了一个简单的神经网络。对于密集连接的层来说，它似乎工作得很好，但是当我添加用于分类的 softmax 层时，我遇到了麻烦。
从输入生成激活值的 softmax 函数本身看起来是正确的，但是当我训练网络时，它在分类方面并没有变得更好。我认为问题出在反向传播代码中——它对于密集层来说效果很好。所以它可能是在 softmax 层的导数计算中。
我的代码可能有一些简单的问题？我尝试了很多变体但无法使其工作..
以下是激活函数的实现：
doubleactivation_function_sigmoid（常量双输入）
{
    返回 1 / (1 + exp(-输入));
}

双激活函数 sigmoid_derivative（常量双输入）
{
    返回输入*（1 - 输入）；
}

双activation_function_relu（常量双输入）
{
    返回 std::max(0.0, 输入);
}

双activation_function_relu_derivative（常量双输入）
{
    返回（输入&gt; 0.0）？ 1.0：0.0；
}

双激活函数_softmax（常量双输入）
{
    // 只需返回输入，稍后会进行分类
    返回输入；
}

双激活函数softmax_derivative（常量双输入）
{
    返回输入*（1 - 输入）；
}

成本函数的实现：
double cost_function_mse（常量双预测，常量双目标）
{
    // MSE 成本函数 - 下面的导数是一个简单的加法！
    返回 0.5 * pow((预测 - 目标), 2);
}

double cost_function_mse_derivative(const 双预测，const 双目标)
{
    // 均方误差
    返回预测-目标；
}

double cost_function_rmse(const 双预测，const 双目标)
{
    return sqrt(0.5 * pow((预测 - 目标), 2));
}

double cost_function_rmse_derivative（const 双预测，const 双目标）
{
    return (预测 - 目标) / sqrt(2.0);
}

double cost_function_crossEntropy(const 双预测，const 双目标)
{
    // 未使用，因为 softmax 是在整个数组上运行的。
    返回 - 目标*exp(预测);
}

double cost_function_crossEntropy_derivative(const 双预测，const 双目标)
{
    返回预测-目标；
}

反向传播函数：
双层::BackwardsPass(
    const层&amp;上一层，
    常量层* nextLayer,
    常量双倍学习率，
    常量列&amp;目标，
    CostFuncPtr cf,
    CostFuncPtr cfD)
{
    双累积误差 = 0;
    for (uint32 n=0; n &lt; numNeurons; n++)
    {
        const 双预测 = 激活值[n]；
        错误[n] = 0；
        
        if (nextLayer == nullptr)
        {
            // 这是输出层
            错误[n] = cfD(预测, 目标[n]); // 调用成本导数函数

            // 仅用于报告
            累积误差 += pow(cf(预测, 目标[n]),2);
        }
        别的
        {
            for (uint32 k=0; k &lt; nextLayer-&gt;numNeurons; k++)
            {
                错误[n] += nextLayer-&gt;权重[k][n] * nextLayer-&gt;梯度[k];
            }
        }

        if (!forClassification)
            梯度[n] = 错误[n] * afD(预测); // 调用激活导数函数
        别的
            梯度[n] = 预测-目标[n]；

    }

    // 更新权重
    for (uint32 n=0; n &lt; numNeurons; n++)
    {
        for (uint32 i = 0; i &lt; previousLayer.numNeurons; ++i)
        {
            // 输入是上一层神经元的激活值
            const 双输入 = previousLayer.activationValue[i];
            权重[n][i] -= 学习率 * 梯度[n] * 输入；
        }

        // 更新偏差
        偏差[n] -= 学习率 * 梯度[n]； // 偏置输入始终为 1，因此被省略
    }
    返回战俘（累积错误，2）；
}

在使用简单测试数据进行训练期间，预测并没有变得更好。]]></description>
      <guid>https://stackoverflow.com/questions/77739953/problem-with-softmax-layer-in-c-neural-network</guid>
      <pubDate>Sun, 31 Dec 2023 17:25:18 GMT</pubDate>
    </item>
    <item>
      <title>在 Flutter 中使用 Real-ESRGAN Onnx</title>
      <link>https://stackoverflow.com/questions/77739855/using-real-esrgan-onnx-in-flutter</link>
      <description><![CDATA[如何在 flutter 中实现 Real-ESRGAN ONNX。我这方面不专业。
有人可以帮助提供示例推理代码。我已将模型从 pytorch 转换为 onnx。
我尝试过一些示例数据并成功，但不知道还要做什么
&lt;前&gt;&lt;代码&gt;
` OrtSession？ _会议;
  细绳？进步;
  细绳？状态；
  Uint8List？增强；
  @覆盖
  无效初始化状态（）{
    super.initState();

    进度 =“正在初始化 ONNX 运行时...”;
    print(&#39;正在初始化 ONNX 运行时...&#39;);
    _initializeOrt();
    进度 =“正在创建 ONNX 会话...”;
    print(&#39;正在创建 ONNX 会话...&#39;);
    _createSession();
  }

  未来&lt;空&gt; _initializeOrt() 异步 {
    尝试 {
      等待 OrtEnv.instance.init();
      设置状态（（）{
        进度 =“ONNX 运行时初始化成功。”；
      });
      _createSession();
    } 捕获 (e) {
      设置状态（（）{
        进度 = &#39;初始化 ONNX 运行时时出错：$e&#39;;
      });
    }
  }

  未来&lt;空&gt; _createSession() 异步 {
    尝试 {
      最终会话选项 = OrtSessionOptions();
      const assetFileName = &#39;assets/RealESRGAN_x4plus_anime_6B.onnx&#39;;
      最终 rawAssetFile = 等待 rootBundle.load(assetFileName);
      最终字节= rawAssetFile.buffer.asUint8List();
      _session = OrtSession.fromBuffer(字节, sessionOptions);
      print(&#39;ONNX 会话创建成功。&#39;);
      设置状态（（）{
        进度 =“ONNX 会话创建成功。”；
      });
    } 捕获 (e) {
      设置状态（（）{
        进度 =“创建 ONNX 会话时出错：$e”；
      });
      print(&#39;创建 ONNX 会话时出错：$e&#39;);
    }
  }
  未来&lt;空&gt; _runInference() 异步 {
    print(&#39;运行推理...&#39;);
    设置状态（（）{
      infstatus = &quot;正在运行推理...&quot;;
    });

    最终形状 = [1, 3, 100, 100]；
    var data = Float32List.fromList(
        列表.填充(1 * 3 * 100 * 100, 0.5)); // 使用 Float32List 的示例数据
    最终 inputOrt = OrtValueTensor.createTensorWithDataList(data, shape);
    最终输入 = {&#39;input&#39;: inputOrt};
    最终 runOptions = OrtRunOptions();
    列表&lt;OrtValue??&gt;输出；

    尝试 {
      输出=等待_会话？.runAsync（runOptions，输入）；
      print(&#39;推理结果：${outputs?[0]}&#39;); // 在这里处理你的输出
      设置状态（（）{
        infstatus = &quot;推理结果：${outputs?[0]}&quot;;
      });

    } 捕获 (e) {
      print(&#39;推理过程中出错：$e&#39;);
    } 最后 {
      inputOrt.release();
      runOptions.release();
      输出？.forEach((元素) {
        元素？.release();
      });
    }

}
图书馆：
Onnx：https://github.com/gtbluesky/onnxruntime_flutter
Python 中的示例用法：
&lt;前&gt;&lt;代码&gt;`导入cv2
将 numpy 导入为 np
将 onnxruntime 导入为 rt
进口火炬
导入时间

# 使用 CUDA 执行提供程序加载 ONNX 模型
sess = rt.InferenceSession(&#39;RealESRGAN_x4plus_anime_6B.onnx&#39;)
print(“已加载模型。”)

# 加载输入图像
in_image = cv2.imread(&#39;input.jpg&#39;, cv2.IMREAD_UNCHANGED)
print(“已加载输入图像。”)

# 将 BGR 转换为 RGB 并转置维度
in_mat = cv2.cvtColor(in_image, cv2.COLOR_BGR2RGB)
in_mat = np.transpose(in_mat, (2, 1, 0))[np.newaxis]
in_mat = in_mat.astype(np.float32)
in_mat = in_mat / 255

# 测量推理时间的开始时间
开始时间 = 时间.time()

# 获取输入和输出名称
input_name = sess.get_inputs()[0].name
输出名称 = sess.get_outputs()[0].名称

print(&quot;输入名称：&quot;, input_name)
print(&quot;输出名称：&quot;,output_name)


# 将输入转换为 torch 张量并将其移至 GPU
in_mat = torch.tensor(in_mat)

# 运行推理
out_mat = sess.run([输出名称], {输入名称: in_mat.cpu().numpy()})[0]


# 测量并打印经过的时间
elapsed_time = time.time() - 开始时间
print(&#39;推理时间：&#39;,elapsed_time)
# 保存输出图像
out_mat = (out_mat.squeeze().transpose((2, 1, 0)) * 255).clip(0, 255).astype(np.uint8)
cv2.imwrite(&#39;输出.jpg&#39;, out_mat)
print(&quot;输出图像已保存。&quot;)`




]]></description>
      <guid>https://stackoverflow.com/questions/77739855/using-real-esrgan-onnx-in-flutter</guid>
      <pubDate>Sun, 31 Dec 2023 16:42:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么 REF 返回两个不同的答案并且差异很大？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77739723/why-does-ref-return-two-different-answers-with-a-large-difference</link>
      <description><![CDATA[我编写了一个程序，通过输入数据文件和目标列并选择最大特征，它会返回您选择的特征的最佳编号和名称（无论时间函数如何，仅收到最佳分数），但出现的问题是 REF 函数有问题吗
看照片：
列数：
3
【假假真】
0.7773148148148148
[真假真]
0.8606481481481485
[真实真实真实]
0.8672222222222222

&lt;前&gt;&lt;代码&gt;
列数 ：
5
【假假真假假】
0.7773148148148148
【假假真真真假】
0.7659259259259259
【假假真真真真】
0.8429629629629631
[真假真真真真]
0.9002777777777776
[ 真实真实真实真实真实]
0.9030555555555558

在选择两个特征时，当我们选择三个特征中的最大值时，得分为0.86
但是当我们选择最多 5 个特征时，该数字将返回 0.76。
按照逻辑，无论最大值如何，它在选择两个特征时至少应该显示 0.86，但它得到了较低的分数。
GitHub 项目链接：https://github.com/KoushaZhiyani/Logistic_Regression_for_Feature_Selection
注：使用train_test_spilt进行评估，在每个特征选择系列中，对100次不同随机状态的train_test_spilt进行评分并求平均值。]]></description>
      <guid>https://stackoverflow.com/questions/77739723/why-does-ref-return-two-different-answers-with-a-large-difference</guid>
      <pubDate>Sun, 31 Dec 2023 15:55:55 GMT</pubDate>
    </item>
    <item>
      <title>splitfolders python库仅创建文件夹-里面没有内容</title>
      <link>https://stackoverflow.com/questions/77739197/splitfolders-python-library-only-creating-folders-no-content-inside</link>
      <description><![CDATA[我正在尝试创建瑜伽姿势预测
我的数据集文件夹结构是
数据集-
--class1
---img1
---img2
--class2
导入分割文件夹
input_folders =“/数据集” 
output_folders = “/Spilted_Dataset” 
splitfolders.ratio(input=input_folders、output=output_folders、seed=1337、ratio=(.8,.1,.1)、group_prefix=None)
但是创建的文件夹只有子文件夹train、test、valid
里面没有图片
我想要文件夹 train 、 test 、 valid 以及特定类中的图像]]></description>
      <guid>https://stackoverflow.com/questions/77739197/splitfolders-python-library-only-creating-folders-no-content-inside</guid>
      <pubDate>Sun, 31 Dec 2023 12:54:47 GMT</pubDate>
    </item>
    <item>
      <title>Keras Sequential 编译后冻结，无法开始拟合</title>
      <link>https://stackoverflow.com/questions/77739015/keras-sequential-freezes-after-compiling-doesnt-start-fitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77739015/keras-sequential-freezes-after-compiling-doesnt-start-fitting</guid>
      <pubDate>Sun, 31 Dec 2023 11:31:51 GMT</pubDate>
    </item>
    <item>
      <title>构建车牌边界框的边界框预测器</title>
      <link>https://stackoverflow.com/questions/77738483/building-a-bounding-box-predictor-for-license-plate-bounding-box</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77738483/building-a-bounding-box-predictor-for-license-plate-bounding-box</guid>
      <pubDate>Sun, 31 Dec 2023 07:12:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的目标列上出现键错误，并且出现值错误：给定列不是数据帧的列</title>
      <link>https://stackoverflow.com/questions/77738345/why-am-i-having-a-key-error-on-my-target-column-and-a-value-error-that-says-a-g</link>
      <description><![CDATA[# 首先，我分割数据
目标=&#39;会员休闲&#39;
X_train = train.drop(目标, 轴=1)
y_train = 训练[目标]
# 然后，转换我的数字列和分类列
cat_trans = Pipeline([(“imputer”, SimpleImputer(strategy=“most_frequent”)),(&#39;encoder&#39;,OneHotEncoder(handle_unknown=“ignore”, drop=“first”,稀疏=False))])
num_trans = Pipeline([(“imputer”, SimpleImputer(strategy=“mean”)),(“scaler”, MinMaxScaler())])
预处理器 = ColumnTransformer(transformers=[(&#39;num&#39;, num_trans, num),(&#39;cat&#39;, cat_trans, cat)])
管道 = 管道([(&#39;预处理器&#39;, 预处理器)])
# 然后接下来的代码给了我错误
pipeline_fit = pipeline.fit(x_train)

键错误和值错误：给定列不是数据帧的列]]></description>
      <guid>https://stackoverflow.com/questions/77738345/why-am-i-having-a-key-error-on-my-target-column-and-a-value-error-that-says-a-g</guid>
      <pubDate>Sun, 31 Dec 2023 06:05:14 GMT</pubDate>
    </item>
    <item>
      <title>我正在为机器学习预测模型编写一个快速 api 服务器，但收到此错误：</title>
      <link>https://stackoverflow.com/questions/77738256/i-ma-writing-a-fast-api-server-for-a-ml-prediction-model-and-i-am-getting-this-e</link>
      <description><![CDATA[from fastapi import FastAPI,文件,UploadFile
进口uvicorn
将 numpy 导入为 np
从 io 导入 BytesIO
从 PIL 导入图像
将张量流导入为 tf


应用程序 = FastAPI()
MODEL=tf.keras.models.load_model(&#39;./bone_fracture_detection_model.h5&#39;)
CLASS_NAMES = [“破裂”,“未破裂”]

@app.get(“/ping”)
异步 def ping():
    返回“你好，我还活着”

def read_file_as_image(data)-&gt;; np.ndarray：
    图像 = np.array(BytesIO(数据))
    返回图像

@app.post(“/预测”)
异步 def 预测(
    文件：上传文件=文件(...)
）：
    图像 = read_file_as_image(等待 file.read())
    image_batch = np.expand_dims(图像,0)
    预测= MODEL.预测（图像）
    Predicted_class = CLASS_NAMES[np.argmax(预测[0])]
    置信度 = np.max(预测[0])
    返回{
        &#39;类&#39;：预测类，
        &#39;信心&#39;：浮动（信心）
    }


如果 __name__ == “__main__”：
    uvicorn.run（应用程序，主机=&#39;localhost&#39;，端口=8000）

这是我遇到的错误
文件“C:\Users\Chetan\Documents\localprograms\api.venv\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 70 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件“C:\Users\Chetan\Documents\localprograms\api.venv\Lib\site-packages\tensorflow\python\framework\constant_op.py”，第103行，在convert_to_eager_tensor中
返回 ops.EagerTensor(值, ctx.device_name, dtype)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError：无法将 NumPy 数组转换为张量（不支持的对象类型 _io.BytesIO）。
在邮递员上，我尝试传递图像并收到内部服务器错误
https://colab.research.google.com/drive /1DNnIVtXZek2BZD9wDaugj-wuI9XEqZrV#scrollTo=iGSVvHFCHlLh
这就是我在 kaggel 上编写骨折模型的方法
我尝试传递从 kaggel 笔记本获得的整个模型输出，但我面临另一个错误，即加载模型无法读取它。我是新手，请用简单的话解释我哪里出错了。]]></description>
      <guid>https://stackoverflow.com/questions/77738256/i-ma-writing-a-fast-api-server-for-a-ml-prediction-model-and-i-am-getting-this-e</guid>
      <pubDate>Sun, 31 Dec 2023 05:06:07 GMT</pubDate>
    </item>
    <item>
      <title>运行时错误：张量的大小必须匹配（维度 1 除外）。预期大小为 18，但列表中张量 1 的大小为 17</title>
      <link>https://stackoverflow.com/questions/77723713/runtimeerror-sizes-of-tensors-must-match-except-in-dimension-1-expected-size-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77723713/runtimeerror-sizes-of-tensors-must-match-except-in-dimension-1-expected-size-1</guid>
      <pubDate>Wed, 27 Dec 2023 19:38:15 GMT</pubDate>
    </item>
    <item>
      <title>Azure 机器学习工作室设计器 - 预测未来销售的算法</title>
      <link>https://stackoverflow.com/questions/77722671/azure-machine-learning-studio-designer-algorithm-to-predict-future-sales</link>
      <description><![CDATA[我正在 Azure 机器学习设计器中进行一项实验，使用线性回归算法构建可以预测未来销售的原型模型。
我在管理前向预测时遇到问题，我找到的所有示例，例如 Microsoft 提供的“回归 - 汽车价格预测（基本）”示例，均是我在管理前向预测时遇到的问题。 (https://github .com/Azure/MachineLearningDesigner/blob/master/articles/samples/regression-automobile-price-prediction-basic.md）用于处理已获得的给定数据集并预测一个缺失值。
我的数据集有 5 列（VoucherDate、Amount、BranchCode、Dolar oficial、Dolar blue）
数据集示例
管道执行
如何根据给定的当前数据来预测未来销售额？然后，我怎样才能看到计算出的所有行？因为在数据预览中我只能看到几行。
我开发了一个管道，可以预测数据集中的销售额（基于 MS 给出的示例），该管道由 SQL Azure 数据库中获得的销售额加上 2 个带有 UDS/ARS 汇率的变量组成报价。
管道执行已完成，评分数据集向我显示给定数据集金额的评分标签。但是，当我尝试生成一个新的数据集（包含我的信息和一些没有销售额的未来记录）时，管道给了我其他结果。]]></description>
      <guid>https://stackoverflow.com/questions/77722671/azure-machine-learning-studio-designer-algorithm-to-predict-future-sales</guid>
      <pubDate>Wed, 27 Dec 2023 15:17:30 GMT</pubDate>
    </item>
    <item>
      <title>存储使用 Torchvision 变换时应用的精确变换</title>
      <link>https://stackoverflow.com/questions/77711542/storing-the-exact-transformation-applied-when-using-torchvision-transforms</link>
      <description><![CDATA[当我们使用 torchvision 或 albumentations 的变换时，我们可以使用随机裁剪和随机亮度对比度等功能来生成增强图像。有没有可能的方法来存储应用于图像的精确变换以获得相应的图像？]]></description>
      <guid>https://stackoverflow.com/questions/77711542/storing-the-exact-transformation-applied-when-using-torchvision-transforms</guid>
      <pubDate>Sun, 24 Dec 2023 18:31:34 GMT</pubDate>
    </item>
    <item>
      <title>从混淆矩阵计算灵敏度和特异性</title>
      <link>https://stackoverflow.com/questions/51513311/calculation-of-sensitivity-and-specificity-from-confusion-matrix</link>
      <description><![CDATA[考虑这样的情况，标记数据的数量为 0 = 1400，标记为 1 = 100。标记为0的数据表示正常运行情况，标记为1的数据表示异常。仅针对异常事件触发警报。
假设二元分类获得以下混淆矩阵
cmMatrix =

                    预测 0 预测 1
           真相 0 1100 (TN) 300 (FP)
           真相 1 30 (FN) 70 (TP)


cmMatrix = [1100,300;30,70];
acc_0 = 100*(cmMatrix(1,1))/sum(cmMatrix(1,:));
acc_1 = 100*(cmMatrix(2,2))/sum(cmMatrix(2,:));

将给出 acc_0 = 78.5714 和 acc_1 = 70
混淆矩阵被读取为 1400 个正常事件，1100 个被正确识别为正常，300 个被错误识别为异常。
那么，在 100 个异常事件中，有 70 个被正确检测为异常，而 30 个被错误检测为异常。
我想计算 1 类的敏感性和特异性，因为这是异常事件检测的主要兴趣。我就是这样做的
灵敏度 = TP/(TP+FN) = 70/(70+30 ) = 0.70
特异性 = TN/(TN+FP) = 1100/(1100+300) = 0.78


灵敏度是指测试正确检测异常事件的能力。为什么灵敏度如此之低，并且与如此高 (70%) 的准确度 acc_1 不同。 
此计算是否正确？各个类别的准确度和灵敏度之间有什么区别？

我的计算有错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/51513311/calculation-of-sensitivity-and-specificity-from-confusion-matrix</guid>
      <pubDate>Wed, 25 Jul 2018 07:35:29 GMT</pubDate>
    </item>
    <item>
      <title>KNN 中需要优化哪些参数？</title>
      <link>https://stackoverflow.com/questions/43726728/what-parameters-to-optimize-in-knn</link>
      <description><![CDATA[我想优化 KNN。关于SVM、RF和XGboost的内容有很多；但对于 KNN 来说很少。
据我所知，邻居的数量是一个需要调整的参数。
但是还有哪些参数需要测试呢？有什么好的文章吗？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/43726728/what-parameters-to-optimize-in-knn</guid>
      <pubDate>Mon, 01 May 2017 21:22:36 GMT</pubDate>
    </item>
    </channel>
</rss>