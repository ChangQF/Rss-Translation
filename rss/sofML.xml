<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 09 Jan 2024 01:02:14 GMT</lastBuildDate>
    <item>
      <title>有没有一种准确的方法来估计 2D 图像上的 3D 位置</title>
      <link>https://stackoverflow.com/questions/77783783/is-there-an-accurate-way-to-estimate-3d-positions-on-a-2d-image</link>
      <description><![CDATA[我是一名实习生，在我的项目的大部分时间里一直在努力解决这个问题。
我将 Python 与 OpenCV 结合使用，并使用我自己的数据训练了 YOLOv8 模型。
我有一个通过机器周围的对象检测获得的边界框，该边界框向外延伸并附加到对象上。我目前面临的问题是，我想估计机器在物体上的位置，如果机器要延伸的话，给定其由非延伸形式的边界框定义的位置。
本质上，我有机器和机器未扩展的对象（下面将详细描述）的 2D 图像。然后，我获得了机器的边界框，并希望估计其在机器延伸并附着到物体时所在的同一 2D 图像上的位置。
相机的角度是相同的（但是它可能会因天气而轻微晃动，这就是为什么它应该是通用的），相机放置在机器的左侧图像和右侧的物体（不是完全侧向，而是倾斜的，因此它朝右侧的物体看去，只能看到左侧机器的侧面轮廓）
需要注意的是，机器不会每次都固定在完全相同的位置，因为物体在移动时会产生一些噪音。
我已经尝试解决这个问题有一段时间了，并尝试了许多不同的想法；然而，我对计算机视觉和机器学习非常陌生，当我尝试某些事情时，我很可能没有正确地做。
我尝试过使用计算机视觉技术来提取特征、透视线等来确定机器的运动，但效果不佳。再说一次，很可能是我没有正确处理它或没有使用正确的方法。
我当前的方法是使用“设置”当扩展机器连接到物体时，它会监视并记录扩展机器的位置。然后，当给定图像来估计位置时，它会采用机器的边界框并将其转换为记录的先前连接位置。这并没有真正按照我的预期工作，并且对于我的需要来说太硬编码了。
我希望获得一些关于如何解决这个问题的想法，我是否应该使用计算机视觉技术（以及如何使用），或者我是否应该尝试训练机器学习模型等。
本质上，我相对陷入困境，不确定从这里该何去何从。]]></description>
      <guid>https://stackoverflow.com/questions/77783783/is-there-an-accurate-way-to-estimate-3d-positions-on-a-2d-image</guid>
      <pubDate>Tue, 09 Jan 2024 00:23:10 GMT</pubDate>
    </item>
    <item>
      <title>了解 GPT 的大嵌入大小与维数灾难的关系</title>
      <link>https://stackoverflow.com/questions/77783766/understanding-the-large-embedding-size-of-gpt-in-relation-to-the-curse-of-dimens</link>
      <description><![CDATA[我最近了解到，据报道 OpenAI 的 GPT-3 模型的嵌入大小为 12288，与机器学习模型中的典型嵌入相比，这似乎非常大。这提出了几个有趣的问题：

GPT-4 如何有效管理如此大的嵌入大小而不陷入维数灾难？维数灾难通常是指随着维数增加，空间体积增加如此之快，导致可用数据变得稀疏，导致模型可靠性降低的现象。鉴于此，GPT-4 是如何设计来应对与如此高维空间相关的挑战的？

如此大的嵌入大小有什么实际影响？这包括计算要求、训练数据量、泛化能力以及用于缓解维度问题的任何技术等方面。


任何有关大规模语言模型及其高维嵌入处理的见解或相关资源的参考，我们将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/77783766/understanding-the-large-embedding-size-of-gpt-in-relation-to-the-curse-of-dimens</guid>
      <pubDate>Tue, 09 Jan 2024 00:15:17 GMT</pubDate>
    </item>
    <item>
      <title>张量流中相同训练和验证数据的不同结果</title>
      <link>https://stackoverflow.com/questions/77783611/different-results-for-the-same-training-and-validation-data-in-tensorflow</link>
      <description><![CDATA[我使用 model.fit 函数来训练我的神经网络
 模型 = tf.keras.Sequential()
        model.add(tf.keras.layers.Dense(单位=50，激活=“relu”，input_shape=(X_train.shape[1],),
        model.add(tf.keras.layers.Dense(单位=50，激活=“relu”，
                                        kernel_regularizer=正则化）
        model.add(tf.keras.layers.Dense(单位=20，激活=“relu”，
                                        kernel_regularizer=正则化）
        model.add(tf.keras.layers.Dense(单位=10，激活=“relu”，
                                        kernel_regularizer=正则化）
        model.add(tf.keras.layers.Dense(单位=1,激活=“sigmoid”))

        model.compile(优化器=tf.keras.optimizers.AdamW(),
                  损失=“binary_crossentropy”，
                  Weighted_metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalsePositives()])

        回调 = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, 耐心=20)

        历史 = model.fit(X_train, Y_train,
                        纪元=500，
                        批量大小=批量，
                        详细=真，
                        验证数据=（X_train，Y_train），
                        类别权重=类别权重，
                        回调=[回调])

它给我的验证和训练指标的结果非常不同，即使它是完全相同的数据。

我的数据非常不平衡，这就是我使用类别权重的原因。然而，它并没有解释为什么对于完全相同的数据，训练和验证指标如此不同。造成这种行为的原因是什么？]]></description>
      <guid>https://stackoverflow.com/questions/77783611/different-results-for-the-same-training-and-validation-data-in-tensorflow</guid>
      <pubDate>Mon, 08 Jan 2024 23:15:43 GMT</pubDate>
    </item>
    <item>
      <title>零/一/少样本学习方法：如何在不更新模型参数的情况下学习？</title>
      <link>https://stackoverflow.com/questions/77782869/zero-one-few-shot-learning-approaches-how-to-learn-without-update-model-parame</link>
      <description><![CDATA[经过一些研究，检查这个，或这个，对某些内容进行粗俗化的帖子网站上，我在以下问题上没有找到令人满意的答案：*-shot 学习和迁移学习之间有什么区别，形式上。
设 $f_{\theta}$ 为多层感知器，对一组向量 \textbf{x}_1,\textbf{x}_2,\cdots,\textbf{x}_N\in\mathbb{ 进行操作R}^d 并将它们分类为 $C\in\mathbb{N}$ 类。
这些$N$向量和$C$类代表学习上下文LC_1（例如对$N=10000$狗和猫进行分类，因此$C$将等于2）。
假设我们在 LC1 上有完美的分类器 $f_{\theta^{\star}_1}$ （即问题测试集的准确度约为 100%）。
对我来说，

迁移学习将是：

我有第二个学习上下文 LC_2，它与 LC_2 “接近”。至 LC_1。例如，LC_2 是一组狮子和马。
因此，类的数量仍然等于 2。因此，为了静态地处理 LC_2，我使用 $f_{\theta^{\star}1}$ （在 LC_1 上训练）并重新训练 $f_{\theta^{\star}1}$ f{\theta^{\star}1}$。一旦执行，我得到$f{\theta^{\star}_2}$。
因此，我将在 LC_1 上从头开始构建的低级知识转移到了 LC_2。对我来说，我已经进行了迁移学习。
我们在这一点上同意吗？

（零/一个/几个）-shot（表示为 *-shot）将是（根据我目前的理解）：

现在 LC_2 是一个“扩展” LC_1 ，例如，我仍在尝试对狗和猫进行分类，但我已将“猴子”添加到了 LC_1 中。班级。如何利用 $f_{\theta^{\star}_1}$ 对猴子进行分类？
我确实有些担心，无法清楚地理解 *-shot 方法的真正含义：

首先，$f_{\theta^{\star}_1}$ 被设计为仅 2 个类，因此根据定义，它在数学上无法推断出超过 3 个类.

其次，在不改变$\theta^{\star}1$的情况下（我读到*-shot学习方法不涉及额外的梯度计算），所以*-shot学习方法使用$ f{\theta^{\star}1}$ 并利用 $f{\theta^{\star}1}$ 内置表示来执行猴子分类，而无需$f{\theta^{\star}_1}$ 定义的任何更改，对我来说毫无意义。


利用内置表示来实现“关闭”任务听起来与我相关，但如果没有模型定义更改或梯度更新，我无法清楚理解这些 *-shot 学习方法是如何工作的。只是面对一些关于 *-shot 学习方法的模糊解释，这对我来说还不够令人满意。
你能帮我吗？ :)]]></description>
      <guid>https://stackoverflow.com/questions/77782869/zero-one-few-shot-learning-approaches-how-to-learn-without-update-model-parame</guid>
      <pubDate>Mon, 08 Jan 2024 19:48:17 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：使用 Keras 创建多视图变分自动编码器模型时，层“full_model”的输入 2 与该层不兼容</title>
      <link>https://stackoverflow.com/questions/77782475/valueerror-input-2-of-layer-full-model-is-incompatible-with-the-layer-when-cr</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77782475/valueerror-input-2-of-layer-full-model-is-incompatible-with-the-layer-when-cr</guid>
      <pubDate>Mon, 08 Jan 2024 18:18:19 GMT</pubDate>
    </item>
    <item>
      <title>尽管进行了学习率调整和正则化，为什么我的模型对 t1、t2、t3 的实时推理预测仍保持静态？</title>
      <link>https://stackoverflow.com/questions/77782249/why-does-my-models-live-inference-prediction-for-t1-t2-t3-remain-static-despi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77782249/why-does-my-models-live-inference-prediction-for-t1-t2-t3-remain-static-despi</guid>
      <pubDate>Mon, 08 Jan 2024 17:34:24 GMT</pubDate>
    </item>
    <item>
      <title>Python LightGBM错误：joblib.externals.loky.process_executor.TermulatedWorkerError {SIGSEGV(-11)} [重复]</title>
      <link>https://stackoverflow.com/questions/77781970/python-lightgbm-error-joblib-externals-loky-process-executor-terminatedworkerer</link>
      <description><![CDATA[我正在使用 Microsoft 的 lightgbm (lgbm) 库。虽然我的 lgbm 脚本与 xgboost 和随机森林的脚本非常相似（两者都工作正常），但在使用 lgbm 时，我似乎在 Mac Book Pro 和 MacStudios（带有 M1 芯片）上始终收到以下错误：
joblib.externals.loky.process_executor.TermminateWorkerError：执行程序管理的工作进程意外终止。这可能是由于调用函数时出现分段错误或内存使用过多导致操作系统杀死工作线程造成的。
worker 的退出代码为 {SIGSEGV(-11)}
相关代码：
_train_x、_val_x、_train_y、_val_y = train_test_split(_train_x、_train_y、test_size = 0.2)
    
lgbm_model = LGBMClassifier（bagging_fraction = 0.75，bagging_freq = 5，random_state = 42，verbose = -1，force_col_wise = True）
    
kfoldcv = StratifiedKFold(n_splits=3, shuffle=True, random_state=7)
    
lgbm_random_search = RandomizedSearchCV(估计器 = lgbm_model, param_distributions = self._param_dict, n_iter = self.num_searches, cv = kfoldcv, verbose=2, random_state=42, n_jobs=-1)
    
lgbm_random_search.fit(_train_x, _train_y)

self._CrossVal_largest_accscore = lgbm_random_search.best_score_
    
lgbm_model = LGBMClassifier(n_jobs=-1，verbose=-1，force_col_wise=True，bagging_fraction = 0.75，bagging_freq = 5，**lgbm_random_search.best_params_)

lgbm_model.fit(_train_x, _train_y, 回调=[early_stopping(50), log_evaluation(50)], eval_set=[(_val_x,_val_y)])

注意，当我简单地删除子句 njobs=-1 时，我的程序在运行以下行时就会终止：
lgbm_random_search.fit(_train_x, _train_y)
环境：
系统软件概述：
系统版本：macOS 14.0 (23A344)
内核版本：Darwin 23.0.0
启动卷：Macintosh
HD启动模式：正常
安全虚拟内存：已启用
系统完整性保护：已启用

硬件概述：
&lt;预&gt;&lt;代码&gt; 型号名称：MacBook Pro
  型号：MK1F3B/A
  芯片：苹果M1 Pro
  核心总数：10（8 个性能和 2 个效率）
  内存：16GB
  系统固件版本：10151.1.1
  操作系统加载程序版本：10151.1.1
  激活锁状态：已启用

应用软件
Visual Studio 代码==1.72.2
蟒蛇==3.10.121

Python 包
&lt;小时/&gt;
anaconda-client==1.12.0
anaconda-navigator==2.4.2
康达==23.7.2
conda-build==3.26.0
joblib==1.3.0
光GBM==4.0.0
matplotlib==3.7.1
matplotlib-内联==0.1.6
numpy==1.23.5
熊猫==2.0.3
scikit-image==0.20.0
scikit学习==1.3.0
scipy==1.11.1
统计模型==0.14.0
sympy==1.12
xgboost==2.0.0

我已经审查并尝试了以下网站中的一些建议解决方案，但无济于事（例如删除 njobs 参数；添加 &#39;pre_dispatch=2&#39; 参数；重新安装 anaconda、lightgbm、joblib；使用较少数量的估计器 30 到 300等）：

n_jobs=-1 的 GridSearchCV 不适用于决策树/随机森林分类

如何修复/调试 scikit learn 中引发的多进程终止工作错误

GridSearch 中的 TermatedWorkerError

由执行器意外终止

如何修复/调试 scikit learn 中抛出的多进程终止工作错误

TermatedWorkerError：托管工作进程被执行者意外终止

使用 RandomizedSearchCV 时的多个作业问题&lt; /p&gt;

]]></description>
      <guid>https://stackoverflow.com/questions/77781970/python-lightgbm-error-joblib-externals-loky-process-executor-terminatedworkerer</guid>
      <pubDate>Mon, 08 Jan 2024 16:42:21 GMT</pubDate>
    </item>
    <item>
      <title>带有我自己的预训练模型的 Sagemaker 批处理变压器</title>
      <link>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:54:18 GMT</pubDate>
    </item>
    <item>
      <title>哪种机器学习模型可用于稀疏时间序列的冷启动预测？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77781715/which-machine-learning-model-for-cold-start-forecasting-on-sparse-time-series</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781715/which-machine-learning-model-for-cold-start-forecasting-on-sparse-time-series</guid>
      <pubDate>Mon, 08 Jan 2024 15:50:08 GMT</pubDate>
    </item>
    <item>
      <title>BayesSearchCV 与 KerasClassifier：调整超参数时出现“无效参数”错误</title>
      <link>https://stackoverflow.com/questions/77781577/bayessearchcv-with-kerasclassifier-invalid-parameter-error-when-tuning-hyperp</link>
      <description><![CDATA[我正在尝试使用 Scikit-Optimize 中的“BayesSearchCV”和 SciKeras 中的“KerasClassifier”来调整 Keras 模型的超参数。但是，我遇到了“ValueError”，指出超参数是“KerasClassifier”的无效参数。
我的代码结构如下：
# 导入必要的库
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入LSTM，Dropout，密集
从tensorflow.keras.optimizers导入Adam、SGD、RMSprop
从tensorflow.keras.wrappers.scikit_learn导入KerasClassifier
从 skopt 导入 BayesSearchCV
from skopt.space import 实数、分类、整数
将 numpy 导入为 np

# 模型构建函数
def create_model（神经元，dropout，优化器，learning_rate，num_features）：
    模型=顺序（）
    model.add(LSTM(神经元, input_shape=(None, num_features), return_sequences=True))
    model.add(Dropout(dropout))
    model.add(LSTM(神经元, return_sequences=False))
    model.add(Dropout(dropout))
    model.add（密集（1，激活=&#39;sigmoid&#39;））
    opt = get_optimizer(优化器, 学习率)
    model.compile(loss=&#39;binary_crossentropy&#39;, 优化器=opt, 指标=[&#39;准确性&#39;])
    返回模型

# 超参数空间
参数 = {
    &#39;神经元&#39;: 整数(25, 200),
    “辍学”：真实（0.1，0.6），
    &#39;优化器&#39;：分类（[&#39;Adam&#39;，&#39;SGD&#39;，&#39;RMSprop&#39;]），
    &#39;学习率&#39;：真实（0.0001，0.5）
}

# 初始化 KerasClassifier
分类器 = KerasClassifier(build_fn=create_model)

# 设置 BayesSearchCV
bayes_search = BayesSearchCV(
    估计器=分类器，
    搜索空间=参数，
    n_iter=50,
    简历=4，
    详细=10，
    n_职位=-1
）

# 拟合过程中出现错误
bayes_search_result = bayes_search.fit(X_train, Y_train)

运行此代码时，我遇到以下错误：
ValueError：估计器 KerasClassifier 的参数丢失无效。这个问题可以通过在 KerasClassifier 构造函数中设置此参数来解决：“KerasClassifier(dropout=0.4380397544384568)”使用“estimator.get_params().keys()”检查可用参数列表

似乎BayesSearchCV正在尝试直接在dropout参数&gt;KerasClassifier，它与 Keras 模型中处理超参数的方式不兼容。
对于如何使用 BayesSearchCV 和 KerasClassifier 为 Keras 模型正确设置超参数调整的任何见解或建议，我将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77781577/bayessearchcv-with-kerasclassifier-invalid-parameter-error-when-tuning-hyperp</guid>
      <pubDate>Mon, 08 Jan 2024 15:25:28 GMT</pubDate>
    </item>
    <item>
      <title>如何构建多输出回归模型的目标变量？</title>
      <link>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</link>
      <description><![CDATA[我想使用 XGBoost 构建一个多输出模型，其中输出是联系客户时预测的销售情况，例如：

output1 是联系后的预测销售额
output2 是未联系情况下的预测销售额。

我的数据如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

区域
销售类别
在线客户
已联系
促销


&lt;正文&gt;

北
3
1
1
1000


北
2
0
0
600


东
2
0
1
500




我打算将“Contacted”和“Sales”合并在一起，形成两个目标列，如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

区域
销售类别
在线客户
Contacted_Sale
NonContacted_Sale


&lt;正文&gt;

北
3
1
1000
0


北
2
0
0
600


东
2
0
500
0




这是正确的方法吗？零会扰乱模型训练并降低模型的准确性吗？将模型与一个预测联系销售和一个预测非接触销售分开的更好方法是吗？]]></description>
      <guid>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:05:39 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用强化学习为一款严肃的游戏制作一个Python聊天机器人，我如何将它链接到一个统一的2D游戏[关闭]</title>
      <link>https://stackoverflow.com/questions/77780729/i-am-making-a-python-chatbot-for-a-serious-game-using-reinforcement-learning-ho</link>
      <description><![CDATA[我正在开发一个项目来创建一个教育游戏，我希望将一个Python聊天机器人连接到我的游戏中，作为一个自适应NPC来教授这个主题，假设我有Python脚本来运行这个游戏，我会这样做吗？程序
我尝试过机器学习代理，但它们并不完全是我想要的，它们更多的是针对角色的自适应动作，我想要一个用于对话的聊天机器人，另外有些人给了我连接到 chatgpt api 的链接，但我想制作一个离线游戏，在游戏内使用 json 文件存储数据，所以如果有人可以指导我该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/77780729/i-am-making-a-python-chatbot-for-a-serious-game-using-reinforcement-learning-ho</guid>
      <pubDate>Mon, 08 Jan 2024 13:43:00 GMT</pubDate>
    </item>
    <item>
      <title>我使用 XGB 分类器训练了数据集</title>
      <link>https://stackoverflow.com/questions/77776124/ive-trained-dataset-using-xgb-classifier</link>
      <description><![CDATA[我从我的队友那里得到了我们项目的这部分代码，我在本地遇到了这个错误，我已经使用 XGB 分类器训练了数据集。
我的代码是：
# XGBoost 分类器模型
从 xgboost 导入 XGBClassifier

# 实例化模型
xgb = XGBClassifier()

# 拟合模型
xgb.fit(X_train,y_train)

然后我得到了这个错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
[70] 中的单元格，第 8 行
      5 xgb = XGBClassifier()
      7#拟合模型
----&gt; 8 xgb.fit(X_train,y_train)

文件 ~/anaconda3/envs/project/lib/python3.10/site-packages/xgboost/core.py:730，在 require_keyword_args..throw_if..inner_f(*args, **kwargs ）
    728 k, arg in zip(sig.parameters, args)：
    第729章
--&gt;第730章

文件〜/anaconda3/envs/project/lib/python3.10/site-packages/xgboost/sklearn.py:1471，在XGBClassifier.fit（self，X，y，sample_weight，base_margin，eval_set，eval_metric，early_stopping_rounds，verbose， xgb_model、sample_weight_eval_set、base_margin_eval_set、feature_weights、回调）
   第1466章
   第1467章
   第1468章
   第1469章
   第1470章
-&gt;第1471章
   攀上漂亮女局长之后1472 ”
   第1473章
   第1474章
   第1476章
   第1478章

ValueError：从“y”的唯一值推断出无效的类。

预期：[0 1]，得到[-1 1]，，我听说 y_train 必须在较新的更新中进行编码，但我对这些事情有点陌生，我也不知道如何做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/77776124/ive-trained-dataset-using-xgb-classifier</guid>
      <pubDate>Mon, 08 Jan 2024 03:09:32 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 模型不适用于不同宽高比的图片</title>
      <link>https://stackoverflow.com/questions/77774178/tensorflow-model-not-working-with-pics-of-different-aspect-ratios</link>
      <description><![CDATA[在我的模型训练中，我遇到了两个问题：

我的模型只能接受 32x32 图像。
我的模型给出了类似“Class 99”的输出当给定 32x32 图像时。它将狗、汽车和飞机的 32x32 图片都分类为 99 类，而我需要一个清晰的标签。

这是两个问题的图像和代码。
99 级
不同的宽高比
导入tensorflow为tf

提前停止 = tf.keras.callbacks.EarlyStopping(
    监视器=“丢失”，
    最小增量=0，
    耐心=10，
    详细=1，
    模式=“自动”，
    基线=无，
    Restore_best_weights=真，
    从纪元开始=10，
）

与 tf.device(&#39;GPU:0&#39;):
    cifar = tf.keras.datasets.cifar100
    (x_train, y_train), (x_test, y_test) = cifar.load_data()
    模型 = tf.keras.applications.ResNet50(
        include_top=真，
        权重=无，
        输入形状=(32, 32, 3),
        班级=100）

    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)
    model.compile(optimizer=“adam”,loss=loss_fn,metrics=[“accuracy”])
    model.fit（x_train，y_train，epochs = 100，batch_size = 64，callbacks = [earlystopping]）

我不知道在哪里将训练标签放入我的代码中，而且我也不知道如何使其在不拉伸或挤压的情况下以不同的纵横比工作（按原样处理图像）。]]></description>
      <guid>https://stackoverflow.com/questions/77774178/tensorflow-model-not-working-with-pics-of-different-aspect-ratios</guid>
      <pubDate>Sun, 07 Jan 2024 17:51:31 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    </channel>
</rss>