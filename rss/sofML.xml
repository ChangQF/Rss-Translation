<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 26 Dec 2023 15:13:50 GMT</lastBuildDate>
    <item>
      <title>机器学习的并行计算使用相同的随机种子产生不同的结果</title>
      <link>https://stackoverflow.com/questions/77717258/parallel-computing-with-machine-learning-produces-different-results-with-the-sam</link>
      <description><![CDATA[使用sklearn.model_selection.RandomizedSearchCV函数。参数列表是在使用np.random.seed(42)后获取的，应该修复。并且每一步都添加了random_state=42。 ShuffleSplit 用于函数分区；
部分代码片段如下：
&lt;前&gt;&lt;代码&gt;my_seed = 42
RandomizedSearchCV(估计器=模型，param_distributions=param_distributions，n_iter=Random_search_n_iter_list\[i\],
cv=ShuffleSplit(test_size=0.3, train_size=0.7, n_splits=10,random_state=my_seed),random_state=my_seed,scoring=“准确度”)

所以我猜这是因为并行计算导致机器学习在采用相同的随机种子后会产生不同的结果。我们该如何解决这个问题呢？或者我在随机过程本身中犯了一个错误？]]></description>
      <guid>https://stackoverflow.com/questions/77717258/parallel-computing-with-machine-learning-produces-different-results-with-the-sam</guid>
      <pubDate>Tue, 26 Dec 2023 12:34:26 GMT</pubDate>
    </item>
    <item>
      <title>我对机器学习中的分类数据编码有两个疑问。建议我如何更好地编码，这将非常有帮助</title>
      <link>https://stackoverflow.com/questions/77717254/i-have-two-doubts-related-to-encoding-categorical-data-in-machine-learning-advi</link>
      <description><![CDATA[
假设我想在 pd.iloc[] 中添加两个不同范围的列和所有行，该怎么做？
我知道您可以通过 pd.iloc[:, [0,2,3] 添加多列。但如果我们想添加两个范围，例如 0:2 和 7:9，那么我们应该怎么做呢？

下面的代码显示了错误 - ValueError: y 应该是一个一维数组，而是得到了一个 shape () 数组。


&lt;小时/&gt;
# 导入必要的库
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd
从 sklearn.impute 导入 SimpleImputer
从 sklearn.compose 导入 ColumnTransformer
从 sklearn.preprocessing 导入 OneHotEncoder
从 sklearn.preprocessing 导入 LabelEncoder

# 加载数据集
df = pd.read_csv(&#39;泰坦尼克号.csv&#39;)
X = df.drop(“幸存”, axis=1)
y = df[“幸存”]

# 识别分类数据
categorical_data = [&#39;Pclass&#39;, &#39;性别&#39;, &#39;登船&#39;]

# 实现 ColumnTransformer 类的实例
ct = ColumnTransformer(transformers = [(&#39;编码器&#39;, OneHotEncoder, categorical_data)], 余数 = &#39;passthrough&#39;)

# 对 ColumnTransformer 实例应用 fit_transform 方法
X = ct.fit_transform(X)

# 将输出转换为 NumPy 数组
X = np.array(X)

# 使用 LabelEncoder 对二进制分类数据进行编码
le = 标签编码器()
y = le.fit_transform(&#39;幸存&#39;)

# 打印更新后的特征矩阵和因变量向量
打印（X）
打印（y）

这段代码有什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77717254/i-have-two-doubts-related-to-encoding-categorical-data-in-machine-learning-advi</guid>
      <pubDate>Tue, 26 Dec 2023 12:33:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Synthesia 风格的视频转换为 Midi 文件？</title>
      <link>https://stackoverflow.com/questions/77717140/how-can-i-convert-a-synthesia-style-video-to-a-midi-file</link>
      <description><![CDATA[我正在尝试找出一些方法来使用 Python 将一些合成风格的视频转换为 midi 文件。视频如下所示： 
我在研究将提取的数据转换为 Midi 的方法时没有遇到问题，因为有大量的资源，但我找不到从视频中提取数据的有效方法。
基本的运动检测不起作用，因为手和粒子也被标记为移动物体（显然）。
有什么方法可以做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/77717140/how-can-i-convert-a-synthesia-style-video-to-a-midi-file</guid>
      <pubDate>Tue, 26 Dec 2023 12:04:15 GMT</pubDate>
    </item>
    <item>
      <title>我的模型在训练后预测完全相反的值。 （即将圆的内部值预测为外部，将外部值预测为内部）</title>
      <link>https://stackoverflow.com/questions/77716617/my-model-is-predicting-completely-opposite-values-after-training-i-e-predicti</link>
      <description><![CDATA[制作数据集
from sklearn.datasets import make_circles
n_样本=1000
x, y = make_circles(n_samples, 噪声=0.03, random_state=42)
X = torch.from_numpy(x).type(torch.float)
Y = torch.from_numpy(y).type(torch.float)
从 sklearn.model_selection 导入 train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=42)

模型（预测圆）（我们知道圆的方程 s (x**2 + y**2 = r**2)
类 cp(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.r = nn.Parameter(torch.randn(1, require_grad = True, dtype=torch.float))
    def 前向（自身，x）：
        返回 x[:, 0]**2 + x[:, 1]**2 - self.r**2
火炬.manual_seed(42)
米 = cp()
loss_fn = nn.BCEWithLogitsLoss()
opt = torch.optim.SGD(params = m.parameters(), lr=0.1)

训练循环
&lt;前&gt;&lt;代码&gt;e = 1000
对于范围 (e+1) 内的 i：
    m.train()
    p = m(xtrain).squeeze()
    f = torch.round(torch.sigmoid(p))
    l = loss_fn(p, ytrain)
    acc = precision_fn(f, ytrain)
    opt.zero_grad()
    l.backward()
    opt.step()
    如果（i%10==0）：
        使用 torch.inference_mode()：
            tp = m(xtest).squeeze()
            tf= 火炬.round(火炬.sigmoid(tp))
            tl = loss_fn(tp, ytest)
            tacc = precision_fn(tf, ytest)
            print(f&quot;epoch: {i} | 训练损失: {l:.4f} | 训练 acc: {acc} | 测试损失: {tl:.4f} | 测试 acc: {tacc}&quot;)
            if(i%100==0): 打印(m.state_dict())

如果我按照上述方式训练模型，它会预测 1 为 0，O 为 1。
IE。 ytrain[:10] = 张量([1., 0., 0., 0., 1., 0., 1., 1., 0., 0.])。预测值为： torch.round(torch.sigmoid(m(xtrain[:10]))) = tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1.])
但是，当我绘制圆时，它的预测正确（圆的半径预测正确）
预测圆
我试图预测一个圆。里面都是0，外面都是1。但训练后，它以相反的顺序进行预测（即外部 0 和内部 1）。请检查一次。我已经提供了完整的代码。]]></description>
      <guid>https://stackoverflow.com/questions/77716617/my-model-is-predicting-completely-opposite-values-after-training-i-e-predicti</guid>
      <pubDate>Tue, 26 Dec 2023 09:49:49 GMT</pubDate>
    </item>
    <item>
      <title>人工智能公司的投资回报率场景[关闭]</title>
      <link>https://stackoverflow.com/questions/77716540/roi-scenario-of-company-in-ai</link>
      <description><![CDATA[我想创建一个基于公司数据的应用程序，它会生成许多投资回报率方案，而不仅仅是投资回报率，您知道有什么可以帮助我的吗？另外，如果您有任何 Github 存储库，请在下面提及
我想要解决此问题的 Github 存储库]]></description>
      <guid>https://stackoverflow.com/questions/77716540/roi-scenario-of-company-in-ai</guid>
      <pubDate>Tue, 26 Dec 2023 09:30:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 val_loss 曲线看起来这么奇怪？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77716410/why-does-my-val-loss-curve-look-so-strange</link>
      <description><![CDATA[类 myResidualBlock1DSample(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, use_1x1conv=False):
        超级（myResidualBlock1DSample，自我）.__init__（）
        self.conv1 = nn.Conv1d(in_channels, out_channels//2, kernel_size, stride, padding=1)
        self.bn1 = nn.BatchNorm1d(out_channels//2)
        self.relu = nn.ReLU()
        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv1d(out_channels//2, out_channels, kernel_size, stride, padding=1)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)
        如果使用_1x1conv：
            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)
            self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)
        别的：
            self.conv3 = 无
            self.pool3 = 无

    def 前向（自身，x）：
        输出 = self.conv1(x)
        输出 = self.bn1(输出)
        输出 = self.relu(输出)
        输出 = self.pool1(输出)
        输出 = self.conv2(输出)
        输出 = self.bn2(输出)
        输出 = self.pool2(输出)
        如果 self.conv3：
            x = self.conv3(x)
            x = self.pool3(x)
        输出 += x
        输出 = self.relu(输出)
        返回


类 myResidualBlock1DUpsample(nn.Module)：
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, use_1x1conv=False):
        超级（myResidualBlock1DUpsample，自我）.__init__（）
        self.conv1 = nn.Conv1d(in_channels, in_channels//2, kernel_size, stride, padding=1)
        self.bn1 = nn.BatchNorm1d(in_channels//2)
        self.relu = nn.ReLU()
        self.upsample1 = nn.Upsample(scale_factor=2, mode=&#39;线性&#39;)
        self.conv2 = nn.Conv1d(in_channels//2, out_channels, kernel_size, stride, padding=1)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.upsample2 = nn.Upsample(scale_factor=2, mode=&#39;线性&#39;)
        如果使用_1x1conv：
            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)
            self.upsample3 = nn.Upsample(scale_factor=4, mode=&#39;线性&#39;)
        别的：
            self.conv3 = 无
            self.upsample3 = 无

    def 前向（自身，x）：
        输出 = self.conv1(x)
        输出 = self.bn1(输出)
        输出 = self.relu(输出)
        输出 = self.upsample1(输出)
        输出 = self.conv2(输出)
        输出 = self.bn2(输出)
        输出 = self.upsample2(输出)
        如果 self.conv3：
            x = self.conv3(x)
            x = self.upsample3(x)
        输出 += x
        输出 = self.relu(输出)
        返回


类 ResidualAutoencoder1Dv2(nn.Module):
    def __init__(自身):
        超级().__init__()
        #编码器
        self.res1 = myResidualBlock1DSample(1, 32, use_1x1conv=True)
        self.res2 = myResidualBlock1DSample(32, 128, use_1x1conv=True)
        self.res5 = myResidualBlock1DSample(128,512,use_1x1conv=True)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(5120, 4096)
        self.fc2 = nn.Linear(4096, 2048)
        self.fc3 = nn.Linear(2048, 1024)
        self.dropout = nn.Dropout(p=0.2)
        self.fc4 = nn.Linear(1024, 4)
        self.relu = nn.ReLU()
        #解码器
        self.fc5 = nn.Linear(4, 47)
        self.conv1 = nn.Conv1d(1, 128, kernel_size=3, stride=1)#序列长度变成45
        self.res3 = myResidualBlock1DUpsample(128, 32, use_1x1conv=True)
        self.res4 = myResidualBlock1DUpsample(32, 1, use_1x1conv=True)
        self.fc6 = nn.Linear(720,700)

    def 前向（自身，x）：
        #编码器
        x = self.res1(x)
        x = self.res2(x)
        x = self.res5(x)
        x = self.展平(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.relu(x)
        x = self.dropout(x)
        编码输出 = self.fc4(x)
        #解码器
        x = self.fc5(编码输出)
        x = x.unsqueeze(1)
        x = self.conv1(x)
        x = self.res3(x)
        x = self.res4(x)
        解码输出 = self.fc6(x)
        返回编码输出、解码输出


为什么我的损失曲线晃动这么大？事实上，曲线仍然可以下降到低点。我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77716410/why-does-my-val-loss-curve-look-so-strange</guid>
      <pubDate>Tue, 26 Dec 2023 08:53:40 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>在本地计算机中设置 UDpipe 服务器</title>
      <link>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</guid>
      <pubDate>Tue, 26 Dec 2023 06:18:57 GMT</pubDate>
    </item>
    <item>
      <title>ML Kit 的姿势检测模型不适用于 Flutter</title>
      <link>https://stackoverflow.com/questions/77715363/ml-kits-pose-detection-model-not-working-on-flutter</link>
      <description><![CDATA[我们需要一个InputImage实例来检测身体的关键点，但是“null”正在退货。
将文件路径传递给InputImage.fromFilePath()：
最终InputImage inputImage = InputImage.fromFilePath(&#39;/assets/images/girl.png&#39;);
打印（inputImage.bytes）； // 输出：空

相同的文件，使用相同的文件路径，并且正在显示图像：
&lt;前&gt;&lt;代码&gt;@覆盖
  小部件构建（BuildContext上下文）{
    返回常量中心（
      孩子：图像（
        image: AssetImage(&#39;assets/images/girl.png&#39;) // 这有效
      ),
    ）；
  }
]]></description>
      <guid>https://stackoverflow.com/questions/77715363/ml-kits-pose-detection-model-not-working-on-flutter</guid>
      <pubDate>Tue, 26 Dec 2023 01:37:57 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 执行情感分析 [关闭]</title>
      <link>https://stackoverflow.com/questions/77714420/how-can-i-perform-sentiment-analysis-using-python</link>
      <description><![CDATA[有人可以帮我解释一下 python 代码吗，因为我是一个尝试做项目的初学者。请亲自联系我，以便我可以分享我的代码，因为我非常紧急地需要代码方面的帮助...
尝试对社交媒体帖子进行情感分析，但在执行算法时遇到问题。]]></description>
      <guid>https://stackoverflow.com/questions/77714420/how-can-i-perform-sentiment-analysis-using-python</guid>
      <pubDate>Mon, 25 Dec 2023 17:08:37 GMT</pubDate>
    </item>
    <item>
      <title>我有带有标签和模式的 json 意图文件，我需要为我的 FYP 创建聊天机器人</title>
      <link>https://stackoverflow.com/questions/77712864/i-have-json-intent-file-with-tags-and-patterns-and-i-need-to-create-chatbot-from</link>
      <description><![CDATA[我正在创建心理健康聊天机器人，并且我有带有标签和模式的 json 数据意图文件。这是我的五年计划，我不知道从哪里开始为聊天机器人创建模型，我需要一些好的建议和简单的步骤来创建我自己的聊天机器人模型]]></description>
      <guid>https://stackoverflow.com/questions/77712864/i-have-json-intent-file-with-tags-and-patterns-and-i-need-to-create-chatbot-from</guid>
      <pubDate>Mon, 25 Dec 2023 07:42:43 GMT</pubDate>
    </item>
    <item>
      <title>用于实时流处理的 Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</link>
      <description><![CDATA[我正在 aws 上对实时视频流进行实时机器学习处理。
对于直播，正在使用 kinesis 视频流。
我正在从模型工件（存储我们的推理脚本和模型文件的位置）创建 sagemaker 端点
当我们从实时流中获取它们时，每个帧都会独立调用此端点。
挑战在于维护变量的缓存/会话状态。当每个帧到达端点时，它没有有关先前运行的结果的信息。为了解决这个问题，我为每次调用下载缓存并将其上传到数据库（dynamo db），这似乎是一种低效的方法。
供参考 - 我在推理脚本中使用 pytorch 框架中外部训练的 YOLO 对象检测模型。
所以我的问题是-
如何维护一个活动的 sagemaker 实例，它可以监听实时流和进程生成的帧？该实例应维护其流的会话状态，并应通过实时流自动调用。]]></description>
      <guid>https://stackoverflow.com/questions/77702505/sagemaker-endpoint-for-processing-on-live-stream</guid>
      <pubDate>Fri, 22 Dec 2023 08:28:38 GMT</pubDate>
    </item>
    <item>
      <title>从 Keras model.evaluate 和 model.predict 获得不同的结果</title>
      <link>https://stackoverflow.com/questions/57212021/getting-different-results-from-keras-model-evaluate-and-model-predict</link>
      <description><![CDATA[我已经使用 word2vec 训练了一个模型来预测主题类别，并使用 keras 训练了一个 lstm 模型，并且在训练期间获得了大约 98% 的准确率，我保存了模型，然后将其加载到另一个文件中以在测试集上进行尝试，我使用了 model.evaluate 和 model.predict 结果非常不同。
我使用keras和tensorflow作为后端，模型摘要是：

&lt;前&gt;&lt;代码&gt;_________________________________________________________________
层（类型）输出形状参数#
=================================================== ===============
lstm_1（LSTM）（无，22）19624
_________________________________________________________________
dropout_1（辍学）（无，22）0
_________________________________________________________________
密集_1（密集）（无，40）920
_________________________________________________________________
activation_1（激活）（无，40）0
=================================================== ===============
总参数：20,544
可训练参数：20,544
不可训练参数：0
_________________________________________________________________
没有任何

代码：
model.compile（loss=&#39;binary_crossentropy&#39;，optimizer=&#39;adam&#39;，metrics=[&#39;accuracy&#39;]）
model.load_weights(os.path.join(&#39;model&#39;, &#39;lstm_model_weights.hdf5&#39;))
分数，acc = model.evaluate（x_test，y_test，batch_size=batch_size）

打印（）
print(&#39;分数：%1.4f&#39; % 分数)
print(&#39;评估准确度：%1.2f%%&#39; % (acc*100))

预测= model.predict(x_test,batch_size=batch_size)
acc2 = np.count_nonzero(预测.argmax(1) == y_test.argmax(1))/y_test.shape[0]
print(&#39;预测精度：%1.2f%%&#39; % (acc2*100))

这段代码的输出是

&lt;前&gt;&lt;代码&gt;39680/40171 [==============================&gt;.] - 预计到达时间：0 秒
得分：0.1192
评估准确率：97.50%
预测准确率：9.03%

谁能告诉我我错过了什么？]]></description>
      <guid>https://stackoverflow.com/questions/57212021/getting-different-results-from-keras-model-evaluate-and-model-predict</guid>
      <pubDate>Fri, 26 Jul 2019 01:29:13 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”</title>
      <link>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</link>
      <description><![CDATA[我正在尝试使用最新的可用资源来开发一些时间序列序列预测。为此，我确实检查了 TensorFlow 时间序列中的示例代码，但收到此错误：
AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”

我正在使用 Anaconda。当前环境是Python 3.5和TensorFlow 1.2.1。也尝试过 TensorFlow 1.3，但没有任何改变。
这是我的代码尝试运行。我在谷歌上没有找到与该问题相关的任何有用信息。有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</guid>
      <pubDate>Sat, 02 Sep 2017 04:48:51 GMT</pubDate>
    </item>
    <item>
      <title>张量流，我想改变输入图像大小</title>
      <link>https://stackoverflow.com/questions/41703944/tensorflow-i-want-to-change-input-image-size</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/41703944/tensorflow-i-want-to-change-input-image-size</guid>
      <pubDate>Tue, 17 Jan 2017 17:59:58 GMT</pubDate>
    </item>
    </channel>
</rss>