<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 20 May 2024 03:16:50 GMT</lastBuildDate>
    <item>
      <title>我想将分位数回归转换为线性规划问题，我该如何解决这个问题</title>
      <link>https://stackoverflow.com/questions/78504275/i-want-to-convert-quantile-regression-into-a-linear-programming-problem-how-can</link>
      <description><![CDATA[我想要分位数回归（转换为线性规划问题，使用sklearn方法解决，但不使用sklearn代码，需要重写，并且不能使用库）代码，klearn是一个软件的界面来解决，有什么解决办法吗？
我尝试使用sklean中的代码，但发现最后是用软件解决的，而且没有解决的代码]]></description>
      <guid>https://stackoverflow.com/questions/78504275/i-want-to-convert-quantile-regression-into-a-linear-programming-problem-how-can</guid>
      <pubDate>Mon, 20 May 2024 00:41:50 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析是否适用于 HU 矩特征 [关闭]</title>
      <link>https://stackoverflow.com/questions/78504177/is-principal-component-analysis-applicable-to-hu-moments-features</link>
      <description><![CDATA[我正在尝试改进使用色相矩作为特征的图像分类应用程序的结果，但当我应用 pca 时，只有一个特征可以弥补方差的 0.95。
我对原始 Hu 特征执行了以下步骤来查找投影矩阵：

标准化
计算协方差
使用 Eigen 库查找特征向量和值
选择构成方差 0.8 的特征向量并丢弃其余的。
结果是一个 1 到 X 矩阵（只有一个特征覆盖了方差的 0.98）
]]></description>
      <guid>https://stackoverflow.com/questions/78504177/is-principal-component-analysis-applicable-to-hu-moments-features</guid>
      <pubDate>Sun, 19 May 2024 23:29:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么在多元线性回归中计算梯度时要对矩阵进行转置？</title>
      <link>https://stackoverflow.com/questions/78504139/why-is-the-matrix-transposed-when-calculating-the-gradient-in-a-multiple-linear</link>
      <description><![CDATA[我正在参加在线机器学习课程，在谈到多变量线性回归时，他们使用以下函数来计算梯度：
def gradient(X, Y, w):
return 2 * np.matmul(X.T, (predict(X, w) - Y)) / X.shape[0]

X 是一个包含数据的矩阵，Y 是一个包含结果的单列矩阵，w 是一个包含权重的单列矩阵。predict(W, w) 返回模型对当前权重的预测，其格式与 Y 相同。
我熟悉使用函数的偏导数来查找模型与该权重的局部最小值的接近程度的想法，但我不明白为什么我需要 X 矩阵为转置形式来进行此计算。我可以只计算每个偏导数并将其用作单独的梯度吗？]]></description>
      <guid>https://stackoverflow.com/questions/78504139/why-is-the-matrix-transposed-when-calculating-the-gradient-in-a-multiple-linear</guid>
      <pubDate>Sun, 19 May 2024 23:04:23 GMT</pubDate>
    </item>
    <item>
      <title>没有数据标准化的PCA比标准化后的性能更好，为什么？</title>
      <link>https://stackoverflow.com/questions/78504113/pca-without-data-normalization-performes-better-than-after-normalization-why</link>
      <description><![CDATA[我有这个 Spotify 数据集，其中包含大约 100k 条记录和 28 个混合数值（离散和连续）和二进制的特征，一些数值变量有很多零值。
我想要执行机器学习分类，对 113 种类型进行分类，数量之多。我想要通过强大的主成分分析来改进我的模型。但我很困惑为什么标准化数据（我使用标准缩放器）的准确性比没有标准化时要差得多。
首先，在数据预处理之后，我执行简单的决策树分类器（在超参数调整之后）并获得 43% 的准确率。

然后，我执行主成分分析 (PCA) 以减少特征数量，以便对数据进行聚类以减少类别数量，并更轻松地检测和可视化异常值。

据我所知，在部署PCA之前，我的数据需要标准化（我在这里使用StandardScaler）。然而我发现，如果没有标准化，我的决策树分类器的一维 PCA 的性能会提高到 51%。相反，通过归一化，2 维的准确度降低到只有 5%，这是我需要的。


这怎么可能？如何提高算法性能？
我的代码
&lt;前&gt;&lt;代码&gt;
pca = PCA(n_components=20) # 我在这里尝试了很多值，因为精度随着更多组件的增加而增加
pca.fit(X_train_norm)
X_train_pca = pca.transform(X_train_norm)

＃ 决策树
X_test_pca = pca.transform(X_test_norm)

dt = DecisionTreeClassifier(min_samples_leaf = 3,random_state=42)
dt.fit(X_train_pca, y_train)

y_pred = dt.predict(X_test_pca)

print(&#39;准确率 %s&#39; % precision_score(y_test, y_pred))
print(&#39;F1-score %s&#39; % f1_score(y_test, y_pred, 平均值=无))
打印（分类报告（y_test，y_pred））

pca_all = PCA(n_components=25)
pca_all.fit(X_train_norm)
X_train_pca = pca_all.transform(X_train_norm)
explained_variance = pca_all.explained_variance_ratio_

plt.figure(figsize=(10, 6))
plt.bar（范围（len（explained_variance）），explained_variance，alpha=0.7，align=&#39;center&#39;，
        label=&#39;个体解释方差&#39;)
plt.step(range(len(explained_variance)), np.cumsum(explained_variance), where=&#39;mid&#39;,
         label=&#39;累积解释方差&#39;)
plt.xlabel(&#39;主成分索引&#39;)
plt.ylabel(&#39;解释方差比率&#39;)
plt.legend(loc=&#39;最佳&#39;)
plt.title(&#39;归一化后主成分解释的方差&#39;)
plt.grid()
plt.show()


我附上了标准化后（圆形）和未标准化（肘形）的主成分分析的数据分布。颜色代表流派。还有我的 PCA 的方差可解释性 [pca_without_normalization](https://i.sstatic.net/HaDoNROy.png)pca_with_normalizationpca_explanability_without_normalization]]></description>
      <guid>https://stackoverflow.com/questions/78504113/pca-without-data-normalization-performes-better-than-after-normalization-why</guid>
      <pubDate>Sun, 19 May 2024 22:44:16 GMT</pubDate>
    </item>
    <item>
      <title>为数字手写识别问题定义自动机[关闭]</title>
      <link>https://stackoverflow.com/questions/78504083/defining-an-automata-for-the-digits-handwritten-recognition-problem</link>
      <description><![CDATA[大家好，你们能帮我吗，我仍然不知道如何定义我的自动机，也不知道它和手写识别过程之间的关系是什么，基本上我在定义转换、状态和字母方面遇到问题。
这是使用张量流和 MNIST 数据集进行手写数字识别的代码，但如何定义我的自动机？？？
`导入操作系统
导入CV2
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将张量流导入为 tf

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = tf.keras.utils.normalize(x_train, axis=1)
x_test = tf.keras.utils.normalize(x_test, axis=1)

模型 = tf.keras.models.Sequential()
model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))
model.add(tf.keras.layers.Dense(128，激活=tf.nn.relu))
model.add(tf.keras.layers.Dense(128，激活=tf.nn.relu))
model.add(tf.keras.layers.Dense(128，激活=tf.nn.relu))
model.add(tf.keras.layers.Dense(10, 激活=tf.nn.softmax))
model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;sparse_categorical_crossentropy&#39;,
              指标=[&#39;准确性&#39;])
model.fit(x_train, y_train, epochs=20)
model.save(&#39;手写.model&#39;)

model = tf.keras.models.load_model(&#39;手写.model&#39;)
损失，准确度 = model.evaluate(x_test, y_test)`
打印（丢失）
打印（准确度）

img = cv2.imread(&#39;img.5.png&#39;)[:,:,0]
img = cv2.resize(img, (28, 28))
img = np.invert(np.array([img]))
预测 = model.predict(img)
print(f&quot;该数字可能是 {np.argmax(prediction)}&quot;)
plt.imshow(img[0], cmap=plt.cm.binary)
plt.show()`
]]></description>
      <guid>https://stackoverflow.com/questions/78504083/defining-an-automata-for-the-digits-handwritten-recognition-problem</guid>
      <pubDate>Sun, 19 May 2024 22:26:28 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型的小批量实现的奇怪绘图模式</title>
      <link>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</guid>
      <pubDate>Sun, 19 May 2024 19:05:35 GMT</pubDate>
    </item>
    <item>
      <title>文本到 Openpose 和奇怪的 RNN 错误</title>
      <link>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</link>
      <description><![CDATA[我想创建从文本描述生成 openpose 的 AI，例如输入“一个男人在跑步”输出将像我提供的图像一样，有没有推荐给我的模型架构？
我的数据条件是

canvas_width: 900px
canvas_height: 300px
帧数：5（5 人）

预期输出
我尝试为这项任务训练 RNN，我使用句子转换器嵌入文本，然后传递给 RNN，损失如下图所示
from sentence_transformers import SentenceTransformer 
sentence_model = SentenceTransformer(&quot;all-MiniLM-L6-v2&quot;)
text = &quot;a man running&quot;
text_input = torch.tensor(sentence_model.encode(text), dtype=torch.float)

loss image with num_layers=3
我的 RNN 设置
embedding_dim = 384
hidden_​​dim = 512
num_layers = 3
output_dim = 180
num_epochs = 100
learning_rate = 0.001
rnn_model = RNN(embedding_dim, hidden_​​dim, num_layers, output_dim)

但问题是无论我输入什么，输出每次都是一样的！但是当我尝试将 num_layers 更改为 1 并保持其他设置相同时，如下所示
embedding_dim = 384
hidden_​​dim = 512
num_layers = 1
output_dim = 180
num_epochs = 100
learning_rate = 0.001
rnn_model = RNN(embedding_dim, hidden_​​dim, num_layers, output_dim)

损失现在看起来像这样
num_layers=1 的损失图像
现在问题已经解决！！
我还尝试检查“每次输出都相同”的原因问题我检查了 dataloader 和其他代码，但没有发现问题只有 num_layers=3 导致问题 num_layers=1 修复了它
这是我的训练循环
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)

trainingEpoch_loss = []
validationEpoch_loss = []

for epoch in range(num_epochs):
    step_loss = []
    rnn_model.train()
    for idx, train_inputs in enumerate(train_dataloader):
        optimizer.zero_grad()
        output = rnn_model(torch.unsqueeze(train_inputs[&#39;text&#39;], dim=0))
       training_loss = 标准（输出，train_inputs [&#39;poses&#39;]）
        training_loss.backward（）
        optimizer.step（）
        step_loss.append（training_loss.item（））

        if（idx+1）％1 == 0：打印（f&#39;Epoch [{epoch+1}/{num_epochs}]，Step [{idx+1}/{len（train_dataloader）}]，损失：{training_loss.item（）：.4f}&#39;）
    trainingEpoch_loss.append（np.array（step_loss）。mean（））

    rnn_model.eval（）
    for idx，val_inputs in enumerate（val_dataloader）：
      validationStep_loss = []
      输出= rnn_model(torch.unsqueeze(val_inputs[&#39;text&#39;], dim=0))
      val_loss = criterion(outputs, val_inputs[&#39;poses&#39;])
      validationStep_loss.append(val_loss.item())
    validationEpoch_loss.append(np.array(validationStep_loss).mean())

这是我的推论
text = &quot;a man running&quot;
processing_text = torch.tensor(sentence_model.encode(text), dtype=torch.float)
output_poses = rnn_model(processed_text.unsqueeze(0))
print(output_poses.shape) #shape=(1, 180) 1 个人是 36（1 个人的原始数据是 54，但我将其更改为 36，因为我只想要 x 和 y 而不是 z，所以剪掉 z 轴）并且有 5 个人，所以 5*36 = 180

我的问题是

除了 RNN 之外，还有其他模型架构推荐用于此任务吗？
为什么无论我输入什么，每次 num_layers=3 时输出都相同，我很困惑，因为如果模型给出相同的输出，损失就不会下降，对吗？这意味着它在推理阶段给出相同的输出

预期答案

最适合我的任务的模型架构，任何论文或 github repo 相关内容都将不胜感激
回答为什么无论我输入什么，当 num_layers=3 时输出都是相同的
]]></description>
      <guid>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</guid>
      <pubDate>Sun, 19 May 2024 17:37:20 GMT</pubDate>
    </item>
    <item>
      <title>'无法解析方法'startActivity(Intent)''和'无法解析 MainActivity 上的构造函数'Intent(MainActivity, Class<CombineLettersActivity>)'' [重复]</title>
      <link>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</link>
      <description><![CDATA[我正在按照此播放列表开发手语翻译应用。
我遇到以下错误：
无法解析方法“startActivity(Intent)”
无法解析构造函数“Intent（MainActivity，Class）”
无法解析构造函数“Intent（MainActivity，Class）”
以下是相关代码片段：
&lt;前&gt;&lt;代码&gt;@Override
protected void onCreate(Bundle savingInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    camera_button = findViewById(R.id.camera_button);
    camera_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看v）{
            startActivity(new Intent(MainActivity.this, CameraActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });

    merge_letter_button = findViewById(R.id.combine_letter_button);
    merge_letter_button.setOnClickListener(new View.OnClickListener() {
        @覆盖
        公共无效onClick（查看视图）{
            startActivity(new Intent(MainActivity.this，CombineLettersActivity.class).addFlags(Intent.FLAG_ACTIVITY_CLEAR_TASK | Intent.FLAG_ACTIVITY_CLEAR_TOP));
        }
    });
}


我尝试更改 Gradle 和 JDK 版本，但问题仍然存在。与我一起参与该项目的一位朋友也尝试解决该问题，但我们尚未成功。
任何帮助将不胜感激。感谢您的时间和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78502999/cannot-resolve-method-startactivityintent-and-cannot-resolve-constructor</guid>
      <pubDate>Sun, 19 May 2024 15:03:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 CoLab 中仅运行部分代码</title>
      <link>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</link>
      <description><![CDATA[我目前正在做一个图像识别项目，模型执行之前的预处理步骤需要相当长的时间。当模型出现错误时，我必须从头开始重新运行所有内容，这是非常耗时的。有没有办法避免从头开始运行整个流程而只执行模型部分？
如果代码没有从头开始执行，则初始部分中的包安装和标签部分将无法正常运行。]]></description>
      <guid>https://stackoverflow.com/questions/78502926/how-to-run-only-part-of-the-code-in-colab</guid>
      <pubDate>Sun, 19 May 2024 14:37:50 GMT</pubDate>
    </item>
    <item>
      <title>如何判断我的 Datasat 是否服从高斯分布？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</link>
      <description><![CDATA[我正在遵循一些有关进行线性回归的教程，并且在构建笔记本时，我正在研究异常值检测，并且在用于进行异常值检测的技术中，其中之一涉及计算标准偏差，但是对于我需要知道我的列是否属于高斯分布。我知道有不同的技术，例如：
直方图
KDE 图
Q-Q图
科洛莫戈洛夫-斯米尔诺夫检验
夏皮罗-威尔克检验
达戈斯蒂诺和皮尔逊检验
我敢打赌还有更多。那么最好使用哪一种呢？我想直方图只是提供了线索，但并没有显示出真正的意图。识别数据集是否为高斯数据的标准做法是什么？例如，我绘制了波士顿数据集和 RM 列的直方图（每间住宅的平均房间数），我发现它是高斯分布：

但是当我使用 shapiro 和 kstest 时，它说 RM 不是高斯！
对于 X.columns 中的 i：
    print(f&#39;{i}: {“非高斯” if shapiro(X[i])[1]&lt;0.05 else “高斯”} {shapiro(X[i])}&#39;)
    print(f&#39;{i}: {“非高斯” if kstest(X[i].values,“范数”)[1]&lt;0.05 else “高斯”} {kstest(X[i].values) ,“标准”)}&#39;)

上面的代码打印：
RM：非高斯 ShapiroResult（统计=0.9608722575483464，pvalue=2.411976537849353e-10）
RM：非高斯 KstestResult（统计=0.9998152774582629，pvalue=0.0，statistic_location=3.561，statistic_sign=-1）

怎么会这样呢？我应该相信什么？]]></description>
      <guid>https://stackoverflow.com/questions/78502864/how-to-say-if-my-datasat-is-a-gaussian-distribution-or-not</guid>
      <pubDate>Sun, 19 May 2024 14:15:12 GMT</pubDate>
    </item>
    <item>
      <title>如何解决pickle.load()中的内存错误？</title>
      <link>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</link>
      <description><![CDATA[with open(r&#39;..\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
    glove_embedding = pickle.load（fp）

回溯（最近一次调用最后一次）
    [39] 中的单元格，第 2 行
          1 以 open(r&#39;D:\NuVision\Sentiment Analysis\glove\glove.840B.300d.pkl&#39;, &#39;rb&#39;) 作为 fp：
    ----&gt; 2 glove_embedding = pickle.load(fp)
    
    内存错误：

glove.pkl 大约有 3 GB，如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78502721/how-to-solve-memory-error-in-pickle-load</guid>
      <pubDate>Sun, 19 May 2024 13:24:24 GMT</pubDate>
    </item>
    <item>
      <title>名称特征不匹配 ML [关闭]</title>
      <link>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</guid>
      <pubDate>Sun, 19 May 2024 05:37:27 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中运行不佳 [关闭]</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 python 写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def preprocess_image(image_path):
    # 想象中的卡里卡
    img = Image.open(图像路径)
    # 在 scala di grigi 中进行想象和转换
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将 l&#39;immagine 转换为 un array numpy 并将 Ridimensiona 转换为 un unico vettare
    img_array = np.array(img).reshape(1, -1)
    返回img_array
*强调文字*
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;成功模型&quot;)
    # 模型用途
    # Carica e pre-elabora un&#39;immagine
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # Prevedere la classe del nuovo esempio
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

在橙色工作流程中，我使用了逻辑回归，该模型的准确性相当高。在图像嵌入中我使用了 Inception v3。 这是我获取数据集的位置。我认为我预处理图像的方式有问题，也许它与Orange方法不同，但我无法解决问题 这是橙色工作流程的图像。
编辑：我还尝试在输入中提供一个图像文件夹，结果并不总是相同，但在包含 500 张猫和狗照片的文件夹中，模型只能识别 10 只狗（对绝大多数狗进行错误分类）]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    <item>
      <title>使用梯度下降时，线性回归模型的训练误差和测试误差非常相似[关闭]</title>
      <link>https://stackoverflow.com/questions/78480089/the-training-error-and-testing-error-is-very-similiar-for-linear-regression-mode</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78480089/the-training-error-and-testing-error-is-very-similiar-for-linear-regression-mode</guid>
      <pubDate>Tue, 14 May 2024 18:43:35 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 HuggingFace Transformers Pipeline 在每个提示（如 vLLM）中生成多个文本补全而不触发错误？</title>
      <link>https://stackoverflow.com/questions/78466376/how-to-generate-multiple-text-completions-per-prompt-like-vllm-using-huggingfa</link>
      <description><![CDATA[我正在使用 HuggingFace Transformers Pipeline 库为给定提示生成多个文本完成。我的目标是利用像 GPT-2 这样的模型来生成不同的可能完成结果，例如 vLLM 中的默认值。但是，当我尝试指定 max_length 和 num_return_sequences 等参数时，我遇到了未使用 model_kwargs 的问题。
这是我正在使用的代码片段：
复制代码
从变压器导入 GPT2Tokenizer、GPT2LMHeadModel、管道
从输入导入列表，字典

def process_prompts(提示: List[str], 模型: GPT2LMHeadModel, tokenizer: GPT2Tokenizer, num_completions: int = 3) -&gt;列表[列表[str]]：
    device = 0 if model.device.type == &#39;cuda&#39; else -1
    text_generator = pipeline(“文本生成”, model=model, tokenizer=tokenizer, device=device)
    输出 = []

    对于提示中的提示：
        尝试：
            结果= text_generator（提示，max_length = 50，num_return_sequences = num_completions，num_beams = num_completions）
            完成 = [结果[&#39;生成的文本&#39;] 结果中的结果]
            输出.追加（完成）
        除了异常 e：
            print(f&quot;处理错误提示{prompt}: {str(e)}&quot;)

    返回输出

如果 __name__ == “__main__”：
    tokenizer = GPT2Tokenizer.from_pretrained(“gpt2”)
    模型 = GPT2LMHeadModel.from_pretrained(“gpt2”)
    model.to(“cuda” if torch.cuda.is_available() else “cpu”)

    example_prompts = [“你好，你好吗？”]
    processed_outputs = process_prompts(example_prompts, model, tokenizer, num_completions=3)
    对于processed_outputs中的输出：
        打印（输出）

还有：
 results = text_generator(prompt, max_length=50, num_return_sequences=num_completions)

当我运行此程序时，出现以下错误：
模型不使用以下`model_kwargs`：[&#39;max_len&#39;]
注意：我知道生成参数中的拼写错误也可能触发此警告，但我已经检查并重新检查了参数名称。

和
 引发 ValueError(
ValueError：没有波束搜索的贪婪方法不支持不同于 1 的 `num_return_sequences`（得到 4）。

什么可能导致此错误，以及如何修复它以使用模型有效地生成多个完成？
交叉：https://discuss.huggingface.co/t/how-to-generate-multiple-text-completions-per-prompt-using-huggingface-transformers-pipeline-without -触发错误/86297]]></description>
      <guid>https://stackoverflow.com/questions/78466376/how-to-generate-multiple-text-completions-per-prompt-like-vllm-using-huggingfa</guid>
      <pubDate>Sun, 12 May 2024 00:06:07 GMT</pubDate>
    </item>
    </channel>
</rss>