<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 12:29:49 GMT</lastBuildDate>
    <item>
      <title>如何显示图像和预测 Confution Matrics</title>
      <link>https://stackoverflow.com/questions/78725594/how-to-display-images-and-predictions-confution-matrics</link>
      <description><![CDATA[我有这样的代码，你可以访问 GitHub，整个过程是相似的，只是架构和数据集不同
https://github.com/cendekialnazalia/CaisimPestDetection/blob/main/Percobaan%20E%20-%20CNN%20add%20Models%20Xception.ipynb
有关更多信息，请参阅结果 CM

在最后一行代码“对测试集进行预测并生成混淆矩阵和分类报告”之后，我添加了类似下面的代码来找出每个测试数据的预测值
test_gen.class_indices

print(preds,preds.shape)

result_index = np.argmax(preds[])
print(result_index)

for i in range(len(preds)):
if(np.argmax(preds[i]) == 0):
print(&quot;Bercak Daun&quot;)
elif(np.argmax(preds[i]) == 1):
print(&quot;Daun Sehat&quot;)
elif(np.argmax(preds[i]) == 2):
print(&quot;Karat Merah&quot;)
else:
print(&quot;Lainya&quot;)

输出
Bercak Daun
Daun Sehat
.
.
.
最多 177
Daun Sehat

除了显示带有字符串的预测之外，我还想将其与图像一起显示。也许有更好、更高效的代码可以解决我的问题，请帮我回答，因为我还是个初学者，想学习]]></description>
      <guid>https://stackoverflow.com/questions/78725594/how-to-display-images-and-predictions-confution-matrics</guid>
      <pubDate>Tue, 09 Jul 2024 12:27:54 GMT</pubDate>
    </item>
    <item>
      <title>使用专家评分训练神经网络进行图像-文本相关性分析</title>
      <link>https://stackoverflow.com/questions/78724935/training-neural-network-for-image-text-relevance-with-expert-scores</link>
      <description><![CDATA[我有两个数据集：
第一个数据集包含由修改后的 ResNet18 模型生成的 768 维图像嵌入。删除最后的全连接层以获得特征表示而不是图像分类。输出被投影到 768 维向量空间中。

第二个数据集由 DistilBERT 生成的 768 维文本嵌入组成。

图像数据集由没有特定主题和相对中性内容的图像组成，描绘了狗在日常环境中玩耍或人们玩耍的场景。
文本数据集更加复杂。它包含图像内容的描述，每个图像都有多个描述。这些描述按从 0 到 1 的连续比例排序，反映了它们在描绘图像方面的准确性。 0 分表示描述和图像之间没有对应关系，而 1 分表示完美匹配。
目标是开发一种搜索解决方案，允许基于预定义的文本查询进行图像检索。约束是避免使用预训练的多模态模型（如 CLIP）并从头开始设计神经网络。
对我来说，这无疑是一个多模态问题。目标是在同一空间内对齐图像和文本向量。为此，我修改了 ResNet18，并打算构建一个以描述等级作为权重初始化的神经网络。但是，我不确定这种方法的正确性。
我寻求正确的指导方向，并倾向于从头开始构建解决方案以掌握底层数学概念，而不是依赖现有模型。
我无法理解的是如何在同一空间中对齐图像向量和相应的文本向量，以便可以将其用于相似性搜索……]]></description>
      <guid>https://stackoverflow.com/questions/78724935/training-neural-network-for-image-text-relevance-with-expert-scores</guid>
      <pubDate>Tue, 09 Jul 2024 10:01:33 GMT</pubDate>
    </item>
    <item>
      <title>可以将已经经过拆分数据阶段、成为训练、验证和测试数据的图像数据集保存到我的计算机存储文件夹中吗？</title>
      <link>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</link>
      <description><![CDATA[我想问一下我做的训练、验证和测试数据的分布，我可以把数据分布以文件夹的形式保存在存储中吗？可以吗？我希望可以:)
如果你想看完整的代码
https://github.com/cendekialnazalia/CaisimPestDetection/blob/main/Percobaan%20E%20-%20CNN%20add%20Models%20Xception.ipynb
我想下载测试数据部分，即&quot;test_gen&quot;或测试数据集。我希望有人能用一个代码来回答我的问题，这个代码可以将数据保存到我的电脑中，而我必须从现有的数据集集合中逐个搜索图像数据
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</guid>
      <pubDate>Tue, 09 Jul 2024 09:41:58 GMT</pubDate>
    </item>
    <item>
      <title>当我通过 docker-compose.yml 运行镜像 ollama 时，无法正确运行它</title>
      <link>https://stackoverflow.com/questions/78724837/i-cannot-run-the-image-ollama-correctly-when-i-run-it-through-docker-compose-yml</link>
      <description><![CDATA[我正在做一个项目，分析文本信息以从中提取特定数据。Python 中的正则表达式效果不佳，因为文本格式不断变化且没有一致性。因此，我决定使用语言模型来处理这些文本，如果文本包含我感兴趣的内容，则返回结果。
在开发程序时，我使用以下命令运行模型：
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
之后，我在代码中发送了一个请求，如下所示：
url = &#39;http://localhost:11434/api/generate&#39;
data = { 
&quot;model&quot;: &quot;llama3&quot;,
&quot;prompt&quot;: f&quot;{input_text}&quot;,
}

这有效（尽管响应需要一点时间才能完成）生成）。
现在，当我尝试配置我的 docker-compose.yml 文件以启动语言模型容器时，它看起来像这样：
ollama:
container_name: ollama
image: ollama/ollama
volumes:
- ollama:/root/.ollama
ports:
- &quot;11434:11434&quot;

volumes:
ollama:

但我只收到 404 错误，这意味着找不到端点。我不明白我做错了什么。有人可以帮忙吗？
此外，有人知道语言模型是否支持多线程吗？我的脚本发送文本非常快，我不确定是否要限制向语言模型发送请求的速率，或者它是否可以处理多线程和异步请求。]]></description>
      <guid>https://stackoverflow.com/questions/78724837/i-cannot-run-the-image-ollama-correctly-when-i-run-it-through-docker-compose-yml</guid>
      <pubDate>Tue, 09 Jul 2024 09:38:52 GMT</pubDate>
    </item>
    <item>
      <title>Keras Tensorflow load_model 函数需要很长时间才能加载模型</title>
      <link>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</link>
      <description><![CDATA[我使用 tensorflow 训练了一个模型（用于识别面部），然后将其保存为“facetracker.h5”。但是，当我尝试加载该模型时，它只是继续加载“[*]”，如下图所示，并且实际上从未完成加载。该模型 (facetracker.h5) 只有 68 MB，所以我是否可以认为这种情况不是由于其大小而发生的？：

facetracker 如下所示：

如能提供任何帮助，我们将不胜感激。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</guid>
      <pubDate>Tue, 09 Jul 2024 09:28:15 GMT</pubDate>
    </item>
    <item>
      <title>强化学习代理没有采取现实行动</title>
      <link>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</link>
      <description><![CDATA[我在 Simulink 环境中使用 PPO 代理，但代理产生的操作似乎是离散的。具体来说，代理仅输出上限或下限。您知道为什么会发生这种情况吗？我正在使用 RL Toolbox 进行训练。
以下是有关我的设置的一些详细信息：
我正在使用带有 ode23t 求解器的可变步长 Simulink 模型。
我的 Simulink 模型使用 Simscape 热流体库并模拟简化的区域供热网络。DHN 有 2 个分支：北 (NORD) 和南 (SUD)。
我正在尝试使用 RL 代理来优化控制，最初专注于通过改变分支中的质量流量来最大限度地降低能源成本。
关于代理的超参数，我使用的是 RL Toolbox，其参数如下：
采样时间 = 3600
折扣因子 = 0.99
GPU
批量大小 = 512
学习率 = 1e-3（对于演员和评论家）
我怀疑我的模型或代理可能存在问题。我将附上 Simulink 模型（应事先加载属性表）。希望问题清楚，有人可以提供帮助！
​​提前谢谢您！
我尝试更改超参数，但没有任何变化
function reward = computeReward(EBio, EGaz, Taller,Tset, Tr,Demandes,production, penalty1,penalty2)

coutBiomass = 0.04 * EBio;
coutGas = 0.1 * EGaz;

%exp(-(Tr - minTemp) / minTemp);

tempDeviation = penalty1 * abs(Taller-Tset);

unmetDemand = penalty1 * max(0, Demandes - production);

minTemp=penalty2 * exp(-(Tr - 318) / 318);

reward = - (coutBiomass + coutGas + tempDeviation + unmetDemand+minTemp);
end

obs = rlNumericSpec([8 1]);
act = rlNumericSpec([2 1],&quot;LowerLimit&quot;,-1,&quot;UpperLimit&quot;,1);
agent=rlTD3Agent(obs,act);
env=rlSimulinkEnv(&quot;Quatrieme_Configuration_SansSolaire_RL_Training&quot;,&quot;Quatrieme_Configuration_SansSolaire_RL_Training/RL Agent&quot;,obs,act);
env.ResetFcn=@randomstart; 
env.UseFastRestart=&quot;on&quot;; 
TimeDelay=0.1; 
]]></description>
      <guid>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</guid>
      <pubDate>Tue, 09 Jul 2024 08:41:06 GMT</pubDate>
    </item>
    <item>
      <title>scikit学习交叉验证分数负值</title>
      <link>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</link>
      <description><![CDATA[我试图建立一个线性回归模型来预测房价，以便从机器学习开始，但在使用以下代码中的交叉验证时遇到负分数值：
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
x = df.drop([&#39;MedHouseVal&#39;], axis=1)
y = df[&#39;MedHouseVal&#39;]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
model = LinearRegression()
model.fit(x_train, y_train)
model.score(x_test, y_test)
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=100)
plt.plot(scores)

我注意到，随着 cv 的增加，平均分数下降。因此，我决定绘制它，并意识到分数在某些时候会呈现负值，但真实预测/样本大小怎么会是负数呢？它是用 (TP + TN - FP - FN)/样本大小计算的吗？
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</guid>
      <pubDate>Mon, 08 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>生存分析 - 估计预期寿命</title>
      <link>https://stackoverflow.com/questions/78719590/survival-analysis-estimating-life-expectancy</link>
      <description><![CDATA[我正在探索生存分析，我的目标是找到一个预测预期寿命（以年为单位）的模型，而不是基于几种生活方式变量的风险比。我有很多饮食变量和二元变量——死亡率。
我使用 Kaplan Meyer 并计算间隔内的 AUC（死亡年龄/审查直到队列的最后一个年龄）来估计预期寿命损失年数。但是，我无法用这种方法使用这些变量。
我也看到了 Cox 比例模型中的函数 predict_survival_function，但曲线没有收敛到 0，因此计算 AUC 没有意义。
我遇到了加速失效时间模型，它似乎允许考虑变量并计算生存时间。有人将它用于类似的目的吗？
有人对预期寿命估计有什么建议吗？有人探索过与随机生存森林相关的任何内容吗？]]></description>
      <guid>https://stackoverflow.com/questions/78719590/survival-analysis-estimating-life-expectancy</guid>
      <pubDate>Mon, 08 Jul 2024 07:31:51 GMT</pubDate>
    </item>
    <item>
      <title>Darknet Yolov4-tiny（灰度输入）到 Tensorflow 权重，转换</title>
      <link>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</link>
      <description><![CDATA[TL;DR:
1 通道 TF 模型的行为与 3 通道模型不同。两者都成功从 Darknet -&gt; TF 转换，但 1 通道模型的表现不如转换前。
手头的任务和声明：
我有两个经过训练的 yolov4-tiny darknet 权重文件 (.weights)，一个有灰度输入（1 通道），另一个有颜色输入（3 通道）。我正在将两个权重文件转换为 Tensorflow 检查点格式，使用一个通用存储库（用于此任务），该存储库位于：
https://github.com/hunglc007/tensorflow-yolov4-tflite.git
两种模型的性能都已通过 c++ opencv readNetFromDarknet() 和 Python 等效项进行了测试。这两个模型都是用灰度图像进行训练的，并且对灰度图像进行操作。3 通道模型的输入只是缩放到 3 通道的灰度图像。
Python 版本：3.10.11
TF 版本：2.10.1
问题陈述：
使用 tf.keras.Models.load_model(X) 加载时，带有颜色输入的权重文件转换良好，之后运行良好，但是当转换灰度输入权重文件时，使用 Tensorflow 加载时模型的性能急剧下降，我的意思是在最明显的情况下，检测结果很差或不存在，而带有颜色输入的模型运行完美。值得注意的是，框不会错位，这意味着当发现检测结果时，它们大致处于正确的位置，但例如宽度和高度可能会偏离。
我知道这个存储库的常见问题（硬编码内容等），并相应地更改了每次转换/模型加载的参数，并且在转换或模型加载期间不会发生任何错误。
我已经确认了输入层：

灰度：（无，640,640,1）
颜色：（无，640,640,3）

测试图像（用于性能测试）使用 opencv-python 加载，并且它们的有效性也已审查，即使将错误维度的数据插入到输入层也会出现错误。
除输入层之外的架构相同，已使用 model.summary() 确认。
我注意到，几年前我用不同的 TF 版本转换的 3 通道模型由 model.summary() 生成的架构有些不同。一些图块层似乎缺失了。此外，一些 tf 操作的名称也不同，但这可能只是 TF 版本不同。
旧颜色模型：
 tf_op_layer_Sigmoid (TensorFlo (None, 40, 40, 3, 2 0 [&#39;tf_op_layer_split_3[0][0]&#39;]
wOpLayer) )

tf_op_layer_Tile/multiples (Te (5,) 0 [&#39;tf_op_layer_strided_slice[0][0]
nsorFlowOpLayer) &#39;]

tf_op_layer_Sigmoid_3 (TensorF (None, 20, 20, 3, 2 0 [&#39;tf_op_layer_split_4[0][0]&#39;]
lowOpLayer) ) )

新灰度模型：
 tf.math.sigmoid (TFOpLambda) (无，40，40，3，2 0 [&#39;tf.split_3[0][0]&#39;]
)

---此处缺少图块层---

tf.math.sigmoid_3 (TFOpLambda) (无，20，20，3，2 0 [&#39;tf.split_4[0][0]&#39;]
)

我现在很卡。有什么帮助吗？
一些反复试验：

使用 Yolov4-tiny Head 解码块 -&gt;即使在模型能够加载的情况下也没有变化（解码时错误的尺寸会引发错误）
之前提到的较旧的 3 通道模型（几年前已转换为 Darknet -&gt; TF），当以与新模型相同的方式加载时，可以完美运行

解决方案：
我从 c++ 打印了带有形状的图层，因为模型在那里工作，我很想知道形状是否完全不同。第一个卷积层根本没有缩小。我检查了 Darknet 用于解析模型的 .cfg 文件，第一个卷积层上有一行“size=3stride=2”。大小解析正确，但步幅解析不正确，并且默认为 1，这使得第一个卷积层的形状为 (640,640,32)，而不是预期的（正确的）(320,320,32)。当我将权重加载到正确的架构时，它当然表现不佳，因为它是用另一种布局训练的。我怀疑我用没有这个错误的 .cfg 训练了 3 通道模型，这就是它完美运行的原因。]]></description>
      <guid>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</guid>
      <pubDate>Fri, 05 Jul 2024 13:54:37 GMT</pubDate>
    </item>
    <item>
      <title>在具有标准化变量的模型中缩放样本外预测：恢复到原始比例</title>
      <link>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</link>
      <description><![CDATA[我正在使用一个模型进行预测，其中变量按 $ x_i = \frac{{x_i - \text{mean}(x_i)}}{{\text{sd}(x_i)}} $ 缩放，并且我保存了平均值和标准差。现在，对于样本外预测，假设目标变量 $ ( x_i )$，基于缩放模型，我该如何缩小预测范围？
我是否应该使用样本内 $ \text{Mean}(x_i) $ 和 $ \text{sd}(x_i) $ 来缩小样本外预测范围，以便：
$ \text{重新缩放的样本外预测} = \text{缩放的预测} \times \text{sd}(x_i) + \text{mean}(x_i) $
这里的适当程序是什么？
Python 示例：
X = np.random.randn(100, 1) * 10 + 50 # 特征
y = 2 * X + 1 + np.random.randn(100, 1) * 5 # 目标变量
X_train, X_test = X[:80], X[80:]
y_train, y_test = y[:80], y[80:]

scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
y_train_scaled = scaler_y.fit_transform(y_train)

model = LinearRegression()
model.fit(X_train_scaled, y_train_scaled)
]]></description>
      <guid>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</guid>
      <pubDate>Tue, 04 Jun 2024 15:17:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Spark 中获取 spark.ml NaiveBayes 概率向量而非 [0-1] 类？</title>
      <link>https://stackoverflow.com/questions/65653286/how-to-get-spark-ml-naivebayes-probability-vector-not-0-1-class-in-spark</link>
      <description><![CDATA[我正在研究 NaiveBayes 分类器，我可以使用训练后的模型预测单个数据点的值，但我想获取概率值。
数据仅分为两类。并且预测函数返回 0 或 1。
import org.apache.log4j.{Level, Logger}
import org.apache.spark.ml.classification.{NaiveBayes, NaiveBayesModel}
import org.apache.spark.ml.feature.LabeledPoint
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.sql.SparkSession

object Test {
def main(args: Array[String]): Unit = {
Logger.getLogger(&quot;org&quot;).setLevel(Level.OFF)
Logger.getLogger(&quot;akka&quot;).setLevel(Level.OFF)
val spark = SparkSession.builder.appName(&quot;Test&quot;).master(&quot;local[4]&quot;).getOrCreate
val dataset = spark.read.option(&quot;inferSchema&quot;, &quot;true&quot;).csv(&quot;data/labelled.csv&quot;).toDF()

import spark.sqlContext.implicits._
val output = dataset.map(row =&gt; {
LabeledPoint(row.getInt(2), Vectors.dense( row.getInt(0) , row.getInt(1)))
})
val Array(training, test) = output.randomSplit(Array(0.7, 0.3),seed = 11L)
training.cache()

val model : NaiveBayesModel = new NaiveBayes().fit(training)
val speed = 110
val hour = 11
val label1 : Double = model.predict(Vectors.dense(speed,hour))
// 更新
val label = model.predictProbability(Vectors.dense(speed,hour)) // 这不起作用并引发错误[1]
}
}

[1] 使用 model.predictProbability 时引发的错误

错误：(24, 23) 类 ProbabilisticClassificationModel 中的方法 predictProbability 无法在 org.apache.spark.ml.classification.NaiveBayesModel 中访问。无法访问受保护的方法 predictProbability，因为封闭的对象 Test 不是包分类中类 ProbabilisticClassificationModel 的子类，其中定义了目标 val label = model.predictProbability(Vectors.dense(speed,hour))
]]></description>
      <guid>https://stackoverflow.com/questions/65653286/how-to-get-spark-ml-naivebayes-probability-vector-not-0-1-class-in-spark</guid>
      <pubDate>Sun, 10 Jan 2021 12:30:28 GMT</pubDate>
    </item>
    <item>
      <title>SVM.SVC() 中的 gamma 参数实际上起什么作用</title>
      <link>https://stackoverflow.com/questions/59594653/what-does-the-gamma-parameter-in-svm-svc-actually-do</link>
      <description><![CDATA[我正在尝试调整我的 SVM 模型，该模型是我使用不同的 gamma 和 C 值构建的。
此外，我还使用了缩放的输入数据进行模型训练。
在尝试了多种组合后，我确实找到了一种 gamma 和 C 的组合，它提供了最佳准确性，尽管我完全不知道 gamma 的作用；PFB：
svc = svm.SVC(gamma=0.025, C=25)

我阅读了文档以了解 gamma 的实际作用（其中说，“‘rbf’、‘poly’ 和 ‘sigmoid’ 的核系数”），现在我更加困惑了。
任何帮助都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/59594653/what-does-the-gamma-parameter-in-svm-svc-actually-do</guid>
      <pubDate>Sat, 04 Jan 2020 20:40:18 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit learn 中实现自定义损失函数</title>
      <link>https://stackoverflow.com/questions/54267745/implementing-custom-loss-function-in-scikit-learn</link>
      <description><![CDATA[我想在 scikit learn 中实现自定义损失函数。我使用以下代码片段：
def my_custom_loss_func(y_true,y_pred):
diff3=max((abs(y_true-y_pred))*y_true)
return diff3

score=make_scorer(my_custom_loss_func,greater_ is_better=False)
clf=RandomForestRegressor()
mnn= GridSearchCV(clf,score)
knn = mnn.fit(feam,labm) 

传递给 my_custom_loss_func 的参数应该是什么？我的标签矩阵称为 labm。我想计算实际输出与预测输出（由模型）乘以真实输出之间的差值。如果我使用 labm 代替 y_true，那么我应该使用什么代替 y_pred？]]></description>
      <guid>https://stackoverflow.com/questions/54267745/implementing-custom-loss-function-in-scikit-learn</guid>
      <pubDate>Sat, 19 Jan 2019 13:47:47 GMT</pubDate>
    </item>
    <item>
      <title>ImportError（'无法导入 PIL.Image。'与 keras-ternsorflow 合作</title>
      <link>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</link>
      <description><![CDATA[我正在学习 lynda.com 上的一些关于在 PyCharmCE 环境中使用 Keras-TensorFlow 进行深度学习的讲座，他们没有遇到这个问题。
我收到此错误：

raise ImportError(&#39;无法导入 PIL.Image。&#39;
ImportError：无法导入 PIL.Image。使用 array_to_img 需要 PIL。

我检查过其他人是否也遇到同样的错误，但对于我来说，使用 pip 安装枕头，命令 pip install Pillow 无法解决任何问题。

MacBook-Pro-de-Rogelio:~ Rogelio$ pip install Pillow
要求已满足：./anaconda3/lib/python3.6/site-packages 中的枕头
MacBook-Pro-de-Rogelio:~ Rogelio$

有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</guid>
      <pubDate>Fri, 12 Jan 2018 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.decomposition.PCA 的特征向量简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我试图了解主成分分析的工作原理，并在sklearn.datasets.load_iris数据集上对其进行测试。我了解每个步骤的工作原理（例如，标准化数据、协方差、特征分解、按最高特征值排序、使用K个选定维度将原始数据转换为新轴）。
下一步是可视化这些特征向量在数据集上投影的位置（在PC1 vs. PC2 图上，对吗？）。
有人可以解释如何在降维数据集的 3D 图上绘制 [PC1、PC2、PC3] 特征向量吗？
此外，我是否正确绘制了这个 2D 版本？我不确定为什么我的第一个特征向量的长度较短。我应该乘以特征值吗？

以下是我为实现此目标所做的一些研究：
我遵循的 PCA 方法来自：
https://plot.ly/ipython-notebooks/principal-component-analysis/#Shortcut---PCA-in-scikit-learn（虽然我不想使用 plotly。我想坚持使用 pandas、numpy、sklearn、matplotlib、scipy 和 seaborn）
我一直在遵循这个绘制特征向量的教程，它看起来很不错简单：使用 matplotlib 进行 PCA 的基本示例，但我似乎无法用我的数据复制结果。
我发现了这一点，但对于我想做的事情来说，它似乎过于复杂，而且我不想创建一个 FancyArrowPatch：使用 matplotlib 和 np.linalg 绘制协方差矩阵的特征向量

我试图让我的代码尽可能简单，以便遵循其他教程：
导入 numpy 作为 np
导入 pandas 作为 pd
导入 matplotlib.pyplot 作为 plt
从 sklearn.datasets 导入 load_iris
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn 导入 decomposition
导入 seaborn 作为 sns； sns.set_style(&quot;whitegrid&quot;, {&#39;axes.grid&#39; : False})

%matplotlib inline
np.random.seed(0)

# 鸢尾花数据集
DF_data = pd.DataFrame(load_iris().data, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])],
columns = load_iris().feature_names)

Se_targets = pd.Series(load_iris().target, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])], 
name = &quot;Species&quot;)

# 缩放平均值 = 0, var = 1
DF_standard = pd.DataFrame(StandardScaler().fit_transform(DF_data), 
index = DF_data.index,
columns = DF_data.columns)

# Sklearn 用于主成分分析

# 维度
m = DF_standard.shape[1]
K = 2

# PCA（我倾向于如何设置它）
M_PCA = decomposition.PCA(n_components=m)
DF_PCA = pd.DataFrame(M_PCA.fit_transform(DF_standard), 
columns=[&quot;PC%d&quot; % k for k in range(1,m + 1)]).iloc[:,:K]

# 绘制特征向量
#https://stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

# 这就是事情变得奇怪的地方...
data = DF_standard

mu = data.mean(axis=0)
特征向量，特征值 = M_PCA.components_, M_PCA.explained_variance_ #eigenvectors, eigenvalues, V = np.linalg.svd(data.T, full_matrices=False)
projected_data = DF_PCA #np.dot(data, eigenvectors)

sigma = projected_data.std(axis=0).mean()

fig, ax = plt.subplots(figsize=(10,10))
ax.scatter(projected_data[&quot;PC1&quot;], projected_data[&quot;PC2&quot;])
for axis, color in zip(eigenvectors[:K], [&quot;red&quot;,&quot;green&quot;]):
# start, end = mu, mu + sigma * axis ### 导致 &quot;ValueError: 需要解压的值太多（预期为 2）&quot;

# 所以我尝试了这个但我认为它不正确
start, end = (mu)[:K], (mu + sigma * axis)[:K] 
ax.annotate(&#39;&#39;, xy=end,xytext=start, arrowprops=dict(facecolor=color, width=1.0))

ax.set_aspect(&#39;equal&#39;)
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    </channel>
</rss>