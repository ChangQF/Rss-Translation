<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Thu, 13 Mar 2025 15:19:58 GMT</lastBuildDate>
    <item>
      <title>使用不同的GIT回购分支进行ML模型开发，测试和部署。关于最佳实践的建议[关闭]</title>
      <link>https://stackoverflow.com/questions/79505557/using-different-git-repo-branches-for-ml-model-development-testing-and-deploym</link>
      <description><![CDATA[我是一名科学家，致力于开发ML模型。我通常将我的开发代码保留在单独的存储库中，然后提取模型，停靠和部署在单独的仓库中。
现在，我正在研究一个小型项目，我不希望维护2个存储库。但是，我不希望在同一分支机构中开发和部署代码。
维护3个分支是一个好习惯吗？

 ML探索：在完成模型算法之前进行实验。 （Jupyter）
 ML-DEV：开发模型的代码。 （Python）
 ml -deploy：部署代码 - 烧瓶应用程序，docker文件等

我想将部署分支作为主人，然后在集成测试后进行生产。
它是否与最佳练习有关？]]></description>
      <guid>https://stackoverflow.com/questions/79505557/using-different-git-repo-branches-for-ml-model-development-testing-and-deploym</guid>
      <pubDate>Thu, 13 Mar 2025 06:15:34 GMT</pubDate>
    </item>
    <item>
      <title>如何从电表的图像中提取读数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79504663/how-do-i-extract-the-reading-from-an-image-of-an-electricity-meter</link>
      <description><![CDATA[我有多个在单个图像中以正方形配置排列的四米的图像：
 meter Image 1 ，
 meter图像2  
仪表可能具有各种照明条件。我获得了Capstone项目，可以使用编程和图像处理从这些图像中提取仪表读数。
对于例如：对于仪表图1 ，输出应为：1130，1130，1600，0400（由于这些读数已显示在仪表上）

我目前的计划是将图像裁剪成四个相等的部分并单独处理。
我已经在单米的图像上尝试了这些步骤：

使用OpenCV将图像转换为灰度
使用 cv2.threshold 功能仅使显示可见
使用 findContour 查找所有轮廓及其边界矩形并根据宽度，高度和纵横比过滤。
裁剪图像，应用一些模糊以使噪音平滑，然后将图像传递给 pytesseract 。

这是上述步骤的Jupyter笔记本。
 https://drive.google.com/file/d/1isfwrgsmhvwr6drd8jbp4jbp4zwqwurbjaso/view?usp = sharing 。
The problem of this approach is that it only works on this specific image and as soon as i replace this image with another one (for eg. this one:Singular meter 2), the whole thing breaks down.该项目要求我构建一个强大的代码，该代码在显示任何仪表时都应起作用，并且在任何照明条件下。
我需要我的项目帮助。
我不是要任何人向我提供完全工作的代码。我只想知道我应该如何解决这个问题。我应该使用机器学习吗？或者只是多个图像处理步骤可以完成工作？]]></description>
      <guid>https://stackoverflow.com/questions/79504663/how-do-i-extract-the-reading-from-an-image-of-an-electricity-meter</guid>
      <pubDate>Wed, 12 Mar 2025 19:14:33 GMT</pubDate>
    </item>
    <item>
      <title>vae的logvar层仅返回零</title>
      <link>https://stackoverflow.com/questions/79504547/logvar-layer-of-a-vae-only-returns-zeros</link>
      <description><![CDATA[我正在用TFJ构建一个变性自动编码器（VAE）。
目前，我只使用FashionMnist数据集进行探索和一个简单的模型，如下所示：
 输入层（28*28*1）
扁平
InterMediate_1（致密50个单位 -  relu）
平均（密集10个单位-RELU）// logVar（密集10个单位relu）
采样器（10个单位）
InterMediate_2（密集50个单位relu）
重建（密集的784个单位 -  sigmoid）
重塑（28*28*1）=＆gt;损失= MSE
 
我创建了一个自定义采样层，该层扩展了tf.layers.layer，如下所示。我可以在线找到其他示例，因为我正在使用td.addloss（）将KL损耗函数添加在图层本身中。
 类WB_SAMPLING扩展了tf.layers.layer {
    构造函数（config）{
        超级（config）;
        this.kl_weight = config.kl_weight; //与重建损失相比，加权KL_LOSS。如果kl_weiht == 0，重建损失是唯一使用的损失
        if（this.kl_weight === undefined）{
            this.kl_weight = 0.0001; // 默认
        }
        this.last_mu;
        this.last_logvar;
        
        //添加kl损失 
        this.addloss（（）=＆gt; {
            const retour = tf.tidy（（）=＆gt; {
                令kl_loss;
                令z_log_var = this.last_logvar;
                令z_mean = this.last_mu;
                kl_loss = tf.scalar（1）.add（z_log_var）.sub（z_mean.square（））。sub（z_log_var.exp（））;
                kl_loss = tf.sum（kl_loss，-1）;
                kl_loss = kl_loss.mul（tf.scalar（-0.5 * this.kl_weight））;
                返回（tf.mean（kl_loss））;
            }）; 
            返回（retour）;

            
        }）; // addloss的结尾
    } //构造函数的结束

    ComputeOutputShape（InputShape）{
        返回inputshape [0]; //与MU相同的形状
    }

    致电（输入，培训）{
        返回tf.tidy（（）=＆gt; {
            const [Mu，logVar] =输入;
            
            //存储MU和LOGVAR值将由KL损耗函数使用
            this.last_mu = mu; // Zmean
            this.last_logvar = logvar; // zlogvar
            
            const z = tf.tidy（（）=＆gt; {
                const batch = mu.shape [0];
                const dim = mu.shape [1];
                const epsilon = tf.randomnormal（[[batch，dim]）;
                const Half = tf.scalar（0.5）;
                const temp = logvar.mul（half）.exp（）。mul（epsilon）;
                const示例= mu.add（temp）;
                返回样品；
            }）;
            返回z;
        }）;
    } //呼叫结束（）

    static get className（）{
        返回“ wb_smpling”;
    }
} // wb_sampling层的结尾
 
该模型效果很好，重建是正确的，但是对我来说似乎很奇怪：logVar层的输出张量仅包含零。
我在平均 / logVar /样品层中使用或多或少单位（从2到20）尝试了。
我试图更改kl_weight参数（这使KL损失与重建损失相比）。我什至尝试使用0的kl_weight（这意味着KL损耗被完全忽略，并且模型仅由于重建损失MSE而变化）。
无论如何，logvar层的输出仅包括零（注意：在训练的开头，有不同的值，但是经过几步训练，只有零保留在输出中）。 
但是，平均层输出各种值，我注意到当kl_weight＆gt; 0比kl_weight == 0时，KL损耗函数似乎正在工作。
这可能是正常的吗？也许在logvar层中高于零的输出不会改善任务中的重建？
您是否在LogVar输出中经历了此类全ZOROS输出？如果没有，您那里有什么价值？您是否知道可能导致问题的原因？]]></description>
      <guid>https://stackoverflow.com/questions/79504547/logvar-layer-of-a-vae-only-returns-zeros</guid>
      <pubDate>Wed, 12 Mar 2025 18:20:02 GMT</pubDate>
    </item>
    <item>
      <title>从不同获取时间处理无效值的最佳方法[已关闭]</title>
      <link>https://stackoverflow.com/questions/79503789/best-approach-to-handle-null-values-from-different-acquisition-times</link>
      <description><![CDATA[ i有一个数据框，其中包含各种生命体征（DBP，SBP，MBP，HR（心率），BIS，EXP_SEV，INSP_SEV（INSP_SEV（INSP_SEV）（启发/expired Sevolfane），随着时间的推移收集了多个患者的收集。这些信号的获取时间有所不同，导致不同的间隔：            
 bis每秒收购，因此其空值很少。
 DBP，SBP和MBP每2秒获取一次，导致每隔一秒钟产生零值。
 exp_sev和ins_sev每7秒获取每7秒，每7秒获取零值。
考虑到这种情况，考虑到我想在数据上同时运行线性回归和LSTM模型（在Python）。，我正在寻找处理这些无效值的最佳方法。

 问题：

我应该算上零值，如果是的，则最合适的方法（例如，插值，前向填充，向后填充）？
离开零值会更好，因为测试集也将拥有它们？

 其他信息：
数据采用时间序列格式，每一行对应于一秒钟的时间。
我想保留不同生命体征之间的时间完整性和关系。
任何见解或建议都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/79503789/best-approach-to-handle-null-values-from-different-acquisition-times</guid>
      <pubDate>Wed, 12 Mar 2025 13:42:54 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习/数据科学技术限制搜索参数[关闭]</title>
      <link>https://stackoverflow.com/questions/79503447/using-machine-learning-data-science-technique-to-restrict-the-search-parameters</link>
      <description><![CDATA[我有一个搜索功能，希望在2个参数之间进行优化。

我希望用户在遍及所有可用记录的情况下都具有尽可能多的灵活性。
我想限制搜索条件，以确保用户在UI上实际上可以使用加载的记录数。

例如，我的搜索具有以下参数：
国家 /地区：用户最多可以选择5种类型。该数据库具有200种独特类型。
创建的日期：我们已经限制了30天。该数据库具有5年的记录。
类别：用户最多可以选择10种类型。该数据库具有3000种独特类型。
想要的结果：
如果用户正在搜索国家，日期范围在10天内，我们知道DB的行计数将为300K，因此我们希望建议用户减少天数。
同样，如果用户正在搜索日本，我们知道在整个5年中，总数只有5K，因此我们不想删除数据范围限制，并建议用户能够搜索更广泛的日期范围。
如何使用机器学习或数据科学技术解决这个问题？
我可以使用蛮力计算每个可能条件的行计数，但随着搜索标准的数量增加，问题似乎并不是最佳的，问题呈指数增长。 ]]></description>
      <guid>https://stackoverflow.com/questions/79503447/using-machine-learning-data-science-technique-to-restrict-the-search-parameters</guid>
      <pubDate>Wed, 12 Mar 2025 11:31:44 GMT</pubDate>
    </item>
    <item>
      <title>从拥抱脸上导入Microsoft/Orca-2-13b时，使Cuda摆脱记忆力</title>
      <link>https://stackoverflow.com/questions/79502752/getting-cuda-out-of-memory-when-importing-microsoft-orca-2-13b-from-hugging-face</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79502752/getting-cuda-out-of-memory-when-importing-microsoft-orca-2-13b-from-hugging-face</guid>
      <pubDate>Wed, 12 Mar 2025 06:05:57 GMT</pubDate>
    </item>
    <item>
      <title>创建用于水压预测的ML模型[关闭]</title>
      <link>https://stackoverflow.com/questions/79502209/creating-ml-model-for-water-pressure-prediction</link>
      <description><![CDATA[我的项目涉及监测管道系统中的水压并使用机器学习来检测异常。
问题：
•我有一个主管，带有压力传感器，可连续监视水压。
•连接到主管的多个阀门可以打开或关闭，创建不同的流动方案。
•我想开发一个可以：的ML模型

预测基于阀状态的预期压力（开放/关闭）。
检测异常，如果实时压力显着偏离预测值。

挑战：
•在许多阀中，组合数的数量呈指数增长（n个阀门为2ⁿ）。存储所有可能的压力值是不切实际的。
•我需要一种在不手动记录每个阀组合的情况下建模系统的方法。
•理想情况下，该模型也应概括和预测，即使是看不见的组合也应推广压力。
到目前为止我的方法：
•我已经考虑使用线性回归模型来映射阀态以施加压力，但担心它可能无法捕获复杂的关系。
•我正在探索神经网络或决策树，但是我不确定如何有效地构建输入功能。
•我计划从传感器中收集现实世界数据，并使用它来训练和验证模型。
我需要帮助：

 最佳ML方法：我应该坚持简单回归，还是像随机森林，梯度增强甚至LSTM之类的东西会更好？

 功能工程：如何有效地表示阀门？

 模型评估：可靠评估性能和标记异常的最佳方法是什么？

 缩放：如何为带有许多阀门的大型系统做这项工作？

]]></description>
      <guid>https://stackoverflow.com/questions/79502209/creating-ml-model-for-water-pressure-prediction</guid>
      <pubDate>Tue, 11 Mar 2025 21:46:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Python SDK将环境变量传递到亚马逊萨吉式制造商的自定义培训脚本？</title>
      <link>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</link>
      <description><![CDATA[我正在使用Amazon Sagemaker中的脚本进行自定义模型，并使用Python SDK启动这项工作。我想将一些环境变量（例如API键或配置标志）传递到培训作业，以便通过OS.Environ在脚本中访问它们。
这是我的代码的简化版本：
 来自sagemaker.stimator导入估算器

估算器=估算器（
    image_uri =&#39;123456789012.dkr.ecr.us-west-2.amazonaws.com/my-custom-image：最新图像&#39;，
    角色=角色，
    instance_count = 1，
    instance_type =&#39;ml.g5.xlarge&#39;，
    entry_point =&#39;train.py&#39;，
    source_dir =&#39;src&#39;，
    环境= {
        &#39;my_api_key&#39;：&#39;abcdef123456&#39;，
        &#39;debug_mode&#39;：&#39;true&#39;
    }
）
 
在我的培训脚本中，我尝试读取变量：
 导入OS

api_key = os.environ.get（&#39;my_api_key&#39;）
打印（＆quot; api键：＆quot; api_key）
 
这是使用Python SDK将环境变量传递给萨吉人培训工作的正确方法吗？我应该注意任何局限性或最佳实践，特别是对于诸如API键之类的敏感信息？]]></description>
      <guid>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</guid>
      <pubDate>Tue, 11 Mar 2025 10:00:30 GMT</pubDate>
    </item>
    <item>
      <title>当我试图运行命令spartlit运行main.py时，为什么我会得到RuntimeError：没有运行事件循环，并且在我的VS代码中？</title>
      <link>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</guid>
      <pubDate>Tue, 11 Mar 2025 09:34:06 GMT</pubDate>
    </item>
    <item>
      <title>生成partialdependedateata函数在用于多类分类模型时返回错误</title>
      <link>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</link>
      <description><![CDATA[我已经使用MLR构建了XGBoost多类分类模型，我想为某些功能可视化部分依赖性。但是，如果我尝试使用 generatePartialDependedAta（）我会收到以下错误：

 Melt.data.table中的错误（AS.Data.table（OUT），MEATH.VARS = target，variable.name = if（td $ type ===：&#39;METAY.VARS&#39;中的一个或多个值无效。

我已经检查了 task.desc 在 task&gt; task 对象和 factor.levels.levels.levels 中的差异。此外，我毫不费力地使用相同的函数生成具有不同目标变量的回归XGBoost的数据。
我的目的是有问题，还是这是一个错误？
这是使用 palmerpenguins 数据集的示例：
 ＃库
图书馆（整洁）
图书馆（Caret）
图书馆（MLR）

Peng＆lt;  -  Palmerpenguins ::企鹅

＃数据分区
set.seed（1234）
Intrain＆lt ;-创建Atapartition（
  y =彭$种，
  p = 0.7，
  列表= f
）

＃构建任务
train_class＆lt;  -  peng [intrain，]％＆gt;％select（-sex，-year）％＆gt;％ 
  CreateMummyFeatures（target =;物种＆quots; cols =;岛; 
  makeClassIftask（data =。，target =;物种；）

＃建立学习者
xgb_class_learner＆lt;  -  makelearner（
  ＆quot“ classif.xgboost”
  predict.type =&#39;响应;
）

＃构建模型
XGB_CLASS＆lt;  - 火车（XGB_CLASS_LEARNER，TRAIN_CLASS）

＃产生部分依赖性
GeneratePartialDependedateData（XGB_Class，Train_class）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</guid>
      <pubDate>Mon, 10 Mar 2025 18:27:01 GMT</pubDate>
    </item>
    <item>
      <title>Pycharm调试不使用TensorFlow。我该如何解决？</title>
      <link>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</link>
      <description><![CDATA[我已经成功安装了以下内容：
  TensorFlow（最新版本2.16.1）
Keras（最新版本3.1.1
 
我正在使用Pycharm 2023.3.5（社区版）。我有一些代码，其中包括tensorflow：
  ...
从tensorflow.keras导入后端为k
...
 
每当我调试代码时，我会收到一个错误，如下所示：
  trackback（最近的最新通话）：
file＆quot” c：\ program文件\ jetbrains \ pycharm社区版2023.3.5 \ plugins \ python-ce \ helpers \ pydev \ pydev \ _pydevd_bundle \ pydevd_xml.py; pydevd_xml.py;
如果Isinstance（o，t [0]）：
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^因为
file＆quot c：\ program files \ python312 \ lib \ lib \ site-packages \ tensorflow \ python \ python \ platform \ flags.py＆quots＆quot＆quort＆quot＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort of 73，in __getAttribute __
返回自我.__ dict __ [&#39;__包装&#39;] .__ getAttribute __（名称）
       ~~~~~~~~~~~~~~ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^es
KeyError：&#39;__包装&#39;
 
我想相信这个问题不是由TensorFlow引起的，但我似乎无法弄清楚确切的问题。我已经浏览了互联网，但无济于事。我得到的最接近的解决方案是问题，但是在我看来，这似乎是一个不同的问题。拜托，这个崇高平台的人，我的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</guid>
      <pubDate>Fri, 29 Mar 2024 03:17:26 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法找到整个数据集中最具代表性的样本集？ [关闭]</title>
      <link>https://stackoverflow.com/questions/56092302/is-there-a-way-to-find-the-most-representative-set-of-samples-of-the-entire-data</link>
      <description><![CDATA[我正在研究文本分类，我有一组200.000条推文。
这个想法是手动标记一组简短的推文和火车分类器，以预测其余标签。监督学习。
我想知道的是，如果有一种方法可以选择哪些样品在火车集合中包含在火车组中，以使该火车组合是整个数据集的良好代表，并且由于火车组中包含的高度多样性，因此训练有素的分类器具有相当多的信任，可以在其余推文上应用。     。]]></description>
      <guid>https://stackoverflow.com/questions/56092302/is-there-a-way-to-find-the-most-representative-set-of-samples-of-the-entire-data</guid>
      <pubDate>Sat, 11 May 2019 16:37:28 GMT</pubDate>
    </item>
    <item>
      <title>无法获得我的线性回归的准确分数</title>
      <link>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</link>
      <description><![CDATA[我正在基于IMDB数据进行回归模型，以预测IMDB值。在线性回归上，我无法获得准确的得分。
我的代码行：
 量表
 
错误：
  valueerror：不支持连续
 
如果我要更改该线以获得R2分数，
  Metrics.R2_Score（test_y，linear_predicated_rating）
 
我能够获得R2而没有任何错误。
我为什么看到这个？
注意： test_y 是pandas dataframe]]></description>
      <guid>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</guid>
      <pubDate>Fri, 11 Aug 2017 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在构建图表后更改每个迭代的变量值？</title>
      <link>https://stackoverflow.com/questions/41143056/how-to-change-the-value-of-variables-each-iteration-after-the-graph-is-built</link>
      <description><![CDATA[我想在Tensorflow中的每次迭代中手动更改变量的值，但我不想更改梯度计算。如何做？]]></description>
      <guid>https://stackoverflow.com/questions/41143056/how-to-change-the-value-of-variables-each-iteration-after-the-graph-is-built</guid>
      <pubDate>Wed, 14 Dec 2016 12:47:22 GMT</pubDate>
    </item>
    <item>
      <title>预测建模 - 分组ID和移动平均值的回归</title>
      <link>https://stackoverflow.com/questions/40221646/predictive-modelling-regression-with-grouped-ids-and-moving-average</link>
      <description><![CDATA[我有一个预测建模问题的问题。起始位置如下所示。 S1-S2是传感器测量值，RUL是我的目标值。
数据架构：
  ID期间S1 S2 S3 Rul
1 1 510.23 643.43 1585.29 6
1 2 512.34 644.89 1586.12 5
1 3 514.65 645.11 1587.99 4
1 4 512.98 647.59 1588.45 3
1 5 516.34 649.04 1590.65 2
1 6 518.12 652.62 1593.09 1
2 1 509.77 640.61 1584.91 9
2 2 510.26 642.06 1586.00 8
2 3 511.95 643.62 1588.09 7 
2 4 513.51 646.51 1589.45 6
2 5 512.17 648.06 1589.54 5
2 6 515.56 646.11 1586.22 4
2 7 518.78 649.34 1586.96 3
2 8 519.90 650.30 1588.95 2
2 9 521.05 651.39 1591.34 1
3 1 501.11 653.99 1580.45 8
3 2 511.45 643.23 1584.09 7
3 3 505.45 643.78 1586.11 6
3 4 504.45 643.43 1588.34 5 
3 5 506.45 643.71 1589.89 4
3 6 511.45 643.33 1591.21 3
3 7 516.45 643.61 1592.42 2
3 8 518.45 643.05 1596.77 1
 
目标：
我的目标是预测看不见数据的剩余有用的现场（rul）。在这种情况下，我只有1种具有不同ID的机器（这意味着1类型和3种不同的物理系统）。为了预测，ID没关系，因为它是同一台机器。此外，我想添加新功能。 S1 S2和S3的移动平均值。因此，我必须添加带有名称A1，A2和A3的三个新列。
例如，A1应该看起来像：
  A1
南
南
512.41
513.32
514.66
515.81
南
南
510.66
511.91
512.54
513.75
515.50
518.08
519.91
南
南
506.00
507.12
505.45
507.45
511.45
515.45
 
下一个问题是，我无法与Nan一起工​​作，因为它是字符串。对于A1，A2和A3，我如何忽略/使用它？
下一个问题是：如何使用带有Train_test_split的Randomforest和Baged Discobled的回归模型来预测看不见的新数据的规则？ （当然，我需要更多数据，此示例仅给出结构。）[S1]，[S2]，[S3]是我的输入，RUR是输出。
此外，我想用平均绝对误差，平均误差和R²。评估模型。
 finaly，我想使用GridSearch方法进行调整。
我知道我想做什么，但是我无法与Python意识到这一点。完整的代码将是完美的。]]></description>
      <guid>https://stackoverflow.com/questions/40221646/predictive-modelling-regression-with-grouped-ids-and-moving-average</guid>
      <pubDate>Mon, 24 Oct 2016 15:04:57 GMT</pubDate>
    </item>
    </channel>
</rss>