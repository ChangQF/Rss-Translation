<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 05 Mar 2024 18:17:27 GMT</lastBuildDate>
    <item>
      <title>对于具有协变量和缺失日期的多元时间序列插补，我应该选择哪种模型？</title>
      <link>https://stackoverflow.com/questions/78109616/which-model-should-i-select-for-a-multivariate-time-series-imputation-where-i-ha</link>
      <description><![CDATA[我有两年时间范围内商店的销售数据。样本数据：

&lt;标题&gt;

日期
目标商店销售额
目标商店促销
Sales_Store1
Promotion_Store1
Sales_Store2
Promotion_Store1


&lt;正文&gt;

2022-06-27
30.0
否
29.0
是
34.0
是


2022-06-28
42.0
否
空
否
39.0
否


2022-06-29
37.0
否
26.0
是
37.0
是


2022-07-02
45.0
否
44.0
否
空
否


2022-07-03
29.0
否
空
是
24.0
是


2022-07-05
34.0
否
40.0
否
42.0
否



为了扩展我的（希望是正确的）问题标题，我想做的是使用上表作为我的训练集来预测我的 Target 商店销售额的基线，希望找到特定促销的提升。该表已根据“目标商店促销”列进行筛选，因此它仅包含没有促销的日期。促销活动每天进行。 Sales_Store1和Promotion_Store1包含类似商店的销售和促销状态。我对他们的选择相当有信心。
示例表的其余部分如下：

&lt;标题&gt;

日期
目标商店销售额
目标商店促销
Sales_Store1
Promotion_Store1
Sales_Store2
Promotion_Store1


&lt;正文&gt;

2022-06-30
55.0
是
34.0
是
67.0
是


2022-07-04
47.0
是
66.0
否
55.0
是



数据具有很强的季节性，但目标商店和所使用的类似商店也有许多缺失值。商店的销售天数约为 600 天。
此外，值得注意的是，使用综合控制的 A/B 测试在这里会失败，因为促销在商店之间是高度同步的。也就是说，如果我的目标商店有正在进行的促销活动，那么很有可能类似的商店也会这样做。 （但不一定）
我希望结果表看起来像这样：

&lt;标题&gt;

日期
目标商店销售额
没有促销的目标商店销售额
目标商店促销
Sales_Store1
Promotion_Store1
Sales_Store2
Promotion_Store1


&lt;正文&gt;

2022-06-30
55.0
45.0
是
34.0
是
67.0
是


2022-07-04
47.0
32.0
是
66.0
否
55.0
是



您知道哪种模型或技术可以帮助我预测此基线吗？我正在研究新的 Tide，但在深入研究之前并尝试使用它，我想我应该问问是否有人面临过类似的挑战。预先感谢！
我最初尝试了典型的 A/B 测试，同时消除协变量，但剩余的数据样本太少了。正如我提到的，大多数促销活动在各商店同时进行。
我尝试使用上述功能（以及月份和工作日等功能）训练 XGBoost 回归器，希望能够捕获季节性，但结果平庸，MAPE 约为 0.15。]]></description>
      <guid>https://stackoverflow.com/questions/78109616/which-model-should-i-select-for-a-multivariate-time-series-imputation-where-i-ha</guid>
      <pubDate>Tue, 05 Mar 2024 17:48:57 GMT</pubDate>
    </item>
    <item>
      <title>修改ML预处理函数以在Google Cloud TPU上进行训练</title>
      <link>https://stackoverflow.com/questions/78109089/modify-ml-preprocessing-function-to-train-on-google-cloud-tpu</link>
      <description><![CDATA[在此处输入图像描述
请帮助我提高 TPU 上的 CPU 使用率。
目前仅使用了 0.5%（附截图）
&lt;前&gt;&lt;代码&gt;最大输入长度 = 128
最大目标长度 = 128

source_lang = &quot;en&quot;;
target_lang =“嗨”

def preprocess_function（示例）：
输入 = \[ex\[source_lang\] 示例中的 ex\[“翻译”\]\]
目标 = \[ex\[target_lang\] 示例中的 ex\[“翻译”\]\]
model_inputs = tokenizer(输入, max_length=max_input_length, 截断=True)

# 为目标设置标记器
使用 tokenizer.as_target_tokenizer()：

标签=分词器（目标，max_length = max_target_length，截断= True）

model_inputs[“labels”] = labels[“input_ids”]
返回模型输入

请帮我修改代码以增加CPU使用率:)
我尝试增加批处理大小，但 RAM 使用量只会增加。
训练时间保持不变且没有减少。]]></description>
      <guid>https://stackoverflow.com/questions/78109089/modify-ml-preprocessing-function-to-train-on-google-cloud-tpu</guid>
      <pubDate>Tue, 05 Mar 2024 16:13:37 GMT</pubDate>
    </item>
    <item>
      <title>我无法使用 DiscreteDistribution 函数</title>
      <link>https://stackoverflow.com/questions/78108981/i-am-not-able-use-discretedistribution-function</link>
      <description><![CDATA[a = DiscreteDistribution({&#39;1&#39;: 1./10, &#39;0&#39;: 9./10})

在这一行中，代码不断抛出错误，在您说“是”之前，我已经安装了石榴并且也导入了它，但仍然显示此错误。我问过 chatgpt，据它说我的代码完全没问题。您认为问题出在哪里？石榴的版本会影响我的代码吗？我是菜鸟，这些东西我都不懂。
我试图创建贝叶斯网络，并且试图获得简单图的概率。我在第一行写了：from pomegranate import *。
NameError：名称“DiscreteDistribution”未定义

这是错误。]]></description>
      <guid>https://stackoverflow.com/questions/78108981/i-am-not-able-use-discretedistribution-function</guid>
      <pubDate>Tue, 05 Mar 2024 15:53:30 GMT</pubDate>
    </item>
    <item>
      <title>尝试建立一个lstm模型</title>
      <link>https://stackoverflow.com/questions/78108041/trying-to-build-an-lstm-model</link>
      <description><![CDATA[我正在尝试构建一个 lstm 模型并拟合训练数据
我收到形状错误：
输入张量的输入形状无效（“sequential_4_1/Cast:0”, shape=(None, 21), dtype=float32)。预期形状（无、9144、21），但输入形状不兼容（无、21）

Sequential.call() 收到的参数：
  输入=tf.Tensor（形状=（无，21），dtype=int64）
  • 训练=真
  • 掩码=无
]]></description>
      <guid>https://stackoverflow.com/questions/78108041/trying-to-build-an-lstm-model</guid>
      <pubDate>Tue, 05 Mar 2024 13:22:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 LSTM 模型进行充电数据负荷预测的时间序列交叉验证[关闭]</title>
      <link>https://stackoverflow.com/questions/78107902/time-series-cross-validation-for-load-forecast-of-charging-data-using-lstm-model</link>
      <description><![CDATA[我目前正在构建一个 LSTM 模型，以使用包含 24 个特征和 12 个月目标列的数据集来预测电动汽车的消耗量。数据采用时间序列格式，间隔为 15 分钟，我想应用时间序列交叉验证来维护时间依赖性。
这是我到目前为止为训练和测试拆分编写的代码：
# 定义用于训练的列
特征 = [&#39;小时&#39;, &#39;季度小时&#39;, &#39;工作日&#39;, &#39;cal_week&#39;, &#39;月份&#39;, &#39;周末&#39;,
                  &#39;季节&#39;，&#39;假期&#39;，&#39;下一个假期&#39;，&#39;bridge_day&#39;，&#39;学校假期&#39;，&#39;quarter_sin&#39;，&#39;quarter_cos&#39;，&#39;hour_sin&#39;，&#39;hour_cos&#39;，
                  &#39;weekday_sin&#39;、&#39;weekday_cos&#39;、&#39;month_sin&#39;、&#39;month_cos&#39;、&#39;cal_week_sin&#39;、&#39;cal_week_cos&#39;、&#39;temp_day_avg&#39;、&#39;humidity_day_avg&#39;、&#39;wind_speed&#39;]

# 提取特征和目标变量
X = Bosch_data[功能].值
y = Bosch_data[&#39;aggregate_conspiration_kWh&#39;].values


# 定义窗口大小
validation_window_size = 7 * 24 * 4 # 7天* 24小时* 4个季度/小时（15T）
test_window_size = 31 * 24 * 4 # 31天* 24小时* 4个季度/小时（15T）

# 将训练集定义为除验证集和测试集之外的所有内容
train_window_size = len(Bosch_data) - validation_window_size - test_window_size

# 将数据分为训练集、验证集和测试集
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=validation_window_size + 31 * 24 * 4, shuffle=False)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=31 * 24 * 4, shuffle=False)

我有两个具体问题：

扩展窗口交叉验证：如何将扩展窗口交叉验证应用于此训练、验证和测试拆分？

选择时间步长：我的数据集呈现每周模式，我想预测未来 30 天的消耗量。考虑到 15 分钟的时间间隔，在这种情况下我的理想时间步长应该是多少？如果我使用 15 分钟的时间间隔作为一个时间步长，则会出现错误。


我愿意接受有关如何解决这些问题并扩展我的时间序列交叉验证代码的建议。任何帮助或指导将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78107902/time-series-cross-validation-for-load-forecast-of-charging-data-using-lstm-model</guid>
      <pubDate>Tue, 05 Mar 2024 12:58:27 GMT</pubDate>
    </item>
    <item>
      <title>无监督自动编码器产生特定的输出维度</title>
      <link>https://stackoverflow.com/questions/78107646/unsupervised-autoencoder-produce-specific-output-dimensions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78107646/unsupervised-autoencoder-produce-specific-output-dimensions</guid>
      <pubDate>Tue, 05 Mar 2024 12:12:37 GMT</pubDate>
    </item>
    <item>
      <title>在 Django 应用程序中通过 PipelineModel.load(model_location) 加载 Ml 模型时遇到错误</title>
      <link>https://stackoverflow.com/questions/78107352/facing-error-on-loading-ml-model-through-pipelinemodel-loadmodel-location-in-d</link>
      <description><![CDATA[您好，我正在使用 django 应用程序，它同时具有 asgi 和 wsgi 模式。现在，当我在独立脚本中加载模型时，它加载时没有任何错误，但是当我通过 django 中的 api 调用加载它以执行任务时，它会出现错误：
 文件“/mnt/d/InnovativeSolutions/DataAnalytics/DataAnalyticsDataTransformation/env2/lib/python3.10/site-packages/pyspark/ml/param/__init__.py”，第 276 行，位于  中;
    src_name_attrs = [(x, getattr(cls, x)) for x in dir(cls)]
属性错误：__provides__

代码：
从 pyspark.ml 导入 PipelineModel
pipeline_model：PipelineModel =等待PipelineModel.load(model_location)

我尝试制作将机器学习模型加载到异步类型的根方法，但仍然面临相同的错误。
独立脚本加载模型没有任何错误。]]></description>
      <guid>https://stackoverflow.com/questions/78107352/facing-error-on-loading-ml-model-through-pipelinemodel-loadmodel-location-in-d</guid>
      <pubDate>Tue, 05 Mar 2024 11:22:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么 SimpleNet 在“推断”阶段突然被杀</title>
      <link>https://stackoverflow.com/questions/78106566/why-simplenet-gets-killed-abruptly-on-inferring-stage</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78106566/why-simplenet-gets-killed-abruptly-on-inferring-stage</guid>
      <pubDate>Tue, 05 Mar 2024 09:19:50 GMT</pubDate>
    </item>
    <item>
      <title>强化学习神经网络概率没有改变[关闭]</title>
      <link>https://stackoverflow.com/questions/78106390/reinforcement-learning-neural-network-probabilities-arent-changing</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78106390/reinforcement-learning-neural-network-probabilities-arent-changing</guid>
      <pubDate>Tue, 05 Mar 2024 08:48:07 GMT</pubDate>
    </item>
    <item>
      <title>邻居索引错误：self._check_indexing_error(key) KeyError：8</title>
      <link>https://stackoverflow.com/questions/78101850/neighbors-indexing-error-self-check-indexing-errorkey-keyerror-8</link>
      <description><![CDATA[我正在创建一个服装推荐系统，使用 NearestNeighbors，数据来自 2 个数据集，其中一个数据集包含 ratings.csv，在本例中 0 和 1&lt; /code&gt; 基于是否保存到愿望清单以及所有衣服的衣服.csv，我想传递服装的 ID 并获取推荐商品的列表，但我收到索引错误。
这是代码：
user_ ratings_df = pd.read_csv(“ ratings.csv”)

user_ ratings_df[&#39;IDGARMENT&#39;] = user_ ratings_df[&#39;IDGARMENT&#39;].astype(int)

# 读入数据；使用默认的 pd.RangeIndex，即 0、1、2 等作为列
Clothes_desc = pd.read_csv(“clothes.csv”, on_bad_lines=&#39;skip&#39;)
Clothing_metadata = Clothing_desc[[&#39;IDGARMENT&#39;, &#39;描述&#39;, &#39;类别&#39;, &#39;品牌&#39;, &#39;价格&#39;]]

衣服元数据[&#39;IDGARMENT&#39;] = 衣服元数据[&#39;IDGARMENT&#39;].astype(int)
Clothes_data = user_ ratings_df.merge(clothes_metadata, on=&#39;IDGARMENT&#39;)

user_item_matrix = user_ ratings_df.pivot(index=[&#39;USERID&#39;], columns=[&#39;IDGARMENT&#39;], value=&#39;RATING&#39;).fillna(0)
用户项矩阵

# 定义一个关于余弦相似度的 KNN 模型
cf_knn_model=NearestNeighbors(metric=&#39;cosine&#39;,algorithm=&#39;brute&#39;,n_neighbors=10,n_jobs=-1)
#lr.fit(x.reshape(-1, 1), y)

# 将模型拟合到我们的矩阵上
cf_knn_model.fit(user_item_matrix)


def dress_recommender_engine(garment_id, 矩阵, cf_model, n_recs):
    # 在矩阵上拟合模型
    cf_knn_model.fit（矩阵）
    
    # 计算邻居距离
    距离，索引 = cf_model.kneighbors(matrix[garment_id], n_neighbors=n_recs)
    Clothing_rec_ids = Sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),key=lambda x: x[1])[:0:-1]
    
    # 存储推荐的列表
    cf_recs = []
    对于我在 dress_rec_ids 中：
        cf_recs.append({&#39;Desc&#39;:clothes_desc[&#39;DESCRIPTION&#39;][i[0]],&#39;距离&#39;:i[1]})
    
    # 选择需要的最多推荐数量
    df = pd.DataFrame(cf_recs, 索引 = 范围(1,n_recs))
    返回df


n_recs = 10
dress_recommender_engine（54448，user_item_matrix，cf_knn_model，n_recs）

我得到的错误是：
&lt;前&gt;&lt;代码&gt;&gt; *keyError Traceback（最近一次调用最后）文件
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802,
&gt;在Index.get_loc（self，key，method，tolerance）3801中尝试：
&gt; -&gt; [第 3802 章] 第 3803 章
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138,
&gt;在 pandas._libs.index.IndexEngine.get_loc() 文件中
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165,
&gt;在 pandas._libs.index.IndexEngine.get_loc() 文件中
&gt; pandas/_libs/hashtable_class_helper.pxi:2263，在
&gt; pandas._libs.hashtable.Int64HashTable.get_item() 文件
&gt; pandas/_libs/hashtable_class_helper.pxi:2273，位于
&gt; pandas._libs.hashtable.Int64HashTable.get_item() KeyError：54448
&gt;上述异常是以下异常的直接原因：
&gt; KeyError Traceback（最近调用
&gt;最后）单元格 In[4]，第 64 行
&gt; 59 返回 df
&gt; 63 n_recs = 10
&gt; ---&gt; 64 dress_recommender_engine(54448, user_item_matrix, cf_knn_model, n_recs) 单元格 In[4]，第 48 行，in
&gt; dress_recommender_engine(garment_id, 矩阵, cf_model, n_recs)
&gt; 42 cf_knn_model.fit（矩阵）
&gt; 44 # 提取输入的电影ID
&gt;第45话
&gt; 46
&gt; 47 # 计算邻居距离
&gt; ---&gt; 48 个距离，索引 = cf_model.kneighbors(matrix[garment_id], n_neighbors=n_recs)
&gt;第49章 衣服
&gt; x: x[1])[:0:-1]
&gt; 51 # 存储推荐的列表 File ~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3807, in
&gt;第3805章1：
&gt;第3806章
&gt; -&gt;第3807章 第3808章 第3809章
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804，
&gt;在Index.get_loc（self，key，method，tolerance）3802返回
&gt; self._engine.get_loc(casted_key) 3803 除了 KeyError 为错误：
&gt; -&gt;第3804章 3805 错误：3806
&gt;第3807章否则我们会失败并重新加注
&gt;第3808章第3809章
&gt;密钥错误：54448*

错误似乎在这一行“distances,indices = cf_model.kneighbors(matrix[garment_id], n_neighbors=n_recs)”中当传递矩阵[garment_id]时，知道如何解决它吗？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78101850/neighbors-indexing-error-self-check-indexing-errorkey-keyerror-8</guid>
      <pubDate>Mon, 04 Mar 2024 14:12:06 GMT</pubDate>
    </item>
    <item>
      <title>我在使用石榴时遇到问题，它不允许我使用 DiscreteDistribution [关闭]</title>
      <link>https://stackoverflow.com/questions/78100004/i-had-a-problem-using-pomegranate-that-it-wont-let-me-use-discretedistribution</link>
      <description><![CDATA[a = DiscreteDistribution({&#39;1&#39;: 1./10, &#39;0&#39;: 9./10})

在这一行中，代码不断抛出错误，在您说“是”之前，我已经安装了石榴并且也导入了它，但仍然显示此错误。我问过 chatgpt，据它说我的代码完全没问题。您认为问题出在哪里？石榴的版本会影响我的代码吗？我是菜鸟，这些东西我都不懂。
我试图创建贝叶斯网络，并且我试图获得一个简单图的概率。我在第一行写了： from pomegranate import * 。
NameError：名称“DiscreteDistribution”未定义
这是错误。]]></description>
      <guid>https://stackoverflow.com/questions/78100004/i-had-a-problem-using-pomegranate-that-it-wont-let-me-use-discretedistribution</guid>
      <pubDate>Mon, 04 Mar 2024 08:55:30 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 3D X 和 2D y 进行训练</title>
      <link>https://stackoverflow.com/questions/78099801/unable-to-use-3d-x-and-2d-y-for-training</link>
      <description><![CDATA[我正在训练一个模型来区分真实数据和虚假数据。
我有一个真实的数据集和一个假的数据集，由于我不知道如何在这两个数据集上训练单个模型，所以我现在正在训练一个真实的模型和一个假的模型。
问题是训练任何模型似乎都是不可能的，因为我收到此错误：
ValueError：输入 X 包含无穷大或对于 dtype(&#39;float16&#39;) 来说太大的值

对于此代码
导入 pandas 作为 pd
将 numpy 导入为 np
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 precision_score
从 sklearn.utils 导入洗牌
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.preprocessing 导入 RobustScaler
从 sklearn.metrics 导入分类报告
从sklearn.metrics导入confusion_matrix

定标器 = RobustScaler()
X = np.load(“fake_x.npy”)
x_data_flat = X.reshape(X.shape[0], -1)
x_data_scaled = 缩放器.fit_transform(x_data_flat)
y = np.load(“fake_y.npy”)
x_data_flat, y = 随机播放(x_data_flat, y)
X_train,X_test,y_train,y_test = train_test_split(x_data_scaled,y,test_size=0.1, train_size=0.1)

clf = 随机森林分类器()
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

准确度=准确度_分数（y_test，y_pred）
print(“准确度：”, 准确度)

print(&quot;分类报告：&quot;)
打印（分类报告（y_test，y_pred））


conf_matrix = fusion_matrix(y_test, y_pred)
print(&quot;混淆矩阵：&quot;)
打印（conf_matrix）

数据肯定太大了，x.shape = (750,1998,101) 和 y.shape = (750,496)。
数据链接：https://drive.google.com/drive/folders/1EYnOIOWP17ALs -903ESFM-02_6VszJEx
对于分类本身，我会在输入上使用相似度分数，无论谁获得更高的相似度分数，输入都将属于其类别。
使用最初是 real.npz 但提取到 real_x.npy 和 real_y.npy 的二维频谱图以使其更容易，模型应该识别输入是属于真实的还是属于我提取到 fake_x 的 fake.npz。 npy 和 fake_y.npy]]></description>
      <guid>https://stackoverflow.com/questions/78099801/unable-to-use-3d-x-and-2d-y-for-training</guid>
      <pubDate>Mon, 04 Mar 2024 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>运行时错误：mat1 和 mat2 形状无法相乘（32x802816 和 200704x256）</title>
      <link>https://stackoverflow.com/questions/78089310/runtimeerror-mat1-and-mat2-shapes-cannot-be-multiplied-32x802816-and-200704x25</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78089310/runtimeerror-mat1-and-mat2-shapes-cannot-be-multiplied-32x802816-and-200704x25</guid>
      <pubDate>Fri, 01 Mar 2024 17:00:59 GMT</pubDate>
    </item>
    <item>
      <title>wandb 表中的彩色文本</title>
      <link>https://stackoverflow.com/questions/75900664/colored-text-in-a-wandb-table</link>
      <description><![CDATA[对于错误分析（对于我的 ASR 模型），我想向 wandb 报告一个表，其中文本采用颜色编码，以显示预测的转录本和真实情况之间的差异（例如删除的单词为灰色，插入为蓝色，替换为红色）。
我尝试了 HTML，即
def _html_c(color: str) -&gt;字符串：
    return f&#39;&#39;

和 ASCII 颜色代码，即
def _c_ascii(color: str) -&gt;字符串：
    如果颜色 == EQUAL_C：
        返回&#39;\033[0m&#39;
    elif 颜色 == REPLACE_C:
        返回&#39;\033[91m&#39;
    elif 颜色 == DELETE_C:
        返回&#39;\033[95m&#39;
    elif 颜色 == INSERT_C:
        返回&#39;\033[94m&#39;
    别的：
        引发 ValueError(f&#39;未知颜色：{color}&#39;)

但是，该表显示的是 kebab 字形而不是 ASCII 颜色代码，并且显示 HTML 代码而不是颜色（请参阅 https://github.com/wandb/wandb/issues/5253）。
那么如何对 wandb 表中的文本进行颜色编码？
我觉得必须有一个解决方案，因为预测和真实情况之间的颜色编码文本本身就表明了这一点（至少 ASR 在视觉上接近通用指标 WER）。但我的搜索毫无结果。
&lt;小时/&gt;
有关计算表格和差异的详细信息：
EQUAL_C = &#39;黑色&#39;
REPLACE_C = &#39;红色&#39;
DELETE_C = &#39;粉红色&#39;
INSERT_C = &#39;橙色&#39;

def Visualize_differences（标签，预测）：
    断言 len(预测) == len(标签)
    返回 [[索引 + 1, Visualize_difference(标签, 预测), 标签]
            对于索引，枚举（zip（标签，预测））中的（标签，预测）]

def Visualize_difference（标签，预测）：
    split_label = _split(标签)
    split_prediction = _split(预测)
    matcher = difflib.SequenceMatcher(无, split_label, split_prediction)
    结果=“”
    对于 matcher.get_opcodes() 中的标签 i1、i2、j1、j2：
        如果标签==&#39;等于&#39;：
            结果+=&#39;&#39;.join(split_label[i1:i2])
        elif 标签 == &#39;替换&#39;:
            结果+= _html_c(REPLACE_C) + &#39;&#39;.join(split_prediction[j1:j2]) + _html_c(EQUAL_C)
        elif 标签 == &#39;删除&#39;:
            结果+= _html_c(DELETE_C) + &#39;&#39;.join(split_label[i1:i2]) + _html_c(EQUAL_C)
        elif 标签 == &#39;插入&#39;:
            结果+= _html_c(INSERT_C) + &#39;&#39;.join(split_prediction[j1:j2]) + _html_c(EQUAL_C)
    返回结果

def _split（输入字符串）：
    模式 = r&quot;(\w+|\s+|[^\w\s]+)&quot;
    返回 re.findall(pattern, input_string)

diff_wandb_table = wandb.Table(data=visualize_differences(ground_truths, 预测), columns=[&#39;样本&#39;, &#39;差异&#39;, &#39;标签&#39;])
    [create_word_error_table 中的行的 diff_wandb_table.add_data(*row)]
]]></description>
      <guid>https://stackoverflow.com/questions/75900664/colored-text-in-a-wandb-table</guid>
      <pubDate>Fri, 31 Mar 2023 16:13:01 GMT</pubDate>
    </item>
    <item>
      <title>在训练和测试数据分割之前或之后对数据进行归一化？</title>
      <link>https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data</link>
      <description><![CDATA[我想将数据分成训练集和测试集，我应该在分割之前还是之后对数据应用归一化？它在构建预测模型时有什么区别吗？]]></description>
      <guid>https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data</guid>
      <pubDate>Fri, 23 Mar 2018 07:13:09 GMT</pubDate>
    </item>
    </channel>
</rss>