<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 05 Mar 2024 12:23:40 GMT</lastBuildDate>
    <item>
      <title>无监督自动编码器产生特定的输出维度</title>
      <link>https://stackoverflow.com/questions/78107646/unsupervised-autoencoder-produce-specific-output-dimensions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78107646/unsupervised-autoencoder-produce-specific-output-dimensions</guid>
      <pubDate>Tue, 05 Mar 2024 12:12:37 GMT</pubDate>
    </item>
    <item>
      <title>尝试训练 Tensorflow.Net 模型时，对象引用未设置为对象的实例[重复]</title>
      <link>https://stackoverflow.com/questions/78107434/object-reference-not-set-to-an-instance-of-an-object-when-attempting-to-train-te</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78107434/object-reference-not-set-to-an-instance-of-an-object-when-attempting-to-train-te</guid>
      <pubDate>Tue, 05 Mar 2024 11:37:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML 进行规划优化</title>
      <link>https://stackoverflow.com/questions/78107420/planification-optimization-with-ml</link>
      <description><![CDATA[我正在研究生产规划过程的自动化。我的目标是实现目前手动完成的流程自动化。有了生产订单列表，员工可以在内部应用程序中手动安排下周/几周的操作。
我有半年的历史数据（应用程序是新的），大约有7500行操作，其中包括操作类型、使用的机器、操作顺序、生产的件数、实际开始和结束时间、开始和结束时间等特征班次、班次信息、产品交付给客户的日期等等。所有的特征都被标准化，最重要的特征如操作类型和使用的机器都是one-hot编码的。
我过去曾使用过一些机器学习技术，但现在我正在努力选择正确的方法。我开始使用线性回归（转换时间）和实时随机森林来预测操作的开始时间，但误差太高了。我已使用 chatgpt 寻求建议，但似乎没有任何作用，它建议我预测操作的持续时间，但我不知道稍后如何使用它来进行自动规划。我需要预测太多的事情，因为我需要在白天、轮班和工作时间内进行新的操作，而不会出现机器使用重叠的情况，而且我不知道从哪里开始。即使我预测了持续时间，我也不知道以后如何使用这些信息来安排操作。
有人参与过类似的项目吗？也许我应该使用完全不同的工具。我只需要一些人类指导。请指教。]]></description>
      <guid>https://stackoverflow.com/questions/78107420/planification-optimization-with-ml</guid>
      <pubDate>Tue, 05 Mar 2024 11:34:43 GMT</pubDate>
    </item>
    <item>
      <title>两个或多个特征组合而成的单个特征是否比 ML 中单独包含数据的多个特征更重要？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78106969/does-a-single-feature-that-is-a-combination-of-two-or-more-features-holds-more-i</link>
      <description><![CDATA[我是机器学习的初学者，我正在尝试预测二手车的价值。我有一个关于二手车的数据集，它有这 3 列，第一列包含汽车的“制造商”和“型号”，而第二列和第三列分别只包含“制造商”和“型号”，请看一下图片，我应该删除第一个包含全名的模型还是应该删除其他两列，记住我想训练一个线性回归模型来预测汽车的价格？哪一列对于模型训练很重要，第一列是第二列和第三列的组合，或者其他两列单独的列更重要，如果是，那么为什么？
我问了 ChatGPT，它说第一列是其他两列的组合，它更重要。]]></description>
      <guid>https://stackoverflow.com/questions/78106969/does-a-single-feature-that-is-a-combination-of-two-or-more-features-holds-more-i</guid>
      <pubDate>Tue, 05 Mar 2024 10:26:25 GMT</pubDate>
    </item>
    <item>
      <title>patchify - `window_shape` 太大 - 较小的批量大小？</title>
      <link>https://stackoverflow.com/questions/78106927/patchify-window-shape-is-too-large-smaller-batch-size</link>
      <description><![CDATA[我正在尝试创建一个 keras 生成器来创建补丁。
数据具有不同的大小。
导入tensorflow为tf
将 numpy 导入为 np
从 patchify 导入 patchify

类数据生成器（tf.keras.utils.Sequence）：
    def __init__(自身、lr_data、hr_data、batch_size、patch_size)：
        self.lr_data = lr_data
        self.hr_data = hr_data
        self.batch_size = 批量大小
        self.patch_size = patch_size

        self.lr_indices = np.arange(len(lr_data))
        self.hr_indices = np.arange(len(hr_data))
        self.min_length = min(len(self.lr_data), len(self.hr_data))

    def __len__(自身):
        return int(np.ceil(self.min_length / self.batch_size))

    def __create_patches(self, img_batch):
        
        patch = patchify(img_batch, (self.patch_size, self.patch_size, img_batch.shape[-1]), step=self.patch_size//2)
        补丁 = patch.reshape(-1, self.patch_size,, self.patch_size,, img_batch.shape[-1])
        
        返回补丁
        
    def __getitem__(自身，索引)：
        start_lr = 索引 * self.batch_size
        end_lr = min((index + 1) * self.batch_size, self.min_length)
        lr_indices = self.lr_indices[start_lr:end_lr]
        
        start_hr = 索引 * self.batch_size
        end_hr = min((index + 1) * self.batch_size, self.min_length)
        hr_indices = self.hr_indices[开始时间:结束时间]
        

        batch_hr = np.asarray([self.hr_data[k] for k in hr_indices])
        batch_lr = np.asarray([self.lr_data[k] for k in lr_indices])
        
        x1 = self.__create_patches(batch_hr)
        x2 = self.__create_patches(batch_lr)
       
        返回 [x1, x2]


LR = np.random.rand(512, 512, 9)
HR = np.random.rand(128, 128, 172)

train_gen = DataGenerator(LR、HR、batch_size=16、patch_size=32)

对于 train_gen 中的 lr、hr：
    打印（lr.形状）

我收到：
 `window_shape` 太大

当我尝试使用patchify时。
如果我使用：train_gen = DataGenerator(LR, HR, batch_size=32, patch_size=32),
所以相同数量的补丁和batch_size，它运行良好。
是否有解决方法可以使其适用于较小的批量大小？]]></description>
      <guid>https://stackoverflow.com/questions/78106927/patchify-window-shape-is-too-large-smaller-batch-size</guid>
      <pubDate>Tue, 05 Mar 2024 10:19:40 GMT</pubDate>
    </item>
    <item>
      <title>错误：根：处理音频文件时出错：仅限整数、切片（`:`）、省略号（`...`）、numpy.newaxis（`None`）[关闭]</title>
      <link>https://stackoverflow.com/questions/78106913/errorrooterror-processing-audio-file-only-integers-slices-ellipsis</link>
      <description><![CDATA[def process_audio():
print(&quot;正在处理音频...&quot;)
如果“音频”不在 request.files 中：
    logging.error(&#39;未提供音频文件&#39;)
    return jsonify({&#39;error&#39;: &#39;未提供音频文件&#39;})

文件 = request.files[&#39;音频&#39;]
if file.filename == &#39;&#39;:
    logging.error(&#39;没有选择文件&#39;)
    return jsonify({&#39;error&#39;: &#39;没有选择文件&#39;})

如果文件：
    # 使用tempfile创建临时文件
    temp_audio_file = tempfile.NamedTemporaryFile(删除=False, 后缀=&#39;.wav&#39;)
    文件路径 = temp_audio_file.name
    尝试：
        文件.保存（文件路径）
    除了异常 e：
        logging.error(f&#39;保存临时文件时出错：{str(e)}&#39;)
        返回 jsonify({&#39;error&#39;: str(e)})

    尝试：
        new_audio_data = extract_audio_features（文件路径）
        打印（类型（新音频数据））
        打印（new_audio_data.shape）
        **new_audio_data.shape = (1, new_audio_data.size)**//这一行有错误
        Predicted_class = model.predict(new_audio_data)

        # 在此初始化特征反馈字典
        特征反馈={
            “衔接率”：feature_coefficients[&#39;衔接率&#39;]，
            “填充字数”: feature_coefficients[&#39;填充字数&#39;],
            “平均 F0”：feature_coefficients[&#39;平均 F0&#39;]，
            “语速”：feature_coefficients[&#39;语速&#39;]，
            “语音情绪”：feature_coefficients[&#39;语音情绪&#39;]，
        }

        Feedback_text = Provide_feedback(predicted_class, feature_feedback)
        logging.info(f“预测类别：{predicted_class}”)
        logging.info(f“反馈文本：{feedback_text}”)

    

在突出显示的行中遇到问题，请帮助尝试 gpt 替代衬里，但没有一个能工作，尝试了 3-4 个替代行，这太令人沮丧了，请帮助无法重塑数组和替代]]></description>
      <guid>https://stackoverflow.com/questions/78106913/errorrooterror-processing-audio-file-only-integers-slices-ellipsis</guid>
      <pubDate>Tue, 05 Mar 2024 10:17:23 GMT</pubDate>
    </item>
    <item>
      <title>变压器尺寸不匹配</title>
      <link>https://stackoverflow.com/questions/78106814/dimension-mismatch-in-transformer</link>
      <description><![CDATA[当我尝试训练模型时收到此错误。
&lt;块引用&gt;
ValueError：尺寸必须相等，但“{{nodetransformer_13/encoder_13/add}}=AddV2[T=DT_FLOAT](transformer_13/encoder_13/dense_858/Relu,transformer_13/encoder_13/strided_slice_1)”的尺寸为65和64输入形状：[8,65,512]，[1,64,512]

使用analyticsvidhya .只需修改下面给出的一些代码即可。
&lt;前&gt;&lt;代码&gt;features_shape = 2048

编码训练 = 排序（设置（img_name_vector））
image_dataset = tf.data.Dataset.from_tensor_slices(encode_train)
图像数据集 = 图像数据集.map(
            load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(8)

对于 img，tqdm(image_dataset) 中的路径：
    批处理特征=图像特征提取模型（img）
    batch_features = tf.reshape(batch_features,
                          （batch_features.shape[0]，-1，batch_features.shape[3]））

    对于 zip 中的 bf、p（batch_features，路径）：
         path_of_feature = p.numpy().decode(“utf-8”)
         自定义特征 = 自定义特征函数（特征路径）
         custom_features = np.array(custom_features.flatten())
         custom_features = np.pad(custom_features, (0, features_shape -
           custom_features.shape[0]), &#39;constant&#39;,constant_values=(0, 0)).astype(np.float32)

         组合特征 = np.vstack((bf.numpy(), custom_features)).astype(np.float32)

         np.save（特征路径，组合特征）

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78106814/dimension-mismatch-in-transformer</guid>
      <pubDate>Tue, 05 Mar 2024 10:00:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么增加层数或神经元数量会导致我的网络输出恒定数量？</title>
      <link>https://stackoverflow.com/questions/78106661/why-does-increasing-the-number-of-layers-or-neurons-cause-my-network-to-output-a</link>
      <description><![CDATA[我已经研究 LSTM 神经网络几个月了。由于准确性较低，我使用各种配置来训练该网络，试图对其进行优化。我面临的一个重要问题是，增加隐藏层或神经元的数量通常会导致网络输出恒定的数量，我不确定为什么会发生这种情况。尽管寻找解决方案并尝试不同的方法，我仍然无法解决这个问题。
以下是有关我的训练数据的一些信息：

我有 150 万个数据点，每个数据点由 0 到 1 之间归一化的 11 个字段组成。输出 (Y) 也是 0 到 1 之间的归一化数字。
网络使用 30 个数据点的序列进行训练。
我正在使用 LSTM 架构。
迄今为止最好的结果是通过 64、32、8、1 层（无 dropout）的网络结构实现的。
由于数字比例较高，我使用 float64 数据类型。
我尝试过训练 40、60 或 100 个 epoch，通常在 20-30 个 epoch 后损失达到 0.06 左右，网络始终欠拟合。
使用的激活函数是 tanh。

我面临一些挑战：

增加层数（例如 128、64、32、8、1 或 64、32、32、8）会产生恒定的输出。
无论我尝试过什么策略，我都无法使网络过度拟合。
]]></description>
      <guid>https://stackoverflow.com/questions/78106661/why-does-increasing-the-number-of-layers-or-neurons-cause-my-network-to-output-a</guid>
      <pubDate>Tue, 05 Mar 2024 09:37:38 GMT</pubDate>
    </item>
    <item>
      <title>为什么 SimpleNet 在“推断”阶段突然被杀</title>
      <link>https://stackoverflow.com/questions/78106566/why-simplenet-gets-killed-abruptly-on-inferring-stage</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78106566/why-simplenet-gets-killed-abruptly-on-inferring-stage</guid>
      <pubDate>Tue, 05 Mar 2024 09:19:50 GMT</pubDate>
    </item>
    <item>
      <title>如何部署机器学习算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78106414/how-to-deploy-machine-learning-algorithm</link>
      <description><![CDATA[所以我有一个 ML 算法，它使用两个文本之间的余弦相似度并返回相似度分数，我的问题是我们可以像在 aws sagemaker 或任何 EC2 实例上部署机器学习模型一样部署这个算法吗？没有训练脚本，也没有 model.pkl 文件，因为这纯粹是一种算法，我在其中获取文本输入并匹配存储在 postgres 数据库中的文本......
我们有什么办法可以实现这一点，或者我需要将此代码合并到我的后端逻辑中以部署在 AWS 上？
我尝试使用MLflow来达到预期的结果，但所有的努力都是徒劳的。]]></description>
      <guid>https://stackoverflow.com/questions/78106414/how-to-deploy-machine-learning-algorithm</guid>
      <pubDate>Tue, 05 Mar 2024 08:52:29 GMT</pubDate>
    </item>
    <item>
      <title>不规则形状检测和测量</title>
      <link>https://stackoverflow.com/questions/78105770/irregular-shape-detection-and-measurement</link>
      <description><![CDATA[我正在尝试使用 OpenCV Python 对榴莲水果进行一些图像分析，但这些图像很难分割。你们能推荐一些图像处理技术，我可以用它来分割和计算水果上的果皮/小室的数量吗？
原始图像如下所示：
原始图片
分割后的图像应如下所示：
理想输出
如果每个外皮都上色就更好了。
我尝试使用 Python 应用精明的边缘检测来强调边缘，并查看是否有任何可以从图像中提取的可能特征，但我认为没有基于我使用的算法。
灰度图像上的 Canny 边缘检测]]></description>
      <guid>https://stackoverflow.com/questions/78105770/irregular-shape-detection-and-measurement</guid>
      <pubDate>Tue, 05 Mar 2024 06:37:51 GMT</pubDate>
    </item>
    <item>
      <title>time_strech() 中的参数编号问题</title>
      <link>https://stackoverflow.com/questions/78105567/argument-number-issue-in-time-strech</link>
      <description><![CDATA[当我像这样定义 stretch() 函数时：
def 拉伸（数据，速率=0.8）：
    返回 librosa.effects.time_stretch(数据，速率)

它给出了错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
TypeError Traceback（最近一次调用最后一次）
[56] 中的单元格，第 6 行
      4 y = []
      5 for i in range(len(audio_df))：
----&gt; 6 feature=get_features(audio_df[&#39;Arrays&#39;].iloc[i]);
      7 表示特征中的 j：
      8 x.追加（j）

Cell In[55]，第 14 行，在 get_features(data) 中
     11 结果.追加（res2）
     13#带伸展和俯仰
---&gt; 14 new_data = 拉伸（数据）
     15 data_stretch_pitch = 音调（new_data，sr）
     16 res3 = extract_features（data_stretch_pitch）

单元格 In[53]，第 7 行，拉伸（数据，速率）
      6 def 拉伸（数据，速率=0.8）：
----&gt; 7 返回 librosa.effects.time_stretch(数据, 速率)

类型错误：time_stretch() 需要 1 个位置参数，但给出了 2 个

但是当我删除“rate”参数时，它会给出错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
TypeError Traceback（最近一次调用最后一次）
单元格 In[58]，第 6 行
      4 y = []
      5 for i in range(len(audio_df))：
----&gt; 6 feature=get_features(audio_df[&#39;Arrays&#39;].iloc[i]);
      7 表示特征中的 j：
      8 x.追加（j）

Cell In[55]，第 14 行，在 get_features(data) 中
     11 结果.追加（res2）
     13#带伸展和俯仰
---&gt; 14 new_data = 拉伸（数据）
     15 data_stretch_pitch = 音调（new_data，sr）
     16 res3 = extract_features（data_stretch_pitch）

单元格 In[57]，第 7 行，拉伸（数据，速率）
      6 def 拉伸（数据，速率=0.8）：
----&gt; 7 返回 librosa.effects.time_stretch(data)

类型错误：time_stretch() 缺少 1 个必需的仅关键字参数：“rate”

我删除了“rate”参数以尝试使用默认值（即使这会对数据产生任何影响），但它仍然给出错误。
我可能是错的，但据我所知，当我给出 2 个参数时，它说它只需要 1 个，当我给出 1 时，它说我缺少一个参数，我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/78105567/argument-number-issue-in-time-strech</guid>
      <pubDate>Tue, 05 Mar 2024 05:50:49 GMT</pubDate>
    </item>
    <item>
      <title>修改现有的文本识别代码以预测用户提供的图像</title>
      <link>https://stackoverflow.com/questions/78105221/modify-existing-text-recognition-code-to-predict-user-supplied-image</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78105221/modify-existing-text-recognition-code-to-predict-user-supplied-image</guid>
      <pubDate>Tue, 05 Mar 2024 03:48:14 GMT</pubDate>
    </item>
    <item>
      <title>shap 与 PolynomialFeatures(level=1) 兼容吗？</title>
      <link>https://stackoverflow.com/questions/78099333/is-shap-compatible-with-polynomialfeaturesdegree-1</link>
      <description><![CDATA[我正在尝试绘制 shap.summary_plot 进行多项式回归，但它给出了尺寸错误
;形状 (12,) 和 (11,) 未对齐： 12(dim 0)!= 11(dim 0)

模型=多项式特征（度=1）

解释器= shap.Explainer（模型=模型，feature_names=df.columns，算法=&#39;自动&#39;）

当我尝试使用 LinearExplainer 时仍然遇到相同的错误
explainer = shap.Explainer(model = model, Algorithm = &#39;auto&#39;)
解释器 = shap.LinearExplainer(模型 = 模型)


shap_values = 解释器.shap_values(df)

我只是想知道 shap 是否与多项式回归兼容。如果兼容如何构建解释器]]></description>
      <guid>https://stackoverflow.com/questions/78099333/is-shap-compatible-with-polynomialfeaturesdegree-1</guid>
      <pubDate>Mon, 04 Mar 2024 06:34:57 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“borb.pdf”导入名称“Run”（/usr/local/lib/python3.10/dist-packages/borb/pdf/__init__.py）</title>
      <link>https://stackoverflow.com/questions/78019286/importerror-cannot-import-name-run-from-borb-pdf-usr-local-lib-python3-10</link>
      <description><![CDATA[from borb.pdf 导入文档
从 borb.pdf 导入页面
从 borb.pdf 导入段落
从 borb.pdf 导入 运行

pdf_text =“”“”
长文本在这里
分为各个部分
”“”

# 创建 PDF 文档
文档 = 文档()

# 将简历文本分成几个部分
sections = pdf_text.split(“\n\n”)

# 迭代各个部分并将它们添加到 PDF 文档中
对于节中的节：
    段落 = 段落()
    运行 = [运行（文本=部分）]
    段落.add(*运行)
    页 = 页（）
    page.add(段落)
    文档.添加（页面）

# 将PDF文档保存到文件中
document.save(“更新后的.pdf”)




在上面的代码中，我尝试使用 borb 将文本插入 pdf
ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-19-d90b0d6013d2&gt;在&lt;细胞系：8&gt;()
      6 from borb.pdf import 段落
      7 #from borb.pdf.text.run 导入运行
----&gt; 8 从borb.pdf导入运行
      9 #from borb.pdf.text.run 导入运行
     10

ImportError：无法从“borb.pdf”导入名称“Run”（/usr/local/lib/python3.10/dist-packages/borb/pdf/__init__.py）

但是我收到上述错误，“运行”功能是否已弃用？以及如何解决上述错误？
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78019286/importerror-cannot-import-name-run-from-borb-pdf-usr-local-lib-python3-10</guid>
      <pubDate>Mon, 19 Feb 2024 08:34:27 GMT</pubDate>
    </item>
    </channel>
</rss>