<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 06 Dec 2023 21:12:48 GMT</lastBuildDate>
    <item>
      <title>如何在 PyTorch 中使用分布式数据并行处理具有昂贵块读取时间的大型数据集？</title>
      <link>https://stackoverflow.com/questions/77615926/how-to-use-distributed-data-parallelism-in-pytorch-with-large-datasets-with-expe</link>
      <description><![CDATA[我有一个由 100 个 .npz 文件组成的数据集，其中包含形状为 (285341, 60664) 的 98% 稀疏 scipy CSR 矩阵，其中行是样本数，列是特征大小。我想在数据集上运行变分自动编码器。我可以访问大内存节点（每个 1.5TB RAM）、计算节点（总共 190GB RAM）和 4 个 GPU（总共 190GB RAM）。目前主要的瓶颈是加载数据，因为整个数据集无法立即装入内存。有哪些仍然允许随机洗牌并减少读取时间的建议？
已尝试过的内容：

使用 MapDataset 来分离不断填充队列并在加载时随机洗牌的加载线程。似乎只在一个 GPU 上工作，但现在是在工作人员之间分配的方式。
IterableDataset 的功能与 MapDataset 相同，但使用了worker_init_fn 来分割负载，但不断出现未实现的错误。 （注意：类太大而且吓人，但如果需要的话可以附加，以及 DataLoader 初始化调用）
]]></description>
      <guid>https://stackoverflow.com/questions/77615926/how-to-use-distributed-data-parallelism-in-pytorch-with-large-datasets-with-expe</guid>
      <pubDate>Wed, 06 Dec 2023 19:51:51 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“Flags”对象没有属性“c_contigious”</title>
      <link>https://stackoverflow.com/questions/77615883/attributeerror-flags-object-has-no-attribute-c-contiguous</link>
      <description><![CDATA[我正在阅读 Aurélien Géron 编写的《机器学习实践》一书，但遇到了以下错误。
代码：
y_train_large = (y_train.astype(&quot;int&quot;) &gt;= 7)
y_train_odd = (y_train.astype(“int”) % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]

＃模型
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)

y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)

最后一行产生以下错误：
&lt;前&gt;&lt;代码&gt;{
AttributeError: &#39;Flags&#39; 对象没有属性 &#39;c_contigious&#39;”
}

由于我正在关注这本书，所以我希望这段代码能够工作。我尝试过 Google Bard 和 Claude AI 聊天机器人的解决方案，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77615883/attributeerror-flags-object-has-no-attribute-c-contiguous</guid>
      <pubDate>Wed, 06 Dec 2023 19:42:47 GMT</pubDate>
    </item>
    <item>
      <title>自动执行 Sagemaker Autopilot 生成的笔记本</title>
      <link>https://stackoverflow.com/questions/77615516/automatic-execution-of-sagemaker-autopilot-generated-notebook</link>
      <description><![CDATA[我能够将数据从本地计算机上传到我的 s3 存储桶，根据该数据创建自动驾驶仪作业，将自动驾驶仪作业的文件输出放回我的 s3 存储桶，并将输出下载到我的本地计算机。我是在 Python 代码中完成这一切的。唯一的问题是，我想运行自动驾驶作业在 Sagemaker 中生成的笔记本，然后从我的存储桶中提取这些执行的笔记本。我想坚持以编程方式执行此操作。有没有人遇到过类似的任务并能够完成它？另外，我是否使用了可行或现实的方法？
我能够将自动驾驶仪生成的笔记本从我的 s3 存储桶下载到本地计算机，并使用此生命周期配置使用该笔记本创建一个笔记本实例：
lifecycle_config_script = &quot;&quot;&quot;&quot;
#!/bin/bash

设置-e

BUCKET_NAME=“{bucket_name}”
NOTEBOOK_PATHS=({notebook_paths})

pip 安装造纸厂

对于“${{NOTEBOOK_PATHS[@]}}”中的笔记本
做
    aws s3 cp“s3://${{BUCKET_NAME}}/${{NOTEBOOK}}” “/home/ec2-user/SageMaker/${{NOTEBOOK}}”
    papermill“/home/ec2-user/SageMaker/${{NOTEBOOK}}” “/home/ec2-user/SageMaker/executed-${{NOTEBOOK}}”
    aws s3 cp“/home/ec2-user/SageMaker/executed-${{NOTEBOOK}}” “s3://${{BUCKET_NAME}}/executed-${{NOTEBOOK}}”
完毕
&quot;&quot;&quot;.format(bucket_name=bucketName, notebook_paths=&#39; &#39;.join([&#39;&quot;&#39; + notebook + &#39;&quot;&#39; for notebook_files]))

在配置实例花费超过 5 分钟后，我查看了 cloudwatch 日志中的生命周期配置，并收到此导入错误：
ImportError：urllib3 v2.0 仅支持 OpenSSL 1.1.1+，当前“ssl”模块使用“OpenSSL 1.0.2k-fips 26 Jan 2017”编译。请参阅：https://github.com/urllib3/urllib3/issues/2168
]]></description>
      <guid>https://stackoverflow.com/questions/77615516/automatic-execution-of-sagemaker-autopilot-generated-notebook</guid>
      <pubDate>Wed, 06 Dec 2023 18:28:43 GMT</pubDate>
    </item>
    <item>
      <title>基于相同输入数据的并行或共享回归网络会更好吗？为什么？</title>
      <link>https://stackoverflow.com/questions/77615153/would-it-be-better-to-have-parallel-or-a-shared-regression-network-based-on-the</link>
      <description><![CDATA[我将多个并行回归网络组合成一个模型，其中组合输出以创建单个损失函数。这些网络正在寻找相同数据的不同方面，并同时进行训练。这可以被认为是一个基于物理的神经网络。
本能地，我想说，分割网络允许每个网络拥有自己的权重，而不受其他方面的干扰，这将加快训练速度和/或提高性能。 ChatGPT 似乎证实了我的怀疑，但无法给我任何来源。
有人有任何论文/证明或知道这两种方法的更具体术语吗？我只是真的不知道如何提出这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77615153/would-it-be-better-to-have-parallel-or-a-shared-regression-network-based-on-the</guid>
      <pubDate>Wed, 06 Dec 2023 17:29:30 GMT</pubDate>
    </item>
    <item>
      <title>使用（非图像）细胞计数数据创建 pytorch CNN</title>
      <link>https://stackoverflow.com/questions/77615149/creating-a-pytorch-cnn-using-non-image-cytometric-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77615149/creating-a-pytorch-cnn-using-non-image-cytometric-data</guid>
      <pubDate>Wed, 06 Dec 2023 17:28:44 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 故障排除：常见错误和解决方案[关闭]</title>
      <link>https://stackoverflow.com/questions/77614844/troubleshooting-tensorflow-navigating-common-errors-and-solutions</link>
      <description><![CDATA[从 matplotlib 导入 gridspec
将 matplotlib.pylab 导入为 plt
将 numpy 导入为 np
将张量流导入为 tf
导入tensorflow_hub作为集线器#

安装后无法修复tensorflow的错误
一次又一次安装后我没有弄清楚错误，他们给出的错误为
错误：找不到满足张量流要求的版本（来自版本：无）
错误：找不到张量流的匹配分布
]]></description>
      <guid>https://stackoverflow.com/questions/77614844/troubleshooting-tensorflow-navigating-common-errors-and-solutions</guid>
      <pubDate>Wed, 06 Dec 2023 16:37:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 tidymodels 框架中的 Youden 索引获取 ML 性能指标？</title>
      <link>https://stackoverflow.com/questions/77614694/how-do-you-get-ml-performance-metrics-using-the-youden-index-in-the-tidymodels-f</link>
      <description><![CDATA[如何使用 tidymodels 框架中的 Youden 索引获取机器学习性能指标？
我在网上搜索过示例，但没有找到。]]></description>
      <guid>https://stackoverflow.com/questions/77614694/how-do-you-get-ml-performance-metrics-using-the-youden-index-in-the-tidymodels-f</guid>
      <pubDate>Wed, 06 Dec 2023 16:12:03 GMT</pubDate>
    </item>
    <item>
      <title>为回归任务微调 BERT 时，预测范围太小而无法拟合数据</title>
      <link>https://stackoverflow.com/questions/77613824/range-of-predictions-too-low-to-fit-data-while-finetuning-bert-for-regression-ta</link>
      <description><![CDATA[我正在尝试针对回归任务微调预训练的 BERT。然而，与真实值的范围相比，预测的范围非常低，如下图所示：
实际与预测
我查看了验证集上每个时期之后的预测，发现了类似的趋势。
我的代码在这里：
def train_model(df):
    # 加载 BERT 分词器和模型
    tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)
    模型 = BertForSequenceClassification.from_pretrained(&#39;bert-base-uncased&#39;, num_labels=1)

    # 准备数据
    texts = df[“句子”].tolist()
    目标 = np.log10(df[“分数”]).astype(float).tolist()

    # 将数据分为训练集、验证集和测试集
    texts_train、texts_temp、targets_train、targets_temp = train_test_split（文本、目标、test_size=0.2、random_state=42）
    texts_val、texts_test、targets_val、targets_test = train_test_split(texts_temp、targets_temp、test_size=0.5、random_state=42)

    # 标记并准备数据
    tokenized_train = tokenizer(texts_train, padding=True, truncation=True, return_tensors=“pt”)
    tokenized_val = tokenizer(texts_val, padding=True, truncation=True, return_tensors=“pt”)
    tokenized_test = tokenizer(texts_test, padding=True, truncation=True, return_tensors=“pt”)

    train_dataset = TensorDataset(tokenized_train[“input_ids”], tokenized_train[“attention_mask”], torch.tensor(targets_train))
    val_dataset = TensorDataset(tokenized_val[“input_ids”], tokenized_val[“attention_mask”], torch.tensor(targets_val))
    test_dataset = TensorDataset(tokenized_test[“input_ids”], tokenized_test[“attention_mask”], torch.tensor(targets_test))

    # 定义损失函数、优化器和评估指标
    标准 = torch.nn.MSELoss()
    优化器 = AdamW(model.parameters(), lr=1e-5)

    # 训练循环
    纪元数 = 10
    批量大小 = 16

    对于范围内的纪元（num_epochs）：
        模型.train()
        对于 DataLoader 中的批次（train_dataset，batch_size=batch_size，shuffle=True）：
            input_ids、attention_mask、标签=批次
            输出=模型（input_ids，attention_mask=attention_mask，标签=标签）
            损失 = 输出.损失
            优化器.zero_grad()
            loss.backward()
            优化器.step()

        ＃ 验证
        模型.eval()
        使用 torch.no_grad()：
            val_预测 = []
            对于DataLoader中的val_batch（val_dataset，batch_size=batch_size）：
                val_input_ids、val_attention_mask、val_labels = val_batch
                val_outputs = 模型（val_input_ids，attention_mask=val_attention_mask）
                val_predictions.extend(val_outputs.logits.squeeze().tolist())
            val_loss = criteria(torch.tensor(val_predictions), torch.tensor(targets_val))
            print(f&#39;Epoch {epoch + 1}/{num_epochs}, 验证损失: {val_loss.item()}&#39;)

    ＃ 测试
    模型.eval()
    使用 torch.no_grad()：
        测试预测 = []
        对于DataLoader中的test_batch（test_dataset，batch_size=batch_size）：
            test_input_ids、test_attention_mask、test_labels = test_batch
            test_outputs = 模型（test_input_ids，attention_mask=test_attention_mask）
            test_predictions.extend(test_outputs.logits.squeeze().tolist())

    # 计算测试指标
    test_loss =mean_squared_error（test_predictions，targets_test）
    print(f&#39;测试损失: {test_loss}&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/77613824/range-of-predictions-too-low-to-fit-data-while-finetuning-bert-for-regression-ta</guid>
      <pubDate>Wed, 06 Dec 2023 14:14:41 GMT</pubDate>
    </item>
    <item>
      <title>训练 llm 以在图数据库中生成查询</title>
      <link>https://stackoverflow.com/questions/77613507/training-llm-for-query-generation-in-a-graph-database</link>
      <description><![CDATA[如果我开发了一个有自己的查询语言的图数据库。我必须找到一种方法向 llm 提供图表，然后 llm 应该能够生成我们数据库的查询。
我在 langchain 中发现了类似的东西，我们可以向它提供 rdf 文件，然后它会生成 sparql 查询。
所以我对此有很多疑问，因为我对此很陌生：
是否可以使用全新的技术来培训法学硕士，就像我们的数据库一样。如果可以的话怎么办。
我知道我们必须向法学硕士提供训练数据。那么在这种情况下，它会是我们数据库查询的数据集吗？如果是，那么我们必须在数据集中提供多少个查询。
抱歉，问题不详细，这只是我第二次在这里问。]]></description>
      <guid>https://stackoverflow.com/questions/77613507/training-llm-for-query-generation-in-a-graph-database</guid>
      <pubDate>Wed, 06 Dec 2023 13:34:06 GMT</pubDate>
    </item>
    <item>
      <title>将机器学习应用于基础无线通信网络？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77613041/apply-machine-learning-in-basic-wireless-communication-network</link>
      <description><![CDATA[如何启动无线通信机器学习项目，特别关注建立源-目的地直接链路并预测目的地接收的数据？]]></description>
      <guid>https://stackoverflow.com/questions/77613041/apply-machine-learning-in-basic-wireless-communication-network</guid>
      <pubDate>Wed, 06 Dec 2023 12:27:21 GMT</pubDate>
    </item>
    <item>
      <title>RNN 模型的 RMSE 值极高</title>
      <link>https://stackoverflow.com/questions/77612881/rmse-value-extremly-high-on-rnn-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77612881/rmse-value-extremly-high-on-rnn-model</guid>
      <pubDate>Wed, 06 Dec 2023 11:59:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow dqn_agentcollect_policy 时出错</title>
      <link>https://stackoverflow.com/questions/77541451/error-while-using-tensorflow-dqn-agent-collect-policy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77541451/error-while-using-tensorflow-dqn-agent-collect-policy</guid>
      <pubDate>Fri, 24 Nov 2023 07:50:20 GMT</pubDate>
    </item>
    <item>
      <title>在新计算机上安装后 CUDA 无法与 TensorFlow 一起使用“ptxas 在将 ptx 编译为 sass 期间返回错误”</title>
      <link>https://stackoverflow.com/questions/77100654/cuda-not-working-with-tensorflow-after-install-on-new-computer-ptxas-returned-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77100654/cuda-not-working-with-tensorflow-after-install-on-new-computer-ptxas-returned-a</guid>
      <pubDate>Wed, 13 Sep 2023 21:41:04 GMT</pubDate>
    </item>
    <item>
      <title>用 BS 解释训练我的 Keras 模型时出现的红色元素</title>
      <link>https://stackoverflow.com/questions/76102956/explaining-the-red-elements-with-bs-that-appear-when-training-my-keras-model</link>
      <description><![CDATA[我对 keras 还很陌生，但已经完成了 Mnist 数据集并达到了 99.2% 的准确率，所以我至少知道如何训练模型。我遇到的问题是它看起来与我所做的其他训练样本有很大不同。我拉了一个 git repo 并从那里开始工作。谁能解释一下这个输出：
这是我期望的输出：在此处输入图像描述
但我不断收到这样的信息：
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/76102956/explaining-the-red-elements-with-bs-that-appear-when-training-my-keras-model</guid>
      <pubDate>Tue, 25 Apr 2023 15:32:11 GMT</pubDate>
    </item>
    <item>
      <title>Pyro Paramstore 的不同访问方法会产生不同的结果</title>
      <link>https://stackoverflow.com/questions/61684499/different-access-methods-to-pyro-paramstore-give-different-results</link>
      <description><![CDATA[我正在学习预测中的 Pyro 介绍性教程，并尝试访问学习到的参数训练模型后，我对其中一些模型使用不同的访问方法得到了不同的结果（而其他模型得到了相同的结果）。
以下是本教程中可重现的精简代码：
导入火炬
进口火爆
导入 Pyro.distributions 作为 dist
从pyro.contrib.examples.bart导入load_bart_od
从pyro.contrib.forecast导入ForecastingModel，Forecaster

pyro.enable_validation（真）
Pyro.clear_param_store()

火爆.__版本__
#&#39;1.3.1&#39;
火炬.__版本__
#&#39;1.5.0+cu101&#39;

# 导入&amp;准备数据
数据集 = load_bart_od()
T, O, D = 数据集[&quot;计数&quot;].shape
data = dataset[&quot;counts&quot;][:T // (24 * 7) * 24 * 7].reshape(T // (24 * 7), -1).sum(-1).log()
数据 = data.unsqueeze(-1)
T0 = 0 # 开始
T2 = data.size(-2) # 结束
T1 = T2 - 52 # 训练/测试分割

# 定义模型类
类 Model1（预测模型）：

    def 模型（自身、零数据、协变量）：
        data_dim = Zero_data.size(-1)
        feature_dim = covariates.size(-1)

        偏差 =pyro.sample(&quot;偏差&quot;, dist.Normal(0, 10).expand([data_dim]).to_event(1))
        重量 =pyro.sample(&quot;重量&quot;, dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))
        预测 = 偏差 + (权重 * 协变量).sum(-1, keepdim=True)
        断言 Prediction.shape[-2:] == Zero_data.shape

        noise_scale =pyro.sample(&quot;noise_scale&quot;, dist.LogNormal(-5, 5).expand([1]).to_event(1))
        噪声距离 = dist.Normal(0, 噪声尺度)

        self.predict(noise_dist, 预测)

# 拟合模型
Pyro.set_rng_seed(1)
Pyro.clear_param_store()
时间 = torch.arange(float(T2)) / 365
协变量 = torch.stack([时间], 暗淡=-1)
预测器=预测器（模型1（），数据[：T1]，协变量[：T1]，学习率= 0.1）

到目前为止一切顺利；现在，我想检查存储在 Paramstore 中的学习到的潜在参数。似乎有不止一种方法可以做到这一点；使用 get_all_param_names() 方法：
pyro.get_param_store().get_all_param_names() 中的名称：
    打印（名称，pyro.param（名称）.data.numpy（））

我明白了
AutoNormal.locs.bias [14.585433]
AutoNormal.scales.bias [0.00631594]
AutoNormal.locs.weight [0.11947815]
AutoNormal.scales.weight [0.00922901]
AutoNormal.locs.noise_scale [-2.0719821]
AutoNormal.scales.noise_scale [0.03469057]

但是使用named_pa​​rameters()方法：
pyro.get_param_store().named_pa​​rameters()

为位置 (locs) 参数提供相同的值，但为所有比例参数提供不同的值：
dict_items([
(&#39;AutoNormal.locs.bias&#39;,参数包含：tensor([14.5854],requires_grad=True)),
(&#39;AutoNormal.scales.bias&#39;,参数包含：tensor([-5.0647],requires_grad=True)),
(&#39;AutoNormal.locs.weight&#39;,参数包含:tensor([0.1195],requires_grad=True)),
(&#39;AutoNormal.scales.weight&#39;,参数包含：tensor([-4.6854],requires_grad=True)),
(&#39;AutoNormal.locs.noise_scale&#39;,参数包含：tensor([-2.0720],requires_grad=True)),
(&#39;AutoNormal.scales.noise_scale&#39;, 参数包含：tensor([-3.3613], require_grad=True))
]）

这怎么可能？根据文档，Paramstore是一个简单的键值存储；里面只有这六个键：
pyro.get_param_store().get_all_param_names() # .keys() 方法给出相同的结果
＃ 结果
字典键（[
&#39;AutoNormal.locs.bias&#39;,
&#39;AutoNormal.scales.bias&#39;,
&#39;AutoNormal.locs.weight&#39;,
&#39;AutoNormal.scales.weight&#39;,
&#39;AutoNormal.locs.noise_scale&#39;,
&#39;AutoNormal.scales.noise_scale&#39;])

因此，不可能一种方法访问一组项目，而另一种方法访问不同的项目。
我在这里遗漏了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/61684499/different-access-methods-to-pyro-paramstore-give-different-results</guid>
      <pubDate>Fri, 08 May 2020 17:20:33 GMT</pubDate>
    </item>
    </channel>
</rss>