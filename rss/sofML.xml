<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 01 Dec 2023 15:14:31 GMT</lastBuildDate>
    <item>
      <title>需要使用自定义高尔斯距离度量进行 KNN 回归的 python 实现吗？</title>
      <link>https://stackoverflow.com/questions/77585984/need-python-implementation-for-knn-regression-with-custom-metric-of-gowers-dista</link>
      <description><![CDATA[我有一个样本数据集，想要使用 gowers 距离来查找 KNN 回归的邻居
示例输入数据：
&lt;前&gt;&lt;代码&gt;
将 pandas 导入为 pd
将 numpy 导入为 np

df = pd.DataFrame([[1,2.6,&#39;A&#39;],[12,5,&#39;X&#39;],[4,7,&#39;A&#39;]])
df.columns = [&#39;Num_1&#39;,&#39;Num_2&#39;,&#39;Cat_1&#39;]

正如数据中我有分类变量和数值变量一样，需要一个自定义度量函数来拟合 Kneigbors 的种植者距离吗？]]></description>
      <guid>https://stackoverflow.com/questions/77585984/need-python-implementation-for-knn-regression-with-custom-metric-of-gowers-dista</guid>
      <pubDate>Fri, 01 Dec 2023 14:31:08 GMT</pubDate>
    </item>
    <item>
      <title>如何计算双向部分相关性（即如何在多个变量上边缘化模型）？</title>
      <link>https://stackoverflow.com/questions/77585923/how-to-compute-two-way-partial-dependence-ie-how-to-marginalize-a-model-over-m</link>
      <description><![CDATA[我想了解双向部分依赖的计算。在本例中，我正在使用随机森林。玩具模型：
library(ggplot2) # 访问mpg数据集
mod &lt;- ranger::ranger(公式=year ~ cyl + cty + displ,
                      数据=英里/加仑，概率= TRUE）

背景：计算单个变量的部分依赖性：
要计算一个变量的部分值，例如 cty，我会在支撑上定义值
grid_size &lt;- 10
cty_vals &lt;- seq(min(mpg$cty), max(mpg$cty), length.out = grid_size)

对于每个值，预测一个数据集，其中所有观测值都具有该 cty 值。
pd_dat &lt;- do.call(rbind, lapply(cty_vals, function(cty_val){
   d &lt;- 英里/加仑
   d$cty &lt;- cty_val
   返回(d)
 })
）

预测(mod, pd_dat)$预测

为了获得最终的 PD，我将对每个 cty_val 进行平均预测（未显示）。
目标：计算多路部分依赖：哪种方法？
假设我现在想要计算双向部分依赖 $PD(cyl, displ)$。为每个变量定义网格：
cty_vals &lt;- seq(min(mpg$cty), max(mpg$cty), length.out = grid_size)
displ_vals &lt;- seq(min(mpg$displ), max(mpg$displ), length.out = grid_size)

从这里我看到两个选项。

预测包含 cty 和 displ 详尽组合的数据集

设置选项 1：
组合 &lt;- Expand.grid(cty_vals, displ_vals)
名称(组合) &lt;- c(&#39;cty&#39;, &#39;displ&#39;)


预测包含 cty 和 displ 任意组合的数据集

设置选项 2：
组合 &lt;- data.frame(cty_vals, displ_vals)
名称(组合) &lt;- c(&#39;cty&#39;, &#39;displ&#39;)

用于计算预测的结果数据框：
&lt;前&gt;&lt;代码&gt;
pd_dat &lt;- do.call(rbind, lapply(1:nrow(combos), function(i){
     d &lt;- 英里/加仑
     d$cty &lt;- 组合$cty[i]
     d$displ &lt;- 组合$displ[i]
     返回(d)
}））

无论哪种情况，我认为最终结果都会总结对 cyl 和 displ 每种组合的预测。
库(dplyr)

preds &lt;- cbind(组合, 预测(mod, pd_dat)$预测)
名称(preds)[3:4] &lt;- sprintf(&#39;prob_%s&#39;, mod$forest$class.values )

预测%&gt;%
  group_by(cty, displ) %&gt;%
  总结（partial_2way_1999 = 平均值（prob_1999），
            partial_2way_2008 = 平均值(prob_2008))

我的直觉是选择选项 1（预测两个变量的详尽组合）。]]></description>
      <guid>https://stackoverflow.com/questions/77585923/how-to-compute-two-way-partial-dependence-ie-how-to-marginalize-a-model-over-m</guid>
      <pubDate>Fri, 01 Dec 2023 14:20:59 GMT</pubDate>
    </item>
    <item>
      <title>用于检测 BIM 模型中错误的机器学习算法 [关闭]</title>
      <link>https://stackoverflow.com/questions/77585593/machine-learning-algorithm-to-detect-errors-in-bim-models</link>
      <description><![CDATA[我正在开展一个学校项目。我正在尝试开发一种机器学习算法来检测 BIM 模型中的错误。现在我已经将范围缩小到自行车停放处。我有很多从网上免费获得的 Bim 模型。有人知道我该怎么做吗？由于我是机器学习的新手，示例代码确实很有帮助。
我需要一个模型来检测冲突（如果可能）以及准确性。我似乎无法在该项目上取得突破。我被困住了。]]></description>
      <guid>https://stackoverflow.com/questions/77585593/machine-learning-algorithm-to-detect-errors-in-bim-models</guid>
      <pubDate>Fri, 01 Dec 2023 13:27:36 GMT</pubDate>
    </item>
    <item>
      <title>对于分割数据，如果我不指定分割比率，pytorch会自己随机进行吗？</title>
      <link>https://stackoverflow.com/questions/77584885/for-splitting-the-data-does-pytorch-do-it-by-itself-randomly-if-i-don-t-specify</link>
      <description><![CDATA[对于分割数据，如果我不指定分割比例，pytorch 会自行随机进行吗？
我正在研究 pytorch 深度学习模型自动编码器，我有包含 10 个类和 500 000 行的数据集（csv 文件）。
我删除了标签列。
我看到一篇研究论文代码，他们没有拆分代码，而是从数据集（csv 文件）中删除了标签]]></description>
      <guid>https://stackoverflow.com/questions/77584885/for-splitting-the-data-does-pytorch-do-it-by-itself-randomly-if-i-don-t-specify</guid>
      <pubDate>Fri, 01 Dec 2023 11:17:31 GMT</pubDate>
    </item>
    <item>
      <title>InvalidArgumentError：double 的 attr 'Tindices' 的值不在允许值列表中：int16、int32、int64</title>
      <link>https://stackoverflow.com/questions/77584003/invalidargumenterror-value-for-attr-tindices-of-double-is-not-in-the-list-of</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77584003/invalidargumenterror-value-for-attr-tindices-of-double-is-not-in-the-list-of</guid>
      <pubDate>Fri, 01 Dec 2023 08:53:25 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 分类，XGBClassifier 与 xgb.train 的 AUC 分数不同，即使在舍入预测概率后也是如此</title>
      <link>https://stackoverflow.com/questions/77583899/xgboost-classification-different-auc-score-for-xgbclassifier-vs-xgb-train-even</link>
      <description><![CDATA[看起来 XGBClassifier 是 xgb.train 的包装器。我试图使用 xgb.train 和 &quot;objective&quot;: &quot;binary:logistic&quot; 训练二元分类器。
似乎使用 xgb.train 后跟 .predict() 返回预测概率，我们可以将其舍入为 0 或 1 以进行分类。
但是，即使在训练数据集上与 XGBClassifier 的 AUC 分数进行比较时，xgb.train 方法也明显较差......
使用xgb.train作为分类器的正确方法是什么？
X = df[X_colnames]
y = df[&#39;BP命中&#39;].astype(&#39;类别&#39;)
dtrain = xgb.DMatrix(X, 标签=y)
param = {“目标”：“二进制：逻辑”，}
模型 = xgb.train(param,dtrain)
y_hat = model.predict(xgb.DMatrix(X))
打印（y_帽子）
print(sklearn.metrics.roc_auc_score(y,[round(y) for y in y_hat]))


模型= XGBClassifier（目标=&#39;二进制：逻辑&#39;）
# 定义训练数据
X = df[X_列名]
y = df[&#39;BP命中&#39;].astype(&#39;类别&#39;)
模型.fit(X,y)
打印（模型.预测（X））
print(sklearn.metrics.roc_auc_score(y,[model.predict(X) 中 y 的 round(y)]))

输出：
&lt;预&gt;&lt;代码&gt;[0.02280498 0.02280498 0.02280498 ... 0.02280498 0.02280498 0.02280498]
0.9427811205601163
[0 0 0 ... 0 0 0]
1.0
]]></description>
      <guid>https://stackoverflow.com/questions/77583899/xgboost-classification-different-auc-score-for-xgbclassifier-vs-xgb-train-even</guid>
      <pubDate>Fri, 01 Dec 2023 08:32:40 GMT</pubDate>
    </item>
    <item>
      <title>如何使用openvino优化模型和YOLO将目标检测应用程序转换为exe</title>
      <link>https://stackoverflow.com/questions/77583764/how-to-convert-object-detection-application-in-exe-by-using-openvino-optimized</link>
      <description><![CDATA[当我使用这个命令pyinstaller main.py --onefile -w 将项目转换为exe文件时，我遇到了这个问题：
错误：[Errno 2] 没有这样的文件或目录：&#39;&#39;C:\Users\sachin\Appdata\Local\Temp\_MEI177322\ultralytics\yolo\cfg\default.yaml。
]]></description>
      <guid>https://stackoverflow.com/questions/77583764/how-to-convert-object-detection-application-in-exe-by-using-openvino-optimized</guid>
      <pubDate>Fri, 01 Dec 2023 07:59:57 GMT</pubDate>
    </item>
    <item>
      <title>寻找特定领域的数据集来训练机器学习模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77583636/seeking-domain-specific-datasets-for-training-machine-learning-models</link>
      <description><![CDATA[我目前正在开发机器学习模型，需要特定领域的数据集。我的目标是训练一个专门理解以领域为中心的内容并与之交互的模型，这些内容的范围可以从 IT 和工程等技术领域到医疗保健或金融等专业领域。
详细信息：
数据类型：我正在寻找包含特定领域术语、行话、工作流程以及与该领域专家相关的任何相关知识的数据集。
用途：目的是训练用于特定领域问答、内容生成和数据分析等任务的模型。
数据特异性：数据在领域覆盖范围方面越全面、越多样化越好。
我尝试过的：
我在 GitHub、Kaggle 和 Google 数据集搜索等平台上搜索了开源数据集。
我研究了学术数据库中的研究论文和特定领域的相关数据集。
我探索了与目标领域的行业合作伙伴的数据共享协议。
我正在联系社区中的任何人，看看是否有人提出建议或知道可以公开或购买此类特定于域的数据集的存储库。]]></description>
      <guid>https://stackoverflow.com/questions/77583636/seeking-domain-specific-datasets-for-training-machine-learning-models</guid>
      <pubDate>Fri, 01 Dec 2023 07:31:33 GMT</pubDate>
    </item>
    <item>
      <title>对视频中的帧进行分类以查看它是否包含一组幻灯片中的一张[关闭]</title>
      <link>https://stackoverflow.com/questions/77583613/categorise-a-frame-in-a-video-to-see-if-it-contains-one-of-a-set-of-slides</link>
      <description><![CDATA[我想要处理视频，其中讲师站在白板前，上面有多张幻灯片。他们可能会四处走动、挡住黑板或在幻灯片上书写。我已经收集了所有幻灯片，但我无法实时训练任何模型，即解决方案应该只是比较两个图像（视频帧和幻灯片图像）之间的“相似性”。我觉得问题是图像相似性和单一分类同时存在。
我的想法是每隔 30 秒左右抓取几帧（假设任何重要幻灯片的使用时间超过 30 秒），并将其与我准备的幻灯片进行比较（一场讲座通常有大约 9-10 张幻灯片）。这有多可行？
我不是在寻找代码，我来这里是为了了解总体思路。我想尽快完成这项工作，因此任何能够完成繁重工作的库都是（非常）可取的，但如果没有其他选择，我确实了解一点 PyTorch。如果唯一的选择是训练我自己的模型，什么架构/模型最适合这个？如果有人可以分享与此相关的任何资源，我也希望如此。]]></description>
      <guid>https://stackoverflow.com/questions/77583613/categorise-a-frame-in-a-video-to-see-if-it-contains-one-of-a-set-of-slides</guid>
      <pubDate>Fri, 01 Dec 2023 07:27:55 GMT</pubDate>
    </item>
    <item>
      <title>在启用反向传播的情况下，有效模拟具有异质空间和时间感受野的神经元？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77582849/efficient-simulation-of-neurons-with-heterogeneous-spatial-and-temporal-receptiv</link>
      <description><![CDATA[我想找到一种方法来对具有异构空间和时间感受野的神经元进行高效模拟，并且理想情况下启用反向传播，以便我可以微调感受野的权重。每个神经元的计算简单，但神经元数量较多（1e5 ~ 1e6）。主要困难在于每个神经元的空间和时间感受野的大小不同（从动物实验数据获得）并且变化很大。在GPU上进行矢量化运算有点困难。
模拟如下：
# 初始化
# 每个神经元的k和l的值是不同的。
获取输入图像的形状（在整个模拟过程中固定）。
对于每个神经元：
    (1).获取其空间感受野下的像素索引，存储为 [k x 2] 数组，因为空间感受野可能不是正方形。
    （2）。初始化空间感受野中的权重，存储为 [k x 1] 数组。
    （3）。获取时间感受野的长度l（时间步数）。
    （4）。初始化时间感受野中的权重，存储为 [l x 1] 数组。
    （5）。初始化一个空的 [l x 1] 数组缓冲区，用零填充。
将所有神经元的参数存储在列表中。

＃ 模拟
对于每个输入图像：
    对于每个神经元：
        (1).根据图像的 [k x 2] 像素索引获得展平的补丁，存储为 [k x 1] 数组。
        （2）。计算图像块与空间感受野权重的内积，输出 [1 x 1] 标量。
        （3）。删除缓冲区中的第一个元素，将其余元素与 [1 x 1] 标量（最后位置的标量）连接，输出 [l x 1] 更新的缓冲区。
        （4）。计算更新后的缓冲区与时间感受野权重的内积，输出 [1 x 1] 标量。
        （5）。将标量传递给 ReLU 函数，将输出设置为神经元的输出。

我已经在 Python JAX 中实现了上述过程。实现与上面的描述几乎完全相同，包括仿真阶段的双for循环。但CPU和GPU上的性能都很慢。
目前，我想找到一种方法来优化模拟过程中的每个神经元循环（因为在测试时，可以从相机实时获取输入图像）。初始化阶段的性能已经不错了。我想要实现的是：

在 CPU 上运行时使用所有可用的 CPU 内核。默认情况下，JAX 仅使用一个 CPU 核心。
在 GPU 上运行时对计算进行向量化，同时保持内存效率。每个神经元的空间和时间感受野的大小都不同。如果我们简单地将小感受野补零到最大尺寸，它可能很容易消耗整个 GPU 内存。
理想情况下，将来可以通过反向传播重复使用相同的模拟代码进行训练。

有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77582849/efficient-simulation-of-neurons-with-heterogeneous-spatial-and-temporal-receptiv</guid>
      <pubDate>Fri, 01 Dec 2023 03:26:31 GMT</pubDate>
    </item>
    <item>
      <title>将时间序列高分辨率数据集存储为一个更简单的事务集，其中包括其元数据[关闭]</title>
      <link>https://stackoverflow.com/questions/77582450/store-time-series-high-resolution-data-sets-each-computed-summarized-into-a-simp</link>
      <description><![CDATA[我正在测试时间序列高分辨率数据集，每个数据集都计算/汇总为一个更简单的事务集（包括其元数据）。这些存储在本地服务器中。我很少遇到连接表的需求；但是，我不断使用时间序列数据来创建其他指标来构建机器学习模型。
CSV 中的每个时间序列数据集最大可达 2.6MB，而交易数据则为 kB 大小。我有超过 20,000 组数据。
什么是具有最佳性能的数据库选项/架构？
关系型还是非关系型？
每个选项的供应商有哪些？
如何确定是否应该迁移到云服务器？
推荐的供应商有哪些？]]></description>
      <guid>https://stackoverflow.com/questions/77582450/store-time-series-high-resolution-data-sets-each-computed-summarized-into-a-simp</guid>
      <pubDate>Fri, 01 Dec 2023 00:47:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 VGG16 MNIST 数字进行迁移学习</title>
      <link>https://stackoverflow.com/questions/77568420/transfer-learning-using-vgg16-mnist-digits</link>
      <description><![CDATA[我正在尝试对 MNIST 数字执行迁移学习。我有兴趣获取 logits 并将其用于基于梯度的攻击。但由于某种原因，即使我的计算机是启用了 GPU 的 Apple m2max 计算机，内核仍然会死机。我也尝试使用 GPU 进行 colab，但遇到同样的问题。该数据集不太好学，我正在重用 imagenet 权重。我该如何解决这个问题？
类 VGG16TransferLearning(tf.keras.Model)：
  def __init__(自我，基本模型，模型)：
    超级（VGG16TransferLearning，自我）.__init__（）
    #基础模型
    self.base_model = 基本模型

   # 其他层
   self.flatten = tf.keras.layers.Flatten()
   self.dense1 = tf.keras.layers.Dense(512, 激活=&#39;relu&#39;)
   self.dense2 = tf.keras.layers.Dense(512, 激活=&#39;relu&#39;)
   self.dense3 = tf.keras.layers.Dense(10)
   self.layers_list = [self.flatten, self.dense1, self.dense2, self.dense3]
  
  #用其他层实例化基础模型
  self.model = models.Sequential(
    [self.base_model, *self.layers_list]
   ）

def 调用(self, *args, **kwargs):
  激活列表 = []
  输出=参数[0]
  
  对于 self.model.layers 中的图层：
    输出 = 层（输出）
    激活列表.append(out)
  如果 kwargs[&#39;训练&#39;]:
   返回
  别的：
   概率 = tf.nn.softmax(输出)
   返回，问题

这是上面类的实例化：
base_model = VGG16(weights=“imagenet”, include_top=False, input_shape=x_train[0].shape)

base_model.trainable = False
我的输入形状是(75,75,3)
这是编译和拟合方法
从tensorflow.keras导入层、模型

模型 = VGG16TransferLearning(base_model, 模型)
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),
          优化器=tf.keras.optimizers.legacy.Adam(),
          指标=[&#39;准确性&#39;])

model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))

这是我每次调用 fit 方法时遇到的错误：
内核重启
Untitled.ipynb 的内核似乎已经死亡。它将自动重新启动
]]></description>
      <guid>https://stackoverflow.com/questions/77568420/transfer-learning-using-vgg16-mnist-digits</guid>
      <pubDate>Wed, 29 Nov 2023 03:29:36 GMT</pubDate>
    </item>
    <item>
      <title>如何按照官方方式将 Hugging Face LLaMA v2 模型的权重重新初始化为原始模型？</title>
      <link>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</guid>
      <pubDate>Fri, 17 Nov 2023 03:15:56 GMT</pubDate>
    </item>
    <item>
      <title>运行时错误：对象没有属性 nms：</title>
      <link>https://stackoverflow.com/questions/63743516/runtimeerror-object-has-no-attribute-nms</link>
      <description><![CDATA[所以我按照本教程构建了一个对象检测，但我得到了一个我的朋友都没有遇到的错误（记住代码是在 MacOS 中运行）。我附上了错误消息的屏幕截图  我不断收到它，以防有任何帮助。
导入torchvision
导入CV2
将 matplotlib.pyplot 导入为 plt
从 PIL 导入图像
from torchvision import 转换为 T

模型 = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
模型.eval()

COCO_INSTANCE_CATEGORY_NAMES = [
    &#39;__background__&#39;, &#39;人&#39;, &#39;自行车&#39;, &#39;汽车&#39;, &#39;摩托车&#39;, &#39;飞机&#39;, &#39;公共汽车&#39;,
    &#39;火车&#39;、&#39;卡车&#39;、&#39;船&#39;、&#39;交通灯&#39;、&#39;消防栓&#39;、&#39;N/A&#39;、&#39;停车标志&#39;、
    &#39;停车计时器&#39;、&#39;长凳&#39;、&#39;鸟&#39;、&#39;猫&#39;、&#39;狗&#39;、&#39;马&#39;、&#39;羊&#39;、&#39;牛&#39;、
    &#39;大象&#39;、&#39;熊&#39;、&#39;斑马&#39;、&#39;长颈鹿&#39;、&#39;N/A&#39;、&#39;背包&#39;、&#39;雨伞&#39;、&#39;N/A&#39;、&#39;N/A&#39;、
    &#39;手提包&#39;、&#39;领带&#39;、&#39;手提箱&#39;、&#39;飞盘&#39;、&#39;滑雪板&#39;、&#39;滑雪板&#39;、&#39;运动球&#39;、
    &#39;风筝&#39;、&#39;棒球棒&#39;、&#39;棒球手套&#39;、&#39;滑板&#39;、&#39;冲浪板&#39;、&#39;网球拍&#39;、
    &#39;瓶子&#39;，&#39;不适用&#39;，&#39;酒杯&#39;，&#39;杯子&#39;，&#39;叉子&#39;，&#39;刀&#39;，&#39;勺子&#39;，&#39;碗&#39;，
    &#39;香蕉&#39;，&#39;苹果&#39;，&#39;三明治&#39;，&#39;橙子&#39;，&#39;西兰花&#39;，&#39;胡萝卜&#39;，&#39;热狗&#39;，&#39;披萨&#39;，
    &#39;甜甜圈&#39;、&#39;蛋糕&#39;、&#39;椅子&#39;、&#39;沙发&#39;、&#39;盆栽&#39;、&#39;床&#39;、&#39;N/A&#39;、&#39;餐桌&#39;、
    &#39;不适用&#39;、&#39;不适用&#39;、&#39;厕所&#39;、&#39;不适用&#39;、&#39;电视&#39;、&#39;笔记本电脑&#39;、&#39;鼠标&#39;、&#39;遥控器&#39;、&#39;键盘&#39;​​、&#39;手机&#39;、
    &#39;微波炉&#39;、&#39;烤箱&#39;、&#39;烤面包机&#39;、&#39;水槽&#39;、&#39;冰箱&#39;、&#39;不适用&#39;、&#39;书&#39;、
    “时钟”、“花瓶”、“剪刀”、“泰迪熊”、“吹风机”、“牙刷”
]


def get_prediction(img_path, 阈值):
    img = Image.open(img_path) # 加载图像
    transform = T.Compose([T.ToTensor()]) # 定义 PyTorch 变换
    img = transform(img) # 将变换应用于图像
    pred = model([img]) # 将图像传递给模型
    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0][&#39;labels&#39;].numpy())] # 获取预测分数
    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0][&#39;boxes&#39;].detach().numpy() )] # 边界框
    pred_score = list(pred[0][&#39;scores&#39;].detach().numpy())
    pred_t = [pred_score.index(x) for x in pred_score if x &gt;临界点][
        -1] # 获取分数大于阈值的索引列表。
    pred_boxes = pred_boxes[:pred_t + 1]
    pred_class = pred_class[:pred_t + 1]
    返回 pred_boxes、pred_class


def object_detection_api(img_path, 阈值=0.5, rect_th=3, text_size=3, text_th=3):
    box, pred_cls = get_prediction(img_path, Threshold) # 获取预测
    img = cv2.imread(img_path) # 用cv2读取图像
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # 转换为 RGB
    对于范围内的 i(len(boxes))：
        cv2.矩形(img, 盒子[i][0], 盒子[i][1], 颜色=(0, 255, 0),
                      height=rect_th) # 用坐标绘制矩形
        cv2.putText(img, pred_cls[i], 框[i][0], cv2.FONT_HERSHEY_SIMPLEX, text_size, (0, 255, 0),
                    Thickness=text_th) # 编写预测类
    plt.figure(figsize=(20, 30)) # 显示输出图像
    plt.imshow(img)
    plt.xticks([])
    plt.yticks([])
    plt.show()


object_detection_api(&#39;./people.jpg&#39;, 阈值=0.8)
]]></description>
      <guid>https://stackoverflow.com/questions/63743516/runtimeerror-object-has-no-attribute-nms</guid>
      <pubDate>Fri, 04 Sep 2020 14:53:22 GMT</pubDate>
    </item>
    <item>
      <title>神经网络对于输入过于敏感</title>
      <link>https://stackoverflow.com/questions/28902484/the-neural-networks-are-too-sensitive-for-the-input</link>
      <description><![CDATA[我有以下两个特征向量：

&lt;前&gt;&lt;代码&gt; 0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000
    0.2567 0.2567
    0.0105 0.0105
    0.0000 -0.0000
   -0.0000 0.0000
    0.0000 0.0000

让我们将第一个称为 A ，将第二个称为 B 。 A 用于学习神经网络，如果您再次将其应用到神经网络，它将给出以下输出：

&lt;前&gt;&lt;代码&gt; 1.0000
    0.0000
   -0.0000

但是如果您应用特征向量B，则以下输出将给出：

&lt;前&gt;&lt;代码&gt;-0.2475
    1.0524
    0.5106

这种形式的结果有何不同！特征向量相同（除了零处，零的符号不同）]]></description>
      <guid>https://stackoverflow.com/questions/28902484/the-neural-networks-are-too-sensitive-for-the-input</guid>
      <pubDate>Fri, 06 Mar 2015 15:52:41 GMT</pubDate>
    </item>
    </channel>
</rss>