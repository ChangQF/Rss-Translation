<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 26 Jul 2024 21:14:20 GMT</lastBuildDate>
    <item>
      <title>如何使用任何类型的基础模型来检测通常发生在眼睛中的疾病？</title>
      <link>https://stackoverflow.com/questions/78799471/how-do-i-use-any-kind-of-foundational-model-to-detect-a-disease-that-generally-h</link>
      <description><![CDATA[我刚来这里不久，如果可以的话，我希望你们能帮我。
我想建立一个模型，可以检测视网膜图像是否有微动脉瘤。
可以使用基础模型吗？如果可以，它会带来什么好处？
如果我想，我可以使用哪种基础模型，比如我最近读到关于 RetFound 的文章，我相信它适合我的范围。
（这就像一个理论问题）如果这些模型甚至没有接受过执行特定任务的训练，它们究竟如何适用于我们的特定用例数据，比如，制作基础模型的人如何决定训练数据的范围？它只是一个对视网膜图像进行处理模型，还是一个范围更广的模型，除了视网膜图像外，它还与其他相关数据有关（我相信）。第三个问题是可选的，如果你能回答，我将不胜感激。
我尝试使用一个基础模型，https://github.com/facebookresearch/deit/blob/main/README_deit.md，但我在这里学得并不多，任何帮助、任何指导都将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78799471/how-do-i-use-any-kind-of-foundational-model-to-detect-a-disease-that-generally-h</guid>
      <pubDate>Fri, 26 Jul 2024 18:19:53 GMT</pubDate>
    </item>
    <item>
      <title>涅斯捷罗夫加速梯度的两种变体：它们是等效的吗？</title>
      <link>https://stackoverflow.com/questions/78799083/two-variants-of-nesterov-accelerated-gradient-are-they-equivalent</link>
      <description><![CDATA[我很困惑地发现 Paperswithcode 上对 Nesterov 加速梯度的描述，即：
v_t = beta * v_t-1 + eta * ∇ J(theta - beta * v_t-1)
theta_t = theta_t-1 + v_t

与原始 Sutskever 等人的论文第 133 页中的描述略有不同。 3：
v_t = beta * v_t-1 - eta * ∇ J(theta + beta * v_t-1)
theta_t = theta_t-1 + v_t

在软弱的时刻，我问过你知道是谁，他围绕前瞻和后瞻制定了一个答案，但我无法验证这一点。
这两个公式是否等价，如果等价，如何证明这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78799083/two-variants-of-nesterov-accelerated-gradient-are-they-equivalent</guid>
      <pubDate>Fri, 26 Jul 2024 16:21:10 GMT</pubDate>
    </item>
    <item>
      <title>Raspberry Pi 0 2W 上的深度音频分类模型的最佳 ML API 是什么？</title>
      <link>https://stackoverflow.com/questions/78798996/what-is-the-best-ml-api-for-a-deep-audio-classification-model-on-the-raspberry-p</link>
      <description><![CDATA[我想听听您的意见，哪种 ML API 最适合构建音频分类模型。此模型将部署在一台小型 Raspberry Pi（Raspberry Pi 0 2W；可能略有不同）计算机上，该计算机位于我正在构建的设备中，是我所从事的技术初创公司的一部分。欢迎您提出您的想法和建议。
我开始使用 tensorflow keras 进行深度频谱分析；但此时的首要任务是构建尽可能最好的模型，我知道 tf keras 有点业余。]]></description>
      <guid>https://stackoverflow.com/questions/78798996/what-is-the-best-ml-api-for-a-deep-audio-classification-model-on-the-raspberry-p</guid>
      <pubDate>Fri, 26 Jul 2024 15:58:11 GMT</pubDate>
    </item>
    <item>
      <title>来自segmentation_models_pytorch 的 Unet 在训练中停滞</title>
      <link>https://stackoverflow.com/questions/78798820/unet-from-segmentation-models-pytorch-stalling-in-training</link>
      <description><![CDATA[我一直在遵循关于在自定义数据集上训练分割模型的教程，但它拒绝在训练模型方面取得任何进展。
这是我的模型设置
import fragmentation_models_pytorch as smp
import torch

ENCODER = &#39;efficientnet-b0&#39;
ENCODER_WEIGHTS = &#39;imagenet&#39;
CLASSES = [&#39;ship&#39;]
ACTIVATION = &#39;sigmoid&#39;
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)

model = smp.Unet(
coder_name=ENCODER, 
coder_weights=ENCODER_WEIGHTS, 
classes=len(CLASSES), 
activation=ACTIVATION,
).to(DEVICE)

from fragmentation_models_pytorch import utils as smp_utils

loss = smp_utils.losses.DiceLoss()
metrics = [
smp_utils.metrics.IoU(threshold=0.5),
]

optimizer = torch.optim.Adam([ 
dict(params=model.parameters(), lr=0.0001),
])


和 epochs 运行器
train_epoch = smp_utils.train.TrainEpoch(
model, 
loss=loss, 
metrics=metrics, 
optimizer=optimizer,
device=DEVICE,
verbose=True,
)

valid_epoch = smp_utils.train.ValidEpoch(
model, 
loss=loss, 
metrics=metrics, 
device=DEVICE,
verbose=True,
)

而且，当我运行训练时，模型只是停留在第一个 epoch 上，没有任何进展
max_score = 0

for i in range(0, 40):

print(&#39;\nEpoch: {}&#39;.format(i))
train_logs = train_epoch.run(train_loader)
valid_logs = valid_epoch.run(valid_loader)

# 执行某些操作（保存模型、更改 lr 等）
if max_score &lt; valid_logs[&#39;iou_score&#39;]:
max_score = valid_logs[&#39;iou_score&#39;]
torch.save(model, &#39;./best_model.pth&#39;)
print(&#39;模型已保存！&#39;)

if i == 25:
optimizer.param_groups[0][&#39;lr&#39;] = 1e-5
print(&#39;将解码器学习率降低至 1e-5！&#39;)

结果：
Epoch：0
train：0%| | 0/3851 [00:00&lt;?, ?it/s]

我这样把它放了 3 个小时，它一点变化都没有
我在 CPU (i7-10710U) 上运行（我知道它比 GPU 慢得多，但我的 GPU (GeForce 1650mq) 不支持 cuda），内存为 32 GB，我之前运行过类似的模型，没有任何问题。
有人能帮帮我吗？也许我漏掉了什么？也许有一个更轻的模型可以在我的系统上运行？
我已经尝试了一些其他设置和模型，YOLOv8 和 YOLOv3 也拒绝训练。]]></description>
      <guid>https://stackoverflow.com/questions/78798820/unet-from-segmentation-models-pytorch-stalling-in-training</guid>
      <pubDate>Fri, 26 Jul 2024 15:14:45 GMT</pubDate>
    </item>
    <item>
      <title>决策树分类器给出错误结果</title>
      <link>https://stackoverflow.com/questions/78797339/decision-tree-classifier-gives-wrong-results</link>
      <description><![CDATA[我正在学习一门机器学习课程，其中的作业是实现 DecisionTreeClassifier 的拟合方法。
这是我的代码：
import numpy as np
import pandas as pd

class MyTreeClf:
def __init__(self, max_depth=5, min_samples_split=2, max_leafs=20):
self.max_depth = max_depth
self.min_samples_split = min_samples_split
self.max_leafs = max_leafs
self.tree = None
self.leafs_cnt = 0

def node_entropy(self, probs):
return -np.sum([p * np.log2(p) for p in probs if p &gt; 0])

def node_ig(self, x_col, y, split_value):
left_mask = x_col &lt;= split_value
right_mask = x_col &gt; split_value

如果 len(x_col[left_mask]) == 0 或 len(x_col[right_mask]) == 0:
返回 0

left_probs = np.bincount(y[left_mask]) / len(y[left_mask])
right_probs = np.bincount(y[right_mask]) / len(y[right_mask])

entropy_after = len(y[left_mask]) / len(y) * self.node_entropy(left_probs) + len(y[right_mask]) / len(y) * self.node_entropy(right_probs)
entropy_before = self.node_entropy(np.bincount(y) / len(y))

返回 entropy_before - entropy_after

def get_best_split(self, X: pd.DataFrame，y：pd.Series）：
best_col，best_split_value，best_ig = None，None，-np.inf

对于 X.columns 中的 col：
sorted_unique_values = np.sort(X[col].unique())

对于 range(1，len(sorted_unique_values)) 中的 i：
split_value = (sorted_unique_values[i - 1] + sorted_unique_values[i]) / 2

ig = self.node_ig(X[col]，y，split_value)

如果 ig &gt; best_ig:
best_ig = ig
best_col = col
best_split_value = split_value

返回 best_col、best_split_value、best_ig

def fit(self, X: pd.DataFrame, y: pd.Series,depth=0):
如果depth == 0:
self.tree = {}

best_col、best_split_value、best_ig = self.get_best_split(X, y)

如果depth &lt; self.max_depth 和 len(y) &gt;= self.min_samples_split 和 self.leafs_cnt &lt; self.max_leafs 和 best_col 不为 None:
left_mask = X[best_col] &lt;= best_split_value
right_mask = X[best_col] &gt; best_split_value

self.tree[depth] = {&#39;col&#39;: best_col, &#39;split&#39;: best_split_value, &#39;left&#39;: {}, &#39;right&#39;: {}}

self.fit(X[left_mask], y[left_mask],depth + 1)
self.fit(X[right_mask], y[right_mask],depth + 1)
else:
class_label = y.mode()[0]
self.tree[depth] = {&#39;class&#39;: class_label}
self.leafs_cnt += 1

在 fit 方法中，该方法使用 X 和 y 来构建树，应该计算叶子的数量。
树的构建如下：
根节点：从根节点开始，遍历每个属性。
阈值选择过程：
对于每个属性，选择唯一值并对其进行排序。
形成阈值列表以拆分值。
对于每个阈值，将数据集拆分为两个子集（左和右）。
评估每次拆分的信息增益。
选择具有最高信息增益的属性和阈值，并将它们保存在层次结构中。
递归拆分：
将数据集拆分为两个子集。
如果子集可以进一步拆分，则递归重复该过程。
如果不可以，则将子集声明为叶子并保存第一个类的概率。
约束：
当满足以下条件之一时停止拆分：
最大树深度
节点中的最小实例数
最大叶子数
即使达到约束，也要通过创建必要的叶子来完成树。
叶子的数量保存在 leafs_cnt 变量中。该方法不返回任何内容。]]></description>
      <guid>https://stackoverflow.com/questions/78797339/decision-tree-classifier-gives-wrong-results</guid>
      <pubDate>Fri, 26 Jul 2024 09:48:47 GMT</pubDate>
    </item>
    <item>
      <title>线性模型的 SHAP 值与手动计算的值不同</title>
      <link>https://stackoverflow.com/questions/78796974/shap-values-for-linear-model-different-from-those-calculated-manually</link>
      <description><![CDATA[我训练一个线性模型来预测房价，然后我手动比较 Shapley 值计算结果与 SHAP 库返回的值，发现它们略有不同。
我的理解是，对于线性模型，Shapley 值由以下公式给出：
coeff * features for obs - coeffs * mean(features in training set)

或者如 SHAP 文档中所述：coef[i] * (x[i] - X.mean(0)[i])，其中 i 是一个特征。
问题是，为什么 SHAP 返回的值与手动计算不同？
代码如下：
import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
来自 sklearn.preprocessing 导入 MinMaxScaler
导入 shap

X, y = fetch_california_housing(return_X_y=True, as_frame=True)

X = X.drop(columns = [&quot;Latitude&quot;, &quot;Longitude&quot;, &quot;AveBedrms&quot;])

X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.3, random_state=0,
)

scaler = MinMaxScaler().set_output(transform=&quot;pandas&quot;).fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

linreg = LinearRegression().fit(X_train, y_train)
coeffs = pd.Series(linreg.coef_, index=linreg.feature_names_in_)

X_test.reset_index(inplace=True, drop=True)
obs = 6188

# 手动 shapley 计算
effect = coeffs * X_test.loc[obs]
effect - coeffs * X_train.mean()

返回结果：
MedInc 0.123210
HouseAge -0.459784
AveRooms -0.128162
Population 0.032673
AveOccup -0.001993
dtype: float64

SHAP 库返回的结果略有不同：
explainer = shap.LinearExplainer(linreg, X_train)
shap_values = explainer(X_test)
shap_values[obs]

结果如下：
.values =
array([ 0.12039244, -0.47172515, -0.12767778, 0.03473923, -0.00251017])

.base_values =
2.0809714707337523

.data =
array([0.25094137, 0.01960784, 0.06056066, 0.07912217, 0.00437137])

设置为忽略交互：
explainer.feature_perturbation

返回
&#39;interventional&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/78796974/shap-values-for-linear-model-different-from-those-calculated-manually</guid>
      <pubDate>Fri, 26 Jul 2024 08:22:09 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError: ‘list’ 对象没有属性 ‘shape’ 错误</title>
      <link>https://stackoverflow.com/questions/78796342/attributeerror-list-object-has-no-attribute-shape-error</link>
      <description><![CDATA[我正在尝试预测股票价格。这是我的代码：
import pandas as pd
import yfinance as web
import numpy as np

从 sklearn.preprocessing 导入 MinMaxScaler
从 tensorflow.python.keras.models 导入 Sequential
从 tensorflow.python.keras.layers 导入 Dense、Dropout
从 tensorflow.python.keras.layers.recurrent 导入 LSTM

company = &#39;TSLA&#39;

start=&#39;2012-01-01&#39;
end=&#39;2024-03-01&#39;

data = web.download(company, start=start, end=end)

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data[&#39;Close&#39;].values.reshape(-1,1))

prediction_days = 60

x_train = []
y_train = []

for x in range(prediction_days, len(scaled_data)):
x_train.append(scaled_data[x-prediction_days:x, 0])
y_train.append(scaled_data[x, 0])

model = Sequential()

model.add(LSTM(units = 50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50))
model.add(Dropout(0.2))

我期望它什么都不输入，但是我得到了这个错误：
但它说作为错误，
回溯（最近一次调用）：
文件
&quot;c:\Users\User1\OneDrive\Documents\Desktop\python\projects\machine\stock_price_predictor.py&quot;，
第 32 行，位于 &lt;module&gt;
model.add(LSTM(units = 50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
^^^^^^^^^^^^^
AttributeError: &#39;list&#39; 对象没有属性 &#39;shape&#39;

如何解决？我尝试将其转换为 np.array，但没有任何效果。这是我的尝试：
import pandas as pd
import yfinance as web
import numpy as np

从 sklearn.preprocessing 导入 MinMaxScaler
从 tensorflow.python.keras.models 导入 Sequential
从 tensorflow.python.keras.layers 导入 Dense、Dropout
从 tensorflow.python.keras.layers.recurrent 导入 LSTM

company = &#39;TSLA&#39;

start=&#39;2012-01-01&#39;
end=&#39;2024-03-01&#39;

data = web.download(company, start=start, end=end)

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data=.fit_transform(data[&#39;Close&#39;].values.reshape(-1,1))

prediction_days = 60

x_train = np.array([])
y_train = np.array([])

对于范围（prediction_days，len（scaled_data））中的 x：
x_train = np.append(x_train，scaled_data[x-prediction_days：x，0])
y_train = np.append(y_train，scaled_data[x，0])

model = Sequential()

model.add(LSTM(units = 50，return_sequences=True，input_shape= 
(x_train.shape[1]，1)))
model.add(Dropout(0.2))
model.add(LSTM(units = 50，return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50))
model.add(Dropout(0.2))

但我却得到了这个错误
回溯（最近一次调用）：
文件 
&quot;c:\Users\User1\OneDrive\Documents\Desktop\python\projects\machine 
learning\stock_price_predictor.py&quot;，第 32 行，位于 &lt;module&gt;
model.add(LSTM(units = 50, return_sequences=True, input_shape= 
(x_train.shape[1], 1))) 
~~~~~~~~~~~~~^^^
IndexError：元组索引超出范围
]]></description>
      <guid>https://stackoverflow.com/questions/78796342/attributeerror-list-object-has-no-attribute-shape-error</guid>
      <pubDate>Fri, 26 Jul 2024 05:31:21 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：参数 clone_function 和 input_tensors 仅支持顺序模型或功能模型</title>
      <link>https://stackoverflow.com/questions/78796155/valueerror-arguments-clone-function-and-input-tensors-are-only-supported-for-se</link>
      <description><![CDATA[我正在使用Quantization perceived training，参考网上的lstm代码，想把QAT放进lstm，结果遇到了ValueError。
ValueError Traceback (most recent call last)
&lt;ipython-input-11-00669bb76f9d&gt; in &lt;cell line: 6&gt;()
4 return layer
5 
----&gt; 6 annotated_model = tf.keras.models.clone_model(
7 model,
8 clone_function=apply_quantization_to_dense,

/usr/local/lib/python3.10/dist-packages/tf_keras/src/models/cloning.py in clone_model(model, input_tensors, clone_function)
544 # 自定义模型类的情况
545 if clone_function or input_tensors:
--&gt; 546 raise ValueError(
547 &quot;参数 clone_function 和 input_tensors &quot;
548 &quot;仅支持 Sequential 模型 &quot;

ValueError: 参数 clone_function 和 input_tensors 仅支持 Sequential 模型或 Functional 模型。收到类型为“Sequential”的模型，其中 clone_function=&lt;function apply_quantization_to_dense 位于0x78b727ec4040&gt; 和 input_tensors=None

这是我的代码
import keras
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dense、Activation
从 keras.datasets 导入 mnist
从 keras.models 导入 Sequential
从 keras.optimizers 导入 Adam

learning_rate = 0.001
training_iters = 20
batch_size = 128
display_step = 10

n_input = 28
n_step = 28
n_hidden = 128
n_classes = 10

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(-1, n_step, n_input)
x_test = x_test.reshape(-1, n_step, n_input)
x_train = x_train.astype(&#39;float32&#39;)
x_test = x_test.astype(&#39;float32&#39;)
x_train /= 255
x_test /= 255

y_train = keras.utils.to_categorical(y_train, n_classes)
y_test = keras.utils.to_categorical(y_test, n_classes)

model = Sequential()
model.add(LSTM(n_hidden,
batch_input_shape=(None, n_step, n_input),
unroll=True))

model.add(Dense(n_classes))
model.add(Activation(&#39;softmax&#39;))

adam = Adam(lr=learning_rate)
model.summary()
model.compile(optimizer=adam,
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

model.fit(x_train, y_train,
batch_size=batch_size,
epochs=training_iters,
verbose=1,
validation_data=(x_test, y_test))

scores = model.evaluate(x_test, y_test, verbose=0)
print(&#39;LSTM 测试分数：&#39;, scores[0])
print(&#39;LSTM 测试准确率：&#39;, scores[1])

def apply_quantization_to_dense(layer):
if isinstance(layer, tf.keras.layers.LSTM):
return tfmot.quantization.keras.quantize_annotate_layer(layer)
return layer

annotated_model = tf.keras.models.clone_model(
模型，
clone_function=apply_quantization_to_dense，
)
]]></description>
      <guid>https://stackoverflow.com/questions/78796155/valueerror-arguments-clone-function-and-input-tensors-are-only-supported-for-se</guid>
      <pubDate>Fri, 26 Jul 2024 03:41:57 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：不支持 y 的稀疏多标签指标 - 如何处理具有稀疏数据的多标签分类？</title>
      <link>https://stackoverflow.com/questions/78795297/valueerror-sparse-multilabel-indicator-for-y-is-not-supported-how-to-handle-m</link>
      <description><![CDATA[我只是一个初学者，我还在学习稀疏矩阵以及它们如何与其他东西一起工作。
这是我遇到的问题，在网上搜索后找不到合适的答案。
我使用默认参数 sparse_output=True 对分类标签进行了 OneHotEncoded，
当我尝试在训练测试拆分后使用 transformed_X 和目标 y 拟合 RandomForestClassifier 时，它显示了此错误。
#seed
np.random.seed(42)

#one hot encoding imports
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer as ct

#Data splitting
X = f_data.drop(&#39;attended&#39;, axis = 1)
y = f_data[&#39;attended&#39;]

#select columns
cat_col = [&#39;days_before&#39;,&#39;day_of_week&#39;,&#39;time&#39;,&#39;category&#39;]

#初始化编码器 
enc = OneHotEncoder()

#使用 ct 拟合编码器
transformer = ct([(&#39;enc&#39;,enc,cat_col)], remainder = &#39;passthrough&#39;)
transformed_X = transformer.fit_transform(X)
transformed_X

&lt;1480x36 稀疏矩阵，类型为 &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;以压缩稀疏行格式存储 10360 个元素&gt;
#BaseLine 模型
np.random.seed(42)

#imports
from sklearn.model_selection import train_test_split as tts
from sklearn.ensemble import RandomForestClassifier

#splitting
X_train,Y_train,X_test,Y_test = tts(transformed_X,y, test_size = 0.2)

#model fitting
model = RandomForestClassifier()
model.fit(X_train,Y_train)

-------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Cell In[416], line 13
11 #modelling
12 model = RandomForestClassifier()
---&gt; 13 model.fit(X_train,Y_train)
15 #模型得分
16 blsc = model.score(X_test,Y_test)

文件 G:\Md Jaffer\UDEMY\Machine Learning Course ZTM\Projects\HeartDesease_Classification\env\Lib\site-packages\sklearn\base.py:1474，在 _fit_context.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(estimator, *args, **kwargs)
1467 estimator._validate_params()
1469 使用 config_context(
1470 skip_parameter_validation=(
1471 prefer_skip_nested_validation 或 global_skip_validation
1472 )
1473 ):
-&gt; 1474 返回 fit_method(estimator, *args, **kwargs)

文件 G:\Md Jaffer\UDEMY\Machine Learning Course ZTM\Projects\HeartDesease_Classification\env\Lib\site-packages\sklearn\ensemble\_forest.py:361，位于 BaseForest.fit(self, X, y, sample_weight)
359 # 验证或转换输入数据
360 if issparse(y):
--&gt; 361 引发 ValueError(&quot;不支持 y 的稀疏多标签指标。&quot;)
363 X, y = self._validate_data(
364 X,
365 y,
(...)
369 force_all_finite=False,
370 )
371 # _compute_missing_values_in_feature_mask 检查 X 是否有缺失值，
372 # 如果底层树基础估计器无法处理缺失值，则会引发错误。
373 # 仅需标准即可确定树是否支持
374 # 缺失值。

ValueError: 不支持 y 的稀疏多标签指标。

我尝试设置 sparse_output=False，但结果显示样本数量不一致。标签编码后的实际形状为 (1480 x 36)
---------------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
Cell In[444]，第 13 行
11 #modelling
12 model = RandomForestClassifier()
---&gt; 13 model.fit(X_train,Y_train)
15 #model score
16 blsc = model.score(X_test,Y_test)

ValueError：发现输入变量的样本数量不一致：[1184, 296]
]]></description>
      <guid>https://stackoverflow.com/questions/78795297/valueerror-sparse-multilabel-indicator-for-y-is-not-supported-how-to-handle-m</guid>
      <pubDate>Thu, 25 Jul 2024 20:21:08 GMT</pubDate>
    </item>
    <item>
      <title>我在训练随机森林回归器时不断遇到这个问题</title>
      <link>https://stackoverflow.com/questions/78795096/i-keep-encountering-this-problem-training-a-random-forest-regressor</link>
      <description><![CDATA[/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: 
UserWarning：X 有特征名称，但 RandomForestRegressor 拟合时没有特征名称
warnings.warn(

我尝试添加 .values，但仍然标记错误。]]></description>
      <guid>https://stackoverflow.com/questions/78795096/i-keep-encountering-this-problem-training-a-random-forest-regressor</guid>
      <pubDate>Thu, 25 Jul 2024 19:18:50 GMT</pubDate>
    </item>
    <item>
      <title>PipeOp classif.avg (mlr3) 错误：对“prob”的断言失败：包含缺失值（元素 1）</title>
      <link>https://stackoverflow.com/questions/78763091/error-with-pipeop-classif-avg-mlr3-assertion-on-prob-failed-contains-missi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78763091/error-with-pipeop-classif-avg-mlr3-assertion-on-prob-failed-contains-missi</guid>
      <pubDate>Thu, 18 Jul 2024 07:56:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 VAE 减少和重建 CNN 模型参数</title>
      <link>https://stackoverflow.com/questions/78457309/reducing-and-reconstruction-cnn-model-parameters-using-a-vae</link>
      <description><![CDATA[假设我有一个带有 2 个 Conv2D 层的简单 CNN 模型，我在我的图像数据集上训练了这个模型，我将把这个 CNN 模型的参数输入到 VAE（作为编码器的输入）中，首先将它们的参数减少到嵌入空间（Z 或 VAE 的潜在空间）。然后，我想使用 VAE 解码器的输出重建 CNN 参数（具有其原始尺寸）。
我不知道如何在 PyTorch 中实现这一点，并将训练好的 CNN 的参数输入到 VAE 模型的编码器输入中，最后将参数向量重建为 CNN 模型参数。
提前致谢！
这是 CNN 模型：
class Net(nn.Module):
def __init__(self):
super(Net, self).__init__()
self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
self.conv2_drop = nn.Dropout2d()
self.fc1 = nn.Linear(320, 50)
self.fc2 = nn.Linear(50, 10)

def forward(self, x):
x = F.relu(F.max_pool2d(self.conv1(x), 2))
x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
x = x.view(-1, 320)
x = F.relu(self.fc1(x))
x = F.dropout(x, training=self.training)
x = self.fc2(x)
return F.log_softmax(x)

以下代码用于 VAE：
class VAE(nn.Module):
def __init__(self, image_channels=1, h_dim=1024, z_dim=32):
super(VAE, self).__init__()
self.encoder = nn.Sequential(
nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),
nn.ReLU(),
nn.Conv2d(32, 64, kernel_size=4, stride=2),
nn.ReLU(),
nn.Conv2d(64, 128, kernel_size=4, stride=2),
nn.ReLU(),
nn.Conv2d(128, 256, kernel_size=4, stride=2),
nn.ReLU(),
Flatten()
)

self.fc1 = nn.Linear(h_dim, z_dim)
self.fc2 = nn.Linear(h_dim, z_dim)
self.fc3 = nn.Linear(z_dim, h_dim)

self.decoder = nn.Sequential(
UnFlatten(),
nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),
nn.ReLU(),
nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),
nn.ReLU(),
nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),
nn.ReLU(),
nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),
nn.Sigmoid(),
)

def reparameterize(self, mu, logvar):
std = logvar.mul(0.5).exp_()
# return torch.normal(mu, std)
esp = torch.randn(*mu.size())
z = mu + std * esp
返回 z

def bottleneck(self, h):
mu, logvar = self.fc1(h), self.fc2(h)
z = self.reparameterize(mu, logvar)
返回 z, mu, logvar

def encode(self, x):
h = self.encoder(x)
z, mu, logvar = self.bottleneck(h)
返回 z, mu, logvar

def decrypt(self, z):
z = self.fc3(z)
z = self.decoder(z)
返回 z

def forward(self, x):
z, mu, logvar = self.encode(x)
z = self.decode(z)
返回 z, mu, logvar
]]></description>
      <guid>https://stackoverflow.com/questions/78457309/reducing-and-reconstruction-cnn-model-parameters-using-a-vae</guid>
      <pubDate>Thu, 09 May 2024 22:59:50 GMT</pubDate>
    </item>
    <item>
      <title>如何让 Matrox Model Finder 在单个图像中多次查找同一模型？</title>
      <link>https://stackoverflow.com/questions/78311681/how-do-i-make-the-matrox-model-finder-look-for-the-same-model-multiple-times-in</link>
      <description><![CDATA[我是 Matrox 的新手，所以这可能是一个初学者的问题。
我有一个托盘，上面有多个项目，它们都是同一型号。当我将 ModelFinder 步骤添加到程序中时，我添加了我正在寻找的模型，但它只显示我注册的模型，我猜是因为相机的失真。我如何让 Matrox 知道还有更多项目，并且它们也是同一型号？

我添加了一个必须找到它的搜索区域，我选择了查找所有出现的选项，但它只显示一个，而不是实际存在的 3/4。
]]></description>
      <guid>https://stackoverflow.com/questions/78311681/how-do-i-make-the-matrox-model-finder-look-for-the-same-model-multiple-times-in</guid>
      <pubDate>Thu, 11 Apr 2024 16:02:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在 SKLearn Estimator 上使用 Sagemaker HyperparameterTuner？</title>
      <link>https://stackoverflow.com/questions/77573670/how-do-i-use-sagemaker-hyperparametertuner-on-a-sklearn-estimator</link>
      <description><![CDATA[我正在关注 Amazon Sagemaker 研讨会，尝试利用 Sagemaker 的几个实用程序，而不是像我目前所做的那样在 Notebook 上运行所有内容。
问题是，在研讨会上，他们教你如何使用来自 AWS 的现成 XGBoost 图像来使用 HyperparameterTuner，而我的大多数管道都在使用 Scikit-Learn 模型，例如 GradientBoostingClassifier 或 RandomForest，所以我正在实例化一个像这样的估算器 此示例文件:
sklearn = SKLearn(entry_point=&quot;train.py&quot;, 
framework_version=&quot;1.2-1&quot;, 
instance_type=&quot;ml.m5.xlarge&quot;, 
role=role,
hyperparameters=fixed_hyperparameters
)

之后，我将使用刚刚创建的估算器实例化 HyperparameterTuner 作业，其中包含我想要的超参数范围测试。
hyperparameters_ranges = {
&quot;n_estimators&quot;: ContinuousParameter(100, 500),
&quot;learning_rate&quot;: ContinuousParameter(1e-2, 1e-1),
&quot;max_depth&quot;: IntegerParameter(2, 5),
&quot;subsample&quot;: ContinuousParameter(0.6, 1),
&quot;max_df&quot;: ContinuousParameter(0.4, 1),
&quot;max_features&quot;: IntegerParameter(5, 25),
&quot;use_idf&quot;: CategoricalParameter([True, False])
}

metric = &quot;validation:f1&quot;

tuner = HyperparameterTuner(
sklearn,
metric,
hyperparameters_ranges,
max_jobs=2,
max_parallel_jobs=2
)

我的问题是，我没有找到任何关于如何访问“train.py”文件中 SKLearn 估算器中传递的超参数的信息。我也没有找到最佳超参数存储在哪里，以便我可以将它们用于最终模型。有人能告诉我这是否可行，或者提供替代方案，看看是否有其他更简单的方法可以做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/77573670/how-do-i-use-sagemaker-hyperparametertuner-on-a-sklearn-estimator</guid>
      <pubDate>Wed, 29 Nov 2023 18:27:13 GMT</pubDate>
    </item>
    <item>
      <title>银行交易数据集</title>
      <link>https://stackoverflow.com/questions/56914395/dataset-for-bank-transaction</link>
      <description><![CDATA[我想使用银行交易数据集制作信用卡和借记卡之间的图表。借记和贷记金额，但没有得到正确的数据集。
有人能给我提供同样的数据集吗？]]></description>
      <guid>https://stackoverflow.com/questions/56914395/dataset-for-bank-transaction</guid>
      <pubDate>Sat, 06 Jul 2019 13:09:23 GMT</pubDate>
    </item>
    </channel>
</rss>