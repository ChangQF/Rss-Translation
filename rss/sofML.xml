<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Dec 2024 21:17:11 GMT</lastBuildDate>
    <item>
      <title>使用 OpenCV 从正面识别和计数书籍</title>
      <link>https://stackoverflow.com/questions/79266411/recognition-and-counting-of-books-from-front-using-opencv</link>
      <description><![CDATA[您好，我想开发一款应用程序，让我可以统计书架上的书籍数量。如果它还能给我一份书籍清单就更好了，因为几乎所有书籍的书脊上都有书名。主要问题是如何找出每一本书，有些书是同一种颜色，因此可能很难将它们挑出来。我该如何进行分割并使用像素分析来准确计数。
我还没有开始。我只是需要一些关于如何去做的想法。
(https://i.sstatic.net/fDewOa6t.jpg)(https://i.sstatic.net/7A5czzJe.jpg)
......................................]]></description>
      <guid>https://stackoverflow.com/questions/79266411/recognition-and-counting-of-books-from-front-using-opencv</guid>
      <pubDate>Mon, 09 Dec 2024 20:46:33 GMT</pubDate>
    </item>
    <item>
      <title>Jupyter Notebook 上的机器学习项目问题-NotFittedError：此 DecisionTreeClassifier 实例尚未安装</title>
      <link>https://stackoverflow.com/questions/79266379/problem-with-machine-learning-project-on-jupyter-notebook-notfittederror-this</link>
      <description><![CDATA[我正在做什么？
我正在开展一个机器学习项目，分析最便宜的电动汽车。目前，我正在研究 Jupyter Notebook。一旦完成，我将开始在 Flask 应用程序上实现它。
我遇到了什么问题？
我在 Jupyter Notebook 上运行此单元：
fig = plt.figure(figsize=(25,20))
tree.plot_tree(clf)
plt.show()

我收到此错误：
-------------------------------------------------------------------------------
NotFittedError Traceback（最近一次调用最后一次）
~\AppData\Local\Temp\ipykernel_8784\285030017.py in &lt;module&gt;
1 fig = plt.figure(figsize=(25,20))
----&gt; 2 tree.plot_tree(clf)
3 plt.show()

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\tree\_export.py in plot_tree(decision_tree, max_depth, feature_names, class_names, label, filled, impurity, node_ids, ratio, rounded, precision, ax, fontsize)
178 &quot;&quot;&quot;
179 
--&gt; 180 check_is_fitted(decision_tree)
181 
182 exporter = _MPLTreeExporter(

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\validation.py in check_is_fitted(estimator, attributed, msg, all_or_any)
1220 
1221 如果未安装：
-&gt; 1222 引发 NotFittedError(msg % {&quot;name&quot;: type(estimator).__name__})
1223 
1224 

NotFittedError：此 DecisionTreeClassifier 实例尚未安装。使用此估算器之前，请使用适当的参数调用“fit”。
&lt;图形尺寸 2500x2000，轴数为 0&gt;

做了什么我试试？
我尝试使用以下代码：
tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42) 
tree_clf.fit(X_test, y_test)
DecisionTreeClassifier(max_depth=2, random_state=42)
clf = tree.DecisionTreeClassifier(random_state=0)
fig = plt.figure(figsize=(25,20))
tree.plot_tree(clf)
plt.show()

我的笔记本在 GitHub 上的链接是什么？
这是链接：
https://github.com/SteveAustin583/cheapest-electric-car/blob/main/ElectricCars.ipynb
我期望什么？
我期望得到一个决策树。
你能帮我解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/79266379/problem-with-machine-learning-project-on-jupyter-notebook-notfittederror-this</guid>
      <pubDate>Mon, 09 Dec 2024 20:32:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 PPO 的自定义环境的奖励没有改善</title>
      <link>https://stackoverflow.com/questions/79266195/reward-not-improving-for-a-custom-environment-using-ppo</link>
      <description><![CDATA[我一直在尝试在 Gym 实现的自定义环境中训练代理，其目标是通过调整每个节点的有功功率（负载）来解决电网中的电压违规问题。我主要尝试了两种算法，即 stable-baselines3、PPO 和 DDPG。但是，这两种算法的结果都非常糟糕（例如奖励随着时间的推移而减少），我希望有人能帮助我找到更好的方向。
因此，代理会进行观察，其中包含每个节点的电压值和一些其他连续值，然后执行操作，即更改电网每个节点上的负载的能力（因此是一个具有 24 个连续值的数组），然后执行功率流以确定新的电压值，然后根据这些新的电压值计算奖励。
我希望我的代理尽可能少地采取行动，并在最少的时间步内解决违规问题。因此，我按以下方式构建了奖励函数：

如果没有违规，我会给它 10 的奖励，并且情节终止
在每个步骤中，如果有违规，我会施加基本惩罚，并添加与调整幅度成比例的额外惩罚
如果代理所做的调整过于极端，以至于我的功率流算法无法收敛并停止工作，我会施加 -10 的惩罚，情节结束。

情节设置：情节从包含违规的初始观察开始。当一个情节结束时，下一个情节将从另一个带有电压的观察开始（有些带有违规行为）。
我的 PPO 模型具有以下参数：
model = PPO(&quot;MlpPolicy&quot;, env, verbose=1, n_steps=256, tensorboard_log=&quot;C:\Users\antonio\Downloads\RL&quot;, ent_coef=0.01, gamma=0.9)

我选择了较低的伽马，因为代理需要优先快速解决违规行为。
以下是 10k 步 PPO 尝试的指标：

对于 DDPG，我使用了 SB3 的默认值，得到了以下结果：

就是这样，抱歉发了这么长的帖子。无论如何，您有什么建议可以给我吗？]]></description>
      <guid>https://stackoverflow.com/questions/79266195/reward-not-improving-for-a-custom-environment-using-ppo</guid>
      <pubDate>Mon, 09 Dec 2024 19:11:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 java 的图像分类模型[关闭]</title>
      <link>https://stackoverflow.com/questions/79266140/image-classification-model-with-java</link>
      <description><![CDATA[好的，我有一个使用 javaFx 创建桌面应用程序的项目，该应用程序用于图像分类，我对机器学习一无所知，所以我正在寻找一个模型将其集成到我的项目中，感谢您的帮助
用于图像分类的机器学习模型]]></description>
      <guid>https://stackoverflow.com/questions/79266140/image-classification-model-with-java</guid>
      <pubDate>Mon, 09 Dec 2024 18:48:30 GMT</pubDate>
    </item>
    <item>
      <title>两个不同时间段的 HR -LR 对的超分辨率实现 [关闭]</title>
      <link>https://stackoverflow.com/questions/79264696/super-resolution-implementation-for-hr-lr-pairs-in-two-different-time-periods</link>
      <description><![CDATA[我正在使用一年中不同时间拍摄的 HR 和 LR 航拍图像对深入研究超分辨率 (SR)。我有在不同时间但针对同一区域拍摄的 25 厘米分辨率图像和 8 厘米分辨率图像，我的目标是训练一个模型，将 25 厘米图像升级到 8 厘米分辨率，然后将结果与地面实况 8 厘米图像进行比较。
我认为我的方法属于基于学习框架的单图像 SR。我计划使用基于 GAN 的方法，但我仍在研究确切的方法。例如，基于参考的 SR 使用附近的 HR 区域作为参考，而真实世界的 SR 似乎更接近我的情况，因为我将面临对齐图像、处理时间变化和有效验证实施等挑战。
如果您有与此类问题相关的见解、论文或存储库，我很乐意听听！您会如何对这项工作进行分类？关于解决时间和空间差异或其他挑战有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/79264696/super-resolution-implementation-for-hr-lr-pairs-in-two-different-time-periods</guid>
      <pubDate>Mon, 09 Dec 2024 10:52:09 GMT</pubDate>
    </item>
    <item>
      <title>模块“keras.api.backend”没有属性“clip”</title>
      <link>https://stackoverflow.com/questions/79116828/module-keras-api-backend-has-no-attribute-clip</link>
      <description><![CDATA[我使用 Colab 进行编码并收到此错误：
AttributeError：模块“keras.api.backend”没有属性“clip”。

我尝试升级 TensorFlow 和 Keras，但仍然收到相同的错误。我在第一个 epoch 拟合模型时收到此错误。
我该如何修复它？
import fragmentation_models as sm
model_vgg16=sm.Unet(backbone_name=backbone,input_shape=(256,256,3),classes=4,activation=&quot;softmax&quot;,encoder_weights=&quot;imagenet&quot;,decoder_use_batchnorm=True,encoder_freeze=False )

model_vgg16.summary()

&quot;&quot;&quot;# loss and metrics&quot;&quot;&quot;

loss=&quot;categorical_crossentropy&quot;

dice_loss=sm.losses.DiceLoss()
focal_loss=sm.losses.CategoricalFocalLoss()

focal_dice_loss=sm.losses.categorical_focal_dice_loss

metric=[sm.metrics.IOUScore(threshold=0.5)]

&quot;&quot;&quot;# compile&quot;&quot;&quot;

lr=0.001
model_vgg16.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),
loss=[focal_dice_loss],
metrics=[metric])

history = model_vgg16.fit(preprocessed_x_train, ytrain_categorical, epochs=20,validation_data=(preprocessed_x_val,y_val_categorical),batch_size=32)

错误：
Epoch 1/20
--------------------------------------------------------------------------------------------
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-76-887dcd97e6be&gt; 在 &lt;cell line: 1&gt;()
----&gt; 1 history = model_vgg16.fit(preprocessed_x_train, ytrain_categorical, epochs=20,
2 validation_data=(preprocessed_x_val,y_val_categorical),
3 batch_size=32)

3 帧
/usr/local/lib/python3.10/dist-packages/segmentation_models/base/ functional.py in categorical_focal_loss(gt, pr, gamma, alpha, class_indexes, **kwargs)
276 
277 # 剪辑以防止 NaN 和 Inf
--&gt; 278 pr = backend.clip(pr, backend.epsilon(), 1.0 - backend.epsilon())
279 
280 # 计算焦点损失

AttributeError: 模块 &#39;keras.api.backend&#39; 没有属性 &#39;clip&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/79116828/module-keras-api-backend-has-no-attribute-clip</guid>
      <pubDate>Wed, 23 Oct 2024 07:29:46 GMT</pubDate>
    </item>
    <item>
      <title>如何配置 YOLOv8 yaml 文件以访问 Azure 上的 Blob 存储数据集？</title>
      <link>https://stackoverflow.com/questions/75848981/how-to-configure-yolov8-yaml-file-to-access-blob-storage-dataset-on-azure</link>
      <description><![CDATA[上下文
我想使用 Yolo (v8) 训练自定义模型。我已经在本地机器上运行了它，但速度很慢，我想在 Azure Machine Learning Studio 上运行该作业以提高效率。我正在使用 Azure ML SDK v2。
问题
当我在 Azure ML 上运行时，我收到一条错误消息，提示 YOLO 无法找到我的训练图像。
回溯（最近一次调用最后一次）：
文件“/opt/conda/envs/ptca/lib/python3.8/site-packages/ultralytics/yolo/engine/trainer.py”，第 125 行，位于 __init__
self.data = check_det_dataset(self.args.data)
文件“/opt/conda/envs/ptca/lib/python3.8/site-packages/ultralytics/yolo/data/utils.py”，第 243 行，位于 check_det_dataset
raise FileNotFoundError(msg)
FileNotFoundError: 
数据集&#39;custom.yaml&#39; 未找到⚠️，缺少路径 [&#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/valid/images&#39;]

代码/分析
这是我用来运行作业的代码：
command_job = command(
display_name=&#39;Test Run 1&#39;,
code=&quot;./src/&quot;,
command=&quot;yolo detect train data=custom.yaml model=yolov8n.pt epochs=1 imgsz=1280 seed=42&quot;,
environment=&quot;my-custom-env:3&quot;,
compute=compute_target
)​​

在我的本地机器上（使用 Visual Studio 代码）， custom.yaml 文件位于 ./src/ 目录中。当我运行上述作业时，custom.yaml 已上传并出现在作业的 Code 部分中（在 Azure ML Studio 中查看）。通过调查，我认为这是具有以下路径的计算工作目录：
&#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/&#39;

我的 custom.yaml 如下所示：
path: ../
train: train/images
val: valid/images

nc: 1
names: [&quot;bike&quot;]

因此，YOLO 正在查看我的 custom.yaml，使用根目录作为路径，并尝试在其中找到 valid/images目录：
&#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/valid/images&#39;

我的图像位于我的 Datastore 中，而不是该目录中，因此出现错误。
我已尝试过 - 更新 custom.yaml 路径
我的所有数据（train 和 valid）都包含在 AzureBlobStorage 中。在 Azure ML Studio 中，我创建了一个 Datastore 并将我的数据添加为 Dataset（引用我的 AzureBlobStorage 帐户）。我的文件结构是：
Dataset/
- Train/
- Images
- Labels
- Valid/
- Images
- Labels

在我的 custom.yaml 文件中，我尝试将 path 替换为以下内容：
 **存储 URI**：https://mystorageaccount.blob.core.windows.net/my-datasets
**数据存储 URI**：azureml://subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/resourcegroups/my-rg/workspaces/my_workspage/datastores/my_datastore/paths/Dataset/

如果我这样做，我会得到相同的错误。这次它将 path 附加到工作目录的末尾。示例：
 &#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/https://mystorageaccount.blob.core.windows.net/my-datasets/valid/images&#39;

我尝试过的方法 - mounting / download 数据集
我已阅读 Microsoft 文档 - （例如 此处 和 此处） - 内容如下：

对于大多数场景，您将使用 URI（uri_folder 和 uri_file） - 存储中的一个位置，可以通过将存储安装或下载到节点轻松映射到作业中计算节点的文件系统。

感觉我应该将我的数据（在我的 Datastore 中）映射到计算文件系统。然后我可以在我的 custom.yaml 中使用该路径。文档没有明确说明我该如何做。
简而言之：如何在 Azure ML 上设置我的数据，以便我的 custom.yaml 中的 path 指向数据？]]></description>
      <guid>https://stackoverflow.com/questions/75848981/how-to-configure-yolov8-yaml-file-to-access-blob-storage-dataset-on-azure</guid>
      <pubDate>Sun, 26 Mar 2023 16:16:11 GMT</pubDate>
    </item>
    <item>
      <title>如何从 NLTK 导入和使用停用词列表？</title>
      <link>https://stackoverflow.com/questions/70698947/how-to-import-and-use-stopwords-list-from-nltk</link>
      <description><![CDATA[我已经从 nltk.corpus 导入了 stopwords，但出现 STOPWORDS 未定义 错误。以下是我的代码：
import nltk
from nltk.corpus import stopwords
#创建停用词列表：
stopwords = set(STOPWORDS)

以上代码出现以下错误：
NameError：名称“STOPWORDS”未定义
]]></description>
      <guid>https://stackoverflow.com/questions/70698947/how-to-import-and-use-stopwords-list-from-nltk</guid>
      <pubDate>Thu, 13 Jan 2022 15:18:48 GMT</pubDate>
    </item>
    <item>
      <title>多维数据 K 均值聚类后的 PCA</title>
      <link>https://stackoverflow.com/questions/69699120/pca-after-k-means-clustering-of-multidimensional-data</link>
      <description><![CDATA[我有以下包含 10 个变量的数据集：

我想用这个多维数据集识别聚类，所以我尝试使用以下代码的 k-means 聚类算法：
clustering_kmeans = KMeans(n_clusters=2, precompute_distances=&quot;auto&quot;, n_jobs=-1)
data[&#39;clusters&#39;] = clustering_kmeans.fit_predict(data)

为了绘制结果，我使用 PCA 进行降维：
reduced_data = PCA(n_components=2).fit_transform(data)
results = pd.DataFrame(reduced_data,columns=[&#39;pca1&#39;,&#39;pca2&#39;])
sns.scatterplot(x=&quot;pca1&quot;, y=&quot;pca2&quot;, hue=kmeans[&#39;clusters&#39;], data=results)
plt.title(&#39;2 维 K-means 聚类&#39;)
plt.show()

最后我得到了以下结果：

所以我有以下结果问题：

但是，这个 PCA 图看起来非常奇怪，将整个数据集分成了两个角。这是正确的吗？还是我写错了代码？

还有其他用于聚类多维数据的算法吗？我查看了这个，但我找不到用于聚类多维数据的合适算法……我如何才能在 Python 中为我的数据集实现 Ward 层次聚类？

为什么我应该使用 PCA 进行降维？我也可以使用 t SNE 吗？这样更好吗？

]]></description>
      <guid>https://stackoverflow.com/questions/69699120/pca-after-k-means-clustering-of-multidimensional-data</guid>
      <pubDate>Sun, 24 Oct 2021 17:21:13 GMT</pubDate>
    </item>
    <item>
      <title>降维——PCA 解释</title>
      <link>https://stackoverflow.com/questions/65470930/dimensionality-reduction-pca-explanation</link>
      <description><![CDATA[我觉得我对 PCA 理解得不是很好，有人能帮我解决下面的困惑吗？
以鸢尾花数据集为例，我有 4 个协变量，x1：萼片长度；x2：萼片宽度；x3：花瓣长度；x4：花瓣宽度。公式如下所示，a1、a2、a3、a4 是协变量的权重。PCA 将尝试使用不同的线性变换来最大化方差。同时也遵循 a1^2 + a2^2 + a3^2 + a4^2=1 的规则。我有兴趣知道 a1、a2、a3、a4 的值。
a1*x1 + a2*x2 + a3*x3 + a4*x4

我在 Python 上有以下代码，我认为哪个是正确的？
# 加载库
从 sklearn.datasets 导入 load_iris
从 sklearn.decomposition 导入 PCA
导入 seaborn 作为 sns
导入 pandas 作为 pd
导入 numpy 作为 np

iris = load_iris()
X = iris.data
df = pd.DataFrame(X,columns=iris.feature_names)

pca = decomposition.PCA(n_components = 4)
digits_pca_4 = pca.fit(X)
digits_pca_4.explained_variance_ratio_

结果是
array([0.92461872, 0.05306648, 0.01710261, 0.00521218])

我的问题是：
我是否正确地假设 a1=sqrt(0.92)、a2=sqrt(0.05)、a3=sqrt(0.02)、a4=sqrt(0.005)？
第二个问题：
如果我选择 a1=a2=a3=a4=0.5 的线性组合，那么与 PCA 的方差相比，这个方差是多少（我假设它小于 PCA 结果，因为 PCA 最大化了方差？）？如何在 Python 中获取 a1=a2=a3=a4=0.5 时的方差？PCA 的方差是下面的代码吗？
pca.explained_variance_.sum()
]]></description>
      <guid>https://stackoverflow.com/questions/65470930/dimensionality-reduction-pca-explanation</guid>
      <pubDate>Sun, 27 Dec 2020 22:06:39 GMT</pubDate>
    </item>
    <item>
      <title>PCA 的输出是什么以及它有何用处？</title>
      <link>https://stackoverflow.com/questions/47048399/what-is-the-output-of-pca-and-how-it-is-useful</link>
      <description><![CDATA[PCA 是一种降维算法，有助于降低数据的维度。
我不明白的是，PCA 会按降序输出特征向量，例如 PC1、PC2、PC3 等。因此，这将成为我们数据的新轴。

我们可以在哪里应用这个新轴来预测测试集数据？
我们实现了从 n 到 n-k 的降维。
如何从我们的数据中获取最有用的变量并从我们的数据中消除不重要的列？
PCA 有替代方法吗？
]]></description>
      <guid>https://stackoverflow.com/questions/47048399/what-is-the-output-of-pca-and-how-it-is-useful</guid>
      <pubDate>Wed, 01 Nov 2017 04:45:26 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析，有多少个成分？</title>
      <link>https://stackoverflow.com/questions/46516469/principal-component-analysis-how-many-components</link>
      <description><![CDATA[我不明白 PCA 的一点。PCA 返回最大化每个特征方差的方向？我的意思是，它将为我们原始空间的每个特征返回一个组件，并且只有 k 个最大的组件才会用作新子空间的轴，对吗？所以实际上如果我在 50 维空间中，并且 49 个特征具有很强的方差，我可以直接传递到 49 维空间吗？]]></description>
      <guid>https://stackoverflow.com/questions/46516469/principal-component-analysis-how-many-components</guid>
      <pubDate>Sun, 01 Oct 2017 20:12:59 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析</title>
      <link>https://stackoverflow.com/questions/18371333/principal-components-analysis</link>
      <description><![CDATA[我正在阅读一篇关于主成分分析的教程（主成分分析教程/Lindsay I Smith）。最后讨论了“恢复旧数据”。我想知道这样做有什么意义吗？我实际上已经在 R 中的 princomp 函数下对名为“USArrests”的数据集进行了尝试。通过转换回旧数据集，我得到的变量数量与原始数据集完全相同，更糟糕的是，转换后的变量 100% 相关。从这个意义上说，PCA 无法减少原始变量的数量，因此无法消除它们之间的相关性。]]></description>
      <guid>https://stackoverflow.com/questions/18371333/principal-components-analysis</guid>
      <pubDate>Thu, 22 Aug 2013 03:46:28 GMT</pubDate>
    </item>
    <item>
      <title>PCA 降低数据集维数的简单解释</title>
      <link>https://stackoverflow.com/questions/12184175/simple-explanation-of-pca-to-reduce-dimensionality-of-dataset</link>
      <description><![CDATA[我知道PCA 不会告诉您数据集中哪些特征最重要，但会告诉您哪些特征组合保留了最大的方差。
您如何利用 PCA 旋转数据集的事实，使其在第一维上具有最大的方差，在第二维上具有第二大的方差，依此类推，以降低数据集的维数？
我的意思是，更深入地说，如何使用前 N 个特征向量将特征向量转换为保留大部分方差的低维表示？]]></description>
      <guid>https://stackoverflow.com/questions/12184175/simple-explanation-of-pca-to-reduce-dimensionality-of-dataset</guid>
      <pubDate>Wed, 29 Aug 2012 18:22:20 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析</title>
      <link>https://stackoverflow.com/questions/10818718/principal-component-analysis</link>
      <description><![CDATA[我必须编写一个分类器（高斯混合模型），用于人类动作识别。
我有 4 个视频数据集。我选择其中 3 个作为训练集，1 个作为测试集。
在将 gmm 模型应用于训练集之前，我先在其上运行 pca。
pca_coeff=princomp(trainig_data);
score = training_data * pca_coeff;
training_data = score(:,1:min(size(score,2),numDimension));

在测试步骤中我应该做什么？我应该在测试数据上执行新的 princomp 吗？
new_pca_coeff=princomp(testing_data);
score = testing_data * new_pca_coeff;
testing_data = score(:,1:min(size(score,2),numDimension));

或者我应该使用我为训练数据计算的 pca_coeff？
score = testing_data * pca_coeff;
testing_data = score(:,1:min(size(score,2),numDimension));
]]></description>
      <guid>https://stackoverflow.com/questions/10818718/principal-component-analysis</guid>
      <pubDate>Wed, 30 May 2012 14:49:05 GMT</pubDate>
    </item>
    </channel>
</rss>