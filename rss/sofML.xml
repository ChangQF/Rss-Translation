<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Mon, 10 Feb 2025 15:19:39 GMT</lastBuildDate>
    <item>
      <title>降尺度操作不捕获峰[关闭]</title>
      <link>https://stackoverflow.com/questions/79427067/downscaling-operation-not-capturing-the-peaks</link>
      <description><![CDATA[我正在使用随机的森林回归模型将数据集降低从更粗的分辨率到更高分辨率。我尝试了交叉验证并调整参数。在检查验证分数时，我的MSE和R2值都相当好。但是，当我使用相同的模型预测新数据集的目标变量时，该模型将无法捕获数据初始数年的峰值。可能是其中一个功能具有主要的重要性。在绘制主要功能的数据时，全年数据稳定。
这使趋势偏离了
具有最重要性的数据之一  ]]></description>
      <guid>https://stackoverflow.com/questions/79427067/downscaling-operation-not-capturing-the-peaks</guid>
      <pubDate>Mon, 10 Feb 2025 12:29:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在大型数据集上训练XGBoost并改善欺诈检测？</title>
      <link>https://stackoverflow.com/questions/79426998/how-to-train-xgboost-on-a-large-dataset-and-improve-fraud-detection</link>
      <description><![CDATA[我只是从ML开始，所以我感谢任何建议。
我正在尝试培训一个模型以进行交易中的欺诈检测。数据高度不平衡（〜96％的正常人比〜4％欺诈）。
第一期 - 记忆消耗
培训文件为32 GB，但是即使仅阅读100万行，我也会收到一个内存分配错误：
  XGBOOST.CORE.XGBOOSTERROR：BAD_MALLOC：无法分配255479999900字节。
 
第二期 - 预测质量差
我正在对100k行进行训练，但是无论我如何调整XGBoost，该模型都几乎都无法检测到欺诈案件。
在这种情况下，XGBoost的最佳类平衡技术是什么？我应该如何处理这个数据集？您建议更改什么？
在此处输入图像描述 
  df = pd.read_csv（&#39;train.csv&#39;，nrows = 100000） 

df.drop（[&#39;transaction_id&#39;，&#39;card_holder_first_name&#39;，&#39;card_holder_last_name&#39;，&#39;is_verified&#39;，&#39;browser&#39;，&#39;browser_version&#39;，&#39;browser_version&#39;，&#39;
    &#39;operation_system&#39;，&#39;operation_system_version&#39;，&#39;card_id&#39;，&#39;ip_address&#39;，&#39;merchant_customer_id&#39;，&#39;merchant_id&#39;，&#39;user_agent&#39;，&#39;user_agent&#39;，
    &#39;merchant_customer_last_name&#39;，&#39;merchant_customer_first_name&#39;，&#39;merchant_customer_phone&#39;，&#39;merchant_customer_email&#39;，&#39;bin&#39;，&#39;bin&#39;，&#39;&#39;
    &#39;clockal_source&#39;，&#39;transaction_source&#39;，&#39;merchant_city&#39;，&#39;merchant_shop_id&#39;，&#39;merchant_shop_name&#39;，&#39;order_number&#39;]， 
    轴= 1，Inplace = true）

df [&#39;bank&#39;]。替换（&#39;&#39;，&#39;_&#39;，regex = true，inplace = true）

df [&#39;create_at&#39;] = pd.to_datetime（df [&#39;create_at&#39;]）
df [&#39;seconds_since_midnight&#39;] = df [&#39;create_at&#39;]。dt.hour * 3600 + df [&#39;create_at&#39;]。dt.minute * 60 + df [&#39;create_at&#39;]。dt.dt.second
df [&#39;day_of_week&#39;] = df [&#39;create_at&#39;]。dt.weekday

df.drop（&#39;create_at&#39;，axis = 1，Inplace = true）

df.loc [pd.isna（df [&#39;merchant_language&#39;]），&#39;merchant_language&#39;] =&#39;unknown&#39;

df.loc [pd.isna（df [&#39;payment_type&#39;]），&#39;payment_type&#39;] = 0

x = df.drop（&#39;is_fraud&#39;，axis = 1）.copy（）

y = df [&#39;is_fraud&#39;]。copy（）

x_encoded = pd.get_dummies（x，columns = [&#39;merchant_country&#39;，      
                                        &#39;transaction_type&#39;，
                                        “商人_language”，
                                        &#39;平台&#39;，
                                        &#39;ip_country&#39;，
                                        &#39;银行&#39;，
                                        “ cardbrand&#39;，
                                        &#39;cardcountry&#39;，
                                        &#39;cardtype&#39;， 
                                        &#39;payment_type&#39;]））


x_train，x_test，y_train，y_test = train_test_split（x_encoded，y，andury_state = 42，strate = y）


clf_xgb = xgb.xgbClassifier（
    objective =;二进制：logistic; quot;
    种子= 42，
    eval_metric =＆quot; aucpr; quot;
    早期_stopping_rounds = 10，
    max_depth = 6，  
    子样本= 0.8，  
    colsample_bytree = 0.8 
）

clf_xgb.fit（
    x_train，
    y_train，
    eval_set = [（x_test，y_test）]，
    冗长= true
）

disp =混淆matrixdisplay.from_estimator（
    clf_xgb，  
    x_test，  
    y_test，  
    display_labels = [不是欺诈者“  
    cmap =&#39;blues;
）
disp.plot（values_format =&#39;d&#39;）

plt.show（）
 
我是ML的新手，所以我还没有尝试过很多技术。我尝试了不同的XGBoost参数，并减少了数据集大小以适合内存，但是该模型仍在努力检测欺诈情况。我不确定最好的方法是处理如此大的不平衡数据集，因此我感谢任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/79426998/how-to-train-xgboost-on-a-large-dataset-and-improve-fraud-detection</guid>
      <pubDate>Mon, 10 Feb 2025 11:56:48 GMT</pubDate>
    </item>
    <item>
      <title>如何后处理基于YOLO的实例分割模型，该模型可产生10个张量作为输出？</title>
      <link>https://stackoverflow.com/questions/79426679/how-to-post-process-the-output-of-a-yolo-based-instance-segmentation-model-that</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79426679/how-to-post-process-the-output-of-a-yolo-based-instance-segmentation-model-that</guid>
      <pubDate>Mon, 10 Feb 2025 09:55:13 GMT</pubDate>
    </item>
    <item>
      <title>测试分类问题的数据配置[关闭]</title>
      <link>https://stackoverflow.com/questions/79426228/test-data-configuration-for-a-classification-problem</link>
      <description><![CDATA[我创建了一个用于培训神经网络的二进制分类问题的数据集。培训数据来自与特定环境（例如2D地图环境）有关的集合。对于测试案例，我考虑了来自同一2D地图的数据点，但培训集中不存在数据点。
这将是有效的测试用例设计？]]></description>
      <guid>https://stackoverflow.com/questions/79426228/test-data-configuration-for-a-classification-problem</guid>
      <pubDate>Mon, 10 Feb 2025 06:23:53 GMT</pubDate>
    </item>
    <item>
      <title>ML模型保存</title>
      <link>https://stackoverflow.com/questions/79426066/ml-models-saving</link>
      <description><![CDATA[我正在训练一种机器学习模型，将阿尔茨海默氏病分为四类。运行培训时期后，我使用代码将模型保存在.pth文件中。但是，在下载了保存的模型并将其与我的接口连接起来后，它没有产生任何结果。经过进一步检查，似乎模型是空的。
 导入火炬
导入Torch.nn作为nn
导入Torch.optim作为最佳
来自TQDM.Auto Import TQDM
来自Torchvision导入模型

＃设置设备（GPU如果可用）
设备= torch.device（&#39;cuda&#39;如果torch.cuda.is_available（）else&#39;cpu&#39;）

＃定义Resnet18模型
类Resnet18（nn.Module）：
    def __init __（self，num_classes）：
        super（resnet18，self）.__ init __（）
        self.model = model.Resnet18（预审计= false）＃设置为true以使用预训练的权重
        self.model.fc = nn.linear（self.model.fc.in_features，num_classes）＃修改最终层

    def向前（self，x）：
        返回self.model（x）

＃用数据集中的类数初始化模型
num_classes = len（train_data_simple.classes）＃根据您的增强数据集进行调整
model_resnet = resnet18（num_classes = num_classes）。

＃损失功能和优化器（SGD和Crossentropy）
loss_fn = nn.Crossentropyloss（）
优化器= optim.sgd（model_resnet.parameters（），lr = 0.1，动量= 0.9）

＃训练循环（使用TQDM进行进度栏）
def train（型号，train_dataloader，test_dataloader，优化器，loss_fn，epochs）：
    对于TQDM中的时期（范围（时代））：
        model.train（）＃将模型设置为训练模式
        Running_loss = 0.0
        recript_train，total_train = 0，0

        对于枚举（train_dataloader）的批次（x，y）：
            x，y = x.to（设备），y.to（设备）

            优化器.zero_grad（）＃零梯度

            输出=模型（x）＃前向通行证
            损失= loss_fn（输出，y）＃计算损失

            lose.backward（）＃backpropagation
            Optimizer.step（）＃更新权重

            running_loss += loss.item（）
            _，预测= torch.max（outputs.data，1）
            total_train += y.size（0）
            recripe_train +=（预测== y）.sum（）。item（）

        ＃打印培训损失和准确性
        打印（f＆quot; epoch [{epoch+1}/{epochs}]，损失：{runn_loss/len（train_dataloader）：。4f}＆quort;）
        打印（f＆quot“训练精度：{100 * recript_train / total_train：.2f}％＆quot”）

        ＃ 验证
        model.eval（）＃开关模型到评估模式进行验证
        recript_val，total_val = 0，0
        使用Torch.no_grad（）：
            对于x_val，y_val在test_dataloader中：
                x_val，y_val = x_val.to（设备），y_val.to（设备）
                val_outputs =模型（x_val）
                _，预测= torch.max（val_outputs.data，1）
                total_val += y_val.size（0）
                prection_val +=（预测== y_val）.sum（）。item（）。

        ＃打印验证精度
        打印（f＆quot“验证精度：{100 * recript_val / total_val：.2f}％＆quort”）

    返回模型

＃示例培训
num_epochs = 30＃根据您的要求调整时期
＃使用增强培训数据加载器
trained_model_resnet = train（model_resnet，train_dataloader_simple，test_dataloader_simple，optimizer，optimizer，lose_fn，num_epochs）

 
这是我在不同单元格中运行的代码来保存模型
 ＃保存训练有素的模型
model_path =＆quot trained_resnet18_model.pth＆quot;
TORCH.SAVE（model_resnet.state_dict（），model_path）
打印（f＆quot“模型保存到{model_path}”
 
我正在训练一种机器学习模型，将阿尔茨海默氏病分为四类，使用pytorch分为四类。经过几个时期的训练后，我想使用诸如model.save（&#39;my_model.h5&#39;）或torch.save（model.state_dict（），&#39;model.pth&#39;）的代码保存训练的模型。
我应该添加代码以将训练的模型保存在定义训练时期并运行训练环的同一单元格中，还是将其放在其他单元格中更好？放置是否会影响模型的保存方式，或者以后如何加载？]]></description>
      <guid>https://stackoverflow.com/questions/79426066/ml-models-saving</guid>
      <pubDate>Mon, 10 Feb 2025 04:15:24 GMT</pubDate>
    </item>
    <item>
      <title>SAM中的细分网格地理空间错误：不可订阅的非类型对象</title>
      <link>https://stackoverflow.com/questions/79425639/segment-geospatial-error-in-sam-predict-nonetype-object-is-not-subscriptable</link>
      <description><![CDATA[我正在使用图书馆 segment-geospatial 我有图像。
  image =&#39;/content/drive/mydrive/myimage.tiff&#39;
sam = samgeo（
    model_type =; vit_h＆quot;
    自动= false，
    sam_kwargs =无，
）

sam.set_image（图像）

盒子= [
        [-51.2546，-22.1771，-51.2541，-22.1767]，
        [-51.2538，-22.1764，-51.2535，-22.1761]，
这是给

sam.predict（boxes = box，point_crs =&#39;
 
当我运行sam.predict（）时，我会收到以下错误：
 
找不到有效的像素坐标。
----------------------------------------------------------------------------- --------------------------------------
TypeError Trackback（最近的最新通话）
＆lt; ipython-Input-72-A3B6CDCAB301＆gt;在＆lt;单元线：0＆gt;（）
----＆gt; 1 sam.predict（boxes = box，point_crs =; epsg：4326＆quot; output =; mask.tif; dtype =; uint8＆quort;

/usr/local/lib/python3.11/dist-packages/samgeo/samgeo.py in prediact（self，point_coords，point_coords，point_labels，box，point_crs，point_crs，mask_input，multimask_output，multimask_output，return_logits，return_logits，returation_logits，returation_logits，returat *Kwargs）
    615坐标= bbox_to_xy（self.source，box，point_crs）
    616 input_boxes = np.array（coords）
 - ＆gt; 617如果isInstance（坐标[0]，int）：
    618 input_boxes = input_boxes [none，：]
    619其他：

TypeError：“非型”对象不可订阅
 
我已经检查了栅格图像crs格式是正确的，我已经尝试了使用它们在文档中提供的示例的代码，并且效果很好，但是当我使用栅格尝试时，它不起作用。
 https://samgeo.gishub.org.org/examples/box_prompts/box_prompts/ ]]></description>
      <guid>https://stackoverflow.com/questions/79425639/segment-geospatial-error-in-sam-predict-nonetype-object-is-not-subscriptable</guid>
      <pubDate>Sun, 09 Feb 2025 20:23:01 GMT</pubDate>
    </item>
    <item>
      <title>CIFAR100的82％测试准确性[封闭]</title>
      <link>https://stackoverflow.com/questions/79425154/82-test-accuracy-on-cifar100</link>
      <description><![CDATA[如何使用100万个参数（或少于1m）和小于80-100m的拖鞋上的CIFAR-100实现82％的测试准确性，固定了50个时期？
我尝试了MobilenetV2并获得了70％的测试准确性，然后有效NETB0并获得了77％的准确性。]]></description>
      <guid>https://stackoverflow.com/questions/79425154/82-test-accuracy-on-cifar100</guid>
      <pubDate>Sun, 09 Feb 2025 15:30:02 GMT</pubDate>
    </item>
    <item>
      <title>在扩散模型中U形网络的上下抽样阶段中不同的缩小参数</title>
      <link>https://stackoverflow.com/questions/79422978/different-concate-dimension-parameters-in-the-up-and-down-sampling-phase-of-u-sh</link>
      <description><![CDATA[我遇到的错误是
 文件＆quot＆quot＆quot＆quot&gt;
    x = torch.cat（（x，residual_x），dim = 1） 
RuntimeError：张量的尺寸必须匹配，除了尺寸1。预期尺寸24，但在列表中获得张量1的尺寸25。
 
该模型的训练数据集输入是Paviau。
调试后要找到问题的输出向量如下：
  down = torch.size（[4，64，25，64，64]）
UP = Torch.Size（[4，64，24，64，64]）
 
整个代码如下：
 
    def向前（self，x，timeStep，feature = false）：
        ＃嵌入式时间
        t = self.time_mlp（timeStep）
        ＃初始转换
        x = self.conv0（x）
        ＃UNET
        ristual_inputs = []
        在self.downs中进行下降：
            x = down（x，t）
            ristual_inputs.append（x）
        为了自我。
            ristual_x = ristual_inputs.pop（）
            ＃print（down =; quord =; residual_x.shape，＆quot up =; quord =; x.Shape）
            ＃添加残留X作为其他频道
            x = torch.cat（（x，residual_x），dim = 1）* 
            如果特征：
                self.features.append（x.detach（）。cpu（）。numpy（））
            x =向上（x，t）
        返回self.output（x）
         
 ]]></description>
      <guid>https://stackoverflow.com/questions/79422978/different-concate-dimension-parameters-in-the-up-and-down-sampling-phase-of-u-sh</guid>
      <pubDate>Sat, 08 Feb 2025 10:14:34 GMT</pubDate>
    </item>
    <item>
      <title>从GPU内存中清除tf.data.dataset</title>
      <link>https://stackoverflow.com/questions/79420818/clearing-tf-data-dataset-from-gpu-memory</link>
      <description><![CDATA[在实施使用 tf.data.dataset 作为KERAS模型的输入的训练环时，我遇到了问题。我的数据集具有以下格式的元素规范：
 （{&#39;data&#39;：tensorSpec（shape =（15000，1），dtype = tf.float32），&#39;index&#39;：tensorspec&#39;：tensorspec（shape =（2，2，2，2， ），dtype = tf.int64）}，tensorspec（shape =（1，），dtype = tf.int32））
 
因此，基本上，每个样本均以元组（x，y）构建形状（15000，1），另一个形状索引（2，）（在培训期间不使用索引）， y 是单个标签。
The tf.data.Dataset is created using dataset = tf.data.Dataset.from_tensor_slices((X, y)), where X是两个密钥的命令：

 数据：形状的NP数组（200k，1500，1）， index  with 
 索引：形状的NP数组（200K，2） 

和 y 是形状的单个数组（200k，1） 
我的数据集有大约200k的培训样本（运行底漆后）和200k验证样本。
呼叫 tf.data.dataset.from_tensor_slices 我注意到GPU内存使用情况中有一个尖峰，在创建培训 tf.dataset ，and和创建验证 tf.dataset 。之后，更多16GB
创建 tf.dataSet 后，我运行了一些操作（例如，洗牌，批处理和预拿方），并调用 model.fit.fit 。我的型号大约有500K可训练的参数。
我遇到的问题是  拟合模型。我需要在一些其他数据上运行推断，因此我使用此数据创建了一个新的 tf.dataset ，再次使用 tf.dataset.from_tensor_slices 。但是，我注意到培训和验证 tf.dataset 仍然存在于GPU内存中，这导致我的脚本随着新的 tf.dataset  i而遇到的不含内存问题 i想要推断。
我在两个 tf.dataset 上尝试调用 del ，然后随后调用 gc.collect（）清除RAM，而不是GPU内存。另外，我尝试禁用我应用的某些操作，例如预摘要，也可以使用批处理大小，但是这些都没有用。我还尝试调用 keras.backend.clear_session（），但它也无助于清除GPU内存。我还尝试从 numba 导入 cuda ，但是由于我的安装，我无法使用它来清除内存。我有什么办法可以从gpu内存中清除 tf.data.dataset ？]]></description>
      <guid>https://stackoverflow.com/questions/79420818/clearing-tf-data-dataset-from-gpu-memory</guid>
      <pubDate>Fri, 07 Feb 2025 12:02:12 GMT</pubDate>
    </item>
    <item>
      <title>Yolov8最终检测头仍输出（1、7、8400），而不是（1、8、8400）</title>
      <link>https://stackoverflow.com/questions/79419018/yolov8-final-detection-head-still-outputs-1-7-8400-instead-of-1-8-8400-f</link>
      <description><![CDATA[我训练了3个类的Yolov8检测模型，但是原始的正向通行证仍然显示（1、7、8400）而不是（1、8、8400）的最终检测输出。
我做了什么：
检查了我的data.yaml：
  train：路径/to/tain/train/images
Val：路径/到/Val/图像
NC：3
名称：[&#39;神经胶质瘤&#39;，&#39;脑膜瘤&#39;，&#39;垂体&#39;]
 
确认的NC：3是正确的。
通过命令从头开始训练：
在
    data =路径/到/data.yaml \
    模型= yolov8x \
    epochs = 1000 \
    imgsz = 640 \
    设备= 1 \
    耐心= 100
 
训练没有错误地进行，并成功完成。
安装了最新的Ultrytics版本（v8.3.72），以确保没有版本问题：
  pip卸载Ultralytics
PIP安装超级词
 
直接加载了新的best.pt：
 超级timportic
导入火炬

型号= yolo（r＆quot; best.pt;）。模型
model.eval（）

dummy_input = torch.randn（1，3，640，640）
使用Torch.no_grad（）：
    输出=模型（Dummy_input）

输出输出：
    ＃一些输出是列表；仔细检查每个元素
    如果Isinstance（Out，Torch.Tensor）：
        打印（OUT.SHAPE）
    别的：
        打印（“列表输出：＆quot” [o。
 
控制台显示检测输出（1、7、8400）。
经过验证的模型元数据说NC = 3和Model.Names有3个类。但是，原始检测层输出仍然是7个通道。
观察：
如果Yolo检测层是真正的3类，则应输出（5 + 3）=每个锚点8个通道，而不是7通道。
不匹配（1、7、8400）通常表明尽管NC = 3。
问题 /请求帮助：
为什么即使我从头开始训练了3堂课，为什么还要原始检测头（1、7、8400）？
如何确保将检测层完全重新定位为（5 + 3）= 8以进行3级检测？
我尝试删除旧的.pt文件，重新检查我的data.yaml，重新安装超级图案和确认模型。model.nc== 3。但是，最终检测层继续产生7个频道，而不是8个频道。。
关于可能导致这种持续不匹配的什么想法？]]></description>
      <guid>https://stackoverflow.com/questions/79419018/yolov8-final-detection-head-still-outputs-1-7-8400-instead-of-1-8-8400-f</guid>
      <pubDate>Thu, 06 Feb 2025 18:39:21 GMT</pubDate>
    </item>
    <item>
      <title>用Java编写的AI分类均匀，奇数行不通[关闭]</title>
      <link>https://stackoverflow.com/questions/79413494/ai-written-in-java-which-classifies-even-and-odd-numbers-doesnt-work</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79413494/ai-written-in-java-which-classifies-even-and-odd-numbers-doesnt-work</guid>
      <pubDate>Wed, 05 Feb 2025 02:09:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么2048年游戏训练对我来说不正常？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79411336/why-is-training-for-the-game-2048-not-working-well-for-me</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79411336/why-is-training-for-the-game-2048-not-working-well-for-me</guid>
      <pubDate>Tue, 04 Feb 2025 10:28:14 GMT</pubDate>
    </item>
    <item>
      <title>随机森林回归中的树木数量</title>
      <link>https://stackoverflow.com/questions/56505551/number-of-trees-in-random-forest-regression</link>
      <description><![CDATA[我正在学习随机的森林回归模型。我知道它形成了许多树（模型），然后我们可以通过平均所有树的结果来预测目标变量。我也对决策树回归算法有一个下降的理解。我们如何形成最佳树木数量？
例如，我有一个数据集，我可以在其中预测人的薪水，而我只有两个输入变量是“年度经验”，“绩效得分”，那么我可以使用这样的数据集形成多少个随机树？随机林木是否取决于输入变量的数量？任何好例子都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/56505551/number-of-trees-in-random-forest-regression</guid>
      <pubDate>Sat, 08 Jun 2019 10:33:36 GMT</pubDate>
    </item>
    <item>
      <title>r的回归森林中的特征选择和预测准确性</title>
      <link>https://stackoverflow.com/questions/45935917/feature-selection-and-prediction-accuracy-in-regression-forest-in-r</link>
      <description><![CDATA[我正在尝试解决一个回归问题，其中输入功能集的大小〜54。
使用单个预测指标“ x1”使用OLS线性回归，我无法解释y-的变化 - 因此，我试图使用回归森林（即随机森林回归）找到其他重要特征。后来发现选定的“ X1”是最重要的功能。
我的数据集有〜14500个条目。我将其分为训练和测试集，比率为9：1。
我有以下问题：

 试图找到重要功能时，我应该在整个数据集上或仅在培训数据上运行回归森林吗？

 找到重要的功能后，是否应该使用顶级功能重新构建模型，以查看功能选择是否以较小的预测能力成本加速计算？

 目前，我已经使用训练集和所有功能构建了模型，并且我将其用于预测测试集。我正在计算训练集中的MSE和R平方。我在培训数据上获得了高MSE和低R2，并反向测试数据（如下所示）。这是不寻常的吗？


 ＆gt;森林＆lt;  -  rancomalforest（fmla，dtraining，ntree = 501，重要性= t）
    
     ＆gt;平均值（（dtraining $ y-预测（森林，data = dtraining））^2）
    
     ＆gt; ＆gt; 0.9371891
    
     ＆gt; rsquared（dtraining $ y，dtraining $ y-预测（森林，data = dtraining））

     ＆gt; ＆gt; 0.7431078
    
     ＆gt;平均值（（dtest $ y-预测（森林，newdata = dtest））^2）

     ＆gt; ＆gt; 0.009771256

     ＆gt; rsquared（dtest $ y，dtest $ y-预测（森林，newdata = dtest））
    
     ＆gt; ＆gt; 0.9950448
 
是否有R-Squared和MSE是此问题的好指标，或者我需要查看其他一些指标来评估该模型是否良好？]]></description>
      <guid>https://stackoverflow.com/questions/45935917/feature-selection-and-prediction-accuracy-in-regression-forest-in-r</guid>
      <pubDate>Tue, 29 Aug 2017 09:51:00 GMT</pubDate>
    </item>
    <item>
      <title>Python监督机器学习</title>
      <link>https://stackoverflow.com/questions/35438540/python-supervised-machine-learning</link>
      <description><![CDATA[我试图了解如何使用 scikit 进行监督机器学习，因此我已经编造了一些属于两个不同集的数据：集合A和集合B。我有18个元素集合中的18个元素。每个元素都有三个变量。请参阅下文：
  #seta
变量1a = [3,4,4,5,4,5,5,6,7,7,5,4,5,6,4,9,3,4]
变量2A = [5,4,4,4,3,4,5,4,5,4,3,4,5,3,4,3,4,4,3]
变量3A = [7,8,4,5,6,7,3,3,3,4,4,9,7,6,8,6,7,8]


#setB
变量1b = [7,8,11,12,7,9,8,7,8,11,15,9,7,6,9,7,11]]
变量2b = [1,2,3,3,4,4,2,4,1,0,1,2,1,3,4,3,1,2,3]
变量3b = [12,18,14,15,16,17,13,13,13,14,14,14,19,17,16,18,16,17,18]
 
我将如何使用
对数据集很小的道歉，并且“构成”。我只想在其他数据集上使用Scikit应用相同的方法。]]></description>
      <guid>https://stackoverflow.com/questions/35438540/python-supervised-machine-learning</guid>
      <pubDate>Tue, 16 Feb 2016 16:59:48 GMT</pubDate>
    </item>
    </channel>
</rss>