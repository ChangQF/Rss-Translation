<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 27 Aug 2024 21:14:19 GMT</lastBuildDate>
    <item>
      <title>学习LSTM神经网络的问题</title>
      <link>https://stackoverflow.com/questions/78920308/the-problem-with-learning-the-lstm-neural-network</link>
      <description><![CDATA[我需要创建一个模型来预测某些信号随时间变化的误差，即解决时间序列回归问题。我为此使用 LSTM：
class MyLSTM(nn.Module):
def __init__(self, num_classes, input_size, hidden_​​size, num_layers, seq_length):
super(MyLSTM, self).__init__()
self.num_classes = num_classes 
self.num_layers = num_layers 
self.input_size = input_size 
self.hidden_​​size = hidden_​​size 
self.seq_length = seq_length 

self.lstm = nn.LSTM(input_size = input_size, hidden_​​size = hidden_​​size, num_layers = num_layers, batch_first = True) 
self.fc_1 = nn.Linear(hidden_​​size, 128) 
self.fc_2 = nn.Linear(128, num_classes) 
self.activatin_func = nn.Tanh()

def forward(self, x):
h_0 = 变量(torch.zeros(self.num_layers, x.size(0), self.hidden_​​size)) 
c_0 = 变量(torch.zeros(self.num_layers, x.size(0), self.hidden_​​size)) 
out, (hn, cn) = self.lstm(x, (h_0, c_0)) 
hn = hn.view(-1, self.hidden_​​size) 
out = self.activatin_func(hn)
out = self.fc_1(out) 
out = self.fc_2(out) 
out = self.activatin_func(out)
return out

超参数：
num_epochs = 1000 
learning_rate = 0.01 

input_size = X.shape[1] 
num_classes = y.shape[1] 

hidden_​​size = 16 
num_layers = 1 

在此处输入图片描述
结果，我在训练阶段得到了模型估计的相当准确的近似值，而在测试阶段得到了差异。我觉得这很奇怪，因为训练非常成功，并且评估函数在预测阶段的值没有急剧跳跃，评估曲线应该足够接近真实值，但在实践中我得到了急剧跳跃，我不明白其性质。
可能是什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78920308/the-problem-with-learning-the-lstm-neural-network</guid>
      <pubDate>Tue, 27 Aug 2024 18:29:17 GMT</pubDate>
    </item>
    <item>
      <title>我在创建聊天机器人时收到错误</title>
      <link>https://stackoverflow.com/questions/78920227/i-received-an-error-while-creating-the-chatbot</link>
      <description><![CDATA[如果有人可以提供帮助，我无法发布直接代码。我正在使用 Keras、TensorFlow 和 Python。我的项目涉及两个主要部分：聊天机器人的创建和聊天机器人前端的开发。提前谢谢您。
以下是图片的链接
https://i.sstatic.net/TpgppnbJ.png]]></description>
      <guid>https://stackoverflow.com/questions/78920227/i-received-an-error-while-creating-the-chatbot</guid>
      <pubDate>Tue, 27 Aug 2024 18:00:12 GMT</pubDate>
    </item>
    <item>
      <title>CNN 优化器未更新权重</title>
      <link>https://stackoverflow.com/questions/78920202/cnn-optimizer-not-updating-weights</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78920202/cnn-optimizer-not-updating-weights</guid>
      <pubDate>Tue, 27 Aug 2024 17:55:02 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型_需要建议[关闭]</title>
      <link>https://stackoverflow.com/questions/78920194/machine-learning-model-need-advice</link>
      <description><![CDATA[`CAD_df = pd.read_csv(&#39;/kaggle/input/canadian-salary-data-from-stack-overflow-survey/CanadaData.csv&#39;, index_col = &#39;Title&#39;)

sorted_CAD=CAD_df.sort_values(by = &#39;Year&#39;, accending=True)
sorted_CAD

# 导入必要的库
从 xgboost 导入 XGBRegressor
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 mean_absolute_error
将 seaborn 导入为 sns
将 matplotlib.pyplot 导入为 plt
%matplotlib inline
从 sklearn.preprocessing 导入 OneHotEncoder
从 sklearn.model_selection 导入 cross_val_score
从 sklearn.pipeline 导入 Pipeline

类型这里


sorted_CAD.nunique()

# 防止数据泄露
CAD_dfn = sorted_CAD.drop([&#39;Year&#39;, &#39;Country&#39;], axis=1)
CAD_dfn

# 设置训练数据和目标变量
y = CAD_dfn[&#39;Salary (USD)&#39;]
X = CAD_dfn.drop(&#39;Salary (USD)&#39;, axis = 1)

# 构建模型训练管道 &amp; fittitng
my_pipeline = Pipeline(steps = [(&#39;preprocessor&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;)),
(&#39;model&#39;,XGBRegressor(n_estimators=900,learning_rate=0.05,random_state=0))])

#训练模型
my_pipeline.fit(X, y)

#由于没有测试数据，因此进行交叉验证
val_score = -1 * cross_val_score(my_pipeline, X, y, cv = 7,scoring = &#39;neg_mean_absolute_error&#39;)

val_score.mean()

&#39;&#39;&#39;该模型使用 [公司规模、行业、经验、国家、城市] 等特征预测普通加拿大人的基本工资 &#39;&#39;&#39;

&#39;该模型使用 [公司规模] 等特征预测普通加拿大人的基本工资,行业,经验,国家,城市] &#39;
val_score.mean()
5474.365167467971
&#39;&#39;&#39;这意味着模型

模型在每个预测值上的准确度为 +/- $5,474，请随意发表评论或更多想法！
&#39;&#39;&#39;
&#39;这意味着模型在每个预测值上的准确度为 +/- $5,474，请随意发表评论或更多想法！\n
我是机器学习的新手，我建立了这个模型，一直在寻求听取关于需要改进什么或需要做更多事情的第二意见？非常感谢任何反馈，谢谢。`your text``]]></description>
      <guid>https://stackoverflow.com/questions/78920194/machine-learning-model-need-advice</guid>
      <pubDate>Tue, 27 Aug 2024 17:53:58 GMT</pubDate>
    </item>
    <item>
      <title>为 AWS SageMaker 配置 IAM 角色</title>
      <link>https://stackoverflow.com/questions/78919257/configuring-an-iam-role-for-aws-sagemaker</link>
      <description><![CDATA[我正在 Udacity 上学习一门课程。对于最终项目，我必须微调 LLM。为此，他们给予 AWS 云积分。但我无法按照指示在 sagemaker 中创建 IAM 角色。我收到以下错误
未选择用于推理托管端点的实例类型。默认为 ml.g5.12xlarge。
ClientError：调用 CreateEndpointConfig 操作时发生错误 (AccessDeniedException)：
用户：arn：aws：sts::730656687357：assumed-role/SageMaker-ProjectSageMakerRole/SageMaker
无权对资源执行：sagemaker：CreateEndpointConfig：
arn：aws：sagemaker：us-west-2：730656687357：endpoint-config/meta-textgeneration-llama-2-7b-2024-08-27-13-31-54-591
在基于身份的策略中明确拒绝

在为 AWS SageMaker 配置 IAM 角色时，没有管理端点来选择它在此输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78919257/configuring-an-iam-role-for-aws-sagemaker</guid>
      <pubDate>Tue, 27 Aug 2024 14:00:06 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv8 迁移学习：冻结层后预训练权重的损失</title>
      <link>https://stackoverflow.com/questions/78918374/yolov8-transfer-learning-loss-of-pretrained-weights-after-freezing-layers</link>
      <description><![CDATA[经过训练后，模型可以准确预测纸板箱，但无法检测到训练前用于识别的任何其他物体。似乎预训练的权重已被覆盖或丢失。我的目标是保留检测其他物体的能力，同时专门针对纸板箱对模型进行微调。
我从 Roboflow 获得了正确标记的数据集。
https://universe.roboflow.com/dataset-t7hz7/cardboard-eupc8
为什么模型在训练后失去了检测其他物体的能力，即使我已经冻结了最初的 10 层？如何保留 YoloV8 原有的物体检测功能，同时专注于识别纸板箱？
代码：
from ultralytics import YOLO

model = YOLO(&#39;yolov8n.pt&#39;)

model.train(
data=&#39;/Users/shubhamb/IdeaProjects/transfer-learning/data/data.yaml&#39;,
epochs=25,
imgsz=416,
freeze=10,
plots=True,
#device=&quot;mps&quot;,
name=&quot;custom_yolov8_model&quot;
)
]]></description>
      <guid>https://stackoverflow.com/questions/78918374/yolov8-transfer-learning-loss-of-pretrained-weights-after-freezing-layers</guid>
      <pubDate>Tue, 27 Aug 2024 10:20:25 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：'DataLoader' 对象在 SuperGradients Trainer 中不可下标</title>
      <link>https://stackoverflow.com/questions/78917847/typeerror-dataloader-object-is-not-subscriptable-in-supergradients-trainer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78917847/typeerror-dataloader-object-is-not-subscriptable-in-supergradients-trainer</guid>
      <pubDate>Tue, 27 Aug 2024 08:28:38 GMT</pubDate>
    </item>
    <item>
      <title>需要机器学习项目工作流程方面的帮助 [关闭]</title>
      <link>https://stackoverflow.com/questions/78917544/need-help-in-ml-project-workflow</link>
      <description><![CDATA[我正在做一个与日志相关的项目。我需要解析日志并将它们缩短为某种模式（日志不断出现）。然后我想用我在某些日志序列之后得到的错误日志来标记每个日志序列。问题是错误有很多种类型。我首先考虑对错误进行聚类，然后从中制作出一定数量的标签（聚类）。然后我想用它们的错误类型来标记非错误日志序列。然后我想用这些数据训练模型，以预测特定日志流可能发生的最可能错误。
有人可以补充和帮助吗？请给我任何你认为对我最好的建议，或者在必要时纠正我。
我正在尝试对所有错误进行聚类，因为我想要有限数量的标签来进行监督学习。我在缩短文本日志数据方面遇到了问题，因为它太大了。]]></description>
      <guid>https://stackoverflow.com/questions/78917544/need-help-in-ml-project-workflow</guid>
      <pubDate>Tue, 27 Aug 2024 07:07:20 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow-federated 0.86.0.. AttributeError: 模块‘tensorflow_federated.python.learning’没有属性‘build_federated_averaging_process</title>
      <link>https://stackoverflow.com/questions/78916201/tensorflow-federated-0-86-0-attributeerror-module-tensorflow-federated-pytho</link>
      <description><![CDATA[--------------------------------------------------------------------------
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-21-ab950bcb167c&gt; 在 &lt;cell line: 1&gt;()
----&gt; 1 trainer = tff.learning.build_federated_averaging_process(
2 model_fn,
3 client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),
4 server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.05)#learning_rate=0.01
5 )

AttributeError: 模块“tensorflow_federated.python.learning”没有属性“build_federated_averaging_process”

我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78916201/tensorflow-federated-0-86-0-attributeerror-module-tensorflow-federated-pytho</guid>
      <pubDate>Mon, 26 Aug 2024 20:32:53 GMT</pubDate>
    </item>
    <item>
      <title>Python文本检测OpenCV + Roboflow OCR相机性能非常滞后问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78913244/python-text-detection-opencvroboflow-ocr-camera-performance-very-lag-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78913244/python-text-detection-opencvroboflow-ocr-camera-performance-very-lag-problem</guid>
      <pubDate>Mon, 26 Aug 2024 07:22:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使用文本数据集训练模型</title>
      <link>https://stackoverflow.com/questions/78865593/how-to-train-a-model-using-a-text-dataset</link>
      <description><![CDATA[我想创建一个生成文本的 AI 模型。具体来说，BDD Gherkin 黄瓜场景和步骤定义基于用户故事的输入。
带有 BDD Gherkin 黄瓜示例的用户故事
例如。
用户故事（输入）：我想在电子商务网站上将产品添加到我的购物篮中进行购买。
输出：自动创建测试用例场景和步骤定义
测试用例场景：

场景 1：验证用户是否可以将一个商品添加到购物车
场景 2：验证用户是否可以从购物车中移除一个商品

测试用例场景 1：

假设用户使用和启动并登录电子商务应用程序
然后用户导航到商品页面。
然后用户选择并单击。
然后用户单击“添加到购物车”按钮。
然后用户应导航到购物车页面。
然后用户应验证购物车页面已成功添加。

测试用例场景 2：

假设用户使用 启动并登录电子商务应用程序 
然后用户应导航到购物车页面。
然后用户在购物车中找到并单击“从购物车中移除”按钮。
然后用户应验证购物车已成功移除。

我创建了一个示例数据集，其中包含映射到场景和步骤定义的用户故事。
数据集
就我目前的理解，逻辑是：我想基于现有用户故事和场景的数据集训练一个模型。在模型训练完成后，我想输入一个用户故事，模型应该提出一个带有步骤定义的合适场景。
我是机器学习的新手，只做过某种形式的监督学习、回归。从一些研究中，我需要使用一些 NLP 技术来处理数据集。从那时起，我就很迷茫。我看到一些人谈论使用 ChatGPT 来训练数据集之类的东西。
做这个项目的好方法是什么。
本质上，我想找出如何使用文本训练模型，以便模型可以接收文本并输出文本。]]></description>
      <guid>https://stackoverflow.com/questions/78865593/how-to-train-a-model-using-a-text-dataset</guid>
      <pubDate>Tue, 13 Aug 2024 09:59:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 Hugging Face Transformers 训练 GPT-2 模型时如何修复分段错误？</title>
      <link>https://stackoverflow.com/questions/78841125/how-to-fix-segmentation-fault-when-training-gpt-2-model-using-hugging-face-trans</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78841125/how-to-fix-segmentation-fault-when-training-gpt-2-model-using-hugging-face-trans</guid>
      <pubDate>Tue, 06 Aug 2024 21:47:06 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 模型无法训练</title>
      <link>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</link>
      <description><![CDATA[我正在尝试使用深度学习来查找粒子的化学状态。作为输入，我有粒子在 X_train 中随时间的位置，形状为 (num_train,sequence_length)。 （我的序列长度为 100），输出是形状为 (num_train,1) 的 Y_train 中包含的转换帧（介于 1 和 100 之间）。
这是一个序列示例（https://i.sstatic.net/Ddmhjc24.jpg），转换位于第 84 帧。
所有数据都是用非常具体的算法生成的，但是该算法不会生成非常复杂的数据，我认为自己很容易找到转换，但我希望这个深度学习模型能够正常工作。
这是 LSTM 代码：
# 过滤

# 定义 LSTM 模型
model = Sequential([
LSTM(64, input_shape=(sequence_length, 1), return_sequences=False), Dense(64,activation=&#39;relu&#39;), Dense(1) ]) # 模型编译器 model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;) # 回归的均方误差 # 模型摘要 model.summary() # 模型模型嵌入 model.fit( X_train, Y_train, epochs=40, batch_size=32,validation_data=(X_test, Y_test)) # 新预测示例预测= model.predict(X_test) print(prediction)  结果： 模型：“sequential”
_________________________________________________________________
层（类型）输出形状参数 # 
====================================================================
lstm (LSTM) (无，64) 16896 

密集 (密集) (无，64) 4160 

密集_1 (密集) (无，1) 65 

============================================================================
总参数：21121 (82.50 KB)
可训练参数： 21121 (82.50 KB)
不可训练参数：0 (0.00 字节)
_________________________________________________________________
Epoch 1/10
631/631 [==============================] - 35s 50ms/step - 损失：1043.6710 - val_loss：840.6771
Epoch 2/10
631/631 [==============================] - 30s 48ms/step - 损失：840.9444 - val_loss：839.9596
Epoch 3/10
631/631 [===============================] - 32s 50ms/步 - 损失：841.6289 - val_loss：840.7188
Epoch 4/10
631/631 [=============================] - 30s 48ms/步 - 损失：840.9946 - val_loss：840.6344
Epoch 5/10
631/631 [===============================] - 33s 52ms/步 - 损失：841.8745 - val_loss：839.9298
Epoch 6/10
631/631 [==============================] - 31s 49ms/步 - 损失：841.6499 - val_loss：839.8434
Epoch 7/10
631/631 [=============================] - 31s 49ms/步 - 损失：841.2045 - val_loss：840.0717
Epoch 8/10
631/631 [===============================] - 30s 48ms/步 - 损失：842.0576 - val_loss： 840.2137
纪元 9/10
631/631 [=============================] - 33s 52ms/步 - 损失：842.7056 - val_loss：840.5657
纪元 10/10
631/631 [=============================] - 30s 48ms/步 - 损失：841.5714 - val_loss：839.8404
70/70 [================================] - 2s 16ms/步
[[52.569366]
[52.569286]
[52.569378]
...
[52.569344]
[52.569313]
[52.56937 ]]

如您所见，当我测试训练后的模型时，无论输入是什么，输出都是相同的。 val_loss 不会随着 epoch 数的增加而改善。这就是问题所在，我不明白发生了什么。
我反复检查了我的数据，X_train 已标准化，我尝试在模型上添加一些 drop out 和其他层，但没有任何变化。
也许使用 LSTM 无法做到这一点，但我认为数据非常简单。我真的想尝试找到一种方法来使用深度学习来找到它。]]></description>
      <guid>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</guid>
      <pubDate>Tue, 16 Jul 2024 07:31:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 Conda + Poetry 有意义吗？</title>
      <link>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</link>
      <description><![CDATA[在机器学习项目中使用 Conda + Poetry 是否有意义？请允许我分享我的（新手）理解，请纠正或启发我：
据我所知，Conda 和 Poetry 有不同的用途，但在很大程度上是多余的：

Conda 主要是一个环境管理器（实际上不一定是 Python），但它也可以管理包和依赖项。
Poetry 主要是一个 Python 包管理器（例如，pip 的升级），但它也可以创建和管理 Python 环境（例如，Pyenv 的升级）。

我的想法是同时使用两者并划分它们的角色：让 Conda 成为环境管理器，让 Poetry 成为包管理器。我的理由是（听起来）Conda 最适合管理环境，可用于编译和安装非 Python 包，尤其是 CUDA 驱动程序（用于 GPU 功能），而 Poetry 作为 Python 包管理器比 Conda 更强大。
我已经设法通过在 Conda 环境中使用 Poetry 相当轻松地完成这项工作。诀窍是不使用 Poetry 来管理 Python 环境：我没有使用 poetry shell 或 poetry run 之类的命令，只使用 poetry init、poetry install 等（在激活 Conda 环境后）。
为了全面披露，我的 environment.yml 文件（用于 Conda）如下所示：
name: N

channels:
- defaults
- conda-forge

dependencies:
- python=3.9
- cudatoolkit
- cudnn

我的 poetry.toml 文件如下所示：
[tool.poetry]
name = &quot;N&quot;
authors = [&quot;B&quot;]

[tool.poetry.dependencies]
python = &quot;3.9&quot;
torch = &quot;^1.10.1&quot;

[build-system]
requires = [&quot;poetry-core&gt;=1.0.0&quot;]
build-backend = &quot;poetry.core.masonry.api&quot;

说实话，我这样做的原因之一是，在没有 Conda 的情况下，我很难安装 CUDA（用于 GPU 支持）。
这个项目设计对你来说合理吗？]]></description>
      <guid>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</guid>
      <pubDate>Tue, 25 Jan 2022 15:09:43 GMT</pubDate>
    </item>
    <item>
      <title>Javascript 或 ML 中的自定义对象检测？</title>
      <link>https://stackoverflow.com/questions/66060711/custom-object-detection-in-javascript-or-ml</link>
      <description><![CDATA[我是对象检测领域的新手。所以不要介意我的基本问题。
我有一张身份证图像。该图像包含便携式身份证和与持卡人相关的其他信息。
目前，我只想裁剪掉身份证。
以前，我曾经以编程方式裁剪它，因为我从未想过可以更改身份证的位置。
图像如下所示：

我想裁剪底部的身份证区域。
正如我之前所说，身份证的位置、宽度和高度不是固定的。
现在我的主要问题是，我是否应该使用 ML 来实现这一点，这会不会有点过头了？
如果那么，我可以按照哪些步骤从此处的切口开始一直到底部来检测底部的 IDCard。我现在没有任何 ML 知识。
如果这确实是一种过度杀伤，那么检测卡的方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/66060711/custom-object-detection-in-javascript-or-ml</guid>
      <pubDate>Fri, 05 Feb 2021 09:26:52 GMT</pubDate>
    </item>
    </channel>
</rss>