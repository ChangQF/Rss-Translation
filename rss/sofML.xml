<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 14 Jun 2024 12:27:49 GMT</lastBuildDate>
    <item>
      <title>直接在 gpu 上加载并生成 Qwen2</title>
      <link>https://stackoverflow.com/questions/78622820/direct-loading-and-generation-qwen2-on-gpu</link>
      <description><![CDATA[我想在挖矿机上部署 LLM 模型 Qwen2-7b-instruct，但由于内存存储量低（4GB RAM）和处理能力有限（2 核奔腾）等限制，我无法做到这一点。
另一方面，我的电脑不支持 CUDA 和 ROCM 技术。
矿机规格：
4x amd rx580 8GB
到目前为止，我还没有找到这个问题的解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78622820/direct-loading-and-generation-qwen2-on-gpu</guid>
      <pubDate>Fri, 14 Jun 2024 11:58:01 GMT</pubDate>
    </item>
    <item>
      <title>在机器学习中，什么时候对数据进行欠采样/过采样</title>
      <link>https://stackoverflow.com/questions/78622628/at-what-point-do-you-undersample-oversample-data-in-machine-learning</link>
      <description><![CDATA[我有一个基本问题，关于在机器学习过程中何时应该对数据集进行欠采样或过采样。目前，我正在处理一个包含 NaN 值的不平衡数据集（约 5% 的阳性情况）。接下来的步骤应该如何衔接？这有一般规则吗？我应该填写缺失值，重新采样数据并继续删除异常值吗？

如能得到任何帮助，我将不胜感激。
我尝试寻找答案，但到目前为止还没有找到任何东西。我不知道正确的顺序是什么。]]></description>
      <guid>https://stackoverflow.com/questions/78622628/at-what-point-do-you-undersample-oversample-data-in-machine-learning</guid>
      <pubDate>Fri, 14 Jun 2024 11:13:18 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 中的 Essentia 模型无法预测</title>
      <link>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</link>
      <description><![CDATA[我正在尝试使用 Essentia discogs_track_embeddings-effnet-bs64 模型和 ML.NET 进行预测。我尝试过使用 tensorflow 和 onnx，但当我尝试预测任何东西时，我都遇到了问题
抛出异常：Microsoft.ML.Data.dll 中的“System.InvalidOperationException”
Microsoft.ML.Data.dll 中发生了未处理的“System.InvalidOperationException”类型的异常
拆分器/合并器工作程序在使用源数据时遇到异常

目前，我正在使用 onnx，因此其余部分将是该尝试的堆栈跟踪和代码。
完整调用堆栈：
 在 Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)
在 Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()
在 Microsoft.ML.Data.RootCursorBase.MoveNext()
在Microsoft.ML.Data.ColumnCursorExtensions.&lt;GetColumnArrayDirect&gt;d__4`1.MoveNext()
在 System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)
在 System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)
在 Program.&lt;Main&gt;$(String[] args) 中的 Program.cs:line 122

在行上：var embeddingColumn = perceivedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
onnx 加载和预测代码：
Console.WriteLine($&quot;[+] Loading Model&quot;);
var mlContext = new MLContext();

// 将 melspectrogram 数据加载到管道中
var modelPath = &quot;discogs_track_embeddings-effnet-bs64-1.onnx&quot;;
var pipeline = mlContext.Transforms.ApplyOnnxModel(
modelFile: modelPath,
fallbackToCpu: true
);
IDataView mockData = mlContext.Data.LoadFromEnumerable(new List&lt;ModelInput&gt;() { new ModelInput() });
var model = pipeline.Fit(mockData);

var schema = model.Transform(mockData).Schema;
Console.WriteLine(&quot;[*] Model Schema:&quot;);
foreach (var column in schema)
{
Console.WriteLine($&quot;Column Name: {column.Name}, Column Type: {column.Type}&quot;);
}

//PredictionEngine&lt;MelspectrogramData, OutputData&gt; predictionEngine = mlContext.Model.CreatePredictionEngine&lt;MelspectrogramData, OutputData&gt;(estimator);

//var predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput, ModelOutput&gt;(mo​​del);

List&lt;ModelOutput&gt; allPredictions = new List&lt;ModelOutput&gt;();

foreach (var fragment in melSpectrogram)
{
var seg = MelSpectrogramGenerator.ConvertToFloat(segment);
for (int i = 0; i &lt; seg.GetLength(0); i++)
{
for (int j = 0; j &lt; seg.GetLength(1); j++)
{
for (int k = 0; k &lt; seg.GetLength(2); k++)
{
// 用您的特定检查替换条件
if (double.IsNaN(seg[i, j, k]) || seg[i, j, k] == null)
{
Console.WriteLine($&quot;NaN found at ({i}, {j}, {k})&quot;);
}
}
}
var data = new ModelInput
{
Melspectrogram = seg
};
IDataView dataView = mlContext.Data.LoadFromEnumerable(new [] { data });
var perceivedData = model.Transform(dataView);

// 检索嵌入
var embeddingColumn = formedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
foreach (var value in embeddingColumn.First())
{
Console.Write($&quot;{value} &quot;);
}
//allPredictions.Add(scoredData.);
Console.WriteLine(&quot;Wheee&quot;);
}

public class ModelInput
{
[VectorType(64, 128, 96)]
[ColumnName(&quot;melspectrogram&quot;)]
public float[,,] Melspectrogram { get; set; }
public ModelInput()
{
Melspectrogram = new float[64, 128, 96];
}
}

// 定义输出模式
public class ModelOutput
{
[VectorType(64, 512)]
[ColumnName(&quot;embeddings&quot;)]
public float[,] Embeddings { get; set; }
public ModelOutput()
{
Embeddings = new float[64, 512];
}
}

目前在 Microsoft.ML 3.0.1、Microsoft.ML.OnnxRuntime.Managed 1.18.0 上
我检查过，我的数据中没有 NaN，而且我的变量都不是 Null。我非常迷茫，不知道如何修复这个问题，甚至不知道如何继续进行故障排除。]]></description>
      <guid>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</guid>
      <pubDate>Fri, 14 Jun 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>孪生网络是否可以通过修改架构用于感知散列？[关闭]</title>
      <link>https://stackoverflow.com/questions/78621922/can-siamese-network-be-used-for-perceptual-hashing-by-modifying-the-architecture</link>
      <description><![CDATA[我读到 Siamese 网络用于图像比较。这让我想知道，通过修改经过适当定制训练的 Siamese 网络，我们能否对大规模 CBIR 系统执行感知哈希处理？]]></description>
      <guid>https://stackoverflow.com/questions/78621922/can-siamese-network-be-used-for-perceptual-hashing-by-modifying-the-architecture</guid>
      <pubDate>Fri, 14 Jun 2024 08:44:34 GMT</pubDate>
    </item>
    <item>
      <title>如何正确修改跳数大小以解决执行 python 模块时出现的断言错误？</title>
      <link>https://stackoverflow.com/questions/78621817/how-do-i-properly-modify-the-hop-size-to-resolve-the-assertion-error-when-execut</link>
      <description><![CDATA[当我运行 aisfx.inference.main(&quot;/home/Debian/Desktop/Audio Pre&quot;, &quot;/home/Debian/Desktop/Audio Post&quot;) 时，模块加载了 27%，当跳跃大小有问题时，会触发 AssertionError。
供参考：

Github 链接：https://github.com/alisonbma/aiSFX
教程链接：https://aisfx.readthedocs.io/en/latest/notebooks/tutorial.html

我期望模块能够 100% 运行且无错误，并对我的音频文件进行排序。
这是我正在查看的内容：
aisfx.inference.main(&quot;/home/Debian/Desktop/Audio Pre&quot;, &quot;/home/Debian/Desktop/Audio Post&quot;)
CPU 或 CUDA：cuda
27%|██████████████████████████████████▍ | 97/365 [00:04&lt;00:13, 19.87it/s]
回溯（最近一次调用）：
文件 &lt;stdin&gt;&gt;，第 1 行，位于 &lt;module&gt;
文件 &quot;/home/Debian/anaconda3/envs/sfx/lib/python3.11/site-packages/aisfx/inference.py&quot;，第 159 行，在 main 中
embedding = model_get_embedding(spec,
^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/home/Debian/anaconda3/envs/sfx/lib/python3.11/site-packages/aisfx/inference.py&quot;，第 97 行，在 model_get_embedding 中
hop_size=compute_hopSize(EMB_BLOCK_LENGTH, emb_hop_size, spec),
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件&quot;/home/Debian/anaconda3/envs/sfx/lib/python3.11/site-packages/aisfx/preprocessing.py&quot;，第 20 行，在 compute_hopSize
assert(hop_size &lt; data.shape[0])
^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError

我的假设是跳跃大小导致了错误，在教程中，他们提到修改 inference.py 文件中的跳跃大小。我尝试将其更改为；0.01、0.001、1.0、5.0、10.0 和 20.0。所有结果都相同 AssertionError。作为参考，有问题的音频文件范围从 3 秒到 39 秒。]]></description>
      <guid>https://stackoverflow.com/questions/78621817/how-do-i-properly-modify-the-hop-size-to-resolve-the-assertion-error-when-execut</guid>
      <pubDate>Fri, 14 Jun 2024 08:19:36 GMT</pubDate>
    </item>
    <item>
      <title>在 tfjs tensorflow.js 中设置残差神经网络块</title>
      <link>https://stackoverflow.com/questions/78621757/setup-a-residual-neural-network-block-in-tfjs-tensorflow-js</link>
      <description><![CDATA[我正在尝试在 tensorflow.js 中实现 ResNet（残差神经网络）的行为。我希望知道他们在做什么的人能给我指明正确的方向。以下代码是否会有效地将第 3、4、5 层变成残差块？更具体地说，我包含的连接层是否像文献中描述的身份跳过连接一样起作用？TFJS 是否自动知道如何通过连接层传递反向传播信号？
 const density_layer_1 = TENSORFLOW.layers.dense({ unit: 1600,activation: &quot;relu&quot;, useBias: true }).apply(input);
const density_layer_2 = TENSORFLOW.layers.dense({ unit: 800,activation: &quot;relu&quot;, useBias: true }).apply(dense_layer_1);
const density_layer_3 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_2);
const density_layer_4 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_3);
const density_layer_5 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_4);
const density_layer_6 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_5);
const concat_layer1 = TENSORFLOW.layers.concatenate().apply([dense_layer_2, density_layer_6]);
const density_layer_7 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(concat_layer1);
const density_layer_8 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_7);
const output = TENSORFLOW.layers.dense({ 单位：1，激活：“线性”，useBias：true }).apply(dense_layer_8);
const residual_model = TENSORFLOW.model({ 输入：输入，输出：输出 });```
]]></description>
      <guid>https://stackoverflow.com/questions/78621757/setup-a-residual-neural-network-block-in-tfjs-tensorflow-js</guid>
      <pubDate>Fri, 14 Jun 2024 08:03:45 GMT</pubDate>
    </item>
    <item>
      <title>Vitas AI(Pytorch)：在模型量化期间出现错误 - AttributeError：无法设置属性</title>
      <link>https://stackoverflow.com/questions/78621742/vitas-aipytorch-getting-error-attributeerror-cant-set-attribute-during-q</link>
      <description><![CDATA[我有一个 Python 版的 LSTM 模型，我正在尝试使用 Vitis AI (Pytorch) 将其部署到 ZCU104 板上。我在量化模型时遇到错误。我收到以下行的错误：
quantizer.export_xmodel(output_dir=&quot;quantize_result&quot;, deploy_check=True)
错误是：
[VAIQ_NOTE]: =&gt;Converting to xmodel ...

回溯（最近一次调用最后一次）：

文件“lstm_quant.py”，第 118 行，位于 &lt;module&gt;

main(args)

文件“lstm_quant.py”，第 107 行，在 main 中

quantizer.export_xmodel(output_dir=“quantize_result”，deploy_check=True)

文件“/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/apis.py”，第 148 行，在 export_xmodel 中

self.processor.export_xmodel(output_dir, deploy_check, dynamic_batch)

文件“/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/base.py”，第 368 行，在 export_xmodel 中

dump_xmodel(output_dir, deploy_check, self._lstm_app)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/base.py&quot;，第 505 行，位于 dump_xmodel

deploy_graphs, _ = get_deploy_graph_list(quantizer.quant_model, quantizer.Nndctgraph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/utils.py&quot;，第 463 行，位于 get_deploy_graph_list

return _deploy_optimize(quant_model, nndct_graph, need_pa​​rtition)

文件&quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/utils.py&quot;，第 419 行，在 _deploy_optimize

g_optmizer = DevGraphOptimizer(nndct_graph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/compile/deploy_optimizer.py&quot;，第 92 行，在 __init__

self._dev_graph.clone_from(nndct_graph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_graph.py&quot;，第133，在 clone_from 中

self._top_block.clone_from(src_graph.block, local_map, converted_nodes)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_block.py&quot;，第 47 行，在 clone_from 中

self.append_node(self.owning_graph.create_node_from(node, local_map, converted_nodes))

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_graph.py&quot;，第 161 行，在 create_node_from 中

node.clone_from(src_node, local_map)

文件&quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_node.py&quot;，第 120 行，在 clone_from 中

self.op.clone_from(src_node.op, local_map)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_operator.py&quot;，第 214 行，在 clone_from 中

setattr(self, config, new_value)

AttributeError：无法设置属性

在以下 Google 链接中附加完整错误、模型代码和量化脚本：
量化脚本：
https://docs.google.com/document/d/1jRYmPH2z70ovpc_FJIBpUQaTHUPRrTgnPVxlQJ1JLug/edit?usp=sharing
模型脚本：
https://docs.google.com/document/d/1OBZw4XhdHpVhA0gKcJn2NzR_WA7ZczQ3hL42f_sMKug/edit?usp=sharing
完整错误：
https://docs.google.com/document/d/1kI1WJqq9pp3aSsGLpNGjf22mzK6swIiZbIXwfUeTGto/edit?usp=sharing
尝试更改 base_operator.py，但没有成功。也尝试简化模型，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78621742/vitas-aipytorch-getting-error-attributeerror-cant-set-attribute-during-q</guid>
      <pubDate>Fri, 14 Jun 2024 08:00:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 pandas 数据框中的 lambda 函数在列之间执行多项计算</title>
      <link>https://stackoverflow.com/questions/78621386/perform-multiple-calculations-among-columns-using-lambda-function-in-pandas-data</link>
      <description><![CDATA[我有一个包含多列的数据框。有一列名为“remaining_lease”，其中 75% 为 Nan。我不想删除该列。因此，我想使用另外两列“lease_commense_date”和“current_year”来计算“remaining_lease”。公式如下：
remaining_lease = 99 - ( current_year - lease_commense_date)
例如： current_year = 2022 和 lease_commense_date = 1979
然后 remaining_lease = 99 - (2022 - 1979) = 56
我编写了一个函数来执行此操作。
def remaining_lease_year(x, current_year, commense_year):
if math.isnan(x): # 如果值为 nan
lease_year = 99 - (current_year - commense_year)
return lease_year
else: #如果值不是 nan
return x

df[&#39;remaining_lease&#39;] = df[&#39;remaining_lease&#39;].apply(lambda x: remaining_lease_year(x, df[&#39;current_year&#39;], df[&#39;lease_commence_date&#39;]))

但是我收到错误：
MemoryError：无法为形状为 (927465,) 且数据类型为 int64 的数组分配 7.08 MiB
还有其他方法可以实现吗？如能提供帮助，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78621386/perform-multiple-calculations-among-columns-using-lambda-function-in-pandas-data</guid>
      <pubDate>Fri, 14 Jun 2024 06:33:10 GMT</pubDate>
    </item>
    <item>
      <title>未找到 keras.utils.PyDataset</title>
      <link>https://stackoverflow.com/questions/78621236/keras-utils-pydataset-not-found</link>
      <description><![CDATA[class BatchedDataset(tf.keras.utils.PyDataSet):
使用 keras PyDataset 时，我不断收到此错误。我尝试更新 tensorflow 并使用 tf.keras.api._v2。这些都不起作用
我正在使用 google colab
]]></description>
      <guid>https://stackoverflow.com/questions/78621236/keras-utils-pydataset-not-found</guid>
      <pubDate>Fri, 14 Jun 2024 05:43:38 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯优化中的探索与利用权衡</title>
      <link>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</link>
      <description><![CDATA[最近我一直在研究贝叶斯优化，但有些东西我不太明白。我知道 BO 使用获取函数来平衡探索和利用。我们可以添加一个参数（epsilon）来调整我们想要更多的探索还是利用。但参数是如何做到的？与 PI 和 EI 获取函数一样，为什么较大的 epsilon 可以使算法更具探索性，反之亦然？]]></description>
      <guid>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</guid>
      <pubDate>Fri, 14 Jun 2024 04:07:57 GMT</pubDate>
    </item>
    <item>
      <title>该数据集需要进行哪些预处理？[关闭]</title>
      <link>https://stackoverflow.com/questions/78620975/which-are-the-preprocessing-required-on-this-dataset</link>
      <description><![CDATA[数据集链接：- https://www.kaggle.com/datasets/nijpadariya/cardiovascular-disease/data
笔记本链接：- https://colab.research.google.com/drive/1h8wa2yUGQJMyZcoifgD-5PsG6XvyvlB2?usp=sharing
上面的笔记本代表了我迄今为止在数据集上所做的工作
因为我必须使用这个数据集，但我不知道我可以显示什么，也不知道这些数据需要哪些预处理步骤，以及如何使用属性来显示一些结果。
有人能帮我找到吗？
有什么帮助可以找到数据集上的结果和预处理步骤所需的]]></description>
      <guid>https://stackoverflow.com/questions/78620975/which-are-the-preprocessing-required-on-this-dataset</guid>
      <pubDate>Fri, 14 Jun 2024 04:01:34 GMT</pubDate>
    </item>
    <item>
      <title>pytorch PascalVOC 数据集中的数据加载器错误：RuntimeError：批次列表中的每个元素应大小相同</title>
      <link>https://stackoverflow.com/questions/78620402/dataloader-error-in-pytorch-pascalvoc-dataset-runtimeerror-each-element-in-lis</link>
      <description><![CDATA[尝试实现时，其中一个步骤是将每幅图像的大小调整为 (448, 448)。但即使应用了转换，Dataloader 也会抛出有关数据集大小差异的异常。
确切的错误消息：“RuntimeError：批次列表中的每个元素应大小相同”
from torchvision import datasets
from torchvision.transforms import v2, ToTensor

from torch.utils.data import DataLoader

validation_data = datasets.voc.VOCDetection(
root=&#39;.DATA/&#39;,
download=False,
image_set=&quot;val&quot;,
transform=v2.Compose([ v2.Resize(size=(448, 448)), ToTensor() ])
)

batch_size = 64

validation_dataloader = DataLoader(validation_data, batch_size=batch_size)

for X, y in validation_dataloader:
print(f&quot;Shape X [N, C, H, W] 的：{X.shape}&quot;)
break
]]></description>
      <guid>https://stackoverflow.com/questions/78620402/dataloader-error-in-pytorch-pascalvoc-dataset-runtimeerror-each-element-in-lis</guid>
      <pubDate>Thu, 13 Jun 2024 22:43:49 GMT</pubDate>
    </item>
    <item>
      <title>如何按照物体在最顶层的顺序检测和识别它们，然后对它们进行分层并为它们分配 ID？</title>
      <link>https://stackoverflow.com/questions/78605533/how-to-detect-and-identify-objects-in-the-order-that-they-are-on-top-then-layer</link>
      <description><![CDATA[
我尝试过过滤掉它们的线条，现在该如何确定哪个物体被隐藏了
我也尝试过使用 yoloV8 来过滤物体，但仍然无法确定哪个物体被另一个物体遮挡了，有人能帮我吗？
CODE:
import cv2
import numpy as np

# 加载图像 + mask、灰度、高斯模糊、Otsu 阈值
image = cv2.imread(&quot;./anhtest/11.png&quot;) # 这是原始图像
original = image.copy()
mask = cv2.imread(&quot;./anhtest/11.png&quot;) # 这是从 U-2-Net 生成的掩码
gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
bg_removed = cv2.bitwise_and(image, image, mask=thresh)

# HSV 颜色阈值
hsv = cv2.cvtColor(bg_removed, cv2.COLOR_BGR2HSV)
lower = np.array([0, 0, 0])
upper = np.array([179, 33, 255])
hsv_mask = cv2.inRange(hsv, lower, upper)
isolated = cv2.bitwise_and(bg_removed, bg_removed, mask=hsv_mask)
isolated = cv2.cvtColor(isolated, cv2.COLOR_BGR2GRAY)
isolated = cv2.threshold(isolated, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

# 变形操作以去除小伪影和噪音
open_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
opening = cv2.morphologyEx(isolated, cv2.MORPH_OPEN, open_kernel, iterations=1)
close_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
close = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, close_kernel, iterations=1)

# 查找轮廓并按最大轮廓面积排序
cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
for c in cnts:
cv2.drawContours(original, [c], -1, (36,255,12), 3)
break

cv2.imshow(&quot;bg_removed&quot;, bg_removed)
cv2.imshow(&quot;hsv_mask&quot;, hsv_mask)
cv2.imshow(&#39;isolated&#39;,isolated)
cv2.imshow(&#39;original&#39;,original)
cv2.waitKey()
]]></description>
      <guid>https://stackoverflow.com/questions/78605533/how-to-detect-and-identify-objects-in-the-order-that-they-are-on-top-then-layer</guid>
      <pubDate>Tue, 11 Jun 2024 05:23:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Pytorch 中手动对某一层的输出进行反量化，并为下一层重新量化？</title>
      <link>https://stackoverflow.com/questions/78239906/how-to-manually-dequantize-the-output-of-a-layer-and-requantize-it-for-the-next</link>
      <description><![CDATA[我正在做一个学校项目，需要我对模型的每一层进行手动量化。具体来说，我想手动实现：

量化激活，结合量化权重 A - 层 A -
量化输出 - 去量化输出 - 重新量化输出，结合量化权重 B - 层 B - ...

我知道 Pytorch 已经有一个量化函数，但该函数仅限于 int8。我想执行从 bit = 16 到 bit = 2 的量化，然后比较它们的准确性。
我遇到的问题是，量化后，层的输出大了几个量级（bit = 16），我不知道如何将其去量化。我正在使用激活和权重的相同最小值和最大值执行量化。因此，这里有一个例子：
激活 = [1,2,3,4]
权重 = [5,6,7,8]
激活和权重的最小值和最大值 = 1, 8
预期的非量化输出 = 70

使用位量化 = 16
量化激活 = [-32768, -23406, -14044, -4681]
量化权重 = [4681, 14043, 23405, 32767]
量化输出 = -964159613
使用最小值 = 1、最大值 = 8 反量化输出 = -102980

这个计算对我来说很有意义，因为输出涉及激活和权重的乘积，它们的幅度增加也相乘。如果我使用原始的最小值和最大值执行一次反量化，则输出会大得多，这是合理的。
Pytorch 如何处理反量化？我试图找到 Pytorch 的量化，但找不到它。如何对输出进行反量化？]]></description>
      <guid>https://stackoverflow.com/questions/78239906/how-to-manually-dequantize-the-output-of-a-layer-and-requantize-it-for-the-next</guid>
      <pubDate>Thu, 28 Mar 2024 17:17:53 GMT</pubDate>
    </item>
    <item>
      <title>我的模型具有较高的准确率和 val_accuracy，但在测试数据上给出了错误的结果</title>
      <link>https://stackoverflow.com/questions/56696906/my-model-has-high-accuracy-and-val-accuracy-but-giving-wrong-result-on-test-data</link>
      <description><![CDATA[我使用 opencv 创建了一些图像，并在其上运行深度神经网络分类器。
它给出了大约 97% 的准确率和 95% 的 val_accuracy，但当我测试它时，它给出了错误的预测。
这是我创建图像的代码。
import cv2
import numpy as np
import random
import os
size = 64

def circle(i,d):
img = np.zeros(shape=(size,size,3))
point = (random.randint(1,size),random.randint(1,size))
img = cv2.circle(img,point,random.randint(1,size),(255,255,0),thickness=2,lineType=8)

if not os.path.exists(d+&quot;/circle&quot;):
os.makedirs(d+&quot;/circle&quot;)
cv2.imwrite(d+&quot;/circle/&quot;+str(i)+&quot;circle.png&quot;,img)
#print(&quot;创建了圆圈&quot;+str(i))

def rectangle(i,d):
img = np.zeros(shape=(size,size,3))
point = (random.randint(1,size),random.randint(1,size))
w = random.randint(1,size);
h = random.randint(1,size);
point2 = (point[0] + w,point[1]+h)
img = cv2.rectangle(img,point,point2,(255, 255, 0), 2)
if not os.path.exists(d+&quot;/react&quot;):
os.makedirs(d+&quot;/react&quot;)
cv2.imwrite(d+&quot;/react/&quot;+str(i)+&quot;react.png&quot;,img)
#print(&quot;created reactangle&quot;+str(i))

def traingle(i,d):
img = np.zeros(shape=(size,size,3))
point1 = (random.randint(1,size),random.randint(1,size))
point2 = (random.randint(1,size),random.randint(1,size))
point3 = (random.randint(1,size),random.randint(1,size))

img = cv2.line(img,point1,point2,(255, 255, 0), 2)
img = cv2.line(img,point2,point3,(255, 255, 0), 2)
img = cv2.line(img,point3,point1,(255, 255, 0), 2)
if not os.path.exists(d+&quot;/tra&quot;):
os.makedirs(d+&quot;/tra&quot;)
cv2.imwrite(d+&quot;/tra/&quot;+str(i)+&quot;tra.png&quot;,img)
#print(&quot;created trangle&quot;+str(i))

if not os.path.exists(&quot;data_train&quot;):
os.makedirs(&#39;data_train&#39;)
for i in range(1,2000):
circle(i,&quot;data_train&quot;)
rectangle(i,&quot;data_train&quot;)
traingle(i,&quot;data_train&quot;)
print(&quot;已创建测试数据&quot;) 
if not os.path.exists(&quot;data_test&quot;):
os.makedirs(&#39;data_test&#39;)
for i in range(1,500):
circle(i,&quot;data_test&quot;)
rectangle(i,&quot;data_test&quot;)
traingle(i,&quot;data_test&quot;)

这是我的分类代码。
# 导入库 
from keras.preprocessing.image import ImageDataGenerator 
from keras.models import Sequential 
from keras.layers import MaxPooling2D,Dropout, Convolution2D
from keras.layers import Flatten, Dense 
from keras import backend as K 

img_width, img_height = 64, 64

train_data_dir = &#39;data_train&#39;
validation_data_dir = &#39;data_test&#39;
nb_train_samples = 5997
nb_validation_samples = 1497
epochs = 3
batch_size = 15

如果 K.image_data_format() == &#39;channels_first&#39;: 
input_shape = (3, img_width, img_height) 
否则: 
input_shape = (img_width, img_height, 3) 
model = Sequential() 

model.add(Convolution2D(32, 3, 3, input_shape = input_shape,activation=&quot;relu&quot;)) 
model.add(MaxPooling2D(pool_size =(2, 2))) 

model.add(Convolution2D(32, 3, 3,activation=&quot;relu&quot;)) 
model.add(MaxPooling2D(pool_size =(2, 2))) 

model.add(Flatten())
model.add(Dropout(0.2)) 
model.add(Dense(output_dim=180,activation=&quot;relu&quot;)) 
model.add(Dropout(0.2)) 
model.add(Dense(3,activation=&quot;softmax&quot;)) 

model.compile(loss =&#39;categorical_crossentropy&#39;, 
optimizer =&#39;adam&#39;, 
metrics =[&#39;categorical_accuracy&#39;]) 

train_datagen = ImageDataGenerator( 
rescale = 1. / 255, 
sher_range = 0.2, 
zoom_range = 0.2, 
Horizo​​ntal_flip = False) 

test_datagen = ImageDataGenerator(rescale = 1. / 255) 

train_generator = train_datagen.flow_from_directory(train_data_dir, 
target_size =(img_width, img_height), 
batch_size = batch_size, class_mode =&#39;categorical&#39;) 

validation_generator = test_datagen.flow_from_directory( 
validation_data_dir, 
target_size =(img_width, img_height), 
batch_size = batch_size, class_mode =&#39;categorical&#39;) 

model.fit_generator(train_generator, 
steps_per_epoch = nb_train_samples, 
epochs = epochs, validation_data = validation_generator, 
validation_steps = nb_validation_samples) 

我尝试过 
1. 更改隐藏层的数量
2. 在最终层之前和第一层之后添加 dropout 层。
2. 添加 conv 层。
请告诉我我做错了什么。
提前谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/56696906/my-model-has-high-accuracy-and-val-accuracy-but-giving-wrong-result-on-test-data</guid>
      <pubDate>Fri, 21 Jun 2019 04:36:34 GMT</pubDate>
    </item>
    </channel>
</rss>