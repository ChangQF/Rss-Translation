<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Tue, 11 Mar 2025 18:25:47 GMT</lastBuildDate>
    <item>
      <title>如何在梯度下降线性回归中减轻高MAE/MSE？</title>
      <link>https://stackoverflow.com/questions/79501719/how-to-mitigate-high-mae-mse-in-gradient-descent-linear-regression</link>
      <description><![CDATA[我正在通过从头开始实现机器学习算法。从基础知识开始，我正在研究线性回归。但是，我面临模型性能的问题。鉴于数据集的简单性，我希望该模型可以密切预测输出，旨在MAE/MSE小于1。。
这是我目前的结果：
  [[[29.76307389]]＃重量
MAE：11.860197526386747
MSE：[320.16732974]
RMSE：[17.89322022]
 
我的问题是：如何减轻高成本功能？这是数据扩展问题（我认为不是）吗？我在代码逻辑中看不到任何缺陷。

我的实现：
 导入numpy作为NP
从sklearn.datasets导入make_regression
来自sklearn.model_selection导入train_test_split

班级体重：

    def __init __（self，n_features：int）：
        self.lim = 1 / np.sqrt（n_features）
        self.n_features = n_features
        self.seed = 42
        np.random.seed（self.seed）

    def Random_uniform（self）：
        返回np.random.uniform（-self.lim，self.lim，（self.n_features，1））

班级回归：
    def __init __（self，n_iter：int，l_rate：float）：
        self.n_iter = n_iter
        self.l_rate = l_rate
        self.w =无
        self.b = 0
        self.Error = 0

    def预测（self，x）：
        返回np.dot（x，self.w） + self.b

    def fit（self，x，y，reg_factor：str = none）：
        n_samples，n_features = x。形状
        如果self.w是无：＃持续权重
            self.w = strige（n_features）.random_rand（）
        y = np.Reshape（y，（-1，1））＃将数组转换为列向量
        正则化= self.regularize（）

        对于_范围（self.n_iter）：
            y_pred = self.predict（x）
            self.error = y -y__pred
            grad_w =（-2 * np.dot（x.t，self.error） / n_samples） 
            grad_b =（-2 * np.sum（self.error）） / n_samples
            self.w-- = self.l_rate * grad_w＃l_rate *（grad_w +正则化_factor）
            self.b- = self.l_rate * grad_b＃l_rate * grad_b


类线性回归（回归）：
    def __init __（self，n_iter：int，l_rate：float）：
        super（）.__ init __（n_iter，l_rate）

    def渐变发达（self，x，y）：
        super（）。拟合（x，y）

类评估对：
    def __init __（self，n：int，y，y_pred）：
        self.n = n
        self.y = np.Reshape（y，（-1，1））＃实际值
        self.y_pred = y_pred＃预测值

    Def Mae（自我）：
        返回np.mean（np.abs（self.y -self.y_pred））
    Def MSE（自我）：
        返回总和（np.pow（（（self.y -self.y_pred），2）） / self.n
    def rmse（self）：
        返回np.sqrt（sum（np.pow（（（self.y -y -self.y_pred）），2）） / self.n）

x，y = make_regression（n_samples = 1000，n_features = 1，噪声= 15，Random_state = 4）

    x_train，x_test，y_train，y_test = train_test_split（
        X，Y，test_size = 0.4，Random_State = 42
    ）

    LR =线性重试（1000，0.01）
    lr.gradientdescent（x_train，y_train）
    lr.printweights（）
    y_pred = lr.predict（x_train）

    mae = essalmetrics（n = x_train.shape [0]，y = y_train，y_pred = y_pred）.mae（）
    打印（f＆quot; mae：{mae}＆quot;）
    MSE = essutuationMetrics（n = x_test.shape [0]，y = y_train，y_pred = y_pred）.mse（）
    打印（MSE：{MSE}＆quot;）
    rmse = evaluationMetrics（n = x_test.shape [0]，y = y_train，y_pred = y_pred）.rmse（）
    打印（f＆quot&#39;rmse：{rmse}＆quot;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79501719/how-to-mitigate-high-mae-mse-in-gradient-descent-linear-regression</guid>
      <pubDate>Tue, 11 Mar 2025 18:00:42 GMT</pubDate>
    </item>
    <item>
      <title>有关机器学习模型上等渗回归的适用性的问题</title>
      <link>https://stackoverflow.com/questions/79501560/question-about-suitability-of-isotonic-regression-on-machine-learning-models</link>
      <description><![CDATA[我知道等渗回归是一种很好的校准方法，尤其是对于单调增加的关系而言。我的数据集具有多个功能，结果是二进制的。我正在该数据集培训机器学习模型，并预测概率。我想校准预测的概率，但是我不确定等渗回归是否是一个不错的选择，因为数量超过10个，结果是二进制的，而不是连续的。校准方法适合这种情况吗？]]></description>
      <guid>https://stackoverflow.com/questions/79501560/question-about-suitability-of-isotonic-regression-on-machine-learning-models</guid>
      <pubDate>Tue, 11 Mar 2025 17:01:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Python SDK将环境变量传递到亚马逊萨吉式制造商的自定义培训脚本？</title>
      <link>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</link>
      <description><![CDATA[我正在使用Amazon Sagemaker中的脚本进行自定义模型，并使用Python SDK启动这项工作。我想将一些环境变量（例如API键或配置标志）传递到培训作业，以便通过OS.Environ在脚本中访问它们。
这是我的代码的简化版本：
 来自sagemaker.stimator导入估算器

估算器=估算器（
    image_uri =&#39;123456789012.dkr.ecr.us-west-2.amazonaws.com/my-custom-image：最新图像&#39;，
    角色=角色，
    instance_count = 1，
    instance_type =&#39;ml.g5.xlarge&#39;，
    entry_point =&#39;train.py&#39;，
    source_dir =&#39;src&#39;，
    环境= {
        &#39;my_api_key&#39;：&#39;abcdef123456&#39;，
        &#39;debug_mode&#39;：&#39;true&#39;
    }
）
 
在我的培训脚本中，我尝试读取变量：
 导入OS

api_key = os.environ.get（&#39;my_api_key&#39;）
打印（＆quot; api键：＆quot; api_key）
 
这是使用Python SDK将环境变量传递给萨吉人培训工作的正确方法吗？我应该注意任何局限性或最佳实践，特别是对于诸如API键之类的敏感信息？]]></description>
      <guid>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</guid>
      <pubDate>Tue, 11 Mar 2025 10:00:30 GMT</pubDate>
    </item>
    <item>
      <title>当我试图运行命令spartlit运行main.py时，为什么我会得到RuntimeError：没有运行事件循环，并且在我的VS代码中？</title>
      <link>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</guid>
      <pubDate>Tue, 11 Mar 2025 09:34:06 GMT</pubDate>
    </item>
    <item>
      <title>如何删除具有不同文件名和大小但在Android中相同的内容的重复图像？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79499987/how-to-delete-duplicate-images-with-different-file-names-and-sizes-but-identical</link>
      <description><![CDATA[我在我的Android设备上有大量从iPhone传输的图像。不幸的是，我现在有许多重复的图像：

没有相同的文件名。
没有相同的文件大小或分辨率。
但包含相同的视觉内容（相同图像）。

我想根据其内容查找并删除这些重复的图像（不是基于文件名，大小或分辨率）。
我尝试通过Google App搜索文件中的内置选项，但找不到根据内容检测重复图像的任何选项。
是否有任何可以根据内容扫描和删除重复图像的Android应用程序或工具？另外，我可以使用任何Python脚本或开源工具来实现这一目标吗？我的目标是自动删除所有具有相同内容的重复图像，无论其文件名，大小或分辨率如何。]]></description>
      <guid>https://stackoverflow.com/questions/79499987/how-to-delete-duplicate-images-with-different-file-names-and-sizes-but-identical</guid>
      <pubDate>Tue, 11 Mar 2025 07:53:05 GMT</pubDate>
    </item>
    <item>
      <title>如何实现具有有限数据和较大姿势/样式变化的强大动漫角色搜索系统？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79499907/how-to-implement-a-robust-anime-character-search-system-with-limited-data-and-la</link>
      <description><![CDATA[我正在努力实施“动漫角色搜索”系统，我非常感谢您可能拥有的任何建议或参考。
使用经典的计算机视觉技术检测动漫图像是相对简单的。例如，一个众所周知的示例是Trace.Moe，它使用Lucene Image Search（LIRE）和其他传统方法准确地指出了给定屏幕截图的动漫剧集和时间戳。这种方法不一定依靠现代深度学习。它仅根据旧视觉算法使用特征提取。
然而，随着AI的兴起，许多人开始使用CNN，VIT或其他深度学习模型（通常来自拥抱面）进行图像特征提取和基于向量的搜索。在我自己的设置中，如果目标动漫角色图像已经索引，我可以达到100％的准确性（即使没有高级矢量数据库（例如基于HNSW的解决方案）），因为系统很容易检索相同或近乎功能的匹配。  
核心问题是，动漫角色的嵌入可能对姿势或样式的轻微变化也极为敏感。如果角色仅移动位置，则嵌入空间中的距离可能会飙升。我尝试通过对比度学习解决这个问题（特别是2022年左右的对比度方法），但到目前为止，结果一直不足。 
一个很大的挑战是数据集本身的性质：有很多字符标签，但每个字符相对较少，样式差异很大。有时，给定角色只有一个参考图像。当只有一两个图像开始时，典型的增强方法无济于事。我考虑使用ControlNet或类似技术生成更多图像来模拟不同的姿势和观点，但是由于参考图像，GAN或扩散模型很少，因此难以产生高质量的一致变化。
我还研究了诸如佛罗伦萨，dinov2和剪辑之类的自动接地方法，以解析或分割图像，然后尝试统一共享功能，但我不确定实践中的效果如何。总的来说，我感到卡住了。该域与标准图像搜索有所不同，因为数据有限，变化很大，即使在完全不同的姿势或艺术风格下，系统也需要识别相同的字符。
即使刮擦Kaggle和其他来源也只能产生几十万张图像，这远远不够覆盖那里的各种动漫角色。数据收集本身是一个巨大的挑战。
你们中有人处理类似问题吗？您是否知道建立强大的动漫角色搜索系统的最佳实践或相关参考，尤其是在此类数据筛选条件下？您有任何指针或建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/79499907/how-to-implement-a-robust-anime-character-search-system-with-limited-data-and-la</guid>
      <pubDate>Tue, 11 Mar 2025 07:11:13 GMT</pubDate>
    </item>
    <item>
      <title>与拆分数量少的类交叉验证的错误[关闭]</title>
      <link>https://stackoverflow.com/questions/79499678/error-on-crossvalidation-with-classes-that-have-less-samples-than-number-of-spli</link>
      <description><![CDATA[我目前正在研究这个问题：
 https://github.com/scikit-com/scikit-learn/scikit-learn/scikit-learn/scikit-learn/scikit-learn/issues/30832  
我正在研究修复它的可能方法。
说明：
使用logistic回归和交叉验证时，在交叉验证时，样本少于拆分数量的类别少于每倍的样本，导致执行Python程序时出现错误。
即使这可能是一个数据问题，也应该有更好的方法来处理它。
复制错误的代码：
 来自sklearn.linear_model导入logisticRegressioncv
导入numpy作为NP
n，m = 20，5
x = np.random.randn（n，m）
y = np.random.randint（0，2，n）
y [-3：] = [3，4，5]
logisticRegressioncv（）。fit（x，y）
 
我想到的一些方法：

将系数设置为代表性不足的类中的0; 
根据我们拥有的真实数据自动创建新数据（即使仅是1个示例）; 
重复数据，直到最低样本的类达到分裂次数； 
简单地提出一个更有意义的例外。

这只是一个数据问题，我应该提出一个例外，还是我可以在这里做更多的事情？
您能给我一些有关解决此问题的好方法的提示或想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79499678/error-on-crossvalidation-with-classes-that-have-less-samples-than-number-of-spli</guid>
      <pubDate>Tue, 11 Mar 2025 04:44:50 GMT</pubDate>
    </item>
    <item>
      <title>我可以将Pytorch与Django Web框架集成在一起吗？</title>
      <link>https://stackoverflow.com/questions/79499340/can-i-integrate-pytorch-with-django-web-framework</link>
      <description><![CDATA[我希望使用Django在网站上创建一些游戏。我想对游戏进行一些机器学习，以便玩家可以与机器学习模型进行比赛。 Django和Pytorch的结合是否可以？我听说了一些称为ONNX的东西，可以帮助将模型提供到前端，我只是想仔细检查与Django一起使用的，而不仅仅是与Nodejs一起使用。如果它不起作用，那么我会感谢任何其他解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/79499340/can-i-integrate-pytorch-with-django-web-framework</guid>
      <pubDate>Mon, 10 Mar 2025 23:06:51 GMT</pubDate>
    </item>
    <item>
      <title>生成partialdependedateata函数在用于多类分类模型时返回错误</title>
      <link>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</link>
      <description><![CDATA[我已经使用MLR构建了XGBoost多类分类模型，我想为某些功能可视化部分依赖性。但是，如果我尝试使用 generatePartialDependedAta（）我会收到以下错误：

 Melt.data.table中的错误（AS.Data.table（OUT），MEATH.VARS = target，variable.name = if（td $ type ===：&#39;METAY.VARS&#39;中的一个或多个值无效。

我已经检查了 task.desc 在 task&gt; task 对象和 factor.levels.levels.levels 中的差异。此外，我毫不费力地使用相同的函数生成具有不同目标变量的回归XGBoost的数据。
我的目的是有问题，还是这是一个错误？
这是使用 palmerpenguins 数据集的示例：
 ＃库
图书馆（整洁）
图书馆（MLR）

Peng＆lt;  -  Palmerpenguins ::企鹅

＃数据分区
set.seed（1234）
Intrain＆lt ;-创建Atapartition（
  y =彭$种，
  p = 0.7，
  列表= f
）

＃构建任务
train_class＆lt;  -  peng [intrain，]％＆gt;％select（-sex，-year）％＆gt;％ 
  CreateMummyFeatures（target =;物种＆quots; cols =;岛; 
  makeClassIftask（data =。，target =;物种；）

＃建立学习者
xgb_class_learner＆lt;  -  makelearner（
  ＆quot“ classif.xgboost”
  predict.type =&#39;响应;
）

＃构建模型
XGB_CLASS＆lt;  - 火车（XGB_CLASS_LEARNER，TRAIN_CLASS）

＃产生部分依赖性
GeneratePartialDependedateData（XGB_Class，Train_class）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</guid>
      <pubDate>Mon, 10 Mar 2025 18:27:01 GMT</pubDate>
    </item>
    <item>
      <title>如何训练网络以检测LIDAR PointCloud对象[关闭]</title>
      <link>https://stackoverflow.com/questions/79498544/how-to-train-a-network-to-detect-lidar-pointcloud-objects</link>
      <description><![CDATA[我正在使用OS1激光雷达传感器，因此我可以访问点云数据集。我需要能够识别对象。
我知道如何预处理数据，如何注释数据，并且我一直在阅读有关尖头柱和深入学习以学习如何训练网络的信息，但是没有存储库来解释如何在自定义数据上进行操作。 
如何训练网络以获取自定义数据？你有消息来源吗？他们中的大多数与汽车或行人有关，但我想确定自己的物体。
我一直在使用MATLAB可视化和注释我感兴趣的对象，但是我无法继续下一步，因为我不了解它们。
https://www.mathworks.com/help/lidar/ug/object-detection-with-point-clouds.html]]></description>
      <guid>https://stackoverflow.com/questions/79498544/how-to-train-a-network-to-detect-lidar-pointcloud-objects</guid>
      <pubDate>Mon, 10 Mar 2025 16:00:24 GMT</pubDate>
    </item>
    <item>
      <title>损失的计算梯度W.R.T学习率Pytorch</title>
      <link>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</guid>
      <pubDate>Mon, 10 Mar 2025 15:11:02 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地运行DeepSeek模型</title>
      <link>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</link>
      <description><![CDATA[我试图根据他们的说明在本地运行DeepSeek，但它不能带来一些愚蠢的错误（我将稍后显示）。
这就是我正在做的。

从此处下载最小型号（3.5GB） noreferrer“&gt; https://huggingface.co/deepseek-ai/deepseek-r1-distill-qwen-1.5b  
按照此处的步骤操作： https://github.com/deepseek-ai/deepseek-v3?tab=readMe-Readme-ov-file#6-how-to-to-to-run-locally  

 2.1获取这个项目
 https://github.com/deepseek-ai/deepseek-ai/deepseek-ai/deepseek-v3.git 
 2.2运行码头容器类似于预先创建的卷以放置模型
  docker run  -  gpus all -it -it -name deepSeek01 -rm -mount source = deepSeekv3，target =/root/deepSeekv3 python：3.10 -Slim bash
 
我正在使用python：3.10-slim，因为这里（ https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-how-to-run-locally ）
＆quot&#39; linux只有python 3.10。 Mac和Windows不支持。
 2.3安装最新更新
apt-get Update 
 2.4获取此文件 https://github.com/deepseek-ai/deepseek-v3/blob/main/main/inference/requirements.txt 并安装要求
  pip install -r sumpliont.txt
 
 2.5将模型复制到安装在Docker容器上的音量。这5个文件来自此处 https：//hugging.co/deepseek-aiek-ai/deepseek-ai/deepseek-ai/deepseek-ai/deepseek/deepseek-ipseek-r1-r1-r1-r1-pp&gt;   config.json
generation_config.json
模型。系统
tokenizer.json
tokenizer_config.json
 
 2.6在此处编写的模型转换 https://github.com/deepseek-ai/deepseek-v3?tab=readme-readme-ov-file#model-weights-conversion 通过此命令
  python convert.py-hf-ckpt-path/root/deepSeekv3/source_model -save-path/root/deepSeekv3/converted_model -n-experts 256-model-parelally 16
 
在此步骤中（转换模型）我得到了此错误
  trackback（最近的最新通话）：
  file＆quort＆quort＆quot deepseekv3/inference/convert.py&quot;，第96行，in＆lt; module＆gt;
    main（args.hf_ckpt_path，args.save_path，args.n_experts，args.model_parallel）
  file＆quot＆quot&#39;deepseekv3/inference/convert.py&quot;，第63行，在main中
    主张映射中的密钥
断言
 
因此，基本上，下一步没有意义，因为这是必不可少的步骤。
我的问题：

我做错了什么？
 YouTube上有一些视频，其中DeepSeek与Ollama一起安装了。真的需要吗？我是否应该像他们在这里描述的那样能够运行它， https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-to-run-locally ？

更新1 
为了调试一点，我添加了这2行。
  print（＆quot;丢失键：＆quot;键）
打印（可用键：＆quot; list（mapping.keys（）））
 
缺少键是以下内容：
  embed_tokens
input_layernorm
down_proj
gate_proj
UP_PROJ
post_attention_layernorm
k_proj
 
虽然所有这些都确实存在于模型中。
另外，@hans Kilian在评论中提到，我可能会放一些文件，而这些文件不需要到source_model文件夹中。
我在convert.py中检查了第11行，其中一些键在模型中不存在。]]></description>
      <guid>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</guid>
      <pubDate>Tue, 25 Feb 2025 22:14:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么拥抱面提供的DeepSeek代码会导致“未知量化类型”错误？</title>
      <link>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</link>
      <description><![CDATA[我正在使用huggingface的此代码：
此代码直接从 deepseek上的huggingface网站页面上的页面

 来自变形金刚导入管道

消息= [
{&#39;&#39;：＆quot“ user quot”内容“：;
这是给出的
pipe =管道（＆quot&#39;text-generation＆quot; deepseek-ai/deepseek-r1＆quort; trust_remote_code = true）
管道（消息）
 

，但我无法加载模型。当我这样做时，我会得到这个问题：
  file＆quot＆lt; ...＆gt;/site-packages/transformers/quantizers/auto.py＆quot;，第97行，在from_dict

提高价值Error（

ValueError：未知量化类型，获得FP8-支持类型为： 
[&#39;awq&#39;，&#39;bitsandbytes_4bit&#39;，&#39;bitsandbytes_8bit&#39;，&#39;gptq&#39;，&#39;aqlm&#39;，&#39;quanto&#39;，&#39;eetq&#39;，&#39;eetq&#39;， 
&#39;HQQ&#39;，“压缩张量”，“ fbgemm_fp8&#39;，&#39;torchao&#39;，&#39;bitnet&#39;]
 
我尝试了不同的代码：
 导入火炬
generate_text = pipeline（model =; deepSeek-ai/deepSeek-r1; torch_dtype = torch.bfloat16，trust_remote_code = true，device_map =; auto;
generate_text（消息）
 
这给出以下错误：

raise ValueError( ValueError: Unknown quantization type, got fp8 - supported types are: [&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39;, &#39;higgs&#39;, &#39;hqq&#39;, &#39;compressed-tensors&#39;, &#39;fbgemm_fp8&#39;, &#39;torchao&#39;，&#39;bitnet&#39;，&#39;vptq&#39;] 

我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>Importerror：无法从“火炬”（未知位置）导入“张量”的名称</title>
      <link>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</link>
      <description><![CDATA[我正在尝试从Pytorch导入 ：
 来自火炬导入张量
 
但我一直遇到此错误：
  Importerror：无法从“火炬”（未知位置）导入名称&#39;tensor&#39;
 
我尝试的是：

检查是否已安装了Pytorch（ pip show torch ），我正在使用版本 2.5.1 。。
重新安装了Pytorch：
  pip卸载火炬
PIP安装火炬
 

测试了python壳中的导入，但错误仍然存​​在。

环境：

 Python版本：3.10 
 Pytorch版本：2.5.1 
 OS：Windows 10 
虚拟环境：是

我该如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</guid>
      <pubDate>Sat, 18 Jan 2025 13:04:35 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法选择</title>
      <link>https://stackoverflow.com/questions/15292547/machine-learning-algorithm-selection</link>
      <description><![CDATA[我是机器学习的新手。我的问题是制作一台机器，根据学生的位置和感兴趣的领域为学生选择大学。即，应该在同一城市中选择与学生地址相同的大学。我对选择算法感到困惑，我可以将perceptron算法用于此任务。 ]]></description>
      <guid>https://stackoverflow.com/questions/15292547/machine-learning-algorithm-selection</guid>
      <pubDate>Fri, 08 Mar 2013 11:07:51 GMT</pubDate>
    </item>
    </channel>
</rss>