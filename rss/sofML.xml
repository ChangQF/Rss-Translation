<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 14 Mar 2024 09:13:28 GMT</lastBuildDate>
    <item>
      <title>由于CPU和GPU之间频繁的数据传输，CNN中的“零填充”是否会增加推理时间？</title>
      <link>https://stackoverflow.com/questions/78158937/does-zero-padding-in-cnn-increase-the-inference-time-due-to-frequent-data-tran</link>
      <description><![CDATA[我认为在设计 DNN 加速器或 NPU 时，CNN 中的零填充是一个非常烦人的操作。所以我想知道在像 Pytorch/TF 这样的现代机器学习框架中，如果 zero-padding 是在 CPU 或 GPU 上执行的（我不擅长它们）？如果在CPU上完成，当存在需要填充的连续层时，由于CPU和GPU之间频繁的数据移动，该操作是否会大大增加总推理时间？否则，GPU如何完成低效的padding操作呢？
我想我没有找到太多这方面的信息。所以我希望有人能帮我解答这个问题。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78158937/does-zero-padding-in-cnn-increase-the-inference-time-due-to-frequent-data-tran</guid>
      <pubDate>Thu, 14 Mar 2024 08:07:04 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 预期监控计划的架构？</title>
      <link>https://stackoverflow.com/questions/78158477/sagemaker-expected-schema-for-monitoring-schedule</link>
      <description><![CDATA[我正在尝试针对模型生成的数据运行 SageMaker 监控作业，但我不断遇到架构验证问题。不幸的是，我找不到任何有关 SageMaker 所期望的确切架构的文档。
它尝试分析的数据如下所示：
[{&quot;captureData&quot;: {&quot;endpointInput&quot;: {&quot;observedContentType&quot;:&quot;application/json&quot;,&quot;mode&quot;: &quot;INPUT&quot;,&quot;data&quot;: &quot;Some输入”、“编码”：“JSON”}、“端点输出”：{“observedContentType”：“application/json”、“模式”：“输出”、“数据”：“原始”输出”,“编码”:“JSON”}},“eventMetadata”:{“eventId”:“abc12345-ca38-42f2-a57b-03b6bd701235”,“推理时间”:“2024-03 -14T02:06:27Z&quot;},&quot;事件版本&quot;:&quot;0&quot;}]

遇到的错误：
com.amazonaws.sagemaker.dataanalyzer.exception.CustomerError：我们目前仅支持平面 json。

我已经将 json 展平以模拟 jsonl 结构。每当我尝试进行调整以进一步展平 json 时，它都会抱怨缺少键。
更多背景：
DataCaptureConfig
capture_options=[“请求”,“响应”]

data_capture_config = DataCaptureConfig(
    启用_捕获=真，
    采样百分比=100，
    destination_s3_uri=s3_capture_upload_path,
    捕获选项=捕获选项
）

基线作业
baseline_job = my_default_monitor.suggest_baseline(
    Baseline_dataset=f“{baseline_data_uri}/fake_data_augmented_with_variability.csv”，
    dataset_format=sagemaker.model_monitor.DatasetFormat.csv(header=True),
    output_s3_uri=baseline_results_uri,
    作业名称=基线作业名称，
    等待=假，
    日志=假
）

监控计划
my_default_monitor.create_monitoring_schedule(
    Monitor_schedule_name=mon_schedule_name,
    端点输入=端点名称，
    post_analytics_processor_script = s3_code_postprocessor_uri，
    output_s3_uri=s3_report_path,
    统计=my_default_monitor.baseline_statistics(),
    约束=my_default_monitor.suggested_constraints(),
    Schedule_cron_expression=CronExpressionGenerator.每小时(),
    enable_cloudwatch_metrics=真，
）

端点调用
响应=runtime_client.invoke_endpoint(
   端点名称=端点名称，
   ContentType =“应用程序/json”，
   正文=body_json
）
]]></description>
      <guid>https://stackoverflow.com/questions/78158477/sagemaker-expected-schema-for-monitoring-schedule</guid>
      <pubDate>Thu, 14 Mar 2024 06:24:08 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow federated 中工作时遇到“学习属性”错误。欢迎提出建议</title>
      <link>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated-sugg</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated-sugg</guid>
      <pubDate>Thu, 14 Mar 2024 05:35:24 GMT</pubDate>
    </item>
    <item>
      <title>cv2.imwrite 行为不正常</title>
      <link>https://stackoverflow.com/questions/78158327/cv2-imwrite-not-behaving-properly</link>
      <description><![CDATA[我正在开发一个使用 cv2 的项目，用于在 Mac 上处理和保存图像。但问题是保存的图像数量为 490，但循环运行了 1251 次。
这是我尝试过的：
faces_path = glob(&#39;./Data/faces/*.jpg&#39;) # 此文件夹中有 1251 张图像

这是处理图像的函数：
def extract_faces(img_path, i):
img = cv2.imread(img_path)
灰色 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY, 1.3, 5)
faces = haar.detectMultiScale(灰色, 1.5, 5)
对于面中的 x,y,w,h：
    roi = img[y:y+h, x:x+h]
    cv2.imwrite(“./Data/cropped/face_{}.jpg”.format(i), roi)

而且，这是我使用该函数的方式：
&lt;前&gt;&lt;代码&gt;# extract_faces(路径, 1)
对于 i，枚举中的路径（faces_path）：
    尝试：
        extract_faces（路径，i）
        print(“信息：{}/{} 已处理。”.format(i, len(faces_path)))
    除了：
        print(&quot;INFO: {}/{} 未成功处理。&quot;.format(i, len(faces_path)))

循环运行了 1251 次，但保存在 cropped 文件夹中的图像为 490 可能是什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78158327/cv2-imwrite-not-behaving-properly</guid>
      <pubDate>Thu, 14 Mar 2024 05:35:03 GMT</pubDate>
    </item>
    <item>
      <title>所有多标签分类模型的准确性为零</title>
      <link>https://stackoverflow.com/questions/78158222/all-multi-label-classification-models-giving-zero-accuracy</link>
      <description><![CDATA[我尝试以零精度应用任何 scikit 多标签模型。
这是预处理后我的数据集的图片： X-label, y 标签，完整数据集
我尝试将 ClassfierChain、BinaryRelevance 和 LabelPowerSet 与多个分类模型一起应用，例如：
def build_model（模型，mlb_estimator，X_train，y_train，X_test，y_test）：
    #创建实例
    clf = mlb_estimator(模型)
    clf.fit(X_train,y_train)
    
    ＃预测
    clf_pred = clf.predict(X_test)
    
    #检查准确性
    acc = 准确度_分数(y_test, clf_pred)
    火腿 = hamming_loss(y_test,clf_pred)
    结果= {“准确率”：acc，“汉明损失”：ham}
    返回结果

clf_chain_model = build_model(MultinomialNB(),LabelPowerset,X_train, y_train, X_test, y_test)

但我得到的只是 0.0 的准确度:(请帮助我仍然是新手，我认为数据预处理可能存在问题，但我无法弄清楚]]></description>
      <guid>https://stackoverflow.com/questions/78158222/all-multi-label-classification-models-giving-zero-accuracy</guid>
      <pubDate>Thu, 14 Mar 2024 05:05:27 GMT</pubDate>
    </item>
    <item>
      <title>将低秩近似应用于可学习参数</title>
      <link>https://stackoverflow.com/questions/78158096/applying-low-rank-approximation-to-learnable-parameters</link>
      <description><![CDATA[我试图了解将低秩近似应用于类中的可学习参数是否有意义。目标是减少参数数量。
我有以下自定义模块：
类 CustomPara(nn.Module):
    
    def __init__(self, num_blocks, in_planes, out_planes, kernel_size):
        super(CustomPara, self).__init__()
        self.coefficient_shape = (num_blocks,1,1,1,1)
        块 = [torch.Tensor(out_planes, in_planes, kernel_size, kernel_size) for _ in range(num_blocks)]
        对于范围内的 i(num_blocks): init.kaiming_normal_(blocks[i])
        self.blocks = nn.Parameter(torch.stack(blocks)) # 这是我们稍后将冻结的内容

    defforward（自身，系数）：
        Final_blocks = (self.blocks*系数).sum(0)
        返回final_blocks

是否可以使用 blocks 参数上的低秩自适应来减少此处可学习参数的数量？
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78158096/applying-low-rank-approximation-to-learnable-parameters</guid>
      <pubDate>Thu, 14 Mar 2024 04:22:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 3 中预先创建的批量图像数据训练分割模型</title>
      <link>https://stackoverflow.com/questions/78157765/training-a-segmentation-model-with-pre-created-batches-of-image-data-in-keras-3</link>
      <description><![CDATA[我有一个用例，我需要在将数据输入模型进行训练之前手动生成批量数据。
假设我有(256 x 100 x 100)图像，而我手动创建的批次的尺寸为(32 x 100 x 100)。如果我的训练集按 [batch_1, batch_2, ... batch_8] 的顺序排列，则得到原始形状 (256 x 100 x 100)。
当我将其提供给 model.fit() 并将批量大小指定为 32 时，模型能否正确获取每个手动批次以按顺序进行训练，不混合每个批次的数据点并创建大小为 32 的新批次？
我正在使用Keras 3.0.1。]]></description>
      <guid>https://stackoverflow.com/questions/78157765/training-a-segmentation-model-with-pre-created-batches-of-image-data-in-keras-3</guid>
      <pubDate>Thu, 14 Mar 2024 02:23:09 GMT</pubDate>
    </item>
    <item>
      <title>使用遗传算法优化面部情绪识别模型超参数</title>
      <link>https://stackoverflow.com/questions/78157230/optimizing-facial-emotion-recognition-model-hyperparameters-using-genetic-algori</link>
      <description><![CDATA[我正在致力于构建一个面部情绪识别系统，可以对快乐、悲伤、愤怒、惊讶等情绪进行分类。我已经使用 TensorFlow/Keras 训练了一个卷积神经网络模型，目前，它实现了准确率50%左右。然而，我相信微调超参数可能会进一步提高准确性。
现在，我有兴趣优化模型的超参数以实现更高的准确性。我听说过使用遗传算法进行超参数优化，但我不确定如何继续。有人可以指导我如何应用遗传算法来微调模型的超参数吗？具体来说，如何修改我的代码以纳入遗传算法以进行超参数优化？
任何帮助或建议将不胜感激。谢谢！
这是我的代码摘要：
将张量流导入为 tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras导入模型，层

# 数据增强
增强器 = ImageDataGenerator(
    重新缩放=1.0/255，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真
）

# 加载数据并将图像大小调整为 48x48 像素
Augmented_trained_data = Augmentor.flow_from_directory(
    “面部识别数据集/训练”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

Augmented_validation_data = Augmentor.flow_from_directory(
    “面部识别数据集/验证”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

Augmented_testing_data = Augmentor.flow_from_directory(
    “面部识别数据集/测试”，
    目标大小=(48, 48),
    批量大小=32，
    color_mode=“灰度”，
    class_mode=“分类”
）

# 模型定义
模型 = models.Sequential([
    层.Conv2D(32, (2, 2), 激活=“relu”, input_shape=(48, 48, 1)),
    层.MaxPool2D((2, 2)),
    层.Conv2D(64, (2, 2), 激活=“relu”),
    层.MaxPool2D((2, 2)),
    层.Conv2D(128, (2, 2), 激活=“relu”),
    层.MaxPool2D((2, 2)),
    层.Flatten(),
    层.密集（128，激活=“relu”），
    层数.Dropout(0.25),
    层.密集（6，激活=“softmax”）
]）

# 模型编译
模型.编译(
    优化器=&#39;亚当&#39;,
    损失=tf.keras.losses.CategoricalCrossentropy(from_logits=False),
    指标=[“准确度”]
）

# 模型训练
模型.拟合(
    增强训练数据，
    验证数据=增强验证数据，
    纪元=10
）

# 模型评估
test_loss, test_accuracy = model.evaluate(augmented_testing_data)
print(f&quot;测试准确度: {test_accuracy * 100:.2f}%&quot;)&#39;&#39;&#39;


]]></description>
      <guid>https://stackoverflow.com/questions/78157230/optimizing-facial-emotion-recognition-model-hyperparameters-using-genetic-algori</guid>
      <pubDate>Wed, 13 Mar 2024 22:53:36 GMT</pubDate>
    </item>
    <item>
      <title>pandas merge 和 pandas concat 有什么区别？ [复制]</title>
      <link>https://stackoverflow.com/questions/78157149/what-is-the-difference-between-pandas-merge-and-pandas-concat</link>
      <description><![CDATA[给出 pandas concat 和 pandas merge 之间的一些主要区别？
答案的理论和这两个功能之间的基本区别。
以及需要重要的重要差异和领域。以及这个函数中使用的是什么函数。]]></description>
      <guid>https://stackoverflow.com/questions/78157149/what-is-the-difference-between-pandas-merge-and-pandas-concat</guid>
      <pubDate>Wed, 13 Mar 2024 22:30:03 GMT</pubDate>
    </item>
    <item>
      <title>常见用户流程分析</title>
      <link>https://stackoverflow.com/questions/78156781/common-userflow-analysis</link>
      <description><![CDATA[我正在尝试在事件日志数据中找到常见的用户流模式。事件日志数据来自桌面应用程序，该应用程序捕获用户单击的位置以及时间戳。桌面应用程序中有 2000 多个独特的按钮。如何使用机器学习、深度学习来找出常见的用户流模式并可视化数据？
我尝试使用前缀跨度，但没有运气，因为我没有得到想要的结果。我认为前缀跨度不是这里的最佳选择。我应该使用任何其他算法或任何其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78156781/common-userflow-analysis</guid>
      <pubDate>Wed, 13 Mar 2024 20:58:12 GMT</pubDate>
    </item>
    <item>
      <title>无法将保存的 keras 模型转换为 TFLite</title>
      <link>https://stackoverflow.com/questions/78156242/cant-convert-saved-keras-model-to-tflite</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78156242/cant-convert-saved-keras-model-to-tflite</guid>
      <pubDate>Wed, 13 Mar 2024 19:00:00 GMT</pubDate>
    </item>
    <item>
      <title>验证错误：无法实例化 GPT4AllEmbeddings 模型</title>
      <link>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</link>
      <description><![CDATA[我在尝试创建 GPT4AllEmbeddings 实例时遇到问题。但是我不断收到以下错误
单元格 In[15]，第 1 行
----&gt; 1 vectorstore = Chroma.from_documents(文档 = 分割, 嵌入 = GPT4AllEmbeddings())
      2 检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
      3检索文档=检索器.get_relevant_documents（“你是什么？”）

文件 ~\anaconda3\Lib\site-packages\pydantic\main.py:341，在 pydantic.main.BaseModel.__init__() 中

ValidationError：GPT4AllEmbeddings 出现 1 个验证错误
__根__
  无法实例化模型（type=value_error）

这是相关的代码片段
vectorstore = Chroma.from_documents(documents = splits, embeddings = GPT4AllEmbeddings())
检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
retrieved_docs =retrieve.get_relevant_documents(“什么是Young Decade？”)
打印（len（检索文档））
打印（retrieve_docs[0].page_content）

如何解决这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</guid>
      <pubDate>Wed, 13 Mar 2024 09:36:07 GMT</pubDate>
    </item>
    <item>
      <title>在 SageMaker 上的 TensorFlow Recommenders 中初始化 FactorizedTopK 时出错：“无法将‘计数器’转换为形状”</title>
      <link>https://stackoverflow.com/questions/78144515/error-initializing-factorizedtopk-in-tensorflow-recommenders-on-sagemaker-cann</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78144515/error-initializing-factorizedtopk-in-tensorflow-recommenders-on-sagemaker-cann</guid>
      <pubDate>Tue, 12 Mar 2024 03:28:18 GMT</pubDate>
    </item>
    <item>
      <title>在恢复的对象中找不到检查点中的值：(root).optimizer.iter</title>
      <link>https://stackoverflow.com/questions/71929036/value-in-checkpoint-could-not-be-found-in-the-restored-object-root-optimizer</link>
      <description><![CDATA[所以我使用了此链接中的预训练权重：http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz
然后我将 pipeline.config 从下载链接复制到我的文件夹，因为我想将优化器更改为 adam 以在我自己的数据集上进行训练（链接中的管道正在使用momentum_optimizer）
这是我要训练的 pipeline.config 代码：
优化器{
亚当_优化器{
  学习率{
    余弦_衰减_学习率{
      学习率基础：0.01
      总步数：50000
      热身学习率：0.026666
      热身步数：1000
    }
  }
  ε：1e-8
}
use_moving_average: false

}
但是 cmd 提示给了我这个：
警告：tensorflow：在恢复的对象中找不到检查点中的值：(root).optimizer.iter
W0419 23：47：07.776149 17436 util.py：194]在恢复的对象中找不到检查点中的值：（root）.optimizer.iter
警告：tensorflow：在恢复的对象中找不到检查点中的值：(root).optimizer.decay
W0419 23：47：07.777309 17436 util.py：194]在恢复的对象中找不到检查点中的值：（root）.optimizer.decay
警告：tensorflow：在恢复的对象中找不到检查点中的值：(root).optimizer.momentum
W0419 23：47：07.779311 17436 util.py：194]在恢复的对象中找不到检查点中的值：（root）.optimizer.momentum

谁能解释一下谢谢
[1]: https://i.stack.imgur.com/BBmVA.png]]></description>
      <guid>https://stackoverflow.com/questions/71929036/value-in-checkpoint-could-not-be-found-in-the-restored-object-root-optimizer</guid>
      <pubDate>Tue, 19 Apr 2022 17:33:49 GMT</pubDate>
    </item>
    <item>
      <title>Docker for Lambda (FAST API) 中的{“无法导入模块‘main’：没有名为‘main’的模块”，“errorType”：“Runtime.ImportModuleError”}</title>
      <link>https://stackoverflow.com/questions/71305887/unable-to-import-module-main-no-module-named-main-errortype-runtime</link>
      <description><![CDATA[我已经创建了一个 Fastapi，现在尝试使用 Docker 容器将其部署到 AWS lambda。但有一个错误：
{“errorMessage”：“无法导入模块“main”：没有名为“main”的模块”，“errorType”：“Runtime.ImportModuleError”，“stackTrace”：[] }

我已经尽力了。
这是我的 main.py 文件：
from fastapi 导入 FastAPI
从 starlette.status 导入 HTTP_302_FOUND,HTTP_303_SEE_OTHER
导入spacy
从字符串导入标点符号
从曼古姆进口曼古姆
进口uvicorn
应用程序 = FastAPI()

@app.get(&#39;/&#39;)
def home():
    返回{“答案”：“你好世界”}

@app.get(&#39;/tags&#39;)
def prep_data(文本):
    标签=标记（文本，nlp）
    标签 = getdict(标签)
    返回 {
        ‘标签’：标签
    }

处理程序 = Mangum(应用程序)
如果 __name__ == “__main__”：
    # 处理程序 = Mangum(应用程序)
    uvicorn.run(&#39;main:app&#39;, host=&#39;0.0.0.0&#39;, port=8000, reload=False, root_path=”/”)

该错误表明 main.py 文件没有 main.py 文件，正如您所看到的 dockerfile：
&lt;前&gt;&lt;代码&gt;来自 public.ecr.aws/lambda/python:3.8

复制./应用程序/应用程序

复制 ./requirements.txt /app/requirements.txt

工作目录/应用程序

运行 pip install -rrequirements.txt

CMD [“main.handler”]

我的目录结构是这样的：
&lt;前&gt;&lt;代码&gt;/应用程序
    主要.py
Dockerfile
要求.txt
]]></description>
      <guid>https://stackoverflow.com/questions/71305887/unable-to-import-module-main-no-module-named-main-errortype-runtime</guid>
      <pubDate>Tue, 01 Mar 2022 08:52:48 GMT</pubDate>
    </item>
    </channel>
</rss>