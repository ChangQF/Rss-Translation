<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 21 Jun 2024 18:20:19 GMT</lastBuildDate>
    <item>
      <title>Tensorflow 模型训练期间使用提前停止功能时出现 Python 解释器状态错误</title>
      <link>https://stackoverflow.com/questions/78653468/python-interpreter-state-error-during-tensorflow-model-training-with-early-stopp</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78653468/python-interpreter-state-error-during-tensorflow-model-training-with-early-stopp</guid>
      <pubDate>Fri, 21 Jun 2024 16:16:11 GMT</pubDate>
    </item>
    <item>
      <title>InvalidArgumentError：图形执行错误不兼容的形状：ViT 中 PatchEncoder 中的 [32,800,64] 与 [32,125,64]</title>
      <link>https://stackoverflow.com/questions/78653170/invalidargumenterror-graph-execution-error-incompatible-shapes-32-800-64-vs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78653170/invalidargumenterror-graph-execution-error-incompatible-shapes-32-800-64-vs</guid>
      <pubDate>Fri, 21 Jun 2024 15:17:08 GMT</pubDate>
    </item>
    <item>
      <title>Bindsnet batchsize>1 准确率</title>
      <link>https://stackoverflow.com/questions/78652942/bindsnet-batchsize1-accuracy</link>
      <description><![CDATA[当我尝试增加batchsize时，我的网络的准确率明显低于batchsize=1。我应该怎么做才能提高准确率？
我在bindsnet中使用了DiehlAndCook2015网络。它不适用于batchsize&gt;1吗？]]></description>
      <guid>https://stackoverflow.com/questions/78652942/bindsnet-batchsize1-accuracy</guid>
      <pubDate>Fri, 21 Jun 2024 14:32:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中如何处理“真实”数据和封闭式方程？</title>
      <link>https://stackoverflow.com/questions/78652914/how-to-deal-with-real-data-and-closed-formed-equation-in-machine-learning</link>
      <description><![CDATA[我的目标是对来自“现实世界”（传感器）的一组数据进行回归分析。
数据采用表格格式。有 6 个独立特征，其值差异很大（需要缩放）。此外，因变量具有很大的可变性（可能需要缩放？）。
当其中一个变量（假设 X1）的绝对值较低时，初始经典训练会显示预测中的弱点。
专家告诉我，在 X1 较低的这个特定区域中，要预测的值（我们称之为 Y）可以通过线性回归来近似。因此，如果所有其他特征都是恒定的，则 X1 和 Y 具有 Y=a * X1 + b 类型的线性依赖关系。
问题是系数“a”和“b”取决于其他特征 a = f(X2,X3,X4,X5)...
请注意，我有一个表，其中列出了其他 5 个特征的几种组合的系数“a”和“b”。
我想将“物理信息”的线性化集成到训练过程中。但我该怎么做呢？我看过物理信息神经网络，但它们只针对 PDE，而不是像我一样针对闭式方程。
对我来说，一个自然的做法是通过方程在这个区域生成假数据。这会被视为物理信息机器学习吗？我看不出添加假数据和添加试图完成方程的损失之间的区别。
非常感谢您的回答，
祝您有美好的一天！]]></description>
      <guid>https://stackoverflow.com/questions/78652914/how-to-deal-with-real-data-and-closed-formed-equation-in-machine-learning</guid>
      <pubDate>Fri, 21 Jun 2024 14:26:46 GMT</pubDate>
    </item>
    <item>
      <title>解释音乐流派分类器准确率低的原因</title>
      <link>https://stackoverflow.com/questions/78652467/explaining-the-poor-accuracy-of-a-music-genre-classifier</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78652467/explaining-the-poor-accuracy-of-a-music-genre-classifier</guid>
      <pubDate>Fri, 21 Jun 2024 12:51:50 GMT</pubDate>
    </item>
    <item>
      <title>MOT 遮挡度量</title>
      <link>https://stackoverflow.com/questions/78652127/mot-occlusion-metric</link>
      <description><![CDATA[是否有任何度量计算，例如 IDF1、MOTA、HOTA 等，专门用于计算方法/算法的性能，例如遮挡对象的 DeepSORT
我试过 IDF1，但它是 ID 的度量，例如 ID 切换，尽管遮挡是 ID 切换的原因之一，但我只想将度量重点放在遮挡上]]></description>
      <guid>https://stackoverflow.com/questions/78652127/mot-occlusion-metric</guid>
      <pubDate>Fri, 21 Jun 2024 11:32:47 GMT</pubDate>
    </item>
    <item>
      <title>聚类实际上会减少数据集中的行数吗？</title>
      <link>https://stackoverflow.com/questions/78652112/does-clustering-actually-reduce-the-number-of-rows-in-a-dataset</link>
      <description><![CDATA[我正在阅读 Luis G. Serrano 的《grokking Machine Learning》一书，看到了这样一句话：
“看起来聚类和降维没什么相似之处，但实际上，它们并没有太大区别。如果我们有一张满是数据的表，每一行对应一个数据点，每一列对应一个特征。因此，我们可以使用聚类来减少数据集中的行数，使用降维来减少列数。”
我对聚类减少行数的说法有疑问。似乎聚类只是对数据进行分组，而不减少其列数。我错了吗？]]></description>
      <guid>https://stackoverflow.com/questions/78652112/does-clustering-actually-reduce-the-number-of-rows-in-a-dataset</guid>
      <pubDate>Fri, 21 Jun 2024 11:30:08 GMT</pubDate>
    </item>
    <item>
      <title>Swin Transformer 中的线性嵌入层是什么？</title>
      <link>https://stackoverflow.com/questions/78651620/what-is-the-linear-embedding-layer-in-swin-transformer</link>
      <description><![CDATA[我的目标是了解 Swin Transformer 中的线性嵌入层实际上是什么
问题是 Swin Transformer 的论文没有解释什么是线性嵌入层。
arXiv：

Swin Transformer

在此原始值特征上应用线性嵌入层以将其投影到任意维度（表示为 C）。

这是论文中对线性嵌入的唯一解释。


PyTorch 文档：

线性
嵌入

YouTube：

嵌入

StackOverflow：

PyTorch 中 Linear 和 Embedding 的区别

老实说，我不知道从哪里开始]]></description>
      <guid>https://stackoverflow.com/questions/78651620/what-is-the-linear-embedding-layer-in-swin-transformer</guid>
      <pubDate>Fri, 21 Jun 2024 09:54:31 GMT</pubDate>
    </item>
    <item>
      <title>如何知道是否有办法改进这个模型，以及如何知道我是否达到了特定模型的限制[关闭]</title>
      <link>https://stackoverflow.com/questions/78650661/how-to-know-if-there-is-a-way-to-improve-this-model-and-also-how-should-i-know-i</link>
      <description><![CDATA[我是数据科学领域的新手，所以当我建立模型时，我不确定我是否已经到达终点，而且我也不知道我还能如何改进模型。这是随机森林分类器，我使用 RandomizeSearchCV 作为参数，最终得到了最高的 73%。此外，我还使用了 class_weight 来平衡类别，我缩放了所有内容并清理了数据，正如您将看到的。我不确定这是否是最好的方法，也不知道在制作模型时 73% 是否足够好，也不知道我是否达到了随机森林分类器的极限。
从 matplotlib 导入 pyplot 作为 plt
从 matplotlib.colors 导入 ListedColormap
导入 pandas 作为 pd
导入 numpy 作为 np
从 sklearn.compose 导入 ColumnTransformer
从 sklearn.model_selection 导入 RandomizedSearchCV、train_test_split
从 sklearn.preprocessing 导入 OneHotEncoder、StandardScaler、LabelEncoder、MinMaxScaler、MaxAbsScaler、RobustScaler
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 classes_report、accuracy_score、confusion_matrix
从 imblearn.over_sampling 导入 SMOTE

pd.set_option(&#39;display.max_rows&#39;, None)
pd.set_option(&#39;display.max_columns&#39;, None)
df = pd.read_csv(&#39;pokemon_data.csv&#39;)

duplicates = df.duplicated()
if duplicates.any():
print(df[duplicates], &quot;DUPLICATE&quot;)
else:
print(&quot;NO DUPLICATES&quot;)

class_dist = df[&#39;type1&#39;].value_counts()
print(class_dist)

df.replace(&#39;—&#39;, np.nan, inplace=True)
numerical_cols = df.select_dtypes(include=np.number).columns
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())
# 现在我们填充分类缺失数据列
categorical_cols = df.select_dtypes(include=&#39;object&#39;).columns
df[categorical_cols] = df[categorical_cols].fillna(&#39;Unknown&#39;)

preprocessor = ColumnTransformer(
transformers=[
(&#39;num&#39;, StandardScaler(), [&#39;dexnum&#39;]),
(&#39;cat&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;), [&#39;species&#39;, &#39;ability1&#39;, &#39;ability2&#39;, &#39;egg_group1&#39;, &#39;egg_group2&#39;])
])

features = [&#39;species&#39;, &#39;ability1&#39;, &#39;ability2&#39;, &#39;egg_group1&#39;,
&#39;egg_group2&#39;]

X = df[features] # 我们用来预测的变量 
y_type1 = df[&#39;type1&#39;] # 我们预测的内容
y_type2 = df[&#39;type2&#39;] # 我们预测什么

preprocessor = ColumnTransformer(
transformers=[
(&#39;num&#39;, StandardScaler(), []),
(&#39;cat&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;), [&#39;species&#39;, &#39;ability1&#39;, &#39;ability2&#39;, &#39;egg_group1&#39;, &#39;egg_group2&#39;])
])

# Train_test_split 用于将数据集拆分为两个子集，即训练集和测试集
X_train, X_test, y_type1_train, y_type1_test = train_test_split(X, y_type1, test_size=0.4, random_state=42)

X_train = preprocessor.fit_transform(X_train)
X_test = preprocessor.transform(X_test)

param_dist = {
&#39;n_estimators&#39;: [9000],
&#39;max_depth&#39;: [1000],
&#39;min_samples_split&#39;: [2],
&#39;min_samples_leaf&#39;: [1],
&#39;max_features&#39;: [&#39;log2&#39;],
&#39;bootstrap&#39;: [False]
}

rf_type1 = RandomForestClassifier(class_weight=&#39;balanced&#39;, random_state=42)
random_search = RandomizedSearchCV(estimator=rf_type1, param_distributions=param_dist, n_iter=50, cv=5, verbose=2, random_state=42, n_jobs=-1)
random_search.fit(X_train, y_type1_train)

# 获取最佳参数
print(&quot;找到最佳参数：&quot;, random_search.best_params_)
print(&quot;最佳准确率： &quot;, random_search.best_score_)

# 使用最佳参数重新训练模型
best_rf = random_search.best_estimator_
y_type1_pred_best = best_rf.predict(X_test)

# 评估模型
print(&quot;具有最佳参数的 Type1 分类报告：&quot;)
print(classification_report(y_type1_test, y_type1_pred_best))
print(&quot;具有最佳参数的 Type1 准确率：&quot;, accuracy_score(y_type1_test, y_type1_pred_best))

]]></description>
      <guid>https://stackoverflow.com/questions/78650661/how-to-know-if-there-is-a-way-to-improve-this-model-and-also-how-should-i-know-i</guid>
      <pubDate>Fri, 21 Jun 2024 06:07:40 GMT</pubDate>
    </item>
    <item>
      <title>有人能帮助我在使用 pytorch 时最大限度地提高 GPU 利用率吗？</title>
      <link>https://stackoverflow.com/questions/78650444/can-anybody-help-me-out-with-maximizing-gpu-utilization-when-using-pytorch</link>
      <description><![CDATA[我目前使用的是带有 7950X CPU 的 RTX 4090。我的目标是在表格数据上运行相对简单的模型时最大限度地提高 GPU 利用率。该模型的参数少于 100 万个，数据形状为 (5,000,000, 120)。当我训练模型时，只有 18% 的 GPU 被利用，完成训练大约需要 3 个小时。
主要问题是，如果我能以某种方式利用 90% 的 GPU，训练时间将显著减少，可能减少到当前时间的五分之一，这将为我节省大量时间。
我尝试了各种解决方案，例如调整批处理大小、增加模型的复杂性以及更改 DataLoader 的 num_workers，但这些都没有起到很好的作用。无论我如何调整，GPU 负载仍然在 10-15% 左右。这真是令人沮丧。
由此，我想到了使用多处理的想法。由于我使用的是单个 GPU，并且单个模型仅使用 18%，因此我仍有空间运行另​​外四个模型。我认为同时运行五个不同的模型可以将 GPU 利用率提高到 100% 左右，从而节省大量时间。但是，当我尝试使用 PyTorch 的多处理时，结果并不理想。
有人能帮我解决这个问题吗，或者我的想法在 PyTorch 中不可行？
我尝试过的方法

将批次大小从 64 增加到 4096、40962、40964
使用 num_workers (2,4,8)
向模型添加更多层
使用 pytorch.multiprocessing
]]></description>
      <guid>https://stackoverflow.com/questions/78650444/can-anybody-help-me-out-with-maximizing-gpu-utilization-when-using-pytorch</guid>
      <pubDate>Fri, 21 Jun 2024 04:50:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 python 和 rembg 去除车窗玻璃背景？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78649936/how-can-remove-car-window-glass-bg-with-python-rembg</link>
      <description><![CDATA[我正在使用 rembg 去除背景，但问题是车窗玻璃的背景没有被去除。在这种情况下，如何去除车窗玻璃的背景。有人能帮帮我吗？
主图像 
--&gt;当前结果图像
--&gt;预期结果图像 
output_data = rembg.remove(input_data)
]]></description>
      <guid>https://stackoverflow.com/questions/78649936/how-can-remove-car-window-glass-bg-with-python-rembg</guid>
      <pubDate>Thu, 20 Jun 2024 23:37:59 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用训练有素的 YOLO-V8 实例分割模型进行预测时将边界框值添加到标签文本文件中？</title>
      <link>https://stackoverflow.com/questions/78649611/how-to-add-the-bounding-box-values-to-the-labels-text-files-during-prediction-wi</link>
      <description><![CDATA[我训练了一个 YOLO-V8 实例分割模型来分割类标签为 0 的对象。我使用 CLI 实例化训练后的模型并根据测试数据进行预测。
!yolo task=segment mode=predict model=&#39;/weights/best.pt&#39; conf=0.25 source=&#39;/test/images&#39; imgsz=1024 save=True save_txt=True save_conf=True

预测后，标签文件将以 .txt 格式存储。这些标签文件包含类索引，后跟多边形坐标，最后是边界框预测的置信度分数。但是，边界框坐标（即 x 中心、y 中心、宽度、高度）不包含在标签文件中。我还想将这些边界框坐标包含到每个标签文件中，因为我想稍后使用这些边界框坐标进行后期处理。示例标签文件内容如下所示：
0 0.21582 0.0898438 0.214844 0.0908203 0.213867 0.0908203 0.210938 0.09375 0.210938 0.0947266 0.203125 0.102539 0.203125 0.103516 0.201172 0.105469 0.200195 0.105469 0.199219 0.106445 0.199219 0.113281 0.200195 0.114258 0.200195 0.115234 0.203125 0.115234 0.204102 0.116211 0.223633 0.116211 0.224609 0.117188 0.227539 0.117188 0.228516 0.118164 0.230469 0.118164 0.231445 0.119141 0.234375 0.119141 0.235352 0.120117 0.248047 0.120117 0.249023 0.121094 0.251953 0.121094 0.25293 0.12207 0.254883 0.0927734 0.260742 0.0917969 0.256836 0.0917969 0.255859 0.0908203 0.233398 0.0908203 0.232422 0.0898438 0.910849

我没有将预测保存到任何“结果”变量中，并且我只在 CLI 中运行预测。]]></description>
      <guid>https://stackoverflow.com/questions/78649611/how-to-add-the-bounding-box-values-to-the-labels-text-files-during-prediction-wi</guid>
      <pubDate>Thu, 20 Jun 2024 21:15:36 GMT</pubDate>
    </item>
    <item>
      <title>如何将主成分分析的结果映射回输入模型的实际特征？</title>
      <link>https://stackoverflow.com/questions/67585809/how-to-map-the-results-of-principal-component-analysis-back-to-the-actual-featur</link>
      <description><![CDATA[当我运行下面的代码时，我会看到“pca.explained_variance_ratio_”和一个直方图，其中显示了每个特征解释的方差比例。
import statsmodels.api as sm
import numpy as np
import pandas as pd
import statsmodels.formula.api as smf
from statsmodels.stats import anova

mtcars = sm.datasets.get_rdataset(&quot;mtcars&quot;, &quot;datasets&quot;, cache=True).data
df = pd.DataFrame(mtcars)

x = df.iloc[:,2:]

from sklearn.preprocessing import StandardScaler

pca = PCA(n_components=11)
principalComponents = pca.fit_transform(df)

#绘制每个 PC 的方差
PC = range(1, pca.n_components_+1)
plt.bar(PC, pca.explained_variance_ratio_, color=&#39;gold&#39;)
plt.xlabel(&#39;Principal Components&#39;)
plt.ylabel(&#39;Variance %&#39;)
plt.xticks(PC)


如何将 PCA 1 和 2 映射回数据框中的原始特征？]]></description>
      <guid>https://stackoverflow.com/questions/67585809/how-to-map-the-results-of-principal-component-analysis-back-to-the-actual-featur</guid>
      <pubDate>Tue, 18 May 2021 12:04:25 GMT</pubDate>
    </item>
    <item>
      <title>用 -99999 替换 nan 值有意义吗？</title>
      <link>https://stackoverflow.com/questions/61049335/does-it-make-sense-to-replace-nan-values-by-99999</link>
      <description><![CDATA[如何用值 -99999 替换数据框中的 nan 值？我在这里找到了它，示例 3：https://www.geeksforgeeks.org/python-pandas-dataframe-replace/ 
df.replace(to_replace = np.nan, value =-99999)
也许 -99999 应该仅表示 -infinite，但此操作背后可能有什么意图？有什么想法或猜测吗？:/
我很感激任何建议！]]></description>
      <guid>https://stackoverflow.com/questions/61049335/does-it-make-sense-to-replace-nan-values-by-99999</guid>
      <pubDate>Sun, 05 Apr 2020 20:51:23 GMT</pubDate>
    </item>
    <item>
      <title>如何计算最佳批次大小？</title>
      <link>https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size</link>
      <description><![CDATA[有时我会遇到一个问题：
分配形状为
的张量时发生 OOM
例如
分配形状为 (1024, 100, 160) 的张量时发生 OOM

其中 1024 是我的批处理大小，我不知道其余的是多少。如果我减少批处理大小或模型中的神经元数量，它就会运行良好。
是否有一种通用方法可以根据模型和 GPU 内存计算最佳批处理大小，这样程序就不会崩溃？
简而言之：我希望我的模型的批处理大小尽可能大，这将适合我的 GPU 内存并且不会使程序崩溃。]]></description>
      <guid>https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size</guid>
      <pubDate>Mon, 09 Oct 2017 20:25:09 GMT</pubDate>
    </item>
    </channel>
</rss>