<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 26 Jan 2025 12:28:41 GMT</lastBuildDate>
    <item>
      <title>如何将 5 个训练模型组合成一个模型，并使用组合模型进行预测？</title>
      <link>https://stackoverflow.com/questions/79388433/how-can-i-combine-5-trained-models-into-a-single-one-and-use-the-combined-model</link>
      <description><![CDATA[我必须实现联合学习。因此，我训练了 5 个模型的列表，并在不同的数据集上训练了每个模型。现在我必须将列表中训练过的模型组合起来，但我不知道该怎么做。之后我必须使用组合模型对测试集进行预测。
class MulticlassClassification:
def __init__(self, input_dims, layer, num_classes):
self.model = Sequential(name=&quot;server_model&quot;)
self.model.add(Dense(
layer[0],
input_shape=(input_dims,),
activation=&#39;relu&#39;
))
for l in layer[1:]:
self.model.add(Dense(l,activation=&#39;relu&#39;))
self.model.add(Dense(num_classes,activation=&#39;softmax&#39;))
self.model.compile(
loss=&#39;sparse_categorical_crossentropy&#39;,
optimizer=&#39;adam&#39;,
metrics=[&#39;accuracy&#39;]
)
self.model.summary()
def set_avg_weights(self,模型):
all_weights = np.array([
model.model.get_weights()
for model in models
])
avg_weights = np.mean(all_weights, axis=0)
self.model.set_weights(avg_weights)

all_weights = np.array([
model.model.get_weights()
for model in models
])
avg_weights = np.mean(all_weights, axis=0)
self.model.set_weights(avg_weights)
def fit(self, X, Y, epochs, batch_size):
self.model.fit(X, Y.to_numpy(), epochs=epochs, batch_size=batch_size)

def predict(self, X, Y):
preds = self.model.predict(X)
preds = [np.argmax(p) for p in preds]
print(classification_report(Y, preds))
ConfusionMatrixDisplay.from_predictions(Y, preds)

#同时进行预处理和训练
label_encoder = preprocessing.LabelEncoder()
model = []
for i in range(5):
model.append(MulticlassClassification(27, [20, 20, 20], num_classes=5))
for i in range(5):
file_path = os.path.join(folder_path, nodes_list[i])
df = pd.read_csv(file_path)
df=df.drop([&#39;FLAGS&#39;],axis=1)
df[&#39;PKT_TYPE&#39;]=label_encoder.fit_transform(df[&#39;PKT_TYPE&#39;])
df[&#39;PKT_CLASS&#39;]=label_encoder.fit_transform(df[&#39;PKT_CLASS&#39;])
df[&#39;NODE_NAME_TO&#39;]=label_encoder.fit_transform(df[&#39;NODE_NAME_TO&#39;])
df[&#39;NODE_NAME_FROM&#39;]=label_encoder.fit_transform(df[&#39;NODE_NAME_FROM&#39;])
print(df[&#39;PKT_TYPE&#39;].unique())
print(df[&#39;NODE_NAME_FROM&#39;].unique())
print(df[&#39;NODE_NAME_TO&#39;].unique())
print(df[&#39;PKT_CLASS&#39;].unique())
X=df.drop([&#39;PKT_CLASS&#39;],axis=1)
Y=df[&#39;PKT_CLASS&#39;]
X1, X2, Y1, Y2= train_test_split(X, Y, train_size=0.9984375, random_state=1)
model[i].fit(X1, Y1, epochs=20, batch_size=32)

#现在我必须将列表 model[] 中的所有模型合并为一个。怎么做？
#然后我必须使用新模型预测测试集。```
]]></description>
      <guid>https://stackoverflow.com/questions/79388433/how-can-i-combine-5-trained-models-into-a-single-one-and-use-the-combined-model</guid>
      <pubDate>Sun, 26 Jan 2025 11:30:49 GMT</pubDate>
    </item>
    <item>
      <title>用时间链接表示特征的 ML 模型类型</title>
      <link>https://stackoverflow.com/questions/79388422/type-of-ml-model-to-represent-features-with-a-time-link</link>
      <description><![CDATA[我正在尝试建立一个模型来预测合同的价格。合约在特定日期具有特定事件和状态。
例如：
2025/01/10 - 波动率：1.2，障碍：1.5，息票 1.1
2025/01/14 - 波动率：0.9，障碍：1.55，息票 1.15
简要解释是，当达到障碍时，息票就会支付。
每个事件日期都有 15 个特征，包括该日期的市场状态以及波动性和远期价格等财务参数。
我希望能够将可变长度序列（不同的合约可能具有不同的障碍日期/息票日期数量）放入网络并获得价格。
首先，我对所有内容进行了标准化，包括标准化为合约长度的时间点
起初我想使用 LSTM，但 LSTM 用于预测序列数据。这不是连续数据，因为前一个时间步骤与下一个时间步骤无关。尽管每个特征都有一个时间相关维度，因为每个特征都与某个时间点相关联
在这种情况下我应该使用哪种技术？]]></description>
      <guid>https://stackoverflow.com/questions/79388422/type-of-ml-model-to-represent-features-with-a-time-link</guid>
      <pubDate>Sun, 26 Jan 2025 11:23:17 GMT</pubDate>
    </item>
    <item>
      <title>如何将grain.IterDataset链接在一起？</title>
      <link>https://stackoverflow.com/questions/79387801/how-to-chain-grain-iterdataset-together</link>
      <description><![CDATA[这是一个关于grain的问题，grain是用于数据提取的python库。https://google-grain.readthedocs.io/en/latest/index.html
在强化学习的背景下，我有一个数据预处理步骤，其中我将比赛重播作为单独的文件，预处理为JAX数组，然后进行处理。
如果有一个库可以理解转换JAX数组列表的逻辑，并将它们捆绑在一起形成序列以训练循环网络，并捆绑成批次以进行梯度下降，那就太好了。
我想我几乎拥有所有组件。我已经实现了一个ReplayDataSource，它是grain.RandomAccessDataSource的子类，它可以打开并将比赛文件预处理到内存中。我已经实现了一个 Sampler，它返回连续的索引来构建序列。使用一个数据源，我就可以得到我需要的一切（示意图）
source = ReplayDataSource( ... )
transformations = [grain.Batch(batch_size)]
sampler = MySampler( ... )

data_loader = Grain.DataLoader(
data_source = source,
sampler = sampler,
operations = transformations,
shard_options=grain.NoSharding(),
)

这将为我的数据集添加 2 个外部维度，一个用于序列，另一个用于批次。太棒了！
缺少一个元素。如果我有 1000 个重播文件，但无法全部加载到内存中，那么我该如何告诉 DataLoader 将 ReplayDataSources 实例化加载到内存中，并在需要时删除它们，因为我会迭代 DataLoader 的元素？
我尝试在 DataLoader 参数上使用 source = [source1, source2]，但没有成功。我尝试使用数据源制作 MapDataset，但我也不知道如何编写它们。IterDataset 也是一样。
我真正关心的唯一粒度功能是序列和批次。如何创建由制作重播文件组成的数据集，并仅在需要时打开它们？]]></description>
      <guid>https://stackoverflow.com/questions/79387801/how-to-chain-grain-iterdataset-together</guid>
      <pubDate>Sun, 26 Jan 2025 00:51:32 GMT</pubDate>
    </item>
    <item>
      <title>评估期间出现断言错误：Detectron2 RetinaNet 微调中预测的类别 ID 超出范围</title>
      <link>https://stackoverflow.com/questions/79387630/assertionerror-during-evaluation-predicted-class-id-out-of-range-in-detectron2</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79387630/assertionerror-during-evaluation-predicted-class-id-out-of-range-in-detectron2</guid>
      <pubDate>Sat, 25 Jan 2025 22:27:24 GMT</pubDate>
    </item>
    <item>
      <title>函数调用 Google GEMINI AI- TypeError：输入类型无效。预期为“genai.FunctionDeclarationType”的实例</title>
      <link>https://stackoverflow.com/questions/79387529/function-calling-google-gemini-ai-typeerror-invalid-input-type-expected-an-in</link>
      <description><![CDATA[我正在尝试使用 iris 数据集运行一个简单的随机森林分类模型并将其集成到 Gemini AI 中
这是我的代码：
import google.generativeai as genai
from vertexai.preview.generative_models import (

FunctionDeclaration,
GenerativeModel,
Part,
Tool,
)

genai.configure(api_key=&quot;API KEY&quot;)

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# 加载并训练模型
iris = load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

def predict_iris_species(sepal_length, sepal_width, petal_length, petal_width):
&quot;&quot;&quot;
根据萼片和花瓣测量值预测鸢尾花种类。

参数：
sepal_length (float)：萼片长度（厘米）。
sepal_width (float)：萼片宽度（厘米）。
petal_length (float)：花瓣长度（厘米）。
petal_width (float)：花瓣宽度（厘米）。

返回：
str：预测的鸢尾花种类。
&quot;&quot;&quot;
input_data = [[sepal_length, sepal_width, petal_length, petal_width]]
prediction = model.predict(input_data)
return str(iris.target_names[prediction[0]])

tools = Tool(
function_declarations=[
FunctionDeclaration(
name=&quot;predict_iris_species&quot;,
description=&quot;根据萼片和花瓣测量值预测鸢尾花种类&quot;,
parameters={
&quot;type&quot;: &quot;object&quot;,
&quot;properties&quot;: {
&quot;sepal_length&quot;: {&quot;type&quot;: &quot;number&quot;, &quot;description&quot;: &quot;长度（厘米）&quot;},
&quot;sepal_width&quot;: {&quot;type&quot;: &quot;number&quot;, &quot;description&quot;: &quot;萼片宽度（厘米）&quot;},
&quot;petal_length&quot;: {&quot;type&quot;: &quot;number&quot;, &quot;description&quot;: &quot;花瓣长度（厘米）&quot;},
&quot;petal_width&quot;: {&quot;type&quot;: &quot;number&quot;, &quot;description&quot;: &quot;花瓣宽度（厘米）&quot;}
},
&quot;required&quot;: [&quot;sepal_length&quot;, &quot;sepal_width&quot;, &quot;petal_length&quot;, &quot;petal_width&quot;]
}
)
]
)

llm = genai.GenerativeModel(model_name=&#39;gemini-1.5-flash&#39;,
tools=[tools])

chat = llm.start_chat()
response = chat.send_message(&quot;萼片长度 5.1、萼片宽度 3.5、花瓣长度 1.4、花瓣宽度 0.2 的鸢尾花属于什么品种？&quot;)
response.text

我收到一条错误消息：
TypeError：输入类型无效。应为 `genai.FunctionDeclarationType` 的实例。
但是，收到一个类型为：&lt;class &#39;vertexai.generative_models._generative_models.Tool&#39;&gt; 的对象。
对象值：function_declarations {
...
property_ordering：&quot;petal_length&quot;
property_ordering：&quot;petal_width&quot;
}
}

这是什么意思？我以为这就是你格式化 JSON 数据的方式？是不是我的 predict_iris_species 函数需要返回其他内容而不是 字符串？
是不是因为它需要输出 JSON 字典？]]></description>
      <guid>https://stackoverflow.com/questions/79387529/function-calling-google-gemini-ai-typeerror-invalid-input-type-expected-an-in</guid>
      <pubDate>Sat, 25 Jan 2025 21:07:11 GMT</pubDate>
    </item>
    <item>
      <title>如何让我的 ML 模型只优化尾部</title>
      <link>https://stackoverflow.com/questions/79387317/how-can-i-get-my-ml-model-to-only-optimize-the-tails</link>
      <description><![CDATA[我正在研究一个不平衡的分类模型（5% 少数类），并且只关心输出分布的尾部。我想知道数据中最好的 10% 和最差的 10%。我尝试在 GBM 训练中使用贝叶斯搜索，该搜索使用 ROC AUC 的尾部作为搜索优化器，但还有更好的办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79387317/how-can-i-get-my-ml-model-to-only-optimize-the-tails</guid>
      <pubDate>Sat, 25 Jan 2025 18:50:34 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 上的 GPU 利用率较低，且无明显瓶颈</title>
      <link>https://stackoverflow.com/questions/79387312/low-gpu-utilization-on-pytorch-without-obvious-bottlenecks</link>
      <description><![CDATA[我正在一个相当简单的深度学习网络（~800kb）上进行训练。
具有 2 层和 128 个神经元的 LSTM，
具有 2 个线性层和 64 个神经元的前馈，
具有 2 个线性层和 64 个神经元的最终前馈，
但是，当我在 RTX 6000 上查看 nvidia-smi 时，我的 GPU 利用率较低，约为 45% 和 140W
我不确定为什么会出现这种情况，因为不应该存在瓶颈，因为数据全部加载到内存中，并且我将张量直接发送到 GPU。因此，GPU 正在对批处理大小进行改组和切片（之前我在 CPU（64 核 Ryzen Threadripper）上执行此操作，但 CPU 已达到最大容量，因此它是瓶颈）。
对于 200 万个输入（每个输入约 1000 个特征），它在我的 RTX 6000 上使用 24GB 中的约 18GB GPU 内存
我使用的批处理大小为 1024，每个时期大约需要 60 秒。训练速度似乎与批处理大小成线性关系，因为 512 大约需要 120 秒，而 2048 需要 33 秒。
我的前向/后向传递是标准的 pytorch 实现。
当我添加 torch.cuda.amp.autocast/GradScaler 和 torch.backends.cudnn.benchmark = True 时，我的利用率和瓦数下降了，但每个时期的时间保持不变。
我想知道您是否可以帮助我排除故障，因为我需要尽快训练这个模型。我还会遇到数据太多而无法放入 GPU（但可以放入 RAM）的问题，因此任何有关有效解决方案的帮助也将不胜感激。我以前使用过 DataLoaders/Dataset，但它真的很慢，当 pinned_memory 和 num_workers &gt; 0 时甚至更慢。
谢谢！如果需要任何进一步的信息，请告诉我]]></description>
      <guid>https://stackoverflow.com/questions/79387312/low-gpu-utilization-on-pytorch-without-obvious-bottlenecks</guid>
      <pubDate>Sat, 25 Jan 2025 18:48:43 GMT</pubDate>
    </item>
    <item>
      <title>y 只有 4 个或更少的值，而我的预处理 DataFrame 有超过 4,000 行。回归可能吗？</title>
      <link>https://stackoverflow.com/questions/79386587/y-has-only-four-values-or-less-while-my-preprocessed-dataframe-has-more-than-4</link>
      <description><![CDATA[我的数据集是根据首尔某个特定地区的单人家庭数量来预测该地区的美食数量。
问题：原始数据的行数超过 100,000。但是，我必须分析 2 个限制区域，每个区域有 2 个真实值。
我使用了无监督学习（KMeans Clustering）、引导程序，并故意给出噪音以适应模型。但似乎不起作用。有人能告诉我如何解决这个问题吗？
我的导师希望我建立一个回归模型。
但看起来这是不可能的，就像 chatGPT 说了 20 次一样。
代码（带有任意噪声的 y，每 2 个群集的 r2_score 为 97.8%，但被拒绝）：
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(&quot;ignore&quot;)
\# 加载数据 rest_data_path = &#39;서울시 휴게음식점 인허가 정보.csv&#39;
one_person_data_path = &#39;1인가구(연령별).csv&#39;
rest_data = pd.read_csv(rest_data_path, encoding=&#39;utf-8&#39;)
one_person_data = pd.read_csv(one_person_data_path, encoding=&#39;utf-8&#39;)

# 预处理数据
one_person_data = one_person_data.rename(columns={&#39;자치구별(2)&#39;: &#39;자치구&#39;})
one_person_data_cleaned = one_person_data[one_person_data[&#39;자치구&#39;] != &#39;자치구별(2)&#39;]
one_person_data_cleaned[&#39;2023_합계&#39;] = one_person_data_cleaned.loc[:, &#39;2023&#39;:&#39;2023.15&#39;].apply(
pd.to_numeric, errors=&#39;coerce&#39;).sum(axis=1)
one_person_summary = one_person_data_cleaned[[&#39;자치구&#39;, &#39;2023_합계&#39;]]

rest_data_cleaned = rest_data.rename(columns={&#39;지번주소&#39;: &#39;주소&#39;})
rest_data_cleaned[&#39;자치구&#39;] = rest_data_cleaned[&#39;주소&#39;].str.split(&#39; &#39;).str[1]

merged_data = pd.merge(rest_data_cleaned, one_person_summary, on=&#39;자치구&#39;, how=&#39;left&#39;)

# 添加噪音
np.随机.种子(42) 
噪声 = np.random.normal(0, 0.05 * merged_data[&#39;2023_합계&#39;].std(),大小=merged_data.shape[0])
merged_data[&#39;y&#39;] = merged_data[&#39;2023_합계&#39;] + 噪声

# 保存数据
result_continuous = merged_data[[&#39;자치구&#39;, &#39;주소&#39;, &#39;2023_합계&#39;, &#39;y&#39;]].dropna()

＃ 输出
结果_连续&#39;

输出
&lt;块引用&gt;
 자치구 주소 2023_합계 y


&lt;块引用&gt;
\5 관악구 서울특별시 관악구 봉천동 1562-17 159036.0 158422.996610
\6 관악구 서울특별시 관악구 봉천동 1562-17 142454.0 146588.600626
\18 관악구 서울특별시 관악구 신림동 1538-14 159036.0 156658.665625
\19 관악구 서울특별시 관악구 신림동 1538-14 142454.0 138756.390843
\46 관악구 서울특별시 관악구 신림동 1519-22 159036.0 157829.983096
\... ... ... ... 
\142131 도봉구 서울특별시 도봉구 창동 808 동아청솔아파트 상і동 209호 46250.0 43593.821116
\142138 관악구 서울특별시 관악구 신림동 1458-4 센트레빌 13차 159036.0 157758.991278
\142139 관악구 서울특별시 관악구 신림동 1458-4 센트레빌 13차 142454.0 140637.617424
\142142  관악구 서울특별시 관악구 봉천동 928-1 우형빌딩 159036.0 158889.888720
\142143 관악구 서울특별시 관악구 봉천동 928-1 우형빌딩 142454.0 142926.767535
\14162行×4列\

from sklearn.preprocessing import OneHotEncoder
从 sklearn.preprocessing 导入StandardScaler

columns_to_encode = [&#39;자치구&#39;]

columns_to_exclude = [&#39;2023_합계&#39;]

encoder = OneHotEncoder(sparse_output=False) # drop=&#39;first&#39; 取消排序
encoded_columns =coder.fit_transform(result_continuous[columns_to_encode])
encoded_column_names =coder.get_feature_names_out(columns_to_encode)

encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names, index=result_continuous.index)

processed_data = result_continuous.drop(columns=columns_to_encode + columns_to_exclude)
final_data = pd.concat（[processed_data，encoded_df]，轴= 1）
Final_data[&#39;주소_hash&#39;] = result_continuous[&#39;주소&#39;].apply(hash)
Final_data = Final_data.drop(columns=[&#39;주소&#39;]) # 원래 주소 열 제거
y = np.log1p(final_data[[&#39;y&#39;]])
Final_data.drop([&#39;y&#39;], axis=1, inplace=True)
定标器=标准定标器()
Final_data_scaled = 缩放器.fit_transform(final_data)
最终数据缩放，y

输出
&lt;块引用&gt;
（数组（[[ 0.72281968,-0.72281968,1.14388039],
[0.72281968，-0.72281968，1.14388039]，
[0.72281968，-0.72281968，-0.74799056]，
...,
[0.72281968，-0.72281968，0.60622321]，
[0.72281968，-0.72281968，0.14385426]，
[0.72281968，-0.72281968，0.14385426]]），`
y
5 11.973030
6 11.895392
18 11.961831
19 11.840482
46 11.969280
... ...
142131 10.682694
142138 11.968830
142139 11.853949
142142 11.975973
142143 11.870095

[14162 行 x 1 列]]]></description>
      <guid>https://stackoverflow.com/questions/79386587/y-has-only-four-values-or-less-while-my-preprocessed-dataframe-has-more-than-4</guid>
      <pubDate>Sat, 25 Jan 2025 11:08:40 GMT</pubDate>
    </item>
    <item>
      <title>InvalidArgumentError：在 Google Colab 上训练 TensorFlow RetinaNet 模型时，流执行器中没有 DNN</title>
      <link>https://stackoverflow.com/questions/79377971/invalidargumenterror-no-dnn-in-stream-executor-while-training-a-tensorflow-reti</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79377971/invalidargumenterror-no-dnn-in-stream-executor-while-training-a-tensorflow-reti</guid>
      <pubDate>Wed, 22 Jan 2025 13:57:32 GMT</pubDate>
    </item>
    <item>
      <title>错误：在对象检测模型中，计算损失时，张量 a (810) 的大小必须与非单维 3 上的张量 b (36) 的大小匹配</title>
      <link>https://stackoverflow.com/questions/79364056/error-the-size-of-tensor-a-810-must-match-the-size-of-tensor-b-36-at-non-si</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79364056/error-the-size-of-tensor-a-810-must-match-the-size-of-tensor-b-36-at-non-si</guid>
      <pubDate>Fri, 17 Jan 2025 08:17:32 GMT</pubDate>
    </item>
    <item>
      <title>将多个模型指标运行记录到 MLFlow 中的同一个图中</title>
      <link>https://stackoverflow.com/questions/79308237/logging-multiple-model-metrics-runs-to-the-same-plot-in-mlflow</link>
      <description><![CDATA[我正在对模型参数进行网格搜索优化，并使用将损失记录到 MLFlow
Mlflow.log_metric(f“{run_number}_Loss”, returns, iteration)

但对于每次新运行，我在 MLFlow UI 中都会得到不同的图。
有没有办法多次记录到同一个图，也许是不同的颜色，并添加图例以便能够轻松比较不同的运行？]]></description>
      <guid>https://stackoverflow.com/questions/79308237/logging-multiple-model-metrics-runs-to-the-same-plot-in-mlflow</guid>
      <pubDate>Wed, 25 Dec 2024 19:50:23 GMT</pubDate>
    </item>
    <item>
      <title>如何从 TensorFlow Model Garden 中的自定义数据集训练的 RetinaNet ResNet50 模型获取预测并检索模型详细信息？</title>
      <link>https://stackoverflow.com/questions/79295907/how-do-i-get-predictions-from-a-custom-dataset-trained-retinanet-resnet50-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79295907/how-do-i-get-predictions-from-a-custom-dataset-trained-retinanet-resnet50-model</guid>
      <pubDate>Fri, 20 Dec 2024 00:12:30 GMT</pubDate>
    </item>
    <item>
      <title>在 Colab 中微调 Llama 3.1 时的上下文长度限制</title>
      <link>https://stackoverflow.com/questions/79104305/context-length-limitation-when-fine-tuning-llama-3-1-in-colab</link>
      <description><![CDATA[我正在通过 Unsloth 库，使用带有自定义数据集（使用 LoRA 技术）的 A100 GPU 在 Google Colab Pro 中对 Llama 3.1 模型进行微调。下面是我正在使用的 LoRA 代码：
max_seq_length = 2048
model = FastLanguageModel.get_peft_model(
model,
r=16, # 选择任意数字 &gt; 0 ！建议 8、16、32、64、128
target_modules=[&quot;q_proj&quot;, &quot;k_proj&quot;, &quot;v_proj&quot;, &quot;o_proj&quot;,
&quot;gate_proj&quot;, &quot;up_proj&quot;, &quot;down​​_proj&quot;],
lora_alpha=16,
lora_dropout=0, # 支持任意，但 = 0 是经过优化的
bias=&quot;none&quot;, # 支持任意，但 = &quot;none&quot; 是经过优化的

use_gradient_checkpointing=&quot;unsloth&quot;, # 对于非常长的上下文，为 True 或 &quot;unsloth&quot;
random_state=3407,
use_rslora=False, # 我们支持等级稳定的 LoRA
loftq_config=None, # 和 LoftQ
)
from trl import SFTTrainer
from transformers import TrainingArguments
from unsloth import is_bfloat16_supported
trainer = SFTTrainer(
model=model,
tokenizer=tokenizer,
train_dataset=dataset,
dataset_text_field=&quot;text&quot;,
max_seq_length=max_seq_length,
dataset_num_proc=2,
packing=False, # 可以使短序列的训练速度提高 5 倍。
args=TrainingArguments(
per_device_train_batch_size=2,
gradient_accumulation_steps=4,
warmup_steps=5,
# num_train_epochs = 1, # 将其设置为 1 次完整的训练运行。
max_steps=60,
learning_rate=2e-4,
fp16=not is_bfloat16_supported(),
bf16=is_bfloat16_supported(),
logs_steps=1,
optim=&quot;adamw_8bit&quot;,
weight_decay=0.01,
lr_scheduler_type=&quot;linear&quot;,
seed=3407,
output_dir=&quot;outputs&quot;,
),
)

加载模型时，我们必须指定最大序列长度，这会限制其上下文窗口。 Llama 3.1 支持最多 128k 的上下文长度，但在本例中我将其设置为 2048，因为它消耗更多的计算和 VRAM。此外，dtype 参数会自动检测您的 GPU 是否支持 BF16 格式，以便在训练期间获得更高的稳定性（此功能仅限于 Ampere 和较新的 GPU）。
我的问题：

如果我在训练时将 max_seq_length 设置为 2048，那么训练后我的模型的上下文长度是多少，128k 还是 2048？
训练模型后，我们可以使用 128k 的上下文长度吗，还是仍然限制为 2048？
]]></description>
      <guid>https://stackoverflow.com/questions/79104305/context-length-limitation-when-fine-tuning-llama-3-1-in-colab</guid>
      <pubDate>Sat, 19 Oct 2024 05:59:26 GMT</pubDate>
    </item>
    <item>
      <title>当我运行以下代码时，TypeError: JoypadSpace.reset() 得到了一个意外的关键字参数“seed”，我该如何解决这个问题？</title>
      <link>https://stackoverflow.com/questions/76509663/typeerror-joypadspace-reset-got-an-unexpected-keyword-argument-seed-when-i</link>
      <description><![CDATA[当我运行此代码时：
从 nes_py.wrappers 导入 JoypadSpace
导入 gym
导入 gym_super_mario_bros
从 gym_super_mario_bros.actions 导入 SIMPLE_MOVEMENT
从 gym.wrappers 导入 GrayScaleObservation
从 stable_baselines3.common.vec_env 导入 VecFrameStack、DummyVecEnv
从 matplotlib 导入 pyplot 作为 plt

env = gym_super_mario_bros.make(&#39;SuperMarioBros-v0&#39;,apply_api_compatibility=True,render_mode=&quot;human&quot;)
env = JoypadSpace(env, SIMPLE_MOVEMENT)
env = GrayScaleObservation(env,keep_dim=True)
env = DummyVecEnv([lambda:env])
env = VecFrameStack(env,4,channels_order=&#39;last&#39;)
state = env.reset()

我收到以下错误：

我应该如何修复此问题？]]></description>
      <guid>https://stackoverflow.com/questions/76509663/typeerror-joypadspace-reset-got-an-unexpected-keyword-argument-seed-when-i</guid>
      <pubDate>Mon, 19 Jun 2023 19:47:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pytorch Geometric 的超图卷积：RuntimeError：索引 2268264 超出了大小为 2268264 的维度 0 的界限</title>
      <link>https://stackoverflow.com/questions/69184856/hypergraph-convolution-using-pytorch-geometric-runtimeerror-index-2268264-is-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/69184856/hypergraph-convolution-using-pytorch-geometric-runtimeerror-index-2268264-is-o</guid>
      <pubDate>Tue, 14 Sep 2021 21:48:03 GMT</pubDate>
    </item>
    </channel>
</rss>