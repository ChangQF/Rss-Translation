<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 16 Mar 2024 09:12:23 GMT</lastBuildDate>
    <item>
      <title>我在梯度提升模型中收到此错误“AttributeError：'HalfSquaredError'对象没有属性'get_init_raw_predictions'”</title>
      <link>https://stackoverflow.com/questions/78171146/i-am-getting-this-error-attributeerror-halfsquarederror-object-has-no-attrib</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78171146/i-am-getting-this-error-attributeerror-halfsquarederror-object-has-no-attrib</guid>
      <pubDate>Sat, 16 Mar 2024 08:56:45 GMT</pubDate>
    </item>
    <item>
      <title>yolo 通过绘制边界点进行脊柱标记训练</title>
      <link>https://stackoverflow.com/questions/78170933/yolo-training-for-spine-labeling-by-plotting-boundary-points</link>
      <description><![CDATA[我正在检查如何通过使用 yolo 在 CT 脊柱图像上标记边界点来实现如图所示的预测。
我正在尝试使用 yolo v8，任何有关如何启动注释的指示都会有所帮助。谢谢
带有预测的结果/预期图像]]></description>
      <guid>https://stackoverflow.com/questions/78170933/yolo-training-for-spine-labeling-by-plotting-boundary-points</guid>
      <pubDate>Sat, 16 Mar 2024 07:32:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 opencv / python / 任何 AI/ML 模型检测并提取二值图像中的四边形的四个点</title>
      <link>https://stackoverflow.com/questions/78170927/detect-and-extract-four-points-of-quadrilaterals-in-an-binary-image-using-opencv</link>
      <description><![CDATA[我有这样的二进制分段蒙版图像：

我想从这样的图像中检测四边形的四个坐标：

output object = [ ( (x11,y11), (x12,y12), (x13,y13), (x14,y14) ) , # 第一个四边形
                  ( (x21,y21), (x22,y22), (x23,y23), (x24,y24) ) ] # 第二个四边形

我尝试过使用边缘检测技术的文档扫描方法，但无法找到四边形的四个点。]]></description>
      <guid>https://stackoverflow.com/questions/78170927/detect-and-extract-four-points-of-quadrilaterals-in-an-binary-image-using-opencv</guid>
      <pubDate>Sat, 16 Mar 2024 07:30:32 GMT</pubDate>
    </item>
    <item>
      <title>从二维输入预测多个输出的回归问题</title>
      <link>https://stackoverflow.com/questions/78170872/the-regression-problem-of-predicting-multiple-outputs-from-two-dimensional-input</link>
      <description><![CDATA[我有几个二维图表，每个图表都有八个独特的数字特征，可用于生成这些图表。我以大量 .csv 文件的形式拥有所有这些图表的 x 和 y 坐标及其数值特征。我想通过使用机器学习或深度学习模型来预测每个图的数值特征（通过使用图的图像或使用每个图的点的坐标）
到目前为止，我已经寻找了许多预训练模型，并在 HuggingFace 等网站上搜索了此类模型，还在 GitHub 代码中搜索了很多。我还在 paperswithcode 网站上搜索了做过同样事情的文章，但不幸的是，我仍然没有找到任何东西！我曾多次尝试自己编写一个网络，但由于这样做的复杂性以及对如何设置网络的超参数以达到预期结果的了解不够，我遇到了很多错误并且无法做到这一点！
有人知道我该怎么做吗？如果您能为我提供任何帮助来完成此操作，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78170872/the-regression-problem-of-predicting-multiple-outputs-from-two-dimensional-input</guid>
      <pubDate>Sat, 16 Mar 2024 07:03:13 GMT</pubDate>
    </item>
    <item>
      <title>删除点云中的底层</title>
      <link>https://stackoverflow.com/questions/78170818/remove-base-floor-in-point-cloud</link>
      <description><![CDATA[我有沙堆 3d 点云的 .obj 文件。它包含底层点和沙堆点。我需要移除底层点并仅过滤沙堆。有相关的 Matlab 或 Python 代码吗？
我尝试了一些使用 python 的代码。但它不正确。]]></description>
      <guid>https://stackoverflow.com/questions/78170818/remove-base-floor-in-point-cloud</guid>
      <pubDate>Sat, 16 Mar 2024 06:31:22 GMT</pubDate>
    </item>
    <item>
      <title>深度学习 NCAAB 模型建议</title>
      <link>https://stackoverflow.com/questions/78170803/deep-learning-ncaab-model-suggestions</link>
      <description><![CDATA[我致力于学习和探索更深入地构建人工智能模型，并通过体育来实现这一目标。我正在根据上个赛季的数据预测一支球队将在哪一轮退出比赛。我已经做到了这一点，但我能达到的最高准确度约为 50-52%。我玩过很多很多功能，更多的层，神经元，纪元等等......请任何建议都会很棒。这是代码和头部数据。
from sklearn.model_selection import train_test_split
从 sklearn.preprocessing 导入 StandardScaler、LabelEncoder
将张量流导入为 tf
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入密集，输入，丢失
从tensorflow.keras.regularizers导入l2
从tensorflow.keras.optimizers导入Adam
从tensorflow.keras.callbacks导入EarlyStopping
从tensorflow.keras.callbacks导入LearningRateScheduler
从tensorflow.keras.layers导入BatchNormalization
从 sklearn.preprocessing 导入 MinMaxScaler


np.随机.种子(42)
tf.random.set_seed(42)


def lr_schedule(epoch, lr):
    如果纪元&gt; 5：
        lr = lr * 0.5 # 每5个epoch将学习率降低一半
    return max(lr, 1e-5) # 确保 lr 不会低于某个阈值

# 初始化学习率调度器回调
lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)

# 加载数据集
df = pd.read_csv(&#39;final_madness.csv&#39;)

# 过滤出2024年的数据
df_filtered = df[df[&#39;年份&#39;] != 2024]

# 特征和目标变量，不包括“TEAM”和“YEAR”
X = df_filtered.drop([&#39;ROUND&#39;, &#39;TEAM&#39;, &#39;YEAR&#39;, &quot;CONF&quot;, &quot;CONF ID&quot;, &quot;QUAD ID&quot;, &quot;TEAM NO&quot;, &quot;TEAM ID&quot;, &quot;&quot;四号”]，轴=1)
打印（X.head（））

y = df_filtered[&#39;圆形&#39;]
打印（y.head（））

# 将数据集分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)

# 实例化 StandardScaler
定标器=标准定标器()

# 在训练数据上拟合缩放器
X_train_scaled = 缩放器.fit_transform(X_train)

# 转换训练集和测试集
X_test_scaled = 缩放器.transform(X_test)

# 初始化编码器
编码器 = LabelEncoder()

# 拟合并变换 y_train 以对标签进行编码
y_train_encoded = 编码器.fit_transform(y_train)

# 使用相同的编码器转换 y_test
y_test_encoded = 编码器.transform(y_test)


# 检查编码后的目标
label_mapping = dict(zip(encoder.classes_, range(len(encoder.classes_))))

模型=顺序（[
    输入(形状=(X_train_scaled.shape[1],)),
    密集（64，kernel_regularizer = l2（0.001）），
    密集（32，kernel_regularizer = l2（0.001）），
    批量归一化(),
    Dropout(0.4), # 添加批量归一化后调整 dropout
    密集（len（np.unique（y_train_encoded）），激活=&#39;softmax&#39;）
]）

选择=亚当（学习率=0.001）
model.compile(loss=&#39;sparse_categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;],optimizer=opt)
打印（模型.摘要（））

Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 8，restore_best_weights = True）

# 将批量大小更新为 32
历史= model.fit（X_train_scaled，y_train_encoded，epochs = 100，batch_size = 64，validation_split = 0.2，callbacks = []）

plt.plot(history.history[&#39;准确度&#39;])
plt.plot(history.history[&#39;val_accuracy&#39;])
plt.title(&#39;模型精度&#39;)
plt.ylabel(&#39;准确率&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.legend([&#39;训练&#39;, &#39;测试&#39;], loc=&#39;左上&#39;)
plt.show()

# 情节训练&amp;验证损失值
plt.plot(history.history[&#39;loss&#39;])
plt.plot(history.history[&#39;val_loss&#39;])
plt.title(&#39;模型损失&#39;)
plt.ylabel(&#39;损失&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.legend([&#39;训练&#39;, &#39;测试&#39;], loc=&#39;左上&#39;)
plt.show()

# 根据测试数据评估模型
test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_encoded)

print(&quot;测试损失：&quot;, test_loss)
print(&quot;测试准确度：&quot;, test_accuracy)

]]></description>
      <guid>https://stackoverflow.com/questions/78170803/deep-learning-ncaab-model-suggestions</guid>
      <pubDate>Sat, 16 Mar 2024 06:28:36 GMT</pubDate>
    </item>
    <item>
      <title>实时检测在YOLOv8中播放音频文件</title>
      <link>https://stackoverflow.com/questions/78170802/playing-audio-file-in-yolov8-in-real-time-detection</link>
      <description><![CDATA[我正在 YOLOv8 项目中工作，以检测困倦并在检测到困倦时播放警报音频文件。我面临的问题是我无法实时播放音频，因为我的检测首先存储在结果中。一旦我关闭检测窗口，它就会访问结果中存储的数据并连续播放音频。我该如何解决这个问题？
导入操作系统
从 ultralytics 导入 YOLO

进口火炬
导入 matplotlib
将 numpy 导入为 np
导入CV2
导入pygame

pygame.init()
sound_to_play = pygame.mixer.Sound(r&#39;D:\ML\同步警惕驱动程序\alarm.wav&#39;)
sound_to_play.play()

模型 = YOLO(r&#39;C:\Users\HP\Downloads\last.pt&#39;)

上限 = cv2.VideoCapture(0)
而真实：
    ret, 框架 = cap.read()

    结果 = model.predict(source=“0”,show=True)
    对于结果中的 r：
        如果 len(r.boxes.cls)&gt;0:
            dclass=r.boxes.cls[0].item()
            打印（d类）
            如果 dclass==2.0:
              sound_to_play.play()
    如果 cv2.waitKey(1) == ord(&#39;q&#39;):
        休息

pygame.quit()
cap.release()
cv2.destroyAllWindows()

&lt;块引用&gt;
问题是我的代码首先进行检测并将其存储在结果中，然后进入 for 循环
预期输出是它同时检测并检查类值
]]></description>
      <guid>https://stackoverflow.com/questions/78170802/playing-audio-file-in-yolov8-in-real-time-detection</guid>
      <pubDate>Sat, 16 Mar 2024 06:28:04 GMT</pubDate>
    </item>
    <item>
      <title>构建 SVM 模型</title>
      <link>https://stackoverflow.com/questions/78170776/building-an-svm-model</link>
      <description><![CDATA[我有一个由 254k 个实例组成的数据集，由于目标列不平衡，我决定对其进行过采样，结果得到了 436k 个实例。我应该考虑欠采样吗？或者我应该对数据集进行下采样，因为 SVM 往往在相对较小的数据集上工作得更好？或者 436k 可以吗？
尝试构建 SVM，但计算时间太长。]]></description>
      <guid>https://stackoverflow.com/questions/78170776/building-an-svm-model</guid>
      <pubDate>Sat, 16 Mar 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：无法将字符串转换为浮点数：'alfa-romero'</title>
      <link>https://stackoverflow.com/questions/78170755/valueerror-could-not-convert-string-to-float-alfa-romero</link>
      <description><![CDATA[当我弹出上述错误时，我正在尝试定义一个相关矩阵。
该列的 dtype 被定义为对象，但我不知道为什么它将它作为字符串。
感谢任何有关如何纠正此问题的线索
[Dtypes说明](https://i.stack.imgur.com/FNOpq.png)]]></description>
      <guid>https://stackoverflow.com/questions/78170755/valueerror-could-not-convert-string-to-float-alfa-romero</guid>
      <pubDate>Sat, 16 Mar 2024 06:04:12 GMT</pubDate>
    </item>
    <item>
      <title>加载 json 模型时 Python tensorflow keras 错误：无法找到类“Sequential”</title>
      <link>https://stackoverflow.com/questions/78170750/python-tensorflow-keras-error-when-load-a-json-model-could-not-locate-class-se</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78170750/python-tensorflow-keras-error-when-load-a-json-model-could-not-locate-class-se</guid>
      <pubDate>Sat, 16 Mar 2024 05:59:37 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统基于内容的过滤模型 - 组合相似度矩阵[关闭]</title>
      <link>https://stackoverflow.com/questions/78170382/recommendation-system-content-based-filtering-model-combine-similarity-matrice</link>
      <description><![CDATA[我第一次使用 python ML 构建电影推荐器。我有一个具有各种属性的电影数据集，以及基于不同属性组的 5 个相似度矩阵。例如，1 个模型显示基于电影标题和情节的相似性向量，另一个模型基于演员阵容等。通过这些，我可以根据 5 组不同的特征找到与输入标题最相似的前 x 部电影。
我的问题是如何组合这 5 个矩阵或其输出来创建一个统一的模型？我读过有关 python 和随机森林中的集成的内容，但我不确定如何在这里应用它们。我有一个名为“likeage”的列，它以数字表示用户是否喜欢某部电影，那么我如何构建一个模型来预测这一点呢？
任何建议或相关文献将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78170382/recommendation-system-content-based-filtering-model-combine-similarity-matrice</guid>
      <pubDate>Sat, 16 Mar 2024 02:05:46 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型仅返回 0 分。我做错了什么？</title>
      <link>https://stackoverflow.com/questions/78170278/the-machine-learning-models-are-only-returning-a-score-of-0-what-am-i-doing-wro</link>
      <description><![CDATA[在 Jupyter-Notebook 中，我创建了一个函数，可以对不同的 sklearn 机器学习模型进行拟合和评分。使用的数据集有超过 400000 行和 103 列，因此我分为两个不同的数据集：训练数据集和验证数据集。但是当我在函数中使用数据时，我想要测试的所有 4 个模型的得分均为 0。
这是我的代码：
# 分割数据集
df_val = df_tmp[df_tmp[&#39;年份&#39;] == 2012]
df_train = df_tmp[df_tmp[&#39;年份&#39;] != 2012]

# 将数据集分为训练和测试
X_train, y_train = df_train.drop(&#39;年&#39;, axis=1), df_train[&#39;年&#39;]
X_val, y_val = df_val.drop(&#39;年份&#39;, axis=1), df_val[&#39;年份&#39;]

# 将模型放入字典中
测试模型 = {
    “套索”：套索()，
    “ElasticNet”：ElasticNet()，
    “RandomForestRegressor”：RandomForestRegressor(),
    “山脊”：山脊()
}

# 创建函数来评估两个模型
def fit_and_score(test_models, X_train, X_val, y_train, y_val):
    
    # 记录模型分数的字典
    模型分数 = {}
    
    ＃ 环形
    for name, model in test_models.items(): # name, model = key, value
        # 拟合模型
        model.fit(X_train, y_train)
        # 评估模型并将其分数附加到 models_scores
        models_scores[名称] = model.score(X_val, y_val)
        
    返回模型分数

首先我想也许我没有正确编写函数，所以我单独测试了模型，它们仍然得分为 0。之后我决定测试是否我的数据有问题（我不认为这是它，bcz 我从一个旧的 Kaggle 竞赛中得到它，推土机竞赛），所以我用相同的数据训练并安装了一个模型，希望我的分数是 1，但我得到了 0.31。我真的不知道该怎么办]]></description>
      <guid>https://stackoverflow.com/questions/78170278/the-machine-learning-models-are-only-returning-a-score-of-0-what-am-i-doing-wro</guid>
      <pubDate>Sat, 16 Mar 2024 01:04:49 GMT</pubDate>
    </item>
    <item>
      <title>将 fit_resamples 与自定义分割数据一起使用？</title>
      <link>https://stackoverflow.com/questions/78167178/use-fit-resamples-with-custom-split-data</link>
      <description><![CDATA[我有一个自定义函数，可以根据各种标准和规则将数据分成训练集和测试集。我想在 tidymodels 工作流程中与 fit_resamples 一起使用此函数。但是，当我可以使我的列表看起来像用 vfold_cv 制作的列表时，它似乎不起作用。我正在使用的示例代码：
data(ames, package = “modeldata”)

split_data &lt;- 函数(df, n) {
  set.seed(123) # 为了重现性
  df$id &lt;- seq.int(nrow(df))
  list_of_splits &lt;- list()
  
  for(i in 1:n) {
    train_index &lt;- 样本(df$id, size=ceiling(nrow(df)*.8))
    train_set &lt;- df[train_index,]
    test_set &lt;- df[-train_index,]
    list_of_splits[[i]] &lt;- list(train_set = train_set, test_set = test_set)
  }
  
  返回（分割列表）
}

分割 &lt;- split_data(ames, 5)

重新采样 &lt;- map(splits, ~rsample::make_splits(
  x = .$train_set |&gt;选择(colnames(.$test_set)),
  评估=.$test_set
））

名称（重新采样）&lt;-paste0（“折叠”，seq_along（重新采样））

重新采样 &lt;- tibble::tibble(splits = 重新采样,
                            id = 名称（重新采样））

lm_model &lt;-
  Linear_reg() %&gt;%
  set_engine(“lm”)

lm_wflow &lt;-
  工作流程() %&gt;%
  add_model(lm_model) %&gt;%
  add_formula(Sale_Price ~ 经度 + 纬度)

res &lt;- lm_wflow %&gt;%
  fit_resamples（重新采样=重新采样）

运行最后一行后返回的错误是：
`check_rset()` 中出现错误：
！ “resamples”参数应该是一个“rset”对象，例如由“vfold_cv()”或其他“rsample”函数生成的类型。

如果我尝试强制该类“rset” class(resamples) &lt;- “rset”，列表看起来不再正确，我得到了相同的错误。
使用自定义交叉折叠数据集的正确方法是什么？
注意 - 附加问题：在上面的示例代码中，测试集和训练集的大小在折叠中是一致的。在我的实际数据中，这会略有不同 - 这有关系吗？]]></description>
      <guid>https://stackoverflow.com/questions/78167178/use-fit-resamples-with-custom-split-data</guid>
      <pubDate>Fri, 15 Mar 2024 13:11:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 提高蛋白质序列 SNP 分类的准确性</title>
      <link>https://stackoverflow.com/questions/78164309/improve-accuracy-on-protein-sequence-snp-classification-using-cnns</link>
      <description><![CDATA[我正在尝试使用卷积神经网络 (CNN) 对蛋白质序列单核苷酸多态性 (SNP) 进行分类。我的数据集由代表这些 SNP 序列的小波相干变换尺度图组成。然而，尽管尝试了各种 CNN 架构并利用迁移学习技术，我仍然无法在训练集和验证集上实现超过 62% 的准确率。数据集中的一些图像
如何处理图像高度相似的数据集？]]></description>
      <guid>https://stackoverflow.com/questions/78164309/improve-accuracy-on-protein-sequence-snp-classification-using-cnns</guid>
      <pubDate>Fri, 15 Mar 2024 02:01:00 GMT</pubDate>
    </item>
    <item>
      <title>Pytroch 分割模型(.pt) 未转换为 CoreML</title>
      <link>https://stackoverflow.com/questions/78091161/pytroch-segmentation-model-pt-not-converting-to-coreml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78091161/pytroch-segmentation-model-pt-not-converting-to-coreml</guid>
      <pubDate>Sat, 02 Mar 2024 01:26:48 GMT</pubDate>
    </item>
    </channel>
</rss>