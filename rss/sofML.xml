<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 12 Nov 2024 12:33:21 GMT</lastBuildDate>
    <item>
      <title>当我想运行 HuggingFace 模型时，Jupyter Notebook 崩溃了</title>
      <link>https://stackoverflow.com/questions/79181010/jupyter-notebook-is-crashing-when-i-want-to-run-huggingface-models</link>
      <description><![CDATA[我使用 Jupyter Notebook 运行 HuggingFace 的一些 ML 模型。
我使用的是 Mac（M2 芯片，内存 32 GB）
这是我的代码：
import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline

# 步骤 1：从 Hugging Face 的 Model Hub 中选择一个预先训练的 NER 模型
# 这里我们使用&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;，这是一个在 CoNLL-2003 数据集上微调的常见 NER 模型
model_name = &quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;

# 步骤 2：加载模型和标记器
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)

# 步骤 3：为 NER 设置管道
ner_pipeline = pipeline(&quot;ner&quot;, model=model, tokenizer=tokenizer, grouped_entities=True)

# 步骤 4：输入要执行 NER 的文本
text = &quot;Hugging Face Inc. 是一家位于纽约市的公司。其总部位于布鲁克林 DUMBO。&quot;

# 步骤 5：使用管道获取命名实体
entities = ner_pipeline(text)

# 步骤 6：打印已识别的实体
for entity in entities:
print(f&quot;Entity: {entity[&#39;word&#39;]}, Label: {entity[&#39;entity_group&#39;]}, Score: {entity[&#39;score&#39;]:.3f}&quot;)

在步骤 2 中，我的内核总是崩溃。我尝试了几种模型，但总是一样。这是错误：
内核重新启动
&lt;kernel name&gt; 的内核似乎已死。它将自动重新启动。

你能帮帮我吗？
我的内存没满，笔记本电脑是全新的。]]></description>
      <guid>https://stackoverflow.com/questions/79181010/jupyter-notebook-is-crashing-when-i-want-to-run-huggingface-models</guid>
      <pubDate>Tue, 12 Nov 2024 12:02:09 GMT</pubDate>
    </item>
    <item>
      <title>SVM 不适用于小型合成数据 - 三个点几乎位于同一条线上</title>
      <link>https://stackoverflow.com/questions/79180840/svm-doesnt-work-on-small-synthetic-data-three-points-almost-lie-on-the-same-l</link>
      <description><![CDATA[考虑以下数据：
X_train = np.array([[ 49, 7],
[196, 14],
[100, 10]]) 
y_train = np.array([1, 1, -1])

我的任务是在此数据上拟合线性 SVM。我使用的是 sklearn 中的 LinearSVC，但它无法在训练数据上达到准确率 1，并给出以下边界（图片）。
此数据是线性可分的，那么如何获得所需的两个类别的分界线？
]]></description>
      <guid>https://stackoverflow.com/questions/79180840/svm-doesnt-work-on-small-synthetic-data-three-points-almost-lie-on-the-same-l</guid>
      <pubDate>Tue, 12 Nov 2024 11:06:24 GMT</pubDate>
    </item>
    <item>
      <title>值错误：序列模型‘sequential_3’尚未定义输入形状</title>
      <link>https://stackoverflow.com/questions/79180267/value-error-sequential-model-sequential-3-has-no-defined-input-shape-yet</link>
      <description><![CDATA[导致“Sequential 模型没有定义的输入形状 1”错误的常见错误或遗漏是什么？
预处理层（如 resize_and_rescale 或 data_augmentation）是否会影响模型第一层的 input_shape？
Keras Sequential 模型第一层的 input_shape 参数的用途是什么？
input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
n_classes = 3

model = models.Sequential([
resize_and_rescale,
data_augmentation,
layer.Conv2D(32, kernel_size = (3,3),activation=&#39;relu&#39;, input_shape = input_shape),
layers.MaxPooling2D((2, 2)),
层。Conv2D（64，kernel_size =（3,3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，kernel_size =（3,3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Flatten（），
层。Dense（64，激活=&#39;relu&#39;），
层。Dense（n_classes，激活=&#39;softmax&#39;),
])

错误显示
值错误：顺序模型“sequential_3”尚未定义输入形状
]]></description>
      <guid>https://stackoverflow.com/questions/79180267/value-error-sequential-model-sequential-3-has-no-defined-input-shape-yet</guid>
      <pubDate>Tue, 12 Nov 2024 08:02:25 GMT</pubDate>
    </item>
    <item>
      <title>MLmetrics F1_Score 函数</title>
      <link>https://stackoverflow.com/questions/79179803/mlmetrics-f1-score-function</link>
      <description><![CDATA[我试图弄清楚当 y_pred 值非二进制时，MLmetrics 库中的 F1_Score 函数如何工作。
例如：
library(MLmetrics)
y &lt;- c(1,1,1,1,1,0,0,0,0,0)
x &lt;- c(1, 0.8, 0.654, 0.99, 0.75, 0.1, 0.3, 0.6, 0.05, 0.2)
x_preds &lt;- ifelse(x &lt; 0.5, 0, 1)
getF1 &lt;- F1_Score(y_true=y, y_pred=x, positive=&quot;1&quot;)
getF2 &lt;- F1_Score(y_true=y, y_pred=x_preds, positive=&quot;1&quot;)

print(getF1)
print(getF2)

给出 getF1=0.3333333 和 getF2 = 0.9090909
R 文档中提供的函数示例旨在计算我所称的 getF2，其中我已明确指定如何根据 0.5 阈值将概率分数分配给任一类标签。我不清楚的是，如果没有指定此阈值（getF1），它如何计算 F1 分数。有人能解释一下，如果保留概率分数，并且在调用 F1_Score 函数之前不将其转换为二进制，该函数默认会做什么吗？我无论如何也想不出它是如何得到 0.3333333 的。]]></description>
      <guid>https://stackoverflow.com/questions/79179803/mlmetrics-f1-score-function</guid>
      <pubDate>Tue, 12 Nov 2024 04:35:57 GMT</pubDate>
    </item>
    <item>
      <title>Vertex AI：Automl-tabular 模板不断给我一个错误</title>
      <link>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</link>
      <description><![CDATA[我正在尝试使用 Google 的 AutoML 产品 (VertexAI) 构建机器学习模型。
我已成功上传我的数据集 - 见下图。

但是，当我尝试使用 AutoML 模板为表格回归创建管道运行时，管道失败。我将在 VertexAI 上展示步骤，我只是使用默认设置而不进行任何更改：





我运行的第一个管道失败了。


我将调试 json 粘贴到 ChatGPT 中。它告诉我尝试将机器类型从 n1-standard-8 或 n1-highmem-8 更改为 n1-standard-4。我试过了，但管道仍然失败。我还确保计算服务已启用正确的设置。
]]></description>
      <guid>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</guid>
      <pubDate>Mon, 11 Nov 2024 11:41:07 GMT</pubDate>
    </item>
    <item>
      <title>提取 Swin-Vit 主干</title>
      <link>https://stackoverflow.com/questions/79177075/extracting-swin-vit-backbone</link>
      <description><![CDATA[我想知道是否有办法提取类似于 resnet 的 Swin-VIT 主干？
我正在尝试训练一些自监督学习算法，其中我只需要获取骨干（特征提取器）并将其传递给我的自监督学习算法（即修复 simCLR/SimSiam、Dino 到骨干）。
使用 resnet，这可以很容易地完成。
resnet = resnet50()
# 加载预训练权重：下面的函数只使用 torch.load 加载权重
resnet = load_model_weights(..., pretrained_weight_file, resnet, num_classes = 51)
# 提取没有 MLP Head 的主干
resnet_bb = torch.nn.Sequential(*list(resnet_bb_model.children())[:-1]) 
# 将主干合并到自监督模型

似乎没有像这样的简单解决方案swin-vit。我一直在使用这个存储库中的 Swin Transformer，因为它包含在大型遥感数据集上训练的预训练权重（在此处输入链接描述）
据我所知，您可以使用 swin_vit.forward_features() 获取 swin-vit 主干的输出
sys.path.append(&quot;RSP/Scene Recognition/models&quot;)
from swin_transformer import SwinTransformer

swin_vit = SwinTransformer()
# 加载预训练权重：仅使用 torch load 加载模型权重
swin_vit = load_model_weights(..., pretrained_weight_file, swin_vit, num_classes = 51)
# 此时，您可以使用 
out = swin_vit.forward_features(img_tensor) 获取特征

但是，我想知道是否有办法将 forward_features 作为单独的类来模仿 resnet_backbone。
原因是当我将它传递给我的自我监督学习算法时，就像这样...
class SimSiam(pl.lightningModule):
def __init__(..., backbone_model):
self.backbone_model = backbone_model
...

def forward(self, x):
f = self.backbone_model.forward_features(X) #(b,3,256,256) -&gt; ... -&gt; #(b, 768)
z = self.projection_head(f) # (b,768) -&gt; ... -&gt; (b,2048)
p = self.prediction_head(z) # (b,2048) -&gt; (b,512) -&gt; (b,2048) 
z = z.detach() #SimSiams 停止梯度以防止崩溃
return z,p
...

... 在训练自监督算法 (SimSiam) 期间，我会得到以下错误。原因是整个骨干模型被传递给 SimSiam 类，但该类只使用了 model.forward_features() 部分（即 Swin-vit 的其余部分，例如未使用的 MLP 头）。
[rank0]: RuntimeError: 看起来您的 LightningModule 具有未用于产生 training_step 返回的损失的参数。如果这是故意的，您必须在 DDP 中启用未使用参数的检测，方法是设置字符串值 strategies=&#39;ddp_find_unused_pa​​rameters_true&#39; 或在策略中设置标志 strategies=DDPStrategy(find_unused_pa​​rameters=True)。
可以通过传递错误中提到的策略来避免 pytorch lightning 中未使用的参数。但是使用 resnet，您永远不会遇到这样的问题，因为您可以只传递骨干（减去 MLP 头），而不是整个骨干模型（带 MLP 头）。
我可能错了，但我觉得在训练完成后加载权重时可能会出现问题（带有骨干训练的自监督学习模型）。因为只有部分模型权重正在更新（如果我们使用策略 =&#39;ddp_find_unused_pa​​rameters_true&#39;）。它可能也很好，但为了避免所有这些，我想知道是否有一种方法可以只传递前向特征（即 swin-vit 骨干），类似于使用 resnet 模型的方式？]]></description>
      <guid>https://stackoverflow.com/questions/79177075/extracting-swin-vit-backbone</guid>
      <pubDate>Mon, 11 Nov 2024 09:26:07 GMT</pubDate>
    </item>
    <item>
      <title>GGML/pytorch 张量实现</title>
      <link>https://stackoverflow.com/questions/79175622/ggml-pytorch-tensors-implementation</link>
      <description><![CDATA[大家好，我最近开始研究自我注意机制的自定义加速器，我不知道 GGML 张量是如何实现的，希望有人能提供指导。
了解张量的 GGML 实现。]]></description>
      <guid>https://stackoverflow.com/questions/79175622/ggml-pytorch-tensors-implementation</guid>
      <pubDate>Sun, 10 Nov 2024 19:51:32 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程回归实现中矩阵乘法的`ValueError`</title>
      <link>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</link>
      <description><![CDATA[我正在使用平方指数核在 Python 中实现高斯过程回归 (GPR) 模型。但是，我在 predict 方法的矩阵乘法步骤中遇到了 ValueError，特别是在尝试计算平均预测时。
我看到的错误是：
ValueError：matmul：输入操作数 1 在其核心维度 0 中不匹配，gufunc 签名为 
(n?,k),(k,m?)-&gt;(n?,m?)（大小 10 与 100 不同）

代码详细信息
以下是此错误中涉及的代码的细分：
import numpy as np

class SquaredExponentialKernel:
def __init__(self, length_scale=1.0, variance=1.0):
self.length_scale = length_scale
self.variance = variance

def __call__(self, x1, x2):
dist_sq = np.sum((x1 - x2)**2)
return self.variance * np.exp(-0.5 * dist_sq / self.length_scale**2)

def cov_matrix(x1, x2, cov_function) -&gt; np.array:
返回 np.array([[cov_function(a, b) for a in x1] for b in x2])

class GPR:
def __init__(self, data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma: float = 0):
self.noise = white_noise_sigma
self.data_x = data_x
self.data_y = data_y
self.covariance_function = covariance_function
self._inverse_of_covariance_matrix_of_input_noise_adj = np.linalg.inv(
cov_matrix(data_x, data_x, covariance_function) + self.noise * np.identity(len(self.data_x))
)
self._memory = None

def predict(self, test_data: np.ndarray) -&gt;; np.ndarray:
KXX_star = cov_matrix(test_data, self.data_x, self.covariance_function)
KX_starX_star = cov_matrix(test_data, test_data, self.covariance_function)
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)
cov_test_data = KX_starX_star - KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ KXX_star.T)
var_test_data = np.diag(cov_test_data)
self._memory = {&#39;mean&#39;: mean_test_data, &#39;covariance_matrix&#39;: cov_test_data, &#39;variance&#39;: var_test_data}
返回 mean_test_data

# 测试数据
np.random.seed(69)
data_x = np.linspace(-5, 5, 10).reshape(-1, 1)
data_y = np.sin(data_x) + 0.1 * np.random.randn(10, 1)

# 实例化并预测
gpr_se = GPR(data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma=0.1)
test_data = np.linspace(-6, 6, 100).reshape(-1, 1)
mean_predictions = gpr_se.predict(test_data)

维度细分
这是矩阵乘法的维度分析，其中误差发生：

KXX_star 计算为 cov_matrix(test_data, self.data_x, self.covariance_function)，结果形状为 (100, 10)。
self._inverse_of_covariance_matrix_of_input_noise_adj 在 __init__ 方法中计算，形状为 (10, 10)。
self.data_y 形状为 (10, 1)。

有问题的行是：
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)

这应该产生形状为 (100, 1) 的结果，因为：

KXX_star 具有形状 (100, 10)，
(self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y) 导致形状为 (10, 1)。

当矩阵乘法的维度似乎对齐时，为什么我在这里收到维度不匹配错误？我该如何修复它？
我预计这个矩阵乘法能够正常工作，因为尺寸在纸面上看起来是兼容的：KXX_star (100, 10) 乘以 (10, 1) 应该得到 (100, 1)。然而，错误表明尺寸不匹配，这意味着某些东西没有按预期对齐。我检查了 self.data_y、self._inverse_of_covariance_matrix_of_input_noise_adj 和 KXX_star 的形状。还尝试重塑 data_y 以确保它始终为 (10, 1)，但错误仍然存​​在。我期望获得 test_data 的平均预测值作为形状为 (100, 1) 的向量，并且没有任何维度问题。]]></description>
      <guid>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</guid>
      <pubDate>Sun, 10 Nov 2024 15:14:18 GMT</pubDate>
    </item>
    <item>
      <title>我应该安装哪个版本的 torch 和 torchtext [关闭]</title>
      <link>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</link>
      <description><![CDATA[我使用的是 Windows，python 版本为 3.11.4，pandas 版本为 2.2.1

我尝试安装 torch 和 torchtext，但总是出现依赖错误。

这两个版本应该安装哪个？
错误：pip 的依赖解析器目前没有考虑所有已安装的软件包。此行为是以下依赖冲突的根源。

torchaudio 2.1.2 需要 torch==2.1.2，但您有不兼容的 torch 2.1.0+cu118。

成功安装 torch-2.1.0+cu118


那么我在哪里可以找到与 torch 2.1.0 兼容的 torchaudio 版本？
torchaudio pypl 没有像 torchtext 和 torchdata 这样的兼容表。]]></description>
      <guid>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</guid>
      <pubDate>Fri, 08 Nov 2024 20:20:10 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/79169750/sagemaker-endpoint</link>
      <description><![CDATA[我正在尝试为我的模型创建 sagemaker 端点。我已将包含推理脚本的 docker 文件推送到 aws ECR。我没有使用 model_fn、input_fn、predict_fn 和 output_fn。我只有一个函数，它从 kinesis 视频流中获取实时流，将我已保存到 docker 文件的 yolo 模型应用到 docker 文件中，然后将检测保存到 s3。当我创建端点时，它每次都会失败。我该怎么办？
我尝试将那些 model_fn、input_fn、predict_fn 和 output_fn 放入推理脚本中。因为我不需要它们，所以我在每个文件中都返回了 None，但它不起作用。
Dockerfile
FROM ultralytics/ultralytics:latest
WORKDIR /workspace
COPY inference.py /workspace/inference.py
COPY yolo_weights/PPE_4.pt /workspace/yolo_weights/PPE_4.pt
COPY static/detection_results /workspace/static/detection_results
RUN pip install --no-cache-dir 
boto3
ENTRYPOINT [&quot;python3&quot;, &quot;/workspace/inference.py&quot;]
Inference.py 文件
import boto3
from ultralytics import YOLO
导入 cv2
导入数学
导入时间
导入操作系统
导入日志记录
def model_fn(model_dir):
&quot;&quot;&quot;&quot;
这是一个虚拟实现。您可以将其留空，或者如果您自己处理所有事情，则返回 None。
&quot;&quot;&quot;&quot;
#model_path = os.path.join(model_dir, &#39;PPE_4.pt&#39;)
#model = YOLO(model_path)
logger.info(&quot;this is inside model&quot;)
return None

def input_fn(input_data, content_type):
&quot;&quot;&quot;&quot;&quot;
如果您自己处理所有事情，则这是一个虚拟实现。
&quot;&quot;&quot;&quot;&quot;
logger.info(&quot;this is inside input&quot;)
return # 按原样返回；您可以在 custom_inference_function 中处理预处理。
def predict_fn(input_data, model):
&quot;&quot;&quot;
在此处调用您的自定义推理函数，该函数处理所有事情（模型加载、数据预处理、推理）。
&quot;&quot;&quot;
logger.info(&quot;this is inside predict&quot;)
return
def output_fn(prediction, accept):
&quot;&quot;&quot;
将预测转换为 SageMaker 期望的输出格式。
&quot;&quot;&quot;
logger.info(&quot;this is inside output&quot;)
return
#这是我的自定义函数，它使用 kinesis HLS 流会话从 kinesis 获取直播流，并加载复制到 docker 容器的模型，然后在获取的 kinesis 视频流上使用该模型。
def video_detection_video(output_path, model_path):
#处理代码
video_detection_video(local_output_path, local_model_path)
upload_to_s3(local_output_path, s3_bucket, output_s3_key)]]></description>
      <guid>https://stackoverflow.com/questions/79169750/sagemaker-endpoint</guid>
      <pubDate>Fri, 08 Nov 2024 11:00:30 GMT</pubDate>
    </item>
    <item>
      <title>FLAML automl 预测概率与预测不匹配</title>
      <link>https://stackoverflow.com/questions/79163315/flaml-automl-prediction-probabilities-do-not-match-the-prediction</link>
      <description><![CDATA[我正在 Fabric 上使用 flaml automl 进行分类练习。
为了利用 spark，我必须使用 to_pandas_on_spark。
这些特征已经组装在一个向量中。
from flaml.automl.spark.utils import to_pandas_on_spark
psdf = to_pandas_on_spark(train_df)

拟合成功，所以我想预测我的测试数据。最佳估计器是 lgbm_spark。
接下来，为了进行评估，我需要一个最终数据框，其中包括目标 alpha 列、预测和概率，以及 test_df（pdate &amp; zm）中存在的 id 列。
psdf_test = to_pandas_on_spark(test_df.select(&quot;features&quot;))
y_pred = automl.predict(psdf_test) 

以上将返回一个带有一列预测的 pyspark.pandas.series.Series
y_pred_prob = automl.predict_proba(psdf_test)

以上将返回一个 pyspark.pandas.series.Series，其中每行都是三个概率的列表。
通常第一个是类别 0 的概率，第二个是类别 1 的概率，第三个是类别 2 的概率。
为了将所有内容整合在一起，我计划将所有内容转换为 pandas 数据框，然后连接起来。
#predictions
y_pred_pd = y_pred.to_pandas() # 转换为 pandas 系列
y_pred_pd = y_pred_pd.to_frame(name=&quot;prediction&quot;) # 转换为列名为“prediction”的 pandas 数据框

# probabilities
y_pred_prob_pd = y_pred_prob.to_pandas() # 转换为 pandas 系列
#y_pred_prob_pd = y_pred_prob_pd.to_frame(name=&quot;probability&quot;) # 转换为列名为“dataframe”的 DataFrame &#39;probability&#39;

# 将 test_df 转换为 pandas DataFrame 以使用标识符重新连接
test_df_pd = test_df.toPandas()

# 连接三个数据框
result_df = pd.concat([test_df_pd, y_pred_pd, y_pred_prob_pd], axis=1)

它有效，但问题是：最高概率与预测不匹配。

请注意，即使假设的类顺序不正确，预测仍然与最高概率不一致概率。

为什么会有差异？
有没有更简洁的方法来实现我想要的结果？
]]></description>
      <guid>https://stackoverflow.com/questions/79163315/flaml-automl-prediction-probabilities-do-not-match-the-prediction</guid>
      <pubDate>Wed, 06 Nov 2024 15:49:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 在低资源语言和葡萄牙语之间进行机器翻译的语言模型</title>
      <link>https://stackoverflow.com/questions/78911175/a-language-model-for-machine-translation-between-a-low-resource-language-and-por</link>
      <description><![CDATA[我正在尝试使用 Tensorflow 训练一种语言模型，用于在低资源语言和葡萄牙语之间进行机器翻译。不幸的是，我收到以下错误：
PS C:\Users\myuser\PycharmProjects\teste&gt; python .\tensorflow_model.py 
2024-08-23 21:29:50.839647：I tensorflow/core/platform/cpu_feature_guard.cc:182] 此 TensorFlow 二进制文件经过优化，可在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
回溯（最近一次调用）：
文件“.\tensorflow_model.py”，第 52 行，位于 &lt;module&gt;
数据集 = tf.data.Dataset.from_tensor_slices((src_tensor, tgt_tensor)).shuffle(BUFFER_SIZE)
文件 &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py&quot;，第 831 行，在 from_tensor_slices 中
返回 from_tensor_slices_op._from_tensor_slices(tensors, name)
文件 &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\from_tensor_slices_op.py&quot;，第 25 行，在 _from_tensor_slices 中
返回 _TensorSliceDataset(tensors, name=name)
文件&quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\from_tensor_slices_op.py&quot;，第 45 行，在 __init__
batch_dim.assert_is_compatible_with(
File &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\framework\tensor_shape.py&quot;，第 300 行，在 assert_is_compatible_with
raise ValueError(&quot;Dimensions %s and %s are notcompatible&quot; %
ValueError: Dimensions 21 and 22 are notcompatible

我该如何克服这个错误？
import tensorflow as tf
import numpy as np
import re
import os

# Clean数据
def preprocess_sentence(sentence):
sentence = sentence.lower().strip()
sentence = re.sub(r&quot;([?.!,¿])&quot;, r&quot; \1 &quot;, sentence)
sentence = re.sub(r&#39;[&quot; &quot;]+&#39;, &quot; &quot;, sentence)
sentence = re.sub(r&quot;[^a-zA-Z?.!,¿]+&quot;, &quot; &quot;, sentence)
sentence = sentence.strip()
sentence = &#39;&lt;start&gt; &#39; + sentence + &#39; &lt;end&gt;&#39;
返回句子

#加载数据的函数
def load_data(file_path_src, file_path_tgt):
src_sentences = open(file_path_src, &#39;r&#39;, encoding=&#39;utf-8&#39;).read().strip().split(&#39;\n&#39;)
tgt_sentences = open(file_path_tgt, &#39;r&#39;, encoding=&#39;utf-8&#39;).read().strip().split(&#39;\n&#39;)

src_sentences = [preprocess_sentence(sentence) for sentence in src_sentences]
tgt_sentences = [preprocess_sentence(sentence) for sentence in tgt_sentences]

返回 src_sentences, tgt_sentences

#加载数据
src_sentences, tgt_sentences = load_data(&#39;src_language.txt&#39;, &#39;portuguese.txt&#39;)

#标记化
src_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=&#39;&#39;)
tgt_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=&#39;&#39;)

src_tokenizer.fit_on_texts(src_sentences)
tgt_tokenizer.fit_on_texts(tgt_sentences)

src_tensor = src_tokenizer.texts_to_sequences(src_sentences)
tgt_tensor = tgt_tokenizer.texts_to_sequences(tgt_sentences)

src_tensor = tf.keras.preprocessing.sequence.pad_sequences(src_tensor, padding=&#39;post&#39;)
tgt_tensor = tf.keras.preprocessing.sequence.pad_sequences(tgt_tensor, padding=&#39;post&#39;)

BUFFER_SIZE = len(src_tensor)

#创建数据集
dataset = tf.data.Dataset.from_tensor_slices((src_tensor, tgt_tensor)).shuffle(BUFFER_SIZE) 
]]></description>
      <guid>https://stackoverflow.com/questions/78911175/a-language-model-for-machine-translation-between-a-low-resource-language-and-por</guid>
      <pubDate>Sun, 25 Aug 2024 12:06:55 GMT</pubDate>
    </item>
    <item>
      <title>无法在 python 中安装 lap==0.4.0 库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow TypeError：无法解压不可迭代的浮点对象</title>
      <link>https://stackoverflow.com/questions/61980349/tensorflow-typeerror-cannot-unpack-non-iterable-float-object</link>
      <description><![CDATA[我正在使用 tensorflow V2.2，在执行 model.evaluate 时遇到 TyepError。有人能告诉我问题可能出在哪里吗？下面显示了执行和错误消息的屏幕截图。
]]></description>
      <guid>https://stackoverflow.com/questions/61980349/tensorflow-typeerror-cannot-unpack-non-iterable-float-object</guid>
      <pubDate>Sun, 24 May 2020 00:50:30 GMT</pubDate>
    </item>
    <item>
      <title>R-派对套餐：cforest 真的是装袋吗？</title>
      <link>https://stackoverflow.com/questions/34293471/r-party-package-is-cforest-really-bagging</link>
      <description><![CDATA[我正在使用“party”包来创建回归树的随机森林。
我创建了一个 ForestControl 类，以限制我的树 (ntree)、节点 (maxdepth) 和用于拟合树 (mtry) 的变量的数量。
我不确定的一件事是 cforest 算法是否对其生成的每棵树使用我的训练集的子集。
我在文档中看到它正在装袋，所以我假设它应该如此。但我不确定我是否理解了该函数中的“子集”输入是什么。
我对使用 ctree 得到的结果也感到困惑：绘制树时，我看到我的训练集的所有变量都分类在不同的终端树节点中，而我原本预计它也只使用一个子集。
所以我的问题是，cforest 是否与 ctree 做同样的事情，或者它真的在打包我的训练集？
提前感谢您的帮助！
Ben]]></description>
      <guid>https://stackoverflow.com/questions/34293471/r-party-package-is-cforest-really-bagging</guid>
      <pubDate>Tue, 15 Dec 2015 15:46:47 GMT</pubDate>
    </item>
    </channel>
</rss>