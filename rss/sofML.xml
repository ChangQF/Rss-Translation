<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 13 Jul 2024 09:14:40 GMT</lastBuildDate>
    <item>
      <title>有没有办法在 winform 应用程序中使用 YoloV8 .Net Framework 4.7？</title>
      <link>https://stackoverflow.com/questions/78743181/is-there-anyway-to-use-yolov8-in-winform-application-net-framework-4-7</link>
      <description><![CDATA[亲爱的朋友们
我有一个基于 .net framework 4.7 的 c# winform 项目
我想知道，有没有办法在 winform 应用程序（.net framework 4.7）中使用 Yolov8？
当我在我的 c# 项目中添加 Yolov8 的引用时，
它出现了这个错误：
YoloV8 使用 system.runtime 版本 6.0
高于 system.runtime 4.1
提前谢谢您
在我的项目中添加 YoloV8]]></description>
      <guid>https://stackoverflow.com/questions/78743181/is-there-anyway-to-use-yolov8-in-winform-application-net-framework-4-7</guid>
      <pubDate>Sat, 13 Jul 2024 07:33:51 GMT</pubDate>
    </item>
    <item>
      <title>机器学习与深度学习 - 相似之处、不同之处、优点和缺点 [重复]</title>
      <link>https://stackoverflow.com/questions/78742949/machine-learning-versus-deep-learning-the-similarities-the-differences-the-p</link>
      <description><![CDATA[我读过关于人工智能，特别是机器学习和深度学习的文章，但我不明白它们之间的区别。
在深度学习中：神经元是什么？这意味着我需要一些计算机来进行深度学习吗？层是什么？
我读过这篇文章，但仍然有疑问。
我知道深度学习是机器学习的一个子集，但它们有什么相似之处？因为据我理解，这两个子集是不同的....
所以我的问题是两者之间的相似之处和不同之处是什么，什么时候我需要使用 ML 和/或 DL？
编辑：
@Sneftel 评论说，问题之间的区别，我的问题是，我相信我不了解基础知识：什么是神经元？什么是层？我需要 X 台计算机来处理 X 个神经元和 X 个层吗？当我理解这一点时，ML 和 DL 之间的相似之处和不同之处是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78742949/machine-learning-versus-deep-learning-the-similarities-the-differences-the-p</guid>
      <pubDate>Sat, 13 Jul 2024 05:30:55 GMT</pubDate>
    </item>
    <item>
      <title>如何在不使用标签编码的情况下对 RandomForest 的非序数分类变量进行编码？</title>
      <link>https://stackoverflow.com/questions/78742216/how-to-encode-non-ordinal-categorical-variables-for-randomforest-without-using-l</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78742216/how-to-encode-non-ordinal-categorical-variables-for-randomforest-without-using-l</guid>
      <pubDate>Fri, 12 Jul 2024 21:11:51 GMT</pubDate>
    </item>
    <item>
      <title>二元分类中的 SHAP 值解释</title>
      <link>https://stackoverflow.com/questions/78740880/shap-value-explanations-in-binary-classification</link>
      <description><![CDATA[我尝试使用每个特征的 SHAP 值来解释我的二元分类模型。我想知道：
正的 SHAP 值是否意味着该特征对预测“1”类的贡献更大，而负的 SHAP 值是否意味着该特征对预测“0”类的贡献更大？
如果我使用绝对 SHAP 值差异来描述特征贡献变化，这个想法是否合理？]]></description>
      <guid>https://stackoverflow.com/questions/78740880/shap-value-explanations-in-binary-classification</guid>
      <pubDate>Fri, 12 Jul 2024 14:25:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 FAISS 减少大型人脸数据库的人脸识别中的误报？</title>
      <link>https://stackoverflow.com/questions/78739882/how-to-reduce-false-positives-in-face-recognition-using-faiss-for-large-face-dat</link>
      <description><![CDATA[我正在开发一个使用人脸识别的考勤跟踪系统。
该系统的工作原理如下：

1. 人脸检测：使用 Ultra Face 检测人脸。
2. 人脸编码：使用 FaceNet 对检测到的人脸进行编码。
3. 人脸比较：将编码的人脸与现有数据库进行比较以标记出勤率
4.使用的库：OpenCV 和 FAISS。
5.来源：CCTV摄像机镜头。

考勤系统说明：
当一个人走到摄像机前时，系统使用Ultra Face检测人脸，并使用FaceNet进行编码。然后将编码的人脸与现有数据库进行比较。如果相似度（余弦相似度）小于0.25，则标记出勤。
问题：
最初，数据库中的人数少于100人，比较时间是可以接受的。随着人数的增加，比较时间明显变长。每个人在数据库中都有5张图片。为了加快比较速度，我改用FAISS库。虽然FAISS显著缩短了比较时间，但也增加了误报（错误地标记出勤）。
人脸比较的旧方法：
for db_name, db_encode in encoding_dict.items():
尝试：
dist = cosine(db_encode, f_e[1])
除 ValueError 为 e 外：
print(&quot;&gt;&gt;&gt;&gt;&gt;&gt; : &quot;,f_e[1],&quot;\n&quot;,type(f_e[1]))
继续
if dist &lt;识别_t：
name = db_name
distance = dist

cv2.rectangle(img, (f_e[0][0], f_e[0][1]), (f_e[0][2], f_e[0][3]), (0, 255, 0), 1)
cv2.putText(img, f&#39;{name}:{distance - 1:.2f}&#39;, (f_e[0][0], f_e[0][1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

使用 FAISS 的新方法：
class StaffCustManagement：
def __init__(self, staff_n_neighbours=4, identification_t=0.80):
self.staff_db：Custom_DB = Custom_DB（db_name =“mydatabase”，col_name =“staff”）
self.staff_names，self.staff_encodings = self.staff_load_encodings（）
self.staff_n_neighbours：int = staff_n_neighbours
self.staff_ini_faiss（）
self.recognition_t：float = identification_t

def staff_load_encodings（self） -&gt; Tuple[List[str], List[np.ndarray]]:
staff_names, staff_encodings = [], []
for document in self.staff_db.find_all_data():
staff_names.append(document[&#39;_id&#39;])
staff_encodings.append(ArrayEncDec.decode_from_base64(b64_str=document[&#39;encoding&#39;]))
return staff_names, staff_encodings

def staff_ini_faiss(self):
if self.staff_names and self.staff_encodings:
Dimensions = 128
self.staff_index_faiss = faiss.IndexFlatL2(dimensions)
faiss_embeddings = np.array(self.staff_encodings, dtype=&#39;float32&#39;)
faiss.normalize_L2(faiss_embeddings)
self.staff_index_faiss.add(faiss_embeddings)

def find_staff_cust(self, current_encode: np.ndarray) -&gt; Tuple[str, float]:
name = &quot;Unknown&quot;
distance = float(&quot;inf&quot;)
if len(self.staff_names) == 0:
return name, distance
target_rep = np.expand_dims(current_encode, axis=0)
# faiss.normalize_L2(target_rep)
distances, neighbours = self.staff_index_faiss.search(target_rep, self.staff_n_neighbours)
print(&quot;Distances&quot;, distances)
print(&quot;neighbors&quot;, neighbours)
if distances[0][0] &gt;= self.recognition_t:
return self.staff_names[neighbors[0][0]].split(&#39;-&#39;)[0], distances[0][0]
return name, distance

问题：
如何在使用 FAISS 进行人脸比较时减少误报我的出勤跟踪系统如何做到这一点？虽然 FAISS 大大缩短了比较时间，但准确性却受到影响，导致出勤标记不正确。是否有任何最佳实践或替代方法可以在大型数据库中保持高精度？]]></description>
      <guid>https://stackoverflow.com/questions/78739882/how-to-reduce-false-positives-in-face-recognition-using-faiss-for-large-face-dat</guid>
      <pubDate>Fri, 12 Jul 2024 10:33:51 GMT</pubDate>
    </item>
    <item>
      <title>如何并行化yolov5的Darknet53的卷积层（在一台电脑上）？[关闭]</title>
      <link>https://stackoverflow.com/questions/78739028/how-to-parallelize-the-convolutional-layers-of-darknet53-of-yolov5-on-one-pc</link>
      <description><![CDATA[我想把YOLOv5的主干算法拆分，部署在多块FPGA上，但是首先需要在一台电脑上把Darknet53卷积层划分成2个或多个区域，进行并行卷积操作。YOLOv5项目要学习什么？需要修改哪些文件？一堆YAML和common.py好混乱啊（YOLOVv5是最新版本）。
我已经在PC上部署了YOLOv5，也做了一些前期的研究，大部分的重点应该在models文件夹，models文件夹里有5个YAML网络配置文件，yolo.py，common.py等，现在想搞清楚研究的顺序，以及如何学习这些文件，在一台电脑上把Darknet53卷积层划分成2个或多个区域，进行并行卷积操作。]]></description>
      <guid>https://stackoverflow.com/questions/78739028/how-to-parallelize-the-convolutional-layers-of-darknet53-of-yolov5-on-one-pc</guid>
      <pubDate>Fri, 12 Jul 2024 07:10:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使 adapter_conditioning_scale 在多个 T2I_Adapter 中可训练？[关闭]</title>
      <link>https://stackoverflow.com/questions/78738957/how-to-make-adapter-conditioning-scale-trainable-in-multiple-t2i-adapter</link>
      <description><![CDATA[下面是使用 Multi T2I_Adapter 的代码。如以下代码所示，adapter_conditioning_scale=[0.8, 0.8]，是手动设置的。
adapters = MultiAdapter(
[
T2IAdapter.from_pretrained(&quot;TencentARC/t2iadapter_keypose_sd14v1&quot;),
T2IAdapter.from_pretrained(&quot;TencentARC/t2iadapter_depth_sd14v1&quot;),
]
)
adapters = adapters.to(torch.float16)

pipe = StableDiffusionAdapterPipeline.from_pretrained(
&quot;CompVis/stable-diffusion-v1-4&quot;,
torch_dtype=torch.float16,
adapter=adapters,
).to(&quot;cuda&quot;)

image = pipe(prompt, cond, adapter_conditioning_scale=[0.8, 0.8]).images[0]
make_image_grid([cond_keypose, cond_depth, image], rows=1, cols=3)

Google 的 Colab
我们可以使用哪种 ML 技术来找到 adapter_conditioning_scale 的最佳值？
参考文献：
huggingface.co
T2IAdapter 代码]]></description>
      <guid>https://stackoverflow.com/questions/78738957/how-to-make-adapter-conditioning-scale-trainable-in-multiple-t2i-adapter</guid>
      <pubDate>Fri, 12 Jul 2024 06:45:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 RAG 识别代码文件中的错误来源[关闭]</title>
      <link>https://stackoverflow.com/questions/78738937/using-rag-to-identify-the-source-of-error-in-a-code-file</link>
      <description><![CDATA[我正在尝试实现一个小工具，它可以自动识别一组代码文件（作为输入）中的哪一部分代码导致了执行期间显示的错误文本。
错误可能是语法错误，也可能是逻辑错误。我还在考虑利用 llms 的 api 调用来更正代码。
据我所知，RAG 是必要的，因为我不可能将所有代码文件的数据都放入提示中，因为它肯定会超出上下文窗口的大小。
哪种类型的 RAG 实现最有用？我想尽可能减少响应延迟？]]></description>
      <guid>https://stackoverflow.com/questions/78738937/using-rag-to-identify-the-source-of-error-in-a-code-file</guid>
      <pubDate>Fri, 12 Jul 2024 06:41:48 GMT</pubDate>
    </item>
    <item>
      <title>在交互式笔记本中加载 Azure ML Studio 中已注册的模型</title>
      <link>https://stackoverflow.com/questions/78736775/load-a-registered-model-in-azure-ml-studio-in-an-interactive-notebook</link>
      <description><![CDATA[我正在使用 Azure 机器学习工作室，我的默认数据存储（blob 存储）中存储了一个 sklearn mlflow 模型，然后我将其注册为模型资产。在将其部署为批处理端点之前，如何将此模型加载到交互式笔记本中以执行一些快速模型推理和测试。
我看到了一篇链接为此处的帖子，建议在本地下载模型工件，但我不需要这样做。我应该能够直接从数据存储或注册的资产加载模型，而无需在多个位置复制模型。我尝试了以下操作，但没有成功。
从已注册的模型资产读取
import mlflow
from azure.ai.ml import MLClient
from azure.ai.ml.entities import Model

ml_client = MLClient(DefaultAzureCredential(), &quot;&lt;subscription_id&gt;&quot;, &quot;&lt;resource_group&gt;&quot;, &quot;&lt;workspace_id&gt;&quot;)

model = ml_client.models.get(&quot;&lt;model_name&gt;&quot;, version=&quot;1&quot;)
loaded_model = mlflow.sklearn.load_model(model.id)

&gt;&gt;&gt; OSError：没有这样的文件或目录：...

从数据存储中读取
import mlflow

model_path = &quot;&lt;datastore_uri_to_model_folder&gt;&quot;
loaded_model = mlflow.sklearn.load_model(model_path)

&gt;&gt;&gt; DeserializationError：无法反序列化内容类型：text/html
]]></description>
      <guid>https://stackoverflow.com/questions/78736775/load-a-registered-model-in-azure-ml-studio-in-an-interactive-notebook</guid>
      <pubDate>Thu, 11 Jul 2024 16:45:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的空间数据管理机器学习模型中的类别不平衡问题</title>
      <link>https://stackoverflow.com/questions/78733642/managing-problems-of-class-imbalance-in-machine-learning-models-using-spatial-da</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78733642/managing-problems-of-class-imbalance-in-machine-learning-models-using-spatial-da</guid>
      <pubDate>Thu, 11 Jul 2024 05:01:17 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow keras Model.fit 返回：ValueError：无法识别的数据类型</title>
      <link>https://stackoverflow.com/questions/78731508/tensorflow-keras-model-fit-returning-valueerror-unrecognized-data-type</link>
      <description><![CDATA[我尝试用 2 个输入来训练 keras 模型：一个图像部分，即 tf.data.Dataset 和一个由 pd.DataFrame 表示的正常部分&gt;
from tensorflow.keras.optimizers import Adam
opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)

model.compile(loss=&quot;mean_absolute_percentage_error&quot;, optimizer=opt)

model.fit(
x=[df.loc[:, df.columns != &#39;target&#39;], ds.batch(8)], y=df[&quot;target&quot;],
epochs=200)

我尝试拟合模型，但我得到了ValueError
ValueError：无法识别的数据类型：x=[...][401059 行 x 52 列]
，&lt;_BatchDataset element_spec=(TensorSpec(shape=(None, 32, 256, 256, 3), 
dtype=tf.float32, name=None), 
TensorSpec(shape=(None, 32, 256, 256, 3), dtype=tf.float32, name=None))&gt;]（类型为 &lt;class &#39;list&#39;&gt;）
]]></description>
      <guid>https://stackoverflow.com/questions/78731508/tensorflow-keras-model-fit-returning-valueerror-unrecognized-data-type</guid>
      <pubDate>Wed, 10 Jul 2024 15:36:58 GMT</pubDate>
    </item>
    <item>
      <title>训练 PINN 来反演未知参数</title>
      <link>https://stackoverflow.com/questions/78730829/train-a-pinn-to-invert-for-unknown-parameters</link>
      <description><![CDATA[我使用 PINN 求解阻尼振荡器微分方程，同时以阻尼振荡器的噪声观测作为输入，找到后者的摩擦参数。我使用自定义训练程序在 Tensorflow 中编写了代码。问题是我定义的可训练参数没有接近我从噪声观测中知道的正确值。最终，PINN 的解决方案完全不正确。但是，我的代码运行得很好，不需要寻找可训练参数，也就是这里的摩擦参数。
以下函数的解释：

oscillator_system_data_loss：振荡器系统作为神经网络的实现，其中可学习参数 mu 传递给在 NN_osc_func 中实现的 ODE
train_NN_data_loss：自定义训练程序
plot_epochs_with_noise：与问题无关，但用于训练时监控

def rocksock_system_data_loss(t, net, func, params, mu, bc, t_data, u_data, lambda1):
t = t.reshape(-1,1)
t = tf.constant(t, dtype = tf.float32)
t_0 = tf.zeros((1,1))

使用 tf.GradientTape() 作为 outer_tape:
outer_tape.watch(t)

使用 tf.GradientTape() 作为 inner_tape:
inner_tape.watch(t)
x = net(t)

dx_dt = inner_tape.gradient(x, t) # 一阶导数

d2x_dt2 = outer_tape.gradient(dx_dt, t) # 二阶导数

bc_loss_1 = tf.square(net(t_0) - bc[0])
bc_loss_2 = tf.square(dx_dt[0] - bc[1])

ode_loss = d2x_dt2 - func(x, dx_dt, params[0], mu, params[2])

data_loss = u_data - net(t_data)

square_loss = tf.square(ode_loss) + lambda1*tf.square(data_loss) + bc_loss_1 + bc_loss_2
total_loss = tf.reduce_mean(square_loss)

return total_loss, mu

def train_NN_data_loss(epochs, optm, NN, func, bc, lambda1, train_t, train_u, data_t, data_u,
data_u_noised, test_t_plot, true_u_plot, testing_t):
train_loss_record = []
loss_tracker = plotting_points(epochs)

mu = tf.Variable(initial_value=tf.ones((1,1)), trainable=True, dtype=tf.float32)
mu_list = []

early_stop = 0

for itr in范围（epochs）：
使用 tf.GradientTape() 作为磁带：
train_loss，mu = 振荡器系统数据损失（train_t，NN，func，params，mu，bc，data_t，data_u_noised，lambda1）
train_loss_record.append（train_loss）

grad_w = 磁带。gradient（train_loss，NN.trainable_variables + [mu]）
optm.apply_gradients（zip（grad_w，NN.trainable_variables + [mu]））

如果 itr 在 loss_tracker 中：
print（train_loss.numpy()）
print（mu.numpy()）
plot_epochs_with_noise（train_t，train_u，data_t，data_u_noised，test_t_plot，true_u_plot，testing_t，itr，NN）

mu_list.append（mu.numpy()）

return train_loss_record, mu_list, early_stop

NN_osc_func = lambda x, dx_dt, k, d, m: -k/m*x - d/m*dx_dt

您可以在此处看到 6000 个 epoch 后的结果。神经网络正在收敛到一条水平线，误差为 5.76，参数估计为 0.84，尽管正确值为 4。这是我的阻尼振荡器设置：
k = 400
d = 4
m = 1
y0 = np.array([1.0, 0.0])

错误结果。
相应损失。
不幸的是，此时我不知道问题可能是什么。我尝试更改 NN_osc_func，并在两个函数中使用了 tape.gradient()。有什么帮助吗？
我的想法是，要么训练更长时间，要么我可能会遇到 PINN 容易出现的一些高频问题。]]></description>
      <guid>https://stackoverflow.com/questions/78730829/train-a-pinn-to-invert-for-unknown-parameters</guid>
      <pubDate>Wed, 10 Jul 2024 13:22:04 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MASK R_CNN 通过 OpenCV 提取图像中的精确区域？</title>
      <link>https://stackoverflow.com/questions/78657727/how-does-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</link>
      <description><![CDATA[我有一个医疗项目，需要提取一个特殊部分（结膜眼球）

自动提取眼睛图像而不了解其坐标，而不是手动提取，而且这个所需区域的坐标也在变化，因为我从许多患者那里捕捉到了图像，我认为必须找到它的形状。我的目标是通过计算结膜眼球中的红色像素来确定贫血和非贫血。我使用掩蔽方法（k 均值）来做到这一点，但我希望可以先直接提取结膜眼球，然后使用 k 均值掩蔽图像并查找，因为我的结果会更准确。当我使用图像分割中的 k 均值时，我发现另一个重叠的红色像素破坏了我的准确性。
。我也听说过机器学习，但在使用机器学习找到患者图像中的邻近区域后，我需要提取结膜髓核。所以我需要代码来仅提取结膜髓核。
我尝试了 k_means 和 kernel，但又添加了一个不需要的红色像素。我听说过实例分割和MASK RCNN。您假设我有我想要的区域，如上图所示，它是 CNN 的数据，那么如何将其用于我的项目。
import cv2
import numpy as np

# 读取图像
image = cv2.imread(&#39;c:/users/stk/desktop/d.png&#39;)

# 将图像转换为 HSV
hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# 定义红色的下限和上限
lower_red = np.array([0, 120, 70])
upper_red = np.array([10, 255, 255])

# 为红色创建蒙版
mask1 = cv2.inRange(hsv, lower_red, upper_red)

# 定义红色的下限和上限
lower_red = np.array([170, 120, 70])
upper_red = np.array([180, 255, 255])

# 为红色创建蒙版
mask2 = cv2.inRange(hsv, lower_red, upper_red)

# 合并两个蒙版
mask = mask1 + mask2

# 为形态学操作创建内核
kernal = np.ones((5, 5), np.uint8)

# 执行形态学操作
mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernal)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernal)

# 将蒙版应用于原始图像
result = cv2.bitwise_and(image, image, mask = mask)

# 保存result
cv2.imwrite(&#39;extracted_red_object.png&#39;, result)

# 显示结果
cv2.imshow(&#39;EXTRACTED RED OBJECT&#39;, result)
cv2.waitKey(0)
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78657727/how-does-use-mask-r-cnn-to-extract-exact-region-in-image-by-opencv</guid>
      <pubDate>Sun, 23 Jun 2024 03:58:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 NLP Python 对文本进行多分类 - 总类别中 2 个类别的召回率相对较低</title>
      <link>https://stackoverflow.com/questions/61279917/multi-classification-of-text-using-nlp-python-recall-is-relatively-very-less-f</link>
      <description><![CDATA[我拥有几乎平衡的数据集，包含 9 个独特类别，每个类别有近 2200 行，差异为 +/-100 行。为了创建模型，我使用了下面提到的 URL 方法，但在每种情况下，我的模型准确率都在 58% 左右，精确率/召回率也在 54% 左右。你能告诉我我做错了什么吗？
https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f
https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a
https://medium.com/@robert.salgado/multiclass-text-classification-from-start-to-finish-f616a8642538
我的数据集只有 2 列，1 列为特征，1 列为标签。
from pandas import ExcelFile

df = pd.read_excel(&#39;Prediction.xlsx&#39;, 
sheet_name=&#39;Sheet1&#39;)
df.head()
BAD_SYMBOLS_RE = re.compile(&#39;[^0-9a-z #+_]&#39;)
STOPWORDS = set(stopwords.words(&#39;english&#39;))
import sys
!{sys.executable} -m pip install lxml

def clean_text(text):
&quot;&quot;&quot;
text: 字符串

return: 修改后的初始字符串
&quot;&quot;&quot;
text = BeautifulSoup(text, &quot;html.parser&quot;).text # HTML 解码
text = text.lower() # 小写文本
text = REPLACE_BY_SPACE_RE.sub(&#39; &#39;, text) # 将文本中的 REPLACE_BY_SPACE_RE 符号替换为空格
text = BAD_SYMBOLS_RE.sub(&#39;&#39;, text) # 从文本中删除 BAD_SYMBOLS_RE 中的符号
text = &#39; &#39;.join(word for word in text.split() if word not in STOPWORDS) # 从文本中删除停用词
return text

df[&#39;notes_issuedesc&#39;] = df[&#39;notes_issuedesc&#39;].apply(clean_text)
print_plot(10)
df[&#39;notes_issuedesc&#39;].apply(lambda x: len(x.split(&#39; &#39;))).sum()
X = df.notes_issuedesc
y = df.final
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 42)
%%time
从 sklearn.naive_bayes 导入 MultinomialNB
从 sklearn.pipeline 导入 Pipeline
从 sklearn.feature_extraction.text 导入 TfidfTransformer

nb = Pipeline([(&#39;vect&#39;, CountVectorizer()),
(&#39;tfidf&#39;, TfidfTransformer()),
(&#39;clf&#39;, MultinomialNB()),
])
nb.fit(X_train, y_train)

来自 sklearn.metrics 导入分类报告
y_pred = nb.predict(X_test)

print(&#39;准确率 %s&#39; % 准确率得分(y_pred, y_test))
print(分类报告(y_test, y_pred,target_names=my_tags))
]]></description>
      <guid>https://stackoverflow.com/questions/61279917/multi-classification-of-text-using-nlp-python-recall-is-relatively-very-less-f</guid>
      <pubDate>Fri, 17 Apr 2020 20:12:37 GMT</pubDate>
    </item>
    <item>
      <title>打印张量的所有内容</title>
      <link>https://stackoverflow.com/questions/52673610/printing-all-the-contents-of-a-tensor</link>
      <description><![CDATA[我偶然发现了这个 PyTorch 教程（在 neuron_networks_tutorial.py 中），其中他们构建了一个简单的神经网络并运行推理。我想打印整个输入张量的内容以进行调试。当我尝试打印张量时，我得到的是类似这样的结果，而不是整个张量：

我看到了类似的 numpy 链接，但不确定哪个适用于 PyTorch。我可以将其转换为 numpy 并可能查看它，但我想避免额外的开销。有没有办法打印整个张量？]]></description>
      <guid>https://stackoverflow.com/questions/52673610/printing-all-the-contents-of-a-tensor</guid>
      <pubDate>Fri, 05 Oct 2018 21:41:40 GMT</pubDate>
    </item>
    </channel>
</rss>