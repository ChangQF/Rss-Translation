<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 20 Mar 2024 12:23:36 GMT</lastBuildDate>
    <item>
      <title>确定 RTX 4090 训练性能不佳的原因</title>
      <link>https://stackoverflow.com/questions/78192841/identifying-the-cause-of-poor-training-performance-of-rtx-4090</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78192841/identifying-the-cause-of-poor-training-performance-of-rtx-4090</guid>
      <pubDate>Wed, 20 Mar 2024 11:16:15 GMT</pubDate>
    </item>
    <item>
      <title>pytorch和cuda安装问题[重复]</title>
      <link>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</link>
      <description><![CDATA[我正在尝试在 Windows 11 上使用 Anaconda3 安装带有 Cuda 的 PyTorch
我的nvidia-smi输出驱动程序版本：551.76，CUDA版本：12.4
我的火炬版本是我从官方网站安装的 12.2
&lt;前&gt;&lt;代码&gt;火炬2.2.1+cu121
火炬音频2.2.1+cu121
火炬视觉 0.17.1+cu121

但问题是，当我运行 torch.cuda.is_available() 时，它显示 false 作为输出。这里出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</guid>
      <pubDate>Wed, 20 Mar 2024 10:58:20 GMT</pubDate>
    </item>
    <item>
      <title>ViT 模型的 HuggingFace Inference API 问题 - “图像特征提取”错误</title>
      <link>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</link>
      <description><![CDATA[我的 Vision Transformer (ViT) 模型 rshrott/vit-base-renovation2 的推理 API 遇到问题。
https://huggingface.co/rshrott/vit-base-renovation2 
当我尝试使用 API 时，收到以下错误：
&lt;前&gt;&lt;代码&gt;{
“错误”：“HfApiJson（反序列化（错误（“未知变体图像特征提取，预期音频分类，音频到音频，音频源分离，自动语音识别，特征提取之一，文本分类、标记分类、问答、翻译、摘要、文本生成、text2text-生成、填充掩模、零样本分类、零样本图像分类、会话、表格问答、图像分类、图像分割、图像到文本、文本到语音、...视觉问答、视频分类、文档问答、图像到图像、深度估计，行：1 ，栏目：318)))”
}

有趣的是，当我直接在 Python 中使用 Transformer 管道时，模型按预期工作：
从转换器导入管道
从 PIL 导入图像
导入请求

管道=管道（模型=“rshrott/vit-base-renovation2”）
url = &#39;https://example.com/image.jpeg&#39;
图像= Image.open(requests.get(url,stream=True).raw)
preds = 管道(图像)

此代码运行没有任何问题并返回预期的预测。但是，通过推理 API 使用同一模型时会遇到错误。我怀疑可能存在与预期任务类型相关的配置问题，但我不确定如何解决它。
为什么会出现此错误以及如何修复它？我已经检查了型号卡和配置，但我似乎无法找到“图像特征提取”的来源或原因。]]></description>
      <guid>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</guid>
      <pubDate>Wed, 20 Mar 2024 10:44:57 GMT</pubDate>
    </item>
    <item>
      <title>从波形中提取峰值和平均面积[关闭]</title>
      <link>https://stackoverflow.com/questions/78190852/peak-and-mean-area-extraction-from-a-waveform</link>
      <description><![CDATA[在此处输入图像描述是否有任何方法可以提取峰值和平均值从当前波形时间序列中提取&gt;
请帮忙。在此处输入图像描述
我尝试手动完成，但数据非常庞大。那么有没有人工智能工具或任何其他方法可以做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78190852/peak-and-mean-area-extraction-from-a-waveform</guid>
      <pubDate>Wed, 20 Mar 2024 04:27:02 GMT</pubDate>
    </item>
    <item>
      <title>对同一数据集的不同子组进行迁移学习[关闭]</title>
      <link>https://stackoverflow.com/questions/78190629/transfer-learning-on-different-subgroups-of-the-same-dataset</link>
      <description><![CDATA[我正在尝试根据回归任务的特定列中的值将原始数据集分为 6 个子组。每个子组中目标变量的分布非常相似。我的目标是通过首先对 5 个子组进行预训练，然后对最后一个子组进行微调来应用迁移学习。
对于预训练，我为每个子组设置了单独的训练、验证和测试集。预训练包括将5个子组的训练集和验证集结合起来，用它们来训练模型，验证模型，然后测量测试集上的损失。
随后，我使用预训练中的模型权重，并仅使用最终子组的训练集和验证集进行微调，并再次测量测试集上的损失。
但是，我遇到了一个问题，即我的模型对预训练数据过度拟合，导致微调过程中第一个周期的提前停止，因为微调集的验证误差会增加。
我的方法正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/78190629/transfer-learning-on-different-subgroups-of-the-same-dataset</guid>
      <pubDate>Wed, 20 Mar 2024 02:45:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么带有 Cartpole 健身房环境的 stable_baselines3 模型通过 sutton_barto_reward 提高了平均剧集奖励？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78188062/why-is-my-stable-baselines3-model-with-cartpole-gym-environment-improving-mean-e</link>
      <description><![CDATA[当我运行此代码时，我看到剧集长度平均值不断增加（就像一个好的模型应该的那样），而剧集平均值奖励保持在 -1 不变，这就是 sutton_barto_reward 系统的工作原理。
导入体育馆
从 cartpole 导入 CartPoleEnv
从 stable_baselines3 导入 PPO
从 stable_baselines3.ppo.policies 导入 MlpPolicy

env = CartPoleEnv(sutton_barto_reward=True)

模型 = PPO(“MlpPolicy”, env, gamma=1, verbose=1)
model.learn(total_timesteps=30000)

但是，我不明白为什么会这样，因为在gymnasium的GitHub文档中的Cartpole代码中似乎没有使用任何折扣率。既然剧集的累积奖励始终相同，那么剧集长度平均值难道不应该没有任何改善吗？]]></description>
      <guid>https://stackoverflow.com/questions/78188062/why-is-my-stable-baselines3-model-with-cartpole-gym-environment-improving-mean-e</guid>
      <pubDate>Tue, 19 Mar 2024 16:02:07 GMT</pubDate>
    </item>
    <item>
      <title>关于空闲时间的数据集？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78187717/data-set-about-free-time</link>
      <description><![CDATA[我想到了一个项目 - 一种用于组织与朋友外出活动的人工智能机器人。其中一部分是实际创建，甚至搜索（如果有的话）预先标记的数据集（这就是 chatgpt 告诉我的 - 我是全新的）。
我在哪里可以找到它，或者如何创建它？]]></description>
      <guid>https://stackoverflow.com/questions/78187717/data-set-about-free-time</guid>
      <pubDate>Tue, 19 Mar 2024 15:11:34 GMT</pubDate>
    </item>
    <item>
      <title>我的 scikit-learn 代码序列正确吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78187495/is-my-scikit-learn-code-sequence-correct</link>
      <description><![CDATA[我已经构建了一个包含一些转换的管道并训练了一个 SVC 分类器。代码中构建模型的步骤顺序是否正确？ n次交叉验证效率较低。
我正在使用此处找到的processed.cleveland.data数据集：https： //archive.ics.uci.edu/dataset/45/heart+disease。
将 pandas 导入为 pd
将 numpy 导入为 np
导入操作系统
从 pathlib 导入路径

从 sklearn.model_selection 导入 train_test_split
从 sklearn.model_selection 导入 StratifiedKFold
从 sklearn.model_selection 导入 cross_val_score

从 sklearn.compose 导入 ColumnTransformer
从 sklearn.pipeline 导入管道
从 sklearn.preprocessing 导入 OneHotEncoder
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.impute 导入 SimpleImputer

从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.svm 导入 SVC
url =“C:/Users/.../processedcleveland.data”
名称 = [&#39;年龄&#39;, &#39;性别&#39;, &#39;cp&#39;, &#39;trestbps&#39;, &#39;chol&#39;, &#39;fbs&#39;, &#39;restecg&#39;, &#39;thalach&#39;, &#39;exang&#39;, &#39;oldpeak&#39;, &#39;slope&#39;, &#39;ca&#39; , &#39;thal&#39;, &#39;num&#39;]
def getData():
        返回 pd.read_csv(url, sep=&#39;,&#39;, 名称=名称)

输入 = 获取数据()
打印（输入.info（））
打印（输入.描述（））

数组=输入.值
X = 数组[:,0:13]
y = 数组[:,13]

dataframe = pd.DataFrame.from_records(X)
数据帧[[1,2,5,6,8]] =数据帧[[1,2,5,6,8]].astype(str)

打印(dataframe.info())

numeric_ix = dataframe.select_dtypes(include=[&#39;int64&#39;, &#39;float64&#39;]).columns
categorical_ix = dataframe.select_dtypes(include=[&#39;object&#39;, &#39;bool&#39;]).columns

打印（数字_ix）
打印（分类_ix）
&#39;&#39;&#39;
t = [(&#39;cat0&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;), [1, 2, 5, 6, 8]), (&#39;cat1&#39;, OneHotEncoder(), categorical_ix), (&#39;num0&#39;, SimpleImputer(strategy) =&#39;中位数&#39;), numeric_ix), (&#39;num1&#39;, MinMaxScaler(), numeric_ix)]
col_transform = ColumnTransformer(变压器=t)

管道 = 管道(步骤=[(&#39;t&#39;, col_transform)])
# 将管道拟合到转换后的数据上
结果 = pipeline.fit_transform(dataframe)

打印（类型（pd.DataFrame.from_records（结果）））
打印（pd.DataFrame.from_records（结果）.to_string（））
&#39;&#39;&#39;
X_train、X_validation、Y_train、Y_validation = train_test_split(X、y、test_size=0.20、random_state=1)


categorical_impute = 管道([
    （“mode_impute”，SimpleImputer（missing_values = np.nan，策略=&#39;most_frequent&#39;）），
    (“one_hot”, OneHotEncoder())
]）

numeric_impute = 管道([
    （“num_mode_impute”，SimpleImputer（missing_values = np.nan，策略=&#39;中位数&#39;）），
    (“min_max”, StandardScaler())
]）

预处理器 = ColumnTransformer([
    (“cat_impute”, categorical_impute, categorical_ix),
    (“num_impute”, numeric_impute, numeric_ix)
]，余数=“直通”）


模型 = SVC(伽玛=&#39;自动&#39;)

kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)

pipeline = Pipeline(steps=[(&#39;prep&#39;, 预处理器), (&#39;m&#39;, model)])

cv_results = cross_val_score(管道, X_train, Y_train, cv=kfold, 评分=&#39;准确度&#39;)
print(&#39;%s: %f (%f)&#39; % (&quot;SVC: &quot;, cv_results.mean(), cv_results.std()))
# 结果 = preprocessor.fit_transform(dataframe)
# print(pd.DataFrame.from_records(结果).to_string())

如上所述，分类器的效率非常低。顺序有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78187495/is-my-scikit-learn-code-sequence-correct</guid>
      <pubDate>Tue, 19 Mar 2024 14:38:47 GMT</pubDate>
    </item>
    <item>
      <title>TF2 和 python 中的 BERT 预处理器模型存在问题</title>
      <link>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</link>
      <description><![CDATA[我正在尝试使用 BERT 来做一个文本分类项目。但是我一直遇到这个错误
`
ValueError Traceback（最近一次调用最后一次）
单元格 In[37]，第 4 行
      2 text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
      3 bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;预处理&#39;)
----&gt; 4 preprocessed_text = bert_preprocess(text_input)
      5 bert_encoder = hub.KerasLayer(encoder_url,
      6 可训练=真，
      7 名称=&#39;BERT_编码器&#39;)
      8 个输出 = bert_encoder(preprocessed_text)
ValueError：调用层“预处理”时遇到异常（类型 KerasLayer）。
KerasTensor 是象征性的：它是形状和数据类型的占位符。它没有任何实际的数值。您无法将其转换为 NumPy 数组。

调用层“预处理”接收的参数（类型 KerasLayer）：
  输入=
  • 培训=无

KerasTensor 是象征性的：它是形状和数据类型的占位符。它没有任何实际的数值。您无法将其转换为 NumPy 数组。



构建此模型时：
&lt;前&gt;&lt;代码&gt;
preprocess_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3&#39;
编码器网址 = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-768-a-12/versions/2&#39;

# Bert 层
text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;预处理&#39;)
预处理文本 = bert_preprocess(text_input)
bert_encoder = hub.KerasLayer(encoder_url,
                              可训练=真，
                              名称=&#39;BERT_编码器&#39;)
输出= bert_encoder（预处理文本）

# 神经网络层
l = tf.keras.layers.Dropout(0.1)(输出[&#39;pooled_output&#39;])
l = tf.keras.layers.Dense(num_classes, 激活=&#39;softmax&#39;, name=&#39;输出&#39;)(l)

# 构建最终模型
模型 = tf.keras.Model(输入=[text_input], 输出=[l])

我看过无数的教程，甚至使用了张量流文档上的教程，即使我复制和粘贴，它们仍然不起作用。我尝试过不同版本的 tf、tf-text 和 tf-hub。我在这个项目中使用了tensorflow-gpu-jupyter docker 容器。
这是我安装库的方法：
!pip install “tensorflow-text”
!pip install “tf-models-official”
!pip install “tensorflow-hub”

版本是：
张量流：2.16.1
张量流文本：2.16.1
张量流中心：0.16.1
我看到的有关此问题的所有其他论坛都说要执行 tf.config.run_functions_eagerly(True) 但这不起作用。
任何事情都会有所帮助。如果您知道如何解决请回答。]]></description>
      <guid>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</guid>
      <pubDate>Tue, 19 Mar 2024 01:42:01 GMT</pubDate>
    </item>
    <item>
      <title>部分依赖图 - 使用缩放数据开发的模型，如何取消 PDP 缩放？</title>
      <link>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</link>
      <description><![CDATA[我已经用Python制作了一个随机森林分类器模型，现在想要制作部分依赖图（PDP）。我使用缩放数据来训练和测试模型，并使 PDP 如下所示：
PartialDependenceDisplay.from_estimator(best_clf, X_test_final, best_features)。但是，x 轴值经过缩放，这限制了可解释性。
在调用 PartialDependenceDisplay 之前取消缩放数据 X_test_final 不起作用，有关如何将 x 轴值从缩放更改为未缩放的任何建议？我已使用 StandardScaler() 缩放了我的数据。]]></description>
      <guid>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</guid>
      <pubDate>Fri, 15 Mar 2024 13:15:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用kaggle中的两个GPU在pytorch中进行训练？</title>
      <link>https://stackoverflow.com/questions/77094149/how-to-use-both-gpus-in-kaggle-for-training-in-pytorch</link>
      <description><![CDATA[我正在 Kaggle GPU 中训练模型。
但正如我所看到的，只有一个 GPU 正在工作。

我使用普通方法进行训练，例如
device = torch.device(&#39;cuda&#39;) if torch.cuda.is_available() else torch.device(&#39;cpu&#39;)
模型 = model.to(设备)

如何同时使用这两个 GPU？]]></description>
      <guid>https://stackoverflow.com/questions/77094149/how-to-use-both-gpus-in-kaggle-for-training-in-pytorch</guid>
      <pubDate>Wed, 13 Sep 2023 04:56:24 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.neighbors._base”导入名称“_check_weights”</title>
      <link>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</link>
      <description><![CDATA[我正在尝试将 Missforest 作为处理表数据中缺失值的方法。
导入sklearn
打印（sklearn.__version__）
-&gt;1.2.1

导入 sklearn.neighbors._base
导入系统
sys.modules[&#39;sklearn.neighbors.base&#39;] = sklearn.neighbors._base

!pip 安装缺少的py
从missingpy导入MissForest

到目前为止一切正常，但从昨天开始，出现了以下错误消息。
导入错误：无法从“sklearn.neighbors._base”导入名称“_check_weights”

我想知道如何处理这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/75633185/importerror-cannot-import-name-check-weights-from-sklearn-neighbors-base</guid>
      <pubDate>Sat, 04 Mar 2023 01:48:43 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 生存模型</title>
      <link>https://stackoverflow.com/questions/75010397/xgboost-survival-model</link>
      <description><![CDATA[我正在尝试开发 XGBoost 生存模型。这是我的代码的快速快照：
X = df_High_School[[&#39;Gender&#39;, &#39;Lived_both_Parents&#39;, &#39;Moth_Born_in_Canada&#39;, &#39;Father_Born_in_Canada&#39;,&#39;Born_in_Canada&#39;,&#39;Aboriginal&#39;,&#39;Visible_Minority&#39;]] # 协变量
y = df_High_School[[&#39;time_to_event&#39;, &#39;event&#39;]] # 事件发生时间和事件指示器

#将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

#开发模型
model = xgb.XGBRegressor(objective=&#39;survival:cox&#39;)

它给了我以下错误：
&lt;块引用&gt;
&lt;小时/&gt;

ValueError Traceback（最近一次调用最后一次）
 在
18
19 # 将模型拟合到训练数据
---&gt; 20 model.fit(X_train, y_train)
21
22 # 对测试集进行预测
2帧
_maybe_pandas_label（标签）中的/usr/local/lib/python3.8/dist-packages/xgboost/core.py
261 if isinstance（标签，DataFrame）：
[262] 第 262 章1：
--&gt; 263 raise ValueError（&#39;标签的数据帧不能有多列&#39;）
264
[第 265 章]
ValueError：标签的 DataFrame 不能有多列
由于这是一个生存模型，我需要两列 t 来指示事件和 time_to_event。我还尝试将 Dataframes 转换为 Numpy，但它也不起作用。
有什么线索吗？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/75010397/xgboost-survival-model</guid>
      <pubDate>Wed, 04 Jan 2023 19:32:04 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有灰度图像的预训练神经网络？</title>
      <link>https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images</link>
      <description><![CDATA[我有一个包含灰度图像的数据集，我想在它们上训练最先进的 CNN。我非常想微调预训练模型（例如 &lt;a href=&quot;https://github.com/tensorflow/models/tree/master/research/slim#Pretrained&quot; rel=&quot;noreferrer ”在这里&lt;/a&gt;)。
问题是，我能找到权重的几乎所有模型都在包含 RGB 图像的 ImageNet 数据集上进行了训练。
我无法使用其中一个模型，因为它们的输入层需要一批形状 (batch_size, height, width, 3) 或 (64, 224, 224, 3)  就我而言，但我的图像批次是 (64, 224, 224)。
有什么方法可以使用这些模型之一吗？我曾想过在加载权重后删除输入层并添加我自己的权重（就像我们对顶层所做的那样）。这种做法正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images</guid>
      <pubDate>Fri, 24 Aug 2018 00:33:04 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 中的 TfidfVectorizer 如何专门包含单词</title>
      <link>https://stackoverflow.com/questions/19753945/tfidfvectorizer-in-sklearn-how-to-specifically-include-words</link>
      <description><![CDATA[我对 TfidfVectorizer 有一些疑问。
我不清楚这些词是如何选择的。我们可以提供最低支持，但在那之后，什么将决定选择哪些功能（例如，更高的支持更多机会）？如果我们说 max_features = 10000，我们总是得到相同的结果吗？如果我们说 max_features = 12000，我们会得到相同的 10000 特征，但额外添加 2000 吗？ 
此外，有没有办法扩展例如 max_features=20000 功能？我将它放在一些文本上，但我知道一些肯定应该包含的单词，还有一些表情符号“:-)”等。如何将这些添加到 TfidfVectorizer 对象中，以便它将可以使用该对象，用它来拟合和预测
to_include = [&quot;:-)&quot;, &quot;:-P&quot;]
方法 = TfidfVectorizer(max_features=20000, ngram_range=(1, 3),
                      # 我知道停用词，但是包含单词怎么样？
                      stop_words=test.stoplist[:100],
                      # 包含单词 ??
                      分析器=&#39;词&#39;,
                      min_df=5)
方法.fit(训练数据)

寻求结果：
X = method.transform(traindata)
X
”的稀疏矩阵
 以压缩稀疏行格式存储了 1135520 个元素&gt;]，
 其中 N 是样本大小
]]></description>
      <guid>https://stackoverflow.com/questions/19753945/tfidfvectorizer-in-sklearn-how-to-specifically-include-words</guid>
      <pubDate>Sun, 03 Nov 2013 14:19:46 GMT</pubDate>
    </item>
    </channel>
</rss>