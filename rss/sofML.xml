<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 18 Jul 2024 12:29:51 GMT</lastBuildDate>
    <item>
      <title>安装 open-pose 时出现问题</title>
      <link>https://stackoverflow.com/questions/78763910/issue-installing-open-pose</link>
      <description><![CDATA[我按照官方页面 (https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation/0_index.md) 上针对 ubuntu (22.04) 的安装步骤进行操作，似乎已安装。但是，在测试部分，我正在运行：
*# Ubuntu 和 Mac
./build/examples/openpose/openpose.bin --video examples/media/video.avi*

但是它不起作用，这是我得到的
upo@upo-Stealth-15M-A11SEK:~/openpose$ ./build/examples/openpose/openpose.bin --video examples/media/video.avi
正在启动 OpenPose 演示...
正在配置 OpenPose...
正在启动线程...
正在自动检测所有可用的 GPU...检测到 1 个 GPU，使用其中 1 个，从 GPU 0 开始。
F0718 11:32:00.771245 104120 syncedmem.cpp:71] 检查失败：错误 == cudaSuccess（2 vs. 0）内存不足
***检查失败堆栈跟踪：***
@ 0x7271ad411b03 google::LogMessage::Fail()
@ 0x7271ad4199d1 google::LogMessage::SendToLog()
@ 0x7271ad4117c2 google::LogMessage::Flush()
@ 0x7271ad41378f google::LogMessageFatal::~LogMessageFatal()
@ 0x7271ac2af1ba caffe::SyncedMemory::mutable_gpu_data()
@ 0x7271ac2e461c caffe::CuDNNConvolutionLayer&lt;&gt;::Forward_gpu()
@ 0x7271ac2700c2 caffe::Net&lt;&gt;::ForwardFromTo()
@ 0x7271ad01fac7 op::NetCaffe::forwardPass()
@ 0x7271ad03b132 op::PoseExtractorCaffe::forwardPass()
@ 0x7271ad035a1c op::PoseExtractor::forwardPass()
@ 0x7271ad033690 op::WPoseExtractor&lt;&gt;::work()
@ 0x7271ad065e6f op::Worker&lt;&gt;::checkAndWork()
@ 0x7271ad066033 op::SubThread&lt;&gt;::workTWorkers()
@ 0x7271ad0732cd op::SubThreadQueueInOut&lt;&gt;::work()
@ 0x7271ad069cb1 op::Thread&lt;&gt;::threadFunction()
@ 0x7271acadc253 (未知)
@ 0x7271ac694ac3 (未知)
@ 0x7271ac726850 (未知)
@ (nil) (未知)
已中止 (核心转储)

我认为，我应该能够运行该示例，因为我有一台 6GB 的 RTX 2060，但它说我的内存不足……所以我不知道如何解决这个问题。
我只想获取 open pose 可以提供的 json 文件，以便我可以将其用于 NN。如果没有解决方案，是否可以使用其他工具获取与 openpose 格式相同的 json 文件？ （作为 mediapipe 或 yolo-pose）我尝试过 yolo（它工作正常）但格式不一样，并且网络经过训练以获取 openpose 格式。
pd：我已经安装了 CUDA 12.4 和 CUDNN 8.9，并且它们应该可以正常工作，因为它们被 tensorflow 识别]]></description>
      <guid>https://stackoverflow.com/questions/78763910/issue-installing-open-pose</guid>
      <pubDate>Thu, 18 Jul 2024 10:46:03 GMT</pubDate>
    </item>
    <item>
      <title>在模型训练中，处理 Web 应用程序上的错误输入数据时遇到困难</title>
      <link>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</guid>
      <pubDate>Thu, 18 Jul 2024 09:48:16 GMT</pubDate>
    </item>
    <item>
      <title>将safetensors模型格式（LLaVA模型）转换为gguf格式</title>
      <link>https://stackoverflow.com/questions/78763327/convert-safetensors-model-formatllava-model-into-gguf-format</link>
      <description><![CDATA[我想在 ollama 中进行 LLaVA 推理，因此我需要将其转换为 gguf 文件格式。
我的模型具有文件格式 safetensors。（使用 lora 训练）
似乎 ollama 仅支持 llama，但不支持 llava，如下所示，
https://github.com/ollama/ollama/blob/main/docs/import.md
我遵循了 llama.cpp 的说明，并在此处使用了代码 convert_lora_to_gguf.py，
https://github.com/ggerganov/llama.cpp/blob/master/convert_lora_to_gguf.py
但是我收到如下错误：
ERROR:lora-to-gguf:不支持 Model LlavaLlamaForCausalLM

如果我在模型文件的 config.json 中写入 llama 模型并运行以下代码，则会收到另一个错误。
model_instance.gguf_writer.add_string(gguf.Keys.General.TYPE, gguf.GGUFType.ADAPTER)
model_instance.gguf_writer.add_string(gguf.Keys.Adapter.TYPE, &quot;lora&quot;)
model_instance.gguf_writer.add_float32(gguf.Keys.Adapter.LORA_ALPHA, float(alpha))
model_instance.gguf_writer.add_quantization_version(gguf.GGML_QUANT_VERSION)
logger.info(&quot;Exporting model...&quot;)
model_instance.write()
logger.info(f&quot;模型已成功导出至 {model_instance.fname_out}&quot;)

Traceback (most recent call last):
File &quot;C:\Users\jjjy2\OneDrive\Desktop\VLM_FastAPI\ollama\convert_lora_to_gguf.py&quot;, line 373, in &lt;module&gt;
model_instance.gguf_writer.add_string(gguf.Keys.General.FILE_TYPE, gguf.GGUFType.ADAPTER)
AttributeError: module &#39;gguf&#39; has no attribute &#39;GGUFType&#39;

似乎所有代码和 gguf 包都不支持 llava，只支持 llama。我必须将我自己训练的模型转换为 gguf。我无法使用 hugging face 的 gguf llava 模型进行推理。
有没有办法转换它？]]></description>
      <guid>https://stackoverflow.com/questions/78763327/convert-safetensors-model-formatllava-model-into-gguf-format</guid>
      <pubDate>Thu, 18 Jul 2024 08:47:53 GMT</pubDate>
    </item>
    <item>
      <title>神经网络成本不变</title>
      <link>https://stackoverflow.com/questions/78763209/neural-network-cost-not-changing</link>
      <description><![CDATA[我似乎无法弄清楚为什么我的成本打印功能每次都给我相同的成本而我的权重和偏差却没有改变。非常感谢您的帮助，我尝试将其放入聊天机器人中，但他们也认为没有错误。
我尝试在各个地方更改代码，但成本仍然没有下降。
import numpy as np

def initialize_params(n_x, n_h, n_y):
W1 = np.random.randn(n_h, n_x) * 0.01
b1 = np.zeros((n_h, 1))
W2 = np.random.randn(n_y, n_h) * 0.01
b2 = np.zeros((n_y, 1))

parameters = {&quot;W1&quot;: W1, &quot;W2&quot;: W2, &quot;b1&quot;: b1, &quot;b2&quot;: b2}
return参数

def sigmoid(x):
返回 1 / (1 + np.exp(-x))

def forward_propagation(X, 参数):
W1 = 参数[&quot;W1&quot;]
b1 = 参数[&quot;b1&quot;]
W2 = 参数[&quot;W2&quot;]
b2 = 参数[&quot;b2&quot;]

Z1 = np.dot(W1, X) + b1
A1 = np.tanh(Z1)
Z2 = np.dot(W2, A1) + b2
A2 = sigmoid(Z2)

cache = {&quot;Z1&quot;: Z1, &quot;A1&quot;: A1, &quot;Z2&quot;: Z2, &quot;A2&quot;: A2}
assert(A2.shape == (1, X.shape[1]))
返回 A2,缓存

def cost_function(A2, Y):
m = Y.shape[1] 
logprob = np.multiply(np.log(A2), Y) + np.multiply((1 - Y), np.log(1 - A2))
cost = -1/m * np.sum(logprob) 
返回成本

def reverse_propagation(parameters, cache, X, Y):
m = X.shape[1]
W1 = 参数[&quot;W1&quot;]
W2 = 参数[&quot;W2&quot;]
A1 = 缓存[&quot;A1&quot;]
A2 = 缓存[&quot;A2&quot;]

dZ2 = A2 - Y
dW2 = 1/m * np.dot(dZ2, A1.T)
db2 = 1/m * np.sum(dZ2, axis=1, keepdims=True)
dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))
dW1 = 1/m * np.dot(dZ1, X.T)
db1 = 1/m * np.sum(dZ1, axis=1, keepdims=True)

grads = {&quot;dW1&quot;: dW1, &quot;dW2&quot;: dW2, &quot;db1&quot;: db1, &quot;db2&quot;: db2}
return grads

def update_parameters(parameters, grads, learning_rate):
W1 = 参数[&quot;W1&quot;]
b1 = 参数[&quot;b1&quot;]
W2 = 参数[&quot;W2&quot;]
b2 =参数[&quot;b2&quot;]

dW1 = grads[&quot;dW1&quot;]
db1 = grads[&quot;db1&quot;]
dW2 = grads[&quot;dW2&quot;]
db2 = grads[&quot;db2&quot;]

W1 = W1 - 学习率 * dW1
b1 = b1 - 学习率 * db1
W2 = W2 - 学习率 * dW2
b2 = b2 - 学习率 * db2

参数 = {&quot;W1&quot;: W1, &quot;b1&quot;: b1, &quot;W2&quot;: W2, &quot;b2&quot;: b2}
返回参数

def nn_model(X, Y, n_x, n_h, n_y, num_iterations=10000, learning_rate=0.01):
参数 = 初始化参数(n_x, n_h, n_y)

对于 i in range(num_iterations):
A2, 缓存 = 前向传播(X, 参数)
成本 = 成本函数(A2, Y)
梯度 = 后向传播(参数, 缓存, X, Y)
参数 = 更新参数(参数, 梯度, 学习率)

如果 i % 1000 == 0:
打印(f&quot;迭代 {i}: 成本 {cost}&quot;)

返回参数

def test_xor():
X = np.array([[0, 0, 1, 1],
[0, 1, 0, 1]])
Y = np.array([[0, 1, 1, 0]])

n_x = X.shape[0]
n_h = 4
n_y = Y.shape[0]

参数 = nn_model(X, Y, n_x, n_h, n_y)

A2, _ = forward_propagation(X, 参数)
predictions = (A2 &gt; 0.5).astype(int)

print(&quot;预测：&quot;, predictions)
print(&quot;真标签：&quot;, Y)

断言 np.array_equal(predictions, Y), &quot;测试失败！&quot;
print(&quot;XOR 测试通过！&quot;)

test_xor()
]]></description>
      <guid>https://stackoverflow.com/questions/78763209/neural-network-cost-not-changing</guid>
      <pubDate>Thu, 18 Jul 2024 08:23:17 GMT</pubDate>
    </item>
    <item>
      <title>安装后无法在 Google Colab 中导入“bm3d”包</title>
      <link>https://stackoverflow.com/questions/78762914/unable-to-import-bm3d-package-in-google-colab-after-installation</link>
      <description><![CDATA[我正在尝试使用 bm3d 包在 Google Colab 中进行图像去噪。几天前我可以毫无问题地使用它。但是，现在即使软件包安装成功，我也遇到了导入错误。

安装 bm3d 软件包：
!pip install bm3d

尝试导入 bm3d 软件包：
import bm3d


观察到的错误：
ImportError：无法从 &#39;scipy._lib.deprecation&#39; (/usr/local/lib/python3.10/dist-packages/scipy/_lib/deprecation.py) 导入名称 &#39;_sub_module_deprecation&#39;

如何解决问题并在 colab 中导入软件包？]]></description>
      <guid>https://stackoverflow.com/questions/78762914/unable-to-import-bm3d-package-in-google-colab-after-installation</guid>
      <pubDate>Thu, 18 Jul 2024 07:16:33 GMT</pubDate>
    </item>
    <item>
      <title>双子座本月印刷日 [关闭]</title>
      <link>https://stackoverflow.com/questions/78762138/gemini-printing-days-of-the-month</link>
      <description><![CDATA[我尝试从下图中打印垃圾日，但无论我怎么尝试，都无法正确打印这些天。
我尝试了不同的温度和提示技术，但都不起作用。
我正在寻找双子座模型的提示
]]></description>
      <guid>https://stackoverflow.com/questions/78762138/gemini-printing-days-of-the-month</guid>
      <pubDate>Thu, 18 Jul 2024 01:57:06 GMT</pubDate>
    </item>
    <item>
      <title>XGBoostError：参数详细程度的值 -1 超出界限 [0,3]</title>
      <link>https://stackoverflow.com/questions/78761783/xgboosterror-value-1-for-parameter-verbosity-exceed-bound-0-3</link>
      <description><![CDATA[错误消息如标题所示。根据下面的代码，这对我来说毫无意义：
clf = xgboost.XGBClassifier(verbosity=1)
print (clf.__class__, clf.verbosity) 
# prints &lt;class &#39;xgboost.sklearn.XGBClassifier&#39;&gt; 1
clf.fit(X=train_data_iter[features].fillna(0), y=train_data_iter[&#39;y&#39;]) # 错误在这里出现

值显然是 1，但不知何故却变成了 -1？我不明白。]]></description>
      <guid>https://stackoverflow.com/questions/78761783/xgboosterror-value-1-for-parameter-verbosity-exceed-bound-0-3</guid>
      <pubDate>Wed, 17 Jul 2024 22:12:23 GMT</pubDate>
    </item>
    <item>
      <title>将 Tensorflow 模型转换为 CoreML 模型时出错</title>
      <link>https://stackoverflow.com/questions/78761234/error-converting-tensorflow-model-to-coreml-model</link>
      <description><![CDATA[NotImplementedError Traceback（最近一次调用最后一次）
Cell In[19]，第 1 行
----&gt; 1 mlmodel = ct.convert(model, convert_to=&quot;mlmodel&quot;, source=&quot;tensorflow&quot;)

文件 ~/anaconda3/lib/python3.11/site-packages/coremltools/converters/_converters_entry.py:551，在 convert(model, source, input, output, classifier_config, minimum_deployment_target, convert_to, compute_precision, skip_model_load, compute_units, package_dir, debug, pass_pipeline)
539 exact_target = _determine_target(convert_to, minimum_deployment_target)
540 _validate_conversion_arguments(
541 model,
542 exact_source,
(...)
549 minimum_deployment_target,
550 )
--&gt; 551 need_fp16_cast_pass = _need_fp16_cast_pass(compute_precision, exact_target)
553 如果 pass_pipeline 为 None:
554 pass_pipeline = PassPipeline()

文件 ~/anaconda3/lib/python3.11/site-packages/coremltools/converters/_converters_entry.py:624，位于 _need_fp16_cast_pass(compute_precision, convert_to)
620 def _need_fp16_cast_pass(
621 compute_precision: Optional[Union[precision, FP16ComputePrecision]], convert_to: Text
622 ) -&gt; bool:
623 if convert_to not in (&quot;mlprogram&quot;, &quot;neuralnetwork&quot;, &quot;milinternal&quot;, &quot;milpython&quot;):
--&gt; 624 raise NotImplementedError(f&quot;后端转换器 {convert_to} 未实现&quot;)
626 if compute_precision is None:
627 return convert_to != &quot;neuralnetwork&quot;

NotImplementedError: 后端转换器 mlmodel 未实现

不知道这个错误是什么意思。我正在尝试将使用 tensorflow 构建的 CNN 模型转换为 coreml 模型，但我一直收到上述错误。
mlmodel = ct.convert(model, convert_to=&quot;mlmodel&quot;, source=&quot;tensorflow&quot;)

这是在从保存的 .h5 文件导入模型后完成的。]]></description>
      <guid>https://stackoverflow.com/questions/78761234/error-converting-tensorflow-model-to-coreml-model</guid>
      <pubDate>Wed, 17 Jul 2024 19:08:55 GMT</pubDate>
    </item>
    <item>
      <title>基于密度的聚类算法的 DBCV 分数是否会奖励更细粒度的聚类？</title>
      <link>https://stackoverflow.com/questions/78760706/does-dbcv-score-for-density-based-clustering-algorithms-reward-more-granular-clu</link>
      <description><![CDATA[我正在尝试根据 DBCV 分数对 HDBSCAN 运行超参数搜索。据我观察，DBCV 分数通常对于更细粒度的集群更高。是因为 DBCV 奖励细粒度集群吗？还是因为我们越来越接近“实际”集群数量？我如何确定我的数据集的集群数量合适？]]></description>
      <guid>https://stackoverflow.com/questions/78760706/does-dbcv-score-for-density-based-clustering-algorithms-reward-more-granular-clu</guid>
      <pubDate>Wed, 17 Jul 2024 16:40:42 GMT</pubDate>
    </item>
    <item>
      <title>使用单个标记和二元标记进行语料库预处理的最佳方法？</title>
      <link>https://stackoverflow.com/questions/78758590/best-approach-corpus-pre-processing-with-single-tokens-and-bigram-tokens</link>
      <description><![CDATA[我想知道是否有关于如何以最聪明的方式解决这个问题的一般建议。
我正在使用 word2vec 来确定特定单词之间的相似度分数（这是我感兴趣的最终输出） - 其中一些是单个标记，但其他应该是二元词组。更复杂的是，我正在使用 tensorflow（为了学习如何使用 tensorflow）。
我想保留在单独列表中找到的二元语法：
Bigram_list = [&quot;northern lights&quot;, &quot;cloud cover&quot;, &quot;table leg&quot;,...]

目前，该过程应如下所示：

识别语料库中的二元语法（使用 nltk 搭配）
创建 identified_bigrams_list = [&quot;northern lights&quot;, &quot;cloud cover&quot;, &quot;banana peel&quot;,...]
在 identified_bigrams_list 中搜索匹配项Bigram_list
问题：用“_”替换语料库中的匹配项，例如“northern_light”、“cloud_cover”。我尝试使用 Bigram_list 的字典（例如 “northern lights”：“northern_lights”）。所以我试图将其放回语料库中，这样它将被视为单个标记并作为单个嵌入进行处理

即使我可以让它工作，但这似乎在计算上效率低下，尤其是当我转向更大的语料库进行实际训练时（目前使用一个很小的语料库来让它工作）。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78758590/best-approach-corpus-pre-processing-with-single-tokens-and-bigram-tokens</guid>
      <pubDate>Wed, 17 Jul 2024 09:02:44 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 中的梯度消失？[关闭]</title>
      <link>https://stackoverflow.com/questions/78757646/vanishing-gradient-in-transformer</link>
      <description><![CDATA[我使用 Pytorch 从头开始​​编写 Transformer 模型。我完成了所有数据预处理并过滤了数据集以供模型输入。
我根据自己所知所能做的一切都已经完成了。但是，模型学习效果并不好。尽管我的学习率高达 0.1，但梯度的数量级为 1e-07 左右。我尝试将 LR=1 设置为 1，只是为了检查是否有任何变化，但梯度仍然非常小。我知道这与 LR 无关，但不知道在哪里寻找变化，因为我已经多次反复查找架构代码。
所以我来这个社区寻求帮助。
我重新设计了我的代码并使用了大量打印语句，但架构正在运行并给出了应有的精确张量形状。除此之外，我不确定我到底应该寻找什么。因为我不知道应该更改代码的哪一部分以获得更好的结果。因此我在这里寻求帮助。
我在这里附上了我的 github repo 链接，以便有人可以轻松下载代码并查看它。
GitHub 链接
这是我的文件夹结构：
testssss.ipynb 不是必需的。
architecture.py：Transformer 架构的主要代码
model.py：结合 architecture.py 中的编码器和解码器
在此处输入图像描述
我试图制作一个从英文到韩文的字符级翻译器语言。]]></description>
      <guid>https://stackoverflow.com/questions/78757646/vanishing-gradient-in-transformer</guid>
      <pubDate>Wed, 17 Jul 2024 04:32:51 GMT</pubDate>
    </item>
    <item>
      <title>即使经过数百个时期，pytorch AdamW 的 LR 仍未衰减</title>
      <link>https://stackoverflow.com/questions/78752899/lr-not-decaying-for-pytorch-adamw-even-after-hundreds-of-epochs</link>
      <description><![CDATA[我有以下使用 Pytorch 中的 AdamW 优化器的代码：
optimizer = AdamW(params=self.model.parameters(), lr=0.00005)

我尝试使用 wandb 进行登录，如下所示：
lrs = {f&#39;lr_group_{i}&#39;: param_group[&#39;lr&#39;]
for i, param_group in enumerate(self.optimizer.param_groups)}
wandb.log({&quot;train_loss&quot;: avg_train_loss, &quot;val_loss&quot;: val_loss, **lrs})

请注意 weight_decay 参数的默认值为 0.01（对于 AdamW）。
当我检查 wandb 仪表板时，它显示 AdamW 的 LR 即使在 200 个 epoch 之后也相同，并且根本没有衰减。我尝试了几次。

为什么 LR 衰减没有发生？
此外，它仅显示一个参数组的 LR。为什么会这样？似乎我在这里错过了一些基本的东西。有人可以指出吗？]]></description>
      <guid>https://stackoverflow.com/questions/78752899/lr-not-decaying-for-pytorch-adamw-even-after-hundreds-of-epochs</guid>
      <pubDate>Tue, 16 Jul 2024 06:09:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 中的空间数据管理机器学习模型中的类别不平衡问题</title>
      <link>https://stackoverflow.com/questions/78733642/managing-problems-of-class-imbalance-in-machine-learning-models-using-spatial-da</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78733642/managing-problems-of-class-imbalance-in-machine-learning-models-using-spatial-da</guid>
      <pubDate>Thu, 11 Jul 2024 05:01:17 GMT</pubDate>
    </item>
    <item>
      <title>使用“pip install catboost”时出错：无法为 catboost 构建 wheel</title>
      <link>https://stackoverflow.com/questions/77133321/error-while-using-pip-install-catboost-failed-building-wheel-for-catboost</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77133321/error-while-using-pip-install-catboost-failed-building-wheel-for-catboost</guid>
      <pubDate>Tue, 19 Sep 2023 09:28:42 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 ImportError：无法从 Google Colaboratory 中的“sklearn.inspection”导入名称“DecisionBoundaryDisplay”？</title>
      <link>https://stackoverflow.com/questions/74628090/how-to-solve-importerror-cannot-import-name-decisionboundarydisplay-from-skl</link>
      <description><![CDATA[我正尝试在 Google Colaboratory 中设计一个决策树决策面，该决策树基于我的数据集中的特征对进行训练。
示例代码：
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.inspection import DecisionBoundaryDisplay
iris = load_iris()

但是 colab 产生了如下错误，
ImportError：无法从 
&#39;sklearn.inspection&#39; (/usr/local/lib/python3.7/dist-packages/sklearn/inspection/__init__.py) 导入名称“DecisionBoundaryDisplay”。

如何在 Google Colab 中解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/74628090/how-to-solve-importerror-cannot-import-name-decisionboundarydisplay-from-skl</guid>
      <pubDate>Wed, 30 Nov 2022 12:51:54 GMT</pubDate>
    </item>
    </channel>
</rss>