<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Fri, 22 Nov 2024 06:25:22 GMT</lastBuildDate>
    <item>
      <title>é¢„æµ‹ç®¡é“æ”¶è´­æ—¥æœŸçš„æ¨¡å‹</title>
      <link>https://stackoverflow.com/questions/79213087/model-to-predict-acquisition-date-for-pipeline</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79213087/model-to-predict-acquisition-date-for-pipeline</guid>
      <pubDate>Thu, 21 Nov 2024 22:25:24 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä¿®å¤å°è¯•é€šè¿‡ Azure Ai Studio é¡¹ç›®è®¿é—® VS ä»£ç æ—¶å‡ºç°çš„è®¿é—®é—®é¢˜</title>
      <link>https://stackoverflow.com/questions/79212964/how-to-fix-access-issues-when-trying-to-access-vs-code-via-azure-ai-studio-proje</link>
      <description><![CDATA[æˆ‘ä»¬ä» Windows æœºå™¨è®¿é—® Azure AI Studio Compute æ—¶é‡åˆ°ä¸€ä¸ªé—®é¢˜ã€‚å½“è®¡ç®—å‡†å¤‡å°±ç»ªå¹¶å°è¯•é€šè¿‡ VScode Desktop è®¿é—®å®ƒæ—¶ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°ä»¥ä¸‹é”™è¯¯æ¶ˆæ¯ï¼šåœ¨é—¨æˆ·ä¸Š

è¿™æ˜¯æˆ‘ä» Vscode è·å¾—çš„æ‰©å±•ï¼š

æ­¤é—®é¢˜ä»…å‘ç”Ÿåœ¨ Windows è®¡ç®—æœºä¸Šï¼Œä» Mac è®¡ç®—æœºè®¿é—®æ—¶ä¸ä¼šå‘ç”Ÿæ­¤é—®é¢˜ã€‚ Compute å®ä¾‹å·²å¯åŠ¨å¹¶æ­£åœ¨è¿è¡Œï¼Œä½†å°è¯•æ‰“å¼€ vscode æ—¶å‡ºç°é”™è¯¯ã€‚å¯¹æ­¤æœ‰ä»»ä½•è§£å†³æ–¹æ¡ˆå—ï¼Ÿ
]]></description>
      <guid>https://stackoverflow.com/questions/79212964/how-to-fix-access-issues-when-trying-to-access-vs-code-via-azure-ai-studio-proje</guid>
      <pubDate>Thu, 21 Nov 2024 21:17:20 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨ä½¿ç”¨ dataloader æµ‹è¯•æ•°æ®é›†æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥è®¾ç½® shuffle=true å—ï¼Ÿæˆ–è€…è¿™æ— æ‰€è°“ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79212687/in-testing-dataset-using-dataloader-should-we-set-shuffle-true-or-it-doesnt-m</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªè‡ªå®šä¹‰æ•°æ®é›†ï¼ˆæŠ«è¨ã€å¯¿å¸å’Œç‰›æ’çš„å›¾ç‰‡ï¼‰ã€‚
æˆ‘æ­£åœ¨ä½¿ç”¨ torch DataLoader æ¥å¤„ç†å®ƒï¼Œç°åœ¨åœ¨ç¼–å†™æµ‹è¯•æ•°æ®åŠ è½½å™¨è‡ªå®šä¹‰æ—¶ï¼Œæˆ‘ä»¬åº”è¯¥è®¾ç½® shuffle=true è¿˜æ˜¯è¿™æ— å…³ç´§è¦ï¼Ÿï¼Ÿ
æˆ‘è¿˜æ²¡æœ‰çœ‹åˆ°åŒºåˆ«ï¼Œåªæ˜¯é—®ä¸€èˆ¬æƒ…å†µã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79212687/in-testing-dataset-using-dataloader-should-we-set-shuffle-true-or-it-doesnt-m</guid>
      <pubDate>Thu, 21 Nov 2024 19:33:30 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆæˆ‘çš„ ML æ¨¡å‹åœ¨ä¸åŒçš„è¿è¡Œä¸­è·å¾—ä¸åŒçš„æ€§èƒ½ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79212471/why-do-i-get-different-performance-on-different-runs-on-my-ml-model</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ snowpark è®­ç»ƒ ml æ¨¡å‹ï¼ˆXgboost å’Œ LightGbmï¼‰ï¼Œä½†æ¯æ¬¡è¿è¡Œåæˆ‘éƒ½ä¼šå¾—åˆ°ä¸åŒçš„æŒ‡æ ‡å€¼ï¼ˆAUCã€å¹³å‡ç²¾åº¦ï¼‰ï¼Œå› æ­¤æ°¸è¿œä¸çŸ¥é“å“ªä¸ªæ˜¯æˆ‘æœ€å¥½çš„æ¨¡å‹ã€‚
æˆ‘å°è¯•åœ¨ç¬”è®°æœ¬çš„å¼€å¤´è®¾ç½®ä¸€ä¸ªå…¨å±€å˜é‡ random_seed = 42ï¼Œå¹¶å°†å…¶æ”¾åœ¨æˆ‘çš„æ¬ é‡‡æ ·å‡½æ•°å’Œæ¨¡å‹çš„åˆå§‹åŒ–ä¸­ï¼š
 if model_type == &#39;xgboost&#39;:
model = XGBClassifier(
random_state=random_seed,
input_cols=feature_cols,
label_cols=target_col,
output_cols=[&#39;PREDICTION&#39;],
passthrough_cols=[&#39;INDIVIDUAL_SK&#39;, &#39;DATE_MONTH&#39;],
**hyperparameters
)

elif model_type == &#39;lightgbm&#39;:
model = LGBMClassifierï¼ˆ
random_state=random_seedï¼Œ
input_cols=feature_colsï¼Œ
label_cols=target_colï¼Œ
output_cols=[&#39;PREDICTION&#39;]ï¼Œ
passthrough_cols=[&#39;INDIVIDUAL_SK&#39;ï¼Œ&#39;DATE_MONTH&#39;]ï¼Œ
**è¶…å‚æ•°

)

def undersample_majority_classï¼ˆdfï¼‰ï¼š

df_with_seniority = df.with_columnï¼ˆâ€œyears_sinceâ€ï¼Œï¼ˆF.colï¼ˆ&#39;TIME_SINCE_FIRST_LEAD&#39;ï¼‰/12ï¼‰ã€‚castï¼ˆ&#39;int&#39;ï¼‰ï¼‰

df_with_random = df_with_seniority.with_columnï¼ˆ&#39;random_order&#39;ï¼ŒF.randomï¼ˆseed=random_seedï¼‰ï¼‰
window_spec = Window.partition_by(&quot;INDIVIDUAL_SK&quot;).order_by(F.col(&#39;random_order&#39;).asc())
df_ranked = df_with_random.with_column(&quot;month_rank&quot;, F.row_number().over(window_spec)
)

df_majority = df_ranked.filter(F.col(&quot;CONVERSION_INDICATOR&quot;) == 0)
df_majority_sampled = df_majority.filter(((F.col(&quot;years_since&quot;) &gt; 10) &amp; (F.col(&quot;month_rank&quot;) == 1)) |
((F.col(&quot;years_since&quot;) &lt;= 10) &amp; (F.col(&quot;month_rank&quot;) &lt;= 2))
)

df_majority_sampled = df_majority_sampled.drop(&#39;years_since&#39;,&#39;month_rank&#39;,&#39;random_order&#39; )
df_minority = df.filter(F.col(&quot;CONVERSION_INDICATOR&quot;) == 1)
df_balanced = df_majority_sampled.union_all(df_minority)

return df_balanced

æˆ‘ä¸çŸ¥é“è¯¥æ€ä¹ˆåšæ‰èƒ½è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

]]></description>
      <guid>https://stackoverflow.com/questions/79212471/why-do-i-get-different-performance-on-different-runs-on-my-ml-model</guid>
      <pubDate>Thu, 21 Nov 2024 18:16:23 GMT</pubDate>
    </item>
    <item>
      <title>ANN æ¨¡å‹çš„å‡†ç¡®æ€§ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79212222/accuracy-of-the-ann-model</link>
      <description><![CDATA[æˆ‘æ›¾å°è¯•ä½¿ç”¨å†å²æ•°æ®æ„å»ºä¸€ä¸ª ANN æ¨¡å‹æ¥é¢„æµ‹å¤ªé˜³è¾å°„ã€‚
2016 - 2020 NSRDB æ•°æ®
ä»¥ä¸‹æ˜¯è¯„ä¼°æŒ‡æ ‡
R2 å€¼ .999
MSE .690
MAE .450
æŸå¤± .690
ä»¥ä¸‹æ˜¯æˆ‘çš„é—®é¢˜
ANN æ¨¡å‹çš„å‡†ç¡®ç‡è¾¾åˆ° .999 æ˜¯å¦æ­£å¸¸
æ˜¯å¦è¿‡åº¦æ‹Ÿåˆï¼Ÿ
æˆ‘é™„ä¸Šäº†è®­ç»ƒæŸå¤±ä¸éªŒè¯æŸå¤±å›¾]]></description>
      <guid>https://stackoverflow.com/questions/79212222/accuracy-of-the-ann-model</guid>
      <pubDate>Thu, 21 Nov 2024 16:58:23 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰æ²¡æœ‰åŠæ³•å¯ä»¥ä½¿ç”¨çº¯æ•°å­—ä¿¡å·å¤„ç†æ¦‚å¿µæå–å¹¶åˆ†ç±»è„‘ç”µå›¾æ•°æ®[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79211719/is-there-a-way-that-i-can-extract-and-then-classify-eeg-data-using-pure-digital</link>
      <description><![CDATA[æˆ‘æ­£åœ¨åšä¸€ä¸ªä½¿ç”¨è„‘ç”µå›¾ä¿¡å·æ•°æ®æ£€æµ‹é©¾é©¶å‘˜å›°å€¦çš„é¡¹ç›®ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¿¡å·ä»å™ªéŸ³å’Œå…¶ä»–ä¼ªå½±ä¸­åˆ†ç¦»å‡ºæ¥ï¼Œä½†åæ¥æˆ‘ä»¬å¦‚ä½•è¯†åˆ«å›°å€¦çŠ¶æ€
æˆ‘å°è¯•ç ”ç©¶å®ƒï¼Œä½†æˆ‘å‘ç°æœºå™¨å­¦ä¹ å‡ ä¹æ— å¤„ä¸åœ¨ï¼Œæˆ‘æ­£åœ¨å¯»æ‰¾ä½¿ç”¨æ•°å­—å›¾åƒå¤„ç†ä»è„‘ç”µå›¾ä¿¡å·ä¸­è¯†åˆ«å›°å€¦çš„æ–¹æ³•ï¼ˆä¹Ÿæ˜¯ç”µå­å’Œé€šä¿¡å·¥ç¨‹è¯¾ç¨‹çš„ä¸»é¢˜ï¼‰]]></description>
      <guid>https://stackoverflow.com/questions/79211719/is-there-a-way-that-i-can-extract-and-then-classify-eeg-data-using-pure-digital</guid>
      <pubDate>Thu, 21 Nov 2024 14:53:06 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ pytorch æœ€å°åŒ–æ±‰æ˜è·ç¦»</title>
      <link>https://stackoverflow.com/questions/79211677/minimization-of-hamming-distance-with-pytorch</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ª mxn çŸ©é˜µï¼Œå…¶ä¸­ m&gt;n å’Œä¸€ä¸ªå‘é‡ bã€‚å®ƒä»¬ä»…ç”± 1 å’Œ 0 ç»„æˆã€‚æ­¤å¤–ï¼Œæ‰€æœ‰åœ°æ–¹çš„å’Œéƒ½æ˜¯ä»¥ 2 ä¸ºæ¨¡çš„ã€‚é€šè¿‡é«˜æ–¯æ¶ˆå…ƒæ³•ï¼Œæˆ‘å¯ä»¥å¾—åˆ° Ax=b çš„è§£ x_pã€‚è¿™æ˜¯ä¸€ä¸ªåŒ…å« 1 å’Œ 0 çš„å‘é‡ã€‚è¿™ä¸æ˜¯å”¯ä¸€çš„è§£å†³æ–¹æ¡ˆã€‚å­˜åœ¨å…¶ä»–åŒ…å«è¾ƒå°‘ 1 çš„è§£ã€‚æˆ‘æƒ³æ‰¾åˆ°åŒ…å«æœ€å°‘ 1 çš„è§£ï¼ˆæ±‰æ˜è·ç¦»ï¼‰ï¼Œå³æˆ‘æƒ³æœ€å°åŒ–æ±‰æ˜è·ç¦»ã€‚
ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘æƒ³åˆ°äº†ä½¿ç”¨ pytorch çš„æ¢¯åº¦ä¸‹é™æ³•ã€‚è¿™æ˜¯æˆ‘çš„ä»£ç ï¼š
def optimal_solution(self, max_iter=100, lr=0.0054, lambda_param=10):

matrix = self.relative_boundary()
# åœ¨ [0,1] ä¸­åˆå§‹åŒ– x å¹¶è½¬æ¢ä¸º pytorch å¼ é‡
x = self.solve()

matrix = torch.tensor(matrix, dtype=torch.float32)
b = torch.tensor(self.boundary_vector, dtype=torch.float32)
x = torch.tensor(x, dtype=torch.float32, require_grad=True)

# Adam æ˜¯æ¢¯åº¦ä¸‹é™çš„é«˜çº§ç‰ˆæœ¬ï¼Œå¯åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­è°ƒæ•´å­¦ä¹ ç‡ã€‚
optimizer = torch.optim.Adam([x], lr=lr)

# è·Ÿè¸ª x å˜åŒ–çš„æ ‡å‡†
prev_x = x.clone()

# å¾ªç¯æ‰§è¡Œæ¢¯åº¦ä¸‹é™ï¼Œæœ€å¤šè¿­ä»£ max_iter æ¬¡ï¼š
for _ in range(max_iter):
optimizer.zero_grad()

# å®šä¹‰æŸå¤±å‡½æ•°ï¼šç¨€ç–æ€§ + çº¦æŸæ»¡è¶³
loss = torch.sum(x) + lambda_param * torch.sum((matrix @ x - b) ** 2)

# è·Ÿè¸ª x çš„å˜åŒ–é‡
change_in_x = torch.norm(x - prev_x).item()

# è®¡ç®—ç›¸å¯¹äº x çš„æŸå¤±æ¢¯åº¦
loss.backward()
# æ ¹æ®æ¢¯åº¦æ›´æ–° x çš„å€¼
optimizer.step()

# åº”ç”¨è½¯æŠ•å½±ï¼ˆä¾‹å¦‚ S å‹ï¼‰ä½¿ x ä¿æŒåœ¨ [0, 1] ä¸­
x.data = torch.clamp(x.data, 0, 1)

# å¯é€‰åœ°æ‰“å°æŸå¤±ä»¥è¿›è¡Œè°ƒè¯•
print(f&quot;è¿­ä»£ {_} æ—¶çš„æŸå¤±ï¼š{loss.item()}, x çš„å˜åŒ–ï¼š{change_in_x}&quot;)

# ä»è®¡ç®—å›¾ä¸­åˆ†ç¦» PyTorch å¼ é‡å¹¶å°†å…¶è½¬æ¢ä¸º NumPy æ•°ç»„ï¼›
# åº”ç”¨ 0.5 çš„é˜ˆå€¼å°†å€¼è½¬æ¢ä¸º 0 æˆ– 1ã€‚
# ç„¶åå‡½æ•°è¿”å›äºŒè¿›åˆ¶è§£å†³æ–¹æ¡ˆå‘é‡ã€‚
x_binary = (x.detach().numpy() &gt; 0.5).astype(int)

return x_binary

ä½†æ˜¯ï¼Œé€šè¿‡å°è¯•ä¸åŒçš„ lambda_par å’Œå­¦ä¹ ç‡ï¼Œæˆ‘è¦ä¹ˆå¾—åˆ°é›¶å‘é‡ï¼Œè¦ä¹ˆå®ƒåªè¾“å‡ºä¸€ä¸ªå…·æœ‰è¾ƒå°‘ 1 çš„å‘é‡ï¼Œä½†ä¸æ»¡è¶³æ–¹ç¨‹ Ax=bã€‚æ‚¨å¯¹æœ‰æ•ˆçš„ä»£ç æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79211677/minimization-of-hamming-distance-with-pytorch</guid>
      <pubDate>Thu, 21 Nov 2024 14:43:15 GMT</pubDate>
    </item>
    <item>
      <title>VAE æŸå¤±å‡å°‘ï¼Œä½†é‡å»ºæ•ˆæœå¹¶æœªæ”¹å–„</title>
      <link>https://stackoverflow.com/questions/79211354/vae-loss-decreases-but-reconstruction-doesnt-improve</link>
      <description><![CDATA[æˆ‘é‡åˆ°äº†é‡å»ºå›¾åƒæ ¹æœ¬ä¸èµ·ä½œç”¨çš„é—®é¢˜ã€‚ä¸‹é¢æ˜¯æˆ‘æ‰§è¡Œå•ä¸ªæ›´æ–°æ­¥éª¤çš„æ–¹æ³•ã€‚æˆ‘çŸ¥é“å¸¸è§„ VAE å¯ä»¥å®ç°æ›´ç®€å•çš„å®ç°ï¼Œä½†ç”±äºå…¶ä»–é™åˆ¶ï¼Œæˆ‘éœ€è¦ä»¥è¿™ç§æ–¹å¼å®ç°å®ƒã€‚å› æ­¤ï¼Œæˆ‘æƒ³çŸ¥é“æ­¤å®ç°ä¸­æ˜¯å¦å­˜åœ¨ä»»ä½•é”™è¯¯ï¼Œè€Œä¸æ˜¯è¦æ±‚æ›´é«˜æ•ˆçš„å®ç°ã€‚zeros_like_batchstats å‡½æ•°è¿”å›ä¸€ä¸ªä¸è¾“å…¥å…·æœ‰ç›¸åŒç»“æ„ä½†æ‰€æœ‰å€¼éƒ½è®¾ç½®ä¸ºé›¶çš„å¯¹è±¡ã€‚
@jax.jit
def train_step(
rng: jax.random.PRNGKey,
state_enc: TrainState,
state_dec: TrainState,
imgs: jax.Array,
) -&gt; Tuple[TrainState, TrainState, Dict]:

((mean, logvar), enc_mutated_vars), vjp_fn_enc = jax.vjp(
lambda params: state_enc.apply_fn(
{&quot;params&quot;: params, &quot;batch_stats&quot;: state_enc.batch_stats},
imgs, train=True, mutable=[&quot;batch_stats&quot;]
),
state_enc.params,
)
z, vjp_fn_latents = jax.vjp(
lambda mean, logvar: sample_z(rng, mean, logvar),
mean, logvar
)

def recon_loss_fn(dec_params, latent_features):
# ä»è§£ç å™¨è·å–é‡å»ºå›¾åƒ
recon, mutated_vars = state_dec.apply_fn(
{&#39;params&#39;: dec_params, &#39;batch_stats&#39;: state_dec.batch_stats},
latent_features, train=True, mutable=[&#39;batch_stats&#39;]
)
recon_loss = jnp.mean(jnp.sum(binary_cross_entropy_fn(recon, imgs), axis=(1, 2, 3), keepdims=True))
è¿”å› recon_loss, mutated_vars

recon_loss_grads_fn = jax.value_and_grad(recon_loss_fn, argnums=(0, 1), has_aux=True)
(recon_loss, dec_mutated_vars), (grads_dec, graz_z) = recon_loss_grads_fn(state_dec.params, z)
    grads_enc_recon=vjp_fn_enc((vjp_fn_latents(graz_z), {â€œbatch_statsâ€: Zeros_like_batchstats(state_enc.batch_stats)}))[0]

    # è®¡ç®—kld_loss
    def kld_loss_fn(å¹³å‡å€¼, logvar):
        kld_loss = jnp.mean(jnp.sum(-0.5 * (1 + logvar - å¹³å‡å€¼ ** 2 - jnp.exp(logvar)), axis=1))
        è¿”å› kld_loss

    kld_loss_grads_fn = jax.value_and_grad(kld_loss_fn, argnums=(0, 1))
    kld_loss, grads_mean_and_logvar = kld_loss_grads_fn(å¹³å‡å€¼, logvar)
    grads_enc_kld = vjp_fn_enc((grads_mean_and_logvar, {&quot;batch_stats&quot;: zeros_like_batchstats(state_enc.batch_stats)}))[0]

# è®¡ç®—ç¼–ç å™¨çš„æ¢¯åº¦
grads_enc = jax.tree_util.tree_map(lambda x, y: x + y, grads_enc_recon, grads_enc_kld)

# å­˜å‚¨æ¢¯åº¦å’Œæ‰¹æ¬¡ç»Ÿè®¡ä¿¡æ¯\
state_enc = state_enc.apply_gradients(grads=grads_enc, batch_stats=enc_mutated_vars[&quot;batch_stats&quot;])
state_dec = state_dec.apply_gradients(grads=grads_dec, batch_stats=dec_mutated_vars[&quot;batch_stats&quot;])

metrics = {
&quot;train/recon_loss&quot;: recon_loss,
&quot;train/kld_loss&quot;: kld_loss,
}
return state_enc, state_dec, metrics

æˆ‘å·²ç¡®è®¤å½¢çŠ¶æ²¡æœ‰é—®é¢˜ï¼Œå¹¶ä¸”æŸå¤±ä¹Ÿåœ¨å‡å°‘ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79211354/vae-loss-decreases-but-reconstruction-doesnt-improve</guid>
      <pubDate>Thu, 21 Nov 2024 13:23:11 GMT</pubDate>
    </item>
    <item>
      <title>å…³äº Talebi è®ºæ–‡ä¸­ç©ºé—´å†³ç­–æ ‘åˆ†è£‚é€»è¾‘çš„æ¾„æ¸… [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79209559/clarification-on-splitting-logic-in-spatial-decision-trees-on-talebi-paper</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ç ”ç©¶ Talebi ç­‰äººçš„è®ºæ–‡â€œç”¨äºåœ°çƒç§‘å­¦æ•°æ®åˆ†æå’Œå»ºæ¨¡çš„çœŸæ­£ç©ºé—´éšæœºæ£®æ—ç®—æ³•â€ï¼Œæˆ‘å¯¹å›¾ 2 æ‰€ç¤ºçš„ç©ºé—´å†³ç­–æ ‘è¿‡ç¨‹æœ‰ä¸€äº›ç–‘é—®ã€‚
æ··åˆæ—‹è½¬å’Œç¼©æ”¾ï¼š
æˆ‘çš„ç†è§£æ˜¯ï¼Œå¯¹äºæ¯ä¸ªå•å…ƒæ ¼ï¼Œå¤šä¸ªå°ºåº¦å’Œæ—‹è½¬çš„ç©ºé—´æ¨¡å¼è¢«çŸ¢é‡åŒ–å¹¶è¿æ¥æˆå•ä¸ªè¾“å…¥å‘é‡ã€‚ç„¶ååœ¨æ ‘åˆ†å‰²è¿‡ç¨‹ä¸­å°†æ­¤è¾“å…¥ç”¨ä½œé¢„æµ‹å™¨ã€‚è¿™æ˜¯æ­£ç¡®çš„å—ï¼Ÿ
æ­¤å¤–ï¼Œæ¨¡å‹å¦‚ä½•ç¡®ä¿æ¥è‡ªä¸åŒæ—‹è½¬å’Œå°ºåº¦çš„æ¨¡å¼åœ¨æ··åˆæˆä¸€ä¸ªå‘é‡æ—¶ä¿ç•™å…¶ç©ºé—´ä¸Šä¸‹æ–‡ï¼Ÿ
åˆ†å‰²ä¸­ç°è‰²åŒºåŸŸçš„ç§»åŠ¨ï¼š
åœ¨å›¾ 2 ä¸­ï¼Œæˆ‘æ³¨æ„åˆ°ç°è‰²å•å…ƒæ ¼ä¼¼ä¹ä»£è¡¨æ•°æ®çš„ä¸€ä¸ªå­é›†ï¼Œåœ¨åˆ†å‰²è¿‡ç¨‹ä¸­ä»ä¸­é—´ç§»åŠ¨åˆ°è§’è½ã€‚

è¿™æ˜¯å¦è¡¨æ˜éšç€æ ‘åˆ†å‰²æˆæ›´å°çš„åŒºåŸŸï¼Œé¢„æµ‹ç©ºé—´ä¼šç¼©å°ï¼Ÿ
è¿™ç§ç§»åŠ¨æ˜¯å°†æ¨¡å¼è¿‡æ»¤æˆæ›´å‡åŒ€çš„å­é›†çš„ç»“æœï¼Œè¿˜æ˜¯ä»£è¡¨äº†æ•°æ®ä¸­ç©ºé—´ä¾èµ–æ€§çš„ç‰¹å®šå†…å®¹ï¼Ÿ

ç¬¬äºŒæ¬¡åˆ†å‰²ä¸­çš„ä¸åŒç°è‰²åŒºåŸŸï¼š

ä¸ºä»€ä¹ˆç¬¬äºŒæ¬¡åˆ†å‰²çš„å·¦åˆ†æ”¯ä¸­çš„ç°è‰²åŒºåŸŸä¿ç•™åœ¨ç¬¬ä¸€ä¸ª-ğ‘…ä¸­ï¼Œè€Œåœ¨å³åˆ†æ”¯ä¸­ï¼Œå®ƒè½¬ç§»åˆ°ç¬¬äºŒä¸ª-ğ‘…ï¼Ÿ
è¿™æ˜¯å¦è¡¨æ˜é€‰æ‹©ä¸åŒçš„é¢„æµ‹å› å­æ¥åˆ†å‰²å·¦åˆ†æ”¯å’Œå³åˆ†æ”¯ï¼Ÿ
å¦‚æœæ˜¯è¿™æ ·ï¼Œè¿™æ˜¯å¦çªå‡ºäº†æ•°æ®é›†ä¸­çš„ç©ºé—´å¼‚è´¨æ€§ï¼Ÿ

ä»»ä½•å…³äºè¿™åœ¨ç©ºé—´å†³ç­–æ ‘ä¸­å¦‚ä½•å·¥ä½œçš„è¯´æ˜æˆ–ç¤ºä¾‹éƒ½å°†éå¸¸æœ‰å¸®åŠ©ã€‚
æˆ‘å°è¯•äº†ä»€ä¹ˆï¼š
æˆ‘å›é¡¾äº†å›¾ 2 çš„æè¿°å’Œè®ºæ–‡â€œç”¨äºåœ°çƒç§‘å­¦æ•°æ®åˆ†æå’Œå»ºæ¨¡çš„çœŸæ­£ç©ºé—´éšæœºæ£®æ—ç®—æ³•â€ä¸­çš„æ–¹æ³•ã€‚æˆ‘è¯•å›¾äº†è§£ç°è‰²åŒºåŸŸå¦‚ä½•å¯¹åº”äºç©ºé—´æ¨¡å¼å’Œç”¨äºåˆ†å‰²çš„é¢„æµ‹å› å­ã€‚
æˆ‘é¢„æœŸä¼šå‘ç”Ÿä»€ä¹ˆï¼š
æˆ‘é¢„æœŸç°è‰²åŒºåŸŸä»£è¡¨é¢„æµ‹å› å­ç©ºé—´çš„ä¸€è‡´åˆ’åˆ†ï¼Œå…¶ä¸­æ¯ä¸ªåˆ†å‰²å¯¹åº”äºæ‰€æœ‰åˆ†æ”¯ä¸­çš„ç›¸åŒé¢„æµ‹å› å­æˆ–ç©ºé—´æ¨¡å¼å­é›†ã€‚
å®é™…å‘ç”Ÿäº†ä»€ä¹ˆï¼š
æˆ‘è§‚å¯Ÿåˆ°åœ¨ç¬¬äºŒæ¬¡åˆ†å‰²ä¸­ï¼Œå·¦åˆ†æ”¯å’Œå³åˆ†æ”¯ä¹‹é—´çš„ç°è‰²åŒºåŸŸä¸åŒã€‚åœ¨å·¦ä¾§ï¼Œç°è‰²åŒºåŸŸå¯¹åº”äºç¬¬ä¸€ä¸ªé¢„æµ‹å› å­ï¼Œè€Œåœ¨å³ä¾§ï¼Œå®ƒè½¬ç§»åˆ°ç¬¬äºŒä¸ªé¢„æµ‹å› å­ã€‚æˆ‘ä¸ç¡®å®šè¿™ç§å·®å¼‚æ˜¯ç”±äºç©ºé—´å¼‚è´¨æ€§ã€ç‹¬ç«‹é¢„æµ‹å› å­é€‰æ‹©è¿˜æ˜¯å…¶ä»–åŸå› é€ æˆçš„ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79209559/clarification-on-splitting-logic-in-spatial-decision-trees-on-talebi-paper</guid>
      <pubDate>Thu, 21 Nov 2024 03:11:43 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨å¤„ç† EOS ä»£å¸æ—¶è®¡ç®—æ‹¥æŠ±äººè„¸æ¨¡å‹çš„æ•™å¸ˆå¼ºåˆ¶å‡†ç¡®åº¦ (TFA)ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79209319/how-to-compute-teacher-forced-accuracy-tfa-for-hugging-face-models-while-handl</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79209319/how-to-compute-teacher-forced-accuracy-tfa-for-hugging-face-models-while-handl</guid>
      <pubDate>Thu, 21 Nov 2024 00:25:48 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆ gamma=0 çš„äºŒå…ƒç„¦ç‚¹äº¤å‰ç†µæ€»æ˜¯ä¼šäº§ç”Ÿ nan æŸå¤±ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79207979/why-does-binary-focal-cross-entropy-with-gamma-0-always-make-nan-loss</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è®­ç»ƒä¸€ä¸ª U-Net æ¥å¯¹æˆ‘ä»¬çš„å®éªŒå›¾åƒè¿›è¡ŒäºŒå€¼åŒ–ã€‚ä½†å‰æ™¯é€šå¸¸æ²¡æœ‰å¾—åˆ°å¾ˆå¥½çš„ä½“ç°ï¼Œæ¢å¥è¯è¯´ï¼Œæˆ‘æœ‰ç±»åˆ«ä¸å¹³è¡¡ï¼Œç½‘ç»œå­¦ä¹ å¾—ä¸å¥½ã€‚æˆ‘ä¸€ç›´åœ¨ä½¿ç”¨ BinaryCrossEntropy ä½œä¸ºæŸå¤±å‡½æ•°ã€‚æ‰€ä»¥ï¼Œæˆ‘æ˜ç™½è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ä¸ªç®€å•æ–¹æ³•æ˜¯å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„æŸå¤±å‡½æ•°ï¼Œä¸ºæ¯ä¸ªç±»åˆ«èµ‹äºˆæƒé‡ã€‚ä½†æˆ‘åœ¨è¿™æ ·åšæ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œæ‰€ä»¥æ”¾å¼ƒäº†è¿™ä¸ªå°è¯•ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œä½¿ç”¨ BinaryFocalCrossEntropy ä¼¼ä¹æ›´ç®€å•ï¼Œå®ƒçš„è¡¨è¾¾å¼ä¸ºï¼ˆå¦‚æœæˆ‘ç†è§£å¾—å¥½çš„è¯ï¼‰

æ‰€ä»¥ï¼Œæˆ‘çš„è®¡åˆ’æ˜¯ä½¿ç”¨ gamma=0ï¼Œè¿™æ ·æˆ‘å°±å¯ä»¥é€šè¿‡è°ƒæ•´ alpha å€¼æ¥ç»™å‡ºç±»åˆ«æƒé‡ã€‚ä½†æ˜¯ï¼Œæˆ‘ä¸æ–­å¾—åˆ° nan æŸå¤±ã€‚å®ƒå‘ç”Ÿåœ¨å‡ ä¸ªæ‰¹æ¬¡ä¹‹åçš„ç¬¬ä¸€ä¸ªæ—¶æœŸå†…ï¼šï¼ˆè¿™é‡Œæˆ‘ä½¿ç”¨ \alpha = 0.75ï¼‰

åœ¨è¿™é‡Œæˆ‘ä½¿ç”¨äº† adam ä¼˜åŒ–å™¨å’Œ Learning_rate 1e-3ã€‚æˆ‘æ³¨æ„åˆ°ï¼Œå¦‚æœæˆ‘æ”¹ç”¨ 1e-4ï¼Œå³ä½¿ nan ä»ç„¶å‡ºç°ï¼Œå®ƒä¹Ÿä¼šå†å‡ºç°å‡ ä¸ªæ‰¹æ¬¡ã€‚ä½ èƒ½å¸®æˆ‘æ‰¾å‡ºè¿™æ˜¯æ€ä¹ˆå›äº‹ï¼Œæˆ‘è¯¥å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79207979/why-does-binary-focal-cross-entropy-with-gamma-0-always-make-nan-loss</guid>
      <pubDate>Wed, 20 Nov 2024 15:49:20 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ä¸åŒçš„æŸå¤±æ¥è®­ç»ƒä¸åŒé˜¶æ®µçš„æ¨¡å‹</title>
      <link>https://stackoverflow.com/questions/79205991/training-different-stage-of-model-with-different-loss</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è®­ç»ƒä¸€ä¸ªä¸¤é˜¶æ®µæ¨¡å‹ã€‚ä½†æ˜¯ï¼Œæˆ‘æƒ³ç”¨ä¸åŒçš„æŸå¤±æ›´æ–°æ¨¡å‹çš„ä¸åŒé˜¶æ®µã€‚ä¾‹å¦‚ï¼Œå‡è®¾ç«¯åˆ°ç«¯æ¨¡å‹ç”±ä¸¤ä¸ªæ¨¡å‹ç»„æˆï¼šmodel1 å’Œ model2ã€‚è¾“å‡ºæ˜¯é€šè¿‡è¿è¡Œè®¡ç®—çš„
features = model1(inputs)
output = model2(features)

æˆ‘æƒ³ç”¨ loss1 æ›´æ–° model1 çš„å‚æ•°ï¼ŒåŒæ—¶ä¿æŒ model2 çš„å‚æ•°ä¸å˜ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘æƒ³ç”¨ loss2 æ›´æ–° model2 çš„å‚æ•°ï¼ŒåŒæ—¶ä¿æŒ model1 çš„å‚æ•°ä¸å˜ã€‚æˆ‘çš„å®Œæ•´å®ç°å¦‚ä¸‹ï¼š
import torch
import torch.nn as nn

# å®šä¹‰ç¬¬ä¸€ä¸ªæ¨¡å‹
class Net(nn.Module):
def __init__(self):
super(Net, self).__init__()
self.conv1 = nn.Linear(20, 10)
self.conv2 = nn.Linear(10, 5)

def forward(self, x):
x = self.conv1(x)
x = self.conv2(x)
return x

# å®šä¹‰ç¬¬äºŒä¸ªæ¨¡å‹
class Net1(nn.Module):
def __init__(self):
super(Net1, self).__init__()
self.conv1 = nn.Linear(5, 1)

def forward(self, x):
x = self.conv1(x)
return x

# åˆå§‹åŒ–æ¨¡å‹
model1 = Net()
model2 = Net1()

# åˆå§‹åŒ–å•ç‹¬çš„æ¯ä¸ªæ¨¡å‹çš„ä¼˜åŒ–å™¨
optimizer = torch.optim.SGD(model1.parameters(), lr=0.1)
optimizer1 = torch.optim.SGD(model2.parameters(), lr=0.1)

optimizer.zero_grad() 
optimizer1.zero_grad()

criterion = nn.CrossEntropyLoss()

# æ ·æœ¬è¾“å…¥å’Œæ ‡ç­¾
inputs = torch.randn(2, 20)
labels = torch.randn(2,1)

features = model1(inputs) 
outputs_model = model2(features) 

loss1 = criterion(outputs_model[0], labels[0]) 
loss2 = criterion(outputs_model, labels) 

loss1.backward(retain_graph=True) 
optimizer.step() 
optimizer.zero_grad()
optimizer1.zero_grad() 

loss2.backward() 

ä½†æ˜¯ï¼Œè¿™å°†è¿”å›
å›æº¯ï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰ï¼š
æ–‡ä»¶ï¼Œç¬¬ 55 è¡Œï¼Œåœ¨ &lt;module&gt;
loss2.backward() 
^^^^^^^^^^^^^^^^^
æ–‡ä»¶ &quot;/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/_tensor.py&quot;, ç¬¬ 521 è¡Œ, åœ¨åå‘ä¼ æ’­ä¸­
torch.autograd.backward(
æ–‡ä»¶ &quot;/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py&quot;, ç¬¬ 289 è¡Œ, åœ¨åå‘ä¼ æ’­ä¸­
_engine_run_backward(
æ–‡ä»¶ &quot;/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py&quot;, ç¬¬ 769 è¡Œ, åœ¨ _engine_run_backward ä¸­
return Variable._execution_engine.run_backward( # è°ƒç”¨ C++ å¼•æ“è¿è¡Œåå‘ä¼ æ’­
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeErrorï¼šæ¢¯åº¦è®¡ç®—æ‰€éœ€çš„å˜é‡ä¹‹ä¸€å·²è¢«å°±åœ°æ“ä½œä¿®æ”¹ï¼š[torch.FloatTensor [10, 5]]ï¼ˆAsStridedBackward0 çš„è¾“å‡º 0ï¼‰å¤„äºç‰ˆæœ¬ 2ï¼›é¢„æœŸä¸ºç‰ˆæœ¬ 1ã€‚æç¤ºï¼šå¯ç”¨å¼‚å¸¸æ£€æµ‹ä»¥æŸ¥æ‰¾æ— æ³•è®¡ç®—æ¢¯åº¦çš„æ“ä½œï¼Œä½¿ç”¨ torch.autograd.set_detect_anomaly(True)ã€‚

æˆ‘æœ‰ç‚¹æ˜ç™½ä¸ºä»€ä¹ˆä¼šå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œä½†æœ‰åŠæ³•è§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79205991/training-different-stage-of-model-with-different-loss</guid>
      <pubDate>Wed, 20 Nov 2024 06:10:33 GMT</pubDate>
    </item>
    <item>
      <title>EOFErrorï¼šè¾“å…¥ä¸è¶³ - Pickle</title>
      <link>https://stackoverflow.com/questions/79198550/eoferror-ran-out-of-input-pickle</link>
      <description><![CDATA[å½“æˆ‘å°è¯•ä»¥ pickle æ ¼å¼åŠ è½½æœºå™¨å­¦ä¹ æ¨¡å‹ä»¥ä¾¿å®ƒåœ¨ Web åº”ç”¨ç¨‹åºä¸­è¿è¡Œæ—¶ï¼Œæˆ‘æ”¶åˆ°æ­¤é”™è¯¯ï¼Œè·¯å¾„æ˜¾ç„¶æ˜¯æ­£ç¡®çš„ï¼Œæˆ‘çš„æ‰€æœ‰æ–‡ä»¶éƒ½ä½äºåŒä¸€æ–‡ä»¶å¤¹ä¸­ã€‚ä½†æ˜¯ï¼Œé”™è¯¯å§‹ç»ˆå­˜åœ¨ã€‚

df = pd.DataFrame.from_dict(user_values, orient=&quot;index&quot;).T

with open(&quot;classifier.pkl&quot;, &quot;rb&quot;) as file:
loaded_model = pickle.load(file)

prediction = loaded_model.predict(df)[0][0]

else:
prediction = None

return render_template(&quot;index.html&quot;, prediction=prediction)

if __name__ == &quot;__main__&quot;:
app.run(debug=True)

]]></description>
      <guid>https://stackoverflow.com/questions/79198550/eoferror-ran-out-of-input-pickle</guid>
      <pubDate>Mon, 18 Nov 2024 02:30:01 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow InvalidArgumentErrorï¼šConcatOp ä¸­çš„è¿æ¥ç»´åº¦ä¸åŒ¹é… - å½¢çŠ¶ä¸åŒ¹é…</title>
      <link>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</guid>
      <pubDate>Wed, 30 Oct 2024 13:00:13 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹é¢„æµ‹è‚¡ç¥¨ä»·æ ¼æ—¶å‡†ç¡®ç‡èƒ½è¾¾åˆ° 100%ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/66154986/why-am-i-getting-100-accuracy-when-using-a-linear-regression-model-to-predict-s</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹åœ¨ Python ä¸­é¢„æµ‹è‚¡ç¥¨ä»·æ ¼ã€‚æˆ‘ä½¿ç”¨ train_test_split åˆ†å‰²æ•°æ®ï¼Œå› æ­¤æ®æˆ‘æ‰€çŸ¥ï¼Œæˆ‘çš„æµ‹è¯•æ•°æ®ä¸åº”è¯¥åœ¨æˆ‘çš„è®­ç»ƒæ•°æ®ä¸­ï¼Œæ‰€ä»¥æˆ‘ä¸æ˜ç™½ä¸ºä»€ä¹ˆæ¨¡å‹çš„å‡†ç¡®ç‡æ˜¯ 100%ã€‚
è¿™æ˜¯æˆ‘çš„ä»£ç ï¼š
X = RMV.drop(&#39;Close&#39;, axis=1)
y = RMV[&#39;Close&#39;]`

æ¥è‡ª sklearn.model_selection å¯¼å…¥ train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)

æ¥è‡ª sklearn.linear_model å¯¼å…¥ LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)

reg_preds = reg.predict(X_test)

å½“æˆ‘ä½¿ç”¨æ­¤ä»£ç è¿è¡Œäº¤å‰éªŒè¯ä»¥æµ‹è¯•å‡†ç¡®æ€§æ—¶ï¼Œæˆ‘å¾—åˆ°çš„å€¼ä¸º1.00ã€‚
scores = model_selection.cross_val_score(reg, X_test, y_test, cv=10)
print (&quot;Accuracy: %0.2f (+/- %0.2f)&quot; % (scores.mean(), scores.std() / 2)) 

ä½œä¸ºå‚è€ƒï¼Œä¸‹é¢æ˜¯æˆ‘ä½¿ç”¨çš„æ•°æ®æ ·æœ¬ï¼š
 æ”¶ç›˜ä»· SMA EMA MACD ä¸Šè½¨ ä¸­è½¨ ä¸‹è½¨ RSI
æ—¥æœŸ 
2010-02-18 60.900002 57.335715 57.419887 2.099073 64.842238 55.4075 45.972762   60.517959
2010-02-19 61.000000 57.967857 57.897236 2.215288 65.422290 55.9000 46.377710 60.672590
2010-02-22 62.099998 58.560714 58.457604 2.368843 66.047128 56.4675 46.887872 62.416318
2010-02-23 61.200001 59.117857 58.823257 2.390360 66.386746 57.0000 47.613254 60.069541
2010-02-24 60.900002 58.539286 59.100156 2.356046 66.504379 57.5425 48.580621 59.269579

æˆ‘å“ªé‡Œé”™äº†ï¼Ÿ
æ›´æ–°ï¼šå‡†ç¡®åº¦ä¼¼ä¹æ˜¯é”™è¯¯çš„æŒ‡æ ‡ï¼Œå› æ­¤æˆ‘å·²æŒ‰ç…§å›å¤çš„å»ºè®®æ”¹ç”¨ MSEï¼š
print(&#39;å‡æ–¹è¯¯å·®ï¼š&#39;, metrics.mean_squared_error(y_true=y_test, y_pred=lm_preds))
print(&#39;åˆ¤å®šç³»æ•°ï¼š%.2f&#39; % metrics.r2_score(y_true=y_test, y_pred=lm_preds))

æ ¹æ®è¿è¡Œæƒ…å†µï¼Œè¿™ç»™äº†æˆ‘å¤§çº¦ MSE = 13-15ï¼ŒR2 = 0.999ï¼Œè¿™ä»ç„¶éå¸¸é«˜ã€‚ç”±äºå¹³å‡è‚¡ä»·åœ¨ 600 å·¦å³ï¼ŒMSE å®é™…ä¸Šå¹¶æ²¡æœ‰çœ‹èµ·æ¥é‚£ä¹ˆé«˜ã€‚è¯¥æ¨¡å‹ä¼¼ä¹ä»ç„¶è¡¨ç°å¾—å¤ªå¥½äº†ã€‚
æˆ‘ä½¿ç”¨çš„æ˜¯ 2010-2020 å¹´çš„ Rightmove è‚¡ç¥¨æ•°æ®ã€‚æˆ‘åˆšåˆšåˆ‡æ¢åˆ°ä½¿ç”¨ 2010-2020 å¹´å’Œ 2019-2020 å¹´æ³¢åŠ¨æ€§æ›´å¤§çš„è‚¡ç¥¨ (PMO.L)ï¼Œå¹¶ä¸”æˆ‘è¿˜åˆ é™¤äº†æˆ‘ä½¿ç”¨çš„ 5/7 ä¸ªæŒ‡æ ‡ã€‚
å¯¹äº 2010-2020 å¹´ï¼Œè¯¥æ¨¡å‹ç»™å‡ºçš„ MSE ä¸º 69ï¼ˆä¸è‚¡ä»·ç›¸æ¯”ç›¸å¯¹è¾ƒä½ï¼‰å’Œ 0.999 R2ã€‚ç„¶è€Œï¼Œå¯¹äº 2019-2020 å¹´ï¼Œè¯¥æ¨¡å‹ç¡®å®ä¼¼ä¹æœ‰ç‚¹å·®ï¼ŒMSE ä¸º 15.5ï¼ŒR2 ä¸º 0.82ï¼Œæ˜æ˜¾ä½äºä»¥å‰ã€‚ç„¶è€Œï¼Œè€ƒè™‘åˆ°è¿™åªæ˜¯ä¸€å¹´çš„æ•°æ®ï¼Œå®ƒçš„è¡¨ç°ä¼¼ä¹ä»ç„¶å¤ªå¥½äº†ã€‚
ä»¥ä¸‹æ˜¯ç”¨äºè®­ç»ƒæ–°è‚¡ç¥¨æ¨¡å‹çš„ç‰¹å¾æ•°æ®æ ·æœ¬ï¼š
2010-2020ï¼š
 SMA EMA
æ—¥æœŸ
2010-02-18 266.214286 266.857731
2010-02-19 266.910714 268.110034
2010-02-22 267.303571 269.428696
2010-02-23 267.589286 269.838203
2010-02-24 264.660714 270.659776

2011-2020:
 SMA EMA
æ—¥æœŸ
2019-02-18 73.425000 73.791397
2019-02-19 73.632143 74.052544
2019-02-20 73.785715 74.325538
2019-02-21 73.953572 74.335466
2019-02-22 73.928572 74.330738
]]></description>
      <guid>https://stackoverflow.com/questions/66154986/why-am-i-getting-100-accuracy-when-using-a-linear-regression-model-to-predict-s</guid>
      <pubDate>Thu, 11 Feb 2021 12:40:43 GMT</pubDate>
    </item>
    </channel>
</rss>