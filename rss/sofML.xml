<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 01 Dec 2023 01:06:24 GMT</lastBuildDate>
    <item>
      <title>数据库部署新手</title>
      <link>https://stackoverflow.com/questions/77582450/new-to-database-deployment</link>
      <description><![CDATA[我是数据库世界的新手，我正在处理具有时间序列高分辨率数据集的测试数据，并且每个数据集都被计算/汇总为更简单的事务集（包括其元数据）。目前这些都存储在本地服务器中。我很少遇到连接表的需求，但我不断使用时间序列数据来创建其他指标来构建机器学习模型。
csv中的每个时间序列数据集最大可达2.6MB，而交易数据则为kB大小。我有超过 20,000 组这样的数据。

什么是具有最佳性能的良好数据库选项/架构？关系型还是非关系型？每个选项都有哪些优秀的供应商？
如何确定是否应该迁移到云服务器？有哪些推荐的供应商？

对此的任何指导将不胜感激！或者任何好的教程101都会很好！
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77582450/new-to-database-deployment</guid>
      <pubDate>Fri, 01 Dec 2023 00:47:12 GMT</pubDate>
    </item>
    <item>
      <title>如何在此示例代码中探索 AWS 分析/ML/AI 服务？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77582249/how-do-i-explore-aws-analytics-ml-ai-services-in-this-example-code</link>
      <description><![CDATA[我想开始使用 AWS 的一些机器学习模型。我看到他们最近发布了 Bedrock 服务，我想设置一个环境来执行此操作。我还需要与 S3、Langchain 和 Vector 数据库（例如 Pinecone）进行交互。这里有一些关于我可能会玩的想法： 示例
我的电脑上有 VS Code，并且我看过一份指南，详细介绍了设置此功能的一些步骤：指南
我从示例链接中看到的是，我猜测使用了 Jupyter notbeook。另外（请原谅我的天真），如果我将 S3 文件放入 Vector 数据库，这些服务肯定需要启动（或设置），并由我付费。之后，只需通过 AWS Bedrock（处理许多底层内容）查询数据库即可。
所以我想我的问题是最初将数据导入矢量数据库：
我需要 Jupyter 笔记本吗？
我需要 AWS Sagemaker 吗？我在设置 SageMaker 时看到，您可以指定 EC2 或某些计算能力。
我需要 VS Code + Python + 其他东西吗？
或者此处链接的指南是否足够？
本质上，要使用我链接的示例，我的设置应该是什么？]]></description>
      <guid>https://stackoverflow.com/questions/77582249/how-do-i-explore-aws-analytics-ml-ai-services-in-this-example-code</guid>
      <pubDate>Thu, 30 Nov 2023 23:35:25 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 蜂群图解读</title>
      <link>https://stackoverflow.com/questions/77581801/shap-beeswarm-plot-interpretation</link>
      <description><![CDATA[我创建了一个 SHAP 蜂群图，我发现当高特征值和低特征值以微笑随机方式聚集在一起时，很难解释变量的影响。以下是几个示例（绿色 = 高，蓝色 = 低）：
示例 1

示例 2

在示例 1 中，我至少可以说极高的特征值对模型输出有积极的影响。但是，我不明白如何处理高点和低点集群，特别是在示例 2 中。我唯一的想法是，具有相同 SHAP 值的相同数量的高点和低点特征值。
那么，对于此类簇是否有更有意义的解释？]]></description>
      <guid>https://stackoverflow.com/questions/77581801/shap-beeswarm-plot-interpretation</guid>
      <pubDate>Thu, 30 Nov 2023 21:22:32 GMT</pubDate>
    </item>
    <item>
      <title>获取 'model.fit' keras API 参数的值</title>
      <link>https://stackoverflow.com/questions/77581428/get-values-of-model-fit-keras-api-parameters</link>
      <description><![CDATA[我正在尝试使用自定义回调函数获取 Kera 顺序模型的详细信息。我需要提取 model.fit() API 中设置的参数的所有值，例如 batch_size、epochs、validation_split 等。但我无法在 Keras 的回调中访问它们。您知道如何自动获取这些值吗？
我正在使用 Python 3.10 和 Keras 2.8。]]></description>
      <guid>https://stackoverflow.com/questions/77581428/get-values-of-model-fit-keras-api-parameters</guid>
      <pubDate>Thu, 30 Nov 2023 20:13:45 GMT</pubDate>
    </item>
    <item>
      <title>我的项目应该使用 TensorFlow 还是 PyTorch？</title>
      <link>https://stackoverflow.com/questions/77581368/should-i-use-tensorflow-or-pytorch-for-my-project</link>
      <description><![CDATA[我正在开展一个导师与学员匹配项目，我的目标是使用深度学习技术和语言模型（例如 BERT 或 GPT）来分析导师和学员的文本资料，以找到合适的匹配。该项目涉及对文本配置文件进行编码、计算相似性分数、生成建议，以及可能微调预训练模型以获得更好的性能。
我正在决定使用 TensorFlow 还是 PyTorch 来实施这个项目。考虑到所涉及的任务，例如文本编码、相似性计算和潜在的微调模型，哪种框架更适合此类项目？在导师与受训者匹配任务的背景下，我应该考虑这两种框架的具体优点或局限性吗？]]></description>
      <guid>https://stackoverflow.com/questions/77581368/should-i-use-tensorflow-or-pytorch-for-my-project</guid>
      <pubDate>Thu, 30 Nov 2023 20:00:14 GMT</pubDate>
    </item>
    <item>
      <title>Orange3 中的关联规则过滤器效果不佳 [关闭]</title>
      <link>https://stackoverflow.com/questions/77580681/association-rules-filters-in-orange3-does-not-work-well</link>
      <description><![CDATA[我正在尝试在 Orange3 中使用关联规则，并且正在使用“按结果过滤工具”。我已经编写了一个条件，但是当我运行程序时，结果图表中给出了其他条件。我已经多次验证是否输入错误，但事实并非如此。
我尝试更改变量，但它没有准确给出所需的内容。
有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77580681/association-rules-filters-in-orange3-does-not-work-well</guid>
      <pubDate>Thu, 30 Nov 2023 17:53:34 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法省略 OpenAIgym 的输出并保留打印语句？</title>
      <link>https://stackoverflow.com/questions/77580652/is-there-a-way-to-omit-the-output-from-openai-gym-and-leave-the-print-statement</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77580652/is-there-a-way-to-omit-the-output-from-openai-gym-and-leave-the-print-statement</guid>
      <pubDate>Thu, 30 Nov 2023 17:45:58 GMT</pubDate>
    </item>
    <item>
      <title>多维输出/多智能体强化学习库</title>
      <link>https://stackoverflow.com/questions/77579893/library-for-multi-dimensional-output-multi-agent-reinforcement-learning</link>
      <description><![CDATA[只是想知道哪个库可以正确实现这一点？
从我迄今为止所看到和尝试过的情况来看，tf-agent 做不到。
有什么建议吗？或者有人知道如何在 tf-agent 上做到这一点（尽管不太可能）？
额外背景信息：
我能找到的最接近的是这个，但它的训练速度是与单个代理相比有点慢。
我知道它会比平时慢，因为它是多代理的，但我怀疑大部分开销来自使用 TFUniformReplayBuffer，而不是混响驱动程序。
我尝试使用混响进行多代理，但它不允许我在使用 PyEnvironment 时自定义运行方式（也称为无法正确自定义 PyDriver）。
并且此问题自 2020 年以来一直处于开放状态，所以我非常怀疑是否会出现是多智能体 RL 上 tf-agent 中可用的正确解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/77579893/library-for-multi-dimensional-output-multi-agent-reinforcement-learning</guid>
      <pubDate>Thu, 30 Nov 2023 16:03:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练YOLOv8会导致崩溃？</title>
      <link>https://stackoverflow.com/questions/77579052/why-does-training-yolov8-cause-a-crash</link>
      <description><![CDATA[我想在由单个类别的 1080p 图像组成的自定义数据集上训练对象检测。我认为我已经正确准备了数据集（将其上传到 roboflow 显示了正确概述类的图像），但是我似乎无法让模型开始训练。起初，我怀疑我使用的数据集可能太大，无法满足我普通笔记本电脑的处理能力（270 个 1080p 图像及其掩模，总计 1.34GB），因此我将其减少到只有 10 个训练图像和 10 个验证图像。还是没有运气。
我的代码：
从 ultralytics 导入 YOLO

# 加载 COCO 预训练的 YOLOv8n 模型
模型 = YOLO(&#39;yolov8n.pt&#39;)

结果 = model.train(data=&#39;(..)\\dataset\\data.yaml&#39;, epochs=5,
                      imgsz=[1920, 1080])

data.yaml 文件：
&lt;前&gt;&lt;代码&gt;名称：
- 烟草
数控：1
测试：数据集\测试
火车：火车\图像
val: 有效\图像

控制台输出：
图像大小 1920 train、1920 val
使用 0 个数据加载器工作人员
将结果记录到运行\检测\train7
开始训练 5 个 epoch...

      Epoch GPU_mem box_loss cls_loss dfl_loss 实例大小
  0%| | 0/1 [00:00
代码在 0% 处停留大约一分钟，我的计算机死机，然后打印处理完成错误。
假设问题确实源于我糟糕的规格，我可以对自定义数据集使用某种云训练吗？我在哪里可以阅读有关构建和上传用于云训练的自定义数据集的更多信息？]]></description>
      <guid>https://stackoverflow.com/questions/77579052/why-does-training-yolov8-cause-a-crash</guid>
      <pubDate>Thu, 30 Nov 2023 13:59:49 GMT</pubDate>
    </item>
    <item>
      <title>OpenAi 从我的应用程序检索数据</title>
      <link>https://stackoverflow.com/questions/77575498/openai-to-retrieve-data-from-my-application</link>
      <description><![CDATA[我管理一个包含数千个商机、客户、联系人等的 CRM 应用程序。我正在寻求实现类似聊天的功能，允许用户提出问题并从存储的记录中检索数据。例如，他们可以查询价值超过 10,000 美元的机会。
最初，我探索使用 NLP to SQL 方法。我向 OpenAI 提供了我的表结构和用户提示，执行生成的 SQL 查询产生了准确的结果。然而，正如在各种实例中所观察到的那样，仅仅依靠 OpenAI 生成 SQL 会带来安全风险。
我正在探索替代方法。一种想法是为特定任务创建专用 API，然后使用 OpenAI 对其进行训练。这看起来是一个可行的解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/77575498/openai-to-retrieve-data-from-my-application</guid>
      <pubDate>Thu, 30 Nov 2023 02:19:04 GMT</pubDate>
    </item>
    <item>
      <title>在自定义转换器中包含多个数据集转换器</title>
      <link>https://stackoverflow.com/questions/77570948/including-multiple-dataset-transformers-in-custom-transformer</link>
      <description><![CDATA[这是我的自定义转换器，旨在转换编码和缩放的主题数据帧：
类 DfGrooming(BaseEstimator, TransformerMixin):
    def __init__(自身):
        self.encodable_columns = [&#39;教育&#39;、&#39;就业类型&#39;、&#39;婚姻状态&#39;、&#39;HasMortgage&#39;、&#39;HasDependents&#39;、&#39;LoanPurpose&#39;、&#39;HasCoSigner&#39;]
        self.scalable_columns = [&#39;年龄&#39;, &#39;收入&#39;, &#39;贷款金额&#39;, &#39;信用分数&#39;, &#39;就业月数&#39;, &#39;利率&#39;, &#39;贷款期限&#39;]
        self.encoder = LabelEncoder()
        self.scaler = MinMaxScaler(feature_range=(0,5))
        self.X_encoded = pd.DataFrame()
        self.X_scaled = pd.DataFrame()
    
def fit(self, X, y=None):
    self.encoder.fit(X[self.encodable_columns])
    self.scaler.fit(X[self.scalable_columns])
    返回自我

def 变换（自身，X，y=无）：
    self.X_encoded = self.encoder.transform(X[self.encodable_columns])
    打印（self.X_encoded.shape）
    X.drop（列= self.encodable_columns，轴= 1，就地= True）
    X = pd.concat([X, self.X_encoded], axis=1)
    打印（X.形状）
    self.X_scaled = X.filter(self.scalable_columns, axis=1)
    self.X_scaled = pd.DataFrame(scaler.transform(self.X_scaled))
    self.X_scaled.columns = self.scalable_columns
    X[self.scalable_columns] = self.X_scaled[self.scalable_columns]
    X.drop([&#39;LoanID&#39;], axis=1, inplace=True)
    打印（X.形状）
    
    返回X

但是运行管道后：
pipeline = Pipeline([(&#39;preparer&#39;, DfGrooming())])
t = pipeline.fit_transform(train_df)
t.head()

我收到以下错误：
ValueError：输入形状错误 (178742, 7)

我想知道实际发生了什么，以及我在变压器的实现中是否遗漏了任何内容。另请建议更好的方法来实施此程序。谢谢
我尝试在一个自定义变压器中包含 2 个变压器。
我期望结合 2 个步骤（可能还有 4 个步骤 - 删除编码和缩放的列并将其添加到主数据帧中）
我有一个工作算法，可以使用函数半自动转换验证和测试集，但想尝试管道]]></description>
      <guid>https://stackoverflow.com/questions/77570948/including-multiple-dataset-transformers-in-custom-transformer</guid>
      <pubDate>Wed, 29 Nov 2023 11:56:48 GMT</pubDate>
    </item>
    <item>
      <title>我们可以在一个 Colab（或 Jupyter Notebook）中使用“train_test_split”两次吗？</title>
      <link>https://stackoverflow.com/questions/77555330/can-we-use-train-test-split-in-one-single-colabor-jupyter-notebook-twice</link>
      <description><![CDATA[我必须使用决策树机器学习算法执行分类和回归。现在我已经完成了代码的回归部分。如果我继续对此进行分类任务，我应该对预处理的数据集执行train_test_split。 在代码中我必须定义 X 和 y 变量，然后执行 X_train、X_test、y_train 和 y_test 部分。回归和分类中都会重复相同的变量。通过从分类中获取相同的变量，它会考虑回归中首先给出的先前值还是会采用新给定的值？
我想清楚地知道我们是否可以在单个 colab 或 jupyter 笔记本中多次使用 train_test_split 函数。]]></description>
      <guid>https://stackoverflow.com/questions/77555330/can-we-use-train-test-split-in-one-single-colabor-jupyter-notebook-twice</guid>
      <pubDate>Mon, 27 Nov 2023 08:05:19 GMT</pubDate>
    </item>
    <item>
      <title>基于预定义的特征子集创建分类器集合</title>
      <link>https://stackoverflow.com/questions/77524700/creating-an-ensemble-of-classifiers-based-on-predefined-feature-subsets</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77524700/creating-an-ensemble-of-classifiers-based-on-predefined-feature-subsets</guid>
      <pubDate>Tue, 21 Nov 2023 17:12:25 GMT</pubDate>
    </item>
    <item>
      <title>如何按照官方方式将 Hugging Face LLaMA v2 模型的权重重新初始化为原始模型？</title>
      <link>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</guid>
      <pubDate>Fri, 17 Nov 2023 03:15:56 GMT</pubDate>
    </item>
    <item>
      <title>Librosa.resample() 重新采样到低于所需的速率</title>
      <link>https://stackoverflow.com/questions/67870647/librosa-resample-resamples-to-a-lower-rate-than-needed</link>
      <description><![CDATA[我正在做一些音频预处理来训练机器学习模型。
该数据集的所有音频文件为：
&lt;块引用&gt;
RIFF（小端）数据、WAVE 音频、Microsoft PCM、16 位、单声道 16000 Hz。

我使用以下代码片段将数据集重新采样到 8000 Hz：
样本，sample_rate = librosa.load（文件名，sr = 16000）
样本= librosa.resample（样本，sample_rate，8000）

然后我使用以下代码片段来重塑新样本：
samples.reshape(1,8000,1)
但由于某种原因，我不断收到以下错误：ValueError：无法将大小为 4000 的数组重新整形为形状 (1,8000,1)，但文件与另一个文件的大小不同，但是它始终低于 8000 HZ（所需的采样率）。
我仔细检查了原始采样率，它是 16000 Hz，我也尝试加载采样率为 8000 的文件，但我没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/67870647/librosa-resample-resamples-to-a-lower-rate-than-needed</guid>
      <pubDate>Mon, 07 Jun 2021 11:18:19 GMT</pubDate>
    </item>
    </channel>
</rss>