<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 26 Dec 2023 09:13:29 GMT</lastBuildDate>
    <item>
      <title>为什么我的 val_loss 曲线看起来这么奇怪？</title>
      <link>https://stackoverflow.com/questions/77716410/why-does-my-val-loss-curve-look-so-strange</link>
      <description><![CDATA[类 myResidualBlock1DSample(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, use_1x1conv=False):
        超级（myResidualBlock1DSample，自我）.__init__（）
        self.conv1 = nn.Conv1d(in_channels, out_channels//2, kernel_size, stride, padding=1)
        self.bn1 = nn.BatchNorm1d(out_channels//2)
        self.relu = nn.ReLU()
        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv1d(out_channels//2, out_channels, kernel_size, stride, padding=1)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)
        如果使用_1x1conv：
            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)
            self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)
        别的：
            self.conv3 = 无
            self.pool3 = 无

    def 前向（自身，x）：
        输出 = self.conv1(x)
        输出 = self.bn1(输出)
        输出 = self.relu(输出)
        输出 = self.pool1(输出)
        输出 = self.conv2(输出)
        输出 = self.bn2(输出)
        输出 = self.pool2(输出)
        如果 self.conv3：
            x = self.conv3(x)
            x = self.pool3(x)
        输出 += x
        输出 = self.relu(输出)
        返回


类 myResidualBlock1DUpsample(nn.Module)：
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, use_1x1conv=False):
        超级（myResidualBlock1DUpsample，自我）.__init__（）
        self.conv1 = nn.Conv1d(in_channels, in_channels//2, kernel_size, stride, padding=1)
        self.bn1 = nn.BatchNorm1d(in_channels//2)
        self.relu = nn.ReLU()
        self.upsample1 = nn.Upsample(scale_factor=2, mode=&#39;线性&#39;)
        self.conv2 = nn.Conv1d(in_channels//2, out_channels, kernel_size, stride, padding=1)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.upsample2 = nn.Upsample(scale_factor=2, mode=&#39;线性&#39;)
        如果使用_1x1conv：
            self.conv3 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1)
            self.upsample3 = nn.Upsample(scale_factor=4, mode=&#39;线性&#39;)
        别的：
            self.conv3 = 无
            self.upsample3 = 无

    def 前向（自身，x）：
        输出 = self.conv1(x)
        输出 = self.bn1(输出)
        输出 = self.relu(输出)
        输出 = self.upsample1(输出)
        输出 = self.conv2(输出)
        输出 = self.bn2(输出)
        输出 = self.upsample2(输出)
        如果 self.conv3：
            x = self.conv3(x)
            x = self.upsample3(x)
        输出 += x
        输出 = self.relu(输出)
        返回


类 ResidualAutoencoder1Dv2(nn.Module):
    def __init__(自身):
        超级().__init__()
        #编码器
        self.res1 = myResidualBlock1DSample(1, 32, use_1x1conv=True)
        self.res2 = myResidualBlock1DSample(32, 128, use_1x1conv=True)
        self.res5 = myResidualBlock1DSample(128,512,use_1x1conv=True)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(5120, 4096)
        self.fc2 = nn.Linear(4096, 2048)
        self.fc3 = nn.Linear(2048, 1024)
        self.dropout = nn.Dropout(p=0.2)
        self.fc4 = nn.Linear(1024, 4)
        self.relu = nn.ReLU()
        #解码器
        self.fc5 = nn.Linear(4, 47)
        self.conv1 = nn.Conv1d(1, 128, kernel_size=3, stride=1)#序列长度变成45
        self.res3 = myResidualBlock1DUpsample(128, 32, use_1x1conv=True)
        self.res4 = myResidualBlock1DUpsample(32, 1, use_1x1conv=True)
        self.fc6 = nn.Linear(720,700)

    def 前向（自身，x）：
        #编码器
        x = self.res1(x)
        x = self.res2(x)
        x = self.res5(x)
        x = self.展平(x)
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        x = self.relu(x)
        x = self.dropout(x)
        编码输出 = self.fc4(x)
        #解码器
        x = self.fc5(编码输出)
        x = x.unsqueeze(1)
        x = self.conv1(x)
        x = self.res3(x)
        x = self.res4(x)
        解码输出 = self.fc6(x)
        返回编码输出、解码输出


为什么我的损失曲线晃动这么大？事实上，曲线仍然可以下降到低点。我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77716410/why-does-my-val-loss-curve-look-so-strange</guid>
      <pubDate>Tue, 26 Dec 2023 08:53:40 GMT</pubDate>
    </item>
    <item>
      <title>RocCurveDisplay.from_estimator 无法显示 Roc 曲线图</title>
      <link>https://stackoverflow.com/questions/77716366/roccurvedisplay-from-estimator-is-not-able-to-display-roc-curve-graph</link>
      <description><![CDATA[RocCurveDisplay.from_estimator 无法显示图表。
随机森林：无结果中显示“无”而不是图表
我不明白这是什么问题？
我曾尝试尽一切可能，不幸的是我未能查明显示图表的正确代码。任何帮助都将不胜感激。下面是我的代码
导入 pandas 作为 pd
从 sklearn.naive_bayes 导入 GaussianNB
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入 precision_score, precision_score

df = pd.read_csv(“xyz.csv”)

X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.3, random_state=56)

分类器 = [
    [&#39;朴素贝叶斯：&#39;, GaussianNB()],
    [&#39;决策树：&#39;, DecisionTreeClassifier(random_state=56)],
    [&#39;随机森林：&#39;, RandomForestClassifier(random_state=56)],
]

Predictions_df=pd.DataFrame()
Predictions_df[&#39;action&#39;] = Y_test

# 使用的各个分类器的准确性
对于名称，分类器中的分类器：
    分类器 = 分类器
    classifier.fit (X_train,Y_train.ravel())
    预测 = classifier.predict(X_test)
    Predictions_df[name.strip(&quot;:&quot;)] = 预测
    打印(“\n”)
    打印（名称，“准确度：”，accuracy_score（Y_test，预测））
    print(名称,“精度:”, precision_score(Y_test,预测))
    RocCurveDisplay.from_estimator(分类器, X_test, Y_test)
    print(name, plt.show()) # 为什么我无法显示 ROC 曲线？
    打印(“\n”)
]]></description>
      <guid>https://stackoverflow.com/questions/77716366/roccurvedisplay-from-estimator-is-not-able-to-display-roc-curve-graph</guid>
      <pubDate>Tue, 26 Dec 2023 08:39:35 GMT</pubDate>
    </item>
    <item>
      <title>Keras / Tensorflow：类型错误：无法序列化类型为 <class 'ellipsis'> 的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/keras-tensorflow-typeerror-cannot-serialize-object-ellipsis-of-type-class</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息（我使用的是 Tensorflow 版本 2.15.0）
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层（代码如下）。
问题：
model.fit(...) 会导致以下错误：
类型错误：无法序列化  类型的对象省略号。要可序列化，类必须实现 get_config() 方法。
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

历史=模型.fit(
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/keras-tensorflow-typeerror-cannot-serialize-object-ellipsis-of-type-class</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>在本地计算机中设置 UDpipe 服务器</title>
      <link>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</guid>
      <pubDate>Tue, 26 Dec 2023 06:18:57 GMT</pubDate>
    </item>
    <item>
      <title>缺失数据的随机森林建模：寻求不需要插补或数据删除的包或方法</title>
      <link>https://stackoverflow.com/questions/77715672/random-forest-modeling-with-missing-data-seeking-packages-or-approaches-that-do</link>
      <description><![CDATA[我有一个包含多个变量的数据集，其中包含缺失值，并且我不希望估算或丢弃它们。我有兴趣在处理缺失的观察结果时将随机森林模型拟合到这些数据。谁能推荐专门设计的软件包或方法，用于将随机森林拟合到缺失值的数据，而不需要插补或删除不完整的记录？”]]></description>
      <guid>https://stackoverflow.com/questions/77715672/random-forest-modeling-with-missing-data-seeking-packages-or-approaches-that-do</guid>
      <pubDate>Tue, 26 Dec 2023 04:28:14 GMT</pubDate>
    </item>
    <item>
      <title>MediaPipe 静态存储视频人脸标志检测</title>
      <link>https://stackoverflow.com/questions/77715244/mediapipe-static-stored-video-face-landmark-detection</link>
      <description><![CDATA[该帖子已被隐藏。你刚刚删除了这篇文章。
关闭。这个问题需要更加有针对性。目前不接受答案。
更新问题，使其仅关注一个问题。这将有助于其他人回答问题。您可以编辑问题或发布新问题。
22 小时前关闭。
此帖子已于 19 小时前编辑并提交审核。
我一直在尝试让媒体管道来检测静态（存储）视频中的面部标志，但所有在线指南和教程都使用实时摄像头源。在 Python 中很容易，但我必须在 JavaScript 中完成。
我发现这两个指南最相关，但都使用实时摄像头。
 https://medium.com/@mamikonyanmichael/what-is-media-pipe-and-how-to-use-it-in-react-53ff418e5a68
https://github.com/jays0606/mediapipe-facelandmark-demo 
如何在静态（本地存储）视频而不是 JavaScript 中的实时摄像头源上运行 Mediapipe 的人脸检测？]]></description>
      <guid>https://stackoverflow.com/questions/77715244/mediapipe-static-stored-video-face-landmark-detection</guid>
      <pubDate>Tue, 26 Dec 2023 00:07:55 GMT</pubDate>
    </item>
    <item>
      <title>如何从图像中测量物体的长度</title>
      <link>https://stackoverflow.com/questions/77714997/how-to-measure-length-of-object-from-image</link>
      <description><![CDATA[我目前正在开展最后一年的项目，重点是使用来自不同平面的超声图像进行胎儿健康分析。完成模型训练阶段后，我在使用新图像测试模型时遇到了挑战。问题在于准确计算股骨长度或头围等测量值，因为我缺乏有关图像像素分辨率的信息。数据的缺失导致测量结果与预期的正常范围不符。我非常感谢有关解决此像素分辨率挑战的指导，以确保更可靠和更精确的测量。
我尝试了所有公式，但最终我需要每个图像的像素值
整个公式将乘以每个图像特定像素分辨率值]]></description>
      <guid>https://stackoverflow.com/questions/77714997/how-to-measure-length-of-object-from-image</guid>
      <pubDate>Mon, 25 Dec 2023 21:17:00 GMT</pubDate>
    </item>
    <item>
      <title>根据游戏数据计算偏差和偏差锐度</title>
      <link>https://stackoverflow.com/questions/77714958/calculating-deviation-and-sharpness-of-deviation-from-game-data</link>
      <description><![CDATA[我发现这个网站可以计算足球比赛的赔率/上盘/下盘。
我想知道如何实现类似的功能。
我可以通过抓取bet365来获取赛季数据，这非常简单。
但是，我对如何计算“偏差”感到困惑。和“偏差锐度” （表中的列名称）基于任何给定比赛中的实时事件。]]></description>
      <guid>https://stackoverflow.com/questions/77714958/calculating-deviation-and-sharpness-of-deviation-from-game-data</guid>
      <pubDate>Mon, 25 Dec 2023 20:58:12 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 raytune 同时优化多个目标（最小化 MSE 和最大化 R^2）？</title>
      <link>https://stackoverflow.com/questions/77714892/how-do-i-optimize-multiple-objectives-minimizing-mse-and-maximizing-r2-simult</link>
      <description><![CDATA[我正在尝试将 MSE_test 优化为最小值，将 R^2 优化为最高，但在尝试弄清楚如何同时执行这两个操作时遇到困难。
我现在拥有的这段代码仅优化 MSE_test
def main():
    # 定义超参数搜索空间
    配置={
        “lr”：tune.loguniform(0.0001, 0.1),
        “时代”：tune.randint(70, 100)
    }

    分析=调.运行（
        调整.with_parameters（train_model，X_train = X_train_normalized，Y_train = Y_train，X_test = X_test_normalized，Y_test = Y_test），
        配置=配置，
        num_samples=15, # 根据您的资源调整此值
        metric=“mse_test”, # 针对测试集上较低的 MSE 进行优化
        模式＝“分钟”，
        Progress_reporter=CLIReporter(metric_columns=[“mse_train”、“r2_train”、“mse_test”、“r2_test”])
    ）

    best_config = Analysis.get_best_config(metric=“mse_test”, mode=“min”)
    print(&quot;最佳超参数：&quot;, best_config)

如果 __name__ == “__main__”：
    主要的（）


我这样做了，但它单独完成了这项工作，并给了我两个我正在尝试优化的不同值。
# 针对 mse_test 进行优化
mse_analysis=tune.run（
    调整.with_parameters（train_model，X_train = X_train_normalized，Y_train = Y_train，X_test = X_test_normalized，Y_test = Y_test），
    配置=配置，
    样本数=10，
    指标=“mse_test”，
    模式＝“分钟”，
    Progress_reporter=CLIReporter(metric_columns=[“mse_train”、“r2_train”、“mse_test”、“r2_test”])
）

# 针对 r2_test 进行优化
r2_analysis=tune.run(
    调整.with_parameters（train_model，X_train = X_train_normalized，Y_train = Y_train，X_test = X_test_normalized，Y_test = Y_test），
    配置=配置，
    样本数=10，
    度量=“r2_test”，
    模式=“最大”，
    Progress_reporter=CLIReporter(metric_columns=[“mse_train”、“r2_train”、“mse_test”、“r2_test”])
）

# 检索最佳配置
best_config_mse = mse_analysis.get_best_config(metric=“mse_test”, mode=“min”)
best_config_r2 = r2_analysis.get_best_config(metric=“r2_test”, mode=“max”)

print(“mse_test 的最佳超参数：”, best_config_mse)
print(“r2_test 的最佳超参数：”, best_config_r2)

]]></description>
      <guid>https://stackoverflow.com/questions/77714892/how-do-i-optimize-multiple-objectives-minimizing-mse-and-maximizing-r2-simult</guid>
      <pubDate>Mon, 25 Dec 2023 20:21:58 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的 python Rest api aiohttp 加载时间错误</title>
      <link>https://stackoverflow.com/questions/77714772/python-rest-api-for-machine-learning-aiohttp-bad-load-times</link>
      <description><![CDATA[我在 python 中使用 aiohttp。我有一个机器学习项目，我想通过restapi 提供该项目。我对这些函数进行了计时，它们执行起来并不需要很长时间。他们不会等待结果，而是检查进度并开始任务。问题是等待时间相当长。我试图找到问题所在，它不是函数本身，而是 aiohttp 来运行函数或发送结果。函数本身不是问题。（等待时间10s，函数执行2e-05）。我只是创建一个包含该项目的类。有人对如何确保快速响应时间有建议吗？有没有办法为 api 预分配资源或在单独的线程中生成机器学习项目。]]></description>
      <guid>https://stackoverflow.com/questions/77714772/python-rest-api-for-machine-learning-aiohttp-bad-load-times</guid>
      <pubDate>Mon, 25 Dec 2023 19:30:24 GMT</pubDate>
    </item>
    <item>
      <title>Tesseract 在简单的手写测试中找不到文本。有没有什么办法解决这一问题？</title>
      <link>https://stackoverflow.com/questions/77714612/tesseract-is-not-finding-text-in-simple-handwriting-test-is-there-any-way-to-fi</link>
      <description><![CDATA[我正在尝试为纸质测试的自动评分提供更好的解决方案。
问题是从测试中提取矩形区域并对手写输入进行 OCR。
虽然手写显然具有挑战性，但这个问题比一般阅读手写要简单得多：

文本方向已知
我可以准确指定我期望的答案和/或合法的字符集。
我愿意从引擎获得概率，如果概率太低，请叫人来裁决（最好不要）。

Tesseract 声称可以手写，可以使用 mingw 在 Linux 和 Windows 上运行，所以看起来不错。
我从表单中提取了手写数据样本。这是示例：

在这种情况下，矩形的边界没有被裁剪掉，但我期望它能够找到我的 64。它失败了。
当我裁剪边界框时，它起作用了。
虽然在这种情况下，我可以解决问题，但我想知道是否可以采取任何措施来提高识别率，因为边界框似乎无害，而且我担心任何微不足道的噪音都会破坏检测。

我可以使用更好的开源包吗？

有没有办法改进我的应用程序的培训？
我想我可以创造一种“语言”对于单个字母，对于整数使用不同的语言，并加载多个超正方引擎，每个引擎专门针对一种问题类型。

内部 API 是否有办法为其提供潜在字符串/字符集的列表，即暗示提高准确性？

]]></description>
      <guid>https://stackoverflow.com/questions/77714612/tesseract-is-not-finding-text-in-simple-handwriting-test-is-there-any-way-to-fi</guid>
      <pubDate>Mon, 25 Dec 2023 18:24:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么支持向量机的 varImp() 出现错误？</title>
      <link>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</guid>
      <pubDate>Mon, 25 Dec 2023 17:08:22 GMT</pubDate>
    </item>
    <item>
      <title>无法在 F# 中将内存数据传递到 AutoML。不明白为什么它不能编译</title>
      <link>https://stackoverflow.com/questions/77714343/cant-pass-in-memory-data-to-automl-in-f-not-understanding-why-it-doesnt-com</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77714343/cant-pass-in-memory-data-to-automl-in-f-not-understanding-why-it-doesnt-com</guid>
      <pubDate>Mon, 25 Dec 2023 16:43:24 GMT</pubDate>
    </item>
    <item>
      <title>卷积神经网络不学习</title>
      <link>https://stackoverflow.com/questions/77704108/convolutional-neural-network-not-learning</link>
      <description><![CDATA[我正在尝试在包含 1500 张图像（15 个类别）的训练集上训练用于图像识别的卷积神经网络。有人告诉我，采用这种架构和从均值为 0、标准差为 0.01 的高斯分布得出的初始权重以及初始偏差值为 0 的情况，在适当的学习率下，它应该达到 30 左右的准确度%。
但是，它根本没有学到任何东西：准确率与随机分类器相似，并且训练后的权重仍然遵循正态分布。我做错了什么？
这是神经网络
class simpleCNN(nn.Module)：
  def __init__(自身):
    super(simpleCNN,self).__init__() #初始化模型

    self.conv1=nn.Conv2d(in_channels=1,out_channels=8,kernel_size=3,stride=1) #输出图像大小为(size+2*padding-kernel)/stride --&gt;62*62
    self.relu1=nn.ReLU()
    self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2) #输出图像62/2--&gt;31*31

    self.conv2=nn.Conv2d(in_channels=8,out_channels=16,kernel_size=3,stride=1) #输出图像为29*29
    self.relu2=nn.ReLU()
    self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2) #输出图像为29/2--&gt;14*14（MaxPool2d近似大小与floor）

    self.conv3=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1) #输出图像为12*12
    self.relu3=nn.ReLU()

    self.fc1=nn.Linear(32*12*12,15) #16 个通道 * 16*16 图像（64*64，步幅为 2 的 2 个 maxpooling），15 个输出特征=15 个类
    self.softmax = nn.Softmax(dim=1)

  def 前向（自身，x）：
    x=self.conv1(x)
    x=self.relu1(x)
    x=self.maxpool1(x)

    x=self.conv2(x)
    x=self.relu2(x)
    x=self.maxpool2(x)

    x=self.conv3(x)
    x=self.relu3(x)

    x=x.view(-1,32*12*12)

    x=self.fc1(x)
    x=self.softmax(x)

    返回x

初始化：
def init_weights(m):
  如果 isinstance(m,nn.Conv2d) 或 isinstance(m,nn.Linear)：
    nn.init.normal_(m.weight,0,0.01)
    nn.init.zeros_(m.bias)

模型 = simpleCNN()
模型.应用（init_weights）

训练函数：
loss_function=nn.CrossEntropyLoss()
优化器=optim.SGD(model.parameters(),lr=0.1,动量=0.9)

def train_one_epoch(epoch_index,loader):
  运行损失=0

  对于 i，枚举（加载器）中的数据：

    input,labels=data #获取小批量
    输出=模型（输入）#前向传递

    loss=loss_function(outputs,labels) #计算损失
    running_loss+=loss.item() #总结到目前为止处理的小批量的损失

    Optimizer.zero_grad() #重置梯度
    loss.backward() #计算梯度
    optimizer.step() #更新权重

  return running_loss/(i+1) # 每个小批量的平均损失


培训：
&lt;前&gt;&lt;代码&gt;纪元=20

best_validation_loss=np.inf

对于范围内的纪元（EPOCHS）：
  print(&#39;纪元{}:&#39;.format(纪元+1))

  模型.train(True)
  train_loss=train_one_epoch(epoch,train_loader)

  运行验证损失=0.0

  模型.eval()

  with torch.no_grad(): # 禁用梯度计算并减少内存消耗
    对于 i，枚举中的 vdata（validation_loader）：
      vinputs,vlabels=vdata
      v输出=模型（v输入）
      vloss=loss_function(v输出,v标签)
      running_validation_loss+=vloss.item()
  验证损失=运行验证损失/(i+1)
  print(&#39;LOSS 训练：{} 验证：{}&#39;.format(train_loss,validation_loss))

  if validation_loss
使用默认初始化，它的效果会好一点，但我应该使用高斯达到 30%。
您能发现一些可能导致它无法学习的问题吗？我已经尝试过不同的学习率和动力。]]></description>
      <guid>https://stackoverflow.com/questions/77704108/convolutional-neural-network-not-learning</guid>
      <pubDate>Fri, 22 Dec 2023 14:06:23 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能 (AI) 预测股票价格</title>
      <link>https://stackoverflow.com/questions/2686981/using-artificial-intelligence-ai-to-predict-stock-prices</link>
      <description><![CDATA[给定一组与  非常相似的数据Motley Fool CAPS 系统，个人用户可以在其中输入各种股票的买入和卖出建议。我想做的是显示每个建议，并且我猜想它是否是未来股票价格（或每股收益或其他）的良好预测器&lt;5&gt;（即相关系数= 1）的评级（1-5）或一个可怕的预测变量（即相关系数 = -1）或介于两者之间。
每个推荐都标记给特定用户，以便可以随着时间的推移进行跟踪。我还可以根据 SP500 价格等来跟踪市场方向（看涨/看跌）。我认为在模型中有意义的组件是：

&lt;前&gt;&lt;代码&gt;用户
方向（长/空）
市场方向
股票部门

我们的想法是，有些用户在牛市中比熊市中表现更好（反之亦然），而有些用户在空头方面比多头方面更好，然后是上述的组合。我可以自动标记市场方向和板块（基于当时的市场和推荐的股票）。
我的想法是，我可以呈现一系列屏幕，并允许我通过显示特定时间段内的可用数据绝对值、市场和部门表现来对每个单独的推荐进行排名。我会按照详细的列表对股票进行排名，以便排名尽可能客观。我的假设是单个用户正确的概率不超过 57% - 但谁知道呢。
我可以加载系统并说“让我们将推荐排名为 90 天后股票价值的预测指标”；这将代表一组非常明确的排名。
现在，关键是 - 我想创建某种机器学习算法，可以识别一系列时间的模式，以便当建议流入应用程序时，我们维护该股票的排名（即类似于相关系数） ）关于该推荐（除了过去的一系列推荐之外）影响价格的可能性。
现在这是超级关键。我从未上过人工智能课程/读过人工智能书籍/更不用说特定于机器学习的内容。因此，我正在寻找指导 - 我可以适应的类似系统的示例或描述。寻找信息或任何一般帮助的地方。或者甚至推动我朝着正确的方向开始......
我的希望是用 F# 来实现这一点，并能够通过 F# 中的新技能、机器学习的实现以及我可以包含在技术组合或博客空间中的潜在内容（应用程序/源代码）给我的朋友留下深刻的印象； 
感谢您提前提供任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/2686981/using-artificial-intelligence-ai-to-predict-stock-prices</guid>
      <pubDate>Wed, 21 Apr 2010 22:24:38 GMT</pubDate>
    </item>
    </channel>
</rss>