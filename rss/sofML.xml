<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 21 Sep 2024 01:12:08 GMT</lastBuildDate>
    <item>
      <title>与其他架构相比，LSTM 为 Apple 的语言识别提供了哪些优势？</title>
      <link>https://stackoverflow.com/questions/79008154/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</link>
      <description><![CDATA[既然 LSTM 的强大功能来自其长程依赖性记忆，那么为什么我们要使用 LSTM 而不是其他架构来从短文本字符串中进行基于字符的语言识别 (LID)？
例如，Apple 发布了一篇行业博客文章，指出他们使用 biLSTM 进行语言识别：https://machinelearning.apple.com/research/language-identification-from-very-short-strings
然后这篇论文试图复制它：https://aclanthology.org/2021.eacl-srw.6/
我在阅读 Karpathy 关于 RNN 的著名文章时，尝试训练一个小型语言识别模型进行练习。我首先尝试了一种简单、直观（对我来说）的方法：使用 tf-idf，使用在训练数据中的双或三元计数上训练的朴素贝叶斯分类器。我的数据集包含不同语系的 13 种语言。虽然我的简单分类器确实表现良好，但在查看类似语言时会出错。例如，西班牙语通常被归类为葡萄牙语。
我研究了神经网络架构，发现 LSTM 经常用于语言识别任务。在阅读了有关 RNN 和 LSTM 的内容后，我无法完全理解为什么 LSTM 更适合用于 LID，尤其是短文本字符串。这不是违反直觉的吗，因为 LSTM 擅长记住长距离依赖关系，而 RNN 则不然？对于短文本字符串，我建议使用 vanilla RNN....
Apple 博客确实说过，

在本文中，我们探讨了如何通过将其视为字符级别的序列标记问题，并使用在短字符序列上训练的双向长短期记忆 (bi-LSTM) 神经网络来提高 LID 准确性。

我觉得我没有理解这里的一些基本知识。
那么，他们的 LSTM 的学习目标是否是正确分类给定的字符 n-gram？这就是他们所说的“序列标记”问题吗？序列标记任务的根本难道不就是分类任务吗（“用 N 个预定义标签中的 1 个标记来自测试集的给定输入”）？
当您使用已知可以处理长序列的架构时，在短字符序列上训练 LSTM 有什么意义？]]></description>
      <guid>https://stackoverflow.com/questions/79008154/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</guid>
      <pubDate>Fri, 20 Sep 2024 20:18:48 GMT</pubDate>
    </item>
    <item>
      <title>复杂、混乱、非线性序列中的下一个数字 [关闭]</title>
      <link>https://stackoverflow.com/questions/79006702/next-number-in-a-complex-chaotic-and-non-linear-sequence</link>
      <description><![CDATA[查看图片
我试图预测一个复杂、混乱且非线性序列中的下一个数字。即使我无法准确预测下一个数字，我也想发现影响序列中值的模式。我认为可能发生的情况如下：
多种因素在起作用：序列中的每个数字可能受到多种不同属性或因素的影响，并且这些因素可以以复杂的方式相互作用。
可能存在噪音：序列可能包含噪音或异常，这意味着可能存在混淆事物的假阳性或假阴性。
属性之间的相互作用：某些属性可能不会产生孤立的影响，而是可以与其他属性（来自序列中的不同位置）相互作用以影响数字的值。
模式发现和预测：最终，我的目标是识别任何潜在模式（如果存在）。即使它是一个混乱的系统，我也希望预测序列中下一个数字的成功率至少达到 60%。
训练数据的困难：鉴于系统非常混乱，我不确定是否可以通过传统方式在一组测试数据上训练系统。
我需要帮助：

使用神经网络是解决此问题的最佳方法吗？
是否有任何现有程序或产品可用于解决此问题？

到目前为止我还没有尝试过任何方法]]></description>
      <guid>https://stackoverflow.com/questions/79006702/next-number-in-a-complex-chaotic-and-non-linear-sequence</guid>
      <pubDate>Fri, 20 Sep 2024 12:16:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 Imagecaption 模型虽然没有过度拟合且损失很低，但性能却很差？[关闭]</title>
      <link>https://stackoverflow.com/questions/79006661/why-does-my-imagecaption-model-perform-poorly-even-though-it-is-not-overfitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79006661/why-does-my-imagecaption-model-perform-poorly-even-though-it-is-not-overfitting</guid>
      <pubDate>Fri, 20 Sep 2024 12:03:50 GMT</pubDate>
    </item>
    <item>
      <title>从 Colab 获取不相关的响应</title>
      <link>https://stackoverflow.com/questions/79006597/getting-irrelevant-responses-from-the-colab</link>
      <description><![CDATA[我正在使用“Bringing-Old-Photos-Back-to-Life”存储库 colab。
但它运行整个存储库，并且没有在划痕图像上显示实际生成的图像。
GitHub Repo
示例图像附在下面：
左图为原始图像，右图由模型生成
我期待有人指导如何改进它。]]></description>
      <guid>https://stackoverflow.com/questions/79006597/getting-irrelevant-responses-from-the-colab</guid>
      <pubDate>Fri, 20 Sep 2024 11:44:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 tch-rs 在 rust 中实现残差神经网络</title>
      <link>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</link>
      <description><![CDATA[我正在尝试使用 tch-rs (Torch) 在 rust 中实现前馈残差神经网络。
到目前为止，这是我的代码：（这是一个最小的可重现示例）
use tch::{nn::{self, batch_norm1d, layer_norm, BatchNormConfig, ConvConfigND, LayerNormConfig, Module, ModuleT}, Tensor};
const NUM_HIDDEN: i64 = 10;

fn res_block(vs: &amp;nn::Path) -&gt; impl ModuleT {
let mut default = ConvConfigND::default();
default.padding = 1;
let conv1 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn1 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
让 conv2 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn2 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
nn::func_t(|x,train| {
let mut residual = Tensor::new();
x.clone(&amp;residual);
let x = bn1.forward_t(&amp;conv1.forward(x),train).relu();
let x = bn2.forward_t(&amp;conv2.forward(&amp;x),train);
let x = x + residual;
return x.relu();
})
}

当我编译此代码时，出现此错误：
`*mut torch_sys::C_tensor` 无法在线程之间安全地共享
在 `BatchNorm` 中，`*mut torch_sys::C_tensor` 未实现特征 `Sync`，而这是 `{closure@src\nn.rs:11:16: 所要求的11:25}：`&amp;BatchNorm` 实现 `Send` 所需的 Send

当我将 forward_t 行放入 func_t 中时，会发生此问题。
我该如何让它工作？
我也尝试使用顺序网络，但它们无法进一步传递残差变量。有没有办法让它工作？还是我需要做其他事情？]]></description>
      <guid>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</guid>
      <pubDate>Fri, 20 Sep 2024 09:07:36 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 lbl2vec 中的 SSL 认证错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/79005521/how-to-solve-ssl-certificaiton-error-in-lbl2vec</link>
      <description><![CDATA[我正在使用 lbl2vec 标记一些非结构化文本数据。但我开始收到 SSL 证书错误。如何解决此问题？
错误详细信息：
SSLError: (MaxRetryError(&quot;HTTPSConnectionPool(host=&#39;huggingface.co&#39;, 
port=443): url 的最大重试次数已超出：/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json 
(由 SSLError(SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] 
证书验证失败：无法获取本地颁发者证书 (_ssl.c:1000)&#39;)))&quot;), &#39;(请求 ID：xxxxxxxxxxxxxxxxxxxxxxxx)&#39;)

引发错误的代码：
from lbl2vec import Lbl2Vec

#使用参数初始化模型
Lbl2Vec_model = Lbl2Vec(keywords_list=list(labels.keywords), tagged_documents=newsgroup_full_corpus[&#39;tagged_docs&#39;][newsgroup_full_corpus[&#39;data_set_type&#39;] == &#39;train&#39;], label_names=list(labels.class_name), similarity_threshold=0.43, min_num_docs=100, epochs=10)

# 训练模型
Lbl2Vec_model.fit()
]]></description>
      <guid>https://stackoverflow.com/questions/79005521/how-to-solve-ssl-certificaiton-error-in-lbl2vec</guid>
      <pubDate>Fri, 20 Sep 2024 06:36:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 selenium 和 beautifulsoup 在 RAG 模型中进行 Web 抓取 [关闭]</title>
      <link>https://stackoverflow.com/questions/79005517/web-scraping-using-selenium-and-beautifulsoup-for-using-in-a-rag-model</link>
      <description><![CDATA[我想为一个项目做网页抓取。
该项目已经实施了一个 rag，我想向模型添加更多信息，因此决定从 youtube 中提取成绩单并使用它来获得更概括的方法。
从 youtube 链接获取和生成成功。但是，当我尝试将网站考虑在内时，我遇到了困难。
因此，我所做的就是我已经使用 html praser 和正则表达式来消除数据噪音，仍然提取网站的评论部分和一些与数据连接相关的内容。
我尝试过的技术是“selenium”、“beautifulsoul”
我做了 html praser 并使用正则表达式来消除数据中的噪音，但它仍然存在。]]></description>
      <guid>https://stackoverflow.com/questions/79005517/web-scraping-using-selenium-and-beautifulsoup-for-using-in-a-rag-model</guid>
      <pubDate>Fri, 20 Sep 2024 06:34:55 GMT</pubDate>
    </item>
    <item>
      <title>在将作业提交给 QPU 之前，如何预先检查代码中的错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/79005253/how-to-check-for-errors-beforehand-in-the-code-before-submitting-the-job-to-qpu</link>
      <description><![CDATA[在 QSVM 中，有没有办法在将量子代码提交给 QPU 进行处理之前检查错误？因为即使代码有错误，QPU 也会运行，这意味着我们将白白浪费大量时间。那么，有没有什么方法可以解决这个问题呢？]]></description>
      <guid>https://stackoverflow.com/questions/79005253/how-to-check-for-errors-beforehand-in-the-code-before-submitting-the-job-to-qpu</guid>
      <pubDate>Fri, 20 Sep 2024 04:51:21 GMT</pubDate>
    </item>
    <item>
      <title>完成 model.register 后，如何在新的 SageMaker Studio UI 中访问评估指标？</title>
      <link>https://stackoverflow.com/questions/79005084/how-to-access-evaluation-metrics-in-new-sagemaker-studio-ui-after-doing-model-re</link>
      <description><![CDATA[我正在为机器学习模型构建 MLOP 管道。注册模型后，如何在 SageMake Studio UI 中访问模型的评估指标？
这是我在 S3 中保存的示例 evaluation.json
{
&quot;metric_groups&quot;: [
{
&quot;name&quot;: &quot;regression_metrics&quot;,
&quot;metric_data&quot;: [
{
&quot;name&quot;: &quot;mse&quot;,
&quot;value&quot;: 6107087691.96
},
{
&quot;name&quot;: &quot;mae&quot;,
&quot;value&quot;: 46717.104
},
{
&quot;name&quot;: &quot;rmse&quot;,
&quot;value&quot;: 78147.85
},
{
&quot;name&quot;: &quot;r2&quot;,
&quot;value&quot;: 0.90
]
}
]
}

这是我的注册步骤：
import logs
from sagemaker.workflow.functions import Join
from sagemaker.model_metrics import MetricsSource, ModelMetrics
from sagemaker.workflow.step_collections import RegisterModel

def create_register_step(
role,
sagemaker_session,
model_package_group_name,
model_approval_status,
training_step,
evaluation_step
):

logs.basicConfig(level=logging.INFO)
logs.info(f&#39;创建注册步骤&#39;)

# log evaluation_report
logs.info(f&#39;评估报告：{evaluation_step}&#39;)

evaluation_s3_uri = evaluation_step.properties.ProcessingOutputConfig.Outputs[&#39;evaluation&#39;].S3Output.S3Uri

model_metrics = ModelMetrics(
model_statistics=MetricsSource(
s3_uri=Join(
on=&quot;/&quot;,
values=[
evaluation_s3_uri,
&quot;evaluation.json&quot;
]
),
content_type=&quot;application/json&quot;
)
)

# 创建 RegisterModel 步骤
register_step = RegisterModel(
name=&#39;ModelRegisterStep&#39;,
estimator=training_step.estimator,
model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,
content_types=[&quot;text/csv&quot;],
response_types=[&quot;text/csv&quot;],
inference_instances=[&quot;ml.m5.large&quot;, &quot;ml.m5.xlarge&quot;],
transform_instances=[&quot;ml.m5.large&quot;],
model_package_group_name=model_package_group_name,
approved_status=model_approval_status,
model_metrics=model_metrics
)

return register_step


我的管道执行成功，但我看不到评估指标
附加图片
我也尝试过手动将 S3 中的评估报告添加到模型版本中，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/79005084/how-to-access-evaluation-metrics-in-new-sagemaker-studio-ui-after-doing-model-re</guid>
      <pubDate>Fri, 20 Sep 2024 03:26:51 GMT</pubDate>
    </item>
    <item>
      <title>无法从 Pytorch Dataset 的 __get_item__ 返回布尔变量</title>
      <link>https://stackoverflow.com/questions/79000230/unable-to-return-a-boolean-variable-from-pytorch-datasets-get-item</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79000230/unable-to-return-a-boolean-variable-from-pytorch-datasets-get-item</guid>
      <pubDate>Wed, 18 Sep 2024 21:33:47 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface Pretrained 中 device_map = "auto" 的替代方案</title>
      <link>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</link>
      <description><![CDATA[我有一个从 huggingface 读取的模型，使用以下代码：
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

现在我读取了模型，并对内部层做了一些修改，并添加了更多层。当我开始训练/微调时，我发现并非所有东西都在同一个模型上。
现在经过更多调查，我发现我的自定义层没有像原始模型那样分布在多个 GPU 上。因此我需要类似 device_map=&quot;auto&quot; 的内容，但在读取模型之后。
因此只需类似
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

model.device_map = &quot;auto&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</guid>
      <pubDate>Sat, 14 Sep 2024 12:42:03 GMT</pubDate>
    </item>
    <item>
      <title>尽管分类报告很好，但模型无法正确预测</title>
      <link>https://stackoverflow.com/questions/78976316/model-cant-predict-correctly-even-though-has-a-good-classification-report</link>
      <description><![CDATA[我尝试从链接运行此模型：
https://www.kaggle.com/code/alexfordna/garbage-classification-mobilenetv2-92-accuracy/notebook
当我在 colab 上使用类似数据集（但较小，2100 张图片到 6 个类）执行此操作时，效果很好。但是当我添加此代码来预测输入图像时：
from google.colab import files
from PIL import Image

def process_uploaded_image(image_path, target_size=(224, 224)):
img = Image.open(image_path)
img = img.resize(target_size) 
img_array = np.array(img) 

if img_array.shape[-1] == 4: 
img_array = img_array[..., :3]

img_array = img_array / 255.0 
img_array = np.expand_dims(img_array, axis=0) 
img_array = mobilenetv2.preprocess_input(img_array) 

return img_array

uploaded = files.upload()

for fn in uploaded.keys(): 
processed_image = process_uploaded_image(fn, target_size=IMAGE_SIZE) 
preds = model.predict(processed_image)
pred_class = np.argmax(preds, axis=1)

plt.imshow(Image.open(fn)) # 显示上传的图片
plt.title(f&#39;预测的类别：{categories[pred_class[0]]}&#39;)
plt.axis(&#39;off&#39;)
plt.show()
print(f&#39;文件 {fn} 被预测为：{categories[pred_class[0]]}&#39;)

结果是错误的预测。例如，模型总是将我的输入预测为“垃圾”类。当我停止运行时，它会更改为另一个类，但它仍然处于错误的预测中。
我还添加了此代码来检查预测概率：
preds = model.predict(processed_image)
pred_probs = preds[0] # 获取第一个（也是唯一一个）批次的预测概率
print(&quot;Prediction probabilities:&quot;, pred_probs)
pred_class = np.argmax(pred_probs)
print(&quot;Predicted class:&quot;, categories[pred_class])

输出：
**1/1** ━━━━━━━━━━━━━━━━━━━━━━ **0s** 24ms/步 预测概率：\[0.31027108 0.12315894 0.47848797 0.00863316 0.07789086 0.00155797\] 
预测类别：金属 

为什么会发生这种情况，我的模型如何正确预测结果？]]></description>
      <guid>https://stackoverflow.com/questions/78976316/model-cant-predict-correctly-even-though-has-a-good-classification-report</guid>
      <pubDate>Thu, 12 Sep 2024 02:58:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在 nltk 中下载 punkt tokenizer？</title>
      <link>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</link>
      <description><![CDATA[我使用 安装了 NLTK 库
pip install nltk

在使用库时
from nltk.tokenize import sent_tokenize 
sent_tokenize(text)

我收到此错误
LookupError: 
**************************************************************************
未找到资源 punkt。
请使用 NLTK 下载器获取资源：

&gt;&gt;&gt; import nltk
&gt;&gt;&gt; nltk.download(&#39;punkt&#39;)

有关更多信息，请参阅：https://www.nltk.org/data.html

尝试加载 tokenizers/punkt/english.pickle

搜索位置：
- &#39;C:\\Users\\adars/nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\share\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Roaming\\nltk_data&#39;
- &#39;C:\\nltk_data&#39;
- &#39;D:\\nltk_data&#39;
- &#39;E:\\nltk_data&#39;
- &#39;&#39;

因此，为了解决此错误，我尝试了
import nltk
nltk.download(&#39;punkt&#39;)

但是我无法下载此包，因为每次运行此包时都会出现错误，提示
[nltk_data] 加载 punkt 时出错：&lt;urlopen 错误 [WinError 10060] A
[nltk_data] 连接尝试失败，因为连接方
[nltk_data] 在一段时间后未正确响应，或者
[nltk_data] 建立连接失败，因为连接的主机
[nltk_data] 未响应&gt;

请帮帮我]]></description>
      <guid>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</guid>
      <pubDate>Tue, 19 Sep 2023 04:36:59 GMT</pubDate>
    </item>
    <item>
      <title>如何继续openai API的不完整响应</title>
      <link>https://stackoverflow.com/questions/76206459/how-to-continue-incomplete-response-of-openai-api</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76206459/how-to-continue-incomplete-response-of-openai-api</guid>
      <pubDate>Tue, 09 May 2023 06:33:09 GMT</pubDate>
    </item>
    <item>
      <title>如何继续进一步训练预先训练的 YOLOv8 模型</title>
      <link>https://stackoverflow.com/questions/75730103/how-to-continue-to-further-train-a-pre-trained-yolov8-model</link>
      <description><![CDATA[我已经在自定义数据集上训练了一个包含 4 个类别的 YOLOv8 模型，用于对象检测。
现在我想通过增加数据集来训练它以检测更多类别。
我是否可以在新数据集上进一步专门训练它，而不是从头开始训练模型？]]></description>
      <guid>https://stackoverflow.com/questions/75730103/how-to-continue-to-further-train-a-pre-trained-yolov8-model</guid>
      <pubDate>Tue, 14 Mar 2023 07:23:23 GMT</pubDate>
    </item>
    </channel>
</rss>