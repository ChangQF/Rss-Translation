<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 22 Apr 2024 18:17:07 GMT</lastBuildDate>
    <item>
      <title>UnicodeEncodeError：“charmap”编解码器无法对位置 19-38 中的字符进行编码：字符映射到 <未定义></title>
      <link>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</link>
      <description><![CDATA[我正在开发一个基于 Flask 的 Web 应用程序，用户可以上传图像以使用机器学习模型进行预测。上传的图像存储在本地目录中，并使用预先训练的模型进行预测。然而，当我点击预测按钮时
是什么导致了这个 UnicodeEncodeError？
如何解决此问题以确保我的应用程序能够正确处理图像上传和预测？
是否有在 Flask 环境中处理字符编码的最佳实践，尤其是在 Windows 上？
==app.py====
@app.route(&#39;/uploadimage&#39;,methods=[&#39;GET&#39;, &#39;POST&#39;])
def upload_image():
    如果不是 session.get(&#39;logged_in&#39;):
        flash(&quot;您需要登录才能上传图片。&quot;, &quot;错误&quot;)
        返回重定向（url_for（&#39;登录&#39;））
    
    如果 request.method == &#39;POST&#39;:
        # 从表单中获取文件
        如果“my_image”不在 request.files 中：
            flash(“请求中没有文件部分。”,“错误”)
            返回重定向(request.url)

        文件 = request.files[&#39;my_image&#39;]

        # 检查文件是否上传
        if file.filename == &#39;&#39;:
            flash(“未选择文件。”, “错误”)
            返回重定向(request.url)

        # 验证文件类型（假设图像文件是图像）
        如果不是 file.filename.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;)):
            flash(“仅允许 PNG、JPG 或 JPEG 文件。”, “错误”)
            返回重定向(request.url)

        # 将文件保存到临时位置
        img_path = os.path.join(&#39;images&#39;, file.filename) # 您可能需要创建 &#39;temp&#39; 目录
        文件.保存（img_path）

        # 获取预测结果
        预测标签 = 预测标签(img_path)

        # 返回预测的标签和一条提示信息
        flash(f&quot;预测：{predicted_label}&quot;, &quot;成功&quot;)
        os.remove(img_path) # 处理后删除临时文件

        return redirect(request.url) # 重新加载页面以避免重新提交

    return render_template(&#39;uploadimage.html&#39;) # 对于 GET 请求，渲染表单

]]></description>
      <guid>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</guid>
      <pubDate>Mon, 22 Apr 2024 17:25:20 GMT</pubDate>
    </item>
    <item>
      <title>异特龙图书馆</title>
      <link>https://stackoverflow.com/questions/78367284/allosaurus-library</link>
      <description><![CDATA[我正在使用 Allosaurus 库，该库没有用于设置整个训练模型的批量大小的参数，在这种情况下我该怎么办。我们需要为此更改训练器代码吗？
请提出任何选择。我还想在 GPU 上执行特征提取。这怎么可能？]]></description>
      <guid>https://stackoverflow.com/questions/78367284/allosaurus-library</guid>
      <pubDate>Mon, 22 Apr 2024 15:19:18 GMT</pubDate>
    </item>
    <item>
      <title>最大似然估计初始参数问题</title>
      <link>https://stackoverflow.com/questions/78366722/maximum-likelihood-estimation-initial-parameters-issue</link>
      <description><![CDATA[我的数据集由 x 和 y 变量组成，我想执行最大似然估计 (MLE) 来拟合 sigmoid 均值函数 μ(X;β)=β0​+1+e−(X−β2​) β1​​ 和数据的线性标准偏差函数 σ(X;α)=α0​+α1​⋅X。我使用最大似然函数 L(θ∣X,Y)=i=1ΣN​logf(Yi​∣Xi​;θ) 估计 beta 和 alpha 参数，以便观察数据中的均值和 sigma 趋势。
可能性 = -np.sum(np.log(norm.pdf(Y, mu, sigma)))
最后，每次遇到以下情况时，使用 result = minusminimum(likelihood, initial_params, args=(X,Y), method=&#39;L-BFGS-B&#39;,options={&#39;maxiter&#39;: 100}) 执行似然优化当传递不同的初始值时获得不同的均值和西格玛值的问题时，我发现我的模型对初始参数变得敏感。有什么方法可以解决这种情况，以便我可以获得自动适合我的模型的均值和西格玛的最佳值？
附：我也应用了不同的优化方法，但没有效果。
我通过其他技术实现它已经取得了所需的结果，但我想使用 MLE 来实现它。我该如何解决这个问题？
我尝试过不同的优化方法]]></description>
      <guid>https://stackoverflow.com/questions/78366722/maximum-likelihood-estimation-initial-parameters-issue</guid>
      <pubDate>Mon, 22 Apr 2024 13:47:56 GMT</pubDate>
    </item>
    <item>
      <title>用于回归问题的 PyTorch 模型，每个样本 4 个图像，图像之间有时间间隔</title>
      <link>https://stackoverflow.com/questions/78366460/pytorch-model-for-regression-problem-with-4-images-per-sample-with-time-gap-betw</link>
      <description><![CDATA[我正在使用一个数据集，其中每个样本对应于以已知延迟拍摄的 4 个图像，并且每组 4 个图像都有一个目标预测，该目标预测是一个数字（不是分类）。我目前已经制作了下面的模型，但它根本没有给出好的结果。有什么建议吗？
class SimpleModel(nn.Module)：
    def __init__(自身):
        超级(SimpleModel, self).__init__()
        
        self.conv1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(8)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.dropout1 = nn.Dropout(p=0.25)
        
        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(16)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.dropout2 = nn.Dropout(p=0.25)
        
        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.bn3 = nn.BatchNorm2d(32)
        self.pool3 = nn.MaxPool2d(kernel_size=5, stride=2)
        self.dropout3 = nn.Dropout(p=0.25)
        
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(28800, 512)
        self.dropout4 = nn.Dropout(p=0.5)
        self.fc2 = nn.Linear(512, 1) # 单输出

    def 前向（自身，x）：
        x = torch.relu(self.bn1(self.conv1(x)))
        x = self.pool1(x)
        x = self.dropout1(x)
        
        x = torch.relu(self.bn2(self.conv2(x)))
        x = self.pool2(x)
        x = self.dropout2(x)
        
        x = torch.relu(self.bn3(self.conv3(x)))
        x = self.pool3(x)
        x = self.dropout3(x)
        
        x = self.展平(x)
        x = torch.relu(self.fc1(x))
        x = self.dropout4(x)
        
        x = self.fc2(x) # 输出层，无回归激活函数
        返回x

此外，目标预测值通常非常小，有时甚至大得多，例如从 1e-9 到 1e2 左右。我已将对数刻度应用于目标预测，以减少这种影响，以尝试改进学习，但不确定它有多大帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78366460/pytorch-model-for-regression-problem-with-4-images-per-sample-with-time-gap-betw</guid>
      <pubDate>Mon, 22 Apr 2024 13:04:42 GMT</pubDate>
    </item>
    <item>
      <title>使用Python绘制糖尿病视网膜病变检测图[关闭]</title>
      <link>https://stackoverflow.com/questions/78365786/mapping-in-a-diabetic-retinopathy-detection-using-python</link>
      <description><![CDATA[我目前正在开发一个使用 Inception V3 预训练模型进行糖尿病视网膜病变分类的 Python 程序，然后将其传递到 SVM 和随机森林分类器。快速分解该项目：

对 5 种类型（0、1、2、3、4）的眼睛图像进行分类，其中 0 表示没有患病，4 表示严重。
在这个特定的程序中，我有意将 0,1 图像映射到值 10，将 2,3,4 映射到值 11，将其变成二元分类器。
然后构建模型，然后正确训练和执行。

为了提供有关我的代码工作的更多详细信息，我想显示图像的特定映射。
我建了两个表：
表 1：它有三列，第一列是从 xero 开始的所有图像的编号，第二列是与图像对应的唯一标识符，第三列是类的原始映射 0、1、2 ,3,4。
表 2：前两列相同，但第三列现在显示映射的 ID（10 或 11）
一些有帮助的图像是：
图片 1
图片_2 图片 3
图片 4
我尝试实现上述问题，但 2,3,4 的映射没有出现，只有 0,1 的映射出现。请帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78365786/mapping-in-a-diabetic-retinopathy-detection-using-python</guid>
      <pubDate>Mon, 22 Apr 2024 11:05:03 GMT</pubDate>
    </item>
    <item>
      <title>预测值与目标值/实际值之间没有相关性[关闭]</title>
      <link>https://stackoverflow.com/questions/78365619/no-correlation-between-predicted-values-and-target-value-real-values</link>
      <description><![CDATA[我正在执行回归任务。当我绘制预测值与实际值时，我发现变量之间没有相关性。我猜这意味着模型无法拟合数据（类似于分类模型预测最常见的类别）。


我尝试了很多方法，但没有一个能够使模型适合数据：

我尝试用对数函数转换目标值：

y_train = np.log(y_train)
y_test = np.log(y_test)



我对目标变量应用了平方根函数，但它不起作用：

y_train = (y_train)**0.5
y_测试 = (y_测试)**0.5



我什至尝试标准化目标函数，但也不起作用

def preprocess_data_standard_regression(数据):
    定标器=标准定标器()
    X = data[[data.columns 中的 col 的 col
              如果不是 col.startswith(&quot;POSTOP_&quot;)
              并且 col !=“in_患者_id”
              和 col != &quot;in_laterity&quot;]]
    y = 数据[“POSTOP_MAN_vault_posto”]
    y = scaler.fit_transform(y.values.reshape(-1,1)).flatten()
    缩放器 = MinMaxScaler()
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)
    X_train = 缩放器.fit_transform(X_train)
    X_test = 缩放器.transform(X_test)
    返回X_train，X_test，y_train，y_test


我的数据集的形状是 545 行 vs 24 列。]]></description>
      <guid>https://stackoverflow.com/questions/78365619/no-correlation-between-predicted-values-and-target-value-real-values</guid>
      <pubDate>Mon, 22 Apr 2024 10:41:06 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该始终在神经网络初始化部分中包含初始化层？</title>
      <link>https://stackoverflow.com/questions/78365535/should-i-always-include-initialization-layers-in-my-neural-network-initializatio</link>
      <description><![CDATA[我看到有人的代码包含使用Xavier这种方式（如下），该代码用于预测具有1400行和300个变量（80个，在one-hot-encoding之前）的房价数据。我查了一下它的描述，上面说防止梯度消失或爆炸，加速收敛。这似乎都是有益的，所以我应该始终在代码中包含 Xavier 初始化吗？或者我什么时候不应该包括 Xavier？ TIA
类 Net(torch.nn.Module):
    def __init__(自身):
        超级(网络,自我).__init__()
        self.hidden_​​layer1 = nn.Linear(331,1024)
        self.hidden_​​layer2 = nn.Linear(1024,1024)
        self.hidden_​​layer3 = nn.Linear(1024,1024)
        self.hidden_​​layer4 = nn.Linear(1024,1024)
        self.output_layer = nn.Linear(1024,1)
        self.dropout = nn.Dropout(p=0.2)
        nn.init.xavier_uniform_(self.hidden_​​layer1.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer2.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer3.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer4.weight)
        nn.init.xavier_uniform_(self.output_layer.weight)

defforward(self,x)：
    输入 = x
    layer1_out = torch.nn.function.gelu(self.hidden_​​layer1(输入))
    Layer1_out = self.dropout(layer1_out)
    Layer2_out = torch.nn.function.gelu(self.hidden_​​layer2(layer1_out))
    Layer2_out = self.dropout(layer2_out)
    layer3_out = torch.nn.function.gelu(self.hidden_​​layer3(layer2_out))
    Layer3_out = self.dropout(layer3_out)
    Layer4_out = torch.nn.function.gelu(self.hidden_​​layer4(layer3_out))
    Layer4_out = self.dropout(layer4_out)
    输出 = torch.relu(self.output_layer(layer4_out))
    返回输出

我一直在尝试学习深度学习，但我一直不清楚在神经网络中包含初始化的重要性。]]></description>
      <guid>https://stackoverflow.com/questions/78365535/should-i-always-include-initialization-layers-in-my-neural-network-initializatio</guid>
      <pubDate>Mon, 22 Apr 2024 10:25:38 GMT</pubDate>
    </item>
    <item>
      <title>您好，请帮忙，我遇到了 djangorestframework 的错误问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78365482/hi-there-help-plz-im-facing-an-error-issue-with-djangorestframework</link>
      <description><![CDATA[我尝试使用 djangorestframework 创建 API，但遇到错误问题，有人可以帮助我调试吗？我的代码如下
serializers.py：
从rest_framework导入序列化器
从rest_framework.exceptions导入ValidationError

类 ImagePredictionSerializer(serializers.Serializer):
    图像 = 序列化器.ImageField()

    def validate_image(自身, 值):
        如果没有值：
            raise ValidationError(“图像字段为必填项”)
        返回值

错误：
/api/upload/ 处出现类型错误
“方法”对象不支持项目分配
请求方式：GET
请求网址：http://127.0.0.1:8000/api/upload/
Django 版本：4.2.3
异常类型：TypeError
异常值：
“方法”对象不支持项目分配
异常位置：C:\src\Django_tuto\fridgevision\env\Lib\site-packages\django\middleware\clickjacking.py，第 34 行，在 process_response 中
在 process.serializers.ImagePredictionSerializer 期间引发
Python 可执行文件：C:\src\Django_tuto\fridgevision\env\Scripts\python.exe
Python版本：3.11.8
Python路径：
[&#39;C:\\src\\Django_tuto\\fridgevision&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\python311.zip&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\DLLs&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311&#39;,
 &#39;C:\\src\\Django_tuto\\fridgevision\\env&#39;,
 &#39;C:\\src\\Django_tuto\\fridgevision\\env\\Lib\\site-packages&#39;]
服务器时间：2024年4月22日周一10:00:10 +0000

我希望获得模型输入图像的预测。这是一个简单的二值分类模型，可以预测图像是好还是坏。]]></description>
      <guid>https://stackoverflow.com/questions/78365482/hi-there-help-plz-im-facing-an-error-issue-with-djangorestframework</guid>
      <pubDate>Mon, 22 Apr 2024 10:15:50 GMT</pubDate>
    </item>
    <item>
      <title>多类问题的层次分类方法</title>
      <link>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</link>
      <description><![CDATA[有一个多类分类任务。我的目标是使用每父节点本地分类器 (LCPN) 方法来解决这个问题。
让我解释一下如何使用 MWE。
假设我有这个虚拟数据集：
将 numpy 导入为 np
从 sklearn.datasets 导入 make_classification
从 scipy.cluster 导入层次结构

X, y = make_classification(n_samples=1000, n_features=10, n_classes=5,
                             n_信息=4）

我想出了这些类之间的距离矩阵：
d = np.array(
[[ 0.、201.537、197.294、200.823、194.517]、
 [201.537, 0., 199.449, 202.941, 196.703],
 [197.294, 199.449, 0., 198.728, 192.354],
 [200.823, 202.941, 198.728, 0., 195.972],
[[194.517, 196.703, 192.354, 195.972, 0.]]
）

因此，我确定了类层次结构，如下所示：
hc = hierarchy.linkage(d, method=&#39;complete&#39;)

得到的树状图如下：
dendrogram = hierarchy.dendrogram(hc, labels=[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;, &#39;D&#39;, &#39;F&#39;])
树状图


我使用hierarchy.to_tree()以树状结构进行说明：

我的问题：
如何按照 LCPN 方法在每个内部节点（包括根）处安装分类器，例如 DecisionTreeClassifier 或 SVM，以像在树中一样进行上图？]]></description>
      <guid>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</guid>
      <pubDate>Sat, 20 Apr 2024 14:08:05 GMT</pubDate>
    </item>
    <item>
      <title>在weka中重新采样过滤器</title>
      <link>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</link>
      <description><![CDATA[我的数据集中的数据实例数量很少。所以，我尝试了“重新采样” Weka中的过滤器可以增加数据量，从而提高模型性能。样本量百分比设置为200可以吗？因为那时我在交叉验证测试中获得了良好的相关系数。
我想知道将样本大小百分比设置为 200 时，重新采样过滤器是否工作正常。
使用此过滤器后，我的模型会准确预测吗？
由于数据量较少，是否有其他增强方法可以增强模型的性能？]]></description>
      <guid>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</guid>
      <pubDate>Sat, 20 Apr 2024 04:29:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 Raspberry Pi 4 在 Python 中崩溃的多线程 [关闭]</title>
      <link>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</link>
      <description><![CDATA[我在尝试使用 Raspberry Pi 4B 完成大学项目时遇到问题。
该项目使用 Python 编写，由 5 个线程组成，其中 2 个线程运行机器学习预测，第 3 个线程按顺序运行一系列计算，以达到与机器学习模型预测的输出相同的输出（这样我可以对比输出是否是合理的值）。另外两个线程是：一个等待 10 秒并激活一个标志（开始处理所需的标志），另一个在终端上打印值（都是从 ML 模型和计算中预测的）。
我的问题是，当我尝试同时运行所有线程时，ML 模型运行正确，但我的计算线程不执行任何操作。相反，如果我不启动 ML 线程，计算线程就会正常工作。
我认为Raspberry没有足够的计算能力，因此计算线程崩溃了。
没有必要所有 3 个线程同时运行（我希望能够选择是否要查看终端上打印的 ML 预测或计算输出），因此我尝试禁用线程当我不使用它们时（使用 thread.join() ）并在我决定希望该线程再次开始运行时再次启动它们（thread.start() ）但它无法正常工作。
我还尝试过使用运行预测或计算函数所需的两个标志（ML_flag 和calculations_flag），但也不起作用。
关于我可以使用的其他技术的任何想法，以便 ML 预测和计算单独运行并且不会崩溃？
谢谢！
下图显示了命令htop：
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</guid>
      <pubDate>Fri, 19 Apr 2024 08:31:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么数组形状会出现这个错误，有其他解决方案吗？</title>
      <link>https://stackoverflow.com/questions/75301595/why-does-this-error-of-array-shape-is-there-other-solutions</link>
      <description><![CDATA[我不断收到此错误，但我通过重塑数组解决了问题：data = data.reshape(-1, 1)
我的输出：
回溯（最近一次调用最后一次）：
  文件“C:\Users\USER\Desktop\python\machine-learning\bot4.py”，第 93 行，在  中
    预测 = model.predict(data)
  文件“C:\Users\USER\Desktop\python\machine-learning\machine-learningVenv\lib\site-packages\sklearn\naive_bayes.py”，第 105 行，在预测中
    X = self._check_X(X)
  文件“C:\Users\USER\Desktop\python\machine-learning\machine-leaningVenv\lib\site-packages\sklearn\naive_bayes.py”，第 579 行，位于 _check_X 中
    返回 self._validate_data(X,accept_sparse=“csr”,reset=False)
  文件“C:\Users\USER\Desktop\python\machine-learning\machine-learningVenv\lib\site-packages\sklearn\base.py”，第 546 行，位于 _validate_data
    X = check_array(X, input_name=“X”, **check_params)
  文件“C:\Users\USER\Desktop\python\machine-learning\machine-learningVenv\lib\site-packages\sklearn\utils\validation.py”，第 902 行，在 check_array 中
    引发值错误（
ValueError：需要 2D 数组，却得到 1D 数组：
array=[&#39;猫正在阳光下睡觉。&#39; “狗对着月亮狂吠。”]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

我期待输出：
[{“猫”:“睡觉”,“狗”:“吠叫”}]]]></description>
      <guid>https://stackoverflow.com/questions/75301595/why-does-this-error-of-array-shape-is-there-other-solutions</guid>
      <pubDate>Tue, 31 Jan 2023 18:27:25 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“tensorflow.keras”的模块，库不匹配</title>
      <link>https://stackoverflow.com/questions/72409779/modulenotfounderror-no-module-named-tensorflow-keras-libraries-mismatching</link>
      <description><![CDATA[软件包1
packages2
这些是我在 anaconda 上的包。我在最后一张照片上收到此错误。我尝试了 stackoverflow 和 github 上的几乎所有内容。我尝试了各种方法来导入 keras 和 tensorflow 。我降级了tensorflow，keras，但我遇到了任何其他错误，例如numpy不兼容等。我将numpy降级为，但这次keras需要更高的版本。
从 keras.preprocessing.text 导入分词器
/从keras.preprocessing.sequence导入pad_sequences
这些是我尝试导入的行。
导入keras
回溯（最近一次调用最后一次）：

  在&lt;单元格行：1&gt;中输入[6]
    导入keras

   中的文件 ~\anaconda3\lib\site-packages\keras\__init__.py:3
    从 。导入实用程序

   中的文件 ~\anaconda3\lib\site-packages\keras\utils\__init__.py:26
    从 .vis_utils 导入 model_to_dot

   中的文件 ~\anaconda3\lib\site-packages\keras\utils\vis_utils.py:7
    从 ..models 导入模型

   中的文件 ~\anaconda3\lib\site-packages\keras\models.py:12
    从 .engine.training 导入模型

   中的文件 ~\anaconda3\lib\site-packages\keras\engine\__init__.py:7
    从 .network 导入 get_source_inputs

   中的文件 ~\anaconda3\lib\site-packages\keras\engine\network.py:15
    从 。进口储蓄

   中的文件 ~\anaconda3\lib\site-packages\keras\engine\ saving.py:21
    从 .. 导入优化器

   中的文件 ~\anaconda3\lib\site-packages\keras\optimizers\__init__.py:1
    从tensorflow.keras.optimizers导入*

ModuleNotFoundError：没有名为“tensorflow.keras”的模块
]]></description>
      <guid>https://stackoverflow.com/questions/72409779/modulenotfounderror-no-module-named-tensorflow-keras-libraries-mismatching</guid>
      <pubDate>Fri, 27 May 2022 18:37:11 GMT</pubDate>
    </item>
    <item>
      <title>将 make_column_transformer 与 OnehotEncoder 和 StandaScaler + 直通结合使用</title>
      <link>https://stackoverflow.com/questions/59605035/using-make-column-transformer-with-onehotencoder-and-standascaler-passthrough</link>
      <description><![CDATA[每当我同时使用 StandardScaler 和 OnehotEncoding 时，我都无法使用 remainder=&#39;passthrough&#39;。不管我怎么说，我都有一个问题。它要么是参数之前的关键字，要么是 fit_tranform 的问题......你能想到的。这是我正在做的事情：
trans_cols= make_column_transformer((OneHotEncoder(),[&#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;,
 &#39;默认&#39;,&#39;住房&#39;,&#39;贷款&#39;,&#39;联系人&#39;,&#39;月份&#39;,&#39;poutcome&#39;]),remainder=&#39;passthrough&#39;)

trans_cols.fit_transform(X)

这是我的专栏：
Index([&#39;年龄&#39;, &#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;, &#39;余额&#39;, &#39;住房&#39;,
   &#39;贷款&#39;, &#39;联系&#39;, &#39;月份&#39;, &#39;持续时间&#39;, &#39;活动&#39;, &#39;pdays&#39;, &#39;上一个&#39;,
   &#39;撅嘴&#39;，&#39;y&#39;]，
  dtype=&#39;对象&#39;)

上面的代码有效，我只是在使用 remainder 键参数时无法组合 2 个估计器。这就是我尝试的原因：
trans_cols= make_column_transformer((OneHotEncoder(),[&#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;,&#39;住房&#39;,&#39;贷款&#39;,
                                                  &#39;联系人&#39;,&#39;月份&#39;,&#39;poutcome&#39;]),remainder=&#39;passthrough&#39;,

(StandardScaler(),[&#39;年龄&#39;, &#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;, &#39;余额&#39;,
                  &#39;住房&#39;,&#39;贷款&#39;, &#39;联系方式&#39;, &#39;月份&#39;, &#39;期限&#39;,
                  &#39;活动&#39;、&#39;pdays&#39;、&#39;上一个&#39;、&#39;poutcome&#39;]))

但是，在我删除 remainder 并保留 2 个元组之前，上述方法不起作用。这是可以理解的。然而，这样做它试图对我的一些数字进行编码，并且有一条消息告诉我它遇到了一些具有浮动的列。而且我的准确性严重下降。]]></description>
      <guid>https://stackoverflow.com/questions/59605035/using-make-column-transformer-with-onehotencoder-and-standascaler-passthrough</guid>
      <pubDate>Sun, 05 Jan 2020 23:14:28 GMT</pubDate>
    </item>
    <item>
      <title>当权重存在时，glmnet 如何标准化变量？</title>
      <link>https://stackoverflow.com/questions/41122803/how-does-glmnet-standardize-variables-when-weights-are-present</link>
      <description><![CDATA[glmnet 允许用户通过 weights 参数输入观察权重向量。 glmnet 还标准化（默认）预测变量以具有零均值和单位方差。我的问题是：当提供 weights 时，glmnet 是否使用每列的加权平均值（和标准差）或未加权平均值（和标准差）来标准化预测变量？]]></description>
      <guid>https://stackoverflow.com/questions/41122803/how-does-glmnet-standardize-variables-when-weights-are-present</guid>
      <pubDate>Tue, 13 Dec 2016 13:50:42 GMT</pubDate>
    </item>
    </channel>
</rss>