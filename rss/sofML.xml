<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 26 Aug 2024 18:21:00 GMT</lastBuildDate>
    <item>
      <title>我们应该在视觉编码器解码器中增加多少训练数据？</title>
      <link>https://stackoverflow.com/questions/78915357/how-much-should-we-augment-our-training-data-in-a-vision-encoder-decoder</link>
      <description><![CDATA[我正在训练一个从图像生成文本的模型，并且正在将文本增强应用到我的数据集以尝试提高模型的性能。我想知道原始文本和增强文本之间的最佳平衡应该是什么。具体来说，我应该使用原始文本与增强文本的百分比是多少（例如，40％原始/60％增强，50％原始/50％增强，60％原始/40％增强，70％原始/30％增强等）？
我很感激您对此的意见，如果您知道任何讨论此主题的论文，请告诉我！
作为上下文，我的原始数据集中有大约150k个文本。
所以我的模型有两个阶段的训练，我得到了这个结果：
实验****************阶段1/阶段2
exp5：60/40****************0.593 /-----
exp6：70/30****************0.591 /-----
exp7： 80/20****************0.592/-----
exp8：90/10****************0.584/-----
到目前为止，似乎在阶段 1 中 60original/40augmented 是最好的，但阶段 2 需要一周以上的时间来训练，这就是为什么我想知道是否存在最佳平衡以节省 GPU 时间。]]></description>
      <guid>https://stackoverflow.com/questions/78915357/how-much-should-we-augment-our-training-data-in-a-vision-encoder-decoder</guid>
      <pubDate>Mon, 26 Aug 2024 16:00:32 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：使用判别损失函数训练 ENet 模型时无法重塑张量</title>
      <link>https://stackoverflow.com/questions/78915099/valueerror-cannot-reshape-tensor-when-training-enet-model-with-discriminative-l</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78915099/valueerror-cannot-reshape-tensor-when-training-enet-model-with-discriminative-l</guid>
      <pubDate>Mon, 26 Aug 2024 14:59:15 GMT</pubDate>
    </item>
    <item>
      <title>我想要一个包含文本和盲文的数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/78915000/i-want-a-dataset-contains-text-and-braille-language</link>
      <description><![CDATA[所以，我正在做一个将语音转换为文本的机器学习模型，然后我正在制作另一个将文本转换为盲文的模型，但我找不到任何同时包含文本和盲文的数据集。
我在 Kaggle 中查找过，但找不到任何数据集，有人可以看看链接或帮我找一个开源数据集吗？
谢谢&lt;3]]></description>
      <guid>https://stackoverflow.com/questions/78915000/i-want-a-dataset-contains-text-and-braille-language</guid>
      <pubDate>Mon, 26 Aug 2024 14:38:17 GMT</pubDate>
    </item>
    <item>
      <title>模型训练时的输入形状问题</title>
      <link>https://stackoverflow.com/questions/78914400/input-shape-problem-during-model-training</link>
      <description><![CDATA[大家好，我的代码中出现了这个问题，你能帮我吗？
ValueError: 输入 0 层“ functional”与层不兼容：预期形状=（None，4096），发现形状=（None，64，4096）
代码：
def generator_output_signature():
return (
(
tf.TensorSpec(shape=[batch_size, 4096], dtype=tf.float32), # X1 具有很多维度
tf.TensorSpec(shape=[batch_size, max_length], dtype=tf.int32) # X2 具有很多维度
),
tf.TensorSpec(shape=[batch_size, vocab_size], dtype=tf.float32) # y 具有很多维度
)
train_dataset = tf.data.Dataset.from_generator(
lambda: data_generator(train_ids, mining, features, tokenizer, max_length, vocab_size, batch_size),
output_signature=generator_output_signature()
)
train_dataset = train_dataset.batch(batch_size).p​​refetch(tf.data.AUTOTUNE)
image_input = 输入(shape=(4096,))
caption_input = 输入(shape=(max_length,))
x = Embedding(vocab_size, 256)(caption_input) # 输出形状：(None, max_length, 256)
x = LSTM(256)(x) # 输出形状：(None, 256)
image_features = Dense(256,activation=&#39;relu&#39;)(image_input) # 输出形状：(None, 256)
x = Add()([x, image_features])
x = Dense(vocab_size,activation=&#39;softmax&#39;)(x) # 输出形状：(None,vocab_size)
model = Model(inputs=[image_input,caption_input],outputs=x)
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;)
print(model.summary())
我试图删除额外的维度，但这是不可能的，所以我无法训练我的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78914400/input-shape-problem-during-model-training</guid>
      <pubDate>Mon, 26 Aug 2024 12:28:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Stable Baselines3 中改变 TD3 模型的输出激活函数？</title>
      <link>https://stackoverflow.com/questions/78914358/how-to-change-the-output-activation-function-of-the-td3-model-in-stable-baseline</link>
      <description><![CDATA[我正在使用 Stable Baselines3 库进行强化学习，并想修改 TD3 模型。具体来说，我想更改 TD3 模型输出层中使用的激活函数。
我该如何实现？
我尝试修改 Stable Baselines3 库中 TD3 模型的输出激活函数。具体来说，我想用不同的激活函数替换默认的 tanh 激活函数。]]></description>
      <guid>https://stackoverflow.com/questions/78914358/how-to-change-the-output-activation-function-of-the-td3-model-in-stable-baseline</guid>
      <pubDate>Mon, 26 Aug 2024 12:16:40 GMT</pubDate>
    </item>
    <item>
      <title>每个时期后根据补丁重建图像</title>
      <link>https://stackoverflow.com/questions/78914175/reconstruct-images-from-patches-after-every-epoch</link>
      <description><![CDATA[我有一张大图像，我将其分割成大小相等的小块。我将这些小块加载到模型中。预测后，我尝试重建补丁以形成输入图像的形状。
batch_size = 20 # 选择补丁数量
epochs = 15

for epoch in range(epochs):

label_as_fake = np.zeros((batch_size, 1)) 
label_as_real = np.ones((batch_size,1)) 

for ii in tqdm(range(len(train_hr_batches))): #总补丁数，100
lr_imgs = train_lr_batches[ii] 
hr_imgs = train_hr_batches[ii] 

generated_pa​​tches = generator.predict_on_batch(lr_imgs)

调用重建函数保存图像
if (epoch+1) % 1 ==0:
reconstructed_sr = reconstruct_patches(generated_pa​​tches, image_height, image_width, patch_height, patch_width) 
save_images(reconstructed_sr, f&#39;reconstructed_sr_epoch_{epoch+1}.TIF&#39;)


我可以在一个 epoch 之后保存 100 个生成的补丁。但是，当我尝试将补丁组合在一起以将图像重建为输入图像的形状时，会出现错误，提示模型正在尝试在一次迭代后（即 20 个补丁后）重建图像。在尝试重建图像之前，如何修改代码以对 100 个补丁进行完整运行？
Cell In[39]，第 7 行
reconstructed_sr = reconstruct_patches(generated_images, image_height, image_width, patch_height, patch_width)

Cell In[37]，reconstruct_patches 中的第 12 行
raise ValueError(f&quot;expected {expected_num_patches} patches but found {actual_num_patches} patches&quot;)

ValueError: expected 100 patches but found 20 patches

代码仅在定义的 batch_size 结束后尝试重建图像]]></description>
      <guid>https://stackoverflow.com/questions/78914175/reconstruct-images-from-patches-after-every-epoch</guid>
      <pubDate>Mon, 26 Aug 2024 11:36:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 CLIP Vision Encoder 创建自定义对象检测模型</title>
      <link>https://stackoverflow.com/questions/78913273/create-a-custom-object-detection-model-with-clip-vision-encoder</link>
      <description><![CDATA[我目前想知道是否可以仅使用剪辑图像编码器来创建我自己的自定义对象检测模型？
我曾尝试从 CLIP 图像编码器中提取图像的嵌入。我想尝试将其提供给一些现有的对象检测模型，例如 YOLOv5 等，其中 CLIP 图像编码器是特征提取器。然而，我无法理解，我该如何继续这个想法。这可能吗？如果是，建议如何继续？]]></description>
      <guid>https://stackoverflow.com/questions/78913273/create-a-custom-object-detection-model-with-clip-vision-encoder</guid>
      <pubDate>Mon, 26 Aug 2024 07:30:04 GMT</pubDate>
    </item>
    <item>
      <title>Yolov8 推理在 Mac 上运行良好，但在 Windows 上运行不佳 [重复]</title>
      <link>https://stackoverflow.com/questions/78911914/yolov8-inference-working-on-mac-but-not-windows</link>
      <description><![CDATA[我在 pycharm 中使用 ultralytics 中的 Yolo v8 对我训练的模型进行推理，当我在 macbook 上运行它时，它运行良好，但在我的 windows 笔记本电脑上，尽管我使用的是相同的 best.pt 文件和相同的代码，但我到处都得到了大量置信度得分为 1 的边界框：
正在发生的事情的示例
from ultralytics import YOLO
from ultralytics.utils.benchmarks import benchmark

model = YOLO(&quot;best.pt&quot;)
# model = YOLO(&quot;yolov8m.pt&quot;)

results = model(source=0, show=True, conf=0.6, save=True)
# results = model.track(source=0, show=True, conf=0.6, tracker=&quot;bytetrack.yaml&quot;)

我之前也遇到过类似（但不完全相同）的问题，与下面链接的问题类似，pycharm 无法检测到 pytorch，每次导入时都会出错：
import torch：如何修复 OSError WinError 126，加载 fbgemm.dll 或依赖项时出错
我使用用户提供的 libomp140.x86_64.dll 文件并将其放在 C:\Windows\System32 中修复了它，这可能是问题所在吗？
我已经尝试过的方法：
我尝试重新安装 ultralytics和 pytorch 库和 pycharm，以为是它们的安装问题，但什么都没改变。
编辑：通过将 ultralytics 版本降级到 8.2.60 解决了这个问题，感谢 Christoph Rackwitz 指出它与此帖子类似：
使用 YOLOv8 进行大量不正确的检测
降级 torch 版本也可能有效，下次我一定会检查 github 上的已知问题。]]></description>
      <guid>https://stackoverflow.com/questions/78911914/yolov8-inference-working-on-mac-but-not-windows</guid>
      <pubDate>Sun, 25 Aug 2024 18:16:41 GMT</pubDate>
    </item>
    <item>
      <title>AWS SageMaker 预测和测试数据</title>
      <link>https://stackoverflow.com/questions/78907538/aws-sagemaker-predictions-and-test-data</link>
      <description><![CDATA[import pandas as pd
import itertools
import numpy as np
import s3fs
from sagemaker.predictor import Predictor
from sagemaker.serializers import CSVSerializer

# 为您的 CSV 文件定义 S3 路径
import pandas as pd
import s3fs

# 为您的 CSV 文件定义 S3 路径
s3_path = &quot;s3://{}/{}/{}.csv&quot;

# 带有附加检查的读取文件函数
def read_and_check_csv(s3_path):
fs = s3fs.S3FileSystem()
with fs.open(s3_path) as f:
try:
# 尝试读取 CSV 文件
df = pd.read_csv(f, header=None, low_memory=False)
# 检查行长度是否一致
if not df.apply(lambda x: len(x.dropna()), axis=1).nunique() == 1:
raise ValueError(&quot;检测到不一致的行长度&quot;)
print(&quot;文件读取成功，似乎为 CSV 格式。&quot;)
return df
except Exception as e:
print(f&quot;无法读取 CSV 文件：{e}&quot;)
return None

# 读取并检查 CSV 文件
df = read_and_check_csv(s3_path)

如果 df 不为 None:
print(df.head())
否则:
print(&quot;文件无法读取或不是有效的 CSV 格式。&quot;)

# 定义用于切片数据的索引
a = [50 * i for i in range(3)]
b = [40 + i for i in range(10)]
indices = [i + j for i, j in itertools.product(a, b)]

# 准备测试数据
test_data = shape.iloc[indices[:-1]]
test_X = test_data.iloc[:, 1:]

# 确保所有行的列数相同
min_cols = test_X.shape[1]
test_X = test_X.dropna(axis=1, how=&#39;all&#39;) # 删除所有 NaN 值的列

# 验证没有具有不同值的行长度
test_X = test_X.apply(lambda x: x.dropna().reset_index(drop=True), axis=1)

# 使用 SageMaker 端点名称初始化预测器
predictor = Predictor(endpoint_name=&#39;endpoint&#39;)

# 确保预测器使用 CSV 序列化器
predictor.serializer = CSVSerializer()

# 将 DataFrame 转换为端点所需的格式
test_X_csv = test_X.to_csv(index=False, header=False, sep=&#39;,&#39;)

# 进行预测
try:
predictions = predictor.predict(test_X_csv)
# 打印预测
print(predictions.decode(&#39;utf-8&#39;))
except Exception as e:
print(f&quot;Error making predictions: {e}&quot;)


我正在使用上面的这个脚本aws sagemaker Jupyter 实验室中的 xgboost 框架。在此脚本之前，我正在运行以下代码来设置端点。
predictor = estimator.deploy(
initial_instance_count=1, instance_type=&quot;ml.m5.2xlarge&quot;
)

我添加了一些错误处理，这就是我了解到我的测试文件似乎无法正确读取的地方。我得到的实际错误是：
无法读取 CSV 文件：检测到不一致的行长度
无法读取文件或文件不是有效的 CSV 格式。
进行预测时出错：调用 InvokeEndpoint 操作时发生错误（ModelError）：从主服务器收到客户端错误（415），消息为“加载 csv 数据失败，出现异常，请确保数据为 csv 格式：
&lt;class &#39;ValueError&#39;&gt;
设置带有序列的数组元素。请求的数组在 1 维之后具有非均匀形状。检测到的形状为 (29,) + 非均匀部分。&quot;

关于如何修复此问题有任何见解吗？]]></description>
      <guid>https://stackoverflow.com/questions/78907538/aws-sagemaker-predictions-and-test-data</guid>
      <pubDate>Fri, 23 Aug 2024 20:58:39 GMT</pubDate>
    </item>
    <item>
      <title>将具有大内核的 maxpool 转换为具有小内核的 maxpool 的等效堆栈[关闭]</title>
      <link>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</link>
      <description><![CDATA[我有一个 onnx 模型，它有一些这样的 MaxPool 层：

我无法使用这些内核形状，因为我只能从 1x1 变为 3x3。 4x4 被认为不是最佳的，但我可以使用它。
我尝试用一​​堆 3x3 内核替换它们，如下所示：

我错误计算了此图像中的输出形状，但我会修复它。
我的疑问是，即使我修复了 MaxPool 层，输出是否会与具有更大内核的原始输出相似？我无法弄清楚应该使用什么组合才能使输出与原始内核相似或最接近。]]></description>
      <guid>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</guid>
      <pubDate>Wed, 21 Aug 2024 06:09:06 GMT</pubDate>
    </item>
    <item>
      <title>DaskLGBMClassifier.fit() 错误：“Future”对象没有属性“get_params”</title>
      <link>https://stackoverflow.com/questions/73209365/dasklgbmclassifier-fit-error-future-object-has-no-attribute-get-params</link>
      <description><![CDATA[我正在尝试 LGBM 的 Dask API，当我安装 DaskLGBMClassifier 时，我收到以下错误：
&#39;Future&#39; 对象没有属性 &#39;get_params&#39;
我尝试在原始代码上对其进行调试。您可以在错误参考中看到的变量模型，Colab 应该是类 LGBMModel 的一个实例，它似乎具有方法 get_params()。
为什么它说 get_params 是一个属性？什么是“Future”对象？
这是错误 错误图像，这是 model=_train，这是 _train 函数，这是 LGBMModel，最后是 获取参数函数。]]></description>
      <guid>https://stackoverflow.com/questions/73209365/dasklgbmclassifier-fit-error-future-object-has-no-attribute-get-params</guid>
      <pubDate>Tue, 02 Aug 2022 14:33:55 GMT</pubDate>
    </item>
    <item>
      <title>对于小型神经网络，激活函数的最佳选择是什么</title>
      <link>https://stackoverflow.com/questions/69240517/what-is-the-best-choice-for-an-activation-function-in-case-of-small-sized-neural</link>
      <description><![CDATA[我正在使用 pytorch 和 autograd 来构建我的神经网络架构。它是一个具有单个输入和输出的小型 3 层网络。假设我必须根据一些初始条件预测一些输出函数，并且我正在使用自定义损失函数。
我面临的问题是：

我的损失最初收敛，但梯度最终消失。

我尝试过 S 型激活和 tanh。tanh 在损失收敛方面给出了稍好的结果。

我尝试过使用 ReLU，但由于我的神经网络中没有太多权重，权重变得无效，并且无法给出良好的结果。


除了 S 型和 tanh 之外，还有其他激活函数可以很好地处理小型神经网络的梯度消失问题吗？还有什么建议我可以尝试吗？]]></description>
      <guid>https://stackoverflow.com/questions/69240517/what-is-the-best-choice-for-an-activation-function-in-case-of-small-sized-neural</guid>
      <pubDate>Sun, 19 Sep 2021 05:20:49 GMT</pubDate>
    </item>
    <item>
      <title>ReLU 何时会杀死神经元？</title>
      <link>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</link>
      <description><![CDATA[我对 ReLU 死亡问题感到困惑。ReLU 只会在前向传递期间杀死神经元吗？还是在后向传递期间也会杀死神经元？]]></description>
      <guid>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</guid>
      <pubDate>Tue, 15 May 2018 11:35:06 GMT</pubDate>
    </item>
    <item>
      <title>避免深度神经网络中的梯度消失</title>
      <link>https://stackoverflow.com/questions/46270122/avoiding-vanishing-gradient-in-deep-neural-networks</link>
      <description><![CDATA[我正在研究 Keras，试图深入研究深度学习。
据我所知，由于梯度消失问题，仅堆叠几个密集层就可以有效地阻止反向传播工作。
我发现有一个预先训练好的 VGG-16 神经网络，您可以下载并在其基础上构建。
这个网络有 16 层，所以我想，这就是您遇到梯度消失问题的地方。
假设我想在 Keras 中自己训练网络。我应该怎么做？我应该将各层分成簇并将它们作为自动编码器进行独立训练，然后在其上堆叠一个分类器并进行训练吗？ Keras 中是否有内置的机制？]]></description>
      <guid>https://stackoverflow.com/questions/46270122/avoiding-vanishing-gradient-in-deep-neural-networks</guid>
      <pubDate>Mon, 18 Sep 2017 00:39:47 GMT</pubDate>
    </item>
    <item>
      <title>阶跃函数计算限制</title>
      <link>https://stackoverflow.com/questions/28462891/step-function-computational-limitations</link>
      <description><![CDATA[阶跃函数作为神经网络的激活函数有哪些局限性？
我听说非线性函数需要具有普遍性，但阶跃函数在这方面处于什么位置？它们是否与线性激活函数一样有限？它们会被归类为线性函数吗？]]></description>
      <guid>https://stackoverflow.com/questions/28462891/step-function-computational-limitations</guid>
      <pubDate>Wed, 11 Feb 2015 19:30:18 GMT</pubDate>
    </item>
    </channel>
</rss>