<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 01 Apr 2024 01:03:18 GMT</lastBuildDate>
    <item>
      <title>使用相机模块训练的 ML 模型未给出预测</title>
      <link>https://stackoverflow.com/questions/78252865/trained-ml-model-with-the-camera-module-is-not-giving-predictions</link>
      <description><![CDATA[我已经训练了 CNN 模型并将其保存为 .h5 格式，但是当我在相机的帮助下使用它进行预测时，我无法预测，相机打开但没有预测和其他内容
这是我的代码，我实际上正在学习 ML，所以你能解决这个问题吗？
这是我的代码，我实际上正在学习 ML，所以你能解决这个问题吗？
当我向笔记本电脑摄像头显示图像时，我希望预测图像类别
将 numpy 导入为 np
导入CV2
从 keras.models 导入 load_model

# 加载模型
模型 = load_model(&#39;C:/Users/Win/Downloads/traffic_classifier.h5&#39;)

＃ 参数
帧宽度 = 640 # 相机分辨率
框架高度 = 480
亮度=180
阈值 = 0.5 # 概率阈值
字体= cv2.FONT_HERSHEY_SIMPLEX

# 设置摄像机
上限 = cv2.VideoCapture(0)
cap.set(3, 框架宽度)
cap.set(4, 框架高度)
cap.set(10, 亮度)

def 预处理(img):
    # 将图像转换为RGB格式
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # 将图像大小调整为 30x30
    img = cv2. 调整大小(img, (30, 30))
    # 标准化像素值
    图片 = 图片 / 255.0
    # 添加批次维度
    img = np.expand_dims(img, 轴=0)
    返回图片

def getClassName(类号):
    类={
        0: &#39;限速 20 公里/小时&#39;,
        1：“限速 30 公里/小时”，
        2：“限速 50 公里/小时”，
        3：“限速 60 公里/小时”，
        4：“限速 70 公里/小时”，
        5：“限速 80 公里/小时”，
        6：“限速 80 公里/小时结束”，
        7: &#39;限速 100 公里/小时&#39;,
        8：“限速 120 公里/小时”，
        9：“禁止通过”，
        10：“3.5吨以上车辆禁止通行”，
        11：“下一个路口的通行权”，
        12：“优先道路”，
        13：“产量”，
        14：“停止”，
        15：“没有车辆”，
        16：“禁止超过 3.5 吨的车辆”，
        17：“禁止进入”，
        18：“一般警告”，
        19：“向左危险曲线”，
        20：“向右危险曲线”，
        21：“双曲线”，
        22：“崎岖不平的道路”，
        23：“路滑”
        24：“道路右侧变窄”，
        25：“道路施工”
        26：“交通信号”，
        27：“行人”，
        28：“儿童穿越”，
        29：“自行车过路处”，
        30：“小心冰/雪”
        31：“野生动物穿越”
        32：“所有速度和超车限制结束”，
        33：“向前右转”
        34：“向前左转”，
        35：“仅向前”，
        36：“直走或右转”
        37：“直走或向左走”，
        38：“靠右行驶”
        39：“靠左行驶”
        40：“强制回旋处”，
        41：“禁止通过的结束”，
        42：“禁止3.5吨以上车辆通行”
    }
    返回类[classNo]

而真实：
    成功，imgOriginal = cap.read()

    # 预处理图像
    img = 预处理(imgOriginal)

    # 预测
    预测 = model.predict(img)
    classIndex = np.argmax(预测，轴=1)
    概率值 = np.amax(预测)

    # 如果概率高于阈值则显示结果
    如果概率值&gt;临界点：
        类名 = getClassName(类索引)
        cv2.putText(imgOriginal, &quot;类: &quot; + 类名, (20, 35), 字体, 0.75, (0, 0, 255), 2, cv2.LINE_AA)
        cv2.putText(imgOriginal, &quot;概率:&quot; + str(round(probabilityValue * 100, 2)) + &quot;%&quot;, (20, 75), 字体, 0.75, (0, 0, 255), 2 ，cv2.LINE_AA)
        cv2.imshow(“结果”, imgOriginal)
    别的：
        cv2.imshow(“处理后的图像”, imgOriginal)

    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;): # 检查是否按下&#39;q&#39;键退出
        休息

cap.release()
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78252865/trained-ml-model-with-the-camera-module-is-not-giving-predictions</guid>
      <pubDate>Sun, 31 Mar 2024 21:19:14 GMT</pubDate>
    </item>
    <item>
      <title>Keras相似度计算。枚举两个张量之间的距离，以列表形式表示</title>
      <link>https://stackoverflow.com/questions/78252612/keras-similarity-calculation-enumerating-distance-between-two-tensors-which-in</link>
      <description><![CDATA[我遵循 Nicholas Renotte 教程“构建深度面部识别应用程序”(Python)。但在第 4 部分我遇到了一个问题，代码如下：
连体 L1 距离等级
类L1Dist（图层）：

    # Init方法-继承
    def __init__(self, **kwargs):
        超级().__init__()

    # 魔法发生在这里 - 相似度计算
    def 调用（自身，input_embedding，validation_embedding）：
        返回 tf.math.abs（输入嵌入 - 验证嵌入）

类型错误：不支持的操作数类型 -：“列表”和“列表”
在视频中一切都很好，但在我的例子中，函数无法进行减法（input_embedding - valid_embedding）
L1Dist.call() 收到的参数：
args=([&#39;&#39;]，[&#39;&#39;])

尝试修改：
def 调用（自身、input_embedding、validation_embedding）：
        input_embedding = tf.convert_to_tensor(input_embedding)
        validation_embedding = tf.convert_to_tensor(validation_embedding)
        input_embedding = tf.squeeze(input_embedding, axis=0) # 删除潜在的第一维
        validation_embedding = tf.squeeze(validation_embedding, axis=0)
        返回 tf.math.abs（输入嵌入 - 验证嵌入）

但是失败了
第108行，在convert_to_eager_tensor中
    返回 ops.EagerTensor(值, ctx.device_name, dtype)
ValueError：TypeError：“KerasTensor”类型的对象没有 len()

尝试过 tf.keras.layers.Subtract()([input_embedding,validation_embedding])
但是 AttributeError: 调用 Subtract.call() 时遇到异常。
“列表”对象没有属性“形状”
使用 keras.ops.subtract（input_embedding，validation_embedding）
面临：ValueError(f“无效的 dtype：{dtype}”)
ValueError：无效的数据类型：列表]]></description>
      <guid>https://stackoverflow.com/questions/78252612/keras-similarity-calculation-enumerating-distance-between-two-tensors-which-in</guid>
      <pubDate>Sun, 31 Mar 2024 19:39:46 GMT</pubDate>
    </item>
    <item>
      <title>如何在机器学习模型中根据目标参数预测输入参数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78252231/how-to-predict-input-parameters-from-target-parameter-in-a-machine-learning-mode</link>
      <description><![CDATA[例如，如果像 T=300 C、时间= 60 分钟、催化剂= A 型这样的实验输入数据给出 70% 的生物柴油产量，我希望 ANN 模型能够预测什么输入参数可以实现 90% 甚至 95% 的生物柴油产量？
我还没有找到解决的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78252231/how-to-predict-input-parameters-from-target-parameter-in-a-machine-learning-mode</guid>
      <pubDate>Sun, 31 Mar 2024 17:28:41 GMT</pubDate>
    </item>
    <item>
      <title>训练精度和验证精度曲线几乎彼此平行。模型是否过度拟合？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78251744/the-training-accuracy-and-the-validation-accuracy-curves-are-almost-parallel-to</link>
      <description><![CDATA[训练和验证精度如下：
Epoch 1/5，训练精度：0.9442，验证精度：0.7626，时间：27.09 秒
Epoch 2/5，训练精度：0.9631，验证精度：0.7518，时间：28.14 秒
Epoch 3/5，训练精度：0.9757，验证精度：0.7914，时间：27.54 秒
Epoch 4/5，训练精度：0.9730，验证精度：0.7698，时间：27.30 秒
Epoch 5/5，训练精度：0.9865，验证精度：0.7482，时间：27.74 秒
它是一个基于文本的英语和印地语新闻标题数据集。
大小为 1680+ 条记录。
使用的模型是带有 Adam 优化器的多语言 BERT。
图表快照
模型是否过度拟合？如果是这样，我们如何改进模型？
我们预计训练精度会急剧上升，验证精度曲线会接近它，但不确定该图是否最优。]]></description>
      <guid>https://stackoverflow.com/questions/78251744/the-training-accuracy-and-the-validation-accuracy-curves-are-almost-parallel-to</guid>
      <pubDate>Sun, 31 Mar 2024 14:52:10 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“llama_index.llms”（未知位置）导入名称“HuggingFaceInferenceAPI”</title>
      <link>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</link>
      <description><![CDATA[想要导入 HuggingFaceInferenceAPI。
从 llama_index.llms 导入 HugggingFaceInferenceAPI

llama_index.llms 文档没有 HuggingFaceInferenceAPI 模块。有人有这方面的更新吗？]]></description>
      <guid>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</guid>
      <pubDate>Sun, 31 Mar 2024 14:21:19 GMT</pubDate>
    </item>
    <item>
      <title>哪个库可以替代机器学习编程中的 causal_conv1d？</title>
      <link>https://stackoverflow.com/questions/78251511/which-library-can-replace-causal-conv1d-in-machine-learning-programming</link>
      <description><![CDATA[最近，我一直在使用 causal_conv1d 库进行机器学习编程，而 causal_conv1d 是 mamba_ssm 库的一部分。但是，我只能在 NVIDIA GPU 上运行这些库。我使用的是带有M系列芯片（M2 PRO）的MAC机器。如何在我的 MAC 计算机上使用 causal_conv1d 库或者是否有任何可用的替代库？
我尝试使用 MPS 版本安装 PyTorch，但 causal_conv1d 库似乎直接需要对 nvcc 和 CUDA 的支持。]]></description>
      <guid>https://stackoverflow.com/questions/78251511/which-library-can-replace-causal-conv1d-in-machine-learning-programming</guid>
      <pubDate>Sun, 31 Mar 2024 13:38:26 GMT</pubDate>
    </item>
    <item>
      <title>在包含文本和图像的 PDF 上微调大型语言模型</title>
      <link>https://stackoverflow.com/questions/78251401/fine-tuning-large-language-model-on-pdfs-containing-text-and-images</link>
      <description><![CDATA[我需要在包含从 PDF 中提取的文本和图像的自定义数据集上微调法学硕士。
对于文本部分，我已成功提取整个文本数据并使用 OpenAI API 生成 JSON/CSV 格式的问题和答案。这种方法对于基于文本的微调非常有效。
但是，我不确定如何处理图像。谁能建议一种方法或库来帮助我处理图像并将其合并到微调过程中？
然后，使用 QnA 的微调模型。此外，我对使用哪个模型来完成此任务感到困惑。
任何指导、资源或见解将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78251401/fine-tuning-large-language-model-on-pdfs-containing-text-and-images</guid>
      <pubDate>Sun, 31 Mar 2024 13:04:38 GMT</pubDate>
    </item>
    <item>
      <title>草图引导文本到图像生成</title>
      <link>https://stackoverflow.com/questions/78251364/sketch-guided-text-to-image-generation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78251364/sketch-guided-text-to-image-generation</guid>
      <pubDate>Sun, 31 Mar 2024 12:53:19 GMT</pubDate>
    </item>
    <item>
      <title>我的 ICNN 似乎不适用于任何 n_hidden</title>
      <link>https://stackoverflow.com/questions/78251346/my-icnn-doesnt-seem-to-work-for-any-n-hidden</link>
      <description><![CDATA[`
类凸线性（nn.Module）：
    def __init__(自身, size_in, size_out):
        超级().__init__()
        self.size_in, self.size_out = size_in, size_out
        权重 = torch.Tensor(size_out, size_in)
        self.weights = nn.Parameter(权重)
        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))

    def 前向（自身，x）：
        w_times_x= torch.mm(x, F.softplus(self.weights.t()))
        返回 w_times_x

类 ICNN(nn.Module):
    def __init__(自身, n_input, n_hidden, n_output):
        超级（ICNN，自我）.__init__()
        self.layers = nn.ModuleDict()
        self.深度 = len(n_hidden)
        self.layers[str(0)] = nn.Linear(n_input, n_hidden[0]).float()
        nn.init.xavier_uniform_(self.layers[str(0)].weight)
        # 创建NN，以n_hidden中的元素数量作为深度
        对于范围内的 i(1, self.deep):
            self.layers[str(i)] =凸线性(n_hidden[i-1], n_hidden[i]).float()

        self.layers[str(self.深度)] =凸线性(n_hidden[self.深度-1], n_output).float()
        
    def 前向（自身，x）：
        # 第一层
        x = x.view(-1, 3, 3)
        det = 火炬.det(x)
        det = det.view(-1, 1)
        x_t = x.转置(1, 2)
        mult = torch.bmm(x_t, x)
        跟踪 = torch.diagonal(mult, dim1=1, dim2=2).sum(1)
        跟踪 = 跟踪.view(-1, 1)
        x = torch.cat((trace, det), 1)
        z = x.clone()
        z = self.layers[str(0)](z)

        对于范围（1，self.深度）中的图层：
            z = self.layers[str(层)](z)
            z = F.softplus(z)
            z = 火炬.square(z)
        y = self.layers[str(self.深度)](z)
        返回y

&lt;前&gt;&lt;代码&gt;n_input = 2
n_输出 = 1
n_隐藏 = [64, 64]
icnn = ICNN(n_输入, n_隐藏, n_输出)

x 是一个 600, 9 数据集，在 defforward 中转换为 600, 2 集：
输出应该是 600, 1
但是对于 n_hidden 的任何其他组合，代码都会给出非常糟糕的结果。
如果有任何疑问 - 我需要一个凸的、非递减的激活函数，线性层的权重为非负]]></description>
      <guid>https://stackoverflow.com/questions/78251346/my-icnn-doesnt-seem-to-work-for-any-n-hidden</guid>
      <pubDate>Sun, 31 Mar 2024 12:46:57 GMT</pubDate>
    </item>
    <item>
      <title>Optuna Hyperband 算法不遵循预期的模型训练方案</title>
      <link>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</link>
      <description><![CDATA[我在 Optuna 中使用 Hyperband 算法时发现了一个问题。根据 Hyperband 算法，当 min_resources = 5、ma​​x_resources = 20 且 reduction_factor = 2 时，搜索应以 支架 1 的初始空间为 4 个模型，每个模型在第一轮中接收 5 epoch。随后，每轮模型的数量减少 2 倍，下一个括号的搜索空间也应减少 2 倍，即括号 2 将进行初始搜索2 个模型的空间，并且剩余模型的 epoch 数量在后续的每一轮中加倍。因此预计模型总数应为 11，但它正在训练很多模型。
文章链接：- https://arxiv.org/pdf/1603.06560.pdf
导入 optuna
将 numpy 导入为 np

# 玩具数据集生成
defgenerate_toy_dataset():
    np.随机.种子(0)
    X_train = np.random.rand(100, 10)
    y_train = np.random.randint(0, 2, 大小=(100,))
    X_val = np.random.rand(20, 10)
    y_val = np.random.randint(0, 2, 大小=(20,))
    返回 X_train、y_train、X_val、y_val

X_train、y_train、X_val、y_val =generate_toy_dataset（）

# 模型构建函数
def build_model（试用）：
    模型=顺序（）
    model.add(Dense(units=Trial.suggest_int(&#39;unit_input&#39;, 20, 30),
                    激活=&#39;selu&#39;,
                    input_shape=(X_train.shape[1],)))

    num_layers = Trial.suggest_int(&#39;num_layers&#39;, 2, 3)
    对于范围内的 i（num_layers）：
        单位 = Trial.suggest_int(f&#39;num_layer_{i}&#39;, 20, 30)
        激活 = Trial.suggest_categorical(f&#39;activation_layer_{i}&#39;, [&#39;relu&#39;, &#39;selu&#39;, &#39;tanh&#39;])
        model.add（密集（单位=单位，激活=激活））
        if Trial.suggest_categorical(f&#39;dropout_layer_{i}&#39;, [True, False]):
            model.add(Dropout(rate=0.5))

    model.add（密集（1，激活=&#39;sigmoid&#39;））

    Optimizer_name = Trial.suggest_categorical(&#39;optimizer&#39;, [&#39;adam&#39;, &#39;rmsprop&#39;])
    如果优化器名称==&#39;亚当&#39;：
        优化器 = tf.keras.optimizers.Adam()
    别的：
        优化器 = tf.keras.optimizers.RMSprop()

    model.compile(optimizer=optimizer,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;,tf.keras.metrics.AUC(name=&#39;val_auc&#39;)])

    返回模型

定义目标（试用）：
    模型 = build_model(试用)
    # 假设你已经准备好数据
    # 修改拟合方法以包含 AUC 指标
    历史= model.fit（X_train_splitted，y_train_splitted，validation_data =（X_val，y_val），详细= 1）
    
    # 检查&#39;val_auc&#39;是否被记录
    auc_key = 无
    对于history.history.keys()中的键：
        if key.startswith(&#39;val_auc&#39;):
            auc_key = 密钥
            print(f&quot;auc_key 是 {auc_key}&quot;)
            休息
    
    如果 auc_key 为 None：
        raise ValueError(“历史记录中未找到 AUC 指标。确保在训练期间记录它。”)
    
    # 报告每个模型的验证 AUC
    
    如果 auc_key ==“val_auc”：
        步长=0
    别的：
        步骤 = int(auc_key.split(&#39;_&#39;)[-1])
    
    auc_value=history.history[auc_key][0]
    试验.报告（auc_value，步骤=步骤）
    print(f&quot;是否修剪:-{Trial.should_prune()}&quot;)
    如果审判.should_prune():
        引发 optuna.TrialPruned()

    返回历史记录.history[auc_key]

# Optuna 研究创建
研究 = optuna.create_study(
    方向=&#39;最大化&#39;,
    修剪器=optuna.pruners.HyperbandPruner(
        最小资源=5，
        最大资源=20,
        减少因子=2
    ）
）

# 开始优化
研究.优化（目标）

]]></description>
      <guid>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</guid>
      <pubDate>Sun, 31 Mar 2024 12:38:07 GMT</pubDate>
    </item>
    <item>
      <title>如何解决这个错误并在深度学习中顺利工作？</title>
      <link>https://stackoverflow.com/questions/78251029/how-can-i-resolve-this-error-and-work-smoothly-in-deep-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78251029/how-can-i-resolve-this-error-and-work-smoothly-in-deep-learning</guid>
      <pubDate>Sun, 31 Mar 2024 10:36:24 GMT</pubDate>
    </item>
    <item>
      <title>model.evaluate 和metrics.accuracy_score 之间的区别</title>
      <link>https://stackoverflow.com/questions/78250436/difference-between-model-evaluate-and-metrics-accuracy-score</link>
      <description><![CDATA[我尝试使用两种不同的方法评估 CNN 模型：
1.
model.evaluate(test_data)

在这种情况下，我得到 79% 的准确度分数：[1.2163524627685547, 0.7924528121948242]
2.
我想获取实际的预测值并使用 scikit-learn 指标来获取准确度分数：
test_prediction=model.predict(test_data)
test_prediction = np.argmax（test_prediction，轴= 1）

y_test = np.concatenate([y_batch for X_batch, y_batch in test_data])

指标.accuracy_score(test_prediction,y_test)

本例中的准确度得分为 21%。
为什么会有差异，哪种方式更可靠？]]></description>
      <guid>https://stackoverflow.com/questions/78250436/difference-between-model-evaluate-and-metrics-accuracy-score</guid>
      <pubDate>Sun, 31 Mar 2024 06:05:04 GMT</pubDate>
    </item>
    <item>
      <title>在数字分类混合数据帧上应用 RandomForestRegressor 来预测两列标签集时得分较低</title>
      <link>https://stackoverflow.com/questions/78242202/low-score-when-applying-randomforestregressor-on-a-numeric-categorical-mixed-dat</link>
      <description><![CDATA[我在 Kaggle 上使用这个保险数据集 insurance数据集尝试构建一个简单的回归器来预测最后两列 [&#39;coverage_level&#39;,&#39;charges&#39;]，同时使用所有其他 10 列作为特征输入到回归器模型中。
我知道用作特征的 10 列既是数字类型又是分类类型，因此我使用 LabelEncoder 进行了一些转换：
df2 = df.copy()
# 姜
le = 标签编码器()
le.fit(df2.gender.drop_duplicates())
df2.gender = le.transform(df2.gender)
...其余分类列如“吸烟者”、“地区”等。

然后我在转换后的数据帧上应用了最小最大缩放器：
inputs = df2[[“年龄”、“性别”、“bmi”、“儿童”、“吸烟者”、“地区”、“医疗历史”、
         “家庭医疗史”、“运动频率”、“职业”]]
目标 = df2[[“coverage_level”, “charges”]]

缩放器 = MinMaxScaler()
scaledInputs = np.array(scaler.fit_transform(输入))

X_train，X_test，y_train，y_test = train_test_split（scaledInputs，目标，test_size = 0.20，random_state = 42）

最后是训练和测试部分：
rf_model = RandomForestRegressor(n_estimators=10, random_state=42)

# 拟合训练集
rf_model.fit(X_train, y_train)
rf_outputs = rf_model.predict(X_test)

rf_mse =mean_squared_error(y_test, rf_outputs)
rf_score = rf_model.score(X_test, y_test)

但是性能非常低，得分为0.27，mse接近2615601。
我尝试了一些修复。第一个不是仅缩放输入，而是在馈送之前缩放了两个目标列 [&#39;coverage_level&#39;,&#39;charges&#39;]，但是，它根本没有帮助。第二个修复是使用one-hot编码代替标签编码，但仍然没有增益。
我该如何调查这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78242202/low-score-when-applying-randomforestregressor-on-a-numeric-categorical-mixed-dat</guid>
      <pubDate>Fri, 29 Mar 2024 05:50:10 GMT</pubDate>
    </item>
    <item>
      <title>中途Discord图片上传问题</title>
      <link>https://stackoverflow.com/questions/75265882/midjourney-discord-image-uploading-problem</link>
      <description><![CDATA[无法仅在单个图像提示中使用 --version 4。
请添加另一个图像提示或文本提示。
/想象 https://media.disc/
尝试在旅途中遇到问题时通过链接上传图像]]></description>
      <guid>https://stackoverflow.com/questions/75265882/midjourney-discord-image-uploading-problem</guid>
      <pubDate>Sat, 28 Jan 2023 06:45:19 GMT</pubDate>
    </item>
    <item>
      <title>如何选择合适的机器学习分类器</title>
      <link>https://stackoverflow.com/questions/3902137/how-to-choose-the-right-machine-learning-classifer</link>
      <description><![CDATA[我在为数据挖掘任务选择正确的分类器时遇到问题。
我使用统计方法来标记网页，并使用 1-4 等级来标记它们，1 是最差的，4 是最好的。
之前，我使用 SVM 来训练系统，因为当时我使用的是二进制 (1,0) 标签。但现在自从我切换到这个4类标签后，我需要更改分类器，因为我认为SVM分类器只能用于二类分类（如果我错了，请纠正我）。
哪种分类器最适合我的分类目的？]]></description>
      <guid>https://stackoverflow.com/questions/3902137/how-to-choose-the-right-machine-learning-classifer</guid>
      <pubDate>Sun, 10 Oct 2010 20:48:51 GMT</pubDate>
    </item>
    </channel>
</rss>