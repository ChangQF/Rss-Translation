<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 09 Apr 2024 03:16:48 GMT</lastBuildDate>
    <item>
      <title>AttributeError：模块“tensorflow.core.framework.types_pb2”没有属性“SerializedDType”</title>
      <link>https://stackoverflow.com/questions/78295612/attributeerror-module-tensorflow-core-framework-types-pb2-has-no-attribute-s</link>
      <description><![CDATA[所以我目前正在使用tensorflow开发一个模型，但是当我运行这行代码时：
导入张量流

我收到此错误：
&lt;块引用&gt;
AttributeError：模块“tensorflow.core.framework.types_pb2”没有属性“SerializedDType”

我使用tensorflow 2.11.0和python 3.10.6。让我知道我的问题需要更多信息，以便我可以更新。
我尝试降级到 tensorflow 2.10.0 但现在，我收到此错误：
&lt;块引用&gt;
导入错误：导入 _pywrap_parallel_device 时 DLL 加载失败：
未找到指定的进程。

如有任何帮助，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78295612/attributeerror-module-tensorflow-core-framework-types-pb2-has-no-attribute-s</guid>
      <pubDate>Tue, 09 Apr 2024 00:39:03 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 mlexperiments 和 mllrnrs 对多变量时间序列 lightgbm 机器学习模型进行交叉验证</title>
      <link>https://stackoverflow.com/questions/78295458/how-to-do-cross-validation-for-multi-variate-time-series-lightgbm-machine-learni</link>
      <description><![CDATA[我尝试使用轻型 GBM 模型来拟合多元时间序列。为了构建模型，我使用 mlexperiments 和 mllrnrs。

使用 timetk 和 Sample 分割时间序列

分割&lt;-生产%&gt;%time_series_split(date_var = newdate,assess=“4个月”,累积= TRUE)
训练 &lt;- rsample::training(splits)%&gt;% select(-newdate)
测试 &lt;- rsample::testing(splits)%&gt;% select(-newdate)


创建时间序列折叠

fold_list&lt;- splitTools::create_timefolds(y = unlist(train_y),k = 5L, use_names = T, type =c (“扩展”))


设置参数和参数网格

#必需的学习者参数，未优化
learner_args &lt;- 列表(
  最大深度=-1L，
  详细 = -1L，
  目标=“回归”，
  公制＝“l2”
）

为mlexperiments::MLCrossValidation 和mlexperiments::MLNestedCV 所需的预测函数和性能指标设置参数
predict_args &lt;- NULL
Performance_metric &lt;- metric(“rmse”)
Performance_metric_args &lt;- NULL
return_models &lt;- TRUE

网格搜索所需
parameter_grid &lt;- Expand.grid(
  bagging_fraction = seq(0.6, 0.8, .2),
  特征分数 = seq(0.6, 0.8, .2),
  min_data_in_leaf = seq(20, 40, 4),
  学习率 = seq(0.1, 0.2, 0.1),
  num_leaves = seq(2, 20, 4))

optim_args &lt;- 列表（
  iters.n = ncores,
  卡帕 = 3.5，
  acq=“ucb”；
）


调整模型

 调谐器 &lt;- mlexperiments::MLTuneParameters$new(
      学习者 = mllrnrs::LearnerLightgbm$new(
        metric_optimization_higher_better = FALSE)，策略 = “网格”，ncores = ncores，seed = 种子)

调谐器$parameter_grid &lt;-parameter_grid
调谐器$learner_args &lt;- learner_args
调谐器$set_data(x = train_x,y = train_y)
tuner_results_grid &lt;-tuner$execute(k = 3)

在此之前我可以完美地运行代码。
但是当我开始进行交叉验证时
验证器 &lt;- mlexperiments::MLNestedCV$new(
   学习者 = mllrnrs::LearnerLightgbm$new(
     metric_optimization_higher_better = FALSE
   ),
   策略=“网格”，
   折叠列表 = 折叠列表,
   k_调整= 3L，
   n 核心 = n 核心，
   种子=种子
 ）
验证器 &lt;- mlexperiments::MLNestedCV$new(
   学习者 = mllrnrs::LearnerLightgbm$new(
     metric_optimization_higher_better = FALSE
   ),
   策略=“网格”，
   折叠列表 = 折叠列表,
   k_调整= 3L，
   n 核心 = n 核心，
   种子=种子
 ）
验证器$parameter_grid &lt;-parameter_grid
验证器$learner_args &lt;- learner_args
validator$split_type &lt;- “分层”
验证器$predict_args &lt;- Predict_args
验证器$performance_metric &lt;- Performance_metric
验证器$performance_metric_args &lt;- Performance_metric_args
验证器$return_models &lt;- return_models
验证器$set_data(
   x = 火车_x,
   y = 火车_y
 ）
validator_results &lt;- validator$execute()

我收到一个错误
CV 折叠：Fold1 kdry::mlh_subset(private$x, train_index) 中的错误：
 `ids` 必须是整数

当我检查验证器环境时，我发现......
我的代码中的以下行
fold_list = Fold_list

不工作。 mlexperiment 和 mllrns 尚未准备好接受时间序列分割输出，每次折叠都有样本内和样本外。
如何解决这个问题。为什么 mlexperiment 和 mllrns 不支持时间序列分割？]]></description>
      <guid>https://stackoverflow.com/questions/78295458/how-to-do-cross-validation-for-multi-variate-time-series-lightgbm-machine-learni</guid>
      <pubDate>Mon, 08 Apr 2024 23:25:34 GMT</pubDate>
    </item>
    <item>
      <title>你能帮我解决这个错误吗[关闭]</title>
      <link>https://stackoverflow.com/questions/78295137/pouvez-vous-maider-%c3%a0-decanter-cette-erreur</link>
      <description><![CDATA[问题是我的 CNN 骨折分类模型的训练步骤没有通过。将显示一条错误消息“
融合卷积实现目前不支持分组卷积。
[[{{节点顺序/conv2d/Relu}}]] [Op:__inference_train_function_8605]”
我正在尝试训练一个用于骨折图像分类的CNN模型，我想以良好的精度和低损失来训练它，但目前没有结果，因为训练步骤给出了错误]]></description>
      <guid>https://stackoverflow.com/questions/78295137/pouvez-vous-maider-%c3%a0-decanter-cette-erreur</guid>
      <pubDate>Mon, 08 Apr 2024 21:32:08 GMT</pubDate>
    </item>
    <item>
      <title>寻求最新的图像分类模型以实现高精度和微调代码</title>
      <link>https://stackoverflow.com/questions/78294759/seeking-latest-image-classification-models-for-high-accuracy-and-fine-tuning-cod</link>
      <description><![CDATA[我目前正在从事一个专注于图像分类的研究项目，特别强调利用机器学习模型的最新进展。我的主要目标是在图像分类任务中实现最高水平的准确性。为了实现这一目标，我正在寻求 2020 年后发布的最新图像分类模型的指导，这些模型与早期模型相比已表现出卓越的准确性。此外，我已将数据集上传到 Google 云端硬盘，并需要帮助使用这些尖端模型微调此数据集，以获得尽可能高的准确度。
在努力解决这个研究问题的过程中，我探索了与图像分类模型相关的各种资源和文档。然而，由于该领域的快速发展，我正在寻求有关最新模型的更新信息和指导，这些模型已显示出显着的准确性改进。我希望找到全面的文档或资源，详细介绍最新模型及其微调程序，以达到最高的准确度水平。然而，到目前为止我所了解到的信息还比较有限，这促使我向社区寻求帮助和见解。]]></description>
      <guid>https://stackoverflow.com/questions/78294759/seeking-latest-image-classification-models-for-high-accuracy-and-fine-tuning-cod</guid>
      <pubDate>Mon, 08 Apr 2024 19:35:40 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络背景下的图信号</title>
      <link>https://stackoverflow.com/questions/78294645/graph-signal-in-the-context-of-graph-neural-network</link>
      <description><![CDATA[我正在阅读有关图神经网络论文的一些有关图信号处理的材料，我发现图信号被定义为向量，因此每个节点信号都是标量。在实践中，节点通常具有向量作为其特征，所以我想知道图形信号如何扩展到这种情况。如果您能在答案中包含参考文献，我将不胜感激。我正在阅读的包含图形信号定义的示例材料之一是 https： //www.seas.upenn.edu/~ese2240/labs/1200_ch_9_signal_processing_on_graphs.pdf]]></description>
      <guid>https://stackoverflow.com/questions/78294645/graph-signal-in-the-context-of-graph-neural-network</guid>
      <pubDate>Mon, 08 Apr 2024 19:02:08 GMT</pubDate>
    </item>
    <item>
      <title>使用 HDF5 可以保存哪些 ML 模型？</title>
      <link>https://stackoverflow.com/questions/78294583/which-ml-models-can-be-saved-using-hdf5</link>
      <description><![CDATA[我已阅读 HDF5 格式 可用于保存机器学习模型。但是，当使用经过训练的 CNNClassifier来自 sktime 的  实例：
导入 h5py
从 sktime.classification.deep_learning.cnn 导入 CNNClassifier
cnn = CNNClassifier(n_epochs=100, batch_size=4) # 它运行 Ne epochs
与 h5py.File(
        “测试.h5”，
        “w”
    ) 作为 f:
    dataset_cnn = f.create_dataset(“cnn”, data=cnn)

但是，我收到以下错误：
回溯（最近一次调用最后一次）：
  文件“”，第 5 行，位于  中。
  文件“/home/tapyu/.cache/pypoetry/virtualenvs/tscnn-PNsUTi5L-py3.10/lib/python3.10/site-packages/h5py/_hl/group.py”，第 183 行，在 create_dataset 中
    dsid = dataset.make_new_dset(组、形状、dtype、数据、名称、**kwds)
  文件“/home/tapyu/.cache/pypoetry/virtualenvs/tscnn-PNsUTi5L-py3.10/lib/python3.10/site-packages/h5py/_hl/dataset.py”，第 86 行，在 make_new_dset 中
    tid = h5t.py_create(dtype, 逻辑=1)
  文件“h5py/h5t.pyx”，第 1658 行，位于 h5py.h5t.py_create 中
  文件“h5py/h5t.pyx”，第 1682 行，位于 h5py.h5t.py_create 中
  文件“h5py/h5t.pyx”，第 1742 行，位于 h5py.h5t.py_create 中
类型错误：对象 dtype dtype(&#39;O&#39;) 没有本机 HDF5 等效项

毕竟，哪些机器学习模型可以使用 HDF5 保存？]]></description>
      <guid>https://stackoverflow.com/questions/78294583/which-ml-models-can-be-saved-using-hdf5</guid>
      <pubDate>Mon, 08 Apr 2024 18:50:35 GMT</pubDate>
    </item>
    <item>
      <title>CNN 教程模型根本拒绝训练</title>
      <link>https://stackoverflow.com/questions/78293057/cnn-tutorial-models-refusing-to-train-at-all</link>
      <description><![CDATA[我遇到的问题涉及在一些众所周知的数据集上创建和使用 CNN 模型。问题始于我的一项家庭作业，我们应该创建一个 CNN 并在 CIFAR10 数据集上运行它。然而这个问题似乎更加严重，我怀疑可能出了什么问题。
我注意到，在运行我自己的模型时，无论我制作什么模型或调整什么超参数，性能都与随机猜测一致。
为了更好地了解什么是好的模型，我在 CIFAR10 和 MNIST 上在线下载了一些教程。教程页面、网站等上的这些模型都报告了不错的准确度，范围在 60-80% 之间。
然而事情就变得奇怪了。当我使用相同的数据预处理等运行这些完全相同的模型（我下载了文件，因此没有复制/粘贴错误）时，我得到了与我自己的模型相同的结果，没有学习发生，准确性保持在 10%。这种行为与我在网上找到的至少四个不同的教程示例是一致的。
我尝试创建一个新的 conda 环境，以便我可以全新安装 tensorflow-gpu，并确保尽可能使用与教程相同的版本，但无论出于何种原因，模型似乎拒绝训练为我。下面是一个最小的可重现示例，我只是从 tensorflow.org 上的 CNN 教程示例和我的结果中复制/粘贴了该示例。
导入tensorflow为tf

从tensorflow.keras导入数据集、图层、模型
将 matplotlib.pyplot 导入为 plt

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# 将像素值标准化为 0 到 1 之间
训练图像，测试图像 = 训练图像 / 255.0，测试图像 / 255.0


模型 = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), 激活=&#39;relu&#39;, input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), 激活=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), 激活=&#39;relu&#39;))


model.add(layers.Flatten())
model.add(layers.Dense(64,activation=&#39;relu&#39;))
model.add(layers.Dense(10))

model.compile(优化器=&#39;亚当&#39;,
          损失=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
          指标=[&#39;准确性&#39;])

历史 = model.fit(train_images, train_labels, epochs=10,
                验证数据=（测试图像，测试标签））

1563/1563 [================================] - 250s 11ms/步 - 损失：2.3027 - 精度：0.0977 - val_loss ：2.3026 - val_accuracy：0.1000
纪元 2/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3028 - 准确度：0.0999 - val_loss ：2.3027 - val_accuracy：0.1000
纪元 3/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3027 - 准确度：0.1011 - val_loss ：2.3027 - val_accuracy：0.1000
纪元 4/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3028 - 精度：0.0993 - val_loss ：2.3027 - val_accuracy：0.1000
纪元 5/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3027 - 准确度：0.0957 - val_loss ：2.3026 - val_accuracy：0.1000
纪元 6/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3028 - 准确度：0.0979 - val_loss ：2.3026 - val_accuracy：0.1000
纪元 7/10
1563/1563 [================================] - 11s 7ms/步 - 损失：2.3027 - 准确度：0.0997 - val_loss ：2.3026 - val_accuracy：0.1000
]]></description>
      <guid>https://stackoverflow.com/questions/78293057/cnn-tutorial-models-refusing-to-train-at-all</guid>
      <pubDate>Mon, 08 Apr 2024 13:58:28 GMT</pubDate>
    </item>
    <item>
      <title>忽略图像分类/分割模型中的某些像素</title>
      <link>https://stackoverflow.com/questions/78292722/ignore-certain-pixels-in-image-classification-segmentation-models</link>
      <description><![CDATA[我有一个由航空照片组成的数据集，想在这些照片上建立图像分割/分类模型。对于标签，我使用包含街道、建筑物等位置信息的矢量数据集，但也有未分类的区域（私人土地）。我不想为这些区域创建“新”类别，但希望模型忽略这些像素并仅根据分类区域进行预测。
在张量流中实现这一点的最佳方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78292722/ignore-certain-pixels-in-image-classification-segmentation-models</guid>
      <pubDate>Mon, 08 Apr 2024 13:02:20 GMT</pubDate>
    </item>
    <item>
      <title>CIFAR10 数据集上的 Tensorflow CNN 模型无法学习</title>
      <link>https://stackoverflow.com/questions/78289990/tensorflow-cnn-model-on-cifar10-dataset-not-learning</link>
      <description><![CDATA[首先，我最近一直在做一项家庭作业，在 CIFAR10 灰度数据集上实现 CNN 模型，以展示其与之前作业中的 FNN 相比的准确性。
但是，这不是我的作业问题，因为我想讨论的训练 CNN 时似乎遇到了更深层次的系统性问题。
值得注意的是，当我运行 CNN 时，似乎无论什么参数、数据集或任何细节都会改变我的模型根本无法学习的事实。
例如，当我在 youtube 上下载与本教程相关的 jupyter 笔记本并自己运行它时，我首先怀疑有更深层次的错误：
Github 链接
对于 FNN，我得到的结果与笔记本/视频中显示的结果完全相同。然而，当我运行 CNN 的单元时，我发现模型没有进行训练，并且损失了 Nan，准确度为 10%，这与随机猜测一致。视频/笔记本说我应该获得 70% 左右的准确度，所以这似乎非常错误。
我下载的另一个教程也发生了这种情况。他们报告在 MNIST 数据集上的准确度为 90%，但是当我运行完全相同的代码时，该模型仅保持在 10% 左右。
如果相关，我可以提供 tf、numpy 等的版本。首先，我使用 GPU 版本的 Tensorflow 在 conda 环境中运行这一切。
下面是我的问题的一个最小示例。我从教程中得到了这个精确的模型、数据处理等，该教程应该给出大约 90% 的准确率，但当我训练模型时，它保持在 10% 左右。
导入tensorflow为tf
将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
将 matplotlib.image 导入为 mpimg
导入迭代工具

打印（tf.__版本__）

cifar10 = tf.keras.datasets.cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

y_train = y_train.flatten()
y_test = y_test.flatten()

输入形状 = (32, 32, 3)

x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)
x_train=x_train / 255.0
x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)
x_test=x_test / 255.0

y_train = tf.one_hot(y_train.astype(np.int32), 深度=10)
y_test = tf.one_hot(y_test.astype(np.int32), 深度=10)

批量大小 = 32
班级数 = 10
纪元 = 50

模型 = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, 3, 填充=&#39;相同&#39;, input_shape=x_train.shape[1:], 激活=&#39;relu&#39;),
    tf.keras.layers.Conv2D(32, 3, 激活=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Dropout(0.25),

    tf.keras.layers.Conv2D(64, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    tf.keras.layers.Conv2D(64, 3, 激活=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.BatchNormalization(),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense（512，激活=&#39;relu&#39;），
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense（num_classes，激活=&#39;sigmoid&#39;），
]）


model.compile（优化器=tf.keras.optimizers.RMSprop（learning_rate=0.0001，衰减=1e-06），
                损失=&#39;categorical_crossentropy&#39;，指标=[&#39;acc&#39;]）

历史 = model.fit(x_train, y_train, batch_size=batch_size,
                    纪元=纪元）
]]></description>
      <guid>https://stackoverflow.com/questions/78289990/tensorflow-cnn-model-on-cifar10-dataset-not-learning</guid>
      <pubDate>Mon, 08 Apr 2024 02:56:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用粒子群优化（PSO）进行特征选择？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78289701/how-using-particle-swarm-optimization-pso-for-features-selection</link>
      <description><![CDATA[拜托，我需要代码 python 来提高预测疾病的准确性，使用 PSO 进行 10,000 条记录的特征（70 个属性）选择，然后使用机器学习算法。
我尝试了很多代码，但没有任何提高准确性的好处。]]></description>
      <guid>https://stackoverflow.com/questions/78289701/how-using-particle-swarm-optimization-pso-for-features-selection</guid>
      <pubDate>Mon, 08 Apr 2024 00:07:19 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 pycaret 获得第二最佳模型参数？</title>
      <link>https://stackoverflow.com/questions/78285377/how-to-get-the-second-best-model-parameter-using-pycaret</link>
      <description><![CDATA[这是我在 google collab 上的代码
# 导入库
从 pycaret.classification 导入 *


exp_clf = 设置（数据，目标=&#39;目标&#39;，规范化=True）


最佳模型 = 比较模型()

这就是结果

此代码将显示最佳模型参数
显示(best_model)

这就是结果

我想知道其他模型参数而不是最佳模型（光梯度增强机），因为 AUC 对我来说不够高。如何显示随机森林分类器的参数？
我尝试了这个，希望它能向我显示第二最佳模型（随机森林）的参数
 显示(best_model[1])

这就是结果
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-20-63c1d322b8ae&gt;在&lt;细胞系：1&gt;()
----&gt; 1 个显示器（best_model[1]）

类型错误：“LGBMClassifier”对象不可下标
]]></description>
      <guid>https://stackoverflow.com/questions/78285377/how-to-get-the-second-best-model-parameter-using-pycaret</guid>
      <pubDate>Sat, 06 Apr 2024 17:53:04 GMT</pubDate>
    </item>
    <item>
      <title>py_call_impl 中的错误（可调用，call_args$未命名，call_args$命名）</title>
      <link>https://stackoverflow.com/questions/78283892/error-in-py-call-implcallable-call-argsunnamed-call-argsnamed</link>
      <description><![CDATA[我正在尝试在 R 中构建 CNN 模型来对三种类型的图像进行分类。 R 中的库似乎创建了一个 Python 虚拟环境并调用它来执行一些张量流任务。我的 R 代码是
库（keras）
库（EBImage）
库（字符串）
库（pb应用）
# 设置图像大小
宽度 &lt;- 50
高度 &lt;- 50

extract_feature &lt;- 函数(dir_path, 宽度, 高度, labelsExist = T) {
  img_size &lt;- 宽度 * 高度
  
  # 列出路径中的图像
  images_names &lt;- list.files(dir_path)
  
  如果（标签存在）{
    # 从文件名中提取类标签
    class_labels &lt;- unique(basename(images_names) %&gt;% str_extract(&quot;^[^_]+&quot;))
    
    # 创建关键向量
    key &lt;- setNames(as.integer(seq_along(class_labels)), class_labels)
    
    # 设置标签
    y &lt;- key[basename(images_names) %&gt;% str_extract(&quot;^[^_]+&quot;)]
  }
  
  print(paste(“开始处理”, length(images_names), “图像”))
  
  # 处理图像
  feature_list &lt;- pblapply(images_names, function(imgname) {
    img &lt;- readImage(file.path(dir_path, imgname))
    img_resized &lt;- 调整大小(img, w = 宽度, h = 高度)
    greyimg &lt;- 通道(img_resized, “灰色”)
    img_matrix &lt;-grayimg@.Data
    img_vector &lt;- as.vector(t(img_matrix))
    返回（img_向量）
  })
  
  feature_matrix &lt;- do.call(rbind, feature_list)
  feature_matrix &lt;- as.data.frame(feature_matrix)
  名称（feature_matrix）&lt;-paste0（“像素”，c（1：img_size））
  
  如果（标签存在）{
    返回（列表（X =特征矩阵，y = y））
  } 别的 {
    返回（特征矩阵）
  }
}

# 准备数据
#train_data &lt;- extract_feature(“C:/Users/aryaj/OneDrive/Desktop/project 6/data/Training/train/”，宽度，高度)
#write.csv(train_data,&#39;C:/Users/aryaj/OneDrive/Desktop/project 6/data/train_data.csv&#39;)
train_data &lt;- read.csv(&#39;C:/Users/aryaj/OneDrive/Desktop/project 6/data/train_data.csv&#39;)
X_train &lt;- train_data$X
# 将标签转换为one-hot编码
unique_labels &lt;- unique(train_data$y)
y_train &lt;- sapply(train_data$y, 函数(x) {
  label_vector &lt;-rep(0, length(unique_labels))
  label_vector[which(unique_labels == x)] &lt;- 1
  返回（标签向量）
})
y_train &lt;- t(y_train)

#test_data &lt;- extract_feature(“C:/Users/aryaj/OneDrive/Desktop/project 6/data/Testing/test/”, 宽度, 高度, labelsExist = F)
#write.csv(test_data,&#39;C:/Users/aryaj/OneDrive/Desktop/project 6/data/test_data.csv&#39;)
test_data &lt;- read.csv(&#39;C:/Users/aryaj/OneDrive/Desktop/project 6/data/test_data.csv&#39;)
X_test &lt;- test_data

# 定义模型
模型 &lt;- keras_model_sequential()
型号%&gt;%
  Layer_dropout(率 = 0.25) %&gt;%
  层_展平（）％&gt;％
  Layer_dense(单位= 50，激活=“relu”)%&gt;%
  Layer_dropout(率 = 0.25) %&gt;%
  Layer_dense（单位=长度（unique_labels），激活=“softmax”）

摘要（模型）

# 编译模型
模型%&gt;%编译(
  损失=&#39;分类交叉熵&#39;，
  优化器=优化器_adam(),
  指标 = c(&#39;准确度&#39;)
）

# 训练模型
历史 &lt;- 模型 %&gt;% 拟合(
  x = X_train，
  y = y_train，
  历元 = 20,
  批量大小 = 100,
  验证数据=列表（X_测试，y_测试）
）

# 评估模型
分数 &lt;- 模型 %&gt;% 评估(X_test, y_test)
print(paste(“测试损失：”, Score[1]))
print(paste(“测试准确度：”, Score[2]))

# 绘制训练历史
情节（历史）

我收到的错误是这样的
&lt;前&gt;&lt;代码&gt;&gt;型号%&gt;%
+ Layer_dropout(率 = 0.25) %&gt;%
+ Layer_flatten() %&gt;%
+ Layer_dense(单位= 50，激活=“relu”) %&gt;%
+ Layer_dropout(率 = 0.25) %&gt;%
+ Layer_dense（单位=长度（unique_labels），激活=“softmax”）
2024-04-06 14:59:23.781982：I tensorflow/core/platform/cpu_feature_guard.cc:210] 此 TensorFlow 二进制文件经过优化，可以在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：AVX2 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
py_call_impl(callable, call_args$unnamed, call_args$named) 中的错误：
  ValueError：只有输入张量可以作为位置参数传递。以下参数值应作为关键字参数传递： （类型）
运行 `reticulate::py_last_error()` 了解详细信息。

我尝试按如下方式更改模型构建步骤
模型 &lt;- keras_model_sequential() %&gt;%
  Layer_dropout(率 = 0.25) %&gt;%
  层_展平（）％&gt;％
  Layer_dense(单位= 50，激活=“relu”)%&gt;%
  Layer_dropout(率 = 0.25) %&gt;%
  Layer_dense（单位=长度（unique_labels），激活=“softmax”）

但即使这个也一直给出同样的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78283892/error-in-py-call-implcallable-call-argsunnamed-call-argsnamed</guid>
      <pubDate>Sat, 06 Apr 2024 09:49:16 GMT</pubDate>
    </item>
    <item>
      <title>神经先知根本不预测？</title>
      <link>https://stackoverflow.com/questions/77231544/neural-prophet-not-predicting-at-all</link>
      <description><![CDATA[我正在尝试预测进入某个海滩的顾客数量。因此，数据中的数字往往会波动，并且希望使用 Neural Prophet 来预测未来的客人。然而，根据我的神经预言模型的当前设置，该模型根本无法预测原始数据中的最终日期，即使对于其他参数它确实预测，只是不准确。
以下是预测结果（虚线）与原始结果（实线）的对比：
在此处输入图片描述
我特意要求预测未来 100 天，但根本没有显示。
这是我的模型设置：
 模型 = NeuralProphet(
        #growth=“off”, # 确定趋势类型：&#39;线性&#39;、&#39;不连续&#39;、&#39;关闭&#39;
        #changepoints=None, #可能包含变更点的日期列表（None -&gt;automatic ）
        n_changepoints=0,
        #changepoints_range=0,
        #trend_reg=0,
        # trend_reg_threshold=False,
        # #seasonality_reg=1,
        # # d_hidden = 0,
        n_lags=10,
        # # num_hidden_​​layers=0, # AR-Net 隐藏层的维度
        # # ar_reg=None, # AR 系数的稀疏性
        学习率=0.01，
        纪元=100，
        Normalize=“auto”, # 标准化类型 (&#39;minmax&#39;, &#39;standardize&#39;, &#39;soft&#39;, &#39;off&#39;)
        impute_missing=真，
        yearly_seasonality=真，
        week_seasonality=假，
        daily_seasonality=假，
        季节性_模式=“乘法”，
        loss_func=“均方误差”,
    ）

    # 将模型与训练数据进行拟合
    model.fit(数据,频率=“D”)
    未来= model.make_future_dataframe（数据，周期= 1000，n_historic_predictions = len（数据））
    预测 = model.predict(future)
]]></description>
      <guid>https://stackoverflow.com/questions/77231544/neural-prophet-not-predicting-at-all</guid>
      <pubDate>Wed, 04 Oct 2023 16:52:25 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 中使用有状态 LSTM 训练多变量多级数回归问题</title>
      <link>https://stackoverflow.com/questions/55811017/training-a-multi-variate-multi-series-regression-problem-with-stateful-lstms-in</link>
      <description><![CDATA[我有 P 过程的时间序列，每个过程的长度不同，但都有 5 个变量（维度）。我试图预测测试过程的估计寿命。我正在用 Keras 中的有状态 LSTM 来解决这个问题。但我不确定我的训练过程是否正确。
我将每个序列分成长度30的批次。因此，每个序列的形状为 (s_i, 30, 5)，其中 s_i 对于每个 P 序列都是不同的 ( s_i = len(P_i)//30).我将所有序列附加到形状为 (N, 30, 5) 的训练数据中，其中 N = s_1 + s_2 + ... + s_p。
型号：
# 设计网络
模型=顺序（）
model.add(LSTM(32，batch_input_shape=(1，train_X[0].shape[1]，train_X[0].shape[2])，stateful=True，return_sequences=True))
model.add(LSTM(16, return_sequences=False))
model.add（密集（1，激活=“线性”））
model.compile(loss=&#39;mse&#39;, 优化器=Adam(lr=0.0005), 指标=[&#39;mse&#39;])

model.summary() 看起来像
&lt;前&gt;&lt;代码&gt;_________________________________________________________________
层（类型）输出形状参数#
=================================================== ===============
lstm_1 (LSTM) (1, 30, 32) 4864
_________________________________________________________________
lstm_2 (LSTM) (1, 16) 3136
_________________________________________________________________
密集_1（密集） (1, 1) 17
=================================================== ===============

训练循环：
对于范围内的纪元（纪元）：
    平均值_tr_acc = []
    平均值_tr_损失 = []
        
    对于范围内的 seq(train_X.shape[0]): #24
            
        # 逐批训练整个序列
        对于范围内的批次（train_X[seq].shape[0]）：#68
            b_loss, b_acc = model.train_on_batch(np.expand_dims(train_X[seq][batch], axis=0), train_Y[seq][batch][-1])
                
            Mean_tr_acc.append(b_acc)
            mean_tr_loss.append(b_loss)
                
        #在每个完整序列训练后重置lstm内部状态
        model.reset_states()

编辑：
损失图的问题是我将自定义损失中的值除以，使它们太小。如果我删除除法并以对数方式绘制损失图，看起来不错。
新问题：
训练完成后，我会尝试进行预测。我向我的模型展示了新流程的 30 个时间样本；因此输入形状与训练期间的 batch_input_shape 相同，即 (1, 30, 5)。我对同一序列的不同批次得到的预测都是相同的。
我认为我在训练过程中做错了什么。
编辑2：
因此，只有训练超过 20 个 epoch 的模型才能预测完全相同的结果。否则，预测值非常接近，但仍然有点不同。我猜这是由于某种过度拟合造成的。
25 个时期的损失如下所示：
]]></description>
      <guid>https://stackoverflow.com/questions/55811017/training-a-multi-variate-multi-series-regression-problem-with-stateful-lstms-in</guid>
      <pubDate>Tue, 23 Apr 2019 12:14:30 GMT</pubDate>
    </item>
    <item>
      <title>from torch._C import * ImportError: DLL 加载失败: 找不到指定的模块</title>
      <link>https://stackoverflow.com/questions/50612899/from-torch-c-import-importerror-dll-load-failed-the-specified-module-could</link>
      <description><![CDATA[我正在尝试使用 python 3.5 在我的 Windows 机器中导入 torch。 （仅限 CPU）（点）
我已按照官方网站中给出的步骤进行操作。 
当我尝试导入 torch 时，出现错误：
from torch._C import *
ImportError: DLL 加载失败: 找不到指定的模块。

我查找了 from torch._C import * (ImportError: DLL load failed: 指定的模块找不到。和ModuleNotFoundError：没有名为“torch._C”的模块 并按照他们的指示进行操作，但错误仍然存​​在。
总回溯：
回溯（最近一次调用最后一次）：
文件“D:\CFPS.py”，第 1 行，位于  中
进口火炬
文件“C:\Program Files (x86)\Python35\lib\site-packages\torch\__init__.py”，
第 78 行，在  中
从火炬._C 导入 *
ImportError: DLL 加载失败: 找不到指定的模块。
【0.6秒完成】

有办法解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/50612899/from-torch-c-import-importerror-dll-load-failed-the-specified-module-could</guid>
      <pubDate>Wed, 30 May 2018 20:29:34 GMT</pubDate>
    </item>
    </channel>
</rss>