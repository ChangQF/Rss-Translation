<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 10 Mar 2024 21:11:18 GMT</lastBuildDate>
    <item>
      <title>反转函数以获得原始输入值</title>
      <link>https://stackoverflow.com/questions/78137497/reverse-function-to-obtain-original-input-values</link>
      <description><![CDATA[我有以下 get_angles 函数，可以从 input_features 创建角度。该函数返回的特征用于训练变分量子电路。
def get_angles(x):
    beta0 = 2 * np.arcsin(np.sqrt(x[1] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))
    beta1 = 2 * np.arcsin(np.sqrt(x[2] ** 2) / np.sqrt(x[2] ** 2 + x[2] ** 2 + 1e-12))
    beta2 = 2 * np.arcsin(np.linalg.norm(x[2:]) / np.linalg.norm(x))
    
    返回 np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])

因此：
input_features = [10, 20, 30, 40, 50]`

# 变换特征
特征 = np.array(get_angles(input_features))


现在，我想通过获取最终的 features 值并将其转换回 get_angles 中使用的 input_features 值来反转此操作&gt; 功能。有没有办法反转上面定义的 get_angles 函数？
提前致谢。
期望通过 get_reverse_angles 函数运行最终的 features 来接收 input_features，我尝试了 get_reverse_angles&lt; 的多种变体/code&gt; 如下所示的功能无效。
def get_reverse_angles(角度):
    # 提取角度
    beta2、neg_beta1、pos_beta1、neg_beta0、pos_beta0 = 角度
    
    # 使用三角方程求解 x
    x0 = np.sqrt(2)
    x1 = np.sin(beta2 / 2) * np.sqrt(2)
    x2 = np.sin(pos_beta1 / 2) * np.sqrt(2)
    x3 = np.sin(pos_beta0 / 2) * np.sqrt(2)
    x4 = np.sin(neg_beta0 / 2) * np.sqrt(2)
    
    # 使用第一个方程计算 x0
    x0 = np.sqrt(x1 ** 2 + x2 ** 2 + x3 ** 2 + x4 ** 2)
    
    # 返回相反操作的值
    返回 np.array([x0, x1 * x0, x2 * x0, x3 * x0, x4 * x0])

get_reverse_angles 函数返回 [ 1.79350156 2.41835701 0.97063605 1.33346136 -1.33346136]，而不是预期的 [10 20 30 40 50] input_features。]]></description>
      <guid>https://stackoverflow.com/questions/78137497/reverse-function-to-obtain-original-input-values</guid>
      <pubDate>Sun, 10 Mar 2024 21:09:43 GMT</pubDate>
    </item>
    <item>
      <title>每次运行时都会出现不同的 ValueError</title>
      <link>https://stackoverflow.com/questions/78137114/different-valueerror-each-time-i-run</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78137114/different-valueerror-each-time-i-run</guid>
      <pubDate>Sun, 10 Mar 2024 18:55:17 GMT</pubDate>
    </item>
    <item>
      <title>多值多目标分类</title>
      <link>https://stackoverflow.com/questions/78136790/multi-value-and-multi-target-classification</link>
      <description><![CDATA[首先，我想检查一下我对类、多类、多值和多目标的理解：
类别
如果我有3个属性（温度、天气和湿度），并且我正在预测天气条件是否有利于玩耍，并且Play是二元的（是、否），这是一个简单的分类，例如：

&lt;标题&gt;

温度
天气
湿度
播放


&lt;正文&gt;

...
...
...
是/否



多类别
类似的情况，但 Play 不是一个枚举列表，包含（互斥的）游戏方式。这将是一个“多类”分类：

&lt;标题&gt;

温度
天气
湿度
播放


&lt;正文&gt;

...
...
...
秋千踢球标签



多值
如果存在多个非互斥的结果，例如每种游戏方式都有其自己的属性，并且每个属性都是二元的（是/否），则这是“多值”：

&lt;标题&gt;

温度
天气
湿度
秋千
踢球
标签


&lt;正文&gt;

...
...
...
是/否
是/否
是/否



多目标
最后一个示例，如果每个可能的结果可能包含非二进制、互斥的值，则这将是多目标：

&lt;标题&gt;

温度
天气
湿度
雪
骑自行车
正在运行


&lt;正文&gt;

...
...
...
滑雪滑雪雪地摩托
山路碎石
跑步机步道跑道



这是正确的吗？
我正在使用 Weka 来预测多目标结果。我希望使用“多目标”分类器的版本(meka.classifiers.multitarget.CC)，但这些结果始终只是“1” （使用“double[][] Predictions = result.allPredictions();”）
|==== 预测 (N=3.0) =====&gt;
| 1 [ -1 -1 -1 -1 ] [ 1.000 1.000 1.000 ]
| 2 [ -1 -1 -1 -1 ] [ 1.000 1.000 1.000 ]
| 3 [ -1 -1 -1 -1 ] [ 1.000 1.000 1.000 ]
|================================&lt;
如果我使用“多标签”分类器（meka.classifiers.multilabel.CC）然后它给我我认为正确的结果，这些值是值列表中的正确索引：
|==== 预测 (N=3.0) =====&gt;
| 1 [ -1 -1 -1 -1 ] [ 2.000 1.000 0.000 ]
| 2 [ -1 -1 -1 -1 ] [ 0.000 1.000 2.000 ]
| 3 [ -1 -1 -1 -1 ] [ 1.000 0.000 2.000 ]
|================================&lt;
我当然可以使用多标签分类器，但它看起来并不是正确的使用方法。
我不明白什么？
我期待多目标能够给我多标签所提供的东西。]]></description>
      <guid>https://stackoverflow.com/questions/78136790/multi-value-and-multi-target-classification</guid>
      <pubDate>Sun, 10 Mar 2024 17:23:21 GMT</pubDate>
    </item>
    <item>
      <title>当第 33 次迭代从头开始训练线性回归时，MSE 始终变为 0</title>
      <link>https://stackoverflow.com/questions/78136597/mse-always-becomes-0-when-training-linear-regression-from-scratch-at-33th-iterat</link>
      <description><![CDATA[我正在尝试在 Kaggle 上的 Spotify 2023 数据集上从头开始训练多线性回归模型。
def min_max_scalar(df, col):
df[col] = (df[col] - min(df[col])) / (max(df[col]) - min(df[col]))
返回 df[列]

defmean_squared_error（实际，预测）：
返回 np.mean((实际 - 预测) ** 2)

Spotify_2023_data[&#39;streams&#39;] = min_max_scalar(spotify_2023_data, &#39;streams&#39;)

X = spotify_2023_data[[&#39;in_spotify_playlists&#39;, &#39;in_apple_playlists&#39;]]
Y = spotify_2023_data[&#39;流&#39;]
X[&#39;ones&#39;] = np.ones(len(X),) #进行拦截

阈值 = 1e-6
步长大小 = 5e-9
theta, theta_prev = np.array(np.repeat(5,3)), np.ones(3,) #随机权重

迭代= 0
训练错误 = []
测试错误 = []
训练大小 = np.arange(1,len(Y)+1)
训练迭代= []
#TODO：33 次，算法失控
for i in Training_size: #意味着通过改变训练数据的数量来显示偏差-方差权衡
    如果 i % 2 == 0: 继续
    X_train = X.iloc[:i]
    y_train = Y.iloc[:i]
    X_test = X.iloc[i:]
    y_test = Y.iloc[i:]

    而 np.linalg.norm(theta - theta_prev) &gt;阈值：课本中使用的#threshold机制来确定何时停止。不幸的是，我必须使用这个。
        θ_prev = θ
        梯度 = mse_gradient(theta, X_train, y_train)
        theta = theta_prev - step_size * 梯度
        if (np.isnan(theta)): 打印(theta)
        迭代 += 1

    print(&quot;i={}, results={}, mse={}&quot;.format(i, f(X_test, theta),mean_squared_error(y_test, f(X_test, theta))))
    print(&quot;theta={}&quot;.format(theta))
    打印（“iter =”，iter）
    迭代= 0
    Training_error.append(mean_squared_error(y_train, f(X_train, theta)))
    test_error.append(mean_squared_error(y_test, f(X_test, theta)))
    训练迭代.append(i)
        
    theta, theta_prev = np.array(np.repeat(5,3)), np.ones(3,)

无论我使用什么 i 值，它似乎总是在第 33 次迭代时产生 NaN 值。我检查过，这可能是因为 theta 此时跳到无穷大。我检查了使用的数据，似乎没有任何丢失的数据。我应该做什么才能让培训继续进行？]]></description>
      <guid>https://stackoverflow.com/questions/78136597/mse-always-becomes-0-when-training-linear-regression-from-scratch-at-33th-iterat</guid>
      <pubDate>Sun, 10 Mar 2024 16:19:49 GMT</pubDate>
    </item>
    <item>
      <title>寻求推进 SketchCode 项目的指导 - YOLOV8 培训已完成 [关闭]</title>
      <link>https://stackoverflow.com/questions/78136580/seeking-guidance-for-advancing-sketchcode-project-yolov8-training-completed</link>
      <description><![CDATA[我一直在致力于一个名为 SketchCode 的令人兴奋的项目，旨在利用深度学习将手绘网站模型转换为功能性 HTML/CSS 代码。我在手绘草图的自定义数据集上成功训练了 YOLOV8 模型，该项目达到了一个里程碑。
这是该项目的非常简化的细分：
图像理解：模型分析手绘草图，识别各个 UI 组件。
序列生成：HTML 代码生成被视为语言翻译任务。该模型将视觉元素转换为相应的 HTML 代码片段。
技术细分：
数据集：我使用了此处提供的手绘草图数据集。
YOLOV8 训练：我使用 Ultralytics 库对 YOLOV8 模型进行了 10 个 epoch 的训练。（使用 GPU 而不是 CPU，并对其进行了 50 个 epoch 的训练）
但是，我目前陷入困境并寻求有关后续步骤的指导。训练输出看起来很有希望，但我不知道接下来该何去何从。
如果您能提供有关我接下来应该关注的重点的见解、建议或建议，我将不胜感激。无论是改进模型、改进数据集还是整合其他技术，您的专业知识都是无价的。
我尝试在 SketchCode 项目的手绘草图数据集上训练 YOLOV8 模型。我希望模型能够学习并准确检测草图中的各种组件，例如按钮、文本框、标题等。完成 10 个 epoch 的训练后，输出结果显示出良好的结果，不同类别的 mAP 分数都不错。]]></description>
      <guid>https://stackoverflow.com/questions/78136580/seeking-guidance-for-advancing-sketchcode-project-yolov8-training-completed</guid>
      <pubDate>Sun, 10 Mar 2024 16:14:16 GMT</pubDate>
    </item>
    <item>
      <title>是否可以对随机森林回归的某些特征进行加权？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78136531/is-it-possible-to-weight-some-features-for-a-random-forest-regression</link>
      <description><![CDATA[我一直在尝试训练一个随机森林模型，该模型根据到其他点的距离以及这些点的气候和地理数据等特征来预测点的特征。问题出现在结果上，它们并不糟糕，但还有改进的余地。该模型预测最重要的特征是点之间的距离，但我们认为它应该更加重视气候数据特征，而不太重视距离。
有没有办法让模型降低距离的重要性？也许给它们加权？或者问题可能出在我们为模型提供的数据上？
我尝试过多种模型，如 Lasso、Gradient Boosting 和 Random Forest。还尝试了不同类型的交叉验证。最好的结果来自具有交叉验证的随机森林，以避免某些空间自相关。尽管如此，该模型预计会比现在更好。我们怀疑它非常重视点之间的距离，但我们不知道如何改变这一点并获得更好的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78136531/is-it-possible-to-weight-some-features-for-a-random-forest-regression</guid>
      <pubDate>Sun, 10 Mar 2024 15:58:48 GMT</pubDate>
    </item>
    <item>
      <title>人脸识别中如何处理规格眩光？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78134869/how-to-handle-specs-glare-in-face-recognition</link>
      <description><![CDATA[我想构建一个基于 python Flask api 的应用程序，我想发送 2 个人物图像（脸部图像）的路径（url 或本地图像），并且如果两张脸都匹配（两张图片都属于），我希望得到“是”的响应同一个人），如果图像是不同的人，则不会。我为此使用了face_recognition 库。在我介绍戴眼镜的人的照片之前，这个算法一直运行良好。该模型无法识别眼镜中是否有眩光。如何进行？有没有一种预处理方法可以提供帮助？或者我应该搬到另一个图书馆？
导入face_recognition
导入CV2
将 numpy 导入为 np
从日期时间导入日期时间
从烧瓶导入烧瓶，请求，jsonify
导入人脸识别
导入请求
从 io 导入 BytesIO
从日期时间导入日期时间
从 PIL 导入图像
应用程序=烧瓶（__名称__）

def preprocess_image(image_path,resize_height=400):
    if image_path.startswith((&#39;http://&#39;, &#39;https://&#39;)):
            响应 = requests.get(图像路径)
            图像 = Image.open(BytesIO(响应.内容))
    别的：
        图像 = Image.open(图像路径)
    exif_data = image.getexif()

    如果 exif_数据：
        如果 exif_data.get(274) == 6:
            图像 = 图像.旋转(270)
    宽度，长度=图像大小
    比例 = resize_height / 长度
    new_width = int(宽度 * 比例)
    打印（图像路径，图像大小，比例，新宽度）
    
    new_width = int(宽度 * 比例)
    resized_image = image.resize((new_width, resize_height))

    rgb_image = resized_image.convert(“RGB”)
    numpy_image = np.array(rgb_image)

    返回numpy_image


@app.route(&#39;/&#39;,methods = [&#39;GET&#39;,&#39;POST&#39;])
def home():
    返回“服务器正在运行”
@app.route(&#39;/compare&#39;,methods = [&#39;GET&#39;,&#39;POST&#39;])
defface_compare():
    st = 日期时间.now()
    数据 = request.get_json()
    image_path1 = 数据[&#39;img1&#39;]
    image_path2 = 数据[&#39;img2&#39;]

    已处理图像1 = 预处理图像(图像路径1)
    已处理图像2 = 预处理图像(图像路径2)
    
    面部位置1 = 面部识别.面部位置（处理后的图像1）
    面部位置2 = 面部识别.面部位置(processed_image2)
    #show_bounding_box(face_locations1,processed_image1)
    #show_bounding_box(face_locations2,processed_image2)
    如果不是face_locations1：
        return jsonify({&#39;result&#39;: &#39;未找到面 1&#39;, &#39;time&#39;:str(datetime.now()-st)})
    如果不是face_locations2：
        return jsonify({&#39;result&#39;: &#39;未找到人脸 2&#39;, &#39;time&#39;:str(datetime.now()-st)})

    face_encoding1=face_recognition.face_encodings(processed_image1,known_face_locations=face_locations1,model=&#39;小&#39;)[0]
    face_encoding2=face_recognition.face_encodings(processed_image2,known_face_locations=face_locations2,model=&#39;小&#39;)[0]
    
    结果=face_recognition.compare_faces([face_encoding1],face_encoding2,公差=0.47)
    return jsonify({&#39;结果&#39;: str(结果[0]), &#39;时间&#39;:str(datetime.now()-st)})

def show_bounding_box(face_loc, img):
    边界框 = []
    对于face_loc中的face_location：
        上、右、下、左 = 面部位置
        bounding_boxes.append((左、上、右、下))
    对于bounding_boxes中的（左，上，右，下）：
        cv2.矩形(img, (左, 上), (右, 下), (0, 255, 0), 2)
    cv2.imshow(“带有边界框的面孔”, img)
    cv2.waitKey(0)

如果 __name__ == &#39;__main__&#39;:
    app.run（调试=True，线程=True）
]]></description>
      <guid>https://stackoverflow.com/questions/78134869/how-to-handle-specs-glare-in-face-recognition</guid>
      <pubDate>Sun, 10 Mar 2024 06:01:06 GMT</pubDate>
    </item>
    <item>
      <title>如何访问CoNull 2003和OntoNotes数据集？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78134821/how-to-access-the-conull-2003-and-ontonotes-datasets</link>
      <description><![CDATA[我发现了某些遗留数据集，例如 CoNull 2003 和 OntoNotes。我如何访问这些数据集并在我的项目中使用它们？他们各自的网站显示了很多我不知道的信息。请帮忙
我正在尝试启动该项目。需要建议]]></description>
      <guid>https://stackoverflow.com/questions/78134821/how-to-access-the-conull-2003-and-ontonotes-datasets</guid>
      <pubDate>Sun, 10 Mar 2024 05:34:51 GMT</pubDate>
    </item>
    <item>
      <title>尝试将标签设置为张量时出现值错误</title>
      <link>https://stackoverflow.com/questions/78134521/value-error-when-trying-to-make-labels-to-tensor</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78134521/value-error-when-trying-to-make-labels-to-tensor</guid>
      <pubDate>Sun, 10 Mar 2024 02:21:05 GMT</pubDate>
    </item>
    <item>
      <title>如何以高精度（+ 90%）对面部特征嵌入进行分类。我可以在 svm 模型中进行哪些调整来对 20 多个类别进行分类</title>
      <link>https://stackoverflow.com/questions/78133540/how-to-classify-facials-features-embedding-with-high-accuracy-90-what-adjus</link>
      <description><![CDATA[我使用facenet提取特征并使用svm进行分类。效果很好，但 20 堂课后，准确率下降到 75%。如何在利用 GPU 的同时优化 svm。
我使用了这个 svm 类模型
scikit learn 的 svm 模型不使用 GPU，所以我使用了这个
类 SVM(nn.Module):
    def __init__(自身):
        超级（SVM，自我）.__init__()
        self.fc = nn.Linear(X.shape[1], len(ClassList))

    def 前向（自身，x）：
        返回 self.fc(x)

但是对于 20 多个类别来说，这个准确率非常低
我也尝试过使用这个：
类 SoftmaxUsed(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.layers = nn.Sequential(nn.Linear(512, 1024),
                                 ReLU(),
                                 nn.Dropout(0.2),
                                 nn.线性(1024, 1024),
                                 ReLU(),
                                 nn.Dropout(0.2),
                                 nn.Linear(1024, len(ClassList)),
                                 nn.LogSoftmax(dim=1))
    def 前向（自身，x）：
        返回 self.layers(x)

但准确率最高仍为 86%]]></description>
      <guid>https://stackoverflow.com/questions/78133540/how-to-classify-facials-features-embedding-with-high-accuracy-90-what-adjus</guid>
      <pubDate>Sat, 09 Mar 2024 18:56:09 GMT</pubDate>
    </item>
    <item>
      <title>RMSE 值也很低，但验证损失图在我的 LSTM 模型中有很多尖峰。我怎样才能解决这个问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78132521/rmse-values-is-also-low-but-validation-loss-graph-has-alot-of-spikes-in-my-lstm</link>
      <description><![CDATA[我创建了一个用于时间序列预测的 LSTM 模型。我的价值观如下，
测试集的 RMSE 分数：1.55

我的验证损失图中有很多峰值，如下所示。如何减少峰值并修复此图表？

我的代码如下，
从 keras.models 导入顺序

def lstm_model(trainX,trainY):
  #创建堆叠的 LSTM 模型
  模型=顺序（）
  model.add(LSTM(64,activation=&#39;relu&#39;,input_shape=(trainX.shape[1],trainX.shape[2]),return_sequences=False))
  模型.add(Dropout(0.2))
  model.add(密集(1))
  # 编译模型
  model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)

  print(&quot;LSTM 模型摘要&quot;)
  打印（模型.摘要（））
  打印(“---------------------------------------------- ----------”）

  # 拟合模型
  历史= model.fit（trainX，trainY，epochs = 200，batch_size = 8，validation_split = 0.01，verbose = 1）
  打印（历史）
  打印(“---------------------------------------------- ----------”）

  #model.save(&#39;/content/gdrive/MyDrive/MScProject/Implementation/lstm.h5&#39;)
  位置 = &#39;/content/gdrive/MyDrive/MScProject/Implementation/&#39; + 银行名称 + &#39;/lstm.h5&#39;
  模型.保存（位置）

  rmse = evaluate_models(历史, 模型)
  返回均方根误差

rmse = lstm_model(trainX,trainY)
模型测试（rmse）
]]></description>
      <guid>https://stackoverflow.com/questions/78132521/rmse-values-is-also-low-but-validation-loss-graph-has-alot-of-spikes-in-my-lstm</guid>
      <pubDate>Sat, 09 Mar 2024 13:36:46 GMT</pubDate>
    </item>
    <item>
      <title>邻居索引错误：self._check_indexing_error(key) KeyError：8</title>
      <link>https://stackoverflow.com/questions/78101850/neighbors-indexing-error-self-check-indexing-errorkey-keyerror-8</link>
      <description><![CDATA[我正在创建一个服装推荐系统，使用 NearestNeighbors，数据来自 2 个数据集，其中一个数据集包含 ratings.csv，在本例中 0 和 1&lt; /code&gt; 基于是否保存到愿望清单以及所有衣服的衣服.csv，我想传递服装的 ID 并获取推荐商品的列表，但我收到索引错误。
这是代码：
user_ ratings_df = pd.read_csv(“ ratings.csv”)

user_ ratings_df[&#39;IDGARMENT&#39;] = user_ ratings_df[&#39;IDGARMENT&#39;].astype(int)

# 读入数据；使用默认的 pd.RangeIndex，即 0、1、2 等作为列
Clothes_desc = pd.read_csv(“clothes.csv”, on_bad_lines=&#39;skip&#39;)
Clothing_metadata = Clothing_desc[[&#39;IDGARMENT&#39;, &#39;描述&#39;, &#39;类别&#39;, &#39;品牌&#39;, &#39;价格&#39;]]

衣服元数据[&#39;IDGARMENT&#39;] = 衣服元数据[&#39;IDGARMENT&#39;].astype(int)
Clothes_data = user_ ratings_df.merge(clothes_metadata, on=&#39;IDGARMENT&#39;)

user_item_matrix = user_ ratings_df.pivot(index=[&#39;USERID&#39;], columns=[&#39;IDGARMENT&#39;], value=&#39;RATING&#39;).fillna(0)
用户项矩阵

# 定义一个关于余弦相似度的 KNN 模型
cf_knn_model=NearestNeighbors(metric=&#39;cosine&#39;,algorithm=&#39;brute&#39;,n_neighbors=10,n_jobs=-1)
#lr.fit(x.reshape(-1, 1), y)

# 将模型拟合到我们的矩阵上
cf_knn_model.fit(user_item_matrix)


def dress_recommender_engine(garment_id, 矩阵, cf_model, n_recs):
    # 在矩阵上拟合模型
    cf_knn_model.fit（矩阵）
    
    # 计算邻居距离
    距离，索引 = cf_model.kneighbors(matrix[garment_id], n_neighbors=n_recs)
    Clothing_rec_ids = Sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),key=lambda x: x[1])[:0:-1]
    
    # 存储推荐的列表
    cf_recs = []
    对于我在 dress_rec_ids 中：
        cf_recs.append({&#39;Desc&#39;:clothes_desc[&#39;DESCRIPTION&#39;][i[0]],&#39;距离&#39;:i[1]})
    
    # 选择需要的最多推荐数量
    df = pd.DataFrame(cf_recs, 索引 = 范围(1,n_recs))
    返回df


n_recs = 10
dress_recommender_engine（54448，user_item_matrix，cf_knn_model，n_recs）

我得到的错误是：
&lt;前&gt;&lt;代码&gt;&gt; *keyError Traceback（最近一次调用最后）文件
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802,
&gt;在Index.get_loc（self，key，method，tolerance）3801中尝试：
&gt; -&gt; [第 3802 章] 第 3803 章
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138,
&gt;在 pandas._libs.index.IndexEngine.get_loc() 文件中
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165,
&gt;在 pandas._libs.index.IndexEngine.get_loc() 文件中
&gt; pandas/_libs/hashtable_class_helper.pxi:2263，在
&gt; pandas._libs.hashtable.Int64HashTable.get_item() 文件
&gt; pandas/_libs/hashtable_class_helper.pxi:2273，位于
&gt; pandas._libs.hashtable.Int64HashTable.get_item() KeyError：54448
&gt;上述异常是以下异常的直接原因：
&gt; KeyError Traceback（最近调用
&gt;最后）单元格 In[4]，第 64 行
&gt; 59 返回 df
&gt; 63 n_recs = 10
&gt; ---&gt; 64 dress_recommender_engine(54448, user_item_matrix, cf_knn_model, n_recs) 单元格 In[4]，第 48 行，in
&gt; dress_recommender_engine(garment_id, 矩阵, cf_model, n_recs)
&gt; 42 cf_knn_model.fit（矩阵）
&gt; 44 # 提取输入的电影ID
&gt;第45话
&gt; 46
&gt; 47 # 计算邻居距离
&gt; ---&gt; 48 个距离，索引 = cf_model.kneighbors(matrix[garment_id], n_neighbors=n_recs)
&gt;第49章 衣服
&gt; x: x[1])[:0:-1]
&gt; 51 # 存储推荐的列表 File ~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3807, in
&gt;第3805章1：
&gt;第3806章
&gt; -&gt;第3807章 第3808章 第3809章
&gt; 〜/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804，
&gt;在Index.get_loc（self，key，method，tolerance）3802返回
&gt; self._engine.get_loc(casted_key) 3803 除了 KeyError 为错误：
&gt; -&gt;第3804章 3805，除了TypeError：3806，引发KeyError（key）
&gt;第3807章否则我们会失败并重新加注
&gt;第3808章第3809章
&gt;密钥错误：54448*

错误似乎在这一行：
距离，索引 = cf_model.kneighbors(matrix[garment_id], n_neighbors=n_recs)
当传递matrix[garment_id]时，知道如何解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/78101850/neighbors-indexing-error-self-check-indexing-errorkey-keyerror-8</guid>
      <pubDate>Mon, 04 Mar 2024 14:12:06 GMT</pubDate>
    </item>
    <item>
      <title>Pytroch 分割模型(.pt) 未转换为 CoreML</title>
      <link>https://stackoverflow.com/questions/78091161/pytroch-segmentation-model-pt-not-converting-to-coreml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78091161/pytroch-segmentation-model-pt-not-converting-to-coreml</guid>
      <pubDate>Sat, 02 Mar 2024 01:26:48 GMT</pubDate>
    </item>
    <item>
      <title>如何重现带有modified_huber损失的SGDClassifier？</title>
      <link>https://stackoverflow.com/questions/78057268/how-do-i-reproduce-a-sgdclassifier-with-modified-huber-loss</link>
      <description><![CDATA[我有一个像这样定义的模型：
rng = 42
模型=管道（[
    (&#39;缩放器&#39;, RobustScaler()),
    (&#39;特征&#39;, SelectKBest(k=42)),
    (&#39;model&#39;, SGDClassifier(loss=&#39;modified_huber&#39;, shuffle=True, random_state=rng))
]）

当我使用完全相同的输入在两个单独的程序执行（一个是临时的，另一个是 cron 作业）中进行训练和预测时，我会得到不同的模型权重，从而得到预测结果。
我注意到“铰链”损失是唯一具有完全相同权重的可重现模型。其他损失函数是什么阻止了它们被重现？
我已经检查并仔细检查输入是否相同，并使用其他损失函数进行验证。]]></description>
      <guid>https://stackoverflow.com/questions/78057268/how-do-i-reproduce-a-sgdclassifier-with-modified-huber-loss</guid>
      <pubDate>Sun, 25 Feb 2024 18:57:43 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.decomposition.PCA 特征向量的简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我正在尝试了解主成分分析的工作原理，并在sklearn.datasets.load_iris数据集上对其进行测试。我了解每个步骤的工作原理（例如标准化数据、协方差、特征分解、排序最高特征值、使用 K 选定的维度将原始数据转换为新轴）。
下一步是可视化这些特征向量在数据集上的投影位置（在PC1 vs. PC2 图上，对吗？）。
有人可以解释如何在降维数据集的 3D 图上绘制 [PC1、PC2、PC3] 特征向量吗？
另外，我是否正确绘制了这个 2D 版本？我不确定为什么我的第一个特征向量的长度较短。我应该乘以特征值吗？
&lt;小时/&gt;
以下是我为实现这一目标所做的一些研究：
我遵循的 PCA 方法来自：
https://plot.ly /ipython-notebooks/principal-component-analysis/#Shortcut---PCA-in-scikit-learn （虽然我不想使用 plotly。我想坚持使用pandas、numpy、sklearn、matplotlib、scipy 和 seaborn）
我一直在遵循本教程来绘制特征向量，它看起来非常简单：基本示例对于带有 matplotlib 的 PCA 但我似乎无法用我的数据复制结果。
我发现了这个，但对于我想要做的事情来说，它似乎过于复杂，而且我不想创建一个 FancyArrowPatch： 使用 matplotlib 和 np.linalg 绘制协方差矩阵的特征向量
&lt;小时/&gt;
我尝试使我的代码尽可能简单，以便遵循其他教程：
将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
从 sklearn.datasets 导入 load_iris
从 sklearn.preprocessing 导入 StandardScaler
来自 sklearn 导入分解
将seaborn导入为sns； sns.set_style(“whitegrid”, {&#39;axes.grid&#39; : False})

%matplotlib 内联
np.随机.种子(0)

# 鸢尾花数据集
DF_data = pd.DataFrame(load_iris().data,
                       索引 = [“iris_%d”; % i for i in range(load_iris().data.shape[0])],
                       列= load_iris().feature_names)

Se_targets = pd.Series(load_iris().target,
                       索引 = [“iris_%d”; % i for i in range(load_iris().data.shape[0])],
                       名称=“物种”）

# 缩放均值 = 0，var = 1
DF_standard = pd.DataFrame(StandardScaler().fit_transform(DF_data),
                           索引 = DF_data.index,
                           列= DF_data.列）

# Sklearn 用于主成分分析

# 变暗
m = DF_standard.shape[1]
K = 2

# PCA（我倾向于如何设置它）
M_PCA = 分解.PCA(n_components=m)
DF_PCA = pd.DataFrame(M_PCA.fit_transform(DF_standard),
                列=[“PC%d” % k for k in range(1,m + 1)]).iloc[:,:K]


# 绘制特征向量
#https://stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

# 这就是事情变得奇怪的地方......
数据 = DF_标准

mu = data.mean(轴=0)
特征向量，特征值 = M_PCA.components_，M_PCA.explained_variance_ #特征向量，特征值，V = np.linalg.svd(data.T, full_matrices=False)
projected_data = DF_PCA #np.dot(数据，特征向量)

西格玛=projected_data.std(axis=0).mean()

图, ax = plt.subplots(figsize=(10,10))
ax.scatter(projected_data[“PC1”],projected_data[“PC2”])
对于轴，zip 中的颜色（特征向量[:K], [“红色”,“绿色”]）：
# start, end = mu, mu + sigma * axis ### 导致“ValueError：太多值无法解压（预期为 2）”

    # 所以我尝试了这个，但我认为它不正确
    开始，结束 = (mu)[:K], (mu + sigma * 轴)[:K]
    ax.annotate(&#39;&#39;, xy=结束,xytext=开始, arrowprops=dict(facecolor=颜色, width=1.0))
    
ax.set_aspect(&#39;等于&#39;)
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    </channel>
</rss>