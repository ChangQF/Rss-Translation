<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 06 Apr 2024 15:13:18 GMT</lastBuildDate>
    <item>
      <title>为用于 QA 的 BERT 训练准备文本语料库</title>
      <link>https://stackoverflow.com/questions/78284470/text-corpus-preparation-for-bert-training-for-qa</link>
      <description><![CDATA[我最近开始学习 NLP（自学），并一直在研究使用 NLP 来帮助教育方面，通过取代“无用”的词来帮助教育。教师。为此，我想训练一个 BERT 模型，该模型可以使用提取式 QA 来回答学生基于特定主题的特定文本语料库提出的问题。
但是，我需要帮助准备用于训练的文本数据，因为它不是我习惯的常用 csv 格式，而且看起来有点不同。数据如下所示，长达数百页：
那么，我该如何为训练 BERT 做准备呢？或者你们有更好的方法可以建议我做我正在尝试的事情吗？]]></description>
      <guid>https://stackoverflow.com/questions/78284470/text-corpus-preparation-for-bert-training-for-qa</guid>
      <pubDate>Sat, 06 Apr 2024 13:03:09 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow.python.keras.layers”没有属性“BatchNormalization”</title>
      <link>https://stackoverflow.com/questions/78284460/attributeerror-module-tensorflow-python-keras-layers-has-no-attribute-batchn</link>
      <description><![CDATA[我目前正在开发一个项目，需要在 TensorFlow Keras 中使用 BatchNormalization。我已经从tensorflow.python.keras导入了层，但是当我尝试使用BatchNormalization时，遇到以下错误：
AttributeError：模块“tensorflow.python.keras.layers”没有属性“BatchNormalization”
这是我的代码片段：
从tensorflow.python.keras导入模型，输入
从tensorflow.python.keras.optimizers导入adam_v2作为Adam
从tensorflow.python.keras导入层
类 InceptionBlock(layers.Layer):
    def __init__(self, f, pooling=True):
        super(InceptionBlock, self).__init__()
        
        self.f = f
        self.pooling = 池化
   
        self.conva0 = 层.Conv2D(self.f, (1, 1), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma0=layers.BatchNormalization()
        self.conva1 = 层.Conv2D(self.f, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma1=layers.BatchNormalization()
        self.conva2 = 层.Conv2D(self.f, (1, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma2=layers.BatchNormalization()
        self.poola = groups.MaxPooling2D(pool_size=(2, 2))
        self.conva3 = 层.Conv2D(self.f, (3, 1), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma3=layers.BatchNormalization()
            

我的tensorflow版本是2.16.1，python版本是3.11.9。我检查了文档，似乎 BatchNormalization 应该在图层模块中可用。有人能解释一下为什么我可能会遇到这个错误吗？我应该使用其他方法在 TensorFlow Keras 中导入 BatchNormalization 吗？
如有任何帮助，我们将不胜感激。
谢谢！
我正在尝试在我的 InceptionBlock 路径中使用 BatchNormalization。]]></description>
      <guid>https://stackoverflow.com/questions/78284460/attributeerror-module-tensorflow-python-keras-layers-has-no-attribute-batchn</guid>
      <pubDate>Sat, 06 Apr 2024 13:00:44 GMT</pubDate>
    </item>
    <item>
      <title>我可以重新训练 AutoModelForSequenceClassification 以生成文本吗？</title>
      <link>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</link>
      <description><![CDATA[我的目标是微调 Mistral 7b 以编写短意识流（文本完成，而不是遵循指令）。
我有一个大型数据库（100 万行），其中包含从互联网上抓取的短文本。我手动将 15k 行标记为 good (1k) 和 bad（其余 14k）示例。我的计划是训练 AutoModelForSequenceClassification在这些示例上标记其他 985k 行。
通过这种方式，我希望收集大约 20k 意识流的好例子来微调 Mistral 7b。
但仅对good示例进行微调并不会使用bad示例中的信息，这些示例的数量要多得多。因此，我正在考虑使用 Mistral 7b 作为 AutoModelForSequenceClassification 的基本模型（遵循 这篇 Medium 文章），然后重新训练生成的 AutoModelForSequenceClassification 以进行文本补全。这需要移除分类头并添加新的/重新训练的 LoRA 组件。
您认为这可行吗？这是否会削弱模型（例如，需要重新学习语法），或者这是否是将坏反例的信息合并到文本生成中的有效方法？或者至少为 LoRA 文本生成微调提供一个良好的初始化点？]]></description>
      <guid>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</guid>
      <pubDate>Sat, 06 Apr 2024 11:32:55 GMT</pubDate>
    </item>
    <item>
      <title>py_call_impl 中的错误（可调用，call_args$未命名，call_args$命名）</title>
      <link>https://stackoverflow.com/questions/78283892/error-in-py-call-implcallable-call-argsunnamed-call-argsnamed</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78283892/error-in-py-call-implcallable-call-argsunnamed-call-argsnamed</guid>
      <pubDate>Sat, 06 Apr 2024 09:49:16 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中计算非常大的数据的 AUC</title>
      <link>https://stackoverflow.com/questions/78283588/calculating-auc-for-very-large-data-in-r</link>
      <description><![CDATA[我想重复计算曲线下面积类型值（AUROC 和 AUPRC）以及大于 2^32 行的数据集的平均精度。我将之前计算的数据集分割成多个块，现在通常我只需rbind它们，然后计算 AUC（我使用evalmod）。这对于较小的“data.table”来说效果很好，但我反复拥有无法行绑定的数据集，因为 R 的（坦率地说愚蠢的）限制为 2^32 行。有人能给我指出一个解决方案吗

将数据“rbin”到大型数据集的不同类中，然后计算 AUC，或者
如何计算每个切片的这些值，以便稍后计算总体 AUC。

提前谢谢你:)
PS：RAM 不是问题，因为数据可以分片保存在内存中]]></description>
      <guid>https://stackoverflow.com/questions/78283588/calculating-auc-for-very-large-data-in-r</guid>
      <pubDate>Sat, 06 Apr 2024 07:35:45 GMT</pubDate>
    </item>
    <item>
      <title>在一组用户数据上训练 ML 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/78283322/train-an-ml-model-on-group-of-user-data</link>
      <description><![CDATA[我需要建立用户支付交易的欺诈检测。
与之前用户的交易历史记录相比，我需要在用户交易中定义一些独特的模式。
我需要在每个用户数据集上训练模型吗？
在这种情况下，我最终会得到大量模型。
请提出正确的方法。
我觉得这是一种推荐系统，其中用户是根据用户之前的历史推荐的。但我不知道他们是如何实现这一目标的。
请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/78283322/train-an-ml-model-on-group-of-user-data</guid>
      <pubDate>Sat, 06 Apr 2024 05:22:34 GMT</pubDate>
    </item>
    <item>
      <title>使用我尝试从头开始构建的神经网络时出现问题</title>
      <link>https://stackoverflow.com/questions/78283274/problem-with-using-a-neural-network-i-tried-to-build-from-scratch</link>
      <description><![CDATA[代码：
&lt;前&gt;&lt;代码&gt;
随机导入
导入数学
将 numpy 导入为 np
类值：
  
  def __init__(self, data, _children=(), _op=&#39;&#39;, label=&#39;&#39;):
    self.data = 数据
    自我毕业= 0.0
    self._backward = lambda: 无
    self._prev = 设置（_children）
    self._op = _op
    self.label = 标签

  def __repr__(自我):
    return f“值(data={self.data})”
  
  def __add__(自己，其他)：
    other = other if isinstance(other, Value) else Value(other)
    out = Value(self.data + other.data, (self, other), &#39;+&#39;)
    
    def _backward():
      自我.grad += 1.0 * 输出.grad
      其他.grad += 1.0 * out.grad
    输出._backward = _backward
    
    返回

  def __mul__(自己，其他)：
    other = other if isinstance(other, Value) else Value(other)
    out = Value(self.data * other.data, (self, other), &#39;*&#39;)
    
    def _backward():
      self.grad += other.data * out.grad
      other.grad += self.data * out.grad
    输出._backward = _backward
      
    返回
  
  def __pow__(自己，其他)：
    assert isinstance(other, (int, float)), “目前仅支持 int/float 幂”
    out = Value(self.data**other, (self,), f&#39;**{other}&#39;)

    def _backward():
        self.grad += 其他 * (self.data ** (其他 - 1)) * out.grad
    输出._backward = _backward

    返回
  
  def __rmul__(self, other): # 其他 * self
    返回自己*其他

  def __truediv__(self, other): # 自己 / 其他
    返回自己 * 其他**-1

  def __neg__(self): # -self
    返回自身 * -1

  def __sub__(self, other): # 自 - 其他
    返回自我+（-其他）

  def __radd__(self, other): # 其他 + self
    返回自己+他人

  def tanh(自身):
    x = 自身数据
    t = np.tanh(x)
    输出 = 值(t, (self, ), &#39;tanh&#39;)

    def _backward():
        self.grad += (1 - t**2) * out.grad
    输出._backward = _backward

    返回

  def exp(自身):
    x = 自身数据
    out = Value(math.exp(x), (self, ), &#39;exp&#39;)
    
    def _backward():
      self.grad += out.data * out.grad # 注意：在视频中我错误地使用了 = 而不是 +=。固定在这里。
    输出._backward = _backward
    
    返回
  
  
  def向后（自身）：
    
    拓扑 = []
    访问过=设置（）
    def build_topo(v):
      如果 v 不在访问中：
        访问过.add(v)
        对于 v._prev 中的孩子：
          构建拓扑（子）
        拓扑.append(v)
    构建拓扑（自身）
    
    自我毕业= 1.0
    对于反向节点（topo）：
      节点._backward()



神经元类：
  
  def __init__(self, nin):
    self.w = [值(random.uniform(-1,1)) for _ in range(nin)]
    self.b = Value(随机.uniform(-1,1))
  
  def __call__(自身，x)：
    # w * x + b
    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)
    输出 = act.tanh()
    返回
  
  def 参数（自身）：
    返回 self.w + [self.b]

类层：
  
  def __init__(self, nin, noout):
    self.neurons = [神经元(nin) for _ in range(nout)]
  
  def __call__(自身，x)：
    outs = [n(x) for n in self.neurons]
    返回 outs[0] 如果 len(outs) == 1 否则 outs
  
  def 参数（自身）：
    return [p 代表 self.neurons 中的神经元，代表神经元中的 p.parameters()]

MLP 类：
  
    def __init__(self, nin, nouts):
        sz = [nin] + nouts
        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]
  
    def __call__(自身，x)：
        对于 self.layers 中的图层：
            x = 层(x)
        返回x
  
    def 参数（自身）：
        return [p for self.layers 中的层 for p in layer.parameters()]

现在用这个东西来预测东西：
随机导入

# 初始化神经网络
n = MLP(nin=2, nouts=[4, 1])

学习率 = 0.1

# 训练循环
对于范围 (200) 内的 k：
    # 生成随机输入数据点
    xs = [[random.uniform(0, 1001), random.uniform(0, 1)] for _ in range(100)]
    ys = [Value(5 + 3*x[0] + x[1]) for x in xs] # 使用 Value 类来表示真实输出
    
    # 前向传递
    ypred = [n(x) for x in xs]
    loss = sum((ygt - yout)**2 for ygt, yout in zip(ys, ypred)) / len(xs) # 计算均方误差
    
    # 向后传递
    对于 n.parameters() 中的 p：
        p.grad = 0.0
    loss.backward()
    
    # 更新权重和偏差
    对于 n.parameters() 中的 p：
        p.data += -learning_rate * p.grad
    
    print(k, 损失.数据)

我试图从函数 y=5+3x+i 预测 y 的值，x 的范围从 0 到 1001，i 的范围从 0 到 1，尝试仅使用 x 来预测，但没有成功，它无法仅使用 x 来完成此操作，给出了无法迭代它的错误。
ypred 搞砸了，它的所有值都是 1.0，我是在做一些非常愚蠢的事情还是因为这件事似乎不起作用，我尝试了 chatgpt，它失败了。
我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78283274/problem-with-using-a-neural-network-i-tried-to-build-from-scratch</guid>
      <pubDate>Sat, 06 Apr 2024 04:49:13 GMT</pubDate>
    </item>
    <item>
      <title>微调t5变压器产生重复输出</title>
      <link>https://stackoverflow.com/questions/78283102/fine-tuned-t5-transformer-generates-repetitive-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78283102/fine-tuned-t5-transformer-generates-repetitive-output</guid>
      <pubDate>Sat, 06 Apr 2024 03:13:49 GMT</pubDate>
    </item>
    <item>
      <title>python- pytorch.compile() 给出运行时错误，指出 python 3.12+ 不支持 Dynamo</title>
      <link>https://stackoverflow.com/questions/78282862/python-pytorch-compile-giving-runtime-error-saying-dynamo-is-not-supported-on</link>
      <description><![CDATA[我正在尝试在本地法学硕士中运行这段代码。
如果编译：
    print(&quot;编译模型&quot;)
    未优化模型 = 模型
    模型 = torch.compile(模型)

这是我得到的错误：
请帮我解决这个问题
回溯（最近一次调用）：
文件“c:\\Users\\abul4\\OneDrive\\Desktop\\LLM\\train.py”，第 180 行，位于 \ 中
模型 = torch.compile(模型)
^^^^^^^^^^^^^^^^^^^^^^
文件“C:\\Users\\abul4\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\__init_\_.py”，第 1801 行，编译中
raise RuntimeError(“Python 3.12+ 不支持 Dynamo”)
运行时错误：Python 3.12+ 不支持 Dynamo
]]></description>
      <guid>https://stackoverflow.com/questions/78282862/python-pytorch-compile-giving-runtime-error-saying-dynamo-is-not-supported-on</guid>
      <pubDate>Sat, 06 Apr 2024 00:46:07 GMT</pubDate>
    </item>
    <item>
      <title>编写成本/损失函数[关闭]</title>
      <link>https://stackoverflow.com/questions/78282847/writing-the-cost-lost-function</link>
      <description><![CDATA[我有以下训练数据集代码：
# 数组格式的数据
train_data = [[3370,4.5,1],[2949,5.4,1],[4020,5.5,1],[4337,4.7,1],[2519,3.6,1],[4461,5.4,1] ,[2755,5.1,1],[3317,3.2,1],[2672,4.3,1],[2854,4.7,1],
 [3663,2.6,1],[3497,3.2,1],[4603,8.2,1],[2780,3.4,1],[5074,2.5,1],[3354,4.9,1],[4732 ,2.7,1],[5506,3.3,1],[4091,5.6,1],[2890,3.4,1],
  [5873,3.2,0],[5400,3.3,0],[5707,2.2,0],[6408,1.5,0],[8019,1.9,0],[7319,1.9,0],[6212 ,3.6,0],[5918,2.7,0],[8621,3.4,0],[8967,1.7,0],
   [4976,2.1,0],[5477,3.6,0],[5302,5.6,0],[7450,4.0,0],[8580,2.3,0],[7496,3.8,0],[6444 ,3.5,0],[5087,2.7,0],[5791,2.7,0],[4812,2.4,0]]
# pytorch 张量格式的数据
train_X, train_y = torch.tensor(train_data)[:,:2], torch.tensor(train_data)[:,2:3]

绘图数据（train_X，train_y）

现在我不知道如何用这个函数编写成本/损失函数
def J(X, y, w, b):

任何人都可以帮我使用 pytorch 编写代码吗？非常感谢
我可以得到代码]]></description>
      <guid>https://stackoverflow.com/questions/78282847/writing-the-cost-lost-function</guid>
      <pubDate>Sat, 06 Apr 2024 00:37:40 GMT</pubDate>
    </item>
    <item>
      <title>Flutter ml 脸部套件 如何判断您的脸部是否被什么东西挡住了？</title>
      <link>https://stackoverflow.com/questions/78282615/flutter-ml-face-kit-how-can-you-tell-if-your-face-is-blocked-by-something</link>
      <description><![CDATA[我需要确定脸部清晰可见且未被遮挡。例如，如果用手捂住嘴。如何使用 ml 面部套件确定这一点？
我尝试通过 Landmark 来做到这一点，但即使你遮住脸部的某些部分，你也可以看到它们]]></description>
      <guid>https://stackoverflow.com/questions/78282615/flutter-ml-face-kit-how-can-you-tell-if-your-face-is-blocked-by-something</guid>
      <pubDate>Fri, 05 Apr 2024 22:38:50 GMT</pubDate>
    </item>
    <item>
      <title>验证的准确性比测试更高</title>
      <link>https://stackoverflow.com/questions/78282544/higher-accuracy-in-validation-that-test</link>
      <description><![CDATA[我使用 80/10/10 分割规则训练了一个模型。我的验证准确度约为 80%（皮尔逊相关），我的测试数据集的准确度约为 83%。这样可以吗？
我尝试了不同的正则化技术来从验证数据集中获得最佳结果，但是，我也不期望在测试数据集中获得更高的准确性]]></description>
      <guid>https://stackoverflow.com/questions/78282544/higher-accuracy-in-validation-that-test</guid>
      <pubDate>Fri, 05 Apr 2024 22:12:48 GMT</pubDate>
    </item>
    <item>
      <title>如何找到不同公司竞争对手产品矩阵与特定品牌数据集的相关性？有机器学习来预测适合度吗？</title>
      <link>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</link>
      <description><![CDATA[我试图找到一个数据集（矩阵）的相关性，该数据集（矩阵）包含行上的客户和他们按列拥有的竞争对手产品（拥有=&#39;是&#39;，不拥有=&#39;否&#39;）和另一个客户数据集拥有我们的品牌（拥有=1，不拥有=0）。请记住，我们品牌数据集中的所有零值都是潜在客户。
我尝试了随机森林，但我们对拥有我们品牌的客户的所有价值观都是积极的，我如何根据所有积极的价值观来预测适合度？]]></description>
      <guid>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</guid>
      <pubDate>Fri, 05 Apr 2024 00:53:35 GMT</pubDate>
    </item>
    <item>
      <title>Python Phonemizer 库在 ubuntu VM 中找不到 espeak 库</title>
      <link>https://stackoverflow.com/questions/78210991/python-phonemizer-library-cant-find-espeak-library-in-ubuntu-vm</link>
      <description><![CDATA[尽管该模型在 Windows 本地计算机上运行良好，但根据此安装指南将路径传递到 espeak-ng 库时 https://bootphon.github.io/phonemizer/install.html ，我无法使其在 Ubuntu 22.04.4 LTS (x86-64) 下的虚拟机中工作。当运行我的脚本通过 wav2vec2phoneme 转录音素时，我收到以下消息
回溯（最近一次调用最后一次）：
文件“/dialrec/phoneme_transcription/phoneme_recognizers/transcribe.py”，第 50 行，位于
phoneme_recognizer = Wav2Vec2Phoneme()
文件“/dialrec/phoneme_transcription/phoneme_recognizers/wav2vec2phoneme.py”，第 24 行，init 中
self.processor = Wav2Vec2Processor.from_pretrained(&quot;facebook/wav2vec2-xlsr-53-espeak-cv-ft&quot;)
文件“/usr/local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py”，第 52 行，在 from_pretrained 中
返回 super().from_pretrained(pretrained_model_name_or_path, **kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/processing_utils.py”，第 465 行，from_pretrained
args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/processing_utils.py”，第 511 行，位于 _get_arguments_from_pretrained
args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
文件“/usr/local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py”，第 837 行，在 from_pretrained 中
返回 tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py”，第 2086 行，from_pretrained
返回 cls._from_pretrained(
文件“/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py”，第 2325 行，位于 _from_pretrained
分词器 = cls(*init_inputs, **init_kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py”，第 153 行， init
self.init_backend(self.phonemizer_lang)
文件“/usr/local/lib/python3.10/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py”，第 202 行， init_backend
self.backend = BACKENDS[self.phonemizer_backend](phonemizer_lang, language_switch=&quot;remove-flags&quot;)
文件“/usr/local/lib/python3.10/site-packages/phonemizer/backend/espeak/espeak.py”，第 45 行，在 init 中
超级().init(
文件“/usr/local/lib/python3.10/site-packages/phonemizer/backend/espeak/base.py”，第 39 行，在 init 中
超级().init(
文件“/usr/local/lib/python3.10/site-packages/phonemizer/backend/base.py”，第 77 行，在 init 中
引发 RuntimeError( # pragma: nocover
运行时错误：您的系统上未安装 espeak

为了安装 espeak，我按照以下步骤操作：

apt-get 安装 espeak-ng
pip3 安装phonemizer
pip3 install espeakng（也尝试过 pip3 install py-espeak-ng）

Espeak 肯定安装在 /usr/lib/x86_64-linux-gnu/libespeak-ng.so.1 和 /usr/bin/espeak-ng 下。
我尝试了以下方法：

无需额外步骤
设置环境变量 PHONEMIZER_ESPEAK_LIBRARY=&#39;/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1&#39; 和 PHONEMIZER_ESPEAK_PATH=&#39;/usr/bin/espeak-ng&#39;。
直接在脚本中设置环境变量
os.environ[&#39;PHONEMIZER_ESPEAK_LIBRARY&#39;] = &#39;/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1&#39;
os.environ[&#39;PHONEMIZER_ESPEAK_PATH&#39;] = &#39;/usr/bin/espeak-ng&#39;

如果有任何帮助，我将不胜感激。提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78210991/python-phonemizer-library-cant-find-espeak-library-in-ubuntu-vm</guid>
      <pubDate>Sat, 23 Mar 2024 13:14:00 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在 scikit learn 中将装袋技术与两种不同的算法结合使用？</title>
      <link>https://stackoverflow.com/questions/26283045/is-it-possible-to-use-the-bagging-technique-with-two-different-algorithms-in-sci</link>
      <description><![CDATA[是否可以将装袋技术与两种不同的算法（例如逻辑回归和随机森林）或（几乎）任何其他算法结合使用？
我需要一些能够返回平均概率或组合概率和预测的东西。这将用于分类任务。]]></description>
      <guid>https://stackoverflow.com/questions/26283045/is-it-possible-to-use-the-bagging-technique-with-two-different-algorithms-in-sci</guid>
      <pubDate>Thu, 09 Oct 2014 16:06:55 GMT</pubDate>
    </item>
    </channel>
</rss>