<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 15 Jan 2025 12:32:28 GMT</lastBuildDate>
    <item>
      <title>使用历史数据训练模型后预测日前每小时电价</title>
      <link>https://stackoverflow.com/questions/79357740/predict-day-ahead-hourly-electricity-prices-after-having-trained-a-model-using-h</link>
      <description><![CDATA[我使用 2015 年至 2024 年的历史数据训练了一个 XGboost 模型。我添加了一些功能，例如天气数据、电力消耗、来自不同来源（如核能和其他可再生能源）的发电量。我已将电价设定为目标。所有数据均为每小时格式。我已经成功训练了模型，但现在我很难预测第二天的电费每小时价格。
我不知道如何使用训练好的模型，使用包含截至 2024 年 12 月 7 日的数据的数据集来预测价格。例如：在模型训练到 2024 年 12 月 7 日后，我如何预测 2025 年 1 月 15 日的每小时价格？
现在，预测代码只取所有特征的最后一个值，并将相同的值放在它试图预测和运行模型的所有行中。
到目前为止，我已经使用了数据集中最近 24 小时的数据（所有特征的最后 24 行），并使用模型来预测价格，但它甚至离实际价格还很远。
# 现在添加预测代码
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 获取最后已知数据
last_known_data = X_test.copy()
# print(last_known_data.columns)

# 设置明天的目标日期
target_date = datetime.now().replace(hour=0,minute=0,second=0,microsecond=0) + timedelta(days=1)

# 创建 24 小时的 DataFrame
prediction_hours = pd.date_range(target_date, target_date + timedelta(hours=23), freq=&#39;H&#39;)
future_df = pd.DataFrame(index=prediction_hours)
future_df[&#39;Start_date&#39;] = future_df.index

# 将日期时间转换为 unix 时间戳（用于训练）
future_df[&#39;Start_date&#39;] = future_df[&#39;Start_date&#39;].astype(np.int64) // 10**9

# 获取所有特征的最后已知值
last_values = last_known_data.iloc[-1].copy()

# 创建用于预测的特征矩阵
for col in X_train.columns:
if col in [&#39;Start_date&#39;, &#39;End_date_x&#39;, &#39;End_date_y&#39;, &#39;End_date&#39;, &#39;dt_iso&#39;]:
future_df[col] = future_df[&#39;Start_date&#39;]
else:
future_df[col] = last_values[col]

# 添加基于时间的特征
future_df[&#39;hour&#39;] = future_df.index.hour
future_df[&#39;day_of_week&#39;] = future_df.index.dayofweek
future_df[&#39;month&#39;] = future_df.index.month

# 使用最后已知价格处理价格滞后特征
last_known_prices = merged_data[&#39;德国/卢森堡 [€/MWh]&#39;].iloc[-72:]

future_df[&#39;price_lag_24&#39;] = last_known_prices.iloc[-24:].values
future_df[&#39;price_lag_48&#39;] = last_known_prices.iloc[-48:-24].values
future_df[&#39;price_lag_72&#39;] = last_known_prices.iloc[-72:-48].values

# 计算滚动温度特征
for window in [24, 48, 72]:
future_df[f&#39;temp_roll_{window}&#39;] = future_df[&#39;temp&#39;].rolling(window=window, min_periods=1).mean()

# 确保列与训练数据匹配
prediction_features = future_df[X_train.columns]

#进行预测
predictions = xgb_model.predict(prediction_features)

# 创建结果 DataFrame
results_df = pd.DataFrame({
&#39;Datetime&#39;: prediction_hours,
&#39;Hour&#39;: prediction_hours.hour,
&#39;Predicted_Price_EUR_MWh&#39;: np.round(predictions, 2)
})

# 打印预测
print(&quot;\n未来 24 小时的预测价格：&quot;)
print(results_df.to_string(index=False))
]]></description>
      <guid>https://stackoverflow.com/questions/79357740/predict-day-ahead-hourly-electricity-prices-after-having-trained-a-model-using-h</guid>
      <pubDate>Wed, 15 Jan 2025 09:50:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 GCP 服务进行图像分类[关闭]</title>
      <link>https://stackoverflow.com/questions/79356912/how-to-use-gcp-service-for-image-classification</link>
      <description><![CDATA[我从物联网设备获取图像作为输入，发送到云端，进行图像分类，并将结果发送回某个 URL。
我尝试使用本地模型为 TF 提供 docker 镜像，并在我的设备上进行分类。
（云端 Ml 部署新手）]]></description>
      <guid>https://stackoverflow.com/questions/79356912/how-to-use-gcp-service-for-image-classification</guid>
      <pubDate>Wed, 15 Jan 2025 02:26:56 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 自动编码器效果很差</title>
      <link>https://stackoverflow.com/questions/79356691/lstm-autoencoder-very-poor-results</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79356691/lstm-autoencoder-very-poor-results</guid>
      <pubDate>Tue, 14 Jan 2025 23:45:14 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习算法的逐步方法[关闭]</title>
      <link>https://stackoverflow.com/questions/79356061/stepwise-way-of-using-machine-learning-algorithms</link>
      <description><![CDATA[
如何使用数据集
如何找到它们，即使网站已经使用过。
-设计测验算法
将数据集映射到测验算法以预测职业。
快速学习的有效方法。

我和我的朋友决定使用霍兰德代码进行技术职业预测。为此，我们需要使用像 knn 这样的机器学习算法，但我们需要合并数据集？但我们不知道如何做到这一点。您能提供指导吗？您是否有其他方法可以解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79356061/stepwise-way-of-using-machine-learning-algorithms</guid>
      <pubDate>Tue, 14 Jan 2025 18:42:46 GMT</pubDate>
    </item>
    <item>
      <title>我需要训练一个多类模型，但我有一个小数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/79355992/i-need-to-train-a-multiclass-model-but-i-have-a-small-dataset</link>
      <description><![CDATA[我有一个包含两列的 Excel 文件，一列包含短语之类的文本，另一列告诉我从“CS1”到“CS8”的分类。文本如下
&quot;NE PAGTO PROVENTOS APOSENTADORIA ESPECIAL SERVIDORES SAÚDE, NOV/2024. REF. FATURA 033/2024. INCLUI REFORMA DE ESCOLAS.&quot;

我已经清理了其他文件，文件总共有 72 个文本，其中 df.shape = (72, 2)。
准确率保持在 50% 以下。但我需要更高。
文件 clean_text.py：
import re

def clean_text(text):
text = re.sub(r&#39;\d{1,4}/\d{4}&#39;, &#39;&#39;, text)
text = re.sub(r&#39;\d+&#39;, &#39;&#39;, text)
text = re.sub(r&#39;[^\w\s]&#39;, &#39;&#39;, text)
text = text.lower()
return text

文件 main.py：
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import顺序
从 tensorflow.keras.layers 导入 Dense、Dropout、Input
从 tensorflow.keras.optimizers 导入 Adam
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
从 sklearn.model_selection 导入 train_test_split
从 sklearn.preprocessing 导入 LabelEncoder
从 sklearn.metrics 导入 Classification_report、Accuracy_score
从 transformers 导入 TFAutoModel、AutoTokenizer
导入 joblib
将 pandas 导入为 pd
从 nltk.corpus 导入停用词
导入 re
从 clean_text 导入 clean_text

df = pd.read_excel(&quot;DADOS PARA CLASSIFICAÇÃO MULTICLASSE.xlsx&quot;, sheet_name=&quot;TREINAMENTO&quot;)
df[&#39;EMPENHO&#39;] = df[&#39;EMPENHO&#39;].apply(clean_text)
descriptions = df[&#39;EMPENHO&#39;].tolist()
labels = df[&#39;CLASSE SINTETICA&#39;].tolist()

print(f&quot;Amostras: {df.shape}&quot;)

label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels)

vect = TfidfVectorizer()
X = vect.fit_transform(descriptions).toarray()

X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)

model = Sequential([
输入(shape=(X_train.shape[1],)),
Dense(128, 激活=&#39;relu&#39;),
Dropout(0.3),
Dense(64, 激活=&#39;relu&#39;),
Dropout(0.3),
Dense(len(label_encoder.classes_), 激活=&#39;softmax&#39;)
])

model.compile(optimizer=Adam(learning_rate=1e-4), loss=&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

accuracy = 0
while accuracy &lt; 0.90:
print(&quot;训练模型...&quot;)
emp_train = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, verbose=0)

y_pred = np.argmax(model.predict(X_test), axis=-1)
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;准确率：{accuracy * 100:.2f}%&quot;)

joblib.dump(vect, &quot;vectorizer.pkl&quot;)
joblib.dump(label_encoder, &quot;label_encoder.pkl&quot;)
model.save(&quot;empenho_model.keras&quot;)

print(&quot;训练模型并计算结果成功了！”）

我尝试使用 BERT 和 PyTorch，但这种方式对我来说更好。]]></description>
      <guid>https://stackoverflow.com/questions/79355992/i-need-to-train-a-multiclass-model-but-i-have-a-small-dataset</guid>
      <pubDate>Tue, 14 Jan 2025 18:16:11 GMT</pubDate>
    </item>
    <item>
      <title>加载 MIT-BIH 心律失常数据库（无需 wfdb 包）</title>
      <link>https://stackoverflow.com/questions/79355429/load-mit-bih-arrhythmia-database-without-wfdb-package</link>
      <description><![CDATA[我打算使用这个数据集，但无论我如何努力搜索，我都找不到文件中数据的格式或结构。我发现的最重要的事情是每隔两个字节就有一个 h33。我在哪里可以找到有关此内容的文档？我找不到注释与这些数据文件的关系。]]></description>
      <guid>https://stackoverflow.com/questions/79355429/load-mit-bih-arrhythmia-database-without-wfdb-package</guid>
      <pubDate>Tue, 14 Jan 2025 15:00:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 PyTorch 中保存 ViT 模型时不会生成 constants.pkl，在边缘设备上部署时是否需要它？</title>
      <link>https://stackoverflow.com/questions/79355096/why-is-constants-pkl-not-generated-when-saving-a-vit-model-in-pytorch-and-is-it</link>
      <description><![CDATA[我训练了一个 Vision Transformer (ViT) 模型进行分类，并使用以下 PyTorch 代码保存了该模型：
torch.save(model, &quot;vit_model.pth&quot;)
当我尝试将保存的模型集成到 Android 应用程序中时，我在运行时遇到了以下错误：
无法启动活动 ComponentInfo{com.test.package/com.test.package.MainActivity}：java.lang.RuntimeException：com.facebook.jni.CppException：PytorchStreamReader 无法定位文件 constants.pkl：找不到文件
我所做的：

我将 .pth 模型文件转换为 zip 文件以检查其内容，我注意到文件中不存在 constants.pkl。
我搜索了有关constants.pkl，但我找不到关于为什么它没有生成或它在这种情况下的作用的明确解释。

我的问题：

为什么使用 torch.save() 保存 PyTorch 模型时没有生成 constants.pkl？
在边缘设备（例如 Android）上部署模型是否需要 constants.pkl？
如果不需要 constants.pkl，我该如何将我的模型集成到 Android 应用程序中而不会遇到此错误？
如果需要 constants.pkl，我该如何生成它或修改我的模型保存过程以包含它？

其他信息：

模型：在 PyTorch 中训练的 Vision Transformer (ViT)。
Android 集成：使用PyTorch Android 库。
应用程序尝试加载模型文件时似乎出现错误。

我需要什么：

明确解释 constants.pkl 的作用以及它是否是 Android 上 PyTorch 模型部署的必需文件。

正确保存模型并将其集成到 Android 应用程序中以避免此问题的步骤或代码示例。

]]></description>
      <guid>https://stackoverflow.com/questions/79355096/why-is-constants-pkl-not-generated-when-saving-a-vit-model-in-pytorch-and-is-it</guid>
      <pubDate>Tue, 14 Jan 2025 13:07:19 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉变换器进行图像分类的准确率较低</title>
      <link>https://stackoverflow.com/questions/79354623/low-accuracy-using-vision-transformers-for-image-classification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79354623/low-accuracy-using-vision-transformers-for-image-classification</guid>
      <pubDate>Tue, 14 Jan 2025 10:07:15 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何工具可以将任何其他数据集格式转换为 sam2 格式以进行微调？[关闭]</title>
      <link>https://stackoverflow.com/questions/79354345/are-there-any-tools-to-convert-from-any-other-dataset-format-to-sam2-format-for</link>
      <description><![CDATA[我在 cvat 中有一个标记的数据集，但 cvat 不支持将数据卸载为 SAM2 格式。有没有可用的自动转换工具？
我可以使用 roboflow，但我有无法上传到第三方资源的数据]]></description>
      <guid>https://stackoverflow.com/questions/79354345/are-there-any-tools-to-convert-from-any-other-dataset-format-to-sam2-format-for</guid>
      <pubDate>Tue, 14 Jan 2025 08:14:24 GMT</pubDate>
    </item>
    <item>
      <title>stable_baselines3：为什么比较 ep_info_buffer 与评估时奖励不匹配？</title>
      <link>https://stackoverflow.com/questions/79353843/stable-baselines3-why-the-reward-does-not-match-comparing-ep-info-buffer-vs-eva</link>
      <description><![CDATA[我正在使用 stable_baselines3 库，这时我发现了一些意想不到的东西。
这里有一个简单的代码来重现这个问题：
import gymnasium as gym

from stable_baselines3 import DQN

env = gym.make(&quot;CartPole-v1&quot;)

model = DQN(&quot;MlpPolicy&quot;, env, verbose=0, stats_window_size=100_000)
model.learn(total_timesteps=100_000)

看看最后一集的奖励：
print(model.ep_info_buffer[-1])


{&#39;r&#39;: 409.0, &#39;l&#39;: 409, &#39;t&#39;: 54.87983

但是如果我使用以下代码评估模型：
obs, info = env.reset()
total_reward = 0
while True:
action, _states = model.predict(obs, deterministic=True)
obs, reward, termed, truncated, info = env.step(action)
total_reward = total_reward + reward
if termed or truncated:
obs, info = env.reset()
break

print(&quot;total_reward {}&quot;.format(total_reward))


total_reward 196.0

我得到了不同的奖励，这是我没有预料到的。
我预计会得到与 409 相同的奖励model.ep_info_buffer[-1]。
为什么会有这种差异？.ep_info_buffer 与每集奖励不同吗？]]></description>
      <guid>https://stackoverflow.com/questions/79353843/stable-baselines3-why-the-reward-does-not-match-comparing-ep-info-buffer-vs-eva</guid>
      <pubDate>Tue, 14 Jan 2025 02:14:32 GMT</pubDate>
    </item>
    <item>
      <title>如何检查随机森林模型是否过度拟合？</title>
      <link>https://stackoverflow.com/questions/79327542/how-to-check-if-the-model-is-overfitting-for-random-forest</link>
      <description><![CDATA[我已经为数据集实现了随机森林，并且平衡了数据，我使用了 80-10-10、70-15-15、60-20-20 和 80-20 方法。我还使用了特征重要性，并在 41 个独立特征中使用了 10 个 imp 特征、15 个 imp 特征、24 个 imp 特征和 34 个 imp 特征。所有上述方法的平均召回率为 95.8%，平均准确率为 96.6%，精确率为 97%。交叉验证召回率（我主要关注召回率）为 95.5%。
我使用训练数据对训练数据本身进行预测，得到了 99.8%
我还使用了热图并删除了 3 个高度相关的特征，但我得到了 80-10-10 的相同分数（热图之后）。
我的模型是否过度拟合？如何检查是否过度拟合？]]></description>
      <guid>https://stackoverflow.com/questions/79327542/how-to-check-if-the-model-is-overfitting-for-random-forest</guid>
      <pubDate>Fri, 03 Jan 2025 19:56:33 GMT</pubDate>
    </item>
    <item>
      <title>Vertex AI：Automl-tabular 模板不断给我一个错误</title>
      <link>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</link>
      <description><![CDATA[我正在尝试使用 Google 的 AutoML 产品 (VertexAI) 构建机器学习模型。
我已成功上传我的数据集 - 见下图。

但是，当我尝试使用 AutoML 模板为表格回归创建管道运行时，管道失败。我将在 VertexAI 上展示步骤，我只是使用默认设置而不进行任何更改：





我运行的第一个管道失败了。


我将调试 json 粘贴到 ChatGPT 中。它告诉我尝试将机器类型从 n1-standard-8 或 n1-highmem-8 更改为 n1-standard-4。我试过了，但管道仍然失败。我还确保计算服务已启用正确的设置。
]]></description>
      <guid>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</guid>
      <pubDate>Mon, 11 Nov 2024 11:41:07 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 detector2 中语义分割的每个类的像素总数</title>
      <link>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</link>
      <description><![CDATA[我想计算每个分割类的像素总数，我只需要每个一般对象的计数，例如每辆车一个类，每个人一个类等等。出于这个原因，我使用语义分割而不是实例分割（实例分割会分别考虑每个车辆或人员实例）。但detectron2中语义分割的输出没有二进制掩码。
我知道实例分割的输出是二进制掩码，可以使用以下代码获取像素数：
masks = output[&#39;instances&#39;].pred_masks 
results = torch.sum(torch.flatten(masks, start_dim=1),dim=1)

这给出了像素数，但分别考虑了每个车辆实例，这是我不想要的。
但是语义分割的输出是字段“sem_seg”，其中包含每个一般类的预测类概率而不是二元掩码，我怎样才能继续获取语义分割中每个类的像素数？]]></description>
      <guid>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</guid>
      <pubDate>Wed, 05 Jun 2024 22:40:27 GMT</pubDate>
    </item>
    <item>
      <title>机器学习还是决策树用于工作匹配？</title>
      <link>https://stackoverflow.com/questions/43319120/machinelearning-or-decisiontree-for-job-matching</link>
      <description><![CDATA[我正在开发一个工作匹配应用程序，我想知道在元素之间进行匹配以获得最佳结果的最佳方法是什么？
在我看来，这是通过决策树，因为我们已经知道元素的结构和预期结果。
但是，机器学习会是一种替代解决方案吗？或者这样做毫无价值？
我可能错了，但对我来说，机器学习对于对乍一看没有明显共同点的数据进行排序是有效的，对吗？
谢谢你的建议！]]></description>
      <guid>https://stackoverflow.com/questions/43319120/machinelearning-or-decisiontree-for-job-matching</guid>
      <pubDate>Mon, 10 Apr 2017 09:10:48 GMT</pubDate>
    </item>
    <item>
      <title>Matlab 中 Libsvm SVR 训练的数据格式</title>
      <link>https://stackoverflow.com/questions/19163090/data-format-for-libsvm-svr-training-in-matlab</link>
      <description><![CDATA[我有两个与 LIBSVM 中的数据输入相关的问题。

我是否需要将数据格式化为稀疏格式才能在 matlab 中输入 svr libsvm？
在将数据输入训练器之前，我是否需要对数据进行规范化？

我正在训练 svr，但没有做任何这些，即使格式化，我也得到了相同的结果。正如 libsvm 文档中提到的，当我们为 OCTAVE 执行数据格式化时，会使用数据格式化，因为只需运行 train.py 和 test.py 即可自动运行所有内容。但在 matlab 中我不确定。
有人可以澄清一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/19163090/data-format-for-libsvm-svr-training-in-matlab</guid>
      <pubDate>Thu, 03 Oct 2013 15:25:13 GMT</pubDate>
    </item>
    </channel>
</rss>