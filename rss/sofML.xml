<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 30 Jul 2024 21:15:42 GMT</lastBuildDate>
    <item>
      <title>如何使用 opencv 检测焊带中的缺陷（例如孔洞）</title>
      <link>https://stackoverflow.com/questions/78813507/how-can-i-detect-defectssuch-as-holes-in-this-welding-strip-using-opencv</link>
      <description><![CDATA[参考图：带孔的焊条：https://i.sstatic.net/VaVQX3th.jpg
正常焊条：https://i.sstatic.net/MBcyyIyp.jpg
我在使用 opencv 检测缺陷（如孔、不均匀性）时遇到问题。我是 opencv 新手，尝试过轮廓检测、边缘检测，但没有得到想要的结果。我想使用 opencv 构建一个算法，检测这些孔并标记它们，而不标记任何其他不必要的东西，这些东西不是缺陷。
这是我在代码中使用的方法
import cv2
import numpy as np
from matplotlib import pyplot as plt

# 加载图像
image_path = &quot;sample weld strip.jpg&quot;
image = cv2.imread(image_path)

# 将图像转换为 HSV 颜色空间
hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

# 定义焊缝条的 HSV 范围
lower_hsv = (1, 1, 1)
upper_hsv = (177, 255, 255)

# 应用 HSV 掩码
mask = cv2.inRange(hsv_image, lower_hsv, upper_hsv)
masked_image = cv2.bitwise_and(image, image, mask=mask)

# 转换为灰度
gray_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY)

# 应用高斯模糊
blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)

# 使用 Canny 进行边缘检测
edges = cv2.Canny(blurred_image, 50, 150)

# 查找轮廓
contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 在重要轮廓（孔洞）周围绘制边界框
holes_image = image.copy()
for contour in contours:
area = cv2.contourArea(contour)
if 10 &lt;area &lt; 25：# 根据您的需要调整此阈值
x, y, w, h = cv2.boundingRect(contour)
cv2.rectangle(holes_image, (x, y), (x+w, y+h), (0, 0, 255), 2)

我正在寻求有关此问题的帮助或指导。任何形式的意见或帮助都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78813507/how-can-i-detect-defectssuch-as-holes-in-this-welding-strip-using-opencv</guid>
      <pubDate>Tue, 30 Jul 2024 20:06:30 GMT</pubDate>
    </item>
    <item>
      <title>如何进行布尔分类处理</title>
      <link>https://stackoverflow.com/questions/78813351/how-to-boolean-categorical-proccessing</link>
      <description><![CDATA[将 pandas 导入为 pd
从 sklearn.impute 导入 SimpleImputer
从 sklearn.model_selection 导入 train_test_split
从 sklearn.preprocessing 导入 StandardScaler、OneHotEncoder、OrdinalEncoder
从 sklearn.pipeline 导入 Pipeline

data = pd.read_csv(&#39;Datasets/StudentScore.csv&#39;)

target = &#39;MathScore&#39;
x = data.drop(data[[target, &#39;Unnamed: 0&#39;]], axis=1)
y = data[target]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

# 数值处理
num_transformer = Pipeline(steps=[
(&#39;imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)),
(&#39;scaler&#39;, StandardScaler())
])

x_train[[&#39;ReadingScore&#39;, &#39;WritingScore&#39;]] = num_transformer.fit_transform(x_train[[&#39;ReadingScore&#39;, &#39;WritingScore&#39;]])
x_test[[&#39;ReadingScore&#39;, &#39;WritingScore&#39;]] = num_transformer.transform(x_test[[&#39;ReadingScore&#39;, &#39;WritingScore&#39;]])

# 序数处理
education_levels = [&quot;high school&quot;, &quot;some high school&quot;, &quot;some college&quot;, &quot;associate&#39;s degree&quot;, &quot;bachelor&#39;s degree&quot;,
&quot;master&#39;s degree&quot;]

ord_transformer = Pipeline(steps=[
(&#39;imputer&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;)),
(&#39;encoder&#39;, OrdinalEncoder(categories=[education_levels])),
])

x_train[[&#39;ParentEduc&#39;]] = ord_transformer.fit_transform(x_train[[&#39;ParentEduc&#39;]])
x_test[[&#39;ParentEduc&#39;]] = ord_transformer.transform(x_test[[&#39;ParentEduc&#39;]])

# 名义处理
nom_transformer = Pipeline(steps=[
(&#39;imputer&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;)),
(&#39;encoder&#39;, OneHotEncoder())
])

x_train[[&#39;EthnicGroup&#39;]] = nom_transformer.fit_transform(x_train[[&#39;EthnicGroup&#39;]])
x_test[[&#39;EthnicGroup&#39;]] = nom_transformer.transform(x_test[[&#39;EthnicGroup&#39;]])

# 布尔处理
bool_transformer = Pipeline(steps=[
(&#39;imputer&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;)),
(&#39;encoder&#39;, OneHotEncoder(sparse_output=False)),
])

x_train[[&#39;Gender&#39;, &#39;LunchType&#39;, &#39;TestPrep&#39;]] = bool_transformer.fit_transform(
x_train[[&#39;Gender&#39;, &#39;LunchType&#39;, &#39;TestPrep&#39;]])
x_test[[&#39;Gender&#39;, &#39;LunchType&#39;, &#39;TestPrep&#39;]] = bool_transformer.transform(x_train[[&#39;Gender&#39;, &#39;LunchType&#39;, &#39;TestPrep&#39;]])


我在尝试创建管道来处理布尔分类特征时遇到错误。具体来说，在训练集和测试集中的特征的 fit_transform 步骤中，我在 #nominal processing 和 #boolean processing 部分中收到了“ValueError：列的长度必须与键的长度相同”。你能帮我吗？谢谢！
`
如上所述：我在尝试创建管道来处理布尔分类特征时遇到错误。具体来说，在训练集和测试集中的特征的 fit_transform 步骤中，我在 #nominal processing 和 #boolean processing 部分中收到了“ValueError：列的长度必须与键的长度相同”。你能帮我吗？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78813351/how-to-boolean-categorical-proccessing</guid>
      <pubDate>Tue, 30 Jul 2024 19:12:18 GMT</pubDate>
    </item>
    <item>
      <title>将两类图像分类器结合在一起</title>
      <link>https://stackoverflow.com/questions/78813144/combine-two-class-of-image-classifier-together</link>
      <description><![CDATA[我制作了两个模型，一个用于狗与猫的分类（它还告诉品种），另一个用于车辆分类（它还告诉汽车的型号），有没有办法将这两个文件结合起来，以便我可以用它来预测我想要的东西（使用 API 的概念）
我的意思是说，在进行预测时，我需要在特定模型中特别上传文件，但我想知道是否有第三种方法，我只需要上传图像，然后它就会提供预测]]></description>
      <guid>https://stackoverflow.com/questions/78813144/combine-two-class-of-image-classifier-together</guid>
      <pubDate>Tue, 30 Jul 2024 18:08:20 GMT</pubDate>
    </item>
    <item>
      <title>Python 错误（类的数量必须大于一；得到 1 个类）</title>
      <link>https://stackoverflow.com/questions/78812818/python-error-the-number-of-classes-has-to-be-greater-than-one-got-1-class</link>
      <description><![CDATA[我需要创建一个 GMM 模型，并且对于每个分布，我必须训练一个 svm 模型。这是目前为止的代码。但我收到此错误（类数必须大于 1；得到 1 个类）。
如何针对每个分布训练每个 svm？
import numpy as np
from sklearn.datasets import make_blobs
from sklearn.mixture import GaussianMixture
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

# 中心数（分布）
N = 3

# 生成具有不同聚类标准差的随机数据点
n_samples = 50000
n_features = 2
cluster_std = 1.0

X, y = make_blobs(n_samples=n_samples, centers=N, n_features=n_features, 
cluster_std=cluster_std, random_state=42)

# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建并训练 GMM 模型
gmm = GaussianMixture(n_components=N, random_state=42)
gmm.fit(X_train)

# 预测训练集的聚类标签
y_train_pred = gmm.predict(X_train)

# 为每个分布训练一个 SVM 模型
svms = []
for i in range(N):
# 为当前分布过滤训练样本
X_train_i = X_train[y_train_pred == i]
y_train_i = y_train[y_train_pred == i]

# 为当前分布训练 SVM
svm = SVC(kernel=&#39;linear&#39;, random_state=42)
svm.fit(X_train_i, y_train_i)
svms.append(svm)

# 保存训练好的 SVM 模型以供将来使用
import joblib
for i, svm in enumerate(svms):
joblib.dump(svm, f&#39;svm_model_distribution_{i}.pkl&#39;)

print(&quot;SVM 训练已完成。&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78812818/python-error-the-number-of-classes-has-to-be-greater-than-one-got-1-class</guid>
      <pubDate>Tue, 30 Jul 2024 16:25:56 GMT</pubDate>
    </item>
    <item>
      <title>我写了一个代码，运行时间太长了[关闭]</title>
      <link>https://stackoverflow.com/questions/78812154/i-wrote-a-code-and-the-running-time-is-too-long</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78812154/i-wrote-a-code-and-the-running-time-is-too-long</guid>
      <pubDate>Tue, 30 Jul 2024 13:59:27 GMT</pubDate>
    </item>
    <item>
      <title>从采访脚本中提取问题和答案[关闭]</title>
      <link>https://stackoverflow.com/questions/78812091/extracting-question-and-answer-from-the-interview-script</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78812091/extracting-question-and-answer-from-the-interview-script</guid>
      <pubDate>Tue, 30 Jul 2024 13:46:06 GMT</pubDate>
    </item>
    <item>
      <title>如何判断汽车配置的相似性？</title>
      <link>https://stackoverflow.com/questions/78811479/how-to-determine-the-similarity-of-a-cars-configuration</link>
      <description><![CDATA[有一个车辆配置的数据集：

ID
品牌
型号
代数
发动机类型
发动机排量
气缸数
车身类型
变速箱类型
发动机代码
制造年份

任务：
确定一种配置与另一种配置的相似程度。
我假设将数据集中的每个条目表示为一个向量，并计算向量之间的余弦相似度。
但是对于如何以数值形式表示值存在误解，例如车身类型：轿车、跨界车、轿跑车等。]]></description>
      <guid>https://stackoverflow.com/questions/78811479/how-to-determine-the-similarity-of-a-cars-configuration</guid>
      <pubDate>Tue, 30 Jul 2024 11:38:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 opencv 提取验证码</title>
      <link>https://stackoverflow.com/questions/78810349/extract-captcha-with-opencv</link>
      <description><![CDATA[我需要提取验证码，我正在研究 opencv。我的目标是可靠地解决这种形式的验证码。
原始验证码
我的临时解决方案是：

用阈值转换二值图像
检测凸面
删除网格

但是现在我不知道下一步该怎么写代码。
有人能给我提供这个问题的关键字或解决方案吗？
我的代码：
import cv2
import numpy as np

image_path = &#39;captcha_wb.png&#39;
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

scale_percent = 200
width = int(image.shape[1] * scale_percent / 100)
height = int(image.shape[0] * scale_percent / 100)
dim = (width, height)
resized_image = cv2.resize(image, dim, interpolation = cv2.INTER_LINEAR)

# kernel = np.ones((2, 2), np.uint8) 

# 使用 cv2.erode() 方法 
# erode_image = cv2.erode(resized_image, kernel, cv2.BORDER_REFLECT)

_,thresholded_image = cv2.threshold(resized_image, 128, 255, cv2.THRESH_BINARY)

# contours, _= cv2.findContours(thresholded_image, cv2.RETR_TREE, 
# cv2.CHAIN_APPROX_SIMPLE) 

cv2.imshow(&#39;Adaptive Gaussian&#39;,thresholded_image)

如果 cv2.waitKey(0) &amp; 0xff == 27: 
cv2.destroyAllWindows() 
]]></description>
      <guid>https://stackoverflow.com/questions/78810349/extract-captcha-with-opencv</guid>
      <pubDate>Tue, 30 Jul 2024 07:38:09 GMT</pubDate>
    </item>
    <item>
      <title>CVAE 合成数据分布范围过窄</title>
      <link>https://stackoverflow.com/questions/78809995/cvae-synthetic-data-distributed-too-narrowly</link>
      <description><![CDATA[我有一个包含三个特征的数据集，两个浮点特征和一个具有 33 个类别的分类特征。（此处称为 Float_A、Float_B 和 Cat_A）。
我正在尝试训练 CVAE 以生成合成数据。使用以下 sklearn 转换器转换数据：
df=df[[&quot;float_A&quot;,&quot;float_B&quot;,&quot;categorical_A&quot;]]

transformers=[(&#39;float_A&#39;,Pipeline(steps=[(&#39;imputer&#39;,SimpleImputer(strategy=&#39;mean&#39;,add_indicator=True)),
(&#39;scaler&#39;,RobustScaler(quantile_range=(5,95)))]),
[&#39;float_A&#39;]),
(&#39;float_B&#39;,
Pipeline( steps=[(&#39;imputer&#39;,SimpleImputer(strategy=&#39;mean&#39;,add_indicator=True)),
(&#39;scaler&#39;,MinMaxScaler())]),
[&#39;float_B&#39;]),
(&#39;cats&#39;,OneHotEncoder(),categorical_columns)]`

transformer=ColumnTransformer(transformers,remainder=&#39;passthrough&#39;)

transformed_df=transformer.fit_transform(df)

我的第二个浮点数有一个 S 形激活函数，声明如下：
Def sample(self,z):
reconstructed=self.decoder(z)
# 将 S 形激活应用于浮点数特征。
reconstructed[:,self.float_B_idx]=torch.sigmoid(reconstructed[:,self.float_B_idx])
returnreconstructed

Def forward(self,x):
z_mean,z_log_var=torch.chunk(self.encoder(x),2,dim=1)
z=self.reparameterize(z_mean,z_log_var)
reconstructed=self.decoder(z)
#将 sigmoid 激活应用于浮点特征。
reconstructed[:,self.float_B_idx]=torch.sigmoid(reconstructed[:,self.float_B_idx])
return reconstructed,z_mean,z_log_var

一旦 CVAE 经过训练（训练和验证损失似乎按应有的方式减少），我尝试使用以下方法生成随机样本：
random_latent_vectors=torch.randn(num_samples,latent_dim)

使用 torch.no_grad()：
gen_df=model.sample(random_latent_vectors).detach().cpu().numpy()

但是 gen_df 中的所有样本都非常“未展开”。
FloatA、FloatB、 Cat[0:2]…

[[0.11782782 0.286538 0.646666 0.266387 0.09747571]
[0.0963359 0.29775462 0.58443785 0.29296008 0.1101962]
[0.1300626 0.31274286 0.59086925 0.30710378 0.10169853]
[0.1232817 0.32317564 0.56470346 0.29102385 0.11446829]
[0.13240162 0.28100765 0.6230704 0.29497638 0.08924796]]

然后，当我在 gen_df 上调用 scaler.inverse_transform 时，我几乎在每一行上都得到了相同的结果。
我尝试了各种方法，我的一个类别非常占主导地位（~90%），因此使用 imblearn 进行了一些类别不平衡欠采样，使其仅占 50% 的主导地位，但仍然获得 100% 的样本。
我尝试为我的 CVAE 添加更多层和复杂性，但再次被证明是徒劳的。]]></description>
      <guid>https://stackoverflow.com/questions/78809995/cvae-synthetic-data-distributed-too-narrowly</guid>
      <pubDate>Tue, 30 Jul 2024 05:57:45 GMT</pubDate>
    </item>
    <item>
      <title>RNN 建模数据准备</title>
      <link>https://stackoverflow.com/questions/78809490/rnn-modelling-data-preparation</link>
      <description><![CDATA[我正在准备用于 rnn 模型的顺序数据，但我将时间数据放在不同的列中，其中天数格式为 0 表示工作日，1 表示周末。时间是否应采用单一数据格式列以用于模型？
此外，我还应该如何准备数据以计算与传感器数据的距离。我添加了数据和距离问题的屏幕截图。
在此处输入图片说明
在此处输入图片说明]]></description>
      <guid>https://stackoverflow.com/questions/78809490/rnn-modelling-data-preparation</guid>
      <pubDate>Tue, 30 Jul 2024 01:26:23 GMT</pubDate>
    </item>
    <item>
      <title>通过预训练模型预测对象不起作用</title>
      <link>https://stackoverflow.com/questions/78809007/predicting-an-object-over-an-pretrained-model-is-not-working</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78809007/predicting-an-object-over-an-pretrained-model-is-not-working</guid>
      <pubDate>Mon, 29 Jul 2024 20:50:17 GMT</pubDate>
    </item>
    <item>
      <title>TFLM“Interpreter->Invoke()”问题导致硬故障</title>
      <link>https://stackoverflow.com/questions/78808999/issues-with-tflm-interpreter-invoke-causing-hard-fault</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78808999/issues-with-tflm-interpreter-invoke-causing-hard-fault</guid>
      <pubDate>Mon, 29 Jul 2024 20:48:04 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降应用</title>
      <link>https://stackoverflow.com/questions/78804107/gradient-descent-application</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78804107/gradient-descent-application</guid>
      <pubDate>Sun, 28 Jul 2024 15:15:45 GMT</pubDate>
    </item>
    <item>
      <title>保存视频中每帧的边界框坐标</title>
      <link>https://stackoverflow.com/questions/30060567/saving-bounding-box-coordinates-for-each-frame-in-a-video</link>
      <description><![CDATA[我有一段摄像机拍摄的视频，场景中有人。我需要浏览该视频的每一帧，并手动保存场景中检测到的人的边界框的坐标（浏览每一帧并在每个人周围画出一个正方形）和头部中心的坐标 - 基本上就是左上、右下、头部中心坐标。边界框必须是正方形。
然后，附加程序将读取一个文件，其中包含正方形和头部中心的坐标以及帧号，并将这些框提取为图像。
对于任何有计算机视觉经验的人来说 - 是否有任何开源软件可以完成我的要求？如果没有，您会推荐使用什么技术来构建此工具？有入门代码吗？]]></description>
      <guid>https://stackoverflow.com/questions/30060567/saving-bounding-box-coordinates-for-each-frame-in-a-video</guid>
      <pubDate>Tue, 05 May 2015 18:27:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit-learn 在朴素贝叶斯分类器中混合分类数据和连续数据</title>
      <link>https://stackoverflow.com/questions/14254203/mixing-categorial-and-continuous-data-in-naive-bayes-classifier-using-scikit-lea</link>
      <description><![CDATA[我正在使用 Python 中的 scikit-learn 开发一种分类算法来预测某些客户的性别。除此之外，我想使用朴素贝叶斯分类器，但我的问题是我有分类数据（例如：“在线注册”、“接受电子邮件通知”等）和连续数据（例如：“年龄”、“会员期限”等）的混合。我以前没有用过 scikit，但我认为高斯朴素贝叶斯适合连续数据，而伯努利朴素贝叶斯可用于分类数据。但是，由于我想在我的模型中同时拥有分类数据和连续数据，我真的不知道如何处理这个问题。任何想法都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/14254203/mixing-categorial-and-continuous-data-in-naive-bayes-classifier-using-scikit-lea</guid>
      <pubDate>Thu, 10 Jan 2013 09:08:22 GMT</pubDate>
    </item>
    </channel>
</rss>