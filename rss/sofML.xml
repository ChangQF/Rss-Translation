<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 13 May 2024 06:20:21 GMT</lastBuildDate>
    <item>
      <title>在 Python ML 中，我的 RMSE 和 MAE 始终计算为 0 尽管步骤正确，但我不确定问题出在哪里 对于下一步该做什么有什么建议吗？</title>
      <link>https://stackoverflow.com/questions/78470290/in-python-ml-both-my-rmse-mae-are-consistently-calculated-as-0-despite-correct</link>
      <description><![CDATA[# 这是我的代码

X = store1.drop([&#39;商店&#39;,&#39;日期&#39;,&#39;Holiday_Flag&#39;,&#39;天数&#39;,&#39;温度&#39;], axis=1)
y = store1[&#39;Weekly_Sales&#39;]

# 缩放预测数据
从 sklearn.preprocessing 导入 StandardScaler
sc = 标准缩放器()
X_sc = sc.fit_transform(X)

从 sklearn.model_selection 导入 train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_sc, y, test_size=0.2, random_state=21)

从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.metrics 导入mean_absolute_error，mean_squared_error
lin_reg = 线性回归()
lin_reg.fit(X_train, y_train)
y_pred = lin_reg.predict(X_test)

print(&quot;MAE: {}&quot; .format(mean_absolute_error(y_test, y_pred)))
print(&quot;RMSE: {}&quot; .format(mean_squared_error(y_test, y_pred)))

笔记本图片(https://i.sstatic.net/Z48nX8dm.png ）
这似乎是正确的，但如此高的准确性确实是我寻求知识渊博的指导的一个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78470290/in-python-ml-both-my-rmse-mae-are-consistently-calculated-as-0-despite-correct</guid>
      <pubDate>Mon, 13 May 2024 05:55:23 GMT</pubDate>
    </item>
    <item>
      <title>我想在输入问题时预测标签</title>
      <link>https://stackoverflow.com/questions/78469857/i-want-to-predict-tags-when-input-the-questions</link>
      <description><![CDATA[`问题=“facetgrid数据标签seaborn”
标签 = “python pandas seaborn”
我在小数据集中使用 MLPClassifier，但实际数据形状是 262529。为此使用哪种算法。我提供我的代码
从 sklearn.neural_network 导入 MLPClassifier
来自 sklearn.feature_extraction.text
导入CountVectorizer
来自 sklearn.model_selection
导入train_test_split
来自 sklearn.metrics
导入准确度_分数
df_half = df.iloc[:int(len(df)*0.1)]q = df_half[&#39;Question&#39;]t = [tags.split() for df_half[&#39;Tags&#39;]]向量化器中的标签= countvectorizer（）x_vectorized1 = vectorizer.fit_transform（q）label_binarizer = multiLabelBinarizer（）y_binarized1 = label_binarizer.fit_transform（t） 2，Random_State = 42）分类器= mlpClassifier (hidden_​​layer_sizes=(100,), max_iter=100, alpha=0.0001,solver=&#39;adam&#39;, verbose=10, random_state=42, tol=0.0001)classifier.fit(X_train1, y_train1)y_pred1 = classifier.predict(X_train1) 
准确度=准确度_得分（y_train1，y_pred1）
print(“准确度：”, 准确度)
精度：0.9964`
我想预测问题​​明智的标签以及算法使用的大数据集中的问题。我正在尝试
TF-IDF
纳维贝叶斯
线性支持向量机
随机森林（RF）`]]></description>
      <guid>https://stackoverflow.com/questions/78469857/i-want-to-predict-tags-when-input-the-questions</guid>
      <pubDate>Mon, 13 May 2024 02:42:40 GMT</pubDate>
    </item>
    <item>
      <title>我如何进一步推进这个 AI/ML 项目？</title>
      <link>https://stackoverflow.com/questions/78469835/how-can-i-proceed-further-in-this-ai-ml-project</link>
      <description><![CDATA[我有 10 个数据集 (.csv)，每个数据集有 100,000 行，每行包含 5 个输入（-4.0f 到 +4.0f）和一个输出列 (0/1)。我想使用它来训练神经网络并预测给定的测试数据集（也有 100,000 行，但没有填充输出列）。
我想创建一个 5--(reLU)--&gt; 32 --(reLU)--&gt; 32 --（乙状结肠） --&gt; 1 个神经网络并用这样的奖励系统对其进行训练 [if (expec.op ==0)reward=1- o/pfromNN; if (expec.op ==1) 奖励= o/pfromNN].
如何使用此调整 NN 的权重或如何进一步进行？我是 NN 的新手。
我想过像体育馆的月球着陆器模块一样这样做，但由于这里没有涉及任何州，我很困惑]]></description>
      <guid>https://stackoverflow.com/questions/78469835/how-can-i-proceed-further-in-this-ai-ml-project</guid>
      <pubDate>Mon, 13 May 2024 02:25:15 GMT</pubDate>
    </item>
    <item>
      <title>如何将 standardscaler() 用于具有多列的单行的 Predict() 函数？</title>
      <link>https://stackoverflow.com/questions/78469729/how-to-use-standardscaler-for-the-predict-function-for-a-single-row-having-m</link>
      <description><![CDATA[很抱歉，如果我的描述含糊不清。
我正在尝试建立一个房价预测系统。数据有异常值并且是非高斯的，对于目标特征 y，使用对数变换。在进行一项热编码之前，我已经使用 StandardScaler() 来适合我的模型。代码如下所示：
numerical_features = df4[[&#39;bhk&#39;, &#39;面积&#39;, &#39;price_lakhs&#39;, &#39;price_per_sqft&#39;]]
categorical_features = df4.select_dtypes(include=[&#39;object&#39;])

定标器=标准定标器()
Standardized_features = scaler.fit_transform(numerical_features)

std_df4 = pd.DataFrame(standardized_features, columns=numerical_features.columns)
std_df4.head()

现在为了预测新值，我使用了这个 Predict_price() 函数。我很难理解如何像上面的代码块一样做到这一点。我将数值和分类值分开。我不能在下面做同样的事情。这段代码工作错误，我认为列 x[3:] 中的一个热编码值也可能已被缩放，这不是上层代码的工作方式。我使用的任何回归模型[下面代码中的 clf.predict()] 对于下面的 Predict() 输入的不同值给出相同的答案。
def Predict_price（bhk，面积，price_per_sqft，类型，区域）：
    
    house_type_loc_index = np.where(X.columns == &#39;type_&#39; + type)[0][0]
    打印（房屋类型位置索引）
    
    Region_loc_index = np.where(X.columns == &#39;region_&#39; + 区域)[0][0]
    打印（region_loc_index）

    x = np.zeros(len(X.columns))
    x[0] = bhk
    x[1] = 面积
    x[2] = 每平方英尺价格
    
    如果 house_type_loc_index &gt;= 0：
        x[房屋类型位置索引] = 1
        
    如果region_loc_index &gt;= 0：
        x[区域位置索引] = 1
    
    列 = X.列
    x = x.reshape(1, -len(列))

    定标器=标准定标器()
    标准化特征 = 缩放器.fit_transform(x)
    数据 = pd.DataFrame(standardized_features, columns = columns)
    
    打印（数据）
    
    ans = clf.predict(数据)[0]
    返回exp(ans)

我期望模型能够根据我给预测函数的输入来预测值。预测函数的调用如下。
predict_price(bhk = 2，面积 = 2000，price_per_sqft = 35，类型 = &#39;公寓&#39;，区域 = &#39;Airoli&#39;)

我得到的答案是：42.6103853222858455
predict_price(bhk = 3，面积 = 600，price_per_sqft = 70，类型 = &#39;别墅&#39;，区域 = &#39;Vashi&#39;)

我得到的答案是：42.6103853222858455
我进一步检查，对于上面的 Predict_price() 行，它收到的每个值都是 0。这就是为什么我强烈认为我在 Predict() 中错误地使用了 standardScaler()
bhk面积价格_每尺户型_公寓户型_独立屋\
0 0.0 0.0 0.0 0.0 0.0

   类型_顶层公寓类型_单间公寓类型_别墅区_阿格里帕达\
0 0.0 0.0 0.0 0.0

   地区_艾罗利 ... 地区_瓦赛 地区_瓦希 地区_维赫罗利 \
0 0.0 ... 0.0 0.0 0.0

   地区_Ville Parle East 地区_Ville Parle West 地区_Virar \
0 0.0 0.0 0.0

   地区_Virar West 地区_Wadala 地区_Worli 地区_other
0 0.0 0.0 0.0 0.0
]]></description>
      <guid>https://stackoverflow.com/questions/78469729/how-to-use-standardscaler-for-the-predict-function-for-a-single-row-having-m</guid>
      <pubDate>Mon, 13 May 2024 01:25:36 GMT</pubDate>
    </item>
    <item>
      <title>随机森林机器学习</title>
      <link>https://stackoverflow.com/questions/78469722/random-forest-machine-learning</link>
      <description><![CDATA[我做了一个模型预测，准确率达到 80%。您可以在此处.
现在，我想要进行案例实现，所以我制作随机数据帧，其中包含 100 行数据，其与训练数据具有完全相同的特征，但是当我运行它时，它会抛出这样的错误...
`ValueError：调用输入形状与训练期间提供的输入形状不同的模型：训练模型时输入单个数组 Tensor(“inputs:0”, shape=(None, 27), dtype=float32)在{&#39;SeniorCitizen&#39;：，&#39;合作伙伴&#39;：，&#39;家属&#39;：，&#39;PhoneService&#39;：、&#39;MultipleLines&#39;: 、&#39;OnlineSecurity&#39;: 、&#39;OnlineBackup&#39;: 、&#39;DeviceProtection&#39;: 、&#39;TechSupport&#39;: 、&#39;StreamingTV&#39;: 、&#39;StreamingMovies&#39;: 、&#39;无纸化账单&#39;: &lt; ;Semantic.NUMERICAL: 1&gt;, &#39;gender_Female&#39;: , &#39;gender_Male&#39;: , &#39;InternetService_DSL&#39;: , &#39;InternetService_Fiber_optic&#39; : 、&#39;InternetService_No&#39;: 、&#39;Contract_Month-to-month&#39;: 、&#39;Contract_One_year&#39;: , &#39;Contract_Two_year&#39;: , &#39;PaymentMethod_Bank_transfer_(automatic)&#39;: , &#39;PaymentMethod_Credit_card_(automatic)&#39;: , &#39;PaymentMethod_Electronic_check &#39;: , &#39;PaymentMethod_Mailed_check&#39;: , &#39;tenure&#39;: , &#39;MonthlyCharges&#39;: , “TotalCharges”：&lt;语义.数值：1&gt;}。
调用层“random_forest_model”接收的参数（类型 RandomForestModel）：
  输入=tf.Tensor（形状=（无，27），dtype=float32）
  • 训练=False`

我很确定train和随机df的列数是相同的，列的名称是相同的，dtype是相同的。我不知道该怎么办了，请帮助我。
您可以在此处查看所有错误消息
我用来制作随机 100 行数据框的代码此处
解决问题]]></description>
      <guid>https://stackoverflow.com/questions/78469722/random-forest-machine-learning</guid>
      <pubDate>Mon, 13 May 2024 01:17:18 GMT</pubDate>
    </item>
    <item>
      <title>在 Streamlit.io 上部署 Python 应用程序时出错：“sklearn”的 ModuleNotFoundError</title>
      <link>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</link>
      <description><![CDATA[在此处输入图片说明
标题：在 Streamlit.io 上部署 Python 应用程序时出错：“sklearn”的 ModuleNotFoundError
描述：
我在 Streamlit.io 上部署 Python 应用程序时遇到错误。尽管在我的 requests.txt 文件中列出了“scikit-learn”，但我在部署过程中遇到了 ModuleNotFoundError。]]></description>
      <guid>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</guid>
      <pubDate>Sun, 12 May 2024 23:18:51 GMT</pubDate>
    </item>
    <item>
      <title>更改层数据类型后的 Keras分段_模型 nan 损失</title>
      <link>https://stackoverflow.com/questions/78469320/keras-segmentation-model-nan-loss-after-changing-layer-dtype</link>
      <description><![CDATA[我正在尝试解决二进制分割问题，我需要从背景中对树进行分类。我的数据预处理函数非常简单，如下所示：
def get_data(a, 路径, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3):
  输出 = np.zeros((len(a), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
  对于 i，enumerate(a) 中的 image_id：
    图像路径 = 路径 + 图像 ID
    图像 = np.array(Image.open(path_image))
    图像=调整大小（图像，（IMG_HEIGHT，IMG_WIDTH），模式=&#39;常量&#39;，保留_范围=真）
    如果 image.shape[-1] == IMG_WIDTH:
      图像 = np.expand_dims(图像, 轴=-1)
    输出[i] = 图像
  返回

图像采用 .tif 格式。
X_train = np.zeros((len(img_list), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)
Y_train = np.zeros((len(mask_list), IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)
X_test = np.zeros((len(img_test), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)

X_train = get_data(img_list, “/content/train/images/”)
Y_train = get_data(mask_list, “/content/train/gt/”, IMG_CHANNELS=1)
X_test = get_data(img_test, “/content/public_test/images/”)

数据形状：
X_train.shape、Y_train.shape、X_test.shape

((2828, 256, 256, 3), (2828, 256, 256, 1), (707, 256, 256, 3))

起初，我的所有数据都是 uint8 类型。但是，我在调用 model.fit(...) 时收到此错误：
类型错误：“Mul”运算的输入“y”的类型为 uint8，与参数“x”的 float32 类型不匹配。

但是当我将数据更改为 np.float32 时，我的 Google Colab 会话在训练时崩溃了。我想知道是否可以将模型数据类型从 float32 更改为占用更少空间的内容，例如 float16 并检查它是否有帮助。我尝试这样做：
a = model.get_config()
对于 a[&#39;layers&#39;] 中的层：
  层[&#39;config&#39;][&#39;dtype&#39;]=&#39;float16&#39;

模型 = model.from_config(a)
model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;)

当我尝试训练模型时，输出如下（RAM 持续缓慢增长）：
纪元 1/100
160/160 [================================] - ETA：0秒 - 损失：nan
Epoch 1：val_loss 没有从 inf 改善
160/160 [================================] - 73s 180ms/步 - 损失：nan - val_loss：nan
纪元 2/100
160/160 [================================] - ETA：0秒 - 损失：nan
Epoch 2：val_loss 没有从 inf 改善
160/160 [================================] - 19s 121ms/步 - 损失：nan - val_loss：nan
纪元 3/100
 45/160 [=======&gt;.................................] - 预计到达时间：13 秒 - 损失：nan

所以我的问题是：为什么损失总是 nan 以及解决该问题的其他方法是什么？
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78469320/keras-segmentation-model-nan-loss-after-changing-layer-dtype</guid>
      <pubDate>Sun, 12 May 2024 21:16:48 GMT</pubDate>
    </item>
    <item>
      <title>确定某些公司名称是否相同的模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78469183/model-to-determine-if-certain-company-names-are-the-same</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78469183/model-to-determine-if-certain-company-names-are-the-same</guid>
      <pubDate>Sun, 12 May 2024 20:10:11 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow ImportError：未定义符号：_ZTIN6snappy4SinkE</title>
      <link>https://stackoverflow.com/questions/78468933/tensorflow-importerror-undefined-symbol-ztin6snappy4sinke</link>
      <description><![CDATA[我尝试在 conda Python 环境中导入 TensorFlow，但遇到以下错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ImportError Traceback（最近一次调用最后一次）
第 1 行 [2] 中的单元格
----&gt; 1 将张量流导入为tf
2 设备名称 = tf.test.gpu_设备名称()
4 如果 device_name != &quot;/device:GPU:0&quot;:
文件〜/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/__init__.py:40
37导入打字为_typing
39 # 不要删除这一行；请参阅https://github.com/tensorflow/tensorflow/issues/42596
---&gt; 40 from tensorflow.python import pywrap_tensorflow # pylint:disable=unused-import
41 从tensorflow.python.tools导入module_util作为_module_util
42 从tensorflow.python.util.lazy_loader导入LazyLoader as _LazyLoader
文件〜/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py:34
29 从tensorflow.python.platform导入self_check
31 # TODO(mdan)：清理反模式：导入以消除副作用。
32
33 # 执行预加载健全性检查，以产生更具可操作性的错误。
---&gt; 34 self_check.preload_check()
36 # pylint: 禁用=通配符导入，g-导入不在顶部，未使用的导入，行太长
38 尝试：
39 # 如果存在显式共享对象，则此导入预计会失败
40 # 依赖项（with_framework_lib=true），因为我们不需要 RTLD_GLOBAL。
文件 ~/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/python/platform/self_check.py:63，在 preload_check() 中
50 引发导入错误（
51 “找不到 DLL %r。 TensorFlow 要求这些 DLL“
52 “安装在您的 %%PATH%% 中指定的目录中”
（...）
56“https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads”
57%”或“.join(缺失))
58 其他：
59 # 加载执行CPU功能保护检查的库。在这里做这个
60 # 作为预加载检查使我们更有可能检测到任何 CPU 功能
61 # 在我们触发它们之前不兼容（这通常会导致
62# 信号）。
---&gt; 63 从tensorflow.python.platform导入_pywrap_cpu_feature_guard
64 _pywrap_cpu_feature_guard.InfoAboutUnusedCPUFeatures()
导入错误：/home/gimhara/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2：未定义符号：_ZTIN6snappy4SinkE

我使用的是安装在 Ubuntu 22.04 上的 Anaconda 环境中的 Python 3.11 和 TensorFlow v2.15.0。
根据我的研究，此错误似乎与 TensorFlow 使用的 Snappy 压缩库版本缺失或不兼容有关。
我已尝试以下步骤来解决该问题：

使用 pip 和 conda 重新安装 TensorFlow。

在 Ubuntu 上安装 libsnappy-dev 软件包。


但是，到目前为止，这些步骤都没有解决问题。
任何人都可以提供有关如何正确解决此 ImportError 并让 TensorFlow 正确运行的指导吗？
如果您需要任何其他信息，或者我是否应该提供有关我的设置或迄今为止已采取的步骤的更多详细信息，请告诉我。
预先感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78468933/tensorflow-importerror-undefined-symbol-ztin6snappy4sinke</guid>
      <pubDate>Sun, 12 May 2024 18:40:19 GMT</pubDate>
    </item>
    <item>
      <title>K-Means：如何解决错误：scatter() 得到参数“c”的多个值</title>
      <link>https://stackoverflow.com/questions/78468674/k-means-how-to-solve-error-scatter-got-multiple-values-for-argument-c</link>
      <description><![CDATA[我是机器学习新手，我有一项任务要求我执行无监督学习，因此我决定使用 K-Means。
我使用Python来编码。我已将数据（我的数据来自 csv 文件）导入到 Google Colab 中。我的数据有 7 个特征，我需要绘制簇，但出现错误：scatter() 获得了参数“c”的多个值。
这是我的代码：
这部分是我决定 k 值的方法。我使用肘部法。
%matplotlib 内联
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns； sns.set()
将 numpy 导入为 np
将 pandas 导入为 pd

从 sklearn.cluster 导入 KMeans

数据=“/内容/信息.csv”
df = pd.read_csv（数据，标题=0）
data = list(zip(x_train[“日期”], x_train[“a”], x_train[“b”], x_train[“c”], x_train[“d”], x_train[“” e&quot;], x_train[&quot;f&quot;]))
打印（数据）

惯性 = []

对于范围 (1,40) 内的 i：
    kmeans = KMeans(n_clusters=i)
    kmeans.fit(数据)
    惯性.append(kmeans.inertia_)

plt.plot（范围（1,40），惯性，标记=&#39;o&#39;）
plt.title(&#39;弯头法&#39;)
plt.xlabel(&#39;簇数&#39;)
plt.ylabel(&#39;惯性&#39;)
plt.show()

这就是出错的地方：
kmeans = KMeans(n_clusters=5)
kmeans.fit(数据)
plt.scatter(x_train[“日期”], x_train[“a”], x_train[“b”], x_train[“c”], x_train[“d”], x_train[“e” ], x_train[&quot;f&quot;], c=kmeans.labels_)
plt.show()

该错误似乎表明出错的部分位于 plt.scatter() 行。
我尝试了 2 个功能，它可以工作，但是当涉及 7 个功能时，我收到错误消息。可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78468674/k-means-how-to-solve-error-scatter-got-multiple-values-for-argument-c</guid>
      <pubDate>Sun, 12 May 2024 17:07:02 GMT</pubDate>
    </item>
    <item>
      <title>使用Torchaudio库创建数据集时出错</title>
      <link>https://stackoverflow.com/questions/78466420/error-when-using-torchaudio-library-to-create-a-data-set</link>
      <description><![CDATA[我正在学习 YT 课程，研究使用 Torchaudio 的城市 8k 数据集。作者编写了完全相同的代码，但在我收到此错误时能够获得输出：
&lt;块引用&gt;
运行时错误：找不到适当的后端来处理 uri C:\Users\hbhavnag\Documents\Hussain\ASU\collision detector\urban sound\UrbanSound8K\audio\5\100263-2-0-121.wav 和格式无。

以下是我的代码：
from torch.utils.data import 数据集
将 pandas 导入为 pd
导入火炬音频
导入操作系统

UrbanSoundDataset 类（数据集）：

    def __init__(自身,annotation_file,audio_dir):
        self.annotations = pd.read_csv(annotation_file)
        self.audio_dir = 音频_dir

    def __len__(自身):
        返回 len(self.annotations)

    def __getitem__(自身，索引)：
        audio_sample_path = self._get_audio_sample_path(索引)
        标签 = self._get_audio_sample_label(索引)
        信号，sr = torchaudio.load（audio_sample_path）
        返回信号、标签
    
    def _get_audio_sample_path（自身，索引）：
        Fold = f“fold{self.annotations.iloc[index,5]}”
        路径 = os.path.join(self.audio_dir, 折叠, self.annotations.iloc[index,0])
        返回路径
    
    def _get_audio_sample_label（自身，索引）：
        返回 self.annotations.iloc[index,6]
    
    如果 __name__ == “__main__”：
        注释_文件 = r“C:\Users\hbhavnag\Documents\Hussain\ASU\碰撞检测\城市声音\UrbanSound8K\metadata\UrbanSound8K.csv”
        audio_dir = r&quot;C:\Users\hbhavnag\Documents\Hussain\ASU\碰撞检测\城市声音\UrbanSound8K\audio&quot;
        usd = UrbanSoundDataset（注释文件，音频目录）
        print (f“数据集中有 {len(usd)} 个样本”)

    信号，标签 = 美元[2]

我尝试查找 Torchaudio 的文档，但不确定是否有任何内容可以直接帮助我。我假设存在一些版本兼容性问题。
我使用的是 Windows。]]></description>
      <guid>https://stackoverflow.com/questions/78466420/error-when-using-torchaudio-library-to-create-a-data-set</guid>
      <pubDate>Sun, 12 May 2024 00:34:24 GMT</pubDate>
    </item>
    <item>
      <title>我如何在 django web 上显示终端输出和 matplotlib 图形</title>
      <link>https://stackoverflow.com/questions/78465419/how-can-i-show-the-terminal-output-and-matplotlib-graphic-on-django-web</link>
      <description><![CDATA[我不知道该怎么做。这是我的 py 代码。 #
&lt;前&gt;&lt;代码&gt;
虹膜 = load_iris()
X = 虹膜数据
y = 虹膜.目标

plt.figure(figsize=(10, 6))
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=&#39;viridis&#39;)
plt.xlabel(&#39;萼片长度&#39;)
plt.ylabel(&#39;萼片宽度&#39;)
plt.title(&#39;Iris Veri Seti&#39;)
plt.colorbar(标签=&#39;类&#39;)
plt.show()
Veri setini eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)

分类器={
    “决策树”：DecisionTreeClassifier()，
    “随机森林”：RandomForestClassifier(),
    “梯度提升”：GradientBoostingClassifier()，
    “AdaBoost”：AdaBoostClassifier()
}

结果={}
对于名称，clf in classifiers.items()：
    clf.fit(X_train_scaled, y_train)
    y_pred = clf.predict(X_test_scaled)
    准确度=准确度_分数（y_test，y_pred）
    精度 = precision_score(y_test, y_pred, 平均值=&#39;加权&#39;)
    召回率=召回率（y_test，y_pred，平均值=&#39;加权&#39;）
    f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)
    results[name] = {“Accuracy”：准确率，“Precision”：精确率，“Recall”：召回率，“F1 Score”：f1}

print(&quot;Sınıflandırma Algoritması\tAccuracy\tPrecision\tRecall\tF1 Score&quot;)
对于名称，results.items() 中的指标：
    print(f&quot;{name}\t{metrics[&#39;Accuracy&#39;]:.4f}\t{metrics[&#39;Precision&#39;]:.4f}\t{metrics[&#39;Recall&#39;]:.4f}\t{metrics [&#39;F1 分数&#39;]:.4f}&quot;)


有没有简单的方法可以在网页上拍摄它？可以是 django 或其他东西，但它必须在网页上。
这是 matplotlib 输出
这是终端的输出]]></description>
      <guid>https://stackoverflow.com/questions/78465419/how-can-i-show-the-terminal-output-and-matplotlib-graphic-on-django-web</guid>
      <pubDate>Sat, 11 May 2024 16:56:57 GMT</pubDate>
    </item>
    <item>
      <title>我可以在我的 Flutter 应用程序中集成将执行语音命令的自定义 AI 模型吗？</title>
      <link>https://stackoverflow.com/questions/78458925/can-i-integrate-custom-ai-model-which-will-do-on-voice-commands-in-my-flutter-ap</link>
      <description><![CDATA[我想知道，因为我与人工智能并没有密切相关并集成它，也没有尝试过，是否有可能集成某种定制的人工智能模型来完成下一步的事情，例如：“嘿，你可以转到我的个人资料设置吗”。对于结果，我希望该人工智能模型能够自动响应我的导航到个人资料屏幕。我不知道这对于 Flutter 是否可行。
我做了一些研究，建议使用语音转文本，反之亦然，Tflite、Pytorch 等。通过他们自己的文本到语音转换功能，我可以从语音中获取文本，并基于它创建执行特定任务的函数（例如导航到我的应用程序中的配置文件设置）。但我不太确定是否要使用自定义 AI。
这只是一个研究问题，如果有人对此有更多了解，并且我需要随意加入对话以帮助我更多地了解这一点..提前致谢！ ：D
没什么——只是一项研究。]]></description>
      <guid>https://stackoverflow.com/questions/78458925/can-i-integrate-custom-ai-model-which-will-do-on-voice-commands-in-my-flutter-ap</guid>
      <pubDate>Fri, 10 May 2024 08:36:43 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 实验跟踪重复</title>
      <link>https://stackoverflow.com/questions/76821347/sagemaker-experiment-tracking-duplication</link>
      <description><![CDATA[我正在尝试通过 AWS SageMaker 使用脚本模式训练模型。
我想使用 AWS SageMaker Experiments 以及训练作业中的一些计算指标来跟踪此训练作业。当我开始训练作业时，会成功创建一个新的实验运行，该实验运行跟踪所有提供的超参数（例如，nesimators）。
但是，如前所述，此外，我还想跟踪自定义脚本中的其他指标（例如准确性）。在这里，我在拟合模型之前使用 load_run()，然后使用 run.log_metric() 记录指标。但是，当我这样做时，SageMaker 会在 UI 中创建一个新的单独实验条目，这意味着我的超参数和指标单独存储在两个单独的实验运行中：

我希望在一次实验运行中看到所有指标和超参数的组合。我做错了什么？
这是我用来启动训练过程的缩写代码：
&lt;前&gt;&lt;代码&gt;
exp_name = “sklearn-脚本模式-实验”

与运行（
    实验名称=实验名称，
    sagemaker_session=sess,
）运行时：

    sklearn_estimator = SKLearn(&#39;train.py&#39;,
                                    instance_type=&#39;ml.m5.large&#39;,
                                    Framework_version=&#39;1.0-1&#39;,
                                    role=“arn:aws:iam:::role/service-role/AmazonSageMaker-ExecutionRole-”,
                                    超参数={&#39;nestimators&#39;: 100},
                                    环境={“区域”：区域}）

    sklearn_estimator.fit({&#39;train&#39;: f&#39;s3://{BUCKET}/{S3_INPUT_PATH}&#39;})

这是缩写的train.py：
 #在这里解析参数...等等...


    模型 = RandomForestClassifier(n_estimators=args.nesimators,
                                   最大深度=5，
                                   随机状态=1）

    使用 load_run(sagemaker_session=sagemaker_session) 作为运行：

        模型.fit(X, y)

        run.log_metric(name = &quot;最终测试损失&quot;, value = 0.9)
]]></description>
      <guid>https://stackoverflow.com/questions/76821347/sagemaker-experiment-tracking-duplication</guid>
      <pubDate>Wed, 02 Aug 2023 15:20:27 GMT</pubDate>
    </item>
    <item>
      <title>每个示例使用多个类别对分类特征进行编码</title>
      <link>https://stackoverflow.com/questions/57752264/encode-a-categorical-feature-with-multiple-categories-per-example</link>
      <description><![CDATA[我正在处理一个数据集，该数据集的一个特征是单个示例具有多个类别。
该功能如下所示：- 

&lt;前&gt;&lt;代码&gt;功能
0 [类别 1、类别 2、类别 2、类别 4、类别 5]
1 [类别 11、类别 20、类别 133]
2 [类别2、类别9]
3 [类别1000、类别1200、类别2000]
4 [类别12]

该问题与发布的问题类似：- 每个示例使用多个类别对分类特征进行编码 - sklearn
现在，我想向量化这个特征。一种解决方案是按照上述类似问题的答案中的建议使用 MultiLabelBinarizer。但是，大约有 2000 个类别，这导致编码数据稀疏且维数非常高。
还有其他可以使用的编码吗？或者这个问题的任何可能的解决方案。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/57752264/encode-a-categorical-feature-with-multiple-categories-per-example</guid>
      <pubDate>Mon, 02 Sep 2019 06:25:01 GMT</pubDate>
    </item>
    </channel>
</rss>