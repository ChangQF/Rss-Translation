<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 23 Mar 2024 18:15:15 GMT</lastBuildDate>
    <item>
      <title>多元多步时间序列预测问题</title>
      <link>https://stackoverflow.com/questions/78211600/a-multivariate-multi-step-time-series-prediction-problem</link>
      <description><![CDATA[我有一个多元多步时间序列预测问题，其中输入 waterA、waterB、waterC、medicineA、medicineB，并输出浊度。
在此处输入图片说明
其中，药物A和药物B是可控的，而三类水是不可控的。
我使用 LSTM 模型使用前 15 个数据点来预测接下来的 15 个数据点（假设 15 个数据点代表 1 小时）。以下是测试集上的一些结果。
在此处输入图片说明
在此处输入图片描述
如果我根据当前时刻过去的数据预测下一小时的浊度。但此刻我打算改变用药量，并预测未来一个多小时的浊度（主要是改变用药对未来浊度的影响），但我不知道三种水的未来值。我曾经尝试使用三个 LSTM 来预测三种类型的未来水，而不是未来的水输入，但这会导致更糟糕的预测结果。还有其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78211600/a-multivariate-multi-step-time-series-prediction-problem</guid>
      <pubDate>Sat, 23 Mar 2024 16:27:56 GMT</pubDate>
    </item>
    <item>
      <title>Google Colab：ImportError：无法从“imblearn.over_sampling”导入名称“MLSMOTE”</title>
      <link>https://stackoverflow.com/questions/78211346/google-colab-importerror-cannot-import-name-mlsmote-from-imblearn-over-samp</link>
      <description><![CDATA[我正在尝试使用 imblearn 库中的 MLSMOTE 包：
从 imblearn.over_sampling 导入 MLSMOTE

收到以下错误消息：
无法从“imblearn.over_sampling”导入名称“MLSMOTE”
不平衡学习包信息：
名称：不平衡学习
版本：0.12.0
摘要：机器学习中不平衡数据集的工具箱。
主页：https://github.com/scikit-learn-contrib /不平衡学习
作者：
作者电子邮件：
许可证：麻省理工学院
位置：/usr/local/lib/python3.10/dist-packages
需要：joblib、numpy、scikit-learn、scipy、threadpoolctl
必需者：imblearn
真的很难过这一点，任何指导将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78211346/google-colab-importerror-cannot-import-name-mlsmote-from-imblearn-over-samp</guid>
      <pubDate>Sat, 23 Mar 2024 15:02:34 GMT</pubDate>
    </item>
    <item>
      <title>Python Phonemizer 库在 ubuntu VM 中找不到 espeak 库</title>
      <link>https://stackoverflow.com/questions/78210991/python-phonemizer-library-cant-find-espeak-library-in-ubuntu-vm</link>
      <description><![CDATA[尽管该模型在 Windows 本地计算机上运行良好，但根据此安装指南将路径传递到 espeak-ng 库时 https://bootphon.github.io/phonemizer/install.html ，我无法使其在 Ubuntu 22.04.4 LTS (x86-64) 下的虚拟机中工作。当运行我的脚本通过 wav2vec2phoneme 转录音素时，我收到以下消息
回溯（最近一次调用最后一次）：
文件“/dialrec/phoneme_transcription/phoneme_recognizers/transcribe.py”，第 50 行，位于
phoneme_recognizer = Wav2Vec2Phoneme()
文件“/dialrec/phoneme_transcription/phoneme_recognizers/wav2vec2phoneme.py”，第 24 行，init 中
self.processor = Wav2Vec2Processor.from_pretrained(&quot;facebook/wav2vec2-xlsr-53-espeak-cv-ft&quot;)
文件“/usr/local/lib/python3.10/site-packages/transformers/models/wav2vec2/processing_wav2vec2.py”，第 52 行，在 from_pretrained 中
返回 super().from_pretrained(pretrained_model_name_or_path, **kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/processing_utils.py”，第 465 行，from_pretrained
args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/processing_utils.py”，第 511 行，位于 _get_arguments_from_pretrained
args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))
文件“/usr/local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py”，第 837 行，在 from_pretrained 中
返回 tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py”，第 2086 行，from_pretrained
返回 cls._from_pretrained(
文件“/usr/local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py”，第 2325 行，位于 _from_pretrained
分词器 = cls(*init_inputs, **init_kwargs)
文件“/usr/local/lib/python3.10/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py”，第 153 行， init
self.init_backend(self.phonemizer_lang)
文件“/usr/local/lib/python3.10/site-packages/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py”，第 202 行， init_backend
self.backend = BACKENDS[self.phonemizer_backend](phonemizer_lang, language_switch=&quot;remove-flags&quot;)
文件“/usr/local/lib/python3.10/site-packages/phonemizer/backend/espeak/espeak.py”，第 45 行，在 init 中
超级().init(
文件“/usr/local/lib/python3.10/site-packages/phonemizer/backend/espeak/base.py”，第 39 行，在 init 中
超级().init(
文件“/usr/local/lib/python3.10/site-packages/phonemizer/backend/base.py”，第 77 行，在 init 中
引发 RuntimeError( # pragma: nocover
运行时错误：您的系统上未安装 espeak
为了安装 espeak，我按照以下步骤操作：

apt-get 安装 espeak-ng
pip3 安装phonemizer
pip3 install espeakng（也尝试过 pip3 install py-espeak-ng）

Espeak 肯定安装在 /usr/lib/x86_64-linux-gnu/libespeak-ng.so.1 和 /usr/bin/espeak-ng 下。
我尝试了以下方法：

无需额外步骤
设置环境变量 PHONEMIZER_ESPEAK_LIBRARY=&#39;/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1&#39; 和 PHONEMIZER_ESPEAK_PATH=&#39;/usr/bin/espeak-ng&#39;。
直接在脚本中设置环境变量
os.environ[&#39;PHONEMIZER_ESPEAK_LIBRARY&#39;] = &#39;/usr/lib/x86_64-linux-gnu/libespeak-ng.so.1&#39;
os.environ[&#39;PHONEMIZER_ESPEAK_PATH&#39;] = &#39;/usr/bin/espeak-ng&#39;

如果有任何帮助，我将不胜感激。提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78210991/python-phonemizer-library-cant-find-espeak-library-in-ubuntu-vm</guid>
      <pubDate>Sat, 23 Mar 2024 13:14:00 GMT</pubDate>
    </item>
    <item>
      <title>人体检测模型 - 使用张量流，无需对象检测 API 或任何预训练模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/78210961/human-detection-model-using-tensorflow-without-object-detection-api-or-any-pre</link>
      <description><![CDATA[我希望使用 TensorFlow 的 CNN（卷积神经网络）构建人体检测模型，而不依赖于任何预先训练的模型。我选择的数据集是 COCO 2017，特别关注人体检测。
任何人都可以提供有关如何有效完成此任务的见解或分步指南吗？我非常感谢任何可以帮助开发此人体检测模型的代码片段、教程或推荐资源。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78210961/human-detection-model-using-tensorflow-without-object-detection-api-or-any-pre</guid>
      <pubDate>Sat, 23 Mar 2024 13:04:12 GMT</pubDate>
    </item>
    <item>
      <title>认识十几个^2简单的鼠标绘制的象形文字/符号？</title>
      <link>https://stackoverflow.com/questions/78210940/recognizing-a-dozen2-simple-mouse-drawn-pictographs-symbols</link>
      <description><![CDATA[问候公平的旅行者！，需要算法？？？确定用户的快速涂鸦是否类似于任何象形文字（在最终确定时可能大小约为 50-200 的组中），如果是，则哪个象形文字最接近。理想情况下相对较轻。
谢谢-AAARRGGGHH！！！啊啊啊！！！谢谢好心的向导...
我尝试将一个完全识字的黑猩猩的思维复制到计算机上，打算强迫它的灰质受到束缚 - 但我缺乏时间、资源和知识来做到这一点。
不幸的是............我自己还没有找到一个自定义iconz的算法，因此我不得不依靠这些无知的巫师来让我最挑剔地找到所有的成分...电子思维。]]></description>
      <guid>https://stackoverflow.com/questions/78210940/recognizing-a-dozen2-simple-mouse-drawn-pictographs-symbols</guid>
      <pubDate>Sat, 23 Mar 2024 12:57:19 GMT</pubDate>
    </item>
    <item>
      <title>在 Kotlin Android 应用程序中运行 TensorFlow Lite 模型遇到困难</title>
      <link>https://stackoverflow.com/questions/78210864/difficulty-running-tensorflow-lite-model-in-kotlin-android-app</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78210864/difficulty-running-tensorflow-lite-model-in-kotlin-android-app</guid>
      <pubDate>Sat, 23 Mar 2024 12:36:06 GMT</pubDate>
    </item>
    <item>
      <title>动态设置SelectKBest的K值</title>
      <link>https://stackoverflow.com/questions/78210795/dynamically-set-k-value-of-selectkbest</link>
      <description><![CDATA[我在管道中使用 SelectKBest，并且希望能够使用 config.ini 文件配置要选择的功能数量。所以基本上在 .ini 文件中我有这个：
# FeatureSelection：设置要选择的特征数量 [FeatureSelection] nb_features = 10000 # 使用 chi2 进行 Kbest 特征选择时要选择的特征数量（整数或全部，all 将保留所有特征，因此不执行特征选择）
所以，问题是，如果我使用的数据输入不足以提取 10 000 个特征，selectKBest 将遇到问题：
ValueError：k 应该 &lt;= n_features = 4873；得到 10000。使用 k=&#39;all&#39; 返回所有特征。
这是正常的，因为它找不到足够的特征来返回 10 000 个特征。现在我正在考虑两种方法，但我不知道哪一种更容易实现并且最准确？

动态设置 k_value，以便如果它高于可用特征的数量，则将其设置为“全部”以便它选择最大数量的特征。否则，将 k_value 保留为 config.ini 文件中设置的值。

根据训练期间提取的比率设置 k_value。想象一下，您在训练 (.fit) 过程中提取 12 000 个特征并保留 10 000 个，则比率为 5/6。因此，这意味着在对验证数据进行预测时，您将保留 5/6 * 可用的功能。假设是 6000，您可以将 k_value 设置为 5000，以最终保持所选特征的相同比例。然而，应该有一个保证，以确定该比率是否大于1。 1 应该将 k_value 设置为“all”另外，因为您无法选择比提取的特征更多的特征。


你会推荐什么？如果有人能帮我解决这个问题，我将非常感激：D
感谢您的宝贵时间！]]></description>
      <guid>https://stackoverflow.com/questions/78210795/dynamically-set-k-value-of-selectkbest</guid>
      <pubDate>Sat, 23 Mar 2024 12:08:23 GMT</pubDate>
    </item>
    <item>
      <title>无法从“jax”导入名称“linear_util”</title>
      <link>https://stackoverflow.com/questions/78210393/cannot-import-name-linear-util-from-jax</link>
      <description><![CDATA[我正在尝试重现S5模型的实验，https://github.com/lindermanlab/ S5，但是在解决环境的时候遇到了一些问题。当我运行 shell 脚本./run_lra_cifar.sh时，出现以下错误
回溯（最近一次调用最后一次）：
  文件“/Path/S5/run_train.py”，第3行，在&lt;module&gt;中。
    从 s5.train 导入火车
  文件“/Path/S5/s5/train.py”，第7行，在&lt;module&gt;中。
    从.train_helpers导入create_train_state，reduce_lr_on_plateau，\
  文件“/Path/train_helpers.py”，第 6 行，在  中。
    从 flax.training 导入 train_state
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/__init__.py”，第 19 行，在  中
    从 。导入核心
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/core/__init__.py”，第 15 行，在  中
    从 .axes_scan 导入广播
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/core/axes_scan.py”，第 22 行，在  中
    从 jax 导入 Linear_util 作为 lu
ImportError：无法从“jax”导入名称“linear_util”（/Path/miniconda3/lib/python3.12/site-packages/jax/__init__.py）

我在 RTX4090 上运行它，我的 CUDA 版本是 11.8。我的jax版本是0.4.25，jaxlib版本是0.4.25+cuda11.cudnn86
我首先尝试使用作者的安装依赖项
pip install -rrequirements_gpu.txt

但是，这似乎不适用于我的情况，因为我什至无法导入 jax。所以我根据 https://jax.readthedocs.io/en 上的说明安装了 jax /latest/installation.html
通过输入
pip install --upgrade pip
pip install --upgrade “jax[cuda11_pip]” -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

到目前为止我已经尝试过：

使用较旧的 GPU（3060 和 2070）
将 python 降级到 3.9

有谁知道可能出了什么问题吗？感谢任何帮助]]></description>
      <guid>https://stackoverflow.com/questions/78210393/cannot-import-name-linear-util-from-jax</guid>
      <pubDate>Sat, 23 Mar 2024 09:57:12 GMT</pubDate>
    </item>
    <item>
      <title>如何将预训练的拥抱脸模型转换为.pt并在本地完全运行？</title>
      <link>https://stackoverflow.com/questions/78210297/how-to-convert-pretrained-hugging-face-model-to-pt-and-run-it-fully-locally</link>
      <description><![CDATA[我正在尝试将此模型转换为.pt格式。它对我来说工作得很好，所以我不想对其进行微调。如何将其导出为.pt并运行界面？
我尝试使用它转换为 .pt：
从变压器导入 AutoConfig、AutoProcessor、AutoModelForCTC、AutoTokenizer、Wav2Vec2Processor
导入库
进口火炬



# 定义模型名称
model_name = “UrukHan/wav2vec2-俄罗斯”

# 加载模型和分词器
config = AutoConfig.from_pretrained(model_name)
模型 = AutoModelForCTC.from_pretrained(model_name, config=config)
处理器 = Wav2Vec2Processor.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# 将模型保存为.pt 文件
torch.save(model.state_dict(), &quot;model.pt&quot;)

# 如果需要的话也保存分词器
tokenizer.save_pretrained(“模型标记器”)

但不幸的是它没有运行界面：
model = AutoModelForCTC.from_pretrained(“model.pt”)
处理器 = AutoProcessor.from_pretrained(“model.pt”)


# 使用模型进行推理
FILE = &#39;这里是 wav.wav&#39;
音频，_ = librosa.load（文件，sr = 16000）
音频=列表（音频）
def map_to_result(batch):
  使用 torch.no_grad()：
    input_values = torch.tensor(batch, device=“cpu”).unsqueeze(0) #, device=“cuda”
    logits = 模型(input_values).logits
  pred_ids = torch.argmax(logits, dim=-1)
  批处理=处理器.batch_decode(pred_ids)[0]
  退货批次
映射到结果（音频）
打印（映射到结果（音频））


模型.eval()

并遇到错误：
`model.pt 不是本地文件夹，也不是“https://huggingface.co/models”上列出的有效模型标识符
`]]></description>
      <guid>https://stackoverflow.com/questions/78210297/how-to-convert-pretrained-hugging-face-model-to-pt-and-run-it-fully-locally</guid>
      <pubDate>Sat, 23 Mar 2024 09:18:49 GMT</pubDate>
    </item>
    <item>
      <title>我做了什么来纠正属性错误。请帮助我[关闭]</title>
      <link>https://stackoverflow.com/questions/78210052/what-did-i-do-to-correct-the-attribute-error-please-help-me</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;batch_size = 100
对于范围 (25) 内的 i：
    num_batches = int(mnist.train.num_examples/batch_size)
    总成本 = 0
    对于范围内的 j（num_batches）：
        batch_x, batch_y = mnist.train.next_batch(batch_size)
        c, _ = sess.run([成本,优化], feed_dict={x:batch_x, y:batch_y, keep_prob:0.8})
        总成本 += c
    打印（总成本）

属性错误
                            回溯（最近一次调用最后一次）
单元格 In[65]，第 3 行
      1 批量大小 = 100
      2 对于范围 (25) 内的 i：
----&gt; 3 num_batches = int(mnist.train.num_examples/batch_size)
      4 总成本 = 0
      5 对于 j 在范围内（num_batches）：

AttributeError：模块“keras.datasets.mnist”没有属性“train”
]]></description>
      <guid>https://stackoverflow.com/questions/78210052/what-did-i-do-to-correct-the-attribute-error-please-help-me</guid>
      <pubDate>Sat, 23 Mar 2024 07:25:50 GMT</pubDate>
    </item>
    <item>
      <title>本地机器上的图像分类，但偶数纪元明显快于奇数纪元</title>
      <link>https://stackoverflow.com/questions/78209594/image-classification-on-local-machine-but-even-numbered-epoch-are-significantly</link>
      <description><![CDATA[我正在使用 Visual Studio 代码在本地计算机上进行图像分类训练，但每个偶数纪元都比奇数纪元快得多，以前有人遇到过这个问题吗？我在谷歌上到处找，但似乎没有人提到这种不规则现象。
因此，我无法正确集成早期停止回调，因为偶数纪元的 val_loss 被搞乱了。我尝试在 google collab 中运行，效果很好，但免费版本有限，有什么想法可以解决这个问题吗？ 我的基线模型的训练结果图像
对于我更复杂的模型，这个问题仍然存在。
# 定义一个 EarlyStopping 回调
Early_stopping = 回调.EarlyStopping(
    Monitor=&#39;val_loss&#39;, # 监控提前停止的指标（验证损失）
    Patient=5, # 停止前没有改善的 epoch 数
    min_delta=1e-7, # 被视为改进的监控指标的最小变化
    verbose=1, # 详细级别（1 表示更新）
    Restore_best_weights=True, # 停止时将模型权重恢复到最佳状态
）

# 定义一个ReduceLROnPlateau回调
高原 = 回调.ReduceLROnPlateau(
    Monitor=&#39;val_loss&#39;, # 监控学习率降低的指标（验证损失）
    Factor=0.5, # 学习率降低的因子（例如，0.2 表示 lr *= 0.2）
    Patient=2, # 降低学习率之前没有改善的 epoch 数
    min_delta=1e-6, # 触发减少的监控指标的最小变化
    Cooldown=0, # 减少后恢复正常操作之前等待的纪元数
    verbose=1 # 详细级别（1 表示更新）
）

def 基线CNN模型():
  # 输入层
  输入=输入（形状=（图像H，图像W，3））

  # 卷积层
  x = Conv2D(32, (3, 3), 激活=&#39;relu&#39;)(输入)
  x = MaxPooling2D((2, 2))(x)
  x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;)(x)
  x = MaxPooling2D((2, 2))(x)

  # 压平层
  x = 展平()(x)

  # 全连接层
  x = 密集(64, 激活=&#39;relu&#39;)(x)
  输出=密集（1，激活=&#39;sigmoid&#39;）（x）

  # 创建模型
  模型=模型（输入=[输入]，输出=输出）

  返回模型

# 清除Keras会话以释放资源
keras.backend.clear_session()

# 使用定义的 &#39;baseline_model&#39; 函数创建 CNN 模型
基线CNN = 基线CNN模型()

# 使用指定的损失、优化器和指标编译 CNN 模型
基线CNN.编译（
    loss=&#39;binary_crossentropy&#39;, # 二元分类的二元交叉熵损失
    Optimizer=keras.optimizers.Adam(), # 具有自定义学习率的 Adam 优化器
    metrics=[&#39;binary_accuracy&#39;] # 训练期间监控的指标（二进制精度）
）

# 显示模型架构的摘要
基线CNN.summary()

# 训练模型
bCNNHist = 基线CNN.fit(trainDS,
          验证数据=valDS，
          纪元=10，
          批量大小=批量大小，
          callbacks=[plateau], #early_stopping, 提前停止和降低学习率的回调
          steps_per_epoch=int(len(trainDF)/batchSize), # 每个训练周期的步数
          validation_steps=int(len(valDF) / batchSize) # 每个验证时期的步骤数)
）
]]></description>
      <guid>https://stackoverflow.com/questions/78209594/image-classification-on-local-machine-but-even-numbered-epoch-are-significantly</guid>
      <pubDate>Sat, 23 Mar 2024 02:41:21 GMT</pubDate>
    </item>
    <item>
      <title>协议错误 - 连接中止</title>
      <link>https://stackoverflow.com/questions/78208623/protocolerror-connection-aborted</link>
      <description><![CDATA[所以我正在制作一个 NLP 项目，其中我有效地进行了数据验证和数据转换，但是当涉及到模型训练时，它抛出了这个错误。我正在尝试从 Hugging-face 获取 cnn pegasus 模型，但它抛出此错误我使用相同的 api 进行数据转换并且它有效，但它抛出此错误，而模型火车请帮助我被困在这里。
我尝试了从禁用防火墙到良好的互联网连接的所有方法。还尝试从 Huggingface 下载模型，然后获取它，但我收到了有关不同权重的警告。]]></description>
      <guid>https://stackoverflow.com/questions/78208623/protocolerror-connection-aborted</guid>
      <pubDate>Fri, 22 Mar 2024 20:07:18 GMT</pubDate>
    </item>
    <item>
      <title>R 混淆矩阵 - 错误：“数据”和“参考”应该是具有相同级别的因素[关闭]</title>
      <link>https://stackoverflow.com/questions/78205262/r-confussion-matrix-error-data-and-reference-should-be-factors-with-the-s</link>
      <description><![CDATA[尽管还有其他针对相同错误消息的报告，但没有一个对我的情况有帮助。
我已经准备了自己的数据，分割如下，但无法获得混淆矩阵。
test_index &lt;- createDataPartition(y =workingData$PM10, times = 1, p = 0.5, list = FALSE)
train_set &lt;-工作数据[-test_index,]
test_set &lt;-工作数据[test_index,]

train_knn &lt;- train(PM10 ~. , method= &quot;knn&quot; , data = train_set)

y_hatknn &lt;- 预测(train_knn, train_set, type = “raw”)

fusionMatrix(y_hatknn, test_set$PM10)

上面最后一行给出
错误：“data”和“reference”应该是具有相同级别的因素。

我想上传数据进行复制，但可以提供基本的：
&lt;前&gt;&lt;代码&gt;str(工作数据)
“数据帧”：3653 obs。 3 个变量：
&#39; $ 日期 : 数字 2e+07 2e+07 2e+07 2e+07 2e+07 ...
&#39; $ Rain_mm: 数字 0.1 6.7 0 1.4 0.8 1.8 15.3 0 2.6 3.8 ...
&#39; $ PM10 : 数字 -1 -1 -1 -1 -1 ...

PM10 是污染 PM10 水平。
如何解决？
添加更多信息：
在原始错误之后：
&lt;块引用&gt;
confusionMatrix(y_hatknn, test_set$PM10)
错误：data 和 reference 应该是具有相同水平的因子。

我尝试设置为因素...
&lt;块引用&gt;
confusionMatrix(y_hatknn, as.factor(test_set$PM10))
错误：data 和 reference 应该是具有相同水平的因子。

以预测为因素...
&lt;块引用&gt;
confusionMatrix(as.factor(y_hatknn), test_set$PM10)
错误：data 和 reference 应该是具有相同水平的因素。

以两个参数为因素...
&lt;块引用&gt;
confusionMatrix(as.factor(y_hatknn), as.factor(test_set$PM10))
fusionMatrix.default(as.factor(y_hatknn), as.factor(test_set$PM10)) 中的错误：
数据的级别不能多于参考

确实需要得到整理，Stack坚持关闭我的帖子，写下gmail中navarrodan007的解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78205262/r-confussion-matrix-error-data-and-reference-should-be-factors-with-the-s</guid>
      <pubDate>Fri, 22 Mar 2024 09:39:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 numpy 函数计算以下 hessian 矩阵以加快计算速度？</title>
      <link>https://stackoverflow.com/questions/78199806/how-can-i-compute-the-following-hessian-using-numpy-functions-to-speed-up-the-co</link>
      <description><![CDATA[我必须实现一个等效函数来计算逻辑损失的 hessian，写为指数项对数之和。我在Python中实现了以下功能：
def hessian(self,w,hess_trick=0):
        赫斯 = 0
        对于 zip(self.data, self.labels) 中的 x_i,y_i:
            hess += np.exp(y_i * np.dot(w.T, x_i))/((1 + np.exp(y_i * np.dot(w.T,x_i)))**2) * np.outer(x_i, x_i.T)
        返回hess + lambda_reg * np.identity(w.shape[0]) + hess_trick * 10**(-12) * np.identity(w.shape[0])

我的问题是如何在不使用慢速 python 的情况下编写等效但更快的函数？
由于我对 numpy 不太有信心，我尝试编写以下函数：
 def new_hessian(self, w, hess_trick=0):
        exp_term = np.exp(self.labels * np.dot(self.data, w))
        sigmoid_term = 1 + exp_term
        inv_sigmoid_sq = 1 / sigmoid_term ** 2

        diag_elements = np.sum((exp_term * inv_sigmoid_sq)[:, np.newaxis] * self.data ** 2, axis=0)
        off_diag_elements = np.dot((exp_term * inv_sigmoid_sq) * self.data.T, self.data)
        hess = np.diag(diag_elements) + off_diag_elements
        正则化 = lambda_reg * np.identity(w.shape[0])

        hess += hess_trick * 1e-12 * np.identity(w.shape[0])

        返回 hess + 正则化

通过调试这个函数，我发现存在一个根本性的问题。对于特征数量较小的值（例如小于 200），hessian 的两种实现并不相等。当我增加特征数量时，这两个函数似乎是相等的。问题是，当使用牛顿方法来优化对数损失来测试这些实现时，较快的实现会比第一个（但在运行时速度方面较慢）实现更多的迭代收敛。]]></description>
      <guid>https://stackoverflow.com/questions/78199806/how-can-i-compute-the-following-hessian-using-numpy-functions-to-speed-up-the-co</guid>
      <pubDate>Thu, 21 Mar 2024 12:02:04 GMT</pubDate>
    </item>
    <item>
      <title>scikeras.wrappers.KerasClassifier 返回 ValueError：无法解释指标标识符：loss</title>
      <link>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</link>
      <description><![CDATA[我正在研究 KerasClassifier，因为我想将其插入 scikit-learn 管道中，但我收到了前面提到的 ValueError。
以下代码应该能够重现我遇到的错误：
从 sklearn.model_selection 导入 KFold，cross_val_score
从 sklearn.preprocessing 导入 StandardScaler
从 scikeras.wrappers 导入 KerasClassifier
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从 sklearn.datasets 导入 load_iris
将 numpy 导入为 np

数据 = load_iris()
X = 数据.数据
y = 数据.目标

def create_model():
    模型=顺序（）
    model.add（密集（8，input_dim = 4，激活=&#39;relu&#39;））
    model.add（密集（3，激活=&#39;softmax&#39;））
    model.compile(loss=&#39;sparse_categorical_crossentropy&#39;,
                  优化器=&#39;亚当&#39;,
                  指标=[&#39;准确性&#39;])
    返回模型

clf = KerasClassifier(build_fn=create_model,
                      纪元=100，
                      批量大小=10，
                      详细=1)

管道=管道（[
    (&#39;缩放器&#39;, StandardScaler()),
    （&#39;clf&#39;，clf）
]）

kf = KFold(n_splits=5, shuffle=True, random_state=42)
结果= cross_val_score（管道，X，y，cv = kf）
print(&quot;交叉验证准确度：&quot;, np.mean(结果))

似乎我的模型正在随着纪元的运行而被编译。但是，之后我收到错误：
ValueError：无法解释指标标识符：丢失

tensorflow 和 scikeras 库的版本是：
scikeras==0.12.0
张量流==2.15.0

编辑：
最终我尝试了不同的库版本，以下内容让我成功运行了代码，看来问题是由 scikit-learn 的版本引起的：
scikeras==0.12.0
张量流==2.15.0
scikit学习==1.4.1
]]></description>
      <guid>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</guid>
      <pubDate>Fri, 01 Mar 2024 17:03:39 GMT</pubDate>
    </item>
    </channel>
</rss>