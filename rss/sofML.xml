<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Wed, 25 Sep 2024 06:24:24 GMT</lastBuildDate>
    <item>
      <title>SBERT å¾®è°ƒæ€»æ˜¯åœ¨å®Œæˆæ‰€æœ‰ epoch ä¹‹å‰åœæ­¢</title>
      <link>https://stackoverflow.com/questions/79021064/sbert-fine-tuning-always-stops-before-finish-all-epochs</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ SBERT é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯ MiniLMï¼‰è¿›è¡Œä¸€ä¸ªåŒ…å« 995 ä¸ªåˆ†ç±»çš„æ–‡æœ¬åˆ†ç±»é¡¹ç›®ã€‚æˆ‘å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨æŒ‰ç…§æ­¤å¤„åˆ—å‡ºçš„æ­¥éª¤è¿›è¡Œæ“ä½œï¼Œä¸€åˆ‡ä¼¼ä¹éƒ½è¿è¡Œæ­£å¸¸ã€‚
æˆ‘çš„é—®é¢˜å‡ºç°åœ¨å®é™…è®­ç»ƒæ¨¡å‹æ—¶ã€‚æ— è®ºæˆ‘åœ¨è®­ç»ƒå‚æ•°ä¸­è®¾ç½®ä»€ä¹ˆå€¼ï¼Œè®­ç»ƒä¼¼ä¹æ€»æ˜¯æå‰ç»“æŸï¼Œå¹¶ä¸”æ°¸è¿œä¸ä¼šå®Œæˆæ‰€æœ‰æ‰¹æ¬¡ã€‚ä¾‹å¦‚ï¼Œæˆ‘è®¾ç½®äº† num_train_epochs=1ï¼Œä½†å®ƒæœ€å¤šåªèƒ½è¾¾åˆ° 0.49 ä¸ª epochã€‚å¦‚æœ num_train_epochs=4ï¼Œå®ƒæ€»æ˜¯åœ¨ 3.49 ä¸ª epoch å¤„ç»“æŸã€‚
è¿™æ˜¯æˆ‘çš„ä»£ç ï¼š
from datasets import load_dataset
from sentence_transformers import (
SentenceTransformer,
SentenceTransformerTrainer,
SentenceTransformerTrainingArguments,
SentenceTransformerModelCardData,
)
from sentence_transformers.losses import BatchAllTripletLoss
from sentence_transformers.training_args import BatchSamplers
from sentence_transformers.evaluation import TripletEvaluator

model = SentenceTransformer(
&quot;nreimers/MiniLM-L6-H384-uncased&quot;,
model_card_data=SentenceTransformerModelCardData(
language=&quot;en&quot;,
license=&quot;apache-2.0&quot;,
model_name=&quot;all-MiniLM-L6-v2&quot;,
)
)

loss = BatchAllTripletLoss(model)
# æŸå¤±æ¦‚è¿°ï¼šhttps://www.sbert.net/docs/sentence_transformer/loss_overview.html
# æ­¤ç‰¹å®šæŸå¤±æ–¹æ³•ï¼šhttps://www.sbert.net/docs/package_reference/sentence_transformer/losses.html#batchalltripletloss

# è®­ç»ƒå‚æ•°ï¼šhttps://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments
args = SentenceTransformerTrainingArguments(
# å¿…éœ€å‚æ•°ï¼š
output_dir=&quot;finetune/model20240924&quot;,
# å¯é€‰è®­ç»ƒå‚æ•°ï¼š
num_train_epochs=1,
max_steps = -1,
per_device_train_batch_size=8,
per_device_eval_batch_size=8,
learning_rate=1e-5,
warmup_ratio=0.1,
fp16=True, # å¦‚æœæ‚¨æ”¶åˆ° GPU æ— æ³•åœ¨ FP16 ä¸Šè¿è¡Œçš„é”™è¯¯ï¼Œè¯·è®¾ç½®ä¸º False
bf16=False, # å¦‚æœæ‚¨æ‹¥æœ‰æ”¯æŒ BF16 çš„ GPUï¼Œè¯·è®¾ç½®ä¸º True
batch_sampler=BatchSamplers.GROUP_BY_LABEL, # 
# å¯é€‰çš„è·Ÿè¸ª/è°ƒè¯•å‚æ•°ï¼š
eval_strategy=&quot;no&quot;,
eval_steps=100,
save_strategy=&quot;epoch&quot;,
# save_steps=100,
save_total_limit=2,
logs_steps=100,
run_name=&quot;miniLm-triplet&quot;, # å¦‚æœåœ¨ W&amp;B ä¸­ä½¿ç”¨`wandb` å·²å®‰è£…
)

trainer = SentenceTransformerTrainer(
model=model,
args=args,
train_dataset=trainDataset,
eval_dataset=devDataset,
loss=loss,
#evaluator=dev_evaluator,
)
trainer.train()

è¯·æ³¨æ„ï¼Œæˆ‘æ²¡æœ‰ä½¿ç”¨è¯„ä¼°å™¨ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨åˆ›å»ºæ¨¡å‹ï¼Œå¹¶åœ¨äº‹åä½¿ç”¨ä¸“ç”¨çš„æµ‹è¯•å€¼é›†å¯¹å…¶è¿›è¡Œæµ‹è¯•ã€‚æˆ‘çš„æ•°æ®é›†ç»“æ„å¦‚ä¸‹ï¼š
Dataset({
features: [&#39;Title&#39;, &#39;Body&#39;, &#39;label&#39;],
num_rows: 23961
})

ä¸ dev æ•°æ®é›†å…·æœ‰ç›¸åŒçš„ç»“æ„ï¼Œåªæ˜¯è¡Œæ•°è¾ƒå°‘ã€‚è¿™å°†æä¾›ä»¥ä¸‹è¾“å‡ºï¼š
 [1473/2996 57:06 &lt; 59:07ï¼Œ0.43 it/sï¼ŒEpoch 0/1]
æ­¥éª¤è®­ç»ƒæŸå¤±
100 1.265600
200 0.702700
300 0.633900
400 0.505200
500 0.481900
600 0.306800
700 0.535600
800 0.369800
900 0.265400
1000 0.345300
1100 0.516700
1200 0.372600
1300 0.392300
1400 0.421900

TrainOutput(global_step=1473, training_loss=0.5003972503496366, metrics={&#39;train_runtime&#39;: 3427.9198, &#39;train_samples_per_second&#39;: 6.99, &#39;train_steps_per_second&#39;: 0.874, &#39;total_flos&#39;: 0.0, &#39;train_loss&#39;: 0.5003972503496366, &#39;epoch&#39;: 0.4916555407209613})

å°½ç®¡æˆ‘è°ƒæ•´äº†å€¼ï¼Œä½†è¿˜æ˜¯æ— æ³•å®Œæˆæ‰€æœ‰æ‰¹æ¬¡ã€‚ä»»ä½•å»ºè®®éƒ½å°†ä¸èƒœæ„Ÿæ¿€ï¼]]></description>
      <guid>https://stackoverflow.com/questions/79021064/sbert-fine-tuning-always-stops-before-finish-all-epochs</guid>
      <pubDate>Wed, 25 Sep 2024 03:55:44 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å°† CIFAR10 æ¨¡å‹çš„å‡†ç¡®ç‡æé«˜åˆ° 80% ä»¥ä¸Šï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79020893/how-to-increase-accurracy-for-cifar10-model-above-80-accuracy</link>
      <description><![CDATA[æœ‰äººèƒ½å¸®åŠ©æˆ‘å—ï¼Ÿæˆ‘ä½¿ç”¨æ¥è‡ª tensorflow æ•°æ®é›†çš„ CIFAR10 æ•°æ®é›†è®­ç»ƒæˆ‘çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä½†æˆ‘æ— æ³•å°†æ¨¡å‹å‡†ç¡®ç‡æé«˜åˆ° 80% ä»¥ä¸Š...
æœ‰äººèƒ½ç»™æˆ‘ä¸€ä¸ªå»ºè®®å—ï¼Ÿ
import tensorflow as tf
import time
import tensorflow_datasets as tfds
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

def normalize(train_images, test_images):
normalized_train_dataset = tf.cast(train_images, tf.float32) / 255.0
normalized_test_dataset = tf.cast(test_images, tf.float32) / 255.0
è¿”å› normalized_train_dataset, normalized_test_dataset

# Normalisasi Dataset
train_dataset, test_dataset = normalize(train_images, test_images)

def visual(image, image_sample=2):
for i in range (image_sample):

print(f&quot;å¼¯æ›²å›¾åƒï¼š{np.shape(image)}&quot;)
print(f&quot;å¼¯æ›²æ•°æ®ï¼š{image[i].dtype}&quot;)
print(f&quot;Nilai æœ€å¤§å›¾åƒï¼š{np.max(image[i])}&quot;)
print(f&quot;Nilai æœ€å°å›¾åƒï¼š{np.min(image[i])}&quot;)

plt.figure(figsize=(6,6))
plt.imshow(image[i])
plt.axis(&#39;off&#39;)
plt.colorbar()
plt.title(&quot;Gambar CIFAR-10&quot;)
plt.grid(False)
plt.show()

visualization(train_dataset)

train_labels = np.squeeze(train_labels)
test_labels = np.squeeze(test_labels)

print(f&quot;Shape Of Train Label : {train_labels.shape}&quot;)

print(f&quot;Shape Of Test_Label : {test_labels.shape}&quot;)

train_labels= to_categorical(train_labels, num_classes=10)
test_labels = to_categorical(test_labels, num_classes=10)

ä» tensorflow.keras.preprocessing.image å¯¼å…¥ ImageDataGenerator

datagen = ImageDataGenerator(
rotation_range=20,
width_shift_range=0.2,
height_shift_range=0.2,
sheath_range=0.2,
zoom_range=0.2,
Horizoâ€‹â€‹ntal_flip=True,
fill_mode=&#39;nearest&#39;
)

model = tf.keras.models.Sequential([
tf.keras.layers.Conv2D(32, (3,3), padding=&#39;same&#39;,activation=tf.nn.relu, input_shape=(32, 32, 3)),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(64, (3,3), padding=&#39;same&#39;,activation=tf.nn.relu),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(128, (3,3), padding=&#39;same&#39;, æ¿€æ´»=tf.nn.relu),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(128, (3,3), padding=&#39;same&#39;, æ¿€æ´»=tf.nn.relu),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(512, (3,3)ï¼Œpadding=&#39;same&#39;ï¼Œactivation=tf.nn.reluï¼Œkernel_regularizer=tf.keras.regularizers.l2(0.01))ï¼Œ
tf.keras.layers.BatchNormalization()ï¼Œ
tf.keras.layers.MaxPool2D((2,2)ï¼Œstrides=2)ï¼Œ

tf.keras.layers.Flatten()ï¼Œ
tf.keras.layers.Dense(512ï¼Œactivation=tf.nn.relu)ï¼Œ
tf.keras.layers.Dropout(0.3)ï¼Œ

tf.keras.layers.Dense(128ï¼Œactivation=tf.nn.relu)ï¼Œ
tf.keras.layers.Dropout(0.5)ï¼Œ

tf.keras.layers.Dense(10ï¼Œæ¿€æ´»=tf.nn.softmax)
])

model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

early_stopping = tf.keras.callbacks.EarlyStopping(
monitor=&#39;val_loss&#39;,
patience=5,
restore_best_weights=True
)

reducer_lr = tf.keras.callbacks.ReduceLROnPlateau(
monitor=&#39;val_loss&#39;,
factor=0.2,
patience=3,
verbose=1,
min_lr=0.00001
)

callbacks = [early_stopping, reducer_lr]

start_time = time.time()

history = model.fit(datagen.flow(
train_dataset,
train_labels,
batch_size=64),
epochs=30,
validation_data=(test_dataset, test_labels),
callbacks=callbacks,
verbose=1
)

end_time = time.time()
training_time = end_time - start_time
print(f&quot;è®­ç»ƒæ—¶é—´ï¼š{training_time/60:.2f} åˆ†é’Ÿ&quot;)

model.save(&#39;hand_gesture_detect.keras&#39;)

# è¯„ä¼°æ¨¡å‹
loss_val, accuracy_val = model.evaluate(test_dataset, test_labels)
print(f&quot;æŸå¤±ï¼š{loss_val}&quot;)
print(f&quot;å‡†ç¡®ç‡ï¼š{accuracy_val}&quot;)

æ¥è‡ª tensorflow.keras.applications å¯¼å…¥ ResNet50

base_model = ResNet50(weights=&#39;ImageNet&#39;, include_top=False, input_tensor=(32, 32, 3))

æˆ‘å·²ç»ä½¿æˆ‘çš„æ¨¡å‹å¤æ‚åŒ–ï¼Œä½†å‡†ç¡®ç‡ä»ç„¶åªæœ‰ 77-80%ï¼Œæˆ‘ä¸çŸ¥é“å¦‚ä½•æé«˜æˆ‘çš„æ¨¡å‹å‡†ç¡®ç‡]]></description>
      <guid>https://stackoverflow.com/questions/79020893/how-to-increase-accurracy-for-cifar10-model-above-80-accuracy</guid>
      <pubDate>Wed, 25 Sep 2024 01:55:02 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨ GPU ä¸Šè¿è¡Œ gridSearchCV æˆ– randonizedSerchCV</title>
      <link>https://stackoverflow.com/questions/79020888/how-to-run-gridsearchcv-or-randonizedserchcv-on-gpu</link>
      <description><![CDATA[æˆ‘æƒ³è¿è¡Œ gridSearchCV æˆ– randonizedSerchCV æ¥ä½¿ç”¨ GPU åœ¨ Colab ç¯å¢ƒä¸­è°ƒæ•´è¶…å‚æ•°ã€‚
ä½†æˆ‘æ‰¾ä¸åˆ°è¿™äº›å‡½æ•°ä¸ GPU å…¼å®¹çš„å®ç°ã€‚
åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•è°ƒæ•´è¶…å‚æ•°ï¼Ÿ
å› æ­¤ï¼Œç”±äºæˆ‘æ‰¾ä¸åˆ°åœ¨ GPU ä¸Šè°ƒæ•´è¶…å‚æ•°çš„å‡½æ•°ï¼Œæˆ‘å°è¯•å®ç° randonizedSerchCVã€‚ä½†æˆ‘è®¤ä¸ºä¸€å®šæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œè€Œæ— éœ€æ‰‹åŠ¨å®ç°è¯¥å‡½æ•°ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79020888/how-to-run-gridsearchcv-or-randonizedserchcv-on-gpu</guid>
      <pubDate>Wed, 25 Sep 2024 01:53:20 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨ PyTorch ä¸­è®­ç»ƒçœ¼ç›éªŒè¯ï¼ˆè€Œéè¯†åˆ«ï¼‰æ¨¡å‹ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79019854/how-to-train-an-eye-verification-not-recognition-model-in-pytorch</link>
      <description><![CDATA[æˆ‘æƒ³çŸ¥é“æˆ‘ä»¬å¦‚ä½•è®­ç»ƒä¸€å¯¹ä¸€å›¾åƒéªŒè¯æ¨¡å‹ã€‚æ¨¡å‹ä¼šæ‹æ‘„ä¸¤å¼ å›¾åƒå¹¶éªŒè¯å®ƒä»¬æ˜¯å¦ç›¸åŒã€‚
æˆ‘åœ¨ç½‘ä¸Šæœç´¢è¿‡ï¼Œä½†åªèƒ½æ‰¾åˆ°æœ‰å…³è¯†åˆ«ï¼ˆä¸€å¯¹å¤šï¼‰çš„ç­”æ¡ˆã€‚
å¦‚ä½•åœ¨æ–‡æœ¬æˆ–ä»£ç ä¸­åˆ›å»ºè¿™æ ·çš„æ¨¡å‹ï¼Ÿ
ä¸ºäº†æ¾„æ¸…èµ·è§ï¼Œæˆ‘è¯´çš„ç›¸åŒæ˜¯æŒ‡çœ¼ç›ç›¸åŒï¼Œå³å®ƒä»¬å±äºåŒä¸€ä¸ªäººã€‚è¿™æ˜¯ä¸€ä¸ªéªŒè¯æ¨¡å‹ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79019854/how-to-train-an-eye-verification-not-recognition-model-in-pytorch</guid>
      <pubDate>Tue, 24 Sep 2024 18:10:07 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä¸ºæ’åæ¨¡å‹ç”Ÿæˆæ•°æ®é›†ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79019494/how-generate-dataset-for-ranking-model</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•åˆ›å»ºä¸¤é˜¶æ®µæ¨èç³»ç»Ÿï¼šä½¿ç”¨çŸ©é˜µåˆ†è§£ç”Ÿæˆå€™é€‰å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨ Lambdarank æ’åæ¨¡å‹å¯¹å…¶è¿›è¡Œæ’åã€‚æˆ‘æœ‰ä¸¤ä¸ªé€‰é¡¹æ¥ç”Ÿæˆæ•°æ®é›†ï¼š

å– 128 ä¸ªé¡¹ç›®
ï¼ˆç›¸å…³é¡¹ç›® + éšæœºé¡¹ç›®å¡«å……ï¼‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹å¯¹å…¶è¿›è¡Œè¯„åˆ†å’Œæ’åºï¼Œç„¶åä½¿ç”¨æ­¤åºåˆ—è®­ç»ƒç¬¬äºŒä¸ªæ¨¡å‹ï¼ˆå› æ­¤æˆ‘ä»¬å§‹ç»ˆå…·æœ‰ç›¸å¯¹å€¼ã€‚
å¯¹æ‰€æœ‰é¡¹ç›®è¿›è¡Œè¯„åˆ†ï¼Œæ’åºå¹¶å–å‰ 128 ä¸ªé¡¹ç›®ï¼Œç„¶åè¿›è¡Œè®­ç»ƒï¼ˆæˆ‘ä»¬å¯èƒ½æ²¡æœ‰ç›¸å…³é¡¹ç›®ï¼Œä½†æˆ‘è®¤ä¸ºè¿™æ›´è‡ªç„¶ï¼Œå› ä¸ºåœ¨ç”Ÿäº§ä¸­æˆ‘ä»¬å°†ä»¥è¿™ç§æ–¹å¼è¿›è¡Œé¢„æµ‹ï¼‰ã€‚

é‚£ä¹ˆï¼Œå“ªä¸ªæ›´å¥½ï¼Ÿæ­¤å¤–ï¼Œåœ¨è®­ç»ƒä¸­ä½¿ç”¨å°æƒé‡ï¼ˆç±»ä¼¼äºéšå¼ ALSï¼‰å¡«å……é¡¹ç›®æ˜¯å¦æœ‰æ„ä¹‰ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79019494/how-generate-dataset-for-ranking-model</guid>
      <pubDate>Tue, 24 Sep 2024 16:14:00 GMT</pubDate>
    </item>
    <item>
      <title>ç±»å‹é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°ç±»â€œSequentialâ€</title>
      <link>https://stackoverflow.com/questions/79019296/typeerror-could-not-locate-class-sequential</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79019296/typeerror-could-not-locate-class-sequential</guid>
      <pubDate>Tue, 24 Sep 2024 15:17:10 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å°†é¢„æµ‹å€¼åˆå¹¶å›æ•°æ®é›†ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79018990/how-to-merge-predicted-value-back-to-the-data-set</link>
      <description><![CDATA[æˆ‘å·²ç»åœ¨ Python ä¸­è®­ç»ƒäº†ä¸€ä¸ª XGboost æ¨¡å‹ï¼Œå¹¶å°†æ¦‚ç‡åˆ—è¡¨ä½œä¸ºè¾“å‡ºã€‚æˆ‘å¦‚ä½•å°†è¿™äº›æ¦‚ç‡å¸¦åˆ°åŸå§‹æ•°æ®é›†ï¼Œä»¥ä¾¿åœ¨ä¸€ä¸ª DF ä¸­æ‹¥æœ‰æ•°æ® + é¢„æµ‹å€¼ï¼Ÿå‡è®¾æˆ‘çš„åŸå§‹åŸå§‹æµ‹è¯• df ç§°ä¸º df_rawã€‚
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)
model = XGBClassifier(n_estimators=1500, max_depth=5, n_jobs=-1, min_child_weight=2, 
early_stopping_rounds=25)
model.fit(X_train, y_train, eval_set=[(X_test, y_test)])
test_outputs = model.predict_proba(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/79018990/how-to-merge-predicted-value-back-to-the-data-set</guid>
      <pubDate>Tue, 24 Sep 2024 14:08:01 GMT</pubDate>
    </item>
    <item>
      <title>cuDNN é”™è¯¯ï¼šCUDNN_STATUS_EXECUTION_FAILED</title>
      <link>https://stackoverflow.com/questions/79018072/cudnn-error-cudnn-status-execution-failed</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79018072/cudnn-error-cudnn-status-execution-failed</guid>
      <pubDate>Tue, 24 Sep 2024 10:04:05 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨ smote å°†è¿‡é‡‡æ ·æ•°æ®å­˜å‚¨åœ¨å•ç‹¬çš„å˜é‡ä¸­ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</link>
      <description><![CDATA[åº”ç”¨ Smote è¿‡é‡‡æ ·æŠ€æœ¯åï¼Œæˆ‘åªæƒ³å°†æ–°ç”Ÿæˆçš„å€¼å­˜å‚¨åˆ° X2 å’Œ y2ã€‚X2 çš„ç‹¬ç«‹ç‰¹å¾å’Œ y2 çš„ç›®æ ‡å˜é‡
import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
dataset = pd.read_csv(&#39;https://archive.ics.uci.edu/static/public/17/data.csv&#39;)
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values
le = LabelEncoder()
y = le.fit_transform(y)
smt = SMOTE()
X1, y1 = smt.fit_resample(X, y)
#åœ¨å•ç‹¬çš„å˜é‡ä¸­ä½¿ç”¨ smote å¯¹æ•°æ®è¿›è¡Œè¿‡é‡‡æ ·
#X2 = ?
#y2 = ?

]]></description>
      <guid>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</guid>
      <pubDate>Tue, 24 Sep 2024 04:07:41 GMT</pubDate>
    </item>
    <item>
      <title>é€šè¿‡æ¨¡å‹çš„å¤§è§„æ¨¡æµ‹è¯•é¢„æµ‹æ¯’æ€§æµ‹å®š[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</link>
      <description><![CDATA[æˆ‘ç›®å‰æ­£åœ¨åˆ›å»ºä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹æ±¡æŸ“å¯¹ç”Ÿç‰©ä½“çš„æ¯’æ€§æµ‹å®šã€‚ç”±äºæ²¡æœ‰åˆé€‚çš„æ•°æ®é›†ï¼Œæˆ‘è¿˜æ²¡æœ‰å°è¯•ä»»ä½•ä¸œè¥¿ã€‚æˆ‘åªæ˜¯æƒ³é—®é—®æˆ‘çš„ä»£ç æ˜¯å¦åˆé€‚ã€‚æ¬¢è¿æå‡ºæ‰¹è¯„ã€‚æ­¤å¤–ï¼Œå¦‚æœæˆ‘é—æ¼äº†ä»€ä¹ˆæˆ–åº”è¯¥åŒ…æ‹¬ä»€ä¹ˆï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚
æ­¤å¤–ï¼Œæˆ‘æ­£åœ¨è€ƒè™‘æ›´å¤šæ¨¡å‹ï¼Œä¾‹å¦‚ RandomForestRegressorã€Boostingï¼ˆAdaBoostã€GradientBoostï¼‰ã€‚æˆ‘åº”è¯¥è€ƒè™‘è¿™äº›å—ï¼Ÿæ­¤å¤–ï¼Œå½“æˆ‘æœ€ç»ˆè·å¾—æ•°æ®æ—¶ï¼Œæ˜¯å¦æœ‰ä»»ä½•æ¨¡å‹æˆ‘åº”è¯¥ä»æµ‹è¯•ä¸­åˆ é™¤ï¼Ÿ
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv(&#39;&#39;) # åŒ…å«æ•°æ®çš„ csv æ–‡ä»¶ï¼ˆæµ“åº¦å’Œæ­»äº¡ç‡ï¼‰

# åŸºæœ¬å›¾è¡¨
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;Mortality&#39;) 

# è®­ç»ƒä¸æµ‹è¯•çš„åŸºæœ¬åˆ’åˆ†
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=101) 

# çº¿æ€§æ¨¡å‹
from sklearn.linear_model import LinearRegression 
lr_model = LinearRegression()
lr_model.fit(X_train,y_train)
lr_preds = lr_model.predict(X_test)
from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_absolute_error(y_test, lr_preds)
np.sqrt(mean_absolute_error(y_test, lr_preds))
concentration_range = np.arange(0,100) # æ ¹æ®æœ€å°/æœ€å¤§æµ“åº¦è°ƒæ•´
concentration_preds = lr_model.predict(concentration_range.reshape(-1,1))
plt.figure(figsize = (12,6),dpi = 200)
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;ä¿¡å·&#39;)
plt.plot(concentration_range,concentration_preds)

# å¤šé¡¹å¼æ¨¡å‹
# ç”¨äºæµ‹è¯•æ¨¡å‹çš„å‡½æ•°
def run_model(model, X_train, y_train, X_test, y_test):
# æ‹Ÿåˆæ¨¡å‹
model.fit(X_train,y_train)

# è·å–æŒ‡æ ‡
preds = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test,preds))
mae = mean_absolute_error(y_test, preds)
print(f&#39;MAE: {mae}&#39;)
print(f&#39;RMSE: {rmse}&#39;)

# ç»˜åˆ¶ç»“æœæ¨¡å‹ä¿¡å·èŒƒå›´
density_range = np.arange(0,100) # å†æ¬¡è°ƒæ•´
density_preds = model.predict(concentration_range.reshape(-1,1))

plt.figure(figsize = (12,8), dpi = 200)
sns.scatterplot(x = &#39;Concentration&#39;, y = &#39;Mortality&#39;, data = df, color = &#39;black&#39;)
plt.plot(concentration_range, density_preds)

æ¥è‡ª sklearn.pipeline å¯¼å…¥ make_pipeline
æ¥è‡ª sklearn.preprocessing å¯¼å…¥ PolynomialFeatures

pipe = make_pipeline(PolynomialFeatures(degree = 2),LinearRegression()) # degree å¯è°ƒæ•´
run_model(pipe, X_train, y_train, X_test, y_test)

# K-Nearest Neighbors æ¨¡å‹
æ¥è‡ª sklearn.neighbors å¯¼å…¥ KNeighborsRegressor
k_values = [1,2,3,4,5,6,7,8,9,10]
for k in k_values:

model = KNeighborsRegressor(n_neighbors=k)
run_model(model, X_train,y_train,X_test, y_test)

# å†³ç­–æ ‘æ¨¡å‹
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor()
run_model(model, X_train, y_train, X_test, y_test)

# SVR æ¨¡å‹
from sklearn.svm import SVR # æ”¯æŒå‘é‡å›å½’
from sklearn.model_selection import GridSearchCV
svr = SVR()
param_grid = {&#39;C&#39;:[0.01,0.1,1,5,10,100,1000],
&#39;gamma&#39;:[&#39;auto&#39;,&#39;scale&#39;]}

grid = GridSearchCV(svr, param_grid)
run_model(grid, X_train,y_train,X_test, y_test)
]]></description>
      <guid>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</guid>
      <pubDate>Mon, 23 Sep 2024 21:25:16 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ Deepface Deepface.represent ä» ROI è·å–åµŒå…¥æ—¶å‡ºé”™</title>
      <link>https://stackoverflow.com/questions/79013712/error-getting-embeddings-from-a-roi-using-deepface-deepface-represent</link>
      <description><![CDATA[æˆ‘åœ¨ä½¿ç”¨ Deepface ä» Retinaface è¯†åˆ«çš„è£å‰ª ROI è·å–åµŒå…¥æ—¶é‡åˆ°äº†é—®é¢˜ã€‚
æˆ‘æ­£å°è¯•ä½¿ç”¨ä¸€äº›åäººçš„æ•°æ®é›†ï¼ˆå›¾åƒï¼‰å­¦ä¹ å¯¹è±¡è¯†åˆ«ï¼Œå¹¶å¯èƒ½è€ƒè™‘å°†å…¶ç”¨äºæˆ‘çš„ä¸ªäººç…§ç‰‡åº“ã€‚æˆ‘å°è¯•ä½¿ç”¨ Haar Cascade è¿›è¡Œäººè„¸æ£€æµ‹ï¼Œå¹¶ä½¿ç”¨ Open Cv ä¸­çš„ LBPHFaceRecognize è¿›è¡Œäººè„¸è¯†åˆ«ï¼Œæ•ˆæœå¾ˆå¥½ã€‚ç„¶åæˆ‘æƒ³å°è¯•ä½¿ç”¨ Retinafce è¿›è¡Œäººè„¸æ£€æµ‹å¹¶è·å¾— ROIã€‚ROI å­˜å‚¨åœ¨åˆ—è¡¨ä¸­ï¼Œå¹¶ä½¿ç”¨ Deepface ä»é€‰å®šçš„ ROI è·å–åµŒå…¥å¹¶å­˜å‚¨åœ¨å¦ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚æˆ‘æ­£åœ¨å°è¯•å°†åµŒå…¥å­˜å‚¨åˆ°åˆ—è¡¨ä¸­ï¼Œä½†æˆ‘ä¸€ç›´å¾—åˆ°
 raise ValueError(
ValueError: æ— æ³•åœ¨ numpy æ•°ç»„ä¸­æ£€æµ‹åˆ°äººè„¸ã€‚è¯·ç¡®è®¤å›¾ç‰‡

æ˜¯äººè„¸ç…§ç‰‡æˆ–è€ƒè™‘å°† force_detection å‚æ•°è®¾ç½®ä¸º Falseã€‚
è™½ç„¶æ‰€æœ‰å›¾åƒéƒ½æœ‰ä¸€å¼ è¢«æ¸…æ¥šæ£€æµ‹åˆ°çš„äººè„¸ã€‚è¿™æ˜¯æˆ‘çš„ä»£ç ä¾›å‚è€ƒï¼š
import os
import cv2 as cv
from retinaface import RetinaFace
from deepface import DeepFace
import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

artist = [&#39;50cent&#39;] # type: ignore #MJ the GOAT!! , &#39;Kanye&#39;, &#39;Eminem&#39;, &#39;MichaelJackson&#39;
ROOT_DIR = &#39;asset/Face_Recon_Dataset&#39; #å›¾åƒæ•°æ®é›†çš„è·¯å¾„
faces_roi =[]
labels = []
embeddings = []
#ç°åœ¨åœ¨è„¸éƒ¨åæ ‡ä¸Šç”»ä¸€ä¸ªçŸ©å½¢
#è„¸éƒ¨èŒƒå›´æœ‰ï¼š
# x1, y1) = (28, 51) #å·¦ä¸Šè§’
# (x2, y2) = (61, 98) #å³ä¸‹è§’
&quot;&quot;&quot; è¿™å®šä¹‰äº†æ£€æµ‹åˆ°çš„è„¸éƒ¨å‘¨å›´çš„çŸ©å½¢è¾¹ç•Œæ¡†ã€‚
- x1 (28)ï¼šè„¸éƒ¨çš„å·¦è¾¹ç¼˜
- y1 (51)ï¼šè„¸éƒ¨çš„ä¸Šè¾¹ç¼˜
- x2 (61)ï¼šè„¸éƒ¨çš„å³è¾¹ç¼˜
- y2 (98)ï¼šè„¸éƒ¨çš„ä¸‹è¾¹ç¼˜&quot;&quot;&quot;

def get_roi():
for artist_name in artist:
# è·å–è‰ºæœ¯å®¶å§“åçš„ç´¢å¼•
label = artist.index(artist_name)
image_folder = os.path.join(ROOT_DIR,artist_name) # è·å–åŒ…å«å›¾åƒçš„å®é™…æ–‡ä»¶å¤¹
for artist_images in os.listdir(image_folder): # åˆ—å‡ºè¯¥ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ
image = os.path.join(image_folder,artist_images)
resp = RetinaFace.detect_faces(image)
# ç¡®ä¿äººè„¸å­˜åœ¨
if isinstance(resp,dict):
img = cv.imread(image)
for face_id, face_data in resp.items():
# print(face_id)
# print(&quot;x1: &quot;, face_data[&#39;facial_area&#39;][0])
# print(&quot;y1: &quot;, face_data[&#39;facial_area&#39;][1])
# print(&quot;x2: &quot;, face_data[&#39;facial_area&#39;][2])
# print(&quot;y2: &quot;, face_data[&#39;facial_area&#39;][3], &quot;\n&quot;)
# è¯»å–å›¾åƒ

# æ£€æµ‹äººè„¸
x1 = face_data[&#39;facial_area&#39;][0]
y1 = face_data[&#39;facial_area&#39;][1]
x2 = face_data[&#39;facial_area&#39;][2]
y2 = face_data[&#39;facial_area&#39;][3]

# ä¸ºäººè„¸ç»˜åˆ¶è¾¹ç•Œæ¡† 
# faces_rect = cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
face_roi = img[y1:y2,x1:x2]

#ç”¨å…¶åç§°æ ‡è®°è£å‰ªåçš„ roi äººè„¸
faces_roi.append(face_roi)

labels.append(label)
print(len(faces_roi))
print(len(labels))
print(&quot;å·²æ ‡è®°å’Œç´¢å¼•çš„å›¾åƒ&quot;)
print(&quot;æ­£åœ¨åˆå§‹åŒ–åµŒå…¥è¿‡ç¨‹.....&quot;)
get_embeddings()

def get_embeddings():
&quot;&quot;&quot; ä½¿ç”¨ deepface ä»æ¯ä¸ªé¢éƒ¨ roi ä¸­æå–åµŒå…¥&quot;&quot;&quot;
print(&quot;Satarting embedding: ğŸš€ğŸš€ &quot;)
for roi in faces_roi:
face_roi_resized = cv.resize(roi, (160, 160)) # å°†äººè„¸ ROI è°ƒæ•´ä¸º 160x160 åƒç´ 
embedding = DeepFace.represent(face_roi_resized, model_name=&quot;Facenet&quot;)
print(embedding)
embeddings.append(embedding)
print(&quot;Vectors storage in list..&quot;)

get_roi()

# æ˜¯æ—¶å€™ä½¿ç”¨ svm åˆ†ç±»å™¨æµ‹è¯•å’Œè®­ç»ƒè¿™ä¸ªåå®¶ä¼™äº†
# å°†åµŒå…¥å’Œç´¢å¼•æ ‡è®°ä¸º numpy æ•°ç»„
X = np.array(embeddings) #feature
y = np.array(labels) #label

# å°†æ•°æ®åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒ SVM åˆ†ç±»å™¨
svm_model = SVC(kernel=&#39;linear&#39;) # çº¿æ€§æ ¸æ˜¯åµŒå…¥çš„è‰¯å¥½é»˜è®¤å€¼
svm_model.fit(X_train, y_train)

# è¯„ä¼°æ¨¡å‹
y_pred = svm_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;SVM æ¨¡å‹å‡†ç¡®ç‡ï¼š{accuracy * 100:.2f}%&quot;)

ä¸ºä»€ä¹ˆå³ä½¿ ROI å·²è¢«è£å‰ªï¼Œè¯¥é”™è¯¯ä»ç„¶å¦‚æ­¤æŒç»­ï¼Œè§£å†³æ­¤é”™è¯¯çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79013712/error-getting-embeddings-from-a-roi-using-deepface-deepface-represent</guid>
      <pubDate>Mon, 23 Sep 2024 08:03:12 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆä½¿ç”¨å›å½’ç®—æ³•è€Œä¸æ˜¯åˆ†ç±»ç®—æ³•ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79013513/why-are-regression-algorithms-used-instead-of-classification-algorithms</link>
      <description><![CDATA[ä¼—æ‰€å‘¨çŸ¥ï¼Œåœ¨ ML ä¸­ï¼Œå¦‚æœä¾èµ–ç‰¹å¾æœ¬è´¨ä¸Šæ˜¯è¿ç»­çš„ï¼Œåˆ™åº”ç”¨å›å½’æ¨¡å‹ã€‚ä½†æ˜¯ï¼Œå¦‚æœä¾èµ–ç‰¹å¾æœ¬è´¨ä¸Šæ˜¯åˆ†ç±»çš„ï¼Œåˆ™ä½¿ç”¨åˆ†ç±»ç®—æ³•ã€‚
æ­£å¦‚æ‚¨åœ¨è¿™å¼ å›¾ï¼ˆhttps://i.sstatic.net/9Q3wfudK.pngï¼‰ä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œæœ€å¤§å€¼ä¸ºã€‚å¤§é‡æ•°æ®ç‚¹é‡å¤å‡ºç°ï¼Œè¡¨æ˜å®ƒä»¬æ­£åœ¨å½¢æˆç±»åˆ«ã€‚
é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆè¿™é‡Œä½¿ç”¨å›å½’ï¼Ÿ
è¿™æ˜¯æ•°æ®é›†ï¼šï¼ˆhttps://drive.google.com/file/d/1vTIiQ0NZKgBI-EfpGzfPKHx1VaAdEYdH/view?usp=sharingï¼‰
æˆ‘å’ŒåŒå­¦ã€è€å¸ˆè®¨è®ºäº†è¿™ä¸ªé—®é¢˜ã€‚ä»–ä»¬éƒ½è¯´å›å½’æ˜¯ç”¨æ¥é¢„æµ‹çš„ï¼Œä½†æ²¡äººèƒ½è§£é‡Šä»–ä»¬æ˜¯å¦‚ä½•å¾—å‡ºåº”è¯¥ç”¨å›å½’æ¥ä»£æ›¿åˆ†ç±»çš„ç»“è®ºçš„ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79013513/why-are-regression-algorithms-used-instead-of-classification-algorithms</guid>
      <pubDate>Mon, 23 Sep 2024 07:10:30 GMT</pubDate>
    </item>
    <item>
      <title>æ˜¯å¦æœ‰ä»»ä½• Python åº“å¯ä»¥ä½¿ç”¨ç›¸æœºæ£€æµ‹è¢«æ£€æµ‹ç‰©ä½“çš„çº¬åº¦å’Œç»åº¦ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/62105606/is-there-any-python-libraries-to-detect-latitude-and-longitude-of-detected-objec</link>
      <description><![CDATA[æˆ‘æƒ³ä½¿ç”¨å¸¦æœ‰ç»åº¦å’Œçº¬åº¦çš„å«æ˜Ÿæ‘„åƒæœºæ¥æ£€æµ‹ç‰©ä½“ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/62105606/is-there-any-python-libraries-to-detect-latitude-and-longitude-of-detected-objec</guid>
      <pubDate>Sat, 30 May 2020 16:40:13 GMT</pubDate>
    </item>
    <item>
      <title>ä»€ä¹ˆæ˜¯ Killed:9 ä»¥åŠå¦‚ä½•åœ¨ macOS ç»ˆç«¯ä¸­ä¿®å¤ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/51833310/what-is-killed9-and-how-to-fix-in-macos-terminal</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€æ®µç”¨äºæœºå™¨å­¦ä¹ é¡¹ç›®çš„ç®€å• Python ä»£ç ã€‚æˆ‘æœ‰ä¸€ä¸ªç›¸å¯¹è¾ƒå¤§çš„è‡ªå‘è¯­éŸ³æ•°æ®åº“ã€‚æˆ‘å¼€å§‹è®­ç»ƒæˆ‘çš„è¯­éŸ³æ¨¡å‹ã€‚ç”±äºè¿™æ˜¯ä¸€ä¸ªåºå¤§çš„æ•°æ®åº“ï¼Œæˆ‘è®©å®ƒè¿å¤œå·¥ä½œã€‚æ—©ä¸Šæˆ‘é†’æ¥æ—¶çœ‹åˆ°ç»ˆç«¯ä¸­å‡ºç°ä¸€ä¸ªç¥ç§˜çš„
Killed: 9
è¡Œã€‚æ²¡æœ‰å…¶ä»–å†…å®¹ã€‚æ²¡æœ‰å…¶ä»–é”™è¯¯æ¶ˆæ¯æˆ–éœ€è¦å¤„ç†çš„å†…å®¹ã€‚ä»£ç è¿è¡Œè‰¯å¥½çº¦ 6 å°æ—¶ï¼Œå æ•´ä¸ªè¿‡ç¨‹çš„ 75%ï¼Œæ‰€ä»¥æˆ‘çœŸçš„ä¸æ˜ç™½å“ªé‡Œå‡ºäº†é—®é¢˜ã€‚
ä»€ä¹ˆæ˜¯ Killed:9 ä»¥åŠå¦‚ä½•ä¿®å¤å®ƒï¼Ÿæµªè´¹æ•°å°æ—¶çš„è®¡ç®—æ—¶é—´éå¸¸ä»¤äººæ²®ä¸§â€¦â€¦
å¦‚æœè¿™å¾ˆé‡è¦ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨ macOS Mojave æµ‹è¯•ç‰ˆã€‚æå‰è°¢è°¢æ‚¨ï¼]]></description>
      <guid>https://stackoverflow.com/questions/51833310/what-is-killed9-and-how-to-fix-in-macos-terminal</guid>
      <pubDate>Tue, 14 Aug 2018 03:28:58 GMT</pubDate>
    </item>
    <item>
      <title>Keras ä¸­â€œFlattenâ€èµ·ä»€ä¹ˆä½œç”¨ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•äº†è§£ Keras ä¸­ Flatten å‡½æ•°çš„ä½œç”¨ã€‚ä¸‹é¢æ˜¯æˆ‘çš„ä»£ç ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•çš„ä¸¤å±‚ç½‘ç»œã€‚å®ƒæ¥æ”¶å½¢çŠ¶ä¸º (3, 2) çš„äºŒç»´æ•°æ®ï¼Œå¹¶è¾“å‡ºå½¢çŠ¶ä¸º (1, 4) çš„ä¸€ç»´æ•°æ®ï¼š
model = Sequential()
model.add(Dense(16, input_shape=(3, 2)))
model.add(Activation(&#39;relu&#39;))
model.add(Flatten())
model.add(Dense(4))
model.compile(loss=&#39;mean_squared_error&#39;, optimizer=&#39;SGD&#39;)

x = np.array([[[1, 2], [3, 4], [5, 6]]])

y = model.predict(x)

print y.shape

è¿™ä¼šæ‰“å°å‡º y å…·æœ‰å½¢çŠ¶ (1, 4)ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘åˆ é™¤ Flatten è¡Œï¼Œåˆ™å®ƒä¼šæ‰“å°å‡º y å…·æœ‰å½¢çŠ¶ (1, 3, 4)ã€‚
æˆ‘ä¸æ˜ç™½è¿™ä¸€ç‚¹ã€‚æ ¹æ®æˆ‘å¯¹ç¥ç»ç½‘ç»œçš„ç†è§£ï¼Œmodel.add(Dense(16, input_shape=(3, 2))) å‡½æ•°æ­£åœ¨åˆ›å»ºä¸€ä¸ªéšè—çš„å®Œå…¨è¿æ¥å±‚ï¼Œå…¶ä¸­åŒ…å« 16 ä¸ªèŠ‚ç‚¹ã€‚è¿™äº›èŠ‚ç‚¹ä¸­çš„æ¯ä¸€ä¸ªéƒ½è¿æ¥åˆ°æ¯ä¸ª 3x2 è¾“å…¥å…ƒç´ ã€‚å› æ­¤ï¼Œç¬¬ä¸€å±‚è¾“å‡ºå¤„çš„ 16 ä¸ªèŠ‚ç‚¹å·²ç»æ˜¯â€œå¹³å¦çš„â€ã€‚å› æ­¤ï¼Œç¬¬ä¸€å±‚çš„è¾“å‡ºå½¢çŠ¶åº”è¯¥æ˜¯ (1, 16)ã€‚ç„¶åï¼Œç¬¬äºŒå±‚å°†å…¶ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºå½¢çŠ¶ä¸º (1, 4) çš„æ•°æ®ã€‚
é‚£ä¹ˆï¼Œå¦‚æœç¬¬ä¸€å±‚çš„è¾“å‡ºå·²ç»æ˜¯â€œå¹³å¦çš„â€å¹¶ä¸”å½¢çŠ¶ä¸º (1, 16)ï¼Œä¸ºä»€ä¹ˆæˆ‘éœ€è¦è¿›ä¸€æ­¥å°†å…¶å¹³å¦åŒ–ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras</guid>
      <pubDate>Wed, 05 Apr 2017 16:48:24 GMT</pubDate>
    </item>
    </channel>
</rss>