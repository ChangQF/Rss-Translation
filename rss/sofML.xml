<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 12 Oct 2024 21:17:01 GMT</lastBuildDate>
    <item>
      <title>结合几种监督学习技术？[关闭]</title>
      <link>https://stackoverflow.com/questions/79081793/combining-several-supervised-learning-techniques</link>
      <description><![CDATA[我的数据集包含大量图像和制表数据（存储在 .csv 文件中）。我打算使用我拥有的所有数据（图像和制表数据）创建一个能够对案例 A 和案例 B 进行分类/识别的机器学习模型。
是否可以结合几种监督学习技术，例如使用 CNN 处理图像，使用随机森林分析制表数据？目标是创建一个对两种类型的数据进行训练的组合模型，该模型可以将案例 A 和案例 B 进行分类。
我的问题是这种方法在机器学习中是否可行。
是否可以在训练过程中整合图像和制表数据？
对于这些类型的数据，通常推荐使用哪种机器学习算法？
我相信 CNN 是图像的不错选择，但我不确定制表数据的最佳方法是什么。
最适合用于此任务的 Python 包是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79081793/combining-several-supervised-learning-techniques</guid>
      <pubDate>Sat, 12 Oct 2024 19:52:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么飞机没有显示在 matplotlib 图中</title>
      <link>https://stackoverflow.com/questions/79081747/why-the-plane-doesnt-show-in-matplotlib-plot</link>
      <description><![CDATA[我正在对具有 13 个特征的波士顿房屋数据集实施 SLP。我为 X 选择“rm”和“zn”，为目标 Y 选择“medv”。我还从头实施了一个感知器类。在这个类中，我有一个名为 plot_losses 的函数，它在一个窗口中绘制预测线（2d）和损失，还绘制 3d 图的预测平面，这就是问题所在，即 3d 部分。
平面未显示在 3d 散点图上。
感知器类实现：
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter

感知器类：
def __init__(self, input_size, lr, epochs):
self.w = np.zeros(input_size)
self.b = 0
self.lr = lr
self.epochs = epochs
self.losses = []

def fit(self, X_train, Y_train):
for _ in range(self.epochs):
for x_i in range(X_train.shape[0]):
x = X_train[x_i]
y = Y_train[x_i]
y_pred = np.dot(x, self.w) + self.b
error = y - y_pred

self.w = self.w + (error * x * self.lr)
self.b = self.b + (error * self.lr)

loss = np.mean(np.abs(error))
self.losses.append(loss)

def predict(self, X_test):
return np.dot(X_test, self.w) + self.b

def plot_losses(self, X_train, Y_train, ax1_title, ax2_title, plot_3d=False, plot_3d_title=&#39;3D Plot&#39;):
for _ in range(self.epochs):
for x_i in range(X_train.shape[0]):
x = X_train[x_i]
y = Y_train[x_i]
Y_pred = np.dot(x, self.w) + self.b

if plot_3d:
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111,projection=&#39;3d&#39;)

X_feature1 = X_train[:, 0]
X_feature2 = X_train[:, 1]

ax.scatter(X_feature1, X_feature2, Y_train, color=&#39;blue&#39;, label=&#39;True Values&#39;)

X1_grid, X2_grid = np.meshgrid(
np.linspace(X_feature1.min(), X_feature1.max(), 20),
np.linspace(X_feature2.min(), X_feature2.max(), 20)
)

Z_pred = self.w[0] * X1_grid + self.w[1] * X2_grid + self.b

ax.plot_surface(X1_grid, X2_grid, Z_pred, color=&#39;red&#39;, alpha=0.5)
ax.set_xlabel(&quot;特征 &#39;rm&#39;&quot;)
ax.set_ylabel(&quot;特征 &#39;zn&#39;&quot;)
ax.set_zlabel(&quot;目标 &#39;medv​​&#39;&quot;)
ax.set_title(plot_3d_title)
ax.legend()
plt.show()
else:
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5))

ax1.scatter(X_train[:, 0], Y_train, color=&#39;blue&#39;, label=&#39;真值&#39;)
ax1.plot(X_train[:, 0], Y_pred, color=&#39;red&#39;, label=&#39;预测值Line&#39;)
ax1.set_title(ax1_title)
ax1.legend()

ax2.plot(self.losses)
ax2.set_title(ax2_title)
ax2.set_xlabel(&quot;Epochs&quot;)
ax2.set_ylabel(&quot;均方误差 (MSE)&quot;)

plt.tight_layout()
plt.show()

波士顿房屋数据集的线性回归：
%matplotlib qt
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
from perceptron import Perceptron
df_boston = pd.read_csv(&#39;input/BostonHousing.csv&#39;)
X = df_boston[[&#39;rm&#39;,&#39;zn&#39;]].values
Y = df_boston[&#39;medv​​&#39;].values
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=.2)

slp = Perceptron(2, .01, 100)
slp.fit(X_train, Y_train) 
slp.plot_losses(X_train,Y_train, &#39;员工工资和经验感知器&#39;, &#39;损失值&#39;, plot_3d=True, plot_3d_title=&#39;波士顿住房感知器&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/79081747/why-the-plane-doesnt-show-in-matplotlib-plot</guid>
      <pubDate>Sat, 12 Oct 2024 19:31:21 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 load_state_dict 加载我的模型：RuntimeError：为 UNetGenerator 加载 state_dict 时出错：state_dict 中出现意外键</title>
      <link>https://stackoverflow.com/questions/79081715/cant-load-my-model-using-load-state-dict-runtimeerror-errors-in-loading-sta</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79081715/cant-load-my-model-using-load-state-dict-runtimeerror-errors-in-loading-sta</guid>
      <pubDate>Sat, 12 Oct 2024 19:09:08 GMT</pubDate>
    </item>
    <item>
      <title>结合 CNN 和随机森林方法？[关闭]</title>
      <link>https://stackoverflow.com/questions/79081396/combining-cnn-and-random-forest-approach</link>
      <description><![CDATA[我的数据集包含大量图像和制表数据（存储在 .csv 文件中）。我打算使用我拥有的所有数据（图像和制表数据）创建一个能够对案例 A 和案例 B 进行分类/识别的机器学习模型。
是否可以结合几种监督学习技术，例如，使用 CNN 处理图像，使用随机森林分析制表数据？目标是创建一个对两种类型的数据进行训练的组合模型，该模型可以将案例 A 和案例 B 进行分类。
我的问题是这种方法在机器学习中是否可行。
是否可以在训练过程中集成图像和制表数据？
对于这些类型的数据，通常推荐使用哪种机器学习算法？
我认为 CNN 是图像的不错选择，但我不确定制表数据的最佳方法是什么。
最适合用于此任务的 Python 包是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79081396/combining-cnn-and-random-forest-approach</guid>
      <pubDate>Sat, 12 Oct 2024 16:08:46 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：X 有 14 个特征，但 LogisticRegression 需要 17128 个特征作为输入 [重复]</title>
      <link>https://stackoverflow.com/questions/79081243/valueerror-x-has-14-features-but-logisticregression-is-expecting-17128-feature</link>
      <description><![CDATA[# 预测系统
# content = input(&quot;输入您的文本：&quot;)

# 访问文本内容而不是 csr_matrix 元素
text_content = X_train[20].toarray()[0]

# 假设 X_train 包含文本数据；如果不包含，则进行相应调整。
# 如果需要，转换为常规 Python 字符串：
text_content = &quot; &quot;.join([str(element) for element in text_content if element != 0])

processed_content = preprocess_and_translate(text_content)
print(&quot;处理后的内容（英文）：&quot;,processed_content)

vectorizer = TfidfVectorizer()

vectorizer.fit_transform([processed_content])

input_data = vectorizer.transform([processed_content])

prediction = model.predict(input_data)
if prediction[0] == 1:
print(&#39;假新闻&#39;)
else:
print(&#39;真实新闻&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/79081243/valueerror-x-has-14-features-but-logisticregression-is-expecting-17128-feature</guid>
      <pubDate>Sat, 12 Oct 2024 14:51:02 GMT</pubDate>
    </item>
    <item>
      <title>如何对 NPU 进行编程以卸载合适的非 AI 相关操作？[关闭]</title>
      <link>https://stackoverflow.com/questions/79080861/how-to-program-a-npu-to-offload-suitable-non-ai-related-operations</link>
      <description><![CDATA[作为 GPU 的替代品，主流 NPU 的硬件功能是否适合用于任何非 AI 工作负载？它们擅长什么？
如果它们可以用于矩阵乘法或数据缓冲区上的其他操作之类的任何事情，那么用 C 语言编写的示例会很好。（对于任何主流 NPU，尤其是运行 Linux 或 Windows 的 PC 台式机，带有内置于 CPU 的 Intel Meteor Lake 或 AMD Ryzen AI。）]]></description>
      <guid>https://stackoverflow.com/questions/79080861/how-to-program-a-npu-to-offload-suitable-non-ai-related-operations</guid>
      <pubDate>Sat, 12 Oct 2024 11:04:04 GMT</pubDate>
    </item>
    <item>
      <title>微批次大小如何影响每个 GPU 的吞吐量？</title>
      <link>https://stackoverflow.com/questions/79080507/how-is-micro-batch-size-influencing-the-throughput-per-gpu</link>
      <description><![CDATA[我正在测试在 Megatron-LM 上全局批次大小恒定的情况下，微批次大小如何影响每个 GPU 的吞吐量。
我已经在 2 个 A40 GPU 上使用基于 400M Transformer 的模型进行了几次测试，并且仅使用数据并行性。以下是一些训练参数

在不同的测试中，我仅更改微批次大小，使用 seq_len =1024 和全局批次大小 =24 进行 100 次迭代训练。以下是使用不同微批次大小的一些结果

我使用 megatron-LM 原生功能每 5 次迭代打印一次日志，并计算所有迭代中每个 GPU 的平均吞吐量。
对于每次迭代，总计算复杂度相同，但每个 GPU 的吞吐量随着微批次大小的增加而增加。我知道这可能与 GPU 缓存负载或算术强度有关，但不太清楚。有人可以提供一些深入的解释吗？]]></description>
      <guid>https://stackoverflow.com/questions/79080507/how-is-micro-batch-size-influencing-the-throughput-per-gpu</guid>
      <pubDate>Sat, 12 Oct 2024 08:20:15 GMT</pubDate>
    </item>
    <item>
      <title>用于增量学习的 Python 非线性回归器</title>
      <link>https://stackoverflow.com/questions/79063665/python-non-linear-regressor-for-incremental-learning</link>
      <description><![CDATA[我想知道 scikit-learn 中是否有一个非线性回归程序，允许增量学习，即通过 partial_fit 调用。我发现 SGDRegressor 和 PassiveAggressiveRegressor 都允许 partial_fit，但它们是线性的，而我的数据显然是非线性的，因此拟合效果并不理想。]]></description>
      <guid>https://stackoverflow.com/questions/79063665/python-non-linear-regressor-for-incremental-learning</guid>
      <pubDate>Mon, 07 Oct 2024 21:18:59 GMT</pubDate>
    </item>
    <item>
      <title>AutoModelForSequenceClassification 损失没有减少</title>
      <link>https://stackoverflow.com/questions/79010018/automodelforsequenceclassification-loss-not-decrease</link>
      <description><![CDATA[从数据集导入 load_dataset
从 torch.utils.data 导入 DataLoader
从 transformers 导入 AutoTokenizer、AutoModelForSequenceClassification
导入 torch
从 tqdm 导入 tqdm

def train_one_epoch(model、dataloader、optimizer):
model.train()
loss_list = []
for batch in tqdm(dataloader):
batch_data = {
&#39;input_ids&#39;: batch[&#39;input_ids&#39;],
&#39;attention_mask&#39;: batch[&#39;attention_mask&#39;],
&#39;labels&#39;: batch[&#39;labels&#39;]
}
loss = model(**batch_data).loss
loss.backward()
optimizer.step()
optimizer.zero_grad()

loss_list.append(loss.detach().item())
avg_loss = sum(loss_list) / len(loss_list)
print(&#39;avg loss在 epoch:&#39;, avg_loss)

def assess(model, dataloader):
model.eval()
all_labels = []
all_predictions = []
for batch in dataloader:
with torch.no_grad():
batch_data = {
&#39;input_ids&#39;: batch[&#39;input_ids&#39;],
&#39;attention_mask&#39;: batch[&#39;attention_mask&#39;]
}
logits = model(**batch_data).logits
predictions = torch.argmax(logits, dim=-1)
labels = batch[&#39;labels&#39;]
all_labels.extend(labels)
all_predictions.extend(predictions)
accuracy = compute_accuracy(all_predictions, all_labels)
print(&quot;Accuracy&quot;, accuracy)
return accuracy

def compute_accuracy(predictions, labels):
correct = 0
for pred，zip(predictions, labels) 中的标签：
if pred == label:
correct += 1
返回正确 / len(labels)

def my_collat​​e_fn(batched_samples):
texts = [example[&#39;text&#39;] 例如在 batched_samples 中]
labels = [example[&#39;label&#39;] 例如在 batched_samples 中]
text_encoding = tokenizer(texts, max_length=128, truncation=True, padding=True, return_tensors=&#39;pt&#39;)
labels = torch.LongTensor(labels)
return {
&#39;input_ids&#39;: text_encoding[&#39;input_ids&#39;].cuda(),
&#39;attention_mask&#39;: text_encoding[&#39;attention_mask&#39;].cuda(),
&#39;labels&#39;: labels.cuda()
}

torch.manual_seed(64)
batch_size = 16
学习率 = 5e-5
训练次数 = 10
模型名称 = “roberta-base”

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

model = model.cuda()

optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate, eps=1e-8)

datasets = load_dataset(&quot;gpt3mix/sst2&quot;)

train_dataloader = DataLoader(
datasets[&#39;train&#39;],
batch_size=8,
shuffle=True,
collat​​e_fn=my_collat​​e_fn,
num_workers=0
)

validation_dataloader = DataLoader(
datasets[&#39;validation&#39;],
batch_size=8,
shuffle=False,
collat​​e_fn=my_collat​​e_fn,
num_workers=0
)

best_acc = 0.0
for周期范围（1，num_epochs + 1）：
train_one_epoch（模型，train_dataloader，优化器）
valid_acc = 评估（模型，validation_dataloader）


100%|██████████| 865/865 [01:27&lt;00:00，9.89it/s]

周期内平均损失：0.6746856869559068

准确率 0.4908256880733945

100%|██████████| 865/865 [01:25&lt;00:00, 10.09it/s]

epoch 中的平均损失：0.6922555248516833

准确率 0.4908256880733945

100%|██████████| 865/865 [01:27&lt;00:00, 9.89it/s]

epoch 中的平均损失：0.6976809655310791

准确率 0.5091743119266054

更改学习率也不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/79010018/automodelforsequenceclassification-loss-not-decrease</guid>
      <pubDate>Sat, 21 Sep 2024 16:24:50 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量</title>
      <link>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</link>
      <description><![CDATA[我无法加载我的模型，它一直显示错误
ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量。收到的输入：[&lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2896&gt;, &lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2897&gt;]
这是我的代码
image_generator = ImageDataGenerator(
rescale=1./255,
rotation_range=20,
zoom_range=0.2,
width_shift_range=0.2,
height_shift_range=0.2,
Horizo​​ntal_flip=True,
validation_split=0.2
)

train_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;training&#39;
)

validation_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;validation&#39;
)

# 加载数据集中子文件夹中的 (num_classes) 类
num_classes = len(train_dataset.class_indices)

from tensorflow.keras.applications.mobilenet import MobileNet

# 加载 MobileNet 模型
pre_trained_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),
include_top=False,
weights=&#39;imagenet&#39;)

pre_trained_model.summary()

# 打印数据集信息以供调试
print(f&quot;训练数据集形状：{train_dataset.image_shape}&quot;)
print(f&quot;验证数据集形状：{validation_dataset.image_shape}&quot;)

pre_trained_model.trainable = False

# 为预训练模型添加自定义层
model = tf.keras.Sequential([
pre_trained_model,
tf.keras.layers.GlobalAveragePooling2D(),
tf.keras.layers.Dense(1024,activation=&#39;relu&#39;),
tf.keras.layers.Dropout(0.5),
tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;) 
])

# 编译模型
#from tensorflow.keras.optimizers import RMSprop
model.compile(optimizer=Adam(learning_rate=0.0001),
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

batch=40
history = model.fit(train_dataset,
validation_data=validation_dataset,
epochs=20,
steps_per_epoch = train_dataset.samples//batch,
validation_steps =validation_dataset.samples//batch,
verbose = 1
)

# 加载模型
model_save_path = &#39;/content/drive/MyDrive/Machine Learning/saved_models/model_plastik.h5&#39;

# 加载模型，确保必要时已编译
loaded_model = tf.keras.models.load_model(model_save_path) 

# 现在您可以根据需要修改已加载的模型
# 例如，如果您想提取子模型：
input_layer_index = 0 # 替换为实际索引
dense_2_index = 3 # 替换为实际索引
loaded_model = tf.keras.models.Model(inputs=loaded_model.layers[input_layer_index].input, 
outputs=loaded_model.layers[dense_2_index].output)

# 检查已加载模型的配置
for i, layer in enumerate(loaded_model.layers):
print(f&quot;Layer {i}: {layer.name} - 输入形状：{layer.input_shape} - 输出形状：{layer.output_shape}&quot;)

print(&quot;已成功加载修订模型。&quot;)

我尝试加载模型，并希望它能够加载以进行测试]]></description>
      <guid>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</guid>
      <pubDate>Thu, 08 Aug 2024 07:06:54 GMT</pubDate>
    </item>
    <item>
      <title>CNN 架构：对“好”图像和“坏”图像进行分类</title>
      <link>https://stackoverflow.com/questions/57943425/cnn-architecture-classifying-good-and-bad-images</link>
      <description><![CDATA[我正在研究实现 CNN 的可能性，以便将图像分类为“好”或“坏”，但我目前的架构没有成功。
表示“坏”的特征图像：

过度曝光
过度饱和
白平衡不正确
模糊

根据这些特征实现神经网络对图像进行分类是否可行，还是最好使用传统算法，该算法仅查看整个图像的亮度/对比度变化并以此方式进行分类？
我曾尝试使用 VGGNet 架构训练 CNN，但无论 epoch 数或步骤数有多少，我似乎总是得到一个有偏差且不可靠的模型。
示例：

我当前的模型架构非常简单（因为我对整个机器学习世界还很陌生），但似乎可以很好地处理其他分类问题，并且我对其进行了轻微修改，以便更好地处理这个二元分类问题：
 # CONV =&gt; RELU =&gt; POOL 层集
# 定义卷积层，使用&quot;ReLU&quot;激活函数
# 并使用池化层减少空间大小（宽度和高度）
model.add(Conv2D(32, (3, 3), padding=&quot;same&quot;, input_shape=input_shape)) # 32 个 3x3 过滤器（高度、宽度、深度）
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization(axis=channel_dimension))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25)) # 有助于防止过度拟合（25% 的神经元随机断开连接）

# (CONV =&gt; RELU) * 2 =&gt; POOL 层集（随着 CNN 的深入，层数会增加）
model.add(Conv2D(64, (3, 3), padding=&quot;same&quot;, input_shape=input_shape)) # 64 个 3x3 过滤器
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization(axis=channel_dimension))
model.add(Conv2D(64, (3, 3), padding=&quot;same&quot;, input_shape=input_shape)) # 64 个 3x3 过滤器
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization(axis=channel_dimension))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25)) # 有助于防止过度拟合 (25%随机断开的神经元数量)

# (CONV =&gt; RELU) * 3 =&gt; POOL 层集（输入体积大小越来越小）
model.add(Conv2D(128, (3, 3), padding=&quot;same&quot;, input_shape=input_shape)) # 128 个 3x3 滤波器
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization(axis=channel_dimension))
model.add(Conv2D(128, (3, 3), padding=&quot;same&quot;, input_shape=input_shape)) # 128 个 3x3 滤波器
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization(axis=channel_dimension))
model.add(Conv2D(128, (3, 3), padding=&quot;same&quot;, input_shape=input_shape)) # 128 3x3 过滤器
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization(axis=channel_dimension))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25)) # 有助于防止过度拟合（25% 的神经元随机断开连接）

# 仅设置 FC =&gt; RELU 层
model.add(Flatten())
model.add(Dense(512))
model.add(Activation(&quot;relu&quot;))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# sigmoid 分类器（输出层）
model.add(Dense(classes))
model.add(Activation(&quot;sigmoid&quot;))

这个模型是否有任何明显的遗漏或错误，或者我根本无法使用深度学习（使用我当前的 GPU，GTX 970）解决这个问题？
这是我编译/训练模型的代码：
# 初始化模型和优化器
print(&quot;[INFO] Training network...&quot;)
opt = SGD(lr=initial_lr, decay=initial_lr / epochs)
model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=opt, metrics=[&quot;accuracy&quot;])

# 设置检查点
model_name = &quot;output/50_epochs_{epoch:02d}_{val_acc:.2f}.model&quot;
checkpoint = ModelCheckpoint(model_name, monitor=&#39;val_acc&#39;, verbose=1, 
save_best_only=True, mode=&#39;max&#39;)
reduce_lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.2,
waiting=5, min_lr=0.001)
tensorboard = TensorBoard(log_dir=&quot;logs/{}&quot;.format(time()))
callbacks_list = [checkpoint, reduce_lr, tensorboard]

# 训练网络
H = model.fit_generator(training_set, steps_per_epoch=500, epochs=50, validation_data=test_set, validation_steps=150, callbacks=callbacks_list)
]]></description>
      <guid>https://stackoverflow.com/questions/57943425/cnn-architecture-classifying-good-and-bad-images</guid>
      <pubDate>Sun, 15 Sep 2019 10:53:49 GMT</pubDate>
    </item>
    <item>
      <title>有没有其他方法可以替代卷积神经网络对图像进行分类？[关闭]</title>
      <link>https://stackoverflow.com/questions/57306780/is-there-any-alternative-to-convolutional-neural-networks-to-classify-images</link>
      <description><![CDATA[深度学习以将图像分类为不同类别而闻名。但是，我对使用任何其他能够对图像进行分类的机器学习模型感兴趣。这些图像大约有 2000 张，采用 png 格式。除了深度学习模型之外，有人知道可以应用于 Python 的任何机器学习模型来对图像进行分类吗？]]></description>
      <guid>https://stackoverflow.com/questions/57306780/is-there-any-alternative-to-convolutional-neural-networks-to-classify-images</guid>
      <pubDate>Thu, 01 Aug 2019 10:16:43 GMT</pubDate>
    </item>
    <item>
      <title>将深度特征提供给机器学习分类器（随机森林）</title>
      <link>https://stackoverflow.com/questions/54438994/feed-deep-features-to-machine-learning-classifiers-random-forest</link>
      <description><![CDATA[我想将我的 CNN 深度特征输入到传统分类器，即随机森林。我不想使用 MLP（多层感知器）来分类我的问题，但需要其他分类器。我有图像数据。我们无法将非结构化数据输入到机器学习分类器。我想先从 CNN（Conv2d、激活、Maxpooling 层）中提取深度特征，然后将图像数据取出成结构化和下采样形式，然后将其输入到普通分类器。我的情况是我想使用随机森林。
我尝试了我的代码，但这个模型给出了一些错误。我想在 flatten 层之后获取输出，这就是为什么我没有添加密集层，因为我只想获取深度特征，而不想对它们进行分类。
model_1=Sequential()

model_1.add(Conv2D(96,(3,3),padding=&quot;valid&quot;))
model_1.add(Activation(&quot;relu&quot;))
model_1.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=&quot;valid&quot;))

model_1.add(Conv2D(180 ,(3,3),padding=&quot;valid&quot;))
model_1.add(Activation(&quot;relu&quot;))

model_1.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=&quot;valid&quot;))

model_1.add(Conv2D(200 ,(3,3),padding=&quot;valid&quot;))
model_1.add(Activation(&quot;relu&quot;))
model_1.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding=&quot;valid&quot;))

model_1.add(Flatten())

model_1.compile(loss=keras.losses.binary_crossentropy, optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;])
model_1.fit(X_128,y_categorical,epochs=100)
x=model_1.predict(X_128)

通过 model.fit 将学习 conv2d 和 model.predict 的权重，我认为我得到了深度特征，但我不知道这是真的还是假的，因为我得到了错误。
错误：
------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-30-3c769c68fc69&gt; 在 &lt;module&gt;() 中
18 
19 model_1.compile(loss=keras.losses.binary_crossentropy, optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;])
---&gt; 20 model_1.fit(X_128,y_categorical,epochs=100)
21 x=model_1.predict(X_128)

/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)
958 sample_weight=sample_weight,
959 class_weight=class_weight,
-&gt; 960 batch_size=batch_size)
961 # 准备验证数据。
962 do_validation = False

/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)
787 feed_output_shapes,
788 check_batch_axis=False, # 不强制执行批量大小。
--&gt; 789 exception_prefix=&#39;target&#39;)
790 
791 # 给定 `sample_weight` 和

/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix) 生成样本权重值
137 &#39;：预期 &#39; + names[i] + &#39; 具有形状 &#39; +
138 str(shape) + &#39; 但得到的数组形状为 &#39; +
--&gt; 139 str(data_shape))
140 返回数据
141 

ValueError：检查目标时出错：预期 flatten_17 具有形状 (33800,) 但得到的数组形状为 (2,)
]]></description>
      <guid>https://stackoverflow.com/questions/54438994/feed-deep-features-to-machine-learning-classifiers-random-forest</guid>
      <pubDate>Wed, 30 Jan 2019 11:00:06 GMT</pubDate>
    </item>
    <item>
      <title>如何将用PCA和随机森林训练的模型应用于测试数据？</title>
      <link>https://stackoverflow.com/questions/36382572/how-to-apply-model-trained-with-pca-and-random-forest-to-test-data</link>
      <description><![CDATA[在解决一个机器学习问题时，我在训练数据上实施 PCA，然后使用 sklearn 在训练数据上应用 .transform。观察方差后，我只保留方差较大的转换数据中的那些列。然后我使用 RandomForestClassifier 训练模型。现在，我很困惑：如何将训练好的模型应用于测试数据，因为测试数据的列数和保留的转换数据（应用随机森林）不同？]]></description>
      <guid>https://stackoverflow.com/questions/36382572/how-to-apply-model-trained-with-pca-and-random-forest-to-test-data</guid>
      <pubDate>Sun, 03 Apr 2016 07:07:01 GMT</pubDate>
    </item>
    <item>
      <title>如何从 scikit-learn 决策树中提取决策规则？</title>
      <link>https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree</link>
      <description><![CDATA[我可以从决策树中经过训练的树中提取底层决策规则（或“决策路径”）作为文本列表吗？
类似于：
如果 A&gt;0.4，则如果 B&lt;0.2，则如果 C&gt;0.8，则 class=&#39;X&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree</guid>
      <pubDate>Tue, 26 Nov 2013 17:58:00 GMT</pubDate>
    </item>
    </channel>
</rss>