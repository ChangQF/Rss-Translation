<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 11 May 2024 01:00:30 GMT</lastBuildDate>
    <item>
      <title>不平衡学习管道的哪些部分应用于测试集？</title>
      <link>https://stackoverflow.com/questions/78462616/which-parts-of-the-imbalanced-learn-pipeline-are-applied-to-the-test-set</link>
      <description><![CDATA[我对机器学习领域还很陌生，所以如果这个问题有点基础，请原谅我。
我创建了一个由 RobustScaler、SMOTE-NC、RandomUndersampling 和随机森林分类器组成的不平衡学习管道。
RandomSearchCV 用于选择最佳的超参数。
我想在我的测试集上测试最佳估计器。
cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)

缩放器 = RobustScaler(quantile_range=(25.0, 75.0))
smote = SMOTENC(categorical_features=categorical_features,抽样策略=0.35,random_state=42)
rus = RandomUnderSampler(sampling_strategy=0.35, random_state=42)
分类器 = RandomForestClassifier(random_state=42)

管道=不平衡_make_pipeline（缩放器，smote，rus，分类器）

random_search = RandomizedSearchCV(管道, param_distributions=param, 评分=scoring_metric, cv=cv, n_iter=10, random_state=42, n_jobs=-1)

best_model = random_search.fit(X_train, y_train).best_estimator_

y_pred = best_model.predict(X_test)

据我了解，只有缩放（使用 X_train 获得的设置）和分类器才应应用于测试集。 SMOTE 和 RandomUndersampling 不应应用于 X_test。
这是由不平衡学习管道保证的还是我必须考虑其他事情？]]></description>
      <guid>https://stackoverflow.com/questions/78462616/which-parts-of-the-imbalanced-learn-pipeline-are-applied-to-the-test-set</guid>
      <pubDate>Fri, 10 May 2024 21:28:24 GMT</pubDate>
    </item>
    <item>
      <title>应用一维 CNN 在不同输入标签之间进行插值</title>
      <link>https://stackoverflow.com/questions/78462567/application-of-1d-cnn-to-interpolate-between-different-input-labels</link>
      <description><![CDATA[我正在尝试应用 1d-cnn 来预测穿过不同屏蔽厚度的输出中子通量。我有一堆输入光谱（不同能量下的归一化权重的一维向量）穿过屏蔽并创建通量（也是能量的一维向量（不同能量下的数值））。我的 1d-cnn 能够在不同能量下使用不同的输入权重及其相应的输出权重（不同能量下的通量）进行训练。现在，我有不同厚度下的输入和输出权重（通量）的数据，并且想要预测是否通过给定厚度（不是训练的厚度之一）的一组权重来预测输出通量。基本上是用 1d-cnn 进行插值，可以理解不同厚度屏蔽的衰减能力之间的关系，并预测任意厚度的输出。
问题的第一级是使用 1d-cnn 网络完成的，当时我唯一的变化是作为能量函数的输入和输出通量。现在，我想添加另一个维度（基本上是一个标签）并在不同标签之间插入结果。]]></description>
      <guid>https://stackoverflow.com/questions/78462567/application-of-1d-cnn-to-interpolate-between-different-input-labels</guid>
      <pubDate>Fri, 10 May 2024 21:13:20 GMT</pubDate>
    </item>
    <item>
      <title>总参数： 0 ，在执行 model.summary() keras 时</title>
      <link>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;模型 = 顺序()
model.add(嵌入(283, 100, input_length=56))
模型.add(LSTM(150))
模型.add(LSTM(150))
model.add（密集（283，激活=&#39;softmax&#39;））

model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=&#39;adam&#39;,metrics=[&#39;accuracy&#39;])

模型.summary()

张量流版本：2.16.1，
Keras 版本：3.3.3，
设备-M3 pro macbook
我尝试使用虚拟数据集（有 282 个唯一单词，使用分词器检查）构建用于文本生成的 LSTM 模型，预期参数非零，但每层输出为 0 个参数。]]></description>
      <guid>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</guid>
      <pubDate>Fri, 10 May 2024 19:49:53 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch自定义Env强化学习如何使其发挥作用？</title>
      <link>https://stackoverflow.com/questions/78462106/pytorch-custom-env-reinforcement-learning-how-to-make-it-work</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78462106/pytorch-custom-env-reinforcement-learning-how-to-make-it-work</guid>
      <pubDate>Fri, 10 May 2024 19:05:45 GMT</pubDate>
    </item>
    <item>
      <title>如何在房屋内部图像中检测并标记地板、墙壁和台面？</title>
      <link>https://stackoverflow.com/questions/78461985/how-can-i-detect-and-tag-floors-walls-and-countertops-in-an-image-of-a-house-i</link>
      <description><![CDATA[正在开展一个项目，我需要分析房屋内部的图像并检测和标记不同的元素，例如地板、墙壁和台面。我正在寻找有关如何使用图像处理或计算机视觉技术来完成此任务的指导。
具体来说，我想开发一种方法来自动识别和标记图像中的这些元素。例如，我希望能够准确地区分地板、墙壁和台面。
有人可以建议适合此任务的算法或方法吗？任何可以简化实现的库或框架也将受到赞赏。
谢谢！
我尝试过的：
到目前为止，我已经尝试了基本的边缘检测算法和颜色分割方法，但还没有取得令人满意的结果。不同元素的边缘经常混合在一起，并且分割不够准确，无法可靠地区分地板、墙壁和台面。
我期待什么：
我希望找到更先进的技术或算法来更好地处理室内场景的复杂性。理想情况下，我正在寻找能够利用纹理、形状甚至上下文信息等特征来提高检测和标记准确性的方法。
任何有关如何改进我的方法的建议或见解将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78461985/how-can-i-detect-and-tag-floors-walls-and-countertops-in-an-image-of-a-house-i</guid>
      <pubDate>Fri, 10 May 2024 18:33:03 GMT</pubDate>
    </item>
    <item>
      <title>是否可以训练神经网络以输入随机森林分类器或任何其他类型的分类器（例如 XGBoost 或决策树）？</title>
      <link>https://stackoverflow.com/questions/78461828/is-it-possible-to-train-a-neural-network-to-feed-into-a-random-forest-classifier</link>
      <description><![CDATA[我想创建一个模型架构来预测未来的股价走势，如下所示：

该模型的目标是预测未来 3 个月内价格是上涨还是下跌。
我尝试了一些模型，例如逻辑回归、神经网络、XGBoost 等。我收到了一些不错的结果。通过使用随机森林分类器，到目前为止我收到了最好的结果。如何使用神经网络对数据进行编码，然后将这些值传递给随机森林分类器进行分类，而不是使用如图所示的 sigmoid 函数的最终输出层（使用 Python、Keras 和 SKlearn）。&lt; /p&gt;
我不是最精通 Keras，所以我想知道是否有可能训练一个神经网络，将其输入到单独的分类器中，如果可以的话，该怎么做。]]></description>
      <guid>https://stackoverflow.com/questions/78461828/is-it-possible-to-train-a-neural-network-to-feed-into-a-random-forest-classifier</guid>
      <pubDate>Fri, 10 May 2024 17:53:36 GMT</pubDate>
    </item>
    <item>
      <title>为职位推荐系统选择正确的集成方法</title>
      <link>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</link>
      <description><![CDATA[我正在开发机器学习职位推荐系统，并且正在考虑使用集成学习方法。我使用的数据集很全面，包括各种属性，例如职位名称、职位描述、工资、地点和公司详细信息。它包含数字、分类和文本数据的混合。
我计划使用结合多种模型和技术的混合方法来提高其性能：
协作过滤或矩阵分解来捕获用户和职位发布之间的交互。
神经网络用于处理复杂的数据类型，例如职位描述中的文本。
决策树或随机森林的可解释性以及处理数字和分类数据混合的能力。
我正在寻求关于哪种集成方法最适合这项任务的建议。我希望模型能够很好地过滤、灵活地处理数据类型、在训练和时间上具有良好的性能，并提供可解释性。谢谢大家&amp;祝你有美好的一天！
我还没有开始，但我会考虑尝试任何合理的方法！]]></description>
      <guid>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</guid>
      <pubDate>Fri, 10 May 2024 17:51:56 GMT</pubDate>
    </item>
    <item>
      <title>如何限制 13b 参数 LLM 模型以提供简短响应</title>
      <link>https://stackoverflow.com/questions/78461646/how-to-restrict-a-13b-parameter-llm-model-to-provide-short-responses</link>
      <description><![CDATA[我尝试提示模型将响应保持在一定的字数限制内，但这不起作用。
当使用最大令牌时，我看到响应在最后被截断。
我使用的是 13b 型号。
关于如何实现这项工作有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78461646/how-to-restrict-a-13b-parameter-llm-model-to-provide-short-responses</guid>
      <pubDate>Fri, 10 May 2024 17:07:46 GMT</pubDate>
    </item>
    <item>
      <title>如何使用深度学习将位于各自房间的扬声器（音频设备）分组为集群？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78461347/how-to-group-speakers-audio-devices-located-in-their-respective-rooms-into-clu</link>
      <description><![CDATA[当前的任务涉及对位于不同房间的扬声器进行分组。例如，如果房间 1 中有 3 个设备，房间 2 中有 5 个设备，则目标是创建两组：一组用于房间 1，另一组用于房间 2，每个组包含各自的扬声器。为了实现这一目标，我们分析声音样本。这些样本是通过从一个扬声器播放声音并从同一房间的其他扬声器录制声音来收集的。此过程会生成一个 .wav 文件，其中包含在该特定房间中播放的声音的录音。
该项目的目的是增强对音频设备相对位置的理解，并探索对这些设备进行智能分组的有效方法或算法。我们的目标是利用这些见解来开发原型设备，以实际演示这一概念。随后，将对原型的性能进行评估，以评估其有效性。
以下是扬声器的基本功能：

扬声器可以播放声音文件，例如“alarm.mp3”。
扬声器可以录制任何声音，并使用其内置麦克风将其保存为 .wav 文件。
您可以调节扬声器输出的音量，使其更大或更小。
您还可以使用 dB 值修改输入增益，该增益决定麦克风捕获的声音量。

这是我解决这个问题的方法：
首先，我将多个设备放置在不同的房间中：扬声器 1 和 2 放置在房间 1 中，扬声器 3、4 和 5 放置在房间 2 中，扬声器 6 和 7 放置在房间 3 中。然后，我自动化了一个流程，其中每个扬声器录制 10 秒，同时另一个扬声器播放声音剪辑，例如“alarm.mp3” 6 秒。这会产生 7 个以聆听和演奏扬声器命名的样本（录音），例如“speaker3_speaker1”和“speaker3_speaker1”。表示扬声器 3 正在录音，而扬声器 1 正在播放。我对所有扬声器组合重复了这个过程，为我提供了一些可以使用的数据。
接下来，我使用 Python 库 Librosa 从这些录音中提取声音特征，包括梅尔倒谱系数 (MFCC) 和梅尔频谱图，它们本质上是代表声音特征的图像。这些特征作为深度学习模型的输入。
现在，我开发了一个 Siamese 神经网络来处理这些 MFCC 和频谱图图像并生成输出。但是，我目前陷入这个阶段，不确定如何继续。
我遇到的一个挑战是，即使扬声器 3 和 7 位于不同的房间，模型也可能会错误地认为它们位于同一个房间，因为它们来自同一家公司，具有相同的型号，并且玩游戏相同的声音文件(“alarm.mp3”)。此问题使分组过程变得复杂。
我正在寻求有关如何解决此问题的建议以及推进此项目的任何其他想法。我愿意探索上述之外的替代想法。请随意提出任何其他有助于解决前面段落中概述的挑战的方法或策略。]]></description>
      <guid>https://stackoverflow.com/questions/78461347/how-to-group-speakers-audio-devices-located-in-their-respective-rooms-into-clu</guid>
      <pubDate>Fri, 10 May 2024 16:08:30 GMT</pubDate>
    </item>
    <item>
      <title>FileNotFoundError：[Errno 2]没有这样的文件或目录：'Models\\model_new.json'</title>
      <link>https://stackoverflow.com/questions/78461085/filenotfounderror-errno-2-no-such-file-or-directory-models-model-new-json</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;Models\\model_new.json&#39;[文本]

这是我在下面的代码中遇到的错误。怎么解决呢。项目存储库的 Github 链接发布在底部。
类应用：

    def __init__(自身):

        self.hs = Hunspell(&#39;en_US&#39;)
        self.vs = cv2.VideoCapture(0)
        self.当前图像 = 无
        self.current_image2 = 无
        self.json_file = open(&quot;Models\model_new.json&quot;, &quot;r&quot;)
        self.model_json = self.json_file.read()
        self.json_file.close()

        self.loaded_model = model_from_json(self.model_json)
        self.loaded_model.load_weights(“模型\model_new.h5”)

        self.json_file_dru = open(&quot;Models\model-bw_dru.json&quot; , &quot;r&quot;)
        self.model_json_dru = self.json_file_dru.read()
        self.json_file_dru.close()

        self.loaded_model_dru = model_from_json(self.model_json_dru)
        self.loaded_model_dru.load_weights(“模型\model-bw_dru.h5”)
        self.json_file_tkdi = open(&quot;Models\model-bw_tkdi.json&quot; , &quot;r&quot;)
        self.model_json_tkdi = self.json_file_tkdi.read()
        self.json_file_tkdi.close()

        self.loaded_model_tkdi = model_from_json(self.model_json_tkdi)
        self.loaded_model_tkdi.load_weights(“模型\model-bw_tkdi.h5”)
        self.json_file_smn = open(&quot;Models\model-bw_smn.json&quot; , &quot;r&quot;)
        self.model_json_smn = self.json_file_smn.read()
        self.json_file_smn.close()

        self.loaded_model_smn = model_from_json(self.model_json_smn)
        self.loaded_model_smn.load_weights(“模型\model-bw_smn.h5”)

https://github.com/emnikhil/Sign-Language-To -文本转换
这是我用于最后一年项目的项目，[如果您必须获取我已附加的我从中克隆项目的存储库的任何参考，则会出现此错误]
这个项目是关于使用 CNN 将美国手语转换为文本，并应用高斯模糊滤波器和灰度来减小图像的大小。我找不到问题的任何解决方案，因此我没有尝试或更改任何代码行并寻找问题的解决方案。
]]></description>
      <guid>https://stackoverflow.com/questions/78461085/filenotfounderror-errno-2-no-such-file-or-directory-models-model-new-json</guid>
      <pubDate>Fri, 10 May 2024 15:19:30 GMT</pubDate>
    </item>
    <item>
      <title>MNIST - mnist.train_images() 问题 - HTTPError: Forbidden</title>
      <link>https://stackoverflow.com/questions/78460997/mnist-problem-with-mnist-train-images-httperror-forbidden</link>
      <description><![CDATA[我目前正在学习神经网络，我想使用 train_images() 函数，但我无法这样做。如果我运行以下代码：
导入 mnist

图像 = mnist.train_images()

，我会得到：
runfile(&#39;C:/Users/deriv/untitled0.py&#39;, wdir=&#39;C:/Users/deriv&#39;)
回溯（最近一次调用最后一次）：

  compat_exec 中的文件 ~\anaconda3\Lib\site-packages\spyder_kernels\py3compat.py:356
    exec（代码、全局变量、局部变量）

  文件 c:\users\deriv\untitled0.py:3
    图像 = mnist.train_images()

  train_images 中的文件 ~\anaconda3\Lib\site-packages\mnist\__init__.py:161
    返回 download_and_parse_mnist_file(&#39;train-images-idx3-ubyte.gz&#39;)

  download_and_parse_mnist_file 中的文件 ~\anaconda3\Lib\site-packages\mnist\__init__.py:143
    fname = download_file(fname, target_dir=target_dir, force=force)

  download_file 中的文件 ~\anaconda3\Lib\site-packages\mnist\__init__.py:59
    urlretrieve(url, target_fname)

  urlretrieve 中的文件 ~\anaconda3\Lib\urllib\request.py:241
    将 contextlib.close(urlopen(url, data)) 作为 fp：

  urlopen 中的文件 ~\anaconda3\Lib\urllib\request.py:216
    返回 opener.open(url, 数据, 超时)

  文件 ~\anaconda3\Lib\urllib\request.py:525 打开
    响应=方法（请求，响应）

  http_response 中的文件 ~\anaconda3\Lib\urllib\request.py:634
    响应 = self.parent.error(

  文件 ~\anaconda3\Lib\urllib\request.py:563 错误
    返回 self._call_chain(*args)

  _call_chain 中的文件 ~\anaconda3\Lib\urllib\request.py:496
    结果 = func(*args)

  http_error_default 中的文件 ~\anaconda3\Lib\urllib\request.py:643
    引发 HTTPError(req.full_url, 代码, msg, hdrs, fp)

HTTP 错误：禁止

我使用pip install正确安装了mnist，但是，我不知道为什么** mnist.train_images()** 会导致错误。抱歉，如果这是一个简单的问题，但是它会对我有很大帮助。
我不知道是否应该直接从 http://下载文件/yann.lecun.com/exdb/mnist/。但是我无法这样做，因为我没有访问此资源的权限。]]></description>
      <guid>https://stackoverflow.com/questions/78460997/mnist-problem-with-mnist-train-images-httperror-forbidden</guid>
      <pubDate>Fri, 10 May 2024 15:02:52 GMT</pubDate>
    </item>
    <item>
      <title>如何纠正 r 中光栅堆栈的方向</title>
      <link>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</link>
      <description><![CDATA[我有一个每日数据的 NetCDF 文件。我将其转换为光栅堆栈，但其方向不正确（我已附上图像）。我该如何纠正它。我还将我的代码附在本文中。 [raster_stack 图像和 r 代码](https://i.sstatic.net/UmI4kSNE.png)
另外，请告诉是否有人知道，我如何从这些栅格文件中提取年度数据到 Excel 格式（在 arcGIS 或 r 中）。我有 1955 年到 2023 年的栅格文件，其中包含每日降雨量数据，我想根据我拥有的管理形状文件提取年降雨量数据。
我在 r 中运行了代码，但没有取得任何进展。
库（光栅）
库（ncdf4）

ncfile &lt;- nc_open(“E:/IMD2/Rainfall/netcdfFiles_0.25 Degree/RF25_ind1955_rfp25.nc”)

variable_name &lt;- “RAINFALL”
降雨数据 &lt;- ncvar_get(ncfile, 变量名称)
lon &lt;- ncvar_get(ncfile, “经度”)
lat &lt;- ncvar_get(ncfile, “纬度”)
时间 &lt;- ncvar_get(ncfile, “TIME”)
lon_range &lt;- 范围(lon)
lat_range &lt;- 范围(lat)

raster_stack &lt;- stack()
for (i in 1:dim(rainfall_data)[3]) {
  raster_layer &lt;- raster(matrix(rainfall_data[,,i], nrow = nrow(rainfall_data), ncol = ncol(rainfall_data)),
                         xmn = lon_range[1], xmx = lon_range[2], ymn = lat_range[1], ymx = lat_range[2],
                         crs =“+proj=longlat +datum=WGS84”）
  raster_stack &lt;- addLayer(raster_stack, raster_layer)
}

&lt;前&gt;&lt;代码&gt;绘图（raster_stack）
翻转 = t(翻转(raster_stack))
情节（翻转）
]]></description>
      <guid>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</guid>
      <pubDate>Thu, 09 May 2024 13:18:03 GMT</pubDate>
    </item>
    <item>
      <title>构建音频到图像分类并制作最佳架构模型</title>
      <link>https://stackoverflow.com/questions/78451244/building-audio-to-image-classification-and-make-a-best-architecture-model</link>
      <description><![CDATA[如何确定音频到图像分类模型构建的任何特定应用程序或用例？
我尝试制作像CNN一样的架构模型，但它无法预测图像，我期望模型能够将相应的图像识别为音频，但毕竟很难实现。]]></description>
      <guid>https://stackoverflow.com/questions/78451244/building-audio-to-image-classification-and-make-a-best-architecture-model</guid>
      <pubDate>Wed, 08 May 2024 21:33:54 GMT</pubDate>
    </item>
    <item>
      <title>高斯模糊相对于像素的导数</title>
      <link>https://stackoverflow.com/questions/77701235/derivative-of-gaussian-blur-with-respect-to-the-pixels</link>
      <description><![CDATA[我正在对图像应用高斯模糊，其中原始图像的每个像素都针对某种目的进行优化，并且高斯模糊是中间变换。由于多种原因，能够获得此变换的雅可比行列式对我来说非常重要。
例如，如果像素的变换可以用 G(p) 给出，那么我需要能够找到 dG/dp。
我对如何真正找到这个感到困惑。它不必是分析性的，它可以通过 Python 程序进行数值化。
我真的不知道从哪里开始。
我有一个 150x150 像素的输入图像。我正在通过 OpenCV 应用高斯模糊。我知道如何找到高斯 X 和 Y 导数，但我不知道如何找到整个变换相对于像素的雅可比。
从数字上讲，我认为有限差分法可行（稍微改变像素并查看效果），但可能有更好的方法不是吗？]]></description>
      <guid>https://stackoverflow.com/questions/77701235/derivative-of-gaussian-blur-with-respect-to-the-pixels</guid>
      <pubDate>Fri, 22 Dec 2023 00:49:16 GMT</pubDate>
    </item>
    <item>
      <title>带有正则化的 Numpy 线性回归</title>
      <link>https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization</link>
      <description><![CDATA[我没有发现我的正则化线性回归代码有什么问题。非正规化我只是这样，我有理由确定这是正确的：
将 numpy 导入为 np

def get_model（特征，标签）：
    返回 np.linalg.pinv(features).dot(labels)

这是我的正则化解决方案的代码，我没有看到它有什么问题：
def get_model(特征、标签、lamb=0.0):
    n_cols = features.shape[1]
    返回 linalg.inv(features.transpose().dot(features) +lambda * np.identity(n_cols))\
            .dot(features.transpose()).dot(标签)

使用羔羊的默认值 0.0，我的意图是它应该给出与（正确的）非正则化版本相同的结果，但差异实际上相当大。
有人看出问题出在哪里吗？]]></description>
      <guid>https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization</guid>
      <pubDate>Mon, 15 Dec 2014 03:26:53 GMT</pubDate>
    </item>
    </channel>
</rss>