<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 12:29:01 GMT</lastBuildDate>
    <item>
      <title>分类器 ML 基于特征和连续变量值预测类别的算法</title>
      <link>https://stackoverflow.com/questions/78825453/classifier-ml-algorithm-for-predicting-class-based-on-features-and-the-value-of</link>
      <description><![CDATA[我正在尝试编写一个分类器，我可以训练它来查看问题实例，并根据其特征和特定变量的值预测问题属于哪个类。我不是在寻找问题的答案，而只是寻找一些关于我应该专注于研究哪种 ML 算法的指导。
这是一个示例问题。假设我们有一些蛋糕食谱。它们具有以下连续变量特征：

面粉量
牛奶量
鸡蛋数量
糖的量

我们还有一个二进制变量：

蛋糕是用燃气还是电烤箱烤的？ （假设燃气为 1，电为 0）
每个食谱都烹制了两次，一次使用燃气，一次使用电

还通过让一些人吃蛋糕来测试蛋糕，每个人都给每个蛋糕一个“美味”指数。这也是一个连续变量，值越高，人们就越喜欢这个蛋糕。
我多次运行这个程序，最终得到一个数据集，每个食谱有两个条目（一个燃气，一个电），每个食谱都有各自的“美味指数”。我们会发现，对于每道菜谱，人们倾向于用燃气或电烹饪，这反映在口味指数中。
现在，我知道这是不现实的，但这是一种说明我想做什么的简单方法。
在训练系统执行此操作后，我现在想让系统采用一种新食谱，并根据具有相似（不一定相同）特征的过去食谱以及燃气或电是否提供最高的口味指数来预测应该使用燃气还是电烹饪。
任何关于哪种机器学习算法最适合此任务的建议都将不胜感激。如前所述，我只是想缩小我的研究范围，不一定是被动接受答案。
提前感谢大家
到目前为止，我已经使用 Scikit-learn 在 Python 中尝试了几种 ML 算法。事实证明，KNN 在基于特征预测类别方面最为准确，但我不确定如何将“品味指数”反映到其中。此外，这似乎是监督式机器学习的一个例子，因为数据被标记（天然气或电力）。]]></description>
      <guid>https://stackoverflow.com/questions/78825453/classifier-ml-algorithm-for-predicting-class-based-on-features-and-the-value-of</guid>
      <pubDate>Fri, 02 Aug 2024 12:17:07 GMT</pubDate>
    </item>
    <item>
      <title>多种编程语言 [关闭]</title>
      <link>https://stackoverflow.com/questions/78824994/multiple-programming-language</link>
      <description><![CDATA[为什么我们需要学习多种编程语言，以及它如何帮助我在大公司找到工作或实习机会？我正在学习数据科学、人工智能和机器学习，而 Python 是我的主要语言，所以我正在考虑将 C++ 添加为我的第二语言。学习多种语言对黑客马拉松有什么帮助？我将非常感谢您的建议。。
我正在努力提高我的技能。。]]></description>
      <guid>https://stackoverflow.com/questions/78824994/multiple-programming-language</guid>
      <pubDate>Fri, 02 Aug 2024 10:25:13 GMT</pubDate>
    </item>
    <item>
      <title>如何通过调整函数的一个输入参数来训练它输出正确的值（基于训练数据）？</title>
      <link>https://stackoverflow.com/questions/78824490/how-to-train-a-function-to-output-a-correct-value-based-on-training-data-by-ad</link>
      <description><![CDATA[我是机器学习的新手。我有一个项目，需要帮助选择合适的机器学习算法。
我有一个包含三个输入（x、y 和 N）的函数：
F(x, y, N) → R
我希望软件自动调整并给出 N 的值（基于输入值 x 和 y），以便函数给出正确的值 R。
我有一个如下所示的训练数据集：



x
y
R




7
2
20


8
5
6


15
6
13


...
...



你对我应该寻找哪种合适的机器学习算法？如果神经网络合适，您对从多少层/节点开始有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78824490/how-to-train-a-function-to-output-a-correct-value-based-on-training-data-by-ad</guid>
      <pubDate>Fri, 02 Aug 2024 08:29:10 GMT</pubDate>
    </item>
    <item>
      <title>关于训练模型过程中遇到的问题</title>
      <link>https://stackoverflow.com/questions/78824487/questions-about-problems-encountered-during-training-model</link>
      <description><![CDATA[我目前正在训练一个 AI 模型，在训练过程中遇到了一些问题，如附图所示。有人能帮我找出问题并提出解决方案吗？问题情况和设置如下：

设置

模型的参数每 64 次迭代更新一次。

模型每个 epoch 需要 30 步，并且有 5 个 warmup epoch。

我正在使用名为 CosineAnnealingWarmup 的学习率调度程序，最大和最小学习率分别为 2e-4 和 8e-7。



问题情况

损失在一段时间内会减少，但在某个点之后开始振荡。

模型的性能指标在某个时间点之后停滞或下降点。




我将非常感激您提供的任何帮助。以下是我的损失、指标和 lr 调度程序。


我尝试了以下方法，但没有奏效。

我正在使用 AsymmetricLoss，并尝试将 gamma_neg 值设置为 2、将 gamma_pos 设置为 0、将 clip 设置为 0.1。

我还将批次大小从 256 增加到 512，但没有任何效果。

我目前正在尝试增加模型的容量，但我似乎得到了类似的结果。


对于 AsymmetricLoss 代码如下：
class AsymmetricLoss(nn.Module):
def __init__(
self, gamma_neg=3, gamma_pos=0, clip=.05, eps=1e-8,
disable_torch_grad_focal_loss=True, cls_cnt_list=None, smoothing=.1
):
super().__init__()

self.gamma_neg = gamma_neg
self.gamma_pos = gamma_pos
self.clip = clip
self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss
self.eps = eps
self.smoothing = smoothing

如果 cls_cnt_list != None:
n_samples = sum(cls_cnt_list)
self.weights = torch.tensor([n_samples / cnt for cnt in cls_cnt_list]) / n_samples

如果 torch.cuda.is_available():
self.weights = self.weights.cuda()
else:
self.weights = None

def forward(self, x, y):
n_pos = y.sum(dim=1, keepdim=True)
y = (1 - self.smoothing) * y + (self.smoothing / (y.shape[1] - n_pos))

# 计算概率
x_sigmoid = torch.sigmoid(x)
xs_pos = x_sigmoid
xs_neg = 1 - x_sigmoid

# 不对称裁剪
if self.clip is not None and self.clip &gt; 0:
xs_neg = (xs_neg + self.clip).clamp(max=1)

# 基本 CE 计算
los_pos = y * torch.log(xs_pos.clamp(min=self.eps))
los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))
loss = los_pos + los_neg

# 非对称聚焦
if self.gamma_neg &gt; 0 or self.gamma_pos &gt; 0:
if self.disable_torch_grad_focal_loss:
torch.set_grad_enabled(False)
pt0 = xs_pos * y
pt1 = xs_neg * (1 - y) # pt = p if t &gt; 0 else 1-p
pt = pt0 + pt1
one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)
one_sided_w = torch.pow(1 - pt, one_sided_gamma)
if self.disable_torch_grad_focal_loss:
torch.set_grad_enabled(True)
loss *= one_sided_w

# 类权重
if self.weights != None:
loss *= self.weights.unsqueeze(0)

return -loss.sum() * 1024
]]></description>
      <guid>https://stackoverflow.com/questions/78824487/questions-about-problems-encountered-during-training-model</guid>
      <pubDate>Fri, 02 Aug 2024 08:28:46 GMT</pubDate>
    </item>
    <item>
      <title>多类图像分类的准确率未提高超过 50%</title>
      <link>https://stackoverflow.com/questions/78823757/accuracy-for-multi-class-image-classification-not-improving-past-50</link>
      <description><![CDATA[我正在开展一个项目，根据牛仔裤背面的图案预测牛仔裤的品牌。
为此，我在网上收集了 3 个不同牛仔裤品牌（arizona、levi、lucky brand）的数据，并为每个品牌获取了大约 100 张图片。然后我做了一些数据增强，虽然非常基础
def generate_more_images():
for dir in os.listdir(&#39;jean_img&#39;):
if dir != &#39;.DS_Store&#39;:
n = 0
for image in os.listdir(f&#39;jean_img/{dir}&#39;):

if image != &#39;.DS_Store&#39;:
img = Image.open(f&#39;jean_img/{dir}/{image}&#39;)
img = img.resize((500,500))
for i in range(10):
img = img.rotate(np.random.uniform(-35,35))
bright_factor = np.random.uniform(0.6, 1.4)
augmenter = ImageEnhance.Brightness(img) 
img =增强器.增强（亮度因子）
如果 n &lt; 200：
img.save（f&#39;jean_img_expand_test/{dir}_expand/{n}_{dir}_{image}&#39;）
elif n &lt; 300:
img.save(f&#39;jean_img_expand_valid/{dir}_expand/{n}_{dir}_{image}&#39;)
else:
img.save(f&#39;jean_img_expand_train/{dir}_expand/{n}_{dir}_{image}&#39;)
n += 1

然后利用这些图像，我训练并测试了多个模型，由于这些图像的复杂性，我认为这些模型的表现会很好，但令我惊讶的是，我的模型表现最好的时候也只能达到 60 多分到 50 多分。
optimizer = Adam(learning_rate=0.001)
reduce_lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.2, waiting=5, min_lr=0.00001)

callback = callups.EarlyStopping(monitor=&#39;val_accuracy&#39;, waiting=20, restore_best_weights=True)

model = Sequential([
layer.Input(shape=(500, 500, 3)), 

layer.Conv2D(32, (3, 3), padding=&#39;same&#39;),
layer.LeakyReLU(alpha=0.3),
layer.MaxPooling2D((2, 2)),
layer.Dropout(0.25),

layer.Flatten(),

layer.Dense(64),
layer.LeakyReLU(alpha=0.3),
layer.Dropout(0.5),

layer.Dense(3,activation=&#39;softmax&#39;)
])
model.compile(optimizer=optimizer, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

model.fit(
train_images,
train_labels,
epochs=100,
validation_data=(val_images, val_labels),
callbacks=[callback, reduce_lr]
)

以下是一些训练图像：



我对计算机视觉还很陌生，但我认为这个分类问题并不难。我已经解决了更多类别的问题，算法运行得很好。如果有人能指出我工作中的缺陷，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78823757/accuracy-for-multi-class-image-classification-not-improving-past-50</guid>
      <pubDate>Fri, 02 Aug 2024 04:11:08 GMT</pubDate>
    </item>
    <item>
      <title>如何利用 Pytorch 的 CrossEntropyLoss 应用类权重来解决多类多输出问题的不平衡数据分类问题</title>
      <link>https://stackoverflow.com/questions/78823685/how-to-apply-class-weights-to-using-pytorchs-crossentropyloss-to-solve-an-imbal</link>
      <description><![CDATA[我正在尝试使用加权损失函数来处理数据中的类别不平衡问题。我的问题是多类别和多输出问题。例如（我的数据有五个输出/目标列（output_1、output_2、output_3），每个目标列有三个类（class_0、class_1 和 class_2）。我目前正在使用 pytorch 的交叉熵损失函数https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html，我看到它有一个权重参数，但我的理解是，这个相同的权重将统一应用于每个输出/目标，但我想在每个输出/目标中为每个类应用单独的权重。
具体来说，我可以获得如下所示的数据



A
B
C
D
E
OUTPUT_1
OUTPUT_2
OUTPUT_3




5.65
3.56
0.94
9.23
6.43
0
2
1


7.43
3.95
1.24
7.22
&lt; td&gt;2.66
0
0
0


9.31
2.42
2.91
2.64
6.28
2
0
2


8.19
5.12
1.32
3.12
8.41
0
2
0


9.35
1.92
3.12
4.13
3.14
0
1
1


8.43
9.72
7.23
8.29
9.18
1
0
2


4.32
2.12
3.84
9.42
8.19
0
1
0


3.92
3.91
2.90
8.1 9
8.41
2
0
2


7.89
1.92
4.12
8.19
7.28
0
1
2
&lt; /tr&gt;

5.21
2.42
3.10
0.31
1.31
2
0
0



因此，
输出 1 中的比例为：0 = 0.6、1 = 0.1、2 = 0.3
输出 2 中的比例为：0 = 0.4、1 = 0.3、2 = 0.3
输出 3 中的比例为：0 = 0.4、1 = 0.2、2 = 0.4

我想根据每个输出列中的类分布应用类权重，以便重新规范化（或重新平衡？不确定这里要使用的术语是什么）第 1 类为 0.15，第 0 类和第 2 类各为 0.425（因此对于 output_1，权重将是 [0.425/0.6, 0.15/0.1, 0.425/0.3]，对于输出 2，它将是 [0.425/0.4, 0.15/0.3, 0.425/0.3] 等）。相反，我理解 pytorch 的 crossentropy 损失函数中的权重参数目前正在执行的操作是将单个类权重应用于每个输出列。我想知道我是否遗漏了什么，是否有办法使用 pytorch 的 crossentropyloss 函数来做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78823685/how-to-apply-class-weights-to-using-pytorchs-crossentropyloss-to-solve-an-imbal</guid>
      <pubDate>Fri, 02 Aug 2024 03:34:55 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow model.evaluate() 崩溃，因为不支持 lab​​el_mode 中的 None 值</title>
      <link>https://stackoverflow.com/questions/78823152/tensorflow-model-evaluate-crashing-because-none-values-from-label-mode-not-sup</link>
      <description><![CDATA[我尝试在 preprocessing.image_dataset_from_directory 上运行 model.evaluate()，但由于 label_mode=None 而无济于事
我尝试从 ImageDataGenerator 的 flow_from_directory 实现与 class_mode=&#39;input&#39; 类似的功能。我尝试了多次，但一直收到相同的错误消息。我也尝试过手动更改模型的输入，但我仍然不确定我哪里出错了。下面是我的代码：
 SIZE = 128
batch_size = 64

train_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\noncloud_train&#39;, 
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None
)

validation_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\noncloud_test&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None

)

anomaly_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\#omitted user name#\Downloads\archive (1)\cloud&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None

)

rescaling_layer = layer.Rescaling(1./255)

def change_inputs(images, labels=None):
x = tensorflow.image.resize(rescaling_layer(images),[SIZE, SIZE], method=tensorflow.image.ResizeMethod.NEAREST_NEIGHBOR)
return x, x

train_dataset = train_generator.map(change_inputs)
validation_dataset = validation_generator.map(change_inputs)
anomaly_dataset = anomaly_generator.map(change_inputs)

#此处有一些模型构建和编译代码，但我省略了它#

# 检查侦察。验证数据和异常图像之间的误差
validation_error = model.evaluate(validation_generator)
anomaly_error = model.evaluate(anomaly_generator)

# 打印出结果
print(f&quot;Recon. error for the validation data is {validation_error}&quot;)
print(f&quot;Recon. error for the anomaly_error is {anomaly_error}&quot;)

最后四行是由于 label_mode 而出现的问题]]></description>
      <guid>https://stackoverflow.com/questions/78823152/tensorflow-model-evaluate-crashing-because-none-values-from-label-mode-not-sup</guid>
      <pubDate>Thu, 01 Aug 2024 21:50:38 GMT</pubDate>
    </item>
    <item>
      <title>更清晰的分割 SAM (Segment Anything)</title>
      <link>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</link>
      <description><![CDATA[好吧，我目前正在做一个项目，我需要像这样分割图像上的对象：
图像 1
图像 2
我选择使用 Meta 的 AI SAM（Segment Anything）来裁剪这些对象。
我的代码如下所示：
import cv2
import numpy as np
import sys, os
from pathlib import Path
import torch
import surveillance as sv
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor

# 获取命令行参数
num = sys.argv[2]
img_path = sys.argv[1]
folder_path = sys.argv[3]

# 从给定路径加载图像
img = cv2.imread(img_path)

# 用于预处理图像以进行裁剪的函数
def preprocess_image_cut(img):
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
return gray

# 用于获取干净图像的函数
def get_clean_image(img, filter_level=1):
gray = preprocess_image_cut(img)
blurred_image = cv2.GaussianBlur(gray, (3, 3), 0)
_, binary_image = cv2.threshold(blurred_image, 210, 255, cv2.THRESH_BINARY)

kernel = np.ones((1, 1), np.uint8)
result_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)
result_image = cv2.medianBlur(result_image, filter_level)

output_image = cv2.bitwise_or(gray, result_image)
return output_image

# 设置管道的函数
def setup_pipeline():
HOME = &#39;C:/&#39;
CHECKPOINT_PATH = os.path.join(HOME, &#39;weights&#39;, &#39;sam_vit_h_4b8939.pth&#39;)
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
MODEL_TYPE = &quot;vit_h&quot;

sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
mask_generator = SamAutomaticMaskGenerator(sam)
return mask_generator

# 运行 SAM 模型的函数
def run_sam(mask_generator, clean_image):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
sam_result = mask_generator.generate(image_rgb)
mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)
detections = sv.Detections.from_sam(sam_result=sam_result)

annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)

masks = [mask[&#39;segmentation&#39;] for mask in sorted(sam_result, key=lambda x: x[&#39;area&#39;, reverse=True])]
return mask

# 设置掩码生成器
mask_generator = setup_pipeline()

if __name__ == &quot;__main__&quot;:
if img_path.endswith(&quot;.png&quot;):
save_path = folder_path
os.makedirs(save_path, exist_ok=True)
if os.path.isdir(f&#39;{folder_path}/PROCESSED&#39;):
os.makedirs(f&#39;{folder_path}/PROCESSED&#39;, exist_ok=True)
img = cv2.imread(img_path)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
clean_image = get_clean_image(img, 3)

print(&quot;开始生成掩码&quot;)
mask = run_sam(mask_generator, clean_image)

for i, mask in enumerate(masks):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgra = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGRA)
extract_region = np.zeros_like(image_bgra)
extract_region[mask] = image_bgra[mask]
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
extract_region = extract_region[y:y+h, x:x+w]
extracted_region[:, :, 3] = (mask[y:y+h, x:x+w] &gt; 0) * 255
save_path2 = f&#39;{folder_path}/PROCESSED/img_{x}_{y}_{w}_{h}.png&#39;
cv2.imwrite(save_path2, extracted_region)

print(&quot;Finished&quot;)

但我目前在一些问题上遇到了困难，比如我不想让 Sam 分割数字，也不想分割将对象与数字联系起来的线条。
有人能对这个话题有什么想法吗，也接受其他分割图像的方法。
分割更清晰，垃圾分割更少]]></description>
      <guid>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</guid>
      <pubDate>Thu, 01 Aug 2024 20:21:17 GMT</pubDate>
    </item>
    <item>
      <title>Colab：内存不足，无法加载 Llama 3</title>
      <link>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</link>
      <description><![CDATA[我正在按照 Youtube 上的教程操作，然后想要加载 Llama3 8B：
model_name = &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;

tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hugging_face_key)
model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key)

得到：
您的会话失败，因为所有可用 RAM 都已使用

尝试过：model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key, low_cpu_mem_usage=True)
但再次出现相同的错误]]></description>
      <guid>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</guid>
      <pubDate>Thu, 01 Aug 2024 12:45:03 GMT</pubDate>
    </item>
    <item>
      <title>Pyannote：离线加载并应用说话人区分</title>
      <link>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</link>
      <description><![CDATA[我尝试离线使用 Pyannotes 模型。
我是这样加载和应用模型的：
from pyannote.audio import Pipeline

access_token = &#39;xxxxxxxxxxx&#39;

model = Pipeline.from_pretrained(
&quot;pyannote/speaker-diarization-3.1&quot;,
use_auth_token=access_token)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

这样就没问题了。
但是现在我按照离线使用的说明操作：https://github.com/pyannote/pyannote-audio/blob/develop/tutorials/applying_a_pipeline.ipynb
我的目录结构如下：
src-
     |-pyannote_offline_config.yaml
     |-pyannote_pytorch_model.bin
---- YAML ----
version: 3.1.0

pipeline:
name: pyannote.audio.pipelines.SpeakerDiarization
params:
clustering: AgglomerativeClustering
embedding: pyannote/wespeaker-voxceleb-resnet34-LM
embedding_batch_size: 32
embedding_exclude_overlap: true
分段：src/pyannote_pytorch_model.bin
分段批处理大小：32

参数：
聚类：
方法：质心
min_cluster_size：12
阈值：0.7045654963945799
分段：
min_duration_off：0.0

---- 正在加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但结果却是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
好的，下次尝试：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

params = {&#39;clustering&#39;:
{&#39;method&#39;: &#39;centroid&#39;,
&#39;min_cluster_size&#39;: 12,
&#39;threshold&#39;: 0.7045654963945799},
&#39;segmentation&#39;:
{&#39;min_duration_off&#39;: 0.0}}

pipeline = model.instantiate(params)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

pipeline(path_in,
num_speakers=num_speakers).labels()

但结果是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
我不明白问题所在。
如果我这样做，它就会起作用：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;, path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但上传到 gitlab 后，测试管道显示：“无法下载‘pyannote/speaker-diarization-3.1’管道。
这可能是因为管道是私有的或封闭的，因此请确保进行身份验证。访问 https://hf.co/settings/tokens
创建您的访问令牌并重试：
Pipeline.from_pretrained(&#39;pyannote/speaker-diarization-3.1&#39;,
... use_auth_token=YOUR_AUTH_TOKEN)&quot;
因此，似乎我的本地计算机上有一些东西没有通过 pip 安装下载。例如，如果我不使用 yaml 加载它，而只使用 model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;)，它也会起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</guid>
      <pubDate>Thu, 01 Aug 2024 12:28:41 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 llama 3 8b 训练 LLaVA-NeXT</title>
      <link>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</guid>
      <pubDate>Thu, 01 Aug 2024 11:56:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在人工神经网络中进行样本外预测？</title>
      <link>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</guid>
      <pubDate>Thu, 01 Aug 2024 10:36:16 GMT</pubDate>
    </item>
    <item>
      <title>面部识别 - 机器学习 [关闭]</title>
      <link>https://stackoverflow.com/questions/78818666/facial-recognition-machine-learning</link>
      <description><![CDATA[我尝试在 Google Colab 上使用 Tensorflow 进行面部识别，但遇到了错误。之前运行正常，但现在却出现此错误。完整的 .ipynb 文件已链接（请注意，您需要一个包含 .jpg 文件的负、正和锚文件夹才能运行程序。）
使暹罗模型出错
文件链接：https://www.mediafire.com/file/a5azngcpmdrrxyd/facial_recognition.ipynb/file
我尝试从 4.3 函数中删除嵌入函数，但当它进入训练时会抛出另一个错误。训练错误
文本代码错误复制：
（删除嵌入后）
Epoch 1/100
-----------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-123-5343d5708b2c&gt; in &lt;cell line: 5&gt;()
3 
4 # 使用提供的训练数据和指定的 epoch 数训练 Siamese 网络
----&gt; 5 训练（siamese_model、train_data、EPOCHS）

7 帧
/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py 在 binary_crossentropy（target、output、from_logits）中
666 
667 如果 len（target.shape）!= len（output.shape）：
-&gt; 668 引发 ValueError(
669 “参数 `target` 和 `output` 必须具有相同的等级”
670 “(ndim)。已收到：”

ValueError：在用户代码中：

文件“&lt;ipython-input-20-c4cff50f6a59&gt;”，第 18 行，在 train_step *
loss = binary_cross_loss(y, yhat)
文件“/usr/local/lib/python3.10/dist-packages/keras/src/losses/loss.py”，第 43 行，在 __call__ **
loss = self.call(y_true, y_pred)
文件“/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py”，第 27 行，在 call
return self.fn(y_true, y_pred, **self._fn_kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py&quot;，第 1913 行，在 binary_crossentropy 中
ops.binary_crossentropy(y_true, y_pred, from_logits=from_logits),
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py&quot;，第 1398 行，在 binary_crossentropy 中
return backend.nn.binary_crossentropy(
文件 &quot;/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py&quot;，第 668 行，在 binary_crossentropy 中
引发 ValueError(

ValueError: 参数 `target` 和 `output` 必须具有相同的等级 (ndim)。收到：target.shape=(16,)，output.shape=(16, 100, 100, 1)

（在删除嵌入之前）

[&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_87&gt;]
-------------------------------------------------------------------------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-139-ccc48c560ce8&gt; in &lt;cell line: 24&gt;()
22 
23 # 使用 make_siamese_model() 函数创建 Siamese 神经网络模型
---&gt; 24 siamese_model = make_siamese_model()
25 
26 # 显示 Siamese 模型的架构和参数摘要

2 帧
&lt;ipython-input-138-755d3b4e05cd&gt; in call(self, input_embedding, validation_embedding)
7 # 魔法在这里发生 - 相似度计算
8 def call(self, input_embedding, validation_embedding):
----&gt; 9 return tf.math.abs(input_embedding - validation_embedding)

TypeError：调用 L1Dist.call() 时遇到异常。

无法自动推断“l1_dist_12”（类型为 L1Dist）的输出形状/dtype。 `L1Dist.call()` 方法不正确，或者您需要实现 `L1Dist.compute_output_spec() / compute_output_shape()` 方法。遇到错误：

不支持的操作数类型：-：&#39;list&#39; 和 &#39;list&#39;

L1Dist.call() 收到的参数：
• args=([&#39;&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_88&gt;&#39;], [&#39;&lt;KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_89&gt;&#39;])
• kwargs=&lt;class &#39;inspect._empty&#39;&gt;
]]></description>
      <guid>https://stackoverflow.com/questions/78818666/facial-recognition-machine-learning</guid>
      <pubDate>Wed, 31 Jul 2024 23:57:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 进行单类物体检测，结果为假阳性 [关闭]</title>
      <link>https://stackoverflow.com/questions/78793283/single-class-object-detection-using-cnn-getting-false-positive</link>
      <description><![CDATA[在这里，我尝试使用 cnn 构建一个 Manhole 物体检测，在这个模型中，经过训练我得到了 95% 的准确率。我得到的是假阳性，例如，如果我用人孔（训练对象）测试图像进​​行检测，它将绘制边界框，而我测试没有训练对象的随机图像，则会出现一个随机边界框，这就是问题所在，在实时网络摄像头测试中也是如此，但在这里，如果对象甚至没有被检测到，则会在框架中获取一些随机边界框。这里我提供我的代码，请帮助
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.layers import Conv2D, Input, BatchNormalization``, Flatten, MaxPool2D, Dense
from pathlib import Path

train_img = Path(&quot;DATASET/train/Manhole&quot;)
val_img = Path(&quot;DATASET\valid\Manhole&quot;)

train_csv = pd.read_csv(&#39;DATASET/train/Manhole/_annotations.csv&#39;) 
val_csv = pd.read_csv(&#39;DATASET/valid/_annotations.csv&#39;)
#print(train_csv)
train_csv[[&#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]] = train_csv[[&#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]].fillna(0)
train_csv[[&#39;xmin&#39;,&#39;ymin&#39;,&#39;xmax&#39;,&#39;ymax&#39;]] = train_csv[[&#39;xmin&#39;,&#39;ymin&#39;,&#39;xmax&#39;,&#39;ymax&#39;]].astype(int)
train_csv.drop_duplicates(subset=&#39;filename&#39;,inplace=True, ignore_index=True)
val_csv.drop_duplicates(subset=&#39;filename&#39;, inplace=True, ignore_index=True)

def datagenerator(df ,batch_size ,path):
while True:
images = np.zeros((batch_size,640,640,3))
bounding_box_coords = np.zeros((batch_size, 4))

for i in range(batch_size):
rand_index = np.random.randint(0, train_csv.shape[0])
row = df.loc[rand_index, :]
images[i] = cv2.imread(str(path/row.filename)) / 255.
bounding_box_coords[i] = np.array([row.xmin, row.ymin, row.xmax, row.ymax])

产生 {&#39;filename&#39;: images}, {&#39;coords&#39;: bounding_box_coords}

# example, label = next(datagenerator(batch_size=16))
# img = example[&#39;filename&#39;][0]
# bbox_coords = label[&#39;coords&#39;][0] 

# x1, y1, x2, y2 = map(int, bbox_coords)
# print(&#39;bbox cords&#39;,x1,y1,x2,y2)
# cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 3)
# cv2.putText(img, &#39;&#39;, (x1,y1-10),cv2.FONT_HERSHEY_DUPLEX, 0.8, (0, 0, 255), 2)
# # plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
# plt.imshow(img)
# plt.show()

input_ = 输入(shape=[640, 640, 3], name=&#39;filename&#39;)

x = input_
x = Conv2D(16, (3,3), 激活=&#39;relu&#39;, 填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2, 填充=&#39;same&#39;)(x)

x = Conv2D(32, (3,3), 激活=&#39;relu&#39;, 填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2, 填充=&#39;same&#39;)(x)

x = Conv2D(64, (3,3),激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，填充=&#39;same&#39;)(x)

x = Conv2D(128，(3,3)，激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，填充=&#39;same&#39;)(x)

x = Conv2D(256，(3,3)，激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，填充=&#39;same&#39;)(x)

x = Conv2D(312，(3,3)，激活=&#39;relu&#39;，填充=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Conv2D(500，(3,3)，activation=&#39;relu&#39;，padding=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Conv2D(580，(3,3)，activation=&#39;relu&#39;，padding=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Conv2D(680，(3,3)，activation=&#39;relu&#39;，padding=&#39;same&#39;)(x)
x = BatchNormalization()(x)
x = MaxPool2D(2，padding=&#39;same&#39;)(x)

x = Flatten()(x)
x = Dense(256，激活=&#39;relu&#39;)(x)
x = Dense(32, 激活=&#39;relu&#39;)(x)
输出坐标 = Dense(4, 名称=&#39;coords&#39;)(x)

模型 = tf.keras.models.Model(input_,output_coords)

模型摘要()

模型编译(loss={&#39;coords&#39;: &#39;mse&#39;},
优化器=tf.keras.optimizers.Adam(5e-5), 
指标={&#39;coords&#39;: &#39;accuracy&#39;})

检查点回调 = ModelCheckpoint(&#39;model_Checkpoint.h5&#39;, 监视器=&#39;val_loss&#39;, save_best_only=True, 模式=&#39;min&#39;)

模型拟合(数据生成器(df=train_csv,batch_size=6,path=train_img), 
epochs=80, steps_per_epoch=150,
validation_data=datagenerator(df=val_csv,batch_size=6,path=val_img), 
validation_steps=240, 
callbacks=[checkpoint_callback])

model.save(&#39;model2.h5&#39;)

我需要代码来在实时网络摄像头中正确检测训练过的对象，而不会出现任何边界框，并从 cnn 接收置信度值，这样我就可以设置检测的阈值]]></description>
      <guid>https://stackoverflow.com/questions/78793283/single-class-object-detection-using-cnn-getting-false-positive</guid>
      <pubDate>Thu, 25 Jul 2024 12:22:40 GMT</pubDate>
    </item>
    <item>
      <title>TF2 和 Python 中的 BERT 预处理器模型存在问题</title>
      <link>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</link>
      <description><![CDATA[我正在尝试使用 BERT 进行文本分类项目。但是我一直遇到此错误
`
ValueError Traceback（最近一次调用最后一次）
Cell In[37]，第 4 行
2 text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
3 bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;preprocessing&#39;)
----&gt; 4 preprocessed_text = bert_preprocess(text_input)
5 bert_encoder = hub.KerasLayer(encoder_url, 
6 trainable=True, 
7 name=&#39;BERT_encoder&#39;)
8 output = bert_encoder(preprocessed_text)
ValueError：调用层“preprocessing”（类型 KerasLayer）时遇到异常。
KerasTensor 是符号化的：它是形状和数据类型的占位符。它没有任何实际数值。您无法将其转换为 NumPy 数组。

调用层“预处理”（类型 KerasLayer）接收的参数：
• 输入=&lt;KerasTensor shape=(None,), dtype=string, sparse=None, name=text&gt;
• 训练=None

KerasTensor 是符号化的：它是形状和数据类型的占位符。它没有任何实际数值。您无法将其转换为 NumPy 数组。


构建此模型时：

preprocess_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3&#39;
encoder_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-768-a-12/versions/2&#39;

# Bert 层
text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;preprocessing&#39;)
preprocessed_text = bert_preprocess(text_input)
bert_encoder = hub.KerasLayer(encoder_url,
trainable=True, 
name=&#39;BERT_encoder&#39;)
outputs = bert_encoder(preprocessed_text)

# 神经网络层
l = tf.keras.layers.Dropout(0.1)(outputs[&#39;pooled_output&#39;])
l = tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;,name=&#39;output&#39;)(l)

# 构建最终模型
model = tf.keras.Model(inputs=[text_input],outputs=[l])

我看过无数教程，甚至使用过 tensorflow 文档中的教程，但即使我复制粘贴，它们仍然不起作用。我尝试过不同版本的 tf、tf-text 和 tf-hub。我正在为这个项目使用 tensorflow-gpu-jupyter docker 容器。
以下是我安装库的方法：
!pip install &quot;tensorflow-text&quot;
!pip install &quot;tf-models-official&quot;
!pip install &quot;tensorflow-hub&quot;

版本如下：
Tensorflow：2.16.1
tensorflow-text：2.16.1
tensorflow-hub：0.16.1
我看到的所有其他论坛都说要执行 tf.config.run_functions_eagerly(True)，但这不起作用。
任何方法都会有帮助。如果您知道如何解决，请回答。]]></description>
      <guid>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</guid>
      <pubDate>Tue, 19 Mar 2024 01:42:01 GMT</pubDate>
    </item>
    </channel>
</rss>