<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 08 Aug 2024 12:29:25 GMT</lastBuildDate>
    <item>
      <title>我正在训练一个 VAE，但在我的批次中，我的 KLD 术语在执行几个步骤后就消失了</title>
      <link>https://stackoverflow.com/questions/78848344/im-training-a-vae-and-my-kld-term-is-vanishing-after-just-a-couple-steps-inside</link>
      <description><![CDATA[这是我的 VAE 损失代码：
def loss_function(x, x_hat, mean, logvar, beta=1.0):
    criterion = nn.MSELoss(reduction=&quot;mean&quot;)
    rebuilding_loss = criterion(x_hat, x)

    KLD = - 0.5 * torch.mean(1+ logvar - mean.pow(2) - logvar.exp())
    print(f&quot;KLD = {KLD}&quot;)
    return rebuilding_loss + KLD*beta

这是我的 VAE（简化版）：
class VariationalAutoEncoder(nn.Module):
def __init__(self, latent_shape):
super(VariationalAutoEncoder, self).__init__()

self.encoder = nn.Sequential(

nn.Linear(18,5184), # new
nn.LeakyReLU(0.2),
nn.Linear(5184,128), # new

)

# 潜在均值和方差对数 

self.mean_layer = nn.Linear(128, latent_shape)
self.logvar_layer = nn.Linear(128,latent_shape)

# 解码器
self.decoder = nn.Sequential(
nn.Linear(latent_shape,128),

nn.LeakyReLU(0.2),
nn.Linear(128,5184),

nn.LeakyReLU(0.2),
nn.Linear(5184,18), # new
nn.Sigmoid(),

)
def encode(self, x):
x = self.encoder(x)
mean, logvar = self.mean_layer(x), self.logvar_layer(x)
return mean, logvar

def reparameterization(self, mean, logvar):
std = torch.exp(0.5 * logvar)
epsilon = torch.randn_like(std).to(device) 
z = mean + std*epsilon
return z

def decrypt(self, z):
return self.decoder(z)

def forward(self, x):
mean, logvar = self.encode(x)
z = self.reparameterization(mean, logvar)

x_hat = self.decode(z)
return x_hat, mean, logvar


在我使用 10^16 的 beta 值后，KLD 的值会达到 10^-7 的数量级。我不确定为什么会这样。我该怎么办？
我目前的超参数是：Adm Optimizer 的权重衰减为 10，lr 为 0.01，ReduceLROnPlateau 调度程序的耐心为 3，因子为 0.5。我在代码中使用梯度裁剪，max_norm 为 0.5，训练 25 个时期。
潜在形状也是 10。
感谢您的帮助！
我尝试使用较小的值进行 beta 退火和循环退火，甚至使用 10^16 作为 beta 值的 beta KLD，但 KLD 项仍然消失为 10^-8。这就像它在我的任务上随机运行一样。我尝试添加一个卷积层，因为输入是一张大小约为 18 x 18 的图像。没有变化。]]></description>
      <guid>https://stackoverflow.com/questions/78848344/im-training-a-vae-and-my-kld-term-is-vanishing-after-just-a-couple-steps-inside</guid>
      <pubDate>Thu, 08 Aug 2024 12:10:40 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface 自动训练失败</title>
      <link>https://stackoverflow.com/questions/78848134/huggingface-autotrain-fail</link>
      <description><![CDATA[我正在尝试 Huggingface Autotrain。我的数据集：

以下是我的配置：

当我开始训练时，我收到此错误：

我做错了什么？我必须提到分类列和数字列吗？如果是，它们是用逗号分隔的吗？我如何决定哪些列放在哪里？]]></description>
      <guid>https://stackoverflow.com/questions/78848134/huggingface-autotrain-fail</guid>
      <pubDate>Thu, 08 Aug 2024 11:26:32 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 改进 Telegram 机器人中的关键字识别和提取</title>
      <link>https://stackoverflow.com/questions/78847420/improving-keyword-recognition-and-extraction-in-a-telegram-bot-using-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78847420/improving-keyword-recognition-and-extraction-in-a-telegram-bot-using-python</guid>
      <pubDate>Thu, 08 Aug 2024 08:52:23 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量</title>
      <link>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</link>
      <description><![CDATA[我无法加载我的模型，它一直显示错误
ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量。收到的输入：[&lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2896&gt;, &lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2897&gt;]
这是我的代码
image_generator = ImageDataGenerator(
rescale=1./255,
rotation_range=20,
zoom_range=0.2,
width_shift_range=0.2,
height_shift_range=0.2,
Horizo​​ntal_flip=True,
validation_split=0.2
)

train_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;training&#39;
)

validation_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;validation&#39;
)

# 加载数据集中子文件夹中的 (num_classes) 类
num_classes = len(train_dataset.class_indices)

from tensorflow.keras.applications.mobilenet import MobileNet

# 加载 MobileNet 模型
pre_trained_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),
include_top=False,
weights=&#39;imagenet&#39;)

pre_trained_model.summary()

# 打印数据集信息以供调试
print(f&quot;训练数据集形状：{train_dataset.image_shape}&quot;)
print(f&quot;验证数据集形状：{validation_dataset.image_shape}&quot;)

pre_trained_model.trainable = False

# 为预训练模型添加自定义层
model = tf.keras.Sequential([
pre_trained_model,
tf.keras.layers.GlobalAveragePooling2D(),
tf.keras.layers.Dense(1024,activation=&#39;relu&#39;),
tf.keras.layers.Dropout(0.5),
tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;) 
])

# 编译模型
#from tensorflow.keras.optimizers import RMSprop
model.compile(optimizer=Adam(learning_rate=0.0001),
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

# batch=40
# history = model.fit(train_dataset,
# validation_data=validation_dataset,
# epochs=20,
# steps_per_epoch = train_dataset.samples//batch,
# validation_steps = validation_dataset.samples//batch,
# verbose = 1
# )

epochs = 20
batch_size = 32

for epoch in range(epochs):
print(f&quot;Epoch {epoch + 1}/{epochs}&quot;)

# 训练 
# 使用 model.fit 进行训练，而不是手动迭代
history = model.fit(
train_dataset,
epochs=1, # 在外循环中一次训练一个 epoch
validation_data=validation_dataset,
steps_per_epoch=train_dataset.samples // batch_size,
validation_steps=validation_dataset.samples // batch_size,
verbose=1
)

# 验证 - 此部分可以保持不变
val_loss, val_accuracy = model.evaluate(validation_dataset)
print(f&quot;验证 - 损失：{val_loss:.4f}, 准确率： {val_accuracy:.4f}&quot;)

print(&quot;训练完成。&quot;)from keras.models import load_model
model_save_path = &#39;/content/drive/MyDrive/Machine Learning/saved_models/model_plastik.h5&#39;
model.save(model_save_path,save_format=&#39;keras&#39;)

model.summary()
print(f&#39;Model disimpan di: {model_save_path}&#39;)

# 加载模型
model_save_path = &#39;/content/drive/MyDrive/Machine Learning/saved_models/model_plastik.h5&#39;

# 加载模型，确保在需要时对其进行编译
loaded_model = tf.keras.models.load_model(model_save_path) 

# 现在您可以根据需要修改已加载的模型
# 例如，如果您想要提取子模型：
input_layer_index = 0 # 用实际索引替换
dense_2_index = 3 # 用实际索引替换
loaded_model = tf.keras.models.Model(inputs=loaded_model.layers[input_layer_index].input, 
outputs=loaded_model.layers[dense_2_index].output)

# 检查已加载模型的配置
for i, layer in enumerate(loaded_model.layers):
print(f&quot;Layer {i}: {layer.name} - 输入形状：{layer.input_shape} - 输出形状：{layer.output_shape}&quot;)

print(&quot;修订后的模型已成功加载。&quot;)

我尝试加载模型，并希望它已加载以进行测试]]></description>
      <guid>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</guid>
      <pubDate>Thu, 08 Aug 2024 07:06:54 GMT</pubDate>
    </item>
    <item>
      <title>无法在 AWS 或 Vercel 上部署 ML 项目</title>
      <link>https://stackoverflow.com/questions/78846779/unable-to-deploy-ml-project-on-aws-or-vercel</link>
      <description><![CDATA[我创建了一个简单的 ML 项目，根据性别、体重和身高预测一个人的 BMI，这是 GitHub 代码存储库的链接
https://github.com/sid111nov/BMIProject
我可以在本地机器上运行它，但无法将其部署到 AWS Bean Stack 或 Vercel。然后我认为我的项目可能存在一些问题，但构建似乎没问题。非常感谢任何解决此问题的意见，提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78846779/unable-to-deploy-ml-project-on-aws-or-vercel</guid>
      <pubDate>Thu, 08 Aug 2024 06:23:07 GMT</pubDate>
    </item>
    <item>
      <title>我正在编写决策树修剪算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78846680/i-am-writing-a-decision-tree-pruning-algorithm</link>
      <description><![CDATA[我正在尝试修剪决策树，这是我的代码，它没有按照我的预期工作，这里到底出了什么问题，
我试图实现的是，我试图根据 2 个标准（纯度阈值和人口阈值）修剪树，下面的算法没有给我我想要的结果，我这里缺少什么条件或检查，如何使其更强大？
# 使用前序遍历和标准修剪树的函数
def prune_preorder(inner_tree, index, purity_threshold=95,population_threshold=5):
# 处理当前节点
node_samples = inner_tree.n_node_samples[index]
# 修复修剪节点的特征确定逻辑
feature = feature_names[inner_tree.feature[index]] if inner_tree.feature[index] != -1 else &quot;Leaf节点”
阈值 = f” &lt;= {inner_tree.threshold[index]:.2f}”如果 inner_tree.feature[index] != -1 否则””
值 = inner_tree.value[index][0]
多数类别计数 = max(值)
纯度 = (多数类别计数 / 总和(值)) * 100 如果节点样本 &gt; 0 否则 0
人口百分比 = (节点样本 / 总样本) * 100 如果节点样本 &gt; 0 else 0

# 在修剪决策之前打印节点统计信息
print(f&quot;Node {feature} {index} : Samples={node_samples}, Purity={purity:.2f}%, Population={population_pct:.2f}%&quot;)

# 检查是否应修剪节点
if purity &gt;= purity_threshold orpopulation_pct &lt;人口阈值：
print(f&quot;修剪节点 {feature} {index} {threshold} (纯度： {purity:.2f}%, 人口： {population_pct:.2f}%)&quot;)
# 通过将子指针设置为 -1 将节点标记为叶子
inner_tree.children_left[index] = -1
inner_tree.children_right[index] = -1
else:
# 如果存在左子树，则遍历左子树
if inner_tree.children_left[index] != -1:
prune_preorder(inner_tree, inner_tree.children_left[index], purity_threshold, 人口阈值)

# 如果存在右子树，则遍历右子树
if inner_tree.children_right[index] != -1:
prune_preorder(inner_tree, inner_tree.children_right[index], purity_threshold,人口阈值)

# 使用前序遍历从根节点应用修剪
prune_preorder(clf.tree_, 0, purity_threshold=95,population_threshold=5)

# 为修剪后的树创建节点标签
node_labels_pruned = custom_node_labels(clf, feature_names, xmtrain, ymtrain)

理想情况下，树在满足修剪标准的任何地方都不应有子节点，但我看到一些标记为叶子的节点没有样本，还有更多子节点，理想情况下不应该这样。]]></description>
      <guid>https://stackoverflow.com/questions/78846680/i-am-writing-a-decision-tree-pruning-algorithm</guid>
      <pubDate>Thu, 08 Aug 2024 05:47:13 GMT</pubDate>
    </item>
    <item>
      <title>未找到与 torch==1.9.1 匹配的分布</title>
      <link>https://stackoverflow.com/questions/78846461/no-matching-distribution-found-for-torch-1-9-1</link>
      <description><![CDATA[我尝试使用 google colab 安装 torchmeta，但它依赖于 torch&lt;1.10.0 and &gt;=1.4.0，每当我尝试安装 torch 1.9.0 或任何版本的 torch&lt;1.10.0 and &gt;=1.4.0 时，都会出现以下错误：

错误：找不到满足要求 torch==1.9.1 的版本（来自版本：1.11.0、1.12.0、1.12.1、1.13.0、1.13.1、2.0.0、2.0.1、2.1.0、2.1.1、2.1.2、2.2.0、2.2.1， 2.2.2、2.3.0、2.3.1、2.4.0)错误：未找到与 torch==1.9.1 匹配的发行版

如何解决此问题？
我正在使用 Google colab，Python 版本 3.10.12。
如果我遇到的问题无法解决，请告诉我使用 colab 安装 torchmeta 的其他方法。
我正在尝试安装 torch&lt;1.10.0 和 &gt;1.4.0，然后安装依赖于我提到的 torch 版本 torch&lt;1.10.0 和 &gt;1.4.0 的 torchmeta。]]></description>
      <guid>https://stackoverflow.com/questions/78846461/no-matching-distribution-found-for-torch-1-9-1</guid>
      <pubDate>Thu, 08 Aug 2024 03:54:54 GMT</pubDate>
    </item>
    <item>
      <title>人工智能技术用于查找两个时间序列之间的相关性/模式/共同趋势[关闭]</title>
      <link>https://stackoverflow.com/questions/78846294/ai-techniques-to-find-correlation-pattern-common-trend-between-two-time-series</link>
      <description><![CDATA[我有一个想法，使用人工智能技术在两个连续的时间序列数据之间找到有用的信息。结果可以是相关值、共同模式或趋势等，输出结果如 TS1（时间序列 1）数据与 TS2 数据相关，反之亦然。
稍后我想特别指出这种关系究竟发生在哪里，以及它是什么类型的效果。

例如：
输入：过去 5 年的 TS1 和 TS2 数据。[浮点/双精度值]
过程：寻找相关性/模式/共同趋势。[这是我寻求指导的部分。]
输出：TS1 的变化每个月都会对 TS2 产生负面影响。 [输出文本可以由

过程部分的结果组成。]

加载数据、将其传递给模型/系统，并为非技术人员解释结果并不是一项艰巨的任务。对我来说，有趣的部分是如何找到某种关系。
到目前为止，我已经使用了 Person、Spearman 和 Kendall 相关性，并且根据我的要求，它工作得很好。但是，我想了解和使用多种技术，尤其是高级统计和机器学习模型。
由于我是时间序列数据的新手，我对选择正确的路径来实现上述目标的知识有限。所以，有人可以指导我哪些高级技术/模型（静态、机器学习等）适合找到两个连续时间序列数据之间的关系？
提前谢谢您。
祝您有美好的一天！ :)]]></description>
      <guid>https://stackoverflow.com/questions/78846294/ai-techniques-to-find-correlation-pattern-common-trend-between-two-time-series</guid>
      <pubDate>Thu, 08 Aug 2024 02:13:43 GMT</pubDate>
    </item>
    <item>
      <title>face_recognition 模块以某种方式严重干扰了 Speech_recognition 模块（python）</title>
      <link>https://stackoverflow.com/questions/78845929/face-recognition-module-somehow-badly-interfering-with-speech-recognition-module</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78845929/face-recognition-module-somehow-badly-interfering-with-speech-recognition-module</guid>
      <pubDate>Wed, 07 Aug 2024 22:40:22 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Sarimax 预测日期？</title>
      <link>https://stackoverflow.com/questions/78845748/how-to-project-forecast-dates-with-sarimax</link>
      <description><![CDATA[我正在使用 Sarimax 进行预测：
# 仅使用 VENDA 过滤数据集
df_int_aux = pd.DataFrame(df_internal[&#39;VENDA&#39;])

# 使用训练数据创建模型
train = round(len(df_int_aux) * 0.85) 
test = len(df_int_aux) - train

model_val = sm.tsa.statespace.SARIMAX(df_int_aux[&quot;VENDA&quot;][:train], order=(0,0,1), seasonal_order=(1, 1, 1, 4), exog=df_internal[&#39;C_EF_VENDA&#39;][:train])

# 拟合模型
model_val_fit = model_val.fit()

# 预测测试数据
validation = model_val_fit.get_forecast(steps=test, exog=df_internal[&#39;C_EF_VENDA&#39;][-test:]) 
validation_mean = validation.predicted_mean

但是，validation_mean 数据集未显示未来日期。它显示的数字索引范围从 101 到 118。数据集有 109 行。我使用前 100 行进行训练，因此第 101 行到第 118 行是模型的预测值。
为什么没有显示预计日期？我该如何解决这个问题？
以下是数据集的示例。可能是因为日期没有遵循特定的频率或模式，所以没有显示日期？
DATE VENDA C_EF_VENDA
2022-01-01 6.004414 12.122044
2022-01-11 10.933905 22.073975
2022-01-18 11.589626 23.397781
2022-01-25 21.005069 42.406200
2022-02-01 8.639416 14.461015
2022-02-08 16.847755 28.200475
2022-02-15 17.289413 28.939740
2022-02-22 16.966222 28.398770
]]></description>
      <guid>https://stackoverflow.com/questions/78845748/how-to-project-forecast-dates-with-sarimax</guid>
      <pubDate>Wed, 07 Aug 2024 21:30:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在 TensorFlow Pipeline 中对大型数据集应用图像增强？</title>
      <link>https://stackoverflow.com/questions/78816835/how-to-apply-image-augmentations-in-tensorflow-pipeline-for-large-dataset</link>
      <description><![CDATA[我有一个图像数据集，每个图像包含一个 1 到 5 个字母的单词。我想使用深度学习对每个图像中组成单词的字符进行分类。这些图像的标签格式如下：
totalcharacter_indexoffirstchar_indexofsecondchar_.._indexoflastchar
我正尝试将这些图像加载到 TensorFlow 管道中，以降低由于内存限制而导致的复杂性。下面是我从目录加载和处理图像和标签的代码：
def process_img(file_path):
label = get_label(file_path)
image = tf.io.read_file(file_path)
image = tf.image.decode_png(image, channels=1) 
image = tf.image.convert_image_dtype(image, tf.float32) 
target_shape = [695, 1204]
image = tf.image.resize_with_crop_or_pad(image, target_shape[0], target_shape[1])

# 对标签进行编码
coded_label = tf.py_function(func=encode_label, inp=[label], Tout=tf.float32)
coded_label.set_shape([5, len(urdu_alphabets)])

return image,coded_label
input_dir = &#39;/kaggle/input/dataset/Data/*&#39;
images_ds = tf.data.Dataset.list_files(input_dir, shuffle=True)

train_count = int(tf.math.round(len(images_ds) * 0.8))
train_ds = images_ds.take(train_count)
test_ds = images_ds.skip(train_count)
train_ds = train_ds.map(process_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.map(process_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.batch(32)
train_ds = train_ds.cache()
test_ds = test_ds.cache()
train_ds = train_ds.shuffle(len(train_ds))
test_ds = test_ds.prefetch(tf.data.AUTOTUNE)
print(train_ds)
print(test_ds)

train_ds 如下所示：
&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(None, 695, 1204, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5, 39), dtype=tf.float32, name=None))&gt;
现在，我想对图像应用简单的增强，例如旋转、剪切、侵蚀和扩张。我最初使用了以下函数：
def augment(image, label):
image = tf.image.random_flip_left_right(image)
image = tf.image.random_flip_up_down(image)
image = tf.keras.preprocessing.image.random_rotation(image, rg=15, row_axis=0, col_axis=1, channel_axis=2, fill_mode=&#39;nearest&#39;, cval=0.0, interpolation_order=1)
image = tf.image.random_zoom(image, [0.85, 0.85])
image = tf.image.random_shear(image, 0.3)
image = tf.image.random_shift(image, 0.1, 0.1)
return image, label

train_augmented_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)
train_augmented_ds = train_augmented_ds.prefetch(buffer_size=tf.data.AUTOTUNE)

但是，tf.image 中的许多函数都已弃用。如何以高效的方式在 TensorFlow 管道中将这些增强应用于图像？
注意：我可以通过不使用 TensorFlow 管道使用 NumPy 数组加载图像来执行这些增强，但我的数据集非常大（110 万张图像），因此我需要一种高效的方法来执行此操作。]]></description>
      <guid>https://stackoverflow.com/questions/78816835/how-to-apply-image-augmentations-in-tensorflow-pipeline-for-large-dataset</guid>
      <pubDate>Wed, 31 Jul 2024 14:11:01 GMT</pubDate>
    </item>
    <item>
      <title>Python Darts 中的 RNN 训练指标</title>
      <link>https://stackoverflow.com/questions/78144820/rnn-training-metrics-in-python-darts</link>
      <description><![CDATA[我目前正在使用 python darts 训练 RNNModel。为了比较不同的训练模型，我想从 fit 方法中提取 train_loss 和 val_loss。我该怎么做？我读过一些关于度量集合的内容，但不知道如何使用它。
这是我当前的代码
from darts.models import RNNModel
from darts import TimeSeries

train = # training data as TimeSeries
model = RNNModel(model=&quot;LSTM&quot;, input_chunk_length=self.past_samples)
model.fit(train)

训练期间，控制台中会显示损失，但我不知道如何访问它。
到目前为止，我尝试在网上查找任何文档，并向 bing chat 和 ChatGPT 寻求帮助。但是他们告诉我使用不存在的 model.history.history[&quot;loss&quot;]]]></description>
      <guid>https://stackoverflow.com/questions/78144820/rnn-training-metrics-in-python-darts</guid>
      <pubDate>Tue, 12 Mar 2024 05:29:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 SKforecast 时出错：[Int64Index([48, ...],\n dtype='int64', name='date_time')] 均不在 [index] 中</title>
      <link>https://stackoverflow.com/questions/77013878/error-when-using-skforecast-none-of-int64index48-n-dtype-int64-na</link>
      <description><![CDATA[我有使用 groupby（基于日期和组）的数据集，结果如下 Dataframe:
| 日期 | 组 | 值 |
|:---- |:------:| -----:|
| 2022-01-01 | 12 | 25.2|
| 2022-01-01 | 15 | 36.54|
| 2022-02-01 | 12 | 55.3|
| 2022-02-01 | 15 | 69.2|

最后我有 177 行。
我的第一个问题是我无法应用 data.asfreq
data = data.asfreq(&#39;MS&#39;) 

我收到此错误：
ValueError：无法在具有重复标签的轴上重新索引

我的第二个问题是当我想应用 xgboost 时我使用了此代码：
data = data.set_index(&#39;date_time&#39;)
#data = data.asfreq(&#39;MS&#39;)
data = data.sort_index()

end_train = &#39;2023-05-01&#39;
end_validation = &#39;2023-06-01&#39;
data_train = data.loc[: end_train, :]
data_val = data.loc[end_train:end_validation, :]
data_test = data.loc[end_train:, :]

print(f&quot;日期训练：{data_train.index.min()} --- {data_train.index.max()} (n={len(data_train)})&quot;)
print(f&quot;日期验证：{data_val.index.min()} --- {data_val.index.max()} (n={len(data_val)})&quot;)
print(f&quot;日期测试：{data_test.index.min()} --- {data_test.index.max()} (n={len(data_test)})&quot;)

forecaster = ForecasterAutoreg(
regressor = XGBRegressor(random_state=123),
lags = 24
)

# 回归器超参数
param_grid = {
&#39;n_estimators&#39;: [100, 500],
&#39;max_depth&#39;: [3, 5, 10],
&#39;learning_rate&#39;: [0.01, 0.1]
}

# 用作预测器的滞后值
lags_grid = [48, 72]

results_grid = grid_search_forecaster(
Forecaster = Forecaster,
y = data.loc[:end_validation, &#39;value&#39;], # 训练和验证数据
param_grid = param_grid,
lags_grid = lags_grid,
steps = 36,
refit = False,
metric = &#39;mean_squared_error&#39;,
initial_train_size = len(data_train),
fixed_train_size = False,
return_best = True,
n_jobs = &#39;auto&#39;,
verbose = False
)

我收到此错误：
KeyError: &quot;None of [Int64Index([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n 82, 83, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61、62、\n 63、64、65、66、67、68、69、70、71、72、73、74、75、76]、\n dtype=&#39;int64&#39;, name=&#39;date_time&#39;)] 在 [index]&quot;

我尝试更改 lags_grid，但出现了几乎相同的错误。
在此先感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77013878/error-when-using-skforecast-none-of-int64index48-n-dtype-int64-na</guid>
      <pubDate>Thu, 31 Aug 2023 07:59:30 GMT</pubDate>
    </item>
    <item>
      <title>无法在 python 中安装 lap==0.4.0 库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark 中的过采样或 SMOTE</title>
      <link>https://stackoverflow.com/questions/53936850/oversampling-or-smote-in-pyspark</link>
      <description><![CDATA[我有 7 个类，总记录数为 115，我想对这些数据运行随机森林模型。但由于数据不足以获得高精度。所以我想对所有类进行过采样，使多数类本身获得更高的计数，然后少数类获得更高的计数。这在 PySpark 中可行吗？
+---------+-----+
| SubTribe|count|
+---------+-----+
| Chill| 10|
| Cool| 18|
|Adventure| 18|
| Quirk| 13|
| Mystery| 25|
| Party| 18|
|Glamorous| 13|
+---------+-----+
]]></description>
      <guid>https://stackoverflow.com/questions/53936850/oversampling-or-smote-in-pyspark</guid>
      <pubDate>Wed, 26 Dec 2018 20:31:36 GMT</pubDate>
    </item>
    </channel>
</rss>