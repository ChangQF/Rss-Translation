<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 12 Jul 2024 12:29:14 GMT</lastBuildDate>
    <item>
      <title>关于使用lstm模型的时间序列数据预测模型数据集</title>
      <link>https://stackoverflow.com/questions/78739703/about-time-series-data-prediction-model-dataset-using-lstm-model</link>
      <description><![CDATA[我有 1400 个地点的年平均交通量数据，并且有 2008 年至 2022 年的数据。目前，为了进行时间序列分析并创建预测模型，我们计划通过将 2008 年至 2019 年设置为训练数据、2020 年至 2021 年设置为验证数据、2022 年设置为测试数据来运行分析。我想使用 lstm 模型继续此方法，从时间序列分析中学习。我不确定如何正确设置和继续验证和测试数据比率。
目前，我们正尝试使用 2008 年的 2020 年数据作为训练数据，使用 2021 年数据作为验证数据，但数据数量不正确的错误仍然出现。]]></description>
      <guid>https://stackoverflow.com/questions/78739703/about-time-series-data-prediction-model-dataset-using-lstm-model</guid>
      <pubDate>Fri, 12 Jul 2024 09:51:37 GMT</pubDate>
    </item>
    <item>
      <title>如何并行化yolov5的Darknet53的卷积层（在一台电脑上）？[关闭]</title>
      <link>https://stackoverflow.com/questions/78739028/how-to-parallelize-the-convolutional-layers-of-darknet53-of-yolov5-on-one-pc</link>
      <description><![CDATA[最近想把YOLOv5的主干算法拆分出来部署到多块FPGA上，但是首先需要在一台电脑上把Darknet53卷积层划分成2个或多个区域进行并行卷积操作。YOLOv5项目要研究什么？需要修改哪些文件？一堆YAML和common.py好混乱啊（YOLOVv5是最新版本）。
我已经在PC上部署了YOLOv5，也做了一些前期研究，大部分的重点应该在models文件夹，models文件夹里面有5个YAML网络配置文件，yolo.py，common.py等，现在想搞清楚研究的顺序，以及学习这些文件的方法，才能在单台电脑上把Darknet53卷积层划分成2个或多个区域进行并行卷积操作。]]></description>
      <guid>https://stackoverflow.com/questions/78739028/how-to-parallelize-the-convolutional-layers-of-darknet53-of-yolov5-on-one-pc</guid>
      <pubDate>Fri, 12 Jul 2024 07:10:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使adapter_conditioning_scale在多个T2I_Adapter中可训练？</title>
      <link>https://stackoverflow.com/questions/78738957/how-to-make-adapter-conditioning-scale-trainable-in-multiple-t2i-adapter</link>
      <description><![CDATA[下面是使用 Multi T2I_Adapter 的代码。如以下代码所示，adapter_conditioning_scale=[0.8, 0.8]，是手动设置的。
 adapters = MultiAdapter(
[
T2IAdapter.from_pretrained(&quot;TencentARC/t2iadapter_keypose_sd14v1&quot;),
T2IAdapter.from_pretrained(&quot;TencentARC/t2iadapter_depth_sd14v1&quot;),
]
)
adapters = adapters.to(torch.float16)

pipe = StableDiffusionAdapterPipeline.from_pretrained(
&quot;CompVis/stable-diffusion-v1-4&quot;,
torch_dtype=torch.float16,
adapter=adapters,
).to(&quot;cuda&quot;)

image = pipe(prompt, cond, adapter_conditioning_scale=[0.8, 0.8]).images[0]
make_image_grid([cond_keypose, cond_depth, image], rows=1, cols=3)

Google 的 Colab
我的问题：
我们可以使用什么机器学习技术来找到 adapter_conditioning_scale 的最佳值？
参考文献：
huggingface.co
T2IAdapter 代码]]></description>
      <guid>https://stackoverflow.com/questions/78738957/how-to-make-adapter-conditioning-scale-trainable-in-multiple-t2i-adapter</guid>
      <pubDate>Fri, 12 Jul 2024 06:45:55 GMT</pubDate>
    </item>
    <item>
      <title>查明代码文件中的错误来源[关闭]</title>
      <link>https://stackoverflow.com/questions/78738937/pinpointing-the-source-of-error-in-a-code-file</link>
      <description><![CDATA[我正在尝试实现一个小工具，它可以自动识别一组代码文件（作为输入）中的哪一部分代码导致了执行期间显示的错误文本。
错误可能是语法错误，也可能是逻辑错误。我还在考虑利用 llms 的 api 调用来更正代码。
据我所知，RAG 是必要的，因为我不可能将所有代码文件的数据都放入提示中，因为它肯定会超出上下文窗口的大小。这就是我尝试探索信息检索技术的原因。我知道一些 RAG 技术，比如 RAG-fusion，但我想得到一些反馈和想法，关于我可以探索哪些其他方法/工具/模型。
可能存在我没有意识到的代码调试问题的某些方面。任何帮助都非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78738937/pinpointing-the-source-of-error-in-a-code-file</guid>
      <pubDate>Fri, 12 Jul 2024 06:41:48 GMT</pubDate>
    </item>
    <item>
      <title>当数据框共享一列时，pd.concat()</title>
      <link>https://stackoverflow.com/questions/78738692/pd-concat-when-dataframes-share-a-column</link>
      <description><![CDATA[我试图连接两个共享一列的数据框。一个数据框包含所有列，但第二个数据框只有单个更改的列。我想连接它们，以便旧值被新值覆盖。我尝试了所有能想到的方法来做到这一点，但没有取得任何进展。以下是我想要发生的事情：
A B
0 1 2
1 2 3

连接：
A
0 3
1 4

成为：
A B
0 3 2
1 4 3

pd.concat(frames, axis=1) 让我得到了最接近的结果。两行乱七八糟，但它们应该合并在一起。不正确的行显示如下：
 A B
0 1 NaN
1 NaN 1

应将行组合在一起才能获得正确的输出。]]></description>
      <guid>https://stackoverflow.com/questions/78738692/pd-concat-when-dataframes-share-a-column</guid>
      <pubDate>Fri, 12 Jul 2024 05:16:59 GMT</pubDate>
    </item>
    <item>
      <title>MLP 回归器工程数据 SKLearn</title>
      <link>https://stackoverflow.com/questions/78738380/mlp-regressor-engineering-data-sklearn</link>
      <description><![CDATA[我的飞机分析模型上分布有 10 个加速度计。从我的分析模型中，我有一组传感器加速度，包括 10 个加速度计 X 6 个自由度 X 6000（60 秒）数据，即 60 x 6000 阵列和 49 X 6000 阵列中飞机上 49 个位置的应力。我使用不同频率的不同时间历史力生成了一组 100 个 60 X 6000 传感器数据和相应的 21 X 6000 传感器数据。我正在尝试使用 MLPRegressor 构建一个 ML 模型，使用交叉验证/提前停止，这样如果我给模型一个 60 x 6000 传感器数据，我就可以预测相应的应力矩阵。由于我想计算应力时间历史的循环次数，因此必须很好地预测带有噪声的应力预测。
我在识别模型的超参数时遇到了麻烦。我大概应该使用多少层？如果我得到的预测不能很好地预测循环计数，是否意味着无法为这种工程数据构建回归模型？
当达到 0.73 交叉验证分数时，我尝试过的大多数参数都无法收敛。此外，scikit learn MLP Regressor 不支持 GPU 使用，运行时间很长。]]></description>
      <guid>https://stackoverflow.com/questions/78738380/mlp-regressor-engineering-data-sklearn</guid>
      <pubDate>Fri, 12 Jul 2024 02:52:04 GMT</pubDate>
    </item>
    <item>
      <title>解决具有不同数据类型分类特征的 Keras 函数模型的类型转换错误</title>
      <link>https://stackoverflow.com/questions/78738365/resolving-type-conversion-error-for-keras-functional-model-with-categorical-feat</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78738365/resolving-type-conversion-error-for-keras-functional-model-with-categorical-feat</guid>
      <pubDate>Fri, 12 Jul 2024 02:44:28 GMT</pubDate>
    </item>
    <item>
      <title>pytorch：ninja：构建已停止：子命令失败</title>
      <link>https://stackoverflow.com/questions/78738275/pytorch-ninja-build-stopped-subcommand-failed</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78738275/pytorch-ninja-build-stopped-subcommand-failed</guid>
      <pubDate>Fri, 12 Jul 2024 01:57:54 GMT</pubDate>
    </item>
    <item>
      <title>在交互式笔记本中加载 Azure ML Studio 中已注册的模型</title>
      <link>https://stackoverflow.com/questions/78736775/load-a-registered-model-in-azure-ml-studio-in-an-interactive-notebook</link>
      <description><![CDATA[我正在使用 Azure 机器学习工作室，我的默认数据存储（blob 存储）中存储了一个 sklearn mlflow 模型，然后我将其注册为模型资产。在将其部署为批处理端点之前，如何将此模型加载到交互式笔记本中以执行一些快速模型推理和测试。
我看到了一篇链接为此处的帖子，建议在本地下载模型工件，但我不需要这样做。我应该能够直接从数据存储或注册的资产加载模型，而无需在多个位置复制模型。我尝试了以下操作，但没有成功。
从已注册的模型资产读取
import mlflow
from azure.ai.ml import MLClient
from azure.ai.ml.entities import Model

ml_client = MLClient(DefaultAzureCredential(), &quot;&lt;subscription_id&gt;&quot;, &quot;&lt;resource_group&gt;&quot;, &quot;&lt;workspace_id&gt;&quot;)

model = ml_client.models.get(&quot;&lt;model_name&gt;&quot;, version=&quot;1&quot;)
loaded_model = mlflow.sklearn.load_model(model.id)

&gt;&gt;&gt; OSError：没有这样的文件或目录：...

从数据存储中读取
import mlflow

model_path = &quot;&lt;datastore_uri_to_model_folder&gt;&quot;
loaded_model = mlflow.sklearn.load_model(model_path)

&gt;&gt;&gt; DeserializationError：无法反序列化内容类型：text/html
]]></description>
      <guid>https://stackoverflow.com/questions/78736775/load-a-registered-model-in-azure-ml-studio-in-an-interactive-notebook</guid>
      <pubDate>Thu, 11 Jul 2024 16:45:51 GMT</pubDate>
    </item>
    <item>
      <title>如何针对简单的 ML 模型对来自 EE 的卫星数据进行标准化/预处理？</title>
      <link>https://stackoverflow.com/questions/78736772/how-do-i-standardize-preprocess-this-satellite-data-from-ee-for-simple-ml-models</link>
      <description><![CDATA[我对 Earth Engine/QGIS 还不太熟悉（没有 ArcGIS 许可证），我想使用一个简单的 ML 模型，利用卫星 VCD、NDVI 和气象数据估算地面 O3。
我对 GIS/地理空间数据处理的世界感到迷茫，所以我尽我所能，疯狂地谷歌搜索并阅读了一些文章，以解释我的理由。
我想使用的数据：
EE 数据集：

Daymet V4 每日气候变量（https://developers.google.com/earth-engine/datasets/catalog/NASA_ORNL_DAYMET_V4#bands)
MOD13A2 NDVI 产品 (https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD13A2)
Sentinel-5P (TROPOMI) O3 VCD 数据 (https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S5P_NRTI_L3_O3#bands)

标签：- 来自 EPA 的地面 O3 数据（https://epa.maps.arcgis.com/apps/webappviewer/index.html?id=5f239fd3e72f424f98ef3d5def547eb5&amp;extent=-146.2334,13.1913,-46.3896,56.5319），转到右上角的“选择图层”图标并选择 O3 活动/非活动，然后将鼠标悬停在任意点上

似乎这个 EPA 数据可以直接导出为 CSV，包括经度、纬度和臭氧测量值。

在这里，我假设我需要从不同来源提取的数据具有相同的空间/时间分辨率，以便使用一些简单的机器学习算法（RF/线性回归）。如果有其他方法，请告诉我！
在我设想的数据集中，每“行”数据将是给定像素在给定日期的气象变量值、NDVI 和 VCD 值，我可以对其执行基本的 RF/回归（使用 EE 或 Python）。在我看来，要使它发挥作用，所有数据集都需要就“像素”是什么达成一致，并成为/成为每日时间分辨率（Daymet 和 TROPOMI 已经是每日的，我假设我可以取最接近的 16 天 NDVI 值）。
基于这个假设，我想让所有数据都具有相同的空间分辨率，所以我正在尝试弄清楚如何“重新投影”将 TROPOMI 数据（当前分辨率为 1111.3km）转换为 1km 分辨率（据我所知，这是所有 Daymet 数据和 MODIS 数据的分辨率）。 *我不知道如何使来自 EPA 数据的“最近像素”（来自点数据而非栅格数据）匹配，以便将其用作数据标签，但这似乎是一个更常见的问题，因此在整理完其余部分后，我将四处寻找如何修复该问题。
因此，我想在这里完成的主要操作是标准化空间分辨率：将 TROPOMI 数据转换为 1km 像素或将 Daymet/MODIS 数据转换为 1.113km 像素。
我尝试在 Earth Engine 中可视化所有三个输入数据集（为 Daymet 选择最高温度），像素似乎根本没有对齐。我已在此处附上每个图层的屏幕截图：ndvi 像素、daymet 像素和 tropomi 像素
TROPOMI 数据似乎给出了某种奇怪的模糊像素，Daymet 数据是规则的方形像素但倾斜，而 NDVI 数据是平行四边形。我隐约觉得这与不同的“投影”/“CRS”有关设置，但我对这两者都不太了解，并且不确定如何继续我认为我需要做的重新缩放。
脚本链接：https://code.earthengine.google.com/6fafaccf040e206e97a32e795611d7e4]]></description>
      <guid>https://stackoverflow.com/questions/78736772/how-do-i-standardize-preprocess-this-satellite-data-from-ee-for-simple-ml-models</guid>
      <pubDate>Thu, 11 Jul 2024 16:43:51 GMT</pubDate>
    </item>
    <item>
      <title>检测图像中的算术运算符[关闭]</title>
      <link>https://stackoverflow.com/questions/78736359/detect-arithmetic-operators-in-an-image</link>
      <description><![CDATA[我使用 keras_ocr 创建了一个 OCR 脚本。输入是流程图（灰度图）。我想提取流程图图像的文本和形状坐标。但是，它不会提取诸如“+、-、*、/”之类的算术运算符。有时它也无法检测数值。这是我的完整脚本。
# 导入必要的库
import os
import matplotlib.pyplot as plt
import keras_ocr
import cv2
import numpy as np
from google.colab import drive
from symspellpy.symspellpy import SymSpell, Verbosity
import pkg_resources

class OCRProcessor:
def __init__(self):
# 创建用于 OCR 处理的管道
self.pipeline = keras_ocr.pipeline.Pipeline()

def __get_bbox(self, image_path):
try:
# 使用 OpenCV 读取图像
image = cv2.imread(image_path)
if image is None:
raise ValueError(f&quot;Image at path {image_path} could not be read.&quot;)

# 将图像转换为 RGB（keras-ocr 需要 RGB 图像）
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# 使用 OCR 管道检测文本
images = keras_ocr.tools.read(image_path)
self.image = images
prediction_groups = self.pipeline.recognize([images])

if not prediction_groups or not prediction_groups[0]:
return [], []

# 提取边界框和文本
texts = []
results = []
for text, box in prediction_groups[0]:
texts.append(text)
xs, ys = set(), set()
for x in box:
xs.add(x[0])
ys.add(x[1])
results.append(list(map(int, [min(xs), min(ys), max(xs), max(ys)]))) # ymin, xmin, ymax, xmax

return texts, results
except Exception as e:
print(f&quot;An error occurred in __get_bbox: {e}&quot;)
return [], []

def process_image(self, image_path):
return self.__get_bbox(image_path)

# 定义函数来更正文本
def correct_text(text_array):
# 初始化 SymSpell 对象
sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)

# 加载字典
dictionary_path = pkg_resources.resource_filename(
&quot;symspellpy&quot;, &quot;frequency_dictionary_en_82_765.txt&quot;)
sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)

corrected_text_array = []
for text in text_array:
suggestions = sym_spell.lookup(text, Verbosity.CLOSEST, max_edit_distance=2)
if suggestions:
corrected_text_array.append(suggestions[0].term)
else:
corrected_text_array.append(text)
return corrected_text_array

# 主函数
def main(image_path):
ocr_processor = OCRProcessor()
ex_text, ex_co = ocr_processor.process_image(image_path)
if not ex_text:
print(f&quot;在路径 {image_path} 处的图像中未检测到文本。&quot;)
return [], [], []

# 更正提取的文本
cr_text = correct_text(ex_text)

# 打印结果
print(&quot;提取的文本：&quot;, ex_text)
print(&quot;更正的文本：&quot;, cr_text)
print(&quot;Extracted Coordinates:&quot;, ex_co)

return ex_text, cr_text, ex_co

# 示例用法（您可以根据需要更新图像路径）
image_path = &#39;/content/Test2.jpg&#39;
ex_text, cr_text, ex_co = main(image_path)

ex_shape, ex_coor = detect_shapes(image_path)

# 打印或使用结果
print(&quot;Detected Shapes:&quot;, ex_shape)
print(&quot;Coordinates for Shapes:&quot;, ex_coor)

当我输入如下所示的流程图图像时，

它会生成一个文本和坐标，如下：
{{&#39;start&#39;,&#39;input&#39;,&#39;as&#39;,&#39;a&#39;,&#39;product&#39;,&#39;axe&#39;,&#39;a&#39;,&#39;print&#39;,&#39;product&#39;,&#39;end&#39;}}

问题是它无法检测到某些算术运算符。有没有什么解决方案可以解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/78736359/detect-arithmetic-operators-in-an-image</guid>
      <pubDate>Thu, 11 Jul 2024 15:09:46 GMT</pubDate>
    </item>
    <item>
      <title>在 Android Studio 中集成已训练的模型</title>
      <link>https://stackoverflow.com/questions/78730286/integration-of-a-trained-model-in-android-studio</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78730286/integration-of-a-trained-model-in-android-studio</guid>
      <pubDate>Wed, 10 Jul 2024 11:31:14 GMT</pubDate>
    </item>
    <item>
      <title>CNN 预测随机图像</title>
      <link>https://stackoverflow.com/questions/78723722/cnn-predicting-random-images</link>
      <description><![CDATA[我已经用 CNN 训练了模型。我已经用胸部 X 光片图像对模型进行了二元分类训练。即使在训练模型之后。模型正在预测汽车、动物等随机图像，并给出更高的置信度。
需要深度学习模型中随机图像预测的解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78723722/cnn-predicting-random-images</guid>
      <pubDate>Tue, 09 Jul 2024 04:49:05 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器中的梯度消失</title>
      <link>https://stackoverflow.com/questions/78700019/vanishing-gradient-in-autoecnoder</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78700019/vanishing-gradient-in-autoecnoder</guid>
      <pubDate>Wed, 03 Jul 2024 03:59:42 GMT</pubDate>
    </item>
    <item>
      <title>模块“keras.layers”没有属性“experimental”</title>
      <link>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</link>
      <description><![CDATA[你好，我试图调整数据集的大小和比例，如下所示，但遇到了此错误：
AttributeError：模块“keras.layers”没有属性“experimental”

resize_and_rescale= tf.keras.Sequential([
layers.experimental.preprocessing.Resizing(IMAGE_SIZE,IMAGE_SIZE),
layers.experimental.preprocessing.Rescaling(1.0/255)
])

]]></description>
      <guid>https://stackoverflow.com/questions/74792455/module-keras-layers-has-no-attribute-experimental</guid>
      <pubDate>Wed, 14 Dec 2022 00:43:49 GMT</pubDate>
    </item>
    </channel>
</rss>