<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 10 Jul 2024 09:16:11 GMT</lastBuildDate>
    <item>
      <title>在 R 中的 nestedcv 包中的 nestcv.train 对象上调用 summary() 和 train_summary() 有什么区别？</title>
      <link>https://stackoverflow.com/questions/78729334/what-is-the-difference-between-calling-summary-and-train-summary-on-a-nestcv</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78729334/what-is-the-difference-between-calling-summary-and-train-summary-on-a-nestcv</guid>
      <pubDate>Wed, 10 Jul 2024 08:11:17 GMT</pubDate>
    </item>
    <item>
      <title>从头开始实现循环神经网络</title>
      <link>https://stackoverflow.com/questions/78729202/recurrent-neural-network-implementation-from-scratch</link>
      <description><![CDATA[它给了我错误，我想是没有完全很好地实现吧？
我不知道我是否做对了所有事情，我需要帮助从头开始编写一个 RNN，用于我的机器人进行外国预测，它将使用价格来学习，我设定的目标是 [1,0] 用于学习买入，[0,1] 用于学习卖出，我还想包括强化学习，这将帮助它更好地学习，我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/78729202/recurrent-neural-network-implementation-from-scratch</guid>
      <pubDate>Wed, 10 Jul 2024 07:42:56 GMT</pubDate>
    </item>
    <item>
      <title>像 medium 或 daily dev 这样的网站如何选择您的兴趣并为您提供相关的信息，它们使用了哪些技术？[关闭]</title>
      <link>https://stackoverflow.com/questions/78729154/how-do-websites-like-medium-or-daily-dev-gets-to-select-your-interests-and-provi</link>
      <description><![CDATA[我想使用与 medium 和 daily dev 相同的功能，这些功能可让您选择您感兴趣的领域，然后为您提供相关博客作为您的订阅源。我不需要使用所有这些功能，但我想知道如何实现这样的功能。我希望能够了解用户的兴趣和知识/专业知识领域以及需求，然后根据这些信息为他们提供相关信息。我猜会涉及机器学习、人工智能等技术，如果我能设法了解创建此类功能所涉及的技术，这将对我大有帮助。
非常感谢任何能尽其所能帮助我的用户。干杯！！
我曾尝试使用 chatGPT 来了解它，但答案有点太模糊了。似乎直接联系相关行业的开发人员会更好、更高效]]></description>
      <guid>https://stackoverflow.com/questions/78729154/how-do-websites-like-medium-or-daily-dev-gets-to-select-your-interests-and-provi</guid>
      <pubDate>Wed, 10 Jul 2024 07:30:23 GMT</pubDate>
    </item>
    <item>
      <title>从示例数据集重新创建文本嵌入</title>
      <link>https://stackoverflow.com/questions/78728307/recreating-text-embeddings-from-an-example-dataset</link>
      <description><![CDATA[我现在的情况是，我有一个句子列表，以及一个 25 维向量上的理想嵌入列表。我试图使用神经网络来生成新的编码，但很挣扎。虽然模型运行良好，但其输出毫无意义，甚至无法准确复制训练数据！
import numpy as np
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# 标记化
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentence_list)
sequences = tokenizer.texts_to_sequences(sentence_list)

# 假设您的向量是 25 维
input_dim = 25

# 定义编码器
input_vec = Input(shape=(max_sequence_length,))
encoded = Dense(25,activation=&#39;tanh&#39;)(input_vec) # 缩减至 16 维的示例
encoder = Model(input_vec,coded)

# 定义解码器
decoded = Dense(input_dim,activation=&#39;sigmoid&#39;)(encoded)
autoencoder = Model(input_vec,coded)

# 编译模型
autoencoder.compile(optimizer=Adam(),loss=&#39;mse&#39;)

# 训练模型
autoencoder.fit(padded_sequences, combined_vectors_clean,
epochs=10,
batch_size=32,
shuffle=True,validation_split= 0.2)


据我所知，我的输入和标签没有任何问题，那么我遗漏了什么？非常感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78728307/recreating-text-embeddings-from-an-example-dataset</guid>
      <pubDate>Wed, 10 Jul 2024 01:39:37 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未在未知的 TensorShape 上定义 as_list()。图像和掩码形状看起来正确</title>
      <link>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</link>
      <description><![CDATA[我正尝试调整 Tensorflow 的示例 UNet 以达到我的目的。主要区别在于，此 UNet 采用 128x128 图像和掩码，而我的图像为 512x512，掩码为 100x100。
尝试运行 model.fit 时出现此错误：
ValueError：as_list() 未在未知的 TensorShape 上定义。

但是，我可以毫无问题地运行 model.predict，它会生成我期望的未经训练的模型的预测。
这是我用来制作和训练模型的代码：
base_model = tf.keras.applications.MobileNetV2(input_shape=[512, 512, 3], include_top=False)

# 使用这些层的激活
layer_names = [
&#39;block_1_expand_relu&#39;, # 64x64
&#39;block_3_expand_relu&#39;, # 32x32
&#39;block_6_expand_relu&#39;, # 16x16
&#39;block_13_expand_relu&#39;, # 8x8
&#39;block_16_project&#39;, # 4x4
]
base_model_outputs = [base_model.get_layer(name).output for name in layer_names]

# 创建特征提取模型
down_stack = tf.keras.Model(inputs=base_model.input, output=base_model_outputs)

down_stack.trainable = False

up_stack = [
pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8
pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16
pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32
pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
input = tf.keras.layers.Input(shape=[512, 512, 3])

# 通过模型进行下采样
skips = down_stack(inputs)
x = skips[-1]
skips = reversed(skips[:-1])

# 上采样并建立 skip 连接
for up, skip in zip(up_stack, skips):
x = up(x)
concat = tf.keras.layers.Concatenate()
x = concat([x, skip])

# 这是模型的最后一层
last = tf.keras.layers.Conv2DTranspose(
filters=output_channels, kernel_size=3, strides=2,
padding=&#39;same&#39;) #64x64 -&gt; 128x128

x = last(x)

return tf.keras.Model(inputs=inputs, output=x)

OUTPUT_CLASSES = 5

model = unet_model(output_channels=OUTPUT_CLASSES)
model.compile(optimizer=&#39;adam&#39;,
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
metrics=[&#39;accuracy&#39;])

model_history = model.fit(train_dataset, epochs=EPOCHS,
validation_data=test_dataset)

我尝试检查每个批次的图像形状和掩码形状。除了最后一个批次（只有一个图像）外，每个批次的图像形状为 (16, 512, 512, 3)，掩码形状为 (16, 100, 100, 1)。
我尝试将此代码放入我的 process_paths（教程中称之为）函数中：
image = tf.reshape(image, [512, 512, 3])

...
mask = tf.reshape(mask, [100, 100, 1])

我尝试对 up_stack 部分中的数字进行一些调整，但最终一无所获，因为我不理解那部分。我的假设是，既然我已经更改了输入大小，我必须更改模型层的输出大小，但我真的不知道该怎么做。另外，我很困惑，如果是这样的话，为什么我仍然可以运行 model.predict。
我的 tensorflow 版本是 2.16.1]]></description>
      <guid>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</guid>
      <pubDate>Tue, 09 Jul 2024 19:17:45 GMT</pubDate>
    </item>
    <item>
      <title>Flutter/Tensorflow 形状不匹配错误</title>
      <link>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</link>
      <description><![CDATA[我正在制作一个运行 tensorflow Lite 模型的 Flutter 应用。我收到以下错误：
无法从形状为 [1, 2] 的 TensorFlowLite 张量 (Identity) 复制到形状为 [1, 215] 的 Java 对象。
背景故事：我训练过的算法使用 215 列并输出 1 或 0。下面是使用 netron.app 的屏幕截图：Netron 图
我不明白为什么这个东西想要将形状 [1,2]（输出）复制到输入 Java 类中。这个代码太高级了，我无法正确调试它。我找不到 Flutter 的 Tensorflow Lite 文档，它只描述了破坏代码的函数的输入参数。下面是出现故障的函数，错误出现在 runModelOnBinary() 函数中。有任何一般指导/帮助/经验吗？
void assessModel() async {
try {

// 生成具有 215 列的随机输入数据，以匹配预期的 860 字节输入大小
List&lt;double&gt; inputData = List.generate(215, (index) =&gt; Random().nextInt(2).toDouble());

// 将 List&lt;double&gt; 转换为 Float32List
Float32List inputBytes = Float32List.fromList(inputData);

// 将 Float32List 转换为 Uint8List
Uint8List inputUint8List = inputBytes.buffer.asUint8List();
print(inputData);
// 在输入数据上运行模型
var output = await Tflite.runModelOnBinary(
binary: inputUint8List,
numResults: 2, // 根据需要进行调整
);
print(&quot;here2&quot;);
// 处理 null 或空输出
if (output == null || output.isEmpty) {
var result = output?[0]; 
/* ChatGPT 告诉我这样做，之前将输出变量作为可打印结果。
我认为这个问题没有太大区别，因为它是在代码中断之后*/
setState(() {
_output = &quot;Predicted: ${result[&#39;label&#39;]} (${result[&#39;confidence&#39;]})&quot;;
});
} else {
setState(() {
_output = output.toString();
});
}
} catch (e) {
// 捕获任何错误并显示它们
setState(() {
_output = &quot;Error running model: $e&quot;;
});
}
}

我尝试调整 numResults 参数，查看文档，甚至 chatGippidy，建议执行 var result = output?[0]，但一切都太模糊了，没有深入介绍这个特定堆栈的工作原理。]]></description>
      <guid>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</guid>
      <pubDate>Tue, 09 Jul 2024 17:44:04 GMT</pubDate>
    </item>
    <item>
      <title>加载模型时出错：SyntaxError：意外的标记“<”，“<!DOCTYPE”... 不是有效的 JSON</title>
      <link>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</link>
      <description><![CDATA[我正在使用 React 上的 ml5 和 p5 创建一个瑜伽 AI 训练器。
我创建了一个组件，它从本地 JSON 文件中获取单个姿势作为道具。该组件还加载我在公共文件夹中添加的模型。该组件的目标是检测某个瑜伽姿势，并且该组件动态返回从网络摄像头检测到的姿势名称。
我测试了两个网络摄像头页面。我们称之为第 1 页和第 2 页。
第 1 页有效。URL 为 /practice。第 1 页指向网络摄像头 1。网络摄像头 1 有效。
第 2 页的 URL 是 /practice/poseId。第 2 页指向不同的网络摄像头组件，网络摄像头 2 的代码与网络摄像头 1 完全相同，只是它接受一个道具，并且该道具是与 ID 匹配的特定姿势。
在第二页，我收到此错误
加载模型时出错：SyntaxError：意外的标记 &#39;&lt;&#39;、&quot;&lt;!DOCTYPE&quot;... 不是有效的 JSON

它指向此代码
 const modelInfo = {
model: &quot;model/model.json&quot;,
metadata: &quot;model/model_meta.json&quot;,
weights: &quot;model/model.weights.bin&quot;,
};

fetch(modelInfo.model)
.then((response) =&gt; {
if (!response.ok) {
throw new Error(`HTTP error! status: ${response.status}`);
}
return response.json();
})
.then((data) =&gt; {
console.log(&quot;Model JSON:&quot;, data);
brain.load(modelInfo, brainLoaded);
})
.catch((error) =&gt; {
console.error(&quot;Error loading model:&quot;, error);
});

我不明白为什么我的组件可以在 /practice URL 上运行，但是当我添加 poseId (/practice/:poseID) 时，即使代码相同，也会显示该错误。
错误出现在以 /practice/:poseId 结尾的 URL 上，例如/practice/1.
错误示例（您看不到底部的姿势标签）：

示例（如果页面 URL 为 /practice，则有效）

这是我的 repo：https://github.com/laura-nguyen/yoga-ai/tree/feature/page-pose-cam]]></description>
      <guid>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</guid>
      <pubDate>Tue, 09 Jul 2024 17:06:11 GMT</pubDate>
    </item>
    <item>
      <title>Vision Transformers (ViT) - 澄清问题</title>
      <link>https://stackoverflow.com/questions/78726466/vision-transformers-vit-clarifying-question</link>
      <description><![CDATA[我在网上找到了下面的代码片段，并在 google colab 上进行了基本的图像分类训练。
有人能用简单的术语解释一下当我们执行 RandomResizedCrop、RandomHorizo​​ntalFlip、Normalize、To Tensors 时，幕后到底发生了什么吗？
来自出版物 -&gt; https://openreview.net/pdf?id=YicbFdNTTy
图像被分解成块，然后进行归一化并输入到神经网络中。
from torchvision.transforms import (CenterCrop,
Compose,
Normalize,
RandomHorizo​​ntalFlip,
RandomResizedCrop,
Resize,
ToTensor)

from transformers import ViTImageProcessor

processor = ViTImageProcessor.from_pretrained(&quot;google/vit-base-patch16-224-in21k&quot;)
image_mean = processing.image_mean
image_std = processing.image_std
size = processing.size[&quot;height&quot;]

normalize = Normalize(mean=image_mean, std=image_std)
_train_transforms = Compose(
[
RandomResizedCrop(size),
RandomHorizo​​ntalFlip(),
ToTensor(),
normalize,
]
)

_val_transforms = Compose(
[
Resize(size),
CenterCrop(size),
ToTensor(),
normalize,
]
)

def train_transforms(examples):
examples[&#39;pixel_values&#39;] = [_train_transforms(image.convert(&quot;RGB&quot;)) for image in examples[&#39;image&#39;]]
return examples

def val_transforms(examples):
examples[&#39;pixel_values&#39;] = [_val_transforms(image.convert(&quot;RGB&quot;)) for image in examples[&#39;image&#39;]]
return示例

food[&#39;train&#39;].set_transform(train_transforms)
food[&#39;test&#39;].set_transform(val_transforms)
]]></description>
      <guid>https://stackoverflow.com/questions/78726466/vision-transformers-vit-clarifying-question</guid>
      <pubDate>Tue, 09 Jul 2024 15:22:15 GMT</pubDate>
    </item>
    <item>
      <title>使用专家评分训练神经网络进行图像-文本相关性分析</title>
      <link>https://stackoverflow.com/questions/78724935/training-neural-network-for-image-text-relevance-with-expert-scores</link>
      <description><![CDATA[我有两个数据集：

第一个数据集包含由修改后的 ResNet18 模型生成的 768 维图像嵌入。删除最后的全连接层以获得特征表示而不是图像分类。输出被投影到 768 维向量空间中。

第二个数据集由 DistilBERT 生成的 768 维文本嵌入组成。


图像数据集由没有特定主题和相对中性内容的图像组成，描绘了狗在日常环境中玩耍或人们玩耍的场景。
文本数据集更加复杂。它包含图像内容的描述，每个图像都有多个描述。这些描述按从 0 到 1 的连续比例排序，反映了它们描绘图像的准确性。 0 分表示描述和图像之间没有对应关系，而 1 分表示完美匹配。
目标是开发一种搜索解决方案，允许基于预定义的文本查询进行图像检索。约束是避免使用预训练的多模态模型（如 CLIP）并从头开始设计神经网络。
对我来说，这无疑是一个多模态问题。目标是在同一空间内对齐图像和文本向量。为此，我修改了 ResNet18，并打算构建一个以描述等级作为权重初始化的神经网络。但是，我不确定这种方法的正确性。
我寻求正确的指导方向，并倾向于从头开始构建解决方案以掌握底层数学概念，而不是依赖现有模型。
我无法理解的是如何在同一空间中对齐图像向量和相应的文本向量，以便可以将其用于相似性搜索……]]></description>
      <guid>https://stackoverflow.com/questions/78724935/training-neural-network-for-image-text-relevance-with-expert-scores</guid>
      <pubDate>Tue, 09 Jul 2024 10:01:33 GMT</pubDate>
    </item>
    <item>
      <title>可以将已经经过拆分数据阶段、成为训练、验证和测试数据的图像数据集保存到我的计算机存储文件夹中吗？</title>
      <link>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</link>
      <description><![CDATA[我想问一下我做的训练、验证和测试数据的分布情况，我能把数据分布以文件夹的形式保存在存储中吗？可以吗？
如果想看完整代码
https://github.com/cendekialnazalia/CaisimPestDetection/blob/main/Percobaan%20E%20-%20CNN%20add%20Models%20Xception.ipynb
我想下载测试数据部分，也就是&quot;test_gen&quot;或者说测试数据集。我希望有人能用一个代码来回答我的问题，该代码可以将数据保存到我的电脑中，而不必从现有的数据集集合中逐个搜索图像数据。]]></description>
      <guid>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</guid>
      <pubDate>Tue, 09 Jul 2024 09:41:58 GMT</pubDate>
    </item>
    <item>
      <title>Keras Tensorflow load_model 函数需要很长时间才能加载模型</title>
      <link>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</link>
      <description><![CDATA[我使用 tensorflow 训练了一个模型（用于识别面部），然后将其保存为“facetracker.h5”。但是，当我尝试加载模型时，它只是继续加载“[*]”，如下图所示，并且实际上从未完成加载。模型（facetracker.h5）只有 68 MB，所以我是否正确地认为这不是由于它的大小而发生的？

facetracker 如下所示：
]]></description>
      <guid>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</guid>
      <pubDate>Tue, 09 Jul 2024 09:28:15 GMT</pubDate>
    </item>
    <item>
      <title>强化学习代理没有采取现实行动</title>
      <link>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</link>
      <description><![CDATA[我在 Simulink 环境中使用 PPO 代理，但代理产生的操作似乎是离散的。具体来说，代理仅输出上限或下限。有什么想法为什么会发生这种情况？我正在使用 RL Toolbox 进行训练。
以下是有关我的设置的一些详细信息：

我正在使用带有 ode23t 求解器的可变步长 Simulink 模型。
我的 Simulink 模型使用 Simscape 库进行热流体处理并模拟简化的区域供热网络。 DHN 有 2 个分支：北 (NORD) 和南 (SUD)。
我正在尝试使用 RL 代理来优化控制，最初专注于通过改变分支中的质量流量来最小化能源成本。

关于代理的超参数，我使用具有以下参数的 RL 工具箱：
采样时间 = 3600
折扣因子 = 0.99
GPU
批次大小 = 512
学习率 = 1e-3（对于演员和评论家）

我怀疑我的模型或代理可能有问题。我将附上 Simulink 模型（应事先加载属性表）。
我尝试更改超参数，但没有任何变化。
function reward = computeReward(EBio, EGaz, Taller,Tset, Tr,Demandes,production, penalty1,penalty2)

coutBiomass = 0.04 * EBio;
coutGas = 0.1 * EGaz;

%exp(-(Tr - minTemp) / minTemp);

tempDeviation = penalty1 * abs(Taller-Tset);

unmetDemand = penalty1 * max(0, Demandes - production);

minTemp=penalty2 * exp(-(Tr - 318) / 318);

reward = - (coutBiomass + coutGas + tempDeviation + unmetDemand+minTemp);
结束

obs = rlNumericSpec([8 1]);
act = rlNumericSpec([2 1],&quot;LowerLimit&quot;,-1,&quot;UpperLimit&quot;,1);
agent=rlTD3Agent(obs,act);
env=rlSimulinkEnv(&quot;Quatrieme_Configuration_SansSolaire_RL_Training&quot;,&quot;Quatrieme_Configuration_SansSolaire_RL_Training/RL Agent&quot;,obs,act);
env.ResetFcn=@randomstart; 
env.UseFastRestart=&quot;on&quot;; 
TimeDelay=0.1; 
]]></description>
      <guid>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</guid>
      <pubDate>Tue, 09 Jul 2024 08:41:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用混淆矩阵可视化预测样本</title>
      <link>https://stackoverflow.com/questions/78719068/how-to-visualize-predicted-samples-using-a-confusion-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78719068/how-to-visualize-predicted-samples-using-a-confusion-matrix</guid>
      <pubDate>Mon, 08 Jul 2024 04:07:24 GMT</pubDate>
    </item>
    <item>
      <title>具有 2 个以上类别的 Tensorflow 神经网络</title>
      <link>https://stackoverflow.com/questions/61556662/tensorflow-neural-network-with-more-than-2-categories</link>
      <description><![CDATA[因此，我在 udemy 上观看了 tensorflow 教程并决定自己尝试一下，他说如果您想要超过 2 个类别，请将激活更改为“softmax”并将单位更改为 4，因为我有 4 个不同的类别（从 0:1 更改为 1:4），如果“y”中只有 2 个不同的值，则一切正常，但是一旦我将其更改为 4 个单位和 4 个类别，我就会收到错误：
ValueError：检查目标时出错：预期 density_3 具有形状 (4,)，但得到的数组具有形状 (1,)
即使将其改回形状“1”只产生真或假类别的结果
我的数据集在 y 中：

import numpy as np
from sklearn.metrics import confused_matrix
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense

dataset = np.load(&#39;/Users/alex/desktop/ANN_dataset_for_brightness.npy&#39;)
X = dataset[:, 0:17]
y = dataset[:, 17:19]

for i in range (27):
if y[i] == 400:
y[i] = 4
elif y[i] == 300:
y[i] = 3
elif y[i] == 200:
y[i] = 2
elif y[i] == 100:
y[i] = 1

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

# 初始化 ANN
classifier = Sequential()

# 添加输入层和第一个隐藏层 // 输入层的输入 dim
classifier.add(Dense(activation=&quot;relu&quot;, input_dim=17, unit=6, kernel_initializer=&quot;uniform&quot;))

# 添加第二个隐藏层层
classifier.add(Dense(activation=&quot;relu&quot;, unit=6, kernel_initializer=&quot;uniform&quot;))

问题出在这里
# 单位 = 类别，softmax = 大于 2
classifier.add(Dense(activation=&quot;softmax&quot;, unit=4, kernel_initializer=&quot;uniform&quot;))

# 编译 ANN
classifier.compile(optimizer = &#39;adam&#39;, loss = &#39;binary_crossentropy&#39;, metrics = [&#39;accuracy&#39;])

# 将 ANN 拟合到训练集
classifier.fit(X_train, y_train, batch_size = 27, nb_epoch = 100)

# 第 3 部分 - 进行预测并评估模型

# 预测测试集结果
y_pred = classifier.predict(X_test)
y_pred = (y_pred &gt; 0.5)

# 制作混淆矩阵
cm = confused_matrix(y_test, y_pred)
]]></description>
      <guid>https://stackoverflow.com/questions/61556662/tensorflow-neural-network-with-more-than-2-categories</guid>
      <pubDate>Sat, 02 May 2020 08:48:03 GMT</pubDate>
    </item>
    <item>
      <title>如何计算伯努利朴素贝叶斯的联合对数似然</title>
      <link>https://stackoverflow.com/questions/52861129/how-to-calculate-the-joint-log-likelihood-for-bernoulli-naive-bayes</link>
      <description><![CDATA[对于使用 BernoulliNB 的分类问题，如何计算联合对数似然。联合似然由以下公式计算，其中 y(d) 是实际输出（不是预测值）的数组，x(d) 是特征的数据集。
我阅读了这个答案并阅读了文档，但它并没有完全满足我的目的。有人可以帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/52861129/how-to-calculate-the-joint-log-likelihood-for-bernoulli-naive-bayes</guid>
      <pubDate>Wed, 17 Oct 2018 18:08:50 GMT</pubDate>
    </item>
    </channel>
</rss>