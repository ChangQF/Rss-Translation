<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Jun 2024 15:16:39 GMT</lastBuildDate>
    <item>
      <title>如何在多元回归中显示预测因子重要性+特征名称？</title>
      <link>https://stackoverflow.com/questions/78587419/how-can-i-display-predictor-importance-feature-name-in-multivariate-regression</link>
      <description><![CDATA[我正在探索一个数据集，目的是找到任何有趣的关系（有很多感兴趣的变量，我想看看哪些特征或特征组合可以预测它们）。
作为第一种方法，我成功地用套索计算了一个多变量（几个目标变量）回归。
pipeline = Pipeline([
(&#39;scaler&#39;, StandardScaler()),
(&#39;model&#39;, Lasso())])

search = GridSearchCV(pipeline,
{&#39;model__alpha&#39;:np.arange(0.1,10,0.1)},
cv = 5,scoring=&quot;neg_mean_squared_error&quot;,verbose=3
)
search.fit(X_train,y_train)
search.best_params_
coefficients = search.best_estimator_.named_steps[&#39;model&#39;].coef_
importance = np.abs(系数)

现在我想看看预测因子的重要性，包括它们的特征名称，因为 importance 只是一堆数字。
我考虑过创建一个包含特征和目标的列名的数组并打印名称 + 系数，但我的问题是我不完全确定如何确保对应关系（正确的名称与正确的系数一起显示）。
有人能帮我吗？
这里有一些额外的信息：

预测因子数量：26
目标数量：30
importance 的形状：（30, 26）

我也非常感谢关于使用哪些重要性指标的任何其他建议或有关可能分析的任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/78587419/how-can-i-display-predictor-importance-feature-name-in-multivariate-regression</guid>
      <pubDate>Thu, 06 Jun 2024 14:49:37 GMT</pubDate>
    </item>
    <item>
      <title>xgboast scale_pos_weight 如果训练数据集中的正样本多于负样本，是否仍然保持平衡？</title>
      <link>https://stackoverflow.com/questions/78587301/xgboast-scale-pos-weight-if-the-training-dataset-has-more-positive-samples-than</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我确信 scale_pos_weight 会是一种更好的方法。是否可以假设因为它小于 1，所以它仍然会正确平衡？当然，特异性在我的研究中很重要，但我们的目标更多是关于召回率、精确度和 f1 分数。这是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/xgboast-scale-pos-weight-if-the-training-dataset-has-more-positive-samples-than</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>大型语言模型发布的关键质量指标是什么？</title>
      <link>https://stackoverflow.com/questions/78587300/what-are-the-key-quality-metrics-for-large-language-model-releases</link>
      <description><![CDATA[我是一名一年级博士生，致力于改进机器学习模型的发布实践，尤其是预先训练的大型语言模型。我想了解上述概念，以便进行初步学习并听取专家的意见。
我一直在阅读不同的文章，但仍然需要专家的意见。]]></description>
      <guid>https://stackoverflow.com/questions/78587300/what-are-the-key-quality-metrics-for-large-language-model-releases</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 paddleocr 从图像文档中提取表格</title>
      <link>https://stackoverflow.com/questions/78586625/extract-tables-from-image-documents-using-paddleocr</link>
      <description><![CDATA[我是 Ocr 的新手。我正尝试从图像格式的表格中提取数据。
输入图像
为此我想使用 paddleocr，paddleocr 是否适合这些类型的表格图像。如果可以，有人可以提供图像的资源或教程吗？或者是否有任何适用于表格图像的软件包]]></description>
      <guid>https://stackoverflow.com/questions/78586625/extract-tables-from-image-documents-using-paddleocr</guid>
      <pubDate>Thu, 06 Jun 2024 12:37:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的验证准确度比训练准确度差？</title>
      <link>https://stackoverflow.com/questions/78586275/why-is-my-validation-accuracy-worse-than-train-accuracy</link>
      <description><![CDATA[我正在 Chestxray 数据集上训练 ResNet50。我的训练数据大约有 15000 个样本，其中 1500 个用于验证，3000 个用于测试。这是一个多标签分类问题，我有 13 个标签，并且对其进行了独热编码。我在训练时遇到了一个问题。尽管观察到训练准确率在各个时期有所提高，但验证准确率似乎有所下降。我尝试了几次实验（操纵学习率、更改架构）和故障排除步骤，但都无法解决这个问题。我也使用了很多数据增强方法，但并没有收敛。我应该怎么做才能对其进行排序？
架构
learning_rate = 0.001
early_stopping = EarlyStopping(monitor=&#39;val_accuracy&#39;,patient=5,restore_best_weights=True)
adam_optimizer = Adam(learning_rate=learning_rate)

resnet50 = ResNet50(input_shape=(256, 256, 3),weights=&#39;imagenet&#39;,include_top=False)

for layer in resnet50.layers:
layer.trainable = False

x = Flatten()(resnet50.output)
prediction = Dense(13,activation=&#39;sigmoid&#39;)(x)

model = Model(inputs=resnet50.input,outputs=prediction)

model.compile(optimizer=adam_optimizer, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

history = model.fit(
train_dataset,
epochs=100,
validation_data=val_dataset,
callbacks=[early_stopping]

结果
Epoch 1/100
477/477 [================================] - 44s 83ms/step - loss: 1.2993 - accuracy: 0.1122 - val_loss: 1.0983 - val_accuracy: 0.1010

Epoch 2/100
477/477 [===============================] - 38s 80ms/step - 损失：1.0298 - 准确度：0.1843 - val_loss：1.3670 - val_accuracy：0.0976

Epoch 3/100
477/477 [===============================] - 39s 81ms/step - 损失：0.9871 - 准确度：0.2328 - val_loss：1.1190 - val_accuracy：0.1155

Epoch 4/100
477/477 [================================] - 39s 81ms/步 - 损失：0.9146 - 准确度：0.2757 - val_loss：1.2730 - val_accuracy：0.0797

Epoch 5/100
477/477 [==============================] - 38s 81ms/步 - 损失：0.9076 - 准确度：0.3011 - val_loss：1.4535 - val_accuracy：0.0708

Epoch 6/100
477/477 [================================] - 39s 82ms/步 - 损失：0.9280 - 准确度：0.3104 - val_loss：1.6235 - val_accuracy：0.0632

Epoch 7/100
477/477 [===============================] - 39s 81ms/step - 损失：0.8828 - 准确度：0.3356 - val_loss：1.3770 - val_accuracy：0.0777

Epoch 8/100
477/477 [===============================] - 39s 82ms/step - 损失：0.8223 - 准确度：0.3633 - val_loss：1.3722 - val_accuracy：0.1512

Epoch 9/100
477/477 [===============================] - 39s 81ms/步 - 损失：0.8407 - 准确度：0.3669 - val_loss：1.3479 - val_accuracy：0.1856

Epoch 10/100
477/477 [==============================] - 39s 81ms/步 - 损失：0.8931 - 准确度：0.3773 - val_loss：1.6562 - val_accuracy：0.0784

Epoch 11/100
477/477 [===============================] - 39s 81ms/step - 损失：0.9010 - 准确度：0.3832 - val_loss：1.9345 - val_accuracy：0.0804

Epoch 12/100
477/477 [===============================] - 39s 81ms/step - 损失：0.8932 - 准确度：0.3961 - val_loss：1.8141 - val_accuracy：0.0900

Epoch 13/100
477/477 [===============================] - 39s 81ms/step - 损失：0.8961 - 准确度：0.4017 - val_loss：2.1651 - val_accuracy：0.0598

Epoch 14/100
477/477 [===============================] - 39s 82ms/step - 损失：0.7799 - 准确度：0.4318 - val_loss：1.8136 - val_accuracy：0.0997
]]></description>
      <guid>https://stackoverflow.com/questions/78586275/why-is-my-validation-accuracy-worse-than-train-accuracy</guid>
      <pubDate>Thu, 06 Jun 2024 11:30:22 GMT</pubDate>
    </item>
    <item>
      <title>如何在支持物联网的自动售货机中实现实时库存跟踪？</title>
      <link>https://stackoverflow.com/questions/78586219/how-to-implement-real-time-inventory-tracking-in-iot-enabled-vending-machines</link>
      <description><![CDATA[该问题的主要目标是收集在自动售货机中实施基于物联网的实时库存跟踪的见解和解决方案。所概述的挑战涉及项目的关键方面，例如传感器选择、数据传输、系统集成、数据安全性和成本效益。通过提供详细的项目目标和具体挑战，该问题旨在让 Stack Overflow 社区提供实用建议、最佳实践和来自他们经验的示例
我尝试过的：

传感器选择：研究并入围了一些可以准确监控库存水平的传感器（例如，称重传感器、红外传感器）。
连接选项：考虑使用 Wi-Fi 和蜂窝网络进行数据传输。测试了初始设置，但面临间歇性连接问题。
数据处理：使用 AWS IoT Core 设置基本的云基础设施，以收集和处理来自传感器的数据。
原型：使用 Arduino 板和称重传感器构建了一个基本原型，以测量库存水平并将数据发送到 AWS IoT Core。原型可以工作，但准确性和可靠性需要改进。

我的期望：

关于最佳传感器类型的建议，以实现准确可靠的库存跟踪。
确保在连接性较差的地区稳定传输数据的解决方案。
自动售货机中 IoT 设备的电源管理技巧。
有关将新 IoT 组件与我们现有的后端系统集成的建议。
]]></description>
      <guid>https://stackoverflow.com/questions/78586219/how-to-implement-real-time-inventory-tracking-in-iot-enabled-vending-machines</guid>
      <pubDate>Thu, 06 Jun 2024 11:16:19 GMT</pubDate>
    </item>
    <item>
      <title>恶意软件特征提取困难，难以找到自动化工具</title>
      <link>https://stackoverflow.com/questions/78585761/stuck-at-the-malware-features-extraction-difficulty-at-finding-automated-tools</link>
      <description><![CDATA[我正在尝试构建一个机器学习恶意软件检测工具；我发现了多个数据集，包括微软恶意软件分类挑战（2015）和 CSV 数据集。问题是我卡在了特征提取上，特别是在 Windows 上自动执行静态和动态分析的工具。
我读过关于 PE（可移植可执行文件）工具（如 pestudio）、沙箱（如 cuckoo sandbox）的文章，但我卡在了需要自动执行分析的部分（即通过 python 代码调用工具）。
我已经使用 CSV 数据训练了多个模型（随机森林、SVM、梯度提升等），但现在我想在真正的恶意软件上尝试一下。
我曾尝试使用 IDA 反汇编程序将二进制文件转换为 .asm 和 .bytes，但似乎我需要专业版才能自动完成转换。
如果有人可以推荐一些工具，我可以用来自动执行 Windows 上的分析和特征提取，我将不胜感激，任何指向正确特征提取的指针也非常感谢 :)]]></description>
      <guid>https://stackoverflow.com/questions/78585761/stuck-at-the-malware-features-extraction-difficulty-at-finding-automated-tools</guid>
      <pubDate>Thu, 06 Jun 2024 09:43:08 GMT</pubDate>
    </item>
    <item>
      <title>在 Azure Databricks 中使用 pyspark ML 库函数时出现 Py4J 安全错误</title>
      <link>https://stackoverflow.com/questions/78585509/py4j-security-error-while-using-pyspark-ml-library-functions-in-azure-databricks</link>
      <description><![CDATA[我试图在我的 Azure Databricks 工作簿中运行以下代码
import pyspark.ml.feature
from pyspark.ml.feature import Tokenizer,StopWordsRemover
tokenizer = Tokenizer()

但是我遇到了这个错误：
Py4JError：调用 
None.org.apache.spark.ml.feature.Tokenizer 时发生错误。跟踪：
py4j.security.Py4JSecurityException：构造函数 public 
org.apache.spark.ml.feature.Tokenizer(java.lang.String) 未列入白名单。

StopWordsRemover 和 pyspark.ml.feature 中的其他一些函数也会出现类似的错误
有没有办法避免此错误，以便我可以使用相同的代码？]]></description>
      <guid>https://stackoverflow.com/questions/78585509/py4j-security-error-while-using-pyspark-ml-library-functions-in-azure-databricks</guid>
      <pubDate>Thu, 06 Jun 2024 08:56:01 GMT</pubDate>
    </item>
    <item>
      <title>使用前向验证时，时间序列数据的 LSTM 性能急剧下降</title>
      <link>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</guid>
      <pubDate>Thu, 06 Jun 2024 06:12:10 GMT</pubDate>
    </item>
    <item>
      <title>Python tensorflow 图像回归模型中的 MAE 损失函数存在问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78583554/issue-with-my-mae-loss-function-in-python-tensorflow-image-regression-model</link>
      <description><![CDATA[我有 8000 张黑色背景上的圆圈图像。每个标签都是圆圈的 x 坐标。每张图片的尺寸为 (128,128,3)。我的训练损失从 2000 开始，到 10 结束，而验证损失保持在 200 左右。另外，我通过将每幅图像除以 255 来对其进行标准化。
images_array 的形状为：(8000,128,128,3)
y 的形状为：(8000,1)
这是我的代码：
from sklearn.model_selection import train_test_split
X_train, X_temp, y_train, y_temp = train_test_split(images_array, y, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

import tensorflow as tf
X_train = tf.convert_to_tensor(X_train)
y_train = tf.convert_to_tensor(y_train)

从 tensorflow 导入 keras
从 tensorflow.keras 导入层，模型
从 tensorflow.keras.models 导入顺序

输入 = keras.Input(shape=(128, 128, 3))

# 定义层

x = 层。Conv2D(8, 3, 激活=&#39;relu&#39;)(输入)
x = 层。MaxPooling2D(2)(x)
x = 层。Conv2D(16, 3, 激活=&#39;relu&#39;)(x)
x = 层。MaxPooling2D(2)(x)
x=层。Flatten()(x)
x = 层。Dense(128, 激活=&#39;relu&#39;)(x)
output_x = 层。Dense(1, 激活 = &#39;linear&#39;, 名称 = &quot;y1_output&quot;)(x)

model = Model(inputs = input, output = output_x)
model.summary()


我可以做些什么来显著改善我的损失？
我尝试了不同的激活函数和不同的优化器。]]></description>
      <guid>https://stackoverflow.com/questions/78583554/issue-with-my-mae-loss-function-in-python-tensorflow-image-regression-model</guid>
      <pubDate>Wed, 05 Jun 2024 21:21:28 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的残差</title>
      <link>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</link>
      <description><![CDATA[假设我们有一个线性模型，该模型适用于某些数据，其残差呈正态分布。我要问的问题是，我们能否在建模方面做得更好？有没有比这个线性模型更好的模型？
由于残差是 ND，因此没有模式可学习，因此线性模型是最好的。你对此有什么看法？
谢谢
我试图找到我的主张的严格证据，但找不到。]]></description>
      <guid>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</guid>
      <pubDate>Wed, 05 Jun 2024 15:14:26 GMT</pubDate>
    </item>
    <item>
      <title>将图像置于中心并在导出时添加背景</title>
      <link>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</link>
      <description><![CDATA[我想自动完成所有这些操作：

选择图像中的对象
在此对象上裁剪我的图像
裁剪为 1:1 的宽高比，在此对象周围留出一点空隙
以 800x800px 的 JPG 格式导出我的图像，我的对象位于图像中心，背景为白色。

我在 win11 64 位上
我做了什么：

安装 Python 并创建环境
安装opencv-python-headless、pillow、numpy、Pytorch以用于 CUDA 11.8
克隆存储库 segment-anything.git 并使用 PIP 安装它
下载sam_vit_b_01ec64.pth

像这样对 py 文件进行编码：
import os
import cv2
import numpy as np
from PIL import Image
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator

def load_image(image_path):
return cv2.imread(image_path)

def save_image(image, path):
cv2.imwrite(path + &#39;.jpg&#39;, image)

def select_object(image):
sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;sam_vit_b_01ec64.pth&quot;)
mask_generator = SamAutomaticMaskGenerator(sam)
mask = mask_generator.generate(image)
largest_mask = max(masks, key=lambda x: x[&#39;area&#39;])
返回 largest_mask[&#39;segmentation&#39;]

def crop_to_object(image, mask):
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
padding = 5
x = max(0, x - padding)
y = max(0, y - padding)
w = min(image.shape[1] - x, w + 2 * padding)
h = min(image.shape[0] - y, h + 2 * padding)

cropped_image = image[y:y+h, x:x+w]
返回 cropped_image

def resize_to_square(image, size=800):
h, w = image.shape[:2]
scale = size / max(h, w)
new_h, new_w = int(h * scale), int(w * scale)
resized_image = cv2.resize(image, (new_w, new_h), 插值=cv2.INTER_LANCZOS4)

new_image = np.ones((size, size, 3), dtype=np.uint8) * 255

top = (size - new_h) // 2
left = (size - new_w) // 2
bottom = top + new_h
right = left + new_w

new_image[top:top+new_h, left:left+new_w] = resized_image

return new_image

def process_image(image_path, output_path):

image = load_image(image_path)
mask = select_object(image)
cropped_image = crop_to_object(image, mask)
final_image = resize_to_square(cropped_image, 800)
save_image(final_image, output_path + &#39;.jpg&#39;)

def process_folder(input_folder, output_folder):

如果 os.path.exists(output_folder):
os.makedirs(output_folder)

对于 root, _, files in os.walk(input_folder):
对于 filename in files:
如果 filename.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;, &#39;.bmp&#39;, &#39;.tiff&#39;)):
input_path = os.path.join(root, filename)

relative_path = os.path.relpath(input_path, input_folder)
output_path = os.path.join(output_folder,relative_path)

output_dir = os.path.dirname(output_path)
如果 os.path.exists(output_dir):
os.makedirs(output_dir)

尝试:
process_image(input_path, output_path)
print(f&quot;已处理 {input_path}&quot;)
except Exception as e:
print(f&quot;无法处理 {input_path}：{e}&quot;)

if __name__ == &quot;__main__&quot;:
input_folder = &quot;&quot;
output_folder = &quot;&quot;
process_folder(input_folder, output_folder)

发生了什么：
我导入了基本图像，我想要预期结果，并且我获得了结果
我得到了一些不同的基本结果：

基本白色背景 -&gt; 结果
Base-nobg -&gt; &gt; 结果

有人能帮我理解我错过了什么吗？
提前谢谢，
Cyril]]></description>
      <guid>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</guid>
      <pubDate>Wed, 05 Jun 2024 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 处理作业权限被拒绝保存 /opt/ml/processing/<folder> 下的 csv 文件</title>
      <link>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</link>
      <description><![CDATA[我正在开展一个涉及 Step Functions 和 SageMaker 的项目。我有一个现有的 Step Function，需要将 SageMaker 集成到其中，我尝试添加处理、模型训练、注册模型和批量转换作业请求等步骤。我还在每个资源的末尾添加了 .sync，以便它等待一个资源完成后再开始下一个资源。
但是，我在 Step Function 的 SageMaker 处理作业中遇到了问题。处理作业运行但未完成，因为权限被拒绝从我处理的 pandas 数据框保存 CSV 文件。
# 依赖项导入
df = pd.read_csv(&quot;/opt/ml/processing/input/data/data.csv&quot;)
print(df.head())

# 对 df 进行一些处理

df.to_csv(&quot;/opt/ml/processing/output/result.csv&quot;, index=False)

以下是处理请求的状态机配置：
如果您需要查看我的配置的其他部分，请给我留言
{
&quot;AppSpecification&quot;: {
&quot;ContainerEntryPoint&quot;: [
&quot;python3&quot;,
&quot;/opt/ml/processing/input/code/processing.py&quot;
]
},
&quot;ProcessingInputs&quot;: [
{
&quot;InputName&quot;: &quot;Input-1&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/data&quot;
}
},
{
&quot;InputName&quot;: &quot;Input-2&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/processing.py&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/code&quot;
}
}
],
&quot;ProcessingOutputConfig&quot;: {
&quot;Outputs&quot;: [
{
&quot;OutputName&quot;: &quot;Output-1&quot;,
&quot;S3Output&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/output/&quot;,
&quot;S3U​​ploadMode&quot;: &quot;EndOfJob&quot;
}
}
]
}
}

ProcessingInputs 配置按预期工作。我在日志中看到 df.head() 将 data.csv 内容正确打印在日志中。但是，当它到达最后一行代码时，我收到以下错误：
PermissionError: Permission Denied &#39;/opt/ml/processing/output/result.csv&#39;
我还尝试将其保存到其他文件夹，如我在网上找到的一些示例中所见，例如保存到 training、result 等文件夹，但到目前为止还没有成功。它给了我同样的权限错误。我使用了为此专门创建的 Lambda 函数，并向 SageMaker 处理作业发出请求，并得到了完全相同的权限被拒绝错误。
我还尝试将文件保存到 /opt/ml/processing/ 之外的完全不同的文件夹中，但 /result.csv
但它给了我不同的错误，因为 SageMaker 只允许我们将 csv 文件保存在 /opt/ml/processing/ 下......所以我不知道该怎么做。
目前，我正在使用 boto3 api 手动保存结果集，并等待处理作业通过我设置的 StoppingCondition.MaxRuntimeInSeconds 时间，最终它停止，我使用附加步骤来获取它。
但我不喜欢我解决问题的方式，我真的需要找到更好的方法来解决这个问题。
有人能告诉我我遗漏了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</guid>
      <pubDate>Wed, 29 May 2024 19:34:23 GMT</pubDate>
    </item>
    <item>
      <title>什么时候 dropout 对分割任务有用？</title>
      <link>https://stackoverflow.com/questions/44160030/when-dropout-is-useful-for-segmentation-task</link>
      <description><![CDATA[我正在从事分割任务。我的数据集很少。我的网络非常深（基于 Resnet）。我的问题是，dropout 在我的领域什么时候有用？我知道 dropout 通常用于处理过拟合问题。但对于分割，我没有看到很多使用 dropout 的论文。谢谢]]></description>
      <guid>https://stackoverflow.com/questions/44160030/when-dropout-is-useful-for-segmentation-task</guid>
      <pubDate>Wed, 24 May 2017 13:37:00 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn：如何获得真阳性、真阴性、假阳性和假阴性</title>
      <link>https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal</link>
      <description><![CDATA[我的问题：
我有一个数据集，它是一个大型 JSON 文件。我读取它并将其存储在 trainList 变量中。
接下来，我对其进行预处理 - 以便能够使用它。
完成后，我开始分类：

我使用 kfold 交叉验证方法来获得平均准确率并训练分类器。
我进行预测并获得该折叠的准确率和混淆矩阵。
在此之后，我想获得 真阳性 (TP)、真阴性 (TN)、假阳性 (FP) 和 假阴性 (FN) 值。我将使用这些参数来获得敏感性和特异性。 

最后，我将使用它将其放入 HTML 中，以便显示包含每个标签的 TP 的图表。
代码：
我目前拥有的变量：
trainList #这是一个包含我数据集的所有数据的 JSON 格式列表
labelList #这是一个包含我数据的所有标签的列表

该方法的大部分内容：
#我将数据从 JSON 格式转换为数字格式
X=vec.fit_transform(trainList)

#我缩放矩阵（不知道为什么，但没有它，就会出错）
X=preprocessing.scale(X.toarray())

#我生成一个 KFold 以进行交叉验证
kf = KFold(len(X), n_folds=10, indices=True, shuffle=True, random_state=1)

#我开始对 kf 中的 train_indices、test_indices 进行交叉验证

X_train=[X[ii] for ii in train_indices]
X_test=[X[ii] for ii in test_indices]
y_train=[listaLabels[ii] for ii in train_indices]
y_test=[listaLabels[ii] for ii in test_indices]

#我训练分类器
trained=qda.fit(X_train,y_train)

#我进行预测
predicted=qda.predict(X_test)

#我获得此折叠的准确率
ac=accuracy_score(predicted,y_test)

#我获得混淆矩阵
cm=confusion_matrix(y_test, predicted)

#我应该计算 TP、TN、FP 和 FN
#我不知道如何继续
]]></description>
      <guid>https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal</guid>
      <pubDate>Thu, 09 Jul 2015 17:19:02 GMT</pubDate>
    </item>
    </channel>
</rss>