<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 22 Aug 2024 18:20:25 GMT</lastBuildDate>
    <item>
      <title>Azure ML Studio 上的 Pytorch 出现错误：mpirun 检测到一个或多个进程以非零状态退出，从而导致作业终止</title>
      <link>https://stackoverflow.com/questions/78901891/pytorch-on-azure-ml-studio-gives-error-mpirun-detected-that-one-or-more-process</link>
      <description><![CDATA[有人知道为什么它不起作用以及我该如何修复它吗？我使用的数据集已经准备好并清理过，因此所有文件都符合所需的参数，即正确的格式、大小和形状。
我正在使用 Azure 提供的 DenseNet 图像分类管道。我使用的数据集包含 223 幅图像。

]]></description>
      <guid>https://stackoverflow.com/questions/78901891/pytorch-on-azure-ml-studio-gives-error-mpirun-detected-that-one-or-more-process</guid>
      <pubDate>Thu, 22 Aug 2024 13:43:15 GMT</pubDate>
    </item>
    <item>
      <title>如何访问 Google Video Intelligence API 使用的预定义标签的完整列表？[关闭]</title>
      <link>https://stackoverflow.com/questions/78901885/how-can-i-access-the-full-list-of-predefined-labels-used-by-google-video-intelli</link>
      <description><![CDATA[我正在使用 Google Video Intelligence API 检测视频中的对象、场景和动作。API 在响应的 entity.description 字段中返回诸如人、汽车、狗等标签。
我了解这些标签是预定义的，来自 Google 机器学习模型使用的结构化分类法。但是，我正在寻找 API 可以检测到的所有可能的标签或类别的完整列表。具体来说，我想知道：
是否有 Google Video Intelligence API 使用的所有标签的官方列表？
我在哪里可以找到或访问此列表？
如果没有已发布的列表，是否有任何已知的资源或方法来收集此信息？
我需要此列表，因为我正在进行类别映射，了解所有可能的标签将有助于确保我涵盖 API 的所有潜在输出。
如果您能提供关于在哪里可以找到这些信息的任何指导或见解，我将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78901885/how-can-i-access-the-full-list-of-predefined-labels-used-by-google-video-intelli</guid>
      <pubDate>Thu, 22 Aug 2024 13:42:14 GMT</pubDate>
    </item>
    <item>
      <title>在 C# 中按相似性对文本文档进行分组</title>
      <link>https://stackoverflow.com/questions/78901288/grouping-text-documents-by-similarity-in-c-sharp</link>
      <description><![CDATA[我试图根据内容的相似程度对一些相对较短的文本文档（通常每个文档最多 500 个单词）进行分组。相似的文档通常在措辞上相当接近，但并不完全相同，因此我正在寻找一种机器学习方法来提供比简单地查找重复文本（即基于相似度的百分比进行分组）更宽松的匹配算法。但是，我对 ML 的经验有限，所以我正在寻找有关至少从哪里开始解决此类问题的信息。
当我使用 C# 工作时，我正在使用 ML.NET 寻找解决方案。我熟悉 K-Means，并且找到了一些关于使用它执行相似性匹配的信息，以及有关 ML.NET 的句子相似性 API的信息，但我不确定这些是否是正确的方向，因为 ML.NET 对这些的实现似乎需要一定数量的监督训练数据，而不是能够完全不受监督地对一组数据进行工作。
我理解，为了让代码理解什么是“相似文本”，可能需要一些预先的数据实际上看起来像，但我不清楚实际实现此类事情的最佳方法，也很难找到相关信息。我知道余弦相似度与此类问题有关，但 ML.NET 是应用它的正确库吗？有没有更简单的解决方案，特别是考虑到文档在文本和主题上已经相对接近？]]></description>
      <guid>https://stackoverflow.com/questions/78901288/grouping-text-documents-by-similarity-in-c-sharp</guid>
      <pubDate>Thu, 22 Aug 2024 11:21:52 GMT</pubDate>
    </item>
    <item>
      <title>使用弹性网络进行特征选择</title>
      <link>https://stackoverflow.com/questions/78901259/feature-selection-with-elastic-net</link>
      <description><![CDATA[我对机器学习中的特征选择还比较陌生。在了解到弹性网络往往比 Lasso 和 Ridge 回归表现更好（特别是因为它解决了多重共线性问题）后，我决定使用它进行特征选择。
我编写了一个代码，在嵌套交叉验证设置（具有 5 个内部折叠和 20 个外部折叠）中从最佳弹性网络模型（具体而言，具有实现最高 AUC 的 alpha 和 lambda 值的模型）中选择最佳特征。然后，我使用这些选定的特征进行进一步的模型训练。
但是，我不确定我是否正确实施了嵌套交叉验证。此外，当我尝试检索 alpha 和 lambda 值以报告它们的可重复性时，我似乎无法在结果中找到它们。
代码如下：
set.seed(1)
train_elastic_net &lt;- function(X_train, y_train, alphas, lambdas) {
best_auc &lt;- 0
best_model &lt;- NULL
best_features &lt;- NULL

for (alpha_value in alphas) {
# 设置交叉验证的训练控制
train_control &lt;- trainControl(method = &quot;cv&quot;, 
number = 5, 
classProbs = TRUE, 
summaryFunction = twoClassSummary)

# 定义调整网格
tune_grid &lt;- expand.grid(alpha = alpha_value, lambda = lambdas)

#使用 caret 训练模型
model &lt;- train(X_train, y_train,
method = &quot;glmnet&quot;,
trControl = train_control,
tuneGrid = tune_grid,
metric = &quot;ROC&quot;,
family = &quot;binomial&quot;)

# 获取最佳模型
best_lambda &lt;- model$bestTune$lambda
elastic_net_model &lt;- glmnet(as.matrix(X_train), y_train, alpha = alpha_value, lambda = best_lambda, family = &quot;binomial&quot;)

# 获取最佳模型的 AUC
auc &lt;- max(model$results$ROC)

# 如果当前模型更好，则更新最佳模型
if (auc &gt; best_auc) {
best_auc &lt;- auc
best_model &lt;- elastic_net_model
coef_elastic_net &lt;- coef(best_model, s = best_lambda)
selected_features &lt;- which(coef_elastic_net != 0) - 1 # 获取非零系数的索引
selected_features &lt;- selected_features[selected_features != 0] # 删除截距索引
best_features &lt;- selected_features
}
}

list(model = best_model, features = best_features)
}

y_train_factor &lt;- as.factor(y_train_total)
X_train_matrix &lt;- as.matrix(X_train_total)

# 定义要搜索的 alpha 和 lambda 值
alpha_values &lt;- seq(0.1, 1, by = 0.1)
lambda_values &lt;- 10^seq(-4, 1, length = 100)

# 为每个分割执行 20 次重复
n_repeats &lt;- 20
selected_features_list &lt;- list()

for (i in 1:n_repeats) {

# 使用弹性网络执行变量选择
result &lt;- train_elastic_net(X_train_matrix, y_train_factor, alpha_values, lambda_values)
best_model &lt;- result$model
best_features &lt;- result$features

# 存储此重复的选定特征
selected_features_list[[i]] &lt;- best_features
}
selected_features_list
# 聚合所有重复的选定特征
selected_features_final &lt;- Reduce(intersect, selected_features_list)
selected_features_final
# 使用最终选定的特征对训练数据进行子集化
X_train_total &lt;- X_train_total[, selected_features_final]
]]></description>
      <guid>https://stackoverflow.com/questions/78901259/feature-selection-with-elastic-net</guid>
      <pubDate>Thu, 22 Aug 2024 11:14:15 GMT</pubDate>
    </item>
    <item>
      <title>您能否建议最佳的 AI 模型来为数据库创建分类器</title>
      <link>https://stackoverflow.com/questions/78901133/can-you-suggest-best-ai-model-to-create-a-classifier-for-a-database</link>
      <description><![CDATA[为数据库创建分类器的最佳解决方案是什么。以下示例：
表 1：
---------------------
|狗|猫|日期|时间|
--------------------
|德国|波斯|12-09-2019|12:00:00|
|贵宾犬|布娃娃|10-08-2022|01:09:11|
|斗牛犬|缅甸猫|09-01-1999|03:00:09|

模型的输入应为“德国”，预测应为“狗”
我尝试了 NER，但我也需要概率。示例：
输入：德语
预期输出：狗：98%
猫：10%
日期：2%
时间：1%
]]></description>
      <guid>https://stackoverflow.com/questions/78901133/can-you-suggest-best-ai-model-to-create-a-classifier-for-a-database</guid>
      <pubDate>Thu, 22 Aug 2024 10:47:45 GMT</pubDate>
    </item>
    <item>
      <title>使用定制的头部来微调语言模型</title>
      <link>https://stackoverflow.com/questions/78901109/finetuning-a-language-model-with-a-customized-head</link>
      <description><![CDATA[我正在微调 BERT 模型来执行一项相当复杂的任务。它应该识别输入字符串中的目标，对每个目标执行回归并输出

输入中每个已识别目标的开始/结束索引
每个目标的回归值

采用 JSON 格式。
据我所知，训练本身非常简单，但要以所需的格式获得输出（JSON 格式的多个输出），我需要自定义模型的头部。
所以，我并不是真的在这里寻找解决方案，而是寻找有关如何做到这一点的资源（教程、论文、视频）。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78901109/finetuning-a-language-model-with-a-customized-head</guid>
      <pubDate>Thu, 22 Aug 2024 10:41:28 GMT</pubDate>
    </item>
    <item>
      <title>用于手语的 LSTM [关闭]</title>
      <link>https://stackoverflow.com/questions/78899773/lstm-for-sign-language</link>
      <description><![CDATA[实时模型是否可以转换为预先录制的视频上传？
例如，我将训练一个用于手语的 LSTM 模型，以实现实时识别。现在我想将其集成到移动应用程序中，这样我就可以随身携带手机，因此预先录制的视频会更好。]]></description>
      <guid>https://stackoverflow.com/questions/78899773/lstm-for-sign-language</guid>
      <pubDate>Thu, 22 Aug 2024 04:16:56 GMT</pubDate>
    </item>
    <item>
      <title>KerasTensors 上的二元交叉熵不起作用</title>
      <link>https://stackoverflow.com/questions/78898962/binary-crossentropy-on-kerastensors-not-working</link>
      <description><![CDATA[我正尝试在 tf/keras 中实现此 VAE，但 binary_crossentropy 似乎出了点问题。
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Lambda, Input, Dense
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.models import Model

...

def build_vae():
...

rebuild_loss = binary_crossentropy(inputs, output) * image_size
kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)
kl_loss = K.sum(kl_loss, axis=-1)
kl_loss *= -0.5
vae_loss = K.mean(reconstruction_loss + kl_loss)

我在 binary_crossentropy 行上收到错误。确认 inputs 和 outputs 属于 KerasTensor 类型后，回溯状态为：

ValueError：KerasTensor 不能用作 TensorFlow 函数的输入。KerasTensor 是形状和 dtype 的符号占位符，用于构建 Keras Functional 模型或 Keras Functions。您只能将其用作 Keras 层或 Keras 操作的输入（来自命名空间 keras.layers 和 keras.operations）。

如何修复此问题？此外，我很好奇为什么 tensorflow.keras.losses.binary_crossentropy 不接受 KerasTensors，或者为什么它不被视为 Keras 函数，即使它在 keras 库中。
我尝试将 binary_crossentropy 包装在 keras Layer 子类中，该行有效，但随后所有 K 函数都会出错。如果我必须对所有使用的 K 函数重复该过程，我会感到惊讶]]></description>
      <guid>https://stackoverflow.com/questions/78898962/binary-crossentropy-on-kerastensors-not-working</guid>
      <pubDate>Wed, 21 Aug 2024 20:53:11 GMT</pubDate>
    </item>
    <item>
      <title>尝试加载 hydra 的配置时出现问题</title>
      <link>https://stackoverflow.com/questions/78896800/problem-when-trying-to-load-the-config-of-hydra</link>
      <description><![CDATA[我正在 google collab 中运行 python 脚本。当我执行此操作时，我收到配置错误，但我不确定如何修复它
代码片段：
import hydra
from pathlib import Path # 导入文件路径处理的路径
import sys # 导入 sys 模块

@hydra.main(config_path=&quot;cfgs&quot;, config_name=&quot;config.yaml&quot;)
def main(cfg):
print(cfg) # 打印解析的配置
from train import Workspace as W
root_dir = Path.cwd()

working = W(cfg)

snap = root_dir / &#39;snapshot.pt&#39;

if snap.exists():
print(f&#39;resuming: {snapshot}&#39;)
working.load_snapshot()

working.train()

if __name__ == &#39;__main__&#39;:
main() 

输出我得到的是：
usage: colab_kernel_launcher.py [--help] [--hydra-help] [-- 
version] [--cfg {job,hydra,all}]
[--resolve] [--package PACKAGE] [-- 
run] [--multirun]
[--shell-completion] [--config-path 
CONFIG_PATH]
[--config-name CONFIG_NAME] [--config- 
dir CONFIG_DIR]
[--info 
[{all,config,defaults,defaults-tree,plugins,searchpath}]]
[overrides ...]
colab_kernel_launcher.py：错误：无法识别的参数：-f
发生异常，使用 %tb 查看完整回溯。
SystemExit：2
]]></description>
      <guid>https://stackoverflow.com/questions/78896800/problem-when-trying-to-load-the-config-of-hydra</guid>
      <pubDate>Wed, 21 Aug 2024 11:54:28 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多层感知器对 FFT 数据进行预处理以进行二元分类？[关闭]</title>
      <link>https://stackoverflow.com/questions/78892290/how-can-fft-data-be-pre-processed-for-binary-classification-using-multi-layer-pe</link>
      <description><![CDATA[我有 410 个 FFT 样本，我打算将它们输入到 MLP 中，以将数据分为两个（二进制）类别。我使用 PyTorch 在 Python 中构建了一个神经网络，该网络尝试对这些数据进行训练。但是，我获得的验证准确率仅达到 70%。
更改 MLP 的模型参数对最终准确率几乎没有影响，这让我相信问题出在初始数据处理上，尽管我可能是错的。
进一步研究这个问题后，我知道需要对数据进行预处理，以使其更易于训练，但我不明白如何预处理 FFT 数据。到目前为止，我已经根据最小值/最大值进行了标准化，并将数据设为零中心。
我查看了此处的帖子，但我的问题仍然存在。
编辑：
添加了 FFT 图像和代码片段
FFT 图像
model = nn.Sequential(OrderedDict([
(&#39;drop1&#39;, nn.Dropout(0.1)),
(&#39;dense1&#39;, nn.Linear(410, 100)),
(&#39;act1&#39;, nn.LeakyReLU()),
# (&#39;drop2&#39;, nn.Dropout(0.1)),
(&#39;drop4&#39;, nn.Dropout(0.2)),
(&#39;dense2&#39;, nn.Linear(100,25)),
(&#39;act2&#39;, nn.Sigmoid()),
(&#39;dense4&#39;, nn.Linear(25, 5)),
(&#39;act4&#39;, nn.LeakyReLU()),
(&#39;dense8&#39;, nn.Linear(5, 1)),
(&#39;act5&#39;, nn.Tanh()),
(&#39;dense5&#39;, nn.Linear(1, 1)),
(&#39;act8&#39;, nn.Sigmoid()),
]))
]]></description>
      <guid>https://stackoverflow.com/questions/78892290/how-can-fft-data-be-pre-processed-for-binary-classification-using-multi-layer-pe</guid>
      <pubDate>Tue, 20 Aug 2024 11:53:33 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试训练 TensorFlow 模型时，出现“ValueError”</title>
      <link>https://stackoverflow.com/questions/78881211/i-get-a-valueerror-when-i-try-to-train-my-tensorflow-model</link>
      <description><![CDATA[这是我在第一个 epoch 调用 model.fit 时遇到的错误：
发生异常：ValueError
层“ functional”需要 2 个输入，但它收到了 1 个输入张量。收到的输入：[&lt;tf.Tensor &#39;data:0&#39; shape=(None, 128) dtype=float32&gt;]
文件 &quot;D:\workspace\Machine Learning 545\PSU_classes\cs445_group_project\code\Keras Music Genres Classification\encoder_decoder_feature_extractor.py&quot;，第 177 行，位于 train_encoder_decoder_model
model.fit(x = X_train,
文件 &quot;D:\workspace\Machine Learning 545\PSU_classes\cs445_group_project\code\Keras Music Genres Classification\encoder_decoder_feature_extractor.py&quot;，第 217 行，位于 &lt;module&gt;
train_encoder_decoder_model = train_encoder_decoder_model(encoder_decoder_model, X_train, y_train, X_test, y_test)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: 层“ functional”需要 2 个输入，但收到 1 个输入张量。收到的输入：[&lt;tf.Tensor &#39;data:0&#39; shape=(None, 128) dtype=float32&gt;]&quot;

这是我的模型：
def define_encoder_decoder_model(num_features):
# 定义编码器
coder_inputs = 输入（shape=(None, num_features))
coder_hidden1 = Dense(100, 激活=&#39;relu&#39;)(encoder_inputs)
coder_hidden2 = Dense(50, 激活=&#39;relu&#39;)(encoder_hidden1)
coder_lstm = LSTM(25, return_state=True)
coder_outputs, state_h, state_c =coder_lstm(encoder_hidden2)
coder_states = [state_h, state_c]

# 定义解码器
decoder_inputs = 输入(shape=(None, 25))
decoder_hidden1 = Dense(50, 激活=&#39;relu&#39;)(decoder_inputs)
decoder_hidden2 = Dense(100, 激活=&#39;relu&#39;)(decoder_hidden1)
decoder_lstm = LSTM(num_features, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decrypt_lstm(decoder_hidden2, initial_state=encoder_states)
decoder_dense = Dense(num_features,activation=&#39;softmax&#39;)
decoder_outputs =coder_dense(decoder_outputs)

# 定义将encoder_inputs和decoder_inputs转换为decoder_outputs的模型
model = Model([encoder_inputs,decoder_inputs],decoder_outputs)

# 编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;,&#39;precision&#39;,&#39;recall&#39;,&#39;f1_score&#39;])

# 模型摘要
model.summary()

在此处返回modeltype

这是我调用model.fit的方式：
def train_encoder_decoder_model(model,X_train, y_train, X_test, y_test):
&quot;&quot;&quot;
使用提供的数据训练编码器-解码器模型。

参数：
model：要训练的编码器-解码器模型。
X_train：输入训练数据。
y_train：目标训练数据。
X_test：输入测试数据。
y_test：目标测试数据。

返回：
训练好的编码器-解码器模型。
&quot;&quot;&quot;
print(&quot;shapes: X_train:&quot;, np.shape(X_train),&quot; y_train: &quot;, np.shape(y_train),&quot; X_test: &quot;, np.shape(X_test),&quot; y_test: &quot;, np.shape(y_test))
# 训练模型
# 将每个时期的训练日志附加到文件中
file_logger = FileLogger(&#39;training.log&#39;)
y_train_T = tf.convert_to_tensor(np.array([y_train]).T)
y_test_T = tf.convert_to_tensor(np.array([y_test]).T)
#x_train = tf.convert_to_tensor(X_train)
y_train = X_train
y_test = X_test
model.fit(x = X_train,
y= y_train,
batch_size=100,
epochs=100,
verbose=2,
validation_data=(X_test, y_test),
callbacks=[file_logger])
返回模型

这是一个编码器-解码器模型，因此 X_train 数据集等于 y_train，X_test、y_test 也一样。在第一种情况下，训练集的形状为 (799,128)，测试数据集为 (299,128)。特征表示为“float64”值。
我在 Visual Studio Code 下运行代码。我将数据预处理为标准化和缩放的数据集，然后将其分为训练数据集和测试数据集，构建我的编码器-解码器模型（参见上面的方法），然后尝试训练模型。我得到的是 model.fit 的这个输出“Epoch 1/100”和上面显示的错误消息。
这个错误是什么以及如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78881211/i-get-a-valueerror-when-i-try-to-train-my-tensorflow-model</guid>
      <pubDate>Sat, 17 Aug 2024 01:20:22 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Matlab 中使用 knnsearch 设置 k 值</title>
      <link>https://stackoverflow.com/questions/78844904/how-to-set-k-value-using-knnsearch-in-matlab</link>
      <description><![CDATA[我有一个代码来对图像进行分类。
training1 = xlsread(&#39;Data Train&#39;);

% 提及训练数据矩阵在 excel 文件中的位置
training = [training1(:,1) training1(:,2) training1(:,3) training1(:,4) training1(:,5) training1(:,6) training1(:,7) training1(:,8) training1(:,9) training1(:,10) training1(:,11) training1(:,12) training1(:,13) training1(:,14) training1(:,15) training1(:,16) training1(:,17) training1(:,18) training1(:,19) training1(:,20) training1(:,21) training1(:,22) training1(:,23) training1(:,24)];

% 提及输入数据变量
Z=[MeanR MeanG MeanB MeanH MeanS MeanV VarRed VarGreen VarBlue VarH VarS VarV RangeR RangeG RangeB RangeH RangeS RangeV sdR sdG sdB sdH sdS sdV];

%执行 knn 分类
result = knnsearch(training,Z);

if (result&gt;=1 &amp;&amp; result&lt;=20)
set(handles.EditBox,&#39;string&#39;,&#39;Raw&#39;);
elseif (result&gt;=21 &amp;&amp; result&lt;=40)
set(handles.EditBox,&#39;string&#39;,&#39;Undercook&#39;);
elseif (result&gt;=41 &amp;&amp; result&lt;=60)
set(handles.EditBox,&#39;string&#39;,&#39;Cook&#39;);
elseif (result&gt;=61 &amp;&amp; result&lt;=80)
set(handles.EditBox,&#39;string&#39;,&#39;Rotten&#39;);
end

knnsearch 语法是否只默认 k 值为 1？
如何才能让 knnsearch 中的 k 值为 5？
当我尝试将其更改为
k = 5;
result = knnsearch(training,Z,&#39;K&#39;,k); 

系统不显示分类结果。]]></description>
      <guid>https://stackoverflow.com/questions/78844904/how-to-set-k-value-using-knnsearch-in-matlab</guid>
      <pubDate>Wed, 07 Aug 2024 17:01:04 GMT</pubDate>
    </item>
    <item>
      <title>检测群体中某个实例的行为变化（但不是整个群体）</title>
      <link>https://stackoverflow.com/questions/74706455/detecting-a-change-in-behavior-in-one-instance-of-a-group-but-not-the-group-as</link>
      <description><![CDATA[我一直在阅读有关时间序列数据中的异常检测的文章，并了解如何使用它来跟踪一段时间内的指标。
例如，假设我们想要跟踪一个人每天使用网站的次数（例如 John）。我们可以使用异常检测来检测 John 的数据何时大幅上升或下降。我们将使用的指标是“John 的网站每日点击量”和日期。
但是，假设我想对许多用户进行同样的检查，但他们都是独立的。该算法并不是试图找到用户活动之间的相关性，而只是在组中的一个用户的活动发生显著变化时提醒我们。所以假设 John 的活动在某一天异常高，我们会收到异常警报。
另一个例子是监控大量设备并检测一台设备何时每分钟发送异常高水平的请求。再次强调，目的不是检测所有发送更多请求的设备之间的相关性，而是提醒我们一个设备的行为与其正常模式不同。
我不确定这是否是正常的异常检测，因为看起来我必须为第一个示例中的每个用户构建一个模型来检测变化。对于少数用户来说，这可能是可行的，但似乎很难扩展到大量用户。
所以我想知道异常检测是否是正确的方法，或者是否存在我不知道的其他 AI 监控解决方案/工具？]]></description>
      <guid>https://stackoverflow.com/questions/74706455/detecting-a-change-in-behavior-in-one-instance-of-a-group-but-not-the-group-as</guid>
      <pubDate>Tue, 06 Dec 2022 17:06:14 GMT</pubDate>
    </item>
    <item>
      <title>如何减少图像异常检测中的假阴性？</title>
      <link>https://stackoverflow.com/questions/71160069/how-to-reduce-false-negatives-in-image-anomaly-detection</link>
      <description><![CDATA[我正在从事一个质量检查项目，我需要开发一个可以检测不规则部件的程序。我面临的问题是我没有很多不规则样本（3,000 多个常规样本中只有 7 个）。我尝试使用 CNN，但由于样本数量不平衡，模型将所有样本检测为常规样本，因此我正在探索的方法是使用异常检测算法。我也尝试使用自动编码器，但由于常规和不规则之间的差异很小，我无法获得任何好的结果。到目前为止，给我带来最佳结果的方法是将局部离群值因子与特征提取器 (HOG) 结合使用。这种方法唯一的问题是，即使在调整算法的参数后，它仍然会给我误报（正常样本被标记为不规则），这对于此应用来说是不可接受的。
我可以在流程中添加什么来消除误报吗？或者您可以推荐我其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/71160069/how-to-reduce-false-negatives-in-image-anomaly-detection</guid>
      <pubDate>Thu, 17 Feb 2022 14:32:38 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的 `stack()` 与 `cat()`</title>
      <link>https://stackoverflow.com/questions/54307225/stack-vs-cat-in-pytorch</link>
      <description><![CDATA[OpenAI 的强化学习 REINFORCE 和 actor-critic 示例有以下代码：
REINFORCE：
policy_loss = torch.cat(policy_loss).sum()

actor-critic：
loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()

一个使用torch.cat，另一个使用torch.stack，用于类似的用例。
据我所知，文档没有明确区分它们。
我很高兴知道这些函数之间的区别。]]></description>
      <guid>https://stackoverflow.com/questions/54307225/stack-vs-cat-in-pytorch</guid>
      <pubDate>Tue, 22 Jan 2019 11:24:47 GMT</pubDate>
    </item>
    </channel>
</rss>