<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Jan 2024 21:13:01 GMT</lastBuildDate>
    <item>
      <title>随机森林模型精度低[已迁移]</title>
      <link>https://stackoverflow.com/questions/77802745/low-accuracy-in-random-forest-model</link>
      <description><![CDATA[HCV.Egy.Data &lt;- read.csv(“~/Stat/Metaheuristic ML/hepatitis+c+virus+hcv+for+egyptian+患者/HCV-Egy-Data.csv”)
表（HCV.Egy.Data$Baselinehistological.staging）
HCV.Egy.Data$Baselinehistological.staging &lt;- as.factor(HCV.Egy.Data$Baselinehistological.staging)
库（“随机森林”）
库（caTools）
split &lt;-sample.split(HCV.Egy.Data, SplitRatio = 0.7)
分裂
训练 &lt;- 子集(HCV.Egy.Data, split == &quot;TRUE&quot;)
测试 &lt;- 子集(HCV.Egy.Data, split == &quot;FALSE&quot;)
set.seed(120) # 设置种子
classifier_RF = randomForest(x = train[,-c(28,29)],
                             y = train$Baselinehistological.staging,
                             ntree = 500，类型=“分类”）
classifier_RF$类
y_pred = 预测(classifier_RF, newdata = 测试[,-c(28,29)])
fusion_mtx = 表(测试[, 29], y_pred)
混淆_mtx

表(train[,29], classifier_RF$预测)

我的 ML 模型使用许多不同的 ML 方法（随机森林、XGboost、adaboost、LR 等），该模型的准确率较低 (20-30%)。这是运行上述代码的混淆矩阵：
&lt;前&gt;&lt;代码&gt; y_pred
     1 2 3 4
  1 13 22 36 38
  2 21 17 39 33
  3 15 20 38 27
  4 13 16 37 45

我们甚至应用了 SMOTE 和离散化步骤，将准确率提高到只有 33%。有谁知道为什么使用该数据集的论文的准确率在 70-95% 范围内？是不是明显缺少了什么？
例如，这是一篇论文：https://www.researchgate.net/profile/Md-Satu/publication/341987762_Predicting_Infectious_State_of_Hepatitis_​​C_Virus_Affected_Patient%27s_Applying_Machine_Learning_Methods/链接/ 5edcab8a45851529453fc609/预测丙型肝炎感染状态患者-应用机器学习方法.pdf
我们还应用了 8 次 SMOTE，但准确率仅提高到 33%。
这是数据集： https://archive.ics.uci.edu/dataset/503/hepatitis+c+virus+hcv+for+egyptian+患者如果您知道任何修复方法，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77802745/low-accuracy-in-random-forest-model</guid>
      <pubDate>Thu, 11 Jan 2024 20:05:57 GMT</pubDate>
    </item>
    <item>
      <title>使用模式识别、机器学习和清算数据预测资产价格走势[关闭]</title>
      <link>https://stackoverflow.com/questions/77801769/predicting-assests-price-moves-using-pattern-recognition-machine-learing-and-li</link>
      <description><![CDATA[我在加密货币市场进行交易，并使用电报机器人 https://t.me/BinanceLiquidations 进行提醒价格在哪里。机器人的每条消息都包含价格、时间、清算价值和红色（多头）或绿色（空头）。现在问题就在这里。几个月来我一直在观察数据，幸运的是发现了两种模式。此后，它激发了我的兴趣，即使用机器学习可以利用数据寻找模式来开发优势。]]></description>
      <guid>https://stackoverflow.com/questions/77801769/predicting-assests-price-moves-using-pattern-recognition-machine-learing-and-li</guid>
      <pubDate>Thu, 11 Jan 2024 16:49:00 GMT</pubDate>
    </item>
    <item>
      <title>训练随机森林花费的时间太长</title>
      <link>https://stackoverflow.com/questions/77801017/training-random-forest-taking-too-long</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77801017/training-random-forest-taking-too-long</guid>
      <pubDate>Thu, 11 Jan 2024 15:02:53 GMT</pubDate>
    </item>
    <item>
      <title>基于地理空间点数据约束的聚类[关闭]</title>
      <link>https://stackoverflow.com/questions/77800495/clustering-based-on-constraints-on-geospatial-point-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77800495/clustering-based-on-constraints-on-geospatial-point-data</guid>
      <pubDate>Thu, 11 Jan 2024 13:42:13 GMT</pubDate>
    </item>
    <item>
      <title>数据帧和多变量标签的嵌套目录上的多视图谱聚类</title>
      <link>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</guid>
      <pubDate>Thu, 11 Jan 2024 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到<class 'NoneType'> [关闭]</title>
      <link>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</link>
      <description><![CDATA[我正在尝试对我的数据运行深度学习代码；但是，由于输入数据中缺少数据集，我遇到了问题。如何解决这个问题？我正在努力解决下面给出的这个错误，下面还提供了输入链接。
python3 Validation2co.py
BP_benchmarkSet_2.csv
BP seqmodel 启动
序列模块（
  (seq_CNN): 顺序(
    (0): Conv1d(100, 64, kernel_size=(16,), stride=(1,), padding=(8,))
    (1): ReLU(原地=True)
    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv1d(64, 32, kernel_size=(16,), stride=(1,), padding=(8,))
    (4): ReLU(inplace=True)
    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv1d(32, 16, kernel_size=(16,), stride=(1,), padding=(8,))
    (7): ReLU(原地=True)
    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  ）
  （seq_FClayer）：线性（in_features = 3008，out_features = 1024，偏差= True）
  （seq_outlayer）：线性（in_features = 1024，out_features = 491，偏差= True）
）
batch_size_32，learning_rate_0.0001，epoch_time_30
selected_208964_ Protein_score.csv
selected_208964_ Protein_score.csv
警告：iprID Q9HTQ2 数据丢失。跳过...
警告：iprID Q9I559 数据丢失。跳过...
警告：iprID Q9HT21 数据丢失。跳过...
警告：iprID Q9I0Q1 数据丢失。跳过...
警告：iprID Q9HVI7 数据丢失。跳过...
警告：iprID Q9I422 数据丢失。跳过...
警告：iprID Q9I2V9 数据丢失。跳过...
警告：iprID Q9HWB6 数据丢失。跳过...
警告：iprID Q9HVT7 数据丢失。跳过...
警告：iprID Q9I3I5 数据丢失。跳过...
警告：iprID Q9I4C1 数据丢失。跳过...
警告：iprID Q9I5K0 数据丢失。跳过...
警告：iprID P26995 数据丢失。跳过...
警告：iprID Q9I1Y7 数据丢失。跳过...
警告：iprID Q9I316 数据丢失。跳过...
警告：iprID Q9I299 数据丢失。跳过...
警告：iprID Q9I2Q4 数据丢失。跳过...
警告：iprID Q9HT20 数据丢失。跳过...
警告：iprID Q9HV34 数据丢失。跳过...
警告：iprID Q9HX99 数据丢失。跳过...
警告：iprID Q9HZK1 数据丢失。跳过...
警告：iprID Q9HXG5 数据丢失。跳过...
警告：iprID Q9I3F5 数据丢失。跳过...
警告：iprID Q9HV44 数据丢失。跳过...
警告：iprID Q9HY92 数据丢失。跳过...
警告：iprID Q9HVX9 数据丢失。跳过...
警告：iprID Q9I6Z3 数据丢失。跳过...
警告：iprID Q9HU16 数据丢失。跳过...
警告：iprID Q9HYL8 数据丢失。跳过...
警告：iprID Q9HI37 数据丢失。跳过...
警告：iprID Q9I1Y4 数据丢失。跳过...
警告：iprID Q9HW04 数据丢失。跳过...
回溯（最近一次调用最后一次）：
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 990 行，在  中。
    验证（条款[0], 5）
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 972 行，验证中
    每个_fold_scores = Main(train_set, test_set, func=func)
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 831 行，位于 Main 中
    seq_train_out, seq_test_out, seq_t = Seq_train(0.0001, 16, train_benchmark, test_benchmark, 30, func) # 15
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 408 行，Seq_train
    对于batch_idx，枚举（train_data_loader）中的（seqMatrix，domainStence，ppiVect，GO_annotiations）：
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 681 行，位于 __next__
    数据 = self._next_data()
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 721 行，位于 _next_data
    data = self._dataset_fetcher.fetch(index) # 可能会引发 StopIteration
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py​​”，第 52 行，在 fetch 中
    返回 self.collat​​e_fn(数据)
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/collat​​e.py”，第 183 行，在 default_collat​​e 中
    引发 TypeError(default_collat​​e_err_msg_format.format(elem_type))
**类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到**
]]></description>
      <guid>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</guid>
      <pubDate>Thu, 11 Jan 2024 04:55:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用离群数据来训练随机森林回归以用于填充其他缺失数据</title>
      <link>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</link>
      <description><![CDATA[dataAgeNull = data[data[“年龄”].isnull()]
dataAgeNotNull = data[data[“年龄”].notnull()]
remove_outlier = dataAgeNotNull[(np.abs(dataAgeNotNull[“票价”]-dataAgeNotNull[“票价”].mean())&gt;(4*dataAgeNotNull[“票价”].std()))|
                      (np.abs(dataAgeNotNull[“Family_Size”]-dataAgeNotNull[“Family_Size”].mean())&gt;(4*dataAgeNotNull[“Family_Size”].std()))
                     ]
rfModel_age = RandomForestRegressor(n_estimators=2000,random_state=42)
ageColumns = [&#39;出发&#39;, &#39;票价&#39;, &#39;舱位等级&#39;, &#39;性别&#39;, &#39;家庭人数&#39;, &#39;标题1&#39;, &#39;标题2&#39;,&#39;客舱&#39;,&#39;机票信息&#39;]
rfModel_age.fit(remove_outlier[ageColumns], remove_outlier[“年龄”])

ageNullValues = rfModel_age.predict(X= dataAgeNull[ageColumns])
dataAgeNull.loc[:,&quot;年龄&quot;] = AgeNullValues
数据 = dataAgeNull.append(dataAgeNotNull)
data.reset_index(inplace=True, drop=True)

为什么我们使用“票价”的离群数据和“family_size”训练 RandomForestRegressor 来填充“年龄”的缺失数据？
我试图理解这段代码，但仍然无法弄清楚
4]]></description>
      <guid>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</guid>
      <pubDate>Thu, 11 Jan 2024 03:58:16 GMT</pubDate>
    </item>
    <item>
      <title>回归任务中日志转换后的指标解释问题</title>
      <link>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</link>
      <description><![CDATA[我目前正在研究房价预测任务，由于目标变量（价格）的非正态分布，我对它进行了对数转换。我使用 RMSE、MAE 和 MAPE 等指标，并且对于模型训练，我使用了 cross_val_score。
获得预测后，我采用 MAE 和 MAPE 指标的指数将其恢复到原始规模。然而，我遇到了意想不到的小值；两个指标都等于 1。我怀疑这些值不正确。
kf = KFold(n_splits=5, random_state=42, shuffle=True)

def rmse_cv（模型）：
    mse_scorer = make_scorer(mean_squared_error)
    rmse = np.sqrt(cross_val_score(模型, 训练, y_train, 评分=mse_scorer, cv=kf))
    返回均方根误差

def mae_cv（模型）：
    mae_scorer = make_scorer(mean_absolute_error)
    mae = cross_val_score(模型, 训练, y_train, 评分=mae_scorer, cv=kf)
    返回梅

def mape_cv（模型）：
    mape_scorer = make_scorer(mean_absolute_percentage_error)
    mape = cross_val_score(模型, 训练, y_train, 评分=mape_scorer, cv=kf)
    返回马普

lightgbm = LGBMRegressor(num_leaves=6, max_depth=7, random_state=42, n_estimators=500, Objective=&#39;回归&#39;)

rmse = rmse_cv(lightgbm)
mae = mae_cv(lightgbm)
映射 = 映射_cv(lightgbm)
print(&#39;Lightgbm rmse %.4f&#39; % (rmse.mean()))
print(&#39;Lightgbm mae %.4f&#39; % (mae.mean()))
print(&#39;Lightgbm mape %.4f&#39; % (mape.mean()))

Lightgbm rmse 0.1331
Lightgbm mae 0.0874
Lightgbm 映射 0.0073

我希望获得合理且可解释的值，以反映模型在原始规模上的性能。然而，这两个指标都得出了意想不到的小值 1，这似乎不准确。我期望在原始价格范围内能够更有意义地表示模型误差。]]></description>
      <guid>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</guid>
      <pubDate>Thu, 11 Jan 2024 03:13:07 GMT</pubDate>
    </item>
    <item>
      <title>考虑到 3D CNN 的挑战和预训练 VideoMAE 模型的内存问题，对震颤强度进行分类的有效方法是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77794520/what-are-efficient-methods-for-classifying-tremor-intensity-given-challenges-wi</link>
      <description><![CDATA[我有一个包含 80 个视频的训练数据集（没有增强）。它们是以 30fps 和 240*480 尺寸录制的 15 秒视频。训练分类模型有哪些选择？问题陈述是我有颤抖者的视频。我想按照 1 - 3 的等级对震颤的强度进行分类。请建议一些处理此问题的方法
我尝试过使用 3D CNN，但它需要过多的计算能力。我还尝试通过微调 Huggingface 中的预训练 VideoMAE 模型来训练模型，但它只接受 16 帧而不是 450 帧（15s * 30fps）。我尝试更改拱门，但它给了我内存错误。]]></description>
      <guid>https://stackoverflow.com/questions/77794520/what-are-efficient-methods-for-classifying-tremor-intensity-given-challenges-wi</guid>
      <pubDate>Wed, 10 Jan 2024 15:31:50 GMT</pubDate>
    </item>
    <item>
      <title>Handritten 数字识别算法前向传播中的矩阵乘法效率低下</title>
      <link>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</link>
      <description><![CDATA[我正在用 python 编写手写数字识别神经网络算法，而不使用预先编写的 ML 库。我目前正在尝试实现一个 DenseLayer 类，并在其中实现一个前向传播函数。我当前的功能如下所示。
类 DenseLayer：
  ...
  
  ...
  def for_prop(自身, input_data):
    self.input = input_data

    transpose_weights = self.weights.T
    # matMulComponent = np.matmul(input_data, transpose_weights)
    print(f&quot;转置形状：{transpose_weights.shape} 和输入形状 {input_data.shape}&quot;)
    matMulComponent = input_data.T @ transpose_weights
    打印（len（matMulComponent））

    z = matMulComponent + self.biases.T
    f_wb = self.act_fun(z)
    
    

    self.output = f_wb.reshape(-1, 1)
    print(f&quot;形状结果：{self.output.shape}&quot;)
    返回自身输出

问题是我正在进行大量的重塑和转置以获得结果。这似乎效率不高。
所以我的问题是：

这个实施起来好吗（因此会导致效率低下）
有没有更好的方法来实现这个前向传播函数

这就是我的输入数据数组的样子（我刚刚打印它并采取了 ss）。我供参考的输入数据是一个扁平的 28*28 数组，每个单元格代表一种颜色。我首先对数据进行标准化（z 分数标准化）
输入数据图像
如果有帮助的话，我还截取了第一层的权重格式的屏幕截图。 （请记住，它在 for_prop 函数中使用之前已被转置）。
第一个隐藏层的权重矩阵图片
前向传播似乎确实有效，但这很好：前向传播进度 ]]></description>
      <guid>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</guid>
      <pubDate>Wed, 10 Jan 2024 04:20:06 GMT</pubDate>
    </item>
    <item>
      <title>scikit 的 RFECV 类如何计算 cv_results_？</title>
      <link>https://stackoverflow.com/questions/77788410/how-does-scikits-rfecv-class-compute-cv-results</link>
      <description><![CDATA[我对递归特征消除交叉验证的理解： (sklearn.feature_selection.RFECV) 您提供一种算法，该算法在整个数据集上进行训练并创建特征重要性排名使用属性 coef_ 或 feature_importances_。现在包含了所有功能，该算法通过交叉验证进行评估。然后，删除排名底部的特征，并在数据集上重新训练模型并创建新的排名，再次通过交叉验证进行评估。这一过程将持续下去，直到只剩下一个特征（或由 min_features_to_select 指定），并且最终选择的特征数量取决于产生最高 CV 分数的特征。 （来源)
问题：每个特征数量的 CV 分数存储在 rfecv.cv_results_[“mean_test_score”] 中，我在尝试复制时遇到了麻烦这些分数无需使用 scikit 的内置方法。
这是我试图获得 n-1 个特征的分数，其中 n 是特征总数。
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.model_selection 导入 StratifiedKFold
从 sklearn.model_selection 导入 cross_validate
从 sklearn.feature_selection 导入 RFECV

alg = DecisionTreeClassifier(random_state = 0)
cv_split = 分层KFold(5)
# train 是 pandas 数据框，x_var 和 y_var 都是包含变量字符串的列表
X = 火车[x_var]
y = np.ravel(train[y_var])

alg.fit(X, y)
最低排名特征 = np.argmin(alg.feature_importances_)
x_var.pop(最低排名特征)

one_removed_feature = 火车[x_var]
alg.fit(one_removed_feature, y)
cv_score = cross_validate(alg, one_removed_feature, y, cv=cv_split, 评分=“准确度”)
np.mean(cv_score[“test_score”])

这是提供不同分数的内置方法：
&lt;前&gt;&lt;代码&gt;rfecv = RFECV(
    估计量=alg,
    步骤=1，
    CV=CV_分裂，
    评分=“准确度”，
）

rfecv.fit(X, y)
rfecv.cv_results_[“mean_test_score”][-2]

如何获得内置方法中计算出的准确分数？
我还想提一下，我确实首先尝试了所有 n 个功能，并且我的方法与
rfecv.cv_results_[“mean_test_score”][-1]。]]></description>
      <guid>https://stackoverflow.com/questions/77788410/how-does-scikits-rfecv-class-compute-cv-results</guid>
      <pubDate>Tue, 09 Jan 2024 16:47:46 GMT</pubDate>
    </item>
    <item>
      <title>在 WSL conda 环境中安装 lightgbm GPU</title>
      <link>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</link>
      <description><![CDATA[--------------------原来的问题------------------------- --------
如何安装LightGBM？
我检查了多个来源，但仍然无法安装。
我尝试了 pip 和 conda 但都返回错误：
[LightGBM] [警告] 目前不支持在 CUDA 中使用稀疏特征。
[LightGBM] [致命] 此版本中未启用 CUDA Tree Learner。
请使用 CMake 选项 -DUSE_CUDA=1 重新编译

我尝试过的内容如下：
git clone --recursive https://github.com/microsoft/LightGBM
cd LightGBM/
mkdir -p 构建
光盘构建
cmake -DUSE_GPU=1 ..
使-j$(nproc)
cd ../python-package
点安装。

-------------------- 下面是我的解决方案（cuda）--------------------- ------------
谢谢各位的回复。我尝试了一些方法，最终效果如下：
首先，确保已安装 cmake（在 wsl 下）：
sudo apt-get update
sudo apt-get 安装 cmake
须藤 apt-get 安装 g++

那么，
git clone --recursive https://github.com/microsoft/LightGBM
cd光GBM
mkdir 构建
光盘构建
cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..
使-j4

目前，安装尚未链接到任何 conda env。为此，在 vscode 终端（或仍然是 wsl）下，conda 激活一个 env，然后创建一个 jupyter 笔记本进行测试：
确保lib_lightgbm.so位于LightGBM/python-package下，如果没有，则复制到该文件夹​​中。
然后在jupyter笔记本中：
导入系统
将 numpy 导入为 np
sys.path.append(&#39;/mnt/d/lgm-test2/LightGBM/python-package&#39;)
将 lightgbm 导入为 lgb

最后一点是，您可以参考 Jame 的回复，设备需要设置为“cuda”而不是“gpu”。]]></description>
      <guid>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</guid>
      <pubDate>Thu, 28 Dec 2023 17:34:48 GMT</pubDate>
    </item>
    <item>
      <title>媒体管道是否与深脸一起使用进行人脸识别以获得更好的准确性</title>
      <link>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</link>
      <description><![CDATA[我使用深脸进行识别，但准确性不好，所以我尝试实现媒体管道，在​​其中提取地标，因此我将其交给深脸以获得更好的准确性。有什么办法可以做到这一点吗？
我从媒体管道中提取特征向量，但如何将其传递到深层脸部？有什么可行的方法吗？
是否使用媒体管道地标进行深度人脸识别以提高准确性？]]></description>
      <guid>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</guid>
      <pubDate>Thu, 28 Dec 2023 09:38:05 GMT</pubDate>
    </item>
    <item>
      <title>如何正确缩放、训练和拟合分类器管道中的数据</title>
      <link>https://stackoverflow.com/questions/74258306/how-to-scale-train-and-fit-data-in-classifier-pipeline-correctly</link>
      <description><![CDATA[我正在尝试扩展我的数据并训练分类器。我当前的数据框如下所示：
col1 col2 col3 类别
---- ---- ---- --------
....

我对分类器管道中的 StandardScaler 如何影响我的数据感到困惑。这是我的主要问题：

Scaler 也会缩放 Y_train 吗？这在机器学习的背景下真的很重要吗？
缩放器会在预测期间自动缩放 X_test 吗？如果没有，我该如何使用之前计算的指标来做到这一点？
我是否遗漏了缩放和拆分方面的一些基本内容？

这些文档有点含糊，所以希望有人能澄清这一点。非常感谢！
目前，我的管道如下所示：
分类器 = Pipeline(steps=[(“scaler”, StandardScaler()), (&#39;svc&#39;, SVC(kernel=“线性”, C=c))])

features = data.loc[:, data.columns != &#39;类别&#39;]
类别 = 数据[&#39;类别&#39;]

X_train, X_test, Y_train, Y_test = train_test_split(特征, 类别, train_size=0.7)

分类器.fit(X_train, Y_train)

分类器.预测(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/74258306/how-to-scale-train-and-fit-data-in-classifier-pipeline-correctly</guid>
      <pubDate>Mon, 31 Oct 2022 02:49:27 GMT</pubDate>
    </item>
    <item>
      <title>在计算测试数据的准确性时遇到此错误</title>
      <link>https://stackoverflow.com/questions/73498671/encountered-this-error-when-calculating-the-accuracy-on-a-test-data</link>
      <description><![CDATA[我是机器学习新手，在计算和返回测试数据的准确性时遇到此错误
def NBAaccuracy(features_train, labels_train, features_test, labels_test):
    ”“”计算朴素贝叶斯分类器“”的准确性
    ### 导入 GaussianNB 的 sklearn 模块
    从 sklearn.naive_bayes 导入 GaussianNB

    ### 创建分类器
    clf = GaussianNB() #TODO

    ### 将分类器拟合到训练特征和标签上
    clf.fit(features_train, labels_train, features_test, labels_test) #TODO

    ### 使用经过训练的分类器来预测测试特征的标签
    pred = clf.predict(features_test, labels_test) #TODO

    ### 计算并返回测试数据的准确性
    ### 这与示例略有不同，
    ### 我们只打印准确性
    ### 你可能需要导入 sklearn 模块
    从 sklearn.metrics 导入 precision_score
    准确度=准确度_分数（features_test，labels_test，normalize = False）#TODO
    返回精度
    返回NBA准确率

我收到此错误：
&lt;块引用&gt;
类型错误：fit() 最多接受 4 个参数（给定 5 个）
]]></description>
      <guid>https://stackoverflow.com/questions/73498671/encountered-this-error-when-calculating-the-accuracy-on-a-test-data</guid>
      <pubDate>Fri, 26 Aug 2022 09:10:51 GMT</pubDate>
    </item>
    </channel>
</rss>