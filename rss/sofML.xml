<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 02 Jan 2024 21:12:29 GMT</lastBuildDate>
    <item>
      <title>sklearn 线性回归 特征名称应与拟合期间传递的特征名称相匹配</title>
      <link>https://stackoverflow.com/questions/77748547/sklearn-linear-regression-the-feature-names-should-match-those-that-were-passed</link>
      <description><![CDATA[我尝试使用 sklearn 线性回归创建模型后计算 r 平方值。
我只是简单

导入 csv 数据集
过滤感兴趣的列
在训练和测试中拆分数据集
创建模型
对测试进行预测
计算 r 平方以了解模型与测试数据集的拟合程度

数据集取自 https://www.kaggle.com/datasets/jeremylarcher/american-house-prices-and-demographics-of-top-cities
代码如下
&#39;&#39;&#39;让我们验证一下价格和浴室床位数量之间是否存在相关性&#39;&#39;&#39;

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression

df = pd.read_csv(&#39;数据/American_Housing_Data_20231209.csv&#39;)

df_interesting_columns = df[[&#39;床&#39;, &#39;浴室&#39;, &#39;价格&#39;]]

Independent_variables = df_interesting_columns[[&#39;床&#39;, &#39;浴室&#39;]]
dependent_variable = df_interesting_columns[[&#39;价格&#39;]]

X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, test_size=0.2)

模型=线性回归()
model.fit(X_train, y_train)

预测 = model.predict(X_test)

print(model.score(y_test, 预测))

但我收到错误
ValueError：特征名称应与拟合期间传递的名称相匹配。
在拟合时看不到的特征名称：

价格
在适合时看到的功能名称，但现在丢失了：
浴室
床位

有人可以帮我理解我做错了什么吗？
谢谢，我希望能正确解释]]></description>
      <guid>https://stackoverflow.com/questions/77748547/sklearn-linear-regression-the-feature-names-should-match-those-that-were-passed</guid>
      <pubDate>Tue, 02 Jan 2024 21:01:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 clean-python 中的 AI 没有按预期学习？</title>
      <link>https://stackoverflow.com/questions/77748132/why-is-my-ai-in-neat-python-not-learning-as-expected</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77748132/why-is-my-ai-in-neat-python-not-learning-as-expected</guid>
      <pubDate>Tue, 02 Jan 2024 19:21:07 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv8多类实例分割</title>
      <link>https://stackoverflow.com/questions/77747887/yolov8-instance-segmentation-of-multiple-classes</link>
      <description><![CDATA[我正在寻求有关 YOLOv8 中多类实例分割的帮助。我已经用 Detectron2 完成了这个任务，想要进行比较。在 Detectron2 中，我需要获取包含图像、蒙版和注释文本文件的文件夹，我在其中指定了边界框和相应的标签（鸟类物种）。但也许这对于 YOLOv8 是不可能的？ Detectron2 的注释如下所示：
图像文件名：“img2.png” # img2.png 是包含形状的二值掩模图像
图像尺寸（X x Y）：824 x 824
具有基本事实的对象：3

# 对象 1 的详细信息
对象1的原始标签：“物种1”
对象 1 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(0, 733) - (9, 751)
对象 1 的像素蒙版：“mask2.png”

# 对象 2 的详细信息
对象2的原始标签：“物种2”
对象 2 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(93, 664) - (143, 684)
对象 2 的像素蒙版：“mask2.png”

# 对象 3 的详细信息
对象3的原始标签：“物种1”
对象 3 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(39, 621) - (60, 667)
对象 3 的像素蒙版：“mask2.png”

实际上 YOLOv8 实例分割的所有教程都集中在一个类上。此外，他们经常专注于使用 Roboflow 进行标签，这对我来说并不有趣，因为我从已有的 ESRI shapefile 转换标签。我使用来自无人机图像的 shapefile 和鸟类光栅，将来自 shapefile 的二进制蒙版的标签转换为标签。我找到了一个教程，它实际上专注于创建标签没有口罩，但仍然只有一节课。使用它，我创建了另一个文件夹“标签”，在其中创建包含对象坐标的文本文件。利用这个，我可以成功地使用一个分割鸟类的模型。 YOLOv8 的标签现在看起来像这样：
&lt;预&gt;&lt;代码&gt;0 0.16019417475728157 0.8058252427184466 0.15898058252427186 0.8070388349514563 0.1529126213592233 0.8070388349514563 ... 0.1650485436893204 0.8070388349514563 0.1638349514563107 0.8070388349514563 0.16262135922330098 0.8058252427184466

0 0.055825242718446605 0.7536407766990292 0.055825242718446605 0.7560679611650486 0.05461165048543689 0.7572815533980582 ... 0 .06067961165048544 0.7536407766990292
0 0.09951456310679611 0.6747572815533981 0.09951456310679611 0.6759708737864077

0.09587378640776699 0.6796116504854369 0.09587378640776699 0.6808252427184466 0.09344660194174757 0.683252427184466 ... 0.1031 5533980582524 0.6771844660194175 0.10194174757281553 0.6759708737864077 0.10072815533980582 0.6759708737864077

但我因此想要更多。我知道如何在配置文件中指定类的数量及其名称。但是，我不确定如何在标签文本文件中指定类。从我在网上找到的内容来看，它们只包含像素坐标。另外，如果我已经有了二进制掩码和边界框注释，我想知道是否有更有效的方法来为 30,000 多个图像创建标签。作为参考，每张图像通常有多种鸟类，并且图像中也可能有不同的鸟类种类。
如何使用YOLOv8实现多类实例分割？]]></description>
      <guid>https://stackoverflow.com/questions/77747887/yolov8-instance-segmentation-of-multiple-classes</guid>
      <pubDate>Tue, 02 Jan 2024 18:23:27 GMT</pubDate>
    </item>
    <item>
      <title>嵌套 CV 循环中的 Optuna 超参数优化建议相同的超参数</title>
      <link>https://stackoverflow.com/questions/77747720/optuna-hyperparameter-optimization-in-a-nested-cv-loop-suggests-identical-hyperp</link>
      <description><![CDATA[我正在执行嵌套 CV，Optuna 在内循环中运行，然后根据外循环的剩余数据评估最佳模型。
但是，Optuna 建议所有 CV 分割使用相同的参数，尽管数据不同。
&lt;前&gt;&lt;代码&gt;i = 0
研究 = {}
    
对于outer_cv.split(x, y)中的outer_train_index、outer_test_index：
        
    x_train_outer, x_test_outer = x.iloc[outer_train_index, :], x.iloc[outer_test_index, :]
    y_train_outer, y_test_outer = y.iloc[outer_train_index], y.iloc[outer_test_index]
        
    我 += 1
    研究[i] = optuna.create_study（方向=&#39;最大化&#39;，study_name=i）
    研究[i].optimize（lambda试验：目标（试验，[...]，x_train_outer，y_train_outer），n_Trials = 500）

    best_params = 研究[i].best_params
    model.set_params(**best_params)
    best_models.append(模型)

    [...]

best_models 返回具有相同模型的列表。
这是我的目标函数：
def 目标（试验，[...]，分类器，x，y）：
    
    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)
    classifier_obj = 分类器（试用）
    
    分数 = cross_validate(
        估计器=classifier_obj，
        X=x,
        y=y,
        简历=内部简历，
        评分=mcc_scorer，
        n_职位=-1
    ）
    
    返回分数[&#39;test_score&#39;].mean()
]]></description>
      <guid>https://stackoverflow.com/questions/77747720/optuna-hyperparameter-optimization-in-a-nested-cv-loop-suggests-identical-hyperp</guid>
      <pubDate>Tue, 02 Jan 2024 17:40:54 GMT</pubDate>
    </item>
    <item>
      <title>将 pdf 转换为图像进行处理时出现错误索引超出范围</title>
      <link>https://stackoverflow.com/questions/77747660/error-index-out-of-range-converting-pdf-to-image-for-processing-it</link>
      <description><![CDATA[将结果转换为可下标时遇到问题？
将 PDF 转换为图像时出错：“结果”对象不可下标。
我还尝试了不同的库，例如 PDF2IMG，但它在处理过程中陷入困境，您建议对此进行最佳编辑吗？我正在尝试将 pdf 转换为图像，然后对其进行处理并获取基于聊天的查询答案类型。
错误：
&lt;前&gt;&lt;代码&gt;回溯：
文件“C:\Users\arbaz\Documents\MultiLangModel\venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py”，第 534 行，位于 _run_script
    exec（代码，模块.__dict__）
文件“C:\Users\arbaz\Documents\MultiLangModel\app2.py”，第 54 行，在  中
    响应2 = get_gemini_response_from_pdf(input_prompt2, pdf_images, input2)^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\arbaz\Documents\MultiLangModel\app2.py”，第 14 行，位于 get_gemini_response_from_pdf
    response2 = model2.generate_content([input_prompt, pdf_images[0], input2])~~~~~~~~~~

代码：
from dotenv import load_dotenv
将streamlit导入为st
从 PIL 导入图像
将 google.generativeai 导入为 genai
导入convertapi
导入操作系统
导入io
导入临时文件

Convertapi.api_secret = &#39;密钥&#39;
genai.configure(api_key=&#39;秘密密钥&#39;)
def get_gemini_response_from_pdf(input_prompt, pdf_images, input2):
    model2 = genai.GenerativeModel(&#39;gemini-pro-version&#39;)
    响应2 = model2.generate_content([input_prompt, pdf_images[0], input2])
    返回response2.text

def Convert_pdf_to_images(上传文件):
    尝试：
        temp_file = f“tmp{uploaded_file.name}”
        以 open(temp_file, &#39;wb&#39;) 作为文件：
            文件.write(uploaded_file.read())

        结果 = Convertapi.convert(&#39;jpg&#39;, {&#39;文件&#39;: temp_file}, from_format=&#39;pdf&#39;)
        if result[&#39;response&#39;][&#39;status&#39;] == &#39;Ok&#39;:
            返回结果[&#39;文件&#39;]
        别的：
            st.write(f&quot;转换失败: {result[&#39;response&#39;][&#39;message&#39;]}&quot;)
            返回 []
    除了异常 e：
        st.write(f“将 PDF 转换为图像时出错：{e}”)
        返回 []

st.set_page_config(page_title=&quot;使用人工智能的文档阅读器&quot;)
st.header(“这是我使用人工智能的文档阅读器”)

input_prompt2 = “””
               您是理解护照、银行对账单和资产金融投资等文件的专家。
               您将收到护照、银行对账单、发票以及资产和金融投资的输入 pdf 文件。
               您必须根据输入图像回答问题
               ”“”
input2 = st.text_input(&quot;PDF文档输入提示：&quot;, key=&quot;input2&quot;)
uploaded_file2 = st.file_uploader(&quot;上传 PDF 文件&quot;, type=&quot;pdf&quot;)
pdf_图像 = []

如果 uploaded_file2 不是 None：
    pdf_images = 转换 pdf_to_images(uploaded_file2)
    对于 pdf_images 中的 img_data：
        img_bytes = img_data[&#39;数据&#39;]
        图像 = Image.open(io.BytesIO(img_bytes))
        st.image(图像, 标题=“转换后的图像”, use_column_width=True)
    
    Submit_pdf = st.button(“生成 Pdf 响应”)
    如果提交_pdf：
        响应2 = get_gemini_response_from_pdf(input_prompt2, pdf_images, input2)
        st.subheader(“响应是”)
        st.write(响应2)

我正在尝试将 pdf 转换为图像，然后对其进行处理并获取基于聊天的查询答案。
尝试了多个库，例如 pdf2img 和其他逻辑]]></description>
      <guid>https://stackoverflow.com/questions/77747660/error-index-out-of-range-converting-pdf-to-image-for-processing-it</guid>
      <pubDate>Tue, 02 Jan 2024 17:28:36 GMT</pubDate>
    </item>
    <item>
      <title>“在微控制器上部署边缘脉冲训练车辆检测和颜色分类模型”</title>
      <link>https://stackoverflow.com/questions/77747578/deploying-edge-impulse-trained-vehicle-detection-and-color-classification-model</link>
      <description><![CDATA[我们目前正在启动一个项目，重点是使用 Edge Impulse 进行车辆检测和颜色分类。我们的目标是在 Edge Impulse 平台中训练我们的图像数据集，然后将模型部署到微控制器上。我们正在寻找的微控制器应该既与 Edge Impulse 兼容，又具有成本效益，能够实现数据的实时分类。
我们主要关注的是了解在微控制器上部署 Edge Impulse 训练模型的可行性和兼容性。我们的最终目标是无缝集成模型，使微控制器能够准确地对实时数据进行分类。
任何有关适合此目的的经济高效的微控制器的指导或建议都非常有价值。
如果在微控制器上部署被证明是不切实际的，我们将不胜感激有关符合我们目标的替代方法的建议。
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/77747578/deploying-edge-impulse-trained-vehicle-detection-and-color-classification-model</guid>
      <pubDate>Tue, 02 Jan 2024 17:09:06 GMT</pubDate>
    </item>
    <item>
      <title>图像处理——如何检测此类图像[关闭]</title>
      <link>https://stackoverflow.com/questions/77747526/image-processing-how-to-detect-this-type-of-images</link>
      <description><![CDATA[在此处输入图片描述
我有一个护照尺寸图像的数据集，必须对其进行验证。但我无法了解如何检测这种类型的图像，因为这对我来说是无效的。
图像应完全拟合才能认为有效，否则无效。
请参考附件中的图片并帮助我。
我已经尝试了各种方法，但仍然无法获得所需的输出。请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/77747526/image-processing-how-to-detect-this-type-of-images</guid>
      <pubDate>Tue, 02 Jan 2024 17:00:35 GMT</pubDate>
    </item>
    <item>
      <title>TimeoutError：处理报价和初始化工作人员尚未在 10.0 秒内完成[关闭]</title>
      <link>https://stackoverflow.com/questions/77747419/timeouterror-processing-offer-and-initializing-the-worker-has-not-finished-in-1</link>
      <description><![CDATA[(https://i.stack.imgur.com/OGVax.png
我在渲染上部署了我的机器学习 Web 应用程序，它引发了这个问题。
然而它在本地主机上工作得很好
有什么解决办法吗？
我尝试查找各种​​网站，但找不到出路。请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/77747419/timeouterror-processing-offer-and-initializing-the-worker-has-not-finished-in-1</guid>
      <pubDate>Tue, 02 Jan 2024 16:36:18 GMT</pubDate>
    </item>
    <item>
      <title>1 个 epoch 后，训练损失显着下降</title>
      <link>https://stackoverflow.com/questions/77747020/after-1-epoch-the-training-loss-dramatically-down</link>
      <description><![CDATA[在此处输入图像描述
您好，我是一名学习股票预测深度学习的学生。
我对学习损失曲线有疑问。
当我运行模型时，一个时期后，训练损失急剧下降，我不明白为什么。
这个模型不是我创建的；相反，我从 GitHub 上 AAAI（人工智能促进协会）接受的代码中获取了它。 （股票预测模型）
代码已经包含了 dropout 和标准化，但我不明白为什么会发生这种情况。
此外，不仅一个数据集会出现此问题，其他数据集（SP、CSI、NDQ 和 NI）也会出现此问题。
*培训：8 年，验证：1 年，测试：2 年
如果您对发生这种情况的原因有任何建议，请分享，我会非常高兴。
非常感谢:)
我希望模型不会过度拟合，因为该模型已被顶级会议接受，并且除了按照说明进行操作外，我没有尝试过任何其他操作。
虽然这个模型没有提供具体数据，但我使用了一般股票数据作为模型的输入。
*代码模型
HGAT 类（torch.nn.Module）：
def __init__(self, 代码):
    超级（HGAT，自我）.__init__()
    self.tickers = 代码
    self.grup = gru(5,32) #或 lstm
    self.attention = 注意(32)
    self.hatt1 = nn.HypergraphConv(32, 32, use_attention=True, Heads=4, concat=False, negative_slope=0.2, dropout=0.5, 偏差=True)
    self.hatt2 = nn.HypergraphConv(32, 32, use_attention=True, Heads=1, concat=False, negative_slope=0.2, dropout=0.5, 偏差=True)
    self.liear = torch.nn.Linear(32,1)
defforward(self,price_input,e):
    上下文，查询 = self.grup(price_input)
    查询 = 查询.reshape(1026,1,32)
    输出，权重= self.attention（查询，上下文）
    输出 = 输出.reshape((1026,32))
    x = F.leaky_relu(self.hatt1(输出,e), 0.2)
    x = F.leaky_relu(self.hatt2(x,e), 0.2)
    返回 F.leaky_relu(self.liear(x))

-很抱歉没有上传代码]]></description>
      <guid>https://stackoverflow.com/questions/77747020/after-1-epoch-the-training-loss-dramatically-down</guid>
      <pubDate>Tue, 02 Jan 2024 15:31:25 GMT</pubDate>
    </item>
    <item>
      <title>加载屏幕停留在“Building editable for Judgelm (pyproject.toml) ... /”</title>
      <link>https://stackoverflow.com/questions/77746734/loading-screen-stays-on-building-editable-for-judgelm-pyproject-toml</link>
      <description><![CDATA[我试图通过 GitHub 将 LLM 模型安装到我的电脑上，在 anaconda 命令 shell 上安装软件包时，加载屏幕很长一段时间没有改变。而且我也没有收到任何错误。
我读到pip升级可能会导致这种情况。然后我升级了 pip 但这个屏幕仍然保持在同一行。 文本
您可以通过此链接查看LLM模型。]]></description>
      <guid>https://stackoverflow.com/questions/77746734/loading-screen-stays-on-building-editable-for-judgelm-pyproject-toml</guid>
      <pubDate>Tue, 02 Jan 2024 14:39:07 GMT</pubDate>
    </item>
    <item>
      <title>Model.predict() 给出相同的值 [-2147483648]</title>
      <link>https://stackoverflow.com/questions/77743313/model-predict-give-same-value-2147483648</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77743313/model-predict-give-same-value-2147483648</guid>
      <pubDate>Mon, 01 Jan 2024 20:52:09 GMT</pubDate>
    </item>
    <item>
      <title>我需要帮助提高我的张量流模型的准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/77734479/i-needed-help-improveing-the-accuracy-of-my-tensorflow-model</link>
      <description><![CDATA[所以我编写了一组基本的张量流代码，测试集准确率达到 97%，然后使用下面的代码帮助我编写一些数字，保存屏幕并打开图像，然后将其转换为 28x28 图像，然后将其输入到模型中，但由于某种原因，模型总是预测 4。
如果您想查看完整代码，请参阅存储库链接：https://github.com/Deadskullcandy/ Mnist_Model
导入 pygame


# 初始化 Pygame
pygame.init()

# 设置屏幕
宽度, 高度 = 280, 280
屏幕 = pygame.display.set_mode((宽度，高度))
pygame.display.set_caption(&#39;绘制并预测&#39;)

# 设置颜色
白色 = (255, 255, 255)

# 设置绘图参数
绘图 = 假

# 主循环
运行=真
在跑步的时候：
    对于 pygame.event.get() 中的事件：
        如果 event.type == pygame.QUIT：
            运行=假
        
        elif event.type == pygame.MOUSEBUTTONDOWN：
            绘图=真实
        
        elif event.type == pygame.MOUSEBUTTONUP：
            绘图 = 假
        
        elif event.type == pygame.MOUSEMOTION 和绘图：
            mouse_pos = pygame.mouse.get_pos()
            pygame.draw.circle（屏幕，白色，mouse_pos，5）
        
        elif event.type == pygame.KEYDOWN：
            如果 event.key == pygame.K_SPACE：
                pygame.image.save（屏幕，&#39;temp.png&#39;）
                图像 = pygame.image.load(&#39;temp.png&#39;).convert()
                图像 = pygame.transform.scale(图像,(28,28))
                图像 = pygame.transform.flip(图像, True, False)
                image_array = pygame.surfarray.array2d(图像)
                image_array = np.resize(image_array,(1,28,28))
                预测=probability_model.predict(image_array)
                打印（np.argmax（预测[0]））

            如果 event.key == pygame.K_r:
                screen.fill(&#39;黑色&#39;)
                
    pygame.display.flip()

pygame.quit()

我不知道如何修复它或模型发生了什么]]></description>
      <guid>https://stackoverflow.com/questions/77734479/i-needed-help-improveing-the-accuracy-of-my-tensorflow-model</guid>
      <pubDate>Sat, 30 Dec 2023 00:28:56 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>预测后如何取消数据缩放？</title>
      <link>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</link>
      <description><![CDATA[我有一个具有 2 个特征（价格和数量）的数据集1 个预测变量（价格），并使用 LTSM 模型根据前一组价格预测下一个价格。
首先我缩放数据集：
#缩放数据
缩放器 = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(数据集)

最后我想取消缩放：
#获取模型预测价格值
预测 = model.predict(x_test)
预测=scaler.inverse_transform(预测)

但这不起作用，我收到此错误：
ValueError：形状为 (400,1) 的不可广播输出操作数与广播形状 (400,2) 不匹配
]]></description>
      <guid>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</guid>
      <pubDate>Wed, 12 Aug 2020 16:20:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用管道中的最佳估计器来预测测试集？</title>
      <link>https://stackoverflow.com/questions/56615768/how-to-use-best-estimator-from-pipeline-to-predict-test-set</link>
      <description><![CDATA[我使用 XGBoost 开发了一个管道，它为我返回了最佳估计器。
但是，尝试使用这个最佳估计器来预测我的测试集时，会出现以下错误：“ValueError：仅 pandas DataFrames 支持使用字符串指定列”。
下面是我使用的管道的代码：
注意：ct 只是使用 SimpleImputer 和 OneHotEncoder 用于分类列的 ColumnTransformer 和 SimpleImputer和用于数字列的 StandardScaler
ml_step_1 = (&#39;transform&#39;, ct)
ml_step_2 = (&#39;PCA&#39;, PCA())
xgb = (&#39;xgb&#39;, XGBRegressor())
xgb_pipe = 管道([ml_step_1, ml_step_2, xgb])
xgb = RandomizedSearchCV(xgb_pipe, xgb_param_grid, cv=kf, 评分=&#39;neg_mean_absolute_error&#39;);
xgb.fit(train_full_features, train_full_target);

运行以下管道，这是我得到的最佳估计器：
最佳 XGBoost 参数：{&#39;xgb__silent&#39;：True，&#39;xgb__n_estimators&#39;：1000，&#39;xgb__max_深度&#39;：4，&#39;xgb__learning_rate&#39;：0.099999999999999999，&#39;transform__num__imputer__strategy&#39;：&#39;中值&#39;，&#39;transform__cat__imputer__strategy&#39;：&#39;most_frequent&#39;，&#39;pca__n_components&#39;：68}

现在，我调用了这个最佳估计器并执行了以下操作：
test_full_imp = pd.DataFrame(xgb.best_estimator_.named_steps[&#39;transform&#39;].transform(test_full))
test_final = xgb.best_estimator_.named_steps[&#39;pca&#39;].transform(test_full_imp)
预测 = xgb.best_estimator_.predict(test_final)
]]></description>
      <guid>https://stackoverflow.com/questions/56615768/how-to-use-best-estimator-from-pipeline-to-predict-test-set</guid>
      <pubDate>Sun, 16 Jun 2019 03:07:00 GMT</pubDate>
    </item>
    </channel>
</rss>