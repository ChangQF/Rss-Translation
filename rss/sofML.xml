<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 10 Aug 2024 12:27:47 GMT</lastBuildDate>
    <item>
      <title>需要用于 GenAI 图像生成的神经网络和深度学习模型</title>
      <link>https://stackoverflow.com/questions/78855910/need-a-neural-network-and-deep-learning-model-for-genai-image-generation</link>
      <description><![CDATA[我需要一个预先训练的模型，可以分析图像中存在的所有形状，并将它们转换为最接近的规则几何形状。图像应根据对称性和不完整曲线的完整性进行规则化。
我尝试使用 object_detection 模型，但发现它没有经过训练来规则化形状]]></description>
      <guid>https://stackoverflow.com/questions/78855910/need-a-neural-network-and-deep-learning-model-for-genai-image-generation</guid>
      <pubDate>Sat, 10 Aug 2024 11:40:24 GMT</pubDate>
    </item>
    <item>
      <title>YOLO 无法正确预测给定的图像</title>
      <link>https://stackoverflow.com/questions/78855613/yolo-is-not-predicting-the-given-image-properly</link>
      <description><![CDATA[我第一次尝试 YOLO。
我正在按照视频教程操作，我编写了与他完全相同的代码，但它对我来说不起作用，我不知道为什么。

from ultralytics import YOLO
import numpy

model = YOLO(&quot;yolov8n.pt&quot;, &quot;v8&quot;)

output = model.predict(source=&quot;dog.jpg&quot;, conf=0.25, save=True)

print(output)
print(output[0].numpy())


我提供给模型的图像：

我得到的输出：

我已经尝试过其他图像，但结果相同。
....................]]></description>
      <guid>https://stackoverflow.com/questions/78855613/yolo-is-not-predicting-the-given-image-properly</guid>
      <pubDate>Sat, 10 Aug 2024 08:55:24 GMT</pubDate>
    </item>
    <item>
      <title>构建 ML 模型时如何选择合适的标签</title>
      <link>https://stackoverflow.com/questions/78854998/how-to-choose-the-appropriate-label-when-building-a-ml-model</link>
      <description><![CDATA[我正在尝试为特定任务训练模型。
这里有一个简单的描述：
image1
image2
以下是两个不同数据集的屏幕截图：图 1 中的数据顺序正确，没有错误，也没有缺失数据。另一方面，图 2 中的数据是无序的，包含噪音，并且有缺失数据。
我想训练一个模型，当输入图 2 中显示类型的数据时，该模型可以返回图 1 中显示类型的数据。
我尝试使用 RF 和 CNN 模型，但结果并没有像我预期的那样发展。我在想这可能是由于标签选择不正确造成的。
其实从图1中，很容易就能发现其中的联系。
例如，
1 2 3 4
A A-1 B B-1
A2 A2-1 B2 B2-1
A3 A3-1 B3 B3-1
A4 A4-1 B4 B4-1
图1这类数据中，A=A2-1，A2=A3-1\
因此，我希望模型能够学习到这种关系，然后在乱序的数据（图2）中找出正确的顺序。一旦确定了一个正确的序列，就可以通过递归得到正确且唯一的顺序。由于行与行之间是相互对应的（即 A A-1 B B-1 固定在同一行），一旦正确确定了一列的序列，整个序列也正确确定了。
所以我尝试使用模型来解决这个问题。该模型能够运行并学到了一些东西，但没有学到任何有用的东西。我开始意识到问题可能在于标签选择。（事实上，这个问题可能可以用算法来解决，但我想用机器学习来实现它。）
我希望有人能就如何选择标签以及拆分训练集和验证集提供建议。]]></description>
      <guid>https://stackoverflow.com/questions/78854998/how-to-choose-the-appropriate-label-when-building-a-ml-model</guid>
      <pubDate>Sat, 10 Aug 2024 01:22:04 GMT</pubDate>
    </item>
    <item>
      <title>我该如何解释这个训练/验证损失曲线？[关闭]</title>
      <link>https://stackoverflow.com/questions/78854439/how-can-i-interpret-this-training-validation-loss-curve</link>
      <description><![CDATA[我实现了机器学习算法进行分类，并生成了训练/验证损失曲线。
这里是：
训练/验证损失曲线
我该如何解释它，我从未见过这样的曲线。它是否显示了一个好的模型？感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78854439/how-can-i-interpret-this-training-validation-loss-curve</guid>
      <pubDate>Fri, 09 Aug 2024 19:57:12 GMT</pubDate>
    </item>
    <item>
      <title>MMpose 推断器不适用于 MP4 文件</title>
      <link>https://stackoverflow.com/questions/78854257/mmpose-inferencer-not-working-for-mp4-files</link>
      <description><![CDATA[我正在尝试使用 MMPose 在视频中的个人的 3D 空间中查找关键点。我使用的代码（之前在 2d 中运行过）是：
from mmpose.apis import MMPoseInferencer
from pathlib import Path
import os

data_folder = Path(&quot;x/videos&quot;)
for filename in os.listdir(data_folder):
if not filename.endswith(&#39;.mp4&#39;):
continue
img_path = os.path.join(data_folder, filename)

inferencer = MMPoseInferencer(pose3d=&quot;human3d&quot;)

result_generator = inferencer(img_path, out_dir=&#39;output&#39;)

每当我尝试访问 results_generator（如 results = [result for result in result_generator]）时，我都会遇到段错误，我猜是因为 result_generator 中没有任何内容。我还希望输出文件夹中有可视化效果和数据，但该文件夹是空的。我有什么明显的错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78854257/mmpose-inferencer-not-working-for-mp4-files</guid>
      <pubDate>Fri, 09 Aug 2024 18:55:46 GMT</pubDate>
    </item>
    <item>
      <title>如何下载机器学习的数据集但仅限于我的 python 文件中？</title>
      <link>https://stackoverflow.com/questions/78854017/how-do-i-download-datasets-for-machine-learning-but-only-in-my-python-file</link>
      <description><![CDATA[我需要下载音频数据集。我正在关注此 Tensorflow 教程，但我不知道如何获取像教程中用于设置原点的链接。我正在使用 Google Collab。
DATASET_PATH = &#39;data/mini_speech_commands&#39;

data_dir = pathlib.Path(DATASET_PATH)
if not data_dir.exists():
tf.keras.utils.get_file(
&#39;mini_speech_commands.zip&#39;,
origin=&quot;http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip&quot;,
extract=True,
cache_dir=&#39;.&#39;, cache_subdir=&#39;data&#39;)

commands = np.array(tf.io.gfile.listdir(str(data_dir)))
commands = commands[(commands != &#39;README.md&#39;) &amp; (commands != &#39;.DS_Store&#39;)]
print(&#39;Commands:&#39;, command)

按照教程中的所有内容，它可以正常工作，但我不明白将音频数据集放入我的 python 文件中的过程以及如何浏览每个音频。]]></description>
      <guid>https://stackoverflow.com/questions/78854017/how-do-i-download-datasets-for-machine-learning-but-only-in-my-python-file</guid>
      <pubDate>Fri, 09 Aug 2024 17:32:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Movenet 检测正确和不正确的姿势？[关闭]</title>
      <link>https://stackoverflow.com/questions/78853603/how-would-i-use-movenet-to-detect-correct-and-incorrect-poses</link>
      <description><![CDATA[我正在尝试使用 Tensorflow、Keras 和 Movenet 检测正确和不正确的坐姿。目前，我在训练、有效和测试文件夹中有好姿势和坏姿势文件夹，其中包含相应的姿势。我对编码模型的方法有一些想法，但我不确定哪种方法真正有效/最合适：

保留好姿势/坏姿势文件夹，使用数据构建和训练 CNN，然后构建/训练微调神经网络以对好姿势和坏姿势进行分类

仅保留好姿势图像，使用斜率计算某些身体部位的正确位置，不构建 CNN。我能想到的唯一问题是，如果某个身体部位阻碍了另一个身体部位怎么办？例如，我有一张正确姿势的照片，我的手臂放在桌子上，准备打字，但我还有另一张正确姿势的照片，我的手臂放在身体两侧，前臂向下不可见。或者姿势不正确，如果有人身体倾斜，脸靠在手上，身体的某些部位就看不见了怎么办？我或 Movenet 会如何处理这种情况？

完全不同的方法

]]></description>
      <guid>https://stackoverflow.com/questions/78853603/how-would-i-use-movenet-to-detect-correct-and-incorrect-poses</guid>
      <pubDate>Fri, 09 Aug 2024 15:33:58 GMT</pubDate>
    </item>
    <item>
      <title>如何完成遮挡的形状？[关闭]</title>
      <link>https://stackoverflow.com/questions/78853333/how-to-complete-occluded-shapes</link>
      <description><![CDATA[我正在做一个项目来补全遮挡形状。
我浏览了互联网，发现我们可以使用插值方法来完成不完整的曲线，但唯一的问题是，在我使用的数据中（在包含每条曲线的点的 csv 文件中），曲线是封闭的……有什么想法可以做到这一点吗？

就像下面给出的这张图片一样，输入是一个 csv 文件，其中包含 3 条曲线的数据点，这些曲线都是封闭的。如果我单独绘制被遮挡的椭圆的输入点，它们将像第二张照片一样出现，而不仅仅是不完整的椭圆边界曲线。

输出应如下所示：
]]></description>
      <guid>https://stackoverflow.com/questions/78853333/how-to-complete-occluded-shapes</guid>
      <pubDate>Fri, 09 Aug 2024 14:32:17 GMT</pubDate>
    </item>
    <item>
      <title>无法设置张量：获取 STRING 类型的值，但输入 0 应为 FLOAT32 类型，名称：serving_default_args_0:0</title>
      <link>https://stackoverflow.com/questions/78853060/cannot-set-tensor-got-value-of-type-string-but-expected-type-float32-for-input</link>
      <description><![CDATA[当我尝试加载模型时，我收到一条错误消息
这是我的代码
interpreter = tf.lite.Interpreter(model_path=&quot;/content/colab_model.tflite&quot;)
interpreter.allocate_tensors()

# 获取输入和输出张量。
input_details = explainer.get_input_details()
output_details = explainer.get_output_details()
# 打印输入详细信息以了解其预期类型和形状
for input_detail in input_details:
print(f&quot;Name: {input_detail[&#39;name&#39;]}, Shape: {input_detail[&#39;shape&#39;]}, Dtype: {input_detail[&#39;dtype&#39;]}&quot;)

# 将用户 ID 转换为字符串
user_id_value = np.array([&#39;42&#39;], dtype=np.str_) 

# 将配方 ID 转换为字符串
recipe_id_values = np.array([&#39;49&#39;, &#39;66&#39;, &#39;62&#39;], dtype=np.str_)

# 使用字符串设置张量值
interpreter.set_tensor(input_details[0][&#39;index&#39;], np.array([recipe_id_values[0]])) 
interpreter.set_tensor(input_details[1][&#39;index&#39;], user_id_value)

# 调用模型
interpreter.invoke()

# 获取输出
output_data = interpretationer.get_tensor(output_details[0][&#39;index&#39;])
print(output_data)

错误
ValueError: 无法设置张量：得到的值类型为 STRING，但输入 0 的预期类型为 FLOAT32，名称为：serving_default_args_0:0

当我尝试先将其转换为浮点 32 时，出现错误
RuntimeError: 将浮点转换为字符串是错误的支持的委托内核未初始化节点号 19 (TfLiteFlexDelegate) 准备失败。委托内核未初始化节点号 19 (TfLiteFlexDelegate) 准备失败。委托内核未初始化节点号 19
(TfLiteFlexDelegate) 准备失败。
]]></description>
      <guid>https://stackoverflow.com/questions/78853060/cannot-set-tensor-got-value-of-type-string-but-expected-type-float32-for-input</guid>
      <pubDate>Fri, 09 Aug 2024 13:30:18 GMT</pubDate>
    </item>
    <item>
      <title>如何集成一项功能来识别手绘形状并实时重新绘制它[关闭]</title>
      <link>https://stackoverflow.com/questions/78852946/how-to-integrate-a-feature-to-recognize-hand-drawn-shapes-and-redraw-it-in-real</link>
      <description><![CDATA[我正在构建一个项目，它可以跟踪我的手指运动并根据我的运动在屏幕上绘图。为此，我使用了 mediaPipe Hands 解决方案。我想集成一个功能来识别圆形、矩形等形状，并以理想的形式重新绘制它。
（当然是视频流）
我实现了一个功能来识别使用 OpenCV 在屏幕上绘制的形状。我尝试在绘图模式下捕获手指跟踪的点，并使用这些点来检测所绘制的形状是圆形还是矩形。我期望它在完成后准确识别形状。然而，实际发生的是，一旦我进入绘图模式，系统就开始将我的手指检测为圆形，并在手指移动到的每个点周围绘制一个圆圈。
我如何检测我正在绘制的形状，然后完美地重新绘制它们？
def understand_shape(points):
if len(points) &lt; 5：
return None

# 计算点的边界框
x_coords, y_coords = zip(*points)
min_x, max_x = min(x_coords), max(x_coords)
min_y, max_y = min(y_coords), max(y_coords)
width, height = max_x - min_x, max_y - min_y

# 使用半径方差检查圆
center_x, center_y = np.mean(x_coords), np.mean(y_coords)
radii = [distance.euclidean((x, y), (center_x, center_y)) for x, y in points]
mean_radius = np.mean(radii)
radius_variance = np.var(radii)

if radius_variance &lt; 1000：# 调整阈值以提高准确度
return (&quot;circle&quot;, (int(center_x), int(center_y), int(mean_radius)))

# 使用纵横比检查矩形
if 0.9 &lt; width / height &lt; 1.1：# 允许正方形略有偏差
if all(min_x &lt;= x &lt;= max_x and min_y &lt;= y &lt;= max_y for x, y in points):
return (&quot;rectangle&quot;, (min_x, min_y, max_x, max_y))

return None

def draw_shape(shape, imgCanvas):
if shape[0] == &quot;circle&quot;:
_, (center_x, center_y, radius) = shape
cv2.circle(imgCanvas, (center_x, center_y), radius, (0, 0, 255), 2)
elif shape[0] == &quot;rectangle&quot;:
_, (min_x, min_y, max_x, max_y) = shape
cv2.rectangle(imgCanvas, (min_x, min_y), (max_x, max_y), (0, 0, 255), 2)
]]></description>
      <guid>https://stackoverflow.com/questions/78852946/how-to-integrate-a-feature-to-recognize-hand-drawn-shapes-and-redraw-it-in-real</guid>
      <pubDate>Fri, 09 Aug 2024 13:06:37 GMT</pubDate>
    </item>
    <item>
      <title>如何找到参数之间的因果关系？[关闭]</title>
      <link>https://stackoverflow.com/questions/78852790/how-to-find-causal-relationship-between-parameters</link>
      <description><![CDATA[我的公司生产嵌入式设备，我们从这些设备中收集了一堆参数（几百个），保存在 CSV 文件中。现在我想找到一个重要的错误参数和所有其他参数之间的因果关系。到目前为止，我所做的就是训练一个 SVM 模型，以重要的错误参数为目标，其余参数为特征，然后找到对目标参数贡献最大的特征。我对结果非常满意，因为贡献最大的标签实际上是有意义的，并且该模型在测试数据上的准确率超过了 90%。
但我不知道如何从这些结果继续找到特定事件中的贡献参数。例如，如果触发了这个错误参数 - 我如何使用我训练过的模型知道哪个参数是贡献最大的参数（假设所有其他参数的上下文）？目前，模型只能告诉我触发错误参数的可能性 - 但不能反过来。]]></description>
      <guid>https://stackoverflow.com/questions/78852790/how-to-find-causal-relationship-between-parameters</guid>
      <pubDate>Fri, 09 Aug 2024 12:31:24 GMT</pubDate>
    </item>
    <item>
      <title>将图像数据地理配准到 Google staelite 地图的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/78852106/what-is-the-best-way-to-georeference-image-data-to-google-staelite-map</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78852106/what-is-the-best-way-to-georeference-image-data-to-google-staelite-map</guid>
      <pubDate>Fri, 09 Aug 2024 09:42:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 TensorFlow 修剪我在 Python 中创建的神经网络？</title>
      <link>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-i-created-in-python-using-tensorflow</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-i-created-in-python-using-tensorflow</guid>
      <pubDate>Fri, 09 Aug 2024 07:50:59 GMT</pubDate>
    </item>
    <item>
      <title>无需深度学习或 Tesseract 的文本图像二元分类器</title>
      <link>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</link>
      <description><![CDATA[我有 20k 张小标签图像，每张图像都有单词“Back”或“Front”。
图像分辨率为全部 (200px, 25px)

我可以使用 tesseract_OCR 对这些图像进行 100% 准确率的分类。
 txt = pytesseract.image_to_string(img, lang=&#39;eng&#39;)
if &quot;Front&quot; in txt:
return &quot;Front&quot;
if &quot;Back&quot; in txt:
return &quot;Back&quot;

问题是，它太慢了（20k 张图像需要 1 小时）并且需要安装 OCR 包。
我知道即使是 3 层的简单 CNN 也能很好地运行，但我认为这个问题似乎可以用简单的算法解决，而不需要复杂的技术。
你能给我推荐一种新方法吗？
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</guid>
      <pubDate>Wed, 07 Aug 2024 06:46:36 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音转文本和翻译（直播）</title>
      <link>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</link>
      <description><![CDATA[我有一个用例，我将在直播中录制一段演讲，并且我希望实时获得音频的文本转录，然​​后翻译该转录。
我是否需要使用 Google 的语音转文本 API，然后将生成的文本发送到翻译 API，还是可以在一行中完成？]]></description>
      <guid>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</guid>
      <pubDate>Thu, 18 Jul 2024 17:21:16 GMT</pubDate>
    </item>
    </channel>
</rss>