<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 17 Dec 2023 18:15:40 GMT</lastBuildDate>
    <item>
      <title>我不明白如何训练元学习器或它如何预测</title>
      <link>https://stackoverflow.com/questions/77675237/i-dont-understand-how-to-train-a-meta-learner-or-how-it-predicts</link>
      <description><![CDATA[我一直在学习机器学习模型，并且遇到了元学习器的概念。
据我所知，这些方法通常通过将多个分类器的预测作为特征、将真实标签作为标签并在此基础上训练另一个模型来工作。
如果我有两个情感分类器，则会给出以下结果：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

文本
真实标签
CL 1 标签
CL 1 概率
CL 2 标签
CL 2 概率


&lt;正文&gt;

快乐
积极
积极
0.9
积极
0.7


悲伤
否定
积极
0.7
否定
0.9


生气
否定
否定
0.8
积极
0.6


内容
积极
积极
0.5
否定
0.8




我训练了一个新模型，将真实标签作为标签，将概率作为特征。新模型如何知道概率指的是哪个标签？基分类器可以以 0.9 的确定性预测任一标签。那么元学习器也应该包含基分类器标签吗？或者基分类器标签是否是元学习器的特征？
一旦元学习器经过训练，我假设它将在测试数据的文本部分上进行测试。但由于它没有学习文本中包含的任何特征，它到底在预测什么？]]></description>
      <guid>https://stackoverflow.com/questions/77675237/i-dont-understand-how-to-train-a-meta-learner-or-how-it-predicts</guid>
      <pubDate>Sun, 17 Dec 2023 16:54:36 GMT</pubDate>
    </item>
    <item>
      <title>使用新数据训练 NLP 模型</title>
      <link>https://stackoverflow.com/questions/77674787/training-nlp-model-on-new-data</link>
      <description><![CDATA[我正在开发一个 NLP 模型（使用 LSTM），该模型接收文本句子（例如谷歌地图评论）并预测星级评分。
我掌握了拥有超过 600 万条评论的 yelp 数据集，我正在用它来训练我的模型。数据集太大，导致我分批训练模型（10K 批审核）。
假设我完成了训练并且取得了合理的表现。随后，Yelp 发布了 100 万条新评论。如何在新数据上训练模型？
1- 我应该仅根据新数据训练模型吗？
或者
2- 将新数据与旧数据结合并重新训练模型？
3-如何避免灾难性遗忘？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77674787/training-nlp-model-on-new-data</guid>
      <pubDate>Sun, 17 Dec 2023 14:36:08 GMT</pubDate>
    </item>
    <item>
      <title>安装旧版本的 scikitlearn</title>
      <link>https://stackoverflow.com/questions/77674168/installation-old-version-of-scikitlearn</link>
      <description><![CDATA[如何安装旧版本的 scikitlearn ？
我安装了最新版本的 scikitlearn，但对我的数据集不起作用
我需要使用波士顿房价数据集，但该数据集不适用于新版本的 scilitlearn
因为这条消息：
自 1.2 版起，load_boston` 已从 scikit-learn 中删除。
波士顿房价数据集存在道德问题：
在[1]中进行了调查，该数据集的作者设计了一个
不可逆变量“B”假设种族自我隔离有
对房价产生积极影响[2]。此外，该项目的目标是
导致创建该数据集的研究是为了研究
空气质量的影响，但没有充分证明
这个假设的有效性。
因此，scikit-learn 维护者强烈反对使用
除非代码的目的是学习和教育，否则此数据集
关于数据科学和机器学习中的道德问题。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77674168/installation-old-version-of-scikitlearn</guid>
      <pubDate>Sun, 17 Dec 2023 11:13:20 GMT</pubDate>
    </item>
    <item>
      <title>关于PyTorch中matmul的批量效果——什么时候减少？</title>
      <link>https://stackoverflow.com/questions/77673891/about-batched-effect-of-matmul-in-pytorch-when-to-reduce</link>
      <description><![CDATA[bp 在批处理 matmul 场景中如何工作？假设我们有一个线性，x的形状是[b,m,k]，W的形状是[k,n]：
&lt;前&gt;&lt;代码&gt; y = xW

然后：
 \frac{\partial L}{\partial W} = x^T\frac{\partial L}{\partial y}

那么W后面发生了什么？

我们保存完整的 $x^T$ 张量 [b,k,m]，并执行批处理的 matmul [b,k,m] x [b,m,n ]，最后将结果归约到[k,n]得到梯度。
我们直接保存平均$x^T$张量[k,m]，并执行批处理的matmul [k,m] x [m,n]获取梯度。

我已经阅读了 PyTorch 的源代码，但我在理解它时遇到了问题。]]></description>
      <guid>https://stackoverflow.com/questions/77673891/about-batched-effect-of-matmul-in-pytorch-when-to-reduce</guid>
      <pubDate>Sun, 17 Dec 2023 09:27:33 GMT</pubDate>
    </item>
    <item>
      <title>自定义神经网络输出层的梯度爆炸问题</title>
      <link>https://stackoverflow.com/questions/77673873/gradient-explosion-issue-with-custom-neural-network-output-layer</link>
      <description><![CDATA[我目前正在制作拟合函数来训练我的神经网络的自定义输出层。当将我的输出层拟合到数据集时，权重很快就会变得非常大。通过迭代 5-6，我已经获得了 Nan 值。
我尝试过提高学习率，但没有成功。我相当确定问题出在我用来计算调整权重步骤的公式中，因为它纯粹是我自己得出的，没有确认其正确性。
这是我的代码。我不确定是否应该包含 Neuron 类。
将 matplotlib 导入为 plt
从神经元导入*
导入时间
将 matplotlib.pyplot 导入为 plt

类输出层：
    def __init__(自身，input_shape，output_shape，activation_func=none)：
        神经元层 = np.array([])
        对于范围内的 x(output_shape)：
            神经元层 = np.append(神经元层,感知器(n_of_weights=input_shape, 步骤=activation_func, 激活=activation_func))
        self.neurons = 神经元_层
    def get_neuron(self, n):
        返回自身神经元[n]
    
    def get_neurons(self):
        返回自身神经元
    
    def set_neurons(self, adj_neurons):
        self.神经元 = adj_neurons
    
    defforward_pass（自身，X）：
        输出 = np.array([])
        对于 self.neurons 中的神经元：
            输出 = np.append(输出,neuron.step_pass(X))
        返回输出
    
    def relu（自身，输入）：
        如果输入&gt;0：
            返回输入
        别的：
            返回0
        
    def drelu（自身，输入）：
        如果输入&gt;0：
            返回1
        别的：
            返回0

    def sigmoid（自身，输入）：
        返回 1/(1+np.e**(-输入))

    def dsigmoid（自身，输入）：
        返回 self.sigmoid(输入)*(1-self.sigmoid(输入))
    
    def 失活（自身，神经元，输入）：
        激活=神经元.get_activation()
        如果激活==&#39;sigmoid&#39;：
            返回 dsigmoid(neuron.raw_pass(input))
        elif激活==&#39;relu&#39;：
            返回 drelu(neuron.raw_pass(input))
        别的：
            返回神经元.raw_pass(输入)
    
    def fit(自我, X, y, 学习率):
        Weight_change = [[w] for w in self.get_neurons()[0].get_weights()]
        错误 = [0]
        神经元 = self.get_neurons()
        对于范围内的 k(len(X))：
            对于神经元中的 n：
                权重 = n.get_weights()[:-1]
                print(&quot;通过：&quot;,self.forward_pass(X[k]))
                a = [(learning_rate*(self.forward_pass(X[k])-y[k])*self.dactivation(n, X[k])*X[k][x])[0] 对于 x 在范围内(长度(权重))]
                print(&quot;输出：&quot;,y[k])
                print(&quot;输入：&quot;,X[k])
                print(&quot;权重&quot;,n.get_weights())
                adj_weights = [权重[x]-(learning_rate*(self.forward_pass(X[k])-y[k])*self.dactivation(n, X[k])*X[k][x])[0 ] 对于范围内的 x(len(权重))]
                adj_weights.append(n.get_weights()[-1:][0]-(learning_rate*(self.forward_pass(X[k])-y[k])*self.dactivation(n, X[k])) [0]）
                n.change_weights(adj_weights)
                print(&#39;权重:&#39;,adj_weights)
                print(&#39;新通行证：&#39;,self.forward_pass(X[k]))
                对于范围内的 x(len(adj_weights))：
                    weight_change[x].append(adj_weights[x])
            error.append(y[k]-n.step_pass(X[k]))
            self.set_neurons(神经元)
        返回weight_change，错误```
]]></description>
      <guid>https://stackoverflow.com/questions/77673873/gradient-explosion-issue-with-custom-neural-network-output-layer</guid>
      <pubDate>Sun, 17 Dec 2023 09:19:07 GMT</pubDate>
    </item>
    <item>
      <title>我想解决一个机器学习问题，其中多个 Excel 文件中的每个文件代表不同的功能[关闭]</title>
      <link>https://stackoverflow.com/questions/77673612/i-want-to-solve-a-machine-learning-problem-where-each-of-a-number-of-excel-files</link>
      <description><![CDATA[我有一个机器学习问题，给我 6 个 Excel 文件，每个文件都有不同的特征作为输入，而我有一个包含输出的 Excel 工作表。以前我习惯只有一张包含所有输入和输出的Excel工作表，我很容易解决这个问题，但现在我知道我有多个Excel数据文件，我该如何解决这个问题。我实际上不知道如何开始这个问题，因为这对我来说是全新的。]]></description>
      <guid>https://stackoverflow.com/questions/77673612/i-want-to-solve-a-machine-learning-problem-where-each-of-a-number-of-excel-files</guid>
      <pubDate>Sun, 17 Dec 2023 07:29:24 GMT</pubDate>
    </item>
    <item>
      <title>我刚开始使用 Streamlit for ML，在将其安装到桌面时遇到此错误。有什么建议吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77673471/im-new-to-using-streamlit-for-ml-and-getting-this-error-on-installing-it-deskto</link>
      <description><![CDATA[
我关闭了 Windows 防火墙，仍然无法下载 Streamlit 软件包
我使用的是 python 3.12.0 而不是 Anaconda
有什么帮助吗？
在 YouTube 或任何其他网站上几乎看不到任何解决方案
系统找不到指定的文件：&#39;C:\Python312\Scripts\f2py.exe&#39; -&gt; &#39;C:\Python312\Scripts\f2py.exe.deleteme&#39;
总是出现此错误
ㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤ ㅤㅤㅤㅤㅤㅤㅤ ㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤㅤ ㅤㅤㅤㅤ]]></description>
      <guid>https://stackoverflow.com/questions/77673471/im-new-to-using-streamlit-for-ml-and-getting-this-error-on-installing-it-deskto</guid>
      <pubDate>Sun, 17 Dec 2023 06:13:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 dataloader 来存储训练数据会改变模型的训练？</title>
      <link>https://stackoverflow.com/questions/77673297/why-does-the-usage-of-dataloader-for-train-data-change-the-training-of-the-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673297/why-does-the-usage-of-dataloader-for-train-data-change-the-training-of-the-model</guid>
      <pubDate>Sun, 17 Dec 2023 04:17:54 GMT</pubDate>
    </item>
    <item>
      <title>端到端 ML 项目的模型训练器问题 - TypeError：initiate_model_training() 缺少 4 个必需的位置参数</title>
      <link>https://stackoverflow.com/questions/77673255/model-trainer-issue-on-end-to-end-ml-project-typeerror-initiate-model-trainin</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673255/model-trainer-issue-on-end-to-end-ml-project-typeerror-initiate-model-trainin</guid>
      <pubDate>Sun, 17 Dec 2023 03:50:40 GMT</pubDate>
    </item>
    <item>
      <title>keras.models.load_model("") 在 h5f.open() 上给出错误[关闭]</title>
      <link>https://stackoverflow.com/questions/77673041/keras-models-load-model-gives-error-on-h5f-open</link>
      <description><![CDATA[当使用keras.models.load时，它会在h5f.open(name, flags, fapl=fapl)上抛出错误，并显示OSError: Unable to打开文件（未找到文件签名）。
DNN模型文件代码
随机导入
将 numpy 导入为 np
将张量流导入为 tf
从 keras.layers 导入密集、Dropout
从 keras.models 导入顺序
从 keras.regularizers 导入 l1, l2
从 keras.optimizers 导入 Adam

def set_seeds(种子 = 100):
    随机种子（种子）
    np.随机.种子（种子）
    tf.random.set_seed(种子)
    
def CW(df):
    c0, c1 = np.bincount(df[“dir”])
    w0 = (1/c0) * (len(df)) / 2
    w1 = (1/c1) * (len(df)) / 2
    返回 {0:w0, 1:w1}

优化器 = Adam(lr = 0.0001)

def create_model(hl = 2, hu = 100, dropout = False, 速率 = 0.3, 正则化 = False,
                 reg = l1(0.0005)，优化器 = 优化器，input_dim = 无）：
    如果不正则化：
        reg = 无
    模型=顺序（）
    model.add（密集（hu，input_dim = input_dim，activity_regularizer = reg，activation =“relu”））
    如果辍学：
        model.add(Dropout(速率, 种子 = 100))
    对于范围（hl）内的图层：
        model.add（密集（hu，激活=“relu”，activity_regularizer = reg））
        如果辍学：
            model.add(Dropout(速率, 种子 = 100))
    model.add(Dense(1, 激活 = “sigmoid”))
    model.compile（损失=“binary_crossentropy”，优化器=优化器，指标=[“准确性”]）
    返回模型


加载模型和参数
# 加载模型
导入keras
model = keras.models.load_model(“C:/Users/Hussein Ali/Desktop/d/DNNModel.py”)

错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
OSError Traceback（最近一次调用最后一次）
第 3 行 [1] 中的单元格
      1 # 加载模型
      2导入keras
----&gt; 3 模型 = keras.models.load_model(“C:/Users/Hussein Ali/Desktop/d/DNNModel.py”)

文件 C:\anaconda\lib\site-packages\keras\utils\traceback_utils.py:70，位于filter_traceback..error_handler(*args, **kwargs)
     67、filtered_tb = _process_traceback_frames（e.__traceback__）
     68 # 要获取完整的堆栈跟踪，请调用：
     69 # `tf.debugging.disable_traceback_filtering()`
---&gt; 70 从 None 引发 e.with_traceback(filtered_tb)
     71 最后：
     72 删除filtered_tb

文件 C:\anaconda\lib\site-packages\h5py\_hl\files.py:533，在 File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy 、fs_persist、fs_threshold、fs_page_size、page_buf_size、min_meta_keep、min_raw_keep、锁定、alignment_threshold、alignment_interval、**kwds）
    第525章
    526锁定，page_buf_size，min_meta_keep，min_raw_keep，
    [第 527 章]
    [第 528 章]
    第529章
    第530章
    [第 531 章]
    第532章
--&gt;第533章
    第535章
    第536章

文件 C:\anaconda\lib\site-packages\h5py\_hl\files.py:226，在 make_fid（名称、模式、userblock_size、fapl、fcpl、swmr）中
    224 如果 swmr 和 swmr_support:
    225 个标志 |= h5f.ACC_SWMR_READ
--&gt; 226 fid = h5f.open（名称，标志，fapl = fapl）
    227 elif 模式 == &#39;r+&#39;:
    [第 228 章]

文件 h5py\_objects.pyx:54，在 h5py._objects.with_phil.wrapper() 中

文件 h5py\_objects.pyx:55，在 h5py._objects.with_phil.wrapper() 中

文件 h5py\h5f.pyx:106，在 h5py.h5f.open() 中

OSError：无法打开文件（未找到文件签名）
]]></description>
      <guid>https://stackoverflow.com/questions/77673041/keras-models-load-model-gives-error-on-h5f-open</guid>
      <pubDate>Sun, 17 Dec 2023 01:20:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么我使用随机森林回归器得到负 R2 分数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77672303/why-im-getting-a-negative-r2-score-with-random-forest-regressor</link>
      <description><![CDATA[我试图使用 Phyton 中的随机森林模型来预测 MOF 的一些变量（来自一篇科学论文），但 R2 的值为负值（与论文不同，论文为正值）。我实际上不知道问题是否出在我的数据集（涉及将数值分配给字符串）或我的代码中。原始数据集是文学数据集，我的版本是“Dados editados 3”
数据集链接：https://docs.google.com/spreadsheets/d/17r-hxcuuzEFdfsqcAdHe_9iIp1d51IvL/edit?usp=sharing&amp;ouid=111702212107777597741&amp;rtpof=true&amp;sd=true
我尝试多次检查代码，但我不知道我做错了什么，因为 RF 模型是一个非常强大的模型。此外，我还使用检测和删除异常值的函数删除数据集的所有 Nan 值。
代码：
导入 pandas 作为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.model_selection 导入 GridSearchCV
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.ensemble 导入 RandomForestRegressor
从sklearn导入预处理
从 sklearn 导入指标
将 numpy 导入为 np

df = pd.read_excel(r&#39;/content/drive/My Drive/Projeto ML/Dados ML.xlsx&#39;,sheet_name =“Dados editados 3”)

df = df.drop(columns = [&#39;酶负载&#39;, &#39;固定率&#39;, &#39;活性保留&#39;] )

df.replace(&#39;-&#39;, np.NaN, inplace = True)

df = df.dropna()

#修改后的函数

def get_outliers(l):
    #如果保留 0.1 和 0.75，那么几乎不会过滤任何异常值
    #q1 是 0.25 分位数，q3 是 0.75 分位数
    q1 = l.分位数(0.25)
    q3 = l.分位数(0.75)
    iqr = q3-q1
    栅栏低 = q1 - 1.5 * iqr
    栅栏高 = q3 + 1.5 * iqr
    返回 [~(i&gt;=fenceLow 且 i&lt;=fenceHigh) for i in l]

离群值 = df.apply(get_outliers)

df = df[~离群值.apply(lambda x:any(x), axis=1)]


X = df.iloc[:, :-1]

Y = df.iloc[:,-1]

x_train，x_test，y_train，y_test = train_test_split（X，Y，test_size = 0.25，random_state = 42）

缩放器 = 预处理.MinMaxScaler(feature_range = (0.1, 0.9))
x_train = 缩放器.fit_transform(x_train)
x_test= 缩放器.fit_transform(x_test)

从 sklearn.model_selection 导入 KFold
从 sklearn.model_selection 导入 cross_val_score
从 sklearn.metrics 导入 r2_score

rf = RandomForestRegressor()

rf.fit(x_train, y_train)

y_pred = rf.predict(x_test)

k_folds = KFold(n_splits = 6)

分数 = cross_val_score(rf, x_train, y_train, cv = k_folds, 评分 = “r2”)

print(&quot;简历分数：&quot;, 分数)
print(&quot;平均简历分数：&quot;, Scores.mean())
print(&quot;平均值中使用的 CV 分数数量：&quot;, len(scores))

在此处输入图像描述
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77672303/why-im-getting-a-negative-r2-score-with-random-forest-regressor</guid>
      <pubDate>Sat, 16 Dec 2023 19:55:00 GMT</pubDate>
    </item>
    <item>
      <title>我应该应用什么预处理来对雕刻文本执行 OCR？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77671624/what-preproccessing-should-i-apply-to-perform-an-ocr-on-an-engraved-text</link>
      <description><![CDATA[我正在尝试对下面有一些其他文本的雕刻数字执行 OCR（参见下图），我正在尝试读取数字并忽略黑色文本。

我尝试过 Google ML 套件文本识别，但它不起作用，我尝试过应用许多过滤器，例如灰度和颜色反转，但它也不起作用。我有一些关于使用 python 和 pytesseract 进行深度学习的线索，但我几乎可以肯定这也行不通。
我想知道，这里的方法是什么？我应该对图像应用任何特定的处理，还是这是一个机器学习问题？这还能解决吗？]]></description>
      <guid>https://stackoverflow.com/questions/77671624/what-preproccessing-should-i-apply-to-perform-an-ocr-on-an-engraved-text</guid>
      <pubDate>Sat, 16 Dec 2023 16:10:46 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试从头开始构建神经网络时出现矩阵乘法错误</title>
      <link>https://stackoverflow.com/questions/77671165/matrix-multiplication-error-when-i-tried-to-build-the-neural-network-from-scratc</link>
      <description><![CDATA[当我了解神经网络的数学工作原理时，我尝试使用 Numpy 从头开始​​构建它。我尝试构建的神经网络结构是具有 3 个节点的 input_layer -&gt; hidden_​​layer_1 有 2 个节点 -&gt; hidden_​​layer_2 有 2 个节点 -&gt;具有 1 个节点的输出层。两个隐藏层都使用ReLu激活函数，输出层使用Sigmoid激活函数。以下是数据集：https://drive.google.com/ file/d/1xP6BvneSdG5SoXL1ADp0veZMSrOcFlQc/view?usp=drive_link代码如下：
将 numpy 导入为 np
将 pandas 导入为 pd

W1 = np.random.rand(2, 3) # 权重矩阵
W2 = np.random.rand(2, 2)
W3 = np.random.rand(1, 2)

B1 = np.random.rand(2, 1) # 偏差向量
B2 = np.random.rand(2, 1)
B3 = np.random.rand(1, 1)

ReLu = lambda x : np.maximum(x, 0)
S 型 = lambda x : 1/ (1+np.exp(-x))

defforward_prop（输入）：

    Z1 = W1@输入 + B1
    A1 = ReLu(Z1)
    
    Z2 = W2@A1 + B2
    A2 = ReLu(Z2)
    
    Z3 = W3@A2 + B3
    A3 = 乙状结肠(Z3)
        
    返回 Z1、A1、Z2、A2、Z3、A3

d_relu = lambda x : x&gt;0
d_sigmoid = lambda x : np.exp(-x) / (1+np.exp(-x))**2

def back_prop(Z1, A1, Z2, A2, Z3, A3, X, Y):
    
    #衍生品
    dC_dA3 = 2*A3 - 2*Y
    
    dA3_dZ3 = d_sigmoid(Z3)
    dZ3_dW3 = A2
    dZ3_dB3 = 1
    dZ3_dA2 = W3
    
    dA2_dZ2 = d_relu(Z2)
    dZ2_dW2 = A1
    dZ2_dB2 = 1
    dZ2_dA1 = W2
    
    dA1_dZ1 = d_relu(Z1)
    dZ1_dW1 = X
    dZ1_dB1 = 1
    
    dC_dW3 = dC_dA3 @ dA3_dZ3 @ dZ3_dW3.T
    dC_dB3 = dC_dA3 @ dA3_dZ3 * dZ3_dB3
    dC_dA2 = dC_dA3 @ dA3_dZ3 @ dZ3_dA2
    dC_dW2 = dC_dA2 @ dA2_dZ2 @ dZ2_dW2.T
    dC_dB2 = dC_dA2 @ dA2_dZ2 * dZ2_dB2
    dC_dA1 = dC_dA2 @ dA2_dZ2 @ dZ2_dA1 # 问题就在这里
    dC_dW1 = dC_dA1 @ dA1_dZ1 @ dZ1_dW1.T
    dC_dB1 = dC_dA1 @ dA1_dZ1 * dZ1_dB1
    
    返回 dC_dW1、dC_dB1、dC_dW2、dC_dB2、dC_dW3、dC_dB3

数据 = pd.read_csv(&#39;light_dark_font_training_set.csv&#39;)
x = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3)

n = x_train.shape[0]
L = 0.05
纪元 = 100_000

对于范围内的 i（纪元）：

    idx = np.random.choice(n, 1, 替换=False)
    x_sample = x_train[idx].transpose()
    y_样本 = y_train[idx]
    
    z1、a1、z2、a2、z3、a3 =forward_prop(x_sample)
    w1, b1, w2, b2, w3, b3 = back_prop(z1, a1, z2, a2, z3, a3, x_sample, y_sample)
    
    W1 -= 长*w1
    W2 -= 长*w2
    W3 -= 长*w3
    
    B1 -= L*b1
    B2 -= L*b2
    B3 -= L*b3
    
    如果 i%10000 == 0:
        打印（一）

当我尝试运行上述程序时，它显示以下值错误，这表明矩阵维度与矩阵乘法不匹配。起初我以为我在反向传播中的偏导数方面遇到了一些问题，但就我的知识而言，它对我来说看起来很好。
为什么会发生这种情况以及如何解决？
&lt;小时/&gt;
ValueError Traceback（最近一次调用最后一次）
 中的 ~\AppData\Local\Temp/ipykernel_11036/3060626554.py
      6
      7 z1, a1, z2, a2, z3, a3 =forward_prop(x_sample)
----&gt; 8 w1, b1, w2, b2, w3, b3 = back_prop(z1, a1, z2, a2, z3, a3, x_sample, y_sample)
      9
     10 W1 -= 长*w1

~\AppData\Local\Temp/ipykernel_11036/566612658.py in back_prop(Z1, A1, Z2, A2, Z3, A3, X, Y)
     22 dC_dW2 = dC_dA2 @ dA2_dZ2 @ dZ2_dW2.T
     23 dC_dB2 = dC_dA2 @ dA2_dZ2 * dZ2_dB2
---&gt; 24 dC_dA1 = dC_dA2 @ dA2_dZ2 @ dZ2_dA1#问题就在这里
     25 dC_dW1 = dC_dA1 @ dA1_dZ1 @ dZ1_dW1.T
     26 dC_dB1 = dC_dA1 @ dA1_dZ1 * dZ1_dB1

ValueError: matmul: 输入操作数 1 的核心维度 0 不匹配，gufunc 签名为 (n?,k),(k,m?)-&gt;(n?,m?)（大小 2 与 1 不同）
]]></description>
      <guid>https://stackoverflow.com/questions/77671165/matrix-multiplication-error-when-i-tried-to-build-the-neural-network-from-scratc</guid>
      <pubDate>Sat, 16 Dec 2023 13:56:10 GMT</pubDate>
    </item>
    <item>
      <title>从时态和非时态数据进行预测[关闭]</title>
      <link>https://stackoverflow.com/questions/77667561/making-predictions-from-temporal-and-non-temporal-data</link>
      <description><![CDATA[我正在研究一个回归问题来预测由 2 个参数组成的目标。这两个参数将根据时间 (YYYY-MM-DD HH:MM) 和非时间数据组成的特征进行预测。
我开始基于“决策树回归”构建 Python 代码算法。尽管数据趋势看起来令人满意，但我的模型似乎产生了与用于训练/测试的数据范围相同的输出。我想知道我的方法好不好。我偶然发现了一些处理相同问题的论文，并使用 CNN-LSTM 模型等进行了解决。这里是我的代码（Google Colab 文件）的链接： https:// drive.google.com/file/d/1ar5Z8kMXx_9slc1e_MMzaAcQAvx5lmzr/view?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/77667561/making-predictions-from-temporal-and-non-temporal-data</guid>
      <pubDate>Fri, 15 Dec 2023 16:25:51 GMT</pubDate>
    </item>
    <item>
      <title>与自然语言处理相关的代码执行错误</title>
      <link>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</link>
      <description><![CDATA[此代码显示了图像中给出的错误。我无法理解其中的原因。
导入系统
断言 sys.version_info[0]==3
断言 sys.version_info[1] &gt;= 5

从平台导入 python_version
assert int(python_version().split(&quot;.&quot;)[1]) &gt;= 5, &quot;请按照\中的说明升级您的Python版本
    在与此笔记本相同的目录中找到 README.txt 文件。您的 Python 版本是“ + python_版本()

从 gensim.models 导入 KeyedVectors
从 gensim.test.utils 导入数据路径
导入打印件
将 matplotlib.pyplot 导入为 plt
plt.rcParams[&#39;figure.figsize&#39;] = [10, 5]

导入nltk
nltk.download(&#39;reuters&#39;) #指定下载位置，可选添加参数：download_dir=&#39;/specify/desired/path/&#39;
从 nltk.corpus 导入路透社

将 numpy 导入为 np
随机导入
将 scipy 导入为 sp
从 sklearn.decomposition 导入 TruncatedSVD
从 sklearn.decomposition 导入 PCA

START_TOKEN = &#39;&#39;
END_TOKEN = &#39;&#39;

np.随机.种子(0)
随机种子(0)

错误消息：
&lt;块引用&gt;
[nltk data]加载路透社时出错：

我不知道如何在Python中使用导入命令。我尝试了所有可能的方法进行检查，包括删除带有其他新闻门户名称的“路透社”，但没有任何效果。现在，如果有人帮助我正确编写代码的“导入”部分，那就更好了。我认为其他部分没问题，因为没有显示其他消息。]]></description>
      <guid>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</guid>
      <pubDate>Wed, 13 Dec 2023 12:07:23 GMT</pubDate>
    </item>
    </channel>
</rss>