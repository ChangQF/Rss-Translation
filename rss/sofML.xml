<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 May 2024 12:27:11 GMT</lastBuildDate>
    <item>
      <title>如何将多个观测值拟合到单个高斯过程</title>
      <link>https://stackoverflow.com/questions/78554891/how-to-fit-a-multiple-observations-to-single-gaussian-process</link>
      <description><![CDATA[我试图将多个观测值拟合到单个高斯过程。
如果我尝试像这样拟合两个观测值 (Y) 的数据，
import numpy as np

from sklearn.gaussian_process import GaussianProcessRegressor

from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

# 示例数据

# 输入数据 X 

X = np.array([[1.0], [2.0], [3.0], [4.0], [5.0]])

# 输出数据 Y 

Y = np.array([[1.5, 2.5], [2.5, 3.5], [3.5, 4.5], [4.5, 5.5], [5.5, 6.5]])

kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))

gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)

# 拟合模型

gp.fit(X, Y)

mean_prediction, cov_prediction = gp.predict(X, return_cov=True)


我得到了两个 mean_prediction 数组和两个 cov_prediction 矩阵。但我想要一个与单个拟合 GP 对应的观测值相同维度的单个均值和协方差矩阵。我该如何实现它。
感谢您的时间和考虑。]]></description>
      <guid>https://stackoverflow.com/questions/78554891/how-to-fit-a-multiple-observations-to-single-gaussian-process</guid>
      <pubDate>Thu, 30 May 2024 12:16:10 GMT</pubDate>
    </item>
    <item>
      <title>如何正确计算图像和文本嵌入之间的余弦相似度以检索结果</title>
      <link>https://stackoverflow.com/questions/78554528/how-to-correctly-compute-cosine-similarity-between-image-and-text-embeddings-for</link>
      <description><![CDATA[我在图像-文本对上训练了一个对比学习模型，现在我想根据图像检索最相似的文本。为此，我使用预训练的图像和文本编码器生成测试图像（嵌入）和测试文本（嵌入）。
然后我想测量每个文本和所有图像嵌入之间的余弦相似度，如下所示
**images = (i1, i2, i3) text = (t1,t2, t3)**

**余弦相似度 = [(t1,i1),(t1, i2), (t1, i3)], [(t2, i1), (t2, i2), (t2, i3)], [(t3, i1), (t3, i2), (t3, i3)]****

使用此代码 

image_embeddings = [loaded_global_vision_encoder(image) for image in test_images]

# 生成查找嵌入
finding_embeddings = [loaded_finding_encoder(tf.convert_to_tensor([finding])) for finding in test_findings]`

# 计算图像和查找嵌入之间的余弦相似度

cosine_similarities = []
for finding_emb in finding_embeddings:
similarities = [tf.keras.losses.cosine_similarity(finding_emb, image_emb, axis=-1) for image_emb in image_embeddings]
cosine_similarities.append(similarities)

然后我找到相似度得分最高的前 1 对，如下所示 

**image_embeddings = [
[0.1, 0.2, 0.3],
[0.4, 0.5, 0.6],
]**

**finding_embeddings = [
[0.3, 0.4, 0.5],
[0.6, 0.7, 0.8]
]**

对于第一个发现的嵌入 [0.3, 0.4, 0.5]：
余弦相似度：

**- 使用 [0.1, 0.2, 0.3]：0.9746**

**- 使用 [0.4, 0.5, 0.6]：0.9873**

对于第二个发现的嵌入 [0.6, 0.7, 0.8]：
余弦相似度：

**- 使用 [0.1, 0.2, 0.3]：0.8847**

**- 使用 [0.4, 0.5, 0.6]：0.9603**

步骤 2：找到前 k 个最相似的图像索引
假设 k = 2
对于第一个发现的嵌入 [0.3, 0.4, 0.5]:

**前 2 个最相似的图像索引：[3, 1]**

对于第二个发现嵌入 [0.6, 0.7, 0.8]:

**前 2 个最相似的图像索引：[2, 4]**

**results = [
[3, 1],
[2, 4],
]
**

使用此代码

```
k = 1
results = [tf.math.top_k(similarities, k).indices.numpy() for similarities in cosine_similarities]
```

所以现在我完全不知道这个检索部分，我对此非常困惑。我的代码如下 

```
predict_reports = [[test_findings[int(idx)] for idx in indices] for indices in results]
```

我认为它是这样工作的

```
test_findings = [
&quot;无急性心肺过程。&quot;,
&quot;心脏大小正常。无局灶性气腔疾病或积液。&quot;,
&quot;肺容量低。无急性发现。&quot;,
&quot;肺部清晰。无胸腔积液或气胸。&quot;,
&quot;胸椎退行性变化。&quot;
]

results = [
[3, 1],
[2, 4],
[0, 3]
]

predict_reports = [
[
&quot;肺部清晰。无胸腔积液或气胸。&quot;,
&quot;心脏大小正常。无局灶性气腔疾病或积液。&quot;
],
[
&quot;肺容量低。无急性发现。&quot;,
&quot;胸椎退行性变化。&quot;
],
[
&quot;无急性心肺过程。&quot;,
&quot;肺部清晰。无胸腔积液或气胸。&quot;
]
]

```

如果它以我解释的方式工作，那么我会很高兴，因为我对使用这种检索方式的结果不满意，但是我很想知道我对此代码的概念是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/78554528/how-to-correctly-compute-cosine-similarity-between-image-and-text-embeddings-for</guid>
      <pubDate>Thu, 30 May 2024 10:57:43 GMT</pubDate>
    </item>
    <item>
      <title>Android 上的随机森林</title>
      <link>https://stackoverflow.com/questions/78554436/random-forest-on-android</link>
      <description><![CDATA[如何使用 CSV 数据在 Android 上使用机器学习随机森林。数据以表格形式呈现，时间段为 2023 年至 2017 年，每年从第 1 个月到第 12 个月。
给我一个教程。
完美完成，没有错误。]]></description>
      <guid>https://stackoverflow.com/questions/78554436/random-forest-on-android</guid>
      <pubDate>Thu, 30 May 2024 10:37:30 GMT</pubDate>
    </item>
    <item>
      <title>如何处理 KNN 中的列？</title>
      <link>https://stackoverflow.com/questions/78554214/how-to-deal-with-columns-in-knn</link>
      <description><![CDATA[目前，我正在学习 ML，从 K 邻居分类开始，我想知道如何处理给我的所有参数（列）。我只有 1 个包含 10k 行的数据集，我将其拆分为 80/20。我在另一个 csv 中也有测试数据（没有 y）。
但困扰我的是，我在学习时只能获得约 78% 的准确率，我想知道如何才能提高我的结果。查看列时，我对这些列特别有一些疑问：
第一个数据集包含 2 个不同的组，而测试数据包含均匀分布的点
与第一张图片相反的情况
与其他列相同
有些奇怪
我应该删除它们吗，还是应该尝试对它们做些什么以在我的训练中使用它们数据？
此外，目前，我不明白为什么我的模型使用 metric=&#39;manhattan&#39; 而不是 euclidean 效果更好，以及如何使用测试/训练数据选择最佳 K。我读到你应该使用 sqrt(N)，其中 N 是测试行数，但事实真的如此吗？
训练/测试数据]]></description>
      <guid>https://stackoverflow.com/questions/78554214/how-to-deal-with-columns-in-knn</guid>
      <pubDate>Thu, 30 May 2024 09:51:40 GMT</pubDate>
    </item>
    <item>
      <title>我正在加载鸢尾花数据集，但出现错误，提示不允许使用重复的名称，我甚至尝试更改名称，但又出现另一个错误</title>
      <link>https://stackoverflow.com/questions/78554157/i-was-loading-the-iris-dataset-but-there-is-an-error-where-it-says-duplicate-na</link>
      <description><![CDATA[url= &quot;https://archive.ics.uci.edu/ml/machine-learning-databases/iris.data&quot;
names = [&#39;sepal-length&#39;,&#39;sepal-width&#39;,&#39;petal-length&#39;,&#39;petal-width&#39;,&#39;petal-width&#39;,&#39;class&#39;] 
dataset = pandas.read_csv(url, names = names)


ValueError: 不允许重复的名称。

我原本期待这个输出，但却出现了错误]]></description>
      <guid>https://stackoverflow.com/questions/78554157/i-was-loading-the-iris-dataset-but-there-is-an-error-where-it-says-duplicate-na</guid>
      <pubDate>Thu, 30 May 2024 09:42:33 GMT</pubDate>
    </item>
    <item>
      <title>特征提取 + 逻辑回归 与 特征提取 + softmax 密集层的区别</title>
      <link>https://stackoverflow.com/questions/78553888/differences-on-features-extraction-logistic-regression-vs-features-extraction</link>
      <description><![CDATA[我有一个用于分类问题的小型图像数据库，因此我选择迁移学习方法。我从 Tensorflow 中的经典方法开始：

在 ImageNet 数据库上预训练的 ResNet50
GlobalMaxPooling2D 层
具有 softmax 激活函数的类数的密集层
使用 Adam 编译器、交叉熵损失和准确率作为指标进行编译。

然后我需要优化超参数，例如批量大小和时期。
一段代码是
将 tensorflow 导入为 tf
数据 = 加载并预处理您的数据
输入 = tf.keras.Input(shape=(None, None, 3))
x= base_resnet(x)
输出 = tf.keras.layers.GlobalMaxPooling2D()(x)
extractor = tf.keras.Model(inputs, output)
x = tf.keras.layers.Dense(nClasses)(x)
outputs = tf.keras.layers.Activation(activation=&quot;softmax&quot;, dtype = &#39;float32&#39;)(x)
model = tf.keras.Model(inputs, output)
model.compile(optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;], loss = &quot;categorical_crossentropy&quot;)

超参数优化之后我会做的
model.fit(...)
model.evaluate(...)

也许是哥伦布蛋，但我已经尝试了提取特征方法加上逻辑回归scikit-learn。
代码片段如下：
from sklearn.linear_model import LogisticRegression

x= base_resnet(x)
outputs = tf.keras.layers.GlobalMaxPooling2D()(x)
extractor = tf.keras.Model(inputs, output)
features = extractor.predict(data) # features extractor

# logistic 回归
log_reg = LogisticRegression(max_iter=500)
log_reg.fit(features, y)

log_reg.predict(features_test)

我在这两种方法中都获得了几乎相同的良好性能（测试集上的准确率接近 91%），但第二种方法快了 10 倍。我遗漏了什么吗？我的方法正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/78553888/differences-on-features-extraction-logistic-regression-vs-features-extraction</guid>
      <pubDate>Thu, 30 May 2024 08:47:43 GMT</pubDate>
    </item>
    <item>
      <title>在经过训练的 LSTM 模型中，使用较大的窗口大小无法获得任何预测</title>
      <link>https://stackoverflow.com/questions/78553585/not-getting-any-predictions-with-higher-window-size-in-trained-lstm-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78553585/not-getting-any-predictions-with-higher-window-size-in-trained-lstm-model</guid>
      <pubDate>Thu, 30 May 2024 07:50:34 GMT</pubDate>
    </item>
    <item>
      <title>平均准确率</title>
      <link>https://stackoverflow.com/questions/78553088/average-precision-score</link>
      <description><![CDATA[GridSearchCV 给出的每次折叠的平均精度得分与我使用相同分割使用 for 循环计算平均精度得分获得的得分不同。
平均精度得分
它们是否以 Sklearn 指南中提到的两种不同方式计算？
在此处输入图像描述
我尝试使用 GridSearchCV 中使用的相同分割来计算平均精度得分，但 GridSearchCv.cv_results_ 的结果更高。]]></description>
      <guid>https://stackoverflow.com/questions/78553088/average-precision-score</guid>
      <pubDate>Thu, 30 May 2024 05:49:52 GMT</pubDate>
    </item>
    <item>
      <title>由于 decision_function，使用 roc_auc 度量的 KNeighborsClassifier 的 GridSearchCV 和 cross_val_score 返回错误</title>
      <link>https://stackoverflow.com/questions/78552800/gridsearchcv-and-cross-val-score-with-kneighborsclassifier-using-roc-auc-metric</link>
      <description><![CDATA[我正在研究二元分类问题。
类别分布为位置：30% - 负面：70%。因此，我决定使用 roc_auc 作为度量标准
然后，我在 KNeighborsClassifier 上运行超参数调整，但出现错误，我不知道如何解决
我使用的 scikit-learn 版本是 &#39;1.2.2&#39;
这是代码
param_grid = [ 
{
&#39;knn__n_neighbors&#39;: np.arange(2, 30, 1),
&#39;knn__weights&#39; : [&#39;uniform&#39;, &#39;distance&#39;],
&#39;knn__algorithm&#39; : [&#39;auto&#39;, &#39;ball_tree&#39;, &#39;kd_tree&#39;],
&#39;knn__leaf_size&#39;: np.arange(30, 1000, 20)
}
]

knn = Pipeline([
(&quot;preprocessing&quot;, preprocessing),
(&quot;knn&quot;, KNeighborsClassifier())
])

grid_search = GridSearchCV(
knn,
param_grid,
cv=cv,
scoring=&quot;roc_auc&quot;,
verbose=0
)
grid_search.fit(x_train, y_train)
grid_search.best_params_

错误是
/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: 评分失败。此训练测试分区中这些参数的分数将设置为 nan。详细信息：
回溯（最近一次调用）：
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 373 行，在 _score 中
y_pred = method_caller(clf, “decision_function”, X)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 73 行，在 _cached_call 中
返回 getattr(estimator, method)(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件&quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_available_if.py&quot;, line 32, in __get__
if not self.check(obj):
^^^^^^^^^^^^^^^
File &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py&quot;, line 46, in check
getattr(self._final_estimator, attr)
AttributeError: &#39;KNeighborsClassifier&#39; object has no attribute &#39;decision_function&#39;

在处理上述异常时，发生了另一个异常：

它说 KNeighborsClassifier 没有属性 decision_function
经过一些阅读，我明白了 decision_function 在度量标准为roc_auc
现在，即使存在此问题，如何运行超参数调整？
此外，即使在使用 KNeighborsClassifier 和 roc_auc 作为指标运行时，cross_val_score 也会返回 nan
knn = Pipeline([
(&quot;preprocessing&quot;, preprocessing),
(&quot;knn&quot;, KNeighborsClassifier(
algorithm=&#39;auto&#39;,
leaf_size=30,
metric=&#39;minkowski&#39;,
n_neighbors=28,
weights=&#39;uniform&#39;
))
])
scores = cross_val_score(knn, x_train, y_train, cv=cv)
scores

错误是
/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: 评分失败。此训练测试分区中这些参数的分数将设置为 nan。详细信息：
回溯（最近一次调用）：
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 117 行，在 __call__ 中
score = scorer(estimator, *args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 444 行，在 _passthrough_scorer 中
返回 estimator.score(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件&quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py&quot;，第 722 行，在分数中
返回 self.steps[-1][1].score(Xt, y, **score_params)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py&quot;，第 668 行，在分数中
返回 accuracy_score(y, self.predict(X), sample_weight=sample_weight)
^^^^^^^^^^^^^^^^^
文件 &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py&quot;，第234，在预测中
neigh_ind = self.kneighbors(X, return_distance=False)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py&quot;，第 824 行，在 kneighbors 中
results = ArgKmin.compute(

现在由 predict() 完成]]></description>
      <guid>https://stackoverflow.com/questions/78552800/gridsearchcv-and-cross-val-score-with-kneighborsclassifier-using-roc-auc-metric</guid>
      <pubDate>Thu, 30 May 2024 04:00:25 GMT</pubDate>
    </item>
    <item>
      <title>理解环境中的形状</title>
      <link>https://stackoverflow.com/questions/78552788/understanding-shapes-in-enviroment</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78552788/understanding-shapes-in-enviroment</guid>
      <pubDate>Thu, 30 May 2024 03:52:57 GMT</pubDate>
    </item>
    <item>
      <title>GCP 上的 AI 平台：持续出现“当前尝试发生内部错误。”错误</title>
      <link>https://stackoverflow.com/questions/78552412/ai-platform-on-gcp-persistent-internal-error-occurred-for-the-current-attempt</link>
      <description><![CDATA[大约一周前，我每次向 Google 的 AI 平台提交作业时都会不断收到此错误：当前尝试发生内部错误。。在作业终止之前，每个作业都会重复此错误 3 次。我尝试在使用时更改区域
gcloud ai-platform jobs submit training

命令，但无济于事。同时，当我运行
gcloud computeregionslist

每个区域的状态都是“UP”。就目前而言，AI 平台对我来说完全无法使用。我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/78552412/ai-platform-on-gcp-persistent-internal-error-occurred-for-the-current-attempt</guid>
      <pubDate>Thu, 30 May 2024 00:35:03 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SHAP 值来分组特征重要性？</title>
      <link>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-grouped-feature-importance</link>
      <description><![CDATA[我做什么：
我借助不同的机器学习算法和不同的预处理步骤等分析来自 EEG 数据的不同生物标志物。这为每种预处理步骤和算法的组合产生了多个模型。
每个模型都使用 StratifiedGroupKFold 进行训练，总共 6 个折叠。
每个折叠都保存为作业库，即 .joblib
生物标志物：
EEG 信号的每个波段都有许多生物标志物。这些生物标志物又由来自 EEG 所有电极的所有信号组成。因此，生物标志物由多个特征组成，这些特征不能分开（每个生物标志物必须包含所有电极数据）。
我想做什么：
在我的第一种方法中，我用所有生物标志物训练了每个模型。现在我想使用特征重要性来确定是否可以省略其中一些。
为此，我想研究每个预处理步骤和每个模型。
有人向我推荐 SHAP，但我的问题是我不知道如何总结每个生物标志物的通道。
编辑：
在这篇论文的帮助下，我终于总结了折叠。但我仍然不明白如何总结每个生物标志物的通道。
新代码：
for r, fold_file in enumerate(fold_files):
model = joblib.load(fold_file)

fold_splits = list(sgkf.split(X, y, groups))

for train_index, test_index in fold_splits:
X_train, X_test = X.iloc[train_index], X.iloc[test_index]
y_train, y_test = y.iloc[train_index], y.iloc[test_index]

explainer = shap.Explainer(model, X_train)
train_shap_values = explainer(X_train)
test_shap_values = explainer(X_test)

for i in range(len(train_index)):
train_folds_shap_values[train_index[i]] += train_shap_values.values[i] / (len(fold_splits) - 1)
for i in range(len(test_index)):
test_folds_shap_values[test_index[i]] += test_shap_values.values[i]

average_train_folds_shap_values = train_folds_shap_values / R
average_test_folds_shap_values = test_folds_shap_values / R

train_shap_df = pd.DataFrame(average_train_folds_shap_values, columns=columns)
test_shap_df = pd.DataFrame(average_test_folds_shap_values, columns=columns)


我第一次尝试它就像这个：
grouped_features = group_features(columns, biomarker_names, bands)

defaggregate_shap_values(shap_df, grouped_features):
aggregated_shap_values = pd.DataFrame()
for group, features in grouped_features.items():
aggregated_shap_values[group] = shap_df[features].sum(axis=1)
returnaggregated_shap_values

train_aggregated_shap_df =aggregate_shap_values(train_shap_df, grouped_features)

test_aggregated_shap_df =aggregate_shap_values(test_shap_df, grouped_features)

shap.summary_plot(train_aggregated_shap_df.values, feature_names=train_aggregated_shap_df.columns.tolist())

但它看起来……不对。我忽略了重要性之间的区别。
分组：

未分组：

提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-grouped-feature-importance</guid>
      <pubDate>Wed, 29 May 2024 06:28:02 GMT</pubDate>
    </item>
    <item>
      <title>YoloV8 结果中没有 'box'、'max' 属性</title>
      <link>https://stackoverflow.com/questions/78547320/yolov8-results-have-no-box-max-properties-in-it</link>
      <description><![CDATA[我已经训练了一个 YOLOV8 模型来识别十字路口的物体（即汽车、道路等）。
它工作正常，我可以将输出作为图像，其中包含感兴趣的分段对象。
但是，我需要做的是捕获原始几何图形（多边形），以便以后可以将它们保存在 txt 文件中。
我尝试了在文档中找到的内容（https://docs.ultralytics.com/modes/predict/#key-features-of-predict-mode）但返回的对象与文档所述不同。
实际上，结果是 TensorFlow 数字列表：

这是我的代码：
import argparse
import cv2
import numpy as np
from pathlib import Path
from ultralytics.yolo.engine.model import YOLO 

# 解析命令行参数
parser = argparse.ArgumentParser()
parser.add_argument(&#39;--source&#39;, type=str, required=True, help=&#39;源图像目录或文件&#39;)
parser.add_argument(&#39;--output&#39;, type=str, default=&#39;output&#39;, help=&#39;输出目录&#39;)
args = parser.parse_args()

# 如果不存在则创建输出目录
Path(args.output).mkdir(parents=True, exist_ok=True)

# 模型路径
model_path = r&#39;C:\\_Projects\\best_100img.pt&#39;

# 直接加载模型
model = YOLO(model_path)
model.fuse()

# 加载图像
if Path(args.source).is_dir():
image_paths = list(Path(args.source).rglob(&#39;*.tiff&#39;))
else:
image_paths = [args.source]

# 处理每幅图像
for image_path in image_paths:
img = cv2.imread(str(image_path))
if img is None:
continue

# 执行推理
predictions = model.predict(image_path, save=True, save_txt=True)

print(&quot;处理完成。&quot;)

问题在于：返回对象（预测变量）没有框、掩码、关键点和等等。
我想我的问题是：

为什么结果与文档如此不同？
是否有转换步骤？
]]></description>
      <guid>https://stackoverflow.com/questions/78547320/yolov8-results-have-no-box-max-properties-in-it</guid>
      <pubDate>Wed, 29 May 2024 04:32:01 GMT</pubDate>
    </item>
    <item>
      <title>A3C 代理（连续动作空间）没有得到适当的训练，只能达到</title>
      <link>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</guid>
      <pubDate>Sat, 25 May 2024 05:21:08 GMT</pubDate>
    </item>
    <item>
      <title>即使按照示例 3 的文档代码操作，PyKan 代码仍然不起作用：分类</title>
      <link>https://stackoverflow.com/questions/78451382/pykan-code-not-working-even-after-following-the-documentation-code-for-example-3</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78451382/pykan-code-not-working-even-after-following-the-documentation-code-for-example-3</guid>
      <pubDate>Wed, 08 May 2024 22:17:49 GMT</pubDate>
    </item>
    </channel>
</rss>