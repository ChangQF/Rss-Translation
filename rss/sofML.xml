<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 28 Jun 2024 03:18:02 GMT</lastBuildDate>
    <item>
      <title>在 Python 中自动选择感兴趣的区域[关闭]</title>
      <link>https://stackoverflow.com/questions/78679950/automatically-select-the-region-of-interest-in-python</link>
      <description><![CDATA[我正在从事一个光学项目，我需要根据一组照片提取感兴趣区域 (ROI)，该组照片由 32 张旋转正方形的照片组成。我找到了一种通过计算整组照片的方差来找到感兴趣区域的方法，如下所示

但现在我需要一种方法来实际提取它并仅针对该区域计算该区域中像素的平均强度。如果有一种方法可以告诉 Python“只获取由这条较暗的线界定的区域内像素的所有值”那就太好了，但我一直找不到如何做到这一点。我发现了一些使用 OpenCV 的实现，但它需要用户交互，我最想避免这部分。还请注意，这不是一个完美的圆形，所以我可以毫无问题地使用较小的圆形区域 - 由程序自动选择 - 但如果也有办法避免这种情况，那就太好了。
你有什么建议吗？文档、文章、示例、一些库、一些我自己实现的算法、一些机器学习方法/算法（这会非常好）来识别和提取区域？根据您的经验，可以完成这项工作的东西。]]></description>
      <guid>https://stackoverflow.com/questions/78679950/automatically-select-the-region-of-interest-in-python</guid>
      <pubDate>Thu, 27 Jun 2024 21:58:28 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地对自定义数据运行 llama3</title>
      <link>https://stackoverflow.com/questions/78679786/how-to-run-llama3-on-custom-data-locally</link>
      <description><![CDATA[我已经使用 Ollama 在我的 PC 上本地设置了 llama3，我有一个包含 aet if 定律的文件，我希望 llama 读取该文件，以便根据其中的定律回答问题。关于如何做到这一点，有什么想法吗？？？]]></description>
      <guid>https://stackoverflow.com/questions/78679786/how-to-run-llama3-on-custom-data-locally</guid>
      <pubDate>Thu, 27 Jun 2024 20:58:36 GMT</pubDate>
    </item>
    <item>
      <title>制作 ML 模型：函数或类 [关闭]</title>
      <link>https://stackoverflow.com/questions/78679773/making-ml-models-functions-or-classes</link>
      <description><![CDATA[我正在构建一个模型，我想获得一些反馈。将模型创建为函数（例如 def model_1）还是类（class Model1:）更好？一种方法是否优于另一种方法？
我创建了几个模型，但它们都是类而不是函数]]></description>
      <guid>https://stackoverflow.com/questions/78679773/making-ml-models-functions-or-classes</guid>
      <pubDate>Thu, 27 Jun 2024 20:54:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 sklearn 的 GradientBoostingClassifier 进行多类分类的指数损失</title>
      <link>https://stackoverflow.com/questions/78679151/exponential-loss-for-multiclass-classification-with-sklearns-gradientboostingcl</link>
      <description><![CDATA[我正在处理一个非常不平衡的多类分类问题，并尝试使用 sklearn 的 GradientBoostingClassifier 作为我的模型。从文档这里，我可以看到唯一可用的损失函数是“对数损失”和“指数”。从我的研究中，我发现指数损失对于负值呈指数增长，这使其对异常值更加敏感。这让我认为它在对我的少数类进行分类方面会比对数损失更好，对数损失对于负值呈线性增长。但是，当我尝试使用指数损失时，我得到了错误

ValueError：ExponentialLoss 需要 2 个类；得到 55 个类别

显示，我无法将指数损失用于多类分类问题。从这篇论文来看，似乎完全可以将指数损失用于多类分类——所以我很好奇为什么这个模型无法使用指数损失。
我应该坚持使用对数损失吗？我应该改变模型吗？为什么我不能将指数损失用于多个类别？任何答案都将不胜感激！我正在尝试进一步了解这个模型]]></description>
      <guid>https://stackoverflow.com/questions/78679151/exponential-loss-for-multiclass-classification-with-sklearns-gradientboostingcl</guid>
      <pubDate>Thu, 27 Jun 2024 17:40:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python sdk v2 在 Azure ML for Pipeline 中加载已注册的组件</title>
      <link>https://stackoverflow.com/questions/78679016/load-registered-component-in-azure-ml-for-pipeline-using-python-sdk-v2</link>
      <description><![CDATA[我正在 Azure 机器学习工作室中创建将在管道中一起运行的组件。在这个基本示例中，我有一个 python 脚本和一个 yml 文件，它们构成了我的组件，还有一个用于定义、实例化和运行管道的笔记本。请参阅下面此组件的文件夹结构概述。
📦component
┣ 📜notebook.ipynb
┣ 📜component_script.py
┗ 📜component_def.yml

然后，在我的笔记本中，我可以使用下面的代码加载组件并将其注册到工作区（请注意，这里我已经实例化了我的 ml_client 对象）。
# 导入组件包
from azure.ai.ml import load_component

# 从 yml 文件加载组件
component = load_component(&quot;component_def.yml&quot;)

# 现在我们将组件注册到工作区
component = ml_client.create_or_update(component)

然后我可以成功地将此组件传递到管道中。我的问题是，既然我已经注册了组件，我就不再需要使用 component = load_component(&quot;component_def.yml&quot;) 来实例化我的组件对象，这需要访问 yml 文件。我应该能够从已注册的组件实例化我的组件对象。我该怎么做？我看到很多关于如何注册组件的 Microsoft 文档，但没有关于如何在注册后使用它们的文档。]]></description>
      <guid>https://stackoverflow.com/questions/78679016/load-registered-component-in-azure-ml-for-pipeline-using-python-sdk-v2</guid>
      <pubDate>Thu, 27 Jun 2024 17:10:34 GMT</pubDate>
    </item>
    <item>
      <title>无论训练期间输入值和权重值有何不同，模型都会预测相同的值</title>
      <link>https://stackoverflow.com/questions/78678671/model-is-predicted-same-value-irrespective-of-different-input-values-and-differe</link>
      <description><![CDATA[我设法从网络资源中实施了深度进化策略。我希望我的模型能够预测在 STAY (0)、BUY (1)、SELL (2) 中的任何一个决定。
为此，我提供了 BankNifty 的 72 OHLC 5 分钟数据，除此之外，我还提供了下面列出的其他特征数据值。
DayWiseFeature：

currentDayOpen
previousDayOpen
previousToPreviousDayOpen
previousDayHigh，
previousToPreviousDayHigh，
previousDayLow，
previousToPreviousDayLow，
previousDayClose，
previousToPreviousDayClose，
当前日枢轴点，
前一天枢轴点，
当前日阻力位1
前一天阻力位1
当前日阻力位2
前一天阻力位2
当前日阻力位3
前一天阻力位3
当前日支撑位级别 1
上一天支持级别 1
当前一天支持级别 2
上一天支持级别 2
当前一天支持级别 3
上一天支持级别 3

WeekWiseFeatures：

当前一周开放
上一周开放
上一周至上一周开放
上一周最高价，
上一周最高价至上一周最高价，
上一周最低价，
上一周最低价至上一周最低价，
上一周收盘价，
上一周收盘价至上一周收盘价，
当前周枢轴水平，
上一周枢轴水平，
当前周阻力位 1
上一周阻力位 1
当前周阻力位 2
上一周阻力位 2
当前周阻力位 3
上一周阻力位 3
当前周支撑位 1
上一周支撑位 1
当前周支撑位 2
上一周支撑位 2
当前周支持级别3
上一周支持级别3

月度功能：

当前月开盘
上一月开盘
上一月上一月开盘
上一月最高价，
上一月上一月最高价，
上一月最低价，
上一月上月最低价，
上月收盘价，
上一月收盘价，
当前月枢轴点位，
上一月枢轴点位，
当前月阻力位 1
上一月阻力位 1
当前月阻力位 2
上一月阻力位 2 
currentMonthResistanceLevel3
previousMonthResistanceLevel3
currentMonthSupportLevel1
previousMonthSupportLevel1
currentMonthSupportLevel2
previousMonthSupportLevel2
currentMonthSupportLevel3
previousMonthSupportLevel3

因此，我的第一个输入层总共有 (4x72)+ (23*3) = 357 个输入。
有了这么多信息，如果我开始训练，经过几次（3 到 6 次）训练循环迭代后，剩余迭代的奖励点数相同。在进一步的迭代中没有任何改进。
当我调试此代码时，我发现，模型继续预测所有剩余迭代（或换句话说，所有不同的输入状态）的停留（0）。
因此，这意味着，模型仅对所有输入状态预测停留（0）（即使每次迭代的权重值不同）。
我可以说的另一个信息是，总共有 13708 个状态，其中，

1187 个状态对购买（1）行动有正奖励（1），对停留（0）或出售（2）行动有负奖励（-1）
1003 个状态对出售（2）行动有正奖励（1），对停留（0）或购买（1）行动有负奖励（-1）
11518 个状态有中性奖励(0) 表示 STAY (0) 操作，负奖励 (-1) 表示 BUY (1) 或 SELL (2) 操作。

注意：当我尝试仅使用 OHLC 数据而不使用其他特征时，我的模型可以正常工作，但准确性不佳，因此我仅添加了这些附加特征来提高准确性。但是在我的模型输入中添加这些附加特征后，我的模型并没有一直改善并预测相同的值 (STAY)，无论输入和权重如何不同（当然，根据 DES 策略，当前权重取决于每次迭代中的先前权重）
我已在此处附上我的笔记本和 bnf.csv 文件供您参考。
https://drive.google.com/drive/folders/13SDsY1O_TGTOOq27OMBCvWHc1Crs3UL9?usp=sharing
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78678671/model-is-predicted-same-value-irrespective-of-different-input-values-and-differe</guid>
      <pubDate>Thu, 27 Jun 2024 15:49:53 GMT</pubDate>
    </item>
    <item>
      <title>Oracle 机器学习（OML）df_datetime 给出“未选择任何列”错误</title>
      <link>https://stackoverflow.com/questions/78678402/oracle-machine-learning-oml-df-datetime-gives-no-columns-are-selected-error</link>
      <description><![CDATA[如果有人能帮忙，我遇到了一些编码问题！我试图从 oml.Dataframe df 中获取 Datetime 类型。我试过这个代码：
 df = oml.sync(query=QUERY)
df_datetime = df.select_types(include=[&#39;oml.Datetime&#39;])

但我收到一个错误，提示没有选择任何列。我是否错误地使用了此功能？
我找到了一种解决方法
 df = oml.sync(query=QUERY)
df_datetime = []
for col, dtype in df.dtypes.items():
if dtype.__name__ == &#39;Datetime&#39;:
df_datetime.append(col)

这确实返回了 Datetime 对象，所以我知道它们存在。如果可以的话，我更愿意使用 select_types 方法，如果有人能向我解释我做错了什么。]]></description>
      <guid>https://stackoverflow.com/questions/78678402/oracle-machine-learning-oml-df-datetime-gives-no-columns-are-selected-error</guid>
      <pubDate>Thu, 27 Jun 2024 14:52:10 GMT</pubDate>
    </item>
    <item>
      <title>React Native 中的图像背景去除器</title>
      <link>https://stackoverflow.com/questions/78677677/image-background-remover-in-react-native</link>
      <description><![CDATA[需要一个像remove.bg这样的图像背景去除器。如果有任何库建议或者我必须使用机器学习概念。
我试过这个库react-native-background-remover，但这个库只能去除人体背景。]]></description>
      <guid>https://stackoverflow.com/questions/78677677/image-background-remover-in-react-native</guid>
      <pubDate>Thu, 27 Jun 2024 12:31:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 Jax 的 vmap 函数在 LinkedLists 上实现矢量化函数</title>
      <link>https://stackoverflow.com/questions/78677115/implementing-a-vectorized-function-over-linkedlists-using-jax-s-vmap-function</link>
      <description><![CDATA[尝试使用 Jax 实现算法的矢量化版本（来自计算几何）。我使用 LinkedList 制作了最小工作示例来特别表达我的查询（否则我将使用 DCEL）。
这个想法是，这个矢量化算法将检查 DCEL 上的某些标准。为了简单起见，我用一个简单的求和算法代替了这个“标准检查程序”。

import jax
from jax import vmap
import jax.numpy as jnp

class Node: 

# 构造函数初始化节点对象 
def __init__(self, data): 
self.data = data 
self.next = None

class LinkedList: 

def __init__(self): 
self.head = None

def push(self, new_data): 
new_node = Node(new_data) 
new_node.next = self.head 
self.head = new_node 

def printList(self): 
temp = self.head 
while(temp): 
print (temp.data,end=&quot; &quot;) 
temp = temp.next

def summate(list) :
prev = None
current = list.head
sum = 0
while(current is not None): 
sum += current.data
next = current.next
current = next
return sum

list1 = LinkedList() 
list1.push(20) 
list1.push(4) 
list1.push(15) 
list1.push(85) 

list2 = LinkedList() 
list2.push(19)
list2.push(13)
list2.push(2)
list2.push(13)

#list(map(summate, ([list1, list2])))

vmap(summate)(jnp.array([list1, list2]))


我收到以下错误。
 TypeError: Value &#39;&lt;__main__.LinkedList object at 0x1193799d0&gt;&#39; dtype 为 object 的数组类型不是有效的 JAX 数组类型。JAX 仅支持数字类型的数组。
目标是，如果我有一组 10,000 个 Linkedlist，我应该能够以矢量化方式在每个 LinkedList 上应用此 summate 函数。我已经在基本 Python 中实现了我想要的功能，但我想在 Jax 中执行此操作，因为有一个更大的概率函数，我将使用此子过程（它是马尔可夫链）。
可能我完全无法在 Jax 上处理此类数据结构，因为错误表明仅支持数字类型。我可以使用 pytrees 以某种方式缓解此限制吗？
建议我使用 jnp 中的简单列表会很诱人，但我只是使用 Linkedlist 作为简单（st）数据结构的示例。如前所述，我实际上是在 DCEL 上工作。
PS：Linkedlist 代码取自 GeeksForGeeks，因为我想快速想出一个最小工作示例。]]></description>
      <guid>https://stackoverflow.com/questions/78677115/implementing-a-vectorized-function-over-linkedlists-using-jax-s-vmap-function</guid>
      <pubDate>Thu, 27 Jun 2024 10:39:40 GMT</pubDate>
    </item>
    <item>
      <title>我无法使用 FastAPI 运行使用 Tensorflow 保存的模型</title>
      <link>https://stackoverflow.com/questions/78674303/i-cannot-run-my-model-that-i-saved-with-tensorflow-with-fastapi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78674303/i-cannot-run-my-model-that-i-saved-with-tensorflow-with-fastapi</guid>
      <pubDate>Wed, 26 Jun 2024 19:25:44 GMT</pubDate>
    </item>
    <item>
      <title>无法运行 xgboost 导入 XGBRegressor [关闭]</title>
      <link>https://stackoverflow.com/questions/78672076/unable-to-run-xgboost-import-xgbregressor</link>
      <description><![CDATA[当我运行以下代码时，
from xgboost import XGBRegressor

我收到错误：
&gt; --------------------------------------------------------------------------- XGBoostError Traceback (most recent call
&gt; last) Cell In[64], line 19
&gt; 17 from sklearn.metrics import mean_squared_error
&gt; 18 from sklearn import metrics
&gt; ---&gt; 19 from xgboost import XGBRegressor File /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/__init__.py:6
&gt; 1 &quot;&quot;&quot;XGBoost: eXtreme Gradient Boosting library.
&gt; 2 
&gt; 3 贡献者：https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md
&gt; 4 &quot;&quot;&quot;
&gt; ----&gt; 6 来自 . import tracker # noqa
&gt; 7 来自 . import collective, dask
&gt; 8 来自 .core import (
&gt; 9 Booster,

我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78672076/unable-to-run-xgboost-import-xgbregressor</guid>
      <pubDate>Wed, 26 Jun 2024 11:17:02 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用 colsample_bytree 超参数时始终保留 XGBoost 中的某个特征</title>
      <link>https://stackoverflow.com/questions/78665326/how-to-always-keep-a-feature-in-xgboost-while-using-colsample-bytree-hyperparame</link>
      <description><![CDATA[我使用 XGBoost 来训练 ML 模型。如果我使用 colsample_bytree 超参数，XGBoost 会平等对待所有特征。我需要始终包含一个二进制特征，因为该特征决定了观察结果属于哪个子样本。其他特征应在训练期间随机包含，由 colsample_bytree 超参数决定。如何做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78665326/how-to-always-keep-a-feature-in-xgboost-while-using-colsample-bytree-hyperparame</guid>
      <pubDate>Tue, 25 Jun 2024 03:52:51 GMT</pubDate>
    </item>
    <item>
      <title>如何将 JSON 中的标记坐标叠加到 JPG 图像中以进行 CNN 训练？[关闭]</title>
      <link>https://stackoverflow.com/questions/78661583/how-to-overlay-labeled-coordinates-from-json-into-jpg-images-for-cnn-training</link>
      <description><![CDATA[我正在开展一个计算机视觉项目，该项目涉及检测和分割 MRI 扫描中的骨折。作为该项目的一部分，我让专家直接在图像上标记骨折区域。此过程会生成一个 JSON 文件，其中包含以下信息：

标记区域的坐标
标记区域的名称
标记图像的名称

我面临的挑战是将这些坐标从 JSON 文件转移到相应的 JPG 图像上，以准备进行 CNN 训练。
以下是我的 JSON 文件结构示例：
&quot;item&quot;: {
&quot;name&quot;: &quot;img-00003-00082.jpg&quot;,
&quot;team&quot;: {
&quot;name&quot;: &quot;Mask&quot;,
&quot;slug&quot;: &quot;mask&quot;
&quot;file_name&quot;: &quot;img-00003-00082.jpg&quot;,
&quot;annotations&quot;: [
{
&quot;bounding_box&quot;: {
&quot;h&quot;: 142.16649999999993,
&quot;w&quot;: 124.14549999999997,
&quot;x&quot;: 679.8006,
&quot;y&quot;: 425.7789
},
&quot;name&quot;: &quot;Broken&quot;,
&quot;polygon&quot;: {
&quot;paths&quot;: [
[
{
&quot;x&quot;: 695.1519,
&quot;y&quot;: 567.9454
},
{
&quot;x&quot;: 679.8006,
&quot;y&quot;: 530.5683
},


到目前为止，我已经设法从 JSON 文件中提取了必要的坐标。但是，我很难将这些坐标叠加到 JPG 图像上以生成 CNN 的训练数据。
我的问题：

如何准确地将 JSON 文件中的坐标叠加到相应的 JPG 图像上？
是否有任何推荐的 Python 库或方法专门适合此任务？
]]></description>
      <guid>https://stackoverflow.com/questions/78661583/how-to-overlay-labeled-coordinates-from-json-into-jpg-images-for-cnn-training</guid>
      <pubDate>Mon, 24 Jun 2024 09:29:08 GMT</pubDate>
    </item>
    <item>
      <title>重用特征来拆分回归决策树的节点</title>
      <link>https://stackoverflow.com/questions/67038993/reusing-a-feature-to-split-regression-decision-trees-nodes</link>
      <description><![CDATA[我看过一个关于回归树算法的视频，最后留下了一个小问题：当数据集中某个特征的残差平方和阈值较低时，该特征将用于分割节点（如果节点中的观测值数量大于某个预定义值）。但是，这个相同的特征可以再次用于分割树的这个分支的节点吗？或者这个分支的后续分割必须通过其他特征定义的阈值进行分割（即使已经分割其他节点的特征的残差平方和阈值较低）？
此外，我在研究决策树分类器时也有同样的疑问：如果一个已经在这个分支中使用过的特征可以分割出基尼不纯度值低于其他特征可以分割的节点的观测值，那么这个特征是否“已被使用”？功能是否允许执行拆分？
提前感谢您的关注！]]></description>
      <guid>https://stackoverflow.com/questions/67038993/reusing-a-feature-to-split-regression-decision-trees-nodes</guid>
      <pubDate>Sat, 10 Apr 2021 20:35:38 GMT</pubDate>
    </item>
    <item>
      <title>初始化权重后，scikit 学习分类器的准确率降低</title>
      <link>https://stackoverflow.com/questions/41804937/decreasing-accuracy-of-scikit-learn-classifier-after-initializing-weight</link>
      <description><![CDATA[我想基于 sklearn 分类器实现 adaboost 分类器，在算法分类器的第一步中我应该将权重初始化为&quot; 1 / # 训练数据&quot;
但这会降低分类器的准确率，我不知道为什么？ （我为所有数据点设置了相同的权重）
我的代码：
svm_weight = SVC()
svm_non_weight = SVC()

w = np.ones(len(target_train))
w.fill(float(1)/float(len(target_train)))
svm_weight.fit(data_train_feature_scaled_pca,
target_train,
sample_weight= w)

svm_non_weight.fit(data_train_feature_scaled_pca,
target_train)

print &quot;score weight : &quot;,svm_weight.score(data_test_feature_scaled_pca,target_train)

print &quot;score non weight : &quot;,svm_non_weight.score(data_test_feature_scaled_pca,target_train)

输出：
得分权重：0.503592561285
得分非权重：0.729289940828

实现的 adaboost：
类 adaboost_classifier：
def __init__(self,train,target,classifier,n_estimator)：
#准备数据集
self.N_classes = np.unique(target)
self.n_estimator = n_estimator
self.N_data = len(train)
self.trained_classifier = [[classifier,float(0),float(0), True ] for i in range(n_estimator)]
indice = []
train = np.array(train)
target = np.array(target)
dataset = np.concatenate((train,target),axis=1)
#连接训练和目标以进行提升

for i in range(len(dataset[0])-1):
indice.append(i)

self.weights = np.zeros([n_estimator,self.N_data])

#初始化权重的 1/n 值
self.weights.fill(1/float(self.N_data))
#进行采样
new_dataset = dataset
self.N_data = len(new_dataset)
#开始训练子分类器
for i in range(n_estimator):
self.loss = np.zeros(self.N_data)
#分离训练和目标数据
new_train = new_dataset[:,indice]
new_target = new_dataset[:,(len(dataset[0])-1)]
#训练分类器：使用数据权重学习 f(X)
self.trained_classifier[i][0].fit(new_train,new_target,sample_weight=self.weights[i])
#计算加权误差，存储在 trained_classifier[i][1] 中
for point in range(self.N_data) :
if(self.trained_classifier[i][0].predict([new_train[point]]) != new_target[point]):
self.loss[point] = 1
self.trained_classifier[i][1] += self.weights[i][point]

#计算分类器 i 的系数，存储在 trained_classifier[i][2] 中
self.trained_classifier[i][2] = 0.5 * np.log((1-self.trained_classifier[i][1])/self.trained_classifier[i][1])
#重新计算权重
for j in range(self.N_data):
if(self.loss[j] == 1):
self.weights[i][j] *= np.exp(self.trained_classifier[i][2])
else:
self.weights[i][j] *= np.exp(-self.trained_classifier[i][2])

#规范化权重
self.trained_classifier[i][1] = self.trained_classifier[i][1] / self.weights[i].sum()
]]></description>
      <guid>https://stackoverflow.com/questions/41804937/decreasing-accuracy-of-scikit-learn-classifier-after-initializing-weight</guid>
      <pubDate>Mon, 23 Jan 2017 11:09:21 GMT</pubDate>
    </item>
    </channel>
</rss>