<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 08 Feb 2024 06:18:42 GMT</lastBuildDate>
    <item>
      <title>是否有一种工具或强大的应用程序技术可以让我们根据数据集自动填充 Excel 工作表中问题的答案？</title>
      <link>https://stackoverflow.com/questions/77959600/is-there-a-tool-or-power-apps-technique-where-we-can-auto-populate-the-responses</link>
      <description><![CDATA[是否有一种工具或强大的应用程序技术可以让我们根据数据集自动填充 Excel 工作表中问题的答案？
示例 - 我们有一个包含 200 个问题和答案的数据集，我们必须根据工作表中提出的 20 个问题自动用答案填充 Excel 工作表。这应该是一个自动化的过程。
请告诉我市场上是否有可用的工具或我们可以使用的技术。
谢谢
我尝试了 copilot，我们可以单独获得响应，但需要更加自动化和快速的流程。]]></description>
      <guid>https://stackoverflow.com/questions/77959600/is-there-a-tool-or-power-apps-technique-where-we-can-auto-populate-the-responses</guid>
      <pubDate>Thu, 08 Feb 2024 06:14:52 GMT</pubDate>
    </item>
    <item>
      <title>就地修剪 nn.Linear 权重会导致意外错误，需要稍微奇怪的解决方法。需要解释</title>
      <link>https://stackoverflow.com/questions/77959410/pruning-nn-linear-weights-inplace-causes-unexpected-error-requires-slightly-wei</link>
      <description><![CDATA[失败
导入火炬

def 测试1():
  层 = nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试1()

有错误
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
RuntimeError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-bb36a010bd86&gt;在&lt;细胞系：10&gt;()
      8 x = 5 - torch.sum(layer(torch.ones(90)))
      9 x.backward()
---&gt; 10 测试1()
     11 # 这也有效
     12

2帧
/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py 向后（张量，grad_tensors，retain_graph，create_graph，grad_variables，输入）
    249 # 一些 Python 版本打印多行函数的第一行
    [第 250 章]
--&gt; 251 Variable._execution_engine.run_backward( # 调用 C++ 引擎来运行向后传递
    252个张量，
    第253章

RuntimeError: 函数 TBackward0 在索引 0 返回无效渐变 - 得到 [10, 90] 但预期形状与 [10, 100] 兼容

这有效
导入火炬

def test2():
  层 = torch.nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  del x #主要变化
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试2()

这也有效
导入火炬
def test3():
  层 = torch.nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  layer.weight = torch.nn.Parameter(layer.weight) #主要变化
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试3()

我在尝试实现一篇关于模型修剪的论文时遇到了这个问题。我相信这与 autograd 图有关，但我不确定到底发生了什么。任何对这些几乎相同的代码片段工作/失败的解释都将非常感激。提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/77959410/pruning-nn-linear-weights-inplace-causes-unexpected-error-requires-slightly-wei</guid>
      <pubDate>Thu, 08 Feb 2024 05:17:32 GMT</pubDate>
    </item>
    <item>
      <title>在 esp32-cam 中使用人脸识别时出现错误 cam_hal：EV-VSYNC-OVF</title>
      <link>https://stackoverflow.com/questions/77958199/error-cam-hal-ev-vsync-ovf-when-using-face-recognition-in-esp32-cam</link>
      <description><![CDATA[我正在我的 esp32-cam 板上使用示例“CameraWebServer”。上传设置如下：
开发板：AI Thinker ESP32-CAM；
CPU频率：240MHz；
闪光频率：80 Mhz；
闪光模式：QIO。
Arduino 集成开发环境 2.0.0
esp32 乐鑫 版本 2.0.14

通过这些设置，我可以上传我的代码，但粪便识别功能不起作用。当我单击“注册面部”时，没有任何反应，并且我的串行监视器显示消息 EV-VSYNC-OVF。如何解决这个问题？
此外，我已经尝试修改上传设置并更改文件“CameraWebServer.ino”中的参数 config.frame_size 和 config.xclk_freq_hz，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77958199/error-cam-hal-ev-vsync-ovf-when-using-face-recognition-in-esp32-cam</guid>
      <pubDate>Wed, 07 Feb 2024 22:12:55 GMT</pubDate>
    </item>
    <item>
      <title>如何让这个专家混合模型在张量流中工作？</title>
      <link>https://stackoverflow.com/questions/77957928/how-can-i-get-this-mixture-of-experts-model-working-in-tensorflow</link>
      <description><![CDATA[我有两个张量。
张量 1 的形状为 (10, None, 16, 16, 64)
张量 2 的形状为 (None, 10)
“无”是c的批量大小
第一个张量表示来自 10 个不同模型的 logits 集合 (10)，其形状是每组 logits，(None) 是批量大小，(16, 16, 64) 是相应模型的输出。
第二个张量表示来自 1 个较小模型的一组 logits（无），即批处理大小，(10) 是 10 个值，表示第一个张量中每组 10 个 logits 的权重应如何。
我想将第一个张量乘以第二个张量，以便输出形状为 (10, None, 16, 16, 64)，并且第一个轴上的每组 logit 由第二个张量的相应 logit 进行加权
然后，我将对第一个轴上的相乘张量求和，以获得 MoE 模型的一个块的输出
以下是所有这些的实施方式（顺便说一下，MOPE 代表预训练专家的混合）：
def CreateMOPEBlock(x, 块, blockNum):
    专家日志 = []

    对于范围内的 i（num_classes）：
        块[i].trainable = False
        ExpertLogits.append(块[i](x))

    门控输入 = x
    GatingConv1 = tf.keras.layers.Conv2D(16, (3, 3), padding=&#39;相同&#39;)(GatingInput)
    GatingLayerNorm1 = tf.keras.layers.LayerNormalization()(GatingConv1)
    GatingLeakyReLU1 = tf.keras.layers.LeakyReLU()(GatingLayerNorm1)
    GatingConv2 = tf.keras.layers.Conv2D(32, (3, 3), padding=&#39;相同&#39;)(GatingLeakyReLU1)
    GatingLayerNorm2 = tf.keras.layers.LayerNormalization()(GatingConv2)
    GatingLeakyReLU2 = tf.keras.layers.LeakyReLU()(GatingLayerNorm2)
    GatingConv3 = tf.keras.layers.Conv2D(64, (3, 3), padding=&#39;相同&#39;)(GatingLeakyReLU2)
    GatingLayerNorm3 = tf.keras.layers.LayerNormalization()(GatingConv3)
    GatingLeakyReLU3 = tf.keras.layers.LeakyReLU()(GatingLayerNorm3)
    GatingFlatten = tf.keras.layers.Flatten()(GatingLeakyReLU3)
    GatingLogits = tf.keras.layers.Dense（num_classes，激活=&#39;softmax&#39;）（GatingFlatten）

    logits1 = ExpertLogits # 形状：(10, 无, 16, 16, 64)
    logits2 = GatingLogits # 形状：（无，10）

    # 在这里做一些奇特的数学计算
    多重逻辑 = ?

    返回 tf.keras.layers.add(multiple_logits)

MOPEInput = tf.keras.layers.Input(形状=(32, 32, 3))

# Block1、2和3只是10个keras顺序模型的数组
MOPEBlock1 = CreateMOPEBlock(MOPEInput, 块1)
MOPEBlock2 = CreateMOPEBlock(MOPEBlock1, 块2)
MOPEBlock3 = CreateMOPEBlock(MOPEBlock2, 块3)

MOPEFlatten = tf.keras.layers.Flatten()(MOPEBlock3)

MOPEX = tf.keras.layers.Dense(1024，激活=&#39;relu&#39;)(MOPEFlatten)
MOPEX = tf.keras.layers.BatchNormalization()(MOPEX)
MOPEX = tf.keras.layers.Dropout(0.33)(MOPEX)

MOPEX = tf.keras.layers.Dense(1024，激活=&#39;relu&#39;)(MOPEX)
MOPEX = tf.keras.layers.BatchNormalization()(MOPEX)
MOPEX = tf.keras.layers.Dropout(0.33)(MOPEX)

MOPEOutput = tf.keras.layers.Dense(num_classes, 激活=&#39;softmax&#39;)(MOPEX)

MOPEModel = tf.keras.Model(MOPEInput, MOPEOutput)

我已经尝试自己解决这个问题了！多次！
我还尝试询问多种大型语言模型，从 Mixtral-8x7b（以我的名字命名）到 GPT4。
结果看起来像这样：
将张量流导入为 tf

# 假设这些是你的张量
张量1 = tf.placeholder(tf.float32, shape=(10, 无, 16, 16, 64))
张量2 = tf.placeholder(tf.float32, shape=(无, 10))

# 重塑张量2（无，10）-&gt; （无、10、1、1、1）
tensor2_expanded = tf.expand_dims(tf.expand_dims(tf.expand_dims(tensor2, axis=-1), axis=-1), axis=-1)

# 排列张量1的轴 (10, None, 16, 16, 64) -&gt; （无、10、16、16、64）
tensor1_permuted = tf.transpose(tensor1, perm=[1, 0, 2, 3, 4])

# 张量相乘
结果= tf.multiply（tensor1_permuted，tensor2_expanded）

# 最后，将结果的轴排列回来 (None, 10, 16, 16, 64) -&gt; （10、无、16、16、64）
结果 = tf.transpose(结果, perm=[1, 0, 2, 3, 4])

即使对每个模型进行了广泛的调试，这些模型的解决方案也不起作用。
我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/77957928/how-can-i-get-this-mixture-of-experts-model-working-in-tensorflow</guid>
      <pubDate>Wed, 07 Feb 2024 21:13:53 GMT</pubDate>
    </item>
    <item>
      <title>错误：OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: 错误：(-215:断言失败) !_src.empty() 在函数“cvtColor”中</title>
      <link>https://stackoverflow.com/questions/77957561/error-opencv4-8-0-io-opencv-modules-imgproc-src-color-cpp182-error-215</link>
      <description><![CDATA[augmented_yes = &#39;/content/drive/MyDrive/脑肿瘤检测/augmented-images/yes&#39;
Augmented_no = &#39;/content/drive/MyDrive/脑肿瘤检测/augmented-images/no&#39;
IMG_WIDTH、IMG_HEIGHT = (240, 240)
X, y = load_data([augmented_yes,augmented_no], (IMG_WIDTH, IMG_HEIGHT))
我正在运行上面的代码，但它给了我错误：
错误回溯（最近一次调用最后一次）
 在&lt;细胞系：6&gt;()
4 IMG_宽度、IMG_高度 = (240, 240)
5
----&gt; 6 X, y = load_data([augmented_yes,augmented_no], (IMG_WIDTH, IMG_HEIGHT))
1 帧
 在crop_brain_contour（图像，绘图）中
6
7 # 将图像转为灰度图，并稍微模糊一下
----&gt; 8 灰度 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)
9 灰色 = cv2.GaussianBlur(灰色, (5, 5), 0)
10
错误：OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: 错误：(-215:断言失败) !_src.empty() 在函数“cvtColor”中
**这是 load_data() 函数：**
def load_data(dir_list, image_size):
”“”
读取图像，调整大小并标准化它们。
论据：
dir_list：表示文件目录的字符串列表。
返回：
X：形状 = (#_examples, image_width, image_height, #_channels) 的 numpy 数组
y：形状 = (#_examples, 1) 的 numpy 数组
”“”
# 加载目录中的所有图片
X = []
y = []
图像宽度、图像高度 = 图像大小

对于 dir_list 中的目录：
    对于 listdir（目录）中的文件名：
        # 加载图像
        image = cv2.imread(目录 + &#39;\\&#39; + 文件名)
        # 裁剪大脑并忽略图像中不必要的其余部分
        图像=crop_brain_contour（图像，图=假）
        # 调整图像大小
        图像 = cv2.resize(图像, dsize=(image_width, image_height), 插值=cv2.INTER_CUBIC)
        # 标准化值
        图像=图像/255。
        # 将图像转换为 numpy 数组并将其附加到 X
        X.append(图像)
        # 如果图像为目标数组，则将值 1 附加到目标数组
        # 位于名为“yes”的文件夹中，否则附加 0。
        如果目录[-3:] == &#39;是&#39;:
            y.追加([1])
        别的：
            y.追加([0])

X = np.array(X)
y = np.array(y)

# 打乱数据
X, y = 随机播放(X, y)

print(f&#39;示例数量为：{len(X)}&#39;)
print(f&#39;X 形状是：{X.shape}&#39;)
print(f&#39;y 形状是: {y.shape}&#39;)

返回 X, y

**
这是crop_brain_contour()函数：**
defcrop_brain_contour（图像，plot=False）：
&lt;前&gt;&lt;代码&gt;#import imutils
#导入CV2
#从 matplotlib 导入 pyplot 作为 plt

# 将图像转为灰度图，并稍微模糊一下
灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

灰色 = cv2.GaussianBlur(灰色, (5, 5), 0)

# 对图像设置阈值，然后执行一系列腐蚀 +
# 膨胀以消除任何小噪声区域
阈值 = cv2.threshold(灰色, 45, 255, cv2.THRESH_BINARY)[1]
thresh = cv2.erode(thresh, 无, 迭代=2)
thresh = cv2.dilate(thresh, 无, 迭代=2)

# 在阈值图像中找到轮廓，然后抓取最大的轮廓
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
c = max(cnts, key=cv2.contourArea)


# 找到极值点
extLeft = tuple(c[c[:, :, 0].argmin()][0])
extRight = tuple(c[c[:, :, 0].argmax()][0])
extTop = 元组(c[c[:, :, 1].argmin()][0])
extBot = tuple(c[c[:, :, 1].argmax()][0])

# 使用四个极值点（左、右、上、下）从原始图像中裁剪出新图像
new_image = 图像[extTop[1]:extBot[1], extLeft[0]:extRight[0]]

如果情节：
    plt.figure()

    plt. 子图(1, 2, 1)
    plt.imshow(图像)

    plt.tick_params(axis=&#39;两者&#39;,which=&#39;两者&#39;,
                    上=假，下=假，左=假，右=假，
                    labelbottom=False、labeltop=False、labelleft=False、labelright=False)

    plt.title(&#39;原图&#39;)

    plt. 子图(1, 2, 2)
    plt.imshow(new_image)

    plt.tick_params(axis=&#39;两者&#39;,which=&#39;两者&#39;,
                    上=假，下=假，左=假，右=假，
                    labelbottom=False、labeltop=False、labelleft=False、labelright=False)

    plt.title(&#39;裁剪后的图像&#39;)

    plt.show()

返回新图像

检查我正在进行的脑肿瘤检测项目的错误在哪里。/
我尝试了很多，但都失败了]]></description>
      <guid>https://stackoverflow.com/questions/77957561/error-opencv4-8-0-io-opencv-modules-imgproc-src-color-cpp182-error-215</guid>
      <pubDate>Wed, 07 Feb 2024 19:52:57 GMT</pubDate>
    </item>
    <item>
      <title>实施 Info NCE 损失时形状不匹配</title>
      <link>https://stackoverflow.com/questions/77957522/shape-mismatch-when-implementing-info-nce-loss</link>
      <description><![CDATA[我正在尝试用我自己的图像实现这篇论文的Info NCE丢失数据集。我正在遵循此 repo 的实现并使用以下代码：
def info_nce_loss(self, features):

        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)
        标签 = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()
        标签 = labels.to(self.args.device)

        特征 = F.normalize(特征, 暗淡=1)

        相似度矩阵 = torch.matmul(特征, 特征.T)
        # 断言相似度矩阵.shape == (
        # self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)
        # 断言相似度_matrix.shape == labels.shape

        # 丢弃标签和相似度矩阵中的主对角线
        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)
        标签 = labels[~mask].view(labels.shape[0], -1)
        相似度矩阵 = 相似度矩阵[~掩码].view(相似度矩阵.形状[0], -1)
        # 断言相似度_matrix.shape == labels.shape

        # 选择并组合多个正数
        正值=相似度矩阵[labels.bool()].view(labels.shape[0],-1)

        # 只选择底片 底片
        负数=相似度矩阵[~labels.bool()].view(similarity_matrix.shape[0],-1)

        logits = torch.cat([正数, 负数], dim=1)
        标签 = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)

        logits = logits / self.args.温度
        返回逻辑、标签

以自我监督的方式训练我的模型。我在代码中使用 batch_size 32 和上述损失函数，一切正常。但是，当我将 batch_size 更改为任何其他数字（例如 256）时，我收到以下错误：
索引 0 处的掩码 [512, 512] 的形状与索引 0 处的索引张量 [2, 2] 的形状不匹配。

错误源于此行：
labels = labels[~mask].view(labels.shape[0], -1)

我尝试调整图像大小，但这也没有帮助。知道这里可能出现什么问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77957522/shape-mismatch-when-implementing-info-nce-loss</guid>
      <pubDate>Wed, 07 Feb 2024 19:46:25 GMT</pubDate>
    </item>
    <item>
      <title>部署 scikit-learn 模型最便宜（或免费）的方法是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77956894/whats-the-cheapest-or-free-way-to-deply-scikit-learn-model</link>
      <description><![CDATA[我尝试使用 Vercel 函数，但安装 scikit-learn 模块导致超出 250MB 限制。这可能是由它的依赖关系引起的。
除了 AWS 或 gcloud 之外还有其他选择吗？我现在只想构建一个概念验证。]]></description>
      <guid>https://stackoverflow.com/questions/77956894/whats-the-cheapest-or-free-way-to-deply-scikit-learn-model</guid>
      <pubDate>Wed, 07 Feb 2024 17:42:58 GMT</pubDate>
    </item>
    <item>
      <title>回归树中的主导特征使所有其他特征无关/0 [关闭]</title>
      <link>https://stackoverflow.com/questions/77954893/dominant-feature-in-regression-tree-makes-all-other-features-irrelevant-0</link>
      <description><![CDATA[我正在使用房地产数据集（高基数），因此我选择了 scikit-learn 回归树模型来尝试根据相关特征预测房屋的价格。我有这些功能 [&#39;Suburb&#39;,&#39;Address&#39;, &#39;Distance&#39;, &#39;Bedroom2&#39;, &#39;Bathroom&#39;, &#39;CouncilArea&#39;,&#39;Price&#39;]。
问题是，当我使用 Address it 时，它会使所有其他功能（“郊区”、“距离”、“卧室 2”、“浴室”、“议会区域”）基本上变得多余。地址是一个非常重要的功能，因此我正在尝试将其纳入其中。
我已经多次执行预处理和标准化步骤来尝试不同的结果。我将给出一个基本概述：
第一种方法最少预处理：

将原始 df 通过（这是基本的预处理，考虑 nan vals 并替换它们。）。
目标编码我的非 int （分类变量）并在整个 X （训练和测试）变量上使用标准标量。 （关于 Standardscaler，我也没有使用它，但有一个小的不明显的差异）

第二种方法标准化：

标准预处理（处理和替换 nan val）
评估数据偏差
我通过 Box Cox 运行了高度倾斜/非对称的值（用 IHS 进行了实验（某些值是负值（负值只是跳过了标准化，因为倾斜还不错），其他列一些数据点 == 0 所以我添加了小值（0.01）到 0 值以使它们为正）和 Log 变换）。 Box cox 标准化了所选值的最佳值，因此我使用了这个（请注意，我没有在所有适用的列上使用 Box Cox，仅在具有高偏差的列上使用 Box Cox，不确定这是否是标准流程）
将新结果和其余分类变量附加回 df
目标编码 X 分类变量（训练/测试）
使用标准标量
遍历回归树（使用 max_leaf，3-25 的差异非常小，因此其他特征变得明显，但它们包含 epsilon 值，所以不是真的）

第三种方法，省略地址：

重复第一种和第二种方法
结果还不错，但证明不使用“地址”让位于其他重要功能！

我还使用线性回归模型重复了这些过程，但它并不能很好地捕捉数据的复杂性质。我正在尝试使其适用于回归树。
我还使用线性回归模型重复了这个过程，但它没有很好地捕捉数据的复杂性质。]]></description>
      <guid>https://stackoverflow.com/questions/77954893/dominant-feature-in-regression-tree-makes-all-other-features-irrelevant-0</guid>
      <pubDate>Wed, 07 Feb 2024 12:52:43 GMT</pubDate>
    </item>
    <item>
      <title>如何获得更好的 AUC 分数？ （和累积提升）</title>
      <link>https://stackoverflow.com/questions/77948795/how-to-yield-a-better-auc-score-and-cumulative-lift</link>
      <description><![CDATA[我有一个包含 60 万条记录和 173 个专注于二元分类的特征的数据集。班级比例约为 98.7:1.3（1.3% 目标=1）。
目前，我正在尝试提高模型的性能，该模型的 AUC 为 73%。此外，我对前 2% 的累积提升是 10.41，对前 5% 的累积提升是 5.92。由于我只会针对正面预测分数的前 2-5%，因此我并不特别关心混淆矩阵阈值或改进矩阵值（FP、FN）。
我通过转换（交互，^2）和手动数学计算执行了特征工程。
尽管如此，在训练了没有工程特征的模型后，AUC 分数大致相同，没有我的工程特征的模型中的累积提升略高。我使用了一个自动功能选择工具，该工具使用 RFE 和 XGBoost 来指示所选功能。
我应该注意到，我训练了模型，该模型具有 3 个周期的下采样数据集（3 个周期中每个周期 40k），分类比为 93.5:6.5（6.5% 目标=1），并使用常规的第 4 个周期验证数据集上的数据（原始 1.3% tareget=1 率）。我使用 H20 来训练我的模型（选择 XGBoost）。
如何提高模型得分和模型质量？我知道模型训练涉及插补，但我应该在预处理/清理阶段尝试使用 SimpleImputer、IterativeImputer 或/和 KNNImputer 吗？这会改善我的模型吗？
我尝试使用或不使用我的工程特征重新训练多个模型，并返回到第 1 步并创建更多变量（工程）以尝试帮助我的 AUC 和提升分数。]]></description>
      <guid>https://stackoverflow.com/questions/77948795/how-to-yield-a-better-auc-score-and-cumulative-lift</guid>
      <pubDate>Tue, 06 Feb 2024 15:11:26 GMT</pubDate>
    </item>
    <item>
      <title>RNN 的训练循环在每个 epoch 后返回相同的损失</title>
      <link>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</link>
      <description><![CDATA[我正在尝试借助此存储库从头开始构建 RNN (https: //github.com/nicklashansen/rnn_lstm_from_scratch/tree/master），但每个时期后的训练损失保持不变。训练循环的代码如下：
# 超参数
纪元数 = 1000

# 初始化一个新网络
参数 = init_rnn(hidden_​​size=hidden_​​size, vocab_size=vocab_size)

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 轨迹丢失
训练损失、验证损失 = []、[]

def check_if_params_updated(old_params, new_params):
    # 该函数检查两组参数是否不同
    对于 zip 中的 old_param、new_param(old_params, new_params)：
        如果不是 np.array_equal(old_param, new_param):
            return True # 参数已更新
    return False # 参数尚未更新


# 对于每个纪元
对于范围内的 i（num_epochs）：
    
    # 轨迹丢失
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
     # 对于验证集中的每个句子
    对于输入，val_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，_ =向后传递（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        
        # 更新损失
        epoch_validation_loss += 损失
    
    # 对于训练集中的每个句子
    对于输入，train_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，梯度=backward_pass（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        打印（inputs_one_hot.shape）
        
        如果 np.isnan(损失):
            raise ValueError(&#39;梯度消失/爆炸！&#39;)
        
        # 更新参数
        params = update_parameters(params, grads, lr=1e-3)
        
        # 更新损失
        epoch_training_loss += 损失
        
    # 保存绘图损失
    Training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # 每 100 个 epoch 打印损失
    如果我％100==0：
        print(f&#39;Epoch {i}, 训练损失: {training_loss[-1]}, 验证损失: {validation_loss[-1]}&#39;)


# 获取测试集中的第一个句子
输入，目标 = test_set[1]

# One-hot 编码输入和目标序列
input_one_hot = one_hot_encode_sequence（输入，vocab_size）
target_one_hot = one_hot_encode_sequence（目标，vocab_size）

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 前向传递
输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）
output_sentence = [idx_to_word[np.argmax(output)] 用于输出中的输出]
print(&#39;输入句子：&#39;)
打印（输入）

print(&#39;\n目标序列:&#39;)
打印（目标）

print(&#39;\n预测序列:&#39;)
print([idx_to_word[np.argmax(output)] 用于输出中的输出])

# 绘制训练和验证损失图
纪元 = np.arange(len(training_loss))
plt.figure()
plt.plot(epoch, Training_loss, &#39;r&#39;, label=&#39;训练损失&#39;,)
plt.plot(epoch,validation_loss,&#39;b&#39;,label=&#39;验证损失&#39;)
plt.图例()
plt.xlabel(&#39;Epoch&#39;), plt.ylabel(&#39;NLL&#39;)
plt.show()

我尝试检查我的参数是否正在更新，它们确实更新了，还尝试检查梯度，它们并不是指数小。每次迭代后损失都会减少，但总纪元的损失保持不变。您可以在存储库中找到完整的代码，其中包括前向和后向传递(https://github.com/危险dude237/RNN_From_Scratch）。]]></description>
      <guid>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</guid>
      <pubDate>Mon, 05 Feb 2024 00:28:27 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“anomalib.engine”的模块</title>
      <link>https://stackoverflow.com/questions/77930973/modulenotfounderror-no-module-named-anomalib-engine</link>
      <description><![CDATA[# 导入需要的模块

从 anomalib.data 导入 MVTec
从 anomalib.models 导入 Patchcore
从 anomalib.engine 导入引擎

错误：
ModuleNotFoundError：没有名为“anomalib.engine”的模块

我正在尝试运行这个......已经遵循库安装并看到了
https://anomalib.readthedocs.io/en/latest/markdown/ get_started/anomalib.html
我认为要么是因为引擎已被修改，要么是被库删除了......
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77930973/modulenotfounderror-no-module-named-anomalib-engine</guid>
      <pubDate>Sat, 03 Feb 2024 05:25:02 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析：分类变量的预测</title>
      <link>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</link>
      <description><![CDATA[我有一台机器在 1 分钟时间间隔内的故障发生数据（以 0 和 1 表示）。 0 代表未发生故障，1 代表发生特定故障。因此，连续0 表示在一段时间内没有发生故障，连续1 表示在一段时间内连续发生故障。
我提供了如下的示例数据结构，现在我如何对下面提供的数据进行时间序列分析故障 A，并根据分析如何进行预测，例如“故障 A 将在未来时间戳中何时发生？” 
# 时间序列多元
将 pandas 导入为 pd
将 numpy 导入为 np

df = pd.DataFrame({&#39;timestamp&#39;:pd.date_range(&#39;2022-05-01 00:01:00&#39;, period=18, freq=&#39;T&#39;),
                   &#39;故障代码&#39;:[&#39;A&#39;]*4+[&#39;B&#39;]*3+[&#39;A&#39;]*2+[&#39;C&#39;]*5+[&#39;B&#39;]*2+[&#39;A&#39;]* 1+[&#39;D&#39;]*1
                  })
df[&#39;脉冲&#39;] = 1

df_ts = df.pivot(index=“时间戳”, columns=“故障代码”, value=“脉冲”)
df_ts = df_ts.fillna(0)
显示（df_ts）



         故障代码 A B C D
时间戳
2022-05-01 00:01:00 1 0 0 0
2022-05-01 00:02:00 1 0 0 0
2022-05-01 00:03:00 1 0 0 0
2022-05-01 00:04:00 1 0 0 0
2022-05-01 00:05:00 0 1 0 0
2022-05-01 00:06:00 0 1 0 0
2022-05-01 00:07:00 0 1 0 0
2022-05-01 00:08:00 1 0 0 0
2022-05-01 00:09:00 1 0 0 0
2022-05-01 00:10:00 0 0 1 0
2022-05-01 00:11:00 0 0 1 0
2022-05-01 00:12:00 0 0 1 0
2022-05-01 00:13:00 0 0 1 0
2022-05-01 00:14:00 0 0 1 0
2022-05-01 00:15:00 0 1 0 0
2022-05-01 00:16:00 0 1 0 0
2022-05-01 00:17:00 1 0 0 0
2022-05-01 00:18:00 0 0 0 1

# 时间序列图
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns

sns.set_theme(style=&quot;whitegrid&quot;) # darkgrid、whitegrid、dark、white 和ticks

故障=[&#39;A&#39;,
        &#39;B&#39;,
        &#39;C&#39;，
        &#39;D&#39;
       ]

plt.figure(figsize = (15,4))
sns.lineplot(数据=df_ts[故障])
plt.show()

上述数据的时间序列图
我要预测A的故障代码（0或1）
         
时间戳故障代码
2022-05-01 00:19:00 ?
2022-05-01 00:20:00 ?
2022-05-01 00:21:00 ？
2022-05-01 00:22:00 ？
2022-05-01 00:23:00 ？
2022-05-01 00:24:00 ？
2022-05-01 00:25:00 ？
]]></description>
      <guid>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</guid>
      <pubDate>Fri, 03 Jun 2022 10:48:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 JamesSteinEncoder 时出现“is_categorical 已弃用”错误</title>
      <link>https://stackoverflow.com/questions/63589556/getting-is-categorical-is-deprecated-error-while-using-jamessteinencoder</link>
      <description><![CDATA[尝试安装 JamesSteinEncoder 时出现以下错误
编码器 = JamesSteinEncoder().fit(X, y)

FutureWarning： is_categorical 已弃用，并将在未来版本中删除。使用 is_categorical_dtype 代替
  elif pd.api.types.is_categorical(cols):

sklearn.__version__ : &#39;0.23.2&#39;

代码：
速度 = [&#39;德国&#39;,&#39;澳大利亚&#39;,&#39;美国&#39;,&#39;法国&#39;,&#39;英国&#39;,&#39;韩国&#39;,&#39;澳大利亚&#39;]
寿命 = [1, 0, 1, 1, 1, 0, 1]
生命 = [1, 1, 0, 1, 1, 0, np.nan]
索引 = [&#39;蜗牛&#39;, &#39;猪&#39;, &#39;大象&#39;,
         ‘兔子’、‘长颈鹿’、‘土狼’、‘马’]
df = pd.DataFrame({&#39;速度&#39;: 速度,
                   “寿命”：寿命，
                  &#39;life&#39;:life}, 索引=索引)

df[&#39;速度&#39;]= df[&#39;速度&#39;].astype(&#39;类别&#39;)

 从category_encoders导入JamesSteinEncoder
    X = df[&#39;速度&#39;]
    y = df[&#39;寿命&#39;]
    enc = JamesSteinEncoder().fit(X, y)

/Users/*/opt/anaconda3/envs/proj/lib/python3.7/site-packages/category_encoders/utils.py:21：FutureWarning：is_categorical 已弃用，并将在未来版本中删除。使用 is_categorical_dtype 代替
  elif pd.api.types.is_categorical(cols):
]]></description>
      <guid>https://stackoverflow.com/questions/63589556/getting-is-categorical-is-deprecated-error-while-using-jamessteinencoder</guid>
      <pubDate>Wed, 26 Aug 2020 02:16:42 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM错误：ValueError：为了提前停止，至少需要一个数据集和评估指标进行评估</title>
      <link>https://stackoverflow.com/questions/61694081/lightgbm-error-valueerror-for-early-stopping-at-least-one-dataset-and-eval-m</link>
      <description><![CDATA[我正在尝试使用 gridsearch 训练 LightGBM，当我尝试训练模型时出现以下错误。 
ValueError：为了提前停止，至少需要一个数据集和评估指标进行评估

我提供了验证数据集和评估指标。不知道为什么我仍然遇到这个问题。这是我的代码。
train_data = rtotal[rtotal[&#39;train_Y&#39;] == 1]
test_data = rtotal[rtotal[&#39;train_Y&#39;] == 0]

trainData，validData = train_test_split（train_data，test_size = 0.007，random_state = 123）

#训练数据准备
X_train = trainData.iloc[:,2:71]
y_train = trainData.loc[:,[&#39;a_class&#39;]]

#验证数据准备
X_valid = validData.iloc[:,2:71]
y_valid = validData.loc[:,[&#39;a_class&#39;]]

#X_测试
X_test = test_data.iloc[:,2:71]

将 lightgbm 导入为 lgb
从 sklearn.model_selection 导入 GridSearchCV

网格参数 = {
    &#39;学习率&#39;：[0.005]，
    “n_估计器”：[40]，
    &#39;num_leaves&#39;: [16,32, 64],
    &#39;目标&#39;：[&#39;多类&#39;]，
    “随机状态”：[501]，
    &#39;num_boost_round&#39;：[3000]，
    &#39;colsample_bytree&#39;：[0.65，0.66]，
    &#39;子样本&#39;：[0.7,0.75],
    &#39;reg_alpha&#39;: [1,1.2],
    &#39;reg_lambda&#39;：[1,1.2,1.4],
    }

lgb_estimator = lgb.LGBMClassifier(boosting_type = &#39;gbdt&#39;,
                                   n_估计器=500，
                                   目标=&#39;多类&#39;，
                                   学习率 = 0.05，叶子数 = 64，
                                   eval_metric = &#39;multi_logloss&#39;,
                                   详细评估=20，
                                   eval_set = [X_valid, y_valid],
                                   Early_stopping_rounds=100）

g_lgbm = GridSearchCV(估计器=lgb_estimator, param_grid=gridParams, n_jobs = 3, cv= 3)

lgb_model = g_lgbm.fit(X=X_train, y=y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/61694081/lightgbm-error-valueerror-for-early-stopping-at-least-one-dataset-and-eval-m</guid>
      <pubDate>Sat, 09 May 2020 08:50:22 GMT</pubDate>
    </item>
    <item>
      <title>什么是 x_train.reshape() 及其作用？</title>
      <link>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</link>
      <description><![CDATA[使用 MNIST 数据集
将 numpy 导入为 np
将张量流导入为 tf
从tensorflow.keras.datasets导入mnist

# MNIST 数据集参数
num_classes = 10 # 总类别（0-9 位数）
num_features = 784 # 数据特征（img 形状：28*28）

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 转换为float32
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)

# 将图像展平为 784 个特征的一维向量 (28*28)
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])

# 将图像值从 [0, 255] 标准化为 [0, 1]
x_train, x_test = x_train / 255., x_test / 255.

在这些代码的第 15 行，即，
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])。我无法理解这些重塑在我们的数据集中到底做了什么......？请解释一下。]]></description>
      <guid>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</guid>
      <pubDate>Sat, 02 May 2020 06:44:34 GMT</pubDate>
    </item>
    </channel>
</rss>