<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 03 Jan 2024 09:15:15 GMT</lastBuildDate>
    <item>
      <title>ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17)</title>
      <link>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</link>
      <description><![CDATA[`
步骤1：创建管道
步骤2：将管道转换为数据帧
步骤3：我正在尝试将管道转换为数据帧，但出现异常。如何解决这个问题呢
步骤4：如何解决ValueError：传递值的形状为(8631, 28)，索引暗示(8631, 17)在管道转换为数据帧之上，
`
from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
从 sklearn.impute 导入 SimpleImputer
从 sklearn.pipeline 导入管道
从 sklearn.compose 导入 ColumnTransformer

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split

print(&quot;步骤1：导入lib&quot;)
print(&quot;第2步：加载原始数据&quot;)
df = pd.read_csv(“online_shoppers_intention.csv”)

print(&quot;第三步：数据准备&quot;)
X = df.drop([&#39;收入&#39;], axis = 1)
y = df[&#39;收入&#39;]

print(&quot;第四步：数据分割&quot;)
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size = .3、random_state = 0)
名称 = X_train.columns.tolist()

numeric_transformer = SimpleImputer(策略 = &#39;常量&#39;)
categorical_transformer = OneHotEncoder(handle_unknown = &#39;忽略&#39;)

numeric_cols = X.select_dtypes(exclude = &quot;object&quot;).columns.values.tolist()
categorical_cols = X.select_dtypes(exclude = [&#39;int&#39;, &#39;float64&#39;, &#39;bool&#39;]).columns.values.tolist()
    
预处理器 = ColumnTransformer(
    变形金刚=[
    (&#39;num&#39;, numeric_transformer, numeric_cols)
    ,(&#39;猫&#39;, categorical_transformer, categorical_cols)
    ],
    余数 = &#39;直通&#39;)

pipeline_preprocessor = Pipeline(steps = [(“预处理器”, 预处理器), (“pandarizer”, FunctionTransformer(lambda x: pd.DataFrame(x, columns = 名称)))]).fit(X_train)
    
X_train_pipe = pipeline_preprocessor.transform(X_train)
X_test_pipe = pipeline_preprocessor.transform(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</guid>
      <pubDate>Wed, 03 Jan 2024 07:51:34 GMT</pubDate>
    </item>
    <item>
      <title>有没有一种方法可以使用 matplotlib 绘制多个图形，每个图形上有多条线？</title>
      <link>https://stackoverflow.com/questions/77749447/is-there-a-way-to-plot-multiple-graphs-with-multiple-lines-on-each-one-using-mat</link>
      <description><![CDATA[我正在尝试绘制不同指标的学习曲线，例如训练和验证损失和准确性。
对于学习率中的 lr：
    opt = SGD(学习率 = lr)
    model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=opt, 指标=[&#39;accuracy&#39;])
    网络= model.fit（x_train_subset，y_train_subset，epochs =迭代，batch_size = 32，validation_data =（X_test，y_test），详细= 1）

    train_loss_values = network.history[&#39;loss&#39;]
    train_accuracy_values = network.history[&#39;accuracy&#39;]
    val_loss_values = 网络.history[&#39;val_loss&#39;]
    val_accuracy_values = network.history[&#39;val_accuracy&#39;]

    plt.plot(epochs, train_accuracy_values, label=f&#39;LR = {lr}&#39;)
    
plt.title(&#39;不同学习率下历元的训练精度&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.ylabel(&#39;训练准确率&#39;)
plt.图例()
plt.网格（真）
plt.show()

这是我拥有的代码，对于以训练准确性为指标的一张图来说，它完全按照我想要的方式工作。
上述代码的输出：

但是，我想针对以下代码中存储的所有不同指标复制此操作四次：
train_loss_values = network.history[&#39;loss&#39;]
train_accuracy_values = network.history[&#39;accuracy&#39;]
val_loss_values = 网络.history[&#39;val_loss&#39;]
val_accuracy_values = network.history[&#39;val_accuracy&#39;]

如果我简单地执行以下操作，它不会创建 4 个单独的图表，它只是将所有数据添加到一个图表中。
对于学习率中的 lr：
    opt = SGD(学习率 = lr)
    model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=opt, 指标=[&#39;accuracy&#39;])
    网络= model.fit（x_train_subset，y_train_subset，epochs =迭代，batch_size = 32，validation_data =（X_test，y_test），详细= 1）

    train_loss_values = network.history[&#39;loss&#39;]
    train_accuracy_values = network.history[&#39;accuracy&#39;]
    val_loss_values = 网络.history[&#39;val_loss&#39;]
    val_accuracy_values = network.history[&#39;val_accuracy&#39;]

    plt.plot(epochs, train_accuracy_values, label=f&#39;LR = {lr}&#39;)
    plt.plot(epochs, train_loss_values, label=f&#39;LR = {lr}&#39;)
    plt.plot(epochs, val_accuracy_values, label=f&#39;LR = {lr}&#39;)
    plt.plot(epochs, val_loss_values, label=f&#39;LR = {lr}&#39;)
    
plt.title(&#39;不同学习率下历元的训练精度&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.ylabel(&#39;训练准确率&#39;)
plt.图例()
plt.网格（真）
plt.show()

我询问了 ChatGPT，它总是建议再次运行整个神经网络 4 次，但我已经运行了一次并在列表中收集了我需要的所有数据。我只需要创建 4 个单独的图。]]></description>
      <guid>https://stackoverflow.com/questions/77749447/is-there-a-way-to-plot-multiple-graphs-with-multiple-lines-on-each-one-using-mat</guid>
      <pubDate>Wed, 03 Jan 2024 02:30:43 GMT</pubDate>
    </item>
    <item>
      <title>神经网络和深度学习问题</title>
      <link>https://stackoverflow.com/questions/77749424/neural-networks-and-deep-learning-question</link>
      <description><![CDATA[我已经解决了除了这个问题之外的所有问题，这是唯一剩下的问题。其实我也解决了这个问题，但是得到的答案是错误的。
在此处输入图像描述
我尝试用Python计算它，但我无法计算出来。]]></description>
      <guid>https://stackoverflow.com/questions/77749424/neural-networks-and-deep-learning-question</guid>
      <pubDate>Wed, 03 Jan 2024 02:18:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 Numpy Randn 将高斯噪声添加到训练数据中</title>
      <link>https://stackoverflow.com/questions/77749174/adding-gaussian-noise-to-your-training-data-with-numpy-randn</link>
      <description><![CDATA[我正在 Tensorflow 上训练一个模型，并希望使用随机噪声作为数据增强的一种方式，以增加有限的样本量，并可能进行正则化。 X_train 是我的训练数据，形状为（sample_size，2D 数组）
噪声 = np.random.randn(x_train.shape[0], x_train.shape[1], x_train.shape[2])
x_train += 噪声

与数据幅度相比，这引入了太多的噪声，因为范围是 +-1，均值为零（自然），这与我的数据大致相同。
我的问题是如何以更合理的方式添加噪声（我应该除以一个数量级并添加 f.e.），以及添加高斯噪声实际上是否可以产生更好的训练模型？&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77749174/adding-gaussian-noise-to-your-training-data-with-numpy-randn</guid>
      <pubDate>Wed, 03 Jan 2024 00:22:38 GMT</pubDate>
    </item>
    <item>
      <title>沙箱和机器学习算法的大（O）[关闭]</title>
      <link>https://stackoverflow.com/questions/77749084/big-o-of-the-sandbox-and-machine-learning-algorithm</link>
      <description><![CDATA[我想对 Cuckoo 沙箱的计算进行比较，并希望将其与一些机器和深度学习算法进行比较：

逻辑回归
k-最近邻居
支持向量机
人工神经网络
长短期记忆

那么布谷鸟沙箱或一般沙箱的 Big(O) 以及上述 ML 算法的 Big(O) 是多少]]></description>
      <guid>https://stackoverflow.com/questions/77749084/big-o-of-the-sandbox-and-machine-learning-algorithm</guid>
      <pubDate>Tue, 02 Jan 2024 23:48:41 GMT</pubDate>
    </item>
    <item>
      <title>将多变量时间序列数据集转换为单变量时间序列数据集</title>
      <link>https://stackoverflow.com/questions/77748902/turning-multivariate-time-series-dataset-into-univariate</link>
      <description><![CDATA[我正在使用深度学习算法进行单变量时间序列预测，因此我需要拥有大量数据集。这是因为我打算研究基于物联网的能源消耗时间序列数据。我找到了一些数据集，但它们的大小仍然不足以解决我的问题。
但是，我确实有一个可用的多元时间序列数据集，该数据集也相当大。为了训练目的将多变量数据集转换为单变量数据集是否可以接受？如果是这样，我打算仅保留目标列并删除所有其他列。这种方法正确吗，或者有替代的想法吗？”]]></description>
      <guid>https://stackoverflow.com/questions/77748902/turning-multivariate-time-series-dataset-into-univariate</guid>
      <pubDate>Tue, 02 Jan 2024 22:37:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用GPT-2计算单词和句子嵌入？</title>
      <link>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</link>
      <description><![CDATA[我正在开发一个使用 GPT-2（特别是 GPT2Model 类）计算单词和句子嵌入的程序。对于词嵌入，我在转发 input_ids 后提取最后一个隐藏状态 outputs[0]，其形状为 batch size x seq len ，到 GPT2Model 类。至于句子嵌入，我在序列末尾提取单词的隐藏状态。这是我尝试过的代码：
从变压器导入 GPT2Tokenizer、GPT2Model
进口火炬

tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)
模型 = GPT2Model.from_pretrained(&#39;gpt2&#39;)
Captions = [“示例标题”、“示例鸟”、“鸟是黄色的，有红色翅膀”、“嗨”、“非常好”]

encoded_captions = [tokenizer.encode(caption) 用于字幕中的字幕]

# 用 0 将序列填充到相同的长度
max_len = max(len(seq) 用于编码字幕中的 seq)
padded_captions = [seq + [0] * (max_len - len(seq)) 对于encoded_captions中的seq]

# 转换为批量大小为 5 的 PyTorch 张量
input_ids = torch.tensor(padded_captions)

输出=模型(input_ids)
word_embedding = 输出[0].连续()
句子嵌入 = word_embedding[ :, -1, : ].contigious()


我不确定我对单词和句子嵌入的计算是否正确，有人可以帮我确认一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</guid>
      <pubDate>Tue, 02 Jan 2024 21:55:52 GMT</pubDate>
    </item>
    <item>
      <title>特征名称应与拟合期间传递的特征名称相匹配</title>
      <link>https://stackoverflow.com/questions/77748547/the-feature-names-should-match-those-that-were-passed-during-fit</link>
      <description><![CDATA[我尝试使用 sklearn 线性回归创建模型后计算 r 平方值。
我只是简单

导入 csv 数据集
过滤感兴趣的列
在训练和测试中拆分数据集
创建模型
对测试进行预测
计算 r 平方以了解模型与测试数据集的拟合程度

数据集取自 https://www.kaggle.com/datasets/jeremylarcher/american-house-prices-and-demographics-of-top-cities
代码如下
&#39;&#39;&#39;让我们验证一下价格和浴室床位数量之间是否存在相关性&#39;&#39;&#39;

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression

df = pd.read_csv(&#39;数据/American_Housing_Data_20231209.csv&#39;)

df_interesting_columns = df[[&#39;床&#39;, &#39;浴室&#39;, &#39;价格&#39;]]

Independent_variables = df_interesting_columns[[&#39;床&#39;, &#39;浴室&#39;]]
dependent_variable = df_interesting_columns[[&#39;价格&#39;]]

X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, test_size=0.2)

模型=线性回归()
model.fit(X_train, y_train)

预测 = model.predict(X_test)

print(model.score(y_test, 预测))

但我收到错误
ValueError：特征名称应与拟合期间传递的名称相匹配。
在拟合时看不到的特征名称：

价格
在适合时看到的功能名称，但现在丢失了：
浴室
床位

我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/77748547/the-feature-names-should-match-those-that-were-passed-during-fit</guid>
      <pubDate>Tue, 02 Jan 2024 21:01:29 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv8多类实例分割</title>
      <link>https://stackoverflow.com/questions/77747887/yolov8-instance-segmentation-of-multiple-classes</link>
      <description><![CDATA[我正在寻求有关 YOLOv8 中多类实例分割的帮助。我已经用 Detectron2 完成了这个任务，想要进行比较。在 Detectron2 中，我需要获取包含图像、蒙版和注释文本文件的文件夹，我在其中指定了边界框和相应的标签（鸟类物种）。但也许这对于 YOLOv8 是不可能的？ Detectron2 的注释如下所示：
图像文件名：“img2.png” # img2.png 是包含形状的二值掩模图像
图像尺寸（X x Y）：824 x 824
具有基本事实的对象：3

# 对象 1 的详细信息
对象1的原始标签：“物种1”
对象 1 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(0, 733) - (9, 751)
对象 1 的像素蒙版：“mask2.png”

# 对象 2 的详细信息
对象2的原始标签：“物种2”
对象 2 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(93, 664) - (143, 684)
对象 2 的像素蒙版：“mask2.png”

# 对象 3 的详细信息
对象3的原始标签：“物种1”
对象 3 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(39, 621) - (60, 667)
对象 3 的像素蒙版：“mask2.png”

实际上 YOLOv8 实例分割的所有教程都集中在一个类上。此外，他们经常专注于使用 Roboflow 进行标签，这对我来说并不有趣，因为我从已有的 ESRI shapefile 转换标签。我使用来自无人机图像的 shapefile 和鸟类光栅，将来自 shapefile 的二进制蒙版的标签转换为标签。我找到了一个教程，它实际上专注于创建标签没有口罩，但仍然只有一节课。使用它，我创建了另一个文件夹“标签”，在其中创建包含对象坐标的文本文件。利用这个，我可以成功地使用一个分割鸟类的模型。 YOLOv8 的标签现在看起来像这样：
&lt;预&gt;&lt;代码&gt;0 0.16019417475728157 0.8058252427184466 0.15898058252427186 0.8070388349514563 0.1529126213592233 0.8070388349514563 ... 0.1650485436893204 0.8070388349514563 0.1638349514563107 0.8070388349514563 0.16262135922330098 0.8058252427184466

0 0.055825242718446605 0.7536407766990292 0.055825242718446605 0.7560679611650486 0.05461165048543689 0.7572815533980582 ... 0 .06067961165048544 0.7536407766990292
0 0.09951456310679611 0.6747572815533981 0.09951456310679611 0.6759708737864077

0.09587378640776699 0.6796116504854369 0.09587378640776699 0.6808252427184466 0.09344660194174757 0.683252427184466 ... 0.1031 5533980582524 0.6771844660194175 0.10194174757281553 0.6759708737864077 0.10072815533980582 0.6759708737864077

但我因此想要更多。我知道如何在配置文件中指定类的数量及其名称。但是，我不确定如何在标签文本文件中指定类。从我在网上找到的内容来看，它们只包含像素坐标。另外，如果我已经有了二进制掩码和边界框注释，我想知道是否有更有效的方法来为 30,000 多个图像创建标签。作为参考，每张图像通常有多种鸟类，并且图像中也可能有不同的鸟类种类。
如何使用YOLOv8实现多类实例分割？]]></description>
      <guid>https://stackoverflow.com/questions/77747887/yolov8-instance-segmentation-of-multiple-classes</guid>
      <pubDate>Tue, 02 Jan 2024 18:23:27 GMT</pubDate>
    </item>
    <item>
      <title>在微控制器上部署边缘脉冲训练的车辆检测和颜色分类模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77747578/deploying-edge-impulse-trained-vehicle-detection-and-color-classification-model</link>
      <description><![CDATA[我们正在启动一个项目，重点是使用 Edge Impulse 进行车辆检测和颜色分类。我们的目标是在 Edge Impulse 平台中训练我们的图像数据集，然后将模型部署到微控制器上。我们正在寻找的微控制器应该既与 Edge Impulse 兼容，又具有成本效益，能够实现数据的实时分类。
我们主要关注的是了解在微控制器上部署 Edge Impulse 训练模型的可行性和兼容性。我们的最终目标是无缝集成模型，使微控制器能够准确地对实时数据进行分类。
关于适合此用途的经济高效的微控制器有什么指导或建议吗？
如果在微控制器上部署被证明是不切实际的，我们将不胜感激有关符合我们目标的替代方法的建议。]]></description>
      <guid>https://stackoverflow.com/questions/77747578/deploying-edge-impulse-trained-vehicle-detection-and-color-classification-model</guid>
      <pubDate>Tue, 02 Jan 2024 17:09:06 GMT</pubDate>
    </item>
    <item>
      <title>1 个时期后，训练损失显着下降 [关闭]</title>
      <link>https://stackoverflow.com/questions/77747020/after-1-epoch-the-training-loss-dramatically-down</link>
      <description><![CDATA[在此处输入图像描述
当我运行模型时，一个时期后，训练损失急剧下降，我不明白为什么。
这个模型不是我创建的；相反，我从 GitHub 上 AAAI（人工智能促进协会）接受的代码中获取了它。 （股票预测模型）
代码已经包含了 dropout 和标准化，但我不明白为什么会发生这种情况。
此外，不仅一个数据集会出现此问题，其他数据集（SP、CSI、NDQ 和 NI）也会出现此问题。
*培训：8 年，验证：1 年，测试：2 年
为什么会发生这种情况？
我希望模型不会过度拟合，因为该模型已被顶级会议接受，并且除了按照说明进行操作外，我没有尝试过任何其他操作。
虽然这个模型没有提供具体数据，但我使用了一般股票数据作为模型的输入。
*代码模型
HGAT 类（torch.nn.Module）：
def __init__(self, 代码):
    超级（HGAT，自我）.__init__()
    self.tickers = 代码
    self.grup = gru(5,32) #或 lstm
    self.attention = 注意(32)
    self.hatt1 = nn.HypergraphConv(32, 32, use_attention=True, Heads=4, concat=False, negative_slope=0.2, dropout=0.5, 偏差=True)
    self.hatt2 = nn.HypergraphConv(32, 32, use_attention=True, Heads=1, concat=False, negative_slope=0.2, dropout=0.5, 偏差=True)
    self.liear = torch.nn.Linear(32,1)
defforward(self,price_input,e):
    上下文，查询 = self.grup(price_input)
    查询 = 查询.reshape(1026,1,32)
    输出，权重= self.attention（查询，上下文）
    输出 = 输出.reshape((1026,32))
    x = F.leaky_relu(self.hatt1(输出,e), 0.2)
    x = F.leaky_relu(self.hatt2(x,e), 0.2)
    返回 F.leaky_relu(self.liear(x))
]]></description>
      <guid>https://stackoverflow.com/questions/77747020/after-1-epoch-the-training-loss-dramatically-down</guid>
      <pubDate>Tue, 02 Jan 2024 15:31:25 GMT</pubDate>
    </item>
    <item>
      <title>LipVoicer Online 开源模型使用</title>
      <link>https://stackoverflow.com/questions/77746726/lipvoicer-online-open-source-model-usage</link>
      <description><![CDATA[主题：在自定义样本上测试 LipVoicer 模型的难度
我目前正在使用 LipVoicer 模型，这是一个开源在线工具，旨在从无声视频中生成语音。 LipVoicer 的 GitHub 存储库位于 https://github.com/yochaiye/LipVoicer。
虽然我已经在 Kaggle 笔记本上成功设置了模型环境，如下面的代码所示：
!git 克隆 https://github.com/yochaiye/LipVoicer.git
cd 唇音
!apt-get 安装 ffmpeg
!git 克隆 https://github.com/hhj1897/face_detection.git
cd 人脸检测
!apt-get 安装 git-lfs
!git lfs 拉
pip install -e 。
光盘 ..
!git 克隆 https://github.com/hhj1897/face_alignment.git
cd 面对齐
pip install -e 。
光盘 ..
!git clone --recursive https://github.com/parlance/ctcdecode.git
cd ctc解码
！点安装。

自述文件提供了模型及其设置的概述，但在指导用户完成测试阶段方面存在不足，尤其是在使用示例时。我正在寻求有关如何在我的特定样本集上有效测试 LipVoicer 模型的帮助或指导。
任何有关此事的见解、指示或建议将不胜感激。感谢您的时间和帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77746726/lipvoicer-online-open-source-model-usage</guid>
      <pubDate>Tue, 02 Jan 2024 14:37:46 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML (TensorFlow-Pytorch) 中几乎没有要预测的列，是否有一个库可以以人工方式创建“人工”列？</title>
      <link>https://stackoverflow.com/questions/77745811/i-have-few-columns-to-predict-in-my-ml-tensorflow-pytorch-is-there-a-library</link>
      <description><![CDATA[我在 ML 中几乎没有要预测的列。
我想要：

生成额外的列（正弦、平均值等）。

应该评估这些额外的列（无论它是否改进模型）。


我的 ML 中需要更多数据来预测的列很少。例如，我有一个以度为单位的角度数据，我取了正弦、余弦和正切值。
我想要所有类型的统计数据（对机器学习有效，即前瞻性），以及任何类型的“阿里”数据。 自动为提供数据机器学习模型 (TensorFlow-Pytorch)。提供到具有这些功能的库的链接，以生成“人工”文件。数据或机器学习。 （我不是在寻找 SMOTE）
额外，如果它会为我评估它们??？了解使用哪些输入 fit()。]]></description>
      <guid>https://stackoverflow.com/questions/77745811/i-have-few-columns-to-predict-in-my-ml-tensorflow-pytorch-is-there-a-library</guid>
      <pubDate>Tue, 02 Jan 2024 11:33:44 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用管道中的最佳估计器来预测测试集？</title>
      <link>https://stackoverflow.com/questions/56615768/how-to-use-best-estimator-from-pipeline-to-predict-test-set</link>
      <description><![CDATA[我使用 XGBoost 开发了一个管道，它为我返回了最佳估计器。
但是，尝试使用这个最佳估计器来预测我的测试集时，会出现以下错误：“ValueError：仅 pandas DataFrames 支持使用字符串指定列”。
下面是我使用的管道的代码：
注意：ct 只是使用 SimpleImputer 和 OneHotEncoder 用于分类列的 ColumnTransformer 和 SimpleImputer和用于数字列的 StandardScaler
ml_step_1 = (&#39;transform&#39;, ct)
ml_step_2 = (&#39;PCA&#39;, PCA())
xgb = (&#39;xgb&#39;, XGBRegressor())
xgb_pipe = 管道([ml_step_1, ml_step_2, xgb])
xgb = RandomizedSearchCV(xgb_pipe, xgb_param_grid, cv=kf, 评分=&#39;neg_mean_absolute_error&#39;);
xgb.fit(train_full_features, train_full_target);

运行以下管道，这是我得到的最佳估计器：
最佳 XGBoost 参数：{&#39;xgb__silent&#39;：True，&#39;xgb__n_estimators&#39;：1000，&#39;xgb__max_深度&#39;：4，&#39;xgb__learning_rate&#39;：0.099999999999999999，&#39;transform__num__imputer__strategy&#39;：&#39;中值&#39;，&#39;transform__cat__imputer__strategy&#39;：&#39;most_frequent&#39;，&#39;pca__n_components&#39;：68}

现在，我调用了这个最佳估计器并执行了以下操作：
test_full_imp = pd.DataFrame(xgb.best_estimator_.named_steps[&#39;transform&#39;].transform(test_full))
test_final = xgb.best_estimator_.named_steps[&#39;pca&#39;].transform(test_full_imp)
预测 = xgb.best_estimator_.predict(test_final)
]]></description>
      <guid>https://stackoverflow.com/questions/56615768/how-to-use-best-estimator-from-pipeline-to-predict-test-set</guid>
      <pubDate>Sun, 16 Jun 2019 03:07:00 GMT</pubDate>
    </item>
    </channel>
</rss>