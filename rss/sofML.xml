<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 25 Jul 2024 09:17:33 GMT</lastBuildDate>
    <item>
      <title>需要一个本地 OCR 解决方案 [关闭]</title>
      <link>https://stackoverflow.com/questions/78791621/need-an-on-premise-ocr-solution</link>
      <description><![CDATA[我正在寻找一种可以在 C++ 中实现的本地 OCR 解决方案，用于高精度文档扫描任务。这些文档主要是用智能手机拍摄的照片，包括护照、账单和收据，这些照片可能会有偏差，并且大多包含打印数据。我探索了几种选择，但发现它们都存在不足：
Tesseract OCR、OCR.space、EasyOCR、PaddleOCR、CuneiForm 和 GOCR 的准确度较低。
ABBYY FineReader、Google Cloud Vision OCR 和 Microsoft Azure Computer Vision API 等付费解决方案太贵了。
我需要一种符合以下标准的 OCR 解决方案：

本地
低成本或免费
可用 C++ 实现或具有 C++ 实现
高精度

请为我推荐任何可能的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78791621/need-an-on-premise-ocr-solution</guid>
      <pubDate>Thu, 25 Jul 2024 05:42:06 GMT</pubDate>
    </item>
    <item>
      <title>寻找机器学习模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78791542/finding-a-machine-learning-model</link>
      <description><![CDATA[我需要帮助寻找一个机器学习模型，该模型可以查看数值，并且可以使用我可以重新利用的一组标准进行预测。
我研究过现有的模型，但我只能找到预测房价的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78791542/finding-a-machine-learning-model</guid>
      <pubDate>Thu, 25 Jul 2024 05:12:34 GMT</pubDate>
    </item>
    <item>
      <title>在列联表和博彩公司知情度/标记度的背景下，DTP 是什么？</title>
      <link>https://stackoverflow.com/questions/78791154/what-is-dtp-in-the-context-of-contingency-tables-and-bookmaker-informedness-mark</link>
      <description><![CDATA[Powers 使用 dtp 概念定义博彩公司知情度/标记度：
“我们可以通过将每个表达式的顶部和底部简化为概率（除以 N2，注意原始偶然性计数总和为 N，简化后的联合概率总和为 1），进一步了解这些回归和相关系数的性质。分子是偶然性矩阵的决定因素，并且是所有三个系数的共同点，简化为 dtp，而回归系数的简化分母仅取决于基础变量的普遍性或偏差。
因此，回归系数博彩公司知情度 (B) 和标记度 (M) 可以用准确率 (Prec) 或召回率以及偏差和流行度 (Prev) 或它们的倒数 (I-) 重新表示：&quot;
全文链接：https://arxiv.org/pdf/2010.16061
博彩公司标记度 = dtp/ [偏差 · (1-偏差)]
博彩公司知情度 = dtp/ [rp·rn]

我不太明白 DTP 是什么。它似乎是列联表的行列式，但我对 DTP 微积分或其首字母缩略词的含义都不是 100% 确定。他说的“所有 3 个系数都相同”是什么意思？在计算行列式之前，我应该将整个矩阵除以 N² 吗？
我期待 DTP 含义及其微积分的正式定义]]></description>
      <guid>https://stackoverflow.com/questions/78791154/what-is-dtp-in-the-context-of-contingency-tables-and-bookmaker-informedness-mark</guid>
      <pubDate>Thu, 25 Jul 2024 01:35:37 GMT</pubDate>
    </item>
    <item>
      <title>hmmlearn 中的隐马尔可夫模型不收敛</title>
      <link>https://stackoverflow.com/questions/78791079/hidden-markov-model-in-hmmlearn-not-converging</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78791079/hidden-markov-model-in-hmmlearn-not-converging</guid>
      <pubDate>Thu, 25 Jul 2024 00:56:12 GMT</pubDate>
    </item>
    <item>
      <title>带有美丽汤的网页抓取图像问题</title>
      <link>https://stackoverflow.com/questions/78790841/web-scraping-images-with-beautiful-soup-issue</link>
      <description><![CDATA[我试图从网上抓取女性平头的图片并将其存储在一个文件夹中，以便以后可以用它来训练模型。然而，我遇到了一个问题，代码输出“DONE”，但我的图片文件夹是空的。我尝试调试并收到错误：无效 URL &#39;/images/branding/googlelogo/2x/googlelogo_color_92x30dp.png&#39;：未提供方案（我删除了代码的调试部分）。
import hashlib, io, request, pandas as pd
from selenium import webdriver
from selenium.webdriver import ChromeOptions
from bs4 import BeautifulSoup
from pathlib import Path
from PIL import Image
import os

def get_content_from_url(url):
options = ChromeOptions()
options.add_argument(&quot;--headless&quot;) # 在无头模式下运行 Chrome
driver = webdriver.Chrome(options=options)

driver.get(url)
page_content = driver.page_source
driver.quit()
return page_content

def parse_image_urls(content, classes, location, source):
soup = BeautifulSoup(content, &quot;html.parser&quot;)
results = []
for a in soup.findAll(attrs={&quot;class&quot;: classes}):
name = a.find(location)
if name and name.get(source) not in results:
results.append(name.get(source))
return results

def save_urls_to_csv(image_urls):
df = pd.DataFrame({&quot;links&quot;: image_urls})
df.to_csv(&quot;links.csv&quot;, index=False, encoding=&quot;utf-8&quot;)

def get_and_save_image_to_file(image_url, output_dir):
image_content = request.get(image_url).content
image_file = io.BytesIO(image_content)
image = Image.open(image_file).convert(&quot;RGB&quot;)
filename = hashlib.sha1(image_content).hexdigest()[:10] + &quot;.png&quot;
file_path = output_dir / filename
image.save(file_path, &quot;PNG&quot;, quality=80)

def main():
url = &quot;https://www.google.com/search?q=female+buzzcut&amp;udm=2&quot; # 用实际 URL 替换
content = get_content_from_url(url)
image_urls = parse_image_urls(
content=content, classes=&quot;srp EIlDfe&quot;, location=&quot;img&quot;, source=&quot;src&quot;
)
save_urls_to_csv(image_urls)

for image_url in image_urls:
get_and_save_image_to_file(
image_url, output_dir=Path(&quot;./images&quot;)
)
if __name__ == &quot;__main__&quot;:
main()
print(&quot;Done!&quot;)

]]></description>
      <guid>https://stackoverflow.com/questions/78790841/web-scraping-images-with-beautiful-soup-issue</guid>
      <pubDate>Wed, 24 Jul 2024 22:34:34 GMT</pubDate>
    </item>
    <item>
      <title>如何追踪之前图像的轮廓？</title>
      <link>https://stackoverflow.com/questions/78790401/how-do-i-track-a-contour-from-my-previous-image</link>
      <description><![CDATA[我有一个细菌细胞移动的视频，我将其转换为帧。现在我想找到每个细菌细胞的瞬时速度。为此，我感兴趣的是找出细菌细胞移动了多少，但我不知道如何告诉我的程序准确识别这种特定的细菌移动了。例如，假设我只有两张图像。对于每张图像，我都有每种细菌的 COM 坐标。现在我如何关联这些数据。我如何让我的程序准确识别这种特定细菌的 COM 变化量。我已将两张图片附上以供参考。


我想到的一个方法是给每个轮廓一个唯一的 id，并将该轮廓的特征与该唯一 id 关联起来。例如它的长轴和短轴长度。这样我就可以关联轮廓的初始和最终 COM。但是这个想法假设所有细菌细胞都是独一无二的，并且我的代码可以准确而精确地识别每个细菌细胞的轮廓，但事实并非如此。如果您感兴趣，我还附上了查找每个细菌细胞轮廓的代码。有人可以提出一些更好的想法吗？非常感谢。
import cv2 as cv
import numpy as np
from numpy.typing import NDArray
import math

def gaussian_filter_multiscale_retinex(image: NDArray, sigmas: list[float], weights: list[float]) -&gt;; NDArray:
img32 = image.astype(&#39;float32&#39;) / 255

img32_log = cv.log(img32 + 1)

msr = np.zeros(image.shape, np.float32)
对于 zip(sigmas, weights) 中的 sigma、weight:

blur = cv.GaussianBlur(img32, ksize=(0, 0), sigmaX=sigma)
blur_log = cv.log(blur + 1)
ssr = cv.subtract(img32_log, blur_log)
ssr = cv.multiply(ssr, weight)

msr = cv.add(msr, ssr)

msr = cv.divide(msr, sum(weights))

msr = cv.normalize(msr, None, 0, 255, cv.NORM_MINMAX, cv.CV_8U)
返回 msr
def calculate_ellipse_area(椭圆):

(cx, cy), (a, b), 角度 = 椭圆
半长轴 = a / 2
半短轴 = b / 2
面积 = math.pi * 半长轴 * 半短轴
返回面积，角度

def process_image(img, size_threshold):
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
rtnx = gaussian_filter_multiscale_retinex(gray, sigmas=[15, 55, 185], weights=[10, 5, 1])
阈值 = cv.adaptiveThreshold(rtnx, 255,自适应方法 = cv.ADAPTIVE_THRESH_GAUSSIAN_C，
阈值类型 = cv.THRESH_BINARY，blockSize = 7，C = -7)
nb_components，输出，统计，_ = cv.connectedComponentsWithStats（阈值，连通性 = 8）
大小 = 统计 [1：，-1]
new_img = np.zeros_like（阈值）
对于 i 在范围内（0，nb_components - 1）：
如果sizes [i]＆gt; = size_threshold：
new_img [输出 == i + 1] = 255
connected_components = cv.connectedComponentsWithStats（new_img）
（numLabels，标签，统计，质心）=connected_components

result_image = np.ones_like（img）* 255
对于 i 在范围内（1， numLabels):
componentMask = (labels == i).astype(&#39;uint8&#39;)
contours, _ = cv.findContours(componentMask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
if len(contours) &gt; 0:
cnt = contours[0]
if len(cnt) &gt;= 5:
ellipse = cv.fitEllipse(cnt)
area, angle = calculate_ellipse_area(ellipse)
if area &lt; 250:
cv.ellipse(result_image, ellipse, (0, 0, 0), 1) # 在白色背景上绘制黑色轮廓
return result_image
img1path = &quot;/Users/yahya2/Desktop/1.png&quot;
img = cv.imread(img1path)
size_threshold = 16
result_image = process_image(img, size_threshold)

cv.imshow(&#39;轮廓&#39;, result_image)
cv.waitKey(0)
cv.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78790401/how-do-i-track-a-contour-from-my-previous-image</guid>
      <pubDate>Wed, 24 Jul 2024 20:14:25 GMT</pubDate>
    </item>
    <item>
      <title>我已经成功安装了 pypdf2，但无法将其导入到我的 python 文件中</title>
      <link>https://stackoverflow.com/questions/78790198/i-have-successfully-installed-the-pypdf2-but-not-able-to-import-it-into-my-pytho</link>
      <description><![CDATA[我已成功安装 pypdf2 模块，但在导入时，我发现缺少此模块。
我尝试使用导入
from PyPDF2 import PdfReader

但它不起作用
此问题有哪些解决方案？]]></description>
      <guid>https://stackoverflow.com/questions/78790198/i-have-successfully-installed-the-pypdf2-but-not-able-to-import-it-into-my-pytho</guid>
      <pubDate>Wed, 24 Jul 2024 19:17:59 GMT</pubDate>
    </item>
    <item>
      <title>Keras CNN 模型对同一输入给出不同的输出预测</title>
      <link>https://stackoverflow.com/questions/78789559/keras-cnn-model-gives-different-output-predictions-for-the-same-input</link>
      <description><![CDATA[嗨，我用 keras 训练了一个 CNN 模型，类似于他们在网站上使用的示例模型，但层数略小，最后还有一个额外的 dropout 层。模型构建函数看起来有点像这样：
&quot; --------- 模型参数 ---------&quot;

epochs = 800
image_size = (384, 256)
batch_size = 128
number_of_layers = 4
drop_out = 0.25
num_dropouts = 2
learn_rate = 0.00001
layer_sizes = [64, 128, 256, 512, 728]
class_weight = {0:1, 1:3}
image_rotation = 0.1

def make_model(input_shape, num_classes, layer_num=3, drop_out=0.25, dropouts=1):
inputs = keras.Input(shape=input_shape)

# 输入块
x = layer.Rescaling(1.0 / 255)(inputs)
x = layer.Conv2D(128, 3, strides=2, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)
x = layer.Activation(&quot;relu&quot;)(x)

previous_block_activation = x # 留出残差

layer_use = []
for i in range(layer_num): layer_use.append(layer_sizes[i])

for size in layer_use:
x = layer.Activation(&quot;relu&quot;)(x)
x = layer.SeparableConv2D(size, 3, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)

x = layer.Activation(&quot;relu&quot;)(x)
x = layer.SeparableConv2D(size, 3, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)

x = layer.MaxPooling2D(3, strides=2, padding=&quot;same&quot;)(x)

# 投影残差
residual = layer.Conv2D(size, 1, strides=2, padding=&quot;same&quot;)(
previous_block_activation
)
x = layer.add([x, residual]) # 添加回残差
previous_block_activation = x # 留出下一个残差

x = layer.SeparableConv2D(1024, 3, padding=&quot;same&quot;)(x)
x = layer.BatchNormalization()(x)
x = layer.Activation(&quot;relu&quot;)(x)

x = layer.GlobalAveragePooling2D()(x)
if num_classes == 2:
unit = 1
else:
unit = num_classes

if dropouts == 1:
x = layer.Dropout(drop_out)(x)
# 我们指定activation=None以便返回logits
outputs = layer.Dense(units,activation=None)(x)
elif dropouts == 2:
x = layer.Dropout(0.2)(x)
x = layer.Dropout(units,activation=None)(x)
outputs = layer.Dropout(drop_out)(x)

返回keras.Model(inputs,outputs)

model = make_model(input_shape=image_size + (3,),num_classes=2,layer_num=number_of_layers,
drop_out=drop_out,dropouts=num_dropouts)

model.compile(
optimizer=keras.optimizers.Adam(learning_rate=learn_rate),
loss=keras.losses.BinaryCrossentropy(from_logits=True),
metrics=[keras.metrics.BinaryAccuracy(name=&quot;acc&quot;)],
)

model.fit(
train_ds,
epochs=epochs,
callbacks=callbacks,
validation_data=val_ds,
class_weight=class_weight
)

模型训练良好 - 达到约 97% 的验证准确率。使用预测函数时，模型通常会根据我提供的输入数据给出合理的输出。我遇到的问题是，使用 predict_on_batch 函数时的输出预测并不相同，如果使用相同的输入数据重复，通常会相差 +-0.15。这是什么原因造成的，一旦模型经过训练并用于预测，对于相同的输入数据，预测难道不应该相同吗？]]></description>
      <guid>https://stackoverflow.com/questions/78789559/keras-cnn-model-gives-different-output-predictions-for-the-same-input</guid>
      <pubDate>Wed, 24 Jul 2024 16:36:55 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Kubeflow Pipelines 中设置启动器和驱动程序映像</title>
      <link>https://stackoverflow.com/questions/78789198/how-to-set-launcher-and-driver-image-in-kubeflow-pipelines</link>
      <description><![CDATA[我正在为我的企业运行 Kubeflow 管道，我们无法使用公共映像。目前，当我运行 Kubeflow Pieplines 时，它会自动转到 gcr.io/ml-pipeline/kfp-driver@sha256:0ce9bf20ac9cbb21e84ff0762d5ae508d21e9c85fde2b14b51363bd1b8cd7528 获取 kfp 驱动程序映像。有没有办法用 KFP SDK 覆盖它？
我看到这个问题已经解决了，但不知道该如何实现。
https://github.com/kubeflow/pipelines/issues/7225]]></description>
      <guid>https://stackoverflow.com/questions/78789198/how-to-set-launcher-and-driver-image-in-kubeflow-pipelines</guid>
      <pubDate>Wed, 24 Jul 2024 15:12:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在窗口上聚合 RESNET50 全局特征？</title>
      <link>https://stackoverflow.com/questions/78788243/how-to-aggregate-resnet50-global-features-over-a-window</link>
      <description><![CDATA[我必须通过时间序列凝视数据集进行人员识别。我有正在观看视频的人的凝视信息，并且对于每个时间戳，我都会从视频中获取裁剪的帧以了解人员正在看哪里，然后将其提供给 RESNET-50 预训练模型以提取其特征。从模型中删除最后一个分类层，以便我获得每个图像的 2048 维向量。
最后，我有一个带有时间戳的时间序列数据，对于每一行，凝视信息 + 2048 个来自 RESNET 模型的特征。我的目标是使用凝视特征进行人员识别，并在这些凝视特征之上，输出 RESNET 特征。
现在，我想进行特征聚合，可能在窗口大小上进行。我一直在研究像 Fischer 向量这样的局部特征聚合方法，但我拥有的是图像的全局特征。
TL;DR，有没有一种好的方法可以在窗口大小上聚合 RESNET-50 特征？
我尝试过使用常见的聚合方法，如均值和方差、最大最小值等，但不确定聚合结果是否对应有意义的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78788243/how-to-aggregate-resnet50-global-features-over-a-window</guid>
      <pubDate>Wed, 24 Jul 2024 12:07:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 SHAP 值生成的蜂群图中点的可见性问题</title>
      <link>https://stackoverflow.com/questions/78788072/issue-with-visibility-of-points-in-beeswarm-plot-generated-using-shap-values</link>
      <description><![CDATA[我理解，在蜂群图中，实例以点/点来表示。因此，人们可以根据 SHAP 值找到水平分布（沿 x 轴）的点簇，当 SHAP 值密度较高时，这些点簇垂直堆叠（沿 y 轴）。
在大多数文档中，我看到蜂群图看起来像这样（https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/）：

创建蜂群图后，我无法清晰地看到这些点。我注意到形状点的边缘形成了更平滑的表面。我不确定我做对了什么或做错了什么，如果您能帮助我改变这一点，我将不胜感激。
这是我运行的代码。
shap_values = explainer.shap_values(X.iloc[0:N_VAL,:], nsamples=NSHAP_SAMPLES)

shap.summary_plot(shap_values, X.iloc[:N_VAL, :], plot_type=&quot;violin&quot;, max_display=21, show=False)

# 调整图形大小以确保所有内容都适合
plt.gcf().set_size_inches(15, 10) # 根据需要调整大小

# 显示图表
plt.show()

代码生成下面的图表

如果您能帮助我了解这里发生了什么以及如何处理这个问题，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78788072/issue-with-visibility-of-points-in-beeswarm-plot-generated-using-shap-values</guid>
      <pubDate>Wed, 24 Jul 2024 11:33:37 GMT</pubDate>
    </item>
    <item>
      <title>安装 tf-models-official 时出现元数据生成失败</title>
      <link>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</link>
      <description><![CDATA[我尝试使用 !pip install tf-models-official 安装 tf-models-official，当它开始收集 kaggle&gt;=1.3.9 时，它返回以下错误：
收集 kaggle&gt;=1.3.9（来自 tf-models-official）
使用缓存的 kaggle-1.6.15.tar.gz (9.1 kB)
安装构建依赖项...完成
获取构建 wheel 的要求...完成
准备元数据（pyproject.toml）...错误
错误：子进程退出并出现错误

× 准备元数据（pyproject.toml）未成功运行。
│ 退出代码：1
╰─&gt; [35 行输出]
回溯（最近一次调用）：
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 353 行，位于 &lt;module&gt;
main()
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 335 行，在 main 中
json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 152 行，在 prepare_metadata_for_build_wheel 中
whl_basename = backend.build_wheel(metadata_directory, config_settings)
文件&quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/build.py&quot;，第 58 行，在 build_wheel 中
return os.path.basename(next(builder.build(directory=wheel_directory,versions=[&#39;standard&#39;])))
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;，第 155 行，在 build 中
artifact = version_api[version](directory,**build_data)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 475 行，在build_standard
for included_file in self.recurse_included_files():
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 176, in recurse_included_files
Yield from self.recurse_selected_project_files()
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 180, in recurse_selected_project_files
if self.config.only_include:
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/config.py&quot;，第 806 行，在 only_include 中
only_include = only_include_config.get(&#39;only-include&#39;, self.default_only_include()) 或 self.packages
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 260 行，在 default_only_include 中
return self.default_file_selection_options.only_include
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/functools.py&quot;，第 981 行，在__get__
val = self.func(instance)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 248 行，位于 default_file_selection_options
raise ValueError(message)
ValueError：无法使用以下启发式方法确定要将哪些文件发送到 wheel 内：https://hatch.py​​pa.io/latest/plugins/builder/wheel/#default-file-selection

最可能的原因是没有与您的项目 (kaggle) 名称匹配的目录。

必须在 `tool.hatch.build.targets.wheel` 表中定义至少一个文件选择选项，请参阅：https://hatch.py​​pa.io/latest/config/build/

例如，如果您打算发送一个名为 `foo` 的目录，该目录位于项目根目录的 `src` 目录中，则可以定义以下内容：

[tool.hatch.build.targets.wheel]
packages = [&quot;src/foo&quot;]
[输出结束]

注意：此错误源自子进程，可能不是 pip 的问题。
错误：metadata-generation-failed

× 生成包元数据时遇到错误。
╰─&gt; 请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip。
提示：请参阅上文了解详情。

我能够在 2 周前安装，现在在新的 jupyter 笔记本内核上突然无法安装。我尝试在旧内核上重新安装，也出现了同样的错误。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</guid>
      <pubDate>Wed, 24 Jul 2024 07:02:59 GMT</pubDate>
    </item>
    <item>
      <title>XGBoostError：参数详细程度的值 -1 超出界限 [0,3]</title>
      <link>https://stackoverflow.com/questions/78761783/xgboosterror-value-1-for-parameter-verbosity-exceed-bound-0-3</link>
      <description><![CDATA[错误消息如标题所示。根据下面的代码，这对我来说毫无意义：
clf = xgboost.XGBClassifier(verbosity=1)
print (clf.__class__, clf.verbosity) 
# prints &lt;class &#39;xgboost.sklearn.XGBClassifier&#39;&gt; 1
clf.fit(X=train_data_iter[features].fillna(0), y=train_data_iter[&#39;y&#39;]) # 错误在这里出现

值显然是 1，但不知何故却变成了 -1？我不明白。]]></description>
      <guid>https://stackoverflow.com/questions/78761783/xgboosterror-value-1-for-parameter-verbosity-exceed-bound-0-3</guid>
      <pubDate>Wed, 17 Jul 2024 22:12:23 GMT</pubDate>
    </item>
    <item>
      <title>没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块</title>
      <link>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</link>
      <description><![CDATA[代码下方
import numpy as np
np.random.seed(0)
from sklearn import datasets
import matplotlib.pyplot as plt
%matplotlib inline
%config InlineBackend.figure_format =&#39;retina&#39;

from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import SGD

错误消息下方
-------------------------------------------------------------------------------
ModuleNotFoundError Traceback (most recent call last)
~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
2 try:
----&gt; 3 from tensorflow.keras.layers.experimental.preprocessing import RandomRotation
4 except ImportError:

ModuleNotFoundError: 没有名为“tensorflow.keras.layers.experimental.preprocessing”的模块

在处理上述异常期间，发生了另一个异常：

ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-5-943507dd87a6&gt; in &lt;module&gt;
6 get_ipython().run_line_magic(&#39;config&#39;, &quot;InlineBackend.figure_format =&#39;retina&#39;&quot;)
7 
----&gt; 8 从 keras.models 导入 Sequential
9 从 keras.layers 导入 Dense
10 从 keras.optimizers 导入 SGD

~\Anaconda3\lib\site-packages\keras\__init__.py in &lt;module&gt;
4 except ImportError:
5 raise ImportError(
----&gt; 6 &#39;Keras 需要 TensorFlow 2.2 或更高版本。&#39;
7 &#39;通过 `pip install tensorflow`&#39; 安装 TensorFlow)
8 

ImportError: Keras 需要 TensorFlow 2.2 或更高版本。通过 `pip install tensorflow` 安装 TensorFlow

注意：`我认为，主要问题是 Tensorflow 版本。我使用了一些命令，如下所示，
conda create -n tf tensorflow
conda activate tf

我还使用了以下命令
conda create -n tf-gpu tensorflow-gpu
conda activate tf-gpu

但是它不起作用，请帮助解决错误。]]></description>
      <guid>https://stackoverflow.com/questions/63542803/no-module-named-tensorflow-keras-layers-experimental-preprocessing</guid>
      <pubDate>Sun, 23 Aug 2020 02:18:29 GMT</pubDate>
    </item>
    <item>
      <title>如何计算伯努利朴素贝叶斯的联合对数似然</title>
      <link>https://stackoverflow.com/questions/52861129/how-to-calculate-the-joint-log-likelihood-for-bernoulli-naive-bayes</link>
      <description><![CDATA[对于使用 BernoulliNB 的分类问题，如何计算联合对数似然。联合似然由以下公式计算，其中 y(d) 是实际输出（不是预测值）的数组，x(d) 是特征的数据集。
我阅读了这个答案并阅读了文档，但它并没有完全满足我的目的。有人可以帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/52861129/how-to-calculate-the-joint-log-likelihood-for-bernoulli-naive-bayes</guid>
      <pubDate>Wed, 17 Oct 2018 18:08:50 GMT</pubDate>
    </item>
    </channel>
</rss>