<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 23 Dec 2024 12:33:09 GMT</lastBuildDate>
    <item>
      <title>训练 transformer 模型时出现 OOM 错误</title>
      <link>https://stackoverflow.com/questions/79302713/oom-error-when-training-transformer-model</link>
      <description><![CDATA[我正在研究 HMER（手写数学表达式识别）问题，并尝试使用 CNN-Transformer 架构。但是，当我尝试训练我的模型时，我遇到了此错误：
DefaultCPUAllocator：内存不足：您尝试分配 69271363584 字节。
我认为我的位置编码存在一些问题，但我真的不知道如何调试它或这里真正的问题是什么（我在这方面还只是初学者）
我当前的模型如下所示
class PositionalEncoding(nn.Module):
def __init__(self, d_model, max_len=5000):
super(PositionalEncoding, self).__init__()
self.encoding = torch.zeros(max_len, d_model)
position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
self.encoding[:, 0::2] = torch.sin(position * div_term)
self.encoding[:, 1::2] = torch.cos(position * div_term)
self.encoding = self.encoding.unsqueeze(0) # 添加批次维度

def forward(self, x):
seq_len = x.size(1)
return x + self.encoding[:, :seq_len, :].to(x.device)

class TransformerDecoder(nn.Module):
def __init__(self, vocab_size, d_model, num_heads, num_layers, max_seq_length):
super(TransformerDecoder, self).__init__()
self.embedding = nn.Embedding(vocab_size, d_model)
self.positional_encoding = PositionalEncoding(d_model, max_seq_length)
decrypt_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=num_heads)
self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)
self.fc_out = nn.Linear(d_model, vocab_size)

def forward(self, target_seqs, memory, target_mask):
# 嵌入目标序列
embedded = self.embedding(target_seqs) # (batch, seq_len, d_model)
embedded = checkpoint(self.positional_encoding, embedded) # 添加位置编码
# 转置以兼容 nn.TransformerDecoder (seq_len, batch, d_model)
embedded = embedded.permute(1, 0, 2)
memory = memory.permute(1, 0, 2)
# 解码
coded = checkpoint(self.transformer_decoder, embedded, memory, target_mask) # (seq_len, batch, d_model)
# 转置回 (batch, seq_len, d_model)
coded = decrypted.permute(1, 0, 2)
# 最终输出层
logits = checkpoint(self.fc_out,coded) # (batch, seq_len, vocab_size)
return logits


我的代码有什么问题吗？如果没有，是什么原因导致我遇到这个问题的]]></description>
      <guid>https://stackoverflow.com/questions/79302713/oom-error-when-training-transformer-model</guid>
      <pubDate>Mon, 23 Dec 2024 09:44:33 GMT</pubDate>
    </item>
    <item>
      <title>并集和交集的 VC 维数的上限[关闭]</title>
      <link>https://stackoverflow.com/questions/79302585/upper-bound-on-vc-dimension-of-union-and-intersection</link>
      <description><![CDATA[问题：类 C 的 VC 维度为 d。类 C’ 包括由 C 中 s 个对象的交集和并集（以任何顺序）形成的所有对象。给出 C’ 的 VC 维度的上限。
尝试
我知道，如果 H 是大小为 s 且 VC 维度为 d 的假设类。以下为真：
如果 H&#39; 是由来自 H 的 s 个假设的所有并集形成的类，并且 s ≥ 1。则 VC 维度 (𝐻&#39;) ≤ $2𝑑𝑠log{_2}⁡(3𝑠)$。
如果 H&#39; 是由所有交集形成的类，则同样为真。
从这里开始是我的尝试：
为了形成 C’，我们允许交集和并集的嵌套组合。这意味着 $⋃{{i=1}}⋂{{j=1}}c{_{ij}}$，其中 c∈C。
如果 𝐶${_⋃}$ 和 𝐶${_⋂}$ 是两个假设类，则它们在并集或交集中的组合类的 VC 维数最多是它们的 VC 维数之和。
每个额外的并集或交集层最多对子集的组合增长贡献 $log{_2}⁡(3𝑠)$。因此，C’ 的 VC 维数受以下限制：VC(C’) ≤ $4𝑑𝑠log{_2}⁡(3𝑠)$。
我很想听听你对这是否正确的看法。]]></description>
      <guid>https://stackoverflow.com/questions/79302585/upper-bound-on-vc-dimension-of-union-and-intersection</guid>
      <pubDate>Mon, 23 Dec 2024 08:40:39 GMT</pubDate>
    </item>
    <item>
      <title>二进制交叉熵的实现给出不正常的结果</title>
      <link>https://stackoverflow.com/questions/79302179/implementation-of-binary-cross-entropy-gives-not-normal-result</link>
      <description><![CDATA[我正在尝试构建一个 NN，但在训练阶段，我得到的损失函数值就异常了。这是为什么呢？
哦，我只能使用 NumPy。
这就是数据看起来相似的方式：
print(X_train.shape) #(784,800)
print(X_test.shape) #(784,200)
print(Y_train.shape) #(800,1)
print(Y_test.shape) #(200,1)

损失函数 - BCE
def log_loss(y_hat, y):
m = y.shape[0]
epsilon = 1e-15 
y_hat = np.clip(y_hat, epsilon, 1 - epsilon) 

# loss = -1/m * (y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))
损失 = -1/m * (np.dot(y.T,np.log(y_hat)) + np.dot((1-y).T, np.log(1-y_hat)))
回报损失

训练阶段 - 前向传播 + 反向传播
input_layer = X_train.shape[0]
hidden_​​layer = 128
learning_rate = 0.01
epochs = 10

W1 = np.random.randn(hidden_​​layer, input_layer)
b1 = np.zeros((hidden_​​layer, 1))
W2 = np.random.randn(1, hidden_​​layer)
b2 = np.zeros((1, 1))

X = X_train
Y = Y_train
loss_list = []
epoch_list = []
num_of_examples = X.shape[1]

for i in range(epochs):
avg_epoch_loss = 0
for j in range(num_of_examples):

Z1 = np.matmul(W1,X[:,j].reshape(-1,1)) + b1 # 不要忘记添加偏差
A1 = sigmoid(Z1)
Z2 = np.matmul(W2,A1) + b2
A2 = sigmoid(Z2)
Yout = Y[j]

loss = log_loss( A2, Yout)
avg_epoch_loss = avg_epoch_loss + loss

dZ2 = (A2-Yout)
dW2 = np.matmul(dZ2,A1.T)
db2 = dZ2

dA1 = np.matmul(W2.T,dZ2)
dZ1 = dA1 * A1 * (1 - A1)
dW1 = np.matmul(dZ1,X[:,j].reshape(-1,1).T)
db1 = dZ1

W2 = W2 - 学习率 * dW2
b2 = b2 - 学习率 * db2
W1 = W1 - 学习率 * dW1
b1 = b1 - 学习率 * db1

avg_epoch_loss = avg_epoch_loss/num_of_examples
loss_list.append(avg_epoch_loss)
epoch_list.append(i)
print(&quot;Epoch&quot;, i,&quot;损失：&quot;，avg_epoch_loss)

这些是不正常的值 - 当然是寻找 0-1 之间的值：
Epoch 0 损失：[-18.37821485]
Epoch 1 损失：[-18.82406892]
Epoch 2 损失：[-18.82406892]
Epoch 3 损失：[-19.99316345]
Epoch 4 损失：[-29.91647793]
Epoch 5 损失：[-32.32075724]
Epoch 6 损失：[-32.89639034]
Epoch 7 损失：[-32.34691639]
Epoch 8 损失： [-32.749394]
第 9 阶段损失：[-33.61631871]
]]></description>
      <guid>https://stackoverflow.com/questions/79302179/implementation-of-binary-cross-entropy-gives-not-normal-result</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 ONNXRuntime C++ 优化 Florence-2 模型推理 - 生成循环的性能优化 [关闭]</title>
      <link>https://stackoverflow.com/questions/79302122/optimizing-florence-2-model-inference-with-onnxruntime-c-performance-optimiz</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79302122/optimizing-florence-2-model-inference-with-onnxruntime-c-performance-optimiz</guid>
      <pubDate>Mon, 23 Dec 2024 04:15:57 GMT</pubDate>
    </item>
    <item>
      <title>模型无法正常学习[关闭]</title>
      <link>https://stackoverflow.com/questions/79301299/model-cant-learn-normally</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79301299/model-cant-learn-normally</guid>
      <pubDate>Sun, 22 Dec 2024 16:24:38 GMT</pubDate>
    </item>
    <item>
      <title>单个卷积滤波器是否可以组合来自输入多个通道的值[关闭]</title>
      <link>https://stackoverflow.com/questions/79301125/can-single-convolutional-filter-combine-values-from-input-multiple-channels</link>
      <description><![CDATA[关于卷积神经网络的问题。
第 1 部分：假设输入是 RGB 图像，我们将其放入卷积层。人们是否曾经使用同时对输入的多个通道（例如 R 和 G）进行操作的过滤器，并在计算中结合两个通道的值？换句话说，过滤器矩阵是 3D（或更多）还是 2D？
第 2 部分：如果我错了，请纠正我，但有时在同一层中可以有多个过滤器。我的意思是，也许输入图像有 1 个通道（灰度），但层的输出有 2 个通道。这相当于有 2 个独立的过滤器，即 2 个不同的 3x3 矩阵，每个矩阵产生一个通道。
我理解过滤器是一个单一（例如 3x3）矩阵，我们在输入图像周围移动它并计算它“覆盖”的区域的某个加权平均值。]]></description>
      <guid>https://stackoverflow.com/questions/79301125/can-single-convolutional-filter-combine-values-from-input-multiple-channels</guid>
      <pubDate>Sun, 22 Dec 2024 14:04:26 GMT</pubDate>
    </item>
    <item>
      <title>我可以在 MacbookM4 上使用 CUDA 吗？[重复]</title>
      <link>https://stackoverflow.com/questions/79300848/can-i-use-cuda-on-macbookm4</link>
      <description><![CDATA[我正在尝试为我的本科论文创建一个动作检测系统。
我现在正尝试将 MMSkeleton 集成到我的项目管道中。https://github.com/open-mmlab/mmskeleton
要使用 MMSkeleton，我需要安装 PyTorch 和 torchvision（需要 CUDA），但据我所知，Mac 无法做到这一点。我收到此错误 OSError：编译 MMSkeleton 需要 CUDA！
有人知道我该如何克服这个障碍吗？]]></description>
      <guid>https://stackoverflow.com/questions/79300848/can-i-use-cuda-on-macbookm4</guid>
      <pubDate>Sun, 22 Dec 2024 10:49:49 GMT</pubDate>
    </item>
    <item>
      <title>为什么当 refit=True 时，在 RandomizedSearchCV 之后会进行额外的拟合？</title>
      <link>https://stackoverflow.com/questions/79300159/why-is-an-additional-fitting-performed-after-randomizedsearchcv-when-refit-true</link>
      <description><![CDATA[我正在使用 scikit-learn 中的 RandomizedSearchCV 进行超参数调整，并注意到即使 refit 参数设置为 True，在找到最佳参数后也会执行额外的拟合步骤。
这是一个最小的可重现示例：
来自 sklearn.datasets 导入 make_classification
来自 sklearn.model_selection 导入 RandomizedSearchCV
来自 sklearn.ensemble 导入 RandomForestClassifier
来自 scipy.stats 导入 randint

# 生成合成数据集
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# 定义模型和参数分布
model = RandomForestClassifier(random_state=42)
param_dist = {
&#39;n_estimators&#39;: randint(10, 100),
&#39;max_depth&#39;: randint(3, 20),
}

# 执行 RandomizedSearchCV
search = RandomizedSearchCV(
model, param_dist, n_iter=10, cv=3, random_state=42, refit=True
)
search.fit(X, y)

# 访问最佳估计器
best_model = search.best_estimator_

print(best_model)

我理解 refit=True 标志表示在超参数调整后，应在整个数据集上重新拟合最佳模型。但是，为什么交叉验证中的“最佳模型”不直接作为 search.best_estimator_ 返回？对整个数据集执行另一个拟合步骤的原因是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79300159/why-is-an-additional-fitting-performed-after-randomizedsearchcv-when-refit-true</guid>
      <pubDate>Sat, 21 Dec 2024 21:49:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 MaxViT 进行迁移学习时我的分类器应该是什么？</title>
      <link>https://stackoverflow.com/questions/79300055/what-should-be-my-classifier-in-transfer-learning-using-maxvit</link>
      <description><![CDATA[我正在尝试使用自定义数据集在 Pytorch 预训练模型上进行迁移学习。我已经能够使用 SqueezeNet 成功执行迁移学习。
对于 Squeezenet，我的分类器是，layers source
model.classifier = nn.Sequential(
nn.Dropout(p=0.2),
nn.Conv2d(512, len(class_names), kernel_size=1),
nn.ReLU(inplace=True),
nn.AdaptiveAvgPool2d((1, 1)))

对于 Efficientnet，我的分类器是，layers source
model.classifier = torch.nn.Sequential(
torch.nn.Dropout(p=0.2, inplace=True),
torch.nn.Linear(in_features=1280,
out_features=output_shape,
bias=True))

我也一直在尝试为 MaxViT 做类似的事情，我查看了源代码，发现参数中有 block_channels[-1]。我最近开始用这个，不知道它们是什么，layers source
self.classifier = nn.Sequential(
nn.AdaptiveAvgPool2d(1),
nn.Flatten(),
nn.LayerNorm(block_channels[-1]),
nn.Linear(block_channels[-1], block_channels[-1]),
nn.Tanh(),
nn.Linear(block_channels[-1], num_classes, bias=False),
)

如果需要，以下是我使用 squeezenet 执行迁移学习的完整代码，仅供参考。
weights = torchvision.models.SqueezeNet1_0_Weights.DEFAULT
model = torchvision.models.squeezenet1_0(weights=weights).to(device)
auto_transforms = weights.transforms()
train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=d1,
test_dir=d2,
transform=auto_transforms,
batch_size=32)
for param in model.features.parameters():
param.requires_grad = False

torch.manual_seed(42)
torch.cuda.manual_seed(42)
output_shape = len(class_names)

model.classifier = nn.Sequential(
nn.Dropout(p=0.2),
nn.Conv2d(512, len(class_names), kernel_size=1),
nn.ReLU(inplace=True),
nn.AdaptiveAvgPool2d((1, 1))).to(device)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
torch.manual_seed(42)
torch.cuda.manual_seed(42)
results = engine.train(model=model,
train_dataloader=train_dataloader,
test_dataloader=test_dataloader,
optimizer=optimizer,
loss_fn=loss_fn,
epochs=15,
device=device)

我的 MaxViT 分类器应该是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79300055/what-should-be-my-classifier-in-transfer-learning-using-maxvit</guid>
      <pubDate>Sat, 21 Dec 2024 20:24:49 GMT</pubDate>
    </item>
    <item>
      <title>ST-GCN 是否过时了？[关闭]</title>
      <link>https://stackoverflow.com/questions/79297114/is-st-gcn-outdated</link>
      <description><![CDATA[我正在尝试构建一个管道来跟踪视频监控录像中的异常情况。
为了对检测到的人的行为进行分类，我想使用 ST-GCN，但是我能找到的唯一文档是 5 年前更新的，但阅读最新研究 ST-GCN 仍在使用中。
有谁知道更新的文档或能给我一些提示，告诉我如何找到一些关于如何将其实现到我的管道中的信息？]]></description>
      <guid>https://stackoverflow.com/questions/79297114/is-st-gcn-outdated</guid>
      <pubDate>Fri, 20 Dec 2024 11:42:14 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch GRU 错误 RuntimeError：大小不匹配，m1：[1600 x 3]，m2：[50 x 20]</title>
      <link>https://stackoverflow.com/questions/66131870/pytorch-gru-error-runtimeerror-size-mismatch-m1-1600-x-3-m2-50-x-20</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/66131870/pytorch-gru-error-runtimeerror-size-mismatch-m1-1600-x-3-m2-50-x-20</guid>
      <pubDate>Wed, 10 Feb 2021 06:23:22 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的神经网络[关闭]</title>
      <link>https://stackoverflow.com/questions/61845701/neural-network-in-python</link>
      <description><![CDATA[我最近开始尝试在不使用任何 NW 模块（如 Tensor Flow）的情况下创建自己的神经网络，但我无法将已定义的变量放入函数中，因此我将数据放入文本文件中，然后对其进行读写。虽然它不允许我将权重重新转换为 int，以便我可以将它们乘以它们的学习率。我收到一条错误消息，提示 int 不适用于基数。

你对此有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/61845701/neural-network-in-python</guid>
      <pubDate>Sun, 17 May 2020 01:07:59 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中初始化权重？</title>
      <link>https://stackoverflow.com/questions/49433936/how-do-i-initialize-weights-in-pytorch</link>
      <description><![CDATA[如何初始化网络的权重和偏差（例如通过 He 或 Xavier 初始化）？]]></description>
      <guid>https://stackoverflow.com/questions/49433936/how-do-i-initialize-weights-in-pytorch</guid>
      <pubDate>Thu, 22 Mar 2018 16:34:42 GMT</pubDate>
    </item>
    <item>
      <title>神经网络（简单）</title>
      <link>https://stackoverflow.com/questions/46079541/neural-network-simple</link>
      <description><![CDATA[我很好奇为什么我没有打印任何输出，因为代码没有错误。
import numpy as np

class NN():
def _init_(self):
# 种子随机数生成器，因此每次程序运行时都会生成相同的数字
# np.random.seed(1)

# 模型单个神经元，具有 3 个输入连接和 1 个输出连接
# 将随机权重分配给 3x1 矩阵，值范围为 -1 到 1
# 平均值为 0
self.synaptic_weights = 2 * np.random.random((3, 1)) - 1

# 描述 s 形曲线我们传递输入的加权和
# 通过此函数将它们标准化为 0 和 1 之间
def __sigmoid(self, x):
return 1 / (1 + np.exp(-x))

# 梯度sigmoid 曲线
def __sigmoid_derivative(self, x):
return x * (1 - x)

def train(self, training_set_input, training_set_output, number_of_training_iterations):
for iteration in np.xrange(number_of_training_iterations):
# 将训练集通过神经网络
output = self.predict(training_set_input)

error = training_set_output - output

# 将误差乘以输入，再乘以 sigmoid 曲线的梯度
adjustment = np.dot(training_set_input.T, error * self.__sigmoid_derivative(output))

# 调整权重
self.synaptic_weights += adjustment

def predict(self, input):
# 将输入通过神经网络（单个神经元）
return self.__sigmoid(np.dot(inputs, self.synaptic_weights))

if __name__ == &quot;__NN__&quot;:
# 初始化单神经元神经网络
nn = NN()
weightz = nn.synaptic_weights
new_predict = nn.predict(np.array[1, 0, 0])

print(&quot;随机起始突触权重&quot;)
print(weightz)

# T 垂直翻转矩阵
training_set_input = np.array([0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1])
training_set_output = np.array([0, 1, 0, 0]).T

# 使用训练集训练网络
# 执行 10,000 次，每次进行小幅调整
nn.train(training_set_input, training_set_output, 10000)

print(&quot;新的起始突触权重&quot;)
print(weightz)

# 测试
print(&quot;预测&quot;)
print(new_predict)

将文件保存为 NN.py]]></description>
      <guid>https://stackoverflow.com/questions/46079541/neural-network-simple</guid>
      <pubDate>Wed, 06 Sep 2017 15:51:06 GMT</pubDate>
    </item>
    <item>
      <title>使用 MLP 的神经网络分类器</title>
      <link>https://stackoverflow.com/questions/43238285/neural-network-classifier-using-mlp</link>
      <description><![CDATA[我正在开发一个 Python 应用程序，它使用一个数据集对扑克牌进行分类，我将发布一些片段。它似乎效果不佳。它无法正确地对牌进行分类。我得到了以下错误
第 298 行，在 fit 中
raise ValueError(&quot;Multioutput target data is not supports with &quot;
ValueError: Multioutput target data is not supports with label binarization

以下是我的代码：
import pandas as pnd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classes_report
training = pnd.read_csv(&quot;.idea/train.csv&quot;)
training.keys()
training.shape
X = np.array(training)
y = np.array(training)
X_train, X_test, y_train, y_test = train_test_split(X, y)
scaler = StandardScaler()
# 仅适合训练数据
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
mlp = MLPClassifier(hidden_​​layer_sizes=(30, 30, 30, 30, 30, 30, 30, 30, 30))
mlp.fit(X_train, y_train)
predictions = mlp.predict(X_test)
print(classification_report(y_test, predictions))
len(mlp.coefs_)
len(mlp.coefs_[0])
len(mlp.intercepts_[0])

以下是我使用的数据集示例：
图片在这里
这里是数据集的描述：
https://archive.ics.uci.edu/ml/datasets/Poker+Hand
有什么问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/43238285/neural-network-classifier-using-mlp</guid>
      <pubDate>Wed, 05 Apr 2017 17:50:50 GMT</pubDate>
    </item>
    </channel>
</rss>