<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 16 Jan 2024 03:16:24 GMT</lastBuildDate>
    <item>
      <title>PyTorch 中 NxM 密集层和 M 个单独的 Nx1 密集层之间的差异</title>
      <link>https://stackoverflow.com/questions/77823080/differences-between-a-nxm-dense-layer-and-m-separate-nx1-dense-layers-in-pytorch</link>
      <description><![CDATA[我很好奇这两种设计选择如何影响训练过程中的梯度计算和优化过程。在反向传播过程中，每个结构的梯度计算会受到怎样的影响？梯度流回网络的方式有什么不同吗？这些不同的网络结构是否需要或受益于不同的优化算法或学习率？我的目的是从梯度计算和优化的角度了解每种模型结构选择的潜在好处和可能的缺点。我以为“渐变”会是一样的，但结果是不同的。
我还尝试了一个实验，将两个模型的权重初始化为 1。然而，当我比较反向传播后的梯度时，它们是不同的。
&lt;前&gt;&lt;代码&gt;
张量(\[\[ 0.0289026424, 0.0164458379, -0.0429413468, -0.0317727998,
\-0.0011618818、0.0309777111、0.0496413819、-0.0330999792、
\-0.0217525940, -0.0376570895, 0.0238987785, -0.0303875748,
0\.0422640890, -0.0327035226, -0.0046056593, 0.0095992200,
0\.0047464888, -0.0015923150, -0.0349406302, 0.0358588137,
0\.0109524736, 0.0521549769, 0.0092769144, 0.0338292755,
0\.0418556146, 0.0403830707, 0.0027946709, -0.0142157376,
0\.0573743209, 0.0421377942, 0.0161724705, 0.0135669028,
0\.0103750098, 0.0048434297, -0.0176108982, -0.0011629635,
0\.0177134797, 0.0047528706, 0.0455351323, -0.0127471210,
\-0.0103122834, 0.0092379786, -0.0011389051, 0.0214950778,
0\.0423520021, 0.0157480091, 0.0166458990, -0.0457958765\]\])
张量(\[\[ 0.0289026424, 0.0164458416, -0.0429413430, -0.0317727998,
\-0.0011618854、0.0309777092、0.0496413782、-0.0330999792、
\-0.0217525922，-0.0376570858，0.0238987822，-0.0303875823，
0\.0422640815, -0.0327035226, -0.0046056607, 0.0095992228,
0\.0047464883, -0.0015923139, -0.0349406339, 0.0358588099,
0\.0109524755, 0.0521549769, 0.0092769163, 0.0338292755,
0\.0418556109, 0.0403830633, 0.0027946699, -0.0142157376,
0\.0573743209, 0.0421377942, 0.0161724724, 0.0135669019,
0\.0103750126, 0.0048434315, -0.0176109001, -0.0011629632,
0\.0177134816, 0.0047528730, 0.0455351323, -0.0127471173,
\-0.0103122853, 0.0092379786, -0.0011389013, 0.0214950833,
0\.0423520021, 0.0157480109, 0.0166459009, -0.0457958728\]\])
火炬.Size(\[48\])
第 12 层的渐变大小为 torch.Size(\[1, 48\])
第 12 层的梯度相同吗？错误的
]]></description>
      <guid>https://stackoverflow.com/questions/77823080/differences-between-a-nxm-dense-layer-and-m-separate-nx1-dense-layers-in-pytorch</guid>
      <pubDate>Tue, 16 Jan 2024 01:37:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 MLflow 中管理数据集？</title>
      <link>https://stackoverflow.com/questions/77822962/how-to-manage-datasets-in-mlflow</link>
      <description><![CDATA[考虑以下取自 MLflow 文档页面&lt;的代码片段&lt; /a&gt;：
导入 mlflow.data
将 pandas 导入为 pd
从 mlflow.data.pandas_dataset 导入 PandasDataset

# 使用来自 Web URL 的鸢尾花数据构建 Pandas DataFrame
dataset_source_url =“http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv”
df = pd.read_csv(dataset_source_url)
# 从 Pandas DataFrame 构造一个 MLflow PandasDataset，并指定 Web URL
# 作为源
数据集：PandasDataset = mlflow.data.from_pandas(df, source=dataset_source_url)

使用 mlflow.start_run()：
    # 将数据集记录到 MLflow Run。指定“训练”上下文表明
    # 数据集用于模型训练
    mlflow.log_input（数据集，上下文=“训练”）

# 检索运行，包括数据集信息
运行 = mlflow.get_run(mlflow.last_active_run().info.run_id)
dataset_info = run.inputs.dataset_inputs[0].dataset
print(f&quot;数据集名称: {dataset_info.name}&quot;)
print(f&quot;数据集摘要：{dataset_info.digest}&quot;)
print(f&quot;数据集配置文件：{dataset_info.profile}&quot;)
print(f&quot;数据集模式：{dataset_info.schema}&quot;)

# 加载数据集的源，即从源URL下载内容到本地
＃ 文件系统
dataset_source = mlflow.data.get_source(dataset_info)
dataset_source.load()

此代码正在开始新的运行并记录作为数据集的输入。这是否意味着在 MLflow 中我们将数据集保存为单独的运行？如果是这样的话，我们如何将具有自己的运行的模型的训练与数据集关联起来？我很困惑 MLflow 如何处理/跟踪数据集！说实话，我期望数据集是不同的实体类型（与运行），我们可以将它们链接到用于模型训练的每次运行。]]></description>
      <guid>https://stackoverflow.com/questions/77822962/how-to-manage-datasets-in-mlflow</guid>
      <pubDate>Tue, 16 Jan 2024 00:40:36 GMT</pubDate>
    </item>
    <item>
      <title>尝试运行 SVC 分类模型，花了一个小时但没有响应</title>
      <link>https://stackoverflow.com/questions/77822664/trying-to-run-a-classification-model-for-svc-taking-hour-and-not-responding</link>
      <description><![CDATA[我已经尝试运行 SVC 分类模型三天了，但该模型没有响应。我检查了我的数据、标准缩放器、训练测试拆分和所有必要的库，所有这些都已正确应用和工作。我运行随机森林分类器模型，该模型运行成功，但存在良好的准确度分数（F1 分数）。但是 SVC 不工作，可能是什么问题？
我尝试过 RandomForest，效果很好，但 SVC 从未起作用。可能是什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77822664/trying-to-run-a-classification-model-for-svc-taking-hour-and-not-responding</guid>
      <pubDate>Mon, 15 Jan 2024 22:38:54 GMT</pubDate>
    </item>
    <item>
      <title>这段代码与现实的元学习算法有多接近？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77821777/how-close-is-this-code-to-a-realistic-metalearning-algorithm</link>
      <description><![CDATA[
maxjann.com/code
我使用 Chat-GPT 4 生成了一个算法，我想知道真正的程序员如何看待这个想法的有用性。
我的想法是元学习算法，它是关于学习算法的学习算法。
目标是超级智能。
ChatGPT Plus 吐出了一些伪代码，但我想知道这些代码是否实际上是革命性的或有缺陷的。]]></description>
      <guid>https://stackoverflow.com/questions/77821777/how-close-is-this-code-to-a-realistic-metalearning-algorithm</guid>
      <pubDate>Mon, 15 Jan 2024 18:47:09 GMT</pubDate>
    </item>
    <item>
      <title>检查输入时出错：期望 flatten_input 有 3 个维度，但得到形状为 (4, 1) 的数组</title>
      <link>https://stackoverflow.com/questions/77821619/error-when-checking-input-expected-flatten-input-to-have-3-dimensions-but-got</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77821619/error-when-checking-input-expected-flatten-input-to-have-3-dimensions-but-got</guid>
      <pubDate>Mon, 15 Jan 2024 18:10:17 GMT</pubDate>
    </item>
    <item>
      <title>TicTacToe 的表格 Q-Learning - 仅最后一个状态/动作对存储在 Q-Table 字典中，其值不为 0</title>
      <link>https://stackoverflow.com/questions/77821339/tabular-q-learning-for-tictactoe-only-the-last-state-action-pair-is-stored-in</link>
      <description><![CDATA[我的 tictactoe 3x3 板的表格 q-learning 实现存在问题。
问题在于，只有最后一步（获胜、失败、平局）及其各自的棋盘状态存储在 q 值不是“0.0”的 q 表中。导致最后移动的所有其他状态和动作对仍然具有值“0.0”。我在下面添加了 q 表，其中显示最后一步的值为“0.2”。但之前所有的移动的值为“0.0”。这只是第一集。即使增加了剧集也不会改变任何事情。只有最后一个动作的 q 值不是“0.0”
类标记（enum.StrEnum）：
    十字＝“X”
    NAUGHT=“O”
    空=“_”


类奖励（enum.IntEnum）：
    获胜=1
    输=-1
    平局 = -0.065
    非终端 = -0.01


# Q-Learning 的常量
EPSILON = 0.1 # 探索因子
ALPHA = 0.2 # 学习率
GAMMA = 0.95 # 折扣系数

TOTAL_EPISODES = 1 # 代理将玩的游戏总数

BOARD = np.array([Mark.EMPTY] * BOARD_SIZE)

def update_q_table(board、action、reward、new_board)：
    board_key = &quot;&quot;.join(board)
    new_board_key = &quot;&quot;.join(new_board)

    旧值 = Q_TABLE_DICT.get((board_key, 操作), 0)

    如果游戏结束（新棋盘）：
        # 如果是最终状态，则无需考虑未来的奖励
        下一个最大= 0
    别的：
        # 估计最优未来值
        下一个最大=最大（
            Q_TABLE_DICT.get((new_board_key, a), 0) for a in possible_moves(new_board)
        ）

    # 使用贝尔曼方程更新当前状态-动作对的 Q 值
    q_value = old_value + ALPHA * (奖励 + GAMMA * next_max - old_value)
    Q_TABLE_DICT[(board_key, 操作)] = q_value

def train_q_learning_agent():
    对于范围内的剧集（TOTAL_EPISODES）：
        board = np.array([Mark.EMPTY] * BOARD_SIZE) # 重置板
        当前标记 = 标记.CROSS

        而不是游戏结束（棋盘）：
            # Q-学习代理 (X) 采取行动
            如果 current_mark == Mark.CROSS:
                动作=选择_动作_q_学习（板，训练=真）
                new_board = make_move_to(板、操作、当前标记)
                奖励 = get_reward(new_board, current_mark)
                打印（新板）
                update_q_table（板、操作、奖励、new_board）

            # 随机玩家 (O) 采取行动
            别的：
                动作= get_random_move（板）
                new_board = make_move_to(板、操作、当前标记)

            板=新板
            current_mark = Mark.NAUGHT 如果 current_mark == Mark.CROSS else Mark.CROSS

def Choose_action_q_learning(board, Training=True) -&gt; &gt;整数：
    如果训练且 random.uniform(0, 1) &lt;厄普西隆：
        # 探索：选择一个随机动作
        返回 np.random.choice(possible_moves(board))
    别的：
        # 利用：根据当前 Q 表选择最佳操作
        board_key = &quot;&quot;.join(board)
        q_值 = {
            动作： Q_TABLE_DICT.get((board_key, 动作), 0)
            对于 possible_moves(board) 中的操作
        }
        返回 max(q_values, key=q_values.get)

第一集的 Q-Table 字典为 json：
&lt;前&gt;&lt;代码&gt;{
    “(&#39;_________&#39;, 0)”: 0.0,
    “（&#39;XO_______&#39;，2）”：0.0，
    “(&#39;XOX____O_&#39;, 3)”: 0.0,
    “(&#39;XOXX___OO&#39;, 4)”: 0.0,
    “（&#39;XOXXXO_OO&#39;，6）”：0.2
}
]]></description>
      <guid>https://stackoverflow.com/questions/77821339/tabular-q-learning-for-tictactoe-only-the-last-state-action-pair-is-stored-in</guid>
      <pubDate>Mon, 15 Jan 2024 17:10:26 GMT</pubDate>
    </item>
    <item>
      <title>当尝试使用tuner.search运行GridTuner类时我遇到了问题</title>
      <link>https://stackoverflow.com/questions/77821202/when-trying-to-run-gridtuner-class-using-tuner-search-%c4%b1-am-having-problem</link>
      <description><![CDATA[类 GridTuner(keras_tuner.GridSearch):
def __init__(self, 超模型, \*\*kwargs):
super().__init__(超级模型，\*\*kwargs)

    def run_Trial(自我, 审判, *args, **kwargs):
        hp = 试验.超参数
        模型 = self.hypermodel.build(hp)
        返回 self.hypermodel.fit(hp, model, *args, **kwargs)
                调谐器 = GridTuner(
                构建模型，
                目标=&#39;val_loss&#39;,
                覆盖=真，
                目录=“D:\\kaggle\\working\\hyperparameters”,
                project_name=f“driams-{有机体}-{抗菌剂}”，
）
                

                tuner.search_space_summary()



                调谐器. 搜索(
                    X_火车，
                    y_火车，
                    验证数据=（X_val，y_val），
                    批量大小=128，
                    纪元=100，
                    类别权重=类别权重，
                    回调=[提前停止(耐心=15)]
）

            best_hp =tuner.get_best_hyperparameters()[0]
            best_model =tuner.hypermodel.build(best_hp)
            best_model.summary()

我正在尝试运行有关超参数的试验，但出现以下错误：
文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\scriptrunner\ \script_runner.py”，第 534 行，在 \_run_script exec(code, module.__dict__) 文件“C:\\Users\\90507\\OneDrive\\Masaüstü\\demo\\app.py”，第 266 行，在\&lt;模块\&gt;; main() 文件“C:\\Users\\90507\\OneDrive\\Masaüstü\\demo\\app.py”，第 234 行，在 maintuner.search( 文件“C:\\Users\\90507”中\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py”，第 234 行，在搜索 self.on_Trial_end(Trial)文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py”，第 338 行，在 on_trial_end self.oracle.end_trial(Trial) 文件 &quot;C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner \\src\\engine\\oracle.py”，第 108 行，wrapped_func ret_val = func(\*args, \*\*kwargs) ^^^^^^^^^^^^^^^^^^ ^^^ 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\tuners\\gridsearch.txt” py”，第 318 行，在 end_Trial super().end_Trial(Trial) 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages \\keras_tuner\\src\\engine\\oracle.py”，第 108 行，wrapped_func ret_val = func(\*args, \*\*kwargs) ^^^^^^^^^^^^^^^^ ^^^^^^ 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\ \oracle.py”，第 586 行，end_Trial self.\_check_consecutive_failures() 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site- packages\\keras_tuner\\src\\engine\\oracle.py”，第 543 行，在 \_check_consecutive_failures 中引发 RuntimeError( ValueError: 无法将 NumPy 数组转换为张量（不支持的对象类型 NoneType）。
我尝试查看数据集内部，检查导入、库并尝试更改代码。我正在尝试这个 https://www.kaggle.com/code/ hlysine/driams-maldi-tof-classifier 代码来制作有关 ML 的 Web 应用程序，我正在使用 Streamlit。]]></description>
      <guid>https://stackoverflow.com/questions/77821202/when-trying-to-run-gridtuner-class-using-tuner-search-%c4%b1-am-having-problem</guid>
      <pubDate>Mon, 15 Jan 2024 16:43:50 GMT</pubDate>
    </item>
    <item>
      <title>RMSE 训练和 MAE 预测 [关闭]</title>
      <link>https://stackoverflow.com/questions/77821170/rmse-training-mae-prediction</link>
      <description><![CDATA[如果我使用 RMSE 损失训练梯度提升回归模型，然后使用 MAE 进行预测，我的模型会成立吗？我问这个问题是因为我这样做了，结果看起来不错，但这纯粹是偶然吗？
使用它可能会遇到哪些陷阱？]]></description>
      <guid>https://stackoverflow.com/questions/77821170/rmse-training-mae-prediction</guid>
      <pubDate>Mon, 15 Jan 2024 16:38:31 GMT</pubDate>
    </item>
    <item>
      <title>有效计算不同目标的输入梯度</title>
      <link>https://stackoverflow.com/questions/77820641/computing-input-gradients-for-different-targets-efficiently</link>
      <description><![CDATA[我正在研究一个类似于对抗性例子的问题。在我的设置中，我想根据不同类的梯度计算输入样本的梯度掩码。更具体地说，我有一个输入图像 x，并且想要计算给定目标类别为 0、1、2、... 的各个像素损失梯度。
我当前的解决方案类似于这个玩具示例：
net = torch.nn.Sequential(torch.nn.Linear(10, 10), torch.nn.ReLU(), torch.nn.Linear(10, 5))
x = 火炬.randn(1, 10)
x.requires_grad = True

y = 净值(x)
损失 = torch.nn.function.mse_loss(y, torch.tensor([0., 1., 2., 3., 4.]), 减少=&#39;无&#39;)[0]
梯度= []
对于损失中的损失：
    loss.backward(retain_graph=True)
    渐变.append(x.grad.clone().detach())
    x.grad.zero_()

由于损失目前是针对每个目标值顺序反向传播的，因此运行时间并不是很好。有没有更有效的方法来在一次向后传递中计算不同类的梯度？由于我的内存也有些有限，因此简单地复制输入示例并并行运行多次是行不通的。
我已经尝试复制输入以并行运行向后传递。不幸的是，我的 GPU 内存在此设置中受到限制。]]></description>
      <guid>https://stackoverflow.com/questions/77820641/computing-input-gradients-for-different-targets-efficiently</guid>
      <pubDate>Mon, 15 Jan 2024 15:00:00 GMT</pubDate>
    </item>
    <item>
      <title>直接从x_t获取x_0和用它按照t-1,t-2,...的顺序获取x_0有什么区别？ 。 。和 DDPM 中的 0？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77820598/what-is-the-difference-between-getting-x-0-directly-from-x-t-and-using-it-to-get</link>
      <description><![CDATA[根据DDPM，我们可以通过重新参数化技巧直接从x_t获取x_0。
利用这个 x_t, x_0 我们可以得到 x_(t-1)，对吧？
重复此操作，我们可以得到x_0。
那么，这些x_0有什么区别呢？为什么我们不直接获取x_0？]]></description>
      <guid>https://stackoverflow.com/questions/77820598/what-is-the-difference-between-getting-x-0-directly-from-x-t-and-using-it-to-get</guid>
      <pubDate>Mon, 15 Jan 2024 14:50:47 GMT</pubDate>
    </item>
    <item>
      <title>Filter_Value 选择 TDA R</title>
      <link>https://stackoverflow.com/questions/77807593/filter-value-selection-tda-r</link>
      <description><![CDATA[我最近一直在尝试在 R 中使用一些 TDA，但我发现的一个限制是“过滤值”的选择。论证。
我的理解是，他们通常使用 X 轴的范围作为“filter_values”。争论，但我没有成功。
这是一个已发布的示例：
devtools::install_github(“paultpearson/TDAmapper”)
devtools::install_github(“christophergandrud/networkD3”)

库（TDAmapper）
图书馆（igraph）

＃数据

n_x &lt;- c(rep(-.5,101),0.01*(-50:50),rep(.5,101))
n_y &lt;- c(0.02*(-50:50),-0.02*(-50:50),0.02*(-50:50))

d_x &lt;- c(代表(-0.9,101),0.02*(-50:25),0.02*(-50:25),
         0.4+sqrt(0.5^2-(0.01*(-50:50))^2))
d_y &lt;- c(0.01*(-50:50),rep(0.5,76),rep(-0.5,76),
         0.01*(-50:50))

nd &lt;- data.frame(x=c(n_x,d_x),y=c(n_y,d_y))
情节（nd）

#MAPPER 示例 - 过滤值参数

m &lt;-mapper1D(
     距离矩阵 = dist(nd),
     过滤值 = c(n_x,d_x),
     间隔数 = 10,
     重叠百分比 = 50,
     num_bins_when_clustering = 10)


但是，我想知道是否有人可以帮助我选择类似于下面所示的试验数据的 filter_values 参数，范围为 1:3（更符合我自己的数据特征）。
将不胜感激。
x1 = 重复(1:3, 次数 = 100)
x2 = 重复(1:3, 次数 = 100)
x3 = 重复次数(1:3, 次数 = 100)
x4 = 重复(1:3, 次数 = 100)
x5 = 重复(1:3, 次数 = 100)

DAT &lt;- data.frame(x1, x2,x3,x4,x5)

非常感谢。
链接
https://www.justinmath.com/mapper-software- tdamapper 演示/
https://tianshufeng.github.io/STA/index.html]]></description>
      <guid>https://stackoverflow.com/questions/77807593/filter-value-selection-tda-r</guid>
      <pubDate>Fri, 12 Jan 2024 15:21:09 GMT</pubDate>
    </item>
    <item>
      <title>回归问题中的精度和准确度相当于什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77778210/what-are-equivalent-of-precision-and-accuracy-in-regression-problems</link>
      <description><![CDATA[我已经使用多层感知器神经网络解决了回归问题。我听说过 MSE、RMASE、MAE 和 R^2 指标。我想确切地知道哪个指标等于或类似于分类问题中的精度和准确度？换句话说，回归问题中的精度和准确度相当于什么？]]></description>
      <guid>https://stackoverflow.com/questions/77778210/what-are-equivalent-of-precision-and-accuracy-in-regression-problems</guid>
      <pubDate>Mon, 08 Jan 2024 09:08:25 GMT</pubDate>
    </item>
    <item>
      <title>Bigquery ML，用于表中分区的多个线性回归模型</title>
      <link>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</link>
      <description><![CDATA[任务
我想使用 bigquery ml 对表中的分区执行多元线性回归，最好使用 dbt 实现。
背景
该表包含 customer_key、c​​ategory、week_key 和花费。应为每个分区计算回归线：customer_key 和类别，按周升序排序。这样，每个类别的每个客户都可以获得该分区内几周内支出趋势的斜率系数。实际上，我需要每个分区一个回归模型，而不是整个表一个回归模型。回归模型的数量估计约为 1 亿个。因此，我想使用 bigquery 来实现工作负载的并行化。

最终结果应该是一个表，其中包含：所有客户的 customer_key、类别、斜率。

此外，我使用 dbt 来运行所有模型，并使用 bigquery 作为数据的计算和存储。因此，我想使用dbt来实现该解决方案。
研究
通过与各个 llms 的聊天，他们似乎建议结合使用程序语句和跨每个分区的 for 循环来执行回归。但是，我想并行化计算。从这个问题 bigquery ML: Running a regression per group and全部组合起来，似乎“BQML 目前不支持在单个 CREATE MODEL 语句中指定不同的组 id 进行回归。”。
创建临时表partitioned_data AS
选择 customer_key、类别、week_key、支出
来自你的表
按客户键分组，类别；

DECLARE partition_list ARRAY&gt;；
开始
-- 迭代暂存表中的每个分区
FOR 分区 IN (
  选择客户键，类别
  FROM 分区数据
  按客户键分组，类别
 ）
 环形
   -- 提取当前分区的数据
 DECLARE partition_data ARRAY&gt;；
 开始
  FOR week_data IN (
    选择 week_key，花费
    FROM 分区数据
    WHERE customer_key = 分区.customer_key
    AND 类别 = 分区.类别
  ）
  环形
    array_append(partition_data, week_data);
  结束循环；
结尾

-- 为当前分区创建模型
创建或替换模型 my_model
选项（
  model_type = &#39;线性回归&#39;,
  标签=&#39;花费&#39;，
  特征 = &#39;week_key&#39;
）
作为
选择 *
FROM UNNEST(partition_data);
结束循环；
结尾;

创建临时表 Final_results AS
选择
  s.customer_key，
  s.类别，
  米坡度
FROM 分区数据 p
加入 （
  选择
    *,
    斜率 = MEAN(statistics.mean_slope)
   来自 ML.MODEL_STATS(model.my_model)
   按客户键、商店键、类别分组
  ）米
 ON p.customer_key = m.customer_key
 AND p.category = m.category;

但是，这个建议的解决方案无法在 bigquery gui 中运行，也不能在 dbt 中运行。
问题
如何完成这个回归任务？要么在 bigquery 上将上面的 sql 代码作为单独的脚本运行，要么重写它以在 dbt 中工作。]]></description>
      <guid>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</guid>
      <pubDate>Thu, 04 Jan 2024 09:36:32 GMT</pubDate>
    </item>
    <item>
      <title>回溯（最近一次调用）<module> 中的 <ipython-input-45-49fddc3d53e6>，IndexError：（列表索引超出范围）</title>
      <link>https://stackoverflow.com/questions/68893169/traceback-most-recent-call-last-ipython-input-45-49fddc3d53e6-in-module-i</link>
      <description><![CDATA[我正在尝试运行此代码，但是出现错误，但我不确定该错误是由于地址文件还是其他原因造成的。
数据集文件包含子宫颈图像。
图像按其标记类别进行组织：Type_1、Type_2 和 Type_3
这是代码：
&lt;小时/&gt;
def im_multi(路径):
   尝试：
       im_stats_im_ = Image.open(路径)
       返回[路径，{&#39;size&#39;：im_stats_im_.size}]
除了：
    打印（路径）
    返回 [路径, {&#39;size&#39;: [0,0]}]

def im_stats(im_stats_df):
im_stats_d = {}
p = 池(cpu_count())
ret = p.map(im_multi, im_stats_df[&#39;路径&#39;])
对于范围内的 i(len(ret))：
    im_stats_d[ret[i][0]] = ret[i][1]
im_stats_df[&#39;size&#39;] = im_stats_df[&#39;path&#39;].map(lambda x: &#39; &#39;.join(str(s) for s in im_stats_d[x][&#39;size&#39;]))
返回im_stats_df

def get_im_cv2(路径):
img = cv2.imread(路径)
调整大小 = cv2.resize(img, (32, 32), cv2.INTER_LINEAR) #使用 cv2.resize(img, (64, 64), cv2.INTER_LINEAR)
返回[路径，已调整大小]

def normalize_image_features(路径):
IMF_d = {}
p = 池(cpu_count())
ret = p.map(get_im_cv2, 路径)
对于范围内的 i(len(ret))：
    imf_d[ret[i][0]] = ret[i][1]
回退=[]
fdata = [imf_d[f] 对于路径中的 f]
fdata = np.array(fdata, dtype=np.uint8)
fdata = fdata.transpose((0, 3, 1, 2))
fdata = fdata.astype(&#39;float32&#39;)
f 数据 = f 数据 / 255
返回fdata

#train = glob.glob(&#39;../input/train/**/*.jpg&#39;) + glob.glob(&#39;../input/additional/**/*.jpg&#39;)
train=glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\train\\Type_1\\*.jpg&#39;)
+glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\train\\Type_2\\*.jpg&#39;) +glob.glob(&#39;D:\\Test
cods\\KerasCNNClean\\data\\train\\Type_3\\*.jpg&#39;)

train = pd.DataFrame([[p.split(&#39;/&#39;)[3],p.split(&#39;/&#39;)[4],p] for p in train], columns =
[&#39;type&#39;,&#39;image&#39;,&#39;path&#39;])[::5] Kaggle 演示的 #limit
火车 = im_stats(火车)
train = train[train[&#39;size&#39;] != &#39;0 0&#39;].reset_index(drop=True) #删除损坏的图像
print(&quot;不良图像已删除&quot;)
print(&quot;加载测试数据&quot;)

train_data = normalize_image_features(train[&#39;path&#39;])
print(&quot;测试数据已加载&quot;)

#np.save（&#39;train.npy&#39;，train_data，allow_pickle = True，fix_imports = True）
np.save（r&#39;D：/测试cods/KerasCNNClean/npyTrain.train.npy&#39;，train_data，allow_pickle = True，
修复导入=真）

le = 标签编码器()
train_target = le.fit_transform(train[&#39;type&#39;].values)
print(le.classes_)

#np.save（&#39;train_target.npy&#39;，train_target，allow_pickle = True，fix_imports = True）
np.save(r&#39;D:/测试 cods/KerasCNNClean/npyTrain.train_target.npy&#39;, train_target,
允许_pickle = True，fix_imports = True）

我找不到问题所在：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
IndexError Traceback（最近一次调用最后一次）
&lt;ipython-input-46-4f89beac4d83&gt;在&lt;模块&gt;中
      1 test = glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\test\\*.jpg&#39;)
----&gt; 2 test = pd.DataFrame([[p.split(&#39;/&#39;)[3],p] for p in test], columns = [&#39;image&#39;,&#39;path&#39;]) #[::20] #limit for Kaggle 演示
      3 print(&quot;加载列车数据&quot;)
      4 test_data = normalize_image_features(测试[&#39;路径&#39;])
      5 np.save（r&#39;D：/测试cods/KerasCNNClean/npyTest.test.npy&#39;，test_data，allow_pickle = True，fix_imports = True）

&lt;ipython-input-46-4f89beac4d83&gt;在 (.0) 中
      1 test = glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\test\\*.jpg&#39;)
----&gt; 2 test = pd.DataFrame([[p.split(&#39;/&#39;)[3],p] for p in test], columns = [&#39;image&#39;,&#39;path&#39;]) #[::20] #limit for Kaggle 演示
      3 print(&quot;加载列车数据&quot;)
      4 test_data = normalize_image_features(测试[&#39;路径&#39;])
      5 np.save（r&#39;D：/测试cods/KerasCNNClean/npyTest.test.npy&#39;，test_data，allow_pickle = True，fix_imports = True）

IndexError：列表索引超出范围
]]></description>
      <guid>https://stackoverflow.com/questions/68893169/traceback-most-recent-call-last-ipython-input-45-49fddc3d53e6-in-module-i</guid>
      <pubDate>Mon, 23 Aug 2021 12:59:13 GMT</pubDate>
    </item>
    <item>
      <title>我如何使用 scikit learn 迭代 python 中的模型“列表”？</title>
      <link>https://stackoverflow.com/questions/56602214/how-can-i-iterate-over-a-list-of-models-in-python-with-scikit-learn</link>
      <description><![CDATA[我构建了一个显示单个模型的一些评估指标的函数，现在我想将此函数应用于我估计的模型池。
旧函数的输入是：
OldFunction（代码：str，x，X_train：np.array，X_test：np.array，X：pd.DataFrame）

地点：
code 是一个字符串，用于创建数据框的列名
x 是型号名称
X_train和X_test是数据分割器的np.arrays
X是整个数据的dataframe
为了估计模型池的指标，我尝试通过在函数中添加循环来修改函数，并将模型放入列表中。
但是这不起作用。
出现问题是因为我无法迭代模型列表，那么我有什么选择？你有什么想法吗？
我将新函数留在下面。
将 numpy 导入为 np
将 pandas 导入为 pd
从 sklearn.metrics 导入 roc_curve, auc
从 sklearn.metrics 导入准确度分数、召回分数、精度分数
从 sklearn.model_selection 导入 cross_val_score

def displaymetrics（代码：列表，模型：列表，X_train：np.array，X_test：np.array，X：pd.DataFrame）：
    对于模型中的 i：
        
        y_score = models[i].fit(X_train, y_train).decision_function(X_test)
        fpr, tpr, _ = roc_curve(y_test, y_score)
        roc_auc = auc(fpr, tpr)
        
        # 传统乐谱
        
        y_pred = pd.DataFrame(model[i].predict(X_train)).reset_index(drop=True)
        Recall_Train,Precision_Train, Accuracy_Train = recall_score(y_train, y_pred), precision_score(y_train, y_pred), precision_score(y_train, y_pred)
        y_pred = pd.DataFrame(model[i].predict(X_test)).reset_index(drop=True)
        召回测试 = 召回分数(y_test, y_pred)
        Precision_Test = precision_score(y_test, y_pred)
        准确度测试 = 准确度分数(y_test, y_pred)
        
        #交叉验证
        cv_au = cross_val_score(models[i], X_test, y_test, cv=30, 评分=&#39;roc_auc&#39;)
        cv_f1 = cross_val_score(models[i], X_test, y_test, cv=30, 评分=&#39;f1&#39;)
        cv_pr = cross_val_score(models[i], X_test, y_test, cv=30, 评分=&#39;精度&#39;)
        cv_re = cross_val_score(models[i], X_test, y_test, cv=30, 评分=&#39;召回&#39;)
        cv_ac = cross_val_score(models[i], X_test, y_test, cv=30, 评分=&#39;准确度&#39;)
        cv_ba = cross_val_score(models[i], X_test, y_test, cv=30, 评分=&#39;balanced_accuracy&#39;)
        cv_au_m、cv_au_std = cv_au.mean()、cv_au.std()
        cv_f1_m、cv_f1_std = cv_f1.mean()、cv_f1.std()
        cv_pr_m、cv_pr_std = cv_pr.mean()、cv_pr.std()
        cv_re_m, cv_re_std= cv_re.mean() , cv_re.std()
        cv_ac_m、cv_ac_std = cv_ac.mean()、cv_ac.std()
        cv_ba_m, cv_ba_std= cv_ba.mean() , cv_ba.std()
        cv_au、cv_f1、cv_pr = (cv_au_m、cv_au_std)、(cv_f1_m、cv_f1_std)、(cv_pr_m、cv_pr_std)
        cv_re、cv_ac、cv_ba = (cv_re_m、cv_re_std)、(cv_ac_m、cv_ac_std)、(cv_ba_m、cv_ba_std)
        元组 = [cv_au、cv_f1、cv_pr、cv_re、cv_ac、cv_ba]
        tuplas = [0]*len(元组)
        对于范围内的 i(len(元组))：
            tuplas[i] = [round(x,4) for x in tuples[i]]
        结果= pd.DataFrame()
        结果[&#39;指标&#39;] = [&#39;roc_auc&#39;, &#39;Accuracy_Train&#39;, &#39;Precision_Train&#39;, &#39;Recall_Train&#39;, &#39;Accuracy_Test&#39;,
                              &#39;Precision_Test&#39;，&#39;Recall_Test&#39;，&#39;cv_roc-auc（平均值，标准差）&#39;，&#39;cv_f1score（平均​​值，标准差）&#39;，
                              &#39;cv_ precision（平均值，std）&#39;，&#39;cv_recall（平均值，std）&#39;，&#39;cv_accuracy（平均值，std）&#39;，
                              &#39;cv_bal_accuracy（平均值，标准差）&#39;]
        results.set_index([&#39;指标&#39;], inplace=True)
        结果[&#39;模型_&#39;+代码[i]] = [roc_auc，Accuracy_Train，Precision_Train，Recall_Train，Accuracy_Test，
                            Precision_Test、Recall_Test、tuplas[0]、tuplas[1]、tuplas[2]、tuplas[3]、
                           图普拉斯[4], 图普拉斯[5]]
    
    返回结果

输出应该是一个数据框，其中每列代表每个模型，行代表指标。]]></description>
      <guid>https://stackoverflow.com/questions/56602214/how-can-i-iterate-over-a-list-of-models-in-python-with-scikit-learn</guid>
      <pubDate>Fri, 14 Jun 2019 16:39:18 GMT</pubDate>
    </item>
    </channel>
</rss>