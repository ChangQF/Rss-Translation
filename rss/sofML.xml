<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 25 Mar 2024 12:23:53 GMT</lastBuildDate>
    <item>
      <title>将 ONNX 模型转换为 Tensorflow Lite - 不支持 pytorch_half_pixel</title>
      <link>https://stackoverflow.com/questions/78218890/converting-onnx-model-to-tensorflow-lite-pytorch-half-pixel-not-supported</link>
      <description><![CDATA[我正在尝试将 ONNX 模型转换为 Tensorflow Lite 格式。简单的代码，但出现此错误。我更新了我的 onnx 版本，但没有成功
导入onnx
将张量流导入为 tf
导入onnx_tf
#
#
# 自述文件：此文件将 onnx 模型转换为 tflite
#
#
#

onnx_model_path = &#39;/home/sfrye/segmentation/segmentation_checkpoints/efficientnet/modified-new.onnx&#39;

onnx_model = onnx.load(onnx_model_path)

tf_model = onnx_tf.backend.prepare(onnx_model)
tf_model.export_graph(“tflite_model.tf”)

这是错误
&lt;前&gt;&lt;代码&gt;
运行时错误：在用户代码中：

    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/backend_tf_module.py”，第 99 行，位于 __call__ *
        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/backend.py”，第 347 行，在 _onnx_node_to_tensorflow_op *
        返回处理程序.handle(节点,tensor_dict=tensor_dict,strict=strict)
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/handlers/handler.py”，第 58 行，句柄 *
        cls.args_check（节点，**kwargs）
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/handlers/backend/resize.py”，第 125 行，位于 args_check *
        异常。OP_UNSUPPORTED_EXCEPT(
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/common/exception.py”，第 50 行，位于 __call__ *
        引发 self._func(self.get_message(op, 框架))

    运行时错误：Tensorflow 不支持调整坐标变换模式=pytorch_half_pixel 的大小。


我尝试更新我的 onnx，因为这解决了某人使用此错误代码的问题]]></description>
      <guid>https://stackoverflow.com/questions/78218890/converting-onnx-model-to-tensorflow-lite-pytorch-half-pixel-not-supported</guid>
      <pubDate>Mon, 25 Mar 2024 11:55:44 GMT</pubDate>
    </item>
    <item>
      <title>ui元素检测的YOLOv8模型结果解读</title>
      <link>https://stackoverflow.com/questions/78218554/interpretation-of-yolov8-model-results-for-ui-elements-detection</link>
      <description><![CDATA[我是计算机视觉新手，刚刚开始使用 YOLOv8 进行对象检测。我收集并注释了我的数据，并对模型进行了 20 个时期的训练。但现在，我陷入了困境 - 我无法理解如何理解结果。
有 YOLOv8 或对象检测经验的人可以帮助我了解如何解释模型的输出吗？我不确定各种指标的含义、如何读取边界框输出，或者我还应该寻找什么来评估模型的性能。
您可以分享的任何建议、技巧或易于理解的资源都会非常有帮助。
非常感谢！
我在测试集上测试了 YOLOv8 模型，结果看起来很有希望。然而，当尝试解释输出时，我感到迷失。我注意到一些元素的代表性不足，而且图表似乎势不可挡。我希望清楚地了解模型的性能并了解如何改进它。]]></description>
      <guid>https://stackoverflow.com/questions/78218554/interpretation-of-yolov8-model-results-for-ui-elements-detection</guid>
      <pubDate>Mon, 25 Mar 2024 10:56:30 GMT</pubDate>
    </item>
    <item>
      <title>用于物体方向估计的模板匹配模型仅在平面内旋转时快速收敛，但在全 3D 方向时失败</title>
      <link>https://stackoverflow.com/questions/78218374/template-matching-model-for-object-orientation-estimation-converges-fast-with-in</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78218374/template-matching-model-for-object-orientation-estimation-converges-fast-with-in</guid>
      <pubDate>Mon, 25 Mar 2024 10:23:10 GMT</pubDate>
    </item>
    <item>
      <title>在时间序列 ARIMA 分析中出现错误“TypeError: no numeric data toplot”</title>
      <link>https://stackoverflow.com/questions/78218276/getting-error-typeerror-no-numeric-data-to-plot-in-a-time-series-arima-analys</link>
      <description><![CDATA[我正在尝试遵循一个教程，其中使用差异数据进行 ARIMA 时间序列分析：
以下是python代码：
def 差异（数据集）：
    差异=列表（）
    对于范围内的 i(1, len(数据集))：
        值 = 数据集[i] - 数据集[i - 1]
        diff.append(值)
    返回系列（差异）

系列 = pd.read_csv(&#39;dataset.csv&#39;)
X = series.values # 构建列表的错误可以在这里看到
X = X.astype(&#39;float32&#39;)
平稳 = 差值(X)
固定.索引 = 系列.索引[1:]
...
固定.plot()
pyplot.show()

当过程到达绘图阶段时，我收到错误：
&lt;块引用&gt;
类型错误：没有要绘制的数字数据

回溯起来，我发现正在解析的数据产生了一个数组的集合。将集合stationary保存为*.csv文件会给我一个如下列表：
&lt;前&gt;&lt;代码&gt;[11.]
[0.]
[16.]
[45.]
[27.]
[-141。]
[46]

有人可以告诉我这里出了什么问题吗？
PS。我已经排除了库导入的部分
编辑 1
数据集的一部分复制如下：
年份，观测值
1994,21
1995,62
1996,56
1997,29
1998,38
1999,201
]]></description>
      <guid>https://stackoverflow.com/questions/78218276/getting-error-typeerror-no-numeric-data-to-plot-in-a-time-series-arima-analys</guid>
      <pubDate>Mon, 25 Mar 2024 10:07:18 GMT</pubDate>
    </item>
    <item>
      <title>Kohya_SS 和多个 python 版本</title>
      <link>https://stackoverflow.com/questions/78218164/kohya-ss-and-multiple-python-versions</link>
      <description><![CDATA[10:20:10-098640 ERROR 当前版本的 python 不适合运行
                         Kohya_ss 图形用户界面
10:20:10-098956 错误 python 版本需要大于或等于
                         3.10.9 且小于 3.11.0
验证失败。正在退出...

尽管我确信我安装了多个 Python 版本并且可以切换到它应该使用的版本，但我不断收到错误？
user@Name-MacBook-Pro ~ % alias python3=“python3.10”
用户@名称-MacBook-Pro ~ % python3 --version
Python 3.10.14

通过 Dreambooth/Lora 界面训练模型，我前一天就可以打开]]></description>
      <guid>https://stackoverflow.com/questions/78218164/kohya-ss-and-multiple-python-versions</guid>
      <pubDate>Mon, 25 Mar 2024 09:42:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 MPI 优化 Optuna 参数</title>
      <link>https://stackoverflow.com/questions/78218072/optuna-parameter-optimisation-with-mpi</link>
      <description><![CDATA[我有一些机器学习代码，它使用 SVM（来自 scikit-learn）和预计算内核，我想使用 optuna 对其进行优化，因此代码简单地看起来有点像这样
def 目标（试用：试用，fast_check=True，target_meter=0，return_info=False）：
     #设置参数
     C = Trial.suggest_float(“C”,0.0​​1,5)
     tol = Trial.suggest_loguniform(“tol”,1e-4,1e-1)
     内核参数 = ...

     #构建火车内核
     内核训练 = ...

     #构建测试内核
     内核测试 = ...

     #火车服务
     svc = SVC(内核=“预计算”, C=C, tol=tol)
     svc.fit(kernel_train, train_labels)
     test_predict = svc.predict(kernel_test)
     test_auc = roc_auc_score(test_labels,test_predict)

     返回测试_auc

Study = optuna.create_study(direction=“最大化”,study_name=&#39;study_1&#39;)
研究.优化（目标，n_Trials=40）


但是，由于我正在计算的内核的复杂性，我使用 mpi4py 来并行计算，但同​​时使用 optuna 和 MPI 时遇到一些问题。
显然，我想要多个处理器上的内核代码，但是当我创建研究并优化它时，我不想在处理器上创建多个不同的研究，我只想对根进行优化的一项研究（我假设？）。我已经尝试了下面的方法，它有效，但是当我不使用 MPI 时，它的优化效果不佳，我认为这正在创建多项研究并优化它们，这似乎效率不高。似乎更难以收敛到最佳参数。
从 mpi4py 导入 MPI

mpi_comm = MPI.COMM_WORLD
排名 = mpi_comm.Get_rank()
n_procs = mpi_comm.Get_size()
根=0

定义目标（）：
     #设置参数
     C = Trial.suggest_float(“C”,0.0​​1,5)
     tol = Trial.suggest_loguniform(“tol”,1e-4,1e-1)
     内核参数 = ...

     #使用 MPI 构建训练内核
     内核训练 = ...

     #使用MPI构建测试内核
     内核测试 = ...

     #火车服务
     如果排名==根：
           svc = SVC(内核=“预计算”, C=C, tol=tol)
           svc.fit(kernel_train, train_labels)
           test_predict = svc.predict(kernel_test)
           test_auc = roc_auc_score(test_labels,test_predict)
     别的：
           测试_auc = 0
     test_auc = mpi_comm.bcast(test_auc, root=0)

如果排名==根：
     Study = optuna.create_study(direction=“最大化”,study_name=&#39;study_1&#39;)
别的：
     研究 = 0
 研究= mpi_comm.bcast（研究，根= 0）

研究.优化（目标，n_Trials=40）

这是一个非常小众的问题，但只是想知道是否有人对这些软件包有任何经验，并且可以帮助建议如何运行多处理代码，同时仅优化一个处理器上的参数。如果任何术语不正确，我深表歉意，我是使用这两个软件包的新手，所以请耐心等待:)]]></description>
      <guid>https://stackoverflow.com/questions/78218072/optuna-parameter-optimisation-with-mpi</guid>
      <pubDate>Mon, 25 Mar 2024 09:20:08 GMT</pubDate>
    </item>
    <item>
      <title>什么是逐点优化器和非逐点优化器？</title>
      <link>https://stackoverflow.com/questions/78217872/what-are-pointwise-optimizers-and-non-pointwise-optimizers</link>
      <description><![CDATA[我最近阅读了有关 fairscale FSDP 的文档
高效的内存管理
提到的地方

结果应与使用逐点优化器（例如 Adam、AdamW、Adadelta、Adamax、SGD 等）的 DDP 相同。但是，当使用非逐点优化器（例如 Adagrad、Adafactor）时，分片会导致结果略有不同、LAMB等

我确实了解 adam 和 adagrad 是如何工作的，但我不完全理解是什么导致了点式优化器和非点式优化器之间的差异？]]></description>
      <guid>https://stackoverflow.com/questions/78217872/what-are-pointwise-optimizers-and-non-pointwise-optimizers</guid>
      <pubDate>Mon, 25 Mar 2024 08:38:11 GMT</pubDate>
    </item>
    <item>
      <title>中等长度 (100bp) DNA 序列的聚类</title>
      <link>https://stackoverflow.com/questions/78217775/clustering-medium-length-100bp-dna-sequences</link>
      <description><![CDATA[您好，我正在尝试对长度约为 100 bp (GCAT) 的 70 个 DNA 序列 fasta 文件进行聚类，以便将基因型簇与我的表型簇进行比较，从而验证表型结果。
您认为采用单热编码和 kmeans 聚类算法来实现这一目标的可行性如何？
我在使用当前的序列聚类软件（DBSCAN、ALFATCLUST）时遇到的一些问题是，它们似乎主要关注较长的 DNA 序列，这意味着它总是将所有序列归为一组，或者只是将序列归为一组。一起出来。一般来说，这些算法对噪声（DNA seq 固有的）也非常敏感，这通常会导致聚类不准确。
有什么想法可以解决这个问题吗？
我尝试使用 DBSCAN、kmeans、cmeans、ALFATCLUST 等进行聚类，但得到了错误的聚类。]]></description>
      <guid>https://stackoverflow.com/questions/78217775/clustering-medium-length-100bp-dna-sequences</guid>
      <pubDate>Mon, 25 Mar 2024 08:15:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的验证准确性不如验证损失那么平滑？</title>
      <link>https://stackoverflow.com/questions/78217319/why-is-my-validation-accuracy-not-as-smooth-as-my-validation-loss</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78217319/why-is-my-validation-accuracy-not-as-smooth-as-my-validation-loss</guid>
      <pubDate>Mon, 25 Mar 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>文本数据转换为数字格式的问题</title>
      <link>https://stackoverflow.com/questions/78217028/issue-in-text-data-conversion-into-numerical-format</link>
      <description><![CDATA[我正在尝试将数据集中存在的文本句子转换为数字格式，以便它可以作为我的 ML 模型的输入。
我觉得理解 ECL 中的 TextVector 有点困难 https ://hpccsystems.com/resources/textvectors-machine-learning-for-textual-data/任何人都可以提供有关此概念的更多详细信息吗？如果有任何示例，请分享文档。]]></description>
      <guid>https://stackoverflow.com/questions/78217028/issue-in-text-data-conversion-into-numerical-format</guid>
      <pubDate>Mon, 25 Mar 2024 04:07:16 GMT</pubDate>
    </item>
    <item>
      <title>谁能帮助我评估我的人工智能学校项目的架构？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78216842/can-anyone-help-me-evaluate-this-architecture-for-my-ai-school-project</link>
      <description><![CDATA[我计划为医疗保健行业开发一种人工智能，可以帮助专业人士为患者提供诊断和预后。将有一系列模型将集成到该系统中。在第一部分中，我希望系统能够根据输入（这将是实验室测试结果的图像，和/或手动输入文本数据）来预测患者是否有很高的机会患有糖尿病、肾病和心血管疾病。它将总结和分析数据集，以解决某些疾病的概率。然后，处理和分析这些数据的算法将由外部强化学习模型进行评估，以改进每个模型的学习过程。我希望我的解释是有道理的。
注意：我计划使用多模态模型单独处理图像中的文本，使用 CNN 处理 X 射线、核磁共振等图像，使用 RNN 处理手动文本输入。
期待您的批评，以进一步提高我的知识。谢谢！！
我创建了该模型的流程图，它将帮助我可视化实现系统目标所需的流程。]]></description>
      <guid>https://stackoverflow.com/questions/78216842/can-anyone-help-me-evaluate-this-architecture-for-my-ai-school-project</guid>
      <pubDate>Mon, 25 Mar 2024 02:39:55 GMT</pubDate>
    </item>
    <item>
      <title>从 Pytorch 中加载 EMNIST 数据集</title>
      <link>https://stackoverflow.com/questions/78215347/load-emnist-dataset-from-within-the-pytorch</link>
      <description><![CDATA[我正在处理 EMNIST 数据集，并希望从 PyTorch 加载它，但它返回一个奇怪的错误：
&lt;块引用&gt;
运行时错误：文件未找到或已损坏。

这是我尝试加载数据集的方法：
trainset = torchvision.datasets.EMNIST(root=“emnist”,
                                   split=“字母”，
                                   火车=真，
                                   下载=真，
                                   变换=transforms.ToTensor())

可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78215347/load-emnist-dataset-from-within-the-pytorch</guid>
      <pubDate>Sun, 24 Mar 2024 16:53:53 GMT</pubDate>
    </item>
    <item>
      <title>尝试在用于虹膜识别的自注释数据集上训练用于虹膜识别的神经网络[关闭]</title>
      <link>https://stackoverflow.com/questions/78199835/trying-to-train-a-neural-network-for-iris-recognition-on-a-self-annotated-datase</link>
      <description><![CDATA[classloss = tf.keras.losses.BinaryCrossentropy()
回归损失 = 本地化损失
类损失（y\[0\]，类）

hist = model.fit(train, epochs=15,validation_data=val,callbacks=\[tensorboard_callback\])


model.fit 抛出以下错误：
batch_classloss = self.cless(y[0], 类)
batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), 坐标)
总损失batch_localizationloss+0.5batch_classloss

ValueError：无法获取未知等级的形状长度。
为什么会出现错误]]></description>
      <guid>https://stackoverflow.com/questions/78199835/trying-to-train-a-neural-network-for-iris-recognition-on-a-self-annotated-datase</guid>
      <pubDate>Thu, 21 Mar 2024 12:07:19 GMT</pubDate>
    </item>
    <item>
      <title>层顺序从未被调用，因此没有定义的输入</title>
      <link>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</link>
      <description><![CDATA[我正在 Anaconda 虚拟环境中运行一个简单的脚本
从 deepface 导入 DeepFace

face_analysis = DeepFace.analyze(img_path = “face3.jpeg”)
打印（面部分析）

但我不断收到此错误。
行动：年龄：25%|██████████████████████████▊ | 1/4 [00:02&lt;00:06, 2.08s/it]
回溯（最近一次调用最后一次）：
  文件“C:\Users\Ctrend.pk\Cheer-Check\test2.py”，第 9 行，在  中
    分析 = DeepFace.analyze(img_path)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\DeepFace.py”，第 222 行，在分析中
    返回人口统计分析（
           ^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\modules\demography.py”，第 157 行，位于分析
    表观年龄 = modeling.build_model(“年龄”).predict(img_content)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\modules\modeling.py”，第 57 行，位于构建模型
    model_obj[模型名称] = model()
                            ^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\extendedmodels\Age.py”，第 32 行，位于__在里面__
    self.model = load_model()
                 ^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\extendedmodels\Age.py”，第 61 行，位于加载模型
    年龄模型=模型（输入=模型.输入，输出=基本模型输出）
                             ^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\ops\operation.py”，第 228 行，在输入中
    返回 self._get_node_attribute_at_index(0, “input_tensors”, “input”)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\ops\operation.py”，第 259 行，在 _get_node_attribute_at_index 中
    引发值错误（
ValueError：层equential_1从未被调用，因此没有定义的输入。

Deepface版本：0.0.87
张量流
版本：2.16.1
我认为它获取了年龄，但随后没有继续。我错过了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</guid>
      <pubDate>Wed, 20 Mar 2024 22:50:10 GMT</pubDate>
    </item>
    <item>
      <title>CatBoostRegressor 与 loss_function='Lq'</title>
      <link>https://stackoverflow.com/questions/76498616/catboostregressor-with-loss-function-lq</link>
      <description><![CDATA[我不知道如何指定“q” “Lq”中的变量损失函数。我收到以下错误消息：
CatBoostError：/src/catboost/catboost/private/libs/options/catboost_options.cpp:82：参数 q 对于 Lq 丢失是必需的

我的代码如下：
from catboost import CatBoostRegressor
从 sklearn.datasets 导入 make_regression
从 sklearn.model_selection 导入 train_test_split
将 numpy 导入为 np

# 生成人工回归数据集
X, y = make_regression(n_samples=1000, n_features=10, random_state=42)

# 将数据集分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建一个 CatBoostRegressor 对象
模型 = CatBoostRegressor(loss_function=&#39;Lq&#39;)

# 拟合模型
model.fit(X_train, y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/76498616/catboostregressor-with-loss-function-lq</guid>
      <pubDate>Sun, 18 Jun 2023 00:20:48 GMT</pubDate>
    </item>
    </channel>
</rss>