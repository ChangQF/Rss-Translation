<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 13 Dec 2023 18:15:26 GMT</lastBuildDate>
    <item>
      <title>Hessian 矩阵最后一层的特征值比其他层小得多[关闭]</title>
      <link>https://stackoverflow.com/questions/77655218/eigenvalues-of-hessian-matrix-final-layer-much-smaller-than-others</link>
      <description><![CDATA[我在各种简单的神经网络模型（例如前馈网络、LeNet CNN 和单层注意力模型）中遇到了 Hessian 特征值的一致模式。具体来说，最终分类层中的 Hessian 特征值非常小（小于 1e-7），与前面层中的值要大得多。有趣的是，模型深处的特征值大小似乎有增加的趋势，但在分类层突然减小。
这一观察似乎违反直觉，特别是考虑到较大的 Hessian 特征值应对应于最不可概括且对数据最敏感的层（请参阅 https://arxiv.org/pdf/1611.01838.pdf)。
我排除了一些事情：

这些模型正在有效地融合并产生具有竞争力的结果
基准数据集上的性能。
各个层的权重大小相似，不是特别大
最后一层很小。
我尝试过各种初始化，甚至合并了
LogSoftmax 非线性进入最后一层。

这是我计算粗麻布和特征值的方法：
 defcompute_hessian(param, loss):
        “”“”计算给定参数和损失的 Hessian 矩阵。
        # 确保计算损失相对于参数的梯度
        first_grad = torch.autograd.grad(loss, param, create_graph=True)[0]
        dummy_param = torch.ones_like(param)
        hessian = torch.autograd.grad(first_grad, param, grad_outputs=dummy_param, create_graph=True)[0]
        返回粗麻布

    def 计算特征值（hessian）：
        ”“”获取特征值“”
        #svd
        特征值 = torch.linalg.svdvals(hessian)
        sum_eigenevalues = torch.sum(特征值)
    返回特征值，sum_eigenevalues.item()

作为背景，hessian 矩阵是损失对参数的二阶导数。它通常用于理解损失函数的形状。获取 hessian 的特征值意味着要么获取 hessian 的 SVD（其形状与参数相同），要么构造 (hessian.T hessian) 的语法矩阵。特征值揭示了损失景观的主曲率（即最大下降或上升的方向）。正特征值表明您处于该方向的局部最小值，负值意味着您可能会进一步下降。较小的特征值通常对应于损失景观中较平坦的区域，这通常与神经网络背景下更好的泛化相关。]]></description>
      <guid>https://stackoverflow.com/questions/77655218/eigenvalues-of-hessian-matrix-final-layer-much-smaller-than-others</guid>
      <pubDate>Wed, 13 Dec 2023 16:40:25 GMT</pubDate>
    </item>
    <item>
      <title>如何重新加入 scikit-learn Logistic 回归在相同索引处预测的概率？</title>
      <link>https://stackoverflow.com/questions/77655113/how-to-rejoin-scikit-learn-logistic-regression-predicted-probabilities-at-same-i</link>
      <description><![CDATA[我已经使用 scikit-learn 的逻辑回归成功地对一些数据运行了逻辑回归，我只想对附加到帧的数据帧进行预测。我有理由怀疑他们预测的概率没有被连接回他们应该加入的行。
这是发生回归的代码，以及将预测附加到原始数据帧的代码。
# 将预测变量 (ind_cols) 和响应变量分成两组以输入逻辑回归函数。

X = full_sample[ind_cols].to_pandas()

y = full_sample[dep_col].to_pandas()

lm = 逻辑回归（
    fit_intercept=真
）

lm.fit(X, y)

# 我想要预测的 DataFrame 是 ret_df，预测变量是 [ind_cols]。

y_pred = lm.predict_proba(ret_df[ind_cols].to_pandas())

y_final = pd.DataFrame(y_pred, columns=[&#39;Prob_0&#39;, &#39;Prob_1&#39;])

ret_df_out = pd.merge(ret_df.to_pandas(), y_final, how=&#39;left&#39;, left_index=True, right_index=True)

ret_df_out.show()

我认为这些值没有连接到相应的行的原因是因为我已经在 R Studio 中进行了精确的回归。在这里，当我查看正面和负面响应的预测值分布时，它们对于 scikit-learn 回归实际上是相同的。
预测是否有可能没有连接回其原始行？它可以解释真 0 和真 1 的预测值分布之间的相似性。]]></description>
      <guid>https://stackoverflow.com/questions/77655113/how-to-rejoin-scikit-learn-logistic-regression-predicted-probabilities-at-same-i</guid>
      <pubDate>Wed, 13 Dec 2023 16:24:42 GMT</pubDate>
    </item>
    <item>
      <title>最后一行的结果没有像我想象的那样出现</title>
      <link>https://stackoverflow.com/questions/77654857/result-of-the-last-line-doesnt-appear-as-i-thought-it-would-be</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77654857/result-of-the-last-line-doesnt-appear-as-i-thought-it-would-be</guid>
      <pubDate>Wed, 13 Dec 2023 15:46:40 GMT</pubDate>
    </item>
    <item>
      <title>优化 url 的文本分析</title>
      <link>https://stackoverflow.com/questions/77654806/optimizing-text-analysis-from-urls</link>
      <description><![CDATA[我正在尝试获取一组网址，
分析他们的文本并返回这些 url 中的前 5 个主题。我正在尝试使用来自 google 的 c# 和 LanguageServiceClient 来做到这一点。
我遇到的问题是下载一大组网址的文本非常耗时，其次我不想单独调用谷歌来获取每页的主题，而是一个大的主题。
有什么建议吗？欢迎使用其他库或 API
我可以一一完成，但如果我想做 10000 多个网址，则无法扩展]]></description>
      <guid>https://stackoverflow.com/questions/77654806/optimizing-text-analysis-from-urls</guid>
      <pubDate>Wed, 13 Dec 2023 15:38:14 GMT</pubDate>
    </item>
    <item>
      <title>Llama2 回归语言模型 (huggingface)</title>
      <link>https://stackoverflow.com/questions/77654285/llama2-language-model-for-regression-huggingface</link>
      <description><![CDATA[我尝试利用给定整个输入序列的模型的最后一个隐藏状态，调整 Llama2 来解决回归任务。
如果随后问问题“2+2 的答案是什么”，则应回答4（虚拟问题，用于解释问题）。&lt; /p&gt;
为此，我将在 pytorch 模型中使用它
导入火炬
将 torch.nn 导入为 nn
从 Transformer 导入 LlamaModel、LlamaTokenizer

类 TransformerModel(nn.Module):
    def __init__(self, 模型名称:str, 附加层大小:int = 1):
        super(TransformerModel, self).__init__()
        self.transformer = LlamaModel.from_pretrained(model_name, torch_dtype=torch.float32, cache_dir=“hugginface_cache/models”)
        self.tokenizer = LlamaTokenizer.from_pretrained(model_name,cache_dir=“hugginface_cache/tokenizer”)

        # 添加一个带有一个输出的附加层
        self.additional_layer = nn.Linear(self.transformer.config.hidden_​​size,additional_layer_size)
        
    defforward(self, input_text):
        # 对输入文本进行标记
        input_ids = self.tokenizer(input_text, return_tensors=“pt”).input_ids.to(“cuda”)
        打印（“输入ID：”，输入ID）

        # 获取变压器的输出
        输出 = self.transformer(input_ids)
        
        # 使用整个最后的隐藏状态作为附加层的输入
        最后隐藏状态 = 输出.最后隐藏状态
        打印（&#39;last_hidden_​​state_shape：&#39;，last_hidden_​​state.size（））

        # 应用附加层
        附加输出= self.附加层（最后隐藏状态）

        返回额外的输出


model_url = “meta-llama/Llama-2-7b-hf”

模型 = TransformerModel(model_url)

但是，对于给定的输入模型（“Hello world！”），输出是大小为 1,4,1 的张量。
我可以验证标记生成器是否将字符串拆分为 4 个标记，我预计这会导致问题。但是，我不确定如何解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77654285/llama2-language-model-for-regression-huggingface</guid>
      <pubDate>Wed, 13 Dec 2023 14:22:48 GMT</pubDate>
    </item>
    <item>
      <title>像 Google Photo-Image 这样的图像搜索被赋予模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77653804/image-search-like-google-photo-image-with-face-is-given-to-model</link>
      <description><![CDATA[当用户上传自拍照时，模型会在多人图像数据集中搜索同一个人，并返回包含该人的所有图像。
第 1 步：从图像数据集中检测所有人脸，并通过 DeepFace(RetinaFace) 和 OpenCV 保存裁剪后的人脸。
第2步：通过OpenCV读取所有裁剪后的面，调整其大小，存储到numpy数组中并标准化。
第 3 步：将其输入 VGG16(Keras) 模型，不包括具有 0 个可训练参数的顶层（使用权重），并从图像 numpy 数组中提取特征。
第4步：将这些提取的特征输入聚类模型（无监督）
我尝试了 KMeans 和凝聚层次聚类，但没有达到预期效果。
聚类根本不准确，更不准确。
任何人都可以帮助我解决这个问题，如何完成这项任务，我在哪一步犯了错误......
图像/数据未标记，想要构建无监督的聚类模型。
这里有 C# 的开源框架吗？]]></description>
      <guid>https://stackoverflow.com/questions/77653804/image-search-like-google-photo-image-with-face-is-given-to-model</guid>
      <pubDate>Wed, 13 Dec 2023 13:04:01 GMT</pubDate>
    </item>
    <item>
      <title>我应该在 Adam 优化器的顶部应用余弦退火调度程序吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77653513/should-i-apply-a-cosine-annealing-scheduler-on-the-top-of-the-adam-optimizer</link>
      <description><![CDATA[Adam 优化器以其自适应调整学习率的能力而闻名，那么余弦退火调度器还有用吗？
我还没有完成实验，部分原因是我没有干净的余弦退火代码示例。特别感谢那些可以提供代码片段的人。]]></description>
      <guid>https://stackoverflow.com/questions/77653513/should-i-apply-a-cosine-annealing-scheduler-on-the-top-of-the-adam-optimizer</guid>
      <pubDate>Wed, 13 Dec 2023 12:16:11 GMT</pubDate>
    </item>
    <item>
      <title>执行与自然语言处理相关的代码时出错[关闭]</title>
      <link>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</link>
      <description><![CDATA[此代码显示了图像中给出的错误。我无法理解其中的原因。

我不知道如何在Python中使用导入命令。我尝试了所有可能的方法进行检查，包括删除带有其他新闻门户名称的“路透社”，但没有任何效果。现在，如果有人帮助我正确编写代码的“导入”部分，那就更好了。我认为其他部分没问题，因为没有显示其他消息。]]></description>
      <guid>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</guid>
      <pubDate>Wed, 13 Dec 2023 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>SEEM 模型在向其传递图像及其推理时面临的问题</title>
      <link>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</link>
      <description><![CDATA[我正在研究 SEEM 模型，这是一个可推广的交互式模型，用于一次性分割图像中任何地方的所有内容。由于资源有限，我在将图像传递给它及其推理时面临问题。我已经安装了所有依赖项并单独加载了 SEEM 模型。有谁对此有任何想法并相应地指导我。
我期待有人能够根据他们的知识指导我，我可以尽快解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</guid>
      <pubDate>Wed, 13 Dec 2023 04:53:29 GMT</pubDate>
    </item>
    <item>
      <title>神经网络在时间序列中查找子序列？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77648688/neural-network-to-find-subsequence-in-time-series</link>
      <description><![CDATA[

蓝线代表时间序列
红色矩形子序列

是否可以通过机器学习方法找到这些子序列？
PS：这是合成数据，在真实数据中经典算法是无效的。这是一个例子：.
]]></description>
      <guid>https://stackoverflow.com/questions/77648688/neural-network-to-find-subsequence-in-time-series</guid>
      <pubDate>Tue, 12 Dec 2023 19:48:08 GMT</pubDate>
    </item>
    <item>
      <title>minMax TicTacToe 代码返回错误的最佳可能移动[关闭]</title>
      <link>https://stackoverflow.com/questions/77596870/minmax-tictactoe-code-returning-the-wrong-best-possible-move</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77596870/minmax-tictactoe-code-returning-the-wrong-best-possible-move</guid>
      <pubDate>Mon, 04 Dec 2023 02:07:13 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace AutoModelForCasualLM “仅解码器架构”警告，即使在设置 padding_side='left' 后也是如此</title>
      <link>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</link>
      <description><![CDATA[我正在使用
AutoModelForCausalLM 和 AutoTokenizer 使用 DialoGPT 生成文本输出。
无论出于何种原因，即使使用 Huggingface 提供的示例，我也会收到此警告：
&lt;块引用&gt;
正在使用仅解码器架构，但检测到右填充！为了正确的生成结果，请在初始化分词器时设置 padding_side=&#39;left&#39;。

从变压器导入 AutoModelForCausalLM, AutoTokenizer
进口火炬


tokenizer = AutoTokenizer.from_pretrained(“microsoft/DialoGPT-medium”)
模型 = AutoModelForCausalLM.from_pretrained(“microsoft/DialoGPT-medium”)

# 我们聊5行吧
对于范围（5）中的步骤：
    # 对新的用户输入进行编码，添加 eos_token 并在 Pytorch 中返回一个张量
    new_user_input_ids = tokenizer.encode(input(“&gt;&gt;用户:”) + tokenizer.eos_token, return_tensors=&#39;pt&#39;)

    # 将新的用户输入标记附加到聊天历史记录中
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) 如果步骤 &gt; 0 其他 new_user_input_ids

    # 生成响应，同时将总聊天历史记录限制为 1000 个令牌，
    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)

    # 漂亮地打印机器人最后的输出令牌
    print(“DialoGPT: {}”.format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0],skip_special_tokens=True)))

代码由 微软在 Huggingface 的模型卡上
我尝试将 padding_side=&#39;left&#39; 添加到标记生成器，但这不会改变任何内容。
显然（从一些阅读来看）DialoGPT 无论如何都希望在右侧填充？
我无法弄清楚这一点，当我尝试谷歌搜索时几乎没有结果。
我能够像这样抑制警告：
from Transformers.utils 导入日志记录

记录.set_verbosity_info()

但这似乎不是最好的答案？]]></description>
      <guid>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</guid>
      <pubDate>Fri, 09 Dec 2022 20:39:39 GMT</pubDate>
    </item>
    <item>
      <title>Python 进程因内存不足 256Gb 而被终止</title>
      <link>https://stackoverflow.com/questions/73888672/python-process-being-killed-due-to-out-of-256gb-memory</link>
      <description><![CDATA[训练数据集是一个 42GB JSON 文件。 mesh 是医学主题标题，将其视为 ID 或标签。 Neighbors_mesh 是一个 28,000 维列表，其中包含有关彼此接近的网格的信息。我们通过 KNN 训练 1.07 M 数据的网格项获得了这些数据。 MLB 拟合变换返回 0 和 1 的 28,000 维向量。但默认情况下每个元素都是 int64。我尝试通过 mask.astype(int__) 来减少它。仍然是 32 位。
运行大约 1M 次迭代后，迭代会阻塞 256GB 内存，但仍然会被杀死。
我的python版本是3.9
该机器拥有256GB内存、20GB交换内存、48核CPU和GPU。
def build_dataset（train_path，neighbors，journal_mesh，MeSH_id_pair_file，index_dic）：

    映射 ID = {}
    打开（MeSH_id_pair_file，&#39;r&#39;）作为f：
        对于 f 中的行：
            (键, 值) = line.split(&#39;=&#39;)
            映射_id[键] = value.strip()

    meshIDs = 列表(mapping_id.values())
    meshIDs = label2index(meshIDs,index_dic)
    meshIDs_str = [str(x) 表示 meshIDs 中的 x]

    print(&#39;标签总数%d&#39; % len(meshIDs_str))
    mlb = MultiLabelBinarizer(类=meshIDs_str)
    mlb.fit(meshIDs_str)

    pmid_neighbors，neighbors_mesh = read_neighbors（neighbors，index_dic）

    f = open(train_path, 编码=“utf8”)
    对象 = ijson.items(f, &#39;articles.item&#39;)
    

    数据集 = []
    print(&quot;对象：&quot;, type(对象))
    print(&quot;pmid 邻居：&quot;, type(pmid_neighbors))

    对于 i，枚举中的 obj(tqdm(objects))：
        数据点 = {}
        尝试：
            ids = obj[“pmid”]
            标题 = obj[&#39;标题&#39;].strip()
            标题 = header.translate(str.maketrans(&#39;&#39;, &#39;&#39;, &#39;[]&#39;))
            摘要 = obj[“abstractText”].strip()
            clean_abstract = Abstract.translate(str.maketrans(&#39;&#39;, &#39;&#39;, &#39;[]&#39;))
            if len(heading) == 0 或 header == &#39;处理中&#39;:
                print(&#39;论文&#39;, ids, &#39;没有标题！&#39;)
                继续
            elif len(clean_abstract) == 0:
                print(&#39;论文&#39;, ids, &#39;没有摘要！&#39;)
                继续
            别的：
                mesh_id = obj[&#39;网格&#39;]
                日记 = obj[&#39;日记&#39;]
                年 = obj[&#39;年&#39;]
                mesh_from_journal=journal_mesh[journal]
                mesh_from_neighbors = []
                如果我&lt; len(pmid_neighbors) 和 ids == pmid_neighbors[i]:
                    mesh_from_neighbors = Neighbors_mesh[i]
                mesh_from_journal_str = [str(x) 表示 mesh_from_journal 中的 x]
                mesh_from_neighbors_str = [str(x) for x in mesh_from_neighbors]
                网格=列表（设置（mesh_from_journal_str + mesh_from_neighbors_str））
                mask = mlb.fit_transform([网格])
                掩码 = mask.astype(np.int_)
                掩码 = mask.tolist()
                print(&quot;网格大小：&quot;, sys.getsizeof(mask))
                print(&quot;网格内容大小：&quot;, sys.getsizeof(mask[0][0]))
                print(&quot;网格内容类型：&quot;, type(mask[0][0]))
                data_point[&#39;pmid&#39;] = id
                data_point[&#39;标题&#39;] = 标题
                data_point[&#39;abstractText&#39;] = clean_abstract
                data_point[&#39;meshID&#39;] = mesh_id
                data_point[&#39;meshMask&#39;] = 掩码
                data_point[&#39;年份&#39;] = 年份
                数据集.append(data_point)
                print(&quot;数据集大小：&quot;, sys.getsizeof(dataset))
        

        除了属性错误：
            print(f&#39;pmid 发生异常: {obj[&quot;pmid&quot;].strip()}&#39;, AttributeError.args())


    pubmed = {&#39;文章&#39;: 数据集}
    返回发布
]]></description>
      <guid>https://stackoverflow.com/questions/73888672/python-process-being-killed-due-to-out-of-256gb-memory</guid>
      <pubDate>Wed, 28 Sep 2022 23:06:08 GMT</pubDate>
    </item>
    <item>
      <title>gTTS 中没有声音</title>
      <link>https://stackoverflow.com/questions/63464494/no-sound-in-gtts</link>
      <description><![CDATA[我正在尝试使用 gTTS 将文本转换为语音。
导入子流程
从 gtts 导入 gTTS

mytext = &#39;Rasa Bot 用户您好，我是机器人&#39;
语言=&#39;en&#39;
myobj = gTTS(文本 = mytext, lang=语言)
myobj.save(“welcome.mp3”)
subprocess.call([&#39;mpg321&#39;,&#39;welcome.mp3&#39;,&#39;--play-and-exit&#39;])


但是我好像听不到任何声音。我在 Ubuntu 中使用 PyCharm 执行此操作。
终端内容如下：
(venv) rome@rome-VirtualBox:~/Desktop/rasa/intr2$ python ttos.py
mpg321：无法识别的选项“--play-and-exit”
适用于第 1、2 和 3 层的高性能 MPEG 1.0/2.0/2.5 音频播放器。
版本0.3.2-1（2012/03/25）。乔·德鲁 (Joe Drew) 撰写并拥有版权，
现在由 Nanakos Chrysostomos 等人维护。
使用不同人的代码。请参阅“自述文件”了解更多信息！
本软件绝对不提供任何保证！使用风险自负！

正在播放welcome.mp3 中的MPEG 流...
MPEG 2.0 第三层，32 kbit/s，24000 Hz 单声道

请帮忙！！]]></description>
      <guid>https://stackoverflow.com/questions/63464494/no-sound-in-gtts</guid>
      <pubDate>Tue, 18 Aug 2020 08:15:35 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 健身房玩家模式</title>
      <link>https://stackoverflow.com/questions/46762083/openai-gym-player-mode</link>
      <description><![CDATA[有谁知道如何作为玩家运行 OpenAI 健身房环境之一。就像让人类玩家玩一轮车竿一样？我已经看到有 env.mode = &#39; human&#39; 但我无法让它正常运行。我尝试按照此处给出的示例 https://www.pinchofintelligence.com/getting -started-openai-gym/ 但它似乎对我不起作用。
如果您能提供任何帮助，我们将不胜感激。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/46762083/openai-gym-player-mode</guid>
      <pubDate>Mon, 16 Oct 2017 02:21:38 GMT</pubDate>
    </item>
    </channel>
</rss>