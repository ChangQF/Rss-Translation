<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 02 Feb 2025 06:21:09 GMT</lastBuildDate>
    <item>
      <title>是否有任何 Python 包支持基于非贪婪树的机器学习算法？[关闭]</title>
      <link>https://stackoverflow.com/questions/79405636/are-there-any-python-packages-which-support-non-greedy-tree-based-machine-learni</link>
      <description><![CDATA[即使它有点贪婪但不是完全贪婪，这可能很有趣。我有一个具有高度复杂的特征交互的数据集。]]></description>
      <guid>https://stackoverflow.com/questions/79405636/are-there-any-python-packages-which-support-non-greedy-tree-based-machine-learni</guid>
      <pubDate>Sat, 01 Feb 2025 20:24:50 GMT</pubDate>
    </item>
    <item>
      <title>从文档中学习 LangChain 的最佳方法是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/79405453/what-is-the-best-way-for-learning-langchain-from-its-documentation</link>
      <description><![CDATA[有人能指导我吗，从文档中学习 LangChain 的最佳方法是什么？它太庞大了，当我查看完整文档时，我感到不知所措。]]></description>
      <guid>https://stackoverflow.com/questions/79405453/what-is-the-best-way-for-learning-langchain-from-its-documentation</guid>
      <pubDate>Sat, 01 Feb 2025 18:19:04 GMT</pubDate>
    </item>
    <item>
      <title>我如何判断模型是否过度拟合？[关闭]</title>
      <link>https://stackoverflow.com/questions/79405195/how-can-i-tell-when-the-model-is-overfitting</link>
      <description><![CDATA[我最近开始研究机器学习，我有一个代码用于评估 SNN 和 ANN 对合成数据中运动事件进行分类的适用性，重点关注它们的速度（推理时间）和准确性。当我绘制损失和准确性曲线时，我确实觉得模型过度拟合了，尽管我检查了聊天 GPT 和 DeepSeek，两者都提到它不是过度拟合，这些结果是由于任务太简单，我可以依靠它们进行这种类型的分析吗？我每次如何才能知道模型是否正确学习？
以下是函数的图表
损失和准确率函数
图形表示
我尝试更改 epoch 的数量，但结果非常相似]]></description>
      <guid>https://stackoverflow.com/questions/79405195/how-can-i-tell-when-the-model-is-overfitting</guid>
      <pubDate>Sat, 01 Feb 2025 15:02:04 GMT</pubDate>
    </item>
    <item>
      <title>分类变量如何影响回归模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/79404865/how-do-categorical-variables-impact-a-regression-model</link>
      <description><![CDATA[在机器学习中，有两种类型的变量，一种是分类变量，另一种是数值变量。当我们对分类变量进行编码时，只有 0 和 1，0 和 1 如何影响模型或对回归模型的影响。它会降低模型性能或提高模型性能等。]]></description>
      <guid>https://stackoverflow.com/questions/79404865/how-do-categorical-variables-impact-a-regression-model</guid>
      <pubDate>Sat, 01 Feb 2025 11:09:48 GMT</pubDate>
    </item>
    <item>
      <title>文件的 CRC-32 错误</title>
      <link>https://stackoverflow.com/questions/79404810/bad-crc-32-for-file</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79404810/bad-crc-32-for-file</guid>
      <pubDate>Sat, 01 Feb 2025 10:39:29 GMT</pubDate>
    </item>
    <item>
      <title>如何使用图像上传作为 Deepseek-R1 等文本生成模型的输入？[关闭]</title>
      <link>https://stackoverflow.com/questions/79404729/how-can-i-use-image-uploads-as-input-for-text-generation-models-like-deepseek-r1</link>
      <description><![CDATA[我正在使用文本生成模型 (Deepseek-R1)，并注意到某些平台允许在文本提示的同时上传图片。例如，在之前的一次互动中，我引用了一张外卖容器中带塑料包装的烤五花肉图片来询问该模型的功能。但是，由于 Deepseek-R1 是基于文本的，这种集成如何工作？
像 Deepseek-R1 这样的文本生成模型可以直接处理图像输入吗？还是有一个中间步骤（例如，图像到文本的转换）？
如果不支持直接图像处理，那么在文本提示中描述视觉内容以指导模型输出的最佳实践是什么？
我希望有处理此类用例的示例或文档参考。]]></description>
      <guid>https://stackoverflow.com/questions/79404729/how-can-i-use-image-uploads-as-input-for-text-generation-models-like-deepseek-r1</guid>
      <pubDate>Sat, 01 Feb 2025 09:33:40 GMT</pubDate>
    </item>
    <item>
      <title>辍学率 AI - ML 课程 [关闭]</title>
      <link>https://stackoverflow.com/questions/79404303/dropout-rate-ai-ml-courses</link>
      <description><![CDATA[有谁知道我可以在哪里获得与人工智能机器学习相关的在线课程的辍学率？
我正在尝试发表一篇关于机器学习领域专门专业人员数量少的原因的文章，我想通过我提出的一个假设来获取有关人工智能课程辍学率及其可能原因的信息。]]></description>
      <guid>https://stackoverflow.com/questions/79404303/dropout-rate-ai-ml-courses</guid>
      <pubDate>Sat, 01 Feb 2025 01:52:01 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：从 Google Drive 加载经过微调的 LLaVA 模型时，“CLIPImageProcessor”对象没有属性“patch_size”</title>
      <link>https://stackoverflow.com/questions/79403742/attributeerror-clipimageprocessor-object-has-no-attribute-patch-size-when-l</link>
      <description><![CDATA[我在 Google Colab 上微调了一个 LLaVA（大型语言和视觉助手）模型，并将其保存到我的 Google Drive 中。以下是我保存模型的方法：
from google.colab import drive 
drive.mount(&#39;/content/drive&#39;, force_remount=True) 
import os 

save_path = &quot;/content/drive/MyDrive/fineTune model1/LLaVA-med-MAKAUT_v1&quot; 
os.makedirs(save_path, exist_ok=True) 

trainer.model.save_pretrained(save_path) 
trainer.tokenizer.save_pretrained(save_path) 
processor.image_processor.save_pretrained(save_path) 

保存后，我的 Google Drive 文件夹包含以下内容文件：

README.md

adapter_model.safetensors

adapter_config.json

tokenizer_config.json

special_tokens_map.json

added_tokens.json

tokenizer.model

tokenizer.json

preprocessor_config.json

config.json


但是，当我尝试加载模型进行测试时，我收到与以下相关的 AttributeError： patch_size:
导入 torch 
从 PIL 导入图像 
从 transformers 导入 LlavaProcessor、LlavaForConditionalGeneration、CLIPImageProcessor 

model_path = &quot;/content/drive/MyDrive/fineTune model/LLaVA-med-MAKAUT_v1&quot; 
process1 = LlavaProcessor.from_pretrained(model_path)

从模型的 vision_config 检查补丁大小
patch_size = new_model_v1.config.vision_config.patch_size 
print(&quot;Patch size:&quot;, patch_size) 

输出：
Patch size: 14 

错误发生在这里：
print(processor1.image_processor.patch_size) 

错误消息：
AttributeError: &#39;CLIPImageProcessor&#39; 对象没有属性 &#39;patch_size&#39;

我尝试过的方法：

确保模型正确保存和加载。

确认模型的视觉配置中存在补丁大小（patch_size：14）。

尝试手动设置 patch_size：
processor1.image_processor.patch_size = 14 



但是，这似乎不是正确的方法，因为 CLIPImageProcessor 没有此属性。
问题：

为什么 CLIPImageProcessor 缺少 patch_size 属性，即使它在模型的 vision_config 中定义？
确保 LLaVA 处理器与微调模型的配置保持一致的正确方法是什么，尤其是关于 patch_size？
是否有推荐的方法来正确加载和利用微调 LLaVA 模型及其处理器以在 Colab 中进行推理？
]]></description>
      <guid>https://stackoverflow.com/questions/79403742/attributeerror-clipimageprocessor-object-has-no-attribute-patch-size-when-l</guid>
      <pubDate>Fri, 31 Jan 2025 18:45:34 GMT</pubDate>
    </item>
    <item>
      <title>从 pix2pix 实现矢量化生成的线条</title>
      <link>https://stackoverflow.com/questions/79402632/vectorize-generated-lines-from-a-pix2pix-implementation</link>
      <description><![CDATA[我有以下使用 pix2pix 模型生成的图像。我希望生成的线条是直的，并且具有相同的高度（如果是水平的）和相同的宽度（如果是垂直的）。
基本上这些线是墙壁，稍后应该被渲染为房子里的墙壁。
有没有任何 python /ml 逻辑可以实现这一点？
]]></description>
      <guid>https://stackoverflow.com/questions/79402632/vectorize-generated-lines-from-a-pix2pix-implementation</guid>
      <pubDate>Fri, 31 Jan 2025 11:47:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyTorch 微调 LLM 时出现运行时错误：“张量的元素 0 不需要梯度”</title>
      <link>https://stackoverflow.com/questions/79402407/runtimeerror-with-pytorch-when-fine-tuning-llm-element-0-of-tensors-does-not-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79402407/runtimeerror-with-pytorch-when-fine-tuning-llm-element-0-of-tensors-does-not-r</guid>
      <pubDate>Fri, 31 Jan 2025 10:11:53 GMT</pubDate>
    </item>
    <item>
      <title>训练 Keras 模型来识别闰年</title>
      <link>https://stackoverflow.com/questions/79401755/training-a-keras-model-to-identify-leap-years</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79401755/training-a-keras-model-to-identify-leap-years</guid>
      <pubDate>Fri, 31 Jan 2025 04:14:59 GMT</pubDate>
    </item>
    <item>
      <title>Whisper 模型实时端点容器部署在 Azure ML 上失败</title>
      <link>https://stackoverflow.com/questions/79399452/whisper-model-real-time-endpoint-container-deployment-failed-on-azure-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79399452/whisper-model-real-time-endpoint-container-deployment-failed-on-azure-ml</guid>
      <pubDate>Thu, 30 Jan 2025 09:50:51 GMT</pubDate>
    </item>
    <item>
      <title>安装 pycoral 会导致“未满足的依赖项”错误，尽管依赖项已得到满足</title>
      <link>https://stackoverflow.com/questions/78593719/installing-pycoral-results-in-unmet-dependencies-error-despite-dependencies-be</link>
      <description><![CDATA[我在 Chromebook 上通过 sudo apt-get install python-pycoral 安装 pycoral 时出现以下错误
以下软件包具有未满足的依赖项：
python3-pycoral：依赖项：python3-tflite-runtime（= 2.5.0.post1），但不会安装
依赖项：python3（&lt; 3.10），但要安装 3.11.2-1+b1
E：无法更正问题，您持有损坏的软件包。

我确认我的设置符合列出的要求，但 pycoral 安装程序似乎忽略了 tflite（出现在 pip list 中）以及当前的 python 版本。
如果您有这方面的经验，我将不胜感激任何解决此问题的帮助。从“未满足的依赖项”错误的怪异性来看，我感觉 tflite 运行时和 python 版本之外的某些东西存在问题]]></description>
      <guid>https://stackoverflow.com/questions/78593719/installing-pycoral-results-in-unmet-dependencies-error-despite-dependencies-be</guid>
      <pubDate>Fri, 07 Jun 2024 19:28:31 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 AI 和机器学习库编写 Python 程序来预测游戏的下一个结果（从两种颜色中挑选一种）</title>
      <link>https://stackoverflow.com/questions/76086477/how-to-make-a-python-program-to-predict-the-next-outcome-of-a-game-of-picking-a</link>
      <description><![CDATA[我想用 Python 编写一个程序，使用 LSTM 技术，可以预测下一个结果或从两种颜色中挑选一种颜色的概率。该程序应使用 AI 和机器学习库，读取最后 40 个结果的模式，从而预测下一个结果。
我为此编写了以下程序。
from keras.models import Sequential
from keras.layers import LSTM, Dense
import numpy as np

def predict_next_color_lstm(outcomes):
if len(outcomes) &lt; 40:
return &quot;Error: 提供的结果数量少于 40。&quot;

# 将字符串输入转换为整数序列
seq = [0 if x == &#39;r&#39; else 1 for x in results]

# 创建 40 个结果的滚动窗口
X = []
y = []
for i in range(len(seq) - 40):
X.append(seq[i:i + 40])
y.append(seq[i + 40])
X = np.array(X)
y = np.array(y)

# 重塑 X 以适应 LSTM 输入形状
X = np.reshape(X, (X.shape[0], X.shape[1], 1))

# 创建 LSTM 模型
model = Sequential()
model.add(LSTM(50, input_shape=(40, 1)))
model.add(Dense(1,activation=&#39;sigmoid&#39;))

# 编译模型
model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;)

# 训练模型
model.fit(X, y, epochs=50, batch_size=32)

# 预测下一个结果
last_40 = seq[-40:]
pred = model.predict(np.array([last_40]))
如果 pred &lt;，则返回“r” 0.5 else &#39;g&#39;

def get_input():
# 要求用户输入长度为 40 的球颜色序列
ball_seq = input(&quot;输入长度为 40 的球颜色序列（例如 rrggrrgrrgggrgrgrgrgrgrgrgrgggrrggggrgggg）：&quot;)
return ball_seq

# _main_
ball_seq = get_input()
print(&quot;预测：&quot;, predict_next_color_lstm(ball_seq))

但是我在执行时不断收到以下错误：
C:\Users\Ashish\miniconda3\python.exe C:\Users\Ashish\Desktop\pyt_pract\test_prob1.py
输入长度为 40 的球颜色序列（例如 rrggrrgrrgggrgrgrrgggggrgrgrgrgrgggrrgggggg）：rgggrrgrggrrgrgrgrgrgrggggrrrrggrrgrgggrgrg
回溯（最近一次调用）：
文件“C:\Users\Ashish\Desktop\pyt_pract\test_prob1.py”，第 50 行，位于 &lt;module&gt;
print(&quot;预测：&quot;，predict_next_color_lstm(ball_seq))
文件“C:\Users\Ashish\Desktop\pyt_pract\test_prob1.py”，第 23 行，位于 predict_next_color_lstm
X = np.reshape(X, (X.shape[0], X.shape[1], 1))
IndexError：元组索引超出范围
]]></description>
      <guid>https://stackoverflow.com/questions/76086477/how-to-make-a-python-program-to-predict-the-next-outcome-of-a-game-of-picking-a</guid>
      <pubDate>Sun, 23 Apr 2023 18:08:18 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中的 StratifiedKFold 与 KFold</title>
      <link>https://stackoverflow.com/questions/65318931/stratifiedkfold-vs-kfold-in-scikit-learn</link>
      <description><![CDATA[我使用此代码测试 KFold 和 StratifiedKFold。
import numpy as np
from sklearn.model_selection import KFold,StratifiedKFold

X = np.array([
[1,2,3,4],
[11,12,13,14],
[21,22,23,24],
[31,32,33,34],
[41,42,43,44],
[51,52,53,54],
[61,62,63,64],
[71,72,73,74]
])

y = np.array([0,0,0,0,1,1,1,1])

sfolder = StratifiedKFold(n_splits=4,random_state=0,shuffle=False)
floder = KFold(n_splits=4,random_state=0,shuffle=False)

for train, test in sfolder.split(X,y):
print(&#39;Train: %s | test: %s&#39; % (train, test))
print(&quot;StratifiedKFold done&quot;)

for train, test in floder.split(X,y):
print(&#39;Train: %s | test: %s&#39; % (train, test))
print(&quot;KFold done&quot;)

我发现 StratifiedKFold 可以保持标签的比例，但是 KFold 不能。
Train: [1 2 3 5 6 7] |测试：[0 4]
训练：[0 2 3 4 6 7] | 测试：[1 5]
训练：[0 1 3 4 5 7] | 测试：[2 6]
训练：[0 1 2 4 5 6] | 测试：[3 7]
分层 KFold 完成
训练：[2 3 4 5 6 7] | 测试：[0 1]
训练：[0 1 4 5 6 7] | 测试：[2 3]
训练：[0 1 2 3 6 7] | 测试：[4 5]
训练：[0 1 2 3 4 5] |测试：[6 7]
KFold 完成

似乎 StratifiedKFold 更好，那么是否不应该使用 KFold？
何时使用 KFold 而不是 StratifiedKFold？]]></description>
      <guid>https://stackoverflow.com/questions/65318931/stratifiedkfold-vs-kfold-in-scikit-learn</guid>
      <pubDate>Wed, 16 Dec 2020 07:30:44 GMT</pubDate>
    </item>
    </channel>
</rss>