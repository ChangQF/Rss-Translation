<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 11 Mar 2024 12:24:38 GMT</lastBuildDate>
    <item>
      <title>对模型进行 GAN 训练，根据 4 个人体测量输入（身高、腰部、胸部、臀部）生成 3D 模型</title>
      <link>https://stackoverflow.com/questions/78140368/gan-training-of-a-model-to-generate-3d-models-from-4-anthropometric-inputheight</link>
      <description><![CDATA[训练循环
num_epochs = 100
对于范围内的纪元（num_epochs）：
对于 train_dataloader 中的批次：
真实数据 = 批次
fake_data = Generator(anthropometric_tensor) # 替换为实际输入
 # 训练鉴别器
    optim_d.zero_grad()
    real_labels = torch.ones(real_data.size(0), 1)
    fake_labels = torch.zeros(fake_data.size(0), 1)
    loss_real = 标准(鉴别器(real_data), real_labels)
    loss_fake = 标准(鉴别器(fake_data.detach()), fake_labels)
    loss_D = loss_real + loss_fake
    loss_D.backward()
    优化器_D.step()

    # 训练生成器
    Optimizer_G.zero_grad()
    loss_G = 标准（鉴别器（假数据），真实标签）
    loss_G.backward()
    优化器_G.step()

print(f&quot;Epoch [{epoch}/{num_epochs}] Loss_D: {loss_D.item()} Loss_G: {loss_G.item()}&quot;)



运行时错误：形状“[-1, 37500]”对于大小 64 的输入无效
]]></description>
      <guid>https://stackoverflow.com/questions/78140368/gan-training-of-a-model-to-generate-3d-models-from-4-anthropometric-inputheight</guid>
      <pubDate>Mon, 11 Mar 2024 11:43:20 GMT</pubDate>
    </item>
    <item>
      <title>如何在训练之前将 pytorch resnet50 模型的输入形状从 3, 224, 224 更改为 224, 224, 3</title>
      <link>https://stackoverflow.com/questions/78140043/how-do-i-change-the-input-shape-of-a-pytorch-resnet50-model-before-training-to-2</link>
      <description><![CDATA[在数据集上进行训练之前，如何更改 pytorch resnet50 模型的输入形状
当我将训练好的模型转换为 .tflite 格式以在 flutter 应用程序中使用时，我遇到了错误，该应用程序基本上希望我将模型的输入张量从 1, 3, 224 更改为 1, 224, 224, 3 ，224。]]></description>
      <guid>https://stackoverflow.com/questions/78140043/how-do-i-change-the-input-shape-of-a-pytorch-resnet50-model-before-training-to-2</guid>
      <pubDate>Mon, 11 Mar 2024 10:47:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 Huggingface MT5 模型中执行批量编码时会得到不同的嵌入？</title>
      <link>https://stackoverflow.com/questions/78139855/why-do-i-get-different-embeddings-when-i-perform-batch-encoding-in-huggingface-m</link>
      <description><![CDATA[我正在尝试使用 HuggingFace 的 mt5-base 模型对一些文本进行编码。我使用的模型如下所示
从转换器导入 MT5EncoderModel、AutoTokenizer

模型 = MT5EncoderModel.from_pretrained(“google/mt5-base”)
tokenizer = AutoTokenizer.from_pretrained(“google/mt5-base”)

def get_t5_embeddings(文本):
    last_hidden_​​state = model(input_ids=tokenizer(texts, return_tensors=“pt”, padding=True).input_ids).last_hidden_​​state
    pooled_sentence = torch.max(last_hidden_​​state, 暗淡=1)
    返回 pooled_sentence[0].detach().numpy()

当我注意到相同的文本与其自身的余弦相似度分数较低时，我正在做一些实验。我做了一些挖掘，意识到如果我批量进行编码，模型会返回非常不同的嵌入。为了验证这一点，我运行了一个小实验，逐步生成 Hello 的嵌入和 10 个 Hello 的列表。并检查列表中 Hello 和第一个 Hello 的嵌入（两者应该相同）。
对于范围 (1, 10) 内的 i：
    print(i, (get_t5_embeddings([“你好”])[0] == get_t5_embeddings([“你好”]*i)[0]).sum())

这将返回嵌入中相互匹配的值的数量。
结果是这样的：
&lt;前&gt;&lt;代码&gt;1 768
2 768
3 768
4 768
5 768
6 768
7 768
8 27
9 27

每次运行它时，如果批量大小超过 768，就会出现不匹配情况。
为什么我会得到不同的嵌入以及如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78139855/why-do-i-get-different-embeddings-when-i-perform-batch-encoding-in-huggingface-m</guid>
      <pubDate>Mon, 11 Mar 2024 10:14:53 GMT</pubDate>
    </item>
    <item>
      <title>Predict_proba() 给出的概率为 0 和 1，但中间值很少</title>
      <link>https://stackoverflow.com/questions/78139504/predict-proba-giving-probabilities-as-0s-and-1s-but-few-intermediate-values</link>
      <description><![CDATA[我正在研究乳腺癌检测分类问题。我已经从 Kaggle 下载了数据集：(https://www.kaggle.com /datasets/yasserh/breast-cancer-dataset)
我想预测：
a) 肿瘤是良性还是恶性
和
b) 肿瘤恶性的概率（0-1）是多少。
我正在实现随机森林分类器。
我面临的问题是，当我使用 rf_classifier.predict_proba() 方法时，我获得的概率包含大量 1 和 0，但中间值很少。理想情况下，我希望概率列中的所有值都是 0 到 1 之间的小数。
这种方法是实现目标的正确方法吗？如果是，如何解决这个问题？
分类器表现非常好。
这是我的代码的相关部分：
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size=0.2)
定标器=标准定标器()

X_train = 缩放器.fit_transform(X_train)
X_test = 缩放器.transform(X_test)

rf_classifier = RandomForestClassifier()
rf_classifier.fit(X_train, y_train)

y_pred = rf_classifier.predict(X_test)

y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]

结果 = np.column_stack((y_test[:200], y_pred[:200], y_pred_proba[:200]))
np.set_printoptions(精度=2, 抑制=True)
print(&quot;实际|预测|概率&quot;)
打印（结果）

输出：

分类报告：
]]></description>
      <guid>https://stackoverflow.com/questions/78139504/predict-proba-giving-probabilities-as-0s-and-1s-but-few-intermediate-values</guid>
      <pubDate>Mon, 11 Mar 2024 09:13:47 GMT</pubDate>
    </item>
    <item>
      <title>Julia 和 MLJ 中的数据类型</title>
      <link>https://stackoverflow.com/questions/78139165/data-type-in-julia-and-mlj</link>
      <description><![CDATA[我是 Julia 的新手，正在尝试拟合一个简单的分类树
包导入和环境激活：
使用 Pkg
Pkg.activate(“.”)

使用 CSV
使用数据框
使用随机
使用下载
使用 ARFF 文件
使用科学类型
使用 DataFramesMeta
使用动态管道
使用MLJ
使用 MLJDecisionTreeInterface

数据：
titanic_reader = CSV.File(“/home/andrea/dev/julia/titanic.csv”; header = 1);
泰坦尼克号 = DataFrame(titanic_reader);

# 删除缺失值
泰坦尼克号 = dropmissing(泰坦尼克号);


泰坦尼克号 = @transform(泰坦尼克号,
    ：类=分类（：类），
    ：性别=分类（：性别），
    ：幸存=分类（：幸存）
    ）；

检查数据
第一（泰坦尼克号，3）

3×4 数据框
 排 │ 班级 性别 年龄 幸存
     │ 猫…猫…Float64 猫…
──────┼──────────────────────────────────
   1 │ 3 男 22.0 N
   2 │ 1 女 38.0 岁
   3 │ 3 女 26.0 岁

检查数据架构
架构（泰坦尼克号）；


┌──────────┬──────────────┬──────────────────────── ──────────────┐
│ 名称 │ scitypes │ 类型 │
├──────────┼──────────────┼────────────────────── ──────────────┤
│ 类 │ 多类{3} │ CategoricalValue{Int64, UInt32} │
│ 性别 │ 多类{2} │ CategoricalValue{String7, UInt32} │
│ 年龄 │ 连续 │ Float64 │
│ 幸存下来 │ 多类{2} │ CategoricalValue{String1, UInt32} │
└──────────┴──────────────┴──────────────────────── ──────────────┘

架构对我来说似乎没问题
准备建模数据：
# 目标和功能
y, X = 解包(泰坦尼克号, ==(:幸存), rng = 123);

# 分区训练&amp;测试
(X_trn, X_tst), (y_trn, y_tst) = 分区((X, y), 0.75, multi=true, rng=123);

拟合模型：
&lt;前&gt;&lt;代码&gt;# 型号
mod = @load DecisionTreeClassifier pkg = “DecisionTree”; ;
fm = mod() ;
fm_mach = 机器(fm, X_trn, y_trn);

问题是这样的：
警告：数据参数的数量和/或类型与指定模型不匹配
│ 支持。通过指定“scitype_check_level=0”来抑制此类型检查。
│
│ 运行“@doc DecisionTree.DecisionTreeClassifier”以了解有关模型要求的更多信息。
│
│ 通常但非唯一地，监督模型是使用以下语法构建的
│ `machine(model, X, y)` 或 `machine(model, X, y, w)` 而大多数其他模型是
│ 用 `machine(model, X)` 构造。这里“X”是特征，“y”是目标，“w”
│ 样本或类别权重。
│
│ 一般来说，`machine(model, data...)`中的数据预计满足
│
│ scitype(数据) &lt;: MLJ.fit_data_scitype(模型)
│
│ 在本案中：
│
│ scitype(数据) = Tuple{Table{Union{AbstractVector{连续}, AbstractVector{Multiclass{3}}, AbstractVector{Multiclass{2}}}}, AbstractVector{Multiclass{2}}}
│
│ fit_data_scitype(model) = Tuple{Table{&lt;:Union{AbstractVector{&lt;:连续}, AbstractVector{&lt;:Count}, AbstractVector{&lt;:OrderedFactor}}}, AbstractVector{&lt;:有限}}
└ @ MLJBase ~/.julia/packages/MLJBase/eCnWm/src/machines.jl:231

显然，在拟合模型时：
适合！(fm_mach)

我收到错误
[信息：学习网络中的上游节点似乎正在提供不兼容的 scitype 数据。往上看。
错误：ArgumentError：无法使用 &lt; 测试无序 CategoricalValue 对象的顺序。使用 isless 代替，或者调用 ordered！父数组上的函数来更改此值
堆栈跟踪：

我几乎确定错误取决于数据类型规范，但是我无法找到解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78139165/data-type-in-julia-and-mlj</guid>
      <pubDate>Mon, 11 Mar 2024 08:07:08 GMT</pubDate>
    </item>
    <item>
      <title>如何获取在 PyCaret 中创建的模型的列名称</title>
      <link>https://stackoverflow.com/questions/78139097/how-do-i-get-column-names-of-a-model-created-in-pycaret</link>
      <description><![CDATA[我正在尝试创建一个 PyCaret 模型
# 加载数据集
从 pycaret.datasets 导入 get_data
保险 = get_data(&#39;保险&#39;)

# 初始化环境
从 pycaret.regression 导入 *

r1 = 设置（保险，目标 = &#39;费用&#39;，session_id = 123，
           标准化=真，
           多项式特征=真，
           bin_numeric_features= [&#39;年龄&#39;, &#39;bmi&#39;])

我看到现在已创建 55 列。如何获取 PyCaret 模型的列名称]]></description>
      <guid>https://stackoverflow.com/questions/78139097/how-do-i-get-column-names-of-a-model-created-in-pycaret</guid>
      <pubDate>Mon, 11 Mar 2024 07:54:33 GMT</pubDate>
    </item>
    <item>
      <title>调用 OnActionReceived 或 RequestDecision 让 Unity ML-Agent 轮流执行，观察次数较少 (0)</title>
      <link>https://stackoverflow.com/questions/78138694/call-onactionreceived-or-requestdecision-to-make-unity-ml-agents-do-their-turn</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78138694/call-onactionreceived-or-requestdecision-to-make-unity-ml-agents-do-their-turn</guid>
      <pubDate>Mon, 11 Mar 2024 06:13:00 GMT</pubDate>
    </item>
    <item>
      <title>在 MERN Stack 应用程序中集成线性回归：Python 还是 JavaScript？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78138619/integrating-linear-regression-in-mern-stack-application-python-or-javascript</link>
      <description><![CDATA[我使用 MERN 堆栈（MongoDB、Express.js、React、Node.js）开发了一个餐厅管理面板，现在正在寻求实现线性回归来预测销售或根据历史数据预测客户流量。后端完全采用 Node.js，但我正在考虑使用 Python 作为线性回归部分，因为它具有广泛的库和对数据科学的支持（如 NumPy、pandas 和 scikit-learn）。
我的困境是，是坚持使用 JavaScript/Node.js 以保持堆栈一致，还是将 Python 引入其中，以获取其卓越的机器学习功能。我担心将 Python 与现有 Node.js 后端集成的潜在复杂性以及如何管理两者之间的通信（如果这是我选择的路线）。另一方面，我也在考虑 Python 库可能为线性回归任务提供的性能和实现的简易性。
我希望了解以下方面的见解：

将 Python 进行线性回归集成到 MERN 堆栈应用程序的可行性和最佳实践。
如果我沿着这条路走下去，管理 Node.js 和 Python 之间通信的潜在挑战和解决方案。
如果留在 JS 生态系统内，可以有效处理线性回归的 JavaScript 库的建议。

最终，我正在寻找有关将线性回归合并到我的项目中的最佳路径的指导，权衡 Python 与 JavaScript 对于这个特定用例的优缺点。
我最初探索直接在 Node.js 中实现线性回归，希望保持一致的技术堆栈。我尝试了几个 JavaScript 库，例如用于基本统计操作的 simple-statistics 和用于更多面向机器学习的任务的 mljs，希望它们能够提供一种将线性回归模型应用到我的数据集的简单方法。
通过这些库，我成功地在 Node.js 中实现了基本的线性回归模型。我的期望是，这种方法不仅能够满足我所需的预测准确性，而且还可以通过避免跨语言集成来保持应用程序部署和维护的简单性。
然而，结果好坏参半。虽然我能够开发和运行线性回归模型，但我遇到了两个主要问题：

性能和可扩展性：JavaScript 解决方案适用于小型数据集，但当我尝试扩大数据大小以更接近地反映餐厅管理面板的实际使用场景时，性能未达到我的预期。处理时间比预期的要长，我开始担心这个解决方案的可扩展性。

功能集和易用性：虽然我使用的库提供了线性回归的基本功能，但我发现与我所知道的可用库相比，它们缺乏功能的广度和高级统计分析的易用性。 Python 的生态系统（例如 scikit-learn）。例如，我想要更复杂的方法来处理模型拟合、诊断和验证，以提高预测准确性，这在 Python 库中似乎更容易访问。


这些经历让我考虑将 Python 作为实现项目的线性回归部分的替代方案，尽管我最初打算将所有内容保留在 Node.js 环境中。这里的期望不仅是实现更好的性能和可扩展性，还包括访问更丰富的数据分析和机器学习工具集，以增强我的餐厅管理面板中预测的功能和准确性。]]></description>
      <guid>https://stackoverflow.com/questions/78138619/integrating-linear-regression-in-mern-stack-application-python-or-javascript</guid>
      <pubDate>Mon, 11 Mar 2024 05:49:33 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在 OpenCV 中创建大型模型而不需要大量 RAM？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78137426/is-it-possible-to-create-a-large-model-in-opencv-without-needing-insane-amounts</link>
      <description><![CDATA[我正在尝试在 OpenCV 中创建一个用于人脸检测的模型（特别是性别和年龄）。我拥有的数据集大约有 50,000 张图像。当我尝试使用大量数据训练模型时，内存使用量就会上升。即使在尝试批处理和卸载加载的 cv::mat 图像时，模型的大小也会增加（我猜这是预料之中的）。
我尝试一次加载和训练一张图像，并且使用此变体我尝试批量训练，但结果仍然相同
ImageCollection 类只是 SEXAGEBRACKET（标签）到图像文件路径的映射。我使用的模型是 LBPHFaceRecognizer。
这是我的“负载和训练”函数看起来像：
void ModelGenerator::LoadImagesAndTrain(const ImageCollection* imageCollection, const cv::Ptr modelToTrain, const bool isUpdatingModel)
{
    cv::大小加载图像大小；
    cv::Mat currLoadedImage；
    std::vector图像使用；
    std::vector&lt;int&gt;标签使用；
    std::multimap*括号ToImageFileNameMap;

    if (imageCollection!= NULL &amp;&amp; modelToTrain != NULL)
    {
        std::cout &lt;&lt; “提供用于训练的图像数量：” &lt;&lt; imageCollection-&gt;GetNumberOfImages() &lt;&lt; std::endl;

        括号ToImageFileNameMap = imageCollection-&gt;GetBracketToFileNameMap();

        //检查这是否是我们第一次训练模型，所有其他调用都将是更新。
        if (isUpdatingModel == false)
        {
            currLoadedImage = cv::imread(bracketToImageFileNameMap-&gt;begin()-&gt;第二个，cv::IMREAD_GRAYSCALE);

            imagesToUse.push_back(currLoadedImage);
            labelsToUse.push_back(bracketToImageFileNameMap-&gt;begin()-&gt;first);

            modelToTrain-&gt;train(imagesToUse, labelsToUse);

            currLoadedImage.release();
        }

        imagesToUse.clear();
        labelsToUse.clear();

        无符号长 i = 1UL；
        for (std::multimap::iterator it=bracketToImageFileNameMap-&gt;begin(); it!=bracketToImageFileNameMap-&gt;end(); it++)
        {
            如果（（i％2000）== 0）
            {
                std::cout &lt;&lt; “训练模型......” &lt;&lt; std::endl;

                modelToTrain-&gt;update(imagesToUse, labelsToUse);

                imagesToUse.clear();
                labelsToUse.clear();
            }

            std::cout &lt;&lt;它-&gt;第一个&lt;&lt; ”：“ &lt;&lt;它-&gt;第二个&lt;&lt; std::endl;

            currLoadedImage = cv::imread(it-&gt;第二个, cv::IMREAD_GRAYSCALE);

            imagesToUse.push_back(currLoadedImage);
            labelsToUse.push_back(it-&gt;first);

            currLoadedImage.release();

            我++;
        }
    }
}

是否可以在 OpenCV 中创建一个非常大的模型（包含 50,000 张图像），而不需要 300GB 的 RAM？]]></description>
      <guid>https://stackoverflow.com/questions/78137426/is-it-possible-to-create-a-large-model-in-opencv-without-needing-insane-amounts</guid>
      <pubDate>Sun, 10 Mar 2024 20:41:02 GMT</pubDate>
    </item>
    <item>
      <title>BigQuery ML - 看不见的类别触发分数</title>
      <link>https://stackoverflow.com/questions/78137175/bigquery-ml-unseen-category-triggers-the-score</link>
      <description><![CDATA[我一直在研究 bqml 中的随机森林分类器模型，该模型应该检测有风险的信用卡交易，其中一个功能是“ payment_method”，它指示 CC 的类型。
当我在“现实世界”上测试它时交易时，我注意到它对新类别“ payment_method ”的交易给出了极高的分数，模型尚未接受过该类别的训练，但仍然不应该像模型预测的那样有风险。
有什么想法为什么会发生这种情况以及我如何确保下次遇到新类别时不会触发高分？
（顺便说一句，随机森林中 bqml 中的自动编码是标签，如果有影响的话。）
bqml 模型不应该对未经训练的类别预测出如此高的分数，而应该了解该类别是合法的。]]></description>
      <guid>https://stackoverflow.com/questions/78137175/bigquery-ml-unseen-category-triggers-the-score</guid>
      <pubDate>Sun, 10 Mar 2024 19:13:08 GMT</pubDate>
    </item>
    <item>
      <title>尝试从 Mistral7B 微调的 LLM 生成摘要时出现意外的关键字参数“use_dora”</title>
      <link>https://stackoverflow.com/questions/78122541/unexpected-keyword-argument-use-dora-when-attempting-to-generate-summary-from</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78122541/unexpected-keyword-argument-use-dora-when-attempting-to-generate-summary-from</guid>
      <pubDate>Thu, 07 Mar 2024 15:29:37 GMT</pubDate>
    </item>
    <item>
      <title>调试 RandomForestRegressor() 在时间序列数据上产生主要恒定的预测结果</title>
      <link>https://stackoverflow.com/questions/76197241/debugging-randomforestregressor-producing-mainly-constant-forecast-results-ove</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76197241/debugging-randomforestregressor-producing-mainly-constant-forecast-results-ove</guid>
      <pubDate>Mon, 08 May 2023 02:56:12 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker Studio 无法加载</title>
      <link>https://stackoverflow.com/questions/70587853/sagemaker-studio-does-not-load-up</link>
      <description><![CDATA[Sagemaker Studio 在前 6 个月里对我来说工作得非常完美。然后我就开始观察这个问题。 错误消息的屏幕截图
屏幕永远保持在这个阶段。这是我尝试过的：

清除我的缓存，即使使用不同的机器也是如此。所以我认为问题不在于浏览器或我的机器。
按上面屏幕截图中的“清除工作区”。
关闭我的 sagemaker 域中的所有应用（不包括“默认”应用）。这最初是有效的，但现在已经完全停止工作了。
使用前一个域中的部分文件创建了一个新的 sagemaker 域。尽管如此，我在新域中也看到了相同的错误消息。

这严重影响了我的工作，我在互联网上找不到解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/70587853/sagemaker-studio-does-not-load-up</guid>
      <pubDate>Wed, 05 Jan 2022 04:37:09 GMT</pubDate>
    </item>
    <item>
      <title>绘制 scikit-learn (sklearn) SVM 决策边界/曲面</title>
      <link>https://stackoverflow.com/questions/51297423/plot-scikit-learn-sklearn-svm-decision-boundary-surface</link>
      <description><![CDATA[我目前正在使用 python 的 scikit 库执行具有线性内核的多类 SVM。
样本训练数据和测试数据如下：
模型数据：

&lt;预&gt;&lt;代码&gt;x = [[20,32,45,33,32,44,0],[23,32,45,12,32,66,11],[16,32,45,12, 32,44,23],[120,2,55,62,82,14,81],[30,222,115,12,42,64,91],[220,12,55,222,82,14,181],[30,222,315, 12,222,64,111]]
y = [0,0,0,1,1,2,2]

我想绘制决策边界并可视化数据集。有人可以帮忙绘制此类数据吗？
上面给出的数据只是模拟数据，因此请随意更改值。
如果至少您能建议应遵循的步骤，那将会很有帮助。
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/51297423/plot-scikit-learn-sklearn-svm-decision-boundary-surface</guid>
      <pubDate>Thu, 12 Jul 2018 04:43:23 GMT</pubDate>
    </item>
    <item>
      <title>n_estimators 总能提高随机森林的性能？</title>
      <link>https://stackoverflow.com/questions/39508983/n-estimators-always-improves-performance-in-randomforest</link>
      <description><![CDATA[我通过 n_estimators 的最低值获得最高分。据我了解，更多的树应该总是会提高性能。谁能解释一下这里发生了什么？
输入：
# 估计 n_estimators

param_test1 = {&#39;n_estimators&#39;: 范围(20, 800, 30)}

clf = RandomForestClassifier(random_state = 10,
                         oob_score = 真，
                         最大深度 = 6,
                         max_features = &#39;sqrt&#39;)

gsearch1 = GridSearchCV(
    估计量=clf,
    param_grid=param_test1,
    评分=&#39;roc_auc&#39;,
    iid=假，
    简历=5)

gsearch1.fit(X, y)
gsearch1.grid_scores_、gsearch1.best_params_、gsearch1.best_score_

输出：
([平均值：0.87685，标准差：0.03149，参数：{u&#39;n_estimators&#39;：20}，
  平均值：0.87551，标准差：0.02979，参数：{u&#39;n_estimators&#39;：50}，
  平均值：0.87588，标准差：0.02970，参数：{u&#39;n_estimators&#39;：80}，
  平均值：0.87545，标准差：0.03043，参数：{u&#39;n_estimators&#39;：110}，
  平均值：0.87593，标准差：0.02979，参数：{u&#39;n_estimators&#39;：140}，
  平均值：0.87506，标准差：0.02913，参数：{u&#39;n_estimators&#39;：170}，
  平均值：0.87599，标准差：0.02890，参数：{u&#39;n_estimators&#39;：200}，
  平均值：0.87559，标准差：0.02875，参数：{u&#39;n_estimators&#39;：230}，
  平均值：0.87561，标准差：0.02890，参数：{u&#39;n_estimators&#39;：260}，
  平均值：0.87500，标准差：0.02867，参数：{u&#39;n_estimators&#39;：290}，
  平均值：0.87476，标准差：0.02848，参数：{u&#39;n_estimators&#39;：320}，
  平均值：0.87434，标准差：0.02800，参数：{u&#39;n_estimators&#39;：350}，
  平均值：0.87408，标准差：0.02823，参数：{u&#39;n_estimators&#39;：380}，
  平均值：0.87461，标准差：0.02789，参数：{u&#39;n_estimators&#39;：410}，
  平均值：0.87452，标准差：0.02764，参数：{u&#39;n_estimators&#39;：440}，
  平均值：0.87466，标准差：0.02775，参数：{u&#39;n_estimators&#39;：470}，
  平均值：0.87498，标准差：0.02805，参数：{u&#39;n_estimators&#39;：500}，
  平均值：0.87530，标准差：0.02797，参数：{u&#39;n_estimators&#39;：530}，
  平均值：0.87519，标准差：0.02760，参数：{u&#39;n_estimators&#39;：560}，
  平均值：0.87498，标准差：0.02789，参数：{u&#39;n_estimators&#39;：590}，
  平均值：0.87529，标准差：0.02784，参数：{u&#39;n_estimators&#39;：620}，
  平均值：0.87526，标准差：0.02792，参数：{u&#39;n_estimators&#39;：650}，
  平均值：0.87553，标准差：0.02807，参数：{u&#39;n_estimators&#39;：680}，
  平均值：0.87540，标准差：0.02794，参数：{u&#39;n_estimators&#39;：710}，
  平均值：0.87561，标准差：0.02786，参数：{u&#39;n_estimators&#39;：740}，
  平均值：0.87554，标准差：0.02814，参数：{u&#39;n_estimators&#39;：770}]，
 {u&#39;n_estimators&#39;：20}，
 0.87684895838888188)
]]></description>
      <guid>https://stackoverflow.com/questions/39508983/n-estimators-always-improves-performance-in-randomforest</guid>
      <pubDate>Thu, 15 Sep 2016 10:38:08 GMT</pubDate>
    </item>
    </channel>
</rss>