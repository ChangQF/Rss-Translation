<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 15 Dec 2023 06:17:53 GMT</lastBuildDate>
    <item>
      <title>如何将我的前端与 google colab 上的机器学习模型集成？</title>
      <link>https://stackoverflow.com/questions/77664369/how-to-integrate-my-front-end-with-a-machine-learning-model-on-google-colab</link>
      <description><![CDATA[我希望将我用于预测的机器学习模型与前端连接起来，这样我就可以拥有一个从用户收集数据的 UI，以便模型可以读取数据并根据其训练给出结果。
我尝试在 YouTube 上寻找答案，但找不到太多帮助]]></description>
      <guid>https://stackoverflow.com/questions/77664369/how-to-integrate-my-front-end-with-a-machine-learning-model-on-google-colab</guid>
      <pubDate>Fri, 15 Dec 2023 05:14:07 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习选择关键帧[关闭]</title>
      <link>https://stackoverflow.com/questions/77663856/keyframe-selection-using-deep-learning</link>
      <description><![CDATA[我想使用深度学习从视频片段中选择单个关键帧。我有一堆发生特定事件的视频片段。我想选择它发生的确切关键帧。
任何想法都会非常有帮助。
提前致谢。
我正在考虑在原始帧和光流帧上应用CNN，结合特征并应用lstm。类的数量就是帧的数量，它会在事件发生的帧上预测 1，在其他地方预测 0。]]></description>
      <guid>https://stackoverflow.com/questions/77663856/keyframe-selection-using-deep-learning</guid>
      <pubDate>Fri, 15 Dec 2023 01:32:55 GMT</pubDate>
    </item>
    <item>
      <title>Conv1D 输入形状</title>
      <link>https://stackoverflow.com/questions/77663705/conv1d-input-shape-for</link>
      <description><![CDATA[我正在针对分类问题训练 CNN。输入形状是一个 x_train.shape = (6352,) 的数字，我有 10 个类。
我构建了这个模型：
# 添加 Conv1D 层
输入形状=(6352,1)

模型 = keras.Sequential()

model.add(keras.layers.Conv1D(16，kernel_size=3，activation=&#39;relu&#39;，input_shape=input_shape))
model.add(keras.layers.MaxPooling1D(pool_size=3))

model.add(keras.layers.Conv1D(32,kernel_size=2,activation=&#39;relu&#39;))
model.add(keras.layers.MaxPooling1D(pool_size=3))

model.add(keras.layers.Flatten())
model.add（keras.layers.Dense（64，激活=&#39;relu&#39;））
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Dense(10, 激活=&#39;softmax&#39;))

模型.summary()

但是当我尝试拟合模型时，我得到了这个：
警告：tensorflow：模型是使用输入 KerasTensor 的形状 (None, 6352, 1) 构建的(type_spec=TensorSpec(shape=(None, 6352, 1), dtype=tf.float32, name=&#39;conv1d_3_input &#39;)，name=&#39;conv1d_3_input&#39;，description=“由层&#39;conv1d_3_input&#39;创建”)，但它是在形状不兼容的输入上调用的(None,)。

 ValueError：调用层“sequential_3”（类型 Sequential）时遇到异常。
    
    层“conv1d_3”的输入0与图层不兼容：预期 min_ndim=3，发现 ndim=1。收到完整形状：（无，）
    
    调用层“sequential_3”接收的参数（类型 Sequential）：
      输入=tf.Tensor（形状=（无，），dtype=float32）
      • 训练=真
      • 掩码=无

如何知道正确的输入形状以及如何通过层跟踪形状以便模型可以工作？
我尝试了几种输入形状，但没有任何效果]]></description>
      <guid>https://stackoverflow.com/questions/77663705/conv1d-input-shape-for</guid>
      <pubDate>Fri, 15 Dec 2023 00:22:56 GMT</pubDate>
    </item>
    <item>
      <title>Python ValueError：给定的列不是数据帧的列</title>
      <link>https://stackoverflow.com/questions/77663537/python-valueerror-a-given-column-is-not-a-column-of-the-dataframe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77663537/python-valueerror-a-given-column-is-not-a-column-of-the-dataframe</guid>
      <pubDate>Thu, 14 Dec 2023 23:15:42 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试解决这个神经网络中的参数数量，有人可以确认我是否正确吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77663109/i-am-trying-to-solve-the-number-of-parameters-in-this-neural-network-can-anybod</link>
      <description><![CDATA[假设有 3 个输入数值预测变量。对于两个隐藏层的神经网络，第一个隐藏层有 10 个单元，第二个隐藏层有 5 个单元，那么该神经网络有多少个参数？
3 个输入数值预测变量
第一个隐藏层有 10 个单元
第二隐藏层 5 个单元
层间连接的参数个数如下：
从输入到第一个隐藏层的连接：
重量：
3×10 = 30
偏见：
10
从第一隐藏层到第二隐藏层的连接：
重量：
10×5=50
偏见：
5
从第二隐藏层到输出层的连接（假设单个输出）：
重量：
5×1=5
偏见：
1
因此，我相信，神经网络中的参数总数就是权重和偏差的总和：
30+10+50+5+1=96]]></description>
      <guid>https://stackoverflow.com/questions/77663109/i-am-trying-to-solve-the-number-of-parameters-in-this-neural-network-can-anybod</guid>
      <pubDate>Thu, 14 Dec 2023 21:17:47 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在不屏蔽整个时间步长的情况下屏蔽训练数据集中的某些值？</title>
      <link>https://stackoverflow.com/questions/77663094/is-there-a-way-to-mask-certain-values-in-a-training-dataset-without-masking-enti</link>
      <description><![CDATA[我正在尝试使用张量流训练一些变压器模型。在我的数据集中，每个时间步长都有多个值（X1，X2，X3）。不幸的是，其中一个输入是稀疏的（X3）。因此，我有 X1 和 X2 的每个时间步长的值，但我只有大约百分之一的 X3 值。
我想训练我的 Transformer 模型，使其能够预测 X1、X2 和 X3，并且我希望以与 X1 和 X2 中的数据相同的采样率进行训练。
有没有一种方法可以只屏蔽缺失的 X3 值，而不屏蔽整个时间步长？或者另一种方法来处理 X3 数据的稀疏性，同时保持 X1 和 X2 的采样率？
目前，我一直在研究使用 keras 嵌入层进行掩蔽，但我意识到这种掩蔽方式会掩盖每个缺失的 X3 值的整个时间步长。我希望它会忽略缺失的值而不忽略整个时间步，但事实并非如此。
我还尝试对我的 X3 数据进行线性插值，以便每个时间步都有一个值，但即使我能够制作非稀疏 X3 数据，X3 数据的噪声本质还是由经过训练的变压器产生的结果插值 X3 非常不可靠。]]></description>
      <guid>https://stackoverflow.com/questions/77663094/is-there-a-way-to-mask-certain-values-in-a-training-dataset-without-masking-enti</guid>
      <pubDate>Thu, 14 Dec 2023 21:14:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras/Tensorflow 约束神经网络损失函数</title>
      <link>https://stackoverflow.com/questions/77662709/constraint-a-neural-network-loss-function-with-keras-tensorflow</link>
      <description><![CDATA[我想创建一个具有多变量结果的神经网络来预测单变量目标。损失函数是指向目标的每个网络结果的均方根之和。我想施加一个正交约束，即每个网络结果必须与所有其他网络结果和目标变量之间的误差正交。我构建了一个自定义损失函数（具有两个网络结果的示例：
def custom_loss(y_true, y_pred):
    # 每个结果的均方误差
    mse1 = tf.keras.losses.mean_squared_error(y_true, y_pred[0])
    mse2 = tf.keras.losses.mean_squared_error(y_true, y_pred[1])

    ortho_loss = K.mean( (y_pred[1] - K.mean(y_pred[1])) * ((y_pred[0] - y_true) - K.mean(y_pred[0] - y_true)) )

    ＃ 总体损耗
    总损失 = mse1 + mse2 + K.mean(1*tf.keras.activations.relu(ortho_loss - 0)) + K.mean(1*tf.keras.activations.relu(-ortho_loss + 0))

    返回总损失

但它没有提供令人满意的结果。如果这可行的话有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77662709/constraint-a-neural-network-loss-function-with-keras-tensorflow</guid>
      <pubDate>Thu, 14 Dec 2023 19:48:13 GMT</pubDate>
    </item>
    <item>
      <title>决策树中的成本复杂性修剪</title>
      <link>https://stackoverflow.com/questions/77662692/cost-complexity-pruning-in-decision-tree</link>
      <description><![CDATA[修剪
在决策尝试的背景下，特别是在成本复杂性修剪中，在下面的演示中（如图所示），我不明白为什么我们用 R(t 替换 R(T−Tt) − R(T) )−R(Tt) 以及为什么我们替换 |f(T−Tt)| - |f(T)| 1 − |f(Tt)|]]></description>
      <guid>https://stackoverflow.com/questions/77662692/cost-complexity-pruning-in-decision-tree</guid>
      <pubDate>Thu, 14 Dec 2023 19:45:36 GMT</pubDate>
    </item>
    <item>
      <title>提高 Keras 中预测比特币价格趋势的 LSTM 模型准确性 [关闭]</title>
      <link>https://stackoverflow.com/questions/77662382/improving-lstm-model-accuracy-for-predicting-bitcoin-price-trends-in-keras</link>
      <description><![CDATA[我正在 Keras 中使用 LSTM（长短期记忆）模型来预测比特币价格的趋势。然而，我正在努力解决模型的准确性，尽管尝试了各种超参数，但似乎无法提高它。
这是我的模型的结构：
从 keras.models 导入顺序
从 keras.layers 导入 LSTM，密集

模型=顺序（）
model.add(LSTM(50, 激活=&#39;relu&#39;, input_shape=(n_steps, n_features)))
model.add(密集(1))
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)

# n_steps和n_features是根据历史比特币价格数据定义的

我使用历史比特币价格数据（在 0 和 1 之间标准化）进行训练。
尽管尝试了不同数量的神经元、添加层并尝试各种激活函数，但模型的损失并未按预期减少，并且对价格趋势的预测也不准确。
我想知道在我为预测比特币价格趋势的特定应用构建 LSTM 的方式中是否缺少一些基本的东西。这可能是我预处理数据的方式有问题，还是有更适合这种时间序列预测的模型架构或超参数集？
对于提高模型的准确性或调试此性能问题有什么建议或建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77662382/improving-lstm-model-accuracy-for-predicting-bitcoin-price-trends-in-keras</guid>
      <pubDate>Thu, 14 Dec 2023 18:34:02 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中面临的困难[关闭]</title>
      <link>https://stackoverflow.com/questions/77661689/facing-difficulty-in-ml</link>
      <description><![CDATA[请帮助我，我在机器学习概念方面遇到困难
希望这个社区的人们能够支持
请帮助我，我在 ML 概念方面遇到困难
希望这个社区的人们能够支持
请帮助我，我在 ML 概念方面遇到困难
期望这个社区的人们支持]]></description>
      <guid>https://stackoverflow.com/questions/77661689/facing-difficulty-in-ml</guid>
      <pubDate>Thu, 14 Dec 2023 16:32:46 GMT</pubDate>
    </item>
    <item>
      <title>获取构建轮子的要求...错误</title>
      <link>https://stackoverflow.com/questions/77661546/getting-requirements-to-build-wheel-error</link>
      <description><![CDATA[我正在尝试安装这个：
https://huggingface.co/microsoft/speecht5_tts
我成功地成功了（费了很大的劲才安装了变压器库）。
但现在当我运行这个命令时：
pip install --upgrade Transformers Sentpiece 数据集[音频]

我收到此错误：
收集句子
  使用缓存的 Sentpiece-0.1.99.tar.gz (2.6 MB)
  安装构建依赖项...完成
  **获取构建轮子的要求...错误**
  错误：子进程退出并出现错误
  
  × 获取构建 Wheel 的需求未成功运行。
  │ 退出代码：1
  ╰─&gt; [31行输出]
      回溯（最近一次调用最后一次）：
        文件“C:\Projects\TerrainGenerator\My project\Assets\StreamingAssets\python\.venv\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 353 行，在  中
          主要的（）
        文件“C:\Projects\TerrainGenerator\My project\Assets\StreamingAssets\python\.venv\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 335 行，在 main 中
          json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Projects\TerrainGenerator\My project\Assets\StreamingAssets\python\.venv\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 118 行，位于 get_requires_for_build_wheel
          返回钩子（config_settings）
                 ^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 325 行，在 get_requires_for_build_wheel 中
          返回 self._get_build_requires(config_settings, requests=[&#39;wheel&#39;])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 295 行，位于 _get_build_requires 中
          self.run_setup()
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 480 行，在 run_setup 中
          超级（_BuildMetaLegacyBackend，自我）.run_setup（setup_script = setup_script）
        文件“C:\Users\Bart\AppData\Local\Temp\pip-build-env-x7n10pf4\overlay\Lib\site-packages\setuptools\build_meta.py”，第 311 行，在 run_setup 中
          执行（代码，局部变量（））
        文件“”，第 126 行，在  中。
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 408 行，在 check_call 中
          retcode = 调用(*popenargs, **kwargs)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 389 行，调用中
          将 Popen(*popenargs, **kwargs) 作为 p：
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 1026 行，位于 __init__ 中
          self._execute_child(args, 可执行文件, preexec_fn, close_fds,
        文件“C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.496.0_x64__qbz5n2kfra8p0\Lib\subprocess.py”，第 1538 行，位于 _execute_child
          hp, ht, pid, tid = _winapi.CreateProcess(可执行文件, args,
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
      FileNotFoundError: [WinError 2] 系统找不到指定的文件
      [输出结束]

  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：子进程退出并出现错误

我使用以下命令安装了wheel：pip installwheel，它表示成功。
我正在 Windows 上的 VS Code 中尝试。]]></description>
      <guid>https://stackoverflow.com/questions/77661546/getting-requirements-to-build-wheel-error</guid>
      <pubDate>Thu, 14 Dec 2023 16:10:36 GMT</pubDate>
    </item>
    <item>
      <title>使用 Marqo 进行矢量搜索的单个或多个键值对数据结构？</title>
      <link>https://stackoverflow.com/questions/77657071/single-or-multiple-key-value-pair-data-structure-for-vector-search-with-marqo</link>
      <description><![CDATA[我正在使用 Marqo Cloud 为工作项目实施矢量搜索。我的文档（产品）有一些数据，其结构可以如下：
单个键值对，例如：标签：红色、斑点、尼龙、休闲
或者每个标签标题包含多个键值对，例如：
红色
设计：斑点
材质: 尼龙
风格：休闲
在矢量搜索中，这些数据结构中的一种会比另一种表现得更好吗？或者差异可能可以忽略不计？]]></description>
      <guid>https://stackoverflow.com/questions/77657071/single-or-multiple-key-value-pair-data-structure-for-vector-search-with-marqo</guid>
      <pubDate>Wed, 13 Dec 2023 23:34:17 GMT</pubDate>
    </item>
    <item>
      <title>模块“numpy”没有属性“MachAr”？</title>
      <link>https://stackoverflow.com/questions/75371176/module-numpy-has-no-attribute-machar</link>
      <description><![CDATA[我有一个问题。当我从“statsmodels.stats.outliers_influence”导入“variance_inflation_factor”时，出现“模块“numpy”没有属性“MachAr””错误，原因是什么？
我曾经在一个项目中执行过这段代码，它运行没有任何问题，但它在后续项目中给出了这个错误]]></description>
      <guid>https://stackoverflow.com/questions/75371176/module-numpy-has-no-attribute-machar</guid>
      <pubDate>Tue, 07 Feb 2023 09:17:47 GMT</pubDate>
    </item>
    <item>
      <title>惰性预测.监督.惰性分类器。 ImportError：无法从“sklearn.utils.deprecation”导入名称“_raise_dep_warning_if_not_pytest”</title>
      <link>https://stackoverflow.com/questions/67305004/lazypredict-supervised-lazyclassifier-importerror-cannot-import-name-raise-d</link>
      <description><![CDATA[我尝试过：
from lazypredict.Supervised import LazyClassifier

但得到以下回溯：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-1-f518cae57501&gt;在&lt;模块&gt;中
     10 从sklearn.linear_model导入LogisticRegression
     11 从 sklearn.ensemble 导入 RandomForestClassifier
---&gt; 12 从lazypredict.Supervised导入LazyClassifier
     13 从sklearn.model_selection导入GridSearchCV
     14 从sklearn.metrics导入accuracy_score

 中的 ~\AppData\Roaming\Python\Python38\site-packages\lazypredict\Supervised.py
     14 从sklearn.preprocessing导入StandardScaler、OneHotEncoder、OrdinalEncoder
     15 从 sklearn.compose 导入 ColumnTransformer
---&gt; 16 从 sklearn.utils.testing 导入 all_estimators
     17 从 sklearn.base 导入 RegressorMixin
     18 从sklearn.base导入ClassifierMixin

S:\anaconda\lib\site-packages\sklearn\utils\testing.py 在  中
      5 来自 . import _testing # 类型：忽略
      6 从 ..externals._pep562 导入 Pep562
----&gt; 7 从 ..utils.deprecation 导入 _raise_dep_warning_if_not_pytest
      8
      9 deprecated_pa​​th = &#39;sklearn.utils.testing&#39;

ImportError：无法从“sklearn.utils.deprecation”导入名称“_raise_dep_warning_if_not_pytest”（S：\ anaconda \ lib \ site-packages \ sklearn \ utils \ deprecation.py）

我当时在 Jupyter 笔记本中工作，并且也已经尝试升级 scikit-learn。]]></description>
      <guid>https://stackoverflow.com/questions/67305004/lazypredict-supervised-lazyclassifier-importerror-cannot-import-name-raise-d</guid>
      <pubDate>Wed, 28 Apr 2021 17:22:07 GMT</pubDate>
    </item>
    <item>
      <title>对于相同的损失函数和优化器，L1 或 L2 正则化是否给出最稀疏的权重？</title>
      <link>https://stackoverflow.com/questions/57967899/does-l1-or-l2-regularization-give-the-most-sparse-weights-for-the-same-loss-func</link>
      <description><![CDATA[如果我考虑一个数据集，对于相同的损失函数和相同的优化器，哪种正则化技术（L1 正则化或 L2 正则化）会输出最高的稀疏权重？]]></description>
      <guid>https://stackoverflow.com/questions/57967899/does-l1-or-l2-regularization-give-the-most-sparse-weights-for-the-same-loss-func</guid>
      <pubDate>Tue, 17 Sep 2019 05:35:08 GMT</pubDate>
    </item>
    </channel>
</rss>