<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 28 Mar 2024 06:18:21 GMT</lastBuildDate>
    <item>
      <title>张量流误差处理算法，对抗性去偏，基于 tf</title>
      <link>https://stackoverflow.com/questions/78235779/tensorflow-error-with-in-processing-algorithm-adversarial-debiasing-which-is-b</link>
      <description><![CDATA[我正在使用来自 AIF360 的对抗性去偏模型，该模型使用 TensorFlow。我收到错误：ValueError：变量 debiased_classifier_20710/classifier_model/W1 已存在，不允许。您的意思是在 VarScope 中设置reuse=True 或reuse=tf.AUTO_REUSE 吗？我不确定如何处理此错误，因为我没有在代码中直接使用 TensorFlow，我只是导入 TensorFlow 作为模型工作的基础。任何线索都会有帮助。 
下面是我遇到的部分代码和错误：
sess = tf.Session()
debiased_model = AdversarialDebiasing(privileged_groups =privileged_groups, unprivileged_groups = unprivileged_groups,scope_name = f&#39;debiased_classifier_{int(np.random.random()*100000)}&#39;, debias = True, sess = sess)
model = debiased_model.fit(train_df)
文件“python3.10/site-packages/aif360/algorithms/transformer.py”，第 27 行，包装器
new_dataset = func(self, *args, **kwargs)
文件“python3.10/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py”，第152行，适合
self.pred_labels, pred_logits = self._classifier_model(self.features_ph, self.features_dim, self.keep_prob)
文件“python3.10/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py”，第 84 行，在 _classifier_model
W1 = tf.get_variable(&#39;W1&#39;, [features_dim, self.classifier_num_hidden_​​units],
文件“python3.10/site-packages/tensorflow/python/ops/variable_scope.py”，第 1616 行，get_variable
返回 get_variable_scope().get_variable(
文件“python3.10/site-packages/tensorflow/python/ops/variable_scope.py”，第 1326 行，get_variable
return var_store.get_variable(
文件“python3.10/site-packages/tensorflow/python/ops/variable_scope.py”，第 582 行，get_variable
返回_true_getter(
文件“python3.10/site-packages/tensorflow/python/ops/variable_scope.py”，第 535 行，在 _true_getter
返回 self._get_single_variable(
文件“python3.10/site-packages/tensorflow/python/ops/variable_scope.py”，第 891 行，在 _get_single_variable
引发 ValueError(err_msg)
ValueError：变量 debiased_classifier_20710/classifier_model/W1 已存在，不允许。您的意思是在 VarScope 中设置reuse=True 或reuse=tf.AUTO_REUSE 吗？
我尝试研究处理此问题的方法，但当模型在后端使用 TensorFlow 时，没有一种方法可以处理此错误。]]></description>
      <guid>https://stackoverflow.com/questions/78235779/tensorflow-error-with-in-processing-algorithm-adversarial-debiasing-which-is-b</guid>
      <pubDate>Thu, 28 Mar 2024 03:57:15 GMT</pubDate>
    </item>
    <item>
      <title>当运行自定义训练循环时，GradientTape 返回 None</title>
      <link>https://stackoverflow.com/questions/78235457/gradienttape-returns-none-when-run-through-custom-training-loop</link>
      <description><![CDATA[我在自定义训练循环中使用 tf.GradientTape 来根据来自望远镜的一些时间序列数据训练模型。我正在使用 keras 优化器和损失函数：keras.optimizers.Adam 和keras.losses.MeanSquaredError。我有两个训练循环，一个有效，第二个 train_sequential 不起作用，因为 tape.gradient(loss, model.trainable_variables) 返回 None 梯度。
导入keras
将 numpy 导入为 np
将 pandas 导入为 pd
将张量流导入为 tf

loss_function = keras.losses.MeanSquaredError()
优化器 = keras.optimizers.Adam(learning_rate=0.001)

def train_traditional(模型:keras.models.Sequential,
                      训练数据：pd.DataFrame，
                      验证数据：pd.DataFrame，
                      序列长度：int，
                      标题，
                      纪元=1):
    # 合并数据
    数据 = pd.concat([训练数据, 验证数据])
    # 提取特征和目标
    特征=数据[标题].值
    目标=数据[标头].shift(-sequence_length).values
    # 删除不完整的序列
    num_sequences = len(特征) - 序列长度
    特征 = 特征[:num_sequences]
    目标 = 目标[:num_sequences]
    # 训练循环
    对于范围内的纪元（纪元）：
        # 打乱数据
        索引 = np.random.permutation(num_sequences)
        features_shuffled = 特征[索引]
        Targets_shuffled = 目标[索引]
        # 小批量训练
        损失=[]
        对于范围内的 i（0、num_sequences、sequence_length）：
            batch_features = features_shuffled[i:i+sequence_length]
            batch_targets = Targets_shuffled[i:i+sequence_length]
            # 前向传递
            使用 tf.GradientTape() 作为磁带：
                model_input = np.expand_dims(batch_features, axis=0)
                预测=模型（model_input）
                损失 = loss_function(batch_targets, 预测)
                损失.追加（损失.numpy（））
            # 反向传播
            梯度 = Tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(zip(梯度, model.trainable_variables))
        print(f&#39;Epoch {epoch + 1}/{epochs}: 步骤 {num_sequences}: 损失 = {np.average(losses)}&#39;)
        损失.clear()
    print(&#39;训练结束。&#39;)

def train_sequential(模型:keras.models.Sequential,
                     训练数据：pd.DataFrame，
                     验证数据：pd.DataFrame，
                     纪元=10）：
    tf.debugging.enable_check_numerics()
    # 训练循环
    对于范围内的纪元（纪元）：
        # 前向传递
        使用 tf.GradientTape() 作为磁带：
            预测序列=生成预测序列（模型，训练数据）
            损失=损失函数（验证数据，预测序列）
            val = Tape.gradient(loss, model.trainable_variables)
            对于 val 中的 v：
                打印（五）
            print(f&quot;损失: {loss}&quot;)
        # 反向传播
        梯度 = val
        对于 model.layers 中的图层：
            打印（层.trainable_variables）
        print(f&#39;渐变: {渐变}&#39;)
        optimizer.apply_gradients(zip(梯度, model.trainable_variables))
        print(f&#39;Epoch {epoch + 1}/{epochs}: 损失: {loss.numpy()}&#39;)
    print(&#39;训练结束。&#39;)

defgenerate_predicted_sequence（模型，input_data）：
    预测序列 = 输入数据
    对于范围内的 i(len(预测序列))：
        模型输入 = 预测序列
        model_input = np.reshape(model_input, (1, 15, 4))
        结果=模型（模型输入）
        Predicted_sequence = np.vstack((predicted_sequence[1:], 结果))
    返回预测序列

training_data 和 validation_data 都是 pandas DataFrame，具有相同的行数和日期时间索引。我确信在我的序列生成中的某个地方我搞乱了 GradientTape 的一些东西，因为相同的数据在传统的训练循环中运行时工作得很好。以下是我使用的模型：
输入形状：（无、15、4）
模型：“SimpleLSTM15”
┏──────────────────────────────────────────────────────────────────────────┳──────────────────────────────────────────────────────────────────── ──────────────────────────────────────┳────────────────────────────┓
┃ 层（类型） ┃ 输出形状 ┃ 参数# ┃
┡────────────────────────────────────────────────────────────────────────────╇──────────────────── ────────────────────────────────────╇──────────────────────────┩
│ lstm (LSTM) │ （无，64） │ 17,664 │
├────────────────────────────────────┼──────────── ────────────────────┼──────────────┤
│密集_8（密集）│（无，4）│260 │
└────────────────────────────────────┴──────────── ────────────────────┴──────────────┘
 总参数：17,924 (70.02 KB)
 可训练参数：17,924 (70.02 KB)
 不可训练参数：0 (0.00 B)
]]></description>
      <guid>https://stackoverflow.com/questions/78235457/gradienttape-returns-none-when-run-through-custom-training-loop</guid>
      <pubDate>Thu, 28 Mar 2024 01:46:46 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 理解样本、时间步长和特征 [关闭]</title>
      <link>https://stackoverflow.com/questions/78235324/lstm-understanding-samples-timesteps-and-features</link>
      <description><![CDATA[在实现美国各地天气预报的 LSTM 模型的任务中，数据集由网格二维数组组成，其中包含温度和压力等九个不同的变量。每个小时快照由100个文件表示，每个文件包含2000个点的数据，每个点对应一个特定的地理位置。
我的问题是，在这种情况下我的样本、时间步长和特征是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78235324/lstm-understanding-samples-timesteps-and-features</guid>
      <pubDate>Thu, 28 Mar 2024 00:52:19 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中自定义 FISTA 优化器和模型状态回滚的问题</title>
      <link>https://stackoverflow.com/questions/78235073/issues-with-custom-fista-optimizer-and-model-state-rollback-in-pytorch</link>
      <description><![CDATA[我在 PyTorch 中为我正在从事的项目开发了一个自定义 FISTA（快速迭代收缩阈值算法）优化器。优化器在正常情况下工作得很好。但是，我在训练期间尝试将模型参数回滚到之前的状态时遇到了问题。
&lt;前&gt;&lt;代码&gt;
进口火炬

将 torch.nn 导入为 nn



FISTA 类（torch.optim.Optimizer）：

    def __init__(self, params, lr, lambda_):

        如果 lr &lt; 0.0：

            raise ValueError(f“无效学习率：{lr} - 应该 &gt;= 0.0”)

        如果 lambda_ &lt; 0.0：

            raise ValueError(f“无效的 lambda：{lambda_} - 应该 &gt;= 0.0”)

        

        默认值 = dict(lr=lr, lambda_=lambda_)

        super(FISTA, self).__init__(参数, 默认值)

    

    defrinkage_operator(self, u, tresh):

        return torch.sign(u) * torch.maximum(torch.abs(u) - tresh, torch.tensor(0.0, device=u.device))



    def 步骤（自我，闭包=无）：

        损失=无

        如果闭包不是 None：

            使用 torch.enable_grad()：

                损失=关闭（）



        对于 self.param_groups 中的组：

            对于组 [&#39;params&#39;] 中的 p：

                如果 p.grad 为 None：

                    继续



                grad = p.grad.data

                lr = 组[&#39;lr&#39;]

                lambda_ = 组[&#39;lambda_&#39;]

                状态 = self.state[p]

                

                # 状态初始化

                如果 len(状态) == 0:

                    状态 = self.state[p]

                    状态[&#39;x_prev&#39;] = p.data

                    状态[&#39;y_prev&#39;] = p.data.clone()

                    state[&#39;t_prev&#39;] = torch.tensor(1., device=p.device)



                x_prev, y_prev, t_prev = 状态[&#39;x_prev&#39;], 状态[&#39;y_prev&#39;], 状态[&#39;t_prev&#39;]



                x_next = self.shrinkage_operator(y_prev - lr * grad, lambda_)

                t_next = (1. + torch.sqrt(1. + 4. * t_prev ** 2)) / 2.

                y_next = x_next + ((t_prev - 1) / t_next) * (x_next - x_prev)



                状态[&#39;x_prev&#39;]，状态[&#39;y_prev&#39;]，状态[&#39;t_prev&#39;] = x_next，y_next，t_next



                p.data.copy_(x_next)



        回波损耗


然后在我的模型训练循环中使用该优化器：
&lt;前&gt;&lt;代码&gt;
Optimizer_penalized = FISTA(params=layer1.parameters(), lambda_=lambda_, lr=lr)

Optimizer_unpenalized = FISTA(params=layer2.parameters(), lambda_=0.0, lr=lr)


我需要其中两个，因为我只想缩小模型的第一层。现在，这个优化器工作得很好，直到我修改了第 1 层和第 2 层。假设我训练我的模型，并在每个时期创建较低的成本值，我像这样保存层：
&lt;前&gt;&lt;代码&gt;
Layer1_before_dict =（layer1.weight.data.clone（）.detach（），layer1.bias.data.clone（）.detach（））

Layer2_before_dict =（layer2.weight.data.clone（）.detach（），layer2.bias.data.clone（）.detach（））


当一个纪元增加成本时，我改变学习率并调用
&lt;前&gt;&lt;代码&gt;
使用 torch.no_grad()：

                layer1.weight.copy_(layer1_before_dict[0])

                layer1.bias.copy_(layer1_before_dict[1])

                Layer2.weight.copy_(layer2_before_dict[0])

                Layer2.bias.copy_(layer2_before_dict[1])


问题出现在这里：回滚层参数后，更改似乎没有反映在优化器的内部状态中。模型层具有正确的值，但调用优化器步骤方法不会返回预期值。
每次损失增加时，我都尝试重新创建优化器，但这也不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78235073/issues-with-custom-fista-optimizer-and-model-state-rollback-in-pytorch</guid>
      <pubDate>Wed, 27 Mar 2024 23:12:27 GMT</pubDate>
    </item>
    <item>
      <title>年龄范围以数值进行计算 CD 消费量与年龄范围的相关性</title>
      <link>https://stackoverflow.com/questions/78234946/age-range-to-numerical-values-to-calcutate-correlation-of-cd-consumption-with-ag</link>
      <description><![CDATA[我确实对值进行了排序。但问题是&#39;до 25&#39;（最多25）。如何将其更改为“0-25”并计算年龄组与总体评分的相关系数。
我的一些数据如下

&lt;标题&gt;

年龄组
总体评分


&lt;正文&gt;

65 岁及以上
38.45


55-64
17.66


最多 25
46.56


45-54
24.95


35-44
33.54


25-34
37.21


]]></description>
      <guid>https://stackoverflow.com/questions/78234946/age-range-to-numerical-values-to-calcutate-correlation-of-cd-consumption-with-ag</guid>
      <pubDate>Wed, 27 Mar 2024 22:36:35 GMT</pubDate>
    </item>
    <item>
      <title>我使用的 KNN 模型总是以 100% 的准确率返回，但事实并非如此</title>
      <link>https://stackoverflow.com/questions/78234777/the-knn-model-i-am-using-is-always-coming-back-at-100-accuracy-but-it-shouldnt</link>
      <description><![CDATA[我刚刚进入机器学习领域，正在研究使用分类模型。目前我正在使用蘑菇分类数据集（类别是有毒的或可食用的）。问题是，虽然我实际上遵循的是我看到其他人所做的最基本的可能程序，但我的模型只返回完美的分类。这是我用来创建模型的代码。
模型 = KNeighborsClassifier(n_neighbors = 5)
    model.fit(X_train, y_train)
    y_preds = model.predict(X_test)
    分数 = 准确度_分数(y_test, y_preds)

这会返回 1.0 的准确度分数，一个完全没有混淆的混淆矩阵（100% 正确的预测值），并且如果我更改 k 数或测试大小，这不会改变。即使将其设置为 50%，结果也是一样。
我已尽我所能清理数据，并且数据完全是一次性编码的。我想这可能会产生影响，但我不确定。下面是我用来准备数据的代码。首先，我填充了缺失值，然后编码了序数数据。任何意见都将受到赞赏！
&lt;代码&gt;
    qmarks = df.loc[df[&#39;Stalk Root&#39;].str.contains(&#39;\?&#39;)] # nan 值是？这里
mode = df[&#39;Stalk Root&#39;].mode() #最常见的答案是 b
df_enc = df.replace(&#39;?&#39;, &#39;b&#39;) #用最常见的值替换所有问号

df_enc[&#39;环号&#39;] = df_enc[&#39;环号&#39;].replace({&#39;n&#39;: 0, &#39;o&#39;: 1, &#39;t&#39;: 2}).astype(int)
df_enc[&#39;鳃间距&#39;] = df_enc[&#39;鳃间距&#39;].replace({&#39;c&#39;: 0, &#39;w&#39;: 1, &#39;d&#39;: 2}).astype(int)
df[&#39;有毒&#39;] = (df[&#39;有毒&#39;] == &#39;p&#39;).astype(int)
df_enc = pd.get_dummies(df)


然后我分割数据，如下所示：
&lt;代码&gt;
    y= df.iloc[:, 0:1]
    X= df.iloc[:, 2:-1]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle= True)



我尝试过更改很多变量，但这并不是第一个对我进行此操作的数据集。不久前，在不同数据集上的线性回归模型发生了这种情况，我也无法弄清楚那里出了什么问题。我可以想象数据编码、训练测试分割或用户错误有问题，但我不知道如何修复它。然而，我确信数据被准确地分割，在训练和测试分割中并不相同，并且数据集的每个类别的分布相对均匀。请帮忙！
编辑：添加数据准备代码]]></description>
      <guid>https://stackoverflow.com/questions/78234777/the-knn-model-i-am-using-is-always-coming-back-at-100-accuracy-but-it-shouldnt</guid>
      <pubDate>Wed, 27 Mar 2024 21:48:38 GMT</pubDate>
    </item>
    <item>
      <title>导入 ARMA 时出现 NotImplementedError</title>
      <link>https://stackoverflow.com/questions/78234689/getting-notimplementederror-while-importing-arma</link>
      <description><![CDATA[这是错误消息
(https://i.stack.imgur.com/rPZbu.png)&lt; /p&gt;
当然有一种方法可以导入它......当尝试使用（statsmodels.tsa.arima.model.ARIMA）时，它只给我ARIMA......它是否从statsmodels移动到另一个库或什么以及我应该如何导入它吗？]]></description>
      <guid>https://stackoverflow.com/questions/78234689/getting-notimplementederror-while-importing-arma</guid>
      <pubDate>Wed, 27 Mar 2024 21:28:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么删除 Chunksize 时会出现错误？</title>
      <link>https://stackoverflow.com/questions/78234289/why-do-i-get-an-error-when-i-remove-chunksize</link>
      <description><![CDATA[我在运行 Python 代码时遇到错误，需要帮助来解决该错误。以下是详细信息：
导入 pandas 作为 pd

df_列表 = []
file_path = &#39;houses.txt&#39;

for chunk in pd.read_csv(file_path, chunksize=1000000, names=[&#39;Size()sqft&#39;, &#39;卧室数量&#39;, &#39;楼层数量&#39;, &#39;房屋年龄&#39;, &#39;价格(1000美元)&#39;]) :
    df_list.append(块)

df = pd.concat(df_list)

打印（df_列表）


输出：
&lt;前&gt;&lt;代码&gt;0 952.0 2.0 1.0 65.0 271.5
1 1244.0 3.0 1.0 64.0 300.0
2 1947.0 3.0 2.0 17.0 509.8
3 1725.0 3.0 2.0 42.0 394.0
4 1959.0 3.0 2.0 15.0 540.0
……………………
95 1224.0 2.0 2.0 12.0 329.0
96 1432.0 2.0 1.0 43.0 388.0
97 1660.0 3.0 2.0 19.0 390.0
98 1212.0 3.0 1.0 20.0 356.0
99 1050.0 2.0 1.0 65.0 257.8

[100 行 x 5 列]]

删除“chunksize”后。我收到此错误：
类型错误：无法连接“”类型的对象；仅 Series 和 DataFrame 对象有效
请解释一下问题所在]]></description>
      <guid>https://stackoverflow.com/questions/78234289/why-do-i-get-an-error-when-i-remove-chunksize</guid>
      <pubDate>Wed, 27 Mar 2024 20:03:32 GMT</pubDate>
    </item>
    <item>
      <title>评估模型时出错：分类指标无法处理二进制目标和连续目标的混合</title>
      <link>https://stackoverflow.com/questions/78234279/error-when-evaluating-models-classification-metrics-cant-handle-a-mix-of-binar</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78234279/error-when-evaluating-models-classification-metrics-cant-handle-a-mix-of-binar</guid>
      <pubDate>Wed, 27 Mar 2024 20:00:54 GMT</pubDate>
    </item>
    <item>
      <title>LSTM：PyTorch Lightning 中的 Predict_step</title>
      <link>https://stackoverflow.com/questions/78233789/lstm-predict-step-in-pytorch-lightning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78233789/lstm-predict-step-in-pytorch-lightning</guid>
      <pubDate>Wed, 27 Mar 2024 18:21:26 GMT</pubDate>
    </item>
    <item>
      <title>正态贝叶斯分类</title>
      <link>https://stackoverflow.com/questions/78233586/normal-bayes-classification</link>
      <description><![CDATA[请帮助我。我是机器学习初学者。如何使用不同类型的协方差矩阵建议来训练普通贝叶斯分类器？
我有一个任务：训练普通贝叶斯分类器：

评估不同类的协方差矩阵，如果它们是 a) 相等、对角 b) 不同标量等
计算经过训练的贝叶斯分类器的分类点 a、b...
显示课程区域

我在 python 上做，但我不明白除了 GaussianNB() 之外我还能做什么。据我所知，这个函数在不检查任何类型的矩阵的情况下建立模型。请帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78233586/normal-bayes-classification</guid>
      <pubDate>Wed, 27 Mar 2024 17:33:47 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tfidfvectorizer 的功能从英语修改为西班牙语</title>
      <link>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</link>
      <description><![CDATA[我有一个 tfidfvectorizer，它适合英语文本数据来预测英语通话的情绪。任务是将其转换为西班牙语。我想使用此 tfidfvectorizers 的权重，并希望将功能从英语转换为西班牙语，例如“谢谢”变成“gracias”并使用旧的权重。所以本质上我想使用相同的 tfidf 矢量器，但修改了特征名称。有人可以建议一些方法在 Python 中做到这一点吗？
编辑：我已经将功能从英语转换为西班牙语，并在英语文本上训练了 tfidf。我需要一种使用旧权重和新功能构建 tfidf 的方法，而不使用 fit 函数或将所有文本转换为西班牙语。
带有解决方案的代码。]]></description>
      <guid>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</guid>
      <pubDate>Wed, 27 Mar 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>使用隔离森林进行异常检测[关闭]</title>
      <link>https://stackoverflow.com/questions/78232159/anomaly-detection-with-isolation-forest</link>
      <description><![CDATA[我有车辆数据。该数据是在会议中测量的。我在数据框中有一列显示测量会话 ID。在“时间”列中，时间每 200 毫秒累加一次。测量的块具有不同的长度。有些是 600000 毫秒长，有些是 400000 毫秒长。如果 id 发生变化，时间列会再次从 0 开始计数。我现在的问题是，我如何向隔离森林教授这一点，或者我如何准备数据和列，以便隔离森林考虑到这一点？我真的需要尽快得到一个好的答案。非常感谢
我没有任何想法。 Time 列也只是 float64 的类型，它不是日期时间对象。]]></description>
      <guid>https://stackoverflow.com/questions/78232159/anomaly-detection-with-isolation-forest</guid>
      <pubDate>Wed, 27 Mar 2024 13:45:39 GMT</pubDate>
    </item>
    <item>
      <title>我在尝试为 Mac 终端安装 PIP3 时遇到问题</title>
      <link>https://stackoverflow.com/questions/78228806/i-am-encountering-an-issue-in-trying-to-install-pip3-for-my-mac-terminal</link>
      <description><![CDATA[我成功安装了：
python3 -m pip install gluoncv

然后我成功安装了：
pip3 安装 virtualenv

但是当我尝试安装以下内容时，我遇到了问题 zsh: command not find: virtualenv：
virtualenv --python=/usr/bin/python2.7 python27

您建议采取什么补救措施？我的目标是安装 PIP 并通过 Xcode 使用 MLModel。我是一名初学者程序员，所以手握&amp;像我 5 岁一样跟我说话真是太感谢了！谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78228806/i-am-encountering-an-issue-in-trying-to-install-pip3-for-my-mac-terminal</guid>
      <pubDate>Wed, 27 Mar 2024 00:37:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 Conda + Poetry 有意义吗？</title>
      <link>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</link>
      <description><![CDATA[在机器学习项目中使用 Conda + Poetry 有意义吗？让我分享一下我（新手）的理解，请指正或赐教：
据我了解，Conda 和 Poetry 有不同的目的，但很大程度上是多余的：

Conda 主要是一个环境管理器（实际上不一定是 Python），但它也可以管理包和依赖项。
Poetry 主要是一个 Python 包管理器（例如，pip 的升级版），但它也可以创建和管理 Python 环境（例如，Pyenv 的升级版） .

我的想法是同时使用两者并划分它们的角色：让 Conda 担任环境管理器，让 Poetry 担任包管理器。我的推理是（听起来）Conda 最适合管理环境，可用于编译和安装非 python 包，尤其是 CUDA 驱动程序（用于 GPU 功能），而 Poetry 作为 Python 包管理器比 Conda 更强大。 
通过在 Conda 环境中使用 Poetry，我成功地相当轻松地完成了这项工作。诀窍是不使用 Poetry 来管理 Python 环境：我没有使用诸如 poetry shell 或 poetry run 这样的命令，只使用 poetry init 、poetry install 等（激活Conda环境后）。
为了充分披露，我的 environment.yml 文件（针对 Conda）如下所示：
&lt;前&gt;&lt;代码&gt;名称：N

渠道：
  - 默认值
  - 康达锻造

依赖项：
  - 蟒蛇=3.9
  -cuda工具包
  - 库德恩

我的poetry.toml文件看起来像这样：
&lt;前&gt;&lt;代码&gt;[工具.诗歌]
名称=“N”
作者 = [“B”]

[工具.诗歌.依赖项]
蟒蛇=“3.9”
火炬 =“^1.10.1”

[构建系统]
需要= [“诗歌核心&gt;=1.0.0”]
构建后端=“poetry.core.masonry.api”

说实话，我这样做的原因之一是我在没有 Conda 的情况下很难安装 CUDA（用于 GPU 支持）。
您认为这个项目设计合理吗？]]></description>
      <guid>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</guid>
      <pubDate>Tue, 25 Jan 2022 15:09:43 GMT</pubDate>
    </item>
    </channel>
</rss>