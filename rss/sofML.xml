<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 12 Aug 2024 15:17:50 GMT</lastBuildDate>
    <item>
      <title>访问 Azure 机器学习中计划的创建日期</title>
      <link>https://stackoverflow.com/questions/78862179/acessing-the-creation-date-of-a-schedule-in-azure-machine-learning</link>
      <description><![CDATA[我试图访问 AML 中计划的创建/定义日期。我尝试了文档和一些解决方法，但到目前为止还没有成功。如果可以访问端点或已发布管道的创建日期，那么它也会解决我的问题。有人知道我该怎么做吗？提前谢谢。
我已经尝试访问上述每个类的属性，但无法获取有关创建时间的信息。我唯一访问过的日期是与计划对象关联的运行日期。]]></description>
      <guid>https://stackoverflow.com/questions/78862179/acessing-the-creation-date-of-a-schedule-in-azure-machine-learning</guid>
      <pubDate>Mon, 12 Aug 2024 14:23:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 ImageDataGenerator 训练 CNN，第二次训练后失败</title>
      <link>https://stackoverflow.com/questions/78861705/training-a-cnn-using-imagedatagenerator-and-training-fails-after-the-2nd-epoch</link>
      <description><![CDATA[我使用 ImageDataGenerator 训练 CNN 时遇到了这个问题，在第二个 Epoch 之后出现了属性错误。
模型如下
模型
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop

def create_model():
&#39;&#39;&#39;创建一个具有 4 个卷积层的 CNN&#39;&#39;&#39;
model = tf.keras.models.Sequential([
tf.keras.layers.Conv2D(32, (3,3),activation=&#39;relu&#39;, input_shape=(150, 150, 3)),
tf.keras.layers.MaxPooling2D(2, 2),
tf.keras.layers.Conv2D(64, (3,3),activation=&#39;relu&#39;),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Conv2D(128, (3,3), 激活=&#39;relu&#39;),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Conv2D(128, (3,3), 激活=&#39;relu&#39;),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(512, 激活=&#39;relu&#39;),
tf.keras.layers.Dense(1, 激活=&#39;sigmoid&#39;)
])

model.compile(loss=&#39;binary_crossentropy&#39;,
optimizer=RMSprop(learning_rate=1e-4),
metrics=[&#39;accuracy&#39;])

返回模型

来自 tensorflow.keras.preprocessing.image 导入 ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
train_dir, # 这是训练图像的源目录
target_size=(150, 150), # 所有图像将调整为 150x150
batch_size=20,
# 由于我们使用 binary_crossentropy 损失，我们需要二进制标签
class_mode=&#39;binary&#39;)

validation_generator = test_datagen.flow_from_directory(
validation_dir,
target_size=(150, 150),
batch_size=20,
class_mode=&#39;binary&#39;,
shuffle= False)

EPOCHS = 20

model = create_model()

history = model.fit(
train_generator,
steps_per_epoch=100, # 2000 images = batch_size * steps
epochs=EPOCHS,
validation_data=validation_generator,
validation_steps=50, # 1000 images = batch_size * steps
verbose=2)

输出
AttributeError Traceback (最近一次调用最后一次)
Cell In[15]，第 8 行
5 model = create_model()
7 # 训练模型
----&gt; 8 history = model.fit(
9 train_generator,
10 steps_per_epoch=100, # 2000 图像 = batch_size * 步骤
11 epochs=EPOCHS,
12 validation_data=validation_generator,
13 validation_steps=50, # 1000 图像 = batch_size * 步骤
14 verbose=2)

文件 ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
-&gt; 122 从 None 中引发 e.with_traceback(filtered_tb)
123 最后：
124 delfiltered_tb

文件 ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras\src\backend\tensorflow\trainer.py:354，位于 TensorFlowTrainer.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)
333 self._eval_epoch_iterator = TFEpochIterator(
334 x=val_x,
335 y=val_y,
...
355 }
356 epoch_logs.update(val_logs)
358 callbacks.on_epoch_end(epoch, epoch_logs)

AttributeError: &#39;NoneType&#39; 对象没有属性 &#39;items&#39;

输出被截断。以可滚动元素形式查看或在文本编辑器中打开。调整单元格输出设置...

我尝试了以下调试步骤：

升级 Tensorflow 和 Keras
尝试更简单的神经网络，看看是否有相同的问题，但它运行良好。
没有将 validation_generator 传递给 model.fit()，而是使用 numpy 手动执行，但这也没有奏效，因为对于它来说，训练数据的准确性和错误在偶数个时期都为 0仅。

还检查了验证数据是否已正确加载。
Python 版本：3.11.9
Tensorflow 版本：2.17.0
Keras 版本：3.4.1]]></description>
      <guid>https://stackoverflow.com/questions/78861705/training-a-cnn-using-imagedatagenerator-and-training-fails-after-the-2nd-epoch</guid>
      <pubDate>Mon, 12 Aug 2024 12:33:51 GMT</pubDate>
    </item>
    <item>
      <title>使用相关的 Sagemaker HP 调整作业作为热启动父作业</title>
      <link>https://stackoverflow.com/questions/78861542/use-relevant-sagemaker-hp-tuning-jobs-as-warm-start-parent-jobs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78861542/use-relevant-sagemaker-hp-tuning-jobs-as-warm-start-parent-jobs</guid>
      <pubDate>Mon, 12 Aug 2024 11:58:24 GMT</pubDate>
    </item>
    <item>
      <title>Colab Pro 订阅问题 - 已收费但未订阅 [关闭]</title>
      <link>https://stackoverflow.com/questions/78860728/colab-pro-subscription-issue-charged-but-not-subscribed</link>
      <description><![CDATA[我于 8 月 10 日购买了 Google Colab Pro 订阅，但我的帐户仍显示为未订阅。虽然资源部分中的资源单元已更新，但我无法使用 Colab Pro，因为我的会话每 15 分钟就会崩溃一次。通过电子邮件联系 colab-billing@google.com 要求退款，但他们甚至没有回复。
购买了 Colab - Pro 订阅，但即使我已付款，也没有订阅。]]></description>
      <guid>https://stackoverflow.com/questions/78860728/colab-pro-subscription-issue-charged-but-not-subscribed</guid>
      <pubDate>Mon, 12 Aug 2024 08:45:37 GMT</pubDate>
    </item>
    <item>
      <title>我如何知道镜头中的某人是否对齐了轮廓？</title>
      <link>https://stackoverflow.com/questions/78860543/how-can-i-know-if-someone-in-camera-aligns-an-outline</link>
      <description><![CDATA[我正在做一个项目，这个项目与实时摄像头的身体测量有很大关系，但为了校准，我需要人站在屏幕中间，直接适应框架尺寸。为此，我使用了一个透明的人形，除了人形的边界外，其他地方都是透明的。我如何检查人是否符合轮廓？
我尝试在屏幕中间使用 png 并从中绘制轮廓并检查地标，但它总是最终检查一个绘制原始图像边界的正方形。而且，即使一个人站得很近，只用一半的身体来适应它，它也能正常工作。
效果很差。我该如何改进？
现在我的代码片段如下所示：
KadirCoordinates = {
&#39;NOSE&#39;: (320, 36),
&#39;LEFT_SHOULDER&#39;: (274, 100),
&#39;RIGHT_SHOULDER&#39;: (372, 104),
&#39;LEFT_HEEL&#39;: (296, 459),
&#39;RIGHT_HEEL&#39;: (343, 459)
}

points_to_collect = [&#39;NOSE&#39;, &#39;LEFT_SHOULDER&#39;, &#39;RIGHT_SHOULDER&#39;, &#39;LEFT_HEEL&#39;, &#39;RIGHT_HEEL&#39;] #臀部和脚踝处有血迹
current_point_index = 0

if result.pose_landmarks:
landmarks = result.pose_landmarks.landmark

detected_points = {}

for landmark in mp_pose.PoseLandmark:
x = int(landmarks[landmark].x * frame_width)
y = int(landmarks[landmark].y * frame_height)
if landmark.name in points_to_collect:
detected_points[landmark.name] = (x, y)
cv2.circle(blended_frame, (x, y), 5, (0, 255, 0), -1)
alignment_score = 0
threshold = 85 # 降低对齐公差阈值

for key in reference_coordinates:
outline_point = reference_coordinates[key]
detected_point =detected_points.get(key, None)
ifdetected_point:
distance = np.linalg.norm(np.array(outline_point) - np.array(detected_point))
#print(f&quot;Distance for {key}: {distance}&quot;) # 调试信息
if distance &lt; Threshold:
alignment_score += 1 # 根据需要调整阈值

# 计算对齐百分比
alignment_percentage = (alignment_score / len(reference_coordinates)) * 100
cv2.putText(blended_frame, &quot;Alignment score is : {}&quot;.format(alignment_percentage), (50, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)

# 检查对齐，如果对齐则启动计时器
if alignment_percentage &gt;95:
]]></description>
      <guid>https://stackoverflow.com/questions/78860543/how-can-i-know-if-someone-in-camera-aligns-an-outline</guid>
      <pubDate>Mon, 12 Aug 2024 07:55:19 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试为我的深度学习模型创建一个 FastAPI，但它似乎无法复制我在 Colab 中测试时得到的结果</title>
      <link>https://stackoverflow.com/questions/78860470/i-am-trying-to-make-a-fastapi-for-my-deep-learning-model-but-it-does-not-seem-t</link>
      <description><![CDATA[我的模型完全是在 Google Colab 上制作的，我使用 Tensorflow 和 Keras 制作了它。我尝试复制我在 YouTube 上看到的一个教程模型，后来我想为它制作一个网站。因此，我选择了 FastAPI 路线。但它似乎无法复制结果，在 Colab 上，它在验证数据集和测试数据集上的表现都很完美，准确率约为 96%。但是当我为其创建 FastAPI 时，无论我输入什么图像，它始终只显示 1 个特定类作为输出，并且该类的置信度为 96-98%。我以 .keras 格式下载了我的模型，因为 Colab 不支持 .h5 文件下载。这是在 Postman 中，API 似乎运行良好，模型本身在 Google Colab 上运行良好，但当我将其连接到 API 时不起作用。
有趣的是，当我在再次训练后以不同的名称第二次下载模型时，置信度似乎再次发生变化，并且现在始终保持这种分布。但是，是的，结果仍然相同，预测类 0 作为输出，只是这次置信度发生了变化（与之前的版本不同，在提供不同的图像后通常不会改变）。我还尝试在单独的文件中进行调试，在本地仅使用 1 张图像进行预测，但仍然失败。它出现了与以前相同的模式。我再次上​​网（Google）Colab 训练和测试模型，看起来效果不错。
下面我提供了我的 API 代码：
from fastapi import FastAPI, UploadFile, File
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from matplotlib import pyplot as plt
from PIL import Image
import numpy as np

app = FastAPI()

# 加载模型
try:
model = load_model(&#39;PotatoDisease.keras&#39;)
except ValueError as e:
print(f&quot;Error loading model: {e}&quot;)

class_names = [&#39;Potato___Early_blight&#39;, &#39;Potato___Late_blight&#39;, &#39;Potato___healthy&#39;]

@app.post(&quot;/predict/&quot;)
async def predict(file: UploadFile = File(...)):
image = Image.open(file.file)
image = image.resize((256, 256))
plt.imshow(image)
image = img_to_array(image)
print(&quot;调整大小和数组转换后的图像形状：&quot;, image.shape)
image = np.expand_dims(image, axis=0)
print(&quot;扩展尺寸后的图像形状：&quot;, image.shape)
image = image / 255.0

#prediction
predictions = model.predict(image)
print(&quot;原始预测输出：&quot;, predictions)
predict_class = class_names[np.argmax(predictions[0])]
confidence = round(100 * np.max(predictions[0]), 2)

return {&quot;predicted_class&quot;: predict_class, &quot;confidence&quot;: confidence}

@app.get(&quot;/&quot;)
def read_root():
return {&quot;message&quot;: &quot;欢迎使用图像分类 API&quot;}
`
]]></description>
      <guid>https://stackoverflow.com/questions/78860470/i-am-trying-to-make-a-fastapi-for-my-deep-learning-model-but-it-does-not-seem-t</guid>
      <pubDate>Mon, 12 Aug 2024 07:38:19 GMT</pubDate>
    </item>
    <item>
      <title>自定义回调“BetaAnnealing”无法正确更新我的 VAE kl_loss 的 beta 值</title>
      <link>https://stackoverflow.com/questions/78860370/custom-callback-betaannealing-isnt-updating-the-beta-value-correctly-for-my-v</link>
      <description><![CDATA[我的 VAE 中有一个自定义层，用于处理损失计算。我有一个自定义回调，用于在每个 epoch 开始时更新 beta 值。计算是正确的，因为它在每个 epoch 开始时打印出所需的 beta 值。但是，CustomVariationalLayer 中的实际 beta 值永远不会更新。
@register_keras_serializable(&#39;CustomVariationalLayer&#39;)
class CustomVariationalLayer(keras.layers.Layer):
def __init__(self, beta=1.0, **kwargs):
self.is_placeholder = True
super(CustomVariationalLayer, self).__init__(**kwargs)
self.beta = beta
self.recon_loss_metric = tf.keras.metrics.Mean(name=&#39;recon_loss&#39;)
self.kl_loss_metric = tf.keras.metrics.Mean(name=&#39;kl_loss&#39;)

def vae_loss(self, x, z_decoded, z_mean, z_log_var):
recon_loss = keras.losses.binary_crossentropy(K.flatten(x), K.flatten(z_decoded))
kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
print(f&quot;\n真实 beta 值 {self.beta:.4f}&quot;)
return recon_loss, self.beta * kl_loss

def call(self, input):
x = 输入[0]
z_decoded = 输入[1]
z_mean = 输入[2]
z_log_var = 输入[3]
recon_loss, kl_loss = self.vae_loss(x, z_decoded, z_mean, z_log_var)
self.add_loss(K.mean(recon_loss + kl_loss))
self.recon_loss_metric.update_state(recon_loss)
self.kl_loss_metric.update_state(kl_loss)
返回 x

def compute_output_shape(self, input_shape):
返回 input_shape[0]

def get_metrics(self):
返回 {&#39;recon_loss&#39;: self.recon_loss_metric.result().numpy(),
&#39;kl_loss&#39;: self.kl_loss_metric.result().numpy()}

class BetaAnnealing(keras.callbacks.Callback):
def __init__(self, layer, initial_beta=0.0, final_beta=1.0, epochs=100):
super(BetaAnnealing, self).__init__()
self.layer = layer
self.initial_beta = initial_beta
self.final_beta = final_beta
self.epochs = epochs

def on_epoch_begin(self, epoch, logs=None):
new_beta = self.initial_beta + (self.final_beta - self.initial_beta) * (epoch / (self.epochs - 1))
self.layer.beta = new_beta
print(f&quot;Epoch {epoch+1}: Beta 值已更新为 {new_beta:.4f}&quot;)
print(f&quot;Layer beta 值：{self.layer.beta}&quot;)

这是我的训练
batch_size = 128
epochs = 50

# 提前停止
es = EarlyStopping(monitor=&#39;val_loss&#39;, mode=&#39;min&#39;, verbose=1, waiting=5)

# Beta 退火
ba = BetaAnnealing(CustomVariationalLayer, initial_beta=0.0, final_beta=1.0, epochs=epochs)

# 编译模型
model.compile(optimizer=&#39;adam&#39;,
loss=None)

# 训练模型
history = model.fit(x_train, x_train,
batch_size=batch_size,
epochs=epochs,
shuffle=True,
validation_data=(x_validate, x_validate),
callbacks=[es, ba])

一开始看起来好像可以正常工作，因为 BetaAnnealing 的打印语句是正确的，但我向自定义层添加了打印语句进行验证，每次 beta 值都是“1.0”。这是我的训练输出的一个示例：
Epoch 1：Beta 值已更新为 0.0000
层 beta 值：0.0
Epoch 1/50

实际 beta 值 1.0000

实际 beta 值 1.0000
53/53 ━━━━━━━━━━━━━━━━━━━━━━ 0s 112ms/step - kl_loss：237.6640 - loss：238.3435 - recon_loss：0.6795
实际 beta 值 1.0000
53/53 ━━━━━━━━━━━━━━━━━━━━━ 17s 162ms/step - kl_loss：234.6529 - loss：235.3318 - recon_loss：0.6789 - val_kl_loss：5.1546 - val_loss：5.8057 - val_recon_loss：0.6506
Epoch 2：Beta 值更新为 0.0204
层 beta 值：0.02040816326530612
Epoch 2/50
53/53 ━━━━━━━━━━━━━━━━━━━━━ 2s 40ms/step - kl_loss：7.7230 - loss：8.3554 - recon_loss：0.6325 - val_kl_loss：922390720.0000 - val_loss：922390720.0000 - val_recon_loss：7.9802
Epoch 3：Beta 值更新为 0.0408
Layer beta 值：0.04081632653061224
Epoch 3/50
53/53 ━━━━━━━━━━━━━━━━━━━━━ 2s 39ms/step - kl_loss：4.8922 - loss：5.5163 - recon_loss：0.6242 - val_kl_loss：740397.3125 - val_loss：740402.4375 - val_recon_loss：4.9765
Epoch 4：Beta 值更新为 0.0612
层 beta 值：0.061224489795918366
Epoch 4/50
53/53 ━━━━━━━━━━━━━━━━━━━━━ 2s 39ms/step - kl_loss：1.3511 - loss：1.9775 - recon_loss：0.6265 - val_kl_loss：1217.8662 - val_loss：1218.7296 - val_recon_loss：0.8520
Epoch 5：Beta 值更新为 0.0816
Layer beta 值：0.08163265306122448
Epoch 5/50
53/53 ━━━━━━━━━━━━━━━━━━━━━━ 2s 41ms/step - kl_loss: 0.2503 - loss: 0.8771 - recon_loss: 0.6268 - val_kl_loss: 3.0466 - val_loss: 3.6738 - val_recon_loss: 0.6260

我该如何让它工作？]]></description>
      <guid>https://stackoverflow.com/questions/78860370/custom-callback-betaannealing-isnt-updating-the-beta-value-correctly-for-my-v</guid>
      <pubDate>Mon, 12 Aug 2024 07:07:31 GMT</pubDate>
    </item>
    <item>
      <title>我应该在评估模式还是训练模式下评估 WGAN-GP 模型？</title>
      <link>https://stackoverflow.com/questions/78860324/should-i-evaluate-wgan-gp-model-on-eval-mode-or-training-mode</link>
      <description><![CDATA[我在 WGAN-GP 模型中使用 batchnorm2d。我听说 GAN 模型最好保持训练模式，因为评估模式非常不稳定，尤其是在生成器中使用 batchnorm 时。这是真的吗？
我已经做了一些测试，训练模型似乎生成了更真实、更多样化的样本，而评估模式下的模型输出的图像质量非常低，几乎看起来像模式崩溃。我原本以为评估模式会给出更好的结果，但似乎我的 WGAN-GP 模型在评估模式下的表现要差得多。这是正常的吗？我应该只使用训练模式的模型进行评估吗？]]></description>
      <guid>https://stackoverflow.com/questions/78860324/should-i-evaluate-wgan-gp-model-on-eval-mode-or-training-mode</guid>
      <pubDate>Mon, 12 Aug 2024 06:56:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 ResNet50 创建 [w, h, f] 的特征张量</title>
      <link>https://stackoverflow.com/questions/78860233/using-resnet50-to-create-a-feature-tensor-of-w-h-f</link>
      <description><![CDATA[我正在尝试实现这篇论文，但我没有理解其中的内容。
它希望我使用 ResNet50 从图像中提取特征，但告诉我提取的特征将具有 [w, h, f] 的维度。但是，我用 ResNet50 看到的一切都给我返回了一个 [f] 的张量（即，它将我的整个图像变成特征，而不是将我的像素变成特征）
我读错了吗，还是我只是不明白我应该用 ResNet50 做什么？
论文中的相关引述：
“我们获得了一个大小为 f 的中间视觉特征表示 Fc。我们使用 ResNet50 [26] 作为我们的主干卷积架构。&quot;
&quot;第一步，将三维特征 Fc 通过保持其宽度重塑为二维特征，即获得特征形状 (f × h, w)。&quot;]]></description>
      <guid>https://stackoverflow.com/questions/78860233/using-resnet50-to-create-a-feature-tensor-of-w-h-f</guid>
      <pubDate>Mon, 12 Aug 2024 06:27:03 GMT</pubDate>
    </item>
    <item>
      <title>Optuna XGBoost 未使用 Mac 的所有 CPU</title>
      <link>https://stackoverflow.com/questions/78859768/optuna-xgboost-not-using-all-of-macs-cpu</link>
      <description><![CDATA[我正在将 Optuna 与 mySQL 一起运行，以尝试实现并行化并使用更多 Mac 的 CPU。例如，当我运行 GridSearchCV 时，我的用户 CPU 使用率将上升到 90%，并且风扇会启动。但是当我使用 Optuna 时，我得到大约 30% 并且没有风扇。这表明它没有被利用。
我尝试使用 mySQL 和分发在 VSCode 的 Jupyter Notebook 上运行两个处理。我这样做的方式是在不同的内核上制作我的笔记本的两个副本，然后通过加载研究在同一个 SQL 数据库上运行优化代码。也许这不是正确的做法？因为在示例中他们在两个终端上运行了 foo.py？
这是我的代码：
def objective(trial, X_train, y_train, X_test, y_test):
# 定义超参数搜索空间
params = {
&#39;n_estimators&#39;: trial.suggest_int(&#39;n_estimators&#39;, 100, 5000),
&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 2, 20),
&#39;learning_rate&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.01, 0.2),
&#39;subsample&#39;: trial.suggest_float(&#39;subsample&#39;, 0.7, 1.0),
&#39;colsample_bytree&#39;: trial.suggest_float(&#39;colsample_bytree&#39;, 0.6, 1.0),
&#39;min_child_weight&#39;: trial.suggest_int(&#39;min_child_weight&#39;, 1, 15),
&#39;gamma&#39;: trial.suggest_float(&#39;gamma&#39;, 0.0, 0.4),
&#39;lambda&#39;: trial.suggest_float(&#39;lambda&#39;, 1e-8, 1.0, log=True),
&#39;alpha&#39;: trial.suggest_float(&#39;alpha&#39;, 1e-8, 1.0, log=True)
}

# 初始化并训练模型
xgb = XGBRegressor(**params)
xgb.fit(X_train, y_train)

# 预测并计算指标
y_pred = xgb.predict(X_test)
error = max_percent_error(y_test, y_pred)
return error # 返回要最小化的误差

if __name__ == &quot;__main__&quot;:
study = optuna.load_study(study_name=&quot;example&quot;, storage=&quot;mysql://root@localhost/example&quot;)

# 对每个类别和目标执行优化
for category in train_test_splits:
for target_name in train_test_splits[category]:
if target_name in best_params_dict:
continue
print(f&quot;Running Optuna Optimization for target: {target_name} in category: {category}&quot;)

X_train = train_test_splits[category][target_name][&#39;X_train&#39;]
y_train = train_test_splits[category][target_name][&#39;y_train&#39;]
X_test = train_test_splits[category][target_name][&#39;X_test&#39;]

y_test = train_test_splits[category][target_name][&#39;y_test&#39;]

# 使用分布式计算优化研究
study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), 
n_trials=1900, n_jobs=-1)

# 存储为此目标找到的最佳参数
best_params = study.best_params
best_params_dict[category][target_name] = best_params

# 使用最佳参数训练最终模型
xgb_best = XGBRegressor(**best_params)
xgb_best.fit(X_train, y_train)

# 使用测试集评估模型
y_pred = xgb_best.predict(X_test)
test_max_percent_error = max_percent_error(y_test, y_pred)
test_r2_score = r2_score(y_test, y_pred)

print(f&quot;{target_name} 的最佳结果：&quot;)
print(f&quot; 最佳参数：{best_params}&quot;)
print(f&quot; 测试最大百分比误差：{test_max_percent_error:.4f}%&quot;)
print(f&quot; 测试 R^2：{test_r2_score:.4f}\n&quot;)


谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78859768/optuna-xgboost-not-using-all-of-macs-cpu</guid>
      <pubDate>Mon, 12 Aug 2024 01:47:51 GMT</pubDate>
    </item>
    <item>
      <title>获取 ValueError：所有数组的长度必须相同</title>
      <link>https://stackoverflow.com/questions/78858321/getting-valueerror-all-arrays-must-be-of-the-same-length</link>
      <description><![CDATA[我一直试图将字典转换为数据框，但每次我都收到 ValueError：所有数组的长度必须相同。我已经检查了每个数组的长度并确认它们相同，但我仍然收到相同的错误
def metrics_from_pipes(pipes_dict):
for name, pipeline in pipes_dict.items():

pipeline.fit(X_train, y_train)
y_pred_val = pipeline.predict(X_val)
y_pred_train = pipeline.predict(X_train)

train_metrics = {
&#39;model&#39;:list(pipes_dict.keys()),
&#39;MAE&#39;:train_mae,
&#39;MAPE&#39;:train_mape,
&#39;RMSE&#39;:train_rmse,
&#39;RSquared&#39;:train_rsquared
}

train_metrics_data = pd.DataFrame(train_metrics)
val_metrics = {
&#39;model&#39;:list(pipes_dict.keys()),
&#39;MAE&#39;:val_mae,
&#39;MAPE&#39;:val_mape,
&#39;RMSE&#39;:val_rmse,
&#39;RSquared&#39;:val_rsquared 
}

val_metrics_data = pd.DataFrame(val_metrics,)

# 合并来自训练集和测试集的指标
train_val_metrics = train_metrics_data.merge(val_metrics_data,
on = &#39;Model&#39;,
how = &#39;left&#39;,
suffixes = (&#39;_train&#39;, &#39;_val&#39;))

# 排序列 
train_val_metrics = train_val_metrics.reindex(columns = [&#39;Model&#39;,
&#39;MAE_train&#39;,
&#39;MAPE_train&#39;,
&#39;RMSE_train&#39;,
&#39;RSquared_train&#39;,
&#39;MAE_val&#39;,
&#39;MAPE_val&#39;,
&#39;RMSE_val&#39;,
&#39;RSquared_val&#39;])

return train_val_metrics.set_index(&#39;Model&#39;).transpose()

# 获取指标表
metrics_table = metrics_from_pipes(pipelines)

运行此代码会出现此错误
ValueError Traceback (most recent call last)
Cell In[45]，第 82 行
80 return train_val_metrics.set_index(&#39;Model&#39;).transpose()
81 # 获取指标表
---&gt; 82 metrics_table = metrics_from_pipes(pipelines)
83 #print(&#39;表 1：基本模型指标&#39;)
84 #metrics_table.style.background_gradient(cmap = Blues)
85 metrics_table

单元格 In[45]，第 50 行，位于 metrics_from_pipes(pipes_dict)
41 # 将性能指标列表聚合到单独的数据框中
42 train_metrics = {
43 &#39;model&#39;:list(pipes_dict.keys()),
44 &#39;MAE&#39;:train_mae,
(...)
47 &#39;RSquared&#39;:train_rsquared
48 }
---&gt; 50 train_metrics_data = pd.DataFrame(train_metrics)
51 val_metrics = {
52 &#39;model&#39;:list(pipes_dict.keys()),
53 &#39;MAE&#39;:val_mae,
(...)
56 &#39;RSquared&#39;:val_rsquared 
57 }
59 val_metrics_data = pd.DataFrame(val_metrics,)

ValueError: 所有数组的长度必须相同

当我检查 train_metrics 和 val 指标的字典结果时，我得到了这个
({&#39;model&#39;: [&#39;Linear Regression&#39;,
&#39;Random Forest Regressor&#39;,
&#39;Gradient Boost Regression&#39;,
&#39;Extra Tree Regressor&#39;],
&#39;MAE&#39;: [829.1023412412194,
288.33455697065233,
712.9637267872279,
0.0010629575741748962],
&#39;MAPE&#39;: [1.0302372135902111,
0.20937541440883897,
0.538244903316323,
6.306697580961048e-07],
&#39;RMSE&#39;: [1120.5542708017374,
416.48933196590013,
1012.399201767692,
0.05804079289490426],
&#39;RSquared&#39;: [0.5598288286601083,
0.9391916010838417,
0.6406981997919169,
0.9999999988190745]},
{&#39;model&#39;: [&#39;线性回归&#39;,
&#39;随机森林回归器&#39;,
&#39;梯度提升回归&#39;,
&#39;额外树回归器&#39;],
&#39;MAE&#39;: [855.9254413559535,
802.5902302175274,
772.3140648475379,
839.9018341377154],
&#39;MAPE&#39;: [1.0395487579496652,
0.5607987708065988,
0.5438627253681279,
0.5852285872937784],
&#39;RMSE&#39;: [1148.6549900167981,
1158.8411708570625,
1109.6145558003204,
1223.23337689915],
&#39;RSquared&#39;: [0.5876710102285392,
0.5803255834810521,
0.6152231339508221,
0.5323905190373128]})
]]></description>
      <guid>https://stackoverflow.com/questions/78858321/getting-valueerror-all-arrays-must-be-of-the-same-length</guid>
      <pubDate>Sun, 11 Aug 2024 12:27:40 GMT</pubDate>
    </item>
    <item>
      <title>我使用自定义增强和 TFRecord 管道在大型图像数据集上训练模型的方法是否有效？[关闭]</title>
      <link>https://stackoverflow.com/questions/78847703/is-my-approach-to-training-a-model-on-a-large-image-dataset-using-custom-augment</link>
      <description><![CDATA[我有一个存储在 TFRecord 文件中的大型图像数据集，我想在这个数据集上训练一个神经网络。我的目标是在将图像输入模型之前对图像应用自定义增强。但是，我找不到内置的 TensorFlow 函数（如 ImageDataGenerator）来在训练之前将增强直接应用于存储为张量的图像。
为了解决这个问题，我编写了一个自定义 ModelTrainer 类，其中我：
从 TFRecord 加载每个图像。
对图像应用一系列自定义变换（侵蚀、膨胀、剪切、旋转）。
创建一个由原始图像及其变换版本组成的批次。
在这个批次上训练模型，其中每个批次由单个图像及其变换版本组成。
这是我的代码片段：
class ModelTrainer:
def __init__(self, model):
self.model = model

def preprocess_image(self, image):
image = tf.cast(image, tf.float32) / 255.0
return image

def apply_erosion(self, image):
kernel = np.ones((5,5), np.uint8)
return cv2.erode(image, kernel, iterations=1)

def apply_dilation(self, image):
kernel = np.ones((5,5), np.uint8)
return cv2.dilate(image, kernel, iterations=1)

def apply_shear(self, image):
rows, cols = image.shape
M = np.float32([[1, 0.5, 0], [0.5, 1, 0]])
返回 cv2.warpAffine(image, M, (cols, rows))

def apply_rotation(self, image, angle=15):
rows, cols = image.shape
M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
返回 cv2.warpAffine(image, M, (cols, rows))

def transform_image(self, img, i):
if i == 0:
返回 img
elif i == 1:
返回 self.apply_erosion(img)
elif i == 2:
返回 self.apply_dilation(img)
elif i == 3:
返回 self.apply_shear(img)
elif i == 4:
返回 self.apply_rotation(img)

def train_on_tfrecord(self, tfrecord_path, dataset, batch_size=5):
dataset = dataset.map(lambda img, lbl: (self.preprocess_image(img), lbl))
dataset = dataset.batch(1)
dataset = iter(dataset)

对于 batch_images，数据集中的标签：
img_np = batch_images.numpy().squeeze()
lbl_np = labels.numpy().squeeze(axis=0)
image_batch = []
label_batch = []

对于 i in range(5):
perceived_image = self.transform_image(img_np, i)
image_batch.append(transformed_image)
label_batch.append(lbl_np)

image_batch_np = np.stack(image_batch, axis=0)
label_batch_np = np.stack(label_batch, axis=0)

image_batch_tensor = tf.convert_to_tensor(image_batch_np, dtype=tf.float32)
label_batch_tensor = tf.convert_to_tensor(label_batch_np, dtype=tf.float32)

loss = self.model.train_on_batch(image_batch_tensor, label_batch_tensor)

predictions = self.model.predict(image_batch_tensor)
predict_labels = np.argmax(predictions, axis=-1)
true_labels = np.argmax(label_batch_tensor, axis=-1)
accuracy = np.mean(predicted_labels == true_labels)

print(f&quot;Batch Loss = {loss}, Accuracy = {accuracy:.4f}&quot;)


我的问题是：

我一次在一个图像及其转换版本上训练模型的方法是否好且有效？
以这种方式训练网络是否可取，在每个批次中处理一个图像及其增强？
是否有更好的方法或优化我应该考虑处理大型数据集和应用自定义增强？
]]></description>
      <guid>https://stackoverflow.com/questions/78847703/is-my-approach-to-training-a-model-on-a-large-image-dataset-using-custom-augment</guid>
      <pubDate>Thu, 08 Aug 2024 09:51:24 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 部分依赖图与线性回归中的训练测试分割不一致</title>
      <link>https://stackoverflow.com/questions/77820555/shap-partial-dependence-plot-misalignment-with-train-test-split-in-linear-regres</link>
      <description><![CDATA[在 Python 中使用线性回归模型的训练测试分割时，我遇到了 SHAP 部分依赖图的问题。当我计算 SHAP 值并绘制测试集中第一个观测值的部分依赖关系时，数据点和基线的对齐似乎不正确。
这是我的代码的简化版本：
import shap
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import pandas as pd
import matplotlib.pyplot as plt
import request

def load_data() -&gt; pd.DataFrame:
&quot;&quot;&quot;
从给定的 URL 加载并返回数据集作为 Pandas DataFrame。

返回：
pd.DataFrame：已加载的数据集。
&quot;&quot;&quot;
url = &quot;https://archive.ics.uci.edu/static/public/165/concrete+compressive+strength.zip&quot;

r = 请求.get(url)

if r.ok:
使用 zipfile.ZipFile(BytesIO(r.content)) 作为 thezip:
使用 thezip.open(&quot;Concrete_Data.xls&quot;) 作为 thefile:
return pd.read_excel(thefile, header=0)
else:
引发异常(&quot;出现错误。&quot;)

df = load_data()

df = df.rename(
columns={
&#39;水泥 (组分 1)(立方米混合物中的千克)&#39;:&#39;水泥&#39;,
&#39;高炉矿渣 (组分 2)(立方米混合物中的千克)&#39;:&#39;blast&#39;,
&#39;粉煤灰 (组分 3)(立方米混合物中的千克)&#39;:&#39;ash&#39;,
&#39;水 (组分 4)(立方米混合物中的千克)&#39;:&#39;water&#39;,
&#39;高效减水剂 (组分 5)(立方米混合物中的千克) m^3 混合物)&#39;:&#39;高效减水剂&#39;,
&#39;粗骨料 (组分 6)(m^3 混合物中 kg)&#39;:&#39;粗&#39;,
&#39;细骨料 (组分 7)(m^3 混合物中 kg)&#39;:&#39;细&#39;,
&#39;年龄 (天)&#39;:&#39;年龄&#39;,
&#39;混凝土抗压强度 (MPa, 兆帕) &#39;: &#39;强度&#39;
}
)
df = df.drop_duplicates()
X = df.drop([&#39;强度&#39;], axis=1) 
y = df[&#39;强度&#39;]

# 拆分数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练模型
model = LinearRegression()
model.fit(X_train, y_train)

# 初始化 SHAP 解释器并计算测试集的值
explainer = shap.Explainer(model.predict, X_train)
shap_values = explainer(X_test)

# 绘制第一个测试观察的部分依赖关系
idx = 0
shap.partial_dependence_plot(
&quot;cement&quot;, model.predict, X_test,
model_expected_value=True, feature_expected_value=True, ice=False,
shap_values=shap_values[idx:idx+1,:]
)

# 保存图
plt.tight_layout()
plt.savefig(&#39;shap_dependence_plot.png&#39;, dpi=300)

但是，当我生成图时，数据点（黑点）与预期值线（蓝线）不一致感兴趣的特征。它似乎沿 y 轴移动。以下是输出图供参考：

当我使用整个数据集 X 而不是仅使用 X_train 初始化 SHAP 解释器时，该图似乎是正确的：
explainer = shap.Explainer(linreg, X)
shap_values = explainer(X_test)

idx = 0
shap.partial_dependence_plot(
&quot;cement&quot;, model.predict, X_test,
model_expected_value=True, feature_expected_value=True, ice=False,
shap_values=shap_values[idx:idx+1,:]
)

结果：

有人能解释一下为什么会出现这种错位，以及如何在使用训练测试分割时纠正部分依赖图吗？
任何见解或建议都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/77820555/shap-partial-dependence-plot-misalignment-with-train-test-split-in-linear-regres</guid>
      <pubDate>Mon, 15 Jan 2024 14:42:18 GMT</pubDate>
    </item>
    <item>
      <title>“Exact”对象没有属性“shap_values”</title>
      <link>https://stackoverflow.com/questions/73685519/exact-object-has-no-attribute-shap-values</link>
      <description><![CDATA[import shap
将 pandas 导入为 pd
从 sklearn.datasets 导入 fetch_california_housing
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestRegressor

dataset = fetch_california_housing(as_frame=True)
X = dataset[&quot;data&quot;]
y = dataset[&quot;target&quot;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = RandomForestRegressor()

model.fit(X_train, y_train)

explainer = shap.Explainer(model.predict, X_test)
shap_values = explainer(X_test)
shap_values = explainer.shap_values(X)

AttributeError: &#39;Exact&#39; 对象没有属性 &#39;shap_values&#39;

为了知道 SHAP 值，即使我输入了上述代码，最后一行也会出现上述错误。
当我查看示例代码时，它似乎没有任何问题，但 SHAP 库版本已更新，问题似乎已经发生。
我可以使用什么代码代替 .shap_values？]]></description>
      <guid>https://stackoverflow.com/questions/73685519/exact-object-has-no-attribute-shap-values</guid>
      <pubDate>Mon, 12 Sep 2022 07:00:33 GMT</pubDate>
    </item>
    <item>
      <title>神经网络训练过程中出现 NAN 的常见原因</title>
      <link>https://stackoverflow.com/questions/33962226/common-causes-of-nans-during-training-of-neural-networks</link>
      <description><![CDATA[我注意到在训练过程中经常出现 NAN 的情况。
很多时候，它似乎是由内积/全连接或卷积层中的权重爆炸引起的。
这是因为梯度计算爆炸而发生的吗？还是因为权重初始化（如果是这样，为什么权重初始化会产生这种影响）？还是很可能是由输入数据的性质引起的？
这里的首要问题很简单：训练期间出现 NAN 的最常见原因是什么？其次，有哪些方法可以解决这个问题（以及它们为什么有效）？]]></description>
      <guid>https://stackoverflow.com/questions/33962226/common-causes-of-nans-during-training-of-neural-networks</guid>
      <pubDate>Fri, 27 Nov 2015 17:23:30 GMT</pubDate>
    </item>
    </channel>
</rss>