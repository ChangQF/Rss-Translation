<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 24 Apr 2024 18:17:11 GMT</lastBuildDate>
    <item>
      <title>有人在 Capsnet 中开发或增强挤压方程吗</title>
      <link>https://stackoverflow.com/questions/78380434/is-anyone-develop-or-enhance-squash-equation-in-capsnet</link>
      <description><![CDATA[def 挤压（向量，轴=-1）：
s_squared_norm = tf.reduce_sum(tf.square(向量), axis, keepdims=True)
尺度 = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + K.epsilon())
返回比例 * 向量
CapsNet 中使用的 Standardd squash 函数，我如何增强它以提高准确性。
我尝试用不同的方式进行编辑，但结果并不好]]></description>
      <guid>https://stackoverflow.com/questions/78380434/is-anyone-develop-or-enhance-squash-equation-in-capsnet</guid>
      <pubDate>Wed, 24 Apr 2024 18:07:04 GMT</pubDate>
    </item>
    <item>
      <title>谷歌 Colab 上的 FIT-SNE</title>
      <link>https://stackoverflow.com/questions/78380376/fit-sne-on-google-colab</link>
      <description><![CDATA[如何在我的 Colab 笔记本上实现基于 FFT 加速插值的 t-SNE (FIt-SNE)？
我试图在狗情绪的kaggle数据集上计算t-SNE ,
我首先尝试获取第一个组件。
&lt;前&gt;&lt;代码&gt;电脑 = 60
pca = 分解.PCA(n_components=pc)
_ = pca.fit(图像)
imgPCA = pca.transform(图像)

tsne = TSNE(n_components=2)
Z = tsne.fit_transform(imgPCA)
绘图嵌入（Z）

然后我尝试了 多核 t-SNE 来提高迭代次数，但我仍然不喜欢
!pip install git+https://github.com/DmitryUlyanov/Multicore-TSNE.git

从 MulticoreTSNE 导入 MulticoreTSNE

Z = MulticoreTSNE(n_jobs=4, n_iter=10000).fit_transform(imgPCA)
图嵌入（Z，show_axis = True）

现在我想尝试使用 FIt-SNE，但我不会知道如何使用它，你能帮我吗？
或者，如果您愿意，也许您可​​以帮助改进之前的代码片段。
有代码可以理解数据集的格式：
导入 pandas 作为 pd
导入CV2

img_size = (192,192,3)
num_px = img_size[0] * img_size[1] * img_size[2]

目录 = &#39;/content/drive/MyDrive/Colab Notebooks/ML/Dog_Emotion/&#39;
图片 = []
标签=[]
labels_df = pd.read_csv(目录 + “labels.csv”)
n_图像 = 0

对于 tqdm 中的图像（labels_df.iloc，desc =“加载图像”，单位=“图像”，总计= 4000）：
  images.append(np.asarray(cv2.resize(cv2.imread(目录 + image[2] + &#39;/&#39; + image[1], cv2.IMREAD_COLOR), img_size[0:2])[:, :, : :-1]))
  labels.append(图像[2])

图像，标签 = np.array(images).reshape(4000, num_px), np.array(labels)

print(f&#39;标签形状：{labels.shape}&#39;)
print(f&#39;图像形状：{images.shape}&#39;)
print(f&#39;图像大小: {img_size}&#39;)

defplot_embedding(Z, show_axis=&quot;False&quot;):
  plt.figure(figsize=(10, 8))
  地图= {标签：i代表i，枚举中的标签（np.unique（标签））}
  color = np.array([map[l] for l in labels])
  plt.scatter(Z[:, 0], Z[:, 1], c = 颜色, cmap = &quot;jet&quot;)
  plt.colorbar()
  plt.title(&#39;2d t-SNE 可视化&#39;)
  如果没有显示轴：
    plt.axis(“关闭”)
  plt.axis(“等于”)
  plt.show()

标签形状：(4000,)
图像形状：(4000, 110592)
图片尺寸：(192, 192, 3)]]></description>
      <guid>https://stackoverflow.com/questions/78380376/fit-sne-on-google-colab</guid>
      <pubDate>Wed, 24 Apr 2024 17:53:14 GMT</pubDate>
    </item>
    <item>
      <title>用户输入字符串和机器学习模型猜测类别吗？</title>
      <link>https://stackoverflow.com/questions/78380232/have-user-input-string-and-machine-learning-model-guess-category</link>
      <description><![CDATA[我目前正在基于 20 Newsgroup 数据集构建机器学习模型。
它有 20 个类别，例如宗教、政治、汽车、计算机等，并预测文本条目正在谈论的内容。
“有谁知道为什么我的斯巴鲁雨刷不适合” - 汽车。
我正在使用 scikit learn，并且有 MLP 和逻辑回归模型。
我想知道是否有一种方法可以让用户输入一个字符串，然后模型吐出它认为它是什么类别？
用户输入：“您推荐什么微处理器？”
型号：“计算机”
我找不到有关该主题的任何好的资源，并且需要一些建议。]]></description>
      <guid>https://stackoverflow.com/questions/78380232/have-user-input-string-and-machine-learning-model-guess-category</guid>
      <pubDate>Wed, 24 Apr 2024 17:25:56 GMT</pubDate>
    </item>
    <item>
      <title>张量流和 PyTorch</title>
      <link>https://stackoverflow.com/questions/78380010/tensorflow-and-pytorch</link>
      <description><![CDATA[我最近开始学习机器学习和人工智能。但我对tensorflow和pytorch有问题，我发现很难安装两者。过程中总会有中断的时候。我可以做些什么来使该过程顺利进行？
我尝试使用 pip 进行正常的过程，每次开始下载时，通常会有一些东西中断该过程。我希望它能够无缝运行，没有任何问题]]></description>
      <guid>https://stackoverflow.com/questions/78380010/tensorflow-and-pytorch</guid>
      <pubDate>Wed, 24 Apr 2024 16:40:17 GMT</pubDate>
    </item>
    <item>
      <title>LLM Studio 无法下载模型并出现错误：无法获取本地颁发者证书</title>
      <link>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</link>
      <description><![CDATA[在LLM studio中，当我尝试下载任何模型时，我遇到以下错误：
下载失败：无法获取本地颁发者证书
]]></description>
      <guid>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</guid>
      <pubDate>Wed, 24 Apr 2024 16:03:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么 bigQueryML 的转换子句不支持 ML.NGRAM？</title>
      <link>https://stackoverflow.com/questions/78379552/why-isnt-ml-ngram-not-supported-in-transform-clause-in-bigqueryml</link>
      <description><![CDATA[我正在使用以下查询来创建模型，但编辑器抱怨转换子句中不支持 ML.NGRAM。
创建或替换模型
`singular-hub-291814.movi​​e_sentiment.mymodel3`
TRANSFORM(ML.NGRAM(string_field_0,[1,2])OVER() 作为 ngram )
选项
  ( model_type=&#39;LOGISTIC_REG&#39;,
    auto_class_weights = TRUE，
    data_split_method=&#39;随机&#39;,
    DATA_SPLIT_EVAL_FRACTION = .10，
    input_label_cols=[&#39;评论&#39;]
  ） 作为

选择
  string_field_0 ，从表中查看；

尽管可以在 SELECT 查询中使用相同的转换。
&lt;前&gt;&lt;代码&gt;选择
  ML.NGRAMS(words_array, [1,2]) 作为 ngrams，
  审查
从表；

而其他转换函数（如 bag_of_words、min_abs_scalar）可以在转换中使用。为什么这种行为会如此不同？是否有不能在 TRANSFORM 子句中使用的转换器的明确列表？]]></description>
      <guid>https://stackoverflow.com/questions/78379552/why-isnt-ml-ngram-not-supported-in-transform-clause-in-bigqueryml</guid>
      <pubDate>Wed, 24 Apr 2024 15:18:24 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 排名指标</title>
      <link>https://stackoverflow.com/questions/78379350/lightgbm-ranking-metrics</link>
      <description><![CDATA[我使用了 LightGBM LambdaRank，但不明白如何根据获得的值进一步计算指标
数据框
将 numpy 导入为 np
将 pandas 导入为 pd
将 lightgbm 导入为 lgb

df = pd.DataFrame({
    “query_id”：[i for i in range(100) for j in range(10)],
    “var1”：np.random.random(size=(1000,)),
    “var2”：np.random.random(size=(1000,)),
    “var3”：np.random.random(size=(1000,)),
    “相关性”:list(np.random.permutation([1,2,3,4,5, 6,7,8,9,10]))*100
})


这是数据框：
query_id var1 var2 var3 相关性
0 0 0.905357 0.894079 0.375130 5
1 0 0.547075 0.377121 0.754090 3
2 0 0.160593 0.397771 0.034981 10
3 0 0.295548 0.162948 0.549913 9
4 0 0.833037 0.233751 0.096317 7
……………………
995 99 0.188557 0.258408 0.090342 6
996 99 0.178921 0.881938 0.467198 2
997 99 0.175884 0.897310 0.992994 8
998 99 0.466874 0.400800 0.561379 1
999 99 0.035098 0.232043 0.982138 4
1000行×5列


我将数据集分为训练集、验证集和测试集
&lt;前&gt;&lt;代码&gt;
train_df = df.iloc[:600]
test_df = df.iloc[600:800]
val_df = df.iloc[800:]

qids_train = train_df.groupby(“query_id”)[“query_id”].count().to_numpy()
X_train = train_df.drop([“query_id”, “相关性”], axis=1)
y_train = train_df[“相关性”]

qids_validation =validation_df.groupby(“query_id”)[“query_id”].count().to_numpy()
X_validation =validation_df.drop([“query_id”,“相关性”], axis=1)
y_validation =validation_df[“相关性”]

qids_test = test_df.groupby(“query_id”)[“query_id”].count().to_numpy()
X_test = test_df.drop([“query_id”,“相关性”], axis=1)
y_test = test_df[“相关性”]

创建 lgb 数据集
lgb_train = lgb.Dataset(X_train, label=y_train, group=qids_train)
lgb_valid = lgb.Dataset(X_validation, label=y_validation, group=qids_validation)
lgb_test = lgb.Dataset(X_test, label=y_test, group=qids_test)


火车模型
param_ranking = {
    “目标”：“lambdarank”，
    “label_gain”：[int(i) for i in range(int(max(y_train.max(), y_validation.max())) + 1)],
    “公制”：[“ndcg”]，
    “评估时间”：5，
    “随机状态”：1，
    “冗长”：-1，
    # &#39;num_threads&#39;: 16,
    “学习率”：0.1，
}
回调 = [
    lgb.early_stopping(20),
    lgb.log_evaluation（周期=10）
]
model_gbm = lgb.train(
    参数排名，
    LGB_火车，
    100,
    valid_sets=[lgb_train, lgb_valid],
    回调=回调，
）

训练直到验证分数在 20 轮内没有提高
[10]训练的ndcg@5：0.880126 valid_1的ndcg@5：1
[20] 训练的 ndcg@5: 0.906826 valid_1 的 ndcg@5: 1
提前停止，最佳迭代是：
[1] 训练的 ndcg@5: 0.789559 valid_1 的 ndcg@5: 1


y_pred = model_gbm.predict(X_test)
X_test[“预测排名”] = y_pred
X_test.sort_values(“预测排名”, 升序=False)


我现在陷入困境，无法计算 map@k、hit@k、mrr、ndcg@k 等指标。如果有人可以帮忙，请解释如何解释 lgbm 模型预测，以便进一步计算测试数据集上的指标
def hit_rate(y_true, y_pred, k=5):
    点击数 = 0
    对于 true，pred 在 zip(y_true, y_pred) 中：
        top_indices = np.argsort(pred)[::-1][:k]
        如果 top_indices 为 true：
            命中数 += 1
    返回命中数 / len(y_true)
hit_rate(y_test, y_pred )
0.0

我尝试计算命中率，但得到了 0]]></description>
      <guid>https://stackoverflow.com/questions/78379350/lightgbm-ranking-metrics</guid>
      <pubDate>Wed, 24 Apr 2024 14:48:25 GMT</pubDate>
    </item>
    <item>
      <title>在 Oracle oml4r 中，库（ORE）在安装后不起作用</title>
      <link>https://stackoverflow.com/questions/78379323/in-oracle-oml4r-libraryore-is-not-working-after-install</link>
      <description><![CDATA[让 rstudio 服务器正常工作后，我按照这些说明启用了 oml4r - https://docs.oracle.com/en/database/oracle/machine-learning/oml4r/2.0.0/oread/install-rstudio-server。 html。特别是我做了以下事情：
&#39;&#39;&#39;
sudo vi /etc/rstudio/rserver.conf
rsession-ld-library-path=R_HOME/lib:ORACLE_HOME/lib
&#39;&#39;&#39;
&#39;&#39;&#39;
cd /usr/lib64/R/etc
sudo vi Renviron.site
ORACLE_HOME=ORACLE_HOME
ORACLE_HOSTNAME=ORACLE_HOSTNAME
ORACLE_SID=ORACLE_SID
&#39;&#39;&#39;
&#39;&#39;&#39;
sudo rstudio-服务器重新启动
&#39;&#39;&#39;
但我仍然无法执行库（ORE）。是否还有其他包需要加载？如果是这样，我应该如何加载它们？]]></description>
      <guid>https://stackoverflow.com/questions/78379323/in-oracle-oml4r-libraryore-is-not-working-after-install</guid>
      <pubDate>Wed, 24 Apr 2024 14:44:12 GMT</pubDate>
    </item>
    <item>
      <title>关于 Sklearn 中的 jaccard_score</title>
      <link>https://stackoverflow.com/questions/78378954/about-jaccard-score-in-sklearn</link>
      <description><![CDATA[我遇到了 jaccard_score 函数的问题 (jaccard_score(ground_true, inference,average=“micro”, Zero_division=0))。我没有足够的内存来存储验证的所有 ground_truth 和推论。因此，我所做的是将每个批次的 Jaccard 分数求和到一个变量，并在验证结束时将该变量除以批次数。通过这种方法，我获得的结果为 0.8084487056909495。然而，当我使用容量更大的计算机来处理数据，并一次处理所有ground_truth和mask时，我得到一个像0.7716579100568796这样的值。有人能解释一下为什么会发生这种情况吗？]]></description>
      <guid>https://stackoverflow.com/questions/78378954/about-jaccard-score-in-sklearn</guid>
      <pubDate>Wed, 24 Apr 2024 13:49:22 GMT</pubDate>
    </item>
    <item>
      <title>合并两个不同的人工智能模型</title>
      <link>https://stackoverflow.com/questions/78376582/merging-two-different-ai-models</link>
      <description><![CDATA[我已经训练了两个模型，一个用于模糊检测，另一个用于两个不同数据集的曝光分类，现在我想合并这两个模型以获得执行这两项任务的单个组合模型
我希望组合模型通过将单个图像作为输入来预测模糊和曝光]]></description>
      <guid>https://stackoverflow.com/questions/78376582/merging-two-different-ai-models</guid>
      <pubDate>Wed, 24 Apr 2024 07:14:39 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow.keras.layers.Flatten() 抛出 INVALID_ARGUMENT 错误</title>
      <link>https://stackoverflow.com/questions/78375639/tensorflow-keras-layers-flatten-throwing-invalid-argument-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78375639/tensorflow-keras-layers-flatten-throwing-invalid-argument-error</guid>
      <pubDate>Wed, 24 Apr 2024 01:56:40 GMT</pubDate>
    </item>
    <item>
      <title>最后一个维度的有效乘法</title>
      <link>https://stackoverflow.com/questions/78344508/effective-multiplication-over-last-dimension</link>
      <description><![CDATA[我有两个火炬张量 - A 形状为 (15, 100, 256) 和 B 形状为 (120, 2010, 256)。如何对最后一个维度进行有效乘法并获得形状 (15, 100, 120, 2010) 的张量。我尝试了类似 torch.einsum(&#39;ijk, mnk -&gt; ijmn&#39;, A, B) 的方法，但据我了解，这种方法隐式创建中间张量并需要大量内存和时间。我还尝试了 opt_einsum 库，但与 torch.einsum 相比，在时间和内存使用方面没有看到很大的差异
当然，我可以在循环中完成它，但我想要得到在时间和内存使用方面都有效的解决方案。预先感谢您]]></description>
      <guid>https://stackoverflow.com/questions/78344508/effective-multiplication-over-last-dimension</guid>
      <pubDate>Thu, 18 Apr 2024 02:13:36 GMT</pubDate>
    </item>
    <item>
      <title>使用函数式 API 进行迁移学习和量化感知训练</title>
      <link>https://stackoverflow.com/questions/72935089/transfer-learning-with-quantization-aware-training-using-functional-api</link>
      <description><![CDATA[我有一个正在使用 MobileNetV2 迁移学习的模型，我想对其进行量化，并将其与使用迁移学习的非量化模型的准确性差异进行比较。但是，它们并不完全支持递归量化，但根据此，此方法应该量化我的模型： https://github.com/tensorflow/model-optimization/issues/377#issuecomment-820948555
我尝试做的是：
导入tensorflow为tf
将tensorflow_model_optimization导入为tfmot
pretrained_model = tf.keras.applications.MobileNetV2(include_top=False)
pretrained_model.trainable = True
    
对于 pretrained_model.layers[:-1] 中的层：
    可训练层 = False
    
quantize_model_pretrained = tfmot.quantization.keras.quantize_model
q_pretrained_model = quantize_model_pretrained(pretrained_model)
    
    
原始输入 = tf.keras.layers.Input(形状=(224, 224, 3))
y = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(original_inputs)
y = 基础模型（原始输入）
y = tf.keras.layers.GlobalAveragePooling2D()(y)
原始输出 = tf.keras.layers.Dense(5, 激活 =“softmax”)(y)

model_1 = tf.keras.Model(原始输入, 原始输出)
量化模型 = tfmot.量化.keras.量化模型
q_aware_model = quantize_model(model_1)

它仍然给我以下错误：
ValueError：不支持在另一个 tf.keras 模型内量化 tf.keras 模型。

我想了解在这种情况下执行量化感知训练的正确方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/72935089/transfer-learning-with-quantization-aware-training-using-functional-api</guid>
      <pubDate>Mon, 11 Jul 2022 07:31:03 GMT</pubDate>
    </item>
    <item>
      <title>使用 OneHotEncoder 时出现错误“预期为 2D 数组，改为 1D 数组”</title>
      <link>https://stackoverflow.com/questions/47957151/error-expected-2d-array-got-1d-array-instead-using-onehotencoder</link>
      <description><![CDATA[我是机器学习的新手，正在尝试解决使用 OneHotEncoder 类遇到的错误。错误是：“预期是二维数组，却得到了一维数组”。因此，当我想到一维数组时，它类似于： [1,4,5,6] ，而二维数组则为 [[2,3], [3,4], [ 5,6]]，但我仍然无法弄清楚为什么会失败。这条线失败了：
X[:, 0] = onehotencoder1.fit_transform(X[:, 0]).toarray()

这是我的完整代码：
# 导入库
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd

# 导入数据集
数据集 = pd.read_csv(&#39;Data2.csv&#39;)
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, 5].values
df_X = pd.DataFrame(X)
df_y = pd.DataFrame(y)

# 替换缺失值
从 sklearn.preprocessing 导入 Imputer
imputer = Imputer（missing_values =&#39;NaN&#39;，策略=&#39;平均值&#39;，轴= 0）
imputer = imputer.fit(X[:, 3:5 ])
X[:, 3:5] = imputer.transform(X[:, 3:5])


# 对分类数据“名称”进行编码
从 sklearn.preprocessing 导入 LabelEncoder、OneHotEncoder
labelencoder_x = LabelEncoder()
X[:, 0] = labelencoder_x.fit_transform(X[:, 0])

# 转化为矩阵
onehotencoder1 = OneHotEncoder(categorical_features = [0])
X[:, 0] = onehotencoder1.fit_transform(X[:, 0]).toarray()

# 编码分类数据“大学”
从 sklearn.preprocessing 导入 LabelEncoder
labelencoder_x1 = LabelEncoder()
X[:, 1] = labelencoder_x1.fit_transform(X[:, 1])

我确信您可以通过这段代码看出我有两列是标签。我使用标签编码器将这些列转换为数字。我想使用 OneHotEncoder 更进一步，将它们转换为一个矩阵，这样每一行都会有这样的内容： 

&lt;前&gt;&lt;代码&gt;0 1 0
1 0 1

我唯一想到的是我如何对标签进行编码。我一项一项地做，而不是一次全部做。不确定这就是问题所在。
我希望做这样的事情：
# 编码分类数据“名称”
从 sklearn.preprocessing 导入 LabelEncoder、OneHotEncoder
labelencoder_x = LabelEncoder()
X[:, 0] = labelencoder_x.fit_transform(X[:, 0])

# 转化为矩阵
onehotencoder1 = OneHotEncoder(categorical_features = [0])
X[:, 0] = onehotencoder1.fit_transform(X[:, 0]).toarray()

# 编码分类数据“大学”
从 sklearn.preprocessing 导入 LabelEncoder、OneHotEncoder
labelencoder_x1 = LabelEncoder()
X[:, 1] = labelencoder_x1.fit_transform(X[:, 1])

# 转化为矩阵
onehotencoder2 = OneHotEncoder(categorical_features = [1])
X[:, 1] = onehotencoder1.fit_transform(X[:, 1]).toarray()

下面你会发现我的整个错误：
文件“/Users/jim/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py”，第 441 行，在 check_array 中
    “如果它包含单个样本。”.format(array))

ValueError：需要 2D 数组，却得到 1D 数组：
数组=[ 2.1.3.2.3.5.5.0.4.0.]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

任何朝着正确方向的帮助都会很棒。]]></description>
      <guid>https://stackoverflow.com/questions/47957151/error-expected-2d-array-got-1d-array-instead-using-onehotencoder</guid>
      <pubDate>Sun, 24 Dec 2017 00:27:08 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”</title>
      <link>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</link>
      <description><![CDATA[我正在尝试使用最新的可用资源来开发一些时间序列序列预测。为此，我确实检查了 TensorFlow 时间序列中的示例代码，但收到此错误：
AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”

我正在使用 Anaconda。当前环境是Python 3.5和TensorFlow 1.2.1。也尝试过 TensorFlow 1.3，但没有任何改变。
这是我的代码尝试运行。我在谷歌上没有找到与该问题相关的任何有用信息。有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</guid>
      <pubDate>Sat, 02 Sep 2017 04:48:51 GMT</pubDate>
    </item>
    </channel>
</rss>