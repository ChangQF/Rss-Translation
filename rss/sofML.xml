<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 19 Nov 2024 21:16:20 GMT</lastBuildDate>
    <item>
      <title>小语言模型和传统人工智能模型的主要区别是什么？它们带来了哪些价值？[关闭]</title>
      <link>https://stackoverflow.com/questions/79204699/what-is-the-main-difference-between-small-langiage-model-and-traditional-ai-mode</link>
      <description><![CDATA[SLM 应该处理公司数据
那么它们与我们迄今为止构建的传统 AI 模型有何不同？
它们与经过微调的 LLM 大型模型有何不同？
SML 能为传统 AI 模型带来什么价值？作为基础，了解这一点非常重要，我可以决定哪种模型最适合需求
向所有能在这里提供帮助的志愿者致以崇高的敬意]]></description>
      <guid>https://stackoverflow.com/questions/79204699/what-is-the-main-difference-between-small-langiage-model-and-traditional-ai-mode</guid>
      <pubDate>Tue, 19 Nov 2024 18:47:35 GMT</pubDate>
    </item>
    <item>
      <title>“机器学习是否是一个有前途的职业领域，还是我应该探索其他选择？” [关闭]</title>
      <link>https://stackoverflow.com/questions/79204113/is-machine-learning-a-promising-career-field-for-the-future-or-should-i-explor</link>
      <description><![CDATA[“我目前是一名 B.Tech 一年级学生，主修计算机科学工程，重点是人工智能和机器学习。虽然我发现机器学习领域很吸引人，但就职业前景和个人兴趣而言，我不确定它是否适合我。
我的一些问题是：
机器学习在未来 5-10 年内是否仍是一个不断增长且需求旺盛的领域？
在从事 ML/AI 职业时，我应该注意哪些具体挑战？
探索全栈 Web 开发、数据工程或网络安全等领域是否会提供更好的机会？
我已经开始学习 Python、DSA 和一些 Web 开发基础知识（HTML、CSS），并且我喜欢通过技术解决实际问题。我正在寻找专业人士或有过类似情况的学生的建议。
提前感谢您的见解！&quot;
&quot;我选择 AI/ML 作为我的专业，因为它似乎是一个趋势和有前途的领域，我的许多同龄人都选择了它。我已经开始学习 Python、数据结构和算法，并且探索了 NumPy 等库。我还喜欢解决问题，并参与了创建聊天机器人和食谱网站等小项目。
最近，我一直在探索全栈 Web 开发和 AI/ML，以多样化我的技能。然而，我发现很难决定我是否应该只专注于 AI/ML 或转向其他领域，如 Web 开发、数据工程或网络安全。&quot;]]></description>
      <guid>https://stackoverflow.com/questions/79204113/is-machine-learning-a-promising-career-field-for-the-future-or-should-i-explor</guid>
      <pubDate>Tue, 19 Nov 2024 15:44:24 GMT</pubDate>
    </item>
    <item>
      <title>我下一步该做什么才能完成我的硕士课程？[关闭]</title>
      <link>https://stackoverflow.com/questions/79203677/what-should-i-do-next-to-complete-my-masters-program</link>
      <description><![CDATA[我目前是硕士课程的第一年，由于我之前没有深度学习背景，所以决定参加密歇根大学的 EECS 498-007 / 598-005。我错过了两个作业——作业 4 关于对象检测，作业 6 关于 VAE 和 GAN。由于密歇根大学的课程是自定进度的，并且涉及从头开始构建模型，这非常具有挑战性，所以我转向 https://www.learnpytorch.io/ 来学习和完成大部分练习。我已经熟悉了 PyTorch 的一般工作流程。我的导师很少插手，提供的帮助很少。
我想知道是否有类似的课程可以让我继续学习，或者在这种情况下我应该怎么做。任何建议都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/79203677/what-should-i-do-next-to-complete-my-masters-program</guid>
      <pubDate>Tue, 19 Nov 2024 13:48:55 GMT</pubDate>
    </item>
    <item>
      <title>“ValueError：形状不兼容”，但是在哪里呢？</title>
      <link>https://stackoverflow.com/questions/79202703/valueerror-shapes-are-incompatible-but-where</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79202703/valueerror-shapes-are-incompatible-but-where</guid>
      <pubDate>Tue, 19 Nov 2024 08:48:36 GMT</pubDate>
    </item>
    <item>
      <title>如何修改我的代码来处理 RGBX（4 通道）图像以进行语义分割？</title>
      <link>https://stackoverflow.com/questions/79201296/how-to-modify-my-code-to-handle-rgbx-4-channel-images-for-semantic-segmentatio</link>
      <description><![CDATA[我是该领域的新手，一直在关注 U-Net 教程，使用 3 通道 RGB 图像进行语义分割https://www.youtube.com/watch?v=68HR_eyzk00&amp;list=PLZsOBAyNTZwbR08R959iCvYT3qzhxvGOE&amp;index=2&amp;ab_channel=DigitalSreeni，对我来说效果很好。但是，我现在需要扩展管道以支持 4 通道 RGBX 图像（即 RGB + 其他通道），但我不确定如何修改代码以适应其他通道，尤其是预处理和 ImageDataGenerator 部分（我认为 ImageDataGenerator 不支持 4 通道图像）。
这是代码（将图像修补为（256 * 256 * 4）并将蒙版修补为（256*256）后）：
import os
import cv2
import numpy as np
import glob
from matplotlib import pyplot as plt
import tensorflow as tf
import splitfolders
import fragmentation_models as sm
from tensorflow.keras.metrics import MeanIoU
from sklearn.preprocessing import MinMaxScaler
from keras.utils import to_categorical

input_folder=&#39;我的图像和掩码的文件夹路径&#39;

output_folder=&#39;输出文件夹的路径&#39;
#按比例分割
splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75,.25),group_prefix=None) 

#重新排列用于 keras 增强的文件夹结构

seed=24
batch_size=16 
n_classes=2 

scaler=MinMaxScaler()

BACKBONE=&#39;resnet34&#39; 
preprocess_input=sm.get_preprocessing(BACKBONE)

def preprocess_data(img, mask, num_class):
#缩放图像
img=scaler.fit_transform(img.reshape(-1, img.shape[-1])).reshape(img.shape)
img=preprocess_input(img) #基于预训练的主干进行预处理
mask=to_categorical(mask, num_class)
return (img,mask)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
def trainGenerator(train_img_path, train_mask_path, num_class):
img_data_gen_args=dict(horizo​​ntal_flip=True, vertical_flip=True, fill_mode=&#39;reflect&#39;) #数据增强

image_datagen=ImageDataGenerator(**img_data_gen_args)
mask_datagen=ImageDataGenerator(**img_data_gen_args)

image_generator=image_datagen.flow_from_directory(train_img_path, class_mode=None, batch_size=batch_size, seed=seed)
mask_generator=image_datagen.flow_from_directory(train_mask_path, class_mode=None，color_mode=&#39;grayscale&#39;，batch_size=batch_size，seed=seed)

train_generator=zip(image_generator，mask_generator)

for (img, mask) in train_generator:
img, mask= preprocess_data(img, mask, num_class)
Yield (img, mask)

train_img_path=&#39;训练图像路径&#39;
train_mask_path=&#39;训练掩码路径&#39;
train_img_gen=trainGenerator(train_img_path, train_mask_path, num_class=2)

val_img_path=&#39;验证图像路径&#39;
val_mask_path=&#39;验证掩码路径&#39;
val_img_gen=trainGenerator(val_img_path, val_mask_path, num_class=2)

x, y=train_img_gen.__next__()

for i in range(0,3):
image=x[i]
mask=np.argmax(y[i], axis=2)
plt.subplot(1,2,1)
plt.imshow(image)
plt.subplot(1,2,2)
plt.imshow(mask, cmap=&#39;gray&#39;)
plt.show()

num_train_imgs=len(os.listdir(&#39;训练图像路径&#39;))
num_val_images=len(os.listdir(&#39;验证路径图像&#39;))
steps_per_epochs=num_train_imgs//batch_size
val_steps_per_epoch=num_val_images//batch_size

IMG_HEIGHT=x.shape[1]
IMG_WIDTH=x.shape[2]
IMG_CHANNELS=x.shape[3]

n_classes=2

model=sm.Unet(&#39;resnet34&#39;,coder_weights=&#39;None&#39;,input_shape=(IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS),classes=n_classes,activation=&#39;softmax&#39;)
model.compile(&#39;Adam&#39;,loss=sm.losses.binary_crossentropy,metrics=[sm.metrics.iou_score,sm.metrics.FScore()])

history=model.fit(train_img_gen, steps_per_epoch=steps_per_epochs, epochs=100, verbose=1, validation_data=val_img_gen, validation_steps=val_steps_per_epoch)

]]></description>
      <guid>https://stackoverflow.com/questions/79201296/how-to-modify-my-code-to-handle-rgbx-4-channel-images-for-semantic-segmentatio</guid>
      <pubDate>Mon, 18 Nov 2024 20:06:05 GMT</pubDate>
    </item>
    <item>
      <title>如何防止目标编码泄漏？[关闭]</title>
      <link>https://stackoverflow.com/questions/79196742/how-can-i-prevent-leaks-in-my-target-encoding</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79196742/how-can-i-prevent-leaks-in-my-target-encoding</guid>
      <pubDate>Sun, 17 Nov 2024 08:04:31 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的暹罗模型不适用于验证数据？</title>
      <link>https://stackoverflow.com/questions/79196054/why-does-my-siamese-model-not-work-on-verification-data</link>
      <description><![CDATA[我的模型之前运行良好，并做出了良好的预测。然而，现在我尝试使用它，它无法识别图像之间的相似性。请帮助解决此问题。
# 保存权重
siamese_model.save(&#39;siamesemodel.h5&#39;)

# 加载模型
model = tf.keras.models.load_model(
&#39;siamesemodel.h5&#39;, 
custom_objects={&#39;L1Dist&#39;: L1Dist, &#39;BinaryCrossentropy&#39;: tf.losses.BinaryCrossentropy}
)

# 验证函数
def verify(model, detection_threshold, validation_threshold):
# 构建结果数组
results = []
for image in os.listdir(os.path.join(&#39;application_data&#39;, &#39;verification_images&#39;)):
input_img = preprocess(os.path.join(&#39;application_data&#39;, &#39;input_image&#39;, &#39;input_image.jpg&#39;))
validation_img = preprocess(os.path.join(&#39;application_data&#39;, &#39;verification_images&#39;, image))

result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))
results.append(result)

# 检测阈值：高于该指标的预测被视为正值
detection = np.sum(np.array(results) &gt; detection_threshold)

 # 验证阈值：正预测的比例/总正样本
validation = detection / len(os.listdir(os.path.join(&#39;application_data&#39;, &#39;verification_images&#39;)))
verified = validation &gt; verify_threshold

返回结果，已验证

cap = cv2.VideoCapture(0)
while cap.isOpened():
ret, frame = cap.read()
frame = frame[120:120+250, 200:200+250, :]

cv2.imshow(&#39;Verification&#39;, frame)

# 验证触发器
if cv2.waitKey(10) &amp; 0xFF == ord(&#39;v&#39;):
# 将输入图像保存到 input_image 文件夹
cv2.imwrite(os.path.join(&#39;application_data&#39;, &#39;input_image&#39;, &#39;input_image.jpg&#39;), frame)
# 运行验证
results, verified = verify(model, 0.5, 0.5)
print(verified)

if cv2.waitKey(10) &amp; 0xFF == ord(&#39;q&#39;):
break
cap.release()
cv2.destroyAllWindows()

打印结果如下：
[array([[9.938484e-09]], dtype=float32),
array([[0.00011181]], dtype=float32),
array([[4.0544733e-06]], dtype=float32),
array([[3.6490118e-07]], dtype=float32),
array([[1.779369e-07]], dtype=float32),
array([[0.15224604]], dtype=float32),
array([[2.0296879e-05]], dtype=float32),
数组([[7.9831276e-05]], dtype=float32),
数组([[2.3284203e-05]], dtype=float32),
数组([[8.0619594e-07]], dtype=float32),
数组([[1.0691416e-06]], dtype=float32),
数组([[1.9231505e-08]], dtype=float32),
数组([[2.243531e-05]], dtype=float32),
数组([[6.483703e-07]], dtype=float32),
数组([[6.656185e-07]], dtype=float32),
array([[4.8954314e-07]], dtype=float32),
array([[9.550116e-08]], dtype=float32),
array([[1.305056e-07]], dtype=float32),
array([[4.187218e-09]], dtype=float32),
array([[3.8443446e-08]], dtype=float32),
array([[5.9630083e-09]], dtype=float32),
array([[1.1699244e-06]], dtype=float32),

我知道保存模型没有问题，因为当我在原始输入上测试重新加载的模型与原始模型时，它们具有相同的输出。
对于给定的输入（两次都是我的一帧），大多数结果应该远高于 0.5。我不明白到底出了什么问题。顺便说一句，这段代码主要来自 YT 教程：https://www.youtube.com/watch?v=FNHLVRJ1HU4&amp;list=PLgNJO2hghbmhHuhURAGbe6KWpiYZt0AMH&amp;index=8]]></description>
      <guid>https://stackoverflow.com/questions/79196054/why-does-my-siamese-model-not-work-on-verification-data</guid>
      <pubDate>Sat, 16 Nov 2024 21:07:31 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow/Keras 模型的 SHAP force_plot 中出现 InvalidArgumentError：切片索引超出范围</title>
      <link>https://stackoverflow.com/questions/79195478/invalidargumenterror-in-shap-force-plot-for-tensorflow-keras-model-slice-index</link>
      <description><![CDATA[我正在使用 TensorFlow/Keras 二元分类模型并使用 SHAP 来解释单个预测。但是，当我尝试生成力图时，我遇到了以下错误：
# 导入 SHAP
import shap

# 确保 data_for_prediction 具有正确的形状
data_for_prediction_reshaped = data_for_prediction.reshape(1, -1)

# 为 DeepExplainer 提供背景数据
background = X_train[:100] # 使用来自训练数据的 100 个样本作为背景

# 初始化 DeepExplainer
explainer = shap.DeepExplainer(model, background)

# 计算 SHAP 值
shap_values = explainer.shap_values(data_for_prediction_reshaped)

# 生成力图
shap.initjs()
shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction_reshaped)

错误：
InvalidArgumentError：{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} 切片索引 1 的维度 0 超出范围。 [Op:StridedSlice] 名称：strided_slice/

其他详细信息：

该模型是具有以下架构的 Keras Sequential 模型：
• 具有 ReLU 激活的多个密集层。
• 每个密集层后都有一个 Dropout 层。
• 用于二元分类的具有 S 形激活的输出层。

背景数据：
• X_train[:100] 是我预处理的训练数据（NumPy 数组）的一部分。

预测输入：

• data_for_prediction_reshaped 是重塑为 (1, n_features) 的单个样本。

形状：

• shap_values[1].shape：SHAP 值的输出形状（针对第 1 类）。
• data_for_prediction_reshaped.shape：将输入特征重塑为 (1, n_features)。


问题：

在此上下文中，“切片索引 1 的维度 0 超出范围”错误是什么意思？
我应该如何调整代码以确保 shap.force_plot 能够与 SHAP 和 TensorFlow/Keras 模型正确配合使用？
对于此用例，我应该注意 SHAP 和 TensorFlow/Keras 之间是否存在特定的兼容性问题？
]]></description>
      <guid>https://stackoverflow.com/questions/79195478/invalidargumenterror-in-shap-force-plot-for-tensorflow-keras-model-slice-index</guid>
      <pubDate>Sat, 16 Nov 2024 15:38:25 GMT</pubDate>
    </item>
    <item>
      <title>coremltools 错误：ValueError：perm 的长度应与 rank(x) 相同：3 != 2</title>
      <link>https://stackoverflow.com/questions/79153512/coremltools-error-valueerror-perm-should-have-the-same-length-as-rankx-3</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79153512/coremltools-error-valueerror-perm-should-have-the-same-length-as-rankx-3</guid>
      <pubDate>Sun, 03 Nov 2024 19:49:49 GMT</pubDate>
    </item>
    <item>
      <title>反馈管理器需要具有单一签名推理的模型</title>
      <link>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</link>
      <description><![CDATA[我在尝试运行机器运行模型时遇到了此错误，该模型应该为驾驶员困倦检测项目提供支持
W0000 00:00:1715924294.765512 2256 inference_feedback_manager.cc:114] 
反馈管理器需要具有单一签名推理的模型。
禁用对反馈张量的支持。

模型架构如下：
#**MODEL**
from keras.layers import BatchNormalization
model = tf.keras.models.Sequential()
# 输入形状是图像的所需大小 145 x 145，颜色为 3 个字节

# 这是第一个卷积
model.add(Conv2D(16, 3,activation=&#39;relu&#39;, input_shape=X_train.shape[1:]))
model.add(BatchNormalization())
model.add(MaxPooling2D())
tf.keras.layers.Dropout(0.3)

# 第二个卷积
model.add(Conv2D(32, 5,activation=&#39;relu&#39;))
model.add(BatchNormalization())
model.add(MaxPooling2D())
tf.keras.layers.Dropout(0.3)

# 第三次卷积
model.add(Conv2D(64, 10,activation=&#39;relu&#39;))
model.add(BatchNormalization())
model.add(MaxPooling2D())
tf.keras.layers.Dropout(0.3)

# 第四次卷积
model.add(Conv2D(128, 12,activation=&#39;relu&#39;))
model.add(BatchNormalization())

# 将结果展平以输入到 DNN
model.add(Flatten())
model.add(Dense(128,activation=&#39;relu&#39;))
model.add(Dropout(0.25))
model.add(Dense(64,activation=&#39;relu&#39;))
# 仅有 1 个输出神经元。
model.add(Dense(1,activation=&#39;sigmoid&#39;))

model.compile(loss=&quot;binary_crossentropy&quot;,metrics=[&quot;accuracy&quot;],optimizer=Adam(lr=0.001))
history = model.fit(train_generator,epochs=10,batch_size=32,validation_data=test_generator)

# 定义服务签名
input_signature = [
tf.TensorSpec(shape=[None,145,145,3],dtype=tf.float32,name=&#39;input_tensor&#39;)
]

@tf.function(input_signature=input_signature)
defserving_fn(inputs):
return model(inputs)

export_dir =&#39;E:\system project\project&#39;
tf.saved_model.save(serving_fn, export_dir)

# 加载模型进行推理
loaded_model = tf.saved_model.load(&#39;my_model.keras&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</guid>
      <pubDate>Fri, 17 May 2024 05:59:50 GMT</pubDate>
    </item>
    <item>
      <title>使用形状值分析模型时，刻度标签中出现字形错误</title>
      <link>https://stackoverflow.com/questions/77637695/glyph-errors-in-tick-labels-when-using-shap-values-to-analysis-my-model</link>
      <description><![CDATA[我正在使用 python 中的 shap 包为我的模型重新创建一些图形。其中之一是瀑布图，它来自我遵循的手册，使用以下代码生成（完整代码太长，请查看手册）。
shap.waterfall_plot(shap_explainer_values[4652]) 
但是，我的图表缺少减号，并显示警告消息“当前字体缺少字形 8722 (\N{MINUS SIGN})”。

stackoverflow 上有很多与此问题相关的问题，都可以使用 解决
plt.rcParams[&#39;axes.unicode_minus&#39;] = False

但是，我的不能。有人能帮忙解决这个问题吗？
我也试过 shutil.rmtree(matplotlib.get_cachedir())。]]></description>
      <guid>https://stackoverflow.com/questions/77637695/glyph-errors-in-tick-labels-when-using-shap-values-to-analysis-my-model</guid>
      <pubDate>Mon, 11 Dec 2023 05:54:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 Google ML Kit 在 Flutter 中进行人脸检测</title>
      <link>https://stackoverflow.com/questions/75332789/face-detection-in-flutter-using-google-ml-kit</link>
      <description><![CDATA[我正在开发一款应用程序，主屏幕上会自动打开一个实时摄像头。
在这里我需要检测面部。
我对如何集成 ML 套件感到困惑。
我必须注册 firebase 吗？？？
我尝试使用 google ml kit，但出现太多错误。]]></description>
      <guid>https://stackoverflow.com/questions/75332789/face-detection-in-flutter-using-google-ml-kit</guid>
      <pubDate>Fri, 03 Feb 2023 07:42:23 GMT</pubDate>
    </item>
    <item>
      <title>如何实现 log_softmax() 来以更快的速度和更高的数值稳定性计算其值（和梯度）？</title>
      <link>https://stackoverflow.com/questions/61567597/how-is-log-softmax-implemented-to-compute-its-value-and-gradient-with-better</link>
      <description><![CDATA[各种框架和库（例如 PyTorch 和 SciPy）提供了用于计算 log(softmax()) 的特殊实现，该实现速度更快且数值更稳定。但是，我无法在这些包中找到此函数 log_softmax() 的实际 Python 实现。
有人可以解释这是如何实现的吗？或者，能给我指出相关的源代码吗？]]></description>
      <guid>https://stackoverflow.com/questions/61567597/how-is-log-softmax-implemented-to-compute-its-value-and-gradient-with-better</guid>
      <pubDate>Sat, 02 May 2020 23:18:14 GMT</pubDate>
    </item>
    <item>
      <title>如何正确地将不平衡的数据集拆分为训练集和测试集？</title>
      <link>https://stackoverflow.com/questions/57229775/how-can-i-properly-split-imbalanced-dataset-to-train-and-test-set</link>
      <description><![CDATA[我有一个航班延误数据集，在采样之前尝试将该数据集拆分为训练集和测试集。准时情况约占总数据的 80%，延误情况约占 20%。
通常，机器学习中训练集和测试集的大小比例为 8:2。但数据太不平衡了。因此，考虑到极端情况，大多数训练数据都是准时情况，而大多数测试数据都是延误情况，准确率会很差。
所以我的问题是如何正确将不平衡的数据集拆分为训练集和测试集？]]></description>
      <guid>https://stackoverflow.com/questions/57229775/how-can-i-properly-split-imbalanced-dataset-to-train-and-test-set</guid>
      <pubDate>Sat, 27 Jul 2019 06:34:52 GMT</pubDate>
    </item>
    <item>
      <title>检测物体异常</title>
      <link>https://stackoverflow.com/questions/47829065/detecting-anomalies-in-objects</link>
      <description><![CDATA[假设我有一个 json 对象数组。
{ firstName: John, Children: [&quot;Maria&quot;,&quot;Alfred&quot;], marriage: false }
{ firstName: George, Children: [&#39;**zoekerbergen alfonso the second**&#39;,&#39;Harvey&#39;], marriage: false }

{ firstName: Hary, Children: [&quot;Sam&quot;,&quot;Obama&quot;], marriage: false }

通常情况下，子项都是一个由单词组成的小数组。
Zoekerbergen alfonso the second 却是一个异常。
有没有办法学习对象的模式，然后检测出诸如此类的异常，比如一个人有 1000 个孩子？]]></description>
      <guid>https://stackoverflow.com/questions/47829065/detecting-anomalies-in-objects</guid>
      <pubDate>Fri, 15 Dec 2017 09:11:55 GMT</pubDate>
    </item>
    </channel>
</rss>