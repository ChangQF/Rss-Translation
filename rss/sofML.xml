<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 14 Apr 2024 07:54:53 GMT</lastBuildDate>
    <item>
      <title>无法解释优化器标识符：<keras.src.optimizers.adam.Adam 对象位于 0x7d8646d22b00></title>
      <link>https://stackoverflow.com/questions/78323015/could-not-interpret-optimizer-identifier-keras-src-optimizers-adam-adam-object</link>
      <description><![CDATA[我正在使用这样的模型训练数据集
导入tensorflow为tf
从tensorflow.keras.optimizers导入Adam

优化器 = Adam(learning_rate=2e-5)

# 编译模型（使用优化器）
model.compile(优化器=优化器,
              损失=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              指标=[&#39;准确性&#39;])


# 训练模型
model.fit（train_inputs，train_labels，epochs=epochs，batch_size=batch_size）

它返回此错误：
ValueError：无法解释优化器标识符：
optimizer.adam 但它无法正常工作]]></description>
      <guid>https://stackoverflow.com/questions/78323015/could-not-interpret-optimizer-identifier-keras-src-optimizers-adam-adam-object</guid>
      <pubDate>Sun, 14 Apr 2024 07:12:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 rf.fit() 时尝试在 pyspark 中使用随机森林时出错</title>
      <link>https://stackoverflow.com/questions/78322361/error-trying-to-use-random-forest-in-pyspark-when-using-rf-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78322361/error-trying-to-use-random-forest-in-pyspark-when-using-rf-fit</guid>
      <pubDate>Sun, 14 Apr 2024 00:30:15 GMT</pubDate>
    </item>
    <item>
      <title>将数据拆分为训练集、验证集和测试集，ID 不重叠，并且仍然平衡目标类</title>
      <link>https://stackoverflow.com/questions/78322346/splitting-data-into-training-validation-and-test-sets-without-overlapping-ids</link>
      <description><![CDATA[我需要将大型数据集拆分为一定比例的训练集、验证集和测试集，同时确保满足以下条件：

在每组中保留唯一的 ID。任何 ID 不能属于多于一组。
每次数据重组时，训练、验证和测试集中每个级别（“热”、“暖”、“冷”）都需要至少出现一次。

data &lt;- data.frame(ID = c(001, 001, 001,
                           002, 002, 002, 002,
                           003, 003, 003, 003,
                           004, 004, 004, 004, 004, 004,
                           005, 005, 005, 005, 005,
                           006, 006, 006, 006,
                           007, 007, 007,
                           008, 008,
                           009, 009,
                           010, 010, 010),
                   var1 = c(0102, 0210, 0405,
                            0318, 0629, 1201,0101,
                            0923、0702、0710、0801、
                            0203、0501、1204、0516、0112、1005、
                            1101、1125、1020、0112、0310、
                            0203、0401、0607、0811、
                            1010、1212、0707、
                            0430, 0428,
                            1030, 1008,
                            0501, 0511, 0601),
                   var2 = c(“冷”, “冷”, “冷”,
                            “温暖”、“温暖”、“温暖”、“温暖”、
                            “冷”、“冷”、“冷”、“冷”、
                            “温暖”、“温暖”、“温暖”、“温暖”、“温暖”、“温暖”、
                            “热”、“热”、“热”、“热”、“热”、
                            “冷”、“冷”、“冷”、“冷”、
                            “热”、“热”、“热”、
                            “温暖”、“温暖”、
                            “热”、“热”、
                            “冷”、“冷”、“冷”））

我尝试使用数据分割包 caret(fx = createDataPartition()) 和 splitTools (fx = partition()) 以及 dplyr 采样函数，但它们应用的分组可确保每个 ID 出现在所有集合中。 
减少数据集是可以的。以下是由现有 Stack Overflow 问题引导的众多尝试之一：
赋值 &lt;- 数据 %&gt;%
        选择（ID，var2）%&gt;%
        不同的(ID) %&gt;%
        行式() %&gt;%
        mutate(Group=sample(c(“验证”,“训练”,“测试”), 1,
                             概率 = c(0.70, 0.20, 0.10)))
数据%&gt;%
  left_join（作业，数据，by =“ID”）

这种尝试忽略了概率论点*没有设置比例。它还不能确保所有级别都出现在训练、验证和测试集中。]]></description>
      <guid>https://stackoverflow.com/questions/78322346/splitting-data-into-training-validation-and-test-sets-without-overlapping-ids</guid>
      <pubDate>Sun, 14 Apr 2024 00:19:39 GMT</pubDate>
    </item>
    <item>
      <title>无法训练具有多个输出的 keras 模型</title>
      <link>https://stackoverflow.com/questions/78322340/can-not-train-keras-model-with-multiple-outputs</link>
      <description><![CDATA[我正在创建一个具有多个不同形状输出的 keras 模型，因为 model.fit 方法不允许我传递 y 值的列表或字典。如果重要的话，模型会拍一张脸的照片，找出几个特征，并尝试猜测这个人的名字。
模型定义：
输入 = tf.keras.Input(shape=(1024, 1024, 3))

稠密_1 = tf.keras.layers.Dense(8192)(输入)
密集_2 = tf.keras.layers.Dense(4096)(密集_1)
race_dense = tf.keras.layers.Dense(512)(dense_2)
性别_密度 = tf.keras.layers.Dense(512)(dense_2)
eye_distance_dense = tf.keras.layers.Dense(512)(dense_2)
name_dense1 = tf.keras.layers.Dense(4096)(输入)
name_dense2 = tf.keras.layers.Dense(2048)(name_dense1)
种族 = tf.keras.layers.Dense(1, name=&quot;race&quot;)(race_dense)
性别 = tf.keras.layers.Dense(1, name=“性别”)(gender_dense)
eye_distance = tf.keras.layers.Dense(1, name=&quot;eye_distance&quot;)(eye_distance_dense)
name_t = tf.keras.layers.Dense(32, name=“名称”)(name_dense2)

模型= tf.keras.Model（输入=输入，输出=[种族，性别，眼睛距离，姓名]）
model.compile(优化器=&#39;亚当&#39;,
              损失={&#39;race&#39;: &#39;sparse_categorical_crossentropy&#39;,
                    &#39;性别&#39;: &#39;sparse_categorical_crossentropy&#39;,
                    &#39;eye_distance&#39;: &#39;sparse_categorical_crossentropy&#39;,
                    &#39;名称&#39;：&#39;sparse_categorical_crossentropy&#39;}，
              指标=[&#39;准确性&#39;])

培训：
model.fit(np.array([图像]).astype(np.float32), ([
                    [比赛],
                    [性别],
                    [眼睛距离]，
                    [填充名称]
]))

我尝试过的 Y 值：
&lt;前&gt;&lt;代码&gt;[
                    [比赛],
                    [性别],
                    [眼睛距离]，
                    [填充名称]
]

和
&lt;前&gt;&lt;代码&gt;{
                    “种族”：[种族]，
                    “性别”：[性别]，
                    “眼睛距离”：[眼睛距离]，
                    “名称”：[填充名称]
}

无论我做什么，它总是会给我一个类似的错误：
ValueError: 无法找到可以处理输入的数据适配器：, ( 包含类型 {&#39;(&quot;})&#39;}) 的值的列表
]]></description>
      <guid>https://stackoverflow.com/questions/78322340/can-not-train-keras-model-with-multiple-outputs</guid>
      <pubDate>Sun, 14 Apr 2024 00:15:42 GMT</pubDate>
    </item>
    <item>
      <title>了解梯度提升中的模型选择</title>
      <link>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</link>
      <description><![CDATA[包含问题的图片
我目前正在研究梯度增强模型，并且遇到了一种我不确定的情况。在我的模型的第一阶段，拟合了决策树，这由模型的阶跃函数外观表示。
但是，当我检查第一阶段的残差时，它们似乎表现出二次模式。这促使我考虑在第二阶段使用 2 次多项式模型。
但我很困惑，因为问题陈述建议在第二阶段使用与第一阶段相同类型的模型（即决策树）。
决策树能否捕获残差中的二次模式？或者，尽管问题陈述提出了建议，但我应该在第二阶段考虑不同类型的模型？
任何关于如何处理这种情况的澄清将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</guid>
      <pubDate>Sat, 13 Apr 2024 23:38:22 GMT</pubDate>
    </item>
    <item>
      <title>使用推荐引擎为两个用户推荐一部电影</title>
      <link>https://stackoverflow.com/questions/78321965/using-recommendation-engine-to-recommend-a-movie-for-two-users</link>
      <description><![CDATA[我使用 torch 和 Fastai 来训练数据并得出用户权重与物品权重。有了经过训练的数据，使用两个用户权重的组合向一对用户推荐电影的最佳方式是什么？是否像取一对用户的 n 个参数权重的平均值然后使用这些权重和余弦相似度函数找到最佳项目一样简单？我是机器学习和数据科学的新手，所以如果这是一个愚蠢的问题，我深表歉意。
movie_factors = learn.model.i_weight.weight
user_factors = learn.model.u_weight.weight

#随机选择两个用户
user1_factors = user_factors[43].data.cpu().numpy()
user2_factors = user_factors[54].data.cpu().numpy()

# 计算user1_factors和user2_factors的平均值
avg_u_factors = torch.from_numpy(np.array((user1_factors + user2_factors) / 2)).to(movie_factors.device)

距离 = nn.CosineSimilarity(dim=1)(movie_factors, avg_u_factors)
idx = distances.argsort(降序=True)[1]
dls.classes[&#39;标题&#39;][idx]
]]></description>
      <guid>https://stackoverflow.com/questions/78321965/using-recommendation-engine-to-recommend-a-movie-for-two-users</guid>
      <pubDate>Sat, 13 Apr 2024 20:41:42 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 pytorch 训练机器学习多项式回归模型</title>
      <link>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch</link>
      <description><![CDATA[我想将数据绘制到 plt.scatter 表单中，但是当我尝试填充它时，它只是说 x 和 y 的大小不同，而且我还挤压了它们仅一维，以便更容易绘制，但仍然不起作用。
这是情节机制：
#使用 matplotlib.pyplot 中的散点图 (x,y) 可视化数据
defplot_predictions(train_features=X_train,
                     train_labels=y_train,
                     test_features=X_test,
                     测试标签=y_测试，
                     预测=无）：
    plt.figure(figsize=(10,7))

    plt.scatter(X_train, y_train, c=“g”, label=“训练数据”)

    plt.scatter(X_test, y_test, c=“b”, label=“测试数据”)

    如果预测不是 None：
        plt.scatter（test_features，预测，c =“r”，标签=“预测”）

    plt.legend(prop={“大小”: 14})

绘图预测（）

#这里尝试解决问题
Predictions_reshape=y_preds.squeeze(dim=1)
labels_reshape=y_train.squeeze(dim=1)
打印（len（y_train），len（y_preds））
打印（labels_reshape.shape，predictions_reshape.shape）

labels_reshape=y_train.detach().numpy()
Predictions_reshape=y_preds.detach().numpy()
图_预测（标签_重塑，预测=预测_重塑）

&lt;块引用&gt;
ValueError：x 和 y 的大小必须相同

我尝试压缩张量，使它们只有一个暗淡，并且我还检查了镜头是否相同，确实如此。]]></description>
      <guid>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch</guid>
      <pubDate>Sat, 13 Apr 2024 20:23:01 GMT</pubDate>
    </item>
    <item>
      <title>ML 查找四边形的角点</title>
      <link>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</link>
      <description><![CDATA[伙计们！我的任务是使用 ML 模型找到四边形形状的 4 个角点。有时四边形的一个角度会丢失（例如页面的折叠角度）。
首先，我尝试使用 MobileNetV3Small 作为主干进行图像分割，因为模型应该小而快。效果很好，但找到角落仍然是一个问题。我尝试按照 官方 keras 关键点检测等示例查找图像的关键点， medium 教程，以及许多其他来源，但似乎没有什么对我有用。我已经尝试修改它们很多次了。测试和验证的损失函数都会下降，但输出甚至不接近所需的位置。也尝试过类似以下的方法：
def conv(模型, 大小, conv2d_kernel, dilation_rate=(1, 1), pooling_size=(2, 2)):
    model.add(Conv2D(大小, conv2d_kernel, dilation_rate=dilation_rate))
    model.add(激活(&#39;relu&#39;))
    model.add(MaxPooling2D(pool_size=max_pooling))
    模型.add(Dropout(0.1))

def 密集（模型，单位）：
    model.add(密集(单位))
    model.add(激活(&#39;relu&#39;))
    模型.add(Dropout(0.1))

模型=顺序（）
model.add(InputLayer(形状=(224, 224, 3)))

转换（模型，大小=32，conv2d_kernel=（2, 2））
转换（模型，大小=64，conv2d_kernel=（3, 3））
转换（模型，大小=128，conv2d_kernel=（3, 3））

模型.add(压平())
密集（模型，20）
密集（模型，20）

model.add(密集(8))
model.compile(优化器=RMSprop(),
              损失=损失.MeanSquaredLogarithmicError(),
              指标=[metrics.MeanAbsoluteError()])

还尝试了像 (8) 和 (4,2) 这样的输出形状，但似乎没有任何效果。任何帮助将不胜感激。
PS：还忘记添加数据集注释正确，或者至少这是我在绘图上看到的。还尝试将坐标标准化为 0 和 1 之间。我的输入是 (224,224,3)。]]></description>
      <guid>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</guid>
      <pubDate>Sat, 13 Apr 2024 20:06:34 GMT</pubDate>
    </item>
    <item>
      <title>如何修剪unet模型</title>
      <link>https://stackoverflow.com/questions/78321877/how-to-pruning-an-unet-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78321877/how-to-pruning-an-unet-model</guid>
      <pubDate>Sat, 13 Apr 2024 20:03:54 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pytest 和假设进行可视化</title>
      <link>https://stackoverflow.com/questions/78321735/using-pytest-and-hypothesis-for-visualization</link>
      <description><![CDATA[我正在使用albumentation库进行图像增强，我也在为每个类似的旋转编写测试用例应该在50 - 90度之内，Blur=blur_limit min：3 max：99，我如何可视化我的测试用例在哪里未能使用假设
带有假设可视化的 pytest]]></description>
      <guid>https://stackoverflow.com/questions/78321735/using-pytest-and-hypothesis-for-visualization</guid>
      <pubDate>Sat, 13 Apr 2024 19:08:00 GMT</pubDate>
    </item>
    <item>
      <title>sklearn DummyClassifier 的预测不正确</title>
      <link>https://stackoverflow.com/questions/78320892/incorrect-prediction-from-sklearn-dummyclassifier</link>
      <description><![CDATA[我正在尝试对学校项目的数据集执行虚拟分类。这个想法是为了了解不同政党发表演讲的频率。我的想法是按以下方式编写此代码：
from sklearn.dummy import DummyClassifier
将 pandas 导入为 pd
导入bz2


以 bz2.open(“data/ch3/speeches-201718.json.bz2”) 作为源：
    Speechs_201718 = pd.read_json（来源）

以 bz2.open(“data/ch3/speeches-201819.json.bz2”) 作为源：
    Speechs_201819 = pd.read_json（来源）


训练数据、测试数据 = 演讲_201718、演讲_201819

train_partys_count = Training_data[&#39;party&#39;].value_counts()
test_partys_count = test_data[&#39;party&#39;].value_counts()
dummy_clf = DummyClassifier(策略=“most_frequent”)

X = train_party_count
y = train_party_count.index
dummy_clf.fit(X.值, y)
打印（X）
打印（y）

test_parties_count.index = pd.CategoricalIndex(test_parties_count.index,categories=train_parties_count.index,ordered=True)
X_test = test_partys_count.sort_index()
打印（X_测试）
pred_mfc = dummy_clf.predict(X_test.values)

print(&quot;Urval av prediktioner [0-4]: &quot;, pred_mfc[:5])


我得到以下输出：
在此处输入图像描述
正如您所看到的，预测应该是 S，但结果却是 C，什么可能是不正确的？
我尝试以多种方式定义训练和测试数据，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78320892/incorrect-prediction-from-sklearn-dummyclassifier</guid>
      <pubDate>Sat, 13 Apr 2024 14:26:18 GMT</pubDate>
    </item>
    <item>
      <title>我可以重新训练 AutoModelForSequenceClassification 以生成文本吗？</title>
      <link>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</link>
      <description><![CDATA[我的目标是微调 Mistral 7b 以编写短意识流（文本完成，而不是遵循指令）。
我有一个大型数据库（100 万行），其中包含从互联网上抓取的短文本。我手动将 15k 行标记为 good (1k) 和 bad（其余 14k）示例。我的计划是训练 AutoModelForSequenceClassification在这些示例上标记其他 985k 行。
通过这种方式，我希望收集大约 20k 意识流的好例子来微调 Mistral 7b。
但仅对good示例进行微调并不会使用bad示例中的信息，这些示例的数量要多得多。因此，我正在考虑使用 Mistral 7b 作为 AutoModelForSequenceClassification 的基本模型（遵循 这篇 Medium 文章），然后重新训练生成的 AutoModelForSequenceClassification 以进行文本补全。这需要移除分类头并添加新的/重新训练的 LoRA 组件。
您认为这可行吗？这是否会削弱模型（例如，需要重新学习语法），或者这是否是将坏反例的信息合并到文本生成中的有效方法？或者至少为 LoRA 文本生成微调提供一个良好的初始化点？]]></description>
      <guid>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</guid>
      <pubDate>Sat, 06 Apr 2024 11:32:55 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tfidfvectorizer 的功能从英语修改为西班牙语</title>
      <link>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</link>
      <description><![CDATA[我有一个 TfidfVectorizer 模型，该模型经过英语文本数据的训练来预测英语通话中的情绪。我想针对西班牙语文本调整此 TfidfVectorizer，以便我可以将其与使用原始英语 TfidfVectorizer 训练的现有 XGBoost 模型一起使用。我的目标是在将功能从英语转换为西班牙语的同时保留现有的权重，例如将“谢谢”翻译为西班牙语。致“谢谢”，并重复使用旧的权重。本质上，我想应用相同的 TfidfVectorizer，但修改了功能名称。
这些功能已从英语翻译为西班牙语，并且 TfidfVectorizer 已针对英语文本进行了训练。我需要一种方法来构建一个新的 TfidfVectorizer，它融合了旧的权重和新的西班牙语特征，而无需重新拟合模型或将整个文本语料库翻译成西班牙语。你能推荐一种Python方法来实现这一点吗？请添加相关的Python代码。]]></description>
      <guid>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</guid>
      <pubDate>Wed, 27 Mar 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中使用 Transformers.pipeline 进行微调 BERT 模型推理时，是否应该使用 model.eval() ？</title>
      <link>https://stackoverflow.com/questions/76388696/should-i-use-model-eval-when-using-transformers-pipeline-for-inference-with-a</link>
      <description><![CDATA[使用 Trainer() 训练 Transformer 模型时，文档显示了以下用法：
model = AutoModelForSequenceClassification.from_pretrained(“bert-base-cased”, num_labels=5)

教练=教练（
    型号=型号，
    参数=训练参数，
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset，
    计算指标=计算指标，
）

如果您选中 model.training 标志，默认情况下它会设置为 false，但 Trainer 有一个调用 model 的逻辑.train() 将其设置为 True，这是有道理的。
使用此微调模型进行推理时，您可以利用 transformers.pipeline，它接受模型对象作为参数。但是，管道没有检查模型是否处于训练模式的逻辑。我没有在源代码中找到它，并且在文档中的任何地方都没有看到它。当我使用管道进行预测时，结果不确定，这是模型未处于评估模式的另一个指标。
生成器 = 管道(
                “某个任务”，
                型号=型号，
                分词器=分词器，
                聚合策略=聚合策略，
                忽略标签=[],
            ）

Generator(“Example”) # 返回分数 X
Generator(“Example”) # 返回分数 Y

# 但如果在创建管道对象之前使用 model.eval()
Generator(“Example”) # 返回分数 X
Generator(“Example”) # 返回分数 X

我应该在 pipeline 中使用模型之前调用 model.eval() 还是应该 pipeline 自行处理它，但由于某种原因不是吗？]]></description>
      <guid>https://stackoverflow.com/questions/76388696/should-i-use-model-eval-when-using-transformers-pipeline-for-inference-with-a</guid>
      <pubDate>Fri, 02 Jun 2023 09:06:27 GMT</pubDate>
    </item>
    <item>
      <title>我想要一个 python 脚本将洋葱图像的背景更改为黑色，该怎么做？</title>
      <link>https://stackoverflow.com/questions/75859536/i-want-a-python-script-to-change-the-background-to-black-of-a-image-of-onion-ho</link>
      <description><![CDATA[我正在尝试将洋葱图像的背景颜色更改为黑色
我尝试使用 opencv 和 Pixellib 在 python 中编写代码，但它不起作用，我希望得到一些帮助来改变这一点]]></description>
      <guid>https://stackoverflow.com/questions/75859536/i-want-a-python-script-to-change-the-background-to-black-of-a-image-of-onion-ho</guid>
      <pubDate>Mon, 27 Mar 2023 19:10:07 GMT</pubDate>
    </item>
    </channel>
</rss>