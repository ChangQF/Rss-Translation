<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 15 Jan 2025 01:14:52 GMT</lastBuildDate>
    <item>
      <title>LSTM 自动编码器效果很差</title>
      <link>https://stackoverflow.com/questions/79356691/lstm-autoencoder-very-poor-results</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79356691/lstm-autoencoder-very-poor-results</guid>
      <pubDate>Tue, 14 Jan 2025 23:45:14 GMT</pubDate>
    </item>
    <item>
      <title>理解 PDP、ICE 和 ALE 值：负中心值的解释 [关闭]</title>
      <link>https://stackoverflow.com/questions/79356236/understanding-pdp-ice-and-ale-values-interpretation-of-negative-centered-valu</link>
      <description><![CDATA[我无法理解部分依赖图 (PDP)、个体条件期望 (ICE)和累积局部效应 (ALE)的概念。具体来说，我对中心 PDP 值或中心 ALE 值为负数的含义感到困惑。为什么我们要将这些值与特征的平均效果进行比较？有人能帮我解释以下示例吗？
当中心 PDP 值或中心 ALE 值为负数时意味着什么？为什么要将其与特征的平均效果进行比较？
我试图理解部分依赖图 (PDP)和个体条件期望 (ICE)的数学定义。据我所知，对于 PDP 和 ICE，我们将一个特征固定在特定值，同时将其他特征保持在数据集中的原始值。对于 PDP，我们取各个预测的平均值以获得全局值。但是，当曲线居中时，我很难解释它。具体来说，当我们减去 PDP 值的平均效应时，曲线从 0 开始。但是当曲线低于零时，我们该如何解释它，特别是在分类问题的背景下？
例如，如果某个特征的中心 PDP 曲线低于零，是否意味着该特征对目标类的预测概率有负面影响？这与基线（平均效应）有何关系，对模型的预测意味着什么？
有人可以解释如何解释中心 PDP 和 ICE 曲线吗，特别是在分类场景中？此外，这种解释与回归问题有何不同？]]></description>
      <guid>https://stackoverflow.com/questions/79356236/understanding-pdp-ice-and-ale-values-interpretation-of-negative-centered-valu</guid>
      <pubDate>Tue, 14 Jan 2025 19:53:28 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习算法的逐步方法[关闭]</title>
      <link>https://stackoverflow.com/questions/79356061/stepwise-way-of-using-machine-learning-algorithms</link>
      <description><![CDATA[
如何使用数据集
如何找到它们，即使网站已经使用过。
-设计测验算法
将数据集映射到测验算法以预测职业。
快速学习的有效方法。

我和我的朋友决定使用霍兰德代码进行技术职业预测。为此，我们需要使用像 knn 这样的机器学习算法，但我们需要合并数据集？但我们不知道如何做到这一点。您能提供指导吗？您是否有其他方法可以解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79356061/stepwise-way-of-using-machine-learning-algorithms</guid>
      <pubDate>Tue, 14 Jan 2025 18:42:46 GMT</pubDate>
    </item>
    <item>
      <title>我需要训练一个多类模型，但我有一个小数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/79355992/i-need-to-train-a-multiclass-model-but-i-have-a-small-dataset</link>
      <description><![CDATA[我有一个包含两列的 Excel 文件，一列包含短语之类的文本，另一列告诉我从“CS1”到“CS8”的分类。文本如下
&quot;NE PAGTO PROVENTOS APOSENTADORIA ESPECIAL SERVIDORES SAÚDE, NOV/2024. REF. FATURA 033/2024. INCLUI REFORMA DE ESCOLAS.&quot;

我已经清理了其他文件，文件总共有 72 个文本，其中 df.shape = (72, 2)。
准确率保持在 50% 以下。但我需要更高。
文件 clean_text.py：
import re

def clean_text(text):
text = re.sub(r&#39;\d{1,4}/\d{4}&#39;, &#39;&#39;, text)
text = re.sub(r&#39;\d+&#39;, &#39;&#39;, text)
text = re.sub(r&#39;[^\w\s]&#39;, &#39;&#39;, text)
text = text.lower()
return text

文件 main.py：
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import顺序
从 tensorflow.keras.layers 导入 Dense、Dropout、Input
从 tensorflow.keras.optimizers 导入 Adam
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
从 sklearn.model_selection 导入 train_test_split
从 sklearn.preprocessing 导入 LabelEncoder
从 sklearn.metrics 导入 Classification_report、Accuracy_score
从 transformers 导入 TFAutoModel、AutoTokenizer
导入 joblib
将 pandas 导入为 pd
从 nltk.corpus 导入停用词
导入 re
从 clean_text 导入 clean_text

df = pd.read_excel(&quot;DADOS PARA CLASSIFICAÇÃO MULTICLASSE.xlsx&quot;, sheet_name=&quot;TREINAMENTO&quot;)
df[&#39;EMPENHO&#39;] = df[&#39;EMPENHO&#39;].apply(clean_text)
descriptions = df[&#39;EMPENHO&#39;].tolist()
labels = df[&#39;CLASSE SINTETICA&#39;].tolist()

print(f&quot;Amostras: {df.shape}&quot;)

label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels)

vect = TfidfVectorizer()
X = vect.fit_transform(descriptions).toarray()

X_train, X_test, y_train, y_test = train_test_split(X, labels_encoded, test_size=0.2, random_state=42)

model = Sequential([
输入(shape=(X_train.shape[1],)),
Dense(128, 激活=&#39;relu&#39;),
Dropout(0.3),
Dense(64, 激活=&#39;relu&#39;),
Dropout(0.3),
Dense(len(label_encoder.classes_), 激活=&#39;softmax&#39;)
])

model.compile(optimizer=Adam(learning_rate=1e-4), loss=&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

accuracy = 0
while accuracy &lt; 0.90:
print(&quot;训练模型...&quot;)
emp_train = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, verbose=0)

y_pred = np.argmax(model.predict(X_test), axis=-1)
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;准确率：{accuracy * 100:.2f}%&quot;)

joblib.dump(vect, &quot;vectorizer.pkl&quot;)
joblib.dump(label_encoder, &quot;label_encoder.pkl&quot;)
model.save(&quot;empenho_model.keras&quot;)

print(&quot;训练模型并计算结果成功了！”）

我尝试使用 BERT 和 PyTorch，但这种方式对我来说更好。]]></description>
      <guid>https://stackoverflow.com/questions/79355992/i-need-to-train-a-multiclass-model-but-i-have-a-small-dataset</guid>
      <pubDate>Tue, 14 Jan 2025 18:16:11 GMT</pubDate>
    </item>
    <item>
      <title>加载 MIT-BIH 心律失常数据库（无需 wfdb 包）</title>
      <link>https://stackoverflow.com/questions/79355429/load-mit-bih-arrhythmia-database-without-wfdb-package</link>
      <description><![CDATA[我打算使用这个数据集，但无论我如何努力搜索，我都找不到文件中数据的格式或结构。我发现的最重要的事情是每隔两个字节就有一个 h33。我在哪里可以找到有关此内容的文档？我找不到注释与这些数据文件的关系。]]></description>
      <guid>https://stackoverflow.com/questions/79355429/load-mit-bih-arrhythmia-database-without-wfdb-package</guid>
      <pubDate>Tue, 14 Jan 2025 15:00:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 PyTorch 中保存 ViT 模型时不会生成 constants.pkl，在边缘设备上部署时是否需要它？</title>
      <link>https://stackoverflow.com/questions/79355096/why-is-constants-pkl-not-generated-when-saving-a-vit-model-in-pytorch-and-is-it</link>
      <description><![CDATA[我训练了一个 Vision Transformer (ViT) 模型进行分类，并使用以下 PyTorch 代码保存了该模型：
torch.save(model, &quot;vit_model.pth&quot;)
当我尝试将保存的模型集成到 Android 应用程序中时，我在运行时遇到了以下错误：
无法启动活动 ComponentInfo{com.test.package/com.test.package.MainActivity}：java.lang.RuntimeException：com.facebook.jni.CppException：PytorchStreamReader 无法定位文件 constants.pkl：找不到文件
我所做的：

我将 .pth 模型文件转换为 zip 文件以检查其内容，我注意到文件中不存在 constants.pkl。
我搜索了有关constants.pkl，但我找不到关于为什么它没有生成或它在这种情况下的作用的明确解释。

我的问题：

为什么使用 torch.save() 保存 PyTorch 模型时没有生成 constants.pkl？
在边缘设备（例如 Android）上部署模型是否需要 constants.pkl？
如果不需要 constants.pkl，我该如何将我的模型集成到 Android 应用程序中而不会遇到此错误？
如果需要 constants.pkl，我该如何生成它或修改我的模型保存过程以包含它？

其他信息：

模型：在 PyTorch 中训练的 Vision Transformer (ViT)。
Android 集成：使用PyTorch Android 库。
应用程序尝试加载模型文件时似乎出现错误。

我需要什么：

明确解释 constants.pkl 的作用以及它是否是 Android 上 PyTorch 模型部署的必需文件。

正确保存模型并将其集成到 Android 应用程序中以避免此问题的步骤或代码示例。

]]></description>
      <guid>https://stackoverflow.com/questions/79355096/why-is-constants-pkl-not-generated-when-saving-a-vit-model-in-pytorch-and-is-it</guid>
      <pubDate>Tue, 14 Jan 2025 13:07:19 GMT</pubDate>
    </item>
    <item>
      <title>使用视觉变换器进行图像分类的准确率较低</title>
      <link>https://stackoverflow.com/questions/79354623/low-accuracy-using-vision-transformers-for-image-classification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79354623/low-accuracy-using-vision-transformers-for-image-classification</guid>
      <pubDate>Tue, 14 Jan 2025 10:07:15 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何工具可以将任何其他数据集格式转换为 sam2 格式以进行微调？[关闭]</title>
      <link>https://stackoverflow.com/questions/79354345/are-there-any-tools-to-convert-from-any-other-dataset-format-to-sam2-format-for</link>
      <description><![CDATA[我在 cvat 中有一个标记的数据集，但 cvat 不支持将数据卸载为 SAM2 格式。有没有可用的自动转换工具？
我可以使用 roboflow，但我有无法上传到第三方资源的数据]]></description>
      <guid>https://stackoverflow.com/questions/79354345/are-there-any-tools-to-convert-from-any-other-dataset-format-to-sam2-format-for</guid>
      <pubDate>Tue, 14 Jan 2025 08:14:24 GMT</pubDate>
    </item>
    <item>
      <title>stable_baselines3：为什么比较 ep_info_buffer 与评估时奖励不匹配？</title>
      <link>https://stackoverflow.com/questions/79353843/stable-baselines3-why-the-reward-does-not-match-comparing-ep-info-buffer-vs-eva</link>
      <description><![CDATA[我正在使用 stable_baselines3 库，这时我发现了一些意想不到的东西。
这里有一个简单的代码来重现这个问题：
import gymnasium as gym

from stable_baselines3 import DQN

env = gym.make(&quot;CartPole-v1&quot;)

model = DQN(&quot;MlpPolicy&quot;, env, verbose=0, stats_window_size=100_000)
model.learn(total_timesteps=100_000)

看看最后一集的奖励：
print(model.ep_info_buffer[-1])


{&#39;r&#39;: 409.0, &#39;l&#39;: 409, &#39;t&#39;: 54.87983

但是如果我使用以下代码评估模型：
obs, info = env.reset()
total_reward = 0
while True:
action, _states = model.predict(obs, deterministic=True)
obs, reward, termed, truncated, info = env.step(action)
total_reward = total_reward + reward
if termed or truncated:
obs, info = env.reset()
break

print(&quot;total_reward {}&quot;.format(total_reward))


total_reward 196.0

我得到了不同的奖励，这是我没有预料到的。
我预计会得到与 409 相同的奖励model.ep_info_buffer[-1]。
为什么会有这种差异？.ep_info_buffer 与每集奖励不同吗？]]></description>
      <guid>https://stackoverflow.com/questions/79353843/stable-baselines3-why-the-reward-does-not-match-comparing-ep-info-buffer-vs-eva</guid>
      <pubDate>Tue, 14 Jan 2025 02:14:32 GMT</pubDate>
    </item>
    <item>
      <title>如何检查随机森林模型是否过度拟合？</title>
      <link>https://stackoverflow.com/questions/79327542/how-to-check-if-the-model-is-overfitting-for-random-forest</link>
      <description><![CDATA[我已经为数据集实现了随机森林，并且平衡了数据，我使用了 80-10-10、70-15-15、60-20-20 和 80-20 方法。我还使用了特征重要性，并在 41 个独立特征中使用了 10 个 imp 特征、15 个 imp 特征、24 个 imp 特征和 34 个 imp 特征。所有上述方法的平均召回率为 95.8%，平均准确率为 96.6%，精确率为 97%。交叉验证召回率（我主要关注召回率）为 95.5%。
我使用训练数据对训练数据本身进行预测，得到了 99.8%
我还使用了热图并删除了 3 个高度相关的特征，但我得到了 80-10-10 的相同分数（热图之后）。
我的模型是否过度拟合？如何检查是否过度拟合？]]></description>
      <guid>https://stackoverflow.com/questions/79327542/how-to-check-if-the-model-is-overfitting-for-random-forest</guid>
      <pubDate>Fri, 03 Jan 2025 19:56:33 GMT</pubDate>
    </item>
    <item>
      <title>DMIR 的 XMorpher 模型 - 数据集问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/79180321/xmorpher-model-for-dmir-dataset-problem</link>
      <description><![CDATA[我正在尝试运行 GitHub 项目 XMorpher (https://github.com/Solemoon/XMorpher/tree/main)，但作者没有提供正确的数据集？他在代码中使用了：
 train_labeled_unlabeled_dir = &#39;data/train_labeled_unlabeled&#39;
train_unlabeled_unlabeled_dir = &#39;data/train_unlabeled_unlabeled&#39;
test_labeled_labeled_dir = &#39;data/test&#39;

但实际上数据文件夹仅包含 0_1.mat 文件，在 Matlab 中打开时，该文件包含 2 个变量：
fix_img # 大小：144x144x128 (int16)
mov_img # 大小：144x144x128 (int16)

由于一张图片包含 5308416 个字节，我无法看到变量的值... 还有其他方法可以运行此模型或我可以使用其他数据集吗？]]></description>
      <guid>https://stackoverflow.com/questions/79180321/xmorpher-model-for-dmir-dataset-problem</guid>
      <pubDate>Tue, 12 Nov 2024 08:25:50 GMT</pubDate>
    </item>
    <item>
      <title>Vertex AI：Automl-tabular 模板不断给我一个错误</title>
      <link>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</link>
      <description><![CDATA[我正在尝试使用 Google 的 AutoML 产品 (VertexAI) 构建机器学习模型。
我已成功上传我的数据集 - 见下图。

但是，当我尝试使用 AutoML 模板为表格回归创建管道运行时，管道失败。我将在 VertexAI 上展示步骤，我只是使用默认设置而不进行任何更改：





我运行的第一个管道失败了。


我将调试 json 粘贴到 ChatGPT 中。它告诉我尝试将机器类型从 n1-standard-8 或 n1-highmem-8 更改为 n1-standard-4。我试过了，但管道仍然失败。我还确保计算服务已启用正确的设置。
]]></description>
      <guid>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</guid>
      <pubDate>Mon, 11 Nov 2024 11:41:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不应该在同一层使用多个激活函数？[关闭]</title>
      <link>https://stackoverflow.com/questions/63125782/why-shouldnt-we-use-multiple-activation-functions-in-the-same-layer</link>
      <description><![CDATA[我见过的所有应用神经网络的示例或案例都有一个共同点 - 它们在属于特定层的所有节点中使用特定类型的激活函数。
据我所知，每个节点都使用非线性激活函数来了解数据中的特定模式。如果是这样，为什么不使用多种类型的激活函数？
我确实找到了一个链接，它基本上说如果我们每层只使用一个激活函数，管理网络会更容易。还有其他好处吗？]]></description>
      <guid>https://stackoverflow.com/questions/63125782/why-shouldnt-we-use-multiple-activation-functions-in-the-same-layer</guid>
      <pubDate>Tue, 28 Jul 2020 01:28:55 GMT</pubDate>
    </item>
    <item>
      <title>机器学习还是决策树用于工作匹配？</title>
      <link>https://stackoverflow.com/questions/43319120/machinelearning-or-decisiontree-for-job-matching</link>
      <description><![CDATA[我正在开发一个工作匹配应用程序，我想知道在元素之间进行匹配以获得最佳结果的最佳方法是什么？
在我看来，这是通过决策树，因为我们已经知道元素的结构和预期结果。
但是，机器学习会是一种替代解决方案吗？或者这样做毫无价值？
我可能错了，但对我来说，机器学习对于对乍一看没有明显共同点的数据进行排序是有效的，对吗？
谢谢你的建议！]]></description>
      <guid>https://stackoverflow.com/questions/43319120/machinelearning-or-decisiontree-for-job-matching</guid>
      <pubDate>Mon, 10 Apr 2017 09:10:48 GMT</pubDate>
    </item>
    <item>
      <title>Matlab 中 Libsvm SVR 训练的数据格式</title>
      <link>https://stackoverflow.com/questions/19163090/data-format-for-libsvm-svr-training-in-matlab</link>
      <description><![CDATA[我有两个与 LIBSVM 中的数据输入相关的问题。

我是否需要将数据格式化为稀疏格式才能在 matlab 中输入 svr libsvm？
在将数据输入训练器之前，我是否需要对数据进行规范化？

我正在训练 svr，但没有做任何这些，即使格式化，我也得到了相同的结果。正如 libsvm 文档中提到的，当我们为 OCTAVE 执行数据格式化时，会使用数据格式化，因为只需运行 train.py 和 test.py 即可自动运行所有内容。但在 matlab 中我不确定。
有人可以澄清一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/19163090/data-format-for-libsvm-svr-training-in-matlab</guid>
      <pubDate>Thu, 03 Oct 2013 15:25:13 GMT</pubDate>
    </item>
    </channel>
</rss>