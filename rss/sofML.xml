<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 01:09:22 GMT</lastBuildDate>
    <item>
      <title>我需要高级机器学习和 LLM 课程的推荐</title>
      <link>https://stackoverflow.com/questions/78863935/i-need-recommendations-for-advanced-machine-learning-and-llm-courses</link>
      <description><![CDATA[我正在寻找一些课程，但找不到提供优质应用和实践课程（最好是免费的）的平台。
有人可以推荐我一门涵盖分类和回归高级技术的高级机器学习课程吗？
此外，有没有关于法学硕士 (LLM) 的入门到中级课程？
感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78863935/i-need-recommendations-for-advanced-machine-learning-and-llm-courses</guid>
      <pubDate>Mon, 12 Aug 2024 23:45:07 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML 二元分类模型的最终预测准确率非常低</title>
      <link>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</guid>
      <pubDate>Mon, 12 Aug 2024 23:32:18 GMT</pubDate>
    </item>
    <item>
      <title>为赌场制定排班解决方案 [关闭]</title>
      <link>https://stackoverflow.com/questions/78863813/working-on-a-shift-scheduling-solution-for-a-casino</link>
      <description><![CDATA[我在一家赌场工作，我们需要在每班次为赌桌游戏分配发牌人。整个晚上游戏都结束了，那些已结束游戏的发牌人会把其他开始游戏的发牌人送回家。这可能是复杂的情况，因为并非所有发牌人都拥有同等的技能并掌握所有游戏。
例如，一个发牌人可能正在玩掷骰子游戏并需要回家，但唯一空闲的发牌人不知道如何发掷骰子。在这种情况下，需要采取多种措施才能让掷骰子发牌人回家。我想建立一个算法来分析所有开放的游戏并就可以采取哪些措施提出建议。
还涉及其他不同的细节，例如开始时间、让替补发牌人让其他发牌人休息、尽可能不要让发牌人移动太多，以及能够选择下一个要回家的发牌人。
我们目前手动执行此操作，这对我们的经理来说非常低效且压力很大。过去几个月我一直在学习 Python，但如果这更适合另一种语言，我也愿意尝试。
我知道这是一个复杂的问题，只是想寻求一些建议，看看下一步应该重点学习什么，比如哪种机器学习最好，创建用户界面等。谢谢！
我已经研究过二分匹配和绘图作为可能的解决方案，但不确定如何实现它]]></description>
      <guid>https://stackoverflow.com/questions/78863813/working-on-a-shift-scheduling-solution-for-a-casino</guid>
      <pubDate>Mon, 12 Aug 2024 22:47:03 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个掩模进行医学图像分割，然后进行逐像素分类？</title>
      <link>https://stackoverflow.com/questions/78863682/how-to-go-for-medical-image-segmentation-with-multiple-masks-and-then-doing-pixe</link>
      <description><![CDATA[我正在研究一个问题，其中我得到了训练图像，每个图像都有两个用于不同类别的掩码。我应该如何分割图像，然后进行像素分类以获得输出图像，其中 0 表示背景，1 和 2 表示两个类别？
我尝试组合掩码，然后将掩码和相应的图像输入分割模型，但不知何故我失败了。我是否应该组合掩码，因为我们还需要在输出中对像素进行分类。]]></description>
      <guid>https://stackoverflow.com/questions/78863682/how-to-go-for-medical-image-segmentation-with-multiple-masks-and-then-doing-pixe</guid>
      <pubDate>Mon, 12 Aug 2024 21:37:57 GMT</pubDate>
    </item>
    <item>
      <title>加载权重时出现意外键错误</title>
      <link>https://stackoverflow.com/questions/78863529/getting-unexpected-keys-error-while-loading-weights</link>
      <description><![CDATA[import torch
from PIL import Image
import numpy as np
from effdet import get_efficientdet_config, EfficientDet

config = get_efficientdet_config(&#39;tf_efficientdet_d0&#39;)
model = EfficientDet(config, pretrained_backbone=True)
model.eval()

当我运行此程序时，我收到错误
加载预训练权重时发现意外键（bn2.bias、bn2.num_batches_tracked、bn2.running_mean、bn2.running_var、bn2.weight、classifier.bias、classifier.weight、conv_head.weight）。如果模型正在调整，则可能会出现这种情况。

我研究了一下，发现这是由于 timm builder 造成的，但没有找到任何解决方案，所以请大家帮我解决这个问题。
我想加载 efficientdet 权重，但结果出现了意外的键错误]]></description>
      <guid>https://stackoverflow.com/questions/78863529/getting-unexpected-keys-error-while-loading-weights</guid>
      <pubDate>Mon, 12 Aug 2024 20:42:04 GMT</pubDate>
    </item>
    <item>
      <title>为一系列点的图形创建邻接矩阵</title>
      <link>https://stackoverflow.com/questions/78863456/creating-an-adjacency-matrix-for-a-graph-of-points-in-a-series</link>
      <description><![CDATA[我想创建一种机制，使用邻接矩阵在一条指令中乘以多个 PyTorch 张量。这些点以串联方式相互连接，但有一个小问题。假设这是一个表示 T 点串联连接的邻接矩阵：
adj_mat = torch.tensor([
[0, 1, 0, 0, 0], # T1 连接到 T2
[1, 0, 1, 0, 0], # T2 连接到 T1 和 T3
[0, 1, 0, 1, 0], # T3 连接到 T2 和 T4
[0, 0, 1, 0, 1], # T4 连接到 T3 和 T5
[0, 0, 0, 1, 0], # T5 连接到 T4
], dtype = torch.float32)

我有多个数量需要对输入张量进行算术运算：
K = torch.tensor([
[1.0, 2.0, 3.0, 4.0, 0.0],
[1.0, 2.0, 3.0, 4.0, 0.0]
], dtype=torch.float32)
C = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0], dtype = torch.float32)
S = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0], dtype = torch.float32)

val = torch.tensor([[1.0, 2.0, 4.0, 8.0, 16.0],
[5.0, 10.0, 15.0, 20.0, 5.0]], dtype = torch.float32)

dev = torch.tensor([11, 30], dtype = torch.float32)

计算如下，遍历 Tensor 的每一行（其中每行将并行计算，希望如此）：
T1 = T1 + (C(T1) * S(T1) * (dev + (T2-T1) * K(T1))
T2 = T2 + (C(T2) * S(T2) * ((T1-T2) * K(T1) + (T3-T2) * K(T2))
T3 = T3 + (C(T3) * S(T3) * ((T2-T3) * K(T2) + (T4-T3) * K(T3))
T4 = T4 + (C(T4) * S(T4) * ((T3-T4) * K(T3)+ (T5-T4) * K(T4))

其中 T1-T5 的值将来自 val 数组。我尝试了类似的方法，首先检查加权差异，即 ((T2-T3) * K(T2) + (T4-T3) * K(T3)) 是否计算正确
T_diffs = val.unsqueeze(1) - val.unsqueeze(2)
T_diffs_weighted = T_diffs * adj_mat.unsqueeze(0) * K.unsqueeze(1)
T_diffs_summed = torch.sum(T_diffs_weighted , dim = 2)
print(&quot;weighted Differences:&quot;, T_diffs_weighted )
print(&quot;Summed Differences:&quot;, T_diffs_summed )

我得到的输出是：
加权差异：张量（[[[ 0., 2., 0., 0., 0.],
[ -1., 0., 6., 0., 0.],
[ -0., -4., 0., 16., 0.],
[ -0., -0., -12., 0., 0.],
[ -0., -0., -0., -32., 0.]],

[[ 0., 10., 0., 0., 0.],
[ -5., 0., 15., 0., -0.],
[ -0., -10., 0., 20., -0.],
[ -0., -0., -15., 0., -0.],
[ 0., 0., 0., 60., 0.]]])

而所需输出为1:
加权差异：张量（[[[ 0., 1., 0., 0., 0.],
[ -1., 0., 6., 0., 0.],
[ 0., -4., 0., 16., 0.],
[ 0., 0., -12., 0., 0.],
[ 0., 0., 0., -32., 0.]],

[[ 0., 5., 0., 0., 0.],
[ -5., 0., 15., 0., -0.],
[ 0., -10., 0., 20., -0.],
[ 0., 0., -15., 0., -0.],
[ 0., 0., 0., 60., 0.]]])

求和差值：张量（[[ 1., 1., 10., -16., 0.],
[ 0., 5., 0., 65., 0.]])

提取的值将是一列，例如，这意味着 T1 将对应于第 0 列。我似乎无法正确地乘以张量 K。我能够正确地计算方程的 K 值，但不能同时计算两者。
最后，如果还有其他方法可以执行此乘法或方程，我们将不胜感激。顺便说一下，这些方程是运行在 Nvidia GPU 上的机器学习模型的一部分。我对 PyTorch 的 [un]squeeze() 方法还比较陌生，这就是为什么这有点难以理解。
1与方程的预期数学输出相比，加权差分矩阵中值的符号可能被反转。但我关注的是与张量 K 的乘法。]]></description>
      <guid>https://stackoverflow.com/questions/78863456/creating-an-adjacency-matrix-for-a-graph-of-points-in-a-series</guid>
      <pubDate>Mon, 12 Aug 2024 20:18:41 GMT</pubDate>
    </item>
    <item>
      <title>ML-Agents：当我的游戏对象的任何部分发生碰撞时，代理为空</title>
      <link>https://stackoverflow.com/questions/78863425/ml-agents-agent-is-null-when-any-part-of-my-game-object-collides</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863425/ml-agents-agent-is-null-when-any-part-of-my-game-object-collides</guid>
      <pubDate>Mon, 12 Aug 2024 20:07:45 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 Torch 使用 4 个 GPU 进行训练：torch.distributed.elastic.multiprocessing.api</title>
      <link>https://stackoverflow.com/questions/78863216/unable-to-train-with-4-gpus-using-torch-torch-distributed-elastic-multiprocessi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863216/unable-to-train-with-4-gpus-using-torch-torch-distributed-elastic-multiprocessi</guid>
      <pubDate>Mon, 12 Aug 2024 19:01:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras/Tensorflow 中实现“生成器历史” GAN</title>
      <link>https://stackoverflow.com/questions/78863055/how-to-implement-generator-history-gan-in-keras-tensorflow</link>
      <description><![CDATA[生成对抗网络 (GAN) 是一种非常有趣的生成模型，但训练起来却很困难。 本文提供了一种提高稳定性的方法：在第 2.3 节中，他们指出

对抗训练的一个问题是鉴别器网络仅关注最新的精炼图像。

并且

[…] 我们引入了一种通过使用精炼图像的历史记录而不是仅使用当前小批量中的图像来更新鉴别器来提高稳定性的方法。

这只是意味着我们必须保留生成器生成的图像的历史记录（例如最后 50 张图像）并随机将它们显示给鉴别器。
这种方法也用于CycleGAN。
我的问题是
如何通过覆盖 Keras 模型类来实现使用图像历史更新鉴别器的方法？事实上，我想通过这种方法扩展 keras CycleGAN 实现（在此处找到）。
我在本教程中找到了一个使用
train_on_batch

的实现。但是，我无法使用 Keras 教程中描述的
model.train

方法成功完成相同的操作。]]></description>
      <guid>https://stackoverflow.com/questions/78863055/how-to-implement-generator-history-gan-in-keras-tensorflow</guid>
      <pubDate>Mon, 12 Aug 2024 18:06:25 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的 Sums 包无法进行标记</title>
      <link>https://stackoverflow.com/questions/78862511/sums-package-failing-to-tokenize-in-python</link>
      <description><![CDATA[我使用以下代码在 Python 中总结我的文本。代码正在 Jupyter Notebook 中运行。我已经使用 pip 命令安装了 sumy。
pip install sumy nltk
python -m nltk.downloader punkt

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from io import StringIO

# 定义要总结的文本
text = &quot;&quot;&quot;
自然语言处理 (NLP) 是人工智能的一个领域，专注于通过自然语言实现计算机与人类之间的互动。NLP 的最终目标是使计算机能够以有价值和有意义的方式理解、解释和响应人类语言。
NLP 用于应用算法来识别和提取自然语言规则，从而将非结构化语言数据转换为计算机可以理解的形式。当提供文本时，计算机可以采用多种不同的方法来处理它。算法可以是基于规则的方法，也可以是基于机器学习的方法。
“”“”

# 使用 StringIO 模拟文件类对象
text_io = StringIO(text)

# 解析文本
parser = PlaintextParser.from_file(text_io, Tokenizer(&quot;english&quot;))

# 初始化 LSA 摘要器
summarizer = LsaSummarizer()

# 生成摘要（您可以调整句子数量）
summary = summaryr(parser.document, sentences_count=2)

# 打印摘要
for sentence in summary:
print(sentence) 

当我运行程序时，我收到以下错误：
ame)
662 def find_class(self, module, name):
663 # 禁止每个函数
--&gt; 664 引发 pickle.UnpicklingError(f&quot;全局 &#39;{module}.{name}&#39; 被禁止&quot;)

UnpicklingError: 全局 &#39;copy_reg._reconstructor&#39; 被禁止 

有什么想法！]]></description>
      <guid>https://stackoverflow.com/questions/78862511/sums-package-failing-to-tokenize-in-python</guid>
      <pubDate>Mon, 12 Aug 2024 15:37:15 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 nltk 函数</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>访问 Azure 机器学习中计划的创建日期</title>
      <link>https://stackoverflow.com/questions/78862179/acessing-the-creation-date-of-a-schedule-in-azure-machine-learning</link>
      <description><![CDATA[我试图访问 AML 中计划的创建/定义日期。我尝试了文档和一些解决方法，但到目前为止还没有成功。如果可以访问端点或已发布管道的创建日期，那么它也会解决我的问题。有人知道我该怎么做吗？提前谢谢。
我已经尝试访问上述每个类的属性，但无法获取有关创建时间的信息。我唯一访问过的日期是与计划对象关联的运行日期。]]></description>
      <guid>https://stackoverflow.com/questions/78862179/acessing-the-creation-date-of-a-schedule-in-azure-machine-learning</guid>
      <pubDate>Mon, 12 Aug 2024 14:23:17 GMT</pubDate>
    </item>
    <item>
      <title>我如何知道镜头中的某人是否对齐了轮廓？</title>
      <link>https://stackoverflow.com/questions/78860543/how-can-i-know-if-someone-in-camera-aligns-an-outline</link>
      <description><![CDATA[我正在做一个项目，这个项目与实时摄像头的身体测量有很大关系，但为了校准，我需要人站在屏幕中间，直接适应框架尺寸。为此，我使用了一个透明的人形，除了人形的边界外，其他地方都是透明的。我如何检查人是否符合轮廓？
我尝试在屏幕中间使用 png 并从中绘制轮廓并检查地标，但它总是最终检查一个绘制原始图像边界的正方形。而且，即使一个人站得很近，只用一半的身体来适应它，它也能正常工作。
效果很差。我该如何改进？
现在我的代码片段如下所示：
KadirCoordinates = {
&#39;NOSE&#39;: (320, 36),
&#39;LEFT_SHOULDER&#39;: (274, 100),
&#39;RIGHT_SHOULDER&#39;: (372, 104),
&#39;LEFT_HEEL&#39;: (296, 459),
&#39;RIGHT_HEEL&#39;: (343, 459)
}

points_to_collect = [&#39;NOSE&#39;, &#39;LEFT_SHOULDER&#39;, &#39;RIGHT_SHOULDER&#39;, &#39;LEFT_HEEL&#39;, &#39;RIGHT_HEEL&#39;] #臀部和脚踝处有血迹
current_point_index = 0

if result.pose_landmarks:
landmarks = result.pose_landmarks.landmark

detected_points = {}

for landmark in mp_pose.PoseLandmark:
x = int(landmarks[landmark].x * frame_width)
y = int(landmarks[landmark].y * frame_height)
if landmark.name in points_to_collect:
detected_points[landmark.name] = (x, y)
cv2.circle(blended_frame, (x, y), 5, (0, 255, 0), -1)
alignment_score = 0
threshold = 85 # 降低对齐公差阈值

for key in reference_coordinates:
outline_point = reference_coordinates[key]
detected_point =detected_points.get(key, None)
ifdetected_point:
distance = np.linalg.norm(np.array(outline_point) - np.array(detected_point))
#print(f&quot;Distance for {key}: {distance}&quot;) # 调试信息
if distance &lt; Threshold:
alignment_score += 1 # 根据需要调整阈值

# 计算对齐百分比
alignment_percentage = (alignment_score / len(reference_coordinates)) * 100
cv2.putText(blended_frame, &quot;Alignment score is : {}&quot;.format(alignment_percentage), (50, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)

# 检查对齐，如果对齐则启动计时器
if alignment_percentage &gt;95:
]]></description>
      <guid>https://stackoverflow.com/questions/78860543/how-can-i-know-if-someone-in-camera-aligns-an-outline</guid>
      <pubDate>Mon, 12 Aug 2024 07:55:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在 HuggingFace 中从头开始重新初始化 GPT2 XL？</title>
      <link>https://stackoverflow.com/questions/78859343/how-to-reinitialize-from-scratch-gpt2-xl-in-huggingface</link>
      <description><![CDATA[我试图确认我的 GPT-2 模型是从头开始训练的，而不是使用任何预先存在的预训练权重。这是我的方法：

加载预训练的 GPT-2 XL 模型：我使用 AutoModelForCausalLM.from_pretrained(&quot;gpt2-xl&quot;) 加载预训练的 GPT-2 XL 模型，并计算此模型权重的总 L2 范数。
从头开始初始化新的 GPT-2 模型：然后我使用 GPT2Config 从头开始​​使用自定义配置初始化新的 GPT-2 模型。
比较 L2 范数：我计算预训练模型和新初始化模型的权重的 L2 范数。我的假设是，如果临时模型确实是从随机权重初始化的，那么临时模型的 L2 范数应该比预训练模型小得多。

这是代码片段：
import torch
from transformers import GPT2LMHeadModel, GPT2Config, AutoModelForCausalLM

# 步骤 1：加载预训练的 GPT-2 XL 模型
pretrained_model = AutoModelForCausalLM.from_pretrained(&quot;gpt2-xl&quot;)

# 步骤 2：计算预训练模型权重的 L2 范数
pretrained_weight_norm = 0.0
for param in pretrained_model.parameters():
pretrained_weight_norm += torch.norm(param, p=2).item()

print(f&quot;Total L2预训练模型权重的范数：{pretrained_weight_norm:.2f}&quot;)

# 步骤 3：使用自定义配置从头开始初始化新的 GPT-2 模型
config = GPT2Config(
vocab_size=52000, # 确保这与 tokenizer 的词汇量相匹配
n_ctx=1024, # 上下文窗口大小（模型一次可以看到的 token 数量）
bos_token_id=0, # 序列开始 token
eos_token_id=1, # 序列结束 token
)
model = GPT2LMHeadModel(config)

# 步骤 4：计算刚初始化的模型权重的 L2 范数
scratch_weight_norm = 0.0
for param in model.parameters():
scratch_weight_norm += torch.norm(param, p=2).item()

print(f&quot;从头开始初始化的模型的总 L2 范数：{scratch_weight_norm:.2f}&quot;)

这种方法是否是确认模型是从头开始训练的有效方法？是否存在任何潜在问题或更好的方法来验证模型没有预先存在的学习权重？
看起来正确
~/beyond-scale-language-data-diversity$ /opt/conda/envs/beyond_scale_div_coeff/bin/python /home/ubuntu/beyond-scale-language-data-diversity/playground/test_gpt2_pt_vs_reinit_scratch.py​​
config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 689/689 [00:00&lt;00:00，8.05MB/s]
model.safetensors：100%|████████████████████████████████████████████████████████████████████████████| 6.43G/6.43G [00:29&lt;00:00，221MB/s]
generation_config.json：100%|██████████████████████████████████████████████████████████████████████████████████████| 124/124 [00:00&lt;00:00，1.03MB/s]
预训练模型权重的总 L2 范数：24542.74
从头初始化模型的总 L2 范数：1637.31
（beyond_scale_div_coeff）

cross: https://discuss.huggingface.co/t/how-to-reinitialize-from-scratch-gpt-xl-in-hugging-face-hf/101905
ref: https://github.com/alycialee/beyond-scale-language-data-diversity/issues/18]]></description>
      <guid>https://stackoverflow.com/questions/78859343/how-to-reinitialize-from-scratch-gpt2-xl-in-huggingface</guid>
      <pubDate>Sun, 11 Aug 2024 20:27:07 GMT</pubDate>
    </item>
    <item>
      <title>如果我导入 pyttsx3 库，我的相机不会打开 opencv2。但是没有显示任何错误</title>
      <link>https://stackoverflow.com/questions/78299560/if-i-import-pyttsx3-library-my-camera-is-not-opening-of-opencv2-however-no-erro</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78299560/if-i-import-pyttsx3-library-my-camera-is-not-opening-of-opencv2-however-no-erro</guid>
      <pubDate>Tue, 09 Apr 2024 15:30:19 GMT</pubDate>
    </item>
    </channel>
</rss>