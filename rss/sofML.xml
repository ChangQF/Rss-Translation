<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 15 Dec 2024 18:22:27 GMT</lastBuildDate>
    <item>
      <title>如何为任何数据集创建强大的预处理函数？[关闭]</title>
      <link>https://stackoverflow.com/questions/79282246/how-to-create-a-robust-preprocessing-function-for-any-dataset</link>
      <description><![CDATA[我正在开展一个项目，根据患者的症状预测合适的医生专业。
该项目包括一项功能，研究人员可以上传自己的数据集并使用预先训练的机器学习模型对其进行评估。在对上传的数据进行训练后，将显示准确率、召回率和精确率等结果。
我需要编写一个通用预处理函数，在对模型进行训练之前处理研究人员上传的任何数据集。
到目前为止，我已经使用标签编码和独热编码对分类数据进行编码，但我担心处理具有不同特征的数据集。以下是我预见到的一些挑战：
噪声数据
不正确的数据类型
缺失值
多重共线性
我的问题：

一个预处理函数能否处理任何给定数据集的所有这些问题？
是否有标准技术可以以通用方式检测和解决噪声数据、不正确的类型或缺失值等问题？
我是否应该考虑为不同类型的数据集创建多个预处理管道，或者是否有一种可以根据数据集进行调整的动态方法？
]]></description>
      <guid>https://stackoverflow.com/questions/79282246/how-to-create-a-robust-preprocessing-function-for-any-dataset</guid>
      <pubDate>Sun, 15 Dec 2024 11:46:39 GMT</pubDate>
    </item>
    <item>
      <title>URL 中损坏的访问控制的数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/79282134/dataset-for-broken-access-control-in-url</link>
      <description><![CDATA[我是一名学生，正在接受一个项目任务，该项目涉及使用机器学习检测 URL 中损坏的访问控制（如 IDOR）。我一直在寻找可用于训练机器学习的数据集，但找不到与我的主题最相关的数据集。你们知道我可以在哪里找到数据集吗？
我尝试使用每个相关关键字搜索有关损坏的访问控制。]]></description>
      <guid>https://stackoverflow.com/questions/79282134/dataset-for-broken-access-control-in-url</guid>
      <pubDate>Sun, 15 Dec 2024 10:22:25 GMT</pubDate>
    </item>
    <item>
      <title>StandardScaler 的管道方法是否可以推广到基于树的集成或神经网络？</title>
      <link>https://stackoverflow.com/questions/79281636/does-the-pipeline-approach-with-standardscaler-generalize-to-tree-based-ensemble</link>
      <description><![CDATA[我在 scikit-learn 中使用 Pipeline 将特征缩放与分类器相结合。这对于逻辑回归非常有效，但我很好奇这种方法是否可以有效地推广到更复杂的模型，例如基于树的集成或神经网络。具体来说，这些模型是否需要不同的缩放策略，或者我可以在它们之间一致地应用 StandardScaler？
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score

# 生成样本数据
np.random.seed(42)
X = np.random.rand(200, 5) # 200 个样本，5 个特征
y = np.random.randint(0, 2, 200) # 二进制目标

# 拆分数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 为不同模型定义管道
pipelines = {
&#39;logistic_regression&#39;: Pipeline([
(&#39;scaler&#39;, StandardScaler()),
(&#39;classifier&#39;, LogisticRegression())
]),
&#39;random_forest&#39;: Pipeline([
(&#39;scaler&#39;, StandardScaler()),
(&#39;classifier&#39;, RandomForestClassifier())
]),
&#39;neural_network&#39;: Pipeline([
(&#39;scaler&#39;, StandardScaler()),
(&#39;classifier&#39;, MLPClassifier(max_iter=500))
])
}

# 评估每个模型
for model_name, pipeline in pipelines.items():
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)
print(f&quot;{model_name} 准确率：{accuracy_score(y_test, y_pred)}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/79281636/does-the-pipeline-approach-with-standardscaler-generalize-to-tree-based-ensemble</guid>
      <pubDate>Sun, 15 Dec 2024 00:58:36 GMT</pubDate>
    </item>
    <item>
      <title>获取“TypeError：ufunc‘isnan’不支持输入类型”</title>
      <link>https://stackoverflow.com/questions/79281350/getting-typeerror-ufunc-isnan-not-supported-for-the-input-types</link>
      <description><![CDATA[我正在做一个机器学习项目，在 Jupyter Notebook 上预测电动汽车的价格。
我运行这些单元：
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
cols = [&#39;County&#39;, &#39;City&#39;, &#39;State&#39;, &#39;ZIP Code&#39;, &#39;Model Year&#39;, &#39;Make&#39;, &#39;Model&#39;, &#39;Electric Vehicle Type&#39;, &#39;Clean Alternative Fuel Vehicle (CAFV) Eligibility&#39;]
for col in cols:
le.fit(t[col])
x[col] = le.transform(x[col]) 
print(le.classes_)

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5，random_state = 0)

r2_score(y_test，lm.predict(x_test))

从 sklearn.tree 导入 DecisionTreeRegressor 
regressor = DecisionTreeRegressor(random_state = 0) 
regressor.fit(x_train，y_train)
r2_score(y_test，regressor.predict(x_test))

r2_score(y_train，regressor.predict(x_train))

uv = np.nanpercentile(df2[&#39;Base MSRP&#39;]，[99])[0]*2

df2[&#39;Base MSRP&#39;][(df2[&#39;Base MSRP&#39;]&gt;uv)] = uv

df2 = df2[df2[&#39;Model Year&#39;] != &#39;N/&#39;] # 过滤掉包含 &#39;Model Year&#39; 的行&#39;N/&#39;

for col in cols:
df2[col] = df2[col].replace(&#39;N/&#39;, -1)
le.fit(df2[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

le = preprocessing.LabelEncoder()

cols = [&#39;County&#39;, &#39;City&#39;, &#39;State&#39;, &#39;ZIP Code&#39;, &#39;Model Year&#39;, &#39;Make&#39;, &#39;Model&#39;, &#39;Electric Vehicle Type&#39;, &#39;Clean Alternative Fuel Vehicle (CAFV) Eligibility&#39;]

for col in cols:
le.fit(t[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

我收到此错误：
TypeError回溯（最近一次调用最后一次）
~\AppData\Local\Temp\ipykernel_16424\1094749331.py in &lt;module&gt;
1 for col in cols:
2 le.fit(t[col])
----&gt; 3 df2[col] = le.transform(df2[col])
4 print(le.classes_)

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\preprocessing\_label.py in transform(self, y)
136 return np.array([])
137 
--&gt; 138 返回 _encode(y, uniques=self.classes_)
139 
140 def inverse_transform(self, y):

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\_encode.py in _encode(values, uniques, check_unknown)
185 else:
186 if check_unknown:
--&gt; 187 diff = _check_unknown(values, uniques)
188 if diff:
189 raise ValueError(f&quot;y 包含之前未见过的标签：{str(diff)}&quot;)

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\_encode.py in _check_unknown(values, known_values, return_mask)
259 
260 # 检查 known_values 中的 nans
--&gt; 261 if np.isnan(known_values).any():
262 diff_is_nan = np.isnan(diff)
263 if diff_is_nan.any():

TypeError: ufunc &#39;isnan&#39; 不支持输入类型，并且根据转换规则 &#39;&#39;safe&#39;&#39;，无法将输入安全地强制转换为任何受支持的类型

我尝试了什么？
我尝试使用以下代码：
le = preprocessing.LabelEncoder()
cols = [&#39;County&#39;, &#39;City&#39;, &#39;State&#39;, &#39;ZIP Code&#39;, &#39;Model Year&#39;, &#39;Make&#39;, &#39;Model&#39;, &#39;Electric Vehicle Type&#39;, &#39;Clean Alternative Fuel Vehicle (CAFV) Eligibility&#39;]
for col in cols:
le.fit(t[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

代码给出了具体的错误。
为了解决这个问题，我尝试使用以下代码来插入缺失值（“N/”）而不是删除它：
for col in cols:
le.fit(t[col].fillna(&#39;Missing&#39;)) # 使用“Missing”插入缺失值
df2[col] = le.transform(df2[col].fillna(&#39;Missing&#39;))
print(le.classes_)

但我仍然收到相同的错误。
这是我的笔记本的链接：https://github.com/SteveAustin583/electric-vehicle-price-prediction-revengers/blob/main/revengers.ipynb
以下是数据集的链接：
https://www.kaggle.com/datasets/rithurajnambiar/electric-vehicle-data
如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79281350/getting-typeerror-ufunc-isnan-not-supported-for-the-input-types</guid>
      <pubDate>Sat, 14 Dec 2024 20:23:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么MobileNet V2模型（mobilenet_v2_1.4_224.tflite）的概率总是相同的？</title>
      <link>https://stackoverflow.com/questions/79281349/why-are-the-probabilities-always-the-same-with-mobilenet-v2-model-mobilenet-v2</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79281349/why-are-the-probabilities-always-the-same-with-mobilenet-v2-model-mobilenet-v2</guid>
      <pubDate>Sat, 14 Dec 2024 20:23:10 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法学习和实现集成兼容的对象检测模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/79280938/is-there-way-to-learn-and-implement-ensemble-compatible-object-detection-models</link>
      <description><![CDATA[我是机器学习的新手。我知道检测模型和其他东西的基础知识。我研究了一些分类模型以及如何将它们组合起来。但我不确定如何将其用于多类对象检测模型。特别是 Yolov8/11 和其他一些单次模型。是否有任何代码或资源可以帮助我组合对象检测模型？
我尝试过一些资源，例如这个“https://github.com/ancasag/ensembleObjectDetection”。但我认为我需要一些更简单的解释。特别是关于加权组合技术。]]></description>
      <guid>https://stackoverflow.com/questions/79280938/is-there-way-to-learn-and-implement-ensemble-compatible-object-detection-models</guid>
      <pubDate>Sat, 14 Dec 2024 15:53:18 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Flatten 层与具有动态尺寸的输入一起使用？</title>
      <link>https://stackoverflow.com/questions/79280552/how-to-use-the-flatten-layer-with-an-input-that-has-a-dynamically-sized-dimensio</link>
      <description><![CDATA[我有一个模型，其输入（具有形状（高度、宽度、时间）的图像批次）具有动态大小的维度（时间），该维度仅在运行时确定。但是，Flatten 层需要完全定义的空间维度。代码片段示例：
import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten, Input

# 定义具有未定义维度 (None) 的输入
input_tensor = Input(shape=(None, 256, 256, None, 13))

# 应用 Dense 层（需要完全定义的形状）
x = Flatten()(input_tensor)
x = Dense(10)(x)

# 构建模型
model = tf.keras.models.Model(inputs=input_tensor, output=x)

model.summary()

这会引发错误：
ValueError：应定义 Dense 层输入的最后一个维度。未找到。

如何使用 Flatten 而不是 GlobalAveragePooling3D 等替代方案使其工作？我需要保留所有像素级信息。]]></description>
      <guid>https://stackoverflow.com/questions/79280552/how-to-use-the-flatten-layer-with-an-input-that-has-a-dynamically-sized-dimensio</guid>
      <pubDate>Sat, 14 Dec 2024 11:31:35 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林预测 FPL 球员总得分 [已迁移]</title>
      <link>https://stackoverflow.com/questions/79280539/predicting-fpl-player-total-points-using-random-forest</link>
      <description><![CDATA[我有一个数据集，其中包含英超联赛（2016-2023 年）大约 100k 个比赛周统计数据。我的目标是预测一名球员在某个比赛周/比赛中将获得多少总分。
我将数据分为训练/测试集，其中训练集包含赛季 &lt; 2022 的统计数据，测试集包含赛季 &gt; 的统计数据2022.
为了说明某位球员的当前状态，我计算了过去 3 个比赛周以下变量的滚动平均值：
进球数、助攻数、零封数、失球数、分钟数、自进球数、扑救数、错失点球数、黄牌数、红牌数、扑救数、影响力、创造力、威胁和 ict_index
然后，我使用这些变量和一些其他变量运行随机森林：
was_home、player_team、opponent_team、opponent_strength、element_type（后卫/中场等）
模型如下所示：
rf &lt;- randomForest(
as.formula(paste(target, &quot;~&quot;, paste(predictors, collapse = &quot; + &quot;))),
data = train,
ntree = 500,
mtry = 7,
nodesize = 10,
significance = TRUE)

这样做我只得到 R^2 约为 57%。所以我的问题是这是否正常，或者我的方法是否出错？我想知道我可以在哪里改进模型，机器学习是否是预测总分的好方法？]]></description>
      <guid>https://stackoverflow.com/questions/79280539/predicting-fpl-player-total-points-using-random-forest</guid>
      <pubDate>Sat, 14 Dec 2024 11:25:11 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 警告未找到可见的 GPU，正在将设备设置为 CPU</title>
      <link>https://stackoverflow.com/questions/79280367/xgboost-warning-no-visible-gpu-is-found-setting-device-to-cpu</link>
      <description><![CDATA[系统信息

XGBoost 版本：2.1.3
NVIDIA 驱动程序版本：565.57.01
CUDA 版本：12.6（来自 nvcc）和 12.7（来自 nvidia-smi）
GPU：Tesla T4
操作系统：Ubuntu 24.04
Python 版本：3.11.10
torch.cuda.is_available()：True

尽管系统显示 CUDA 和 GPU 可用，但我遇到了来自 XGBoost 的以下警告：

XGBoost 警告：/workspace/src/context.cc:43：未找到可见的 GPU，将设备设置为CPU。

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79280367/xgboost-warning-no-visible-gpu-is-found-setting-device-to-cpu</guid>
      <pubDate>Sat, 14 Dec 2024 09:12:14 GMT</pubDate>
    </item>
    <item>
      <title>结合 RNN 和 FFN [关闭]</title>
      <link>https://stackoverflow.com/questions/79280265/combine-rnn-and-ffn</link>
      <description><![CDATA[在 FFN 中，我们有一些输入和一些输出，并以此为基础训练模型。在 RNN 中，输入是序列的一段，输出是同一序列的下一个时间步。但是，在我的场景中，我将关节旋转作为输入，将顶点位置作为随时间变化的输出。我不知道如何在 RNN 中处理两个不同的序列（关节旋转和顶点位置）。
我有时间依赖性，并且这两个序列也是相互依赖的。我应该结合使用 FFN 和 RNN 来解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/79280265/combine-rnn-and-ffn</guid>
      <pubDate>Sat, 14 Dec 2024 07:42:00 GMT</pubDate>
    </item>
    <item>
      <title>拟合非线性混合模型 [迁移]</title>
      <link>https://stackoverflow.com/questions/79279411/fitting-a-nonlinear-mixed-model</link>
      <description><![CDATA[我试图拟合一个非线性混合模型 (nLMM)，以测试某些生物的丰度是否受到导致丰度显著增加的事件后的采样期的影响。
数据显示了一条重要的曲线，这些生物的丰度在事件发生后激增（事件发生在采样期：-1 和 1 之间），但随后下降。
我试图构建一个非线性混合模型，但我发现理解如何构建模型非常具有挑战性（例如，model &lt;- lmer(abundance ~ samples_period + (1 | rep), data = data）。我非常感谢任何帮助来确定丰度是否受到采样期的影响。
data &lt;- data.frame(
abundant = c(79, 72, 58, 61, 88, 123, 119, 96, 67, 78, 143, 75, 105, 46, 58, 
127, 173, 181, 67, 120, 64, 30, 49, 47, 104, 83, 146, 118, 53, 
98, 223, 257, 255, 292, 354, 133, 129, 140, 27, 55, 68, 148, 
122, 132, 77, 121, 108, 109),
rep = c(&quot;T1&quot;, &quot;T2&quot;, &quot;T3&quot;, &quot;T1&quot;, &quot;T2&quot;, &quot;T3&quot;, “T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T3”、“T1”、“T2”、“T3”、“
“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“T3”、“T1”、“T2”、“ “T3”, “T1”, “T2”, “T3”, 
“T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”, “T1”, “T2”, “T3”),
sampling_period_consecutive = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 
6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9, 9, 10, 10, 
10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 
14, 14, 15, 15, 15, 16, 16, 16),
采样周期 = c(-5, -5, -5, -4, -4, -4, -3, -3, -3, -2, -2, -2, -1, -1, 
-1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 
6, 11, 11, 11, 22, 22, 22, 34, 34, 34, 46, 46, 58, 
58, 58)
)

]]></description>
      <guid>https://stackoverflow.com/questions/79279411/fitting-a-nonlinear-mixed-model</guid>
      <pubDate>Fri, 13 Dec 2024 19:32:50 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost/XGBRanker 生成概率而不是排名分数</title>
      <link>https://stackoverflow.com/questions/79278625/xgboost-xgbranker-to-produce-probabilities-instead-of-ranking-scores</link>
      <description><![CDATA[我有一个学生考试成绩的数据集，如下所示：
班级 ID 班级规模 学生编号 智商 学习时间 分数
1 3 3 101 10 98
1 3 4 99 19 80
1 3 6 130 3 95
2 4 4 93 5 50
2 4 5 103 9 88
2 4 8 112 12 99
2 4 1 200 10 100 

我想建立一个机器学习模型，尝试使用 IQ 和 Hours_Studied 预测谁将成为班级第一名（即最高 Score），对于任何给定的 Class_ID特征。
由于这是一个排名问题，因此自然的一类学习模型是使用 XGBoost 中的 XGBRanker 或 lightgbm 中的 LGBMRanker。
这是我使用 xgboost 的代码：
from sklearn.model_selection import GroupShuffleSplit
import xgboost as xgb

gss = GroupShuffleSplit(test_size=.40, n_splits=1, random_state = 7).split(df, groups=df[&#39;Class_ID&#39;])

X_train_inds, X_test_inds = next(gss)

train_data = df.iloc[X_train_inds]
X_train = train_data.loc[:, ~train_data.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;,&#39;Score&#39;])]
y_train = train_data.loc[:, train_data.columns.isin([&#39;Score&#39;])]

groups = train_data.groupby(&#39;Class_ID&#39;).size().to_frame(&#39;Class_size&#39;)[&#39;Class_size&#39;].to_numpy()

test_data = df.iloc[X_test_inds]

X_test = test_data.loc[:, ~test_data.columns.isin([&#39;Student_Number&#39;,&#39;Score&#39;])]
y_test = test_data.loc[:, test_data.columns.isin([&#39;Score&#39;])]

model = xgb.XGBRanker( 
tree_method=&#39;hist&#39;,
device=&#39;cuda&#39;,
booster=&#39;gbtree&#39;,
objective=&#39;rank:pairwise&#39;,
enable_categorical=True,
random_state=42, 
learning_rate=0.1,
colsample_bytree=0.9, 
eta=0.05, 
max_depth=6, 
n_estimators=175, 
subsample=0.75 
)

model.fit(X_train, y_train, group=groups, verbose=True)

def predict(model, df):
return model.predict(df.loc[:, ~df.columns.isin([&#39;Class_ID&#39;,&#39;Student_Number&#39;])])

predictions = (X_test.groupby(&#39;Class_ID&#39;)
.apply(lambda x: predict(model, x)))

代码运行良好，具有合理的预测能力。但是，输出是“相关性得分”列表，而不是概率列表。但似乎 XGBRanker 和 LGBMRanker 都没有属性 predict_proba，该属性返回获得班级最高分的概率。
所以我的问题是，有没有办法将 相关性得分 转换为概率，或者是否有其他自然类别的排名模型可以处理此类问题？
编辑在这个问题中，我只关心最终名列前茅的人（或者可能是前三名），所以排名并不是那么重要（例如，知道学生 4 排名第 11 位，学生 8 排名第 12 位并不那么重要），所以我想一种方法是在 xgboost 中使用分类而不是排名。但我想知道还有其他方法吗。]]></description>
      <guid>https://stackoverflow.com/questions/79278625/xgboost-xgbranker-to-produce-probabilities-instead-of-ranking-scores</guid>
      <pubDate>Fri, 13 Dec 2024 14:20:37 GMT</pubDate>
    </item>
    <item>
      <title>模型部署：交叉验证和超参数调整</title>
      <link>https://stackoverflow.com/questions/79275593/model-deployment-cross-validation-and-hyperparameter-tuning</link>
      <description><![CDATA[我正在使用 Prophet（时间序列的元模型），我有一个与模型部署相关的问题，该问题也扩展到其他机器学习算法。因此，我使用了元文档中提供的代码进行超参数调整。它的工作原理类似于网格搜索，并基于交叉验证输出模型中使用的最佳超参数组合。该最佳组合的 RMSE 约为 11.15。因此，考虑到我想部署模型并发送到生产，我应该使用网格搜索提供的超参数组合在整个数据集上重新训练模型，还是应该将使用交叉验证训练的模型发送到生产？

我问这个问题是因为当我使用网格搜索中的超参数在整个数据集上训练模型时，RMSE 比交叉验证的更高（更差）。
]]></description>
      <guid>https://stackoverflow.com/questions/79275593/model-deployment-cross-validation-and-hyperparameter-tuning</guid>
      <pubDate>Thu, 12 Dec 2024 15:01:43 GMT</pubDate>
    </item>
    <item>
      <title>Pyannote：离线加载和应用说话人区分</title>
      <link>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</link>
      <description><![CDATA[我尝试离线使用 Pyannotes 模型。
我是这样加载和应用模型的：
from pyannote.audio import Pipeline

access_token = &#39;xxxxxxxxxxx&#39;

model = Pipeline.from_pretrained(
&quot;pyannote/speaker-diarization-3.1&quot;,
use_auth_token=access_token)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

这样就没问题了。
但是现在我按照离线使用的说明操作：https://github.com/pyannote/pyannote-audio/blob/develop/tutorials/applying_a_pipeline.ipynb
我的目录结构如下：
src-
     |-pyannote_offline_config.yaml
     |-pyannote_pytorch_model.bin
---- YAML ----
version: 3.1.0

pipeline:
name: pyannote.audio.pipelines.SpeakerDiarization
params:
clustering: AgglomerativeClustering
embedding: pyannote/wespeaker-voxceleb-resnet34-LM
embedding_batch_size: 32
embedding_exclude_overlap: true
分段：src/pyannote_pytorch_model.bin
分段批处理大小：32

参数：
聚类：
方法：质心
min_cluster_size：12
阈值：0.7045654963945799
分段：
min_duration_off：0.0

---- 正在加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但结果却是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
好的，下次尝试：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

params = {&#39;clustering&#39;:
{&#39;method&#39;: &#39;centroid&#39;,
&#39;min_cluster_size&#39;: 12,
&#39;threshold&#39;: 0.7045654963945799},
&#39;segmentation&#39;:
{&#39;min_duration_off&#39;: 0.0}}

pipeline = model.instantiate(params)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

pipeline(path_in,
num_speakers=num_speakers).labels()

但结果是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
我不明白问题所在。
如果我这样做，它就会起作用：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;, path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但上传到 gitlab 后，测试管道显示：“无法下载‘pyannote/speaker-diarization-3.1’管道。
这可能是因为管道是私有的或封闭的，因此请确保进行身份验证。访问 https://hf.co/settings/tokens
创建您的访问令牌并重试：
Pipeline.from_pretrained(&#39;pyannote/speaker-diarization-3.1&#39;,
... use_auth_token=YOUR_AUTH_TOKEN)&quot;
因此，似乎我的本地计算机上有一些东西没有通过 pip 安装下载。例如，如果我不使用 yaml 加载它，而只使用 model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;)，它也会起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</guid>
      <pubDate>Thu, 01 Aug 2024 12:28:41 GMT</pubDate>
    </item>
    <item>
      <title>从头开始训练的 Keras Xception 在历史记录中给出了约 100% 的准确率，但在评估时仅预测 1，准确率为 50%</title>
      <link>https://stackoverflow.com/questions/72930709/keras-xception-trained-from-scratch-give-100-accuracy-in-the-history-but-only</link>
      <description><![CDATA[我在 keras 上训练 Xception 模型，没有使用预训练权重来解决二元分类问题，结果出现了非常奇怪的行为。历史图显示训练准确率不断增加，直到达到 100%，而验证准确率始终在 50% 左右，因此看起来是过度拟合，但事实并非如此，因为我检查过，即使在训练集上，它也总是预测（接近）1。
这种行为的原因可能是什么？
这是我用来训练的代码。 x_train_xception 已由 keras.applications.xception.preprocess_input 函数预处理。
我使用相同的代码（除了模型创建之外）来训练预训练的 Xception 模型，效果很好
inLayerX = Input((512, 512, 4))
xceptionModel = keras.applications.Xception(include_top = True, weights=None, input_tensor=inLayerX, classes=1, classifier_activation= &#39;sigmoid&#39;)

xceptionModel.compile(loss= &#39;binary_crossentropy&#39;, metrics = [&#39;accuracy&#39;])

history = xceptionModel.fit(x_train_xception, y_train, batch_size= batch_size, epochs= epochs, validation_data=(x_val_xception, y_val))

_, accTest = xceptionModel.evaluate(x_test_xception, y_test)
_, accVal = xceptionModel.evaluate(x_val_xception, y_val)
_, accTrain = xceptionModel.evaluate(x_train_xception, y_train)
print(&quot;训练准确率 {:.2%}&quot;.format(accTrain))
print(&quot;验证准确率 {:.2%}&quot;.format(accVal))
print(&quot;测试准确率 {:.2%}&quot;.format(accTest))

输出：
2/2 [================================] - 6s 2s/step - 损失： 1.2063 - 准确率：0.5000
1/1 [==============================] - 4s 4s/步 - 损失：1.2960 - 准确率：0.4667
4/4 [================================] - 5s 1s/步 - 损失：1.2025 - 准确率：0.5083
训练准确率 50.83%
验证准确率 46.67%
测试准确率 50.00%

验证和测试准确率在预期之内，但真正困扰我的是训练准确率，从历史记录来看，我预计训练准确率接近 100%。
模型准确率
模型损失]]></description>
      <guid>https://stackoverflow.com/questions/72930709/keras-xception-trained-from-scratch-give-100-accuracy-in-the-history-but-only</guid>
      <pubDate>Sun, 10 Jul 2022 17:58:52 GMT</pubDate>
    </item>
    </channel>
</rss>