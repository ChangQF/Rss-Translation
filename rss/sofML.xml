<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 09 Jun 2024 18:18:32 GMT</lastBuildDate>
    <item>
      <title>搜索具有相似文本的文档</title>
      <link>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</link>
      <description><![CDATA[我有一个包含三个属性的文档：标签、位置和文本。
目前，我正在使用 LangChain/pgvector/embeddings 对它们全部进行索引。
我得到了满意的结果，但我想知道是否有更好的方法，因为我想查找一个或多个具有特定标签和位置的文档，但文本可能会有很大差异，但含义仍然相同。出于这个原因，我考虑使用嵌入/向量数据库。
这是否也是使用 RAG（检索增强生成）来“教”的一个例子LLM 不知道的一些常见缩写？
import pandas as pd

from langchain_core.documents import Document
from langchain_postgres import PGVector
from langchain_postgres.vectorstores import PGVector
from langchain_openai.embeddings import OpenAIEmbeddings

connection = &quot;postgresql+psycopg://langchain:langchain@localhost:5432/langchain&quot;
embeddings = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)
collection_name = &quot;notas_v0&quot;

vectorstore = PGVector(
embeddings=embeddings,
collection_name=collection_name,
connection=connection,
use_jsonb=True,
)

# 开始索引

# df = pd.read_csv(&quot;notes.csv&quot;)
# df = df.dropna() # .head(10000)
# df[&quot;tags&quot;] = df[&quot;tags&quot;].apply(
# lambda x: [tag.strip() for tag in x.split(&quot;,&quot;) if tag.strip()]
# )

# long_texts = df[&quot;Texto Longo&quot;].tolist()
# wc = df[&quot;Centro Trabalho Responsável&quot;].tolist()
# notes = df[&quot;Nota&quot;].tolist()
# tags = df[&quot;tags&quot;].tolist()

# documents = list(
# map(
# lambda x: Document(
# page_content=x[0], metadata={&quot;wc&quot;: x[1], &quot;note&quot;: x[2], &quot;tags&quot;: x[3]}
# ),
# zip(long_texts, wc, notes, tags),
# )
# )

# print(
# [
# vectorstore.add_documents(documents=documents[i : i + 100])
# for i in range(0, len(documents), 100)
# ]
# )
# print(&quot;Done.&quot;)

### END INDEX

### BEGIN QUERY

result = vectorstore.similarity_search_with_relevance_scores(
&quot;EVTD202301222707&quot;,
filter={&quot;note&quot;: {&quot;$in&quot;: [&quot;15310116&quot;]}, &quot;tags&quot;: {&quot;$in&quot;: [&quot;abcd&quot;, &quot;xyz&quot;]}},
k=10, # 结果限制
)

### END QUERY
]]></description>
      <guid>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</guid>
      <pubDate>Sun, 09 Jun 2024 16:40:32 GMT</pubDate>
    </item>
    <item>
      <title>PHP proc_open 与 Python 脚本导致 UnicodeEncodeError</title>
      <link>https://stackoverflow.com/questions/78599045/php-proc-open-with-python-script-causes-unicodeencodeerror</link>
      <description><![CDATA[我尝试使用 proc_open 从 PHP 脚本运行 Python 脚本。Python 脚本在直接从命令行运行时运行良好，但从 PHP 运行时会引发 UnicodeEncodeError。我怀疑问题可能与 PHP 中捕获和处理输出的方式有关，但我不确定如何修复它。
我正在开发一个项目，需要从 PHP 脚本调用 Python 脚本。Python 脚本处理一些数据并打印结果。以下是我使用的 PHP 代码：
&lt;?php

function my_shell_exec($cmd, &amp;$stdout=null, &amp;$stderr=null) {
$proc = proc_open($cmd,[
1 =&gt; [&#39;pipe&#39;,&#39;w&#39;],
2 =&gt; [&#39;pipe&#39;,&#39;w&#39;],
],$pipes);
$stdout = stream_get_contents($pipes[1]);
fclose($pipes[1]);
$stderr = stream_get_contents($pipes[2]);
fclose($pipes[2]);
return proc_close($proc);
}

$output = my_shell_exec(&#39;.\\.venv\\Scripts\\activate &amp;&amp; .\\.venv\\Scripts\\python.exe infer.py&#39;, $stdout, $stderr);
var_dump($output);
var_dump($stdout);
var_dump($stderr);
exit();

PHP 输出：
int(1)
string(183) &quot;初始化模型
模型已存在于 keras-model/model-transventricular-v3.keras 中，跳过模型初始化。
推断图像
(1, 256, 256, 1)
&quot; keras-model\model-transventricular-v3.keras &quot;
&quot;
string(2416) &quot;2024-06-09 22:57:14.361024: I tensorflow/core/util/port.cc:113] oneDNN 自定义操作已启用。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 `TF_ENABLE_ONEDNN_OPTS=0`。
...
回溯（最近一次调用最后一次）：
文件 &quot;D:\path\to\infer.py&quot;，第 220 行，位于 &lt;module&gt;
infer_image(&quot;input.dat&quot;)
文件 &quot;D:\path\to\infer.py&quot;，第 201 行，在 infer_image 中
prediction = model.predict(images)
文件 &quot;C:\path\to\python\lib\encodings\cp1252.py&quot;，第 19 行，在 encode 中
return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: &#39;charmap&#39; 编解码器无法对位置 19-38 中的字符进行编码：字符映射到 &lt;undefined&gt;

直接命令行执行（工作正常）：
(.venv) D:\path\to\project&gt;.\.venv\Scripts\activate &amp;&amp; .\.venv\Scripts\python.exe infer.py
2024-06-09 22:56:04.593392：I tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。
...
初始化模型
模型已存在于 keras-model/model-transventricular-v3.keras 中，跳过模型初始化。
推断图像
(1, 256, 256, 1)
I0000 00:00:1717948579.475089 18516 service.cc:153] StreamExecutor 设备 (0): 主机，默认版本
2024-06-09 22:56:19.530820: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] 禁用 MLIR 崩溃重现器，设置环境变量 `MLIR_CRASH_REPRODUCER_DIRECTORY` 以启用。
I0000 00:00:1717948580.392302 18516 device_compiler.h:188] 使用 XLA 编译集群！此行在进程的整个生命周期内最多记录一次。
1/1 ━━━━━━━━━━━━━━━━━━━━━ 2s 2s/step


Python 脚本 (infer.py):
import os
from keras.models import load_model # type: ignore
# from keras.optimizers import Adam # type: ignore
from dotenv import load_dotenv
import cv2
import numpy as np
import gdown

if __name__ == &#39;__main__&#39;:
if not os.path.exists(&#39;input.dat&#39;):
print(&quot;input.dat not exist&quot;)
exit(0)

print(&quot;Init model&quot;)
init_model()

print(&quot;Infer image&quot;)
infer_image(&quot;input.dat&quot;)

def infer_image(image_filepath):
# 预处理图像
images = preproces(image_filepath)
print(images.shape)

path = os.path.join(&#39;keras-model&#39;, &#39;model-transventricular-v3.keras&#39;)
print(&#39;&quot;&#39;, path, &#39;&quot;&#39;)

# 加载模型
model = load_model(path)

# 预测图像
prediction = model.predict(images)
predictions = np.argmax(prediction, axis=1)

# 进一步处理
]]></description>
      <guid>https://stackoverflow.com/questions/78599045/php-proc-open-with-python-script-causes-unicodeencodeerror</guid>
      <pubDate>Sun, 09 Jun 2024 16:06:09 GMT</pubDate>
    </item>
    <item>
      <title>提高 LSTM 模型对股票价格预测的鲁棒性</title>
      <link>https://stackoverflow.com/questions/78598814/improving-robustness-of-lstm-model-for-stock-price-prediction</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78598814/improving-robustness-of-lstm-model-for-stock-price-prediction</guid>
      <pubDate>Sun, 09 Jun 2024 14:15:44 GMT</pubDate>
    </item>
    <item>
      <title>如何提高多标签分类的准确度得分？</title>
      <link>https://stackoverflow.com/questions/78598665/how-to-improve-accuracy-score-in-multilabel-classification</link>
      <description><![CDATA[我想知道如何在多标签分类问题中提高准确率并降低损失。
当多标签中有两个类时，其准确率较高且损失较低。
from numpy import mean
from numpy import std
from sklearn.datasets import make_multilabel_classification
from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import accuracy_score, hamming_loss

# 定义数据集
X, y = make_multilabel_classification(n_samples=10000, n_features=10, n_classes=2, random_state=1)

# 总结数据集形状
print(X.shape, y.shape)
# 总结前几个示例
for i in range(10):
print(X[i], y[i])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)

来自 sklearn.preprocessing 导入 StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
print(scaler.mean_)
print(scaler.var_)

x_train_std = scaler.transform(X_train)
x_test_std = scaler.transform(X_test)

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(x_train_std, y_train)

pred = knn.predict(x_test_std)

print(accuracy_score(y_test, pred))
print(hamming_loss(y_test, pred))

accuracy_score: 0.8345, hamming_loss: 0.08875
但是随着类别数超过3，准确率得分逐渐下降，损失增加。
# define dataset
X, y = make_multilabel_classification(n_samples=10000, n_features=10, n_classes=3, random_state=1)

n_classes= 3 --&gt; accuracy_score: 0.772, hamming_loss: 0.116
n_classes= 4 --&gt; accuracy_score：0.4875，hamming_loss：0.194125
使用 RandomForestClassifier 和 ClassifierChain(estimator=SVC) 也是如此。
为什么会发生这种情况，有没有办法提高准确度分数并降低损失？]]></description>
      <guid>https://stackoverflow.com/questions/78598665/how-to-improve-accuracy-score-in-multilabel-classification</guid>
      <pubDate>Sun, 09 Jun 2024 13:03:31 GMT</pubDate>
    </item>
    <item>
      <title>Unity ML-Agents --num-envs 获取环境 ID</title>
      <link>https://stackoverflow.com/questions/78598596/unity-ml-agents-num-envs-get-env-id</link>
      <description><![CDATA[我想训练一款需要用户登录的游戏。目前，我对登录名进行了硬编码以使用训练帐户。每个玩家只能登录一次，因此使用 --num-envs=x 参数进行训练仍将导致只有一个环境实际进行训练。有没有办法访问当前环境的 ID，以便我可以为每个单独的环境使用不同的登录名？我希望能够说
playerName = $&quot;player{envId};

有没有办法做到这一点？
我研究了 Academy 和 Communicator 实现，但没有发现任何有用的东西。]]></description>
      <guid>https://stackoverflow.com/questions/78598596/unity-ml-agents-num-envs-get-env-id</guid>
      <pubDate>Sun, 09 Jun 2024 12:31:24 GMT</pubDate>
    </item>
    <item>
      <title>不适当的图像检测 NSFW [关闭]</title>
      <link>https://stackoverflow.com/questions/78598085/inappropriate-image-detection-nsfw</link>
      <description><![CDATA[我将开发一种人工智能，用于检测应用程序的不适当对象。
不适当的类别：裸体、血腥、枪支、刀具和暴力。
当其中一种情况发生时，客户说这是不适当的就足够了。
我不知道哪种方法适合这个问题。我尝试使用现有的 nudenet 模型，但它的表现不如我想要的那样好。
在我看来，在使用 nudenet 检测裸体的同时，我想从头开始训练一个不同的模型来检测其余的禁忌类别。我不知道把一张图片放入两个模型中来做出决定是否太难或不合理。
我无法决定我应该把它作为分类问题还是对象识别问题来解决。
如果我想把它作为对象识别来解决，我需要标记图像，而我不想标记包含裸体的图像。有没有网站出售包含标记裸体的数据集？
除此之外，我不知道哪种模型更适合使用，是分类还是物体检测？
我将等待您的所有建议和评论。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78598085/inappropriate-image-detection-nsfw</guid>
      <pubDate>Sun, 09 Jun 2024 09:03:03 GMT</pubDate>
    </item>
    <item>
      <title>在 Scikit-learn 管道中过滤 y 的中间模型</title>
      <link>https://stackoverflow.com/questions/78597981/intermediate-model-that-filters-y-in-scikit-learn-pipelines</link>
      <description><![CDATA[我想实现一个具有中间分类器的预测架构。该模型将被拟合，然后预测训练集另一部分上的二进制特征类别的概率。然后，转换器将删除概率小于给定值的每个实例。显然，也应该删除与这些实例相对应的 y 值。默认的 sklearn 行为不支持此功能，它不允许在管道内转换 y 以进行优化，例如 GridSearchCV。
我的自定义模型转换器如下（我使用的是 sklearn==1.4.0，这非常重要）：
class My_Int_Classifier(BaseEstimator, TransformerMixin):
def __init__(self, pctg_int_model=0.5, int_target=None, thres_prob=0.5, y_final_target=None, **kwargs):
self.model=RandomForestClassifier(n_estimators=100, criterion=&#39;gini&#39;, max_depth=None,
min_weight_fraction_leaf=0.0, max_features=&#39;sqrt&#39;,
max_leaf_nodes=None, min_impurity_decrease=0.0,
bootstrap=True, oob_score=False, n_jobs=None,
random_state=None, verbose=0, warm_start=False,
class_weight=None, ccp_alpha=0.0, max_samples=None,
monotonic_cst=None, min_samples_split=2, min_samples_leaf=1)
self.__dict__.update(kwargs)
self.pctg_int_model =pctg_int_model
self.int_target = int_target
self.thres_prob =thres_prob
self.y_final_target=y_final_target
self.model=self.model.set_params(**kwargs)

def fit(self, x, y=None):
int_X=X.iloc[0:math.floor(self.pctg_int_model*len(X))]
self.model.fit(int_X.drop(self.int_target, axis=1), int_X[self.int_target])
return self

def transform(self, x, y=None):
remaining_X=X.iloc[math.floor(self.pctg_int_model*len(x)):]
remaining_X=remaining X.drop(self.int_target, axis=1)
remaining_y = self.y_final_target.iloc[math.floor(self.pctg_int_model*len(self.y_final_target)):]
probs = self.model.predict proba (remaining X)[:0]
remaining_X[&#39;proba_int&#39;] = probs
remaining_X = remaining_X.reset_index(drop=True)
remaining_y=remaining_y.reset_index(drop=True)
remaining_y= pd.Series(remaining_y, name=&#39;remaining_y&#39;)
df = pd.concat([remaining X, remaining_y])
df =df[df[&#39;proba_int&#39;]&lt;=self.thres_prob]
remaining_X=df.drop(&#39;remaining y&#39;, axis-1)
remaining_y=df[&#39;remaining_y&#39;]
return (remaining_X, remaining_y)

和相应的 fit_transform。单独来看，这个方法运行良好，问题是我需要将 remaining_y 作为新的 y 传递到以下（最后一个）估计器中，管道形式为
int_model = My_Int_Classifier(int_target=&#39;int_binary_target&#39;, y_final_target=y_train)

pipeline_rfr = Pipeline([(&#39;scaler&#39;, StandardScaler()), (&#39;int_model&#39;, model_rfr), (&#39;final_model&#39;, RandomForestRegressor())])

但是不起作用。
我想要一个如下所示的解决方案，其形式为 此处:
class MyWrapperEstimator(RealEstimator):
def fit(X, y=None):
if isinstance(X, tuple):
X, y = X
super().fit(X=X, y=y)

这样我就可以将最后一个 RandomForestRegressor 包装在这个类中，但效果并不好。
任何见解都非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/78597981/intermediate-model-that-filters-y-in-scikit-learn-pipelines</guid>
      <pubDate>Sun, 09 Jun 2024 08:08:16 GMT</pubDate>
    </item>
    <item>
      <title>在图像分类蘑菇中训练具有 2 个输出类的模型时出错</title>
      <link>https://stackoverflow.com/questions/78597865/error-when-train-model-with-2-output-classes-in-image-classification-mushroom</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78597865/error-when-train-model-with-2-output-classes-in-image-classification-mushroom</guid>
      <pubDate>Sun, 09 Jun 2024 07:17:35 GMT</pubDate>
    </item>
    <item>
      <title>将 ML 推理后端服务从 Python 迁移到 Rust [关闭]</title>
      <link>https://stackoverflow.com/questions/78597775/migration-of-ml-inference-backend-service-from-python-to-rust</link>
      <description><![CDATA[我有在 FastAPI 上运行并在容器映像上运行的 ML 推理服务。
FastAPI 上的端点只是 /infer。它将尝试从不同语言（PHP）上的另一个身份验证服务验证 JWT。如果不存在有效且经过训练的模型，则它会尝试将经过训练的模型下载到容器的本地存储中。如果有效且存在，它将执行预处理、推理、后处理并返回响应。这些步骤取决于 Numpy 等 Python 依赖项。
ML 生态系统正在使用 keras 和 tensorflow 并将其存储在容器的本地存储中。
如果我想将 /infer 端点迁移到 Rust，是否可行？
如果可以，我需要哪些框架、库和依赖项来执行此操作？
或者，实际上这是不可能的，因为 tensorflow 和 keras 以及另一个深度学习框架都专注于 Python。因此，不仅 Rust，任何其他语言（例如 Golang）可能都不适合迁移。这意味着我不应该迁移。]]></description>
      <guid>https://stackoverflow.com/questions/78597775/migration-of-ml-inference-backend-service-from-python-to-rust</guid>
      <pubDate>Sun, 09 Jun 2024 06:25:08 GMT</pubDate>
    </item>
    <item>
      <title>同一组内距离最小的图节点着色</title>
      <link>https://stackoverflow.com/questions/78597010/graph-node-coloring-with-minimal-distance-within-same-group</link>
      <description><![CDATA[我有一个带权重的边列表（节点 1 节点 2 权重）作为无向图的输入。
A B 10
A C 9
A D 2
B C 1

我还有一个颜色列表作为输入，如下所示：
红色：2
蓝色：2

假设我们定义 2 个节点的距离是节点 A 和 B 之间的最短路径，用 dist(A,B) 表示。符号 c 是唯一颜色的列表。在示例中，c=[red, blue]

同一组内节点对的距离总和表示如下：Ired,
Iblue，等等。

一个组与另一个组之间的节点对的距离总和表示如下：Ered,blue 

将颜色分配给节点后，解决方案通过以下公式进行评估：

如果我们在上述示例中选择 B、C 为红色，A、D 为蓝色，则得分为：

Ired=1

Ired=2
E红色，蓝色=dist(A,B)+dist(A,C)+dist(D,B)+dist(D,C)=10+9+12+11=42
得分=4/5(1+2)+1/5(42)=2.4+8.4=10.8
我正在寻找一种算法，该算法以某种方式将颜色分配给节点，使计算出的得分最小。我相信在多项式复杂度下不可能找到全局最优值，但该算法至少应该找到一个很好的近似值。]]></description>
      <guid>https://stackoverflow.com/questions/78597010/graph-node-coloring-with-minimal-distance-within-same-group</guid>
      <pubDate>Sat, 08 Jun 2024 21:44:35 GMT</pubDate>
    </item>
    <item>
      <title>在 Raspberry Pi 4 上安装 MediaPipe 时出现问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78596275/problem-with-installation-mediapipe-on-raspberry-pi-4</link>
      <description><![CDATA[我在 Raspberry Pi 4 上安装 MediaPipe 时遇到问题。首先，我遇到一个错误，即没有 MediaPipe，安装 mediapipe-rpi4 后，我收到此警报。
这是一条错误消息：
import mediapipe
回溯（最近一次调用最后一次）：
文件“&lt;stdin&gt;”，第 1 行，在&lt;module&gt;
文件“/home/pi/TWT/TWT_V2/RobotProgram/env/lib/python3.9/site-packages/mediapipe/__init__.py”，第 16 行，在&lt;module&gt;
从 mediapipe.python 导入 *
文件 &quot;/home/pi/TWT/TWT_V2/RobotProgram/env/lib/python3.9/site-packages/mediapipe/python/__init__.py&quot;，第 17 行，位于 &lt;module&gt;
从 mediapipe.python._framework_bindings 导入 resource_util
ModuleNotFoundError：没有名为“mediapipe.python._framework_bindings”的模块

有人能帮我吗？
我正在尝试在 Raspberry Pi 4 上安装 MediaPipe 以用于我的手部检测模块。]]></description>
      <guid>https://stackoverflow.com/questions/78596275/problem-with-installation-mediapipe-on-raspberry-pi-4</guid>
      <pubDate>Sat, 08 Jun 2024 16:17:17 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在 Elixir Nx/Schorar 中进行 ELISA 分析？</title>
      <link>https://stackoverflow.com/questions/78565463/is-elisa-analysis-in-elixir-nx-schorar-possible</link>
      <description><![CDATA[我已阅读 Medium 上的文章 ELISA Analysis in Python。
上述文章使用 SciPy 的 curve_fit 函数根据 4 参数逻辑回归 (4PL) 模型找到近似曲线，如下所示：
from scipy.optimize import curve_fit

x = [1.95, 3.91, 7.381, 15.63, 31.25, 62.5, 125,250, 500, 1000]
y = [0.274, 0.347, 0.392, 0.420, 0.586, 1.115, 1.637, 2.227, 2.335, 2.372]

def log4pl(x, A, B, C, D):
return(((A - D) / (1.0 + ((x / C) ** B))) + D)

params, _ = curve_fit(log4pl, x, y)
A, B, C, D = params[0], params[1], params[2], params[3]

我想使用 Nx/Scholar Elixir 中的库。
可能吗？如果您能给我任何提示，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78565463/is-elisa-analysis-in-elixir-nx-schorar-possible</guid>
      <pubDate>Sun, 02 Jun 2024 04:29:18 GMT</pubDate>
    </item>
    <item>
      <title>通过单一数字指标训练 XGBoost</title>
      <link>https://stackoverflow.com/questions/78558863/training-xgboost-over-a-single-number-metric</link>
      <description><![CDATA[假设我正在用 Python（xgboost 版本 2.0.3）构建一个 XGBoost 模型（这里的回归或分类完全不重要）来预测股票市场时间序列分析中的目标变量。
例如，目标可能是：时间序列中的下一个值或二进制变量，如果下一个值高于前一个值，则设置为 1，否则设置为 0。
为了训练模型，是否可以使用回归问题中的 MSE 或分类问题中的“二元逻辑”。
训练后，可以根据测试集中模型的输出对策略进行回测并计算总体回报。
我的问题是：使用 xgboost scikit-learn 接口，是否可以根据用于回测策略的性能指标来训练模型？
例如：按照策略最大化训练集中的总体回报规则。
在xgboost库网站上，展示了如何使用自定义损失函数来训练模型：
def softprob_obj(labels: np.ndarray, predt: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
rows = labels.shape[0]
classes = predt.shape[1]
grad = np.zeros((rows, classes), dtype=float)
hess = np.zeros((rows, classes), dtype=float)
eps = 1e-6
for r in range(predt.shape[0]):
target = labels[r]
p = softmax(predt[r, :])
for c in range(predt.shape[1]):
g = p[c] - 1.0 if c == target else p[c]
h = max((2.0 * p[c] * (1.0 - p[c])).item(), eps)
grad[r, c] = g
hess[r, c] = h

grad = grad.reshape((rows * classes, 1))
hess = hess.reshape((rows * classes, 1))
return grad, hess

clf = xgb.XGBClassifier(tree_method=&quot;hist&quot;, objective=softprob_obj)

目标函数需要计算梯度和 hessian。
假设函数定义如下：
def maximum_performance_metric(y_true: np.ndarray, y_pred: np.ndarray):
# 指标计算（例如：使用 y_pred 计算总体回报
overall_return = get_overall_return(y_pred, real_prices, ...) #overall_return 是浮点数
return grad, hess


是否可以根据总体回报计算梯度和 hessian，然后使用此自定义损失训练模型函数？
函数 maximize_performance_metric() 如何访问包含 real_prices 的变量（需要整体回报计算）？]]></description>
      <guid>https://stackoverflow.com/questions/78558863/training-xgboost-over-a-single-number-metric</guid>
      <pubDate>Fri, 31 May 2024 08:14:07 GMT</pubDate>
    </item>
    <item>
      <title>我用自己的数据集训练yolo模型，但是没有测试结果</title>
      <link>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</link>
      <description><![CDATA[我正在使用 Yolov3 模型和从 Kaggle 收到的数据集来训练模型。模型训练已完成，我将新权重添加到备份文件夹。我运行我训练过的水果之一进行测试，但没有发生物体检测。相同的图像显示为 Prediction.jpg。训练似乎不错，但我不明白为什么它无法检测物体。请帮助我。
训练终端代码：
./darknet detector train /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/Desktop/Projects/Bitirmeprojesi/yolov3.weights

测试终端代码：
./darknet detector test /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/darknet/backup/yolov3_final.weights -thresh 0.25 -out predictions.jpg

我设置并编辑了 obj.data 和 obj.names 和yolov3.cfg 文件。
我有 3 个类：苹果、香蕉和橙子。我已经根据3个classes在cfg文件中正确设置了filter、class值等值。
cfg文件 
[net]
# Testing
batch=64
subdivisions=1
# Training
subdivisions=16
width= 608
height=608
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=0.3

learning_rate=0.001
burn_in=1000
max_batches = 6000 # classnum * 2000
policy=steps
steps=3600,4800 # max_batches num %80, %90 
scales=.1,.1

数据集中除了.jpg图片，还有yolo 格式的同名 .txt 文件。
文件图像：

包含所有图像路径的 train.txt 和 test.txt 文件也已准备就绪。
当我在终端中运行测试命令时，它可以工作，但图片看起来一样，没有检测对象的边界框。我确定我已经安装了 Opencv。我使用的是 macOS。为什么它没有检测到它？请有人帮忙。我多次通过 make clean 清理了暗网，并通过 make opencv = 1 运行它，但结果没有改变。
[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00
总 BFLOPS 137.613 
avg_outputs = 1052318 
从 /Users/melisabagcivan/darknet/backup/yolov3_final.weights... 加载权重
查看 64，训练：32013 K-images (500 Kilo-batches_64) 
完成！从权重文件加载了 107 个层 
输入图像路径：/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg
检测层：82 - 类型 = 28 
检测层：94 - 类型 = 28 
检测层：106 - 类型 = 28 
/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg：预测时间为 6738.129000 毫秒。

我尝试使用了许多图像，但它没有在任何图像中绘制方框。我不明白它是否无法检测到它，或者我在测试时是否犯了错误。]]></description>
      <guid>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</guid>
      <pubDate>Fri, 17 May 2024 19:21:32 GMT</pubDate>
    </item>
    <item>
      <title>无需深度学习技术的手写数字识别</title>
      <link>https://stackoverflow.com/questions/72229909/handwritten-digit-recognition-without-deep-learning-techniques</link>
      <description><![CDATA[我有一个项目要交，需要我用 Python 开发一个程序，可以识别以图像形式给出的手写数字（我想 MNIST 数据集会派上用场）
但不使用深度学习技术、TensorFlow 库等。
有人能建议我应该尝试使用哪种算法来解决这个问题吗？
提前谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/72229909/handwritten-digit-recognition-without-deep-learning-techniques</guid>
      <pubDate>Fri, 13 May 2022 12:51:45 GMT</pubDate>
    </item>
    </channel>
</rss>