<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Mon, 14 Oct 2024 01:17:27 GMT</lastBuildDate>
    <item>
      <title>Gymnasium è‡ªå®šä¹‰ç¯å¢ƒâ€œå¤ªå¤šå€¼æ— æ³•è§£å‹â€é”™è¯¯</title>
      <link>https://stackoverflow.com/questions/79084313/gymnasium-custom-environment-too-many-values-to-unpack-error</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨å…·æœ‰ä½“è‚²é¦†å’Œç¨³å®šåŸºçº¿çš„è‡ªå®šä¹‰ç¾¤ä½“ç¾¤é›†ç¯å¢ƒã€‚æˆ‘æœ‰ä¸€ä¸ªè‡ªå®šä¹‰ç­–ç•¥å’Œè®­ç»ƒå¾ªç¯ã€‚
æˆ‘çš„è¡ŒåŠ¨å’Œè§‚å¯Ÿç©ºé—´å¦‚ä¸‹ï¼š
min_action = np.array([-5, -5] * len(self.agents), dtype=np.float32)
max_action = np.array([5, 5] * len(self.agents), dtype=np.float32)

min_obs = np.array([-np.inf, -np.inf, -2.5, -2.5] * len(self.agents), dtype=np.float32)
max_obs = np.array([np.inf, np.inf, 2.5, 2.5] * len(self.agents), dtype=np.float32)

è®­ç»ƒä»£ç ï¼š
import numpy as np
import torch as th
from Parameters import *
from stable_baselines3 import PPO
from main import FlockingEnv, CustomMultiAgentPolicy
from Callbacks import TQDMProgressCallback, LossCallback
import os
from stable_baselines3.common.vec_env import DummyVecEnv

if os.path.exists(Results[&quot;Rewards&quot;]):
os.remove(Results[&quot;Rewards&quot;])
print(f&quot;File {Results[&#39;Rewards&#39;]} has been removed.&quot;)

if os.path.exists(&quot;training_rewards.json&quot;):
os.remove(&quot;training_rewards.json&quot;)
print(f&quot;æ–‡ä»¶ training_rewards å·²è¢«åˆ é™¤ã€‚&quot;) 

def seed_everything(seed):
np.random.seed(seed)
os.environ[&#39;PYTHONHASHSEED&#39;] = str(seed)
th.manual_seed(seed)
th.cuda.manual_seed(seed)
th.backends.cudnn.deterministic = True
env.seed(seed)
env.action_space.seed(seed)

loss_callback = LossCallback()
env = DummyVecEnv([lambda: FlockingEnv()])

seed_everything(SimulationVariables[&quot;Seed&quot;])

# # æ¨¡å‹è®­ç»ƒ
model = PPO(CustomMultiAgentPolicy, env, tensorboard_log=&quot;./ppo_Agents_tensorboard/&quot;, verbose=1)
model.set_random_seed(SimulationVariables[&quot;ModelSeed&quot;])
progress_callback = TQDMProgressCallback(total_timesteps=SimulationVariables[&quot;LearningTimeSteps&quot;])
# è®­ç»ƒæ¨¡å‹
model.learn(total_timesteps=SimulationVariables[&quot;LearningTimeSteps&quot;], callback=[progress_callback, loss_callback])

é”™è¯¯ï¼š
ä½¿ç”¨ cuda è®¾å¤‡
å›æº¯ï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰ï¼š
æ–‡ä»¶ &quot;D:\Thesis_\FlockingFinal\MultiAgentFlocking\Training.py&quot;ï¼Œè¡Œ45ï¼Œåœ¨&lt;module&gt;ä¸­
model.learn(total_timesteps=SimulationVariables[&quot;LearningTimeSteps&quot;], callback=[progress_callback, loss_callback]) 
æ–‡ä»¶&quot;C:\Python312\Lib\site-packages\stable_baselines3\ppo\ppo.py&quot;ï¼Œç¬¬ 315 è¡Œï¼Œåœ¨ learn ä¸­
return super().learn(
^^^^^^^^^^^^^^^
æ–‡ä»¶&quot;C:\Python312\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py&quot;ï¼Œç¬¬ 287 è¡Œï¼Œåœ¨ learn ä¸­
total_timesteps, callback = self._setup_learn(
^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶&quot;C:\Python312\Lib\site-packages\stable_baselines3\common\base_class.py&quot;ï¼Œç¬¬ 423 è¡Œï¼Œåœ¨ _setup_learn
self._last_obs = self.env.reset() # ç±»å‹ï¼šignore[assignment]
^^^^^^^^^^^^^^^^^
æ–‡ä»¶ &quot;C:\Python312\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py&quot;ï¼Œç¬¬ 77 è¡Œï¼Œåœ¨ reset
obs ä¸­ï¼Œself.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueErrorï¼šå¤ªéœ€è¦è§£å‹çš„å€¼å¾ˆå¤šï¼ˆé¢„è®¡ä¸º 2 ä¸ªï¼‰

æˆ‘ä¹Ÿåœ¨ gym ä¸­ä½¿ç”¨äº†ç±»ä¼¼çš„ç§å­å‡½æ•°ï¼Œä½†æ²¡æœ‰å‡ºç°é”™è¯¯ï¼Œæˆ‘ä»¥ä¸ºæ˜¯å®ƒå¯¼è‡´äº†é”™è¯¯ï¼Œä½†å³ä½¿æˆ‘ä¸ä½¿ç”¨å®ƒï¼Œé”™è¯¯ä¹Ÿä¸ä¼šæ¶ˆå¤±ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79084313/gymnasium-custom-environment-too-many-values-to-unpack-error</guid>
      <pubDate>Sun, 13 Oct 2024 22:45:48 GMT</pubDate>
    </item>
    <item>
      <title>DETRï¼ˆæ£€æµ‹å˜å‹å™¨ï¼‰æ¨¡å‹ä¸é€‚ç”¨äºæˆ‘çš„æ•°æ®é›†</title>
      <link>https://stackoverflow.com/questions/79084295/detr-detection-transformer-model-is-not-working-for-my-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79084295/detr-detection-transformer-model-is-not-working-for-my-dataset</guid>
      <pubDate>Sun, 13 Oct 2024 22:27:50 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘æ˜¯å¦åº”è¯¥å°†é—å¿˜é›†æ‹†åˆ†ä¸ºè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼Œä»¥ä½¿ç”¨ CNN å’Œ Celeba æ•°æ®é›†è¿›è¡Œåå­¦ä¹ å®éªŒï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79084014/should-i-split-the-forget-set-into-train-validate-test-for-an-unlearning-experim</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ CelebA æ•°æ®é›†ä¸Šè®­ç»ƒä¸€ä¸ªç®€å•çš„ CNNï¼Œå¹¶å°è¯•é€šè¿‡åˆ›å»ºä¸€ä¸ªé—å¿˜é›†ï¼ˆæ¥è‡ª CelebA çš„éšæœºéƒ¨åˆ†å›¾åƒï¼‰æ¥è¿›è¡Œåå­¦ä¹ å®éªŒã€‚
CNN å·²åœ¨å®Œæ•´è®­ç»ƒé›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶è¿›è¡Œäº†å•ç‹¬çš„éªŒè¯å’Œæµ‹è¯•æ‹†åˆ†ä»¥è¿›è¡Œè¯„ä¼°ã€‚
æˆ‘æ˜¯å¦åº”è¯¥å°†é—å¿˜é›†æ‹†åˆ†ä¸ºè®­ç»ƒ/æµ‹è¯•/éªŒè¯å­é›†ï¼Œå¦‚æœæ˜¯ï¼Œä¸ºä»€ä¹ˆï¼Ÿï¼ˆé—å¿˜é›†çº¦å è®­ç»ƒé›†çš„ 10% - å…¶ä½™ 90% ä¸ºä¿ç•™é›†ï¼‰
åœ¨æˆ‘å½“å‰çš„åå­¦ä¹ å®éªŒä¸­ï¼Œæˆ‘åªå¯¹é—å¿˜é›†è¿›è¡Œåå­¦ä¹ ï¼Œæ²¡æœ‰è¿›è¡Œä»»ä½•é‡æ–°è®­ç»ƒã€‚å› æ­¤ï¼Œæˆ‘åœ¨æ­¤è¿‡ç¨‹ä¸­ä»…ä½¿ç”¨å®Œæ•´æ¨¡å‹å’Œé—å¿˜é›†ã€‚
æˆ‘å°è¯•ä½¿ç”¨æˆ‘ç›¸åº”æ‹†åˆ†çš„é—å¿˜é›†ï¼Œä½†æµ‹è¯•å˜å¾—æ£˜æ‰‹ï¼Œå¹¶ä¸”å¯èƒ½åªæœ‰ä¸€ä¸ªé—å¿˜é›†æ„Ÿè§‰åˆä¹é€»è¾‘ï¼ˆå› ä¸ºé—å¿˜é›†ä¸­ä¸æ˜¯åŒä¸€ä¸ªäººï¼Œå®ƒæ˜¯ä¸€ä¸ªæ··åˆåŒ…ï¼‰
å› æ­¤ï¼Œæ‹†åˆ†ä¸ºæµ‹è¯•å’ŒéªŒè¯æ„å‘³ç€å®ƒæ˜¯ä¸åŒé¢å­”çš„ä¸åŒåŒ…ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79084014/should-i-split-the-forget-set-into-train-validate-test-for-an-unlearning-experim</guid>
      <pubDate>Sun, 13 Oct 2024 19:44:40 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆå°½ç®¡ä½¿ç”¨äº† RLZoo3 çš„æœ€ä½³è¶…å‚æ•°ï¼Œæˆ‘çš„ SB3 DQN ä»£ç†ä»æ— æ³•å­¦ä¹  CartPole-v1ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79083972/why-is-my-sb3-dqn-agent-unable-to-learn-cartpole-v1-despite-using-optimal-hyperp</link>
      <description><![CDATA[æˆ‘ä» RLZoo3 è·å¾—äº†ç”¨äºè®­ç»ƒ CartPole-v1 çš„æœ€ä½³è¶…å‚æ•°ã€‚æˆ‘åˆ›å»ºäº†ä¸€ä¸ªæœ€å°ç¤ºä¾‹æ¥å±•ç¤ºæˆ‘çš„ CartPole ä»£ç†çš„æ€§èƒ½ã€‚æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œä»£ç†åº”è·å¾— 500 åˆ†ï¼Œæ‰èƒ½æˆåŠŸå®Œæˆä¸€é›†ã€‚ä¸å¹¸çš„æ˜¯ï¼Œåˆ†æ•°æ²¡æœ‰è¶…è¿‡ 300ã€‚
è¿™æ˜¯æˆ‘çš„ä»£ç  -
import gymnasium as gym
import numpy as np
import torch
from stable_baselines3 import DQN
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import BaseCallback
from torch.utils.tensorboard import SummaryWriter
import os

def set_seed(seed):
np.random.seed(seed)
torch.manual_seed(seed)
torch.backends.cudnn.deterministic = True

class TensorBoardCallback(BaseCallback):
def __init__(self, log_dir):
super().__init__()
self.writer = SummaryWriter(log_dir=log_dir)
self.episode_rewards = []
self.current_episode_reward = 0

def _on_step(self):
self.current_episode_reward += self.locals[&#39;rewards&#39;][0]

å¦‚æœ self.locals[&#39;dones&#39;][0]:
self.episode_rewards.append(self.current_episode_reward)
self.writer.add_scalar(&#39;train/episode_reward&#39;, self.current_episode_reward, self.num_timesteps)
self.current_episode_reward = 0

å¦‚æœ len(self.episode_rewards) &gt;= 100:
avg_reward = sum(self.episode_rewards[-100:]) / 100
self.writer.add_scalar(&#39;train/average_reward&#39;, avg_reward, self.num_timesteps)

return True

def on_training_end(self):
self.writer.close()

# è®¾ç½®æ—¥å¿—ç›®å½•
log_dir = &quot;tensorboard_logs&quot;
os.makedirs(log_dir, exist_ok=True)

# è®¾ç½®å¯é‡å¤æ€§çš„ç§å­
seed = 42
set_seed(seed)

# åˆ›å»ºç¯å¢ƒ
env = gym.make(&quot;CartPole-v1&quot;)
env = DummyVecEnv([lambda: env])

# ä½¿ç”¨æ¥è‡ª rlzoo3 çš„è¶…å‚æ•°åˆ›å»ºæ¨¡å‹
model = DQN(
policy=&quot;MlpPolicy&quot;,
env=env,
learning_rate=2.3e-3,
batch_size=64,
buffer_size=100000,
learning_starts=1000,
gamma=0.99,
target_update_interval=10,
train_freq=256,
gradient_steps=128,
exploration_fraction=0.16,
exploration_final_eps=0.04,
policy_kwargs=dict(net_arch=[256, 256]),
verbose=1,
tensorboard_log=log_dir,
seed=seed
)

# åˆ›å»ºå›è°ƒ
tb_callback = TensorBoardCallback(log_dir)

# è®­ç»ƒæ¨¡å‹
total_timesteps = 50000
model.learn(total_timesteps=total_timesteps, callback=tb_callback)

print(&quot;è®­ç»ƒå®Œæˆã€‚æ‚¨å¯ä»¥ä½¿ç”¨ TensorBoard æŸ¥çœ‹ç»“æœã€‚&quot;)
print(f&quot;åœ¨æ‚¨çš„ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼štensorboard --logdir {log_dir}&quot;)

env.close()

è¿™æ˜¯æœ€ç»ˆç»“æœ -
]]></description>
      <guid>https://stackoverflow.com/questions/79083972/why-is-my-sb3-dqn-agent-unable-to-learn-cartpole-v1-despite-using-optimal-hyperp</guid>
      <pubDate>Sun, 13 Oct 2024 19:23:17 GMT</pubDate>
    </item>
    <item>
      <title>ML æ¢¯åº¦ä¸‹é™ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79082800/ml-gradient-descent</link>
      <description><![CDATA[æ¢¯åº¦ä¸‹é™
æ¢¯åº¦ä¸‹é™æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¹¿æ³›ä½¿ç”¨çš„ä¼˜åŒ–ç®—æ³•ä¹‹ä¸€ã€‚å®ƒé€šè¿‡è¿­ä»£è°ƒæ•´æ¨¡å‹å‚æ•°æ¥å¸®åŠ©æœ€å°åŒ–æˆæœ¬å‡½æ•°ï¼ˆæˆ–æŸå¤±å‡½æ•°ï¼‰ã€‚
æ¢¯åº¦ä¸‹é™ä¸­çš„å¯¼æ•°ï¼šæ¢¯åº¦ï¼ˆåå¯¼æ•°å‘é‡ï¼‰æ˜¾ç¤ºæŸå¤±å‡½æ•°æœ€é™¡å³­çš„å¢é•¿æ–¹å‘ã€‚ä¸ºäº†æœ€å°åŒ–æŸå¤±ï¼Œå‚æ•°ä¼šæ²¿æ¢¯åº¦çš„åæ–¹å‘æ›´æ–°ã€‚ä»æ•°å­¦ä¸Šæ¥è¯´ï¼Œå‚æ•°æ›´æ–°è§„åˆ™æ˜¯ï¼š
ğœƒ
ğœƒ
âˆ’
ğ›¼
âˆ‡
ğœƒ
ğ½
(
ğœƒ
)
Î¸=Î¸âˆ’Î±âˆ‡
Î¸
â€‹
J(Î¸)
å…¶ä¸­
ğœƒ
Î¸ è¡¨ç¤ºæ¨¡å‹å‚æ•°ï¼Œ
ğ›¼
Î± è¡¨ç¤ºå­¦ä¹ ç‡ï¼Œ
âˆ‡
ğœƒ
ğ½
(
ğœƒ
)
âˆ‡
Î¸
â€‹
J(Î¸) æ˜¯æˆæœ¬å‡½æ•°ç›¸å¯¹äº
ğœƒ
Î¸ çš„æ¢¯åº¦ã€‚
2. æˆæœ¬å‡½æ•°ï¼ˆæŸå¤±å‡½æ•°ï¼‰
æˆæœ¬å‡½æ•°æ˜¯è®­ç»ƒæœŸé—´è¦æœ€å°åŒ–çš„ç›®æ ‡å‡½æ•°ã€‚ç¤ºä¾‹åŒ…æ‹¬å›å½’ä»»åŠ¡çš„å‡æ–¹è¯¯å·® (MSE) å’Œåˆ†ç±»ä»»åŠ¡çš„äº¤å‰ç†µã€‚
å¾®åˆ†å­¦ç”¨äºè®¡ç®—æˆæœ¬å‡½æ•°ç›¸å¯¹äºæ¨¡å‹å‚æ•°çš„å¯¼æ•°ï¼Œä»¥æŒ‡å¯¼å¦‚ä½•è°ƒæ•´å‚æ•°ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79082800/ml-gradient-descent</guid>
      <pubDate>Sun, 13 Oct 2024 09:18:27 GMT</pubDate>
    </item>
    <item>
      <title>Python åœ¨åˆ†é… numpy æ•°ç»„æ—¶æŠ›å‡º MemoryError</title>
      <link>https://stackoverflow.com/questions/79082341/python-throws-memoryerror-while-allocating-a-numpy-array</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä»¥ç±»ä¼¼ sklearn çš„æ–¹å¼æ‹Ÿåˆ QML ç®—æ³•ï¼š
num_features = X_train.shape[1]

feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)
ansatz = RealAmplitudes(num_qubits=num_features, reps=3)
optimizer = COBYLA(maxiter=100)

vqc = VQC(
feature_map=feature_map,
ansatz=ansatz,
optimizer=optimizer
)

vqc.fit(X_train, y_train.to_numpy())

åœ¨æ‰§è¡Œ vqc.fit(X_train, y_train.to_numpy()) è¡Œæ—¶ï¼Œè§£é‡Šå™¨æŠ›å‡ºå¼‚å¸¸ï¼š
MemoryErrorï¼šæ— æ³•ä¸ºå½¢çŠ¶ä¸º (1048576,) ä¸”æ•°æ®ç±»å‹ä¸º &lt;U420  çš„æ•°ç»„åˆ†é… 1.64 GiB
é—®é¢˜æ˜¯ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨çš„æœºå™¨æœ‰ 120 GB çš„ RAMï¼Œæˆ‘ä¸æ˜ç™½å®ƒä¸ºä»€ä¹ˆä¸èƒ½ä¸ºæ•°ç»„åˆ†é… 1.64 GBã€‚ä½ èƒ½å¸®æˆ‘è§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿæœ‰ä»€ä¹ˆæ–¹æ³•å¯ä»¥çªç ´è¿™ä¸ª RAM é™åˆ¶å—ï¼Ÿ
æˆ‘ä¸ç¡®å®šï¼Œä½†æˆ‘æƒ³è¯•è¯•è¿™ä¸ª https://stackoverflow.com/a/58686879ã€‚ç„¶è€Œï¼Œæˆ‘è®¤ä¸ºè¿™è¡Œä¸é€šï¼Œä¹Ÿè®¸ä½ æœ‰æ›´å¤šçš„æƒ³æ³•ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79082341/python-throws-memoryerror-while-allocating-a-numpy-array</guid>
      <pubDate>Sun, 13 Oct 2024 03:26:07 GMT</pubDate>
    </item>
    <item>
      <title>ç»“åˆå‡ ç§ç›‘ç£å­¦ä¹ æŠ€æœ¯ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79081793/combining-several-supervised-learning-techniques</link>
      <description><![CDATA[æˆ‘çš„æ•°æ®é›†åŒ…å«å¤§é‡å›¾åƒå’Œåˆ¶è¡¨æ•°æ®ï¼ˆå­˜å‚¨åœ¨ .csv æ–‡ä»¶ä¸­ï¼‰ã€‚æˆ‘æ‰“ç®—ä½¿ç”¨æˆ‘æ‹¥æœ‰çš„æ‰€æœ‰æ•°æ®ï¼ˆå›¾åƒå’Œåˆ¶è¡¨æ•°æ®ï¼‰åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿå¯¹æ¡ˆä¾‹ A å’Œæ¡ˆä¾‹ B è¿›è¡Œåˆ†ç±»/è¯†åˆ«çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚
æ˜¯å¦å¯ä»¥ç»“åˆå‡ ç§ç›‘ç£å­¦ä¹ æŠ€æœ¯ï¼Œä¾‹å¦‚ä½¿ç”¨ CNN å¤„ç†å›¾åƒï¼Œä½¿ç”¨éšæœºæ£®æ—åˆ†æåˆ¶è¡¨æ•°æ®ï¼Ÿç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªå¯¹ä¸¤ç§ç±»å‹çš„æ•°æ®è¿›è¡Œè®­ç»ƒçš„ç»„åˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥å°†æ¡ˆä¾‹ A å’Œæ¡ˆä¾‹ B è¿›è¡Œåˆ†ç±»ã€‚
æˆ‘çš„é—®é¢˜æ˜¯è¿™ç§æ–¹æ³•åœ¨æœºå™¨å­¦ä¹ ä¸­æ˜¯å¦å¯è¡Œã€‚
æ˜¯å¦æœ‰å¯èƒ½åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ•´åˆå›¾åƒå’Œåˆ¶è¡¨æ•°æ®ï¼Ÿ
å¯¹äºè¿™äº›ç±»å‹çš„æ•°æ®ï¼Œé€šå¸¸æ¨èä½¿ç”¨å“ªç§æœºå™¨å­¦ä¹ ç®—æ³•ï¼Ÿ
æˆ‘ç›¸ä¿¡ CNN æ˜¯å›¾åƒçš„ä¸é”™é€‰æ‹©ï¼Œä½†æˆ‘ä¸ç¡®å®šåˆ¶è¡¨æ•°æ®çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆã€‚
æœ€é€‚åˆç”¨äºæ­¤ä»»åŠ¡çš„ Python åŒ…æ˜¯ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79081793/combining-several-supervised-learning-techniques</guid>
      <pubDate>Sat, 12 Oct 2024 19:52:24 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆé£æœºæ²¡æœ‰æ˜¾ç¤ºåœ¨ matplotlib å›¾ä¸­</title>
      <link>https://stackoverflow.com/questions/79081747/why-the-plane-doesnt-show-in-matplotlib-plot</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¯¹å…·æœ‰ 13 ä¸ªç‰¹å¾çš„æ³¢å£«é¡¿æˆ¿å±‹æ•°æ®é›†å®æ–½ SLPã€‚æˆ‘ä¸º X é€‰æ‹©â€œrmâ€å’Œâ€œznâ€ï¼Œä¸ºç›®æ ‡ Y é€‰æ‹©â€œmedvâ€ã€‚æˆ‘è¿˜ä»å¤´å®æ–½äº†ä¸€ä¸ªæ„ŸçŸ¥å™¨ç±»ã€‚åœ¨è¿™ä¸ªç±»ä¸­ï¼Œæˆ‘æœ‰ä¸€ä¸ªåä¸º plot_losses çš„å‡½æ•°ï¼Œå®ƒåœ¨ä¸€ä¸ªçª—å£ä¸­ç»˜åˆ¶é¢„æµ‹çº¿ï¼ˆ2dï¼‰å’ŒæŸå¤±ï¼Œè¿˜ç»˜åˆ¶ 3d å›¾çš„é¢„æµ‹å¹³é¢ï¼Œè¿™å°±æ˜¯é—®é¢˜æ‰€åœ¨ï¼Œå³ 3d éƒ¨åˆ†ã€‚
å¹³é¢æœªæ˜¾ç¤ºåœ¨ 3d æ•£ç‚¹å›¾ä¸Šã€‚
æ„ŸçŸ¥å™¨ç±»å®ç°ï¼š
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter

æ„ŸçŸ¥å™¨ç±»ï¼š
def __init__(self, input_size, lr, epochs):
self.w = np.zeros(input_size)
self.b = 0
self.lr = lr
self.epochs = epochs
self.losses = []

def fit(self, X_train, Y_train):
for _ in range(self.epochs):
for x_i in range(X_train.shape[0]):
x = X_train[x_i]
y = Y_train[x_i]
y_pred = np.dot(x, self.w) + self.b
error = y - y_pred

self.w = self.w + (error * x * self.lr)
self.b = self.b + (error * self.lr)

loss = np.mean(np.abs(error))
self.losses.append(loss)

def predict(self, X_test):
return np.dot(X_test, self.w) + self.b

def plot_losses(self, X_train, Y_train, ax1_title, ax2_title, plot_3d=False, plot_3d_title=&#39;3D Plot&#39;):
for _ in range(self.epochs):
for x_i in range(X_train.shape[0]):
x = X_train[x_i]
y = Y_train[x_i]
Y_pred = np.dot(x, self.w) + self.b

if plot_3d:
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111,projection=&#39;3d&#39;)

X_feature1 = X_train[:, 0]
X_feature2 = X_train[:, 1]

ax.scatter(X_feature1, X_feature2, Y_train, color=&#39;blue&#39;, label=&#39;True Values&#39;)

X1_grid, X2_grid = np.meshgrid(
np.linspace(X_feature1.min(), X_feature1.max(), 20),
np.linspace(X_feature2.min(), X_feature2.max(), 20)
)

Z_pred = self.w[0] * X1_grid + self.w[1] * X2_grid + self.b

ax.plot_surface(X1_grid, X2_grid, Z_pred, color=&#39;red&#39;, alpha=0.5)
ax.set_xlabel(&quot;ç‰¹å¾ &#39;rm&#39;&quot;)
ax.set_ylabel(&quot;ç‰¹å¾ &#39;zn&#39;&quot;)
ax.set_zlabel(&quot;ç›®æ ‡ &#39;medvâ€‹â€‹&#39;&quot;)
ax.set_title(plot_3d_title)
ax.legend()
plt.show()
else:
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5))

ax1.scatter(X_train[:, 0], Y_train, color=&#39;blue&#39;, label=&#39;çœŸå€¼&#39;)
ax1.plot(X_train[:, 0], Y_pred, color=&#39;red&#39;, label=&#39;é¢„æµ‹å€¼Line&#39;)
ax1.set_title(ax1_title)
ax1.legend()

ax2.plot(self.losses)
ax2.set_title(ax2_title)
ax2.set_xlabel(&quot;Epochs&quot;)
ax2.set_ylabel(&quot;å‡æ–¹è¯¯å·® (MSE)&quot;)

plt.tight_layout()
plt.show()

æ³¢å£«é¡¿æˆ¿å±‹æ•°æ®é›†çš„çº¿æ€§å›å½’ï¼š
%matplotlib qt
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
from perceptron import Perceptron
df_boston = pd.read_csv(&#39;input/BostonHousing.csv&#39;)
X = df_boston[[&#39;rm&#39;,&#39;zn&#39;]].values
Y = df_boston[&#39;medvâ€‹â€‹&#39;].values
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=.2)

slp = Perceptron(2, .01, 100)
slp.fit(X_train, Y_train) 
slp.plot_losses(X_train,Y_train, &#39;å‘˜å·¥å·¥èµ„å’Œç»éªŒæ„ŸçŸ¥å™¨&#39;, &#39;æŸå¤±å€¼&#39;, plot_3d=True, plot_3d_title=&#39;æ³¢å£«é¡¿ä½æˆ¿æ„ŸçŸ¥å™¨&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/79081747/why-the-plane-doesnt-show-in-matplotlib-plot</guid>
      <pubDate>Sat, 12 Oct 2024 19:31:21 GMT</pubDate>
    </item>
    <item>
      <title>æ— æ³•ä½¿ç”¨ load_state_dict åŠ è½½æˆ‘çš„æ¨¡å‹ï¼šRuntimeErrorï¼šä¸º UNetGenerator åŠ è½½ state_dict æ—¶å‡ºé”™ï¼šstate_dict ä¸­å‡ºç°æ„å¤–é”®</title>
      <link>https://stackoverflow.com/questions/79081715/cant-load-my-model-using-load-state-dict-runtimeerror-errors-in-loading-sta</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79081715/cant-load-my-model-using-load-state-dict-runtimeerror-errors-in-loading-sta</guid>
      <pubDate>Sat, 12 Oct 2024 19:09:08 GMT</pubDate>
    </item>
    <item>
      <title>ç»“åˆ CNN å’Œéšæœºæ£®æ—æ–¹æ³•ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79081396/combining-cnn-and-random-forest-approach</link>
      <description><![CDATA[æˆ‘çš„æ•°æ®é›†åŒ…å«å¤§é‡å›¾åƒå’Œåˆ¶è¡¨æ•°æ®ï¼ˆå­˜å‚¨åœ¨ .csv æ–‡ä»¶ä¸­ï¼‰ã€‚æˆ‘æ‰“ç®—ä½¿ç”¨æˆ‘æ‹¥æœ‰çš„æ‰€æœ‰æ•°æ®ï¼ˆå›¾åƒå’Œåˆ¶è¡¨æ•°æ®ï¼‰åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿå¯¹æ¡ˆä¾‹ A å’Œæ¡ˆä¾‹ B è¿›è¡Œåˆ†ç±»/è¯†åˆ«çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚
æ˜¯å¦å¯ä»¥ç»“åˆå‡ ç§ç›‘ç£å­¦ä¹ æŠ€æœ¯ï¼Œä¾‹å¦‚ï¼Œä½¿ç”¨ CNN å¤„ç†å›¾åƒï¼Œä½¿ç”¨éšæœºæ£®æ—åˆ†æåˆ¶è¡¨æ•°æ®ï¼Ÿç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªå¯¹ä¸¤ç§ç±»å‹çš„æ•°æ®è¿›è¡Œè®­ç»ƒçš„ç»„åˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥å°†æ¡ˆä¾‹ A å’Œæ¡ˆä¾‹ B è¿›è¡Œåˆ†ç±»ã€‚
æˆ‘çš„é—®é¢˜æ˜¯è¿™ç§æ–¹æ³•åœ¨æœºå™¨å­¦ä¹ ä¸­æ˜¯å¦å¯è¡Œã€‚
æ˜¯å¦å¯ä»¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é›†æˆå›¾åƒå’Œåˆ¶è¡¨æ•°æ®ï¼Ÿ
å¯¹äºè¿™äº›ç±»å‹çš„æ•°æ®ï¼Œé€šå¸¸æ¨èä½¿ç”¨å“ªç§æœºå™¨å­¦ä¹ ç®—æ³•ï¼Ÿ
æˆ‘è®¤ä¸º CNN æ˜¯å›¾åƒçš„ä¸é”™é€‰æ‹©ï¼Œä½†æˆ‘ä¸ç¡®å®šåˆ¶è¡¨æ•°æ®çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆã€‚
æœ€é€‚åˆç”¨äºæ­¤ä»»åŠ¡çš„ Python åŒ…æ˜¯ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79081396/combining-cnn-and-random-forest-approach</guid>
      <pubDate>Sat, 12 Oct 2024 16:08:46 GMT</pubDate>
    </item>
    <item>
      <title>ç”¨äºå¢é‡å­¦ä¹ çš„ Python éçº¿æ€§å›å½’å™¨</title>
      <link>https://stackoverflow.com/questions/79063665/python-non-linear-regressor-for-incremental-learning</link>
      <description><![CDATA[æˆ‘æƒ³çŸ¥é“ scikit-learn ä¸­æ˜¯å¦æœ‰ä¸€ä¸ªéçº¿æ€§å›å½’ç¨‹åºï¼Œå…è®¸å¢é‡å­¦ä¹ ï¼Œå³é€šè¿‡ partial_fit è°ƒç”¨ã€‚æˆ‘å‘ç° SGDRegressor å’Œ PassiveAggressiveRegressor éƒ½å…è®¸ partial_fitï¼Œä½†å®ƒä»¬æ˜¯çº¿æ€§çš„ï¼Œè€Œæˆ‘çš„æ•°æ®æ˜¾ç„¶æ˜¯éçº¿æ€§çš„ï¼Œå› æ­¤æ‹Ÿåˆæ•ˆæœå¹¶ä¸ç†æƒ³ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79063665/python-non-linear-regressor-for-incremental-learning</guid>
      <pubDate>Mon, 07 Oct 2024 21:18:59 GMT</pubDate>
    </item>
    <item>
      <title>åªæœ‰è¾“å…¥å¼ é‡å¯ä»¥ä½œä¸ºä½ç½®å‚æ•°ä¼ é€’</title>
      <link>https://stackoverflow.com/questions/78360982/only-input-tensors-may-be-passed-as-positional-arguments</link>
      <description><![CDATA[ä» PIL å¯¼å…¥å›¾åƒ
å¯¼å…¥ matplotlib.pyplot ä½œä¸º plt
å¯¼å…¥ argparse
å¯¼å…¥ pickle
å¯¼å…¥ numpy
ä½œä¸º np
ä» tensorflow å¯¼å…¥ keras
ä» keras.applications.xception å¯¼å…¥ Xception
ä» keras.preprocessing.sequence å¯¼å…¥ pad_sequences
ä» tensorflow.keras.preprocessing.text å¯¼å…¥ Tokenizer
å¯¼å…¥ tensorflow ä½œä¸º tf

# ä½¿ç”¨ Lambda å®šä¹‰è‡ªå®šä¹‰å±‚ï¼ˆä¸å¸¦ name å‚æ•°ï¼‰
class NotEqual(tf.keras.layers.Layer):
def __init__(self, name=None):
super(NotEqual, self).__init__(name=name)

def call(self, x, y): # ä½¿ç”¨å…³é”®å­—å‚æ•°â€œxâ€å’Œâ€œyâ€
return tf.math.not_equal(x, y)

# å®šä¹‰ç”¨äºæå–ç‰¹å¾ã€ç”Ÿæˆæè¿°çš„å‡½æ•°ï¼Œå’Œå…¶ä»–å¿…è¦çš„å®ç”¨ç¨‹åº
def extract_features(filename, model):
try:
image = Image.open(filename)
except:
print(&quot;ERROR: æ— æ³•æ‰“å¼€å›¾ç‰‡ï¼è¯·ç¡®ä¿å›¾ç‰‡è·¯å¾„å’Œæ‰©å±•åæ­£ç¡®&quot;)
image = image.resize((299, 299))
image = np.array(image)
if image.shape[2] == 4:
image = image[..., :3]
image = np.expand_dims(image, axis=0)
image = image / 127.5
image = image - 1.0
feature = model.predict(image)
return feature

def word_for_id(integer, tokenizer):
for word, index in tokenizer.word_index.items():
if index == integer:
return word
return None

def generate_desc(model, tokenizer, photo, max_length):
in_text = &#39;start&#39;
for i in range(max_length):
sequence = tokenizer.texts_to_sequences([in_text])[0]
sequence = pad_sequences([sequence], maxlen=max_length)
pred = model.predict({&#39;image_input&#39;: photo, &#39;text_input&#39;:sequence}) # å°†è¾“å…¥ä½œä¸ºå­—å…¸ä¼ é€’
pred = np.argmax(pred)
word = word_for_id(pred, tokenizer)
if word is None:
break
in_text += &#39; &#39; + word
if word == &#39;end&#39;:
break
return in_text

# è§£æå‚æ•°
ap = argparse.ArgumentParser()
ap.add_argument(&#39;-i&#39;, &#39;--image&#39;, required=True, help=&quot;Image Path&quot;)
args = vars(ap.parse_args())
img_path = args[&#39;image&#39;]

# åŠ è½½tokenizer
tokenizer = pickle.load(open(&quot;tokenizer.p&quot;, &quot;rb&quot;))

# å®šä¹‰æ¨¡å‹çš„è·¯å¾„
model_path = &#39;models/model_9.h5&#39;
# ä½¿ç”¨è‡ªå®šä¹‰å¯¹è±¡ï¼ˆåŒ…æ‹¬ NotEqual å±‚ï¼‰åŠ è½½æ¨¡å‹
ä½¿ç”¨ keras.utils.custom_object_scope({&#39;NotEqual&#39;: NotEqual}):
model = tf.keras.models.load_model(model_path)

æˆ‘å°è¯•ä»¥å„ç§æ–¹å¼è¿è¡Œæ­¤ä»£ç ï¼Œä½†å‡ºç°é”™è¯¯ï¼š
 model = tf.keras.models.load_model(model_path)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶â€œC:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\saving\saving_api.pyâ€ï¼Œç¬¬ 183 è¡Œï¼Œä½äº load_model
return legacy_h5_format.load_model_from_hdf5(filepath)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶ â€œC:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\legacy\saving\legacy_h5_format.pyâ€ï¼Œç¬¬ 133 è¡Œï¼Œä½äº load_model_from_hdf5
model = saving_utils.model_from_config(
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶â€œC:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\legacy\saving\saving_utils.pyâ€ï¼Œç¬¬ 85 è¡Œï¼Œä½äº model_from_config
return serialization.deserialize_keras_object(
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶â€œC:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\legacy\saving\serialization.pyâ€ï¼Œç¬¬ 495 è¡Œï¼Œä½äº deserialize_keras_object
deserialized_obj = cls.from_config(
^^^^^^^^^^^^^^^^^
æ–‡ä»¶â€œC:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\model.pyâ€ï¼Œç¬¬ 528 è¡Œï¼Œä½äº from_config ä¸­
return functional_from_config(
^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶â€œC:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\function.pyâ€ï¼Œç¬¬ 528 è¡Œï¼Œä½äº functional_from_config ä¸­
process_node(layer, node_data)
æ–‡ä»¶&quot;C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\function.py&quot;ï¼Œç¬¬ 475 è¡Œï¼Œä½äº process_node
layer(*args, **kwargs)
æ–‡ä»¶ &quot;C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\utils\traceback_utils.py&quot;ï¼Œç¬¬ 122 è¡Œï¼Œä½äº error_handler
raise e.with_traceback(filtered_tb) from None
æ–‡ä»¶ &quot;C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\layers\layer.py&quot;ï¼Œç¬¬ 721 è¡Œï¼Œä½äº __call__
raise ValueError(
ValueError: åªèƒ½å°†è¾“å…¥å¼ é‡ä½œä¸ºä½ç½®å‚æ•°ä¼ é€’ã€‚ä»¥ä¸‹å‚æ•°å€¼åº”ä½œä¸ºå…³é”®å­—å‚æ•°ä¼ é€’ï¼š0ï¼ˆç±»å‹ä¸º &lt;class &#39;int&#39;&gt;ï¼‰
]]></description>
      <guid>https://stackoverflow.com/questions/78360982/only-input-tensors-may-be-passed-as-positional-arguments</guid>
      <pubDate>Sun, 21 Apr 2024 09:15:40 GMT</pubDate>
    </item>
    <item>
      <title>é”™è¯¯ï¼šå…·æœ‰ ML Compute åŠ é€ŸåŠŸèƒ½çš„ TensorFlow ä»…é€‚ç”¨äº macOS 11.0 åŠæ›´é«˜ç‰ˆæœ¬</title>
      <link>https://stackoverflow.com/questions/74563984/error-tensorflow-with-ml-compute-acceleration-is-only-available-on-macos-11-0-a</link>
      <description><![CDATA[ä¸‹è½½ Tensor Flow mac å‘å¸ƒåŒ… (https://github.com/apple/tensorflow_macos/releases)ï¼Œæ‰“å¼€ tensorflow_macos-0.1alpha3.tar.gz åŒ…ï¼Œè¿è¡Œâ€œinstall_venv.shâ€è„šæœ¬ï¼Œå‡ºç°ä»¥ä¸‹é”™è¯¯ ERROR: å¸¦æœ‰ ML Compute åŠ é€Ÿçš„ TensorFlow ä»…åœ¨ macOS 11.0 åŠæ›´é«˜ç‰ˆæœ¬ä¸Šå¯ç”¨ã€‚
æˆ‘åœ¨ conda ç¯å¢ƒä¸­ä½¿ç”¨ python 3.8 è¿è¡Œå®ƒï¼ˆæˆ‘å°è¯•è¿‡ 3.7-3.11ï¼Œç»“æœç›¸åŒï¼‰ã€‚
æˆ‘ä¼šåœ¨ apple github repo ä¸Šå‘å¸ƒï¼Œä½†å®ƒå·²è¢«å…¬å¼€å­˜æ¡£ï¼Œæ‰€ä»¥å‡è®¾å®ƒä¸å†å¯ç”¨ï¼Ÿ
æˆ‘å°è¯•è¿‡åœ¨ conda ç¯å¢ƒä¸­ä½¿ç”¨ python 3.8 è¿è¡Œå®ƒï¼ˆæˆ‘å°è¯•è¿‡ 3.7-3.11ï¼Œç»“æœç›¸åŒï¼‰ã€‚
æˆ‘é¢„è®¡å®‰è£…ä¼šæˆåŠŸã€‚æˆ‘å°è¯•å®‰è£… pip install tensorflowï¼ˆå³æ²¡æœ‰ç‰¹å®šäº macï¼‰ï¼ŒpyCharm çœ‹åˆ°äº† lib tensorflowï¼Œä½†æˆ‘å¾—åˆ°
Apple M1ï¼šè¿›ç¨‹å®Œæˆï¼Œé€€å‡ºä»£ç ä¸º 132ï¼ˆè¢«ä¿¡å· 4 ä¸­æ–­ï¼šsigillï¼Œè§£å†³æ–¹æ¡ˆæ˜¯ä»ä¸Šé¢å®‰è£…åŒ…ï¼šhttps://github.com/apple/tensorflow_macos/issues/270]]></description>
      <guid>https://stackoverflow.com/questions/74563984/error-tensorflow-with-ml-compute-acceleration-is-only-available-on-macos-11-0-a</guid>
      <pubDate>Thu, 24 Nov 2022 16:46:17 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆè‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ Transformer éœ€è¦ä¸€å †ç¼–ç å™¨ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/59384146/why-do-transformers-in-natural-language-processing-need-a-stack-of-encoders</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å…³æ³¨è¿™ç¯‡å…³äº transformers çš„åšå®¢
http://jalammar.github.io/illustrated-transformer/
æˆ‘å”¯ä¸€ä¸æ˜ç™½çš„æ˜¯ä¸ºä»€ä¹ˆéœ€è¦ä¸€å †ç¼–ç å™¨æˆ–è§£ç å™¨ã€‚æˆ‘çŸ¥é“å¤šå¤´æ³¨æ„åŠ›å±‚æ•è·äº†é—®é¢˜çš„ä¸åŒè¡¨ç¤ºç©ºé—´ã€‚æˆ‘ä¸æ˜ç™½ä¸ºä»€ä¹ˆéœ€è¦ä¸€å †ç¼–ç å™¨å’Œè§£ç å™¨ã€‚ä¸€ä¸ªç¼–ç å™¨/è§£ç å™¨å±‚ä¸è¡Œå—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/59384146/why-do-transformers-in-natural-language-processing-need-a-stack-of-encoders</guid>
      <pubDate>Wed, 18 Dec 2019 00:57:26 GMT</pubDate>
    </item>
    <item>
      <title>çº¿æ€§å›å½’çˆ†ç‚¸çš„æ¢¯åº¦ä¸‹é™</title>
      <link>https://stackoverflow.com/questions/50219054/gradient-descent-for-linear-regression-exploding</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨æ­¤èµ„æºå®ç°çº¿æ€§å›å½’çš„æ¢¯åº¦ä¸‹é™ï¼šhttps://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/
æˆ‘çš„é—®é¢˜æ˜¯ï¼Œæˆ‘çš„æƒé‡æ­£åœ¨çˆ†ç‚¸å¼å¢é•¿ï¼ˆå‘ˆæŒ‡æ•°å¢é•¿ï¼‰ï¼Œå¹¶ä¸”æœ¬è´¨ä¸Šä¸é¢„æœŸç›¸åã€‚
é¦–å…ˆï¼Œæˆ‘åˆ›å»ºäº†ä¸€ä¸ªæ•°æ®é›†ï¼š
def y(x, a):
return 2*x + a*np.random.random_sample(len(x)) - a/2

x = np.arange(20)
y_true = y(x,10)

çœ‹èµ·æ¥åƒè¿™æ ·ï¼š

è¦ä¼˜åŒ–çš„çº¿æ€§å‡½æ•°ï¼š
def y_predict(x, m, b):
return m*x + b

å› æ­¤ï¼Œå¯¹äºä¸€äº›éšæœºé€‰æ‹©çš„å‚æ•°ï¼Œç»“æœå¦‚ä¸‹ï¼š
m0 = 1
b0 = 1

a = y_predict(x, m0, b0)

plt.scatter(x, y_true)
plt.plot(x, a)
plt.show()


ç°åœ¨æˆæœ¬çœ‹èµ·æ¥æ˜¯è¿™æ ·çš„ï¼š
cost = (1/2)* np.sum((y_true - a) ** 2)

æˆæœ¬ç›¸å¯¹äºé¢„æµ‹ (dc_da) çš„åå¯¼æ•°ï¼š
dc_da = (a - y_true) # ä»ç„¶æ˜¯ä¸€ä¸ªå‘é‡

æˆæœ¬ç›¸å¯¹äºæ–œç‡å‚æ•° (dc_dm) çš„åå¯¼æ•°ï¼š
dc_dm = dc_da.dot(x) # ç°åœ¨æ˜¯ä¸€ä¸ªå¸¸æ•°

æˆæœ¬ç›¸å¯¹äº y æˆªè·å‚æ•° (dc_db) çš„åå¯¼æ•°ï¼š
dc_db = np.sum(dc_da) # ä¹Ÿæ˜¯ä¸€ä¸ªå¸¸æ•°

æœ€åæ˜¯æ¢¯åº¦ä¸‹é™çš„å®ç°ï¼š
iterations = 10

m0 = 1

b0 = 1

learning_rate = 0.1

N = len(x)

for i in range(iterations):

a = y_predict(x, m0, b0)

cost = (1/2) * np.sum((y_true - a) ** 2)

dc_da = (a - y_true)

mgrad = dc_da.dot(x)
bgrad = np.sum(dc_da)

m0 -= learning_rate * (2 / N) * mgrad
b0 -= learning_rate * (2 / N) * bgrad

if (i % 2 == 0):
print(&quot;Iteration {}&quot;.format(i))
print(&quot;Cost: {}, m: {}, b: {}\n&quot;.format(cost, m0, b0))

ç»“æœä¸ºï¼š
è¿­ä»£ 0
Cost: 1341.5241150881411, m: 26.02473879743261, b: 2.8683883457327797

è¿­ä»£ 2
Cost: 409781757.38124645, m: 13657.166910552878, b: 1053.5831308528543

è¿­ä»£ 4
Cost: 132510115599264.75ï¼Œmï¼š7765058.4350503925ï¼Œbï¼š598610.1166795876

è¿­ä»£ 6
æˆæœ¬ï¼š4.284947676217907e+19ï¼Œmï¼š4415631880.089208ï¼Œbï¼š340401694.5610262

è¿­ä»£ 8
æˆæœ¬ï¼š1.3856132043127762e+25ï¼Œmï¼š2510967578365.3584ï¼Œbï¼š193570850213.62192

æˆ‘çš„å®ç°æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/50219054/gradient-descent-for-linear-regression-exploding</guid>
      <pubDate>Mon, 07 May 2018 16:54:52 GMT</pubDate>
    </item>
    </channel>
</rss>