<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 05 Jul 2024 12:27:37 GMT</lastBuildDate>
    <item>
      <title>如果损失没有进一步减少，如何停止训练？</title>
      <link>https://stackoverflow.com/questions/78711202/how-to-stop-training-if-loss-doesnt-decrease-further</link>
      <description><![CDATA[我正在使用以下 .cfg 训练 Yolo Tiny Net 模型：
[Common]
image_size：448
batch_size：16
num_classes：21
max_objects_per_image：21
[DataSet]
name：yolo.dataset.text_dataset.TextDataSet
path：VOC_Dataset/pascal_voc.txt
thread_num：5
[Net]
name：yolo.net.yolo_tiny_net.YoloTinyNet
weight_decay：0.0005
cell_size：7
boxes_per_cell：2
object_scale：1
noobject_scale：0.5
class_scale：1
coord_scale：5
[Solver]
name：yolo.solver.yolo_solver.YoloSolver
learning_rate： 0.000001
moment: 0.9
max_iterators: 1000000
pretrain_model_path: lenet_model_to_use.ckpt
train_dir: models/train

此处 lenet_model_to_use.ckpt 是之前使用的训练模型，其标签比实际训练模型少一个（我为其添加了标签和图像，以便新模型能够识别该新图像）
我注意到，使用当前的 le​​arning_rate，模型训练会继续执行，而损失不会减少。我的问题是，如果经过两个连续步骤后损失没有进一步减少，我想停止训练。
要添加的参数名称是什么，在 .cfg 文件中的哪个部分下设置哪个值？]]></description>
      <guid>https://stackoverflow.com/questions/78711202/how-to-stop-training-if-loss-doesnt-decrease-further</guid>
      <pubDate>Fri, 05 Jul 2024 11:29:31 GMT</pubDate>
    </item>
    <item>
      <title>核密度估计：所有数据点与带宽内结果不同</title>
      <link>https://stackoverflow.com/questions/78711117/kernel-density-estimation-different-results-for-all-data-points-vs-within-band</link>
      <description><![CDATA[我正在使用 Python 对道路事故数据进行核密度估计 (KDE)，但这里我将使用 1d 数据仅用于说明。在拟合 KDE 模型时，我注意到考虑所有数据点与限制带宽内的数据点时会得到不同的结果。具体来说，当仅使用带宽内的点时，我在点数较少的区域和点数较多的区域得到的密度值几乎相同，这对我来说似乎是违反直觉的。我不知道该如何解释这一点，或者这是否是代码问题。
def KDE(x_list,radius):
return (1/(len(x_list)*radius))*np.sum([K(x/radius) for x in x_list])

def kde_val(x,dati):
return K((x-xi))

dataset = np.array([10,11,10,55,56,57,58,59])

x_range = np.linspace(dataset.min()-0.3, dataset.max()+0.3, num=600)

# 实验的带宽值
H = [30, 40, 50,30, 40, 50]
n_samples = dataset.size

# 不同带宽值的线属性
color_list = [&quot;棕色&quot;,&quot;黑色&quot;,&quot;黄色&quot;,&quot;蓝色&quot;,&quot;红色&quot;,&quot;绿色&quot;]
alpha_list = [0.8, 1, 0.8,0.8, 1, 0.8]
width_list = [1.7,2.5,1.7,1.7,2.5,1.7]

plt.figure(figsize=(10,4))
# 迭代带宽值
i=0
for h, color, alpha, width in zip(H, color_list, alpha_list, width_list):
i+=1

# 迭代数据点
y_range=[]
for x in x_range:
a=x-dataset
b=a[abs(a) &lt;= h] #仅考虑带宽 h 内的数据点
if i&gt;3: #当i&gt;3 我考虑所有数据点
b=x-dataset
y_range.append(KDE(b,h))
y_range=np.array(y_range)

plt.plot(x_range, y_range, 
color=color, alpha=alpha, linewidth=width, 
label=f&#39;{h}&#39;)

plt.plot(dataset, np.zeros_like(dataset) , &#39;s&#39;, 
markersize=8, color=&#39;black&#39;)


KDE
我找不到任何忽略带宽之外的数据点的库来比较结果。]]></description>
      <guid>https://stackoverflow.com/questions/78711117/kernel-density-estimation-different-results-for-all-data-points-vs-within-band</guid>
      <pubDate>Fri, 05 Jul 2024 11:10:51 GMT</pubDate>
    </item>
    <item>
      <title>在生物学项目中使用人体细胞实例分割</title>
      <link>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</link>
      <description><![CDATA[我对深度学习和 fastai 完全陌生，这可能是一个非常简单的问题，但我在为与生物学相关的项目进行实例分割时遇到了困难。
关于问题：我有一些人类细胞的图片（每张图片大约有 5 个细胞），我想要实现的是创建一个模型，可以拍摄这样的照片并识别细胞。我面临的问题是：我可以让模型识别细胞，但无法区分不同的细胞。（这意味着作为输出，我得到一个 .png 图片，其中 0 表示背景，1 表示细胞；所以我没有得到关于它们分离的信息）。例如，如果我想计算图片上有多少个单元格，那么这将是一个问题。
澄清一下：我手头有：单元格图片（RGB，.jpg）并且我有 2 种类型的蒙版：第一种是灰度（背景为 0，单元格全部为 1，.png）并且我还有一个 RGB 图片，其中所有单元格都有不同的 RGB 值（如果图片上有 4 个单元格，则存在 4 个不同的 RGB 值；背景始终为 0）。也是 .png。
使用 fastai，我的 DataBlock 如下所示：
 dblock = DataBlock(blocks = (ImageBlock, MaskBlock(codes)),
get_items = get_image_files,
splitter = RandomSplitter(),
get_y = get_label,
item_tfms = Resize(224))

dls = dblock.dataloaders(path, bs=5)

问题：我知道此代码无法工作，因为模型输入的灰度图像只有 0 和 1。但我不知道如何合并其他类型的掩码，该掩码实际上包含有关不同细胞分离的信息。（所有细胞都是同一类型）。
非常感谢您的帮助，
Andrej
上面已经提到了：)]]></description>
      <guid>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</guid>
      <pubDate>Fri, 05 Jul 2024 10:24:16 GMT</pubDate>
    </item>
    <item>
      <title>当它们都使用同一个类时，我该如何抓取整个表？到目前为止，我只能得到名称</title>
      <link>https://stackoverflow.com/questions/78710808/how-do-i-scrape-a-whole-table-when-they-all-use-the-same-class-i-can-so-far-ge</link>
      <description><![CDATA[我试图获取标有“关键利率”的表中的数据。但是，我只能提取名称，因为它们具有独特的样式（）。
我想要表中的数据并使用 Pandas 将其排列成表。
请帮忙
代码：
URL = &quot;https://www.centralbank.go.ke/&quot;
page = request.get(url)
soup = BeautifulSoup(page.content, &#39;html.parser&#39;)

job_elems = soup.find_all(&#39;td&#39;, class_=&quot;tg-4eph&quot;) 
for job_elem in job_elems: 
title_elem = job_elem.find(&#39;small&#39;) 
if title_elem: 
print(title_elem.text.strip())
]]></description>
      <guid>https://stackoverflow.com/questions/78710808/how-do-i-scrape-a-whole-table-when-they-all-use-the-same-class-i-can-so-far-ge</guid>
      <pubDate>Fri, 05 Jul 2024 09:55:49 GMT</pubDate>
    </item>
    <item>
      <title>如何将中国公司归类为 NAC 代码 [关闭]</title>
      <link>https://stackoverflow.com/questions/78709423/how-to-class-chinese-company-to-naics-code</link>
      <description><![CDATA[我想将一家中国上市公司或任何一家上市公司映射到NAICS代码。我有这些公司的业务范围和主营业务描述（中文，每年）和NAICS手册（英文，2012 2017 2022年更改）。使用什么技术进行分类会更好？
我想知道我应该使用什么样的软件，什么样的方法，我需要掌握哪些技术，这需要什么设备。我想尽快得到最终结果。非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78709423/how-to-class-chinese-company-to-naics-code</guid>
      <pubDate>Fri, 05 Jul 2024 02:04:54 GMT</pubDate>
    </item>
    <item>
      <title>cnnhistory=model.fit(x_traincnn, y_train, batch_size=20, epochs=500, validation_data=(x_testcnn, y_test)) 无值不支持错误</title>
      <link>https://stackoverflow.com/questions/78709319/cnnhistory-model-fitx-traincnn-y-train-batch-size-20-epochs-500-validation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78709319/cnnhistory-model-fitx-traincnn-y-train-batch-size-20-epochs-500-validation</guid>
      <pubDate>Fri, 05 Jul 2024 00:58:54 GMT</pubDate>
    </item>
    <item>
      <title>如何列出 TensorFlow GradientTape 记录的操作</title>
      <link>https://stackoverflow.com/questions/78708623/how-to-list-operations-recorded-by-tensorflow-gradienttape</link>
      <description><![CDATA[我想打印出 GradientTape 在前向传递过程中记录的所有步骤。
作为一个简单的示例，我创建了以下代码，在单个神经元上实现单个训练步骤。
import tensorflow as tf

@tf.function
def one_training_step(X, y, loss_fn,activation_fn):
with tf.GradientTape() as tape:
y_ =activation_fn(X @ w + b)
loss_value = loss_fn(y_true=y, y_pred=y_)
grads = tape.gradient(loss_value, [w, b])
print(f&quot;Watched: {tape.watched_variables()}&quot;)
print(f&quot;Grads: {grads}&quot;)

X = tf.constant([[1.0]], dtype=float, name=&#39;X&#39;)
y = tf.constant([[1.0]], dtype=float, name=&#39;y&#39;)
w = tf.Variable([[2.0]], dtype=float, name=&#39;w&#39;)
b = tf.Variable([[3.0]], dtype=float, name=&#39;b&#39;)
activation_fn = tf.keras.activations.get(&#39;sigmoid&#39;)
loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)
one_training_step(X, y, loss_fn,activation_fn)

输出如下：
Watched: (&lt;tf.Variable &#39;w:0&#39; shape=(1, 1) dtype=float32&gt;, &lt;tf.Variable &#39;b:0&#39; shape=(1, 1) dtype=float32&gt;)
Grads: [&lt;tf.Tensor &#39;gradient_tape/matmul/MatMul:0&#39; shape=(1, 1) dtype=float32&gt;, &lt;tf.Tensor &#39;AddN:0&#39; shape=(1, 1) dtype=float32&gt;]

这似乎表示 w 的矩阵乘法和 b 的加法。
但是其他可微计算 - 激活函数和损失发生了什么？
我想获取梯度带在前向传递过程中记录的所有步骤的列表。这很重要，因为我正在研究自定义神经网络（例如具有递归连接的网络），并且我想弄清楚应用了哪些计算来给出梯度。]]></description>
      <guid>https://stackoverflow.com/questions/78708623/how-to-list-operations-recorded-by-tensorflow-gradienttape</guid>
      <pubDate>Thu, 04 Jul 2024 19:12:24 GMT</pubDate>
    </item>
    <item>
      <title>是否可以恢复使用 YOLOV8 训练的 .h5 模型以用于 YOLOTINYNET</title>
      <link>https://stackoverflow.com/questions/78708595/is-it-possible-to-restore-a-h5-model-trained-with-yolov8-to-use-for-yolotinynet</link>
      <description><![CDATA[我已经使用 YoloV8 训练了一个模型，我想在 YoloTinyNet 中使用它，我之前从 YOLOv8 保存了 .h5 模型，如下所示：
model = YOLO(&#39;yolov8/weights/yolov8n.pt&#39;)
model.save(&#39;saved_model\\yolov8.h5&#39;)

现在我想在 TinyYoloNet 程序中使用该 h5 文件，是否可以按原样恢复它？
使用 YoloTinyNet 相关代码，我通常按如下方式恢复模型：
sess = tf.Session()
save_path = saver.save(sess, &quot;./model.ckpt&quot;)#这里我必须指定 .h5？
saver.restore(sess, model_file)
np_predict = sess.run(predicts, feed_dict={image: np_img})

感谢您澄清并提供可行的替代方案。]]></description>
      <guid>https://stackoverflow.com/questions/78708595/is-it-possible-to-restore-a-h5-model-trained-with-yolov8-to-use-for-yolotinynet</guid>
      <pubDate>Thu, 04 Jul 2024 19:00:34 GMT</pubDate>
    </item>
    <item>
      <title>如何将 YoloTinyNet 转换为 YOLO 变量？</title>
      <link>https://stackoverflow.com/questions/78708138/how-to-convert-yolotinynet-to-yolo-variables</link>
      <description><![CDATA[我正在使用从 YoloTinyNet 模型获得的检测结果，如下所示：
results = YoloTinyNet(self._common_params, self._net_params, test=True).inference(image)

进一步处理它们并获得高级计算。
另一方面，我重新训练了 YOLO 模型，并希望使用它代替我的旧 YoloTinyNet 模型，如下所示：
model = YOLO(&#39;/yolov8/weights/yolov8n.pt&#39;)
results = model(source=&#39;./image.jpg&#39;, conf=0.25)[0]

如何链接两个不同的模型，有没有办法在它们之间进行转换？]]></description>
      <guid>https://stackoverflow.com/questions/78708138/how-to-convert-yolotinynet-to-yolo-variables</guid>
      <pubDate>Thu, 04 Jul 2024 16:23:37 GMT</pubDate>
    </item>
    <item>
      <title>训练 yolo 权重来识别一张额外的图像？</title>
      <link>https://stackoverflow.com/questions/78708085/train-yolo-weights-to-recognize-one-additional-image</link>
      <description><![CDATA[我有一个 YOLO 模型，正在训练它以使其能够识别新对象，并在新数据中定义新类别以用于训练。
使用新数据进行训练的完整代码如下：
from ultralytics import YOLO

model = YOLO(&#39;yolov8/weights/yolov8n.pt&#39;)
results = model(source=&#39;./weirdobject.jpg&#39;, conf=0.25, save_txt=None)[0]
print(results)

annotated_frame = results.plot() 

import cv2

import surveillance as sv

sv.plot_image(annotated_frame)

#使用 roboflow 下载带有新图像注释的数据（数据集包含 1 张带注释的图像）
from roboflow import Roboflow

rf = Roboflow(api_key=&quot;idofproject&quot;)
print(rf.workspace().projects())
project = rf.workspace(&quot;id1&quot;).project(&quot;id2&quot;)
version = project.version(4)
#从 roboflow 下载数据以训练模型
dataset = version.download(model_format=&quot;yolov8&quot;, location=&quot;./datasets&quot;)

#使用包含添加注释图像的数据训练模型
results = model.train(data=&quot;roboflow_ml_image_detection/datasets/data.yaml&quot;, epochs=5)

results = model.val()
#产生新的预测，其中应包括具有正确标签的新图像检测
results = model(source=&#39;./weirdobject.jpg&#39;, conf=0.25, save_txt=None)[0]
# 这个结果是错误的，因为模型没有使用包含新图像的新数据进行训练
print(results)

包含一张图片的数据集已下载到 python 项目中，并具有以下结构：

data.yaml 文件如下：
names:
- small_ball
nc: 1
roboflow:
license: CC BY 4.0
project: nao-s07zd
url: https://universe.roboflow.com/id1/id2/dataset/4
version: 4
working: id2
#test: ../test/images
train: ./train/images
val: ./valid/images

第二次的结果和训练之前的结果一样，为什么？]]></description>
      <guid>https://stackoverflow.com/questions/78708085/train-yolo-weights-to-recognize-one-additional-image</guid>
      <pubDate>Thu, 04 Jul 2024 16:08:46 GMT</pubDate>
    </item>
    <item>
      <title>如何转换日期格式</title>
      <link>https://stackoverflow.com/questions/78708002/how-to-convert-date-formet</link>
      <description><![CDATA[我正在用 Python 训练模型，下面是我的代码。
发生了错误。
ValueError：无法将字符串转换为浮点数：&#39;2020-03-24&#39;

#将数据拆分为 x 和 y
x = tsla.drop(&quot;Date&quot;, axis=1)
y = tsla[&#39;Date&#39;]

#将数据拆分为训练和测试
x_train, x_test, y_train, y_tset = train_test_split(x,y, test_size=0.2, random_state=42)

# 模型 
model = LinearRegression()
model.fit(x_train, y_train)

我尝试在 x y 上训练模型。]]></description>
      <guid>https://stackoverflow.com/questions/78708002/how-to-convert-date-formet</guid>
      <pubDate>Thu, 04 Jul 2024 15:47:21 GMT</pubDate>
    </item>
    <item>
      <title>将最优模型应用于测试集</title>
      <link>https://stackoverflow.com/questions/78707916/to-apply-the-optimal-model-to-the-test-set</link>
      <description><![CDATA[我有一个数据集需要训练和测试，还有另一个数据集作为测试集。
我已经使用训练数据集获得了最佳模型，并希望将该模型应用于测试集进行预测，但遇到了此错误消息：
ValueError：特征名称应与拟合期间传递的特征名称匹配。

如何解决此错误？
df = pd.read_csv(&#39;training.csv&#39;)
df.drop([&#39;USAGE(0)&#39;, &#39;CUSTOMERID&#39;], axis=1, inplace=True)

# 初始化编码器并拟合训练数据
encoder = OneHotEncoder(drop=&#39;first&#39;, sparse_output=False)
encoder.fit(df.select_dtypes(include=[&#39;object&#39;]))

# 在训练数据中编码字符串类型变量
for column in df.select_dtypes(include=[&#39;object&#39;]).columns:
coded_result =coder.transform(df[[column]])
coded_df = pd.DataFrame(encoded_result, columns=encoder.get_feature_names_out([column]))
df.drop(column, axis=1, inplace=True)
df = pd.concat([df,coded_df], axis=1)

# 分离特征和标签
label = &#39;PAYMENT(0)&#39;
excluded_columns = [label]
features = [feature for feature in df.columns if feature not in excluded_columns]
X = df[features]
y = df[label]

# 训练-测试分割
test_size = 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)

# 构建并训练初始决策树模型
model = DecisionTreeClassifier(criterion=&#39;gini&#39;, min_samples_leaf=3000)
model.fit(X_train, y_train)

# 使用网格搜索进行超参数调整和交叉验证
param_grid = {
&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;],
&#39;min_samples_leaf&#39;: [10, 20, 30, 40, 50, 60, 70, 80]
}
cv = KFold(n_splits=10, shuffle=True)
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv,scoring=&#39;accuracy&#39;)
grid_search.fit(X_train, y_train)

# 训练最优模型
optimal_model = grid_search.best_estimator_

# 可视化最优决策树
plt.figure(figsize=(100, 20))
plot_tree(optimal_model, filled=True, feature_names=features)
plt.show()

# 加载新测试数据
new_test_df = pd.read_csv(&#39;trial.csv&#39;)

# 保留提交文件的“ID”列
submission_ids = new_test_df[&#39;CUSTOMERID&#39;].copy()

new_test_df.drop(&#39;USAGE(0)&#39;, axis=1, inplace=True)

# 确保所有必需的列都存在
for column in df.select_dtypes(include=[&#39;object&#39;]).columns:
if column not in new_test_df.columns:
new_test_df[column] = 0

# 在新测试数据中编码字符串类型变量
for column in new_test_df.select_dtypes(include=[&#39;object&#39;]).columns:
coded_result =编码器.transform(new_test_df[[column]]) # 使用拟合的编码器进行转换
encoded_df = pd.DataFrame(encoded_result, columns=encoder.get_feature_names_out([column]))
new_test_df.drop(column, axis=1, inplace=True)
new_test_df = pd.concat([new_test_df,coded_df], axis=1)

# 确保新测试数据具有与训练数据相同的特征列
for feature in features:
if feature not in new_test_df.columns:
new_test_df[feature] = 0
X_new_test = new_test_df[features]

# 将最优模型应用于新测试数据
y_new_test_pred = optimal_model.predict(X_new_test)

# 将预测保存到名为&quot;mapping.csv&quot;
submission = pd.DataFrame({
&#39;CUSTOMERID&#39;: submission_ids,
&#39;PAYMENT(0)&#39;: y_new_test_pred
})

submission.to_csv(&#39;mapping.csv&#39;, index=False)
]]></description>
      <guid>https://stackoverflow.com/questions/78707916/to-apply-the-optimal-model-to-the-test-set</guid>
      <pubDate>Thu, 04 Jul 2024 15:27:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 AWS DeepRacer 学生联赛中提高我的汽车速度？[关闭]</title>
      <link>https://stackoverflow.com/questions/78703745/how-to-increase-speed-of-my-car-in-aws-deepracer-student-league</link>
      <description><![CDATA[如何在此处访问速度的输入参数？
# 读取输入参数
track_width = params[&#39;track_width&#39;]
distance_from_center = params[&#39;distance_from_center&#39;]

我曾尝试使用此方法访问速度参数
speed = params[&#39;speed&#39;]

但这导致错误并且无法运行模型]]></description>
      <guid>https://stackoverflow.com/questions/78703745/how-to-increase-speed-of-my-car-in-aws-deepracer-student-league</guid>
      <pubDate>Wed, 03 Jul 2024 18:36:28 GMT</pubDate>
    </item>
    <item>
      <title>如何训练 yolov8 识别另一幅图像</title>
      <link>https://stackoverflow.com/questions/78703688/how-to-train-yolov8-to-recognize-one-additional-image</link>
      <description><![CDATA[因此，我想使用包含一张带注释图像的数据集（使用 roboflow）来训练 yolov8，以将标签添加到当前模型，以便训练后的模型能够识别新图像。
首先，我获取在 roboflow 中注释的单图像数据集，如下所示：
dataset = version.download(model_format=&quot;yolov8&quot;, location=&quot;./datasets&quot;)

然后使用以下命令训练 yolov8 模型：
results = model.train(data=&quot;/roboflow_ml_image_detection/datasets/oups-1/data.yaml&quot;, epochs=5)

然后导出新模型：
success = model.export(format=&quot;onnx&quot;)

我将再次使用它对新图像进行预测：
model = YOLO(&#39;/roboflow_ml_image_detection/runs/detect/train29/weights/last.pt&#39;)

results = model(source=&#39;./weirdobject.jpg&#39;, conf=0.25)[0]

最后尝试使用 supervision 检测图像的标签：
import surveillance as sv

detections = sv.Detections.from_ultralytics(results)

bounding_box_annotator = sv.BoundingBoxAnnotator()

label_annotator = sv.LabelAnnotator()

annotated_image = bounding_box_annotator.annotate(
scene=image, detections=detections)
annotated_image = label_annotator.annotate(
scene=annotated_image, detections=detections)

sv.plot_image(annotated_image)

但最终调用仅显示没有框架和标签的图像。
这里有什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78703688/how-to-train-yolov8-to-recognize-one-additional-image</guid>
      <pubDate>Wed, 03 Jul 2024 18:21:02 GMT</pubDate>
    </item>
    <item>
      <title>chemprop：RuntimeError：在“目标”中检测到以下值：张量（[0，12]），但仅预期以下值[0，1] [关闭]</title>
      <link>https://stackoverflow.com/questions/78698076/chemprop-runtimeerror-detected-the-following-values-in-target-tensor-0-1</link>
      <description><![CDATA[运行 Chemprop 脚本时出现运行时错误。
所有脚本均可在此处找到：
https://github.com/chemprop/chemprop/blob/main/examples/training.ipynb
我遇到错误的部分是：
trainer.fit(mpnn, train_loader, val_loader)

两个月前它还可以正常工作。
我已经更新了所有软件包。]]></description>
      <guid>https://stackoverflow.com/questions/78698076/chemprop-runtimeerror-detected-the-following-values-in-target-tensor-0-1</guid>
      <pubDate>Tue, 02 Jul 2024 15:44:02 GMT</pubDate>
    </item>
    </channel>
</rss>