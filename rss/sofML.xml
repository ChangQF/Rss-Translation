<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 18:20:07 GMT</lastBuildDate>
    <item>
      <title>如果使用 tf.lite.interpreter，循环中会发生内存泄漏</title>
      <link>https://stackoverflow.com/questions/78727155/memory-leak-in-loop-if-use-tf-lite-interpreter</link>
      <description><![CDATA[我正在开发一个 FastAPI 项目，该项目接受带有模型名称和数据的请求。这些数据经过标准路径：（预处理、模型处理、后处理）。每个模型的解释器都存储在字典中，以便再次调用模型。
由于这些模型很多（超过 500 个），占用的 RAM 量接近 3 GB。
我想尝试减少 RAM 消耗，并尝试删除 tf.lite.interpreter 保存，但这导致了内存泄漏。据我了解，这是由于 tf.lite.interpreter 每次创建实例时都会在内存中存储一​​些数据。
我想知道是否可以在处理后删除 tf.lite.interpreter 创建的所有数据。以减少 RAM 消耗。
还是假设 tf.lite.interpreter 是为模型创建的，并在运行期间不断存储？
使用模型后，有什么方法可以释放内存吗？
我的方法有意义吗？
提前感谢您的帮助。我刚刚开始使用 ML。
一开始，我用 memory_profiler 对内存进行了分析。它显示内存是在 tf.lite.Interpreter() 的行上分配的
之后我创建了一个小脚本进行测试。
from time import perf_counter, sleep
import tensorflow as tf
import psutil
import logs
from logs.handlers import RotatingFileHandler

PATH = ...

rotating_handler = RotatingFileHandler(
filename=&#39;logs/memory_leak.log&#39;, 
mode=&#39;a+&#39;, 
maxBytes=int(20e6),
backupCount=10, 
encoding=&#39;utf-8&#39;
)
formatter = logs.Formatter(&#39;%(asctime)s - %(levelname)s - %(message)s&#39;, datefmt=&#39;%Y-%m-%d %H:%M:%S&#39;)
rotating_handler.setFormatter(formatter)
root_logger = logs.getLogger()
root_logger.setLevel(logging.WARNING)
root_logger.addHandler(rotating_handler)

def create_interpreter(path:str):
with tf.device(&#39;/CPU:0&#39;):
timer_start: float = perf_counter()
interpretationer = tf.lite.Interpreter(model_path=path)
interpretationer.allocate_tensors()
create_time = perf_counter() - timer_start
print(f&#39;ID 解释器：{id(interpreter)}&#39;)
print(f&#39;时间：{create_time}&#39;)
process = psutil.Process()
mem_info = process.memory_info()
logs.warning(f&#39;内存使用情况：RSS={mem_info.rss / 1024 ** 2:.2f} MB, VMS={mem_info.vms / 1024 ** 2:.2f} MB&#39;)
return interpretationer

while True:
some_interpreter = create_interpreter(path=PATH)
some_interpreter.allocate_tensors()
sleep(5)
del some_interpreter

我知道 del 删除的只是链接，但我认为之后 python GC 会清除内存。
根据这个脚本的日志，python 进程消耗的内存正在缓慢增加。]]></description>
      <guid>https://stackoverflow.com/questions/78727155/memory-leak-in-loop-if-use-tf-lite-interpreter</guid>
      <pubDate>Tue, 09 Jul 2024 18:07:46 GMT</pubDate>
    </item>
    <item>
      <title>Flutter/Tensorflow 形状不匹配错误</title>
      <link>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</link>
      <description><![CDATA[我正在制作一个运行 tensorflow Lite 模型的 Flutter 应用。我收到以下错误：
无法从形状为 [1, 2] 的 TensorFlowLite 张量 (Identity) 复制到形状为 [1, 215] 的 Java 对象。
背景故事：我训练过的算法使用 215 列并输出 1 或 0。下面是使用 netron.app 的屏幕截图：Netron 图
我实在无法理解为什么这个东西想要将形状 [1,2]（输出）复制到输入 Java 类中。这个代码太高级了，我无法正确调试它（我想有办法，但我有点新手）。我找不到 Tensorflow Lite 的 Flutter 文档，因为对我来说太模糊了，它只描述了破坏代码的函数的输入参数。下面是破坏的函数，错误在 runModelOnBinary() 函数中。任何一般性的指导/帮助/经验都将不胜感激，因为我对 Flutter、Dart 和 AI 还不太熟悉。如果需要，我可以发布整个 main.dart 代码，但我不确定是否有必要。
void assessModel() async {
try {

// 生成具有 215 列的随机输入数据以匹配预期的 860 字节输入大小
List&lt;double&gt; inputData = List.generate(215, (index) =&gt; Random().nextInt(2).toDouble());

// 将 List&lt;double&gt;到 Float32List
Float32List inputBytes = Float32List.fromList(inputData);

// 将 Float32List 转换为 Uint8List
Uint8List inputUint8List = inputBytes.buffer.asUint8List();
print(inputData);
// 在输入数据上运行模型
var output = await Tflite.runModelOnBinary(
binary: inputUint8List,
numResults: 2, // 根据需要进行调整
);
print(&quot;here2&quot;);
// 处理 null 或空输出
if (output == null || output.isEmpty) {
var result = output?[0]; 
/* ChatGPT 告诉我这样做，之前将输出变量作为可打印结果。
我认为这个问题没有太大区别，因为它是在代码中断之后*/
setState(() {
_output = &quot;Predicted: ${result[&#39;label&#39;]} (${result[&#39;confidence&#39;]})&quot;;
});
} else {
setState(() {
_output = output.toString();
});
}
} catch (e) {
// 捕获任何错误并显示它们
setState(() {
_output = &quot;Error running model: $e&quot;;
});
}
}

我尝试调整 numResults 参数，查看文档，甚至 chatGippidy，建议执行 var result = output?[0]，但一切都太模糊，没有深入介绍这个特定堆栈的工作原理。]]></description>
      <guid>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</guid>
      <pubDate>Tue, 09 Jul 2024 17:44:04 GMT</pubDate>
    </item>
    <item>
      <title>autokeras 无法运行，依赖项出现错误</title>
      <link>https://stackoverflow.com/questions/78726939/autokeras-not-running-with-error-in-dependency</link>
      <description><![CDATA[import tensorflow as tf
#from tensorflow.keras import layer
#import tensorflow_datasets as tfds
import os
#import PIL
import numpy as np

# 定义路径
train_dir = &#39;data3/train&#39;
val_dir = &#39;data3/val&#39;
test_dir = &#39;data3/test&#39;

# 定义参数
batch_size = 32
img_height = 224
img_width = 224

# 创建用于训练、验证和测试集的 tf.data.Dataset
train_ds = tf.keras.utils.image_dataset_from_directory(
train_dir,
validation_split=0.2,
subset=&quot;training&quot;,
seed=123,
image_size=(img_height, img_width),
batch_size=batch_size
)

val_ds = tf.keras.utils.image_dataset_from_directory(
val_dir,
validation_split=0.2,
subset=&quot;validation&quot;,
seed=123,
image_size=(img_height, img_width),
batch_size=batch_size
)

test_ds = tf.keras.utils.image_dataset_from_directory(
test_dir,
image_size=(img_height, img_width),
batch_size=batch_size
)

# 标准化图像
normalization_layer = tf.keras.layers.Rescaling(1./255)

train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))
test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))

# 优化数据集性能
AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

import autokeras as ak

# 定义 AutoKeras 图像分类器
clf = ak.ImageClassifier(
overwrite=True,
max_trials=1 # 调整数据集的试验次数
)

# 训练 AutoKeras 模型
clf.fit(train_ds, validation_data=val_ds, epochs=1)

# 导出最佳模型
best_model = clf.export_model()

# 将最佳模型保存到文件
best_model.save(&#39;pneumonia_detection_autokeras.h5&#39;)

# 加载已保存的模型
#loaded_model = tf.keras.models.load_model(&#39;pneumonia_detection_autokeras.h5&#39;, custom_objects=ak.CUSTOM_OBJECTS)

出现以下错误
文件“C:\Users\atish\OneDrive\Documents\VSCode\Python2\learning.py”，第 60 行，位于
import autokeras as ak
文件&quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras_init_.py&quot;，第 15 行，位于 
来自 autokeras.auto_model 导入 AutoModel
文件 &quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\auto_model.py&quot;，第 26 行，位于 
来自 autokeras 导入块
文件 &quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\blocks_init_.py&quot;，第 18 行，位于 autokeras.blocks.basic 导入 BertBlock
文件&quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\blocks\basic.py&quot;，第 25 行，位于 
来自 autokeras 导入 keras_layers
文件 &quot;C:\Users\atish\OneDrive\Documents\VSCode\Python2\myenv\Lib\site-packages\autokeras\keras_layers.py&quot;，第 27 行，位于 
来自 tensorflow.keras.layers.experimental 导入预处理
ModuleNotFoundError：没有名为“tensorflow.keras.layers.experimental”的模块]]></description>
      <guid>https://stackoverflow.com/questions/78726939/autokeras-not-running-with-error-in-dependency</guid>
      <pubDate>Tue, 09 Jul 2024 17:13:24 GMT</pubDate>
    </item>
    <item>
      <title>加载模型时出错：SyntaxError：意外的标记“<”，“<!DOCTYPE”... 不是有效的 JSON</title>
      <link>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</link>
      <description><![CDATA[我正在使用 React 上的 ml5 和 p5 创建一个瑜伽 ai 训练器。
我创建了一个组件，它从本地 JSON 文件中获取单个姿势作为道具。该组件还加载我在公共文件夹中添加的模型。该组件的目标是检测某个瑜伽姿势，并且该组件动态返回从网络摄像头检测到的姿势名称。
我测试了两个网络摄像头页面。我们称之为第 1 页和第 2 页。
第 1 页有效。网址为 /practice。第 1 页指向网络摄像头 1。网络摄像头 1 有效。
第 2 页的网址为 /practice/poseId。第 2 页指向不同的网络摄像头组件，网络摄像头 2 的代码与网络摄像头 1 完全相同，只是它接受一个道具，并且该道具是与 ID 匹配的特定姿势。
在第二页，我收到此错误
加载模型时出错：SyntaxError：意外的标记“&lt;”，“&lt;!DOCTYPE”... 不是有效的 JSON
它指向此代码
 const modelInfo = {
model: &quot;model/model.json&quot;,
metadata: &quot;model/model_meta.json&quot;,
weights: &quot;model/model.weights.bin&quot;,
};

fetch(modelInfo.model)
.then((response) =&gt; {
if (!response.ok) {
throw new Error(`HTTP error! status: ${response.status}`);
}
return response.json();
})
.then((data) =&gt; {
console.log(&quot;Model JSON:&quot;, data);
brain.load(modelInfo, brainLoaded);
})
.catch((error) =&gt; {
console.error(&quot;Error loading model:&quot;, error);
});

我不明白为什么我的组件在 /practice url 上有效，但是当我添加 poseId (/practice/:poseID) 时，即使代码相同，也会显示该错误。
错误出现在以 /practice/:poseId 结尾的 url 上，例如/practice/1.
错误示例（您看不到底部的姿势标签）：

示例（如果页面网址为 /practice，则有效）

这是我的仓库：https://github.com/laura-nguyen/yoga-ai/tree/feature/page-pose-cam
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</guid>
      <pubDate>Tue, 09 Jul 2024 17:06:11 GMT</pubDate>
    </item>
    <item>
      <title>Vision Transformers (ViT) - 澄清问题</title>
      <link>https://stackoverflow.com/questions/78726466/vision-transformers-vit-clarifying-question</link>
      <description><![CDATA[我是 DS 和 ML 的新手，对计算机视觉和图像分类问题空间很陌生。
我在网上/博客上找到了下面的代码片段，并在 google colab 上进行了基本的图像分类训练。
有人能用简单的术语解释一下当我们执行 RandomResizedCrop、RandomHorizo​​ntalFlip、Normalize 和 To Tensors 时，幕后到底发生了什么吗？
来自出版物 -&gt; https://openreview.net/pdf?id=YicbFdNTTy
图像被分解成块，然后进行归一化并输入到神经网络中。
from torchvision.transforms import (CenterCrop,
Compose,
Normalize,
RandomHorizo​​ntalFlip,
RandomResizedCrop,
Resize,
ToTensor)

from transformers import ViTImageProcessor

processor = ViTImageProcessor.from_pretrained(&quot;google/vit-base-patch16-224-in21k&quot;)
image_mean = processing.image_mean
image_std = processing.image_std
size = processing.size[&quot;height&quot;]

normalize = Normalize(mean=image_mean, std=image_std)
_train_transforms = Compose(
[
RandomResizedCrop(size),
RandomHorizo​​ntalFlip(),
ToTensor(),
normalize,
]
)

_val_transforms = Compose(
[
Resize(size),
CenterCrop(size),
ToTensor(),
normalize,
]
)

def train_transforms(examples):
examples[&#39;pixel_values&#39;] = [_train_transforms(image.convert(&quot;RGB&quot;)) for image in examples[&#39;image&#39;]]
return examples

def val_transforms(examples):
examples[&#39;pixel_values&#39;] = [_val_transforms(image.convert(&quot;RGB&quot;)) for image in examples[&#39;image&#39;]]
return示例

food[&#39;train&#39;].set_transform(train_transforms)
food[&#39;test&#39;].set_transform(val_transforms)

感谢您的帮助！！！]]></description>
      <guid>https://stackoverflow.com/questions/78726466/vision-transformers-vit-clarifying-question</guid>
      <pubDate>Tue, 09 Jul 2024 15:22:15 GMT</pubDate>
    </item>
    <item>
      <title>Google Collab Pro+ 运行时断开连接问题</title>
      <link>https://stackoverflow.com/questions/78726238/google-collab-pro-runtime-disconnect-issues</link>
      <description><![CDATA[过去 3 天，我一直在运行笔记本以进行机器学习，一切都按预期进行。突然，运行时断开连接，重新连接后，代码停止执行，这种情况已经发生过多次。
代码很好，因为它使用较小的数据集成功完成，我如何确定是什么原因导致代码停止执行，考虑到 Pro+ 还按每个计算单元收费，这现在花费了一点钱。
所有资源的利用率都远低于 100%，当时有大量计算单元。
如能提供任何帮助，我们将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78726238/google-collab-pro-runtime-disconnect-issues</guid>
      <pubDate>Tue, 09 Jul 2024 14:36:35 GMT</pubDate>
    </item>
    <item>
      <title>我该如何解决 UnicodeDecodeError？</title>
      <link>https://stackoverflow.com/questions/78726197/how-can-i-solve-the-unicodedecodeerror</link>
      <description><![CDATA[我尝试使用我的数据集训练更快的 rcnn，但我总是收到此错误。“UnicodeDecodeError：&#39;utf-8&#39; 编解码器无法解码位置 118 中的字节 0xfd：无效的起始字节”。
这是异常：
UnicodeDecodeError：&#39;utf-8&#39; 编解码器无法解码位置 118 中的字节 0xfd：无效的起始字节
这是回溯：
文件“C:\Users\90531\Desktop\New_tf2\models\research\object_detection\model_main_tf2.py”，第 114 行，位于 &lt;module&gt;
tf.compat.v1.app.run()
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow\python\platform\app.py”，第 36 行，运行中
_run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\absl\app.py”，第 308 行，运行中
_run_main(main, args)
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\absl\app.py”，第 254 行，运行中
sys.exit(main(argv))
文件“C:\Users\90531\Desktop\New_tf2\models\research\object_detection\model_main_tf2.py”，第 105 行，在 main 中
model_lib_v2.train_loop(
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\object_detection\model_lib_v2.py”，第 505 行，在 train_loop 中
configs = get_configs_from_pipeline_file(
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\object_detection\utils\config_util.py”，第 138 行，在 get_configs_from_pipeline_file 中
proto_str = f.read()
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow\python\lib\io\file_io.py”，第 114 行，在 read 中
self._preread_check()
文件“C:\Users\90531\anaconda3\envs\tensorflow2\lib\site-packages\tensorflow\python\lib\io\file_io.py”，第 76 行，在 _preread_check 中
self._read_buf = _pywrap_file_io.BufferedInputStream(
UnicodeDecodeError: &#39;utf-8&#39; 编解码器无法解码位置 118 中的字节 0xfd：起始字节无效

我尝试使用此代码进行训练模型（efficientdet_d0_coco17_tpu-32.tar.gz）：
python model_main_tf2.py --pipeline_config_path==ssd_efficientdet_d0_512x512_coco17_tpu-8.config --model_dir==training --alsologtostderr]]></description>
      <guid>https://stackoverflow.com/questions/78726197/how-can-i-solve-the-unicodedecodeerror</guid>
      <pubDate>Tue, 09 Jul 2024 14:26:30 GMT</pubDate>
    </item>
    <item>
      <title>我需要改变什么参数才能满足要求？</title>
      <link>https://stackoverflow.com/questions/78725972/what-parameter-do-i-need-to-change-for-it-to-match-requirements</link>
      <description><![CDATA[我正在尝试基于修改后的 MNSIT 数据集训练模型，以便它对带有标签 10 的随机图像进行分类。我不断收到 Typeerror。
transform = transforms.Compose([
transforms.ToTensor(),
transforms.Normalize((0.1307,), (0.3081,))
])

dataset1 = datasets.MNIST(root=&#39;./data&#39;, train=True, transform = transform)
dataset2 = datasets.MNIST(root=&#39;./data&#39;, train=False, transform=transform)
num_new_images = 7000
noisy_images = torch.randn(num_new_images, 1, 28, 28)
mean = 0.1307
std = 0.3081
random_images = (noisy_images-mean)/std
noisy_labels = torch.full((num_new_images,),10, dtype=torch.long)
new_dataset = torch.utils.data.TensorDataset(noisy_images, noisy_labels)
combined_dataset = torch.utils.data.ConcatDataset([dataset1, new_dataset])
len(combined_dataset) 
num_val_images = 1000
noisy_images = torch.randn(num_val_images, 1, 28, 28)
random_val_images = (noisy_images-mean)/std
noisy_val_labels = torch.full((num_val_images,),10, dtype=torch.long)
new_val_dataset = torch.utils.data.TensorDataset(random_val_images, noisy_val_labels)
combined_val_dataset = torch.utils.data.ConcatDataset([dataset2, new_val_dataset])
batch_size = 128
train_loader = torch.utils.data.DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(combined_val_dataset, batch_size=batch_size, shuffle=False)

错误：
TypeError Traceback（最近一次调用最后一次）
Cell In[12]，第 74 行
72 # 训练神经网络
73 for epoch in range(num_epochs):
---&gt; 74 对于 train_loader 中的图像、标签：
75 输出 = 模型（图像）
76 损失 = 标准（输出、标签）

文件 ~\PycharmProjects\tensorflow_start\venv\Lib\site-packages\torch\utils\data\dataloader.py:633，在 _BaseDataLoaderIter.__next__(self) 中
630 如果 self._sampler_iter 为 None：
631 # TODO(https://github.com/pytorch/pytorch/issues/76750)
632 self._reset() # 类型：ignore[call-arg]
--&gt; 633 data = self._next_data()
634 self._num_yielded += 1
635 if self._dataset_kind == _DatasetKind.Iterable and \
636 self._IterableDataset_len_called is not None and \
637 self._num_yielded &gt; self._IterableDataset_len_called:

我已经尝试更改标签的数据类型，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/78725972/what-parameter-do-i-need-to-change-for-it-to-match-requirements</guid>
      <pubDate>Tue, 09 Jul 2024 13:43:42 GMT</pubDate>
    </item>
    <item>
      <title>机器学习 [关闭]</title>
      <link>https://stackoverflow.com/questions/78725899/machine-learning</link>
      <description><![CDATA[ final_svm_model = SVC() 
final_nb_model = GaussianNB() 
final_rf_model = RandomForestClassifier(random_state=18) 
final_svm_model.fit(X, y) 
final_nb_model.fit(X, y) 
final_rf_model.fit(X, y) 

test_data = pd.read_csv(&quot;dataset/Testing.csv&quot;).dropna(axis=1) 

test_X = test_data.iloc[:, :-1] 
test_Y =coder.transform(test_data.iloc[:, -1]) 

svm_preds = final_svm_model.predict(test_X) 
nb_preds = final_nb_model.predict(test_X) 
rf_preds = final_rf_model.predict(test_X) 
[mode([i,j,k])[0][0] for i,j,k in zip(svm_preds, nb_preds, rf_preds)] 

cf_matrix = chaos_matrix(test_Y, final_preds) 
plt.figure(figsize=(12,8)) 

sns.heatmap(cf_matrix, annot = True) 

我收到此错误
IndexError：标量变量的索引无效。

我在 mode([i,j,k})[0][0] 附近收到此错误]]></description>
      <guid>https://stackoverflow.com/questions/78725899/machine-learning</guid>
      <pubDate>Tue, 09 Jul 2024 13:27:30 GMT</pubDate>
    </item>
    <item>
      <title>可以将已经经过拆分数据阶段、成为训练、验证和测试数据的图像数据集保存到我的计算机存储文件夹中吗？</title>
      <link>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</link>
      <description><![CDATA[我想问一下我做的训练、验证和测试数据的分布，我可以把数据分布以文件夹的形式保存在存储中吗？可以吗？我希望可以:)
如果你想看完整的代码
https://github.com/cendekialnazalia/CaisimPestDetection/blob/main/Percobaan%20E%20-%20CNN%20add%20Models%20Xception.ipynb
我想下载测试数据部分，即&quot;test_gen&quot;或测试数据集。我希望有人能用一个代码来回答我的问题，这个代码可以将数据保存到我的电脑中，而不必从现有的数据集集合中逐个搜索图像数据
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</guid>
      <pubDate>Tue, 09 Jul 2024 09:41:58 GMT</pubDate>
    </item>
    <item>
      <title>Keras Tensorflow load_model 函数需要很长时间才能加载模型</title>
      <link>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</link>
      <description><![CDATA[我使用 tensorflow 训练了一个模型（用于识别面部），然后将其保存为“facetracker.h5”。但是，当我尝试加载该模型时，它只是继续加载“[*]”，如下图所示，并且实际上从未完成加载。该模型 (facetracker.h5) 只有 68 MB，所以我是否可以认为这种情况不是由于其大小而发生的？：

facetracker 如下所示：

如能提供任何帮助，我们将不胜感激。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</guid>
      <pubDate>Tue, 09 Jul 2024 09:28:15 GMT</pubDate>
    </item>
    <item>
      <title>无法在 Roboflow 上将属性添加到类作为子类</title>
      <link>https://stackoverflow.com/questions/78723630/unable-to-add-attributes-to-classes-as-subclasses-on-roboflow</link>
      <description><![CDATA[我正在使用 Roboflow 注释我的视频，并尝试向标签框（类）添加属性（子类）。我检查了所有资源，最新文档表明，将属性作为子类添加到我的类的功能应该在项目设置页面中可用。但是，我似乎找不到它。
我目前正在使用免费的公共计划。这可能是我无法访问此功能的原因吗？有没有其他人遇到过这个问题？最近更新后免费版本中是否已禁用此功能？如果升级到付费计划可以解决此问题，我愿意考虑。]]></description>
      <guid>https://stackoverflow.com/questions/78723630/unable-to-add-attributes-to-classes-as-subclasses-on-roboflow</guid>
      <pubDate>Tue, 09 Jul 2024 04:00:51 GMT</pubDate>
    </item>
    <item>
      <title>scikit学习交叉验证分数负值</title>
      <link>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</link>
      <description><![CDATA[我试图建立一个线性回归模型来预测房价，以便从机器学习开始，但在使用以下代码中的交叉验证时遇到负分数值：
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
x = df.drop([&#39;MedHouseVal&#39;], axis=1)
y = df[&#39;MedHouseVal&#39;]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
model = LinearRegression()
model.fit(x_train, y_train)
model.score(x_test, y_test)
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=100)
plt.plot(scores)

我注意到，随着 cv 的增加，平均分数下降。因此，我决定绘制它，并意识到分数在某些时候会呈现负值，但真实预测/样本大小怎么会是负数呢？它是用 (TP + TN - FP - FN)/样本大小计算的吗？
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</guid>
      <pubDate>Mon, 08 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用混淆矩阵可视化预测样本</title>
      <link>https://stackoverflow.com/questions/78719068/how-to-visualize-predicted-samples-using-a-confusion-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78719068/how-to-visualize-predicted-samples-using-a-confusion-matrix</guid>
      <pubDate>Mon, 08 Jul 2024 04:07:24 GMT</pubDate>
    </item>
    <item>
      <title>ImportError（'无法导入 PIL.Image。'与 keras-ternsorflow 合作</title>
      <link>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</link>
      <description><![CDATA[我正在学习 lynda.com 上的一些关于在 PyCharmCE 环境中使用 Keras-TensorFlow 进行深度学习的讲座，他们没有遇到这个问题。
我收到此错误：

raise ImportError(&#39;无法导入 PIL.Image。&#39;
ImportError：无法导入 PIL.Image。使用 array_to_img 需要 PIL。

我检查过其他人是否也遇到同样的错误，但对于我来说，使用 pip 安装枕头，命令 pip install Pillow 无法解决任何问题。

MacBook-Pro-de-Rogelio:~ Rogelio$ pip install Pillow
要求已满足：./anaconda3/lib/python3.6/site-packages 中的枕头
MacBook-Pro-de-Rogelio:~ Rogelio$

有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</guid>
      <pubDate>Fri, 12 Jan 2018 11:49:58 GMT</pubDate>
    </item>
    </channel>
</rss>