<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 20 Sep 2024 15:17:15 GMT</lastBuildDate>
    <item>
      <title>复杂、混乱、非线性序列中的下一个数字 [关闭]</title>
      <link>https://stackoverflow.com/questions/79006702/next-number-in-a-complex-chaotic-and-non-linear-sequence</link>
      <description><![CDATA[查看图片
我试图预测一个复杂、混乱且非线性序列中的下一个数字。即使我无法准确预测下一个数字，我也想发现影响序列中值的模式。我认为可能发生的情况如下：
多种因素在起作用：序列中的每个数字可能受到多种不同属性或因素的影响，并且这些因素可以以复杂的方式相互作用。
可能存在噪音：序列可能包含噪音或异常，这意味着可能存在混淆事物的假阳性或假阴性。
属性之间的相互作用：某些属性可能不会产生孤立的影响，而是可以与其他属性（来自序列中的不同位置）相互作用以影响数字的值。
模式发现和预测：最终，我的目标是识别任何潜在模式（如果存在）。即使它是一个混乱的系统，我也希望预测序列中下一个数字的成功率至少达到 60%。
训练数据的困难：鉴于系统非常混乱，我不确定是否可以通过传统方式在一组测试数据上训练系统。
我需要帮助：

使用神经网络是解决此问题的最佳方法吗？
是否有任何现有程序或产品可用于解决此问题？

到目前为止我还没有尝试过任何方法]]></description>
      <guid>https://stackoverflow.com/questions/79006702/next-number-in-a-complex-chaotic-and-non-linear-sequence</guid>
      <pubDate>Fri, 20 Sep 2024 12:16:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 tch-rs 在 rust 中实现残差神经网络</title>
      <link>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</link>
      <description><![CDATA[我正在尝试使用 tch-rs (Torch) 在 rust 中实现前馈残差神经网络。
到目前为止，这是我的代码：（这是一个最小的可重现示例）
use tch::{nn::{self, batch_norm1d, layer_norm, BatchNormConfig, ConvConfigND, LayerNormConfig, Module, ModuleT}, Tensor};
const NUM_HIDDEN: i64 = 10;

fn res_block(vs: &amp;nn::Path) -&gt; impl ModuleT {
let mut default = ConvConfigND::default();
default.padding = 1;
let conv1 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn1 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
让 conv2 = nn::conv1d(vs, NUM_HIDDEN, NUM_HIDDEN, 3, default);
让 bn2 = batch_norm1d(vs, NUM_HIDDEN, BatchNormConfig::default());
nn::func_t(|x,train| {
let mut residual = Tensor::new();
x.clone(&amp;residual);
let x = bn1.forward_t(&amp;conv1.forward(x),train).relu();
let x = bn2.forward_t(&amp;conv2.forward(&amp;x),train);
let x = x + residual;
return x.relu();
})
}

当我编译此代码时，出现此错误：
`*mut torch_sys::C_tensor` 无法在线程之间安全地共享
在 `BatchNorm` 中，`*mut torch_sys::C_tensor` 未实现特征 `Sync`，而这是 `{closure@src\nn.rs:11:16: 所要求的11:25}：`&amp;BatchNorm` 实现 `Send` 所需的 Send

当我将 forward_t 行放入 func_t 中时，会发生此问题。
我该如何让它工作？
我也尝试使用顺序网络，但它们无法进一步传递残差变量。有没有办法让它工作？还是我需要做其他事情？]]></description>
      <guid>https://stackoverflow.com/questions/79006068/residual-neural-network-in-rust-with-tch-rs</guid>
      <pubDate>Fri, 20 Sep 2024 09:07:36 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 lbl2vec 中的 SSL 认证错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/79005521/how-to-solve-ssl-certificaiton-error-in-lbl2vec</link>
      <description><![CDATA[我正在使用 lbl2vec 标记一些非结构化文本数据。但我开始收到 SSL 证书错误。如何解决此问题？
错误详细信息：
SSLError: (MaxRetryError(&quot;HTTPSConnectionPool(host=&#39;huggingface.co&#39;, 
port=443): url 的最大重试次数已超出：/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json 
(由 SSLError(SSLCertVerificationError(1, &#39;[SSL: CERTIFICATE_VERIFY_FAILED] 
证书验证失败：无法获取本地颁发者证书 (_ssl.c:1000)&#39;)))&quot;), &#39;(请求 ID：xxxxxxxxxxxxxxxxxxxxxxxx)&#39;)

引发错误的代码：
from lbl2vec import Lbl2Vec

#使用参数初始化模型
Lbl2Vec_model = Lbl2Vec(keywords_list=list(labels.keywords), tagged_documents=newsgroup_full_corpus[&#39;tagged_docs&#39;][newsgroup_full_corpus[&#39;data_set_type&#39;] == &#39;train&#39;], label_names=list(labels.class_name), similarity_threshold=0.43, min_num_docs=100, epochs=10)

# 训练模型
Lbl2Vec_model.fit()
]]></description>
      <guid>https://stackoverflow.com/questions/79005521/how-to-solve-ssl-certificaiton-error-in-lbl2vec</guid>
      <pubDate>Fri, 20 Sep 2024 06:36:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 selenium 和 beautifulsoup 在 RAG 模型中进行 Web 抓取 [关闭]</title>
      <link>https://stackoverflow.com/questions/79005517/web-scraping-using-selenium-and-beautifulsoup-for-using-in-a-rag-model</link>
      <description><![CDATA[我想为一个项目做网页抓取。
该项目已经实施了一个 rag，我想向模型添加更多信息，因此决定从 youtube 中提取成绩单并使用它来获得更概括的方法。
从 youtube 链接获取和生成成功。但是，当我尝试将网站考虑在内时，我遇到了困难。
因此，我所做的就是我已经使用 html praser 和正则表达式来消除数据噪音，仍然提取网站的评论部分和一些与数据连接相关的内容。
我尝试过的技术是“selenium”、“beautifulsoul”
我做了 html praser 并使用正则表达式来消除数据中的噪音，但它仍然存在。]]></description>
      <guid>https://stackoverflow.com/questions/79005517/web-scraping-using-selenium-and-beautifulsoup-for-using-in-a-rag-model</guid>
      <pubDate>Fri, 20 Sep 2024 06:34:55 GMT</pubDate>
    </item>
    <item>
      <title>在将作业提交给 QPU 之前，如何预先检查代码中的错误？[关闭]</title>
      <link>https://stackoverflow.com/questions/79005253/how-to-check-for-errors-beforehand-in-the-code-before-submitting-the-job-to-qpu</link>
      <description><![CDATA[在 QSVM 中，有没有办法在将量子代码提交给 QPU 进行处理之前检查错误？因为即使代码有错误，QPU 也会运行，这意味着我们将白白浪费大量时间。那么，有没有什么方法可以解决这个问题呢？]]></description>
      <guid>https://stackoverflow.com/questions/79005253/how-to-check-for-errors-beforehand-in-the-code-before-submitting-the-job-to-qpu</guid>
      <pubDate>Fri, 20 Sep 2024 04:51:21 GMT</pubDate>
    </item>
    <item>
      <title>完成 model.register 后，如何在新的 SageMaker Studio UI 中访问评估指标？</title>
      <link>https://stackoverflow.com/questions/79005084/how-to-access-evaluation-metrics-in-new-sagemaker-studio-ui-after-doing-model-re</link>
      <description><![CDATA[我正在为机器学习模型构建 MLOP 管道。注册模型后，如何在 SageMake Studio UI 中访问模型的评估指标？
这是我在 S3 中保存的示例 evaluation.json
{
&quot;metric_groups&quot;: [
{
&quot;name&quot;: &quot;regression_metrics&quot;,
&quot;metric_data&quot;: [
{
&quot;name&quot;: &quot;mse&quot;,
&quot;value&quot;: 6107087691.96
},
{
&quot;name&quot;: &quot;mae&quot;,
&quot;value&quot;: 46717.104
},
{
&quot;name&quot;: &quot;rmse&quot;,
&quot;value&quot;: 78147.85
},
{
&quot;name&quot;: &quot;r2&quot;,
&quot;value&quot;: 0.90
]
}
]
}

这是我的注册步骤：
import logs
from sagemaker.workflow.functions import Join
from sagemaker.model_metrics import MetricsSource, ModelMetrics
from sagemaker.workflow.step_collections import RegisterModel

def create_register_step(
role,
sagemaker_session,
model_package_group_name,
model_approval_status,
training_step,
evaluation_step
):

logs.basicConfig(level=logging.INFO)
logs.info(f&#39;创建注册步骤&#39;)

# log evaluation_report
logs.info(f&#39;评估报告：{evaluation_step}&#39;)

evaluation_s3_uri = evaluation_step.properties.ProcessingOutputConfig.Outputs[&#39;evaluation&#39;].S3Output.S3Uri

model_metrics = ModelMetrics(
model_statistics=MetricsSource(
s3_uri=Join(
on=&quot;/&quot;,
values=[
evaluation_s3_uri,
&quot;evaluation.json&quot;
]
),
content_type=&quot;application/json&quot;
)
)

# 创建 RegisterModel 步骤
register_step = RegisterModel(
name=&#39;ModelRegisterStep&#39;,
estimator=training_step.estimator,
model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,
content_types=[&quot;text/csv&quot;],
response_types=[&quot;text/csv&quot;],
inference_instances=[&quot;ml.m5.large&quot;, &quot;ml.m5.xlarge&quot;],
transform_instances=[&quot;ml.m5.large&quot;],
model_package_group_name=model_package_group_name,
approved_status=model_approval_status,
model_metrics=model_metrics
)

return register_step


我的管道执行成功，但我看不到评估指标
附加图片
我也尝试过手动将 S3 中的评估报告添加到模型版本中，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/79005084/how-to-access-evaluation-metrics-in-new-sagemaker-studio-ui-after-doing-model-re</guid>
      <pubDate>Fri, 20 Sep 2024 03:26:51 GMT</pubDate>
    </item>
    <item>
      <title>R 中一个记录与另一个数据集之间的 Gower 距离[迁移]</title>
      <link>https://stackoverflow.com/questions/79004932/gower-distance-between-one-record-and-another-dataset-in-r</link>
      <description><![CDATA[我想计算数据集 1 的一条记录与数据集 2 的所有记录之间的 Gower 距离。我可以编写如下代码吗？
library(gower)

data(iris)
dat1 &lt;- iris[1:10,]
dat2 &lt;- iris[11:30,]

gower::gower_dist(dat1[1,], dat2)

这给了我长度为 20 的结果。

0.09079365 0.09873016 0.16142857 0.29476190 0.20920635 0.33079365 0.21936508 0.05000000 0.23952381 0.11507937 0.12095238 0.15079365 0.16984127 0.24523810 0.16539683 0.12920635 0.17206349 0.03555556 0.02761905 0.14063492

我可以将第一个值解释为 dat1[1,] 和 dat2[1,] 之间的 gower 距离，将第二个值解释为 dat1[1,] 和 dat2[2,] 之间的 gower 距离，依此类推吗？
让我感到困惑的是，如果我计算
gower::gower_dist(dat1[1,],dat2[1,])

，这给了我

0.75

它应该是 0.09079365 吗？为什么是 0.75？
最终，我想计算 dat1 中每个观测值与 dat2 中每个观测值的 gower 距离。]]></description>
      <guid>https://stackoverflow.com/questions/79004932/gower-distance-between-one-record-and-another-dataset-in-r</guid>
      <pubDate>Fri, 20 Sep 2024 01:30:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 MATLAB 和 Roboflow 从标记图像测量裂缝宽度 [关闭]</title>
      <link>https://stackoverflow.com/questions/79003546/measuring-crack-width-from-labeled-images-using-matlab-and-roboflow</link>
      <description><![CDATA[我有一个包含裂缝的图像数据集，我使用 MATLAB 中的像素标记对其进行了标记。我使用 Roboflow 用这些标记图像训练了一个模型。现在，我想测量图像中裂缝的宽度。图像还有一个网格供参考
具体来说，我需要模型：

测量裂缝宽度。
将裂缝归类为：

&quot;小于 0.3 毫米&quot;
&quot;大于 0.3 毫米&quot;



此外，输出应包括裂缝的类型（例如，发际线、结构等）。
我到目前为止尝试过的方法：
我已经使用 Roboflow 训练了模型，但我不确定如何继续测量裂缝宽度。
我探索过使用 MATLAB 进行像素标记，但还没有找到正确的方法来计算宽度并根据 0.3 毫米阈值对其进行分类。
问题：
我应该采用什么方法来测量图像中的裂缝宽度？
是否有特定的工具、库或软件（除 MATLAB 和 Roboflow 之外）可以帮助完成这项任务？
有人可以推荐相关课程或文档来帮助我改进我的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79003546/measuring-crack-width-from-labeled-images-using-matlab-and-roboflow</guid>
      <pubDate>Thu, 19 Sep 2024 16:18:54 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface Pretrained 中 device_map = "auto" 的替代方案</title>
      <link>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</link>
      <description><![CDATA[我有一个从 huggingface 读取的模型，使用以下代码：
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

现在我读取了模型，并对内部层做了一些修改，并添加了更多层。当我开始训练/微调时，我发现并非所有东西都在同一个模型上。
现在经过更多调查，我发现我的自定义层没有像原始模型那样分布在多个 GPU 上。因此我需要类似 device_map=&quot;auto&quot; 的内容，但在读取模型之后。
因此只需类似
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map=&quot;auto&quot;, trust_remote_code=True)

model.device_map = &quot;auto&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/78985137/alternative-to-device-map-auto-in-huggingface-pretrained</guid>
      <pubDate>Sat, 14 Sep 2024 12:42:03 GMT</pubDate>
    </item>
    <item>
      <title>尽管分类报告很好，但模型无法正确预测</title>
      <link>https://stackoverflow.com/questions/78976316/model-cant-predict-correctly-even-though-has-a-good-classification-report</link>
      <description><![CDATA[我尝试从链接运行此模型：
https://www.kaggle.com/code/alexfordna/garbage-classification-mobilenetv2-92-accuracy/notebook
当我在 colab 上使用类似数据集（但较小，2100 张图片到 6 个类）执行此操作时，效果很好。但是当我添加此代码来预测输入图像时：
from google.colab import files
from PIL import Image

def process_uploaded_image(image_path, target_size=(224, 224)):
img = Image.open(image_path)
img = img.resize(target_size) 
img_array = np.array(img) 

if img_array.shape[-1] == 4: 
img_array = img_array[..., :3]

img_array = img_array / 255.0 
img_array = np.expand_dims(img_array, axis=0) 
img_array = mobilenetv2.preprocess_input(img_array) 

return img_array

uploaded = files.upload()

for fn in uploaded.keys(): 
processed_image = process_uploaded_image(fn, target_size=IMAGE_SIZE) 
preds = model.predict(processed_image)
pred_class = np.argmax(preds, axis=1)

plt.imshow(Image.open(fn)) # 显示上传的图片
plt.title(f&#39;预测的类别：{categories[pred_class[0]]}&#39;)
plt.axis(&#39;off&#39;)
plt.show()
print(f&#39;文件 {fn} 被预测为：{categories[pred_class[0]]}&#39;)

结果是错误的预测。例如，模型总是将我的输入预测为“垃圾”类。当我停止运行时，它会更改为另一个类，但它仍然处于错误的预测中。
我还添加了此代码来检查预测概率：
preds = model.predict(processed_image)
pred_probs = preds[0] # 获取第一个（也是唯一一个）批次的预测概率
print(&quot;Prediction probabilities:&quot;, pred_probs)
pred_class = np.argmax(pred_probs)
print(&quot;Predicted class:&quot;, categories[pred_class])

输出：
**1/1** ━━━━━━━━━━━━━━━━━━━━━━ **0s** 24ms/步 预测概率：\[0.31027108 0.12315894 0.47848797 0.00863316 0.07789086 0.00155797\] 
预测类别：金属 

为什么会发生这种情况，我的模型如何正确预测结果？]]></description>
      <guid>https://stackoverflow.com/questions/78976316/model-cant-predict-correctly-even-though-has-a-good-classification-report</guid>
      <pubDate>Thu, 12 Sep 2024 02:58:40 GMT</pubDate>
    </item>
    <item>
      <title>预测多元时间序列（《动手机器学习》一书第 15 章）错误</title>
      <link>https://stackoverflow.com/questions/77623127/forecasting-multivariate-time-series-in-chapter-15-of-the-book-hands-on-machin</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77623127/forecasting-multivariate-time-series-in-chapter-15-of-the-book-hands-on-machin</guid>
      <pubDate>Thu, 07 Dec 2023 21:20:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 nltk 中下载 punkt tokenizer？</title>
      <link>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</link>
      <description><![CDATA[我使用 安装了 NLTK 库
pip install nltk

在使用库时
from nltk.tokenize import sent_tokenize 
sent_tokenize(text)

我收到此错误
LookupError: 
**************************************************************************
未找到资源 punkt。
请使用 NLTK 下载器获取资源：

&gt;&gt;&gt; import nltk
&gt;&gt;&gt; nltk.download(&#39;punkt&#39;)

有关更多信息，请参阅：https://www.nltk.org/data.html

尝试加载 tokenizers/punkt/english.pickle

搜索位置：
- &#39;C:\\Users\\adars/nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\share\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Roaming\\nltk_data&#39;
- &#39;C:\\nltk_data&#39;
- &#39;D:\\nltk_data&#39;
- &#39;E:\\nltk_data&#39;
- &#39;&#39;

因此，为了解决此错误，我尝试了
import nltk
nltk.download(&#39;punkt&#39;)

但是我无法下载此包，因为每次运行此包时都会出现错误，提示
[nltk_data] 加载 punkt 时出错：&lt;urlopen 错误 [WinError 10060] A
[nltk_data] 连接尝试失败，因为连接方
[nltk_data] 在一段时间后未正确响应，或者
[nltk_data] 建立连接失败，因为连接的主机
[nltk_data] 未响应&gt;

请帮帮我]]></description>
      <guid>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</guid>
      <pubDate>Tue, 19 Sep 2023 04:36:59 GMT</pubDate>
    </item>
    <item>
      <title>如何继续openai API的不完整响应</title>
      <link>https://stackoverflow.com/questions/76206459/how-to-continue-incomplete-response-of-openai-api</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76206459/how-to-continue-incomplete-response-of-openai-api</guid>
      <pubDate>Tue, 09 May 2023 06:33:09 GMT</pubDate>
    </item>
    <item>
      <title>如何继续进一步训练预先训练的 YOLOv8 模型</title>
      <link>https://stackoverflow.com/questions/75730103/how-to-continue-to-further-train-a-pre-trained-yolov8-model</link>
      <description><![CDATA[我已经在自定义数据集上训练了一个包含 4 个类别的 YOLOv8 模型，用于对象检测。
现在我想通过增加数据集来训练它以检测更多类别。
我是否可以在新数据集上进一步专门训练它，而不是从头开始训练模型？]]></description>
      <guid>https://stackoverflow.com/questions/75730103/how-to-continue-to-further-train-a-pre-trained-yolov8-model</guid>
      <pubDate>Tue, 14 Mar 2023 07:23:23 GMT</pubDate>
    </item>
    <item>
      <title>np.where：“ValueError：操作数不能与形状一起广播（38658637，）（9456，）”</title>
      <link>https://stackoverflow.com/questions/62721390/np-where-valueerror-operands-could-not-be-broadcast-together-with-shapes-386</link>
      <description><![CDATA[我有两个具有两种不同形状的数据框：

df_rts_1 #Shape: (38658637, 7)
df_crsh_rts #Shape: (9456, 6)

我尝试使用 np.where 根据以下特定条件将列值 (df_rts_1[&#39;crash&#39;]) 更新为等于 1：

df_rts_1[&#39;tmc_code&#39;]= df_crsh_rts[&#39;tmc&#39;]
df_rts_1[&#39;measurement_tstamp&#39;] 介于 df_crsh_rts[&#39;Start_time&#39;] 和df_crsh_rts[&#39;Closed_time&#39;]

我的代码：
df_rts_1[&#39;crash&#39;] = np.where((df_rts_1[&#39;tmc_code&#39;].values == df_crsh_rts[&#39;tmc&#39;].values) &amp; ((df_rts_1[&#39;measurement_tstamp&#39;].values &gt; df_crsh_rts[&#39;Start_time&#39;].values) &amp; (df_rts_1[&#39;measurement_tstamp&#39;].values &gt; df_crsh_rts[&#39;Closed_time&#39;].values)), 1, df_rts_1[&#39;crash&#39;])

我收到了标题中的错误。我对 Python/数据科学还很陌生。]]></description>
      <guid>https://stackoverflow.com/questions/62721390/np-where-valueerror-operands-could-not-be-broadcast-together-with-shapes-386</guid>
      <pubDate>Fri, 03 Jul 2020 19:07:11 GMT</pubDate>
    </item>
    </channel>
</rss>