<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 22 Apr 2024 12:26:54 GMT</lastBuildDate>
    <item>
      <title>使用 python 绘制糖尿病视网膜病变检测图</title>
      <link>https://stackoverflow.com/questions/78365786/mapping-in-a-diabetic-retinopathy-detection-using-python</link>
      <description><![CDATA[我目前正在开发一个使用 Inception V3 预训练模型进行糖尿病视网膜病变分类的 Python 程序，然后将其传递给 SVM 和随机森林分类器。快速分解该项目：

对 5 种类型（0、1、2、3、4）的眼睛图像进行分类，其中 0 表示没有患病，4 表示严重。
在这个特定的程序中，我有意将 0,1 图像映射到值 10，将 2,3,4 映射到值 11，将其变成二元分类器。
然后构建模型，然后正确训练和执行。

为了提供有关我的代码工作的更多详细信息，我想显示图像的特定映射。
我建了两个表：
表 1：它有三列，第一列是从 xero 开始的所有图像的编号，第二列是与图像对应的唯一标识符，第三列是类的原始映射 0、1、2 ,3,4。
表 2：前两列相同，但第三列现在显示映射的 ID（10 或 11）
一些有帮助的图片是：
图片 1
图片_2 图片 3
图片 4
我尝试实现上述问题，但是 2,3,4 的映射没有出现，只有 0,1 的映射出现。请帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78365786/mapping-in-a-diabetic-retinopathy-detection-using-python</guid>
      <pubDate>Mon, 22 Apr 2024 11:05:03 GMT</pubDate>
    </item>
    <item>
      <title>预测值与目标值/实际值之间没有相关性</title>
      <link>https://stackoverflow.com/questions/78365619/no-correlation-between-predicted-values-and-target-value-real-values</link>
      <description><![CDATA[我目前正在开发一个机器学习项目。具体来说是回归任务。当我绘制预测值与实际值时，我发现变量之间没有相关性。我猜这意味着模型无法拟合数据（类似于分类模型预测最常见的类别）。未进行转换的预测值与实际值实际值与绝对值错误信息
我尝试了很多方法，但没有一个能够使模型适合数据：

我尝试用对数函数转换目标值：

y_train = np.log(y_train)
y_test = np.log(y_test)

对数变换的预测值与实际值

我对目标变量应用了平方根函数，但它不起作用：

&lt;前&gt;&lt;代码&gt;y_train = (y_train)**0.5
y_测试 = (y_测试)**0.5

平方根变换的预测值与实际值

我什至尝试标准化目标函数，但也不起作用

def preprocess_data_standard_regression(数据):
    定标器=标准定标器()
    X = data[[data.columns 中的 col 的 col
              如果不是 col.startswith(&quot;POSTOP_&quot;)
              并且 col !=“in_患者_id”
              和 col !=“in_laterity”]]
    y = 数据[“POSTOP_MAN_vault_posto”]
    y = scaler.fit_transform(y.values.reshape(-1,1)).flatten()
    缩放器 = MinMaxScaler()
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)
    X_train = 缩放器.fit_transform(X_train)
    X_test = 缩放器.transform(X_test)
    返回 X_train、X_test、y_train、y_test

标准化后的结果
我的数据集的形状是 545 行 vs 24 列。
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78365619/no-correlation-between-predicted-values-and-target-value-real-values</guid>
      <pubDate>Mon, 22 Apr 2024 10:41:06 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该始终在神经网络初始化部分中包含初始化层？</title>
      <link>https://stackoverflow.com/questions/78365535/should-i-always-include-initialization-layers-in-my-neural-network-initializatio</link>
      <description><![CDATA[我看到有人的代码包含使用Xavier这种方式（如下），该代码用于预测具有1400行和300个变量（80个，在one-hot-encoding之前）的房价数据。我查了一下它的描述，上面说防止梯度消失或爆炸，加速收敛。这似乎都是有益的，所以我应该始终在代码中包含 Xavier 初始化吗？或者我什么时候不应该包括 Xavier？ TIA
类 Net(torch.nn.Module):
    def __init__(自身):
        超级(网络,自我).__init__()
        self.hidden_​​layer1 = nn.Linear(331,1024)
        self.hidden_​​layer2 = nn.Linear(1024,1024)
        self.hidden_​​layer3 = nn.Linear(1024,1024)
        self.hidden_​​layer4 = nn.Linear(1024,1024)
        self.output_layer = nn.Linear(1024,1)
        self.dropout = nn.Dropout(p=0.2)
        nn.init.xavier_uniform_(self.hidden_​​layer1.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer2.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer3.weight)
        nn.init.xavier_uniform_(self.hidden_​​layer4.weight)
        nn.init.xavier_uniform_(self.output_layer.weight)

defforward(self,x)：
    输入 = x
    layer1_out = torch.nn.function.gelu(self.hidden_​​layer1(输入))
    Layer1_out = self.dropout(layer1_out)
    Layer2_out = torch.nn.function.gelu(self.hidden_​​layer2(layer1_out))
    Layer2_out = self.dropout(layer2_out)
    Layer3_out = torch.nn.function.gelu(self.hidden_​​layer3(layer2_out))
    Layer3_out = self.dropout(layer3_out)
    Layer4_out = torch.nn.function.gelu(self.hidden_​​layer4(layer3_out))
    Layer4_out = self.dropout(layer4_out)
    输出 = torch.relu(self.output_layer(layer4_out))
    返回输出

我一直在尝试学习深度学习，但我一直不清楚在神经网络中包含初始化的重要性。]]></description>
      <guid>https://stackoverflow.com/questions/78365535/should-i-always-include-initialization-layers-in-my-neural-network-initializatio</guid>
      <pubDate>Mon, 22 Apr 2024 10:25:38 GMT</pubDate>
    </item>
    <item>
      <title>您好，请帮忙，我遇到了 djangorestframework 的错误问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78365482/hi-there-help-plz-im-facing-an-error-issue-with-djangorestframework</link>
      <description><![CDATA[我尝试使用 djangorestframework 创建 API，但遇到错误问题，有人可以帮助我调试吗？我的代码如下
serializers.py：
从rest_framework导入序列化器
从rest_framework.exceptions导入ValidationError

类 ImagePredictionSerializer(serializers.Serializer):
    图像 = 序列化器.ImageField()

    def validate_image(自身, 值):
        如果没有值：
            raise ValidationError(“图像字段为必填项”)
        返回值

错误：
/api/upload/ 处出现类型错误
“方法”对象不支持项目分配
请求方式：GET
请求网址：http://127.0.0.1:8000/api/upload/
Django 版本：4.2.3
异常类型：TypeError
异常值：
“方法”对象不支持项目分配
异常位置：C:\src\Django_tuto\fridgevision\env\Lib\site-packages\django\middleware\clickjacking.py，第 34 行，在 process_response 中
在 process.serializers.ImagePredictionSerializer 期间引发
Python 可执行文件：C:\src\Django_tuto\fridgevision\env\Scripts\python.exe
Python版本：3.11.8
Python路径：
[&#39;C:\\src\\Django_tuto\\fridgevision&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\python311.zip&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\DLLs&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311\\Lib&#39;,
 &#39;C:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python311&#39;,
 &#39;C:\\src\\Django_tuto\\fridgevision\\env&#39;,
 &#39;C:\\src\\Django_tuto\\fridgevision\\env\\Lib\\site-packages&#39;]
服务器时间：2024年4月22日周一10:00:10 +0000

我希望获得模型输入图像的预测。这是一个简单的二值分类模型，可以预测图像是好还是坏。]]></description>
      <guid>https://stackoverflow.com/questions/78365482/hi-there-help-plz-im-facing-an-error-issue-with-djangorestframework</guid>
      <pubDate>Mon, 22 Apr 2024 10:15:50 GMT</pubDate>
    </item>
    <item>
      <title>测量 pytorch 模型的 FPS 的正确方法是什么？</title>
      <link>https://stackoverflow.com/questions/78365230/which-is-correct-way-to-measure-fps-of-pytorch-model</link>
      <description><![CDATA[当我使用此代码时，我通过 cuda 事件（8.7 FPS）和 pref_counter （8.8 FPS）获得几乎相同的 FPS 值
 model.to(设备)

    宽、高 = 640, 640
    dummy_input = torch.randn(200, 1, 3, w, h, dtype=torch.float).to(设备)

    步骤、重复次数 = 10, 100
        # 分配 40MB 来匹配 A100 上的 L2 缓存大小
    x = torch.empty(int(40 * (1024 ** 2)), dtype=torch.int8, device=&#39;cuda&#39;)

    deflush_cache():
        x.zero_()

    # 热身步骤
    对于范围内的 i（步数）：
        _ = model(dummy_input[i]) # 不记录时间

    start_events = [torch.cuda.Event(enable_timing=True) for _ in range(repetitions)]
    end_events = [torch.cuda.Event(enable_timing=True) for _ in range(repetitions)]

    for i in tqdm(范围(重复), desc=&#39;进度&#39;):
        刷新缓存（）
        torch.cuda._sleep(1_000_000)

        start_events[i].record()
        _ = 模型(dummy_input[i])
        end_events[i].record()

    torch.cuda.synchronize()
    times = [s.elapsed_time(e) for s, e in zip(start_events, end_events)]

    # 重置时钟速度()
    
    Mean_syn = np.sum(次) / 重复次数
    fps = 1000 / 均值_syn

    print(&quot;平均推理时间: {:.4f} ms&quot;.format(mean_syn))
    print(&quot;平均 FPS {} x {}: {:.4f}&quot;.format(w, h, fps))

    # 热身步骤
    对于范围内的 i（步数）：
        _ = model(dummy_input[i]) # 不记录时间

    时间=0
    for i in tqdm(范围(重复), desc=&#39;进度&#39;):
        s = time.perf_counter()
        _ = 模型(dummy_input[i])
        e = time.perf_counter()
        t += (e-s)

    每秒帧数 = 100/吨
    print(“平均 FPS {} x {}: {:.4f}”.format(w, h, fps))

但是如果我在 pref_counter 方法中添加 torch.cuda.empty_cache() ，那么 pref_counter 方法中的 FPS 将变为 34.8。
 for i in tqdm(range(repetitions), desc=&#39;Progress&#39;):
        torch.cuda.empty_cache()
        s = time.perf_counter()
        _ = 模型(dummy_input[i])
        e = time.perf_counter()
        t += (e-s)

    每秒帧数 = 100/吨
    print(&quot;平均 FPS {} x {}: {:.4f}&quot;.format(w, h, fps))

那么哪个是正确的以及为什么会发生这种情况。有人可以帮忙吗？
我也尝试将 torch.cuda.empty_cache() 包含在 cuda 事件中，但 FPS 在 cuda 事件方法中保持不变。]]></description>
      <guid>https://stackoverflow.com/questions/78365230/which-is-correct-way-to-measure-fps-of-pytorch-model</guid>
      <pubDate>Mon, 22 Apr 2024 09:28:52 GMT</pubDate>
    </item>
    <item>
      <title>SpaCy 微调 GPU</title>
      <link>https://stackoverflow.com/questions/78364403/spacy-fine-tuning-gpu</link>
      <description><![CDATA[我使用 spaCy 和 classy 分类训练文本分类器。但模型训练时不使用gpu，fine-tuning时间很长
GPU信息
&lt;前&gt;&lt;代码&gt;$ nvidia-smi
2024 年 4 月 22 日星期一 09:41:13
+------------------------------------------------ --------------------------------------+
| NVIDIA-SMI 545.29.06 驱动程序版本：545.29.06 CUDA 版本：12.3 |
|------------------------------------------+----- ---------------+--------------------+
| GPU 名称持久性-M |总线 ID Disp.A |挥发性未校正。 ECC |
|风扇温度性能功率：使用/上限 |内存使用情况 | GPU-Util 计算 M。
| | |米格·M。
|============================================+======== ==============+======================|
| 0 NVIDIA GeForce GTX 1650 Ti 关闭 | 00000000:01:00.0 关闭 |不适用 |
|不适用 62C P8 1W / 50W | 6MiB / 4096MiB | 0% 默认 |
| | |不适用 |
+----------------------------------------------------+----- ---------------+--------------------+
                                                                                         
+------------------------------------------------ --------------------------------------+
|流程：|
| GPU GI CI PID 类型 进程名称 GPU 内存 |
| ID ID 用途 |
|=================================================== ========================================|
| 0 不适用 不适用 2154 G /usr/bin/gnome-shell 1MiB |
+------------------------------------------------ --------------------------------------+

GPU 可用于 cupy
导入 cupy 作为 cp
x = cp.array([1, 2, 3])
打印（x）

[1 2 3]

GPU 可用于手电筒
导入火炬
打印（火炬.__版本__）
打印（火炬.版本.cuda）

将张量流导入为 tf
打印（tf.__版本__）
打印（tf.test.gpu_device_name（））

12.1
2.15.0
/设备:GPU:0

我已经尝试过这个。
spacy.require_gpu()

还有这个
spacy.prefer_gpu(0)

nlp.add_pipe(
 &#39;classy_classification&#39;,
 配置={
      “数据”：train_samples，
      &#39;model&#39; : &#39;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&#39;,
      &#39;设备&#39;：&#39;GPU&#39;，
      “详细”：正确
    }
）
]]></description>
      <guid>https://stackoverflow.com/questions/78364403/spacy-fine-tuning-gpu</guid>
      <pubDate>Mon, 22 Apr 2024 06:47:09 GMT</pubDate>
    </item>
    <item>
      <title>无法导入 py 文件并出现以下错误消息：无法解析导入“load_images”(reportMissingImports)</title>
      <link>https://stackoverflow.com/questions/78364383/the-py-file-cannot-be-imported-and-the-following-error-message-appears-import</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78364383/the-py-file-cannot-be-imported-and-the-following-error-message-appears-import</guid>
      <pubDate>Mon, 22 Apr 2024 06:43:40 GMT</pubDate>
    </item>
    <item>
      <title>Python 机器学习代码故障排除：Fit 函数问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78364124/troubleshooting-python-machine-learning-code-issues-with-fit-function</link>
      <description><![CDATA[我正在尝试构建一个机器学习模型，但效果不是很好。有人可以帮我吗？这是我的代码。我创建这段代码是为了我的练习和理解。如果可能的话，有人可以帮助我使用此代码吗？
我用来训练代码的数据位于此处
将 numpy 导入为 np

将 pandas 导入为 pd



# 数据准备

data = pd.read_csv(&#39;调查肺癌.csv&#39;)

测试数据 = data.head(300)



# 取消注释以使用特定列

# x1 = 测试数据[&#39;性别&#39;]

# x2 = 测试数据[&#39;年龄&#39;]



# 使用除“LUNG_CANCER”之外的所有列

x = 测试数据.列

Xc = np.array([testdata[i] for i in x if i != &#39;LUNG_CANCER&#39;])

X = np.column_stack((np.ones(300), Xc.T))



# 将“GENDER”编码为二进制

对于范围内的 i(len(X.T[1]))：

    如果 X.T[1][i] == &#39;M&#39;，则 X.T[1][i] = 1，否则 0



# 将“LUNG_CANCER”编码为二进制

y = testdata[&#39;LUNG_CANCER&#39;].apply(lambda x: 1 if x == &#39;yes&#39; else 0)



# 逻辑回归实现

逻辑回归类：

    def __init__(自身, X, y, lr=0.01, n=1000):

        自我.X = X

        自我.y = y

        self.weight = np.zeros(X.shape[1])

        self.lr = lr

        self.n_iter = n



    @静态方法

    定义 sigmoid(z):

        返回 1 / (1 + np.exp(-z))



    def 适合（自我）：

        对于 _ 在范围内（self.n_iter）：

            y_pred = np.dot(self.X, self.weight)

            pred = self.sigmoid(y_pred)

            dw = (1 / self.X.shape[0]) * np.dot(self.X.T, pred - self.y)

            self.weight -= self.lr * dw

        返回自重



    def 预测（自我，信息）：

        z = np.dot(信息, self.weight)

        prob = self.sigmoid(z)

        如果 prob &gt; 则返回 1 0.5 否则 0



# 测试模型

测试=逻辑回归（X，y）

打印（测试.fit（））

信息 = np.array([1, 1, 64, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2])

预测=测试.预测（信息）

打印（预测）
]]></description>
      <guid>https://stackoverflow.com/questions/78364124/troubleshooting-python-machine-learning-code-issues-with-fit-function</guid>
      <pubDate>Mon, 22 Apr 2024 05:31:10 GMT</pubDate>
    </item>
    <item>
      <title>我对我创建的 PINNs 模型有疑问 [关闭]</title>
      <link>https://stackoverflow.com/questions/78363881/i-have-doubts-about-the-pinns-model-that-i-created</link>
      <description><![CDATA[我尝试为一维表面波高程创建 PINN，输入为 (x,t)。经过长时间的尝试和错误，我意识到我的模型仍然不适合。我对之前创建的代码产生了怀疑，但又找不到错误所在，因为训练过程一直运行得很顺利。
我的代码哪里出错了？
导入tensorflow为tf
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

# 转换为 TensorFlow 张量
x_train = tf.convert_to_tensor(x, dtype=tf.float32)
t_train = tf.convert_to_tensor(t, dtype=tf.float32)
eta_train = tf.convert_to_tensor(eta_X, dtype=tf.float32)

# 组合 x 和 t 作为训练输入
输入 = tf.concat([x_train, t_train], axis=1)

# 定义物理信息神经网络 (PINN) 模型
PINN 类（tf.keras.Model）：
    def __init__(自身):
        超级（PINN，自我）.__init__()
        self.dense1 = tf.keras.layers.Dense(1000，激活=&#39;tanh&#39;，input_dim=2)
        self.dense2 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense3 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense4 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense5 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.dense6 = tf.keras.layers.Dense(1000, 激活=&#39;tanh&#39;)
        self.output_layer = tf.keras.layers.Dense(1, 激活=无)
        
    def 调用（自身，输入）：
        x = 输入[:, 0:1]
        t = 输入[:, 1:2]
        concat_input = tf.concat([x,t], 轴=1)
        hidden_​​1 = self.dense1(concat_input)
        隐藏_2 = self.dense2(隐藏_1)
        隐藏_3 = self.dense3(隐藏_2)
        隐藏_4 = self.dense4(隐藏_3)
        隐藏_5 = self.dense5(隐藏_4)
        隐藏_6 = self.dense6(隐藏_5)
        输出 = self.output_layer(hidden_​​6)
        返回输出
    
def物理损失（模型，x，t）：
    使用 tf.GradientTape(persistent=True) 作为磁带：
        磁带.watch(x)
        磁带.watch(t)
        u_pred = 模型(tf.concat([x,t], axis=1))
        u_x = Tape.gradient(u_pred, x)
        u_t = Tape.gradient(u_pred, t)
        删除磁带
    
    克=9.81
    h = 1
    
    损失 = u_t + np.sqrt(g*h) * u_x
    
    返回 tf.reduce_mean(tf.square(loss))

# 创建并编译PINN模型
模型 = PINN()
优化器 = tf.keras.optimizers.Adam(learning_rate=0.0001)

# 训练循环
纪元 = 200000
对于范围内的纪元（纪元）：
    使用 tf.GradientTape() 作为磁带：
        物理损失值=物理损失（模型，x_train，t_train）
        data_loss_value = tf.reduce_mean(tf.square(模型(输入) - eta_train))
        总损失 = 物理损失值 + 数据损失值
        
    梯度 = Tape.gradient(total_loss, model.trainable_variables)
    optimizer.apply_gradients(zip(梯度, model.trainable_variables))
    
    如果纪元 % 1000 == 0:
        print(f&quot;纪元 {epoch}/{epochs}，总损失：{total_loss.numpy()}，物理损失：{physicals_loss_value.numpy()}，数据损失：{data_loss_value.numpy()}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78363881/i-have-doubts-about-the-pinns-model-that-i-created</guid>
      <pubDate>Mon, 22 Apr 2024 03:47:04 GMT</pubDate>
    </item>
    <item>
      <title>我收到错误 - ValueError: 在使用模型 ss3 进行投票分类器时，估计器 SS3 应该是分类器</title>
      <link>https://stackoverflow.com/questions/78362782/i-am-getting-an-error-valueerror-the-estimator-ss3-should-be-a-classifier-whi</link>
      <description><![CDATA[我正在研究一个使用投票的集成模型，用于 ss3 模型、svm 模型和 RoBERTa 模型，但我遇到了很多错误。
我尝试包含拟合函数、预测函数，并尝试在 ss3 类的 init 中添加 _estimator_type = &#39;classifier&#39; 行，但随后出现错误，表明这是不必要的。请帮助我消除这个错误并指导我如何制作集成模型。
这是我面临最多问题的代码部分：
SS3 级：
def __init__(自身):
    _estimator_type = &#39;分类器&#39;
    # self.train_df = 无
    self.cf = 无
    self. precision = 无，
    自我回忆=无，
    self.f1_score = 无，
    self.accuracy = 无，
    self.local_values = 无

def get_params(self, deep=True):
    返回 {
        &#39;_estimator_type&#39;：self._estimator_type，
    }

这是错误：
回溯（最近一次调用最后一次）：
 第 236 行，在 _validate_estimators 中
    引发值错误（
ValueError：估计器 SS3 应该是一个分类器。

进程已完成，退出代码为 1
]]></description>
      <guid>https://stackoverflow.com/questions/78362782/i-am-getting-an-error-valueerror-the-estimator-ss3-should-be-a-classifier-whi</guid>
      <pubDate>Sun, 21 Apr 2024 18:48:18 GMT</pubDate>
    </item>
    <item>
      <title>Baseline3 TD3，reset() 方法值太多，无法解包错误</title>
      <link>https://stackoverflow.com/questions/78361630/baseline3-td3-reset-method-too-many-values-to-unpack-error</link>
      <description><![CDATA[环境是python 3.10，stable-baseline3 2.3.0，我正在尝试TD3算法。
无论我做什么，我都会遇到同样的错误。
据我所知，重置方法的返回值与定义的观察空间相同
我制作的环境有如下重置方法
def重置（自身，种子=0）：
    self.current_index = 0
    self.current_cash = self.start_cash
    self.done = False
    self.当前时间 = self.开始时间

    # 초기 관찰 상태 계산
    初始状态 = self.get_state() # 字典
    返回初始状态

它从来都不复杂，定义环境，模型也很好
从 stable_baselines3.common.torch_layers 导入 BaseFeaturesExtractor
从 stable_baselines3 导入 TD3

类 CustomFeatureExtractor(BaseFeaturesExtractor):
    def __init__(自我，观察空间，features_dim = 5)：
        super(CustomFeatureExtractor, self).__init__(observation_space, features_dim)
        self.model_alpha = ModelAlpha()
    
    defforward（自我，观察）：
        价格 = 观察结果[&#39;价格&#39;]
        位置 = 观测值[&#39;位置&#39;]
        数量 = 观测值[&#39;数量&#39;]
        pnr = 观测值[&#39;pnr&#39;]
        
        return self.model_alpha(价格, torch.cat([位置, 数量, pnr]))
        
        
# 환경과 모델 설정
env = MarketEnvironment(蜡烛, &#39;2020-07-01 00:00:00&#39;, &#39;2023-12-31 23:59:00&#39;) # 여러분의 환경 설정
策略_kwargs = 字典（
    features_extractor_class=自定义特征提取器，
    features_extractor_kwargs=dict（features_dim=5）
）

模型 = TD3(“MultiInputPolicy”，env，policy_kwargs=policy_kwargs，batch_size=128，verbose=1)

Jupyter 提示符显示
使用CPU设备
使用 Monitor 包装器包装环境
将环境包装在 DummyVecEnv 中。
它运行良好，直到
model.learn（total_timesteps=1，log_interval=10，progress_bar=True）

这段代码。
无论我做了什么，它都会一遍又一遍地这么说
文件 ~\.conda\envs\mlbase-py3.10\lib\site-packages\stable_baselines3\common\off_policy_algorithm.py:297，在 OffPolicyAlgorithm._setup_learn(self、total_timesteps、callback、reset_num_timesteps、tb_log_name ， 进度条）
    第290章
    第291章
    292 和 self.env.num_envs &gt; 1
    293 而不是 isinstance(self.action_noise, VectorizedActionNoise)
    第294章）：
    第295章
--&gt;第297章
    298 总时间步数，
    299回调，
    300 重置_num_timesteps，
    第301章
    第302章
    第303章）

文件~\.conda\envs\mlbase-py3.10\lib\site-packages\stable_baselines3\common\base_class.py:425，在BaseAlgorithm._setup_learn(self,total_timesteps,callback,reset_num_timesteps,tb_log_name,progress_bar)中
    第423章
    第424章 断言self.env不是None
--&gt;第425章
    第426章
    第427章

文件 ~\.conda\envs\mlbase-py3.10\lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py:77，在 DummyVecEnv.reset(self) 中
     75 为 env_idx 在范围内（self.num_envs）：
     76 Maybe_options = {“选项”: self._options[env_idx]} if self._options[env_idx] else {}
---&gt; 77 obs, self.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
     78 self._save_obs（env_idx，obs）
     79 # 种子和选项仅使用一次

ValueError：需要解包的值太多（预期为 2）

我知道这个错误的reset()方法是在一个名为VecEnv的抽象类中
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78361630/baseline3-td3-reset-method-too-many-values-to-unpack-error</guid>
      <pubDate>Sun, 21 Apr 2024 12:58:27 GMT</pubDate>
    </item>
    <item>
      <title>KNN 类型错误和数据标准化</title>
      <link>https://stackoverflow.com/questions/78360476/knn-typeerror-and-data-normalization</link>
      <description><![CDATA[即使完成教程指示的所有操作，我也无法使预测正常工作。
从 sklearn.neighbors 导入 KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=3, metric=&#39;euclidean&#39;)
knn_model.fit(train_val_process, merge_labels.label)
y_pred_knn = knn.predict(test_data_process)

错误如下：
TypeError：KNeighborsClassifier.predict() 缺少 1 个必需的位置参数：
&#39;X&#39;

我应该将数据均值标准化为 1 std 0。这样好吗？
from sklearn.preprocessing import StandardScaler
定标器=标准定标器()
缩放器.fit(pd.concat([train_data, val_data]))
train_data_process = pd.DataFrame(scaler.transform(train_data), columns=train_data.columns)
val_data_process = pd.DataFrame(scaler.transform(val_data), columns=val_data.columns)
train_val_process = pd.concat([train_data, val_data])
test_data_process = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns)
y_test = test_labels.label
]]></description>
      <guid>https://stackoverflow.com/questions/78360476/knn-typeerror-and-data-normalization</guid>
      <pubDate>Sun, 21 Apr 2024 05:13:50 GMT</pubDate>
    </item>
    <item>
      <title>梅尔频谱图的卷积自动编码器。不起作用</title>
      <link>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</link>
      <description><![CDATA[在此处输入图像描述
# 将列表转换为 numpy 数组
data_array = np.array(data_list, dtype=&#39;float32&#39;)
data_array = np.array(data_array, dtype=&#39;float32&#39;) / 255.0 # 所以我的数据是从0到1
导入操作系统
导入keras
将 numpy 导入为 np
将张量流导入为 tf
从张量流导入keras
从 keras.layers 导入输入、Conv2D、BatchNormalization、MaxPooling2D、UpSampling2D、Flatten、Dense、Reshape、Dropout
从 keras.models 导入模型
从 sklearn.model_selection 导入 train_test_split
#从keras.preprocessing.image导入img_to_array，load_img
从 sklearn.model_selection 导入 train_test_split
#from keras.callbacks 导入 LearningRateScheduler
从 sklearn.model_selection 导入 train_test_split
从 keras.callbacks 导入 TensorBoard
导入时间
从 keras 导入正则化器

train_images, test_images = train_test_split(data_array, test_size=0.1) # 10% 用于测试
train_images, val_images = train_test_split(train_images, test_size=0.1) # 其余的 10% 用于验证

print(f&#39;训练集大小：{train_images.shape}&#39;)
print(f&#39;验证集大小：{val_images.shape}&#39;)
print(f&#39;测试集大小：{test_images.shape}&#39;)

# 超参数正确或接近正确？参数以纸质为准。
H、W、C = 256, 256, 1 # 1 排列 np 黑白
学习率 = 1e-3
批量大小 = 16
纪元 = 50 #Random 纪元
Latent_dim = 128 # 理解

l2_reg = 正则化器.l2(1e-4)

输入=输入（形状=（H，W，C））
x = Conv2D(32, (5, 5), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(输入)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), padding=&#39;same&#39;)(x) #固定池化
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), 填充=&#39;相同&#39;)(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), 填充=&#39;相同&#39;)(x)

# X 是我最后一层的输出

# 关于 X\ 的瓶颈操作
瓶颈=展平()(x)
瓶颈=密集（latent_dim，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（bottleneck）#潜在空间（LS）
瓶颈 = Dropout(0.3)(bottleneck) # 应用 dropout 进行正则化
                                       #输出是瓶颈
#解码器
x = 密集（8* 8* 128，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（瓶颈）
x = 重塑((8, 8, 128))(x)
x = 上采样2D((2, 2))(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(32, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
#填充？
#x = ZeroPadding2D(padding=((2, 2), (14, 14)))(x) # 大小要求？
# 最终重建
outputs = Conv2D(1, (5, 5), activate=&#39;sigmoid&#39;, padding=&#39;same&#39;, kernel_regularizer=l2_reg)(x) # 修改 1 因为之前有一个 3 : 没有意义，为什么是 sigmoid
#Sigmoid = 0 到 1 之间的值
#或Relu


# 完整的自动编码器模型
自动编码器=模型（输入，输出）
autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;]) # 或 mse
 


# 模型架构
自动编码器.summary()
打印（train_images.shape，test_images.shape）

从 keras.callbacks 导入 EarlyStopping

#early_stopping = EarlyStopping（monitor=&#39;val_loss&#39;，耐心=5，restore_best_weights=True）
# train_images、val_images 在 CAE 开始时预加载

历史=自动编码器.fit(
    train_images, train_images, # 输入和目标
    纪元=纪元，
    批量大小=批量大小，
    洗牌=真，#真
    回调=[张量板],
    验证数据=（val_images，val_images），#validation_data=（val_images，val_images）
）
# 生成重建
rec_images = autoencoder.predict(val_images)[[在此处输入图像描述](https://i.stack.imgur.com/4g01e.png)](https://i.stack.imgur.com/trl9d.png)

我有 2550 个 2 秒的音频文件，我应用了 Mel 扫描图，仅使用 np 数组数据，我为我的 CAE 提供了这些尺寸 2562561。我已经应用了早期停止、主动学习和调节 L2 来提高我的 NN 学习，但我不知道为什么它不起作用。我对 NN 没有太多的经验，我想了解我在 NN 上做错了什么。我将在此处附上代码和结果。如果您想分享您的类似经验和这些问题的解决方案，请提前致谢。 在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</guid>
      <pubDate>Fri, 19 Apr 2024 12:38:40 GMT</pubDate>
    </item>
    <item>
      <title>将 make_column_transformer 与 OnehotEncoder 和 StandaScaler + 直通结合使用</title>
      <link>https://stackoverflow.com/questions/59605035/using-make-column-transformer-with-onehotencoder-and-standascaler-passthrough</link>
      <description><![CDATA[每当我同时使用 StandardScaler 和 OnehotEncoding 时，我都无法使用 remainder=&#39;passthrough&#39;。不管我怎么说，我都有一个问题。它要么是参数之前的关键字，要么是 fit_tranform 的问题......你能想到的。这是我正在做的事情：
trans_cols= make_column_transformer((OneHotEncoder(),[&#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;,
 &#39;默认&#39;,&#39;住房&#39;,&#39;贷款&#39;,&#39;联系人&#39;,&#39;月份&#39;,&#39;poutcome&#39;]),remainder=&#39;passthrough&#39;)

trans_cols.fit_transform(X)

这是我的专栏：
Index([&#39;年龄&#39;, &#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;, &#39;余额&#39;, &#39;住房&#39;,
   &#39;贷款&#39;, &#39;联系&#39;, &#39;月份&#39;, &#39;持续时间&#39;, &#39;活动&#39;, &#39;pdays&#39;, &#39;上一个&#39;,
   &#39;撅嘴&#39;，&#39;y&#39;]，
  dtype=&#39;对象&#39;)

上面的代码有效，只是在使用 remainder 键参数时无法组合 2 个估计器。这就是我尝试的原因：
trans_cols= make_column_transformer((OneHotEncoder(),[&#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;,&#39;住房&#39;,&#39;贷款&#39;,
                                                  &#39;联系人&#39;,&#39;月份&#39;,&#39;poutcome&#39;]),remainder=&#39;passthrough&#39;,

(StandardScaler(),[&#39;年龄&#39;, &#39;工作&#39;, &#39;婚姻&#39;, &#39;教育&#39;, &#39;默认&#39;, &#39;余额&#39;,
                  &#39;住房&#39;,&#39;贷款&#39;, &#39;联系方式&#39;, &#39;月份&#39;, &#39;期限&#39;,
                  &#39;活动&#39;、&#39;pdays&#39;、&#39;上一个&#39;、&#39;poutcome&#39;]))

但是，在我删除 remainder 并保留 2 个元组之前，上述方法不起作用。这是可以理解的。然而，这样做它试图对我的一些数字进行编码，并且有一条消息告诉我它遇到了一些具有浮动的列。而且我的准确性严重下降。]]></description>
      <guid>https://stackoverflow.com/questions/59605035/using-make-column-transformer-with-onehotencoder-and-standascaler-passthrough</guid>
      <pubDate>Sun, 05 Jan 2020 23:14:28 GMT</pubDate>
    </item>
    <item>
      <title>R 错误中的 K 均值聚类</title>
      <link>https://stackoverflow.com/questions/46002289/k-means-clustering-in-r-error</link>
      <description><![CDATA[我有一个在 R 中创建的数据集。它的结构如下：

&lt;前&gt;&lt;代码&gt;&gt;头（btc_data）
           日期 btc_close eth_close vix_close gold_close DEXCHUS 更改
1647 2010-07-18 0.09 无 无 无 无 0
1648 2010-07-19 0.08 不适用 25.97 115.730 不适用 -1
1649 2010-07-20 0.07 不适用 23.93 116.650 不适用 -1
1650 2010-07-21 0.08 不适用 25.64 115.850 不适用 1
1651 2010-07-22 0.05 不适用 24.63 116.863 不适用 -1
1652 2010-07-23 0.06 不适用 23.47 116.090 不适用 1

我正在尝试使用 k 均值对观察结果进行聚类。但是，我收到以下错误消息：

&lt;前&gt;&lt;代码&gt;&gt; km &lt;- kmeans(trainingDS, 3)
do_one(nmeth) 中的错误：外部函数调用中的 NA/NaN/Inf (arg 1)
另外：警告消息：
在 storage.mode(x) &lt;- &quot;double&quot; 中：通过强制引入的 NA

这是什么意思？我对数据的预处理是否错误？我可以做什么来修复它？我不能删除 NA，因为在 4500 个初始观察中，如果我运行完整案例，我只剩下 100 个观察。
基本上，我希望基于值为 -1,0,1 的 change 列形成 3 个簇。然后，我希望分析每个集群的组成部分，以找到最强的变化预测因素。还有哪些其他算法对此最有用？ 
我还尝试使用以下代码删除所有 NA 值，但仍然收到相同的错误消息：

&lt;前&gt;&lt;代码&gt;&gt; Complete_cases &lt;- btc_data[complete.cases(btc_data), ]
&gt; km &lt;- kmeans(complete_cases, 3, nstart = 20)
do_one(nmeth) 中的错误：外部函数调用中的 NA/NaN/Inf (arg 1)
另外：警告消息：
在 storage.mode(x) &lt;- &quot;double&quot; 中：通过强制引入的 NA

&gt; sum(!sapply(btc_data, is.finite))
[1]8008
&gt;总和（sapply（btc_data，is.nan））
[1] 0
&gt;
&gt; sum(!sapply(complete_cases, is.finite))
[1] 0
&gt;总和（sapply（complete_cases，is.nan））
[1] 0

这是数据的格式：

&lt;前&gt;&lt;代码&gt;&gt; sapply（btc_data，类）
      日期 btc_close eth_close vix_close gold_close DEXCHUS 更改
    “日期”“数字”“数字”“数字”“数字”“数字”“系数”
]]></description>
      <guid>https://stackoverflow.com/questions/46002289/k-means-clustering-in-r-error</guid>
      <pubDate>Fri, 01 Sep 2017 14:19:42 GMT</pubDate>
    </item>
    </channel>
</rss>