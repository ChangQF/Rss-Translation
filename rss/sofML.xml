<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 11 Jun 2024 09:17:32 GMT</lastBuildDate>
    <item>
      <title>InvalidArgumentError：图形执行错误：矩阵大小不兼容：</title>
      <link>https://stackoverflow.com/questions/78606444/invalidargumenterror-graph-execution-error-matrix-size-incompatible</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78606444/invalidargumenterror-graph-execution-error-matrix-size-incompatible</guid>
      <pubDate>Tue, 11 Jun 2024 09:04:15 GMT</pubDate>
    </item>
    <item>
      <title>使用算法的 KDTree 变体时，OpenCV KNearest 函数不计算距离</title>
      <link>https://stackoverflow.com/questions/78606051/opencv-knearest-function-not-calculating-distances-when-using-the-kdtree-variant</link>
      <description><![CDATA[我正在尝试使用 OpenCV 的 KNearest 函数（OpenCV 4.5.1，C++）来计算到最近邻居的距离。我对分类或回归都不感兴趣，只是测量这个距离。使用“Brute Force”版本的算法可以实现这一点，但使用“KDTree”版本则不行。
我进行了一些简单的实验来尝试让它工作。以下是一些测试代码：
cv::Mat trainData = (cv::Mat_&lt;float&gt;(5, 2) &lt;&lt; 3.0, 3.0, 4.0, 4.0, 5.0, 5.1, 7.0, 7.1, 10.1, 11);
cv::Mat trainLabels = (cv::Mat_&lt;int&gt;(5, 1) &lt;&lt; 0, 0, 0, 0, 0);

cv::Ptr&lt;cv::ml::KNearest&gt; knnKdt = cv::ml::KNearest::create();
knnKdt-&gt;setAlgorithmType(cv::ml::KNearest::KDTREE);

knnKdt-&gt;train(trainData, cv::ml::ROW_SAMPLE, trainLabels);

cv::Mat testData = (cv::Mat_&lt;float&gt;(2, 2) &lt;&lt; 15, 14, 4, 4.1);
cv::Mat result, responses, dists;

knnKdt-&gt;findNearest(testData, 1, result, responses, dists);`

当我使用调试器在调用“findNearest”之后检查变量时，我看到“result”的大小为 (2, 1)，而“responses”和“dists”的大小均为 (0, 0)。为什么该函数没有为我计算距离？我是不是遗漏了什么？当我使用强力版本时，一切都按预期运行。在此先感谢您提供的任何帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78606051/opencv-knearest-function-not-calculating-distances-when-using-the-kdtree-variant</guid>
      <pubDate>Tue, 11 Jun 2024 07:41:51 GMT</pubDate>
    </item>
    <item>
      <title>当比较不是以相同角度拍摄的图像时，如何处理角度不匹配？[关闭]</title>
      <link>https://stackoverflow.com/questions/78606026/how-can-i-handle-angle-mismatching-when-comparing-images-that-are-not-taken-at-t</link>
      <description><![CDATA[ aligned_image1, aligned_image2 = align_images(image1, image2)

# 将对齐的图像转换为灰度
gray1 = cv2.cvtColor(aligned_image1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(aligned_image2, cv2.COLOR_BGR2GRAY)

# 计算对齐图像之间的绝对差异
difference = cv2.absdiff(gray1, gray2)

# 计算两个灰度图像之间的 SSIM
(score, diff) = ssim(gray1, gray2, full=True)
print(&quot;SSIM: {}&quot;.format(score))

# 差异图像包含两个图像之间的差异
diff = (diff * 255).astype(&quot;uint8&quot;)

# 对差异图像进行阈值处理以获取差异区域
_, thresh = cv2.threshold(diff, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)

# 查找差异区域的轮廓
contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 在对齐的图像上绘制边界矩形以可视化差异
output1 = aligned_image1.copy()
output2 = aligned_image2.copy()
contourArea = []
for contour in contours:
contourArea.append(cv2.contourArea(contour))
# (x, y, w, h) = cv2.boundingRect(contour)
# cv2.rectangle(output1, (x, y), (x + w, y + h), (0, 0, 255), 2)
# cv2.rectangle(output2, (x, y), (x + w, y + h), (0, 0, 255), 2)
print(contourArea)
major_changes = detect_major_changes(contourArea)

print(major_changes)
# 在检测到重大变化的轮廓周围绘制矩形
for i in range(len(contours)):
if i in [change[0] for change in major_changes]:
(x, y, w, h) = cv2.boundingRect(contours[i])
cv2.rectangle(output1, (x, y), (x + w, y + h), (0, 0, 255), 2)
cv2.rectangle(output2, (x, y), (x + w, y + h), (0, 0, 255), 2)
# 创建差异图像以可视化变化
difference_image = cv2.bitwise_xor(gray1, gray2)

# 绘制图像以可视化差异
fig, axis = plt.subplots(1, 4, figsize=(25, 10))
axis[0].imshow(cv2.cvtColor(output1, cv2.COLOR_BGR2RGB))
axis[0].set_title(&quot;Aligned Image 1 with Rectangles&quot;)
axis[0].axis(&quot;off&quot;)

axis[1].imshow(cv2.cvtColor(output2, cv2.COLOR_BGR2RGB))
axis[1].set_title(&quot;Aligned Image 2 with Rectangles&quot;)
axis[1].axis(&quot;off&quot;)

axis[2].imshow(diff, cmap=&#39;gray&#39;)
axis[2].set_title(&quot;SSIM差异”）
axes[2].axis(&quot;off&quot;)

axes[3].imshow(difference_image, cmap=&#39;gray&#39;)
axes[3].set_title(&quot;差异图像&quot;)
axes[3].axis(&quot;off&quot;)

plt.show()

我正在做一个实时图像比较项目，用户可以上传两幅图像。这些图像可能不是以相同的角度或相同的视觉条件拍摄的。在比较这些图像时，如何处理角度不匹配的问题？
问题我正在使用 OpenCVOpenCV 和 PythonPython 进行图像处理和比较。挑战在于准确比较角度或视觉条件不完全对齐的图像。这会引入视角和光线的差异，影响比较的准确性。
当前方法当前方法用户上传两幅图像。图像被实时处理和比较。应解决角度和视觉条件不匹配问题，以确保准确的比较结果。

在比较不是以相同角度拍摄的图像时，如何处理角度不匹配问题？
在图像比较过程中，应考虑哪些技术或算法来解决视角和光线差异问题？
OpenCV 或 Python 中是否有特定的库或工具可以帮助处理这些挑战？

目标我想知道如何解决实时图像比较中的角度不匹配问题，以确保准确的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78606026/how-can-i-handle-angle-mismatching-when-comparing-images-that-are-not-taken-at-t</guid>
      <pubDate>Tue, 11 Jun 2024 07:36:57 GMT</pubDate>
    </item>
    <item>
      <title>每个时间戳有多个条目的数据集-解决方案？</title>
      <link>https://stackoverflow.com/questions/78605877/dataset-with-multiple-entries-per-timestamp-solutions</link>
      <description><![CDATA[我目前正在开展一个项目，我想预测某些公司每月股价的百分比变化。我有一个包含月度数据的数据集，因此这些公司的股价变化百分比也是按月计算的。我目前每个时间戳（月）有多个条目，范围从每月 185 到 238。
我听说和读到过，每个时间戳的多个条目会使模型难以学习，因此难以做出准确的预测。当我将条目数量限制为每月一个时，我会丢失非常重要的信息，因此这对我不利。
有人可以解释一下，并给出一些我可以遵循的建议，或者我可以尝试的模型吗？
提前谢谢您！
我已经尝试过 XGBoost。当使用不考虑训练的先前股票价格数据时，XGBoost 确实很难学习。]]></description>
      <guid>https://stackoverflow.com/questions/78605877/dataset-with-multiple-entries-per-timestamp-solutions</guid>
      <pubDate>Tue, 11 Jun 2024 07:05:41 GMT</pubDate>
    </item>
    <item>
      <title>PLS-DA分类器选择</title>
      <link>https://stackoverflow.com/questions/78605744/pls-da-classifier-selection</link>
      <description><![CDATA[我们正在构建模型，尝试根据患者元数据中的疾病状态辨别病例和对照。在无监督 (PCA) 和监督分析 (PLS-DA) 中，造成差异的最大驱动因素是性别。我的一位同事建议按性别划分队列，并实质上建立两个不同的模型 - 一个用于女性，一个用于男性。这种方法效果很好，但我想知道，将参与者的性别纳入分类器是否更有意义？例如，与其使用 illness 和 control 作为分类器并在运行任何分析之前按性别划分队列，不如将整个队列作为输入，并将分类器设置为 illness-female、illness-male、control-female 和 control-male。
我想知道这两种方法是否有我可能没有考虑到的优缺点。我们希望将来能将这些模型用于临床应用。
到目前为止，我已经对队列进行了拆分，男性和女性队列中每个组成部分的变化驱动因素截然不同。我还没有将性别作为分类器的一部分来运行这个模型，我想知道这在目前是否具有概念意义。]]></description>
      <guid>https://stackoverflow.com/questions/78605744/pls-da-classifier-selection</guid>
      <pubDate>Tue, 11 Jun 2024 06:28:06 GMT</pubDate>
    </item>
    <item>
      <title>如何训练模型根据部分输入预测完整的产品名称？</title>
      <link>https://stackoverflow.com/questions/78605611/how-to-train-a-model-to-predict-full-product-names-from-partial-input</link>
      <description><![CDATA[我正在开展一个机器学习项目，需要根据给定的部分产品名称预测完整的产品名称。例如：
完整产品名称：“Women Viscose Rayon Kurta Pant Dupatta Set”
部分名称：“Women Viscose Rayon Kur”。
我有一个庞大的数据集来训练模型。最初，我尝试使用余弦相似度，但结果并不令人满意。我正在寻找一种更好的方法，最好是通过微调现有的开源模型。
要求：

模型类型：可以根据部分输入生成或完成文本的模型。
数据集：足够大以训练强大的模型。
开源：最好使用开源工具和库。

我目前的方法：

余弦相似度：尝试使用余弦相似度进行匹配，但发现它不足以生成全名。
探索语言模型：考虑微调预先训练的语言模型，但需要有关最佳方法和实践的指导。
]]></description>
      <guid>https://stackoverflow.com/questions/78605611/how-to-train-a-model-to-predict-full-product-names-from-partial-input</guid>
      <pubDate>Tue, 11 Jun 2024 05:54:00 GMT</pubDate>
    </item>
    <item>
      <title>国际象棋中有效和无效走法的分类</title>
      <link>https://stackoverflow.com/questions/78605587/classification-of-valid-and-invalids-moves-in-chess</link>
      <description><![CDATA[我已经开始学习二元分类的基本机器学习概念。我创建了一个问题陈述，用于识别国际象棋中特定白棋的有效/无效走法。我创建了自己的数据集，如下所示。我使用了编号而不是 a1、a2 格式

white_pawn_moves.csv
--------------------
current_position, next_position, valid
12, 17, 0
13, 19, 0
16, 20, 0
12, 28, 1
4, 13, 0

来自 ml.net cli 的命令：
-----------
mlnet 分类 --dataset &quot;white_pawn_moves.csv&quot; --label-col 2 --has-header true --train-time 10

我在数据集中添加了 100 行，即不同的组合。如果我们考虑 8x8 棋盘，可能的组合将是 64*64 = 4096。当我尝试使用分类技术运行时，它似乎没有给出正确的预测。我有以下问题

对于这类问题，多少数据即行足够？因为
我们知道最大可能的组合不能超过 4096，而其他一些
问题可能有 100 万，识别数据集的好经验法则是什么？它是基于特征数量吗？
一般来说，当我知道输入的范围和输出的范围时，我应该如何知道多少数据是足够的？假设特征 1 可以从 1 到 1000
而特征 2 可以从 2 到 20？我们是否可以限制或规定特征输入范围
不能超过或低于某些值？是不是应该永远训练模型？

有时甚至 12,17 的预测也为 1，尽管样本数据将该记录标记为 0。链接为 https://learn.microsoft.com/en-us/dotnet/machine-learning/automate-training-with-cli]]></description>
      <guid>https://stackoverflow.com/questions/78605587/classification-of-valid-and-invalids-moves-in-chess</guid>
      <pubDate>Tue, 11 Jun 2024 05:44:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 PyTorch 和 TensorFlow 实现 ResNet-50 和 SSD300 模型</title>
      <link>https://stackoverflow.com/questions/78605564/how-to-implement-resnet-50-and-ssd300-models-using-pytorch-and-tensorflow</link>
      <description><![CDATA[我正在尝试使用 PyTorch 框架实现 ResNet-50 和 SSD300 模型以执行对象检测任务。我遇到了一个问题，我的 SSD300 模型仅关注图像的中心并预测所有图像的相同边界框。我需要帮助来识别和解决此问题。
1-我在 PyTorch 框架中将 resnet50 作为主干与 SSD300 模型一起实现以执行对象检测任务。
2-我遵循了输入图像的推荐预处理步骤，包括调整大小和规范化。
3-我使用了预先训练的模型，并期望它们能够很好地推广到提供的输入图像
4-我使用了数据增强技术。
我期望 SSD300 模型能够检测图像不同部分中的对象，并根据每幅图像的内容返回不同的边界框。具体来说，我预计该模型不会只关注图像的中心，而是会对图像中各个位置的物体提供准确的预测。
无论实际内容如何，​​SSD300 模型始终会预测位于图像中间的边界框。所有输入图像的边界框都相同，这表明模型的学习或推理过程可能存在问题。]]></description>
      <guid>https://stackoverflow.com/questions/78605564/how-to-implement-resnet-50-and-ssd300-models-using-pytorch-and-tensorflow</guid>
      <pubDate>Tue, 11 Jun 2024 05:35:00 GMT</pubDate>
    </item>
    <item>
      <title>我创建的模型损失很大</title>
      <link>https://stackoverflow.com/questions/78604179/getting-high-loss-on-the-model-that-i-created</link>
      <description><![CDATA[我无法分享堆栈上的完整数据，因此我只会分享下面的代码。
过去几天我一直在尝试这些数据，但似乎损失在 18000 或 15000 左右，这太高了。我的同事告诉我要使用神经网络来处理这些数据。
model = Sequential([
layer.Dense(128,activation=&#39;relu&#39;),
layer.Dense(64,activation=&#39;relu&#39;),
layer.Dense(32,activation=&#39;relu&#39;),
layer.Dense(1,activation=&#39;relu&#39;)
])

model.compile(loss=&#39;mse&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;mae&#39;])

model.fit(x_train, y_train,epochs=100,batch_size=80)

`Epoch 1/100
3/3 ━━━━━━━━━━━━━━━━━━━━━━ 1s 78ms/step -损失：242343.5312 - mae：465.7755
纪元 2/100
3/3 ━━━━━━━━━━━━━━━━━━━━━ 0s 20ms/步 - 损失：243483.7969 - mae：468.0649
纪元 3/100
3/3 ━━━━━━━━━━━━━━━━━━━━━━━ 0s 29ms/步 - 损失：246071.8281 - mae： 468.4903
纪元 4/100
3/3 ━━━━━━━━━━━━━━━━━━━━━ 0s 20ms/步 - 损失：250888.7188 - mae：476.0695
纪元 5/100
3/3 ━━━━━━━━━━━━━━━━━━━━━━ 0s 15ms/步 - 损失：242264.2188 - mae：465.4283
纪元 6/100
3/3 ━━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - 损失：242441.9062 - mae：464.7845
有人能帮我把这个损失降到最低吗？我将不胜感激。
数据集示例 -
我的数据样本]]></description>
      <guid>https://stackoverflow.com/questions/78604179/getting-high-loss-on-the-model-that-i-created</guid>
      <pubDate>Mon, 10 Jun 2024 19:23:13 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种 ML 模型进行销售预测？</title>
      <link>https://stackoverflow.com/questions/78602784/which-ml-model-should-i-use-for-sales-prediction</link>
      <description><![CDATA[给定披萨店的数据进行训练，其中包含历史销售数据在此处输入图片说明。



X 形状
Y 形状




(1582, 13)
(1582,)



我使用的是顺序 NN，其中有 6 个密集层，带有“relu”，1 个输出层，带有“线性”激活函数 (128,64,32,16,8,4,1)。
我尝试添加 l2 正则化，但它仍然无法正常工作。
Epoch 999/1000
20/20 [==============================] - 0s 6ms/step - 损失：40284.5391 - mae：163.4370 - val_loss：96699.7188 - val_mae：260.4841
Epoch 1000/1000
20/20 [==============================] - 0s 19ms/step - 损失：40112.4141 - mae：163.2846 - val_loss：98381.9688 - val_mae： ]]></description>
      <guid>https://stackoverflow.com/questions/78602784/which-ml-model-should-i-use-for-sales-prediction</guid>
      <pubDate>Mon, 10 Jun 2024 14:05:42 GMT</pubDate>
    </item>
    <item>
      <title>如何比较两个多维张量</title>
      <link>https://stackoverflow.com/questions/78602074/how-to-compare-two-multi-dimension-tensors</link>
      <description><![CDATA[我有以下张量
import torch as t
a = t.tensor([[[[1.0, 2.0], [3.0, 2.0]],[[1.0, 2.0], [2.0, 3.0]],[[1.0, 2.0], [2.0, 3.0]]], [[[1.0, 2.0], [3.0, 2.0]],[[1.0, 2.0], [2.0, 3.0]],[[1.0, 2.0], [2.0, 3.0]],[[1.0, 2.0], [3.0, 2.0]],[[1.0, 2.0], [2.0, 3.0]],[[1.0, 2.0], [2.0, 3.0]],[[1.0, 2.0], [2.0, 3.0]]]])

b = t.tensor([[[[1.0, 2.0], [3.0, 2.0]],[[1.0, 2.0], [2.0, 3.0]],[[1.0, 2.0], [2.0, 3.0]]], [[[1.0, 2.0], [3.0, 2.0]],[[1.0, 2.0], [2.0, 2.0]],[[1.0, 2.0], [2.0, 2.0]],[[1.0, 2.0], [2.0, 3.0]]],[[[1.0, 1.0], [3.0, 2.0]],[[1.0, 2.0], [2.0, 3.0]]],[[1.0, 2.0], [2.0, 3.0]]])

答案 = t.all(a.eq(b)).sum()

print(ans)

预期值为 1，因为第一个 (3,2,2) 的所有值都相等。但它总是返回零。]]></description>
      <guid>https://stackoverflow.com/questions/78602074/how-to-compare-two-multi-dimension-tensors</guid>
      <pubDate>Mon, 10 Jun 2024 11:41:30 GMT</pubDate>
    </item>
    <item>
      <title>在预处理 CT 扫描图像系列数据以训练 CNN 模型以获得更好的准确性时，我应该如何具体地关注我感兴趣的区域？</title>
      <link>https://stackoverflow.com/questions/78601522/how-specific-should-i-be-with-my-region-of-interest-while-preprocessing-a-ct-sca</link>
      <description><![CDATA[我正在尝试训练一个 3D CNN 模型，以在一个数据集上对癌症分期进行分类，该数据集由头部到颈部的 CT 图像系列组成，分为 5 个类别，与癌症的分期相对应。每个阶段都有与每位患者相对应的文件夹，每个文件夹包含 120 帧 CT 图像系列。我想将一个图像立方体输入到模型中，以考虑空间分辨率和深度分辨率，并将图像立方体归类为五个类别之一。
在 120 张图像中，大约有 10 帧存在癌症。
我将整个图像集（每个患者 120 张）作为 3D 图像立方体传入 3D 卷积模型，对数据进行归一化处理，其结构如下所示）：
num_classes = 5
model = Sequential([
tf.keras.Input(shape=(255, 255, 120, 1)),
# 卷积层 1
Conv3D(16, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),

MaxPooling3D((2, 2, 1), strides=(2, 2, 1), padding=&quot;same&quot;),

# 卷积层 2
Conv3D(32, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2), padding=&quot;same&quot;),

# 卷积层 3
Conv3D(32, (3, 3, 3), activity=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2),padding=&quot;same&quot;),

# 卷积层 4
Conv3D(64, (3, 3, 3), activity=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2),padding=&quot;same&quot;),

# 卷积层 5
Conv3D(128, (3, 3, 3), activity=&#39;relu&#39;),
BatchNormalization(),

# 卷积层 6
Conv3D(128, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2),padding=&quot;same&quot;),
#Dropout(0.25),
# 扁平层
Flatten(),

# 密集层 1
Dense(256,activation=&#39;relu&#39;, kernel_initializer = &#39;glorot_uniform&#39;, kernel_regularizer=tf.keras.regularizers.L2(0.01)),
BatchNormalization(),
#Dropout(0.35),
# 密集层 2
Dense(128,activation=&#39;relu&#39;, kernel_initializer = &#39;glorot_uniform&#39;, kernel_regularizer=tf.keras.regularizers.L2(0.01)),
BatchNormalization(),
#Dropout(0.25),
# 输出层
Dense(num_classes,activation=&#39;softmax&#39;)
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

这是我将 DICOM 图像加载到输入 (X) 和输出 (Y) 标签中的方式：
def load_dicom_images(folder_path):
images = []
for file in sorted(os.listdir(folder_path)):
ds = pydicom.dcmread(os.path.join(folder_path, file))
# 转换为灰度图像并调整大小为 255x255
image = ds.pixel_array
image = cv2.resize(image, (255, 255))
# 标准化图像
normalized_images= (image.astype(np.float32)-image.mean())/image.std()
images.append(normalized_images)
# 将列表转换为 numpy 数组
images = np.array(images)
return images

def load_data(stage_folder): #Stage 文件夹包含与类别相关的五个文件夹
X = []
y = [] 
# 将阶段映射到标签
stage_to_label = {&#39;Stage I&#39;: 0, &#39;Stage II&#39;: 1, &#39;Stage III&#39;: 2, &#39;Stage IVA&#39;: 3, &#39;Stage IVB&#39;: 4 }

for stage in os.listdir(stage_folder):
stage_path = os.path.join(stage_folder, stage)
label = stage_to_label[stage]
forp​​atient_id in os.listdir(stage_path):
patient_folder = os.path.join(stage_path,patient_id)
selected_images = load_dicom_images(patient_folder)

X.append(selected_images)
y.append(label)

X = np.array(X)
y = np.array(y)

# 将 y 转换为分类（独热编码）
y = to_categorical(y, num_classes=5)

return X, y

history = model.fit(X_train, y_train, batch_size=1, epochs=50, validation_data=(X_test, y_test), verbose = True,回调=回调)

这会导致训练准确率 (21%) 和验证准确率较低，并且验证损失会随着每个时期而增加。我根据 CNN 的输入重塑了数据。
我是否需要进一步处理我的数据并仅包含癌变帧，过滤掉其余帧，还是应该包含整个数据以保留深度分辨率并寻找不同的方法来提高准确率？]]></description>
      <guid>https://stackoverflow.com/questions/78601522/how-specific-should-i-be-with-my-region-of-interest-while-preprocessing-a-ct-sca</guid>
      <pubDate>Mon, 10 Jun 2024 09:39:03 GMT</pubDate>
    </item>
    <item>
      <title>scikit 中的 gbrt_minimize 如何决定尝试多少个参数分割</title>
      <link>https://stackoverflow.com/questions/78592454/how-does-gbrt-minimize-from-scikit-decide-how-many-parameter-splits-to-try</link>
      <description><![CDATA[根据我对https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html和梯度提升决策树的理解，我假设对于 N 个参数，回归器会沿着每个参数选择一组分割，计算出应用此分割如何对数据进行分区，然后决定选择哪个分割以最大程度地减少损失（对于特定分位数）。
我的问题是，如果您的参数是实数，您如何决定在哪些参数值处进行分割？我原本希望找到某种参数来确定要进行多少次“等距”分割，但我只看到一个参数可以确定分割两侧所需的数据值数量以使其有效。这是否意味着它以某种方式反向运作？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78592454/how-does-gbrt-minimize-from-scikit-decide-how-many-parameter-splits-to-try</guid>
      <pubDate>Fri, 07 Jun 2024 14:14:02 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 Huggingface 训练器的学习率？</title>
      <link>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</link>
      <description><![CDATA[我正在使用以下参数训练模型：
Seq2SeqTrainingArguments(
output_dir = &quot;./out&quot;, 
overwrite_output_dir = True,
do_train = True,
do_eval = True,

per_device_train_batch_size = 2, 
gradient_accumulation_steps = 4,
per_device_eval_batch_size = 8, 

learning_rate = 1.25e-5,
warmup_steps = 1,

save_total_limit = 1,

evaluation_strategy = &quot;epoch&quot;,
save_strategy = &quot;epoch&quot;,
logs_strategy = &quot;epoch&quot;, 
num_train_epochs = 5, 

gradient_checkpointing = True,
fp16 = True, 

predict_with_generate = True,
generation_max_length = 225,

report_to = [&quot;tensorboard&quot;],
load_best_model_at_end = True,
metric_for_best_model = &quot;wer&quot;,
greater_is_better = False,
push_to_hub = False,
)

我假设warmup_steps=1固定了学习率。
但是，训练结束后，我查看文件 trainer_state.json，发现学习率似乎没有固定。
以下是 learning_rate 和 step 的值：
learning_rate，steps
1.0006 e-05 1033
7.5062 e-06 2066
5.0058 e-06 3099
2.5053 e-06 4132
7.2618 e-09 5165

学习率似乎没有固定在 1.25e-5（步骤 1 之后）。我遗漏了什么？如何修复学习率。]]></description>
      <guid>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</guid>
      <pubDate>Wed, 10 Jan 2024 09:14:26 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“ctgan”（/usr/local/lib/python3.10/dist-packages/ctgan/__init__.py）导入名称“CTGANSynthesizer”</title>
      <link>https://stackoverflow.com/questions/76664787/importerror-cannot-import-name-ctgansynthesizer-from-ctgan-usr-local-lib</link>
      <description><![CDATA[我正在研究从 GAN 生成合成数据，但在使用 CTGANSynthesizer 时遇到了一些问题。以下是代码示例：
from ctgan import CTGANSynthesizer
ctgan = CTGANSynthesizer() 
ctgan.fit(data) 

我收到以下错误
ImportError:
&gt; from ctgan import CTGANSynthesizer

ImportError: 无法从 `ctgan` 导入名称 `CTGANSynthesizer`

我正在尝试使用此 GAN 从孟加拉语文本数据集生成一些孟加拉语文本数据。]]></description>
      <guid>https://stackoverflow.com/questions/76664787/importerror-cannot-import-name-ctgansynthesizer-from-ctgan-usr-local-lib</guid>
      <pubDate>Tue, 11 Jul 2023 18:22:29 GMT</pubDate>
    </item>
    </channel>
</rss>