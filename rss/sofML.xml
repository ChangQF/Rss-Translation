<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 08 Mar 2024 00:56:52 GMT</lastBuildDate>
    <item>
      <title>HOML练习第2章分类中的数据增强</title>
      <link>https://stackoverflow.com/questions/78124870/homl-excersice-chapter-2-data-augmentation-in-classification</link>
      <description><![CDATA[问题引用
&lt;块引用&gt;
编写一个函数，可以将 MNIST 图像在任何方向（左、右、上、下）移动一个像素。⁠ 然后，对于训练集中的每个图像，创建四个移动副本（每个方向一个）并将它们添加到训练集中。最后，在这个扩展的训练集上训练你的最佳模型，并在测试集上测量其准确性。您应该观察到您的模型现在表现得更好了！这种人工增长训练集的技术称为数据增强或训练集扩展。

我尝试的解决方案：
来自 scipy.ndimage.interpolation 导入移位
将 numpy 导入为 np
从 sklearn.linear_model 导入 SGDClassifier
从 sklearn.model_selection 导入 cross_val_score

def shift_image(图像, 方向):
    图像 = image.reshape((28, 28))
    如果方向==“右”：
        返回移位（图像，[0, 1]，cval=0）
    elif 方向==“左”：
        返回移位（图像，[0，-1]，cval = 0）
    elif 方向 == “向上”：
        返回移位（图像，[-1, 0]，cval=0）
    elif 方向 == “向下”：
        返回移位（图像，[1, 0]，cval=0）



移位图像 = []

对于 X_train 中的 img：
    shift_images.append(shift_image(img, “右”))
    shift_images.append(shift_image(img, “左”))
    shift_images.append(shift_image(img, “向上”))
    shift_images.append(shift_image(img, “向下”))

# 将移位图像列表转换为 numpy 数组
X_train_shifted = np.array(shifted_images)
flattened_images = X_train_shifted.reshape((-1, 28 * 28))
打印（展平图像.形状）
打印（X_train.shape）
X_combined = np.concatenate((X_train, flattened_images))
X_combined.shape



y_combined = np.concatenate((y_train,y_train,y_train,y_train,y_train))

sgd_clf = SGDClassifier()
sgd_clf.fit(X_combined,y_combined)
cross_val_score(sgd_clf,X_combined,y_combined,cv=3,scoring=“准确度”)

交叉验证分数输出：
数组([0.08093, 0.10234, 0.10207])

为什么我得到的分数比虚拟分类器差？]]></description>
      <guid>https://stackoverflow.com/questions/78124870/homl-excersice-chapter-2-data-augmentation-in-classification</guid>
      <pubDate>Thu, 07 Mar 2024 23:31:26 GMT</pubDate>
    </item>
    <item>
      <title>更好的分类模型架构[关闭]</title>
      <link>https://stackoverflow.com/questions/78124708/a-better-model-architecture-for-classification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78124708/a-better-model-architecture-for-classification</guid>
      <pubDate>Thu, 07 Mar 2024 22:40:36 GMT</pubDate>
    </item>
    <item>
      <title>Chrome 扩展工具中的 500 内部服务器错误</title>
      <link>https://stackoverflow.com/questions/78124159/500-internal-server-error-in-a-chrome-extension-tool</link>
      <description><![CDATA[我正在尝试为网络钓鱼电子邮件检测系统创建一个 Chrome 扩展工具。该系统使用“提取”按钮来收集发件人、主题和电子邮件正文文本，并使用“扫描”按钮来分析提取的电子邮件正文中的网络钓鱼指标。虽然我可以成功提取信息，但单击“扫描”按钮会导致控制台中显示 500 内部服务器错误。有什么建议可以解决这个问题吗？
后端.py
导入回溯
从烧瓶导入烧瓶，请求，jsonify
将 pandas 导入为 pd
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
从 sklearn.linear_model 导入 LogisticRegression
从flask_cors导入CORS
导入 json
导入日志记录
从 http 导入 HTTPStatus


应用程序=烧瓶（__名称__）


# 加载数据集
数据集 = pd.read_csv(“mail_data.csv”)

# 用空字符串替换空值
mail_data = dataset.where((pd.notnull(dataset)), &#39;&#39;)

# 将垃圾邮件标记为0；正品如1
mail_data.loc[mail_data[&#39;类别&#39;] == &#39;垃圾邮件&#39;, &#39;类别&#39;,] = 0
mail_data.loc[mail_data[&#39;类别&#39;] == &#39;真实&#39;, &#39;类别&#39;,] = 1

# 假设您的数据集有一个包含电子邮件内容的“文本”列和一个用于网络钓鱼的“标签”列
X = mail_data[&#39;消息&#39;]
Y = mail_data[&#39;类别&#39;]

＃ 特征提取
feature_extraction = TfidfVectorizer(min_df=1, stop_words=&#39;english&#39;, lowercase=True)
X_features = feature_extraction.fit_transform(X)

# 将 Y 值转换为整数
Y = Y.astype(&#39;int&#39;)

# 训练模型
模型=逻辑回归()
model.fit(X_features, Y)


@app.route(&#39;/&#39;, 方法=[&#39;GET&#39;, &#39;POST&#39;])
def Predict_phishing():
    如果 request.method == &#39;POST&#39;:
        email_content = request.json.get(&#39;email_content&#39;, &#39;&#39;)
        # 输入数据的特征提取

        email_content_feature = feature_extraction.transform([email_content])
        # 使用训练好的模型进行预测
        预测 = model.predict(email_content_feature)[0]

        

        返回 jsonify({&#39;预测&#39;: 预测})
    # 如果请求方法是GET，则返回一条消息
    别的：
        return jsonify({&#39;message&#39;: &#39;请使用POST方法进行预测。&#39;})
    

   
如果 __name__ == &#39;__main__&#39;:
    应用程序运行（调试=真）


popup.js
// 存储电子邮件主题、发件人和消息的变量
让 emailSubjectSenderMessage = {};

// 向 content.js 发送消息以提取电子邮件内容的函数
函数提取电子邮件内容（）{
  chrome.tabs.query({ active: true, currentWindow: true }, (tabs) =&gt; {
    if (tabs &amp;&amp; tabs.length &gt; 0 &amp;&amp; tabs[0].id) {
      const activeTab = tabs[0];
      chrome.tabs.sendMessage(activeTab.id, { action: &#39;extractEmailContent&#39; }, (response) =&gt; {
        if (chrome.runtime.lastError) {
          // 处理发送消息时的任何错误

        } 别的 {
          // 检查响应中是否包含 emailContent
          if (response &amp;&amp; response.emailContent) {
            // 提取邮件内容
            const emailContent = response.emailContent;

            // 提取发件人的电子邮件地址
            const senderEmail = emailContent.senderEmail;

            // 将电子邮件主题、发件人和消息存储在变量中
            电子邮件主题发件人消息 = {
              主题：电子邮件内容.主题，
              发件人：发件人电子邮件，
              消息：emailContent.body
            };

            // 显示提取的内容，包括发件人的电子邮件地址
            显示电子邮件内容（电子邮件内容，发件人电子邮件）；
          } 别的 {
            displayErrorMessage(&#39;此页面上找不到电子邮件数据。&#39;);
          }
        }
      });
    } 别的 {
      console.error(&#39;无效的选项卡或选项卡 ID 不可用。&#39;);
    }
  });
}


// 显示提取的电子邮件内容的函数
函数显示电子邮件内容（电子邮件内容，发件人电子邮件）{
  const emailContentDiv = document.getElementById(&#39;emailContent&#39;);
  emailContentDiv.innerHTML = `发件人： ${senderEmail}&lt;br&gt;&lt;strong&gt;主题：&lt;/strong&gt; ${emailContent.subject}&lt;br&gt;&lt;strong&gt;消息：&lt;/strong&gt; ${emailContent.body}`;
}

// 显示错误信息的函数
函数显示错误消息（消息）{
  const emailContentDiv = document.getElementById(&#39;emailContent&#39;);
  emailContentDiv.textContent = 消息；
}
]]></description>
      <guid>https://stackoverflow.com/questions/78124159/500-internal-server-error-in-a-chrome-extension-tool</guid>
      <pubDate>Thu, 07 Mar 2024 20:28:12 GMT</pubDate>
    </item>
    <item>
      <title>机器学习通过 SVC 症状预测疾病 [关闭]</title>
      <link>https://stackoverflow.com/questions/78123509/machine-learning-prediction-of-disease-by-symptoms-with-svc</link>
      <description><![CDATA[我正在尝试创建一种通过症状来预防疾病的功能，但我有什么想法吗？
它会像：
症状 = [“皮肤皮疹”、“连续打喷嚏”、“瘙痒”]
pred（症状，模型）

这是我当前的代码：
将 pandas 导入为 pd
从 sklearn.preprocessing 导入 LabelEncoder、StandardScaler
从 sklearn.model_selection 导入 train_test_split
从 sklearn.svm 导入 SVC
从 sklearn.metrics 导入准确度_分数、精度_分数、召回_分数、f1_分数

def load_and_preprocess_data(文件路径):
    df = pd.read_csv(文件路径)

    # 识别非数字列（不包括“疾病”）
    non_numeric_cols = df.select_dtypes(include=[&#39;object&#39;]).columns.difference([&#39;Disease&#39;])
    print(&quot;非数字列（不包括&#39;疾病&#39;）：&quot;, non_numeric_cols)

    df.fillna(0,就地=True)

    如果 df.columns 中有“疾病”：
        le = 标签编码器()
        df[&#39;疾病&#39;] = le.fit_transform(df[&#39;疾病&#39;])

    X = df.drop(&#39;疾病&#39;, axis=1)
    y = df[&#39;疾病&#39;]

    # 特征缩放（如果需要，考虑替代缩放方法）
    定标器=标准定标器()
    X = pd.DataFrame(scaler.fit_transform(X))

    返回 X, y

def build_and_train_model(X_train, y_train):
    # 使用不同的内核进行实验（线性、rbf 等）
    model = SVC(kernel=&#39;linear&#39;) # 替换为所选内核

    # 训练模型
    model.fit(X_train, y_train)

    返回模型

def Predict_and_evaluate(模型, X_test, y_test):
    y_pred = model.predict(X_test)
    准确度=准确度_得分(y_test, y_pred)
    精度 = precision_score(y_test, y_pred, 平均值=&#39;加权&#39;)
    召回率=召回率（y_test，y_pred，平均值=&#39;加权&#39;）
    f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)

    print(“准确度：”, 准确度)
    print(&quot;精度：&quot;, 精度)
    print(“回忆：”, 回忆)
    print(&quot;F1-分数：&quot;, f1)


def main():
    文件路径 = &#39;数据集/merged_dataset.csv&#39;

    X, y = load_and_preprocess_data(文件路径)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    模型 = build_and_train_model(X_train, y_train)

    预测和评估（模型，X_测试，y_测试）


如果 __name__ == “__main__”：
    主要的（）

这就是 csv 的样子：
疾病、瘙痒、皮疹、结节性皮肤疹、连续打喷嚏
真菌感染,1,3,4,0,0
真菌感染,1,3,0,0,6
过敏,1,3,0,0,0
... 和更多

是症状的严重程度，如 1,3,4,0,0（0 表示对该疾病不重要）
所以我必须用我训练的模型通过症状列表来猜测疾病我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/78123509/machine-learning-prediction-of-disease-by-symptoms-with-svc</guid>
      <pubDate>Thu, 07 Mar 2024 18:09:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorFlow 进行元学习 (MAML) 训练以简化描述期间 GPU 内存超出 [关闭]</title>
      <link>https://stackoverflow.com/questions/78122917/gpu-memory-exceeded-during-meta-learning-maml-training-with-tensorflow-for-str</link>
      <description><![CDATA[我正在开发一个元学习项目，用于描绘卫星图像和 DEM 衍生产品的流线。我的 TensorFlow 模型使用 MAML 过程，但我始终超出 GPU 内存限制。
关键细节：

任务：简化地理空间数据的描绘。

框架：TensorFlow

元学习算法：模型无关元学习 (MAML)

网络：U-Net架构

当前可行参数： ~700K

所需参数：70+ 百万

梯度计算： tf.GradientTape


问题：
模型训练过程始终耗尽 GPU 内存。我想扩展模型以处理更多的参数。
示例代码：
类 MAML：
    def __init__(自身、模型、优化器、inner_step_size、num_inner_steps):
        self.model = 模型
        self.optimizer = 优化器
        self.inner_step_size = inner_step_size
        self.num_inner_steps = num_inner_steps

        # 初始化 TensorBoard 日志记录的摘要编写器
        self.summary_writer = tf.summary.create_file_writer(&#39;日志/&#39;)

    def inner_update(自身、support_data、support_labels、original_weights):

        使用 tf.GradientTape() 作为 task_tape：
            task_preds = self.model(support_data)
            plt.imshow(task_preds[0])
            plt.show()
            # task_loss = f1_loss(support_labels, task_preds)
            task_loss = tf.keras.losses.binary_crossentropy(support_labels, task_preds)


        task_gradients = task_tape.gradient(task_loss, self.model.trainable_variables)
        fast_weights = [w - self.inner_step_size * g for w, g in zip(original_weights, task_gradients)]

        返回 fast_weights, task_loss.numpy()

    defouter_update（自我，剧集）：
        原始权重 = self.model.get_weights()

        # 内部更新
        fast_weights,task_loss = self.inner_update(episode[&#39;support_set_data&#39;],episode[&#39;support_set_labels&#39;],original_weights)

        # 临时设置模型权重以进行验证
        self.model.set_weights(fast_weights)

        使用 tf.GradientTape() 作为 meta_tape：
            meta_val_preds = self.model(episode[&#39;query_set_data&#39;])
            meta_val_loss = f1_loss(episode[&#39;query_set_labels&#39;], meta_val_preds)
        meta_gradients = meta_tape.gradient(meta_val_loss, self.model.trainable_variables)

        # 恢复原始权重并应用外部更新
        self.model.set_weights(original_weights)
        self.optimizer.apply_gradients(zip(meta_gradients, self.model.trainable_variables))
        返回task_loss，meta_val_loss.numpy()

    def fit(自我、剧集、纪元)：
        对于范围内的纪元（纪元）：
            任务损失 = []
            val_losses = []
            对于剧集中的剧集：
                task_loss, val_loss = self.outer_update(episode)
                # 打印（任务损失，val_loss）
                task_losses.append(task_loss)
                val_losses.append(val_loss)

            # 记录该时期的平均任务损失和验证损失
            使用 self.summary_writer.as_default()：
                tf.summary.scalar(&#39;任务损失&#39;, np.mean(task_losses), step=epoch)
                tf.summary.scalar(&#39;验证损失&#39;, np.mean(val_losses), step=epoch)

            # 打印该纪元的平均损失
            print(f&quot;Epoch {epoch + 1}/{epochs} - 任务损失：{np.mean(task_losses):.4f}，验证损失：{np.mean(val_losses):.4f}&quot;)

硬件：
Google Colab：高 RAM (51.0 GB)、A100 (16.0 GB) 节点。
其他问题：

是否有专门针对 TensorFlow 中元学习的已知内存优化策略？

使用tf.GradientTape进行梯度计算会成为瓶颈吗？如果是这样，什么替代方案可能更节省内存？

是否有有效的技术可以在不牺牲该领域性能的情况下降低模型复杂性？

内存高效的分布式训练方法有帮助吗？

图层冻结：我尝试通过冻结较大模型中的某些图层来减少内存消耗。然而，这并没有解决 GPU 内存限制。具体来说，我尝试在训练过程中冻结Unet模型的编码器。

模型缩减：由于内存问题仍然存在，我改用了一个明显更小的模型。虽然这允许我运行训练过程，但模型现在无法收敛。这表明较小的模型可能缺乏学习简化描述所需模式的能力。

]]></description>
      <guid>https://stackoverflow.com/questions/78122917/gpu-memory-exceeded-during-meta-learning-maml-training-with-tensorflow-for-str</guid>
      <pubDate>Thu, 07 Mar 2024 16:24:53 GMT</pubDate>
    </item>
    <item>
      <title>寻求时间有序变量的决策树算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78122700/seeking-a-decision-tree-algorithm-for-temporally-ordered-variables</link>
      <description><![CDATA[我正在寻找一种方法（在 R 或 Python 中）来构建考虑变量时间顺序的决策树。目标是迫使决策树反映变量的顺序性质。一组变量是时间 1 中发生的事件的指示符，第二组变量与时间 2 相关，依此类推。本质上，我的目标是引导算法首先利用与较早时间点相关的变量，然后按顺序利用与较晚时间点相关的变量。该方法促进了逐步的分类过程，其中每个步骤都根据先前步骤的信息细化类别。
也就是说，算法首先用与第一时间点相关的变量进行分类，然后再对第二时间点进行进一步分类和“清理”。生成的子样本包含与第二个时间点相关的变量，依此类推。以某种方式强制算法首先使用与第一轮相关的变量，然后使用与第二轮相关的变量，依此类推。
它可以使用例如 R 中的插入符包手动完成，但我确信有一个更优雅、自动化的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78122700/seeking-a-decision-tree-algorithm-for-temporally-ordered-variables</guid>
      <pubDate>Thu, 07 Mar 2024 15:51:04 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Val 损失没有显示？如何显示它然后用训练损失绘制它</title>
      <link>https://stackoverflow.com/questions/78122308/why-val-loss-is-not-showing-how-to-display-it-then-plot-it-with-training-loss</link>
      <description><![CDATA[在数据集上微调 pytorch llm(IDEFICS9b) 后，训练结果未显示 val 损失，如何收集它，然后用训练损失绘制它？
training_args = TrainingArguments(
    output_dir=f“{model_name}-vqa1”，
    学习率=3e-5，
    fp16=正确，
    per_device_train_batch_size=16，
    per_device_eval_batch_size=16，
    梯度累积步数=1，
    dataloader_pin_memory=False,
    save_total_limit=3,
    评价_策略=“步骤”，
    save_strategy=&quot;步骤&quot;,
    保存步骤=10，
    评估步骤=10，
    记录步骤=10，
    最大步数=1000，
    删除_未使用的列=假，
    Push_to_hub=假,
    label_names=[“标签”],
    load_best_model_at_end=真，
    report_to=无，
    optim=&quot;paged_adamw_8bit&quot;,
）
教练=教练（
    型号=型号，
    参数=训练参数，
    train_dataset=train_ds,
    eval_dataset=eval_ds,
）

train_results = trainer.train()

训练结果如下：
&lt;块引用&gt;
TrainOutput(global_step=10,training_loss=2.2117252349853516,metrics={&#39;train_runtime&#39;: 15.7995, &#39;train_samples_per_second&#39;: 10.127, &#39;train_steps_per_second&#39;: 0.633, &#39;total_flos&#39;: 470670709819392.0, &#39;train_loss&#39;：2.2117252349853516，&#39;纪元&#39;： 0.02})
]]></description>
      <guid>https://stackoverflow.com/questions/78122308/why-val-loss-is-not-showing-how-to-display-it-then-plot-it-with-training-loss</guid>
      <pubDate>Thu, 07 Mar 2024 14:56:29 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.multiclass.OneVsRestClassifier 中的回调</title>
      <link>https://stackoverflow.com/questions/78119978/callbacks-in-sklearn-multiclass-onevsrestclassifier</link>
      <description><![CDATA[我想使用回调和 eval_set 等。
但我有一个问题：
from sklearn.multiclass import OneVsRestClassifier
导入lightgbm

&lt;前&gt;&lt;代码&gt;详细 = 100
参数 = {
    “目标”：“二元”，
    “n_估计器”：500，
    “详细”：0
}
适合参数= {
    “eval_set”：eval_数据集，
    “回调”：[CustomCallback（详细）]
}

clf = OneVsRestClassifier(lightgbm.LGBMClassifier(**params))
clf.fit(X_train, y_train, **fit_params)

我如何将 fit_params 交给我的估算器？我明白
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- --------------------------
---&gt; 13 clf.fit(X_train, y_train, **fit_params)

TypeError：OneVsRestClassifier.fit() 得到意外的关键字参数“eval_set”
]]></description>
      <guid>https://stackoverflow.com/questions/78119978/callbacks-in-sklearn-multiclass-onevsrestclassifier</guid>
      <pubDate>Thu, 07 Mar 2024 08:59:29 GMT</pubDate>
    </item>
    <item>
      <title>加载图像边界框输出相同大小的错误</title>
      <link>https://stackoverflow.com/questions/78118283/loading-image-bounding-boxes-outputs-equal-size-error</link>
      <description><![CDATA[我正在尝试为我的数据集创建一个 PyTorch 数据加载器。每个图像都有一定数量的汽车和每个汽车的边界框，但并非所有图像都具有相同数量的边界框。
您可能无法运行它，但这里有一些信息。
这是我的数据加载器
类 AGR_Dataset（数据集）：
    def __init__(self,annotations_root,img_root,transform=None):
        ”“”
        论据：
            comments_root（字符串）：带有注释的 csv 文件的路径。
            img_root（字符串）：包含所有图像的目录。
            变换（可调用，可选）：要应用的可选变换
                在样品上。
        ”“”
        self.annotations_root = 注释_root
        self.img_root = img_root
        self.transform = 变换

    def __len__(自身):
        返回 len(self.annotations_root)
    
    def __getitem__(self, idx):
        # idx 可能是索引或图像名称，我认为图像 naem
        如果 torch.is_tensor(idx):
            idx = idx.tolist()
        
        idx_name = os.listdir(self.img_root)[idx]
        # 打印(idx_name)
        
        img_name = os.path.join(self.img_root, idx_name)
        Comments_data = os.path.join(self.annotations_root, f&quot;{idx_name.removesuffix(&#39;.jpg&#39;)}.txt&quot;)
        # print(img_name, 注释数据)

        图像 = io.imread(img_name)

        以 open(annotation_data, &#39;r&#39;) 作为文件：
            行= file.readlines()
            图像数据 = []
            img_标签 = []
            对于行中行：
                line = line.split(&#39;,&#39;)
                line = [i.strip() for i in line]
                line = [float(num) for num in line[0].split()]
                img_labels.append(int(行[0]))
                img_data.append(行[1:])

        框 = tv_tensors.BoundingBoxes(img_data, format=&#39;CXCYWH&#39;, canvas_size=(image.shape[0], image.shape[1]))

        # 样本 = {&#39;image&#39;: 图像, &#39;bbox&#39;: 盒子, &#39;labels&#39;: img_labels}
        样本= {&#39;image&#39;：图像，&#39;bbox&#39;：盒子}

        如果自我变换：
            样本 = self.transform(样本)

        打印（样本[&#39;图像&#39;].shape）
        打印（样本[&#39;bbox&#39;].shape）
        # print(样本[&#39;标签&#39;].shape)
        返回样品

我运行转换并创建数据加载器
data_transform = v2.Compose([
    v2.ToImage(),
    # v2.调整大小(680),
    v2.RandomResizedCrop(大小=(680, 680), 抗锯齿=True),
    # v2.ToDtype(torch.float32,scale=True),
    v2.ToTensor()
]）

Transformed_dataset = AGR_Dataset(f&#39;{annotations_path}/test/&#39;,
                        f&#39;{img_path}/测试/&#39;,
                        变换=数据变换）

数据加载器=数据加载器(transformed_dataset,batch_size=2,
                        洗牌=假，num_workers=0）

然后我尝试用它迭代它，并最终使用边界框查看和图像。
对于 i，枚举（dataloader）中的示例：
    打印（我，样本）
    print(i, 样本[&#39;image&#39;].size(), 样本[&#39;bbox&#39;].size())

    如果我==4：
        休息

批处理大小为 1 时，它运行正常，批处理大小为 2 时，出现此错误
torch.Size([3, 680, 680])
火炬.Size([12, 4])

火炬.Size([3, 680, 680])
火炬.Size([259, 4])

RuntimeError: 堆栈期望每个张量大小相等，但在条目 0 处得到 [12, 4]，在条目 1 处得到 [259, 4]


我认为这是由于边界框数量不相等造成的，但如何克服这个问题？
我的变换中需要 ToTensor 吗？我开始认为我不这样做，因为 v2 使用 ToImage()，而 ToTensor 正在被贬值。

如有任何其他意见或帮助，我们将不胜感激。
我不确定如何创建一个工作示例，我会继续尝试。
我尝试过的
我尝试通过注释数据加载器中的 tv_tensors.BoundingBoxes 行来不将边界框加载为张量，但由于某种原因，我的调整大小无法正常工作。
我刚刚尝试在数据加载器中像这样分割框和图像
样本 = 图像
    目标= {&#39;bbox&#39;：盒子，&#39;标签&#39;：img_labels}

运气不好]]></description>
      <guid>https://stackoverflow.com/questions/78118283/loading-image-bounding-boxes-outputs-equal-size-error</guid>
      <pubDate>Thu, 07 Mar 2024 01:30:38 GMT</pubDate>
    </item>
    <item>
      <title>RF 模型的 MLJ.jl 中的数据类型总是错误</title>
      <link>https://stackoverflow.com/questions/78116043/data-type-is-always-wrong-in-mlj-jl-with-the-rf-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78116043/data-type-is-always-wrong-in-mlj-jl-with-the-rf-model</guid>
      <pubDate>Wed, 06 Mar 2024 16:41:59 GMT</pubDate>
    </item>
    <item>
      <title>使用LSTM模型进行充电数据负荷预测的时间序列交叉验证</title>
      <link>https://stackoverflow.com/questions/78107902/time-series-cross-validation-for-load-forecast-of-charging-data-using-lstm-model</link>
      <description><![CDATA[我目前正在构建一个 LSTM 模型，以使用包含 24 个特征和 12 个月目标列的数据集来预测电动汽车的消耗量。数据采用时间序列格式，间隔为 15 分钟，我想应用时间序列交叉验证来维护时间依赖性。
这是我到目前为止为训练和测试拆分编写的代码：
# 定义用于训练的列
特征 = [&#39;小时&#39;, &#39;季度小时&#39;, &#39;工作日&#39;, &#39;cal_week&#39;, &#39;月份&#39;, &#39;周末&#39;,
                  &#39;季节&#39;，&#39;假期&#39;，&#39;下一个假期&#39;，&#39;bridge_day&#39;，&#39;学校假期&#39;，&#39;quarter_sin&#39;，&#39;quarter_cos&#39;，&#39;hour_sin&#39;，&#39;hour_cos&#39;，
                  &#39;weekday_sin&#39;、&#39;weekday_cos&#39;、&#39;month_sin&#39;、&#39;month_cos&#39;、&#39;cal_week_sin&#39;、&#39;cal_week_cos&#39;、&#39;temp_day_avg&#39;、&#39;humidity_day_avg&#39;、&#39;wind_speed&#39;]

# 提取特征和目标变量
X = Bosch_data[功能].值
y = Bosch_data[&#39;aggregate_conspiration_kWh&#39;].values


# 定义窗口大小
validation_window_size = 7 * 24 * 4 # 7天* 24小时* 4个季度/小时（15T）
test_window_size = 31 * 24 * 4 # 31天* 24小时* 4个季度/小时（15T）

# 将训练集定义为除验证集和测试集之外的所有内容
train_window_size = len(Bosch_data) - validation_window_size - test_window_size

# 将数据分为训练集、验证集和测试集
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=validation_window_size + 31 * 24 * 4, shuffle=False)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=31 * 24 * 4, shuffle=False)

我有两个具体问题：

扩展窗口交叉验证：如何将扩展窗口交叉验证应用于此训练、验证和测试拆分？

选择时间步长：我的数据集呈现每周模式，我想预测未来 30 天的消耗量。考虑到 15 分钟的时间间隔，在这种情况下我的理想时间步长应该是多少？如果我使用 15 分钟的时间间隔作为一个时间步长，则会出现错误。


我愿意接受有关如何解决这些问题并扩展我的时间序列交叉验证代码的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78107902/time-series-cross-validation-for-load-forecast-of-charging-data-using-lstm-model</guid>
      <pubDate>Tue, 05 Mar 2024 12:58:27 GMT</pubDate>
    </item>
    <item>
      <title>用Python代码编写的RNN反向传播公式</title>
      <link>https://stackoverflow.com/questions/78102670/rnn-backpropagation-formula-written-in-python-code</link>
      <description><![CDATA[鉴于常规 RNN 网络反向传播的文本描述，我无法将给定的公式与此处的 python 代码关联起来：
https://dennybritz.com/posts/ wildml/recurrent-neural-networks-tutorial-part-3/
另请参阅此屏幕截图。
你能澄清一下吗？
为我应用链式法则与给定的 python 代码不匹配。如果我没记错的话，给出：
f(x) = tanh(x)
然后：
df/dx = 1 - tanh^2(x)
但是我没有看到给定的 python 代码对 tanh 函数的任何使用。]]></description>
      <guid>https://stackoverflow.com/questions/78102670/rnn-backpropagation-formula-written-in-python-code</guid>
      <pubDate>Mon, 04 Mar 2024 16:16:44 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 AttributeError: 'ConfigDict' 对象在 mmdetection 上没有属性 'data'？</title>
      <link>https://stackoverflow.com/questions/74209071/how-to-fix-attributeerror-configdict-object-has-no-attribute-data-on-mmdete</link>
      <description><![CDATA[我目前正在尝试为自定义数据集设置毫米检测，并且一直遇到这些错误。我尝试删除代码中的 def 函数，更改文件位置以及上述所有内容。我不知道代码有什么问题以及为什么它不起作用。
from argparse import ArgumentParser
从 mmdet.apis 导入 init_detector、inference_detector
导入MMCV
从 mmdet.apis 导入（async_inference_ detector、inference_ detector、
                        init_Detector、show_result_pyplot）
导入异步
进口火炬
从 mmdet.apis 导入 init_detector、async_inference_detector
从 mmdet.utils.contextmanagers 导入并发

定义数据（）：
# 新配置继承基本配置以突出显示必要的修改
    base_ = &#39;configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_1x_coco.py&#39;

# 我们还需要更改 head 中的 num_classes 以匹配数据集的注释
# dict 是一个 python 字典对象，用于从 PyTorch 保存或加载模型
    模型=字典（
        roi_head=字典（
        # 定义边界框可以绕过的类数
            bbox_head=dict(num_classes=1),
            #
            mask_head=dict(num_classes=1)))

def 数据集():
    # 修改数据集相关设置
    dataset_type = &#39;COCO数据集&#39;
    #定义类
    类 = (&#39;受电弓&#39;)
    数据=字典（
        火车=字典（
            img_prefix=&#39;测试/&#39;,
            类=类，
            ann_file=&#39;train/Pan2_COCO.json&#39;),
        val=字典（
            img_prefix=&#39;测试/&#39;,
            类=类，
            ann_file=&#39;val/Pan2_COCO.json&#39;),
        测试=字典（
            img_prefix=&#39;测试/&#39;,
            类=类，
            ann_file=&#39;val/Pan2_COCO.json&#39;))
定义负载（）：
# 我们可以使用预训练的Mask RCNN模型来获得更高的性能
    load_from = &#39;测试/检查点/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth&#39;

数据（）
数据集()
加载（）

错误消息：
回溯（最近一次调用最后一次）：
  文件“tools/train.py”，第244行，在&lt;module&gt;中。
    主要的（）
  文件“tools/train.py”，第 135 行，在 main 中
    setup_multi_processes（cfg）
  文件“/home/dtl-admin/dev/mmdetection/mmdet/utils/setup_env.py”，第 30 行，setup_multi_processes
    workers_per_gpu = cfg.data.get(&#39;workers_per_gpu&#39;, 1)
  文件“/home/dtl-admin/miniconda3/envs/mmtest/lib/python3.8/site-packages/mmcv/utils/config.py”，第 519 行，在 __getattr__ 中
    返回 getattr(self._cfg_dict, 名称)
  文件“/home/dtl-admin/miniconda3/envs/mmtest/lib/python3.8/site-packages/mmcv/utils/config.py”，第 50 行，在 __getattr__ 中
    提高前任
AttributeError：“ConfigDict”对象没有属性“data”

我期待图像检测到类受电弓的输出。但是，无论我尝试什么，我都无法获得任何输出，并且我已尝试更改尽可能多的变量。]]></description>
      <guid>https://stackoverflow.com/questions/74209071/how-to-fix-attributeerror-configdict-object-has-no-attribute-data-on-mmdete</guid>
      <pubDate>Wed, 26 Oct 2022 13:58:38 GMT</pubDate>
    </item>
    <item>
      <title>学习一种双线性形式的矩阵函数</title>
      <link>https://stackoverflow.com/questions/67740146/learn-the-matrix-function-of-a-sort-of-bilinear-form</link>
      <description><![CDATA[我正在考虑对标量函数 f:R^n-&gt;R 进行回归的问题，其中我有一组训练样本 (x1,y1),...,(xN,yN)，其中 yi = f(xi)。
我知道原则上我可以应用任何神经网络架构来对此函数进行回归，但是我想利用我了解的属性来设计网络。
准确地说，我知道 f(x)= x^TA(x)x$ 对于 nxn 矩阵值函数 A(x)，我不太清楚，但我知道它是对称且正定的。
我认为，既然我知道函数的这种结构，那么应用“标准”函数并不是一种有效的方法。架构来解决这个问题。这个问题实际上看起来像是在 R^n 上寻找并逼近度量的问题。
由于 A(x) 是对称正定的，对于未知的矩阵值函数 B(x)，我想将其重写为 A(x) = B(x)^TB(x)。因此，函数 f(x) 以更简单的方式重写：f(x) = |B(x)x|^2，其中唯一的未知数是矩阵函数 B(x)。
现在，是否有一些已知的架构非常适合这种情况？
使用 B(x) 常数生成训练数据，我已经很容易地解决了这个问题，定义了要优化的权重，并且效果很好。但是，如果矩阵 B(x) 与 x 相关，我不完全确定如何继续。
到目前为止，我已经实现了一个从 R^n 到 R^{n^2} 的神经网络，其中输出被重新整形为 nxn 矩阵 B(x) 来学习。然而，这仅适用于简单的 B(x)，对我来说仍然不清楚原因。]]></description>
      <guid>https://stackoverflow.com/questions/67740146/learn-the-matrix-function-of-a-sort-of-bilinear-form</guid>
      <pubDate>Fri, 28 May 2021 13:51:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit-learn 对文本进行标记</title>
      <link>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</link>
      <description><![CDATA[我有以下代码从一组文件（文件夹名称是类别名称）中提取特征以进行文本分类。
导入sklearn.datasets
从 sklearn.feature_extraction.text 导入 TfidfVectorizer

train = sklearn.datasets.load_files(&#39;./train&#39;,description=None,categories=None,load_content=True,shuffle=True,encoding=None,decode_error=&#39;strict&#39;,random_state=0)
print len(训练数据)
打印train.target_names

向量化器 = TfidfVectorizer()
X_train = 矢量化器.fit_transform(train.data)

它抛出以下堆栈跟踪：
回溯（最近一次调用最后一次）：
  文件“C:\EclipseWorkspace\TextClassifier\main.py”，第 16 行，在  中
    X_train = 矢量化器.fit_transform(train.data)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 1285 行，在 fit_transform 中
    X = super(TfidfVectorizer, self).fit_transform(raw_documents)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 804 行，在 fit_transform 中
    self.fixed_vocabulary_)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 739 行，在 _count_vocab 中
    对于分析（doc）中的功能：
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 236 行，位于 &lt;lambda&gt; 中
    tokenize(预处理(self.decode(doc))), stop_words)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 113 行，解码
    doc = doc.decode(self.encoding, self.decode_error)
  文件“C:\Python27\lib\encodings\utf_8.py”，第 16 行，解码中
    返回codecs.utf_8_decode（输入，错误，True）
UnicodeDecodeError：“utf8”编解码器无法解码位置 32054 中的字节 0xff：起始字节无效

我运行Python 2.7。我怎样才能让它发挥作用？
编辑：
我刚刚发现这对于使用 utf-8 编码的文件（我的文件是 ANSI 编码）非常有效。有什么方法可以让 sklearn.datasets.load_files() 使用 ANSI 编码吗？]]></description>
      <guid>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</guid>
      <pubDate>Fri, 01 May 2015 00:39:09 GMT</pubDate>
    </item>
    </channel>
</rss>