<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 01 Dec 2023 12:26:17 GMT</lastBuildDate>
    <item>
      <title>对于分割数据，如果我不指定分割比率，pytorch会自己随机进行吗？</title>
      <link>https://stackoverflow.com/questions/77584885/for-splitting-the-data-does-pytorch-do-it-by-itself-randomly-if-i-don-t-specify</link>
      <description><![CDATA[对于分割数据，如果我不指定分割比例，pytorch 会自行随机进行吗？
我正在研究 pytorch 深度学习模型自动编码器，我有包含 10 个类和 50 万行的数据集（csv 文件）。
我删除了标签列。
我看到一篇研究论文代码，他们没有拆分代码，而是从数据集（csv 文件）中删除了标签]]></description>
      <guid>https://stackoverflow.com/questions/77584885/for-splitting-the-data-does-pytorch-do-it-by-itself-randomly-if-i-don-t-specify</guid>
      <pubDate>Fri, 01 Dec 2023 11:17:31 GMT</pubDate>
    </item>
    <item>
      <title>用于学习一维分布的扩散模型</title>
      <link>https://stackoverflow.com/questions/77584229/diffusion-models-for-learning-1d-distributions</link>
      <description><![CDATA[我是扩散模型的新手。我想知道使用它们来学习一维分布模型是否有意义，即将正态分布 (0,1) 转换为目标分布。如果是这样，您能给我提供一些伪代码或用 Python 实现的存储库示例吗？非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77584229/diffusion-models-for-learning-1d-distributions</guid>
      <pubDate>Fri, 01 Dec 2023 09:34:56 GMT</pubDate>
    </item>
    <item>
      <title>InvalidArgumentError：double 的 attr 'Tindices' 的值不在允许值列表中：int16、int32、int64</title>
      <link>https://stackoverflow.com/questions/77584003/invalidargumenterror-value-for-attr-tindices-of-double-is-not-in-the-list-of</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77584003/invalidargumenterror-value-for-attr-tindices-of-double-is-not-in-the-list-of</guid>
      <pubDate>Fri, 01 Dec 2023 08:53:25 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 分类，XGBClassifier 与 xgb.train 的 AUC 分数不同，即使在舍入预测概率后也是如此</title>
      <link>https://stackoverflow.com/questions/77583899/xgboost-classification-different-auc-score-for-xgbclassifier-vs-xgb-train-even</link>
      <description><![CDATA[看起来 XGBClassifier 是 xgb.train 的包装器。我试图使用 xgb.train 和 &quot;objective&quot;: &quot;binary:logistic&quot; 训练二元分类器。
似乎使用 xgb.train 后跟 .predict() 返回预测概率，我们可以将其舍入为 0 或 1 以进行分类。
但是，即使在训练数据集上与 XGBClassifier 的 AUC 分数进行比较时，xgb.train 方法也明显较差......
使用xgb.train作为分类器的正确方法是什么？
X = df[X_colnames]
y = df[&#39;BP命中&#39;].astype(&#39;类别&#39;)
dtrain = xgb.DMatrix(X, 标签=y)
param = {“目标”：“二进制：逻辑”，}
模型 = xgb.train(param,dtrain)
y_hat = model.predict(xgb.DMatrix(X))
打印（y_帽子）
print(sklearn.metrics.roc_auc_score(y,[round(y) for y in y_hat]))


模型= XGBClassifier（目标=&#39;二进制：逻辑&#39;）
# 定义训练数据
X = df[X_列名]
y = df[&#39;BP命中&#39;].astype(&#39;类别&#39;)
模型.fit(X,y)
打印（模型.预测（X））
print(sklearn.metrics.roc_auc_score(y,[model.predict(X) 中 y 的 round(y)]))

输出：
&lt;预&gt;&lt;代码&gt;[0.02280498 0.02280498 0.02280498 ... 0.02280498 0.02280498 0.02280498]
0.9427811205601163
[0 0 0 ... 0 0 0]
1.0
]]></description>
      <guid>https://stackoverflow.com/questions/77583899/xgboost-classification-different-auc-score-for-xgbclassifier-vs-xgb-train-even</guid>
      <pubDate>Fri, 01 Dec 2023 08:32:40 GMT</pubDate>
    </item>
    <item>
      <title>如何使用openvino优化模型和YOLO将目标检测应用程序转换为exe</title>
      <link>https://stackoverflow.com/questions/77583764/how-to-convert-object-detection-application-in-exe-by-using-openvino-optimized</link>
      <description><![CDATA[当我使用这个命令pyinstaller main.py --onefile -w 将项目转换为exe文件时，我遇到了这个问题：
错误：[Errno 2] 没有这样的文件或目录：&#39;&#39;C:\Users\sachin\Appdata\Local\Temp\_MEI177322\ultralytics\yolo\cfg\default.yaml。
]]></description>
      <guid>https://stackoverflow.com/questions/77583764/how-to-convert-object-detection-application-in-exe-by-using-openvino-optimized</guid>
      <pubDate>Fri, 01 Dec 2023 07:59:57 GMT</pubDate>
    </item>
    <item>
      <title>寻找特定领域的数据集来训练机器学习模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77583636/seeking-domain-specific-datasets-for-training-machine-learning-models</link>
      <description><![CDATA[我目前正在开发机器学习模型，需要特定领域的数据集。我的目标是训练一个专门理解以领域为中心的内容并与之交互的模型，这些内容的范围可以从 IT 和工程等技术领域到医疗保健或金融等专业领域。
详细信息：
数据类型：我正在寻找包含特定领域术语、行话、工作流程以及与该领域专家相关的任何相关知识的数据集。
用途：目的是训练用于特定领域问答、内容生成和数据分析等任务的模型。
数据特异性：数据在领域覆盖范围方面越全面、越多样化越好。
我尝试过的：
我在 GitHub、Kaggle 和 Google 数据集搜索等平台上搜索了开源数据集。
我研究了学术数据库中的研究论文和特定领域的相关数据集。
我探索了与目标领域的行业合作伙伴的数据共享协议。
我正在联系社区中的任何人，看看是否有人提出建议或知道可以公开或购买此类特定于域的数据集的存储库。]]></description>
      <guid>https://stackoverflow.com/questions/77583636/seeking-domain-specific-datasets-for-training-machine-learning-models</guid>
      <pubDate>Fri, 01 Dec 2023 07:31:33 GMT</pubDate>
    </item>
    <item>
      <title>对视频中的帧进行分类以查看它是否包含一组幻灯片中的一张</title>
      <link>https://stackoverflow.com/questions/77583613/categorise-a-frame-in-a-video-to-see-if-it-contains-one-of-a-set-of-slides</link>
      <description><![CDATA[我想要处理视频，其中讲师站在白板前，上面有多张幻灯片。他们可能会四处走动、挡住黑板或在幻灯片上书写。我已经收集了所有幻灯片，但我无法实时训练任何模型，即解决方案应该只是比较两个图像（视频帧和幻灯片图像）之间的“相似性”。我觉得问题是图像相似性和单一分类同时存在。
我的想法是每隔 30 秒左右抓取几帧（假设任何重要幻灯片的使用时间超过 30 秒），并将其与我准备的幻灯片进行比较（一场讲座通常有大约 9-10 张幻灯片）。这有多可行？
我不是在寻找代码，我来这里是为了了解总体思路。我想尽快完成这项工作，因此任何能够完成繁重工作的库都是（非常）可取的，但如果没有其他选择，我确实了解一点 PyTorch。如果唯一的选择是训练我自己的模型，什么架构/模型最适合这个？如果有人可以分享与此相关的任何资源，我也希望如此。
编辑：伙计们至少在这样做之前评论一下为什么你投反对票，这有什么问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77583613/categorise-a-frame-in-a-video-to-see-if-it-contains-one-of-a-set-of-slides</guid>
      <pubDate>Fri, 01 Dec 2023 07:27:55 GMT</pubDate>
    </item>
    <item>
      <title>在启用反向传播的情况下，有效模拟具有异质空间和时间感受野的神经元？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77582849/efficient-simulation-of-neurons-with-heterogeneous-spatial-and-temporal-receptiv</link>
      <description><![CDATA[我想找到一种方法来对具有异构空间和时间感受野的神经元进行高效模拟，并且理想情况下启用反向传播，以便我可以微调感受野的权重。每个神经元的计算简单，但神经元数量较多（1e5 ~ 1e6）。主要困难在于每个神经元的空间和时间感受野的大小不同（从动物实验数据获得）并且变化很大。在GPU上进行矢量化运算有点困难。
模拟如下：
# 初始化
# 每个神经元的k和l的值是不同的。
获取输入图像的形状（在整个模拟过程中固定）。
对于每个神经元：
    (1).获取其空间感受野下的像素索引，存储为 [k x 2] 数组，因为空间感受野可能不是正方形。
    （2）。初始化空间感受野中的权重，存储为 [k x 1] 数组。
    （3）。获取时间感受野的长度l（时间步数）。
    （4）。初始化时间感受野中的权重，存储为 [l x 1] 数组。
    （5）。初始化一个空的 [l x 1] 数组缓冲区，用零填充。
将所有神经元的参数存储在列表中。

＃ 模拟
对于每个输入图像：
    对于每个神经元：
        (1).根据图像的 [k x 2] 像素索引获得展平的补丁，存储为 [k x 1] 数组。
        （2）。计算图像块与空间感受野权重的内积，输出 [1 x 1] 标量。
        （3）。删除缓冲区中的第一个元素，将其余元素与 [1 x 1] 标量（最后位置的标量）连接，输出 [l x 1] 更新的缓冲区。
        （4）。计算更新后的缓冲区与时间感受野权重的内积，输出 [1 x 1] 标量。
        （5）。将标量传递给 ReLU 函数，将输出设置为神经元的输出。

我已经在 Python JAX 中实现了上述过程。实现与上面的描述几乎完全相同，包括仿真阶段的双for循环。但CPU和GPU上的性能都很慢。
目前，我想找到一种方法来优化模拟过程中的每个神经元循环（因为在测试时，可以从相机实时获取输入图像）。初始化阶段的性能已经不错了。我想要实现的是：

在 CPU 上运行时使用所有可用的 CPU 内核。默认情况下，JAX 仅使用一个 CPU 核心。
在 GPU 上运行时对计算进行向量化，同时保持内存效率。每个神经元的空间和时间感受野的大小都不同。如果我们简单地将小感受野补零到最大尺寸，它可能很容易消耗整个 GPU 内存。
理想情况下，将来可以通过反向传播重复使用相同的模拟代码进行训练。

有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77582849/efficient-simulation-of-neurons-with-heterogeneous-spatial-and-temporal-receptiv</guid>
      <pubDate>Fri, 01 Dec 2023 03:26:31 GMT</pubDate>
    </item>
    <item>
      <title>unserialize(socklist[[n]]) 中的错误：在插入符中执行 RF 模型时从连接读取错误</title>
      <link>https://stackoverflow.com/questions/77582605/error-in-unserializesocklistn-error-reading-from-connection-while-execut</link>
      <description><![CDATA[我正在尝试运行随机森林代码，以使用 R studio 中的插入符包对卫星图像进行分类。在训练模型时，我总是收到错误“unserialize(socklist[[n]]) 中的错误：从连接读取错误”。尝试关闭集群时“unserialize(node$con) 中的错误：从连接读取时出错”这个错误来了。我正在使用 caret 包并使用 doparallel 包进行并行计算
&quot;cl &lt;- makeCluster(3/4 * detectorCores())
registerDoParallel(cl)”
我使用的系统具有 i9（第 13 代）、128 GB 内存，并尝试使用 28、24、16 核。所有的尝试都以这个错误告终。我重新安装了 R 和 R studio，将版本更改为旧版本，在终端中运行脚本，但出现了同样的错误。相同的代码在 i5（第 9 代）笔记本电脑上成功运行； 16 GB 内存仅使用 3 个核心，但输出需要 12 小时。我该如何解决这个问题。这是代码、R studio 还是我正在使用的系统的问题？]]></description>
      <guid>https://stackoverflow.com/questions/77582605/error-in-unserializesocklistn-error-reading-from-connection-while-execut</guid>
      <pubDate>Fri, 01 Dec 2023 01:53:00 GMT</pubDate>
    </item>
    <item>
      <title>将时间序列高分辨率数据集存储为一个更简单的事务集，其中包括其元数据[关闭]</title>
      <link>https://stackoverflow.com/questions/77582450/store-time-series-high-resolution-data-sets-each-computed-summarized-into-a-simp</link>
      <description><![CDATA[我正在测试时间序列高分辨率数据集，每个数据集都计算/汇总为一个更简单的事务集（包括其元数据）。这些存储在本地服务器中。我很少遇到连接表的需求；但是，我不断使用时间序列数据来创建其他指标来构建机器学习模型。
CSV 中的每个时间序列数据集最大可达 2.6MB，而交易数据则为 kB 大小。我有超过 20,000 组数据。
什么是具有最佳性能的数据库选项/架构？
关系型还是非关系型？
每个选项的供应商有哪些？
如何确定是否应该迁移到云服务器？
推荐的供应商有哪些？]]></description>
      <guid>https://stackoverflow.com/questions/77582450/store-time-series-high-resolution-data-sets-each-computed-summarized-into-a-simp</guid>
      <pubDate>Fri, 01 Dec 2023 00:47:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 VGG16 MNIST 数字进行迁移学习</title>
      <link>https://stackoverflow.com/questions/77568420/transfer-learning-using-vgg16-mnist-digits</link>
      <description><![CDATA[我正在尝试对 MNIST 数字执行迁移学习。我有兴趣获取 logits 并将其用于基于梯度的攻击。但由于某种原因，即使我的计算机是启用了 GPU 的 Apple m2max 计算机，内核仍然会死机。我也尝试使用 GPU 进行 colab，但遇到同样的问题。该数据集不太好学，我正在重用 imagenet 权重。我该如何解决这个问题？
类 VGG16TransferLearning(tf.keras.Model)：
  def __init__(自我，基本模型，模型)：
    超级（VGG16TransferLearning，自我）.__init__（）
    #基础模型
    self.base_model = 基本模型

   # 其他层
   self.flatten = tf.keras.layers.Flatten()
   self.dense1 = tf.keras.layers.Dense(512, 激活=&#39;relu&#39;)
   self.dense2 = tf.keras.layers.Dense(512, 激活=&#39;relu&#39;)
   self.dense3 = tf.keras.layers.Dense(10)
   self.layers_list = [self.flatten, self.dense1, self.dense2, self.dense3]
  
  #用其他层实例化基础模型
  self.model = models.Sequential(
    [self.base_model, *self.layers_list]
   ）

def 调用(self, *args, **kwargs):
  激活列表 = []
  输出=参数[0]
  
  对于 self.model.layers 中的图层：
    输出 = 层（输出）
    激活列表.append(out)
  如果 kwargs[&#39;训练&#39;]:
   返回
  别的：
   概率 = tf.nn.softmax(输出)
   返回，问题

这是上面类的实例化：
base_model = VGG16(weights=“imagenet”, include_top=False, input_shape=x_train[0].shape)

base_model.trainable = False
我的输入形状是(75,75,3)
这是编译和拟合方法
从tensorflow.keras导入层、模型

模型 = VGG16TransferLearning(base_model, 模型)
model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),
          优化器=tf.keras.optimizers.legacy.Adam(),
          指标=[&#39;准确性&#39;])

model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))

这是我每次调用 fit 方法时遇到的错误：
内核重启
Untitled.ipynb 的内核似乎已经死亡。它将自动重新启动
]]></description>
      <guid>https://stackoverflow.com/questions/77568420/transfer-learning-using-vgg16-mnist-digits</guid>
      <pubDate>Wed, 29 Nov 2023 03:29:36 GMT</pubDate>
    </item>
    <item>
      <title>如何按照官方方式将 Hugging Face LLaMA v2 模型的权重重新初始化为原始模型？</title>
      <link>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</guid>
      <pubDate>Fri, 17 Nov 2023 03:15:56 GMT</pubDate>
    </item>
    <item>
      <title>如何防止 Keras 在训练期间计算指标</title>
      <link>https://stackoverflow.com/questions/71412499/how-to-prevent-keras-from-computing-metrics-during-training</link>
      <description><![CDATA[我正在使用 Tensorflow/Keras 2.4.1，并且我有一个（无监督的）自定义指标，它将我的多个模型输入作为参数，例如：
model = build_model() # 返回一个 tf.keras.Model 对象
my_metric = custom_metric(model.output, model.input[0], model.input[1])
模型.add_metric(my_metric)
[...]
model.fit([...]) # 使用 fit 进行训练

但是，custom_metric 非常昂贵，因此我希望仅在验证期间计算它。我找到了这个答案，但我几乎不明白如何使解决方案适应我的指标，该指标使用多个模型输入作为参数，因为update_state 方法似乎不太灵活。
在我的上下文中，除了编写自己的训练循环之外，是否有办法避免在训练期间计算我的指标？
另外，我很惊讶我们无法本机指定 Tensorflow 某些指标只能在验证时计算，这有什么原因吗？
此外，由于模型经过训练来优化损失，并且训练数据集不应用于评估模型，我什至不明白为什么默认情况下 Tensorflow 在训练期间计算指标。]]></description>
      <guid>https://stackoverflow.com/questions/71412499/how-to-prevent-keras-from-computing-metrics-during-training</guid>
      <pubDate>Wed, 09 Mar 2022 16:11:26 GMT</pubDate>
    </item>
    <item>
      <title>Keras 何时以及如何计算每批样本的指标？</title>
      <link>https://stackoverflow.com/questions/66311611/when-and-how-keras-calculate-metrics-for-each-batch-of-samples</link>
      <description><![CDATA[我看到 Keras 自定义指标如何工作，并且指标函数中的 tf.print 与 model.fit 的回调打印之间的计算不匹配。
导入张量流为 tf # tf2.4.1
将 numpy 导入为 np
模型 = tf.keras.models.Sequential(
    tf.keras.layers.Dense(1, input_shape=(1,))
）
def my_metric_fn(y_true, y_pred):
    squared_difference = tf.square(y_true - y_pred)
    损失 = tf.reduce_mean(squared_difference, axis=-1)
    tf.print(y_true.shape, y_pred.shape, 损失, tf.reduce_mean(squared_difference))
    回波损耗
model.compile（优化器=&#39;adam&#39;，损失=&#39;mean_squared_error&#39;，指标=[my_metric_fn]）
x = np.random.rand(4,1)
y = x ** 2
历史= model.fit（x = x，y = y，batch_size = 2，epochs = 2）
打印（历史.历史）

输出（格式化以提高可读性）
纪元 1/2
TensorShape([2, 1]) TensorShape([2, 1]) [9.79962078e-06 0.0534314588] 0.02672063
1/2 [==============&gt;........................] - ETA：0秒 - 损失：0.0267 - my_metric_fn：0.0267
TensorShape([2, 1]) TensorShape([2, 1]) [0.0397406667 0.179955378] 0.109848022
2/2 [================================] - 0s 7ms/步 - 损耗：0.0544 - my_metric_fn：0.0544

纪元2/2
TensorShape([2, 1]) TensorShape([2, 1]) [0.0392204635 0.0521505736] 0.0456855185
1/2 [==============&gt;........................] - ETA：0秒 - 损失：0.0457 - my_metric_fn：0.0457
TensorShape([2, 1]) TensorShape([2, 1]) [0.177408844 2.45939535e-08] 0.088704437
2/2 [================================] - 0s 5ms/步 - 损耗：0.0600 - my_metric_fn：0.0600
{&#39;损失&#39;：[0.06828432530164719，0.06719497591257095]，&#39;my_metric_fn&#39;：[0.06828432530164719，0.06719497591257095]}

在上面的输出中查看批次的打印损失。
纪元 1/2 1/2 tf.print：0.02672063，model.fit：0.0267。好的。
Epoch 1/2 2/2 tf.print：0.109848022，但 model.fit：0.0544。不行。
如何理解这些匹配和不匹配？ 0.0544 从哪里来？]]></description>
      <guid>https://stackoverflow.com/questions/66311611/when-and-how-keras-calculate-metrics-for-each-batch-of-samples</guid>
      <pubDate>Mon, 22 Feb 2021 07:31:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 keras 计算每个时期的 Fscore（不是批量）</title>
      <link>https://stackoverflow.com/questions/61683829/calculating-fscore-for-each-epoch-using-keras-not-batch-wise</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/61683829/calculating-fscore-for-each-epoch-using-keras-not-batch-wise</guid>
      <pubDate>Fri, 08 May 2020 16:41:15 GMT</pubDate>
    </item>
    </channel>
</rss>