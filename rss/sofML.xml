<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 14 Feb 2024 21:12:24 GMT</lastBuildDate>
    <item>
      <title>有没有方法可以识别 XGBoost 树适合哪个数据子样本？</title>
      <link>https://stackoverflow.com/questions/77997182/are-there-ways-to-identify-which-subsample-of-data-an-xgboost-tree-was-fitted-on</link>
      <description><![CDATA[我有兴趣了解是否可以确定为每棵树的训练随机选择哪些特定的样本行（根据子样本参数）。例如，训练集有 100 行，子采样率为 0.7，我很想知道为每棵树的训练选择的确切 70 行。我一直在到处寻找解决方案，但没有运气。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77997182/are-there-ways-to-identify-which-subsample-of-data-an-xgboost-tree-was-fitted-on</guid>
      <pubDate>Wed, 14 Feb 2024 20:58:25 GMT</pubDate>
    </item>
    <item>
      <title>Bagging 和 OOB 分配出现问题</title>
      <link>https://stackoverflow.com/questions/77997095/trouble-with-bagging-and-oob-assignment</link>
      <description><![CDATA[我正在学习 ML 课程，这是我的第一门课程，我是 ML 新手，并且我一直在做一些作业。我对其中一个有关装袋和 OOB 的问题有疑问
我必须填写下面代码中的行。这是 sklearn 的 BaggingRegressor 的简化版本。请注意，sklearn API 未保留。
该算法应该能够在引导数据集上训练同一模型类的不同实例，并为训练集提供 OOB 分数。
模型应作为模型类传递，没有显式参数，也没有括号。
虽然我已经有了 _generate_splits() 函数，但我仍然在努力解决其余的问题。
谁能告诉我这些函数的公式是什么？
将 numpy 导入为 np
`SimplifiedBaggingRegressor 类：
def __init__(self, num_bags, oob=False):
    self.num_bags = num_bags
    self.oob = oob
    
def _generate_splits(self, 数据: np.ndarray):
    &#39;&#39;&#39;
    为每个包生成索引并存储在 self.indices_list 列表中
    &#39;&#39;&#39;
    self.indices_list = []
    数据长度 = len(数据)
    对于范围内的包（self.num_bags）：
        # 这里是你的代码
                  bag_indices = list(范围(0,total_samples))
        self.indices_list.append(bag_indices)
    
def fit(自身、模型构造函数、数据、目标)：
    &#39;&#39;&#39;
    每个包袋都适合模型。
    不带参数（且不带 ()）的模型构造函数被传递给此函数。
    
    例子：
    
    bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)
    bagging_regressor.fit(线性回归, X, y)
    &#39;&#39;&#39;
    self.data = 无
    自我目标=无
    self._generate_splits（数据）
    assert len(set(list(map(len, self.indices_list)))) == 1, &#39;所有袋子的长度应该相同！&#39;
    assert list(map(len, self.indices_list))[0] == len(data), &#39;所有包都应包含 `len(data)` 个元素！&#39;
    self.models_list = []
    对于范围内的包（self.num_bags）：
        模型 = model_constructor()
        data_bag, target_bag = # 这里是你的代码
        self.models_list.append(model.fit(data_bag, target_bag)) # 在此存储拟合模型
    如果是 self.oob:
        self.data = 数据
        self.target = 目标
    
def 预测（自身，数据）：
    &#39;&#39;&#39;
    从传递的数据集中获取每个对象的平均预测
    &#39;&#39;&#39;
    # 这里是你的代码

def _get_oob_predictions_from_every_model（自身）：
    &#39;&#39;&#39;
    生成列表的列表，其中列表 i 包含 self.data[i] 对象的预测
    来自所有在训练阶段没有见过这个物体的模型
    &#39;&#39;&#39;
    list_of_predictions_lists = [[] for _ in range(len(self.data))]
    # 这里是你的代码
    
    self.list_of_predictions_lists = np.array(list_of_predictions_lists, dtype=object)

def _get_averged_oob_predictions（自我）：
    &#39;&#39;&#39;
    计算训练集中每个对象的平均预测。
    如果训练阶段的所有包中都使用了对象，则返回 None 而不是预测
    &#39;&#39;&#39;
    self._get_oob_predictions_from_every_model()
    self.oob_predictions = # 这里是你的代码
    
    
def OOB_score(自身):
    &#39;&#39;&#39;
    计算至少有一个预测的所有对象的均方误差
    &#39;&#39;&#39;
    self._get_averged_oob_predictions()
    在此处返回#您的代码`

我试图理解原始 BaggingRegressor 类是如何工作的，但我有点困惑。]]></description>
      <guid>https://stackoverflow.com/questions/77997095/trouble-with-bagging-and-oob-assignment</guid>
      <pubDate>Wed, 14 Feb 2024 20:35:59 GMT</pubDate>
    </item>
    <item>
      <title>扩散模型中的高损失</title>
      <link>https://stackoverflow.com/questions/77996298/high-loss-in-diffusion-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77996298/high-loss-in-diffusion-model</guid>
      <pubDate>Wed, 14 Feb 2024 17:41:48 GMT</pubDate>
    </item>
    <item>
      <title>在 cmake --build 期间无法将类型的非常量左值引用绑定到类型的右值</title>
      <link>https://stackoverflow.com/questions/77995524/cannot-bind-non-const-lvalue-reference-of-type-to-an-rvalue-of-type-during-cmake</link>
      <description><![CDATA[我正在尝试使用 cmake 构建我的项目，我正在使用不同的库，其中包含以下功能：
 voidforward(const MatrixType&amp; 输入，MatrixType&amp; 输出) {
    // 将输入复制到内部状态缓冲区
    states_[0] = 输入；
    // 计算通过隐藏层的前向传递
    for (size_t i=0; i 
在我自己的文件 RLController.cpp 中，我尝试在第 260 行将此函数调用为 ctrl_-&gt;forward(obScaled_, actScaled_);。
obScaled_ 和 actScaled_ 在我的头文件中定义为 Eigen::Matrix obScaled_、actScaled_ 并通过 ctrl.actScaled_.setZero(ctrl.mlp_output_size); 设置为零。
当我这样做时，我收到此错误：
&lt;块引用&gt;
错误：无法绑定“eignets::MultiLayerPerceptron::MatrixType&amp;”类型的非常量左值引用{aka &#39;Eigen::Matrix ;&amp;&#39;} 为 &#39;eignets::MultiLayerPerceptron::MatrixType&#39; 类型的右值 {aka &#39;Eigen::Matrix&#39;}
257 | 257 ctrl_-&gt;forward(obScaled_, actScaled_);

这不正是您应该通过引用调用的方式吗？
我觉得奇怪的是它曾经可以工作，但在迁移到另一个文件夹后它停止工作。但在构建过程中似乎没有任何与依赖项相关的错误。
为了完整起见，这是 RLController.cpp 中定义的函数，我将其称为转发函数：
void RLController::ComputeAction(float obs[], int obs_size){
    // obs 是来自环境的观测向量
    // 使用观察向量和 ctrl_ 模型计算动作向量

    // 缩放观察向量
    getObMean(obs);
    getObStd(obs);
    for (int i = 0; i &lt; obs_size; ++i) {
        obScaled_[i] = ((obs[i] - 平均值)) / std_dev;
    }

    ctrl_-&gt;forward(obScaled_, actScaled_);

    // 将动作向量转换为 double
    actDouble_ = actScaled_.cast();
    准确_-&gt; setDTarget(actDouble_);

}

forward 应该只是将 obScaled_ 传递给我已经训练过的多层感知器，并在 actScaled_ 中给我 3 个动作值，我通过引用传递了这些值。我陷入了用 cmake 构建的困境。如果我从 RLController.cpp 中取消第 260 行，它就会成功构建。]]></description>
      <guid>https://stackoverflow.com/questions/77995524/cannot-bind-non-const-lvalue-reference-of-type-to-an-rvalue-of-type-during-cmake</guid>
      <pubDate>Wed, 14 Feb 2024 15:41:28 GMT</pubDate>
    </item>
    <item>
      <title>UndefinedMetricWarning：精度定义不明确，由于没有预测样本而被设置为 0.0</title>
      <link>https://stackoverflow.com/questions/77995496/undefinedmetricwarning-precision-is-ill-defined-and-being-set-to-0-0-due-to-no</link>
      <description><![CDATA[当我尝试拟合 X 和 Y 训练集时，它会向我发出警告消息：
UndefinedMetricWarning：精度定义不明确，由于没有预测样本而被设置为 0.0。使用“zero_division”参数来控制此行为。 _warn_prf(平均值，修饰符，f“{metric.capitalize()}是”，len(结果))
这导致我的精确率、召回率和 F1 分数为 0。但是添加后
average=&#39;weighted&#39; 和 labels，它产生了可用的分数：
f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;, labels=np.unique(y_pred))

但是我的问题是我的 Y_pred 保持不变，每当我制作 ConfusionMatrix 时，它都会显示有 0 个 True 或 False Positive。有没有办法改变我的 Y_pred，以反映我修正的分数？
如上所述，我修复了分数，但 Y_pred 仍然不变。]]></description>
      <guid>https://stackoverflow.com/questions/77995496/undefinedmetricwarning-precision-is-ill-defined-and-being-set-to-0-0-due-to-no</guid>
      <pubDate>Wed, 14 Feb 2024 15:37:39 GMT</pubDate>
    </item>
    <item>
      <title>一类 SVM - 测试集上的异常值相对于训练集非常低</title>
      <link>https://stackoverflow.com/questions/77995464/one-class-svm-outliers-on-test-set-very-low-relative-to-training-set</link>
      <description><![CDATA[我正在使用 scikit-learn 一类 SVM 进行异常值检测。但相对于训练集，测试集上检测到的异常值数量非常少。
单类 SVM 的每个输入都是三个浮点数 [float1、float2、float3] 的列表。
所有列都使用最小-最大缩放比例缩放为 0 到 1 之间的值。
我按如下方式初始化并拟合 SVM：
clf = OneClassSVM(kernel=&#39;线性&#39;, nu=0.01, gamma=&#39;auto&#39;).fit(training_and_testing_sets[:TRAINING_SET_SIZE])

因为我对 nu 使用了 0.01 的值。我预计测试集上的异常值数量为整个测试集的 1%。但它是 0.004%。测试集也相应地缩放。
造成这种差异的原因是什么以及如何解决该问题？]]></description>
      <guid>https://stackoverflow.com/questions/77995464/one-class-svm-outliers-on-test-set-very-low-relative-to-training-set</guid>
      <pubDate>Wed, 14 Feb 2024 15:33:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用虚拟或标签编码训练决策树或逻辑回归或随机森林分类器有差异[关闭]</title>
      <link>https://stackoverflow.com/questions/77995197/why-is-there-a-difference-in-training-a-decisiontree-or-a-logisticregression-or</link>
      <description><![CDATA[我正在运行两项作业，第一个作业使用虚拟变量转换分类特征（按 10 列的顺序创建），第二个作业使用标签编码，因此大约有 10 个类别。
我有一个数据框，其中 df[&#39;salary&#39;] 是几个不同的位置。
为什么当我尝试这三种算法（DecisionTree 或 LogisticRegression 或 RandomForestClassifier）时内核会停止，而当我做假人时它却运行得很好？
结果是一列包含 1 到 10 个整数值，或者 10 列包含 0 或 1 值。这些算法没有用参数实例化，因此这是最简单的问题：标签编码的列/特征如何使算法变慢，并且比添加列的 get_dummies 更重？]]></description>
      <guid>https://stackoverflow.com/questions/77995197/why-is-there-a-difference-in-training-a-decisiontree-or-a-logisticregression-or</guid>
      <pubDate>Wed, 14 Feb 2024 14:54:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 IML 计算 Shapley 值时出错</title>
      <link>https://stackoverflow.com/questions/77991202/error-calculating-shapley-values-using-iml</link>
      <description><![CDATA[#训练随机森林模型
设置.种子(8431)
cvforest.train &lt;- 训练(x = 训练[, c(3:122, 124:138)], y = 训练[, 123],
                        方法＝“cforest”，度量＝“RMSE”，
                        trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 5),
                        控制= cforest_unbiased（ntree = 1000，minsplit = 5，minbucket = 5）
）

cvforest.model.train&lt;-cvforest.train$finalModel #最终模型对象

#计算 shapley 值
X &lt;- 训练[, c(3:122, 124:138)]
y &lt;- 火车[, 123]

预测器 &lt;- iml::Predictor$new(cvforest.model.train, data = X, y = y)
shapley_vals &lt;- iml::Shapley$new(预测器)

使用上面的代码，我使用 R 中的插入符号和 party 包拟合了一个随机森林模型。现在我想计算该模型的 Shapley 值。但是，当我使用上面的代码创建“shapley_vals”对象时，我发现“results”和“fit”选项为 NULL。我不确定我错过了哪些步骤。关于下一步该做什么有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77991202/error-calculating-shapley-values-using-iml</guid>
      <pubDate>Tue, 13 Feb 2024 22:29:02 GMT</pubDate>
    </item>
    <item>
      <title>Wandb：如何在高级图例部分显示分组平均值</title>
      <link>https://stackoverflow.com/questions/77858891/wandb-how-to-show-grouped-average-in-the-advanced-legend-section</link>
      <description><![CDATA[我正在努力记录我的种子机器学习训练的等待和偏差，我可以看到我所做的事情的良好可视化。
在高级图例部分我可以看到。
[[ ${mean} σ ${stddev} (${min}, ${max}) ]] ${run:displayName}

当我悬停时，[[ ${mean} σ ${stddev} (${min}, ${max}) ]] 部分可见。
如何将此值附加到如下所示的文本
[[ ${mean} σ ${stddev} (${min}, ${max}) ]] ${run:displayName} - ${mean} σ ${stddev}

感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/77858891/wandb-how-to-show-grouped-average-in-the-advanced-legend-section</guid>
      <pubDate>Mon, 22 Jan 2024 09:41:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 MLP 分类器，少数类精度、召回率、fscore 全部变为零</title>
      <link>https://stackoverflow.com/questions/75389106/minority-class-precision-recall-fscore-all-become-zero-with-mlp-classifier</link>
      <description><![CDATA[我使用 SkLearn 上提供的 MLP 分类器训练了我的模型。
我使用代码分割数据
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size=0.3、stratify=y、random_state=1)

X_train 长度 = 9405
y_train = 0: 7562, 1: 1843 的类别分布
X_测试长度 = 4032
y_test 的类别分布 = 0: 3242, 1: 790

MLP分类器的代码是
MLP = MLPClassifier(random_state=1,learning_rate =“constant”,learning_rate_init=0.3,momentum = 0.2)
MLP.fit(X_train, y_train)
R_y_pred = MLP.predict(X_test)
target_names = [&#39;否&#39;, &#39;是&#39;]
打印（分类报告（y_test，R_y_pred，target_names = target_names，zero_division = 0））

zero_division= 0 已包含在分类报告中，因为这是我之前的问题分类报告中少数类的准确率、召回率、F1 分数均为零值。我上一个问题的错误已得到纠正，但是我使用上述代码获得的分类报告似乎不正确。分类器未能将是类别（少数类别）分类，并将所有类别分类为无类别
分类报告如下所示
 精确召回率 f1-score 支持

            无 0.80 1.00 0.89 3242
            是 0.00 0.00 0.00 790

       精度 0.80 4032
      宏观平均 0.40 0.50 0.45 4032
   加权平均 0.65 0.80 0.72 4032

该问题仅发生在 SVM 和 MLP 分类器上。该模型通过随机森林和逻辑回归训练得很好。该数据集是经过标签编码的分类数据集。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/75389106/minority-class-precision-recall-fscore-all-become-zero-with-mlp-classifier</guid>
      <pubDate>Wed, 08 Feb 2023 16:52:13 GMT</pubDate>
    </item>
    <item>
      <title>机器学习准确性报告错误消息[重复]</title>
      <link>https://stackoverflow.com/questions/73603106/machine-learning-accuracy-report-error-message</link>
      <description><![CDATA[我有一个包含 200 个观察值的小样本。以下是我使用的代码。
y_test_pred = model.predict(X_test)
evaluate_nn(y_test, y_test_pred.round(), train=False)

我的准确率非常高。请参阅以下输出。
4/4 [================================] - 0s 2ms/步
测试结果：
=================================================
准确率：92.86%
_______________________________________________
分类报告：
           0.0 1.0 精度宏平均值加权平均值
精度 0.00 0.93 0.93 0.46 0.86
召回率 0.00 1.00 0.93 0.50 0.93
f1 分数 0.00 0.96 0.93 0.48 0.89
支持 7.00 91.00 0.93 98.00 98.00
_______________________________________________
混淆矩阵：
 [[ 0 7]
 [0 91]]

但是，我收到以下警告。
&lt;块引用&gt;
C:\Users\gaowe\anaconda3\lib\site-packages\sklearn\metrics_classification.py:1318: UndefinedMetricWarning: 精度和 F 分数定义不明确，在没有预测样本的标签中设置为 0.0。使用 zero_division 参数来控制此行为。
_warn_prf（平均值，修饰符，msg_start，len（结果））

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/73603106/machine-learning-accuracy-report-error-message</guid>
      <pubDate>Sun, 04 Sep 2022 22:04:28 GMT</pubDate>
    </item>
    <item>
      <title>如何计算训练数据和测试数据存储在两个不同 csv 文件中的模型的 F1 分数或准确度分数？ [复制]</title>
      <link>https://stackoverflow.com/questions/68736498/how-to-calculate-f1-score-or-accuracy-score-for-model-which-has-training-data-an</link>
      <description><![CDATA[我是机器学习领域的新手。我正在解决一个问题陈述来预测 IPL 比赛获胜者，其中给出了两个 csv 文件（训练数据和测试数据以两个单独的 csv 文件的形式）。
训练数据有大约 700 条记录，测试数据有 60 条记录。
testdf 中不存在目标变量（获胜者）
我尝试了随机森林分类器。下面是代码：
predictor_var=[&#39;team1&#39;,&#39;team2&#39;,&#39;city&#39;,&#39;venue&#39;,&#39;toss_decision&#39;,&#39;toss_winner&#39;]

结果_var=[&#39;获胜者&#39;]

从 sklearn.ensemble 导入 RandomForestClassifier

randomForest1 = RandomForestClassifier（n_estimators = 100）

randomForest1.fit(traindf[predictor_var],traindf[outcome_var])

pred=randomForest1.predict(testdf[predictor_var])

那么，我怎样才能获得 F1 分数，在提交上述预测时，我收到以下警告：
&lt;块引用&gt;
UndefinedMetricWarning：F 分数定义不明确，在没有预测样本的标签中设置为 0.0。
&#39;精度&#39;、&#39;预测&#39;、平均值、warn_for)
]]></description>
      <guid>https://stackoverflow.com/questions/68736498/how-to-calculate-f1-score-or-accuracy-score-for-model-which-has-training-data-an</guid>
      <pubDate>Wed, 11 Aug 2021 05:36:35 GMT</pubDate>
    </item>
    <item>
      <title>混淆矩阵中的模型精度为 0% [重复]</title>
      <link>https://stackoverflow.com/questions/58064454/model-precision-is-0-in-confusion-matrix</link>
      <description><![CDATA[我正在尝试使用 Python 中的逻辑回归来预测二元结果，我的分类报告显示我的模型对目标变量=0 的预测精度为 0%。它对我的目标变量的预测精度为 87%=1
从 sklearn.linear_model 导入 LogisticRegression
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入分类报告
从sklearn.metrics导入confusion_matrix

X=df[[&#39;RegDec&#39;, &#39;SchoolDiv&#39;, &#39;性别&#39;, &#39;荣誉&#39;, &#39;TestOptional&#39;, &#39;领土&#39;, &#39;学术索引&#39;,
     &#39;INSTAward&#39;、&#39;NEED&#39;、&#39;TOTAWD&#39;、&#39;ETHN3&#39;、&#39;IR_Total&#39;、&#39;pell&#39;]]
y= df [&#39;保留&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)


对数模型 = LogisticRegression()
logmodel.fit(X_train,y_train)

预测=logmodel.预测（X_test）
打印（分类报告（y_测试，预测））

为什么我的“0”精度是 0？这是输出
 精确召回率 f1-score 支持

           0 0.00 0.00 0.00 92
           1 0.87 1.00 0.93 614

    准确度 0.87706
   宏观平均 0.43 0.50 0.47 706
加权平均 0.76 0.87 0.81 706

confusion_matrix(y_test,predictions)#不预测0

数组([[ 0, 92],
       [ 0, 614]], dtype=int64)

我想知道是否有一些错误影响了我的结果。]]></description>
      <guid>https://stackoverflow.com/questions/58064454/model-precision-is-0-in-confusion-matrix</guid>
      <pubDate>Mon, 23 Sep 2019 14:16:03 GMT</pubDate>
    </item>
    <item>
      <title>UndefinedMetricWarning：召回率和 F 分数定义不明确，在没有真实样本的标签中设置为 0.0。 '召回'、'真实'、平均值、warn_for)</title>
      <link>https://stackoverflow.com/questions/48980313/undefinedmetricwarning-recall-and-f-score-are-ill-defined-and-being-set-to-0-0</link>
      <description><![CDATA[当我使用以下代码计算单类的 precision_recall_fscore_support 时（仅 1 ）
将 numpy 导入为 np
从 sklearn.metrics 导入 precision_recall_fscore_support

#制作数组
ytrue = np.array([&#39;1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;])
ypred = np.array([&#39;0&#39;, &#39;0&#39;, &#39;0&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;, &#39;1&#39;])

#只保留1个
y_true, y_pred = zip(*[[ytrue[i], ypred[i]] for i in range(len(ytrue)) if ytrue[i]==“1”])

#获取分数
precision_recall_fscore_support(y_true, y_pred,average=&#39;加权&#39;)

我收到以下警告：
UndefinedMetricWarning：召回率和 F 分数定义不明确，在没有真实样本的标签中设置为 0.0。
  &#39;召回&#39;、&#39;真实&#39;、平均值、warn_for)

和输出：
&lt;前&gt;&lt;代码&gt;（1.0、0.625、0.76923076923076927、无）

我找到了SO线程UndefinedMetricWarning：F-score 定义不明确，在没有预测样本的标签中设置为 0.0 具有类似的警告，但我认为它不适用于我的问题。
问题：我的输出结果是否有效，或者我应该关注警告消息吗？如果是这样，我的代码有什么问题以及如何修复？]]></description>
      <guid>https://stackoverflow.com/questions/48980313/undefinedmetricwarning-recall-and-f-score-are-ill-defined-and-being-set-to-0-0</guid>
      <pubDate>Mon, 26 Feb 2018 01:38:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit-learn 了解分类报告中的 UndefinedMetricWarning？ [复制]</title>
      <link>https://stackoverflow.com/questions/28144006/understanding-undefinedmetricwarning-in-classification-report-with-scikit-learn</link>
      <description><![CDATA[我有一个包含 5 个类别的文本分类任务，问题是我的精度很差，并且出现此警告，可能是由于数据不平衡造成的（我不确定）：
&lt;块引用&gt;
/usr/local/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771：UndefinedMetricWarning：精度定义不明确，在没有预测样本的标签中设置为 0.0。

我猜这个警告是由于数据聚集在 5 标签中而产生的。如何解决此警告以及如何增加分类报告的结果？我还尝试了使用以下超参数的网格搜索：
最佳参数设置：
    clf__C：0.1
    向量__max_df：0.25
    vect__ngram_range: (1, 1)
    vect__use_idf：正确

准确性：
0.456923076923

但是结果仍然很糟糕，有人可以帮助我使用 SVC 或其他模型来提高这个结果吗？]]></description>
      <guid>https://stackoverflow.com/questions/28144006/understanding-undefinedmetricwarning-in-classification-report-with-scikit-learn</guid>
      <pubDate>Mon, 26 Jan 2015 02:29:18 GMT</pubDate>
    </item>
    </channel>
</rss>