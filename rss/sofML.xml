<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 09 Aug 2024 15:18:17 GMT</lastBuildDate>
    <item>
      <title>无法设置张量：获取 STRING 类型的值，但输入 0 应为 FLOAT32 类型，名称：serving_default_args_0:0</title>
      <link>https://stackoverflow.com/questions/78853060/cannot-set-tensor-got-value-of-type-string-but-expected-type-float32-for-input</link>
      <description><![CDATA[当我尝试加载模型时，我收到一条错误消息
这是我的代码

interpreter = tf.lite.Interpreter(model_path=&quot;/content/colab_model.tflite&quot;)
interpreter.allocate_tensors()

# 获取输入和输出张量。
input_details = explainer.get_input_details()
output_details = explainer.get_output_details()
# 打印输入详细信息以了解其预期类型和形状
for input_detail in input_details:
print(f&quot;Name: {input_detail[&#39;name&#39;]}, Shape: {input_detail[&#39;shape&#39;]}, Dtype: {input_detail[&#39;dtype&#39;]}&quot;)

# 将用户 ID 转换为字符串
user_id_value = np.array([&#39;42&#39;], dtype=np.str_) 

# 将配方 ID 转换为字符串
recipe_id_values = np.array([&#39;49&#39;, &#39;66&#39;, &#39;62&#39;], dtype=np.str_)

# 使用字符串设置张量值
interpreter.set_tensor(input_details[0][&#39;index&#39;], np.array([recipe_id_values[0]])) 
interpreter.set_tensor(input_details[1][&#39;index&#39;], user_id_value)

# 调用模型
interpreter.invoke()

# 获取输出
output_data = interpretationer.get_tensor(output_details[0][&#39;index&#39;])
print(output_data)


错误
ValueError：无法设置张量：获得 STRING 类型的值，但输入 0 应为 FLOAT32 类型，名称：serving_default_args_0:0
当我尝试将其首先转换为浮点 32 时，出现错误
RuntimeError：不支持将浮点转换为字符串委托内核不支持已初始化节点号 19（TfLiteFlexDelegate）准备失败。委托内核未初始化节点号 19（TfLiteFlexDelegate）准备失败。委托内核未初始化节点号 19（TfLiteFlexDelegate）准备失败。]]></description>
      <guid>https://stackoverflow.com/questions/78853060/cannot-set-tensor-got-value-of-type-string-but-expected-type-float32-for-input</guid>
      <pubDate>Fri, 09 Aug 2024 13:30:18 GMT</pubDate>
    </item>
    <item>
      <title>集成识别手绘形状并实时重绘的功能</title>
      <link>https://stackoverflow.com/questions/78852946/integrate-a-feature-to-recognize-hand-drawn-shapes-and-redraw-it-in-real-time</link>
      <description><![CDATA[我正在构建一个项目，它可以跟踪我的手指运动并根据我的运动在屏幕上绘图。为此，我使用了 mediaPipe Hands 解决方案。我想集成一个功能来识别圆形、矩形等形状，并以理想的形式重新绘制它。
（当然是视频流）
我实现了一个功能来识别使用 OpenCV 在屏幕上绘制的形状。我尝试在绘图模式下捕获手指跟踪的点，并使用这些点来检测所绘制的形状是圆形还是矩形。我期望它在完成后准确识别形状。然而，实际发生的是，一旦我进入绘图模式，系统就开始将我的手指检测为圆形，并在手指移动到的每个点周围绘制一个圆圈。
#############
def understand_shape(points):
if len(points) &lt; 5：
return None

# 计算点的边界框
x_coords, y_coords = zip(*points)
min_x, max_x = min(x_coords), max(x_coords)
min_y, max_y = min(y_coords), max(y_coords)
width, height = max_x - min_x, max_y - min_y

# 使用半径方差检查圆
center_x, center_y = np.mean(x_coords), np.mean(y_coords)
radii = [distance.euclidean((x, y), (center_x, center_y)) for x, y in points]
mean_radius = np.mean(radii)
radius_variance = np.var(radii)

if radius_variance &lt; 1000：# 调整阈值以提高准确度
return (&quot;circle&quot;, (int(center_x), int(center_y), int(mean_radius)))

# 使用纵横比检查矩形
if 0.9 &lt; width / height &lt; 1.1：# 允许正方形略有偏差
if all(min_x &lt;= x &lt;= max_x and min_y &lt;= y &lt;= max_y for x, y in points):
return (&quot;rectangle&quot;, (min_x, min_y, max_x, max_y))

return None

def draw_shape(shape, imgCanvas):
if shape[0] == &quot;circle&quot;:
_, (center_x, center_y, radius) = shape
cv2.circle(imgCanvas, (center_x, center_y), radius, (0, 0, 255), 2)
elif shape[0] == &quot;rectangle&quot;:
_, (min_x, min_y, max_x, max_y) = shape
cv2.rectangle(imgCanvas, (min_x, min_y), (max_x, max_y), (0, 0, 255), 2)
#############
]]></description>
      <guid>https://stackoverflow.com/questions/78852946/integrate-a-feature-to-recognize-hand-drawn-shapes-and-redraw-it-in-real-time</guid>
      <pubDate>Fri, 09 Aug 2024 13:06:37 GMT</pubDate>
    </item>
    <item>
      <title>机器学习/统计学：如何找到参数之间的因果关系？[关闭]</title>
      <link>https://stackoverflow.com/questions/78852790/machine-learning-statistics-how-to-find-causal-relationship-between-parameter</link>
      <description><![CDATA[我的公司生产嵌入式设备，我们从这些设备中收集了一堆参数（几百个），保存在 CSV 文件中。现在我想找到一个重要的错误参数和所有其他参数之间的因果关系。到目前为止，我所做的就是训练一个 SVM 模型，以重要的错误参数为目标，其余参数为特征，然后找到对目标参数贡献最大的特征。我对结果非常满意，因为贡献最大的标签实际上是有意义的，并且该模型在测试数据上的准确率超过了 90%。
但我不知道如何从这些结果继续找到特定事件中的贡献参数。例如，如果触发了这个错误参数 - 我如何使用我训练过的模型知道哪个参数是贡献最大的参数（假设所有其他参数的上下文）？目前，模型只能告诉我触发错误参数的可能性 - 但不能反过来。
我希望我在这里描述的是有意义的。抱歉，我的英语不是我的母语。]]></description>
      <guid>https://stackoverflow.com/questions/78852790/machine-learning-statistics-how-to-find-causal-relationship-between-parameter</guid>
      <pubDate>Fri, 09 Aug 2024 12:31:24 GMT</pubDate>
    </item>
    <item>
      <title>在浏览器/API 中通过 RTSP 流实时处理低延迟视频的方法</title>
      <link>https://stackoverflow.com/questions/78852698/ways-for-real-time-processing-of-video-via-rtsp-stream-in-browser-api-with-low-l</link>
      <description><![CDATA[对于 RTSP 流，我想使用基于 Python 的模型来处理它，问题是延迟，对于实时处理，没有太多经济上可行的选择，这些选择由于延迟问题而受到限制。
独特而有趣的方式是使用 roboflow.js 进行浏览器推理，但将 RTSP 转换为另一种格式，以便可以使用该流，这给我带来了另一个问题。
处理结果的整个流需要在 UI 上显示
鉴于需要使用 Python 实用程序实时处理 RTSP 流，最佳选择是什么？
我已经通过命令行工具获取 RTSP 流然后转换为 HLS 格式，但流是在 10 秒内创建的，除了处理（鉴于我已经有一个模型），它可能需要更长的时间，那么有没有更好的方法可以处理 RTSP 并实时处理？]]></description>
      <guid>https://stackoverflow.com/questions/78852698/ways-for-real-time-processing-of-video-via-rtsp-stream-in-browser-api-with-low-l</guid>
      <pubDate>Fri, 09 Aug 2024 12:12:35 GMT</pubDate>
    </item>
    <item>
      <title>每秒 2500 帧的视频处理的硬件要求</title>
      <link>https://stackoverflow.com/questions/78852250/hardware-requirement-for-video-processing-of-2500-frames-per-second</link>
      <description><![CDATA[我有 50 个摄像头，每个摄像头都提供 1080p 分辨率的馈送，我正在使用 YOLOv8n 模型在这些摄像头上应用视频分析和计算机视觉技术。为了满足我的要求，我需要每秒处理大约 2,500 帧。
我在配备 32GB RAM 的 Rtx3090 GPU 上进行了测试，我能够每秒处理 200 帧。
您能否建议实现此目标所需的适​​当硬件和 GPU 设置？此外，是否有经济高效的替代方案，例如使用多个 Jetson AGX Orin 设备或选择基于云的解决方案？]]></description>
      <guid>https://stackoverflow.com/questions/78852250/hardware-requirement-for-video-processing-of-2500-frames-per-second</guid>
      <pubDate>Fri, 09 Aug 2024 10:24:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 device_map 选择可用的 GPU 设备</title>
      <link>https://stackoverflow.com/questions/78852192/choose-available-gpu-devices-with-device-map</link>
      <description><![CDATA[from transformers import AutoTokenizer, AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
model_id,
torch_dtype=torch.bfloat16,
device_map=&quot;cuda:3&quot;,
)

服务器上有很多 GPU，但我只能使用其中两个。我应该如何配置 device_map（或其他参数）才能让模型在两个 GPU 上运行？]]></description>
      <guid>https://stackoverflow.com/questions/78852192/choose-available-gpu-devices-with-device-map</guid>
      <pubDate>Fri, 09 Aug 2024 10:04:34 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Android Studio 中创建情绪识别应用程序[关闭]</title>
      <link>https://stackoverflow.com/questions/78851919/how-to-create-emotion-recognition-app-in-android-studio</link>
      <description><![CDATA[我想创建一个基本上可以检测人类情绪的应用程序，我可以使用 jupyter 笔记本来验证它，但是当我想做同样的事情时，我无法做到，因为无法下载 opencv、mlkit 和其他不同的库。
如何在 android studio 中安装这些库以及如何在 android studio 中运行此代码]]></description>
      <guid>https://stackoverflow.com/questions/78851919/how-to-create-emotion-recognition-app-in-android-studio</guid>
      <pubDate>Fri, 09 Aug 2024 08:56:02 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Tensorflow / Python 中修剪这个神经网络？</title>
      <link>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-in-tensorflow-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-in-tensorflow-python</guid>
      <pubDate>Fri, 09 Aug 2024 07:50:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的精度突然降到0.5？</title>
      <link>https://stackoverflow.com/questions/78850531/why-does-my-precision-suddenly-drop-to-0-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78850531/why-does-my-precision-suddenly-drop-to-0-5</guid>
      <pubDate>Thu, 08 Aug 2024 21:43:15 GMT</pubDate>
    </item>
    <item>
      <title>如何在 sklearn 管道中实现反向序数编码并避免 NotFittedError？</title>
      <link>https://stackoverflow.com/questions/78848893/how-to-implement-reverse-ordinal-encoding-in-a-sklearn-pipeline-and-avoid-a-notf</link>
      <description><![CDATA[我正在尝试清理一个数据集，该数据集包含来自不同特征（包括数字和分类）的大量缺失值。我的想法如下：

使用 OrdinalEncoder 只保留数值并将缺失值保留为 NaN（不能使用 OneHotEncoder，因为它会创建新列，这些列为 NaN）
使用 KNNImputer 估算缺失值
反转编码，因为没有合理的理由在类别中绘制某种顺序

这是我目前的代码：
import pandas as pd
import numpy as np
from sklearn import set_config
set_config(transform_output=&quot;pandas&quot;)
from sklearn.preprocessing import OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute 导入 KNNImputer
从 sklearn.base 导入 BaseEstimator、TransformerMixin

class RoundingToIntegerTransformer(BaseEstimator、TransformerMixin):
def fit(self, X, y=None):
return self

def transform(self, X):
return np.round(X) 

class ReverseOrdinalEncoder(BaseEstimator、TransformerMixin):
def __init__(self,coder_name, categorical_columns):
self.encoder_name =coder_name
self.categorical_columns = categorical_columns

def fit(self, X, y=None):
return self

def transform(self, X, y=None):
X_ = X.copy()
coder = self.encoder_name
X_categorical = X_[categorical_columns] 
X_categorical =编码器.逆变换（X_categorical）
X_[categorical_columns] = X_categorical
返回 X_

数据 = pd.DataFrame({
&#39;类别 1&#39;：[&#39;a&#39;，&#39;b&#39;，&#39;a&#39;，np.nan，&#39;c&#39;，&#39;b&#39;]，
&#39;类别 2&#39;：[&#39;x&#39;，&#39;y&#39;，&#39;x&#39;，&#39;z&#39;，np.nan，&#39;y&#39;]，
&#39;数值 1&#39;：[1.1，np.nan，3.3，4.4，5.5，np.nan]，
&#39;数值 2&#39;：[np.nan，2.2，np.nan，4.4，5.5，6.6]
})

数值列 = data.select_dtypes(include=&#39;number&#39;).columns.tolist()
categorical_columns = data.select_dtypes(include=&#39;object&#39;).columns.tolist()

ordinal_encoder = OrdinalEncoder(encoded_missing_value=np.nan)

first_encoder = ColumnTransformer(transformers=[
(&#39;ordinal_cat&#39;, ordinal_encoder, categorical_columns)
],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False)

imputer = Pipeline([
(&#39;KNN_imputing&#39;, KNNImputer()),
(&#39;rounding&#39;, ColumnTransformer(transformers=[(&#39;round_cat&#39;, RoundingToIntegerTransformer() , categorical_columns)],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False))
])

reverse_encoder = ReverseOrdinalEncoder(
coder_name=first_encoder.transformers[0][1], 
categorical_columns=categorical_columns
)

preprocessor = Pipeline([
(&#39;encoding&#39;, first_encoder),
(&#39;imputing&#39;, imputer),
(&#39;decoding&#39;, reverse_encoder)
])

我尝试了一段时间，但从未成功，我总是收到以下错误：
&gt;NotFittedError：此 OrdinalEncoder 实例尚未安装。使用此估算器之前，请使用适当的参数调用“fit”。

我理解这个错误，但我认为由于序数编码器在管道中出现得早，因此在反向编码器中使用时它会被安装。有没有什么办法可以实现这个功能？]]></description>
      <guid>https://stackoverflow.com/questions/78848893/how-to-implement-reverse-ordinal-encoding-in-a-sklearn-pipeline-and-avoid-a-notf</guid>
      <pubDate>Thu, 08 Aug 2024 14:07:04 GMT</pubDate>
    </item>
    <item>
      <title>在 RAG 中处理没有 LLMS 的问候类型问题</title>
      <link>https://stackoverflow.com/questions/78843382/handling-greet-type-of-questions-without-llm-in-rag</link>
      <description><![CDATA[我正在为一个聊天机器人实现一个检索增强生成 (RAG) 系统，该系统可以处理各种用户查询。虽然 RAG 的主要设计目的是通过检索相关文档并使用语言模型 (LLM) 生成响应来提供信息丰富的响应，但我想处理某些类型的查询，例如问候和礼貌交流，而无需借助 LLM 来提高效率和控制力。
具体来说，我想管理问候类型的问题，例如“你好”、“你好吗？”、 “早上好”等。这些问题通常是公式化的，不需要像更复杂的问题那样深入理解上下文。依靠 LLM 来处理这些问题可能会效率低下且过度。
是否有可能在没有 LLM 的情况下创建类似聊天机器人的问候交流系统？]]></description>
      <guid>https://stackoverflow.com/questions/78843382/handling-greet-type-of-questions-without-llm-in-rag</guid>
      <pubDate>Wed, 07 Aug 2024 11:17:51 GMT</pubDate>
    </item>
    <item>
      <title>如何继续创建视频描述模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</link>
      <description><![CDATA[我一直在尝试制作一个可以实时将视频转换为文本的应用程序。这意味着您可以将实时视频转换为文本。
首先，我尝试仅使用 gpt api，但当然速度很慢，而且远远达不到实时。然后我想到使用对象检测模型和 gpt 来生成视频描述，但问题是它非常不准确，因为只检测到了对象，但错过了背景或动作，我尝试过跟踪以及 yolo 的姿势模型，但这似乎也不起作用。那么，有什么建议可能有效吗？]]></description>
      <guid>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</guid>
      <pubDate>Wed, 07 Aug 2024 07:34:13 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 和 Opacus 用于差异隐私</title>
      <link>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</link>
      <description><![CDATA[在使用 Jupyter Notebook（可从此处获取）测试来自 TensorFlow 网站的示例代码时，我遇到了错误。您可以在此处找到我关于该错误的 SO 问题。
因此，我决定使用 PyTorch、Opacus 和 PySyft 为相同功能编写等效实现。然而，不幸的是，我又遇到了另一个错误。
下面是实现与 TensorFlow 网站中的示例代码相同功能的代码，但使用 PyTorch 和 Opacus 和 PySyft，以及错误消息。
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from opacus import PrivacyEngine

# 定义一个简单的模型
class SimpleCNN(nn.Module):
def __init__(self):
super(SimpleCNN, self).__init__()
self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
self.fc1 = nn.Linear(32*26*26, 10)

def forward(self, x):
x = torch.relu(self.conv1(x))
x = x.view(-1, 32*26*26)
x = self.fc1(x)
return torch.log_softmax(x, dim=1)

# 数据加载器
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = datasets.MNIST(&#39;.&#39;, train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 初始化模型、优化器和损失函数
model = SimpleCNN()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.NLLLoss()

# 初始化 PrivacyEngine
privacy_engine = PrivacyEngine(
model,
batch_size=64,
sample_size=len(train_loader.dataset),
epochs=1,
max_grad_norm=1.0,
)

privacy_engine.attach(optimizer)

# 训练循环
model.train()
for epoch in range(1):
for data, target in train_loader:
optimizer.zero_grad()
output = model(data)
loss = criterion(output, target)
loss.backward()
optimizer.step()

# 打印隐私统计数据
epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(1e-5)
print(f&quot;Epsilon: {epsilon}, Delta: 1e-5&quot;)

错误：
-------------------------------------------------------------------------------
TypeError Traceback (最近一次调用最后一次)
Cell In[1]，第 32 行
29 criterion = nn.NLLLoss()
31 # 初始化 PrivacyEngine
---&gt; 32 privacy_engine = PrivacyEngine(
33 model,
34 batch_size=64,
35 sample_size=len(train_loader.dataset),
36 epochs=1,
37 max_grad_norm=1.0,
38 )
40 privacy_engine.attach(optimizer)
42 # 训练循环

TypeError: PrivacyEngine.__init__() 获得了意外的关键字参数“batch_size”
]]></description>
      <guid>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</guid>
      <pubDate>Tue, 06 Aug 2024 13:17:08 GMT</pubDate>
    </item>
    <item>
      <title>如果训练数据集中的正样本多于负样本，XGBoost 的 scale_pos_weight 是否可以正确平衡正样本？</title>
      <link>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我相信 scale_pos_weight 会是一种更好的方法。
是否可以安全地假设，由于比率小于 1，它仍将正确平衡类别？特异性在我的研究中很重要，但我们的主要目标集中在召回率、精确度和 F1 分数上。此设置是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>如何处理预测标签比例很重要的多标签分类问题？</title>
      <link>https://stackoverflow.com/questions/62597159/how-to-approach-a-multilabel-classification-problem-where-the-proportions-of-the</link>
      <description><![CDATA[我最初的任务是根据基因表达模式对各种细胞类型（类别）进行分类，而这个问题只是涉及从多个类别中预测一个标签。这很容易做到，因为我可以分配一个独热编码向量并训练神经网络。
现在的新问题是样本中可能混合了各种细胞（因此是多标签问题）。新的挑战不仅是检测多个标签，还要检测每个标签的比例。例如，如果总共有 3 个 cell_types，并且样本包含 2 个 cell_type_1、1 个 cell_type_2 和 1 个 cell_type_3，则分类器的输出应为 [0.50, 0.25, 0.25]，而不是 [1, 1, 1]。
从我所做的简短研究来看，有多种方法可以进行二元分类，但比例分类的方法并不多。我读过关于不同准确度函数的文章，例如精确匹配率和汉明损失，这些函数似乎对这类问题很有希望。还了解到最后一层的激活函数应该是 S 型函数，而不是 Softmax，因为 Softmax 会分配一个概率，而这个属性会削弱其识别多个标签的能力。我想知道，由于比例很重要，这是否会对我有利？
我想首先了解一下这个问题是否可能（我习惯于做分类），针对这个问题推荐的损失/准确度函数类型，各种架构（如果以前已经做得很好），以及任何其他建议/资源。此外，如果这可能有助于提供更多背景信息，我正在使用 R 中的 Keras。]]></description>
      <guid>https://stackoverflow.com/questions/62597159/how-to-approach-a-multilabel-classification-problem-where-the-proportions-of-the</guid>
      <pubDate>Fri, 26 Jun 2020 14:40:54 GMT</pubDate>
    </item>
    </channel>
</rss>