<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 09:19:18 GMT</lastBuildDate>
    <item>
      <title>调用 BroadcastTo.call() 时遇到异常</title>
      <link>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</guid>
      <pubDate>Sun, 27 Oct 2024 19:29:36 GMT</pubDate>
    </item>
    <item>
      <title>绝对、相对、旋转和学习位置编码之间的区别[关闭]</title>
      <link>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</link>
      <description><![CDATA[位置编码（绝对、相对、旋转）和学习到的位置编码之间有什么区别？
我了解绝对、相对和旋转编码之间的区别，但我无法识别这些编码和学习到的位置编码之间的任何区别。]]></description>
      <guid>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</guid>
      <pubDate>Sun, 27 Oct 2024 16:39:04 GMT</pubDate>
    </item>
    <item>
      <title>删除所有人口后，Python NEAT 给出错误</title>
      <link>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</guid>
      <pubDate>Sun, 27 Oct 2024 16:27:23 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的负损失没有减少</title>
      <link>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</guid>
      <pubDate>Sun, 27 Oct 2024 16:07:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么卷积层的输出形状不会跨通道相乘？</title>
      <link>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</link>
      <description><![CDATA[# 第一个卷积层：输入通道 = 1，输出通道 = 32，内核大小 = 5x5，填充 = 2（相同）
self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)
# 第一个池化层：最大池化，内核大小 = 2x2，步长 = 2
self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

# 第二个卷积层：输入通道 = 32，输出通道 = 64，内核大小 = 5x5，填充 = 2（相同）
self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
# 第二个池化层：最大池化，内核大小 = 2x2， stride = 2
self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

为什么第二个卷积层后的输出不是
14 * 14 * 32 * 64？对于32通道的输入，每个卷积核只作用于一个通道，因此会产生64种不同的结果。难道不应该将32个通道相乘吗？
我得到的答案是：对于输入的每个14 * 14位置，5532核与5532输入区域进行点积将产生14*14的单通道输出。核大小不是5 * 5吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</guid>
      <pubDate>Sun, 27 Oct 2024 14:14:47 GMT</pubDate>
    </item>
    <item>
      <title>输入图像与 TensorFlow 模型输入形状不兼容</title>
      <link>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</link>
      <description><![CDATA[我正在构建一个模型，我想测试它的性能，因此我导入了一个本地文件并加载它，并尝试使用以下代码预测它的标签：
from tensorflow.preprocessing import image
# tensorlfow 等的其他导入。

#...

# 示例图像
img_path = &quot;./Model/data/brain/train/Glioma/images/gg (2).jpg&quot;
img = image.load_img(img_path,target_size=(256,256))
arr = image.img_to_array(img)
t_img = tf.convert_to_tensor(arr)
print(t_img.shape) # 返回 (256,256,3)
# 客户端测试
client = Client(&quot;brain&quot;) # 自定义类。包含模型：顺序（已编译和训练）
client.predict(img=t_img) # 调用 self.model.predict(t_img)

但是我收到以下错误：
输入 Tensor(&quot;data:0&quot;, shape=(32, 256, 3), dtype=float32) 的输入形状无效。预期形状 (None, 256, 256, 3)，但输入具有不兼容的形状 (32, 256, 3)

我在训练模型中有一个输入层，其 input_shape=[256,256,3]（来自图像宽度、高度和 rgb 值）
您能帮助我理解问题并解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</guid>
      <pubDate>Sun, 27 Oct 2024 11:57:01 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的 Tensorflow predict() 时间序列对齐</title>
      <link>https://stackoverflow.com/questions/79106002/tensorflow-predict-timeseries-alignment-in-python</link>
      <description><![CDATA[假设我在 Tensorflow 中创建一个顺序输入 LSTM，如下所示：
def Sequential_Input_LSTM(df, input_sequence):
df_np = df.to_numpy()
X = []
y = []

for i in range(len(df_np) - input_sequence):
row = [a for a in df_np[i:i + input_sequence]]
X.append(row)
label = df_np[i + input_sequence]
y.append(label)

return np.array(X), np.array(y)

X, y = Sequential_Input_LSTM(df_data , 10) # pandas DataFrame df_data 包含我们的数据

在此示例中，我将数据切片X（输入向量）和 y（标签），例如前 10 个值（序列长度）用作 X，第 11 个值用作第一个 y。然后，将 10 个值的窗口向右移动一步（再移动一个时间步），我们再次为 X 取 10 个值，并将第二行之后的值作为下一个 y，依此类推。
然后假设我将 X 的一部分作为我的 X_test，并使用 LSTM model 进行时间序列预测，例如 predictions = model.predict(X_test)。
当我实际尝试此操作并绘制 predict(X_test) 的结果时，它看起来像 y 数组，并且预测结果是同步的，无需进一步调整。我预计在将预测数组与标签一起绘制时，我必须手动将预测数组向右移动 10 个时间步，因为我无法解释预测的前 10 个时间戳来自哪里。
由于模型尚未收到 10 个输入序列值，X_test 的前 10 个时间步的预测来自哪里？Tensorflow 是否使用 X_test 中的最后几个时间步来创建前 10 个值的预测，还是一开始的预测只是纯粹的猜测？]]></description>
      <guid>https://stackoverflow.com/questions/79106002/tensorflow-predict-timeseries-alignment-in-python</guid>
      <pubDate>Sat, 19 Oct 2024 21:37:05 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习预训练模型</title>
      <link>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</link>
      <description><![CDATA[我在 Google Colab 上拟合迁移学习模型。但是，我在代码中遇到了一条警告消息
Epoch 1/30
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: 
UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。
请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()

在第一个 epoch 之后，我收到以下错误：
----------------------------------------------------------------------------------------
KeyboardInterrupt Traceback（最近一次调用最后一次）
&lt;ipython-input-23-962a870d4412&gt; in &lt;cell line: 16&gt;()
14 # 拟合模型
15 # 运行单元。执行需要一些时间
---&gt; 16 training_history = model_efficientnet.fit(
17 training_set,
18 validation_data=validate_set,

我已经成功地拟合了其他六个迁移学习模型，没有任何问题，它们的准确率令人满意。
如何解决这个问题？
我想获得训练准确率和验证准确率]]></description>
      <guid>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</guid>
      <pubDate>Thu, 15 Aug 2024 14:49:45 GMT</pubDate>
    </item>
    <item>
      <title>通过电子邮件对话训练 GPT-3</title>
      <link>https://stackoverflow.com/questions/75783524/train-gpt-3-on-email-conversations</link>
      <description><![CDATA[我必须在电子邮件数据上训练 GPT-3，以便支持团队可以从聊天机器人那里快速获得客户之前提出的问题的答案。客户和支持团队之间有电子邮件对话（客户 1 提出问题，支持团队回答，客户 1 提出另一个问题……）。我必须：

过滤重要的对话并仅向 GPT-3 提供它们。
准备并将它们转换为正确的格式，以便我可以训练模型。

关于如何实现这些步骤以及是否使用微调或嵌入，有什么想法吗？
GPT-3 必须将问题与支持团队给出的答案联系起来。]]></description>
      <guid>https://stackoverflow.com/questions/75783524/train-gpt-3-on-email-conversations</guid>
      <pubDate>Sun, 19 Mar 2023 16:44:07 GMT</pubDate>
    </item>
    <item>
      <title>Tensor Flow TFX 管道中的图像处理</title>
      <link>https://stackoverflow.com/questions/72166920/image-processing-in-tensor-flow-tfx-pipelines</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/72166920/image-processing-in-tensor-flow-tfx-pipelines</guid>
      <pubDate>Mon, 09 May 2022 04:10:29 GMT</pubDate>
    </item>
    <item>
      <title>如何计算召回率、准确率和 f 度量？</title>
      <link>https://stackoverflow.com/questions/56608300/how-to-calculate-recall-precision-and-f-measure</link>
      <description><![CDATA[我正在做一个情绪分析项目。
我需要计算召回率、准确率和 f 度量，但我不知道我的数据集的语法，如下所示：
#训练数据格式，包含文本的单词及其权重和文本的类标签

train_set = [
({&#39;adam&#39;: 0.05,&#39;is&#39;: 0.0, &#39;a&#39;: 0.0, &#39;good&#39;: 0.02, &#39;man&#39;: 0.0}, 1),
({&#39;eve&#39;: 0.0, &#39;is&#39;: 0.0, &#39;a&#39;: 0.0,&#39;good&#39;: 0.02,&#39;woman&#39;: 0.0}, 1),
({&#39;adam&#39;: 0.05, &#39;is&#39;: 0.0, &#39;evil&#39;: 0.0}, 0)]

#0 或 1 表示类标签

#测试数据与训练数据相同

这是我当前的代码
from nltk.classify import apply_features

def naivebyse(finaltfidfVector):
train_set = []
j = 0
for vector in finaltfidfVector:
if j &lt; 2100: # 取 70% 的数据进行训练
train_set.append(vector)
j += 1
else:
break

test_set = []
j = 0
for vector in finaltfidfVector:
if j &lt; 3000 和 j &gt;= 2100：# 测试的 30%
test_set.append(vector)
if j&gt;= 3000:
break
j += 1

classifier = nltk.NaiveBayesClassifier.train(train_set)
print(&quot;讽刺分类器的准确率：&quot;, 
(nltk.classify.accuracy(classifier, test_set)*100))
refsets = collections.defaultdict(set)
testsets = collections.defaultdict(set)

for i, (feats, label) in enumerate(test_set):
refsets[label].add(i)
perceived = classifier.classify(feats)
testsets[observed].add(i)

print(&quot;准确率百分比：&quot; , nltk.metrics.precision(refsets[&#39;1&#39;], 
testsets[&#39;1&#39;])*100)
print(&quot;Recall Percentage : &quot;, nltk.metrics.recall(refsets[&#39;1&#39;], 
testsets[&#39;1&#39;])*100)

异常
Tkinter 回调中的异常
无法重新分配 20234 字节

有人可以提供一些关于如何执行任务的提示吗？]]></description>
      <guid>https://stackoverflow.com/questions/56608300/how-to-calculate-recall-precision-and-f-measure</guid>
      <pubDate>Sat, 15 Jun 2019 07:25:35 GMT</pubDate>
    </item>
    <item>
      <title>深度强化学习 - 如何处理动作空间中的边界[关闭]</title>
      <link>https://stackoverflow.com/questions/51127979/deep-reinforcement-learning-how-to-deal-with-boundaries-in-action-space</link>
      <description><![CDATA[我构建了一个自定义强化学习环境和代理，它类似于迷宫游戏。
在迷宫中有 5 种可能的动作：上、下、左、右和停留。如果被阻挡，例如代理无法上去，那么人们如何设计环境和代理来模拟这种情况？
具体来说，代理处于当前状态s0，根据定义，采取下、左、右动作将使状态更改为其他值并立即获得奖励（如果在出口则为&gt;0）。一种可能的方法是，当采取上动作时，状态将保持在s0，奖励将是一个很大的负数。理想情况下，代理将学习这一点，并且永远不会再在这个状态下上。 
但是，我的代理似乎没有学到这一点。相反，它仍然向上。另一种方法是对代理和环境进行硬编码，使代理在s0时无法执行操作向上，我能想到的是：

当某些状态下不允许向上时，我们查看不同操作的Q值
选择除向上之外具有最大Q值的操作
因此，代理永远不会执行无效操作

我想问的是上述方法是否可行？会不会有什么与此相关的问题？或者有没有更好的设计来处理边界和无效操作？]]></description>
      <guid>https://stackoverflow.com/questions/51127979/deep-reinforcement-learning-how-to-deal-with-boundaries-in-action-space</guid>
      <pubDate>Mon, 02 Jul 2018 00:35:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 scikit learn 计算多类别情况的精确度、召回率、准确度和 f1 分数？</title>
      <link>https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case</guid>
      <pubDate>Wed, 15 Jul 2015 04:17:36 GMT</pubDate>
    </item>
    <item>
      <title>QLearning 和永无止境的剧集</title>
      <link>https://stackoverflow.com/questions/1836731/qlearning-and-never-ending-episodes</link>
      <description><![CDATA[假设我们有一个 (x,y) 平面，机器人可以在其中移动。现在我们将世界的中心定义为目标状态，这意味着一旦机器人达到该状态，我们将给予它 100 的奖励。
现在，假设有 4 个状态（我将其称为 A、B、C、D）可以导致目标状态。
第一次处于 A 并进入目标状态时，我们将按如下方式更新 QValues 表：
Q(state = A, action = going to goal state) = 100 + 0

可能会发生以下两种情况之一。我可以在这里结束这一集，然后开始另一个集，让机器人再次找到目标状态，或者我可以继续探索世界，即使我找到了目标状态。如果我尝试这样做，我会看到一个问题。如果我处于目标状态并返回到状态 A，它的 Qvalue 将如下所示：
Q(state = goalState, action = going to A) = 0 + gamma * 100

现在，如果我尝试再次从 A 转到目标状态：
Q(state = A, action = going to goal state) = 100 + gamma * (gamma * 100)

这意味着如果我继续这样做，因为 0 &lt;= gamma &lt;= 0，两个 qValues 都会永远上升。
这是 QLearning 的预期行为吗？我做错了什么吗？如果这是预期行为，这不会导致问题吗？我知道从概率上讲，所有 4 个状态（A、B、C 和 D）都会以相同的速率增长，但即便如此，让它们永远增长也让我有点烦。
允许代理在找到目标后继续探索的想法与代理距离目标状态越近，就越有可能处于可以立即更新的状态有关。]]></description>
      <guid>https://stackoverflow.com/questions/1836731/qlearning-and-never-ending-episodes</guid>
      <pubDate>Wed, 02 Dec 2009 23:53:13 GMT</pubDate>
    </item>
    <item>
      <title>强化学习的良好实现？[关闭]</title>
      <link>https://stackoverflow.com/questions/740389/good-implementations-of-reinforcement-learning</link>
      <description><![CDATA[对于一个人工智能项目，我需要实现一个强化学习算法，该算法可以打败一个简单的俄罗斯方块游戏。该游戏是用 Java 编写的，我们有源代码。我知道强化学习理论的基础知识，但想知道 SO 社区中是否有人有这方面的经验。

对于在俄罗斯方块游戏中实施强化学习，您推荐的阅读材料是什么？
是否有值得一看的优秀开源项目可以完成类似的事情？

越具体越好，但欢迎提供有关该主题的一般资源。
跟进：
这是我为未来的学生提供的解决方案（代码和写作）：
论文 / 代码]]></description>
      <guid>https://stackoverflow.com/questions/740389/good-implementations-of-reinforcement-learning</guid>
      <pubDate>Sat, 11 Apr 2009 16:32:19 GMT</pubDate>
    </item>
    </channel>
</rss>