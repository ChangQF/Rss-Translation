<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 03 Jun 2024 09:16:15 GMT</lastBuildDate>
    <item>
      <title>如何开发根据文本提示生成网站模板的人工智能模型？</title>
      <link>https://stackoverflow.com/questions/78569248/how-to-develop-an-ai-model-for-generating-website-templates-from-text-prompts</link>
      <description><![CDATA[我正在开展一个项目，开发一个可以根据用户提供的文本提示生成网站模板的 AI 模型。该模型应该能够解释所需功能、配色方案、页面数量和动态元素等详细信息。
我正在寻找以下方面的指导：

技术堆栈：
哪些 AI 框架和库最适合此任务（例如 TensorFlow、PyTorch）？
哪些自然语言处理 (NLP) 模型可以有效理解和解析文本提示（例如 GPT-4、BERT）？
生成的模板应与哪些 Web 开发技术兼容（例如 HTML、CSS、JavaScript、React）？
基础设施要求：
训练和部署此类 AI 模型的推荐硬件和软件要求是什么？
是否有任何云平台提供 AI 模型训练和网络托管的集成解决方案？
开发工作流程：
应如何训练 AI 模型以准确地将文本提示转换为网页设计规范？
哪些数据集对于训练模型以理解网页设计概念和用户偏好有用？
集成和部署：
如何将模型集成到用户友好的界面中，以便非技术用户生成网站模板？
确保生成的网站响应迅速、可访问且符合现代网络标准的最佳实践是什么？
非常感谢任何见解或建议。谢谢！
]]></description>
      <guid>https://stackoverflow.com/questions/78569248/how-to-develop-an-ai-model-for-generating-website-templates-from-text-prompts</guid>
      <pubDate>Mon, 03 Jun 2024 08:46:20 GMT</pubDate>
    </item>
    <item>
      <title>姿势估计等待检测</title>
      <link>https://stackoverflow.com/questions/78569025/pose-estimation-waiting-detect</link>
      <description><![CDATA[如何使用 mediapipe 姿势估计确定某人是否正在等待？
在 Mediapipe 姿势估计部分，
转换为图像 RGB 并取特定点 (4,7,10,13)，取 X 和 Y 坐标（所有点的坐标）。]]></description>
      <guid>https://stackoverflow.com/questions/78569025/pose-estimation-waiting-detect</guid>
      <pubDate>Mon, 03 Jun 2024 07:50:28 GMT</pubDate>
    </item>
    <item>
      <title>用于聊天中问答识别的印地语 NLP 模型</title>
      <link>https://stackoverflow.com/questions/78568815/hindi-nlp-model-for-question-and-answer-identification-in-chats</link>
      <description><![CDATA[我正在开展一个自然语言处理项目，涉及分析印地语聊天数据。具体来说，我需要在聊天记录中识别问题及其对应的答案。
是否有任何预先训练过的印地语 NLP 模型或库可以有效地处理此任务？理想情况下，我正在寻找一种解决方案，可以：
检测句子并将其分类为问题或答案。
识别上下文并将问题与各自的答案配对。
任何有关模型、库或方法的建议都将不胜感激。谢谢！
我尝试了各种模型，但没有一个适合。]]></description>
      <guid>https://stackoverflow.com/questions/78568815/hindi-nlp-model-for-question-and-answer-identification-in-chats</guid>
      <pubDate>Mon, 03 Jun 2024 06:56:50 GMT</pubDate>
    </item>
    <item>
      <title>Transformer 模型在攻击期间预测相同的 token，但在训练期间表现良好</title>
      <link>https://stackoverflow.com/questions/78568713/transformer-model-predicting-the-same-token-during-infrence-but-performing-well</link>
      <description><![CDATA[我的 Transformer 模型无法正常工作。
训练循环：
for epoch in range(40):
data_loader = tqdm(data_loader, desc=f&quot;Epoch {epoch + 1}/{20}&quot;, unit=&quot;batch&quot;)
for batch_idx, (en_batch, hi_batch) in enumerate(data_loader):
en_batch = en_batch.to(&#39;cuda&#39;).to(torch.long)
hi_batch = hi_batch.to(&#39;cuda&#39;).to(torch.long)
y_pred = model(en_batch, hi_batch)
loss = loss_fn(y_pred[:, 0:127, :].transpose(2,1), hi_batch[:, 1:128]).mean()
history.append(loss.item())
如果 batch_idx % 400 == 0:
clear_output(wait=False)
torch.save(history, &#39;history2.pth&#39;)
torch.save(losses, &#39;valLoss2.pth&#39;)
torch.save(model.state_dict(), &#39;model_weightsBPE2.pth&#39;)
model.eval()
val_loss = 0
使用 torch.no_grad():
对于 id , (en_batch, hi_batch) 在 enumerate(val_loader, 1):
en_batch, hi_batch = en_batch.to(&#39;cuda&#39;), hi_batch.to(&#39;cuda&#39;)
y_pred = model(en_batch.to(torch.long), hi_batch[:, :-1].to(torch.long))
val_loss += loss_fn(y_pred[:, 0:127, :].transpose(2,1), hi_batch[:, 1:128].to(torch.long)).mean()
如果 id % 5 == 0:
break
val_loss /= 5
model.train()
print(f&quot;验证损失：{val_loss}&quot;)
losses.append(val_loss.item())
如果 batch_idx % 100 == 0:
print(&quot;-&quot;20, batch_idx, &quot;-&quot;, epoch, &quot;-&quot;, loss.item(), &quot;-&quot;20)
print(&quot;en : &quot;, id_to_token(en_batch, &quot;en&quot;))
print(&quot;hi : &quot;, id_to_token(hi_batch, &quot;hi&quot;))
print(&quot;out: &quot;, id_to_token_M(y_pred, &quot;hi&quot;))
optimizer.zero_grad()
loss.backward()
optimizer.step()
scheduler.step()


训练输出：
out: संघ के प्रदेशाध्यक्ष बृज मो गाुप्ता ने महारे्ल इेंदिर क के艾特里公园韋प माया।


推理循环：
def inference_loop( input_seq, max_output_length=128):
input_seq = input_seq.unsqueeze(0) # 添加批次维度
current_token = torch.tensor([[1]], device=input_seq.device)
output_seq = []
for * in range(max*output_length):
predictions = model(input_seq, current_token)
next_token = predictions[:, -1, :].argmax(dim=-1)
current_token = torch.cat([current_token, next_token.unsqueeze(0)], dim=1)
if next_token.item() == 2:
break
output_seq.append(next_token.item())
return output_seq


推理输出：
&#39; क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क क&#39;


我该如何解决这个问题，训练和验证损失都下降了，但在推理过程中它开始一次又一次地预测相同的标记。]]></description>
      <guid>https://stackoverflow.com/questions/78568713/transformer-model-predicting-the-same-token-during-infrence-but-performing-well</guid>
      <pubDate>Mon, 03 Jun 2024 06:31:29 GMT</pubDate>
    </item>
    <item>
      <title>矩阵的线性回归</title>
      <link>https://stackoverflow.com/questions/78568690/linear-reggresion-of-matrix</link>
      <description><![CDATA[设 \(\mathbf{X}\in\mathbb{R}^{n\times d}\) 为回归量矩阵，并设 \(\mathbf{Y}\in\mathbb{ R}^n \) 是响应向量。考虑参数向量 \(\mathbf{b}\in\mathbb{R}^d\) 的线性回归模型。求最小二乘 (LS) 函数相对于参数向量 \(\mathbf{b}\) 的梯度和 Hessian 矩阵。

线性回归模型：
\[
\mathbf{Y} = \mathbf{Xb} + \mathbf{\epsilon}
\]
其中 \( \mathbf{Y} \in \mathbb{R}^n\) 是响应向量， \(\mathbf{X}\in \mathbb{R}^{n\times d}\) 是矩阵回归器中，\(\mathbf{b}\in\mathbb{R}^d\) 是参数向量，\(\mathbf{\epsilon}\) 是误差向量。

我被困住了。也许
相对于 \( \mathbf{b}\) 的梯度为： \[ \mathbf{b}} J(\mathbf{b}) = \mathbf{b}} \left ( \frac{1} {2}(\mathbf{Y} - \mathbf{Xb})^\top(\mathbf{Y} - \mathbf{Xb})\right) \] 简化 \( J (\mathbf{b}) 的表达式) \): \[ J(\mathbf{b}) = \frac{1}{2} (\mathbf{Y}^\top \mathbf{Y} - 2 \mathbf{Y} ^\top \mathbf{ Xb} + \mathbf{b}^\top \mathbf{X}^\top \mathbf{Xb}) \] 则梯度为： \[ \nabla_{\mathbf{b}} J (\mathbf{b} ) = -\mathbf{X}^\top \mathbf{Y} + \mathbf{X}^\top \mathbf{Xb}\]]]></description>
      <guid>https://stackoverflow.com/questions/78568690/linear-reggresion-of-matrix</guid>
      <pubDate>Mon, 03 Jun 2024 06:25:46 GMT</pubDate>
    </item>
    <item>
      <title>我的训练被随机终止，没有错误日志</title>
      <link>https://stackoverflow.com/questions/78568551/my-training-gets-killed-randomly-without-an-error-log</link>
      <description><![CDATA[我一直在尝试在集群计算机上训练 trackformer 模型。它显示了一条 Killed 消息，并且没有任何日志。
Killed 消息
将权重传递到模型中时发生错误
尝试 dmesg 时，我得到了以下输出
[2024 年 6 月 3 日星期一 07:24:26] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=task_0,mems_allowed=0-1,oom_memcg=/system.slice/slurmstepd.scope/job_19894856,task_memcg=/system
.slice/slurmstepd.scope/job_19894856/step_batch/user/task_0,task=python,pid=702977,uid=1380211
[2024 年 6 月 3 日星期一 07:24:26] 内存 cgroup 内存不足：已终止进程 702977 (python) total-vm:16068556kB, anon-rss:2144556kB, file-rss:123156kB, shmem-rss:28256kB, UID:1380211 pgtab
les:10612kB oom_score_adj:0


我试图在自定义数据集上训练 trackformer 模型。但训练过程随机停止]]></description>
      <guid>https://stackoverflow.com/questions/78568551/my-training-gets-killed-randomly-without-an-error-log</guid>
      <pubDate>Mon, 03 Jun 2024 05:38:39 GMT</pubDate>
    </item>
    <item>
      <title>XGBRanker `label` 参数理解</title>
      <link>https://stackoverflow.com/questions/78568511/xgbranker-label-parameter-understanding</link>
      <description><![CDATA[我正在尝试测试 XGBRanker 的金融产品推荐系统。一个人可以随着时间的推移多次购买多种产品或同一种产品。
我已准备如下所示的数据。在这里，客户 1 在过去 2 年内购买了 P1 和 P2 [在线 + 离线]，但在我的平台上点击是最近的 [最近 30/60 天]。此外，我将使用 pyspark 运行我的代码。



id
功能 1（点击 P1）
功能 2（点击 P2）
功能 3（点击 P3）
购买的产品（标签）




1
2
-
5
P1


1
2
-
5
P2


2
-
 3
2
P2


3
5
1
7
P1


3
5
1
7
P3



由于过去 30/60 天每个产品的点击数据都相同，XGBRanker 将如何了解同一客户购买的不同产品。
关于如何为 XGBRanker 准备输入，有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78568511/xgbranker-label-parameter-understanding</guid>
      <pubDate>Mon, 03 Jun 2024 05:23:12 GMT</pubDate>
    </item>
    <item>
      <title>如何在可变形 DETR 中可视化注意力以及基于 DETR 的一系列后续工作？</title>
      <link>https://stackoverflow.com/questions/78568416/how-to-visualize-attentions-in-deformable-detr-and-a-series-of-follow-up-works-i</link>
      <description><![CDATA[许多论文，即使代码是开源的，也没有提供生成这些可视化的具体代码。因此，我想问一下是否有任何脚本或参考资料可以指导这些可视化的重现。
具体来说，Conditional-DETR 中的框定位可视化或其他一些作品中的 Cross Attention 可视化。很多时候，即使我能理解作者想要通过这些图传达的意思，但理解用于可视化的实际视觉特征和后处理方法仍然完全难以捉摸。]]></description>
      <guid>https://stackoverflow.com/questions/78568416/how-to-visualize-attentions-in-deformable-detr-and-a-series-of-follow-up-works-i</guid>
      <pubDate>Mon, 03 Jun 2024 04:41:57 GMT</pubDate>
    </item>
    <item>
      <title>稳定扩散图像中的突变检测方法</title>
      <link>https://stackoverflow.com/questions/78568259/detection-methods-for-mutations-in-stable-diffusion-images</link>
      <description><![CDATA[我正在使用 Python 中的稳定扩散来生成人体图像。我面临的一个挑战是自动检测生成的图像中的任何异常。这些异常包括手、脚等身体部位的不规则性，或身体部位过多或过少，以及介于两者之间的一切。
我测试了几种方法，但没有成功。例如，我尝试使用 OpenAI GPT4 视觉来识别这些异常；但是，它无法检测到异常，除非我说“你确定吗”几次，然后它似乎会发现它。
为了保持本地化，我尝试了视觉模型，如 llava，但这也失败了。我也尝试训练自己的卷积神经网络，但由于训练数据不足（手动标记），它最终过度拟合。其他潜在解决方案（如 ViT 和 EfficientNet）似乎也面临数据不足的相同问题。
我需要的是一种无需人工干预即可自动检测这些异常的方法，有什么建议吗？
我尝试了以下操作：



试用
问题




OpenAI GPT4 视觉
除非多次提示，否则无法检测到异常


本地视觉模型（如 llava）
未发现异常


训练自己的卷积神经网络
由于训练数据不足（手动标记）


潜在解决方案（如 ViT 和 EfficientNet）
面临数据不足的相同问题



不良照片示例：
1：图片
2：图片
3：图片]]></description>
      <guid>https://stackoverflow.com/questions/78568259/detection-methods-for-mutations-in-stable-diffusion-images</guid>
      <pubDate>Mon, 03 Jun 2024 03:28:04 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow-Keras 训练在 Macbook M2 Pro 上出现问题 - 在云端和其他操作系统上运行良好</title>
      <link>https://stackoverflow.com/questions/78567702/tensorflow-keras-training-goes-awry-on-macbook-m2-pro-runs-fine-on-cloud-and-o</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78567702/tensorflow-keras-training-goes-awry-on-macbook-m2-pro-runs-fine-on-cloud-and-o</guid>
      <pubDate>Sun, 02 Jun 2024 21:11:56 GMT</pubDate>
    </item>
    <item>
      <title>编码结果以布尔值而不是数字形式输出</title>
      <link>https://stackoverflow.com/questions/78565774/encoded-result-gives-output-as-bolean-instead-of-numeric</link>
      <description><![CDATA[执行 OneHotEncoding 后，我的数据框将其列的值设为 True 和 False，而不是我应该得到的 1 和 0。我的代码如下所示，其中数据框为 ds，分类列名称为“type”：
pd.get_dummies(ds,columns = [&quot;type&quot;])

我试图获取数字结果。]]></description>
      <guid>https://stackoverflow.com/questions/78565774/encoded-result-gives-output-as-bolean-instead-of-numeric</guid>
      <pubDate>Sun, 02 Jun 2024 07:52:13 GMT</pubDate>
    </item>
    <item>
      <title>即使指定了某些列，Pandas 也会获取数据框的所有列</title>
      <link>https://stackoverflow.com/questions/78559070/pandas-takes-all-columns-of-a-dataframe-even-when-some-columns-are-specified</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78559070/pandas-takes-all-columns-of-a-dataframe-even-when-some-columns-are-specified</guid>
      <pubDate>Fri, 31 May 2024 08:59:38 GMT</pubDate>
    </item>
    <item>
      <title>在 Feast + Cassandra 中存储特征之前是否需要一个中间持久存储？</title>
      <link>https://stackoverflow.com/questions/78544969/is-an-intermediary-persistent-store-needed-before-storing-features-in-feast-ca</link>
      <description><![CDATA[我目前正在为 MLOps 项目构建大数据管道，该管道用于批处理。
这是当前设置：

我将原始结构化数据存储在 Hive 中。
Spark 作业提取原始数据并对其进行处理。
我打算使用 feast 和 Apache Cassandra 作为离线存储，用于存储由我的 Spark 作业产生的计算和整理特征。

我想高效地将数据从 spark 作业传递到 feast 和 Cassandra，我不确定在将处理后的数据传递给 feast 以存储在离线存储中之前，是否需要中间数据持久性解决方案来保存处理后的数据，在我的情况下有必要吗？]]></description>
      <guid>https://stackoverflow.com/questions/78544969/is-an-intermediary-persistent-store-needed-before-storing-features-in-feast-ca</guid>
      <pubDate>Tue, 28 May 2024 15:00:31 GMT</pubDate>
    </item>
    <item>
      <title>预测多元时间序列时 VARIMA 模型的模型漂移</title>
      <link>https://stackoverflow.com/questions/78544041/model-drift-for-varima-model-when-forecasting-multivariate-time-series</link>
      <description><![CDATA[我目前正在尝试在多变量时间序列数据上训练 VARIMA 模型，该数据是关于冷却系统的 5 种不同类型的传感器测量的。数据具有周期性，因此完全相同的模式每 25 个数据点左右就会重复出现。我有一个包含 5 个不同组件的数据集，其中每分钟都有一个数据点。我使用了 2 周的数据来训练模型，然后让它合成数据。我使用的 VARIMA 模型是从 Darts 包导入的，我这样定义模型：model_VARIMA = VARIMA(p=12, d=0, q=0, trend=&quot;n&quot;)。该模型是在 2 周的训练数据上训练的。当预测未来 30 个点或更多时，预测显然开始显示模型漂移。所有组件都没有产生周期性的多变量时间序列数据，而是慢慢开始遵循一条不再改变值的直线水平线。换句话说，所有成分的标准偏差都会慢慢变为零，所有成分都会慢慢开始向其平均值漂移并永远停留在那里。我想知道是否有人对此有解释并有解决问题的方法。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78544041/model-drift-for-varima-model-when-forecasting-multivariate-time-series</guid>
      <pubDate>Tue, 28 May 2024 12:15:20 GMT</pubDate>
    </item>
    <item>
      <title>langchain RetrievalQA 错误：ValueError：缺少一些输入键：{'query'}</title>
      <link>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</link>
      <description><![CDATA[在 RAG 项目中，我使用的是 langchain。当我使用查询输入运行 QA 链时，此错误一直出现：
----&gt; result = qa_chain({&#39;query&#39;: question})
ValueError: 缺少一些输入键：{&#39;query&#39;}

这是我的代码：
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# 构建提示
template = &quot;&quot;&quot;根据以下上下文回答问题。
上下文：
{context}
------------------
问题：{query}
答案：&quot;&quot;&quot;

# LLM 链
QA_CHAIN_PROMPT = PromptTemplate.from_template(template)
qa_chain = RetrievalQA.from_chain_type(
llm,
trieser=vectordb.as_retriever(),
return_source_documents=True,
chain_type_kwargs={&quot;prompt&quot;: QA_CHAIN_PROMPT}
)

question = &quot;这篇研究论文使用了什么方法？&quot;

result = qa_chain({&#39;query&#39;: question})

# 检查查询结果
result[&quot;result&quot;]
# 检查我们从中获取的源文档
result[&quot;source_documents&quot;][0]
]]></description>
      <guid>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</guid>
      <pubDate>Fri, 24 May 2024 21:23:49 GMT</pubDate>
    </item>
    </channel>
</rss>