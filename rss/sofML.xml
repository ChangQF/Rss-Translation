<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 28 Jan 2025 15:17:32 GMT</lastBuildDate>
    <item>
      <title>如何正确地使用大数据进行训练？[关闭]</title>
      <link>https://stackoverflow.com/questions/79394095/how-do-i-correctly-train-with-big-data</link>
      <description><![CDATA[我想以监督的方式训练深度神经网络。对于这个训练任务，我可以使用某个分布自行生成数据。问题是我只能保存一定量的数据。
现在我的想法是在第一个数据集上训练网络，删除该数据集并生成具有该分布的新数据集。现在继续进行。每个数据集上的任务也相同。
我如何跟踪过度拟合并最终得到一个泛化的模型？
我目前的想法：
我事先生成一个测试集，在每次数据集训练之后，我都会在测试集上验证我的网络。此外，对于每个训练集，我都会生成一个单独的验证集，以跟踪在一个训练数据集上训练期间的过度拟合。此外，由于我有可用的数据集，我很想在单个数据集上进行周期训练，但这不会增加过度拟合的可能性吗？]]></description>
      <guid>https://stackoverflow.com/questions/79394095/how-do-i-correctly-train-with-big-data</guid>
      <pubDate>Tue, 28 Jan 2025 14:04:10 GMT</pubDate>
    </item>
    <item>
      <title>Keras 训练问题：“您的输入数据不足”警告和 0 损失/准确度</title>
      <link>https://stackoverflow.com/questions/79394023/keras-training-issue-your-input-ran-out-of-data-warning-and-0-loss-accuracy</link>
      <description><![CDATA[我正在使用 ImageDataGenerator 训练 CNN 模型，数据集包含 1500 张训练图像和 32 个批次大小。我计算每个时期的步数为
⌈1500/32⌉=47，最后一个批次不完整，我正在使用 flow_from_directory() 加载图像。但是，在第一个时期之后，模型显示某些时期的损失为 0，准确率为 0，并且训练中断并显示警告：

UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 steps_per_epoch * epochs 个批次。构建数据集时可能需要使用 .repeat() 函数。 self.gen.throw(typ, value, traceback)

train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# 从目录导入数据并将其转换为批次
train_data = train_datagen.flow_from_directory(train_path,
batch_size=32,
target_size=(224, 224),
class_mode=&quot;binary&quot;)

valid_data = valid_datagen.flow_from_directory(test_path,
batch_size=32,
target_size=(224, 224),
class_mode=&quot;binary&quot;)

tf.random.set_seed(42)

model_1 = tf.keras.models.Sequential([
输入（形状=（224, 224, 3）），
Conv2D（过滤器=10，
kernel_size=3，
strides=1，
padding=&#39;valid&#39;，
激活=&#39;relu&#39;），
Conv2D（10，3，激活=&#39;relu&#39;），
Conv2D（10，3，激活=&#39;relu&#39;），
Flatten（），
Dense（1，激活=&#39;sigmoid&#39;）
]）

model_1.compile（loss=“binary_crossentropy”，
optimizer=tf.keras.optimizers.Adam（），
metrics=[“accuracy”]）

history_1 = model_1.fit（train_data，
epochs=5，
steps_per_epoch=len（train_data），
validation_data=valid_data，
validation_steps=len(valid_data))

输出日志
Epoch 1/5
/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: 您的 PyDataset 类应在其构造函数中调用 super().__init__(**kwargs)。**kwargs 可以包括 workers、use_multiprocessing、max_queue_size。请勿将这些参数传递给 fit()，因为它们将被忽略。
self._warn_if_super_not_called()
47/47 ━━━━━━━━━━━━━━━━━━━━━ 767s 14s/步 - 准确度：0.6488 - 损失：0.6197 - val_accuracy：0.7620 - val_loss：0.4793
Epoch 2/5
47/47 ━━━━━━━━━━━━━━━━━━━━━━ 0s 426us/步 - 准确度： 0.0000e+00 - 损失：0.0000e+00
Epoch 3/5
/usr/lib/python3.11/contextlib.py:158：UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 steps_per_epoch * epochs 个批次。您可能需要在构建数据集时使用 .repeat() 函数。
self.gen.throw(typ, value, traceback)
47/47 ━━━━━━━━━━━━━━━━━━━━━━ 48s 224ms/step - 准确度：0.8120 - 损失：0.4131 - val_accuracy：0.8600 - val_loss：0.3441
Epoch 4/5
47/47 ━━━━━━━━━━━━━━━━━━━━━━━ 3s 54ms/step - 准确度： 0.0000e+00 - 损失：0.0000e+00
纪元 5/5
47/47 ━━━━━━━━━━━━━━━━━━━━━━ 11 秒 219 毫秒/步 - 准确度：0.8336 - 损失：0.3814 - val_accuracy：0.8880 - val_loss：0.3042]]></description>
      <guid>https://stackoverflow.com/questions/79394023/keras-training-issue-your-input-ran-out-of-data-warning-and-0-loss-accuracy</guid>
      <pubDate>Tue, 28 Jan 2025 13:39:12 GMT</pubDate>
    </item>
    <item>
      <title>使用巨大且不同尺寸的图像训练 CNN</title>
      <link>https://stackoverflow.com/questions/79393407/training-a-cnn-with-huge-and-different-dimensions-of-images</link>
      <description><![CDATA[我有一个包含高维度图像（空表）的数据集，我正尝试将其用于分类目的。根据这些统计数据：

由于维度差异太大，因此无法统一维度，而且这可能会压缩表格的行，从而导致表格的结构发生变化。有什么想法可以处理这种情况吗？我相信这样的维度会消耗大量的计算资源，而我没有这些资源（我最多只有 8gb VRAM）。]]></description>
      <guid>https://stackoverflow.com/questions/79393407/training-a-cnn-with-huge-and-different-dimensions-of-images</guid>
      <pubDate>Tue, 28 Jan 2025 10:07:48 GMT</pubDate>
    </item>
    <item>
      <title>人工智能如何连续两次给我错误答案这个简单的问题[关闭]</title>
      <link>https://stackoverflow.com/questions/79393114/how-ai-give-me-the-wrong-answer-twice-in-a-row-of-this-simple-question</link>
      <description><![CDATA[早上好，程序员们，今天我出于好奇，尝试在 deep ai.org 上计算二进制到十六进制和八进制数。但每次都给我错误的答案。看：

另外：正确的答案：

看完这个，AI 没那么聪明XD]]></description>
      <guid>https://stackoverflow.com/questions/79393114/how-ai-give-me-the-wrong-answer-twice-in-a-row-of-this-simple-question</guid>
      <pubDate>Tue, 28 Jan 2025 08:17:46 GMT</pubDate>
    </item>
    <item>
      <title>NLP 和 ML 是否相关，或者是否有机会构建不需要 ML 的 NLP 项目？[关闭]</title>
      <link>https://stackoverflow.com/questions/79392404/are-nlp-and-ml-related-or-there-is-a-chance-to-build-an-nlp-project-without-the</link>
      <description><![CDATA[就我对学习 NLP 的兴趣而言，我仍然觉得 NLP 和 ML 有点令人困惑。
我尝试询问聊天 gbt 和 Deepseek，但仍然没有找到答案！
以及深度学习和神经网络，这很乱，但希望我能得到答案。]]></description>
      <guid>https://stackoverflow.com/questions/79392404/are-nlp-and-ml-related-or-there-is-a-chance-to-build-an-nlp-project-without-the</guid>
      <pubDate>Mon, 27 Jan 2025 23:15:48 GMT</pubDate>
    </item>
    <item>
      <title>新的 2025 Spring Boot 与 PyTorch 模型集成：嵌入预训练网络 [关闭]</title>
      <link>https://stackoverflow.com/questions/79391741/new-2025-spring-boot-integration-with-pytorch-model-embedding-a-pre-trained-net</link>
      <description><![CDATA[我正在努力将预先训练好的 PyTorch 模型集成到 Spring Boot 应用程序中。我的目标是利用应用程序公开的 REST API 中的模型推理功能。我在网上搜索过，但没有找到关于最佳方法的明确指南。有人可以提供一些指导或为我指出有用的资源吗？
具体问题：

首选方法：将 PyTorch 模型嵌入 Spring Boot 应用程序中的推荐方法是什么？是否有简化流程的成熟库或框架？
序列化/反序列化：如何有效地序列化 PyTorch 模型以在 Spring Boot 应用程序中部署？这项任务是否有特定的格式或工具？
模型服务：集成模型后，如何在 Spring Boot 中创建一个 API 端点，该端点接受输入数据、将其提供给模型进行推理并返回预测？

我想在 Spring Boot 上创建一个微服务应用程序，其中一个服务将训练 PyTorch 神经网络模型。我对 Spring Boot、RESTful 和 PyTorch 模型框架有基本的了解。]]></description>
      <guid>https://stackoverflow.com/questions/79391741/new-2025-spring-boot-integration-with-pytorch-model-embedding-a-pre-trained-net</guid>
      <pubDate>Mon, 27 Jan 2025 18:03:04 GMT</pubDate>
    </item>
    <item>
      <title>从图像数据中采样</title>
      <link>https://stackoverflow.com/questions/79391082/sampling-from-image-data</link>
      <description><![CDATA[有没有一种方法可以从图像数据集中进行采样，以保持其中的最高方差，同时保持所有可能的异常值和最多的信息？]]></description>
      <guid>https://stackoverflow.com/questions/79391082/sampling-from-image-data</guid>
      <pubDate>Mon, 27 Jan 2025 14:10:03 GMT</pubDate>
    </item>
    <item>
      <title>EfficientNetB3模型识别脑肿瘤准确率极低及学习停滞问题</title>
      <link>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</guid>
      <pubDate>Mon, 27 Jan 2025 11:58:17 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras 3 中打印出层间的张量值？</title>
      <link>https://stackoverflow.com/questions/79389885/how-do-i-print-out-the-tensor-values-in-between-layers-in-keras-3</link>
      <description><![CDATA[我正在使用带有 PyTorch 后端的 Keras 3。
我正在尝试将其他人编写的模型移植到另一个运行时，我想转储每层之后的张量汇总统计信息，以便找出我在移植过程中错误实现的哪个操作（可能是注意，哈哈）。
如何在 Keras 3 模型中插入打印语句？我能找到的所有其他答案都与 tf.keras 有关，这似乎与我使用的完全不同。也没有方法 keras.backend.print_tensor()。
我也尝试过创建一个这样的中间模型（为了便于理解，我挑选的模型是 Moonshine）：
encoder = model.encoder.encoder
encoder_intermediate_model = Model(
input=encoder.inputs, output=[layer.output for layer incoder.layers]
)

但尝试运行此程序时会崩溃，并出现模糊错误：
回溯（最近一次调用）：
文件“C:\Users\ibiyemi\projects\wellington-ml\moonshine.py”，第 764 行，位于&lt;module&gt;
编码器输出 = 编码器中间模型 (
^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\ibiyemi\projects\wellington-ml\.venv\Lib\site-packages\keras\src\utils\traceback_utils.py&quot;，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件 &quot;C:\Users\ibiyemi\projects\wellington-ml\.venv\Lib\site-packages\torch\nn\modules\module.py&quot;，第 1736 行，位于 _wrapped_call_impl 中
返回 self._call_impl(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\ibiyemi\projects\wellington-ml\.venv\Lib\site-packages\torch\nn\modules\module.py&quot;，第 1747 行，在 _call_impl 中
return forward_call(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: &quot;调用 Functional.call() 时遇到异常。\n\n\x1b[1m2365371176512\x1b[0m\n\nFunctional.call() 收到的参数:\n • 输入=[&#39;torch.Tensor(shape=torch.Size([1, 1248, 416]), dtype=float32)&#39;, &#39;torch.Tensor(shape=torch.Size([1]), dtype=int32)&#39;]\n • training=None\n • mask=[&#39;None&#39;, &#39;None&#39;]&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/79389885/how-do-i-print-out-the-tensor-values-in-between-layers-in-keras-3</guid>
      <pubDate>Mon, 27 Jan 2025 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>无法获取 SentenceTransformer 模型的度量图</title>
      <link>https://stackoverflow.com/questions/79388997/unable-to-get-the-metrics-plots-of-sentencetransformer-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79388997/unable-to-get-the-metrics-plots-of-sentencetransformer-model</guid>
      <pubDate>Sun, 26 Jan 2025 17:42:51 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 3.5 中使用 SavedModel 格式</title>
      <link>https://stackoverflow.com/questions/79388942/using-savedmodel-format-in-keras-3-5</link>
      <description><![CDATA[我在尝试使用 tf.keras.models.load_model(Path_to_pb_model) 加载 Savedformat 模型时遇到了问题。
我正在使用 Tensorflow 2.17.1 和 Keras 3.5。
显然 Keras 3 只接受 .keras 或 .h5 格式。
首先，我有点困惑，因为根据此文档：
保存和加载模型，您应该能够保存 &amp;在 Keras 3 中加载 .pb 模型。

文档有误吗？因为当我尝试在 Colab 中运行此代码时，出现错误，提示仅支持 .keras 和 .h5 文件格式。
另外，我还查看了本指南，了解如何加载 &amp;使用 tf.saved_model API 保存 SavedModel 格式，但不会返回 Keras 对象，也没有 .evaluate() 或 .predict() 方法。
那么有没有办法在 Keras3 中加载 SavedModel 格式？然后在我的测试数据上评估该模型？]]></description>
      <guid>https://stackoverflow.com/questions/79388942/using-savedmodel-format-in-keras-3-5</guid>
      <pubDate>Sun, 26 Jan 2025 17:06:14 GMT</pubDate>
    </item>
    <item>
      <title>用时间链接表示特征的 ML 模型类型 [关闭]</title>
      <link>https://stackoverflow.com/questions/79388422/type-of-ml-model-to-represent-features-with-a-time-link</link>
      <description><![CDATA[我正在尝试建立一个模型来预测合同的价格。合约在特定日期具有特定事件和状态。
例如：
2025/01/10 - 波动率：1.2，屏障：1.5，息票 1.1
2025/01/14 - 波动率：0.9，屏障：1.55，息票 1.15

简要解释是，当达到屏障时，息票将支付。
每个事件日期都有 15 个特征，包括该日期的市场状态以及波动性和远期价格等财务参数。
我希望能够将可变长度序列（不同的合约可能具有不同的屏障日期/息票日期数量）放入网络并获得价格。
首先，我对所有内容进行了标准化，包括标准化为合约长度的时间点
起初我想使用 LSTM，但 LSTM 的用于预测顺序数据。这不是顺序数据，因为前一个时间步骤与下一个时间步骤无关。尽管每个特征都有一个时间相关维度，因为每个特征都与某个时间点相关联
在这种情况下我应该使用哪种技术？
示例特征矩阵
时间障碍 票息波动率 前向
0.1 1.1 1.4 1.5 0.98
0.3 0 0 1.3 0.97
0.9 1.4 1.6 0.3 0.95
0.95. 1.0. 1.8. 2.4. 0.97

此特征矩阵表示合同的定义。基本上，在时间 0.1 时，障碍为 1.1，支付票息为 1.4。在时间 0.3 时，没有障碍或优惠券，但我们有一些波动性和前瞻性信息，确实会影响合约的价格。更改时间值会显著影响价格。
因此它不是时间序列数据，因为它不是随时间变化的序列。它只是表示合约所处环境的事件和状态。使用其中一些参数的蒙特卡罗方法将计算价格，但我需要使用 ML 来执行此操作。]]></description>
      <guid>https://stackoverflow.com/questions/79388422/type-of-ml-model-to-represent-features-with-a-time-link</guid>
      <pubDate>Sun, 26 Jan 2025 11:23:17 GMT</pubDate>
    </item>
    <item>
      <title>使用“bitsandbytes”4 位量化需要最新版本的 bitsandbytes：“pip install -U bitsandbytes”</title>
      <link>https://stackoverflow.com/questions/79344565/using-bitsandbytes-4-bit-quantization-requires-the-latest-version-of-bitsandby</link>
      <description><![CDATA[加载 tokenizer 时，我收到此错误：
ImportError：使用 bitsandbytes 4 位量化需要最新版本的 bitsandbytes：
pip install -U bitsandbytes。

我在 Macbook M2 pro 上使用 Jupyter 笔记本。
以下是源代码：
quant_config = BitsAndBytesConfig(
load_in_4bit=True,
bnb_4bit_use_double_quant=True,
bnb_4bit_compute_dtype=torch.bfloat16,
bnb_4bit_quant_type=&quot;nf4&quot;

tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = &quot;right&quot;

base_model = AutoModelForCausalLM.from_pretrained(
BASE_MODEL,
quantization_config=quant_config,
device_map=&quot;auto&quot;,
)

base_model.generation_config.pad_token_id = tokenizer.pad_token_id

有人能帮忙吗？
我按照说明更新了 bitsandbytes，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/79344565/using-bitsandbytes-4-bit-quantization-requires-the-latest-version-of-bitsandby</guid>
      <pubDate>Fri, 10 Jan 2025 03:52:41 GMT</pubDate>
    </item>
    <item>
      <title>optuna 试验可以被清除/删除吗？（处理随时间推移的政权更迭）</title>
      <link>https://stackoverflow.com/questions/75939676/can-optuna-trials-be-purged-deleted-dealing-with-regime-changes-over-time</link>
      <description><![CDATA[背景：我正在建模的 ML 问题会随着时间推移而随着不同的制度而变化 - 因此模型权重和最佳模型超参数会随着时间推移而变化。
问题：对于给定的 optuna.study，当我调用 study.best_trial.params 时，这可能会将最佳试验标识为过去的试验 - 这代表了对当前制度的最佳参数的过时观点。
次要问题：当 optuna 在优化过程中对超参数进行采样以进行评估时，它会使用所有试验的结果来概率地告知从何处进行采样。随着制度的变化，较旧的试验在此过程中的相关性降低。
问题：随着时间的推移，有没有办法清除、删除或忽略较旧的试验？这样上述两个问题就解决了吗？
反思：

也许我误解了 optuna 的工作原理。我认为获取 best_params 的最佳方法是调用 optuna.study.best_trial.params，它会查看所有历史试验并贪婪地找到具有最佳优化分数的试验并返回用于该运行的参数。
但也许有另一种方法可以获取过去 N 次试验中的 best_params？
或者也许我应该只关注从最后一次试验中获取最佳参数 - 这将很好地代表当前情况。我相信我可以使用 study.get_trials()[-1].params 来获得它。

感谢您的任何反馈/建议。]]></description>
      <guid>https://stackoverflow.com/questions/75939676/can-optuna-trials-be-purged-deleted-dealing-with-regime-changes-over-time</guid>
      <pubDate>Wed, 05 Apr 2023 12:53:15 GMT</pubDate>
    </item>
    <item>
      <title>使用预训练 CNN 提取的特征作为 CNN/NN 的新特征 [关闭]</title>
      <link>https://stackoverflow.com/questions/41189112/using-features-extracted-using-a-pretrained-cnn-as-new-features-for-an-cnn-nn</link>
      <description><![CDATA[我正在使用预训练的 CNN 从图片中提取特征。将这些特征用作新 CNN/NN 的输入是否有意义？以前有人这样做过吗？]]></description>
      <guid>https://stackoverflow.com/questions/41189112/using-features-extracted-using-a-pretrained-cnn-as-new-features-for-an-cnn-nn</guid>
      <pubDate>Fri, 16 Dec 2016 17:00:42 GMT</pubDate>
    </item>
    </channel>
</rss>