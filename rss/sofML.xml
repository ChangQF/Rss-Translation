<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 10 Jul 2024 01:06:38 GMT</lastBuildDate>
    <item>
      <title>Azure Custom Vision 从网络摄像头获取图像，然后返回图像</title>
      <link>https://stackoverflow.com/questions/78727554/azure-custom-vision-to-get-an-image-from-webcam-and-then-return-an-image</link>
      <description><![CDATA[我希望创建一项服务，将网络摄像头中的图像发送到 Azure Custom Vision，并让其返回它认为匹配的图像。这可以用于纸牌游戏，因此如果您在网络摄像头上显示黑桃 A，它将能够返回黑桃 A 的图像。这是否适合 Azure Custom Vision？我创建了一个项目并上传和标记了图像，但我还没有看到这样的用例。]]></description>
      <guid>https://stackoverflow.com/questions/78727554/azure-custom-vision-to-get-an-image-from-webcam-and-then-return-an-image</guid>
      <pubDate>Tue, 09 Jul 2024 19:57:34 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未在未知的 TensorShape 上定义 as_list()。图像和掩码形状看起来正确</title>
      <link>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</link>
      <description><![CDATA[我正尝试调整 Tensorflow 的示例 UNet 以达到我的目的。主要区别在于，此 UNet 采用 128x128 图像和掩码，而我的图像为 512x512，掩码为 100x100。
尝试运行 model.fit 时出现此错误：
ValueError：as_list() 未在未知的 TensorShape 上定义。

但是，我可以毫无问题地运行 model.predict，它会生成我期望的未经训练的模型的预测。
这是我用来制作和训练模型的代码：
base_model = tf.keras.applications.MobileNetV2(input_shape=[512, 512, 3], include_top=False)

# 使用这些层的激活
layer_names = [
&#39;block_1_expand_relu&#39;, # 64x64
&#39;block_3_expand_relu&#39;, # 32x32
&#39;block_6_expand_relu&#39;, # 16x16
&#39;block_13_expand_relu&#39;, # 8x8
&#39;block_16_project&#39;, # 4x4
]
base_model_outputs = [base_model.get_layer(name).output for name in layer_names]

# 创建特征提取模型
down_stack = tf.keras.Model(inputs=base_model.input, output=base_model_outputs)

down_stack.trainable = False

up_stack = [
pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8
pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16
pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32
pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
input = tf.keras.layers.Input(shape=[512, 512, 3])

# 通过模型进行下采样
skips = down_stack(inputs)
x = skips[-1]
skips = reversed(skips[:-1])

# 上采样并建立 skip 连接
for up, skip in zip(up_stack, skips):
x = up(x)
concat = tf.keras.layers.Concatenate()
x = concat([x, skip])

# 这是模型的最后一层
last = tf.keras.layers.Conv2DTranspose(
filters=output_channels, kernel_size=3, strides=2,
padding=&#39;same&#39;) #64x64 -&gt; 128x128

x = last(x)

return tf.keras.Model(inputs=inputs, output=x)

OUTPUT_CLASSES = 5

model = unet_model(output_channels=OUTPUT_CLASSES)
model.compile(optimizer=&#39;adam&#39;,
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
metrics=[&#39;accuracy&#39;])

model_history = model.fit(train_dataset, epochs=EPOCHS,
validation_data=test_dataset)

我尝试检查每个批次的图像形状和掩码形状。除了最后一个批次（只有一个图像）外，每个批次的图像形状为 (16, 512, 512, 3)，掩码形状为 (16, 100, 100, 1)。
我尝试将此代码放入我的 process_paths（教程中称之为）函数中：
image = tf.reshape(image, [512, 512, 3])

...
mask = tf.reshape(mask, [100, 100, 1])

我尝试对 up_stack 部分中的数字进行一些调整，但最终一无所获，因为我不理解那部分。我的假设是，既然我已经更改了输入大小，我必须更改模型层的输出大小，但我真的不知道该怎么做。另外，我很困惑，如果是这样的话，为什么我仍然可以运行 model.predict。
我的 tensorflow 版本是 2.16.1]]></description>
      <guid>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</guid>
      <pubDate>Tue, 09 Jul 2024 19:17:45 GMT</pubDate>
    </item>
    <item>
      <title>如何设置 XGBoost 中的所有默认参数或安装旧版本的 XGBoost？</title>
      <link>https://stackoverflow.com/questions/78727359/how-to-set-all-default-parameters-in-xgboost-or-install-an-older-version-of-xgbo</link>
      <description><![CDATA[XGBoost 将每个参数的值设置为“无”，而不是 2.1.0 文档中所述的默认值。有没有办法将所有参数设置为默认值，而无需手动分配所有参数？我上次使用 XGBoost（2022 年 9 月）时从未遇到过此问题。这个问题是此版本独有的吗？
我尝试过手动设置默认值，但我一定是错过了什么。它一直告诉我缺少一些参数。
我的代码：
xgb_model = XGBClassifier(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1,
colsample_bynode=1, colsample_bytree=1, gamma=0, device = &#39;cpu&#39;,
significance_type=&#39;gain&#39;, interaction_constraints=&#39;&#39;,
learning_rate=0.300000012, max_delta_step=0, max_depth=6,
min_child_weight=1, monotone_constraints=&#39;()&#39;,
n_estimators=100, n_jobs=12, num_parallel_tree=1,
objective=&#39;reg:squarederror&#39;, random_state=0, reg_alpha=0,
reg_lambda=1, scale_pos_weight=None, subsample=1,
tree_method=&#39;exact&#39;, verify_parameters=1, verbosity=1, max_leaves = 0)

xgb_model.fit(X_train, y_train)

输出：
XGBClassifier(base_score=0.5, booster=&#39;gbtree&#39;, callbacks=None,
colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
device=&#39;cpu&#39;, early_stopping_rounds=None,
enable_categorical=False, eval_metric=None, feature_types=None,
gamma=0, grow_policy=None, significance_type=&#39;gain&#39;,
interaction_constraints=&#39;&#39;, learning_rate=0.300000012,
max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,
max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,
missing=nan, monotone_constraints=&#39;()&#39;, multi_strategy=None,
n_estimators=100, n_jobs=12, num_parallel_tree=1,
objective=&#39;reg:squarederror&#39;, ...)

这是上面的错误消息。我甚至无法在 XGBoost 文档中找到其中一些参数的默认值。
此外，我尝试使用 pip 和“pip3 install xgboost 1.6.2”下载旧版本，但它给了我错误“找不到满足要求 1.6.2 的版本，未找到与 1.6.2 匹配的发行版”。我真的希望旧版本不会有同样的问题。
(base) PS C:\Users\myUsername&gt; pip3 install xgboost=1.6.2
错误：无效要求：“xgboost=1.6.2”
提示：= 不是有效运算符。你的意思是 == 吗？
]]></description>
      <guid>https://stackoverflow.com/questions/78727359/how-to-set-all-default-parameters-in-xgboost-or-install-an-older-version-of-xgbo</guid>
      <pubDate>Tue, 09 Jul 2024 19:05:07 GMT</pubDate>
    </item>
    <item>
      <title>Flutter/Tensorflow 形状不匹配错误</title>
      <link>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</link>
      <description><![CDATA[我正在制作一个运行 tensorflow Lite 模型的 Flutter 应用。我收到以下错误：
无法从形状为 [1, 2] 的 TensorFlowLite 张量 (Identity) 复制到形状为 [1, 215] 的 Java 对象。
背景故事：我训练过的算法使用 215 列并输出 1 或 0。下面是使用 netron.app 的屏幕截图：Netron 图
我不明白为什么这个东西想要将形状 [1,2]（输出）复制到输入 Java 类中。这个代码太高级了，我无法正确调试它。我找不到 Flutter 的 Tensorflow Lite 文档，它只描述了破坏代码的函数的输入参数。下面是出现故障的函数，错误出现在 runModelOnBinary() 函数中。有任何一般指导/帮助/经验吗？
void assessModel() async {
try {

// 生成具有 215 列的随机输入数据，以匹配预期的 860 字节输入大小
List&lt;double&gt; inputData = List.generate(215, (index) =&gt; Random().nextInt(2).toDouble());

// 将 List&lt;double&gt; 转换为 Float32List
Float32List inputBytes = Float32List.fromList(inputData);

// 将 Float32List 转换为 Uint8List
Uint8List inputUint8List = inputBytes.buffer.asUint8List();
print(inputData);
// 在输入数据上运行模型
var output = await Tflite.runModelOnBinary(
binary: inputUint8List,
numResults: 2, // 根据需要进行调整
);
print(&quot;here2&quot;);
// 处理 null 或空输出
if (output == null || output.isEmpty) {
var result = output?[0]; 
/* ChatGPT 告诉我这样做，之前将输出变量作为可打印结果。
我认为这个问题没有太大区别，因为它是在代码中断之后*/
setState(() {
_output = &quot;Predicted: ${result[&#39;label&#39;]} (${result[&#39;confidence&#39;]})&quot;;
});
} else {
setState(() {
_output = output.toString();
});
}
} catch (e) {
// 捕获任何错误并显示它们
setState(() {
_output = &quot;Error running model: $e&quot;;
});
}
}

我尝试调整 numResults 参数，查看文档，甚至 chatGippidy，建议执行 var result = output?[0]，但一切都太模糊了，没有深入介绍这个特定堆栈的工作原理。]]></description>
      <guid>https://stackoverflow.com/questions/78727055/flutter-tensorflow-missmatching-shapes-error</guid>
      <pubDate>Tue, 09 Jul 2024 17:44:04 GMT</pubDate>
    </item>
    <item>
      <title>加载模型时出错：SyntaxError：意外的标记“<”，“<!DOCTYPE”... 不是有效的 JSON</title>
      <link>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</link>
      <description><![CDATA[我正在使用 React 上的 ml5 和 p5 创建一个瑜伽 AI 训练器。
我创建了一个组件，它从本地 JSON 文件中获取单个姿势作为道具。该组件还加载我在公共文件夹中添加的模型。该组件的目标是检测某个瑜伽姿势，并且该组件动态返回从网络摄像头检测到的姿势名称。
我测试了两个网络摄像头页面。我们称之为第 1 页和第 2 页。
第 1 页有效。URL 为 /practice。第 1 页指向网络摄像头 1。网络摄像头 1 有效。
第 2 页的 URL 是 /practice/poseId。第 2 页指向不同的网络摄像头组件，网络摄像头 2 的代码与网络摄像头 1 完全相同，只是它接受一个道具，并且该道具是与 ID 匹配的特定姿势。
在第二页，我收到此错误
加载模型时出错：SyntaxError：意外的标记 &#39;&lt;&#39;、&quot;&lt;!DOCTYPE&quot;... 不是有效的 JSON

它指向此代码
 const modelInfo = {
model: &quot;model/model.json&quot;,
metadata: &quot;model/model_meta.json&quot;,
weights: &quot;model/model.weights.bin&quot;,
};

fetch(modelInfo.model)
.then((response) =&gt; {
if (!response.ok) {
throw new Error(`HTTP error! status: ${response.status}`);
}
return response.json();
})
.then((data) =&gt; {
console.log(&quot;Model JSON:&quot;, data);
brain.load(modelInfo, brainLoaded);
})
.catch((error) =&gt; {
console.error(&quot;Error loading model:&quot;, error);
});

我不明白为什么我的组件可以在 /practice URL 上运行，但是当我添加 poseId (/practice/:poseID) 时，即使代码相同，也会显示该错误。
错误出现在以 /practice/:poseId 结尾的 URL 上，例如/practice/1.
错误示例（您看不到底部的姿势标签）：

示例（如果页面 URL 为 /practice，则有效）

这是我的 repo：https://github.com/laura-nguyen/yoga-ai/tree/feature/page-pose-cam]]></description>
      <guid>https://stackoverflow.com/questions/78726907/error-loading-model-syntaxerror-unexpected-token-doctype-is-not-v</guid>
      <pubDate>Tue, 09 Jul 2024 17:06:11 GMT</pubDate>
    </item>
    <item>
      <title>在 MNIST 数据集上训练的 Tensorflow 模型在自己的测试图像上准确率较低</title>
      <link>https://stackoverflow.com/questions/78726737/tensorflow-model-trained-on-mnist-dataset-gives-low-accuracy-on-own-test-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78726737/tensorflow-model-trained-on-mnist-dataset-gives-low-accuracy-on-own-test-images</guid>
      <pubDate>Tue, 09 Jul 2024 16:26:30 GMT</pubDate>
    </item>
    <item>
      <title>Vision Transformers (ViT) - 澄清问题</title>
      <link>https://stackoverflow.com/questions/78726466/vision-transformers-vit-clarifying-question</link>
      <description><![CDATA[我在网上找到了下面的代码片段，并在 google colab 上进行了基本的图像分类训练。
有人能用简单的术语解释一下当我们执行 RandomResizedCrop、RandomHorizo​​ntalFlip、Normalize、To Tensors 时，幕后到底发生了什么吗？
来自出版物 -&gt; https://openreview.net/pdf?id=YicbFdNTTy
图像被分解成块，然后进行归一化并输入到神经网络中。
from torchvision.transforms import (CenterCrop,
Compose,
Normalize,
RandomHorizo​​ntalFlip,
RandomResizedCrop,
Resize,
ToTensor)

from transformers import ViTImageProcessor

processor = ViTImageProcessor.from_pretrained(&quot;google/vit-base-patch16-224-in21k&quot;)
image_mean = processing.image_mean
image_std = processing.image_std
size = processing.size[&quot;height&quot;]

normalize = Normalize(mean=image_mean, std=image_std)
_train_transforms = Compose(
[
RandomResizedCrop(size),
RandomHorizo​​ntalFlip(),
ToTensor(),
normalize,
]
)

_val_transforms = Compose(
[
Resize(size),
CenterCrop(size),
ToTensor(),
normalize,
]
)

def train_transforms(examples):
examples[&#39;pixel_values&#39;] = [_train_transforms(image.convert(&quot;RGB&quot;)) for image in examples[&#39;image&#39;]]
return examples

def val_transforms(examples):
examples[&#39;pixel_values&#39;] = [_val_transforms(image.convert(&quot;RGB&quot;)) for image in examples[&#39;image&#39;]]
return示例

food[&#39;train&#39;].set_transform(train_transforms)
food[&#39;test&#39;].set_transform(val_transforms)
]]></description>
      <guid>https://stackoverflow.com/questions/78726466/vision-transformers-vit-clarifying-question</guid>
      <pubDate>Tue, 09 Jul 2024 15:22:15 GMT</pubDate>
    </item>
    <item>
      <title>使用专家评分训练神经网络进行图像-文本相关性分析</title>
      <link>https://stackoverflow.com/questions/78724935/training-neural-network-for-image-text-relevance-with-expert-scores</link>
      <description><![CDATA[我有两个数据集：

第一个数据集包含由修改后的 ResNet18 模型生成的 768 维图像嵌入。删除最后的全连接层以获得特征表示而不是图像分类。输出被投影到 768 维向量空间中。

第二个数据集由 DistilBERT 生成的 768 维文本嵌入组成。


图像数据集由没有特定主题和相对中性内容的图像组成，描绘了狗在日常环境中玩耍或人们玩耍的场景。
文本数据集更加复杂。它包含图像内容的描述，每个图像都有多个描述。这些描述按从 0 到 1 的连续比例排序，反映了它们描绘图像的准确性。 0 分表示描述和图像之间没有对应关系，而 1 分表示完美匹配。
目标是开发一种搜索解决方案，允许基于预定义的文本查询进行图像检索。约束是避免使用预训练的多模态模型（如 CLIP）并从头开始设计神经网络。
对我来说，这无疑是一个多模态问题。目标是在同一空间内对齐图像和文本向量。为此，我修改了 ResNet18，并打算构建一个以描述等级作为权重初始化的神经网络。但是，我不确定这种方法的正确性。
我寻求正确的指导方向，并倾向于从头开始构建解决方案以掌握底层数学概念，而不是依赖现有模型。
我无法理解的是如何在同一空间中对齐图像向量和相应的文本向量，以便可以将其用于相似性搜索……]]></description>
      <guid>https://stackoverflow.com/questions/78724935/training-neural-network-for-image-text-relevance-with-expert-scores</guid>
      <pubDate>Tue, 09 Jul 2024 10:01:33 GMT</pubDate>
    </item>
    <item>
      <title>可以将已经经过拆分数据阶段、成为训练、验证和测试数据的图像数据集保存到我的计算机存储文件夹中吗？</title>
      <link>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</link>
      <description><![CDATA[我想问一下我做的训练、验证和测试数据的分布情况，我能把数据分布以文件夹的形式保存在存储中吗？可以吗？
如果想看完整代码
https://github.com/cendekialnazalia/CaisimPestDetection/blob/main/Percobaan%20E%20-%20CNN%20add%20Models%20Xception.ipynb
我想下载测试数据部分，也就是&quot;test_gen&quot;或者说测试数据集。我希望有人能用一个代码来回答我的问题，该代码可以将数据保存到我的电脑中，而不必从现有的数据集集合中逐个搜索图像数据。]]></description>
      <guid>https://stackoverflow.com/questions/78724858/can-save-an-image-dataset-that-has-gone-through-the-splitting-data-stage-becomin</guid>
      <pubDate>Tue, 09 Jul 2024 09:41:58 GMT</pubDate>
    </item>
    <item>
      <title>Keras Tensorflow load_model 函数需要很长时间才能加载模型</title>
      <link>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</link>
      <description><![CDATA[我使用 tensorflow 训练了一个模型（用于识别面部），然后将其保存为“facetracker.h5”。但是，当我尝试加载模型时，它只是继续加载“[*]”，如下图所示，并且实际上从未完成加载。模型（facetracker.h5）只有 68 MB，所以我是否正确地认为这不是由于它的大小而发生的？

facetracker 如下所示：
]]></description>
      <guid>https://stackoverflow.com/questions/78724780/keras-tensorflow-load-model-function-taking-forever-to-load-a-model</guid>
      <pubDate>Tue, 09 Jul 2024 09:28:15 GMT</pubDate>
    </item>
    <item>
      <title>强化学习代理没有采取现实行动</title>
      <link>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</link>
      <description><![CDATA[我在 Simulink 环境中使用 PPO 代理，但代理产生的操作似乎是离散的。具体来说，代理仅输出上限或下限。有什么想法为什么会发生这种情况？我正在使用 RL Toolbox 进行训练。
以下是有关我的设置的一些详细信息：

我正在使用带有 ode23t 求解器的可变步长 Simulink 模型。
我的 Simulink 模型使用 Simscape 库进行热流体处理并模拟简化的区域供热网络。 DHN 有 2 个分支：北 (NORD) 和南 (SUD)。
我正在尝试使用 RL 代理来优化控制，最初专注于通过改变分支中的质量流量来最小化能源成本。

关于代理的超参数，我使用具有以下参数的 RL 工具箱：
采样时间 = 3600
折扣因子 = 0.99
GPU
批次大小 = 512
学习率 = 1e-3（对于演员和评论家）

我怀疑我的模型或代理可能有问题。我将附上 Simulink 模型（应事先加载属性表）。
我尝试更改超参数，但没有任何变化。
function reward = computeReward(EBio, EGaz, Taller,Tset, Tr,Demandes,production, penalty1,penalty2)

coutBiomass = 0.04 * EBio;
coutGas = 0.1 * EGaz;

%exp(-(Tr - minTemp) / minTemp);

tempDeviation = penalty1 * abs(Taller-Tset);

unmetDemand = penalty1 * max(0, Demandes - production);

minTemp=penalty2 * exp(-(Tr - 318) / 318);

reward = - (coutBiomass + coutGas + tempDeviation + unmetDemand+minTemp);
结束

obs = rlNumericSpec([8 1]);
act = rlNumericSpec([2 1],&quot;LowerLimit&quot;,-1,&quot;UpperLimit&quot;,1);
agent=rlTD3Agent(obs,act);
env=rlSimulinkEnv(&quot;Quatrieme_Configuration_SansSolaire_RL_Training&quot;,&quot;Quatrieme_Configuration_SansSolaire_RL_Training/RL Agent&quot;,obs,act);
env.ResetFcn=@randomstart; 
env.UseFastRestart=&quot;on&quot;; 
TimeDelay=0.1; 
]]></description>
      <guid>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</guid>
      <pubDate>Tue, 09 Jul 2024 08:41:06 GMT</pubDate>
    </item>
    <item>
      <title>无法在 Roboflow 上将属性添加到类作为子类 [关闭]</title>
      <link>https://stackoverflow.com/questions/78723630/unable-to-add-attributes-to-classes-as-subclasses-on-roboflow</link>
      <description><![CDATA[我正在使用 Roboflow 注释我的视频，并尝试向标签框（类）添加属性（子类）。我检查了所有资源，最新文档表明，将属性作为子类添加到我的类的功能应该在项目设置页面中可用。但是，我似乎找不到它。
我目前正在使用免费的公共计划。这可能是我无法访问此功能的原因吗？有没有其他人遇到过这个问题？最近更新后免费版本中是否已禁用此功能？如果升级到付费计划可以解决此问题，我愿意考虑。]]></description>
      <guid>https://stackoverflow.com/questions/78723630/unable-to-add-attributes-to-classes-as-subclasses-on-roboflow</guid>
      <pubDate>Tue, 09 Jul 2024 04:00:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用混淆矩阵可视化预测样本</title>
      <link>https://stackoverflow.com/questions/78719068/how-to-visualize-predicted-samples-using-a-confusion-matrix</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78719068/how-to-visualize-predicted-samples-using-a-confusion-matrix</guid>
      <pubDate>Mon, 08 Jul 2024 04:07:24 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“keras.wrappers”的模块</title>
      <link>https://stackoverflow.com/questions/78541790/modulenotfounderror-no-module-named-keras-wrappers</link>
      <description><![CDATA[我正在尝试使用 GridSearchCV 进行机器学习分类任务，但是这行代码一直出错，有什么建议吗？
from keras.wrappers.scikit_learn import KerasClassifier

我的 tensorflow 版本是 2.16.1，我的 keras 版本是 3.3.3
我尝试了以下操作：
pip install scikeras

from scikeras.wrappers import KerasClassifier

并得到“ImportError：无法从‘sklearn.utils.deprecation’导入名称‘_deprecate_Xt_in_inverse_transform’”
如能提供任何帮助，我们将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78541790/modulenotfounderror-no-module-named-keras-wrappers</guid>
      <pubDate>Tue, 28 May 2024 03:17:40 GMT</pubDate>
    </item>
    <item>
      <title>ImportError（'无法导入 PIL.Image。'与 keras-ternsorflow 合作</title>
      <link>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</link>
      <description><![CDATA[我正在学习 lynda.com 上的一些关于在 PyCharmCE 环境中使用 Keras-TensorFlow 进行深度学习的讲座，他们没有遇到这个问题。
我收到此错误：

raise ImportError(&#39;无法导入 PIL.Image。&#39;
ImportError：无法导入 PIL.Image。使用 array_to_img 需要 PIL。

我检查过其他人是否也遇到同样的错误，但对于我来说，使用 pip 安装枕头，命令 pip install Pillow 无法解决任何问题。

MacBook-Pro-de-Rogelio:~ Rogelio$ pip install Pillow
要求已满足：./anaconda3/lib/python3.6/site-packages 中的枕头
MacBook-Pro-de-Rogelio:~ Rogelio$

有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</guid>
      <pubDate>Fri, 12 Jan 2018 11:49:58 GMT</pubDate>
    </item>
    </channel>
</rss>