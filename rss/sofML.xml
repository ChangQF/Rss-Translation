<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 15:16:17 GMT</lastBuildDate>
    <item>
      <title>使用 LLM 创建聊天机器人，用于与 Excel 或 PDF 文件交互</title>
      <link>https://stackoverflow.com/questions/78866843/create-a-chatbot-using-llm-for-interacting-with-excel-or-pdf-files</link>
      <description><![CDATA[我想创建一个聊天机器人，它可以根据我输入的 excel 或 PDF 文件回答问题。我有 AWS 基本访问权限，可以在其中使用多个模型。我的 excel 文件有 20k 行和 10 列。有人可以建议我应该使用哪个最好的 LLM 模型吗？或者如果有人可以分享一些相关资源，那将非常有帮助。提前谢谢了
我尝试了一些模型，但要么我得到了 token 错误，要么输出不准确。]]></description>
      <guid>https://stackoverflow.com/questions/78866843/create-a-chatbot-using-llm-for-interacting-with-excel-or-pdf-files</guid>
      <pubDate>Tue, 13 Aug 2024 14:26:01 GMT</pubDate>
    </item>
    <item>
      <title>AutoGluon 是否适用于文本 + 时间序列 (TS)？</title>
      <link>https://stackoverflow.com/questions/78866667/is-autogluon-for-text-time-series-ts-available</link>
      <description><![CDATA[我想根据我的自定义数据集进行多变量预测，其中包含文本和时间序列。听起来像：
input_text = &quot;....&quot; # 一个段落
input_ts = [t0, t1, ..., tn] # input_ts[t] 指的是第 t 个时间步的值
output = [0.5, 2.11, ...] # 一维浮点数组

model = ModelFromAutoMM()
pred = model(input_text, input_ts)
evaluate(pred, output)

我希望使用 AutoGluon（当前版本为 v1.1.1）构建 AutoML 管道？现在可以使用吗？
顺便说一句，我想知道是否有其他 AutoML 框架或库可以完成此任务？]]></description>
      <guid>https://stackoverflow.com/questions/78866667/is-autogluon-for-text-time-series-ts-available</guid>
      <pubDate>Tue, 13 Aug 2024 13:45:24 GMT</pubDate>
    </item>
    <item>
      <title>算法无法找到图像</title>
      <link>https://stackoverflow.com/questions/78866202/the-algorithm-cannot-find-the-images</link>
      <description><![CDATA[我正在使用 Yolo-nas 开发一种算法，我用 labelImg 准备了数据集。我使用 Python 3.10.11 和超梯度监督一起执行此算法。问题如下：算法加载数据，但在绘制图像时显示无法在目录中找到图像，我用其他算法进行了一些测试，它可以找到目录的路径。我怀疑是超梯度版本（3.7.1）

当我必须绘制训练数据时，错误开始出现
FileNotFoundError：未找到dataset\images\train\img1.png。请确保已下载数据集并且路径正确
注意：数据集中的图像是 pdf，我将它们转换为 png，以便能够在 labelImg 中使用它们并识别对象类
-我尝试更改目录
-重新制作数据集
-我检查了另一种算法是否可以搜索图像，并且它可以。
这是代码：

import torch
torch.__version__

来自 tqdm.notebook 导入 tqdm
来自 super_gradients.training 导入 dataloaders
来自 super_gradients.training.dataloaders.dataloaders 导入 coco_detection_yolo_format_train, coco_detection_yolo_format_val
来自 super_gradients.training 导入模型
来自 super_gradients.training.losses 导入 PPYoloELoss
来自super_gradients.training.metrics 导入 DetectionMetrics_050
从 super_gradients.training.models.detection_models.pp_yolo_e 导入 PPYoloEPostPredictionCallback

dataset_params = {
&#39;data_dir&#39;: &quot;nf/dataset&quot;, 
&#39;train_images_dir&#39;: &quot;dataset/images/train&quot;,
&#39;train_labels_dir&#39;: &quot;dataset/labels/train&quot;,
&#39;val_images_dir&#39;: &quot;dataset/images/val&quot;,
&#39;val_labels_dir&#39;: &quot;dataset/labels/val&quot;,
&#39;classes&#39;: [&#39;cabecalho&#39;, &#39;assinatura&#39;, &#39;rodape&#39;]
}

MODEL_ARCH = &#39;yolo_nas_l&#39;
DEVICE = &#39;cuda&#39;如果 torch.cuda.is_available() 否则 &quot;cpu&quot;
BATCH_SIZE = 10 
MAX_EPOCHS = 12
CHECKPOINT_DIR = &#39;\checkpoint&#39;
EXPERIMENT_NAME = &quot;nf&quot;

dados_treino = coco_detection_yolo_format_train(
dataset_params={
&#39;data_dir&#39;: dataset_params[&#39;data_dir&#39;],
&#39;images_dir&#39;: dataset_params[&#39;train_images_dir&#39;],
&#39;labels_dir&#39;: dataset_params[&#39;train_labels_dir&#39;],
&#39;classes&#39;: dataset_params[&#39;classes&#39;]
},
dataloader_params={
&#39;batch_size&#39;: BATCH_SIZE,
&#39;num_workers&#39;: 1
}
)

val_dados = coco_detection_yolo_format_val(
dataset_params={
&#39;data_dir&#39;: dataset_params[&#39;data_dir&#39;],
&#39;images_dir&#39;: dataset_params[&#39;val_images_dir&#39;],
&#39;labels_dir&#39;: dataset_params[&#39;val_labels_dir&#39;], 
&#39;classes&#39;: dataset_params[&#39;classes&#39;]
},
dataloader_params={
&#39;batch_size&#39;: BATCH_SIZE,
&#39;num_workers&#39;: 1
}
)

dados_treino.dataset.transforms

dados_treino.dataset.plot()

]]></description>
      <guid>https://stackoverflow.com/questions/78866202/the-algorithm-cannot-find-the-images</guid>
      <pubDate>Tue, 13 Aug 2024 12:07:15 GMT</pubDate>
    </item>
    <item>
      <title>我在尝试使用 Hampel 进行 ECG 信号分析时，在下面的代码中出现了 IndexError</title>
      <link>https://stackoverflow.com/questions/78865609/i-am-getting-indexerror-in-below-code-where-i-am-trying-to-use-hampel-for-ecg-si</link>
      <description><![CDATA[代码：
signal = signal - np.mean(signal)
# 从结果对象中提取过滤后的数据
outlier_indices = hampel(pd.Series(signal), window_size=100).filtered_data 
peaks = [list(map(itemgetter(1), g)) for k, g in groupby(enumerate(outlier_indices), lambda x: x[0] - x[1])]

# 在使用索引之前，先将其转换为整数
peaks_max_vals = [peaks[i][np.argmax(abs(signal[np.round(peaks[i]).astype(int)]))] for i in range(len(peaks))] 

peaks_sign = np.sign(signal[peaks_max_vals])

diffs_max = np.where(np.diff(peaks_max_vals) &lt; 40)[0]

zipped_list = list(zip(signal[peaks_max_vals], peaks_sign, peaks_max_vals))

to_remove = []

for i in diffs_max:
a = i + 1
if zipped_list[i][0] &gt; zipped_list[a][0] and zipped_list[i][1] == zipped_list[a][1]:
to_remove.append(a)
elif zipped_list[i][0] &lt; zipped_list[a][0] 和 zipped_list[i][1] == zipped_list[a][1]:
to_remove.append(i)

for index in sorted(to_remove, reverse=True):
peaks_max_vals.pop(index)

错误：

IndexError Traceback (most recent call
last) in &lt;cell line: 9&gt;()
7 peaks_max_vals = [peaks[i][np.argmax(abs(signal[np.round(peaks[i]).astype(int)]))] for
i in range(len(peaks))]
8
----&gt; 9 peaks_sign = np.sign(signal[peaks_max_vals])
10
11 diffs_max = np.where(np.diff(peaks_max_vals) &lt; 40)[0]
IndexError：只有整数、切片 (:)、省略号 (...)、numpy.newaxis (None) 和整数或布尔数组才是有效索引
]]></description>
      <guid>https://stackoverflow.com/questions/78865609/i-am-getting-indexerror-in-below-code-where-i-am-trying-to-use-hampel-for-ecg-si</guid>
      <pubDate>Tue, 13 Aug 2024 10:01:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用文本数据集训练模型</title>
      <link>https://stackoverflow.com/questions/78865593/how-to-train-a-model-using-a-text-dataset</link>
      <description><![CDATA[我想创建一个生成文本的 AI 模型。具体来说，BDD Gherkin 黄瓜场景和步骤定义基于用户故事的输入。
带有 BDD Gherkin 黄瓜示例的用户故事
例如。
用户故事（输入）：我想在电子商务网站上将产品添加到我的购物篮中进行购买。
输出：自动创建测试用例场景和步骤定义
测试用例场景：

场景 1：验证用户是否可以将一个商品添加到购物车
场景 2：验证用户是否可以从购物车中移除一个商品

测试用例场景 1：

假设用户使用和启动并登录电子商务应用程序
然后用户导航到商品页面。
然后用户选择并单击。
然后用户单击“添加到购物车”按钮。
然后用户应导航到购物车页面。
然后用户应验证购物车页面已成功添加。

测试用例场景 2：

假设用户使用 启动并登录电子商务应用程序 
然后用户应导航到购物车页面。
然后用户在购物车中找到并单击“从购物车中移除”按钮。
然后用户应验证购物车已成功移除。

我创建了一个示例数据集，其中包含映射到场景和步骤定义的用户故事。
数据集
就我目前的理解，逻辑是：我想基于现有用户故事和场景的数据集训练一个模型。在模型训练完成后，我想输入一个用户故事，模型应该提出一个带有步骤定义的合适场景。
我是机器学习的新手，只做过某种形式的监督学习、回归。从一些研究中，我需要使用一些 NLP 技术来处理数据集。从那时起，我就很迷茫。我看到一些人谈论使用 ChatGPT 来训练数据集之类的东西。
做这个项目的好方法是什么。
本质上，我想找出如何使用文本训练模型，以便模型可以接收文本并输出文本。]]></description>
      <guid>https://stackoverflow.com/questions/78865593/how-to-train-a-model-using-a-text-dataset</guid>
      <pubDate>Tue, 13 Aug 2024 09:59:03 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace 运行评估时加速设备错误</title>
      <link>https://stackoverflow.com/questions/78865570/huggingface-accelerate-device-error-when-running-evaluation</link>
      <description><![CDATA[我正在多 GPU 集群上运行一些实验，并且正在使用加速。我试图在训练数据加载器中每次批量迭代后计算一些指标。虽然训练代码似乎使用加速运行良好（它利用多个 GPU），但在尝试计算上述指标时我遇到了错误。似乎在执行前向传递后，评估输出张量时将其放在与输入张量不同的设备上。给出错误的代码如下：
def calculatePerplexity(sentence, model, tokenizer, accelerater):
&quot;&quot;&quot;
exp(loss)
&quot;&quot;&quot;
... input_ids = torch.tensor(sentence).unsqueeze(0)
print(f&quot;输入 ids 设备：{input_ids.device}&quot;)
model.eval()
with torch.no_grad():
output = model(input_ids, labels=input_ids)
output = accelerater.gather_for_metrics(outputs)
loss, logits = output[:2]
loss, logits = accelerater.prepare(loss, logits)
print(f&quot;损失设备：{loss.device}&quot;)
print(f&#39;模型设备：{model.device}&#39;)
print(f&#39;Logits 设备：{logits.device}&#39;)

probabilities = torch.nn. functional.softmax(logits, dim=-1)
all_prob = []
input_ids_processed = input_ids[0][1:]
for i, token_id in enumerate(input_ids_processed):
probability = probabilities[0, i, token_id].item()
all_prob.append(probability)

# 用于度量计算的内容
probs = torch.nn. functional.softmax(logits[0, :-1], dim=-1)
log_probs = torch.nn. functional.log_softmax(logits[0, :-1], dim=-1)
token_log_probs = log_probs.gather(dim=-1, index=input_ids_processed.unsqueeze(-1)).squeeze(-1)
mu = (probs * log_probs).sum(-1)
sigma = (probs * torch.square(log_probs)).sum(-1) - torch.square(mu)
mink_plus = (token_log_probs - mu) / sigma.sqrt()

调试语句的输出如下：
输入 ids 设备：cpu
丢失设备：cuda：0
模型设备：cpu
Logits 设备：cuda：0

对于我使用的 4 个不同的 GPU，情况都一样，这会导致以下错误：
token_log_probs = log_probs.gather(dim=-1, index=input_ids_processed.unsqueeze(-1)).squeeze(-1)
[rank2]: ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank2]: RuntimeError：预期所有张量都在同一设备上，但发​​现至少两个设备，cuda:0 和 cpu！（在方法 wrapper_CUDA_gather 中检查参数索引的参数时）

我不确定我在这里做错了什么，我认为使用 gather_for_metrics 方法或在损失和对数上调用 accelerator.prepare 会有所帮助，但事实并非如此（删除这些语句时我收到相同的错误）。任何建议都将不胜感激！
为了完整起见，以下是我在计算指标时使用的其余（相关）代码：
# 训练循环
for i, (batch_inputs, batch_labels) in tqdm(enumerate(dataloader)):
all_labels += batch_labels

unlearned_model, tokenizer = load_base_model(self.experiment_args.model_dir_prefix, self.experiment_args.model)
torch.cuda.empty_cache()

optimizer = torch.optim.Adam(unlearned_model.parameters(), lr=self.unlearning_args.lr)
unlearned_model, optimizer, batch_inputs = accelerater.prepare(unlearned_model, optimizer, batch_inputs)
# 取消学习数据并计算 PPL 值
for i in range(self.unlearning_args.steps):
unlearned_model = unlearn_dataslice(unlearned_model, optimizer, batch_inputs, self.unlearning_args, accelerater)

torch.cuda.empty_cache()
UL_PPL_vals += calculate_PPL_values(unlearned_model, tokenizer, batch_inputs, accelerater)

def unlearn_dataslice(model, optimizer, sentences, args, accelerater):
learning_rate = args.lr
model.train()

optimizer.zero_grad()
input_data = sentences.clone().detach()

output = model(input_data)
# 添加一个减号，使梯度上升而不是下降
loss = -output[0][&#39;logits&#39;]
accelerater.backward(loss.mean())
torch.cuda.empty_cache()
optimizer.step()
del optimizer
torch.cuda.empty_cache()
返回模型

def calculate_PPL_values(model, tokenizer, text_batch, accelerater):
PPL_values = []
for text in text_batch:
PPL = calculatePerplexity(text, model, tokenizer, accelerater)[0]
PPL_values.append(PPL)
返回 PPL_values

在此代码中，我删除了许多调试语句，这些语句检查了 unlearned_model 和 batch_inputs 的设备在整个训练循环中是否位于同一设备 cpu 上，因此我很确定那里没有不一致之处。]]></description>
      <guid>https://stackoverflow.com/questions/78865570/huggingface-accelerate-device-error-when-running-evaluation</guid>
      <pubDate>Tue, 13 Aug 2024 09:54:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在 CPU 上使用 Meta 的 MusicGen 加速音乐生成？初学者最实惠的选择是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/78864824/how-can-i-speed-up-music-generation-with-metas-musicgen-on-a-cpu-best-affordab</link>
      <description><![CDATA[我目前有一个微服务，它使用 Audiocraft 的 MusicGen (Meta) 根据文本输入生成音乐。当我在没有 GPU 的本地机器上运行该服务时，生成音乐大约需要 9 分钟。我研究过使用带 GPU 的 AWS EC2 实例、支持 NVIDIA GPU 的 Docker 等选项，但我不确定对于不想在这个副业上花太多钱的初学者来说哪个是最佳选择。关于如何经济高效地加快这一过程，有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78864824/how-can-i-speed-up-music-generation-with-metas-musicgen-on-a-cpu-best-affordab</guid>
      <pubDate>Tue, 13 Aug 2024 07:02:47 GMT</pubDate>
    </item>
    <item>
      <title>如何更新已经微调的 GPT2 模型</title>
      <link>https://stackoverflow.com/questions/78864545/how-to-update-already-finetuned-model-of-gpt2</link>
      <description><![CDATA[我已经使用 Transformers GPT-2 针对我的数据集训练了我的模型。我已经训练过并给出了正确的输出。现在我想在保留之前训练过的模型的同时，在更多数据上训练我的模型。我不想创建新的模型，只想使用更新的数据训练之前的模型。
我尝试在训练中使用“overwrite = False”，但我不知道它是否会起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78864545/how-to-update-already-finetuned-model-of-gpt2</guid>
      <pubDate>Tue, 13 Aug 2024 05:44:48 GMT</pubDate>
    </item>
    <item>
      <title>使用 Ultralytics YOLOv8 时边界框/图像检测不准确</title>
      <link>https://stackoverflow.com/questions/78864290/bounding-boxes-image-detection-are-inaccurate-when-using-ultralytics-yolov8</link>
      <description><![CDATA[使用 yolov8x-obb 时，边界框和图像检测不准确。如何解决此问题？
这是我的代码
from ultralytics import YOLO

model = YOLO(&#39;yolov8x-obb&#39;)

results = model(&quot;boat.jpg&quot;, save=True, show=True)

这是我的结果：船图片]]></description>
      <guid>https://stackoverflow.com/questions/78864290/bounding-boxes-image-detection-are-inaccurate-when-using-ultralytics-yolov8</guid>
      <pubDate>Tue, 13 Aug 2024 03:38:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Scikit-Learn 为分类变量选择参考水平？</title>
      <link>https://stackoverflow.com/questions/78864148/how-to-select-a-reference-level-for-categorical-variables-using-scikit-learn</link>
      <description><![CDATA[我正在尝试将代码从 SAS 转换为训练 GLM 的 Python。为此，我使用带有 CLASS 字的 hpgenselect 来处理分类变量。在 SAS 中，我可以选择模型所需的任何分类变量的参考级别。参考级别是将接收值 0 的类别，并且将成为其他变量进行比较的参考。
我搜索过，但没有在 Scikit-Learn 中找到类似的方法。有没有办法在 scikit-learn 或其他 Python 库中选择参考？]]></description>
      <guid>https://stackoverflow.com/questions/78864148/how-to-select-a-reference-level-for-categorical-variables-using-scikit-learn</guid>
      <pubDate>Tue, 13 Aug 2024 02:19:55 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML 二元分类模型的最终预测准确率非常糟糕</title>
      <link>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</guid>
      <pubDate>Mon, 12 Aug 2024 23:32:18 GMT</pubDate>
    </item>
    <item>
      <title>我们如何运行 Apple 雪貂模型？</title>
      <link>https://stackoverflow.com/questions/78863794/how-do-we-run-the-apple-ferret-model</link>
      <description><![CDATA[我已经安装了苹果雪貂模型所需的所有权重和检查点，除了运行 3 个终端并测试演示之外，我如何在本地运行模型来为图像文件夹添加标题？
谢谢！
我尝试了https://vivekupadhyay1.medium.com/how-to-use-ferret-apples-open-source-multimodal-llm-for-your-next-project-c561f0087a5d，但无法找到 github repo 中提到的 eval.py 或脚本。]]></description>
      <guid>https://stackoverflow.com/questions/78863794/how-do-we-run-the-apple-ferret-model</guid>
      <pubDate>Mon, 12 Aug 2024 22:36:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么我不能用 C++ 构建一个没有依赖关系的神经网络，即使它可以在 Numpy 中运行？</title>
      <link>https://stackoverflow.com/questions/78862784/why-cant-i-build-a-neural-network-in-c-with-no-dependencies-even-though-it-w</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862784/why-cant-i-build-a-neural-network-in-c-with-no-dependencies-even-though-it-w</guid>
      <pubDate>Mon, 12 Aug 2024 16:55:51 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 nltk 函数</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>优化大数据集上的 Pandas 性能</title>
      <link>https://stackoverflow.com/questions/78752483/optimizing-pandas-performance-on-large-datasets</link>
      <description><![CDATA[我正在使用 pandas 处理一个大型数据集（约 1000 万行和 50 列），在数据操作和分析过程中遇到了严重的性能问题。这些操作包括过滤、合并和聚合数据，目前执行时间太长。
我读过几种优化技术，但不确定哪种技术最有效且适用于我的情况。以下是有关我的工作流程的一些细节：
我主要使用 pandas 进行数据清理、转换和分析。
我的操作包括多个 groupby 和 apply 函数。
我在一台具有 16GB RAM 的机器上运行分析。
社区能否分享优化 pandas 在大型数据集上的性能的最佳实践？
1.内存管理技术。
2.执行 groupby 和 apply 的有效方法。
3.处理大型数据集的 pandas 替代方案。
4. 有没有关于并行处理或有效利用多核的技巧。
我主要使用 pandas 进行数据清理、转换和分析。
我的操作包括多个 groupby 和 apply 函数。
我在一台有 16GB RAM 的机器上运行分析。]]></description>
      <guid>https://stackoverflow.com/questions/78752483/optimizing-pandas-performance-on-large-datasets</guid>
      <pubDate>Tue, 16 Jul 2024 02:24:48 GMT</pubDate>
    </item>
    </channel>
</rss>