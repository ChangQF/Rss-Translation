<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 28 Nov 2023 12:26:25 GMT</lastBuildDate>
    <item>
      <title>修改 tidytext get_sentiments() 中某些单词的情感</title>
      <link>https://stackoverflow.com/questions/77563423/modifying-the-sentiment-of-certain-words-in-tidytext-get-sentiments</link>
      <description><![CDATA[我正在尝试修改 df 中一些特定单词的情绪，使它们更适合我的上下文，这些单词在我的上下文中使用时带有负面含义，但已被归类为具有积极情绪。这两个字就是“人才”。和“更喜欢”。
这是我的代码：
#加载包
图书馆（dplyr）
库（ggplot2）
需要（读xl）
图书馆（整洁的文本）
需要（writexl）

数据示例：
dput(sentiment_words[1:20,c(7,8,9)])

数据输出：
struction(list(word = c(“天赋”, “更喜欢”, “谎言”, “困难”, “更糟”,
“瘾君子”、“令人讨厌的”、“难以忍受的”、“令人作呕的”、“令人恼火的”、
“奇怪”、“不体贴”、“奇怪”、“压倒性”、“问题”、“投诉”、
“受限”、“爱”、“受限”、“白痴”)、情绪 = c(“积极”、
“阳性”、“阴性”、“阴性”、“阴性”、“阴性”、“阴性”、
“阴性”、“阴性”、“阴性”、“阴性”、“阴性”、“阴性”、
“阴性”、“阴性”、“阴性”、“阴性”、“阳性”、“阴性”、
“负”)，计数＝c(79L，3L，53L，316L，2L，2L，3L，2L，2L，
7L、24L、2L、24L、2L、198L、21L、4L、52L、4L、19L))，类别=c(“grouped_df”，
“tbl_df”、“tbl”、“data.frame”)、row.names = c(NA，-20L)、groups = 结构(列表(
    word = c(“瘾君子”, “抱怨”, “禁闭”, “ftw”, “困难”,
    “白痴”、“不体贴”、“令人恼火”、“问题”、“谎言”、
    “迷失”、“爱”、“讨厌”、“压倒性”、“令人作呕”、
    “难以忍受”、“奇怪”、“更糟”), .rows = Structure(list(
        6L、16L、C(17L、19L)、2L、4L、20L、12L、10L、15L、3L、
        1L、18L、7L、14L、9L、8L、c(11L、13L)、5L)，ptype = 整数(0)，类 = c(“vctrs_list_of”，
    “vctrs_vctr”，“列表”)))，class = c(“tbl_df”，“tbl”，“data.frame”)
), row.names = c(NA, -18L), .drop = TRUE))

 ###### Word 情感分析 ######
## 使用“TIDYTEXT”情感词典
情感词&lt;- df |&gt;
  tidytext::unnest_tokens(输出=“单词”，输入=“帖子”) |&gt;
  dplyr::anti_join(tidytext::stop_words)|&gt;
  dplyr::inner_join(tidytext::get_sentiments(“bing”))

情感词%&gt;%
  计数（单词，排序= TRUE）

# 检查最常见的正面和负面词
情感词&lt;-
情感词 %&gt;% group_by(word) %&gt;% mutate(count = n())
 
bing_word_counts &lt;-情感词 %&gt;%
  dplyr::inner_join(tidytext::get_sentiments(“bing”) %&gt;%
  计数（单词、情感、排序 = TRUE））
]]></description>
      <guid>https://stackoverflow.com/questions/77563423/modifying-the-sentiment-of-certain-words-in-tidytext-get-sentiments</guid>
      <pubDate>Tue, 28 Nov 2023 11:13:39 GMT</pubDate>
    </item>
    <item>
      <title>通过 ImageDataGenerator 在 Tensorflow 中保存每个时期的批量图像</title>
      <link>https://stackoverflow.com/questions/77563371/save-batches-of-images-for-each-epochs-in-tensorflow-via-imagedatagenerator</link>
      <description><![CDATA[我使用 Tensorflow 中的 ImageDataGenerator 函数创建批量图像。 
我知道，根据 ImageDataGenerator 随机应用于我的数据集的不同转换，每个时期的每批图像都略有不同。
datagen_full_data_aug = ImageDataGenerator(**data_full_aug)

train_generator_images=datagen_full_data_aug.flow_from_dataframe(
    数据框=火车，
    目录=文件夹图像，
    x_col=&#39;文件名&#39;,
    类模式=无，
    随机播放=真，
    种子=种子，
    批量大小=批量大小，
    目标大小=（图像大小，图像大小））

这就是我训练/拟合模型的方式。
history=model.fit(train_generator,
                  步骤_per_epoch=步骤_per_epoch，
                  纪元=纪元，
                  详细=2，
                  验证数据=验证生成器，
                  valid_steps=val_steps_per_epoch,
                  回调=[检查点],
                  批次大小 = 批次大小）

在特定时期的训练过程中，我的准确性有时会出现一些变化。 
IoU-准确率波动
我想将每个时期的单独批次图像保存在不同的文件夹中（如 epoch_1、epoch_2...等），以便我可以分析哪些图像可能导致准确性波动如此之大。 而且我将能够得出哪些转变可能影响了特定时期的模型。 
如果每个图像都可以重复使用我的数据集中给出的名称来对 puproses 进行排序，那就太好了。 
我应该如何进行？
我尝试了保存功能：
 save_to_dir=无，
    save_prefix=&#39;&#39;,
    save_format=&#39;png&#39;,

但这会将所有历元的所有图像保存到一个文件夹中。我们无法区分第 1 纪元和第 2 纪元的图像......等等。]]></description>
      <guid>https://stackoverflow.com/questions/77563371/save-batches-of-images-for-each-epochs-in-tensorflow-via-imagedatagenerator</guid>
      <pubDate>Tue, 28 Nov 2023 11:05:17 GMT</pubDate>
    </item>
    <item>
      <title>累积时间序列数据集的插补</title>
      <link>https://stackoverflow.com/questions/77562836/imputation-for-cumulative-times-series-dataset</link>
      <description><![CDATA[我想估算一个累积时间序列数据集，如下所示：
累积数据集
每列是降雨量的累计总和。
我尝试过 GAIN 方法来估算该数据集；然而，结果并不像我的预期。我得到的损失非常低，但是插补后的数据集有一些错误，如下所示：
插补后的错误
我想询问处理此类数据集的一些方法。]]></description>
      <guid>https://stackoverflow.com/questions/77562836/imputation-for-cumulative-times-series-dataset</guid>
      <pubDate>Tue, 28 Nov 2023 09:51:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么图像、音视频、文本被视为非结构化数据？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77562031/why-images-audio-video-clips-text-are-regarded-as-unstructured-data</link>
      <description><![CDATA[一般来说，在机器学习或数据科学中，表格数据被视为结构化数据，而其他数据类型（例如图像、音频/视频剪辑、文本等）被视为非结构化数据。
我很困惑，以图像为例，它们只是以矩阵或高维张量的形式存储在计算机中，显然具有一定的结构，为什么还称为非结构化数据？
与其他类型的数据类似，这些数据都是数字化的，因此具有各种存储结构以便计算机轻松读取和处理，为什么它们都被视为非结构化数据？
所以我想知道非结构化数据和表格数据（结构化数据）之间的本质区别是什么。]]></description>
      <guid>https://stackoverflow.com/questions/77562031/why-images-audio-video-clips-text-are-regarded-as-unstructured-data</guid>
      <pubDate>Tue, 28 Nov 2023 07:39:15 GMT</pubDate>
    </item>
    <item>
      <title>ML-DL 图像（表单）验证</title>
      <link>https://stackoverflow.com/questions/77561863/ml-dl-image-form-validation</link>
      <description><![CDATA[我有一个图像，它是表单的屏幕截图，我想创建一个模型，将图像作为输入并验证它是否具有相同的表单结构。
我读到 CNN 可能有帮助，或者图像相似性也可能是最好的方法
另一种思考方法是从图像中提取测试并与输入图像中的文本进行比较
所以有什么建议我应该搜索哪些主题来定义和解决这个问题
我尝试开始将标记图像作为数据集来标记表单标题和部分，但不确定这是否有用]]></description>
      <guid>https://stackoverflow.com/questions/77561863/ml-dl-image-form-validation</guid>
      <pubDate>Tue, 28 Nov 2023 07:00:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用tensorflow训练ML模型进行人脸比较并在java中使用它？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77561597/how-to-train-a-ml-model-for-face-comparison-using-tensorflow-and-use-it-in-java</link>
      <description><![CDATA[我想比较两张脸，无论它们是否是同一个人。为此，我使用预先训练的模型 (FaceNet) 来获取面部嵌入并比较两个面部。
为了使用 FaceNet 模型，我使用了这个 github 链接。但我无法这样做，因为它是 5 年前的代码，给我带来了折旧错误。
我有 LFW 数据集（成对的图像），我想自己训练一个模型，并想用它在 java 中比较人脸（使用人脸嵌入）。
如何使用tensorflow训练模型并在java中使用它进行人脸比较？]]></description>
      <guid>https://stackoverflow.com/questions/77561597/how-to-train-a-ml-model-for-face-comparison-using-tensorflow-and-use-it-in-java</guid>
      <pubDate>Tue, 28 Nov 2023 05:46:10 GMT</pubDate>
    </item>
    <item>
      <title>用于线性回归的随机梯度下降算法的意外输出</title>
      <link>https://stackoverflow.com/questions/77560377/unexpected-output-with-stochastic-gradient-descent-algorithm-for-linear-regressi</link>
      <description><![CDATA[在为我的 ML 作业实现 SGD 算法时，我得到了意外的输出。
这是我的训练数据的一部分，通常有 320 行：

我的数据集：https://github.com/Jangrae/csv/ blob/master/carseats.csv
我首先做了一些数据预处理：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 StandardScaler
将 numpy 导入为 np

train_data = pd.read_csv(&#39;carseats_train.csv&#39;)
train_data.replace({&#39;是&#39;: 1, &#39;否&#39;: 0}, inplace=True)
onehot_tr = pd.get_dummies(train_data[&#39;ShelveLoc&#39;], dtype=int, prefix_sep=&#39;_&#39;, prefix=&#39;ShelveLoc&#39;)
train_data = train_data.drop(&#39;ShelveLoc&#39;, axis=1)
train_data = train_data.join(onehot_tr)


train_data_Y = train_data.iloc[:, 0]
train_data_X = train_data.drop(&#39;销售额&#39;, axis=1)


然后实现这样的算法：
&lt;前&gt;&lt;代码&gt;学习率 = 0.01
epoch_num = 50
初始w = 0.1
截距 = 0.1
w_matrix = np.ones((12, 1)) * 初始w

对于范围内的 e（epoch_num）：
    对于范围内的 i(len(train_data_X))：

        x_i = train_data_X.iloc[i].to_numpy()
        y_i = train_data_Y.iloc[i]
        
        y_估计 = np.dot(x_i, w_matrix) + 截距
        
        grad_w = x_i.reshape(-1, 1) * (y_i - y_估计)
    
        grad_intercept = (y_i - y_估计)
        
       
        w_matrix = w_matrix - 2 * 学习率 * grad_w
        截距 = 截距 - 2 * 学习率 * 梯度截距
        
        

print(&quot;最终权重：\n&quot;, w_matrix)
print(&quot;最终拦截：&quot;,拦截)

但是输出是
最终权重：
 [[南]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]
 [楠]]
最终截距：[nan]

我用不同的学习率运行它，我也尝试了收敛阈值，但仍然得到相同的结果..我不明白为什么我的代码给了我nans..
有人能看到这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77560377/unexpected-output-with-stochastic-gradient-descent-algorithm-for-linear-regressi</guid>
      <pubDate>Mon, 27 Nov 2023 22:46:46 GMT</pubDate>
    </item>
    <item>
      <title>如何提取给定文档集的顶级分类器特征</title>
      <link>https://stackoverflow.com/questions/77560320/how-to-extract-top-classifier-features-for-a-given-set-of-documents</link>
      <description><![CDATA[我有一个经过二元分类任务训练的逻辑回归分类器。我想提取 X 中给定文档集的顶级分类器特征（信息最丰富的系数）。这些文档的索引存储在名为 idx_list 的列表中。
我尝试使用以下代码提取 X 中所有文档的主要特征：
 def most_informative_feature_for_binary_classification（分类器，向量化器，n=20）：
        类标签 = 分类器.classes_
        feature_names = vectorizer.get_feature_names_out()
        topn_class1 = 排序(zip(classifier.coef_[0], feature_names))[:n]
        topn_class2 = 排序(zip(classifier.coef_[0], feature_names))[-n:]
        print(&#39;0 类主要功能： ----------------------&#39;)
        class0_feat =[]
        对于 coef，topn_class1 中的壮举：
            #print (class_labels[0], coef, feat)
            打印（壮举）
            class0_feat.append(feat )
    
        class0_feat = [str(x) for x in class0_feat]
        使用 open(&#39;../../classification/result/class0_top_features_top_&#39;+str(top_features_nb)+&#39;_&#39;+network+&#39;.txt&#39;,&#39;w&#39;) 作为 f：
            f.write(&#39;\n&#39;.join(class0_feat))
        
        print(&#39;1 类主要功能： ----------------------&#39;)
        class1_feat = []
        对于 coef，相反的壮举（topn_class2）：
            #print (class_labels[1], coef, feat)
            打印（壮举）
            class1_feat.append(壮举)

此代码适用于提取 X 中所有文档的主要特征，但我想提取 idx_list 定义的一组特定文档的主要特征。
使用 Sklearn 对文本文档进行分类：
向量化器 = TfidfVectorizer(input=&#39;文件名&#39;, min_df=mindf, max_df = maxdf)
        X = 矢量化器.fit_transform(friend_files)
        
        print(&quot;X 形状：&quot;,X.shape)

        y = list(username_labels.values()) # 0 或 1

        clf = 逻辑回归()

        clf.fit(X, y)
        most_informative_feature_for_binary_classification3（clf，矢量化器，n=10）

如何修改代码以提取 idx_list 指定文档的顶级特征？]]></description>
      <guid>https://stackoverflow.com/questions/77560320/how-to-extract-top-classifier-features-for-a-given-set-of-documents</guid>
      <pubDate>Mon, 27 Nov 2023 22:32:30 GMT</pubDate>
    </item>
    <item>
      <title>神经网络意外预测</title>
      <link>https://stackoverflow.com/questions/77560144/neuralnet-unexpected-prediction</link>
      <description><![CDATA[我试图了解神经网络包是如何工作的。
我使用的是 mnist 数据集，其中包含对应于不同图片的 60.000 行和代表图片每个像素的 785 列（除了第一个像素）
与图片标签对应的列）。
initial_data &lt;- read.csv(file = &#39;train.csv&#39;, header = TRUE)

数据如下所示：
 标签 Pixel1 Pixel2 Pixel3 Pixel4 Pixel5 Pixel6 ...
1 5 0 0 3 0 1 0 ...
2 3 0 0 0 7 0 0 ...
ETC

首先，我删除方差等于 0 的像素。因为它们无法提供评估图片中写入的数字的信息。
filtered_data &lt;-initial_data %&gt;%
  select_if(函数(列) var(列) != 0)

# 显示新过滤数据的维度
暗淡（过滤数据）

然后我对数据进行标准化，以确保每个功能的贡献相同
到模型中，算法不受较大尺度特征的影响。
filtered_data &lt;- as.data.frame(scale(filtered_data[-1]))

现在我进行数据分区（80% 训练和 20% 测试）。
filtered_data$label &lt;-initial_data$label
filtered_data &lt;-filtered_data %&gt;% select(标签, everything())
索引 &lt;- createDataPartition(filtered_data$label, p = 0.8, list = FALSE)

# 创建训练集和验证集
训练数据&lt;-过滤数据[索引，]
validation_data &lt;-filtered_data[-index, ]

# 通过预测变量和标签分隔
训练数据X &lt;- 训练数据[-1]
训练数据Y &lt;- 训练数据[1]
validation_data_X &lt;-validation_data[-1]
validation_data_Y &lt;-validation_data[1]

现在我生成一个非常简单的神经网络并进行预测
input_variables &lt;- 粘贴（名称（training_data_X），collapse =＆quot; +＆quot;）
输出变量 &lt;- 名称(training_data_Y)[1]
content_formula &lt;- 粘贴（输出变量，“~”，输入变量）

simple_nn_model &lt;- 神经网络（内容公式，数据 = 训练数据，隐藏 = 1，
                             act.fct =“逻辑”，线性输出= FALSE）

Predictions_simple_model &lt;- 预测（simple_nn_model，newdata =validation_data_X）

问题：我希望对象predictions_simple_model包含10列（每列代表0到9之间的一个数字），并且它们的值范围应该从0到1（取决于预测者所做的预测）模型）。但是，相反，我获得了一列，并且它们的所有值都等于 1。
&lt;前&gt;&lt;代码&gt;&gt;预测简单模型
           [,1]
137 1.0000000
171 1.0000000
213 1.0000000
225 1.0000000
236 1.0000000
420 1.0000000
第576章 1.0000000
615 1.0000000
899 1.0000000
ETC

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77560144/neuralnet-unexpected-prediction</guid>
      <pubDate>Mon, 27 Nov 2023 21:52:43 GMT</pubDate>
    </item>
    <item>
      <title>将 pyspark 数据帧保存为 RecordIO protobuf</title>
      <link>https://stackoverflow.com/questions/77559860/save-pyspark-dataframe-as-recordio-protobuf</link>
      <description><![CDATA[我想以 RecordIO protobuf 格式保存我的 pyspark 数据帧。我正在使用 Amazon EMR 运行我的 pyspark 脚本，并且我想使用 AWS SageMaker 来训练机器学习模型。
SageMaker 管道模式仅接受 RecordIO protobuf 作为输入，因此我的问题
我尝试将我的 pyspark 数据帧保存为 recordio protobuf，如下所示：
output_path = f“s3://my_path/output_processed”
df_transformed.write.format(“sagemaker”).mode(“覆盖”).save(output_path)

但是当我运行 sagemaker 模型时，即使我的数据帧没有缺失值，我也会收到缺失值的错误。可能是什么问题以及如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77559860/save-pyspark-dataframe-as-recordio-protobuf</guid>
      <pubDate>Mon, 27 Nov 2023 20:49:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在 argparse 中为 AzureML 中的管道添加元组？</title>
      <link>https://stackoverflow.com/questions/77459218/how-to-add-tuple-in-argparse-for-the-pipeline-in-azureml</link>
      <description><![CDATA[我想对我在管道中执行的函数进行argparse元组。为了简单起见，我将跳过读取数据和其他与主题不太相关的步骤。看起来像这样：
def model_train_sales(X_train, order: tuple,seasonal_order: tuple):

    模型 = sm.tsa.SARIMAX(X_train[&#39;sales&#39;], order=order,seasonal_order=seasonal_order)
    结果 = model.fit()

    返回模型、结果

def main():

    解析器 = argparse.ArgumentParser()

    parser.add_argument(&quot;--order&quot;, type=tuple)
    parser.add_argument(&quot;--seasonal_order&quot;, type=tuple)

    args = parser.parse_args()

    模型，结果 = model_train_sales(X_train[&#39;sales&#39;], order=args.order,
    seasonal_order=args.seasonal_order)

此时一切都很好，但是当您开始构建管道时，解析变量的类型不同。
来自 azure.ai.ml 导入命令
从 azure.ai.ml 导入输入、输出

演示模型训练组件 = 命令（
    name=&#39;我的萨里玛管道&#39;,
    display_name=&#39;我的描述&#39;,
    description=&#39;长描述。&#39;,
    输入={
        “订单”：输入（类型=&#39;&lt;类型&gt;&#39;），
        “seasonal_order”：输入（type=&#39;&#39;），
    },
    输出=字典（
        df = 输出（类型=“uri_folder”，模式=“rw_mount”）
    ),
    代码 = feature_creation_src_dir,
    命令=“”“python sarima_model.py \
              --order ${{inputs.order}} --seasonal_order ${{inputs.seasonal_order}} \
              --df ${{输出.df}}
              ”“”，
    环境= f“{pipeline_job_env.name}”{pipeline_job_env.version}”，
）

在这里，我在处签名了我不确定应该是哪种类型的地方。我知道类型是有限的，可以是 string、integer、number 或 bool。
有什么方法可以解析其中的元组吗？或者唯一的方法是分别解析 p, d, q 和 P, D, Q, S 并将它们组合成主函数中的元组？]]></description>
      <guid>https://stackoverflow.com/questions/77459218/how-to-add-tuple-in-argparse-for-the-pipeline-in-azureml</guid>
      <pubDate>Fri, 10 Nov 2023 10:17:33 GMT</pubDate>
    </item>
    <item>
      <title>在单个虚拟机中使用 mlflow 为多个 ML 模型提供服务</title>
      <link>https://stackoverflow.com/questions/70620074/serving-multiple-ml-models-using-mlflow-in-a-single-vm</link>
      <description><![CDATA[我已在虚拟机中设置了 mlflow 服务，并且可以使用 mlflowserve 命令为模型提供服务。
想知道我们是否可以在单个虚拟机中托管多个模型？
我正在使用以下命令在虚拟机中使用 mlflow 来提供模型。
命令：
/mlflow 模型服务 -m 模型:/$模型名称/$版本 --no-conda -p 443 -h 0.0.0.0

以上命令创建一个模型服务并在 443 端口上运行它。
是否可以使用其中的模型名称创建如下所示的端点？
当前网址：
https://localhost:443/incalls
预期网址：
https://localhost:443/模型名称/调用？]]></description>
      <guid>https://stackoverflow.com/questions/70620074/serving-multiple-ml-models-using-mlflow-in-a-single-vm</guid>
      <pubDate>Fri, 07 Jan 2022 10:48:20 GMT</pubDate>
    </item>
    <item>
      <title>错误：尝试在自定义 HF 数据集上使用 trainer.train() 时，vars() 参数必须具有 __dict__ 属性？</title>
      <link>https://stackoverflow.com/questions/69539538/error-vars-argument-must-have-dict-attribute-when-trying-to-use-trainer-t</link>
      <description><![CDATA[我有以下模型正在尝试微调（CLIP_ViT + 分类头）。这是我的模型定义：
CLIPNN 类（nn.Module）：

    def __init__(self, num_labels, pretrained_name=“openai/clip-vit-base-patch32”, dropout=0.1):
        超级().__init__()
        self.num_labels = num_labels
        # 加载预训练的 Transformer &amp;处理器
        self.transformer = CLIPVisionModel.from_pretrained(pretrained_name)
        self.processor = CLIPProcessor.from_pretrained(pretrained_name)
        # 初始化其他层（头部在变压器主体之后）
        self.classifier = nn.Sequential(
            nn.Linear(512, 128, 偏差=True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=dropout, inplace=False),
            nn.Linear(128, self.num_labels, 偏差=True))
        
        defforward（自我，输入，标签=无，**kwargs）：
            logits = self.classifier(输入)
            损失=无
            如果标签不是无：
                loss_fct = nn.CrossEntropyLoss()
                损失 = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))

            返回序列分类器输出（
                损失=损失，
                对数=对数，
            ）

我还有以下数据集定义：
class CLIPDataset(nn.utils.data.Dataset)：
    def __init__(自身、嵌入、标签):
        self.embeddings = 嵌入
        self.labels = 标签

    def __getitem__(self, idx):
        item = {“嵌入”: nn.Tensor(self.embeddings[idx])}
        item[&#39;labels&#39;] = nn.LongTensor([self.labels[idx]])
        归还物品

    def __len__(自身):
        返回 len(self.labels)


注意：这里我假设模型是预先计算的嵌入并且不计算嵌入，我知道如果我想微调 CLIP 基本模型，这不是正确的逻辑，我只是​​想得到我的代码可以工作。
类似这样的事情会引发错误：
模型 = CLIPNN(num_labels=2)
train_data = CLIPDataset(train_data, y_train)
test_data = CLIPDataset(test_data, y_test)

教练=教练（
    模型=模型，args=training_args，train_dataset=train_data，eval_dataset=test_data
）
训练师.train()

&lt;块引用&gt;
类型错误回溯（最近一次调用）
----&gt; 1 个trainer.train()
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/trainer.py
在火车中（自我，resume_from_checkpoint，审判，ignore_keys_for_eval，
**kwargs）第1256章 self.control = self.callback_handler.on_epoch_begin（args，self.state，self.control）
1257 → 1258 为步骤，输入 enumerate(epoch_iterator): 1259 1260 #
如果恢复训练，请跳过任何已训练的步骤
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/utils/data/dataloader.py 在 next(self) 515 如果 self._sampler_iter 为 None: 516 self._reset() →
517 数据 = self._next_data() 518 self._num_yielded += 1 519 if
self._dataset_kind == _DatasetKind.Iterable 和 \
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/utils/data/dataloader.py in _next_data(self) 555 def _next_data(self): 556 索引 =
self._next_index() # 可能引发 StopIteration → 557 data =
self._dataset_fetcher.fetch(index) # 可能会引发 StopIteration 558 如果
self._pin_memory: 559 数据 = _utils.pin_memory.pin_memory(data)
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py
在 fetch(self, possible_batched_index) 45 else: 46 data =
self.dataset[possible_batched_index] —&gt; 47 返回
self.collat​​e_fn(数据)
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/data/data_collat​​or.py
在 default_data_collat​​or(features, return_tensors) 64 65 如果
return_tensors == “pt”: —&gt;; 66 返回
torch_default_data_collat​​or(features) 67 elif return_tensors == “tf”:
68 返回 tf_default_data_collat​​or(features)
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/data/data_collat​​or.py
在 torch_default_data_collat​​or(features) 80 81 如果没有
isinstance(features[0], (dict, BatchEncoding)): —&gt;; 82 个特征 =
[vars(f) for f in features] 83first = features[0] 84batch = {}
~/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/data/data_collat​​or.py
在 (.0) 80 81 中，如果不是 isinstance(features[0], (dict, BatchEncoding))：
—&gt; 82 特征 = [特征中 f 的 vars(f)] 83 第一个 = 特征[0] 84
批次 = {}
类型错误：vars() 参数必须具有 dict 属性

知道我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/69539538/error-vars-argument-must-have-dict-attribute-when-trying-to-use-trainer-t</guid>
      <pubDate>Tue, 12 Oct 2021 11:12:03 GMT</pubDate>
    </item>
    <item>
      <title>如何从预训练模型加载保存的分词器</title>
      <link>https://stackoverflow.com/questions/58417374/how-to-load-the-saved-tokenizer-from-pretrained-model</link>
      <description><![CDATA[我使用 Huggingface 转换器在 Pytorch 中微调了预训练的 BERT 模型。所有训练/验证都是在云中的 GPU 上完成的。
训练结束时，我保存模型和分词器，如下所示：
best_model.save_pretrained(&#39;./saved_model/&#39;)
tokenizer.save_pretrained(&#39;./saved_model/&#39;)

这会在 saved_model 目录中创建以下文件：
&lt;前&gt;&lt;代码&gt;config.json
添加的_token.json
Special_tokens_map.json
tokenizer_config.json
词汇表.txt
pytorch_model.bin

现在，我将 saved_model 目录下载到我的计算机中，并希望加载模型和分词器。我可以像下面这样加载模型
model = torch.load(&#39;./saved_model/pytorch_model.bin&#39;,map_location=torch.device(&#39;cpu&#39;))
但是如何加载分词器呢？我是 pytorch 的新手，不确定，因为有多个文件。也许我没有以正确的方式保存模型？]]></description>
      <guid>https://stackoverflow.com/questions/58417374/how-to-load-the-saved-tokenizer-from-pretrained-model</guid>
      <pubDate>Wed, 16 Oct 2019 15:57:36 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML.NET 的动态训练/测试课程</title>
      <link>https://stackoverflow.com/questions/52822696/dynamic-training-test-classes-with-ml-net</link>
      <description><![CDATA[这是此处问题的后续内容
动态类/对象 ML.net 的 PredictionMoadel&lt; ;T输入，T输出&gt;火车（）
我的系统无法在编译时使用预定义的类，因此我尝试将动态类提供给 ML.NET，如下所示
 // 字段数据类型
    公开课领域
    {
        公共字符串字段名 { get;放; }
        公共类型 FieldType { 获取；放; }
    }

    // 动态类助手
    公共类 DynamicClass ：DynamicObject
    {
        私有只读字典&lt;字符串，KeyValuePair&lt;类型，对象&gt;&gt; _字段；

        公共 DynamicClass(List 字段)
        {
            _fields = new Dictionary&lt;字符串, KeyValuePair&lt;类型, 对象&gt;&gt;();
            fields.ForEach(x =&gt; _fields.Add(x.FieldName,
                new KeyValuePair&lt;类型，对象&gt;(x.FieldType, null)));
        }

        public override bool TrySetMember(SetMemberBinder活页夹，对象值)
        {
            if (_fields.ContainsKey(binder.Name))
            {
                var type = _fields[binder.Name].Key;
                if (value.GetType() == 类型)
                {
                    _fields[binder.Name] = new KeyValuePair&lt;类型，对象&gt;(类型，值);
                    返回真；
                }
                else throw new Exception(&quot;Value &quot; + value + &quot; 不是类型 &quot; + type.Name);
            }
            返回假；
        }

        公共覆盖布尔TryGetMember（GetMemberBinder活页夹，输出对象结果）
        {
            结果 = _fields[binder.Name].Value;
            返回真；
        }
    }

    私有静态无效主（字符串[] args）
    {
        var fields = new List&lt;字段&gt;;
        {
            新字段 {FieldName = &quot;名称&quot;, FieldType = typeof(string)},
            新字段 {FieldName = &quot;收入&quot;, FieldType = typeof(float)}
        };

        动态 obj1 = new DynamicClass(字段);
        obj1.Name = &quot;约翰&quot;;
        obj1.收入 = 100f;

        动态 obj2 = new DynamicClass(字段);
        obj2.Name = &quot;爱丽丝&quot;;
        obj2.收入 = 200f;

        var TrainingData = new List&lt;动态&gt;; {对象1，对象2}；

        var env = new LocalEnvironment();
        var schemaDef = SchemaDefinition.Create(typeof(DynamicClass));
        schemaDef.Add(new SchemaDefinition.Column(null, &quot;Name&quot;, TextType.Instance));
        schemaDef.Add(new SchemaDefinition.Column(null, &quot;收入&quot;, NumberType.R4));
        var trainDataView = env.CreateStreamingDataView(trainingData, schemaDef);

        var pipeline = new CategoricalEstimator(env, &quot;名称&quot;)
            .Append(new ConcatEstimator(env, &quot;功能&quot;, &quot;名称&quot;))
            .Append(new FastTreeRegressionTrainer(env, &quot;收入&quot;, &quot;特征&quot;));

        var model = pipeline.Fit(trainDataView);
    }

并收到错误：“&#39;在类型&#39;System.Object&#39;中找不到名称为&#39;Name&#39;的字段或属性”。我尝试使用反射生成类，但遇到了同样的问题。
有解决办法吗？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/52822696/dynamic-training-test-classes-with-ml-net</guid>
      <pubDate>Mon, 15 Oct 2018 18:24:15 GMT</pubDate>
    </item>
    </channel>
</rss>