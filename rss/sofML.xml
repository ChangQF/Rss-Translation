<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Tue, 25 Mar 2025 01:21:11 GMT</lastBuildDate>
    <item>
      <title>有什么方法可以在使用CV2保持文本的清晰度的同时删除此还原图像的背景噪声？</title>
      <link>https://stackoverflow.com/questions/79531758/is-there-any-way-to-remove-the-background-noise-of-this-restored-image-while-mai</link>
      <description><![CDATA[原始图像：
这是原始图像 
部分还原图像：
这是部分修复的图像 
第一个图像是在通过一些恢复技术运行之前。第二张图像是在修复后。背景噪音很多，字符的一部分缺少。我想从此图像中提取文本。我们可以在保持文本的准确性的同时执行此操作吗？任何帮助都将受到赞赏！]]></description>
      <guid>https://stackoverflow.com/questions/79531758/is-there-any-way-to-remove-the-background-noise-of-this-restored-image-while-mai</guid>
      <pubDate>Mon, 24 Mar 2025 17:32:07 GMT</pubDate>
    </item>
    <item>
      <title>CATBOOST模型的串联TF-IDF数据和分类数据</title>
      <link>https://stackoverflow.com/questions/79531266/concatenating-tf-idf-data-and-categorical-data-for-catboost-model</link>
      <description><![CDATA[我一直在尝试将TF-IDF数据与分类数据相连。但是，当串联时，默认情况下，分类数据会自动转换为float。由于catboost不支持分类特征的浮动，因此由于不再被认为是分类数据而导致稀疏数据的错误。
有解决这个问题的解决方案吗？请在下面找到我的代码以供参考：
 导入numpy作为NP
导入大熊猫作为pd
来自Catboost Import CatboostClassifier
来自sklearn.feature_extraction.text导入tfidfvectorizer
从Sklearn.Preprocessing Import LabElenCoder
来自scipy.sparse导入hstack，csr_matrix

text_data = [
    “我喜欢机器学习和数据科学”
    “深度学习是机器学习的子集”
    “自然语言处理是惊人的”
    “ AI正在改变世界”
    “大数据和AI正在彻底改变行业”。
这是给出的

pecorical_data = {
    “ cantory”：“ tech; quot” tech&#39;tech&#39;nlp’s&#39;&#39;
    “地区”：“欧洲”，“亚洲”欧洲“欧洲”
}

y = np.Array（[0，1，0，1，1]）

df_cat = pd.dataframe（centorical_data）

vectorizer = tfidfvectorizer（）
x_tfidf = vectorizer.fit_transform（text_data）

df_cat_encoded = df_cat.apply（labelencoder（）。fit_transform）

x_categorical = csr_matrix（df_cat_encoded.values）

x_combind = hstack（[x_tfidf，x_categorical]）

model = catboostClassifier（迭代= 100，Learning_rate = 0.1，深度= 5，冗长= 0）

model.fit（x_combined，y，cat_features = [x_tfidf.shape [1]，x_tfidf.shape [1] + 1]）

预测= model.predict（x_combined）

打印（预测）
 
错误：
  catboostror：&#39;data&#39;是scipy.sparse.spmatrix floating Point数值类型， 
这意味着没有分类功能，但是“ cat_features”参数指定非零 
分类功能的数量
 ]]></description>
      <guid>https://stackoverflow.com/questions/79531266/concatenating-tf-idf-data-and-categorical-data-for-catboost-model</guid>
      <pubDate>Mon, 24 Mar 2025 13:53:36 GMT</pubDate>
    </item>
    <item>
      <title>Lora Fineted Llama 8b的自定义前往前方法 - 使用Unsploth</title>
      <link>https://stackoverflow.com/questions/79531231/custom-forward-method-for-lora-finetuned-llama-8b-using-unsloth</link>
      <description><![CDATA[我正在尝试对我的固定模型进行一些消融研究。试图超载前向方法
 类GROK_CUSTOMPEFTCAUSALLM（TORCH.NN.MODULE）：
def __init __（自我，模型）：
    super（）.__ init __（）
    self.model =型号＃原始fastlanguagemodel

    ＃修补内部模型的前进
    orig_forward = self.model.model.forward

    def new_forward（inned_self，input_ids，activation_mask = none，num_logits_to_keep = none，** kwargs）：
        打印（&#39;🔹自定义前进被调用！＆quot; flush = true）

        ＃嵌入
        hidden_​​states = inner_self.model.embed_tokens（input_ids）
        打印（嵌入后隐藏状态：{hidden_​​states.shape}＆quot; flush = true）

        ＃注意面具
        如果active_mask无：
            activation_mask = torch.ones（input_ids.shape，dtype = type = turch.bfloat16，device = input_ids.device）.bool（）
        别的：
            ##强制入bool
            activation_mask = activation_mask.bool（）

        ＃层
        past_key_values =无
        对于i，在枚举中层（inner_self.model.layers）：
            打印（f＆quot&#39;layer {i}＆quot＆quot＆clush = true）
            layer_output = layer（hidden_​​states，activation_mask = activation_mask）
            print（f&#39;layer {i} output：{type（layer_output）}，len：{len（layer_output）如果isInstance（layer_output，tuple，tuple）else 1}＆quot;，\ \
                                                                                              冲洗= true）
            hidden_​​states = layer_output [0]如果isInstance（layer_output，tuple）else layer_output
            如果len（layer_output）＆gt; 1：
                past_key_values = layer_output [1]＃更新kv缓存
            print（f＆quot&#39;efter layer {i}：{hidden_​​states.shape}＆quort＆quort＆quort; flush = true）

        ＃规范
        hidden_​​states = inner_self.model.norm（hidden_​​states）
        print（f＆quot&#39;norm：{hidden_​​states.shape}＆quort＆quot; flush = true）

        ＃logits
        logits = inner_self.lm_head（hidden_​​states）
        print（f＆quot“ logits：{logits.shape}＆quort”，flush = true）

        ＃返回完整输出
        返回causallMoutputwithpast（logits = logits，past_key_values = past_key_values）
    ＃覆盖内部模型的前进
    导入类型
    self.model.model.forward = types.methodtype（new_forward，self.model.model）

def生成（self， *args，** kwargs）：
    打印（&#39;🔹自定义生成调用！＆quot; flush = true）
    ＃过滤num_logits_to_keep

    if&#39;num_logits_to_keep＆quot在夸尔格斯：
        del Kwargs [＆quot; num_logits_to_keep;]
    返回self.model.generate（*args，** kwargs）
 
我像这样调用了
 模型，tokenizer = fastlanguagemodel.from_pretrateing（
        model_name = inf_model_，
        max_seq_length = 3072，
        dtype = none，
        load_in_4bit = true
）

eos_token = tokenizer.eos_token

模型= fastlanguagemodel.for_inference（模型）

＃补丁传递通行证
模型= grok_custompeftcausallm（模型）
print（type（model.model））＃确保它是您的“ SkippableModel”
输入= tokenizer（
[
    data_prompt.format（
        语境_，
        “”
    ）
]，return_tensors =; pt; quot。


print（data_prompt.format（上下文_，; quord;））
启动器_ = time.time（）
输出=型号。generate（**输入，max_new_tokens = 800，温度= 0.1）
打印（&#39;take out ::&#39;，time.time（） - 启动_）

答案= tokenizer.batch_decode（输出）
 
它只是生成gibberish（在没有此超载的情况下，它的性能绝对是预期的 - 良好的代码生成）。现在的问题是，我可以使用的层次结构的唯一部分是Model.Model，它指向基本Meta Llama上的Casualllama包装器。我有一种不好的感觉，这不是正确的前进，不塞在引擎盖下发生了其他事情。我在这里错过了什么？]]></description>
      <guid>https://stackoverflow.com/questions/79531231/custom-forward-method-for-lora-finetuned-llama-8b-using-unsloth</guid>
      <pubDate>Mon, 24 Mar 2025 13:38:48 GMT</pubDate>
    </item>
    <item>
      <title>TABPFN功能选择提高了keyError（f“ [{key}]中的一个都不在[{axis_name}]中</title>
      <link>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</guid>
      <pubDate>Sun, 23 Mar 2025 22:59:22 GMT</pubDate>
    </item>
    <item>
      <title>DUAT息肉细分模型未开箱即用[关闭]</title>
      <link>https://stackoverflow.com/questions/79529461/duat-polyp-segmentation-model-not-working-out-of-the-box</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79529461/duat-polyp-segmentation-model-not-working-out-of-the-box</guid>
      <pubDate>Sun, 23 Mar 2025 18:24:52 GMT</pubDate>
    </item>
    <item>
      <title>回归失败，初始猜测很差[关闭]</title>
      <link>https://stackoverflow.com/questions/79528937/regression-fails-with-poor-initial-guess</link>
      <description><![CDATA[考虑模型参数在大小上有显着差异的回归任务，例如：
  def func（x，p）：
    P1，P2，P3 = P
    返回np.sin（p1 * x） * np.exp（p2 * x） * p3

＃真参数：
P1，P2，P3 = NP.PI/0.01，-1.25，1.2356＃314.1592，-1.25，1.2356
 
系统需要一个可行的初始猜测才能收敛到正确的解决方案，例如：
  p0 = [np.pi/0.01-80，-1.25-1，1.2356-1]
 
但是，如果最初的猜测离真解决方案太远，则回归可能无法收敛。例如，以下初始猜测可能行不通：
  p0 = [np.pi/0.02-10，-1.25-1，1.2356-1]
 
可重复的代码如下：
 导入numpy作为np
从scipy.ptimize导入至少_squares
导入matplotlib.pyplot作为PLT

def func（x，p）：
    P1，P2，P3 = P
    返回np.sin（p1 * x） * np.exp（p2 * x） * p3

def残差（p，y，x）：
    返回Y-弹药（x，p）

x = np.linspace（0，0.05，50）
P1，P2，P3 = NP.PI/0.01，-1.25，1.2356
y0 = func（x，[p1，p2，p3]）
y = y0 + np.random.randn（len（x）） * 0.05

p0 = [np.pi/0.02-10，-1.25-1，1.2356-1]

结果=最差_squares（残差，p0，args =（y，x））

打印（“ true参数：＆quot” [P1，P2，P3]）
打印（“近似参数：＆quort; result.x）

x_test = np.linspace（0，0.05，200）
y_test = func（x_test，result.x）
y_real = func（x_test，[p1，p2，p3]）
plt.plot（x_test，y_test，label =; precept; quot; quot;
plt.plot（x，y，&#39;.r&#39;，label =&#39;real＆quot;）
 
或这是一个pytorch版本：
 导入numpy作为np
导入火炬
从火炬进口
导入matplotlib.pyplot作为PLT

类Guesseq（nn.Module）：
    def __init __（自我）：
        super（gueseq，self）.__ INIT __（）
        self.params = nn.parameter（torch.tensor（[[np.pi/0.01-10，-1.25+1，1.2356-1]）））））））））））
    
    def向前（self，x）：
        out = torch.sin（self.params [0] * x） * \
            TORCH.EXP（-self.params [1] * x） * \
            self.params [2]
        返回

x = np.linspace（0，0.05，100）
y = np.sin（np.pi/0.01 * x） * np.exp（-1.25 * x） * 1.2356 + np.random.rand（x.Shape [0]） * 0.05

x = torch.tensor（x，dtype = turch.float32）
Y = TORCH.TENSOR（Y，DTYPE = TORCH.FLOAT32）
x = x.Reshape（（ -  1，1））
y = y.Reshape（（ -  1，1））

型号= gueseq（）
优化器= torch.optim.adam（model.parameters（），lr = 0.01）
mse = nn.mseloss（）
对于范围的我（2000年）：
    优化器.zero_grad（）
    y_pred =模型（x）
    损失= TORCH.MEAN（TORCH.SQUARE（Y_PRED -y））
    loss.backward（）
    如果我％100 == 0：
        打印（损失）
    优化器.step（）

x_test = torch.linspace（0，0.05，200）.RESHAPE（（ -  1，1））
y_test =模型（x_test）
print（＆quot; true参数：[{} {} {}]＆quort; .format（np.pi/0.01，-1.25，1.2356））
print（&#39;近似参数：{}＆quort; format（model.params.detach（）。numpy（）））
plt.plot（x_test.detach（）。cpu（）。numpy（）。flatten（），y_test.detach（）。cpu（）。
plt.plot（x.detach（）。cpu（）。numpy（）。flatten（），y.detach（）。cpu（）。
plt.legend（）
plt.show（）
 
当初始猜测远离真正的解决方案时，或者没有初始猜测之前，如何解决问题？]]></description>
      <guid>https://stackoverflow.com/questions/79528937/regression-fails-with-poor-initial-guess</guid>
      <pubDate>Sun, 23 Mar 2025 12:22:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么SeceentialFeaturesElector最多返回“ N_features_in_ -1”预测变量？</title>
      <link>https://stackoverflow.com/questions/79528929/why-does-sequentialfeatureselector-return-at-most-n-features-in-1-predictor</link>
      <description><![CDATA[我有一个具有六个功能的培训数据集，我正在使用 sequentialFeaturesElector 查找“最佳”线性回归模型的特征子集。以下代码返回三个功能，我将调用 x1，x2，x3 。
  sfs = sequentialFeaturesElector（linearregression（），n_features_to_select =&#39;auto&#39;， 
                                tol = 0.05，方向=&#39;正向&#39;， 
                                评分=&#39;neg_root_mean_squared_error&#39;，cv = 8）
sfs.fit_transform（x_train，y_train）
 
要检查结果，我决定使用功能的子集 x1，x2，x3 而不是 x_train 来运行相同的代码。我期望看到功能 x1，x2，x3 再次返回，但仅是功能 x1，x2 。同样，在同一代码中再次使用这两个功能仅返回 x1 。看来 sfs 的行为始终始终返回输入功能的适当子集，最多使用 n_features_in_-1 列，但是我似乎无法在 scikit-learn docs 。这是正确的吗？如果是这样，不允许的理由是什么
 sfs 返回完整的功能？
我还检查了使用向后选择是否会返回完整功能集。
  sfs = sequentialFeaturesElector（linearregression（），n_features_to_select =&#39;auto&#39;， 
                                tol = 1000，方向=&#39;向后&#39;， 
                                评分=&#39;neg_root_mean_squared_error&#39;，cv = 8）
sfs.fit_transform（x_train，y_train）
 
我将阈值设置为是一个很大的值，希望从 x_train 的完整功能中没有令人满意的改进。但是，它没有返回六个原始功能，而是返回了五个。文档只是说明

如果10分在两个连续的特征添加或删除之间至少会增加分数，请停止添加或删除。

因此，在交叉验证期间似乎没有考虑完整的功能集，并且在远期选择的末尾或在向后选择的开始时， sfs 的行为是不同的。如果完整的功能超过了功能的任何适当子集，那么我们不希望 sfs 返回这种可能性吗？是否有标准方法可以比较选定的特征的适当子集以及使用交叉验证的完整功能？]]></description>
      <guid>https://stackoverflow.com/questions/79528929/why-does-sequentialfeatureselector-return-at-most-n-features-in-1-predictor</guid>
      <pubDate>Sun, 23 Mar 2025 12:16:03 GMT</pubDate>
    </item>
    <item>
      <title>当训练模型使用KAFKA和RDL索引4096训练模型时的错误是否超出了尺寸4096的轴0</title>
      <link>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</guid>
      <pubDate>Sat, 22 Mar 2025 05:30:38 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Codebert嵌入识别类似的代码零件？</title>
      <link>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</link>
      <description><![CDATA[我正在使用Codebert比较两个代码的相似性。例如：
 ＃代码1
def calculate_area（半径）：
返回3.14 *半径 *半径
 
 ＃代码2
def Compute_circle_area（R）：
返回3.14159 * r * r
 
 Codebert创建“嵌入”就像对代码的详细描述为数字。然后，我比较这些数值描述，以查看代码的相似之处。这对于告诉我多少代码是相似的。
但是，我无法分辨Codebert认为哪些部分相似。因为“嵌入”很复杂，我无法轻易看到Codebert的重点。比较逐字代码在这里不起作用。
我的问题是：我如何找出两个代码段的哪些特定部分Codebert认为相似，而不仅仅是获得一般相似性得分？
我尝试了简单的DIFF方法，但这违反了纯粹使用Codebert的目的。
我想知道是否可以单独使用Codebert。]]></description>
      <guid>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</guid>
      <pubDate>Thu, 20 Mar 2025 14:30:35 GMT</pubDate>
    </item>
    <item>
      <title>面对ModulenotFoundError：没有名为“ ragas.metrics.critique”的模块</title>
      <link>https://stackoverflow.com/questions/79512981/facing-modulenotfounderror-no-module-named-ragas-metrics-critique</link>
      <description><![CDATA[在AWS Sagemaker Jupyterlab笔记本中运行代码段时，我的错误低于错误：

 modulenotfounderror：没有名为&#39;ragas.metrics.critique&#39;的模块

 导入警告
警告。FilterWarnings（“忽略”）＃忽略与Pydantic V1到V2迁移有关的警告

来自拉加斯进口评估
从ragas.metrics导入（
    忠诚，
    答案_relevancy，
    context_recall，
    context_precision，
    context_entity_recall，
    答案_象征性，
    答案_校正
）

来自ragas.metrics.Critique Import（
有害， 
恶意， 
连贯性， 
正确性， 
简明
）

＃在此处指定指标
指标= [
        忠诚，
        答案_relevancy，
        context_precision，
        context_recall，
        context_entity_recall，
        答案_象征性，
        wonse_correctness，
        有害， 
        恶意， 
        连贯性， 
        正确性， 
        简明
    这是给出的

结果=评估（
    数据集=数据集， 
    指标=指标，
    llm = llm_for_evaluation，
    嵌入= bedrock_embeddings，
）

df = result.to_pandas（）
 
我试图通过使用命令“ PIP install ragas”来重新安装拉加斯。并且仍然面临同一问题。
当我检查ragas时，它似乎已经正确安装了。
 pip显示ragas 
 名称：ragas
版本：0.2.14
概括： 
主页： 
作者： 
作者 - 邮件： 
执照： 
位置：/opt/conda/lib/python3.11/site-packages
要求：AppDirs，数据集，Diskcache，Langchain，Langchain-Community，Langchain-core，Langchain_openai，Nest-Asyncio，Numpy，Numpy，Openai，Openai，Pydantic，Tiktoken，Tiktoken
要求： 
注意：您可能需要重新启动内核才能使用更新的软件包。
 
如何解决这个问题？
 更新----  
我能够通过安装0.1.16版本的Ragas的以下步骤来解决上述问题，但是当我运行上述代码部分时，我会收到一个新问题（如下所述）。。
％pip安装ragas == 0.1.16 

  Importerror Trackback（最近的最新通话）
[27]中的细胞17
4来自拉加斯进口评估
5来自ragas.metrics进口（
6忠诚，
7 wonse_relevancy，
（...）
12个答案_校正
13）
---＆gt; 17来自ragas.metrics.Critique Importique（
18有害，
19恶意，
20连贯性，
21正确性，
22简洁
23）
25＃在这里指定指标
26指标= [
27忠诚，
28答案_relevancy，
（...）
38简洁
39]

file/opt/conda/lib/python3.11/site-packages/ragas/metrics/critique.py:13
11来自ragas.llms.output_parser导入ragasoutputparser，get_json_format_instructions
12来自ragas.llms.prompt进口提示
---＆gt; 13摘自ragas.metrics.base Import EvaluationMode，metricwithllm
15如果t.type_checking：
16来自langchain_core.callbacks.base导入回调

Importerror：无法从&#39;ragas.metrics.base&#39;（/opt/conda/lib/python3.11/site-packages/ragas/ragas/metrics/base.py）导入名称&#39;evaluationMode&#39;
 ]]></description>
      <guid>https://stackoverflow.com/questions/79512981/facing-modulenotfounderror-no-module-named-ragas-metrics-critique</guid>
      <pubDate>Sun, 16 Mar 2025 17:49:25 GMT</pubDate>
    </item>
    <item>
      <title>高效NETB3模型的准确性非常低，并且在识别脑肿瘤问题方面学习高原</title>
      <link>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79390644/very-low-accuracy-of-efficientnetb3-model-and-learning-plateau-on-identifying-br</guid>
      <pubDate>Mon, 27 Jan 2025 11:58:17 GMT</pubDate>
    </item>
    <item>
      <title>神经网络不确定的乳腺癌数据集</title>
      <link>https://stackoverflow.com/questions/52358505/neural-network-undefitting-breast-cancer-dataset</link>
      <description><![CDATA[我正在尝试在乳腺癌数据集上创建一个用于二进制分类的神经网络：
  https://wwwww.kaggle.com/uciml/uciml/uciml/breast-cancer-cancer-wisconsin-data-data-data-data-data-data 
我的神经网络由3层组成（不包括输入层）：

 第一层：6个带有Tanh激活的神经元。

 第二层：6个带有Tanh激活的神经元。

 最终层：1个神经元，带有Sigmoid激活。


不幸的是，我在训练示例中仅获得约44％的精度，在测试示例中的精度约为23％。
这是我的python代码：
 导入numpy作为NP
导入大熊猫作为pd
导入matplotlib.pyplot作为PLT

data = pd.read_csv（&#39;data.csv; quot;）
data = data.drop（[&#39;id&#39;]，轴= 1）
data = data.drop（data.columns [31]，轴= 1）
data = data.replace（{&#39;m&#39;：1，&#39;b&#39;：0}）

x =数据
x = x.drop（[&#39;诊断&#39;]，轴= 1）
x = np.array（x）

x_mean = np.mean（x，axis = 1，keepdims = true）
x_std = np.std（x，axis = 1，keepdims = true）
x_n =（x -x_mean） / x_std
y = np.array（数据[&#39;诊断&#39;]）
y = y.Reshape（569，1）
M = 378
y_train = y [：m，：]
y_test = y [m：，：]

x_train = x_n [：M，：]
x_test = x_n [m :，：]

Def Sigmoid（Z）：
  返回1 /（1 + np.exp（-z））

def dsigmoid（z）：
  返回np.multiply（z，（1 -z））

def tanh（z）：
  返回（np.exp（z）-np.exp（-z）） /（np.exp（z） + np.exp（-z））

def dtanh（z）：
  返回1 -np.square（tanh（z））

def成本（a，y）：
  m = y.形[0]
  返回 - （1.0/m） *np.sum（np.dot（y.t，np.log（a）） + np.dot（（（1 -y）.t，np，np.log（1 -a）））

def train（x，y，型号，epocs，a）：
  W1 =模型[&#39;W1&#39;]
  W2 =模型[&#39;W2&#39;]
  W3 =模型[&#39;W3&#39;]
  
  B1 =模型[&#39;B1&#39;]
  B2 =模型[&#39;B2&#39;]
  B3 =模型[&#39;B3&#39;]
  
  费用= []
  
  对于我的范围（EPOC）：
    
    ＃前传播

    z1 = np.dot（x，w1） + b1
    a1 = tanh（z1）

    z2 = np.dot（a1，w2） + b2
    a2 = tanh（z2）

    z3 = np.dot（a2，w3） + b3
    A3 = Sigmoid（Z3）
    
    costs.append（成本（A3，y））

    #back繁殖
    
    dz3 = z3 -y
    d3 = np.multiply（dz3，dsigmoid（z3））
    dw3 = np.dot（a2.t，d3）
    db3 = np.sum（d3，axis = 0，keepdims = true）

    d2 = np.multiply（np.dot（d3，w3.t），dtanh（z2））
    dw2 = np.dot（a1.t，d2）
    db2 = np.sum（d2，轴= 0，keepdims = true）

    d1 = np.multiply（np.dot（d2，w2.t），dtanh（z1））
    dw1 = np.dot（x.T，d1）
    db1 = np.sum（d1，axis = 0，keepdims = true）

    W1  -  =（A / M） * DW1
    W2- =（A / M） * DW2
    w3- =（a / m） * dw3

    B1  -  =（A / M） * DB1
    b2  -  =（a / m） * db2
    B3  -  =（A / M） * DB3
    
  cache = {&#39;w1&#39;：w1，&#39;w2&#39;：w2，&#39;w3&#39;：w3，&#39;b1&#39;：b1&#39;：b1，&#39;b2&#39;：b2，&#39;b3&#39;：b3}
  返回缓存，成本

np.random.seed（0）

型号= {&#39;w1&#39;：np.random.rand（30，6） * 0.01，&#39;w2&#39;：np.random.rand（6，6） * 0.01，&#39;w3&#39;：np.random.rand（6，1） &#39;b3&#39;：np.random.rand（1，1）}

型号，成本=火车（x_train，y_train，型号，1000，0.1）

plt.plot（[i在范围内（1000）]，费用）
打印（费用[999]）
plt.show（）



def预测（x，y，模型）：
  W1 =模型[&#39;W1&#39;]
  W2 =模型[&#39;W2&#39;]
  W3 =模型[&#39;W3&#39;]
  
  B1 =模型[&#39;B1&#39;]
  B2 =模型[&#39;B2&#39;]
  B3 =模型[&#39;B3&#39;]
  
  z1 = np.dot（x，w1） + b1
  a1 = tanh（z1）

  z2 = np.dot（a1，w2） + b2
  a2 = tanh（z2）

  z3 = np.dot（a2，w3） + b3
  A3 = Sigmoid（Z3）
  
  m = a3.形[0]
  y_predict = np.zeros（（M，1））
  
  对于我的范围（m）：
    y_predict = 1如果a3 [i，0]＆gt; 0.5其他0
  返回y_predict
 ]]></description>
      <guid>https://stackoverflow.com/questions/52358505/neural-network-undefitting-breast-cancer-dataset</guid>
      <pubDate>Sun, 16 Sep 2018 21:24:54 GMT</pubDate>
    </item>
    <item>
      <title>训练模型以识别句子中出现的名称</title>
      <link>https://stackoverflow.com/questions/51476682/training-a-model-to-identify-names-appearing-in-a-sentence</link>
      <description><![CDATA[我有一个数据集，其中包含大约238583人的名称。名称可以包含多个单词：例如：
  Willie Enriquez，James J Johnson，D.J。 khaled 。
 我的问题是在句子中出现这些名称时识别这些名称。我正在尝试创建一个机器学习模型，该模型可以识别输入是否为名称。我的麻烦是找出该模型的输入和输出。由于我有一堆名称，因此我可以训练一个模型，该模型可以识别输入是一个名称时的名称，但是该句子中的其他单词又如何。该模型还应该能够识别不是名称的单词。假设句子中有任何其他单词，那么为此目的的理想数据集是什么？在随机的单词上训练模型并将其标记为非名称是有意义的吗？
（名称出现的整个句子不可用。用户可以绝对键入他/她想要的任何内容）
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/51476682/training-a-model-to-identify-names-appearing-in-a-sentence</guid>
      <pubDate>Mon, 23 Jul 2018 10:30:30 GMT</pubDate>
    </item>
    <item>
      <title>对神经网络的输入类型很重要？ [关闭]</title>
      <link>https://stackoverflow.com/questions/37438078/does-type-of-input-to-the-neural-network-matter</link>
      <description><![CDATA[我正在做视频分类。
我有一个神经网络，我必须使用视频（图像组）训练。
我可以选择从几个选项更改网络输入的形状。
在所有情况下，我都认为网络体系结构（排列和层数）＆amp;学习参数（LR/Decay/正则化/等）是恒定的。
例如，我可以选择将网络输入作为以下内容之一。

  batch_size x（no_of_imgs*no_of_channels）x高度x宽度{3尺寸输入} 

  batch_size x no_of_imgs x no_of_channels x高度x宽度{4尺寸输入} 

  batch_size x no_of_channels x no_of_imgs x高度x宽度{4尺寸输入} 


输入形状将如何影响网络的准确性？]]></description>
      <guid>https://stackoverflow.com/questions/37438078/does-type-of-input-to-the-neural-network-matter</guid>
      <pubDate>Wed, 25 May 2016 13:04:48 GMT</pubDate>
    </item>
    <item>
      <title>R-鼠标 - 机器学习：从火车到测试集的重复使用插补计划</title>
      <link>https://stackoverflow.com/questions/33500047/r-mice-machine-learning-re-use-imputation-scheme-from-train-to-test-set</link>
      <description><![CDATA[我正在建立一个预测模型，并且正在使用小鼠软件包在我的培训集中插入NAS。由于我需要为测试集重新使用相同的插补方案，因此如何将其重新应用于测试数据？
 ＃生成示例数据
set.seed（333）
mydata＆lt;  -  data.frame（a = as.logical（rbinom（100，1，0.5））），
                     b = as.logical（rbinom（100，1，0.2）），
                     c = as.logical（rbinom（100，1，0.8）），
                     y = as.logical（rbinom（100，1，0.6）））

na_a＆lt;  -  as.logical（rbinom（100，1，0.3））
na_b＆lt;  -  as.logical（rbinom（100，1，0.3））
na_c＆lt;  -  as.logical（rbinom（100，1，0.3））
mydata $ a [na_a]＆lt;  -  na
mydata $ b [na_b]＆lt;  -  na
mydata $ c [na_c]＆lt;  -  na

＃创建火车/测试集
图书馆（Caret）
Intrain＆lt;  -  createAtapartition（mydata $ y，p = .8，list = false）
train＆lt;  -  mydata [intrain，] 
测试＆lt;  -  mydata [-intrain，]

＃将NAS插入火车套装
图书馆（小鼠）
imp＆lt;  - 小鼠（火车，方法=“ logreg”）
Train_imp＆lt;  - 完整（IMP）

＃将插补方案应用于测试集
test_imp＆lt;  -  unknown_function（test，imp $ unknown_data）
 ]]></description>
      <guid>https://stackoverflow.com/questions/33500047/r-mice-machine-learning-re-use-imputation-scheme-from-train-to-test-set</guid>
      <pubDate>Tue, 03 Nov 2015 13:12:09 GMT</pubDate>
    </item>
    </channel>
</rss>