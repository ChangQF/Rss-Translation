<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 18 May 2024 06:17:52 GMT</lastBuildDate>
    <item>
      <title>机器学习算法令人困惑[关闭]</title>
      <link>https://stackoverflow.com/questions/78498683/machine-learning-algorithms-are-confusing</link>
      <description><![CDATA[我试图理解 SVM 和决策树算法，但我不明白，有人可以给我一个例子吗]]></description>
      <guid>https://stackoverflow.com/questions/78498683/machine-learning-algorithms-are-confusing</guid>
      <pubDate>Sat, 18 May 2024 04:57:12 GMT</pubDate>
    </item>
    <item>
      <title>计算错误的神经网络比正确计算的神经网络更好</title>
      <link>https://stackoverflow.com/questions/78497893/neural-network-with-incorrect-calculation-better-than-correct-one</link>
      <description><![CDATA[我设计了自己的神经网络，发现了一个错误。在反向传播过程中，我没有将 Z 值插入激活函数的导数中，而是插入了 A 值。结果是，当我使用 A 值时，神经网络的学习速度比使用 Z 值的计算更快、更稳定。计算应该是错误的。那么为什么它效果更好，产生更好的结果和更稳定的结果呢？
Z=x×w+b A=activationfunction(Z)
计算错误，但结果更好：
dA/dZ=activationfunction_derivative(A)
delta = deltas[-1].dot(self.weights[i].T) * self.leaky_relu_derivative(self.activations[i])
计算正确，但结果更差：
dA/dZ=activationfunction_derivative(Z)
代码错误，但结果更好：
def leaky_relu(self, x, alpha=0.01):
return np.where(x &gt; 0, x, alpha * x)

def leaky_relu_derivative(self, x, alpha=0.01):
返回 np.where(x &gt; 0, 1, alpha)
def linear(self, x):
返回 x

def linear_derivative(self):
返回 1

def forward_propagation(self, X):
self.activations = []
activation = X
self.activations.append(activation)
for weight, bias in zip(self.weights[:-1], self.biases[:-1]):
activation = self.leaky_relu(np.dot(activation, weight) + bias)
self.activations.append(activation)
activation = self.linear(np.dot(activation, self.weights[-1]) + self.biases[-1])
self.activations.append(activation)
返回激活

def msnq(self, y_true, y_pred):
返回 np.mean(np.square(y_true - y_pred))

def backpropagation(self, y_true, t):
deltas = [] 
error = y_true - self.activations[-1]
delta = error * self.linear_derivative() 
deltas.append(delta) 
for i in range(len(self.activations) - 2, 0, -1):
delta = deltas[-1].dot(self.weights[i].T) * self.leaky_relu_derivative(self.activations[i])
deltas.append(delta) 
]]></description>
      <guid>https://stackoverflow.com/questions/78497893/neural-network-with-incorrect-calculation-better-than-correct-one</guid>
      <pubDate>Fri, 17 May 2024 20:48:33 GMT</pubDate>
    </item>
    <item>
      <title>机器学习 - 如何将数据清理纳入训练模型中</title>
      <link>https://stackoverflow.com/questions/78497891/machine-learning-how-to-incorporate-data-cleansing-into-trained-model</link>
      <description><![CDATA[我一直在尝试寻找这个问题的答案，但没有找到任何与之相关的内容。
问题是，如果我清理数据并将中值归入 NaN 值，我是否应该以某种方式将其合并到将用于测试数据的模型中。换句话说，我的测试数据是否也需要清理和估算，或者训练会解决这个问题吗？我想说它需要被合并，因为否则 NaN 值会破坏模型，而且任何偏度都不会得到解决。
特别是：
用中位数替换 NaN：
data = data.fillna(data.median())

使用分位数变换处理偏度，使每个特征遵循正态分布（以下仅举一例）。
qualtile_transformer = QuantileTransformer(output_distribution=&#39;正常&#39;, random_state=0&#39;)
数据[&#39;feat_0&#39;] = quantile_transformer.fit_transform(数据[&#39;feat_0&#39;].values.reshape(-1,1)).flatten()

型号：
从 sklearn.linear_model 导入 LinearRegression
Linear_regr = 线性回归()
Linear_regr.fit(Xtrain,Ytrain)

预测：
# 使用测试集进行预测
Ypred = Linear_regr.predict(Xtest)

谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78497891/machine-learning-how-to-incorporate-data-cleansing-into-trained-model</guid>
      <pubDate>Fri, 17 May 2024 20:47:39 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中为我的标签应用程序处理数据库锁</title>
      <link>https://stackoverflow.com/questions/78497797/handle-database-locks-in-python-for-my-labeling-app</link>
      <description><![CDATA[我希望我的应用程序的用户检索一些要标记的数据。在第一个版本中，我没有实现锁定，因此多个用户可以同时访问相同的数据，因此第二个版本会覆盖第一个版本的标签。
我正在使用 python fastAPI sqlite 后端。
我最初想出了为标签添加“is-being-labelized”值的想法，以便下一个提议的数据不一样。我不喜欢它，因为我不知道如何处理用户在没有标记数据的情况下退出应用程序（或其他应用程序）的情况。目前，我最好的方法是添加一个包含检索时间时间戳的列，并实现一个逻辑，假设检索后 30 秒，我们检查标签是否不再是 None。如果它仍然是 None （意味着该人没有标记），我们删除时间戳的值。我也不完全高兴，因为它不能处理人们冥想然后回来标记数据的情况。
您还有更好的建议吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78497797/handle-database-locks-in-python-for-my-labeling-app</guid>
      <pubDate>Fri, 17 May 2024 20:19:31 GMT</pubDate>
    </item>
    <item>
      <title>我用自己的数据集训练yolo模型但没有测试结果</title>
      <link>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</link>
      <description><![CDATA[我正在使用 Yolov3 模型以及从 Kaggle 收到的数据集来训练模型。模型训练已完成，我将新权重添加到备份文件夹中。我运行了我训练过的一种水果进行测试，但没有发生对象检测。同一图像显示为 Prediction.jpg。训练看起来不错，但我不明白为什么它不能检测物体。请帮助我。
火车站代码：
./darknet探测器列车 /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/Desktop/Projects/Bitirmeprojesi/yolov3.weights

测试终端代码：
./darknet探测器测试 /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/darknet/backup/yolov3_final.weights -thresh 0.25 -out预测.jpg

我设置并编辑了 obj.data、obj.names 和 yolov3.cfg 文件。
我有 3 个类别：苹果、香蕉和橙子。我已经根据3个类在cfg文件中正确设置了filter和class值等值。
cfg 文件
[网]
# 测试
批次=64
细分=1
＃ 训练
细分=16
宽度= 608
高度=608
通道=3
动量=0.9
衰减=0.0005
角度=0
饱和度=1.5
曝光=1.5
色调=0.3

学习率=0.001
烧入=1000
max_batches = 6000 # 类数 * 2000
政策=步骤
步骤=3600,4800 # max_batches num %80, %90
尺度=.1,.1

数据集中除了.jpg图片外，还有yolo格式的同名.txt文件。
在此处输入图像描述文件图像
包含所有图像路径的 train.txt 和 test.txt 文件也已准备就绪。
当我在终端中运行测试命令时，它可以工作，但图片看起来相同，没有检测对象的边界框。我确定我已经安装了 Opencv。我正在使用 macOS。为什么它没有检测到它？请有人帮忙。我多次通过 make clean 清理暗网，并通过 make opencv = 1 运行它，但结果没有改变。
[yolo]参数：iou损失：mse（2），iou_norm：0.75，obj_norm：1.00，cls_norm：1.00，delta_norm：1.00，scale_x_y：1.00
总 BFLOPS 137.613
平均输出 = 1052318
正在从 /Users/melisabagcivan/darknet/backup/yolov3_final.weights 加载权重...
 看过 64 个，训练过：32013 个 K 图像（500 Kilo-batches_64）
完毕！从权重文件加载 107 层
输入图像路径：/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg
 检测层：82-类型=28
 检测层数：94-型=28
 检测层：106-类型=28
/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg：预测为 6738.129000 毫秒。

我尝试了很多图像，但它没有在任何图像中绘制方框。我不明白是它无法检测到它还是我在测试时犯了错误。请帮忙，我快疯了。]]></description>
      <guid>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</guid>
      <pubDate>Fri, 17 May 2024 19:21:32 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中运行不佳</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 python 写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def 预处理图像（图像路径）：
    # 想象中的卡里卡
    img = Image.open(图像路径)
    # 在 scala di grigi 中进行想象和转换
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将 l&#39;immagine 转换为 un array numpy 并将 Ridimensiona 转换为 un unico vettare
    img_array = np.array(img).reshape(1, -1)
    返回img_array

# 使用的意义
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;连续成功模型&quot;)
    # 模型用途
    # Carica e pre-elabora un&#39;immagine
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # Prevedere la classe del nuovo esempio
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

你知道模型在 Python 中表现不同的原因吗？我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用决策树算法和bert算法对文本进行分类</title>
      <link>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-algorithm-to-classify-a-text</link>
      <description><![CDATA[我想集成并使用 BERT 和决策树两种算法进行文本分类，因此我需要该领域的指导和帮助。
如果有人有这个领域的源代码或文章，请提供给我。或者即使朋友有更好的建议将 BERT 算法与任何其他算法结合起来]]></description>
      <guid>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-algorithm-to-classify-a-text</guid>
      <pubDate>Fri, 17 May 2024 17:44:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在流模式下分割拥抱脸部数据集而不将其加载到内存中？</title>
      <link>https://stackoverflow.com/questions/78497069/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-me</link>
      <description><![CDATA[我正在使用 Hugging Face 数据集，我需要将数据集拆分为训练集和验证集。我的主要要求是数据集应该以流模式处理，因为我不想将整个数据集加载到内存中。
从数据集导入load_dataset，DatasetDict

# 从 Hugging Face 加载数据集
数据集 = load_dataset(&#39;小队&#39;, split=&#39;训练&#39;)

# 将数据集分为训练集和验证集
# 指定测试集（验证集）的分数
train_val_split = dataset.train_test_split(test_size=0.1)

# 提取训练和验证数据集
train_dataset = train_val_split[&#39;train&#39;]
val_dataset = train_val_split[&#39;测试&#39;]

# 打印数据集的大小
print(f&quot;训练集大小: {len(train_dataset)}&quot;)
print(f&quot;验证集大小: {len(val_dataset)}&quot;)

# 如果需要的话保存数据集
# train_dataset.save_to_disk(&#39;路径/到/train_dataset&#39;)
# val_dataset.save_to_disk(&#39;路径/到/val_dataset&#39;)

是否有一种方法可以在流模式下分割 Hugging Face 数据集？对我的代码的任何建议或改进将不胜感激。
参考文献：

https ://discuss.huggingface.co/t/how-to-split-a-dataset-into-train-test-and-validation/1238
https://discuss.huggingface.co/t/how-to-split-main-dataset-into-train-dev-test-as-datasetdict/1090/21
https://discuss.huggingface .co/t/possible-to-stream-and-create-new-splits/67214
https://huggingface.co/docs/datasets/v1.11.0 /splits.html
https://discuss.huggingface.co/t/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-memory /87205
]]></description>
      <guid>https://stackoverflow.com/questions/78497069/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-me</guid>
      <pubDate>Fri, 17 May 2024 17:18:18 GMT</pubDate>
    </item>
    <item>
      <title>学习率不更新</title>
      <link>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</link>
      <description><![CDATA[def make_prediction(x0,t0):
    输入 = torch.vstack([x0,t0])
    Layer_1 = torch.matmul(w0,输入)
    返回层_1

损失1 = nn.MSELoss()
def loss_function():
            u_t=(make_prediction(x,t+inf_s)-make_prediction(x,t))/inf_s
            u_x=(make_prediction(x+inf_s,t)-make_prediction(x,t))/inf_s
            u_xx=(make_prediction(x+inf_s,t)-2*make_prediction(x,t)+make_prediction(x-inf_s,t))/inf_s**2
            返回 (1/N_i)*(loss1(make_prediction(x0IC,t0IC), u0IC))+(1/N_b)*(loss1(make_prediction(x0BC1,t0BC1), u0BC1))
            +(1/N_b)*(loss1(make_prediction(x0BC2,t0BC2), u0BC2))+(1/N_f)*(np.pi/0.01)*(loss1(u_xx-u_t-make_prediction(x,t)*u_x , 0))

def train_step(w,b, 学习率):
    可训练变量 = [w,b]
    优化器 = torch.optim.SGD(trainable_variables, lr=learning_rate,momentum=0.9)
    调度程序 = torch.optim.lr_scheduler.ExponentialLR(优化器, gamma=0.01)
    损失 = loss_function()
    loss.backward()
    使用 torch.no_grad()：
        w -= 学习率 * w.grad
        b -= 学习率 * b.grad
        w.grad.zero_()
        b.grad.zero_()
    优化器.step()
    调度程序.step()
train_step(w,偏差,学习率)

我运行此代码（通过scheduler.ExponentialLR），但学习率没有变化。
您认为问题从何而来？
我写了完整的代码...感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</guid>
      <pubDate>Fri, 17 May 2024 16:56:52 GMT</pubDate>
    </item>
    <item>
      <title>尝试在自定义 autograd 函数内部的模型上调用 autograd.grad，在初始化时有效，但在设置权重/偏差时无效</title>
      <link>https://stackoverflow.com/questions/78496967/trying-to-call-autograd-grad-on-a-model-inside-of-a-custom-autograd-function-wo</link>
      <description><![CDATA[伯努利近似器类（nn.Module）：
  def __init__(self,hidden_​​dim):
    超级().__init__()
    self.线性1 = nn.Linear(2,hidden_​​dim)
    self.线性2 = nn.Linear（hidden_​​dim，hidden_​​dim）
    self.线性3 = nn.Linear(hidden_​​dim, hide_dim)
    self.linear4 = nn.Linear(hidden_​​dim, 1)
    self.relu = nn.ReLU()



  def 前向（自身，x）：
    out = self.relu(self.线性1(x))
    out = self.relu(self.线性2(out))
    输出 = self.relu(self.线性3(输出))
    输出 = torch.sigmoid(self.线性4(输出))
    返回

model = torch.load(&#39;bernoullimodel9.pth&#39;,map_location=device)

BernoulliSampleFunction 类（torch.autograd.Function）：
    @静态方法
    defforward(ctx, 概率, random_numbers):
        结果 = torch.zeros_like(概率)
        输入 = []
        输出 = []
        对于范围内的 i(probabilities.shape[1])：
          使用 torch.enable_grad()：
            输入 = torch.cat((概率[:, i].unsqueeze(1).double(), random_numbers[:, i].unsqueeze(1).double()), dim=1).clone().requires_grad_ （真的）
            输入.追加（输入）
            输出=模型（输入）
            输出.追加（输出）
            结果[:, i] = output.squeeze().detach()
        inputLength = torch.tensor(len(输入))
        输入.扩展（输出）
        ctx._dict = model.state_dict()
        ctx.save_for_backward(inputLength, *输入)
        返回结果

    @静态方法
    def向后（ctx，grad_output）：
      print(“grad_output:”,grad_output)
      输入长度，*输入= ctx.saved_tensors
      输出=输入[输入长度：]
      输入 = 输入[:输入长度]
      toReturn = torch.zeros_like(grad_output)
      toReturn2 = torch.zeros_like(grad_output)
      torch.set_grad_enabled(True)
      使用 torch.enable_grad()：
        模型=伯努利近似器(32)
       # model.load_state_dict(ctx._dict)
        对于 model.parameters() 中的参数：
          print(&quot;参数 1:&quot;,param)
        对于范围内的 i(toReturn.shape[1])：
          输入 = 输入[i].float()
          print(&quot;输入：&quot;,输入)
          输出=模型（输入）
          print(&quot;输出：&quot;,输出)
          delta, *g_pars = autograd.grad(输出, [输入] + list(model.parameters()), grad_output[:,i].unsqueeze(1).requires_grad_(),allow_unused=True)
          打印（“增量：”，增量）
          toReturn[:,i] = delta[:,0]
          toReturn2[:,i] = delta[:,1]
      print(&quot;返回：&quot;,返回)
      返回返回，返回2

尝试通过在 torch.enable_grad() 内部重新创建模型、为其提供相同的输入然后调用 autograd.grad 来获取相对于模型输入的梯度。仅当模型已初始化时，autograd.grad 才能正常工作，但如果我对其权重/偏差的值进行任何更改，则无论如何，梯度均为 0。我尝试了各种将训练模型的权重和偏差复制到新实例的方法； .copy_() 和 torch.no_grad(), param.data = savingParamTensor.如果我直接调用 .copy_() ，它会导致就地修改错误。对保存的输出调用 autograd.grad 也有相同的结果。
autograd.grad 仅在使用新初始化的模型时才起作用，但不可能更改权重并更新计算图。包括您是否在 .init 调用中更改它们。]]></description>
      <guid>https://stackoverflow.com/questions/78496967/trying-to-call-autograd-grad-on-a-model-inside-of-a-custom-autograd-function-wo</guid>
      <pubDate>Fri, 17 May 2024 16:52:11 GMT</pubDate>
    </item>
    <item>
      <title>nlp 中的无监督情感分析</title>
      <link>https://stackoverflow.com/questions/78495476/unsupervised-sentiment-analysis-in-nlp</link>
      <description><![CDATA[如何对未标记的数据进行情感分析，我查遍了互联网（给出了聚类算法），但效果不佳。如何对未标记的数据从头开始进行情感分析，例如使用深度学习。我的意思是大公司如何使用他们的数据进行情感分析之类的任务，他们是否标记了数百万数据
我尝试过一些聚类算法，如LDA、Kmeans，但效果不佳。
怎么做。
或者也许可以向我指出学习此内容的资源
我必须从头开始，而不是使用一些预训练的模型]]></description>
      <guid>https://stackoverflow.com/questions/78495476/unsupervised-sentiment-analysis-in-nlp</guid>
      <pubDate>Fri, 17 May 2024 11:51:53 GMT</pubDate>
    </item>
    <item>
      <title>神经网络回归的 Numpy 实现仅学习数据集的第一个样本</title>
      <link>https://stackoverflow.com/questions/78494357/numpy-implementation-of-neural-network-regression-learns-only-first-sample-of-th</link>
      <description><![CDATA[实现一个具有 16（特征）+1（偏差）输入和 1 个输出的回归任务的神经网络，我只使用 numpy 和向量化，当我在训练集上训练它时，输入的第一个样本是只有一个人学得很好，其他人都学了一点，但一点也不好。
我在反向传播操作中做错了什么吗？
通过在训练样本中添加值为 1 的特征，在第一层中实现偏差。
我尝试了不同的学习率和网络维度，但没有任何变化。这是我得到的输出，其中 l 是标签，y 是预测值，前 5 行是损失级数：
&lt;前&gt;&lt;代码&gt;损失：[8702.85226111]
损失：[6.46234854e-27]
损失：[1.61558713e-27]
损失：[4.03896783e-28]
损失：[0。]


左：131.042274 右：[131.042274]
左：64.0 右：[103.78313187]
l：89.429199 y：[30.54333083]
l：111.856492 y：[108.32052489]
左：69.3899 右：[57.11792288]

这是我用于此任务的 Colab 笔记本：
https://colab.research.google.com/drive/1SNEjgZQkmQW9LV8PSxE_Lx4VIQSjf1rP?usp=分享
向后传递：
def向后(l,y,输入,alpha=0.00001):
  l_out.d=o_d(l,y)
  l3.d=h_d(l_out.w,l3.z,l_out.d)
  l2.d=h_d(l3.w,l2.z,l3.d)
  l1.d=h_d(l2.w,l1.z,l2.d)
  #不确定
  l_out.dadw=da_dw(l_out.z,l3.a)
  l3.dadw=da_dw(l3.z,l2.a)
  l2.dadw=da_dw(l2.z,l1.a)
  l1.dadw=da_dw(l1.z,输入.T)

  l_out.e=w_e(l_out.dadw,l_out.d)
  l3.e=w_e(l3.dadw,l3.d)
  l2.e=w_e(l2.dadw,l2.d)
  l1.e=w_e(l1.dadw,l1.d)

  l_out.w=l_out.w-alpha*l_out.e
  l3.w=l3.w-alpha*l3.e
  l2.w=l2.w-alpha*l2.e
  l1.w=l1.w-alpha*l1.e

我正在对每个样本进行向后传递，首先计算输出层的增量，即
&lt;前&gt;&lt;代码&gt;#out 增量
def o_d(l,y):
  返回-(l-y)

然后对隐藏层执行相同的操作
#隐藏的增量
def h_d(w, z, d):
  temp=np.matmul(d.T,w)
  温度=relu_der(z)*温度
  返回温度

现在激活函数相对于每层权重的导数
def da_dw(z,a):
返回 np.outer(relu_der(z), a)

然后我通过执行计算每个权重的误差
def w_e(dadw,d):
  返回 badw * d[:, np.newaxis]

最后我更新了权重]]></description>
      <guid>https://stackoverflow.com/questions/78494357/numpy-implementation-of-neural-network-regression-learns-only-first-sample-of-th</guid>
      <pubDate>Fri, 17 May 2024 08:18:24 GMT</pubDate>
    </item>
    <item>
      <title>我的逻辑回归机器学习模型有问题</title>
      <link>https://stackoverflow.com/questions/78493918/i-am-having-problem-with-my-logistics-regression-machine-learning-model</link>
      <description><![CDATA[我的模型精度很差。此数据取自 https://archive.ics.uci .edu/dataset/15/breast+cancer+wisconsin+original 显示逻辑回归模型的准确度为 96%，所以问题确实出在我的模型中。我在 R 中构建了以下模型。
# 导入数据集
tumor_study &lt;- read.csv(“breast-cancer-wisconsin.data”, header = FALSE, na.strings = “NA”)

# 添加列名
特征&lt;-c(“id_number”，“ClumpThickness”，“Uniformity_CellSize”，
              “Uniformity_CellShape”、“边缘粘附”、
              “SingleEpithelial_CellSize”、“BareNuclei”、“Bland_Chromatin”、
              “Normal_Nucleoli”、“Mitoses”、“Class”）

colnames(tumor_study) &lt;- 特征

# 清洗数据
# 删除第一列（id_number）
肿瘤研究 &lt;- 肿瘤研究[,-1]

# 转换“?” BareNuclei 列中为 NA，然后为数字
tumor_study$BareNuclei[tumor_study$BareNuclei == &quot;?&quot;] &lt;- NA
tumor_study$BareNuclei &lt;- as.numeric(tumor_study$BareNuclei)

# 删除 BareNuclei 中缺失值的行
tumor_study &lt;-tumor_study[!is.na(tumor_study$BareNuclei),]

# 将类转换为因子
tumor_study$Class &lt;- 因子(tumor_study$Class, level = c(2, 4), labels = c(“良性”, “恶性”))

# 将数据集分为训练集和测试集
库（caTools）
设置.种子(123)
split &lt;-sample.split(tumor_study$Class, SplitRatio = 0.8)
Training_set &lt;-tumor_study[split == TRUE,]
test_set &lt;-tumor_study[split == FALSE,]

# 应用特征缩放
训练集[, 1:9] &lt;- 比例(训练集[, 1:9])
test_set[, 1:9] &lt;- 比例(test_set[, 1:9])

# 构建逻辑回归模型
分类器 &lt;- glm(公式 = Class ~ ., family = 二项式, data = Training_set)

# 预测训练集的概率
prob_y_train &lt;- 预测（分类器，类型 = &#39;响应&#39;，newdata = Training_set[,-10]）
Predicted_y_training &lt;- ifelse(prob_y_train &gt;= 0.5,“良性”,“恶性”)

# 使用 test_set 进行预测
prob_y_test &lt;- 预测（分类器，类型 = &#39;响应&#39;，newdata = test_set[,-10]）
Predicted_y_test &lt;- ifelse(prob_y_test &gt;= 0.5,“良性”,“恶性”)

# 使用混淆矩阵检查准确性
cm_test &lt;- 表(test_set[,10], Predicted_y_test)
打印（厘米_测试）

## 如果你检查准确度...它接近 2%

如何找出模型中的问题？]]></description>
      <guid>https://stackoverflow.com/questions/78493918/i-am-having-problem-with-my-logistics-regression-machine-learning-model</guid>
      <pubDate>Fri, 17 May 2024 06:43:30 GMT</pubDate>
    </item>
    <item>
      <title>具有 n 维卫星图像的多类 UNet</title>
      <link>https://stackoverflow.com/questions/78491587/multiclass-unet-with-n-dimensional-satellite-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78491587/multiclass-unet-with-n-dimensional-satellite-images</guid>
      <pubDate>Thu, 16 May 2024 17:28:46 GMT</pubDate>
    </item>
    <item>
      <title>我应该在 GitHub 上分享我的自我项目吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78484980/should-i-share-my-self-projects-on-github</link>
      <description><![CDATA[我一直在考虑是否应该在 GitHub 上分享我自己的项目。这些项目主要涉及机器学习，重点关注回归和分类任务。虽然我已经付出了努力，但我不确定是否值得清理代码并上传它。展示这些小项目实际上是否有益，或者最终只是浪费时间？]]></description>
      <guid>https://stackoverflow.com/questions/78484980/should-i-share-my-self-projects-on-github</guid>
      <pubDate>Wed, 15 May 2024 15:26:31 GMT</pubDate>
    </item>
    </channel>
</rss>