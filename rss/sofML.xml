<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Fri, 04 Apr 2025 18:24:21 GMT</lastBuildDate>
    <item>
      <title>如何在不平衡的多类NLP数据集中使用Pytorch来提高变压器模型（例如BERT）的性能？</title>
      <link>https://stackoverflow.com/questions/79555874/how-can-i-improve-performance-of-transformer-models-like-bert-using-pytorch-on-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79555874/how-can-i-improve-performance-of-transformer-models-like-bert-using-pytorch-on-a</guid>
      <pubDate>Fri, 04 Apr 2025 16:36:59 GMT</pubDate>
    </item>
    <item>
      <title>如何获得独立拆分的数据的单个P值或beta多样性[封闭]</title>
      <link>https://stackoverflow.com/questions/79555836/how-to-get-individual-p-value-or-beta-diversity-for-data-that-is-split-independe</link>
      <description><![CDATA[我使用其p值将基于0和1作为成对连接的独立网络与独立网络相关联。我现在知道什么是独立地与广告相关的，因为现在它们的连接基于成对连接，但我想知道他们对AD的个人连接。。]]></description>
      <guid>https://stackoverflow.com/questions/79555836/how-to-get-individual-p-value-or-beta-diversity-for-data-that-is-split-independe</guid>
      <pubDate>Fri, 04 Apr 2025 16:17:20 GMT</pubDate>
    </item>
    <item>
      <title>使用骰子构建张量流模型来生成反事实[封闭]</title>
      <link>https://stackoverflow.com/questions/79555811/building-a-tensorflow-model-using-dice-to-generate-counterfactuals</link>
      <description><![CDATA[我正在使用该数据集生成反事实的骰子软件包进行一个项目： https://archive.ics.uci.edu/dataset/144/statlog+gergers+credit+data  
我已经使用Sklearn后端工作了，但是我也想看看是否可以使用TF进行。果然，我试图让它起作用，但根本没有任何作用。我想知道是否有人有建立这些模型可以分享任何经验的经验。下面我为工作模型放了代码：
 导入dice_ml
导入大熊猫作为pd
来自dice_ml.utils进口帮助者＃实用程序功能
从sklearn.com possope导入columntransformer
从sklearn.semblection incort intim
来自sklearn.model_selection导入train_test_split
来自Sklearn.Pipeline Import Pipeline
从Sklearn.Preprocessing Import StandardardScaler，OneHotenCoder

＃步骤1：加载数据集
data_url =＆quort; https：//archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german/german.data＆quot; quot;
列= [状态&#39;&#39; “属性”，“年龄”，“&#39;&#39;
dataset = pd.read_csv（data_url，delim_whitespace = true，names =列）



dataset.head（）

target =数据集[&#39;target&#39;]
train_dataset，test_dataset，y_train，y_test = train_test_split（dataset，target，test_size = 0.2，randy_state = 42，stratefify = target）
x_train = train_dataset.drop（columns = [&#39;target&#39;]，axis = 1）
x_test = test_dataset.drop（columns = [&#39;target&#39;]，axis = 1）

d = dice_ml.data（dataFrame = dataset，continule_features = [&#39;duration&#39;，&#39;Creditamount&#39;，&#39;intermentRate&#39;，&#39;soltstentRate&#39;，&#39;reciends&#39;，&#39;age&#39;，&#39;age&#39;，&#39;nocustCredits&#39;，nucliable&#39;]，numlable&#39;]，outcome_name =&#39;target&#39;）
数值= [&#39;持续时间&#39;，&#39;Creditamount&#39;，&#39;intermantrate&#39;，&#39;soridence&#39;，&#39;age&#39;，&#39;aperecredits&#39;，&#39;numlable&#39;]
分类= x_train.columns.difference（数值）

packorical_transformer = pipeline（steps = [[
    （&#39;onehot&#39;，onehotencoder（handle_unknown =&#39;nighore&#39;））
）））

转换= columntransFormer（
    变形金刚= [
        （&#39;cat&#39;，cantorical_transformer，分类）
    ）））

clf = pipeline（steps = [（&#39;预处理程序&#39;，变换），
                        （&#39;分类器&#39;，RandomforestClassifier（）））））

型号= clf.fit（x_train，y_train）


m = dice_ml.model（model = model，backend =＆quot; sklearn＆quort;）

exp = dice_ml.dice（d，m，method =;随机;）

instance_index = dataset [dataset [&#39;target;] == 2] .index [0]
query_instance = x_test.loc [[instance_index]]
cf = exp.generate_counterfactuals（query_instance，total_cfs = 10，desired_range = none，
                                  desired_class =; quot; quot;
                                  permitted_range = none，features_to_vary =; all＆quot;）

打印（“在下面的特征重要性”
打印（“本地”
imp = exp.local_feature_importance（query_instance，cf_examples_list = cf.cf.cf_examples_list）
打印（imp.local_importance）

打印（“全球”）
cobj = exp.global_feature_importance（x_train [0:10]，total_cfs = 10，postthoc_sparsity_param = none）
打印（Cobj.summary_importance）


pd.set_option（&#39;display.max_columns&#39;，无）
cf.visualize_as_dataframe（show_only_changes = true）
cf.to_json（）

打印（“在下面调试”
print（model.predict（x_test [0：5]））
打印（test_dataset.loc [x_test.index，&#39;target;]）

cf.to_json（）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79555811/building-a-tensorflow-model-using-dice-to-generate-counterfactuals</guid>
      <pubDate>Fri, 04 Apr 2025 16:00:33 GMT</pubDate>
    </item>
    <item>
      <title>用于序数响应变量的机器学习算法[封闭]</title>
      <link>https://stackoverflow.com/questions/79555616/machine-learning-algorithm-for-an-ordinal-response-variable</link>
      <description><![CDATA[我想确定增强泥炭地恢复潜力的因素。
作为响应变量，我正在使用描述给定泥炭地的状况的数据，这些数据可以分类为好/中间/坏/破坏条件。您能告诉我哪种机器学习算法适合通过这种响应变量预测（可以将其与学校成绩进行比较）。
我还会寻找一些文献建议！]]></description>
      <guid>https://stackoverflow.com/questions/79555616/machine-learning-algorithm-for-an-ordinal-response-variable</guid>
      <pubDate>Fri, 04 Apr 2025 14:45:20 GMT</pubDate>
    </item>
    <item>
      <title>使用Python [封闭]在物体下的阴影效果</title>
      <link>https://stackoverflow.com/questions/79555124/shadow-effect-under-the-object-using-python</link>
      <description><![CDATA[我正在努力在汽车下添加落下阴影效果。有人知道该怎么做吗？
我正在附上两个图像：一个没有阴影，一个是阴影。我需要一个可以帮助我构建一个系统的人，可以使用阴影图像转换为无阴影图像
带有阴影图像：
 
没有阴影图像：
 ]]></description>
      <guid>https://stackoverflow.com/questions/79555124/shadow-effect-under-the-object-using-python</guid>
      <pubDate>Fri, 04 Apr 2025 11:00:20 GMT</pubDate>
    </item>
    <item>
      <title>在数字数据集中训练它后，模型将MNIST数据集中的数字误分类[封闭]</title>
      <link>https://stackoverflow.com/questions/79555122/model-misclassifies-digits-from-mnist-dataset-after-trained-it-on-digits-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79555122/model-misclassifies-digits-from-mnist-dataset-after-trained-it-on-digits-dataset</guid>
      <pubDate>Fri, 04 Apr 2025 10:59:17 GMT</pubDate>
    </item>
    <item>
      <title>ML模型将如何将二进制标志（0和1）视为正/负数或异常值？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79555055/how-will-an-ml-model-treat-binary-flags-0-and-1-as-positive-negative-or-as-ou</link>
      <description><![CDATA[我正在使用Arima和Prophet模型进行预测果汁销售。我的培训数据从2018年到2024年，我注意到2024年最后一个季度的销售突然增加，这在往年从未发生过。为此，我们在数据中添加了一个二进制标志，除了2024年的最后一个季度外，所有几个月的设置为0，设置为1。
我的问题是：预测模型（Arima和Prophet）是否将此标志视为异常值，还是会通过增加或减少预计的销售来影响预测？
对这些模型如何处理此类标志的任何见解将不胜感激！当我应用此标志时，预测结果并不乐观。]]></description>
      <guid>https://stackoverflow.com/questions/79555055/how-will-an-ml-model-treat-binary-flags-0-and-1-as-positive-negative-or-as-ou</guid>
      <pubDate>Fri, 04 Apr 2025 10:23:37 GMT</pubDate>
    </item>
    <item>
      <title>yolov11培训给火炬。</title>
      <link>https://stackoverflow.com/questions/79553429/yolov11-training-gives-torch-outofmemoryerror</link>
      <description><![CDATA[我正在尝试为一组图像训练Yolov11模型，但我遇到了一个问题。该模型正在训练的GPU是GeForce RTX 4070 Super。
我将yolov11与gpu一起用火炬。
  print（Torch .__版本__）
2.5.1+CU121
 
我在没有遇到此命令的问题之前几次训练了该模型：
  yolo任务=检测模式=火车设备= 0 epochs = 2000 batch = 32 data =; c：\ project \ yolo \ yolo \ data_custom.yaml; model =; c：\ project \ yolo \ yolov11m.pt; IMGSZ = 640
 
，但这并没有给我足够好的结果。因此，如果我以前理解“ imgsz”的价值来理解。到1440年（我的图像为2560 x 1440），该模型应训练剪钩质量的图像。所以我尝试运行此命令：
  yolo任务=检测模式=火车设备= 0 epochs = 2000 batch = 32 data =; c：\ project \ yolo \ yolo \ data_custom.yaml; model =; c：\ project \ yolo \ yolov11m.pt; IMGSZ = 640
 
运行此命令给我一个我不知道如何解决的错误。错误如下：
  TORCH.OUTOFMEMORYERROR：CUDA失败。试图分配1.48吉布。 GPU 0的总容量为11.99 GIB，其中0字节是免费的。在分配的内存19.12 GIB中，Pytorch分配了406.58 MIB，由Pytorch保留，但未分配。如果保留但未分配的内存是大的，请尝试设置pytorch_cuda_alloc_conf = Expandable_segments：true以避免碎片。  请参阅记忆管理（https://pytorch.org/docs/stable/notes/cuda.html#environment-variables）的文档。
 
有人如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/79553429/yolov11-training-gives-torch-outofmemoryerror</guid>
      <pubDate>Thu, 03 Apr 2025 15:54:34 GMT</pubDate>
    </item>
    <item>
      <title>indexError：目标1超出范围__ [关闭]</title>
      <link>https://stackoverflow.com/questions/79553292/indexerror-target-1-is-out-of-bounds</link>
      <description><![CDATA[我正在尝试使用Pytorch模型在多类分类问题中编写我的第一个代码，并且此错误出现在训练循环中。您能告诉我如何解决此错误
模型：
 导入火炬
从火炬进口

TORCH.MANUAL_SEED（1234）

nn_model类（nn.module）：
    def __init __（自我）：
        super（）.__ init __（）
        self.layer1 = nn.linear（len（x_train.columns），128）
        self.layer2 = nn.linear（128，64）
        self.layer3 = nn.linear（64，1）
        self.relu = nn.relu（）
        self.softmax = nn.softmax（）
    def向前（self，x）：
        x = self.relu（self.layer1（x））
        x = self.relu（self.layer2（x））
        x = self.sigmoid（self.layer3（x））
        返回x

型号= nn_model（）
model.state_dict（）
 
使用的损失功能和优化器：
 优化器= torch.optim.adam（lr = 0.001，params = model.parameters（））

loss_function = torch.nn.Crossentropyloss（）
 
训练和测试循环：
  epochs = 10000

对于范围内的时期（1，时期 + 1）：
    
    ＃训练循环
    model.train（）
    ＃1。向前传球
    
    y_pred = model（torch.tensor（np.array（x_train）））。float（））
    
    ＃2。计算损失
    
    损失= lose_function（torch.Round（y_pred）.float（），torch.tensor（np.array（y_train））。long（））
    
    ＃3。优化器零毕业
    
    优化器.zero_grad（）
    
    ＃4。向后损失
    
    loss.backward（）
    
    ＃5。优化步骤
    优化器.step（）
    
    如果epoch％1000 == 0：
        model.eval（）
        使用TORCH.Inference_mode（）：
            
            y_pred_val =型号（torch.tensor（np.array（x_cross_val））））
            
            loss_val = loss_function（torch.Round（y_pred_val）.long（），torch.tensor（np.array（y_cross_val））。long（））。

            
            print（f&#39;epoch：{epoch} |损失：{lose_val：4f}&#39;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79553292/indexerror-target-1-is-out-of-bounds</guid>
      <pubDate>Thu, 03 Apr 2025 14:51:31 GMT</pubDate>
    </item>
    <item>
      <title>用双输出TFLITE模型进行媒介图像分割</title>
      <link>https://stackoverflow.com/questions/79552491/mediapipe-image-segmentation-with-dual-output-tflite-model</link>
      <description><![CDATA[遵循MediaPipe的代码示例，我正在使用自己的自定义TFLITE模型来实现图像分割。这是我的代码：
  option
    base_options = base_options，
    Runnun_mode = mp.tasks.vision.runningmode.image，
    output_confidence_masks = true，
    output_category_mask = false
）

mp_image = mp.image.create_from_file（image_path）
使用Vision.imagesementer.create_from_options（选项）作为细分器：
    segmentation_result = segmenter.Sement（mp_image）
    output_mask = semengation_result.confidence_masks [0]
 
我遇到了以上代码的两个问题：

 该模型有两个输出：
输出0：name = Identity0，shape = [1，1]，type = numpy.float32 
输出1：name = identity1，shape = [1，x，y，z]，type = numpy.float32（其中x * y * z == image_width * image_height * image_channel = 1）
 如何检索两个输出，而不仅仅是一个？

  profure_masks值几乎相同（min/max = 0.0701157/0.070115715），这似乎是不寻常的。原始图像包含一个人，使用我的自定义TFLITE模型与tf.lite.interpreter.get_tensor（）。时，输出是正确的。


我知道许多框架都支持具有多个输入和输出的模型，因此我对可能缺少的内容感到困惑。这是我的具体问题：

我需要在Tflite模型文件中添加特殊元数据吗？
我应该如何修改原始MediaPipe代码来处理多个输出？
]]></description>
      <guid>https://stackoverflow.com/questions/79552491/mediapipe-image-segmentation-with-dual-output-tflite-model</guid>
      <pubDate>Thu, 03 Apr 2025 09:14:58 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测模型，带有XGBoost和Dask大数据集崩溃</title>
      <link>https://stackoverflow.com/questions/79547006/time-series-forecasting-model-with-xgboost-and-dask-large-datasets-crashing</link>
      <description><![CDATA[我正在Python建立一个时间序列预测模型，以预测公用事业公司不同客户类型的每小时KWH负载。该数据集包含约8100万行，在2  -  4年内为2300个客户提供每小时负载数据。客户类型由二进制列表示：EV，HP，太阳能和TOU。数据集具有以下变量：
   -  read_date：datetime64 [us]
   - 仪表：字符串
  -KWH：float64
   - 城市：弦
   - 温度：float64
  -EV：INT64
   - 太阳能：INT64
  -HP：INT64
  -TOU：INT64
   - 小时：INT32
   - 天：INT32
   - 月份：INT32
   - 年：INT64
  -day_of_week：int32
   - 季节：弦
  -customer_type：字符串
  -HOUR_SIN：FLOAT64
  -HOUR_COS：FLOAT64
  -month_sin：float64
  -month_cos：float64
  -Day_of_week_sin：float64
  -Day_of_week_cos：float64
  -Day_sin：float64
  -Day_cos：float64
   -  is_holiday：int64
  -City_Reading：INT64
  -City_lynnfield：INT64
  -City_NorthReading：INT64
  -City_wilmington：INT64
   - 季_WINTER：INT64
  -Season_spring：INT64
   -  sepen_summer：int64
   -  sepen_fall：INT64
 
After cleaning the data, I dropped the following features from both the training and test datasets: meter, customer_type, season, read_date, city, day, month, hour, day_of_week.我的目标变量是小时kWh负载。
我试图使用dask构建XGBoost模型以进行分发，但它一直在以下错误崩溃：
  essertionError：错误
2025-03-31 14：12：26,995-分布式。
 
我正在使用128GB RAM和Intel I7-14700K 3.40 GHz处理器的本地计算机工作。我正在寻找有关如何处理此大型数据集预测时间序列的指导，以及如何在使用DASK进行分发时避免崩溃。这是我的示例代码：
 ＃导入必要的库
导入numpy作为NP
导入dask.dataframe作为DD
导入dask.array作为da
导入XGBoost为XGB
来自dask.distribed Import客户端
来自dask.diarostics导入进步键 
来自sklearn.metrics incort cone_absolute_error，mean_squared_error，r2_score
进口警告
导入matplotlib.pyplot作为PLT
从TQDM导入TQDM

＃使用dask加载数据（大型镶木文件有效）
some_feats_dd = dd.read_parquet（&#39;pre_ml_some_features.parquet＆quort＆quot;）

＃重命名dataFrame
df_processed = some_feats_dd

＃基于读取_DATE进行训练和测试的数据
df_train = df_processed [df_processed [＆quot; 2025]＃在2025年之前保持行
df_test = df_processed [df_processed [&#39;Year; eart; quot; quot; quot; quort; quot; quort; quot&#39;== 2025]＃从2025年开始保持行

＃排除列并准备训练的功能和目标变量
dublude_cols = [kwh＆quot&#39;米，&#39;customer_type&#39;&#39;&#39; 
                ＆quot&#39;&#39;

＃准备培训功能（x）和目标变量（y）
x_train = df_train.drop（columns = ubl_cols）
y_train = df_train [＆quot; kwh＆quot;]

＃计算总长度并确保精确3个块
train_size = len（y_train.compute（））
test_size = len（df_test）＃无需计算，dask可以推断

＃用强制3个块将y_train和y_test转换为dask阵列
y_train = da.from_array（y_train.compute（），chunks =（train_size // 3，））
y_test = da.from_array（df_test [＆quot; kwh;]。compute（），chunks =（test_size // test_size // 2，））

＃确保与x_train和x_test的分区匹配
x_train = x_train.repartition（npartitions = 3）
x_test = x_test.repartition（npartitions = 3）

＃启动DASK客户端以进行并行处理
客户端=客户端（）

＃打印D​​ask仪表板URL
打印（f＆quot“ dask仪表板

＃从xgboost.dask使用daskdmatrix
dask_train_data = xgb.dask.daskdmatrix（客户端，x_train，y_train）

＃设置XGBoost的参数
params = {
    “目标”：“ reg：squaredErr”，＃回归任务
    &#39;eval_metric&#39;：&#39;rmse&#39;，
    &#39;tree_method&#39;：“历史”，＃使用基于直方图的方法来更快训练
    &#39;冗长&#39;：1，＃启用基本记录
}

＃初始化dask-xgboost模型
dask_gbr = xgb.dask.daskxgbregressor（**参数）

＃使用DASK训练模型（这将自动并行化）
使用进度栏（）：＃显示训练期间的进度
    dask_gbr.fit（dask_train_data）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79547006/time-series-forecasting-model-with-xgboost-and-dask-large-datasets-crashing</guid>
      <pubDate>Mon, 31 Mar 2025 18:33:41 GMT</pubDate>
    </item>
    <item>
      <title>Infror：导入onnx_cpp2py_export时DLL负载失败：动态链接库（DLL）初始化例程失败</title>
      <link>https://stackoverflow.com/questions/78996950/importerror-dll-load-failed-while-importing-onnx-cpp2py-export-a-dynamic-link</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78996950/importerror-dll-load-failed-while-importing-onnx-cpp2py-export-a-dynamic-link</guid>
      <pubDate>Wed, 18 Sep 2024 07:08:40 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：尺寸超出范围（预计在[-1，0]范围内，但获得1）</title>
      <link>https://stackoverflow.com/questions/48377214/runtimeerror-dimension-out-of-range-expected-to-be-in-range-of-1-0-but-go</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/48377214/runtimeerror-dimension-out-of-range-expected-to-be-in-range-of-1-0-but-go</guid>
      <pubDate>Mon, 22 Jan 2018 08:18:12 GMT</pubDate>
    </item>
    <item>
      <title>多个人工神经网络</title>
      <link>https://stackoverflow.com/questions/45160402/multiple-artificial-neural-networks</link>
      <description><![CDATA[我正在尝试建立一个多个人工神经网络，如图像（a）：
  （ source&gt; source ））
我希望每个网络在自己的域上独立工作。必须为其特定任务构建和培训单个网络。最终决定将根据单个网络的结果做出，通常称为专家网络或代理。
由于隐私，我无法共享我的数据。
我尝试使用Python中的TensorFlow设置此设置。它可以实现吗，如果是的，我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/45160402/multiple-artificial-neural-networks</guid>
      <pubDate>Tue, 18 Jul 2017 07:37:07 GMT</pubDate>
    </item>
    <item>
      <title>如何找到真实数据的概率分布和参数？</title>
      <link>https://stackoverflow.com/questions/37487830/how-to-find-probability-distribution-and-parameters-for-real-data</link>
      <description><![CDATA[我有一个来自 sklearn 的数据集，然后绘制了 load&gt; load_diabetes.target  data的分布（即 load&gt; load_diabetes.data 用于预测的回归值的值）。
使用python 3，如何获得该分布的分布类型和参数，最类似于？
我知道 target 值都是积极的，并且偏斜（potitve偏斜/右偏斜）。 。 。 Python有没有办法提供一些分布，然后最适合 target  data/vector？或者，根据给出的数据，实际建议适合？这对于具有理论统计知识但将其应用于“真实数据”的经验的人来说是真正有用的。
 奖金
使用这种类型的方法来弄清楚您的后验分布在“真实数据”中是什么是有意义的。如果没有，为什么不呢？
 来自sklearn.datasets import load_diabetes
导入matplotlib.pyplot作为PLT
进口海洋为SNS； sns.set（）
导入大熊猫作为pd

#get数据
data = load_diabetes（）
x，y_ = data.data，data.target

#ormanize数据
sr_y = pd.Series（y_，name =＆quot y_（目标向量分布）＆quot;）

#plot数据
图，ax = plt.subplots（）
sns.distplot（sr_y，bins = 25，color =; g＆quot; ax = ax）
plt.show（）
 
  &lt;img alt =“在此处输入图像描述” src =“ https://i.sstatic.net/ol9gk.png”]]></description>
      <guid>https://stackoverflow.com/questions/37487830/how-to-find-probability-distribution-and-parameters-for-real-data</guid>
      <pubDate>Fri, 27 May 2016 15:58:31 GMT</pubDate>
    </item>
    </channel>
</rss>