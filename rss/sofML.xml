<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 30 Oct 2024 18:23:14 GMT</lastBuildDate>
    <item>
      <title>TensorFlow InvalidArgumentError：ConcatOp 中的连接维度不匹配 - 形状不匹配</title>
      <link>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</guid>
      <pubDate>Wed, 30 Oct 2024 13:00:13 GMT</pubDate>
    </item>
    <item>
      <title>我的项目中可以使用任何机器学习算法吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/79140771/is-there-any-machine-learning-algorithm-to-use-in-my-project</link>
      <description><![CDATA[“我正在开发一个机器学习模型，根据用户在多个科目（例如能力和常识）上的测试成绩向他们推荐书籍。推荐应适应用户的表现水平，根据他们的得分是高于还是低于某些阈值来推荐不同的书籍。哪种 ML 算法最适合此目的，我需要包含哪种数据字段才能有效地训练模型？”
我尝试使用 K-最近邻 (KNN) 算法训练模型，数据集包含 user_id、科目名称、科目分数和推荐书籍等字段。但是，准确度得分很低，并且模型在根据用户分数推荐相关书籍方面的表现不如预期。由于我是机器学习领域的新手并且仍在学习，因此我正在寻求指导，了解哪些算法可能更有效，以及哪些其他数据字段可能有助于提高模型准确性。]]></description>
      <guid>https://stackoverflow.com/questions/79140771/is-there-any-machine-learning-algorithm-to-use-in-my-project</guid>
      <pubDate>Wed, 30 Oct 2024 10:54:06 GMT</pubDate>
    </item>
    <item>
      <title>训练 IP-Adapter plus 模型后的推理错误</title>
      <link>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</link>
      <description><![CDATA[我从以下位置下载了软件包
https://github.com/tencent-ailab/IP-Adapter

运行命令来训练 IP-Adapter plus 模型（输入：文本 + 图像，输出：图像）：
accelerate launch --num_processes 2 --multi_gpu --mixed_precision &quot;fp16&quot; \
tutorial_train_plus.py \
--pretrained_model_name_or_path=&quot;stable-diffusion-v1-5/&quot; \
--image_encoder_path=&quot;models/image_encoder/&quot; \
--data_json_file=&quot;assets/prompt_image.json&quot; \
--data_root_path=&quot;assets/train/&quot; \
--mixed_precision=&quot;fp16&quot; \
--resolution=512 \
--train_batch_size=2 \
--dataloader_num_workers=4 \
--learning_rate=1e-04 \
--weight_decay=0.01 \
--output_dir=&quot;out_model/&quot; \
--save_steps=3

训练过程中，出现提示，但训练可以继续：
已删除共享张量 {&#39;adapter_modules.27.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_v_ip.weight&#39;, &#39;adapter_modules.31.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_k_ip.weight&#39;, &#39;adapter_modules.31.to_v_ip.weight&#39;, &#39;adapter_modules.11.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_k_ip.weight&#39;, &#39;adapter_modules.25.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_k_ip.weight&#39;, &#39;adapter_modules.19.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_k_ip.weight&#39;, &#39;adapter_modules.29.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_v_ip.weight&#39;, &#39;adapter_modules.25.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_k_ip.weight&#39;, &#39;adapter_modules.9.to_v_ip.weight&#39;, &#39;adapter_modules.9.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_v_ip.weight&#39;, &#39;adapter_modules.27.to_v_ip.weight&#39;, &#39;adapter_modules.29.to_v_ip.weight&#39;, &#39;adapter_modules.19.to_k_ip.weight&#39;, &#39;adapter_modules.11.to_v_ip.weight&#39;}。这应该没问题，但请检查重新加载时是否收到任何警告

训练完成后，转换权重以生成 ip_adapter.bin，然后使用此文件中的以下模型路径运行推理代码 ip_adapter-plus_demo.py：
base_model_path = &quot;SG161222/Realistic_Vision_V4.0_noVAE&quot;
vae_model_path = &quot;stabilityai/sd-vae-ft-mse&quot;
image_encoder_path = &quot;models/image_encoder&quot;
ip_ckpt = &quot;out_model/demo_plus_checkpoint/ip_adapter.bin&quot;

显示错误：
raise RuntimeError(&#39;Error(s) in loading state_dict for {}:\n\t{}&#39;.format(
RuntimeError: Error(s) in loading state_dict for ModuleList:
state_dict 中缺少键：&quot;1.to_k_ip.weight&quot;, &quot;1.to_v_ip.weight&quot;, &quot;3.to_k_ip.weight&quot;, &quot;3.to_v_ip.weight&quot;, &quot;5.to_k_ip.weight&quot;, &quot;5.to_v_ip.weight&quot;, &quot;7.to_k_ip.weight&quot;, &quot;7.to_v_ip.weight&quot;, &quot;9.to_k_ip.weight&quot;, &quot;9.to_v_ip.weight&quot;, “11.to_k_ip.weight”, “11.to_v_ip.weight”, “13.to_k_ip.weight”, “13.to_v_ip.weight”, “15.to_k_ip.weight”, “15.to_v_ip.weight”, “17.to_k_ip.weight”, “17.to_v_ip.weight”, “19.to_k_ip.weight”, “19.to_v_ip.weight”, “21.to_k_ip.weight”, “21.to_v_ip.weight”, “23.to_k_ip.weight”, “23.to_v_ip.weight”, &quot;25.to_k_ip.weight&quot;, &quot;25.to_v_ip.weight&quot;, &quot;27.to_k_ip.weight&quot;, &quot;27.to_v_ip.weight&quot;, &quot;29.to_k_ip.weight&quot;, &quot;29.to_v_ip.weight&quot;, &quot;31.to_k_ip.weight&quot;, &quot;31.to_v_ip.weight&quot;.

什么步骤出错导致此错误？]]></description>
      <guid>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</guid>
      <pubDate>Wed, 30 Oct 2024 07:32:22 GMT</pubDate>
    </item>
    <item>
      <title>我们如何计算零膨胀泊松回归和零膨胀负二项回归的平均绝对误差（MAE）（R 或 python）？</title>
      <link>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</link>
      <description><![CDATA[现在，我尝试使用 Python 在进行零膨胀泊松回归和零膨胀负二项回归时计算平均绝对误差 (MAE)。
我将数据分为训练数据和测试数据。我使用下面的代码，但它不起作用。
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
import statsmodels.formula.api as smf
import tensorflow as tf
df = pd.read_excel(&#39;....&#39;, sheet_name=&#39;Sheet1&#39;)
print(df.head())
X = df[[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]
y = df[&#39;g&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from statsmodels.discrete.count_model import ZeroInflatedPoisson
y_zip = y_train.values

y_zip_test = y_test.values

X_count = X_train.values # 计数部分的预测器
X_zero = X_train.values # 零膨胀部分的预测器

X_count_test = X_test.values
X_zero_test = X_test.values

# 为截距添加一个常数
X_count = sm.add_constant(X_count)
X_zero = sm.add_constant(X_zero)

# 拟合 ZIP 模型
zip_model = ZeroInflatedPoisson(endog=y_zip, exog=X_count, exog_infl=X_zero, indication=&#39;logit&#39;)
zip_model_fit = zip_model.fit()
print(zip_model_fit.summary())

# 进行预测
y_pred = zip_model_fit.predict(X_count_test)

# 计算 MAE
mae = np.mean(np.abs(y_zip_test - y_pred))
print(f&#39;平均绝对误差：{mae}&#39;)

结果如下
-------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Cell In[3], line 33
29 print(zip_model_fit.summary())
32 # 进行预测
---&gt; 33 y_pred = zip_model_fit.predict(X_count_test)
35 # 计算 MAE 测试
36 mae = np.mean(np.abs(y_zip_test - y_pred))

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\base\model.py:1174，位于 Results.predict(self, exog, transform, *args, **kwargs)
1127 &quot;&quot;&quot;
1128 调用 self.model.predict 并以 self.params 作为第一个参数。
1129 
(...)
1169 返回预测。
1170 &quot;&quot;&quot;
1171 exog, exog_index = self._transform_predict_exog(exog,
1172 transform=transform)
-&gt; 1174 predict_results = self.model.predict(self.params, exog, *args,
1175 **kwargs)
1177 如果 exog_index 不为 None 且不 hasattr(predict_results,
1178 &#39;predicted_values&#39;):
1179 如果 predict_results.ndim == 1:

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\discrete\count_model.py:453，位于 GenericZeroInflated.predict(self, params, exog, exog_infl, Exposure, Offset, which, y_values)
449 params_main = params[self.k_inflate:]
451 prob_main = 1 - self.model_infl.predict(params_infl, exog_infl)
--&gt; 453 lin_pred = np.dot(exog, params_main[:self.exog.shape[1]]) + Exposure + Offset
455 # 重构：这很不靠谱，
456 # model_main 中应该有一个合适的预测方法
457 # 这只是 prob(y=0 | model_main)
458 tmp_exog = self.model_main.exog

ValueError：形状 (21,6) 和 (7,) 未对齐：6 (1 维) != 7 (0 维)

你能给我一些解决方案吗？
我试过计算 MAE，但多次出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</guid>
      <pubDate>Wed, 30 Oct 2024 07:04:19 GMT</pubDate>
    </item>
    <item>
      <title>Kong AI 代理插件：在 Kong AI 网关上配置自托管 LLM 的正确参数</title>
      <link>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</guid>
      <pubDate>Wed, 30 Oct 2024 03:54:46 GMT</pubDate>
    </item>
    <item>
      <title>对整个数据集进行标准化（MinMax）是否会对看不见的时间序列数据产生更好的结果？[关闭]</title>
      <link>https://stackoverflow.com/questions/79136221/normalization-minmax-on-the-whole-dataset-produces-better-results-on-unseen-ti</link>
      <description><![CDATA[我已经训练了一个模型，用于预测价格相对于 15 天的最小最大值：1 最大值；0 最小值；否则为 0.5。问题是 Keras 中的 mse 回归，该模型是无状态的：
RNN(PeepholeCell(units=2,activation=&#39;relu&#39;))
TimeDistributed(Dense(1))
Dense(1)
优化器是 Adam。形状：
test_X.shape = (69501, 1, 45); test_y.shape = (11508, 1, 1)
我进行了如下拟合：
history = model.fit(train_X, train_y,
epochs=num_epochs, batch_size=10080, validation_data=(test_X, test_y), verbose=2,
shuffle=False, callbacks=[
earlystopping,
reduce_lr
]
, class_weight=class_weights
)

我对不同的模型配置、学习率策略进行了不同的训练尝试，并使用了 2014 年至 2021 年的每小时汇总数据，并使用了 2019 年至 2021 年的数据进行测试。对于验证，我使用了当前未见的数据（最近 900 天），粒度为 1 天，（最近 900 * 24）粒度为 1 小时。要预测的 y 数据为 0（表示最小相对值）、1（表示最大值）和 0.5（否则）。标签 (y) 具有振荡统计数据，但在不同批次（平均值、标准差、最大值、最小值、QR）中随时间变化的幅度相同。除了一些大小反映价格幅度变化的特征外，这些特征还具有恒定范围（例如振荡器）。
我发现，通过回测对看不见的数据执行的最佳模型是仅将 MinMax 缩放器 (scikit) 应用于整个数据集的模型，如果仅通过拟合训练并使用训练拟合缩放器转换测试来应用，则结果无所谓。
是否存在计算原因或数据统计原因，说明为什么使用通过 scikitlearn 的 MinMax 规范化器预处理的数据训练的模型在拟合和转换整个数据集而不是在训练和使用该缩放器转换测试时产生类似的结果？]]></description>
      <guid>https://stackoverflow.com/questions/79136221/normalization-minmax-on-the-whole-dataset-produces-better-results-on-unseen-ti</guid>
      <pubDate>Tue, 29 Oct 2024 07:40:35 GMT</pubDate>
    </item>
    <item>
      <title>3D加工零件特征识别（点云、网格）</title>
      <link>https://stackoverflow.com/questions/79062004/3d-machining-part-feature-recognition-point-cloud-mesh</link>
      <description><![CDATA[我有一个加工部件 (.STL)，想要识别（并提取）它的加工特征。有些特征很简单，但有些更复杂，这就是为什么我认为机器学习方法会很合适，因为我无法用数学方式描述该特征。
有一个 FeatureNet，它基本上可以完成这项工作，但它无法识别多个特征，并且代码无法按预期工作。
我还知道 AAGNet，它可以完成我想要的工作，但它使用 .STEP 作为输入，但我有一个网格（如果我转换它，则是点云）。
由于有更多的点云存储库，我认为我可以使用它们来解决我的问题。像 FPFH 这样的东西是正确的方向吗，还是我走错了路？
如果我使用机器学习方法，我可以轻松创建标记数据集。]]></description>
      <guid>https://stackoverflow.com/questions/79062004/3d-machining-part-feature-recognition-point-cloud-mesh</guid>
      <pubDate>Mon, 07 Oct 2024 12:41:25 GMT</pubDate>
    </item>
    <item>
      <title>在 lightgbm 中，为什么 train 和 cv API 会接受 categorical_feature 参数，而它已经存在于数据集构造中</title>
      <link>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</link>
      <description><![CDATA[以下是 lightgbm 的 .cv API

lightgbm.cv(params, train_set, num_boost_round=100, folds=None, nfold=5, stratified=True, shuffle=True, metrics=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, fpreproc=None, seed=0, callbacks=None, eval_train_metric=False, return_cvbooster=False)

有一个参数cateogrical_feature

分类特征。如果是 int 列表，则解释为索引。如果是 str 列表，则解释为特征名称（也需要指定 feature_name）。

现在 .train API

lightgbm.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, keep_training_booster=False, callbacks=None)

这里还有一个 categorical_feature 参数。文档与上述相同
现在，正如您所注意到的，这两个 API 都使用 lightgbm 数据集，而该数据集本身采用 categorical_feature 参数。文档完全相同
问题：

如果两者都指定，哪一个优先？
建议在哪个位置指定 categorical_feature？
这两个选择在内部与 lightgbm 管道的工作方式有何不同？
]]></description>
      <guid>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</guid>
      <pubDate>Thu, 25 Apr 2024 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层“顺序”的输入 0 与层不兼容</title>
      <link>https://stackoverflow.com/questions/71370360/valueerror-input-0-of-layer-sequential-is-incompatible-with-the-layer</link>
      <description><![CDATA[我有一个聊天机器人模型，我用数据集对其进行了训练，以提供“标准”对话，例如你好，你好吗等。现在我想用一个数据集来“扩展”现有模型，该数据集可以提供与运输、库存等相关的问题的答案。
这是我的工作/已经训练过的模型：
# 创建顺序模型
model = Sequential()

# 添加第一层，其输入形状取决于输入的大小和“relu”激活函数
model.add(Dense(256, input_shape=(len(training_data_x[0]),),activation=activations.relu))

# 添加 Dropout 以防止过度拟合
model.add(Dropout(0.6))
# 具有 64 个神经元的附加层
model.add(Dense(128,activation=activations.relu))
model.add(Dropout(0.2))
# 具有类别神经元数量的附加密集层 &amp; softmax 激活函数
# -&gt; 将输出层中的结果添加到“1”得到 %
model.add(Dense(len(training_data_y[0]),activation=activations.softmax))
# print(len(training_data_y[0])) = 71
sgd = SGD(learning_rate=0.01, decay=1e-6, motivation=0.9, nesterov=True)
# 编译模型
model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd, metrics=[&#39;accuracy&#39;])

output = model.fit(np.array(training_data_x), np.array(training_data_y), epochs=200, batch_size=5, verbose=1)
plot_model_output(output)
model.summary()
model.save(&#39;./MyModel_tf&#39;, save_format=&#39;tf&#39;)

训练数据准备如下一个单独的类，并将某个 json 文件作为输入。
现在我只需将 JSON 文件替换为包含与我想添加到模型中的内容相关的数据的文件，并尝试像这样拟合它：
json_data = json.loads(open(&#39;data.json&#39;).read())

model = load_model(&#39;MyModel_tf&#39;)

model.fit(np.array(training_data_x), np.array(training_data_y), epochs=200, batch_size=5, verbose=1)

但是当我运行它时，我收到此错误：
ValueError: 输入 0 of layer &quot;sequence&quot;与层不兼容：预期形状=（无，652），发现形状=（无，71）

我假设数据是问题所在……但它的结构完全相同，只是更短。
我的问题：

我尝试实现它的方式有意义吗？
我应该尝试以不同的方式添加其他数据吗？
第二个数据集的长度必须与第一个数据集的长度相同吗？
]]></description>
      <guid>https://stackoverflow.com/questions/71370360/valueerror-input-0-of-layer-sequential-is-incompatible-with-the-layer</guid>
      <pubDate>Sun, 06 Mar 2022 12:41:31 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：不可散列类型：pd.get_dummies 的“Series”</title>
      <link>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</link>
      <description><![CDATA[我尝试对我拥有的数据框中的一些名义数据（来自 Kaggle 的 House Regression）使用 pd.get_dummies。我将所有名义类别分成列名列表，&#39;obj_nominal&#39;。
当我调用
pd.get_dummies(df, columns=obj_nominal)

我收到错误：
TypeError: unhashable type: &#39;Series&#39;.

到目前为止，我所做的唯一预处理是删除数据集中的空值。我也尝试过使用 Sklearn OneHotEncoder，但它会产生相同的错误。
我也尝试过使用以下方法制作单独的数据框：
x = df.iloc[:, obj_nominal]

并在数据框上传递 get_dummies：
pd.get_dummies(data = x)

但还是没运气……
数据可在 https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data 下载]]></description>
      <guid>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</guid>
      <pubDate>Fri, 07 Jan 2022 05:51:22 GMT</pubDate>
    </item>
    <item>
      <title>我如何获得 LPRNet 的置信度分数？</title>
      <link>https://stackoverflow.com/questions/64421715/how-can-i-get-the-confidence-scores-of-lprnet</link>
      <description><![CDATA[我是 openvino 工具包提供的 LPRNet 的新手：
https://github.com/openvinotoolkit/training_extensions
我想获得预测结果的概率，但似乎 tf.nn.ctc_greedy_decoder 只返回 neg_sum_logits，我不确定如何将其转换为概率。
有人知道我该如何得到它吗？
任何建议都将不胜感激！
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/64421715/how-can-i-get-the-confidence-scores-of-lprnet</guid>
      <pubDate>Mon, 19 Oct 2020 05:41:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 LPRNet 和 CTCLoss 在 pytorch/keras 中进行 OCR 时无法收敛</title>
      <link>https://stackoverflow.com/questions/61571491/ocr-in-pytorch-keras-with-lprnet-and-ctcloss-doesnt-converge</link>
      <description><![CDATA[我先在 keras 中实现了这篇论文中的 LPRNet，然后在 pytorch 中实现了它。对于 pytorch，我使用了此代码作为示例。它在任何版本中都没有收敛。即使在 150000 个 epoch 之后，损失也从 30 开始下降到 27。在 pytorch 版本中，我没有使用验证，以便更快地进行训练。
我尝试过：

使用 xavier_uniform_、xavier_normal 和我在 torch.nn.init 中找到的所有其他内容初始化 conv2d 权重
使用另一个数据集，其中包含其他人用于其 rcnn ocr 模型的 50 张清晰图像
尝试使用 sgd 而不是 adam

使用 pytorch 的完整 colab 位于此处，我的数据集位于此处
在 keras 中，我曾经成功地使模型在训练集上过度拟合。我的训练集只有 50 张图像，但我应用了随机效应以避免过度拟合。在他们的论文中，作者没有说明他们使用了多大的数据集。问题可能出在模型实现上？此外，原始论文包含空间变换器网络，我没有使用，因为他们说它是可选的，但它的缺失会是个问题吗？
class Softmax(nn.Module):
def __init__(self):
super().__init__()

def forward(self, x):
#se aplica pt torch.Size([1, 30, 1, 74])
return torch.nn. functional.log_softmax(x, 3)

class Reshape(nn.Module):
def __init__(self):
super().__init__()

def forward(self, x):
# se aplica pt torch.Size([1, 30, 1, 74])
#pentru CTCloss
#trebuie sa fie (T,N,C) ，其中 T=输入长度，N=批量大小，C=数量类
x = x.permute(3, 0, 1, 2)
return x.view(x.shape[0], x.shape[1], x.shape[2])

def init_weights(m):
if type(m) == nn.Conv2d:
torch.nn.init.xavier_uniform_(m.weight)
#m.bias.data.fill_(0.01)

class small_basic_block(nn.Module):
def __init__(self, ch_in, ch_out):
super().__init__()
self.block = nn.Sequential(
nn.Conv2d(ch_in, ch_out//4, kernel_size=1),
nn.ReLU(),
nn.Conv2d(ch_out//4, ch_out//4, kernel_size=(3,1), padding=(1,0)),
nn.ReLU(),
nn.Conv2d(ch_out//4, ch_out//4, kernel_size=(1,3), padding=(0,1)),
nn.Conv2d(ch_out//4, ch_out, kernel_size=1)
)
self.block.apply(init_weights)

def forward(self, x):
return self.block(x)

class LPRNet(nn.Module):
def __init__(self, class_num):
super().__init__()
self.lprnet = nn.Sequential(
nn.Conv2d(3, 64, kernel_size=3, stride=1),
nn.BatchNorm2d(num_features=64),
nn.ReLU(),
nn.MaxPool2d(kernel_size=3, stride=1),
small_basic_block(ch_in=64, ch_out=128),
nn.BatchNorm2d(num_features=128),
nn.ReLU(),
nn.MaxPool3d(kernel_size=(1, 3, 3), stride=(2, 2, 1)),
small_basic_block(ch_in=64, ch_out=256),
nn.BatchNorm2d(num_features=256),
nn.ReLU(),
small_basic_block(ch_in=256, ch_out=256),
nn.BatchNorm2d(num_features=256),
nn.ReLU(),
nn.MaxPool3d(kernel_size=(1,3,3), stride=(4,2,1)),
nn.Dropout(0.5),
nn.Conv2d(64, 256, kernel_size=(4,1), stride=1),
nn.BatchNorm2d(num_features=256),
nn.ReLU(),
nn.Dropout(0.5),
nn.Conv2d(256, class_num, kernel_size=(1,13), stride=1),
nn.BatchNorm2d(num_features=class_num),
nn.ReLU(), # torch.Size([1, 30, 1, 74])
Softmax(),
Reshape()
)
self.lprnet.apply(init_weights)

def forward(self, x):
return self.lprnet(x)

ctc_loss = nn.CTCLoss(blank=alphabet.index(&#39;$&#39;))

model = LPRNet(len(alphabet)+1)
model.to(dev)
opt = optim.Adam(model.parameters())
scheduler = optim.lr_scheduler.StepLR(opt, step_size=100000, gamma=0.1)

def train(epochs):
for i in range(epochs):
X_data, Y_data, X_data_len, Y_data_len = train_set.next_batch()
X_data = model(X_data)
loss = ctc_loss(X_data, Y_data, X_data_len, Y_data_len)
loss.backward()
opt.step()
opt.zero_grad()
scheduler.step()
]]></description>
      <guid>https://stackoverflow.com/questions/61571491/ocr-in-pytorch-keras-with-lprnet-and-ctcloss-doesnt-converge</guid>
      <pubDate>Sun, 03 May 2020 08:18:14 GMT</pubDate>
    </item>
    <item>
      <title>维度问题：检查输入时出错：预期 conv2d_1_input 有 4 个维度，但得到的数组形状为 (26, 26, 1)</title>
      <link>https://stackoverflow.com/questions/60802354/dimension-problems-error-when-checking-input-expected-conv2d-1-input-to-have-4</link>
      <description><![CDATA[我有一个 CNN，它以以下通过 Canny 边缘检测转换为二值图像的图像作为输入。
​​并输出三个类别之一。
img = cv2.imread(path)
img = cv2.Canny(img, 33, 76)
img = np.resize(img, (26, 26, 1))
imgs.append(img)

据我所知，我必须将其转换为 3 维 (26,26,1) 图像，以便网络可以使用它。这是我的网络：
IMG_HEIGHT = 26
IMG_WIDTH = 26
no_Of_Filters=60
size_of_Filter=(5,5)
size_of_pool=(2,2)
no_Of_Nodes = 500
model_new = Sequential([
Conv2D(no_Of_Filters, size_of_Filter, padding=&#39;same&#39;,activation=&#39;relu&#39;, input_shape=(IMG_HEIGHT, IMG_WIDTH , 1)),
MaxPooling2D(pool_size=size_of_pool),
Conv2D(no_Of_Filters, size_of_Filter, padding=&#39;same&#39;,activation=&#39;relu&#39;),
MaxPooling2D(pool_size=size_of_pool),
Conv2D(64, size_of_Filter, padding=&#39;same&#39;,激活=&#39;relu&#39;),
MaxPooling2D(pool_size=size_of_pool),
Flatten(),
Dense(512, 激活=&#39;relu&#39;),
Dense(3, 激活=&#39;softmax&#39;)
])

训练效果良好。在我训练并创建模型后，我想针对该网络测试图像
test_image = cv2.Canny(test_image ,33,76)
test_image = np.resize(test_image, (26, 26, 1))
test_image = test_image [np.newaxis, ...]
prediction = model.predict(test_image)
print(prediction)

现在我收到错误：
ValueError：检查输入时出错：预期 conv2d_1_input 有 4 个维度，但得到的数组形状为 (26, 26, 1)

为什么训练后的模型现在需要 4 维输入？]]></description>
      <guid>https://stackoverflow.com/questions/60802354/dimension-problems-error-when-checking-input-expected-conv2d-1-input-to-have-4</guid>
      <pubDate>Sun, 22 Mar 2020 17:06:46 GMT</pubDate>
    </item>
    <item>
      <title>我们如何解释负调整兰特指数？</title>
      <link>https://stackoverflow.com/questions/42418773/how-can-we-interpret-negative-adjusted-rand-index</link>
      <description><![CDATA[调整后的随机指数 (ARI) 是比较两个聚类的常用指标。不幸的是，在执行聚类分析并进行比较后，我通常会得到负 ARI。我该如何解释这些负 ARI 来描述这些聚类之间的差异？如果负 ARI 毫无意义，有什么关于适当指标的建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/42418773/how-can-we-interpret-negative-adjusted-rand-index</guid>
      <pubDate>Thu, 23 Feb 2017 14:38:38 GMT</pubDate>
    </item>
    <item>
      <title>MATLAB NN 工具箱：使用 trainlm 时出错</title>
      <link>https://stackoverflow.com/questions/21180830/matlab-nn-toolbox-error-using-trainlm</link>
      <description><![CDATA[我有一个 90×8 的数据集，我从 90 个字符图像（即数字 1-9）中提取了特征（通过在每个 10×10 单元格中对 1 求和）。每行代表一个图像。
我正在尝试使用以下代码来训练神经网络并识别新的输入图像（数字介于 1 和 9 之间）：
net.trainFcn=&#39;traingdx&#39;;
net.performFcn=&#39;sse&#39;;
net.trainParam.goal=0.1;
net.trainParam.show=20;
net.trainParam.epochs=5000;
net.trainParam.mc=0.95;
net =newff(minmax(datasetNormalized&#39;),[20 9],{&#39;logsig&#39; &#39;logsig&#39;});
T=reshape(repmat([1:9],10,1),1,90);
[net,tr]=train(net,datasetNormalized,T);

之后我想使用下面的方法使用训练好的网络识别新图像。m 是一个也经过特征提取的图像字符。
[a,m]=max(sim(net,m));
disp(b);

我遇到了以下错误，但我不知道该如何解决：

使用 trainlm 时出错（第 109 行）
输入和目标的样本数量不同。
network/train 中的错误（第 106 行）[net,tr] =
feval(net.trainFcn,net,X,T,Xi,Ai,EW,net.trainParam);
Neural 中的错误（第 55 行）[net,tr]=train(net,datasetNormalized,T);

注意：datasetNormalized 是我的数据集在 [0,1] 中标准化。
哪个部分导致了问题？]]></description>
      <guid>https://stackoverflow.com/questions/21180830/matlab-nn-toolbox-error-using-trainlm</guid>
      <pubDate>Fri, 17 Jan 2014 08:08:16 GMT</pubDate>
    </item>
    </channel>
</rss>