<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Fri, 21 Mar 2025 06:27:30 GMT</lastBuildDate>
    <item>
      <title>Google Colab：模型培训会自动停止，好像按下Ctrl+C</title>
      <link>https://stackoverflow.com/questions/79524578/google-colab-model-training-stops-automatically-as-if-ctrlc-was-pressed</link>
      <description><![CDATA[我正在Google Colab中训练Yolo模型，但是训练会自动停止，好像我手动按下CTRL+C一样。终端中的最后一个输出显示 ^C，该过程终止而没有任何错误消息。
 没有错误，只有 ^c ^c看起来好像我手动中断   ]]></description>
      <guid>https://stackoverflow.com/questions/79524578/google-colab-model-training-stops-automatically-as-if-ctrlc-was-pressed</guid>
      <pubDate>Fri, 21 Mar 2025 04:58:16 GMT</pubDate>
    </item>
    <item>
      <title>catboost问题？ numpy.dtype的大小改变了，可能表明二进制不兼容。预计从C标头96，从PyObject获得88</title>
      <link>https://stackoverflow.com/questions/79524538/catboost-problem-numpy-dtype-size-changed-may-indicate-binary-incompatibility</link>
      <description><![CDATA[ ＃基本导入
导入numpy作为NP
导入大熊猫作为pd
导入matplotlib.pyplot作为PLT 
进口海洋作为SNS
＃建模
来自sklearn.metrics导入均值_squared_error，r2_score
来自Sklearn.neighbors进口kneighborsregressor
从Sklearn.Tre Import DecisionTreeTreeGressor
来自Sklearn.smentermemble Import RandomForestRegressor，adaboostregressor
来自Sklearn.svm导入SVR
来自sklearn.linear_model导入线性重试，山脊，拉索
来自sklearn.metrics import r2_score，mean_absolute_error，mean_squared_error
来自sklearn.model_selection导入随机搜索
来自Catboost Import Catboostregressor
从XGBoost Import XGBRegressor
进口警告
 
当我评论catboost 时，一切都完美地导入
使用Python 3.12.0
我已经尝试过：
升级所有相关库（pip install -upgrade＆lt; package_name＆gt;）。
检查使用PIP列表的过时的软件包 - 已更新。
创建一个新的虚拟环境并重新安装所有内容。
 ive尝试了numpy（＆lt; 2.0.0）的不同版本下载
 idk现在该怎么办
错误：
  value error trackback（最近的最新呼叫）
[17]中的单元，第15行
     13来自sklearn.metrics导入r2_score，mean_absolute_error，mean_squared_error
     14来自sklearn.model_selection导入随机搜索
---＆gt; 15来自Catboost Import Catboostregressor
     16来自XGBoost Import XGBRegressor
     17进口警告

文件D：\ git-repos \ end-to-end \ venv \ lib \ lib \ site-packages \ catboost \ catboost \ __ init__.py:1
----＆gt; 1来自.core导入（
      2个功能data，efstrtype，eshapcalctype，efeatureslectionalgorithm，efeaturesleslectiongrouping，
      3池，catboost，catboostClassifier，catboostregressor，catboostranker，catboostror，简历，sample_gaussian_process，train，train，
      4 sum_models，_have_equal_features，to_regressor，to_classifier，to_ranker，multiregressioncustompomtric，
      5个多何件限制态原则，多坐维仪，多坐维群岛。
      6）＃NOQA
      7来自.version导入版本为__vers__＃noqa
      8 __ all__ = [
      9&#39;featuresdata&#39;，&#39;efstrype&#39;，&#39;eshapcalctype&#39;，&#39;efeatureSelectionalgorithm&#39;，&#39;efeatureSelectiongrouping&#39;，&#39;
     10“池”，“ catboost”，“ catboostClassifier”，“ catboostregressor&#39;，&#39;catboostranker&#39;，&#39;catboostror&#39;，&#39;catboostror&#39;，&#39;
   （...）13&#39;MultitargetCustomtric&#39;，&#39;MultitargetCustomObjective&#39;
     14]

文件D：\ git-repos \ end-to-end \ venv \ lib \ site-packages \ catboost \ core.py.py：45
     40通行证
     42进口Scipy.sparse
---＆gt; 45来自.plot_helpers导入save_plot_file，try_plot_offline，offlineMetricVisualizer
     46来自。导入_catboost
     47来自.metrics Itmotinmetric

文件D：\ git-repos \ end-to-end \ venv \ lib \ site-packages \ catboost \ catboost \ plot_helpers.py：5
      2导入OS
      3进口警告
----＆gt; 5来自。导入_catboost
      6 fspath = _catboost.fspath
      9 def try_plot_offline（图）：

文件_catboost.pyx：1，在init _catboost（）中

ValueError：numpy.dtype的大小更改，可能表示二进制不兼容。预计从C标头96，从PyObject获得88
 ]]></description>
      <guid>https://stackoverflow.com/questions/79524538/catboost-problem-numpy-dtype-size-changed-may-indicate-binary-incompatibility</guid>
      <pubDate>Fri, 21 Mar 2025 04:15:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的代码不导致张量的错误“元素0”不需要毕业，也不需要grad_fn'</title>
      <link>https://stackoverflow.com/questions/79524465/why-does-not-my-code-cause-the-error-element-0-of-tensors-does-not-require-grad</link>
      <description><![CDATA[给定下面的代码片段，我使用 model.fc1.requires_grad_（false） and  model.fc2.requires_grad_（false）冻结神经网络的权重。
如果我使用损失=标准（输出，y_batch）来计算损失，则训练很好。但是，当我使用 lose = Compute_loss（Model）计算损失时，我会得到错误 RuntimeError：Tensors的Element 0不需要Grad，并且没有Grad_fn 。为什么不 lose = Criterion（输出，y_batch）导致错误？
  def Compute_loss（模型）：
    对于_，params中的params.named_pa​​rameters（）：
        损失= sum（参数）
    回报损失

类SimpleNet（nn.Module）：
    def __init __（self，input_size，hidden_​​size，output_size）：
        超级（SimpleNet，Self）.__ INIT __（）
        self.fc1 = nn.linear（input_size，hidden_​​size）
        self.fc2 = nn.linear（hidden_​​size，output_size）

    def向前（self，x）：
        x = self.fc1（x）
        x = self.fc2（x）
        返回x

model = simpleNet（input_size，hidden_​​size，output_size）

标准= nn.Crossentropyloss（）
优化器= Optim.SGD（model.parameters（），lr = Learning_rate）

对于范围（num_epochs）的时代：
    对于emumerate（dataloader）中的batch_idx（x_batch，y_batch）：
        优化器.zero_grad（）
        输出=模型（x_batch）
        损失=标准（输出，y_batch） 
        ＃损失= compute_loss（模型）
         
        loss.backward（） 
        优化器.step（） 
                
        if（batch_idx + 1）％10 == 0：
            model.fc1.requires_grad_（false）
            model.fc2.requires_grad_（false）
                        
打印（“训练完成！”）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79524465/why-does-not-my-code-cause-the-error-element-0-of-tensors-does-not-require-grad</guid>
      <pubDate>Fri, 21 Mar 2025 02:40:41 GMT</pubDate>
    </item>
    <item>
      <title>如何根据整天的订单时间正确群集每日交货方式？</title>
      <link>https://stackoverflow.com/questions/79524308/how-to-correctly-cluster-daily-delivery-patterns-based-on-order-time-through-the</link>
      <description><![CDATA[我有一个数据集，该数据集在不同时间记录每天的订单数（交货），我正在尝试使用聚类来识别高峰交付期。但是，我在获得有意义的集群方面面临着挑战。
我尝试的是：
 dbscan：

 在这个时间序列的数据中努力识别单独的簇。

 它要么将所有内容分为一个群集，要么产生了太多的小噪声点。


分层聚类：

 多个峰的顶部被分组到同一群集中。

 多个山谷的底部也分为类似的集群。

 结果，我只得到四个主要集群，这与不同的基于时间的峰。


我需要帮助：

 如何更好地段交付时间？

 高斯混合模型（GMM），K-均值或特定时间序列的聚类会更好吗？

 我应该尝试的功能工程技术，例如以不同的方式汇总数据或转换时间变量？


 图形强调部分  
 带有彩色部分的图形  
代码
 
x = df [&#39;time_in_minutes&#39;]。values.reshape（-1，1）
y = df [&#39;orders&#39;]。values.reshape（-1，1）

＃使用Min-Max缩放扩展数据
sualer = minmaxscaler（）
X_SCALED = Scaleer.fit_transform（x）
y_scaled = scale.fit_transform（y）

＃结合聚类的功能
data_scaled = np.hstack（（x_scaled，y_scaled））

＃情节树状图（更好的可视化）
plt.figure（无花果=（12，6））
plt.title（层级聚类的树状图；）
plt.xlabel（“数据点”）
plt.ylabel（“距离”）

＃使用truncate_mode避免压缩问题
sch.dendrogram（sch.linkage（data_scaled，method =&#39;ward&#39;），truncate_mode =＆quot;
plt.show（）

＃应用分层集群
num_clusters = 4＃根据树状图调整
hc = groclomerativeclustering（n_clusters = num_clusters，metric =&#39;euclidean&#39;，linkage =&#39;ward&#39;）
df [&#39;cluster&#39;] = hc.fit_predict（data_scaled）

＃带有不同颜色的绘图群集（修复：使用数字time_in_minutes）
plt.figure（无花果=（12，6））
对于范围内的群集（num_clusters）：
    plt.scatter（df.loc [df [&#39;cluster&#39;] == cluster，&#39;time_in_minutes&#39;]， 
                df.loc [df [&#39;cluster&#39;] ==群集，&#39;arrivals&#39;]， 
                label = f&#39;cluster {cluster}&#39;，alpha = 0.7）

plt.xlabel（&#39;time（分钟）&#39;）
plt.ylabel（“订单”）
plt.title（“随着时间的时间订单”）
plt.legend（）
plt.grid（true，linestyle =&#39; - &#39;，alpha = 0.5）
plt.show（）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79524308/how-to-correctly-cluster-daily-delivery-patterns-based-on-order-time-through-the</guid>
      <pubDate>Thu, 20 Mar 2025 23:51:07 GMT</pubDate>
    </item>
    <item>
      <title>我可以在iPhone上实现离线面部识别吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79524096/can-i-implement-offline-face-recognition-on-iphone</link>
      <description><![CDATA[我正在研究 flutter的iOS应用程序，该应用程序使用离线面部识别在周日校车期间跟踪孩子。目的是用脸识别孩子。这是计划的工作流程：

  到达星期日学校：给每个孩子的照片。

如果已识别→标记为存在。
如果不确定→提出类似的手动确认匹配。
如果新→创建一个新的配置文件。


  回家旅行：扫描每个孩子并与存储的数据进行比较。

生成失踪的孩子  
创建一个订购的下车列表，随着孩子的掉落，它会实时更新。


  持续学习：每周每周将两张照片存储（到达＆amp;出发）提高识别精度随着时间的流逝。


问题：

我可以在 iOS设备上完全离线实现高质量的面部识别（iPhone 11）？
什么 flutter软件包或核心ML模型我应该研究吗？
 是否会在设备培训（每周更新面部数据集）是可行的吗？
]]></description>
      <guid>https://stackoverflow.com/questions/79524096/can-i-implement-offline-face-recognition-on-iphone</guid>
      <pubDate>Thu, 20 Mar 2025 21:14:13 GMT</pubDate>
    </item>
    <item>
      <title>如何从Pytorch中的自定义任意损失功能更新模型权重？</title>
      <link>https://stackoverflow.com/questions/79523864/how-to-update-model-weights-from-a-custom-arbitrary-loss-function-in-pytorch</link>
      <description><![CDATA[从最后开始：

无论如何，我可以通过调用一些pytorch函数来编写任意损失功能，从而保留自动射击图？
我如何确保我的损失功能是“有线的”到自动射击？
如果无法做到，我该如何将损失分数倒退？


嗨，我正在Pytorch创建一个神经网络，我需要创建一个任意损失功能。
我想训练一个能够预测没有已知标签的输出的模型。我并不真正在乎实际输出，而是对此语义。换句话说，我想验证输出“有意义”。因此，我决定设计自己的损失功能。
  input_data 是（M，4）张量， output_data 是（M，M） tensor。
然后，我从 outpe&gt; outption_data 和 m 和 m 和 pre_input_data 中构造 m 的UUID列表。
“预输入”数据是一个简短的JSON对象，其中有几个字段，例如UUID。
如果该模型预测了一个“距离之外”的价值。相应的输出数据等于无。
有效性函数仅计算出界外结果的总和并返回。
我的问题是损耗功能断开了自动摩rad，我的模型的权重根本不更新。

 ＃velitiesloss被计算为```&#39;&#39;&#39;结果的总和。
class Vivelitiesloss（nn.模块）：
    def __init __（自我）：
        super（valiesityloss，self）.__ INIT __（）

    def向前（
        自己， 
        输出：（列表[输出]，列表[输出]），
    ）：
        bef，aft =输出
        
        损失= self .__ compute_loss（bef.output）
        损失 += self .__ compute_loss（aft.output）

        返回TORCH.TENSOR（float（lose），需要_grad = true）

    def __compute_loss（self，x） - ＆gt; INT：
        损失= 0
        对于x中的项目：
            如果项目没有：
               损失 += 1
        回报损失
 ]]></description>
      <guid>https://stackoverflow.com/questions/79523864/how-to-update-model-weights-from-a-custom-arbitrary-loss-function-in-pytorch</guid>
      <pubDate>Thu, 20 Mar 2025 18:53:43 GMT</pubDate>
    </item>
    <item>
      <title>使用Essentia模型进行音乐标记的问题</title>
      <link>https://stackoverflow.com/questions/79523823/issues-using-essentia-models-for-music-tagging</link>
      <description><![CDATA[ 背格： 
我正在使用一些模型来生成音乐的标签，例如音乐中的流派，情绪和乐器（音频文件）。原始型号在.pb扩展中。这些模型可在 https://essentia.upf.edu/models.html 和我使用的型号at is： ars as：

 discogs-effnet-bs64-1 
 genre_discogs400-discogs-effnet-1 
 mtg_jamendo_instrument-discogs-effnet-1 
 mtg_jamendo_moodtheme-discogs-effnet-1 

在相应的JSON文件中给出了模型的输入和输出，这些文件显示了类，输入/输出大小和名称。
默认.pb模型只需使用内置函数：
 来自Essentia.Standard Import（
    单层，
    TensorFlowPredictefteffnetDiscogs，
    TensorFlowPredict2d，
）
def essentia_feature_extraction（audio_file，sample_rate）：
    ＃加载音频文件
    audio = monoloader（fileName = audio_file，采样= 16000，res ampamplequality = 4）（）（）

    ＃嵌入音频功能
    embeddings = embedding_model（音频）

    result_dict = {}
    processed_labels = list（MAP（process_labels，genre_labels）））
    ＃流派预测
    genre_predictions = genre_model（嵌入）
    result_dict [＆quot; quot; quot; quot_predictions（genre_predictions，processed_labels）
    ＃情绪/主题预测
    mood_predictions = mood_model（嵌入）
    result_dict [＆quot; quots; quot; quot_predictions（
        mood_predictions，mood_theme_classes，阈值= 0.05
    ）

    ＃乐器预测
    instrument_predictions = instrument_model（嵌入）
    result_dict [＆quot&#39;instruments＆quort＆quort = filter_predictions（
        instrument_predictions，instrument_classes
    ）

    返回result_dict
 
 问题： 
无论我用哪种音频文件作为输入，我都会为情绪和仪器提供相同的输出预测。流派预测现在通常为零（含义“未知类型”。
 导入libreosa
导入numpy作为NP
导入tritonclient.http作为httpclient

def essentia_feature_extraction_triton（audio_file，sample_rate）：
    尝试：
        音频，sr = librosa.load（audio_file，sr = 16000，mono = true）
        音频= audio.astype（np.float32）

        mel_spectrogram = libreosa.feature.melspectrogram（
            y =音频，sr = 16000，n_fft = 2048，hop_length = 512，n_mels = 128
        ）
        mel_spectrogram = libreosa.power_to_db（mel_spectrogram，ref = 1.0）

        如果mel_spectRogram.Shape [1]＆lt; 96：
            mel_spectrogram = np.pad（
                mel_spectRogram，（（（0，0），（0，96 -mel_spectRogram.shape [1]）），模式=＆quot;
            ）
        elif mel_spectrogram.shape [1]＆gt; 96：
            mel_spectRogram = mel_spectrogram [：，：96]

        mel_spectRogram = np.expand_dims（mel_spectRogram，axis = 0）.astype（np.float32）


        使用httpclient.inferenceserverclient（url = triton_url）作为triton_client：
            ＃--- effnet Discogs（组合模型）---
            input_name =＆quot; melspectrogram; quot;
            genre_output_name =“激活”
            embedding_output_name =＆quot&#39;embeddings; quot;

            inputs = [httpclient.inferinput（input_name，mel_spectrogram.shape，shape，shape，fp32＆quort&#39;&#39;）]
            输入[0] .SET_DATA_FROM_NUMPY（MEL_SPECTROGRAM）

            输出= [
                httpclient.inferrequestedoutput（genre_output_name），
                httpclient.inferrequestedoutput（embedding_output_name）
            这是给出的

            结果= triton_client.infer（
                model_name = effnet_discogs_model_name，inputs =输入，输出=输出
            ）

            genre_predictions = results.as_numpy（genre_output_name）
            embeddings = results.as_numpy（empedding_output_name）
            embeddings = embeddings.astype（np.float32）

            ＃---情绪预测---
            input_name =＆quot&#39;embeddings;
            output_name =“激活”
            inputs = [httpclient.inferinput（input_name，embeddings.shape，shape，fp32＆quort&#39;）]
            输入[0] .set_data_from_numpy（嵌入）

            outputs = [httpclient.inferrequestedoutput（output_name）]
            mood_predictions = triton_client.infer（
                model_name = mood_model_name，inputs =输入，输出=输出
            ）.AS_NUMPY（output_name）

            ＃---仪器预测---
            input_name =＆quot&#39;embeddings;
            output_name =“激活”
            inputs = [httpclient.inferinput（input_name，embeddings.shape，shape，fp32＆quort&#39;）]
            输入[0] .set_data_from_numpy（嵌入）

            outputs = [httpclient.inferrequestedoutput（output_name）]
            instrument_predictions = triton_client.infer（
                model_name = instrument_model_name，inputs =输入，输出=输出
            ）.AS_NUMPY（output_name）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79523823/issues-using-essentia-models-for-music-tagging</guid>
      <pubDate>Thu, 20 Mar 2025 18:31:24 GMT</pubDate>
    </item>
    <item>
      <title>DL4J自动编码器用于异常检测：意外结果</title>
      <link>https://stackoverflow.com/questions/79523631/dl4j-autoencoder-for-anomaly-detection-unexpected-results</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79523631/dl4j-autoencoder-for-anomaly-detection-unexpected-results</guid>
      <pubDate>Thu, 20 Mar 2025 16:59:01 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Codebert嵌入识别类似的代码零件？</title>
      <link>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</link>
      <description><![CDATA[我正在使用Codebert比较两个代码的相似性。例如：
 ＃代码1
def calculate_area（半径）：
返回3.14 *半径 *半径
 
 ＃代码2
def Compute_circle_area（R）：
返回3.14159 * r * r
 
 Codebert创建“嵌入”就像对代码的详细描述为数字。然后，我比较这些数值描述，以查看代码的相似之处。这对于告诉我多少代码是相似的。
但是，我无法分辨Codebert认为哪些部分相似。因为“嵌入”很复杂，我无法轻易看到Codebert的重点。比较逐字代码在这里不起作用。
我的问题是：我如何找出两个代码段的哪些特定部分Codebert认为相似，而不仅仅是获得一般相似性得分？
我尝试了简单的DIFF方法，但这违反了纯粹使用Codebert的目的。
我想知道是否可以单独使用Codebert。]]></description>
      <guid>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</guid>
      <pubDate>Thu, 20 Mar 2025 14:30:35 GMT</pubDate>
    </item>
    <item>
      <title>从Edge Export TFJS模型，Express/Node API中获取对象检测结果</title>
      <link>https://stackoverflow.com/questions/79521051/get-object-detection-results-from-edge-export-tfjs-model-bin-dict-in-express</link>
      <description><![CDATA[我已经将我的vertexai模型导出到tfjs as&#39;edge;

 dict.txt 
 group1_shard1of2.bin 
 group1_shard2of2.bin 
 model.json 

现在，我将图像从客户发送到节点/快递端点，这确实很难弄清楚 - 因为我发现TFJS文档很糟糕，可以理解我需要做什么。  但这是我所拥有的：
 &#39;@tensorflow/tfjs-node;：＆quot&#39;^4.22.0＆quot;
＆quot@types/multer＆quot;：＆quot^1.4.12＆quot;
＆quot“ multer”：&#39;^1.4.5-lts.1＆quort;
 
，然后在我的端点处理程序中进行图像＆amp;型号：
 
const upload = multer（{{
  存储：MemoryStorage（），
  限制：{
    文件大小：10 * 1024 * 1024，// 10MB限制
  }，，
}）。单个（&#39;image&#39;）;

//加载字典文件
const loadDictionary =（）=＆gt; {
  const dictpath = path.join（__ dirname，&#39;model&#39;，&#39;dict_03192025.txt&#39;）;
  const content = fs.ReadFileSync（dictpath，&#39;utf-8&#39;）;
  return content.split（&#39;\ n&#39;）。filter（line =＆gt; line.trim（）！==&#39;&#39;&#39;）;
};

const getToppredictions =（
  预测：数字[]，
  标签：字符串[]，
  topk = 5
）=＆gt; {
  //获取按概率排序的索引
  const索引=预测
    .map（（（_，i）=＆gt; i）
    。

  //以其概率获得顶级K预测
  return indices.slice（0，topk）.map（index =＆gt;（{{
    标签：标签[索引]，
    概率：预测[索引]，
  }））;
};

导出const扫描= async（req：request，res：response）=＆gt; {
  上载（req as not，res as any，async err =＆gt; {
    如果（err）{
      返回res.status（400）.send（{消息：err.message}）;
    }

    const file =（req as noy）.file as express.multer.file;

    如果（！文件||！file.buffer）{
      返回res.status（400）.send（{消息：&#39;没有图像文件提供&#39;}）;
    }

    尝试 {
      //加载字典
      const labels = loadDictionary（）;

      //加载JSON格式的模型
      const模型=等待tf.loadgraphmodel（
        &#39;file：//&#39; + __dirname +&#39;/model/model_03192025.json&#39;
      ）；

      //处理图像
      const image = tf.node.decodeimage（file.Buffer，3，&#39;int32&#39;）;
      const尺寸= tf.image.ResizeBilesBileNear（图像，[512，512]）;
      const rangure image = justized.div（255.0）;
      const batchedimage = normolizedImage.expandDims（0）;
      const预测=等待model.executeasync（batchedimage）;

      //提取预测数据并获得最佳匹配
      const预测= array.isarray（预测）
        ？等待（预测[0]作为tf.tensor）.array（）
        ：等待（作为tf.tensor的预测）.array（）;

      const flatpredictions =（预测为number [] []）。flat（）;
      const toppredictions = getToppredictions（flatpredictions，labels）;

      //清理张量
      image.dispose（）;
      调整大小。dispose（）;
      归一化图。dispose（）;
      batchedimage.dispose（）;
      if（array.isarray（predivions））{
        prective.foreach（p =＆gt;（p as tf.tensor）.dispose（））;
      } 别的 {
        （作为tf.tensor的预测）.dispose（）;
      }

      返回res.status（200）。
        消息：“成功处理的图像”，
        尺寸：file.size，
        类型：file.mimetype，
        预测：预测，
      }）;
    } catch（错误）{
      Console.Error（&#39;错误处理图像：&#39;，错误）;
      返回res.status（500）.send（{消息：&#39;错误处理image&#39;}）;
    }
  }）;
};

//包装器功能处理类型铸造
导出const scanhandler = [
  上传，
  （req：request，res：reverse）=＆gt;扫描（req，res），
]作为const;
 
这是我关注的内容：

我是否正确加载模型为 GraphModel ？我尝试了其他人，这是唯一起作用的。
我正在调整大小为512x512好吗？
如何更好地处理结果？  如果我想要最高的“评分”图像，最好的方法是什么？
]]></description>
      <guid>https://stackoverflow.com/questions/79521051/get-object-detection-results-from-edge-export-tfjs-model-bin-dict-in-express</guid>
      <pubDate>Wed, 19 Mar 2025 18:11:20 GMT</pubDate>
    </item>
    <item>
      <title>Llama2型号在设备MPS上运行时获取WERID符号</title>
      <link>https://stackoverflow.com/questions/78202731/llama2-model-get-werid-symbols-when-running-on-device-mps</link>
      <description><![CDATA[ 来自Transformers Import AutoTokenizer，AutoModelforCausAllm，BitsandBytesConfig，LlamaforCausallm

model_id =＆quot“ meta-llama/llama-2-7b-chat-hf”

tokenizer = autotokenizer.from_pretaining（model_id，token = os.environ [&#39;hf_token&#39;]）
model = automodelforcausallm.from_pretrataining（model_id，device_map =&#39;auto&#39;，token = os.environ [&#39;hf_token&#39;]）

文字=;指示：Quote：想象力更多。来自：＆quot;
设备=&#39;MPS&#39;
型号（设备）
inputs = tokenizer（text，return_tensors =; pt; quot;）。到（设备）
打印（输入）
输出= model.generate（**输入，max_new_tokens = 20）
print（tokenizer.decode（输出[0]，skip_special_tokens = true））
打印（输出）

＆gt;＆gt;＆gt;指示：Quote：想象力更多。来自：ralphљъ，2ъUrlso0\\。ћo0oљoo
 
我有奇怪的符号，例如“ralphљъ，2ъUrlso0.ћo0oљoo”。在MPS上运行时，但在CPU上工作正常。我在128克M2 Ultra Mac Studio上运行。]]></description>
      <guid>https://stackoverflow.com/questions/78202731/llama2-model-get-werid-symbols-when-running-on-device-mps</guid>
      <pubDate>Thu, 21 Mar 2024 20:50:47 GMT</pubDate>
    </item>
    <item>
      <title>如何激活yolov8的MPS</title>
      <link>https://stackoverflow.com/questions/78126688/how-can-%c4%b1-activate-mps-for-yolov8</link>
      <description><![CDATA[ 从超级物质导入YOLO
型号= yolo（; yolov8n.yaml; quot）＃从头开始构建新型号
型号= yolo（＆quot; yolov8n.pt;）
型号（MPS;）
结果= model.train（data =&#39;data/datas.yaml&#39;，
conf = 0.3，
epochs = 3，设备=&#39;mps&#39;）
 
我正在尝试在Yolov8模型上训练模型，但是即使我尝试了3个时代，训练时间也需要数小时。我安装了夜间版本和普通版本，但它不起作用。
我也尝试过，但它不起作用
  torch.backends.mps.is_available（）
版本：Macos Sonoma
 ]]></description>
      <guid>https://stackoverflow.com/questions/78126688/how-can-%c4%b1-activate-mps-for-yolov8</guid>
      <pubDate>Fri, 08 Mar 2024 09:30:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使Tesseract识别连字符或减去标志？</title>
      <link>https://stackoverflow.com/questions/69977249/how-to-make-tesseract-recognize-hyphens-or-minus-signs</link>
      <description><![CDATA[我想使用Tesseract阅读毕业文凭的成绩。这些位于桌子般的结构中，您可以在这里看到： https://www.asv.bayern.de/doku/gy/oberstufe/zeugnis/abitur  
由于Tesseract实际上并非设计用于读取表，因此我将表格分为单个列，让Tesseract读取这些值，然后将列重新合并在一起。然后，我也可以将它们转移到tibble中。我在这里找到了这个想法： https://themockup.blog/posts/2021-01-18-reading-tables-from-images-with-magick/  
这样，我很好地管理了单个列类型（字符或整数）。但是有一个问题。您可以希望看到，所有行或列中都没有成绩。这些空细胞充满连字符“  - ”。但是，Tesseract并未识别这些连字符，这就是为什么单个列表元素具有不同数量值的原因。这也导致列长度不同，这就是为什么我不能将它们合并到一个tibble中。
因此，我正在寻找一种识别连字符的方法，以免被忽略。这些列都应该具有相同的长度，以便我可以将它们加入一个tibble。
附件是我当前正在使用的代码。它基本上与模型博客教程中的情况相同，但具有单独的调整人。例如，我在白名单中添加了连字符（ - ），下划线（_）和点（。）。单个农作物区域与我的原始证书上的裁剪区相对应，我当然在这里不显示哪个。希望您能理解这一点。
我对您的支持感到非常高兴，谢谢！
 ＃＃只需要下载一次：
tesseract_download（“ deu”）

现在加载字典
（Deutsch＆lt;  -  Tesseract（“ Deu＆quot”））

abiturzeugnis＆lt;  -  pdftools :: pdf_convert（&#39;./ example.pdf&#39;，dpi = 600）

text＆lt;  -  tesseract :: ocr（Abiturzeugnis，Engine = Deutsch）
猫（文字）

#####
图书馆（pdftools）

bitmap＆lt;  -  pdf_render_page（&#39;./ example.pdf&#39;，page = 2，dpi = 600）
昏暗（位图）
位图

Abiturzeugnis＆lt;  -  image_read（位图）

no_grid＆lt;  -  abiturzeugnis％＆gt;％
image_deskew（）％＆gt;％ 
#image_convert（type =&#39;bilevel&#39;）％＆gt;％ 
image_quantize（colorspace =＆quot;灰色＆quort）％＆gt;％ 
image_transparent（color =; white＆quot; fuzz = 30）％＆gt;％
image_background（“白色”）

图书馆（整洁）

img_ocr_fun＆lt;  - 功能（trim_width，trim_start，char_num = true）{
num_only＆lt;  -  tesseract :: tesseract（    
选项= list（tessedit_char_whitelist = c（; q._-- 0123456789＆quot））
）
组合＆lt ;- Tesseract :: Tesseract（
选项=列表（
  tessedit_char_whitelist = paste0（
    c（字母，字母，“” ._ 0123456789（ - ）
））

 input_char＆lt;  -  if（istrue（char_num））{
num_only
} 别的 {
组合
}
no_grid％＆gt;％
image_crop（geometry_area（trim_width，3180，trim_start，1400））％＆gt;％
OCR（发动机= input_char）％＆gt;％
str_split（模式=; \ n＆quot;）％＆gt;％
UNLIST（）％＆gt;％
enframe（）％＆gt;％
选择（-Name）％＆gt;％
filter（！is.na（value），str_length（value）＆gt; 0）
}

c（
no_grid％＆gt;％
image_crop（geometry_area（750，3180，270，1400）），），
no_grid％＆gt;％
image_crop（geometry_area（115，3180，1210，1400）），），
no_grid％＆gt;％
image_crop（geometry_area（105，3180，1460，1400）），），
no_grid％＆gt;％
image_crop（geometry_area（100，3180，1700，1400）），
no_grid％＆gt;％
image_crop（geometry_area（100，3180，1950，1400）），
no_grid％＆gt;％
image_crop（geometry_area（600，3180，2125，1400））
）％＆gt;％
image_append（）％＆gt;％
image_ggplot（）

all_ocr＆lt;  -  list（trim_width = c（750，115，105，100，100，100，600），
            trim_start = C（270，1210，1460，1700，1950，2125），
            char_num = c（false，true，true，true，true，false））％＆gt;％  
purrr :: pmap（img_ocr_fun） 

all_ocr

data_df＆lt;  -  all_ocr％＆gt;％ 
bind_cols（）％＆gt;％ 
set_names（nm =&#39;fach＆quot&#39;11 i; quot;“ 11 ii” 12 i＆quot;“” 12 ii＆quot;“ 12 ii” 

data_df
 ]]></description>
      <guid>https://stackoverflow.com/questions/69977249/how-to-make-tesseract-recognize-hyphens-or-minus-signs</guid>
      <pubDate>Mon, 15 Nov 2021 15:56:16 GMT</pubDate>
    </item>
    <item>
      <title>如何在变压器培训中实施教师的努力？</title>
      <link>https://stackoverflow.com/questions/57099613/how-is-teacher-forcing-implemented-for-the-transformer-training</link>
      <description><![CDATA[ in  tensorflow的这一部分 Tensorflow的这部分 Tensorflow的Tuterorial，他们提到了他们在教师身上进行培训。据我所知，教师努力涉及将目标输出馈送到模型中，以使其收敛更快。所以我很好奇在这里如何完成？真正的目标是 tar_real ，据我所知，它仅用于计算损失和准确性。
此代码如何实施教师？]]></description>
      <guid>https://stackoverflow.com/questions/57099613/how-is-teacher-forcing-implemented-for-the-transformer-training</guid>
      <pubDate>Thu, 18 Jul 2019 17:12:25 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机。精度和/或准确性？</title>
      <link>https://stackoverflow.com/questions/36846795/support-vector-machine-precision-and-or-accuracy</link>
      <description><![CDATA[我正在尝试弄清我使用的代码是计算精度还是准确性或两者兼而有之。由于我只有少量的统计背景（用另一种语言），所以我真的不理解 wikipedia&#39;&gt; wikipedia文章涵盖该主题。
具体地我使用以下python代码：
 来自Sklearn Import SVM，Cross_validation
clf = svm.svc（内核=内核，c = c）
scores = cross_validation.cross_val_score（clf，featurematrix，np.squeeze（labelmatrix），cv = d_inds）
 
  scikit-learn 函数可以在此处找到：

     sklearn.svc.svm.svc.svc.svc       
 ]]></description>
      <guid>https://stackoverflow.com/questions/36846795/support-vector-machine-precision-and-or-accuracy</guid>
      <pubDate>Mon, 25 Apr 2016 17:03:37 GMT</pubDate>
    </item>
    </channel>
</rss>