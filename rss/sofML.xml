<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 14 Jun 2024 15:17:12 GMT</lastBuildDate>
    <item>
      <title>karateclub MUSAE 嵌入产生奇怪的列数</title>
      <link>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</link>
      <description><![CDATA[我正在尝试属性节点嵌入和结构嵌入，但 karateclub 实现返回的矩阵具有奇怪的列数。
MUSAE 给出 128 个“特征”，而不是请求的 32 个。当我请求 32 个时，GLEE 给出了 33 个。我遗漏了什么吗？
import random
import numpy as np
import networkx as nx
from scipy.sparse import coo_matrix

from karateclub.node_embedding.attributed import MUSAE
from karateclub.node_embedding.neighbourhood import GLEE

g = nx.newman_watts_strogatz_graph(50, 10, 0.2)

X = {i：random.sample(range(150),50) for i in range(50)}

row = np.array([k for k, v in X.items() for val in v])
col = np.array([val for k, v in X.items() for val in v])
data = np.ones(50*50)
shape = (50, 150)

X = coo_matrix((data, (row, col)), shape=shape)

model = MUSAE(dimensions=32)
model.fit(g, X)
emb = model.get_embedding()
print(emb.shape)

model = GLEE(dimensions=32)
model.fit(g)
emb = model.get_embedding()
print(emb.shape)

输出：
(50, 128)
(50, 33)
]]></description>
      <guid>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</guid>
      <pubDate>Fri, 14 Jun 2024 15:02:08 GMT</pubDate>
    </item>
    <item>
      <title>RobertaForSequenceClassification 的一些权重未初始化</title>
      <link>https://stackoverflow.com/questions/78623284/some-weights-of-robertaforsequenceclassification-were-not-initialized</link>
      <description><![CDATA[我训练了一个基于 Bert 的模型并想加载它。因此我想出了一个python脚本-
import torch
from transformers import RobertaForSequenceClassification, AutoTokenizer, AutoModel
RobertaForSequenceClassification
def read_code_file(file_path):
with open(file_path, &#39;r&#39;) as file:
code = file.read()
return code

code_file_path = &#39;/home/hprakash/test/code.c&#39;

input_text = read_code_file(code_file_path)

tokenizer = AutoTokenizer.from_pretrained(&quot;/home/hprakash/tokenizer&quot;, local_files_only=True)

model = RobertaForSequenceClassification.from_pretrained(&quot;/home/hprakash/Ghidra-O2-Function&quot;, local_files_only=True)

input_ids = tokenizer.encode(input_text, return_tensors=&#39;pt&#39;)

使用 torch.no_grad():
output = model(input_ids)

print(output)

我尝试运行此脚本后遇到了此错误 -
初始化 RobertaForSequenceClassification 时未使用 /home/hprakash/Ghidra-O2-Function 处的模型检查点的一些权重：[&#39;lm_head.dense.weight&#39;, &#39;lm_head2.decoder.weight&#39;, &#39;lm_head3.decoder.bias&#39;, &#39;lm_head3.dense.weight&#39;, &#39;lm_head2.dense.weight&#39;, &#39;lm_head3.decoder.weight&#39;, &#39;lm_head2.layer_norm.bias&#39;, &#39;lm_head2.bias&#39;, &#39;lm_head2.dense.bias&#39;, &#39;lm_head.layer_norm.bias&#39;, &#39;lm_head.bi as&#39;, &#39;lm_head3.layer_norm.weight&#39;, &#39;lm_head3.dense.bias&#39;, &#39;lm_head3.bias&#39;, &#39;lm_head.dense.bias&#39;, &#39;lm_head2.decoder.bias&#39;, &#39;lm_head.layer_norm.weight&#39;, &#39;lm_head3.layer_norm.bias&#39;, &#39;lm_head2.layer_norm.weight&#39;]

如果您从针对另一项任务或使用另一种架构训练的模型的检查点初始化 RobertaForSequenceClassification（例如从 BertForPreTraining 模型初始化 BertForSequenceClassification 模型），则会出现这种情况。

如果您从您期望完全相同的模型的检查点初始化 RobertaForSequenceClassification（从 BertForSequenceClassification 模型初始化 BertForSequenceClassification 模型），则不会出现这种情况。

RobertaForSequenceClassification 的一些权重未从 /home/hprakash/Ghidra-O2-Function 处的模型检查点初始化，而是新初始化的：[&#39;classifier.dense.bias&#39;, &#39;classifier.out_proj.weight&#39;, &#39;classifier.dense.weight &#39;, &#39;classifier.out_proj.bias&#39;] 

您可能应该在下游任务上训练此模型，以便能够将其用于预测和推理。

SequenceClassifierOutput(loss=None, logits=tensor(\[\[0.2434, 0.1226\]\]), hidden_​​states=None,tentions=None)

我已经对模型进行了微调。错误日志仍然显示我需要进一步微调。
我尝试调试我的脚本，但它似乎不起作用，而且我不断收到相同的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78623284/some-weights-of-robertaforsequenceclassification-were-not-initialized</guid>
      <pubDate>Fri, 14 Jun 2024 13:35:39 GMT</pubDate>
    </item>
    <item>
      <title>文本部分识别</title>
      <link>https://stackoverflow.com/questions/78623123/text-sections-recognition</link>
      <description><![CDATA[我有一段纯文本，如下：
患者姓名：Anakin Skywalker
出生日期：31/12/9999
DOS：
主诉膝盖：
患者报告左膝疼痛，疼痛被描述为酸痛、剧烈和僵硬。
症状频率被描述为频繁（清醒时间的 50-75%）。VAS 评分为 7/10。
现病史膝盖：
患者否认有任何放射性症状。患者报告左膝和右膝主动运动时出现摩擦音。患者报告双膝晨僵，持续时间不到
20-30 分钟。
触诊：
左膝触诊时疼痛？
否
右膝触诊时疼痛？
否
膝关节活动范围：
左膝
活动范围正常
活动时疼痛？
否
右膝
活动范围正常
活动时疼痛？否
在膝盖测试期间，已注意到不稳定性。功能性膝盖测试如下所述。
体检
计划：
建议患者双膝进行以下治疗：
注射：
患者将接受一系列 3 次粘弹性补充程序，将 Euflexxa (J7323) 置于膝盖中。这将以每周一次的频率进行，持续 3 周。
患者每膝将接受 20 毫克/2 毫升的剂量。
诊断
单侧原发性骨关节炎，左膝 - M17.12
单侧原发性骨关节炎，右膝 - M17.11
双侧原发性膝关节骨关节炎 - M17.0
旧银河帝国医疗办公室，LLC
666 号公路 66 号死星
由皇帝帕尔帕廷电子签名。于 9999 年 7 月 31 日星期二下午 05:22
,
Medical Offices Of Old Galactic Empire, LLC
666 Highway 66 Death Star

在文本中，我必须识别具有以下名称的部分：

膝盖不适
膝关节现病史
触诊
体检
计划
诊断

我需要找到该部分的边界。
实际上，我可以使用预定义的部分名称列表找到部分的开头。
主要问题是在文档中的某个部分无法通过部分名称识别的情况下识别部分的结尾。
我对如何解决此类问题的任何想法和假设感兴趣已解决。]]></description>
      <guid>https://stackoverflow.com/questions/78623123/text-sections-recognition</guid>
      <pubDate>Fri, 14 Jun 2024 13:03:07 GMT</pubDate>
    </item>
    <item>
      <title>是否有针对不平衡数据集的 ML 算法？</title>
      <link>https://stackoverflow.com/questions/78623027/is-there-an-ml-algorithm-for-imbalanced-dataset</link>
      <description><![CDATA[我的用例很基础。我有 3 个标签，分别是正面、负面和中性。此 ML 模型的数据是流式/批处理的。假设每个批次包含 100 个样本（batch_size=100）。我可以清楚地看到这是一个在线/增量学习问题。我的批次也有可能获得不平衡/倾斜的数据样本。例如，B1-B4 可能包含所有正面数据，B5-B10 可能包含所有负面数据，B11-B15 可能包含所有中性数据样本。
在了解用例并进行一些基础研究后，我想到在 partial_fit () 上使用 SGDClassifier 可以很好地解决我的问题。
我面临的实际困难是，在完成 15 个批次的训练（每个标签 5 个批次）后，我的模型将所有推理数据预测为最新标签。在找到根本原因后，我发现模型在最近几批训练中对最近的批次（中性样本）进行了训练，因此一切都被预测为中性。
鉴于这个困难，我还有另一个困难。我无法执行数据平衡技术，如 SMOTE、欠采样、过采样等，因为我没有接触过完整的数据集。在任何给定的时间实例中，我只能访问当前批次数据（100 个样本）和在先前批次上训练的模型（partial_fit () 模型）。
start_timer = time.time()
column_classes_lists = [np.array(sgd_model[PIPELINE_MODEL_CONSTANTS.META][PIPELINE_MODEL_CONSTANTS.CLASSES].get(key)) for key in sgd_model[PIPELINE_MODEL_CONSTANTS.META][PIPELINE_MODEL_CONSTANTS.CLASSES].keys()]

if data is not None:
kf = KFold(n_splits = PREDICTOR_CONSTANTS.NUM_FOLDS)
y_predictions, y_actual = [], []
# target_df = pd.DataFrame(target)

for train_index, val_index in kf.split(data):
X_train_fold, X_val_fold = [data[idx] for idx in train_index], [data[idx] for idx in val_index]
y_train_fold = [[target[col][idx][0] for col in target.keys()] for idx in train_index]
y_val_fold = [[target[col][idx][0] for col in target.keys()] for idx in val_index]

sgd_model[PIPELINE_MODEL_CONSTANTS.MODEL].partial_fit(np.array(X_train_fold), y_train_fold, classes = column_classes_lists)

y_predictions.extend(sgd_model[PIPELINE_MODEL_CONSTANTS.MODEL].predict(X_val_fold))

y_actual.extend(y_val_fold)

Utils.calculate_prediction_metrics(sgd_model, target, y_actual, y_predictions, column_classes_lists, meta)
else:
Utils.calculate_prediction_metrics(sgd_model, target, None, None, column_classes_lists, meta)

logger.warning(f&quot;SGDModel 在 {time.time() - start_timer} 秒内成功训练了 id: {id}，得分指标为：{sgd_model[PIPELINE_MODEL_CONSTANTS.META][PIPELINE_MODEL_CONSTANTS.SCORES]}&quot;)
return sgd_model


除此之外，在我的训练过程中的任何时间点都可能出现新的标签。对于 partial_fit()，我们需要在第一次训练调用中传递所有可能的标签。因此，我猜 sklearn 的 partial_fit() 可能不太适合我的情况。
你能帮我找到一个用 Python 实现的针对这种情况的最佳解决方案吗？
我尝试了上述算法]]></description>
      <guid>https://stackoverflow.com/questions/78623027/is-there-an-ml-algorithm-for-imbalanced-dataset</guid>
      <pubDate>Fri, 14 Jun 2024 12:40:42 GMT</pubDate>
    </item>
    <item>
      <title>直接在 gpu 上加载并生成 Qwen2</title>
      <link>https://stackoverflow.com/questions/78622820/direct-loading-and-generation-qwen2-on-gpu</link>
      <description><![CDATA[我想在挖矿机上部署 LLM 模型 Qwen2-7b-instruct，但由于内存存储量低（4GB RAM）和处理能力有限（2 核奔腾）等限制，我无法做到这一点。
另一方面，我的电脑不支持 CUDA 和 ROCM 技术。
矿机规格：
4x amd rx580 8GB
到目前为止，我还没有找到这个问题的解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78622820/direct-loading-and-generation-qwen2-on-gpu</guid>
      <pubDate>Fri, 14 Jun 2024 11:58:01 GMT</pubDate>
    </item>
    <item>
      <title>在机器学习中，什么时候对数据进行欠采样/过采样</title>
      <link>https://stackoverflow.com/questions/78622628/at-what-point-do-you-undersample-oversample-data-in-machine-learning</link>
      <description><![CDATA[我有一个基本问题，关于在机器学习过程中何时应该对数据集进行欠采样或过采样。目前，我正在处理一个包含 NaN 值的不平衡数据集（约 5% 的阳性情况）。接下来的步骤应该如何衔接？这有一般规则吗？我应该填写缺失值，重新采样数据并继续删除异常值吗？

如能得到任何帮助，我将不胜感激。
我尝试寻找答案，但到目前为止还没有找到任何东西。我不知道正确的顺序是什么。]]></description>
      <guid>https://stackoverflow.com/questions/78622628/at-what-point-do-you-undersample-oversample-data-in-machine-learning</guid>
      <pubDate>Fri, 14 Jun 2024 11:13:18 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 中的 Essentia 模型无法预测</title>
      <link>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</link>
      <description><![CDATA[我正在尝试使用 Essentia discogs_track_embeddings-effnet-bs64 模型和 ML.NET 进行预测。我尝试过使用 tensorflow 和 onnx，但当我尝试预测任何东西时，我都遇到了问题
抛出异常：Microsoft.ML.Data.dll 中的“System.InvalidOperationException”
Microsoft.ML.Data.dll 中发生了未处理的“System.InvalidOperationException”类型的异常
拆分器/合并器工作程序在使用源数据时遇到异常

目前，我正在使用 onnx，因此其余部分将是该尝试的堆栈跟踪和代码。
完整调用堆栈：
 在 Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)
在 Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()
在 Microsoft.ML.Data.RootCursorBase.MoveNext()
在Microsoft.ML.Data.ColumnCursorExtensions.&lt;GetColumnArrayDirect&gt;d__4`1.MoveNext()
在 System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)
在 System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)
在 Program.&lt;Main&gt;$(String[] args) 中的 Program.cs:line 122

在行上：var embeddingColumn = perceivedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
onnx 加载和预测代码：
Console.WriteLine($&quot;[+] Loading Model&quot;);
var mlContext = new MLContext();

// 将 melspectrogram 数据加载到管道中
var modelPath = &quot;discogs_track_embeddings-effnet-bs64-1.onnx&quot;;
var pipeline = mlContext.Transforms.ApplyOnnxModel(
modelFile: modelPath,
fallbackToCpu: true
);
IDataView mockData = mlContext.Data.LoadFromEnumerable(new List&lt;ModelInput&gt;() { new ModelInput() });
var model = pipeline.Fit(mockData);

var schema = model.Transform(mockData).Schema;
Console.WriteLine(&quot;[*] Model Schema:&quot;);
foreach (var column in schema)
{
Console.WriteLine($&quot;Column Name: {column.Name}, Column Type: {column.Type}&quot;);
}

//PredictionEngine&lt;MelspectrogramData, OutputData&gt; predictionEngine = mlContext.Model.CreatePredictionEngine&lt;MelspectrogramData, OutputData&gt;(estimator);

//var predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput, ModelOutput&gt;(mo​​del);

List&lt;ModelOutput&gt; allPredictions = new List&lt;ModelOutput&gt;();

foreach (var fragment in melSpectrogram)
{
var seg = MelSpectrogramGenerator.ConvertToFloat(segment);
for (int i = 0; i &lt; seg.GetLength(0); i++)
{
for (int j = 0; j &lt; seg.GetLength(1); j++)
{
for (int k = 0; k &lt; seg.GetLength(2); k++)
{
// 用您的特定检查替换条件
if (double.IsNaN(seg[i, j, k]) || seg[i, j, k] == null)
{
Console.WriteLine($&quot;NaN found at ({i}, {j}, {k})&quot;);
}
}
}
var data = new ModelInput
{
Melspectrogram = seg
};
IDataView dataView = mlContext.Data.LoadFromEnumerable(new [] { data });
var perceivedData = model.Transform(dataView);

// 检索嵌入
var embeddingColumn = formedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
foreach (var value in embeddingColumn.First())
{
Console.Write($&quot;{value} &quot;);
}
//allPredictions.Add(scoredData.);
Console.WriteLine(&quot;Wheee&quot;);
}

public class ModelInput
{
[VectorType(64, 128, 96)]
[ColumnName(&quot;melspectrogram&quot;)]
public float[,,] Melspectrogram { get; set; }
public ModelInput()
{
Melspectrogram = new float[64, 128, 96];
}
}

// 定义输出模式
public class ModelOutput
{
[VectorType(64, 512)]
[ColumnName(&quot;embeddings&quot;)]
public float[,] Embeddings { get; set; }
public ModelOutput()
{
Embeddings = new float[64, 512];
}
}

目前在 Microsoft.ML 3.0.1、Microsoft.ML.OnnxRuntime.Managed 1.18.0 上
我检查过，我的数据中没有 NaN，而且我的变量都不是 Null。我非常迷茫，不知道如何修复这个问题，甚至不知道如何继续进行故障排除。]]></description>
      <guid>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</guid>
      <pubDate>Fri, 14 Jun 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>孪生网络是否可以通过修改架构用于感知散列？[关闭]</title>
      <link>https://stackoverflow.com/questions/78621922/can-siamese-network-be-used-for-perceptual-hashing-by-modifying-the-architecture</link>
      <description><![CDATA[我读到 Siamese 网络用于图像比较。这让我想知道，通过修改经过适当定制训练的 Siamese 网络，我们能否对大规模 CBIR 系统执行感知哈希处理？]]></description>
      <guid>https://stackoverflow.com/questions/78621922/can-siamese-network-be-used-for-perceptual-hashing-by-modifying-the-architecture</guid>
      <pubDate>Fri, 14 Jun 2024 08:44:34 GMT</pubDate>
    </item>
    <item>
      <title>如何正确修改跳数大小以解决执行 python 模块时出现的断言错误？</title>
      <link>https://stackoverflow.com/questions/78621817/how-do-i-properly-modify-the-hop-size-to-resolve-the-assertion-error-when-execut</link>
      <description><![CDATA[当我运行 aisfx.inference.main(&quot;/home/Debian/Desktop/Audio Pre&quot;, &quot;/home/Debian/Desktop/Audio Post&quot;) 时，模块加载了 27%，当跳跃大小有问题时，会触发 AssertionError。
供参考：

Github 链接：https://github.com/alisonbma/aiSFX
教程链接：https://aisfx.readthedocs.io/en/latest/notebooks/tutorial.html

我期望模块能够 100% 运行且无错误，并对我的音频文件进行排序。
这是我正在查看的内容：
aisfx.inference.main(&quot;/home/Debian/Desktop/Audio Pre&quot;, &quot;/home/Debian/Desktop/Audio Post&quot;)
CPU 或 CUDA：cuda
27%|██████████████████████████████████▍ | 97/365 [00:04&lt;00:13, 19.87it/s]
回溯（最近一次调用）：
文件 &lt;stdin&gt;&gt;，第 1 行，位于 &lt;module&gt;
文件 &quot;/home/Debian/anaconda3/envs/sfx/lib/python3.11/site-packages/aisfx/inference.py&quot;，第 159 行，在 main 中
embedding = model_get_embedding(spec,
^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/home/Debian/anaconda3/envs/sfx/lib/python3.11/site-packages/aisfx/inference.py&quot;，第 97 行，在 model_get_embedding 中
hop_size=compute_hopSize(EMB_BLOCK_LENGTH, emb_hop_size, spec),
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件&quot;/home/Debian/anaconda3/envs/sfx/lib/python3.11/site-packages/aisfx/preprocessing.py&quot;，第 20 行，在 compute_hopSize
assert(hop_size &lt; data.shape[0])
^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError

我的假设是跳跃大小导致了错误，在教程中，他们提到修改 inference.py 文件中的跳跃大小。我尝试将其更改为；0.01、0.001、1.0、5.0、10.0 和 20.0。所有结果都相同 AssertionError。作为参考，有问题的音频文件范围从 3 秒到 39 秒。]]></description>
      <guid>https://stackoverflow.com/questions/78621817/how-do-i-properly-modify-the-hop-size-to-resolve-the-assertion-error-when-execut</guid>
      <pubDate>Fri, 14 Jun 2024 08:19:36 GMT</pubDate>
    </item>
    <item>
      <title>在 tfjs tensorflow.js 中设置残差神经网络块</title>
      <link>https://stackoverflow.com/questions/78621757/setup-a-residual-neural-network-block-in-tfjs-tensorflow-js</link>
      <description><![CDATA[我正在尝试在 tensorflow.js 中实现 ResNet（残差神经网络）的行为。我希望知道他们在做什么的人能给我指明正确的方向。以下代码是否会有效地将第 3、4、5 层变成残差块？更具体地说，我包含的连接层是否像文献中描述的身份跳过连接一样起作用？TFJS 是否自动知道如何通过连接层传递反向传播信号？
 const density_layer_1 = TENSORFLOW.layers.dense({ unit: 1600,activation: &quot;relu&quot;, useBias: true }).apply(input);
const density_layer_2 = TENSORFLOW.layers.dense({ unit: 800,activation: &quot;relu&quot;, useBias: true }).apply(dense_layer_1);
const density_layer_3 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_2);
const density_layer_4 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_3);
const density_layer_5 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_4);
const density_layer_6 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_5);
const concat_layer1 = TENSORFLOW.layers.concatenate().apply([dense_layer_2, density_layer_6]);
const density_layer_7 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(concat_layer1);
const density_layer_8 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_7);
const output = TENSORFLOW.layers.dense({ 单位：1，激活：“线性”，useBias：true }).apply(dense_layer_8);
const residual_model = TENSORFLOW.model({ 输入：输入，输出：输出 });```
]]></description>
      <guid>https://stackoverflow.com/questions/78621757/setup-a-residual-neural-network-block-in-tfjs-tensorflow-js</guid>
      <pubDate>Fri, 14 Jun 2024 08:03:45 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯优化中的探索与利用权衡</title>
      <link>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</link>
      <description><![CDATA[最近我一直在研究贝叶斯优化，但有些东西我不太明白。我知道 BO 使用获取函数来平衡探索和利用。我们可以添加一个参数（epsilon）来调整我们想要更多的探索还是利用。但参数是如何做到的？与 PI 和 EI 获取函数一样，为什么较大的 epsilon 可以使算法更具探索性，反之亦然？]]></description>
      <guid>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</guid>
      <pubDate>Fri, 14 Jun 2024 04:07:57 GMT</pubDate>
    </item>
    <item>
      <title>该数据集需要进行哪些预处理？[关闭]</title>
      <link>https://stackoverflow.com/questions/78620975/which-are-the-preprocessing-required-on-this-dataset</link>
      <description><![CDATA[数据集链接：- https://www.kaggle.com/datasets/nijpadariya/cardiovascular-disease/data
笔记本链接：- https://colab.research.google.com/drive/1h8wa2yUGQJMyZcoifgD-5PsG6XvyvlB2?usp=sharing
上面的笔记本代表了我迄今为止在数据集上所做的工作
因为我必须使用这个数据集，但我不知道我可以显示什么，也不知道这些数据需要哪些预处理步骤，以及如何使用属性来显示一些结果。
有人能帮我找到吗？
有什么帮助可以找到数据集上的结果和预处理步骤所需的]]></description>
      <guid>https://stackoverflow.com/questions/78620975/which-are-the-preprocessing-required-on-this-dataset</guid>
      <pubDate>Fri, 14 Jun 2024 04:01:34 GMT</pubDate>
    </item>
    <item>
      <title>pytorch PascalVOC 数据集中的数据加载器错误：RuntimeError：批次列表中的每个元素应大小相同</title>
      <link>https://stackoverflow.com/questions/78620402/dataloader-error-in-pytorch-pascalvoc-dataset-runtimeerror-each-element-in-lis</link>
      <description><![CDATA[尝试实现时，其中一个步骤是将每幅图像的大小调整为 (448, 448)。但即使应用了转换，Dataloader 也会抛出有关数据集大小差异的异常。
确切的错误消息：“RuntimeError：批次列表中的每个元素应大小相同”
from torchvision import datasets
from torchvision.transforms import v2, ToTensor

from torch.utils.data import DataLoader

validation_data = datasets.voc.VOCDetection(
root=&#39;.DATA/&#39;,
download=False,
image_set=&quot;val&quot;,
transform=v2.Compose([ v2.Resize(size=(448, 448)), ToTensor() ])
)

batch_size = 64

validation_dataloader = DataLoader(validation_data, batch_size=batch_size)

for X, y in validation_dataloader:
print(f&quot;Shape X [N, C, H, W] 的：{X.shape}&quot;)
break
]]></description>
      <guid>https://stackoverflow.com/questions/78620402/dataloader-error-in-pytorch-pascalvoc-dataset-runtimeerror-each-element-in-lis</guid>
      <pubDate>Thu, 13 Jun 2024 22:43:49 GMT</pubDate>
    </item>
    <item>
      <title>实现神经网络的岭回归方程</title>
      <link>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network</link>
      <description><![CDATA[我试图在 MATLAB 中复制以下方程，以使用岭回归训练找到神经网络的最佳输出权重矩阵。
使用岭回归训练后的神经网络输出权重矩阵：

此方程来自 Mantas Lukosevicius 提供的回声状态网络指南，可在以下位置找到：https://www.researchgate.net/publication/319770153_A_practical_guide_to_applying_echo_state_networks（见第 11 页）
我的尝试如下。我认为外括号（红色）使其成为非传统的双重求和，这意味着 Voss 提出的方法（见 https://www.mathworks.com/matlabcentral/answers/1694960-nested-loops-for-double-summation）无法遵循。请注意，y_i 是一个 T x 1 向量，而 y_i_target 也是一个 T x 1 向量。Wout_i 是一个 N x 1 向量，其中 N 是神经网络中的节点数。我为每个 i^th 目标训练信号生成三个 Ny x 1 向量 Wout_i,y_i,y_i_target，其中 Ny 是训练信号的数量。Wout 的最终输出是一个 N x 1 向量，其中向量中的每个元素都是网络中每个节点的最佳权重。
N = 100; % 神经网络节点数
Ny = 200; % 训练信号数
T = 50; % 每个训练信号的时间长度 
X = rand(N,T); % 神经网络状态矩阵
reg = 10^-4; % 岭回归系数
outer_sum = zeros(Ny,1);
for i = 1:Ny
y_i_target = rand(T,1); % 训练信号
Wout_i = ((X*X&#39; + reg*eye(N)) \ (X*y_i_target)); 
Wouts{i} = Wout_i; % 针对每个第 i 个目标训练信号收集的每个 Wout_i 的单元矩阵
y_i = Wout_i&#39;*X; % 预测信号 
inner_sum = sum(((y_i&#39;-y_i_target).^2)+reg*norm(Wout_i)^2);
outer_sum(i) = inner_sum;
end
outer_sum = outer_sum.*(1/Ny);
[minval, minidx] = min(outer_sum);
Wout = cell2mat(Wouts(minidx));

我对 Wout 的最终答案是 N 乘以 1，正如它应该的那样，但我对我的答案不确定。我特别不确定我是否正确地完成了关于 Wout 操作的双重求和和 arg min。有什么方法可以验证我的答案吗？
解决方案：
我尝试了另一种方法/尝试，如下所示：
N = 100; % 神经网络中的节点数
Ny = 200; % 训练信号数
T = 50; % 每个训练信号的时间长度
X = rand(N,T); % 神经网络状态矩阵
reg = 10^-4; % 岭回归系数
MSE = zeros(Ny,1);
for i = 1:Ny
y_i_target = rand(T,1); % 训练信号
Wout_i = ((X*X&#39; + reg*eye(N)) \ (X*y_i_target)); % Luko 等人的 Eq. 9。
Wouts{i} = Wout_i; % 为每个第 i 个目标训练信号收集每个 Wout_i 的单元矩阵
y_i = Wout_i&#39;*X; % 预测信号
MSE(i) = (1/T)*sum((y_i&#39;-y_i_target).^2); % 均方误差
end
[minval, minidx] = min(MSE);
Wout = cell2mat(Wouts(minidx));

我相信这次尝试比第一次更好，但我不确定它是否仍然正确。
正如 BillBokeey 所强调的那样，所需的方程只是 Luko 等人提出的方程 9 的迭代版本。要进行训练，必须将方程 9 应用于训练数据集中的每个目标信号，并选择最小化均方误差 (MSE) 的结果 W_out。]]></description>
      <guid>https://stackoverflow.com/questions/78597100/implement-ridge-regression-equation-for-a-neural-network</guid>
      <pubDate>Sat, 08 Jun 2024 22:31:47 GMT</pubDate>
    </item>
    <item>
      <title>我的模型具有较高的准确率和 val_accuracy，但在测试数据上给出了错误的结果</title>
      <link>https://stackoverflow.com/questions/56696906/my-model-has-high-accuracy-and-val-accuracy-but-giving-wrong-result-on-test-data</link>
      <description><![CDATA[我使用 opencv 创建了一些图像，并在其上运行深度神经网络分类器。
它给出了大约 97% 的准确率和 95% 的 val_accuracy，但当我测试它时，它给出了错误的预测。
这是我创建图像的代码。
import cv2
import numpy as np
import random
import os
size = 64

def circle(i,d):
img = np.zeros(shape=(size,size,3))
point = (random.randint(1,size),random.randint(1,size))
img = cv2.circle(img,point,random.randint(1,size),(255,255,0),thickness=2,lineType=8)

if not os.path.exists(d+&quot;/circle&quot;):
os.makedirs(d+&quot;/circle&quot;)
cv2.imwrite(d+&quot;/circle/&quot;+str(i)+&quot;circle.png&quot;,img)
#print(&quot;创建了圆圈&quot;+str(i))

def rectangle(i,d):
img = np.zeros(shape=(size,size,3))
point = (random.randint(1,size),random.randint(1,size))
w = random.randint(1,size);
h = random.randint(1,size);
point2 = (point[0] + w,point[1]+h)
img = cv2.rectangle(img,point,point2,(255, 255, 0), 2)
if not os.path.exists(d+&quot;/react&quot;):
os.makedirs(d+&quot;/react&quot;)
cv2.imwrite(d+&quot;/react/&quot;+str(i)+&quot;react.png&quot;,img)
#print(&quot;created reactangle&quot;+str(i))

def traingle(i,d):
img = np.zeros(shape=(size,size,3))
point1 = (random.randint(1,size),random.randint(1,size))
point2 = (random.randint(1,size),random.randint(1,size))
point3 = (random.randint(1,size),random.randint(1,size))

img = cv2.line(img,point1,point2,(255, 255, 0), 2)
img = cv2.line(img,point2,point3,(255, 255, 0), 2)
img = cv2.line(img,point3,point1,(255, 255, 0), 2)
if not os.path.exists(d+&quot;/tra&quot;):
os.makedirs(d+&quot;/tra&quot;)
cv2.imwrite(d+&quot;/tra/&quot;+str(i)+&quot;tra.png&quot;,img)
#print(&quot;created trangle&quot;+str(i))

if not os.path.exists(&quot;data_train&quot;):
os.makedirs(&#39;data_train&#39;)
for i in range(1,2000):
circle(i,&quot;data_train&quot;)
rectangle(i,&quot;data_train&quot;)
traingle(i,&quot;data_train&quot;)
print(&quot;已创建测试数据&quot;) 
if not os.path.exists(&quot;data_test&quot;):
os.makedirs(&#39;data_test&#39;)
for i in range(1,500):
circle(i,&quot;data_test&quot;)
rectangle(i,&quot;data_test&quot;)
traingle(i,&quot;data_test&quot;)

这是我的分类代码。
# 导入库 
from keras.preprocessing.image import ImageDataGenerator 
from keras.models import Sequential 
from keras.layers import MaxPooling2D,Dropout, Convolution2D
from keras.layers import Flatten, Dense 
from keras import backend as K 

img_width, img_height = 64, 64

train_data_dir = &#39;data_train&#39;
validation_data_dir = &#39;data_test&#39;
nb_train_samples = 5997
nb_validation_samples = 1497
epochs = 3
batch_size = 15

如果 K.image_data_format() == &#39;channels_first&#39;: 
input_shape = (3, img_width, img_height) 
否则: 
input_shape = (img_width, img_height, 3) 
model = Sequential() 

model.add(Convolution2D(32, 3, 3, input_shape = input_shape,activation=&quot;relu&quot;)) 
model.add(MaxPooling2D(pool_size =(2, 2))) 

model.add(Convolution2D(32, 3, 3,activation=&quot;relu&quot;)) 
model.add(MaxPooling2D(pool_size =(2, 2))) 

model.add(Flatten())
model.add(Dropout(0.2)) 
model.add(Dense(output_dim=180,activation=&quot;relu&quot;)) 
model.add(Dropout(0.2)) 
model.add(Dense(3,activation=&quot;softmax&quot;)) 

model.compile(loss =&#39;categorical_crossentropy&#39;, 
optimizer =&#39;adam&#39;, 
metrics =[&#39;categorical_accuracy&#39;]) 

train_datagen = ImageDataGenerator( 
rescale = 1. / 255, 
sher_range = 0.2, 
zoom_range = 0.2, 
Horizo​​ntal_flip = False) 

test_datagen = ImageDataGenerator(rescale = 1. / 255) 

train_generator = train_datagen.flow_from_directory(train_data_dir, 
target_size =(img_width, img_height), 
batch_size = batch_size, class_mode =&#39;categorical&#39;) 

validation_generator = test_datagen.flow_from_directory( 
validation_data_dir, 
target_size =(img_width, img_height), 
batch_size = batch_size, class_mode =&#39;categorical&#39;) 

model.fit_generator(train_generator, 
steps_per_epoch = nb_train_samples, 
epochs = epochs, validation_data = validation_generator, 
validation_steps = nb_validation_samples) 

我尝试过 
1. 更改隐藏层的数量
2. 在最终层之前和第一层之后添加 dropout 层。
2. 添加 conv 层。
请告诉我我做错了什么。
提前谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/56696906/my-model-has-high-accuracy-and-val-accuracy-but-giving-wrong-result-on-test-data</guid>
      <pubDate>Fri, 21 Jun 2019 04:36:34 GMT</pubDate>
    </item>
    </channel>
</rss>