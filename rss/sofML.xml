<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sun, 09 Mar 2025 18:18:59 GMT</lastBuildDate>
    <item>
      <title>错误分类的样本是单独的类</title>
      <link>https://stackoverflow.com/questions/79496368/misclassified-samples-as-a-separate-class</link>
      <description><![CDATA[我一直在尝试将一组数据分类用于二进制分类。我看到数据的一个子集被错误分类，我删除了该子集，分类器的准确性从88％提高到96％。
我正在考虑为这些样本创建一个单独的类，然后与多类分类进行分类。这是合适的吗？
还有其他处理这些样品的方法吗？这些样本现在由二进制分类器随机分配给两个类。至少几次，我将决策树重现。]]></description>
      <guid>https://stackoverflow.com/questions/79496368/misclassified-samples-as-a-separate-class</guid>
      <pubDate>Sun, 09 Mar 2025 18:06:59 GMT</pubDate>
    </item>
    <item>
      <title>我在形状对齐中遇到了错误，该如何解决？</title>
      <link>https://stackoverflow.com/questions/79496192/i-am-having-a-error-with-shape-alignment-how-can-i-solve-this</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79496192/i-am-having-a-error-with-shape-alignment-how-can-i-solve-this</guid>
      <pubDate>Sun, 09 Mar 2025 16:02:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将libtorch纳入虚幻的Eengine 5？</title>
      <link>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-to-unreal-eengine-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-to-unreal-eengine-5</guid>
      <pubDate>Sun, 09 Mar 2025 15:03:36 GMT</pubDate>
    </item>
    <item>
      <title>当用简化运行时，模态可以正常执行。但是，当输入图像时，它无法正常工作</title>
      <link>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</guid>
      <pubDate>Sun, 09 Mar 2025 07:49:34 GMT</pubDate>
    </item>
    <item>
      <title>TPU上的RESNET50计算NAN的准确性和损失，在Google Colab中的CPU上正常工作</title>
      <link>https://stackoverflow.com/questions/79495542/resnet50-on-tpu-calculates-nan-for-accuracy-and-loss-works-fine-on-cpu-in-googl</link>
      <description><![CDATA[我使用Google Colab在V2-8 TPU加速器上培训了RESNET50，我已经用5000张形状（224、224、3）喂了它。我已经对它们进行了规范，没有NAN，没有INF，没有阶级失衡，一切都还好：
  input_shape =（224，224，3）

使用Strategy.scope（）：
    base_model = resnet50（weights =&#39;imagenet&#39;，include_top = false，input_shape = input_shape）
    base_model.trainable = false
    型号= tf.keras.models.sequeential（[[
        base_model，
        tf.keras.layers.globalaveragepooling2d（），
        tf.keras.layers.dense（1024，activation =&#39;relu&#39;），
        tf.keras.layers.dense（6，activation =&#39;sigmoid&#39;） 
    ）））
    model.compile（优化器=&#39;adam&#39;， 
                  损失=&#39;binary_crossentropy&#39;，
                  指标= [&#39;准确性&#39;]）
    
型号
    x_train， 
    y_train， 
    时代= 10， 
    验证_data =（x_val，y_val），
    batch_size = 32
  ）
 
当我对TPU进行训练时，训练期间的准确性和损失成为NAN。当我切换到CPU时，一切正常。
为什么会发生这种情况以及如何解决？
我尝试在Google Colab中对TPU和CPU进行培训。我希望该模型在没有任何问题的情况下进行培训，包括NAN值损失或准确性，尤其是因为培训在CPU上效果很好。但是，当使用TPU时，我遇到了NAN值的准确性和损失。我还验证了数据很干净，没有NAN，无限或失衡问题，并确保模型编译和培训设置是正确的。]]></description>
      <guid>https://stackoverflow.com/questions/79495542/resnet50-on-tpu-calculates-nan-for-accuracy-and-loss-works-fine-on-cpu-in-googl</guid>
      <pubDate>Sun, 09 Mar 2025 07:07:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用训练有素的AI模型进行预测？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79495434/how-do-i-use-my-trained-ai-model-to-make-predictions</link>
      <description><![CDATA[我制作了用于多类分类的AI模型，它运行良好，但我不知道如何使用训练有素的模型做出单个预测或更多的预测。
我知道它可能在下面的代码中，但我无法弄清楚。
  n_epochs = 200
batch_size = 5
batches_per_epoch = len（x_train）// batch_size

best_acc = 0
best_weights =无
train_loss_hist = []
train_acc_hist = []
test_loss_hist = []
test_acc_hist = []

＃训练循环
对于范围（n_epochs）的时期：

    epoch_loss = []
    epoch_acc = []
    model.train（）
    使用tqdm.trange（batches_per_epoch，unit =; batch; mininterval = 0）作为bar：
        bar.set_description（f＆quot; epoch {epoch}＆quot;）
        因为我在酒吧：
        ＃批量
           start = i * batch_size
           x_batch = x_train [start：start+batch_size]
           y_batch = y_train [start：start+batch_size]
           ＃正向通行证
           y_pred =模型（x_batch）
           损失= loss_fn（y_pred，y_batch）
           ＃向后传球
           优化器.zero_grad（）
           loss.backward（）
           ＃更新权重
           优化器.step（）
           ＃计算和存储指标
           acc =（torch.argmax（y_pred，1）== torch.argmax（y_batch，1））。float（）。平均（）。
           epoch_loss.append（float（loss））
           epoch_acc.append（float（acc））
           bar.set_postfix（
            损失= float（损失），
            ACC = float（ACC）
           ）
＃在评估模式下设置模型并通过测试集运行
model.eval（）
y_pred =模型（x_test）
ce = loss_fn（y_pred，y_test）
acc =（torch.argmax（y_pred，1）== torch.argmax（y_test，1））。float（）。平均（）。
ce = float（CE）
ACC = float（ACC）
＃节省最佳模型
train_loss_hist.append（np.mean（epoch_loss）））
train_acc_hist.append（np.mean（epoch_acc）））
test_loss_hist.append（CE）
test_acc_hist.append（ACC）
如果acc＆gt; best_acc：
    best_acc = acc
    best_weights = copy.deepcopy（model.state_dict（））
print（f＆quot; epoch {epoch}验证：cross-entropy = {ce：.2f}，准确度= {acc*100：.1f}％＆quort;）
 
我使用pytorch构建模型。这是我的模型：
 类多类（nn.module）：
    def __init __（自我）：
        super（）.__ init __（）
        self.hidden = nn.linear（4，8）
        self.act = nn.relu（）
        self.output = nn.linear（8，3）

    def向前（self，x）：
        x = self.act（self.hidden（x））
        x = self.Output（x）
        返回x
 ]]></description>
      <guid>https://stackoverflow.com/questions/79495434/how-do-i-use-my-trained-ai-model-to-make-predictions</guid>
      <pubDate>Sun, 09 Mar 2025 05:02:34 GMT</pubDate>
    </item>
    <item>
      <title>导入pytorch时：“错误加载torch_python.dll或其依赖项之一”</title>
      <link>https://stackoverflow.com/questions/79495211/oserror-when-importing-pytorch-error-loading-torch-python-dll-or-one-of-its-de</link>
      <description><![CDATA[我使用 pip安装火炬安装了pytorch，但是当我尝试导入它时，我会收到以下错误：
  Oserror Trackback（最近的最新通话）  
[1]中的单元，第1行  
----＆gt; 1进口火炬  
      2印刷（Torch .__版本__）  
      3印刷（Torch.version.cuda） 

file＆quort&#39;\。venv \ lib \ site-packages \ torch \ __ init __. py＆quort&#39;,，第274行  
    270增加错误  
    272 kernel32.seterrormode（prev_error_mode）  
 - ＆gt; 274 _load_dll_libraries（）  
    275 del _load_dll_libraries


file＆quot&#39;\。venv \ lib \ site-packages \ torch \ __ init __. py＆quort; py＆quort in _load_dll_libraries in _load_dll_libraries  
    253 err = ctypes.winerror（last_error）  
    254 err.Strerror +=（  
    255 f&#39;错误加载“ {dll}”＆quot;或它的依赖之一。  
    256）  
 - ＆gt; 257增加错误  
    258 Elif Res并非没有：  
    259 is_loaded = true 

Oserror：[Winerror 127]找不到指定的程序。错误加载; \。venv \ lib \ site-packages \ torch \ lib \ torch_python.dll;或它的依赖之一。
 
 我的系统配置：&lt; /strong&gt; 
OS：Windows 11 
Python版本：3.11（pyenv）
Pytorch版本：2.6.0 
CUDA工具包已安装：11.8 
使用的安装命令：PIP安装火炬
虚拟环境：是（VENV）
 尝试了不同的pytorch安装 
使用官方Pytorch的推荐命令安装
网站：
  pip安装火炬火炬火炬 -  index-url https://download.pytorch.org/whl/cu118
 
  oserror：[winerror 127 winerror 127]在那儿无法找到 conda conda conda，但无法在那里找到pera。]]></description>
      <guid>https://stackoverflow.com/questions/79495211/oserror-when-importing-pytorch-error-loading-torch-python-dll-or-one-of-its-de</guid>
      <pubDate>Sun, 09 Mar 2025 00:03:32 GMT</pubDate>
    </item>
    <item>
      <title>OPENCV，YOLO或培训模型，以预测照片是否满足护照或学校身份证的要求？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79494898/opencv-yolo-or-train-a-model-for-predicting-if-a-photo-meets-requirement-for-pa</link>
      <description><![CDATA[是否可以单独使用OpenCV，或与Yolo（例如Yolo）结合使用OPENCV来验证图像是否适合ID卡吗？没有头饰，没有太阳镜，白色背景。还是训练模型会更容易，更准确？我一直在django中使用yolo的openCV，并且我得到了误报，也许我的代码是错误的，也许这些库是用于更通用的用例，哪种路径是最好的-opencv + yolo或训练我的模型？]]></description>
      <guid>https://stackoverflow.com/questions/79494898/opencv-yolo-or-train-a-model-for-predicting-if-a-photo-meets-requirement-for-pa</guid>
      <pubDate>Sat, 08 Mar 2025 19:17:28 GMT</pubDate>
    </item>
    <item>
      <title>在单个设备上运行时，应在降低图中删除集体通信操作吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79494735/should-collective-communication-ops-be-removed-or-become-no-ops-in-graph-lower</link>
      <description><![CDATA[我正在研究集体通信操作（例如，全合理，全聚集）期间图表降低阶段的优化。我的直觉是，当这些CCL操作在单个设备上执行（或仅包含一个成员的进程组）时，它们没有真正的语义影响，并且可以安全地删除或降低到no-op以避免不必要的开销。 
但是，在检查了Jax，StableHlo（和XLA），NVIDIA的NCCL和TORCH等框架中的实现之后，我还没有找到任何明确的实例，可以在应用此类优化的情况下进行。 
我的问题是：

 这些框架中的任何一个是否实现“单位设备”优化（即，在不需要通信时降低过程中删除或绕过集体OP）？

 如果没有，是否存在特定原因 - 例如维护IR语义，调试或调度考虑因素 - 为什么将集体OP保留，即使它充当NO-OP？


我审查了JAX，StableHlo，NCCL和Torch的源代码和文档。分发，但没有发现在单个设备上运行时删除集体操作的明确优化。]]></description>
      <guid>https://stackoverflow.com/questions/79494735/should-collective-communication-ops-be-removed-or-become-no-ops-in-graph-lower</guid>
      <pubDate>Sat, 08 Mar 2025 17:08:45 GMT</pubDate>
    </item>
    <item>
      <title>解构稳定扩散3.5管道</title>
      <link>https://stackoverflow.com/questions/79494728/deconstructiong-the-stable-diffusion-3-5-pipeline</link>
      <description><![CDATA[我正在尝试解构SD3.5（特别是3.5个介质）管道，以便在降压步骤上具有受控的过程。我无法进行回调，因为我需要根据其他管道修改潜在。
我正在尝试在以下拥抱面指南上执行步骤：
 https://huggingface.co/docs/diffusers/en/using-diffusers/write_own_pipeline_pipeline#deconstruct-the-stable-diffusion-diffusion-pipeline  
我修改了文本编码以适合SD3.5，我还尝试加载整个管道，并在其上运行Encode_prompt函数，以获取文本嵌入和汇总的嵌入，以适应提示和负个提示。当运行该功能并将其输出作为常规管道输入而不是提示提示时，它可以正常工作，因此这似乎不是引起问题的原因。
我还将UNET从文章中更改为使用模型的预训练变压器。之后，我调整了解码器以匹配扩散器上管道源代码上的相同解码。
输出图像在通过扩散器运行管道时看起来并不相同。我不确定在哪里可以找到与SD3管道解构类似的实现，或者我缺少什么。
 在此处输入图像说明  ]]></description>
      <guid>https://stackoverflow.com/questions/79494728/deconstructiong-the-stable-diffusion-3-5-pipeline</guid>
      <pubDate>Sat, 08 Mar 2025 17:06:18 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下，为什么单次编码会具有更差的准确性？</title>
      <link>https://stackoverflow.com/questions/77610686/why-does-the-one-hot-encoding-give-worse-accuracy-in-this-case</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77610686/why-does-the-one-hot-encoding-give-worse-accuracy-in-this-case</guid>
      <pubDate>Wed, 06 Dec 2023 05:12:08 GMT</pubDate>
    </item>
    <item>
      <title>二进制分类：为什么使用+1/0作为标签， +1/-1甚至 +100/-100之间有什么区别</title>
      <link>https://stackoverflow.com/questions/74752325/binary-classification-why-use-1-0-as-label-whats-the-difference-between-1-1</link>
      <description><![CDATA[在二进制分类问题中，我们通常将+1用于正标，为负标签0。  这是为什么？特别是为什么使用0而不是-1作为负面标签？
使用-1用于负标签，甚至更普遍，我们可以将+100用于正标签，而-100可以用于负标签？？]]></description>
      <guid>https://stackoverflow.com/questions/74752325/binary-classification-why-use-1-0-as-label-whats-the-difference-between-1-1</guid>
      <pubDate>Sat, 10 Dec 2022 11:05:01 GMT</pubDate>
    </item>
    <item>
      <title>从keras.engine.topolgy导入网络的错误</title>
      <link>https://stackoverflow.com/questions/70239943/error-to-import-network-from-keras-engine-topolgy</link>
      <description><![CDATA[我通过降低keras（pip install&#39;keras == 2.1.6&#39; -  force-redinstall）来安装拓扑软件包，因为它在较新版本中不存在。我仍在遇到一个错误以导入网络。
 尝试：
来自Keras.Engine.Topology进口网络

错误：
Importerror：无法从&#39;keras.engine.topology&#39;导入名称&#39;网络&#39;（/usr/local/lib/python3.7/dist-packages/keras/engine/engine/topology.py）
 
如果不存在网络，则如何获得该代码（Cyclegan）可以使用Network（）。任何帮助将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/70239943/error-to-import-network-from-keras-engine-topolgy</guid>
      <pubDate>Mon, 06 Dec 2021 01:12:32 GMT</pubDate>
    </item>
    <item>
      <title>重新启动运行时，模型负载获得不同的结果</title>
      <link>https://stackoverflow.com/questions/68116676/model-load-get-different-result-after-restart-runtime</link>
      <description><![CDATA[我已经使用Google Colab编写了Resnet50型号。训练我的模型后，然后在不重新启动运行时间的情况下保存模型后，将获得相同的结果，但是在重新启动运行时Google Colab并运行 Xtrain，Ytest，Ytest，X_Val，Y_VAL，Y_VAL 然后再次加载模型，我将获得不同的结果。
这是我的代码：
  #hyperParameter和回调
batch_size = 128
num_epochs = 120
input_shape =（48、48、1）
num_classes = 7

#compile模型。
从keras.optimizer进口亚当，sgd
model = resnet50（input_shape =（48、48、1），类= 7）
优化器= SGD（Learning_rate = 0.0005）
model.compile（优化器=优化器，lose =&#39;Sparse_categorical_crossentropy&#39;，metrics = [&#39;准确性&#39;]）

model.summary（）
历史= model.fit（
    data_generator.flow（Xtrain，ytrain，），
    step_per_epoch = len（xtrain） / batch_size，
    epochs = num_epochs， 
    详细= 1，
    验证_data =（x_val，y_val））

导入matplotlib.pyplot作为PLT 
model.save（&#39;fix_model_resnet50editsgd5st.h5&#39;）

#plot图
准确性=历史[&#39;精确度&#39;]
val_accuracy =历史[&#39;val_accuracy&#39;]
损失=历史[&#39;损失&#39;]
val_loss =历史[&#39;val_loss&#39;]
num_epochs = range（len（准确性））
plt.plot（num_epochs，准确性，&#39;r&#39;，label =&#39;triending acc&#39;）
plt.plot（num_epochs，val_accuracy，&#39;b&#39;，label =&#39;验证acc&#39;）
plt.title（“训练和验证精度”）
plt.ylabel（“准确性”）  
plt.xlabel（&#39;epoch&#39;）
plt.legend（）
plt. -figure（）
plt.plot（num_epochs，损失，&#39;r&#39;，label =“训练损失”）
plt.plot（num_epochs，val_loss，&#39;b&#39;，label =&#39;验证损失&#39;）
plt.title（“培训和验证损失”）
plt.ylabel（“损失”）  
plt.xlabel（&#39;epoch&#39;）
plt.legend（）
plt.show（）

#load模型
来自keras.models import load_model
model_load = load_model（&#39;fix_model_resnet50editsgd5st.h5&#39;）

model_load.summary（）


testdatamodel = model_load.evaluate（Xtest，ytest） 
打印（“测试损失” + str（testdatamodel [0]））
打印（“测试ACC：＆quot” + str（testdatamodel [1]））

traindata = model_load.evaluate（xtrain，ytrain） 
打印（“测试损失” + str（traindata [0]））
打印（“测试acc：＆quot” + str（traindata [1]））

valdata = model_load.evaluate（x_val，y_val） 
打印（“测试损失” + str（valdata [0]））
打印（“测试acc：＆quot” + str（valdata [1]））
 
  - 训练和保存模型后，然后运行加载模型，而无需重新启动运行时Google Colab：
如您所见
测试损失：0.9411-精度：0.6514 
火车损失：0.7796-准确性：0.7091 
  modelevaluateTestest＆amp;火车 
在重新启动运行时Colab之后再次运行加载模型：
测试损失：0.7928-准确性：0.6999 
火车损失：0.8189-准确性：0.6965 
 重新启动运行时评估测试和训练 ]]></description>
      <guid>https://stackoverflow.com/questions/68116676/model-load-get-different-result-after-restart-runtime</guid>
      <pubDate>Thu, 24 Jun 2021 13:25:12 GMT</pubDate>
    </item>
    <item>
      <title>用Scikit-Learn进行象征性文字</title>
      <link>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</link>
      <description><![CDATA[我有以下代码从一组文件（文件夹名称是类别名称）中提取文本分类的代码。
 导入sklearn.datasets
来自sklearn.feature_extraction.text导入tfidfvectorizer

train = sklearn.datasets.datasets.load_files（&#39;./ train&#39;，description = none，类别= none，load_content = true，shuffle = true，encoding = none，decode_error =&#39;strict&#39;
打印Len（train.data）
打印火车。target_names

vectorizer = tfidfvectorizer（）
x_train = vectorizer.fit_transform（train.data）
 
它抛出以下堆栈跟踪：
  trackback（最近的最新通话）：
  文件“ C：\ eclipseworkspace \ textClassifier \ main.py”，第16行，in＆lt; module＆gt;
    x_train = vectorizer.fit_transform（train.data）
  文件“ c：\ python27 \ lib \ lib \ site-packages \ sklearn \ feature_extraction \ text.py”，第1285行，在fit_transform中
    x = super（tfidfvectorizer，self）.fit_transform（raw_documents）
  文件“ c：\ python27 \ lib \ lib \ site-packages \ sklearn \ feature_extraction \ text.py”，第804行，在fit_transform中
    self.fixed_vocabulary_）
  文件“ c：\ python27 \ lib \ site-packages \ sklearn \ sklearn \ feature_extraction \ text.py”，第739行，in _count_vocab
    对于分析中的功能（DOC）：
  文件“ c：\ python27 \ lib \ site-packages \ sklearn \ feature_extraction \ text.py”，第236行，in＆lt; lambda＆gt;
    tokenize（preprocess（self.decode（doc））），stop_words）
  文件“ C：\ Python27 \ lib \ site-packages \ sklearn \ sklearn \ feature_extraction \ text.py”，第113行，在解码中
    doc = doc.decode（self.soding，self.decode_error）
  文件“ C：\ Python27 \ lib \ cododings \ utf_8.py”，第16行，在解码中
    返回codecs.utf_8_decode（输入，错误，true）
UNICODEDEDECODEERROR：&#39;utf8&#39;编解码器无法在位置32054中解码字节0xff：无效启动字节
 
我运行Python 2.7。我该如何工作？
 编辑：
我刚刚发现，这对于具有 utf-8 编码的文件非常有效（我的文件是 ansi 编码）。有什么办法可以获得 sklearn.datasets.load_files（）与 ansi 编码？]]></description>
      <guid>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</guid>
      <pubDate>Fri, 01 May 2015 00:39:09 GMT</pubDate>
    </item>
    </channel>
</rss>