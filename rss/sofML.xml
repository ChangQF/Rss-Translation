<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 30 Oct 2024 15:18:34 GMT</lastBuildDate>
    <item>
      <title>TensorFlow InvalidArgumentError：ConcatOp 中的连接维度不匹配 - 形状不匹配</title>
      <link>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</guid>
      <pubDate>Wed, 30 Oct 2024 13:00:13 GMT</pubDate>
    </item>
    <item>
      <title>我的项目中可以使用任何机器学习算法吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/79140771/is-there-any-machine-learning-algorithm-to-use-in-my-project</link>
      <description><![CDATA[“我正在开发一个机器学习模型，根据用户在多个科目（例如能力和常识）上的测试成绩向他们推荐书籍。推荐应适应用户的表现水平，根据他们的得分是高于还是低于某些阈值来推荐不同的书籍。哪种 ML 算法最适合此目的，我需要包含哪种数据字段才能有效地训练模型？”
我尝试使用 K-最近邻 (KNN) 算法训练模型，数据集包含 user_id、科目名称、科目分数和推荐书籍等字段。但是，准确度得分很低，并且模型在根据用户分数推荐相关书籍方面的表现不如预期。由于我是机器学习领域的新手并且仍在学习，因此我正在寻求指导，了解哪些算法可能更有效，以及哪些其他数据字段可能有助于提高模型准确性。]]></description>
      <guid>https://stackoverflow.com/questions/79140771/is-there-any-machine-learning-algorithm-to-use-in-my-project</guid>
      <pubDate>Wed, 30 Oct 2024 10:54:06 GMT</pubDate>
    </item>
    <item>
      <title>训练 IP-Adapter plus 模型后的推理错误</title>
      <link>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</link>
      <description><![CDATA[我从以下位置下载了软件包
https://github.com/tencent-ailab/IP-Adapter

运行命令来训练 IP-Adapter plus 模型（输入：文本 + 图像，输出：图像）：
accelerate launch --num_processes 2 --multi_gpu --mixed_precision &quot;fp16&quot; \
tutorial_train_plus.py \
--pretrained_model_name_or_path=&quot;stable-diffusion-v1-5/&quot; \
--image_encoder_path=&quot;models/image_encoder/&quot; \
--data_json_file=&quot;assets/prompt_image.json&quot; \
--data_root_path=&quot;assets/train/&quot; \
--mixed_precision=&quot;fp16&quot; \
--resolution=512 \
--train_batch_size=2 \
--dataloader_num_workers=4 \
--learning_rate=1e-04 \
--weight_decay=0.01 \
--output_dir=&quot;out_model/&quot; \
--save_steps=3

训练过程中，出现提示，但训练可以继续：
已删除共享张量 {&#39;adapter_modules.27.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_v_ip.weight&#39;, &#39;adapter_modules.31.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_k_ip.weight&#39;, &#39;adapter_modules.31.to_v_ip.weight&#39;, &#39;adapter_modules.11.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_k_ip.weight&#39;, &#39;adapter_modules.25.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_k_ip.weight&#39;, &#39;adapter_modules.19.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_k_ip.weight&#39;, &#39;adapter_modules.29.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_v_ip.weight&#39;, &#39;adapter_modules.25.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_k_ip.weight&#39;, &#39;adapter_modules.9.to_v_ip.weight&#39;, &#39;adapter_modules.9.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_v_ip.weight&#39;, &#39;adapter_modules.27.to_v_ip.weight&#39;, &#39;adapter_modules.29.to_v_ip.weight&#39;, &#39;adapter_modules.19.to_k_ip.weight&#39;, &#39;adapter_modules.11.to_v_ip.weight&#39;}。这应该没问题，但请检查重新加载时是否收到任何警告

训练完成后，转换权重以生成 ip_adapter.bin，然后使用此文件中的以下模型路径运行推理代码 ip_adapter-plus_demo.py：
base_model_path = &quot;SG161222/Realistic_Vision_V4.0_noVAE&quot;
vae_model_path = &quot;stabilityai/sd-vae-ft-mse&quot;
image_encoder_path = &quot;models/image_encoder&quot;
ip_ckpt = &quot;out_model/demo_plus_checkpoint/ip_adapter.bin&quot;

显示错误：
raise RuntimeError(&#39;Error(s) in loading state_dict for {}:\n\t{}&#39;.format(
RuntimeError: Error(s) in loading state_dict for ModuleList:
Missing key(s) in state_dict: &quot;1.to_k_ip.weight&quot;, &quot;1.to_v_ip.weight&quot;, &quot;3.to_k_ip.weight&quot;, &quot;3.to_v_ip.weight&quot;, &quot;5.to_k_ip.weight&quot;, &quot;5.to_v_ip.weight&quot;, &quot;7.to_k_ip.weight&quot;, &quot;7.to_v_ip.weight&quot;, &quot;9.to_k_ip.weight&quot;, &quot;9.to_v_ip.weight&quot;, “11.to_k_ip.weight”, “11.to_v_ip.weight”, “13.to_k_ip.weight”, “13.to_v_ip.weight”, “15.to_k_ip.weight”, “15.to_v_ip.weight”, “17.to_k_ip.weight”, “17.to_v_ip.weight”, “19.to_k_ip.weight”, “19.to_v_ip.weight”, “21.to_k_ip.weight”, “21.to_v_ip.weight”, “23.to_k_ip.weight”, “23.to_v_ip.weight”, &quot;25.to_k_ip.weight&quot;, &quot;25.to_v_ip.weight&quot;, &quot;27.to_k_ip.weight&quot;, &quot;27.to_v_ip.weight&quot;, &quot;29.to_k_ip.weight&quot;, &quot;29.to_v_ip.weight&quot;, &quot;31.to_k_ip.weight&quot;, &quot;31.to_v_ip.weight&quot;.

什么步骤出错导致此错误？]]></description>
      <guid>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</guid>
      <pubDate>Wed, 30 Oct 2024 07:32:22 GMT</pubDate>
    </item>
    <item>
      <title>我们如何计算零膨胀泊松回归和零膨胀负二项回归的平均绝对误差（MAE）（R 或 python）？</title>
      <link>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</link>
      <description><![CDATA[现在，我尝试使用 Python 在进行零膨胀泊松回归和零膨胀负二项回归时计算平均绝对误差 (MAE)。
我将数据分为训练数据和测试数据。我使用下面的代码，但它不起作用。
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
import statsmodels.formula.api as smf
import tensorflow as tf
df = pd.read_excel(&#39;....&#39;, sheet_name=&#39;Sheet1&#39;)
print(df.head())
X = df[[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]
y = df[&#39;g&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from statsmodels.discrete.count_model import ZeroInflatedPoisson
y_zip = y_train.values

y_zip_test = y_test.values

X_count = X_train.values # 计数部分的预测器
X_zero = X_train.values # 零膨胀部分的预测器

X_count_test = X_test.values
X_zero_test = X_test.values

# 为截距添加一个常数
X_count = sm.add_constant(X_count)
X_zero = sm.add_constant(X_zero)

# 拟合 ZIP 模型
zip_model = ZeroInflatedPoisson(endog=y_zip, exog=X_count, exog_infl=X_zero, indication=&#39;logit&#39;)
zip_model_fit = zip_model.fit()
print(zip_model_fit.summary())

# 进行预测
y_pred = zip_model_fit.predict(X_count_test)

# 计算 MAE
mae = np.mean(np.abs(y_zip_test - y_pred))
print(f&#39;平均绝对误差：{mae}&#39;)

结果如下
-------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Cell In[3], line 33
29 print(zip_model_fit.summary())
32 # 进行预测
---&gt; 33 y_pred = zip_model_fit.predict(X_count_test)
35 # 计算 MAE 测试
36 mae = np.mean(np.abs(y_zip_test - y_pred))

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\base\model.py:1174，位于 Results.predict(self, exog, transform, *args, **kwargs)
1127 &quot;&quot;&quot;
1128 调用 self.model.predict 并以 self.params 作为第一个参数。
1129 
(...)
1169 返回预测。
1170 &quot;&quot;&quot;
1171 exog, exog_index = self._transform_predict_exog(exog,
1172 transform=transform)
-&gt; 1174 predict_results = self.model.predict(self.params, exog, *args,
1175 **kwargs)
1177 如果 exog_index 不为 None 且不 hasattr(predict_results,
1178 &#39;predicted_values&#39;):
1179 如果 predict_results.ndim == 1:

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\discrete\count_model.py:453，位于 GenericZeroInflated.predict(self, params, exog, exog_infl, Exposure, Offset, which, y_values)
449 params_main = params[self.k_inflate:]
451 prob_main = 1 - self.model_infl.predict(params_infl, exog_infl)
--&gt; 453 lin_pred = np.dot(exog, params_main[:self.exog.shape[1]]) + Exposure + Offset
455 # 重构：这很不靠谱，
456 # model_main 中应该有一个合适的预测方法
457 # 这只是 prob(y=0 | model_main)
458 tmp_exog = self.model_main.exog

ValueError：形状 (21,6) 和 (7,) 未对齐：6 (1 维) != 7 (0 维)

你能给我一些解决方案吗？
我试过计算 MAE，但多次出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</guid>
      <pubDate>Wed, 30 Oct 2024 07:04:19 GMT</pubDate>
    </item>
    <item>
      <title>Kong AI 代理插件：在 Kong AI 网关上配置自托管 LLM 的正确参数</title>
      <link>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</guid>
      <pubDate>Wed, 30 Oct 2024 03:54:46 GMT</pubDate>
    </item>
    <item>
      <title>验证数据的输入形状无效</title>
      <link>https://stackoverflow.com/questions/79139121/invalid-input-shape-for-validation-data</link>
      <description><![CDATA[我正在使用 Tensorflow 在 Python 中开发一个简单的 ML 模型。代码如下：
import tensorflow as tf
import pandas as pd

# 加载 CSV 数据
def load_data(filename):
data = pd.read_csv(filename)
X = data[[&#39;X0&#39;,&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]]
Y = data[[&#39;Y0&#39;,&#39;Y1&#39;]]
return tf.data.Dataset.from_tensor_slices((X.values, Y.values))

training_data = load_data(&quot;binarydatatraining.csv&quot;)
print(training_data)

# 构建一个简单的神经网络模型
model = tf.keras.models.Sequential([
tf.keras.layers.Dense(4,activation=&#39;relu&#39;),
tf.keras.layers.Dense(2)
])
# 编译模型
model.compile(optimizer=&#39;adam&#39;,
loss=&#39;mean_squared_error&#39;)

# 加载验证数据
validation_data = load_data(&quot;binarydatavalidation.csv&quot;)
print(validation_data)

# 训练模型
model.summary()
model.fit(training_data.batch(9), epochs=5)
model.summary()
model.fit(training_data.batch(9), epochs=1, validation_data = validation_data, validation_steps = 2)

一切都运行正常，直到我开始包含验证数据，该数据具有与训练数据相同数量的参数。然后我收到错误
ValueError：调用 Sequential.call() 时遇到异常。

[1m输入 Tensor(&quot;sequence_1/Cast:0&quot;, shape=(4,), dtype=float32) 的输入形状无效。预期形状 (None, 4)，但输入具有不兼容的形状 (4,)[0m

Sequential.call() 收到的参数：
• 输入=tf.Tensor(shape=(4,), dtype=int64)
• 训练=False
• 掩码=None

打印验证和训练数据集显示它们具有相同的维度，并且运行 print(training_data) 和 print(validation_data) 都给出
&lt;_TensorSliceDataset element_spec=(TensorSpec(shape=(4,), dtype=tf.int64, name=None), TensorSpec(shape=(2,), dtype=tf.int64, name=None))&gt;

如何正确设置验证数据以与 model.fit 内联运行？]]></description>
      <guid>https://stackoverflow.com/questions/79139121/invalid-input-shape-for-validation-data</guid>
      <pubDate>Tue, 29 Oct 2024 21:59:29 GMT</pubDate>
    </item>
    <item>
      <title>对整个数据集进行标准化（MinMax）是否会对看不见的时间序列数据产生更好的结果？[关闭]</title>
      <link>https://stackoverflow.com/questions/79136221/normalization-minmax-on-the-whole-dataset-produces-better-results-on-unseen-ti</link>
      <description><![CDATA[我已经训练了一个模型，用于预测价格相对于 15 天的最小最大值：1 最大值；0 最小值；否则为 0.5。问题是 Keras 中的 mse 回归，该模型是无状态的：
RNN(PeepholeCell(units=2,activation=&#39;relu&#39;))
TimeDistributed(Dense(1))
Dense(1)
优化器是 Adam。形状：
test_X.shape = (69501, 1, 45); test_y.shape = (11508, 1, 1)
我进行了如下拟合：
history = model.fit(train_X, train_y,
epochs=num_epochs, batch_size=10080, validation_data=(test_X, test_y), verbose=2,
shuffle=False, callbacks=[
earlystopping,
reduce_lr
]
, class_weight=class_weights
)

我对不同的模型配置、学习率策略进行了不同的训练尝试，并使用了 2014 年至 2021 年的每小时汇总数据，并使用了 2019 年至 2021 年的数据进行测试。对于验证，我使用了当前未见的数据（最近 900 天），粒度为 1 天，（最近 900 * 24）粒度为 1 小时。要预测的 y 数据为 0（表示最小相对值）、1（表示最大值）和 0.5（否则）。标签 (y) 具有振荡统计数据，但在不同批次（平均值、标准差、最大值、最小值、QR）中随时间变化的幅度相同。除了一些大小反映价格幅度变化的特征外，这些特征还具有恒定范围（例如振荡器）。
我发现，通过回测对看不见的数据执行的最佳模型是仅将 MinMax 缩放器（scikit）应用于整个数据集的模型，如果仅通过拟合训练并使用训练拟合缩放器转换测试来应用，则结果无所谓。
是否存在计算原因或数据统计原因，说明为什么使用通过 scikitlearn 的 MinMax 规范化器预处理的数据训练的模型在拟合和转换整个数据集而不是在训练和使用该缩放器转换测试时产生类似的结果？]]></description>
      <guid>https://stackoverflow.com/questions/79136221/normalization-minmax-on-the-whole-dataset-produces-better-results-on-unseen-ti</guid>
      <pubDate>Tue, 29 Oct 2024 07:40:35 GMT</pubDate>
    </item>
    <item>
      <title>3D加工零件特征识别（点云、网格）</title>
      <link>https://stackoverflow.com/questions/79062004/3d-machining-part-feature-recognition-point-cloud-mesh</link>
      <description><![CDATA[我有一个加工部件 (.STL)，想要识别（并提取）它的加工特征。有些特征很简单，但有些更复杂，这就是为什么我认为机器学习方法会很合适，因为我无法用数学方式描述该特征。
有一个 FeatureNet，它基本上可以完成这项工作，但它无法识别多个特征，并且代码无法按预期工作。
我还知道 AAGNet，它可以完成我想要的工作，但它使用 .STEP 作为输入，但我有一个网格（如果我转换它，则是点云）。
由于有更多的点云存储库，我认为我可以使用它们来解决我的问题。像 FPFH 这样的东西是正确的方向吗，还是我走错了路？
如果我使用机器学习方法，我可以轻松创建标记数据集。]]></description>
      <guid>https://stackoverflow.com/questions/79062004/3d-machining-part-feature-recognition-point-cloud-mesh</guid>
      <pubDate>Mon, 07 Oct 2024 12:41:25 GMT</pubDate>
    </item>
    <item>
      <title>在 lightgbm 中，为什么 train 和 cv API 会接受 categorical_feature 参数，而它已经存在于数据集构造中</title>
      <link>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</link>
      <description><![CDATA[以下是 lightgbm 的 .cv API

lightgbm.cv(params, train_set, num_boost_round=100, folds=None, nfold=5, stratified=True, shuffle=True, metrics=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, fpreproc=None, seed=0, callbacks=None, eval_train_metric=False, return_cvbooster=False)

有一个参数cateogrical_feature

分类特征。如果是 int 列表，则解释为索引。如果是 str 列表，则解释为特征名称（也需要指定 feature_name）。

现在 .train API

lightgbm.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, keep_training_booster=False, callbacks=None)

这里还有一个 categorical_feature 参数。文档与上述相同
现在，正如您所注意到的，这两个 API 都使用 lightgbm 数据集，而该数据集本身采用 categorical_feature 参数。文档完全相同
问题：

如果两者都指定，哪一个优先？
建议在哪个位置指定 categorical_feature？
这两个选择在内部与 lightgbm 管道的工作方式有何不同？
]]></description>
      <guid>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</guid>
      <pubDate>Thu, 25 Apr 2024 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>警告：tensorflow：顺序模型中的层只能有一个输入张量</title>
      <link>https://stackoverflow.com/questions/73181243/warningtensorflowlayers-in-a-sequential-model-should-only-have-a-single-input</link>
      <description><![CDATA[我从 tensorflow 网站对自动编码器的第一个示例的介绍 复制了过去的代码，以下代码适用于 mnist 时尚数据集，但不适用于我的数据集。这给了我一个很长的警告。请告诉我我的数据集出了什么问题
警告
屏幕上缺少相同的错误
这里 x_train 是我的数据集：
tf.shape(x_train)

输出 &lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([169,** **28, 28])&gt;

这里 x_train 是 mnist 数据集：
tf.shape(x_train)

输出&lt;tf.Tensor: shape=(3,), dtype=int32, numpy=array([60000, 28, 28])&gt;

我制作数据集的整个代码：
dir_path=&#39;auto/ttt/&#39;
data=[]
x_train=[]
for i in os.listdir(dir_path):
img=image.load_img(dir_path+&#39;//&#39;+i,color_mode=&#39;grayscale&#39;,target_size=(28,28)) 
data=np.array(img)
data=data/255.0
x_train.append(data)

这是警告：
警告：tensorflow：顺序模型中的层应该只有一个输入张量。已接收：输入=(&lt;tf.Tensor&#39;IteratorGetNext:0&#39;shape=(None, 28)dtype=float32&gt;,&lt;tf.Tensor&#39;IteratorGetNext:1&#39;shape=(None, 28)dtype=float32&gt;,&lt;tf.Tensor&#39;IteratorGetNext:2&#39;shape=(None, 28)
dtype=float32&gt;,&lt;tf.Tensor&#39;IteratorGetNext:3&#39;shape=(None, 28)
dtype=float32&gt;,&lt;tf.Tensor&#39;IteratorGetNext:4&#39;shape=(None, 28)dtype=float32&gt;,&lt;tf.Tensor&#39;IteratorGetNext:5&#39;shape=(None, 28)dtype=float32&gt;,&lt;tf.Tensor &#39;IteratorGetNext:6&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:7&#39; shape=(None, 28) dtype=flo...

还有这个值错误（相同的警告）：
ValueError：调用层“sequential_4”（类型为 Sequential）时遇到异常。

层“flatten_2”需要 1 个输入，但它收到了 169 个输入张量。收到的输入：[&lt;tf.Tensor &#39;IteratorGetNext:0&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:1&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:2&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:3&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:4&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:5&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:6&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:7&#39; shape=(None, 28) dtype=float32&gt;, &lt;tf.Tensor &#39;IteratorGetNext:8&#39; shape=(None, 28) dtype=float3...
]]></description>
      <guid>https://stackoverflow.com/questions/73181243/warningtensorflowlayers-in-a-sequential-model-should-only-have-a-single-input</guid>
      <pubDate>Sun, 31 Jul 2022 06:54:28 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层“顺序”的输入 0 与层不兼容</title>
      <link>https://stackoverflow.com/questions/71370360/valueerror-input-0-of-layer-sequential-is-incompatible-with-the-layer</link>
      <description><![CDATA[我有一个聊天机器人模型，我用数据集对其进行了训练，以提供“标准”对话，例如你好，你好吗等。现在我想用一个数据集来“扩展”现有模型，该数据集可以提供与运输、库存等相关的问题的答案。
这是我的工作/已经训练过的模型：
# 创建顺序模型
model = Sequential()

# 添加第一层，其输入形状取决于输入的大小和“relu”激活函数
model.add(Dense(256, input_shape=(len(training_data_x[0]),),activation=activations.relu))

# 添加 Dropout 以防止过度拟合
model.add(Dropout(0.6))
# 具有 64 个神经元的附加层
model.add(Dense(128,activation=activations.relu))
model.add(Dropout(0.2))
# 具有类别神经元数量的附加密集层 &amp; softmax 激活函数
# -&gt; 将输出层中的结果添加到“1”得到 %
model.add(Dense(len(training_data_y[0]),activation=activations.softmax))
# print(len(training_data_y[0])) = 71
sgd = SGD(learning_rate=0.01, decay=1e-6, motivation=0.9, nesterov=True)
# 编译模型
model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd, metrics=[&#39;accuracy&#39;])

output = model.fit(np.array(training_data_x), np.array(training_data_y), epochs=200, batch_size=5, verbose=1)
plot_model_output(output)
model.summary()
model.save(&#39;./MyModel_tf&#39;, save_format=&#39;tf&#39;)

训练数据准备如下一个单独的类，并将某个 json 文件作为输入。
现在我只需将 JSON 文件替换为包含与我想添加到模型中的内容相关的数据的文件，并尝试像这样拟合它：
json_data = json.loads(open(&#39;data.json&#39;).read())

model = load_model(&#39;MyModel_tf&#39;)

model.fit(np.array(training_data_x), np.array(training_data_y), epochs=200, batch_size=5, verbose=1)

但是当我运行它时，我收到此错误：
ValueError: 输入 0 of layer &quot;sequence&quot;与层不兼容：预期形状=（无，652），发现形状=（无，71）

我假设数据是问题所在……但它的结构完全相同，只是更短。
我的问题：

我尝试实现它的方式有意义吗？
我应该尝试以不同的方式添加其他数据吗？
第二个数据集的长度必须与第一个数据集的长度相同吗？
]]></description>
      <guid>https://stackoverflow.com/questions/71370360/valueerror-input-0-of-layer-sequential-is-incompatible-with-the-layer</guid>
      <pubDate>Sun, 06 Mar 2022 12:41:31 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：不可散列类型：pd.get_dummies 的“Series”</title>
      <link>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</link>
      <description><![CDATA[我尝试对我拥有的数据框中的一些名义数据（来自 Kaggle 的 House Regression）使用 pd.get_dummies。我将所有名义类别分成列名列表，&#39;obj_nominal&#39;。
当我调用
pd.get_dummies(df, columns=obj_nominal)

我收到错误：
TypeError: unhashable type: &#39;Series&#39;.

到目前为止，我所做的唯一预处理是删除数据集中的空值。我也尝试过使用 Sklearn OneHotEncoder，但它会产生相同的错误。
我也尝试过使用以下方法制作单独的数据框：
x = df.iloc[:, obj_nominal]

并在数据框上传递 get_dummies：
pd.get_dummies(data = x)

但还是没运气……
数据可在 https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data 下载]]></description>
      <guid>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</guid>
      <pubDate>Fri, 07 Jan 2022 05:51:22 GMT</pubDate>
    </item>
    <item>
      <title>维度问题：检查输入时出错：预期 conv2d_1_input 有 4 个维度，但得到的数组形状为 (26, 26, 1)</title>
      <link>https://stackoverflow.com/questions/60802354/dimension-problems-error-when-checking-input-expected-conv2d-1-input-to-have-4</link>
      <description><![CDATA[我有一个 CNN，它以以下通过 Canny 边缘检测转换为二值图像的图像作为输入。
​​并输出三个类别之一。
img = cv2.imread(path)
img = cv2.Canny(img, 33, 76)
img = np.resize(img, (26, 26, 1))
imgs.append(img)

据我所知，我必须将其转换为 3 维 (26,26,1) 图像，以便网络可以使用它。这是我的网络：
IMG_HEIGHT = 26
IMG_WIDTH = 26
no_Of_Filters=60
size_of_Filter=(5,5)
size_of_pool=(2,2)
no_Of_Nodes = 500
model_new = Sequential([
Conv2D(no_Of_Filters, size_of_Filter, padding=&#39;same&#39;,activation=&#39;relu&#39;, input_shape=(IMG_HEIGHT, IMG_WIDTH , 1)),
MaxPooling2D(pool_size=size_of_pool),
Conv2D(no_Of_Filters, size_of_Filter, padding=&#39;same&#39;,activation=&#39;relu&#39;),
MaxPooling2D(pool_size=size_of_pool),
Conv2D(64, size_of_Filter, padding=&#39;same&#39;,激活=&#39;relu&#39;),
MaxPooling2D(pool_size=size_of_pool),
Flatten(),
Dense(512, 激活=&#39;relu&#39;),
Dense(3, 激活=&#39;softmax&#39;)
])

训练效果良好。在我训练并创建模型后，我想针对该网络测试图像
test_image = cv2.Canny(test_image ,33,76)
test_image = np.resize(test_image, (26, 26, 1))
test_image = test_image [np.newaxis, ...]
prediction = model.predict(test_image)
print(prediction)

现在我收到错误：
ValueError：检查输入时出错：预期 conv2d_1_input 有 4 个维度，但得到的数组形状为 (26, 26, 1)

为什么训练后的模型现在需要 4 维输入？]]></description>
      <guid>https://stackoverflow.com/questions/60802354/dimension-problems-error-when-checking-input-expected-conv2d-1-input-to-have-4</guid>
      <pubDate>Sun, 22 Mar 2020 17:06:46 GMT</pubDate>
    </item>
    <item>
      <title>如何将输入图像与 CNN 中第一个卷积层的神经元进行映射？[关闭]</title>
      <link>https://stackoverflow.com/questions/60690923/how-to-map-input-image-with-neurons-in-first-conv-layer-in-cnn</link>
      <description><![CDATA[我很难将输入图像与第一个 CNN 转换层中的神经元进行映射，但我对输入特征如何映射到 ANN 中的第一个隐藏层有基本的了解。
理解输入图像与第一个转换层中的神经元之间的映射的最佳方法是什么？
我如何澄清对以下代码示例的疑问？代码取自 Coursera 的 DL 课程。
def initialize_parameters():
&quot;&quot;&quot;
初始化权重参数以使用 tensorflow 构建神经网络。形状为：
W1：[4, 4, 3, 8]
W2：[2, 2, 8, 16]
返回：
参数——包含 W1、W2 的张量字典
&quot;&quot;&quot;

tf.set_random_seed(1) # 以便您的&quot;random&quot;数字与我们的数字相匹配

### 此处开始代码 ###（大约 2 行代码）
W1 = tf.get_variable(&quot;W1&quot;,[4,4,3,8],initializer = tf.contrib.layers.xavier_initializer(seed = 0))
W2 = tf.get_variable(&quot;W2&quot;,[2,2,8,16],initializer = tf.contrib.layers.xavier_initializer(seed = 0))
### 此处结束代码 ###

parameters = {&quot;W1&quot;: W1,
&quot;W2&quot;: W2}

返回参数

def forward_propagation(X,parameters):
&quot;&quot;&quot;
为模型实现前向传播：
CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED

参数：
X -- 输入数据集占位符，形状为 (输入大小、示例数量)
参数 -- 包含参数“W1”、“W2”的 Python 字典
形状在 Initialize_parameters 中给出

返回：
Z3 -- 最后一个 LINEAR 单元的输出
“”

# 从字典“parameters”中检索参数
W1 = 参数[&#39;W1&#39;]
W2 = 参数[&#39;W2&#39;]

### 此处开始代码 ###
# CONV2D：步幅为 1，填充“相同”
Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = &#39;相同&#39;)
# RELU
A1 = tf.nn.relu(Z1)
# MAXPOOL：窗口 8x8，步幅 8，填充“相同”
P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = &#39;相同&#39;)
# CONV2D：过滤器 W2，步幅 1，填充“相同”
Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = &#39;SAME&#39;)
# RELU
A2 = tf.nn.relu(Z2)
# MAXPOOL: 窗口 4x4, 步幅 4, padding &#39;SAME&#39;
P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = &#39;SAME&#39;)
# FLATTEN
P2 = tf.contrib.layers.flatten(P2)
# FULLY-CONNECTED，无非线性激活函数（不调用 softmax）。
# 输出层中有 6 个神经元。提示：其中一个参数应该是“activation_fn=None”
Z3 = tf.contrib.layers.fully_connected(P2, 6,activation_fn=None)
### END CODE HERE ###

return Z3

with tf.Session() as sess:
np.random.seed(1)
X, Y = create_placeholders(64, 64, 3, 6)
parameters = initialize_parameters()
Z3 = forward_propagation(X, parameters)
init = tf.global_variables_initializer()
sess.run(init)
a = sess.run(Z3, {X: np.random.randn(1,64,64,3), Y: np.random.randn(1,6)})
print(&quot;Z3 = &quot; + str(a))

这个输入图像的大小是多少64643 由 8 个大小为 443 的过滤器处理？
stride = 1、padding = same 和 batch_size = 1。
到目前为止，我所理解的是，第一个卷积层中的每个神经元将有 8 个过滤器，每个过滤器的大小为 443。第一个卷积层中的每个神经元将获取与过滤器大小相同的输入图像部分（这里是 443），并应用卷积运算并产生八个 64*64 特征映射。
如果我的理解正确，那么：

为什么我们需要跨步操作，因为每个神经元处理的内核大小和输入图像部分是相同的，如果我们应用步幅 = 1（或 2），则输入图像部分的边界是交叉的，这是我们不需要的，对吗？

我们如何知道输入图像的哪一部分（与内核大小相同）映射到第一个卷积层的哪个神经元？


如果不是，那么：

输入图像如何在第一个卷积层的神经元上传递，是完整的输入图像传递给每个神经元（就像在完全连接的 ANN 中一样，其中所有输入特征被映射到第一个隐藏层中的每个神经元）？

或输入图像的一部分？我们如何知道输入图像的哪一部分映射到第一个卷积层的哪个神经元？

上述示例（W1= [4, 4, 3, 8]）指定的内核数量是每个神经元还是第一个卷积层中的内核总数？

我们如何知道上述示例在第一个卷积层中使用了多少个神经元？

神经元数量和第一个卷积层的内核数量之间有什么关系吗？

]]></description>
      <guid>https://stackoverflow.com/questions/60690923/how-to-map-input-image-with-neurons-in-first-conv-layer-in-cnn</guid>
      <pubDate>Sun, 15 Mar 2020 08:16:45 GMT</pubDate>
    </item>
    <item>
      <title>我们如何解释负调整兰特指数？</title>
      <link>https://stackoverflow.com/questions/42418773/how-can-we-interpret-negative-adjusted-rand-index</link>
      <description><![CDATA[调整后的随机指数 (ARI) 是比较两个聚类的常用指标。不幸的是，在执行聚类分析并进行比较后，我通常会得到负 ARI。我该如何解释这些负 ARI 来描述这些聚类之间的差异？如果负 ARI 毫无意义，有什么关于适当指标的建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/42418773/how-can-we-interpret-negative-adjusted-rand-index</guid>
      <pubDate>Thu, 23 Feb 2017 14:38:38 GMT</pubDate>
    </item>
    </channel>
</rss>