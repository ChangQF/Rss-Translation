<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 20 Jul 2024 15:17:46 GMT</lastBuildDate>
    <item>
      <title>如何将职位名称与职位空缺名称或职位空缺描述进行匹配？</title>
      <link>https://stackoverflow.com/questions/78772979/how-to-match-job-title-with-vacancies-name-or-vacancy-descriptions</link>
      <description><![CDATA[如何将 400 个职业与 10,000 个职位空缺进行匹配？我有两个文件：一个文件包含职业名称及其所属部门，第二个文件是来自 hh.kz 的 10,000 个职位空缺，包含职位名称及其描述。我需要将 400 个职业分配到适当的职位空缺，例如，将“高级前端开发人员”与“Web 开发人员”、“UI/UX 设计师”与“Web 设计师”等进行匹配。我已经清理和规范化了数据，使用了词嵌入，但效果不佳。我还能尝试什么？
我尝试使用关键字，但对我来说不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78772979/how-to-match-job-title-with-vacancies-name-or-vacancy-descriptions</guid>
      <pubDate>Sat, 20 Jul 2024 14:06:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们在 Unet 中使用连接？[关闭]</title>
      <link>https://stackoverflow.com/questions/78772734/why-we-use-concatenation-in-unet</link>
      <description><![CDATA[
为什么我们在 unet 中使用连接，以及我们是如何得到这些灰线的。有人可以详细解释一下吗，我是新手
我尝试了 Unet 架构，但我无法理解我们如何得到灰线，即分割图像。
有人可以解释一下这是如何工作的吗？]]></description>
      <guid>https://stackoverflow.com/questions/78772734/why-we-use-concatenation-in-unet</guid>
      <pubDate>Sat, 20 Jul 2024 12:20:56 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型分类变量热编码背后的逻辑</title>
      <link>https://stackoverflow.com/questions/78772604/logic-behind-the-categorical-variables-hot-encoding-for-machine-learning-models</link>
      <description><![CDATA[我不明白在机器学习中，对于分类变量，例如分类变量“Is_available”（具有 2 个唯一值，是和否），我们只是将“是”替换为 1，将“否”替换为 0，并且我们不对具有“是”和“否”等值的此类分类变量使用任何热编码。但对于分类变量，例如“性别”（具有 2 个唯一值男性和女性），我们使用热编码。为什么不对“Is_available”列使用热编码，为什么对“性别”列使用热编码？
这背后的逻辑是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78772604/logic-behind-the-categorical-variables-hot-encoding-for-machine-learning-models</guid>
      <pubDate>Sat, 20 Jul 2024 11:25:51 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习进行手语字母识别，结果预测错误</title>
      <link>https://stackoverflow.com/questions/78772476/sign-language-alphabet-identification-using-machine-learning-giving-wrong-predic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78772476/sign-language-alphabet-identification-using-machine-learning-giving-wrong-predic</guid>
      <pubDate>Sat, 20 Jul 2024 10:17:39 GMT</pubDate>
    </item>
    <item>
      <title>二元分类：准确率始终等于 1 [关闭]</title>
      <link>https://stackoverflow.com/questions/78771535/binary-classification-accuracy-always-equal-to-1</link>
      <description><![CDATA[为二元图像分类任务训练 CNN。然而，在验证和测试分数上，准确率始终显示为 1。不过，损失曲线并未显示过度拟合。
尝试添加类别权重来平衡类别权重。]]></description>
      <guid>https://stackoverflow.com/questions/78771535/binary-classification-accuracy-always-equal-to-1</guid>
      <pubDate>Sat, 20 Jul 2024 00:17:14 GMT</pubDate>
    </item>
    <item>
      <title>R 中的神经网络代码</title>
      <link>https://stackoverflow.com/questions/78771276/neural-network-codes-in-r</link>
      <description><![CDATA[我正在 R 中运行我的神经网络代码来处理我的生存数据。我可以运行这些代码，但我需要计算神经网络模型的指标（精度、准确度、灵敏度、特异性），并且我应该计算混淆矩阵并绘制 Roc 曲线。你能帮我根据我的代码写出这部分代码吗？
library(survival)
library(nnet)
library(readxl)
df2 &lt;- read_excel(&quot;E:/SOLMAZ/BS DATA/data BS.xlsx&quot;)
df2
# 将数据分成训练集和测试集
train.index &lt;- sample(1:nrow(df2), round(0.8*nrow(df2)))
train.data &lt;- df2[train.index,]
test.data &lt;- df2[-train.index,]

# 定义一个隐藏层的神经网络模型
nn.model&lt;- nnet(Surv(time_15year,BS_death) ~ age +sex +edu +job +place + cvahis +mihis + bphis+ heartdis + diabhis +hlphis +smok +pastsmok +pasive + activity + waterpip + cvatype, data = train.data, size = 5, maxit = 1000)

# 在测试集上生成预测
test.data$pred &lt;- predict(nn.model, newdata =test.data)
test.data$pred &lt;- ifelse(test.data$pred&gt;median(test.data$pred, na.rm = TRUE),1,0)
print(head(test.data))
table(as.factor(test.data$BS_death),as.factor(test.data$pred[,&quot;status&quot;]))
]]></description>
      <guid>https://stackoverflow.com/questions/78771276/neural-network-codes-in-r</guid>
      <pubDate>Fri, 19 Jul 2024 21:29:13 GMT</pubDate>
    </item>
    <item>
      <title>神经网络训练经过几个时期后，准确度的提高变得非常缓慢[关闭]</title>
      <link>https://stackoverflow.com/questions/78770508/accuracy-improving-gets-so-slow-after-some-epoches-in-neural-network-training</link>
      <description><![CDATA[我有大约 7000 万个样本来训练神经网络模型，准确率提高得非常顺利和快速，直到 25-30 个 epoch 左右，25-30 个 epoch 之后就变得非常慢。
例如

epoch 7：损失：5.1151 - 准确率：0.1055
epoch 18：损失：2.9058 - 准确率：0.1516
epoch 26：损失：2.9018 - 准确率：0.2466
epoch 30：损失：2.9091 - 准确率：0.2615
epoch 56：损失：2.7810 - 准确率：0.2732

是不是因为我的学习率，或者模型对于这种训练来说太简单了？
这是我的模型参数：
input_neurons = 65 
output_neurons = 4880
hidden_​​layers = 3
hidden_​​neurons = 256
epochs = 100
batch_size = 8132
learning_rate = 0.001

这是我的模型：
with strategies.scope():
# 模型
model = keras.Sequential([
keras.layers.Input(shape=(input_neurons,)),
keras.layers.Dense(hidden_​​neurons,activation=&#39;relu&#39;),
keras.layers.Dense(hidden_​​neurons,activation=&#39;relu&#39;),
keras.layers.Dense(hidden_​​neurons,activation=&#39;relu&#39;),
keras.layers.Dense(output_neurons,activation=&#39;softmax&#39;)])

optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer, loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
model.summary()

我用这个代码训练它：
def data_generator():
for x, y in dataset:
Yield x.numpy(), y.numpy()

steps_per_epoch = 69820098 // batch_size

history = model.fit(
data_generator(),
epochs=epochs,
steps_per_epoch=steps_per_epoch,
verbose=1)
]]></description>
      <guid>https://stackoverflow.com/questions/78770508/accuracy-improving-gets-so-slow-after-some-epoches-in-neural-network-training</guid>
      <pubDate>Fri, 19 Jul 2024 17:05:47 GMT</pubDate>
    </item>
    <item>
      <title>寻求将不规则 Excel 布局自动转换为结构化数据集的技术</title>
      <link>https://stackoverflow.com/questions/78768436/seeking-techniques-to-automate-transformation-of-irregular-excel-layouts-to-stru</link>
      <description><![CDATA[我面临的挑战是将不规则的 Excel 布局自动转换为结构化数据集。这些 Excel 文件通常包含：
合并单元格
分层列
注释和说明……如下所示：在此处输入图像描述
目标：
我想将这些复杂的 Excel 布局转换为计算机可以理解的结构化数据集，从而实现无缝的数据可视化和解释。
可以使用哪些技术或工具来自动化此转换过程？是否有任何机器学习模型、数据预处理技术或软件工具可以帮助标准化和结构化这些不同的 Excel 文件？]]></description>
      <guid>https://stackoverflow.com/questions/78768436/seeking-techniques-to-automate-transformation-of-irregular-excel-layouts-to-stru</guid>
      <pubDate>Fri, 19 Jul 2024 08:53:47 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音转文本和翻译（直播）</title>
      <link>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</link>
      <description><![CDATA[我有一个用例，我将在直播中录制一段演讲，并且我希望实时获得音频的文本转录，然​​后翻译该转录。
我是否需要使用 Google 的语音转文本 API，然后将生成的文本发送到翻译 API，还是可以在一行中完成？]]></description>
      <guid>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</guid>
      <pubDate>Thu, 18 Jul 2024 17:21:16 GMT</pubDate>
    </item>
    <item>
      <title>KLDivLoss 的输入是什么</title>
      <link>https://stackoverflow.com/questions/78753296/what-input-for-kldivloss</link>
      <description><![CDATA[我有一个 CNN 架构，希望使用 Kullback-Leibler 损失（来自 pytorch 的 KLDivLoss）来比较输出张量和目标张量（灰度图像）。
我有点困惑，不知道输入到损失函数的图像应该是什么格式。我理解它不应该直接是像素值，而应该是一个概率分布。
这里有一些我犹豫要不要使用的可能性，但我不确定它们是否正确：

保持图像尺寸并用其概率替换像素值（用 count(pixel_value)/total_number_of_pixels 替换每个像素值）
只需应用 softmax（但最高概率与更高的像素值相关联，这在我的例子中并不十分相关）
用大小为 256 的向量作为损失函数，其每个元素都是图像中相应像素值的概率（count(pixel_value)/total_number_of_pixels）

我的图像在 0 和 1 之间标准化。]]></description>
      <guid>https://stackoverflow.com/questions/78753296/what-input-for-kldivloss</guid>
      <pubDate>Tue, 16 Jul 2024 07:54:06 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 模型无法训练</title>
      <link>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</link>
      <description><![CDATA[我正在尝试使用深度学习来查找粒子的化学状态。作为输入，我有粒子在 X_train 中随时间的位置，形状为 (num_train,sequence_length)。 （我的序列长度为 100），输出是形状为 (num_train,1) 的 Y_train 中包含的转换帧（介于 1 和 100 之间）。
这是一个序列示例（https://i.sstatic.net/Ddmhjc24.jpg），转换位于第 84 帧。
所有数据都是用非常具体的算法生成的，但是该算法不会生成非常复杂的数据，我认为自己很容易找到转换，但我希望这个深度学习模型能够正常工作。
这是 LSTM 代码：
# 过滤

# 定义 LSTM 模型
model = Sequential([
LSTM(64, input_shape=(sequence_length, 1), return_sequences=False), Dense(64,activation=&#39;relu&#39;), Dense(1) ]) # 模型编译器 model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;) # 回归的均方误差 # 模型摘要 model.summary() # 模型模型嵌入 model.fit( X_train, Y_train, epochs=40, batch_size=32,validation_data=(X_test, Y_test)) # 新预测示例预测= model.predict(X_test) print(prediction)  结果： 模型：“sequential”
_________________________________________________________________
层（类型）输出形状参数 # 
====================================================================
lstm (LSTM) (无，64) 16896 

密集 (密集) (无，64) 4160 

密集_1 (密集) (无，1) 65 

============================================================================
总参数：21121 (82.50 KB)
可训练参数： 21121 (82.50 KB)
不可训练参数：0 (0.00 字节)
_________________________________________________________________
Epoch 1/10
631/631 [==============================] - 35s 50ms/step - 损失：1043.6710 - val_loss：840.6771
Epoch 2/10
631/631 [==============================] - 30s 48ms/step - 损失：840.9444 - val_loss：839.9596
Epoch 3/10
631/631 [===============================] - 32s 50ms/步 - 损失：841.6289 - val_loss：840.7188
Epoch 4/10
631/631 [=============================] - 30s 48ms/步 - 损失：840.9946 - val_loss：840.6344
Epoch 5/10
631/631 [===============================] - 33s 52ms/步 - 损失：841.8745 - val_loss：839.9298
Epoch 6/10
631/631 [==============================] - 31s 49ms/步 - 损失：841.6499 - val_loss：839.8434
Epoch 7/10
631/631 [=============================] - 31s 49ms/步 - 损失：841.2045 - val_loss：840.0717
Epoch 8/10
631/631 [===============================] - 30s 48ms/步 - 损失：842.0576 - val_loss： 840.2137
纪元 9/10
631/631 [=============================] - 33s 52ms/步 - 损失：842.7056 - val_loss：840.5657
纪元 10/10
631/631 [=============================] - 30s 48ms/步 - 损失：841.5714 - val_loss：839.8404
70/70 [================================] - 2s 16ms/步
[[52.569366]
[52.569286]
[52.569378]
...
[52.569344]
[52.569313]
[52.56937 ]]

如您所见，当我测试训练后的模型时，无论输入是什么，输出都是相同的。 val_loss 不会随着 epoch 数的增加而改善。这就是问题所在，我不明白发生了什么。
我反复检查了我的数据，X_train 已标准化，我尝试在模型上添加一些 drop out 和其他层，但没有任何变化。
也许使用 LSTM 无法做到这一点，但我认为数据非常简单。我真的想尝试找到一种方法来使用深度学习来找到它。]]></description>
      <guid>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</guid>
      <pubDate>Tue, 16 Jul 2024 07:31:40 GMT</pubDate>
    </item>
    <item>
      <title>无法加载可教机器模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78237621/unable-to-load-the-teachable-machine-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78237621/unable-to-load-the-teachable-machine-model</guid>
      <pubDate>Thu, 28 Mar 2024 10:51:19 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试使用数据集包创建数据集时，出现“无法转换，因为列名不匹配”错误</title>
      <link>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</link>
      <description><![CDATA[DataFrame 结构
上图显示了我的数据的结构。
from sklearn.model_selection import train_test_split
from datasets import Features, ClassLabel, Value, Dataset, DatasetDict

df_train, df_tmp = train_test_split(
movie_df,stratify=movie_df[&quot;label&quot;], test_size=0.2)

df_val, df_test = train_test_split(
df_tmp,stratify=df_tmp[&quot;label&quot;], test_size=0.5)

ds_features = Features({&quot;text&quot;: Value(&quot;string&quot;), &quot;label&quot;: ClassLabel(names=labels)})

dataset = DatasetDict({
&quot;train&quot;: Dataset.from_pandas(df_train.reset_index(drop=True),features=ds_features),
&quot;valid&quot;: Dataset.from_pandas(df_val.reset_index(drop=True),features=ds_features),
&quot;test&quot;: Dataset.from_pandas(df_test.reset_index(drop=True),features=ds_features)})

dataset

此代码给我一个值错误，如下所示：
错误
错误
我期望得到类似的东西，但值不一样：
DatasetDict({
train: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 13267
})
valid: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1658
})
test: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1659
})
})

有人能告诉我我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</guid>
      <pubDate>Wed, 13 Mar 2024 04:00:13 GMT</pubDate>
    </item>
    <item>
      <title>如何解决在训练自己的 DDSP-VST 模型的官方示例中 Google 协作的（依赖）错误？</title>
      <link>https://stackoverflow.com/questions/77216743/how-to-solve-dependency-error-on-google-collab-in-official-example-for-trainin</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77216743/how-to-solve-dependency-error-on-google-collab-in-official-example-for-trainin</guid>
      <pubDate>Mon, 02 Oct 2023 15:30:02 GMT</pubDate>
    </item>
    <item>
      <title>在 RNN 中未找到 rnn_utils 模块</title>
      <link>https://stackoverflow.com/questions/61175064/module-not-found-rnn-utils-in-rnn</link>
      <description><![CDATA[我需要使用这个库来构建我的模型，但是我遇到了这个错误。
from rnn_utils import *

没有名为“rnn_utils”的模块]]></description>
      <guid>https://stackoverflow.com/questions/61175064/module-not-found-rnn-utils-in-rnn</guid>
      <pubDate>Sun, 12 Apr 2020 17:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>