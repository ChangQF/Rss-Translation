<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 11 Aug 2024 18:21:13 GMT</lastBuildDate>
    <item>
      <title>与 Google Colab（Tesla T4）相比，我的 GPU（RTX 3070）真的那么慢吗？</title>
      <link>https://stackoverflow.com/questions/78858972/is-my-gpu-rtx-3070-that-slow-when-compared-to-google-colab-tesla-t4</link>
      <description><![CDATA[当使用我的 jupyter 笔记本和 google colab（使用完全相同的笔记本）训练同一模型时，
它们都运行相同的代码，因此它们肯定都使用“cuda”作为设备。
我的本​​地机器总训练时间：72.489 秒 |
Google Colab 总训练时间：3.115 秒
这是一个巨大的差异。以下是我机器的“nvidia-smi”输出
在此处输入图片说明
以及来自 google colab：
在此处输入图片说明
*我已重新安装并更新了完整的 pytorch 生态系统，更新了我的驱动程序和 CUDA 驱动程序。
我的机器上的 cuda 中一切都在运行，但不知何故速度很慢。在我的机器中，CPU 实际上比 GPU 更快。
BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()

train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)
train_loader = DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
train_loader, test_loader

这就是我的加载器的设置方式。
batch, labels = next(iter(train_loader))
print(f&#39;{batch.size() = }&#39;)
print(f&#39;{labels.size() = }&#39;)

在我这边加载一个批次需要 2-3 秒。而在 google colab 中速度更快。这可能是瓶颈吗？
我应该做什么吗？还是我的 GPU 真的那么糟糕？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78858972/is-my-gpu-rtx-3070-that-slow-when-compared-to-google-colab-tesla-t4</guid>
      <pubDate>Sun, 11 Aug 2024 17:29:05 GMT</pubDate>
    </item>
    <item>
      <title>如何调试不工作的 Yolov8n 模型？</title>
      <link>https://stackoverflow.com/questions/78858811/how-do-i-debug-yolov8n-model-not-working</link>
      <description><![CDATA[我正在尝试使用预先训练的 yolov8 模型进行对象检测和跟踪。我能够成功加载它，但由于某种原因，当它检测到对象时，它会随机检测到许多与图像无关的不同对象，所有对象的置信度得分均为 1.0。
这是我的代码：
from ultralytics import YOLO
import cv2

#加载 yolov8 模型
model = YOLO(&quot;yolov8n.pt&quot;)

#加载 video()
video_path = &#39;./puppy.mp4&#39;
cap = cv2.VideoCapture(video_path)

ret = True
while ret:
ret,frame = cap.read()
#从视频中返回一个新帧；如果成功读取帧，则 ret 为真，否则为假
如果不是 ret:
break
#检测对象
#跟踪对象
results = model.track(frame,persist=True) #persist= True，因此 YOLO 会记住它之前见过的帧

#绘制结果
frame_ = results[0].plot() #创建用于检测的图像
#也可以使用 cv2.rectangle 和 cv2.putText
#可视化
cv2.imshow(&#39;frame&#39;,frame_)
if cv2.waitKey(25) &amp; 0xFF==ord(&#39;q&#39;):
break

输出：
0：384x640 3 辆汽车、33 辆摩托车、21 架飞机、29 列火车、52 艘船、9 个消防栓、7 个长凳、1 个手提箱、37 个滑雪板、6 个滑雪板、1 个运动球、5 根棒球棒、8 个瓶子、1 个叉子、20 把刀、64 把勺子、1 个马桶、1 个烤面包机、1 把牙刷、329.4 毫秒
速度：4.5 毫秒预处理、329.4 毫秒推理、51.4 毫秒后处理每个形状为 (1, 3, 384, 640) 的图像

0：384x640 1 辆自行车、16 辆汽车、4 辆摩托车、13 架飞机、4公共汽车、9 列火车、9 艘船、8 个交通信号灯、1 个消防栓、10 个停车标志、2 张长椅、3 只羊、2 头牛、1 把雨伞、2 个飞盘、2 根棒球棒、1 副棒球手套、5 支网球拍、2 把刀、2 把勺子、1 根胡萝卜、3 个热狗、5 个披萨、1 个甜甜圈、1 张沙发、1 张床、476.8 毫秒
速度：9.3 毫秒预处理、476.8 毫秒推理、0.0 毫秒后处理每个形状为 (1, 3, 384, 640) 的图像

0：384x640 1 个人、7 辆汽车、3 辆摩托车、20 架飞机、1 辆公共汽车、7 列火车、44 艘船、2 个消防栓、5 个停车标志、3 个停车计费表、2 只鸟、3 头牛、2大象、1 只熊、4 把雨伞、1 个手提包、1 个飞盘、1 把刀、4 把勺子、2 个苹果、1 个胡萝卜、1 个热狗、1 个披萨、1 个蛋糕、1 张餐桌、651.2 毫秒
速度：15.5 毫秒预处理、651.2 毫秒推理、15.8 毫秒后处理每个形状为 (1、3、384、640) 的图像

0：384x640 7 个人、3 辆汽车、1 辆摩托车、2 列火车、13 艘船、2 个交通信号灯、2 个消防栓、54 个停车标志、2 个停车计费表、2 只猫、4 只狗、1 头牛、18 只熊、1 匹斑马、15 只长颈鹿、11 把雨伞、14 个手提包、6 条领带、1 个飞盘、1 个滑雪板、1 个运动球、 5 个棒球手套、4 个酒杯、1 把叉子、1 把刀、1 把勺子、1 个苹果、1 个橙子、1 根胡萝卜、2 个披萨、1 张餐桌、2 台笔记本电脑、1 部手机、1 个水槽、1 个吹风机、656.2 毫秒
速度：0.0 毫秒预处理、656.2 毫秒推理、66.9 毫秒后处理每个形状为 (1, 3, 384, 640) 的图像

0：384x640 20 艘船、8 张长凳、5 只猫、4 个手提箱、48 个飞盘、3 个滑板、20 个碗、1 张沙发、26 张床、37 台笔记本电脑、1 个鼠标、15 个遥控器、30 部手机、27 本书、1057.5 毫秒
速度：15.7 毫秒预处理、1057.5 毫秒推理，形状为 (1, 3, 384, 640) 时每幅图像的后处理时间为 55.0ms

如您所见，当视频中只有一条狗时，它检测到了许多随机物体。
这是我第一次使用 yolo，我是计算机视觉领域的新手。
我也尝试使用终端使用 yolov8n 进行预测，但它仍然检测到许多不同的物体，置信度均为 1.0。
这是我在 CLI 中输入的内容：
 yolo predict model=yolov8n.pt source=&#39;https://ultralytics.com/images/bus.jpg&#39;
输出：
Ultralytics YOLOv8.2.75 🚀 Python-3.12.3 torch-2.4.0+cpu CPU（第 11 代 Intel Core(TM) i5-1145G7 2.60GHz）
YOLOv8n 摘要（融合）：168 层、3,151,904 个参数、0 个梯度、8.7 GFLOP

将 https://ultralytics.com/images/bus.jpg 下载到&#39;bus.jpg&#39;...
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 134k/134k [00:00&lt;00:00，8.86MB/s]
图像 1/1 C:\Users\aksha\OneDrive\Documents\Computer_Vision\tutorial_detect\bus.jpg：640x480 79 人、3 辆自行车、46 辆汽车、46 辆摩托车、15 架飞机、11 辆公共汽车、5 列火车、28 辆卡车、49 艘船、4 个消防栓、2 个停车计费表、2 个运动球、6 个瓶子、4 把勺子、324.2ms
速度：15.6ms 预处理、324.2ms 推理、27.8ms 后处理，形状为 (1, 3, 640, 480)，每幅图像
结果保存到 runs\detect\predict
💡 了解更多信息https://docs.ultralytics.com/modes/predict

我的 ultralytics、torch 和 np 版本如下：
8.2.75 - ultralytics
2.4.0+cpu - torch
1.26.4 - numpy
我不确定问题是什么；我尝试卸载并重新安装 ultralytics 两次，但问题没有解决。]]></description>
      <guid>https://stackoverflow.com/questions/78858811/how-do-i-debug-yolov8n-model-not-working</guid>
      <pubDate>Sun, 11 Aug 2024 16:25:30 GMT</pubDate>
    </item>
    <item>
      <title>纪元 1/3 ^C（model.fit() 以此行终止且没有任何错误）</title>
      <link>https://stackoverflow.com/questions/78858484/epoch-1-3-c-model-fit-was-terminate-with-this-line-and-without-any-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78858484/epoch-1-3-c-model-fit-was-terminate-with-this-line-and-without-any-error</guid>
      <pubDate>Sun, 11 Aug 2024 13:47:36 GMT</pubDate>
    </item>
    <item>
      <title>获取 ValueError：所有数组的长度必须相同</title>
      <link>https://stackoverflow.com/questions/78858321/getting-valueerror-all-arrays-must-be-of-the-same-length</link>
      <description><![CDATA[我一直试图将字典转换为数据框，但每次我都收到 ValueError：所有数组的长度必须相同。我已经检查了每个数组的长度并确认它们相同，但我仍然收到相同的错误
def metrics_from_pipes(pipes_dict):
for name, pipeline in pipes_dict.items():

pipeline.fit(X_train, y_train)
y_pred_val = pipeline.predict(X_val)
y_pred_train = pipeline.predict(X_train)

train_metrics = {
&#39;model&#39;:list(pipes_dict.keys()),
&#39;MAE&#39;:train_mae,
&#39;MAPE&#39;:train_mape,
&#39;RMSE&#39;:train_rmse,
&#39;RSquared&#39;:train_rsquared
}

train_metrics_data = pd.DataFrame(train_metrics)
val_metrics = {
&#39;model&#39;:list(pipes_dict.keys()),
&#39;MAE&#39;:val_mae,
&#39;MAPE&#39;:val_mape,
&#39;RMSE&#39;:val_rmse,
&#39;RSquared&#39;:val_rsquared 
}

val_metrics_data = pd.DataFrame(val_metrics,)

# 合并来自训练集和测试集的指标
train_val_metrics = train_metrics_data.merge(val_metrics_data,
on = &#39;Model&#39;,
how = &#39;left&#39;,
suffixes = (&#39;_train&#39;, &#39;_val&#39;))

# 排序列 
train_val_metrics = train_val_metrics.reindex(columns = [&#39;Model&#39;,
&#39;MAE_train&#39;,
&#39;MAPE_train&#39;,
&#39;RMSE_train&#39;,
&#39;RSquared_train&#39;,
&#39;MAE_val&#39;,
&#39;MAPE_val&#39;,
&#39;RMSE_val&#39;,
&#39;RSquared_val&#39;])

return train_val_metrics.set_index(&#39;Model&#39;).transpose()

# 获取指标表
metrics_table = metrics_from_pipes(pipelines)

运行此代码会出现此错误
ValueError Traceback (most recent call last)
Cell In[45]，第 82 行
80 return train_val_metrics.set_index(&#39;Model&#39;).transpose()
81 # 获取指标表
---&gt; 82 metrics_table = metrics_from_pipes(pipelines)
83 #print(&#39;表 1：基本模型指标&#39;)
84 #metrics_table.style.background_gradient(cmap = Blues)
85 metrics_table

单元格 In[45]，第 50 行，位于 metrics_from_pipes(pipes_dict)
41 # 将性能指标列表聚合到单独的数据框中
42 train_metrics = {
43 &#39;model&#39;:list(pipes_dict.keys()),
44 &#39;MAE&#39;:train_mae,
(...)
47 &#39;RSquared&#39;:train_rsquared
48 }
---&gt; 50 train_metrics_data = pd.DataFrame(train_metrics)
51 val_metrics = {
52 &#39;model&#39;:list(pipes_dict.keys()),
53 &#39;MAE&#39;:val_mae,
(...)
56 &#39;RSquared&#39;:val_rsquared 
57 }
59 val_metrics_data = pd.DataFrame(val_metrics,)

ValueError: 所有数组的长度必须相同

当我检查 train_metrics 和 val 指标的字典结果时，我得到了这个
({&#39;model&#39;: [&#39;Linear Regression&#39;,
&#39;Random Forest Regressor&#39;,
&#39;Gradient Boost Regression&#39;,
&#39;Extra Tree Regressor&#39;],
&#39;MAE&#39;: [829.1023412412194,
288.33455697065233,
712.9637267872279,
0.0010629575741748962],
&#39;MAPE&#39;: [1.0302372135902111,
0.20937541440883897,
0.538244903316323,
6.306697580961048e-07],
&#39;RMSE&#39;: [1120.5542708017374,
416.48933196590013,
1012.399201767692,
0.05804079289490426],
&#39;RSquared&#39;: [0.5598288286601083,
0.9391916010838417,
0.6406981997919169,
0.9999999988190745]},
{&#39;model&#39;: [&#39;线性回归&#39;,
&#39;随机森林回归器&#39;,
&#39;梯度提升回归&#39;,
&#39;额外树回归器&#39;],
&#39;MAE&#39;: [855.9254413559535,
802.5902302175274,
772.3140648475379,
839.9018341377154],
&#39;MAPE&#39;: [1.0395487579496652,
0.5607987708065988,
0.5438627253681279,
0.5852285872937784],
&#39;RMSE&#39;: [1148.6549900167981,
1158.8411708570625,
1109.6145558003204,
1223.23337689915],
&#39;RSquared&#39;: [0.5876710102285392,
0.5803255834810521,
0.6152231339508221,
0.5323905190373128]})
]]></description>
      <guid>https://stackoverflow.com/questions/78858321/getting-valueerror-all-arrays-must-be-of-the-same-length</guid>
      <pubDate>Sun, 11 Aug 2024 12:27:40 GMT</pubDate>
    </item>
    <item>
      <title>批量数据的 SGD 优化器设置</title>
      <link>https://stackoverflow.com/questions/78858189/sgd-optimizer-setting-for-batched-data</link>
      <description><![CDATA[我正在学习 Joh Krohn 的数学入门课程。课程解释得很清楚，但有一件事让我很困惑。在这个任务中 https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/regression-in-pytorch.ipynb，我们使用了 torch.optim.SGD torch SGD，它运行了所有示例数据。
optimizer = torch.optim.SGD([m,b], lr = 0.01)
epochs = 999
for epoch in range(epochs): 

optimizer.zero_grad() # 将梯度重置为零；否则它们会累积

yhats = 回归（xs，m，b）# 步骤 1
C = mse（yhats，ys）# 步骤 2

C.backward() # 步骤 3

optimizer.step() # 步骤 4

在第二个练习中，我们进行了学习率调度 https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/learning-rate-scheduling.ipynb
有 8.000.000 个数据点，因此数据被设置为批处理，并且代码在这些样本上轮流运行，而不是在所有数据上按时期运行。然而，这不是用 torch.optim.SGD 完成的，而是在代码上显示以查看数学是如何工作的。我正在努力用 torch.optim.SGD 运行它。如何编写代码来运行它，而不是像下面这样编写大型数学方程式，其中已经创建了所有方程式，例如梯度、theta：
n = 8000000
x = torch.linspace(0., 8., n)
y = -0.5*x + 2 + torch.normal(mean=torch.zeros(n), std=1)
indices = np.random.choice(n, size=2000, replace=False)
gradient = torch.tensor([[b.grad.item(), m.grad.item()]]).T
theta = torch.tensor([[b, m]]).T 
lr = 0.01
new_theta = theta - lr*gradient
C = mse(regression(x[batch_indices], m, b), y[batch_indices])
b.requires_grad_()
m.requires_grad_()

def return(my_x, my_m, my_b):
return my_m*my_x + my_b

m = torch.tensor([0.9]).requires_grad_()
b = torch.tensor([0.1]).requires_grad_()

batch_size = 32 # 模型超参数
batch_indices = np.random.choice(n, size=batch_size, replace=False)
yhat = return(x[batch_indices], m, b)

yhat = return(x[batch_indices], m, b)

def mse(my_yhat, my_y): 
sigma = torch.sum((my_yhat - my_y)**2)
return sigma/len(my_y)

C = mse(yhat, y[batch_indices])

C.backward()
m.grad
b.grad

gradient = torch.tensor([[b.grad.item(), m.grad.item()]]).T

theta = torch.tensor([[b, m]]).T 

lr = 0.01
new_theta = theta - lr*gradient
new_theta

b = new_theta[0]
m = new_theta[1]

C = mse(regression(x[batch_indices], m, b), y[batch_indices])

rounds = 100 

for r in range(rounds): 

# 这个采样步骤很慢；稍后我们将介绍更快的批量采样： 
batch_indices = np.random.choice(n, size=batch_size, replace=False)

yhat = return(x[batch_indices], m, b) # 步骤 1
C = mse(yhat, y[batch_indices]) # 步骤 2

C.backward() # 步骤 3

gradient = torch.tensor([[b.grad.item(), m.grad.item()]]).T
theta = torch.tensor([[b, m]]).T 

new_theta = theta - lr*gradient # 步骤 4

b = new_theta[0].requires_grad_()
m = new_theta[1].requires_grad_()
]]></description>
      <guid>https://stackoverflow.com/questions/78858189/sgd-optimizer-setting-for-batched-data</guid>
      <pubDate>Sun, 11 Aug 2024 11:20:48 GMT</pubDate>
    </item>
    <item>
      <title>解决自动标记（优化）+分类问题</title>
      <link>https://stackoverflow.com/questions/78858155/tackling-an-automatic-labeling-optimization-classification-problem</link>
      <description><![CDATA[我知道这不太侧重于编程，但我不知道还有什么地方可以问这个问题。这更多的是关于方法而不是技术问题。
上下文
我有一个优化 + 分类任务。因此，本质上，我的数据具有以下列：
[&#39;Model ID&#39;, &#39;Q&#39;, &#39;refinement&#39;, &#39;avg_time&#39;, &#39;lattice&#39;, &#39;radius&#39;]（还有更多，但为了简洁起见，我们只保留这些）

Model ID：代表“设计”，每个 Model ID 将有多行

Q：这是目标变量

refinement：这是一个设置变量；它可以取 1-8 的值，这直接影响 Q，（模型 ID，细化）对是唯一的。因此，模型 ID 将具有多行，细化程度各不相同

avg_time：这是模拟完成所需的时间，仅受细化的影响，细化程度越高，所需的时间越长。此值与设计无关，它仅取决于细化，因此特定细化的所有设计都具有相同的时间。

lattice 和 radius：这些代表“设计”，本质上更改它们将更改 Q


数据集
我的数据集来自随机设计的模拟。对于每个设计，我们可以有以下行为：

持续增加（每次细化时的 Q 值高于上一个细化级别）
持续减少（每次细化时的 Q 值低于上一个细化级别）
之字形，其中 Q 值遵循此当前模式（高，低，高，低）或（低，高，低，高）
碗形，其中 Q 值遵循此当前模式：（高，低，低，高）
梯形，其中 Q 值遵循此当前模式：（低，高，高，低）
我有代码可以检测这些形状并返回布尔值：

def is_zigzag(q_values)

def is_bowl(q_values)

def is_trapezoid(q_values)

数据集中细化的值范围是 2-5，但细化可以取 1-8 的值。
任务
因此，我试图实现的是自动标记每个模型 ID（通过对行进行分组）和最佳细化值（范围为 1-8），以最大化 Q 的变化（增量越大越好）并最小化所花费的时间（越低越好）。问题是由于数据是在细化级别 5 处切割的，所以我想到使用概率方法（例如 MLE）来创建未来细化的预期变化和预期所花费的时间。但我似乎无法“调整”它，所以它很有用。获得预期值后，我需要一个成本函数来计算（优化）Q 的回报与完成该细化级别所花费的增加时间的比较。
在下一部分中，我将开发一个分类器，它将采用设计和最佳细化。从理论上讲，它应该可以预测未见过的设计的最佳细化级别
我很感激任何有关解决这个问题的指导/帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78858155/tackling-an-automatic-labeling-optimization-classification-problem</guid>
      <pubDate>Sun, 11 Aug 2024 11:01:40 GMT</pubDate>
    </item>
    <item>
      <title>处理缺失数据并建立具有不完整信息的预测模型？</title>
      <link>https://stackoverflow.com/questions/78858124/handling-missing-data-and-building-a-predictive-model-with-incomplete-informatio</link>
      <description><![CDATA[我正在为涉及 20 个影响点的供水网络开发一个预测模型。但是，我只有这 20 个点中的 10 个的历史数据。
我想知道如何在这个不完整的数据集下构建预测模型。具体来说：
我可以使用哪些方法来处理剩余 10 个点的缺失数据？在这种情况下，是否有任何标准技术或最佳实践来处理缺失数据？
我如何有效地将我拥有的 10 个点的数据合并到模型中？我可以采用哪些策略来确保有效利用可用数据进行准确预测？
是否有特定的技术或模型可以帮助在数据不完整的情况下进行预测？我对可以有效管理和利用不完整数据的方法感兴趣。
&quot;我还没有具体的方法。&quot;]]></description>
      <guid>https://stackoverflow.com/questions/78858124/handling-missing-data-and-building-a-predictive-model-with-incomplete-informatio</guid>
      <pubDate>Sun, 11 Aug 2024 10:43:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 hub.KerasLayer 使用 tf.keras.sequential 制作深度学习模型时出错</title>
      <link>https://stackoverflow.com/questions/78857786/error-when-using-hub-keraslayer-using-tf-keras-sequential-to-make-deep-learning</link>
      <description><![CDATA[我是刚开始使用 keras 的，这里我遇到了一些问题：
创建一个构建 Keras 模型的函数
def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):
print(&quot;Building model with:&quot;, MODEL_URL)

model = tf.keras.Sequential([
hub.KerasLayer(MODEL_URL), # 第 1 层（输入层）
tf.keras.layers.Dense(units=OUTPUT_SHAPE, 
activation=&quot;softmax&quot;) # 第 2 层（输出层）
])

# 编译模型
model.compile(
loss=tf.keras.losses.CategoricalCrossentropy(), # 我们的模型想要减少这个（它的猜测有多错误）
optimizer=tf.keras.optimizers.Adam()，# 一个朋友告诉我们的模型如何改进它的猜测
metrics=[&quot;accuracy&quot;] # 我们希望这个数字上升
)

# 构建模型
model.build(INPUT_SHAPE) # 让模型知道它将获得什么样的输入

返回模型

我有上面的函数，当我运行下面的其他程序时
model = create_model()
model.summary()

它会产生一些错误
TypeError：添加的层必须是 Layer 类的实例。收到：layer= 类型为 &lt;class &#39;keras.src.layers.core.dense.Dense&#39;&gt;。
所以我错了什么，我一直在搜索这个，但问题和我得到的不一样]]></description>
      <guid>https://stackoverflow.com/questions/78857786/error-when-using-hub-keraslayer-using-tf-keras-sequential-to-make-deep-learning</guid>
      <pubDate>Sun, 11 Aug 2024 08:05:45 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 CV-k 折叠预测“是”“否”的均方误差？[关闭]</title>
      <link>https://stackoverflow.com/questions/78857561/how-to-calculate-mean-square-error-for-predictions-yes-no-with-a-cv-k-fold</link>
      <description><![CDATA[为了根据满意度指数和参与度指数预测客户是否会购买产品，我们使用了 k 近邻法。
如何用 4 倍交叉验证过程评估预测均方误差？它不需要在 R 中。我只需要如何计算它的理论。
我知道如何用数字计算，但不知道如何用字符串计算]]></description>
      <guid>https://stackoverflow.com/questions/78857561/how-to-calculate-mean-square-error-for-predictions-yes-no-with-a-cv-k-fold</guid>
      <pubDate>Sun, 11 Aug 2024 05:16:27 GMT</pubDate>
    </item>
    <item>
      <title>如何提高 SGDRegressor 模型性能</title>
      <link>https://stackoverflow.com/questions/78857401/how-to-improve-sgdregressor-model-performance</link>
      <description><![CDATA[我正在做一个个人项目，比较 OLS 模型和 SGDRessor 模型之间的模型性能。OLS 模型并不完美，但运行良好。SGDR 模型预测偏差很大。我检查了迭代过程中的成本降低情况。结果表明学习率太高。然而，降低学习率似乎会使成本降低变得更糟。
我是机器学习的新手，我不知道如何改进 SGDR 模型。任何建议都将不胜感激。
这是我的代码：Google Colab 链接。您可以重点关注“梯度下降方法”部分和“排除 SGDR 故障”。
提前感谢您的时间和帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78857401/how-to-improve-sgdregressor-model-performance</guid>
      <pubDate>Sun, 11 Aug 2024 02:34:35 GMT</pubDate>
    </item>
    <item>
      <title>TensorBoard 中的 add_hparams() 函数无法正常工作</title>
      <link>https://stackoverflow.com/questions/78857269/add-hparams-function-from-tensorboard-doesnt-work-properly</link>
      <description><![CDATA[我试图向此 SummaryWriter 添加指标，但不起作用。
我正在使用 SummaryWriter 的 add_hparams() 函数，其详细信息可在此处找到：https://pytorch.org/docs/stable/tensorboard.html。
我这样做：
 writer = SummaryWriter(f&#39;runs/lstm_experiment_final&#39;)

for e in tqdm(range(num_epochs)):
tr_loss, tr_f1, tr_precision, tr_recall = training_loop(model, train_dataloader, loss_function, optimizer, e, writer)
val_loss, val_f1, val_precision, val_recall = validation_loop(model, test_dataloader, loss_function, e, writer)

metric_dict = {&#39;Loss/train&#39;: tr_loss, &#39;Loss/valid&#39;: val_loss,
&#39;F1/train&#39;: tr_f1, &#39;F1/valid&#39;: val_f1,
&#39;Precision/train&#39;: tr_precision, &#39;Precision/valid&#39;: val_precision,
&#39;Recall/train&#39;: tr_recall, &#39;Recall/valid&#39;: val_recall}
writer.add_hparams(best_params, metric_dict, global_step=num_epochs-1)
writer.close()

这就是正在发生的事情。
在此处输入图片描述
换句话说，超参数确实记录在 TensorBoard 上，但度量值却没有记录。
我希望有人已经看到我的问题并知道如何解决这个问题。
提前谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78857269/add-hparams-function-from-tensorboard-doesnt-work-properly</guid>
      <pubDate>Sun, 11 Aug 2024 00:21:56 GMT</pubDate>
    </item>
    <item>
      <title>启用 GPU 2024-OSError：[WinError 127] 找不到指定的过程</title>
      <link>https://stackoverflow.com/questions/78856582/enable-gpu-2024-oserror-winerror-127-the-specified-procedure-could-not-be-fo</link>
      <description><![CDATA[我正在尝试启用 GPU 进行机器学习，但遇到了这个问题：

OSError：[WinError 127] 找不到指定的程序。错误
加载
“C:\Users\name\anaconda3\Lib\site-packages\torch\lib\c10_cuda.dll”
或其依赖项之一。

目前，我正在使用配备 NVIDIA 3050 GPU 的 Windows 笔记本电脑，以 Python 作为我的主要开发语言。

注意到该文件存在，因为 torch 库是使用 pip 直接下载的。因此，从技术上讲，此错误不应该发生。

最初，我收到了类似的错误“[WinError 126] 找不到指定的过程。”但我已经更新并安装了 VisualStudio 2022 的 C/C++ 编译器，它解决了 [WinError 126}，但我得到的却是 [WinError 127]。
要安装和启用 GPU，我将按照此教程执行以下步骤。

安装 VisualStudio -&gt; 全部下载

安装 Pytorch (pip) -&gt; CUDA 12.4

安装 CUDA 工具包 (12.6)

下载 cuDNN“下载 cuDNN v8.9.7 (2023 年 12 月 5 日)，适用于 CUDA 12.x”

将 cuDNN 的内容按照各自的文件夹名称粘贴到“NVIDIA GPU 计算工具包”中。


已验证已安装的 CUDA 已添加到环境中

我也按照这个最近更新的视频的建议下载 C/C++ 编译器。然而，这并没有解决我的问题。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78856582/enable-gpu-2024-oserror-winerror-127-the-specified-procedure-could-not-be-fo</guid>
      <pubDate>Sat, 10 Aug 2024 16:59:08 GMT</pubDate>
    </item>
    <item>
      <title>在扩展中访问 NetLogo 扩展</title>
      <link>https://stackoverflow.com/questions/78851057/accessing-netlogo-extensions-within-an-extension</link>
      <description><![CDATA[我正在尝试开发一个 NetLogo 扩展来与不同的 LLMS（在线、离线）进行通信。LLM 调用返回 JSON 格式的字符串。我想解析 JSON 并将其转换为嵌套的 TABLE 对象，以访问 NetLogo Table 扩展。
是否有办法让一个扩展访问和使用另一个扩展中的类？]]></description>
      <guid>https://stackoverflow.com/questions/78851057/accessing-netlogo-extensions-within-an-extension</guid>
      <pubDate>Fri, 09 Aug 2024 03:21:02 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量</title>
      <link>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</link>
      <description><![CDATA[我无法加载我的模型，它一直显示错误
ValueError：层“dense_2”需要 1 个输入，但它收到了 2 个输入张量。收到的输入：[&lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2896&gt;, &lt;KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2897&gt;]
这是我的代码
image_generator = ImageDataGenerator(
rescale=1./255,
rotation_range=20,
zoom_range=0.2,
width_shift_range=0.2,
height_shift_range=0.2,
Horizo​​ntal_flip=True,
validation_split=0.2
)

train_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;training&#39;
)

validation_dataset = image_generator.flow_from_directory(
directory=path_to_dataset,
target_size=(224, 224),
batch_size=32,
subset=&#39;validation&#39;
)

# 加载数据集中子文件夹中的 (num_classes) 类
num_classes = len(train_dataset.class_indices)

from tensorflow.keras.applications.mobilenet import MobileNet

# 加载 MobileNet 模型
pre_trained_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),
include_top=False,
weights=&#39;imagenet&#39;)

pre_trained_model.summary()

# 打印数据集信息以供调试
print(f&quot;训练数据集形状：{train_dataset.image_shape}&quot;)
print(f&quot;验证数据集形状：{validation_dataset.image_shape}&quot;)

pre_trained_model.trainable = False

# 为预训练模型添加自定义层
model = tf.keras.Sequential([
pre_trained_model,
tf.keras.layers.GlobalAveragePooling2D(),
tf.keras.layers.Dense(1024,activation=&#39;relu&#39;),
tf.keras.layers.Dropout(0.5),
tf.keras.layers.Dense(num_classes,activation=&#39;softmax&#39;) 
])

# 编译模型
#from tensorflow.keras.optimizers import RMSprop
model.compile(optimizer=Adam(learning_rate=0.0001),
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

batch=40
history = model.fit(train_dataset,
validation_data=validation_dataset,
epochs=20,
steps_per_epoch = train_dataset.samples//batch,
validation_steps =validation_dataset.samples//batch,
verbose = 1
)

# 加载模型
model_save_path = &#39;/content/drive/MyDrive/Machine Learning/saved_models/model_plastik.h5&#39;

# 加载模型，确保必要时已编译
loaded_model = tf.keras.models.load_model(model_save_path) 

# 现在您可以根据需要修改已加载的模型
# 例如，如果您想提取子模型：
input_layer_index = 0 # 替换为实际索引
dense_2_index = 3 # 替换为实际索引
loaded_model = tf.keras.models.Model(inputs=loaded_model.layers[input_layer_index].input, 
outputs=loaded_model.layers[dense_2_index].output)

# 检查已加载模型的配置
for i, layer in enumerate(loaded_model.layers):
print(f&quot;Layer {i}: {layer.name} - 输入形状：{layer.input_shape} - 输出形状：{layer.output_shape}&quot;)

print(&quot;已成功加载修订模型。&quot;)

我尝试加载模型，并希望它能够加载以进行测试]]></description>
      <guid>https://stackoverflow.com/questions/78846949/valueerror-layer-dense-2-expects-1-inputs-but-it-received-2-input-tensors</guid>
      <pubDate>Thu, 08 Aug 2024 07:06:54 GMT</pubDate>
    </item>
    <item>
      <title>将自定义模型和配置注册到 AutoModel 和 AutoConfig</title>
      <link>https://stackoverflow.com/questions/77428197/registering-custom-model-and-config-to-automodel-and-autoconfig</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77428197/registering-custom-model-and-config-to-automodel-and-autoconfig</guid>
      <pubDate>Mon, 06 Nov 2023 00:48:18 GMT</pubDate>
    </item>
    </channel>
</rss>