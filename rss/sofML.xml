<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 04 Apr 2024 09:14:19 GMT</lastBuildDate>
    <item>
      <title>为什么 LSTM 对非序列时间序列数据集的准确率达到 90%</title>
      <link>https://stackoverflow.com/questions/78272446/why-lstm-is-giving-90-accuracy-for-non-sequential-time-series-dataset</link>
      <description><![CDATA[我目前正在研究时间序列分类。
为此我使用了 LSTM 模型。我以非顺序时间序列数据集的形式提供输入，这给了我 90% 的准确度。然而这是错误的方法，所以我给出了顺序时间序列数据集，结果准确率为 64%。
实际上，我预计准确度为 64-67%，因为存在一些重叠的时间序列数据点。但我的疑问是为什么非顺序时间序列的准确率达到 90%。
预计准确度为 64-67%]]></description>
      <guid>https://stackoverflow.com/questions/78272446/why-lstm-is-giving-90-accuracy-for-non-sequential-time-series-dataset</guid>
      <pubDate>Thu, 04 Apr 2024 07:50:02 GMT</pubDate>
    </item>
    <item>
      <title>我以 h5 格式单独保存了年龄、性别和情绪预测模型。有谁知道如何将它们组合在一起以供实时使用？</title>
      <link>https://stackoverflow.com/questions/78271808/i-have-separate-saved-models-for-age-gender-and-emotion-prediction-in-h5-format</link>
      <description><![CDATA[我创建了年龄、性别和情绪预测模型，并将它们保存为 h5 格式。
我将它们组合在一起来预测输出，但用于自定义输入。我无法将它们组合起来进行实时预测。]]></description>
      <guid>https://stackoverflow.com/questions/78271808/i-have-separate-saved-models-for-age-gender-and-emotion-prediction-in-h5-format</guid>
      <pubDate>Thu, 04 Apr 2024 05:17:49 GMT</pubDate>
    </item>
    <item>
      <title>/workspace/src/data/data.cc:501: 检查失败: this->labels.Size() % this->num_row_ == 0 (712 vs. 0) : 标签大小不正确</title>
      <link>https://stackoverflow.com/questions/78271393/workspace-src-data-data-cc501-check-failed-this-labels-size-this-num-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78271393/workspace-src-data-data-cc501-check-failed-this-labels-size-this-num-r</guid>
      <pubDate>Thu, 04 Apr 2024 02:48:24 GMT</pubDate>
    </item>
    <item>
      <title>CNN ValueError：由于下采样，输出中的维度之一 <= 0</title>
      <link>https://stackoverflow.com/questions/78271160/cnn-valueerror-one-of-the-dimensions-in-the-output-is-0-due-to-downsampling</link>
      <description><![CDATA[我正在制作一个深度学习模型来预测一个值。声明如下：我们有一个
时间 vs A vs B vs C -- xls 文件（多个，存在于 Data 命名文件夹中）
我想使用 A、B、C 的先前值来预测 A。这 ofc 意味着当它是第一个预测时，我们将得到 N/A，因为我们没有旧的 A 给用户。
目前我有这个：（我真的是新手，到处都在网上搜索）：
def load_data(folder_path):
    数据帧 = []
    对于 os.listdir(folder_path) 中的 file_name：
        if file_name.endswith(&#39;.xls&#39;):
            file_path = os.path.join(文件夹路径, 文件名)
            df = pd.read_excel(file_path) # 假设数据是Excel格式
            data_frames.append(df)
    返回 pd.concat(data_frames,ignore_index=True)

def preprocess_data(数据):
    X = 数据[[&#39;S&#39;, &#39;A&#39;, &#39;T&#39;]]
    y = 数据[&#39;F&#39;]
    定标器=标准定标器()
    X_scaled = 缩放器.fit_transform(X)
    X_reshape = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1) # CNN 重塑
    返回 X_reshape, y, 缩放器


def build_cnn_model(input_shape):
    模型=顺序（）
    model.add(Conv1D(filters=1, kernel_size=10, 激活=&#39;relu&#39;, input_shape=(1, 1,3),))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Conv1D(filters=64, kernel_size=3,activation=&#39;relu&#39;))
    model.add(MaxPooling1D(pool_size=2))
    模型.add(压平())
    model.add（密集（64，激活=&#39;relu&#39;））
    model.add(密集(1))
    返回模型



def train_and_predict_next_Frequency(folder_path, current_scheduled, current_actual):
    数据=加载数据（文件夹路径）

    X、y、缩放器 = preprocess_data(数据)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    输入形状 = (X_train.shape[1], 1)
    X_train_reshape = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
    X_test_reshape = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

    打印（输入形状）
    模型 = build_cnn_model(input_shape)

    model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

    model.fit（X_train_reshape，y_train，epochs = 50，batch_size = 32，verbose = 1）

    mse = model.evaluate(X_test_reshape, y_test, verbose=0)
    print(&quot;均方误差：&quot;, mse)

    scaled_input = scaler.transform([[current_scheduled, current_actual]])
    input_reshape =scaled_input.reshape(1, 2, 1) # CNN 重塑
    next_Frequency_scaled = model.predict(input_reshape)
    next_Frequency =scaler.inverse_transform(next_Frequency_scaled.reshape(-1, 1))
    返回下一个频率[0][0]



文件夹路径=“数据” # 包含 Excel 文件的文件夹
当前计划 = 10
当前实际 = 8
预测频率 = train_and_predict_next_Frequency(folder_path, current_scheduled, current_actual)
print(“预测的下一个频率：”,predicted_Frequency)

我在这里收到此错误：
ValueError：由于 conv1d_10 中的下采样，输出中的维度之一 &lt;= 0。
考虑增加输入大小。收到的输入形状 [None, 1, 1, 3] 会产生
维度中具有零值或负值的输出形状。

使用 A、B、C 的先前值来预测A。 （上一个是什么？，我们有时间来告诉它）。
我尝试更改图层功能，但没有成功。我想实现上述目标]]></description>
      <guid>https://stackoverflow.com/questions/78271160/cnn-valueerror-one-of-the-dimensions-in-the-output-is-0-due-to-downsampling</guid>
      <pubDate>Thu, 04 Apr 2024 01:02:37 GMT</pubDate>
    </item>
    <item>
      <title>用10000条数据训练神经网络，运行无误；但是当有10000000条数据时，就会出现错误，为什么？</title>
      <link>https://stackoverflow.com/questions/78271142/training-a-neural-network-with-10000-data-it-runs-without-error-but-with-10000</link>
      <description><![CDATA[运行时错误：无法在需要 grad 的张量上调用 numpy()。请改用tensor.detach().numpy()。
这个错误指的是下面这句话
&lt;块引用&gt;

输出=并行(n_jobs=arg.sim.jobs)(延迟(parfun)(i) for i in tqdm.tqdm(range(arg.sim.n_ensemble),position=0,leave=True))
段落中
&lt;块引用&gt;
如果arg.sim.n_ensemble&gt;1：

 #用多个进程训练网络并预测参数
            如果 arg.sim.jobs&gt;1：
                def parfun(i):
                    net = deep.learn_ML(ML_signal_noisy, arg.sim.bvalues, arg)
                    返回 deep.predict_ML(ML_signal_noisy[:arg.sim.num_samples_eval, :], arg.sim.bvalues, net, arg)
                输出=并行(n_jobs=arg.sim.jobs)(延迟(parfun)(i) for i in tqdm.tqdm(range(arg.sim.n_ensemble),position=0,leave=True))
                对于范围内的 bb(arg.sim.n_ensemble)：
                    paramsNN[aa,bb] = 输出[bb]
            #用一个过程训练网络并预测参数

几天前，我用数据训练了一个神经网络（NN），其中包含 10000 个数字。神经网络运行没有错误，但结果很差。
然后我将数据增加到 10000000 个数字，期望结果会更好，但是神经网络在没有明确 numpy 的情况下在句子中显示了错误。]]></description>
      <guid>https://stackoverflow.com/questions/78271142/training-a-neural-network-with-10000-data-it-runs-without-error-but-with-10000</guid>
      <pubDate>Thu, 04 Apr 2024 00:56:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 TensorFlow 中使用 model.fit() 会出现 ValueError: Unrecognized data type: x=[...] (of type <class 'list'>) 错误？</title>
      <link>https://stackoverflow.com/questions/78271090/why-do-i-get-valueerror-unrecognized-data-type-x-of-type-class-list</link>
      <description><![CDATA[我尝试运行下面的代码，取自  CS50的AI课程：
导入 csv
将张量流导入为 tf
从 sklearn.model_selection 导入 train_test_split

# 从文件中读取数据
open(“banknotes.csv”) 作为 f：
    读者 = csv.reader(f)
    下一个（读者）

    数据 = []
    对于读卡器中的行：
        数据.追加（
            {
                “证据”：[行[:4]中单元格的浮点（单元格）]，
                “标签”：如果 row[4] == “0”，则为 1否则 0,
            }
        ）

# 将数据分为训练组和测试组
证据 = [行[“证据”] 数据中的行]
labels = [行[“标签”] 数据中的行]
X_训练，X_测试，y_训练，y_测试=train_test_split（
    证据、标签、test_size=0.4
）

# 创建一个神经网络
模型 = tf.keras.models.Sequential()

# 添加一个包含 8 个单元的隐藏层，并使用 ReLU 激活
model.add(tf.keras.layers.Dense(8, input_shape=(4,), 激活=“relu”))

# 添加 1 个单元的输出层，使用 sigmoid 激活
model.add(tf.keras.layers.Dense(1,激活=“sigmoid”))

# 训练神经网络
模型.编译(
    优化器=“adam”，损失=“binary_crossentropy”，指标=[“准确性”]
）
model.fit(X_training, y_training, epochs=20)

# 评估模型的表现
model.evaluate(X_testing, y_testing, verbose=2)

但是，我收到以下错误：
回溯（最近一次调用最后一次）：
  文件“C:\Users\Eric\Desktop\coding\cs50\ai\lectures\lecture5\banknotes\banknotes.py”，第 41 行，在  中
    model.fit(X_training, y_training, epochs=20)
  文件“C:\Users\Eric\Desktop\coding\cs50\ai\.venv\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
    从 None 引发 e.with_traceback(filtered_tb)
  文件“C:\Users\Eric\Desktop\coding\cs50\ai\.venv\Lib\site-packages\keras\src\trainers\data_adapters\__init__.py”，第 113 行，在 get_data_adapter 中
    raise ValueError(f“无法识别的数据类型：x={x}（类型为 {type(x)})”)
ValueError：无法识别的数据类型：x=[...]（类型）

其中“...”是是训练数据。
知道出了什么问题吗？我在 Windows 计算机上使用 Python 版本 3.11.8 和 TensorFlow 版本 2.16.1。
我尝试在 Google Colab 笔记本中运行相同的代码，并且它有效：问题仅发生在我的本地计算机上。这是我期望的输出：
纪元 1/20
26/26 [================================] - 1s 2ms/步 - 损失：1.1008 - 准确度：0.5055
纪元 2/20
26/26 [================================] - 0s 2ms/步 - 损失：0.8588 - 准确度：0.5334
纪元 3/20
26/26 [================================] - 0s 2ms/步 - 损失：0.6946 - 准确度：0.5917
纪元 4/20
26/26 [================================] - 0s 2ms/步 - 损失：0.5970 - 准确度：0.6683
纪元 5/20
26/26 [================================] - 0s 2ms/步 - 损失：0.5265 - 准确度：0.7120
纪元 6/20
26/26 [================================] - 0s 2ms/步 - 损失：0.4717 - 准确度：0.7655
纪元 7/20
26/26 [================================] - 0s 2ms/步 - 损失：0.4258 - 准确度：0.8177
纪元 8/20
26/26 [================================] - 0s 2ms/步 - 损失：0.3861 - 准确度：0.8433
纪元 9/20
26/26 [================================] - 0s 2ms/步 - 损失：0.3521 - 准确度：0.8615
纪元 10/20
26/26 [================================] - 0s 2ms/步 - 损失：0.3226 - 准确度：0.8870
纪元 11/20
26/26 [================================] - 0s 2ms/步 - 损失：0.2960 - 准确度：0.9028
纪元 12/20
26/26 [================================] - 0s 2ms/步 - 损失：0.2722 - 准确度：0.9125
纪元 13/20
26/26 [================================] - 0s 2ms/步 - 损失：0.2506 - 准确度：0.9283
纪元 14/20
26/26 [================================] - 0s 2ms/步 - 损失：0.2306 - 准确度：0.9514
纪元 15/20
26/26 [================================] - 0s 3ms/步 - 损失：0.2124 - 准确度：0.9660
纪元 16/20
26/26 [================================] - 0s 2ms/步 - 损失：0.1961 - 准确度：0.9769
纪元 17/20
26/26 [================================] - 0s 2ms/步 - 损失：0.1813 - 准确度：0.9781
18/20 纪元
26/26 [================================] - 0s 2ms/步 - 损失：0.1681 - 准确度：0.9793
19/20 纪元
26/26 [================================] - 0s 2ms/步 - 损失：0.1562 - 准确度：0.9793
20/20 纪元
26/26 [================================] - 0s 2ms/步 - 损失：0.1452 - 准确度：0.9830
18/18 - 0s - 损失：0.1407 - 准确度：0.9891 - 187ms/epoch - 10ms/step
[0.14066053926944733，0.9890710115432739]
]]></description>
      <guid>https://stackoverflow.com/questions/78271090/why-do-i-get-valueerror-unrecognized-data-type-x-of-type-class-list</guid>
      <pubDate>Thu, 04 Apr 2024 00:28:01 GMT</pubDate>
    </item>
    <item>
      <title>在 ARMA 模型中使用梯度下降进行系数估计</title>
      <link>https://stackoverflow.com/questions/78270443/using-gradient-descent-for-coefficient-estimation-in-arma-model</link>
      <description><![CDATA[我正在尝试使用梯度下降来估计其系数，从头开始实现 ARMA 模型。我知道这可能不是理想的解决方案。但我最担心的是，如果这不是一个正确的解决方案。
这是我的 ARMA 模型方程。为此，假设数据集已经静止。

为此，我采用了残差平方和，如下所示，
 
以及衍生品如下：

然后使用梯度下降算法，我可以获得所有系数的值。这是一个好方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78270443/using-gradient-descent-for-coefficient-estimation-in-arma-model</guid>
      <pubDate>Wed, 03 Apr 2024 20:50:17 GMT</pubDate>
    </item>
    <item>
      <title>抛物线拟合肺部分段区域</title>
      <link>https://stackoverflow.com/questions/78269913/parabola-fitting-over-lungs-segmented-region</link>
      <description><![CDATA[我正在尝试对胸部 X 光图像进行肺部分割
&lt;前&gt;&lt;代码&gt;导入cv2
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
从 sklearn.cluster 导入 KMeans

def 边距(img, margin_percent=10):
    h, w = img.shape
    margin_x = int(w * margin_percent / 100)
    margin_y = int(h * margin_percent / 100)
    裁剪 = img[margin_y:h-margin_y, margin_x:w-margin_x]
    返回裁剪

def 进程（img）：
    flat_img = img.flatten().reshape(-1, 1)
    kmeans = KMeans(n_clusters=2, n_init=10, random_state=0)
    标签 = kmeans.fit_predict(flat_img)
    中心= kmeans.cluster_centers_
    如果 np.mean(centers[1]) &gt; np.mean(中心[0]):
        标签 = 1 - 标签
    聚集 = np.reshape(标签, img.shape)
    clustered_binary = np.uint8(clustered * 255)
    返回 clustered_binary

def segment_and_filter(clustered_img):
    ret, thresh = cv2.threshold(clustered_img, 0, 255, cv2.THRESH_BINARY)
    如果 cv2.__version__[0] &gt; ‘3’：
        轮廓， _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    别的：
        _，轮廓，_ = cv2.findContours（阈值，cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_SIMPLE）
    
    最大面积 = 0
    最大轮廓=无
    对于轮廓中的轮廓：
        面积 = cv2.contourArea(轮廓)
        如果面积&gt;最大面积：
            最大面积=面积
            最大轮廓 = 轮廓
    
    结果 = np.zeros_like(clustered_img)
    cv2.drawContours(结果, [最大轮廓], -1, 255, 厚度=cv2.FILLED)
    返回结果，最大轮廓

def process_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    裁剪后的img =边距（img）
    clustered_img = 进程(cropped_img)
    过滤结果，最大轮廓=分段和过滤器（簇状图像）
    
    组合图像 = np.hstack((filtered_result[:, :filtered_result.shape[1] // 2],
                                cv2.flip(filtered_result[:, :filtered_result.shape[1] // 2], 1)))
    
    返回组合图像

image_path =“/kaggle/input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0105-0001.jpeg”
结果图像=过程图像（图像路径）

plt.figure(figsize=(9, 3))
plt.imshow(result_image, cmap=&#39;灰色&#39;)
plt.title(&#39;合并肺&#39;)
plt.axis(&#39;on&#39;)
plt.show()


上面的代码给出了这个输出
到目前为止一切都很好
现在我想拟合一条覆盖两个肺部区域的抛物线
尝试了多次
但这没有用
你能帮我吗？
在单肺上尝试过，但对两个肺都不起作用

预期
]]></description>
      <guid>https://stackoverflow.com/questions/78269913/parabola-fitting-over-lungs-segmented-region</guid>
      <pubDate>Wed, 03 Apr 2024 18:57:31 GMT</pubDate>
    </item>
    <item>
      <title>创建用于 html 理解和数据提取的 AI 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/78268338/create-a-ai-model-for-html-understanding-and-extraction-of-data</link>
      <description><![CDATA[我正在开发一个项目，要求是我应该制作一个脚本，可以从给定的链接获取包含特定数据的表。因为有很多网站的结构不同，有些有table标签，有些使用div，有些使用其他标签。
现在，我对机器学习之类的东西非常陌生。如果有人可以指导我如何实现这一目标或给我一个正确的路线图。我应该学习什么，什么对我这个项目有帮助。不过，我精通 python 和数据抓取。
数据非常相似，我认为这是可能的。我将向专家展示一些例子。
https://www.rockauto.com/en/moreinfo.php?pk=101750&amp;cc=0&amp;pt=1000587&amp;jsn=788&amp;optionchoice=0-0-8-1


像这样的表格和交换号码（如果有）
另一个例子是
https://www.aimsinduscial。 com.au/gates-9770-13a1955-green-stripe-belt-heavy-duty-en

我想创建一个自定义框架，为我提供的具有类似数据类型（产品规格）的所有网站获取数据。我对机器学习一无所知，想要这个项目的路线图。我没有太多时间，这就是我需要指导的原因。]]></description>
      <guid>https://stackoverflow.com/questions/78268338/create-a-ai-model-for-html-understanding-and-extraction-of-data</guid>
      <pubDate>Wed, 03 Apr 2024 14:20:16 GMT</pubDate>
    </item>
    <item>
      <title>write_deltalake 错误 - > OSError 通用 Deltalocal 对象存储错误：不支持操作（操作系统错误 95）[关闭]</title>
      <link>https://stackoverflow.com/questions/78268024/write-deltalake-error-oserror-generic-deltalocal-objectstore-error-operatio</link>
      <description><![CDATA[尝试将 pandas 数据帧转换为 delta 表，标题中出现错误。生成一个表，但 delta_log 为空，无法读取数据。
尝试创建增量表，通过数据集使用 MLS 上传到 blob。
将 pandas 导入为 pd
导入操作系统
从 azureml.core 导入数据存储区、数据集、工作区
从 azureml.data.datapath 导入 DataPath
从 Delta 导入 *
training_data = pd.read_csv(&#39;Training.csv&#39;)
如果不是 os.path.isdir(&#39;output&#39;):
os.makedirs(&#39;输出&#39;)
导入操作系统
从 deltalake 导入 DeltaTable
从 deltalake.writer 导入 write_deltalake
write_deltalake(“输出/some_delta_lake”，training_data)
错误：OSError：通用 DeltaLocalObjectStore 错误：不支持操作（操作系统错误 95）]]></description>
      <guid>https://stackoverflow.com/questions/78268024/write-deltalake-error-oserror-generic-deltalocal-objectstore-error-operatio</guid>
      <pubDate>Wed, 03 Apr 2024 13:29:07 GMT</pubDate>
    </item>
    <item>
      <title>m=365 时 PM10 浓度预测的 SARIMA 模型存在问题</title>
      <link>https://stackoverflow.com/questions/78270055/issue-with-sarima-model-for-pm10-concentration-forecasting-with-m-365</link>
      <description><![CDATA[我正在尝试构建 SARIMA（季节性自回归综合移动平均线）模型，用于根据五年的数据预测 PM10 浓度。但是，当我将季节性参数 m 设置为 365 时，我的代码似乎无法运行。
有人可以解释一下为什么我的代码没有在 m=365 下运行并提出潜在的解决方案吗？
提前致谢！
# 这是我的代码片段：
## 将数据集拆分为训练集和测试集

    `train_size = int(len(Alipur_df) * 0.8) # 80% 训练，20% 测试`
    `训练，测试 = Alipur_df[:train_size], Alipur_df[train_size:]`

## 将训练 DataFrame 转换为 numpy 数组

    `train_values = train[&#39;Alipur&#39;].values`
    `test_values = test[&#39;Alipur&#39;].values`

## 使用 auto_arima 找到 SARIMA 的最佳参数

    `auto_model = auto_arima(train[&#39;Alipur&#39;],seasonal=True,stationary=True,m=365,trac
]]></description>
      <guid>https://stackoverflow.com/questions/78270055/issue-with-sarima-model-for-pm10-concentration-forecasting-with-m-365</guid>
      <pubDate>Wed, 03 Apr 2024 06:23:04 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“llama_index.llms”（未知位置）导入名称“HuggingFaceInferenceAPI”</title>
      <link>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</link>
      <description><![CDATA[想要导入 HuggingFaceInferenceAPI。
从 llama_index.llms 导入 HugggingFaceInferenceAPI

llama_index.llms 文档没有 HuggingFaceInferenceAPI 模块。有人有这方面的更新吗？]]></description>
      <guid>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</guid>
      <pubDate>Sun, 31 Mar 2024 14:21:19 GMT</pubDate>
    </item>
    <item>
      <title>在应用 varImp 函数时使用带插入符号的 xgbTree 方法和目标变量的权重时出现非树模型错误</title>
      <link>https://stackoverflow.com/questions/63731960/non-tree-model-error-when-using-xgbtree-method-with-caret-and-weights-to-target</link>
      <description><![CDATA[当我使用 Caret 包中的“train”函数创建模型以使用权重进行梯度提升时，在使用“varImp”函数时出现错误，表示未检测到树模型。但是当我去掉重量时它就起作用了。
下面的代码会产生错误：
set.seed(123)

model_weights &lt;- ifelse(modelo_df_sseg$FATALIDADES == 1,
                        是 = (1/表(modelo_df_sseg$FATALIDADES)[2]) * 0.5,
                        否 = (1/表(modelo_df_sseg$FATALIDADES)[1]) * 0.5
                        ）

模型 &lt;- 火车（
  as.factor(FATALIDADES) ~.,
  数据= modelo_df_sseg，
  方法=“xgbTree”，
  trControl = trainControl(“cv”, 数量 = 10),
  权重 = 模型权重
  ）

varImp(模型)

但是如果我不施加权重，它就会起作用。
为什么 varImp 无法识别我的树？
编辑 2020 年 9 月 4 日
评论部分的missuse建议使用wts而不是权重。现在我收到以下错误：
nominalTrainWorkflow 中的错误（x = x，y = y，wts = 权重，info = trainInfo，：形式参数 &#39;wts&#39; 与多个实际参数匹配

我用 R 内置数据集编写了一个小代码，以便您可以自己测试：
set.seed(123)

Basex &lt;- 逮捕

model_weights &lt;- ifelse(basex$released == 2,
                        是 = (1/表(basex$released)[2]) * 0.5,
                        否 = (1/表(basex$released)[1]) * 0.5
                        ）

y = basex$已发布
x = 基x
tc = trainControl(“cv”，数量 = 10)

mtd =“xgbTree”；
模型 &lt;- 火车（
  X，
  是，
  方法=MTD，
  trControl = tc,
  wts = 模型权重，
  详细 = TRUE
  ）

也许我创建的权重向量是错误的。但我找不到任何有关“wts”参数的文档。]]></description>
      <guid>https://stackoverflow.com/questions/63731960/non-tree-model-error-when-using-xgbtree-method-with-caret-and-weights-to-target</guid>
      <pubDate>Thu, 03 Sep 2020 21:35:31 GMT</pubDate>
    </item>
    <item>
      <title>Keras AttributeError：“列表”对象没有属性“ndim”</title>
      <link>https://stackoverflow.com/questions/48493755/keras-attributeerror-list-object-has-no-attribute-ndim</link>
      <description><![CDATA[我正在 Jupyter Notebook (Python 3.6) 中运行 Keras 神经网络模型
我收到以下错误

&lt;块引用&gt;
  属性错误：“列表”对象没有属性“ndim”

从 Keras.model 调用 .fit() 方法后

&lt;前&gt;&lt;代码&gt;模型 = 顺序()
model.add(Dense(5, input_dim=len(X_data[0]), 激活=&#39;sigmoid&#39; ))
model.add(Dense(1, 激活 = &#39;sigmoid&#39;))
model.compile(loss=&#39;mean_squared_error&#39;, 优化器=&#39;adam&#39;, 指标=[&#39;acc&#39;])
model.fit（X_data，y_data，epochs = 20，batch_size = 10）

我检查了 Keras 的requirements.txt 文件（在 Anaconda3 中），numpy、scipy 和六个模块版本都是最新的。
如何解释这个 AttributeError？
完整的错误消息如下（似乎与Numpy有些相关）：

&lt;块引用&gt;
  ------------------------------------------------------------ ---------------------------- AttributeError Traceback（最近调用
  最后）在（）
        3 model.add(密集(1,激活=&#39;sigmoid&#39;))
        4 model.compile(loss=&#39;mean_squared_error&#39;, 优化器=&#39;adam&#39;, 指标=[&#39;acc&#39;])
  ----&gt; 5 model.fit(X_data, y_data, epochs=20, batch_size=10)
~\Anaconda3\lib\site-packages\keras\models.py 中的 fit(self, x, y,
  批量大小、纪元、详细、回调、validation_split、
  验证数据、洗牌、类权重、样本权重、初始纪元、
  steps_per_epoch、validation_steps、**kwargs）
      第963章
      第964章
  --&gt; 第965章 验证步骤=验证步骤）
      966
      第967章
  
  ~\Anaconda3\lib\site-packages\keras\engine\training.py 中的 fit(self, x,
  y、batch_size、纪元、详细、回调、validation_split、
  验证数据、洗牌、类权重、样本权重、初始纪元、
  steps_per_epoch、validation_steps、**kwargs) 1591
  第1592章 1592
  -&gt; 1593 batch_size=batch_size) 1594 # 准备验证数据。第1595章
  
  ~\Anaconda3\lib\site-packages\keras\engine\training.py 中
  _standardize_user_data(self、x、y、sample_weight、class_weight、check_batch_axis、batch_size) 1424
  self._feed_input_shapes，1425
  check_batch_axis=False,
  第1426章 1427、第1427章
  第1428章
  
  ~\Anaconda3\lib\site-packages\keras\engine\training.py 中
  _standardize_input_data（数据、名称、形状、check_batch_axis、exception_prefix）
       68 elif isinstance（数据，列表）：
       69 data = [x.values if x.class.name == &#39;DataFrame&#39; else x for x in data]
  ---&gt; 70 data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]
       71 其他：
       72 data = data.values if data.class.name == &#39;DataFrame&#39; else data
~\Anaconda3\lib\site-packages\keras\engine\training.py 中
  (.0)
       68 elif isinstance（数据，列表）：
       69 data = [x.values if x.class.name == &#39;DataFrame&#39; else x for x in data]
  ---&gt; 70 data = [np.expand_dims(x, 1) if x is not None and x.ndim == 1 else x for x in data]
       71 其他：
       72 data = data.values if data.class.name == &#39;DataFrame&#39; else data
属性错误：“列表”对象没有属性“ndim”
]]></description>
      <guid>https://stackoverflow.com/questions/48493755/keras-attributeerror-list-object-has-no-attribute-ndim</guid>
      <pubDate>Mon, 29 Jan 2018 02:55:27 GMT</pubDate>
    </item>
    <item>
      <title>NotFittedError：估计器未安装，在利用模型之前调用“fit”</title>
      <link>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</link>
      <description><![CDATA[我在 Macbook OSX 10.2.1 (Sierra) 上运行 Python 3.5.2。
在尝试从 Kaggle 运行泰坦尼克号数据集的一些代码时，我不断收到以下错误：

&lt;块引用&gt;
  &lt;小时/&gt;
  
  NotFittedError Traceback（最近调用
  最后）在（）
        6
        7 # 使用测试集进行预测并打印它们。
  ----&gt; 8 my_prediction = my_tree_one.predict(test_features)
        9 打印（我的预测）
       10 
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
  在预测（自我，X，check_input）中
      第429章
      第430章
  --&gt; 431 X = self._validate_X_predict(X, check_input)
      第432章
      [第 433 章]
  
  /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
  在 _validate_X_predict(self, X, check_input) 中
      第386章
      第387章
  --&gt; 388 raise NotFittedError(&quot;估计器未安装，&quot;
      第389章
      390 
NotFittedError：估计器未安装，请在利用之前调用 fit
  型号。

有问题的代码似乎是这样的：
# 用中位数估算缺失值
test.Fare[152] = test.Fare.median()

# 从测试集中提取特征：Pclass、Sex、Age 和 Fare。
test_features = test[[&quot;Pclass&quot;, &quot;性别&quot;, &quot;年龄&quot;, &quot;票价&quot;]].values

# 使用测试集进行预测并打印它们。
my_prediction = my_tree_one.predict(test_features)
打印（我的预测）

# 创建一个包含两列的数据框：PassengerId &amp;幸存下来了。幸存包含你的预测
PassengerId =np.array(test[&quot;PassengerId&quot;]).astype(int)
my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [&quot;幸存&quot;])
打印（我的解决方案）

# 检查您的数据框是否有 418 个条目
打印（my_solution.shape）

# 将解决方案写入名为 my_solution.csv 的 csv 文件
my_solution.to_csv(&quot;my_solution_one.csv&quot;,index_label = [&quot;PassengerId&quot;])

这里是其余代码的链接。
由于我已经调用了“fit”函数，因此我无法理解此错误消息。我哪里出错了？感谢您抽出时间。
编辑：
结果发现问题是从上一个代码块继承而来的。
# 拟合你的第一个决策树：my_tree_one
my_tree_one = 树.DecisionTreeClassifier()
my_tree_one = my_tree_one.fit(features_one, 目标)

# 查看包含的功能的重要性和得分
打印（my_tree_one.feature_importances_）
打印（my_tree_one.score（features_one，目标））

用行：
my_tree_one = my_tree_one.fit(features_one, target)
生成错误：

&lt;块引用&gt;
  ValueError：输入包含 NaN、无穷大或太大的值
  dtype(&#39;float32&#39;)。
]]></description>
      <guid>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</guid>
      <pubDate>Fri, 02 Dec 2016 17:10:22 GMT</pubDate>
    </item>
    </channel>
</rss>