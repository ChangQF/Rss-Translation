<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Thu, 06 Mar 2025 12:35:32 GMT</lastBuildDate>
    <item>
      <title>数据科学和ML [关闭]</title>
      <link>https://stackoverflow.com/questions/79489029/data-science-and-ml</link>
      <description><![CDATA[如何进行预处理和构建ML模型，该模型分析每个文件具有唯一/看不见的属性（列）的异质CSV文件，并且该模型必须动态地适应这些不同的模式以产生结果？
示例方案：
 csv 1：列=“温度”，“湿度”，“城市”→“]→目标=天气状况（例如，“下雨”。
 csv 2：columns = [销售;
期望适应任何CSV模式，跨看不见的属性，并提供有意义的预测，尽管模式可变性。 ，]]></description>
      <guid>https://stackoverflow.com/questions/79489029/data-science-and-ml</guid>
      <pubDate>Thu, 06 Mar 2025 10:35:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的面部识别模型检测下载和实时相机图像，而不是正确检测屏幕截图，如何解决此错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79488408/why-is-my-face-recognition-model-detecting-downloaded-and-live-camera-images-but</link>
      <description><![CDATA[有关该项目的小信息：
该项目是一个面部识别系统，可以分析保存的图像文件和网络摄像头输入的图像。该模型检测到给定的图像是来自现场摄像头，下载的图像还是屏幕截图。它使用Insightface的面部嵌入以及图像分析技术，例如边缘检测，亮度测量和频域分析（FFT）来区分这些图像类型。该系统还根据训练有素的数据集将面部归类为已知或未知的面孔。但是，当我为文件夹中存储的屏幕快照图像提供了一条路径时，该模型无法预测为屏幕截图图像，而是将其视为实时相机图像。如何解决此错误检测？]]></description>
      <guid>https://stackoverflow.com/questions/79488408/why-is-my-face-recognition-model-detecting-downloaded-and-live-camera-images-but</guid>
      <pubDate>Thu, 06 Mar 2025 06:07:37 GMT</pubDate>
    </item>
    <item>
      <title>MediaPipe rtlite对象检测模型中的输出层</title>
      <link>https://stackoverflow.com/questions/79486927/output-layers-in-mediapipe-rtlite-object-detection-model</link>
      <description><![CDATA[I&#39;m somewhat new to ML/AI and I trained my custom model exactly per the sample example given by mediapipe:  https://colab.reasearch.google.com/github/googlesamples/mediapipe/mediapipe/blob/main/main/examples/customization/customization/object_detector.ipynb#scrollto= eolnzgoafs5bs5b 
问题：我无法理解输出的组织方式，因此我可以从解释器中获取以下方式：
  tfliteTensor *output_locations =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[0]）;
 tfliteTensor *output_classes =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[1]）;
 tfliteTensor *output_scores =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[2]）;
 tfliteTensor *output_detections =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[3]）;
 
我发现上述COLAB的自定义训练的模型只有两个输出层，其中一个介绍了4个边界盒坐标，而另一种则给出了对我没有任何意义的东西。有人请向我解释如何学习和弄清楚这一点。关于rtlite的文档尚不清楚，我迷路了。]]></description>
      <guid>https://stackoverflow.com/questions/79486927/output-layers-in-mediapipe-rtlite-object-detection-model</guid>
      <pubDate>Wed, 05 Mar 2025 15:25:16 GMT</pubDate>
    </item>
    <item>
      <title>当使用不同GPU训练模型时，结果不一致</title>
      <link>https://stackoverflow.com/questions/79486105/inconsistent-results-when-training-models-using-different-gpus</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79486105/inconsistent-results-when-training-models-using-different-gpus</guid>
      <pubDate>Wed, 05 Mar 2025 10:10:04 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost在等于传输数据的输入上无法正确预测</title>
      <link>https://stackoverflow.com/questions/79485691/xgboost-does-not-predict-properly-on-input-thats-equal-to-traning-data</link>
      <description><![CDATA[为什么这个非常简单的XGBoost ML示例即使在输入中也会产生全弹药，这相当于训练数据？这看起来像是一种琐碎的输入情况，不需要对ML进行任何微调，但是即使我对ML（MAX_DEPTH，ETA等）调整了HyperParams，也没有任何改变。
 将大熊猫作为pd导入
导入XGBoost为XGB

x = pd.dataframe（（[[[0]，[1]，[2]，[3]，[4]，[5]]），列= [&#39;x&#39;]）
y = pd.dataframe（[0，1，0，1，0，1]，列= [&#39;y&#39;]）

型号= xgb.xgbClassifier（）
型号（x，y）
打印（模型。

[0 0 0 0 0 0]
 ]]></description>
      <guid>https://stackoverflow.com/questions/79485691/xgboost-does-not-predict-properly-on-input-thats-equal-to-traning-data</guid>
      <pubDate>Wed, 05 Mar 2025 06:59:19 GMT</pubDate>
    </item>
    <item>
      <title>Android MediaPipe第二推理实例无法初始化</title>
      <link>https://stackoverflow.com/questions/79484601/android-mediapipe-second-inference-instance-cant-be-initialized</link>
      <description><![CDATA[我对 google.mediapipe进行了一些实验框架并观察下一期……如果初始化了某些实例/任务，则无法在推理任务的另一个实例。之后。
例如，我以姿势检测模型运行MediaPipe任务，当我尝试初始化TexteMbedder实例时，我会收到以下例外：

 com.google.mediapipe.framework.mediapipeexception：找不到：验证的GraphConfig初始化失败。
没有名称的注册对象：MediaPipe :: tasks :: text :: text_embedder :: textembeddergraph;无法找到计算器“ MediaPipe.tasks.text.text_embedder.textembeddergraph”
在com.google.mediapipe.framework.graph.nativestartrunninggraph（本机方法）
在com.google.mediapipe.framework.graph.startrunninggraph（graph.java:336）
在com.google.mediapipe.tasks.core.taskrunner.create（taskrunner.java:72）
在com.google.mediapipe.tasks.text.textembedder.textembedder.createfromoptions（textembedder.java:159）

 i从他们的示例（姿势检测）中运行代码库，并将文本任务依赖添加到项目中。
实例化：
  baseOptions.builder baseOptionsBuilder = baseOptions.builder（）;
             baseOptionsBuilder.SetModelassetPath（&#39;unision_sentence_encoder.tflite＆quot;）;
textembedder.textembedderoptions选项=
                            textembedder.textembedpertions.builder（）
                                    .setBaseOptions（baseOptionsbuilder.build（））
                                                                            。建造（）;
mtextembedder = textembedder.createfromoptions（上下文，选项）;
 
我尝试了不同的版本/组合（视觉＆amp; text）到目前为止，但到目前为止还没有运气... 
我想知道是否可以同时运行2个实例？
  upd ：2同时实例在iOS 上正常工作]]></description>
      <guid>https://stackoverflow.com/questions/79484601/android-mediapipe-second-inference-instance-cant-be-initialized</guid>
      <pubDate>Tue, 04 Mar 2025 18:46:25 GMT</pubDate>
    </item>
    <item>
      <title>由于亚当优化器加载模型时警告</title>
      <link>https://stackoverflow.com/questions/79484194/warning-when-loading-the-model-because-of-adam-optimizer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79484194/warning-when-loading-the-model-because-of-adam-optimizer</guid>
      <pubDate>Tue, 04 Mar 2025 15:48:02 GMT</pubDate>
    </item>
    <item>
      <title>'numpy.ndarray'对象没有属性'groupby'</title>
      <link>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</link>
      <description><![CDATA[我正在尝试使用 category_encoders.targetencoder 在Python中应用目标编码。但是，我一直遇到以下错误：
  attributeError：&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39;
 
 来自category_encoder
来自sklearn.model_selection导入train_test_split

＃目标编码的功能
encoding_cols = [&#39;等级&#39;，&#39;sub_grade&#39;，&#39;home_ownhip&#39;，&#39;verification_status&#39;， 
                 “目的”，“ application_type”，“ zipcode”]

＃火车测试拆分
x_train_cv，x_test，y_train_cv，y_test = train_test_split（x，y，test_size = 0.25，andury_state = 1）
x_train，x_test_cv，y_train，y_test_cv = train_test_split（x_train_cv，y_train_cv，test_size = 0.25，andury_state = 1）

＃初始化目标编码器
encoder = targetencoder（）

＃应用目标编码
因为我在encoding_cols中：
    x_train [i] = encoder.fit_transform（x_train [i]，y_train）＃**错误在这里发生**
    x_test_cv [i] = encoder.transform（x_test_cv [i]）
    x_test [i] = encoder.transform（x_test [i]）
 
想要成功地将目标编码应用于分类列，而不会遇到&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39; error。]]></description>
      <guid>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</guid>
      <pubDate>Tue, 04 Mar 2025 08:00:57 GMT</pubDate>
    </item>
    <item>
      <title>始终获得“输入用完数据”</title>
      <link>https://stackoverflow.com/questions/79396860/always-getting-your-input-ran-out-of-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79396860/always-getting-your-input-ran-out-of-data</guid>
      <pubDate>Wed, 29 Jan 2025 13:15:41 GMT</pubDate>
    </item>
    <item>
      <title>恢复标准标准的名称（）。fit_transform（）</title>
      <link>https://stackoverflow.com/questions/71509883/recovering-features-names-of-standardscaler-fit-transform-with-sklearn</link>
      <description><![CDATA[从 kaggle的教程 href =“ https://www.dropbox.com/s/xc9my0ratl994gm/aquifer_petrignano.csv?dl = 0” rel =“ noreferrer”&gt;可从此处下载
代码：
 进口SEABON作为SNS
导入matplotlib.pyplot作为PLT
导入numpy作为np＃线性代数
导入PANDAS作为PD＃数据处理，CSV文件I/O（例如PD.Read_CSV）
导入matplotlib.pyplot作为PLT＃用于绘制设施
从DateTime Import DateTime，日期
来自sklearn.model_selection import timpleseriessplit，gridsearchcv
导入XGBoost为XGB
来自sklearn.metrics导入均值_squared_error，mean_absolute_error
导入数学
从sklearn.prepercorsing进口标准标准

df = pd.read_csv（“ ./ data/aquifer_petrignano.csv”）

df [&#39;date&#39;] = pd.to_dateTime（df.date，格式=&#39;％d/％m/％y&#39;）
df = df [df.rainfall_bastia_umbra.notna（）]。reset_index（drop = true）

df = df.interpaly（方法=&#39;ffill&#39;）
df = df [[[&#39;date&#39;，&#39;雨fall_bastia_umbra&#39;，&#39;depth_to_togrongwater_p24&#39;，&#39;depth_to_to _ groundwater_p25&#39;，&#39;devies_bastia_umbra&#39;，&#39;devies_petrignano&#39;，&#39; &#39;hydometry_fiume_chiascio_petrignano&#39;]]。res ampleme（&#39;7d&#39;，on =&#39;date&#39;）。sean（）。reset_index（drop = false）

x = df.drop（[&#39;depth_to_groundWater_p24&#39;，&#39;depth_to_togrongwater_p25&#39;，&#39;date&#39;]，axis = 1）
y1 = df.depth_to_groundWater_p24
y2 = df.depth_to_groundwater_p25

sualer = StandardScaler（）
x = sualer.fit_transform（x）

model = xgb.xgbregressor（）
param_search = {&#39;max_depth&#39;：range（1，2，2），
                &#39;min_child_weight&#39;：范围（1，2，2），
                &#39;n_estimators&#39;：[1000]，，
                &#39;Learning_rate&#39;：[0.1]}

tscv = timeseriessplit（n_splits = 2）
gsearch = gridSearchCV（estionator =模型，cv = tscv，
                        param_grid = param_search）
gsearch.fit（x，y1）

xgb_grid = xgb.xgbregressor（** gsearch.best_params_）
XGB_GRID.FIT（X，Y1）

ax = xgb.plot_importance（xgb_grid）
ax.figure.tight_layout（）
ax.figure.savefig（&#39;test.png&#39;）

y_val = y1 [-80：]
x_val = x [-80：]

y_pred = xgb_grid.predict（x_val）
print（mean_absolute_error（y_val，y_pred））
print（Math.sqrt（mean_squared_error（y_val，y_pred）））
 
我绘制了一个重要的图形，其原始特征名称隐藏了：
  如果我评论这两行：
  sualer =标准尺度（）
x = sualer.fit_transform（x）
 
我得到输出：
  我如何使用 scaler.fit_transform（）  x 并获得具有原始功能名称的功能重要图？]]></description>
      <guid>https://stackoverflow.com/questions/71509883/recovering-features-names-of-standardscaler-fit-transform-with-sklearn</guid>
      <pubDate>Thu, 17 Mar 2022 09:28:43 GMT</pubDate>
    </item>
    <item>
      <title>建立和揭示机器学习模型REST API的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/42080598/what-is-the-best-way-to-build-and-expose-a-machine-learning-model-rest-api</link>
      <description><![CDATA[我一直在使用SpringFramework设计REST API，并将它们部署在Tomcat之类的Web服务器上。我还研究了建立机器学习模型，并使用该模型在Python中使用Sklearn进行预测。
现在，我有了一个用例，在 中，我想揭示建立机器学习模型的REST API，而另一种使预测的REST API  。哪些架构应该帮助我实现这一目标？ （相同的一个示例也许是亚马逊机器学习；它们已经暴露了用于生成模型并进行预测的REST API）
我在互联网上搜索并找到了以下方式：

在Java -ML模型 + REST API 中写下整个东西
在Python -ML模型 + REST API 中写下整个内容

但是，使用机器学习，它的模型和预测确实更容易，并且在python中提供了诸如Sklearn，而不是Java之类的图书馆。我真的很想 使用Python进行机器学习部分 。
我正在考虑和接近使用Java的REST API的方法，但使用子过程进行Python ML呼叫。那会起作用吗？
有人可以帮助我讨论我可以采取的可能的建筑方法吗？另外，请建议最可行的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/42080598/what-is-the-best-way-to-build-and-expose-a-machine-learning-model-rest-api</guid>
      <pubDate>Tue, 07 Feb 2017 02:19:11 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec和向量起源</title>
      <link>https://stackoverflow.com/questions/35189656/word2vec-and-vector-origin</link>
      <description><![CDATA[我读了Mikolov等人在Word2Vec上的两篇论文（请参阅 and nofollow =“ nofollow”&gt;此处 rel =“ nofollow”&gt;在这里）。 
我理解单词向量的概念及其表示含义。但是，我不明白训练神经网络时最终单词矢量来自哪里。输入是单词的单次编码，它们试图预测另一个单词的单次编码。那么您如何获得最终的n维词向量？]]></description>
      <guid>https://stackoverflow.com/questions/35189656/word2vec-and-vector-origin</guid>
      <pubDate>Wed, 03 Feb 2016 23:19:13 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec是否具有隐藏层？</title>
      <link>https://stackoverflow.com/questions/33374010/does-word2vec-has-a-hidden-layer</link>
      <description><![CDATA[当我阅读Tomas Mikolov的一篇论文时： http：&gt;

我对连续的字袋型号有一个关注：

第一个提出的架构类似于FeedForward NNLM，其中除去非线性隐藏层，并为所有单词共享投影层（不仅仅是投影矩阵）；因此，所有单词都被投射到相同的位置（它们的向量平均）。

我发现有人提到Word2Vec模型中有一个隐藏的层，但是据我了解，该模型中只有一个投影层。该投影层是否与隐藏层相同的工作？
另一个问题是如何将输入数据投射到投影层中？ 
“投影层是所有单词共享的（不仅是投影矩阵）”，这是什么意思？]]></description>
      <guid>https://stackoverflow.com/questions/33374010/does-word2vec-has-a-hidden-layer</guid>
      <pubDate>Tue, 27 Oct 2015 16:57:34 GMT</pubDate>
    </item>
    <item>
      <title>如何将GridSearchCV与Sklearn中的自定义估算器一起使用？</title>
      <link>https://stackoverflow.com/questions/29393739/how-to-use-gridsearchcv-with-custom-estimator-in-sklearn</link>
      <description><![CDATA[我有一个应与Sklearn API兼容的估计器。我试图使用 GridSearchCV 拟合此估算器的一个参数，但我不明白该怎么做。
这是我的代码：
 导入numpy作为NP
进口Sklearn作为SK

来自sklearn.linear_model导入linearrecression，lassolarscv，ridgecv
来自sklearn.linear_model.base导入linearclassifiermixin，sparsecoefmixin，sparesEstimator


类ELM（质估计器）：

    def __init __（self，n_nodes，link =&#39;rbf&#39;，output_function =&#39;lasso&#39;，n_jobs = 1，c = 1）：
        self.n_jobs = n_jobs
        self.n_nodes = n_nodes
        self.c = c

        如果link ==&#39;rbf&#39;：
            self.link = lambda z：np.exp（-z*z）
        elif link ==&#39;sig&#39;：
            self.link = lambda Z：1./(1 + np.exp（-z）） 
        elif link ==&#39;id&#39;：
            self.link = lambda Z：Z
        别的：
            self.link =链接

        如果output_function ==&#39;lasso&#39;：
            self.output_function = lassolarscv（cv = 10，n_jobs = self.n_jobs）
        elif output_function ==&#39;lr&#39;：
            self.output_function = linearregression（n_jobs = self.n_jobs）

        elif output_function ==&#39;ridge&#39;：
            self.output_function = ridgecv（cv = 10）

        别的：
            self.output_function = output_function

        返回 


    def H（self，x）：

        n，p = X.Shape
        xw = np.dot（x，self.w.t）
        xw = xw + np.ones（（n，1））。点（self.b.t）
        返回self.link（xw）

    def fit（self，x，y，w = none）：

        n，p = X.Shape
        self.mean_y = y.mean（）
        如果w ==无：
            self.w = np.random.uniform（-self.c，self.c，（self.n_nodes，p））
        别的：
            self.w = w

        self.b = np.random.uniform（-self.c，self.c，（self.n_nodes，1））
        self.h_train = self.h（x）
        self.output_function.fit（self.h_train，y）

        返回自我

    def预测（self，x）：
        self.h_predict = self.h（x）
        返回self.output_function.predict（self.h_predict）

    def get_params（self，deep = true）：
        返回{“ n_nodes”：self.n_nodes， 
                “链接”：self.link，
                “ output_function”：self.output_function，
                “ n_jobs”：self.n_jobs， 
                “ C”：self.c}

    def set_params（self，**参数）：
        对于参数，parameters.items（）中的值：
            setAttr（self，parameter，value）



###适合C参数### 
x = np.random.normal（0，1，（100,5））
y = x [：，1] * x [：，2] + np.random.normal（0，.1，100） 

gs = sk.grid_search.gridsearchcv（elm（n_nodes = 20，output_function =&#39;lr&#39;）， 
                                 cv = 5， 
                                 param_grid = {“ c”：np.linspace（0.0001,1,10）}，
                                 fit_params = {}）

＃gs.fit（x，y）＃错误
 ]]></description>
      <guid>https://stackoverflow.com/questions/29393739/how-to-use-gridsearchcv-with-custom-estimator-in-sklearn</guid>
      <pubDate>Wed, 01 Apr 2015 14:39:33 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec中负抽采样的概念是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/27860652/what-is-the-concept-of-negative-sampling-in-word2vec</link>
      <description><![CDATA[我正在阅读2014年论文  word2vec解释：派生Mikolov等人。
负抽采样单词 - 插入方法 （注意：直接下载链接），并引用了“否定抽样”的概念：

 Mikolov等。呈现负面采样方法作为更有效的
得出单词嵌入的方式。否定采样是基于
Skip-gram模型，实际上是在优化不同的目标。

我很难理解负抽采样的概念。
  httpps://arxiv.org/pdf/1402.3722v1.pd1.pdf 
任何人都可以用外行的术语解释什么是负面采样？]]></description>
      <guid>https://stackoverflow.com/questions/27860652/what-is-the-concept-of-negative-sampling-in-word2vec</guid>
      <pubDate>Fri, 09 Jan 2015 12:31:25 GMT</pubDate>
    </item>
    </channel>
</rss>