<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 16 Jul 2024 12:29:07 GMT</lastBuildDate>
    <item>
      <title>尝试在多 GPU 设置上训练机器翻译的 Transformer 模型</title>
      <link>https://stackoverflow.com/questions/78754435/trying-to-train-transformer-model-for-machine-translation-on-multi-gpu-setup</link>
      <description><![CDATA[我正在尝试训练机器翻译的变换模型。这是训练函数：
在单个 GPU 上训练时，我得到以下结果：
for src, tgt in train_dataloader:
try:
src = src.to(DEVICE)
tgt = tgt.to(DEVICE)
 tgt_input = tgt[:-1, :]

src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)

logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)

...
在Seq2SeqTransformer：
class Seq2SeqTransformer(nn.Module):
def forward(self,
src: Tensor,
trg: Tensor,
src_mask: Tensor,
tgt_mask: Tensor,
src_padding_mask: Tensor,
tgt_padding_mask: Tensor,
memory_key_padding_mask: Tensor):
 src_emb = self.positional_encoding(self.src_tok_emb(src))
tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))
outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,
src_padding_mask, tgt_padding_mask, memory_key_padding_mask)
return self.generator(outs)

在此行：
outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,
src_padding_mask, tgt_padding_mask, memory_key_padding_mask)
我明白了：

sec_emb 的大小为 (31,31) tgt_emb 的大小为 (37,37)

并且训练运行顺利。
现在，我正尝试使用此设置在具有 8 个 GPU 的计算机上进行训练：
transformer = nn.DataParallel(transformer)
transformer = transformer.to(DEVICE)

在调试模式下，我检查了此行中的值：
outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,
src_padding_mask, tgt_padding_mask, memory_key_padding_mask)
我明白了：

sec_emb 的大小为 (4,31) tgt_emb 的大小为 (5,37)

我认为这是因为所有东西都是并行工作的。
但是，我遇到了此错误消息：

文件
&quot;C:\Projects\MT005.venv\Lib\site-packages\torch\nn\ functional.py&quot;,
line 5382，在 multi_head_attention_forward 中
引发 RuntimeError(f&quot;2D attn_mask 的形状是 {attn_mask.shape}，但应该是 {correct_2d_size}。&quot;) RuntimeError:
2D attn_mask 的形状是 torch.Size([4, 31])，但应该是
(4, 4)。

有人可以帮助我或提供一些指导吗？]]></description>
      <guid>https://stackoverflow.com/questions/78754435/trying-to-train-transformer-model-for-machine-translation-on-multi-gpu-setup</guid>
      <pubDate>Tue, 16 Jul 2024 12:00:27 GMT</pubDate>
    </item>
    <item>
      <title>优化 pgvector 以实现多用户文档存储：索引和分区的最佳实践</title>
      <link>https://stackoverflow.com/questions/78754328/optimizing-pgvector-for-multi-user-document-storage-best-practices-for-indexing</link>
      <description><![CDATA[我使用 PostgreSQL 和 pgvector 以及 LangChain 进行文档存储和检索。我的设置：

许多用户，每个用户上传多个文档
文档具有带 userId 的元数据
需要按用户隔离用户文档并按 userId 进行过滤
使用 LangChain 进行带过滤器的检索

当前表结构：
CREATE TABLE document_vector (
id BIGSERIAL,
content TEXT,
metadata JSONB,
embedding VECTOR(1536)
);

优化可扩展性和查询性能的最佳方法是什么？

为每个用户创建一个新表？
添加 user_id 列并对表进行分区？
索引元数据 - &gt;&gt;&#39;userId&#39;？
另一种方法？

寻找一种可扩展性好且在使用用户特定过滤器进行向量相似性搜索时保持良好性能的解决方案。
感谢您的帮助！
我尝试根据存储在元数据 JSONB 字段中的 userId 在 document_vector 表上实现哈希分区，但不确定这是否是正确的方法。
CREATE TABLE document_vector (
id BIGSERIAL,
content TEXT,
metadata JSONB,
embedding VECTOR(1536)
) PARTITION BY HASH ((metadata-&gt;&gt;&gt;&#39;userId&#39;));
]]></description>
      <guid>https://stackoverflow.com/questions/78754328/optimizing-pgvector-for-multi-user-document-storage-best-practices-for-indexing</guid>
      <pubDate>Tue, 16 Jul 2024 11:33:47 GMT</pubDate>
    </item>
    <item>
      <title>t-SNE 中的不同结果</title>
      <link>https://stackoverflow.com/questions/78754318/different-result-in-t-sne</link>
      <description><![CDATA[有人能帮我回答我的问题吗？
所以我从纸上获取数据集并使用 t-SNE 进行可视化。另一方面，我尝试按照之前的数据集特征创建新的数据集。但是在 t-SNE 上绘制新数据集后，我得到了相反的结果。您可以在此图中看到

我感到困惑的是，视觉效果不应该是相同的吗？因为我提取的方式和特征是相同的？或者至少它们对于标签位置的方向是相同的。在 result-2021 中，标签 0 在左边，标签 1 在右边，但在 dataset_full 中，标签 0 在右边，但标签 1 在左边]]></description>
      <guid>https://stackoverflow.com/questions/78754318/different-result-in-t-sne</guid>
      <pubDate>Tue, 16 Jul 2024 11:31:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么我要将 Python 包安装到我的 Machine_Learning 环境中，但它们却是在本地安装的？[关闭]</title>
      <link>https://stackoverflow.com/questions/78753784/why-am-i-installing-python-packages-into-my-machine-learning-environment-but-th</link>
      <description><![CDATA[在此处输入图片说明在此处输入图片说明在此处输入图片说明
如图所示，我使用
“(D:\conda_envs\Machine_Learning) C:\Users\GuYuanji&gt;python -m pip install -r &quot;C:\Users\GuYuanji\2022-Machine-Learning-Specialization-main\requirements.txt&quot;” 

要安装 Python 包，但它们的安装方式如下。
我希望在我指定的环境中安装这些包。]]></description>
      <guid>https://stackoverflow.com/questions/78753784/why-am-i-installing-python-packages-into-my-machine-learning-environment-but-th</guid>
      <pubDate>Tue, 16 Jul 2024 09:40:15 GMT</pubDate>
    </item>
    <item>
      <title>嘿，有人能帮我解答这个基本的机器学习问题吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78753768/hey-can-anyone-help-me-with-this-basic-ml-question</link>
      <description><![CDATA[ 多选题 
嗨，我想找到这个问题的答案，这是关于机器学习的一个基本问题。你能帮我吗？我希望了解机器学习中的关键概念和技术，例如算法、数据预处理、模型训练和评估。如果您有任何提示或资源可以帮助我很好地掌握这些主题并将它们应用于实际场景，那就太好了。非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78753768/hey-can-anyone-help-me-with-this-basic-ml-question</guid>
      <pubDate>Tue, 16 Jul 2024 09:36:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyTorch 计算信息熵</title>
      <link>https://stackoverflow.com/questions/78753537/compute-information-entropy-with-pytorch</link>
      <description><![CDATA[问题：
如何利用当前模型计算信息熵。
当我尝试实现这篇论文提出的方法时。但我不知道如何让它发挥作用。
假设有一个矩阵 M，它是 m x n。
这个矩阵 M 缺少一些条目。 
该模型的任务是完成矩阵M，使用的方法类似于矩阵分解，但采用自动编码器的架构。
以下是该论文的陈述，未经修改。

在该算法中，我们使用二项分布概率来衡量每个未知延迟的不确定性。具体而言，对于每个未知延迟，我们利用当前模型计算两个潜在延迟的概率。这两个概率构成二项分布。


因此，我们将延迟值的概率设为P(x)=p，P(x_bar)=1-p，其中p等于1表示我们知道x处的延迟，p等于0表示我们不知道x_bar处的延迟。


同时，我们使用信息熵来衡量分布的不确定性。 
对于二项分布，信息熵可以计算为：H(p)=-plog(p)-(1-p)log(1-p)

这是否类似于使用 sigmoid 或 softmax 将模型的输出转换为概率
然后使用概率获取信息熵？
任何帮助都值得感激。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78753537/compute-information-entropy-with-pytorch</guid>
      <pubDate>Tue, 16 Jul 2024 08:42:59 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 模型无法训练</title>
      <link>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</link>
      <description><![CDATA[我正在尝试使用深度学习来查找粒子的化学状态。作为输入，我有粒子在 X_train 中随时间的位置，形状为 (num_train,sequence_length)。 （我的序列长度为 100），输出是形状为 (num_train,1) 的 Y_train 中包含的转换帧（介于 1 和 100 之间）。
这是一个序列示例（https://i.sstatic.net/Ddmhjc24.jpg），转换位于第 84 帧。
所有数据都是用非常具体的算法生成的，但是该算法不会生成非常复杂的数据，我认为自己很容易找到转换，但我希望这个深度学习模型能够正常工作。
这是 LSTM 代码：
# 过滤

# 定义 LSTM 模型
model = Sequential([
LSTM(64, input_shape=(sequence_length, 1), return_sequences=False),
Dense(64,activation=&#39;relu&#39;),
Dense(1)
])

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;) # 回归的均方误差

# 显示模型摘要
model.summary()

# 训练模型
model.fit(X_train, Y_train, epochs=40, batch_size=32, validation_data=(X_test, Y_test))

# 用新数据进行预测的示例
prediction = model.predict(X_test)
print(prediction)

结果：
模型：“顺序”
_________________________________________________________________
层（类型）输出形状参数 # 
====================================================================
lstm (LSTM) (无，64) 16896 

密集 (密集) (无，64) 4160 

密集_1 (密集) (无，1) 65 

============================================================================
总参数：21121 (82.50 KB)
可训练参数： 21121 (82.50 KB)
不可训练参数：0 (0.00 字节)
_________________________________________________________________
Epoch 1/10
631/631 [==============================] - 35s 50ms/step - 损失：1043.6710 - val_loss：840.6771
Epoch 2/10
631/631 [==============================] - 30s 48ms/step - 损失：840.9444 - val_loss：839.9596
Epoch 3/10
631/631 [===============================] - 32s 50ms/步 - 损失：841.6289 - val_loss：840.7188
Epoch 4/10
631/631 [=============================] - 30s 48ms/步 - 损失：840.9946 - val_loss：840.6344
Epoch 5/10
631/631 [===============================] - 33s 52ms/步 - 损失：841.8745 - val_loss：839.9298
Epoch 6/10
631/631 [==============================] - 31s 49ms/步 - 损失：841.6499 - val_loss：839.8434
Epoch 7/10
631/631 [=============================] - 31s 49ms/步 - 损失：841.2045 - val_loss：840.0717
Epoch 8/10
631/631 [===============================] - 30s 48ms/步 - 损失：842.0576 - val_loss： 840.2137
纪元 9/10
631/631 [=============================] - 33s 52ms/步 - 损失：842.7056 - val_loss：840.5657
纪元 10/10
631/631 [=============================] - 30s 48ms/步 - 损失：841.5714 - val_loss：839.8404
70/70 [================================] - 2s 16ms/步
[[52.569366]
[52.569286]
[52.569378]
...
[52.569344]
[52.569313]
[52.56937 ]]

如您所见，当我测试训练后的模型时，无论输入是什么，输出都是相同的。 val_loss 不会随着 epoch 的数量而改善。 这就是问题所在，我不明白发生了什么。
我是深度学习的初学者，所以也许我犯了一个非常简单的错误。 但是我仔细检查了我的数据，X_train 已标准化，我尝试在我的模型上添加一些 drop out 和其他层，但没有任何变化。
也许使用 LSTM 无法做到这一点，但我认为数据非常简单。 我真的想尝试找到一种方法来使用深度学习来找到它。 我 d]]></description>
      <guid>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</guid>
      <pubDate>Tue, 16 Jul 2024 07:31:40 GMT</pubDate>
    </item>
    <item>
      <title>即使经过数百个时期，pytorch AdamW 的 LR 仍未衰减</title>
      <link>https://stackoverflow.com/questions/78752899/lr-not-decaying-for-pytorch-adamw-even-after-hundreds-of-epochs</link>
      <description><![CDATA[我有以下使用 Pytorch 中的 AdamW 优化器的代码：
optimizer = AdamW(params=self.model.parameters(), lr=0.00005)

我尝试使用 wandb 进行登录，如下所示：
lrs = {f&#39;lr_group_{i}&#39;: param_group[&#39;lr&#39;]
for i, param_group in enumerate(self.optimizer.param_groups)}
wandb.log({&quot;train_loss&quot;: avg_train_loss, &quot;val_loss&quot;: val_loss, **lrs})

请注意 weight_decay 参数的默认值为 0.01（对于 AdamW）。
当我检查 wandb 仪表板时，它显示 AdamW 的 LR 即使在 200 个 epoch 之后也相同，并且根本没有衰减。我尝试了几次。

为什么 LR 衰减没有发生？
此外，它仅显示一个参数组的 LR。为什么会这样？似乎我在这里错过了一些基本的东西。有人可以指出吗？]]></description>
      <guid>https://stackoverflow.com/questions/78752899/lr-not-decaying-for-pytorch-adamw-even-after-hundreds-of-epochs</guid>
      <pubDate>Tue, 16 Jul 2024 06:09:44 GMT</pubDate>
    </item>
    <item>
      <title>视频对象分割准确率</title>
      <link>https://stackoverflow.com/questions/78752737/video-object-segmentation-accuracy</link>
      <description><![CDATA[我有一个关于测量视频分割模型准确度的问题。我发现这些模型通常使用 2 个成功衡量标准：Jaccard 指数和轮廓准确度。但是，我从未真正看到过这些方法的实现代码。有人知道我可以在哪里找到这些代码吗？谢谢。
我在网上查过，但找不到这些代码。]]></description>
      <guid>https://stackoverflow.com/questions/78752737/video-object-segmentation-accuracy</guid>
      <pubDate>Tue, 16 Jul 2024 04:51:49 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch DataLoader 中用于 LSTM 模型的 WeightedRandomSampler 的 IndexError</title>
      <link>https://stackoverflow.com/questions/78752550/indexerror-with-weightedrandomsampler-in-pytorch-dataloader-for-lstm-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78752550/indexerror-with-weightedrandomsampler-in-pytorch-dataloader-for-lstm-model</guid>
      <pubDate>Tue, 16 Jul 2024 03:05:49 GMT</pubDate>
    </item>
    <item>
      <title>优化大数据集上的 Pandas 性能</title>
      <link>https://stackoverflow.com/questions/78752483/optimizing-pandas-performance-on-large-datasets</link>
      <description><![CDATA[我正在使用 pandas 处理一个大型数据集（约 1000 万行和 50 列），在数据操作和分析过程中遇到了严重的性能问题。这些操作包括过滤、合并和聚合数据，目前执行时间太长。
我读过几种优化技术，但不确定哪种技术最有效且适用于我的情况。以下是有关我的工作流程的一些细节：
我主要使用 pandas 进行数据清理、转换和分析。
我的操作包括多个 groupby 和 apply 函数。
我在一台具有 16GB RAM 的机器上运行分析。
社区能否分享优化 pandas 在大型数据集上的性能的最佳实践？
1.内存管理技术。
2.执行 groupby 和 apply 的有效方法。
3.处理大型数据集的 pandas 替代方案。
4. 有没有关于并行处理或有效利用多核的技巧。
我主要使用 pandas 进行数据清理、转换和分析。
我的操作包括多个 groupby 和 apply 函数。
我在一台有 16GB RAM 的机器上运行分析。]]></description>
      <guid>https://stackoverflow.com/questions/78752483/optimizing-pandas-performance-on-large-datasets</guid>
      <pubDate>Tue, 16 Jul 2024 02:24:48 GMT</pubDate>
    </item>
    <item>
      <title>在带有 Bullseye 的 Raspberry Pi 3B 上安装 Ultralytics 以运行 yolov5 时出错，“错误：无法为使用 PEP 517 的 opencv-python 构建轮子...”</title>
      <link>https://stackoverflow.com/questions/78752286/error-installing-ultralytics-to-run-yolov5-on-raspberry-pi-3b-with-bullseye-er</link>
      <description><![CDATA[我尝试使用 pip 在装有 Bullseye OS 的 Raspberry Pi 3B 上安装 Ultralytics。虽然我能够安装所有依赖项以成功运行 yolov5，但在尝试安装 Ultralytics 时，我收到错误，
&quot;CMake 安装出现问题，中止构建。CMake 可执行文件是 /tmp/pip-build-env-3didr32b/overlay/lib/python3.9/site-packages/cmake/data/bin/cmake

错误：无法为 opencv-python 构建 wheel
无法构建 opencv-python
错误：无法为使用 PEP 517 且无法直接安装的 opencv-python 构建 wheel&quot;

虽然有多种方法可以成功安装 opencv，并且对我来说很有效，但立即安装 Ultralytics 会导致再次安装 opencv，从而导致同样的失败。有人知道如何修复这个问题吗？
我尝试过单独安装 open-cv，然后安装 ultralytics，但出现了同样的错误。有人建议在安装 ultralytics 之前先安装 opencv-python-headless，但我无法成功安装此包。]]></description>
      <guid>https://stackoverflow.com/questions/78752286/error-installing-ultralytics-to-run-yolov5-on-raspberry-pi-3b-with-bullseye-er</guid>
      <pubDate>Tue, 16 Jul 2024 00:06:34 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface 的 Beam RunInference 和句子转换器</title>
      <link>https://stackoverflow.com/questions/78750157/beam-runinference-and-sentence-transformers-from-huggingface</link>
      <description><![CDATA[我正在尝试将 RunInference beam Transform 与 stsb-xlm-r-multilingual 模型一起使用。
像这样：
 inferences = (
formatted_examples
| &quot;Run Inference&quot; &gt;&gt; RunInference(model_handler)
| &#39;ProcessOutput&#39; &gt;&gt; beam.ParDo(PostProcessor())
)

而 model_handler 是：
model_handler = HuggingFacePipelineModelHandler(
task=PipelineTask.FeatureExtraction,
model = &quot;sentence-transformers/stsb-xlm-r-multilingual&quot;,
load_pipeline_args={&#39;framework&#39;: &#39;pt&#39;},
inference_args={&#39;max_length&#39;: 200}
)

但是，转换返回的 predictionResult 对象包含一个嵌套数组，其中包含多个嵌入。
我可以像这样访问嵌入：
result.inference[0][0][0]。
这为我提供了一个嵌入。
我不确定所有其他嵌入是什么。我只对其中一个感兴趣，我不需要所有数据。
虽然我总是可以通过使用上面显示的内部索引来获取嵌入，但我想知道我是否做错了什么，或者是否有办法将一些参数传递给处理程序，以指示它只返回单个嵌入？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78750157/beam-runinference-and-sentence-transformers-from-huggingface</guid>
      <pubDate>Mon, 15 Jul 2024 13:36:33 GMT</pubDate>
    </item>
    <item>
      <title>无法将 (Dimension(None)、Dimension(80)) 的元素转换为张量</title>
      <link>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</link>
      <description><![CDATA[我正在尝试阅读 LibRecommender 中有关模型训练过程的教程：https://librecommender.readthedocs.io/en/latest/tutorial.html
我停在了训练模型阶段，代码如下：
model = WideDeep(
task=&quot;ranking&quot;,
data_info=data_info,
embed_size=16,
n_epochs=2,
loss_type=&quot;cross_entropy&quot;,
lr={&quot;wide&quot;: 0.05, &quot;deep&quot;: 7e-4},
batch_size=2048,
use_bn=True,
hidden_​​units=(128, 64, 32),
)

model.fit(
train_data,
neg_sampling=True, # 对训练和评估数据执行负抽样
verbose=2,
shuffle=True,
eval_data=eval_data,
metrics=[&quot;loss&quot;, &quot;roc_auc&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;ndcg&quot;],
)

我收到错误：
TypeError：调用 Flatten.call() 时遇到异常。

无法将 (Dimension(None)、Dimension(80)) 的元素转换为 Tensor。请考虑将元素转换为受支持的类型。请参阅 https://www.tensorflow.org/api_docs/python/tf/dtypes 了解受支持的 TF 数据类型。

Flatten.call() 接收的参数：
• 输入=tf.Tensor(shape=(?, 5, 16), dtype=float32)

我不知道为什么会收到此错误？我假设本教程中没有错误，我按照所示按 1:1 执行。
我在 PyCharm 环境中工作并使用 Jupyter 笔记本。]]></description>
      <guid>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</guid>
      <pubDate>Sun, 14 Jul 2024 14:37:06 GMT</pubDate>
    </item>
    <item>
      <title>当我通过 docker-compose.yml 运行镜像 ollama 时，无法正确运行它</title>
      <link>https://stackoverflow.com/questions/78724837/i-cannot-run-the-image-ollama-correctly-when-i-run-it-through-docker-compose-yml</link>
      <description><![CDATA[我正在做一个项目，分析文本信息以从中提取特定数据。Python 中的正则表达式效果不佳，因为文本格式不断变化且没有一致性。因此，我决定使用语言模型来处理这些文本，如果文本包含我感兴趣的内容，则返回结果。
在开发程序时，我使用以下命令运行模型：
docker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama
之后，我在代码中发送了一个请求，如下所示：
url = &#39;http://localhost:11434/api/generate&#39;
data = { 
&quot;model&quot;: &quot;llama3&quot;,
&quot;prompt&quot;: f&quot;{input_text}&quot;,
}

这有效（尽管响应需要一点时间才能完成）生成）。
现在，当我尝试配置我的 docker-compose.yml 文件以启动语言模型容器时，它看起来像这样：
ollama:
container_name: ollama
image: ollama/ollama
volumes:
- ollama:/root/.ollama
ports:
- &quot;11434:11434&quot;

volumes:
ollama:

但我只收到 404 错误，这意味着找不到端点。我不明白我做错了什么。有人可以帮忙吗？
此外，有人知道语言模型是否支持多线程吗？我的脚本发送文本非常快，我不确定是否要限制向语言模型发送请求的速率，或者它是否可以处理多线程和异步请求。]]></description>
      <guid>https://stackoverflow.com/questions/78724837/i-cannot-run-the-image-ollama-correctly-when-i-run-it-through-docker-compose-yml</guid>
      <pubDate>Tue, 09 Jul 2024 09:38:52 GMT</pubDate>
    </item>
    </channel>
</rss>