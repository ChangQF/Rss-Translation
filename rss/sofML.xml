<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Dec 2023 03:15:34 GMT</lastBuildDate>
    <item>
      <title>GPT4/gpt 3.5 turb0 的支持/置信度得分</title>
      <link>https://stackoverflow.com/questions/77700790/support-confidence-score-for-gpt4-gpt-3-5-turb0</link>
      <description><![CDATA[计算以下 API 输出的置信度得分的方法或过程：
 openai.ChatCompletion.create
我打算使用 F1-score 等...连贯性分数等...
是否可以使用 azure open ai api 获取置信度分数 目前没有提供置信度值的开放式 ai api]]></description>
      <guid>https://stackoverflow.com/questions/77700790/support-confidence-score-for-gpt4-gpt-3-5-turb0</guid>
      <pubDate>Thu, 21 Dec 2023 22:10:51 GMT</pubDate>
    </item>
    <item>
      <title>人工神经网络实施中的故障排除</title>
      <link>https://stackoverflow.com/questions/77700758/troubleshooting-issues-in-artificial-neural-network-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77700758/troubleshooting-issues-in-artificial-neural-network-implementation</guid>
      <pubDate>Thu, 21 Dec 2023 22:01:55 GMT</pubDate>
    </item>
    <item>
      <title>如何将多元约束优化应用于神经网络模型？</title>
      <link>https://stackoverflow.com/questions/77700030/how-do-i-apply-multivariate-constrained-optimization-to-a-neural-network-model</link>
      <description><![CDATA[我的神经网络模型，采用 x1 和 x2 并返回 y。给定一些 x1，我想找到 x2（具有下限），它可以最小化 y 的值。我怎样才能做到这一点？我使用 pickle 保存了我的 nn。
我希望我可以将网络模型传递给 scipy.optimize.minimize() 作为最小化函数，但我无法弄清楚。]]></description>
      <guid>https://stackoverflow.com/questions/77700030/how-do-i-apply-multivariate-constrained-optimization-to-a-neural-network-model</guid>
      <pubDate>Thu, 21 Dec 2023 19:01:12 GMT</pubDate>
    </item>
    <item>
      <title>在 ML.NET 中使用 ONNX 模型进行预测</title>
      <link>https://stackoverflow.com/questions/77700012/make-predictions-using-an-onnx-model-in-ml-net</link>
      <description><![CDATA[我有一个预训练的 ONNX 模型，我想将其用作预测的基础。当我分析它时，我发现这个预训练模型只包含一个具有浮点值的向量。

但是，我想使用真实值进行预测。在我看来，我必须事先将实际值转换为浮点数（这就是我在这里使用 inputTransformed 变量尝试的），以便引擎可以做出预测。我该怎么做呢？这样还可以吗？
var onnxPipeline = mlContext.Transforms.ApplyOnnxModel(@“PATH”);
var Transformer = onnxPipeline.Fit(mlContext.Data.LoadFromEnumerable(Array.Empty()));
var TransformedValues = pipeline.Fit(transformedData).Transform(transformedData);
var onnxPredictionEngine = mlContext.Model.CreatePredictionEngine(transformer);
var pred = onnxPredictionEngine.Predict(inputTransformed).Score;
]]></description>
      <guid>https://stackoverflow.com/questions/77700012/make-predictions-using-an-onnx-model-in-ml-net</guid>
      <pubDate>Thu, 21 Dec 2023 18:57:47 GMT</pubDate>
    </item>
    <item>
      <title>使用有关单词的附加信息来改进 LSTM 预测</title>
      <link>https://stackoverflow.com/questions/77699985/using-additional-information-about-words-for-lstm-prediction-improvement</link>
      <description><![CDATA[我有一个单词列表，其中每个单词都有两个标签。
我训练了一个 LSTM 模型来预测序列中的下一个单词，但我也想以某种方式利用有关每个单词的附加信息来改进模型的预测。
如何为模型包装有关单词的附加信息？
我的数据：
我有一个包含 [word1、word2、word3]、[word2、word3、word4] 等序列的数据集，我有一个 csv，其中每个单词都标有 label1 和 label2：word、label1、label2。]]></description>
      <guid>https://stackoverflow.com/questions/77699985/using-additional-information-about-words-for-lstm-prediction-improvement</guid>
      <pubDate>Thu, 21 Dec 2023 18:51:53 GMT</pubDate>
    </item>
    <item>
      <title>我将 detectorron2 与 roboflow 结合使用，使用更快的 R CNN 进行缺陷检测。如何使用 model_final.pth 进行带注释的部署？</title>
      <link>https://stackoverflow.com/questions/77699854/i-used-detectron2-with-roboflow-for-defect-detection-using-faster-r-cnn-how-to</link>
      <description><![CDATA[我在 detectorron2 Faster rcnn 的帮助下开发了一个缺陷检测模型。我的数据集用 roboflow 注释并使用 api 调用它。经过训练，我得到了一个文件 model_final.pth。现在，不要每次都训练模型，而是给我使用 model_final.pth 来识别缺陷和带有注释的输出的代码
我尝试了一些方法，但输出图像没有标注注释。]]></description>
      <guid>https://stackoverflow.com/questions/77699854/i-used-detectron2-with-roboflow-for-defect-detection-using-faster-r-cnn-how-to</guid>
      <pubDate>Thu, 21 Dec 2023 18:24:17 GMT</pubDate>
    </item>
    <item>
      <title>tf Keras：model.fit 错误“未实现：不支持将字符串转换为浮点数”</title>
      <link>https://stackoverflow.com/questions/77699401/tf-keras-model-fit-error-unimplemented-cast-string-to-float-is-not-supported</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77699401/tf-keras-model-fit-error-unimplemented-cast-string-to-float-is-not-supported</guid>
      <pubDate>Thu, 21 Dec 2023 16:49:56 GMT</pubDate>
    </item>
    <item>
      <title>另一幅图像中的图像识别[关闭]</title>
      <link>https://stackoverflow.com/questions/77699133/image-identification-within-another-image</link>
      <description><![CDATA[我有一个网站的屏幕截图。
我还有 10-15 个品牌徽标/商标图像。
假设有5个这样的品牌。
我总共有大约 60 个徽标/商标图像。
现在我的任务是以某种方式识别网站屏幕截图是否具有这些徽标，然后相应地告诉屏幕截图所属的品牌。
我想要一个还返回结果的解决方案，因为如果网站不包含我拥有的徽标，则找不到熟悉的徽标。
我应该采取什么方法？
图像比例和徽标图像比例可能会有很大差异。
我尝试过使用opencv模板匹配，但结果不太好。它给出了很多误报，例如徽标的置​​信度很高，即使它不存在，并且它用于指示错误的品牌。
我希望这是高度准确的。如果系统有疑问，它可以跳过网站图像，但应该减少错误答案。]]></description>
      <guid>https://stackoverflow.com/questions/77699133/image-identification-within-another-image</guid>
      <pubDate>Thu, 21 Dec 2023 16:01:33 GMT</pubDate>
    </item>
    <item>
      <title>用于批量 RNAseq 数据和随机森林模型的机器学习的 R 代码</title>
      <link>https://stackoverflow.com/questions/77698532/r-code-for-machine-learning-of-bulk-rnaseq-data-and-random-forest-model</link>
      <description><![CDATA[我想从批量 RNAseq 数据（使用 R 代码）和随机森林模型进行机器学习，并且我需要一个完整的 R 代码，用于使用此模型进行机器学习，其中包括我的 RNAseq 数据的最佳预处理（a批量RNAseq文件training_data.csv），看看大约有多少基因。它可以或应该被包含在内，例如能够对数据中不同类型的细胞进行分类等。此外，还可以了解除了随机森林之外对于此类数据使用的最佳模型是什么。]]></description>
      <guid>https://stackoverflow.com/questions/77698532/r-code-for-machine-learning-of-bulk-rnaseq-data-and-random-forest-model</guid>
      <pubDate>Thu, 21 Dec 2023 14:12:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 EmbeddingSimilarityEvaluator() 解释增强 SBERT 训练的评估值 [关闭]</title>
      <link>https://stackoverflow.com/questions/77698048/interpretation-of-evaluation-values-of-augmented-sbert-training-with-embeddingsi</link>
      <description><![CDATA[我训练 BI 编码器以获得增强型 SBERT，并获得最终训练结果。
如何解释最终训练结果的以下输出？
EmbeddingSimilarityEvaluator：评估测试数据集上的模型：
余弦相似度：Pearson：0.8115 Spearman：0.7777
曼哈顿距离：皮尔逊：0.7318 斯皮尔曼：0.6822
欧几里得距离：Pearson：0.7332 Spearman：0.6835
点积相似度： Pearson：0.7780 Spearman：0.7543

0.7777387754875323 # test_evaluator(...) 的输出

以下代码片段的输出结果：
# 加载存储的augmented-sbert模型
bi_encoder = SentenceTransformer(bi_encoder_path)
test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name=&#39;sts-test&#39;)
test_evaluator（bi_encoder，output_path = bi_encoder_path）

是高人还是低人。斯皮尔曼比较好？他们提供有关相关性的信息。]]></description>
      <guid>https://stackoverflow.com/questions/77698048/interpretation-of-evaluation-values-of-augmented-sbert-training-with-embeddingsi</guid>
      <pubDate>Thu, 21 Dec 2023 12:43:54 GMT</pubDate>
    </item>
    <item>
      <title>如何从具有一对多关系的数据集开始创建用于机器学习的数据集？</title>
      <link>https://stackoverflow.com/questions/77696639/how-do-i-create-a-dataset-for-machine-learning-starting-from-datasets-that-have</link>
      <description><![CDATA[我有一个数据集（我们称之为 dataset1，它是一个 3000x6 数据集），结构如下：
X1,X2,X3,X4,X5,观察索引
D,3,3,0.12,0.3,0
B,2,3,0.2,0.27,1
B,4,5,0.2,0.18,2
A,3,5,0.28,0.24,3
B,3,5,0.17,0.29,4
列“ObservationIndex”包含一个扩展的整数序列，用作包含许多行（准确地说是 191 行）的 CSV 文件的索引。
因此，对于 dataset1 中的每一行，都存在一个对应的包含 191 行的 CSV 文件。
每个对应的 191 行 csv 的结构如下：
head_id,tail_id,initial_condition,目标变量
152331933,152432928,假,假
152331933,152432917,假,假
152331933,152331936,假,假
152331936,152943327,假,假
目的是预测目标变量，可以是 1 或 0。
如何创建可输入机器学习模型的数据集？
我的想法围绕着需要以某种方式创建新特征以形成正确的数据集。但是这个目标变量应该是什么？我已经排除了将所有 CSV 文件合并在一起的可能性，因为这会生成巨大的数据集。但是，我不确定在使用这些新功能训练模型后，如何恢复到对原始目标变量进行分类的原始问题。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77696639/how-do-i-create-a-dataset-for-machine-learning-starting-from-datasets-that-have</guid>
      <pubDate>Thu, 21 Dec 2023 08:31:21 GMT</pubDate>
    </item>
    <item>
      <title>如何将预测与标签相匹配 [CNN]？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77696572/how-do-i-match-predictions-with-labels-cnn</link>
      <description><![CDATA[我在 https://www.kaggle.com/datasets/iamsouravbanerjee/indian-food-images-dataset/data
Colab 文件：
https://colab.research.google.com/drive/1HWnVTUFf- CpZmNc16ZlQU_O5zwz_Elf4?usp=共享
我能够获得预测，但无法将其转换为菜名。我的项目需要它获取菜名，这样我才能获取它的营养。
如何让标签适用于此模型？或者这只是模型的错误
从tensorflow.keras.models导入load_model
从tensorflow.keras.preprocessing导入图像
从tensorflow.keras.applications.xception导入preprocess_input，decode_predictions
将 numpy 导入为 np

all_classes = [&#39;modak&#39;、&#39;bhindi_masala&#39;、&#39;butter_chicken&#39;、&#39;sohan_halwa&#39;、&#39;bhatura&#39;、&#39;poha&#39;、&#39;chicken_razala&#39;、&#39;imarti&#39;、&#39;qubani_ka_meetha&#39;、&#39;kajjikaya&#39;、&#39;makki_di_roti_sarson_da_saag&#39;、&#39;misi_roti&#39; , &#39;palak_paneer&#39;, &#39;naan&#39;, &#39;chikki&#39;, &#39;kachori&#39;, &#39;poornalu&#39;, &#39;anarsa&#39;, &#39;lassi&#39;, &#39;pithe&#39;, &#39;ghevar&#39;, &#39;sohan_papdi&#39;, &#39;chicken_tikka_masala&#39;, &#39;kadai_paneer&#39;, &#39; chhena_kheeri&#39;、&#39;rasgulla&#39;、&#39;lyangcha&#39;、&#39;chak_hao_kheer&#39;、&#39;aloo_gobi&#39;、&#39;navrattan_korma&#39;、&#39;daal_puri&#39;、&#39;phirni&#39;、&#39;chana_masala&#39;、&#39;kofta&#39;、&#39;dharwad_pedha&#39;、&#39;aloo_shimla_mirch&#39;、&#39;paneer_butter_masala &#39; , &#39;sandesh&#39;, &#39;double_ka_meetha&#39;, &#39;karela_bharta&#39;, &#39;maach_jhol&#39;, &#39;sheera&#39;, &#39;chicken_tikka&#39;, &#39;kalakand&#39;, &#39;misti_doi&#39;, &#39;biryani&#39;, &#39;ras_malai&#39;, &#39;daal_baati_churma&#39;, &#39;pootharekulu&#39;, &#39; gajar_ka_halwa&#39;、&#39;rabri&#39;、&#39;boondi&#39;、&#39;sutar_feni&#39;、&#39;aloo_tikki&#39;、&#39;malapua&#39;、&#39;薄饼&#39;、&#39;gulab_jamun&#39;、&#39;shankarpali&#39;、&#39;dal_makhani&#39;、&#39;ledikeni&#39;、&#39;kadhi_pakoda&#39;、&#39;shrikhand&#39; , &#39;cham_cham&#39;, &#39;bandar_laddu&#39;, &#39;unni_appam&#39;, &#39;aloo_matar&#39;, &#39;doodhpak&#39;, &#39;adhirasam&#39;, &#39;basundi&#39;, &#39;sheer_korma&#39;, &#39;mysore_pak&#39;, &#39;aloo_methi&#39;, &#39;dal_tadka&#39;, &#39;kakinada_khaja&#39;, &#39; gavvalu&#39;、&#39;dum_aloo&#39;、&#39;litti_chokha&#39;、&#39;ariselu&#39;、&#39;jalebi&#39;、&#39;kuzhi_paniyaram&#39;]
img_path = &#39;/content/JalebiIndia.jpg&#39; # 替换为图像路径
img = image.load_img(img_path, target_size=(100, 100)) # 调整大小以匹配模型的预期输入大小
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, 轴=0)
img_array = 预处理_输入(img_array)

# 获取模型预测
预测 = model_Xception.predict(img_array)

# 获取预测的类别索引
Predicted_class_index = np.argmax(预测)

# 将预测的类索引映射到您的自定义类标签
预测类标签 = 所有类[预测类索引]

print(&quot;预测类别：&quot;)
打印（预测的类标签）
]]></description>
      <guid>https://stackoverflow.com/questions/77696572/how-do-i-match-predictions-with-labels-cnn</guid>
      <pubDate>Thu, 21 Dec 2023 08:13:17 GMT</pubDate>
    </item>
    <item>
      <title>将变量从一个模块导入到另一个模块[关闭]</title>
      <link>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</guid>
      <pubDate>Mon, 18 Dec 2023 10:44:18 GMT</pubDate>
    </item>
    <item>
      <title>AutoTrain 高级 CLI：错误：无法识别的参数：--fp16 --use-int4</title>
      <link>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</link>
      <description><![CDATA[我目前在使用提供的自动训练工具在 Colab 笔记本中使用 LLM 模型微调数据时遇到问题。错误消息表明 autotrain 无法识别参数“--fp16”和“--use-int4”。我已经检查了文档和语法，但问题仍然存在。您能否提供解决此问题的指导或提供有关任何潜在解决方案的见解？谢谢。
/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13：
 UserWarning：无法加载图像Python扩展：&#39;/usr/local/lib/python3.10/dist-packages/torchvision/image.so：未定义符号：_ZN3c104cuda9SetDeviceEi&#39;如果您不打算使用`torchvision中的图像功能。 io`，你可以忽略这个警告。否则，您的环境可能有问题。在从源代码构建“torchvision”之前，您是否安装了“libjpeg”或“libpng”？ warn( 用法: autotrain  [] AutoTrain 高级 CLI: 错误: 无法识别的参数: --fp16 --use-int4

错误的屏幕截图
直到昨天，这段代码在这个 https://github.com/huggingface/autotrain-advanced 存储库中给出的 colab 笔记本上运行良好微调LLM，现在出现此错误。]]></description>
      <guid>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</guid>
      <pubDate>Fri, 15 Dec 2023 07:53:31 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace AutoModelForCasualLM “仅解码器架构”警告，即使在设置 padding_side='left' 后也是如此</title>
      <link>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</link>
      <description><![CDATA[我正在使用
AutoModelForCausalLM 和 AutoTokenizer 使用 DialoGPT 生成文本输出。
无论出于何种原因，即使使用 Huggingface 提供的示例，我也会收到此警告：
&lt;块引用&gt;
正在使用仅解码器架构，但检测到右填充！为了正确的生成结果，请在初始化分词器时设置 padding_side=&#39;left&#39;。

从变压器导入 AutoModelForCausalLM, AutoTokenizer
进口火炬


tokenizer = AutoTokenizer.from_pretrained(“microsoft/DialoGPT-medium”)
模型 = AutoModelForCausalLM.from_pretrained(“microsoft/DialoGPT-medium”)

# 我们聊5行吧
对于范围（5）中的步骤：
    # 对新的用户输入进行编码，添加 eos_token 并在 Pytorch 中返回一个张量
    new_user_input_ids = tokenizer.encode(input(“&gt;&gt;用户:”) + tokenizer.eos_token, return_tensors=&#39;pt&#39;)

    # 将新的用户输入标记附加到聊天历史记录中
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) 如果步骤 &gt; 0 其他 new_user_input_ids

    # 生成响应，同时将总聊天历史记录限制为 1000 个令牌，
    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)

    # 漂亮地打印机器人最后的输出令牌
    print(“DialoGPT: {}”.format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0],skip_special_tokens=True)))

代码由 微软在 Huggingface 的模型卡上
我尝试将 padding_side=&#39;left&#39; 添加到标记生成器，但这不会改变任何内容。
显然（从一些阅读来看）DialoGPT 无论如何都希望在右侧填充？
我无法弄清楚这一点，当我尝试谷歌搜索时几乎没有结果。
我能够像这样抑制警告：
from Transformers.utils 导入日志记录

记录.set_verbosity_info()

但这似乎不是最好的答案？]]></description>
      <guid>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</guid>
      <pubDate>Fri, 09 Dec 2022 20:39:39 GMT</pubDate>
    </item>
    </channel>
</rss>