<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 20 Dec 2023 06:14:52 GMT</lastBuildDate>
    <item>
      <title>我应该如何在机器学习中正确使用交叉验证技术（cross_val_score）？</title>
      <link>https://stackoverflow.com/questions/77689532/how-should-i-use-cross-validation-technique-cross-val-score-in-machine-learnin</link>
      <description><![CDATA[我很难理解应该如何正确使用交叉验证技术（在本例中为cross_val_score）。
我正在研究机器学习回归问题。所有预处理步骤（插补、变换、缩放、编码等）均已完成。现在我需要决定使用哪种机器学习回归算法。
数据由 2 个文件组成：

train.csv - 独立特征 + 目标（1460 行）
test.csv - 仅独立特征（1459 行）

我的想法是使用 cross_val_score 选择最佳基础回归模型，然后在最佳基础模型上使用 GridSearchCV 来找到它的最佳超参数。
1) 如果我想使用 cross_val_scrore，我应该使用 train_test_split 分割 train.csv 数据并使用 X_train 和 y_train （1168 行）还是可以使用 X_train_full 和 y_train_full （1460 行）？&lt; /p&gt;
train_df = pd.read_csv(&#39;train.csv&#39;)

X_train_full = train_df.drop(&#39;目标&#39;), 轴 = 1
y_train_full = train_df[&#39;目标&#39;]

X_train，X_holdout，y_train，y_holdout = train_test_split（X_train_full，y_train_full，test_size = 0.2，random_state = 22）

2) 下面是我用来决定需要使用哪种基本回归机器学习模型的代码。我使用了 X_train 和 y_train，认为我应该以某种方式使用 X_holdout 和 y_holdout 来验证/确认决定，但我不知道这是否是正确的方法以及在这种情况下下一步该怎么做。
base_models = [

    (“线性回归”, LinearRegression()),
    (“岭回归”，Ridge())，
    (“套索回归”，Lasso())，
    （“弹性网络回归”，ElasticNet()），
    (“决策树”，DecisionTreeRegressor())，
    (“KNN 回归器”，KNeighborsRegressor())，
    (“SVR”，SVR())，
    （“随机森林”，RandomForestRegressor（）），
    (“额外树回归器”，ExtraTreesRegressor())，
    (“AdaBoost回归器”，AdaBoostRegressor())，
    (“梯度增强回归器”，GradientBoostingRegressor())，
    (“XGBoost”, XGBRegressor()),
    (“LightGBM”，LGBMRegressor())，
    (“CatBoost”，CatBoostRegressor(loss_function=&#39;RMSE&#39;，logging_level=&#39;Silent&#39;))

    ]

# 初始化列表来存储数据

基本模型名称 = []
base_model_rmse_scores = []

# 初始化各个交叉验证折叠分数的列表

cv_fold_scores = [[] for _ in range(10)] # 假设折叠 10 次

# 迭代模型并附加到列表

对于名称，base_models 中的模型：

    # 获取每次折叠的交叉验证分数

    分数 = np.sqrt(-cross_val_score(模型, X_train, y_train, 评分=“neg_mean_squared_error”, cv=10, n_jobs = -1))

    # 附加模型名称

    base_model_names.append(名称)

    # 添加跨折叠的均方根误差 (RMSE)

    base_model_rmse_scores.append(np.mean(分数))

    # 附加单独的折叠分数

    对于 i，枚举中的分数（分数）：
        cv_fold_scores[i].append(分数)

    # 从列表创建 DataFrame

    base_models_results_df = pd.DataFrame({“模型”: base_model_names, “Mean_RMSE”: base_model_rmse_scores})

    # 添加各个交叉验证折叠分数的列

    对于我，枚举中的fold_scores（cv_fold_scores）：
        base_models_results_df[f&quot;Fold_{i+1}_RMSE&quot;] = Fold_scores

    # 设置“模型”列作为索引

    base_models_results_df = base_models_results_df.set_index(“模型”)

    # 按均方根误差 (RMSE) 升序对 DataFrame 进行排序

    base_models_results_df = base_models_results_df.sort_values（by=“Mean_RMSE”，升序=True）

    基础模型结果df


从上图可以看出，CatBoost 是最好的基础模型，其平均 RMSE 为 0.319293。
3) 我可以做些什么来确保这个特定模型最适合使用吗？是否可以过度拟合或不足？我可以使用 X_holdout 和 y_holdout 集以某种方式验证它吗？如果我需要使用 X_train_full 和 y_train_full，这种情况下该怎么办？我非常困惑，希望能在这里找到所有答案。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/77689532/how-should-i-use-cross-validation-technique-cross-val-score-in-machine-learnin</guid>
      <pubDate>Wed, 20 Dec 2023 06:11:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么我在安装requirements.txt时收到此错误</title>
      <link>https://stackoverflow.com/questions/77689351/why-i-was-getting-this-error-while-installing-requirements-txt</link>
      <description><![CDATA[PS C:\Users\SAI BHUVAN\Documents\EndToEndMLProject&gt; pip install -r 要求.txt
获取文件:///C:/Users/SAI%20BHUVAN/Documents/EndToEndMLProject（来自-rrequirements.txt（第10行））
安装构建依赖项...完成
检查构建后端是否支持 build_editable ...完成
获取构建可编辑的需求...完成
准备可编辑元数据 (pyproject.toml) ...错误
错误：子进程退出并出现错误
× 准备可编辑元数据 (pyproject.toml) 未成功运行。
│ 退出代码：1
╰─&gt; [21行输出]
回溯（最近一次调用最后一次）：
文件“C:\Users\SAI BHUVAN\AppData\Local\Programs\Python\Python311\Lib\site-packages\pip_vendor\pyproject_hooks_in_process_in_process.py”，第 353 行，位于
主要的（）
文件“C：\ Users \ SAI BHUVAN \ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ pip_vendor \ pyproject_hooks_in_process_in_process.py”，第335行，在main中
json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C：\ Users \ SAI BHUVAN \ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ pip_vendor \ pyproject_hooks_in_process_in_process.py”，第181行，在prepare_metadata_for_build_editable中
返回钩子（元数据目录，配置设置）
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C：\ Users \ SAI BHUVAN \ AppData \ Local \ Temp \ pip-build-env-fmoiyisg \ overlay \ Lib \ site-packages \ setuptools \ build_meta.py”，第446行，在prepare_metadata_for_build_editable中
返回 self.prepare_metadata_for_build_wheel(
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\SAI BHUVAN\AppData\Local\Temp\pip-build-env-fmoiyisg\overlay\Lib\site-packages\setuptools\build_meta.py”，第368行，在prepare_metadata_for_build_wheel中
self._bubble_up_info_directory(metadata_directory, “.egg-info”)
文件“C:\Users\SAI BHUVAN\AppData\Local\Temp\pip-build-env-fmoiyisg\overlay\Lib\site-packages\setuptools\build_meta.py”，第 337 行，位于 _bubble_up_info_directory 中
info_dir = self._find_info_directory(元数据目录, 后缀)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^
文件“C:\Users\SAI BHUVAN\AppData\Local\Temp\pip-build-env-fmoiyisg\overlay\Lib\site-packages\setuptools\build_meta.py”，第 348 行，位于 _find_info_directory 中
assert len(candidates) == 1, f“找到多个 {suffix} 目录”
^^^^^^^^^^^^^^^^^^^^^^
AssertionError：找到多个 .egg-info 目录
[输出结束]
注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：元数据生成失败
× 生成包元数据时遇到错误。
╰─&gt;请参阅上面的输出。
注意：这是上面提到的包的问题，​​而不是 pip 的问题。
提示：详细信息请参阅上文。
我尝试解决这个问题，但无法解决。]]></description>
      <guid>https://stackoverflow.com/questions/77689351/why-i-was-getting-this-error-while-installing-requirements-txt</guid>
      <pubDate>Wed, 20 Dec 2023 05:19:33 GMT</pubDate>
    </item>
    <item>
      <title>找不到满足张量流要求的版本（来自版本：无）没有找到张量流的匹配分布</title>
      <link>https://stackoverflow.com/questions/77689277/could-not-find-a-version-that-satisfies-the-requirement-tensorflow-from-version</link>
      <description><![CDATA[即使我已经升级了我的 python 及其 64 位，我仍然遇到这个问题。


错误：找不到满足张量流要求的版本（来自版本：无）
错误：找不到张量流的匹配分布



同时我的 python 是最新的。


Python 3.12.1



我已经尝试更新 Python，但仍然遇到有关 Tensorflow 安装的问题。任何人都可以帮助我。我什至安装了 C++ vc_redist.x64.exe]]></description>
      <guid>https://stackoverflow.com/questions/77689277/could-not-find-a-version-that-satisfies-the-requirement-tensorflow-from-version</guid>
      <pubDate>Wed, 20 Dec 2023 04:55:01 GMT</pubDate>
    </item>
    <item>
      <title>如何制作一个单神经元的神经网络？</title>
      <link>https://stackoverflow.com/questions/77688349/how-can-i-make-a-one-neuron-neural-network</link>
      <description><![CDATA[我想制作一个像 w1x1+w2x2+w3*x3+b1 这样的单神经元函数
我的训练输入是
&lt;前&gt;&lt;代码&gt; [1, 0, 0],
                    [0, 1, 0],
                    [0,0,1],
                    [1, 1, 0],
                    [0,1,1],
                    [1,1,1],
                    [2, 0, 0]

训练输出是：
&lt;前&gt;&lt;代码&gt;[1,2,0,1,0,2,3]

我尝试使用一种热编码来编写代码，但失败了。我是 AI 编码新手，不想使用任何 AI 库，例如 Pytorch 和 Tensorflow 或 scikitlearn。这个问题困扰了我两周，我也尝试了不同的代码，但没有成功。这是一个示例代码，我知道它是错误的，但它可能会给您带来见解。
&lt;前&gt;&lt;代码&gt;
将 numpy 导入为 np
将 pandas 导入为 pd

定义 sigmoid(x):
    返回 1 /(1+np.exp(-x))

def sigmoid_derivative(x):
    返回 x*(1-x)

训练输入 = np.array([
                    [1,0,0],
                    [0, 1, 0],
                    [0,0,1],
                    [1, 1, 0],
                    [0,1,1],
                    [1,1,1],
                    [2, 0, 0]
                ]）

Training_outputs = np.array([[1,2,0,1,0,2,3]]).T

np.随机.种子(1)

synaptic_weights = 2 * np.random.random((3,1))-1
print(&#39;随机起始突触权重：&#39;)
打印（突触权重）

对于范围（2000）内的迭代：

    输入层=训练输入

    输出 = sigmoid(np.dot(input_layer, synaptic_weights))

    错误 = 训练输出 - 输出

    调整 = 误差 * sigmoid_derivative(输出)

    synaptic_weights += np.dot(input_layer.T,调整)

print(&#39;训练后的突触权重：&#39;)
打印（突触权重）

print(&#39;训练后的输出：&#39;)
打印（输出）


我希望它输出像 [0,1,0,0] 这样的结果，意思是 1 作为一个热编码。我不知道该怎么做。]]></description>
      <guid>https://stackoverflow.com/questions/77688349/how-can-i-make-a-one-neuron-neural-network</guid>
      <pubDate>Tue, 19 Dec 2023 22:33:45 GMT</pubDate>
    </item>
    <item>
      <title>我正在寻求建议来解决我创建的问题，我基本上是在优化花园的布局，但需要考虑许多因素[关闭]</title>
      <link>https://stackoverflow.com/questions/77688112/im-looking-for-advice-to-solve-a-problem-i-created-where-i-am-basically-optimiz</link>
      <description><![CDATA[假设我有一堆灌木丛，我为具有以下列名称的灌木丛创建一个数据集。
布什类型（或名称），
布什需要阳光，
需要灌木土壤，
布什高度，
衬套宽度（衬套直径），
布什值得注意的营养需求，
布什著名的营养提供（土壤），
布什昆虫吸引，
布什昆虫分散注意力，
ETC....
好吧，我想将这些灌木丛放在我使用 x、y、z 坐标创建的 3-D 地图上（我可以在其中给出湿度和土壤类型等坐标值），但我希望优化灌木丛的位置（基本上我正在尝试优化我的花园的布局）。
我的意思是，假设我住在北半球，所以我想要南方最短的灌木丛和北方最高的灌木丛，并且我想充分利用我的空间，所以如果有一个灌木丛很小并且不不需要太多阳光，那么我希望程序将其放置在另一个更高的灌木丛的叶子下，如果一个灌木丛吸引蚜虫，另一个灌木吸引瓢虫（瓢虫吃蚜虫），我想把它们放在彼此附近，并且相同根据营养需求，如果一棵灌木向土壤中添加了大量氮，那么我希望该程序将这些植物放置在一起。问题是程序需要考虑很多因素，我不知道如何让计算机进行这种优化，因为虽然一件事可能对两种植物昆虫有益，但它可能与土壤方面相反。我会想出一个每个列重要性的排名系统吗？我需要考虑的另一件事是，我可能只有一株这种类型的灌木，但我也可以拥有 12 株这种其他类型的灌木。这是我想知道的关于这个问题的信息：
这是什么类型的问题（比如我可以查找什么来了解人们如何处理类似的问题）以及我应该查看哪些资源来学习如何解决这样的问题？
我想做研究以了解如何最好地编码，所以任何建议都会非常有帮助！我是一名初学者编码员，只有一点点制作不同计算器的经验，并完成了基本的机器学习课程，只是为了让你们知道我在哪里。感谢您为我提供的任何帮助！
我尝试对优化思维主题进行研究，这将提供一些类似的场景，但它比这更深入，因此比我预期的更深。接下来我尝试思考，由于我对优化不太了解，我该如何解决这个问题，并且我决定考虑如何将我学到的机器学习知识应用到这个问题上，但这似乎并不可行就像无监督或监督机器学习的最佳应用一样。因此，我试图找到类似的问题，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77688112/im-looking-for-advice-to-solve-a-problem-i-created-where-i-am-basically-optimiz</guid>
      <pubDate>Tue, 19 Dec 2023 21:32:55 GMT</pubDate>
    </item>
    <item>
      <title>AWS Sagemaker/ML 操作</title>
      <link>https://stackoverflow.com/questions/77687831/aws-sagemaker-ml-ops</link>
      <description><![CDATA[我在尝试使用 AWS Sagemaker 端点进行推理时遇到 AWS 实例问题。我需要的图像 ml.g5.12xlargem 不在我的配额范围内。我需要这个，或者我的模型尺寸太大。当我开票时，他们只是告诉我使用当前的配额，但我没有现金可以浪费。
现在我在 Colab Notebook 中微调了 Llama-2-7b-chat，并手动将其上传到 s3 存储桶中。
有什么办法可以适当增加配额吗？致电 AWS Support 对您有用吗？我的s3存储桶包含model.tar.gz，可能格式不正确，因此太大。
解决方案可能是按照 Sagemaker Studio 中的说明进行部署：
https://aws.amazon.com/blogs/machine-learning/llama-2-foundation-models-from-meta-are-now-available-in-amazon-sagemaker-jumpstart/
但如果我不在 Sagemaker Studio 中进行训练，这是否可能：
https： //github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/llama-2-finetuning.ipynb
这可能有效，但重新训练需要时间。我仍然会遇到同样的问题，因为该实例不在我的配额内。
或者我应该使用不同的文本生成模型，称为 Phi-2。它的性能比 llama 2 稍好一些，是 2.7B 参数，比 7B Llama 模型少很多。它可能能够运行成本低得多且可用的计算。它需要迁移到 Azure AI Studio，并对功能进行完整的重新培训，以及学习曲线。

增加配额或减小模型大小的某种方法
在 Sagemaker studio 中以略有不同的方式训练和运行推理
使用不同的文本生成模型 (Phi-2)，并在 Azure AI Studio 中执行此操作（我计划在将来执行此操作，只有在必要时我才会立即执行此操作）
]]></description>
      <guid>https://stackoverflow.com/questions/77687831/aws-sagemaker-ml-ops</guid>
      <pubDate>Tue, 19 Dec 2023 20:26:02 GMT</pubDate>
    </item>
    <item>
      <title>新的 ML 模型具有较低的历元损失，但平均 RMSE 较高。如何/为什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77687730/new-ml-model-with-lower-epoch-loss-but-higher-average-rmse-how-why</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77687730/new-ml-model-with-lower-epoch-loss-but-higher-average-rmse-how-why</guid>
      <pubDate>Tue, 19 Dec 2023 20:04:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么 MLNet 没有得出合理的结论</title>
      <link>https://stackoverflow.com/questions/77687481/why-is-mlnet-not-coming-to-reasonable-conclusions</link>
      <description><![CDATA[我有一个模型，它目前基于合理的推理，然后对其进行测试来支持它。问题是预测多人游戏中的获胜者。
所以我希望使用一些机器学习来改进它。第一次尝试是做大小玩家的游戏，数据如下col0[标签],col1-col10[玩家一数据],col11-20[玩家二数据]...
数据是平衡的，因此每个类别的可能性与其他类别的可能性相同。
当样本用完时，这能够以 24% 的准确率进行预测，但问题是我知道，如果你只按每个玩家的第一个列排序，你会在样本中获得 27% 的准确率（并且你需要向你的老板为什么会这样）。我还知道所有其他数据都具有预测能力，可以解释原因并通过回归证明这一点，并且它们都在现实世界中发挥了与测试相同的准确性。
我尝试简化 MLNet 的问题，将其变成二元分类问题，并让它预测两个玩家的相对成功，数据再次平衡。这与第一列的执行方式几乎相同，但我可以看到它使用其他参数，如果我使用它们，我会得到比这产生的更好的结果。
经过几个小时的训练，我终于有了一个 6 人游戏的模型，它与第一个排序排序达到了同等水平，但我觉得我不能相信它，因为它无意中接触到了样本外的数据适者生存，淘汰在样本外表现不佳的模型。
我使用“Microsoft.ML”在本地运行了这个但我尝试过不同的自动化机器学习提供商 azure、amazon、google，但它们都未能产生更好的结果。当人们不断告诉我 ML 很棒，你可以向其扔数据，但就这个问题而言，它只是不如人类洞察力时，我是否遗漏了一些东西。
请注意，六人游戏有 1,000,000 条记录，我将其分解为两人游戏的 10,000,000 条记录。
关于提高性能有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77687481/why-is-mlnet-not-coming-to-reasonable-conclusions</guid>
      <pubDate>Tue, 19 Dec 2023 19:11:11 GMT</pubDate>
    </item>
    <item>
      <title>用于优化的多变量梯度上升问题</title>
      <link>https://stackoverflow.com/questions/77687410/problem-with-multivariable-gradient-ascent-for-optimization</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77687410/problem-with-multivariable-gradient-ascent-for-optimization</guid>
      <pubDate>Tue, 19 Dec 2023 18:56:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 LightGBM.LGBMRanker 执行交叉验证，同时将组保持在一起？</title>
      <link>https://stackoverflow.com/questions/77687360/how-to-perform-cross-validation-with-lightgbm-lgbmranker-while-keeping-groups-t</link>
      <description><![CDATA[我遇到了搜索问题，我有一个查询和网址数据集。对于给定的查询，每对（查询、网址）都有一个相关性（目标），即一个应保留网址顺序的浮点数。
我想对我的 lightgbm.LGBMRanker 模型进行交叉验证，目标为 ndcg。
我浏览了文档，发现将实例保留在同一个组中非常重要，因为实例实际上是一个包含所有关联 URL 的查询。
然而，我对此有一个问题，因为我收到以下错误：
ValueError: 计算 NDCG 仅当存在超过 1 个文档时才有意义。反而得到了1。

我使用了调试器，虽然我的数据集中没有任何大小小于 2 的组，但在 _feval 函数中我有较小的组，这意味着 cv() 函数实际上并未将组保持在一起。
在 lightgbm.cv 我看到没有 LGBMRanker。
但我可以看到函数 lightbm.cv 精确指出通过参数传递的值优先于通过参数提供的值。我的理解是这个值被传递给cv函数的底层模型。
这是我到目前为止的代码：
def eval_model(
    自己，
    模型：lightgbm.LGBMRanker，
    k_fold: int = 3,
    种子：int = 42，
）：
    “”“”用 NDCG 进行评估“”“”

    def _feval(y_pred: np.ndarray, lgb_dataset: lightgbm.basic.Dataset):
        y_true = lgb_dataset.get_label()
        serp_sizes = lgb_dataset.get_group()

        ndcg_值 = []
        开始=0
        对于 serp_sizes 中的大小：
            结束=开始+大小
            y_true_serp, y_pred_serp = y_true[开始:结束], y_pred[开始:结束]
            ndcg_serp = sklearn.metrics.ndcg_score(
                [y_true_serp]，[y_pred_serp]，k=10
            ）
            ndcg_values.append(ndcg_serp)
            开始=结束

        eval_name =“my-ndcg”；
        eval_result = np.mean(ndcg_values)
        更大更好=真
        返回 eval_name、eval_result、greater_is_better

    lgb_dataset = lightgbm.Dataset(data=self.X, label=self.y, group=self.serp_sizes)
    cv_结果 = lightgbm.cv(
        params={**model.get_params(), &quot;group&quot;: self.serp_sizes},
        train_set=lgb_dataset,
        num_boost_round=1_000,
        nfold=k_fold,
        分层=假，
        种子=种子，
        费瓦尔=_费瓦尔,
    ）
    ndcg = np.mean(cv_results[“my-ndcg”])

    返回 NDCG

我的错误/误解在哪里？
是否有一个简单的解决方法可以使用 lightgbm.LGBMRanker 执行交叉验证，并将组保持在一起？]]></description>
      <guid>https://stackoverflow.com/questions/77687360/how-to-perform-cross-validation-with-lightgbm-lgbmranker-while-keeping-groups-t</guid>
      <pubDate>Tue, 19 Dec 2023 18:47:13 GMT</pubDate>
    </item>
    <item>
      <title>python中的矩阵乘法以获得成本函数[关闭]</title>
      <link>https://stackoverflow.com/questions/77686666/matrix-multiplication-in-python-to-get-cost-function</link>
      <description><![CDATA[谁能告诉我为什么我的代码给出了错误的输出？
评论的是我的。
# 分级函数：cofi_cost_func
#UNQ_C1

def cofi_cost_func(X, W, b, Y, R, lambda_):
    ”“”
    返回基于内容的过滤的成本
    参数：
      X (ndarray (num_movies,num_features))：项目特征矩阵
      W (ndarray (num_users,num_features)) ：用户参数矩阵
      b (ndarray (1, num_users) ：用户参数向量
      Y (ndarray (num_movies,num_users) ：电影用户评分矩阵
      R (ndarray (num_movies,num_users) ：矩阵，其中 R(i, j) = 1 如果第 i 个电影由第 j 个用户评分
      lambda_ (float): 正则化参数
    返回：
      J（浮点数）：成本
    ”“”
    nm, nu = Y.shape
    J = 0
    ### 从这里开始代码 ###
    
# J+= np.sum(np.square((R*(X@(W.T)+b)-Y)))/2
# J+= (lambda_/2)*np.sum(np.square(W))
# J+= (lambda_/2)*np.sum(np.square(X))
        
    对于 j 在范围内（nu）：
        w = W[j,:]
        b_j = b[0,j]
        对于范围内的 i（nm）：
            x = X[i,:]
            y = Y[i,j]
            r = R[i,j]
            J += np.square(r * (np.dot(w,x) + b_j - y ) )
    J = J/2
    J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))
            
            
            
    
    
    ### 在此结束代码 ###

    返回J

我不知道为什么使用我的成本函数代码测试会失败，我只是尝试在不使用循环的情况下做同样的事情。
 J+= np.sum(np.square((R*(X@(W.T)+b)-Y)))/2
    J+= (lambda_/2)*np.sum(np.square(W))
    J+= (lambda_/2)*np.sum(np.square(X))
]]></description>
      <guid>https://stackoverflow.com/questions/77686666/matrix-multiplication-in-python-to-get-cost-function</guid>
      <pubDate>Tue, 19 Dec 2023 16:34:22 GMT</pubDate>
    </item>
    <item>
      <title>机器学习后指标结果相同的问题</title>
      <link>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</guid>
      <pubDate>Tue, 19 Dec 2023 15:36:36 GMT</pubDate>
    </item>
    <item>
      <title>绘制K折交叉验证的ROC曲线</title>
      <link>https://stackoverflow.com/questions/57708023/plotting-the-roc-curve-of-k-fold-cross-validation</link>
      <description><![CDATA[我正在处理不平衡的数据集。在应用 ML 模型之前，我将数据集分为测试集和训练集，然后应用 SMOTE 算法来平衡数据集。我想应用交叉验证并绘制每个折叠的 ROC 曲线，显示每个折叠的 AUC，并在图中显示 AUC 的平均值。我将重采样的训练集变量命名为 X_train_res 和 y_train_res，以下是代码：
cv = StratifiedKFold(n_splits=10)
分类器= SVC（内核=&#39;sigmoid&#39;，概率= True，random_state = 0）

tprs = []
曲线面积=[]
Mean_fpr = np.linspace(0, 1, 100)
plt.figure(figsize=(10,10))
我=0
对于火车，在 cv.split(X_train_res, y_train_res) 中测试：
    probas_ = classifier.fit(X_train_res[训练], y_train_res[训练]).predict_proba(X_train_res[测试])
    # 计算 ROC 曲线并计算曲线面积
    fpr, tpr, 阈值 = roc_curve(y_train_res[测试], probas_[:, 1])
    tprs.append(interp(mean_fpr, fpr, tpr))
    tprs[-1][0] = 0.0
    roc_auc = auc(fpr, tpr)
    aucs.append(roc_auc)
    plt.plot(fpr, tpr, lw=1, alpha=0.3,
             label=&#39;ROC 折叠 %d (AUC = %0.2f)&#39; % (i, roc_auc))

    我 += 1
plt.plot([0, 1], [0, 1], 线型=&#39;--&#39;, lw=2, 颜色=&#39;r&#39;,
         标签=&#39;机会&#39;，alpha=.8)

mean_tpr = np.mean(tprs, 轴=0)
平均值_tpr[-1] = 1.0
mean_auc = auc(mean_fpr,mean_tpr)
std_auc = np.std(aucs)
plt.plot(mean_fpr,mean_tpr,颜色=&#39;b&#39;,
         label=r&#39;平均 ROC (AUC = %0.2f $\pm$ %0.2f)&#39; % (mean_auc, std_auc),
         lw=2，阿尔法=.8)

std_tpr = np.std(tprs, 轴=0)
tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
plt.fill_ Between(mean_fpr, tprs_lower, tprs_upper, color=&#39;grey&#39;, alpha=.2,
                 标签=r&#39;$\pm$ 1 标准。开发。”）

plt.xlim([-0.01, 1.01])
plt.ylim([-0.01, 1.01])
plt.xlabel(&#39;误报率&#39;,fontsize=18)
plt.ylabel(&#39;真阳性率&#39;,fontsize=18)
plt.title(&#39;SVM的交叉验证ROC&#39;,fontsize=18)
plt.legend(loc=“右下”, prop={&#39;size&#39;: 15})
plt.show()

以下是输出：

请告诉我绘制交叉验证的 ROC 曲线的代码是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/57708023/plotting-the-roc-curve-of-k-fold-cross-validation</guid>
      <pubDate>Thu, 29 Aug 2019 10:18:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用分类变量运行聚类</title>
      <link>https://stackoverflow.com/questions/52401225/how-to-run-clustering-with-categorical-variables</link>
      <description><![CDATA[我尝试仅使用分类变量运行聚类。由于 Kmeans 仅适用于数值数据，是否有可用的聚类技术？
我有 30 个变量，如邮政编码、年龄组、爱好、首选频道、婚姻状况、信用风险（低、中、高）、教育状况等。如果我将每个变量转换为虚拟变量并运行 kmeans，我将有 90 列（30*3 - 假设每个变量有 4 个因子）。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/52401225/how-to-run-clustering-with-categorical-variables</guid>
      <pubDate>Wed, 19 Sep 2018 08:16:04 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中参数、特征和类之间的区别</title>
      <link>https://stackoverflow.com/questions/35819869/difference-between-parameters-features-and-class-in-machine-learning</link>
      <description><![CDATA[我是机器学习和自然语言处理方面的新手。
我总是对这三个术语感到困惑？
据我了解：
class：我们的模型输出的各种类别。给出一个人的名字，确定他/她是男性还是女性？
假设我正在使用朴素贝叶斯分类器。
我的功能和参数是什么？
此外，上述单词的一些可互换使用的别名是什么？]]></description>
      <guid>https://stackoverflow.com/questions/35819869/difference-between-parameters-features-and-class-in-machine-learning</guid>
      <pubDate>Sat, 05 Mar 2016 21:02:05 GMT</pubDate>
    </item>
    </channel>
</rss>