<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Dec 2024 01:24:43 GMT</lastBuildDate>
    <item>
      <title>时间序列运动捕捉数据的 PCA 图聚类问题</title>
      <link>https://stackoverflow.com/questions/79263104/pca-plot-clustering-issue-with-time-series-motion-capture-data</link>
      <description><![CDATA[我正在使用 PCA 对手部动作捕捉数据的时间序列数据集进行降维，并遇到了意外的聚类行为。以下是我的过程和我面临的问题的详细信息。

上下文：
我有一个使用智能手套捕捉的手部动作记录数据集，每个手指上有 4 个传感器。每个传感器提供：

位置值：X、Y、Z
旋转值：X、Y、Z、W

数据记录在单独的文件中，每个文件包含 10 次手势重复。这些重复随后被分割成单独的文件（每个文件 1 个重复），贴上标签，并合并成一个大型数据集。
在对数据进行标签编码和缩放后，我使用以下代码应用 PCA 进行降维：
# PCA 用于降维
pca_components = 3
pca = PCA(n_components=pca_components)
x_train_pca = pca.fit_transform(x_train_scaled)

为了可视化结果，我创建了一个 PCA 摘要图，其中每个数据段都表示为一个点。目标是查看每个手势的 10 个点的聚类。以下是总结 PCA 结果的代码：
# 将 PCA 结果转换为 DataFrame 以关联标签
x_train_pca_df = pd.DataFrame(x_train_pca, columns=[&#39;PC1&#39;, &#39;PC2&#39;, &#39;PC3&#39;])
x_train_pca_df[&#39;label&#39;] = y_train_data
x_train_pca_df[&#39;segment&#39;] = train_data[&#39;segment&#39;].values.ravel()

# 计算每个数据集的 PC1 和 PC2 的平均值（将每个数据集总结为一个点）
summary_train_points = x_train_pca_df.groupby([&#39;label&#39;, &#39;segment&#39;]).mean().reset_index()

以下是我用来绘制总结 PCA 的方法数据：
def plot_3d_pca_matplotlib(summary_points, title=&#39;3D PCA Plot&#39;):
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111,projection=&#39;3d&#39;)

# 对于每个唯一数据集（标签），分散点并分配图例条目
unique_labels = summary_points[&#39;label&#39;].unique()

for label in unique_labels:
# 过滤当前标签的数据
filtered_data = summary_points[summary_points[&#39;label&#39;] == label]

# 当前标签点的散点图
ax.scatter(filtered_data[&#39;PC1&#39;],
filtered_data[&#39;PC2&#39;],
filtered_data[&#39;PC3&#39;],
label=label)

ax.set_xlabel(&#39;PCA 组件 1&#39;)
ax.set_ylabel(&#39;PCA 组件 2&#39;)
ax.set_zlabel(&#39;PCA 组件 3&#39;)
ax.set_title(title)
ax.legend(title=&quot;Labels&quot;, loc=&quot;center left&quot;, bbox_to_anchor=(1.05, 0.7))

plt.subplots_adjust(left=0.05, right=0.75)
plt.show()


问题：
当我为相同手势记录一组新数据并绘制 PCA 结果时，我希望看到每个手势有 20 个点（10 个来自原始数据的点 + 10 个来自新数据的点）的聚类。
相反，PCA 图显示每个手势有两个独立的 10 个点的簇。这表明，即使手势相同，新数据也未与 PCA 空间中的原始数据对齐。

问题：
什么原因导致相同手势被分离为不同的簇？
可能与以下因素有关：

缩放过程？
传感器校准不一致？
在应用 PCA 之前是否需要对齐或对数据进行额外的预处理？
]]></description>
      <guid>https://stackoverflow.com/questions/79263104/pca-plot-clustering-issue-with-time-series-motion-capture-data</guid>
      <pubDate>Sun, 08 Dec 2024 18:31:23 GMT</pubDate>
    </item>
    <item>
      <title>我无法在我的 GPU 上训练模型，并收到 CUDA-Assertion-Error</title>
      <link>https://stackoverflow.com/questions/79263006/i-cant-train-a-model-on-my-gpu-getting-cuda-assertion-error</link>
      <description><![CDATA[这是我的神经网络代码，使用 pytorch：
 class BLSTM(nn.Module): 
def __init__(self,vocab_size): 
super(BLSTM,self).__init__() 
self.Embeddings = nn.Embedding(vocab_size,100) 
self.LSTM = nn.LSTM(100,128,bidirectional=True) 
self.fc = nn.Linear(128*2,3) 
self.dropout = nn.Dropout(0.5) 
self.tanh = nn.Tanh() 

def forward(self,X): 
embed = self.Embeddings(X) 
print(embed) 
output , (hidden , cell) = self.LSTM(embed) 
last_hidden = output[:, -1,:] 
logits = self.fc(self.dropout(last_hidden)) 
self.tanh(logits) 
return logits

我在 model.to(&quot;device&quot;) 处收到 cuda 断言错误。指定的尺寸或网络是否存在问题。我已检查内存分配，没有问题，我将在下面发布错误
Cell In[52]，第 10 行
7 device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
8 print(device)
---&gt; 10 model.to(device)
11 X_train = np.squeeze(torch.tensor(X_train,dtype=torch.long))
12 X_val = np.squeeze(torch.tensor(X_val,dtype=torch.long))

文件 C:\Python312\Lib\site-packages\torch\nn\modules\module.py:1340，位于 Module.to(self, *args, **kwargs)
...
RuntimeError: CUDA 错误：设备端断言已触发
CUDA 内核错误可能会在其他 API 调用中异步报告，因此下面的堆栈跟踪可能不正确。
对于调试，请考虑传递 CUDA_LAUNCH_BLOCKING=1
使用 `TORCH_USE_CUDA_DSA` 进行编译以启用设备端断言。

有人能解释一下这个问题的真正原因吗？
我必须用给定的网络训练模型，但在将模型分配给 gpu 时，我遇到了这个错误。我搞不清楚。否则他们会向我显示张量错误。张量的维度是 1。]]></description>
      <guid>https://stackoverflow.com/questions/79263006/i-cant-train-a-model-on-my-gpu-getting-cuda-assertion-error</guid>
      <pubDate>Sun, 08 Dec 2024 17:29:15 GMT</pubDate>
    </item>
    <item>
      <title>解决 TensorFlow 1.15.8 自动编码器模型训练中的图像模糊和褪色问题</title>
      <link>https://stackoverflow.com/questions/79263001/addressing-blurry-and-faded-images-in-tensorflow-1-15-8-autoencoder-model-traini</link>
      <description><![CDATA[问题描述：
我正在训练一个卷积自动编码器进行图像重建，但与预期结果相比，模型输出模糊且对比度低。设置如下：
Python 版本：3.7
TensorFlow 版本：1.15.8 (DirectML)
GPU：AMD Radeon RX 6700XT
模型类型：卷积自动编码器

尽管进行了数据规范化和增强（旋转、亮度调整、水平翻转），但该模型仍难以生成高质量的重建。问题似乎与卷积层或损失函数有关。
我尝试过的方法：

降低学习率。
将数据集标准化为 [0,1][0,1] 范围。
调整编码器和解码器中的过滤器数量。
使用 MSE 作为损失函数。

问题：
1-) 将编码器/解码器层中的过滤器加倍是否有助于解决模糊问题，就像对 GAN 评论家所做的那样？
2-) 是否可以在训练期间将 MAE 损失与 MSE 结合起来以缓解去饱和问题？
3-) 是否有特定的架构或学习调整来提高输出质量并避免模糊/褪色结果如何？
图像：
输入、目标（预期输出）和预测输出已附加以供比较。
示例 1： 
示例 2： 
如果您能提供任何建议或见解以有效解决此问题，我将不胜感激。提前感谢您！]]></description>
      <guid>https://stackoverflow.com/questions/79263001/addressing-blurry-and-faded-images-in-tensorflow-1-15-8-autoencoder-model-traini</guid>
      <pubDate>Sun, 08 Dec 2024 17:27:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么两个不同的逻辑回归模型对同一源数据产生截然不同的结果？[关闭]</title>
      <link>https://stackoverflow.com/questions/79262779/why-are-two-different-logistic-regression-models-producing-vastly-different-resu</link>
      <description><![CDATA[我正在处理 NFL 数据，预测比赛结果。我的源数据（用于以下两个过程）包含约 3,800 行，每行 20 个单独的特征（每支球队 10 个，外加日期、比赛 ID、主队和客队以及主场胜利/客场胜利列）。
模型“A”循环通过特定日期范围进行训练/测试分割。也就是说，我使用硬截止值，因此每组在日期方面都是连续的。我使用的日期反映了 50%、55% 等最高 85% 的分割。使用此模型，8 个准确度结果中的每一个都是 ~ 61%，这对于 NFL 预测来说是典型的（可能有点偏高）。
模型“B”使用 sklearn 中的 train_test_split 模块以与上述相同的百分比分割数据。我意识到这种方法会打乱数据，所以我知道每个分割都使用与模型 A 不同的数据。但使用这种方法，每个周期的百分比准确率约为 82%，远高于模型 A，而且似乎不合理。因此，我想了解我是否正确地实现了其中一种（或两种）方法。
（如果有人可以向我展示如何附加我的源 csv，我很乐意这样做）
模型 A 的相关部分
train_test_date_range = [&#39;2017-11-02&#39;, &#39;2018-10-04&#39;, &#39;2019-09-05&#39;, &#39;2019-12-01&#39;, &#39;2020-11-05&#39;, &#39;2021-10-03&#39;, &#39;2022-01-02&#39;, &#39;2022-11-24&#39;]

features = [
&#39;team_1_average_ptsScored_last_five&#39;,
&#39;team_1_average_feature_1_last_five&#39;,

为清晰起见，功能列表缩写

&#39;team_2_average_feature_9_allowed_last_three_away&#39;,
&#39;team_2_average_feature_10_allowed_last_three_away&#39;
]

for tt_line_date in train_test_date_range :

train_data = match_stats[match_stats[&#39;date&#39;] &lt; tt_line_date]
test_data = match_stats[match_stats[&#39;date&#39;] &gt;= tt_line_date]

X_train = train_data[features]
X_test = test_data[features]
Y_train = train_data[&#39;team_1_result&#39;]
Y_test = test_data[&#39;team_1_result&#39;]

names = [&quot;Log Reg&quot;]

classifiers = [
LogisticRegression()
]

for name, clf in zip(names, classifiers):
# 将分类器拟合到训练数据上并进行预测
clf.fit(X_train, Y_train)
test_data[name + &#39;_team_1_result&#39;] = clf.predict(X_test)
accuracy = clf.score(X_test, Y_test)

print(name + &#39; T/T_Line 处的准确率 &#39; + tt_line_date + &#39; =&#39;, format(accuracy, &quot;.2%&quot;))

模型“A”的输出
T/T_Line 2017-11-02 的对数回归准确度 = 62.11%
T/T_Line 2018-10-04 的对数回归准确度 = 61.83%
等等。

模型“B”的相关部分
train_test_split_range = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85]

for tt_line in train_test_split_range: 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tt_line, random_state=42)

model = LogisticRegression()

scaler = StandardScaler()

scaled_train = scaler.fit_transform(X_train)
scaled_test = scaler.fit_transform(X_test)

model.fit(X_train, y_train)
y_pred_proba = model.predict_proba(X_train)[:, 1]

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])

# 计算伪 r 平方
# 修改自：https://github.com/scikit-learn/scikit-learn/issues/25982
ll_null = log_loss(y_train, [y_train.mean()] * len(y_train))
ll_model = log_loss(y_train, y_pred_proba)
pseudo_r2 = 1 - ll_model / ll_null

# 打印指标
print(f&quot;\033[1m\033[4mResults at &quot; + str(tt_line) + &quot;训练/测试分割\033[0m&quot;)
print(f&quot;准确率：{accuracy:.3f}&quot;)
print(f&quot;精确率：{precision:.3f}&quot;)
print(f&quot;召回率：{recall:.3f}&quot;)
print(f&quot;F1 得分：{f1:.3f}&quot;)
print(f&quot;ROC AUC：{roc_auc:.3f}&quot;)
print(f&quot;伪 R 平方：{pseudo_r2:.3f}&quot;)
print()

模型“B”的输出（8 个中的 1 个，但很典型）
0.5 训练/测试分割的结果
准确率：0.820
精确率：0.828
召回率：0.854
F1 分数：0.841
ROC AUC：0.896
伪 R 平方：0.490
]]></description>
      <guid>https://stackoverflow.com/questions/79262779/why-are-two-different-logistic-regression-models-producing-vastly-different-resu</guid>
      <pubDate>Sun, 08 Dec 2024 15:41:51 GMT</pubDate>
    </item>
    <item>
      <title>机器学习如何计算微小动物的数量？[关闭]</title>
      <link>https://stackoverflow.com/questions/79261944/machine-learning-to-count-microscopic-animals</link>
      <description><![CDATA[我正在做一个项目，我们想使用机器学习在显微镜下计数幼年淡水贻贝（150 微米大）。我应该如何处理照明？我想尝试使用单色光来查看贻贝是否在不同波长下发出荧光，以便算法可以将其与垃圾区分开来。是否有一种便宜的方法可以获得单色照明来测试这一点？我在显微镜上使用奥林巴斯 tg-4 相机。
我尝试了普通光，但很难将贻贝与幼年蜗牛或其他垃圾区分开来。]]></description>
      <guid>https://stackoverflow.com/questions/79261944/machine-learning-to-count-microscopic-animals</guid>
      <pubDate>Sun, 08 Dec 2024 06:12:51 GMT</pubDate>
    </item>
    <item>
      <title>未来训练模型的文本标记方法</title>
      <link>https://stackoverflow.com/questions/79261744/text-labeling-approach-to-train-a-model-in-the-future</link>
      <description><![CDATA[我正在学习一些机器学习概念，最近这真的很有趣。我正在开发一个文档处理器，它将接收大量 PDF 并标记其中的数据。我想知道我是否有正确的方法来为稍后要创建的模型生成训练数据。
PDF 文件的路径被输入到一个使用 DocTR 提取文本的函数中。数据格式如下：
 data_list.append({
&#39;id&#39;:coord_key,
&#39;text&#39;:block_list[coord_key],
&quot;x1&quot;:float(block[&quot;geometry&quot;][0][0]),
&quot;y1&quot;:float(block[&quot;geometry&quot;][1][0]),
&quot;x2&quot;:float(block[&quot;geometry&quot;][0][1]),
&quot;y2&quot;:float(block[&quot;geometry&quot;][1][1])
});

Coord_Key 用作文本块的 ID。x1、x2、y1、y2 是文档上边界框的坐标，因此位置是已知的。文本当然就是所讨论的文本。
我的想法是获取这些数据并将其传递到 Label Studio，然后我将使用 Open AI 来帮助我应用我想要使用的特定标签。例如：address、phoneNumber、remarks 等。我当然会查看它得出的结果，并在筛选信息时进行更正。这样，我要训练的模型就有了最好的学习信息。
此时的目标是生成训练数据，以便我可以使用 Tensorflow 编写一些内容，学习如何自行进行标记。
这种方法正确吗？在我开始大量从我必须测试的文档中创建更多此类数据之前，我是否应该考虑为我的模型创建训练数据的其他事项？]]></description>
      <guid>https://stackoverflow.com/questions/79261744/text-labeling-approach-to-train-a-model-in-the-future</guid>
      <pubDate>Sun, 08 Dec 2024 02:23:07 GMT</pubDate>
    </item>
    <item>
      <title>模块“keras.api.backend”没有属性“clip”</title>
      <link>https://stackoverflow.com/questions/79116828/module-keras-api-backend-has-no-attribute-clip</link>
      <description><![CDATA[我使用 Colab 进行编码并收到此错误：
AttributeError：模块“keras.api.backend”没有属性“clip”。

我尝试升级 TensorFlow 和 Keras，但仍然收到相同的错误。我在第一个 epoch 拟合模型时收到此错误。
我该如何修复它？
import fragmentation_models as sm
model_vgg16=sm.Unet(backbone_name=backbone,input_shape=(256,256,3),classes=4,activation=&quot;softmax&quot;,encoder_weights=&quot;imagenet&quot;,decoder_use_batchnorm=True,encoder_freeze=False )

model_vgg16.summary()

&quot;&quot;&quot;# loss and metrics&quot;&quot;&quot;

loss=&quot;categorical_crossentropy&quot;

dice_loss=sm.losses.DiceLoss()
focal_loss=sm.losses.CategoricalFocalLoss()

focal_dice_loss=sm.losses.categorical_focal_dice_loss

metric=[sm.metrics.IOUScore(threshold=0.5)]

&quot;&quot;&quot;# compile&quot;&quot;&quot;

lr=0.001
model_vgg16.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),
loss=[focal_dice_loss],
metrics=[metric])

history = model_vgg16.fit(preprocessed_x_train, ytrain_categorical, epochs=20,validation_data=(preprocessed_x_val,y_val_categorical),batch_size=32)

错误：
Epoch 1/20
--------------------------------------------------------------------------------------------
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-76-887dcd97e6be&gt; 在 &lt;cell line: 1&gt;()
----&gt; 1 history = model_vgg16.fit(preprocessed_x_train, ytrain_categorical, epochs=20,
2 validation_data=(preprocessed_x_val,y_val_categorical),
3 batch_size=32)

3 帧
/usr/local/lib/python3.10/dist-packages/segmentation_models/base/ functional.py in categorical_focal_loss(gt, pr, gamma, alpha, class_indexes, **kwargs)
276 
277 # 剪辑以防止 NaN 和 Inf
--&gt; 278 pr = backend.clip(pr, backend.epsilon(), 1.0 - backend.epsilon())
279 
280 # 计算焦点损失

AttributeError: 模块 &#39;keras.api.backend&#39; 没有属性 &#39;clip&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/79116828/module-keras-api-backend-has-no-attribute-clip</guid>
      <pubDate>Wed, 23 Oct 2024 07:29:46 GMT</pubDate>
    </item>
    <item>
      <title>多维数据 K 均值聚类后的 PCA</title>
      <link>https://stackoverflow.com/questions/69699120/pca-after-k-means-clustering-of-multidimensional-data</link>
      <description><![CDATA[我有以下包含 10 个变量的数据集：

我想用这个多维数据集识别聚类，所以我尝试使用以下代码的 k-means 聚类算法：
clustering_kmeans = KMeans(n_clusters=2, precompute_distances=&quot;auto&quot;, n_jobs=-1)
data[&#39;clusters&#39;] = clustering_kmeans.fit_predict(data)

为了绘制结果，我使用 PCA 进行降维：
reduced_data = PCA(n_components=2).fit_transform(data)
results = pd.DataFrame(reduced_data,columns=[&#39;pca1&#39;,&#39;pca2&#39;])
sns.scatterplot(x=&quot;pca1&quot;, y=&quot;pca2&quot;, hue=kmeans[&#39;clusters&#39;], data=results)
plt.title(&#39;2 维 K-means 聚类&#39;)
plt.show()

最后我得到了以下结果：

所以我有以下结果问题：

但是，这个 PCA 图看起来非常奇怪，将整个数据集分成了两个角。这是正确的吗？还是我写错了代码？

还有其他用于聚类多维数据的算法吗？我查看了这个，但我找不到用于聚类多维数据的合适算法……我如何才能在 Python 中为我的数据集实现 Ward 层次聚类？

为什么我应该使用 PCA 进行降维？我也可以使用 t SNE 吗？这样更好吗？

]]></description>
      <guid>https://stackoverflow.com/questions/69699120/pca-after-k-means-clustering-of-multidimensional-data</guid>
      <pubDate>Sun, 24 Oct 2021 17:21:13 GMT</pubDate>
    </item>
    <item>
      <title>Gan 制作出不饱和、褪色的图像</title>
      <link>https://stackoverflow.com/questions/66292084/gan-produces-desaturated-faded-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/66292084/gan-produces-desaturated-faded-images</guid>
      <pubDate>Sat, 20 Feb 2021 13:26:47 GMT</pubDate>
    </item>
    <item>
      <title>降维——PCA 解释</title>
      <link>https://stackoverflow.com/questions/65470930/dimensionality-reduction-pca-explanation</link>
      <description><![CDATA[我觉得我对 PCA 理解得不是很好，有人能帮我解决下面的困惑吗？
以鸢尾花数据集为例，我有 4 个协变量，x1：萼片长度；x2：萼片宽度；x3：花瓣长度；x4：花瓣宽度。公式如下所示，a1、a2、a3、a4 是协变量的权重。PCA 将尝试使用不同的线性变换来最大化方差。同时也遵循 a1^2 + a2^2 + a3^2 + a4^2=1 的规则。我有兴趣知道 a1、a2、a3、a4 的值。
a1*x1 + a2*x2 + a3*x3 + a4*x4

我在 Python 上有以下代码，我认为哪个是正确的？
# 加载库
从 sklearn.datasets 导入 load_iris
从 sklearn.decomposition 导入 PCA
导入 seaborn 作为 sns
导入 pandas 作为 pd
导入 numpy 作为 np

iris = load_iris()
X = iris.data
df = pd.DataFrame(X,columns=iris.feature_names)

pca = decomposition.PCA(n_components = 4)
digits_pca_4 = pca.fit(X)
digits_pca_4.explained_variance_ratio_

结果是
array([0.92461872, 0.05306648, 0.01710261, 0.00521218])

我的问题是：
我是否正确地假设 a1=sqrt(0.92)、a2=sqrt(0.05)、a3=sqrt(0.02)、a4=sqrt(0.005)？
第二个问题：
如果我选择 a1=a2=a3=a4=0.5 的线性组合，那么与 PCA 的方差相比，这个方差是多少（我假设它小于 PCA 结果，因为 PCA 最大化了方差？）？如何在 Python 中获取 a1=a2=a3=a4=0.5 时的方差？PCA 的方差是下面的代码吗？
pca.explained_variance_.sum()
]]></description>
      <guid>https://stackoverflow.com/questions/65470930/dimensionality-reduction-pca-explanation</guid>
      <pubDate>Sun, 27 Dec 2020 22:06:39 GMT</pubDate>
    </item>
    <item>
      <title>PCA 的输出是什么以及它有何用处？</title>
      <link>https://stackoverflow.com/questions/47048399/what-is-the-output-of-pca-and-how-it-is-useful</link>
      <description><![CDATA[PCA 是一种降维算法，有助于降低数据的维度。
我不明白的是，PCA 会按降序输出特征向量，例如 PC1、PC2、PC3 等。因此，这将成为我们数据的新轴。

我们可以在哪里应用这个新轴来预测测试集数据？
我们实现了从 n 到 n-k 的降维。
如何从我们的数据中获取最有用的变量并从我们的数据中消除不重要的列？
PCA 有替代方法吗？
]]></description>
      <guid>https://stackoverflow.com/questions/47048399/what-is-the-output-of-pca-and-how-it-is-useful</guid>
      <pubDate>Wed, 01 Nov 2017 04:45:26 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析，有多少个成分？</title>
      <link>https://stackoverflow.com/questions/46516469/principal-component-analysis-how-many-components</link>
      <description><![CDATA[我不明白 PCA 的一点。PCA 返回最大化每个特征方差的方向？我的意思是，它将为我们原始空间的每个特征返回一个组件，并且只有 k 个最大的组件才会用作新子空间的轴，对吗？所以实际上如果我在 50 维空间中，并且 49 个特征具有很强的方差，我可以直接传递到 49 维空间吗？]]></description>
      <guid>https://stackoverflow.com/questions/46516469/principal-component-analysis-how-many-components</guid>
      <pubDate>Sun, 01 Oct 2017 20:12:59 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析</title>
      <link>https://stackoverflow.com/questions/18371333/principal-components-analysis</link>
      <description><![CDATA[我正在阅读一篇关于主成分分析的教程（主成分分析教程/Lindsay I Smith）。最后讨论了“恢复旧数据”。我想知道这样做有什么意义吗？我实际上已经在 R 中的 princomp 函数下对名为“USArrests”的数据集进行了尝试。通过转换回旧数据集，我得到的变量数量与原始数据集完全相同，更糟糕的是，转换后的变量 100% 相关。从这个意义上说，PCA 无法减少原始变量的数量，因此无法消除它们之间的相关性。]]></description>
      <guid>https://stackoverflow.com/questions/18371333/principal-components-analysis</guid>
      <pubDate>Thu, 22 Aug 2013 03:46:28 GMT</pubDate>
    </item>
    <item>
      <title>PCA 降低数据集维数的简单解释</title>
      <link>https://stackoverflow.com/questions/12184175/simple-explanation-of-pca-to-reduce-dimensionality-of-dataset</link>
      <description><![CDATA[我知道PCA 不会告诉您数据集中哪些特征最重要，但会告诉您哪些特征组合保留了最大的方差。
您如何利用 PCA 旋转数据集的事实，使其在第一维上具有最大的方差，在第二维上具有第二大的方差，依此类推，以降低数据集的维数？
我的意思是，更深入地说，如何使用前 N 个特征向量将特征向量转换为保留大部分方差的低维表示？]]></description>
      <guid>https://stackoverflow.com/questions/12184175/simple-explanation-of-pca-to-reduce-dimensionality-of-dataset</guid>
      <pubDate>Wed, 29 Aug 2012 18:22:20 GMT</pubDate>
    </item>
    <item>
      <title>主成分分析</title>
      <link>https://stackoverflow.com/questions/10818718/principal-component-analysis</link>
      <description><![CDATA[我必须编写一个分类器（高斯混合模型），用于人类动作识别。
我有 4 个视频数据集。我选择其中 3 个作为训练集，1 个作为测试集。
在将 gmm 模型应用于训练集之前，我先在其上运行 pca。
pca_coeff=princomp(trainig_data);
score = training_data * pca_coeff;
training_data = score(:,1:min(size(score,2),numDimension));

在测试步骤中我应该做什么？我应该在测试数据上执行新的 princomp 吗？
new_pca_coeff=princomp(testing_data);
score = testing_data * new_pca_coeff;
testing_data = score(:,1:min(size(score,2),numDimension));

或者我应该使用我为训练数据计算的 pca_coeff？
score = testing_data * pca_coeff;
testing_data = score(:,1:min(size(score,2),numDimension));
]]></description>
      <guid>https://stackoverflow.com/questions/10818718/principal-component-analysis</guid>
      <pubDate>Wed, 30 May 2012 14:49:05 GMT</pubDate>
    </item>
    </channel>
</rss>