<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 15 May 2024 06:19:55 GMT</lastBuildDate>
    <item>
      <title>model.compile 损失 TypeError：缺少必需的位置参数</title>
      <link>https://stackoverflow.com/questions/78481612/model-compile-loss-typeerror-missing-required-positional-argument</link>
      <description><![CDATA[最小的例子是
将 numpy 导入为 np
将张量流导入为 tf
从张量流导入keras
从 keras.losses 导入 huber

# 创建数据集
x = np.random.rand(10, 1)
y = 2 * x + np.random.randn(10, 1) * 0.1

# 定义模型
模型 = keras.Sequential([
    keras.layers.Dense(1, input_shape=[1])
]）

# 编译模型
# model.compile(loss=huber, optimizationr=&#39;adam&#39;) # 有效
# model.compile(loss=&#39;huber&#39;, optimizationr=&#39;adam&#39;) # 有效
model.compile(loss=huber(delta=0.1), 优化器=&#39;adam&#39;)

＃ 训练
model.fit(x, y, epochs=5)

当我在 model.compile() 中使用 huber loss 时，这两种方法都有效。
从 keras.losses 导入 huber

model.compile(loss=“huber”, optimizationr=optimizer=&#39;adam&#39;)

或者

model.compile(loss=huber, 优化器=optimizer=&#39;adam&#39;)


但是如果我想添加delta，就会出现TypeError。
添加 delta 的正确方法是什么？
感谢您的提前。
&lt;前&gt;&lt;代码&gt;
---&gt; 18 model.compile(loss=huber(delta=delta), 优化器=&#39;adam&#39;)
     

文件 ~/anaconda3/envs/py38/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153，位于filter_traceback..error_handler(*args, **kwargs)
    151 异常如 e 除外：
...
-&gt;第1170章
   第1171章
   第1172章 返回结果

类型错误：缺少必需的位置参数
]]></description>
      <guid>https://stackoverflow.com/questions/78481612/model-compile-loss-typeerror-missing-required-positional-argument</guid>
      <pubDate>Wed, 15 May 2024 04:29:44 GMT</pubDate>
    </item>
    <item>
      <title>机器学习平台的多节点 GPU 利用与 Docker</title>
      <link>https://stackoverflow.com/questions/78481571/multi-node-gpu-utilization-with-docker-for-machine-learning-platform</link>
      <description><![CDATA[我的家庭实验室服务器有两个节点，我们称它们为节点 A 和节点 B。节点 A 有 4 个 GPU，节点 B 有 2 个 GPU。如何将计算能力与 Docker 容器结合起来用于机器学习/深度学习工具？如果有更好的解决方案，我很想知道。 :)
由于我对计算机系统的了解有限，我在节点 A 上安装了 Docker，并运行了一个机器学习平台容器（Jupyter 容器），以利用我拥有的最大计算能力。但是，通过这种方法，我最多只能利用节点 A 的 4 个 GPU。有没有办法结合这两种资源？理想情况下，当我在 Jupyter 容器内执行 nvidia-smi 时，它应该检测到来自节点 A 和节点 B 的 6 个 GPU。]]></description>
      <guid>https://stackoverflow.com/questions/78481571/multi-node-gpu-utilization-with-docker-for-machine-learning-platform</guid>
      <pubDate>Wed, 15 May 2024 04:13:13 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 Excel 电子表格拟合 sklearn 模型</title>
      <link>https://stackoverflow.com/questions/78481567/is-it-possible-to-fit-a-sklearn-model-using-a-excel-spreadsheet</link>
      <description><![CDATA[嗨，我是这个社区的新手，
但我想出了这个好奇心
因为我有一个嵌入式板来训练 sklearn
我有 nvidia jetson tx2，带有 256 个 nvidia cuda 核心
所以为了减少内存中的负载，我只是将训练数据传输到 Excel 文件中，通过导入我可以训练模型
导入训练数据
现在为了将其提供给模型，有一种方法
通过将数据添加到列表或 numpy 数组或张量
同样的后续代码
Excel数据转换成数据结构
然后通过model.fit给模型
model.fit
我知道这是一种不是最佳的方式
我的第一个问题是，有没有办法直接将 Excel 文件提供给 .h5 模型
没有任何可以忽略的中间数据结构
我尝试在网上搜索，但没有找到任何方法，如果您发现或知道作为一个社区，我们应该讨论和贡献知识。共同学习、共同进步。
现在我脑海中还存在一个次要的后续问题，那就是
我的第二个问题是如何专门为 jetson 设备或任何嵌入式板编写优化代码，即将到来。空间复杂度是我关心的问题之一，我只编写最小化代码，nvidia 编译器也已经编写了代码优化
但是有什么方法可以优化我所缺少的代码
我的正常代码看起来像
&lt;前&gt;&lt;代码&gt;
任何简约的优化代码编写方法
对于资源有限的计算机（例如嵌入式板）
使用最少的基本临时库编写，如 c++]]></description>
      <guid>https://stackoverflow.com/questions/78481567/is-it-possible-to-fit-a-sklearn-model-using-a-excel-spreadsheet</guid>
      <pubDate>Wed, 15 May 2024 04:09:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 TensorFlow 提高多类分类的准确性？</title>
      <link>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</link>
      <description><![CDATA[我正在使用 TensorFlow 解决多类分类问题，并在实现令人满意的准确性方面遇到了挑战。我有7节课。文件夹中的每个类包含 2000 个 .csv 文件（每个文件有两列）。当我使用二元分类方法训练模型，用另一个类测试一个类时，准确性和 val_accuracy 会很高，0.85 到 0.95，但是当我使用多标签 7 进行测试时类，准确率最高达到0.47。下面是包含数据抛光和模型多类的代码。
#文件夹中的 csv 类
文件夹路径 = [
    &#39;/content/drive/MyDrive/medical_chem/Aa&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ab&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ac&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ba&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Bb&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Cc&#39;,
    &#39;/内容/驱动器/MyDrive/medical_chem/DD&#39;
]


数据 = []
标签=[]

#加载文件夹并将文件csv存档在数据框中
对于 enumerate(folder_paths) 中的 class_index、folder_path：
    对于 os.listdir(folder_path) 中的文件：
        file_path = os.path.join(文件夹路径, 文件)
        df = pd.read_csv(文件路径)
        数据.append(df)
        标签.append(class_index)

X = 数据
y = 标签

# 找到数据框中的最小值
min_length = min(len(df) for df in X)
# 设置数据帧长度相同
truncated_dfs = [df.head(min_length) for df in X]
# 数据帧到 numpy 数组
X = np.array([df.truncated_dfs 中 df 的值])


# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 标准化数据
X_train = 归一化(X_train, 轴=1)
X_test = 归一化(X_test, 轴=1)
y_train = to_categorical(y_train, num_classes=7)
y_test = to_categorical(y_test, num_classes=7)


X_train.shape、y_train.shape、X_test.shape、y_test.shape
# 输出 ((8943, 2906, 2), (8943, 7), (2236, 2906, 2), (2236, 7))

模型 = tf.keras.Sequential([
    tf.keras.layers.Dense(128, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(64, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(32, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(7,activation=&#39;softmax&#39;) # 7个类的输出层
]）

# 训练模型的检查点
checkpoint_path = “training_checkpoint/cp.ckpt”
checkpoint_dir = os.path.dirname(checkpoint_path)
checkpoint_callback = ModelCheckpoint(文件路径=checkpoint_path,
                                      save_weights_only=真，
                                      save_best_only=真，
                                      监视器=&#39;val_loss&#39;,
                                      详细=1)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;分类交叉熵&#39;，
              指标=[&#39;准确性&#39;])

#model.load_weights(检查点路径)

历史 = model.fit(X_train, y_train,
                    纪元=100，
                    验证数据=（X_测试，y_测试），
                    回调=[检查点回调])


我尝试过调整神经网络的架构，尝试不同的激活函数，并优化学习率和批量大小等超参数。但是，我仍然没有达到预期的准确性。
我确信我出错的地方是在预处理数据或模型中，因为二进制训练有很好的结果。
与二进制训练相比，准确度为 0.85 至 0.95
**多类别的预期准确率：高于 0.90
**
数据集： https://drive .google.com/drive/folders/1UAt50dPH7ABeoLu16nfa19g4oVccPeFO?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</guid>
      <pubDate>Wed, 15 May 2024 00:27:22 GMT</pubDate>
    </item>
    <item>
      <title>特征工程是一种新近特征[关闭]</title>
      <link>https://stackoverflow.com/questions/78481149/feature-engineering-a-recency-feature</link>
      <description><![CDATA[我有一个客户评分问题，我正在专门研究预测转化并得出转化的概率分数（使用 xgboost 分类器 atm）。我想介绍一个功能，但我很难明确该功能的定义。
具体来说，我知道当事件 A 最近发生时（例如，客户给我们的办公室打电话），这表明客户对我们的产品感兴趣并且可能会转化。为此，我创建了一个新近度功能，基本上是：（今天 - 事件日期）以天为单位。
问题在于，这没有捕捉到旧客户记录的影响。例如，客户可能在一年前给我们打电话（事件 A 触发），并在不久后进行转换，并且使用该公式，新近度特征将相对较大。我希望模型知道低新近度值会转化为更高的概率。
有没有什么好的方法来设计功能来捕捉这种关系？]]></description>
      <guid>https://stackoverflow.com/questions/78481149/feature-engineering-a-recency-feature</guid>
      <pubDate>Wed, 15 May 2024 00:26:20 GMT</pubDate>
    </item>
    <item>
      <title>oml4r dplyr 是否支持选择辅助函数</title>
      <link>https://stackoverflow.com/questions/78480951/are-the-select-helper-functions-supported-in-oml4r-dplyr</link>
      <description><![CDATA[选择辅助函数是否应该在 oml4r dplyr 的透明层中工作。
我不这么认为，因为我下面显示的内容，
&lt;前&gt;&lt;代码&gt;&gt; e &lt;- 矿石拉动(EMP)
&gt; e %&gt;% select(包含(“NO”)) %&gt;% print
     员工部门
7369 7369 20
7499 7499 30
7521 7521 30
7566 7566 20
7654 7654 30
7698 7698 30
7782 7782 10
7788 7788 20
7839 7839 10
7844 7844 30
7876 7876 20
7900 7900 30
7902 7902 20
7934 7934 10
&gt; emp &lt;- ore.push(EMP)
&gt; emp %&gt;% select(包含(“NO”)) %&gt;% print
`eval_select_impl()` 中的错误：
！ `x` 必须是一个向量，而不是一个 目的。
运行 rlang::last_trace() 查看错误发生的位置。
]]></description>
      <guid>https://stackoverflow.com/questions/78480951/are-the-select-helper-functions-supported-in-oml4r-dplyr</guid>
      <pubDate>Tue, 14 May 2024 22:47:19 GMT</pubDate>
    </item>
    <item>
      <title>在 oml4r 中创建嵌入式 R 脚本时出现“PLS-00201：必须声明标识符‘SYS.RQSCRIPTCREATE’”错误</title>
      <link>https://stackoverflow.com/questions/78480688/pls-00201-identifier-sys-rqscriptcreate-must-be-declared-error-when-creatin</link>
      <description><![CDATA[我在尝试使用 oml4r 创建嵌入式 R 脚本时遇到此错误，
# 创建一个公共脚本，可供任何用户使用。
&gt; ore.scriptCreate(“GLBGLM”,
+ 函数（数据、公式、...）
+ glm(公式 = 公式, 数据 = 数据, ...),
+ 全局 = TRUE,
+ 覆盖=真）
ore.scriptCreate(“GLBGLM”，函数(数据，公式，...) glm(公式=公式，：
  .oci.GetQuery(conn, statements, data = data, prefetch = prefetch, 中的错误：
  ORA-06550: 第 1 行，第 7 列：
PLS-00201：必须声明标识符“SYS.RQSCRIPTCREATE”
ORA-06550: 第 1 行，第 7 列：
PL/SQL：语句被忽略
帮助：https://docs.oracle.com/error-help/db/ora-06550/

这是我正在尝试的脚本，
 ore.scriptCreate(“GLBGLM”,
                 函数（数据、公式、...）
                   glm(公式 = 公式, 数据 = 数据, ...),
                 全局=真，
                 覆盖=真）
]]></description>
      <guid>https://stackoverflow.com/questions/78480688/pls-00201-identifier-sys-rqscriptcreate-must-be-declared-error-when-creatin</guid>
      <pubDate>Tue, 14 May 2024 21:15:58 GMT</pubDate>
    </item>
    <item>
      <title>使用梯度下降时，线性回归模型的训练误差和测试误差非常相似[关闭]</title>
      <link>https://stackoverflow.com/questions/78480089/the-training-error-and-testing-error-is-very-similiar-for-linear-regression-mode</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78480089/the-training-error-and-testing-error-is-very-similiar-for-linear-regression-mode</guid>
      <pubDate>Tue, 14 May 2024 18:43:35 GMT</pubDate>
    </item>
    <item>
      <title>带训练数据的基本贝叶斯线性回归[关闭]</title>
      <link>https://stackoverflow.com/questions/78479716/basic-bayesian-linear-regression-with-training-data</link>
      <description><![CDATA[在此处输入图片描述
我很困惑，因为我以为我的体重参数是w？无论如何，我想要验证我是否走在正确的道路上或完全被误导了，因为我的可能性一直为 0。
# 之前的分发
rv = multivariate_normal([0,0,0], (alpha ** (-1)) * np.eye(3))

#可能性
阿尔法 = 0.7
协方差 = (alpha ** (-1)) * np.eye(len(traininDataY))
w = np.array([0, 2.5, -0.5])
TransposeW= w.reshape(-1, 1)
phi = np.column_stack((np.ones_like(x1train), np.power(x1train, 2), np.power(x2train, 3)))
平均值 = np.dot(xmatrix, w_Transpose)
可能性 = multivariate_normal.pdf(tTrain, np.ravel(mean), Cov2)
]]></description>
      <guid>https://stackoverflow.com/questions/78479716/basic-bayesian-linear-regression-with-training-data</guid>
      <pubDate>Tue, 14 May 2024 17:19:05 GMT</pubDate>
    </item>
    <item>
      <title>ML 模型签名/水印 [关闭]</title>
      <link>https://stackoverflow.com/questions/78479253/ml-model-signing-watermarking</link>
      <description><![CDATA[我需要研究一项服务是否可以验证另一项服务是否使用特定的 ML 模型进行计算。这个想法是“验证者”服务正在调用“worker”具有输入的服务以及将在工作端处理输入的预期模型。工作人员正在响应模型提出的预测。然后验证器服务必须确认使用了正确的模型。此外，Miner 可以随时重新训练模型。
我有什么选择？是否有任何已知的良好做法？]]></description>
      <guid>https://stackoverflow.com/questions/78479253/ml-model-signing-watermarking</guid>
      <pubDate>Tue, 14 May 2024 15:49:25 GMT</pubDate>
    </item>
    <item>
      <title>调查 TensorFlow 和 PyTorch 性能的差异</title>
      <link>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</guid>
      <pubDate>Tue, 14 May 2024 13:54:26 GMT</pubDate>
    </item>
    <item>
      <title>PDF 阅读模型并给出准确答案</title>
      <link>https://stackoverflow.com/questions/78477795/model-for-pdf-read-and-give-accurate-answers</link>
      <description><![CDATA[任何人都可以建议聊天机器人的最佳模型吗？如果我给出任何 PDF 模型，应该阅读该 pdf，那么如果我问与该 PDF 模型相关的任何问题，应该给出正确的答案。
到目前为止，我已经发现了 1 个 Gemini 模型，但根据我的 PDF 数据，它不应该给出正确的答案]]></description>
      <guid>https://stackoverflow.com/questions/78477795/model-for-pdf-read-and-give-accurate-answers</guid>
      <pubDate>Tue, 14 May 2024 11:33:29 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：CUDA 错误：设备端断言已触发</title>
      <link>https://stackoverflow.com/questions/78475975/runtimeerror-cuda-error-device-side-assert-triggered</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78475975/runtimeerror-cuda-error-device-side-assert-triggered</guid>
      <pubDate>Tue, 14 May 2024 05:51:57 GMT</pubDate>
    </item>
    <item>
      <title>“管道”对象没有属性“_check_fit_params”</title>
      <link>https://stackoverflow.com/questions/78440449/pipeline-object-has-no-attribute-check-fit-params</link>
      <description><![CDATA[来自 imblearn.over_sampling 导入 SMOTE
从 imblearn.under_sampling 导入 RandomUnderSampler
从 imblearn.pipeline 导入管道

# 定义特征和目标
X = df.drop(&#39;感染&#39;, axis=1)
y = df[&#39;感染&#39;]

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定义重采样策略
over = SMOTE(sampling_strategy=0.5) # 将少数类过采样到多数类的 50%
under = RandomUnderSampler(sampling_strategy=0.8) # 将多数类欠采样至其原始大小的 80%

管道 = 管道(步骤=[(&#39;o&#39;, 上), (&#39;u&#39;, 下)])

# 应用重采样
X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)

# 显示新的类分布
print(“重采样的类分布：”, pd.Series(y_resampled).value_counts())

这是我的代码
这是我遇到的错误
AttributeError Traceback（最近一次调用最后一次）
单元格 In[7]，第 19 行
     16 pipeline = Pipeline(steps=[(&#39;o&#39;, over), (&#39;u&#39;, under)])
     18 # 应用重采样
---&gt; 19 X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)
     21 # 显示新的班级分布
     22 print(&quot;重采样的类分布：&quot;, pd.Series(y_resampled).value_counts())

文件 ~\anaconda3\Lib\site-packages\imblearn\pipeline.py:372，在 Pipeline.fit_resample(self, X, y, **fit_params)
    第342章
    第343章
    第344章
   （...）
    第369章 变身的目标。
    第370章
    第371章
--&gt; [第 372 章]
    第373章
    第374章

AttributeError：“管道”对象没有属性“_check_fit_params”

我已经尝试了一切。我的所有包都已更新。我尝试使用的所有方法都在 sklearn 和 imblearn 这两个网站上查看。]]></description>
      <guid>https://stackoverflow.com/questions/78440449/pipeline-object-has-no-attribute-check-fit-params</guid>
      <pubDate>Tue, 07 May 2024 06:12:34 GMT</pubDate>
    </item>
    <item>
      <title>线性回归的正规方程</title>
      <link>https://stackoverflow.com/questions/49347878/normal-equation-for-linear-regression</link>
      <description><![CDATA[我有以下 X 和 y 矩阵：

为此，我想使用正规方程方法计算线性回归方程的最佳 θ 值：
theta = inv(X^T * X) * X^T * y
theta 的结果应该是：[188.400,0.3866,-56.128,-92.967,-3.737]
我通过以下方式实现这些步骤：
X=np.matrix([[1,1,1,1],[2104,1416,1534,852],[5,3,3,2],[1,2,2, 1],[45,41,30,36]])
y=np.matrix([460,232,315,178])

XT=np.转置(X)

XTX=XT.点(X)

inv=np.linalg.inv(XTX)

inv_XT=inv.dot(XT)

θ=inv_XT.dot(y)

打印（θ）

但我没有得到想要的结果。相反，它会抛出错误：

&lt;块引用&gt;
  回溯（最近一次调用最后一次）：文件“C:/”，第 19 行，位于
      theta=inv_XT.dot(y) ValueError：形状 (4,5) 和 (1,4) 未对齐：5 (dim 1) != 1 (dim 0)

我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/49347878/normal-equation-for-linear-regression</guid>
      <pubDate>Sun, 18 Mar 2018 12:28:38 GMT</pubDate>
    </item>
    </channel>
</rss>