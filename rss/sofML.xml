<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Wed, 05 Mar 2025 21:18:47 GMT</lastBuildDate>
    <item>
      <title>我在拥抱脸上有错误，什么都没有起作用</title>
      <link>https://stackoverflow.com/questions/79486433/im-having-an-error-on-hugging-face-and-nothing-is-working</link>
      <description><![CDATA[我正在尝试在拥抱面上部署一个项目，但是有一个我似乎无法解决的错误。
 我正在遇到此错误  
 无法在9001-9001范围内的任何端口上启动节点服务器。
请安装节点20或更高版本，并将环境变量gradio_node_path设置为节点可执行文件的路径。
您可以通过设置环境变量gradio_node_port明确指定端口。
 
即使我拥有节点版本20。
有建议吗？
我尝试了所有内容，我检查了二手端口，我检查了环境变量是否正确，我检查了Gradio版本，我没有做什么。]]></description>
      <guid>https://stackoverflow.com/questions/79486433/im-having-an-error-on-hugging-face-and-nothing-is-working</guid>
      <pubDate>Wed, 05 Mar 2025 12:02:21 GMT</pubDate>
    </item>
    <item>
      <title>当使用不同GPU训练模型时，结果不一致</title>
      <link>https://stackoverflow.com/questions/79486105/inconsistent-results-when-training-models-using-different-gpus</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79486105/inconsistent-results-when-training-models-using-different-gpus</guid>
      <pubDate>Wed, 05 Mar 2025 10:10:04 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost在等于传输数据的输入上无法正确预测</title>
      <link>https://stackoverflow.com/questions/79485691/xgboost-does-not-predict-properly-on-input-thats-equal-to-traning-data</link>
      <description><![CDATA[为什么这个非常简单的XGBoost ML示例即使在输入中也会产生全弹药，这相当于训练数据？这看起来像是一种琐碎的输入情况，不需要对ML进行任何微调，但是即使我对ML（MAX_DEPTH，ETA等）调整了HyperParams，也没有任何改变。
 将大熊猫作为pd导入
导入XGBoost为XGB

x = pd.dataframe（（[[[0]，[1]，[2]，[3]，[4]，[5]]），列= [&#39;x&#39;]）
y = pd.dataframe（[0，1，0，1，0，1]，列= [&#39;y&#39;]）

型号= xgb.xgbClassifier（）
型号（x，y）
打印（模型。

[0 0 0 0 0 0]
 ]]></description>
      <guid>https://stackoverflow.com/questions/79485691/xgboost-does-not-predict-properly-on-input-thats-equal-to-traning-data</guid>
      <pubDate>Wed, 05 Mar 2025 06:59:19 GMT</pubDate>
    </item>
    <item>
      <title>无法生成图像嵌入：张量A的大小（1246）必须与非辛格尔顿维度1处的张量B（77）匹配</title>
      <link>https://stackoverflow.com/questions/79485638/failed-to-generate-image-embeddings-the-size-of-tensor-a-1246-must-match-the</link>
      <description><![CDATA[我正在使用句子转换器模型来嵌入图像文件（pil ImageFile）。但是，它在标题中给出了错误。我尝试了很多事情来解决它，但无济于事。
我知道这与张量的大小有关，因此我尝试将其截断，但我做了一些研究，但找不到截断的方法，而无需更改代码。我认为可能有一个简单的解决方案，但找不到。
代码分析一个文件夹，（应该）返回其中图像的嵌入。
 将大熊猫作为pd导入
从stone_transformers导入句子词术语
导入操作系统
导入numpy作为NP
从pil导入图像，imageFile

imageFile.load_truncated_images = true

image_files = [&#39;.jpg&#39;，&#39;.jpeg&#39;，&#39;.png&#39;]

班级分析仪：

    def __init __（自我）：
        self.image_model = sencencetransformer（&#39;clip-vit-b-32＆quot）
        
    def Analyze_directory（自我，路径）：

        files_data = []
        
        使用os.scandir（路径）作为dir_iter：
            要进入dir_iter：
                尝试：
                    如果entry.is_file（）：
                        _，ext = os.path.splitext（entry.name）
                        如果在image_files中进行ext：
                            尝试：
                                使用image.open（os.path.join（path，entry.name））作为img：
                                    img.convert（“ RGB”）
                                    file_data = {
                                        ＆quot“ path＆quot”：entry.name，
                                        ＆quot“ content＆quot”：img，
                                        “类型”：“图像”
                                    }
                            除例外为E：
                                file_data = {
                                    ＆quot“ path＆quot”：entry.name，
                                    ＆quot“ content＆quot”：“”
                                    “类型”：“图像”
                                }

                        别的：
                            file_data = {
                                ＆quot“ path＆quot”：entry.name，
                                ＆quot“ content＆quot”：“”
                                “类型”：“未知”
                            }
                        
                    files_data.append（file_data）
                
                除例外为E：
                    继续
        
        df = pd.dataframe（files_data）

        嵌入= []
        对于_，在df.iterrows（）中行列：
            如果行[type; quot&#39;] ==;
                尝试：
                    img = img.resize（（224，224））
                    ＃将pil图像转换为张量
                    img_tensor = np.array（img）
                    ＃将像素值标准化为[-1，1]范围通过剪辑期望的范围
                    img_normalized =（img_tensor / 255.0 * 2.0） -  1.0
                    img_batch = np.expand_dims（img_normalized，axis = 0）
                    嵌入= self.image_model.encode（str（img_batch））。numpy（）[0]
                除例外为E：
                    提高RuntimeError（f＆quot“无法生成图像嵌入：{str（e）};）
            别的：
                ＃处理未知类型
                嵌入= np .eros（384）

            embeddings.Append（嵌入）
        
        嵌入= np.array（嵌入）
        
        返回嵌入
 
我尝试截断张量，但找不到方法。
我认为仅预处理图像可以解决它，但它没有
错误消息：
  trackback（最近的最新通话）：
  file＆quort＆lt; frozen runpy＆gt;＆quot，line 198，in _run_module_as_main
  file＆quort＆lt; frozen runpy＆gt;＆quot，line 88，in _run_code in _run_code
  file＆quot＆quot c：\ users \ ... \ src \ document_analyzer \ main.py ,, 15，in＆lt; module＆gt;
    主要的（）
    ~~~~ ^^
  file＆quot c：\ users \ ... \ src \ document_analyzer \ main.py，&#39;第6行，在main中
    folder_structure = Analyzer.Analyze_directory（路径）
  file＆quort c：\ users \ ... \ src \ document_analyzer \ andaryzer.py ,， 69，在Analyze_directory中
    提高RuntimeError（f＆quot“无法生成图像嵌入：{str（e）};）
RuntimeError：无法生成图像嵌入：张量A（1203）的大小必须匹配张量B（77）在非辛格尔顿尺寸1
 ]]></description>
      <guid>https://stackoverflow.com/questions/79485638/failed-to-generate-image-embeddings-the-size-of-tensor-a-1246-must-match-the</guid>
      <pubDate>Wed, 05 Mar 2025 06:33:01 GMT</pubDate>
    </item>
    <item>
      <title>Android MediaPipe第二推理实例无法初始化</title>
      <link>https://stackoverflow.com/questions/79484601/android-mediapipe-second-inference-instance-cant-be-initialized</link>
      <description><![CDATA[我对 google.mediapipe进行了一些实验框架并观察下一期……如果初始化了某些实例/任务，则无法在推理任务的另一个实例。之后。
例如，我以姿势检测模型运行MediaPipe任务，当我尝试初始化TexteMbedder实例时，我会收到以下例外：

 com.google.mediapipe.framework.mediapipeexception：找不到：验证的GraphConfig初始化失败。
没有名称的注册对象：MediaPipe :: tasks :: text :: text_embedder :: textembeddergraph;无法找到计算器“ MediaPipe.tasks.text.text_embedder.textembeddergraph”
在com.google.mediapipe.framework.graph.nativestartrunninggraph（本机方法）
在com.google.mediapipe.framework.graph.startrunninggraph（graph.java:336）
在com.google.mediapipe.tasks.core.taskrunner.create（taskrunner.java:72）
在com.google.mediapipe.tasks.text.textembedder.textembedder.createfromoptions（textembedder.java:159）

 i从他们的示例（姿势检测）中运行代码库，并将文本任务依赖添加到项目中。
实例化：
  baseOptions.builder baseOptionsBuilder = baseOptions.builder（）;
             baseOptionsBuilder.SetModelassetPath（&#39;unision_sentence_encoder.tflite＆quot;）;
textembedder.textembedderoptions选项=
                            textembedder.textembedpertions.builder（）
                                    .setBaseOptions（baseOptionsbuilder.build（））
                                                                            。建造（）;
mtextembedder = textembedder.createfromoptions（上下文，选项）;
 
我尝试了不同的版本/组合（视觉＆amp; text）到目前为止，但到目前为止还没有运气... 
我想知道是否可以同时运行2个实例？
  upd ：2同时实例在iOS 上正常工作]]></description>
      <guid>https://stackoverflow.com/questions/79484601/android-mediapipe-second-inference-instance-cant-be-initialized</guid>
      <pubDate>Tue, 04 Mar 2025 18:46:25 GMT</pubDate>
    </item>
    <item>
      <title>由于亚当优化器加载模型时警告</title>
      <link>https://stackoverflow.com/questions/79484194/warning-when-loading-the-model-because-of-adam-optimizer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79484194/warning-when-loading-the-model-because-of-adam-optimizer</guid>
      <pubDate>Tue, 04 Mar 2025 15:48:02 GMT</pubDate>
    </item>
    <item>
      <title>'numpy.ndarray'对象没有属性'groupby'</title>
      <link>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</link>
      <description><![CDATA[我正在尝试使用 category_encoders.targetencoder 在Python中应用目标编码。但是，我一直遇到以下错误：
  attributeError：&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39;
 
 来自category_encoder
来自sklearn.model_selection导入train_test_split

＃目标编码的功能
encoding_cols = [&#39;等级&#39;，&#39;sub_grade&#39;，&#39;home_ownhip&#39;，&#39;verification_status&#39;， 
                 “目的”，“ application_type”，“ zipcode”]

＃火车测试拆分
x_train_cv，x_test，y_train_cv，y_test = train_test_split（x，y，test_size = 0.25，andury_state = 1）
x_train，x_test_cv，y_train，y_test_cv = train_test_split（x_train_cv，y_train_cv，test_size = 0.25，andury_state = 1）

＃初始化目标编码器
encoder = targetencoder（）

＃应用目标编码
因为我在encoding_cols中：
    x_train [i] = encoder.fit_transform（x_train [i]，y_train）＃**错误在这里发生**
    x_test_cv [i] = encoder.transform（x_test_cv [i]）
    x_test [i] = encoder.transform（x_test [i]）
 
想要成功地将目标编码应用于分类列，而不会遇到&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39; error。]]></description>
      <guid>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</guid>
      <pubDate>Tue, 04 Mar 2025 08:00:57 GMT</pubDate>
    </item>
    <item>
      <title>始终获得“输入用完数据”</title>
      <link>https://stackoverflow.com/questions/79396860/always-getting-your-input-ran-out-of-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79396860/always-getting-your-input-ran-out-of-data</guid>
      <pubDate>Wed, 29 Jan 2025 13:15:41 GMT</pubDate>
    </item>
    <item>
      <title>CIFAR10的训练模型在真实图像上的表现差</title>
      <link>https://stackoverflow.com/questions/78170557/trained-model-on-cifar10-performs-poorly-on-real-images</link>
      <description><![CDATA[所以我正在尝试使用CIFAR10数据集训练模型。
问题是，尽管模型在验证和测试集上的性能很好（约为95-96％），但该模型无法预测从Internet下载的图像（与输入一样进行预处理）。我知道已经有很多类似的问题，事实上，我已经尝试实施这些建议，但是到目前为止，没有任何问题对我有用。我不知道我做错了什么。
这是我的方法：

数据：测试 -  80％，验证 -  10％（val_dataset在模型中的输入。
模型（转移学习）：我使用Resnet50作为基本模型，使用“ Imagenet”权重并冷冻。
 upsmpling2d（（7,7））将图像从32x32x3调整到224x224x3  - ＆gt; RESNET50-＆GT;扁平 - ＆gt;密集（relu） - ＆gt;辍学 - ＆gt;致密（10，SoftMax）。 

是因为该数据集中的图像分辨率太低，而从互联网下载的图像分辨率更高？我不知道如何描述这一点，但是即使在将下载的图像大小调整到32x32x3中以进行模型。预测，它们仍然看起来与数据集中的图像有所不同？
数据集中的图像：
 下载的图像（原始）：
 下载的图像（调整到32x32x3）：
 这是问题吗？如果没有，您能告诉我我做错了什么，或者我能做什么，我的模型可以在现实生活中表现良好？
非常感谢。
更新：如何将下载的图像示例简化（建议之后）：
  #loading图像
dir =&#39;image.jpg; quot;
im_array2 = np.array（image.open（dir））

img_size = 32

#calcalcrution降低尺寸，同时保持纵横比
r = img_size / im_array2.shape [0]
dim =（img_size，int（im_array2.shape [1] * r））

test_image = np.floor（tf.image.resize（im_array2，dim））。astype（int）

#crop图像尺寸32x32
test_image = tf.image.resize_with_crop_or_pad（test_image，img_size，img_size）

#convert到float32，因为那是我设置的输入类型，因为输入将图像批量拍摄
im = np.float32（test_image）
im_array2 = np.expand_dims（im，axis = 0）

#normoralize图像数组以适合输入设置
im_array2 = im_array2/255

 
新结果：
 但表现仍然没有提高。]]></description>
      <guid>https://stackoverflow.com/questions/78170557/trained-model-on-cifar10-performs-poorly-on-real-images</guid>
      <pubDate>Sat, 16 Mar 2024 04:03:22 GMT</pubDate>
    </item>
    <item>
      <title>恢复标准标准的名称（）。fit_transform（）</title>
      <link>https://stackoverflow.com/questions/71509883/recovering-features-names-of-standardscaler-fit-transform-with-sklearn</link>
      <description><![CDATA[从 kaggle的教程 href =“ https://www.dropbox.com/s/xc9my0ratl994gm/aquifer_petrignano.csv?dl = 0” rel =“ noreferrer”&gt;可从此处下载
代码：
 进口SEABON作为SNS
导入matplotlib.pyplot作为PLT
导入numpy作为np＃线性代数
导入PANDAS作为PD＃数据处理，CSV文件I/O（例如PD.Read_CSV）
导入matplotlib.pyplot作为PLT＃用于绘制设施
从DateTime Import DateTime，日期
来自sklearn.model_selection import timpleseriessplit，gridsearchcv
导入XGBoost为XGB
来自sklearn.metrics导入均值_squared_error，mean_absolute_error
导入数学
从sklearn.prepercorsing进口标准标准

df = pd.read_csv（“ ./ data/aquifer_petrignano.csv”）

df [&#39;date&#39;] = pd.to_dateTime（df.date，格式=&#39;％d/％m/％y&#39;）
df = df [df.rainfall_bastia_umbra.notna（）]。reset_index（drop = true）

df = df.interpaly（方法=&#39;ffill&#39;）
df = df [[[&#39;date&#39;，&#39;雨fall_bastia_umbra&#39;，&#39;depth_to_togrongwater_p24&#39;，&#39;depth_to_to _ groundwater_p25&#39;，&#39;devies_bastia_umbra&#39;，&#39;devies_petrignano&#39;，&#39; &#39;hydometry_fiume_chiascio_petrignano&#39;]]。res ampleme（&#39;7d&#39;，on =&#39;date&#39;）。sean（）。reset_index（drop = false）

x = df.drop（[&#39;depth_to_groundWater_p24&#39;，&#39;depth_to_togrongwater_p25&#39;，&#39;date&#39;]，axis = 1）
y1 = df.depth_to_groundWater_p24
y2 = df.depth_to_groundwater_p25

sualer = StandardScaler（）
x = sualer.fit_transform（x）

model = xgb.xgbregressor（）
param_search = {&#39;max_depth&#39;：range（1，2，2），
                &#39;min_child_weight&#39;：范围（1，2，2），
                &#39;n_estimators&#39;：[1000]，，
                &#39;Learning_rate&#39;：[0.1]}

tscv = timeseriessplit（n_splits = 2）
gsearch = gridSearchCV（estionator =模型，cv = tscv，
                        param_grid = param_search）
gsearch.fit（x，y1）

xgb_grid = xgb.xgbregressor（** gsearch.best_params_）
XGB_GRID.FIT（X，Y1）

ax = xgb.plot_importance（xgb_grid）
ax.figure.tight_layout（）
ax.figure.savefig（&#39;test.png&#39;）

y_val = y1 [-80：]
x_val = x [-80：]

y_pred = xgb_grid.predict（x_val）
print（mean_absolute_error（y_val，y_pred））
print（Math.sqrt（mean_squared_error（y_val，y_pred）））
 
我绘制了一个重要的图形，其原始特征名称隐藏了：
  如果我评论这两行：
  sualer =标准尺度（）
x = sualer.fit_transform（x）
 
我得到输出：
  我如何使用 scaler.fit_transform（）  x 并获得具有原始功能名称的功能重要图？]]></description>
      <guid>https://stackoverflow.com/questions/71509883/recovering-features-names-of-standardscaler-fit-transform-with-sklearn</guid>
      <pubDate>Thu, 17 Mar 2022 09:28:43 GMT</pubDate>
    </item>
    <item>
      <title>哪些词嵌入维度值代表什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/49732976/what-actually-word-embedding-dimensions-values-represent</link>
      <description><![CDATA[我对Word2Vec和Word Embedding有疑问，我下载了手套预训练的单词嵌入（形状40,000 x 50），并使用此功能从中提取信息：
 导入numpy作为np
DEF LOADGLOVEMODEL（手套）：
    打印（“加载手套型”）
    f = open（手套，&#39;r&#39;）
    模型= {}
    对于F中的行
        splitline = line.split（）
        word = splitline [0]
        嵌入= np.Array（[[float（val）for val for val in Splitline [1：]]）
        模型[Word] =嵌入
    打印（完成。“
    返回模型
 
现在，如果我称此函数为Word &#39;Python&#39;，则类似：
  print（loadglovemodel（&#39;glove.6b.100d.txt&#39;）[&#39;python&#39;]）
 
它给了我1x50形状向量，例如：
  [0.24934 0.68318 -0.044711 -1.3842 -0.0073079 0.651
 -0.33958 -0.19785 -0.33925 0.26691 -0.033062 0.15915
  0.89547 0.53999 -0.55817 0.46245 0.36722 0.1889
  0.83189 0.81421 -0.11835 -0.53463 0.24158 -0.038864
  1.1907 0.79353 -0.12308 0.6642 -0.77619 -0.45713
 -1.054 -0.20557 -0.13296 0.12239 0.88458 1.024
  0.32288 0.82105 -0.069367 0.024211 -0.51418 0.8727
  0.25759 0.91526 -0.64221 0.041159 -0.60208 0.54631
  0.66076 0.19796 -1.1393 0.79514 0.45966 -0.18463
 -0.64131 -0.24929 -0.40194 -0.50786 0.80579 0.53365
  0.52732 0.39247 -0.29884 0.009585 0.99953 -0.061279
  0.71936 0.32901 -0.052772 0.67135 -0.80251 -0.25789
  0.49615 0.48081 -0.68403 -0.012239 0.048201 0.29461
  0.20614 0.33556 -0.64167 -0.64708 0.13377 -0.12574
 -0.46382 1.3878 0.95636 -0.067869 -0.0017411 0.52965
  0.45668 0.61041 -0.11514 0.42627 0.17342 -0.7995
 -0.24502 -0.6086 -0.38469 -0.4797]
 
我需要帮助了解输出矩阵。这些价值代表什么，生成新单词具有重要意义？]]></description>
      <guid>https://stackoverflow.com/questions/49732976/what-actually-word-embedding-dimensions-values-represent</guid>
      <pubDate>Mon, 09 Apr 2018 12:27:22 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec输出向量如何用于计算相似性？ [关闭]</title>
      <link>https://stackoverflow.com/questions/41365746/how-word2vec-output-vectors-are-used-to-compute-the-similarities</link>
      <description><![CDATA[我对Word2Vec输出向量的解释有些困惑！
如果我想预测特定单词后出现的最可能的单词（W1），我可以使用最近的单词与W1使用吗？
我的意思是，一个与W1最短距离的单词可以解释为具有最高概率的下一个单词？]]></description>
      <guid>https://stackoverflow.com/questions/41365746/how-word2vec-output-vectors-are-used-to-compute-the-similarities</guid>
      <pubDate>Wed, 28 Dec 2016 16:09:33 GMT</pubDate>
    </item>
    <item>
      <title>了解Word2Vec的跳过结构和输出</title>
      <link>https://stackoverflow.com/questions/34363250/understanding-word2vecs-skip-gram-structure-and-output</link>
      <description><![CDATA[我有一个关于word2vec中跳过的模型的两个问题：

 第一部分是关于结构的：据我了解，跳过模型是基于一个具有一个输入权重矩阵 w 的神经网络，一个大小n的隐藏层和C输出权重矩阵 w&#39;每个都用于生产C输出载体的一个。这是正确的吗？

 第二部分是关于输出向量的：据我所知，每个输出向量均为大小V，并且是SoftMax函数的结果。每个输出向量 node 对应于词汇中单词的索引，每个节点的值是相应单词在该上下文位置（对于给定的输入单词）出现的概率。但是，即使训练实例是，目标输出向量也不是单热编码的。这是正确的吗？


我想象的是以下几行（构造示例）：
假设词汇[&#39;quick&#39;，&#39;fox&#39;，&#39;跳“跳”，“懒惰”，“狗”]和c = 1的上下文，并假设对于输入词&#39;跳跃&#39;我看到两个输出向量看起来像这样：&gt; 
 [0.2  0.6  0.01 0.1 0.09] 
 [0.2 0.2 0.01 0.16  0.43 ] 
我将其解释为“狐狸”是在“跳跃”之前最有可能出现的单词（p = 0.6），而“狗”之后最有可能出现（p = 0.43）。
我有这个权利吗？还是我完全离开？]]></description>
      <guid>https://stackoverflow.com/questions/34363250/understanding-word2vecs-skip-gram-structure-and-output</guid>
      <pubDate>Fri, 18 Dec 2015 20:12:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么Word2Vec为每个单词使用2个表示？</title>
      <link>https://stackoverflow.com/questions/29381505/why-does-word2vec-use-2-representations-for-each-word</link>
      <description><![CDATA[我试图理解为什么Word2Vec的Skipgram模型为每个单词具有2个表示（隐藏的表示嵌入单词）和输出表示形式（也称为上下文单词嵌入）。这仅仅是为了普遍性，上下文可以是任何东西（不仅是单词），还是有更根本的原因]]></description>
      <guid>https://stackoverflow.com/questions/29381505/why-does-word2vec-use-2-representations-for-each-word</guid>
      <pubDate>Wed, 01 Apr 2015 01:44:41 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec中负抽采样的概念是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/27860652/what-is-the-concept-of-negative-sampling-in-word2vec</link>
      <description><![CDATA[我正在阅读2014年论文  word2vec解释：派生Mikolov等人。
负抽采样单词 - 插入方法 （注意：直接下载链接），并引用了“否定抽样”的概念：

 Mikolov等。呈现负面采样方法作为更有效的
得出单词嵌入的方式。否定采样是基于
Skip-gram模型，实际上是在优化不同的目标。

我很难理解负抽采样的概念。
  httpps://arxiv.org/pdf/1402.3722v1.pd1.pdf 
任何人都可以用外行的术语解释什么是负面采样？]]></description>
      <guid>https://stackoverflow.com/questions/27860652/what-is-the-concept-of-negative-sampling-in-word2vec</guid>
      <pubDate>Fri, 09 Jan 2015 12:31:25 GMT</pubDate>
    </item>
    </channel>
</rss>