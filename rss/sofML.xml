<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Wed, 09 Apr 2025 06:28:31 GMT</lastBuildDate>
    <item>
      <title>使用分类和数值数据构建预测模型</title>
      <link>https://stackoverflow.com/questions/79563333/building-a-prediction-model-with-categorical-and-numerical-data</link>
      <description><![CDATA[我正在构建ML模型的过程中。一个背景是数据集包括分类和数值变量，我将预测4个数值变量。
Q1：我在分类变量中有多个类别，并且使用一个热编码将创建30列。目前，我正在使用标签编码，并且由于没有订单，我觉得这是错误的。想知道是否有更好的方法来处理它？
Q2：您认为这种情况的最佳ML模型是什么？目前，我正在尝试LR，RF和XGBoost。问题是我觉得每个目标变量的输入变量都可能会略有变化。 ATM我建立了单独的型号，但我更喜欢建立1个型号。
Q3：对于特征选择，我正在使用RF，您建议使用CAT和NUM变量组合的情况有任何更好的方法吗？向前和向后消除并不是真的很好地工作，但不确定是否因为没有足够的数据。
问题4：我面临的另一个问题是，大多数独立变量都是相关的（不是真正的独立），这就是为什么我决定使用功能选择方法的原因。还有其他方法吗？ PCA仅用于线性数据，我不确定数据集何时增加关系是否会保持线性。但是现在看起来是线性的。]]></description>
      <guid>https://stackoverflow.com/questions/79563333/building-a-prediction-model-with-categorical-and-numerical-data</guid>
      <pubDate>Wed, 09 Apr 2025 02:10:42 GMT</pubDate>
    </item>
    <item>
      <title>Facebook先知 - 没有得到期望的结果[关闭]</title>
      <link>https://stackoverflow.com/questions/79563090/facebook-prophet-not-getting-desired-result</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79563090/facebook-prophet-not-getting-desired-result</guid>
      <pubDate>Tue, 08 Apr 2025 21:32:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么XGBoost不处理将数据复制到GPU（直接支持Numpy阵列或Pandas而不是像Cupy这样的库）？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79562678/why-does-xgboost-do-not-handle-the-data-copying-to-gpu-a-direct-support-to-nump</link>
      <description><![CDATA[我正在使用XGBoost，以使其更快地使用GPU方法，代码变得复杂，这个问题对我来说。我对这个主题的研究还不错，我是GPU的新手。]]></description>
      <guid>https://stackoverflow.com/questions/79562678/why-does-xgboost-do-not-handle-the-data-copying-to-gpu-a-direct-support-to-nump</guid>
      <pubDate>Tue, 08 Apr 2025 17:09:01 GMT</pubDate>
    </item>
    <item>
      <title>Hfhubhttperror：403禁止：无。无法访问：https：//hf.co/api/s3proxy [闭幕]</title>
      <link>https://stackoverflow.com/questions/79562246/hfhubhttperror-403-forbidden-none-cannot-access-content-at-https-hf-co-api</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79562246/hfhubhttperror-403-forbidden-none-cannot-access-content-at-https-hf-co-api</guid>
      <pubDate>Tue, 08 Apr 2025 13:52:28 GMT</pubDate>
    </item>
    <item>
      <title>如何在Pytorch中执行全球结构化修剪</title>
      <link>https://stackoverflow.com/questions/79561884/how-to-perform-global-structured-pruning-in-pytorch</link>
      <description><![CDATA[我正在培训CIFAR10以下简单CNN 
  simplecnn（nn.module）：
    def __init __（自我）：
        super（）.__ init __（）
        self.conv1 = nn.conv2d（3，32，kernel_size = 3，padding = 1）
        self.conv2 = nn.conv2d（32，64，kernel_size = 3，padding = 1）
        self.pool = nn.maxpool2d（2，2）
        self.relu = nn.relu（）

        self.fc1 = nn.linear（64 * 8 * 8，128，bias = false）
        self.fc2 = nn.linear（128，128，bias = false）
        self.fc3 = nn.linear（128，10，bias = false）

    def向前（self，x）：
        x = self.pool（self.relu（self.conv1（x）））
        x = self.pool（self.relu（self.conv2（x）））
        x = x.View（-1，64 * 8 * 8）
        x = self.relu（self.fc1（x））
        x = self.relu（self.fc2（x））
        x = self.fc3（x）
        返回x
 
我想在网络的最后部分执行全局结构化修剪，MLP部分（SO  fc1 ， fc2 ， fc3 ），截止百分比。基本上，我想根据总连接性切断 x 神经元（以及所有相对连接）的百分比。在pytorch中，有一个函数可以执行类似的作业： ln_structrud  
 导入torch.nn.utils.prune作为修剪
prune.ln_structruct（model.fc1，name =&#39;strize&#39;，量= fraction_of_neurons_to_prune）
prune.ln_structruct（model.fc2，name =&#39;strize&#39;，量= fraction_of_neurons_to_prune）
prune.ln_structruct（model.fc3，name =&#39;strige&#39;，量= fraction_of_neurons_to_prune）
 
 ，但主要问题是，此函数将逐层而不是全球将小数应用于修剪。我希望某些东西可以截断，例如，网络的MLP部分中的80％的神经元，而不是一层80％。
是否有执行我想要的功能？我自己怎么写？在Pytorch中缺乏执行此非常常见的操作的功能对我来说似乎很奇怪，但是我找不到任何东西。]]></description>
      <guid>https://stackoverflow.com/questions/79561884/how-to-perform-global-structured-pruning-in-pytorch</guid>
      <pubDate>Tue, 08 Apr 2025 11:20:16 GMT</pubDate>
    </item>
    <item>
      <title>分析测试分数是聚类问题还是EDA问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79561831/is-analyzing-test-scores-a-clustering-problem-or-an-eda-problem</link>
      <description><![CDATA[我有一个28个个性评估功能的数据集，该数据集衡量了诸如勤奋或社交能力之类的人格属性，以确定公司工作场所的绩效。我的任务是分析数据集（只有1300名公司中的最高表现者），以查看我是否可以提出成功角色，因为特质或特征的组合会使一个人成功？所有28列均在[0,100]范围内。
我尝试绘制特征或将平均值从最高到最低，但这些感觉太简单了。我可以尝试使用聚类算法，但是我不确定是什么最适合此用例？我尝试了PCA和K-均值，但轮廓得分为0.2，所以我可以肯定的是，我患有尺寸的诅咒。关于如何解决这个问题的任何建议？]]></description>
      <guid>https://stackoverflow.com/questions/79561831/is-analyzing-test-scores-a-clustering-problem-or-an-eda-problem</guid>
      <pubDate>Tue, 08 Apr 2025 10:52:34 GMT</pubDate>
    </item>
    <item>
      <title>损失功能 - 率卡住/常数</title>
      <link>https://stackoverflow.com/questions/79561760/loss-function-gradient-stuck-constant</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79561760/loss-function-gradient-stuck-constant</guid>
      <pubDate>Tue, 08 Apr 2025 10:19:13 GMT</pubDate>
    </item>
    <item>
      <title>ML河的决策树的印刷规则</title>
      <link>https://stackoverflow.com/questions/79561495/printing-rules-from-decision-tree-in-river-ml</link>
      <description><![CDATA[我正在使用河流ML库，并使用决策树模型。我想从训练有素的树木中打印或提取决策规则。但是，看来图书馆目前没有提供内置方法来执行此操作。
如何手动从河中的树模型手动打印决策规则？
  pipeline = compose.pipeline（
        self.extract_features（事件=事件），
        ordinalencoder（），
        lastClassifier（max_depth = 5，track_error = true，remove_poor_attrs = true）
    ）
metric = f1（）
    self.state.update（{&#39;pipeline&#39;：pipeline，&#39;metric&#39;：metric}）


标签= 1如果分类_label其他0

＃检索当前管道组件
pipeline = self.state.value（）[&#39;pipeline&#39;]
模型=管道[&#39;lastClassifier&#39;]
metric = self.state.value（）[&#39;metric&#39;]

＃进行预测并更新度量
predicted_label = model.predict_one（self.state.value（）[&#39;pipeline&#39;] [&#39;dict&#39;]）
吨

＃通过新事件更新模型
model.learn_one（self.state.value（）[&#39;pipeline&#39;] [&#39;dict&#39;]，标签）

＃保存更新的状态
self.state.update（{&#39;pipeline&#39;：pipeline，&#39;metric&#39;：metric}）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79561495/printing-rules-from-decision-tree-in-river-ml</guid>
      <pubDate>Tue, 08 Apr 2025 07:59:08 GMT</pubDate>
    </item>
    <item>
      <title>图像旋转：使用Pytorch进行角度检测的模型</title>
      <link>https://stackoverflow.com/questions/79560879/image-rotation-model-for-angle-detection-using-pytorch</link>
      <description><![CDATA[基本上，我正在尝试创建一个模型，该模型将检测旋转特定图像的角度。另外，我还有一个由1500个文档的数据集，该数据集由上旋转的图像产生
 随机。样本（[0，90，-90，180]，2）
 
每个角度的变化
  random.均匀（-10，10）
 
导致〜4K旋转图像。
所以我想出了当前的模型来预测所需角度的罪和cos：
 类CnnRotAteRegression（nn.Module）：
    def __init __（自我）：
        super（cnnrotateregression，self）.__ init __（）
        self.conv1 = nn.conv2d（3，64，kernel_size = 3）
        self.conv2 = nn.conv2d（64，128，kernel_size = 3）
        self.conv3 = nn.conv2d（128，256，kernel_size = 3）
        self.conv4 = nn.conv2d（256，512，kernel_size = 3）
        self.conv5 = nn.conv2d（512，512，kernel_size = 3）
        
        self.bn1 = nn.batchnorm2d（64）
        self.bn2 = nn.batchnorm2d（128）
        self.bn3 = nn.batchnorm2d（256）
        self.bn4 = nn.batchnorm2d（512）
        self.bn5 = nn.batchnorm2d（512）
        
        self.activation = nn.relu（）
        self.pool = nn.avgpool2d（kernel_size = 2）
        self.pool2 = nn.adaptiveavgpool2d（（8,8））

        self.linear_l1 = nn.linear（512*8*8，512）
        self.linear_l2 = nn.linear（512，256）
        self.linear_l3 = nn.linear（256，2）＃sin + cos

    def向前（self，x）：
        x = self.activation（self.pool（self.bn1（self.conv1（x））））
        x = self.activation（self.pool（self.bn2（self.conv2（x））））
        x = self.activation（self.pool（self.bn3（self.conv3（x））））
        x = self.activation（self.pool（self.bn4（self.conv4（x））））
        x = self.activation（self.pool（self.bn5（self.conv5（x））））
        
        x = self.pool2（x）
        x = x.view（x.Size（0），-1）
        
        x = self.activation（self.linear_l1（x））
        x = self.activation（self.linear_l2（x））
        x = self.linear_l3（x）

        x = f.normalize（x，p = 2，dim = 1）

        返回x
 
训练零件：
  model = cnnrotateRegression（）
型号=型号。

loss_function = nn.mseloss（）
优化器= Optim.Adam（model.parameters（），LR = 0.001）
num_of_epochs = 11


对于范围（num_of_epochs）的时代：
    model.train（）
    Running_loss = 0.0
    对于图像，在tqdm中的标签（train_loader，desc =＆quot;训练循环”：

        图像，标签=图像。

        angles = Angle_to_sin_cos（标签）
        norm_angles = f.normalize（角度，p = 2，dim = 1）

        优化器.zero_grad（）
        输出=模型（图像）
        损失= lose_function（输出，norm_angles）
        loss.backward（）
        优化器.step（）

        running_loss += loss.item（）
    train_loss = runn_loss / len（train_loader）
 
函数将sin和cos转换为角度，反之亦然：
  def angle_to_sin_cos（angle）：
    tensor_angle = Angle.clone（）。distach（）
    radian = tensor_angle * torch.pi / 180.0
    返回Torch.Stack（[[Torch.Cos（Radian），Torch.sin（Radian）]，DIM = 1）

DEF SIN_COS_TO_ANGLE（输出）：
    cos_val，sin_val =输出[：，0]，输出[：，1]
    Angle_rad = torch.atan2（sin_val，cos_val）
    Angle_deg = Angle_rad *（180 / Torch.pi）
    返回angle_deg
 
我的模型在确定范围 +-10度的小角度方面的表现差。您建议改进/增强以实现更好的“小度”。预测？]]></description>
      <guid>https://stackoverflow.com/questions/79560879/image-rotation-model-for-angle-detection-using-pytorch</guid>
      <pubDate>Mon, 07 Apr 2025 22:20:43 GMT</pubDate>
    </item>
    <item>
      <title>对于基于等级的数据集选择的正确模型是什么？</title>
      <link>https://stackoverflow.com/questions/79560209/what-is-the-correct-model-to-choose-for-a-rank-based-dataset-with-many-missing-o</link>
      <description><![CDATA[我目前正在进行一个项目，我计划研究Tiktok歌曲病毒性对Spotify图表表现的影响，以及哪种歌曲特征适度这种关系。
我的数据集包含来自两个平台的每周前50个图表数据，涉及约200周，因此我总共有约20,000个观察结果，其中约9,500个是独特的歌曲。由于图表的性质，歌曲通常仅出现几周，从而导致小组数据集中缺少许多观察结果。我也有许多歌曲特征变量，这些变量是数值的值，以及每首歌曲发布的视频数量，我可以用作独立变量。我计划给每个排名号码的分数，以将层次结构转换为数值。
我当前的方法是使用混合效应模型，因为：

 数据集的嵌套结构（嵌套在歌曲中）

 混合模型对于不平衡数据（缺少观测）是可靠的

 歌曲变异性中的随机效果捕获


这是一个好方法吗？否则，在这种情况下应用的ML方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79560209/what-is-the-correct-model-to-choose-for-a-rank-based-dataset-with-many-missing-o</guid>
      <pubDate>Mon, 07 Apr 2025 14:58:02 GMT</pubDate>
    </item>
    <item>
      <title>单词错误率在第一个时期自动语音识别系统后几乎100％[封闭]</title>
      <link>https://stackoverflow.com/questions/79560091/word-error-rate-almost-100-after-first-epoch-automatic-speech-recognition-syste</link>
      <description><![CDATA[我尝试使用语音脑训练ASR系统。但是，在第一个时期之后，我的单词错误率是疯狂的 - 为99.63％。实际上几乎是100％。这是训练日志的整个行：
 时期：1，LR：1.00E+00-火车损失：5.15-有效损失：4.42，有效CER 81.95，有效的WER。 99.63
 
我不确定我是否只是完全搞砸了。我知道在第一个时代之后很难说，但是我的计算机运行速度真的很慢，所以我只是想知道看起来是否错了。
如果是相关的，则数据集由149,759个话语组成。我了解LM和该表演的代币因素，但我只想知道这是否是主要的危险信号。]]></description>
      <guid>https://stackoverflow.com/questions/79560091/word-error-rate-almost-100-after-first-epoch-automatic-speech-recognition-syste</guid>
      <pubDate>Mon, 07 Apr 2025 14:03:49 GMT</pubDate>
    </item>
    <item>
      <title>与Keras进行渐进学习[关闭]</title>
      <link>https://stackoverflow.com/questions/79559837/progressive-learning-with-keras</link>
      <description><![CDATA[我正在使用UNET类型网络来解决细分问题。我的图像是384x348x3（是频道的最后一个维度）。我使用Keras（TensorFlow后端）。我有一个庞大的数据集，并且面临一些内存问题，这就是为什么我正在与数据机器合作。但是，我的模型正在努力学习，在某个时候，由于内存问题而破裂。为了提供一种可以提高F1分数（精度和召回）的强大学习，我了解了一个想法：以间隔（0.1、0.2、0.3、0.4）切碎数据集，因此首先培训只会占整个数据集的10％。首先拟合之后，我使用训练有素的模型，并使用第一个10％的数据和接下来的20％数据重新训练。这样，我就能获得更合理的F1分数，但记忆问题仍然存在。我不知道这个近似是否有意义，或者我是否在代码的某些部分中弄乱了它：
  def load_progress（self）：
    尝试：
        开放（self.models_path + triending_progress.json.json＆quot” r＆quot;“）为f：
           数据= JSON.LOAD（F）
           返回数据[last_phase_completed＆quot&#39;]
    除了filenotfounderror：
        返回-1＃如果没有保存进展，请从0开始
    
def save_progress（self，阶段）：
    开放（self.models_path +&#39;triending_progress.json.json＆quot“ w＆quot”）为f：
        json.dump（{&#39;last_phase_completed＆quot;：phase}，f）

增量= [0.1、0.2、0.3、0.4]＃％dat datos USADOS EN CADA FASE
datasets_indices = []
total_datos = len（火车）
    
inicio = 0
以增量为INC：
    fin = inicio + int（inc * total_datos）
    datasets_indices.append（list（range（inicio，fin））））
    inicio = fin＃包括旧组和新的数据组
            
    ＃加载最后一个完整的阶段
    last_phase_completed = self.load_progress（）


模型= []
对于我，枚举（datasets_indices）中的subset_indices：
    
    train_sub = train.iloc [subset_indices]
    train_sub = train_sub.sample（frac = 1.0，Random_state = 7）
    val = val.sample（frac = 1.0，Random_state = 7）
    train_loader = datagenerator（data = trib_sub.reset_index（drop =; true＆quort; quot;），
                                        batch_size = batch_size，
                                        dim =（高度，宽度））
    验证_loader = datagenerator（data = val.reset_index（drop =＆quot; true＆quort; quot），
                                            batch_size = batch_size，
                                            dim =（高度，宽度））
            
    如果i＆lt; = last_phase_completed：
        继续＃跳过阶段已经完成
            
    {len（subset_indices）}样本＆quort＆quort&#39;&#39;
    logging.info（f＆quot; \ n training阶段{i+1}带{len（subset_indices）}示例＆quot;）
            
    历史记录，model_name，model，train_loader，val_loader = vgapp.execute（train_loader，validation_loader，i，model）
    ＃Guardar Modelo y Progreso
    model.Save（conf [model; quod; quot; quartial; quartial; quot; quote; quode; quode&#39; + f＆quot; f＆quot&#39;ground&#39;/modelo_fase_ {i + 1} .h5; h5;
    vgapp.save_progress（i）
 
  vgapp.execute 是一个函数，如果步骤= 0，则它构建模型，对其进行编译并适合它。否则，它采用输入模型并适合它。
在一些时期之后，Docker断断续续，我想这是因为记忆问题。
我的问题是：

我在这里做什么以提高F1分数并减少记忆问题？
如果这样做，为什么我会继续遇到内存问题？
有更好的方法吗？
]]></description>
      <guid>https://stackoverflow.com/questions/79559837/progressive-learning-with-keras</guid>
      <pubDate>Mon, 07 Apr 2025 12:10:06 GMT</pubDate>
    </item>
    <item>
      <title>通过预测前馈神经网络预测可变长度的输出？</title>
      <link>https://stackoverflow.com/questions/79559377/how-to-handle-outputs-of-variable-length-when-predicting-with-a-feed-forward-neu</link>
      <description><![CDATA[我正在处理一个回归问题，在给定固定大小的输入x时，输出y可以是可变长度值的序列。
输入和输出都是归一化的浮点值。因此，我们正在谈论回归任务。
问题以y数组样本的可变大小（最大长度46）。
平均而言，只有前30-35个值（在46中）有效。
因此，要训练网络，我正在尝试的解决方案是：

将每个Y阵列样品的非valid值（0.0）
火车和预测
&#39;undad＆quot＆quot＆quot输出阵列通过删除所有尾随零（或非常小的值）。

问题是：

实际上，小值在0.0左右也可以是有效值，从而产生歧义。也许最好使用像-100这样的可笑的怪异数字？
看来，网络从未真正从有效的谷（例如：2.3）跳到0.0，但是它正在产生平稳的过渡到0.0，从而产生了非常糟糕的输出。

解决这个问题的好解决方案是什么？
如果数组值是整数，则可以使用特殊的int作为令牌。但是拥有浮子会使一切变得更加棘手。]]></description>
      <guid>https://stackoverflow.com/questions/79559377/how-to-handle-outputs-of-variable-length-when-predicting-with-a-feed-forward-neu</guid>
      <pubDate>Mon, 07 Apr 2025 08:13:54 GMT</pubDate>
    </item>
    <item>
      <title>tensorboard的add_hparams（）函数无法正常工作</title>
      <link>https://stackoverflow.com/questions/78857269/add-hparams-function-from-tensorboard-doesnt-work-properly</link>
      <description><![CDATA[我正在尝试将指标添加到此摘要Writer，但它不起作用。
我正在使用summarywriter的add_hparams（）函数，其详细信息可以在此处找到： https://pytorch.org/docs/stable/tensorboard.html 。
我这样做：
  writer = summaryWriter（f&#39;runs/lstm_experiment_final&#39;）

对于tqdm（range（num_epochs））中的e：
    tr_loss，tr_f1，tr_precision，tr_recall = triending_loop（型号，train_dataloader，loss_function，优化器，e，writer）
    val_loss，val_f1，val_precision，val_recall = validation_loop（型号，test_dataloader，loss_function，e，e，writer）

metric_dict = {&#39;损失/火车&#39;：tr_loss，&#39;损失/有效&#39;：val_loss，
                         &#39;F1/train&#39;：tr_f1，&#39;f1/有效&#39;：val_f1，
                         “精确/火车”：tr_precision，“精确/有效”：val_precision，
                         “召回/火车”：tr_recall，&#39;召回/有效&#39;：val_recall}
writer.add_hparams（best_params，metric_dict，global_step = num_epochs-1）
writer.close（）    
 
这就是发生的事情。
 在此处输入图像说明 
换句话说，超参数确实在张板上记录，但公制值不是。
我希望有人已经看到我的问题，并且知道如何解决这个问题。
预先感谢。]]></description>
      <guid>https://stackoverflow.com/questions/78857269/add-hparams-function-from-tensorboard-doesnt-work-properly</guid>
      <pubDate>Sun, 11 Aug 2024 00:21:56 GMT</pubDate>
    </item>
    <item>
      <title>使用armadillo库计算邓恩的索引的错误</title>
      <link>https://stackoverflow.com/questions/77341536/error-calculating-dunns-index-in-c-using-armadillo-library</link>
      <description><![CDATA[我一直在尝试使用Armadillo库找到我正在处理的较大算法的Dunns索引。每当我运行代码时，我都会得到一个输出 dunns索引：-Nan（ind），并且错误地说我不在索引。我提供下面的代码以及我用于测试的主要功能。该代码还具有我添加的随机检查来尝试解决问题。
  #include＆lt; iostream＆gt;
#include＆lt; armadillo＆gt;

使用名称空间性std;
使用名称空间ARMA；

double dunns（int clusters_number，const mat＆amp＆amp; distm，const uvec＆amp; ind）{
    //确定唯一群集的数量
    int i = max（ind）;
    VEC分母；

    for（int i2 = 1; i2＆lt; = i; ++ i2）{
        uvec indi = find（ind == i2）;
        uvec indj = find（ind！= i2）;

        //检查Indi和Indj是否没有空
        如果（！indi.is_empty（）＆amp;＆amp;！
            垫子温度；

            //检查索引是否在范围内提取之前
            if（indi.max（）＆lt; distm.n_rows＆amp;＆amp; indj.max（）＆lt; distm.n_cols）{
                temp = distm.submat（indi，indj）;
                分母= join_cols（分母，vectorise（temp））;
            }
            别的 {
                //调试：引起错误的打印索引
                cout＆lt;＆lt; “错误：集群的界限”索引。 ＆lt;＆lt; i2＆lt;＆lt;端
            }
        }
    }

    double num = 0.0;  //将num初始化为0.0

    //在找到最低限度之前检查分母是否没有空
    如果（！denominator.is_empty（））{
        num = min（分母）;
    }

    MAT NEG_OBS = ZEROS＆lt; MAT＆gt;（distm.n_rows，distm.n_cols）;

    for（int ix = 1; ix＆lt; = i; ++ ix）{
        uvec indxs = find（ind == ix）;

        //检查INDXS是否没有空
        如果（！indxs.is_empty（））{
            //在设置元素之前检查索引是否在范围内
            if（indxs.max（）＆lt; distm.n_rows）{
                neg_obs.submat（indxs，indxs）.fill（1.0）;
            }
        }
    }

    //打印中间值
    cout＆lt;＆lt; “中间值：” ＆lt;＆lt;端
    cout＆lt;＆lt; “分母：” ＆lt;＆lt;分母＆lt;＆lt;端
    cout＆lt;＆lt; ＆quot num：; quot; ＆lt;＆lt; num＆lt;＆lt;端

    MAT DEM = neg_obs％distm;
    double max_dem = max（max（dem））;

    //打印max_dem
    cout＆lt;＆lt; ＆quot&#39;max_dem：＆quot; ＆lt;＆lt; max_dem＆lt;＆lt;端

    double di = num / max_dem;
    返回di;
}

int main（）{
    //用于测试的新输入
    int clusters_number = 2;

    //修改的差异矩阵（4x4）
    MAT DISTM（4，4）;
    distm＆lt;＆lt; 0.0＆lt;＆lt; 1.0＆lt;＆lt; 2.0＆lt;＆lt; 3.0
        ＆lt;＆lt; 1.0＆lt;＆lt; 0.0＆lt;＆lt; 1.0＆lt;＆lt; 2.0
        ＆lt;＆lt; 2.0＆lt;＆lt; 1.0＆lt;＆lt; 0.0＆lt;＆lt; 1.0
        ＆lt;＆lt; 3.0＆lt;＆lt; 2.0＆lt;＆lt; 1.0＆lt;＆lt; 0.0;

    //修改的群集指数（4x1）
    arma :: uvec ind;
    ind＆lt;＆lt; 1＆lt;＆lt; 1＆lt;＆lt; 2＆lt;＆lt; 2;

    //打印输入差异矩阵
    cout＆lt;＆lt; “差异矩阵：” ＆lt;＆lt;端
    cout＆lt;＆lt; distm＆lt;＆lt;端

    //打印群集索引
    cout＆lt;＆lt; “集群索引：” ＆lt;＆lt;端
    cout＆lt;＆lt; ind＆lt;＆lt;端

    double di = dunns（clusters_number，distm，ind）;

    cout＆lt;＆lt; ＆quot“邓恩的索引：” ＆lt;＆lt; di＆lt;＆lt;端

    返回0;
}
 
数据格式似乎正确。我正在使用Double用于差异矩阵和ARMA :: UVEC用于集群指数，这是合适的。
数据对齐：差异矩阵和群集指数中数据点的对齐似乎是正确的。矩阵中的每个数据点对应于集群指数中的条目。
似乎在差异矩阵中似乎没有任何空簇或缺少数据点。数据似乎已经完成。
鉴于数据似乎正确对齐，并且没有空的群集或丢失的数据没有明显的问题，因此我仍然遇到“界限”的“索引”很困惑。在下提取过程中的错误。]]></description>
      <guid>https://stackoverflow.com/questions/77341536/error-calculating-dunns-index-in-c-using-armadillo-library</guid>
      <pubDate>Sun, 22 Oct 2023 20:09:58 GMT</pubDate>
    </item>
    </channel>
</rss>