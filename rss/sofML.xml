<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Sep 2024 09:17:31 GMT</lastBuildDate>
    <item>
      <title>训练准确率不断提高，但验证准确率早期停滞</title>
      <link>https://stackoverflow.com/questions/78947096/training-accuracy-keeps-increasing-but-validation-plateaus-early</link>
      <description><![CDATA[我尝试使用自己实现的 Resnet 模型对 CIFAR-100 数据集进行分类。
我尝试了多种不同的超参数配置，更改了学习率、批量大小、辍学率、数据增强和正则化，但我所做的一切都无法将验证准确率提高 40% 以上，而训练准确率可以达到 99%。
我意识到训练准确率高但验证准确率低是过度拟合的标志，但在增加正则化参数和辍学率后，我仍然没有看到任何改善。训练、验证和测试的分割由 CIFAR-100 提供，因此分别为 40000、10000、10000。
有人知道如何突破这个瓶颈，或者知道我可能哪里出错了吗？
以下是我一直在尝试的超参数类型：
learning_rates = [0.001, 0.0001]
batch_sizes = [16, 32]
dropout_rates = [0.3,0.5]
decay = [0.001, 0.0001]

以下是我一直在增强数据的方式：
transform = transforms.Compose([
transforms.RandomCrop(32, padding=4),
transforms.RandomHorizo​​ntalFlip(),
transforms.RandomRotation(10),
transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

DATA_ROOT_FOLDER = &#39;./cifar-100-python&#39; 

train_data = datasets.CIFAR100(root=f&quot;{DATA_ROOT_FOLDER}&quot;, train=True, download=True, transform=transform)
test_data = datasets.CIFAR100(root=f&quot;{DATA_ROOT_FOLDER}&quot;, train=False, download=True, transform=transform)

train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)

batch_size = 64
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)

这些是我得到的结果。
准确度图
准确度图失落]]></description>
      <guid>https://stackoverflow.com/questions/78947096/training-accuracy-keeps-increasing-but-validation-plateaus-early</guid>
      <pubDate>Wed, 04 Sep 2024 06:18:19 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中进行向量搜索，根据上下文获取独特性分数</title>
      <link>https://stackoverflow.com/questions/78946820/vector-search-in-python-to-get-the-unqueness-score-according-to-context</link>
      <description><![CDATA[我有一篇带有标题和说明的博客文章，我想将其唯一性与 CSV 文件中的多个博客条目进行比较。CSV 包含多个博客，每个博客都有标题和元描述。
我目前使用 TF-IDF 矢量化和余弦相似度将单个博客与 CSV 文件中的所有条目进行比较。但是，这种方法仅基于确切的单词而不是上下文进行匹配。]]></description>
      <guid>https://stackoverflow.com/questions/78946820/vector-search-in-python-to-get-the-unqueness-score-according-to-context</guid>
      <pubDate>Wed, 04 Sep 2024 04:27:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Google Colab 中导入 KerasRegressor？</title>
      <link>https://stackoverflow.com/questions/78946669/how-do-i-import-kerasregressor-in-google-colab</link>
      <description><![CDATA[我正在使用 Google colab，在导入 KerasRegressor 时遇到问题。
我运行：
from tensorflow.keras.wrappers.scikit_learn import KerasRegressor

并收到以下错误：
ModuleNotFoundError：没有名为“tensorflow.keras.wrappers”的模块

在一些论坛中，我发现有人解决了“scikeras”的问题，但我在 colab 上遇到了这个问题。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78946669/how-do-i-import-kerasregressor-in-google-colab</guid>
      <pubDate>Wed, 04 Sep 2024 03:10:09 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 回归器给出非常糟糕的相对误差％[关闭]</title>
      <link>https://stackoverflow.com/questions/78945802/xgboost-regressor-giving-very-bad-relative-error</link>
      <description><![CDATA[当我训练 XGBRegressor 时，对因变量进行了 boxcox 变换，以获得更高的线性度，因为它可以改善模型。对于标准化指标，我获得了 94.7% 的良好准确度，rmse 良好，相对误差 % 为 1.8%。但是当我尝试对因变量进行逆变换时，相对误差 % 为 245%。这令人担忧，因为随机森林给出的相对误差 % 为 10。随机森林和 XGBoost 几乎给出了因变量形式相同的平均绝对误差，但不知何故 XG 的相对误差 % 为 245%。这怎么可能呢？
我尝试过 hypertuning XGBoost，希望得到一些好消息，但错误率上升到了 450%。]]></description>
      <guid>https://stackoverflow.com/questions/78945802/xgboost-regressor-giving-very-bad-relative-error</guid>
      <pubDate>Tue, 03 Sep 2024 19:28:23 GMT</pubDate>
    </item>
    <item>
      <title>深度 CFR 实现</title>
      <link>https://stackoverflow.com/questions/78945640/deep-cfr-implementation</link>
      <description><![CDATA[我从原始 Deep CFR 文章中获取了代码
论文
我现在正在为我的游戏实现 Deep CFR 算法，当我编写完整算法时，我遇到了很多错误。所以我的问题是，本文末尾的代码是否完全正确，错误是否在我的代码中？如果有人已经为他们自己的任务实现了 Deep CFR 并且可以分享提示/代码，那就太好了
如果有人愿意提供帮助，我可以上传我的实现。它需要最终确定，我没有足够的经验来了解如何正确实现它。
这是我的代码：

nn.py
memory.py
deep_cfr.py
game_tree.py
utils.py

对于这个游戏，我从这个库中获取了 texasholdem。]]></description>
      <guid>https://stackoverflow.com/questions/78945640/deep-cfr-implementation</guid>
      <pubDate>Tue, 03 Sep 2024 18:26:16 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的均方误差成本函数如何具有与 y-hat（预测）相对应的 y（目标）？[关闭]</title>
      <link>https://stackoverflow.com/questions/78945062/how-does-the-mean-squared-error-cost-function-from-machine-learning-have-a-y-ta</link>
      <description><![CDATA[这个问题与 Coursera 上的 Andrew Ng 机器学习专业课程有关。
在平方误差成本函数公式中，我们从 y-hat（预测）中减去 y（目标）并对其求平方。但 y-hat 来自一个新的输入，我们已经在函数（直线）上找到了它的预测；如果 x 输入是一个在训练集上未见过的全新值，它如何有相应的 y（目标）来减去？
我可能误解了这里的东西。
这是一个学习问题，所以我认为我误解了一些东西，或者课程只是让我理解一些东西——这是课程的第一周。]]></description>
      <guid>https://stackoverflow.com/questions/78945062/how-does-the-mean-squared-error-cost-function-from-machine-learning-have-a-y-ta</guid>
      <pubDate>Tue, 03 Sep 2024 15:27:40 GMT</pubDate>
    </item>
    <item>
      <title>要求法学硕士 (LLM) 取一个值并从可接受的值列表中选择最适用的标签。我该如何预防幻觉？[关闭]</title>
      <link>https://stackoverflow.com/questions/78944999/asking-an-llm-to-take-a-value-and-choose-the-most-applicable-tag-from-an-accepte</link>
      <description><![CDATA[我有一个工作流，其中有大约 17,000 个值，这些值代表给定公司的行业价值（例如金融科技、医疗保健等）。其中许多被认为过于具体，因此我构建了一个提示，要求它获取每个值并从 250 个已批准的行业标签列表中选择最合适的值。我的问题是，尽管提示中明确说明，但 LLM 仍然以相当高的频率产生幻觉（900 个不同的值）。这是我的提示：
您将获得两个列表，一个包含公司所在行业的已批准值（行业价值），另一个包含广泛的不同行业（行业标签）。您的任务是将第二个列表中的每个行业标签与第一个列表中最合适的行业值进行匹配。风险投资公司将使用这些标签来识别他们可能投资的公司，因此需要从这个角度对其进行评估。只返回一个值至关重要。请勿返回不在批准的行业值列表中的值。如果没有相关匹配，则返回“无匹配”。

仅返回每个行业标签的批准列表中匹配的行业值，

格式为 YAML，不包含任何超出此格式的附加文本、说明或内容。 不返回任何额外文本至关重要。
在输入和输出之间保留行业顺序也至关重要，仅反映基于所提供信息的必要分类。 请不要返回 YAML 输出之外的任何其他文本。 输出格式与提供的示例输出相同至关重要。

每个行业标签应具有以下列表中的一个行业值：

3D 打印
配件
...

示例输入：
- 行业标签：农业加工
- 行业标签：金融科技
- 行业标签：胡言乱语
...

Yaml 输出：
- 行业标签：
农业加工：
行业价值：农业

- 行业标签：
金融科技：
行业价值：金融科技

- 行业标签：
胡言乱语：
行业价值：不匹配
...

以下是行业价值：
- 行业标签：多元化材料
- 行业标签：政府和公共服务
- 行业标签：医疗管理咨询
...

此处使用省略号缩短提示显示。尽管我已要求它不要生成批准列表之外的值，但它仍然会生成，我需要一些关于如何解决此问题的提示。]]></description>
      <guid>https://stackoverflow.com/questions/78944999/asking-an-llm-to-take-a-value-and-choose-the-most-applicable-tag-from-an-accepte</guid>
      <pubDate>Tue, 03 Sep 2024 15:11:06 GMT</pubDate>
    </item>
    <item>
      <title>我的海康威视摄像机 FPS 低且延迟严重</title>
      <link>https://stackoverflow.com/questions/78943962/low-fps-and-lot-of-delay-with-my-hikvision-cam</link>
      <description><![CDATA[我有一个任务，使用 OpenCV 处理来自 Hikvision IP 摄像机的流媒体视频。最初，视频的 FPS 约为 20-25，延迟为 2-3 秒。然而，随着代码运行时间的延长，FPS 迅速下降，延迟增加。最终，FPS 下降到 2-3，视频冻结。
class VideoLoader:
@staticmethod
def load_video(video_path):
cap = cv2.VideoCapture(video_path)
cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc(&#39;M&#39;, &#39;J&#39;, &#39;P&#39;, &#39;G&#39;))
cap.set(cv2.CAP_PROP_FPS, 25)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) 
assert cap.isOpened(), &quot;Video dosyası okunurken hata oluştu&quot;
return cap

我尝试过使用 GPU、采用多线程和降低分辨率等方法，但这些方法效果都不太好。您认为问题是什么，我该如何解决它
def frame_reader(cap, frame_queue):
while cap.isOpened():
success, frame = cap.read()
if not success:
break
if not frame_queue.full(): # 检查队列是否有空间
frame_queue.put(frame)
cap.release()
frame_queue.put(None) # 流结束信号

def video_processor(frame_queue, output_queue, model, class_names, playing_sounds):
Threshold = 0.5 # 测试结果
device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model.to(device)

while True:
frame = frame_queue.get()
if frame is None: # 流结束信号
break
start_time = time.time()
img = cv2.resize(frame, (640, 480))
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).float().unsqueeze(0).to(device)
img_tensor /= 255.0 # 标准化

def video_detection(video_source):
cap = VideoLoader.load_video(video_source)
model = YOLO(&quot;YOLO-Weights/ppe.pt&quot;)
class_names = [&#39;safety-glasses&#39;, &#39;gloves&#39;, &#39;orange-vest&#39;, &#39;yellow-vest&#39;,]
playing_sounds = set()

frame_queue = Queue(maxsize=5)
output_queue =队列（最大大小=5）

reader_thread = threading.Thread（目标=frame_reader，参数=（cap，frame_queue），守护进程=True）
processor_thread = threading.Thread（目标=video_processor，参数=（frame_queue，output_queue，model，class_names，played_sounds），守护进程=True）

reader_thread.start()
processor_thread.start()
]]></description>
      <guid>https://stackoverflow.com/questions/78943962/low-fps-and-lot-of-delay-with-my-hikvision-cam</guid>
      <pubDate>Tue, 03 Sep 2024 10:50:27 GMT</pubDate>
    </item>
    <item>
      <title>如何实现自适应负荷和光伏预测模型的强化学习？[关闭]</title>
      <link>https://stackoverflow.com/questions/78942987/how-to-implement-reinforcement-learning-for-adaptive-load-and-pv-forecasting-mod</link>
      <description><![CDATA[我正在开展一个项目，使用时间序列数据构建负载和光伏 (PV) 预测模型。目前，我已经使用随机森林和 LSTM 实现了模型，虽然它们表现相当不错，但由于趋势多变，我遇到了挑战。
我面临的问题是，负载和 PV 输出由于外部因素而高度可变。例如，负载因不同的消费模式而变化，PV 输出因气候变化而波动。我需要一个可以动态适应这些变化的模型。
我正在考虑使用强化学习 (RL) 来开发一个可以实时适应这些环境变化的模型。我的目标是实施一种在线学习方法，让模型不断学习并根据新数据进行自我更新。但是，我发现重新训练随机森林和 LSTM 等模型在计算上非常昂贵。
我的问题是：

如何有效地实施强化学习以实现这种自适应预测？
是否有特定的 RL 算法或技术非常适合动态变化环境中的时间序列预测？
在在线学习场景中，我可以使用哪些策略来平衡模型性能和计算成本之间的权衡？
有任何指导或资源吗？

我已经实施了随机森林和 LSTM 模型来进行负载和 PV 预测。这些模型对于初始预测效果很好，但很难适应数据随时间变化的趋势。我探索了在线学习方法，希望它们能提供实时适应的解决方案。但是，我发现不断重新训练这些模型在计算上非常昂贵，并且不适合我的用例。
我希望开发一种可以实时适应负载和 PV 趋势变化的模型，而无需不断重新训练。我的目标是找到一种可以动态高效地处理数据变化的方法。
到目前为止，我尝试过的模型要么需要频繁重新训练，这很昂贵，要么它们无法足够快地适应数据的变化。这导致预测准确性随着时间的推移而下降。]]></description>
      <guid>https://stackoverflow.com/questions/78942987/how-to-implement-reinforcement-learning-for-adaptive-load-and-pv-forecasting-mod</guid>
      <pubDate>Tue, 03 Sep 2024 06:46:11 GMT</pubDate>
    </item>
    <item>
      <title>SAM 模型中无法检测图像 - TypeError：无法处理此数据类型</title>
      <link>https://stackoverflow.com/questions/78942834/image-not-detecting-in-sam-model-typeerror-cannot-handle-this-data-type</link>
      <description><![CDATA[每当我上传任何类型的图像时，都会出现相同的错误。它是否只处理高质量图像（或任何特定类型的图像），还是我的代码中存在一些错误？
我尝试了不同的图像，上面的代码是 chatgpt 经过一些修改后给出的。仍然没有运气。我得到一个
TypeError：无法处理此数据类型：（1, 1, 640, 3），|u1

代码：
import torch
import numpy as np
from PIL import Image
fromsegment_anything import sam_model_registry, SamPredictor
from google.colab import files

# 加载 SAM 模型

sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;/content/sam_vit_b_01ec64.pth&quot;)
predictor = SamPredictor(sam)

uploaded = files.upload()
image_name = list(uploaded.keys())[0]

image = Image.open(image_name).convert(&quot;RGB&quot;)
image_np = np.array(image)

# 检查图像形状

print(f&quot;原始图像形状：{image_np.shape}&quot;)

# 如果存在额外维度，则删除它们

if len(image_np.shape) == 4 and image_np.shape[0] == 1:
image_np = image_np.squeeze(0) # 如果第一个维度的大小为 1，则删除它

# 确保图像的格式和类型正确

image_np = image_np.astype(np.uint8)

print(f&quot;处理后的图像形状：{image_np.shape}&quot;)

# 将图像设置为 SAM 预测器

predictor.set_image(image_np)

# 预测图像的蒙版

masks = predictor.predict()

# 确保您有蒙版并使用它们

if mask is not None and len(masks) &gt; 0:
mask = mask[0] # 假设第一个掩码就是您需要的

# 将掩码应用于图像
masked_image = np.where(mask[..., None], image_np, 0) # 将掩码应用于图像

# 将掩码图像转换回 PIL 图像
masked_image = Image.fromarray(masked_image)

# 显示掩码图像
masked_image.show()

else:
print(&quot;未找到给定图像的掩码。&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78942834/image-not-detecting-in-sam-model-typeerror-cannot-handle-this-data-type</guid>
      <pubDate>Tue, 03 Sep 2024 05:49:49 GMT</pubDate>
    </item>
    <item>
      <title>梯度盗贼代理的性能问题</title>
      <link>https://stackoverflow.com/questions/78942595/performance-issue-with-gradient-bandit-agent</link>
      <description><![CDATA[我正在阅读 Sutton&amp;Barto 的《强化学习：导论》。尝试测试梯度强盗代理（第 2.7 章）。但性能极低。我试过：

使用基线 = 平均奖励，不使用基线；
alpha = 0.1、0.2、0.3、0.4；
初始偏好 H = 0、1、10、100。

没有任何帮助。
这是我的 Python 代码，用于代理的 生命步骤 = 动作选择 + 参数更新 (self = agent)：
# 用于概率计算：
pref_exps = np.exp(self.params[&quot;preferences&quot;])
pref_exps_sum = sum(pref_exps)

# 选择强盗：
choice_dice = np.random.uniform() * pref_exps_sum
accum_pref_exp = 0
for i, pref_exp in enumerate(pref_exps):
accum_pref_exp += pref_exp
if accum_pref_exp &gt;= choice_dice:
self.chosen_bandit_i = i
break

# self.reward 在此处填充：
self.perform_bandit(self.chosen_bandit_i)

# 更新基线：
self.params[&quot;lifetime&quot;] += 1
self.params[&quot;average_reward&quot;] += 1 / self.params[&quot;lifetime&quot;] * (self.reward - self.params[&quot;average_reward&quot;])

# 更新偏好：
for i, pref_exp in enumerate(pref_exps):
probability = pref_exp / pref_exps_sum
if i == self.chosen_bandit_i:
self.params[&quot;preferences&quot;][i] += self.params[&quot;alpha&quot;] * (self.reward - self.params[&quot;average_reward&quot;]) * (1 - probability)
else:
self.params[&quot;preferences&quot;][i] -= self.params[&quot;alpha&quot;] * (self.reward - self.params[&quot;average_reward&quot;]) * probability

此代码导致性能极差（100 个代理，每个代理访问自己的 10 个 1-armed-bandits，测试超过 2000 步），我们可以从下图中看到：

我看过这篇帖子，修复错误后，它的代码似乎与我的代码相同，这也是那篇帖子的原因。但与我的代码不同，那篇帖子的代码在纠正后可以正常工作！
我不知道我在哪里犯了错误。你能帮助我正确使用Gradient-bandit 代理的全部功能吗？]]></description>
      <guid>https://stackoverflow.com/questions/78942595/performance-issue-with-gradient-bandit-agent</guid>
      <pubDate>Tue, 03 Sep 2024 03:40:50 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：在层“conv2d_7”上调用“set_weights(weights)”，权重列表长度为 2，但该层需要 1 个权重</title>
      <link>https://stackoverflow.com/questions/78836514/valueerror-called-set-weightsweights-on-layer-conv2d-7-with-a-weight-list</link>
      <description><![CDATA[我尝试在模型中的某一层上设置权重，但无济于事。
我在网上查找了类似问题的解决方案，但似乎都不起作用。变量“w”（如下面代码所示）的结构为 [numpy array, numpy array]。第一个的大小为 (3, 3, 3, 64)，第二个的形状为 (64,)。我想实现与 tf 2.X 中的“weights”kwarg 类似的功能，但似乎无法让它工作。这是我的代码：
encoder = Sequential()
encoder.add(layers.Conv2D(64, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;,use_bias=False,input_shape=(SIZE,SIZE,3)))
w = model.layers[0].get_weights()
encoder.layers[0].set_weights([w])
encoder.add(layers.MaxPooling2D((2, 2),padding=&#39;same&#39;))
encoder.add(layers.Conv2D(32, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;,weights=model.layers[2].get_weights()))
encoder.add(layers.MaxPooling2D((2, 2), padding=&#39;same&#39;))
encoder.add(layers.Conv2D(16, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;,weights=model.layers[4].get_weights()))
encoder.add(layers.MaxPooling2D((2, 2), padding=&#39;same&#39;))
encoder.summary()

错误：
错误：ValueError：您在层“conv2d_7”上调用了`set_weights(weights)`，权重列表长度为 2，但该层需要 1 个权重。
]]></description>
      <guid>https://stackoverflow.com/questions/78836514/valueerror-called-set-weightsweights-on-layer-conv2d-7-with-a-weight-list</guid>
      <pubDate>Mon, 05 Aug 2024 21:33:29 GMT</pubDate>
    </item>
    <item>
      <title>自定义模型聚合器 TensorFlow Federated</title>
      <link>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</link>
      <description><![CDATA[我正在尝试使用 TensorFlow Federated，使用 FedAvg 算法模拟训练过程。
trainer = tff.learning.algorithms.build_weighted_fed_avg(
model_fn= tff_model,
client_optimizer_fn=client_optimizer,
server_optimizer_fn=server_optimizer
)

我想使用自定义权重来聚合客户端的更新，而不是使用它们的样本数量。我知道 tff.learning.algorithms.build_weighted_fed_avg() 有一个名为 client_weighting 的参数，但唯一接受的值来自类 tff.learning.ClientWeighting，它是一个枚举。
还有其他方法可以使用自定义权重吗？]]></description>
      <guid>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</guid>
      <pubDate>Mon, 05 Aug 2024 16:06:48 GMT</pubDate>
    </item>
    <item>
      <title>UnicodeEncodeError：'charmap'编解码器无法对位置 19-38 的字符进行编码：字符映射到 <undefined></title>
      <link>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</link>
      <description><![CDATA[我正在开发一个基于 Flask 的 Web 应用程序，用户可以上传图像以使用机器学习模型进行预测。上传的图像存储在本地目录中，并使用预先训练的模型进行预测。但是，当我点击预测按钮时
是什么导致了这个 UnicodeEncodeError？
我该如何解决这个问题，以确保我的应用程序能够正确处理图像上传和预测？
在 Flask 环境中，尤其是在 Windows 上，是否有处理字符编码的最佳实践？
==app.py====
@app.route(&#39;/uploadimage&#39;, methods=[&#39;GET&#39;, &#39;POST&#39;])
def upload_image():

file = request.files[&#39;my_image&#39;]
# 获取预测
predict_label = predict_label(img_path)
# 使用 flash 消息返回预测标签
flash(f&quot;Prediction: {predicted_label}&quot;, &quot;success&quot;)
os.remove(img_path) # 处理后删除临时文件
return render_template(&#39;uploadimage.html&#39;) # 对于 GET 请求，呈现表单


即使我设置了环境变量“UTF-8”，我仍然收到此错误
错误
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py”，第 19 行，位于 encode 中
返回codecs.charmap_encode(input,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: &#39;charmap&#39; 编解码器无法对位置 19-38 中的字符进行编码：字符映射到未定义。
============
即使我得到了一个最简单的代码来测试编码
标题是“要测试您的控制台是否可以处理 UTF-8，请尝试输出带有特殊字符或 Unicode 字符的文本：&quot;
print(&quot;UTF-8 test: àéîöü — 中文 — العربية&quot;)


错误与此相同好吧
print(&quot;UTF-8 测试：����� � \u4e2d\u6587 � \u0627\u0644\u0639\u0631\u0628\u064a\u0629&quot;)
文件 &quot;C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py&quot;，第 19 行，在编码中
返回 codecs.charmap_encode(input,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: &#39;charmap&#39; 编解码器无法对位置中的字符进行编码20-21：字符映射到 ]]></description>
      <guid>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</guid>
      <pubDate>Mon, 22 Apr 2024 17:25:20 GMT</pubDate>
    </item>
    <item>
      <title>如何沿批次将张量连接到 keras 层（不指定批次大小）？</title>
      <link>https://stackoverflow.com/questions/68345125/how-to-concatenate-a-tensor-to-a-keras-layer-along-batch-without-specifying-bat</link>
      <description><![CDATA[我想将嵌入层的输出与自定义张量 (myarr / myconst) 连接起来。我可以使用固定的批处理大小指定所有内容，如下所示：
import numpy as np
import tensorflow as tf

BATCH_SIZE = 100
myarr = np.ones((10, 5))
myconst = tf.constant(np.tile(myarr, (BATCH_SIZE, 1, 1)))

# 模型定义
inputs = tf.keras.layers.Input((10,), batch_size=BATCH_SIZE)
x = tf.keras.layers.Embedding(10, 5)(inputs)
x = tf.keras.layers.Concatenate(axis=1)([x, myconst])
model = tf.keras.models.Model(inputs=inputs, output=x)

但是，如果我不要指定批处理大小和平铺我的数组，即仅以下...
myarr = np.ones((10, 5))
myconst = tf.constant(myarr)

# 模型定义
inputs = tf.keras.layers.Input((10,))
x = tf.keras.layers.Embedding(10, 5)(inputs)
x = tf.keras.layers.Concatenate(axis=1)([x, myconst])
model = tf.keras.models.Model(inputs=inputs, output=x)

... 我收到一个错误，指定形状 [(None, 10, 5), (10, 5)] 无法连接。有没有办法添加这个 None / batch_size 轴以避免平铺？
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/68345125/how-to-concatenate-a-tensor-to-a-keras-layer-along-batch-without-specifying-bat</guid>
      <pubDate>Mon, 12 Jul 2021 09:40:09 GMT</pubDate>
    </item>
    </channel>
</rss>