<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 09 Feb 2024 06:17:44 GMT</lastBuildDate>
    <item>
      <title>即使将其设置为可训练，机器学习模型也不会训练权重</title>
      <link>https://stackoverflow.com/questions/77965679/machine-learning-model-does-not-train-weights-even-after-setting-it-trainable</link>
      <description><![CDATA[以下是我一直在研究的模型。我一直在尝试使用生成器使用数据集 UCF-101 来训练它，但由于某种原因，即使将 VGG19 预训练的层设置为可训练后，它们仍然不会更新其权重值。我尝试了很多替代方案，但到目前为止没有任何效果。
我看到所有其他图层权重都在更新，但那些没有。
我的问题是：
什么可能导致某些可训练层在反向传播期间无法训练？
这是我的模型。
导入tensorflow为tf
从tensorflow.keras.applications导入VGG19
从tensorflow.keras.layers导入图层
从tensorflow.keras.layers导入乘法、Conv2D、注意力
从tensorflow.keras.layers导入（TimeDistributed、LSTM、Dense、Dropout、Flatten、GlobalAveragePooling2D、
                                     批量归一化）
从tensorflow.keras.models导入顺序


SpatialAttentionLayer 类（图层）：
    def __init__(self, **kwargs):
        super(SpatialAttentionLayer, self).__init__(**kwargs)

    def 构建（自身，input_shape）：
        self.conv2d = Conv2D(filters=512, kernel_size=(7, 7), 激活=&#39;softmax&#39;, padding=&#39;same&#39;)

    def 调用（自身，输入）：
        注意力 = self.conv2d(输入)
        return Multiply()([输入，注意力])


类 TemporalAttentionLayer(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(TemporalAttentionLayer, self).__init__(**kwargs)

    def 构建（自身，input_shape）：
        self.kernel = self.add_weight(name=&#39;kernel&#39;,
                                      形状=(输入形状[-1], 1),
                                      初始值设定项=&#39;glorot_uniform&#39;,
                                      可训练=真）

    def 调用（自身，输入）：
        Attention_scores = tf.keras.backend.dot(输入，self.kernel)
        注意分数= tf.keras.backend.squeeze（注意分数，-1）
        注意分数 = tf.keras.backend.softmax(注意分数)
        Attention_sequence = 输入 * Attention_scores[..., None]
        attend_sequence = tf.reduce_sum(attended_sequence, axis=1)
        返回参加序列


# todo：为文档创建模型图
def ActionDetectionModel（num_frames，frame_width，frame_height，通道，num_classes，lstm_units = 256，
                         dend_units=1024，dropout_rate=0.5，fine_tune_until=None）：
    # 加载 VGG19 模型，不包括顶层
    base_model = VGG19（include_top = False，权重=&#39;imagenet&#39;，input_shape =（frame_width，frame_height，通道））

    对于 base_model.layers 中的图层：
        可训练层 = False
    如果fine_tune_until：
        对于 base_model.layers[-fine_tune_until:] 中的图层：
            层.可训练= True

    # 定义顺序模型
    模型=顺序（[
        # 添加TimeDistributed层通过VGG19处理每一帧
        TimeDistributed(base_model, input_shape=(num_frames,frame_width,frame_height,channels)),

        #TimeDistributed(SpatialAttentionLayer()),
        时间分布式(GlobalAveragePooling2D()),

        时间分布(Flatten()),

        # 用于时间处理的 LSTM 层
        LSTM（lstm_units，return_sequences = True），

        # 添加时间注意力机制
        时间注意力层（），

        # 用于正则化的批量归一化
        批量归一化(),

        # 用于进一步处理的密集层
        密集（dense_units，激活=&#39;relu&#39;），
        辍学率（辍学率），

        # 最终预测层
        密集（num_classes，激活=&#39;softmax&#39;）
    ]）

    返回模型



有一次，我在模型的开头添加了一个简化的 SpatialAttentionLayer；那时，该模型尚未接受训练。
我根据 VGG19 更改了模型，认为反向传播期间可能会发生一些事情。
我已经改变了学习率几次，但这些权重没有改变。有一次，我将整个 VGG19 设置为可训练，但什么也没有。]]></description>
      <guid>https://stackoverflow.com/questions/77965679/machine-learning-model-does-not-train-weights-even-after-setting-it-trainable</guid>
      <pubDate>Fri, 09 Feb 2024 02:00:44 GMT</pubDate>
    </item>
    <item>
      <title>如何查明两个相似图像之间的差异[关闭]</title>
      <link>https://stackoverflow.com/questions/77965431/how-to-pinpoint-differences-between-two-similar-images</link>
      <description><![CDATA[有关我的问题的一些背景信息。我有一个想要自动化的任务。我收到了两张图片

显示某些事物/部件应位于何处的模板
我必须将图像与模板进行比较。任何缺失的部件我都必须手动放置。

我想编写一个程序，可以采用模板并检查第 2 项是否缺少任何部分。
我已阅读此内容。然而，我的模板是电脑pdf文件，图像是用手机拍摄的照片。因此 stackoverflow 中的建议不太适合我的场景。
有没有办法在丢失的东西上放置一个边界框？
一个例子可以是

我收到了一张数字棋盘的屏幕截图，棋子随机分布在方格上

我收到一张真实棋盘的图片，必须检查它是否与屏幕截图相符。


我想在缺少棋子的棋子上放置一个边界框
我尝试使用结构相似性，但不断获得相似性分数。我更希望获得显示差异的输出图像。同样，我尝试了边缘检测和减法。但由于图像的大小或比例不同，因此它永远不会抵消]]></description>
      <guid>https://stackoverflow.com/questions/77965431/how-to-pinpoint-differences-between-two-similar-images</guid>
      <pubDate>Fri, 09 Feb 2024 00:16:37 GMT</pubDate>
    </item>
    <item>
      <title>如何修复错误：AttributeError：“VotingRegressor”对象没有属性“_model_meta”？</title>
      <link>https://stackoverflow.com/questions/77965050/how-to-fix-the-error-attributeerror-votingregressor-object-has-no-attribute</link>
      <description><![CDATA[我正在从事预测分析并使用 XGBoost 和支持向量回归器模型。
我集成了这两个模型，现在我需要在进行推理时验证这个模型。
集成是通过 VotingRegressor 完成的：
ensemble_model = VotingRegressor([
        （&#39;XGBoost&#39;，model_prod_xgb），
        (&#39;SVR&#39;, model_prod_svr)])
        
ensemble_model.fit(X_train, y_train)

产生错误的部分是这样的：
run_id = ensemble_model._model_meta.run_id

AttributeError：“VotingRegressor”对象没有属性“_model_meta”

如何修复此错误？]]></description>
      <guid>https://stackoverflow.com/questions/77965050/how-to-fix-the-error-attributeerror-votingregressor-object-has-no-attribute</guid>
      <pubDate>Thu, 08 Feb 2024 22:11:35 GMT</pubDate>
    </item>
    <item>
      <title>推荐系统的代码可以在jupyter上运行，但不能在.py文件中运行[关闭]</title>
      <link>https://stackoverflow.com/questions/77964268/recommendation-system-s-code-works-on-jupyter-but-dont-works-in-a-py-file</link>
      <description><![CDATA[你好。
我使用jupyter Notebook编写了推荐系统代码
我需要在 django 中使用这个推荐系统。为此，我将 jupyter 代码导出到 .py 文件。
但我的代码在 django （.py 文件）中不起作用，只返回一个空字典
你能告诉我我的代码问题吗？\
&lt;块引用&gt;
注意：该代码是电影推荐系统的代码，我是为这本书定制的，所以有些变量的名称与电影相关。

我的数据集（https://www.kaggle.com/datasets/ arashnic/图书推荐数据集)
我的 .ipynb 文件 (https://drive.google. com/file/d/1Q_i6FnNEfeoTwQWyiqK6gl6PlCZzHciD/view?usp=sharing)
请尽快帮助我，我也非常需要这个系统的工作
非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/77964268/recommendation-system-s-code-works-on-jupyter-but-dont-works-in-a-py-file</guid>
      <pubDate>Thu, 08 Feb 2024 19:19:22 GMT</pubDate>
    </item>
    <item>
      <title>当有多个输入时，如何使用检索器使用 langchain 创建抹布链？</title>
      <link>https://stackoverflow.com/questions/77964228/how-can-i-create-a-rag-chain-with-langchain-using-a-retriever-when-having-multip</link>
      <description><![CDATA[我在尝试了解如何使用“|”时遇到一些问题。声明链时langchain中的管道符号。
prompt_template = “””
  仅根据以下上下文进行响应：
  {语境}

作为负责优化给定项目的经验丰富的专家，您的专业知识至关重要
应对挑战并抓住机遇。

问题和机遇：
{问题和机会}

业务目标：
{业务_目标}

项目介绍：
{描述}

请以 JSON 格式提供全面的回复，包括以下内容
成分：

1. 建议的解决方案：
 - 制定详细的计划来克服已确定的挑战并利用
机会。

2. 技术细节：
 - 对该项目指定的技术进行深入分析。
 - 指定要使用的编程语言、框架和平台。
 - 示例：Python、Azure、Pytorch、Tensorflow、AWS、Openai、LLM...

 示例输出（JSON 格式）：
{{

 &quot;solution&quot;: &quot;这里有您的详细解决方案&quot;,
 “技术”：[“技术1”、“技术2”、...]，
 }}
”“”

提示 = ChatPromptTemplate.from_template(prompt_template)

然后我构建我的检索
retriever = vectordb.as_retriever()

和我的法学硕士
llm = AzureChatOpenAI(
    api_key=openai_api_key,
    api_version=openai_api_version,
    azure_endpoint=openai_api_base,
    型号=llm_model）

然后我添加我的输出解析器
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
从 langchain.callbacks 导入 get_openai_callback

Solution_schema = ResponseSchema(名称=“解决方案”，描述=“给定的”)
Technologies_schema = ResponseSchema（名称=“技术”，描述=“给定的”）

响应模式= [解决方案模式，
                    技术_架构]

输出解析器 = StructuredOutputParser.from_response_schemas(response_schemas)

最后，当我尝试使用链条将所有这些组合在一起时，我惨遭失败
&lt;前&gt;&lt;代码&gt;rag_chain = (
    {“上下文”：检索器，“问题和机会”：RunnablePassthrough()，“业务目标”：RunnablePassthrough()，“描述”：RunnablePassthrough()}
    |迅速的
    |勒姆
    |输出解析器
）

rag_chain.invoke（问题和机会，业务目标，描述）

收到此错误：
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-30-3a4e499badd2&gt;在&lt;细胞系：1&gt;()
----&gt; 1 rag_chain.invoke（问题和机会，业务目标，描述）

类型错误：RunnableSequence.invoke() 需要 2 到 3 个位置参数，但给出了 4 个
]]></description>
      <guid>https://stackoverflow.com/questions/77964228/how-can-i-create-a-rag-chain-with-langchain-using-a-retriever-when-having-multip</guid>
      <pubDate>Thu, 08 Feb 2024 19:12:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 mlx 中进行蒙版填充？</title>
      <link>https://stackoverflow.com/questions/77963476/how-do-i-do-masked-fill-in-mlx</link>
      <description><![CDATA[我想在 mlx 中实现 masked_fill，但它与 float(&#39;-inf&#39;) 配合效果不佳
https://pytorch.org/docs/stable/generate /torch.Tensor.masked_fill.html
我正在尝试使用 mlx.core.where 来实现此目的
masked_tensor = mlx.core.where(mask, mlx.core.array(float(&#39;-inf&#39;)), mlx.core.array(0))

但是对于面具
数组([[假，假，真，真]，
       [假，假，真，真]，
       [假，假，真，真]，
       [假，假，真，真]]，dtype = bool）

这会返回
数组([[nan, nan, -inf, -inf],
       [南，南，-inf，-inf]，
       [南，南，-inf，-inf]，
       [南，南，-inf，-inf]]，dtype = float32）

这不是我想要的。理想情况下它会返回
数组([[0, 0, -inf, -inf],
       [0, 0, -inf, -inf],
       [0, 0, -inf, -inf],
       [0, 0, -inf, -inf]], dtype=float32)

帮助]]></description>
      <guid>https://stackoverflow.com/questions/77963476/how-do-i-do-masked-fill-in-mlx</guid>
      <pubDate>Thu, 08 Feb 2024 16:55:27 GMT</pubDate>
    </item>
    <item>
      <title>在 esp32-cam 中使用人脸识别时出现错误 cam_hal：EV-VSYNC-OVF</title>
      <link>https://stackoverflow.com/questions/77958199/error-cam-hal-ev-vsync-ovf-when-using-face-recognition-in-esp32-cam</link>
      <description><![CDATA[我正在我的 esp32-cam 板上使用示例“CameraWebServer”。上传设置如下：
开发板：AI Thinker ESP32-CAM；
CPU频率：240MHz；
闪光频率：80 Mhz；
闪光模式：QIO。
Arduino 集成开发环境 2.0.0
esp32 乐鑫 版本 2.0.14

通过这些设置，我可以上传我的代码，但粪便识别功能不起作用。当我单击“注册面部”时，没有任何反应，并且我的串行监视器显示消息 EV-VSYNC-OVF。如何解决这个问题？
此外，我已经尝试修改上传设置并更改文件“CameraWebServer.ino”中的参数 config.frame_size 和 config.xclk_freq_hz，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77958199/error-cam-hal-ev-vsync-ovf-when-using-face-recognition-in-esp32-cam</guid>
      <pubDate>Wed, 07 Feb 2024 22:12:55 GMT</pubDate>
    </item>
    <item>
      <title>如何让这个专家混合模型在张量流中工作？</title>
      <link>https://stackoverflow.com/questions/77957928/how-can-i-get-this-mixture-of-experts-model-working-in-tensorflow</link>
      <description><![CDATA[我有两个张量。
张量 1 的形状为 (10, None, 16, 16, 64)
张量 2 的形状为 (None, 10)
“无”是c的批量大小
第一个张量表示来自 10 个不同模型的 logits 集合 (10)，其形状是每组 logits，(None) 是批量大小，(16, 16, 64) 是相应模型的输出。
第二个张量表示来自 1 个较小模型的一组 logits（无），即批处理大小，(10) 是 10 个值，表示第一个张量中每组 10 个 logits 的权重应如何。
我想将第一个张量乘以第二个张量，以便输出形状为 (10, None, 16, 16, 64)，并且第一个轴上的每组 logit 由第二个张量的相应 logit 进行加权
然后，我将对第一个轴上的相乘张量求和，以获得 MoE 模型的一个块的输出
以下是所有这些的实施方式（顺便说一下，MOPE 代表预训练专家的混合）：
def CreateMOPEBlock(x, 块, blockNum):
    专家日志 = []

    对于范围内的 i（num_classes）：
        块[i].trainable = False
        ExpertLogits.append(块[i](x))

    门控输入 = x
    GatingConv1 = tf.keras.layers.Conv2D(16, (3, 3), padding=&#39;相同&#39;)(GatingInput)
    GatingLayerNorm1 = tf.keras.layers.LayerNormalization()(GatingConv1)
    GatingLeakyReLU1 = tf.keras.layers.LeakyReLU()(GatingLayerNorm1)
    GatingConv2 = tf.keras.layers.Conv2D(32, (3, 3), padding=&#39;相同&#39;)(GatingLeakyReLU1)
    GatingLayerNorm2 = tf.keras.layers.LayerNormalization()(GatingConv2)
    GatingLeakyReLU2 = tf.keras.layers.LeakyReLU()(GatingLayerNorm2)
    GatingConv3 = tf.keras.layers.Conv2D(64, (3, 3), padding=&#39;相同&#39;)(GatingLeakyReLU2)
    GatingLayerNorm3 = tf.keras.layers.LayerNormalization()(GatingConv3)
    GatingLeakyReLU3 = tf.keras.layers.LeakyReLU()(GatingLayerNorm3)
    GatingFlatten = tf.keras.layers.Flatten()(GatingLeakyReLU3)
    GatingLogits = tf.keras.layers.Dense（num_classes，激活=&#39;softmax&#39;）（GatingFlatten）

    logits1 = ExpertLogits # 形状：(10, 无, 16, 16, 64)
    logits2 = GatingLogits # 形状：（无，10）

    # 在这里做一些奇特的数学计算
    多重逻辑 = ?

    返回 tf.keras.layers.add(multiple_logits)

MOPEInput = tf.keras.layers.Input(形状=(32, 32, 3))

# Block1、2和3只是10个keras顺序模型的数组
MOPEBlock1 = CreateMOPEBlock(MOPEInput, 块1)
MOPEBlock2 = CreateMOPEBlock(MOPEBlock1, 块2)
MOPEBlock3 = CreateMOPEBlock(MOPEBlock2, 块3)

MOPEFlatten = tf.keras.layers.Flatten()(MOPEBlock3)

MOPEX = tf.keras.layers.Dense(1024，激活=&#39;relu&#39;)(MOPEFlatten)
MOPEX = tf.keras.layers.BatchNormalization()(MOPEX)
MOPEX = tf.keras.layers.Dropout(0.33)(MOPEX)

MOPEX = tf.keras.layers.Dense(1024，激活=&#39;relu&#39;)(MOPEX)
MOPEX = tf.keras.layers.BatchNormalization()(MOPEX)
MOPEX = tf.keras.layers.Dropout(0.33)(MOPEX)

MOPEOutput = tf.keras.layers.Dense(num_classes, 激活=&#39;softmax&#39;)(MOPEX)

MOPEModel = tf.keras.Model(MOPEInput, MOPEOutput)

我已经尝试自己解决这个问题了！多次！
我还尝试询问多种大型语言模型，从 Mixtral-8x7b（以我的名字命名）到 GPT4。
结果看起来像这样：
将张量流导入为 tf

# 假设这些是你的张量
张量1 = tf.placeholder(tf.float32, shape=(10, 无, 16, 16, 64))
张量2 = tf.placeholder(tf.float32, shape=(无, 10))

# 重塑张量2（无，10）-&gt; （无、10、1、1、1）
tensor2_expanded = tf.expand_dims(tf.expand_dims(tf.expand_dims(tensor2, axis=-1), axis=-1), axis=-1)

# 排列张量1的轴 (10, None, 16, 16, 64) -&gt; （无、10、16、16、64）
tensor1_permuted = tf.transpose(tensor1, perm=[1, 0, 2, 3, 4])

# 张量相乘
结果= tf.multiply（tensor1_permuted，tensor2_expanded）

# 最后，将结果的轴排列回来 (None, 10, 16, 16, 64) -&gt; （10、无、16、16、64）
结果 = tf.transpose(结果, perm=[1, 0, 2, 3, 4])

即使对每个模型进行了广泛的调试，这些模型的解决方案也不起作用。
我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/77957928/how-can-i-get-this-mixture-of-experts-model-working-in-tensorflow</guid>
      <pubDate>Wed, 07 Feb 2024 21:13:53 GMT</pubDate>
    </item>
    <item>
      <title>DeepFM 推荐模型日志记录问题 [已关闭]</title>
      <link>https://stackoverflow.com/questions/77862051/deepfm-recommender-model-logging-issues</link>
      <description><![CDATA[我正在尝试使用 DeepFM 模型进行推荐。但无法使用tensorflow或mlflow记录模型。
如果有人以前使用过这个模型，你有同样的解决方案吗？
将 pandas 导入为 pd
从 libreco.data 导入 random_split
从 libreco.algorithms 导入 WideDeep,DeepFM
从 sklearn.preprocessing 导入 LabelEncoder、MinMaxScaler
从 libreco.data 导入 random_split、DatasetFeat、DatasetPure、TransformedSet
从 libreco.evaluation 导入评估

train_data, data_info = DatasetFeat.build_trainset(df,user_col=[&#39;用户&#39;,&#39;年龄&#39;], item_col=[&#39;项目&#39;,&#39;流行度&#39;, &#39;运行时&#39;, &#39;投票平均&#39;,&#39;标签&#39;,&#39;流派&#39;],稀疏_col=[&#39;用户&#39;,&#39;项目&#39;,&#39;流派&#39;],dense_col=[&#39;流行度&#39;,&#39;运行时&#39;,&#39;投票平均&#39;,&#39;年龄&#39;,&#39;标签&#39;])

显示（train_data.item_indices.shape，train_data.user_indices.shape，train_data.dense_values.shape，train_data.sparse_indices.shape，train_data.sparse_indices.shape，train_data.labels.shape）

模型= DeepFM（data_info = data_info，任务=&#39;排名&#39;，loss_type =&#39;cross_entropy&#39;，embed_size = 16，n_epochs = 20，lr = 0.001，lr_decay = False，epsilon = 1e-05，batch_size = 256，sampler =&#39;随机&#39;, num_neg=1, use_bn=True, hide_units=(128, 64, 32), multi_sparse_combiner=&#39;sqrtn&#39;)
历史= model.fit（train_data，neg_sampling = True，verbose = 1，shuffle = True，eval_data =无，metrics =无，k = 10，eval_batch_size = 8192，eval_user_num =无，num_workers = 0）
]]></description>
      <guid>https://stackoverflow.com/questions/77862051/deepfm-recommender-model-logging-issues</guid>
      <pubDate>Mon, 22 Jan 2024 18:39:17 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformers 的推荐系统获取具有项目名称和类型的数据集的有效方法[关闭]</title>
      <link>https://stackoverflow.com/questions/77852593/efficient-methods-for-obtaining-dataset-with-item-names-and-types-for-transforme</link>
      <description><![CDATA[我找不到一种简单的方法（最好是 API）来获取大量项目名称及其类型的数据。例如，电影有其类型（恐怖、爱情、喜剧），游戏有其类型（恐怖、单人），音乐有其类型（古典、钢琴）等。
我能找到的最好办法就是访问 IMDB 等网站，并尝试从网站本身中获取数据（这在大多数地方甚至可能违反 TOS？）。
您是否找到了任何可以获取服务的完整项目列表及其类别等的 API，您能否分享它或者建议一种比抓取网络更简单的方法，因为它已经花费了我更多的时间应该，但在承诺之前我很想听听也许有人有更好的想法..
我试图在 Spotfiy、Google、Steam 等上查找 API，这将使我能够访问所有可能的游戏名称及其类别，但在其 API 中找不到任何此类端点。]]></description>
      <guid>https://stackoverflow.com/questions/77852593/efficient-methods-for-obtaining-dataset-with-item-names-and-types-for-transforme</guid>
      <pubDate>Sat, 20 Jan 2024 20:18:55 GMT</pubDate>
    </item>
    <item>
      <title>如何将极坐标数据框与 scikit-learn 一起使用？</title>
      <link>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</link>
      <description><![CDATA[我无法将极坐标数据帧与 scikitlearn 一起使用进行机器学习训练。
目前，我正在极坐标中进行所有数据帧预处理，在模型训练期间，我将其转换为 pandas 数据帧以使其正常工作。
是否有任何方法可以直接使用 Polars 数据帧进行 ML 训练而不将其更改为 pandas？]]></description>
      <guid>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</guid>
      <pubDate>Fri, 11 Nov 2022 05:59:55 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析：分类变量的预测</title>
      <link>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</link>
      <description><![CDATA[我有一台机器在 1 分钟时间间隔内的故障发生数据（以 0 和 1 表示）。 0 代表未发生故障，1 代表发生特定故障。因此，连续0 表示在一段时间内没有发生故障，连续1 表示在一段时间内连续发生故障。
我提供了如下的示例数据结构，现在我如何对下面提供的数据进行时间序列分析故障 A，并根据分析如何进行预测，例如“故障 A 将在未来时间戳中何时发生？” 
# 时间序列多元
将 pandas 导入为 pd
将 numpy 导入为 np

df = pd.DataFrame({&#39;timestamp&#39;:pd.date_range(&#39;2022-05-01 00:01:00&#39;, period=18, freq=&#39;T&#39;),
                   &#39;故障代码&#39;:[&#39;A&#39;]*4+[&#39;B&#39;]*3+[&#39;A&#39;]*2+[&#39;C&#39;]*5+[&#39;B&#39;]*2+[&#39;A&#39;]* 1+[&#39;D&#39;]*1
                  })
df[&#39;脉冲&#39;] = 1

df_ts = df.pivot(index=“时间戳”, columns=“故障代码”, value=“脉冲”)
df_ts = df_ts.fillna(0)
显示（df_ts）



         故障代码 A B C D
时间戳
2022-05-01 00:01:00 1 0 0 0
2022-05-01 00:02:00 1 0 0 0
2022-05-01 00:03:00 1 0 0 0
2022-05-01 00:04:00 1 0 0 0
2022-05-01 00:05:00 0 1 0 0
2022-05-01 00:06:00 0 1 0 0
2022-05-01 00:07:00 0 1 0 0
2022-05-01 00:08:00 1 0 0 0
2022-05-01 00:09:00 1 0 0 0
2022-05-01 00:10:00 0 0 1 0
2022-05-01 00:11:00 0 0 1 0
2022-05-01 00:12:00 0 0 1 0
2022-05-01 00:13:00 0 0 1 0
2022-05-01 00:14:00 0 0 1 0
2022-05-01 00:15:00 0 1 0 0
2022-05-01 00:16:00 0 1 0 0
2022-05-01 00:17:00 1 0 0 0
2022-05-01 00:18:00 0 0 0 1

# 时间序列图
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns

sns.set_theme(style=&quot;whitegrid&quot;) # darkgrid、whitegrid、dark、white 和ticks

故障=[&#39;A&#39;,
        &#39;B&#39;,
        &#39;C&#39;，
        &#39;D&#39;
       ]

plt.figure(figsize = (15,4))
sns.lineplot(数据=df_ts[故障])
plt.show()

上述数据的时间序列图：

我要预测A的故障代码（0或1）
         
时间戳故障代码
2022-05-01 00:19:00 ?
2022-05-01 00:20:00 ?
2022-05-01 00:21:00 ？
2022-05-01 00:22:00 ？
2022-05-01 00:23:00 ？
2022-05-01 00:24:00 ？
2022-05-01 00:25:00 ？
]]></description>
      <guid>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</guid>
      <pubDate>Fri, 03 Jun 2022 10:48:17 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 变换。在分割任务中组合图像对的使用</title>
      <link>https://stackoverflow.com/questions/66284850/pytorch-transforms-compose-usage-for-pair-of-images-in-segmentation-tasks</link>
      <description><![CDATA[我正在尝试在分段任务中使用 transforms.Compose() 。但我不确定如何对图像和蒙版使用相同的（几乎）随机变换。
所以在我的分割任务中，我有原始图片和相应的掩模，我想生成更多随机变换的图像对来训练 popurse。这意味着如果我对原始图片进行一些变换，这种变换也应该发生在我的蒙版图片上，然后这对图像就可以进入我的 CNN。我的变压器是这样的：
train_transform = Transforms.Compose([
            Transforms.Resize(512), # 调整大小，较小的边缘将被匹配。
            变换.RandomHorizo​​ntalFlip(p=0.5),
            变换.RandomVerticalFlip(p=0.5),
            变换.RandomRotation(90),
            变换.RandomResizedCrop(320,scale=(0.3, 1.0)),
            添加高斯噪声(0., 1.),
            Transforms.ToTensor(), # 将 PIL 图像或 ndarray 转换为张量。
            Transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # 标准化为 Imagenet 均值和标准差
]）

mask_transform = 变换.Compose([
            Transforms.Resize(512), # 调整大小，较小的边缘将被匹配。
            变换.RandomHorizo​​ntalFlip(p=0.5),
            变换.RandomVerticalFlip(p=0.5),
            变换.RandomRotation(90),
            变换.RandomResizedCrop(320,scale=(0.3, 1.0)),
            ##---------------------！------------------
            Transforms.ToTensor(), # 将 PIL 图像或 ndarray 转换为张量。
            Transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) # 标准化为 Imagenet 均值和标准差
]）


请注意，在代码块中，我添加了一个可以向原始图像转换添加随机噪声的类，该类不在 mask_transformation 中，我希望我的蒙版图像遵循原始图像转换，但忽略随机噪声。那么这两个转变如何成对发生（具有相同的随机行为）？]]></description>
      <guid>https://stackoverflow.com/questions/66284850/pytorch-transforms-compose-usage-for-pair-of-images-in-segmentation-tasks</guid>
      <pubDate>Fri, 19 Feb 2021 20:52:30 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络只预测一件事</title>
      <link>https://stackoverflow.com/questions/62712282/my-neural-network-only-predicts-one-thing</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/62712282/my-neural-network-only-predicts-one-thing</guid>
      <pubDate>Fri, 03 Jul 2020 09:16:53 GMT</pubDate>
    </item>
    <item>
      <title>Mahout 基于项目的推荐引擎，没有偏好值</title>
      <link>https://stackoverflow.com/questions/17712903/mahout-item-based-recommendation-engine-with-no-preference-values</link>
      <description><![CDATA[我正在尝试使用 Mahout 构建一个推荐引擎，该引擎仅根据项目之间的相似性提供推荐，而不考虑用户偏好（即评分）。项目相似度由 mahout 外部的一些其他进程计算并保存到文件中。到目前为止，我已经确定我可以使用该类：
GenericBooleanPrefItemBasedRecommender

...选择项目，文档称其“适合在数据中不存在偏好值概念时使用”。但是，该类仍将其作为输入：
(DataModel dataModel, ItemSimilarity 相似度)

我知道我可以使用 ItemSimilarity 类来提供项目到项目的相似度值，但是在这种情况下我的数据模型是什么？我没有偏好，这似乎正是数据模型所代表的东西。我该如何解决这个问题，或者我在这里看错了东西？]]></description>
      <guid>https://stackoverflow.com/questions/17712903/mahout-item-based-recommendation-engine-with-no-preference-values</guid>
      <pubDate>Thu, 18 Jul 2013 01:13:28 GMT</pubDate>
    </item>
    </channel>
</rss>