<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 21 Aug 2024 12:28:57 GMT</lastBuildDate>
    <item>
      <title>根据 scikit-learn ColumnTransformer 访问用于归纳和规范化新数据的值</title>
      <link>https://stackoverflow.com/questions/78896943/accessing-the-values-used-to-impute-and-normalize-new-data-basded-upon-scikit-le</link>
      <description><![CDATA[因此，我使用 ´scikit-learn´ 在训练集上构建机器学习模型，然后在测试集上对它们进行评估。在训练集上，我使用 ColumnTransformer 执行数据插补和缩放，然后使用 Kfold CV 构建逻辑回归模型，最终模型用于预测测试集上的值。最终模型还使用 ColumnTransformer 的结果来插补测试集上的缺失值，例如，最小-最大标量将从训练集中获取最小值和最大值，并在缩放测试集时使用这些值。我如何才能看到这些从训练集中得出然后用于预测测试集的缩放值？我在 ´scikit-learn´ 文档中找不到有关它的任何信息。以下是我使用的代码：
来自 sklearn.linear_model 导入 SGDClassifier
来自 sklearn.model_selection 导入 RepeatedStratifiedKFold
来自 sklearn.model_selection 导入 GridSearchCV
来自 sklearn.compose 导入 ColumnTransformer
来自 sklearn.impute 导入 SimpleImputer
来自 sklearn.pipeline 导入 Pipeline
来自 sklearn.preprocessing 导入 MinMaxScaler、OneHotEncoder

def preprocessClassifierLR(categorical_vars, numeric_vars):###categorical_vars 和 numeric_vars 是定义 X 中存在的分类和数字变量的列名的列表

categorical_pipeline = Pipeline(steps=[(&#39;mode&#39;, SimpleImputer(missing_values=np.nan, strategies=&quot;most_frequent&quot;)),
(&quot;one_hot_encode&quot;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))])

numeric_pipeline = Pipeline(steps=[(&#39;numeric&#39;, SimpleImputer(strategy=&quot;median&quot;)),
(&quot;scaling&quot;, MinMaxScaler())])

col_transform = ColumnTransformer(transformers=[(&quot;cats&quot;, categorical_pipeline, categorical_vars),
(&quot;nums&quot;, numeric_pipeline, numeric_vars)])

lr = SGDClassifier(loss=&#39;log_loss&#39;, penalty=&#39;elasticnet&#39;)
model_pipeline = Pipeline(steps=[(&#39;preprocess&#39;, col_transform),
(&#39;classifier&#39;, lr)])

random_grid_lr = {&#39;classifier__alpha&#39;: [1e-1, 0.2, 0.5],
&#39;classifier__l1_ratio&#39;: [1e-3, 0.5]}

kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=47)

param_search = GridSearchCV(model_pipeline, random_grid_lr,scoring=&#39;roc_auc&#39;, cv=kfold, refit=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

param_search = preprocessClassifierLR(categorical_vars, numeric_vars)
train_mod = param_search.fit(X_train, y_train)
print(&quot;Mod AUC:&quot;, train_mod.best_score_)

test_preds = train_mod.predict_proba(X_)[:,1]


我无法提供真实数据，但 X 是一个包含独立变量的数据框，y 是二元结果变量。train_mod 是一个包含列转换器和 SGD 分类器步骤的管道。我可以通过运行 train_mod.best_params_ 轻松从分类器中获取类似的参数信息，例如最佳 lambda 和 alpha 值，但我无法找出用于列转换器的统计数据，例如 1) 用于分类特征的简单插补器的模式，2) 用于数字特征的简单插补器的中值，以及 3) 用于缩放数字特征的最小值和最大值。有人知道如何访问这些信息吗？
提前致谢！
我假设 train_mod.best_estimator_[&#39;preprocess&#39;].transformers_ 包含此信息，类似于 train_mod.best_params_ 为我提供从模型训练中得出的 alpha 和 lambda 值，然后将其应用于测试集。]]></description>
      <guid>https://stackoverflow.com/questions/78896943/accessing-the-values-used-to-impute-and-normalize-new-data-basded-upon-scikit-le</guid>
      <pubDate>Wed, 21 Aug 2024 12:24:53 GMT</pubDate>
    </item>
    <item>
      <title>我在加载 hydra 的配置时遇到了一些问题</title>
      <link>https://stackoverflow.com/questions/78896800/i-get-some-problem-with-load-the-config-of-hydra</link>
      <description><![CDATA[我使用 Google colab 运行代码
code:
import hydra
from pathlib import Path # 导入文件路径处理路径
import sys # 导入 sys 模块
@hydra.main(config_path=&quot;cfgs&quot;, config_name=&quot;config.yaml&quot;)
def main(cfg):
print(cfg) # 打印解析后的配置

from train import Workspace as W

root_dir = Path.cwd()

workspace = W(cfg)

snapshot = root_dir / &#39;snapshot.pt&#39;

if snap.exists():

print(f&#39;resuming: {snapshot}&#39;)

workspace.load_snapshot()

workspace.train()

if name == &#39;ma​​in&#39;:
main()
输出：
用法：colab_kernel_launcher.py [--help] [--hydra-help] [--version] [--cfg {job,hydra,all}]
[--resolve] [--package PACKAGE] [--run] [--multirun]
[--shell-completion] [--config-path CONFIG_PATH]
[--config-name CONFIG_NAME] [--config-dir CONFIG_DIR]
[--info [{all,config,defaults,defaults-tree,plugins,searchpath}]]
[overrides ...]
colab_kernel_launcher.py：错误：无法识别的参数：-f
发生异常，使用 %tb 查看完整回溯。
SystemExit：2
我想要修复此错误]]></description>
      <guid>https://stackoverflow.com/questions/78896800/i-get-some-problem-with-load-the-config-of-hydra</guid>
      <pubDate>Wed, 21 Aug 2024 11:54:28 GMT</pubDate>
    </item>
    <item>
      <title>在 ML 线性回归中绘制多特征数据</title>
      <link>https://stackoverflow.com/questions/78896787/plotting-multi-feature-data-in-ml-linear-regression</link>
      <description><![CDATA[我的问题是关于 sci-kit learn 背后究竟是如何工作的，特别是当我们用多个特征（X）拟合线性回归模型时，例如房价特征和一个 y（价格）

模型如何运作，绘制多特征数据，然后如何在背后为这些数据选择曲线？
我无法绘制数据。]]></description>
      <guid>https://stackoverflow.com/questions/78896787/plotting-multi-feature-data-in-ml-linear-regression</guid>
      <pubDate>Wed, 21 Aug 2024 11:52:23 GMT</pubDate>
    </item>
    <item>
      <title>在进行连续文本分析后更新和添加数据点时，如何计算和更新权重和分数？</title>
      <link>https://stackoverflow.com/questions/78896688/how-to-calculate-and-update-weights-and-score-when-updating-and-adding-data-poin</link>
      <description><![CDATA[我有以下场景。也许有人可以帮助我正确地做到这一点。
我正在做文本分析并得到一组带有分数的主题。我正在存储这些。
我将其保存如下。
`{
&quot;Topic&quot;: {
&quot;TopicName&quot;: &quot;/Computers &amp;电子/编程”，
“得分”：35.371166
}，
“TotalCountOfTopic”：70
}，
{
“主题”：{
“主题名称”：&quot;/科学/计算机科学&quot;，
“得分”：35.900078
}，
“TotalCountOfTopic”：69
}，
{
“主题”：{
“主题名称”：&quot;/商业&amp; Industrial&quot;,
&quot;Score&quot;: 38.20758
},
&quot;TotalCountOfTopic&quot;: 47
}`
我想要做的是随后进行第二批文本分析，并且我想要更新这些数字。
我采取的步骤如下。
将之前运行的分数与我拥有的分数平均，添加新的分数并找到中位数。
`var oldWeight = user.TotalAnalysis[oldTopicIndex].TotalCountOfTopic * user.TotalAnalysis[oldTopicIndex].Topic?.Score;
var totalCount = user.TotalAnalysis[oldTopicIndex].TotalCountOfTopic + 1; // 增加总数
 var updatedTopic = new TopicAverage()
{

Topic = new Topic()
{

Score = (oldWeight + newTopic.Score) / totalCount,// 更正后的加权平均计算

TopicName = newTopic.TopicName
}, 
TotalCountOfTopic = totalCount
};`

我认为这是正确的做法，但我很好奇社区是怎么想的。
谢谢
我采取的步骤如下。
将之前运行的分数与我已有的分数平均，添加新分数并找到中位数。]]></description>
      <guid>https://stackoverflow.com/questions/78896688/how-to-calculate-and-update-weights-and-score-when-updating-and-adding-data-poin</guid>
      <pubDate>Wed, 21 Aug 2024 11:26:23 GMT</pubDate>
    </item>
    <item>
      <title>GAN 模型中图形嵌入的反向传播运行时错误</title>
      <link>https://stackoverflow.com/questions/78896269/runtimeerror-on-backpropagation-in-a-gan-model-for-graph-embeddings</link>
      <description><![CDATA[我正在尝试学习如何在图形嵌入上创建 GAN，但一直遇到错误

RuntimeError：尝试第二次向后遍历图形（或在已释放已保存的张量后直接访问它们）。调用 .backward() 或 autograd.grad() 时，图形的已保存中间值将被释放。如果您需要第二次向后浏览图表，或者在调用向后调用后需要访问已保存的张量，请指定 retain_graph=True。

class Generator(nn.Module):
def __init__(self, label_dim, noise_dim, embedding_dim):
super(Generator, self).__init__()
self.fc1 = nn.Linear(label_dim + noise_dim, 64)
self.fc2= nn.Linear(64, embedding_dim)

def forward(self, label, noise):
label = label.unsqueeze(1).float()
x = torch.cat([label, noise], dim=1)
x = torch.relu(self.fc1(x))
x = self.fc2(x)
return x

class Discriminator(nn.Module):
def __init__(self, embedding_dim):
super(Discriminator, self).__init__()
self.fc1 = nn.Linear(embedding_dim, 64)
self.fc2 = nn.Linear(64, 1)

def forward(self, x):
x = torch.relu(self.fc1(x))
x = torch.sigmoid(self.fc2(x))
return x

subset_size =1000
batch_size = 32
num_epochs = 100
noise_dim = 32
embedding_dim = 32
label_dim = 1

graph_embeddings = torch.stack(graph_embeddings_list).to(device)

dataset = TensorDataset(graph_embeddings,indexed_labels_tensor)

subset_indices = torch.randperm(len(graph_embeddings))[:subset_size]
subset = torch.utils.data.Subset(dataset, subset_indices)

dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)

device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)

generator = Generator(label_dim=label_dim, noise_dim=noise_dim, embedding_dim=embedding_dim).to(device)
discriminator = Discriminator(embedding_dim=embedding_dim).to(device)

optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)

criterion = nn.BCELoss()

for epoch in range(num_epochs):
for n, (real_embeddings, labels) in enumerate(dataloader):

real_samples_labels = torch.ones((real_embeddings.size(0), 1)).to(device=device)
generated_samples_labels = torch.zeros((real_embeddings.size(0), 1)).to(device=device)

print(&quot;生成的样本形状：&quot;, generated_samples_labels.shape)
print(&quot;真实样本形状：&quot;, real_samples_labels.shape)

real_embeddings = real_embeddings.to(device=device)
labels = labels.to(device=device)

latent_space_samples = torch.randn((labels.size(0), noise_dim)).to(device=device)
generated_samples = generator(labels, latent_space_samples)

all_samples = torch.cat((real_embeddings, generated_samples)).to(torch.float32)
all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels)).to(torch.float32)

discriminator.zero_grad()

output_discriminator = discriminator(all_samples)

print(&quot;判别器输出形状：&quot;, output_discriminator.shape)
print(&quot;判别器输出：&quot;, output_discriminator)

loss_discriminator = criterion(output_discriminator, all_samples_labels)

print(&quot;判别器后向损失：&quot;, loss_discriminator.item())
loss_discriminator.backward() 
print(&quot;已完成鉴别器的反向传递&quot;)
optimizer_D.step()

generator.zero_grad()

latent_space_samples = torch.randn((labels.size(0), noise_dim)).to(device=device)
generated_samples = generator(labels, latent_space_samples)

output_discriminator_generated = discriminator(generated_samples) 
loss_generator = criterion(output_discriminator_generated, real_samples_labels)

print(f&quot;生成器反向传递之前 - epoch {epoch}, batch {n}&quot;)
loss_generator.backward(create_graph=True)
print(f&quot;生成器反向传递之后 - epoch {epoch}, batch {n}&quot;)
optimizer_G.step()

if n == len(dataloader) - 1:
print(f&quot;Epoch: {epoch} Loss D.: {loss_discriminator.item()}&quot;)
print(f&quot;Epoch: {epoch} Loss G.: {loss_generator.item()}&quot;)


我尝试创建一个简单的 GAN 来计算与标签相关的图形嵌入。但错误发生在 loss_discriminator.backward() 部分。
我认为该过程是正确的。我尝试分离并重新计算 loss_generation 中的 output_discriminator，但都无济于事。我仍在学习 GAN 架构和图形数据结构。所以欢迎任何帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78896269/runtimeerror-on-backpropagation-in-a-gan-model-for-graph-embeddings</guid>
      <pubDate>Wed, 21 Aug 2024 09:50:24 GMT</pubDate>
    </item>
    <item>
      <title>COCO json文件中分割值的面积是如何计算的？</title>
      <link>https://stackoverflow.com/questions/78895866/how-is-the-area-of-segmentation-value-in-coco-json-file-calculated</link>
      <description><![CDATA[所以我刚刚浏览了一个 COCO JSON 文件，并遇到了一个称为 area 的字段。在使用 cv2.countNonZero() 函数之前，我已经计算了分割面积，并将二进制掩码传递给它，但我不知道 COCO JSON 中的面积值是如何计算的。它只是分割多边形所包围的像素数吗？
如果感兴趣，我在将 SAHI（切片辅助超推理）输出转换为 COCO 格式后获得了 JSON 输出。]]></description>
      <guid>https://stackoverflow.com/questions/78895866/how-is-the-area-of-segmentation-value-in-coco-json-file-calculated</guid>
      <pubDate>Wed, 21 Aug 2024 08:13:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用 model.summary() 时阻止 Jupyter 重新启动？</title>
      <link>https://stackoverflow.com/questions/78895569/how-to-stop-jupyter-from-restarting-when-using-model-summary</link>
      <description><![CDATA[我在 jupyter 上使用 keras，并尝试运行代码“model.summary()”。但是，jupyter 不断重新启动。
我曾尝试将 max_buffer_size 增加到 17gb，但没有成功。有人可以帮忙建议如何解决这个问题吗？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78895569/how-to-stop-jupyter-from-restarting-when-using-model-summary</guid>
      <pubDate>Wed, 21 Aug 2024 07:03:20 GMT</pubDate>
    </item>
    <item>
      <title>将具有大内核的 maxpool 转换为具有小内核的 maxpool 的等效堆栈</title>
      <link>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</link>
      <description><![CDATA[我有一个 onnx 模型，它有一些这样的 MaxPool 层：
https://ibb.co/KKWLD2h
我无法使用这些内核形状，因为我只能从 1x1 变为 3x3。 4x4 被认为不是最佳的，但我可以使用它。
我尝试用一​​堆 3x3 内核替换它们，如下所示：
https://ibb.co/crDMrtW
我错误计算了此图像中的输出形状，但我会修复它。
我的疑问是，即使我修复了 MaxPool 层，输出是否会与具有更大内核的原始输出相似？我无法弄清楚应该使用什么组合才能使输出与原始内核相似或最接近。]]></description>
      <guid>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</guid>
      <pubDate>Wed, 21 Aug 2024 06:09:06 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“ChannelAug”的模块</title>
      <link>https://stackoverflow.com/questions/78895108/modulenotfounderror-no-module-named-channelaug</link>
      <description><![CDATA[当我使用
sh run_train_regdb.sh

控制台说：ModuleNotFoundError：没有名为“ChannelAug”的模块
但 conda 和 pip 无法安装此模块
我不知道如何修复这个问题，我应该安装哪个模块？
我不知道如何修复这个问题，我应该安装哪个模块？]]></description>
      <guid>https://stackoverflow.com/questions/78895108/modulenotfounderror-no-module-named-channelaug</guid>
      <pubDate>Wed, 21 Aug 2024 04:08:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在一个 cv2 相机屏幕中运行两个计算机视觉模型</title>
      <link>https://stackoverflow.com/questions/78894715/how-to-run-two-computer-vision-models-in-one-cv2-camera-screen</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78894715/how-to-run-two-computer-vision-models-in-one-cv2-camera-screen</guid>
      <pubDate>Tue, 20 Aug 2024 23:51:16 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Selenium 中获得更快的 API 响应？</title>
      <link>https://stackoverflow.com/questions/78893351/how-to-get-a-faster-api-response-in-selenium</link>
      <description><![CDATA[我正在用 selenium 开发一个机器人，当日历在白天变绿时，它会从日历中选择一个日期，当日期变绿时，机器人会选择它，然后加载页面的其余部分以输入信息。但问题是日期只变绿了 2 秒，选择日期后，会向服务器生成一个请求，需要 3 秒才能响应，因此我的机器人在选择日期后出现错误，因为日期在 API 响应之前就变回了红色。我该如何解决这个问题，以便机器人可以在不到 2 秒的时间内完成日期选择过程，而不是 3 秒？
我尝试过隐式和显式等待，但都没有用]]></description>
      <guid>https://stackoverflow.com/questions/78893351/how-to-get-a-faster-api-response-in-selenium</guid>
      <pubDate>Tue, 20 Aug 2024 15:46:11 GMT</pubDate>
    </item>
    <item>
      <title>适合发票提取的 ml 模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78892147/suitable-ml-model-for-invoice-extraction</link>
      <description><![CDATA[我必须构建一个 ml 模型，用于从不同布局的 pdf 文件中提取发票详细信息，例如客户姓名、发票日期、发票号码等。发票 pdf 文件具有不同的格式，例如，在一个 pdf 文件中，发票日期位于右上角，而在另一个 pdf 文件中，则位于左上角。我有大约 252 个样本。我正在使用 202 个样本进行训练，其中 28 个样本用于验证。我目前正在使用每个标签/类的边界框坐标训练张量流更快的 RCNN resnet101 对象检测模型（例如：发票日期，数字是标签），其中 num_train_steps = 2000，批量大小 = 4 和 num_eval_steps = 250。当我在测试图像上测试训练后的模型时，其中一些能够提取发票详细信息，但其中一些给出错误的输出，甚至有时它们为相同的发票详细信息提供多个输出（例如，它们为一个发票日期预测两个值）。我应该如何调整参数（批量大小、num_train_steps、num_eval_steps）？我应该在下载的 ml 模型的配置文件上更改任何内容吗？为了更好地理解，请参阅faster rcnn 的配置文件]]></description>
      <guid>https://stackoverflow.com/questions/78892147/suitable-ml-model-for-invoice-extraction</guid>
      <pubDate>Tue, 20 Aug 2024 11:18:03 GMT</pubDate>
    </item>
    <item>
      <title>t() 期望张量具有 <= 2 维，但自身是 3D</title>
      <link>https://stackoverflow.com/questions/75274241/t-expects-a-tensor-with-2-dimensions-but-self-is-3d</link>
      <description><![CDATA[我是 PyTorch 的新手，写了如下简单代码来对一些输入进行分类。模型输入有 8*2，批量大小为 2，模型中的输入层有 2 个节点。我不知道哪里出了问题！
X1=np.array([[2,1],[3,2],[-4,-1],[-1,-3],[2,-1],[3,-3],[-2,1],[-4,-2]])
Y1=np.array([0,0,0,0,1,1,1,1])
X=torch.tensor(X1)
Y=torch.tensor(Y1)

BATCH_SIZE=2
trainset= torch.utils.data.TensorDataset(X, Y)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,
shuffle=True, num_workers=1) 
from torch.nn.modules import flatten

learning_rate = 0.01
num_epochs = 20

device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
model = MyModel()
model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

## 计算准确率
def get_accuracy(logit, target, batch_size):
&#39;&#39;&#39; 获取训练轮的准确率 &#39;&#39;&#39;
corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()
accuracy = 100.0 * corrects/batch_size
return accuracy.item()

model = MyModel()

# 注释掉 IPython magic 以确保 Python 兼容性。

对于范围（num_epochs）内的 epoch：
train_running_loss = 0.0
train_acc = 0.0

## 训练步骤
对于 trainloader 中的输入、标签：

#inputs=torch.flatten(inputs)
输入、标签=inputs.to(device), 标签.to(device)
#inputs = 输入.to(device)
#labels = 标签.to(device)

optimizer.zero_grad()

## 前向 + 反向传播 + 损失

print(inputs)

输出 = model.forward(inputs)
损失 = criterion(outputs, labels)

loss.backward()

## 更新模型参数
optimizer.step()

train_running_loss += loss.detach().item()
train_acc += get_accuracy(outputs, labels, BATCH_SIZE)

#model.train()
model.eval()
print(&#39;Epoch： %d | 损失： %.4f | 训练准确率： %.2f&#39;%(epoch, train_running_loss / i, train_acc/i))

我的模型如下：
class MyModel(nn.Module):
def __init__(self):
super(MyModel, self).__init__()
self.d1 = nn.Linear(2,3)
self.d2 = nn.Linear(3,1)
self.init_weights()

def init_weights(self):
k1=torch.tensor([0.1,-0.72,0.94,-0.29,0.12,0.44])
k1=torch.unsqueeze(torch.unsqueeze(k1,0),0)
self.d1.weight.data=k1
k2=torch.tensor([1,-1.16,-0.26])
k2=torch.unsqueeze(torch.unsqueeze(k2,0),0)
self.d2.weight.data=k2

def forward(self, x):
x = self.d1(x)
x = F.tanh(x)
x = self.d2(x)
out = F.sigmoid(x)
return out

然后我收到一个错误：
-------------------------------------------------------------------------------
RuntimeError Traceback (most recent call last)
&lt;ipython-input-27-196d819d3ccd&gt; in &lt;module&gt;
101 print(inputs)
102 
--&gt; 103 输出 = model.forward(输入)
104 损失 = 标准(输出，标签)
105 

2 帧
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py in forward(self, input)
112 
113 def forward(self, input: Tensor) -&gt; Tensor:
--&gt; 114 return F.linear(input, self.weight, self.bias)
115 
116 def extra_repr(self) -&gt; str:

RuntimeError: t() 期望张量具有 &lt;= 2 维，但 self 是 3D

我展平了输入，但没有任何变化。我应该怎么做才能修复它？]]></description>
      <guid>https://stackoverflow.com/questions/75274241/t-expects-a-tensor-with-2-dimensions-but-self-is-3d</guid>
      <pubDate>Sun, 29 Jan 2023 10:38:06 GMT</pubDate>
    </item>
    <item>
      <title>在新类中，我收到一个 AttributeError: 无法在 <module '__main__'> 上获取属性 'ResNet1D'</title>
      <link>https://stackoverflow.com/questions/69030379/torch-loadml-model-in-new-class-i-receive-an-attributeerror-cant-get-attribu</link>
      <description><![CDATA[我已使用 Google Colab 在名为 model_prep.py 的文件中成功训练了卷积神经网络模型。该模型的准确率为 92%。现在我对该模型很满意，我已使用 pyTorch 保存了我的模型。
torch.save(model, &#39;/content/drive/MyDrive/myModel.pt&#39;)

我对此的理解是，一旦模型经过完全训练，我就可以使用 pyTorch 保存训练后的模型，然后将其加载到未来的项目中以对新数据进行预测。因此，我创建了一个单独的 test.py 文件，并在其中加载了经过训练的模型，如下所示：
model = torch.load(&#39;/content/drive/MyDrive/myModel.pt&#39;)
model.eval()

但在新的 test.py 文件中，我收到一条错误消息
AttributeError: 无法在 &lt;module &#39;__main__&#39;&gt; 上获取属性 &#39;ResNet1D&#39;

虽然在与创建经过训练的模型相同的笔记本 (model_prep.py) 中加载模型时不会发生此错误。此错误仅在将模型加载到没有模型架构的单独笔记本中时发生。我该如何解决这个问题？我想将经过训练的模型加载到一个新的单独文件中以对新数据执行。有人能提出解决方案吗？
将来，我想使用 tkinter 创建一个 GUI，并部署经过训练的模型，使用 tkinter 文件中的新数据检查预测。这可能吗？]]></description>
      <guid>https://stackoverflow.com/questions/69030379/torch-loadml-model-in-new-class-i-receive-an-attributeerror-cant-get-attribu</guid>
      <pubDate>Thu, 02 Sep 2021 12:33:05 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的 `view()` 起什么作用？</title>
      <link>https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch</link>
      <description><![CDATA[view() 对张量 x 做了什么？负值代表什么？
x = x.view(-1, 16 * 5 * 5)
]]></description>
      <guid>https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch</guid>
      <pubDate>Mon, 27 Feb 2017 07:21:10 GMT</pubDate>
    </item>
    </channel>
</rss>