<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 07 Dec 2023 15:15:11 GMT</lastBuildDate>
    <item>
      <title>如何使用tensorflow.js进行钓鱼网站检测</title>
      <link>https://stackoverflow.com/questions/77621010/how-to-use-tensorflow-js-for-phishing-website-detection</link>
      <description><![CDATA[我正在尝试创建一个网络钓鱼检测器 chrome 扩展作为副项目。
我尝试使用tensorflow.js（使用这个tfjs演示).
但是，效率并不是那么高。
是否有任何可用的模型可供客户端使用。]]></description>
      <guid>https://stackoverflow.com/questions/77621010/how-to-use-tensorflow-js-for-phishing-website-detection</guid>
      <pubDate>Thu, 07 Dec 2023 14:56:12 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下如何计算标准差（或置信区间）？</title>
      <link>https://stackoverflow.com/questions/77620366/how-to-calculate-standard-deviation-or-confidence-interval-in-this-case</link>
      <description><![CDATA[对于同一分类（二元）任务，我现在有五个独立的分类结果。我可以计算每个预测的 AUC（受试者工作特征曲线下面积），并且可以通过 Delong 方法获得置信区间 [1]。现在我需要通过平均这五个 AUC（例如，使用箱线图）来显示我的结果，如何计算平均 AUC 的标准差（或置信区间）。
[1] DeLong, E. R.、D. M. DeLong 和 D. L. Clarke-Pearson (1988)。 “比较两个或多个相关接收器工作特性曲线下的面积：非参数
我有两种计算方法，但不知道是否正确。 (1)使用5个AUC值的样本标准差； （2）使用每个AUC的标准差的均方根（最后需要除以5）。我更喜欢第二种选择，因为我可以将每个 AUC 视为随机变量并使用 Var((X+Y)/2)=(Var(X)+Var(Y))/4 等公式。]]></description>
      <guid>https://stackoverflow.com/questions/77620366/how-to-calculate-standard-deviation-or-confidence-interval-in-this-case</guid>
      <pubDate>Thu, 07 Dec 2023 13:23:54 GMT</pubDate>
    </item>
    <item>
      <title>Spacy 从上次训练的模型中重新训练（在线学习）</title>
      <link>https://stackoverflow.com/questions/77620043/spacy-retrain-from-last-trained-models-online-learning</link>
      <description><![CDATA[我正在使用 SpaCy 的 TextCatCNN 来解决文本分类问题。我刚刚准备好训练、测试和验证数据，并开始使用训练命令生成的默认配置文件训练模型：
python -m spacy init config --pipeline textcat ;

&lt;前&gt;&lt;代码&gt;[路径]
火车=空
开发=空
向量=空
init_tok2vec = null

[系统]
gpu_分配器=空
种子 = 0

[自然语言处理]
lang =“en”；
管道 = [“textcat”]
批量大小 = 1000
禁用 = []
创建之前 = null
创建后=空
after_pipeline_creation = null
tokenizer = {“@tokenizers”：“spacy.Tokenizer.v1”}
向量 = {“@vectors”：“spacy.Vectors.v1”}

[成分]

[组件.textcat]
工厂=“textcat”
记分器 = {“@scorers”：“spacy.textcat_scorer.v2”}
阈值 = 0.0

[组件.textcat.模型]
@architectures = “spacy.TextCatBOW.v2”
独占类 = true
ngram_size = 1
无输出层 = false
nO = 空

[语料库]

[语料库.dev]
@readers =“spacy.Corpus.v1”
路径 = ${paths.dev}
最大长度=0
gold_preproc = false
限制 = 0
增强器 = null

[语料库.train]
@readers =“spacy.Corpus.v1”
路径 = ${paths.train}
最大长度=0
gold_preproc = false
限制 = 0
增强器 = null

[训练]
dev_corpus = “corpora.dev”;
train_corpus = “语料库.train”;
种子 = ${系统.种子}
gpu_allocator = ${system.gpu_allocator}
辍学率 = 0.1
累积梯度= 1
耐心=1600
最大纪元 = 0
最大步数 = 20000
评估频率 = 200
冻结组件 = []
注释组件 = []
before_to_disk = null
更新前=空

[训练.batcher]
@batchers = “spacy.batch_by_words.v1”
丢弃尺寸过大= false
公差 = 0.2
获取长度=空

[训练.batcher.大小]
@schedules =“compounding.v1”；
开始 = 100
停止=1000
化合物 = 1.001
t = 0.0

[训练记录器]
@loggers = “spacy.ConsoleLogger.v1”
进度条=假

[训练.优化器]
@optimizers =“Adam.v1”；
贝塔1 = 0.9
贝塔2 = 0.999
L2_is_weight_decay = true
L2 = 0.01
梯度剪辑 = 1.0
使用平均值 = false
每股收益 = 0.00000001
学习率 = 0.001

[训练.score_weights]
猫得分 = 1.0
cats_score_desc = null
cats_micro_p = null
cats_micro_r = null
cats_micro_f = null
cats_macro_p = null
cats_macro_r = null
cats_macro_f = null
cats_macro_auc = null
cats_f_per_type = null

[预训练]

[初始化]
向量 = ${paths.向量}
init_tok2vec = ${paths.init_tok2vec}
词汇数据=空
查找=空
before_init = null
after_init = null

[初始化.组件]

[初始化.tokenizer]

评估后，我得到了一些指标，一切正常。当时间流逝并生成新的数据样本时，问题就出现了（我通过生成两个训练集来模拟它）。我只想“更新权重”我的模型，以便包含新数据的方差。这称为在线学习。
我尝试通过在 [components.textcat] 中将 factory = &quot;textcat&quot; 更改为 source = &quot;/model-best&quot;  部分，但是当使用第二组数据进行训练时，损失函数值等于第一个训练过程，因此它没有执行在线学习。此外，当使用第二组数据进行预测时，指标相同或更差。
如果可以的话，我如何使用 SpaCy 的 TextCatCNN 进行在线学习？]]></description>
      <guid>https://stackoverflow.com/questions/77620043/spacy-retrain-from-last-trained-models-online-learning</guid>
      <pubDate>Thu, 07 Dec 2023 12:35:14 GMT</pubDate>
    </item>
    <item>
      <title>如何提高噪声数据集的分类精度（模型的鲁棒性）？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77619251/how-to-improve-classification-accuracy-robustness-of-model-on-a-noisy-dataset</link>
      <description><![CDATA[我有一个分类问题，我为此开发了以下模型。 1. kNN 2. SVM 3. MLP 和 4. 逻辑回归。现在我应该研究当数据集被随机高斯噪声破坏时算法的鲁棒性。
我在数据样本中添加了噪声，所有算法的性能在存在噪声的情况下都会下降，4 种算法之间存在一些细微的差异。现在，我应该通过一些方法来提高这个嘈杂数据集的分类准确性，因为在现实世界中，数据会很嘈杂。我对提高模型对噪声的鲁棒性的技术完全一无所知。]]></description>
      <guid>https://stackoverflow.com/questions/77619251/how-to-improve-classification-accuracy-robustness-of-model-on-a-noisy-dataset</guid>
      <pubDate>Thu, 07 Dec 2023 10:24:29 GMT</pubDate>
    </item>
    <item>
      <title>多维嵌入如何帮助决定跨两个类别的句子分类输入</title>
      <link>https://stackoverflow.com/questions/77619250/how-multidimensional-embedding-help-to-decide-sentence-classify-input-across-two</link>
      <description><![CDATA[示例：https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C3/W2/ungraded_labs/C3_W2_Lab_1_imdb.ipynb
型号：“sequential_5”
_________________________________________________________________
 层（类型）输出形状参数#
=================================================== ===============
 embedding_5（嵌入）（无、120、16）160000
                                                                 
 flatten_5（压平）（无，1920）0
                                                                 
 密集_6（密集）（无，1）1921
                                                                 
=================================================== ===============
总参数：161921 (632.50 KB)
可训练参数：161921 (632.50 KB)
不可训练参数：0（0.00 字节）
_________________________________________________________________

从上面的模型我们可以定义这样的处理。
dense_6 -&gt;该层接受 1920 个输入并给出单个输出标签，该标签对评论是正面还是负面进行分类。
展平_5 -&gt;该层只是压平输入向量。
嵌入_5 -&gt;该层最多包含 120 个单词，并将每个单词的维度定义为向量。
这里我们想要对代表负面或正面评论的单词进行分类。当我们训练一个模型时，这16个维度在逻辑上意味着什么。
现在，如果我们简单地谈论dense_6，它有 1920 个特征，这些特征被赋予权重来预测 id，组合所有特征确实反映了负面评论或正面评论。
一旦我们训练了模型，这些特征在逻辑上的含义是什么？我们如何将这一单层与回归模型关联起来]]></description>
      <guid>https://stackoverflow.com/questions/77619250/how-multidimensional-embedding-help-to-decide-sentence-classify-input-across-two</guid>
      <pubDate>Thu, 07 Dec 2023 10:24:28 GMT</pubDate>
    </item>
    <item>
      <title>如何开发一个能够根据用户查询搜索和建议相关链接的聊天机器人？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77618816/how-can-i-develop-a-chatbot-with-the-ability-to-search-and-suggest-relevant-link</link>
      <description><![CDATA[在缺乏直接高级支持的情况下，我们的团队目前正在努力快速找到相关文档网页来解决产品问题。为了简化这一过程，我们正在探索开发一个能够搜索内部网站并建议相关网页（文档网站）的聊天机器人。我们如何共同实施这样的聊天机器人来增强我们团队的支持工作流程？
作为第一步，我们的团队使用 Python 中的网络抓取来从网页收集数据，并将其保存到文件中。随后，我们利用 NLTK 包并在这些文件上训练我们的模型。然而，当询问具体问题时，例如“静香是一个什么样的女孩？”该模型使用“印度历史”、“哆啦A梦”和“谷歌历史”等网页进行训练，倾向于根据查询中出现的各个单词来建议页面。例如，由于存在“Shizuka”一词，它建议“Doraemon”网页；由于“Kind”一词，它建议“印度历史”页面。虽然我们尝试通过删除“Kind”等某些单词来增强结果，但基于单词的方法可能无法为我们的产品文档产生相关结果。我们可以实施哪些修改或方法来确保我们的产品文档获得更加上下文准确的结果？]]></description>
      <guid>https://stackoverflow.com/questions/77618816/how-can-i-develop-a-chatbot-with-the-ability-to-search-and-suggest-relevant-link</guid>
      <pubDate>Thu, 07 Dec 2023 09:11:33 GMT</pubDate>
    </item>
    <item>
      <title>PatternRank可以提取带有中缀“-”的关键词吗？</title>
      <link>https://stackoverflow.com/questions/77618627/can-patternrank-extract-the-keyphrases-with-infix</link>
      <description><![CDATA[我尝试使用 PatternRank 从带有词性标记的文本文档中提取关键短语。但是，一些带有中缀“-”、“/”等的关键字无法识别可能是目标的关键字，而“_”可以被PatternRank识别。
示例：
导入spacy
将 pandas 导入为 pd
将 numpy 导入为 np
从 keybert 导入 KeyBERT
从 keyphrase_vectorizers 导入 KeyphraseCountVectorizer
从 sklearn.feature_extraction.text 导入 CountVectorizer

text = [&#39;&#39;&#39;BERT 是 NLP 的预训练模型。&#39;&#39;&#39;]
kw_model1.extract_keywords(docs=text, vectorizer=KeyphraseCountVectorizer(spacy_pipeline=nlp, lowercase=False, pos_pattern=&#39;*****&#39;, stop_words=&#39;english&#39;), use_mmr=True)

&gt;&gt;&gt;输出：[(&#39;BERT 是&#39;, 0.6578), (&#39;NLP&#39;, 0.5684)]


但是如果我将“-”替换为“_”：
导入spacy
将 pandas 导入为 pd
将 numpy 导入为 np
从 keybert 导入 KeyBERT
从 keyphrase_vectorizers 导入 KeyphraseCountVectorizer
从 sklearn.feature_extraction.text 导入 CountVectorizer

text = [&#39;&#39;&#39;BERT 是 NLP 的预训练模型。&#39;&#39;&#39;]
kw_model1.extract_keywords(docs=text, vectorizer=KeyphraseCountVectorizer(spacy_pipeline=nlp, lowercase=False, pos_pattern=&#39;*****&#39;, stop_words=&#39;english&#39;), use_mmr=True)

&gt;&gt;&gt;输出：[(&#39;BERT 是&#39;, 0.6579), (&#39;NLP&#39;, 0.5666), (&#39;预训练模型&#39;, 0.5215)]


我已经使用 spaCy 修改了分词器中缀模式，如下所示，以保留“-”、“/”等中缀。但它仍然不起作用。
导入重新
从 spacy.lang.char_classes 导入 ALPHA、ALPHA_LOWER、ALPHA_UPPER
从 spacy.lang.char_classes 导入 CONCAT_QUOTES、LIST_ELLIPSES、LIST_ICONS、LIST_PUNCT、LIST_QUOTES、CURRENCY、UNITS、PUNCT、LIST_CURRENCY
从 spacy.util 导入compile_infix_regex，compile_prefix_regex，compile_suffix_regex
从 spacy.tokenizer 导入 Tokenizer
# 修改分词器中缀模式
# 不希望分词器根据字母之间的连字符进行分割
中缀 = (
    LIST_ELLIPES
    + 列表_图标
    + [
        r&quot;(?&lt;=[0-9])[+\\-\\*^](?=[0-9-])&quot;,
        r&quot;(?&lt;=[{al}{q}])\\.(?=[{au}{q}])&quot;.format(
            al=ALPHA_LOWER、au=ALPHA_UPPER、q=CONCAT_QUOTES
        ),
        r&quot;(?&lt;=[{a}]),(?=[{a}])&quot;.format(a=ALPHA),
        # 注释掉按字母之间的连字符分割的正则表达式：
        # r&quot;(?&lt;=[{a}])(?:{h})(?=[{a}])&quot;.format(a=ALPHA, h=连字符),
        r&quot;(?&lt;=[{a}0-9])[:&gt;&gt;=/](?=[{a}])&quot;.format(a=ALPHA),
    ]
）

后缀 = (
    列表_PUNCT
    + 列表省略号
    + LIST_QUOTES
    + 列表_图标
    + [“&#39;s”、“&#39;S”、“&#39;s”、“&#39;S”、“—”、“–”]
    + [
        r”(?&lt;=[0-9])\+”,
        r“(?&lt;=°[FfCcKk])\.”,
        r&quot;(?&lt;=[0-9])(?:{c})&quot;.format(c=CURRENCY),
        r&quot;(?&lt;=[0-9])(?:{u})&quot;.format(u=UNITS),
        r&quot;(?&lt;=[0-9{al}{e}{p}(?:{q})])\.&quot;.format(
            al=ALPHA_LOWER, e=r&quot;%²\-\+&quot;, q=CONCAT_QUOTES, p=PUNCT
        ),
        r&quot;(?&lt;=[{au}][{au}])\.&quot;.format(au=ALPHA_UPPER),
    ]
）

前缀 = (
    [“§”、“%”、“=”、“—”、“–”、r“\+(?![0-9])”]
    + 列表_PUNCT
    + 列表省略号
    + LIST_QUOTES
    + 列表_货币
    + 列表_图标
）

]]></description>
      <guid>https://stackoverflow.com/questions/77618627/can-patternrank-extract-the-keyphrases-with-infix</guid>
      <pubDate>Thu, 07 Dec 2023 08:36:10 GMT</pubDate>
    </item>
    <item>
      <title>自定义 haar 级联无法正确检测对象</title>
      <link>https://stackoverflow.com/questions/77617944/custom-haar-cascade-not-detecting-object-properly</link>
      <description><![CDATA[我想创建一个 Haar 级联用于舌头检测。我已尝试使用 Cascade Trainer GUI（版本 3.3.1）构建 Haar 级联 40 多次，但它无法正确检测。我怎样才能做到这一点？
我创建了一个用于存放舌头图像（正样本“p”）的文件夹和另一个用于存放没有舌头的常见图像（负样本“n”）的文件夹，每个文件夹包含 150 个样本图像。一切都运行完美，没有任何错误，但测试图像没有检测到舌头。]]></description>
      <guid>https://stackoverflow.com/questions/77617944/custom-haar-cascade-not-detecting-object-properly</guid>
      <pubDate>Thu, 07 Dec 2023 06:00:31 GMT</pubDate>
    </item>
    <item>
      <title>多输出模块的 Keras 精度不会改变</title>
      <link>https://stackoverflow.com/questions/77617914/keras-accuracy-does-not-change-for-multi-output-module</link>
      <description><![CDATA[我想预测对欺诈案件的处罚/处罚，输入格式为（损害金额（$），如果是累犯），目标格式为（罚款（$），监狱（月），社区服务（小时），缓刑（月）） - 以下是我的代码：
fname = “文件路径.tsv”
全部输入 = []
所有输出 = []

将 open(fname) 作为 f：
    对于 i，enumerate(f) 中的行：
        如果我&lt; 3:#第一行
            print(&quot;标题:&quot;, line.strip().split(&#39;\t&#39;))
            继续
        fields = line.strip().split(&#39;\t&#39;)
        all_in.append([int(a.replace(&quot;,&quot;, &quot;&quot;)) for a in fields[5:7]])
        all_out.append([int(a.replace(&quot;,&quot;, &quot;&quot;)) for a in fields[7:11]])

case_in = np.array(all_in, dtype = “uint64”)
target_out = np.array(all_out, dtype = “uint64”)

Normalize_layer = tf.keras.layers.Normalization(axis=-1, name = “normalize_in”)
Normalize_layer.adapt(all_in)
Normalize_out = tf.keras.layers.Normalization(axis=-1, name = “normalize_out”)
Normalize_out.adapt(all_out)
denormalize_out = tf.keras.layers.Normalization(axis=-1, invert = True, name = “denormalize_out”)
denormalize_out.adapt(all_out)
缩放输出 = 标准化输出（全部输出）

输入= Normalize_layer（输入（形状= 2））
x = 密集（6，input_dim = 2，激活=“sigmoid”，use_bias = True）（输入）
x = 密集(4, 激活 = “sigmoid”)(x)
y_4 = 密集(1, 激活 = “sigmoid”, 名称 = “y_4”)(x)
惩罚=密集（3，激活=“sigmoid”，名称=“惩罚”）（x）
y_1 = 密集（1，激活=“sigmoid”，名称=“y_1”）（惩罚）
y_2 = 密集（1，激活=“sigmoid”，名称=“y_2”）（惩罚）
y_3 = 密集（1，激活=“sigmoid”，名称=“y_3”）（惩罚）

模型 = 模型（输入 = 输入，输出 = [y_1，y_2，y_3，y_4]）

模型.编译(
    优化器= SGD(learning_rate=0.01,weight_decay=1e-6,momentum=0.9,nesterov=True),
    损失={
        “y_1” ：“均方误差”，
        “y_2” ：“均方误差”，
        “y_3” ：“均方误差”，
        “y_4” ：“均方误差”
    },
    指标=[&#39;准确性&#39;]
）

模型.拟合(
    案例输入，
    横向扩展，
    batch_size = 10,##数据增加后，增加
    纪元 = 300，
    详细 = 2,
    验证分割= 0.8
）

对于 model.layers 中的图层：
    print(&quot;=====图层:&quot;, 图层名称,&quot;=====&quot;)
    if layer.get_weights() != []:
        权重=layer.get_weights()[0]
        偏差=layer.get_weights()[1]
        print(&quot;权重：&quot;)
        打印（权重）
        print(“偏差：”)
        打印（偏差）
    别的：
        print(&quot;权重：&quot;, [])

而且，一旦开始训练模型，准确性就根本不会改变。另外，当我试图解决这个问题时，我搞砸了一些东西，使大约 50 个数据集的数据只是 .fit 操作的一批，尽管我的批量大小为 10。我只是尝试了太多的事情来修复我的代码互联网上到处都是，这让一切变得更加混乱。
最初，我尝试对数据进行标准化，包括我的来龙去脉，这解冻了我的损失函数，但它并没有真正对准确性函数产生任何影响。我还将 ReLU 函数也更改为 sigmoid 函数，因为在某些时候，死 ReLU 似乎可能存在问题，因为我的层上的偏差没有从最初的 0 更新。之后，我不断地研究优化器、损失函数和纪元，但都无济于事。
如何让模块真正发挥作用？您对代码有一般反馈吗？]]></description>
      <guid>https://stackoverflow.com/questions/77617914/keras-accuracy-does-not-change-for-multi-output-module</guid>
      <pubDate>Thu, 07 Dec 2023 05:51:59 GMT</pubDate>
    </item>
    <item>
      <title>从 ampligraph 导入复杂数据时如何修复此错误 ImportError</title>
      <link>https://stackoverflow.com/questions/77617662/how-to-fix-this-error-importerror-while-importing-complex-from-ampligraph</link>
      <description><![CDATA[ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-41-449fec1eb93c&gt;在&lt;细胞系：28&gt;()
     26 从 imblearn.over_sampling 导入 RandomOverSampler、SMOTE、ADASYN
     27 从 imblearn.under_sampling 导入 ClusterCentroids、RandomUnderSampler、NearMiss、TomekLinks
---&gt; 28 从 ampligraph.latent_features 导入 ComplEx
     29

ImportError：无法从“ampligraph.latent_features”导入名称“ComplEx”（/usr/local/lib/python3.10/dist-packages/ampligraph/latent_features/__init__.py）

我尝试降级放大器来修复它，但它不起作用。我也尝试阅读新版本的文档，但我不知道，因为我是新手。]]></description>
      <guid>https://stackoverflow.com/questions/77617662/how-to-fix-this-error-importerror-while-importing-complex-from-ampligraph</guid>
      <pubDate>Thu, 07 Dec 2023 04:28:22 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“Flags”对象没有属性“c_contigious”</title>
      <link>https://stackoverflow.com/questions/77615883/attributeerror-flags-object-has-no-attribute-c-contiguous</link>
      <description><![CDATA[我正在阅读 Aurélien Géron 编写的《机器学习实践》一书，但遇到了以下错误。
代码：
y_train_large = (y_train.astype(&quot;int&quot;) &gt;= 7)
y_train_odd = (y_train.astype(“int”) % 2 == 1)
y_multilabel = np.c_[y_train_large, y_train_odd]

＃模型
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_multilabel)

y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)

最后一行产生以下错误：
&lt;前&gt;&lt;代码&gt;{
AttributeError: &#39;Flags&#39; 对象没有属性 &#39;c_contigious&#39;”
}

由于我正在关注这本书，所以我希望这段代码能够工作。我尝试过 Google Bard 和 Claude AI 聊天机器人的解决方案，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77615883/attributeerror-flags-object-has-no-attribute-c-contiguous</guid>
      <pubDate>Wed, 06 Dec 2023 19:42:47 GMT</pubDate>
    </item>
    <item>
      <title>如何将从 ListFromFiles 创建的 Tensorflow 数据集划分为训练集、验证集和测试集？</title>
      <link>https://stackoverflow.com/questions/77615270/how-can-i-divide-a-tensorflow-dataset-created-from-listfromfiles-into-train-val</link>
      <description><![CDATA[我有一个目录，其中包含我想要分成训练集、验证集和测试集的文件。我采取的方法是：
# 定义正负路径
POS = os.path.join(“*.txt”)

# 创建正数据集
pos = tf.data.Dataset.list_files(POS)

如果我尝试：
&lt;前&gt;&lt;代码&gt;位置[3]

我得到：
TypeError：“_ShuffleDataset”对象不可下标

我曾想过使用 take &amp; 进行拆分跳过 - 例如
train = pos.take(10)
有效 = pos.skip(10).take(5)
测试 = pos.skip(15).take(5)

但是，当我在包含 10 个文本文件 (a-j) 的示例目录中尝试以下测试时：
导入操作系统
将张量流导入为 tf

# 定义正向和负向路径
POS = os.path.join(“*.txt”)

# 创建数据集
pos = tf.data.Dataset.list_files(POS)#.shuffle(len(POS))

对于范围（20）内的 _：
    对于 pos.take(1) 中的 x：
       打印（x）

我得到这个输出：
tf.Tensor(b&#39;./c.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./g.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./g.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./c.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./g.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./b.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./g.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./c.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./g.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./c.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./h.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./e.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./c.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./f.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./f.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./h.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./i.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./b.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./j.txt&#39;, shape=(), dtype=string)
tf.Tensor(b&#39;./d.txt&#39;, shape=(), dtype=string)

由于目录中只有 10 个 txt 文件，因此我预计会看到相同的输出 20x、10 个不同文件的列表（后跟崩溃）或 2 个 10 个不同文件的列表。相反，take 似乎每次都在处理一个新的列表。因此，我使用 skip 和 take 的想法很可能最终会在我的集合之间出现重叠。
我唯一能想到做的就是在创建数据集之前拆分文件列表。但是，必须有某种方法从数据集中获取切片。 切片 TF 数据 中的方法对我不起作用。我在 take 的文档中没有看到任何内容。]]></description>
      <guid>https://stackoverflow.com/questions/77615270/how-can-i-divide-a-tensorflow-dataset-created-from-listfromfiles-into-train-val</guid>
      <pubDate>Wed, 06 Dec 2023 17:47:52 GMT</pubDate>
    </item>
    <item>
      <title>基于相同输入数据的并行或共享回归网络会更好吗？为什么？</title>
      <link>https://stackoverflow.com/questions/77615153/would-it-be-better-to-have-parallel-or-a-shared-regression-network-based-on-the</link>
      <description><![CDATA[我将多个并行回归网络组合成一个模型，其中组合输出以创建单个损失函数。这些网络正在寻找相同数据的不同方面，并同时进行训练。这可以被认为是一个基于物理的神经网络。
本能地，我想说，分割网络允许每个网络拥有自己的权重，而不受其他方面的干扰，这将加快训练速度和/或提高性能。 ChatGPT 似乎证实了我的怀疑，但无法给我任何来源。
有人有任何论文/证明或知道这两种方法的更具体术语吗？我只是真的不知道如何提出这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77615153/would-it-be-better-to-have-parallel-or-a-shared-regression-network-based-on-the</guid>
      <pubDate>Wed, 06 Dec 2023 17:29:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 tidymodels 框架中的 Youden 索引获取 ML 性能指标？</title>
      <link>https://stackoverflow.com/questions/77614694/how-do-you-get-ml-performance-metrics-using-the-youden-index-in-the-tidymodels-f</link>
      <description><![CDATA[如何使用 tidymodels 框架中的 Youden 索引获取机器学习性能指标？
我在网上搜索过示例，但没有找到。]]></description>
      <guid>https://stackoverflow.com/questions/77614694/how-do-you-get-ml-performance-metrics-using-the-youden-index-in-the-tidymodels-f</guid>
      <pubDate>Wed, 06 Dec 2023 16:12:03 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 S3 中保存的 recordio protobuf 数据训练 sagemaker 模型</title>
      <link>https://stackoverflow.com/questions/77518065/cant-train-sagemaker-model-using-recordio-protobuf-data-saved-in-s3</link>
      <description><![CDATA[我想使用 PySpark 在 Amazon EMR 中预处理数据，并使用管道模式在 SageMaker 中训练机器学习模型。我现在遇到的问题是将数据保存在 S3 中并将其输入模型。
SageMaker 模型接受 application/x-recordio-protobuf 类型。因此，我将数据保存为：
output_path = f“s3://my_path/output_processed”
df_transformed.write.format(“sagemaker”).mode(“覆盖”).save(output_path)

其中df_transformed是一个pyspark数据帧。
当我尝试将数据输入模型时：
records = RecordSet(s3_data=train_path, s3_data_type=&#39;S3Prefix&#39;, num_records=-1, feature_dim=50) rcf​​.fit(records)

我收到此错误：
&lt;前&gt;&lt;代码&gt;失败。原因：客户端错误：无法读取数据通道“train”。请求的内容类型是“application/x-recordio-protobuf”。请验证数据是否与请求的内容类型匹配。 （由 MXNetError 引起）

你知道我做错了什么吗？是否有必要在 EMR 中单独预处理数据并在 SageMaker 中进行训练，还是我可以在 SageMaker 中完成所有操作？ （考虑到成本）。
我遵循的教程：https://aws.amazon.com/blogs/machine-learning/using-pipe-in​​put-mode-for-amazon-sagemaker-algorithms/]]></description>
      <guid>https://stackoverflow.com/questions/77518065/cant-train-sagemaker-model-using-recordio-protobuf-data-saved-in-s3</guid>
      <pubDate>Mon, 20 Nov 2023 18:10:59 GMT</pubDate>
    </item>
    </channel>
</rss>