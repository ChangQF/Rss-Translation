<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 13 Aug 2024 03:18:18 GMT</lastBuildDate>
    <item>
      <title>我可以在哪里开始在机器人技术中实施机器学习？[关闭]</title>
      <link>https://stackoverflow.com/questions/78864202/where-can-i-get-started-to-implement-machine-learning-in-robotics</link>
      <description><![CDATA[最近我学习了机器学习，解决了一堆分类和回归问题。现在我想运用我的知识来构建一个真正的机器人，它能够自行行驶并使用超声波传感器避开障碍物。我可以从哪里开始，或者我到底需要知道什么才能使用传感器值训练我的模型并通过机器学习模型控制我的机器人。
我曾尝试利用超声波传感器值和训练模型，但不知道该如何做，然后使用这个训练过的模型来真正让机器人移动。]]></description>
      <guid>https://stackoverflow.com/questions/78864202/where-can-i-get-started-to-implement-machine-learning-in-robotics</guid>
      <pubDate>Tue, 13 Aug 2024 02:50:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Scikit-Learn 为分类变量选择参考水平？</title>
      <link>https://stackoverflow.com/questions/78864148/how-to-select-a-reference-level-for-categorical-variables-using-scikit-learn</link>
      <description><![CDATA[我正在尝试将代码从 SAS 转换为训练 GLM 模型的 Python。为此，我使用带有类词的 hpgenselect 来处理分类变量。在 SAS 中，我可以选择模型所需的任何分类变量的参考级别。参考级别基本上是将接收值 0 的类别，并且它将是其他变量进行比较的参考。
我搜索过，但没有在 Scikit-Learn 中找到类似的方法。有没有办法在 scikit-learn 或其他 Python 库中选择参考？
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78864148/how-to-select-a-reference-level-for-categorical-variables-using-scikit-learn</guid>
      <pubDate>Tue, 13 Aug 2024 02:19:55 GMT</pubDate>
    </item>
    <item>
      <title>我需要高级机器学习和 LLM 课程的推荐</title>
      <link>https://stackoverflow.com/questions/78863935/i-need-recommendations-for-advanced-machine-learning-and-llm-courses</link>
      <description><![CDATA[我正在寻找一些课程，但找不到提供优质应用和实践课程（最好是免费的）的平台。
有人可以推荐我一门涵盖分类和回归高级技术的高级机器学习课程吗？
此外，有没有关于法学硕士 (LLM) 的入门到中级课程？
感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78863935/i-need-recommendations-for-advanced-machine-learning-and-llm-courses</guid>
      <pubDate>Mon, 12 Aug 2024 23:45:07 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML 二元分类模型的最终预测准确率非常低</title>
      <link>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</guid>
      <pubDate>Mon, 12 Aug 2024 23:32:18 GMT</pubDate>
    </item>
    <item>
      <title>为赌场制定排班解决方案 [关闭]</title>
      <link>https://stackoverflow.com/questions/78863813/working-on-a-shift-scheduling-solution-for-a-casino</link>
      <description><![CDATA[我在一家赌场工作，我们需要在每班次为赌桌游戏分配发牌人。整个晚上游戏都结束了，那些已结束游戏的发牌人会把其他开始游戏的发牌人送回家。这可能是复杂的情况，因为并非所有发牌人都拥有同等的技能并掌握所有游戏。
例如，一个发牌人可能正在玩掷骰子游戏并需要回家，但唯一空闲的发牌人不知道如何发掷骰子。在这种情况下，需要采取多种措施才能让掷骰子发牌人回家。我想建立一个算法来分析所有开放的游戏并就可以采取哪些措施提出建议。
还涉及其他不同的细节，例如开始时间、让替补发牌人让其他发牌人休息、尽可能不要让发牌人移动太多，以及能够选择下一个要回家的发牌人。
我们目前手动执行此操作，这对我们的经理来说非常低效且压力很大。过去几个月我一直在学习 Python，但如果这更适合另一种语言，我也愿意尝试。
我知道这是一个复杂的问题，只是想寻求一些建议，看看下一步应该重点学习什么，比如哪种机器学习最好，创建用户界面等。谢谢！
我已经研究过二分匹配和绘图作为可能的解决方案，但不确定如何实现它]]></description>
      <guid>https://stackoverflow.com/questions/78863813/working-on-a-shift-scheduling-solution-for-a-casino</guid>
      <pubDate>Mon, 12 Aug 2024 22:47:03 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个掩模进行医学图像分割，然后进行逐像素分类？</title>
      <link>https://stackoverflow.com/questions/78863682/how-to-go-for-medical-image-segmentation-with-multiple-masks-and-then-doing-pixe</link>
      <description><![CDATA[我正在研究一个问题，其中我得到了训练图像，每个图像都有两个用于不同类别的掩码。我应该如何分割图像，然后进行像素分类以获得输出图像，其中 0 表示背景，1 和 2 表示两个类别？
我尝试组合掩码，然后将掩码和相应的图像输入分割模型，但不知何故我失败了。我是否应该组合掩码，因为我们还需要在输出中对像素进行分类。]]></description>
      <guid>https://stackoverflow.com/questions/78863682/how-to-go-for-medical-image-segmentation-with-multiple-masks-and-then-doing-pixe</guid>
      <pubDate>Mon, 12 Aug 2024 21:37:57 GMT</pubDate>
    </item>
    <item>
      <title>加载权重时出现意外键错误</title>
      <link>https://stackoverflow.com/questions/78863529/getting-unexpected-keys-error-while-loading-weights</link>
      <description><![CDATA[import torch
from PIL import Image
import numpy as np
from effdet import get_efficientdet_config, EfficientDet

config = get_efficientdet_config(&#39;tf_efficientdet_d0&#39;)
model = EfficientDet(config, pretrained_backbone=True)
model.eval()

当我运行此程序时，我收到错误
加载预训练权重时发现意外键（bn2.bias、bn2.num_batches_tracked、bn2.running_mean、bn2.running_var、bn2.weight、classifier.bias、classifier.weight、conv_head.weight）。如果模型正在调整，则可能会出现这种情况。

我研究了一下，发现这是由于 timm builder 造成的，但没有找到任何解决方案，所以请大家帮我解决这个问题。
我想加载 efficientdet 权重，但结果出现了意外的键错误]]></description>
      <guid>https://stackoverflow.com/questions/78863529/getting-unexpected-keys-error-while-loading-weights</guid>
      <pubDate>Mon, 12 Aug 2024 20:42:04 GMT</pubDate>
    </item>
    <item>
      <title>为一系列点的图形创建邻接矩阵</title>
      <link>https://stackoverflow.com/questions/78863456/creating-an-adjacency-matrix-for-a-graph-of-points-in-a-series</link>
      <description><![CDATA[我想创建一种机制，使用邻接矩阵在一条指令中乘以多个 PyTorch 张量。这些点以串联方式相互连接，但有一个小问题。假设这是一个表示 T 点串联连接的邻接矩阵：
adj_mat = torch.tensor([
[0, 1, 0, 0, 0], # T1 连接到 T2
[1, 0, 1, 0, 0], # T2 连接到 T1 和 T3
[0, 1, 0, 1, 0], # T3 连接到 T2 和 T4
[0, 0, 1, 0, 1], # T4 连接到 T3 和 T5
[0, 0, 0, 1, 0], # T5 连接到 T4
], dtype = torch.float32)

我有多个数量需要对输入张量进行算术运算：
K = torch.tensor([
[1.0, 2.0, 3.0, 4.0, 0.0],
[1.0, 2.0, 3.0, 4.0, 0.0]
], dtype=torch.float32)
C = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0], dtype = torch.float32)
S = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0], dtype = torch.float32)

val = torch.tensor([[1.0, 2.0, 4.0, 8.0, 16.0],
[5.0, 10.0, 15.0, 20.0, 5.0]], dtype = torch.float32)

dev = torch.tensor([11, 30], dtype = torch.float32)

计算如下，遍历 Tensor 的每一行（其中每行将并行计算，希望如此）：
T1 = T1 + (C(T1) * S(T1) * (dev + (T2-T1) * K(T1))
T2 = T2 + (C(T2) * S(T2) * ((T1-T2) * K(T1) + (T3-T2) * K(T2))
T3 = T3 + (C(T3) * S(T3) * ((T2-T3) * K(T2) + (T4-T3) * K(T3))
T4 = T4 + (C(T4) * S(T4) * ((T3-T4) * K(T3)+ (T5-T4) * K(T4))

其中 T1-T5 的值将来自 val 数组。我尝试了类似的方法，首先检查加权差异，即 ((T2-T3) * K(T2) + (T4-T3) * K(T3)) 是否计算正确
T_diffs = val.unsqueeze(1) - val.unsqueeze(2)
T_diffs_weighted = T_diffs * adj_mat.unsqueeze(0) * K.unsqueeze(1)
T_diffs_summed = torch.sum(T_diffs_weighted , dim = 2)
print(&quot;weighted Differences:&quot;, T_diffs_weighted )
print(&quot;Summed Differences:&quot;, T_diffs_summed )

我得到的输出是：
加权差异：张量（[[[ 0., 2., 0., 0., 0.],
[ -1., 0., 6., 0., 0.],
[ -0., -4., 0., 16., 0.],
[ -0., -0., -12., 0., 0.],
[ -0., -0., -0., -32., 0.]],

[[ 0., 10., 0., 0., 0.],
[ -5., 0., 15., 0., -0.],
[ -0., -10., 0., 20., -0.],
[ -0., -0., -15., 0., -0.],
[ 0., 0., 0., 60., 0.]]])

而所需输出为1:
加权差异：张量（[[[ 0., 1., 0., 0., 0.],
[ -1., 0., 6., 0., 0.],
[ 0., -4., 0., 16., 0.],
[ 0., 0., -12., 0., 0.],
[ 0., 0., 0., -32., 0.]],

[[ 0., 5., 0., 0., 0.],
[ -5., 0., 15., 0., -0.],
[ 0., -10., 0., 20., -0.],
[ 0., 0., -15., 0., -0.],
[ 0., 0., 0., 60., 0.]]])

求和差值：张量（[[ 1., 1., 10., -16., 0.],
[ 0., 5., 0., 65., 0.]])

提取的值将是一列，例如，这意味着 T1 将对应于第 0 列。我似乎无法正确地乘以张量 K。我能够正确地计算方程的 K 值，但不能同时计算两者。
最后，如果还有其他方法可以执行此乘法或方程，我们将不胜感激。顺便说一下，这些方程是运行在 Nvidia GPU 上的机器学习模型的一部分。我对 PyTorch 的 [un]squeeze() 方法还比较陌生，这就是为什么这有点难以理解。
1与方程的预期数学输出相比，加权差分矩阵中值的符号可能被反转。但我关注的是与张量 K 的乘法。]]></description>
      <guid>https://stackoverflow.com/questions/78863456/creating-an-adjacency-matrix-for-a-graph-of-points-in-a-series</guid>
      <pubDate>Mon, 12 Aug 2024 20:18:41 GMT</pubDate>
    </item>
    <item>
      <title>ML-Agents：当我的游戏对象的任何部分发生碰撞时，代理为空</title>
      <link>https://stackoverflow.com/questions/78863425/ml-agents-agent-is-null-when-any-part-of-my-game-object-collides</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863425/ml-agents-agent-is-null-when-any-part-of-my-game-object-collides</guid>
      <pubDate>Mon, 12 Aug 2024 20:07:45 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 Torch 使用 4 个 GPU 进行训练：torch.distributed.elastic.multiprocessing.api</title>
      <link>https://stackoverflow.com/questions/78863216/unable-to-train-with-4-gpus-using-torch-torch-distributed-elastic-multiprocessi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863216/unable-to-train-with-4-gpus-using-torch-torch-distributed-elastic-multiprocessi</guid>
      <pubDate>Mon, 12 Aug 2024 19:01:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在 HuggingFace 中从头开始重新初始化 GPT2 XL？</title>
      <link>https://stackoverflow.com/questions/78859343/how-to-reinitialize-from-scratch-gpt2-xl-in-huggingface</link>
      <description><![CDATA[我试图确认我的 GPT-2 模型是从头开始训练的，而不是使用任何预先存在的预训练权重。这是我的方法：

加载预训练的 GPT-2 XL 模型：我使用 AutoModelForCausalLM.from_pretrained(&quot;gpt2-xl&quot;) 加载预训练的 GPT-2 XL 模型，并计算此模型权重的总 L2 范数。
从头开始初始化新的 GPT-2 模型：然后我使用 GPT2Config 从头开始​​使用自定义配置初始化新的 GPT-2 模型。
比较 L2 范数：我计算预训练模型和新初始化模型的权重的 L2 范数。我的假设是，如果临时模型确实是从随机权重初始化的，那么临时模型的 L2 范数应该比预训练模型小得多。

这是代码片段：
import torch
from transformers import GPT2LMHeadModel, GPT2Config, AutoModelForCausalLM

# 步骤 1：加载预训练的 GPT-2 XL 模型
pretrained_model = AutoModelForCausalLM.from_pretrained(&quot;gpt2-xl&quot;)

# 步骤 2：计算预训练模型权重的 L2 范数
pretrained_weight_norm = 0.0
for param in pretrained_model.parameters():
pretrained_weight_norm += torch.norm(param, p=2).item()

print(f&quot;Total L2预训练模型权重的范数：{pretrained_weight_norm:.2f}&quot;)

# 步骤 3：使用自定义配置从头开始初始化新的 GPT-2 模型
config = GPT2Config(
vocab_size=52000, # 确保这与 tokenizer 的词汇量相匹配
n_ctx=1024, # 上下文窗口大小（模型一次可以看到的 token 数量）
bos_token_id=0, # 序列开始 token
eos_token_id=1, # 序列结束 token
)
model = GPT2LMHeadModel(config)

# 步骤 4：计算刚初始化的模型权重的 L2 范数
scratch_weight_norm = 0.0
for param in model.parameters():
scratch_weight_norm += torch.norm(param, p=2).item()

print(f&quot;从头开始初始化的模型的总 L2 范数：{scratch_weight_norm:.2f}&quot;)

这种方法是否是确认模型是从头开始训练的有效方法？是否存在任何潜在问题或更好的方法来验证模型没有预先存在的学习权重？
看起来正确
~/beyond-scale-language-data-diversity$ /opt/conda/envs/beyond_scale_div_coeff/bin/python /home/ubuntu/beyond-scale-language-data-diversity/playground/test_gpt2_pt_vs_reinit_scratch.py​​
config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 689/689 [00:00&lt;00:00，8.05MB/s]
model.safetensors：100%|████████████████████████████████████████████████████████████████████████████| 6.43G/6.43G [00:29&lt;00:00，221MB/s]
generation_config.json：100%|██████████████████████████████████████████████████████████████████████████████████████| 124/124 [00:00&lt;00:00，1.03MB/s]
预训练模型权重的总 L2 范数：24542.74
从头初始化模型的总 L2 范数：1637.31
（beyond_scale_div_coeff）

cross: https://discuss.huggingface.co/t/how-to-reinitialize-from-scratch-gpt-xl-in-hugging-face-hf/101905
ref: https://github.com/alycialee/beyond-scale-language-data-diversity/issues/18]]></description>
      <guid>https://stackoverflow.com/questions/78859343/how-to-reinitialize-from-scratch-gpt2-xl-in-huggingface</guid>
      <pubDate>Sun, 11 Aug 2024 20:27:07 GMT</pubDate>
    </item>
    <item>
      <title>机器学习（GAN）生成图像</title>
      <link>https://stackoverflow.com/questions/78859294/machine-learning-gan-to-generate-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78859294/machine-learning-gan-to-generate-images</guid>
      <pubDate>Sun, 11 Aug 2024 20:01:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 Ultralytics YOLOv8 在图像检测方面效果不佳？[关闭]</title>
      <link>https://stackoverflow.com/questions/78850625/why-is-ultralytics-yolov8-giving-poor-results-for-image-detection</link>
      <description><![CDATA[在按照 YouTube 教程使用 Ultralytics 进行图像检测后，我得到的结果与视频不一致。边界框不在正确的主题上，所有内容都被错误识别。为什么我做了相同的操作，Ultralytics 却无法正常工作？
我不知道我的 GPU 是否与此有关，但我有一台 RTX 3060。我也根据视频正确安装了所有内容，使用了相同的代码，并且我也使用了相同的足球视频。
视频链接：https://www.youtube.com/watch?v=neBZ6huolkg
这是我当前的代码
from ultralytics import YOLO

model = YOLO(&#39;yolov8x&#39;)

results = model.predict(&#39;soccer_clip.mp4&#39;, save=True)

我的结果
我的结果
Youtube 视频结果（视频时间戳：10:46）
Youtube 结果]]></description>
      <guid>https://stackoverflow.com/questions/78850625/why-is-ultralytics-yolov8-giving-poor-results-for-image-detection</guid>
      <pubDate>Thu, 08 Aug 2024 22:20:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOv8 进行大量错误检测</title>
      <link>https://stackoverflow.com/questions/78820748/alot-of-incorrect-detection-using-yolov8</link>
      <description><![CDATA[我尝试使用 Visual Code Studio 运行 YOLOv8。安装了 ultralytics 并在 vs code 终端上运行了 yolo predict model=yolov8n.pt source=&#39;https://ultralytics.com/images/bus.jpg&#39;。
但是我收到的输出是
2 个人、1 辆自行车、5 辆汽车、10 辆摩托车、73 艘船、3 个停车标志、1 只狗、10 匹马、10 头牛、32 只熊、1 只长颈鹿、63 把雨伞、6 个手提包、9 个飞盘、15 块滑雪板、5 块冲浪板、12 把刀、5 张床、37 张餐桌

这些显然不是这张图片的一部分。

当我第一次安装 ultralytics 并尝试运行 torch 时，出现了缺少依赖项的错误。fbgemm.ddl 丢失。后来，当我安装 vs_BuildTools 时，这个问题得到了解决。然后我继续在虚拟环境中运行代码，其中使用 torch 的程序运行没有任何错误。然后我继续输入此代码片段并遇到此问题。我也尝试使用命令提示符和 jupyter 笔记本运行，但同样的问题仍然存在。
我也检查了版本是否兼容，结果是兼容的。我还没有安装 cuda，是因为这个原因还是还有其他我不知道的问题？请有人帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78820748/alot-of-incorrect-detection-using-yolov8</guid>
      <pubDate>Thu, 01 Aug 2024 11:33:58 GMT</pubDate>
    </item>
    <item>
      <title>如果我导入 pyttsx3 库，我的相机不会打开 opencv2。但是没有显示任何错误</title>
      <link>https://stackoverflow.com/questions/78299560/if-i-import-pyttsx3-library-my-camera-is-not-opening-of-opencv2-however-no-erro</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78299560/if-i-import-pyttsx3-library-my-camera-is-not-opening-of-opencv2-however-no-erro</guid>
      <pubDate>Tue, 09 Apr 2024 15:30:19 GMT</pubDate>
    </item>
    </channel>
</rss>