<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 01 Jul 2024 21:14:33 GMT</lastBuildDate>
    <item>
      <title>如何在 macOS 10.12 上运行 Core ML 模型？</title>
      <link>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</link>
      <description><![CDATA[https://developer.apple.com/documentation/coreml 提到 macOS 10.13+：

如何在 macOS 10.12 上运行 Core ML 模型？

在 Ubuntu 20.04 上创建的 Core ML 模型示例（使用 Python 3.10 和 torch 2.3.1 测试）：
git clone https://github.com/huggingface/exporters.git
cd exporters
pip install -e .
python -m exporters.coreml --model=distilbert-base-uncasederated/ --quantize=float32 
]]></description>
      <guid>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</guid>
      <pubDate>Mon, 01 Jul 2024 20:13:24 GMT</pubDate>
    </item>
    <item>
      <title>NLP 情绪分析网络不起作用</title>
      <link>https://stackoverflow.com/questions/78693863/nlp-sentiment-analysis-net-is-not-working</link>
      <description><![CDATA[我想为我的最终项目训练一个用于情绪分析的神经网络，但它不起作用。
数据集包含波兰语评论，预期包含 11 列标签，11 种具有真/假值的不同情绪。我加载了数据，从中提取了词条，删除了停用词。然后我对数据进行了矢量化。我认为模型出了问题，训练不正常，准确率很低。
import tensorflow as tf
from tensorflow import keras

import numpy as np
!pip install -q spacy --upgrade
!python -m spacy download pl_core_news_md
from keras.preprocessing.text import one_hot
from keras.preprocessing.sequence import pad_sequences
import pandas as pd
import re
import spacy
nlp = spacy.load(&quot;pl_core_news_md&quot;)

df_in = pd.read_csv(url_in, sep=&#39;\t&#39;)

df_expected = pd.read_csv(url_expected, sep=&#39;\t&#39;)

df_expected_final = df_expected.astype(int)
def preprocess_text(text):
doc = nlp(text)
processed_tokens = []
for token in doc:
if not token.is_stop:
processed_tokens.append(token.lemma_.lower())
processed_text = &#39; &#39;.join(processed_tokens)
return processing_text

df_in[&#39;processed_text&#39;] = df_in[&#39;text&#39;].apply(preprocess_text)

vocab_size = len(set(&quot; &quot;.join(df_in[&#39;processed_text&#39;]).split()))
print(f&quot;Liczba unikalnych słów (vocab_size): {vocab_size}&quot;)
encoded_docs = [one_hot(d, vocab_size) for d in df_in[&#39;processed_text&#39;]]
max_length = len(max(encoded_docs, key = len))
padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding=&#39;post&#39;)
vocabulary_size = 16132

model = keras.Sequential()
model.add(keras.layers.Embedding(vocabulary_size, 16))
model.add(keras.layers.GlobalAveragePooling1D())
model.add(keras.layers.Dense(16,activation=&#39;relu&#39;))
model.add(keras.layers.Dense(16,activation=&#39;relu&#39;))
model.add(keras.layers.Dense(11,activation=&#39;softmax&#39;))

model.summary()
lr = 0.01
epoch_num = 50
opt = keras.optimizers.Adam(learning_rate=lr)
model.compile(optimizer=opt,
loss=&#39;binary_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

x_val = padded_docs[:1434]
partial_x_train = padded_docs[1434:]
y_val = df_expected_final[:1434]
partial_y_train = df_expected_final[1434:]
history = model.fit(partial_x_train,
partial_y_train,
epochs=epoch_num,
batch_size=512,
validation_data=(x_val, y_val),
verbose=1,
callbacks=[logging_callback])
]]></description>
      <guid>https://stackoverflow.com/questions/78693863/nlp-sentiment-analysis-net-is-not-working</guid>
      <pubDate>Mon, 01 Jul 2024 19:00:24 GMT</pubDate>
    </item>
    <item>
      <title>本地机器上的实时语音分割 [无 GPU/外部 API] [关闭]</title>
      <link>https://stackoverflow.com/questions/78693474/realtime-speech-diarization-on-local-machine-no-gpu-external-apis</link>
      <description><![CDATA[我正在寻找一些在本地机器上不使用任何 GPU 的实时语音分割解决方案。目前有类似的东西吗？
我知道分割对于 CPU 来说是一项复杂的任务，老实说，我的任务甚至不需要分割。我想要实现的任务是麦克风的音频将继续流式传输，任何随机的人都可以对着麦克风说话，但当第一个人已经在说话时，每当另一个人要说话时，代码就会指出检测到了第二个人。就是这样！分割其实是不需要的，但除了分割之外，我想不出更好的解决方案来实现我想要的。
目前有没有这样的解决方案可以用于我的任务？
我能找到的只有 pyannote 解决方案、Nvidia 的 NeMo 和一些其他解决方案，但它们都必须加载需要高 GPU RAM 的重型模型。我想要一些可以在本地 CPU 上运行的简单方法。而且我绝对不允许使用付费的外部 API，例如 Assembly AI/Deepgram。]]></description>
      <guid>https://stackoverflow.com/questions/78693474/realtime-speech-diarization-on-local-machine-no-gpu-external-apis</guid>
      <pubDate>Mon, 01 Jul 2024 17:09:07 GMT</pubDate>
    </item>
    <item>
      <title>如何解决VAE训练中的梯度爆炸问题？</title>
      <link>https://stackoverflow.com/questions/78693456/how-to-solve-exploding-gradient-problem-in-vae-training</link>
      <description><![CDATA[我尝试在 CelebA 数据集上实现 VAE，灵感来自 MNIST 的 Tensorflow 实现。我尝试过改变批处理大小，但似乎没有效果。形成的图像大部分都是灰色的。理想情况下，我们希望 KL 散度和重建损失都接近于零，但在我的例子中，两者都呈指数增长。
这是我得到的损失曲线。
这是损失函数定义块：
optimizer = tf.keras.optimizers.Adam(1e-4)
def log_normal_pdf(sample, mean, logvar, raxis=1):
log2pi = tf.math.log(2. * np.pi)
return tf.reduce_sum(
-.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),
axis=raxis)

def compute_loss(model, x):
mean, logvar = model.encode(x)
z = model.reparameterize(mean, logvar)
x_logit = model.decode(z)
cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)
#logpx_z = tf.reduce_mean(tf.square(x - x_logit), axis=[1, 2, 3])
logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])
logpz = log_normal_pdf(z, 0., 0.)
logqz_x = log_normal_pdf(z, mean, logvar)
return -tf.reduce_mean(logpx_z + logpz - logqz_x), logpx_z, logqz_x-logpz

我的潜在维度是 16，批量大小为 500。另外，我的输入只有 500 张图片。
我已经尝试更改输入的大小，但似乎没有影响。
以下是模型定义：
class CVAE(tf.keras.Model):
def __init__(self, latent_dim):
super(CVAE, self).__init__()
self.latent_dim = latent_dim
self.encoder = tf.keras.Sequential(
[
tf.keras.layers.InputLayer(input_shape=(64, 64, 3)),
tf.keras.layers.Conv2D(
filters=32, kernel_size=3, strides=(2, 2),activation=&#39;relu&#39;),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Conv2D(
filters=64, kernel_size=3, strides=(2, 2),activation=&#39;relu&#39;),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Conv2D(
filters=128, kernel_size=3, strides=(2, 2), activity=&#39;relu&#39;),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Conv2D(
filters=256, kernel_size=3, strides=(2, 2), activity=&#39;relu&#39;),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Conv2D(
filters=512, kernel_size=3, strides=(2, 2), activity=&#39;relu&#39;),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.Flatten(),
# 无激活
tf.keras.layers.Dense(latent_dim + latent_dim),
]
)

self.decoder = tf.keras.Sequential(
[
tf.keras.layers.InputLayer(input_shape=(latent_dim,)),
tf.keras.layers.Dense(units=4*4*256,activation=tf.nn.relu),
tf.keras.layers.Reshape(target_shape=(4, 4, 256)),
tf.keras.layers.Conv2DTranspose(
filters=128, kernel_size=3, strides=2, padding=&#39;same&#39;,
activation=&#39;relu&#39;),
tf.keras.layers.Conv2DTranspose(
filters=64, kernel_size=3, strides=2, padding=&#39;same&#39;,
激活=&#39;relu&#39;),
tf.keras.layers.Conv2DTranspose(
过滤器=32，kernel_size=3，strides=2，padding=&#39;same&#39;,
激活=&#39;relu&#39;),
tf.keras.layers.Conv2DTranspose(
过滤器=3，kernel_size=3，strides=2，padding=&#39;same&#39;),
]
)
@tf.function
def sample(self，eps=None):
如果 eps 为 None:
eps = tf.random.normal(shape=(100，self.latent_dim))
返回 self.decode(eps，apply_sigmoid=True)

def encode(self，x):
平均值，logvar = tf.split(self.encoder(x)，num_or_size_splits=2，axis=1)
返回平均值，logvar

def reparameterize(self，平均值， logvar):
eps = tf.random.normal(shape=mean.shape)
return eps * tf.exp(logvar * .5) + mean

def decrypt(self, z, apply_sigmoid=False):
logits = self.decoder(z)
if apply_sigmoid:
probs = tf.sigmoid(logits)
return probs
return logits

这是 colab 笔记本的链接]]></description>
      <guid>https://stackoverflow.com/questions/78693456/how-to-solve-exploding-gradient-problem-in-vae-training</guid>
      <pubDate>Mon, 01 Jul 2024 17:03:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 Detectron2 进行多任务问题分割和关键点检测</title>
      <link>https://stackoverflow.com/questions/78692534/multitask-issue-segmentation-keypoint-detection-with-detectron2</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78692534/multitask-issue-segmentation-keypoint-detection-with-detectron2</guid>
      <pubDate>Mon, 01 Jul 2024 13:32:45 GMT</pubDate>
    </item>
    <item>
      <title>使用黑盒评分的无监督反向传播</title>
      <link>https://stackoverflow.com/questions/78692093/unsupervised-backpropagation-with-blackbox-scoring</link>
      <description><![CDATA[我有一个向量集，它对 x 进行评分，分数是一个浮点数，而黑盒是另一个程序。我想尝试通过更改向量化来提高分数。我不知道更好的向量化是什么样子，因此它是无监督的，应该从获得的分数中学习。你会建议什么机器学习方法？损失函数是负分数吗？]]></description>
      <guid>https://stackoverflow.com/questions/78692093/unsupervised-backpropagation-with-blackbox-scoring</guid>
      <pubDate>Mon, 01 Jul 2024 11:58:12 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 pytorch 提取视觉变换器的倒数第二层输出</title>
      <link>https://stackoverflow.com/questions/78691616/cannot-extract-penultimate-layer-output-of-a-vision-transformer-with-pytorch</link>
      <description><![CDATA[我有以下模型，该模型使用我自己的 DataParallel 训练的数据集进行了调整
model = timm.create_model(&#39;vit_base_patch16_224&#39;, pretrained=False)
model.head = nn.Sequential(nn.Linear(768, 512),nn.ReLU(),nn.BatchNorm1d(512),nn.Dropout(p=0.2),nn.Linear(512, 141))
checkpoint = torch.load(&#39;vit_b_16v3.pth&#39;)
checkpoint = {k.partition(&#39;module.&#39;)[2]: v for k, v in checkpoint.items()}
# 加载参数
model.load_state_dict(checkpoint)

但是，我不知道如何获取这种视觉转换器的倒数第二层输出。我尝试了本教程，但不起作用。我只想输入一张图片，并有一个 512 维向量来描述它。使用 Tensorflow 做这件事很容易，但在 Pytorch 中我却很挣扎。
P.s：我的最后一层如下
(norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
(fc_norm): Identity()
(head_drop): Dropout(p=0.0, inplace=False)
(head): Sequential(
(0): Linear(in_features=768, out_features=512, bias=True)
(1): ReLU()
(2): BatchNorm1d(512, eps=1e-05, motivation=0.1, affine=True, track_running_stats=True)
(3): Dropout(p=0.2, inplace=False)
(4): Linear(in_features=512, out_features=141,bias=True)
)
)
]]></description>
      <guid>https://stackoverflow.com/questions/78691616/cannot-extract-penultimate-layer-output-of-a-vision-transformer-with-pytorch</guid>
      <pubDate>Mon, 01 Jul 2024 10:16:39 GMT</pubDate>
    </item>
    <item>
      <title>Roboflow Vs. Darknet 用于生成权重文件和创建模型</title>
      <link>https://stackoverflow.com/questions/78691574/roboflow-vs-darknet-for-generating-weight-file-and-creating-the-model</link>
      <description><![CDATA[我有一个 YoloV8 数据文件格式，它是手动完成的数据（图像）注释。
生成模型并因此产生权重文件的最有效和最直接的方法是什么？是通过以下命令使用 darknet 吗：
darknet.exe detector train data/obj.data yolo-obj.cfg backup\yolo-obj_2000.weights

然后使用类似下面的命令生成关联模型：
python tools/model_converter/convert.py cfg/yolov3.cfg weights/yolov3.weights weights/yolov3.h5

或者通过以下命令使用 Roboflow：
version.deploy(model_type=&quot;yolov8&quot;, model_path=f”{HOME}/runs/detect/train/&quot;)

在我看来，darknet 更难安装。]]></description>
      <guid>https://stackoverflow.com/questions/78691574/roboflow-vs-darknet-for-generating-weight-file-and-creating-the-model</guid>
      <pubDate>Mon, 01 Jul 2024 10:07:36 GMT</pubDate>
    </item>
    <item>
      <title>学习 Python 的最佳书籍 [关闭]</title>
      <link>https://stackoverflow.com/questions/78690958/best-book-to-learn-python</link>
      <description><![CDATA[寻求具有最新更新的最佳 Python 书籍推荐
我渴望从头开始学习 Python，并随时了解该语言的最新发展。随着 Python 的快速发展，我想确保自己学习的是最新的功能、最佳实践和行业标准。
您能否推荐一本全面且适合初学者的书籍，该书涵盖 Python 3.x（最好是最新版本，Python 3.10 或 3.11），并包含以下主题：
核心 Python 概念：变量、数据类型、控制结构、函数、面向对象编程等
数据分析和可视化：NumPy、Pandas、Matplotlib 和 Seaborn
Web 开发：Flask 或 Django、HTML、CSS 和 JavaScript 基础知识
机器学习和人工智能：scikit-learn、TensorFlow 和 Keras
最佳实践和编码标准：代码组织、调试和测试
]]></description>
      <guid>https://stackoverflow.com/questions/78690958/best-book-to-learn-python</guid>
      <pubDate>Mon, 01 Jul 2024 07:35:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python sdk v2 在 Azure ML for Pipeline 中加载已注册的组件</title>
      <link>https://stackoverflow.com/questions/78679016/load-registered-component-in-azure-ml-for-pipeline-using-python-sdk-v2</link>
      <description><![CDATA[我正在 Azure 机器学习工作室中创建将在管道中一起运行的组件。在这个基本示例中，我有一个 python 脚本和一个 yml 文件，它们构成了我的组件，还有一个用于定义、实例化和运行管道的笔记本。请参阅下面此组件的文件夹结构概述。
📦component
┣ 📜notebook.ipynb
┣ 📜component_script.py
┗ 📜component_def.yml

然后，在我的笔记本中，我可以使用下面的代码加载组件并将其注册到工作区（请注意，这里我已经实例化了我的 ml_client 对象）。
# 导入组件包
from azure.ai.ml import load_component

# 从 yml 文件加载组件
component = load_component(&quot;component_def.yml&quot;)

# 现在我们将组件注册到工作区
component = ml_client.create_or_update(component)

然后我可以成功地将此组件传递到管道中。我的问题是，既然我已经注册了组件，我就不再需要使用 component = load_component(&quot;component_def.yml&quot;) 来实例化组件对象，这需要访问 yml 文件。我应该能够从已注册的组件实例化组件对象。我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/78679016/load-registered-component-in-azure-ml-for-pipeline-using-python-sdk-v2</guid>
      <pubDate>Thu, 27 Jun 2024 17:10:34 GMT</pubDate>
    </item>
    <item>
      <title>wandb 的超频算法在哪些时期检查改进？</title>
      <link>https://stackoverflow.com/questions/78530549/at-which-epochs-does-the-hyperband-algorithm-of-wandb-checks-for-improvement</link>
      <description><![CDATA[我正在尝试使用 wandb 库的超参数调整（又名扫描）功能（链接到其官方页面）。我正在尝试应用贝叶斯超带算法。
现在，正如这些页面中提到的那样（如何定义扫描配置），（与提前终止选项相关的参数是什么），在提前终止下，我们必须提到 4 个参数（一般），它们是 min_iter、s、eta 和 max_iter，它看起来如下所示。
我的疑问总结：
总之，我想知道的是，
给定所有 4 个：- min_iter、s、eta 和max_iter

超频带算法将在哪些时期检查改进？

考虑到我正在尝试做贝叶斯超频带，第一个括号中将评估多少次运行，连续的括号中将评估多少次运行？

是否有任何方法或经验法则来决定这 4 个参数（min_iter、s、eta 和 max_iter）的取值？

请更详细地解释一下参数 s 和 eta（特别是 eta），即使用一些基础数学知识（如果可能，请保持简单）。


我对什么有疑问？ （更详细/上下文解释）：
（这里），他们有点解释了在哪些时期（他们的）超频带算法实现会检查改进情况并决定是否终止运行。
当我们只关注每次运行的最小迭代次数时
当我们只关注每次运行的最小迭代次数时
但是对于我们关注的是每次运行的最小和最大迭代次数的情况？
就像下面这个...
#在 yaml 文件中，由 wanbd 在 python 中使用
early_terminate:
type: hyperband
min_iter: 10
s: 3
eta: 4
max_iter: 50

我已经尝试过的：
我甚至尽我所能阅读原始论文并试图了解发生了什么（或可能发生什么）（链接到 hyperband 算法的原始论文），但无法得到满意的答案。
我甚至尝试访问他们的 github 页面，那里有示例，但他们只展示了如何编写配置，并没有深入解释它的作用。]]></description>
      <guid>https://stackoverflow.com/questions/78530549/at-which-epochs-does-the-hyperband-algorithm-of-wandb-checks-for-improvement</guid>
      <pubDate>Fri, 24 May 2024 20:25:42 GMT</pubDate>
    </item>
    <item>
      <title>将 ONNX 模型转换为 Tensorflow Lite - 不支持 pytorch_half_pixel</title>
      <link>https://stackoverflow.com/questions/78218890/converting-onnx-model-to-tensorflow-lite-pytorch-half-pixel-not-supported</link>
      <description><![CDATA[我正在尝试将 ONNX 模型转换为 Tensorflow Lite 格式。代码简单，但出现此错误。我更新了我的 onnx 版本，但没有成功
import onnx
import tensorflow as tf
import onnx_tf
#
#
# README：此文件将 onnx 模型转换为 tflite
#
#
#

onnx_model_path = &#39;/home/sfrye/segmentation/segmentation_checkpoints/efficientnet/modified-new.onnx&#39;

onnx_model = onnx.load(onnx_model_path)

tf_model = onnx_tf.backend.prepare(onnx_model)
tf_model.export_graph(&quot;tflite_model.tf&quot;)

错误如下

RuntimeError：在用户代码中：

文件&quot;/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/backend_tf_module.py&quot;，第 99 行，在 __call__ *
output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,
File &quot;/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/backend.py&quot;，第 347 行，在 _onnx_node_to_tensorflow_op *
return handler.handle(node, tensor_dict=tensor_dict, strict=strict)
File &quot;/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/handlers/handler.py&quot;，第 58 行，在 handle *
cls.args_check(node, **kwargs)
文件 &quot;/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/handlers/backend/resize.py&quot;，第 125 行，在 args_check *
exception.OP_UNSUPPORTED_EXCEPT(
文件 &quot;/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/common/exception.py&quot;，第 50 行，在 __call__ *
raise self._func(self.get_message(op, framework))

RuntimeError: Tensorflow 不支持调整 coordinate_transformation_mode=pytorch_half_pixel 的大小。


我尝试更新我的 onnx，因为这解决了此错误代码的某些问题]]></description>
      <guid>https://stackoverflow.com/questions/78218890/converting-onnx-model-to-tensorflow-lite-pytorch-half-pixel-not-supported</guid>
      <pubDate>Mon, 25 Mar 2024 11:55:44 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：不可散列类型：pd.get_dummies 的“Series”</title>
      <link>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</link>
      <description><![CDATA[我尝试对我拥有的数据框中的一些名义数据（来自 Kaggle 的 House Regression）使用 pd.get_dummies。我将所有名义类别分成列名列表，&#39;obj_nominal&#39;。
当我调用
pd.get_dummies(df, columns=obj_nominal)

我收到错误：
TypeError：不可哈希类型：&#39;Series&#39;。

到目前为止，我所做的唯一预处理是删除数据集中的空值。我也尝试过使用 Sklearn OneHotEncoder，但它会产生相同的错误。
我也尝试过使用以下方法制作单独的数据框：
x = df.iloc[:, obj_nominal]

并在数据框上传递 get_dummies：
pd.get_dummies(data = x)

但还是没运气……
数据可在 https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data 下载]]></description>
      <guid>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</guid>
      <pubDate>Fri, 07 Jan 2022 05:51:22 GMT</pubDate>
    </item>
    <item>
      <title>反向传播和反向模式自动微分之间有什么区别？</title>
      <link>https://stackoverflow.com/questions/49926192/what-is-the-difference-between-backpropagation-and-reverse-mode-autodiff</link>
      <description><![CDATA[通过阅读这本书，我熟悉了以下内容：

对于每个训练实例，反向传播算法首先进行
预测（正向传递），测量误差，然后反向遍历每个
层以测量每个
连接的误差贡献（反向传递），最后稍微调整连接
权重以减少误差。

但是我不确定这与 TensorFlow 的反向模式自动微分实现有何不同。
据我所知，反向模式自动微分首先沿正向遍历图形，然后在第二遍中计算输出相对于输入的所有偏导数。这与传播算法非常相似。
反向传播与反向模式自动微分有何不同？]]></description>
      <guid>https://stackoverflow.com/questions/49926192/what-is-the-difference-between-backpropagation-and-reverse-mode-autodiff</guid>
      <pubDate>Thu, 19 Apr 2018 16:43:07 GMT</pubDate>
    </item>
    <item>
      <title>当setCar设置为true时，如何显示前提和后果？</title>
      <link>https://stackoverflow.com/questions/39066421/how-to-display-the-premise-and-consequence-when-the-setcar-is-set-to-true</link>
      <description><![CDATA[我想在 Weka 3.8.0 中运行 apriori 算法后，获取生成规则的每一行的前提和后果。
 apriori.setNumRules(NUMBER_OF_RULES);
apriori.setMinMetric(MINIMUM_CONFIDENCE);
apriori.setLowerBoundMinSupport(MINIMUM_SUPPORT);

apriori.setCar(true);

apriori.buildAssociations(instances);

我尝试使用下面的代码来获取规则，但它给出了一个异常
（weka.associations.ItemSet 无法转换为 weka.associations.AprioriItemSet）：
 AssociationRules arules = apriori.getAssociationRules();

此外，我尝试使用 getAllTheRules() 方法，但它给出了不同的结果。
 ArrayList&lt;Object&gt;[] arules = apriori.getAllTheRules();
System.out.println(((ItemSet)arules[0].get(1)).getRevision()); //12014
System.out.println(((ItemSet)arules[0].get(2)).getRevision()); //12014
System.out.println(((ItemSet)arules[0].get(5)).getRevision()); //12014
]]></description>
      <guid>https://stackoverflow.com/questions/39066421/how-to-display-the-premise-and-consequence-when-the-setcar-is-set-to-true</guid>
      <pubDate>Sun, 21 Aug 2016 16:30:51 GMT</pubDate>
    </item>
    </channel>
</rss>