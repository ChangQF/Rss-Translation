<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 04 Dec 2023 01:01:19 GMT</lastBuildDate>
    <item>
      <title>spaCy 值错误：[E1041] 需要字符串、文档或字节作为输入，但得到：<class 'float'></title>
      <link>https://stackoverflow.com/questions/77596731/spacy-value-error-e1041-expected-a-string-doc-or-bytes-as-input-but-got</link>
      <description><![CDATA[我正在尝试使用 spaCy 对中文输入进行矢量化。
我的代码如下：
nlp = spacy.load(&#39;zh_core_web_md&#39;)
def tokenize_and_vectorize_textZH(text): clean_tokensZH = [] for token in nlp(text): if (not token.is_stop) &amp; (token.lemma_ != &#39;-PRON-&#39;) &amp; (不是 token.is_punct): # -PRON- 是一个特殊的全包“引理” spaCy 用于任何代词，我们要排除这些 if (len(token.vector) != 300): print(token) clean_tokensZH.append(token.vector) return np.array(clean_tokensZH)
`all_summmed_vecsZH = []
def sum_vecsZH(输入):
tokenized_vectorsZH = input.apply(tokenize_and_vectorize_textZH)
tokenized_vectorZH = tokenized_vectorsZH.to_numpy()
打印(len(tokenized_vectorsZH))
#print（类型（标记化向量））
对于 tokenized_vectorsZH 中的行：
&lt;前&gt;&lt;代码&gt;#print(行)

summed_vecZH = [0]*300 # 从 300 个零的列表开始

for vec in row: # 循环遍历与行中每个标记对应的每个向量
  #if (len(vec) != 300):
    #打印（向量）
  summed_vecZH += vec

all_summmed_vecs.append(summed_vecZH)`

`sum_vecsZH(X_trainZH)
打印（all_summmed_vecs）
sum_vecsZH(y_trainZH)
打印（all_summmed_vecs）
sum_vecsZH(X_testZH)
打印（all_summmed_vecs）
sum_vecsZH(y_testZH)
打印（all_summmed_vecs）`
这个错误的原因是什么？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77596731/spacy-value-error-e1041-expected-a-string-doc-or-bytes-as-input-but-got</guid>
      <pubDate>Mon, 04 Dec 2023 00:59:14 GMT</pubDate>
    </item>
    <item>
      <title>MLPClassifier 适合二元分类吗？</title>
      <link>https://stackoverflow.com/questions/77596591/is-mlpclassifier-appropriate-for-binary-classification</link>
      <description><![CDATA[我编写了一个使用 MLPClassifier 来解决二元分类问题的程序。它有点有效，但我不相信这是正确的模型。
我有 1300 个整数的十六进制数要放入两个类之一：类 0 和类 1。一个潜在的问题是，在我的训练数据中，98% 属于类 0，因此我将从 &quot; 获得 98% 的准确率“预测函数”总是返回“class 0”与输入无关。
是否有专为此类问题设计的机器学习模型？
================================================== ===============
TLDR？
我的数据如下：
X = 数组([[ 0, 11, 51, 13, 0, 9],
       [51,13,0,9,0,11],
       [ 0, 8, 0, 10, 0, 13],
       ...,
       [ 0, 11, 61, 12, 0, 8],
       [ 0, 8, 0, 0, 60, 11],
       [30, 11, 0, 6, 0, 9]])

目标是 y，一个包含 1300 个 0 和 1 的列表。我使用 MLPClassifier 并获得了 98% 的预测准确率。这时我突然想到，98% 的元组恰好属于 0 类，因此，如果我不费心进行任何机器学习，而是猜测类始终为 0，那么我将获得 98% 的准确率。
我检查了拟合度，看看它在 1 类元组上的表现如何，发现其中 82% 的预测正确，因此准确度为 98% 的 82%，即大约 80%，我想改进，但是怎么办？
除了盲目增加层的大小/数量之外，我不知道如何更改 MLPClassifier 的参数，但我突然想到，我很可能使用完全错误的模型来解决带有 Yes/ 的学习问题没有分类。另外，六元组中的整数不是任意的，我想到这也可能与模型的选择有关。特别是，六个输入中的三个始终在 0 - 15 范围内，另外三个是两位数代码，第一位数字有三种可能，第二位数字有两种可能。
感谢您的任何想法。
代码：
m = MLPClassifier(hidden_​​layer_sizes = (256, 128, 64), max_iter=10000) # 从我在网上找到的示例粘贴:(
_ = m.fit(X, y)
yhat = m.predict(X)
cm = 混淆矩阵(y, yhat)
print( &#39;准确率 = &#39;, np.mean( y == yhat ) )
打印（厘米）

输出：
准确度 = 0.9816653934300993
[[1267 13]
 [11 18]]

(pdb) class1 = [ i for i in range(len(y)) if y[i] == 1]
(pdb) z = m.predict(np.row_stack((X[q] for q in class1)))
(pdb) z
数组([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 , 1, 1, 1, 0, 1])
(pdb) len(z), 总和(z)
29, 24
]]></description>
      <guid>https://stackoverflow.com/questions/77596591/is-mlpclassifier-appropriate-for-binary-classification</guid>
      <pubDate>Sun, 03 Dec 2023 23:53:22 GMT</pubDate>
    </item>
    <item>
      <title>如何预测回归模型的健康百分比值</title>
      <link>https://stackoverflow.com/questions/77596584/how-to-predict-health-percentage-values-for-regression-model</link>
      <description><![CDATA[我目前正在研究预测维护数据集，其中包含来自传感器的数据、任何错误的发生以及每台机器的一些特征。在进行特征工程之后，我创建了一个列，其中包含引擎剩余使用寿命的％百分比。
y_column 是一系列从 0 到 1 均匀递增的变量，当达到 1（表示发生错误）时返回到 0。我正在使用回归模型，我的结果如下图所示。由于我是机器学习新手，解决此类问题的方法是什么？我比较习惯分类。有哪些方法可以改善此类结果？
我添加了滚动平均值/标准差/最小值/最大值，我添加了滞后特征，我复制了该数据集分类方法中使用的一些技术，但即使我得到 20% 的 RMSE 和 MAE，它也没有捕获问题的形象正确。到目前为止，我正在使用 GradientBoostingRegressor KNeighborsRegressor RandomForestRegressor。改善结果的一般技巧有哪些？顺便说一句，模型无需任何超参数调整即可拟合。对这种类型的结果有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77596584/how-to-predict-health-percentage-values-for-regression-model</guid>
      <pubDate>Sun, 03 Dec 2023 23:49:03 GMT</pubDate>
    </item>
    <item>
      <title>如何运行以下 Python 和 Boto3 代码？</title>
      <link>https://stackoverflow.com/questions/77596323/how-do-i-run-the-following-python-and-boto3-code</link>
      <description><![CDATA[我正在尝试探索 AWS 的机器学习模型。 AWS 最近发布了 Bedrock 服务，我想设置一个环境来执行此操作。我还需要与 S3、Langchain 和 Vector 数据库（例如 Pinecone）进行交互。这里有一些关于我可能会玩的东西的想法，我会尝试遵循这个：示例
我的 PC 上有 VS Code，并且我看过一份指南，其中详细介绍了使用 Pythin 和 Boto3 进行设置的一些步骤：指南
我从示例链接中看到的是，我猜测使用了 Jupyter notbeook。另外（请原谅我的天真），如果我将 S3 文件放入 Vector 数据库，这些服务将需要启动（或设置）肯定，并且由我支付。否则这个 Vector 数据库将位于哪里以及 Langchain 将在哪里运行？
例如运行：
%pip install --no-build-isolation --force-reinstall \
    “boto3＞=1.28.57” \
    “awscli&gt;=1.29.57” \
    “botocore”=1.31.57”

%pip install --quiet langchain==0.0.309

您将如何以及在哪里键入此命令来运行？
之后，Vector 数据库将仅通过 AWS Bedrock（它处理许多底层内容）进行查询。所以我想我的其他问题是最初将数据导入矢量数据库：
我需要 AWS Sagemaker 吗？我在设置 SageMaker 时看到，您可以指定 EC2 或某些计算能力。
有没有一种简单的方法可以在没有 SageMaker 的情况下使用此示例，或者 SageMaker 是最容易设置和使用的？
或者此处链接的指南是否足够？
本质上，要使用我链接的示例，我的设置应该是什么？]]></description>
      <guid>https://stackoverflow.com/questions/77596323/how-do-i-run-the-following-python-and-boto3-code</guid>
      <pubDate>Sun, 03 Dec 2023 22:03:30 GMT</pubDate>
    </item>
    <item>
      <title>二元分类的最佳机器学习模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77596028/best-machine-learning-model-for-binary-classification</link>
      <description><![CDATA[我有 1300 个整数的十六进制数要放入两个类之一：类 0 和类 1。一个潜在的问题是，在我的训练数据中，98% 属于类 0，因此我将从 &quot; 获得 98% 的准确率“预测函数”总是返回“class 0”与输入无关。
是否有专为此类问题设计的机器学习模型？
================================================== ===============
TLDR？
我的数据如下：
X = 数组([[ 0, 11, 51, 13, 0, 9],
       [51,13,0,9,0,11],
       [ 0, 8, 0, 10, 0, 13],
       ...,
       [ 0, 11, 61, 12, 0, 8],
       [ 0, 8, 0, 0, 60, 11],
       [30, 11, 0, 6, 0, 9]])

目标是 y，一个包含 1300 个 0 和 1 的列表。我使用 MLPClassifier 并获得了 98% 的预测准确率。这时我突然想到，98% 的元组恰好属于 0 类，因此，如果我不费心进行任何机器学习，而是猜测类始终为 0，那么我将获得 98% 的准确率。
我检查了拟合度，看看它在 1 类元组上的表现如何，发现其中 82% 的预测正确，因此准确度为 98% 的 82%，即大约 80%，我想改进，但是怎么办？
除了盲目增加层的大小/数量之外，我不知道如何更改 MLPClassifier 的参数，但我突然想到，我很可能使用完全错误的模型来解决带有 Yes/ 的学习问题没有分类。另外，六元组中的整数不是任意的，我想到这也可能与模型的选择有关。特别是，六个输入中的三个始终在 0 - 15 范围内，另外三个是两位数代码，第一位数字有三种可能，第二位数字有两种可能。
感谢您的任何想法。
代码：
m = MLPClassifier(hidden_​​layer_sizes = (256, 128, 64), max_iter=10000) # 从我在网上找到的示例粘贴:(
_ = m.fit(X, y)
yhat = m.predict(X)
cm = 混淆矩阵(y, yhat)
print( &#39;准确率 = &#39;, np.mean( y == yhat ) )
打印（厘米）

输出：
准确度 = 0.9816653934300993
[[1267 13]
 [11 18]]

(pdb) class1 = [ i for i in range(len(y)) if y[i] == 1]
(pdb) z = m.predict(np.row_stack((X[q] for q in class1)))
(pdb) z
数组([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 , 1, 1, 1, 0, 1])
(pdb) len(z), 总和(z)
29, 24
]]></description>
      <guid>https://stackoverflow.com/questions/77596028/best-machine-learning-model-for-binary-classification</guid>
      <pubDate>Sun, 03 Dec 2023 20:16:04 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML 模型给出的准确度、F1 分数、精确度和召回率均为 1.0，但似乎过度拟合 [关闭]</title>
      <link>https://stackoverflow.com/questions/77595988/my-ml-model-gives-accuracy-f1-score-precision-and-recall-as-1-0-but-it-seems-o</link>
      <description><![CDATA[
我有 Spotify 音乐数据集。
playlist_genre 是目标变量，它有 6 个类别 - 摇滚、拉丁、R&amp;B、说唱、流行、器乐
如果我使用标签编码对目标变量进行编码，那么我得到的准确度和 F1 分数为 1.0
如果我使用 getDummies 或 one-hot 编码，那么我的准确度和 f1 分数将分别降至 0.29 和 0.19。

使用的分类算法：随机森林
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/77595988/my-ml-model-gives-accuracy-f1-score-precision-and-recall-as-1-0-but-it-seems-o</guid>
      <pubDate>Sun, 03 Dec 2023 20:05:31 GMT</pubDate>
    </item>
    <item>
      <title>如何修复我的感知器来识别数字？</title>
      <link>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</guid>
      <pubDate>Sun, 03 Dec 2023 14:03:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 svm 进行高光谱图像分类</title>
      <link>https://stackoverflow.com/questions/77594411/hyperspectral-image-classification-using-svm</link>
      <description><![CDATA[将 pandas 导入为 pd
将 numpy 导入为 np
导入操作系统
从 sklearn.impute 导入 SimpleImputer
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 precision_score
从 imblearn.over_sampling 导入 SMOTE
从 imblearn.under_sampling 导入 RandomUnderSampler



# CSV 文件所在的目录
目录 = &#39;驱动器/我的驱动器/StO2_mat(size513_911)/&#39;

# 初始化空列表来存储数据和文件名
数据数组 = []
文件名 = []

# 循环遍历目录下的所有CSV文件
对于 os.listdir（目录）中的文件名：
    if filename.endswith(&#39;.csv&#39;):
        file_path = os.path.join(目录, 文件名)
        df = pd.read_csv(文件路径)
        data_array = df.values.ravel()
        data_arrays.append(data_array)
        file_names.append(文件名)

# 从一维 NumPy 数组列表创建一个 DataFrame
数据 = pd.DataFrame(data_arrays)

# 添加“目标列”包含原始文件名
数据[&#39;目标列&#39;] = 文件名

# 检查是否有足够的唯一样本用于分割
if len(data[&#39;target_column&#39;].unique()) &lt;= 1:
    print(“没有足够的唯一样本用于训练-测试分割。”)
别的：
    # 分离非数字和数字数据列
    non_numeric_data = data.select_dtypes(&#39;字符串&#39;)
    numeric_data = data.select_dtypes(include=[&#39;number&#39;])

    # 估算数值数据中的缺失值
    imputer = SimpleImputer(策略=&#39;均值&#39;)
    numeric_data_impulated = imputer.fit_transform(numeric_data)
    numeric_data_impulated_df = pd.DataFrame(numeric_data_impulated)

    # 合并非数值数据和估算数值数据
    impulated_data = pd.concat([non_numeric_data, numeric_data_impulated_df], axis=1)

    # 将数据分为训练集和测试集
    X_train, X_test, y_train, y_test = train_test_split(impulated_data.drop(&#39;target_column&#39;, axis=1), impulated_data[&#39;target_column&#39;], test_size=0.1, random_state=42)

   # 将 SMOTE 应用于训练数据
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

    # 使用 RandomForestClassifier （如您的示例中所示）
    clf = RandomForestClassifier(n_estimators=100, random_state=42)
    clf.fit(X_train_resampled, y_train_resampled)

    # 对测试数据进行预测
    y_pred = clf.predict(X_test)

    # 评估模型性能
    准确度=准确度_得分(y_test, y_pred)
    print(&#39;准确度：&#39;, 准确度)

对于此代码，我遇到错误，没有足够独特的样本用于训练测试分割。如何解决这个问题？
我尝试过欠采样、不同的 ckassifiers，如 svm、knn 和随机森林分类器（对数据 imabalance 不太敏感）。仍然无法解决该错误。]]></description>
      <guid>https://stackoverflow.com/questions/77594411/hyperspectral-image-classification-using-svm</guid>
      <pubDate>Sun, 03 Dec 2023 13:04:03 GMT</pubDate>
    </item>
    <item>
      <title>代理收集 10 个产品并返回 12x11 矩阵中的起点时出现问题</title>
      <link>https://stackoverflow.com/questions/77594273/issue-with-agent-collecting-10-products-and-returning-to-starting-point-in-a-12x</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594273/issue-with-agent-collecting-10-products-and-returning-to-starting-point-in-a-12x</guid>
      <pubDate>Sun, 03 Dec 2023 12:24:25 GMT</pubDate>
    </item>
    <item>
      <title>人工智能-儿童人工智能[关闭]</title>
      <link>https://stackoverflow.com/questions/77594032/artificial-intelligence-child-ais</link>
      <description><![CDATA[一个人工智能可以构建另一个人工智能——子人工智能吗？
自动化机器学习
是的，人工智能可以被编程来生成代码或设计另一个人工智能系统。此过程涉及使用自动代码生成、机器学习和神经架构搜索等技术。自动代码生成涉及编写算法或使用模板来创建新程序或模型。机器学习可用于训练模型，该模型可以根据现有代码库中的模式和示例生成代码。
神经架构搜索 (NAS) 是一种特定方法，其中人工智能算法用于探索和发现给定任务的最佳神经网络架构。 NAS 可以自动化神经网络的设计，神经网络是人工智能系统的关键组成部分。
总之，通过采用各种编程和机器学习技术，可以开发一个人工智能来构建另一个人工智能。然而，值得注意的是，虽然人工智能可以协助创建新的人工智能系统，但通常需要人类专业知识来定义正在生成的人工智能的目标、约束和参数，以及评估和完善结果。&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77594032/artificial-intelligence-child-ais</guid>
      <pubDate>Sun, 03 Dec 2023 11:16:35 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：这两个结构没有相同的嵌套结构。加载 roberta 模型时</title>
      <link>https://stackoverflow.com/questions/77593802/valueerror-the-two-structures-dont-have-the-same-nested-structure-while-loadi</link>
      <description><![CDATA[我使用了以下罗伯塔情感模型，并将其微调到我的文本数据。
roberta_model = TFAutoModelForSequenceClassification.from_pretrained(&#39;cardiffnlp/twitter-roberta-base-sentiment&#39;)

tokenizer = AutoTokenizer.from_pretrained(&#39;cardiffnlp/twitter-roberta-base-sentiment&#39;)
tokenized_data = tokenizer(list(df[&#39;text&#39;]), padding=True, return_tensors=&#39;np&#39;)
tokenized_data = dict(tokenized_data)

def get_model(罗伯塔_模型):
  input_ids = 输入（形状=（无，），dtype=&#39;int32&#39;，名称=&#39;input_ids&#39;）
  注意掩码=输入（形状=（无，），dtype=&#39;int32&#39;，名称=&#39;注意掩码&#39;）
  罗伯塔输出=罗伯塔模型（输入ID，注意掩码=注意掩码）[0]
  输出=密集（32，激活=&#39;relu&#39;）（roberta_outputs）
  输出=密集（3，激活=&#39;softmax&#39;）（输出）
  模型= tf.keras.Model（输入= [input_ids，attention_mask]，输出=输出）
  返回模型

模型 = get_model(罗伯塔_模型)
model.compile(优化器=Adam(3e-5)，指标= [&#39;准确性&#39;]，损失=&#39;sparse_categorical_crossentropy&#39;)
历史= model.fit（tokenized_data，y，validation_split = 0.2，epochs = 5）

当我使用以下方式保存模型时：
model.save(&#39;/content/mymodel&#39;)

并使用以下命令重新加载模型：
model = keras.models.load_model(&#39;/content/mymodel&#39;)

它显示此错误：
ValueError：两个结构没有相同的嵌套结构。

我尝试过将其保存为 h5 和 keras 格式。上述问题是当前的问题。有时在它给我一个错误 str object is not callable 之前。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77593802/valueerror-the-two-structures-dont-have-the-same-nested-structure-while-loadi</guid>
      <pubDate>Sun, 03 Dec 2023 10:04:12 GMT</pubDate>
    </item>
    <item>
      <title>对成本函数的绘制方式感到困惑[关闭]</title>
      <link>https://stackoverflow.com/questions/77590637/confused-about-how-a-cost-function-is-graphed</link>
      <description><![CDATA[我目前正在学习梯度下降，但我对成本函数的绘制方式感到困惑。
我理解均方误差平均和的公式，但是如何使用各个点来求导数？
在添加到总和之前是否将每个错误绘制在图表上？网上有很多使用图表来显示找到最小值的解释。]]></description>
      <guid>https://stackoverflow.com/questions/77590637/confused-about-how-a-cost-function-is-graphed</guid>
      <pubDate>Sat, 02 Dec 2023 13:57:43 GMT</pubDate>
    </item>
    <item>
      <title>将 llama_index 与 mac m1 一起使用</title>
      <link>https://stackoverflow.com/questions/75979420/using-llama-index-with-mac-m1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75979420/using-llama-index-with-mac-m1</guid>
      <pubDate>Mon, 10 Apr 2023 17:46:58 GMT</pubDate>
    </item>
    <item>
      <title>如何确定sklearn中MLPClassifier的“损失函数”？</title>
      <link>https://stackoverflow.com/questions/53369866/how-can-i-determine-loss-function-for-mlpclassifier-in-skilearn</link>
      <description><![CDATA[我想使用sklearn的MLPClassifier
mlp = MLPClassifier(hidden_​​layer_sizes=(50,), max_iter=10, alpha=1e-4,
                求解器=&#39;sgd&#39;，详细=10，tol=1e-4，random_state=1，
                Learning_rate_init=.1)

我没有找到损失函数的任何参数，我希望它是mean_squared_error。是否可以根据模型确定它？]]></description>
      <guid>https://stackoverflow.com/questions/53369866/how-can-i-determine-loss-function-for-mlpclassifier-in-skilearn</guid>
      <pubDate>Mon, 19 Nov 2018 07:12:03 GMT</pubDate>
    </item>
    <item>
      <title>NotFittedError：估计器未安装，在利用模型之前调用“fit”</title>
      <link>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</link>
      <description><![CDATA[我在 Macbook OSX 10.2.1 (Sierra) 上运行 Python 3.5.2。
在尝试从 Kaggle 运行泰坦尼克号数据集的一些代码时，我不断收到以下错误：

&lt;块引用&gt;
  &lt;小时/&gt;
  
  NotFittedError Traceback（最近调用
  最后）在（）
        6
        7 # 使用测试集进行预测并打印它们。
  ----&gt; 8 my_prediction = my_tree_one.predict(test_features)
        9 打印（我的预测）
       10 
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
  在预测（自我，X，check_input）中
      第429章
      第430章
  --&gt; 431 X = self._validate_X_predict(X, check_input)
      第432章
      [第 433 章]
  
  /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
  在 _validate_X_predict(self, X, check_input) 中
      第386章
      第387章
  --&gt; 388 raise NotFittedError(&quot;估计器未安装，&quot;
      第389章
      390 
NotFittedError：估计器未安装，请在利用之前调用 fit
  型号。

有问题的代码似乎是这样的：
# 用中位数估算缺失值
test.Fare[152] = test.Fare.median()

# 从测试集中提取特征：Pclass、Sex、Age 和 Fare。
test_features = test[[&quot;Pclass&quot;, &quot;性别&quot;, &quot;年龄&quot;, &quot;票价&quot;]].values

# 使用测试集进行预测并打印它们。
my_prediction = my_tree_one.predict(test_features)
打印（我的预测）

# 创建一个包含两列的数据框：PassengerId &amp;幸存下来了。幸存包含你的预测
PassengerId =np.array(test[&quot;PassengerId&quot;]).astype(int)
my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [&quot;幸存&quot;])
打印（我的解决方案）

# 检查您的数据框是否有 418 个条目
打印（my_solution.shape）

# 将解决方案写入名为 my_solution.csv 的 csv 文件
my_solution.to_csv(&quot;my_solution_one.csv&quot;,index_label = [&quot;PassengerId&quot;])

这里是其余代码的链接。
由于我已经调用了“fit”函数，因此我无法理解此错误消息。我哪里错了？感谢您抽出时间。
编辑：
结果发现问题是从上一个代码块继承而来的。
# 拟合你的第一个决策树：my_tree_one
my_tree_one = 树.DecisionTreeClassifier()
my_tree_one = my_tree_one.fit(features_one, 目标)

# 查看包含的功能的重要性和得分
打印（my_tree_one.feature_importances_）
打印（my_tree_one.score（features_one，目标））

用行：
my_tree_one = my_tree_one.fit(features_one, target)
生成错误：

&lt;块引用&gt;
  ValueError：输入包含 NaN、无穷大或太大的值
  dtype(&#39;float32&#39;)。
]]></description>
      <guid>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</guid>
      <pubDate>Fri, 02 Dec 2016 17:10:22 GMT</pubDate>
    </item>
    </channel>
</rss>