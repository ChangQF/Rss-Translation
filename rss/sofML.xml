<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Sep 2024 12:33:29 GMT</lastBuildDate>
    <item>
      <title>使用机器学习对 CAD 模型进行特征提取[关闭]</title>
      <link>https://stackoverflow.com/questions/79018489/feature-extraction-of-cad-models-using-machine-learning</link>
      <description><![CDATA[我想从 CAD 模型中提取某些特定于对象的特征。CAD 模型以 dxf 文件格式提供，理想情况下应以这种格式进行处理。由于 dxf 文件格式是矢量图形，我的想法是在图形中显示点和连接，其中点代表节点，它们之间的连接是图形的边缘。然后我想训练一个 GCN，以便它可以对节点进行分类。让我们以数字电路图为例：我的模型应该从这样的电路图中提取连接。因此，应该执行节点分类。
因此，该过程应如下所示：
准备用作测试数据的数据（这里我们仍然需要澄清如何准确标记 GCN 的测试数据）。
训练模型并随后在以前未知的图表（尚未见过的 CAD 模型）上对模型进行评估。
也许在此期间出现了一个问题，为什么我坚持使用 dxf 文件格式。原因如下：我不仅希望从我的模型中获得分类（连接与否），还希望获得连接的确切位置。为此，我曾想过可以将位置作为特征集成到节点的特征向量中，然后稍后访问它。
现在我们继续讨论我的问题：

我的想法是否可以实现？我很担心，因为我读到过 GCN 无法访问归纳学习或不是为此设计的。
您对可以采取什么方法来实现这样的努力还有其他想法吗？

我的第一个方法是通过 CNN 进行分类。但由于转换为 png 或 jpeg 导致几何信息丢失，因此不再可能进行精确定位。提取特征的位置是一项主要任务。]]></description>
      <guid>https://stackoverflow.com/questions/79018489/feature-extraction-of-cad-models-using-machine-learning</guid>
      <pubDate>Tue, 24 Sep 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>cuDNN 错误：CUDNN_STATUS_EXECUTION_FAILED</title>
      <link>https://stackoverflow.com/questions/79018072/cudnn-error-cudnn-status-execution-failed</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79018072/cudnn-error-cudnn-status-execution-failed</guid>
      <pubDate>Tue, 24 Sep 2024 10:04:05 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型预测训练标签本身作为结果[关闭]</title>
      <link>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</link>
      <description><![CDATA[我正在尝试根据具有“消息”、“尾巴”和“手指”特征的数据构建一个模型来预测“物种”，并标记“物种”（参见下面 data.csv 的前几行）：



消息
手指
尾巴
物种




pluvia arbor aquos
4
no
Aquari


cosmix xeno nebuz odbitaz
5
是
Zorblax


solarix glixx novum galaxum quasar
5
是
Zorblax


arborsectus pesros ekos dootix nimbus
2
是
Florian



我的代码是：
import warnings
warnings.simplefilter(&quot;ignore&quot;)
import pandas as pd
import numpy as np
将 matplotlib.pyplot 导入为 plt
从 sklearn.preprocessing 导入 LabelEncoder
从 sklearn.feature_extraction.text 导入 CountVectorizer
从 sklearn.naive_bayes 导入 MultinomialNB

df = pd.read_csv(&quot;data.csv&quot;)
X = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
X = [str (item) for item in X]
y = df[&quot;species&quot;]

le = LabelEncoder()
y = le.fit_transform(y)

cv = CountVectorizer()
X = cv.fit_transform(X).toarray()

model = MultinomialNB()
model.fit(X, y)

test_data = pd.read_csv(&#39;test.csv&#39;)
test_data_array = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
test_data_array = [str (item) for item in test_data_array]
test_data_array = cv.fit_transform(test_data_array).toarray()

y_prediction = model.predict(test_data_array)
y_prediction = le.inverse_transform(y_prediction)

print(y_prediction)

我按照本教程进行操作一样。
问题是，当我尝试运行它时，除了一些差异外，它只是逐字逐句地输出原始训练数据的物种列（有 493 个结果，而测试数据包含 299 个条目，训练数据包含 500 个条目）。它实际上并没有为测试数据预测任何内容。我不明白为什么代码不起作用。有人能帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</guid>
      <pubDate>Tue, 24 Sep 2024 04:08:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 smote 将过采样数据存储在单独的变量中？</title>
      <link>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</link>
      <description><![CDATA[应用 Smote 过采样技术后，我只想将新生成的值存储到 X2 和 y2。X2 的独立特征和 y2 的目标变量
import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
dataset = pd.read_csv(&#39;https://archive.ics.uci.edu/static/public/17/data.csv&#39;)
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values
le = LabelEncoder()
y = le.fit_transform(y)
smt = SMOTE()
X1, y1 = smt.fit_resample(X, y)
#在单独的变量中使用 smote 对数据进行过采样
#X2 = ?
#y2 = ?

]]></description>
      <guid>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</guid>
      <pubDate>Tue, 24 Sep 2024 04:07:41 GMT</pubDate>
    </item>
    <item>
      <title>在语言检测中使用数组作为特征时出现 KeyError</title>
      <link>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</link>
      <description><![CDATA[我正在按照此教程使用机器学习进行语言检测。然而，在我使用的数据集中，有多个变量作为特征。我尝试用 X = data[&quot;Text&quot;] 代替 X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]（message、fingers 和 tail 是我正在使用的三个特征变量），但它会抛出 KeyError；
Traceback（最近一次调用最后一次）：
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;，第 3805 行，在 get_loc
return self._engine.get_loc(casted_key)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;index.pyx&quot;，第 167 行，在pandas._libs.index.IndexEngine.get_loc
文件“index.pyx”，第 196 行，位于 pandas._libs.index.IndexEngine.get_loc
文件“pandas\\_libs\\hashtable_class_helper.pxi”，第 7081 行，位于 pandas._libs.hashtable.PyObjectHashTable.get_item
文件“pandas\\_libs\\hashtable_class_helper.pxi”，第 7089 行，位于 pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

上述异常是导致以下异常的直接原因：

回溯（最近一次调用）：
文件&lt;module&gt; 中的 &quot;c:\Users\usr\Downloads\thecode.py&quot;，第 13 行
X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]
~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py&quot;, 第 4102 行, 位于 __getitem__
indexer = self.columns.get_loc(key)
^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;, 第 3812 行, 位于 get_loc
引发 KeyError(key) err
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

我应该如何实现代码才能使用所有功能而不抛出错误？]]></description>
      <guid>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</guid>
      <pubDate>Mon, 23 Sep 2024 22:15:21 GMT</pubDate>
    </item>
    <item>
      <title>通过模型大规模测试预测毒性测定</title>
      <link>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</link>
      <description><![CDATA[我目前正在创建一个模型来预测污染对生物体的毒性测定。由于没有合适的数据集，我还没有尝试任何东西。我只是想问问我的代码是否合适。欢迎提出批评。此外，如果我遗漏了什么或应该包括什么，请告诉我。
此外，我正在考虑更多模型，例如 RandomForestRegressor、Boosting（AdaBoost、GradientBoost）。我应该考虑这些吗？此外，当我最终获得数据时，是否有任何模型我应该从测试中删除？
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv(&#39;&#39;) # 包含数据的 csv 文件（浓度和死亡率）

# 基本图表
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;Mortality&#39;) 

# 训练与测试的基本划分
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=101) 

# 线性模型
from sklearn.linear_model import LinearRegression 
lr_model = LinearRegression()
lr_model.fit(X_train,y_train)
lr_preds = lr_model.predict(X_test)
from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_absolute_error(y_test, lr_preds)
np.sqrt(mean_absolute_error(y_test, lr_preds))
concentration_range = np.arange(0,100) # 根据最小/最大浓度调整
concentration_preds = lr_model.predict(concentration_range.reshape(-1,1))
plt.figure(figsize = (12,6),dpi = 200)
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;信号&#39;)
plt.plot(concentration_range,concentration_preds)

# 多项式模型
# 用于测试模型的函数
def run_model(model, X_train, y_train, X_test, y_test):
# 拟合模型
model.fit(X_train,y_train)

# 获取指标
preds = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test,preds))
mae = mean_absolute_error(y_test, preds)
print(f&#39;MAE: {mae}&#39;)
print(f&#39;RMSE: {rmse}&#39;)

# 绘制结果模型信号范围
density_range = np.arange(0,100) # 再次调整
density_preds = model.predict(concentration_range.reshape(-1,1))

plt.figure(figsize = (12,8), dpi = 200)
sns.scatterplot(x = &#39;Concentration&#39;, y = &#39;Mortality&#39;, data = df, color = &#39;black&#39;)
plt.plot(concentration_range, density_preds)

来自 sklearn.pipeline 导入 make_pipeline
来自 sklearn.preprocessing 导入 PolynomialFeatures

pipe = make_pipeline(PolynomialFeatures(degree = 2),LinearRegression()) # degree 可调整
run_model(pipe, X_train, y_train, X_test, y_test)

# K-Nearest Neighbors 模型
来自 sklearn.neighbors 导入 KNeighborsRegressor
k_values = [1,2,3,4,5,6,7,8,9,10]
for k in k_values:

model = KNeighborsRegressor(n_neighbors=k)
run_model(model, X_train,y_train,X_test, y_test)

# 决策树模型
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor()
run_model(model, X_train, y_train, X_test, y_test)

# SVR 模型
from sklearn.svm import SVR # 支持向量回归
from sklearn.model_selection import GridSearchCV
svr = SVR()
param_grid = {&#39;C&#39;:[0.01,0.1,1,5,10,100,1000],
&#39;gamma&#39;:[&#39;auto&#39;,&#39;scale&#39;]}

grid = GridSearchCV(svr, param_grid)
run_model(grid, X_train,y_train,X_test, y_test)
]]></description>
      <guid>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</guid>
      <pubDate>Mon, 23 Sep 2024 21:25:16 GMT</pubDate>
    </item>
    <item>
      <title>有人知道如何修复库错误吗？</title>
      <link>https://stackoverflow.com/questions/79015388/does-anyone-know-how-to-fix-library-error</link>
      <description><![CDATA[我遇到了这个错误，尝试了所有方法，但还是无法解决：
ModuleNotFoundError Traceback (most recent call last)
&lt;ipython-input-13-6c7180fd4822&gt; in &lt;cell line: 1&gt;()
----&gt; 1 from crewapi_module import CrewAPI # 用正确的导入路径替换
2 
3 crew_api = CrewAPI(api_key=&quot;your_crewai_api_key&quot;)
4 
5 # 现在您可以与 API 交互，例如：

ModuleNotFoundError：没有名为“crewapi_module”的模块
]]></description>
      <guid>https://stackoverflow.com/questions/79015388/does-anyone-know-how-to-fix-library-error</guid>
      <pubDate>Mon, 23 Sep 2024 15:52:13 GMT</pubDate>
    </item>
    <item>
      <title>受不同聚类大小约束的 KMeans</title>
      <link>https://stackoverflow.com/questions/79015120/kmeans-constrained-with-different-cluster-size</link>
      <description><![CDATA[我有一个包含商店坐标的数据框，我想根据供应商应该访问该商店的日期将它们划分为簇。例如，假设供应商应该访问 180 家商店。他应该在周一到周五访问 30-34 家商店，周六，他应该访问其他日子的 60%。
我该怎么做？使用 kmeans-constrained，我只能将它们划分为大小相等的簇。也许我需要使用某种解算器或在集群之间移动点以达到我想要的数字，但我不知道如何做到这一点。
以下是将它们均等划分的代码：
# 循环遍历供应商集群
for vendor in df[&quot;vendor&quot;].unique():

# 每个供应商的商店数量
n_shops = df.loc[df[&quot;vendor&quot;] == vendor][&quot;cod_shop&quot;].count()

# 索引
idx = df.loc[df[&quot;vendor&quot;] == vendor].index

# 一周中各天的集群数量
num_clusters = 5 # 星期一至星期五

# 集群的平均大小
avg_size = n_shops / (num_clusters + 0.6)

# 定义限制
min_shops = round(avg_size - n_shops * pct, 0)
max_shops = math.ceil(avg_size + n_shops * pct)

# 模型
kmeans = KMeansConstrained(n_clusters=num_clusters, size_min=min_shops, size_max=max_shops, random_state=42)
labels = kmeans.fit_predict(df.loc[df[&quot;vendor&quot;] == vendor][[&quot;latitude&quot;, &quot;longitude&quot;]])

# 向数据框添加标签
df.loc[idx, &quot;visit_day&quot;] = labels
]]></description>
      <guid>https://stackoverflow.com/questions/79015120/kmeans-constrained-with-different-cluster-size</guid>
      <pubDate>Mon, 23 Sep 2024 14:42:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 NumPy 实现基本神经网络的问题</title>
      <link>https://stackoverflow.com/questions/79014083/problem-implementing-a-basic-neural-network-with-numpy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79014083/problem-implementing-a-basic-neural-network-with-numpy</guid>
      <pubDate>Mon, 23 Sep 2024 09:49:44 GMT</pubDate>
    </item>
    <item>
      <title>构建 OCR 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/79013996/building-ocr-model</link>
      <description><![CDATA[我正在研究一个机器学习模型，其中输入是图像和实体名称，目标是从图像中提取相应的实体值。例如，如果实体名称是“高度”，并且图像包含门的高度，则模型应提取此值（例如 6 英尺）以及正确的单位。
输入：
图像：包含对象（例如门）和相关信息（例如高度或其他相关测量值）。
实体名称：关键字，例如“高度”或“重量”，指定要从图像中提取的值。
输出：
与图像中的实体相对应的值及其单位（例如“6 英尺”）。
挑战：
实体值可以出现在图像的不同部分，具有不同的文本格式、字体或样式。
需要识别和提取测量单位（例如，米、英尺）以及值。
问题：

处理此类任务的最佳方法或模型架构是什么？
是否有任何特定技术或预训练模型可以帮助将图像和实体名称组合为输入，以从图像中提取相应的值？
我应该如何预处理图像和标签以训练此类任务的模型？
是否有任何关于框架和工具的指导、参考或建议？

我尝试使用带有 CTC 损失的 CNN+RNN，但我的损失接近 20 并且没有进一步减少
这里我附上了我的 google cloab 链接
笔记本链接]]></description>
      <guid>https://stackoverflow.com/questions/79013996/building-ocr-model</guid>
      <pubDate>Mon, 23 Sep 2024 09:27:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 Deepface Deepface.represent 从 ROI 获取嵌入时出错</title>
      <link>https://stackoverflow.com/questions/79013712/error-getting-embeddings-from-a-roi-using-deepface-deepface-represent</link>
      <description><![CDATA[我在使用 Deepface 从 Retinaface 识别的裁剪 ROI 获取嵌入时遇到了问题。
我正尝试使用一些名人的数据集（图像）学习对象识别，并可能考虑将其用于我的个人照片库。我尝试使用 Haar Cascade 进行人脸检测，并使用 Open Cv 中的 LBPHFaceRecognize 进行人脸识别，效果很好。然后我想尝试使用 Retinafce 进行人脸检测并获得 ROI。ROI 存储在列表中，并使用 Deepface 从选定的 ROI 获取嵌入并存储在另一个列表中。我正在尝试将嵌入存储到列表中，但我一直得到
 raise ValueError(
ValueError: 无法在 numpy 数组中检测到人脸。请确认图片

是人脸照片或考虑将 force_detection 参数设置为 False。
虽然所有图像都有一张被清楚检测到的人脸。这是我的代码供参考：
import os
import cv2 as cv
from retinaface import RetinaFace
from deepface import DeepFace
import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

artist = [&#39;50cent&#39;] # type: ignore #MJ the GOAT!! , &#39;Kanye&#39;, &#39;Eminem&#39;, &#39;MichaelJackson&#39;
ROOT_DIR = &#39;asset/Face_Recon_Dataset&#39; #图像数据集的路径
faces_roi =[]
labels = []
embeddings = []
#现在在脸部坐标上画一个矩形
#脸部范围有：
# x1, y1) = (28, 51) #左上角
# (x2, y2) = (61, 98) #右下角
&quot;&quot;&quot; 这定义了检测到的脸部周围的矩形边界框。
- x1 (28)：脸部的左边缘
- y1 (51)：脸部的上边缘
- x2 (61)：脸部的右边缘
- y2 (98)：脸部的下边缘&quot;&quot;&quot;

def get_roi():
for artist_name in artist:
# 获取艺术家姓名的索引
label = artist.index(artist_name)
image_folder = os.path.join(ROOT_DIR,artist_name) # 获取包含图像的实际文件夹
for artist_images in os.listdir(image_folder): # 列出该目录中的所有图像
image = os.path.join(image_folder,artist_images)
resp = RetinaFace.detect_faces(image)
# 确保人脸存在
if isinstance(resp,dict):
img = cv.imread(image)
for face_id, face_data in resp.items():
# print(face_id)
# print(&quot;x1: &quot;, face_data[&#39;facial_area&#39;][0])
# print(&quot;y1: &quot;, face_data[&#39;facial_area&#39;][1])
# print(&quot;x2: &quot;, face_data[&#39;facial_area&#39;][2])
# print(&quot;y2: &quot;, face_data[&#39;facial_area&#39;][3], &quot;\n&quot;)
# 读取图像

# 检测人脸
x1 = face_data[&#39;facial_area&#39;][0]
y1 = face_data[&#39;facial_area&#39;][1]
x2 = face_data[&#39;facial_area&#39;][2]
y2 = face_data[&#39;facial_area&#39;][3]

# 为人脸绘制边界框 
# faces_rect = cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
face_roi = img[y1:y2,x1:x2]

#用其名称标记裁剪后的 roi 人脸
faces_roi.append(face_roi)

labels.append(label)
print(len(faces_roi))
print(len(labels))
print(&quot;已标记和索引的图像&quot;)
print(&quot;正在初始化嵌入过程.....&quot;)
get_embeddings()

def get_embeddings():
&quot;&quot;&quot; 使用 deepface 从每个人脸 roi 中提取嵌入&quot;&quot;&quot;
print(&quot;Satarting embedding: 🚀🚀 &quot;)
for roi in faces_roi:
face_roi_resized = cv.resize(roi, (160, 160)) # 将人脸 ROI 调整为 160x160 像素
embedding = DeepFace.represent(face_roi_resized, model_name=&quot;Facenet&quot;)
print(embedding)
embeddings.append(embedding)
print(&quot;Vectors storage in list..&quot;)

get_roi()

# 是时候使用 svm 分类器测试和训练这个坏家伙了
# 将嵌入和索引标记为 numpy 数组
X = np.array(embeddings) #feature
y = np.array(labels) #label

# 将数据分成训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练 SVM 分类器
svm_model = SVC(kernel=&#39;linear&#39;) # 线性核是嵌入的良好默认值
svm_model.fit(X_train, y_train)

# 评估模型
y_pred = svm_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;SVM 模型准确率：{accuracy * 100:.2f}%&quot;)

为什么即使 ROI 已被裁剪，该错误仍然如此持续，解决此错误的最佳方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79013712/error-getting-embeddings-from-a-roi-using-deepface-deepface-represent</guid>
      <pubDate>Mon, 23 Sep 2024 08:03:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用回归算法而不是分类算法？[关闭]</title>
      <link>https://stackoverflow.com/questions/79013513/why-are-regression-algorithms-used-instead-of-classification-algorithms</link>
      <description><![CDATA[众所周知，在 ML 中，如果依赖特征本质上是连续的，则应用回归模型。但是，如果依赖特征本质上是分类的，则使用分类算法。
正如您在这张图（https://i.sstatic.net/9Q3wfudK.png）中看到的那样，最大值为。大量数据点重复出现，表明它们正在形成类别。
那么，为什么这里使用回归？
这是数据集：（https://drive.google.com/file/d/1vTIiQ0NZKgBI-EfpGzfPKHx1VaAdEYdH/view?usp=sharing）
我和同学、老师讨论了这个问题。他们都说回归是用来预测的，但没人能解释他们是如何得出应该用回归来代替分类的结论的。]]></description>
      <guid>https://stackoverflow.com/questions/79013513/why-are-regression-algorithms-used-instead-of-classification-algorithms</guid>
      <pubDate>Mon, 23 Sep 2024 07:10:30 GMT</pubDate>
    </item>
    <item>
      <title>将音频文件分割成块，跳过小于所需时间长度的块，并预测整个音频文件的情感</title>
      <link>https://stackoverflow.com/questions/76253683/split-an-audio-file-into-chunks-skip-the-chunks-less-than-desired-time-duration</link>
      <description><![CDATA[我正在将音频信号分类为情绪类，并使用 hugginface 的模型，该模型仅接收 8 秒的音频。所以我将音频分成 8 秒的文件。
我已将文件“A”分成 a1、a2、a3、a4、a5、a6、a7、a8
现在我使用该模型对每个音频进行分类，但我需要通过取文件 a1-a8 的预测平均值来找到音频文件“A”的总体类别。
我该怎么做，请帮帮我。
names = []
# 使用 Ridzuan/Audio_Emotion_Classifier(huggingface) 将音频文件的大小调整为 &lt;8 秒，以便进行预测
for file in tqdm(Path(&quot;D:/program/SER_DATA_sample/exg/&quot;).glob(&quot;**/*.wav&quot;)):
name = os.path.basename(file).split(&#39;.&#39;)[0]
names.append(names)
names_df = pd.DataFrame(names)

temp = name
path = []
audio_path = &#39;C:/Users/XTEND/PycharmProjects/DATA_EVAL/RESAMPLE/&#39;
dir_list = os.listdir(audio_path)
# label = os.path.basename(audio_path).split(&#39;_&#39;)[1].split(&#39;.&#39;)[0]

audio = AudioSegment.from_file(file)
length_audio = len(audio)
print(&quot;音频文件长度&quot;, length_audio)

start = 0
# 以毫秒为单位，这将截取 7 秒的音频
Threshold = 7000
end = 0
counter = 0
num_split = length_audio/threshold
print(num_split)

while start &lt; len(audio):
end += 阈值
print(start, end)
file = audio[start:end]
filename = f&#39;RESAMPLE/{counter}{name}.wav&#39;
file.export(filename, format=&quot;wav&quot;)
print(file)
counter += 1
start += 阈值

file_path = &#39;C:/Users/XTEND/PycharmProjects/DATA_EVAL/RESAMPLE/&#39;
# file_path = &#39;D:/program/XTEND_AUDIO_DATASET/ps/&#39;
dir_list = os.listdir(file_path)
number_files = len(dir_list)
print(number_files)

emo_df = []
routes = []
count = 1

for i in dir_list:
audio_data = file_path + i
routes.append(audio_data)
audio_path_df = pd.DataFrame(paths, columns=[&#39;Path&#39;])
count += 1
print(count, audio_data)

data_ori, sample_rate = librosa.load(audio_data)
data, _ = librosa.effects.trim(data_ori)

test = prepare_test(audio_data)
pred = classifier.predict(test)
pred_df = pd.DataFrame(pred.T, index=[&#39;anger&#39;, &#39;happiness&#39;, &#39;neutral&#39;, &#39;sadness&#39;, &#39;surprised&#39;],
columns=[&#39;Scores&#39;])
print(pred_df)
emo = pred_df[pred_df[&#39;Scores&#39;] == pred_df.max().values[0]].index[0]
print(emo)
emo_df.append(emo)
]]></description>
      <guid>https://stackoverflow.com/questions/76253683/split-an-audio-file-into-chunks-skip-the-chunks-less-than-desired-time-duration</guid>
      <pubDate>Mon, 15 May 2023 11:40:33 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将 Google Colab 代码转换为 Web 服务或 REST API</title>
      <link>https://stackoverflow.com/questions/60443948/is-there-a-way-to-turn-google-colab-code-into-web-services-or-rest-apis</link>
      <description><![CDATA[我有一个机器学习模块，它使用 Google Colab 的免费 G​​PU 执行 NLP 任务，我想用它制作一个 Web 应用程序。我一直在考虑使用 React js 作为前端，使用 spring boot 作为后端，想知道是否有办法将 Google Colab 的代码与后端连接起来。
想知道在 Colab 中构建包含 ML 模块的 Web 应用程序的其他替代建议。任何形式的帮助都值得赞赏。]]></description>
      <guid>https://stackoverflow.com/questions/60443948/is-there-a-way-to-turn-google-colab-code-into-web-services-or-rest-apis</guid>
      <pubDate>Fri, 28 Feb 2020 01:10:30 GMT</pubDate>
    </item>
    <item>
      <title>面临 ValueError：目标是多类但平均值='二进制'</title>
      <link>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</link>
      <description><![CDATA[我正在尝试对我的数据集使用朴素贝叶斯算法。我能够找出准确率，但试图找出相同的精确度和召回率。但是，它抛出了以下错误：
ValueError：目标是多类，但平均值=&#39;binary&#39;。请选择其他平均设置。

有人可以建议我如何继续吗？我尝试在精确度和召回率分数中使用average =&#39;micro&#39;。它没有任何错误，但它给出了相同的准确度、精确度和召回率分数。
我的数据集：
train_data.csv：
review,label
颜色和清晰度极佳，正面
可惜图片不如我的 40 英寸三星清晰明亮，负面

test_data.csv：
review,label
图片清晰漂亮，正面
图片不清晰，负面

我的代码：
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confused_matrix

X_train, y_train = pd.read_csv(&#39;train_data.csv&#39;)
X_test, y_test = pd.read_csv(&#39;test_data.csv&#39;)

vec = CountVectorizer() 
X_train_transformed = vec.fit_transform(X_train) 
X_test_transformed = vec.transform(X_test)

clf = MultinomialNB()
clf.fit(X_train_transformed, y_train)

score = clf.score(X_test_transformed, y_test)

y_pred = clf.predict(X_test_transformed)
cm = confused_matrix(y_test, y_pred)

precision = precision_score(y_test, y_pred, pos_label=&#39;positive&#39;)
recall = recall_score(y_test, y_pred, pos_label=&#39;positive&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</guid>
      <pubDate>Tue, 11 Sep 2018 05:28:04 GMT</pubDate>
    </item>
    </channel>
</rss>