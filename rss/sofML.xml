<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 26 Oct 2024 09:16:24 GMT</lastBuildDate>
    <item>
      <title>为什么这个简单的（Keras）机器学习代码给出了错误的答案？</title>
      <link>https://stackoverflow.com/questions/79127884/why-does-this-simple-keras-machine-learning-code-give-the-wrong-answer</link>
      <description><![CDATA[我正在尝试学习一些时间序列神经网络 ML，但得到的解有些奇怪，因此我尝试对我能想到的最简单的非平凡情况进行建模，即预测 n+1 为序列 0,1,2,3,...n 中的下一个数字（使用 LSTM 模型）。
每个数据点的训练数据是一系列紧接在前的数字，我假设只要每个训练集的数据长度 &gt;= 2（因为它是一个算术序列），它就应该很容易解决模型。
无论训练系列的大小如何，下面的代码都会为所有测试数据返回一个常数。有人能解释一下我做错了什么吗？
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math

import statistics

dim = 5

data = pd.Series(range(0,200))

# 设置 80% 的数据用于训练
training_data_len = math.ceil(len(data) * .8)

# 规范化数据
train_data = data[:training_data_len]

# 拆分数据集
train_data = data[:training_data_len]
test_data = data[training_data_len:]
print(train_data.shape, test_data.shape)

# 选择值
dataset_train = train_data.values 
# 将 1D 重塑为 2D 数组
dataset_train = np.reshape(dataset_train, (-1,1))

# 选择值
dataset_test = test_data.values
# 将 1D 数组重塑为 2D 数组
dataset_test = np.reshape(dataset_test, (-1,1)) 

X_train = []
y_train = []
for i in range(dim, len(dataset_train)):
X_train.append(dataset_train[i-dim:i, 0])
y_train.append(dataset_train[i, 0])

X_test = []
y_test = []
for i in range(dim, len(dataset_test)):
X_test.append(dataset_test[i-dim:i, 0])
y_test.append(dataset_test[i, 0])

# 将数据转换为 Numpy 数组
X_train, y_train = np.array(X_train), np.array(y_train)

#重塑
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))
y_train = np.reshape(y_train, (y_train.shape[0],1))
print(&quot;X_train :&quot;,X_train.shape,&quot;y_train :&quot;,y_train.shape)

# 将数据转换为 numpy 数组
X_test, y_test = np.array(X_test), np.array(y_test)

#重塑
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))
y_test = np.reshape(y_test, (y_test.shape[0],1))
print(&quot;X_test :&quot;,X_test.shape,&quot;y_test :&quot;,y_test.shape)

# 导入库
从 keras.models 导入 Sequential
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dense
从 keras.layers 导入 SimpleRNN
从 keras.layers 导入 Dropout
从 keras.layers 导入 GRU, Bidirectional
从 keras.optimizers 导入 SGD
从 sklearn 导入 metrics
从 sklearn.metrics 导入 mean_squared_error

# 初始化模型
regressorLSTM = Sequential()

# 添加 LSTM 层
regressorLSTM.add(LSTM(dim, 
return_sequences = True, 
input_shape = (X_train.shape[1],1)))
regressorLSTM.add(LSTM(dim, 
return_sequences = False))

#添加输出层
regressorLSTM.add(Dense(1))

#编译模型
regressorLSTM.compile(optimizer = &#39;adam&#39;,
loss = &#39;mean_squared_error&#39;,
metrics = [&quot;accuracy&quot;])

#拟合模型
regressorLSTM.fit(X_train, 
y_train, 
batch_size = 1, 
epochs = 4)
regressorLSTM.summary()

# 使用 X_test 数据的预测
y_LSTM = regressorLSTM.predict(X_test)

#绘制 LSTM 预测图
plt.plot(train_data.index[dim:], train_data[dim:], label = &quot;train_data&quot;, color = &quot;b&quot;)
plt.plot(test_data.index, test_data, label = &quot;test_data&quot;, color = &quot;g&quot;)
plt.plot(test_data.index[dim:], y_LSTM, label = &quot;y_LSTM&quot;, color = &quot;orange&quot;)
plt.legend()
plt.xlabel(&quot;X&quot;)
plt.ylabel(&quot;Y&quot;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79127884/why-does-this-simple-keras-machine-learning-code-give-the-wrong-answer</guid>
      <pubDate>Sat, 26 Oct 2024 05:28:55 GMT</pubDate>
    </item>
    <item>
      <title>我需要从图像中提取每个数字</title>
      <link>https://stackoverflow.com/questions/79127410/i-need-to-extract-each-of-the-numbers-from-the-image</link>
      <description><![CDATA[我正在做图像分割，其中有不同类型的数字图像，如下所示。我能够对 MNIST 合并图像执行图像分割，但该方法不适用于带有水平线的图像。在任何类型的方向和图像噪声中，分别分割每个数字的最佳方法是什么？


我正在使用此代码分割图像中的每个数字，尤其是从数字写在水平线之间的噪声图像中
import os
import cv2
import matplotlib.pyplot as plt

# 加载图像
# image_path = &#39;/mnt/data/013.png&#39;
image_path = &#39;/content/drive/My Drive/demo/captcha/samples/010.png&#39;
image = cv2.imread(image_path)

# 转换为灰度
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# 应用高斯模糊以减少噪音
blurred = cv2.GaussianBlur(gray, (5, 5), 0)

# 应用二元阈值
_, binary_image = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

# 在阈值图像中查找轮廓
contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 创建原始图像的副本以绘制轮廓
output_image = image.copy()

# 按大小过滤轮廓（以去除噪音）
digit_contours = [c for c in contours if cv2.contourArea(c) &gt; 50]

# 绘制轮廓（可选可视化）
cv2.drawContours(output_image, digit_contours, -1, (0, 255, 0), 2)

# 创建一个列表来存储单个数字图像
digit_images = []

# 从原始图像中提取每个数字
for i, contour in enumerate(digit_contours):
x, y, w, h = cv2.boundingRect(contour)
digit = gray[y:y+h, x:x+w]
digit_images.append(digit)
# 使用子图单独显示每个数字
plt.subplot(1, len(digit_contours), i + 1) # 为每个数字创建子图
plt.imshow(digit, cmap=&#39;gray&#39;) # 以灰度显示当前数字
plt.axis(&#39;off&#39;) # 关闭轴标签

# 可选将每个数字保存为单独的图像
cv2.imwrite(f&quot;digit_{x}.png&quot;, digit)

# 显示带有单独数字显示的结果
plt.figure(figsize=(10, 6))
plt.imshow(output_image)
plt.title(&quot;Extracted Digits&quot;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79127410/i-need-to-extract-each-of-the-numbers-from-the-image</guid>
      <pubDate>Fri, 25 Oct 2024 21:50:45 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的损失太多[关闭]</title>
      <link>https://stackoverflow.com/questions/79126726/too-much-loss-in-machine-learning</link>
      <description><![CDATA[我正在训练一个预测加密货币价格的神经网络，但数据丢失太大，代码如下：
import numpy as np
import tensorflow as tf
from tensorflow.keras import layer, models,Sequential,Model,Input
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import *
import matplotlib.pyplot as plt
import ccxt
import pandas as pd
import request
import json
import datetime as dt
import time

# Определение входов
input1 = Input(shape=(100, 1))
input2 = Input(shape=(100, 1))

# 用 LSTM 构建机器学习模型已保存
lstm1 = layer.LSTM(units=256, return_sequences=True,activation=&#39;sigmoid&#39;)(input1)
lstm1 = layer.LSTM(units=128, return_sequences=True,activation=&#39;tanh&#39;)(lstm1)
lstm1 = layer.LSTM(units=64,activation=&#39;linear&#39;)(lstm1)
lstm1 = layer.Dropout(0.2)(lstm1)

lstm2 = layer.LSTM(units=256, return_sequences=True,activation=&#39;sigmoid&#39;)(input2)
lstm2 = layer.LSTM(units=128, return_sequences=True,activation=&#39;tanh&#39;)(lstm2)
lstm2 = layer.LSTM(units=64,激活 = &#39;线性&#39;）（lstm2）lstm2 = groups.Dropout（0.2）（lstm2）＃ Объединяем все LSTM выходы merged = groups.concatenate（[lstm1, lstm2]）＃Добавляем Dense слой для объединенного вы хода 输出 = 层.Dense(100, 激活=&#39;线性&#39;)(合并) # Создание и компиляция модели 模型 = 模型(输入=[输入1, 输入2], 输出=输出) 优化器 = Adam(learning_rate=0.000005) model.compile(loss=&#39;mse&#39;, 优化器=优化器) df = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/btcdata15m.csv&quot;, sep =&quot;\t&quot;)

list_of_close = df[&#39;Open&#39;].to_list()
print(len(list_of_close))

df1 = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/btcoi15m.csv&quot;, sep =&quot;\t&quot;)
list_of_oi = df1[&#39;openInterest&#39;].to_list()
print(len(list_of_oi))

df3 = pd.read_csv(&quot;/content/drive/MyDrive/traiding_bot/futures_nn_pred/y.csv&quot;, sep =&quot;\t&quot;)
y = df3[&#39;Close&#39;].to_list()
print(len(y))
x1 = np.array(list_of_close).reshape(100,100)
x2 = np.array(list_of_oi).reshape(100,100)

min_max_scaler = MinMaxScaler()
x1 = min_max_scaler.fit_transform(x1)
x2 = min_max_scaler.fit_transform(x2)

x1 = x1.astype(float)
x2 = x2.astype(float)

y = np.array(y).reshape(100,100).astype(float)

# 改进模型
history = model.fit([x1,x2], y,batch_size=64, epochs=100)

上次亏损为：3848644352.0000
我的数据集包含 10,000 个收盘蜡烛和 10,000 个未平仓合约值
我如何才能将损失降到最低？]]></description>
      <guid>https://stackoverflow.com/questions/79126726/too-much-loss-in-machine-learning</guid>
      <pubDate>Fri, 25 Oct 2024 17:19:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么 train_batch*.jpg 中缺少一些边界框/标签？这些图像是由 YOLOv7 在训练时自动生成的</title>
      <link>https://stackoverflow.com/questions/79126416/why-are-some-bounding-boxes-labels-missing-in-train-batch-jpg-these-images-a</link>
      <description><![CDATA[我正在自定义数据集上训练 YOLOv7 模型。虽然我的召回率超过 0.9，但精度低于 0.1。为了调查这个问题，我检查了训练脚本生成的 train_batch*.jpg 拼贴画，发现有些图像包含没有任何相关标签或边界框的对象。
我尝试解析图像和标签列表。所有图像都有一个带有适当注释的相应 txt 文件。
这是正常现象吗？如果不是，如何解决这个问题？
https://github.com/WongKinYiu/yolov7/]]></description>
      <guid>https://stackoverflow.com/questions/79126416/why-are-some-bounding-boxes-labels-missing-in-train-batch-jpg-these-images-a</guid>
      <pubDate>Fri, 25 Oct 2024 15:48:34 GMT</pubDate>
    </item>
    <item>
      <title>有没有快速的方法可以提高物体检测模型的置信度？[关闭]</title>
      <link>https://stackoverflow.com/questions/79126036/is-there-a-fast-way-to-raise-the-confidence-levels-of-an-object-detection-model</link>
      <description><![CDATA[我目前正在构建一个对象检测模型，用于识别冰箱图片中的食品成分。我使用 Google Colab 来编码和训练我的模型，并使用 RESNET-50 的架构。我删除了现有的类别，并使用 Google Colab 最好的 GPU 在包含约 6,000 张图像（已注释，70% 为训练，15% 为有效，15% 为测试）的数据集上对其进行训练。训练后，我的模型似乎仍然没有学到任何东西。取得如此糟糕的结果是否正常，或者是否有方法可以更快地进行训练并获得更好的结果？我听说过 Google Cloud，但我不知道它是否会有所作为。我是否遗漏了一些隐藏参数？
这是我编写所有内容的 Google-Colab Notebook：https://colab.research.google.com/drive/1m4zbNE8-qVUkep-37Mz2S3URvELdGWX6?usp=sharing
为了训练我的模型，我使用了 pytorch_lightning 的 Trainer。然而，训练需要很长时间，即使经过 30 个时期的训练，当预测正确时（通常情况并非如此），未见数据的置信度仍然低于 5%。
编辑：目前，我正在使用一个新的、更定性的数据集，其中包含 20k 张图像，分为 68 个类别。我没有对模型进行足够的测试，因为我发现预测太低了，如果你看看笔记本，你会发现我必须设置 CONFIDENCE_THRESHOLD_2 = 0.03 才能获得任何结果，但我认为这是由于训练不足造成的。]]></description>
      <guid>https://stackoverflow.com/questions/79126036/is-there-a-fast-way-to-raise-the-confidence-levels-of-an-object-detection-model</guid>
      <pubDate>Fri, 25 Oct 2024 14:02:24 GMT</pubDate>
    </item>
    <item>
      <title>在 Accord.NET 中使用隔离森林进行异常检测的问题：缺少命名空间</title>
      <link>https://stackoverflow.com/questions/79125178/issue-with-using-isolation-forest-for-anomaly-detection-in-accord-net-missing-n</link>
      <description><![CDATA[在此处输入图片描述
我尝试使用 Accord.NET 库（特别是使用 Isolation Forest 算法）在我的 C# 应用程序中实现异常检测。但是，我遇到一个错误，指示 Accord.MachineLearning.AnomalyDetection 命名空间不存在。
\&lt;PackageReference Include=&quot;Accord.MachineLearning&quot; Version=&quot;3.8.0&quot; /\&gt;

\&lt;PackageReference Include=&quot;Accord.Math&quot; Version=&quot;3.8.0&quot; /\&gt;

\&lt;PackageReference Include=&quot;Accord.Statistics&quot; Version=&quot;3.8.0&quot; /\&gt;

\&lt;PackageReference Include=&quot;CsvHelper&quot; Version=&quot;33.0.1&quot; /\&gt;

CS0234：类型或命名空间名称“AnomalyDetection”在命名空间“Accord.MachineLearning”中不存在（您是否缺少程序集引用？）

using CsvHelper;
using Microsoft.AspNetCore.Http;
using Microsoft.AspNetCore.Mvc;
using System.Collections.Generic;
using System.Globalization;
using System.IO;
using System.Linq;
using CVAnomalyDetection.Models;

public class HomeController : Controller
{
private List&lt;CsvData&gt; _csvData;

public IActionResult Index()
{
return View();
}

[HttpPost]
public IActionResult Upload(IFormFile file)
{
if (file != null &amp;&amp; file.Length &gt; 0)
{
using (var reader = new StreamReader(file.OpenReadStream()))
using (var csv = new CsvReader(reader, CultureInfo.InvariantCulture))
{
_csvData = csv.GetRecords&lt;CsvData&gt;().ToList();
}
return View(&quot;Index&quot;, _csvData);
}
return RedirectToAction(&quot;Index&quot;);
}

[HttpPost]
public IActionResult Predict()
{
var anomalies = DetectAnomalies(_csvData);
return View(&quot;AnomalyResults&quot;, anomalies);
}

private List&lt;CsvData&gt; DetectAnomalies(List&lt;CsvData&gt; data)
{
// 独热编码分类列
var uniqueValuesProductCategory = data.Select(x =&gt; x.ProductCategory).Distinct().ToList();
var uniqueValuesCustomerRegion = data.Select(x =&gt; x.CustomerRegion).Distinct().ToList();
var uniqueValuesPaymentMethod = data.Select(x =&gt; x.PaymentMethod).Distinct().ToList();

// 创建用于异常检测的输入数据数组
var combinedData = new List&lt;double[]&gt;();

foreach (var item in data)
{
var features = new List&lt;double&gt;();

// ProductCategory 的独热编码
foreach (var value in uniqueValuesProductCategory)
{
features.Add(value == item.ProductCategory ? 1.0 : 0.0);
}

// CustomerRegion 的独热编码
foreach (var value in uniqueValuesCustomerRegion)
{
features.Add(value == item.CustomerRegion ? 1.0 : 0.0);
}

// PaymentMethod 的独热编码
foreach (var value in uniqueValuesPaymentMethod)
{
features.Add(value == item.PaymentMethod ? 1.0 : 0.0);
}

combinedData.Add(features.ToArray());
}

// 初始化隔离森林
varisolationForest = new Accord.MachineLearning.IsolationForest()
{
NumberOfTrees = 100,
Contamination = 0.05 // 根据需要进行调整
};

// 使用组合数据训练隔离森林模型
isolationForest.Learn(combinedData.ToArray());

// 预测异常
var predictions =isolationForest.Decide(combinedData.ToArray());

// 查找并返回实际的异常记录
return data.Where((d, index) =&gt; predictions[index] == -1).ToList(); // -1 表示异常
}

private double EuclideanDistance(double[] a, double[] b)
{
return Math.Sqrt(a.Zip(b, (x, y) =&gt; Math.Pow(x - y, 2)).Sum());
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79125178/issue-with-using-isolation-forest-for-anomaly-detection-in-accord-net-missing-n</guid>
      <pubDate>Fri, 25 Oct 2024 10:02:00 GMT</pubDate>
    </item>
    <item>
      <title>我是否需要使用具有混合值的 kprototype 聚类来缩放数据？[关闭]</title>
      <link>https://stackoverflow.com/questions/79124536/do-i-need-to-scale-the-data-with-kprototype-clustering-with-mixed-value</link>
      <description><![CDATA[我想使用 kmodes.kprototypes 中的 kprototype 对一些混合数据进行聚类。因此，有些是数值数据，有些是分类数据。我需要缩放数据吗？如果是，我是否只需要缩放数值数据？
我不熟悉 kprototype 的实现，我想对一些混合数据进行聚类。缩放能给我带来更好的结果吗？]]></description>
      <guid>https://stackoverflow.com/questions/79124536/do-i-need-to-scale-the-data-with-kprototype-clustering-with-mixed-value</guid>
      <pubDate>Fri, 25 Oct 2024 06:48:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MIRNet 模型保存和重用低光增强功能？[关闭]</title>
      <link>https://stackoverflow.com/questions/79124119/how-to-save-and-reuse-low-light-enhancement-using-mirnet-model</link>
      <description><![CDATA[我最近在 Keras 上发现了一个关于图像增强的有趣教程。代码没问题，我运行没有任何错误，但我不知道如何保存模型并重新使用它。
我试了很多次，但无法保存模型。有人能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/79124119/how-to-save-and-reuse-low-light-enhancement-using-mirnet-model</guid>
      <pubDate>Fri, 25 Oct 2024 02:48:27 GMT</pubDate>
    </item>
    <item>
      <title>训练 AI 模型以纠正多边形坐标中的错误的最佳方法 [关闭]</title>
      <link>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</link>
      <description><![CDATA[我需要选择一个最适合训练的 AI 模型和一个 Python 库。我有来自 djangorestframework-gis 库的以 Multipolygon 字段表示的坐标，它们在不同范围内存在小误差 - 大约 0.75 到 1 米。此外，我有相同地块的正确坐标。该模型需要学习找到正确数据和错误数据之间的差异，并在此基础上找到一种算法来确定错误，以便将来纠正错误坐标。]]></description>
      <guid>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</guid>
      <pubDate>Thu, 24 Oct 2024 19:14:14 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 混合预测和预测</title>
      <link>https://stackoverflow.com/questions/79122079/ml-net-mix-forecast-and-predict</link>
      <description><![CDATA[我正在制作一个简单的应用程序来检测 .NET 中的网络异常
应用程序正在收集原始数据包，然后对其进行分析并确定是否发生了潜在攻击（使用静态算法）。目前，我已经实现了基于 TCP 数据包中的 SYN 和 ACK 标志来检测 TCP 洪水攻击的算法。除了分析之外，应用程序还在指定模式中将数据保存在文件中：
SOURCE_IP | DESTINATION_IP | TIMESTAMP (TIMEVAL) | SYN | ACK
10.0.0.5 | 10.0.0.10 | 1726332243,275925 | 1 | 1

我想实现 ML 模型（使用 ML.NET），根据当前“会话”中已经收集的数据预测是否发生攻击。
我尝试添加另一列“IsAttack”，这是我的标签。之后，我模拟了 tcp 洪水攻击，并通过完成最后一列来准备训练数据。但 ml 模型还包括当前会话中所有为“0”的先前标签，因此它无法正常工作。另一方面，当我尝试预测场景时，ML 仅从单行获取数据。有什么想法可以混合预测和预测吗？或者任何其他解决方案？
生成的 ML 模型：
public partial class TCPFloodMLDetector
{
/// &lt;summary&gt;
/// TCPFloodMLDetector 的模型输入类。
/// &lt;/summary&gt;
#region 模型输入类
public class ModelInput
{
[LoadColumn(0)]
public string SourceAddress { get; set; }

[LoadColumn(1)]
public string DestinationAddress { get; set; }

[LoadColumn(2)]
public double Timeval { get; set; }

[LoadColumn(3)]
public bool SYN { get; set; }

[LoadColumn(4)]
public bool ACK { get; set; }

[LoadColumn(5)]
[ColumnName(@&quot;col5&quot;)]
public Single IsAttack { get; set; }
}

#endregion

/// &lt;summary&gt;
/// TCPFloodMLDetector 的模型输出类。
/// &lt;/summary&gt;
#region 模型输出类
public class ModelOutput
{
[ColumnName(@&quot;col5&quot;)]
public float[] Col5 { get; set; }

[ColumnName(@&quot;col5_LB&quot;)]
public float[] Col5_LB { get; set; }

[ColumnName(@&quot;col5_UB&quot;)]
public float[] Col5_UB { get; set; }

}

#endregion

private static string MLNetModelPath = Path.GetFullPath(@&quot;D:\Projects\NetworkAnalyzer\\Models\TCPFloodMLDetector.mlnet&quot;);

public static readonly Lazy&lt;TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt;&gt; PredictEngine = new Lazy&lt;TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt;&gt;(() =&gt; CreatePredictEngine(), true);

/// &lt;summary&gt;
/// 使用此方法对 &lt;see cref=&quot;ModelInput&quot;/&gt; 进行预测。
/// &lt;/summary&gt;
/// &lt;param name=&quot;input&quot;&gt;model input。&lt;/param&gt;
/// &lt;returns&gt;&lt;seealso cref=&quot; ModelOutput&quot;/&gt;&lt;/returns&gt;
public static ModelOutput Predict(ModelInput? input = null, int? horizo​​n = null)
{
var predEngine = PredictEngine.Value;
return predEngine.Predict(input, horizo​​n);
}

private static TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt; CreatePredictEngine()
{
var mlContext = new MLContext();
ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var schema);
return mlModel.CreateTimeSeriesEngine&lt;ModelInput, ModelOutput&gt;(mlContext);
}
}

我在每秒运行的 Detect 函数中使用它：
public async Task Detect()
{
try
{
var context = new MLContext();
var data = context.Data.LoadFromTextFile&lt;TCPFloodInputModel&gt;(&quot;tcpflood.txt&quot;,
hasHeader: false, SeparatorChar: &#39;|&#39;);

TCPFloodMLDetector.LoadIDataViewFromFile(context, &quot;tcpflood.txt&quot;,
&#39;|&#39;, false, true);

// 使用默认选项进行预测。
var modelOutput = TCPFloodMLDetector.Predict();
Console.WriteLine(string.Join(&quot;,&quot;, modelOutput.Col5));

// 预测接下来的 5 个周期
modelOutput = TCPFloodMLDetector.Predict(horizo​​n: 5);
Console.WriteLine(string.Join(&quot;,&quot;, modelOutput.Col5));
}
catch (Exception ex)
{

}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79122079/ml-net-mix-forecast-and-predict</guid>
      <pubDate>Thu, 24 Oct 2024 13:12:42 GMT</pubDate>
    </item>
    <item>
      <title>基于文本描述的聚类[关闭]</title>
      <link>https://stackoverflow.com/questions/79112237/clustering-based-on-text-descriptions</link>
      <description><![CDATA[我为一家在线电子商务托管网站工作，最近我被要求标记一个数据库，该数据库包含 1000 多万条企业提供的服务。每条条目都有许多数据点，但最重要的是以下字段：
ServiceName：企业主为服务设置的简短名称（例如，“15 分钟儿童理发”）
ServiceDescription：企业主编写的服务详细描述（例如，“这是专为儿童提供的理发服务”）
Price：服务费用（例如，“30 美元”）
此标记任务的主要目标是帮助检测潜在欺诈行为。例如，如果有人报告理发价格为 1000 美元，则会引起警觉，因为我们标记的数据中理发的平均价格约为 60 美元，标准差为 10 美元。
背景环境
我唯一的参考是企业自行报告其业务类型（例如，“美发沙龙”）。我的一位同事使用关键字和预定义的常见销售商品列表成功地对这些数据的一小部分进行了分类。但是，我无法访问这样的列表或有关如何进行的明确指南。
如何在没有预定义标签的情况下有效地标记这个大型数据集？
是否有任何技术或工具可以帮助我根据描述和服务名称对这些服务进行分类？
我使用 chatgpt 将服务标记为类别取得了一些成功，但我认为这对于如此大的数据集来说不是一个可行的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/79112237/clustering-based-on-text-descriptions</guid>
      <pubDate>Tue, 22 Oct 2024 02:14:38 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 异常：TreeExplainer 中的可加性检查失败</title>
      <link>https://stackoverflow.com/questions/68233466/shap-exception-additivity-check-failed-in-treeexplainer</link>
      <description><![CDATA[我试图为局部解释创建单行的 shap 值，但一直出现此错误。我尝试了各种方法，但仍然无法修复它们。
我到目前为止所做的事情 -
创建了随机决策树模型 -
from sklearn.ensemble import ExtraTreesRegressor
extra_tree = ExtraTreesRegressor(random_state=42)
extra_tree.fit(X_train, y_train)

然后尝试计算 shap 值 -
# 创建解释器对象
explainer = shap.Explainer(extra_tree) 
explainer.expected_value
array([15981.25812347])

#计算单行的 shap 值
shap_values = explainer.shap_values(pd.DataFrame(X_train.iloc[9274]).T)

这给了我这个错误 -
异常：TreeExplainer 中的可加性检查失败！请确保传递给解释器的数据矩阵与模型训练时的形状相同。如果您的数据形状正确，请在 GitHub 上报告此问题。考虑使用 feature_perturbation=&#39;interventional&#39; 选项重试。此检查失败，因为对于其中一个样本，SHAP 值的总和为 25687017588058.968750，而模型输出为 106205.580000。如果这个差异是可以接受的，您可以设置 check_additivity=False 以禁用此检查。

我传递的训练形状和单行具有相同的列数
X_train.shape
(421570, 164)
(pd.DataFrame(X_train.iloc[9274]).T).shape
(1, 164)

我不认为这会引起任何问题。但为了确保万无一失，我还尝试使用重塑方法带来正确的形状。
shap_values = explainer.shap_values(X_train.iloc[9274].values.reshape(1, -1))

X_train.iloc[9274].values.reshape(1, -1).shape
(1, 164)

这也不能解决问题。所以，我想也许我还需要匹配行数。所以我创建了一个小数据框并尝试测试它。
train = pd.concat([X_train, y_train], axis=&quot;columns&quot;)
train_small = train.sample(n=500, random_state=42)
X_train_small = train_small.drop(&quot;Weekly_Sales&quot;, axis=1).copy()
y_train_small = train_small[&quot;Weekly_Sales&quot;].copy()

# 训练随机决策树模型
from sklearn.ensemble import ExtraTreesRegressor
extra_tree_small = ExtraTreesRegressor(random_state=42)
extra_tree_small.fit(X_train_small, y_train_small)

# 创建解释器对象
explainer = shap.Explainer(extra_tree_small)
shap_values = explainer.shap_values(X_train_small)

# 我也尝试过像这样添加 y 值 
shap_values = explainer.shap_values(X_train_small, y_train_small)

但什么都没起作用。
GitHub 上的一个人建议卸载并重新安装
shap 在 GitHub 上的最新版本：
pip install git+https://github.com/slundberg/shap.git

也试过了，还是不行。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/68233466/shap-exception-additivity-check-failed-in-treeexplainer</guid>
      <pubDate>Sat, 03 Jul 2021 05:21:02 GMT</pubDate>
    </item>
    <item>
      <title>批量标准化是否适用于小批量？</title>
      <link>https://stackoverflow.com/questions/56859748/does-batch-normalisation-work-with-a-small-batch-size</link>
      <description><![CDATA[我使用批量标准化，批量大小为 10 来进行人脸检测。
批量标准化是否适用于如此小的批量大小？如果不行，那么我还能使用什么来进行标准化？]]></description>
      <guid>https://stackoverflow.com/questions/56859748/does-batch-normalisation-work-with-a-small-batch-size</guid>
      <pubDate>Tue, 02 Jul 2019 20:38:25 GMT</pubDate>
    </item>
    <item>
      <title>ALS 算法 Spark MLlib - 如何获得我自己的“个人推荐”（我尚未排名的电影排名）</title>
      <link>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</link>
      <description><![CDATA[我在 Azure Databricks 中使用 PySpark。我使用 Sparks MLlib 库 ALS 算法来预测电影评分，效果很好。但是，我尝试添加一个数据框，其中包含我对 10 部随机选择的电影的评分。当我这样做时，我只能获得我已经排名的电影的预测排名。 
我希望能够使用该模型根据他们的排名获得推荐。
我有执行以下任务的 Spark 代码：

导入数据（RatingsSmall、MoviesSmall、RatingsLarge、Movies Large）
将 Ratings small 与 Movies Small 合并，将 Ratings Large 与 Movies Large 合并
将两个新数据集附加在一起
删除不相关的列 Timestamp 和 Genre

我现在有一个干净的表，其中包含 MovieID、Title（电影名称）、UserID 和 Ranking。我将从此处展示代码。如果您想要之前的代码，我也可以提交。

将数据拆分为训练集和测试集 (0.80, 0.20)
ALS 算法
显示预测。

希望以上内容能帮助您完成我所附的代码。
我只获得已提交排名的预测。
我尝试将我的排名加入训练集。从这里，我希望获得数据集中其他电影的推荐或预测。
我的尝试：
导入了具有我自己排名的 DF。
将其 (UnionAll) 附加到训练集。
获得预测（但仅限于我已经排名的电影）
code:
#拆分数据集

training, test = All_Movies.randomSplit([0.8, 0.2])
from pyspark.ml.recommendation import ALS

from pyspark.ml.evaluation import RegressionEvaluator

#设置模型

ALS = ALS(maxIter=10, regParam=0.01, userCol = &quot;userId&quot;,itemCol=&quot;movieId&quot;, ratingsCol=&quot;rating&quot;, coldStartStrategy=&quot;drop&quot;)

#将模型拟合到训练集并附加个人推荐

model = ALS.fit(training.unionAll(PersonalDF)) #PersonalDF 是我的排名

#获取测试集的预测
predictions = model.transform(test).dropna()

#直到一切都很好这里。

#尝试获取我的电影的预测排名
mySampledMovies = model.transform(PersonalDF) 
mySampledMovies.registerTempTable(&quot;mySampledMovies&quot;)

display(sqlContext.sql(&quot;select userId, movieId, ratings,title, prediction from mySampledMovies&quot;))

我期望一个 DataFrame 表示我的用户 ID、电影 ID、排名、预测。对于我没见过的电影，排名为 N/A 或 Null，预测有值。
非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</guid>
      <pubDate>Fri, 08 Feb 2019 12:00:58 GMT</pubDate>
    </item>
    <item>
      <title>如何从一系列图像中预测下一张图像？</title>
      <link>https://stackoverflow.com/questions/49714969/how-can-i-predict-the-next-image-from-a-series-of-images</link>
      <description><![CDATA[我计划从图像序列中预测下一张图像。我在互联网上（Google/YouTube）搜索过教程和类似的工作。但我找不到任何内容。
我想知道是否有可能找到模式并预测下一张图像，我能否找到一些相关教程。]]></description>
      <guid>https://stackoverflow.com/questions/49714969/how-can-i-predict-the-next-image-from-a-series-of-images</guid>
      <pubDate>Sun, 08 Apr 2018 06:07:06 GMT</pubDate>
    </item>
    </channel>
</rss>