<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 11 Dec 2023 03:15:52 GMT</lastBuildDate>
    <item>
      <title>针对我的 TSA 用例的自定义张量流 CNN 实现</title>
      <link>https://stackoverflow.com/questions/77637163/custom-tensorflow-cnn-implemetnation-for-my-tsa-use-case</link>
      <description><![CDATA[我想在时间序列数据集中找到某些特征和模式。我尝试过使用 HMM 聚类，但它没有产生好的结果。我想要实现类似于 RCNN 在 2D 情况下所做的事情，但在一维情况下。我可以在其中为模型提供示例，它会在序列中找到更多示例，并标记找到它的时间范围。给定一个时间序列序列 T，假设我想通过它运行 CNN，并且假设我想要对多个模式进行多类分类，每个模式可以发生多次。在我的具体实现中，我希望能够识别发生特定模式的时间帧 t，因此将卷积开始和结束的日期时间信息保留为特征图中的另一层将很有用。我想保留有关何时发现它的日期时间范围信息。我知道 python 不允许重载，但是我是否可以修改 conv1D 的代码以在特征映射中保留第二层并保留每个特征的时间戳，然后最终可能有一个 [start_time, end_time] 对于特定模式。因此，特征图将是一个 XY2 张量，并且在每次卷积操作之后，新图将包含 [oldest_start_time,newest_end_time] 的日期时间。到目前为止，我的训练是否有任何问题，我是否使用了错误的工具（也许是基于 RNN 的架构？）？在tensorflow中自定义实现通常是如何完成的，我需要编写自己的GD实现吗？
到目前为止还没有尝试过任何事情，只是处于想法阶段。尝试看看我是否使用了错误的工具，可能使用的是 RNN 类型架构。在我承诺编码之前，我需要确保我的想法是正确的。或者，我正在考虑首先进行多类分类，然后为每个命中的类运行自定义 1D-CNN 网络，然后 bin 搜索将大小缩小到时间范围内。]]></description>
      <guid>https://stackoverflow.com/questions/77637163/custom-tensorflow-cnn-implemetnation-for-my-tsa-use-case</guid>
      <pubDate>Mon, 11 Dec 2023 02:14:57 GMT</pubDate>
    </item>
    <item>
      <title>发生错误：需要 2D 数组，却得到 1D 数组：[关闭]</title>
      <link>https://stackoverflow.com/questions/77636896/an-error-occurred-expected-2d-array-got-1d-array-instead</link>
      <description><![CDATA[在这一行中：
stacked_predictions_2d = ensemble_predictions(X_test、X_train、y_test、y_train、rf_model、svm_model、gru_model、lstm_model、xgb_model、neural_network_model)`

我遇到这个问题：
发生错误：需要二维数组，却得到一维数组：array=[4.185 4.22 3.975 4.055 4.0475 4.015 4.0925 4.28 4.3375
4.4175
 4.46 4.1675 4.145 4.1525 4.0525 4.1375 4.1 4.05 4.2125 4.21
 4.1575 4.165 4.2925 4.23 4.3875 4.3975 4.2975 4.3125 4.29 4.44
 4.525 4.365 4.3125 4.3825 4.4725 4.3225 4.335 4.335 4.39 4.4075
 4.35 4.305 4.37 4.2625 4.29 4.22 4.2475 4.325 4.415 4.47
 4.5025 4.265 4.245 4.26 4.15 4.1675 4.11 4.15 4.0325 4.04
 4.1625 3.9275 3.885 3.6875 3.625 3.55 3.49 3.64 3.6 3.67]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

我不知道为什么会遇到这个问题，也不知道为什么它不告诉我问题出在哪个数组中。
X_TRAIN 的形状：(70, 17)
X_TEST 的形状：(30, 17)
Y_TRAIN 的形状：(70,)
Y_TEST 的形状：(30,)
累积特征的形状 (1, 19)

y 测试和训练应该是 1d，因为它们只包含样本。我不知道问题出在哪个数组中，但我确实知道这不是训练或测试，因为他们正在预测在获得此数据时价值 400 美元的股票的股价。
问题可能是什么以及如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77636896/an-error-occurred-expected-2d-array-got-1d-array-instead</guid>
      <pubDate>Mon, 11 Dec 2023 00:03:35 GMT</pubDate>
    </item>
    <item>
      <title>在google colab上安装cuML时出现问题</title>
      <link>https://stackoverflow.com/questions/77636413/problem-when-installing-cuml-on-google-colab</link>
      <description><![CDATA[我在 google colab 上安装 RAPIDS 和 cuML 时遇到此错误：https://i。 stack.imgur.com/7Q12u.png
我按照此链接的说明进行操作：https://docs.rapids .ai/deployment/stable/platforms/colab/
我检查过，我已连接到 T4 GPU，并且我也尝试使用其他 GPU：
https://i.stack.imgur.com/BszUI.png
我的python版本似乎没问题，我使用的是python 3.10.12
我尝试使用--no-cache-dir选项，但它似乎没有改变任何东西。
我还尝试按照说明使用 conda 安装 RAPIDS，但在安装 cuml 时遇到了同样的问题]]></description>
      <guid>https://stackoverflow.com/questions/77636413/problem-when-installing-cuml-on-google-colab</guid>
      <pubDate>Sun, 10 Dec 2023 20:54:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit-learn 在没有预先存在标签的评论中进行情感分类的策略 [关闭]</title>
      <link>https://stackoverflow.com/questions/77635747/strategies-for-emotion-classification-in-comments-without-pre-existing-labels-us</link>
      <description><![CDATA[我正在开发一个项目，涉及使用 Python 和 scikit-learn 对文本评论中的情感进行分类。但是，我的数据集没有预先存在的情感标签。
我正在寻求有关在没有预先存在的标签的情况下进行情绪分类的可能策略的建议。如何定义情绪类别？我可以使用哪些类型的特征或文本表示方法来捕捉评论中的情感方面？
有任何代码示例、推荐的库或经过验证的方法的参考吗？]]></description>
      <guid>https://stackoverflow.com/questions/77635747/strategies-for-emotion-classification-in-comments-without-pre-existing-labels-us</guid>
      <pubDate>Sun, 10 Dec 2023 17:29:53 GMT</pubDate>
    </item>
    <item>
      <title>我的 GAN 项目正在生成噪声图像</title>
      <link>https://stackoverflow.com/questions/77635721/my-gan-project-is-generating-noisy-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77635721/my-gan-project-is-generating-noisy-images</guid>
      <pubDate>Sun, 10 Dec 2023 17:22:47 GMT</pubDate>
    </item>
    <item>
      <title>客户购买倾向模型，我该怎么做？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77635210/customer-propensity-to-purchase-model-how-do-i-go-about-it</link>
      <description><![CDATA[所以我有这个数据集，其中包括时间戳、购买的产品类别以及有关用户在电子商务平台上的行为的其他信息，例如：他们购买的频率、来自哪个类别、imp 评论如何、添加到购物车、购物车放弃，保存以供稍后使用，等等以及所有详细信息。
现在我想训练一个模型，然后为客户进行这个虚拟电子商务模拟，他们执行的某些操作将被添加到实时数据库中（客户可能存在多个会话，其中日期也是分析），模型可以对其进行处理，然后仪表板可以显示他们在接下来的几周/几个月内购买特定产品类别的可能性。
我已经使用过ml和dl，但我对它还很陌生，所以如果这是愚蠢的事情，我提前道歉，但我很困惑，就像我错过了一些关于如何创建它并制作它的细节它有效。
有什么建议吗？请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/77635210/customer-propensity-to-purchase-model-how-do-i-go-about-it</guid>
      <pubDate>Sun, 10 Dec 2023 14:44:02 GMT</pubDate>
    </item>
    <item>
      <title>想要使用监督或无监督构建建议模型吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</link>
      <description><![CDATA[假设我们从一个巨大的区域开始，想要建立一个模型来建议是否建议在 latlon 的每个点放置多少新信号发射器。
第一步：在边界区域（100m 网格）内创建所有可能的 latlon
第二步：创建所有相关功能，例如
-最近的现有发射器距离
- 该点的当前信号电平（在此示例 latlon 中）
- 使用最接近该点的现有发射器的使用量（在此示例 latlon 中）
-当前点使用信号的用户数量
问题

如果我选择 NNet 模型，我需要提出评分函数来计算每个特征向量的合适分数。因为它是有监督模型，所以需要用该模型进行训练，如何找到合适的评分函数？当我找到分数函数时，我是否需要考虑特定特征的异常值？

如果我可以拥有标记数据，那么 ML 模型的好处是什么，因为我可以使用此评分函数与自动化的传统软件来生成点列表的排名。

如果我使用无监督方法，它只会根据特征对相似的特征点进行分组，但是如何对这个点进行排序，不知何故，我需要教育模型每个特征，较高的值意味着好，或者更高的值意味着不好，对吗？

有什么建议或更好的型号选择吗？


我试图概述脚趾步骤，但我有疑问，因为该方法听起来并不优于传统的自动化软件。]]></description>
      <guid>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</guid>
      <pubDate>Sun, 10 Dec 2023 07:29:16 GMT</pubDate>
    </item>
    <item>
      <title>Visual Studio 在 yolo7v 上训练时找不到 cuda 错误</title>
      <link>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</link>
      <description><![CDATA[当我尝试在 yolo v7 上训练时，出现此错误：
文件“train.py”，第 595 行，在  中
    设备= select_device(opt.device,batch_size=opt.batch_size)
  文件“C:\Users\96Crori\Desktop\yolov7_custom_training\yolov7\utils\torch_utils.py”，第 71 行，位于 select_device
    断言 torch.cuda.is_available(), f&#39;CUDA 不可用，请求的设备 {device} 无效&#39; # 检查可用性
AssertionError：CUDA 不可用，请求的设备 0 无效

我安装了cuda版本11.3，但我不知道为什么Visual Studios找不到它]]></description>
      <guid>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</guid>
      <pubDate>Sun, 10 Dec 2023 02:39:08 GMT</pubDate>
    </item>
    <item>
      <title>为什么tensorflow的AudioIOTensor的WAV文件的张量输出与decode_wav的输出不同？</title>
      <link>https://stackoverflow.com/questions/77628394/why-does-tensor-output-for-wav-file-from-tensorflows-audioiotensor-differ-from</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77628394/why-does-tensor-output-for-wav-file-from-tensorflows-audioiotensor-differ-from</guid>
      <pubDate>Fri, 08 Dec 2023 17:55:59 GMT</pubDate>
    </item>
    <item>
      <title>具有不同输入形状的 3D 深度学习输入 [关闭]</title>
      <link>https://stackoverflow.com/questions/77602918/3d-deep-learning-input-with-varying-input-shapes</link>
      <description><![CDATA[如何将可变维度的数据集输入到深度学习模型中。
我正在使用可变切片进行 3D 医学成像，我使用了 PCA 和其他切片选择技术以及填充以使模型具有相同的形状
但我想知道是否有任何用于深度学习模型的可变输入形状的技术。
下面是代码：
来自tensorflow.keras导入层

#输入形状 = (200, 200, 60, 1)
输入形状=像素数组[1:]
输入 = keras.Input(shape=(pixel_arrays.shape[1:]))
x=layers.Conv3D(filters=16,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(输入)
x=layers.Conv3D(filters=32,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(x)
x=layers.Conv3D(filters=64,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(x)
#x = 层.Conv3D(filters=32, kernel_size=3, 激活=&#39;relu&#39;, padding=&#39;same&#39;)(x)
]]></description>
      <guid>https://stackoverflow.com/questions/77602918/3d-deep-learning-input-with-varying-input-shapes</guid>
      <pubDate>Mon, 04 Dec 2023 22:33:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在colab中查找数据集的列中有多少个不同的数据[关闭]</title>
      <link>https://stackoverflow.com/questions/77599408/how-to-find-how-many-different-data-are-in-a-column-of-a-data-set-in-colab</link>
      <description><![CDATA[我有一个大约由 400000 行和 8 列组成的数据集，我只想知道一列中有多少种不同类型的数据，我该怎么做？列中的数据是字符串的形式，我需要给它们分配数字，所以我需要找出该列中有多少个不同的单词。我不知道我应该做什么]]></description>
      <guid>https://stackoverflow.com/questions/77599408/how-to-find-how-many-different-data-are-in-a-column-of-a-data-set-in-colab</guid>
      <pubDate>Mon, 04 Dec 2023 12:22:17 GMT</pubDate>
    </item>
    <item>
      <title>如何修复我的感知器来识别数字？</title>
      <link>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</guid>
      <pubDate>Sun, 03 Dec 2023 14:03:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 tidymodels 进行特征消除以筛选多个模型</title>
      <link>https://stackoverflow.com/questions/72896969/feature-elimination-to-screen-for-multiple-models-using-tidymodels</link>
      <description><![CDATA[我目前正在执行回归建模，数据集的特征数量 (p) 高于观测值 (n)。
通常为 p = 10000 和 n = 30。此外，我想测试许多模型并找到最好的一个。
我现在要做的就是首先消除这些功能。将其从 10K 减少到 20-30，使用
step_select_mrmr() 或 step_select_vip()。我通过将其放在管道的顶部来实现这一点。
然后我会继续测试许多模型。
这种做法合理吗？]]></description>
      <guid>https://stackoverflow.com/questions/72896969/feature-elimination-to-screen-for-multiple-models-using-tidymodels</guid>
      <pubDate>Thu, 07 Jul 2022 11:23:56 GMT</pubDate>
    </item>
    <item>
      <title>Python：如何从 Optuna LightGBM 研究中检索最佳模型？</title>
      <link>https://stackoverflow.com/questions/62144904/python-how-to-retrieve-the-best-model-from-optuna-lightgbm-study</link>
      <description><![CDATA[我希望获得最佳模型，以便稍后在笔记本中使用，以使用不同的测试批次进行预测。
可重现的示例（取自 Optuna Github）：
导入 lightgbm 为 lgb
将 numpy 导入为 np
导入 sklearn.datasets
导入 sklearn.metrics
从 sklearn.model_selection 导入 train_test_split

导入奥图纳


# 仅供参考：目标函数可以接受额外的参数
#（https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args）。
定义目标（试用）：
    数据，目标 = sklearn.datasets.load_breast_cancer(return_X_y=True)
    train_x、valid_x、train_y、valid_y = train_test_split（数据、目标、test_size=0.25）
    dtrain = lgb.Dataset(train_x, label=train_y)
    dvalid = lgb.Dataset(valid_x, label=valid_y)

    参数 = {
        “目标”：“二进制”，
        “公制”：“auc”，
        “详细程度”：-1，
        &quot;boosting_type&quot;: &quot;gbdt&quot;,
        &quot;lambda_l1&quot;: Trial.suggest_loguniform(&quot;lambda_l1&quot;, 1e-8, 10.0),
        &quot;lambda_l2&quot;: Trial.suggest_loguniform(&quot;lambda_l2&quot;, 1e-8, 10.0),
        &quot;num_leaves&quot;: Trial.suggest_int(&quot;num_leaves&quot;, 2, 256),
        &quot;feature_fraction&quot;: Trial.suggest_uniform(&quot;feature_fraction&quot;, 0.4, 1.0),
        &quot;bagging_fraction&quot;: Trial.suggest_uniform(&quot;bagging_fraction&quot;, 0.4, 1.0),
        &quot;bagging_freq&quot;: Trial.suggest_int(&quot;bagging_freq&quot;, 1, 7),
        &quot;min_child_samples&quot;: Trial.suggest_int(&quot;min_child_samples&quot;, 5, 100),
    }

    # 添加用于修剪的回调。
    pruning_callback = optuna.integration.LightGBMPruningCallback（试用版，“auc”）
    gbm = lgb.train(
        参数，dtrain，valid_sets = [dvalid]，verbose_eval = False，callbacks = [pruning_callback]
    ）

    preds = gbm.predict(valid_x)
    pred_labels = np.rint(preds)
    准确度 = sklearn.metrics.accuracy_score(valid_y, pred_labels)
    返回精度


我的理解是，下面的研究将调整准确性。我想以某种方式从研究中检索最佳模型（不仅仅是参数）而不将其保存为泡菜，我只想在笔记本中的其他地方使用该模型。 

&lt;前&gt;&lt;代码&gt;
如果 __name__ == &quot;__main__&quot;:
    研究 = optuna.create_study(
        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10)，方向=“最大化”
    ）
    研究.优化（目标，n_Trials=100）

    print(&quot;最佳试用：&quot;)
    试验 = 研究.best_试验

    print(&quot; 参数: &quot;)
    对于 Trial.params.items() 中的键、值：
        print(&quot; {}: {}&quot;.format(key, value))


期望的输出是
best_model = ~上面的模型~
new_target_pred = best_model.predict(new_data_test)
指标.accuracy_score(new_target_test, new__target_pred)

]]></description>
      <guid>https://stackoverflow.com/questions/62144904/python-how-to-retrieve-the-best-model-from-optuna-lightgbm-study</guid>
      <pubDate>Tue, 02 Jun 2020 04:35:05 GMT</pubDate>
    </item>
    <item>
      <title>如何检测身份证上的全息图覆盖层？</title>
      <link>https://stackoverflow.com/questions/52887039/how-to-detect-hologram-overlays-like-the-ones-in-id-cards</link>
      <description><![CDATA[有什么好的方法可以检测身份证等安全文件中的全息图吗？我已经尝试了很多方法，例如索贝尔滤波器、拉普拉斯算子等，但仍然很难判断卡片上是否有全息图。
原始图像

从左到右：拉普拉斯算子、SobelX、SobelY
]]></description>
      <guid>https://stackoverflow.com/questions/52887039/how-to-detect-hologram-overlays-like-the-ones-in-id-cards</guid>
      <pubDate>Fri, 19 Oct 2018 06:41:29 GMT</pubDate>
    </item>
    </channel>
</rss>