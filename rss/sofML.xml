<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 03 Jul 2024 09:16:21 GMT</lastBuildDate>
    <item>
      <title>我可以申请序列 keras 模型的专利吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78700633/can-i-patent-a-sequential-keras-model</link>
      <description><![CDATA[我的问题与任何代码片段都无关，但我想问一下我是否创建了一个 keras 模型
这里是从 网站 获取的示例
model = keras.Sequential()
model.add(keras.Input(shape=(16,)))
model.add(keras.layers.Dense(8))

# 请注意，您也可以省略初始“Input”。
# 在这种情况下，模型在第一次调用训练/评估方法之前没有任何权重（因为它尚未构建）：
model = keras.Sequential()
model.add(keras.layers.Dense(8))
model.add(keras.layers.Dense(4))
# model.weights 尚未创建

# 而如果您指定“输入”，则模型会在您添加层时连续构建：
model = keras.Sequential()
model.add(keras.Input(shape=(16,)))
model.add(keras.layers.Dense(8))
len(model.weights) # 返回“2”

# 使用延迟构建模式（未指定输入形状）时，您可以
# 选择通过调用
# `build(batch_input_shape)` 来手动构建模型：
model = keras.Sequential()
model.add(keras.layers.Dense(8))
model.add(keras.layers.Dense(4))
model.build((None, 16))
len(model.weights) # 返回“4”

# 请注意，使用延迟构建模式（未指定输入形状）时，
# 第一次调用 `fit`、`eval` 或 `predict` 时，
# 或第一次对某些输入数据调用模型时，模型就会构建。
model = keras.Sequential()
model.add(keras.layers.Dense(8))
model.add(keras.layers.Dense(1))
model.compile(optimizer=&#39;sgd&#39;, loss=&#39;mse&#39;)

现在我的模型相对来说处于类似的模式，由于 keras 是一个开源库，所以我获得了专利。]]></description>
      <guid>https://stackoverflow.com/questions/78700633/can-i-patent-a-sequential-keras-model</guid>
      <pubDate>Wed, 03 Jul 2024 07:27:39 GMT</pubDate>
    </item>
    <item>
      <title>Mask2Former-model：AttributeError：'list' 对象在推理中没有属性 'shape'</title>
      <link>https://stackoverflow.com/questions/78700458/mask2former-model-attributeerror-list-object-has-no-attribute-shape-on-inf</link>
      <description><![CDATA[我正在尝试微调 mask2former 模型，如此存储库中所述。
据我所知，训练工作正常，但每次我尝试在模型上运行推理时，当处理后的图像传递给模型时，我都会收到上述错误。
我使用的代码与示例笔记本中的推理代码完全相同。当我运行此笔记本的第 17 个单元格时，会出现错误。

我尝试将输入从 torch.tensor 更改为 numpy.array，但这没有帮助
我尝试完全重新创建 Inference_with_Mask2Former.ipynb 笔记本中编写的代码，以查看我的代码是否存在问题。它仍然不起作用
我尝试使用 tensor.unsqueeze() 将输入图像张量的维度从 [C, H, W] 更改为 [B, C, H, W]，但由于维度不正确而引发错误
]]></description>
      <guid>https://stackoverflow.com/questions/78700458/mask2former-model-attributeerror-list-object-has-no-attribute-shape-on-inf</guid>
      <pubDate>Wed, 03 Jul 2024 06:44:54 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：项目数量传递错误 9，位置意味着 1</title>
      <link>https://stackoverflow.com/questions/78700237/valueerror-wrong-number-of-items-passed-9-placement-implies-1</link>
      <description><![CDATA[我正在尝试计算数据框中两列之间的余弦相似度。它的代码片段如下：
def cal_cosine_similarity(row):
vec1 = np.array(row[&#39;sup_vec&#39;])
vec2 = np.array(row[&#39;vector&#39;])
return cosine_similarity([vec1], [vec2])[0][0]
cross_join_df[&#39;cos_sim&#39;] = cross_join_df.apply(cal_cosine_similarity,axis = 1)

大多数情况下，这种方法都行得通，但有时我会收到如下错误：
Traceback（最近一次调用最后一次）：
File &quot;/usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py&quot;, line 2898, in get_loc
return self._engine.get_loc(casted_key)
文件 &quot;pandas/_libs/index.pyx&quot;, 第 70 行, 位于 pandas._libs.index.IndexEngine.get_loc
文件 &quot;pandas/_libs/index.pyx&quot;, 第 101 行, 位于 pandas._libs.index.IndexEngine.get_loc
文件 &quot;pandas/_libs/hashtable_class_helper.pxi&quot;, 第 1675 行, 位于 pandas._libs.hashtable.PyObjectHashTable.get_item
文件 &quot;pandas/_libs/hashtable_class_helper.pxi&quot;, 第 1683 行, 位于 pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: &#39;cos_sim&#39;
上述异常是导致以下异常的直接原因异常：
回溯（最近一次调用）：
文件“/usr/local/lib/python3.8/site-packages/pandas/core/generic.py”，第 3576 行，在 _set_item 中
loc = self._info_axis.get_loc(key)
文件“/usr/local/lib/python3.8/site-packages/pandas/core/indexes/base.py”，第 2900 行，在 get_loc 中
从 err 引发 KeyError(key)
KeyError：&#39;cos_sim&#39;
在处理上述异常期间，发生了另一个异常：
回溯（最近一次调用）：
文件“/opt/prism/src/main.py”，第 79 行，在 &lt;module&gt; 中
res = job.run()
文件 &quot;/opt/prism/src/jobs/v2/SparkJob.py&quot;，第 45 行，运行中
self.start()
文件 &quot;/opt/prism/src/jobs/v2/SparkJob.py&quot;，第 71 行，启动中
raise e
文件 &quot;/opt/prism/src/jobs/v2/SparkJob.py&quot;，第 68 行，启动中
self.execute(self.input_data, 1)
文件 &quot;/opt/prism/src/jobs/v2/DprmMappingInference.py&quot;，第 289 行，执行中
cross_join_df[&#39;cos_sim&#39;] = cross_join_df.apply(cal_cosine_similarity,axis = 1)
文件&quot;/usr/local/lib/python3.8/site-packages/pandas/core/frame.py&quot;，第 3044 行，在 __setitem__ 中
self._set_item(key, value)
文件 &quot;/usr/local/lib/python3.8/site-packages/pandas/core/frame.py&quot;，第 3121 行，在 _set_item 中
NDFrame._set_item(self, key, value)
文件 &quot;/usr/local/lib/python3.8/site-packages/pandas/core/generic.py&quot;，第 3579 行，在 _set_item 中
self._mgr.insert(len(self._info_axis), key, value)
文件 &quot;/usr/local/lib/python3.8/site-packages/pandas/core/internals/managers.py&quot;，第1198，在插入中
block = make_block(values=value, ndim=self.ndim, placement=slice(loc, loc + 1))
文件 &quot;/usr/local/lib/python3.8/site-packages/pandas/core/internals/blocks.py&quot;，第 2744 行，在 make_block 中
return klass(values, ndim=ndim, placement=placement)
文件 &quot;/usr/local/lib/python3.8/site-packages/pandas/core/internals/blocks.py&quot;，第 2400 行，在 __init__ 中
super().__init__(values, ndim=ndim, placement=placement)
文件 &quot;/usr/local/lib/python3.8/site-packages/pandas/core/internals/blocks.py&quot;，第 130 行，在 __init__ 中
raise ValueError(
ValueError：项目数错误，超过 9，位置意味着 1

我无法找到此错误。此错误是否由余弦相似度函数的某些功能引起？]]></description>
      <guid>https://stackoverflow.com/questions/78700237/valueerror-wrong-number-of-items-passed-9-placement-implies-1</guid>
      <pubDate>Wed, 03 Jul 2024 05:35:57 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器中的梯度消失</title>
      <link>https://stackoverflow.com/questions/78700019/vanishing-gradient-in-autoecnoder</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78700019/vanishing-gradient-in-autoecnoder</guid>
      <pubDate>Wed, 03 Jul 2024 03:59:42 GMT</pubDate>
    </item>
    <item>
      <title>如何利用小型神经网络高效地做出大量预测？</title>
      <link>https://stackoverflow.com/questions/78699009/how-to-efficiently-make-a-lot-of-predictions-with-small-neural-network</link>
      <description><![CDATA[我需要用小型神经网络（100-150 个参数）进行大量预测。我在 TensorFlow 中实现了它，但遇到了效率问题。这是伪代码：
for my_dense_netowrk,my_lstm_netowrk in networks_list
my_dense_netowrk.paramters = 100
my_lstm_netowrk.paramters = 150
for images in data[:60]:
@tf.function
def tf_wrapper(images, state):
model_data = meta_model(images)
data_prepared = image_preparation(model_data)

results = my_dense_netowrk(data_prepared)
results.shape = (19000,1,1)

better_results, state = my_lstm_netowrk(results, state)
return better_results, state

better_results, state = tf_wrapper(images, state)

my_dense_netowrk_n2.paramters = 100
my_lstm_netowrk_n2.paramters = 100

并继续...


我使用 tensorflow 数据管道 api，实际上所有必需的数据（数据变量）都可以分配到我的内存中。
在构建和将数据作为一大堆（批处理大小为 19000）插入神经网络以并行化所有内容时，我没有为我的神经网络指定批处理大小。即使是 lstm 也不会受到序列处理的瓶颈，因为它必须一次处理 19000 个输入。但是当我将神经网络参数增加 10 倍（我不需要）时，我的代码几乎没有注意到它认为批处理大小相当大。
@tf.fcuntion 加快了一切速度。
我尝试了分析，但由于发生了太多操作，未能找到瓶颈。我发现内核启动只花费了一半的时间，因为通常 tensorflow 预计这个过程会花费大量时间，所以我猜它没有针对此类任务进行优化，因为当我将循环从 60 增加到 6000 时，每次循环的效率都会提高 10 倍！似乎需要时间进行准备。
image_preparation() 函数仅使用 tf 操作，如重塑、堆叠、平铺，我无法提前准备数据。
我使用带有 M3 Max 芯片的 macOS，使用 GPU 或 CPU 没有区别。我尝试了 python 3.8、3.9、3.10、3.11、3.12。

因此，似乎 tensorflow 并没有被我的模型所限制，这很奇怪，而且互联网上没有太多关于如何有效地从小模型中获得大量预测的讨论，每个人都将这样的库用于大型 NN。虽然我认为我的管道应该会从中受益，因为我使用了大批量，但 gpu 根本没有帮助。所以我真的很难找到一个好的解决方案来解决我的问题，并想寻求建议。也许有更好的 ml 框架可以解决我的问题（PyTorch、Jax，也许还有其他？）或者我只是不擅长分析？或者我应该尝试用汇编语言构建自己的内核吗？我不知道]]></description>
      <guid>https://stackoverflow.com/questions/78699009/how-to-efficiently-make-a-lot-of-predictions-with-small-neural-network</guid>
      <pubDate>Tue, 02 Jul 2024 19:52:03 GMT</pubDate>
    </item>
    <item>
      <title>机器过期域名 gnews [关闭]</title>
      <link>https://stackoverflow.com/questions/78698880/machine-expired-domains-gnews</link>
      <description><![CDATA[我需要创建一台机器，一个程序，通过网站 https://www.expireddomains.net/ 从过期域名列表中获取仅属于 google 新闻的域名。
我需要检测 2019 年 12 月之前属于 google 新闻的 google 新闻域名
我曾尝试手动检查过期域名以查看它们是否属于 Google 新闻，但此过程非常耗时且效率低下。我希望找到一种更自动化的方法来交叉引用过期域名及其在 2019 年 12 月之前的 Google 新闻状态。
但是，我还没有找到可以有效完成此任务的现有工具或方法。我需要一个可以自动化此过程的解决方案，从而节省我的时间并确保准确性。]]></description>
      <guid>https://stackoverflow.com/questions/78698880/machine-expired-domains-gnews</guid>
      <pubDate>Tue, 02 Jul 2024 19:15:05 GMT</pubDate>
    </item>
    <item>
      <title>我的感知器和 sklearn 感知器的区别</title>
      <link>https://stackoverflow.com/questions/78698399/difference-in-my-perceptron-and-sklearn-perceptron</link>
      <description><![CDATA[我从头开始编写感知器算法，并将训练后获得的权重与训练 sklearn 感知器模型后获得的权重进行比较。我相信 sklearn 模型将权重和偏差初始化为零向量，我选择学习率 eta0=1 来匹配我的感知器代码。 （注意：我的代码中的偏差是向量 w_b 中的最后一项）
我的代码：
def perceptron(X_train, y_train):
#将权重初始化为 0
w = np.zeros(len(X_train.columns))
b = 0
w_b = np.append(w, b)
while True:
misclassifications = 0 
for X , Y in zip(X_train.values, y_train.values):
X_i = np.append(X, 1)
if Y*(np.dot(X_i,w_b)) &lt;= 0:
w_b = w_b + Y*X_i
misclassifications += 1
if misclassifications == 0:
break
return w_b

w_b = perceptron(X_train, y_train)

结果：[-3. 6.7 -1. ]
sklearn 代码：
perceptron = Perceptron(max_iter=1000, eta0=1,random_state=42) 
perceptron.fit(X_train, y_train)

print(&quot;weights are&quot;,perceptron.coef_)
print(&quot;bias is&quot;,perceptron.intercept_)

结果：weights are [[-4.7 10.1]] bias is [-2.]
我期望权重相同，但事实并非如此。有什么线索可以解释原因吗？]]></description>
      <guid>https://stackoverflow.com/questions/78698399/difference-in-my-perceptron-and-sklearn-perceptron</guid>
      <pubDate>Tue, 02 Jul 2024 17:04:46 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中使用不同分辨率图像训练 DeepLabV3 的最佳实践</title>
      <link>https://stackoverflow.com/questions/78698316/best-practice-to-train-deeplabv3-with-different-resolution-images-in-pytorch</link>
      <description><![CDATA[我正在尝试在 COCO 2017 数据集 上训练 PyTorch 的 DeepLabV3 进行语义分割，但我不确定如何处理不同分辨率的图像。我知道 DeepLab 的架构可以毫无问题地处理它们，但由于它们的分辨率，我无法将它们分批堆叠。处理此问题的最佳做法是什么？我是否将它们调整为固定大小？我是否随机裁剪固定大小？我知道有很多解决方案可以解决此问题，但我真的不知道在语义分割训练的背景下最佳做法是什么。
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78698316/best-practice-to-train-deeplabv3-with-different-resolution-images-in-pytorch</guid>
      <pubDate>Tue, 02 Jul 2024 16:39:00 GMT</pubDate>
    </item>
    <item>
      <title>chemprop：RuntimeError：在“目标”中检测到以下值：张量（[0，12]），但仅预期以下值[0，1]</title>
      <link>https://stackoverflow.com/questions/78698076/chemprop-runtimeerror-detected-the-following-values-in-target-tensor-0-1</link>
      <description><![CDATA[运行 Chemprop 脚本时出现运行时错误。
所有脚本均可在此处找到：
https://github.com/chemprop/chemprop/blob/main/examples/training.ipynb
我遇到错误的部分是：
trainer.fit(mpnn, train_loader, val_loader)
两个月前它还可以正常工作。
我已经更新了所有软件包]]></description>
      <guid>https://stackoverflow.com/questions/78698076/chemprop-runtimeerror-detected-the-following-values-in-target-tensor-0-1</guid>
      <pubDate>Tue, 02 Jul 2024 15:44:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 OpenCV 和自适应阈值检测和掩盖图像中的花朵</title>
      <link>https://stackoverflow.com/questions/78697737/struggling-to-detect-and-mask-flowers-in-images-using-opencv-and-adaptive-thresh</link>
      <description><![CDATA[我正在做一个项目，需要使用 OpenCV 和自适应阈值检测和掩盖图像中的花朵。尽管我付出了努力，但结果并不一致。有些花朵被很好地掩盖了，但其他花朵要么被部分掩盖，要么根本检测不到。我在 TensorFlow 中使用 Oxford Flowers 102 数据集来完成这项任务。下面是我正在使用的代码：
(train_dataset, test_dataset, validation_dataset), ds_info = tfds.load(&#39;oxford_flowers102&#39;, split=[&#39;test&#39;, &#39;train&#39;,&#39;validation&#39;], with_info=True, as_supervised=True)

def normalize_img(image, label):
image = tf.image.resize(image, (256, 256))
return tf.cast(image, tf.float32) / 255.0, label

train_dataset = train_dataset.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_dataset = train_dataset.cache()
train_dataset = train_dataset.shuffle(ds_info.splits[&#39;train&#39;].num_examples)
train_dataset = train_dataset.batch(32)
train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)

def detect_flowers_and_mask(image):
image_np = (image.numpy() * 255).astype(np.uint8)
gray_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY) 
binary_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2) 
contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_SIMPLE)

如果轮廓：
max_contour = max(contours，key=cv2.contourArea)
mask = np.zeros_like(gray_image，dtype=np.uint8)
cv2.drawContours(mask，[max_contour]，-1，(255，255，255)，厚度=cv2.FILLED)
masked_image = cv2.bitwise_and(image_np，image_np，mask=mask)
else:
masked_image = image_np

返回 masked_image

plt.figure(figsize=(15, 15)) 
for i, (image_batch, label_batch) in enumerate(train_dataset.take(20)):
for image, label in zip(image_batch, label_batch):
masked_image = detect_flowers_and_mask(image)
plt.subplot(4, 5, i+1)
plt.imshow(masked_image)
plt.title(ds_info.features[&#39;label&#39;].int2str(label.numpy())) 
plt.axis(&quot;off&quot;)
plt.tight_layout()
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/78697737/struggling-to-detect-and-mask-flowers-in-images-using-opencv-and-adaptive-thresh</guid>
      <pubDate>Tue, 02 Jul 2024 14:34:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOV8 best.pt 文件的对象跟踪算法，该文件是在自定义数据集上训练的？[关闭]</title>
      <link>https://stackoverflow.com/questions/78696932/object-tracking-algo-with-yolov8-best-pt-file-which-is-trained-on-custom-dataset</link>
      <description><![CDATA[我已经使用 YOLOV8 在自定义数据集上训练了一个模型。从中获得了 best.pt 文件。我想使用一些跟踪器算法来跟踪该对象。有人可以给我推荐一些算法吗？也请附上一些链接，以便我可以参考。
此外，如何查看此组合模型的性能指标？
除了 DeepSORT，因为我已经尝试过了。]]></description>
      <guid>https://stackoverflow.com/questions/78696932/object-tracking-algo-with-yolov8-best-pt-file-which-is-trained-on-custom-dataset</guid>
      <pubDate>Tue, 02 Jul 2024 12:08:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 SAM-LSTM-RESNET</title>
      <link>https://stackoverflow.com/questions/78694533/using-sam-lstm-resnet</link>
      <description><![CDATA[我使用的是 SAM-LSTM-RESNET 包，遇到了这个形状的问题。
包中附带的示例图片也出现了同样的问题，所以它不能正常工作，这很奇怪。有人知道如何在不修改包代码的情况下修复此问题吗？
from sam_lstm import SalMap
import os

if not os.path.exists(&quot;\\samples&quot;):
os.makedirs(&quot;\\samples&quot;)

SalMap.auto()

这是回溯
-------------------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Input In [5], in &lt;cell line: 9&gt;()
6 if not os.path.exists(&quot;\\samples&quot;):
7 os.makedirs(&quot;\\samples&quot;)
----&gt; 9 SalMap.auto()

文件 ~\anaconda3\lib\site-packages\sam_lstm\__init__.py:48，位于 SalMap.auto(cls)
45 @classmethod
46 def auto(cls):
47 salmap = cls()
---&gt; 48 salmap.compile()
49 salmap.load_weights()
50 salmap.predict_maps()

文件 ~\anaconda3\lib\site-packages\sam_lstm\__init__.py:59，位于 SalMap.compile(self)
57 def compile(self):
58 self.model = Model(
---&gt; 59 输入=[self.x, self.x_maps], 输出=sam_resnet([self.x, self.x_maps])
60 )
61 self.model.compile(
62 RMSprop(learning_rate=1e-4),
63 损失=[kl_divergence, correlation_coefficient, nss],
64 损失权重=[10, -2, -1],
65 )

文件~\anaconda3\lib\site-packages\sam_lstm\models.py:192，在 sam_resnet(x) 中
190 def sam_resnet(x):
191 # 扩张卷积网络
--&gt; 192 dcn = dcn_resnet(input_tensor=x[0])
193 conv_feat = Conv2D(512, (3, 3), padding=&quot;same&quot;,activation=&quot;relu&quot;)(dcn.output)
194 # 注意力卷积 LSTM

文件 ~\anaconda3\lib\site-packages\sam_lstm\dcn_resnet.py:259, 在 dcn_resnet(input_tensor) 中
252 # 加载权重
253 weights_path = get_file(
254 &quot;resnet50_weights_th_dim_ordering_th_kernels_notop.h5&quot;,
255 TH_WEIGHTS_PATH_NO_TOP,
256 cache_subdir=&quot;weights&quot;,
257 file_hash=&quot;f64f049c92468c9affcd44b0976cdafe&quot;,
258 )
--&gt; 259 model.load_weights(weights_path)
261 返回模型

文件 ~\anaconda3\lib\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 中引发 e.with_traceback(filtered_tb)
123 finally:
124 delfiltered_tb

文件 ~\anaconda3\lib\site-packages\keras\src\backend\common\variables.py:226，位于 KerasVariable.assign(self, value)
224 value = self._convert_to_tensor(value, dtype=self.dtype)
225 if not shape_equal(value.shape, self.shape):
--&gt; 226 raise ValueError(
227 “目标变量的形状和”
228 ““`variable.assign(value)` 中的目标值的形状必须匹配。”
229 “`variable.assign(value)` 中目标值的形状必须匹配。”
230 f“variable.shape={self.value.shape},”
231 f“收到：value.shape={value.shape}。”
232 f“目标变量：{self}”
233 )
234 if in_stateless_scope():
235 scope = get_stateless_scope()

ValueError: `variable.assign(value)` 中目标变量的形状和目标值的形状必须匹配。variable.shape=(7, 7, 3, 64), 收到：value.shape=(64, 3, 7, 7)。目标变量：&lt;KerasVariable shape=(7, 7, 3, 64), dtype=float32, path=conv1/kernel&gt;

你看这个错误基本上是形状以某种方式被转置了，但我不知道如何修复它？]]></description>
      <guid>https://stackoverflow.com/questions/78694533/using-sam-lstm-resnet</guid>
      <pubDate>Mon, 01 Jul 2024 23:22:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 macOS 10.12 上运行 Core ML 模型？</title>
      <link>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</link>
      <description><![CDATA[https://developer.apple.com/documentation/coreml 提到 macOS 10.13+：

如何在 macOS 10.12 上运行 Core ML 模型？

在 Ubuntu 20.04 上使用 Hugging Face 的 Exporters lib:
git clone https://github.com/huggingface/exporters.git
cd exporters
pip install -e .
python -m exporters.coreml --model=distilbert-base-uncasederated/ --quantize=float32 
]]></description>
      <guid>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</guid>
      <pubDate>Mon, 01 Jul 2024 20:13:24 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入技术从数据库中进行人脸识别</title>
      <link>https://stackoverflow.com/questions/78688976/face-recognize-from-the-database-using-embedding-technique</link>
      <description><![CDATA[我目前正在开展一个项目，旨在识别大学记录中是否存在任何个人的照片。所提出的方法涉及将每个学生照片的嵌入及其详细信息存储在矢量数据库中。当需要比较照片时，系统将生成该照片的嵌入值，然后将该值与数据库进行比较。如果该值在特定阈值内，则表明该个人存在于记录中。
我正在寻求专家建议，以确定这种方法是否可行。如果对此方法有任何疑虑，我将不胜感激最佳解决方案的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78688976/face-recognize-from-the-database-using-embedding-technique</guid>
      <pubDate>Sun, 30 Jun 2024 15:09:55 GMT</pubDate>
    </item>
    <item>
      <title>Spark MLlib 中 DataFrame 的‘rawPrediction’和‘probability’列是什么意思？</title>
      <link>https://stackoverflow.com/questions/37903288/what-do-columns-rawprediction-and-probability-of-dataframe-mean-in-spark-mll</link>
      <description><![CDATA[我训练了一个 LogisticRegressionModel 之后，用它对测试数据 DF 进行了变换，得到了预测 DF。然后当我调用 prediction.show() 时，输出的列名为：[label | features | rawPrediction | probability | prediction]。我知道 label 和 featrues 是什么意思，但是我该如何理解 rawPrediction|probability|prediction？]]></description>
      <guid>https://stackoverflow.com/questions/37903288/what-do-columns-rawprediction-and-probability-of-dataframe-mean-in-spark-mll</guid>
      <pubDate>Sun, 19 Jun 2016 02:00:47 GMT</pubDate>
    </item>
    </channel>
</rss>