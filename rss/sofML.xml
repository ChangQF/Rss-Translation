<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 01 Feb 2024 12:24:40 GMT</lastBuildDate>
    <item>
      <title>如何控制头盔物体检测模型产生的相同警报？</title>
      <link>https://stackoverflow.com/questions/77919736/how-to-control-the-same-alerts-being-produced-by-a-helmet-object-detection-model</link>
      <description><![CDATA[我们有一个头盔对象检测模型，它可以检测是否佩戴头盔的人的天气。如果一个人没有戴头盔，它会通过 MQTT 代理将坐标发送到服务器。
现在，如果一个人没有戴头盔站在一个地方，则会产生连续的相同警报，但不应保存所有警报，因为这是同一个人，否则如果一个人只是移动一英寸或几厘米，则应该保存所有警报亦未得救。我的要求是同一个人的警报不应在数据库中多次保存，从而导致冗余。
从模型中，我们仅获得场景的坐标。
如何处理这种情况或管理同一个人的警报？ （这里我们不知道人脸，因为它只有头盔检测模型）
寻找一种有效的方法来处理这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77919736/how-to-control-the-same-alerts-being-produced-by-a-helmet-object-detection-model</guid>
      <pubDate>Thu, 01 Feb 2024 11:20:27 GMT</pubDate>
    </item>
    <item>
      <title>在交叉验证过程中我应该测试哪些数据？</title>
      <link>https://stackoverflow.com/questions/77919597/which-data-should-i-test-during-the-cross-validation-process</link>
      <description><![CDATA[我正在通过微调预训练 bert 模型来开发分类应用程序。首先，我将数据除以 2。训练和测试。然后，我使用交叉验证方法对训练数据进行 10 次重复和 10 次折叠训练。所以训练数据分为两部分：训练和验证。该模型是使用各个时期的验证数据进行评估的，但我不保存它们。 5个epoch后，A模型训练结束。该模型名称为repeat1fold1。我使用测试数据来衡量模型的性能（repeat1fold1）。每次重复和折叠完成后，我都会记录得到的测试结果。例如，在上面的例子中我训练了 100 个模型。最后，我通过取平均值来报告它们（测试数据指标）。这是错误的吗？
我应该报告验证指标吗？
注意：我不做参数优化。
我需要澄清术语]]></description>
      <guid>https://stackoverflow.com/questions/77919597/which-data-should-i-test-during-the-cross-validation-process</guid>
      <pubDate>Thu, 01 Feb 2024 10:59:18 GMT</pubDate>
    </item>
    <item>
      <title>培训师的表现就像是从头开始培训</title>
      <link>https://stackoverflow.com/questions/77919591/trainer-acts-as-if-its-training-from-scratch</link>
      <description><![CDATA[我正在使用 Huggingface 训练器训练模型，并为 resume_from_checkpoint 参数指定了检查点文件夹。
但是，当它继续训练时，它仍然会使用与第一个保存步骤相对应的名称保存检查点（例如 checkpoint-4，即使 resume_from_checkpoint 应从  开始检查点-4096）。进度条还显示所有 max_steps，尽管我不希望它从头开始。
这是一个常见问题吗？我该如何解决这个问题？
我将训练参数保存在 yaml 文件中：
training_args：
   学习率：!!float 1e-4
   do_train：正确
   每个设备训练批次大小：8
   每设备评估批量大小：8
   记录步骤：1024
   输出目录：/path/to/training_output/
   overwrite_output_dir：假
   删除未使用的列：假
   保存策略：步骤
   评估策略：步骤
   保存步骤：1024
   load_best_model_at_end：真
   热身步数：100
   最大步数：65536
   种子：22
   resume_from_checkpoint：/path/to/checkpoint-4096

然后通过使用 **kwargs 初始化 TrainingArguments 对象来训练模型。
但是终端显示：
将模型检查点保存到 /path/to/checkpoint-4

进度条显示了所有步骤，即使我需要它从步骤 4096 开始。]]></description>
      <guid>https://stackoverflow.com/questions/77919591/trainer-acts-as-if-its-training-from-scratch</guid>
      <pubDate>Thu, 01 Feb 2024 10:58:33 GMT</pubDate>
    </item>
    <item>
      <title>如何安全地将元数据添加到 mlflow 模型？</title>
      <link>https://stackoverflow.com/questions/77919524/how-to-add-metadata-to-a-mlflow-model-safely</link>
      <description><![CDATA[当我训练 ML 模型时，我会得到一些想要存储在模型附近的参数，以便在生产中加载它们。
有一个功能
mlflow.pyfunc.log_model 可以得到元数据作为参数。
但是这并不安全
&lt;块引用&gt;
实验性：此参数可能会在未来版本中更改或删除，恕不另行通知。

我的考虑：

标签。我尝试使用注册模型并将它们添加到标签中，但它似乎不适用于长字符串。如 key = &quot;abc&quot;, value = &quot;abc&quot;*1000
unwrap_python_model()。不，这是实验性的

我该如何解决我的任务？]]></description>
      <guid>https://stackoverflow.com/questions/77919524/how-to-add-metadata-to-a-mlflow-model-safely</guid>
      <pubDate>Thu, 01 Feb 2024 10:47:58 GMT</pubDate>
    </item>
    <item>
      <title>无法启动 Azure Ml studio，这会出现“加载 Azure Ml 工作区时出错”错误</title>
      <link>https://stackoverflow.com/questions/77919192/not-able-to-launch-the-azure-ml-studio-which-gives-me-error-loading-azure-ml-wo</link>
      <description><![CDATA[我对 Azure 机器学习及其与专用终结点的链接不熟悉。我有一个位于专用端点后面的 Azure Ml 工作区，并且公共访问已被禁用，当我尝试启动工作室时，出现加载工作区错误错误。请参阅下图以供参考：
在此处输入图片描述
我不确定可能出了什么问题。任何人都可以指导我吗
谢谢
全科医生]]></description>
      <guid>https://stackoverflow.com/questions/77919192/not-able-to-launch-the-azure-ml-studio-which-gives-me-error-loading-azure-ml-wo</guid>
      <pubDate>Thu, 01 Feb 2024 09:59:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 Haystack Annotation Tool 或替代方案生成 SQuAD 数据的更简单方法</title>
      <link>https://stackoverflow.com/questions/77919016/easier-way-to-use-haystack-annotation-tool-or-alternative-to-generate-squad-data</link>
      <description><![CDATA[这几天我陷入了一个复杂的境地。我是 NLP 问答任务的新手，我想以 SQuAD 格式注释一些段落。经过一番研究，我发现 deepset.ai 的 Haystack Annotation Tool 是实现此目的的最佳选择。
大多数旧教程都建议直接在他们的注释网站上开设帐户。然而，他们不再将其托管在他们的网站上；相反，他们在 GitHub 上提供代码并指导用户在本地使用它。在此页面和视频教程中，他们为用户概述了三个步骤：下载 Docker在桌面上，从此链接克隆 git 存储库，然后使用以下命令docker-compose up。
当我在具有 32GB RAM 的虚拟机上安装并打开 Docker Desktop 时，出现了问题；它显示错误：“Docker Desktop - 意外的 WSL 错误。”经过一番调查，我发现我需要更改 BIOS 来修复它。然而，我的网络工程师告诉我，他们无法对 BIOS 进行任何更改。
随后，我在只有 8GB RAM 的 PC 上安装了 Docker。不幸的是，它消耗了我一半以上的 RAM 和 CPU，使得正确使用变得困难。此外，在 Haystack 注释工具的文档中，他们建议更改数据库信息。不幸的是，我不知道他们指的是哪个数据库。
&lt;块引用&gt;
DEFAULT_ADMIN_EMAIL：“example@example.com”
DEFAULT_ADMIN_PASSWORD：“演示密码”
DB_HOSTNAME：“db”
DB_NAME: &quot;数据库名称&quot;
DB_USERNAME：“somesafeuser”
DB_PASSWORD：“一些安全密码”
POSTGRES_USER：“somesafeuser”
POSTGRES_PASSWORD: “一些安全密码”
POSTGRES_DB：“数据库名称”
COOKIE_KEYS：“somesafecookiekeys”
JWT_SECRET：“一些安全的秘密”

现在，我的问题是，我认为在机器学习中生成问答数据集（如 SQuAD）应该不会那么难使用。为什么没有在线/离线、易于使用、用户友好的 UI？ Deepset.ai 的 HayStack Annotation 工具是唯一可以轻松创建 SQuAD 数据的工具吗？为什么没有其他人让它更容易使用？请帮我;我一直被这个问题困扰并且感到沮丧。非常感谢。
在原始问题中提到了示例和链接。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/77919016/easier-way-to-use-haystack-annotation-tool-or-alternative-to-generate-squad-data</guid>
      <pubDate>Thu, 01 Feb 2024 09:33:33 GMT</pubDate>
    </item>
    <item>
      <title>损失在减少，验证准确率正常，但分类报告统计数据很低</title>
      <link>https://stackoverflow.com/questions/77918946/loss-is-decreasing-and-validation-accuracy-is-normal-but-classification-report</link>
      <description><![CDATA[我有一个多类分类任务，用于预测 21 个类的 ui 元素草图的类型。这是我的数据增强代码
&lt;前&gt;&lt;代码&gt;目标大小 = (224, 224)
target_dims = (224, 224, 3) # 添加 RGB 通道
n_类 = 21
val_frac = 0.1
批量大小 = 64

data_augmentor = ImageDataGenerator(samplewise_center=True,
                                    Samplewise_std_normalization=真，
                                    验证分割=val_frac)

train_generator = data_augmentor.flow_from_directory（data_dir，target_size=target_size，batch_size=batch_size，shuffle=True，subset=“训练”）
val_generator = data_augmentor.flow_from_directory（data_dir，target_size=target_size，batch_size=batch_size，subset=“验证”）

此外，这是我的模型的代码
from tensorflow.keras.callbacks import EarlyStopping

# 定义 EarlyStopping 回调
Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

# 创建你的模型
my_model = 顺序()
my_model.add(Conv2D(64，kernel_size=4，strides=1，activation=&#39;relu&#39;，input_shape=target_dims))
my_model.add(Conv2D(64，kernel_size=4，strides=2，activation=&#39;relu&#39;))
my_model.add(Dropout(0.5))
my_model.add(Conv2D(128，kernel_size=4，strides=1，activation=&#39;relu&#39;))
my_model.add(Conv2D(128，kernel_size=4，strides=2，activation=&#39;relu&#39;))
my_model.add(Dropout(0.5))
my_model.add(Conv2D(256，kernel_size=4，strides=1，activation=&#39;relu&#39;))
my_model.add(Conv2D(256，kernel_size=4，strides=2，activation=&#39;relu&#39;))
my_model.add(Dropout(0.5))
my_model.add(Conv2D(512，kernel_size=4，strides=1，activation=&#39;relu&#39;))
my_model.add(Conv2D(512，kernel_size=4，strides=2，activation=&#39;relu&#39;))
my_model.add(压平())
my_model.add(Dropout(0.5))
my_model.add（密集（512，激活=&#39;relu&#39;））
my_model.add（密集（n_classes，激活=&#39;softmax&#39;））

# 编译模型
my_model.compile（优化器=&#39;adam&#39;，损失=&#39;categorical_crossentropy&#39;，指标=[“准确性”]）


所以主要问题是训练期间验证准确率良好（平均约为 73%）。但如果我随后使用这个模型并创建分类报告，我得到的统计数据非常低，f1、精度和准确度约为 0.5%。造成这种行为的原因是什么？数据集或增强是否存在问题？或者这个模型对于这套模型来说太简单了？]]></description>
      <guid>https://stackoverflow.com/questions/77918946/loss-is-decreasing-and-validation-accuracy-is-normal-but-classification-report</guid>
      <pubDate>Thu, 01 Feb 2024 09:24:02 GMT</pubDate>
    </item>
    <item>
      <title>LSTM不断绘制纯直线，结果等于0</title>
      <link>https://stackoverflow.com/questions/77918581/lstm-keeps-plotting-the-pure-straight-line-with-the-result-equals-to-0</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77918581/lstm-keeps-plotting-the-pure-straight-line-with-the-result-equals-to-0</guid>
      <pubDate>Thu, 01 Feb 2024 08:14:26 GMT</pubDate>
    </item>
    <item>
      <title>在为超正方体创建 .box 文件时，是否可以选择/绘制除矩形或正方形之外的其他图形？</title>
      <link>https://stackoverflow.com/questions/77918390/is-it-possible-to-select-draw-other-figures-other-than-rectangles-or-squares-whe</link>
      <description><![CDATA[我正在尝试构建自定义数据集，然后对其进行训练，以改进tesseract 的 OCR。
请注意，我在机器学习方面的经验很少，尤其是在神经网络方面。
我尝试识别的图像上的文本如下：








正如您所看到的，文本被扭曲并且有一条或多条线穿过其中。问题是，当我标记每个字符以创建 .box 文件时，由于扭曲，我还会得到其他字符的片段。
例如：

所以我想知道是否可以绘制不同类型的边界框。]]></description>
      <guid>https://stackoverflow.com/questions/77918390/is-it-possible-to-select-draw-other-figures-other-than-rectangles-or-squares-whe</guid>
      <pubDate>Thu, 01 Feb 2024 07:37:21 GMT</pubDate>
    </item>
    <item>
      <title>对交叉熵损失真的很困惑</title>
      <link>https://stackoverflow.com/questions/77917816/really-confused-about-cross-entropy-loss</link>
      <description><![CDATA[我遇到了我的项目面临的关于交叉熵损失的三个详细实现。顺便说一下，needle 是我要构建的东西，所以你可以把它看作像 pytorch 一样的东西。
那么谁能解释一下为什么？
第一个版本：
def softmax_loss(Z, y_one_hot):
    ”“”返回softmax损失。请注意，出于本次作业的目的，
    你不需要担心“很好”缩放数值属性
    log-sum-exp 计算的一部分，但可以直接计算它。

    参数：
        Z (ndl.Tensor[np.float32]): 形状的 2D 张量
            (batch_size, num_classes)，包含 logit 预测
            每堂课。
        y (ndl.Tensor[np.int8]): 形状的 2D 张量 (batch_size, num_classes)
            每个示例的真实标签索引处包含 1，并且
            其他地方为零。

    返回：
        样本上的平均 softmax 损失。 (ndl.张量[np.float32])
    ”“”
    ### 开始你的解决方案
    # 假设二元选择，之前 y 表示真实标签，例如
    # [0, 1, 0, 1, 0]
    # 返回 np.mean(np.log(np.sum(np.exp(Z), axis=1)) - Z[np.arange(y.size), y])
    #
    # 然而，这个问题应用了 ndl 并使用 one-hot y 作为张量，例如
    # [[1, 0],
    # [0, 1],
    # [1, 0],
    # [0, 1],
    # [1, 0]]
    # 这种情况下，直接执行矩阵乘法。
    #
    # 顺便说一下，如果这里设置axes=1的话，是不会通过测试的。这是因为轴应该是
    # 这里是一个可迭代对象，如果没有优化， int 绝不是可迭代的，因此我们应用
    # 元组轴=(1,)。
    lhs = ndl.log(ndl.exp(Z).sum(axes=(1,))).sum() # 求和到 (B, 1)，然后是标量
    rhs = (y_one_hot * Z).sum() # EW (B, k) 然后是标量
    
    return (lhs - rhs) / Z.shape[0] # 除以批量大小
    ### 结束你的解决方案

第二个版本：
def softmax_loss(Z, y):
    ”“”返回softmax损失。请注意，出于本次作业的目的，
    你不需要担心“很好”缩放数值属性
    log-sum-exp 计算的一部分，但可以直接计算它。

    参数：
        Z (np.ndarray[np.float32]): 形状的 2D numpy 数组
            (batch_size, num_classes)，包含 logit 预测
            每堂课。
        y (np.ndarray[np.uint8]): 形状为 (batch_size, ) 的一维 numpy 数组
            包含每个示例的真实标签。

    返回：
        样本上的平均 softmax 损失。
    ”“”
    ### 开始你的代码
    # 例如，假设 exp_logits 和 y 是
    # [[0.3, 0.2, 0.5] [2, 1, 1, 1]
    # [0.1, 0.6, 0.3]
    # [0.4, 0.3, 0.3]
    # [0.1, 0.7, 0.2]]
    # 高级索引从行[0, 1, 2, 3]和列[2, 1, 1, 1]获取元素，
    # 表示真实分类的预测点。
    lhs = np.log(np.sum(np.exp(Z), axis=1)) # 求和为形状 (B, 1)
    rhs = Z[np.arange(y.size), y] # 形状 (B, 1)
    # 这是预测点相减然后求平均值；
    # 如果先求均值再减，就减一。
    avg_loss = np.mean(左轴 - 右轴)
    
    返回平均损失
    ### 结束你的代码

第三个版本：
&lt;前&gt;&lt;代码&gt;
/* 由于矩阵在 C++ 中表示为数组，因此它将指向每次迭代的开始。 */
const float *X_batch = &amp;X[iter * batch * n];

/* 要计算 exp_logits，首先初始化形状为 (B, k) = (B, n) * (n, k) 的数组。 */
float *exp_logits = new float[batch * k];
mat_mul(X_batch, theta, exp_logits, 批次, n, k); // 实际上在这里记录
/* 在数组的 from 中对 (B, k) exp_logits 进行一一指数运算。 */
for (size_t i = 0; i &lt; 批 * k; i++) exp_logits[i] = exp(exp_logits[i]);

/* 对 axis=1 的矩阵求和，即在 &#39;k&#39; 的维度上。 */
for (size_t i = 0; i &lt; 批次; i++) {
    浮点总和=0；
    for (size_t j = 0; j &lt; k; j++) sum += exp_logits[i * k + j];
    for (size_t j = 0; j &lt; k; j++) exp_logits[i * k + j] /= sum; // grad 实际上在这里
}
/* exp_logits 总是在迭代中更新，但我们需要预先为 y 添加 iter*batch。
    * 例如，假设 exp_logits 和 y 是
    * [[0.3, 0.2, 0.5] [[2]
    * [0.1, 0.6, 0.3] [1]
    * [0.4, 0.3, 0.3] [1]
    * [0.1, 0.7, 0.2]] [1]]
    * 减去后，损失将如下所示
    * [[0.3, 0.2, -0.5]
    * [0.1，-0.4，0.3]
    * [0.4，-0.7，0.3]
    * [0.1,-0.3,0.2]]
    */
for (size_t i = 0; i &lt; 批次; i++) exp_logits[i * k + y[iter * 批次 + i]] -= 1;

我希望有人能好心地提示我一下。]]></description>
      <guid>https://stackoverflow.com/questions/77917816/really-confused-about-cross-entropy-loss</guid>
      <pubDate>Thu, 01 Feb 2024 05:04:35 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv1是否需要在每个单元格中训练样本？或者它可以概括来自其他细胞的训练样本吗？</title>
      <link>https://stackoverflow.com/questions/77917722/does-yolov1-need-training-examples-in-every-cell-or-can-it-generalize-training</link>
      <description><![CDATA[由于每个特定单元的输出权重不在其他单元之间共享，因此我的理解是 YOLO 网络需要每个单元中每个类的训练示例。这感觉效率很低，尤其是对于拥有很多很多小区的网络。
当每个班级没有太多训练示例时，人们如何解决这个问题？也许通过使用大量翻译图像来增强训练集？
YOLO 论文似乎没有提及数据增强。也许他们的训练集非常完整，并且包含每个单元中每个类别的示例。]]></description>
      <guid>https://stackoverflow.com/questions/77917722/does-yolov1-need-training-examples-in-every-cell-or-can-it-generalize-training</guid>
      <pubDate>Thu, 01 Feb 2024 04:25:01 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch RuntimeError：函数“NativeBatchNormBackward0”在其第 0 个输出中返回了 nan 值[关闭]</title>
      <link>https://stackoverflow.com/questions/77914164/pytorch-runtimeerror-function-nativebatchnormbackward0-returned-nan-values-in</link>
      <description><![CDATA[我尝试从一篇提供 Tensorflow 代码的论文中实现一个卷积神经网络，并将其转换为 Pytorch。
我尝试重现的是：
https://github.com/akensert/deep-learning-peak-检测/树/主
这个想法是将 8192 个元素数组交给神经网络，神经网络检测不同的峰值及其沿该数组的位置。存储库提供了两个示例数组，但我无法运行神经网络，因为第一层已经产生错误。我在下面的示例中包含了第一层，它重现了与以下层完全相同的错误行为。
使用 torch.autograd.detect_anomaly() 我收到错误：
RuntimeError：函数“NativeBatchNormBackward0”在第 0 个输出中返回了 nan 值。
第一次调用loss.backward()期间。
我无法找出此错误背后的原因，因为我在网络上找不到任何有关它的信息。
所讨论的架构是在 conv1d() 期间 -&gt; BatchNorm1d() -&gt;; ReLU() -&gt;; MaxPool1d() 顺序。如果我注释掉 BatchNorm1d() 层，则不会发生错误。
我运行一个自定义损失函数，根据三个特征的两个 BCELosses 和一个 MSELoss 计算加权损失。
损失本身以数字形式返回，并且表现符合预期。
这是一个使用第一个卷积层和自定义损失重现代码的示例：
导入火炬
将 torch.nn 导入为 nn
将 numpy 导入为 np


类 CustomLoss(torch.nn.Module):
    def __init__(自身):
        超级().__init__()

    def 前向（自我，y_pred，y_true，n_splits，weight_prob = 1.0，weight_loc = 1.0，weight_area = 1.0）：
        y_true = torch.Tensor(y_true)
        y_pred = torch.Tensor(y_pred)

        pred_prob、pred_loc、pred_area = torch.tensor_split(y_pred、n_splits、dim=1)
        true_prob、true_loc、true_area = torch.tensor_split(y_true、n_splits、dim=1)

        掩码 = true_prob.eq(1.)

        prob_loss = torch.nn.BCELoss()(true_prob, pred_prob)
        loc_loss = torch.nn.BCELoss()(
            torch.masked_select(true_loc, mask), torch.masked_select(pred_loc, mask))
        area_loss = torch.nn.MSELoss()(
            torch.masked_select(true_area, mask), torch.masked_select(pred_area, mask))

        返回 （
                概率损失 * 权重概率 +
                loc_loss * 权重_loc +
                面积损失 * 重量面积
        ）


类 PeakDetection(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.n_splits = 3
        self.conv_block1 = nn.Sequential(
            nn.Conv1d(in_channels=1,
                      输出通道=3，
                      内核大小=9，
                      步幅=2，
                      填充=4),
            nn.BatchNorm1d(3),
            ReLU(),
            nn.MaxPool1d（内核大小=16）
        ）

    def 前向（自身，x）：
        输出 = self.conv_block1(x)
        输出 = self.CustomActivation(输出)
        返回输出

    def CustomActivation（自身，输入）：
        pred, loc, 区域 = torch.tensor_split(输入, self.n_splits, dim=1)
        pred = torch.sigmoid(pred)
        loc = torch.sigmoid(loc)
        return torch.concat([pred, loc, area], dim=1)


torch.autograd.detect_anomaly(True)
# torch.manual_seed(42)
模型 = PeakDetection()

优化器 = torch.optim.Adam(params=model.parameters(), lr=0.01)

X = np.ones((32, 1, 8192))
y = np.ones((32, 3, 256))

使用 torch.autograd.detect_anomaly()：
    y_pred = 模型(火炬.张量(X))
    损失 = CustomLoss()(y_pred, torch.Tensor(y), n_splits=3)
    优化器.zero_grad()
    loss.backward()
    优化器.step()

manual_seed(42) 总是会产生相关的 NativeBatchNormBackward0 错误。]]></description>
      <guid>https://stackoverflow.com/questions/77914164/pytorch-runtimeerror-function-nativebatchnormbackward0-returned-nan-values-in</guid>
      <pubDate>Wed, 31 Jan 2024 14:33:58 GMT</pubDate>
    </item>
    <item>
      <title>从预测数组重建图像 - 填充相同显示重建图像中的网格图块</title>
      <link>https://stackoverflow.com/questions/77878901/image-reconstruction-from-predicted-array-padding-same-shows-grid-tiles-in-rec</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77878901/image-reconstruction-from-predicted-array-padding-same-shows-grid-tiles-in-rec</guid>
      <pubDate>Thu, 25 Jan 2024 09:43:55 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：缓冲区数据类型不匹配，预期为“double_t”，但得到“float” - hdbscanValidity_index</title>
      <link>https://stackoverflow.com/questions/76242882/valueerror-buffer-dtype-mismatch-expected-double-t-but-got-float-hdbscan</link>
      <description><![CDATA[我使用hdbscan包中的有效性索引，它根据以下论文实现DBCV评分：
https://www.dbs.ifi.lmu.de /~zimek/publications/SDM2014/DBCV.pdf
我正在做一个人脸聚类项目，使用有效性索引后提示错误。
这是代码：
dbcv_score_output = hdbscan.validity.validity_index(feature_vectors, archive_labels)
dbcv_分数_输出

完整错误：
hdbscan/validity.py:30: Ru​​ntimeWarning: 电源遇到溢出
  距离矩阵[距离矩阵！= 0] = (1.0 / 距离矩阵[

-------------------------------------------------- ------------------------
ValueError Traceback（最近一次调用最后一次）
文件〜/anaconda3/lib/python3.9/site-packages/hdbscan/validity.py:371，在validation_index（X，标签，指标，d，per_cluster_scores，mst_raw_dist，详细，** kwd_args）
    第356章 继续
    第358章
    [第 359 章]
    360X，
   （...）
    第367章
    第368章）
    [第 370 章]
--&gt;第371章
    [第 372 章]
    [第 374 章]

文件〜/anaconda3/lib/python3.9/site-packages/hdbscan/validity.py:165，在internal_minimum_spanning_tree(mr_distances)中
    136 def 内部最小跨度树（mr_distances）：
    第137章
    第138章
    139 个可达距离。给定最小生成树“内部”
   （...）
...
    167 为索引，枚举中的行(min_span_tree[1:], 1)：

文件 hdbscan/_hdbscan_linkage.pyx:15，在 hdbscan._hdbscan_linkage.mst_linkage_core()

ValueError：缓冲区数据类型不匹配，预期为“double_t”，但得到“float”

快速浏览输入及其类型：

特点：
dtype=float32
形状：（70201、320）


档案/集群（它是标签编码的）：
形状：(70201,)


当我尝试将功能类型更改为 double/float64 时，它显示了不同类型的错误：
hdbscan/validity.py:33: RuntimeWarning: true_divide 中遇到无效值
  结果 /= distance_matrix.shape[0] - 1
-------------------------------------------------- ------------------------
ValueError Traceback（最近一次调用最后一次）
文件〜/anaconda3/lib/python3.9/site-packages/hdbscan/validity.py:372，在validation_index（X，标签，指标，d，per_cluster_scores，mst_raw_dist，详细，** kwd_args）
    第358章
    [第 359 章]
    360X，
   （...）
    第367章
    第368章）
    [第 370 章]
    第371章
--&gt; [第 372 章]
    [第 374 章]
    第376章

文件〜/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:40，在_amax（a，轴，out，keepdims，初始，其中）
     38 def _amax(a, axis=None, out=None, keepdims=False,
     39 初始=_NoValue，其中=True）：
---&gt; 40 return umr_maximum(a, axis, None, out, keepdims, initial, where)

ValueError：零大小数组到没有标识的缩减操作最大值

我检查了存储库中的所有相关问题和修复，但没有效果。有什么建议或修复吗？]]></description>
      <guid>https://stackoverflow.com/questions/76242882/valueerror-buffer-dtype-mismatch-expected-double-t-but-got-float-hdbscan</guid>
      <pubDate>Sat, 13 May 2023 13:04:50 GMT</pubDate>
    </item>
    <item>
      <title>将经过训练的机器学习模型与 React Native 应用程序集成</title>
      <link>https://stackoverflow.com/questions/74961856/to-integrate-a-trained-machine-learning-model-with-react-native-app</link>
      <description><![CDATA[我有一个 FYP 项目（Instagram 等社交媒体应用程序），需要我创建一个简单的推荐系统。我已经使用 Python 对余弦相似度数据集进行了训练，但我不知道下一步该做什么。如何将经过训练的机器学习模型集成到 React Native 中，或者是否有更好、更简单的方法来制作推荐系统？
我尝试阅读文档和观看视频。但我似乎仍然无法掌握一些困难的概念。如果您能在训练我的模型后向我提供有关学习内容的说明或步骤，我将不胜感激。或者，如果我必须使用一些库或软件包等。[不确定这是否是适合此查询的论坛]]]></description>
      <guid>https://stackoverflow.com/questions/74961856/to-integrate-a-trained-machine-learning-model-with-react-native-app</guid>
      <pubDate>Fri, 30 Dec 2022 13:02:29 GMT</pubDate>
    </item>
    </channel>
</rss>