<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 15 Apr 2024 09:13:21 GMT</lastBuildDate>
    <item>
      <title>寻求建议：建立一个模型来区分手写数字和印刷数字</title>
      <link>https://stackoverflow.com/questions/78327181/seeking-advice-building-a-model-to-differentiate-handwritten-vs-printed-digits</link>
      <description><![CDATA[我正在开发一种机器学习模型，可以准确识别图像中的数字是手写的还是打印的。尽管可以访问 Char74K 和 MNIST 等数据集，但我仍在努力让我的模型表现良好。
我对基本机器学习模型有一些经验，但我发现这个特殊的挑战有点令人畏惧。
模型尝试：鉴于卷积神经网络 (CNN) 在基于图像的任务中取得的成功，我尝试使用它，但结果并不理想。
我正在寻求以下方面的建议：
最佳模型架构：是否有适合此类任务的特定架构或层？
有效的预处理：关于可能提高模型性能的预处理技术有什么建议吗？
数据集平衡和增强：有关如何平衡和增强这些数据集以获得更好训练结果的提示。
如果有人解决过类似问题或了解相关文献或教程，我将非常感谢您的见解。
非常感谢您花时间阅读并回复。任何指导或参考将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78327181/seeking-advice-building-a-model-to-differentiate-handwritten-vs-printed-digits</guid>
      <pubDate>Mon, 15 Apr 2024 08:52:41 GMT</pubDate>
    </item>
    <item>
      <title>基于人工智能的扩展的模型建议</title>
      <link>https://stackoverflow.com/questions/78326814/model-suggestion-for-ai-based-scaling</link>
      <description><![CDATA[我们正在探索根据给定大小缩放 UI 容器内元素的想法。
容器用json对象表示，例如：
&lt;前&gt;&lt;代码&gt;{
   “尺寸”：“小”，
   “元素”：[
      {
         “类型”：“图像”，
         “x”：348，
         “y”：36，
         “宽度”：607，
         “高度”：201
      },
      {
         “类型”：“文本”，
         “x”：45，
         “y”：100，
         “宽度”：100，
         “高度”：104
      }
   ]
}

我们将为 medium 和 large 尺寸提供类似的 JSON，并调整 x,y 坐标和 width 以及JSON 中每个元素的 height。
目前，这些调整是通过基于规则的算法来处理的，该算法有时效果不佳，我们必须手动调整坐标或尺寸。
是否有任何机器学习模型可以有效地解决这个问题，并在我们用足够的数据训练它的情况下建议坐标和尺寸？]]></description>
      <guid>https://stackoverflow.com/questions/78326814/model-suggestion-for-ai-based-scaling</guid>
      <pubDate>Mon, 15 Apr 2024 07:44:35 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法仅使用 LangChain 或其他 OpenAI API 上的口头指令来自动化整个机器学习/数据可视化流程工作流程？</title>
      <link>https://stackoverflow.com/questions/78326755/is-there-any-way-to-automate-the-entire-ml-data-visualization-process-workflow-u</link>
      <description><![CDATA[我打算在应用程序中使用开放式 AI API/插件来自动化整个机器学习工作流程，其中包括图像分类和基于规则的系统，以根据数据结果生成通用推荐和智能洞察。
我找到了通过 YouTube 实现的示例，但不确定如何将其用于定制应用程序。
导入操作系统
导入系统

导入openai
从 langchain.chains 导入 ConversationalRetrievalChain，RetrievalQA
从 langchain.chat_models 导入 ChatOpenAI
从 langchain.document_loaders 导入 DirectoryLoader、TextLoader
从 langchain.embeddings 导入 OpenAIEmbeddings
从 langchain.indexes 导入 VectorstoreIndexCreator
从 langchain.indexes.vectorstore 导入 VectorStoreIndexWrapper
从 langchain.llms 导入 OpenAI
从 langchain.vectorstores 导入 Chroma

导入常量

os.environ[“OPENAI_API_KEY”] = Constants.APIKEY

# 启用保存到磁盘&amp;重用模型（对相同数据进行重复查询）
坚持=错误

查询=无
如果 len(sys.argv) &gt; 1：
  查询 = sys.argv[1]

如果 PERSIST 和 os.path.exists(“persist”)：
  print(&quot;重用索引...\n&quot;)
  Vectorstore = Chroma(persist_directory=“持久”, embedding_function=OpenAIEmbeddings())
  索引 = VectorStoreIndexWrapper(向量存储=向量存储)
别的：
  #loader = TextLoader(&quot;data/data.txt&quot;) # 如果您只需要 data.txt，请使用此行
  loader = DirectoryLoader(“数据/”)
  如果坚持：
    index = VectorstoreIndexCreator(vectorstore_kwargs={“persist_directory”:“persist”}).from_loaders([loader])
  别的：
    索引 = VectorstoreIndexCreator().from_loaders([loader])

链 = ConversationalRetrievalChain.from_llm(
  llm=ChatOpenAI(模型=“gpt-3.5-turbo”),
  检索器=index.vectorstore.as_retriever(search_kwargs={“k”: 1}),
）

聊天记录 = []
而真实：
  如果没有查询：
    查询=输入（“提示：”）
  if 在 [&#39;quit&#39;, &#39;q&#39;, &#39;exit&#39;] 中查询：
    sys.exit()
  结果=链（{“问题”：查询，“聊天历史记录”：聊天历史记录}）
  打印（结果[&#39;答案&#39;]）

  chat_history.append((查询, 结果[&#39;答案&#39;]))
  查询=无

我不熟悉实现以及使用插件是否可行，因此欢迎任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/78326755/is-there-any-way-to-automate-the-entire-ml-data-visualization-process-workflow-u</guid>
      <pubDate>Mon, 15 Apr 2024 07:33:28 GMT</pubDate>
    </item>
    <item>
      <title>如何找到 RBF 核 SVM 的准确性？</title>
      <link>https://stackoverflow.com/questions/78325995/how-can-i-find-accuracy-in-rbf-kernal-svm</link>
      <description><![CDATA[我正在尝试使用 SVM 实现人体检测。我正在使用 HOG 特征提取，然后对其应用 SVM。当我应用线性 SVM 时，我会得到图像的分数，但在 RBF kernal SVM 中我只能得到 0 和 1。无论如何我可以获得检测分数吗？我怎样才能像线性SVM一样看到RBF核的系数？
我尝试了Python提供的SVM库。]]></description>
      <guid>https://stackoverflow.com/questions/78325995/how-can-i-find-accuracy-in-rbf-kernal-svm</guid>
      <pubDate>Mon, 15 Apr 2024 03:45:27 GMT</pubDate>
    </item>
    <item>
      <title>在 VSCode 终端中卡住“git init”</title>
      <link>https://stackoverflow.com/questions/78325941/stuck-with-git-init-in-vscode-terminal</link>
      <description><![CDATA[我开始学习 ML，为此我使用 anaconda 提示符和 vscode 终端创建了一个 conda 环境。但是，当尝试将其链接到我的 github 存储库时，出现以下错误。这是错误运行“git init”时。
我尝试检查系统中的 PATH 变量，并且 git 已添加到路径中。想不出其他什么了。任何进一步的内容都会有很大帮助，谢谢！！]]></description>
      <guid>https://stackoverflow.com/questions/78325941/stuck-with-git-init-in-vscode-terminal</guid>
      <pubDate>Mon, 15 Apr 2024 03:21:57 GMT</pubDate>
    </item>
    <item>
      <title>torch.nn.function.binary_cross_entropy 如何处理大小为 N x 2 的输出和标签？</title>
      <link>https://stackoverflow.com/questions/78325848/how-does-torch-nn-functional-binary-cross-entropy-treat-outputs-and-labels-of-si</link>
      <description><![CDATA[分类器模型输出 N x 2 数组，同样数据集的标签具有相同的形状，每一行 [-ve, +ve] 代表一个分类实例，因此如果该行是，则数组中的左列有 1真负数，右边为零&amp;反之亦然。
使用torch.nn.function.binary_cross_entropy，但我需要使用权重参数，因为这些类非常不平衡13:1 -ve:+ve。我正在使用权重数组 torch.tensor([1.,13.]) 权重 13 是否应用于数组右列的所有条目或具有 1 的所有条目与列无关？文档中不清楚实现细节。]]></description>
      <guid>https://stackoverflow.com/questions/78325848/how-does-torch-nn-functional-binary-cross-entropy-treat-outputs-and-labels-of-si</guid>
      <pubDate>Mon, 15 Apr 2024 02:35:47 GMT</pubDate>
    </item>
    <item>
      <title>在测试数据集上进行评估时，模型显示零准确度和几乎零损失？</title>
      <link>https://stackoverflow.com/questions/78325622/model-showing-zero-accuracy-and-almost-zero-loss-when-evaluated-on-the-testing-d</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78325622/model-showing-zero-accuracy-and-almost-zero-loss-when-evaluated-on-the-testing-d</guid>
      <pubDate>Mon, 15 Apr 2024 00:22:30 GMT</pubDate>
    </item>
    <item>
      <title>如何结合2种模型机器学习？</title>
      <link>https://stackoverflow.com/questions/78325594/how-to-combine-2-model-machine-learning</link>
      <description><![CDATA[我是机器学习的初学者。我有 2 个用于预测水可饮用性的机器学习模型，模型 1 使用决策树，模型 2 使用随机森林。那么如何组合该模型来制作新模型呢？我可以用它制作一个新模型吗？我使用Python编程。
组合 2 个模型来制作一个新模型。]]></description>
      <guid>https://stackoverflow.com/questions/78325594/how-to-combine-2-model-machine-learning</guid>
      <pubDate>Mon, 15 Apr 2024 00:09:16 GMT</pubDate>
    </item>
    <item>
      <title>Sklearm FeatureHasher 无法处理数据框中的单个列</title>
      <link>https://stackoverflow.com/questions/78324647/sklearm-featurehasher-not-working-on-a-single-column-in-a-dataframe</link>
      <description><![CDATA[我尝试在数据框中的单个列上执行特征哈希器，但它不断给出错误：
&lt;块引用&gt;
ValueError：样本不能是单个字符串。输入必须是字符串可迭代对象上的可迭代对象。

from sklearn.feature_extraction import FeatureHasher

哈希向量大小 = 50
fh = FeatureHasher(n_features=hash_vector_size, input_type=&#39;string&#39;)
hashed_df = pd.DataFrame(fh.transform(X_train[“Item_Identifier”]).toarray(),
                         columns=[&#39;H&#39;+str(i) for i in range (hash_vector_size)])

我期望一个包含 50 列的数据框，其中的数据将被散列]]></description>
      <guid>https://stackoverflow.com/questions/78324647/sklearm-featurehasher-not-working-on-a-single-column-in-a-dataframe</guid>
      <pubDate>Sun, 14 Apr 2024 17:20:17 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在随机森林的核心中使用 adaBoosting 而不是 bootstrap？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</link>
      <description><![CDATA[随机森林使用 Bagging（Bootstrapping）为其每棵树选择样本，对吗？是否可以使用 adaBoosting 代替？有什么优点和优点？缺点？为什么我没看到这个？
我看到 Sci-kit learn 中的 RandomForestClassifier 允许启用/禁用引导程序，否则没有选项可以用 boosting 替换它。
我这么问是因为我在大学里学过，在选择样本来创建树时，装袋和提升是两种可能的选择，但到目前为止我发现的似乎与此相反。]]></description>
      <guid>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</guid>
      <pubDate>Sat, 13 Apr 2024 04:19:58 GMT</pubDate>
    </item>
    <item>
      <title>识别随机森林中错误分类的样本</title>
      <link>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</link>
      <description><![CDATA[我正在 RStudio 中执行随机森林分析，我可以使用下面的代码提取混淆矩阵。我可以看到有多少样本被错误分类，但是我可以使用什么代码来识别哪些特定样本被错误分类？
库（随机森林）
库（rfPermute）

rfmetrics &lt;- randomForest(x, y, ntree=ntree,重要性=T)
打印（rfmetrics）

称呼：
 randomForest(x = x, y = y, ntree = ntree, 重要性 = T)
               随机森林类型：分类
                     树木数量：1999
每次分割尝试的变量数量：25

        OOB 估计错误率：56.88%
混淆矩阵：
  1 2 3 4 类.错误
1 8 7 7 4 0.6923077
2 4 19 2 4 0.3448276
3 3 3 15 6 0.4444444
4 3 9 10 5 0.8148148
]]></description>
      <guid>https://stackoverflow.com/questions/78306767/identifying-misclassified-samples-in-randomforest</guid>
      <pubDate>Wed, 10 Apr 2024 19:44:24 GMT</pubDate>
    </item>
    <item>
      <title>我可以重新训练 AutoModelForSequenceClassification 以生成文本吗？</title>
      <link>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</link>
      <description><![CDATA[我的目标是微调 Mistral 7b 以编写短意识流（文本完成，而不是遵循指令）。
我有一个大型数据库（100 万行），其中包含从互联网上抓取的短文本。我手动将 15k 行标记为 good (1k) 和 bad（其余 14k）示例。我的计划是训练 AutoModelForSequenceClassification在这些示例上标记其他 985k 行。
通过这种方式，我希望收集大约 20k 意识流的好例子来微调 Mistral 7b。
但仅对good示例进行微调并不会使用bad示例中的信息，这些示例的数量要多得多。因此，我正在考虑使用 Mistral 7b 作为 AutoModelForSequenceClassification 的基本模型（遵循 这篇 Medium 文章），然后重新训练生成的 AutoModelForSequenceClassification 以进行文本补全。这需要移除分类头并添加新的/重新训练的 LoRA 组件。
您认为这可行吗？这是否会削弱模型（例如，需要重新学习语法），或者这是否是将坏反例的信息合并到文本生成中的有效方法？或者至少为 LoRA 文本生成微调提供一个良好的初始化点？]]></description>
      <guid>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</guid>
      <pubDate>Sat, 06 Apr 2024 11:32:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 max_new_tokens 的 LLM 输出不完整</title>
      <link>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</link>
      <description><![CDATA[我正在尝试 Huggingface LLM 模型。
我注意到的一个问题是模型的输出突然结束，我理想地希望它完成其之间的段落/句子/代码。 （或者完全尝试在一些固定数量的标记内完成答案）
虽然我已经提供了 max_new_tokens = 300 并且在提示中我写道：
“输出最多应为 300 个字。”
响应总是不完整并且突然结束。我可以通过什么方式要求在所需数量的输出令牌内获得完整的输出？
代码：
检查点=“HuggingFaceH4/starchat-alpha”
设备=“cuda”； if torch.cuda.is_available() else “cpu”
StarCoderModel 类：
  def __init__(自身):
    self.tokenizer = AutoTokenizer.from_pretrained(检查点)
    # 如果需要 GPU，请确保 docker run 命令中提供了 `--gpus all`
    self.model = AutoModelForCausalLM.from_pretrained(检查点, device_map=&#39;auto&#39;)

  def infer(self, input_text, token_count):
    输入 = self.tokenizer.encode(input_text, return_tensors=“pt”).to(device)
    输出 = self.model.generate(输入, max_new_tokens=token_count, pad_token_id=self.tokenizer.eos_token_id)
    返回 self.tokenizer.decode(outputs[0])[len(input_text):]

样本输出：
私有数据类型FuntionName(String someId) {
    // TODO：替换为利用 someId 获取信息的实现
    返回数据类型.Value；
}


评论：

- 如果代码中存在 someId，则使用 Client 的 getAPI 以 someId 作为参数来获取一些信息。
- 如果

]]></description>
      <guid>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</guid>
      <pubDate>Thu, 07 Sep 2023 18:02:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 bootstrap 方法得出置信区间 AUC</title>
      <link>https://stackoverflow.com/questions/75309099/confidence-interval-auc-with-the-bootstrap-method</link>
      <description><![CDATA[今天我尝试制作一个 bootstrap 来获取各种不同 ML 算法 AUC 的区间置信度。
我使用了我的个人医疗数据集，其中包含 61 个特征，格式如下：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

年龄
女性


&lt;正文&gt;

65
1


45
0




例如，我使用了这种类型的算法：
X = data_sevrage.drop([&#39;Echec_sevrage&#39;], axis=1)

y = data_sevrage[&#39;Echec_sevrage&#39;]

X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.25, random_state=0)

lr = LogisticRegression(C=10 ,penalty=&#39;l1&#39;,solver=&#39;saga&#39;, max_iter=500).fit(X_train,y_train)
分数=roc_auc_score(y_test,lr.predict_proba(X_test)[:,1])
精度、召回率、阈值 = precision_recall_curve(y_test, lr.predict_proba(X_test)[:,1])
auc_ precision_recall = Metrics.auc(召回率, 精度)
y_pred = lr.predict(X_test)
print(&#39;ROC AUC 分数:&#39;,分数)
print(&#39;auc_ precision_recall :&#39;,auc_ precision_recall)

最后，当我使用 boostrap 方法获取置信区间时（我从其他主题获取代码：如何在Python中比较不同二元分类器的ROC AUC分数并评估统计显着性？）
def bootstrap_auc(clf, X_train, y_train, X_test, y_test, nsamples=1000):
    auc_值 = []
    对于范围内的 b（n 个样本）：
        idx = np.random.randint(X_train.shape[0], size=X_train.shape[0])
        clf.fit(X_train[idx], y_train[idx])
        pred = clf.predict_proba(X_test)[:, 1]
        roc_auc = roc_auc_score(y_test.ravel(), pred.ravel())
        auc_values.append(roc_auc)
    返回 np.percentile(auc_values, (2.5, 97.5))

bootstrap_auc(lr, X_train, y_train, X_test, y_test, nsamples=1000)

我有这个错误：
&lt;块引用&gt;
“没有 [Int64Index([21, 22, 20, 31, 30, 13, 22, 1, 31, 3, 2, 9, 9, 18, 29, 30, 31,\n 31, 16 , 11, 23, 7, 19, 10, 14, 5, 10, 25, 30, 24, 8, 20],\n dtype=&#39;int64&#39;)] 在[列]中”

我使用了另一种方法，并且出现了几乎相同的错误：
&lt;前&gt;&lt;代码&gt; n_bootstraps = 1000
rng_seed = 42 # 控制再现性
bootstrapped_scores = []

rng = np.random.RandomState(rng_seed)
对于范围内的 i(n_bootstraps)：
    # 通过对预测索引进行替换采样来引导
    索引 = rng.randint(0, len(y_pred), len(y_pred))
    if len(np.unique(y_test[索引])) &lt; 2：
        # ROC AUC 至少需要 1 个正样本和 1 个负样本
        # 待定义：拒绝样本
        继续

    分数 = roc_auc_score(y_test[索引], y_pred[索引])
    bootstrapped_scores.append(分数)
    print(&quot;Bootstrap #{} ROC 区域: {:0.3f}&quot;.format(i + 1, Score))

&lt;块引用&gt;
“[6, 3, 12, 14, 10, 7, 9] 不在索引中”

你能帮我一下吗？我测试了很多解决方案，但每次都会出现此错误。
谢谢！
机器学习算法上 AUC 置信区间的 Bootstrap 方法。]]></description>
      <guid>https://stackoverflow.com/questions/75309099/confidence-interval-auc-with-the-bootstrap-method</guid>
      <pubDate>Wed, 01 Feb 2023 10:51:08 GMT</pubDate>
    </item>
    <item>
      <title>将 Scikit-Learn OneHotEncoder 与 Pandas DataFrame 结合使用</title>
      <link>https://stackoverflow.com/questions/58101126/using-scikit-learn-onehotencoder-with-a-pandas-dataframe</link>
      <description><![CDATA[我正在尝试使用 Scikit-Learn 的 OneHotEncoder 将 Pandas DataFrame 中包含字符串的列替换为 one-hot 编码的等效项。我的下面的代码不起作用：
从 sklearn.preprocessing 导入 OneHotEncoder
# 数据是 Pandas DataFrame

jobs_encoder = OneHotEncoder()
jobs_encoder.fit(data[&#39;职业&#39;].unique().reshape(1, -1))
data[&#39;职业&#39;] = jobs_encoder.transform(data[&#39;职业&#39;].to_numpy().reshape(-1, 1))

它会产生以下错误（列表中的字符串被省略）：
------------------------------------------------ ----------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-91-3a1f568322f5&gt;在&lt;模块&gt;()中
      3 jobs_encoder = OneHotEncoder()
      4 jobs_encoder.fit(data[&#39;职业&#39;].unique().reshape(1, -1))
----&gt; 5 数据[&#39;职业&#39;] = jobs_encoder.transform(数据[&#39;职业&#39;].to_numpy().reshape(-1, 1))

/usr/local/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py 变换（self，X）
    第730章 复制=真）
    第731章：
--&gt;第732章
    第733章
    第734章

/usr/local/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py 在 _transform_new(self, X)
    第678章
    第679章
--&gt;第680章
    第681章
    第682章

_transform 中的/usr/local/anaconda3/envs/ml/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py（self，X，handle_unknown）
    120 msg =（“在第{1}列中发现未知类别{0}”
    正文 正文_第 121 章
--&gt; 122 引发值错误（消息）
    123 其他：
    攀上漂亮女局长之后124

ValueError: 在转换过程中在第 0 列中发现未知类别 [&#39;...&#39;, ..., &#39;...&#39;]

以下是一些示例数据：
数据[&#39;职业&#39;] =

0 未知
1 个保险箱
2 接收
3 未知
4 导联
          ...
111988工业
111989 先生
111990 混乱
111991 先生
111992项目
名称：职业，长度：111993，dtype：对象

我究竟做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/58101126/using-scikit-learn-onehotencoder-with-a-pandas-dataframe</guid>
      <pubDate>Wed, 25 Sep 2019 14:47:16 GMT</pubDate>
    </item>
    </channel>
</rss>