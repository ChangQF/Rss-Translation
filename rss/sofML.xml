<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 17 Apr 2024 12:24:59 GMT</lastBuildDate>
    <item>
      <title>Keras-rl2 错误与 Tensorflow 的兼容性</title>
      <link>https://stackoverflow.com/questions/78340927/keras-rl2-error-compability-with-tensorflow</link>
      <description><![CDATA[我目前在使用 keras-rl2 和 tensorflow 时遇到问题，我不知道为什么，我只是在互联网上搜索 keras-rl2、tensorflow 和 keras 文档，但没有找到解决方案。
目前，我想将keras-rl2与最新版本的tensorflow（2.16.1和keras 3）一起使用，但在使用时遇到了一些这样的错误
from rl.agents import DKQAgent

ModuleNotFoundError Traceback（最近一次调用最后一次）
单元格 In[37]，第 1 行
----&gt; 1 导入rl.agents
      3 print(&quot;RL 代理库版本：&quot;, rl.agents.__version__)

文件 D:\Anaconda\Lib\site-packages\rl\agents\__init__.py:2
      1 从.dqn导入DQNAgent、NAFAgent、ContinuationDQNAgent
----&gt; 2 从.ddpg导入DDPGAgent
      3 从.cem导入CEMAgent
      4 从.sarsa导入SarsaAgent、SARSAAgent

文件 D:\Anaconda\Lib\site-packages\rl\agents\dqn.py:8
      5 从tensorflow.keras.layers导入Lambda，输入，层，密集
      7.从rl.core导入Agent
----&gt; 8 从 rl.policy 导入 EpsGreedyQPolicy、GreedyQPolicy
      9 从 rl.util 导入 *
     12 defmean_q(y_true, y_pred):

文件 D:\Anaconda\Lib\site-packages\rl\core.py:8
      4 将numpy导入为np
      5 从tensorflow.keras.callbacks导入历史记录
      7 从 rl.callbacks 导入 (
----&gt; 8 回调列表，
      9 测试记录器，
     10 训练情节记录器，
     11 训练间隔记录器，
     12 展示台
     13）
     16级代理：
     17 “”“”所有已实现代理的抽象基类。
     18
     19 每个代理通过首先观察环境（由 `Env` 类定义）进行交互
   （...）
     37 处理器（`Processor` 实例）：有关详细信息，请参阅[处理器](#processor)。
     38、“”“”

文件 D:\Anaconda\Lib\site-packages\rl\callbacks.py:12
      9 fromtensorflow.python.keras.callbacks import Callback as KerasCallback, CallbackList as KerasCallbackList
     10 从tensorflow.python.keras.utils.generic_utils导入Progbar
---&gt; 12类回调（KerasCallback）：
     13 def _set_env（自身，环境）：
     14 self.env = 环境

ModuleNotFoundError：没有名为“keras.utils.generic_utils”的模块

当我认为我只需要将其降级到某个版本（例如 2.13.0 和 keras 2.13.0）时，它仍然会出现这样的错误
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ImportError Traceback（最近一次调用最后一次）
单元格 In[18]，第 1 行
----&gt; 1 从 rl.agents.dqn 导入 DQNAgent

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\agents\__init__.py:1
----&gt; 1 从.dqn导入DQNAgent、NAFAgent、ContinuationDQNAgent
      2 从.ddpg导入DDPGAgent
      3 从.cem导入CEMAgent

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\agents\dqn.py:7
      4 从tensorflow.keras.models导入模型
      5 从tensorflow.keras.layers导入Lambda，输入，层，密集
----&gt; 7.从rl.core导入Agent
      8 从 rl.policy 导入 EpsGreedyQPolicy、GreedyQPolicy
      9 从 rl.util 导入 *

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\core.py:7
      4 将numpy导入为np
      5 从tensorflow.keras.callbacks导入历史记录
----&gt; 7 从 rl.callbacks 导入 (
      8 回调列表，
      9 测试记录器，
     10 训练情节记录器，
     11 训练间隔记录器，
     12 展示台
     13）
     16级代理：
     17 “””所有已实现代理的抽象基类。
     18
     19 每个代理通过首先观察环境（由 `Env` 类定义）进行交互
   （...）
     37 处理器（`Processor` 实例）：有关详细信息，请参阅[处理器](#processor)。
     38、“”“”

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\callbacks.py:8
      6 将 numpy 导入为 np
      7 将张量流导入为tf
----&gt; 8 从tensorflow.keras导入__version__作为KERAS_VERSION
      9 fromtensorflow.python.keras.callbacks import Callback as KerasCallback, CallbackList as KerasCallbackList
     10 从tensorflow.python.keras.utils.generic_utils导入Progbar

ImportError：无法从“tensorflow.keras”导入名称“__version__”（D:\Anaconda\envs\AI\Lib\site-packages\keras\api\_v2\keras\__init__.py）

任何人都可以给我一个解释或解决方案，为什么它总是错误？
感谢您的关心]]></description>
      <guid>https://stackoverflow.com/questions/78340927/keras-rl2-error-compability-with-tensorflow</guid>
      <pubDate>Wed, 17 Apr 2024 12:20:33 GMT</pubDate>
    </item>
    <item>
      <title>使用张量流保存和加载模型的问题</title>
      <link>https://stackoverflow.com/questions/78340212/issues-with-saving-and-loading-a-model-using-tensorflow</link>
      <description><![CDATA[我创建了一个简单的 cnn 模型，它使用 mobilenet 作为预训练模型。训练后我想保存模型以供以后使用，但无法将其保存为 HDF5 格式。将其保存到 keras 后也无法加载模型。
我尝试使用保存模型
 model.save(“model.h5”)

我收到错误：
ValueError：无法同步创建数据集（名称已存在）
显然我尝试过使用不同的名称，但没有一个有效。
将模型保存为 .keras 格式后，当我尝试加载模型时出现错误
内核形状必须与输入具有相同的长度，
型号：
模型 = tf.keras.models.Sequential()
mobilenet = MobileNet(input_shape = (224, 224, 3), 权重 = &#39;imagenet&#39;, include_top=False)
对于 mobilenet.layers 中的图层：
    层.trainable = False
model.add（移动网络）

model.add(Conv2D(filters = 1024,kernel_size = 2, padding =“相同”,activation=“relu”))
model.add(tf.keras.layers.AveragePooling2D(pool_size=2))
model.add(tf.keras.layers.Flatten())
model.add（tf.keras.layers.Dense（512，激活=“relu”））
model.add（tf.keras.layers.Dense（4，激活=“softmax”））
]]></description>
      <guid>https://stackoverflow.com/questions/78340212/issues-with-saving-and-loading-a-model-using-tensorflow</guid>
      <pubDate>Wed, 17 Apr 2024 10:17:30 GMT</pubDate>
    </item>
    <item>
      <title>“LogisticRegressionTrainingSummary”对象没有属性“fMeasureByThreshold”</title>
      <link>https://stackoverflow.com/questions/78340023/logisticregressiontrainingsummary-object-has-no-attribute-fmeasurebythreshold</link>
      <description><![CDATA[我是 Pyspark 和 Databricks 的新手，正在尝试创建 Logistic 回归模型（通过 Databrticks 本身提供的 Spark_DS&amp;ML_exercise）。将模型拟合到我的训练数据后。我正在尝试按阈值从摘要中获取 f 度量。
我运行了以下代码：
从 pyspark.ml.classification 导入 LogisticRegression

# 创建初始LogisticRegression模型
lr = LogisticRegression(labelCol=“标签”, featuresCol=“特征”, maxIter=10)

# 设置概率阈值，高于该阈值则预测为 1
lr.setThreshold(train_positive_rate)
# lr.setThreshold(0.5) # 如果知道你有平衡数据，可以使用这个

# 使用训练数据训练模型
lrModel = lr.fit(火车)

# 获取用于评估指标和其他参数的训练摘要
lrTrainingSummary = lrModel.summary

# 如果您想使用最佳模型阈值而不是经验正率，请找到最佳模型阈值
fMeasure = lrTrainingSummary.fMeasureByThreshold

但是我收到了这个 AttributeError:
AttributeError：“LogisticRegressionTrainingSummary”对象没有属性“fMeasureByThreshold”

fMeasureByThreshold 似乎不再存在。是这样吗？]]></description>
      <guid>https://stackoverflow.com/questions/78340023/logisticregressiontrainingsummary-object-has-no-attribute-fmeasurebythreshold</guid>
      <pubDate>Wed, 17 Apr 2024 09:49:16 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型中分类数据平均二进制编码方法的澄清</title>
      <link>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</link>
      <description><![CDATA[有很多方法可以将分类数据转换为用于各种统计任务的数值数据。然而，大多数编码方法（例如 One-Hot 编码）会创建更多数据集列，从而产生高维数据。
因此，我引入了一种称为平均二进制编码的方法，该方法在训练模型中应用二进制数据表示。方法如下：

平均二进制值 (X) = (1/|N|) * Σ B_X
哪里 |N|是分类数据X中二进制值的长度，B是分类数据X的二进制表示。
&lt;前&gt;&lt;代码&gt;|分类数据 |应用于配方|编码数据|
| ---------------- | -------------------------------------------------- -------------------------------------------------- --| ------------------ |
|男 | (0+1+0+0+1+1+0+1+0+1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0 +1+1+0+0+1+0+1) ÷ 32 | 0.46875 |
|女 | (0+1+0+0+0+1+1+0+0+1+1+0+0+1+0+1+0+1+1+0+1+1+0+1+0 +1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0+1+1+0+0+1+0+1) ÷ 48 | 0.4791666666666667 |
|是的 | (0+1+0+1+1+0+0+1+0+1+1+0+0+1+0+1+0+1+1+1+0+0+1+1) ÷ 24 | 0.5416666666666666 |
|没有 | (0+1+0+0+1+1+1+0+0+1+1+0+1+1+1+1) ÷16 | 0.625 | 0.625
| 1 | (0+0+1+1+0+0+0+1) ÷ 8 | 0.375 | 0.375
| 0 | (0+0+1+1+0+0+0+0) ÷ 8 | 0.25 | 0.25

例如，
分类数据“男性”的二进制表示为 01001101011000010110110001100101。
该二进制数据的长度是 32。
因此，根据公式，编码值为0.46875。
我想进一步了解这种编码方法，看看它是否适用于统计模型。
对分类数据进行编码是否有任何具体注意事项或限制？]]></description>
      <guid>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</guid>
      <pubDate>Wed, 17 Apr 2024 09:09:55 GMT</pubDate>
    </item>
    <item>
      <title>是否有在训练中使用负例来改进特征学习的方法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78339582/are-there-methods-for-using-negative-examples-in-training-in-order-to-improve-fe</link>
      <description><![CDATA[我有一个人工智能，它应该生成图像作为合成数据，用于训练图像分类人工智能。
结果不够现实/准确，无法用作培训课程的实际数据点。
我可以将它们用作“反例”，以便人工智能学会不以某种方式对它们进行分类，即使它们看起来与真实物体相似？这可以用来让人工智能更详细地了解课程的真实特征吗？
是否存在这样的事情，或者这是一个不好的方法？
我尝试在网上做一些研究，但诸如“out-ouf-distributionlearning”、“contrastivelearning”、“inversereinforcementlearning”之类的东西都没有。都指不同的事物...]]></description>
      <guid>https://stackoverflow.com/questions/78339582/are-there-methods-for-using-negative-examples-in-training-in-order-to-improve-fe</guid>
      <pubDate>Wed, 17 Apr 2024 08:45:04 GMT</pubDate>
    </item>
    <item>
      <title>** 进入 DGEES 参数编号 13 时有非法值</title>
      <link>https://stackoverflow.com/questions/78338695/on-entry-to-dgees-parameter-number-13-had-an-illegal-value</link>
      <description><![CDATA[我是机器学习的新手。
我正在运行一个定义了 arima 模型（auto_arima 函数）的 python 应用程序。
与 scipy==1.12.0 &amp; numpy==1.26.4。
执行后，出现错误，
** 在进入 DGEES 参数 13 时有一个非法值
如何查看数字 13 是多少？我该如何处理这个问题？
如果需要更多详细信息，请告诉我。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78338695/on-entry-to-dgees-parameter-number-13-had-an-illegal-value</guid>
      <pubDate>Wed, 17 Apr 2024 06:08:48 GMT</pubDate>
    </item>
    <item>
      <title>隔离森林、自动编码器、ADTK Lib</title>
      <link>https://stackoverflow.com/questions/78338298/isolation-forest-vs-autoencoder-vs-adtk-lib</link>
      <description><![CDATA[我有一个项目，我对不同公司的股票市场数据进行异常检测，数据集为雅虎财经。隔离森林、自动编码器和 ADTK Lib 哪种异常检测方法最好。
我已经准备好了代码。我得到的准确度大致相同。]]></description>
      <guid>https://stackoverflow.com/questions/78338298/isolation-forest-vs-autoencoder-vs-adtk-lib</guid>
      <pubDate>Wed, 17 Apr 2024 04:08:46 GMT</pubDate>
    </item>
    <item>
      <title>小时间序列数据集中的异常值检测[关闭]</title>
      <link>https://stackoverflow.com/questions/78337873/outliers-detection-in-a-small-time-series-dataset</link>
      <description><![CDATA[我在一个月内从 400 个网络外围设备获取了数据，每 15 分钟记录一次。我的目标是单独识别每天的异常情况。鉴于数据集相对较小（每天 96 个点）
哪种机器学习方法最适合获得最佳结果？]]></description>
      <guid>https://stackoverflow.com/questions/78337873/outliers-detection-in-a-small-time-series-dataset</guid>
      <pubDate>Wed, 17 Apr 2024 01:00:27 GMT</pubDate>
    </item>
    <item>
      <title>请求 DFS、PMI 和成对约束实施方面的帮助 (Python) [已关闭]</title>
      <link>https://stackoverflow.com/questions/78337813/request-for-assistance-with-dfs-pmi-and-pairwise-constraints-implementation-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78337813/request-for-assistance-with-dfs-pmi-and-pairwise-constraints-implementation-p</guid>
      <pubDate>Wed, 17 Apr 2024 00:27:43 GMT</pubDate>
    </item>
    <item>
      <title>如何用 0 个初始训练数据构建实时推荐系统？</title>
      <link>https://stackoverflow.com/questions/78336322/how-do-i-build-a-real-time-recommendation-system-with-0-initial-training-data</link>
      <description><![CDATA[我正在开发一个实时流媒体网络应用程序。我们目前有 0 个用户和流数据。
如果我只是随机生成自己的数据，则存在创建不良数据的风险，那么我应该如何训练 ML 模型呢？我应该使用服务（AWZ、Azure 等）吗？]]></description>
      <guid>https://stackoverflow.com/questions/78336322/how-do-i-build-a-real-time-recommendation-system-with-0-initial-training-data</guid>
      <pubDate>Tue, 16 Apr 2024 17:16:45 GMT</pubDate>
    </item>
    <item>
      <title>当环境处于截断的情况下时，我应该如何处理值函数？</title>
      <link>https://stackoverflow.com/questions/78334914/how-should-i-handle-the-value-function-when-the-environment-is-rested-in-a-trunc</link>
      <description><![CDATA[我阅读了终止/截断的文档并理解了之间的区别环境的终止情况和截断情况，但我无法理解为什么该值会像下面这样更新。
如果终止：# case 1
    下一个 q 值 = 奖励
否则：#情况2
    下一个 q 值 = 奖励 + 折扣因子 * Q 的最大动作（下一个状态，动作）

# 这样可以更有效地编写
下一个q值=奖励+（未终止）*折扣因子*Q的最大动作（下一个状态，动作）

据我了解，截断信号后环境将被重置，下一步是环境的初始步骤，从 env.reset() 调用。在这种情况下，状态和下一个状态之间没有关系，我不知道为什么使用下一个状态的 Q 值来更新该值。
假设环境的时间限制是1000。那么，无论第1000步的状态是什么，下一步都将是环境的初始步骤。即使在相同的状态和相同的动作下，如果时间步不是1000，下一个状态也会不同，并且会使用不同的Q值。
为什么使用下一个状态的 Q 项来更新截断情况下的值？在截断的情况下也忽略 Q 项不是更好吗？
另外，我想知道如何处理连续任务中下一个状态的 Q 项。在每个截断的情况下，错误的状态（从 env.reset() 调用）是否会被视为下一个状态？
我试图找到类似的问题，但没有找到。可能有一些原因，但我可以找出原因。]]></description>
      <guid>https://stackoverflow.com/questions/78334914/how-should-i-handle-the-value-function-when-the-environment-is-rested-in-a-trunc</guid>
      <pubDate>Tue, 16 Apr 2024 13:31:42 GMT</pubDate>
    </item>
    <item>
      <title>使用张量流创建的 u-net 时，max_pooling2d 之前的尺寸存在问题</title>
      <link>https://stackoverflow.com/questions/78310228/problem-with-dimensions-before-max-pooling2d-while-using-a-u-net-created-with-te</link>
      <description><![CDATA[我有一个用tensorflow编码的u-net架构：
def down_block(x, 过滤器, kernel_size=(3, 3), padding=&#39;same&#39;, strides=1):
    x = tf.keras.layers.Conv2D（过滤器，kernel_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.Conv2D（过滤器，kernel_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    返回x

def up_block(x, 跳过, 过滤器, kernel_size=(3, 3), padding=&#39;相同&#39;, strides=1):
    x = tf.keras.layers.UpSampling2D((2, 2))(x)
    x = tf.keras.layers.Concatenate(axis=3)([x, 跳过])
    x = tf.keras.layers.Conv2D（过滤器，keras_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.Conv2D（过滤器，kernel_size，padding=padding，strides=strides）（x）
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)
    返回x

def Unet(input_size=(256, 256, 3), 类=2, dropout_rate=0.5):
    输入 = tf.keras.Input(input_size)
    过滤器 = [64, 128, 256, 512, 1024]

    ＃ 向下
    x = 输入
    跳过 = []
    对于过滤器 [:-1] 中的 f：
        x = down_block(x, f)
        跳过.append(x)
        x = tf.keras.layers.MaxPooling2D((2, 2))(x)

    x = down_block(x, 过滤器[-1])

    ＃ 向上
    对于反转中的 i（范围（len（跳过）））：
        x = up_block(x, 跳过[i], 过滤器[i])

    #x = tf.keras.layers.Dropout(dropout_rate)(x)
    x = tf.keras.layers.Conv2D(类, (1, 1), 填充=“相同”, 激活=“sigmoid”)(x)

    模型= tf.keras.models.Model（输入，x，名称=“U-Net”）
    返回模型

当我尝试用我的数据训练这个架构时，我遇到了这个错误，我不明白为什么：
W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES 在 mkl_maxpooling_op.cc:214 处失败：中止：计算收到异常：状态：2，消息：无法为池转发创建描述符传播原语，在文件tensorflow/core/kernels/mkl/mkl_maxpooling_op.cc:211中
tensorflow.python.framework.errors_impl.AbortedError：调用层“max_pooling2d”（类型 MaxPooling2D）时遇到异常。
[...]
{{function_node __wrapped__MaxPool_device_/job:localhost/replica:0/task:0/device:CPU:0}} 计算收到异常：状态：2，消息：无法在文件张量流中为池化前向传播原语创建描述符/core/kernels/mkl/mkl_maxpooling_op.cc:211 [Op:MaxPool] 名称：
调用层“max_pooling2d”接收的参数（类型 MaxPooling2D）：
  输入=tf.Tensor（形状=（1024,1024,1,64），dtype=float32）

我尝试了很多不同尺寸的图片，将“channels_first”放在或“channels_last”，但在调用 model.fit() 时总会出现问题。
这是我用来测试模型的代码：
`
如果 __name__ == &#39;__main__&#39;:
    打印（tf.__版本__）
    模型 = Unet(input_size=(1024, 1024, 1), 类=1, dropout_rate=0.2)
    模型.summary()

    大小 = (1024, 1024, 1)
    img = np.random.randn(大小[0],大小[1],大小[2])*100
    标签 = np.random.randn(大小[0],大小[1],大小[2])
    对于范围内的 i(0,size[0]):
        对于范围（0，大小[1]）中的j：
            对于范围（0，大小[2]）中的k：
                如果标签[i][j][k]&gt;0：标签[i][j][k]=1
                否则：标签[i][j][k]=0
    img_list = [img, img, img]
    标签列表 = [标签，标签，标签]

    数据 = 列表(zip(img_list,label_list))
    input_dataset = tf.data.Dataset.from_tensor_slices([data_point[0] for data_point in data])
    target_dataset = tf.data.Dataset.from_tensor_slices([data_point[1] for data_point in data])
    数据集 = tf.data.Dataset.zip((input_dataset, target_dataset))

    对于img，数据集中的标签：
        打印（img.形状，标签.形状）

    model.compile(optimizer=tf.keras.optimizers.RMSprop(),
                  损失=tf.keras.losses.BinaryCrossentropy(),
                  指标=[&#39;binary_accuracy&#39;],
                  run_eagerly=真）

    new_var = model.fit(数据集,epochs=10)

我已经尝试了很多事情：更小或更大的图片尺寸，将其作为 fit() 函数的参数的不同方法，使用 tf.transpose 来成功 maxpooling2D...
我只是希望使用该模型在灰色模式下使用方形图片 (512x512x1) 或 (1024x1024x1) 成功完成训练阶段。]]></description>
      <guid>https://stackoverflow.com/questions/78310228/problem-with-dimensions-before-max-pooling2d-while-using-a-u-net-created-with-te</guid>
      <pubDate>Thu, 11 Apr 2024 12:08:33 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：使用 `bitsandbytes` 8 位量化需要 Accelerate：`pip install Accelerate` 和最新版本的 Bitsandbytes：`pip install</title>
      <link>https://stackoverflow.com/questions/78254344/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78254344/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</guid>
      <pubDate>Mon, 01 Apr 2024 08:15:53 GMT</pubDate>
    </item>
    <item>
      <title>在 Mac 上安装 pgvector 扩展</title>
      <link>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</link>
      <description><![CDATA[我正在尝试在我的 Mac 上安装 postgres 矢量扩展，但我得到了
错误：扩展名“向量”没有版本“0.4.0”的安装脚本或更新路径。

这就是我所做的：

按照 github 上所示的安装指南进行操作：


但是当我运行CREATE EXTENSION vector;时出现错误：
错误：无法打开扩展控制文件“/Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/vector.control”：没有这样的文件或目录


我使用以下方法将 pgvector 的内容复制到 posgresql/extension 中：
sudo cp -r ~/Downloads/pgvector/* /Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/


尝试运行CREATE EXTENSION向量；现在错误是：
错误：扩展名“向量”没有版本“0.4.0”的安装脚本或更新路径。

这里有人遇到过这个问题吗？
顺便说一句，我正在使用PostgreSQL 13.10]]></description>
      <guid>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</guid>
      <pubDate>Tue, 07 Mar 2023 15:32:42 GMT</pubDate>
    </item>
    <item>
      <title>Python 上每个系数具有特定约束的多元线性回归</title>
      <link>https://stackoverflow.com/questions/50410037/multiple-linear-regression-with-specific-constraint-on-each-coefficients-on-pyth</link>
      <description><![CDATA[我目前正在数据集上运行多元线性回归。起初，我没有意识到我需要限制自己的体重；事实上，我需要有具体的积极和积极的态度。负权重。
更准确地说，我正在做一个评分系统，这就是为什么我的一些变量应该对笔记产生积极或消极的影响。然而，当运行我的模型时，结果并不符合我的预期，我的一些“正”变量得到负系数，反之亦然。
举个例子，假设我的模型是：
&lt;预置&gt;&lt;代码&gt;y = W0*x0 + W1*x1 + W2*x2

如果 x2 是一个“正”变量，我想对 W2 施加一个约束使其为正！
我已经对这个问题进行了很多研究，但我没有发现任何关于特定权重/系数的约束，我发现的只是将所有系数设置为正或将它们加起来为一。
我正在使用 ScikitLearn 包开发 Python。这就是我获得最佳模型的方法：
def ridge(Xtrain, Xtest, Ytrain, Ytest, 位置):
    param_grid={&#39;alpha&#39;:[0.01, 0.1, 1, 10, 50, 100, 1000]}
    gs = grid_search.GridSearchCV(Ridge(), param_grid=param_grid, n_jobs=-1, cv=3)
    gs.fit(Xtrain, Ytrain)
    hatytrain = gs.predict(Xtrain)
    hatytest = gs.predict(Xtest)

知道如何对特定变量的系数分配约束吗？定义每个约束可能会很麻烦，但我不知道该怎么做。]]></description>
      <guid>https://stackoverflow.com/questions/50410037/multiple-linear-regression-with-specific-constraint-on-each-coefficients-on-pyth</guid>
      <pubDate>Fri, 18 May 2018 11:10:22 GMT</pubDate>
    </item>
    </channel>
</rss>