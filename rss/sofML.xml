<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 07 Apr 2024 09:13:31 GMT</lastBuildDate>
    <item>
      <title>如何在不始终拥有用户 ID 的情况下根据多个标准推荐增强功能？</title>
      <link>https://stackoverflow.com/questions/78287221/how-to-recommend-enhancements-based-on-multiple-criteria-without-always-having-u</link>
      <description><![CDATA[我正在开发一个推荐系统，该系统根据按摩名称、服务长度、中心名称以及偶尔的用户详细信息向用户建议增强功能（附加服务）。但是，我遇到了一些需要帮助的挑战。
涉及的数据集结构如下：
用户数据集：包含 USER_ID、AGE、GENDER、ZIPCODE 和 BASE_CENTER。
项目数据集：包含ITEM_ID和ITEM_NAME（代表增强）。
交互数据集：包括 USER_ID、ITEM_ID、TIMESTAMP、SERVICE_LENGTH、MASSAGE_NAME、CENTER_NAME 和 EVENT_TYPE。
我的系统的一个值得注意的方面是，每个增强功能都可以与多个按摩名称和中心名称相关联。以下是我面临的具体问题：
用户 ID 缺失：在很多情况下，我没有 USER_ID。在推荐过程中处理此类情况的最佳实践是什么？我应该默认使用通用用户配置文件，还是有更复杂的方法来保持个性化而无需用户识别？
不同中心的建议不一致：我发现不同的中心有时会产生相同的增强建议，尽管我预计中心名称会影响建议的多样性。此外，用户年龄、性别和中心名称的变化似乎并没有像预期那样改变结果。
不同输入的相同结果：无论年龄、性别和中心名称输入如何变化，系统都倾向于推荐相同的增强功能。我正在寻找策略来使结果多样化并使建议对这些输入变量更加敏感。
问题：
如何改进我的推荐系统以有效处理没有用户 ID 的实例，确保一定程度的个性化？
我可以采用哪些策略或模型来使我的系统对用户详细信息（年龄、性别）和中心名称的变化更加敏感，从而提供更加多样化和相关的增强建议？
任何有关如何应对这些挑战的见解或建议将不胜感激。
尝试更改架构，但输出没有太大差异]]></description>
      <guid>https://stackoverflow.com/questions/78287221/how-to-recommend-enhancements-based-on-multiple-criteria-without-always-having-u</guid>
      <pubDate>Sun, 07 Apr 2024 08:59:41 GMT</pubDate>
    </item>
    <item>
      <title>我如何将图像数据集上传到 vs code [关闭]</title>
      <link>https://stackoverflow.com/questions/78287042/how-can-i-upload-an-image-dataset-to-vs-code</link>
      <description><![CDATA[我在 google colab 中制作了一个用于植物病害检测的机器学习模型，我想在 VS Code 中运行它，所以我想将图像数据集导入到 VS Code 中，我该怎么做
我已将代码从 colab 复制到 VS Code，现在我想导入数据集]]></description>
      <guid>https://stackoverflow.com/questions/78287042/how-can-i-upload-an-image-dataset-to-vs-code</guid>
      <pubDate>Sun, 07 Apr 2024 07:48:39 GMT</pubDate>
    </item>
    <item>
      <title>如何为 CNN 机器学习模型制作前端和后端</title>
      <link>https://stackoverflow.com/questions/78286791/how-to-make-a-frontend-and-a-backend-for-a-cnn-machine-learning-model</link>
      <description><![CDATA[我制作了一个机器学习模型来检测马铃薯植株上的疾病。现在我想为模型创建一个前端，从用户那里获取图像并预测输出，同时我还想要一个后端来存储数据。另外我将如何集成前端和后端。
我想知道如何创建一个后端来存储数据。以及如何整合前端和后端。]]></description>
      <guid>https://stackoverflow.com/questions/78286791/how-to-make-a-frontend-and-a-backend-for-a-cnn-machine-learning-model</guid>
      <pubDate>Sun, 07 Apr 2024 05:53:18 GMT</pubDate>
    </item>
    <item>
      <title>如何将预处理图像从 jupyter 笔记本导出到下载中的“preprocessedimages”文件？</title>
      <link>https://stackoverflow.com/questions/78286595/how-can-i-export-preprocessed-images-from-jupyter-notebook-to-preprocessedimage</link>
      <description><![CDATA[我正在开发一款支持机器学习的石头剪刀布游戏应用程序。在探索包含“岩石”的数据集之后文件，“纸质”文件和“剪刀”中，我使用翻转、旋转等变换生成了 RPS 数据集中 1751 个图像的变体。现在，我需要将所有预处理图像导出到名为“preprocessedimages”的空文件中。在我电脑的下载文件中。
如何编写一个循环，将变换（翻转、旋转、重新缩放）应用于数据中的所有图像，并将每个调整后的图像保存在文件夹中？我使用下面的代码生成了增强图像，但如何导出它们？
def Data_Preprocessing(x_train,y_train, x_test, y_test, Batch_size):
    
    
    train_datagen = 图像数据生成器(
        水平翻转=真，
        垂直翻转=真，
        旋转范围 = 20,
        重新缩放 = 1./255)
   
    train_generator = train_datagen.flow（x_train，y_train，batch_size = Batch_size）
    
    test_datagen = ImageDataGenerator（重新缩放= 1./255）
    
    
    test_generator = test_datagen.flow（x_test，y_test，batch_size = Batch_size，shuffle = False）
    
    
    返回train_generator、test_generator

&lt;前&gt;&lt;代码&gt;BATCH_SIZE = 64
train_gen、test_gen = 数据预处理（x_train、y_train、x_test、y_test、Batch_size = BATCH_SIZE）

对于train_gen中的批次：
    图像、标签=批次
    数据可视化（图像、标签、label_str、grid_size = (5, 5)）
]]></description>
      <guid>https://stackoverflow.com/questions/78286595/how-can-i-export-preprocessed-images-from-jupyter-notebook-to-preprocessedimage</guid>
      <pubDate>Sun, 07 Apr 2024 03:54:42 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV 新手，我如何安装/构建 opencv_traincascade</title>
      <link>https://stackoverflow.com/questions/78286577/new-to-opencv-how-do-i-install-build-opencv-traincascade</link>
      <description><![CDATA[所以我一直致力于机器学习项目，并且需要使用 opencv_traincascade 训练自定义数据集。但每当我尝试安装它时，它就永远无法工作。我还有其他东西，比如 opencv_annotation 和其他东西可以工作，但是 traincascade 或 event createsamples 不起作用。我必须手动构建这些吗？
我下载了mingw-gcc、cmake，在网上找不到可行的解决方案。顺便说一句，我有 opencv 4.9.0，手动安装在 anaconda 和我的 C: 驱动器中。我也尝试过寻找一些第三方，他们安装了整个 opencv 并且可以复制，但没有运气。任何帮助将不胜感激，谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78286577/new-to-opencv-how-do-i-install-build-opencv-traincascade</guid>
      <pubDate>Sun, 07 Apr 2024 03:46:34 GMT</pubDate>
    </item>
    <item>
      <title>将 Python 推荐系统连接到 Laravel 应用程序</title>
      <link>https://stackoverflow.com/questions/78286410/connecting-python-recommendation-system-to-laravel-application</link>
      <description><![CDATA[我使用 Python 和余弦相似度算法开发了一个基本的推荐系统。现在，我有兴趣创建一个 Laravel 应用程序来集成这个推荐系统。但是，我不确定如何在两者之间建立联系。
任何帮助将不胜感激！
我没有找到任何可以开始的东西！！]]></description>
      <guid>https://stackoverflow.com/questions/78286410/connecting-python-recommendation-system-to-laravel-application</guid>
      <pubDate>Sun, 07 Apr 2024 01:54:56 GMT</pubDate>
    </item>
    <item>
      <title>所有模型的训练、验证集和测试集的 F1 分数、精确度和召回率均较高</title>
      <link>https://stackoverflow.com/questions/78286020/high-f1-score-precision-and-recall-on-training-validation-set-and-test-set-on</link>
      <description><![CDATA[我正在研究一个关于 Kaggle。有一些特征，例如燃料消耗、燃料等。我尝试根据该数据集进行分类任务，将排放量高于 160 定义为不可接受 (1)，低于 160 定义为可接受 (0)。数据不平衡，可接受类有13269个数据，不可接受类有9287个数据。我尝试使用不同的分类模型，例如随机森林分类器、决策树分类器和逻辑回归，所有这些模型在训练集、验证集甚至测试集上都实现了接近 1 的 f1 分数，这看起来很奇怪。数据没有缺失值或空值，并且在将其输入模型之前由标准定标器进行标准化。
在此处输入图像说明在此处输入图像描述
我的第一个假设是当所有模型都这样执行时数据泄漏。我多次检查了代码，甚至用函数检查了数据集，训练集和测试集之间没有重复的行。我尝试使用所有特征，然后使用随机森林发现最相关的一些特征，例如“COMB（L/100 km）”、“COMB（mpg）”、“燃油消耗”、“HWY（L/100 km）” 100 公里）”、“气缸”、“发动机尺寸”和他们玩了一下，但在所有精确度、召回率和 f1 上仍然获得了高分。我通过偶然从较大的类中删除一些数据来平衡数据集。我使用网格搜索制作模型，因此我尝试通过定义不同的参数网格以及手动定义来使模型更加复杂和简单。我还通过阈值检查了精度和召回率。
在此处输入图片说明
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78286020/high-f1-score-precision-and-recall-on-training-validation-set-and-test-set-on</guid>
      <pubDate>Sat, 06 Apr 2024 21:57:10 GMT</pubDate>
    </item>
    <item>
      <title>循环图像时出现 TensorFlow InvalidArgumentError</title>
      <link>https://stackoverflow.com/questions/78285543/tensorflow-invalidargumenterror-while-looping-over-images</link>
      <description><![CDATA[迭代图像时出现以下错误：
InvalidArgumentError: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} 图像中固有的通道数必须为 1、3 或 4，为 2
     [[{{节点decode_image/DecodeImage}}]] [Op:IteratorGetNext]名称：

我用来定义数据和迭代图像的代码：
data=tf.keras.utils.image_dataset_from_directory（main_path，batch_size=None）

形状=[]
对于枚举（数据）中的 i，（图像，标签）：
    尝试：
        通道大小=图像.形状
        形状.append（通道大小）
    除了 tf.errors.InvalidArgumentError 为 e：
        打印（一）
    

即使指定批量大小，我也会遇到相同的错误。
我使用的数据集是来自 Kaggle 的猫和狗分类数据集。
我最好的猜测是，数据中存在错误的图像，这导致了错误，我想通过循环所有图像来找到该图像。我仍然收到 Try/Except 块的错误。
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78285543/tensorflow-invalidargumenterror-while-looping-over-images</guid>
      <pubDate>Sat, 06 Apr 2024 18:53:39 GMT</pubDate>
    </item>
    <item>
      <title>我认为我的模型过度拟合？有什么建议么？</title>
      <link>https://stackoverflow.com/questions/78285324/i-think-my-model-is-overfitting-any-suggestions</link>
      <description><![CDATA[所以我正在使用来自kaggle的deepfake检测数据集，我的模型似乎过度拟合，大约有2000张图像，其中1k用于“真实”类，1k用于“假”类。所有图像都是面孔。我使用的是 VGG16，因为它众所周知适合深度伪造面部检测。
以下是过去 10 个周期的结果：
找到属于 2 个类别的 1632 个图像。
找到属于 2 个类别的 204 张图像。
找到属于 2 个类别的 205 张图像。
纪元 1/10
51/51 [==============================] - 1234s 24s/步 - 损失：0.1841 - 准确度：0.9577 - val_loss ：0.7258 - val_accuracy：0.6719
纪元 2/10
51/51 [================================] - 1168s 23s/步 - 损失：0.1397 - 准确度：0.9712 - val_loss ：0.7331 - val_accuracy：0.6406
纪元 3/10
51/51 [================================] - 1186s 23s/步 - 损失：0.1215 - 准确度：0.9743 - val_loss ：0.7938 - val_accuracy：0.6719
纪元 4/10
51/51 [==============================] - 1187s 23s/步 - 损失：0.0914 - 准确度：0.9884 - val_loss ：0.8304 - val_accuracy：0.6615
纪元 5/10
51/51 [================================] - 1188s 23s/步 - 损失：0.0705 - 准确度：0.9939 - val_loss ：0.9022 - val_accuracy：0.6562
纪元 6/10
51/51 [================================] - 1155s 23s/步 - 损失：0.0683 - 准确度：0.9896 - val_loss ：0.9072 - val_accuracy：0.6354
纪元 7/10
51/51 [==============================] - 1154s 23s/步 - 损失：0.0541 - 准确度：0.9951 - val_loss ：0.8924 - val_accuracy：0.6719
纪元 8/10
51/51 [==============================] - 1175s 23s/步 - 损失：0.0403 - 准确度：0.9975 - val_loss ：0.9353 - val_accuracy：0.6510
纪元 9/10
51/51 [==============================] - 1189s 23s/步 - 损失：0.0420 - 准确度：0.9969 - val_loss ：1.0692 - val_accuracy：0.6198
纪元 10/10
51/51 [==============================] - 1185s 23s/步 - 损失：0.0288 - 准确度：0.9988 - val_loss ：1.0250 - val_accuracy：0.6510
/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103：UserWarning：您正在通过“model.save()”将模型保存为 HDF5 文件。此文件格式被视为旧格式。我们建议使用原生 Keras 格式，例如`model.save(&#39;my_model.keras&#39;)`。
  saving_api.save_model(
6/6 [================================] - 135s 21s/步 - 损失：1.1160 - 准确度：0.6042
测试精度：0.6041666865348816，结果如下

如果有人想知道，这里是过去 10 个时期的代码：
从 google.colab 导入驱动器
导入操作系统
将张量流导入为 tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入load_model

train_dir = &#39;/content/drive/MyDrive/dataset/train&#39;
val_dir = &#39;/content/drive/MyDrive/dataset/val&#39;
test_dir = &#39;/content/drive/MyDrive/dataset/test&#39;

＃参数
批量大小 = 32
历元 = 5
图像形状 = (224, 224)

save_model_path = &#39;/content/drive/MyDrive/dataset/trained_model_updated.h5&#39;
模型 = load_model(保存的模型路径)

#预处理
train_datagen = ImageDataGenerator(重新缩放=1./255)
val_datagen = ImageDataGenerator(重新缩放=1./255)
test_datagen = ImageDataGenerator（重新缩放=1./255）

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）

val_generator = val_datagen.flow_from_directory(
    val_dir,
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）

test_generator = test_datagen.flow_from_directory(
    测试目录，
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）


model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])


历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=纪元，
    验证数据=val_generator，
    validation_steps=val_generator.samples //batch_size
）


model.save(&#39;/content/drive/MyDrive/dataset/trained_model_updated.h5&#39;)

test_loss, test_acc = model.evaluate(test_generator,steps=test_generator.samples //batch_size)
print(f&#39;测试准确度：{test_acc}&#39;)


我运行了该模型大约 20 个 epoch，并不断更改参数，应用数据增强。尽管该模型对训练数据产生了良好的准确性，但对验证和测试集而言仍停滞在 67% 左右。
在前 5 个 epoch 中，模型的验证准确率确实从 53% 提高到 67%，但在最后 15 个 epoch 中仍然停滞不前。
为了确认，我还尝试使用来自互联网的一些图像，但它没有正确识别这些图像，并且会错误地将一些假图像分类为“真实”。
我很确定它的过度拟合是正确的吗？
我没有计算资源来训练更大的数据集，除了增加数据集大小之外还有其他解决方案吗？任何建议，将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78285324/i-think-my-model-is-overfitting-any-suggestions</guid>
      <pubDate>Sat, 06 Apr 2024 17:38:39 GMT</pubDate>
    </item>
    <item>
      <title>如何正确表示模型的数据</title>
      <link>https://stackoverflow.com/questions/78284870/how-to-correctly-represent-data-for-a-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78284870/how-to-correctly-represent-data-for-a-model</guid>
      <pubDate>Sat, 06 Apr 2024 15:16:11 GMT</pubDate>
    </item>
    <item>
      <title>如何解释神经网络中隐藏神经元的输出？</title>
      <link>https://stackoverflow.com/questions/78281488/how-to-interpret-the-outputs-of-the-hidden-neurons-in-a-neural-network</link>
      <description><![CDATA[我正在训练一个由 2 个神经元组成的 1 个隐藏层的 FNN：
模型 = train1([2])
绘制拟合以及每个隐藏神经元的输出（分布式表示）时：
plot1(X1, y1, label=&quot;train&quot;)
图1（X1测试，y1测试，标签=“测试”）
plot1fit(torch.linspace(0, 13, 500).unsqueeze(1), 模型, 隐藏=True, 比例=False)

输出如下：

当使用 3 个隐藏神经元进行训练时：

如何解释每个隐藏神经元的可视化和输出的拟合情况？]]></description>
      <guid>https://stackoverflow.com/questions/78281488/how-to-interpret-the-outputs-of-the-hidden-neurons-in-a-neural-network</guid>
      <pubDate>Fri, 05 Apr 2024 17:23:10 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归房价r2得分问题</title>
      <link>https://stackoverflow.com/questions/78275121/multiple-linear-regression-house-price-r2-score-problem</link>
      <description><![CDATA[我有样本房价数据和简单代码：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 LabelEncoder、StandardScaler
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.metrics 导入 r2_score

数据 = pd.read_csv(&#39;house_price_4.csv&#39;)
df = pd.DataFrame(数据)
df[&#39;区域&#39;] = df[&#39;区域&#39;].str.replace(&#39;,&#39;, &#39;&#39;)
df = df.dropna()

# 对分类特征“地址”进行编码
df[&#39;地址&#39;] = df[&#39;地址&#39;].astype(&#39;类别&#39;).cat.codes
df[&#39;停车&#39;] = df[&#39;停车&#39;].replace({True: 1, False: 0})
df[&#39;仓库&#39;] = df[&#39;仓库&#39;].replace({True: 1, False: 0})
df[&#39;电梯&#39;] = df[&#39;电梯&#39;].replace({True: 1, False: 0})

X = df.drop(columns=[&#39;价格(美元)&#39;,&#39;价格&#39;])
y = df[&#39;价格&#39;]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

r_squared = r2_score(y_test, y_pred)
print(f&#39;R^2 得分: {r_squared:.4f}&#39;)

                                                                  

我的 R2 分数非常低：0.34
如何获得更高的 R2 分数？
这是我的示例数据：https://drive.google .com/file/d/14Se90XbGJivftq3_VrtgRSalkCplduVX/view?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78275121/multiple-linear-regression-house-price-r2-score-problem</guid>
      <pubDate>Thu, 04 Apr 2024 16:01:38 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 中的恒定预测值</title>
      <link>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</link>
      <description><![CDATA[我正在尝试使用 LightGBM 回归来预测变量 (Y)。然而我的预测值都是相同的（即常数）。有人可以帮忙检测问题吗？
data_x = [[2021,5,368.92],[2023,11,356.82],[2022,10,352.49],[2023,5,343.63],[2023,10,324.91],[2022,12,352.02],[2021,6,370.7 9] ,[2022,5,386.59],[2019,2,301.56],[2021,4,353.7],[2021,1,303.93],[2021,9,371.94],[2019,4,310.77],[2021,3,345.3],[2020,5,249。 63],[ 2022,4,381.16],[2023,4,363.14],[2019,7,304.19],[2020,7,258.43],[2022,2,412.47],[2022,8,353.43],[2019,6,302.34],[2020,1,319。 88]，[2022年， 7,361.66],[2020,9,265.39],[2022,3,408.72],[2022,1,417.47],[2022,6,351.92],[2022,9,344.06],[2022,11,373.75],[2019,9,314.97], [2019,11,324.14] ,[2023,2,377.23],[2021,11,380.83],[2021,12,403.12],[2023,7,368.73],[2023,1,379.76],[2019,5,295.02],[2023,9,343.78],[2020,4, 248.54],[ 2019,10,314.79],[2019,8,295.92],[2023,3,354.09],[2023,6,357.35],[2021,2,324.31],[2020,3,246.26],[2019,3,295.36],[2020,12,30 6.27]，[2021， 8,376.54],[2020,6,258.21],[2023,8,352.35],[2021,7,370.21],[2020,10,259.13],[2020,8,275.66],[2019,12,315.47],[2020,11,301.27 ],[2021,10,389.23] ,[2019,1,291.94],[2020,2,302.38]]

df_x = pd.DataFrame(data_x, columns=[&#39;年&#39;, &#39;月&#39;, &#39;关闭&#39;])

data_y = [[1479.42],[1654.53],[1537.76],[1621.22],[1567.62],[1528.39],[1444.63],[1562.17],[1356.81],[1463.48],[1558.9],[1463.96] ,[1362.03],[1432.7],[1502.46],[1524.71],[1592.68],[1342.74],[1467.48],[1553.66],[1609.19],[1349.1],[1379.39],[1496.12],[ 1448.08]、[1562.96]、[1525.25]、[1575.06]、[1591.15]、[1544.66]、[1319.9]、[1366.73]、[1482.72]、[1520.73]、[1557.03]、[1577.37]、[1624 .74] ,[1402.05],[1614.94],[1482.28],[1338.88],[1354.6],[1553.65],[1606.36],[1510.78],[1348.05],[1323.39],[1542.95],[1411.64],[ 1493.44],[1563.53],[1414.8],[1452.67],[1491.7],[1451.43],[1467.23],[1477.13],[1360.29],[1386.48]]

df_y = pd.DataFrame(data_y, columns=[&#39;值&#39;])

X_df_earn_ind_fin_train，X_df_earn_ind_fin_test，y_df_earn_ind_fin_train，y_df_earn_ind_fin_test = train_test_split（df_x，df_y，test_size = 0.3，random_state = 21）

hyper_params = {
    &#39;任务&#39;：&#39;训练&#39;，
    &#39;boosting_type&#39;：&#39;gbdt&#39;，
    &#39;目标&#39;：&#39;回归&#39;，
    &#39;公制&#39;：[&#39;mape&#39;，&#39;auc&#39;]，
    “学习率”：0.01，
    “特征分数”：0.9，
    &#39;bagging_fraction&#39;：0.7，
    &#39;bagging_freq&#39;：10，
    “详细”：0，
    &#39;详细评估&#39;：-1，
    “最大深度”：10，
    “叶子数”：96，
    “max_bin”：256，
    “迭代次数”：1000，
    “n_估计器”：250
}

gbm = lgm.LGBMRegressor(**hyper_params)
gbm.fit(X_df_earn_ind_fin_train, y_df_earn_ind_fin_train,
        eval_set=[(X_df_earn_ind_fin_test, y_df_earn_ind_fin_test)],
        eval_metric=&#39;mape&#39;)

y_pred_df_earn_ind_test = gbm.predict(X_df_earn_ind_fin_test)


但是我的输出只是一个常量值的数组
y_pred_df_earn_ind_test =
数组([1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863])


如何纠正这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</guid>
      <pubDate>Mon, 01 Apr 2024 21:17:37 GMT</pubDate>
    </item>
    <item>
      <title>cross_val_predict 中是否有 xgb.XGBRegressor 的示例，其中回调=[early_stop], Early_stop=xgb.callback.EarlyStopping？</title>
      <link>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</link>
      <description><![CDATA[在文档
XGBClassifier 有一个 EarlyStopping：
&lt;前&gt;&lt;代码&gt;```
es = xgboost.callback.EarlyStopping(
    轮数=2，
    min_delta=1e-3,
    save_best=真，
    最大化=假，
    data_name=“validation_0”，
    metric_name=“mlogloss”,
    ）
clf = xgboost.XGBClassifier(tree_method=“hist”, device=“cuda”, 回调=[es])

X, y = load_digits(return_X_y=True)
clf.fit(X, y, eval_set=[(X, y)])```

但是“validation_0”是如何实现的？引用 clf.fit 中的 eval_set 来让 EarlyStopping 指标进行评估？
我尝试将其应用到 XGBRegressor：
`将 xgboost 导入为 xgb
从 sklearn.model_selection 导入 cross_val_predict，KFold
将 pandas 导入为 pd
将 numpy 导入为 np

类 CustomEarlyStopping(xgb.callback.EarlyStopping):
    def __init__(self, rounds=2, min_delta=1e-3, save_best=True, maximise=False, data_name=“validation_0”, metric_name=“rmse”):
        super().__init__(rounds=rounds, min_delta=min_delta, save_best=save_best, maximise=maximize, data_name=data_name, metric_name=metric_name)
    
# 火车模型（10x10 倍 CV）
cvx = KFold(n_splits=10, shuffle=True, random_state=239)
es = 自定义早期停止()

模型= xgb.XGBRegressor（colsample_bytree = 0.3，learning_rate = 0.1，max_深度= 10，alpha = 10，n_estimators = 500，n_jobs = -1，
                     random_state=239，回调=[es]）
model.set_params(tree_method=&#39;approx&#39;, device=&#39;cpu&#39;)

cv_preds = []
对于范围 (0,10) 内的 i：
    cv_preds.append(cross_val_predict(模型, np.asarray(X_train), np.asarray(y_train), cv=cvx, method=&#39;predict&#39;, n_jobs=1, verbose=2))`

我把data_name=“validation_0”放在在 EarlyStopping __init__ 中，而不在每个 cv 折叠中命名测试集。
这段代码的行为有什么问题？谢谢。
XGBRegressor 的代码返回了此错误：
ValueError：必须至少有 1 个验证数据集才能提前停止。

应该发生的情况是 cv_preds 被 10 个预测 y 的 ndarray 填充。]]></description>
      <guid>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</guid>
      <pubDate>Mon, 18 Mar 2024 08:42:57 GMT</pubDate>
    </item>
    <item>
      <title>Python：GridSearchCV 花费太长时间才能完成运行</title>
      <link>https://stackoverflow.com/questions/72101295/python-gridsearchcv-taking-too-long-to-finish-running</link>
      <description><![CDATA[我正在尝试进行网格搜索来优化我的模型，但执行时间太长。我的总数据集只有大约 15,000 个观察值，大约有 30-40 个变量。我成功地通过 gridsearch 运行了一个随机森林，这花了大约一个半小时，但现在我已经切换到 SVC，它已经运行了 9 个多小时，但仍然没有完成。以下是我的交叉验证代码示例：
从 sklearn.model_selection 导入 GridSearchCV
从 sklearn 导入 svm
从 sklearn.svm 导入 SVC

SVM_Classifier= SVC(random_state=7)



param_grid = {&#39;C&#39;: [0.1, 1, 10, 100],
              ‘伽马’：[1,0.1,0.01,0.001],
              &#39;kernel&#39;: [&#39;线性&#39;, &#39;poly&#39;, &#39;rbf&#39;, &#39;sigmoid&#39;],
              &#39;度&#39; : [0, 1, 2, 3, 4, 5, 6]}

grid_obj = GridSearchCV(SVM_Classifier,
                        
                        return_train_score=真，
                        参数网格=参数网格，
                        评分=&#39;roc_auc&#39;,
                        简历=3，
                       职位数 = -1)

grid_fit = grid_obj.fit(X_train, y_train)
SVMC_opt = grid_fit.best_estimator_

打印（&#39;=&#39;*20）
print(&quot;最佳参数：&quot; + str(grid_obj.best_estimator_))
print(&quot;最佳参数：&quot; + str(grid_obj.best_params_))
print(&#39;最佳成绩：&#39;, grid_obj.best_score_)
打印（&#39;=&#39;*20）


我已经将交叉验证从 10 个减少到 3 个，并且我使用 n_jobs=-1，因此我正在调动所有核心。我还缺少什么可以在这里做来加快这个过程吗？]]></description>
      <guid>https://stackoverflow.com/questions/72101295/python-gridsearchcv-taking-too-long-to-finish-running</guid>
      <pubDate>Tue, 03 May 2022 14:51:20 GMT</pubDate>
    </item>
    </channel>
</rss>