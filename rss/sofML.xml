<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 14 Apr 2024 14:44:23 GMT</lastBuildDate>
    <item>
      <title>facebook / detr-resnet-50 模型中的标签数量</title>
      <link>https://stackoverflow.com/questions/78323867/number-of-labels-in-facebook-detr-resnet-50-model</link>
      <description><![CDATA[我正准备在自定义数据集上训练 Facebook ResNet DETR 模型，以检测图像中的签名（我的数据集中只有 1 个类）。我不确定分配给模型配置中的 num_labels 参数的适当值。根据上下文，该值是否应该设置为 1（因为我只检测签名），或者我应该为没有任何签名的情况添加第二个标签？
这是代码
model = DetrForObjectDetection.from_pretrained(pretrained_model_name_or_path=CHECKPOINT,num_labels=????,ignore_mismatched_sizes=True)]]></description>
      <guid>https://stackoverflow.com/questions/78323867/number-of-labels-in-facebook-detr-resnet-50-model</guid>
      <pubDate>Sun, 14 Apr 2024 13:02:52 GMT</pubDate>
    </item>
    <item>
      <title>具有完整链接的分层凝聚聚类以对一维数据集进行聚类</title>
      <link>https://stackoverflow.com/questions/78323771/hierarchical-agglomerative-clustering-with-complete-linkage-to-cluster-a-1dimens</link>
      <description><![CDATA[我目前正在研究分层凝聚聚类，并熟悉其在表格中呈现的数据集的应用。但是，我不确定如何将此方法应用于一维数据集，特别是当仅对图形 x 轴上表示的数据点进行聚类时。谁能指导我如何在一维数据集的层次凝聚聚类中使用单一和完整的链接？此外，如果您能提供可以帮助我了解如何解决未来类似问题的示例或方法，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78323771/hierarchical-agglomerative-clustering-with-complete-linkage-to-cluster-a-1dimens</guid>
      <pubDate>Sun, 14 Apr 2024 12:19:33 GMT</pubDate>
    </item>
    <item>
      <title>Whitewine 数据集上的 K 均值聚类问题</title>
      <link>https://stackoverflow.com/questions/78323717/k-means-clustering-problem-on-whitewine-dataset</link>
      <description><![CDATA[我目前正在努力使用 R 编程语言对名为 Whitewine 的数据集进行聚类，并比较应用主成分分析 (PCA) 之前和之后的聚类效果。尽管进行了多次尝试，我还是面临着挑战，因为即使在应用 PCA 后，我的数据点也没有以最佳方式聚类。
在 PCA 之前：我执行了异常值去除并采用 z 分数标准化来预处理数据集。&lt; /a&gt;
但是，聚类结果并不理想，聚类之间有明显的重叠。
PCA之后：利用prcomp函数，我降低了数据集的维度。
为了读者的利益，我也提供了每个实例的代码。
这是在 PCA 之前
# 异常值去除前的汇总统计信息
摘要(Whitewine_v6[, 1:11])

# 计算每列的下限和上限
lower_bounds &lt;- apply(Whitewine_v6[, 1:11], 2, function(x) 分位数(x, 0.25) - 1.5 * IQR(x))
upper_bounds &lt;- apply(Whitewine_v6[, 1:11], 2, function(x) 分位数(x, 0.75) + 1.5 * IQR(x))

# 识别前 11 列中的任何值超出范围的行
异常值 &lt;- apply(Whitewine_v6[, 1:11], 1, function(row) any(row &lt; lower_bounds | row &gt; upper_bounds))

# 对数据集进行子集化以删除具有异常值的行
Whitewine_clean &lt;- Whitewine_v6[!离群值, ]

# 检查清理后的数据集的维度
暗淡（Whitewine_clean）


#k=2 的 K 均值聚类
#K-Means 聚类投资
设置.种子(123)
k_mean1&lt;-kmeans(Whitewine_scaled, 2)

#有关集群解决方案的有用信息
#集群中心
k_mean1$中心
#集群
k_mean1$簇

# 提取BSS和TSS
BSS &lt;- k_mean1$ Betweenss
TSS &lt;- k_mean1$totss

# 计算WSS
WSS &lt;- sum(k_mean1$withinss)

# 计算总 WSS
Total_WSS &lt;- k_mean1$tot.withinss

# 计算BSS/TSS比率
BSS_TSS_ratio &lt;- BSS / TSS

# 打印结果
猫（“BSS：”，BSS，“\n”）
猫（“TSS：”，TSS，“\n”）
cat(&quot;总 WSS:&quot;, WSS, &quot;\n&quot;)
cat(&quot;BSS/TSS 比率：&quot;, BSS_TSS_ratio, &quot;\n&quot;)

#说明k-means聚类
fviz_cluster(k_mean1, Whitewine_scaled, geom=“点”, ellipse.type=“凸”, ggtheme=theme_light())

cluster_silhouette&lt;-silhouette(k_mean1$cluster, dist(Whitewine_scaled))
fviz_silhouette（cluster_silhouette）


这是 PCA 之后的
#新的“转换”数据集，其中选择的主成分作为属性
Whitewine_pca&lt;-data.frame(processed_data$x[,1:7])


我所做的总结：
我清理并缩放了我的数据集 (Whitewine)，为聚类做好准备。然后，我使用主成分分析（PCA）来简化数据。即使经过这些步骤，我的簇看起来仍然不明显。我尝试了K-means（因为这是我的项目中指定的方法，我不能使用任何其他方法），但结果并没有太大改善。现在，我正在寻求有关如何使我的集群更清晰的建议，尤其是在使用 PCA 之后。正如我之前所说，我的项目只能使用 K-means 聚类方法。我使用 4 种方法（NbClust、Elbow 方法、Gap 统计、Silhouette）确定了最佳簇数。
提前致歉，无法直接提供图像。]]></description>
      <guid>https://stackoverflow.com/questions/78323717/k-means-clustering-problem-on-whitewine-dataset</guid>
      <pubDate>Sun, 14 Apr 2024 12:00:20 GMT</pubDate>
    </item>
    <item>
      <title>如何正确加载和保存tf官方模型</title>
      <link>https://stackoverflow.com/questions/78323409/how-to-correctly-load-and-save-tf-official-models</link>
      <description><![CDATA[我正在尝试保存并加载本教程中经过训练的模型&gt; https://www.tensorflow.org/hub/tutorials/movinet
这是本教程中的简要代码：
def build_classifier(batch_size、num_frames、分辨率、backbone、num_classes)：
  “”“在骨干模型之上构建分类器。”“”“
  模型 = movinet_model.MovinetClassifier(
      骨干=骨干，
      类数=类数）
  model.build([batch_size, num_frames, 分辨率, 分辨率, 3])
  返回模型

模型 = build_classifier(batch_size, num_frames, 分辨率, 主干网, 7)
纪元数 = 30
loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
优化器 = tf.keras.optimizers.Adam(learning_rate = 0.001)

model.compile（loss=loss_obj，optimizer=&#39;adam&#39;，metrics=[&#39;accuracy&#39;]）
结果 = model.fit(train_ds,
                    验证数据=val_ds，
                    纪元=num_epochs，
                    验证频率=1，
                    详细=1)

以下代码是我尝试做的：
model.save(“./saved_model1”)
模型 = tf.keras.layers.TFSMLayer(&#39;./saved_model1&#39;, call_endpoint=&#39;serving_default&#39;)
model.evaluate(test_ds, return_dict=True)

错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
AttributeError Traceback（最近一次调用最后一次）
[86] 中的单元格，第 1 行
----&gt; 1 model.evaluate(test_ds, return_dict=True)

AttributeError：“TFSMLayer”对象没有属性“evaluate”

&lt;块引用&gt;
尝试将模型另存为 .keras 、 .h5

model.save(&#39;my_model.keras&#39;)
load_model = tf.keras.models.load_model(“my_model.keras”, custom_objects={&#39;MovinetClassifier&#39;: movinet_model.MovinetClassifier})
model.evaluate(test_ds, return_dict=True)


&lt;块引用&gt;
并收到此错误：

&lt;前&gt;&lt;代码&gt;--------------------
AttributeError Traceback（最近一次调用最后一次）
[28] 中的单元格，第 3 行
      1 model_path=“my_movinet_model2.keras”
      2 # 加载模型 = tf.keras.models.load_model(model_path)
----&gt; 3 load_model = tf.keras.models.load_model(model_path, custom_objects={&#39;MovinetClassifier&#39;: movinet_model.MovinetClassifier})
      4 model.evaluate(test_ds, return_dict=True)

文件/opt/conda/lib/python3.10/site-packages/keras/src/ saving/ saving_api.py:176，在load_model（文件路径，custom_objects，编译，safe_mode）中
    第173章
  
  ................................................

文件/opt/conda/lib/python3.10/site-packages/official/projects/movinet/modeling/movinet_model.py:78，在MovinetClassifier.__init__(self,backbone,num_classes,input_specs,activation,dropout_rate,kernel_initializer,kernel_regularizer 、bias_regularizer、output_states、**kwargs）
     75 self._output_states = 输出状态
     77 状态规格=无
---&gt; 78如果backbone.use_external_states：
     79 状态规格=骨干.初始状态规格（
     80 input_shape=input_specs[&#39;image&#39;].shape)
     82 个输入，输出 = self._build_network(
     83 主干，input_specs，state_specs=state_specs)

AttributeError：“dict”对象没有属性“use_external_states``
 
回溯很长，需要包含在内。我不确定如何像教程一样正确加载和评估保存的模型。
]]></description>
      <guid>https://stackoverflow.com/questions/78323409/how-to-correctly-load-and-save-tf-official-models</guid>
      <pubDate>Sun, 14 Apr 2024 10:10:52 GMT</pubDate>
    </item>
    <item>
      <title>值错误：数据不明确（由于某种原因，所有 x 值均为 1）</title>
      <link>https://stackoverflow.com/questions/78323348/value-error-data-is-ambiguous-for-some-reason-all-x-values-are-1</link>
      <description><![CDATA[所以我正在编写一个基于文本生成音乐的人工智能模型。我检查了所有的预处理功能，它们似乎工作得很好。 x 个样本是用于训练的预处理文本，由于某种原因，它们在输入模型时最终都为 1。
导入tensorflow为tf
从tensorflow.keras.preprocessing.text导入Tokenizer
从tensorflow.keras.layers导入LSTM，密集，嵌入，输入，TimeDistributed，激活
从tensorflow.keras.models导入模型
从tensorflow.keras.preprocessing.sequence导入pad_sequences
导入 csv
导入库
导入操作系统
将 numpy 导入为 np

os.system(&#39;cls&#39; if os.name == &#39;nt&#39; else &#39;clear&#39;)

# 加载音频的函数
def load_audio(文件路径):
    y, sr = librosa.load(文件路径)
    返回 y, sr

# 提取音频特征的函数
def extract_features(音频, sr):
    mfccs = librosa.feature.mfcc(y=音频, sr=sr)
    返回 mfccs.T

# 文本编码函数
defencode_text（文本，分词器）：
    序列 = tokenizer.texts_to_sequences([text])[0]
    返回序列

# 数据预处理函数
def preprocess_data(行、分词器、music_dir):
    Song_path = os.path.join(music_dir, row[&#39;歌曲&#39;])
    print(f&#39;检索到的歌曲路径：{song_path}&#39;)
    音频，sr = load_audio（歌曲路径）
    mfccs = extract_features(音频, sr)
    文本 = 行[&#39;提示&#39;]
    序列=encode_text（文本，分词器）
    padd_sequence = pad_sequences([序列], maxlen=43, padding=&#39;post&#39;)
    Expanded_pa​​dd_sequence = np.expand_dims(pagged_sequence, axis=1)
    返回 mfccs，扩展的_填充_序列

# 加载数据集并标记化提示
以 open(file=&#39;dataset.csv&#39;, mode=&#39;r&#39;,encoding=&#39;utf-8&#39;) 作为数据集：
    reader = csv.DictReader(数据集)
    all_prompts = [row[&#39;prompt&#39;] for reader 中的行]

分词器 = 分词器(num_words=5000)
tokenizer.fit_on_texts(all_prompts)

# 准备模型训练数据
预处理音频 = []
预处理文本 = []
music_dir = os.path.join(os.getcwd(), &#39;音乐&#39;)

以 open(file=&#39;dataset.csv&#39;, mode=&#39;r&#39;,encoding=&#39;utf-8&#39;) 作为数据集：
    数据集.seek(0)
    reader = csv.DictReader(数据集)
    对于读卡器中的行：
        mfccs，expanded_pa​​ngled_sequence = preprocess_data（行，标记器，music_dir）
        preprocessed_audio.append(mfccs)
        preprocessed_text.append(expanded_pa​​dded_sequence)

example_mfccs = preprocessed_audio[0]
mfccs_timesteps = len(example_mfccs)
mfccs_features = len(example_mfccs[0])
最大文本长度 = 43

audio_input = 输入（形状=（mfccs_timesteps，mfccs_features），名称=&#39;audio_input&#39;）
text_input = 输入（形状=（max_text_len，），名称=&#39;text_input&#39;）

num_lstm_units = 128

text_embedding = 嵌入（input_dim=tokenizer.num_words，output_dim=64）（text_input）
text_encoder = LSTM(num_lstm_units, return_sequences=True)(text_embedding)
解码器 = LSTM(num_lstm_units, return_sequences=True)(text_encoder)
解码器 = LSTM(num_lstm_units)(解码器)
#decoder_upsampled = TimeDistributed（密集（mfccs_features））（解码器）
model_output = Activation(&#39;sigmoid&#39;, name=&#39;model_output&#39;)(解码器)
模型=模型（输入=文本输入，输出=模型输出）

model.compile(loss=&#39;mse&#39;, 优化器=&#39;adam&#39;)
打印（len（预处理文本））
打印（len（预处理音频））

# 训练模型
epochs = int(input(&#39;请输入纪元数：&#39;))
model.fit(x=预处理文本，y=预处理音频，纪元=纪元)
model.save(&#39;Ihy.tf&#39;, overwrite=True, include_optimizer=True)

错误是：
ValueError：数据基数不明确。确保所有数组包含相同数量的样本。
“x”尺寸：1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 , 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1
“y”尺寸：3982、9838、7699、14171、8417、6547、9082、6763、10255、11647、6754、9491、17134、8414、10078、8303、9107、14320、 45、7339、10338、6933、9302 , 11573, 11859, 8915, 8949, 9709, 10538, 10924, 9507, 9987, 9445, 11571, 9563, 9705, 10081, 11245, 10239, 11909, 9678, , 10041

我尝试并尝试调试所有内容，并且所有文本预处理功能都工作得很好。他们返回好的数组。音频预处理正确 (y)，文本仅为 1 秒 (x)。]]></description>
      <guid>https://stackoverflow.com/questions/78323348/value-error-data-is-ambiguous-for-some-reason-all-x-values-are-1</guid>
      <pubDate>Sun, 14 Apr 2024 09:47:06 GMT</pubDate>
    </item>
    <item>
      <title>无法解释优化器标识符：<keras.src.optimizers.adam.Adam 对象位于 0x7d8646d22b00></title>
      <link>https://stackoverflow.com/questions/78323015/could-not-interpret-optimizer-identifier-keras-src-optimizers-adam-adam-object</link>
      <description><![CDATA[我正在使用这样的模型训练数据集
导入tensorflow为tf
从tensorflow.keras.optimizers导入Adam

优化器 = Adam(learning_rate=2e-5)

# 编译模型（使用优化器）
model.compile(优化器=优化器,
              损失=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              指标=[&#39;准确性&#39;])


# 训练模型
model.fit（train_inputs，train_labels，epochs=epochs，batch_size=batch_size）

它返回此错误：
ValueError：无法解释优化器标识符：
optimizer.adam 但它无法正常工作]]></description>
      <guid>https://stackoverflow.com/questions/78323015/could-not-interpret-optimizer-identifier-keras-src-optimizers-adam-adam-object</guid>
      <pubDate>Sun, 14 Apr 2024 07:12:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 rf.fit() 时尝试在 pyspark 中使用随机森林时出错</title>
      <link>https://stackoverflow.com/questions/78322361/error-trying-to-use-random-forest-in-pyspark-when-using-rf-fit</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78322361/error-trying-to-use-random-forest-in-pyspark-when-using-rf-fit</guid>
      <pubDate>Sun, 14 Apr 2024 00:30:15 GMT</pubDate>
    </item>
    <item>
      <title>将数据拆分为训练集、验证集和测试集，ID 不重叠，并且仍然平衡目标类</title>
      <link>https://stackoverflow.com/questions/78322346/splitting-data-into-training-validation-and-test-sets-without-overlapping-ids</link>
      <description><![CDATA[我需要将大型数据集拆分为一定比例的训练集、验证集和测试集，同时确保满足以下条件：

在每组中保留唯一的 ID。任何 ID 不能属于多于一组。
每次数据重组时，训练、验证和测试集中每个级别（“热”、“暖”、“冷”）都需要至少出现一次。

data &lt;- data.frame(ID = c(001, 001, 001,
                           002, 002, 002, 002,
                           003, 003, 003, 003,
                           004, 004, 004, 004, 004, 004,
                           005, 005, 005, 005, 005,
                           006, 006, 006, 006,
                           007, 007, 007,
                           008, 008,
                           009, 009,
                           010, 010, 010),
                   var1 = c(0102, 0210, 0405,
                            0318, 0629, 1201,0101,
                            0923、0702、0710、0801、
                            0203、0501、1204、0516、0112、1005、
                            1101、1125、1020、0112、0310、
                            0203、0401、0607、0811、
                            1010、1212、0707、
                            0430, 0428,
                            1030, 1008,
                            0501, 0511, 0601),
                   var2 = c(“冷”, “冷”, “冷”,
                            “温暖”、“温暖”、“温暖”、“温暖”、
                            “冷”、“冷”、“冷”、“冷”、
                            “温暖”、“温暖”、“温暖”、“温暖”、“温暖”、“温暖”、
                            “热”、“热”、“热”、“热”、“热”、
                            “冷”、“冷”、“冷”、“冷”、
                            “热”、“热”、“热”、
                            “温暖”、“温暖”、
                            “热”、“热”、
                            “冷”、“冷”、“冷”））

我尝试使用数据分割包 caret(fx = createDataPartition()) 和 splitTools (fx = partition()) 以及 dplyr 采样函数，但它们应用的分组可确保每个 ID 出现在所有集合中。 
减少数据集是可以的。以下是由现有 Stack Overflow 问题引导的众多尝试之一：
赋值 &lt;- 数据 %&gt;%
        选择（ID，var2）%&gt;%
        不同的(ID) %&gt;%
        行式() %&gt;%
        mutate(Group=sample(c(“验证”,“训练”,“测试”), 1,
                             概率 = c(0.70, 0.20, 0.10)))
数据%&gt;%
  left_join（作业，数据，by =“ID”）

这种尝试忽略了概率论点*没有设置比例。它还不能确保所有级别都出现在训练、验证和测试集中。]]></description>
      <guid>https://stackoverflow.com/questions/78322346/splitting-data-into-training-validation-and-test-sets-without-overlapping-ids</guid>
      <pubDate>Sun, 14 Apr 2024 00:19:39 GMT</pubDate>
    </item>
    <item>
      <title>无法训练具有多个输出的 keras 模型</title>
      <link>https://stackoverflow.com/questions/78322340/can-not-train-keras-model-with-multiple-outputs</link>
      <description><![CDATA[我正在创建一个具有多个不同形状输出的 keras 模型，因为 model.fit 方法不允许我传递 y 值的列表或字典。如果重要的话，模型会拍一张脸的照片，找出几个特征，并尝试猜测这个人的名字。
模型定义：
输入 = tf.keras.Input(shape=(1024, 1024, 3))

稠密_1 = tf.keras.layers.Dense(8192)(输入)
密集_2 = tf.keras.layers.Dense(4096)(密集_1)
race_dense = tf.keras.layers.Dense(512)(dense_2)
性别_密度 = tf.keras.layers.Dense(512)(dense_2)
eye_distance_dense = tf.keras.layers.Dense(512)(dense_2)
name_dense1 = tf.keras.layers.Dense(4096)(输入)
name_dense2 = tf.keras.layers.Dense(2048)(name_dense1)
种族 = tf.keras.layers.Dense(1, name=&quot;race&quot;)(race_dense)
性别 = tf.keras.layers.Dense(1, name=“性别”)(gender_dense)
eye_distance = tf.keras.layers.Dense(1, name=&quot;eye_distance&quot;)(eye_distance_dense)
name_t = tf.keras.layers.Dense(32, name=“名称”)(name_dense2)

模型= tf.keras.Model（输入=输入，输出=[种族，性别，眼睛距离，姓名]）
model.compile(优化器=&#39;亚当&#39;,
              损失={&#39;race&#39;: &#39;sparse_categorical_crossentropy&#39;,
                    &#39;性别&#39;: &#39;sparse_categorical_crossentropy&#39;,
                    &#39;eye_distance&#39;: &#39;sparse_categorical_crossentropy&#39;,
                    &#39;名称&#39;：&#39;sparse_categorical_crossentropy&#39;}，
              指标=[&#39;准确性&#39;])

培训：
model.fit(np.array([图像]).astype(np.float32), ([
                    [比赛],
                    [性别],
                    [眼睛距离]，
                    [填充名称]
]))

我尝试过的 Y 值：
&lt;前&gt;&lt;代码&gt;[
                    [比赛],
                    [性别],
                    [眼睛距离]，
                    [填充名称]
]

和
&lt;前&gt;&lt;代码&gt;{
                    “种族”：[种族]，
                    “性别”：[性别]，
                    “眼睛距离”：[眼睛距离]，
                    “名称”：[填充名称]
}

无论我做什么，它总是会给我一个类似的错误：
ValueError: 无法找到可以处理输入的数据适配器：, ( 包含类型 {&#39;( 包含类型值 {&quot;&quot;})&#39;})
]]></description>
      <guid>https://stackoverflow.com/questions/78322340/can-not-train-keras-model-with-multiple-outputs</guid>
      <pubDate>Sun, 14 Apr 2024 00:15:42 GMT</pubDate>
    </item>
    <item>
      <title>了解梯度提升中的模型选择</title>
      <link>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</link>
      <description><![CDATA[包含问题的图片
我目前正在研究梯度增强模型，并且遇到了一种我不确定的情况。在我的模型的第一阶段，拟合了决策树，这由模型的阶跃函数外观表示。
但是，当我检查第一阶段的残差时，它们似乎表现出二次模式。这促使我考虑在第二阶段使用 2 次多项式模型。
但我很困惑，因为问题陈述建议在第二阶段使用与第一阶段相同类型的模型（即决策树）。
决策树能否捕获残差中的二次模式？或者，尽管问题陈述提出了建议，但我应该在第二阶段考虑不同类型的模型？
任何关于如何处理这种情况的澄清将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78322296/understanding-model-selection-in-gradient-boosting</guid>
      <pubDate>Sat, 13 Apr 2024 23:38:22 GMT</pubDate>
    </item>
    <item>
      <title>使用推荐引擎为两个用户推荐一部电影</title>
      <link>https://stackoverflow.com/questions/78321965/using-recommendation-engine-to-recommend-a-movie-for-two-users</link>
      <description><![CDATA[我使用 torch 和 Fastai 来训练数据并得出用户权重与物品权重。有了经过训练的数据，使用两个用户权重的组合向一对用户推荐电影的最佳方式是什么？是否像取一对用户的 n 个参数权重的平均值然后使用这些权重和余弦相似度函数找到最佳项目一样简单？我是机器学习和数据科学的新手，所以如果这是一个愚蠢的问题，我深表歉意。
movie_factors = learn.model.i_weight.weight
user_factors = learn.model.u_weight.weight

#随机选择两个用户
user1_factors = user_factors[43].data.cpu().numpy()
user2_factors = user_factors[54].data.cpu().numpy()

# 计算user1_factors和user2_factors的平均值
avg_u_factors = torch.from_numpy(np.array((user1_factors + user2_factors) / 2)).to(movie_factors.device)

距离 = nn.CosineSimilarity(dim=1)(movie_factors, avg_u_factors)
idx = distances.argsort(降序=True)[1]
dls.classes[&#39;标题&#39;][idx]
]]></description>
      <guid>https://stackoverflow.com/questions/78321965/using-recommendation-engine-to-recommend-a-movie-for-two-users</guid>
      <pubDate>Sat, 13 Apr 2024 20:41:42 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 pytorch 训练机器学习多项式回归模型</title>
      <link>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch</link>
      <description><![CDATA[我想将数据绘制成 plt.scatter 表单，但是当我尝试填充它时，它只是说 x 和 y 的大小不同，而且我还挤压了它们仅一维，以便更容易绘制，但仍然不起作用。
这是情节机制：
#使用 matplotlib.pyplot 中的散点图 (x,y) 可视化数据
defplot_predictions(train_features=X_train,
                     train_labels=y_train,
                     test_features=X_test,
                     测试标签=y_测试，
                     预测=无）：
    plt.figure(figsize= (10,7))

    plt.scatter(X_train, y_train, c=“g”, label=“训练数据”)

    plt.scatter(X_test, y_test, c=“b”, label=“测试数据”)

    如果预测不是 None：
        plt.scatter（test_features，预测，c =“r”，标签=“预测”）

    plt.legend(prop={“大小”: 14})

绘图预测（）

#这里尝试解决问题
Predictions_reshape=y_preds.squeeze(dim=1)
labels_reshape=y_train.squeeze(dim=1)
打印（len（y_train），len（y_preds））
打印（labels_reshape.shape，predictions_reshape.shape）

labels_reshape=y_train.detach().numpy()
Predictions_reshape=y_preds.detach().numpy()
图_预测（标签_重塑，预测=预测_重塑）

&lt;块引用&gt;
ValueError：x 和 y 的大小必须相同

我尝试压缩张量，使它们只有一个暗淡，并且我还检查了镜头是否相同，确实如此。]]></description>
      <guid>https://stackoverflow.com/questions/78321929/im-training-a-model-of-machine-learning-polynomial-regression-using-pytorch</guid>
      <pubDate>Sat, 13 Apr 2024 20:23:01 GMT</pubDate>
    </item>
    <item>
      <title>我可以重新训练 AutoModelForSequenceClassification 以生成文本吗？</title>
      <link>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</link>
      <description><![CDATA[我的目标是微调 Mistral 7b 以编写短意识流（文本完成，而不是遵循指令）。
我有一个大型数据库（100 万行），其中包含从互联网上抓取的短文本。我手动将 15k 行标记为 good (1k) 和 bad（其余 14k）示例。我的计划是训练 AutoModelForSequenceClassification在这些示例上标记其他 985k 行。
通过这种方式，我希望收集大约 20k 意识流的好例子来微调 Mistral 7b。
但仅对good示例进行微调并不会使用bad示例中的信息，这些示例的数量要多得多。因此，我正在考虑使用 Mistral 7b 作为 AutoModelForSequenceClassification 的基本模型（遵循 这篇 Medium 文章），然后重新训练生成的 AutoModelForSequenceClassification 以进行文本补全。这需要移除分类头并添加新的/重新训练的 LoRA 组件。
您认为这可行吗？这是否会削弱模型（例如，需要重新学习语法），或者这是否是将坏反例的信息合并到文本生成中的有效方法？或者至少为 LoRA 文本生成微调提供一个良好的初始化点？]]></description>
      <guid>https://stackoverflow.com/questions/78284197/can-i-retrain-an-automodelforsequenceclassification-for-text-generation</guid>
      <pubDate>Sat, 06 Apr 2024 11:32:55 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tfidfvectorizer 的功能从英语修改为西班牙语</title>
      <link>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</link>
      <description><![CDATA[我有一个 TfidfVectorizer 模型，该模型经过英语文本数据的训练来预测英语通话中的情绪。我想针对西班牙语文本调整此 TfidfVectorizer，以便我可以将其与使用原始英语 TfidfVectorizer 训练的现有 XGBoost 模型一起使用。我的目标是在将功能从英语转换为西班牙语的同时保留现有的权重，例如将“谢谢”翻译为西班牙语。致“谢谢”，并重复使用旧的权重。本质上，我想应用相同的 TfidfVectorizer，但修改了功能名称。
这些功能已从英语翻译为西班牙语，并且 TfidfVectorizer 已针对英语文本进行了训练。我需要一种方法来构建一个新的 TfidfVectorizer，它融合了旧的权重和新的西班牙语特征，而无需重新拟合模型或将整个文本语料库翻译成西班牙语。你能推荐一种Python方法来实现这一点吗？请添加相关的Python代码。]]></description>
      <guid>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</guid>
      <pubDate>Wed, 27 Mar 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中使用 Transformers.pipeline 进行微调 BERT 模型推理时，是否应该使用 model.eval() ？</title>
      <link>https://stackoverflow.com/questions/76388696/should-i-use-model-eval-when-using-transformers-pipeline-for-inference-with-a</link>
      <description><![CDATA[使用 Trainer() 训练 Transformer 模型时，文档显示了以下用法：
model = AutoModelForSequenceClassification.from_pretrained(“bert-base-cased”, num_labels=5)

教练=教练（
    型号=型号，
    参数=训练参数，
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset，
    计算指标=计算指标，
）

如果您选中 model.training 标志，默认情况下它会设置为 false，但 Trainer 有一个调用 model 的逻辑.train() 将其设置为 True，这是有道理的。
使用此微调模型进行推理时，您可以利用 transformers.pipeline，它接受模型对象作为参数。但是，管道没有检查模型是否处于训练模式的逻辑。我没有在源代码中找到它，并且在文档中的任何地方都没有看到它。当我使用管道进行预测时，结果不确定，这是模型未处于评估模式的另一个指标。
生成器 = 管道(
                “一些_任务”，
                型号=型号，
                分词器=分词器，
                聚合策略=聚合策略，
                忽略标签=[],
            ）

Generator(“Example”) # 返回分数 X
Generator(“Example”) # 返回分数 Y

# 但如果在创建管道对象之前使用 model.eval()
Generator(“Example”) # 返回分数 X
Generator(“Example”) # 返回分数 X

我应该在 pipeline 中使用模型之前调用 model.eval() 还是应该 pipeline 自行处理它，但由于某种原因不是吗？]]></description>
      <guid>https://stackoverflow.com/questions/76388696/should-i-use-model-eval-when-using-transformers-pipeline-for-inference-with-a</guid>
      <pubDate>Fri, 02 Jun 2023 09:06:27 GMT</pubDate>
    </item>
    </channel>
</rss>