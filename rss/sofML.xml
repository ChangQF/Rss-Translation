<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 08 Apr 2024 03:15:27 GMT</lastBuildDate>
    <item>
      <title>CIFAR10 数据集上的 Tensorflow CNN 模型无法学习</title>
      <link>https://stackoverflow.com/questions/78289990/tensorflow-cnn-model-on-cifar10-dataset-not-learning</link>
      <description><![CDATA[首先，我最近一直在做一项家庭作业，在 CIFAR10 灰度数据集上实现 CNN 模型，以展示其与之前作业中的 FNN 相比的准确性。
但是，这不是我的作业问题，因为我想讨论的训练 CNN 时似乎遇到了更深层次的系统性问题。
值得注意的是，当我运行 CNN 时，似乎无论什么参数、数据集或任何细节都会改变我的模型根本无法学习的事实。
例如，当我在 youtube 上下载与本教程相关的 jupyter 笔记本并自己运行它时，我首先怀疑有更深层次的错误：
链接
对于 FNN，我得到的结果与笔记本/视频中显示的结果完全相同。然而，当我运行 CNN 的单元格时，我发现模型没有进行训练，并且损失了 Nan，准确度为 10%，这与随机猜测一致。视频/笔记本说我应该获得 70% 左右的准确度，所以这似乎非常错误。
我下载的另一个教程也发生了这种情况。他们报告在 MNIST 数据集上的准确度为 90%，但是当我运行完全相同的代码时，该模型仅保持在 10% 左右。
如果相关，我可以提供 tf、numpy 等的版本。首先，我使用 GPU 版本的 Tensorflow 在 conda 环境中运行这一切。]]></description>
      <guid>https://stackoverflow.com/questions/78289990/tensorflow-cnn-model-on-cifar10-dataset-not-learning</guid>
      <pubDate>Mon, 08 Apr 2024 02:56:44 GMT</pubDate>
    </item>
    <item>
      <title>创建一个自定义 AI 模型，从任何输入网站提取特定数据</title>
      <link>https://stackoverflow.com/questions/78289977/create-a-custom-ai-model-that-extracts-specific-data-from-any-input-website</link>
      <description><![CDATA[我想制作一个自定义脚本，可以从网站（可以是具有类似数据类型的任何网站）中提取特定类型的表数据。因为有很多网站的结构不同，有些有table标签，有些使用div，有些使用其他标签。
数据有相似之处，我认为这是可能实现的。
我将向专家展示一些示例。
https://www.rockauto.com/en/moreinfo.php?pk=101750&amp;cc=0&amp;pt=1000587&amp;jsn=788&amp;optionchoice=0-0-8-1


像这样的表和交换号码（如果有）将由脚本提取。
另一个例子是
https://www.aimsinduscial。 com.au/gates-9770-13a1955-green-stripe-belt-heavy-duty-en

您可以看到表格中有产品的规格。需要提取此类表。
现在，我对机器学习一无所知，并且想要这个项目的路线图。我没有太多时间，这就是我需要指导的原因。
如果有人可以指导我如何实现这一目标或给我一个正确的路线图。我应该学习什么，什么对我这个项目有帮助。不过，我精通 python 和数据抓取。]]></description>
      <guid>https://stackoverflow.com/questions/78289977/create-a-custom-ai-model-that-extracts-specific-data-from-any-input-website</guid>
      <pubDate>Mon, 08 Apr 2024 02:49:21 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：“GraphModule”对象不可下标（Pytorch 中 .onnx ML 模型的访问权重）</title>
      <link>https://stackoverflow.com/questions/78289901/typeerror-graphmodule-object-is-not-subscriptable-access-weights-for-onnx-m</link>
      <description><![CDATA[我有一个流行的 .onnx ML 天气预报模型，我正在尝试将其转换为 PyTorch 进行微调。我使用以下代码来转换它：
导入操作系统
将 numpy 导入为 np
导入onnx
从 onnx 导入 numpy_helper
将 onnxruntime 导入为 ort
从 onnx2torch 导入 转换

model_24 = onnx.load(&#39;pangu_weather_24.onnx&#39;)
tm = Convert(model_24) #将onnx模型转换为torch

从这里，我想访问“tm”对象中模型的权重，但我似乎无法在网上找到任何相关资源。
尝试使用 tm[0] 对其进行下标会显示以下错误：
TypeError：“GraphModule”对象不可下标

通过“tm.dict”获取该对象的字典更加令人困惑（粘贴在图像中）。
在线访问 PyTorch 权重矩阵的常规方法也显示出图形模块不可下标的相同错误]]></description>
      <guid>https://stackoverflow.com/questions/78289901/typeerror-graphmodule-object-is-not-subscriptable-access-weights-for-onnx-m</guid>
      <pubDate>Mon, 08 Apr 2024 02:13:29 GMT</pubDate>
    </item>
    <item>
      <title>Google colab 如何修复安装 Box2D 时出现的车轮构建错误</title>
      <link>https://stackoverflow.com/questions/78289756/google-colab-how-to-fix-wheel-building-error-when-installing-box2d</link>
      <description><![CDATA[我正在尝试在 Google Colab 中使用 Box2D 和 TensorFlow 编写强化学习模型。我对所有内容都有一个简单的单行安装命令，因为我发现每当我尝试进行多行安装时，Colab 都会中断，甚至 Gymnasium 主页面也将 pip install Box2D 作为正确的安装方法它。
每当我尝试安装它时，都会收到此错误：
!pip install tensorflow[and-cuda] stable-baselinesgym Box2D
  错误：子进程退出并出现错误
  
  × python setup.py bdist_wheel 未成功运行。
  │ 退出代码：1
  ╰─&gt;输出见上文。
  
  注意：此错误源自子进程，并且可能不是 pip 的问题。
  Box2D 的构建轮子（setup.py）...错误
  错误：Box2D 构建轮子失败
  为 Box2D 运行 setup.py clean
构建 Box2D 失败
错误：无法为 Box2D 构建轮子，这是安装基于 pyproject.toml 的项目所必需的

我在网上找到的每个解决方案都不起作用，但似乎都有同样的问题。我该如何修复它？]]></description>
      <guid>https://stackoverflow.com/questions/78289756/google-colab-how-to-fix-wheel-building-error-when-installing-box2d</guid>
      <pubDate>Mon, 08 Apr 2024 00:44:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用粒子群优化（PSO）进行数据集的特征选择以使用Python预测疾病？</title>
      <link>https://stackoverflow.com/questions/78289701/how-using-particle-swarm-optimization-pso-for-features-selection-of-dataset-fo</link>
      <description><![CDATA[拜托，我需要代码 python 来提高预测疾病的准确性，使用 PSO 进行 10,000 条记录的特征（70 个属性）选择，然后使用机器学习算法。
我尝试了很多代码，但没有任何提高准确性的好处。]]></description>
      <guid>https://stackoverflow.com/questions/78289701/how-using-particle-swarm-optimization-pso-for-features-selection-of-dataset-fo</guid>
      <pubDate>Mon, 08 Apr 2024 00:07:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 cGAN 生成的似乎只是噪声？</title>
      <link>https://stackoverflow.com/questions/78289217/why-is-my-cgan-generating-what-seems-to-be-just-noise</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78289217/why-is-my-cgan-generating-what-seems-to-be-just-noise</guid>
      <pubDate>Sun, 07 Apr 2024 20:36:07 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 预测的问题</title>
      <link>https://stackoverflow.com/questions/78288928/problems-with-tensorflow-forcasting</link>
      <description><![CDATA[我正在创建一个机器学习预测模型来预测苏格兰的风能和太阳能。当通过预测模型运行它时，它会产生大约 0.00004 的损失，所以我假设它能够很好地预测这些数据。但这就是产生的
编辑：
对于上下文，使用的数据框是苏格兰某个地点平均风速的实际值。它采用 M/S 格式，并已标准化以用于预测算法。
带有预测的图表
显然这是不对的，我不知道如何解决它。
这是我使用的代码
df = pd.DataFrame(data=wind_data[0], columns=[&#39;mean_wind_speed&#39;])

df.fillna(方法=&#39;bfill&#39;, inplace=True)

输入形状 = (365*24*5, 1)
输出形状 = (30*24, 1)

def 准备数据(df):
    n = len(df)
    train_df = df[0:int(n * 0.6)]
    val_df = df[int(n * 0.6):int(n * 0.8)]
    test_df = df[int(n * 0.8):]

    train_std = train_df.std().values
    train_mean = train_df.mean().values

    train_df = (train_df - train_mean) / train_std
    val_df = (val_df - train_mean) / train_std
    test_df = (test_df - train_mean) / train_std

    返回train_df、val_df、test_df

train_df、val_df、test_df = 准备数据(df)

def create_lstm_model(input_shape,learning_rate=0.001):
    优化器 = Adam(学习率=学习率)
    模型=顺序（[
        LSTM（64，输入形状=输入形状），
        密集(1)
    ]）
    model.compile（优化器=优化器，损失=&#39;mse&#39;，指标=[&#39;mae&#39;]）
    返回模型

自定义学习率 = 0.001

lstm_model = create_lstm_model(input_shape=(input_shape[0], input_shape[1]),learning_rate=custom_learning_rate)
历史= lstm_model.fit（train_df，train_df，validation_data =（val_df，val_df），epochs = 10）

def recursive_forecast（模型，初始输入，预测步骤）：
    预测=[]
    当前输入 = 初始输入
    对于 _ 在范围内（forecast_steps）：
        # 预测下一个时间步
        next_prediction = model.predict(current_input[np.newaxis, :, :])
        # 将预测添加到预测中
        预测.append(next_prediction)
        # 通过删除第一个时间步并附加预测来更新当前输入
        current_input = np.concatenate((current_input[1:], next_prediction), axis=0)
    返回 np.array(预测).reshape(-1, 1)

initial_input = test_df.iloc[0:input_shape[0]] # 使用最后一个 &#39;input_shape[0]&#39; 数据点作为初始输入
Forecast_steps = output_shape[0] # 预测的时间步数
预测= recursive_forecast（lstm_model，initial_input.values，forecast_steps）

plt.plot(np.arange(len(test_df)), test_df, label=&#39;实际&#39;, color=&#39;蓝色&#39;)
plt.plot(np.arange(len(test_df), len(test_df) + len(预测)), 预测, label=&#39;预测&#39;, color=&#39;红色&#39;)
plt.xlabel(&#39;时间步长&#39;)
plt.ylabel(&#39;风速&#39;)
plt.title(&#39;预测&#39;)
plt.网格（真）
plt.图例()
plt.show()

任何帮助将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78288928/problems-with-tensorflow-forcasting</guid>
      <pubDate>Sun, 07 Apr 2024 18:45:26 GMT</pubDate>
    </item>
    <item>
      <title>关闭选项卡后如何保持 Paperspace 的渐变笔记本运行</title>
      <link>https://stackoverflow.com/questions/78288786/how-do-i-keep-paperspaces-gradients-notebooks-running-after-i-close-my-tabs</link>
      <description><![CDATA[我正在纸空间的渐变上运行笔记本。当我预订一台机器 4 小时并开始在其中运行 jupyter 笔记本时，如果我关闭浏览器，执行就会停止。我怎样才能改变这种行为？我在 google collab pro 上没有遇到这个问题
我尝试了免费和付费 GPU 机器，并尝试升级到 Pro 帐户]]></description>
      <guid>https://stackoverflow.com/questions/78288786/how-do-i-keep-paperspaces-gradients-notebooks-running-after-i-close-my-tabs</guid>
      <pubDate>Sun, 07 Apr 2024 17:58:26 GMT</pubDate>
    </item>
    <item>
      <title>澄清：模型评估 - Tran 和 Val 损失</title>
      <link>https://stackoverflow.com/questions/78288712/clarification-model-evaluation-tran-and-val-loss</link>
      <description><![CDATA[我不确定我的模型是否表现良好。我的理解是，如果我的模型在训练和验证损失之间进行调整，也表明没有欠拟合或过拟合。然而，我的教授不同意，并说我的模型没有经过充分的训练，这表明图表本身是不正确的。
我不确定问题出在哪里或者到底出了什么问题。有人可以提供一些指导或帮助吗？
我的模型的训练和 val 损失图
我通过在嵌入层中添加一些噪声来训练模型。
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/78288712/clarification-model-evaluation-tran-and-val-loss</guid>
      <pubDate>Sun, 07 Apr 2024 17:35:17 GMT</pubDate>
    </item>
    <item>
      <title>如何创建 CNN-LSTM 架构？</title>
      <link>https://stackoverflow.com/questions/78288542/how-to-create-cnn-lstm-architecture</link>
      <description><![CDATA[我尝试创建混合 CNN 和 LSTM 模型。我遇到了与架构形状相关的问题。这导致epoch无法跑完数据200次。
我的数据大小是（96,2）
错误：
纪元 1/200
    178/未知 9s 34ms/步 - 损耗：1.2366 - mse：5.4560
-------------------------------------------------- ------------------------
InvalidArgumentError Traceback（最近一次调用最后一次）
第 4 行 [40] 中的单元格
      2 is_train = True
      3 如果是_train：
----&gt; 4 model_create.fit（train_dataset，epochs = 200，batch_size = 128）

无法将张量添加到批次中：元素数量不匹配。形状为：[张量]：[78,2]，[批次]：[96,2]
     [[{{node IteratorGetNext}}]] [操作：__inference_one_step_on_iterator_23678]

CNN-LSTM模型：
def create_model_architecture():
    model_cnn = tf.keras.models.Sequential([
        tf.keras.layers.Conv1D（过滤器=64，
                               内核大小=3，
                               激活=&#39;relu&#39;,
                               输入形状=输入数据形状），
        tf.keras.layers.MaxPooling1D(pool_size=2,strides=1, padding=“相同”),
        tf.keras.layers.Conv1D（过滤器=64，
                               内核大小=3，
                               激活=&#39;relu&#39;),
        tf.keras.layers.MaxPooling1D(pool_size=2,strides=1, padding=“相同”),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.LSTM(32, return_sequences=True),
        tf.keras.layers.LSTM(16),
        tf.keras.layers.Reshape((-1,16)),
        #tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1, 激活=&#39;sigmoid&#39;)
    ]）
    返回 model_cnn


编译模型
def create_model():
    tf.random.set_seed(51)

    model_create = create_model_architecture()
    #model_create = create_LSTM_model()
    model_create.compile(loss=tf.keras.losses.Huber(),
                  优化器=tf.keras.optimizers.Adam(learning_rate=0.001),
                  指标=[“mse”])
    返回模型_创建

模型创建 = 创建模型()

model_create.summary()

model_create.fit（train_dataset，epochs = 200，batch_size = 128）


我曾尝试在 flatten() 函数之前添加 reshape 来改变形状。我还减小了批量大小和纪元大小。这些都不起作用。如何将我的模型与 train_data 相匹配？]]></description>
      <guid>https://stackoverflow.com/questions/78288542/how-to-create-cnn-lstm-architecture</guid>
      <pubDate>Sun, 07 Apr 2024 16:34:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pytorch 进行高效的成对采样</title>
      <link>https://stackoverflow.com/questions/78287754/efficient-pair-sampling-with-pytorch</link>
      <description><![CDATA[我有一个包含大约 150k 图像和 150k 音频的数据集。每个图像，都有相应的音频。我希望我的网络能够学习使用图像数据将一个音频映射到另一个音频。
当我创建这些源目标对时，我的目标是从训练数据的子集中采样的，并且还必须满足特定的阈值标准。然后创建源目标对进行训练。
我现在这样做的方式是导出目标采样的子集，并在自定义数据集的 getitem() 中应用阈值。这花费了太长的时间并在训练过程中造成了瓶颈。
我不确定如何解决这个问题并加快训练速度。我该如何解决这个问题。
def _getitem_(idx):
   sourceimg、sourceaudio = self.data[idx]
   Target_dataset = create_subset(sourceimg, sourceaudio)
   迭代次数 = 0
   虽然正确：
     targetimg, targetaudio = np.random(Target_dataset)
     如果 cal_value(target_img) &gt;= 阈值：
       返回sourceimg、sourceaudio、targetimg、targetaudio
     迭代+=1
     如果迭代次数 &gt;= 10：
       _getitem_(random.randint(0, len(self.dataset))

def cal_val(targetimg, sourceimg):
   sourceimg=np.load(source_mat)
   targetimg = np.load(target_mat)
   diff = np.abs(source_mat - target_mat)
   阈值差异 = np.where(diff &gt; 0 , 1, 0)
   Average_difference = np.mean(thresholded_difference)
   返回平均值_差异

def create_subset(sourceimg):
  子数组=[]
  sourceindex1, sourceindex2 = os.path.basename(sourceimg).split(“/”)[1:3]
  对于 arr 中的元素：
      elementindex1, elementindex2 = os.path.basename(element).split(“/”)[1:3]
       if(elementindex1 == sourceindex1 且 elementindex2 == sourceindex2):
            子数组.append(元素)
  返回子数组

我在训练期间尝试过这样做。但就我拥有的数据量而言，这根本没有效率。如何在不增加数据加载器中的批处理大小或 num_worker 的情况下加快训练速度]]></description>
      <guid>https://stackoverflow.com/questions/78287754/efficient-pair-sampling-with-pytorch</guid>
      <pubDate>Sun, 07 Apr 2024 12:16:21 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV 新手，我如何安装/构建 opencv_traincascade</title>
      <link>https://stackoverflow.com/questions/78286577/new-to-opencv-how-do-i-install-build-opencv-traincascade</link>
      <description><![CDATA[所以我一直在从事机器学习项目，并且需要使用 opencv_traincascade 训练自定义数据集。但每当我尝试安装它时，它就永远无法工作。我还有其他东西，比如 opencv_annotation 和其他东西可以工作，但是 traincascade 或 event createsamples 不起作用。我必须手动构建这些吗？
我下载了mingw-gcc、cmake，在网上找不到可行的解决方案。顺便说一句，我有 opencv 4.9.0，手动安装在 anaconda 和我的 C: 驱动器中。我也尝试过寻找一些第三方，他们安装了整个 opencv 并且可以复制，但没有运气。任何帮助将不胜感激，谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78286577/new-to-opencv-how-do-i-install-build-opencv-traincascade</guid>
      <pubDate>Sun, 07 Apr 2024 03:46:34 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow”没有属性“Summary”</title>
      <link>https://stackoverflow.com/questions/78277279/attributeerror-module-tensorflow-has-no-attribute-summary</link>
      <description><![CDATA[运行此代码时：
def scalar_summary(自身、标签、值、步骤)：
        “”“记录标量变量。”“”
        摘要 = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])
        self.writer.add_summary（摘要，步骤）

我收到错误消息：
AttributeError：模块“tensorflow”没有属性“Summary”。您的意思是：“摘要”吗？
我正在尝试运行 https:/ 中的代码Google colabs 上的 /github.com/InhwanBae/ENet-SAD_Pytorch/blob/master/utils/tensorboard.py。我正在尝试使用 CULane 数据集训练 ENet-SAD 模型。]]></description>
      <guid>https://stackoverflow.com/questions/78277279/attributeerror-module-tensorflow-has-no-attribute-summary</guid>
      <pubDate>Fri, 05 Apr 2024 00:51:51 GMT</pubDate>
    </item>
    <item>
      <title>ML ColumnTransformer OneHotEncoder</title>
      <link>https://stackoverflow.com/questions/78274904/ml-columntransformer-onehotencoder</link>
      <description><![CDATA[当在数据帧的第一列中转换分类数据时，我发现 ColumnTransformer 与 OneHotEncoder 出现奇怪的行为。当我向 csv 文件添加一行时，就会发生此行为。
初始数据为：
标题、每日总收入、影院、DayInYear
AC汀巴黎,307,5,257
给莫莫的一封信，307,5,257
生命的另一天,307,5,257
批准收养，307,5,257
四月与非凡的世界, 307,5,257
美女,307,5,257
鸟男孩被遗忘的孩子，307,5,257
奇科丽塔,307,5,257

运行代码时
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd

数据集 = pd.read_csv(&#39;../data/GKIDS_DayNum_test_names.csv&#39;)
数据集[&#39;标题&#39;].str.strip()
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

从 sklearn.compose 导入 ColumnTransformer
从 sklearn.preprocessing 导入 OneHotEncoder

title_column_index = dataset.columns.get_loc(&#39;标题&#39;)
print(&#39;标题索引：&#39;, title_column_index)
ct = ColumnTransformer(transformers=[(&#39;编码器&#39;, OneHotEncoder(), [title_column_index])], 剩余=&#39;passthrough&#39;)
X_Encoded = np.array(ct.fit_transform(X))
打印（X_编码）

结果是正确的：
&lt;前&gt;&lt;代码&gt;[[1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 307 5]]

但是，当我添加附加行时：BlueGiant,307,5,257
到文件并重新运行代码我得到奇怪的输出：
&lt;前&gt;&lt;代码&gt; (0, 0) 1.0
  (0, 9) 307.0
  (0, 10) 5.0
  (1, 1) 1.0
  (1, 9) 307.0
  (1, 10) 5.0
  (2, 2) 1.0
  (2, 9) 307.0
  (2, 10) 5.0
  (3, 3) 1.0
  (3, 9) 307.0
  (3, 10) 5.0
  (4, 4) 1.0
  (4, 9) 307.0
  (4, 10) 5.0
  (5, 5) 1.0
  (5, 9) 307.0
  (5, 10) 5.0
  (6, 6) 1.0
  (6, 9) 307.0
  (6, 10) 5.0
  (7, 8) 1.0
  (7, 9) 307.0
  (7, 10) 5.0
  (8, 7) 1.0
  (8, 9) 307.0
  (8, 10) 5.0

我不明白为什么会这样。
请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78274904/ml-columntransformer-onehotencoder</guid>
      <pubDate>Thu, 04 Apr 2024 15:25:57 GMT</pubDate>
    </item>
    <item>
      <title>Yolo v9 保存每个纪元和损失</title>
      <link>https://stackoverflow.com/questions/78232885/yolo-v9-saving-each-epoch-and-loss</link>
      <description><![CDATA[我有这段代码可以在自定义数据集上训练 yolov9 模型。但由于我只有 T4 GPU 并且我的数据集很大，所以它只训练了 3 个 epoch，然后就停止了。我想单独训练每个纪元并保存它，它是损失。我该怎么做？
这是我正在使用的代码：
%cd /content/my_drive/MyDrive/yolov9/yolov9

!python train.py \
--batch 16 --epochs 25 --img 640 --min-items 0 --close-mosaic 15 \
--data /content/my_drive/MyDrive/yolov9/yolov9/data.yaml \
--weights /content/my_drive/MyDrive/yolov9/yolov9/gelan-c.pt \
--cfg 模型/检测/gelan-c.yaml \
--hyp hyp.scratch-high.yaml
]]></description>
      <guid>https://stackoverflow.com/questions/78232885/yolo-v9-saving-each-epoch-and-loss</guid>
      <pubDate>Wed, 27 Mar 2024 15:36:49 GMT</pubDate>
    </item>
    </channel>
</rss>