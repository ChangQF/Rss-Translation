<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 15:16:48 GMT</lastBuildDate>
    <item>
      <title>针对多模态目标的大型 MSE 模型</title>
      <link>https://stackoverflow.com/questions/78550210/huge-mse-model-for-multimodal-targets</link>
      <description><![CDATA[我有四个输入参数，我想预测 500 个值（表示频率函数中的电场值），所以我的数据集大约有 50000 个数据，y=50000*500……这里的目标是根据 E 的峰值推断出共振频率
我尝试使用一个简单的 CNN（带有两个卷积层）：
class CNN(nn.Module):
def init(self):
super(CNN, self).init()
self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)
self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
self.fc = nn.Linear(32 * 1, 500)

def forward(self, x):
x = F.relu(self.conv1(x))
x = F.max_pool1d(x, kernel_size=2, stride=2)
x = F.relu(self.conv2(x))
x = F.max_pool1d(x, kernel_size=2, stride=2)
x = x.view(-1, 32 * 1)
x = self.fc(x)
return x

但我获得的 MSE 很大：
Epoch [1/6], Train Loss: 26878214.0000, Val Loss: 27697948.0000 
Epoch [2/6], Train Loss: 24366062.0000, Val Loss: 27761616.0000
Epoch [3/6]，训练损失：28823276.0000，Val 损失：27700362.0000 
Epoch [4/6]，训练损失：20534644.0000，Val 损失：27853372.0000 
Epoch [5/6]，训练损失：26829138.0000，Val 损失：29004308.0000 
Epoch [6/6]，训练损失：21424500.0000，Val 损失：28001668.0000 
测试集上的均方误差 (MSE)：29475708.0`

我可以做些什么来更好地解决我的问题？模型有什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78550210/huge-mse-model-for-multimodal-targets</guid>
      <pubDate>Wed, 29 May 2024 14:25:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 CSE-CIC-IDS2018 数据集的机器学习创建网络入侵检测系统 (NIDS)？</title>
      <link>https://stackoverflow.com/questions/78549360/how-to-create-a-network-intrusion-detection-system-nids-using-machine-learning</link>
      <description><![CDATA[我目前正在开展一个名为 NetGuardian 的项目，这是一个利用机器学习来检测入侵的网络入侵检测系统 (NIDS)。我计划使用 CSE-CIC-IDS2018 数据集来训练我的模型。但是，我面临挑战，希望得到以下方面的指导：

数据预处理：


我应该如何预处理 CSE-CIC-IDS2018 数据集以实现最佳训练？
是否有推荐的特定技术或库来处理此数据集？


特征选择：


在这种情况下，特征选择的最佳实践是什么？
我应该使用提供的所有特征还是选择一个子集更好？如果是，我该如何确定哪些特征最重要？


模型选择：


哪些机器学习算法对 NIDS 最有效？
是否有特定模型在 CSE-CIC-IDS2018 数据集上表现特别好？


训练和评估：


我应该如何拆分数据集进行训练和测试以确保可靠的性能评估？
我应该使用哪些指标来评估我的 NIDS 的性能？


实施：


是否有任何教程或资源可以指导我使用机器学习构建 NIDS？
在构建过程中我应该避免哪些常见陷阱实施？

如果您能提供任何建议、资源或代码片段来帮助我开始构建 NetGuardian，我将不胜感激。
我熟悉 Python 和常用库，例如​​ Pandas、Scikit-Learn 和 TensorFlow/PyTorch。
我的目标是创建一个强大而高效的 NIDS，可以准确检测各种类型的网络入侵。
提前感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78549360/how-to-create-a-network-intrusion-detection-system-nids-using-machine-learning</guid>
      <pubDate>Wed, 29 May 2024 11:55:47 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的均匀分布数据</title>
      <link>https://stackoverflow.com/questions/78549325/uniformly-distibuted-data-for-machine-learning</link>
      <description><![CDATA[对于线性模型，我有均匀分布的变量，例如逻辑回归、线性 SVM、MLP 假设变量服从正态分布，变量服从多重共线，对吧？如果数据服从幂律、对数正态或偏态，我们可以应用 box-cox 变换将其转换为高斯分布，现在如果数据服从正态分布，我可以直接应用模型吗？当数据服从均匀分布时，它也能很好地工作吗？如果不是，如何将均匀分布转换为正态分布？
上面提到的相同问题]]></description>
      <guid>https://stackoverflow.com/questions/78549325/uniformly-distibuted-data-for-machine-learning</guid>
      <pubDate>Wed, 29 May 2024 11:49:49 GMT</pubDate>
    </item>
    <item>
      <title>在云中运行 ML 训练的经济有效方法有哪些？[关闭]</title>
      <link>https://stackoverflow.com/questions/78549284/what-are-cost-effective-ways-to-run-ml-training-in-the-cloud</link>
      <description><![CDATA[在研究机构工作时，在集群上训练机器学习模型通常是既定做法（例如通过提交 Slurm 作业）。但是，关于在商业云中训练 ML 模型的文献似乎并不多。在云上训练 ML 模型出于各种原因可能是可取的：靠近数据、快速扩展、无需配置自己的硬件等。
是否有任何已知的经济高效的云训练方法、任何技巧或最佳实践？
以下是我在 AWS 环境中确定的方法，但我对任何云提供商的方法都感兴趣：

使用 SageMaker

优点：托管、AWS 的一流支持、无服务器
缺点：笨拙、昂贵


使用 Lambda

优点：无服务器
缺点：冷启动


使用 EC2 实例

优点：接近您使用桌面的方式
缺点：如果使用率低并且您不启动/停止它，则成本高昂按需


使用 EC2 现货实例

优点：便宜
缺点：需要编写额外的代码来处理中断


]]></description>
      <guid>https://stackoverflow.com/questions/78549284/what-are-cost-effective-ways-to-run-ml-training-in-the-cloud</guid>
      <pubDate>Wed, 29 May 2024 11:40:39 GMT</pubDate>
    </item>
    <item>
      <title>Anylogic 和 ML 模型</title>
      <link>https://stackoverflow.com/questions/78549243/anylogic-and-ml-models</link>
      <description><![CDATA[我的目标是在我的 Anylogic 模型中包含一个随机森林模型，以预测我的代理变量的值。
我见过一个 Python 连接和 ML 模型使用示例，其中包含 pyCom 库，带有 AI 的简单医院，但我甚至无法运行它。
我已经导入了 pypeline 库。
但我遇到两个错误：
第一个在运行模型之前：

无法解析导入 com.google。位置：简单医院（AI 测试平台）/患者 - 代理类型

第二个在我运行它时：

无法运行 Python 代码；反馈：TypeError(&quot;&lt;class &#39;keras.src.initializers.random_initializers.GlorotUniform&#39;&gt; 无法正确反序列化。请确保 get_config() 返回的 Python 对象实例（层、模型等）的组件在模型的 from_config() 方法中明确反序列化。\n\nconfig={&#39;module&#39;: &#39;keras.initializers&#39;, &#39;class_name&#39;: &#39;GlorotUniform&#39;, &#39;config&#39;: {&#39;seed&#39;: None, &#39;dtype&#39;: &#39;float32&#39;}, &#39;registered_name&#39;: None}.\n\n遇到异常：GlorotUniform.init() 获得了意外的关键字参数 &#39;dtype&#39;&quot;)

我的电脑上有 python，包含所有库（numpy、pandas、tensorflow、 skit-learn...) 和 pyCommunicator 似乎可以工作，因为我测试了基本教程。问题可能是第二种情况下的 keras 版本？但哪个是正确的版本？
它们可能是很容易解决的问题，但我是自学编程的，我需要更详细的指导。]]></description>
      <guid>https://stackoverflow.com/questions/78549243/anylogic-and-ml-models</guid>
      <pubDate>Wed, 29 May 2024 11:33:27 GMT</pubDate>
    </item>
    <item>
      <title>Synthcity DECAF 生成人工智能中的形状误差</title>
      <link>https://stackoverflow.com/questions/78548544/synthcity-decaf-shape-error-in-generative-artificial-intelligence</link>
      <description><![CDATA[我正在尝试使用 DECAF 生成器生成新数据，但出现无法解决的错误。
我使用的代码与主 repo 文档中提到的代码完全相同（链接 Synthcity Docs）：
from sklearn.datasets import load_iris
from synthcity.plugins import Plugins

X, y = load_iris(as_frame = True, return_X_y = True)
X[&quot;target&quot;] = y

plugin = Plugins().get(&quot;decaf&quot;, n_iter = 100)
plugin.fit(X)

plugin.generate(50)

我不断得到
ValueError：传递值的形状为 (150, 1)，索引暗示 (150, 3)

无论我做什么。我有点惊讶错误竟然会发生，因为它实际上是作者的一个案例研究。
有人能解释或更重要的是解决这个错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78548544/synthcity-decaf-shape-error-in-generative-artificial-intelligence</guid>
      <pubDate>Wed, 29 May 2024 09:25:58 GMT</pubDate>
    </item>
    <item>
      <title>如何让 LangChain 代理可以访问 DataFrame？</title>
      <link>https://stackoverflow.com/questions/78547953/how-to-make-dataframe-accessible-to-langchain-agent</link>
      <description><![CDATA[我目前正在开发一个 LangChain 代理，需要一些帮助，使 DataFrame (df) 可供代理访问。下面是我想实现的目标的简要概述：
代理可以访问多个功能工具。
这些工具需要 DataFrame (df) 作为参数。
代理的任务是调用这些工具，传递存储在 df 变量中的数据。
有没有办法确保代理可以访问 df 变量，以便它可以成功地将数据传递给功能工具？有什么指导或例子吗？
我尝试在提示模板中传递数据，但需要 30 多秒。在此部分中，代理重新格式化数据，然后才传递。但我希望代理传递变量。
我还尝试创建一个工具函数，该函数使用查询从数据库中提取数据并将其存储在变量中。但是 llm 使用的代理仍然会转换为 json 格式然后传递它。
我希望 llm 接受变量并在不进行任何格式化的情况下传递它（以节省时间）。]]></description>
      <guid>https://stackoverflow.com/questions/78547953/how-to-make-dataframe-accessible-to-langchain-agent</guid>
      <pubDate>Wed, 29 May 2024 07:28:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SHAP 值来表示 EEG 生物标志物和特征重要性？</title>
      <link>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-eeg-biomarker-and-feature-importance</link>
      <description><![CDATA[我做什么：
我借助不同的机器学习算法和不同的预处理步骤等分析来自 EEG 数据的不同生物标志物。这为每种预处理步骤和算法的组合产生了多个模型。
每个模型都使用 StratifiedGroupKFold 进行训练，总共 6 个折叠。
每个折叠都保存为作业库，即 .joblib
生物标志物：
EEG 信号的每个波段都有许多生物标志物。这些生物标志物又由来自 EEG 所有电极的所有信号组成。因此，生物标志物由多个特征组成，这些特征不能分开（每个生物标志物必须包含所有电极数据）。
我想做什么：
在我的第一种方法中，我用所有生物标志物训练了每个模型。现在我想使用特征重要性来确定是否可以省略其中一些。
为此，我想研究每个预处理步骤和每个模型。
有人向我推荐 SHAP，但我的问题是我不知道如何总结每个生物标志物的折叠和通道。
这是我第一次尝试至少总结折叠（例如，我仅使用一个模型中的所有折叠）：
for i, (train_index, test_index) in enumerate(sgkf.split(X, y, groups)):
X_test, y_test = X.iloc[test_index], y.iloc[test_index]

# Modell
fold_file = fold_files[i]
clf = joblib.load(fold_file)

# SHAP-Explainer
explainer = shap.LinearExplainer(clf, X_test)
shap_values = explainer.shap_values(X_test)
sv = explainer(X_test)

all_shap_values.append(shap_values)

shap_values_stacked = np.vstack([sv[1] for sv in all_shap_values])
shap_values_mean = np.abs(shap_values_stacked).mean(0) 
importance_df = pd.DataFrame({
&quot;feature&quot;: columns,
&quot;shap_values&quot;: shap_values_mean
})

我首先通过 explainer.shap_values 尝试，因为这似乎是最简单的方法。但是我无法绘制它，我需要 sv = expaliner(X)。
我的问题分为两部分：

我如何总结折叠？（平均值？）
我如何对每个生物标志物的通道进行分组？我可以添加这些值吗？或者我会扭曲结果吗？

（生物标志物的命名方式使我可以轻松识别通道）
提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-eeg-biomarker-and-feature-importance</guid>
      <pubDate>Wed, 29 May 2024 06:28:02 GMT</pubDate>
    </item>
    <item>
      <title>YoloV8 结果中没有 'box'、'max' 属性</title>
      <link>https://stackoverflow.com/questions/78547320/yolov8-results-have-no-box-max-properties-in-it</link>
      <description><![CDATA[我已经训练了一个 YOLOV8 模型来识别十字路口的物体（即汽车、道路等）。
它工作正常，我可以将输出作为带有感兴趣分割对象的图像。
但是，我需要做的是捕获原始几何图形（多边形），以便稍后将它们保存在 txt 文件中。
我尝试了在文档中找到的内容（https://docs.ultralytics.com/modes/predict/#key-features-of-predict-mode）但返回的对象与文档所述不同。
实际上，结果是 TensorFlow 数字列表：

这是我的代码：
import argparse
import cv2
import numpy as np
from pathlib import Path
from ultralytics.yolo.engine.model import YOLO 

# 解析命令行参数
parser = argparse.ArgumentParser()
parser.add_argument(&#39;--source&#39;, type=str, required=True, help=&#39;源图像目录或文件&#39;)
parser.add_argument(&#39;--output&#39;, type=str, default=&#39;output&#39;, help=&#39;输出目录&#39;)
args = parser.parse_args()

# 如果不存在则创建输出目录
Path(args.output).mkdir(parents=True, exist_ok=True)

# 模型路径
model_path = r&#39;C:\\_Projects\\best_100img.pt&#39;

# 直接加载模型
model = YOLO(model_path)
model.fuse()

# 加载图像
if Path(args.source).is_dir():
image_paths = list(Path(args.source).rglob(&#39;*.tiff&#39;))
else:
image_paths = [args.source]

# 处理每幅图像
for image_path in image_paths:
img = cv2.imread(str(image_path))
if img is None:
continue

# 执行推理
predictions = model.predict(image_path, save=True, save_txt=True)

print(&quot;处理完成。&quot;)

问题在于：返回对象（预测变量）没有框、掩码、关键点和等等。
我想我的问题是：

为什么结果与文档如此不同？
是否有转换步骤？
]]></description>
      <guid>https://stackoverflow.com/questions/78547320/yolov8-results-have-no-box-max-properties-in-it</guid>
      <pubDate>Wed, 29 May 2024 04:32:01 GMT</pubDate>
    </item>
    <item>
      <title>机器学习项目：PCB 的光学检测 [关闭]</title>
      <link>https://stackoverflow.com/questions/78547175/machine-learning-project-optical-inspection-of-pcbs</link>
      <description><![CDATA[我有一个项目要创建一个机器学习模型，其中有一个印刷电路板 (PCB) 被分成 16 个部分的图像，我们以正确的印刷电路板组件为基础，然后在相机的帮助下放大印刷电路板 (PCB) 组件以检查它是否与正确的印刷电路板 (PCB) 组件匹配。
我完全不知道该如何处理这个问题，因为我对图像处理的机器学习知识很少，所以请有人帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78547175/machine-learning-project-optical-inspection-of-pcbs</guid>
      <pubDate>Wed, 29 May 2024 03:18:48 GMT</pubDate>
    </item>
    <item>
      <title>当使用大规模数据进行训练时，数据是如何处理？[关闭]</title>
      <link>https://stackoverflow.com/questions/78547001/when-training-with-large-scale-data-how-is-the-data-processed</link>
      <description><![CDATA[我面临着使用大规模数据进行训练的挑战，具体来说是大约 19 TB 的视频数据。创建模型并不困难，但我不知道在哪里存储如此大量的数据以及如何使用它。由于我们没有高性能计算机，似乎我们可能需要租用一些。我很好奇处理大规模数据的 AI 开发人员通常如何处理这种情况。
此外，我发现可以使用 AWS，但我想知道这种方法是否真的被采用，或者是否有更好的替代方案。]]></description>
      <guid>https://stackoverflow.com/questions/78547001/when-training-with-large-scale-data-how-is-the-data-processed</guid>
      <pubDate>Wed, 29 May 2024 01:50:16 GMT</pubDate>
    </item>
    <item>
      <title>我得到了 ValueError: np.nan 是一个无效文档，预期是字节或 unicode 字符串</title>
      <link>https://stackoverflow.com/questions/78545256/i-got-valueerror-np-nan-is-an-invalid-document-expected-byte-or-unicode-string</link>
      <description><![CDATA[import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 读取第一个包含业务代码和说明的 Excel 文件
df1 = pd.read_excel(&quot;E:/file1.xlsx&quot;)

# 读取第二个包含业务许可证的 Excel 文件
df2 = pd.read_excel(&quot;E:/file2.xlsx&quot;)

# 初始化 TF-IDF 向量化器
tfidf_vectorizer = TfidfVectorizer()

# 将业务说明和许可证合并为一个列表
combined_text = list(df1[&#39;Business descriptions&#39;]) + list(df2[&#39;Business licences&#39;])

# 在合并的文本上拟合并转换 TF-IDF 向量化器
tfidf_matrix = tfidf_vectorizer.fit_transform(combined_text)

# 计算 TF-IDF 向量之间的余弦相似度
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# 获取余弦相似度矩阵中业务描述和许可证的索引
desc_indices = range(len(df1))
lic_indices = range(len(df1), len(df1) + len(df2))

# 创建一个字典来存储业务描述和许可证之间的映射
mapping_dict = {}

# 遍历业务描述并根据余弦相似度找到最佳匹配的许可证
for desc_idx in desc_indices:
best_match_idx = max(lic_indices, key=lambda x: cosine_sim[desc_idx][x])
映射字典[df1.loc[desc_idx, &#39;Business codes&#39;]] = df2.loc[best_match_idx - len(df1), &#39;Business licences&#39;]

# 从映射字典创建新的数据框
mapped_df = pd.DataFrame(list(mapping_dict.items()), columns=[&#39;Business codes&#39;, &#39;Mapped Business licences&#39;])

# 将映射数据保存到新的 Excel 文件
mapped_df.to_excel(&#39;mapped_data.xlsx&#39;, index=False)


嗨，我有 2 个 excel 文件。其中一个有两列，分别是业务代码和业务描述。Excel 文件 2 有一列，即业务许可证。我想对业务描述和业务许可证之间的常用词进行语义文本映射。这是我从 chatgpt 获得的代码，我收到错误：ValueError：np.nan 是无效文档，预期为字节或 unicode 字符串。
感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78545256/i-got-valueerror-np-nan-is-an-invalid-document-expected-byte-or-unicode-string</guid>
      <pubDate>Tue, 28 May 2024 15:57:51 GMT</pubDate>
    </item>
    <item>
      <title>GPU 上的 Pytorch 比 CPU 上的 numpy 慢很多？</title>
      <link>https://stackoverflow.com/questions/78537571/pytorch-in-gpu-is-much-slower-than-numpy-on-cpu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78537571/pytorch-in-gpu-is-much-slower-than-numpy-on-cpu</guid>
      <pubDate>Mon, 27 May 2024 06:56:13 GMT</pubDate>
    </item>
    <item>
      <title>哪种方法适合基于人脸检测的考勤系统，需要在没有 GPU 系统的低硬件设备上运行 [关闭]</title>
      <link>https://stackoverflow.com/questions/78515586/which-is-the-suitable-approach-for-face-detection-based-attendance-system-which</link>
      <description><![CDATA[需要在 Raspberry pi 中快速准确地运行人脸检测代码。没有 GPU，输出会非常慢，我无法使用 GPU，因此如果有人可以帮助或指导我，我将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78515586/which-is-the-suitable-approach-for-face-detection-based-attendance-system-which</guid>
      <pubDate>Wed, 22 May 2024 06:09:35 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv8：如何在测试集上计算映射</title>
      <link>https://stackoverflow.com/questions/78073911/yolov8-how-to-calculate-map-on-test-set</link>
      <description><![CDATA[假设我有一个名为“test”的文件夹，里面有“images”和“labels”文件夹。我还有一个经过训练的 YOLOv8 模型，名为“best.pt”。我的标签是多边形（yolo-obb .txt 文件）。
我想找到我的 YOLOv8 模型在此测试集上的平均精度 (MAP)。
我已经阅读了预测和基准测试的文档，但是，我很难找到从一些测试图像计算地图的示例。
https://docs.ultralytics.com/modes/predict/
https://docs.ultralytics.com/modes/benchmark/
from ultralytics import YOLO

# 加载预训练YOLOv8n 模型
model = YOLO(&#39;best.pt&#39;)

# 对图像运行推理
results = model([&#39;test/images/bus.jpg&#39;, &#39;test/images/zidane.jpg&#39;]) # 2 个 Results 对象的列表

我想我必须将图像列表放在上面，然后编写代码来计算测试文件夹中所有内容的映射并取平均值。有没有已经完成此操作的软件包？
实现此任务的代码是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78073911/yolov8-how-to-calculate-map-on-test-set</guid>
      <pubDate>Wed, 28 Feb 2024 11:05:52 GMT</pubDate>
    </item>
    </channel>
</rss>