<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 10 Dec 2023 15:13:07 GMT</lastBuildDate>
    <item>
      <title>Azure 机器学习笔记本部署问题</title>
      <link>https://stackoverflow.com/questions/77635239/azure-machine-learning-notebook-deployment-problem</link>
      <description><![CDATA[“大家好，
我正在尝试从 Azer 机器学习笔记本运行我的项目，但终端不断告诉我：目录中没有这样的文件。我不知道还应该在哪里上传脚本和相关文件才能使其正常工作，或者代码中哪里有错误。有人可以建议如何解决这个问题吗？非常感谢！
我尝试上传笔记本、容器中我的个人目录中的文件并创建共享文件。]]></description>
      <guid>https://stackoverflow.com/questions/77635239/azure-machine-learning-notebook-deployment-problem</guid>
      <pubDate>Sun, 10 Dec 2023 14:55:06 GMT</pubDate>
    </item>
    <item>
      <title>客户购买倾向模型，我该怎么做？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77635210/customer-propensity-to-purchase-model-how-do-i-go-about-it</link>
      <description><![CDATA[所以我有这个数据集，其中包括时间戳、购买的产品类别以及有关用户在电子商务平台上的行为的其他信息，例如：他们购买的频率、来自哪个类别、imp 评论如何、添加到购物车、购物车放弃，保存以供稍后使用，等等以及所有详细信息。
现在我想训练一个模型，然后为客户进行这个虚拟电子商务模拟，他们执行的某些操作将被添加到实时数据库中（客户可能存在多个会话，其中日期也是分析），模型可以对其进行处理，然后仪表板可以显示他们在接下来的几周/几个月内购买特定产品类别的可能性。
我已经使用过ml和dl，但我对它还很陌生，所以如果这是愚蠢的事情，我提前道歉，但我很困惑，就像我错过了一些关于如何创建它并制作它的细节它有效。
有什么建议吗？请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/77635210/customer-propensity-to-purchase-model-how-do-i-go-about-it</guid>
      <pubDate>Sun, 10 Dec 2023 14:44:02 GMT</pubDate>
    </item>
    <item>
      <title>调整图像分割模型（来自 TF 教程）以进行二元掩蔽</title>
      <link>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</link>
      <description><![CDATA[我需要 Tensorflow 的图像分割模型。输入为图像和掩码（二进制、掩码或非掩码），输出为带有 0 和 1 的图像掩码。
我遵循了 https://www.tensorflow.org/tutorials/ 中的图像分割教程图像/分割
但现在我想在我的数据集上运行它的二进制掩码（没有边框类）
新数据集已准备好并输入到 model.fit 中。应该没问题吧。
如何将此模型更改为只有 2 个类（非屏蔽和屏蔽）？
base_model: keras.Model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)

# 使用这些层的激活
图层名称 = [
    &#39;block_1_expand_relu&#39;, # 64x64
    &#39;block_3_expand_relu&#39;, # 32x32
    &#39;block_6_expand_relu&#39;, # 16x16
    &#39;block_13_expand_relu&#39;, # 8x8
    &#39;block_16_project&#39;, # 4x4
]
base_model_outputs = [base_model.get_layer(name).layer_names 中名称的输出]

# 创建特征提取模型
down_stack = 模型（输入=base_model.输入，输出=base_model_outputs）

down_stack.trainable = False

上层堆栈 = [
    pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8
    pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16
    pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32
    pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64
]

def unet_model(output_channels:int):
  输入 = 层.Input(形状=[128, 128, 3])

  # 通过模型进行下采样
  跳过= down_stack（输入）
  x = 跳过[-1]
  跳过 = 反转(跳过[:-1])

  # 上采样并建立跳跃连接
  对于 up，在 zip 中跳过（up_stack，skips）：
    x = 上(x)
    concat = 层.Concatenate()
    x = concat([x, 跳过])

  # 这是模型的最后一层
  最后=层.Conv2DTranspose(
      过滤器=output_channels，kernel_size=3，步幅=2，
      padding=&#39;相同&#39;) #64x64 -&gt; 128x128

  x = 最后一个(x)

  返回模型（输入=输入，输出=x​​）

输出类 = 3

模型 = unet_model(output_channels=OUTPUT_CLASSES)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

当我将 OUTPUT_CLASSES 更改为 2 时，出现错误：
W tensorflow/core/kernels/data/generator_dataset_op.cc:108] 完成 GeneratorDataset 迭代器时发生错误：FAILED_PRECONDITION：Python 解释器状态未初始化。该过程可以被终止。

当OUTPUT_CLASSES为1时，预测掩码为空。
也许还必须改变其他东西？我还不熟悉神经网络架构，所以我可能看不到明显的东西。]]></description>
      <guid>https://stackoverflow.com/questions/77635064/adjust-image-segmentaion-model-from-tf-tutorial-for-binary-masking</guid>
      <pubDate>Sun, 10 Dec 2023 13:55:04 GMT</pubDate>
    </item>
    <item>
      <title>可转移的定向 FGSM 攻击尝试产生非常差的准确度性能</title>
      <link>https://stackoverflow.com/questions/77634593/transferable-targeted-fgsm-attack-attempt-yielding-very-poor-accuracy-performanc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77634593/transferable-targeted-fgsm-attack-attempt-yielding-very-poor-accuracy-performanc</guid>
      <pubDate>Sun, 10 Dec 2023 11:25:53 GMT</pubDate>
    </item>
    <item>
      <title>想要使用监督或无监督构建建议模型吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</link>
      <description><![CDATA[假设我们从一个巨大的区域开始，想要建立一个模型来建议是否建议在 latlon 的每个点放置多少新信号发射器。
第一步：在边界区域（100m 网格）内创建所有可能的 latlon
第二步：创建所有相关功能，例如
-最近的现有发射器距离
- 该点的当前信号电平（在此示例 latlon 中）
- 使用最接近该点的现有发射器的使用量（在此示例 latlon 中）
-当前点使用信号的用户数量
问题

如果我选择 NNet 模型，我需要提出评分函数来计算每个特征向量的合适分数。因为它是有监督模型，所以需要用该模型进行训练，如何找到合适的评分函数？当我找到分数函数时，我是否需要考虑特定特征的异常值？

如果我可以拥有标记数据，那么 ML 模型的好处是什么，因为我可以使用此评分函数与自动化的传统软件来生成点列表的排名。

如果我使用无监督方法，它只会根据特征对相似的特征点进行分组，但是如何对这个点进行排序，不知何故，我需要教育模型每个特征，较高的值意味着好，或者更高的值意味着不好，对吗？

有什么建议或更好的型号选择吗？


我试图概述脚趾步骤，但我有疑问，因为该方法听起来并不优于传统的自动化软件。]]></description>
      <guid>https://stackoverflow.com/questions/77634013/idea-to-build-suggestion-model-using-supervised-or-unsupervised</guid>
      <pubDate>Sun, 10 Dec 2023 07:29:16 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试从 Transformer 导入 Trainer 时，DLL 失败</title>
      <link>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</link>
      <description><![CDATA[我想在本地计算机上微调基于 Transformer 的模型，因此当我尝试导入训练器时
从 Transformers 导入 Trainer

出现此错误
导入错误：导入 lib 时 DLL 加载失败：找不到指定的过程。
运行时错误：由于以下错误，无法导入transformers.trainer（查找其回溯）：
导入 lib 时 DLL 加载失败：找不到指定的过程。
如何解决此错误？
环境
蟒蛇
库达12.3
Python 3.9.18
火炬2.1.0+cu118
火炬音频2.1.0+cu118
火炬视觉 0.16.0+cu118
变形金刚 4.35.2

我尝试升级CUDA，升级和降级transformers库，torch及其子库，但没有帮助]]></description>
      <guid>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</guid>
      <pubDate>Sun, 10 Dec 2023 05:33:49 GMT</pubDate>
    </item>
    <item>
      <title>Visual Studio 在 yolo7v 上训练时找不到 cuda 错误</title>
      <link>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</link>
      <description><![CDATA[当我尝试在 yolo v7 上训练时，出现此错误：
文件“train.py”，第 595 行，在  中
    设备= select_device(opt.device,batch_size=opt.batch_size)
  文件“C:\Users\96Crori\Desktop\yolov7_custom_training\yolov7\utils\torch_utils.py”，第 71 行，位于 select_device
    断言 torch.cuda.is_available(), f&#39;CUDA 不可用，请求的设备 {device} 无效&#39; # 检查可用性
AssertionError：CUDA 不可用，请求的设备 0 无效

我安装了cuda版本11.3，但我不知道为什么Visual Studios找不到它]]></description>
      <guid>https://stackoverflow.com/questions/77633532/visual-studios-can-not-find-cuda-error-while-training-on-yolo7v</guid>
      <pubDate>Sun, 10 Dec 2023 02:39:08 GMT</pubDate>
    </item>
    <item>
      <title>一个简单的玩具机器学习问题，令人惊讶的是它无法学到任何东西</title>
      <link>https://stackoverflow.com/questions/77633472/a-simple-toy-ml-problem-that-surprisingly-fails-to-learn-anything</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77633472/a-simple-toy-ml-problem-that-surprisingly-fails-to-learn-anything</guid>
      <pubDate>Sun, 10 Dec 2023 02:00:35 GMT</pubDate>
    </item>
    <item>
      <title>我需要制作一个机器学习模型，根据公司电子邮件使用数据评估员工流失率 [关闭]</title>
      <link>https://stackoverflow.com/questions/77632626/i-need-to-make-an-ml-model-that-evaluates-employee-attrition-rate-based-on-his-c</link>
      <description><![CDATA[此模型输入是每个员工的电子邮件使用情况的元数据，例如发出的电子邮件数量、收到的电子邮件数量等以及每封电子邮件的内容。输出是每个员工的自然流失率。该评估基于比较不同时期之间的电子邮件使用数据。
主要问题是没有附加数据集来解决这个问题。您建议采用什么方法来生成数据集？我应该为此模型选择哪种算法？]]></description>
      <guid>https://stackoverflow.com/questions/77632626/i-need-to-make-an-ml-model-that-evaluates-employee-attrition-rate-based-on-his-c</guid>
      <pubDate>Sat, 09 Dec 2023 19:38:25 GMT</pubDate>
    </item>
    <item>
      <title>在张量流中的卷中执行串联时出现问题</title>
      <link>https://stackoverflow.com/questions/77632484/issue-performing-concatenation-in-a-volume-in-tensorflow</link>
      <description><![CDATA[我正在构建一个肿瘤分割深度学习模型，即将使用3D Unet，但我提出了这个问题，这是我的代码：
# 卷积块
def conv_block(输入, num_filters):
    x = Conv3D(num_filters, (3, 3, 3), padding = “相同”)(输入)
    x = BatchNormalization()(x)
    x = 激活(“relu”)(x)

    x = Conv3D(num_filters, (3, 3, 3), 填充 = “相同”)(x)
    x = BatchNormalization()(x)
    x = 激活(“relu”)(x)

    返回x

# 编码器块
def编码器_块（输入，num_filters）：
    x = conv_block(输入, num_filters)
    p = MaxPool3D((2, 2, 2))(x)
    返回 x, p

# 解码器块
def解码器_块（输入，跳过，num_filters）：
    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=“相同”)(输入)
    x = 连接()([x, 跳过])
    x = conv_block(x, num_filters)
    返回x

# 大学网络

def unet(输入形状):
    输入 = 输入（输入形状）

    “----编码器----”
    s1, p1 = 编码器_块(输入, 64)
    s2, p2 = 编码器_块(p1, 128)
    s3, p3 = 编码器_块(p2, 256)
    s4, p4 = 编码器_块(p3, 512)

    “----桥---”
    b1 = conv_block(p4, 1024)

    “----解码器----”
    d1 = 解码器_块(b1, s4, 512)
    d2 = 解码器_块(d1, s3, 256)
    d3 = 解码器块(d2, s2, 128)
    d4 = 解码器块(d3, s1, 64)

    输出 = Conv3D(1, 1, 填充 =“相同”, 激活 =“sigmoid”)(d4)

    模型=模型（输入，输出，名称=“UNET”）
    返回模型

输入形状 = (155, 255, 255, 3)

测试模型=unet(输入形状)

问题是这样的：
&lt;前&gt;&lt;代码&gt;在&lt;细胞系：3&gt;()
      1 输入形状 = (155, 255, 255, 3)
      2
----&gt; 3 测试模型=unet(输入形状)

3帧
&lt;ipython-input-14-03345eb7b1a8&gt;在unet（输入形状）中
     14
     15、“----解码器----”
---&gt; 16 d1 = 解码器_块(b1, s4, 512)
     17 d2 = 解码器_块（d1，s3，256）
     18 d3 = 解码器_块(d2, s2, 128)

&lt;ipython-input-12-44442d65f832&gt;在解码器块（输入，跳过，num_filters）
      2 def解码器_块（输入，跳过，num_filters）：
      3 x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=“相同”)(输入)
----&gt; 4 x = 连接()([x, 跳过])
      5 x = conv_block(x, num_filters)
      6 返回 x

error_handler 中的 /usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py(*args, **kwargs)
     68 # 要获取完整的堆栈跟踪，请调用：
     69 # `tf.debugging.disable_traceback_filtering()`
---&gt; 70 从 None 引发 e.with_traceback(filtered_tb)
     71 最后：
     72 删除filtered_tb

/usr/local/lib/python3.10/dist-packages/keras/src/layers/merging/concatenate.py 在 build(self, input_shape)
    129）
    [130] 第 130 章1：
--&gt; 131 引发值错误（err_msg）
    132
    133 def _merge_function（自我，输入）：

ValueError：“连接”层需要具有匹配形状（连接轴除外）的输入。收到：input_shape=[(无、18、30、30、512)、(无、19、31、31、512)]

我不知道为什么输出层对一个体素求和，这会产生错误，我不想消除该体素，因为它可能是有价值的信息]]></description>
      <guid>https://stackoverflow.com/questions/77632484/issue-performing-concatenation-in-a-volume-in-tensorflow</guid>
      <pubDate>Sat, 09 Dec 2023 18:48:43 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 的自定义优化器</title>
      <link>https://stackoverflow.com/questions/77632195/custom-optimizer-for-tensorflow</link>
      <description><![CDATA[我正在尝试在 TensorFlow 上试验神经网络的自定义优化算法，但由于缺乏有关该主题的信息而陷入困境。我需要的是一些代码，这些代码将在每次迭代时为我提供向量 x （当前点）和向量 g （x 处的梯度），然后我将更新 x，然后使用一些代码来设置更新后的值。这是我目前所拥有的：
来自tensorflow.python.framework导入操作
从tensorflow.python.ops导入gen_training_ops
从tensorflow.python.ops导入math_ops
从tensorflow.python.training导入优化器
从tensorflow.python.util.tf_export导入tf_export
将张量流导入为 tf
将 numpy 导入为 np

类 TestGD(优化器.优化器):
  def __init__(自身, rad=0.01,
               use_locking=False, name=“TestGD”）：
    super(TestGD, self).__init__(use_locking, 名称)
    self._radius = rad

  def _create_slots(self, var_list):
    num_dims = len(var_list)
    self._beta = (num_dims - 1) / (num_dims + 1)
    self._B_matrix = np.identity(num_dims)

  def _prepare（自我）：
    self._radn_t = ops.convert_to_tensor(self._call_if_callable(self._radius), name=“beta”)
    self._beta_t = ops.convert_to_tensor(self._call_if_callable(self._beta), name=“beta”)
    self._B_matrix_t = ops.convert_to_tensor(self._call_if_callable(self._B_matrix), name=“B”)

  def _apply_dense（自身，梯度，变量）：
    返回 self._resource_apply_dense(grad, var)

  def _resource_apply_dense（自身，梯度，变量）：
    print(grad.shape, &quot;&lt;------------&quot;)
    #我计划在这里的某个地方实现我的算法
    var_update = tf.compat.v1.assign_sub(var, 0.01 * grad)
    返回 tf.group(var_update)

  def _apply_sparse(自我, grad, var):
    raise NotImplementedError(“不支持稀疏梯度更新。”)


# 构建LeNet模型
模型 = tf.keras.Sequential([
    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), 激活=&#39;relu&#39;, input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), 激活=&#39;relu&#39;),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(120, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(84, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(10, 激活=&#39;softmax&#39;)
]）

# 使用您的自定义优化器
#custom_optimizer = SimpleGD(learning_rate=0.001)
自定义优化器 = TestGD()

# 使用自定义优化器编译模型
model.compile(优化器=custom_optimizer,
              损失=&#39;sparse_categorical_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

# 获取数据集
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0 # 将像素值标准化为 0 到 1 之间

x_train = x_train[..., tf.newaxis].astype(“float32”)
x_test = x_test[..., tf.newaxis].astype(“float32”)

train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=60000).batch(64)

test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))
测试数据集 = 测试数据集.batch(64)

＃ 训练
model.fit(train_dataset, epochs=5)

＃ 评估
test_loss, test_acc = model.evaluate(test_dataset)
print(f&quot;测试准确度：{test_acc}&quot;)

问题是，我得到的 grad 和 var 的形状非常奇怪，它们绝对不是向量。我应该怎么做才能将问题减少到 x 和 g 向量以及如何在最小化步骤后正确更新结果？]]></description>
      <guid>https://stackoverflow.com/questions/77632195/custom-optimizer-for-tensorflow</guid>
      <pubDate>Sat, 09 Dec 2023 17:23:42 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML 模型给出的准确度、F1 分数、精确度和召回率均为 1.0，但似乎过度拟合 [关闭]</title>
      <link>https://stackoverflow.com/questions/77595988/my-ml-model-gives-accuracy-f1-score-precision-and-recall-as-1-0-but-it-seems-o</link>
      <description><![CDATA[
我有 Spotify 音乐数据集。
playlist_genre 是目标变量，它有 6 个类别 - 摇滚、拉丁、R&amp;B、说唱、流行、器乐
如果我使用标签编码对目标变量进行编码，那么我得到的准确度和 F1 分数为 1.0
如果我使用 getDummies 或 one-hot 编码，那么我的准确度和 f1 分数将分别降至 0.29 和 0.19。

使用的分类算法：随机森林
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/77595988/my-ml-model-gives-accuracy-f1-score-precision-and-recall-as-1-0-but-it-seems-o</guid>
      <pubDate>Sun, 03 Dec 2023 20:05:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 max_new_tokens 的 LLM 输出不完整</title>
      <link>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</link>
      <description><![CDATA[我正在尝试 Huggingface LLM 模型。
我注意到的一个问题是模型的输出突然结束，我理想地希望它完成其之间的段落/句子/代码。 （或者完全尝试在一些固定数量的标记内完成答案）
虽然我已经提供了 max_new_tokens = 300 并且在提示中我写道：
“输出最多应为 300 个字。”
响应总是不完整并且突然结束。我可以通过什么方式要求在所需数量的输出令牌内获得完整的输出？
代码：
检查点=“HuggingFaceH4/starchat-alpha”
设备=“cuda”； if torch.cuda.is_available() else “cpu”
StarCoderModel 类：
  def __init__(自身):
    self.tokenizer = AutoTokenizer.from_pretrained(检查点)
    # 如果需要 GPU，请确保 docker run 命令中提供了 `--gpus all`
    self.model = AutoModelForCausalLM.from_pretrained(检查点, device_map=&#39;auto&#39;)

  def infer(self, input_text, token_count):
    输入 = self.tokenizer.encode(input_text, return_tensors=“pt”).to(device)
    输出 = self.model.generate(输入, max_new_tokens=token_count, pad_token_id=self.tokenizer.eos_token_id)
    返回 self.tokenizer.decode(outputs[0])[len(input_text):]

样本输出：
私有数据类型FuntionName(String someId) {
    // TODO：替换为利用 someId 获取信息的实现
    返回数据类型.Value；
}


评论：

- 如果代码中存在 someId，则使用 Client 的 getAPI 以 someId 作为参数来获取一些信息。
- 如果

]]></description>
      <guid>https://stackoverflow.com/questions/77061898/incomplete-output-with-llm-with-max-new-tokens</guid>
      <pubDate>Thu, 07 Sep 2023 18:02:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用ML模型和FastAPI处理多个用户的请求？</title>
      <link>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</link>
      <description><![CDATA[我正在研究通过FastAPI分发人工智能模块的过程。
我创建了一个 FastAPI 应用，它使用预先学习的机器学习模型来回答问题。
这种情况下，一个用户使用没有问题，但多个用户同时使用时，响应可能会太慢。
那么，当多个用户输入问题时，有没有办法一次性复制模型并加载进去呢？
类句子bert_ai()：
    def __init__(self) -&gt;; __init__(self) -&gt;没有任何：
        超级().__init__()

 def Ask_query(自我,查询,topN):
        开始 = 时间.time()

        询问结果 = []
        分数 = []
        结果值 = []
        嵌入器 = torch.load(model_path)
        corpus_embeddings = embedder.encode（语料库，convert_to_tensor=True）
        query_embedding = embedder.encode（查询，convert_to_tensor=True）
        cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0] #torch.Size([121])121개의 말뭉치에 대한 코사인 유사도 값ה다.
        cos_scores = cos_scores.cpu()

        top_results = np.argpartition(-cos_scores, range(topN))[0:topN]

        对于 top_results[0:topN] 中的 idx：
            Ask_result.append(corpusid[idx].item())
            #.item()으로 접근하는 유는 张量(5)에서 해당 숫자에 접근하기 위한 방식다.
            分数.append(round(cos_scores[idx].item(),3))

        #서버에 json array 형태로 내보내기 위한 작업
        对于 zip 中的 i,e(ask_result,score)：
            result_value.append({“pred_id”:i,“pred_weight”:e})
        结束 = 时间.time()
        print(&#39;시간체크&#39;,endd-startt)
        返回结果值
        # return &#39;,&#39;.join(str(e) for e in Ask_result),&#39;,&#39;.join(str(e) for e in Score)



类 Item_inference(BaseModel):
    文本：str
    topN : 可选[int] = 1

@app.post(&quot;/retrieval&quot;,tags=[&quot;知识推荐&quot;])
异步 def Knowledge_recommendation(item: Item_inference):
  
    # db.append(item.dict())
    item.dict()
    结果 = _ai.ask_query(item.text, item.topN)

    返回结果


如果 __name__ == “__main__”：
    解析器 = argparse.ArgumentParser()
    parser.add_argument(&quot;--port&quot;, default=&#39;9003&#39;, type=int)
    # parser.add_argument(&quot;--mode&quot;, default=&#39;cpu&#39;, type=str, help=&#39;cpu 表示 CPU 模式，gpu 表示 GPU 模式&#39;)
    args = parser.parse_args()

    _ai = 句子bert_ai()
    uvicorn.run（应用程序，主机=“0.0.0.0”，端口=args.port，workers=4）

修正版本
@app.post(&quot;/aaa&quot;) def your_endpoint(request: Request, item:Item_inference): start = time.time() model = request. app.state.model item.dict() #커널 실행시 필요 _ai = Sentencebert_ai() results = _ai.ask_query(item.text, item.topN,model) end = time.time() print(end-start) return结果```
]]></description>
      <guid>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</guid>
      <pubDate>Fri, 25 Mar 2022 07:13:32 GMT</pubDate>
    </item>
    <item>
      <title>UnboundLocalError：赋值前引用的局部变量“batch_outputs”</title>
      <link>https://stackoverflow.com/questions/63364588/unboundlocalerror-local-variable-batch-outputs-referenced-before-assignment</link>
      <description><![CDATA[我正在使用 Keras 编写机器学习代码来对前列腺癌的严重程度进行分级。运行后出现如下错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
UnboundLocalError Traceback（最近一次调用最后一次）
&lt;ipython-input-14-0e08590512ec&gt;在&lt;模块&gt;中
      8 表示列中的文件：
      9 数据=generate_tiles(文件)
---&gt; 10 预测 = model.predict(数据)
     11 max_score = 预测.max()
     12

_method_wrapper 中的 /opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py(self, *args, **kwargs)
     86 raise ValueError(&#39;多工作模式下不支持{}。&#39;.format(
     87 方法.__名称__))
---&gt; 88 返回方法（self，*args，**kwargs）
     89
     90返回tf_decorator.make_decorator（

/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py 中的预测（自我，x，batch_size，详细，步骤，回调，max_queue_size，工人，use_multiprocessing）
   第1283章
   第1284章
-&gt;第1285章
   第1286章
   第1287章

UnboundLocalError：赋值前引用的局部变量“batch_outputs”

有谁知道批量输出也会引用什么？我的代码中没有这样的变量。]]></description>
      <guid>https://stackoverflow.com/questions/63364588/unboundlocalerror-local-variable-batch-outputs-referenced-before-assignment</guid>
      <pubDate>Tue, 11 Aug 2020 18:50:56 GMT</pubDate>
    </item>
    </channel>
</rss>