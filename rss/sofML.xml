<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 15 Mar 2024 15:13:46 GMT</lastBuildDate>
    <item>
      <title>连续数据的过采样</title>
      <link>https://stackoverflow.com/questions/78167792/oversampling-for-continuos-data</link>
      <description><![CDATA[有一些工具可以为我的数据帧构建合成数据吗？我没有足够的小类示例，我无法使用 SMOTE 或类似的东西，因为它们只接受离散数据
我不想让我的连续数据变得离散，但我找不到更好的选择]]></description>
      <guid>https://stackoverflow.com/questions/78167792/oversampling-for-continuos-data</guid>
      <pubDate>Fri, 15 Mar 2024 14:51:35 GMT</pubDate>
    </item>
    <item>
      <title>Fabric Notebook 在使用 TSfresh 进行特征提取时遇到错误</title>
      <link>https://stackoverflow.com/questions/78167696/fabric-notebook-running-into-error-while-using-tsfresh-for-feature-extraction</link>
      <description><![CDATA[我目前正在尝试使用 Fabric Notebooks 构建我的第一个机器学习算法，但我一直遇到一个似乎不存在答案的问题。
当我尝试调用 tsfresh 的函数 extract_features 时，我不断遇到相同的错误/警告：
“请确保通过调用 set_mlflow_env_config 将环境 EnvConfig 传递给工作人员，以便正确触发工作人员上的 mlflow。”
这特别奇怪，因为此时我什至还没有导入 mlflow
我尝试过在导入和不导入 MLflow 的情况下运行它，两者都会产生相同的结果。在文档中，我似乎找不到名为“set_mlflow_env_config”的函数我很迷失。
任何人有任何想法，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78167696/fabric-notebook-running-into-error-while-using-tsfresh-for-feature-extraction</guid>
      <pubDate>Fri, 15 Mar 2024 14:35:49 GMT</pubDate>
    </item>
    <item>
      <title>Generative Ai API 获取响应时出错</title>
      <link>https://stackoverflow.com/questions/78167229/generative-ai-apis-error-in-getting-response</link>
      <description><![CDATA[#我在 Generatve Ai 、HuggingFace api 密钥 google/flan-base 模型中生成响应时遇到错误
#这是我的代码和最后一个单元格错误
导入操作系统
导入 json
将 pandas 导入为 pd
导入回溯
从 langchain 导入 PromptTemplate、HuggingFaceHub、LLMChain
从 langchain.chains 导入 SequentialChain
从 dotenv 导入 load_dotenv

加载_dotenv()
key = os.getenv(“hugging_face_key”)
os.environ[&#39;HUGGINGFACEHUB_API_TOKEN&#39;] = key
llm = HuggingFaceHub(repo_id=&#39;google/flan-t5-base&#39;, model_kwargs={&#39;温度&#39;: 0.5})

RESPONSE_JSON = {
    “1”：{
        &quot;mcq&quot;: &quot;多项选择题&quot;,
        “选项”：{
            “a”：“选择此处”，
            “b”：“选择此处”，
            “c”：“选择此处”，
            “d”：“选择此处”，
        },
        “正确”：“正确答案”，
    },
    “2”：{
        &quot;mcq&quot;: &quot;多项选择题&quot;,
        “选项”：{
            “a”：“选择此处”，
            “b”：“选择此处”，
            “c”：“选择此处”，
            “d”：“选择此处”，
        },
        “正确”：“正确答案”，
    },
    “3”：{
        &quot;mcq&quot;: &quot;多项选择题&quot;,
        “选项”：{
            “a”：“选择此处”，
            “b”：“选择此处”，
            “c”：“选择此处”，
            “d”：“选择此处”，
        },
        “正确”：“正确答案”，
    },
}

模板=“”“
文本：{文本}
您是 MCQ 专家。鉴于上述文字，您的工作是\
以 {tone} 语气为 {subject} 学生创建一个包含 {number} 个多项选择题的测验，
确保问题不重复，并检查所有问题是否与文本相符。
确保按照下面的 RESPONSE_JSON 格式设置您的响应并将其用作指南。 \
确保进行 {number} 个 MCQ
### RESPONSE_JSON
{响应_json}
”“”

quiz_ Generation_prompt = 提示模板(
    input_variables=[&quot;文本&quot;,&quot;数字&quot;,&quot;主题&quot;,&quot;语气&quot;,&quot;re​​sponse_json&quot;],
    模板=模板
）
quiz_chain = LLMChain(llm=llm，prompt=quiz_ Generation_prompt，output_key=“quiz”，verbose=True)

模板2 =“”“
您是一位专业的英语语法学家和作家。为 {subject} 学生提供多项选择测验。\
您需要评估问题的复杂性并对测验进行完整的分析。出于复杂性考虑，最多只能使用 50 个单词
如果测验不符合学生的认知和分析能力，\
更新需要更改的测验问题并更改语气，使其完全适合学生的能力。
测验_MCQ：
{测验}

上述测验的专家英语作家检查：
”“”
    
quiz_evaluation_prompt = PromptTemplate(input_variables=[“主题”,“测验”], template=TEMPLATE2)
review_chain = LLMChain(llm=llm，prompt=quiz_evaluation_prompt，output_key=“审阅”，verbose=True)

generate_evaluate_chain = SequentialChain(chains=[quiz_chain, review_chain], input_variables=[&quot;text&quot;,&quot;number&quot;,&quot;subject&quot;,&quot;tone&quot;,&quot;re​​sponse_json&quot;],
                                          output_variables=[“测验”,“评论”], verbose=True)

# 假设您之前已经定义了“file_path”
以 open(file_path, &#39;r&#39;) 作为文件：
    文本 = 文件.read()

json.dumps(RESPONSE_JSON)

数量 = 5
主题=“机器学习”
TONE =“简单”

# 执行generate_evaluate_chain并将结果存储在&#39;response&#39;中
响应=generate_evaluate_chain.run（文本=文本，数字=数字，主题=主题，音调=音调，response_json=json.dumps（RESPONSE_JSON））



#我最后一个单元格中的错误
当不存在一个输出键时，不支持run。得到[&#39;测验&#39;，&#39;评论&#39;]。
尝试了不同的功能并做了一些研究，但没有用]]></description>
      <guid>https://stackoverflow.com/questions/78167229/generative-ai-apis-error-in-getting-response</guid>
      <pubDate>Fri, 15 Mar 2024 13:21:49 GMT</pubDate>
    </item>
    <item>
      <title>部分依赖图 - 使用缩放数据开发的模型，如何取消 PDP 缩放？</title>
      <link>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</link>
      <description><![CDATA[我已经用Python制作了一个随机森林分类器模型，现在想要制作部分依赖图（PDP）。我使用缩放数据来训练和测试模型，并使 PDP 如下所示：
PartialDependenceDisplay.from_estimator(best_clf, X_test_final, best_features)。但是，x 轴值经过缩放，这限制了可解释性。
在调用 PartialDependenceDisplay 之前取消缩放数据 X_test_final 不起作用，有关如何将 x 轴值从缩放更改为未缩放的任何建议？我已经使用 StandardScaler() 缩放了我的数据。]]></description>
      <guid>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</guid>
      <pubDate>Fri, 15 Mar 2024 13:15:52 GMT</pubDate>
    </item>
    <item>
      <title>将 fit_resamples 与自定义分割数据一起使用？</title>
      <link>https://stackoverflow.com/questions/78167178/use-fit-resamples-with-custom-split-data</link>
      <description><![CDATA[我有一个自定义函数，可以根据各种标准和规则将数据分成训练集和测试集。我想在 tidymodels 工作流程中与 fit_resamples 一起使用此函数。但是，当我可以使我的列表看起来像用 vfold_cv 制作的列表时，它似乎不起作用。我正在使用的示例代码：
data(ames, package = “modeldata”)

split_data &lt;- 函数(df, n) {
  set.seed(123) # 为了重现性
  df$id &lt;- seq.int(nrow(df))
  list_of_splits &lt;- list()
  
  for(i in 1:n) {
    train_index &lt;- 样本(df$id, size=ceiling(nrow(df)*.8))
    train_set &lt;- df[train_index,]
    test_set &lt;- df[-train_index,]
    list_of_splits[[i]] &lt;- list(train_set = train_set, test_set = test_set)
  }
  
  返回（分割列表）
}

分割 &lt;- split_data(ames, 5)

重新采样 &lt;- map(splits, ~rsample::make_splits(
  x = .$train_set |&gt;选择(colnames(.$test_set)),
  评估=.$test_set
））

名称（重新采样）&lt;-paste0（“折叠”，seq_along（重新采样））

重新采样 &lt;- tibble::tibble(splits = 重新采样,
                            id = 名称（重新采样））

lm_model &lt;-
  Linear_reg() %&gt;%
  set_engine(“lm”)

lm_wflow &lt;-
  工作流程() %&gt;%
  add_model(lm_model) %&gt;%
  add_formula(Sale_Price ~ 经度 + 纬度)

res &lt;- lm_wflow %&gt;%
  fit_resamples（重新采样=重新采样）

运行最后一行后返回的错误是：
`check_rset()` 中出现错误：
！ “resamples”参数应该是一个“rset”对象，例如由“vfold_cv()”或其他“rsample”函数生成的类型。

如果我尝试强制该类“rset” class(resamples) &lt;- “rset”，列表看起来不再正确，我得到了相同的错误。
使用自定义交叉折叠数据集的正确方法是什么？
注意 - 附加问题：在上面的示例代码中，测试集和训练集的大小在折叠中是一致的。在我的实际数据中，这会略有不同 - 这有关系吗？
基于以下答案的解决方案：
data(ames, package = “modeldata”)

split_data &lt;- 函数(df, n) {
  set.seed(123) # 为了重现性
  df$id &lt;- seq.int(nrow(df))
  list_of_splits &lt;- list()
  
  for(i in 1:n) {
    train_index &lt;- 样本(df$id, size=ceiling(nrow(df)*.8))
    train_set &lt;- df[train_index,]
    test_set &lt;- df[-train_index,]
    list_of_splits[[i]] &lt;- list(train_set = train_set, test_set = test_set)
  }
  
  返回（分割列表）
}

分割 &lt;- split_data(ames, 5)

重新采样 &lt;- 地图（分割，〜列表（
  分析 = .$train_set |&gt;选择(colnames(.$test_set)) |&gt;拉（id），
  评估 = .$test_set$id
））

splits &lt;- lapply（重新采样，make_splits，数据= ames）

Final_split &lt;- Manual_rset(splits, Paste(“Split”, seq(1:5)))

lm_model &lt;-
  Linear_reg() %&gt;%
  set_engine(“lm”)

lm_wflow &lt;-
  工作流程() %&gt;%
  add_model(lm_model) %&gt;%
  add_formula(Sale_Price ~ 经度 + 纬度)

res &lt;- lm_wflow %&gt;%
  fit_resamples（重新采样= Final_split）

收集指标（res）
]]></description>
      <guid>https://stackoverflow.com/questions/78167178/use-fit-resamples-with-custom-split-data</guid>
      <pubDate>Fri, 15 Mar 2024 13:11:15 GMT</pubDate>
    </item>
    <item>
      <title>如何将多个视频输入组合成 (2+1)D ResNet</title>
      <link>https://stackoverflow.com/questions/78166723/how-do-i-combine-multiple-video-inputs-into-a-21d-resnet</link>
      <description><![CDATA[我开发了 (2+1)D ResNet 的 v1，它将每帧的像素数据作为输入，并用于预测该视频中最多 8 个对象的边界框坐标。我当前输入的形状是：
（batch_size、n_frames、高度、宽度、通道）
我的输出是这样的：
&lt;代码&gt;（n_frames，32）
我使用交并集（IoU）作为损失，并且看到一些相对较差的结果。我想通过增加模型中的特征数量来增加这一点（数据集很小，但将来会增加）。我从视频中提取的特征是：

边缘
运动向量
颜色直方图
光流
纹理

如何利用这些功能从我的模型中获得更好的预测？
我的第一步是将像素数据、单个特征和标签放入列表中。然后我创建了训练、测试和验证分组。使用帧生成器类将它们转换为数据集。
然后我创建了以下架构：
input_shape =（无、无、高度、宽度、4）
frames_input=layers.Input(形状=(无，高度，宽度，3))
Edges_input=layers.Input(形状=(无，高度，宽度，1))
merged_input=layers.concatenate(\[frames_input, Edges_input\], axis=-1)

# 重塑输入张量以包含不同长度的时间维度

x = 图层.Reshape((-1, 高度, 宽度, 4))(merged_input)

x = Conv2Plus1D(filters=FILTERS, kernel_size=KERNAL_SIZE, padding=&#39;same&#39;)(x)
x = 层.BatchNormalization()(x)
x = 层.ReLU()(x)
x = 调整视频大小(高度 // 2, 宽度 // 2)(x)

# 区块 1

x = add_residual_block(x, 16, (3, 3, 3))
x = 调整视频大小(高度 // 4, 宽度 // 4)(x)

# 区块 2

x = add_residual_block(x, 32, (3, 3, 3))
x = 调整视频大小(高度 // 8, 宽度 // 8)(x)

# 区块 3

x = add_residual_block(x, 64, (3, 3, 3))
x = 调整视频大小(高度 // 16, 宽度 // 16)(x)

# 区块 4

x = add_residual_block(x, 128, (3, 3, 3))

# 应用 TimeDistributed 密集层来输出每帧的边界框坐标

x = TimeDistributed(layers.GlobalAveragePooling2D())(x) # 将空间维度转换为单维度
x = TimeDistributed(layers.Dense(32))(x)

BoundingBoxV2_model = keras.Model（[frames_input，edges_input]，x）

并像这样构建模型：
sampled_frames，sampled_edges，sampled_labels = next(iter(train_ds)) BoundingBoxV2_model.build([sampled_frames，sampled_edges])
当我尝试拟合我的模型时，出现以下错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
单元格位于\[149\]，第 1 行
\----\&gt; 1 历史 = BoundingBoxV2_model.fit(x = train_ds,
2 epoch = EPOCHS,
3 验证数据 = val_ds)

文件c:\\Users\\Rpiku\\miniconda3\\envs\\rally_stream\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70，位于filter_traceback中。\ .error_handler(\*args, \*\*kwargs)
67 过滤_tb = \_process_traceback_frames(e.__traceback__)
68 # 要获取完整的堆栈跟踪，请调用：
69 # `tf.debugging.disable_traceback_filtering()`
\---\&gt; 70 从 None 引发 e.with_traceback(filtered_tb)
71 最后：
72 删除filtered_tb

文件 \~\\AppData\\Local\\Temp\__autograph_ generated_file3rk3lb1s.py:15，位于outer_factory.\.inner_factory.\.tf__train_function(iterator)
13 尝试：
14 do_return =真
\---\&gt; 15 retval_ = ag_\_.converted_call(ag_\_.ld(step_function), (ag_\_.ld(self), ag_\_.ld(迭代器)), 无, fscope)
16 除外：
17 do_return = 假

ValueError：在用户代码中：

    文件“c:\Users\Rpiku\miniconda3\envs\rally_stream\lib\site-packages\keras\engine\training.py”，第 1160 行，在 train_function *

...
文件“c:\\Users\\Rpiku\\miniconda3\\envs\\rally_stream\\lib\\site-packages\\keras\\engine\\input_spec.py”，第216行，位于assert_input_compatibility中
引发值错误（

    ValueError：层“model_8”期望 2 个输入，但它收到 1 个输入张量。收到的输入：[]`
]]></description>
      <guid>https://stackoverflow.com/questions/78166723/how-do-i-combine-multiple-video-inputs-into-a-21d-resnet</guid>
      <pubDate>Fri, 15 Mar 2024 11:54:13 GMT</pubDate>
    </item>
    <item>
      <title>无限循环运行并且即使在 40 分钟后也没有获取输出 [关闭]</title>
      <link>https://stackoverflow.com/questions/78166475/endless-loop-running-and-not-fetching-the-output-even-after-40-minutes</link>
      <description><![CDATA[代码：

错误：

我尝试通过中断终端来运行，但是超过 20 的评级（这是需要的）不可用。即使跑了一个多小时他们也没有停下来。
终端运行了更长的时间，没有结束，但是当中断时，它在第 6 行显示一个错误，这完全没问题。
我想知道这是否是由于我使用的 json 文件大小以及我的系统 RAM 效率低下所致。]]></description>
      <guid>https://stackoverflow.com/questions/78166475/endless-loop-running-and-not-fetching-the-output-even-after-40-minutes</guid>
      <pubDate>Fri, 15 Mar 2024 11:10:11 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中线性回归的内部工作原理</title>
      <link>https://stackoverflow.com/questions/78165544/internal-working-of-linear-regression-in-scikit-learn</link>
      <description><![CDATA[我试图了解 Scikit-learn 中线性回归模型的内部工作原理。
这是我的数据集

这是我执行 one-hot-encoding 后的数据集。

这是执行线性回归后的系数和截距值。

销售价格是从属列，其余列是特征。
这些是在这种情况下工作正常的预测值。

我注意到系数的数量比特征的数量多 1。这就是我生成特征矩阵的方式：
feature_matrix = dataFrame.drop([&#39;售价($)&#39;], axis = &#39;列&#39;).to_numpy()

# 要添加为列的数组
bias_column = np.array([[1] for i in range(len(feature_matrix))])

# 使用append()方法将列添加到数组
feature_matrix = np.concatenate([bias_column, feature_matrix], axis = 1) # axis = 1表示列，0表示行

结果

我想知道的是 Scikit-learn 如何使用这些系数和截距来预测值。
这是我尝试过的。
我还注意到，通过进行此计算得到的值实际上等于每种情况下的里程数。但这不是这里的依赖功能。那么这是怎么回事？]]></description>
      <guid>https://stackoverflow.com/questions/78165544/internal-working-of-linear-regression-in-scikit-learn</guid>
      <pubDate>Fri, 15 Mar 2024 08:26:45 GMT</pubDate>
    </item>
    <item>
      <title>部署机器学习时出错 - Flask 项目</title>
      <link>https://stackoverflow.com/questions/78165242/error-while-deploying-machine-learning-flask-project</link>
      <description><![CDATA[我正在尝试使用 LSTM 构建手语识别模型。我是烧瓶新手，找不到问题所在。当我运行该文件时，它会打开相机但不会检测到该操作。此外，一旦相机打开，应用程序就会卡住。请帮我找出错误，代码如下：
来自flask导入Flask，render_template，Response
导入CV2
进口泡菜
导入 pyttsx3
将 numpy 导入为 np
将 mediapipe 导入为 mp
导入线程

应用程序=烧瓶（__名称__）

从tensorflow.keras.models导入load_model
model = load_model(&#39;action.h5&#39;)

mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils

actions = np.array([&#39;你好&#39;,&#39;我是&#39;,&#39;阿凡&#39;,&#39;谢谢&#39;,&#39;我爱你&#39;,&#39;发烧&#39;,&#39;再见&#39;,&#39;上帝&#39;])

def mediapipe_detection（图像，模型）：
    图像 = cv2.cvtColor(图像, cv2.COLOR_BGR2RGB)
    image.flags.writeable = False
    结果 = model.process(图像)
    image.flags.writeable = True
    图像 = cv2.cvtColor(图像, cv2.COLOR_RGB2BGR)
    返回图像、结果

def extract_keypoints(结果):
    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)
    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)
    返回 np.concatenate([lh, rh])

def draw_styled_landmarks（图像，结果）：
    mp_drawing.draw_landmarks(图像, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                             mp_drawing.DrawingSpec(颜色=(100, 100, 100), 厚度=2, 圆半径=4),
                             mp_drawing.DrawingSpec(颜色=(100, 100, 100), 厚度=2, 圆半径=2)
                             ）
    mp_drawing.draw_landmarks(图像, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                             mp_drawing.DrawingSpec(颜色=(200, 200,200), 厚度=2, 圆半径=4),
                             mp_drawing.DrawingSpec(颜色=(200, 200, 200), 厚度=2, 圆半径=2)
                             ）

序列=[]
句子=[]
预测=[]
阈值 = 0.5

上限 = cv2.VideoCapture(0)

defgenerate_frames():
    sequence = [] # 初始化序列变量
    Sentence = [] # 初始化Sentence变量
    而真实：
        ret, 框架 = cap.read()
        如果不转：
            休息

        图像，结果= mediapipe_detection（框架，整体）
        draw_styled_landmarks（图像，结果）
        关键点 = extract_keypoints(结果)
        序列.append(关键点)
        序列 = 序列[-30:]

        如果长度（序列）== 30：
            res = model.predict(np.expand_dims(序列，轴=0))[0]
            预测.append(np.argmax(res))
            
            if np.unique(预测[-10:])[0] == np.argmax(res):
                如果 res[np.argmax(res)] &gt;临界点：
                    if len(句子) &gt; 0:
                        if actions[np.argmax(res)] !=句子[-1]:
                            句子.append(actions[np.argmax(res)])
                            new_word = 动作[np.argmax(res)]
                            t2s.say(new_word)
                            t2s.runAndWait()
                    别的：
                        句子.append(actions[np.argmax(res)])
                        new_word = 动作[np.argmax(res)]
                        t2s.say(new_word)
                        t2s.runAndWait()

            if len(句子) &gt; 5：
                句子 = 句子[-5:]

        ret, buffer = cv2.imencode(&#39;.jpg&#39;, 图片)
        帧 = buffer.tobytes()
        产量（b&#39;--帧\r\n&#39;
                b&#39;内容类型：image/jpeg\r\n\r\n&#39; + 帧 + b&#39;\r\n&#39;)

    cap.release()


@app.route(&#39;/&#39;)
定义索引（）：
    返回 render_template(&#39;index.html&#39;)

@app.route(&#39;/video_feed&#39;)
def video_feed():
    返回响应（generate_frames（），mimetype =&#39;multipart / x-mixed-replace；边界=框架&#39;）

如果 __name__ == “__main__”：
    t2s = pyttsx3.init()
    整体 = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)
    应用程序运行（调试=真）
  


我尝试过更改模型和修改代码，但不起作用。最初相机馈送未显示，但现在可以正常工作]]></description>
      <guid>https://stackoverflow.com/questions/78165242/error-while-deploying-machine-learning-flask-project</guid>
      <pubDate>Fri, 15 Mar 2024 07:20:28 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习预测未来股票价格[关闭]</title>
      <link>https://stackoverflow.com/questions/78163298/predicting-future-stock-prices-using-machine-learning</link>
      <description><![CDATA[我正在尝试用 python 训练机器学习模型（xgb）来预测股票价格。我首先获取股票价格，然后计算技术指标以用作特征。然后，我将数据拆分为训练集和测试集，其中特征（modeling_df）为 X，收盘价（closes）为 Y。
我的问题是，我不确定该模型实际上是根据过去的价格来预测价格，但该模型是通过查看当前时间的特征来预测价格。我还想确保它使用“滚动窗口”，因此，如果有 30 个值，则值 11-20 应基于 0-10，而 21-30 应基于 0- 20.
如果有人知道神经网络的解决方案是否不同，那么我们也将不胜感激！
scaled_features = scaler.fit_transform(modeling_df)

X = 缩放特征
Y = 关闭

x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.05,shuffle=False)

然后我使用：
final_model = xgb.XGBRegressor(**best_params)
Final_model.fit(x_train,y_train, )

预测 = Final_model.predict(x_test)

然后我使用 matplotlib 显示它。
我尝试将整个数据集移动 10（和其他值），以尝试预测未来的 10 个数据点，但我不确定如何验证它是否确实有效。
这是我的图表（数据集没有被移动）。
烛台 + 蓝线 = 实际价格
紫色线 = 预测价格
图表：

这里有一些数据：
功能和价格（不变）：

&lt;标题&gt;

时间
Og 价格
RSI


&lt;正文&gt;

11:02
3.61
51.07


11:03
3.62
57.89


11:04
3.62
60.28


11:05
3.61
62.92



预测与原价：

&lt;标题&gt;

时间
Og 价格
预测


&lt;正文&gt;

11:02
3.6
3.61


11:03
3.61
3.62


11:04
3.61
3.62


11:05
3.61
3.61



本质上，我想确保我的模型没有使用 11:02-05 的 RSI 来预测 11:05 的值。我希望它使用 11:02-04 的值来预测 11:05 的值，以便它预测未来。]]></description>
      <guid>https://stackoverflow.com/questions/78163298/predicting-future-stock-prices-using-machine-learning</guid>
      <pubDate>Thu, 14 Mar 2024 20:30:48 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Plot 中 GBT 的值表示什么？</title>
      <link>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</link>
      <description><![CDATA[我使用 tfdf.keras.GradientBoostedTreesModel 进行二元分类，并在使用 tfdf.model_plotter.plot_model_in_colab 绘制它时，它显示了分割条件下的值：有值的节点
这个“价值”是什么？意思是？
我已经阅读了 gbt 模型和绘图仪的文档，但找不到有关此值的任何内容。]]></description>
      <guid>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</guid>
      <pubDate>Thu, 14 Mar 2024 13:26:35 GMT</pubDate>
    </item>
    <item>
      <title>更改源代码后如何运行YOLOv8？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78153468/how-do-i-run-yolov8-after-changing-the-source-code</link>
      <description><![CDATA[我需要将 YOLOv8 模型中的默认损失函数（CIOU）更改为 DIOU（或者可能添加自定义函数）。更改后我需要运行模型。
如何使用更改后的代码运行模型？
我找到了需要更改代码的必要文件。现在我不清楚运行模型。
我正在使用 ultralytics 库运行模型，但我认为更改代码后，我无法像那样运行模型。
我对此很陌生，因此我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78153468/how-do-i-run-yolov8-after-changing-the-source-code</guid>
      <pubDate>Wed, 13 Mar 2024 11:37:16 GMT</pubDate>
    </item>
    <item>
      <title>嵌入后无法将序列数据转换为 3D 张量</title>
      <link>https://stackoverflow.com/questions/78153453/failed-to-convert-sequence-data-to-a-3d-tensor-after-the-embedding</link>
      <description><![CDATA[我正在使用序列数据（RNA序列）进行分类任务，所以我想尝试CNN，我只是发现在数据编码（我使用序数编码）之后我必须将输入数据编码转换为3D 张量，我仍然不明白如何做到这一点，因此输入形状将是（batch_size，sequence_lenght，num_features）
这是我的输入数据代码：
&lt;块引用&gt;
使用提供的字符“”填充右侧的序列。至 11420 nt
pad_list = df[&#39;Seq&#39;].str.ljust(11420,&#39;&#39;)
减少太长的序列长度
pad_list = pad_list.map(lambda x: x[0:11420])
使用序数编码将核苷酸编码为整数
类别=[“A”、“C”、“G”、“U” 、“T”、“N”、“R”、“K”、“S”、“Y”、“M”、“W”、“D”、“_” ]
ordi = OrdinalEncoder(handle_unknown=“use_encoded_value”,unknown_value=15)
ordi.fit(np.array(列表(类别)).reshape(-1, 1))
pad_list= pad_list.map(lambda seq: ordi.transform(np.array(list(seq)).reshape(-1, 1)))
#将序列转换为整数列表列表而不是矩阵
sequence_input= np.array(pad_list.to_list()).reshape((len(pad_list), len(pad_list[0])))`

我真的尝试使用 cnn 模型查找此类数据的代码，但没有找到好的代码，而且我是这个领域的新手，所以我真的很想了解如何在 cnn 中使用序列数据]]></description>
      <guid>https://stackoverflow.com/questions/78153453/failed-to-convert-sequence-data-to-a-3d-tensor-after-the-embedding</guid>
      <pubDate>Wed, 13 Mar 2024 11:35:10 GMT</pubDate>
    </item>
    <item>
      <title>torch.transforms.normalize 中的数字是什么以及如何选择它们？</title>
      <link>https://stackoverflow.com/questions/65467621/what-are-the-numbers-in-torch-transforms-normalize-and-how-to-select-them</link>
      <description><![CDATA[我以下 一些 教程，我在 transforms 部分不断看到不同的数字，这些数字对我来说似乎相当随意
即，
transform = Transforms.Compose([transforms.ToTensor(), Transforms.Normalize((0.5,), (0.5,))])

或
transform =transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])

或
transform = 变换.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

或其他。
我想知道这些数字是从哪里出现的，以及如何知道选择正确的数字？
我即将使用 MNIST 来保持理智，但很快就会使用我自己独特的数据集，并且可能需要我自己的标准化。]]></description>
      <guid>https://stackoverflow.com/questions/65467621/what-are-the-numbers-in-torch-transforms-normalize-and-how-to-select-them</guid>
      <pubDate>Sun, 27 Dec 2020 15:57:14 GMT</pubDate>
    </item>
    <item>
      <title>什么是 x_train.reshape() 及其作用？</title>
      <link>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</link>
      <description><![CDATA[使用 MNIST 数据集
将 numpy 导入为 np
将张量流导入为 tf
从tensorflow.keras.datasets导入mnist

# MNIST 数据集参数
num_classes = 10 # 总类别（0-9 位数）
num_features = 784 # 数据特征（img 形状：28*28）

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 转换为float32
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)

# 将图像展平为 784 个特征的一维向量 (28*28)
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])

# 将图像值从 [0, 255] 标准化为 [0, 1]
x_train, x_test = x_train / 255., x_test / 255.

在这些代码的第 15 行，即，
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])。我无法理解这些重塑在我们的数据集中到底做了什么......？请解释一下。]]></description>
      <guid>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</guid>
      <pubDate>Sat, 02 May 2020 06:44:34 GMT</pubDate>
    </item>
    </channel>
</rss>