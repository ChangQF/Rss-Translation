<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 16 Nov 2024 18:21:11 GMT</lastBuildDate>
    <item>
      <title>使用 knn 算法的图形 ql 突变类型错误[关闭]</title>
      <link>https://stackoverflow.com/questions/79195596/type-error-on-graph-ql-mutation-using-knn-algortihm</link>
      <description><![CDATA[require(&#39;@tensorflow/tfjs-node&#39;); //在笔记本电脑 CPU 上运行 tfjs
const tf = require(&#39;@tensorflow/tfjs&#39;); //在 Tensorflow JS lib 中需要
const Users = require(&#39;../../mongodb/models/users&#39;)
const Posts = require(&#39;../../mongodb/models/posts&#39;)

function knn(features, labels, predictionPoint, k) { 
features = tf.tensor(features);
la​​bels = tf.tensor(labels);
const {mean, variance} = tf.moments(features, 0);
const scaledPrediction = predictionPoint.sub(mean).div(variance.pow(0.5)) //用于标准化的缩放预测 const
const apple = features.sub(mean)
/* 步骤 0 - 特征标准化 */
.div(variance.pow(0.5))
/* 步骤 1 - 查找特征之间的距离 &amp;预测点特征 */
.sub(scaledPrediction) //广播操作
.pow(2) //逐元素运算，对每个元素求平方
.sum(1) //沿 x(1) 轴求和
.sqrt() //逐元素运算，对每个元素取 .5 = sqrt 的幂
/* 第 2 步 - 从最小距离到最大距离排序 */
.expandDims(1) //我们在 x 轴上扩展距离张量的维度，以获得 [4,1] 的形状，与标签距离相同
.concat(labels, 1) //我们将标签连接到 x 轴上的距离，以便它们通过一个张量中的相同索引链接
.unstack() //我们将 1 个张量拆分为 1 个包含多个张量的 Vanilla JS 数组
/* 拆分张量后，我们正在处理 vanilla JS 数组，从现在开始我们只能使用 vanilla JS 方法*/
.sort((a,b) =&gt; a.get(0) &gt; b.get(0) ? 1 : -1) //按距离从小到大的顺序对函数 tp sprt 张量进行排序
/* 步骤 3 - 平均前 k 条记录的标签值 */ 
.slice(0, k)//获取前 k 条记录

return apple
}
module.exports = knn

这是我从后端 graphql 服务器发送请求的 knn 函数。
const prediction = async(args) =&gt;{
let count = []
let countt = []
const users = await Users.find({email: {$ne:`${args.email}`}}).exec();
users.map((user)=&gt;{
let name = user.username
user.likes[0].map((genre)=&gt;{
let pusht = 
{ [name]:[`${genre.adventure}`,
`${genre.action}`,
`${genre.comedy}`,
`${genre.drama}`,
`${genre.fantasy}`,
`${genre.horror}`,
`${genre.romance}`,
`${genre.sciencefiction}`,
`${genre.thriller}`,
`${genre.mystery}`,
`${genre.documentary}`,
`${genre.western}`,
`${genre.musical}`,
`${genre.anime}`,
`${genre.educational}`,
]}
count.push(pusht)
console.log(count)
})
})
const userss = await Users.find({email:args.email}).exec()
userss.map((user)=&gt;{
user.likes[0].map((genre)=&gt;{
let pushtt = 
{ [args.email]:[`${genre.adventure}`,
`${genre.action}`,
`${genre.comedy}`,
`${genre.drama}`,
`${genre.fantasy}`,
`${genre.horror}`,
`${genre.romance}`,
`${genre.sciencefiction}`,
`${genre.thriller}`,
`${genre.mystery}`,
`${genre.documentary}`,
`${genre.western}`,
`${genre.musical}`,
`${genre.anime}`,
`${genre.educational}`,
]}
​​countt.push(pushtt)
console.log(countt)
})
})
try{
count.forEach((feature, i) =&gt; {
const result = knn(tf.tensor(Object.values(feature)), tf.tensor(Object.keys(feature)), tf.tensor(Object.values(countt)), 10);
console.log(&#39;User Prediction&#39;, result); //注销用户预测
return {peopleyoumaylike: result}
})
}
catch(e){
console.log(e)
}

}

以上是我正在发送的 gql 请求。下面是我收到的 gql 错误。
{
&quot;errors&quot;: [
{
&quot;message&quot;: &quot;PeopleYouMayLike.peopleyoumaylike 的类型必须是输出类型，但得到的是：[function GraphQLObjectType]。&quot;
},
{
&quot;message&quot;: &quot;Expected GraphQL named type but got: [function GraphQLObjectType]。&quot;
}
]
}

我不知道如何处理和解决该问题。我不知道为什么会导致类型错误。控制台日志未显示在终端上。所以我看不到结果。我该怎么办。我在开发项目时错误地实现了 docker。所以我认为 vs code javascript 调试器不起作用。请帮忙。提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/79195596/type-error-on-graph-ql-mutation-using-knn-algortihm</guid>
      <pubDate>Sat, 16 Nov 2024 16:37:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 google colab 中使用从 kaggle 加载的数据（实际使用它）</title>
      <link>https://stackoverflow.com/questions/79195592/how-to-use-loaded-data-from-kaggle-in-google-colab-to-actually-work-with-it</link>
      <description><![CDATA[因此，我最近从此 https://www.kaggle.com/datasets/mostafaabla/garbage-classification 网站导入了数据集。尽管我在 google colab 中的文件中有它（已解压和所有这些东西），但我不知道如何在代码本身中实现它。就像来自 tensorflow 的 Fashion mnist 教程 https://www.tensorflow.org/tutorials/keras/classification?hl 它加载为
fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
如何将数据导入/加载到代码单元并通过分成类来处理它（因为在该教程数据集中有多个类，而在我的自定义数据集中有 12 个）
请问如何操作？
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 定义训练和验证目录的路径
train_dir = &#39;garbage-classification/train&#39;
val_dir = &#39;garbage-classification/validation&#39;

# 创建 ImageDataGenerator 进行数据增强
train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen = ImageDataGenerator(rescale=1./255)

# 从目录加载图像
train_generator = train_datagen.flow_from_directory(
train_dir,
target_size=(150, 150), # 根据需要调整图像大小
batch_size=32,
class_mode=&#39;categorical&#39; # 如果有多个类，请使用 &#39;categorical&#39;
)

validation_generator = val_datagen.flow_from_directory(
val_dir,
target_size=(150, 150),
batch_size=32,
class_mode=&#39;categorical&#39;
)

我使用 perplexity 尝试解决，结果得到了这个。显然它没有起作用，所以..]]></description>
      <guid>https://stackoverflow.com/questions/79195592/how-to-use-loaded-data-from-kaggle-in-google-colab-to-actually-work-with-it</guid>
      <pubDate>Sat, 16 Nov 2024 16:34:39 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow/Keras 模型的 SHAP force_plot 中出现 InvalidArgumentError：切片索引超出范围</title>
      <link>https://stackoverflow.com/questions/79195478/invalidargumenterror-in-shap-force-plot-for-tensorflow-keras-model-slice-index</link>
      <description><![CDATA[我正在使用 TensorFlow/Keras 二元分类模型并使用 SHAP 来解释单个预测。但是，当我尝试生成力图时，我遇到了以下错误：
# 导入 SHAP
import shap

# 确保 data_for_prediction 具有正确的形状
data_for_prediction_reshaped = data_for_prediction.reshape(1, -1)

# 为 DeepExplainer 提供背景数据
background = X_train[:100] # 使用来自训练数据的 100 个样本作为背景

# 初始化 DeepExplainer
explainer = shap.DeepExplainer(model, background)

# 计算 SHAP 值
shap_values = explainer.shap_values(data_for_prediction_reshaped)

# 生成力图
shap.initjs()
shap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction_reshaped)


错误：
InvalidArgumentError：{{function_node _wrapped__StridedSlice_device/job:localhost/replica:0/task:0/device:CPU:0}} 切片索引 1 的维度 0 超出范围。[Op:StridedSlice] 名称：strided_slice/
其他详细信息：
1. 该模型是具有以下架构的 Keras Sequential 模型：
• 具有 ReLU 激活的多个密集层。
• 每个密集层后都有一个 Dropout 层。
• 具有用于二元分类的 S 形激活的输出层。
2. 背景数据：
• X_train[:100] 是我预处理的训练数据（NumPy 数组）的一部分。
3. 预测输入：
• data_for_prediction_reshaped 是重塑为 (1, n_features) 的单个样本。
4. 形状：
• shap_values[1].shape：SHAP 值的输出形状（针对第 1 类）。
• data_for_prediction_reshaped.shape：重塑为 (1, n_features) 的输入特征。
问题：
1. 在此上下文中，“维度 0 的切片索引 1 超出范围”错误是什么意思？
2. 我应该如何调整代码以确保 shap.force_plot 能够与 SHAP 和 TensorFlow/Keras 模型一起正常工作？
3. 对于此用例，我应该注意 SHAP 和 TensorFlow/Keras 之间是否存在特定的兼容性问题？
如能提供任何指导，我们将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79195478/invalidargumenterror-in-shap-force-plot-for-tensorflow-keras-model-slice-index</guid>
      <pubDate>Sat, 16 Nov 2024 15:38:25 GMT</pubDate>
    </item>
    <item>
      <title>视觉变换器的计算复杂度[关闭]</title>
      <link>https://stackoverflow.com/questions/79195302/computation-complexity-of-vision-transformer</link>
      <description><![CDATA[我正在寻求有关 Vision Transformers (ViTs) 计算复杂度的澄清，特别是关于多头自注意力 (MSA)、MLP 块、LayerNorm (LN) 和每个块后应用的残差连接等组件。尽管查阅了大量研究论文和资源，但我发现很难掌握这些组件的计算复杂度是如何得出和计算的清晰而简单的解释。有人能提供更详细、更易于理解的解释吗？提前感谢您的帮助。
我试图理解如何计算 ViT 的计算复杂度，但我对计算它感到困惑。我期待解释 ViT 计算复杂度部分从补丁嵌入到 MLP 块。]]></description>
      <guid>https://stackoverflow.com/questions/79195302/computation-complexity-of-vision-transformer</guid>
      <pubDate>Sat, 16 Nov 2024 14:07:32 GMT</pubDate>
    </item>
    <item>
      <title>BERTopic partial_fit 占位符集群表示</title>
      <link>https://stackoverflow.com/questions/79195169/bertopic-partial-fit-placeholder-cluster-representation</link>
      <description><![CDATA[我有大约 2M 个文本文档，每个文档都很小，我想对它们进行聚类。（最终将增长到大约 500M。）虽然我愿意接受建议，但我目前正在使用 Python3 包 BERTopic 的在线技术。在对 140 个 15k 个文档块使用 partial_fit 后，我只剩下对 topic_model.get_topic_info() 的调用，它返回未完成的聚类表示。也就是说，我看到聚类名称 0____ 的表示为 [,,,,,,,,]。我看到大多数聚类都是这样的。我从 Google Gemini 得到的建议是对我的所有文档调用 topic_model.fit(all_documents)，这些文档目前在磁盘上压缩后只有 86 GB，对于 RAM 来说太多了。我该如何填写这些聚类的表示？]]></description>
      <guid>https://stackoverflow.com/questions/79195169/bertopic-partial-fit-placeholder-cluster-representation</guid>
      <pubDate>Sat, 16 Nov 2024 12:50:38 GMT</pubDate>
    </item>
    <item>
      <title>小数据集的音频微调配置</title>
      <link>https://stackoverflow.com/questions/79195104/audio-fine-tuning-configuration-for-small-data-set</link>
      <description><![CDATA[我是数据训练方面的新手，尤其是在微调方面。我想尝试使用 vits 对音频数据进行微调，数据集小于 100 个音频文件，每个音频文件小于 10 秒，问题就在这里，我已经尝试了几种情况，例如调整

Epoch
Batch Size
Learning Rate
Betas
Warm up Epochs
Mel Processing data

但不知何故它仍然没有给出我想要的结果。我读了文档，它说给出大约 600-1000 个 epoch 可以得到很好的结果，但就我而言，情况仍然不是这样。我尝试了大约 4 天来训练几种情况：
第一次：

注释：这是我第一次进行微调项目
批次大小：16
时期：200
时间：~20 分钟
结果：我听到了很多像机器一样的声音，有些声音捕捉正确，但如果不集中注意力，声音太小而无法注意到

第二次：

注释：我读了几篇文章，似乎较小的批次可以为小数据量提供更紧密的结果，至于时期，我需要确保不要过度拟合，所以我尝试在这里实现它
批次大小：8
时期： 300
时间：~30 分钟
结果：使用这种方法，我开始听到一些声音，尽管它仍然有很多类似机器的模式，但开始在这个案例上有所启发

第三：

注释：根据第二种情况的结果，我认为增加 epoch 可以得到更好的结果，因为范围很广，所以在这种情况下，我尝试遵循推荐的配置（16 批次 &amp; 10000 个 epoch），但尝试使 epoch 更小
批次大小：8
epoch：3000
时间：~8-9 小时
结果：不知何故，在这个结果中，它开始听起来不像机器那样，大约 25%，所以如果我想添加 epoch，也许增加批次大小会有所帮助

第四次：

注意：基于最后的情况，我尝试增加批次大小，因为我的规格不是那么糟糕（我将在本节下方提供其他信息）
批次大小：16
epoch：4000
时间：~7-8 小时
结果：在这种情况下，不知何故它让声音变得非常奇怪，就像减少了性能

基于此，我想问一下，如何正确计算训练的值以获得至少不错的结果？我对第一次微调有点困惑
至于我的PC 规格，这里是：

NVidia RTX 3060 12 GB DDR6 配备 64 GB RAM &amp;第 12 代英特尔 I7-12700F

我曾尝试从 GPT 获取我的设置的最佳配置，但不知何故结果仍然相同，它给出了以下参数：
 &quot;train&quot;: {
&quot;log_interval&quot;: 50,
&quot;eval_interval&quot;: 200,
&quot;seed&quot;: 1234,
&quot;epochs&quot;: 1000,
&quot;learning_rate&quot;: 1e-4,
&quot;betas&quot;: [0.9, 0.98],
&quot;eps&quot;: 1e-9,
&quot;batch_size&quot;: 4,
&quot;fp16_run&quot;: true,
&quot;lr_decay&quot;: 0.9999,
&quot;segment_size&quot;: 8192,
&quot;init_lr_ratio&quot;: 1,
&quot;warmup_epochs&quot;: 5,
&quot;c_mel&quot;: 30,
&quot;c_kl&quot;: 1.0
}

截至存储库默认配置，给出的内容如下：
 &quot;train&quot;: {
&quot;log_interval&quot;: 200,
&quot;eval_interval&quot;: 1000,
&quot;seed&quot;: 1234,
&quot;epochs&quot;: 10000,
&quot;learning_rate&quot;: 2e-5,
&quot;betas&quot;: [0.8, 0.99],
&quot;eps&quot;: 1e-9,
&quot;batch_size&quot;: 16,
&quot;fp16_run&quot;: true,
&quot;lr_decay&quot;: 0.999875,
&quot;segment_size&quot;: 8192,
&quot;init_lr_ratio&quot;: 1,
&quot;warmup_epochs&quot;: 0,
&quot;c_mel&quot;: 45,
&quot;c_kl&quot;: 1.0
}

所以这里有一些我想问的问题：
有没有针对 100 个数据集以下音频文件的微调配置建议？最大批次大小是否应始终低于样本数据总量？]]></description>
      <guid>https://stackoverflow.com/questions/79195104/audio-fine-tuning-configuration-for-small-data-set</guid>
      <pubDate>Sat, 16 Nov 2024 12:03:58 GMT</pubDate>
    </item>
    <item>
      <title>如何使用神经网络找到下图中所有交点的坐标？</title>
      <link>https://stackoverflow.com/questions/79194488/how-can-i-find-coordinate-of-all-intersection-points-in-the-following-image-with</link>
      <description><![CDATA[我想使用神经网络找到下图中的所有交点。有人知道我该如何实现吗？

目前，我使用 openCV 阈值或边缘检测，但在某些情况下效果不佳。所以，我想使用神经网络来做到这一点，但我就是不知道如何使用神经网络来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/79194488/how-can-i-find-coordinate-of-all-intersection-points-in-the-following-image-with</guid>
      <pubDate>Sat, 16 Nov 2024 03:55:18 GMT</pubDate>
    </item>
    <item>
      <title>Rectools‘Dataset’对象没有属性‘from_dataset’</title>
      <link>https://stackoverflow.com/questions/79194068/rectools-dataset-object-has-no-attribute-from-dataset</link>
      <description><![CDATA[我尝试使用 Python 库 Rectools 中的 DSSMModel，但遇到了一些问题。
sparse_features_dataset = Dataset.construct(
train_data,
user_features_df=users_data,
cat_user_features=[&quot;gender&quot;, &quot;age&quot;],
item_features_df=items_data,
cat_item_features=&#39;source_id&#39;
)

model = DSSMModel(sparse_features_dataset, 
max_epochs = 10,
batch_size = 64)

#此行导致问题：
model.fit(sparse_features_dataset)

你能告诉我哪里出了问题吗？
当我使用此库中的其他模型时，一切都正常，但这个模型有问题]]></description>
      <guid>https://stackoverflow.com/questions/79194068/rectools-dataset-object-has-no-attribute-from-dataset</guid>
      <pubDate>Fri, 15 Nov 2024 21:56:55 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 错误检查失败：m == 1 || n == 1：</title>
      <link>https://stackoverflow.com/questions/79193653/xgboost-error-check-failed-m-1-n-1</link>
      <description><![CDATA[嗨，我正在尝试通过 XGBoostClassifier 运行我的数据，但遇到了以下问题。请帮忙。
!pip install xgboost
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()
y_train=encoder.fit_transform(y_train)
model=XGBClassifier(objective=&quot;binary:logistic&quot;,n_estimators=10,max_depth=3, learning_rate=.1)
model.fit(X_train,y_train)
y_pred=model.predict(X_test)
print(classification_report(y_test,y_pred))`

我尝试添加标签编码器。我得到的错误如下
XGBoostError: [12:07:18] C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling- group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\data\array_interface.h:218: 检查失败: m == 1 || n == 1: 

​]]></description>
      <guid>https://stackoverflow.com/questions/79193653/xgboost-error-check-failed-m-1-n-1</guid>
      <pubDate>Fri, 15 Nov 2024 18:59:05 GMT</pubDate>
    </item>
    <item>
      <title>尝试在 R 中使用 tensorflow 和 teras 进行图像识别时出错</title>
      <link>https://stackoverflow.com/questions/79193329/error-trying-to-do-image-recognition-using-tensorflow-and-teras-in-r</link>
      <description><![CDATA[我正在按照本教程进行操作 -
https://www.r-bloggers.com/2021/03/how-to-build-your-own-image-recognition-app-with-r-part-1/amp/
但是遇到了一个错误。
model_function &lt;- function(learning_rate = 0.001, 
dropoutrate=0.2, n_dense=1024){

k_clear_session()

model &lt;- keras_model_sequence() %&gt;%
mod_base %&gt;% 
layer_global_average_pooling_2d() %&gt;% 
layer_dense(units = n_dense) %&gt;%
layer_activation(&quot;relu&quot;) %&gt;%
layer_dropout(dropoutrate) %&gt;%
layer_dense(units=output_n,activation=&quot;softmax&quot;)

model %&gt;% compile(
loss = &quot;categorical_crossentropy&quot;,
optimizer = optimizer_adam(lr = learning_rate),
metrics = &quot;accuracy&quot;
)

return(model)

}

model &lt;- model_function()

此代码的最后一行出现以下错误 -
py_call_impl(callable, call_args$unnamed, call_args$named) 中的错误: 
ValueError：层的输入应为张量。层“xception”的输入为“&lt;Sequential name=sequential,built=False&gt;”（类型为&lt;class&#39;keras.src.models.sequential.Sequential&#39;&gt;）。
运行`reticulate::py_last_error()`了解详情。

有人知道我该如何修复这个问题吗？或者有其他教程可以推荐吗？]]></description>
      <guid>https://stackoverflow.com/questions/79193329/error-trying-to-do-image-recognition-using-tensorflow-and-teras-in-r</guid>
      <pubDate>Fri, 15 Nov 2024 17:01:55 GMT</pubDate>
    </item>
    <item>
      <title>如何从头开始创建模型以从扫描的发票中提取文本和表格数据</title>
      <link>https://stackoverflow.com/questions/79192367/how-can-i-create-a-model-from-scratch-to-extract-text-and-table-data-from-scanne</link>
      <description><![CDATA[所以我目前正在做一个项目，我们收到了 25 种不同的发票类型，全部都经过了扫描。最终目标是从发票中提取文本和表格数据，然后最终将这些数据解析为 Excel。发票类型采用不同的格式。我们如何提取表格数据 + 文本？我们可以为 25 种发票类型创建 1 个模型来执行此操作吗？还是我们需要 25 个模型。]]></description>
      <guid>https://stackoverflow.com/questions/79192367/how-can-i-create-a-model-from-scratch-to-extract-text-and-table-data-from-scanne</guid>
      <pubDate>Fri, 15 Nov 2024 12:24:08 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 提前停止轮次</title>
      <link>https://stackoverflow.com/questions/79189607/xgboost-early-stopping-rounds</link>
      <description><![CDATA[下面的代码一直在崩溃，我不知道发生了什么
import optuna
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 假设 `X` 和 `y` 是你的特征矩阵和目标数组
X_train, X_valid, y_train, y_valid = train_test_split(df_combined, y, test_size=0.2, random_state=42)

# 为 Optuna 定义目标函数
def objective(trial):
# 为超参数建议值
params = {
&quot;objective&quot;: &quot;reg:squarederror&quot;,
&quot;eval_metric&quot;: &quot;rmse&quot;,
&quot;tree_method&quot;: &quot;hist&quot;, # 使用 hist 方法
&quot;device&quot;: &quot;cuda&quot;, # 指定使用 GPU
&quot;learning_rate&quot;: trial.suggest_float(&quot;learning_rate&quot;, 0.01, 0.3, log=True),
&quot;max_depth&quot;: trial.suggest_int(&quot;max_depth&quot;, 3, 10),
&quot;min_child_weight&quot;: trial.suggest_float(&quot;min_child_weight&quot;, 1, 10),
&quot;gamma&quot;: trial.suggest_float(&quot;gamma&quot;, 0, 1),
&quot;subsample&quot;: trial.suggest_float(&quot;subsample&quot;, 0.5, 1.0),
&quot;colsample_bytree&quot;: trial.suggest_float(&quot;colsample_bytree&quot;, 0.5, 1.0),
&quot;lambda&quot;: trial.suggest_float(&quot;lambda&quot;, 1e-3, 10.0, log=True),
&quot;alpha&quot;: trial.suggest_float(&quot;alpha&quot;, 1e-3, 10.0, log=True),
&quot;n_estimators&quot;: 1000 # 在模型初始化中定义 n_estimators
}

# 初始化模型
model = xgb.XGBRegressor(**params)

# 使用早期停止回调训练模型
model.fit(
X_train,
y_train,
eval_set=[(X_valid, y_valid)],
verbose=False,
early_stopping_rounds=50 # 如果之后没有改进则停止50 轮
)

# 预测并计算验证集的 RMSE
preds = model.predict(X_valid)
rmse = mean_squared_error(y_valid, preds, squared=False)

return rmse # Optuna 将其最小化

# 设置 Optuna 研究
study = optuna.create_study(direction=&quot;minimize&quot;)

# 优化超参数
study.optimize(objective, n_trials=100, n_jobs=40) # 100 次试验，40 次并行作业

# 显示最佳试验
print(&quot;最佳试验：&quot;)
trial = study.best_trial
print(f&quot;值 (RMSE)：{trial.value}&quot;)
print(&quot; Params: &quot;)
for key, value in trial.params.items():
print(f&quot; {key}: {value}&quot;)

我得到
TypeError: XGBModel.fit() 得到一个意外的关键字参数 &#39;early_stopping_rounds&#39;

我已更新所有内容以确保我拥有所有更新的库。
提前停止轮次是正确的（我认为），但由于某种原因，它只是爆炸了。]]></description>
      <guid>https://stackoverflow.com/questions/79189607/xgboost-early-stopping-rounds</guid>
      <pubDate>Thu, 14 Nov 2024 16:14:40 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用 FastAPI 在 model.predict() 中直接使用 Pydantic 模型（BaseModel）吗？如果不行，为什么？</title>
      <link>https://stackoverflow.com/questions/71849683/can-we-use-pydantic-models-basemodel-directly-inside-model-predict-using-fas</link>
      <description><![CDATA[我正在使用带有 FastAPI 的 Pydantic 模型 (Basemodel)，并将输入转换为 dictionary，然后将其转换为 Pandas DataFrame，以便将其传递到 model.predict() 函数中进行机器学习预测，如下所示：
from fastapi import FastAPI
import uvicorn
from pydantic import BaseModel
import pandas as pd
from typing import List

class Inputs(BaseModel):
f1: float,
f2: float,
f3: str

@app.post(&#39;/predict&#39;)
def predict(features: List[Inputs]):
output = []

# 循环输入特征列表
for data in features:
result = {}

# 将数据转换为 dict()，然后转换为 DataFrame
data = data.dict()
df = pd.DataFrame([data])

# 获取预测
prediction = classifier.predict(df)[0]

# 获取概率
probability = classifier.predict_proba(df).max()

# 分配给字典 
result[&quot;prediction&quot;] = prediction
result[&quot;probability&quot;] = probability

# 将字典附加到列表（许多输出）
output.append(result)

返回输出

它运行良好，只是我不太确定它是否优化或是否是正确的方法，因为我将输入转换两次以获得预测。此外，我不确定在输入数量巨大的情况下它是否会快速地工作。对此有什么改进吗？如果有办法（甚至除了使用 Pydantic 模型之外），我可以直接工作并避免经过转换和循环。]]></description>
      <guid>https://stackoverflow.com/questions/71849683/can-we-use-pydantic-models-basemodel-directly-inside-model-predict-using-fas</guid>
      <pubDate>Tue, 12 Apr 2022 22:11:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练时我的 Keras 模型的准确率始终为 0？</title>
      <link>https://stackoverflow.com/questions/45632549/why-is-the-accuracy-for-my-keras-model-always-0-when-training</link>
      <description><![CDATA[我构建了一个简单的 Keras 网络：
import numpy as np;

from keras.models import Sequential;
from keras.layers import Dense,Activation;

data= np.genfromtxt(&quot;./kerastests/mydata.csv&quot;, delimiter=&#39;;&#39;)
x_target=data[:,29]
x_training=np.delete(data,6,axis=1)
x_training=np.delete(x_training,28,axis=1)

model=Sequential()
model.add(Dense(20,activation=&#39;relu&#39;, input_dim=x_training.shape[1]))
model.add(Dense(10,activation=&#39;relu&#39;))
model.add(Dense(1));

model.compile(optimizer=&#39;adam&#39;,loss=&#39;mean_squared_error&#39;,metrics=[&#39;accuracy&#39;])
model.fit(x_training, x_target)

如您所见，从我的源数据中，我删除了 2 列。一列是带有字符串格式日期的列（在数据集中，除此之外，我还有表示日期的列、表示月份的列和表示年份的列，因此我不需要该列），另一列是我用作模型目标的列）。
当我训练这个模型时，我得到了这个输出：
32/816 [&gt;.............................] - ETA：23s - loss：13541942.0000 - acc：0.0000e+00
800/816 [===========================&gt;.] - ETA：0s - loss：11575466.0400 - acc：0.0000e+00 
816/816 [================================] - 1s - 损失：11536905.2353 - 精度：0.0000e+00 
纪元 2/10
32/816 [&gt;.............................] - ETA：0s - 损失：6794785.0000 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5381360.4314 - 精度：0.0000e+00 
纪元 3/10
32/816 [&gt;.............................] - ETA：0s - 损失： 6235184.0000 - 精度：0.0000e+00
800/816 [============================&gt;.] - ETA：0s - 损失：5199512.8700 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5192977.4216 - 精度：0.0000e+00 
纪元 4/10
32/816 [&gt;.............................] - ETA：0s - 损失：4680165.5000 - 精度： 0.0000e+00
736/816 [===========================&gt;...] - ETA：0s - 损失：5050110.3043 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5168771.5490 - 精度：0.0000e+00 
纪元 5/10
32/816 [&gt;.............................] - ETA：0s - 损失：5932391.0000 - 精度：0.0000e+00
768/816 [============================&gt;..] - ETA：0 秒 - 损失：5198882.9167 - 精度：0.0000e+00
816/816 [==============================] - 0 秒 - 损失：5159585.9020 - 精度：0.0000e+00 
纪元 6/10
32/816 [&gt;.............................] - ETA：0 秒 - 损失：4488318.0000 - 精度：0.0000e+00
768/816 [============================&gt;..] - ETA：0s - 损失：5144843.8333 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5151492.1765 - 精度：0.0000e+00 
纪元 7/10
32/816 [&gt;.............................] - ETA：0s - 损失：6920405.0000 - 精度：0.0000e+00
800/816 [=============================&gt;.] - ETA：0s - 损失：5139358.5000 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5169839.2941 - 精度：0.0000e+00 
纪元 8/10
32/816 [&gt;.............................] - ETA：0s - 损失：3973038.7500 - 精度：0.0000e+00
672/816 [==========================&gt;......] - ETA：0s - 损失：5183285.3690 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5141417.0000 - 精度：0.0000e+00 
Epoch 9/10
32/816 [&gt;.............................] - ETA：0s - 损失：4969548.5000 - 精度：0.0000e+00
768/816 [===========================&gt;..] - ETA：0s - 损失：5126550.1667 - 精度： 0.0000e+00
816/816 [===============================] - 0s - 损失：5136524.5098 - 精度：0.0000e+00 
纪元 10/10
32/816 [&gt;.............................] - ETA：0s - 损失：6334703.5000 - 精度：0.0000e+00
768/816 [===========================&gt;..] - ETA：0s - 损失：5197778.8229 - 精度：0.0000e+00
816/816 [===============================] - 0s - 损失：5141391.2059 - 准确率：0.0000e+00 

为什么会发生这种情况？我的数据是时间序列。我知道对于时间序列，人们通常不使用 Dense 神经元，但这只是一个测试。真正让我困惑的是准确率始终为 0。而且，在其他测试中，我甚至输了：得到一个“NAN”值。
有人能帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/45632549/why-is-the-accuracy-for-my-keras-model-always-0-when-training</guid>
      <pubDate>Fri, 11 Aug 2017 10:08:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Weka 中使用 MFCC 进行音频分类？</title>
      <link>https://stackoverflow.com/questions/45224049/how-to-use-mfccs-in-weka-for-audio-classification</link>
      <description><![CDATA[我正在尝试开发一种使用 Weka 中的 MFCC 对音频进行分类的方法。我拥有的 MFCC 是用 1024 的缓冲区大小生成的，因此每个音频记录都有一系列 MFCC 系数。我想将这些系数转换为 Weka 的 ARFF 数据格式，但我不确定如何解决这个问题。
我还问了一个关于合并数据的问题，因为我觉得这可能会影响数据转换为 ARFF 格式。
我知道对于 ARFF，数据需要通过属性列出。MFCC 的每个系数应该是单独的属性还是作为单个属性的系数数组？每个数据应该代表单个 MFCC、时间窗口还是整个文件或声音？下面，我写出了我认为如果只考虑一个 MFCC 应该是什么样子，我认为这无法对整个声音进行分类。
@relation audio

@attribute mfcc1 real
@attribute mfcc2 real
@attribute mfcc3 real
@attribute mfcc4 real
@attribute mfcc5 real
@attribute mfcc6 real
@attribute mfcc7 real
@attribute mfcc8 real
@attribute mfcc9 real
@attribute mfcc10 real
@attribute mfcc11 real
@attribute mfcc12 real
@attribute mfcc13 real
@attribute class {bark, honk, talking, wind}

@data
126.347275, -9.709645, 4.2038302, -11.606304, -2.4174862, -3.703139, 12.748064, -5.297932, -1.3114156, 2.1852574, -2.1628475, -3.622149, 5.851326, bark

如能提供任何帮助，我们将不胜感激。
编辑：
我已生成一些 ARFF 文件使用 Weka 使用 openSMILE 按照此 网站中的方法，但我不确定如何使用这些数据对音频进行分类，因为每行数据都是来自同一文件的 10 毫秒音频。每行的名称属性都是“未知”，我认为这是数据将尝试分类的属性。我如何才能对整体声音（而不是 10 毫秒）进行分类并将其与其他几个整体声音进行比较？

编辑 #2：成功！
在更彻底地阅读我找到的网站后，我看到了 Accumulate 脚本以及测试和训练数据文件。accumulate 脚本将来自不同音频文件的每个 MFCC 数据集合生成的所有文件放在一个 ARFF 文件中。他们的文件由大约 200 个属性组成，其中包含 12 个 MFCC 的统计数据。虽然我无法使用 OpenSmile 检索这些统计数据，但我使用了 Python 库来执行此操作。统计数据包括最大值、最小值、峰度、范围、标准差等。我使用 Weka 中的 BayesNet 和多层感知器准确地对我的音频文件进行了分类，这两项方法都为我带来了 100% 的准确率。]]></description>
      <guid>https://stackoverflow.com/questions/45224049/how-to-use-mfccs-in-weka-for-audio-classification</guid>
      <pubDate>Thu, 20 Jul 2017 19:52:54 GMT</pubDate>
    </item>
    </channel>
</rss>