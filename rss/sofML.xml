<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 15 Jul 2024 03:19:25 GMT</lastBuildDate>
    <item>
      <title>如何制作一个自动检查工程图形答题纸并相应分配分数的系统[关闭]</title>
      <link>https://stackoverflow.com/questions/78747310/how-to-a-make-system-which-automatically-check-the-engineering-graphics-answer-s</link>
      <description><![CDATA[如何制作一个系统，自动检查工程图形答题纸并根据其正确性分配分数此类图形图像需要分配分数
尝试进行图像处理但无法做到。你能告诉我如何制作这个项目以及我应该使用哪些python库以及如何使用吗？]]></description>
      <guid>https://stackoverflow.com/questions/78747310/how-to-a-make-system-which-automatically-check-the-engineering-graphics-answer-s</guid>
      <pubDate>Sun, 14 Jul 2024 19:38:24 GMT</pubDate>
    </item>
    <item>
      <title>IndexError：目标 32 超出范围。运行时损失 = 标准（y_pred，y_train）</title>
      <link>https://stackoverflow.com/questions/78747258/indexerror-target-32-is-out-of-bounds-while-running-loss-criteriony-pred-y</link>
      <description><![CDATA[我正在运行一个简单的神经网络，其中包含一些大约 1112 行、23 个输入、2 个隐藏层和 31 个可能输出的 csv 数据。在前向训练之后，在以下代码执行过程中，我收到以下错误消息
在行 loss = criterion(y_pred, y_train)
错误：
-----------------------------------------------------------------------------
IndexError Traceback（最近一次调用最后一次）
&lt;ipython-input-64-47488b841fa2&gt; 在 &lt;cell line: 5&gt;()
8 
9 
---&gt; 10 loss = criterion(y_pred, y_train)
11 
12 #loss.append(loss.detach().numpy())

3 帧
/usr/local/lib/python3.10/dist-packages/torch/nn/ functional.py in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)
3084 如果 size_average 不为 None 或 reduce 不为 None:
3085 reduction = _Reduction.legacy_get_string(size_average, reduce)
-&gt; 3086 返回 torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
3087 
3088 

IndexError：目标 32 超出范围。

有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78747258/indexerror-target-32-is-out-of-bounds-while-running-loss-criteriony-pred-y</guid>
      <pubDate>Sun, 14 Jul 2024 19:10:09 GMT</pubDate>
    </item>
    <item>
      <title>需要有关针对医疗领域的计算机视觉问题采取哪些措施的建议[关闭]</title>
      <link>https://stackoverflow.com/questions/78747070/need-advice-on-what-steps-to-take-regarding-a-computer-vision-problem-in-the-med</link>
      <description><![CDATA[我在实验室工作，遇到了一个问题，想得到一些指导。我在实验室的角色大致是计算机视觉科学家。我的任务是将一个领域的图像转换为另一个领域的图像，而不会丢失精细的细节。我需要将此图像转换为此图像。至少在结构上。我不想使用诸如 GAN 之类的工具，因为它们往往会添加多余的细节并以对我的任务有害的方式产生幻觉。我想尽可能地保留甚至带出图像的精细细节。有人能告诉我如何做到这一点吗？
我尝试过的一种方法是使用高斯展开或高斯近似。我的想法是，我添加并处理多个高斯函数，这样当我将它们相互添加时，它会创建一个近似的内核，我可以用它来卷积图像，从而最大化某种图像相似度得分（我目前正在使用 SSIM）。这是该方法的伪代码。这里有任何有效性吗？这不是确切的方法，因为我使用 scipy optimize 来处理优化步骤。
for i in N:
for j in N:
for m in N:
g1 = produce_gaussian(i)
g2 = produce_gaussian(j)
g3 = produce_gaussian(m)

final_gaussian = g1 + g2 + g3 
convolution = convolve2d(input_image, final_gaussian)
if SSIM(convolution, target_image)
set_values(g1, g2, g3)

我还尝试了维纳反卷积（image），总的来说，结果相当不错。有人能为我提供解决这个问题的指导吗？我想知道接下来可以采取哪些好的措施。]]></description>
      <guid>https://stackoverflow.com/questions/78747070/need-advice-on-what-steps-to-take-regarding-a-computer-vision-problem-in-the-med</guid>
      <pubDate>Sun, 14 Jul 2024 17:52:46 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow/Keras `load_img` 错误：“无法导入 PIL.Image”</title>
      <link>https://stackoverflow.com/questions/78746872/tensorflow-keras-load-img-error-could-not-import-pil-image</link>
      <description><![CDATA[尽管下载了枕头模块，我仍然遇到导入错误，是的，尽管我遇到了错误，但我还是卸载了枕头。有什么办法可以修复它吗？https://i.sstatic.net/eAhcTExv.png
我希望包含所有图像的文件夹被导入，这样我就可以通过导入的图像训练数据]]></description>
      <guid>https://stackoverflow.com/questions/78746872/tensorflow-keras-load-img-error-could-not-import-pil-image</guid>
      <pubDate>Sun, 14 Jul 2024 16:20:23 GMT</pubDate>
    </item>
    <item>
      <title>无法将 (Dimension(None)、Dimension(80)) 的元素转换为张量</title>
      <link>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</link>
      <description><![CDATA[我正在尝试阅读 LibRecommender 中有关模型训练过程的教程：https://librecommender.readthedocs.io/en/latest/tutorial.html
我停在了训练模型阶段，代码如下：
model = WideDeep(
task=&quot;ranking&quot;,
data_info=data_info,
embed_size=16,
n_epochs=2,
loss_type=&quot;cross_entropy&quot;,
lr={&quot;wide&quot;: 0.05, &quot;deep&quot;: 7e-4},
batch_size=2048,
use_bn=True,
hidden_​​units=(128, 64, 32),
)

model.fit(
train_data,
neg_sampling=True, # 对训练和评估数据执行负抽样
verbose=2,
shuffle=True,
eval_data=eval_data,
metrics=[&quot;loss&quot;, &quot;roc_auc&quot;, &quot;precision&quot;, &quot;recall&quot;, &quot;ndcg&quot;],
)

我收到错误：
TypeError：调用 Flatten.call() 时遇到异常。

无法将 (Dimension(None)、Dimension(80)) 的元素转换为 Tensor。请考虑将元素转换为受支持的类型。请参阅 https://www.tensorflow.org/api_docs/python/tf/dtypes 了解受支持的 TF 数据类型。

Flatten.call() 接收的参数：
• 输入=tf.Tensor(shape=(?, 5, 16), dtype=float32)

我不知道为什么会收到此错误？我假设本教程中没有错误，我按照所示按 1:1 执行。
我在 PyCharm 环境中工作并使用 Jupyter 笔记本。]]></description>
      <guid>https://stackoverflow.com/questions/78746638/failed-to-convert-elements-of-dimensionnone-dimension80-to-tensor</guid>
      <pubDate>Sun, 14 Jul 2024 14:37:06 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow 中无需编译新模型即可增加神经网络层的大小</title>
      <link>https://stackoverflow.com/questions/78746621/increasing-the-size-of-a-neural-network-layer-without-compiling-a-new-model-in-t</link>
      <description><![CDATA[我正在训练一个窄 3 层 TensorFlow 神经网络，其层大小为 (input_size, small_number_hidden_​​units, output_size)，并使用学习到的权重作为更宽 3 层网络的初始条件的蓝图，其层大小为 (input_size, large_number_hidden_​​units, output_size)。我的目标是利用窄模型找到的解决方案，降低更宽模型的训练成本。除了隐藏单元的数量外，这两个模型都具有相同的架构。
是否可以通过使用单个模型并在需要时向其隐藏层添加单元来避免创建和编译两个模型的开销？例如，是否可以采用层大小为 (input_size, small_number_hidden_​​units, output_size) 的未经训练的网络，关闭大部分隐藏单元，以便在前向和后向传递过程中忽略它们，在该状态下训练网络以节省计算时间，然后在训练过程中的某个时间点打开所有隐藏单元并完成训练？
我曾考虑使用掩码关闭隐藏单元，如这篇文章中所述，但我不清楚这是否真的会降低计算成本。]]></description>
      <guid>https://stackoverflow.com/questions/78746621/increasing-the-size-of-a-neural-network-layer-without-compiling-a-new-model-in-t</guid>
      <pubDate>Sun, 14 Jul 2024 14:28:44 GMT</pubDate>
    </item>
    <item>
      <title>多线程 TFRecord 写入在 kaggle 笔记本上突然停止[关闭]</title>
      <link>https://stackoverflow.com/questions/78746204/multithreading-tfrecord-writing-stops-abruptly-on-kaggle-notebook</link>
      <description><![CDATA[我正在寻求有关在 Kaggle 笔记本中 TFRecord 写入的多线程方面的帮助。我正在研究 VGGFace2 数据集，旨在将图像对转换为 TFRecords，用于训练、验证和测试集，但该过程在单线程上运行速度过慢。
TFRecord 文件包含此配对图像的 protobuf 示例，以表示同一个人和不同的人。
挑战和我尝试过的方法：

单线程处理速度慢：即使是处理数据集的有限子集（每个目录 5 个图像对用于训练，每个目录 2 个图像对用于验证/测试），使用单线程也需要大量时间（可能长达 24 小时）。我已尽可能优化代码，因此我开始探索多线程以提高性能。

多线程问题：当我使用 concurrent.futures.ThreadPoolExecutor 实现多线程时，会话突然停止，没有任何错误消息。此外，所有变量都丢失，需要从头开始完全重新启动。有趣的是，使用单个目录时，多线程可以完美运行（因为我实现的多线程是同时处理不同的目录，所以即使使用多线程池执行器对象，处理单个目录也不再是多线程，而是单线程进程），但即使使用两个目录也会导致与上述相同的问题（VGGFace2 大约有 8631 个目录）。


我的问题：

潜在原因：这些多线程问题背后的原因可能是什么？这是 Kaggle 资源的内存限制吗？

替代方法：其他人是否遇到过类似的挑战？在 Kaggle 环境中，是否有其他方法可以加速 TFRecord 写入？


附加说明：

我正在使用 contextlib.ExitStack 库来打开许多写入器并同时写入。

我在 Kaggle 讨论和 Stack Overflow 上广泛搜索解决方案，但没有找到针对这种情况的具体解决方案。


您对 Kaggle 笔记本中的多线程有什么见解或经验，特别是在处理像 VGGFace2 这样的数据集时？]]></description>
      <guid>https://stackoverflow.com/questions/78746204/multithreading-tfrecord-writing-stops-abruptly-on-kaggle-notebook</guid>
      <pubDate>Sun, 14 Jul 2024 11:10:50 GMT</pubDate>
    </item>
    <item>
      <title>教导人工智能展现简单情绪以对抗孤独 [关闭]</title>
      <link>https://stackoverflow.com/questions/78745027/teaching-an-ai-to-show-simple-emotions-to-fight-loneliness</link>
      <description><![CDATA[我计划开发一种尽可能自然的计算机宠物。我认为神经网络可以很好地用于此，因为它们可以不断适应用户，并且不需要任何硬编码规则。
该程序应该记录用户的脸部，也许还会向 KI 传输一些额外的状态详细信息。
我在考虑一种 AI，它在最后选择某个状态，然后将其作为图像显示给用户。我的问题是我不知道从哪里获取
（对于监督学习）我应该从哪里获取训练数据或
（对于强化学习）我应该如何制作评估函数。
也许无监督学习也适用于这种情况。
最后，我想把整个东西喂给一个可爱的机器人，然后它只会让用户感觉到有人在那里感知你，所以除了一个有情绪反应的人工智能之外，我对其他任何东西都不感兴趣。
我在这个领域真的不太了解，所以另一个非常基本的问题：我也听说过一些关于“情绪-BICA”的事情，这可以用吗？或者首先应该如何设计一个神经、情绪网络？
在我的研究过程中，我遇到了莫夫林和其他一些人工宠物。但是，我看不出它们是如何工作的。
最后，我只想再说一遍，我只想学习一种构建对用户做出反应的人工智能的方法，而不是真正的宠物，我只是希望它比简单的算法更好。我还相信，当你让人工智能做它的事情时，它会特别强大，当你给它一些元规则时，它就会发展出复杂的行为。]]></description>
      <guid>https://stackoverflow.com/questions/78745027/teaching-an-ai-to-show-simple-emotions-to-fight-loneliness</guid>
      <pubDate>Sat, 13 Jul 2024 21:32:19 GMT</pubDate>
    </item>
    <item>
      <title>BERT 嵌入余弦相似度看起来非常随机且无用</title>
      <link>https://stackoverflow.com/questions/78744975/bert-embedding-cosine-similarities-look-very-random-and-useless</link>
      <description><![CDATA[我以为你可以使用 BERT 嵌入来确定语义相似性。我试图用这个将一些单词分组，但结果很糟糕。
例如，这是一个关于动物和水果的小例子。注意到相似度最高的是猫和香蕉吗？
import torch
from transformers import BertTokenizer, BertModel
from sklearn.metrics.pairwise import cosine_similarity

tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)
model = BertModel.from_pretrained(&#39;bert-base-uncased&#39;, output_hidden_​​states=True).eval()

def gen_embedding(word):
encoding = tokenizer(word, return_tensors=&#39;pt&#39;)
with torch.no_grad():
output = model(**encoding)

token_embeddings = output.last_hidden_​​state.squeeze()
token_embeddings = token_embeddings[1 : -1]
word_embedding = token_embeddings.mean(dim=0)
return word_embedding

words = [
&#39;cat&#39;,
&#39;seagull&#39;,
&#39;mango&#39;,
&#39;banana&#39;
]

embs = [gen_embedding(word) for word in words]

print(cosine_similarity(embs))

# array([[1. , 0.33929926, 0.7086487 , 0.79372996],
# [0.33929926, 1.0000001 , 0.29915804, 0.4000572 ],
# [0.7086487 , 0.29915804, 1. , 0.7659105 ],
# [0.79372996, 0.4000572 , 0.7659105 , 0.99999976]], dtype=float32)

我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78744975/bert-embedding-cosine-similarities-look-very-random-and-useless</guid>
      <pubDate>Sat, 13 Jul 2024 20:58:49 GMT</pubDate>
    </item>
    <item>
      <title>无法在 databricks 中运行 Pysparkling</title>
      <link>https://stackoverflow.com/questions/78744050/unable-to-run-pysparkling-in-databricks</link>
      <description><![CDATA[!pip install h2o_pysparkling_3.5
from pysparkling import H2OConf,H2OContext
hc = H2OContext.getOrCreate()

我收到以下错误
IllegalArgumentException：不支持的参数：（spark.speculation，true）

我尝试了 spark.conf.set(&quot;spark.speculation&quot;, &quot;false&quot;)，但出现了以下错误
[CANNOT_MODIFY_CONFIG] 无法修改 Spark 配置的值：
&quot;spark.speculation&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/78744050/unable-to-run-pysparkling-in-databricks</guid>
      <pubDate>Sat, 13 Jul 2024 14:02:12 GMT</pubDate>
    </item>
    <item>
      <title>BART 配备所有虚拟功能</title>
      <link>https://stackoverflow.com/questions/78731704/bart-with-all-dummy-features</link>
      <description><![CDATA[我正尝试将 BART 应用于分类问题，其中预测变量是虚拟变量以及 y 变量。我知道这是一种不常见的设置，但不幸的是这就是设置。实际上，0 和 1 值是从 -4 到 4 的分类变量中获得的，将负值设置为 0，将正值添加到 1。我还有数据的分类版本，以防它有用。
现在，我的预测变量包含大量 NA 值（即 70%），由 648x48 的 0-1 虚拟变量矩阵组成。我的 y 变量不包含缺失值，有 648 个值。
我目前正在使用 RStudio 在 R 中工作。然而，当我执行下面的代码时，结果却令人失望：
bart_machine = build_bart_machine(predictors, response_var,use_missing_data = TRUE, use_missing_data_dummies_as_covars = TRUE)
bart_machine$confusion_matrix

也就是说，我获得了一个 NULL 混淆矩阵，并且
bartMachine v1.3.4.1 用于回归

缺失数据功能开启
训练数据大小：n = 638 和 p = 96
在 8 个核心、50 棵树、250 个 burn-in 和 1000 个 post 上构建，耗时 5.8 秒。样本

事先对 y 的 sigsq 估计：0.016

老化后的平均 sigsq 估计：0.00314

样本内统计数据：
L1 = 9.91
L2 = 1.01
rmse = 0.04
Pseudo-Rsq = 0.9547
残差的 shapiro-wilk 正态性检验的 p-val：0

零均值噪声的 p-val：0.99451

现在我的问题是：

您是否认为我有太多 NA 值而无法执行 BART？

您认为我的设置至少应该产生一个混淆矩阵吗？

您认为数据的分类版本在这里可能更有帮助还是上述令人失望的结果是由于更深层次的原因吗？


编辑：我实际上已经进行了预测，但它们相当令人失望：
# 提取特征名称
feature_names &lt;- bart_machine[[&quot;training_data_features_with_missing_features&quot;]]

# 删除&quot;M_&quot;前缀
feature_names &lt;- gsub(&quot;^M_&quot;, &quot;&quot;, feature_names)

# 使用重命名的特征名称更新 bart_machine 对象
bart_machine[[&quot;training_data_features_with_missing_features&quot;]] &lt;- feature_names

# 检查 bart_machine 训练数据中的特征名称
training_data &lt;- bart_machine[[&quot;model_matrix_training_data&quot;]]
training_feature_names &lt;- colnames(training_data)

# 删除 &quot;M_&quot;列名中的前缀
training_feature_names &lt;- gsub(&quot;^M_&quot;, &quot;&quot;, training_feature_names)

# 使用重命名的列更新 bart_machine 对象
colnames(training_data) &lt;- training_feature_names
bart_machine[[&quot;model_matrix_training_data&quot;]] &lt;- training_data

# 使用相同方法在 albany2005_predictors 中插入缺失数据
imputed_data_2005 &lt;- mice(albany2005[, -1], m = 5, method = &#39;pmm&#39;, maxit = 50, seed = 500)
complete_data_2005 &lt;- complete(imputed_data_2005, 1)

# 删除 &quot;M_&quot; albany2005_predictors 中列名的前缀
colnames(complete_data_2005) &lt;- gsub(&quot;^M_&quot;, &quot;&quot;, colnames(complete_data_2005))

# 确保 albany2005_predictors 具有与训练数据相同的列，但不包括“y_remaining”
required_cols &lt;- setdiff(training_feature_names, &quot;y_remaining&quot;)
albany2005_predictors &lt;- complete_data_2005[, required_cols, drop = FALSE]

# 为 albany2005_response 中的非 NA 值创建逻辑向量
non_na_indices &lt;- !is.na(albany2005_response)

# 子集预测值和albany2005_response 使用 non_na_indices
non_na_predicted_values &lt;- predict_values[non_na_indices]
non_na_actual_values &lt;- albany2005_response[non_na_indices]

# 使用 bartMachine 模型对 2005 年数据进行预测
predicted_values &lt;- predict(bart_machine, albany2005_predictors, type = &quot;class&quot;)

# 计算 RMSE
# 将预测值转换为数字
non_na_predicted_values &lt;- as.numeric(as.character(non_na_predicted_values))

# 将实际值转换为数字
non_na_actual_values &lt;- as.numeric(as.character(non_na_actual_values))

rmse &lt;- sqrt(mean((non_na_predicted_values - non_na_actual_values)^2))

# 打印 RMSE
print(paste(&quot;RMSE: &quot;, rmse))。###非常高的 RMSE!!!
]]></description>
      <guid>https://stackoverflow.com/questions/78731704/bart-with-all-dummy-features</guid>
      <pubDate>Wed, 10 Jul 2024 16:18:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么我在 TensorFlow 中使用 model.fit() 时会得到 ValueError：无法识别的数据类型：x=[...] (类型 <class 'list'>)？</title>
      <link>https://stackoverflow.com/questions/78271090/why-do-i-get-valueerror-unrecognized-data-type-x-of-type-class-list</link>
      <description><![CDATA[我尝试运行以下代码，该代码取自 CS50 的 AI 课程：
import csv
import tensorflow as tf
from sklearn.model_selection import train_test_split

# 从文件读取数据
with open(&quot;banknotes.csv&quot;) as f:
reader = csv.reader(f)
next(reader)

data = []
for row in reader:
data.append(
{
&quot;evidence&quot;: [float(cell) for cell in row[:4]],
&quot;label&quot;: 1 if row[4] == &quot;0&quot; else 0,
}
)

#将数据分为训练组和测试组
evidence = [row[&quot;evidence&quot;] for row in data]
labels = [row[&quot;label&quot;] for row in data]
X_training, X_testing, y_training, y_testing = train_test_split(
evidence, labels, test_size=0.4
)

# 创建神经网络
model = tf.keras.models.Sequential()

# 添加一个有 8 个单元的隐藏层，使用 ReLU 激活函数
model.add(tf.keras.layers.Dense(8, input_shape=(4,),activation=&quot;relu&quot;))

# 添加一个有 1 个单元的输出层，使用 sigmoid 激活函数
model.add(tf.keras.layers.Dense(1,activation=&quot;sigmoid&quot;))

# 训练神经网络
model.compile(
optimizer=&quot;adam&quot;, loss=&quot;binary_crossentropy&quot;, metrics=[&quot;accuracy&quot;]
)
model.fit(X_training, y_training, epochs=20)

# 评估模型的表现
model.evaluate(X_testing, y_testing, verbose=2)

但是，我收到以下错误：
Traceback（最近一次调用最后一次）：
文件“C:\Users\Eric\Desktop\coding\cs50\ai\lectures\lecture5\banknotes\banknotes.py”，第 41 行，位于&lt;module&gt;
model.fit(X_training, y_training, epochs=20)
文件 &quot;C:\Users\Eric\Desktop\coding\cs50\ai\.venv\Lib\site-packages\keras\src\utils\traceback_utils.py&quot;，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件 &quot;C:\Users\Eric\Desktop\coding\cs50\ai\.venv\Lib\site-packages\keras\src\trainers\data_adapters\__init__.py&quot;，第 113 行，位于 get_data_adapter 中
引发 ValueError(f&quot;无法识别的数据类型：x={x}（类型为 {type(x)}）&quot;)
ValueError：无法识别的数据类型：x=[...]（类型为 &lt;class &#39;list&#39;&gt;)

其中“...”是训练数据。
知道哪里出错了吗？我在 Windows 计算机上使用 Python 版本 3.11.8 和 TensorFlow 版本 2.16.1。
我尝试在 Google Colab 笔记本中运行相同的代码，并且成功了：问题仅发生在我的本地机器上。这是我期望的输出：
Epoch 1/20
26/26 [==============================] - 1s 2ms/step - 损失：1.1008 - 准确度：0.5055
Epoch 2/20
26/26 [===============================] - 0s 2ms/step - 损失：0.8588 - 准确度：0.5334
Epoch 3/20
26/26 [================================] - 0s 2ms/step - 损失：0.6946 - 准确度：0.5917
Epoch 4/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.5970 - 准确度：0.6683
纪元 5/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.5265 - 准确度：0.7120
纪元 6/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.4717 - 准确度：0.7655
纪元 7/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.4258 - 准确度：0.8177
纪元 8/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.3861 - 准确度：0.8433
纪元 9/20
26/26 [================================] - 0s 2ms/步 - 损失：0.3521 - 准确度：0.8615
纪元 10/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.3226 - 准确度：0.8870
纪元 11/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.2960 - 准确度：0.9028
纪元 12/20
26/26 [================================] - 0s 2ms/步 - 损失：0.2722 - 准确度：0.9125
纪元 13/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.2506 - 准确度：0.9283
纪元 14/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.2306 - 准确度：0.9514
纪元 15/20
26/26 [================================] - 0s 3ms/步 - 损失：0.2124 - 准确度：0.9660
纪元 16/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.1961 - 准确度：0.9769
纪元 17/20
26/26 [==============================] - 0s 2ms/步 - 损失：0.1813 - 准确度：0.9781
纪元 18/20
26/26 [================================] - 0s 2ms/步 - 损失：0.1681 - 准确度：0.9793
纪元 19/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.1562 - 准确度：0.9793
Epoch 20/20
26/26 [===============================] - 0s 2ms/步 - 损失：0.1452 - 准确度：0.9830
18/18 - 0s - 损失：0.1407 - 准确度：0.9891 - 187ms/epoch - 10ms/步
[0.14066053926944733, 0.9890710115432739]
]]></description>
      <guid>https://stackoverflow.com/questions/78271090/why-do-i-get-valueerror-unrecognized-data-type-x-of-type-class-list</guid>
      <pubDate>Thu, 04 Apr 2024 00:28:01 GMT</pubDate>
    </item>
    <item>
      <title>NameError：名称“plot_confusion_matrix”未定义</title>
      <link>https://stackoverflow.com/questions/65651544/nameerror-name-plot-confusion-matrix-is-not-defined</link>
      <description><![CDATA[我正在尝试使用 VGG16 创建一个分类模型，但是在项目结束时，我在获取混淆矩阵时遇到了错误。下面给出了代码，
导入的包和模块是：
import os
import keras
import numpy as np
import tensorflow as tf
from keras.models import Model
import matplotlib.pyplot as plt
from keras.optimizers import Adam
from keras.applications import MobileNet
from sklearn.metrics import chaos_matrix
from keras.layers.core import Dense, Activation
from keras.metrics import categorical_crossentropy
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator
from keras.applications.mobilenet import preprocess_input
from tensorflow.keras.preprocessing import image_dataset_from_directory

注意：对于简短地讲我只是跳过了链接的数据集
下面定义 VGG16：
vgg16_model = keras.applications.vgg16.VGG16()
vgg16_model.summary()

现在，定义模型：
model = Sequential()
for layer in vgg16_model.layers:
model.add(layer)

for layer in model.layers:
layer.trainable = False

model.add(Dense(2,activation=&#39;softmax&#39;))

编译模型：
model.compile(Adam(lr=.0001),loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

拟合模型：
model.fit_generator(train_batches, steps_per_epoch=4, validation_data=valid_batches, validation_steps=4, epochs=10, verbose=2)

现在是混淆矩阵：
test_imgs, test_labels = next(test_batches)
plots(test_imgs, titles=test_labels)
test_labels = test_labels[:,0] 
predictions = model.predict_generator(test_batches, steps=1, verbose=0)
cm = chaos_matrix(test_labels, np.round(predictions[:,0]))

下面我遇到了一个错误，请关注下面代码，
cm_plot_labels = [&#39;diseaseAffectedEggplant&#39;,&#39;freshEggplant&#39;]
plot_confusion_matrix(cm, cm_plot_labels, title=&quot;Confusion Matrix&quot;) // 这行，我遇到了一个错误

错误如下，
-------------------------------------------------------------------------------
NameError Traceback (most recent call last)
&lt;ipython-input-28-43b96d543746&gt; in &lt;module&gt;()
1 cm_plot_labels = [&#39;diseaseAffectedEggplant&#39;,&#39;freshEggplant&#39;]
----&gt; 2 plot_confusion_matrix(cm, cm_plot_labels, title=&quot;Confusion Matrix&quot;)

NameError: 名称 &#39;plot_confusion_matrix&#39; 未定义
]]></description>
      <guid>https://stackoverflow.com/questions/65651544/nameerror-name-plot-confusion-matrix-is-not-defined</guid>
      <pubDate>Sun, 10 Jan 2021 08:53:18 GMT</pubDate>
    </item>
    <item>
      <title>什么是 x_train.reshape() 以及它的作用是什么？</title>
      <link>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</link>
      <description><![CDATA[使用 MNIST 数据集
import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist

# MNIST 数据集参数
num_classes = 10 # 总类别（0-9 位数字）
num_features = 784 # 数据特征（图像形状：28*28）

(x_train, y_train), (x_test, y_test) = mnist.load_data()

# 转换为 float32
x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)

# 将图像展平为 784 个特征（28*28）的一维向量
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])

# 将图像值从 [0, 255] 标准化为 [0, 1]
x_train, x_test = x_train / 255., x_test / 255.

在这些代码的第 15 行中，
x_train, x_test = x_train.reshape([-1, num_features]), x_test.reshape([-1, num_features])。我无法理解这些重塑在我们的数据集中到底起什么作用..?? 请解释一下。]]></description>
      <guid>https://stackoverflow.com/questions/61555486/what-is-x-train-reshape-and-what-it-does</guid>
      <pubDate>Sat, 02 May 2020 06:44:34 GMT</pubDate>
    </item>
    <item>
      <title>分类交叉熵和二元交叉熵之间的差异</title>
      <link>https://stackoverflow.com/questions/52965686/difference-between-categorical-and-binary-cross-entropy</link>
      <description><![CDATA[使用 keras，我必须训练一个模型来预测图像是属于类别 0 还是类别 1。我对 binary 和 categorical_cross_entropy 感到困惑。我已经搜索过但还是很困惑。有人提到，当我们试图预测多类时，我们只使用分类交叉熵，并且我们应该为此使用独热编码器向量。所以这意味着当我们要使用 binary_cross_entrpoy 进行训练时，我们不需要任何独热编码向量标签。有人建议将 binary_cross_entropy 的 one_hot 向量表示为 [0. 1.]（如果类别为 1）或 [1. 0.]（如果类别为 0）。
我使用独热编码器 [0 1] 或 [1 0] 和分类交叉熵。我的最后一层是
model.add(Dense(num_classes,activation=&#39;softmax&#39;))

# 编译模型
model.compile(loss=&#39;categorical_crossentropy&#39;, 
optimizer=&#39;adadelta&#39;, 
metrics=[&#39;accuracy&#39;])
]]></description>
      <guid>https://stackoverflow.com/questions/52965686/difference-between-categorical-and-binary-cross-entropy</guid>
      <pubDate>Wed, 24 Oct 2018 09:36:45 GMT</pubDate>
    </item>
    </channel>
</rss>