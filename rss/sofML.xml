<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 17 May 2024 18:19:29 GMT</lastBuildDate>
    <item>
      <title>如何使用决策树算法和bert算法对文本进行分类</title>
      <link>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-algorithm-to-classify-a-text</link>
      <description><![CDATA[我想集成并使用 BERT 和决策树两种算法进行文本分类，因此我需要该领域的指导和帮助。
如果有人有这个领域的源代码或文章，请提供给我。或者即使朋友有更好的建议将 BERT 算法与任何其他算法结合起来]]></description>
      <guid>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-algorithm-to-classify-a-text</guid>
      <pubDate>Fri, 17 May 2024 17:44:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在流模式下分割拥抱脸部数据集而不将其加载到内存中？</title>
      <link>https://stackoverflow.com/questions/78497069/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-me</link>
      <description><![CDATA[我正在使用 Hugging Face 数据集，我需要将数据集拆分为训练集和验证集。我的主要要求是数据集应该以流模式处理，因为我不想将整个数据集加载到内存中。
从数据集导入load_dataset，DatasetDict

# 从 Hugging Face 加载数据集
数据集 = load_dataset(&#39;小队&#39;, split=&#39;火车&#39;)

# 将数据集分为训练集和验证集
# 指定测试集（验证集）的分数
train_val_split = dataset.train_test_split(test_size=0.1)

# 提取训练和验证数据集
train_dataset = train_val_split[&#39;train&#39;]
val_dataset = train_val_split[&#39;测试&#39;]

# 打印数据集的大小
print(f&quot;训练集大小: {len(train_dataset)}&quot;)
print(f&quot;验证集大小: {len(val_dataset)}&quot;)

# 如果需要的话保存数据集
# train_dataset.save_to_disk(&#39;路径/到/train_dataset&#39;)
# val_dataset.save_to_disk(&#39;路径/到/val_dataset&#39;)

是否有一种方法可以在流模式下分割 Hugging Face 数据集？对我的代码的任何建议或改进将不胜感激。
参考文献：

https ://discuss.huggingface.co/t/how-to-split-a-dataset-into-train-test-and-validation/1238
https://discuss.huggingface.co/t/how-to-split-main-dataset-into-train-dev-test-as-datasetdict/1090/21
https://discuss.huggingface .co/t/possible-to-stream-and-create-new-splits/67214
https://huggingface.co/docs/datasets/v1.11.0 /splits.html
https://discuss.huggingface.co/t/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-memory /87205
]]></description>
      <guid>https://stackoverflow.com/questions/78497069/how-to-split-a-hugging-face-dataset-in-streaming-mode-without-loading-it-into-me</guid>
      <pubDate>Fri, 17 May 2024 17:18:18 GMT</pubDate>
    </item>
    <item>
      <title>学习率不更新</title>
      <link>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</link>
      <description><![CDATA[def make_prediction(x0,t0):
    输入 = torch.vstack([x0,t0])
    Layer_1 = torch.matmul(w0,输入)
    返回层_1

损失1 = nn.MSELoss()
def loss_function():
            u_t=(make_prediction(x,t+inf_s)-make_prediction(x,t))/inf_s
            u_x=(make_prediction(x+inf_s,t)-make_prediction(x,t))/inf_s
            u_xx=(make_prediction(x+inf_s,t)-2*make_prediction(x,t)+make_prediction(x-inf_s,t))/inf_s**2
            返回 (1/N_i)*(loss1(make_prediction(x0IC,t0IC), u0IC))+(1/N_b)*(loss1(make_prediction(x0BC1,t0BC1), u0BC1))
            +(1/N_b)*(loss1(make_prediction(x0BC2,t0BC2), u0BC2))+(1/N_f)*(np.pi/0.01)*(loss1(u_xx-u_t-make_prediction(x,t)*u_x , 0))

def train_step(w,b, 学习率):
    可训练变量 = [w,b]
    优化器 = torch.optim.SGD(trainable_variables, lr=learning_rate,momentum=0.9)
    调度程序 = torch.optim.lr_scheduler.ExponentialLR(优化器, gamma=0.01)
    损失 = loss_function()
    loss.backward()
    使用 torch.no_grad()：
        w -= 学习率 * w.grad
        b -= 学习率 * b.grad
        w.grad.zero_()
        b.grad.zero_()
    优化器.step()
    调度程序.step()
train_step(w,偏差,学习率)

我运行此代码（通过scheduler.ExponentialLR），但学习率没有变化。
您认为问题从何而来？
我写了完整的代码...感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</guid>
      <pubDate>Fri, 17 May 2024 16:56:52 GMT</pubDate>
    </item>
    <item>
      <title>尝试在自定义 autograd 函数内部的模型上调用 autograd.grad，在初始化时有效，但在设置权重/偏差时无效</title>
      <link>https://stackoverflow.com/questions/78496967/trying-to-call-autograd-grad-on-a-model-inside-of-a-custom-autograd-function-wo</link>
      <description><![CDATA[伯努利近似器类（nn.Module）：
  def __init__(self,hidden_​​dim):
    超级().__init__()
    self.线性1 = nn.Linear(2,hidden_​​dim)
    self.线性2 = nn.Linear（hidden_​​dim，hidden_​​dim）
    self.线性3 = nn.Linear(hidden_​​dim, hide_dim)
    self.linear4 = nn.Linear(hidden_​​dim, 1)
    self.relu = nn.ReLU()



  def 前向（自身，x）：
    out = self.relu(self.线性1(x))
    out = self.relu(self.线性2(out))
    输出 = self.relu(self.线性3(输出))
    输出 = torch.sigmoid(self.线性4(输出))
    返回

model = torch.load(&#39;bernoullimodel9.pth&#39;,map_location=device)

BernoulliSampleFunction 类（torch.autograd.Function）：
    @静态方法
    defforward(ctx, 概率, random_numbers):
        结果 = torch.zeros_like(概率)
        输入 = []
        输出 = []
        对于范围内的 i(probabilities.shape[1])：
          使用 torch.enable_grad()：
            输入 = torch.cat((概率[:, i].unsqueeze(1).double(), random_numbers[:, i].unsqueeze(1).double()), dim=1).clone().requires_grad_ （真的）
            输入.追加（输入）
            输出=模型（输入）
            输出.追加（输出）
            结果[:, i] = output.squeeze().detach()
        inputLength = torch.tensor(len(输入))
        输入.扩展（输出）
        ctx._dict = model.state_dict()
        ctx.save_for_backward(inputLength, *输入)
        返回结果

    @静态方法
    def向后（ctx，grad_output）：
      print(“grad_output:”,grad_output)
      输入长度，*输入= ctx.saved_tensors
      输出=输入[输入长度：]
      输入 = 输入[:输入长度]
      toReturn = torch.zeros_like(grad_output)
      toReturn2 = torch.zeros_like(grad_output)
      torch.set_grad_enabled(True)
      使用 torch.enable_grad()：
        模型=伯努利近似器(32)
       # model.load_state_dict(ctx._dict)
        对于 model.parameters() 中的参数：
          print(&quot;参数 1:&quot;,param)
        对于范围内的 i(toReturn.shape[1])：
          输入 = 输入[i].float()
          print(&quot;输入：&quot;,输入)
          输出=模型（输入）
          print(&quot;输出：&quot;,输出)
          delta, *g_pars = autograd.grad(输出, [输入] + list(model.parameters()), grad_output[:,i].unsqueeze(1).requires_grad_(),allow_unused=True)
          打印（“增量：”，增量）
          toReturn[:,i] = delta[:,0]
          toReturn2[:,i] = delta[:,1]
      print(&quot;返回：&quot;,返回)
      返回返回，返回2

尝试通过在 torch.enable_grad() 内部重新创建模型、为其提供相同的输入然后调用 autograd.grad 来获取相对于模型输入的梯度。仅当模型已初始化时，autograd.grad 才能正常工作，但如果我对其权重/偏差的值进行任何更改，则无论如何，梯度均为 0。我尝试了各种将训练模型的权重和偏差复制到新实例的方法； .copy_() 和 torch.no_grad(), param.data = savingParamTensor.如果我直接调用 .copy_() ，它会导致就地修改错误。对保存的输出调用 autograd.grad 也有相同的结果。
autograd.grad 仅在使用新初始化的模型时才起作用，但不可能更改权重并更新计算图。包括您是否在 .init 调用中更改它们。]]></description>
      <guid>https://stackoverflow.com/questions/78496967/trying-to-call-autograd-grad-on-a-model-inside-of-a-custom-autograd-function-wo</guid>
      <pubDate>Fri, 17 May 2024 16:52:11 GMT</pubDate>
    </item>
    <item>
      <title>选择测试数据来衡量现成分类模型的性能并提高精度</title>
      <link>https://stackoverflow.com/questions/78495909/choosing-test-data-to-measure-performance-of-an-off-the-shelf-classification-mod</link>
      <description><![CDATA[我使用分类模型（German-BERT-uncased Transformer 模型），该模型已针对二分分类任务对大约 44,000 个手动标记的社交媒体帖子进行了微调。我将该模型应用于一个新的数据集（大约 10,000 个帖子），该数据集不是原始训练数据的一部分，它为我提供了每个帖子的标签及其各自的置信水平。我现在想做两件事：

通过计算精度、召回率和 F1 分数来衡量分类器在新数据集上的性能
基于此，我想选择置信水平的截止值，以提高两个预测类别之一的精度

为了解决 1)，我想手动标记 10,000 个帖子中的 500 个。但是，我现在不确定如何选择这些职位。当然，您通常会进行随机选择以避免偏差。但很有可能，在 500 个职位中，这两个类别之一的代表性严重不足。
鉴于我有模型提供的 10,000 个帖子的标签和置信度，我想知道是否应该进行混合选择，例如：手动标记的 500 个帖子中随机选择 20%，40 % 是分类器以高于 0.5 的置信度预测类别 1 的情况，另外 40% 是分类器以高于 0.5 的置信度预测类别 2 的情况。
我已经尝试查找对此提出建议的文献，但不幸的是，除了一篇或多或少相关的论文之外，没有找到任何内容，该论文对于类似但略有不同的问题使用 20%/80% 分割 (doi.org/10.1017/潘.2022.15）。
关于2），我阅读了不同的建议，例如考虑成本错误预测的。由于我的情况没有实际成本，因此这个选项似乎不适合我。不过，我也听说您可以使用 Youden&#39;s J 来选择截止置信水平，可提高二分分类任务中某一类的精度（参见示例 8.9）。我的最终目标是最大限度地减少误报。
如果您根据自己对这两个问题中的任何一个的经验有任何建​​议，或者您对此有一些不错的读物，请告诉我:)也愿意提供更多信息，这是我在这里的第一篇文章，我是不确定需要多少详细信息。]]></description>
      <guid>https://stackoverflow.com/questions/78495909/choosing-test-data-to-measure-performance-of-an-off-the-shelf-classification-mod</guid>
      <pubDate>Fri, 17 May 2024 13:13:29 GMT</pubDate>
    </item>
    <item>
      <title>如何将机器学习模型与snort/suricata集成</title>
      <link>https://stackoverflow.com/questions/78495663/how-to-integrate-machine-learning-model-with-snort-suricata</link>
      <description><![CDATA[我创建了一个机器学习模型，现在我想将其与 snort 或 suricata 等 ids 集成，如果有人可以提供帮助或拥有与此主题相关的任何资源，我将不胜感激。
我考虑过创建 Snort 插件，但找不到太多关于如何做到这一点的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78495663/how-to-integrate-machine-learning-model-with-snort-suricata</guid>
      <pubDate>Fri, 17 May 2024 12:27:54 GMT</pubDate>
    </item>
    <item>
      <title>nlp 中的无监督情感分析</title>
      <link>https://stackoverflow.com/questions/78495476/unsupervised-sentiment-analysis-in-nlp</link>
      <description><![CDATA[如何对未标记的数据进行情感分析，我查遍了互联网（给出了聚类算法），但效果不佳。如何对未标记的数据从头开始进行情感分析，例如使用深度学习。我的意思是大公司如何使用他们的数据进行情感分析之类的任务，他们是否标记了数百万数据
我尝试过一些聚类算法，如LDA、Kmeans，但效果不佳。
怎么做。
或者也许可以向我指出学习此内容的资源
我必须从头开始，而不是使用一些预训练的模型]]></description>
      <guid>https://stackoverflow.com/questions/78495476/unsupervised-sentiment-analysis-in-nlp</guid>
      <pubDate>Fri, 17 May 2024 11:51:53 GMT</pubDate>
    </item>
    <item>
      <title>多元模型“abess”包中的变化系数</title>
      <link>https://stackoverflow.com/questions/78495306/change-coefficient-in-multivariate-model-abess-package</link>
      <description><![CDATA[我正在尝试更改训练模型的系数，如下所示
set.seed(1)
y &lt;- cumsum(rnorm(100))
x &lt;- 1:长度(y)

LR &lt;- lm(y~x)
pr &lt;- 预测(LR, cbind.data.frame(x))

绘图（x，y，t =“l”）
行（pr，col = 4）


更改一些模型系数，仅作为示例
LR$系数 &lt;- LR$系数 + 0.05
new_pr &lt;- 预测(LR, cbind.data.frame(x))
行（new_pr，col = 2，lty = 2）


现在我想对具有许多响应函数的 abess 包中的模型执行相同的操作
y &lt;- 矩阵(rnorm(200), ncol = 4) ; colnames(y) &lt;-paste0(“y”, 1:ncol(y))
x &lt;- 矩阵(rnorm(200), ncol = 4) ; colnames(x) &lt;-paste0(“x”, 1:ncol(x))
图书馆（阿贝斯）
################ 多元高斯模型 ################
abess_fit &lt;- abess(x, y, family = “mgaussian”)

但问题是，当我尝试获取模型的系数时，我得到了几组系数，在本例中有 5 个，但数量取决于数据。
abess_fit[[“beta”]]

$`0`
“ddiMatrix”类的 4 x 4 对角矩阵
   y1 y2 y3 y4
x1 0 。 。 。
x2 . 0 . 。
x3 . 。 0 .
x4。 。 。 0

$`1`
“dgCMatrix”类的 4 x 4 稀疏矩阵
           y1 y2 y3 y4
x1 。 。 。 。
x2 -0.1015219 0.02199386 0.1122985 -0.250586
x3 . 。 。 。
x4。 。 。 。

$`2`
类“dgCMatrix”的 4 x 4 稀疏矩阵
            y1 y2 y3 y4
x1 。 。 。 。
x2 -0.09682036 0.03178114 0.11441030 -0.24966314
x3 . 。 。 。
x4 -0.11844742 -0.24657644 -0.05320414 -0.02324879

$`3` .. $`4` .. $`5`

和
abess_fit[[“截距”]]

[[1]]
[1] 0.10044828 0.11732645 -0.15248544 0.07686929

[[2]]
[1] 0.1096521 0.1153325 -0.1626663 0.0995871

[[3]] .. [[4]] .. [[5]]

我不明白为什么有几组以及我需要哪组系数来更改模型。]]></description>
      <guid>https://stackoverflow.com/questions/78495306/change-coefficient-in-multivariate-model-abess-package</guid>
      <pubDate>Fri, 17 May 2024 11:21:53 GMT</pubDate>
    </item>
    <item>
      <title>在 amazon sagemaker jupyter Lab 上传大文件</title>
      <link>https://stackoverflow.com/questions/78495028/uploading-big-files-at-amazon-sagemaker-jupyter-lab</link>
      <description><![CDATA[我需要在亚马逊 sagemaker 上上传大型预训练 pytorch 模型文件，该文件可通过 Huggingface 链接获取，文件大小约为 14GB。我已在 macbook 本地下载了文件，但是当我在 sagemaker jupyter lab 上上传文件时，需要花费很多时间并且上传速度很慢。有没有任何命令可以使用 jupyter lab 终端轻松上传这个大文件？
文件链接如下：
https://huggingface.co/csuhan/ OneLLM-7B/resolve/main/consolidated.00-of-01.pth]]></description>
      <guid>https://stackoverflow.com/questions/78495028/uploading-big-files-at-amazon-sagemaker-jupyter-lab</guid>
      <pubDate>Fri, 17 May 2024 10:24:22 GMT</pubDate>
    </item>
    <item>
      <title>神经网络回归的 Numpy 实现仅学习数据集的第一个样本</title>
      <link>https://stackoverflow.com/questions/78494357/numpy-implementation-of-neural-network-regression-learns-only-first-sample-of-th</link>
      <description><![CDATA[实现一个具有 16（特征）+1（偏差）输入和 1 个输出的回归任务的神经网络，我只使用 numpy 和向量化，当我在训练集上训练它时，输入的第一个样本是只有一个人学得很好，其他人都学了一点，但一点也不好。
我在反向传播操作中做错了什么吗？
通过在训练样本中添加值为 1 的特征，在第一层中实现偏差。
我尝试了不同的学习率和网络维度，但没有任何变化。这就是我得到的输出，其中 l 是标签，y 是预测值，前 5 行是损失级数：
&lt;前&gt;&lt;代码&gt;损失：[8702.85226111]
损失：[6.46234854e-27]
损失：[1.61558713e-27]
损失：[4.03896783e-28]
损失：[0。]


左：131.042274 右：[131.042274]
左：64.0 右：[103.78313187]
l：89.429199 y：[30.54333083]
l：111.856492 y：[108.32052489]
左：69.3899 右：[57.11792288]

这是我用于此任务的 Colab 笔记本：
https://colab.research.google.com/drive/1SNEjgZQkmQW9LV8PSxE_Lx4VIQSjf1rP?usp=分享
向后传递：
def向后(l,y,输入,alpha=0.00001):
  l_out.d=o_d(l,y)
  l3.d=h_d(l_out.w,l3.z,l_out.d)
  l2.d=h_d(l3.w,l2.z,l3.d)
  l1.d=h_d(l2.w,l1.z,l2.d)
  #不确定
  l_out.dadw=da_dw(l_out.z,l3.a)
  l3.dadw=da_dw(l3.z,l2.a)
  l2.dadw=da_dw(l2.z,l1.a)
  l1.dadw=da_dw(l1.z,输入.T)

  l_out.e=w_e(l_out.dadw,l_out.d)
  l3.e=w_e(l3.dadw,l3.d)
  l2.e=w_e(l2.dadw,l2.d)
  l1.e=w_e(l1.dadw,l1.d)

  l_out.w=l_out.w-alpha*l_out.e
  l3.w=l3.w-alpha*l3.e
  l2.w=l2.w-alpha*l2.e
  l1.w=l1.w-alpha*l1.e

我正在对每个样本进行向后传递，首先计算输出层的增量，即
&lt;前&gt;&lt;代码&gt;#out 增量
def o_d(l,y):
  返回-(l-y)

然后对隐藏层执行相同的操作
#隐藏的增量
def h_d(w, z, d):
  temp=np.matmul(d.T,w)
  温度=relu_der(z)*温度
  返回温度

现在激活函数相对于每层权重的导数
def da_dw(z,a):
返回 np.outer(relu_der(z), a)

然后我通过执行计算每个权重的误差
def w_e(dadw,d):
  返回 badw * d[:, np.newaxis]

最后我更新了权重]]></description>
      <guid>https://stackoverflow.com/questions/78494357/numpy-implementation-of-neural-network-regression-learns-only-first-sample-of-th</guid>
      <pubDate>Fri, 17 May 2024 08:18:24 GMT</pubDate>
    </item>
    <item>
      <title>具有 n 维卫星图像的多类 UNet</title>
      <link>https://stackoverflow.com/questions/78491587/multiclass-unet-with-n-dimensional-satellite-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78491587/multiclass-unet-with-n-dimensional-satellite-images</guid>
      <pubDate>Thu, 16 May 2024 17:28:46 GMT</pubDate>
    </item>
    <item>
      <title>eval(predvars, data, env) 中的错误：未找到对象“适配器”</title>
      <link>https://stackoverflow.com/questions/78466280/error-in-evalpredvars-data-env-object-adapter-not-found</link>
      <description><![CDATA[我正在尝试在 tf-idf 矩阵上训练随机森林分类器，其中的列是评论中的单词。
获得一个想法：
标签...1实际上是适配器
1 0 0.01495934 0.02880089
2 0 0.00000000 0.00000000
3 0 0.00000000 0.00000000

我使用 train_data 训练了模型，其中标签为 [0] 表示负数，[1] 表示正数。
这是代码：
set.seed(123)
random_forest_model &lt;- 训练（标签...1 ~ .,
               数据 = 训练数据，
               方法=“rf”，
               trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 10),
               调整网格 = 展开.网格(mtry = 100),
               n树= 500，
               重要性=真）

我想使用经过训练的模型来预测另一个矩阵的评论是正面还是负面。
使用此代码：
# 对测试集进行预测
y_pred &lt;- 预测（random_forest_model，newdata = test_data）

问题是我收到此错误：
eval(predvars, data, env) 中的错误：未找到对象“适配器”

因为并非train_data中存在的所有单词（列）也存在于test_data中。对test_data的评价不同。
该模型的想法是在这种情况下预测评论是正面还是负面。不可能找到总是具有相同单词的矩阵。
我尝试输入 RF 模型数据框而不是矩阵，因为我读到它更好，但它没有解决问题。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78466280/error-in-evalpredvars-data-env-object-adapter-not-found</guid>
      <pubDate>Sat, 11 May 2024 22:55:59 GMT</pubDate>
    </item>
    <item>
      <title>(tflite_flutter) tflite 模型（文本分类）给出相同的结果</title>
      <link>https://stackoverflow.com/questions/76880529/tflite-flutter-tflite-model-text-classification-giving-the-same-result</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76880529/tflite-flutter-tflite-model-text-classification-giving-the-same-result</guid>
      <pubDate>Fri, 11 Aug 2023 03:35:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 PyTorch 从本地目录导入 MNIST 数据集</title>
      <link>https://stackoverflow.com/questions/64080130/how-to-import-the-mnist-dataset-from-local-directory-using-pytorch</link>
      <description><![CDATA[我正在 PyTorch 中编写一个众所周知的问题 MNIST 手写数字数据库 的代码。我下载了训练和测试数据集（从主网站），包括标记的数据集。数据集格式为t10k-images-idx3-ubyte.gz，提取后为t10k-images-idx3-ubyte。我的数据集文件夹看起来像
&lt;前&gt;&lt;代码&gt;MINST
 数据
  火车图像-idx3-ubyte.gz
  火车标签-idx1-ubyte.gz
  t10k-images-idx3-ubyte.gz
  t10k-标签-idx1-ubyte.gz

现在，我编写了一个代码来加载数据，如下所示
def load_dataset():
    data_path =“/home/MNIST/Data/”
    xy_trainPT = torchvision.datasets.ImageFolder(
        root=data_path，transform=torchvision.transforms.ToTensor()
    ）
    train_loader = torch.utils.data.DataLoader(
        xy_trainPT，batch_size = 64，num_workers = 0，shuffle = True
    ）
    返回train_loader

我的代码显示支持的扩展名是：.jpg、.jpeg、.png、.ppm、.bmp、.pgm、.tif、.tiff、.webp
如何解决这个问题，并且我还想检查我的图像是否已从数据集中加载（仅一个图形包含前 5 个图像）？]]></description>
      <guid>https://stackoverflow.com/questions/64080130/how-to-import-the-mnist-dataset-from-local-directory-using-pytorch</guid>
      <pubDate>Sat, 26 Sep 2020 16:38:11 GMT</pubDate>
    </item>
    <item>
      <title>如何根据信用记录计算信用评分</title>
      <link>https://stackoverflow.com/questions/37712731/how-to-calculate-credit-score-on-the-basis-of-credit-history</link>
      <description><![CDATA[我有一个特定人群的信用历史数据集，我需要计算每个人的信用评分。
我计划根据信用历史变量计算概率，然后尝试将该概率转换为分数。这种方法会起作用吗？或者我应该遵循什么技术或方法？]]></description>
      <guid>https://stackoverflow.com/questions/37712731/how-to-calculate-credit-score-on-the-basis-of-credit-history</guid>
      <pubDate>Wed, 08 Jun 2016 20:54:30 GMT</pubDate>
    </item>
    </channel>
</rss>