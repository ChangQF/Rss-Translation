<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 21 Mar 2024 00:58:59 GMT</lastBuildDate>
    <item>
      <title>为什么线性回归的纯 NumPy 实现的学习率优化如此无效？</title>
      <link>https://stackoverflow.com/questions/78196911/why-is-learning-rate-optimization-to-pure-numpy-implementation-of-linear-regress</link>
      <description><![CDATA[在 numpy 中创建简单的线性回归模型后，我发现改变步长/学习率并不能有效提高模型的准确性或收敛速度。请注意给出此标准模型：
&lt;代码&gt;
％％时间

x = np.arange(100)
y = 3 * x + 5
x = np.column_stack((np.ones(100), x))

w = np.zeros((100, 2))
步长=10**-4
迭代次数 = 10**5

对于范围内的 i（迭代）：
    损失 = 2 * (np.sum(w * x, axis=1) - y)
    w -= step_size * np.average(x * loss[:, None], axis=0)

打印（w[0]）

模型提供以下输出：
&lt;前&gt;&lt;代码&gt;[4.60820653 3.00590689]
CPU时间：用户5.04秒，系统：19.9毫秒，总计：5.06秒
挂壁时间：5.07 秒


更改step_size变量可以被视为超参数优化，但是当将其更改为大于10-4（例如10-3）时，模型无法收敛并爆炸：
&lt;前&gt;&lt;代码&gt;#step_size = 10**-3
[楠楠]
CPU时间：用户4.98秒，系统：38.2毫秒，总计：5.02秒
挂壁时间：5秒

这种行为在数学上是可以预料到的，但遇到这种情况却令人沮丧，并引出了一个问题：如何更有效地优化步长？
&lt;小时/&gt;
我尝试更改与梯度相关的系数（我将梯度变量标记为“损失”），而不是更改步长，因为这也会影响每个步骤的戏剧性（据我所知）给定更大或更小的损失，因此下降的梯度更陡。令人惊讶的是，将损失系数从 2 更改为 5 显着提高了性能（这正是我所做的，而不是优化步长，但我想这是一个单独的主题）。
# 将损耗系数从 2 更改为 5
[4.99998468 3.00000023]
CPU时间：用户5.03秒，系统：42.7毫秒，总计：5.07秒
挂壁时间：5.08 秒
]]></description>
      <guid>https://stackoverflow.com/questions/78196911/why-is-learning-rate-optimization-to-pure-numpy-implementation-of-linear-regress</guid>
      <pubDate>Thu, 21 Mar 2024 00:26:12 GMT</pubDate>
    </item>
    <item>
      <title>如何更改基于 Llama 2 的模型的默认嵌入向量大小？</title>
      <link>https://stackoverflow.com/questions/78196744/how-to-change-default-embedding-vector-size-of-a-llama-2-based-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78196744/how-to-change-default-embedding-vector-size-of-a-llama-2-based-model</guid>
      <pubDate>Wed, 20 Mar 2024 23:26:36 GMT</pubDate>
    </item>
    <item>
      <title>有人在打开 gitbash 时遇到问题吗？我可能弄乱了我的环境变量，然后它不允许它打开任何可以修复它的想法？</title>
      <link>https://stackoverflow.com/questions/78196727/is-anyone-had-issues-opening-gitbash-i-might-have-messed-up-my-environment-varia</link>
      <description><![CDATA[我能够打开 gitbash 及其所有文件，并且我需要它才能打开，但它已正确安装。
仍然无法打开我已经使用了任务管理器，建议使用其他一些方法来查看我是否可以更新程序，我有最新版本，我弄乱了我的环境变量，所以可能有人可以帮忙吗？
任务管理器、Winget 键命令提示符、管理员运行应用程序]]></description>
      <guid>https://stackoverflow.com/questions/78196727/is-anyone-had-issues-opening-gitbash-i-might-have-messed-up-my-environment-varia</guid>
      <pubDate>Wed, 20 Mar 2024 23:22:20 GMT</pubDate>
    </item>
    <item>
      <title>vercel：错误：上传文件的大小超过 300MB</title>
      <link>https://stackoverflow.com/questions/78196675/vercel-error-size-of-uploaded-file-exceeds-300mb</link>
      <description><![CDATA[我正在尝试部署一个使用 Deepface.analyze 函数的基本 python 应用程序。尝试在 Vercel 上部署应用程序时，出现此错误：
上传文件大小超过300MB

是因为像deepFace和tensorflow这样的大型库吗？还是因为我的代码结构？
我有一个具有以下结构的基本 python Flask 应用程序：
&lt;前&gt;&lt;代码&gt;静态
--样式.css
模板
--index.html
应用程序.py
要求.txt
]]></description>
      <guid>https://stackoverflow.com/questions/78196675/vercel-error-size-of-uploaded-file-exceeds-300mb</guid>
      <pubDate>Wed, 20 Mar 2024 23:05:34 GMT</pubDate>
    </item>
    <item>
      <title>层顺序从未被调用，因此没有定义的输入</title>
      <link>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</link>
      <description><![CDATA[我的简单脚本给了我这个错误：
从 deepface 导入 DeepFace

face_analysis = DeepFace.analyze(img_path = “face3.jpeg”, model_name = “Facenet”)
打印（面部分析）

层顺序从未被调用，因此没有定义的输入

Deepface版本：0.0.87
张量流
版本：2.16.1]]></description>
      <guid>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</guid>
      <pubDate>Wed, 20 Mar 2024 22:50:10 GMT</pubDate>
    </item>
    <item>
      <title>启动 ML 项目指南</title>
      <link>https://stackoverflow.com/questions/78196528/guide-to-starting-a-ml-project</link>
      <description><![CDATA[我正在致力于创建机器学习模型，学习如何将传入电子邮件分类到文件夹中，主要重点是模型必须自主学习，而无需了解电子邮件习惯，并且随着时间的推移，可以更好地进行分类。
有关如何启动此项目的任何提示、视频、链接、知识以及如何创建此自主分类的策略？ （我正在使用安然语料库数据集）。
在启动项目时需要帮助]]></description>
      <guid>https://stackoverflow.com/questions/78196528/guide-to-starting-a-ml-project</guid>
      <pubDate>Wed, 20 Mar 2024 22:20:07 GMT</pubDate>
    </item>
    <item>
      <title>快速文本嵌入以进行逻辑回归</title>
      <link>https://stackoverflow.com/questions/78196310/fasttext-embeddings-in-order-to-do-logistic-regression</link>
      <description><![CDATA[我想进行嵌入，然后进行逻辑回归。输出数据是这些
&lt;预&gt;&lt;代码&gt;0 [[-0.00034277988, 0.0013405628, -1.998733e-05,...
1 [[0.00075779966, -0.00025276924, 0.0009634475,...
2 [[-0.0032675266, -0.0015163509, 0.0051634307, ...
3 [[0.0006605284，-0.0040500723，0.0041460698，-...
                              ...
第4774章 [[0.0005923094, -0.00194318, 0.0015639212, 0.0...
第4775章 [[-0.002365636, 0.0023984204, -0.0004855222, -...
第4776章 [[-0.0028686645, 0.0019738101, 0.0037081288, 0...
第4777章 [[0.0024941873, -0.0019521558, -0.0019918315, ...
名称：推文，长度：4779，dtype：对象

但是为了进行回归，我需要它们为数字类型，因此我需要将每个数字放在不同的列上：[4778 行 x 768 列]
我的fasttext代码是这样的。我不知道更改 fasttext 代码是否更好，还是在准备好嵌入后进行更改
df = pd.read_csv(&#39;OGTDv1.csv&#39;)

Sentence = [word_tokenize(rev.lower()) for rev in df.Tweet.to_string(index=False)]
模型= FastText（句子，vector_size = 128，窗口= 5，min_count = 3，工人= 4，纪元= 10，种子= 42）
model.save(&#39;tokped_review.ft&#39;)

ftext = 模型.wv

def get_sentence_embeddings(句子, 模型):
    标记 = word_tokenize(sentence.lower())
    embeddings = [model.wv[token] for tokens in tokens if token in model.wv]
    返回嵌入

df_emb = df[&#39;Tweet&#39;].apply(lambda x: get_sentence_embeddings(x, model))


打印（df_emb）
df_emb.to_pickle(&#39;ToxicityFastText_Embeddings.pkl&#39;)```
]]></description>
      <guid>https://stackoverflow.com/questions/78196310/fasttext-embeddings-in-order-to-do-logistic-regression</guid>
      <pubDate>Wed, 20 Mar 2024 21:24:02 GMT</pubDate>
    </item>
    <item>
      <title>我可以将候选数据集转换为检索 topK 张量流模型的输入吗？</title>
      <link>https://stackoverflow.com/questions/78196301/can-i-turn-candidates-dataset-to-input-on-retrieval-topk-tensorflow-model</link>
      <description><![CDATA[我有一个检索张量流训练模型，并使用 tfrs.layers.factorized_top_k.BruteForce 来预测第一个 k 的附近候选者，如下实现：
index = tfrs.layers.factorized_top_k.BruteForce(final_model.query_model)

索引.index_from_dataset(
    tf.data.Dataset.zip((parsed_topK.batch(128).map(lambda x: x[&#39;id&#39;]), parsed_topK.batch(128).map(final_model.candidate_model)))
）

并获取前 5 个结果：
结果 = 索引(input_query, k=5)

我想知道是否可以将搜索数据库（在此代码中由 parsed_topK 表示）转换为模型的输入，例如：
索引(input_query, input_candidates, k=5)

在此示例中，其中input_candidates = parsed_topK
我尝试调用final_model.predict(input_query, input_candidates)，但我需要实现一个call()方法，并且我不知道这个方法需要做什么。]]></description>
      <guid>https://stackoverflow.com/questions/78196301/can-i-turn-candidates-dataset-to-input-on-retrieval-topk-tensorflow-model</guid>
      <pubDate>Wed, 20 Mar 2024 21:22:27 GMT</pubDate>
    </item>
    <item>
      <title>如何处理高基数类别变量？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78195917/how-to-handle-high-cardinality-categorial-variables</link>
      <description><![CDATA[目前，我正在开发一个异常检测项目。该项目使用客户信息，因此我有很多分类变量，例如国家/地区、州、电子邮件等。
我正在努力建立处理此类数据的正确方法，因为在模型的应用中，模型可能必须处理它从未见过的信息。
我知道 Sci-kit Learn 有一个参数来处理未知数据，但我认为这种方法不是正确的，因为此选项会给很多观测值赋予 0 值。
为了处理电子邮件变量，我考虑将电子邮件分为用户和域。]]></description>
      <guid>https://stackoverflow.com/questions/78195917/how-to-handle-high-cardinality-categorial-variables</guid>
      <pubDate>Wed, 20 Mar 2024 19:47:26 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface 模型的填充标记应该是什么？ [复制]</title>
      <link>https://stackoverflow.com/questions/78195900/what-should-be-the-padding-token-for-a-huggingface-model</link>
      <description><![CDATA[应该是 eos 代币还是 PAD 代币？我收到此错误消息：
&lt;块引用&gt;
ValueError：要求填充，但分词器没有填充
令牌。请选择一个令牌用作 pad_token
（tokenizer.pad_token = tokenizer.eos_token 例如） 或添加新的 pad
通过 tokenizer.add_special_tokens({&#39;pad_token&#39;: &#39;[PAD]&#39;}) 获取令牌。

那么我应该使用哪些令牌？]]></description>
      <guid>https://stackoverflow.com/questions/78195900/what-should-be-the-padding-token-for-a-huggingface-model</guid>
      <pubDate>Wed, 20 Mar 2024 19:43:47 GMT</pubDate>
    </item>
    <item>
      <title>机器学习实际上需要多少数学知识？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78195837/how-much-maths-is-actually-required-in-machine-learning</link>
      <description><![CDATA[我刚刚读完 12 年级，计划从事 AI/ML 职业。然而，我对从哪里开始学习以及成为一名优秀的机器学习工程师需要多少数学感到困惑。你们能帮我吗？机器学习需要多少数学知识？
我刚刚开始第 12 节课，即将开始学习 AI /ML]]></description>
      <guid>https://stackoverflow.com/questions/78195837/how-much-maths-is-actually-required-in-machine-learning</guid>
      <pubDate>Wed, 20 Mar 2024 19:27:11 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 分词器问题。 num_words 到底做什么？</title>
      <link>https://stackoverflow.com/questions/78195133/tensorflow-tokenizer-question-what-num-words-does-exactly</link>
      <description><![CDATA[执行此代码时，我得到 11937，但我不应该得到 10.000 吗？
如果我不应该，我有几个后续问题：

num_words 有什么意义？
我得到的数字 11937 代表什么？
如何限制词汇量？

MAX_WORDS_COUNT = 10000
胜利大小 = 1000
获胜跳数 = 100

tokenizer = Tokenizer(num_words=MAX_WORDS_COUNT, 过滤器=&#39;!&quot;#$%&amp;()*+,-–—./…:;&lt;=&gt;?@[\\]^_`{|}~ «»\t\n\xa0\ufeff&#39;,
                      lower=True, split=&#39; &#39;, oov_token=&#39;unknown_word&#39;, char_level=False, )

tokenizer.fit_on_texts(x_data)

items = list(tokenizer.word_index.items())
打印（长度（项目））

我期望输出为 10.000，因为我相信 num_words 限制了词汇量的大小。
如果需要，我可以提供我的 Colab 笔记本中的完整代码。]]></description>
      <guid>https://stackoverflow.com/questions/78195133/tensorflow-tokenizer-question-what-num-words-does-exactly</guid>
      <pubDate>Wed, 20 Mar 2024 17:04:50 GMT</pubDate>
    </item>
    <item>
      <title>如何从shap值中只得到重要的词？</title>
      <link>https://stackoverflow.com/questions/78194233/how-can-get-only-important-word-from-shap-value</link>
      <description><![CDATA[我只想获取文字和值，而不获取图表。
shap_values[:,:,1].abs.mean(0) 根据重要性提供“单词”。然而，代码给出了一个仅由数字组成的数组。如果您使用 shap.plots.bar(shap_values[:,:,1].abs.mean(0))，您可以看到单词。在没有图表的情况下，如何获得考虑到其重要性的“单词”？
!pip 安装数据集
从数据集导入load_dataset

数据集 = load_dataset(“imdb”)
df = 数据集[&#39;测试&#39;].to_pandas()
Short_data = [v[:500] for v in df[“text”][:20]]

从转换器导入 AutoTokenizer、AutoModelForSequenceClassification、管道
t1okenizer = AutoTokenizer.from_pretrained(“lvwerra/distilbert-imdb”)
m1odel = AutoModelForSequenceClassification.from_pretrained(“lvwerra/distilbert-imdb”)
分类器 = pipeline(&#39;文本分类&#39;, device=0,return_all_scores=True, model=m1odel,tokenizer=t1okenizer)
分类器（短数据[：10]）

导入形状
解释器 = shap.Explainer(分类器)
shap_values = 解释器(short_data[:20])
shap.plots.bar(shap_values[:,:,1].abs.mean(0))
]]></description>
      <guid>https://stackoverflow.com/questions/78194233/how-can-get-only-important-word-from-shap-value</guid>
      <pubDate>Wed, 20 Mar 2024 14:44:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 的 Google Colab Bert 实例化错误</title>
      <link>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</link>
      <description><![CDATA[我正在尝试在 Colab 上使用 Tensorflow 构建 Bert 模型。这段代码几周前就可以完美运行。现在，如果我尝试实例化模型，则会收到以下错误：
初始化 TF 2.0 模型 TFBertModel 时未使用 PyTorch 模型的某些权重：[&#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls .predictions.transform.LayerNorm.weight&#39;、&#39;cls.predictions.bias&#39;、&#39;cls.seq_relationship.bias&#39;、&#39;cls.predictions.transform.dense.bias&#39;、&#39;cls.seq_relationship.weight&#39;]
- 如果您从在其他任务或其他架构上训练的 PyTorch 模型初始化 TFBertModel（例如，从 BertForPreTraining 模型初始化 TFBertForSequenceClassification 模型），这是预期的。
- 如果您从希望完全相同的 PyTorch 模型初始化 TFBertModel（例如，从 BertForSequenceClassification 模型初始化 TFBertForSequenceClassification 模型），则不会出现这种情况。
TFBertModel 的所有权重都是从 PyTorch 模型初始化的。
如果您的任务与检查点模型训练的任务类似，您就可以使用 TFBertModel 进行预测，而无需进一步训练。
-------------------------------------------------- ------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-14-b0e769ef7​​890&gt;在&lt;细胞系：7&gt;()
      5 SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
      6 SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
----&gt; 7 SC_pooler_output = SC_bert_model(SC_input_layer, Attention_mask=SC_mask_layer)[1] # 第二个输出，che è il pooler_output
      8
      9 # 辍学层的Aggiungi

36帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py 在 type_spec_from_value(value) 中
   1002 3，“无法将 %r 转换为张量：%s” % (类型(值).__name__, e))
   1003
-&gt;第1004章
   第1005章 1005
   1006

TypeError：调用层“嵌入”时遇到异常（类型 TFBertEmbeddings）。

无法为名称构建 TypeSpec：“tf.debugging.assert_less_5/assert_less/Assert/Assert”
op：“断言”
输入：“tf.debugging.assert_less_5/assert_less/All”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_0”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_1”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_2”
输入：“占位符”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_4”
输入：“tf.debugging.assert_less_5/assert_less/y”
属性{
  键：“总结”
  价值 {
    我：3
  }
}
属性{
  键：“T”
  价值 {
    列表 {
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_INT32
      类型：DT_STRING
      类型：DT_INT32
    }
  }
}
 不支持的类型。

调用层“embeddings”接收的参数（类型 TFBertEmbeddings）：
  • input_ids=
  •position_ids=无
  • token_type_ids=
  • input_embeds=无
  •过去的键值长度=0
  • 训练=False

模型的代码是：
SC_input_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“input_ids”)
SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
SC_pooler_output = SC_bert_model（SC_input_layer，attention_mask = SC_mask_layer）[1]

# Dropout 层的Aggiungi
SC_dropout_layer = Dropout(dropout_rate)(SC_pooler_output)
SC_output_layer = 密集（6，激活=&#39;sigmoid&#39;）（SC_dropout_layer）
SC_model = 模型(输入=[SC_input_layer, SC_mask_layer], 输出=SC_output_layer)

我发现安装tensorflow 2.10.0可以工作，但是使用Google Colab时我的CUDA版本有问题，并且使用tensorflow 2.10它无法识别GPU。
该代码几周前就可以工作，有人有解决方案吗？
编辑：同样的错误出现在 Kaggle 上。]]></description>
      <guid>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</guid>
      <pubDate>Sun, 17 Mar 2024 17:03:42 GMT</pubDate>
    </item>
    <item>
      <title>部署机器学习 Flask 项目时出错</title>
      <link>https://stackoverflow.com/questions/78165242/error-while-deploying-machine-learning-flask-project</link>
      <description><![CDATA[我正在尝试使用 LSTM 构建手语识别模型。我是 Flask 新手，找不到问题所在。当我运行该文件时，它会打开相机但不会检测到该操作。此外，一旦相机打开，应用程序就会卡住。如何找到错误？
代码如下：
来自flask导入Flask，render_template，Response
导入CV2
进口泡菜
导入 pyttsx3
将 numpy 导入为 np
将 mediapipe 导入为 mp
导入线程

应用程序=烧瓶（__名称__）

从tensorflow.keras.models导入load_model
model = load_model(&#39;action.h5&#39;)

mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils

actions = np.array([&#39;你好&#39;,&#39;我是&#39;,&#39;阿凡&#39;,&#39;谢谢&#39;,&#39;我爱你&#39;,&#39;发烧&#39;,&#39;再见&#39;,&#39;上帝&#39;])

def mediapipe_detection（图像，模型）：
    图像 = cv2.cvtColor(图像, cv2.COLOR_BGR2RGB)
    image.flags.writeable = False
    结果 = model.process(图像)
    image.flags.writeable = True
    图像 = cv2.cvtColor(图像, cv2.COLOR_RGB2BGR)
    返回图像、结果

def extract_keypoints(结果):
    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)
    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)
    返回 np.concatenate([lh, rh])

def draw_styled_landmarks（图像，结果）：
    mp_drawing.draw_landmarks(图像, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                             mp_drawing.DrawingSpec(颜色=(100, 100, 100), 厚度=2, 圆半径=4),
                             mp_drawing.DrawingSpec(颜色=(100, 100, 100), 厚度=2, 圆半径=2)
                             ）
    mp_drawing.draw_landmarks(图像, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,
                             mp_drawing.DrawingSpec(颜色=(200, 200,200), 厚度=2, 圆半径=4),
                             mp_drawing.DrawingSpec(颜色=(200, 200, 200), 厚度=2, 圆半径=2)
                             ）

序列=[]
句子=[]
预测=[]
阈值 = 0.5

上限 = cv2.VideoCapture(0)

defgenerate_frames():
    sequence = [] # 初始化序列变量
    Sentence = [] # 初始化Sentence变量
    而真实：
        ret, 框架 = cap.read()
        如果不转：
            休息

        图像，结果= mediapipe_detection（框架，整体）
        draw_styled_landmarks（图像，结果）
        关键点 = extract_keypoints(结果)
        序列.append(关键点)
        序列 = 序列[-30:]

        如果长度（序列）== 30：
            res = model.predict(np.expand_dims(序列，轴=0))[0]
            预测.append(np.argmax(res))
            
            if np.unique(预测[-10:])[0] == np.argmax(res):
                如果 res[np.argmax(res)] &gt;临界点：
                    if len(句子) &gt; 0:
                        if actions[np.argmax(res)] !=句子[-1]:
                            句子.append(actions[np.argmax(res)])
                            new_word = 动作[np.argmax(res)]
                            t2s.say(new_word)
                            t2s.runAndWait()
                    别的：
                        句子.append(actions[np.argmax(res)])
                        new_word = 动作[np.argmax(res)]
                        t2s.say(new_word)
                        t2s.runAndWait()

            if len(句子) &gt; 5：
                句子 = 句子[-5:]

        ret, buffer = cv2.imencode(&#39;.jpg&#39;, 图片)
        帧 = buffer.tobytes()
        产量（b&#39;--帧\r\n&#39;
                b&#39;内容类型：image/jpeg\r\n\r\n&#39; + 帧 + b&#39;\r\n&#39;)

    cap.release()


@app.route(&#39;/&#39;)
定义索引（）：
    返回 render_template(&#39;index.html&#39;)

@app.route(&#39;/video_feed&#39;)
def video_feed():
    返回响应（generate_frames（），mimetype =&#39;multipart / x-mixed-replace；边界=框架&#39;）

如果 __name__ == “__main__”：
    t2s = pyttsx3.init()
    整体 = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)
    应用程序运行（调试=真）
  


我尝试过更改模型和修改代码，但不起作用。最初相机馈送未显示，但现在可以正常工作]]></description>
      <guid>https://stackoverflow.com/questions/78165242/error-while-deploying-machine-learning-flask-project</guid>
      <pubDate>Fri, 15 Mar 2024 07:20:28 GMT</pubDate>
    </item>
    </channel>
</rss>