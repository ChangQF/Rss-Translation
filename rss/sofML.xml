<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 30 Oct 2024 21:16:27 GMT</lastBuildDate>
    <item>
      <title>TensorFlow InvalidArgumentError：ConcatOp 中的连接维度不匹配 - 形状不匹配</title>
      <link>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79141216/tensorflow-invalidargumenterror-concatenation-dimension-mismatch-in-concatop</guid>
      <pubDate>Wed, 30 Oct 2024 13:00:13 GMT</pubDate>
    </item>
    <item>
      <title>我的项目中可以使用任何机器学习算法吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/79140771/is-there-any-machine-learning-algorithm-to-use-in-my-project</link>
      <description><![CDATA[我正在开发一个机器学习模型，根据用户在多个科目（例如能力和常识）上的测试成绩向他们推荐书籍。推荐应适应用户的表现水平，根据他们的得分是高于还是低于某些阈值来推荐不同的书籍。哪种 ML 算法最适合此目的，我需要包含哪种数据字段才能有效地训练模型？
我尝试使用 K-最近邻 (KNN) 算法训练模型，数据集包含 user_id、科目名称、科目分数和推荐书籍等字段。但是，准确度得分很低，并且模型在根据用户分数推荐相关书籍方面表现不佳。哪些算法可能效果更好，哪些其他数据字段可能有助于提高模型准确性？]]></description>
      <guid>https://stackoverflow.com/questions/79140771/is-there-any-machine-learning-algorithm-to-use-in-my-project</guid>
      <pubDate>Wed, 30 Oct 2024 10:54:06 GMT</pubDate>
    </item>
    <item>
      <title>训练 IP-Adapter plus 模型后的推理错误</title>
      <link>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</link>
      <description><![CDATA[我从 https://github.com/tencent-ailab/IP-Adapter 下载了软件包
运行命令来训练 IP-Adapter plus 模型（输入：文本 + 图像，输出：图像）：
accelerate launch --num_processes 2 --multi_gpu --mixed_precision &quot;fp16&quot; \
tutorial_train_plus.py \
--pretrained_model_name_or_path=&quot;stable-diffusion-v1-5/&quot; \
--image_encoder_path=&quot;models/image_encoder/&quot; \
--data_json_file=&quot;assets/prompt_image.json&quot; \
--data_root_path=&quot;assets/train/&quot; \
--mixed_precision=&quot;fp16&quot; \
--resolution=512 \
--train_batch_size=2 \
--dataloader_num_workers=4 \
--learning_rate=1e-04 \
--weight_decay=0.01 \
--output_dir=&quot;out_model/&quot; \
--save_steps=3

训练过程中，出现提示，但训练可以继续：
已删除共享张量 {&#39;adapter_modules.27.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_v_ip.weight&#39;, &#39;adapter_modules.31.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_k_ip.weight&#39;, &#39;adapter_modules.31.to_v_ip.weight&#39;, &#39;adapter_modules.11.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_k_ip.weight&#39;, &#39;adapter_modules.25.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_k_ip.weight&#39;, &#39;adapter_modules.19.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_k_ip.weight&#39;, &#39;adapter_modules.29.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_v_ip.weight&#39;, &#39;adapter_modules.25.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_k_ip.weight&#39;, &#39;adapter_modules.9.to_v_ip.weight&#39;, &#39;adapter_modules.9.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_v_ip.weight&#39;, &#39;adapter_modules.27.to_v_ip.weight&#39;, &#39;adapter_modules.29.to_v_ip.weight&#39;, &#39;adapter_modules.19.to_k_ip.weight&#39;, &#39;adapter_modules.11.to_v_ip.weight&#39;}。这应该没问题，但请检查重新加载时是否收到任何警告

训练完成后，转换权重以生成 ip_adapter.bin，然后使用此文件中的以下模型路径运行推理代码 ip_adapter-plus_demo.py：
base_model_path = &quot;SG161222/Realistic_Vision_V4.0_noVAE&quot;
vae_model_path = &quot;stabilityai/sd-vae-ft-mse&quot;
image_encoder_path = &quot;models/image_encoder&quot;
ip_ckpt = &quot;out_model/demo_plus_checkpoint/ip_adapter.bin&quot;

显示错误：
raise RuntimeError(&#39;Error(s) in loading state_dict for {}:\n\t{}&#39;.format(
RuntimeError: Error(s) in loading state_dict for ModuleList:
state_dict 中缺少键：&quot;1.to_k_ip.weight&quot;, &quot;1.to_v_ip.weight&quot;, &quot;3.to_k_ip.weight&quot;, &quot;3.to_v_ip.weight&quot;, &quot;5.to_k_ip.weight&quot;, &quot;5.to_v_ip.weight&quot;, &quot;7.to_k_ip.weight&quot;, &quot;7.to_v_ip.weight&quot;, &quot;9.to_k_ip.weight&quot;, &quot;9.to_v_ip.weight&quot;, “11.to_k_ip.weight”, “11.to_v_ip.weight”, “13.to_k_ip.weight”, “13.to_v_ip.weight”, “15.to_k_ip.weight”, “15.to_v_ip.weight”, “17.to_k_ip.weight”, “17.to_v_ip.weight”, “19.to_k_ip.weight”, “19.to_v_ip.weight”, “21.to_k_ip.weight”, “21.to_v_ip.weight”, “23.to_k_ip.weight”, “23.to_v_ip.weight”, &quot;25.to_k_ip.weight&quot;, &quot;25.to_v_ip.weight&quot;, &quot;27.to_k_ip.weight&quot;, &quot;27.to_v_ip.weight&quot;, &quot;29.to_k_ip.weight&quot;, &quot;29.to_v_ip.weight&quot;, &quot;31.to_k_ip.weight&quot;, &quot;31.to_v_ip.weight&quot;.

什么步骤出错导致此错误？]]></description>
      <guid>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</guid>
      <pubDate>Wed, 30 Oct 2024 07:32:22 GMT</pubDate>
    </item>
    <item>
      <title>如何计算零膨胀泊松回归和零膨胀负二项回归的平均绝对误差（MAE）？</title>
      <link>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</link>
      <description><![CDATA[我尝试使用 Python 在进行零膨胀泊松回归和零膨胀负二项回归时计算平均绝对误差 (MAE)。
我将数据分为训练数据和测试数据。我使用下面的代码，但它不起作用：
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
import statsmodels.formula.api as smf
import tensorflow as tf
df = pd.read_excel(&#39;....&#39;, sheet_name=&#39;Sheet1&#39;)
print(df.head())
X = df[[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]
y = df[&#39;g&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from statsmodels.discrete.count_model import ZeroInflatedPoisson
y_zip = y_train.values

y_zip_test = y_test.values

X_count = X_train.values # 计数部分的预测器
X_zero = X_train.values # 零膨胀部分的预测器

X_count_test = X_test.values
X_zero_test = X_test.values

# 为截距添加一个常数
X_count = sm.add_constant(X_count)
X_zero = sm.add_constant(X_zero)

# 拟合 ZIP 模型
zip_model = ZeroInflatedPoisson(endog=y_zip, exog=X_count, exog_infl=X_zero, indication=&#39;logit&#39;)
zip_model_fit = zip_model.fit()
print(zip_model_fit.summary())

# 进行预测
y_pred = zip_model_fit.predict(X_count_test)

# 计算 MAE
mae = np.mean(np.abs(y_zip_test - y_pred))
print(f&#39;平均绝对误差：{mae}&#39;)

结果如下
-------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Cell In[3], line 33
29 print(zip_model_fit.summary())
32 # 进行预测
---&gt; 33 y_pred = zip_model_fit.predict(X_count_test)
35 # 计算 MAE 测试
36 mae = np.mean(np.abs(y_zip_test - y_pred))

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\base\model.py:1174，位于 Results.predict(self, exog, transform, *args, **kwargs)
1127 &quot;&quot;&quot;
1128 调用 self.model.predict 并以 self.params 作为第一个参数。
1129 
(...)
1169 返回预测。
1170 &quot;&quot;&quot;
1171 exog, exog_index = self._transform_predict_exog(exog,
1172 transform=transform)
-&gt; 1174 predict_results = self.model.predict(self.params, exog, *args,
1175 **kwargs)
1177 如果 exog_index 不为 None 且不 hasattr(predict_results,
1178 &#39;predicted_values&#39;):
1179 如果 predict_results.ndim == 1:

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\discrete\count_model.py:453，位于 GenericZeroInflated.predict(self, params, exog, exog_infl, Exposure, Offset, which, y_values)
449 params_main = params[self.k_inflate:]
451 prob_main = 1 - self.model_infl.predict(params_infl, exog_infl)
--&gt; 453 lin_pred = np.dot(exog, params_main[:self.exog.shape[1]]) + Exposure + Offset
455 # 重构：这很不靠谱，
456 # model_main 中应该有一个合适的预测方法
457 # 这只是 prob(y=0 | model_main)
458 tmp_exog = self.model_main.exog

ValueError：形状 (21,6) 和 (7,) 未对齐：6 (dim 1) != 7 (dim 0)

如何解决此错误？]]></description>
      <guid>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</guid>
      <pubDate>Wed, 30 Oct 2024 07:04:19 GMT</pubDate>
    </item>
    <item>
      <title>Kong AI 代理插件：在 Kong AI 网关上配置自托管 LLM 的正确参数</title>
      <link>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</guid>
      <pubDate>Wed, 30 Oct 2024 03:54:46 GMT</pubDate>
    </item>
    <item>
      <title>在这个简单的数据集中，模型性能滞后不到 50%</title>
      <link>https://stackoverflow.com/questions/78812358/model-performance-lagging-under-50-in-this-simple-dataset</link>
      <description><![CDATA[我正在按照此教程学习 keras
手动生成的数据集：

在临床试验中，对 13 至 100 岁的个体进行了实验性药物测试
该试验有 2100 名参与者。其中一半年龄在 65 岁以下 &amp;其余患者年龄在 65 岁或以上。
约 95% 的 65 岁或以上患者出现副作用。
约 95% 的 65 岁以下患者没有出现副作用。

for i in range (50):
# 约 5% 的年轻患者出现副作用
random_younger = randint(13,64)
train_samples.append(random_younger)
train_labels.append(1)

# 约 5% 的老年患者没有出现副作用
random_older = randint(65,100)
train_samples.append(random_older)
train_labels.append(0)

for i in range(1000):
# 约 95% 的年轻患者没有出现副作用
random_younger = randint(13,64)
train_samples.append(random_younger)
train_labels.append(0)

# 约 95% 的老年患者确实经历了副作用
random_older = randint(65,100)
train_samples.append(random_older)
train_labels.append(1)

然后使用 MinMaxScaler 缩放样本
然后使用一个简单的顺序模型：
model = Sequential([
Dense(units=16, input_shape=(1,),activation=&#39;relu&#39;),
Dense(units=32,activation=&#39;relu&#39;),
Dense(units=2,activation=&#39;softmax&#39;)
])

model.compile( 
optimizer=Adam(learning_rate=0.005), 
loss=&#39;sparse_categorical_crossentropy&#39;, 
metrics=[&#39;accuracy&#39;]
)

model.fit(
x=scaled_train_samples,
y=train_labels,
batch_size=10,
epochs=30, 
shuffle=True, 
verbose=2
)

但是，准确率徘徊在 50% 左右，损失在 70% 左右。我尝试在我的 PC 和Google colab。
Epoch 1/30
210/210 - 2s - 损失：0.7457 - 准确度：0.5029 - 2s/epoch - 7ms/step
Epoch 2/30
210/210 - 0s - 损失：0.7254 - 准确度：0.4957 - 413ms/epoch - 2ms/step
Epoch 3/30
210/210 - 0s - 损失：0.7142 - 准确度：0.5048 - 353ms/epoch - 2ms/step
Epoch 4/30
210/210 - 0s - 损失：0.6964 - 准确度：0.4914 - 386ms/epoch - 2ms/step
Epoch 5/30
210/210 - 0s - 损失：0.6971 - 准确度：0.5090 - 371ms/epoch - 2ms/step
Epoch 6/30
210/210 - 0s - 损失：0.6969 - 准确度：0.4938 - 351ms/epoch - 2ms/step
Epoch 7/30
210/210 - 0s - 损失：0.6958 - 准确度：0.4929 - 385ms/epoch - 2ms/step
...
...
Epoch 24/30
210/210 - 0s - 损失：0.6936 - 准确度：0.5000 - 367ms/epoch - 2ms/step
Epoch 25/30
210/210 - 0s - 损失：0.6935 - 准确度： 0.5010 - 367ms/epoch - 2ms/step
Epoch 26/30
210/210 - 0s - 损失：0.6940 - 准确度：0.4962 - 354ms/epoch - 2ms/step
Epoch 27/30
210/210 - 0s - 损失：0.6936 - 准确度：0.4819 - 472ms/epoch - 2ms/step
Epoch 28/30
210/210 - 0s - 损失：0.6937 - 准确度：0.4943 - 388ms/epoch - 2ms/step
Epoch 29/30
210/210 - 0s - 损失：0.6938 - 准确度：0.4905 - 406ms/epoch - 2ms/step
Epoch 30/30
210/210 - 0s - 损失：0.6935 - 准确率：0.4990 - 389ms/epoch - 2ms/step

我只是按照教程操作，但不明白我哪里犯了错误。
手动生成的简单数据集上的简单顺序模型。
准确率有望提高，但滞后约 50%。]]></description>
      <guid>https://stackoverflow.com/questions/78812358/model-performance-lagging-under-50-in-this-simple-dataset</guid>
      <pubDate>Tue, 30 Jul 2024 14:37:43 GMT</pubDate>
    </item>
    <item>
      <title>如何将 FITS 文件转换为 Numpy 数组</title>
      <link>https://stackoverflow.com/questions/70578067/how-to-convert-a-fits-file-to-a-numpy-array</link>
      <description><![CDATA[我正在尝试训练一个 AI 算法来确定星系的光度红移，为此我有一个包含训练数据的 FITS 文件。我需要将此 FITS 文件转换为可在 Python 中轻松操作的格式，特别是 numpy 数组。我已经尝试使用 astropy 并按照以下 youtube 视频操作：
https://www.youtube.com/watch?v=goH9yXu4jWw
但是，当我尝试转换文件然后检查数据类型时，它仍然是一个 FITS 文件而不是 numpy 数组。如果有人能帮忙，我将不胜感激！
import astropy.io
from astropy.io import fits

truth_north = fits.open(&#39;dr9_pz_truth_north.fits&#39;)

data = truth_north[1].data 


当我打印数据类型时，它会给出 astropy.io.fits.fitsrec.FITS_rec
我被告知 FITS_rec 类的行为就像一个 numpy 数组，但是我必须将文件转换为一个 numpy 数组。
注意：我已经在 Physics Stack Exchange 上发布了这个问题，但是我的问题并没有得到真正的回答。
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/70578067/how-to-convert-a-fits-file-to-a-numpy-array</guid>
      <pubDate>Tue, 04 Jan 2022 11:26:32 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：无法在 <module '__main__' (built-in)> 上获取属性 'video_dataset'</title>
      <link>https://stackoverflow.com/questions/68858858/attributeerror-cant-get-attribute-video-dataset-on-module-main-built</link>
      <description><![CDATA[我有一个已预处理的数据集，但此错误持续发生。
我尝试了来自多个社区的 if__name___==&#39;ma​​in_&#39;: 方法，但如果使用不当，就会不断出现错误。
回溯（最近一次调用最后一次）：
文件“&lt;string&gt;&gt;”，第 1 行，位于 &lt;module&gt;
文件“D:\anaconda\envs\mj\lib\multiprocessing\spawn.py”，第 116 行，位于 spawn_main 中
exitcode = _main(fd, parent_sentinel)
文件“D:\anaconda\envs\mj\lib\multiprocessing\spawn.py”，第 126 行，位于 _main 中
self = reduction.pickle.load(from_parent)
AttributeError：无法在 &lt;module &#39;__main__&#39; (built-in)&gt; 上获取属性“video_dataset”

定义方式如下。
class video_dataset(Dataset):
def __init__(self,frame_list,sequence_length = 16,transform = None):
self.frame_list = frame_list
self.transform = transform
self.sequence_length = serial_length
def __len__(self):
return len(self.frame_list)
def __getitem__(self,idx):
label,path = self.frame_list[idx]
img = cv2.imread(path)
seq_img = list()
for i in range(16):
img1 = img[:,128*i:128*(i+1),:]
if(self.transform):
img1 = self.transform(img1)
seq_img.append(img1)
seq_image = torch.stack(seq_img)
seq_image = seq_image.reshape(3,16,im_size,im_size)
return seq_image,decoder[label]

import torchvision
import torch
from torch import nn
import torch.nn. functional as F
import torchvision.models as models
import torch.optim as optim
import copy
import os
from tqdm.autonotebook import tqdm
import matplotlib.pyplot as plt
from torch.utils.data import Dataset
from torchvision import transforms
from torch.utils.data import DataLoader
import numpy as np
from torch.utils.data.sampler import SubsetRandomSampler
import cv2
import sys
import import_ipynb

这是最终错误发生的位置。
from torch.autograd import Variable
iteration = 0
acc_all = list()
loss_all = list()

for epoch in range(num_epochs):
print(&#39;&#39;)
print(f&quot;--- Epoch {epoch} ---&quot;)
phase1 = dataloaders.keys()
for phase in phase1:
print(&#39;&#39;)
print(f&quot;--- Phase {phase} ---&quot;)
epoch_metrics = {&quot;loss&quot;: [], &quot;acc&quot;: []}
for batch_i, (X, y) in enumerate(dataloaders[phase]):
#iteration = iteration+1
image_sequences = Variable(X.to(device), require_grad=True)
labels = Variable(y.to(device), require_grad=False)
optimizer.zero_grad()
#model.lstm.reset_hidden_​​state()
predictions = model(image_sequences)
loss = cls_criterion(predictions, labels)
acc = 100 * (predictions.detach().argmax(1) == labels).cpu().numpy().mean()
loss.backward()
optimizer.step()
epoch_metrics[&quot;loss&quot;].append(loss.item())
epoch_metrics[&quot;acc&quot;].append(acc)
if(phase==&#39;train&#39;):
lr,mom = onecyc.calc()
update_lr(optimizer, lr)
update_mom(optimizer, mom)
batches_done = epoch * len(dataloaders[phase]) + batch_i
batches_left = num_epochs * len(dataloaders[phase]) - batches_done
sys.stdout.write(
“\r[Epoch %d/%d] [Batch %d/%d] [Loss：%f (%f)，Acc：%.2f%% (%.2f%%)]”
% (
epoch,
num_epochs,
batch_i,
len(dataloaders[phase]),
loss.item(),
np.mean(epoch_metrics[&quot;loss&quot;]),
acc,
np.mean(epoch_metrics[&quot;acc&quot;]),
)
)

# 清空缓存
if torch.cuda.is_available():
torch.cuda.empty_cache()

print(&#39;&#39;)
print(&#39;{} , acc: {}&#39;.format(phase,np.mean(epoch_metrics[&quot;acc&quot;])))
torch.save(model.state_dict(),&#39;weights_crime/c3d_{}.h5&#39;.format(epoch))
if(phase==&#39;train&#39;):
acc_all.append(np.mean(epoch_metrics[&quot;acc&quot;]))
loss_all.append(np.mean(epoch_metrics[&quot;loss&quot;]))

原始代码在这里
https://github.com/sanchit2843/Videoclassification/blob/master/train.ipynb]]></description>
      <guid>https://stackoverflow.com/questions/68858858/attributeerror-cant-get-attribute-video-dataset-on-module-main-built</guid>
      <pubDate>Fri, 20 Aug 2021 08:03:11 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 中使用 NSL-KDD 数据集进行超参数优化以提高分类准确率</title>
      <link>https://stackoverflow.com/questions/61648867/hyperparameter-optimization-for-improving-classification-accuracy-using-nsl-kdd</link>
      <description><![CDATA[我正在研究 NSL-KDD 数据集，我的任务是使用 scikit-learn 提高分类算法的准确性。具体来说，我感兴趣的是实现超过 80% 的准确率。
我已经从 scikit-learn 中实现了各种分类算法，例如 K-最近邻 (KNN) 分类器，但我目前正在努力实现所需的准确率。
我怀疑超参数优化可能是提高模型性能的关键。但是，我不确定最有效的超参数调整方法以及这些超参数的最佳值。
我已经查看了 scikit-learn 文档并探索了一些基本技术，例如网格搜索，但我正在寻求更多关于应该关注哪些超参数以及如何针对 NSL-KDD 数据集对其进行最佳优化的指导。
我将不胜感激任何与 scikit-learn 中分类算法的超参数优化相关的见解、建议或代码示例。具体来说，我正在寻找有关最重要的超参数调整方法的建议以及可能产生超过 80% 准确度得分的任何特定值或范围。]]></description>
      <guid>https://stackoverflow.com/questions/61648867/hyperparameter-optimization-for-improving-classification-accuracy-using-nsl-kdd</guid>
      <pubDate>Thu, 07 May 2020 02:33:01 GMT</pubDate>
    </item>
    <item>
      <title>关于使用 R 进行 KNN 的 k 倍交叉验证的问题</title>
      <link>https://stackoverflow.com/questions/55328424/question-regarding-k-fold-cross-validation-for-knn-using-r</link>
      <description><![CDATA[我正在尝试对几个 k 值进行 5 倍交叉验证。我使用了 ISLR 包中的 OJ 数据集。
到目前为止我的代码如下，
library(ISLR)
library(class)
ks=c(1:5)
err.rate.test &lt;- numeric(length = 5)
folds &lt;- cut(seq(1,nrow(OJ)),breaks=5,labels=FALSE)

for (j in seq(along = ks)) {
set.seed(123)
cv.knn &lt;- sapply(1:5, FUN = function(i) {
testID &lt;- which(folds == i, arr.ind = TRUE)
test.X &lt;- OJ[testID, 3]
test.Y &lt;- OJ[testID, 1]
train.X &lt;- OJ[-testID, 3]
train.Y &lt;- OJ[-testID, 1]
knn.test &lt;- knn(data.frame(train.X), data.frame(test.X), train.Y, k = ks[j])
cv.test.est &lt;- mean(knn.test != test.Y)
return(cv.test.est)
})
err.rate.test[j] &lt;- mean(cv.knn)

}

err.rate.test
[1] 0.3757009 0.3757009 0.3757009 0.3757009 0.3757009

代码没有给出任何错误。但出于某种原因，我对每个 k 值的测试错误率都相同。这对我来说似乎很奇怪。所以我认为我的代码有问题。
有人能帮我解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/55328424/question-regarding-k-fold-cross-validation-for-knn-using-r</guid>
      <pubDate>Sun, 24 Mar 2019 20:48:12 GMT</pubDate>
    </item>
    <item>
      <title>如何为 k-NN 找到最佳的 k 值？</title>
      <link>https://stackoverflow.com/questions/46599534/how-to-find-the-best-value-of-k-for-the-k-nn</link>
      <description><![CDATA[我有 4 个不同的数据集，每个数据集包含属于以下两个类别之一的二维样本：1 或 2。每个样本的类别标签（1 或 2）位于最后一列。第一列和第二列包含代表样本的二维点的坐标。我的任务是：
对于 k-NN，找到 k 的最佳值，并使用 scikit-learn 将其与 1-NN 的值进行比较。
我是机器学习和 Python 的新手。请告诉我如何找到最佳 k，以及我们必须根据哪种度量来选择最佳 k。]]></description>
      <guid>https://stackoverflow.com/questions/46599534/how-to-find-the-best-value-of-k-for-the-k-nn</guid>
      <pubDate>Fri, 06 Oct 2017 06:26:22 GMT</pubDate>
    </item>
    <item>
      <title>Matlab 交叉验证和 K-NN</title>
      <link>https://stackoverflow.com/questions/35560228/matlab-cross-validation-and-k-nn</link>
      <description><![CDATA[我正在尝试在 Matlab 中构建一个带有交叉验证的 knn 分类器。由于我的 MATLAB 版本，我使用了 knnclassify() 来构建分类器 (classKNN = knnclassify (sample_test, sample_training, training_label))。
我无法使用 crossval()。]]></description>
      <guid>https://stackoverflow.com/questions/35560228/matlab-cross-validation-and-k-nn</guid>
      <pubDate>Mon, 22 Feb 2016 17:38:11 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证的 KNN 分类器</title>
      <link>https://stackoverflow.com/questions/23174032/knn-classifier-using-cross-validation</link>
      <description><![CDATA[我正在尝试使用交叉验证方法实现 KNN 分类器，其中我有某个角色的不同图像用于训练（例如 5 张图像），另外两张用于测试。现在我明白了交叉验证的原理，只需在训练时选择误差值最小的 K，然后将其与测试数据一起使用，以查看结果的准确性。
如何在 matlab 中训练图像以获取 K 值？我是否应该比较它们并尝试找出不匹配项？！]]></description>
      <guid>https://stackoverflow.com/questions/23174032/knn-classifier-using-cross-validation</guid>
      <pubDate>Sat, 19 Apr 2014 18:46:58 GMT</pubDate>
    </item>
    <item>
      <title>k-最近邻算法</title>
      <link>https://stackoverflow.com/questions/15566423/k-nearest-neighbour-algorithm</link>
      <description><![CDATA[我正在我的智能设备上实施 k-Nearest Neighbour 算法，以便从识别数据中识别人类活动。我将解释如何实施它。你们能否建议我改进我所采取的步骤并回答我在此过程中可能提出的任何问题？
这些是步骤：

我下载了一个标记数据集，它由加速度计的三轴加速度以及描述活动的标签组成。我将在此数据集中选择一些我希望识别的活动数据（在我的情况下是行走、坐着、站立）。
然后，我将从每个加速度计数据窗口（即数据集中包含 128 个加速度计数据读数的每个单个记录）中提取特征（在我的情况下是加速度幅度的平均值、最小值、最大值、标准偏差），并将这些特征与窗口标签一起以 JSON 格式存储在设备上的文本文件中（作为一个记录）。因此，训练数据集中的一个记录/样本将包括：平均值、最小值、最大值、标准偏差和一个标签
在分类步骤中，从收集的数据中，我还将有一个加速度计数据窗口，从中提取上述 4 个特征。因此，我需要将收集数据的 4 个特征与训练数据中的每个样本进行比较。由于一条记录包含 4 个特征，我该如何找到它们之间的相似性？

作为第 (3) 点问题的解决方案，我考虑对每个特征采用 k-最近邻，计算它们之间的差异，然后从每个特征中选出大多数。您觉得如何？您能提出任何优化建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/15566423/k-nearest-neighbour-algorithm</guid>
      <pubDate>Fri, 22 Mar 2013 09:06:25 GMT</pubDate>
    </item>
    <item>
      <title>k近邻算法中k的值</title>
      <link>https://stackoverflow.com/questions/11568897/value-of-k-in-k-nearest-neighbor-algorithm</link>
      <description><![CDATA[我有 7 个需要分类的类别，并且有 10 个特征。在这种情况下，我需要使用 k 的最优值吗？或者我必须对 1 到 10 之间的 k 值（大约 10）运行 KNN，然后借助算法本身确定最佳值？]]></description>
      <guid>https://stackoverflow.com/questions/11568897/value-of-k-in-k-nearest-neighbor-algorithm</guid>
      <pubDate>Thu, 19 Jul 2012 20:36:46 GMT</pubDate>
    </item>
    </channel>
</rss>