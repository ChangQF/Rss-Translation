<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 08 Mar 2024 03:13:52 GMT</lastBuildDate>
    <item>
      <title>siann的解决方案有一个问题： ValueError: Variable <tf.Variable 'u/bias:0' shape=(1,) dtype=float64> has `None` forgradient</title>
      <link>https://stackoverflow.com/questions/78125337/there-is-a-problem-with-scianns-solution-valueerror-variable-tf-variable-u</link>
      <description><![CDATA[尊敬的社区：我使用scinn求解偏微分方程时出现问题，结果显示：ValueError: Variable 对于渐变有 None 。请确保您的所有操作都定义了梯度（即可微分）。常见的无梯度操作：K.argmax、K.round、K.eval。
导入数学
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 siann 导入为 sn
从 siann.utils.math 导入 diff、sign、sin、cos、tan、exp、sqrt、pow


亩=0.20
罗 = 1000
xE = 21*1000000000
G = xE/(2*(1 + mu))
cp = math.sqrt(xE*(1 - mu)/(rho*(1 + mu)*(1 - 2*mu)))
r0 = 2.5
xdb = 100/1000
xdp = 2.5*100/1000
ρ0 = 1000
xD = 4000
SB = 4000/1000
r0 = 3.0
b = 2.0
阿尔法 = 2000

# 计算A0
定义 A0():
    term1 = xdb/(8*sb)*rho0*xD**2
    项 2 = (xdp/xdb)**2.2
    返回第 1 项/第 2 项

# 待解变量
r = sn.Variable(&#39;r&#39;, dtype=&#39;float64&#39;)
z = sn.Variable(&#39;z&#39;, dtype=&#39;float64&#39;)
t = sn.Variable(&#39;t&#39;, dtype=&#39;float64&#39;)
u = sn.Functional(&#39;u&#39;, [r, z, t], 4*[40], &#39;tanh&#39;)

# 偏微分方程
PDE1= diff(u,r,阶=2)+1/r*diff(u,r)+diff(u,z,阶=2)-1/cp*diff(u,t,阶=2)


＃边界条件
公差=0.0000001
BC1= (1-符号(t-TOL))*(1-符号(r-r0-TOL))*(diff(u,z))
BC2=(1+符号(z-TOL))*(1-符号(z-b-TOL))*(1-符号(r-r0-TOL))*(xE/(1+mu)*(mu/( 1-2*mu)*(diff(u,r,阶=2)+diff(u,r)/r+diff(u,z,阶=2))+diff(u,r,阶=2) )-A0()*exp(-1*alpha*t))

# 训练和验证模型
m = sn.SciModel([r,z,t], [PDE1, BC1,BC2])
r_data,z_data,t_data = np.meshgrid(
    np.linspace(r0, 10, 40),
    np.linspace(0, 5, 40),
    np.linspace(0, 0.001, 100)
）
 
# 这一步出错了
h = m.train([r_data,z_data,t_data], 3*[&#39;零&#39;],learning_rate=0.002, epochs=1000, verbose=0)

r_test,z_test ,t_test = np.meshgrid(
    np.linspace(0, 10, 40),
    np.linspace(0, 5, 40),
    np.linspace(0, 0.001, 80)
）
u_pred = u1.eval(m, [r_test,z_test ,t_test])

图 = plt.figure(figsize=(3, 4))
plt.pcolor(r_test, z_test, u_pred, cmap=&#39;地震&#39;)
plt.xlabel(&#39;r&#39;)
plt.ylabel(&#39;z&#39;)
plt.colorbar()

我试图解决它，然后在 h = m.train(...) 步骤出现 ValueError：Variable  ;对于渐变有 None 。请确保您的所有操作都定义了梯度（即可微分）。常见没有梯度的ops：K.argmax、K.round、K.eval.，导致无法求解]]></description>
      <guid>https://stackoverflow.com/questions/78125337/there-is-a-problem-with-scianns-solution-valueerror-variable-tf-variable-u</guid>
      <pubDate>Fri, 08 Mar 2024 03:00:25 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 Mbed 编译过程中的问题？（深度明智_conv.cc）</title>
      <link>https://stackoverflow.com/questions/78125296/how-can-i-solve-the-problem-during-mbed-compiledepthwise-conv-cc</link>
      <description><![CDATA[我正在使用tinyML 书学习机器学习。
我正在尝试 Mbed 编译，但它不起作用。
问题情况如下：
本书提出了以下流程。
make -f tensorflow/lite/micro/tools/make/Makefile \
TARGET=mbed TAGS=“cmsis-nn disco_f746ng”生成_微_语音_mbed_项目

更改目录。
cd tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed

配置 Mbed 项目根目录。
mbed 配置根目录。

MBed 部署
mbed 部署

修改 Mbed 配置文件以使用 C++11。
python3 -c &#39;导入文件输入，glob;
对于 glob.glob(“mbed-os/tools/profiles/*.json”) 中的文件名：
    对于 fileinput.input(filename, inplace=True) 中的行：
        print(line.replace(&quot;\&quot;-std=gnu++98\&quot;&quot;,&quot;\&quot;-std=c++11\&quot;, \&quot;-fpermissive\&quot;&quot;; ))&#39;


并编译
mbed 编译 -m DISCO_F746NG -t GCC_ARM

但是，在部署过程中遇到了一些问题。在部署过程中，出现了问题。在寻找解决方案时，我发现了修改 make 命令的建议，如下所示。
make -f tensorflow/lite/micro/tools/make/Makefile \
TARGET=mbed TAGS=“CMSIS-NN disco_f746ng”生成_微_语音_mbed_项目

修改后，我按照同样的方式进行了编译过程，但遇到了以下错误。
编译[82.7%]：深度明智_conv.cc
[错误] heightwise_conv.cc@178,9：从“int”到“const cmsis_nn_dims*”的无效转换[-fpermissive]
[错误] heightwise_conv.cc@178,22：从“int”到“const cmsis_nn_dims*”的无效转换[-fpermissive]
[错误] heightwise_conv.cc@178,49：函数“int32_t arm_depthwise_conv_s8_opt_get_buffer_size(const cmsis_nn_dims*, const cmsis_nn_dims*)”的参数太多
[错误] heightwise_conv.cc@184,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@195,9: &#39;ARM_MATH_SUCCESS&#39; 未在此范围内声明；您的意思是“ARM_MATH_DSP”吗？
[错误] heightwise_conv.cc@184,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@200,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@212,9: &#39;ARM_MATH_SUCCESS&#39; 未在此范围内声明；您的意思是“ARM_MATH_DSP”吗？
[错误] heightwise_conv.cc@200,34：无法将“constsigned char*”转换为“const cmsis_nn_context*”
[错误] heightwise_conv.cc@272,5: &#39;arm_depthwise_conv_u8_basic_ver1&#39; 未在此范围内声明；您的意思是“arm_depthwise_conv_fast_s16”吗？
[错误]“_queue.SimpleQueue”对象没有属性“queue”
[mbed] 错误：“/usr/bin/python3”返回错误。
       代码：1
       路径：“/home/ghjeon/tensorflow-lite/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed”
       命令：“/usr/bin/python3 -u /home/ghjeon/tensorflow-lite/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed/mbed-os/tools/make .py -t GCC_ARM -m DISCO_F746NG --源 . --build ./BUILD/DISCO_F746NG/GCC_ARM”
       提示：您可以使用“-v”重试最后一个命令详细输出标志
---


我无法解决这个问题。我已经2天无法解决这个问题了。我预先感谢任何可以提供帮助的人。
[错误]“_queue.SimpleQueue”对象没有属性“queue”

我看到信息表明上述错误可以通过使用Python 2.7来解决。但是，我不确定这是否允许使用 CLI1。因为ARM建议CLI1需要Python 3.7.x版本。]]></description>
      <guid>https://stackoverflow.com/questions/78125296/how-can-i-solve-the-problem-during-mbed-compiledepthwise-conv-cc</guid>
      <pubDate>Fri, 08 Mar 2024 02:44:08 GMT</pubDate>
    </item>
    <item>
      <title>Brainfuck 的机器学习库 [关闭]</title>
      <link>https://stackoverflow.com/questions/78125270/machine-learning-library-for-brainfuck</link>
      <description><![CDATA[我最近开始使用 Brainfuck 进行专业的工作，但我不知道有多少这种语言的库，我向工作和大学的同事询问了哪些库可以用于专注于图像处理的机器学习模型，但它我不太清楚哪个是最好的。
我会听取建议。
非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78125270/machine-learning-library-for-brainfuck</guid>
      <pubDate>Fri, 08 Mar 2024 02:29:07 GMT</pubDate>
    </item>
    <item>
      <title>HOML练习第2章分类中的数据增强</title>
      <link>https://stackoverflow.com/questions/78124870/homl-excersice-chapter-2-data-augmentation-in-classification</link>
      <description><![CDATA[问题引用
&lt;块引用&gt;
编写一个函数，可以将 MNIST 图像在任何方向（左、右、上、下）移动一个像素。⁠ 然后，对于训练集中的每个图像，创建四个移动副本（每个方向一个）并将它们添加到训练集中。最后，在这个扩展的训练集上训练你的最佳模型，并在测试集上测量其准确性。您应该观察到您的模型现在表现得更好了！这种人工增长训练集的技术称为数据增强或训练集扩展。

我尝试的解决方案：
来自 scipy.ndimage.interpolation 导入移位
将 numpy 导入为 np
从 sklearn.linear_model 导入 SGDClassifier
从 sklearn.model_selection 导入 cross_val_score

def shift_image(图像, 方向):
    图像 = image.reshape((28, 28))
    如果方向==“右”：
        返回移位（图像，[0, 1]，cval=0）
    elif 方向==“左”：
        返回移位（图像，[0，-1]，cval = 0）
    elif 方向 == “向上”：
        返回移位（图像，[-1, 0]，cval=0）
    elif 方向 == “向下”：
        返回移位（图像，[1, 0]，cval=0）



移位图像 = []

对于 X_train 中的 img：
    shift_images.append(shift_image(img, “右”))
    shift_images.append(shift_image(img, “左”))
    shift_images.append(shift_image(img, “向上”))
    shift_images.append(shift_image(img, “向下”))

# 将移位图像列表转换为 numpy 数组
X_train_shifted = np.array(shifted_images)
flattened_images = X_train_shifted.reshape((-1, 28 * 28))
打印（展平图像.形状）
打印（X_train.shape）
X_combined = np.concatenate((X_train, flattened_images))
X_combined.shape



y_combined = np.concatenate((y_train,y_train,y_train,y_train,y_train))

sgd_clf = SGDClassifier()
sgd_clf.fit(X_combined,y_combined)
cross_val_score(sgd_clf,X_combined,y_combined,cv=3,scoring=“准确度”)

交叉验证分数输出：
数组([0.08093, 0.10234, 0.10207])

为什么我得到的分数比虚拟分类器差？]]></description>
      <guid>https://stackoverflow.com/questions/78124870/homl-excersice-chapter-2-data-augmentation-in-classification</guid>
      <pubDate>Thu, 07 Mar 2024 23:31:26 GMT</pubDate>
    </item>
    <item>
      <title>更好的分类模型架构[关闭]</title>
      <link>https://stackoverflow.com/questions/78124708/a-better-model-architecture-for-classification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78124708/a-better-model-architecture-for-classification</guid>
      <pubDate>Thu, 07 Mar 2024 22:40:36 GMT</pubDate>
    </item>
    <item>
      <title>Chrome 扩展工具中的 500 内部服务器错误</title>
      <link>https://stackoverflow.com/questions/78124159/500-internal-server-error-in-a-chrome-extension-tool</link>
      <description><![CDATA[我正在尝试为网络钓鱼电子邮件检测系统创建一个 Chrome 扩展工具。该系统使用“提取”按钮来收集发件人、主题和电子邮件正文文本，并使用“扫描”按钮来分析提取的电子邮件正文中的网络钓鱼指标。虽然我可以成功提取信息，但单击“扫描”按钮会导致控制台中显示 500 内部服务器错误。有什么建议可以解决这个问题吗？
后端.py
导入回溯
从烧瓶导入烧瓶，请求，jsonify
将 pandas 导入为 pd
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
从 sklearn.linear_model 导入 LogisticRegression
从flask_cors导入CORS
导入 json
导入日志记录
从 http 导入 HTTPStatus


应用程序=烧瓶（__名称__）


# 加载数据集
数据集 = pd.read_csv(“mail_data.csv”)

# 用空字符串替换空值
mail_data = dataset.where((pd.notnull(dataset)), &#39;&#39;)

# 将垃圾邮件标记为0；正品如1
mail_data.loc[mail_data[&#39;类别&#39;] == &#39;垃圾邮件&#39;, &#39;类别&#39;,] = 0
mail_data.loc[mail_data[&#39;类别&#39;] == &#39;真实&#39;, &#39;类别&#39;,] = 1

# 假设您的数据集有一个包含电子邮件内容的“文本”列和一个用于网络钓鱼的“标签”列
X = mail_data[&#39;消息&#39;]
Y = mail_data[&#39;类别&#39;]

＃ 特征提取
feature_extraction = TfidfVectorizer(min_df=1, stop_words=&#39;english&#39;, lowercase=True)
X_features = feature_extraction.fit_transform(X)

# 将 Y 值转换为整数
Y = Y.astype(&#39;int&#39;)

# 训练模型
模型=逻辑回归()
model.fit(X_features, Y)


@app.route(&#39;/&#39;, 方法=[&#39;GET&#39;, &#39;POST&#39;])
def Predict_phishing():
    如果 request.method == &#39;POST&#39;:
        email_content = request.json.get(&#39;email_content&#39;, &#39;&#39;)
        # 输入数据的特征提取

        email_content_feature = feature_extraction.transform([email_content])
        # 使用训练好的模型进行预测
        预测 = model.predict(email_content_feature)[0]

        

        返回 jsonify({&#39;预测&#39;: 预测})
    # 如果请求方法是GET，则返回一条消息
    别的：
        return jsonify({&#39;message&#39;: &#39;请使用POST方法进行预测。&#39;})
    

   
如果 __name__ == &#39;__main__&#39;:
    应用程序运行（调试=真）


popup.js
// 存储电子邮件主题、发件人和消息的变量
让 emailSubjectSenderMessage = {};

// 向 content.js 发送消息以提取电子邮件内容的函数
函数提取电子邮件内容（）{
  chrome.tabs.query({ active: true, currentWindow: true }, (tabs) =&gt; {
    if (tabs &amp;&amp; tabs.length &gt; 0 &amp;&amp; tabs[0].id) {
      const activeTab = tabs[0];
      chrome.tabs.sendMessage(activeTab.id, { action: &#39;extractEmailContent&#39; }, (response) =&gt; {
        if (chrome.runtime.lastError) {
          // 处理发送消息时的任何错误

        } 别的 {
          // 检查响应中是否包含 emailContent
          if (response &amp;&amp; response.emailContent) {
            // 提取邮件内容
            const emailContent = response.emailContent;

            // 提取发件人的电子邮件地址
            const senderEmail = emailContent.senderEmail;

            // 将电子邮件主题、发件人和消息存储在变量中
            电子邮件主题发件人消息 = {
              主题：电子邮件内容.主题，
              发件人：发件人电子邮件，
              消息：emailContent.body
            };

            // 显示提取的内容，包括发件人的电子邮件地址
            显示电子邮件内容（电子邮件内容，发件人电子邮件）；
          } 别的 {
            displayErrorMessage(&#39;此页面上找不到电子邮件数据。&#39;);
          }
        }
      });
    } 别的 {
      console.error(&#39;无效的选项卡或选项卡 ID 不可用。&#39;);
    }
  });
}


// 显示提取的电子邮件内容的函数
函数显示电子邮件内容（电子邮件内容，发件人电子邮件）{
  const emailContentDiv = document.getElementById(&#39;emailContent&#39;);
  emailContentDiv.innerHTML = `发件人： ${senderEmail}&lt;br&gt;&lt;strong&gt;主题：&lt;/strong&gt; ${emailContent.subject}&lt;br&gt;&lt;strong&gt;消息：&lt;/strong&gt; ${emailContent.body}`;
}

// 显示错误信息的函数
函数显示错误消息（消息）{
  const emailContentDiv = document.getElementById(&#39;emailContent&#39;);
  emailContentDiv.textContent = 消息；
}
]]></description>
      <guid>https://stackoverflow.com/questions/78124159/500-internal-server-error-in-a-chrome-extension-tool</guid>
      <pubDate>Thu, 07 Mar 2024 20:28:12 GMT</pubDate>
    </item>
    <item>
      <title>机器学习通过 SVC 症状预测疾病 [关闭]</title>
      <link>https://stackoverflow.com/questions/78123509/machine-learning-prediction-of-disease-by-symptoms-with-svc</link>
      <description><![CDATA[我正在尝试创建一种通过症状来预防疾病的功能，但我有什么想法吗？
它会像：
症状 = [“皮肤皮疹”、“连续打喷嚏”、“瘙痒”]
pred（症状，模型）

这是我当前的代码：
将 pandas 导入为 pd
从 sklearn.preprocessing 导入 LabelEncoder、StandardScaler
从 sklearn.model_selection 导入 train_test_split
从 sklearn.svm 导入 SVC
从 sklearn.metrics 导入准确度_分数、精度_分数、召回_分数、f1_分数

def load_and_preprocess_data(文件路径):
    df = pd.read_csv(文件路径)

    # 识别非数字列（不包括“疾病”）
    non_numeric_cols = df.select_dtypes(include=[&#39;object&#39;]).columns.difference([&#39;Disease&#39;])
    print(&quot;非数字列（不包括&#39;疾病&#39;）：&quot;, non_numeric_cols)

    df.fillna(0,就地=True)

    如果 df.columns 中有“疾病”：
        le = 标签编码器()
        df[&#39;疾病&#39;] = le.fit_transform(df[&#39;疾病&#39;])

    X = df.drop(&#39;疾病&#39;, axis=1)
    y = df[&#39;疾病&#39;]

    # 特征缩放（如果需要，考虑替代缩放方法）
    定标器=标准定标器()
    X = pd.DataFrame(scaler.fit_transform(X))

    返回 X, y

def build_and_train_model(X_train, y_train):
    # 使用不同的内核进行实验（线性、rbf 等）
    model = SVC(kernel=&#39;linear&#39;) # 替换为所选内核

    # 训练模型
    model.fit(X_train, y_train)

    返回模型

def Predict_and_evaluate(模型, X_test, y_test):
    y_pred = model.predict(X_test)
    准确度=准确度_得分(y_test, y_pred)
    精度 = precision_score(y_test, y_pred, 平均值=&#39;加权&#39;)
    召回率=召回率（y_test，y_pred，平均值=&#39;加权&#39;）
    f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)

    print(“准确度：”, 准确度)
    print(&quot;精度：&quot;, 精度)
    print(“回忆：”, 回忆)
    print(&quot;F1-分数：&quot;, f1)


def main():
    文件路径 = &#39;数据集/merged_dataset.csv&#39;

    X, y = load_and_preprocess_data(文件路径)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    模型 = build_and_train_model(X_train, y_train)

    预测和评估（模型，X_测试，y_测试）


如果 __name__ == “__main__”：
    主要的（）

这就是 csv 的样子：
疾病、瘙痒、皮疹、结节性皮肤疹、连续打喷嚏
真菌感染,1,3,4,0,0
真菌感染,1,3,0,0,6
过敏,1,3,0,0,0
... 和更多

是症状的严重程度，如 1,3,4,0,0（0 表示对该疾病不重要）
所以我必须用我训练的模型通过症状列表来猜测疾病我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/78123509/machine-learning-prediction-of-disease-by-symptoms-with-svc</guid>
      <pubDate>Thu, 07 Mar 2024 18:09:35 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.multiclass.OneVsRestClassifier 中的回调</title>
      <link>https://stackoverflow.com/questions/78119978/callbacks-in-sklearn-multiclass-onevsrestclassifier</link>
      <description><![CDATA[我想使用回调和 eval_set 等。
但我有一个问题：
from sklearn.multiclass import OneVsRestClassifier
导入lightgbm

&lt;前&gt;&lt;代码&gt;详细 = 100
参数 = {
    “目标”：“二元”，
    “n_估计器”：500，
    “详细”：0
}
适合参数= {
    “eval_set”：eval_数据集，
    “回调”：[CustomCallback（详细）]
}

clf = OneVsRestClassifier(lightgbm.LGBMClassifier(**params))
clf.fit(X_train, y_train, **fit_params)

我如何将 fit_params 交给我的估算器？我明白
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- --------------------------
---&gt; 13 clf.fit(X_train, y_train, **fit_params)

TypeError：OneVsRestClassifier.fit() 得到意外的关键字参数“eval_set”
]]></description>
      <guid>https://stackoverflow.com/questions/78119978/callbacks-in-sklearn-multiclass-onevsrestclassifier</guid>
      <pubDate>Thu, 07 Mar 2024 08:59:29 GMT</pubDate>
    </item>
    <item>
      <title>加载图像边界框输出相同大小的错误</title>
      <link>https://stackoverflow.com/questions/78118283/loading-image-bounding-boxes-outputs-equal-size-error</link>
      <description><![CDATA[我正在尝试为我的数据集创建一个 PyTorch 数据加载器。每个图像都有一定数量的汽车和每个汽车的边界框，但并非所有图像都具有相同数量的边界框。
您可能无法运行它，但这里有一些信息。
这是我的数据加载器
类 AGR_Dataset（数据集）：
    def __init__(self,annotations_root,img_root,transform=None):
        ”“”
        论据：
            comments_root（字符串）：带有注释的 csv 文件的路径。
            img_root（字符串）：包含所有图像的目录。
            变换（可调用，可选）：要应用的可选变换
                在样品上。
        ”“”
        self.annotations_root = 注释_root
        self.img_root = img_root
        self.transform = 变换

    def __len__(自身):
        返回 len(self.annotations_root)
    
    def __getitem__(self, idx):
        # idx 可能是索引或图像名称，我认为图像 naem
        如果 torch.is_tensor(idx):
            idx = idx.tolist()
        
        idx_name = os.listdir(self.img_root)[idx]
        # 打印(idx_name)
        
        img_name = os.path.join(self.img_root, idx_name)
        Comments_data = os.path.join(self.annotations_root, f&quot;{idx_name.removesuffix(&#39;.jpg&#39;)}.txt&quot;)
        # print(img_name, 注释数据)

        图像 = io.imread(img_name)

        以 open(annotation_data, &#39;r&#39;) 作为文件：
            行= file.readlines()
            图像数据 = []
            img_标签 = []
            对于行中行：
                line = line.split(&#39;,&#39;)
                line = [i.strip() for i in line]
                line = [float(num) for num in line[0].split()]
                img_labels.append(int(行[0]))
                img_data.append(行[1:])

        框 = tv_tensors.BoundingBoxes(img_data, format=&#39;CXCYWH&#39;, canvas_size=(image.shape[0], image.shape[1]))

        # 样本 = {&#39;image&#39;: 图像, &#39;bbox&#39;: 盒子, &#39;labels&#39;: img_labels}
        样本= {&#39;image&#39;：图像，&#39;bbox&#39;：盒子}

        如果自我变换：
            样本 = self.transform(样本)

        打印（样本[&#39;图像&#39;].shape）
        打印（样本[&#39;bbox&#39;].shape）
        # print(样本[&#39;标签&#39;].shape)
        返回样品

我运行转换并创建数据加载器
data_transform = v2.Compose([
    v2.ToImage(),
    # v2.调整大小(680),
    v2.RandomResizedCrop(大小=(680, 680), 抗锯齿=True),
    # v2.ToDtype(torch.float32,scale=True),
    v2.ToTensor()
]）

Transformed_dataset = AGR_Dataset(f&#39;{annotations_path}/test/&#39;,
                        f&#39;{img_path}/测试/&#39;,
                        变换=数据变换）

数据加载器=数据加载器(transformed_dataset,batch_size=2,
                        洗牌=假，num_workers=0）

然后我尝试用它迭代它，并最终使用边界框查看和图像。
对于 i，枚举（dataloader）中的示例：
    打印（我，样本）
    print(i, 样本[&#39;image&#39;].size(), 样本[&#39;bbox&#39;].size())

    如果我==4：
        休息

批处理大小为 1 时，它运行正常，批处理大小为 2 时，出现此错误
torch.Size([3, 680, 680])
火炬.Size([12, 4])

火炬.Size([3, 680, 680])
火炬.Size([259, 4])

RuntimeError: 堆栈期望每个张量大小相等，但在条目 0 处得到 [12, 4]，在条目 1 处得到 [259, 4]


我认为这是由于边界框数量不相等造成的，但如何克服这个问题？
我的变换中需要 ToTensor 吗？我开始认为我不这样做，因为 v2 使用 ToImage()，而 ToTensor 正在被贬值。

如有任何其他意见或帮助，我们将不胜感激。
我不确定如何创建一个工作示例，我会继续尝试。
我尝试过的
我尝试通过注释数据加载器中的 tv_tensors.BoundingBoxes 行来不将边界框加载为张量，但由于某种原因，我的调整大小无法正常工作。
我刚刚尝试在数据加载器中像这样分割框和图像
样本 = 图像
    目标= {&#39;bbox&#39;：盒子，&#39;标签&#39;：img_labels}

运气不好]]></description>
      <guid>https://stackoverflow.com/questions/78118283/loading-image-bounding-boxes-outputs-equal-size-error</guid>
      <pubDate>Thu, 07 Mar 2024 01:30:38 GMT</pubDate>
    </item>
    <item>
      <title>RF 模型的 MLJ.jl 中的数据类型总是错误</title>
      <link>https://stackoverflow.com/questions/78116043/data-type-is-always-wrong-in-mlj-jl-with-the-rf-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78116043/data-type-is-always-wrong-in-mlj-jl-with-the-rf-model</guid>
      <pubDate>Wed, 06 Mar 2024 16:41:59 GMT</pubDate>
    </item>
    <item>
      <title>使用LSTM模型进行充电数据负荷预测的时间序列交叉验证</title>
      <link>https://stackoverflow.com/questions/78107902/time-series-cross-validation-for-load-forecast-of-charging-data-using-lstm-model</link>
      <description><![CDATA[我目前正在构建一个 LSTM 模型，以使用包含 24 个特征和 12 个月目标列的数据集来预测电动汽车的消耗量。数据采用时间序列格式，间隔为 15 分钟，我想应用时间序列交叉验证来维护时间依赖性。
这是我到目前为止为训练和测试拆分编写的代码：
# 定义用于训练的列
特征 = [&#39;小时&#39;, &#39;季度小时&#39;, &#39;工作日&#39;, &#39;cal_week&#39;, &#39;月份&#39;, &#39;周末&#39;,
                  &#39;季节&#39;，&#39;假期&#39;，&#39;下一个假期&#39;，&#39;bridge_day&#39;，&#39;学校假期&#39;，&#39;quarter_sin&#39;，&#39;quarter_cos&#39;，&#39;hour_sin&#39;，&#39;hour_cos&#39;，
                  &#39;weekday_sin&#39;、&#39;weekday_cos&#39;、&#39;month_sin&#39;、&#39;month_cos&#39;、&#39;cal_week_sin&#39;、&#39;cal_week_cos&#39;、&#39;temp_day_avg&#39;、&#39;humidity_day_avg&#39;、&#39;wind_speed&#39;]

# 提取特征和目标变量
X = Bosch_data[功能].值
y = Bosch_data[&#39;aggregate_conspiration_kWh&#39;].values


# 定义窗口大小
validation_window_size = 7 * 24 * 4 # 7天* 24小时* 4个季度/小时（15T）
test_window_size = 31 * 24 * 4 # 31天* 24小时* 4个季度/小时（15T）

# 将训练集定义为除验证集和测试集之外的所有内容
train_window_size = len(Bosch_data) - validation_window_size - test_window_size

# 将数据分为训练集、验证集和测试集
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=validation_window_size + 31 * 24 * 4, shuffle=False)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=31 * 24 * 4, shuffle=False)

我有两个具体问题：

扩展窗口交叉验证：如何将扩展窗口交叉验证应用于此训练、验证和测试拆分？

选择时间步长：我的数据集呈现每周模式，我想预测未来 30 天的消耗量。考虑到 15 分钟的时间间隔，在这种情况下我的理想时间步长应该是多少？如果我使用 15 分钟的时间间隔作为一个时间步长，则会出现错误。


我愿意接受有关如何解决这些问题并扩展我的时间序列交叉验证代码的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78107902/time-series-cross-validation-for-load-forecast-of-charging-data-using-lstm-model</guid>
      <pubDate>Tue, 05 Mar 2024 12:58:27 GMT</pubDate>
    </item>
    <item>
      <title>用Python代码编写的RNN反向传播公式</title>
      <link>https://stackoverflow.com/questions/78102670/rnn-backpropagation-formula-written-in-python-code</link>
      <description><![CDATA[鉴于常规 RNN 网络反向传播的文本描述，我无法将给定的公式与此处的 python 代码关联起来：
https://dennybritz.com/posts/ wildml/recurrent-neural-networks-tutorial-part-3/
另请参阅此屏幕截图。
你能澄清一下吗？
为我应用链式法则与给定的 python 代码不匹配。如果我没记错的话，给出：
f(x) = tanh(x)
然后：
df/dx = 1 - tanh^2(x)
但是我没有看到给定的 python 代码对 tanh 函数的任何使用。]]></description>
      <guid>https://stackoverflow.com/questions/78102670/rnn-backpropagation-formula-written-in-python-code</guid>
      <pubDate>Mon, 04 Mar 2024 16:16:44 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 AttributeError: 'ConfigDict' 对象在 mmdetection 上没有属性 'data'？</title>
      <link>https://stackoverflow.com/questions/74209071/how-to-fix-attributeerror-configdict-object-has-no-attribute-data-on-mmdete</link>
      <description><![CDATA[我目前正在尝试为自定义数据集设置毫米检测，并且一直遇到这些错误。我尝试删除代码中的 def 函数，更改文件位置以及上述所有内容。我不知道代码有什么问题以及为什么它不起作用。
from argparse import ArgumentParser
从 mmdet.apis 导入 init_detector、inference_detector
导入MMCV
从 mmdet.apis 导入（async_inference_ detector、inference_ detector、
                        init_Detector、show_result_pyplot）
导入异步
进口火炬
从 mmdet.apis 导入 init_detector、async_inference_detector
从 mmdet.utils.contextmanagers 导入并发

定义数据（）：
# 新配置继承基本配置以突出显示必要的修改
    base_ = &#39;configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_1x_coco.py&#39;

# 我们还需要更改 head 中的 num_classes 以匹配数据集的注释
# dict 是一个 python 字典对象，用于从 PyTorch 保存或加载模型
    模型=字典（
        roi_head=字典（
        # 定义边界框可以绕过的类数
            bbox_head=dict(num_classes=1),
            #
            mask_head=dict(num_classes=1)))

def 数据集():
    # 修改数据集相关设置
    dataset_type = &#39;COCO数据集&#39;
    #定义类
    类 = (&#39;受电弓&#39;)
    数据=字典（
        火车=字典（
            img_prefix=&#39;测试/&#39;,
            类=类，
            ann_file=&#39;train/Pan2_COCO.json&#39;),
        val=字典（
            img_prefix=&#39;测试/&#39;,
            类=类，
            ann_file=&#39;val/Pan2_COCO.json&#39;),
        测试=字典（
            img_prefix=&#39;测试/&#39;,
            类=类，
            ann_file=&#39;val/Pan2_COCO.json&#39;))
定义负载（）：
# 我们可以使用预训练的Mask RCNN模型来获得更高的性能
    load_from = &#39;测试/检查点/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth&#39;

数据（）
数据集()
加载（）

错误消息：
回溯（最近一次调用最后一次）：
  文件“tools/train.py”，第244行，在&lt;module&gt;中。
    主要的（）
  文件“tools/train.py”，第 135 行，在 main 中
    setup_multi_processes（cfg）
  文件“/home/dtl-admin/dev/mmdetection/mmdet/utils/setup_env.py”，第 30 行，setup_multi_processes
    workers_per_gpu = cfg.data.get(&#39;workers_per_gpu&#39;, 1)
  文件“/home/dtl-admin/miniconda3/envs/mmtest/lib/python3.8/site-packages/mmcv/utils/config.py”，第 519 行，在 __getattr__ 中
    返回 getattr(self._cfg_dict, 名称)
  文件“/home/dtl-admin/miniconda3/envs/mmtest/lib/python3.8/site-packages/mmcv/utils/config.py”，第 50 行，在 __getattr__ 中
    提高前任
AttributeError：“ConfigDict”对象没有属性“data”

我期待图像检测到类受电弓的输出。但是，无论我尝试什么，我都无法获得任何输出，并且我已尝试更改尽可能多的变量。]]></description>
      <guid>https://stackoverflow.com/questions/74209071/how-to-fix-attributeerror-configdict-object-has-no-attribute-data-on-mmdete</guid>
      <pubDate>Wed, 26 Oct 2022 13:58:38 GMT</pubDate>
    </item>
    <item>
      <title>学习一种双线性形式的矩阵函数</title>
      <link>https://stackoverflow.com/questions/67740146/learn-the-matrix-function-of-a-sort-of-bilinear-form</link>
      <description><![CDATA[我正在考虑对标量函数 f:R^n-&gt;R 进行回归的问题，其中我有一组训练样本 (x1,y1),...,(xN,yN)，其中 yi = f(xi)。
我知道原则上我可以应用任何神经网络架构来对此函数进行回归，但是我想利用我了解的属性来设计网络。
准确地说，我知道 f(x)= x^TA(x)x$ 对于 nxn 矩阵值函数 A(x)，我不太清楚，但我知道它是对称且正定的。
我认为，既然我知道函数的这种结构，那么应用“标准”函数并不是一种有效的方法。架构来解决这个问题。这个问题实际上看起来像是在 R^n 上寻找并逼近度量的问题。
由于 A(x) 是对称正定的，对于未知的矩阵值函数 B(x)，我想将其重写为 A(x) = B(x)^TB(x)。因此，函数 f(x) 以更简单的方式重写：f(x) = |B(x)x|^2，其中唯一的未知数是矩阵函数 B(x)。
现在，是否有一些已知的架构非常适合这种情况？
使用 B(x) 常数生成训练数据，我已经很容易地解决了这个问题，定义了要优化的权重，并且效果很好。但是，如果矩阵 B(x) 与 x 相关，我不完全确定如何继续。
到目前为止，我已经实现了一个从 R^n 到 R^{n^2} 的神经网络，其中输出被重新整形为 nxn 矩阵 B(x) 来学习。然而，这仅适用于简单的 B(x)，对我来说仍然不清楚原因。]]></description>
      <guid>https://stackoverflow.com/questions/67740146/learn-the-matrix-function-of-a-sort-of-bilinear-form</guid>
      <pubDate>Fri, 28 May 2021 13:51:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit-learn 对文本进行标记</title>
      <link>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</link>
      <description><![CDATA[我有以下代码从一组文件（文件夹名称是类别名称）中提取特征以进行文本分类。
导入sklearn.datasets
从 sklearn.feature_extraction.text 导入 TfidfVectorizer

train = sklearn.datasets.load_files(&#39;./train&#39;,description=None,categories=None,load_content=True,shuffle=True,encoding=None,decode_error=&#39;strict&#39;,random_state=0)
print len(训练数据)
打印train.target_names

向量化器 = TfidfVectorizer()
X_train = 矢量化器.fit_transform(train.data)

它抛出以下堆栈跟踪：
回溯（最近一次调用最后一次）：
  文件“C:\EclipseWorkspace\TextClassifier\main.py”，第 16 行，在  中
    X_train = 矢量化器.fit_transform(train.data)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 1285 行，在 fit_transform 中
    X = super(TfidfVectorizer, self).fit_transform(raw_documents)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 804 行，在 fit_transform 中
    self.fixed_vocabulary_)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 739 行，在 _count_vocab 中
    对于分析（doc）中的功能：
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 236 行，位于 &lt;lambda&gt; 中
    tokenize(预处理(self.decode(doc))), stop_words)
  文件“C:\Python27\lib\site-packages\sklearn\feature_extraction\text.py”，第 113 行，解码
    doc = doc.decode(self.encoding, self.decode_error)
  文件“C:\Python27\lib\encodings\utf_8.py”，第 16 行，解码中
    返回codecs.utf_8_decode（输入，错误，True）
UnicodeDecodeError：“utf8”编解码器无法解码位置 32054 中的字节 0xff：起始字节无效

我运行Python 2.7。我怎样才能让它发挥作用？
编辑：
我刚刚发现这对于使用 utf-8 编码的文件（我的文件是 ANSI 编码）非常有效。有什么方法可以让 sklearn.datasets.load_files() 使用 ANSI 编码吗？]]></description>
      <guid>https://stackoverflow.com/questions/29980037/tokenizing-text-with-scikit-learn</guid>
      <pubDate>Fri, 01 May 2015 00:39:09 GMT</pubDate>
    </item>
    </channel>
</rss>