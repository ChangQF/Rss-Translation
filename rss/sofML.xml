<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 04 Sep 2024 18:19:18 GMT</lastBuildDate>
    <item>
      <title>如何计算 Cov2D 层的尺寸？</title>
      <link>https://stackoverflow.com/questions/78949615/how-can-the-dimensions-of-a-cov2d-layer-be-calculated</link>
      <description><![CDATA[我试图了解我的 GAN 生成器输出的尺寸。每层之后的结果尺寸如下：
开始：torch.Size([128, 74, 1, 1]) 
block1 之后：torch.Size([128, 256, 3, 3]) 
block2 之后：torch.Size([128, 128, 6, 6]) 
block3 之后：torch.Size([128, 64, 13, 13]) 
block4 之后：torch.Size([128, 1, 28, 28])

生成器代码如下。此处 z_dim 为 74，但最初为 64。它附加了 10 个类标签，如下所示。
 fake_noise = get_noise(cur_batch_size, z_dim, device=device) 
noise_and_labels = Combine_vectors(fake_noise, one_hot_labels)
fake = gen(noise_and_labels)

class Generator(nn.Module):
&#39;&#39;&#39;
Generator 类
值：
z_dim：噪声向量的维度，标量
im_chan：输出图像的通道数，标量
（MNIST 是黑白的，因此 1 个通道是您的默认值）
hidden_​​dim：内部维度，标量
&#39;&#39;&#39;
def __init__(self, z_dim=10, im_chan=1, hidden_​​dim=64):
super(Generator, self).__init__()
self.z_dim = z_dim
# 构建神经网络
self.block1 = self.make_gen_block(z_dim, hidden_​​dim * 4)
self.block2 = self.make_gen_block(hidden_​​dim * 4, hidden_​​dim * 2, kernel_size=4, stride=1)
self.block3 = self.make_gen_block(hidden_​​dim * 2, hidden_​​dim)
self.block4 = self.make_gen_block(hidden_​​dim, im_chan, kernel_size=4, final_layer=True)

def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, padding=1, final_layer=False):
&#39;&#39;&#39;
函数返回与 DCGAN 生成器块对应的操作序列；
转置卷积、批量规范（最后一层除外）和激活。
参数：
input_channels：输入特征表示有多少个通道
output_channels：输出特征表示应该有多少个通道
kernel_size：每个卷积滤波器的大小，相当于 (kernel_size, kernel_size)
stride：卷积的步幅
final_layer：布尔值，如果是最后一层则为 true，否则为 false
（影响激活和 batchnorm）
&#39;&#39;&#39;
如果不是 final_layer：
return nn.Sequential(
nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),
nn.BatchNorm2d(output_channels),
nn.LeakyReLU(0.2, inplace=True),
)
else：
return nn.Sequential(
nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride),
nn.Tanh(),
)

def forward(self, noise):
&#39;&#39;&#39;
完成生成器前向传递的函数：给定一个噪声张量，
返回生成的图像。
参数：
noise：具有维度 (n_samples, input_dim) 的噪声张量
&#39;&#39;&#39;
x = noise.view(len(noise), self.z_dim, 1, 1)
print(f&#39;Gen: {x.shape}&#39;)
x = self.block1(x)
print(f&#39;After block1: {x.shape}&#39;)
x = self.block2(x)
print(f&#39;After block2: {x.shape}&#39;)
x = self.block3(x)
print(f&#39;After block3: {x.shape}&#39;)
x = self.block4(x)
print(f&#39;After block4: {x.shape}&#39;)
return x

def get_noise(n_samples, z_dim, device=&#39;cpu&#39;):
&#39;&#39;&#39;
用于创建噪声向量的函数：给定维度 (n_samples, z_dim)
创建该形状的张量，其中填充了来自正态分布的随机数。
参数：
n_samples：要生成的样本数，标量
z_dim：噪声向量的维度，标量
device：设备类型
&#39;&#39;&#39;
return torch.randn(n_samples, z_dim, device=device)

根据此处的公式，第一个块之后的结果将是(1 + 2x0 -1x(3-1) -1)/2 +1 = 0 但它显示 3x3。我在这里做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78949615/how-can-the-dimensions-of-a-cov2d-layer-be-calculated</guid>
      <pubDate>Wed, 04 Sep 2024 16:09:58 GMT</pubDate>
    </item>
    <item>
      <title>通过索引为张量赋值后，值不匹配</title>
      <link>https://stackoverflow.com/questions/78949501/mismatch-of-values-after-assigning-values-to-a-tensor-by-index</link>
      <description><![CDATA[我正在编写一个 PyTorch 训练代码，它构建了一个算法类。其中有一个步骤需要为内部张量分配一些值。但是，即使代码只有两行，也有一个错误。我发现分配的张量的值与分配的值不同。
这是该类的代码：
class PRODEN(Algorithm):
&quot;&quot;&quot;
PRODEN
参考：部分标签学习的真实标签的渐进式识别，ICML 2020。
&quot;&quot;&quot;

def __init__(self, input_shape, train_givenY, hparams):
super(PRODEN, self).__init__(input_shape, train_givenY, hparams)
self.featurizer = networks.Featurizer(input_shape, self.hparams)
self.classifier = networks.Classifier(
self.featurizer.n_outputs,
self.num_classes)

self.network = nn.Sequential(self.featurizer, self.classifier)
self.optimizer = torch.optim.Adam(
self.network.parameters(),
lr=self.hparams[&quot;lr&quot;],
weight_decay=self.hparams[&#39;weight_decay&#39;]
)
train_givenY = torch.from_numpy(train_givenY)
tempY = train_givenY.sum(dim=1).unsqueeze(1).repeat(1, train_givenY.shape[1])
label_confidence = train_givenY.float()/tempY
self.label_confidence = label_confidence

def update(self, minibatches):
_, x, strong_x, partial_y, _, index = minibatches
loss = self.rc_loss(self.predict(x), index)
self.optimizer.zero_grad()
loss.backward()
self.optimizer.step()
self.confidence_update(x, partial_y, index)
return {&#39;loss&#39;: loss.item()}

def rc_loss(self, output, index):
device = &quot;cuda&quot; if index.is_cuda else &quot;cpu&quot;
self.label_confidence = self.label_confidence.to(device)
logsm_outputs = F.log_softmax(outputs, dim=1)
#print(self.label_confidence.is_cuda)
final_outputs = logsm_outputs * self.label_confidence[index, :]
average_loss = - ((final_outputs).sum(dim=1)).mean()
return average_loss

def predict(self, x):
return self.network(x)

def confidence_update(self, batchX, batchY, batch_index):
with torch.no_grad():
batch_outputs = self.predict(batchX)
temp_un_conf = F.softmax(batch_outputs, dim=1)
&#39;&#39;&#39;有问题的代码开始了&#39;&#39;&#39;
self.label_confidence[batch_index, :] = temp_un_conf * batchY # un_confidence 存储每个示例的权重
&#39;&#39;&#39;问题代码结束&#39;&#39;&#39;
base_value = self.label_confidence.sum(dim=1).unsqueeze(1).repeat(1, self.label_confidence.shape[1])
self.label_confidence = self.label_confidence / base_value

问题出在 confidence_update 上。我发现
self.label_confidence[batch_index, :]

的值与
temp_un_conf * batchY

在此分配之后
self.label_confidence[batch_index, :] = temp_un_conf * batchY

仅适用于少数示例，但适用于大多数示例。例如，对于 1024 的批次大小，第一次迭代时大约有 4 个示例，之后会变得更大。我对这个问题非常沮丧，尝试了很多方法：

这个问题只存在于 CIFAR10 中，但其他数据集不存在这个问题。

所有张量的数据类型都是 Float32。

所有张量都在 gpu 上。


如果有人能告诉我我的代码出了什么问题，我将不胜感激！
我希望有人能告诉我我的代码出了什么问题。]]></description>
      <guid>https://stackoverflow.com/questions/78949501/mismatch-of-values-after-assigning-values-to-a-tensor-by-index</guid>
      <pubDate>Wed, 04 Sep 2024 15:41:44 GMT</pubDate>
    </item>
    <item>
      <title>从巨大的文本文件和一行提示生成文章</title>
      <link>https://stackoverflow.com/questions/78949493/generate-article-from-a-huge-text-file-and-a-one-line-prompt</link>
      <description><![CDATA[我想从一个大文本文件和一个单行提示中生成一篇大约 100 行的文章
第 1 行：敏捷的棕色狐狸跳过了懒狗。
第 2 行：困难中蕴藏着机遇。
第 3 行：生活就是当你忙于制定其他计划时发生的事情。
第 4 行：在这个不断试图让你成为其他东西的世界中做你自己是最大的成就。
第 5 行：成功不是终点，失败也不是致命的：继续前进的勇气才是最重要的。
第 6 行：敏捷的棕色狐狸吃肉。
提示：狐狸做了什么？
输出文章：敏捷的棕色狐狸跳过了懒狗。敏捷的棕色狐狸吃肉。
这只是一个小例子给定。
您能改进我的代码或给我一个更好的解决方案吗？
我所说的改进我的代码的意思是我想过度拟合我的文本文件。
# prepare_dataset.py

来自 transformers 导入 GPT2Tokenizer
来自 datasets 导入 Dataset
导入 pandas 作为 pd

def load_and_prepare_dataset(file_path):
&quot;&quot;&quot;从文本文件加载并准备数据集。&quot;&quot;&quot;
使用 open(file_path, &#39;r&#39;) 作为文件：
text = file.read()

lines = text.split(&#39;.&#39;)

data = {&#39;text&#39;: lines} 
df = pd.DataFrame(data)

tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)

tokenizer.pad_token = tokenizer.eos_token

def tokenize_function(examples):
return tokenizer(examples[&#39;text&#39;], padding=&#39;max_length&#39;, truncation=True, max_length=512)

dataset = Dataset.from_pandas(df)

tokenized_datasets = dataset.map(tokenize_function, batched=True)
tokenized_datasets = tokenized_datasets.rename_column(&quot;input_ids&quot;, &quot;labels&quot;)

return tokenized_datasets

如果__name__ == &quot;__main__&quot;:
dataset = load_and_prepare_dataset(&#39;data.txt&#39;) 
dataset.save_to_disk(&#39;./dataset&#39;)

# train_model.py

from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments
from datasets import load_from_disk

def fine_tune_model(train_dataset):
&quot;&quot;&quot;在给定的数据集上微调 GPT-2 模型。&quot;&quot;&quot;
tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)
model = GPT2LMHeadModel.from_pretrained(&#39;gpt2&#39;)

training_args = TrainingArguments(
output_dir=&#39;./results&#39;, # 输出目录
evaluation_strategy=&#39;epoch&#39;, # 要使用的评估策略
learning_rate=2e-5, # 学习率
per_device_train_batch_size=2, # 用于训练的批次大小
per_device_eval_batch_size=2, # 用于评估的批次大小
num_train_epochs=1, # 训练周期数
weight_decay=0.01, # 权重衰减强度
logs_dir=&#39;./logs&#39;, # 用于存储日志的目录
logs_steps=10, # 日志记录之间的步骤数
)

trainer = Trainer(
model=model, # 要训练的模型
args=training_args, # 参数用于训练
train_dataset=train_dataset, # 训练数据集
)

trainer.train()

def main():
dataset = load_from_disk(&#39;./dataset&#39;)
print(dataset.column_names)
print(dataset[0]) 

fine_tune_model(dataset)

if __name__ == &quot;__main__&quot;:
main()
]]></description>
      <guid>https://stackoverflow.com/questions/78949493/generate-article-from-a-huge-text-file-and-a-one-line-prompt</guid>
      <pubDate>Wed, 04 Sep 2024 15:40:27 GMT</pubDate>
    </item>
    <item>
      <title>empty() 在 Cu-net 模型中接收到了无效的参数组合</title>
      <link>https://stackoverflow.com/questions/78949410/empty-received-an-invalid-combination-of-arguments-in-cu-net-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78949410/empty-received-an-invalid-combination-of-arguments-in-cu-net-model</guid>
      <pubDate>Wed, 04 Sep 2024 15:23:33 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“gaze_tracking”导入名称“GazeTracking”[关闭]</title>
      <link>https://stackoverflow.com/questions/78948526/importerror-cannot-import-name-gazetracking-from-gaze-tracking</link>
      <description><![CDATA[每当我单击 python main.py 时，我都会卡住。以下是我无法解决的错误：
(newenv) C:\Users\Khan Mohd Arshad\OneDrive\Desktop\major\Oculus&gt;python main.py
2024-09-04 17:24:09.930311：我 tensorflow/core/util/port.cc:153] oneDNN 自定义操作已启用。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 `TF_ENABLE_ONEDNN_OPTS=0`。
2024-09-04 17:24:11.396430：我 tensorflow/core/util/port.cc:153] oneDNN 自定义操作已启用。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量“TF_ENABLE_ONEDNN_OPTS=0”。
警告：tensorflow：来自 C:\Users\Khan Mohd Arshad\OneDrive\Desktop\major\Oculus\newenv\Lib\site-packages\tf_keras\src\losses.py:2976：名称 tf.losses.sparse_softmax_cross_entropy 已弃用。请改用 tf.compat.v1.losses.sparse_softmax_cross_entropy。

回溯（最近一次调用）：
文件“C:\Users\Khan Mohd Arshad\OneDrive\Desktop\major\Oculus\main.py”，第 16 行，位于&lt;module&gt;
来自 gaze_tracking 导入 GazeTracking
ImportError：无法从“gaze_tracking”（未知位置）导入名称“GazeTracking”

我尝试运行自闭症检测项目。我下载了所有要求，然后出现错误。
这是 repo。请运行并解释步骤。https://github.com/deyRupak/oculus.git]]></description>
      <guid>https://stackoverflow.com/questions/78948526/importerror-cannot-import-name-gazetracking-from-gaze-tracking</guid>
      <pubDate>Wed, 04 Sep 2024 12:00:14 GMT</pubDate>
    </item>
    <item>
      <title>如何设置 Kubernetes GPU 集群以与位于本地网络中不同 PC 上的 GPU 协同工作？</title>
      <link>https://stackoverflow.com/questions/78947983/how-to-set-up-kubernetes-gpu-cluster-to-work-with-gpus-located-on-different-pcs</link>
      <description><![CDATA[我想在 Jupyter Notebook 中设置一个用于机器学习的 Kubernetes GPU 集群。我在一个本地网络中有 3 台配备 GPU（RTX 3060ti）的计算机，我想结合这些 GPU 的资源来运行神经网络训练和其他机器学习方法。
我的 RTX 3060ti 在解决某些神经网络训练任务时会执行太长的计算，我想用它来加速神经网络的训练。
感谢您的任何建议！
我尝试搜索有关此主题的信息，但大多数文章都涉及将一个 GPU 的资源分配给不同的机器学习任务。]]></description>
      <guid>https://stackoverflow.com/questions/78947983/how-to-set-up-kubernetes-gpu-cluster-to-work-with-gpus-located-on-different-pcs</guid>
      <pubDate>Wed, 04 Sep 2024 09:48:45 GMT</pubDate>
    </item>
    <item>
      <title>Azure ML Studio 数据资产权限被拒绝</title>
      <link>https://stackoverflow.com/questions/78947921/azure-ml-studio-permission-denied-on-data-asset</link>
      <description><![CDATA[我使用下面的代码通过 python azure API 创建了一个数据资产。模式如下：
wasbs://&lt;container-name&gt;@&lt;account name&gt;.blob.core.windows.net/&lt;folder&gt;/*.csv

其中帐户和容器与 Azure 机器学习工作区使用的相同。
 tbl = mltable.from_delimited_files(
path=[{&quot;pattern&quot;: body}],
delimiter=&quot;,&quot;,
header=MLTableHeaders.all_files_same_headers,
infer_column_types=True,
include_path_column=False,
encoding=MLTableFileEncoding.utf8,
)

my_data = Data(
path=mltable_folder, 
type=AssetTypes.MLTABLE,
name=&quot;Measurements&quot;,
)

my_data = ml_client.data.create_or_update(my_data)

数据资产已成功创建，我可以使用 UI 探索数据。此外，MLTable 文件看起来正常，具有正确的模式。
当我使用数据资产和自创计算实例启动自动化 ML 任务时，我收到以下错误：
错误消息：尝试访问流时身份验证失败。请确保您已设置正确的权限。确定（此请求无权使用此权限执行此操作。）| session_id=0e120470-1498-4fc9-8201-19783974e5df
ErrorResponse 
{
&quot;error&quot;: {
&quot;code&quot;: &quot;UserError&quot;,
&quot;message&quot;: &quot;提供的数据存储区中的数据路径无法访问。请确保您对资源拥有必要的访问权限。错误：\n错误代码：ScriptExecution.StreamAccess.Authentication\nNative 错误：数据流访问错误：ExecutionError(StreamError(PermissionDenied(Some(此请求无权使用此权限执行此操作。))))\n\tVisitError(ExecutionError(StreamError(PermissionDenied(Some(此请求无权使用此权限执行此操作。)))))\n=&gt;执行错误导致失败：从输入数据源流式传输时出错\n\tExecutionError(StreamError(PermissionDenied(Some(此请求未获授权使用此权限执行此操作。))))\n错误消息：尝试访问流时身份验证失败。请确保您已设置正确的权限。Ok(此请求未获授权使用此权限执行此操作。)| session_id=0e120470-1498-4fc9-8201-19783974e5df&quot;,
&quot;inner_error&quot;: {
&quot;code&quot;: &quot;Auth&quot;,
&quot;inner_error&quot;: {
&quot;code&quot;: &quot;Authentication&quot;,
&quot;inner_error&quot;: {
&quot;code&quot;: &quot;DataPathInaccessible&quot;
}
}
}
}
}

注意：当我使用具有相同数据和数据存储的 UI 创建数据资产时，我没有收到任何错误，并且一切正常。
我尝试了各种访问设置，但似乎无法使这个设置正常工作。还有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78947921/azure-ml-studio-permission-denied-on-data-asset</guid>
      <pubDate>Wed, 04 Sep 2024 09:36:02 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中进行向量搜索，根据上下文获取独特性分数</title>
      <link>https://stackoverflow.com/questions/78946820/vector-search-in-python-to-get-the-unqueness-score-according-to-context</link>
      <description><![CDATA[我有一篇带有标题和说明的博客文章，我想将其唯一性与 CSV 文件中的多个博客条目进行比较。CSV 包含多个博客，每个博客都有标题和元描述。
我目前使用 TF-IDF 矢量化和余弦相似度将单个博客与 CSV 文件中的所有条目进行比较。但是，这种方法仅基于确切的单词而不是上下文进行匹配。]]></description>
      <guid>https://stackoverflow.com/questions/78946820/vector-search-in-python-to-get-the-unqueness-score-according-to-context</guid>
      <pubDate>Wed, 04 Sep 2024 04:27:53 GMT</pubDate>
    </item>
    <item>
      <title>梯度盗贼代理的性能问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78942595/performance-issue-with-gradient-bandit-agent</link>
      <description><![CDATA[我正在阅读 Sutton&amp;Barto 的《强化学习：导论》。尝试测试梯度强盗代理（第 2.7 章）。但性能极低。我试过：

使用基线 = 平均奖励，不使用基线；
alpha = 0.1、0.2、0.3、0.4；
初始偏好 H = 0、1、10、100。

没有任何帮助。
这是我的 Python 代码，用于代理的 生命步骤 = 动作选择 + 参数更新 (self = agent)：
# 用于概率计算：
pref_exps = np.exp(self.params[&quot;preferences&quot;])
pref_exps_sum = sum(pref_exps)

# 选择强盗：
choice_dice = np.random.uniform() * pref_exps_sum
accum_pref_exp = 0
for i, pref_exp in enumerate(pref_exps):
accum_pref_exp += pref_exp
if accum_pref_exp &gt;= choice_dice:
self.chosen_bandit_i = i
break

# self.reward 在此处填充：
self.perform_bandit(self.chosen_bandit_i)

# 更新基线：
self.params[&quot;lifetime&quot;] += 1
self.params[&quot;average_reward&quot;] += 1 / self.params[&quot;lifetime&quot;] * (self.reward - self.params[&quot;average_reward&quot;])

# 更新偏好：
for i, pref_exp in enumerate(pref_exps):
probability = pref_exp / pref_exps_sum
if i == self.chosen_bandit_i:
self.params[&quot;preferences&quot;][i] += self.params[&quot;alpha&quot;] * (self.reward - self.params[&quot;average_reward&quot;]) * (1 - probability)
else:
self.params[&quot;preferences&quot;][i] -= self.params[&quot;alpha&quot;] * (self.reward - self.params[&quot;average_reward&quot;]) * probability

此代码导致性能极差（100 个代理，每个代理访问自己的 10 个 1-armed-bandits，测试超过 2000 步），我们可以从下图中看到：

我看过这篇帖子，修复错误后，它的代码似乎与我的代码相同，这也是那篇帖子的原因。但与我的代码不同，那篇帖子的代码在纠正后可以正常工作！
我不知道我在哪里犯了错误。你能帮助我正确使用Gradient-bandit 代理的全部功能吗？]]></description>
      <guid>https://stackoverflow.com/questions/78942595/performance-issue-with-gradient-bandit-agent</guid>
      <pubDate>Tue, 03 Sep 2024 03:40:50 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：在层“conv2d_7”上调用“set_weights(weights)”，权重列表长度为 2，但该层需要 1 个权重</title>
      <link>https://stackoverflow.com/questions/78836514/valueerror-called-set-weightsweights-on-layer-conv2d-7-with-a-weight-list</link>
      <description><![CDATA[我尝试在模型中的某一层上设置权重，但无济于事。
我在网上查找了类似问题的解决方案，但似乎都不起作用。变量“w”（如下面代码所示）的结构为 [numpy array, numpy array]。第一个的大小为 (3, 3, 3, 64)，第二个的形状为 (64,)。我想实现与 tf 2.X 中的“weights”kwarg 类似的功能，但似乎无法让它工作。这是我的代码：
encoder = Sequential()
encoder.add(layers.Conv2D(64, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;,use_bias=False,input_shape=(SIZE,SIZE,3)))
w = model.layers[0].get_weights()
encoder.layers[0].set_weights([w])
encoder.add(layers.MaxPooling2D((2, 2),padding=&#39;same&#39;))
encoder.add(layers.Conv2D(32, (3, 3),activation=&#39;relu&#39;,padding=&#39;same&#39;,weights=model.layers[2].get_weights()))
encoder.add(layers.MaxPooling2D((2, 2), padding=&#39;same&#39;))
encoder.add(layers.Conv2D(16, (3, 3),activation=&#39;relu&#39;, padding=&#39;same&#39;,weights=model.layers[4].get_weights()))
encoder.add(layers.MaxPooling2D((2, 2), padding=&#39;same&#39;))
encoder.summary()

错误：
错误：ValueError：您在层“conv2d_7”上调用了`set_weights(weights)`，权重列表长度为 2，但该层需要 1 个权重。
]]></description>
      <guid>https://stackoverflow.com/questions/78836514/valueerror-called-set-weightsweights-on-layer-conv2d-7-with-a-weight-list</guid>
      <pubDate>Mon, 05 Aug 2024 21:33:29 GMT</pubDate>
    </item>
    <item>
      <title>自定义模型聚合器 TensorFlow Federated</title>
      <link>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</link>
      <description><![CDATA[我正在尝试使用 TensorFlow Federated，使用 FedAvg 算法模拟训练过程。
trainer = tff.learning.algorithms.build_weighted_fed_avg(
model_fn= tff_model,
client_optimizer_fn=client_optimizer,
server_optimizer_fn=server_optimizer
)

我想使用自定义权重来聚合客户端的更新，而不是使用它们的样本数量。我知道 tff.learning.algorithms.build_weighted_fed_avg() 有一个名为 client_weighting 的参数，但唯一接受的值来自类 tff.learning.ClientWeighting，它是一个枚举。
还有其他方法可以使用自定义权重吗？]]></description>
      <guid>https://stackoverflow.com/questions/78835380/custom-model-aggregator-tensorflow-federated</guid>
      <pubDate>Mon, 05 Aug 2024 16:06:48 GMT</pubDate>
    </item>
    <item>
      <title>UnicodeEncodeError：'charmap'编解码器无法对位置 19-38 的字符进行编码：字符映射到 <undefined></title>
      <link>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</link>
      <description><![CDATA[我正在开发一个基于 Flask 的 Web 应用程序，用户可以上传图像以使用机器学习模型进行预测。上传的图像存储在本地目录中，并使用预先训练的模型进行预测。但是，当我点击预测按钮时
是什么导致了这个 UnicodeEncodeError？
我该如何解决这个问题，以确保我的应用程序能够正确处理图像上传和预测？
在 Flask 环境中，尤其是在 Windows 上，是否有处理字符编码的最佳实践？
==app.py====
@app.route(&#39;/uploadimage&#39;, methods=[&#39;GET&#39;, &#39;POST&#39;])
def upload_image():

file = request.files[&#39;my_image&#39;]
# 获取预测
predict_label = predict_label(img_path)
# 使用 flash 消息返回预测标签
flash(f&quot;Prediction: {predicted_label}&quot;, &quot;success&quot;)
os.remove(img_path) # 处理后删除临时文件
return render_template(&#39;uploadimage.html&#39;) # 对于 GET 请求，呈现表单


即使我设置了环境变量“UTF-8”，我仍然收到此错误
错误
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py”，第 19 行，位于 encode 中
返回codecs.charmap_encode(input,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: &#39;charmap&#39; 编解码器无法对位置 19-38 中的字符进行编码：字符映射到未定义。
============
即使我得到了一个最简单的代码来测试编码
标题是“要测试您的控制台是否可以处理 UTF-8，请尝试输出带有特殊字符或 Unicode 字符的文本：&quot;
print(&quot;UTF-8 test: àéîöü — 中文 — العربية&quot;)


错误与此相同好吧
print(&quot;UTF-8 测试：����� � \u4e2d\u6587 � \u0627\u0644\u0639\u0631\u0628\u064a\u0629&quot;)
文件 &quot;C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py&quot;，第 19 行，在编码中
返回 codecs.charmap_encode(input,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
UnicodeEncodeError: &#39;charmap&#39; 编解码器无法对位置中的字符进行编码20-21：字符映射到 ]]></description>
      <guid>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</guid>
      <pubDate>Mon, 22 Apr 2024 17:25:20 GMT</pubDate>
    </item>
    <item>
      <title>如何沿批次将张量连接到 keras 层（不指定批次大小）？</title>
      <link>https://stackoverflow.com/questions/68345125/how-to-concatenate-a-tensor-to-a-keras-layer-along-batch-without-specifying-bat</link>
      <description><![CDATA[我想将嵌入层的输出与自定义张量 (myarr / myconst) 连接起来。我可以使用固定的批处理大小指定所有内容，如下所示：
import numpy as np
import tensorflow as tf

BATCH_SIZE = 100
myarr = np.ones((10, 5))
myconst = tf.constant(np.tile(myarr, (BATCH_SIZE, 1, 1)))

# 模型定义
inputs = tf.keras.layers.Input((10,), batch_size=BATCH_SIZE)
x = tf.keras.layers.Embedding(10, 5)(inputs)
x = tf.keras.layers.Concatenate(axis=1)([x, myconst])
model = tf.keras.models.Model(inputs=inputs, output=x)

但是，如果我不要指定批处理大小和平铺我的数组，即仅以下...
myarr = np.ones((10, 5))
myconst = tf.constant(myarr)

# 模型定义
inputs = tf.keras.layers.Input((10,))
x = tf.keras.layers.Embedding(10, 5)(inputs)
x = tf.keras.layers.Concatenate(axis=1)([x, myconst])
model = tf.keras.models.Model(inputs=inputs, output=x)

... 我收到一个错误，指定形状 [(None, 10, 5), (10, 5)] 无法连接。有没有办法添加这个 None / batch_size 轴以避免平铺？
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/68345125/how-to-concatenate-a-tensor-to-a-keras-layer-along-batch-without-specifying-bat</guid>
      <pubDate>Mon, 12 Jul 2021 09:40:09 GMT</pubDate>
    </item>
    <item>
      <title>如何裁剪无人机拍摄的太阳能电池板？</title>
      <link>https://stackoverflow.com/questions/51414835/how-do-i-crop-the-solar-panels-captured-by-drone</link>
      <description><![CDATA[我目前正在从无人机拍摄的图像中裁剪太阳能电池板（附上示例图像）。我尝试过使用轮廓，但没有得到正确的结果。它没有检测到图像中的所有太阳能电池板，其中一些缺失了。我在这里遇到了麻烦。我该如何继续？请帮我解决这个问题。
谢谢，
示例代码：
import cv2
import numpy as np
img = cv2.imread(&#39;D:\\SolarPanel Images\\solarpanel.jpg&#39;)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray,(5,5),0)
edges = cv2.Canny(blur,100,200) 
th3 = cv2.adaptiveThreshold(edges,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)

im2, contours, Hierarchy = cv2.findContours(th3, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
print(&quot;Len of contours&quot;,len(contours)
try: Hierarchy = Hierarchy[0]
except: Hierarchy = []

height, width, = Edges.shape
min_x, min_y = width, height
max_x = max_y = 0

# 计算轮廓的边界框，并将其绘制在图像上，
for contour, hier in zip(contours, Hierarchy):
area = cv2.contourArea(contour)

if area &gt; 10000 and area &lt; 250000:
(x,y,w,h) = cv2.boundingRect(contour)
min_x, max_x = min(x, min_x), max(x+w, max_x)
min_y, max_y = min(y, min_y), max(y+h, max_y)
如果 w &gt; 80 且 h &gt; 80:
cv2.rectangle(img, (x,y), (x+w,y+h), (255, 0, 0), 2)

cv2.imshow(&#39;cont imge&#39;, img)
cv2.waitKey(0)

]]></description>
      <guid>https://stackoverflow.com/questions/51414835/how-do-i-crop-the-solar-panels-captured-by-drone</guid>
      <pubDate>Thu, 19 Jul 2018 05:18:40 GMT</pubDate>
    </item>
    <item>
      <title>FileNotFoundError：[WinError 3] 系统找不到指定的路径：</title>
      <link>https://stackoverflow.com/questions/51007476/filenotfounderror-winerror-3-the-system-cannot-find-the-path-specified</link>
      <description><![CDATA[我尝试运行此教程中的代码。我已将代码和数据集放在同一目录中，但仍然出现以下错误。
FileNotFoundError Traceback (most recent call last)
&lt;ipython-input-6-5f5284db0527&gt; in &lt;module&gt;()
39 # 从所有图像中提取特征
40 directory = &#39;Flicker8k&#39;
---&gt; 41 features = extract_features(directory)
42 print(&#39;Extracted Features: %d&#39; % len(features))
43 # 保存到文件

&lt;ipython-input-6-5f5284db0527&gt;在 extract_features(directory) 中
18 # 从每张照片中提取特征
19 features = dict()
---&gt; 20 for name in listdir(directory):
21 # 从文件加载图像
22 filename = directory + &#39;/&#39; + name

**FileNotFoundError: [WinError 3] 系统找不到指定的路径：&#39;Flicker8k&#39;**
]]></description>
      <guid>https://stackoverflow.com/questions/51007476/filenotfounderror-winerror-3-the-system-cannot-find-the-path-specified</guid>
      <pubDate>Sun, 24 Jun 2018 06:24:04 GMT</pubDate>
    </item>
    </channel>
</rss>