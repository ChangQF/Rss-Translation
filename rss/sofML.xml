<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 15 Aug 2024 06:22:31 GMT</lastBuildDate>
    <item>
      <title>不规则指数</title>
      <link>https://stackoverflow.com/questions/78873685/irregualr-index</link>
      <description><![CDATA[客户数据
数据集通过图像提供，请在阅读问题之前先参考所附图像
这里我用 OneHotEncoder 对性别列进行了编码
问题：我确实想仅对 Female[0] 列应用对数转换，但它对所有列都应用了对数转换，为什么？
代码：
import pandas as p
from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
import numpy as n
import seaborn as sns
import scipy.stats as sci
import matplotlib.pyplot as plt
customer=p.read_csv(&#39;/content/Customers.csv&#39;)
customer.drop([&#39;CustomerID&#39;,&#39;Profession&#39;,&#39;Family Size&#39;,&#39;Work Experience&#39;],axis=1,inplace=True)
import pandas as p
column=ColumnTransformer(
[
(&#39;ohe_gender&#39;,OneHotEncoder(sparse=False,dtype=n.int32),[0])
],remainder=&#39;passthrough&#39;
)
function=ColumnTransformer(
[
(&#39;function&#39;,FunctionTransformer(n.log1p),[0,1])
],remainder=&#39;passthrough&#39;
)
s=column.fit_transform(customer)
function.fit_transform(s)

输出
array([[0.00000000e+00, 6.93147181e-01, 1.90000000e+01,
1.50000000e+04,
3.90000000e+01],
[0.00000000e+00, 6.93147181e-01, 2.10000000e+01, 3.50000000e+04,
8.10000000e+01],
[6.93147181e-01, 0.00000000e+00, 2.00000000e+01, 8.60000000e+04,
6.00000000e+00],
...,
[0.00000000e+00, 6.93147181e-01, 8.70000000e+01, 9.09610000e+04,
1.40000000e+01],
[0.00000000e+00, 6.93147181e-01, 7.70000000e+01, 1.82109000e+05,
4.00000000e+00],
[0.00000000e+00, 6.93147181e-01, 9.00000000e+01, 1.10610000e+05,
5.20000000e+01]]

注意：在 FunctionTransformer 之前编码（OHE）后，o/p 是
array([[ 0, 1, 19, 15000, 39],
[ 0, 1, 21, 35000, 81],
[ 1, 0, 20, 86000, 6],
...,
[ 0, 1, 87, 90961, 14],
[ 0, 1, 77, 182109, 4],
[ 0, 1, 90, 110610, 52]])

（我确实想在上述数组的第 [0] 个索引中应用对数变换，但正如您在第一个 O/p 中看到的那样，它应用于所有值，尽管我在列变换器中指定了 [0]。为什么？
我希望您解决了这个问题。
我期望输出只有 [0] 个索引的对数。
insort 将 OHE 应用于 Gender 并仅在第 0 列上进行对数变换]]></description>
      <guid>https://stackoverflow.com/questions/78873685/irregualr-index</guid>
      <pubDate>Thu, 15 Aug 2024 04:58:50 GMT</pubDate>
    </item>
    <item>
      <title>你好！我如何确定机器学习模型的训练和测试准确度结果是好还是坏？</title>
      <link>https://stackoverflow.com/questions/78873404/hi-how-do-i-determine-the-train-and-test-accuracy-result-for-a-machine-learning</link>
      <description><![CDATA[我正在使用几种机器学习模型（例如 svm、ann、随机森林和 knn）对 covid 19 疫情进行预测。我很困惑如何比较哪个是准确度最高的模型，以及训练和测试准确度结果、均方误差和 r 平方。还有一个问题，训练和测试准确度结果通常首选的单位是什么？是百分比/整数还是小数点
对上述问题进行清晰解释]]></description>
      <guid>https://stackoverflow.com/questions/78873404/hi-how-do-i-determine-the-train-and-test-accuracy-result-for-a-machine-learning</guid>
      <pubDate>Thu, 15 Aug 2024 01:55:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在不使用 for 循环的情况下直接从 Claude API 对多个完成（n）进行采样？</title>
      <link>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</link>
      <description><![CDATA[我正在使用 Anthropic Claude API，并尝试在单个 API 调用中为给定的提示生成多个完成（n 个完成）。 OpenAI 的 API 在其采样设置中提供了一个 n 参数来实现这一点，但我在 Claude API 中找不到等效选项。
我目前的方法：
我目前正在使用重试机制来处理 API 调用期间的潜在错误，如下所示：
from tenacity import retry, stop_after_attempt, wait_exponential

def before_sleep(retry_state):
print(f&quot;(Tenacity) Retry, error that cause it: {retry_state.outcome.exception()}&quot;)

def retry_error_callback(retry_state):
exception = retry_state.outcome.exception()
exception_str = str(exception)
if &quot;prompt is too long&quot; in exception_str and &quot;400&quot;在 exception_str 中：
引发异常
返回“没有需要我们提前退出的错误。”

@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator, prompt: str) -&gt;; dict:
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n, # 旨在生成多个完成
stop_sequences=gen.sampling_params.stop[:3],
)
return response

问题：
我在 Anthropic API 中找不到 n 参数允许在一个请求中生成多个完成的文档。
问题：

Claude API 是否支持在单个 API 调用中直接生成多个完成（n 个完成）？
如果不支持，是否有推荐的解决方法或最佳实践来实现此目的，而无需循环多个请求？
任何指导或建议都将不胜感激！

cross discord：https://discord.com/channels/1072196207201501266/1213976011998498816/threads/1273440866861846549
cross：https://dev.to/brando90/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-loop-2m1e

现在这样做：
@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator，提示：str) -&gt; dict:
# max_tokens=8192, # Claude 3.5 的 max_tokens https://docs.anthropic.com/en/docs/about-claude/models#model-comparison
# client = anthropic.Anthropic(api_key=gen.api_key)
# response = client.messages.create(
# response_text: str = gen.llm.messages.create(
# model=gen.sampling_params.model,
# max_tokens=gen.sampling_params.max_tokens,
# #temperature=temperature, # 注意提示生成器不会将其作为输入
# system=gen.sampling_params.system,
# messages=[
# {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
# ],
#temperature=gen.sampling_params.temperature,
#top_p=gen.sampling_params.top_p,
#n=gen.sampling_params.n,
#stop=gen.sampling_params.stop[:3],
# ).content[0].text
if not hasattr(gen.sampling_params, &#39;n&#39;):
gen.sampling_params.n = 1
content: list[dict] = [] 
for _ in range(gen.sampling_params.n):
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n,
stop_sequences=gen.sampling_params.stop[:3],
)
content.append(response)
response = dict(content=content)
# 消息示例：https://docs.anthropic.com/en/api/messages-examples
返回响应
]]></description>
      <guid>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</guid>
      <pubDate>Thu, 15 Aug 2024 00:37:53 GMT</pubDate>
    </item>
    <item>
      <title>Python：为什么尽管使用了垃圾收集器，我的代码仍然泄漏内存？</title>
      <link>https://stackoverflow.com/questions/78872867/python-why-is-my-code-leaking-memory-despite-using-garbage-collector</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78872867/python-why-is-my-code-leaking-memory-despite-using-garbage-collector</guid>
      <pubDate>Wed, 14 Aug 2024 20:43:25 GMT</pubDate>
    </item>
    <item>
      <title>Python mediappe手部识别方块优化</title>
      <link>https://stackoverflow.com/questions/78872856/python-mediappe-hand-recognition-square-optimization</link>
      <description><![CDATA[所以 python 有 mediapupe lib，它提供了识别照片/视频上手的工具
我在我的项目中使用它。但我正在考虑优化 - 所以它会运行得更快。
我们知道，如果在 1 帧上有一只手 - 它在另一帧中不会太远 - 所以没有必要重复整个照片 - 手周围的区域就足够了（包括测量它的角速度和径向速度）
mediapype 是否包含一些优化方法？或者它只是愚蠢地让代码愚蠢地检查整张照片？
我还没有搜索过有关这方面的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78872856/python-mediappe-hand-recognition-square-optimization</guid>
      <pubDate>Wed, 14 Aug 2024 20:38:41 GMT</pubDate>
    </item>
    <item>
      <title>python：“顺序”层需要 1 个输入，但它收到了 48 个输入张量</title>
      <link>https://stackoverflow.com/questions/78872766/python-layer-sequential-expects-1-inputs-but-it-received-48-input-tensors</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78872766/python-layer-sequential-expects-1-inputs-but-it-received-48-input-tensors</guid>
      <pubDate>Wed, 14 Aug 2024 20:06:08 GMT</pubDate>
    </item>
    <item>
      <title>语法错误：无效的不可打印字符 U+00A0</title>
      <link>https://stackoverflow.com/questions/78872236/syntaxerror-invalid-non-printable-character-u00a0</link>
      <description><![CDATA[我想建立一个基本的逻辑回归模型，但当我尝试将数据输入模型时，出现了不可打印字符错误
model.fit(X_train, y_train
SyntaxError: 无效的不可打印字符 U+00A0
我试图建立逻辑回归模型]]></description>
      <guid>https://stackoverflow.com/questions/78872236/syntaxerror-invalid-non-printable-character-u00a0</guid>
      <pubDate>Wed, 14 Aug 2024 17:20:55 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用图像分类来自动检测网页是否正常显示吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78870242/can-i-use-image-classification-to-automatically-detect-if-a-web-page-is-display</link>
      <description><![CDATA[在自动化测试中，有些情况需要手动检查截图，判断页面在窗口大小改变时是否存在缺页、文字溢出等异常情况。
我想训练一个图像分类的模型来检查网页，但是我没有截断或重叠或页面丢失等情况的截图……不知道这种方式可行吗？]]></description>
      <guid>https://stackoverflow.com/questions/78870242/can-i-use-image-classification-to-automatically-detect-if-a-web-page-is-display</guid>
      <pubDate>Wed, 14 Aug 2024 09:47:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML 算法对图像进行分类时，如何修复“找到具有 dim 4 的数组”错误</title>
      <link>https://stackoverflow.com/questions/78869863/how-fix-found-array-with-dim-4error-when-using-ml-algorthims-to-classify-image</link>
      <description><![CDATA[我有一个简单的 ML 分类问题。我有 8 个文件夹，每个文件夹代表一个类，因此我首先从文件夹中加载这些图像并分配标签，然后将其保存为 csv 文件（代码如下）
def load_images_from_folder(root_folder):
image_paths = []
images = []
labels = []
for label in os.listdir(root_folder):
label_path = os.path.join(root_folder, label)
if os.path.isdir(label_path):
for filename in os.listdir(label_path):
img_path = os.path.join(label_path, filename)
if os.path.isfile(img_path) and (filename.endswith(&quot;.jpg&quot;):
img = Image.open(img_path)
img = img.resize((128, 128))
img_array = np.array(img)
image_paths.append(img_path)
images.append(img_array)
labels.append(label)
return image_paths, images, labels
if __name__ == &quot;__main__&quot;:
root_folder_path = &quot;./Datasets_1&quot;
image_paths, images, labels = load_images_from_folder(root_folder_path)

然后我将图像和标签转换为 DataFrame 并加载它
data = {&quot;Images&quot;: image_paths, &quot;Labels&quot;: labels}
df = pd.DataFrame(data)
df.to_csv(&quot;original_data.csv&quot;, index=False)
csv_file = &quot;original_data.csv&quot;
df = pd.read_csv(csv_file)

我还将向 DataFrame 添加一个带有编码标签的新列“Encoded_Labels”，并将“Encoded_Labels”列转换为整数
df[&#39;Encoded_Labels&#39;] =coded_labels
df[&#39;Encoded_Labels&#39;] = df[&#39;Encoded_Labels&#39;].astype(int)

最后，我将数据集拆分为训练集和测试集，并对训练图像进行预处理
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)
def load_and_preprocess_images(file_paths, target_size=(128, 128)):
images = []
for file_path in file_paths:
img = Image.open(file_path)
img = img.resize(target_size)
img_array = np.array(img) / 255.0 # 标准化像素值
images.append(img_array)
return np.array(images)

X_train = load_and_preprocess_images(train_df[&#39;Images&#39;].values)
y_train = train_df[&#39;Encoded_Labels&#39;].values
X_test = load_and_preprocess_images(test_df[&#39;Images&#39;].values)
y_test = test_df[&#39;Encoded_Labels&#39;].values**your text**

X_train 的输出形状为
(20624, 128, 128, 3)

对于这一点，我没有问题，我可以使用它使用 DL 模型没有问题，但是尝试使用 ML 模型（例如 KNN、SVM、DT 等）时。示例代码如下
from sklearn.svm import SVC
svc = SVC(kernel=&#39;linear&#39;,gamma=&#39;auto&#39;)
svc.fit(X_train, y_train)`

或
knn_clf = KNeighborsClassifier()
knn_clf.fit(X_train, y_train)
y_pred = knn_clf.predict(X_test)
accuracy = metrics.accuracy_score(y_test, y_pred)
print(&quot;Accuracy of KNN Classifier : %.2f&quot; % (准确率*100))

我收到此错误
ValueError：找到 dim 为 4 的数组。SVC 预期 &lt;= 2。

如何修复此错误？]]></description>
      <guid>https://stackoverflow.com/questions/78869863/how-fix-found-array-with-dim-4error-when-using-ml-algorthims-to-classify-image</guid>
      <pubDate>Wed, 14 Aug 2024 08:26:27 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn 版本不匹配问题。我不知道应该安装哪个版本</title>
      <link>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</link>
      <description><![CDATA[我正在努力解决涉及 Scikit-learn 的版本不匹配问题。每当我尝试安装不同版本的 Scikit-learn 时，我都会遇到一系列错误，这些错误似乎因我尝试的每个版本而异。

问题的核心似乎是 Scikit-learn 与其依赖项（例如 NumPy 和 SciPy）之间的不兼容性。这些依赖项对于 Scikit-learn 正常运行至关重要，找到可以协同工作的正确版本已成为一项艰巨的任务。尽管我付出了努力，但我还是无法找到一个可以解决错误并与我现有设置很好地集成的 Scikit-learn 版本。反复试验的过程只会导致越来越多的挫败感，因为每个新版本都会带来一系列问题，而不是解决核心问题。
这个版本不匹配严重影响了我在项目中有效使用 Scikit-learn 的能力。缺乏关于将 Scikit-learn 与其依赖项的兼容版本对齐的明确指导增加了我的困难，使我很难继续工作并实现预期结果。]]></description>
      <guid>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</guid>
      <pubDate>Wed, 14 Aug 2024 04:15:49 GMT</pubDate>
    </item>
    <item>
      <title>如何为二进制数据集实现自动编码器？</title>
      <link>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset</link>
      <description><![CDATA[我被要求创建一个自动编码器，用于重建二进制 CSV 文件（解码）。
我根据 geeksforgeeks 中的 MNIST 示例实现了一个。但我对正确性非常不确定，包括损失的计算以及 relu 和线性部分。我做了一些研究，似乎在这种情况下 BCEloss 也比 MSEloss 更好。
有什么建议吗？
以下代码可以生成输出，但损失非常小。建议的批量大小、隐藏维度层和时期数是多少。

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# 设置随机种子以实现可重复性
np.random.seed(42)
torch.manual_seed(42)

# 生成玩具数据：D = 100 名患者，K = 10 个表型，二进制值（0 或 1）
D，K = dm.shape
#data = np.random.randint(0, 2, size=(D, K)).astype(np.float32)

# 将 numpy 数组转换为 PyTorch 张量
data_tensor = torch.tensor(dm)
print(data_tensor.shape)

# 定义 Autoencoder 模型
class Autoencoder(nn.Module):
def __init__(self, input_dim, hidden_​​dim):
super(Autoencoder, self).__init__()
# 编码器
self.encoder = nn.Sequential(
nn.Linear(input_dim, hidden_​​dim),
nn.ReLU()
)
# 解码器
self.decoder = nn.Sequential(
nn.Linear(hidden_​​dim, input_dim),
nn.Sigmoid()
)

def forward(self, x):
coded = self.encoder(x)
coded = self.decoder(encoded)
returncoded

# 超参数
input_dim = K
hidden_​​dim = 5 # 隐藏层维度，需要调整

# 初始化模型、损失函数和优化器
model = Autoencoder(input_dim=input_dim, hidden_​​dim=hidden_​​dim)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练参数
num_epochs = 5
batch_size = 10

# 训练循环
for epoch in range(num_epochs):
for i in range(0, D, batch_size):
batch_data = data_tensor[i:i+batch_size]

# 正向传递
outputs = model(batch_data)
loss = criterion(outputs, batch_data)

# 反向传递和优化
optimizer.zero_grad() 
loss.backward()
optimizer.step()

#print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss}&#39;)
if (epoch+1) % 10 == 0:
print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}&#39;)

# 通过重建输入数据测试模型
with torch.no_grad():
reconstructed = model(data_tensor)

print(&quot;Original Data:&quot;)
print(data_tensor)

print(&quot;Reconstructed Data:&quot;)
print(reconstructed)
]]></description>
      <guid>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset</guid>
      <pubDate>Wed, 14 Aug 2024 00:44:26 GMT</pubDate>
    </item>
    <item>
      <title>runs\train\exp10 不是目录</title>
      <link>https://stackoverflow.com/questions/78868439/runs-train-exp10-is-not-a-directory</link>
      <description><![CDATA[我试图在自己的计算机上使用自定义数据训练 YoloV5 模型，但一直出现此错误：
train: weights=yolov5s.pt, cfg=models/yolov5s.yaml, data=data.yaml, hyp=data\hyps\hyp.scratch-low.yaml, epochs=300, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, worker=8, project=runs\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, waiting=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False
github：跳过检查（不是 git 存储库），有关更新，请参阅 https://github.com/ultralytics/yolov5
YOLOv5 2024-7-15 Python-3.12.2 torch-2.3.1+cpu CPU
超参数：lr0=0.01, lrf=0.01, motivation=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, Translation=0.1, scale=0.5, sheath=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
TensorBoard：以“tensorboard --logdir runs\train”开始，在 http://localhost:6006/ 查看
回溯（最近一次调用）：
文件&lt;module&gt; 中的“C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py”，第 986 行
main(opt)
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py&quot;，第 688 行，在 main 中
train(opt.hyp, opt, device, callbacks)
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\train.py&quot;，第 180 行，在 train 中
loggers = Loggers(
^^^^^^^^^
文件 &quot;C:\Users\Usuário\yolov5_work2024\yolov5-master\utils\loggers\__init__.py&quot;，第 121 行，在 __init__ 中
self.tb = SummaryWriter(str(s))
^^^^^^^^^^^^^^^^^^^^^^
文件&quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 249 行，在 __init__ 中
self._get_file_writer()
文件 &quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 281 行，在 _get_file_writer 中
self.file_writer = FileWriter(
^^^^^^^^^^^
文件 &quot;C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\utils\tensorboard\writer.py&quot;，第 75 行，在 __init__ 中
self.event_writer = EventFileWriter(**
^^^^^^^^^^^^^^^^^
文件“C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorboard\summary\writer\event_file_writer.py”，第 72 行，在 __init__ 中
tf.io.gfile.makedirs(logdir)
文件“C:\Users\Usuário\AppData\Local\Programs\Python\Python312\Lib\site-packages\tensorflow\python\lib\io\file_io.py”，第 513 行，在 recursive_create_dir_v2 中
_pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))
tensorflow.python.framework.errors_impl.FailedPreconditionError: runs\train\exp10 不是目录

我尝试从预先训练的模型训练我的模型（正如 yolov5 文档所推荐的那样），如下所示：
python train.py --img 640 --batch 32 --epochs 300 --data data.yaml --weights yolov5s.pt
或者从头开始，如下所示：
python train.py --img 640 --batch 32 --epochs 300 --data data.yaml --cfg models/yolov5s.yaml
我还看到了其他问题，例如 GitHub 上的问题 #12008 和 Stack Overflow 上的这个问题 tensorflow.python.framework.errors_impl.FailedPreconditionError: runs\train\exp3 不是目录，但还没有找到任何解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78868439/runs-train-exp10-is-not-a-directory</guid>
      <pubDate>Tue, 13 Aug 2024 21:58:27 GMT</pubDate>
    </item>
    <item>
      <title>YOLOV8 创建了太多边界框[重复]</title>
      <link>https://stackoverflow.com/questions/78867501/yolov8-creating-too-many-bounding-boxes</link>
      <description><![CDATA[我使用 yoloV8 训练了一个模型，该模型有助于检测摩托车骑手的头盔，并尝试通过创建虚拟环境 venv 并安装以下软件包 numpy opencv-python tensorflow ultralytics 来运行
起初，它向我显示了错误

OSError：[WinError 126] 找不到指定的模块。加载“D:\ACADEMICS\projects\helmet\venv\Lib\site-packages\torch\lib\fbgemm.dll”时出错或其依赖项之一。

通过在安装过程中下载 Visual Studio 2022 社区版 并安装 C++ 桌面环境 解决了缺少文件的问题。
但是现在在随机位置创建的边界框太多了。
当前输出：

预期结果：


已编辑 == 在下面添加了代码

import cv2
from ultralytics import YOLO

model = YOLO(&quot;runs/detect/train2/weights/best.pt&quot;)

results = model.predict(source=&#39;download.jpeg&#39;, show = True, save=True)
]]></description>
      <guid>https://stackoverflow.com/questions/78867501/yolov8-creating-too-many-bounding-boxes</guid>
      <pubDate>Tue, 13 Aug 2024 16:57:54 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 nltk 函数</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>ML 查找四边形的角</title>
      <link>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</link>
      <description><![CDATA[我的作业是使用 ML 模型找到四边形角的 4 个点。有时四边形的一个角会丢失（例如页面的折叠角）。
首先，我尝试使用 MobileNetV3Small 作为主干进行图像分割，因为该模型应该小而快。效果很好，但找到角仍然是一个问题。我曾尝试按照官方 keras 关键点检测、中等教程和许多其他来源等示例查找图像的关键点，但似乎对我都不起作用。我尝试过多次修改它们。损失函数在测试和验证中都下降了，但输出甚至没有接近所需的位置。也尝试了类似下面的方法：
def conv(model, size, conv2d_kernel, dilation_rate=(1, 1), pooling_size=(2, 2)):
model.add(Conv2D(size, conv2d_kernel, dilation_rate=dilation_rate))
model.add(Activation(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=max_pooling))
model.add(Dropout(0.1))

def density(model, unit):
model.add(Dense(units))
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.1))

model = Sequential()
model.add(InputLayer(shape=(224, 224, 3)))

conv(model, size=32, conv2d_kernel=(2, 2))
conv(model, size=64, conv2d_kernel=(3, 3))
conv(model, size=128, conv2d_kernel=(3, 3))

model.add(Flatten())
dense(model, 20)
dense(model, 20)

model.add(Dense(8))
model.compile(optimizer=RMSprop(),
loss=losses.MeanSquaredLogarithmicError(),
metrics=[metrics.MeanAbsoluteError()])

还尝试了输出形状 (8) 和 (4,2)，但似乎没有任何效果。任何帮助都将不胜感激。
PS：还忘记补充一点，数据集的注释是正确的，或者至少这是我在图表上看到的。还尝试将坐标标准化为 0 到 1 之间。我的输入是 (224,224,3)。]]></description>
      <guid>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</guid>
      <pubDate>Sat, 13 Apr 2024 20:06:34 GMT</pubDate>
    </item>
    </channel>
</rss>