<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 27 Aug 2024 09:16:42 GMT</lastBuildDate>
    <item>
      <title>需要机器学习项目工作流程方面的帮助 [关闭]</title>
      <link>https://stackoverflow.com/questions/78917544/need-help-in-ml-project-workflow</link>
      <description><![CDATA[我正在做一个与日志相关的项目。我需要解析日志并将它们缩短为某种模式（日志不断出现）。然后我想用我在某些日志序列之后得到的错误日志来标记每个日志序列。问题是错误有很多种类型。我首先考虑对错误进行聚类，然后从中制作出一定数量的标签（聚类）。然后我想用它们的错误类型来标记非错误日志序列。然后我想用这些数据训练模型，以预测特定日志流可能发生的最可能错误。
有人可以补充和帮助吗？请给我任何你认为对我最好的建议，或者在必要时纠正我。
我正在尝试对所有错误进行聚类，因为我想要有限数量的标签来进行监督学习。我在缩短文本日志数据方面遇到了问题，因为它太大了。]]></description>
      <guid>https://stackoverflow.com/questions/78917544/need-help-in-ml-project-workflow</guid>
      <pubDate>Tue, 27 Aug 2024 07:07:20 GMT</pubDate>
    </item>
    <item>
      <title>测试集和训练集的性能相似，但验证集上的性能差别很大[关闭]</title>
      <link>https://stackoverflow.com/questions/78917504/performance-of-the-test-set-and-the-training-set-is-similar-but-the-performance</link>
      <description><![CDATA[测试集和训练集的性能相似，但验证集的性能差异很大。
我使用的所有变量都与日期时间无关，但我在 sklearn 中训练的所有模型仍然面临这个问题。
例如，训练集中的 R2 = 0.7，测试集中的 R2 = 0.68。然而，当我在验证集中应用模型时，R2 下降到 0.5。
有什么原因或解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/78917504/performance-of-the-test-set-and-the-training-set-is-similar-but-the-performance</guid>
      <pubDate>Tue, 27 Aug 2024 06:57:15 GMT</pubDate>
    </item>
    <item>
      <title>计算高效的国际象棋解算器</title>
      <link>https://stackoverflow.com/questions/78917392/compute-efficient-chess-solvers</link>
      <description><![CDATA[alphago/muzero 系列广为人知，但超人国际象棋解算器是在许多专门的 TPU 上训练的。
是否有计算效率高的国际象棋解算器的方法（或论文参考），即在使用一个标准 GPU 进行训练的约束下可以玩得相当好的国际象棋解算器？]]></description>
      <guid>https://stackoverflow.com/questions/78917392/compute-efficient-chess-solvers</guid>
      <pubDate>Tue, 27 Aug 2024 06:26:32 GMT</pubDate>
    </item>
    <item>
      <title>运行 plumber API 时返回多个值</title>
      <link>https://stackoverflow.com/questions/78916863/returning-multiple-values-when-running-plumber-api</link>
      <description><![CDATA[我使用 R 中的 caret 库创建了 xgboost 模型。当我在 plumber 中运行此模型时，Swagger 响应主体中会出现数据库的所有预测。我只想要一个预测。与模型变量的插入类别相对应的预测。下面是我的 API 示例
model &lt;- readRDS(&#39;model_xgb.rds&#39;)

#\* param var1
#\* param var2
#\* param var3
#\* param var4
#\* get/prediction

function(var1,var2,var3,var4)

{
data&lt;-
tibble(
var1=as.factor(var1),
var2=as.factor(var2),
var3=as.factor(var3),
var4=as.factor(var4)
)

predict(model,new_data=data, type=&#39;prob&#39;) %&gt;% pluck(1)

}

Plumber is返回：
[
{&quot;0&quot;:0.9152,
&quot;1&quot;:0.0848
},
{&quot;0&quot;:0.5379,
&quot;1&quot;:0.4621
},
{&quot;0&quot;:0.9912,
&quot;1&quot;:0.0088
}
.
.
.
]

我只想要一个结果]]></description>
      <guid>https://stackoverflow.com/questions/78916863/returning-multiple-values-when-running-plumber-api</guid>
      <pubDate>Tue, 27 Aug 2024 02:30:17 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试通过 cmd 运行设置代码时出现 Python 错误</title>
      <link>https://stackoverflow.com/questions/78916659/python-error-when-im-trying-to-run-a-set-code-by-cmd</link>
      <description><![CDATA[有一次，我看到一则广告，介绍如何用 Python 制作一个由 AI 生成的冒险游戏，于是我去 YouTube 查看了视频。虽然视频已经过时了，但我还是跟得上。但是当我尝试运行从此处下载的一组 Python 代码时，特别是
from cassandra.cluster import Cluster

我收到错误：
Traceback（最近一次调用最后一次）：
文件“C:\Users\xxxxx\Desktop\My_Database\tutorial.py”，第 1 行，位于&lt;module&gt;
从 cassandra.cluster 导入 Cluster
文件“cassandra\cluster.py”，第 173 行，位于 init cassandra.cluster
cassandra.DependencyException：无法加载默认连接类
观察到以下异常：
- 未找到使用 libev 所需的 C 扩展。这可能意味着您在安装驱动程序时没有所需的构建依赖项。请参阅 http://datastax.github.io/python-driver/installation.html#c-extensions，了解有关安装构建依赖项和构建 C 扩展的说明。
- 无法导入 asyncore 模块。请注意，此模块已在 Python 3.12 中删除，因此当使用此版本（或任何更新版本）的驱动程序时，您将需要使用其他事件循环实现之一。

尽管我搜索了这个问题，发现了很多类似的问题都得到了解决，但是它们都没有为我解决问题，所以我来这里希望有人能解决我的问题。
当我运行代码时，我希望它会像视频显示的那样工作，但事实并非如此。尽管我搜索了这个问题，发现了很多类似的问题都得到了解决，但是它们都没有为我解决问题，所以我来这里希望有人能解决我的问题。]]></description>
      <guid>https://stackoverflow.com/questions/78916659/python-error-when-im-trying-to-run-a-set-code-by-cmd</guid>
      <pubDate>Tue, 27 Aug 2024 00:23:56 GMT</pubDate>
    </item>
    <item>
      <title>放大第 2 代预测转录设置</title>
      <link>https://stackoverflow.com/questions/78916597/amplify-gen-2-predictions-transcribe-set-up</link>
      <description><![CDATA[我尝试在我的 React Native 应用中设置 Amplify Gen 2 Predictions 转录，但一直收到 转录错误：[NoRegion：缺少区域。]，但我似乎找不到在哪里添加该信息。
这是我目前的设置：
backend.ts
从“@aws-amplify/backend”导入 { defineBackend }；
从“./auth/resource”导入 { auth }；
从“./data/resource”导入 { data }；
从“aws-cdk-lib”导入 { Stack }；
从“aws-cdk-lib/aws-iam”导入 { PolicyStatement }；

const backend = defineBackend({
auth,
data,
});

// 为所需用例配置策略。
// 下面包含的操作涵盖所有支持的 ML 功能
backend.auth.resources.unauthenticatedUserIamRole.addToPrincipalPolicy(
new PolicyStatement({
action: [
&quot;translate:TranslateText&quot;,
&quot;polly:SynthesizeSpeech&quot;,
&quot;transcribe:StartStreamTranscriptionWebSocket&quot;,
],
resources: [&quot;*&quot;],
})
);

backend.addOutput({
custom: {
Predictions: {
convert: {
TranslationText: {
defaults: {
sourceLanguage: &quot;en&quot;,
targetLanguage: &quot;es&quot;,
},
proxy: false,
region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
.region,
},
transcription: {
defaults: {
language: &quot;en-US&quot;,
},
proxy: false,
region: Stack.of(backend.auth.resources.unauthenticatedUserIamRole)
.region,
},
},
},
},
});

我如何使用它：
 const transcribeAudio = async (audioBytes) =&gt; {
try {
const { transcription } = await Predictions.convert({
region: &quot;us-east-1&quot;,
transcription: {
source: {
bytes: audioBytes,
},
},
});
console.log(&quot;Transcription:&quot;, transcription);
// 处理转录结果（例如，将其设置为状态、显示它等）
} catch (error) {
console.error(&quot;Transcription error:&quot;, error);
}
};
]]></description>
      <guid>https://stackoverflow.com/questions/78916597/amplify-gen-2-predictions-transcribe-set-up</guid>
      <pubDate>Mon, 26 Aug 2024 23:38:28 GMT</pubDate>
    </item>
    <item>
      <title>Fairmot 重新实现 reid 过度拟合？</title>
      <link>https://stackoverflow.com/questions/78916378/fairmot-reimplementation-reid-overfitting</link>
      <description><![CDATA[我正在以一种非常简化的方式重新实现 Fairmot，我喜欢他们的工作，但我对机器学习还很陌生，我很难理解为什么在对 mot17、prw、cuhksysu 和部分加州理工学院行人进行训练时，reid 分支似乎立即过度拟合，而训练损失似乎以正常方式减少。
我想到了一些动机：

我的数据比原始项目少，所以模型在 reid 上过度拟合

我正在对他们的工作进行简化的增强，没有旋转，没有裁剪，所以这意味着我的数据更少，或者至少我的数据集中的变化更少

我搞砸了 id 损失，但我几乎复制粘贴了他们的函数，所以 :)

我使用的模型有点不同，可能对于任务来说太简单了（一直被教导更简单-&gt;更少的过度拟合，无论如何我使用双线性插值进行上采样而不是逆卷积，因为我无法消除棋盘效应）

验证代码实现得很糟糕，但我试图在训练集上进行验证，结果与训练一致损失

我搞砸了一些我无法理解的事情


我在这里发布了我正在重新实现模型的 colab 笔记本，如果你有空闲时间并愿意帮助我，那就太好了！
此外，如果我的代码正确，我正在模型部分加载 crowdhuman 上的预训练，并且我已经修改了数据集以具有不重叠的 id。
这是我的 colab，Google 限制了数据集的下载次数，无论如何它应该可以正常运行，如果不是，对不起。
https://colab.research.google.com/drive/1EVR3S6Qd0sFeRbhCYiZo5xtPZXYHsOvA?usp=sharing
哦，我在这里发布了我正在使用的 id 损失：
class IdLoss(nn.Module):
def init(self,n_id):
super(IdLoss, self).init()
device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
self.id_classifier = nn.Linear(id_vect_size, int(n_id+1),device=device)
self.cross_entr_loss=nn.CrossEntropyLoss(ignore_index=-1)
self.dropout = nn.Dropout(0.3)

def forward(self, id_output, ind_target, mask_target, id_targets):
id_vectors = gather_feat(id_output, ind_target)
id_vectors = id_vectors[mask_target &gt; 0].contiguous()
id_vectors = F.normalize(id_vectors)
id_targets = id_targets[mask_target &gt; 0].contiguous()
id_logits = self.id_classifier(id_vectors)

return self.cross_entr_loss(id_logits, id_targets)

我尝试了空间 dropout、限制 reid 向量大小、添加增强、不同的数据集大小（但最多 45000 张图像）我添加了 50% 的对原始图像执行增强的可能性，我简化了模型，改变了学习率。无法使 reid 损失表现良好。]]></description>
      <guid>https://stackoverflow.com/questions/78916378/fairmot-reimplementation-reid-overfitting</guid>
      <pubDate>Mon, 26 Aug 2024 21:44:44 GMT</pubDate>
    </item>
    <item>
      <title>如何从头开始训练已训练好的变压器模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78916326/how-to-train-trained-transformer-models-from-scratch</link>
      <description><![CDATA[对于某些实验，我想采用预训练模型，例如这个或这个，并重新初始化它们，以便我可以在我的数据集上从头开始训练它们。主要目标是只使用它们的架构，而不是权重。我该怎么做？
似乎我可以使用不同的配置初始化（例如，LlamaConfig），但有没有更通用的方法，初始化训练好的模型，然后打乱它们的权重以获得相同的随机权重初始化？使用不同配置初始化的问题在于，我不完全了解每个模型的确切架构。]]></description>
      <guid>https://stackoverflow.com/questions/78916326/how-to-train-trained-transformer-models-from-scratch</guid>
      <pubDate>Mon, 26 Aug 2024 21:19:47 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow-federated 0.86.0.. AttributeError: 模块‘tensorflow_federated.python.learning’没有属性‘build_federated_averaging_process</title>
      <link>https://stackoverflow.com/questions/78916201/tensorflow-federated-0-86-0-attributeerror-module-tensorflow-federated-pytho</link>
      <description><![CDATA[
AttributeError Traceback（最近一次调用最后一次）
在&lt;cell line: 1&gt;()
----&gt; 1 trainer = tff.learning.build_federated_averaging_process(
2 model_fn,
3 client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.01),
4 server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.05)#learning_rate=0.01
5 )
AttributeError: module &#39;tensorflow_federated.python.learning&#39; 没有属性 &#39;build_federated_averaging_process&#39;
我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78916201/tensorflow-federated-0-86-0-attributeerror-module-tensorflow-federated-pytho</guid>
      <pubDate>Mon, 26 Aug 2024 20:32:53 GMT</pubDate>
    </item>
    <item>
      <title>如何提高图像字幕模型字幕的质量和描述性</title>
      <link>https://stackoverflow.com/questions/78916109/how-to-improve-the-quality-and-descriptiveness-of-image-captioning-model-caption</link>
      <description><![CDATA[我正在开发一个服装图像字幕模型，并正在创建自己的训练数据集。目前它有大约 300 张图片，总共大约 1300 个字幕。我知道这个数据集很小，但在测试期间，模型输出的字幕是非描述性的，例如“短袖衬衫”，而大多数训练示例是“黑色短袖图案衬衫”或“带有白色地狱开始世界文字的黑色衬衫”，那么为什么模型的输出和训练示例会有如此大的差异。我也不清楚如何让模型预测衬衫上的文字，以进行样本外预测。
我的模型是这样的：
from tensorflow.keras.models import Model

input1 = Input(shape=(1920,)) 
input2 = Input(shape=(max_length,)) 

img_features = Dense(256,activation=&#39;relu&#39;)(input1) 
img_features = Dropout(0.5)(img_features)
img_features_flattened = Flatten()(img_features)
img_features_repeated = RepeatVector(max_length)(img_features_flattened)

sentence_features = Embedding(vocab_size, 256, mask_zero=False)(input2) 
sentence_features = Dropout(0.5)(sentence_features)

attention = MultiHeadAttention(
num_heads=8, # 注意力头的数量
key_dim=256 # 注意力键的维度
)(query=sentence_features, value=img_features_repeated, key=img_features_repeated)

context =tention

merged = concatenate([context, sentence_features])

sentence_features = LSTM(256)(merged)
x = Dropout(0.5)(sentence_features)

x = add([x, img_features_flattened])
x = Dense(128,activation=&#39;relu&#39;)(x)
x = Dropout(0.5)(x)

output = Dense(vocab_size,activation=&#39;softmax&#39;)(x)

caption_model = Model(inputs=[input1, input2], output=output)
caption_model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;adam&#39;)

这就是我定义训练和验证集的方式，这会导致模型无法预测样本之外的服装品牌的文本吗？
tokenizer.fit_on_texts(captions)
vocab_size = len(tokenizer.word_index) + 1
max_length = max(len(caption.split()) for caption in captions)

images = data[&#39;image&#39;].unique().tolist()
nimages = len(images)

split_index = round(0.9*nimages)
train_images = images[:split_index]
val_images = images[split_index:]

train = data[data[&#39;image&#39;].isin(train_images)]
test = data[data[&#39;image&#39;].isin(val_images)]

train.reset_index(inplace=True,drop=True)
test.reset_index(inplace=True,drop=True)


我使用了以下方法：温度调整和核采样。这两种方法都改善了结果，但我仍在寻找更多方法]]></description>
      <guid>https://stackoverflow.com/questions/78916109/how-to-improve-the-quality-and-descriptiveness-of-image-captioning-model-caption</guid>
      <pubDate>Mon, 26 Aug 2024 19:58:39 GMT</pubDate>
    </item>
    <item>
      <title>由于尺寸不相等，处理化学分子原子时出现批处理错误</title>
      <link>https://stackoverflow.com/questions/78913966/batching-error-when-processing-chemical-molecule-atoms-because-sizes-not-equal</link>
      <description><![CDATA[我正在设计一个可以根据节点特征、边缘特征预测属性的神经网络。但是，当我尝试将批处理大小设置为大于 1 时，事情就出错了。分子中的原子数不同，因此在将多个分子批处理在一起时会导致错误。更具体地说，将出现以下错误：
RuntimeError：堆栈期望每个张量大小相等，但在条目 0 处得到 [6, 25] 
而在条目 1 处得到 [8, 25]

。6 和 8 表示该分子中有 6/8 个原子，25 表示每个原子有 25 个特征。有没有比根据另一个类似问题添加零来调整大小更好的解决方案，因为分子的大小可能高达 30 或更多。
重现此问题的代码如下：
def mol_to_graph(smiles):
&quot;&quot;&quot;将 SMILES 字符串转换为分子图。&quot;&quot;&quot;
mol = Chem.MolFromSmiles(smiles)
AllChem.Compute2DCoords(mol)

node_features = []
for atom in mol.GetAtoms():
node_features.append(atom.GetAtomicNum())

edge_indices = []
edge_features = []

for bond in mol.GetBonds():
i = bond.GetBeginAtomIdx()
j = bond.GetEndAtomIdx()
edge_indices.append((i, j))
edge_indices.append((j, i))
edge_features.append(bond_features(bond))
edge_features.append(bond_features(bond))
node_features = torch.tensor(node_features)
edge_indices = torch.tensor(edge_indices).t().contiguous()
edge_features = torch.tensor(edge_features)
return node_features, edge_indices, edge_features
class MolecularDataset(Dataset):
def __init__(self, smiles_list, property):
self.smiles_list = smiles_list
self.property = property

def __len__(self):
return len(self.smiles_list)

def __getitem__(self, idx):
smiles = self.smiles_list[idx]
property = self.property[idx]
node_feat, edge_index, edge_attr = mol_to_graph(smiles)
return node_feat, edge_index, edge_attr, torch.tensor(property, dtype=torch.float32)
train_dataset = MolecularDataset(smiles.tolist(), property.tolist())
train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
model = TheModel(node_feat_dim, edge_feat_dim, global_feat_dim, hidden_​​dim).to(device)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.MSELoss()
for i in tqdm(range(25)):
for node_feat, edge_index, edge_attr, target in train_loader:
node_feat, edge_index, edge_attr, target = node_feat.to(device), edge_index.to(device), edge_attr.to(device), target.to(device)
node_feat = node_feat.squeeze(0)
edge_index = edge_index.squeeze(0)
edge_attr = edge_attr.squeeze(0)
target = target.squeeze(0)
global_feat = torch.randn((1, global_feat_dim)).to(device)

_, _, global_feat_pred = model(node_feat, edge_attr, edge_index, global_feat)
pred.append(global_feat_pred.squeeze())
]]></description>
      <guid>https://stackoverflow.com/questions/78913966/batching-error-when-processing-chemical-molecule-atoms-because-sizes-not-equal</guid>
      <pubDate>Mon, 26 Aug 2024 10:39:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在决策树中使用直方图实现分箱条件？</title>
      <link>https://stackoverflow.com/questions/78911846/how-to-implement-a-condition-for-binning-using-histogram-in-decision-tree</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78911846/how-to-implement-a-condition-for-binning-using-histogram-in-decision-tree</guid>
      <pubDate>Sun, 25 Aug 2024 17:28:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOv8 进行大量错误检测</title>
      <link>https://stackoverflow.com/questions/78820748/a-lot-of-incorrect-detection-using-yolov8</link>
      <description><![CDATA[我尝试使用 Visual Code Studio 运行 YOLOv8。安装了 ultralytics 并在 vs code 终端上运行了 yolo predict model=yolov8n.pt source=&#39;https://ultralytics.com/images/bus.jpg&#39;。
但是我收到的输出是
2 个人、1 辆自行车、5 辆汽车、10 辆摩托车、73 艘船、3 个停车标志、1 只狗、10 匹马、10 头牛、32 只熊、1 只长颈鹿、63 把雨伞、6 个手提包、9 个飞盘、15 块滑雪板、5 块冲浪板、12 把刀、5 张床、37 张餐桌

这些显然不是这张图片的一部分。

当我第一次安装 ultralytics 并尝试运行 torch 时，出现了缺少依赖项的错误。fbgemm.ddl 丢失。后来，当我安装 vs_BuildTools 时，这个问题得到了解决。然后我继续在虚拟环境中运行代码，其中使用 torch 的程序运行没有任何错误。然后我继续输入此代码片段并遇到此问题。我也尝试使用命令提示符和 jupyter 笔记本运行，但同样的问题仍然存在。
我也检查了版本是否兼容，结果是兼容的。我还没有安装 cuda，是因为这个原因还是还有其他我不知道的问题？]]></description>
      <guid>https://stackoverflow.com/questions/78820748/a-lot-of-incorrect-detection-using-yolov8</guid>
      <pubDate>Thu, 01 Aug 2024 11:33:58 GMT</pubDate>
    </item>
    <item>
      <title>ValidationError：LLMChain 的 2 个验证错误</title>
      <link>https://stackoverflow.com/questions/77842203/validationerror-2-validation-errors-for-llmchain</link>
      <description><![CDATA[这是我的完整代码：
!pip install -q transformers einops accelerate langchain bitsandbytes sentence_transformers faiss-cpu pypdf sentencepiece 
from langchain import HuggingFacePipeline 
from transformers import AutoTokenizer 
from langchain.embeddings import HuggingFaceEmbeddings 
from langchain.document_loaders.csv_loader import CSVLoader 
from langchain.vectorstores import FAISS, Chroma
from langchain.chains import RetrievalQA 
from langchain.prompts import PromptTemplate
from langchain.chains import ConversationalRetrievalChain
from langchain.chains.question_answering import load_qa_chain
from langchain.memory import ConversationBufferMemory
import accelerate
import transformers 
import torch 
import textwrap 
loader = CSVLoader(&#39;/kaggle/input/csvdata/chatdata.csv&#39;, encoding=&quot;utf-8&quot;, csv_args={&#39;delimiter&#39;: &#39;,&#39;}) 
data = loader.load() 

embeddings = HuggingFaceEmbeddings(model_name=&#39;sentence-transformers/all-MiniLM-L6-v2&#39;,model_kwargs={&#39;device&#39;: &#39;cpu&#39;}) 

db = FAISS.from_documents(data, embeddings)

#Mistral 7B 模型 llm

import torch
from transformers import (
AutoModelForCausalLM,
AutoTokenizer,
GenerationConfig,
TextStreamer,
pipeline,
)

MODEL_NAME = &quot;mistralai/Mistral-7B-Instruct-v0.1&quot;

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForCausalLM.from_pretrained(
MODEL_NAME, device_map=&quot;auto&quot;, torch_dtype=torch.float16, load_in_8bit=True
)

generation_config = GenerationConfig.from_pretrained(MODEL_NAME)
generation_config.max_new_tokens = 1024
generation_config.temperature = 0.0001
generation_config.do_sample = True
streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

llm = pipeline(
&quot;text-generation&quot;,
model=model,
tokenizer=tokenizer,
return_full_text=True,
generation_config=generation_config,
num_return_sequences=1,
eos_token_id=tokenizer.eos_token_id,
pad_token_id=tokenizer.eos_token_id,
streamer=streamer,
)

def format_prompt(prompt, system_prompt=&quot;&quot;):
if system_prompt.strip():
return f&quot;[INST] {system_prompt} {prompt} [/INST]&quot;
return f&quot;[INST] {prompt} [/INST]&quot;

SYSTEM_PROMPT = &quot;&quot;&quot;

您是临床数据科学家和数据分析师，专门从事统计数据分析和报告生成。您的使命是为医疗保健和临床研究提供准确且富有洞察力的数据驱动解决方案。在回答问题时，请发挥临床数据科学领域经验丰富的数据专业人士的专业知识和精准度。
如果您遇到没有必要信息的问题，请务必避免提供推测性或不准确的答案。
&quot;&quot;&quot;.strip()

chain = ConversationalRetrievalChain.from_llm(
llm,
chain_type=&quot;stuff&quot;,
trieser=db.as_retriever(),
return_source_documents=True,
verbose=True,
)

这里我遇到了错误：
ValidationError: LLMChain 的 2 个验证错误
llm
预期 Runnable 实例 (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)
llm
预期 Runnable 实例 (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)

from textwrap import fill

result = chain(input(&quot;ClinicalTrial Planimeter ChatBot ---&quot;)
)
print(fill(result[&quot;result&quot;].strip(), width=80))

此 llm 链使用 llm、矢量数据库和提示进行编程以与 csv 聊天，我在运行 ConversationalRetrievalChain 时遇到上述错误]]></description>
      <guid>https://stackoverflow.com/questions/77842203/validationerror-2-validation-errors-for-llmchain</guid>
      <pubDate>Thu, 18 Jan 2024 20:20:48 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型无法预测测试集中的值</title>
      <link>https://stackoverflow.com/questions/62838589/keras-model-not-predicting-values-in-the-test-set</link>
      <description><![CDATA[我正在构建一个 Keras 模型来预测用户是否会选择某个产品（二元分类）。
模型似乎在训练时保留的验证集上取得了进展，但当涉及到测试集时，模型的预测全为 0。
我的数据集看起来像这样：
train_dataset

customer_id id target customer_num_id
0 TCHWPBT 4 0 1
1 TCHWPBT 13 0 1
2 TCHWPBT 20 0 1
3 TCHWPBT 23 0 1
4 TCHWPBT 28 0 1
... ... ... ... ...
1631695 D4Q7TMM 849 0 7417
1631696 D4Q7TMM 855 0 7417
1631697 D4Q7TMM 856 0 7417
1631698 D4Q7TMM 858 0 7417
1631699 D4Q7TMM 907 0 7417

我使用以下命令将其拆分为 Train/Val 集：
from sklearn.model_selection import train_test_split

Train, Val = train_test_split(train_dataset, test_size=0.1, random_state=42, shuffle=False)

拆分数据集后，我选择在训练和验证模型时使用的特征：
train_customer_id = Train[&#39;customer_num_id&#39;]
train_vendor_id = Train[&#39;id&#39;]
train_target = Train[&#39;target&#39;]

val_customer_id = Val[&#39;customer_num_id&#39;]
val_vendor_id = Val[&#39;id&#39;]
val_target = Val[&#39;target&#39;]

... 并运行模型：
epochs = 2

for e in range(epochs):
print(&#39;EPOCH: &#39;, e)
model.fit([train_customer_id, train_vendor_id], train_target, epochs=1, verbose=1, batch_size=384)

prediction = model.predict(x=[train_customer_id, train_vendor_id], verbose=1, batch_size=384)
train_f1 = f1_score(y_true=train_target.astype(&#39;float32&#39;), y_pred=prediction.round())
print(&#39;TRAIN F1: &#39;, train_f1)

val_prediction = model.predict(x=[val_customer_id, val_vendor_id], verbose=1, batch_size=384)
val_f1 = f1_score(y_true=val_target.astype(&#39;float32&#39;), y_pred=val_prediction.round())
print(&#39;VAL F1: &#39;, val_f1)

EPOCH: 0
1468530/1468530 [==============================] - 19s 13us/step - 损失: 0.0891
TRAIN F1: 0.1537511577647422
VAL F1: 0.09745762711864409
EPOCH: 1
1468530/1468530 [==============================] - 19s 13us/step - 损失：0.0691
TRAIN F1：0.308748569645272
VAL F1：0.2076433121019108

验证准确率似乎随着时间的推移而提高，模型预测 1 和 0：
 prediction = model.predict(x=[val_customer_id, val_vendor_id], verbose=1, batch_size=384)
np.unique(prediction.round())

array([0., 1.], dtype=float32)

但是当我尝试预测测试集时，模型预测所有值都是 0：
prediction = model.predict(x=[test_dataset[&#39;customer_num_id&#39;], test_dataset[&#39;id&#39;]], verbose=1, batch_size=384)
np.unique(prediction.round())

array([0.], dtype=float32)

测试数据集看起来与训练集和验证集相似，并且它在训练过程中与验证集一样被忽略，但模型无法输出除 0 以外的值。
测试数据集如下所示：
 test_dataset

customer_id id customer_num_id
0 Z59FTQD 243 7418
1 0JP29SK 243 7419
... ... ... ...
1671995 L9G4OFV 907 17414
1671996 L9G4OFV 907 17414
1671997 FDZFYBA 907 17415

这里可能存在什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/62838589/keras-model-not-predicting-values-in-the-test-set</guid>
      <pubDate>Fri, 10 Jul 2020 16:30:15 GMT</pubDate>
    </item>
    </channel>
</rss>