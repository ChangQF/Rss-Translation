<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 29 Jun 2024 09:16:26 GMT</lastBuildDate>
    <item>
      <title>适用于 PHP 开发专家的机器学习框架（DJANGO 除外）[关闭]</title>
      <link>https://stackoverflow.com/questions/78685308/machine-learning-framework-except-django-for-developer-expert-in-php</link>
      <description><![CDATA[我曾经是一名 PHP 开发人员，在创建了大量项目之后，我想尝试机器学习。我应该尝试什么框架，因为我对 Python 了如指掌，但除了解决竞争性编程问题外，我从未使用过基于 Python 构建项目。
我擅长构建 MVC 模式网页。
DJANGO 是我不喜欢的框架之一，请推荐另一个。]]></description>
      <guid>https://stackoverflow.com/questions/78685308/machine-learning-framework-except-django-for-developer-expert-in-php</guid>
      <pubDate>Sat, 29 Jun 2024 07:18:30 GMT</pubDate>
    </item>
    <item>
      <title>RK3588 上支持的 ML 框架和命令 NPU 执行</title>
      <link>https://stackoverflow.com/questions/78685276/supported-ml-frameworks-and-commanding-npu-execution-on-rk3588</link>
      <description><![CDATA[我正在探索在 NPU RK3588 上运行机器学习模型。有人可以分享哪些 ML 框架支持此 NPU 吗？此外，我想知道如何命令 NPU 专门运行使用这些框架的模型。任何见解或资源都将不胜感激！
我是新手，到目前为止我还没有尝试过任何事情]]></description>
      <guid>https://stackoverflow.com/questions/78685276/supported-ml-frameworks-and-commanding-npu-execution-on-rk3588</guid>
      <pubDate>Sat, 29 Jun 2024 06:59:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 GNN 无法完成这么简单的任务？</title>
      <link>https://stackoverflow.com/questions/78685248/why-cant-my-gnn-work-on-such-a-simple-task</link>
      <description><![CDATA[我正在使用图神经网络 (GNN) 进行节点回归预测。目前，我正在为每个节点生成具有 10 维特征且没有边特征的随机图。每个节点的标签是通过将其自身特征相加并将其邻居特征的总和相加而创建的。因此，我认为 GNN 预测标签应该是一个简单的任务，损失应该会收敛到零。然而，实际损失在 45 左右波动。我尝试了很多方法将损失降至零，但都没有奏效。该模型在某种程度上可以起到这样的作用：
节点 0：预测：9.7522，真实：12.9197
节点 1：预测：-6.3811，真实：-9.2859
节点 2：预测：-19.5746，真实：-7.5249
节点 3：预测：-77.1716，真实：-17.7568
节点 4：预测：-2.2538，真实：-5.5253
节点 5：预测：-9.8838，真实：-4.1401
节点 6：预测：-10.5909，真实：-8.0105
节点 7：预测：-5.9015，真实：-9.8000
节点 8：预测： -20.8053，真实：-30.8081
节点 9：预测：5.1975，真实：2.2300
节点 10：预测：-14.8946，真实：-8.9688
节点 11：预测：-4.1185，真实：-4.4405
节点 12：预测：-21.0528，真实：-25.8891
节点 13：预测：-3.3378，真实：-8.9060
节点 14：预测：-6.5355，真实：-7.4367
节点 15：预测：29.2404，真实：30.6309
节点 16：预测：-37.1685，真实：-64.5965
节点17：预测：-6.4728，真实：-4.6115
节点 18：预测：8.0359，真实：9.0135
节点 19：预测：25.7627，真实：29.4366
节点 20：预测：26.4058，真实：20.6240
节点 21：预测：13.3435，真实：12.7873
节点 22：预测：-47.8510，真实：-53.5470
节点 23：预测：-12.2702，真实：-21.0920
节点 24：预测：-33.2615，真实：-29.9373
节点 25：预测：19.7694，真实值：26.7916
节点 26：预测值：3.0540，真实值：7.8801
节点 27：预测值：22.9412，真实值：23.2001
节点 28：预测值：10.8517，真实值：11.9646
节点 29：预测值：-9.5051，真实值：-14.9755

但我认为预测值应该更符合真实值。我想知道为什么我的 GNN 不能完成这么简单的任务？
我的完整代码位于：
https://github.com/zyg18/GNN/blob/main/GNN.py
我尝试过许多 GNN 模型，例如：
class SimpleGNN(torch.nn.Module):
def __init__(self, num_node_features):
super(SimpleGNN, self).__init__()
self.conv = GCNConv(num_node_features, 1, bias=False)

def forward(self, x, edge_index):
return self.conv(x, edge_index).squeeze(-1)

class GNNWithTwoConvLayers(torch.nn.Module):
def init(self, num_node_features):
super(GNNWithTwoConvLayers, self).init()
self.conv1 = GCNConv(num_node_features, 64)
self.conv2 = GCNConv(64, 64)
self.fc1 = torch.nn.Linear(64, 16)
self.fc2 = torch.nn.Linear(16, 1)
self.dropout = torch.nn.Dropout(0.5)

def forward(self, x, edge_index):
x = self.conv1(x, edge_index)
x = F.relu(x)
x = self.dropout(x)
x = self.conv2(x, edge_index)
x = F.relu(x)
x = self.dropout(x)
x = self.fc1(x)
x = F.relu(x)
x = self.fc2(x)
返回 x.squeeze(-1)

class GNN(torch.nn.Module):
def init(self, num_node_features):
super(GNNWithTwoConvLayers, self).init()
self.conv1 = GCNConv(num_node_features, 64)
self.fc1 = torch.nn.Linear(64, 16)
self.fc2 = torch.nn.Linear(16, 1)
self.dropout = torch.nn.Dropout(0.5)

def forward(self, x, edge_index):
x = self.conv1(x, edge_index)
x = F.relu(x)
x = self.dropout(x)
x = self.fc1(x)
x = F.relu(x)
x = self.fc2(x)
返回 x.squeeze(-1)
]]></description>
      <guid>https://stackoverflow.com/questions/78685248/why-cant-my-gnn-work-on-such-a-simple-task</guid>
      <pubDate>Sat, 29 Jun 2024 06:43:38 GMT</pubDate>
    </item>
    <item>
      <title>使用 X = tester.drop('label', axis=1) 和 y = tester['label'] 拆分数据时出现 KeyError: “['label'] not found in axis”</title>
      <link>https://stackoverflow.com/questions/78684880/keyerror-label-not-found-in-axis-when-splitting-data-with-x-tester-drop</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78684880/keyerror-label-not-found-in-axis-when-splitting-data-with-x-tester-drop</guid>
      <pubDate>Sat, 29 Jun 2024 01:40:35 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归梯度下降中的不同成本函数算法与成本函数本身</title>
      <link>https://stackoverflow.com/questions/78684727/logistic-regression-different-cost-function-algorithm-in-gradient-descent-vs-cos</link>
      <description><![CDATA[为什么在逻辑回归中成本函数看起来像这样：
在此处输入图像描述
但是，在实现梯度下降时，成本函数基本上被简化为不包含对数的线性回归成本函数：
在此处输入图像描述
我完全理解为什么在逻辑回归中对数是必要的，因为存在多个局部最小值并且可能无法达到全局最小值。那么为什么它们不存在于梯度下降算法中呢？
我原本以为梯度下降中的成本函数是相同的。]]></description>
      <guid>https://stackoverflow.com/questions/78684727/logistic-regression-different-cost-function-algorithm-in-gradient-descent-vs-cos</guid>
      <pubDate>Fri, 28 Jun 2024 23:30:17 GMT</pubDate>
    </item>
    <item>
      <title>kdb+/q q/kdb+ 中的机器学习</title>
      <link>https://stackoverflow.com/questions/78684235/kdb-q-machine-learning-in-q-kdb</link>
      <description><![CDATA[如果我在端口 5012 的 hdb 进程中存储了一个表。
我已经安装了 PyKX 并将其成功导入到终端中的 python 提示符中。
然后我连接到我的 host=‘localhost’, port=5012  并运行一个简单的查询以从 hdb 返回我的数据 q(‘{select name,price,volume,vwap from tab where date&gt;2024.01.01}’)
然后如何在 python 机器学习算法之一中使用这些数据。您如何将表数据转换为可用的 python 数据点，然后输入到您选择的模型中？您是否必须提取每列数据并保存为某种类型的变量，例如在 q 进程中运行 exec  语句？]]></description>
      <guid>https://stackoverflow.com/questions/78684235/kdb-q-machine-learning-in-q-kdb</guid>
      <pubDate>Fri, 28 Jun 2024 19:47:48 GMT</pubDate>
    </item>
    <item>
      <title>用于安装机器的优化模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78684160/optimization-model-for-fitting-a-machine</link>
      <description><![CDATA[我正在从事这个项目，目标是让机器自动对准一个非常具体的点。无需过多细节，我能够轻松确定 0 到 1 范围内的对准程度，并且能够在 x 轴和 y 轴上移动我的机器，并立即看到这个“对准率”如何增加或减少。这在理论上似乎很简单，但有一些问题让我在尝试让机器对准时不知所措。
我的第一个想法是尝试强行使用它。机器永远不会从 0 对准开始，所以我在想我可以让它在给定轴上任意向一个方向移动，看看对准度量是增加还是减少。如果从非零值开始，它总是会看到一些增加或减少。如果它增加，则再次朝该方向移动，如果它减少，则返回并尝试另一个方向，如果它在两个方向上都减少，则停止。我会在另一个轴上重复此操作，效果会很好。
但是，由于对齐的特殊性，我被告知这极易陷入局部最大值。所以我的下一个想法是梯度下降。我将对齐参数设置为负数，并尝试找到最小值。但我以前从未使用过梯度下降，从我在网上看到的 Python 示例中，梯度下降的每个用例都需要了解函数的梯度才能使用。我不知道这一点，所以我不知道梯度下降是否是我想要的。
我想我只是问是否有人对这种情况有任何优化建议，可以推荐仅在不断构建的数据库上工作，而不是预先建立的公式或信息数据库。一开始我只知道当前 (x, y) 方向和当前对齐比率（从 0 到 1），我必须通过进行细微调整并观察这对系统的影响，使其尽可能接近 1，但我还必须避免陷入局部最大值而无法达到最佳状态。也许最好的选择是实现类似蛮力的东西，但强制它跳过多个步骤并重复，如果“最佳”比率小于给定数字（如 0.9 或类似数字）？我不知道。任何帮助都将不胜感激，即使它只是一份其他优化策略的列表，让我可以在自己的时间查找。我甚至不知道其中大多数的正式术语，所以研究很痛苦。]]></description>
      <guid>https://stackoverflow.com/questions/78684160/optimization-model-for-fitting-a-machine</guid>
      <pubDate>Fri, 28 Jun 2024 19:23:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Yamnet 检测乐器</title>
      <link>https://stackoverflow.com/questions/78684112/detection-of-musical-instruments-using-yamnet</link>
      <description><![CDATA[我的目标是用人工智能（机器学习）检测乐器。
我目前正在使用 Yamnet 模型进行推理，但它的类别范围非常广泛，例如“咆哮”、“打印机”和“钢琴”。我想知道这是否会导致它在检测乐器时不太精确，因为乐器类别只是总类别的一小部分。
Kaggle 上对 Yamnet 模型的描述指出：

您应该进行一定程度的微调和校准，以使 YAMNet 可用于您构建的任何系统。

还有另一个名为 NSynth 的模型，它拥有大量乐器样本数据集，但它用于合成新声音，而不是对乐器进行分类/检测。
在这种情况下，使用 NSynth 对 Yamnet 模块进行微调是否有意义？]]></description>
      <guid>https://stackoverflow.com/questions/78684112/detection-of-musical-instruments-using-yamnet</guid>
      <pubDate>Fri, 28 Jun 2024 19:08:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用 Haarcascades 时提高我的结果 [关闭]</title>
      <link>https://stackoverflow.com/questions/78682011/how-to-improve-my-results-while-using-haarcascades</link>
      <description><![CDATA[来自https://github.com/opencv/opencv/tree/master/data/haarcascades
一直在使用 smile.xml 文件，但效果不太准确。
我应该做哪些更改才能提高准确性
我的代码：
import cv2 as cv
import numpy as np
smile_cascade = cv.CascadeClassifier(&#39;haarcascade_smile.xml&#39;)
face_cascade = cv.CascadeClassifier(&#39;haarcascade_frontalface_default.xml&#39;)
cap = cv.VideoCapture(0)
while True:
ret,img = cap.read()
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)
faces = face_cascade.detectMultiScale(gray,1.3,5)
for (x,y,w,h) in faces:
cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
roi_gray = gray[y:y+h,x:x+w]
roi_color = img[y:y+h,x:x+w]
smiles = smile_cascade.detectMultiScale(gray, 
scaleFactor=1.3, 
minNeighbors=40, 
minSize=(30, 30),
flags=cv.CASCADE_SCALE_IMAGE)
for (ex,ey,ew,eh) in smiles:
cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)
cv.imshow(&#39;img&#39;,img)
k = cv.waitKey(30) &amp; 0xFF
if k ==27:
break
cap.release()
cv.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78682011/how-to-improve-my-results-while-using-haarcascades</guid>
      <pubDate>Fri, 28 Jun 2024 10:47:20 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft Fabric 数据科学 - 如何使用应用模型向导在 Delta 表中保存概率和预测？</title>
      <link>https://stackoverflow.com/questions/78680642/microsoft-fabric-data-science-how-to-save-probabilities-along-with-predictions</link>
      <description><![CDATA[我为二元分类任务创建了一个逻辑回归模型。该模型在预测方面表现良好，我得到了我想要的结果。但随着业务需求的变化，我也想获得每个类别的概率。我使用 predict_proba 方法来获取 2 个类别的概率。这适用于测试数据。我得到了预测及其概率。我将实验保存为 ML 模型（使用 ML 向导中的应用此模型）并按照以下步骤操作：

选择用于评分的源数据
将数据正确映射到我的 ML 模型的输入
指定我的模型输出的目标
创建一个使用 PREDICT 生成预测结果并将其作为增量表存储到 Lakehouse 的笔记本

但是，我只在我的增量表中获得了预测，而没有概率。有没有办法我也可以获得概率？
我按照此链接上的说明进行操作：链接
我注意到的另一件事是在实验和模型的输出模式上，数据类型是 int 32，这对于预测来说是正确的，但对于概率来说应该是大小为 [-1,2] 的数组。
为了以防万一，我还将链接附加到我的笔记本中：笔记本。
]]></description>
      <guid>https://stackoverflow.com/questions/78680642/microsoft-fabric-data-science-how-to-save-probabilities-along-with-predictions</guid>
      <pubDate>Fri, 28 Jun 2024 04:22:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我尝试从 (.fif) 文件进行可视化时，会在 mne-python 中收到此运行时警告？</title>
      <link>https://stackoverflow.com/questions/78679466/why-am-i-getting-this-runtime-warning-in-mne-python-while-trying-to-visualize-fr</link>
      <description><![CDATA[我正在努力使用 mne-python 进行预处理的 eeg 通道可视化部分。这些 (&#39;.fif&#39;) 文件是从 (&#39;.mat&#39;) 文件预处理的。这是我在 kaggle 笔记本中使用的代码：
import mne
import os
import numpy as np

# 定义存储 .fif 文件的目录
data_dir = &#39;/kaggle/input/preproccesed-dataset/128-channel-resting(2.0)/kaggle/working/preprocessed_mat_output_directory&#39;

# 列出目录中的所有 .fif 文件
fif_files = [f for f in os.listdir(data_dir) if f.endswith(&#39;-epo.fif&#39;)]

# 加载每个 .fif 文件
epochs_list = [mne.read_epochs(os.path.join(data_dir, fif_file)) for fif_file in fif_files]

# 连接所有将 epochs 合并为单个 Epochs 对象
all_epochs = mne.concatenate_epochs(epochs_list)

# 预处理：应用高通滤波器
all_epochs.filter(l_freq=1.0, h_freq=40.0)

# 执行 ICA
ica = mne.preprocessing.ICA(n_components=20, random_state=97)
ica.fit(all_epochs)

# 根据检查或自动标准手动排除组件
ica.exclude = [0, 1] # 根据已识别的工件组件进行调整

# 将 ICA 应用于 epochs
all_epochs = ica.apply(all_epochs)

# 绘制诱发反应
evoked = all_epochs.average()
evoked.plot()

# 绘制 PSD
fig_psd = all_epochs.plot_psd(fmin=1.0, fmax=40.0, average=True, spatial_colors=False)

# 绘制地形图
fig_topo = evoked.plot_topomap(times=[0.1, 0.2, 0.3], ch_type=&#39;eeg&#39;, average=0.05)

# 计算并绘制 TFR
from mne.time_frequency import tfr_morlet
freqs = np.arange(6, 30, 3)
n_cycles = freqs / 2
power = tfr_morlet(all_epochs, freqs=freqs, n_cycles=n_cycles, return_itc=False, average=True)
fig_tfr = power.plot([0])

# 确保保存目录存在
save_dir = &#39;/kaggle/working/mat_visuals/&#39;
os.makedirs(save_dir, exist_ok=True) # 如果目录不存在，则创建目录

# 保存处理后的数据
all_epochs.save(os.path.join(save_dir, &#39;processed-epochs.fif&#39;), overwrite=True)
evoked.save(os.path.join(save_dir, &#39;evoked-ave.fif&#39;), overwrite=True)

# 如果需要，保存图形
fig_psd.savefig(os.path.join(save_dir, &#39;psd_plot.png&#39;))
fig_topo.savefig(os.path.join(save_dir, &#39;topomap_plot.png&#39;))
fig_tfr.savefig(os.path.join(save_dir, &#39;tfr_plot.png&#39;))

这是我收到的错误：
Runtime-ERROR
我尝试更改这两行代码：
# 绘制 PSD
fig_psd = all_epochs.plot_psd(fmin=1.0, fmax=40.0, average=False, spatial_colors=False)

# 绘制地形图
fig_topo = evoked.plot_topomap(times=False, ch_type=&#39;eeg&#39;, average=0.05)

我还尝试阅读以下 2 个文档：
neurotechedu , mne-python
但我仍然找不到任何解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78679466/why-am-i-getting-this-runtime-warning-in-mne-python-while-trying-to-visualize-fr</guid>
      <pubDate>Thu, 27 Jun 2024 19:16:05 GMT</pubDate>
    </item>
    <item>
      <title>绘制预测掩码的问题</title>
      <link>https://stackoverflow.com/questions/78669554/issue-with-plotting-predicted-masks</link>
      <description><![CDATA[我目前正在进行一个深度学习项目“叶病分割”。我已经训练了一个模型超过 50 个时期，并获得了以下准确度和损失指标：
训练损失：19.4736，训练准确度：0.9395
验证损失：19.6197，验证准确度：0.9100
测试损失：19.6148，测试准确度：0.9123
但是，当我绘制预测的蒙版时，它们看起来不准确。我的绘图代码有问题吗？
def plot_predictions(model, images, mask, num_samples=5):
predictions = model.predict(images[:num_samples])
for i in range(num_samples):
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.title(&#39;真实图像&#39;)
plt.imshow(images[i])
plt.subplot(1, 3, 2)
plt.title(&#39;地面真相面具&#39;)
plt.imshow(masks[i], cmap=&#39;gray&#39;) # 假设面具已经是二进制的
plt.subplot(1, 3, 3)
plt.title(&#39;预测面具&#39;)
plt.imshow(predictions[i][:, :, 0], cmap=&#39;gray&#39;) # 转换预测面具转换为二进制
plt.show()

plot_predictions(model, test_images.numpy(), test_masks_L, num_samples=5)

原始图像-蒙版-预测蒙版
请检查我的代码并帮助找出可能导致此问题的任何错误？]]></description>
      <guid>https://stackoverflow.com/questions/78669554/issue-with-plotting-predicted-masks</guid>
      <pubDate>Tue, 25 Jun 2024 21:18:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 skimage imsave 保存重建的二进制图像</title>
      <link>https://stackoverflow.com/questions/77248571/how-to-save-a-reconstructed-binary-image-using-skimage-imsave</link>
      <description><![CDATA[我一直在尝试使用 skimage 库对图像进行预处理以进行特征提取。但我无法保存图像，因为它给出错误提示“无法将模式 F 写入 PNG”
处理图像的函数在此处给出
def image_process(image):
img = imread(image)
rem_img = remove(img)
rgb_img = rgba2rgb(rem_img)
gray_img = rgb2gray(rgb_img)
bin_img = gray_img &lt; Threshold_otsu(gray_img)
Smooth_img = gaussian(bin_img)
Seed_px = np.copy(smooth_img)
Seed_px[1:-1 , 1:-1]=smooth_img.max()
Mask = Smooth_img
Filled_img = Reconstruction(seed_px , Mask , Method =&#39;erosion&#39;)

返回 filled_img

然后尝试使用 imsave 将图像保存在 BW 目录中
leaf_img = &quot;neem.jpg&quot;
processing_img = image_process(leaf_img)
imsave(&quot;BW/leaf.png&quot;, processing_img)

显示错误
KeyError Traceback (most recent call last)
File C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1299, in _save(im, fp, filename, chunk, save_all)
1298 try:
-&gt; 1299 rawmode, mode = _OUTMODES[mode]
1300 except KeyError as e:

KeyError: &#39;F&#39;

上述异常是导致以下异常的直接原因：

OSError Traceback (most recent call last)
Cell In[26], line 3
1 leaf_img = &quot;neem.jpg&quot;
2 processing_img = image_process(leaf_img)
----&gt; 3 imsave(&quot;BW/leaf.png&quot;, processing_img)

文件 C:\Python\lib\site-packages\skimage\io\_io.py:143，在 imsave(fname, arr, plugin, check_contrast, **plugin_args) 中
141 如果 check_contrast 和 is_low_contrast(arr):
142 warn(f&#39;{fname} 是低对比度图像&#39;)
--&gt; 143 返回 call_plugin(&#39;imsave&#39;, fname, arr, plugin=plugin, **plugin_args)

文件 C:\Python\lib\site-packages\skimage\io\manage_plugins.py:205，在 call_plugin(kind, *args, **kwargs) 中
202 除外 IndexError:
203 引发 RuntimeError(f&#39;无法找到 {kind} 的插件“{plugin}”。&#39;)
--&gt; 205 return func(*args, **kwargs)

文件 C:\Python\lib\site-packages\imageio\v3.py:139，在 imwrite(uri, image, plugin, extension, format_hint, **kwargs) 中
104 def imwrite(uri, image, *, plugin=None, extension=None, format_hint=None, **kwargs):
105 &quot;&quot;&quot;将 ndimage 写入给定的 URI。
106 
107 具体行为取决于所使用的文件类型和插件。要了解
(...)
136 
137 &quot;&quot;&quot;
--&gt; 139 使用 imopen(
140 uri,
141 &quot;w&quot;,
142 legacy_mode=False,
143 plugin=plugin,
144 format_hint=format_hint,
145 extension=extension,
146 ) 作为 img_file:
147coded = img_file.write(image, **kwargs)
149 returncoded

文件 C:\Python\lib\site-packages\imageio\core\v3_plugin_api.py:367，位于 PluginV3.__exit__(self, type, value, traceback)
366def __exit__(self, type, value, traceback) -&gt; None:
--&gt; 367 self.close()

文件 C:\Python\lib\site-packages\imageio\plugins\pillow.py:123，位于 PillowPlugin.close(self) 中
122 def close(self) -&gt; None:
--&gt; 123 self._flush_writer()
125 if self._image:
126 self._image.close()

文件 C:\Python\lib\site-packages\imageio\plugins\pillow.py:457，位于 PillowPlugin._flush_writer(self) 中
454 self.save_args[&quot;save_all&quot;] = True
455 self.save_args[&quot;append_images&quot;] = self.images_to_write
--&gt; 457 primary_image.save(self._request.get_file(), **self.save_args)
458 self.images_to_write.clear()
459 self.save_args.clear()

文件 C:\Python\lib\site-packages\PIL\Image.py:2431，位于 Image.save(self, fp, format, **params)
2428 fp =builtins.open(filename, &quot;w+b&quot;)
2430 尝试：
-&gt; 2431 save_handler(self, fp, filename)
2432 except Exception:
2433 if open_fp:

文件 C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1302，在 _save(im, fp, filename, chunk, save_all) 中
1300 except KeyError as e:
1301 msg = f&quot;cannot write mode {mode} as PNG&quot;
-&gt; 1302 raise OSError(msg) from e
1304 #
1305 # write minimal PNG file
1307 fp.write(_MAGIC)

OSError: 无法在此处将模式 F 写入 PNG 类型


有人可以解释一下这里的问题是什么吗？解决方案将非常有帮助。提前谢谢了]]></description>
      <guid>https://stackoverflow.com/questions/77248571/how-to-save-a-reconstructed-binary-image-using-skimage-imsave</guid>
      <pubDate>Sat, 07 Oct 2023 06:06:06 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未知层：“CustomScaleLayer”。请确保您使用的是`keras.utils.custom_object_scope`</title>
      <link>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</guid>
      <pubDate>Fri, 16 Jun 2023 09:13:29 GMT</pubDate>
    </item>
    <item>
      <title>如何提高机器学习的分类准确性</title>
      <link>https://stackoverflow.com/questions/41447104/how-to-improve-classification-accuracy-for-machine-learning</link>
      <description><![CDATA[我曾使用极限学习机进行分类，发现我的分类准确率只有 70% 以上，这导致我使用集成方法创建更多分类模型，并根据大多数模型的分类对测试数据进行分类。但是，这种方法只能将分类准确率提高一小步。请问还有哪些其他方法可用于提高二维线性不可分数据集的分类准确率？]]></description>
      <guid>https://stackoverflow.com/questions/41447104/how-to-improve-classification-accuracy-for-machine-learning</guid>
      <pubDate>Tue, 03 Jan 2017 15:41:10 GMT</pubDate>
    </item>
    </channel>
</rss>