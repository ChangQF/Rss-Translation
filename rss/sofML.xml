<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 13 May 2024 01:02:59 GMT</lastBuildDate>
    <item>
      <title>在 Streamlit.io 上部署 Python 应用程序时出错：“sklearn”的 ModuleNotFoundError</title>
      <link>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</link>
      <description><![CDATA[在此处输入图片说明
标题：在 Streamlit.io 上部署 Python 应用程序时出错：“sklearn”的 ModuleNotFoundError
描述：
我在 Streamlit.io 上部署 Python 应用程序时遇到错误。尽管在我的 requests.txt 文件中列出了“scikit-learn”，但我在部署过程中遇到了 ModuleNotFoundError。]]></description>
      <guid>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</guid>
      <pubDate>Sun, 12 May 2024 23:18:51 GMT</pubDate>
    </item>
    <item>
      <title>确定某些公司名称是否相同的模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78469183/model-to-determine-if-certain-company-names-are-the-same</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78469183/model-to-determine-if-certain-company-names-are-the-same</guid>
      <pubDate>Sun, 12 May 2024 20:10:11 GMT</pubDate>
    </item>
    <item>
      <title>准确的时间序列异常检测</title>
      <link>https://stackoverflow.com/questions/78469052/accurate-time-series-anomaly-detection</link>
      <description><![CDATA[尝试以最高精度对时间序列数据执行异常检测。您最近遇到的任何框架或 python 库。或者请告诉我您遇到过或使用过的最好的图书馆。
问候，
K
尝试过像 PyCaret 这样的库，但错误率很高。]]></description>
      <guid>https://stackoverflow.com/questions/78469052/accurate-time-series-anomaly-detection</guid>
      <pubDate>Sun, 12 May 2024 19:18:40 GMT</pubDate>
    </item>
    <item>
      <title>最终迭代中的 Tensorflow 错误：重塑的输入是具有 28 个值的张量，但请求的形状具有 128 个值</title>
      <link>https://stackoverflow.com/questions/78468947/tensorflow-error-in-final-iteration-input-to-reshape-is-a-tensor-with-28-values</link>
      <description><![CDATA[def DMRL(n_users, n_items, embed_dim, n_factors):
    断言 embed_dim % n_factors == 0，“embed_dim 必须能被 n_factors 整除”
    
    user_input = 输入(形状=(1,), dtype=&#39;int32&#39;, name=&#39;UserInput&#39;)
    user_embedding = 嵌入(n_users, embed_dim, name=&#39;UserEmbedding&#39;)(user_input)
    用户=扁平化（名称=&#39;UserFlatten&#39;）（user_embedding）
    
    item_input = 输入(形状=(1,), dtype=&#39;int32&#39;, name=&#39;ItemInput&#39;)
    item_embedding = 嵌入(n_items, embed_dim, name=&#39;ItemEmbedding&#39;)(item_input)
    items = Flatten(name=&#39;ItemFlatten&#39;)(item_embedding)

    textual_input = 输入（形状=（768，），名称=&#39;TextualInput&#39;）
    textual_mlp = Modal_MLP(embed_dim, 4)(textual_input)

    Visual_input = 输入（形状=（4096，），名称=&#39;VisualInput&#39;）
    Visual_mlp = Modal_MLP(embed_dim, 4)(visual_input)
    
    user_factor_embedding = tf.split(用户, n_factors, 1)
    item_factor_embedding = tf.split(items, n_factors, 1)
    textual_factor_embedding = tf.split(textual_mlp, n_factors, 1)
    视觉因子嵌入 = tf.split(视觉_mlp, n_factors, 1)

    #解缠结表示学习
    cor_loss = CorrelationLossLayer(n_factors)([视觉因子_嵌入、文本_因子_嵌入、用户_因子_嵌入、项目_因子_嵌入])

    # 因素交互作用
    评级 = FactorInteractionLayer(n_factors)([user_factor_embedding, item_factor_embedding, textual_factor_embedding, Visual_factor_embedding])
    评级 = Flatten()(评级)

    输出=密集（1，激活=&#39;线性&#39;）（评级）
    
    模型=模型（输入= [用户输入，项目输入，文本输入，视觉输入]，输出= [输出，cor_loss]）

    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),
                  损失=[mse_loss, cor_loss_dummy],
                  损失权重=[1.0,0.2])
    返回模型

def mse_loss(y_true, y_pred):
    返回 tf.keras.losses.MeanSquaredError()(y_true, y_pred)

def cor_loss_dummy(y_true, y_pred):
    返回 y_pred

emebd_dim = 128
n_因子 = 2
batch_size = emebd_dim //n_factors

    model.fit([train_user, train_item, train_text, train_image],
                    [train_y，tf.zeros_like(train_y)]，
                    批量大小=批量大小，
                    纪元=50，
                    回调=[es],
                    验证分割=0.1）


train_user 形状：(275232,)
train_item 形状：(275232,)
train_text 形状：(275232, 768)
训练图像形状：(275232, 4096)
train_y.shape: (275232,)
最后一次迭代中总是出现错误并显示以下消息：
reshape 的输入是一个具有 28 个值的张量，但请求的形状有 128 个
我预计错误发生在 FactorInteractionLayer 类中。
类 FactorInteractionLayer(层):
    def __init__(self, n_factors):
        super(FactorInteractionLayer, self).__init__()
        self.n_factors = n_factors
        self.h = 密集(3, 激活=&#39;tanh&#39;)
        self.user_sig = Dense(1, 激活=&#39;sigmoid&#39;)
        self.text_sig = Dense(1, 激活=&#39;sigmoid&#39;)
        self.visual_sig = Dense(1, 激活=&#39;sigmoid&#39;)
        self.attention_layer = Dense(3, 激活=&#39;softmax&#39;)

    def 调用（自身，输入）：
        用户嵌入、项目嵌入、文本嵌入、视觉嵌入 = 输入[0]、输入[1]、输入[2]、输入[3]

        输出=0
        对于范围内的 i(self.n_factors)：
            user_emb、item_emb、text_emb、visual_emb = user_embedding[i]、item_embedding[i]、text_embedding[i]、visual_embedding[i]

            user_item_text_visual = Concatenate()([user_emb, item_emb, text_emb, Visual_emb])
            h = self.h(user_item_text_visual)
            注意力权重 = self.attention_layer(h)

            user_item = tf.matmul(user_emb, item_emb)
            user_item = self.user_sig(user_item)
            user_text = tf.matmul(user_emb, text_emb)
            user_text = self.text_sig(user_text)
            user_visual = tf.matmul(user_emb, Visual_emb)
            用户视觉 = self.视觉_sig(用户视觉)

            用户项目重要性=注意力权重[:, 0]
            用户文本重要性=注意力权重[:, 1]
            用户视觉重要性=注意力权重[:, 2]

            user_item_imp = tf.tensordot（user_item，user_item_importance，轴= 0）
            user_text_imp = tf.tensordot(user_text, user_text_importance, 轴=0)
            user_visual_imp = tf.tensordot（user_visual，user_visual_importance，轴= 0）

            sum_concat = 连接()([user_item_imp, user_text_imp, user_visual_imp])

            输出+= tf.reduce_sum(sum_concat)
        输出 = tf.expand_dims(输出, -1)
        返回输出

但是错误消息上方还有一些附加消息：
节点：&#39;gradient_tape/model/ItemEmbedding/embedding_lookup/Reshape_1&#39;。
所以，我无法预测问题出在哪里。]]></description>
      <guid>https://stackoverflow.com/questions/78468947/tensorflow-error-in-final-iteration-input-to-reshape-is-a-tensor-with-28-values</guid>
      <pubDate>Sun, 12 May 2024 18:44:27 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow ImportError：未定义符号：_ZTIN6snappy4SinkE</title>
      <link>https://stackoverflow.com/questions/78468933/tensorflow-importerror-undefined-symbol-ztin6snappy4sinke</link>
      <description><![CDATA[我尝试在 conda Python 环境中导入 TensorFlow，但遇到以下错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ImportError Traceback（最近一次调用最后一次）
第 1 行 [2] 中的单元格
----&gt; 1 将张量流导入为tf
2 设备名称 = tf.test.gpu_设备名称()
4 如果 device_name != &quot;/device:GPU:0&quot;:
文件〜/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/__init__.py:40
37导入打字为_typing
39 # 不要删除这一行；请参阅https://github.com/tensorflow/tensorflow/issues/42596
---&gt; 40 from tensorflow.python import pywrap_tensorflow # pylint:disable=unused-import
41 从tensorflow.python.tools导入module_util作为_module_util
42 从tensorflow.python.util.lazy_loader导入LazyLoader as _LazyLoader
文件〜/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py:34
29 从tensorflow.python.platform导入self_check
31 # TODO(mdan)：清理反模式：导入以消除副作用。
32
33 # 执行预加载健全性检查，以产生更具可操作性的错误。
---&gt; 34 self_check.preload_check()
36 # pylint: 禁用=通配符导入，g-导入不在顶部，未使用的导入，行太长
38 尝试：
39 # 如果存在显式共享对象，则此导入预计会失败
40 # 依赖项（with_framework_lib=true），因为我们不需要 RTLD_GLOBAL。
文件 ~/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/python/platform/self_check.py:63，在 preload_check() 中
50 引发导入错误（
51 “找不到 DLL %r。 TensorFlow 要求这些 DLL“
52 “安装在您的 %%PATH%% 中指定的目录中”
（...）
56“https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads”
57%”或“.join(缺失))
58 其他：
59 # 加载执行CPU功能保护检查的库。在这里做这个
60 # 作为预加载检查使我们更有可能检测到任何 CPU 功能
61 # 在我们触发它们之前不兼容（这通常会导致
62# 信号）。
---&gt; 63 从tensorflow.python.platform导入_pywrap_cpu_feature_guard
64 _pywrap_cpu_feature_guard.InfoAboutUnusedCPUFeatures()
导入错误：/home/gimhara/anaconda3/envs/tf-env/lib/python3.11/site-packages/tensorflow/python/platform/../../libtensorflow_framework.so.2：未定义符号：_ZTIN6snappy4SinkE

我使用的是安装在 Ubuntu 22.04 上的 Anaconda 环境中的 Python 3.11 和 TensorFlow v2.15.0。
根据我的研究，此错误似乎与 TensorFlow 使用的 Snappy 压缩库版本缺失或不兼容有关。
我已尝试以下步骤来解决该问题：

使用 pip 和 conda 重新安装 TensorFlow。

在 Ubuntu 上安装 libsnappy-dev 软件包。


但是，到目前为止，这些步骤都没有解决问题。
任何人都可以提供有关如何正确解决此 ImportError 并使 TensorFlow 正确运行的指导吗？
如果您需要任何其他信息，或者我是否应该提供有关我的设置或迄今为止已采取的步骤的更多详细信息，请告诉我。
预先感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78468933/tensorflow-importerror-undefined-symbol-ztin6snappy4sinke</guid>
      <pubDate>Sun, 12 May 2024 18:40:19 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：clean() 得到了意外的关键字参数“fix_unicode”</title>
      <link>https://stackoverflow.com/questions/78468882/typeerror-clean-got-an-unexpected-keyword-argument-fix-unicode</link>
      <description><![CDATA[我已经编写了一个Python程序来实现BERT算法，但是我遇到了下面的错误，下面是cleantext()函数。我更新了cleantext包，但是它不起作用。我已经编写了一个Python程序来实现BERT算法，但是我遇到了下面的错误错误和 cleantext() 函数如下。我更新了 cleantext 包，但它不起作用
代码：
def cleanhtml(raw_html):
    clean = re.compile(&#39;&lt;.*?&gt;&#39;)
    cleantext = re.sub(cleanr, &#39;&#39;, raw_html)
    返回纯文本

定义清洁（文本）：
    文本 = 文本.strip()
    
    #定期清洁
    文本=干净（文本，
        fix_unicode=真，
        to_ascii=假,
        较低=真，
        no_line_breaks=真，
        no_urls=真，
        no_emails=正确，
        no_phone_numbers=正确，
        no_numbers=假，
        no_digits=假，
        no_currency_symbols=真，
        no_punct=假,
        Replace_with_url=&quot;&quot;,
        Replace_with_email=“”，
        Replace_with_phone_number=“”，
        Replace_with_number=“”，
        Replace_with_digit=“0”，
        Replace_with_currency_symbol=“”，
    ）

    # 清理 html
    文本 = cleanhtml(文本)
    
    # 标准化
    标准化器 = hazm.Normalizer()
    文本=规范化器.规范化（文本）
    # 删除奇怪的模式
    wierd_pattern = re.compile(“[”;
        u“\U0001F600-\U0001F64F” # 表情符号
        u“\U0001F300-\U0001F5FF” # 符号 &amp;象形文字
        u“\U0001F680-\U0001F6FF” # 交通 &amp;地图符号
        u“\U0001F1E0-\U0001F1FF” # 标志 (iOS)
        u“\U00002702-\U000027B0”
        u“\U000024C2-\U0001F251”
        u“\U0001f926-\U0001f937”
        你&#39;\U00010000-\U0010ffff&#39;
        你“\u200d”
        u“\u2640-\u2642”
        u“\u2600-\u2B55”
        你“\u23cf”
        你“\u23e9”
        你“\u231a”
        你“\u3030”
        u“\ufe0f”
        你“\u2069”
        你“\u2066”
        # 你“\u200c”
        你“\u2068”
        你“\u2067”
        “]+”，flags=re.UNICODE)
    
    文本 = wierd_pattern.sub(r&#39;&#39;, 文本)
    
    # 删除多余的空格、主题标签
    文本 = re.sub(“#”, “”, 文本)
    文本 = re.sub(“\s+”, “”, 文本)
    
    返回文本

 data[&#39;cleaned_comment&#39;] = data[2].apply(cleaning)

# 根据评论的字词计算评论的长度
数据[&#39;cleaned_comment_len_by_words&#39;] = 数据[&#39;cleaned_comment&#39;].apply(lambda t: len(hazm.word_tokenize(t)))

# 删除长度少于三个字的评论
data[&#39;cleaned_comment_len_by_words&#39;] = data[&#39;cleaned_comment_len_by_words&#39;].apply(lambda len_t: len_t if minlim &lt; len_t &lt;= maxlim else len_t)
数据 = data.dropna(subset=[&#39;cleaned_comment_len_by_words&#39;])
数据 = data.reset_index(drop=True)

数据.head()

错误：
TypeError Traceback（最近一次调用最后一次）

&lt;ipython-input-17-46d1839b8806&gt;在&lt;细胞系：1&gt;()
----&gt; 1 数据[&#39;cleaned_comment&#39;] = 数据[2].apply(cleaning)
      2
      3 # 根据评论的字数计算评论的长度
      4 数据[&#39;cleaned_comment_len_by_words&#39;] = 数据[&#39;cleaned_comment&#39;].apply(lambda t: len(hazm.word_tokenize(t)))
      5

4帧

&lt;ipython-input-12-1e73a60c1c12&gt;在清洁中（文本）
      8
      9#定期清洗
---&gt; 10 文本 = 干净（文本，
     11fix_unicode=真，
     12 to_ascii=假,

类型错误：clean() 得到了意外的关键字参数“fix_unicode”

请帮我解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/78468882/typeerror-clean-got-an-unexpected-keyword-argument-fix-unicode</guid>
      <pubDate>Sun, 12 May 2024 18:21:16 GMT</pubDate>
    </item>
    <item>
      <title>SVC 最小化问题中的两个不同公式意味着什么？</title>
      <link>https://stackoverflow.com/questions/78468865/what-two-different-formulas-in-svc-minimization-problem-means</link>
      <description><![CDATA[我正在研究支持向量机，对于软边距，我发现了如下形式的最小化问题：
最小化问题
这个公式似乎很容易理解，我们必须最小化权重，其结果将是增加边距，但由于它是软边距，我们允许某些点位于超平面的错误一侧，这表示为松弛变量的总和，但是在 sklean 之后我发现了另一种......形式？
另一种形式的最小化问题
这里我们有损失函数和惩罚函数，我无法真正理解我们如何解释它，在其他教程中我看到它带有松弛变量，这对我来说更容易。
但现在在我的课程作业中，我需要描述 sklearn 包中 SVC 的所有参数，您能否建议一些有关它的教程以及我应该考虑以上两个公式中的哪一个......更好？
我该如何处理损失和惩罚？它的数学意义是什么？
或者我应该更依赖哪个公式？
我试图找到关于这个主题的任何可以理解的教程，但我没有取得多大成功。]]></description>
      <guid>https://stackoverflow.com/questions/78468865/what-two-different-formulas-in-svc-minimization-problem-means</guid>
      <pubDate>Sun, 12 May 2024 18:16:11 GMT</pubDate>
    </item>
    <item>
      <title>交通密度预测的人工智能算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78468804/ai-algorithm-for-traffic-density-prediction</link>
      <description><![CDATA[我正在开发我的 FYP 项目，这是一个基于密度的交通控制器。数据将从红外传感器收集并发送到数据库。现在我想制作一个模型，根据传感器收集的数据预测未来的交通趋势。因此，建议我应该采取的方法来实现我的预期目标，并建议我一些可以在这种情况下提供最佳准确性的算法。
...................................................... ...................................................... ...................................................... ......................................]]></description>
      <guid>https://stackoverflow.com/questions/78468804/ai-algorithm-for-traffic-density-prediction</guid>
      <pubDate>Sun, 12 May 2024 17:54:03 GMT</pubDate>
    </item>
    <item>
      <title>K-Means：如何解决错误：scatter() 得到参数“c”的多个值</title>
      <link>https://stackoverflow.com/questions/78468674/k-means-how-to-solve-error-scatter-got-multiple-values-for-argument-c</link>
      <description><![CDATA[我是机器学习新手，我有一项任务要求我执行无监督学习，因此我决定使用 K-Means。
我使用Python来编码。我已将数据（我的数据来自 csv 文件）导入到 Google Colab 中。我的数据有 7 个特征，我需要绘制簇，但出现错误：scatter() 获得参数“c”的多个值。
这是我的代码：
这部分是我如何确定 k 值的。我使用肘部法。
%matplotlib 内联
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns； sns.set()
将 numpy 导入为 np
将 pandas 导入为 pd

从 sklearn.cluster 导入 KMeans

数据=“/内容/信息.csv”
df = pd.read_csv（数据，标题=0）
data = list(zip(x_train[&quot;日期&quot;], x_train[&quot;a&quot;], x_train[&quot;b&quot;], x_train[&quot;c&quot;], x_train[&quot;d&quot;], x_train[&quot;] e&quot;], x_train[&quot;f&quot;]))
打印（数据）

惯性 = []

对于范围 (1,40) 内的 i：
    kmeans = KMeans(n_clusters=i)
    kmeans.fit(数据)
    惯性.append(kmeans.inertia_)

plt.plot（范围（1,40），惯性，标记=&#39;o&#39;）
plt.title(&#39;弯头法&#39;)
plt.xlabel(&#39;簇数&#39;)
plt.ylabel(&#39;惯性&#39;)
plt.show()

这就是出错的地方：
kmeans = KMeans(n_clusters=5)
kmeans.fit(数据)
plt.scatter(x_train[“日期”], x_train[“a”], x_train[“b”], x_train[“c”], x_train[“d”], x_train[“e” ], x_train[“f”], c=kmeans.labels_)
plt.show()

该错误似乎表明出错的部分位于 plt.scatter() 行。
我尝试了 2 个功能，它可以工作，但是当涉及 7 个功能时，我收到错误消息。可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78468674/k-means-how-to-solve-error-scatter-got-multiple-values-for-argument-c</guid>
      <pubDate>Sun, 12 May 2024 17:07:02 GMT</pubDate>
    </item>
    <item>
      <title>我正在寻找最新的机器学习或深度学习方法来将 DNA 转换为数字链？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78468020/i-am-looking-for-recent-machine-learning-or-deep-learning-methods-to-convert-dna</link>
      <description><![CDATA[我有一个 DNA 序列，我想使用 AI 方法将该序列转换为另一个数字列表。
示例：
&lt;前&gt;&lt;代码&gt;S=[ACGCACGCAGCCGACGCAGCACCAAGCAGCAG]

改造后：
&lt;前&gt;&lt;代码&gt;St=[0.2,0.36,0.3,1.5......]

到目前为止我什么也没尝试。]]></description>
      <guid>https://stackoverflow.com/questions/78468020/i-am-looking-for-recent-machine-learning-or-deep-learning-methods-to-convert-dna</guid>
      <pubDate>Sun, 12 May 2024 13:25:20 GMT</pubDate>
    </item>
    <item>
      <title>使用Torchaudio库创建数据集时出错</title>
      <link>https://stackoverflow.com/questions/78466420/error-when-using-torchaudio-library-to-create-a-data-set</link>
      <description><![CDATA[我正在学习 YT 课程，研究使用 Torchaudio 的城市 8k 数据集。作者编写了完全相同的代码，但在我收到此错误时能够获得输出：
&lt;块引用&gt;
运行时错误：找不到适当的后端来处理 uri C:\Users\hbhavnag\Documents\Hussain\ASU\collision detector\urban sound\UrbanSound8K\audio\5\100263-2-0-121.wav 和格式无。

以下是我的代码：
from torch.utils.data 导入数据集
将 pandas 导入为 pd
导入火炬音频
导入操作系统

UrbanSoundDataset 类（数据集）：

    def __init__(自身,annotation_file,audio_dir):
        self.annotations = pd.read_csv(annotation_file)
        self.audio_dir = 音频_dir

    def __len__(自身):
        返回 len(self.annotations)

    def __getitem__(自身，索引)：
        audio_sample_path = self._get_audio_sample_path(索引)
        标签 = self._get_audio_sample_label(索引)
        信号，sr = torchaudio.load（audio_sample_path）
        返回信号、标签
    
    def _get_audio_sample_path（自身，索引）：
        Fold = f“fold{self.annotations.iloc[index,5]}”
        路径 = os.path.join(self.audio_dir, 折叠, self.annotations.iloc[index,0])
        返回路径
    
    def _get_audio_sample_label（自身，索引）：
        返回 self.annotations.iloc[index,6]
    
    如果 __name__ == “__main__”：
        注释_文件 = r“C:\Users\hbhavnag\Documents\Hussain\ASU\碰撞检测\城市声音\UrbanSound8K\metadata\UrbanSound8K.csv”
        audio_dir = r&quot;C:\Users\hbhavnag\Documents\Hussain\ASU\碰撞检测\城市声音\UrbanSound8K\audio&quot;
        usd = UrbanSoundDataset（注释文件，音频目录）
        print (f“数据集中有 {len(usd)} 个样本”)

    信号，标签 = 美元[2]

我尝试查找 Torchaudio 的文档，但不确定是否有任何内容可以直接帮助我。我假设存在一些版本兼容性问题。
我使用的是 Windows。]]></description>
      <guid>https://stackoverflow.com/questions/78466420/error-when-using-torchaudio-library-to-create-a-data-set</guid>
      <pubDate>Sun, 12 May 2024 00:34:24 GMT</pubDate>
    </item>
    <item>
      <title>我如何在 django web 上显示终端输出和 matplotlib 图形</title>
      <link>https://stackoverflow.com/questions/78465419/how-can-i-show-the-terminal-output-and-matplotlib-graphic-on-django-web</link>
      <description><![CDATA[我不知道该怎么做。这是我的 py 代码。 #
&lt;前&gt;&lt;代码&gt;
虹膜 = load_iris()
X = 虹膜数据
y = 虹膜.目标

plt.figure(figsize=(10, 6))
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=&#39;viridis&#39;)
plt.xlabel(&#39;萼片长度&#39;)
plt.ylabel(&#39;萼片宽度&#39;)
plt.title(&#39;Iris Veri Seti&#39;)
plt.colorbar(标签=&#39;类&#39;)
plt.show()
Veri setini eğitim ve test setlerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)

分类器={
    “决策树”：DecisionTreeClassifier()，
    “随机森林”：RandomForestClassifier(),
    “梯度提升”：GradientBoostingClassifier()，
    “AdaBoost”：AdaBoostClassifier()
}

结果={}
对于名称，clf in classifiers.items()：
    clf.fit(X_train_scaled, y_train)
    y_pred = clf.predict(X_test_scaled)
    准确度=准确度_分数（y_test，y_pred）
    精度 = precision_score(y_test, y_pred, 平均值=&#39;加权&#39;)
    召回率=召回率（y_test，y_pred，平均值=&#39;加权&#39;）
    f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)
    results[name] = {“Accuracy”：准确率，“Precision”：精确率，“Recall”：召回率，“F1 Score”：f1}

print(&quot;Sınıflandırma Algoritması\tAccuracy\tPrecision\tRecall\tF1 Score&quot;)
对于名称，results.items() 中的指标：
    print(f&quot;{name}\t{metrics[&#39;Accuracy&#39;]:.4f}\t{metrics[&#39;Precision&#39;]:.4f}\t{metrics[&#39;Recall&#39;]:.4f}\t{metrics [&#39;F1 分数&#39;]:.4f}&quot;)


有没有简单的方法可以在网页上拍摄它？可以是 django 或其他东西，但它必须在网页上。
这是 matplotlib 输出
这是终端的输出]]></description>
      <guid>https://stackoverflow.com/questions/78465419/how-can-i-show-the-terminal-output-and-matplotlib-graphic-on-django-web</guid>
      <pubDate>Sat, 11 May 2024 16:56:57 GMT</pubDate>
    </item>
    <item>
      <title>我可以在我的 Flutter 应用程序中集成将执行语音命令的自定义 AI 模型吗？</title>
      <link>https://stackoverflow.com/questions/78458925/can-i-integrate-custom-ai-model-which-will-do-on-voice-commands-in-my-flutter-ap</link>
      <description><![CDATA[我想知道，因为我与人工智能并没有密切相关并集成它，也没有尝试过，是否有可能集成某种定制的人工智能模型来完成下一步的事情，例如：“嘿，你可以转到我的个人资料设置吗”。对于结果，我希望该人工智能模型能够自动响应我的导航到个人资料屏幕。我不知道这对于 Flutter 是否可行。
我做了一些研究，建议使用语音转文本，反之亦然，Tflite、Pytorch 等。通过他们自己的文本到语音转换功能，我可以从语音中获取文本，并基于它创建执行特定任务的函数（例如导航到我的应用程序中的配置文件设置）。但我不太确定是否要使用自定义 AI。
这只是一个研究问题，如果有人对此有更多了解，并且我需要随意加入对话以帮助我更多地了解这一点..提前致谢！ ：D
没什么——只是一项研究。]]></description>
      <guid>https://stackoverflow.com/questions/78458925/can-i-integrate-custom-ai-model-which-will-do-on-voice-commands-in-my-flutter-ap</guid>
      <pubDate>Fri, 10 May 2024 08:36:43 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 实验跟踪重复</title>
      <link>https://stackoverflow.com/questions/76821347/sagemaker-experiment-tracking-duplication</link>
      <description><![CDATA[我正在尝试通过 AWS SageMaker 使用脚本模式训练模型。
我想使用 AWS SageMaker Experiments 以及训练作业中的一些计算指标来跟踪此训练作业。当我开始训练作业时，会成功创建一个新的实验运行，该实验运行跟踪所有提供的超参数（例如，nesimators）。
但是，如前所述，此外，我还想跟踪自定义脚本中的其他指标（例如准确性）。在这里，我在拟合模型之前使用 load_run()，然后使用 run.log_metric() 记录指标。但是，当我这样做时，SageMaker 会在 UI 中创建一个新的单独实验条目，这意味着我的超参数和指标单独存储在两个单独的实验运行中：

我希望在一次实验运行中看到所有指标和超参数的组合。我做错了什么？
这是我用来启动训练过程的缩写代码：
&lt;前&gt;&lt;代码&gt;
exp_name = “sklearn-脚本模式-实验”

与运行（
    实验名称=实验名称，
    sagemaker_session=sess,
）运行时：

    sklearn_estimator = SKLearn(&#39;train.py&#39;,
                                    instance_type=&#39;ml.m5.large&#39;,
                                    Framework_version=&#39;1.0-1&#39;,
                                    role=“arn:aws:iam:::role/service-role/AmazonSageMaker-ExecutionRole-”,
                                    超参数={&#39;nestimators&#39;: 100},
                                    环境={“区域”：区域})

    sklearn_estimator.fit({&#39;train&#39;: f&#39;s3://{BUCKET}/{S3_INPUT_PATH}&#39;})

这是缩写的train.py：
 #在这里解析参数...等等...


    模型 = RandomForestClassifier(n_estimators=args.nesimators,
                                   最大深度=5，
                                   随机状态=1）

    使用 load_run(sagemaker_session=sagemaker_session) 运行：

        模型.fit(X, y)

        run.log_metric(name = &quot;最终测试损失&quot;, value = 0.9)
]]></description>
      <guid>https://stackoverflow.com/questions/76821347/sagemaker-experiment-tracking-duplication</guid>
      <pubDate>Wed, 02 Aug 2023 15:20:27 GMT</pubDate>
    </item>
    <item>
      <title>如何将机器学习应用于模糊匹配</title>
      <link>https://stackoverflow.com/questions/43366705/how-to-apply-machine-learning-to-fuzzy-matching</link>
      <description><![CDATA[假设我有一个 MDM 系统（主数据管理），其主要应用是检测和防止记录重复。 
每次销售代表在系统中输入新客户时，我的 MDM 平台都会对现有记录进行检查，计算单词或短语或属性对之间的 Levenshtein 或 Jaccard 或 XYZ 距离，考虑权重和系数并输出相似度得分等等。 
典型的模糊匹配场景。
我想知道应用机器学习技术来优化匹配输出是否有意义，即以最大准确度查找重复项。 
以及它最有意义的地方。 

优化属性的权重？
通过预测比赛结果来提高算法置信度？
了解我要配置到算法中的匹配规则？
还有别的事吗？

还有关于该主题的这个出色的答案，但我没有不太明白这个人是否真的使用了机器学习。 
我的理解是，加权模糊匹配已经是一个足够好的解决方案，甚至从财务角度来看也是如此，因为每当您部署这样的 MDM 系统时，您都必须进行一些分析和预处理，无论是手动编码匹配规则或训练机器学习算法。
所以我不确定添加机器学习是否会代表一个重要的价值主张。 
任何想法都值得赞赏。]]></description>
      <guid>https://stackoverflow.com/questions/43366705/how-to-apply-machine-learning-to-fuzzy-matching</guid>
      <pubDate>Wed, 12 Apr 2017 10:16:48 GMT</pubDate>
    </item>
    </channel>
</rss>