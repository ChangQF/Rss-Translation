<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 14 Aug 2024 06:22:48 GMT</lastBuildDate>
    <item>
      <title>Scikit-learn 版本不匹配问题。我不知道应该安装哪个版本</title>
      <link>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</link>
      <description><![CDATA[在此处输入图片说明我正在努力解决涉及 Scikit-learn 的版本不匹配问题，事实证明这是一个相当棘手的问题。每当我尝试安装不同版本的 Scikit-learn 时，我都会遇到一系列错误，这些错误似乎因我尝试的每个版本而异。问题的核心似乎是 Scikit-learn 与其依赖项（例如 NumPy 和 SciPy）之间的不兼容性。这些依赖项对于 Scikit-learn 正常运行至关重要，找到可以协同工作的正确版本已成为一项艰巨的任务。尽管我付出了努力，但我还是无法找到一个可以解决错误并与我现有设置很好地集成的 Scikit-learn 版本。反复试验的过程只会导致越来越多的挫败感，因为每个新版本都会带来自己的一系列问题，而不是解决核心问题。此版本不匹配严重影响了我在项目中有效使用 Scikit-learn 的能力。缺乏关于如何将 Scikit-learn 与其依赖项的兼容版本对齐的明确指导增加了我的困难，使我很难继续工作并实现预期成果。]]></description>
      <guid>https://stackoverflow.com/questions/78869112/scikit-learn-version-mismatch-problem-and-i-dont-know-which-version-should-be</guid>
      <pubDate>Wed, 14 Aug 2024 04:15:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Pytorch 为二进制数据集实现自动编码器</title>
      <link>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset-using-pytorch</link>
      <description><![CDATA[我对 Autoencoder 及其功能非常陌生。我被要求创建一个重建二进制 CSV 文件（解码）的 Autoencoder。
我根据 geeksforgeeks 的 MNIST 示例实现了一个。但我对包括损失计算和 relu 和线性部分的正确性非常不确定。我做了一些研究，似乎在这种情况下 BCEloss 也比 MSEloss 更好。
任何建议都非常感谢。
以下代码可以生成输出，但损失非常小。建议的批量大小、隐藏维度层和时期数是多少。

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim

# 设置随机种子以实现可重复性
np.random.seed(42)
torch.manual_seed(42)

# 生成玩具数据：D = 100 名患者，K = 10 个表型，二进制值（0 或 1）
D，K = dm.shape
#data = np.random.randint(0, 2, size=(D, K)).astype(np.float32)

# 将 numpy 数组转换为 PyTorch 张量
data_tensor = torch.tensor(dm)
print(data_tensor.shape)

# 定义 Autoencoder 模型
class Autoencoder(nn.Module):
def __init__(self, input_dim, hidden_​​dim):
super(Autoencoder, self).__init__()
# 编码器
self.encoder = nn.Sequential(
nn.Linear(input_dim, hidden_​​dim),
nn.ReLU()
)
# 解码器
self.decoder = nn.Sequential(
nn.Linear(hidden_​​dim, input_dim),
nn.Sigmoid()
)

def forward(self, x):
coded = self.encoder(x)
coded = self.decoder(encoded)
return解码

# 超参数
input_dim = K
hidden_​​dim = 5 # 隐藏层维度，需要调整

# 初始化模型、损失函数和优化器
model = Autoencoder(input_dim=input_dim, hidden_​​dim=hidden_​​dim)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练参数
num_epochs = 5
batch_size = 10

# 训练循环
for epoch in range(num_epochs):
for i in range(0, D, batch_size):
batch_data = data_tensor[i:i+batch_size]

# 正向传递
outputs = model(batch_data)
loss = criterion(outputs, batch_data)

# 反向传递和优化
optimizer.zero_grad()
loss.backward()
optimizer.step()

#print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss}&#39;)
if (epoch+1) % 10 == 0:
print(f&#39;Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}&#39;)

# 通过重建输入数据测试模型
with torch.no_grad():
reconstructed = model(data_tensor)

print(&quot;Original Data:&quot;)
print(data_tensor)

print(&quot;Reconstructed Data:&quot;)
print(reconstructed)
]]></description>
      <guid>https://stackoverflow.com/questions/78868720/how-to-implement-an-autoencoder-for-a-binary-dataset-using-pytorch</guid>
      <pubDate>Wed, 14 Aug 2024 00:44:26 GMT</pubDate>
    </item>
    <item>
      <title>如何将保存的模型从 Kaggle 导入和下载到本地模型</title>
      <link>https://stackoverflow.com/questions/78867971/how-to-import-and-download-saved-models-from-kaggle-to-local-model</link>
      <description><![CDATA[我正在开展一个使用模型组合进行集成训练的项目，但在处理某些数据格式时遇到了问题。我能够在 Kaggle 上成功下载并使用 gemma 和 llama 语言模型，但很难从 Bert 模型下载并转换为有用的模型进行预处理。文件格式为 .pb 保存的模型格式。到目前为止，我已经成功导入了模型数据，构建了编码器，并从下载的文件中保存了一个模型（至少我认为是这样）。这是我目前所拥有的：
import tensorflow as tf
from transformers import BertTokenizer
import kagglehub
import keras

# 下载模型（假设已设置 api 密钥和访问权限）
path = kagglehub.model_download(&quot;tensorflow/bert/tensorFlow2/en-wwm-uncased-l-24-h-1024-a-16&quot;)

print(&quot;模型文件路径：&quot;, path)

model_path=path
#使用 keras 和 bert tokenizer 构建模型和编码器
model = keras.layers.TFSMLayer(model_path, call_endpoint=&#39;serving_default&#39;)
encoder = BertTokenizer.from_pretrained(model_path+r&#39;\assets\vocab.txt&#39;)

# 概念证明
print(&quot;用户：&quot;)
input_text = tf.keras.layers.Input(shape=(), dtype=tf.string)
# 标记输入（此处出错）
tokenize=[encoder(segment) for fragment in input_text]

我遇到的主要问题是 tokenizer。当我标记文本时，它会抛出错误：
回溯（最近一次调用最后一次）：
文件“C:\Users\cwaid\example4.py”，第 20 行，位于 &lt;module&gt;
tokenize=[encoder(segment) for section in input_text]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\cwaid\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\backend\common\keras_tensor.py&quot;, line 120, in __iter__
raise NotImplementedError(
NotImplementedError: 不支持对符号 KerasTensor 进行迭代。

我不太确定我的模型和编码器是否根据此错误正确初始化，但我不知道如何修复它，因为这是从Kaggle 文档。
就我的项目而言，我没有使用 kaggle journal 或 jupyter notebook，因为我试图用低级语言构建一个独立的预训练模型系统，用于集成学习，而是用 python 构建一个概念证明。
我曾尝试将 pb 文件转换为纯 keras 和元文件，但没有一个有据可查的解决方案，所以我试图避免这样做，以免使我正在做的事情复杂化（尽管如果它更合适，我愿意接受它）。此外，我尝试将其转换为基于 pytorch 的系统，但似乎除非我的模型和编码器正确，否则数据不适合直接翻译，但同样，我不知道是否是这种情况。]]></description>
      <guid>https://stackoverflow.com/questions/78867971/how-to-import-and-download-saved-models-from-kaggle-to-local-model</guid>
      <pubDate>Tue, 13 Aug 2024 19:13:56 GMT</pubDate>
    </item>
    <item>
      <title>COCO 格式到 YOLO 格式（分割蒙版）[关闭]</title>
      <link>https://stackoverflow.com/questions/78867841/coco-format-to-yolo-format-segmentation-masks</link>
      <description><![CDATA[我需要分割我拥有的图像，以便创建用于训练 YOLOv8-seg 的数据集。
我正在尝试使用 CVAT 创建分割蒙版，但是我无法使用 YOLO 导出格式导出分割注释，因此我使用 COCO 导出格式，然后考虑将其转换为 YOLO 格式。
如何使用 Python 代码将 COCO 格式（带分割）转换为 YOLO 格式（带分割）？
有谁知道任何（免费/便宜）工具可以自动将分割导出为 YOLO 格式，而不必转换 COCO 格式？]]></description>
      <guid>https://stackoverflow.com/questions/78867841/coco-format-to-yolo-format-segmentation-masks</guid>
      <pubDate>Tue, 13 Aug 2024 18:23:45 GMT</pubDate>
    </item>
    <item>
      <title>如何使用声学信号处理和机器学习将蓝莓分类为“脆”、“多汁”或“软”？[关闭]</title>
      <link>https://stackoverflow.com/questions/78867785/how-to-classify-blueberries-as-crunchy-juicy-or-soft-using-acoustic-signa</link>
      <description><![CDATA[我正在开展一个项目，根据蓝莓的质地对蓝莓进行分类，具体来说，是软的、多汁的还是脆的，使用蓝莓压碎时发出的声音。我有大约 1100 个音频样本，并且为每个样本生成了声谱图。
不幸的是，我没有标记数据，所以我不能直接应用监督机器学习技术。相反，我正在寻找基于声谱图区分这三个类别的有效方法。
我附上了我认为可能是软的、多汁的和脆的蓝莓的声谱图示例。但是，由于数据没有标记，我不确定这些假设是否正确。
这是我的假设：
脆浆果：压碎时，它们会在音频信号中产生单独的、不同的峰值。这些峰值随时间而分散，表明浆果正在以清晰、分段的方式分裂。
脆浆果
多汁浆果：压碎时，它们会在音频信号中产生连续的峰值。这些峰值更紧密地堆积在一起并持续存在，表明果汁和果肉会爆发，阻力较小，从而产生更平滑的声音。
多汁浆果
软浆果：这些浆果产生的峰值很少且很小。声音微弱且不太清晰，表明浆果很容易被压碎，阻力很小，对音频信号的干扰最小。
软浆果
我尝试的方法：
我尝试通过检测音频信号特定时间范围内的峰值来对蓝莓进行分类。这种方法让我能够有效地区分软浆果和脆浆果，因为软浆果产生的峰值更少、更小，而脆浆果的峰值则明显、分离。
我的预期：
我预计这种峰值检测方法也有助于对多汁浆果进行分类，因为我预计连续、幅度更高的峰值将与其他类别不同。
实际发生的情况：
虽然该方法对软浆果和脆浆果很有效，但未能成功区分多汁浆果。多汁浆果峰的连续性并不像我预期的那样突出，因此很难对它们进行准确的分类。]]></description>
      <guid>https://stackoverflow.com/questions/78867785/how-to-classify-blueberries-as-crunchy-juicy-or-soft-using-acoustic-signa</guid>
      <pubDate>Tue, 13 Aug 2024 18:10:48 GMT</pubDate>
    </item>
    <item>
      <title>YOLOV8 创建了太多边界框[重复]</title>
      <link>https://stackoverflow.com/questions/78867501/yolov8-creating-too-many-bounding-boxes</link>
      <description><![CDATA[我使用 yoloV8 训练了一个模型，该模型有助于检测摩托车骑手的头盔，并尝试通过创建虚拟环境 venv 并安装以下软件包 numpy opencv-python tensorflow ultralytics 来运行
起初，它向我显示了错误

OSError：[WinError 126] 找不到指定的模块。加载“D:\ACADEMICS\projects\helmet\venv\Lib\site-packages\torch\lib\fbgemm.dll”时出错或其依赖项之一。

通过在安装过程中下载 Visual Studio 2022 社区版 并安装 C++ 桌面环境 解决了缺少文件的问题。
但是现在在随机位置创建的边界框太多了
以下是示例
太多框
它实际上应该是什么样的
预期结果

已编辑 == 在下面添加了代码

import cv2
from ultralytics import YOLO

模型 = YOLO(&quot;runs/detect/train2/weights/best.pt&quot;)

结果 = 模型.预测(source=&#39;download.jpeg&#39;, show = True, save=True)
]]></description>
      <guid>https://stackoverflow.com/questions/78867501/yolov8-creating-too-many-bounding-boxes</guid>
      <pubDate>Tue, 13 Aug 2024 16:57:54 GMT</pubDate>
    </item>
    <item>
      <title>我的 ML 二元分类模型的最终预测准确率非常糟糕[关闭]</title>
      <link>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863903/final-predictions-accuracy-of-my-ml-binary-classification-model-is-horrible</guid>
      <pubDate>Mon, 12 Aug 2024 23:32:18 GMT</pubDate>
    </item>
    <item>
      <title>我们如何运行 Apple 雪貂模型？</title>
      <link>https://stackoverflow.com/questions/78863794/how-do-we-run-the-apple-ferret-model</link>
      <description><![CDATA[我已经安装了苹果雪貂模型所需的所有权重和检查点，除了运行 3 个终端并测试演示之外，我如何在本地运行模型来为图像文件夹添加标题？
我尝试了 https://vivekupadhyay1.medium.com/how-to-use-ferret-apples-open-source-multimodal-llm-for-your-next-project-c561f0087a5d，但无法找到 github repo 中提到的 eval.py 或脚本。]]></description>
      <guid>https://stackoverflow.com/questions/78863794/how-do-we-run-the-apple-ferret-model</guid>
      <pubDate>Mon, 12 Aug 2024 22:36:25 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个掩模进行医学图像分割，然后进行逐像素分类？</title>
      <link>https://stackoverflow.com/questions/78863682/how-to-go-for-medical-image-segmentation-with-multiple-masks-and-then-doing-pixe</link>
      <description><![CDATA[我获得了训练图像，每幅图像都有两个掩码，分别代表两个不同的类别。我应该如何分割图像，然后进行像素分类，以获得输出图像，其中 0 代表背景，1 和 2 代表两个类别？
我尝试组合掩码，然后将掩码和相应的图像输入分割模型，但不知何故我失败了。我是否应该组合掩码，因为我们还需要在输出中对像素进行分类。]]></description>
      <guid>https://stackoverflow.com/questions/78863682/how-to-go-for-medical-image-segmentation-with-multiple-masks-and-then-doing-pixe</guid>
      <pubDate>Mon, 12 Aug 2024 21:37:57 GMT</pubDate>
    </item>
    <item>
      <title>当我的游戏对象的任何部分发生碰撞时，代理为空</title>
      <link>https://stackoverflow.com/questions/78863425/agent-is-null-when-any-part-of-my-game-object-collides</link>
      <description><![CDATA[我正在根据 Unity 的 WalkerAgent 训练布娃娃走路，我做了一些改动以更好地满足我的目的。现在，每当布娃娃的任何身体部位与地面碰撞时，代理都是空的，从而阻止任何奖励被应用。
我多次检查了我的代码，看起来没有任何问题。该项目似乎也设置正确。导致我陷入这种困境的原始错误是

nullreferenceexception：对象引用未设置为对象实例Unity.MLAgentsExamples.ObjectContact.OnCollisionStay
(UnityEngine.Collision col) (at
Assets/Scripts/ObjectContact.cs:55)UnityEngine.Physics:OnSceneContact(PhysicsScene,
IntPtr, Int32) (at
/Users/bokken/build/output/unity/unity/Modules/Physics/ScriptBindings/PhysicsContact.bindings.cs:49)

我很确定所有事情都按正确的顺序发生，并且代理应该在调用之前初始化。
据我所知，这些是代码。
来自 WalkerAgent（主脚本）：
public override void Initialize()
{
m_OrientationCube = GetComponentInChildren&lt;OrientationCubeController&gt;();

//设置每个身体部位
m_JdController = GetComponent&lt;JointDriveController&gt;();

m_JdController.SetupBodyPart(hips);
m_JdController.SetupBodyPart(spine);
m_JdController.SetupBodyPart(head);
m_JdController.SetupBodyPart(legrotateL);
m_JdController.SetupBodyPart(thighL);
m_JdController.SetupBodyPart(kneerotateL);
m_JdController.SetupBodyPart(shinL);
m_JdController.SetupBodyPart(footL);
m_JdController.SetupBodyPart(腿部旋转R);
m_JdController.SetupBodyPart(大腿R);
m_JdController.SetupBodyPart(膝盖旋转R);
m_JdController.SetupBodyPart(小腿R);
m_JdController.SetupBodyPart(脚R);
m_JdController.SetupBodyPart(手臂旋转L);
m_JdController.SetupBodyPart(手臂L);
m_JdController.SetupBodyPart(前臂旋转L);
m_JdController.SetupBodyPart(前臂L);
m_JdController.SetupBodyPart(手L);
m_JdController.SetupBodyPart(手臂旋转R);
m_JdController.SetupBodyPart(手臂R);
m_JdController.SetupBodyPart(前臂旋转R);
m_JdController.SetupBodyPart(前臂R);
m_JdController.SetupBodyPart(handR);
}

来自 JointDriveController：
public void SetupBodyPart(Transform t)
{
var bp = new BodyPart
{
rb = t.GetComponent&lt;Rigidbody&gt;(),
joint = t.GetComponent&lt;CharacterJoint&gt;(),
StartingPos = t.position,
StartingRot = t.rotation
};
bp.rb.maxAngularVelocity = k_MaxAngularVelocity;

// 添加并设置地面接触脚本
bp.objectContact = t.GetComponent&lt;ObjectContact&gt;();

var agent = gameObject.GetComponent&lt;Agent&gt;();
如果 (agent == null)
{
agent = gameObject.AddComponent&lt;Agent&gt;();
}
bp.objectContact.agent = agent;

如果 (!bp.objectContact)
{
bp.objectContact = t.gameObject.AddComponent&lt;ObjectContact&gt;();
bp.objectContact.agent = gameObject.GetComponent&lt;Agent&gt;();
}
else
bp.objectContact.agent = gameObject.GetComponent&lt;Agent&gt;();

如果 (bp.objectContact.agent == null)
Debug.LogError($&quot;未找到 {t.name} 的代理&quot;);

bp.thisJdController = this;
bodyPartsDict.Add(t, bp);
bodyPartsList.Add(bp);
}

来自 ObjectContact：
void OnCollisionEnter(Collision col)
{
if (agent == null)
{
Debug.LogError($&quot;Agent is null on {gameObject.name} during OnCollisionEnter with {col.gameObject.name}&quot;);
return;
}

if (col.transform.CompareTag(k_Ground))
touchingGround = true;

if (col.transform.CompareTag(k_Wall))
touchingWall = true;

if (col.transform.CompareTag(k_Target))
{
touchingTarget = true;
agent.AddReward(targetReward);
}
}

void OnCollisionStay(Collision col)
{
if (col.transform.CompareTag(k_Ground))
agent.AddReward(groundContactPenalty);

if (col.transform.CompareTag(k_Wall))
agent.AddReward(wallContactPenalty);

Debug.Log($&quot;OnCollisionStay called for {gameObject.name} with {col.gameObject.name}&quot;);

if (agent == null)
{
Debug.LogError(&quot;Agent is null during OnCollisionStay&quot;);
return;
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/78863425/agent-is-null-when-any-part-of-my-game-object-collides</guid>
      <pubDate>Mon, 12 Aug 2024 20:07:45 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 Torch 使用 4 个 GPU 进行训练：torch.distributed.elastic.multiprocessing.api</title>
      <link>https://stackoverflow.com/questions/78863216/unable-to-train-with-4-gpus-using-torch-torch-distributed-elastic-multiprocessi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78863216/unable-to-train-with-4-gpus-using-torch-torch-distributed-elastic-multiprocessi</guid>
      <pubDate>Mon, 12 Aug 2024 19:01:10 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的 Sums 包无法进行标记</title>
      <link>https://stackoverflow.com/questions/78862511/sums-package-failing-to-tokenize-in-python</link>
      <description><![CDATA[我使用以下代码在 Python 中总结我的文本。代码正在 Jupyter Notebook 中运行。我已经使用 pip 命令安装了 sumy。
pip install sumy nltk
python -m nltk.downloader punkt

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer
from io import StringIO

# 定义要总结的文本
text = &quot;&quot;&quot;
自然语言处理 (NLP) 是人工智能的一个领域，专注于通过自然语言实现计算机与人类之间的互动。NLP 的最终目标是使计算机能够以有价值和有意义的方式理解、解释和响应人类语言。
NLP 用于应用算法来识别和提取自然语言规则，从而将非结构化语言数据转换为计算机可以理解的形式。当提供文本时，计算机可以采用多种不同的方法来处理它。算法可以是基于规则的方法，也可以是基于机器学习的方法。
“”“”

# 使用 StringIO 模拟文件类对象
text_io = StringIO(text)

# 解析文本
parser = PlaintextParser.from_file(text_io, Tokenizer(&quot;english&quot;))

# 初始化 LSA 摘要器
summarizer = LsaSummarizer()

# 生成摘要（您可以调整句子数量）
summary = summaryr(parser.document, sentences_count=2)

# 打印摘要
for sentence in summary:
print(sentence) 

当我运行程序时，我收到以下错误：
ame)
662 def find_class(self, module, name):
663 # 禁止每个函数
--&gt; 664 引发 pickle.UnpicklingError(f&quot;全局 &#39;{module}.{name}&#39; 被禁止&quot;)

UnpicklingError: 全局 &#39;copy_reg._reconstructor&#39; 被禁止 

有什么想法！]]></description>
      <guid>https://stackoverflow.com/questions/78862511/sums-package-failing-to-tokenize-in-python</guid>
      <pubDate>Mon, 12 Aug 2024 15:37:15 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降算法中的学习率</title>
      <link>https://stackoverflow.com/questions/78844901/learning-rate-in-gradient-descent-algorithm</link>
      <description><![CDATA[在梯度下降算法中，我根据它们的导数更新B和M值，然后将它们与学习率值相乘，但是当我对L使用相同的值，例如0.0001时，它不能正常工作。减小或增加L值不起作用。作为一种解决方法，我不得不为b和m值设置不同的L值。这是正常的还是有错误？
import pandas as pd
import matplotlib.pyplot as plt
import time
import random

# Veri seti
veri_seti = &quot;study_score_decreasing.csv&quot; #study_score_decreasing.csv #study_score_increasing.csv 
data = pd.read_csv(veri_seti)

# 梯度下降 Fonksiyonu
def gradient_descent(m_next, b_next, points, L):
m_gradient = 0
b_gradient = 0
n = len(points)

for i in range(n):
x = points.iloc[i].study_time
y = points.iloc[i].score

m_gradient += -(2/n) * x * (y - (m_next * x + b_next))
b_gradient += -(2/n) * (y - (m_next * x + b_next))

m = m_next - m_gradient * 0.0001 #(L = 0.0001)
b = b_next - b_gradient * 0.1 #(L = 0.1)

return m, b

# 图形选项 图表
def show_graph(m, b):
plt.scatter(data.study_time, data.score, color=&quot;red&quot;)
x_range = range(int(data.study_time.min()), int(data.study_time.max()) + 1)
plt.plot(x_range, [m * x + b for x in x_range], color=&quot;blue&quot;)
plt.xlabel(&#39;学习时间&#39;)
plt.ylabel(&#39;分数&#39;)
plt.title(&#39;学习时间与分数&#39;)
plt.show()
time.sleep(0.001)
print(&quot;=&gt; F(X):&quot;, round(m, 1), &quot;X +&quot;, round(b, 3))

# Ana Fonksiyon
def main(m, b, L, epochs):
print(&quot;=&gt; F(X):&quot;, m, &quot;X&quot;, b)

for i in range(epochs):
m, b = gradient_descent(m, b, data, L)
show_graph(m, b)

# 基础说明
main(random.uniform(-1, 110), random.uniform(-10, 10), 0.1, 250)

我逐个更新了L值，得到了合乎逻辑的结果，但是用一个共同的L值，为什么解看起来不合逻辑呢？]]></description>
      <guid>https://stackoverflow.com/questions/78844901/learning-rate-in-gradient-descent-algorithm</guid>
      <pubDate>Wed, 07 Aug 2024 16:59:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOv8 进行大量错误检测</title>
      <link>https://stackoverflow.com/questions/78820748/alot-of-incorrect-detection-using-yolov8</link>
      <description><![CDATA[我尝试使用 Visual Code Studio 运行 YOLOv8。安装了 ultralytics 并在 vs code 终端上运行了 yolo predict model=yolov8n.pt source=&#39;https://ultralytics.com/images/bus.jpg&#39;。
但是我收到的输出是
2 个人、1 辆自行车、5 辆汽车、10 辆摩托车、73 艘船、3 个停车标志、1 只狗、10 匹马、10 头牛、32 只熊、1 只长颈鹿、63 把雨伞、6 个手提包、9 个飞盘、15 块滑雪板、5 块冲浪板、12 把刀、5 张床、37 张餐桌

这些显然不是这张图片的一部分。

当我第一次安装 ultralytics 并尝试运行 torch 时，出现了缺少依赖项的错误。fbgemm.ddl 丢失。后来，当我安装 vs_BuildTools 时，这个问题得到了解决。然后我继续在虚拟环境中运行代码，其中使用 torch 的程序运行没有任何错误。然后我继续输入此代码片段并遇到此问题。我也尝试使用命令提示符和 jupyter 笔记本运行，但同样的问题仍然存在。
我也检查了版本是否兼容，结果是兼容的。我还没有安装 cuda，是因为这个原因还是还有其他我不知道的问题？请有人帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78820748/alot-of-incorrect-detection-using-yolov8</guid>
      <pubDate>Thu, 01 Aug 2024 11:33:58 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的空间数据框中识别横断面上的点</title>
      <link>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</link>
      <description><![CDATA[我有调查数据，沿着与海岸垂直的平行横断面每隔 1 海里记录一次。对于每条记录，我都有纬度和经度、速度、方位等信息。沿着横断面，速度约为 10 节。我还在样条间（速度可能不同，方位肯定不同）处有一些点，如果进行了拖网，我还在样条外有一些点。
我想要做的是将属于同一样条的所有点分组（例如，参见图）：

这只是使用 1 NM 点间距离完成的，正如您在图中看到的那样，这实际上不起作用，因为只要有样条间（如样条 5），它就会与样条本身分组在一起。此外，在横断面 13 中，由于某种原因，2 个后续记录之间的距离略大于 1 海里，因此这些点被分成 2 个横断面（您可以看到颜色略有不同）。
此处显示的数据框示例：
 |year |datetime |xkm |ykm |logdiff |time_diff |distance |bearing |speed |
|&lt;dbl&gt; |&lt;dttm&gt; |&lt;dbl&gt; |&lt;dbl&gt; |&lt;dbl&gt;| &lt;dbl&gt;| &lt;drtn&gt; | &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;|
|------|---------- |------|-----|--------|------ --|---------|--------|------|
|2023 |2023-09-26 15:03:00 |221. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:08:00 |223. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:14:00 |225. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:19:00 |227. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:25:00 |229. |1606.| 1| 360 秒 | 1| -1.84| 10|
|2023 |2023-09-26 15:30:00 |231. |1606.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:36:00 |233. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:41:00 |234. |1605.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:47:00 |236. |1605.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:52:00 |238. |1605.| 1| 300 秒 | 1| -1.58| 12|

在 R 中解决这个问题的最佳方法是什么？我考虑过一些无监督的机器学习算法，比如使用 dbscan 进行聚类，但我不确定我是否正确使用了它。除了点之间的距离，我还想使用其他参数来分类一个点是否属于横断面（例如方位和速度）。
我的尝试：
# 准备聚类数据
clustering_data &lt;- df %&gt;% select(year, speed, bearing, xkm, ykm)

dput(clustering_data) 

# dput 输出
structure(list(year = c(2023, 2023, 2023, 2023, 2023, 2023, 2023, 
2023, 2023, 2023), datetime = c(45195.6270833333, 45195.6305555556, 
45195.6347222222, 45195.6381944444, 45195.6423611111, 45195.6458333333, 
45195.65, 45195.6534722222, 45195.6576388889, 45195.6611111111
), xkm = c(221, 223, 225, 227, 229, 231, 233, 234, 236, 238), 
ykm = c(1606, 1606, 1606, 1606, 1606, 1606, 1606, 1605, 1605, 
1605), logdiff = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1), time_diff = c(&quot; 360 秒 &quot;, 
&quot; 300 秒 &quot;, &quot; 360 秒 &quot;, &quot; 300 秒 &quot;, &quot; 360 秒 &quot;, &quot; 300 秒 &quot;, 
&quot; 360 秒 &quot;, &quot; 300 秒 &quot;, &quot; 360 秒 &quot;, &quot; 300 秒 &quot;), 
distance = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1), bearing = c(-1.58, 
-1.58, -1.58, -1.58, -1.84, -1.85, -1.58, -1.85, -1.58, -1.58
), speed = c(10, 12, 10, 12, 10, 12, 10, 12, 10, 12)), row.names = c(NA, 
10L), class = &quot;data.frame&quot;)

# 应用 DBSCAN 聚类
set.seed(123)
db &lt;- dbscan(clu​​stering_data, eps = 1.8, minPts = 5)


有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</guid>
      <pubDate>Wed, 24 Jul 2024 10:33:52 GMT</pubDate>
    </item>
    </channel>
</rss>