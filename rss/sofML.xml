<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 02 Jul 2024 18:20:30 GMT</lastBuildDate>
    <item>
      <title>为什么我无法在 PyCharm 中从 tensorflow 导入 keras？</title>
      <link>https://stackoverflow.com/questions/78698615/why-cant-i-import-keras-from-tensorflow-in-pycharm</link>
      <description><![CDATA[我目前正在 PyCharm 中处理一个项目，但在导入 tensorflow.keras 时遇到了问题。似乎 PyCharm 编辑器无法识别 keras 模块。错误消息表明后缀 keras 未被识别，并且似乎 keras 模块位于 python 文件夹内，而不是直接位于 tensorflow 目录中。tf.version 为 2.12.0。
我已尝试以下步骤来解决问题，但均未奏效：
重新安装 TensorFlow：
pip uninstall tensorflow
pip install tensorflow
已检查 TensorFlow 版本：

已验证环境：
import tensorflow as tf
print(tf.__version__)

确保已激活正确的虚拟环境。
确保 TensorFlow 安装在正确的环境中。
手动检查模块位置：
注意到 keras 位于 python 文件夹中，而不是直接位于 tensorflow 目录中。
我可以在调用 keras 之前使用 python 前缀，但这并不常规，需要我禁用 Eager Execution。有人遇到过类似的问题吗？我该如何修复这个问题，以便正确识别 tensorflow.keras？tensorflow 是否有任何我应该注意的更新？我的问题出在 py-charm 上，jupyter-lab 运行良好。或者我应该安装与 Keras 模块相关的任何其他 tensorflow 软件包。]]></description>
      <guid>https://stackoverflow.com/questions/78698615/why-cant-i-import-keras-from-tensorflow-in-pycharm</guid>
      <pubDate>Tue, 02 Jul 2024 17:59:48 GMT</pubDate>
    </item>
    <item>
      <title>我的感知器和 sklearn 感知器的区别</title>
      <link>https://stackoverflow.com/questions/78698399/difference-in-my-perceptron-and-sklearn-perceptron</link>
      <description><![CDATA[我从头开始编写感知器算法，并将训练后获得的权重与训练 sklearn 感知器模型后获得的权重进行比较。我相信 sklearn 模型将权重和偏差初始化为零向量，我选择学习率 eta0=1 来匹配我的感知器代码。 （注意：我的代码中的偏差是向量 w_b 中的最后一项）
我的代码：
def perceptron(X_train, y_train):
#将权重初始化为 0
w = np.zeros(len(X_train.columns))
b = 0
w_b = np.append(w, b)
while True:
misclassifications = 0 
for X , Y in zip(X_train.values, y_train.values):
X_i = np.append(X, 1)
if Y*(np.dot(X_i,w_b)) &lt;= 0:
w_b = w_b + Y*X_i
misclassifications += 1
if misclassifications == 0:
break
return w_b

w_b = perceptron(X_train, y_train)

结果：[-3. 6.7 -1. ]
sklearn 代码：
perceptron = Perceptron(max_iter=1000, eta0=1,random_state=42) 
perceptron.fit(X_train, y_train)

print(&quot;weights are&quot;,perceptron.coef_)
print(&quot;bias is&quot;,perceptron.intercept_)

结果：weights are [[-4.7 10.1]] bias is [-2.]
我期望权重相同，但事实并非如此。有什么线索可以解释原因吗？]]></description>
      <guid>https://stackoverflow.com/questions/78698399/difference-in-my-perceptron-and-sklearn-perceptron</guid>
      <pubDate>Tue, 02 Jul 2024 17:04:46 GMT</pubDate>
    </item>
    <item>
      <title>在 PyTorch 中使用不同分辨率图像训练 DeepLabV3 的最佳实践</title>
      <link>https://stackoverflow.com/questions/78698316/best-practice-to-train-deeplabv3-with-different-resolution-images-in-pytorch</link>
      <description><![CDATA[我正在尝试在 COCO 2017 数据集 上训练 PyTorch 的 DeepLabV3 进行语义分割，但我不确定如何处理不同分辨率的图像。我知道 DeepLab 的架构可以毫无问题地处理它们，但由于它们的分辨率，我无法将它们分批堆叠。处理此问题的最佳做法是什么？我是否将它们调整为固定大小？我是否随机裁剪固定大小？我知道有很多解决方案可以解决此问题，但我真的不知道在语义分割训练的背景下最佳做法是什么。
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78698316/best-practice-to-train-deeplabv3-with-different-resolution-images-in-pytorch</guid>
      <pubDate>Tue, 02 Jul 2024 16:39:00 GMT</pubDate>
    </item>
    <item>
      <title>使用在自定义数据集上训练的 YOLOV8 best.pt 文件的对象跟踪算法？</title>
      <link>https://stackoverflow.com/questions/78696932/object-tracking-algo-with-yolov8-best-pt-file-which-is-trained-on-custom-dataset</link>
      <description><![CDATA[我已经使用 YOLOV8 在自定义数据集上训练了一个模型。从中获得了 best.pt 文件。我想使用一些跟踪器算法来跟踪该对象。有人可以给我推荐一些算法吗？也请附上一些链接，以便我可以参考。
此外，如何查看此组合模型的性能指标？
除了 DeepSORT，因为我已经尝试过了。]]></description>
      <guid>https://stackoverflow.com/questions/78696932/object-tracking-algo-with-yolov8-best-pt-file-which-is-trained-on-custom-dataset</guid>
      <pubDate>Tue, 02 Jul 2024 12:08:35 GMT</pubDate>
    </item>
    <item>
      <title>X(Twitter) 使用 Python 进行抓取 [关闭]</title>
      <link>https://stackoverflow.com/questions/78696532/xtwitter-scraping-using-python</link>
      <description><![CDATA[我想提取特定推文的信息，如内容、图像和其他媒体等。
例如：“https://twitter.com/username/status/123xxxxxxx”
我想提取存储在 ID 为“123xxxxxxx”的推文中的信息。
如何使用 Python 实现它，因为 tweepy 不再起作用，而 ntscraper 允许检索特定个人资料的推文（据我所知）。
我尝试使用 ntscraper，但没有支持抓取特定推文的属性。]]></description>
      <guid>https://stackoverflow.com/questions/78696532/xtwitter-scraping-using-python</guid>
      <pubDate>Tue, 02 Jul 2024 10:43:53 GMT</pubDate>
    </item>
    <item>
      <title>小行星游戏上的 ML RL 与神经网络</title>
      <link>https://stackoverflow.com/questions/78696449/ml-rl-with-neural-network-on-asteroids-game</link>
      <description><![CDATA[我建立了一个 DQ 网络，它可以分析小行星的状态，并且火箭会给出最佳的执行动作（左转、右转、射击、空闲）。但是代理一直在发射子弹？

有人能帮我解决这个问题吗？
我以为代理会探索所有 4 个动作，但它一直在发射子弹，很难向左或向右移动，几乎停留在中心并不断发射子弹。]]></description>
      <guid>https://stackoverflow.com/questions/78696449/ml-rl-with-neural-network-on-asteroids-game</guid>
      <pubDate>Tue, 02 Jul 2024 10:27:16 GMT</pubDate>
    </item>
    <item>
      <title>将文件添加到 Vertex-AI Bucket</title>
      <link>https://stackoverflow.com/questions/78696253/adding-file-to-vertex-ai-bucket</link>
      <description><![CDATA[我在 Google Cloud Vertex-AI 的工作台中使用笔记本，有时我想创建一个多标签 aiplatform.TextDataset。为此，我首先需要拥有 gcs_source。我尝试使用存储在与笔记本同一目录中的 JSON 行文件，但 aiplatform.TextDataset.create() 一直失败并显示以下错误消息：

TypeError：wrap_method() 获得了意外的关键字参数“default_compression”

我认为这是因为我用于 gcs_source 以创建 TextDataset 的 JSON 行文件不在存储桶中。
这是问题吗？如果是这样，我该如何将 JSON 添加到 Bucket？
更新：
这不是问题，我在 Bucket 中使用以下命令创建了文件：
import json
client = storage.Client()
bucket = client.get_bucket(&#39;&lt;my_bucket&gt;&#39;)
blob = bucket.blob(&#39;&lt;my_file&gt;.jsonl&#39;)
with blob.open(&#39;w&#39;) as f:
for d in data:
json.dump(d, f)
f.write(&#39;\n&#39;)

我检查了一下，文件已在 bucket 中正确创建。但我仍然收到相同的错误]]></description>
      <guid>https://stackoverflow.com/questions/78696253/adding-file-to-vertex-ai-bucket</guid>
      <pubDate>Tue, 02 Jul 2024 09:48:03 GMT</pubDate>
    </item>
    <item>
      <title>cuda 12.1 安装中遇到错误，GPU：2x Nvidia L4 张量</title>
      <link>https://stackoverflow.com/questions/78695698/facing-error-in-cuda-12-1-installation-gpu-2x-nvidia-l4-tensor</link>
      <description><![CDATA[我有一台新的 Debian 11 服务器，我在其中添加了 Nvidia L4 Tensor GPU，但在尝试安装 cuda-12.1.0 时出现以下错误。
错误：
make\[1\]：离开目录‘/usr/src/linux-5.10.27’
完成。
内核模块编译完成。
错误：无法加载内核模块‘nvidia.ko’。这种情况最常发生在以下情况下：此内核模块是针对错误或配置不当的内核源构建的，其 gcc 版本与用于构建目标内核的版本不同，或者存在另一个驱动程序（如 nouveau）并阻止 NVIDIA 内核模块获得 NVIDIA 设备的所有权，或者此 NVIDIA Linux 图形驱动程序版本不支持此系统中安装的任何 NVIDIA 设备。
有关详细信息，请参阅文件“/var/log/nvidia-installer.log”末尾的日志条目“内核模块加载错误”和“内核消息”。
内核模块加载错误：没有这样的设备

NVRM：分配给您的 NVIDIA 设备的 PCI I/O 区域无效：
NVRM：BAR0 为 0M @ 0x0（PCI：0000：01：00.0）
nvidia：0000：01：00.0 的探测失败，错误为 -1
NVRM：1 个设备的 NVIDIA 探测例程失败。
NVRM：所有 NVIDIA 设备均未初始化。
nvidia-nvlink：未注册的 Nvlink Core，主设备号 247
错误：安装失败。有关详细信息，请参阅文件“/var/log/nvidia-installer.log”。您可以在 Linux 驱动程序下载页面 (www.nvidia.com) 上的 README 中找到有关修复安装问题的建议。

我尝试了从 Google 和其他资源中获得的以下方法。
  内核更新 (6.x.x-deb)
  手动安装 Nvidia 驱动程序
  添加 repo (ppa:graphics-drivers/ppa)
  Cuda 安装 (运行文件、本地 repo、网络 repo)
我还尝试手动安装 Nvidia 驱动程序 (530.x.x、535.x.x、555.x.x)，但仍然无法获得兼容的驱动程序。
服务器规格：
  操作系统：Debian 11
  Arch：x86_64
  GPU：​​2x Nvidia L4 Tensor
我有上述服务器配置，想要安装cuda-toolkit 12.1.0 带有合适的 Nvidia 驱动程序。Cuda-toolkit 版本：12.1.0]]></description>
      <guid>https://stackoverflow.com/questions/78695698/facing-error-in-cuda-12-1-installation-gpu-2x-nvidia-l4-tensor</guid>
      <pubDate>Tue, 02 Jul 2024 07:57:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将 .mlpackage Core ML 模型转换为 .mlmodel Core ML 模型？</title>
      <link>https://stackoverflow.com/questions/78695468/how-can-one-convert-a-mlpackage-core-ml-model-to-a-mlmodel-core-ml-model</link>
      <description><![CDATA[如何将 .mlpackage 模型转换为 .mlmodel 模型？

在 Ubuntu 20.04 上使用 Hugging Face 的 Exporters lib 创建的 .mlpackage Core ML 模型示例（使用 Python 3.10 和 torch 2.3.1 测试）：
git clone https://github.com/huggingface/exporters.git
cd exporters
pip install -e .
python -m exporters.coreml --model=distilbert-base-uncasederated/ --quantize=float32 
]]></description>
      <guid>https://stackoverflow.com/questions/78695468/how-can-one-convert-a-mlpackage-core-ml-model-to-a-mlmodel-core-ml-model</guid>
      <pubDate>Tue, 02 Jul 2024 07:03:04 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark 中的 RankingMetrics 未按预期工作</title>
      <link>https://stackoverflow.com/questions/78695397/rankingmetrics-in-pyspark-not-working-as-expected</link>
      <description><![CDATA[嗨，我有一个像这样的 pyspark df。
 (&#39;recs&#39;, &#39;array&lt;string&gt;&#39;),
(&#39;model_pred_score&#39;, &#39;array&lt;double&gt;&#39;),
(&#39;ground_truth_score&#39;, &#39;array&lt;double&gt;&#39;),
(&#39;model_ranked_items&#39;, &#39;array&lt;string&gt;&#39;),
(&#39;actual_ranked_items&#39;, &#39;array&lt;string&gt;&#39;)]

其中 recs 包含向客户推荐的商品列表，大小为 n，它将向客户推荐相关和不相关的商品。
model_pred_score 是模型预测的分数，为 int， ground_truth_score 是基于交互计算的浮点数，如果客户根本没有与项目交互，它也可以有 0。
现在我已经对 recs 进行了排序，这将为我们提供 model_ranked_items 和 actual_ranked_items，它们是根据其分数排名的项目。它们都将具有相等大小的 recs 数组列
现在我想计算这些项目的 NDCG 和 Precision，因此我像这样使用 Python 中的 RankingMetrics 库。
predictions_and_labels_rdd = df_grp.rdd.map(lambda row: (row[&quot;model_ranked_items&quot;], row[&quot;actual_ranked_items&quot;]))
ranking_metrics = RankingMetrics(predictions_and_labels_rdd)

ranking_metrics.ndcgAt(10)
ranking_metrics.precisionAt(10)

我不知道我在这里遗漏了什么，但我总是得到所有指标的 1。我后来还为 ndcg 添加了相关性列，但所有指标的得分仍然为 1。
我是否不应该将不相关的项目添加到 ground_truth_set？]]></description>
      <guid>https://stackoverflow.com/questions/78695397/rankingmetrics-in-pyspark-not-working-as-expected</guid>
      <pubDate>Tue, 02 Jul 2024 06:42:59 GMT</pubDate>
    </item>
    <item>
      <title>精确而强大的角点检测（噪声图像、脏污物体）</title>
      <link>https://stackoverflow.com/questions/78694749/precise-and-robust-corner-detection-noisy-image-dirty-object</link>
      <description><![CDATA[鉴于一定的质量控制要求，我们实施了一个自动化系统来测量钢板生产线的某些尺寸。问题是，有时系统不够强大，系统选择的像素不能反映我们人类推理认为的真实角落。该图像大约为 17 MPixels-
此简化的代码片段应代表我们的测量过程：
defcontrast_stretch(image, multiplier=1.0):
min_val = np.min(image)
max_val = np.max(image)
stretched = (image - min_val) * (255 / (max_val - min_val) * multiplier)
stretched = np.clip(stretched, 0, 255).astype(np.uint8)
returnstretched

def distance(pt1, pt2):
return math.sqrt((pt2[0] - pt1[0]) ** 2 + (pt2[1] - pt1[1]) ** 2)

defmeasure_diagonals(image, contours, px_to_mm):
refined_corners = []
for cnt in轮廓：
rect = cv2.minAreaRect(cnt)
box = cv2.boxPoints(rect)
box = np.int0(box)
corners = cv2.cornerSubPix(image, np.float32(box), (5, 5), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))
refined_corners.append(corners)
如果 len(refined_corners) &gt;= 2:
d1 = distance(refined_corners[0][0], refined_corners[0][2])
d2 = distance(refined_corners[1][0], refined_corners[1][2])
m1 = d1 * px_to_mm
m2 = d2 * px_to_mm
diff = abs(m2 - m1)
返回 m1, m2, diff
返回 None, None, None

# 加载校准数据
calibration_data = load_calibration_data(calibration_data_path)
mtx = calibration_data[&quot;mtx&quot;]
dist = calibration_data[&quot;dist&quot;]

# 加载图像
frame = cv2.imread(img_path)

# 不失真图像
frame_undistorted = cv2.undistort(frame, mtx, dist, None, mtx)

# 转换为灰度
gray = cv2.cvtColor(frame_undistorted, cv2.COLOR_BGR2GRAY)

# 应用双边滤波器
filtered_image = cv2.bilateralFilter(gray, 9, 125, 25)

# 增强对比度
enhanced_image =对比度拉伸（过滤后的图像）

# 检测轮廓
_, edge = cv2.threshold(enhanced_image, 140, 255, cv2.THRESH_BINARY)
contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 测量对角线
px_to_mm = 0.1 # 示例转换因子
m1, m2, diff = measure_diagonals(enhanced_image, contours, px_to_mm)

这是一个正确选择角的示例：
ROI 生成阈值（白点），然后是圆角子像素（黑点）：

这是一个错误选择的角落的例子：
红色部分是我们知道的真正角落

我知道我们应该改善照明。我们正在测量一个大面积（&gt;4 米），要有一个能产生明亮、均匀图像的照明系统极具挑战性，因此我们应用了大量软件校正，例如双边滤波器、增益和对比度增强器。]]></description>
      <guid>https://stackoverflow.com/questions/78694749/precise-and-robust-corner-detection-noisy-image-dirty-object</guid>
      <pubDate>Tue, 02 Jul 2024 01:35:14 GMT</pubDate>
    </item>
    <item>
      <title>HTML 文件输出未生成</title>
      <link>https://stackoverflow.com/questions/78694578/html-file-output-not-generating</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78694578/html-file-output-not-generating</guid>
      <pubDate>Mon, 01 Jul 2024 23:43:32 GMT</pubDate>
    </item>
    <item>
      <title>使用 SAM-LSTM-RESNET</title>
      <link>https://stackoverflow.com/questions/78694533/using-sam-lstm-resnet</link>
      <description><![CDATA[我使用的是 SAM-LSTM-RESNET 包，遇到了这个形状的问题。
包中附带的示例图片也出现了同样的问题，所以它不能正常工作，这很奇怪。有人知道如何在不修改包代码的情况下修复此问题吗？
from sam_lstm import SalMap
import os

if not os.path.exists(&quot;\\samples&quot;):
os.makedirs(&quot;\\samples&quot;)

SalMap.auto()

这是回溯
-------------------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Input In [5], in &lt;cell line: 9&gt;()
6 if not os.path.exists(&quot;\\samples&quot;):
7 os.makedirs(&quot;\\samples&quot;)
----&gt; 9 SalMap.auto()

文件 ~\anaconda3\lib\site-packages\sam_lstm\__init__.py:48，位于 SalMap.auto(cls)
45 @classmethod
46 def auto(cls):
47 salmap = cls()
---&gt; 48 salmap.compile()
49 salmap.load_weights()
50 salmap.predict_maps()

文件 ~\anaconda3\lib\site-packages\sam_lstm\__init__.py:59，位于 SalMap.compile(self)
57 def compile(self):
58 self.model = Model(
---&gt; 59 输入=[self.x, self.x_maps], 输出=sam_resnet([self.x, self.x_maps])
60 )
61 self.model.compile(
62 RMSprop(learning_rate=1e-4),
63 损失=[kl_divergence, correlation_coefficient, nss],
64 损失权重=[10, -2, -1],
65 )

文件~\anaconda3\lib\site-packages\sam_lstm\models.py:192，在 sam_resnet(x) 中
190 def sam_resnet(x):
191 # 扩张卷积网络
--&gt; 192 dcn = dcn_resnet(input_tensor=x[0])
193 conv_feat = Conv2D(512, (3, 3), padding=&quot;same&quot;,activation=&quot;relu&quot;)(dcn.output)
194 # 注意力卷积 LSTM

文件 ~\anaconda3\lib\site-packages\sam_lstm\dcn_resnet.py:259, 在 dcn_resnet(input_tensor) 中
252 # 加载权重
253 weights_path = get_file(
254 &quot;resnet50_weights_th_dim_ordering_th_kernels_notop.h5&quot;,
255 TH_WEIGHTS_PATH_NO_TOP,
256 cache_subdir=&quot;weights&quot;,
257 file_hash=&quot;f64f049c92468c9affcd44b0976cdafe&quot;,
258 )
--&gt; 259 model.load_weights(weights_path)
261 返回模型

文件 ~\anaconda3\lib\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 中引发 e.with_traceback(filtered_tb)
123 finally:
124 delfiltered_tb

文件 ~\anaconda3\lib\site-packages\keras\src\backend\common\variables.py:226，位于 KerasVariable.assign(self, value)
224 value = self._convert_to_tensor(value, dtype=self.dtype)
225 if not shape_equal(value.shape, self.shape):
--&gt; 226 raise ValueError(
227 “目标变量的形状和”
228 ““`variable.assign(value)` 中的目标值的形状必须匹配。”
229 “`variable.assign(value)` 中目标值的形状必须匹配。”
230 f“variable.shape={self.value.shape},”
231 f“收到：value.shape={value.shape}。”
232 f“目标变量：{self}”
233 )
234 if in_stateless_scope():
235 scope = get_stateless_scope()

ValueError: `variable.assign(value)` 中目标变量的形状和目标值的形状必须匹配。variable.shape=(7, 7, 3, 64), 收到：value.shape=(64, 3, 7, 7)。目标变量：&lt;KerasVariable shape=(7, 7, 3, 64), dtype=float32, path=conv1/kernel&gt;

你看这个错误基本上是形状以某种方式被转置了，但我不知道如何修复它？]]></description>
      <guid>https://stackoverflow.com/questions/78694533/using-sam-lstm-resnet</guid>
      <pubDate>Mon, 01 Jul 2024 23:22:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 macOS 10.12 上运行 Core ML 模型？</title>
      <link>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</link>
      <description><![CDATA[https://developer.apple.com/documentation/coreml 提到 macOS 10.13+：

如何在 macOS 10.12 上运行 Core ML 模型？

在 Ubuntu 20.04 上使用 Hugging Face 的 Exporters lib:
git clone https://github.com/huggingface/exporters.git
cd exporters
pip install -e .
python -m exporters.coreml --model=distilbert-base-uncasederated/ --quantize=float32 
]]></description>
      <guid>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</guid>
      <pubDate>Mon, 01 Jul 2024 20:13:24 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 Huggingface 训练器的学习率？</title>
      <link>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</link>
      <description><![CDATA[我正在使用以下参数训练模型：
Seq2SeqTrainingArguments(
output_dir = &quot;./out&quot;, 
overwrite_output_dir = True,
do_train = True,
do_eval = True,

per_device_train_batch_size = 2, 
gradient_accumulation_steps = 4,
per_device_eval_batch_size = 8, 

learning_rate = 1.25e-5,
warmup_steps = 1,

save_total_limit = 1,

evaluation_strategy = &quot;epoch&quot;,
save_strategy = &quot;epoch&quot;,
logs_strategy = &quot;epoch&quot;, 
num_train_epochs = 5, 

gradient_checkpointing = True,
fp16 = True, 

predict_with_generate = True,
generation_max_length = 225,

report_to = [&quot;tensorboard&quot;],
load_best_model_at_end = True,
metric_for_best_model = &quot;wer&quot;,
greater_is_better = False,
push_to_hub = False,
)

我假设 warmup_steps=1 固定了学习率。
但是，训练结束后，我查看文件 trainer_state.json，发现学习率似乎没有固定。
以下是 learning_rate 和 step 的值：
learning_rate，steps
1.0006 e-05 1033
7.5062 e-06 2066
5.0058 e-06 3099
2.5053 e-06 4132
7.2618 e-09 5165

学习率似乎没有固定在 1.25e-5（步骤 1 之后）。我遗漏了什么？如何修复学习率。]]></description>
      <guid>https://stackoverflow.com/questions/77792137/how-to-fix-the-learning-rate-for-huggingface%c2%b4s-trainer</guid>
      <pubDate>Wed, 10 Jan 2024 09:14:26 GMT</pubDate>
    </item>
    </channel>
</rss>