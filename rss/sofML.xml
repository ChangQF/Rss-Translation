<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 09 May 2024 15:15:49 GMT</lastBuildDate>
    <item>
      <title>将分类加权损失函数集成到我的代码中后，准确性下降</title>
      <link>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</link>
      <description><![CDATA[我想提高准确性，并且我有不平衡数据集：akiec：229，bcc：360，bkl：769，df：81，mel：779，vasc：99。为了解决这个问题，我选择将分类加权损失机制集成到模型中。然而，尽管进行了这样的调整，我还是注意到准确性随后下降了。这个意想不到的结果让我怀疑实施过程中出现了错误。您能否帮助我识别和解决任何潜在的错误以优化模型的性能？
# 定义目录
train_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Train&#39;
test_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Test&#39;
validation_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Validation&#39;

# 确定类的数量
numClasses = len(os.listdir(train_dir))

# 定义超参数网格
参数网格 = {
    &#39;学习率&#39;：[0.001]，
    &#39;批量大小&#39;：[16]，
}

最佳准确度 = 0
最佳参数=无

# 执行网格搜索
对于 ParameterGrid(param_grid) 中的参数：
    # 为每次网格搜索迭代加载预训练的 VGG19 模型
    base_model = VGG19(权重=&#39;imagenet&#39;, include_top=False, input_shape=(224, 224, 3))
    对于 base_model.layers 中的图层：
        可训练层 = False

    # 定义函数从最后一个卷积层提取特征
    def extract_features（生成器，模型）：
        特征 = model.predict(生成器)
        返回 features.reshape((len(generator.filenames), -1))

    # 创建数据生成器
    train_datagen = 图像数据生成器(
        重新缩放=1./255，
        旋转范围=20，
        宽度偏移范围=0.2，
        height_shift_range=0.2，
        剪切范围=0.2，
        缩放范围=0.2，
        水平翻转=真，
        fill_mode=&#39;最近&#39;)

    validation_datagen = ImageDataGenerator（重新缩放=1./255）

    train_generator = train_datagen.flow_from_directory(
        火车目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）

    validation_generator =validation_datagen.flow_from_directory(
        验证目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）
&#39;&#39;&#39;

可能这里有一个错误

&#39;&#39;&#39;

    # 定义类索引
    类索引 = {
        &#39;基亚克&#39;: 0,
        “密件抄送”：1，
        &#39;bkl&#39;：2，
        “df”：3，
        “梅尔”：4，
        “血管”：5
    }

    ## 计算班级人数
    类计数 = {}
    对于 os.listdir(train_dir) 中的 class_name：
        class_counts[class_name] = len(os.listdir(os.path.join(train_dir, class_name)))

    # 计算类别权重
    类权重 = {}
    Total_samples = sum(class_counts.values())
    对于 class_name、class_count 在 class_counts.items() 中：
        class_weights[class_indices[class_name]] = 总样本数 / (class_count * len(class_counts))



    # 定义模型架构以接受提取的特征作为输入
    输入=输入(形状=(combined_data_train.shape[1],))
    x = 密集（256，激活=&#39;relu&#39;）（输入）
    预测=密集（numClasses，激活=&#39;softmax&#39;）（x）
    模型=模型（输入=输入，输出=预测）

    # 使用当前的超参数和类权重编译模型
    model.compile（优化器=SGD（learning_rate=params[&#39;learning_rate&#39;]），loss=&#39;sparse_categorical_crossentropy&#39;，metrics=[&#39;accuracy&#39;]，sample_weight_mode=&#39;temporal&#39;）

    # 定义提前停止
    Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

    # 通过提前停止来训练模型
    num_epochs = 50 # 您可以在此处调整纪元数
    历史=模型.fit(
        x=组合数据训练，
        y=train_generator.labels,
        纪元=num_epochs，
        批量大小=参数[&#39;批量大小&#39;],
        validation_data=(combined_data_validation,validation_generator.labels),
        回调=[early_stopping],
        类权重=类权重，
        详细=1
    ）

    model.save(&#39;best_vgg19_model_with_age.h5&#39;)

    # 根据验证数据评估模型
    _，val_accuracy = model.evaluate（combined_data_validation，validation_generator.labels，详细= 0）

    # 如有必要，更新最佳精度和最佳参数
    如果 val_accuracy &gt;最佳准确度：
        最佳准确度 = 验证准确度
        最佳参数 = 参数

# 打印最佳参数和准确度
print(&#39;最佳参数：&#39;, best_params)
print(&#39;最佳验证准确度：&#39;, best_accuracy)


# 加载最佳模型
best_model = load_model(&#39;best_vgg19_model_with_age.h5&#39;)

]]></description>
      <guid>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</guid>
      <pubDate>Thu, 09 May 2024 14:52:54 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么工具来注释机器学习项目的图像，以便我可以向每个边界框添加数据</title>
      <link>https://stackoverflow.com/questions/78455181/what-tool-should-i-use-to-annotate-images-for-a-machine-learning-project-so-that</link>
      <description><![CDATA[我和我的团队有大量水果图像需要注释来训练 YOLO 模型。注释过程需要包括每个水果周围的边界框和重量等附加数据。
根据 YOLO 文档，可以通过直接将补充信息附加到通常包含边界框数据的文件来包含补充信息。我在 GitHub 上发现了一条建议采用这种方法的回复（回复链接），但我还没有找到支持在定义边界框的同时添加额外数据的注释工具（例如 Roboflow 或 CVAT）。
虽然可以在创建边界框后手动将数据添加到文本文件中，但这将是一项艰巨的任务。我正在寻找一种更加自动化的解决方案，我可以在其中对每个图像进行注释，同时方便地添加其他信息。
是否有支持此功能的工具或网站？]]></description>
      <guid>https://stackoverflow.com/questions/78455181/what-tool-should-i-use-to-annotate-images-for-a-machine-learning-project-so-that</guid>
      <pubDate>Thu, 09 May 2024 14:36:09 GMT</pubDate>
    </item>
    <item>
      <title>如何纠正 r 中光栅堆栈的方向</title>
      <link>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</link>
      <description><![CDATA[我有一个每日数据的 NetCDF 文件。我将其转换为光栅堆栈，但其方向不正确（我已附上图像）。我该如何纠正它。我还将我的代码附在本文中。 [raster_stack 图像和 r 代码](https://i.sstatic.net/UmI4kSNE.png)
另外，请告诉是否有人知道，我如何从这些栅格文件中提取年度数据到 Excel 格式（在 arcGIS 或 r 中）。我有 1955 年到 2023 年的栅格文件，其中包含每日降雨量数据，我想根据我拥有的管理形状文件提取年降雨量数据。
我在 r 中运行了代码，但没有取得任何进展。]]></description>
      <guid>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</guid>
      <pubDate>Thu, 09 May 2024 13:18:03 GMT</pubDate>
    </item>
    <item>
      <title>如何为大型语言模型有效构建提示？</title>
      <link>https://stackoverflow.com/questions/78454565/how-to-structure-prompts-effectively-for-large-language-models</link>
      <description><![CDATA[我目前正在使用大型语言模型 (LLM)，并在构建提示以获得最准确和相关的响应方面面临挑战。我对提示工程有基本的了解，但正在寻找有关如何改进提示的最佳实践和建议。
这是我的具体问题：

LLM 的结构良好的提示的关键组成部分是什么？
提示的复杂性或简单性如何影响 LLM 的回答？
设计提示时是否需要避免常见的陷阱或错误？

我对确保模型理解并遵守提示中提供的上下文的技术特别感兴趣。任何可以指导我的示例或资源将不胜感激。
我希望指导法学硕士做什么和不做什么，包括与之相关的流程和链条，正如我所期望的那样
我尝试过的示例提示：
”“”作为您的专属助手，我在这里解答与我们公司产品和服务相关的任何疑问。请注意，我的专业知识仅限于内部主题，我不具备处理外部查询或执行数学计算的能力。”“”
在某些情况下，此提示有效，但在其他情况下则无效。]]></description>
      <guid>https://stackoverflow.com/questions/78454565/how-to-structure-prompts-effectively-for-large-language-models</guid>
      <pubDate>Thu, 09 May 2024 12:52:49 GMT</pubDate>
    </item>
    <item>
      <title>Stylegan3汽车生成问题</title>
      <link>https://stackoverflow.com/questions/78454480/stylegan3-car-generation-issue</link>
      <description><![CDATA[你好堆栈溢出社区，
我正在尝试训练stylegan3来生成汽车图像，特别是某个国家的救护车，我有一个小的数据集，经过长时间的训练过程后的输出不方便，我是否需要更长的训练或更大的数据集？
我试图使我的数据集更加统一，并连续训练我的网络 3 天，输出仍然看起来与原始数据完全相同，但分辨率较低，您对针对此用例的更好网络有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78454480/stylegan3-car-generation-issue</guid>
      <pubDate>Thu, 09 May 2024 12:37:13 GMT</pubDate>
    </item>
    <item>
      <title>我的情绪分析给出了错误的预测</title>
      <link>https://stackoverflow.com/questions/78454399/my-sentiment-analysis-is-giving-wrong-predictions</link>
      <description><![CDATA[我有一个包含两列的数据框：推文和标签（攻击性语言、仇恨言论、无仇恨和攻击性）。
我清理了推文并创建了我的模型。
但建模后，我的所有测试文本都给出了相同的预测结果：“无仇恨和冒犯”
# 清理我的文本
def clean_text(text):
text = str(text).lower()
text = re.sub(&#39;\[.*?\]&#39;, &#39;&#39;, text)
text = re.sub(&#39;https?://\S+|www\.\S+&#39;, &#39;&#39;, text)
text = re.sub(&#39;&lt;.*?&gt;+&#39;, &#39;&#39;, text)
text = re.sub(&#39;[%s]&#39; % re.escape(string.punctuation), &#39;&#39;, text)
text = re.sub(&#39;\n&#39;, &#39;&#39;, text)
text = re.sub(&#39;\w*\d\w*&#39;, &#39;&#39;, text)
text = [word for word in text.split(&#39; &#39;) if word not in stopword]
text = &quot;&quot;.join(text)
text = [stemmer.stem(word) for word in text.split(&#39; &#39;)]
text = &quot;&quot;.join(text)

return text

data[&quot;tweet&quot;] = data[&quot;tweet&quot;].apply(clean_text)

# 将我的列转换为数组
import numpy as np
x = np.array(data[&quot;tweet&quot;])
y = np.array(data[&quot;labels&quot;])

# 拟合 tweet 列以进行建模
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
count_vec = CountVectorizer()
X = count_vec.fit_transform(x)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33，random_state = 42)

来自 sklearn.tree 导入 DecisionTreeClassifier

dc_tree = DecisionTreeClassifier()
dc_tree.fit(X_train, y_train)

##测试我的模型
test_text = &quot;杀死他们所有人并烧毁它&quot;
test_data = count_vec.transform([test_text]).toarray()

print(dc_tree.predict(test_data)) 
#输出：[&#39;没有仇恨和攻击性&#39;] #期望：[&#39;仇恨言论&#39;]

test_text = &quot;实践爱和耐心，过上美好的生活！&quot;
test_data2 = count_vec.transform([test_text]).toarray()
print(dc_tree.predict(test_data2)) 
#输出：[&#39;没有仇恨和攻击性&#39;]

]]></description>
      <guid>https://stackoverflow.com/questions/78454399/my-sentiment-analysis-is-giving-wrong-predictions</guid>
      <pubDate>Thu, 09 May 2024 12:19:20 GMT</pubDate>
    </item>
    <item>
      <title>feature_weights 参数没有影响 Xgboost</title>
      <link>https://stackoverflow.com/questions/78454026/the-feature-weights-parameter-has-no-effect-xgboost</link>
      <description><![CDATA[xgboost 有一个 parameter feature_weights 应该影响模型选择特征的概率，也就是说，我们可以给每个特征更多或更少的权重，但似乎该参数不起作用还是我做错了什么？
X &lt;- as.matrix(iris[,-5])
Y &lt;- ifelse(iris$Species==&quot;setosa&quot;, 1, 0)

库（xgboost）
dm1 &lt;- xgb.DMatrix(X, 标签 = Y)
#我为每个特征设置不同的概率
dm2 &lt;- xgb.DMatrix(X, 标签 = Y, feature_weights = c(1, 0, 0, 0.01))
params &lt;- list(objective = “binary:logistic”, eval_metric = “logloss”)

设置.种子(1)



xgb1 &lt;- xgboost（数据 = dm1，参数 = 参数，nrounds = 10，print_every_n = 5）

[1] 火车对数损失：0.448305
[6] 火车对数损失：0.090220
[10]训练对数损失：0.033148



xgb2 &lt;- xgboost（数据 = dm2，参数 = 参数，nrounds = 10，print_every_n = 5）

[1] 火车对数损失：0.448305
[6] 火车对数损失：0.090220
[10]训练对数损失：0.033148

但是模型的行为完全相同，似乎参数feature_weights被简单地忽略了]]></description>
      <guid>https://stackoverflow.com/questions/78454026/the-feature-weights-parameter-has-no-effect-xgboost</guid>
      <pubDate>Thu, 09 May 2024 11:10:59 GMT</pubDate>
    </item>
    <item>
      <title>输入列的架构不匹配预期的字符串或字符串向量，得到 UInt32（参数“inputSchema”）</title>
      <link>https://stackoverflow.com/questions/78453914/schema-mismatch-for-input-column-expected-string-or-vector-of-string-got-uint32</link>
      <description><![CDATA[未处理的异常。System.ArgumentOutOfRangeException：输入列“QuestionKey”的架构不匹配：预期为字符串或字符串向量，获取 UInt32（参数“inputSchema”）
代码：
// 尝试不同的文本特征化技术
var tokenizedText = mlContext.Transforms.Text.TokenizeIntoWords(&quot;Tokens&quot;, &quot;Question&quot;);
var wordEmbeddings = mlContext.Transforms.Text.ApplyWordEmbedding(&quot;Features&quot;, &quot;Tokens&quot;, WordEmbeddingEstimator.PretrainedModelKind.SentimentSpecificWordEmbedding);
 var concatenatedFeatures = mlContext.Transforms.Concatenate(&quot;FeaturesConcatenated&quot;, &quot;Features&quot;);

// 将“问题”列转换为 KeyType
var modelPipeline = mlContext.Transforms.Conversion.MapValueToKey(&quot;QuestionKey&quot;, &quot;Question&quot;)
.Append(mlContext.Transforms.Text.TokenizeIntoWords(&quot;Tokens&quot;, &quot;QuestionKey&quot;))
.Append(mlContext.Transforms.Text.ApplyWordEmbedding(&quot;Features&quot;, &quot;Tokens&quot;, WordEmbeddingEstimator.PretrainedModelKind.SentimentSpecificWordEmbedding))
.Append(mlContext.Transforms.Categorical.OneHotEncoding(&quot;QuestionEncoded&quot;, &quot;QuestionKey&quot;))
.Append(mlContext.Transforms.Conversion.MapValueToKey(&quot;Label&quot;, &quot;Answer&quot;))
.Append(mlContext.Transforms.Concatenate(&quot;FeaturesConcatenated&quot;, &quot;Features&quot;));

// 使用 AutoML 或手动调整进行超参数调整实验
var trainer = mlContext.MulticlassClassification.Trainers.LightGbm(labelColumnName: &quot;Answer&quot;, featureColumnName: &quot;Question&quot;);

var trainingPipeline = modelPipeline.Append(trainer);

// 训练模型
var trainingModel = trainingPipeline.Fit(dataView);

// 将训练好的模型保存到文件
mlContext.Model.Save(trainedModel, dataView.Schema, modelPath);

return trainingModel;
}

我正在使用包含两列问题和答案的数据集构建一个常见问题聊天机器人。该数据集包含大约 30000 个问答。我在这里尝试了不同的技术，但一直卡在这里。请帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78453914/schema-mismatch-for-input-column-expected-string-or-vector-of-string-got-uint32</guid>
      <pubDate>Thu, 09 May 2024 10:49:39 GMT</pubDate>
    </item>
    <item>
      <title>如何配置作业yaml和Yolov8数据集ymal来访问Azure上的数据资产？</title>
      <link>https://stackoverflow.com/questions/78453842/how-to-configure-job-yaml-and-yolov8-dataset-ymal-to-access-data-asset-on-azure</link>
      <description><![CDATA[我目前正在使用 Azure ML CLI v2 在 Azure ML 工作室中使用 Yolov8 训练自定义模型。
问题：
当我在 Azure ML 上运行作业时，收到一条错误消息“权限被拒绝”
错误代码：ScriptExecution.StreamAccess.Authentication
本机错误：来自输入数据源的流式传输错误
    StreamError(PermissionDenied(Some(此请求无权使用此权限执行此操作。)))
=&gt;访问流时权限被拒绝。原因：一些（该请求无权使用该权限执行该操作。）
    PermissionDenied(Some(此请求无权使用此权限执行此操作。))
错误消息：尝试访问流时身份验证失败。确保您设置了正确的权限。好的（该请求无权使用该权限执行该操作。）| session_id=da7b713c-6cc8-4f6d-b24f-b54ab37e14ef

Yaml 文件：

job.yaml：

$schema：https://azuremlschemas.azureedge.net/latest/commandJob.schema.json
实验名称：yolov8-实验

命令： |
  sed -i“s|路径：.*$|路径：${{inputs.training_data}}|”自定义数据集.yaml
  # 训练模型
  yolo 任务=检测训练数据=custom_dataset.yaml 模型=${{inputs.model_to_train }} epochs=10 项目=yolov8-实验名称=实验

输入：
  训练数据：
    类型：uri_文件夹
    模式：ro_mount
    path: azure:data_asset:1 #我已经从本地文件创建了数据资产。
  模型到训练：
    类型：自定义模型
    路径：azureml:yolov8l:1

code: /training-code/ #custom_dataset.yaml 存储在本地的路径
环境：azureml：yolov8-环境：1
计算：azureml：compute_cluster


custom_dataset.yaml 文件：

路径：../数据集
火车：/图像/火车/
测试：/图像/测试/
值：/图像/测试/

NC=2

# 类名
名称：[class1，class2]

我参考了以下文章：
中-文章-yolov8-training-azure-cli
在 Azure ML 上训练模型使用 CLI v2 - Microsoft 培训
我目前在确定继续进行 Azure 设置所需的权限时遇到问题。我已使用“az login”成功登录，并成功创建了各种组件，例如环境、计算集群和数据资产。
但是，我不确定进一步操作所需的具体权限。有人可以提供有关我的设置需要授予哪些权限才能正常运行的指导吗？任何见解或建议将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78453842/how-to-configure-job-yaml-and-yolov8-dataset-ymal-to-access-data-asset-on-azure</guid>
      <pubDate>Thu, 09 May 2024 10:35:51 GMT</pubDate>
    </item>
    <item>
      <title>房地产数据集中的多标签回归问题面临的挑战</title>
      <link>https://stackoverflow.com/questions/78453678/challenges-with-a-multi-label-regression-problem-in-a-real-estate-dataset</link>
      <description><![CDATA[我目前正在进行一项研究，旨在预测纽约房产的销售价格和交易执行时间。为此，我拥有一个纽约出售的各种房产的数据集，其中包含有关房产特征的几个特征。
我试图实现的是一个多输出回归问题。我和教授讨论了这个问题，在最后的协议中，他让我解释为什么预测交易执行时间可能会有问题。
这是我的想法，我想知道这对您是否有意义，或者是否还有其他我没有考虑到的问题：
在我看来，主要问题是评估结果的准确性。问题在于交易执行时间可能受到数据集中不存在的无数无法量化的外部因素的影响。例如，房地产经纪人的熟练程度、他们在房地产行业的人脉、他们出售房产的决心、天气状况、买家的经验等等。
因此，交易执行时间的多个值可能表现出相同的特征模式。因此，我们正在处理一个多标签回归问题。因此，创建尽可能准确地预测交易执行时间的模型可能会隐藏一些困难。
我还应该考虑其他数学或 ML 优化因素吗？]]></description>
      <guid>https://stackoverflow.com/questions/78453678/challenges-with-a-multi-label-regression-problem-in-a-real-estate-dataset</guid>
      <pubDate>Thu, 09 May 2024 10:06:01 GMT</pubDate>
    </item>
    <item>
      <title>确定适当的统计检验来比较生存分析中 ML/DL 模型之间的性能差异</title>
      <link>https://stackoverflow.com/questions/78453674/determining-the-appropriate-statistical-test-for-comparing-performance-differenc</link>
      <description><![CDATA[我进行了一项实验，在生存分析任务中训练和测试了 8 个 ML 和 DL 模型，每个模型都经过超参数优化。调优后，每个模型在训练数据上训练一次，在测试数据上测试一次，得到代表模型性能的 8 个 c 指数分数。
现在，我想确定这些模型之间的性能是否存在显着差异。由于我有多个模型并且每个模型有一组测试结果，我应该使用什么统计假设检验来评估性能差异的显着性？我应该考虑 Kruskal-Wallis 检验、方差分析或其他检验吗？此外，我如何解释从所选测试中获得的结果？任何见解或指导将不胜感激。
]]></description>
      <guid>https://stackoverflow.com/questions/78453674/determining-the-appropriate-statistical-test-for-comparing-performance-differenc</guid>
      <pubDate>Thu, 09 May 2024 10:05:23 GMT</pubDate>
    </item>
    <item>
      <title>Yolo 模型中的增量分类器和表示学习</title>
      <link>https://stackoverflow.com/questions/78448470/incremental-classifier-and-representation-learning-in-yolo-models</link>
      <description><![CDATA[我的 YOLO 模型遇到问题。
最初，我用 7 个类对其进行了训练。现在，我想向模型添加 4 个新类。然而，当我将原始 7 个类别的数据与新的 4 个类别的数据结合起来时，训练时间和相关的云成本显着增加。有什么好的解决方案可以有效地将这些额外的类合并到模型中而不增加训练时间和成本？
我的期望是减少增量学习的成本和培训时间。]]></description>
      <guid>https://stackoverflow.com/questions/78448470/incremental-classifier-and-representation-learning-in-yolo-models</guid>
      <pubDate>Wed, 08 May 2024 12:20:14 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError: 默认进程组尚未初始化，请确保调用 init_process_group</title>
      <link>https://stackoverflow.com/questions/78376085/runtimeerror-default-process-group-has-not-been-initialized-please-make-sure-t</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78376085/runtimeerror-default-process-group-has-not-been-initialized-please-make-sure-t</guid>
      <pubDate>Wed, 24 Apr 2024 05:05:11 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中添加L1标准化？</title>
      <link>https://stackoverflow.com/questions/48782758/how-to-add-l1-normalization-in-python</link>
      <description><![CDATA[我正在尝试从头开始编写逻辑回归代码。在这段代码中，我认为我的成本导数是我的正则化，但我的任务是添加 L1norm 正则化。你如何在Python中添加这个？是否应该在我定义成本导数的地方添加此内容？感谢任何正确方向的帮助。
def Sigmoid(z):
    返回 1/(1 + np.exp(-z))

def 假设(theta, X):
    返回 Sigmoid(X @ theta)

def Cost_Function(X,Y,theta,m):
    hi = 假设(theta, X)
    _y = Y.reshape(-1, 1)
    J = 1/float(m) * np.sum(-_y * np.log(hi) - (1-_y) * np.log(1-hi))
    返回J

def Cost_Function_Derivative(X,Y,theta,m,alpha):
    hi = 假设(theta,X)
    _y = Y.reshape(-1, 1)
    J = alpha/float(m) * X.T @ (hi - _y)
    返回J

def Gradient_Descent(X,Y,θ,m,alpha):
    new_theta = theta - Cost_Function_Derivative(X,Y,theta,m,alpha)
    返回 new_theta

定义精度(theta):
    正确 = 0
    长度 = len(X_test)
    预测=（假设（theta，X_test）&gt; 0.5）
    _y = Y_test.reshape(-1, 1)
    正确=预测==_y
    my_accuracy = (np.sum(正确) / 长度)*100
    print (&#39;LR 精度:&#39;, my_accuracy, &quot;%&quot;)

def Logistic_Regression(X,Y,alpha,theta,num_iters):
    m = 长度（Y）
    对于范围内的 x（num_iters）：
        new_theta = Gradient_Descent(X,Y,theta,m,alpha)
        θ = 新_θ
        如果 x % 100 == 0：
            打印 #(&#39;θ: &#39;, θ)
            print #(&#39;成本：&#39;, Cost_Function(X,Y,theta,m))
    精度(θ)
ep = .012
初始_theta = np.random.rand(X_train.shape[1],1) * 2 * ep - ep
阿尔法 = 0.5
迭代次数 = 10000
Logistic_Regression(X_train,Y_train,alpha,initial_theta,迭代)
]]></description>
      <guid>https://stackoverflow.com/questions/48782758/how-to-add-l1-normalization-in-python</guid>
      <pubDate>Wed, 14 Feb 2018 08:34:48 GMT</pubDate>
    </item>
    <item>
      <title>NLTK 与距离度量的一致性</title>
      <link>https://stackoverflow.com/questions/32733510/nltk-agreement-with-distance-metric</link>
      <description><![CDATA[我的任务是计算 注释者间协议 “https://en.wikipedia.org/wiki/Multi-label_classification” rel=&quot;nofollow noreferrer&quot;&gt;多标签分类，其中每个示例可以分配多个标签。我发现 NLTK 可以根据距离度量来衡量一致性。
我正在寻找使用 MASI 距离计算 krippendorff alpha 的示例。
这就是我所拥有的。
&lt;前&gt;&lt;代码&gt;导入nltk
从 nltk.metrics 导入 masi_distance


玩具数据 = [[&#39;1&#39;, 5723, [1,2]],[&#39;2&#39;, 5723, [2,3]]]

任务= nltk.metrics.agreement.AnnotationTask（数据= toy_data，距离= masi_distance）
打印任务.alpha()

此代码失败并显示
类型错误：不可散列的类型：“列表”

以下方法也不起作用：
toy_data = [[&#39;1&#39;, 5723, set([1,2])],[&#39;2&#39;, 5723, set([2,3])]]

你有一个可行的例子吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/32733510/nltk-agreement-with-distance-metric</guid>
      <pubDate>Wed, 23 Sep 2015 07:28:09 GMT</pubDate>
    </item>
    </channel>
</rss>