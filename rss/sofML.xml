<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 09 Apr 2024 18:15:51 GMT</lastBuildDate>
    <item>
      <title>“应用 Lasserre 的 SOS 松弛从 2D 地标进行 3D 形状重建：有效策略和实施指南”</title>
      <link>https://stackoverflow.com/questions/78299711/applying-lasserres-sos-relaxations-for-3d-shape-reconstruction-from-2d-landmar</link>
      <description><![CDATA[要使用 Lasserre 的凸平方和 (SOS) 松弛层次结构从单个图像中的 2D 地标进行 3D 形状重建，您必须首先理解问题和基本的数学思想。
目标是使用源自 2D 图像的 2D 地标、点或特征来重建对象的 3D 形状。由于将 2D 点映射到 3D 空间的固有模糊性以及地标数据中存在噪声或异常值，这是一项艰巨的任务。
Lasserre 的 SOS 松弛层次结构通过将其转换为多项式优化分配，提供了解决该问题的系统方法。主要思想是将未知的3D形状表示为多项式函数，然后应用SOS松弛来近似该函数的全局最小值，对应于最佳3D形状重建。
要使用 Lasserre 层次结构，您通常创建一个多项式目标函数来表示观察到的 2D 地标和投影的 3D 地标之间的差异。然后最小化该目标函数，同时遵守确保重建的 3D 形状有效的约束（例如，非负深度值）。
SOS 松弛需要创建一系列接近原始多项式优化问题的半定程序 (SDP)。层次结构的每个步骤都对 SDP 增加了限制，从而可以更准确地估计全局最小值。
使用 SOS 松弛的一个关键部分是选择基函数或单项式来描述多项式。通过仔细挑选一小部分代表多项式重要特征的基函数，您可以极大地降低 SDP 的计算成本。
使用 Lasserre 的凸平方和 (SOS) 松弛层次结构从单个图像中的 2D 地标重建 3D 形状。然而，根据文献和理论理解，人们通常会将问题表述为一项多项式优化任务，创建目标函数以最小化观察到的 2D 地标和投影的 3D 地标之间的差异，然后使用 SOS 松弛来近似全局最小值功能。希望通过应用 SOS 松弛，可以有效地处理问题的非凸方面，从而更准确地重建 3D 几何形状。]]></description>
      <guid>https://stackoverflow.com/questions/78299711/applying-lasserres-sos-relaxations-for-3d-shape-reconstruction-from-2d-landmar</guid>
      <pubDate>Tue, 09 Apr 2024 15:52:29 GMT</pubDate>
    </item>
    <item>
      <title>计算Python中两个sumamries之间的BLEU分数</title>
      <link>https://stackoverflow.com/questions/78299375/calculating-bleu-score-between-two-sumamries-in-python</link>
      <description><![CDATA[预测=“我是ABC。我已经在 XYZ 大学完成了计算机应用学士学位，目前正在通过远程教育攻读计算机应用硕士学位。”


引用=“我是ABC。我已经在 XYZ 完成了为期四年的 PC 应用认证，目前正在通过远程培训攻读 PC 应用研究生学位。”

从 nltk.translate.bleu_score 导入句子_bleu

# 对句子进行标记
Prediction_tokens = Prediction.split()
Reference_tokens = Reference.split()

# 计算 BLEU 分数
bleu_score = Sentence_bleu([参考标记], 预测标记)

# 打印 BLEU 分数
print(f&quot;BLEU 分数: {bleu_score:.4f}&quot;)

我得到的 BLEU 分数为 0。我认为我在某个地方犯了错误。但不确定在哪里。]]></description>
      <guid>https://stackoverflow.com/questions/78299375/calculating-bleu-score-between-two-sumamries-in-python</guid>
      <pubDate>Tue, 09 Apr 2024 14:58:15 GMT</pubDate>
    </item>
    <item>
      <title>静态嵌入与情境化嵌入</title>
      <link>https://stackoverflow.com/questions/78299260/static-vs-contextualized-embeddings</link>
      <description><![CDATA[使用类似于具有一个隐藏层的自动编码器的网络架构的嵌入方法是什么？哪一个？输入是什么？输出是什么？模型中的嵌入向量由哪些部分构成？
我不确定答案是否是 Word2Vec。]]></description>
      <guid>https://stackoverflow.com/questions/78299260/static-vs-contextualized-embeddings</guid>
      <pubDate>Tue, 09 Apr 2024 14:41:00 GMT</pubDate>
    </item>
    <item>
      <title>计算 AI 生成的摘要和人工生成的摘要之间的 BLEU 分数</title>
      <link>https://stackoverflow.com/questions/78299237/calculate-bleu-score-between-ai-generated-summary-and-its-human-derived-summary</link>
      <description><![CDATA[我正在尝试计算人工智能生成的语料库和手动编写的摘要之间的 BLEU、ROGUE 分数。
预测 = &quot;
我是ABC。我已经在 XYZ 大学完成了计算机应用学士学位，目前正在通过远程教育攻读计算机应用硕士学位。
在我的学术历程中，我在 C、C++ 和 Python 等编程语言、SQL 数据库和 uipath 中的 RPA 方面打下了基础，并且我还擅长沟通、解决问题的技能、时间管理等软技能、领导素质 团队合作、协调。我热衷于将我的理论知识转化为现实世界的应用。 ”
手动参考=”
我是ABC。我已经在 XYZ 完成了为期四年的 PC 应用认证，现在正在通过远程培训寻求 PC 应用研究生学位。
通过我的学术旅行，我在 C、C++ 和 Python 等编程语言、SQL 中的数据集和 uipath 中的 RPA 方面建立了自己的基础，而且我还擅长通信、批判性思维能力等微妙能力，有效利用时间，权威质量合作和协调。我热衷于将我的假设信息解释为真正的应用。”
我想通过计算它们的 BLEU 分数和 ROGUE 分数来比较这两个摘要。这是我第一次使用这些指标。所以我不确定是否使用句子_BLEU()或语料库_BLUE或将它们分成标记等。所以如果有人可以帮助我使用Python代码来计算这两个指标？]]></description>
      <guid>https://stackoverflow.com/questions/78299237/calculate-bleu-score-between-ai-generated-summary-and-its-human-derived-summary</guid>
      <pubDate>Tue, 09 Apr 2024 14:36:08 GMT</pubDate>
    </item>
    <item>
      <title>用于回归的非线性数据的离群值检测</title>
      <link>https://stackoverflow.com/questions/78299049/outlier-detection-for-non-linear-data-for-regression</link>
      <description><![CDATA[我正在努力解决两个具有 82% 相关性的参数，这两个参数呈现出非线性关系和连续波动。尽管尝试在 scikit-learn 中使用 LocalOutlierFactor、DBSCAN、IsolationForest 和 PolynomialFeature，但异常值去除仍然具有挑战性。参数1的范围是0.01到0.077，参数2的范围是3到12。
寻求有关有效异常值去除方法的建议，以提高相关性并更好地准备用于训练随机森林回归模型的数据。任何见解或经验将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78299049/outlier-detection-for-non-linear-data-for-regression</guid>
      <pubDate>Tue, 09 Apr 2024 14:08:34 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“deepface.commons”导入名称“距离”（/opt/anaconda3/envs/LIP/lib/python3.9/site-packages/deepface/commons/__init__.py）</title>
      <link>https://stackoverflow.com/questions/78298624/importerror-cannot-import-name-distance-from-deepface-commons-opt-anacond</link>
      <description><![CDATA[无法在Python中导入deepface
我目前在 macbook 上使用 Pycharm。
虚拟环境已激活，但仍出现以下错误。
有人可以帮我吗？
Python 3.9
Deepface 0.0.89（最新）
张量流版本2.14.1
虚拟环境已激活。
一切都已安装，但仍无法解决导入错误。]]></description>
      <guid>https://stackoverflow.com/questions/78298624/importerror-cannot-import-name-distance-from-deepface-commons-opt-anacond</guid>
      <pubDate>Tue, 09 Apr 2024 12:57:54 GMT</pubDate>
    </item>
    <item>
      <title>努力开发使用带有 ARFRegressor 算法的 River 库的在线学习代码</title>
      <link>https://stackoverflow.com/questions/78298486/struggling-with-developing-code-for-an-online-learning-using-river-library-with</link>
      <description><![CDATA[我已经分割了数据，但正在努力编写用于训练模型的代码，并使用 pickle 将模型保存在特定目录中以供将来使用。关于如何继续的任何建议？
# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

从河流进口评估
从河流进口森林
来自河流的进口指标
来自河流的进口预处理

型号=（
    预处理.StandardScaler() |
    森林.ARFRegressor(种子=42)
）
指标 = 指标.MAE()

# 在测试集上评估模型
mae = evaluate.progressive_val_score(X_test, y_test, 模型, 指标)
print(f&#39;测试集上的 MAE: {mae}&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78298486/struggling-with-developing-code-for-an-online-learning-using-river-library-with</guid>
      <pubDate>Tue, 09 Apr 2024 12:35:37 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种算法来检测汽车多媒体启动时侧边栏的出现？</title>
      <link>https://stackoverflow.com/questions/78297772/which-algorithm-to-use-to-detect-the-appearance-of-sidebar-on-car-multimedia-boo</link>
      <description><![CDATA[我需要创建一个系统来检测从启动汽车多媒体系统到侧边栏首次出现在屏幕上之间所经过的时间。侧边栏具有矩形形状，并且始终位于屏幕的边缘之一。根据汽车制造商的不同，多媒体的外观也有所不同。我想知道如果我不关心执行速度或实时工作，哪种图像检测算法最合适。
SSD、Faster R-CNN、YOLO 还是其他？]]></description>
      <guid>https://stackoverflow.com/questions/78297772/which-algorithm-to-use-to-detect-the-appearance-of-sidebar-on-car-multimedia-boo</guid>
      <pubDate>Tue, 09 Apr 2024 10:25:32 GMT</pubDate>
    </item>
    <item>
      <title>识别和清理数据集中有问题的三元组[关闭]</title>
      <link>https://stackoverflow.com/questions/78297420/identifying-and-cleaning-problematic-triplets-in-a-dataset</link>
      <description><![CDATA[我有三元组（嵌入、嵌入、相关标志）我有大约 5k 个这样的三元组。
有一些三元组（一些少量）实际上并不相关，但在我的数据中显示为相关。
嵌入维度为512。
什么是不相关我认为没有问题。
有什么想法可以找到那些被怀疑是错误的有问题的三元组，可以手动检查和清理。
我尝试构建分类器，但它们的性能不太好。]]></description>
      <guid>https://stackoverflow.com/questions/78297420/identifying-and-cleaning-problematic-triplets-in-a-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 09:23:02 GMT</pubDate>
    </item>
    <item>
      <title>如何计算二元分类概率[关闭]</title>
      <link>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</link>
      <description><![CDATA[我正在研究一些基于数值特征的二元分类问题，例如预测维护、信用卡欺诈、心脏病等。我通常喜欢使用随机森林，因为它用途广泛、稳健且可以获得高指标。
除了预测1或0之外，我还想预测获得1的概率（在0.00到1.00之间浮动）。如何在代码中实现这一点？
我使用了随机森林分类器的predict_proba()方法。然而，它主要产生极值（0.00 - 0.10 和 0.90 - 1.00）。 也许它没有很好地校准？另外，我使用了SVM分类器的decision_function()方法，但SVM似乎不是很通用。因此我正在寻找一种不同的方法。
我更喜欢与 RF 分类器相关的方法，但我对其他方法持开放态度。
这是我的代码的相关部分：
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

校准器 = CaliberatedClassifierCV(rf, cv=&#39;prefit&#39;)
模型 = calibrator.fit(X_train, y_train)

概率 = model.predict_proba(X_test)

y_pred = model.predict(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</guid>
      <pubDate>Tue, 09 Apr 2024 07:56:47 GMT</pubDate>
    </item>
    <item>
      <title>YOLOV8 预测相反的类别 [关闭]</title>
      <link>https://stackoverflow.com/questions/78292691/yolov8-predicting-opposite-classes</link>
      <description><![CDATA[我正在尝试使用 Yolov8n.pt 检测对象。我已经使用 RoboFlow 分配了课程。该模型预测的类别非常相反。为什么？如果有请给出解决方案。谢谢。
我无法上传参考图片，因此我添加了该图片的链接。请在下面找到它：]]></description>
      <guid>https://stackoverflow.com/questions/78292691/yolov8-predicting-opposite-classes</guid>
      <pubDate>Mon, 08 Apr 2024 12:57:12 GMT</pubDate>
    </item>
    <item>
      <title>每批次和历元的验证和训练损失</title>
      <link>https://stackoverflow.com/questions/65638101/validation-and-training-loss-per-batch-and-epoch</link>
      <description><![CDATA[我正在使用 Pytorch 运行一些深度学习模型。我目前正在跟踪每个时期的训练和验证损失，这是相当标准的。但是，跟踪每批/迭代的训练和验证损失的最佳方法是什么？
对于训练损失，我可以在每次训练循环后保留一个损失列表。但是，验证损失是在整个 epoch 之后计算的，所以我不确定如何计算每批的验证损失。我唯一能想到的就是在每个训练批次之后运行整个验证步骤并跟踪这些步骤，但这似乎有点矫枉过正并且需要大量计算。
比如训练是这样的：
for epoch in range(2): # 多次循环数据集
running_loss = 0.0
对于 i，enumerate(trainloader, 0) 中的数据：
    # 获取输入；数据是[输入，标签]的列表
    输入，标签=数据

    # 将参数梯度归零
    优化器.zero_grad()

    # 前向+后向+优化
    输出 = 净值（输入）
    损失=标准（输出，标签）
    loss.backward()
    优化器.step()

    # 打印统计数据
    running_loss += loss.item()

对于验证损失：
与 torch.no_grad():
    对于测试加载器中的数据：
        图像、标签=数据
        输出=净（图像）
        _, 预测 = torch.max(outputs.data, 1)
        总计 += labels.size(0)
        正确+=（预测==标签）.sum().item()
        # 验证损失
        batch_loss = error(outputs.float(), labels.long()).item()
        loss_test +=batch_loss
    loss_test /= len(testloader)

验证损失/测试部分是在每个时期完成的。我正在寻找一种方法来获取每批次的验证损失，这就是我上面的观点。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/65638101/validation-and-training-loss-per-batch-and-epoch</guid>
      <pubDate>Sat, 09 Jan 2021 00:25:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用gensim使用deepset的词嵌入预训练模型？</title>
      <link>https://stackoverflow.com/questions/65121932/how-to-use-deepsets-word-embedding-pre-trained-models-using-gensim</link>
      <description><![CDATA[我试图理解 word2vec，并决定尝试使用德语 word2vec 模型。然后我找到了deepset的页面关于他们的预训练模型，但我不明白如何使用（加载）word2vec 模型。我期待一个文件，但有 &quot;矢量&quot;和“词汇 ”文本文件。如何使用这些文件通过 gensim（或任何其他工具）加载预训练模型？
更新：
我尝试了 @gojomo 的回答，但收到了此错误：
回溯（最近一次调用最后一次）：
  文件“/home/bugra/word2vec_imp/pretrained_models/testtt.py”，第 11 行，在  中。
    二进制=假）
  文件“/home/bugra/word2vec_imp/project_envv/lib/python3.7/site-packages/gensim/models/keyedvectors.py”，第 1549 行，采用 load_word2vec_format
    限制=限制，数据类型=数据类型）
  文件“/home/bugra/word2vec_imp/project_envv/lib/python3.7/site-packages/gensim/models/utils_any2vec.py”，第 277 行，采用 _load_word2vec_format
    vocab_size, vector_size = (int(x) for x in header.split()) # 因文件格式无效而抛出异常
  文件“/home/bugra/word2vec_imp/project_envv/lib/python3.7/site-packages/gensim/models/utils_any2vec.py”，第 277 行，位于  中。
    vocab_size, vector_size = (int(x) for x in header.split()) # 因文件格式无效而抛出异常
ValueError：基数为 10 的 int() 的文字无效：“b&#39;UNK””

因此，在 Traceack 中，vocab_size, vector_size = (int(x) for x in header.split()) header 是 Vector 的第一行来自 gensim 页面的文本。它看起来像这样：
&lt;预&gt;&lt;代码&gt;b&#39;UNK&#39; -0.07903 0.01641 0.006979 -0.035038 0.006474 0.002469 -0.050103 0.142654 -0.03505 0.003106 -0.021312 0.094076 -0.01825 5 -0.098097 0.087143 0.105799 0.008606 -0.001315 0.069005 0.062015 0.019944 -0.007749 -0.007412 0.050015 -0.083615 0.007712 0.0331 61 0.017965 - 0.06154 -0.017696 0.061967 0.053028 0.038143 -0.07057 0.01561 0.019588 -0.041708 0.034371 -0.066838 -0.059769 0.075711 -0.114826 0.014009 0.050187 -0.01899 -0.076014 -0.052502 0.086082 0.049812 0.008456 -0.01283 0.039918 -0.001924 -0.003752 0.031073 0.034325 0 .040086 0.078946 -0.012194 0.056323 0.126129 -0.024503 0.026304 - 0.074797 -0.098972 0.003672 0.051386 -0.017574 -0.050253 -0.07677 0.004362 -0.069935 -0.048108 0.020127 0.007066 -0.024247 0.04191 1 0.03377 -0.011906 -0.0168 -0.00355 -0.003168 0.05164 -0.055769 0.01488 -6e-06 0.094575 -0.066246 -0.111004 -0.031954 0.006958 0.0052 59 0.15825 0.102919 0.010383 -0.064236 -0.037729 -0.031751 -0.069492 -0.004198 -0.034654 -0.060518 -0.046611 -0.048463 -0.010096 -0.057894 -0.046687 0.062827 0.0169 07 0.096869 -0.036037 -0.106403 0.056466 0.095621 -0.046383 0.090213 -0.019204 -0.116271 -0.00824 -0.017732 0.037387 -0.021405 -0.0404 93 - 0.059114 0.12289 0.032563 0.103712 0.072411 -0.106944 -0.110485 -0.027564 0.023977 -0.048099 0.036966 -0.11356 -0.009166 0.074402 0.128162 0.080086 0.112749 0.050494 0.064998 0.089217 0.029182 -0.07277 0.058653 0.061047 -0.05293 -0.01979 0.107459 0.002719 -0 .008774 -0.098009 0.009321 0.099869 0.024181 -0.071247 -0.054372 0.019997 0.024442 0.108639 0.053727 -0.089804 0.118491 -0.044407 -0.045336 0.078483 0.059462 -0.012287 0.028941 0.064551 0.066738 0.029614 0.0927 68 0.021783 -0.018141 -0.032692 0.000178 0.021413 0.044657 -0.041903 0.027439 -0.029112 -0.027419 -0.091497 0.00712 -0.076297 -0.0976 02 -0.098875 -0.067403 -0.015912 0.055845 0.057585 -0.061145 -0.006828 0.044573 0.049632 0.014541 -0.024579 -0.045455 0.095474 -0.02978 -0.060053 -0.005672 -0.002711 0.059481 -0.060563 0.04756 2 -0.086001 0.064536 0.196527 -0.105742 -0.019043 0.038534 -0.099681 0.031009 -0.020548 -0.058781 0.064247 0.008213 0.126322 0.0298 59 0.013129 -0.021303 0.043993 0.033347 0.020245 0.037738 - 0.02178 0.027693 -0.07024 0.004687 0.045271 -0.022966 0.014069 0.022861 -0.02787 0.082912 -0.049544 0.016079 -0.004684 0.000572 0.077382 0.036401 0.054974 -0.039538 0.002119 0.034002 -0.008836 -0.014758 0.00959 -0.064647 -0.034766 0.016912 -0.036381 -0.037106 0.073451 -0.098941 -0.092281 -0.018656 0.050538 0.041422 0.041235 0.011248 -0.106058 0.066443 0.083865 0.094636 0.004414 -0.092855 -0.027255 0.005234 0.066584 0.055394 0.023019 -0.001949 -0.0667 94 -0.064739 0.038924 -0.016647 0.000555 0.02428 0.016469 -0.0467 -0.035343 -0.066789 -0.025929 -0.023397 0.062855 0.020142 -0.047568 0.010299 -0.021509 -0.02826 0.029225 0.01803 0.024336 0.018226 -0.009453 -0.068584

如有任何帮助，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/65121932/how-to-use-deepsets-word-embedding-pre-trained-models-using-gensim</guid>
      <pubDate>Thu, 03 Dec 2020 08:02:21 GMT</pubDate>
    </item>
    <item>
      <title>拟合模型时，批量大小和轮数应该有多大？</title>
      <link>https://stackoverflow.com/questions/35050753/how-big-should-batch-size-and-number-of-epochs-be-when-fitting-a-model</link>
      <description><![CDATA[我的训练集有 970 个样本，验证集有 243 个样本。
拟合模型以优化 val_acc 时，批量大小和轮数应该有多大？是否有基于数据输入大小的经验法则可供使用？]]></description>
      <guid>https://stackoverflow.com/questions/35050753/how-big-should-batch-size-and-number-of-epochs-be-when-fitting-a-model</guid>
      <pubDate>Thu, 28 Jan 2016 00:21:39 GMT</pubDate>
    </item>
    <item>
      <title>如何解读scikit的learn混淆矩阵和分类报告？</title>
      <link>https://stackoverflow.com/questions/30746460/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report</link>
      <description><![CDATA[我有一个情感分析任务，为此我使用这个语料库，意见有 5 个类别 (非常负、负、neu、pos、非常pos），从1到5。所以我做如下分类：
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
将 numpy 导入为 np
tfidf_vect= TfidfVectorizer(use_idf=True, smooth_idf=True,
                            sublinear_tf=False, ngram_range=(2,2))
从 sklearn.cross_validation 导入 train_test_split, cross_val_score

将 pandas 导入为 pd

df = pd.read_csv(&#39;/corpus.csv&#39;,
                     标头=0，sep=&#39;,&#39;,名称=[&#39;id&#39;,&#39;内容&#39;,&#39;标签&#39;])

X = tfidf_vect.fit_transform(df[&#39;content&#39;].values)
y = df[&#39;标签&#39;].值


从 sklearn 导入交叉验证
X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,
                                                    y，测试大小=0.33）


从 sklearn.svm 导入 SVC
svm_1 = SVC(内核=&#39;线性&#39;)
svm_1.fit(X, y)
svm_1_prediction = svm_1.predict(X_test)

然后通过指标我获得了以下混淆矩阵和分类报告，如下：
print &#39;\n分类报告:\n&#39;,classification_report(y_test, svm_1_prediction)
print &#39;\n混淆矩阵:\n&#39;,confusion_matrix(y_test, svm_1_prediction)

然后，这就是结果：
分类报告：
             精确召回率 f1-score 支持

          1 1.00 0.76 0.86 71
          2 1.00 0.84 0.91 43
          3 1.00 0.74 0.85 89
          4 0.98 0.95 0.96 288
          5 0.87 1.00 0.93 367

平均/总计 0.94 0.93 0.93 858


混淆矩阵：
[[ 54 0 0 0 17]
 [ 0 36 0 1 6]
 [0 0 66 5 18]
 [ 0 0 0 273 15]
 [0 0 0 0 367]]

如何解释上述混淆矩阵和分类报告。我尝试阅读 文档 和这个 问题。但仍然可以解释这里发生了什么，特别是用这些数据？这个矩阵在某种程度上是“对角的”吗？另一方面，该数据的召回率、精度、f1score 和支持度意味着什么？对于这个数据我能说什么？提前感谢大家]]></description>
      <guid>https://stackoverflow.com/questions/30746460/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report</guid>
      <pubDate>Wed, 10 Jun 2015 03:12:02 GMT</pubDate>
    </item>
    </channel>
</rss>