<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 12 Aug 2024 09:17:39 GMT</lastBuildDate>
    <item>
      <title>Colab Pro 订阅问题 - 已收费但未订阅</title>
      <link>https://stackoverflow.com/questions/78860728/colab-pro-subscription-issue-charged-but-not-subscribed</link>
      <description><![CDATA[我于 8 月 10 日购买了 Google Colab Pro 订阅，但我的帐户仍显示为未订阅。虽然资源部分中的资源单元已更新，但我无法使用 Colab Pro，因为我的会话每 15 分钟就会崩溃一次。通过电子邮件联系 colab-billing@google.com 要求退款，但他们甚至没有回复。
购买了 Colab - Pro 订阅，但即使我已付款，也没有订阅。]]></description>
      <guid>https://stackoverflow.com/questions/78860728/colab-pro-subscription-issue-charged-but-not-subscribed</guid>
      <pubDate>Mon, 12 Aug 2024 08:45:37 GMT</pubDate>
    </item>
    <item>
      <title>我如何知道镜头中的某人是否对齐了轮廓？</title>
      <link>https://stackoverflow.com/questions/78860543/how-can-i-know-if-someone-in-camera-aligns-an-outline</link>
      <description><![CDATA[我正在做一个项目，这个项目与实时摄像头的身体测量有很大关系，但为了校准，我需要人站在屏幕中间，直接适应框架尺寸。为此，我使用了一个透明的人形，除了人形的边界外，其他地方都是透明的。我如何检查人是否符合轮廓？
我尝试在屏幕中间使用 png 并从中绘制轮廓并检查地标，但它总是最终检查一个绘制原始图像边界的正方形。而且，即使一个人站得很近，只用一半的身体来适应它，它也能正常工作。
效果很差。我该如何改进？
现在我的代码片段如下所示：
KadirCoordinates = {
&#39;NOSE&#39;: (320, 36),
&#39;LEFT_SHOULDER&#39;: (274, 100),
&#39;RIGHT_SHOULDER&#39;: (372, 104),
&#39;LEFT_HEEL&#39;: (296, 459),
&#39;RIGHT_HEEL&#39;: (343, 459)
}

points_to_collect = [&#39;NOSE&#39;, &#39;LEFT_SHOULDER&#39;, &#39;RIGHT_SHOULDER&#39;, &#39;LEFT_HEEL&#39;, &#39;RIGHT_HEEL&#39;] #臀部和脚踝处有血迹
current_point_index = 0

if result.pose_landmarks:
landmarks = result.pose_landmarks.landmark

detected_points = {}

for landmark in mp_pose.PoseLandmark:
x = int(landmarks[landmark].x * frame_width)
y = int(landmarks[landmark].y * frame_height)
if landmark.name in points_to_collect:
detected_points[landmark.name] = (x, y)
cv2.circle(blended_frame, (x, y), 5, (0, 255, 0), -1)
alignment_score = 0
threshold = 85 # 降低对齐公差阈值

for key in reference_coordinates:
outline_point = reference_coordinates[key]
detected_point =detected_points.get(key, None)
ifdetected_point:
distance = np.linalg.norm(np.array(outline_point) - np.array(detected_point))
#print(f&quot;Distance for {key}: {distance}&quot;) # 调试信息
if distance &lt; Threshold:
alignment_score += 1 # 根据需要调整阈值

# 计算对齐百分比
alignment_percentage = (alignment_score / len(reference_coordinates)) * 100
cv2.putText(blended_frame, &quot;Alignment score is : {}&quot;.format(alignment_percentage), (50, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)

# 检查对齐，如果对齐则启动计时器
if alignment_percentage &gt;95:
]]></description>
      <guid>https://stackoverflow.com/questions/78860543/how-can-i-know-if-someone-in-camera-aligns-an-outline</guid>
      <pubDate>Mon, 12 Aug 2024 07:55:19 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试为我的深度学习模型创建一个 FastAPI，但它似乎无法复制我在 Colab 中测试时得到的结果</title>
      <link>https://stackoverflow.com/questions/78860470/i-am-trying-to-make-a-fastapi-for-my-deep-learning-model-but-it-does-not-seem-t</link>
      <description><![CDATA[我的模型完全是在 Google Colab 上制作的，我使用 Tensorflow 和 Keras 制作了它。我尝试复制我在 YouTube 上看到的一个教程模型，后来我想为它制作一个网站。因此，我选择了 FastAPI 路线。但它似乎无法复制结果，在 Colab 上，它在验证数据集和测试数据集上的表现都很完美，准确率约为 96%。但是当我为其创建 FastAPI 时，无论我输入什么图像，它始终只显示 1 个特定类作为输出，并且该类的置信度为 96-98%。我以 .keras 格式下载了我的模型，因为 Colab 不支持 .h5 文件下载。这是在 Postman 中，API 似乎运行良好，模型本身在 Colab 上运行良好，但当我将其连接到 API 时不起作用。
有趣的是，当我在再次训练后以不同的名称第二次下载模型时，置信度似乎再次发生变化，并且现在始终保持这种分布。但是，是的，结果仍然相同，预测类 0 作为输出，只是这次置信度发生了变化（与之前的版本不同，在提供不同的图像后通常不会改变）。我还尝试在单独的文件中进行调试，在本地仅使用 1 张图像进行预测，但仍然失败。它出现了与以前相同的模式。我再次上​​网到 Colab 训练和测试模型，看起来效果不错。
下面我提供了我的 API 代码：
`
from fastapi import FastAPI, UploadFile, File
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from matplotlib import pyplot as plt
from PIL import Image
import numpy as np
app = FastAPI()

# 加载模型
try:
model = load_model(&#39;PotatoDisease.keras&#39;)
except ValueError as e:
print(f&quot;Error loading model: {e}&quot;)

class_names = [&#39;Potato___Early_blight&#39;, &#39;Potato___Late_blight&#39;, &#39;Potato___healthy&#39;]

@app.post(&quot;/predict/&quot;)
async def predict(file: UploadFile = File(...)):
image = Image.open(file.file)
image = image.resize((256, 256))
plt.imshow(image)
image = img_to_array(image)
print(&quot;调整大小和数组转换后的图像形状：&quot;, image.shape)
image = np.expand_dims(image, axis=0)
print(&quot;扩展尺寸后的图像形状：&quot;, image.shape)
image = image / 255.0

#prediction
predictions = model.predict(image)
print(&quot;原始预测输出：&quot;, predictions)
predict_class = class_names[np.argmax(predictions[0])]
confidence = round(100 * np.max(predictions[0]), 2)

return {&quot;predicted_class&quot;: predict_class, &quot;confidence&quot;: confidence}

@app.get(&quot;/&quot;)
def read_root():
return {&quot;message&quot;: &quot;欢迎使用图像分类 API&quot;}
`
]]></description>
      <guid>https://stackoverflow.com/questions/78860470/i-am-trying-to-make-a-fastapi-for-my-deep-learning-model-but-it-does-not-seem-t</guid>
      <pubDate>Mon, 12 Aug 2024 07:38:19 GMT</pubDate>
    </item>
    <item>
      <title>自定义回调“BetaAnnealing”无法正确更新我的 VAE kl_loss 的 beta 值</title>
      <link>https://stackoverflow.com/questions/78860370/custom-callback-betaannealing-isnt-updating-the-beta-value-correctly-for-my-v</link>
      <description><![CDATA[我的 VAE 中有一个自定义层，用于处理损失计算。我有一个自定义回调，用于在每个 epoch 开始时更新 beta 值。计算是正确的，因为它在每个 epoch 开始时打印出所需的 beta 值。但是，CustomVariationalLayer 中的实际 beta 值永远不会更新。
@register_keras_serializable(&#39;CustomVariationalLayer&#39;)
class CustomVariationalLayer(keras.layers.Layer):
def __init__(self, beta=1.0, **kwargs):
self.is_placeholder = True
super(CustomVariationalLayer, self).__init__(**kwargs)
self.beta = beta
self.recon_loss_metric = tf.keras.metrics.Mean(name=&#39;recon_loss&#39;)
self.kl_loss_metric = tf.keras.metrics.Mean(name=&#39;kl_loss&#39;)

def vae_loss(self, x, z_decoded, z_mean, z_log_var):
recon_loss = keras.losses.binary_crossentropy(K.flatten(x), K.flatten(z_decoded))
kl_loss = -0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)
print(f&quot;\n真实 beta 值 {self.beta:.4f}&quot;)
return recon_loss, self.beta * kl_loss

def call(self, input):
x = 输入[0]
z_decoded = 输入[1]
z_mean = 输入[2]
z_log_var = 输入[3]
recon_loss, kl_loss = self.vae_loss(x, z_decoded, z_mean, z_log_var)
self.add_loss(K.mean(recon_loss + kl_loss))
self.recon_loss_metric.update_state(recon_loss)
self.kl_loss_metric.update_state(kl_loss)
返回 x

def compute_output_shape(self, input_shape):
返回 input_shape[0]

def get_metrics(self):
返回 {&#39;recon_loss&#39;: self.recon_loss_metric.result().numpy(),
&#39;kl_loss&#39;: self.kl_loss_metric.result().numpy()}

class BetaAnnealing(keras.callbacks.Callback):
def __init__(self, layer, initial_beta=0.0, final_beta=1.0, epochs=100):
super(BetaAnnealing, self).__init__()
self.layer = layer
self.initial_beta = initial_beta
self.final_beta = final_beta
self.epochs = epochs

def on_epoch_begin(self, epoch, logs=None):
new_beta = self.initial_beta + (self.final_beta - self.initial_beta) * (epoch / (self.epochs - 1))
self.layer.beta = new_beta
print(f&quot;Epoch {epoch+1}: Beta 值已更新为 {new_beta:.4f}&quot;)
print(f&quot;Layer beta 值：{self.layer.beta}&quot;)

这是我的训练
batch_size = 128
epochs = 50

# 提前停止
es = EarlyStopping(monitor=&#39;val_loss&#39;, mode=&#39;min&#39;, verbose=1, waiting=5)

# Beta 退火
ba = BetaAnnealing(CustomVariationalLayer, initial_beta=0.0, final_beta=1.0, epochs=epochs)

# 编译模型
model.compile(optimizer=&#39;adam&#39;,
loss=None)

# 训练模型
history = model.fit(x_train, x_train,
batch_size=batch_size,
epochs=epochs,
shuffle=True,
validation_data=(x_validate, x_validate),
callbacks=[es, ba])

一开始看起来好像可以正常工作，因为 BetaAnnealing 的打印语句是正确的，但我向自定义层添加了打印语句进行验证，每次 beta 值都是“1.0”。这是我的训练输出的一个示例：
Epoch 1：Beta 值已更新为 0.0000
层 beta 值：0.0
Epoch 1/50

实际 beta 值 1.0000

实际 beta 值 1.0000
53/53 ━━━━━━━━━━━━━━━━━━━━━━ 0s 112ms/step - kl_loss：237.6640 - loss：238.3435 - recon_loss：0.6795
实际 beta 值 1.0000
53/53 ━━━━━━━━━━━━━━━━━━━━━ 17s 162ms/step - kl_loss：234.6529 - loss：235.3318 - recon_loss：0.6789 - val_kl_loss：5.1546 - val_loss：5.8057 - val_recon_loss：0.6506
Epoch 2：Beta 值更新为 0.0204
层 beta 值：0.02040816326530612
Epoch 2/50
53/53 ━━━━━━━━━━━━━━━━━━━━━ 2s 40ms/step - kl_loss：7.7230 - loss：8.3554 - recon_loss：0.6325 - val_kl_loss：922390720.0000 - val_loss：922390720.0000 - val_recon_loss：7.9802
Epoch 3：Beta 值更新为 0.0408
Layer beta 值：0.04081632653061224
Epoch 3/50
53/53 ━━━━━━━━━━━━━━━━━━━━━ 2s 39ms/step - kl_loss：4.8922 - loss：5.5163 - recon_loss：0.6242 - val_kl_loss：740397.3125 - val_loss：740402.4375 - val_recon_loss：4.9765
Epoch 4：Beta 值更新为 0.0612
层 beta 值：0.061224489795918366
Epoch 4/50
53/53 ━━━━━━━━━━━━━━━━━━━━━ 2s 39ms/step - kl_loss：1.3511 - loss：1.9775 - recon_loss：0.6265 - val_kl_loss：1217.8662 - val_loss：1218.7296 - val_recon_loss：0.8520
Epoch 5：Beta 值更新为 0.0816
Layer beta 值：0.08163265306122448
Epoch 5/50
53/53 ━━━━━━━━━━━━━━━━━━━━━━ 2s 41ms/step - kl_loss: 0.2503 - loss: 0.8771 - recon_loss: 0.6268 - val_kl_loss: 3.0466 - val_loss: 3.6738 - val_recon_loss: 0.6260

我该如何让它工作？]]></description>
      <guid>https://stackoverflow.com/questions/78860370/custom-callback-betaannealing-isnt-updating-the-beta-value-correctly-for-my-v</guid>
      <pubDate>Mon, 12 Aug 2024 07:07:31 GMT</pubDate>
    </item>
    <item>
      <title>我应该在评估模式还是训练模式下评估 WGAN-GP 模型？</title>
      <link>https://stackoverflow.com/questions/78860324/should-i-evaluate-wgan-gp-model-on-eval-mode-or-training-mode</link>
      <description><![CDATA[我在 WGAN-GP 模型中使用 batchnorm2d。我听说 GAN 模型最好保持训练模式，因为评估模式非常不稳定，尤其是在生成器中使用 batchnorm 时。这是真的吗？
我已经做了一些测试，训练模型似乎生成了更真实、更多样化的样本，而评估模式下的模型输出的图像质量非常低，几乎看起来像模式崩溃。我原本以为评估模式会给出更好的结果，但似乎我的 WGAN-GP 模型在评估模式下的表现要差得多。这是正常的吗？我应该只使用训练模式的模型进行评估吗？]]></description>
      <guid>https://stackoverflow.com/questions/78860324/should-i-evaluate-wgan-gp-model-on-eval-mode-or-training-mode</guid>
      <pubDate>Mon, 12 Aug 2024 06:56:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 ResNet50 创建 [w, h, f] 的特征张量</title>
      <link>https://stackoverflow.com/questions/78860233/using-resnet50-to-create-a-feature-tensor-of-w-h-f</link>
      <description><![CDATA[我正在尝试实现这篇论文，但我没有理解其中的内容。
它希望我使用 ResNet50 从图像中提取特征，但告诉我提取的特征将具有 [w, h, f] 的维度。但是，我用 ResNet50 看到的一切都给我返回了一个 [f] 的张量（即，它将我的整个图像变成特征，而不是将我的像素变成特征）
我读错了吗，还是我只是不明白我应该用 ResNet50 做什么？
论文中的相关引述：
“我们获得了一个大小为 f 的中间视觉特征表示 Fc。我们使用 ResNet50 [26] 作为我们的主干卷积架构。&quot;
&quot;第一步，将三维特征 Fc 通过保持其宽度重塑为二维特征，即获得特征形状 (f × h, w)。&quot;]]></description>
      <guid>https://stackoverflow.com/questions/78860233/using-resnet50-to-create-a-feature-tensor-of-w-h-f</guid>
      <pubDate>Mon, 12 Aug 2024 06:27:03 GMT</pubDate>
    </item>
    <item>
      <title>Optuna XGBoost 未使用 Mac 的所有 CPU</title>
      <link>https://stackoverflow.com/questions/78859768/optuna-xgboost-not-using-all-of-macs-cpu</link>
      <description><![CDATA[我正在将 Optuna 与 mySQL 一起运行，以尝试实现并行化并使用更多 Mac 的 CPU。例如，当我运行 GridSearchCV 时，我的用户 CPU 使用率将上升到 90%，并且风扇会启动。但是当我使用 Optuna 时，我得到大约 30% 并且没有风扇。这表明它没有被利用。
我尝试使用 mySQL 和分发在 VSCode 的 Jupyter Notebook 上运行两个处理。我这样做的方式是在不同的内核上制作我的笔记本的两个副本，然后通过加载研究在同一个 SQL 数据库上运行优化代码。也许这不是正确的做法？因为在示例中他们在两个终端上运行了 foo.py？
这是我的代码：
def objective(trial, X_train, y_train, X_test, y_test):
# 定义超参数搜索空间
params = {
&#39;n_estimators&#39;: trial.suggest_int(&#39;n_estimators&#39;, 100, 5000),
&#39;max_depth&#39;: trial.suggest_int(&#39;max_depth&#39;, 2, 20),
&#39;learning_rate&#39;: trial.suggest_float(&#39;learning_rate&#39;, 0.01, 0.2),
&#39;subsample&#39;: trial.suggest_float(&#39;subsample&#39;, 0.7, 1.0),
&#39;colsample_bytree&#39;: trial.suggest_float(&#39;colsample_bytree&#39;, 0.6, 1.0),
&#39;min_child_weight&#39;: trial.suggest_int(&#39;min_child_weight&#39;, 1, 15),
&#39;gamma&#39;: trial.suggest_float(&#39;gamma&#39;, 0.0, 0.4),
&#39;lambda&#39;: trial.suggest_float(&#39;lambda&#39;, 1e-8, 1.0, log=True),
&#39;alpha&#39;: trial.suggest_float(&#39;alpha&#39;, 1e-8, 1.0, log=True)
}

# 初始化并训练模型
xgb = XGBRegressor(**params)
xgb.fit(X_train, y_train)

# 预测并计算指标
y_pred = xgb.predict(X_test)
error = max_percent_error(y_test, y_pred)
return error # 返回要最小化的误差

if __name__ == &quot;__main__&quot;:
study = optuna.load_study(study_name=&quot;example&quot;, storage=&quot;mysql://root@localhost/example&quot;)

# 对每个类别和目标执行优化
for category in train_test_splits:
for target_name in train_test_splits[category]:
if target_name in best_params_dict:
continue
print(f&quot;Running Optuna Optimization for target: {target_name} in category: {category}&quot;)

X_train = train_test_splits[category][target_name][&#39;X_train&#39;]
y_train = train_test_splits[category][target_name][&#39;y_train&#39;]
X_test = train_test_splits[category][target_name][&#39;X_test&#39;]

y_test = train_test_splits[category][target_name][&#39;y_test&#39;]

# 使用分布式计算优化研究
study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test), 
n_trials=1900, n_jobs=-1)

# 存储为此目标找到的最佳参数
best_params = study.best_params
best_params_dict[category][target_name] = best_params

# 使用最佳参数训练最终模型
xgb_best = XGBRegressor(**best_params)
xgb_best.fit(X_train, y_train)

# 使用测试集评估模型
y_pred = xgb_best.predict(X_test)
test_max_percent_error = max_percent_error(y_test, y_pred)
test_r2_score = r2_score(y_test, y_pred)

print(f&quot;{target_name} 的最佳结果：&quot;)
print(f&quot; 最佳参数：{best_params}&quot;)
print(f&quot; 测试最大百分比误差：{test_max_percent_error:.4f}%&quot;)
print(f&quot; 测试 R^2：{test_r2_score:.4f}\n&quot;)


谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78859768/optuna-xgboost-not-using-all-of-macs-cpu</guid>
      <pubDate>Mon, 12 Aug 2024 01:47:51 GMT</pubDate>
    </item>
    <item>
      <title>Epoch 1/3 ^C - model.fit() 以此行终止，且没有任何错误</title>
      <link>https://stackoverflow.com/questions/78858484/epoch-1-3-c-model-fit-was-terminated-with-this-line-and-without-any-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78858484/epoch-1-3-c-model-fit-was-terminated-with-this-line-and-without-any-error</guid>
      <pubDate>Sun, 11 Aug 2024 13:47:36 GMT</pubDate>
    </item>
    <item>
      <title>获取 ValueError：所有数组的长度必须相同</title>
      <link>https://stackoverflow.com/questions/78858321/getting-valueerror-all-arrays-must-be-of-the-same-length</link>
      <description><![CDATA[我一直试图将字典转换为数据框，但每次我都收到 ValueError：所有数组的长度必须相同。我已经检查了每个数组的长度并确认它们相同，但我仍然收到相同的错误
def metrics_from_pipes(pipes_dict):
for name, pipeline in pipes_dict.items():

pipeline.fit(X_train, y_train)
y_pred_val = pipeline.predict(X_val)
y_pred_train = pipeline.predict(X_train)

train_metrics = {
&#39;model&#39;:list(pipes_dict.keys()),
&#39;MAE&#39;:train_mae,
&#39;MAPE&#39;:train_mape,
&#39;RMSE&#39;:train_rmse,
&#39;RSquared&#39;:train_rsquared
}

train_metrics_data = pd.DataFrame(train_metrics)
val_metrics = {
&#39;model&#39;:list(pipes_dict.keys()),
&#39;MAE&#39;:val_mae,
&#39;MAPE&#39;:val_mape,
&#39;RMSE&#39;:val_rmse,
&#39;RSquared&#39;:val_rsquared 
}

val_metrics_data = pd.DataFrame(val_metrics,)

# 合并来自训练集和测试集的指标
train_val_metrics = train_metrics_data.merge(val_metrics_data,
on = &#39;Model&#39;,
how = &#39;left&#39;,
suffixes = (&#39;_train&#39;, &#39;_val&#39;))

# 排序列 
train_val_metrics = train_val_metrics.reindex(columns = [&#39;Model&#39;,
&#39;MAE_train&#39;,
&#39;MAPE_train&#39;,
&#39;RMSE_train&#39;,
&#39;RSquared_train&#39;,
&#39;MAE_val&#39;,
&#39;MAPE_val&#39;,
&#39;RMSE_val&#39;,
&#39;RSquared_val&#39;])

return train_val_metrics.set_index(&#39;Model&#39;).transpose()

# 获取指标表
metrics_table = metrics_from_pipes(pipelines)

运行此代码会出现此错误
ValueError Traceback (most recent call last)
Cell In[45]，第 82 行
80 return train_val_metrics.set_index(&#39;Model&#39;).transpose()
81 # 获取指标表
---&gt; 82 metrics_table = metrics_from_pipes(pipelines)
83 #print(&#39;表 1：基本模型指标&#39;)
84 #metrics_table.style.background_gradient(cmap = Blues)
85 metrics_table

单元格 In[45]，第 50 行，位于 metrics_from_pipes(pipes_dict)
41 # 将性能指标列表聚合到单独的数据框中
42 train_metrics = {
43 &#39;model&#39;:list(pipes_dict.keys()),
44 &#39;MAE&#39;:train_mae,
(...)
47 &#39;RSquared&#39;:train_rsquared
48 }
---&gt; 50 train_metrics_data = pd.DataFrame(train_metrics)
51 val_metrics = {
52 &#39;model&#39;:list(pipes_dict.keys()),
53 &#39;MAE&#39;:val_mae,
(...)
56 &#39;RSquared&#39;:val_rsquared 
57 }
59 val_metrics_data = pd.DataFrame(val_metrics,)

ValueError: 所有数组的长度必须相同

当我检查 train_metrics 和 val 指标的字典结果时，我得到了这个
({&#39;model&#39;: [&#39;Linear Regression&#39;,
&#39;Random Forest Regressor&#39;,
&#39;Gradient Boost Regression&#39;,
&#39;Extra Tree Regressor&#39;],
&#39;MAE&#39;: [829.1023412412194,
288.33455697065233,
712.9637267872279,
0.0010629575741748962],
&#39;MAPE&#39;: [1.0302372135902111,
0.20937541440883897,
0.538244903316323,
6.306697580961048e-07],
&#39;RMSE&#39;: [1120.5542708017374,
416.48933196590013,
1012.399201767692,
0.05804079289490426],
&#39;RSquared&#39;: [0.5598288286601083,
0.9391916010838417,
0.6406981997919169,
0.9999999988190745]},
{&#39;model&#39;: [&#39;线性回归&#39;,
&#39;随机森林回归器&#39;,
&#39;梯度提升回归&#39;,
&#39;额外树回归器&#39;],
&#39;MAE&#39;: [855.9254413559535,
802.5902302175274,
772.3140648475379,
839.9018341377154],
&#39;MAPE&#39;: [1.0395487579496652,
0.5607987708065988,
0.5438627253681279,
0.5852285872937784],
&#39;RMSE&#39;: [1148.6549900167981,
1158.8411708570625,
1109.6145558003204,
1223.23337689915],
&#39;RSquared&#39;: [0.5876710102285392,
0.5803255834810521,
0.6152231339508221,
0.5323905190373128]})
]]></description>
      <guid>https://stackoverflow.com/questions/78858321/getting-valueerror-all-arrays-must-be-of-the-same-length</guid>
      <pubDate>Sun, 11 Aug 2024 12:27:40 GMT</pubDate>
    </item>
    <item>
      <title>处理缺失数据并使用不完整信息建立预测模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78858124/handling-missing-data-and-building-a-predictive-model-with-incomplete-informatio</link>
      <description><![CDATA[我正在为涉及 20 个影响点的供水网络开发一个预测模型。但是，我只有这 20 个点中的 10 个的历史数据。
我想知道如何在这个不完整的数据集下构建预测模型。具体来说：
我可以使用哪些方法来处理剩余 10 个点的缺失数据？在这种情况下，是否有任何标准技术或最佳实践来处理缺失数据？
我如何有效地将我拥有的 10 个点的数据合并到模型中？我可以采用哪些策略来确保有效利用可用数据进行准确预测？
是否有特定的技术或模型可以帮助在数据不完整的情况下进行预测？我对可以有效管理和利用不完整数据的方法感兴趣。
我还没有具体的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78858124/handling-missing-data-and-building-a-predictive-model-with-incomplete-informatio</guid>
      <pubDate>Sun, 11 Aug 2024 10:43:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 hub.KerasLayer 使用 tf.keras.sequential 制作深度学习模型时出错</title>
      <link>https://stackoverflow.com/questions/78857786/error-when-using-hub-keraslayer-using-tf-keras-sequential-to-make-deep-learning</link>
      <description><![CDATA[# 创建一个构建 Keras 模型的函数

def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):
print(&quot;Building model with:&quot;, MODEL_URL)

model = tf.keras.Sequential([
hub.KerasLayer(MODEL_URL), # 第 1 层（输入层）
tf.keras.layers.Dense(units=OUTPUT_SHAPE, 
activation=&quot;softmax&quot;) # 第 2 层（输出层）
])

# 编译模型
model.compile(
loss=tf.keras.losses.CategoricalCrossentropy(), # 我们的模型想要减少这个（它的猜测有多错误）
optimizer=tf.keras.optimizers.Adam(), # 一个朋友告诉我们的模型如何改进它的猜测
metrics=[&quot;accuracy&quot;] # 我们希望这个值上升
)

# 构建模型
model.build(INPUT_SHAPE) # 让模型知道它将获得什么样的输入

返回模型

我有上面的函数，当我运行下面的其他程序时
model = create_model()
model.summary()

它会产生一些错误
TypeError：添加的层必须是 Layer 类的实例。
收到：layer=&lt;Dense name=dense_18,built=False&gt; 类型为 &lt;class &#39;keras.src.layers.core.dense.Dense&#39;&gt;。

我哪里做错了？]]></description>
      <guid>https://stackoverflow.com/questions/78857786/error-when-using-hub-keraslayer-using-tf-keras-sequential-to-make-deep-learning</guid>
      <pubDate>Sun, 11 Aug 2024 08:05:45 GMT</pubDate>
    </item>
    <item>
      <title>有人可以指导我学习 Yolov10 的路线图吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78850160/can-anyone-guide-me-the-roadmap-for-learning-yolov10</link>
      <description><![CDATA[我对深入研究深度学习领域很感兴趣，尤其关注使用 YOLOv10 进行对象检测。
但是，我对该领域常用的许多工具和框架仍然很陌生，例如 TensorFlow、OpenCV 和 PyTorch。
鉴于 YOLOv10 是 YOLO 系列中的最新版本，并引入了几个高级功能，例如 NMS 无训练和提高效率，我有点不知所措，不知道从哪里开始。
我正在寻找一个全面的路线图，可以指导我完成有效使用 YOLOv10 所需的先决条件、必要技能和学习资源。
我希望获得一些特定领域的建议包括：
我应该首先掌握的深度学习中的关键基础主题。

考虑到我对 PyTorch 和 OpenCV 还不熟悉，请提供学习资源或教程。

如何理解对象检测概念，特别是在 YOLOv10 的背景下。

为训练和部署 YOLO 模型设置开发环境的最佳实践。

任何可以巩固我理解的推荐项目或练习。

]]></description>
      <guid>https://stackoverflow.com/questions/78850160/can-anyone-guide-me-the-roadmap-for-learning-yolov10</guid>
      <pubDate>Thu, 08 Aug 2024 19:38:10 GMT</pubDate>
    </item>
    <item>
      <title>我使用自定义增强和 TFRecord 管道在大型图像数据集上训练模型的方法是否有效？[关闭]</title>
      <link>https://stackoverflow.com/questions/78847703/is-my-approach-to-training-a-model-on-a-large-image-dataset-using-custom-augment</link>
      <description><![CDATA[我有一个存储在 TFRecord 文件中的大型图像数据集，我想在这个数据集上训练一个神经网络。我的目标是在将图像输入模型之前对图像应用自定义增强。但是，我找不到内置的 TensorFlow 函数（如 ImageDataGenerator）来在训练之前将增强直接应用于存储为张量的图像。
为了解决这个问题，我编写了一个自定义 ModelTrainer 类，其中我：
从 TFRecord 加载每个图像。
对图像应用一系列自定义变换（侵蚀、膨胀、剪切、旋转）。
创建一个由原始图像及其变换版本组成的批次。
在这个批次上训练模型，其中每个批次由单个图像及其变换版本组成。
这是我的代码片段：
class ModelTrainer:
def __init__(self, model):
self.model = model

def preprocess_image(self, image):
image = tf.cast(image, tf.float32) / 255.0
return image

def apply_erosion(self, image):
kernel = np.ones((5,5), np.uint8)
return cv2.erode(image, kernel, iterations=1)

def apply_dilation(self, image):
kernel = np.ones((5,5), np.uint8)
return cv2.dilate(image, kernel, iterations=1)

def apply_shear(self, image):
rows, cols = image.shape
M = np.float32([[1, 0.5, 0], [0.5, 1, 0]])
返回 cv2.warpAffine(image, M, (cols, rows))

def apply_rotation(self, image, angle=15):
rows, cols = image.shape
M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)
返回 cv2.warpAffine(image, M, (cols, rows))

def transform_image(self, img, i):
if i == 0:
返回 img
elif i == 1:
返回 self.apply_erosion(img)
elif i == 2:
返回 self.apply_dilation(img)
elif i == 3:
返回 self.apply_shear(img)
elif i == 4:
返回 self.apply_rotation(img)

def train_on_tfrecord(self, tfrecord_path, dataset, batch_size=5):
dataset = dataset.map(lambda img, lbl: (self.preprocess_image(img), lbl))
dataset = dataset.batch(1)
dataset = iter(dataset)

对于 batch_images，数据集中的标签：
img_np = batch_images.numpy().squeeze()
lbl_np = labels.numpy().squeeze(axis=0)
image_batch = []
label_batch = []

对于 i in range(5):
perceived_image = self.transform_image(img_np, i)
image_batch.append(transformed_image)
label_batch.append(lbl_np)

image_batch_np = np.stack(image_batch, axis=0)
label_batch_np = np.stack(label_batch, axis=0)

image_batch_tensor = tf.convert_to_tensor(image_batch_np, dtype=tf.float32)
label_batch_tensor = tf.convert_to_tensor(label_batch_np, dtype=tf.float32)

loss = self.model.train_on_batch(image_batch_tensor, label_batch_tensor)

predictions = self.model.predict(image_batch_tensor)
predict_labels = np.argmax(predictions, axis=-1)
true_labels = np.argmax(label_batch_tensor, axis=-1)
accuracy = np.mean(predicted_labels == true_labels)

print(f&quot;Batch Loss = {loss}, Accuracy = {accuracy:.4f}&quot;)


我的问题是：

我一次在一个图像及其转换版本上训练模型的方法是否好且有效？
以这种方式训练网络是否可取，在每个批次中处理一个图像及其增强？
是否有更好的方法或优化我应该考虑处理大型数据集和应用自定义增强？
]]></description>
      <guid>https://stackoverflow.com/questions/78847703/is-my-approach-to-training-a-model-on-a-large-image-dataset-using-custom-augment</guid>
      <pubDate>Thu, 08 Aug 2024 09:51:24 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 部分依赖图与线性回归中的训练测试分割不一致</title>
      <link>https://stackoverflow.com/questions/77820555/shap-partial-dependence-plot-misalignment-with-train-test-split-in-linear-regres</link>
      <description><![CDATA[在 Python 中使用线性回归模型的训练测试分割时，我遇到了 SHAP 部分依赖图的问题。当我计算 SHAP 值并绘制测试集中第一个观测值的部分依赖关系时，数据点和基线的对齐似乎不正确。
这是我的代码的简化版本：
import shap
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import pandas as pd
import matplotlib.pyplot as plt
import request

def load_data() -&gt; pd.DataFrame:
&quot;&quot;&quot;
从给定的 URL 加载并返回数据集作为 Pandas DataFrame。

返回：
pd.DataFrame：已加载的数据集。
&quot;&quot;&quot;
url = &quot;https://archive.ics.uci.edu/static/public/165/concrete+compressive+strength.zip&quot;

r = 请求.get(url)

if r.ok:
使用 zipfile.ZipFile(BytesIO(r.content)) 作为 thezip:
使用 thezip.open(&quot;Concrete_Data.xls&quot;) 作为 thefile:
return pd.read_excel(thefile, header=0)
else:
引发异常(&quot;出现错误。&quot;)

df = load_data()

df = df.rename(
columns={
&#39;水泥 (组分 1)(立方米混合物中的千克)&#39;:&#39;水泥&#39;,
&#39;高炉矿渣 (组分 2)(立方米混合物中的千克)&#39;:&#39;blast&#39;,
&#39;粉煤灰 (组分 3)(立方米混合物中的千克)&#39;:&#39;ash&#39;,
&#39;水 (组分 4)(立方米混合物中的千克)&#39;:&#39;water&#39;,
&#39;高效减水剂 (组分 5)(立方米混合物中的千克) m^3 混合物)&#39;:&#39;高效减水剂&#39;,
&#39;粗骨料 (组分 6)(m^3 混合物中 kg)&#39;:&#39;粗&#39;,
&#39;细骨料 (组分 7)(m^3 混合物中 kg)&#39;:&#39;细&#39;,
&#39;年龄 (天)&#39;:&#39;年龄&#39;,
&#39;混凝土抗压强度 (MPa, 兆帕) &#39;: &#39;强度&#39;
}
)
df = df.drop_duplicates()
X = df.drop([&#39;强度&#39;], axis=1) 
y = df[&#39;强度&#39;]

# 拆分数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练模型
model = LinearRegression()
model.fit(X_train, y_train)

# 初始化 SHAP 解释器并计算测试集的值
explainer = shap.Explainer(model.predict, X_train)
shap_values = explainer(X_test)

# 绘制第一个测试观察的部分依赖关系
idx = 0
shap.partial_dependence_plot(
&quot;cement&quot;, model.predict, X_test,
model_expected_value=True, feature_expected_value=True, ice=False,
shap_values=shap_values[idx:idx+1,:]
)

# 保存图
plt.tight_layout()
plt.savefig(&#39;shap_dependence_plot.png&#39;, dpi=300)

但是，当我生成图时，数据点（黑点）与预期值线（蓝线）不一致感兴趣的特征。它似乎沿 y 轴移动。以下是输出图供参考：

当我使用整个数据集 X 而不是仅使用 X_train 初始化 SHAP 解释器时，该图似乎是正确的：
explainer = shap.Explainer(linreg, X)
shap_values = explainer(X_test)

idx = 0
shap.partial_dependence_plot(
&quot;cement&quot;, model.predict, X_test,
model_expected_value=True, feature_expected_value=True, ice=False,
shap_values=shap_values[idx:idx+1,:]
)

结果：

有人能解释一下为什么会出现这种错位，以及如何在使用训练测试分割时纠正部分依赖图吗？
任何见解或建议都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/77820555/shap-partial-dependence-plot-misalignment-with-train-test-split-in-linear-regres</guid>
      <pubDate>Mon, 15 Jan 2024 14:42:18 GMT</pubDate>
    </item>
    <item>
      <title>“Exact”对象没有属性“shap_values”</title>
      <link>https://stackoverflow.com/questions/73685519/exact-object-has-no-attribute-shap-values</link>
      <description><![CDATA[import shap
将 pandas 导入为 pd
从 sklearn.datasets 导入 fetch_california_housing
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestRegressor

dataset = fetch_california_housing(as_frame=True)
X = dataset[&quot;data&quot;]
y = dataset[&quot;target&quot;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = RandomForestRegressor()

model.fit(X_train, y_train)

explainer = shap.Explainer(model.predict, X_test)
shap_values = explainer(X_test)
shap_values = explainer.shap_values(X)

AttributeError: &#39;Exact&#39; 对象没有属性 &#39;shap_values&#39;

为了知道 SHAP 值，即使我输入了上述代码，最后一行也会出现上述错误。
当我查看示例代码时，它似乎没有任何问题，但 SHAP 库版本已更新，问题似乎已经发生。
我可以使用什么代码代替 .shap_values？]]></description>
      <guid>https://stackoverflow.com/questions/73685519/exact-object-has-no-attribute-shap-values</guid>
      <pubDate>Mon, 12 Sep 2022 07:00:33 GMT</pubDate>
    </item>
    </channel>
</rss>