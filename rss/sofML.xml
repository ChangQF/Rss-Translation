<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 02 May 2024 09:15:02 GMT</lastBuildDate>
    <item>
      <title>我如何解决此错误并使我的代码运行</title>
      <link>https://stackoverflow.com/questions/78417439/how-do-i-resolve-this-error-and-get-my-code-running</link>
      <description><![CDATA[找不到指定的模块。加载“C:\Users\mechg\OneDrive\Desktop\modeltesting\env\Lib\site-packages\torch\lib\fbgemm.dll”时出错或其依赖项之一。
当我运行依赖于 torch 的 python 脚本时，这是我遇到的错误，到处搜索但无法解决，请帮助我
这是代码
导入火炬
从 PIL 导入图像
从 Transformer 导入 AutoModelForCausalLM、AutoTokenizer

model_id =“qresearch/llama-3-vision-alpha-hf”
模型 = AutoModelForCausalLM.from_pretrained(
    model_id、trust_remote_code=True、torch_dtype=torch.float16
）

tokenizer = AutoTokenizer.from_pretrained(
    型号_id，
    use_fast=真，
）

image = Image.open(“照片.jpg”)

打印（
    分词器.解码(
        model.answer_question(image, “描述图像”, tokenizer),
        Skip_special_tokens=真，
    ）
）

]]></description>
      <guid>https://stackoverflow.com/questions/78417439/how-do-i-resolve-this-error-and-get-my-code-running</guid>
      <pubDate>Thu, 02 May 2024 07:09:45 GMT</pubDate>
    </item>
    <item>
      <title>无法在 vs code 和 Python 中安装 dlib [已关闭]</title>
      <link>https://stackoverflow.com/questions/78417341/unable-to-install-dlib-in-vs-code-python</link>
      <description><![CDATA[每当我尝试安装时都会遇到此错误。
在此处输入图片描述
这些是我拥有的 Py 和 Cmake 的版本
在此处输入图片描述
我必须下载 Dlib，但我遇到的问题是版本的兼容性。任何人都可以指导我如何修复该错误。]]></description>
      <guid>https://stackoverflow.com/questions/78417341/unable-to-install-dlib-in-vs-code-python</guid>
      <pubDate>Thu, 02 May 2024 06:47:55 GMT</pubDate>
    </item>
    <item>
      <title>Model.evaluate 与 Model.predict：Keras、迁移学习：为什么准确度存在如此差异？</title>
      <link>https://stackoverflow.com/questions/78417156/model-evaluate-vs-model-predict-keras-transfer-learning-why-such-difference</link>
      <description><![CDATA[我正在使用预先训练的 resnet 50 模型进行图像分类。运行模型几个时期后，我得到的结果是：
Epoch 8/20 损失：0.5705 - 准确度：0.8785 - val_loss：0.9226 - val_accuracy：0.8135
Epoch 9/20 损失：0.5509 - 准确度：0.8780 - val_loss：0.9321 - val_accuracy：0.7979
获得的这些结果可以改进，但我们暂时保留这些结果。
当我运行 model.evaluate() 时，我获得了一个我期望的值：
# 评估模型 test_loss, test_acc = model.evaluate(val_data_flow) print(&quot;测试准确度:&quot;, test_acc)
测试准确度：0.7978515625
当我运行 Model.predict() 时，准确性非常糟糕：
从sklearn.metrics导入classification_report


# 对测试数据集生成预测
预测 = model.predict(val_data_flow)

# 将预测转换为类标签
Predicted_labels = np.argmax(预测，轴=1)

# 从测试数据集中提取真实标签
true_labels = val_data_flow.labels

# 生成分类报告
class_names = list(val_data_flow.class_indices.keys())
打印（分类报告（真实标签，预测标签，目标名称=类名称））


 精确召回率 f1-score 支持

       1 0.33 0.38 0.36 330
       2 0.00 0.00 0.00 14
       3 0.17 0.17 0.17 133
       4 0.09 0.11 0.10 102
       5 0.00 0.00 0.00 5
       6 0.00 0.00 0.00 21
       7 0.12 0.12 0.12 133
       8 0.18 0.16 0.17 154
       9 0.18 0.13 0.15 132

精度 0.21 1024
宏观平均 0.12 0.12 0.12 1024
加权平均值 0.20 0.21 0.21 1024

什么可能导致这样的问题？或者是因为函数 model.predict 和 model.evaluate 的工作方式不同？
我的数据集非常不平衡]]></description>
      <guid>https://stackoverflow.com/questions/78417156/model-evaluate-vs-model-predict-keras-transfer-learning-why-such-difference</guid>
      <pubDate>Thu, 02 May 2024 06:02:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用已经制作的嵌入尝试不同的分块策略？</title>
      <link>https://stackoverflow.com/questions/78417029/how-to-try-different-chunking-strategies-with-already-make-embeddings</link>
      <description><![CDATA[如何使用已创建的嵌入尝试不同的分块策略？嵌入存储在 vectorDB 中。据我所知，在分块过程之后，会创建嵌入。这就是我感到疑惑的原因。如果我错了，请纠正我。]]></description>
      <guid>https://stackoverflow.com/questions/78417029/how-to-try-different-chunking-strategies-with-already-make-embeddings</guid>
      <pubDate>Thu, 02 May 2024 05:22:26 GMT</pubDate>
    </item>
    <item>
      <title>图像分析以寻找适印性[关闭]</title>
      <link>https://stackoverflow.com/questions/78416596/image-analysis-to-find-printability</link>
      <description><![CDATA[我是编码新手。我有一张 cad 图像 cad.png。 3D 打印后的 CAD 图像 print.png 后的几张图像。
我想将 cad 图像与打印图像进行比较，看看打印是否准确。匹配的百分比是多少。
稍后，如果可能的话，尝试预测它是叠印还是印刷不足。
图像有不同的尺寸。我需要任何参考点来测量图像中的对象吗？
我应该如何进行？]]></description>
      <guid>https://stackoverflow.com/questions/78416596/image-analysis-to-find-printability</guid>
      <pubDate>Thu, 02 May 2024 01:31:25 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 上的推理困难</title>
      <link>https://stackoverflow.com/questions/78416324/difficulty-performing-inference-on-lstm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78416324/difficulty-performing-inference-on-lstm</guid>
      <pubDate>Wed, 01 May 2024 23:08:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习 - 神经网络</title>
      <link>https://stackoverflow.com/questions/78416266/machine-learning-neural-network</link>
      <description><![CDATA[我是初学者。我正在尝试创建一个具有一个隐藏层的神经网络，它将图像分为 12 个不同的类别。当我尝试使用梯度下降函数运行代码来开始训练模型时，代码根本不输出任何内容并移至下一个单元格。
definitialize_parameters(hidden_​​units):
    w1 = np.random.randn(hidden_​​units, 640 * 480 * 3) * 0.01
    b1 = np.zeros((hidden_​​units, 1))
    w2 = np.random.randn(12, 隐藏单元) * 0.01
    b2 = np.zeros((12, 1))
    返回 w1、b1、w2、b2

def ReLU(Z):
    返回 np.maximum(0, Z)

def softmax(Z):
    expZ = np.exp(Z)
    返回 expZ / np.sum(expZ, axis=0, keepdims=True)

defforward_propagation(w1, b1, w2, b2, X):
    z1 = np.dot(w1, X) + b1
    a1 = ReLU(z1)
    z2 = np.dot(w2, a1) + b2
    a2 = softmax(z2)
    返回 z1、a1、z2、a2

def onehotencoding(Y):
    one_hot_Y = np.zeros((Y.size, Y.max() + 1))
    one_hot_Y[np.arange(Y.size), Y] = 1
    one_hot_Y = one_hot_Y.T
    返回 one_hot_Y

def导数ReLU(Z):
    返回Z&gt; 0

def back_propagation(w2, a1, z1, a2, X, Y):
    m = Y 尺寸
    one_hot_Y = onehotencoding(Y)
    dz2 = a2 - one_hot_Y
    dw2 = 1 / m * np.dot(dz2, a1.T)
    db2 = 1 / m * np.sum(dz2, axis=1, keepdims=True)
    dz1 = np.dot(w2.T, dz2) *导数ReLU(z1)
    dw1 = 1 / m * np.dot(dz1, X.T)
    db1 = 1 / m * np.sum(dz1, axis=1, keepdims=True)
    返回 dw1、db1、dw2、db2

def update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):
    w1 = w1 - 阿尔法 * dw1
    b1 = b1 - 阿尔法 * db1
    w2 = w2 - 阿尔法 * dw2
    b2 = b2 - 阿尔法 * db2
    返回 w1、b1、w2、b2

此代码单元格在此结束，后面是此代码块。
def get_predictions(a2):
    返回 np.argmax(a2, 轴=0)

def get_accuracy(预测, Y):
    返回 np.sum(预测 == Y) / Y.size

defgradient_descent(X,Y,hidden_​​units,迭代,alpha):
    w1、b1、w2、b2 = 初始化参数（隐藏单元）
    对于范围内的 i（迭代）：
        z1, a1, z2, a2 = 前向传播(w1, b1, w2, b2, X)
        dw1, db1, dw2, db2 = 反向传播(w2, a1, z1, a2, X, Y)
        w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)
        如果我％10==0：
            预测 = get_predictions(a2)
            准确度 = get_accuracy(预测, Y)
            print(&quot;迭代：&quot;, i)
            print(&quot;准确率：&quot;, 准确率)
    返回 w1、b1、w2、b2


这是开始训练的梯度下降函数。
w1, b1, w2, b2 = 梯度下降(X_train, Y_train, 500, 迭代=1000, alpha=0.1)]]></description>
      <guid>https://stackoverflow.com/questions/78416266/machine-learning-neural-network</guid>
      <pubDate>Wed, 01 May 2024 22:43:52 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM——我实际上有多少棵树？</title>
      <link>https://stackoverflow.com/questions/78416214/lightgbm-how-many-trees-do-i-actually-have</link>
      <description><![CDATA[初学者在这里尝试 LGBM。我的代码看起来像这样
clf = lgb.LGBMClassifier(max_深度=3，详细程度=-1，n_estimators=3)
clf.fit(train_data[特征],train_data[&#39;y&#39;],sample_weight=train_data[&#39;权重&#39;])
print (f“我有 {clf.n_estimators_} 估计器”)
图，ax = plt.subplots（nrows = 4，figsize =（50,36），sharex = True）
lgb.plot_tree(clf, tree_index=7, dpi=600, ax=ax[0]) # 为什么有第七棵树？
lgb.plot_tree(clf, tree_index=8, dpi=600, ax=ax[1]) # 为什么它有第 8 棵树？
#lgb.plot_tree(clf, tree_index=9, dpi=600, ax=ax[2]) # 崩溃
#lgb.plot_tree(clf, tree_index=10, dpi=600, ax=ax[3]) # 崩溃

令我惊讶的是，尽管有 n_estimators=3，但我似乎有 9 棵树？我如何实际设置树的数量，以及与之相关的，n_estimators 是做什么的？我读过文档，我以为是树的数量，但似乎是别的东西。
另外，我如何解释单独的树及其顺序 0、1、2 等。我了解随机森林，以及每棵树如何同等重要。在 boosting 中，第一棵树最重要，下一棵树的重要性要低得多，下一棵树的重要性要低得多。所以在我的脑海中，当我查看树形图时，我该如何“模拟” LightGBM 推理过程？]]></description>
      <guid>https://stackoverflow.com/questions/78416214/lightgbm-how-many-trees-do-i-actually-have</guid>
      <pubDate>Wed, 01 May 2024 22:24:21 GMT</pubDate>
    </item>
    <item>
      <title>当不打乱测试数据时，Torchmetrics 的准确性问题。为什么？</title>
      <link>https://stackoverflow.com/questions/78415660/torchmetrics-accuracy-issue-when-dont-shuffle-test-data-why</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78415660/torchmetrics-accuracy-issue-when-dont-shuffle-test-data-why</guid>
      <pubDate>Wed, 01 May 2024 19:45:02 GMT</pubDate>
    </item>
    <item>
      <title>如何微调代码bert模型/建议可以生成yaml代码的模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</link>
      <description><![CDATA[任何人都可以建议我如何微调 Codebert 模型。有什么解决办法吗？请给我一些建议。
我想知道 codebert 是开源的，我们可以使用 cpu 运行它吗？可以生成 ymal 代码吗？或者请推荐适合生成ymal代码的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</guid>
      <pubDate>Wed, 01 May 2024 17:45:57 GMT</pubDate>
    </item>
    <item>
      <title>如何根据用户的输入测试模型？ （根据电影评论预测情绪）</title>
      <link>https://stackoverflow.com/questions/78414840/how-to-test-a-model-on-users-input-predict-sentiment-from-movie-reviews</link>
      <description><![CDATA[我的代码：
导入matplotlib
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
从 keras.utils 导入到_categorical
从 keras 导入模型
从 keras 导入层
将张量流导入为 tf
将 pandas 导入为 pd

从 keras.datasets 导入 imdb
（训练数据，训练目标），（测试数据，测试目标）= imdb.load_data（num_words = 10000）

def OneHotEncoding_fn(IMDBData,维度=10000):
   OneHotEncoded_Data=np.zeros((len(IMDBData),维度))
   对于 i，枚举中的序列（IMDBData）：
    OneHotEncoded_Data[i，序列]=1。
   返回 OneHotEncoded_Data
    
训练数据=OneHotEncoding_fn(训练数据)
测试数据=OneHotEncoding_fn(测试数据)
Training_targets=np.asarray(training_targets).astype(&#39;float32&#39;)
test_targets=np.asarray(testing_targets).astype(&#39;float32&#39;)

模型=models.Sequential()
model.add(layers.Dense(50,activation=&#39;relu&#39;,input_shape=(10000,)))
model.add(layers.Dropout(0.3,noise_shape=None,seed=None))
model.add(layers.Dense(50,activation=&#39;relu&#39;))
model.add(layers.Dropout(0.2,noise_shape=None,seed=None))
model.add（layers.Dense（50，激活=“relu”））
model.add(layers.Dense(1,activation=&#39;sigmoid&#39;))
模型.summary()

数据验证=训练数据[:5000]
Training_data_without_val=training_data[5000:]
Targets_validation=training_targets[:5000]
Training_targets_without_val=training_targets[5000:]

model.compile(optimizer=&#39;RMSprop&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
历史=模型.fit(training_data_without_val,training_targets_without_val,epochs=25,batch_size=512,validation_data=(data_validation,targets_validation))

x = input(&#39;写下您的评论：&#39;)
pred=模型.预测(x)

我需要写我的评论（例如“这是非常有趣的电影”）来测试模型的准确性。输入后，程序必须对我的单词进行编码以索引相关的 Keras IMDB 索引并输出结果（1 或 0）。如何做到这一点？
我尝试在这里查找信息：https://keras.io/api/datasets/imdb / ，但没有成功。我需要编写一个函数，允许您输入用户的文本（​​在报告中，给出网络如何处理用户文本的示例）。错误：无法识别的数据类型：x=这是一部非常有趣的电影（类型为）]]></description>
      <guid>https://stackoverflow.com/questions/78414840/how-to-test-a-model-on-users-input-predict-sentiment-from-movie-reviews</guid>
      <pubDate>Wed, 01 May 2024 16:26:06 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“ParticleSwarmOptimization”对象没有属性“global_best_fitnes”</title>
      <link>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</link>
      <description><![CDATA[用于特征选择的执行代码 PSO 出错
def 健身（位置）：
    selected_features = np.array(位置, dtype=bool)
    X_selected = X.iloc[:, selected_features]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    分类器 = KNeighborsClassifier()
    分类器.fit(X_train, y_train)
    y_pred = 分类器.预测(X_test)
    准确度=准确度_得分(y_test, y_pred)
    返回精度

将 numpy 导入为 np

粒子群优化类：
    def __init__(自身、n_粒子、n_特征、n_迭代、fitness_function、w=0.5、c1=1、c2=2)：
        self.n_粒子 = n_粒子
        self.n_features = n_features
        self.n_iterations = n_iterations
        self.fitness_function = 健身函数
        自我.w = w
        自身.c1 = c1
        自身.c2 = c2

    def 初始化粒子（自身）：
        返回 np.random.choice([0, 1], size=(self.n_articles, self.n_features))

    def update_velocity(自身、速度、个人最佳、全局最佳、位置)：
        认知 = self.c1 * np.random.rand() * (personal_best - 位置)
        社会 = self.c2 * np.random.rand() * (global_best - 位置)
        返回 self.w * 速度 + 认知 + 社交

    def update_position（自身，位置，速度）：
        返回 np.round(1 / (1 + np.exp(-velocity))).astype(int)

    def 优化（自我）：
        self.best_fitness_history = [] # 添加此行来存储健身历史记录

        # 初始化粒子
        位置 = self.initialize_articles()
        速度 = np.zeros((self.n_articles, self.n_features))

        个人最佳 = 位置.copy()
        Personal_best_fitness = np.array([self.fitness_function(pos) for pos in individual_best])

        self.global_best = individual_best[np.argmax(personal_best_fitness)]
        self.global_best_fitness = np.max(personal_best_fitness)

        对于范围内的迭代（self.n_iterations）：
            对于范围内的 i(self.n_articles)：
                # 更新速度和位置
                速度[i] = self.update_velocity(速度[i], individual_best[i], self.global_best, 位置[i])
                位置[i] = self.update_position(位置[i], 速度[i])

                # 更新个人最好成绩
                current_fitness = self.fitness_function(position[i])
                如果 current_fitness &gt;个人最佳健身[i]：
                    个人最佳[i] = 位置[i].copy()
                    个人最佳健康度[i] = 当前健康度

                    # 更新全局最佳值
                    如果 current_fitness &gt; self.global_best_fitness：
                        self.global_best = 位置[i].copy()
                        self.global_best_fitness = current_fitness
                        
                        self.best_fitness_history.append(self.global_best_fitness)

        返回 self.global_best, self.global_best_fitnes
]]></description>
      <guid>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</guid>
      <pubDate>Wed, 01 May 2024 13:57:37 GMT</pubDate>
    </item>
    <item>
      <title>从 python 中的随机森林回归模型中查找最大值</title>
      <link>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</link>
      <description><![CDATA[当用户给出上限时，我一直在使用随机森林回归来计算广告支出回报率 (ROAS)。我的模型采用三个输入变量：电视、广播和报纸广告的成本。然而，为了找到最优值，我需要使用 for 循环来遍历每一美元，这非常耗时。有没有更快的方法来找到程序中的最高 y 值？
def ROASPrediction(Q、电视、广播、报纸)：
    rec =“最佳销售推荐投资”
    y_大 = 0
    x_b = 0
    y_b = 0
    z_b = 0
    对于范围内的 x(TV // 2, TV)：
        对于范围内的 y（单选 // 2，单选）：
            对于范围内的 z（报纸 // 2，报纸）：
                customer_features = np.array([x, y, z])
                客户特征1 = 客户特征.reshape(1, -1)
                # customer_features1 =pd.DataFrame(customer_features)
                model_fit1 = joblib.load(&#39;/content/drive/MyDrive/ROAS.joblib&#39;)
                y_future_pred = model_fit1.predict(customer_features1)
                打印（“y_future_pred”，y_future_pred）
                if (y_future_pred[0] &gt;= y_big):
                    y_big = y_future_pred[0]
                    x_b = x
                    y_b = y
                    z_b = z
    # y_future_pred1= str(y_future_pred[0]) + “M$”
    # y_roas= y_future_pred[0]*1000000 / (电视+广播+报纸)
    y_future_pred1 = str(y_big) + “M$”
    y_roas = y_big * 1000000 /（电视+广播+报纸）
    x_b1 = str(x_b)
    y_b1 = str(y_b)
    z_b1 = str(z_b)
    y_roas1 = str(y_roas) + “%”
    返回记录，x_b1，y_b1，z_b1，y_future_pred1，y_roas1

以下代码是我的随机森林模型。
df = pd.read_csv(&#39;/Advertising.csv&#39;)
df.head()
x = df[[&#39;电视&#39;,&#39;广播&#39;,&#39;报纸&#39;]]
y = df[[&#39;销售额&#39;]]
x_train, x_test, y_train, y_test = train_test_split (x, y, test_size=0.20 , random_state=41)
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)
rf_regressor.fit(x_train, y_train)
y_pred = rf_regressor.predict(x_test)

这是我正在使用的 csv 文件。 
有没有办法让 ROASPrediction 函数更加高效，这样就不需要 5 分钟来计算 30 美元的电视、广播和报纸？]]></description>
      <guid>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</guid>
      <pubDate>Tue, 30 Apr 2024 06:42:36 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    <item>
      <title>将图像转换为像素[关闭]</title>
      <link>https://stackoverflow.com/questions/78373235/convertion-of-images-to-pixel</link>
      <description><![CDATA[如果我将五个图像放入要转换为 CSV 表单中的像素的文件夹中，然后将五个图像中的每一个都需要放置在五行中的每一行中，有人可以协助创建 Python 代码吗？非常需要代码。
完整的源代码]]></description>
      <guid>https://stackoverflow.com/questions/78373235/convertion-of-images-to-pixel</guid>
      <pubDate>Tue, 23 Apr 2024 14:41:47 GMT</pubDate>
    </item>
    </channel>
</rss>