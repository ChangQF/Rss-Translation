<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 24 Apr 2024 09:14:11 GMT</lastBuildDate>
    <item>
      <title>顺序最小优化器的训练损失曲线上的峰值</title>
      <link>https://stackoverflow.com/questions/78377148/spikes-on-training-loss-curve-of-sequential-minimal-optimizer</link>
      <description><![CDATA[我正在尝试实现一个具有硬边距的 SMO 优化器来解决大边距分类器，但是，我注意到训练损失曲线上有奇怪的尖峰（我正在使用铰链损失），我做了什么吗错了？
我的代码
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
导入时间

np.随机.种子(0)


def SMO_impl(no_of_points):
#数据点生成
    区域_abc = []
    区域_bcd = []

    while(len(region_abc) &lt; no_of_points 或 len(region_bcd) &lt; no_of_points):
        new_point = np.random.uniform(0,1,(2,))
        if(new_point[1]&gt;new_point[0] 且 len(region_bcd) &lt; no_of_points):
            Region_bcd.append(new_point)
        elif(new_point[1] 容差且 alphas[i] &gt; 0)):
                j = pick_j(i,len(数据点))
                error_j = sum([alphas[k]*y[k]*np.dot(data_points[j],data_points[k]) for k in range(len(data_points))]) + b - y[j]

                old_alpha_i, old_alpha_j = alphas[i], alphas[j]

                L = max(0, alphas[j] - alphas[i]) 如果 y[i] != y[j] 否则 max(0, alphas[i] + alphas[j] - C)
                H = min(C, C + alphas[j] - alphas[i]) 如果 y[i] != y[j] else min(C, alphas[i] + alphas[j])

                如果 L == H：
                    继续

                eta = 2* np.dot(data_points[i], data_points[j]) - np.dot(data_points[i], data_points[i]) - np.dot(data_points[j], data_points[j])
                如果（eta &gt;= 0）：
                    继续
                new_alpha_j = alphas[j] - y[j] * (error_i - error_j) / eta
                new_alpha_j = np.clip(new_alpha_j, L, H)

                阿尔法[j] = new_alpha_j
                if(np.abs(alphas[j]-old_alpha_j)&lt;0.00001):
                    继续
                alphas[i] = alphas[i] + y[i]*y[j]*(old_alpha_j-alphas[j])

                b1 = b - error_i - y[i]*(old_alpha_i-alphas[i])*np.dot(data_points[i],data_points[i])- y[j]*(old_alpha_j-alphas[j])*np .dot(数据点[i],数据点[j])
                b2 = b - error_j - y[i]*(old_alpha_i-alphas[i])*np.dot(data_points[i],data_points[j]) - y[j]*(old_alpha_j-alphas[j])*np .dot(数据点[j],数据点[j])

                if(alphas[i]&gt;0):
                    b = b1
                elif(alphas[j]&gt;0):
                    b = b2
                别的：
                    b = (b1+b2)/2
                改变的阿尔法 += 1
        总损失 = sum([hinge_loss(alphas, y, data_points,i,b) for i in range(len(data_points))]) / len(data_points)
                         
        损失.append(total_loss)
        迭代 = 迭代 + 1 if(changed_alphas==0) else 0

    #训练损失曲线

    plt.plot(losses, label = f&#39;每组有 {no_of_points} 点的训练损失曲线&#39;)
    plt.title(f&#39;每组有 {no_of_points} 点的训练损失曲线&#39;)

 
SMO_impl(20)

曲线
在此处输入图像描述
忽略以下内容
（看起来我的帖子主要是代码；添加更多细节。看起来我的帖子主要是代码；添加更多细节。）]]></description>
      <guid>https://stackoverflow.com/questions/78377148/spikes-on-training-loss-curve-of-sequential-minimal-optimizer</guid>
      <pubDate>Wed, 24 Apr 2024 08:59:54 GMT</pubDate>
    </item>
    <item>
      <title>尽管 GPU 可用，但 CUDA 设置失败</title>
      <link>https://stackoverflow.com/questions/78376600/cuda-setup-failed-despite-gpu-being-available</link>
      <description><![CDATA[我需要使用bitsandbytes包来运行使用Falcon7B模型的代码。我已经安装了 CUDA，并且我的系统具有 NVIDIA RTX A6000 GPU。我的系统有 Windows 11 操作系统。
这是代码，它只是导入部分：
导入火炬
从数据集导入load_dataset
从变压器导入 AutoModelForCausalLM、AutoTokenizer、BitsAndBytesConfig、TrainingArguments、GenerationConfig
从peft导入LoraConfig，get_peft_model，PeftConfig，PeftModel，prepare_model_for_kbit_training
从 trl 导入 SFTTrainer
进口警告
warnings.filterwarnings(“忽略”)

这是错误：
运行时错误：
        尽管 GPU 可用，但 CUDA 安装失败。请运行以下命令来获取更多信息：

        python -m 位和字节

        检查命令的输出并查看是否可以找到 CUDA 库。您可能需要添加它们
        到您的 LD_LIBRARY_PATH。如果您怀疑存在错误，请从 python -m bitsandbytes 获取信息
        并在以下位置提出问题：https://github.com/TimDettmers/bitsandbytes/issues



RuntimeError：由于以下错误而无法导入transformers.training_args（查找其回溯）：

        尽管 GPU 可用，但 CUDA 安装失败。请运行以下命令来获取更多信息：

        python -m 位和字节

        检查命令的输出并查看是否可以找到 CUDA 库。您可能需要添加它们
        到您的 LD_LIBRARY_PATH。如果您怀疑存在错误，请从 python -m bitsandbytes 获取信息
        并在以下位置提出问题：https://github.com/TimDettmers/bitsandbytes/issues

有时不会出现此错误，并且代码可以正常工作。但大多数时候我都会遇到此错误，并且无法找到准确的修复方法。
当系统中未安装 CUDA 时，首次出现此错误。安装后没有报错，但是第二天再次运行时，又出现了同样的错误。
接下来我尝试将 python 版本降级到 3.11.1 以下，之后代码再次运行。但今天我再次面临同样的错误。
这是我的 CUDA 版本：
&lt;前&gt;&lt;代码&gt;nvcc --版本
nvcc：NVIDIA (R) Cuda 编译器驱动程序
版权所有 (c) 2005-2023 NVIDIA 公司
建于 Wed_Feb__8_05:53:42_Cooperative_Universal_Time_2023
Cuda 编译工具，版本 12.1，V12.1.66
构建cuda_12.1.r12.1/compiler.32415258_0
]]></description>
      <guid>https://stackoverflow.com/questions/78376600/cuda-setup-failed-despite-gpu-being-available</guid>
      <pubDate>Wed, 24 Apr 2024 07:18:58 GMT</pubDate>
    </item>
    <item>
      <title>合并两个不同的人工智能模型</title>
      <link>https://stackoverflow.com/questions/78376582/merging-two-different-ai-models</link>
      <description><![CDATA[我已经训练了两个模型，一个用于模糊检测，另一个用于两个不同数据集的曝光分类，现在我想合并这两个模型以获得执行这两项任务的单个组合模型
我希望组合模型通过将单个图像作为输入来预测模糊和曝光]]></description>
      <guid>https://stackoverflow.com/questions/78376582/merging-two-different-ai-models</guid>
      <pubDate>Wed, 24 Apr 2024 07:14:39 GMT</pubDate>
    </item>
    <item>
      <title>训练 DL 模型时，本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束</title>
      <link>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</link>
      <description><![CDATA[我正在创建一个植物病害识别模型。我有一个包含 38 种疾病的数据集，每种疾病有大约 2000 张图像。但是在训练模型时，由于一些 OUT_OF_RANGE 错误，一些时期被跳过。有人可以帮我解决这个问题吗？
导入操作系统
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、展平、密集、输入

train_dir = &#39;数据集/火车&#39;
valid_dir = &#39;数据集/有效&#39;
批量大小 = 32

train_datagen = 图像数据生成器(
    重新缩放=1./255，
    旋转范围=40，
    width_shift_range=0.2，
    height_shift_range=0.2，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真，
    fill_mode=&#39;最近&#39;
）

valid_datagen = ImageDataGenerator(重新缩放=1./255)

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

valid_generator = valid_datagen.flow_from_directory(
    有效目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

模型=顺序（[
    输入(形状=(150, 150, 3)),
    Conv2D(32, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    展平（），
    密集（512，激活=&#39;relu&#39;），
    Dense(38,activation=&#39;softmax&#39;) # 根据疾病类别的数量调整输出单位
]）

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=10，
    验证数据=有效生成器，
    valid_steps=valid_generator.samples // 批量大小
）

model.save(&#39;plant_disease_model.h5&#39;)

class_indices = train_generator.class_indices
疾病名称 = 列表(class_indices.keys())
print(“类索引到疾病名称的映射：”, class_indices)

终端：
找到属于 38 个类别的 70295 个图像。
找到属于 38 个类别的 17572 张图像。
2024-04-23 19：50：32.085744：我tensorflow / core / platform / cpu_feature_guard.cc：210]此TensorFlow二进制文件经过优化以使用可用的CPU仪器
性能关键操作中的操作。
要启用以下指令：AVX2 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
纪元 1/10
\.venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.p
y：120：用户警告：您的“PyDataset”类应在其构造函数中调用“super().__init__(**kwargs)”。 `**kwargs` 可以包括 `workers`、`use_m
ultiprocessing`、`max_queue_size`。不要将这些参数传递给“fit()”，因为它们将被忽略。
  self._warn_if_super_not_used()
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m905s←[0m 411ms/步]]准确度：0.4608 - 损失：1.8737 - val_accuracy：0.7432 - val_
损失：0.8556
纪元 2/10
←[1m 1/2196←[0m ←[37m–––––––––––––––––––←[0m ←[1m12:02←[0m 329ms/步 - 精度: 0.6875] -损失：0.78202024-04-23 20:05:37.996528：W张量
ow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束
         [[{{节点It​​eratorGetNext}}]]
C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py:155: UserWarning: 您的输入数据不足；中断训练。嘛
确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次。您可能需要使用`.repeat()`函数
构建您的数据集。
  self.gen.throw（类型，值，回溯）
2024-04-23 20:05:38.068817：W tensorflow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：结束
顺序
         [[{{节点It​​eratorGetNext}}]]
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m0s←[0m 49us/步]]准确度：0.6875 - 损失：0.7820 - val_accuracy：0.7500 - val_los
秒：0.2462

如上所示，epoch 1 已成功完成，但 epoch 2 由于某些错误而终止。同样，epoch 3、5、7、9 成功完成，但 epoch 4、6、8、10 出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</guid>
      <pubDate>Wed, 24 Apr 2024 06:27:20 GMT</pubDate>
    </item>
    <item>
      <title>优化问题的软件方法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78376279/software-approach-for-optimization-problem</link>
      <description><![CDATA[我陷入了优化问题，不知道从哪里着手。这些是问题的条件和整体背景：
我们有一组类型的产品，每种类型都有在生产线上执行的几个步骤。
生产线由7台机器组成
例如，产品可以通过步骤（或机器）编号 1、5 和 7
产品用货车运送到不同的机器上，总共有3辆货车。我根据一些推理确定了货车是这样划分的：货车 1 机器 1 到 5 都包括在内，货车 2 机器 2 到 4 都包括在内，货车 3 机器 5 到 7 都包括在内。货车不能碰撞，每台机器一次只能加工一种产品。机器 1 用于入口，只能通过货车 1 进入，机器 7（出口机器）只能通过货车 3 进入
我们的目标是优化生产，以便一年至少生产 70.000 件。我必须找到不同类型产品进入生产线的顺序（例如：A、D、E、K、 C ....) 使单位总数最大化
产品列表及其必须执行的顺序如下所示：

A 3 7 10
B 3 7 9 10
C 3 7 10
D 3 6 7 10
E 3 6 7 8 9 10
F 3 4 6 7 10
G 3 4 6 7 8 9 10
H 3 4 9 6 9 7 10
我3 4 6 7 10
J 3 4 6 7 8 9 10
K 3 4 6 7 8 9 10
L 3 5 9 6 7 4 5 9 6 9 7 10 
中号3 5 9 6 7 4 5 9 6 9 7 10

我们有在每台机器上花费的时间。
我正在考虑是否使用某种优化，例如杰克逊定律，与优化相关的东西，或者遗传算法，甚至强化学习。你有什么看法？
我正在考虑是否使用某种优化，例如杰克逊定律，与优化相关的东西，或者遗传算法，甚至强化学习。你有什么看法？]]></description>
      <guid>https://stackoverflow.com/questions/78376279/software-approach-for-optimization-problem</guid>
      <pubDate>Wed, 24 Apr 2024 06:08:01 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 的 DDP 在扩散模型训练中的运行时错误</title>
      <link>https://stackoverflow.com/questions/78376085/runtime-error-with-pytorchs-ddp-in-the-diffusion-model-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78376085/runtime-error-with-pytorchs-ddp-in-the-diffusion-model-training</guid>
      <pubDate>Wed, 24 Apr 2024 05:05:11 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 tflite_flutter 包，在将张量图像转换为格式以处理资产中的模型和标签时出现错误</title>
      <link>https://stackoverflow.com/questions/78376014/i-am-using-tflite-flutter-package-and-i-am-getting-error-while-converting-to-ten</link>
      <description><![CDATA[主要问题是将 tflite 模型集成到我的应用程序时。由于我的标签从 0-15，所以我得到的范围错误索引为 16。唯一的问题在于它处理图像并将其转换为张量图像的方式。我只想根据图像与条件匹配的标签显示输出：高度：256，宽度：256，batchSize：32，通道：3，颜色格式：BGR。模型和标签已经存在于资产文件夹中。
我尝试先加载模型和标签，然后将图像转换为张量图像，然后将值传递给模型，模型将返回给定图像的索引，该索引将从标签映射以产生 0-15 及其相应的正确输出价值观。我期待正确的张量图像转换和基于输入给定图像的正确输出。
GitHub 链接]]></description>
      <guid>https://stackoverflow.com/questions/78376014/i-am-using-tflite-flutter-package-and-i-am-getting-error-while-converting-to-ten</guid>
      <pubDate>Wed, 24 Apr 2024 04:39:48 GMT</pubDate>
    </item>
    <item>
      <title>Keras EarlyStopping 回调停止条件？</title>
      <link>https://stackoverflow.com/questions/78375602/keras-earlystopping-callback-stopping-condition</link>
      <description><![CDATA[我正在使用 Keras 提前停止回调，目的是在训练损失连续 10 个时期没有改善时停止训练。我的代码和训练结果如下： 
尽管损失在连续 10 个时期内没有表现出任何改善，但训练似乎还是提前停止了，这就是我对 Keras 文档中 EarlyStopping 如何工作的解释。我是否误解了什么或者我的代码是错误的？]]></description>
      <guid>https://stackoverflow.com/questions/78375602/keras-earlystopping-callback-stopping-condition</guid>
      <pubDate>Wed, 24 Apr 2024 01:37:20 GMT</pubDate>
    </item>
    <item>
      <title>在电价预测神经网络的训练、验证和测试集中分割 3 年每小时数据的好方法是什么？</title>
      <link>https://stackoverflow.com/questions/78375436/what-is-a-good-approach-to-split-3-years-of-hourly-data-in-a-train-validation-a</link>
      <description><![CDATA[我想训练一个简单的神经网络来预测某个地区的电价。然而，我只有“有限”的可用数据（该地区连续 3 年的历史价格、发电量和负荷，间隔 1 小时 - 不允许导入其他数据）。文献建议以 60-20-20、70-15-15 或 80-10-10 的方式拆分以获得训练集、验证集和测试集。分裂“2年、0.5年、0.5年”训练集、验证集和测试集分别将导致 1 月至 6 月期间的超参数优化，并在 7 月至 12 月期间测试模型。直觉上，这对我来说不是一个好方法，因为这会导致验证和测试集中的季节性不匹配。这种直觉是否正确？如果正确，可以采取什么替代方法？
我搜索了很长一段时间，找到了一种名为“滚动交叉验证”的方法，但我不确定这是正确的方法，因为我对神经网络主题还很陌生。]]></description>
      <guid>https://stackoverflow.com/questions/78375436/what-is-a-good-approach-to-split-3-years-of-hourly-data-in-a-train-validation-a</guid>
      <pubDate>Wed, 24 Apr 2024 00:00:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 Vector API 优化 Java 中 int16 向量点积的计算</title>
      <link>https://stackoverflow.com/questions/78375306/optimizing-the-calculation-of-the-dot-product-of-int16-vectors-in-java-using-vec</link>
      <description><![CDATA[TL;DR：使用 Java 的 Vector API 优化 16 位整数数组乘法而不溢出。
我正在尝试优化一个性能关键的循环，该循环应用激活函数并使用 Java 的（正在孵化的）Vector API 计算两个 int16 数组的点积。这是我当前的标量实现：
for (int i = 0; i &lt; HIDDEN_SIZE; i++)
{
    结果 += screlu(us.values[i]) * network.L1Weights[i]
        + screlu(them.values[i]) * network.L1Weights[i + HIDDEN_SIZE];
}

哪里
private static int screlu(短i)
{
    int v = Math.max(0, Math.min(i, QA));
    返回 v * v；
}

我尝试像这样矢量化它：
int[] usValues = new int[HIDDEN_SIZE];
int[] 他们值 = new int[HIDDEN_SIZE];

for (int i = 0; i &lt; HIDDEN_SIZE; i++)
{
    usValues[i] = (int) us.values[i];
    themValues[i] = (int) them.values[i];
}

IntVector sum = IntVector.zero(INT_SPECIES);

for (; i &lt; upperBound; i += INT_SPECIES.length())
{
    IntVector va = IntVector.fromArray(INT_SPECIES, usValues, i);
    IntVector vb = IntVector.fromArray(INT_SPECIES, themValues, i);
    IntVector vc = IntVector.fromArray(INT_SPECIES, network.L1Weights, i);
    IntVector vd = IntVector.fromArray(INT_SPECIES, network.L1Weights, i + HIDDEN_SIZE);

    va = va.max(0).min(QA);
    va = va.mul(va).mul(vc);

    vb = vb.max(0).min(QA);
    vb = vb.mul(vb).mul(vd);

    sum = sum.add(va).add(vb);
}

int 结果 = sum.reduceLanes(VectorOperators.ADD);

由于溢出，我不得不使用 32 位宽的通道，将吞吐量减半。结果，性能仅稍好一些。经过一番研究，我发现 _mm256_madd_epi16 等内在函数完全解决了我的问题，但我在文档中找不到任何有关它的信息。 Vector API 中是否存在等效操作，如果不存在，是否有其他解决方案来解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/78375306/optimizing-the-calculation-of-the-dot-product-of-int16-vectors-in-java-using-vec</guid>
      <pubDate>Tue, 23 Apr 2024 23:01:03 GMT</pubDate>
    </item>
    <item>
      <title>valueerror: 层“model_2”的输入 0 与该层不兼容：预期形状=(none, 128, 128, 3)，发现形状=(1, 224, 224, 3)</title>
      <link>https://stackoverflow.com/questions/78361052/valueerror-input-0-of-layer-model-2-is-incompatible-with-the-layer-expected</link>
      <description><![CDATA[我正在尝试使用 cnn 模型和 Streamlit UI 进行疟疾检测。但它显示“valueerror：层“model_2”的输入0”的错误与层不兼容：预期形状=(无, 128, 128, 3)，发现形状=(1, 224, 224, 3)”用于预测。
错误消息：
ValueError：层“model_2”的输入 0与图层不兼容：预期形状=(无, 128, 128, 3)，发现形状=(1, 224, 224, 3)

回溯：
文件“C:\Users\HP\.conda\envs\DiseasePredictionSystem\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py”，第 584 行，位于 _run_script
    exec（代码，模块.__dict__）
文件“C:\Users\HP\Desktop\多种疾病预测系统\多种疾病pred.py”，第361行，在&lt;模块&gt;中。
    结果 = malaria_model.predict(final_image)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\HP\.conda\envs\DiseasePredictionSystem\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
    从 None 引发 e.with_traceback(filtered_tb)
文件“C:\Users\HP\.conda\envs\DiseasePredictionSystem\Lib\site-packages\keras\src\layers\input_spec.py”，第 245 行，位于assert_input_compatibility 中
    引发值错误（

这是我与 CNN 模型交互的 UI：

这是我用于该项目的 UI 文件。
malaria_model = tf.keras.models.load_model(r&#39;C:\Users\HP\Desktop\多种疾病预测系统\保存的模型\malaria.h5&#39;)
#疟疾预测页面
如果选择==“疟疾疾病预测”：

     ＃页面标题
     st.title(&#39;使用机器学习预测疟疾&#39;)
     
     IMG_大小 = 224
     def resize_rescale(图像):
          返回 tf.image.resize(图像, (IMG_SIZE, IMG_SIZE))/255.0

     uploaded_image = st.file_uploader(&quot;上传图片&quot;, type=[&quot;jpg&quot;, &quot;png&quot;, &quot;jpeg&quot;])

     如果 uploaded_image 不是 None：
    # 显示上传的图片
         st.image（uploaded_image，caption =“上传的图像”，use_column_width = False）
         图像 = Image.open(上传的图像)
    
    # 处理图像（例如，执行图像分析）

     if st.button(“PREDICT”)：
         image_array = tf.keras.preprocessing.image.img_to_array(图像)

    # 将 NumPy 数组转换为 TensorFlow 张量
         张量图像 = tf.convert_to_tensor(image_array)
         张量图像 = tf.expand_dims(张量图像，轴=0)
    
         最终图像=调整大小重新缩放（张量图像）

         结果 = malaria_model.predict(final_image)

         如果结果[0][0] &lt; 0.5：
            st.header(“寄生虫”)
         别的：
            st.header(“未感染”)

这是我用于该项目的参考代码文件：https://github.com/kanchitank/Medibuddy-Smart-Disease-Predictor/blob/main/notebooks/malaria.ipynb]]></description>
      <guid>https://stackoverflow.com/questions/78361052/valueerror-input-0-of-layer-model-2-is-incompatible-with-the-layer-expected</guid>
      <pubDate>Sun, 21 Apr 2024 09:40:42 GMT</pubDate>
    </item>
    <item>
      <title>通过 Keras 训练同时检查不同类型的数据</title>
      <link>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</link>
      <description><![CDATA[在回归任务中，我得到以下数据：

具有已知标签的输入向量。 MSE损失应该用在预测和标签之间。
没有标签的输入向量对，已知模型应给出相似的结果。应在两个预测之间使用 MSE 损失。

同时将这两种数据拟合 Keras 模型的正确方法是什么？
理想情况下，我希望训练循环以交错的方式迭代这两种类型 - 一个有监督的（1）批次，然后是一个自我监督的（2）批次，然后再次监督，等等。
如果重要的话，我正在使用 Jax 后端。 Keras 版本 3.2.1。]]></description>
      <guid>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</guid>
      <pubDate>Thu, 18 Apr 2024 16:05:11 GMT</pubDate>
    </item>
    <item>
      <title>在时间序列 ARIMA 分析中出现错误“TypeError：没有要绘制的数值数据”</title>
      <link>https://stackoverflow.com/questions/78218276/getting-error-typeerror-no-numeric-data-to-plot-in-a-time-series-arima-analys</link>
      <description><![CDATA[我正在尝试遵循一个教程，其中使用差异数据进行 ARIMA 时间序列分析：
以下是python代码：
def 差异（数据集）：
    差异=列表（）
    对于范围内的 i(1, len(数据集))：
        值 = 数据集[i] - 数据集[i - 1]
        diff.append(值)
    返回系列（差异）

系列 = pd.read_csv(&#39;dataset.csv&#39;)
X = series.values # 构建列表的错误可以在这里看到
X = X.astype(&#39;float32&#39;)
平稳 = 差值(X)
固定.索引 = 系列.索引[1:]
...
固定.plot()
pyplot.show()

当过程到达绘图阶段时，我收到错误：
&lt;块引用&gt;
类型错误：没有要绘制的数字数据

回溯起来，我发现正在解析的数据产生了一个数组的集合。将集合stationary保存为*.csv文件会给我一个如下列表：
&lt;前&gt;&lt;代码&gt;[11.]
[0.]
[16.]
[45.]
[27.]
[-141。]
[46]

有人可以告诉我这里出了什么问题吗？
PS。我已经排除了库导入的部分
编辑 1
数据集的一部分复制如下：
年份，观测值
1994,21
1995,62
1996,56
1997,29
1998,38
1999,201
]]></description>
      <guid>https://stackoverflow.com/questions/78218276/getting-error-typeerror-no-numeric-data-to-plot-in-a-time-series-arima-analys</guid>
      <pubDate>Mon, 25 Mar 2024 10:07:18 GMT</pubDate>
    </item>
    <item>
      <title>中途Discord图片上传问题</title>
      <link>https://stackoverflow.com/questions/75265882/midjourney-discord-image-uploading-problem</link>
      <description><![CDATA[无法仅在单个图像提示中使用 --version 4。
请添加另一个图像提示或文本提示。
/想象 https://media.disc/
尝试在旅途中遇到问题时通过链接上传图像]]></description>
      <guid>https://stackoverflow.com/questions/75265882/midjourney-discord-image-uploading-problem</guid>
      <pubDate>Sat, 28 Jan 2023 06:45:19 GMT</pubDate>
    </item>
    <item>
      <title>用于多标签分类的 CLIP</title>
      <link>https://stackoverflow.com/questions/74927358/clip-for-multi-label-classification</link>
      <description><![CDATA[我正在使用 CLIP 来确定单词和图像之间的相似性。
现在我正在使用这个 repo 和以下代码，对于分类它给出了很好的结果。我需要它来进行多标签分类，其中我需要使用 sigmoid 而不是 softmax。
导入火炬
从 PIL 导入图像
导入 open_clip

模型, _, 预处理 = open_clip.create_model_and_transforms(&#39;ViT-B-32-quickgelu&#39;, pretrained=&#39;laion400m_e32&#39;)
tokenizer = open_clip.get_tokenizer(&#39;ViT-B-32-quickgelu&#39;)

图像 = 预处理(Image.open(&quot;CLIP.png&quot;)).unsqueeze(0)
text = tokenizer([“图表”, “一只狗”, “一只猫”])

与 torch.no_grad(), torch.cuda.amp.autocast():
    image_features = model.encode_image(图像)
    text_features = model.encode_text(text)
    image_features /= image_features.norm(dim=-1, keepdim=True)
    text_features /= text_features.norm(dim=-1, keepdim=True)

    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)

print(“标签概率：”, text_probs) # 打印：[[1., 0., 0.]]

现在我想将它用于多类别。例如，如果我们有图像狗和猫，我希望两者都有很高的概率，所以我需要用 sigmoid 运行它。但这给我的结果都是 0.55 左右，正确的类别是 0.56，错误的类别是 0.54，所以像这样的 [0.54, 0.555, 0.56]。我希望在使用 sigmoid 后得到类似 [0.01, 0.98, 0.99] 的结果。
我在那里做错了什么？我怎样才能得到我想要的结果？]]></description>
      <guid>https://stackoverflow.com/questions/74927358/clip-for-multi-label-classification</guid>
      <pubDate>Tue, 27 Dec 2022 08:56:22 GMT</pubDate>
    </item>
    </channel>
</rss>