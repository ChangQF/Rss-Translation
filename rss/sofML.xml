<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Apr 2024 15:14:20 GMT</lastBuildDate>
    <item>
      <title>如何对机器学习项目进行建模？</title>
      <link>https://stackoverflow.com/questions/78311330/how-to-model-a-machine-learning-project</link>
      <description><![CDATA[我有 200 个不同的传感器，有 3 种测量原理。这些可以概括如下：

&lt;标题&gt;

传感器类型
测量类型 1
测量类型 2
测量类型 3


&lt;正文&gt;

类型 1
1.1
2.1
3.1


类型 2
1.2
2.2
3.2


...
...
...
...



输出要求：整体传感器状态（好/绿，坏/红，好/黄）
应该如何开始这样一个机器学习项目。
需要考虑的一些注意事项：

没有基本事实
每种测量类型都有阈值

每种传感器类型对于每种测量类型都有不同的阈值
所有测量结果都是时间序列表格数据

感谢任何帮助:)]]></description>
      <guid>https://stackoverflow.com/questions/78311330/how-to-model-a-machine-learning-project</guid>
      <pubDate>Thu, 11 Apr 2024 15:04:54 GMT</pubDate>
    </item>
    <item>
      <title>具有多输出回归和自定义损失函数的 LightGBM</title>
      <link>https://stackoverflow.com/questions/78310990/lightgbm-with-multi-output-regression-and-custom-loss-function</link>
      <description><![CDATA[有人知道我是否可以将 LightGBM 与多输出回归以及自定义损失函数一起使用。
问题是我必须使用 LightGBM。如有帮助，将不胜感激。
提前致谢。
我知道我可以使用 sklearn 的 MultiOutputRegression 来包装 LightGBM，但这不允许我定义自定义损失函数，因为我可以使用 Keras 来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78310990/lightgbm-with-multi-output-regression-and-custom-loss-function</guid>
      <pubDate>Thu, 11 Apr 2024 14:15:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么模型的准确率没有论文建议的那么高？</title>
      <link>https://stackoverflow.com/questions/78310497/why-is-the-accuracy-of-the-model-not-as-high-as-the-paper-suggests</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78310497/why-is-the-accuracy-of-the-model-not-as-high-as-the-paper-suggests</guid>
      <pubDate>Thu, 11 Apr 2024 12:58:38 GMT</pubDate>
    </item>
    <item>
      <title>迄今为止，哪种图像去雾模型最好？当对真实数据进行训练时，所有在线可用的模型都会给出丑陋的结果</title>
      <link>https://stackoverflow.com/questions/78310078/which-is-the-best-model-for-image-dehazing-till-now-when-train-on-real-data-all</link>
      <description><![CDATA[目前用于图像去雾的最佳模型或算法是什么？据我研究（从性能指标），我了解到 GMAN 架构具有最高的准确性。但我想提高模型的准确性。
我也尝试实现一些架构和 GAN，但到目前为止，我仅在 GMAN 中获得最高的准确度，但在真实数据图像上进行测试时，它没有给我正确的图像。
边缘的颜色正在扩散，模型也扰乱了天空（大气图像）]]></description>
      <guid>https://stackoverflow.com/questions/78310078/which-is-the-best-model-for-image-dehazing-till-now-when-train-on-real-data-all</guid>
      <pubDate>Thu, 11 Apr 2024 11:41:10 GMT</pubDate>
    </item>
    <item>
      <title>如何标准化输出数据</title>
      <link>https://stackoverflow.com/questions/78308791/how-can-i-normalize-the-output-data</link>
      <description><![CDATA[在他的 Flutter 项目中使用 TensorFlowLite 来查找脸上的点。输出如下所示：
模型输出
如何将这些数据转换为坐标？]]></description>
      <guid>https://stackoverflow.com/questions/78308791/how-can-i-normalize-the-output-data</guid>
      <pubDate>Thu, 11 Apr 2024 07:31:57 GMT</pubDate>
    </item>
    <item>
      <title>PyCaret Predict_model 数据集兼容性</title>
      <link>https://stackoverflow.com/questions/78308672/pycaret-predict-model-dataset-compatibility</link>
      <description><![CDATA[我正在尝试使用 pycaret 使用看不见的数据来预测分数。我确信我看不见的数据框具有模型中包含的所有功能，但我仍然收到此错误：
CatBoostError：catboost/libs/data/model_dataset_compatibility.cpp:81：位置 1 应该是名为 Customer_Acct 的功能（找到 Pay_Acct）

我在看不见的数据框中都有这两列。
当我使用 model.features_names_in_ 检查时，我发现这两个特征都在模型中，所以我不知道问题是什么。
我尝试交换两列的位置，但没有成功。我也尝试删除任一列，但随后遇到了不同的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78308672/pycaret-predict-model-dataset-compatibility</guid>
      <pubDate>Thu, 11 Apr 2024 07:07:14 GMT</pubDate>
    </item>
    <item>
      <title>Numpy reshape() 以编程方式以 3D 形式显示 2D 数组</title>
      <link>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</link>
      <description><![CDATA[示例数据
我有一系列经纬度的天气数据，其形状如下：(1038240,4)（有关示例数据，请参阅照片）
我想将其重塑为形状 (4,721,1440)，这将是 721 x 1440 地球图像上的四个天气变量（&amp; lat/lon）。
我已经尝试过：
newarr = t_new.reshape(4,721,1440)

这会将其置于正确的形状，但与前两个纬度/经度坐标与以下首选格式不匹配：
对于上图中的 (6,4) 示例数据，此操作看起来像下面的 (2,3,2) 数组：
所需输出示例
newarr = t_new.reshape(4,721,1440)
]]></description>
      <guid>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</guid>
      <pubDate>Thu, 11 Apr 2024 06:06:56 GMT</pubDate>
    </item>
    <item>
      <title>将手写数学方程解析为字符串/数值</title>
      <link>https://stackoverflow.com/questions/78307038/parse-handwritten-math-equation-to-string-numerical-value</link>
      <description><![CDATA[我有这个图像，我需要在Python中解决。它非常像手写数字，我需要将图像解析为字符串，甚至更好，对其求值并获取该表达式或与此类似的表达式的结果。
有什么方法可以至少半可靠地做到这一点吗？阅读它需要使用大量手写字符进行机器学习，但我无法理解它是如何工作的。我也希望它能够相当快地解析图像，但我不介意用数据训练我的模型，无论它在实际识别数字之前需要训练多长时间。
感谢任何帮助，提前致谢！
我尝试过超正方体，但它只能从该图像中检测到 4 和 5，因为我认为这些图像是不整洁和草率的，即使在将其转换为黑白并增强对比度等之后也是如此。]]></description>
      <guid>https://stackoverflow.com/questions/78307038/parse-handwritten-math-equation-to-string-numerical-value</guid>
      <pubDate>Wed, 10 Apr 2024 20:44:13 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：“模型”层的输入 0 与该层不兼容：预期形状=（无，64，32，1），发现形状=（32，32，1）</title>
      <link>https://stackoverflow.com/questions/78301623/valueerror-input-0-of-layer-model-is-incompatible-with-the-layer-expected-sh</link>
      <description><![CDATA[我尝试调试并添加了打印语句，令我惊讶的是它的形状是正确的，但程序说它的形状不正确
形状：（无、64、32、1）
型号：“型号”
_________________________________________________________________
 层（类型）输出形状参数#
=================================================== ===============
 图像（输入层）[(无, 64, 32, 1)] 0

 Conv1 (Conv2D)（无、64、32、32）320

 pool1 (MaxPooling2D)（无、32、16、32）0

 批量归一化（BatchN（无，32,16,32）128
 正规化）

 重塑（重塑）（无、32、512）0

 密集2（密集）（无、32、16）8208

 batch_normalization_1 (Batc (无, 32, 16) 64
 h归一化）

 双向（Bidirectiona（无、32、256）148480
 l)

 密集3（密集）（无、32、42）10794

=================================================== ===============
总参数：167,994
可训练参数：167,898
不可训练参数：96
_________________________________________________________________
没有任何
输入形状：(64,32,1)
**回溯（最近一次调用最后一次）：
  文件“D:\Arabic-Handwriting-OCR\Arabic-Handwriting-OCR\inference.py”，第156行，在&lt;模块&gt;中。
    preds = Prediction_model.predict(batch_images)
  文件“C:\Users\User\miniconda3\envs\tf\lib\site-packages\keras\utils\traceback_utils.py”，第 70 行，位于 error_handler 中
    从 None 引发 e.with_traceback(filtered_tb)
  文件“C:\Users\User\AppData\Local\Temp\__autograph_ generated_file42woagrz.py”，第 15 行，位于 tf__predict_function 中
    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)
ValueError：在用户代码中：ValueError：层“模型”的输入 0与图层不兼容：预期形状=(None, 64, 32, 1)，发现形状=(32, 32, 1)**

我尝试检查模型输入的形状，它的字面意思是 (64, 32, 1)，但回溯显示找到的形状=(32,32,1)，为什么呢？我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78301623/valueerror-input-0-of-layer-model-is-incompatible-with-the-layer-expected-sh</guid>
      <pubDate>Wed, 10 Apr 2024 00:15:22 GMT</pubDate>
    </item>
    <item>
      <title>如何将段落拆分成没有标点符号（包括句号、逗号等）的句子</title>
      <link>https://stackoverflow.com/questions/78290380/how-to-split-a-paragraph-into-sentences-where-there-is-no-punctuation-including</link>
      <description><![CDATA[我想将段落分成没有标点符号的句子，包括句号、逗号等。
例如：“我叫 Brayan，今年 12 岁”
需要拆分为
我叫布雷扬
我今年12岁了
我尝试过 Spacy 和 NLTK 库。但无法达到这个结果。]]></description>
      <guid>https://stackoverflow.com/questions/78290380/how-to-split-a-paragraph-into-sentences-where-there-is-no-punctuation-including</guid>
      <pubDate>Mon, 08 Apr 2024 05:35:18 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：“GraphModule”对象不可下标（Pytorch 中 .onnx ML 模型的访问权重）</title>
      <link>https://stackoverflow.com/questions/78289901/typeerror-graphmodule-object-is-not-subscriptable-access-weights-for-onnx-m</link>
      <description><![CDATA[我有一个流行的 .onnx ML 天气预报模型，我正在尝试将其转换为 PyTorch 进行微调。我使用以下代码来转换它：
导入操作系统
将 numpy 导入为 np
导入onnx
从 onnx 导入 numpy_helper
将 onnxruntime 导入为 ort
从 onnx2torch 导入 转换

model_24 = onnx.load(&#39;pangu_weather_24.onnx&#39;)
tm = Convert(model_24) #将onnx模型转换为torch

从这里，我想访问“tm”对象中模型的权重，但我似乎无法在网上找到任何相关资源。
尝试使用 tm[0] 对其进行下标会显示以下错误：
TypeError：“GraphModule”对象不可下标

通过“tm.dict”获取该对象的字典更加令人困惑（粘贴在图像中）。
在线访问 PyTorch 权重矩阵的常规方法也显示出图形模块不可下标的相同错误]]></description>
      <guid>https://stackoverflow.com/questions/78289901/typeerror-graphmodule-object-is-not-subscriptable-access-weights-for-onnx-m</guid>
      <pubDate>Mon, 08 Apr 2024 02:13:29 GMT</pubDate>
    </item>
    <item>
      <title>Unity barracuda，用于实现 onnx 模型的张量</title>
      <link>https://stackoverflow.com/questions/78010709/unity-barracuda-tensor-to-implement-an-onnx-model</link>
      <description><![CDATA[张量 inputTensor = new Tensor(1, 30 * 258, 30*258, 1, keypointsSequence.ToArray());

我需要使梭子鱼张量适用于接收尺寸 (1, 30, 258) 作为输入的 onnx 模型，我不知道为什么它不给我并且会生成错误。
我也在使用barracuda，除此之外它还告诉我输入是错误的并给我带来了以下问题：
AssertionException：断言失败。价值观并不相等。
预计：258 == 7740
UnityEngine.Assertions.Assert.Fail（System.String 消息、System.String userMessage）（位于 &lt;30adf90198bc4c4b83910c6fb1877998&gt;:0）
UnityEngine.Assertions.Assert.AreEqual[T]（T 预期、T 实际、System.String 消息、System.Collections.Generic.IEqualityComparer`1[T] 比较器）（位于 &lt;30adf90198bc4c4b83910c6fb1877998&gt;:0）
UnityEngine.Assertions.Assert.AreEqual[T]（T 预期，T 实际，System.String 消息）（位于 &lt;30adf90198bc4c4b83910c6fb1877998&gt;:0）
UnityEngine.Assertions.Assert.AreEqual（预期为 System.Int32，实际为 System.Int32）（位于 &lt;30adf90198bc4c4b83910c6fb1877998&gt;:0）
Unity.Barracuda.ComputeOps.Dense（Unity.Barracuda.Tensor X、Unity.Barracuda.Tensor W、Unity.Barracuda.Tensor B、Unity.Barracuda.Layer+FusedActivation fusedActivation）（位于 ./Library/PackageCache/com.unity。 barracuda@3.0.0/Barracuda/Runtime/Core/Backends/BarracudaCompute.cs:1177)
Unity.Barracuda.PrecompiledComputeOps.Dense（Unity.Barracuda.Tensor X、Unity.Barracuda.Tensor W、Unity.Barracuda.Tensor B、Unity.Barracuda.Layer+FusedActivation fusedActivation）（位于 ./Library/PackageCache/com.unity. barracuda@3.0.0/Barracuda/Runtime/Core/Backends/BarracudaPrecompiledCompute.cs:931)
Unity.Barracuda.ComputeOps.MatMul（Unity.Barracuda.Tensor X、System.Boolean xTranspose、Unity.Barracuda.Tensor Y、System.Boolean yTranspose）（位于 ./Library/PackageCache/com.unity.barracuda@3.0.0/梭子鱼/运行时/核心/后端/BarracudaCompute.cs:1125)
Unity.Barracuda.ReferenceCPUOps.LSTM（Unity.Barracuda.Tensor X、Unity.Barracuda.Tensor[] W、Unity.Barracuda.Tensor[] R、Unity.Barracuda.Tensor[] Wb、Unity.Barracuda.Tensor[] Rb ，Unity.Barracuda.Tensor隐藏，Unity.Barracuda.Tensor单元）（位于./Library/PackageCache/com.unity.barracuda@3.0.0/Barracuda/Runtime/Core/Backends/BarracudaReferenceCPU.cs:3713）
Unity.Barracuda.StatsOps.LSTM（Unity.Barracuda.Tensor X、Unity.Barracuda.Tensor[] W、Unity.Barracuda.Tensor[] R、Unity.Barracuda.Tensor[] Wb、Unity.Barracuda.Tensor[] Rb ，Unity.Barracuda.Tensor隐藏，Unity.Barracuda.Tensor单元）（位于./Library/PackageCache/com.unity.barracuda@3.0.0/Barracuda/Runtime/Core/Backends/StatsOps.cs:1047）
Unity.Barracuda.GenericWorker+d__36.MoveNext () （位于 ./Library/PackageCache/com.unity.barracuda@3.0.0/Barracuda/Runtime/Core/Backends/GenericWorker.cs:1018）
Unity.Barracuda.GenericWorker.Execute（）（位于./Library/PackageCache/com.unity.barracuda@3.0.0/Barracuda/Runtime/Core/Backends/GenericWorker.cs:187）
Unity.Barracuda.GenericWorker.Execute（Unity.Barracuda.Tensor 输入）（位于 ./Library/PackageCache/com.unity.barracuda@3.0.0/Barracuda/Runtime/Core/Backends/GenericWorker.cs:179）
script.DoInference（Unity.Barracuda.Tensor inputTensor）（位于 Assets/Scripts/script.cs:190）
script+d__9.MoveNext ()（位于 Assets/Scripts/script.cs:172）
UnityEngine.SetupCoroutine.InvokeMoveNext（System.Collections.IEnumerator 枚举器，System.IntPtr returnValueAddress）（位于 &lt;30adf90198bc4c4b83910c6fb1877998&gt;:0）
UnityEngine.MonoBehaviour:StartCoroutine(IEnumerator)
Visuallizer:LateUpdate()（位于 Assets/Scripts/Visuallizer.cs:54）
]]></description>
      <guid>https://stackoverflow.com/questions/78010709/unity-barracuda-tensor-to-implement-an-onnx-model</guid>
      <pubDate>Sat, 17 Feb 2024 01:51:22 GMT</pubDate>
    </item>
    <item>
      <title>在 Kaggle 上进行模型训练时如何使用多个 GPU</title>
      <link>https://stackoverflow.com/questions/77694839/how-can-i-use-multiple-gpus-during-model-training-on-kaggle</link>
      <description><![CDATA[在 Kaggle 上，我有 2 个 GPU T4，但我不明白如何在 Pytorch 中使用它们或调整代码以在 2 个 GPU 上进行训练
2 个 GPU 的图片
我的训练代码：
对于范围（2）中的纪元：

    运行损失 = 0.0
    对于 tqdm（数据集）中的数据：
        输入，标签=数据
        优化器.zero_grad()
        输出 = 模型（输入）
        损失=标准（输出，标签）
        loss.backward()
        优化器.step()

        running_loss += loss.item()
]]></description>
      <guid>https://stackoverflow.com/questions/77694839/how-can-i-use-multiple-gpus-during-model-training-on-kaggle</guid>
      <pubDate>Wed, 20 Dec 2023 22:41:19 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“layoutlm”导入名称“LayoutlmConfig”</title>
      <link>https://stackoverflow.com/questions/72480985/importerror-cannot-import-name-layoutlmconfig-from-layoutlm</link>
      <description><![CDATA[我正在尝试保存 LayoutLM 模型的预测。
论文 - https://arxiv.org/abs/1912.13318
笔记本 - https://www.kaggle .com/code/iamarjunchandra/layoutlm-document-sequence-labeling-model/notebook
当我运行以下代码进行预测时出现问题
！ python unilm/layoutlm/examples/seq_labeling/run_seq_labeling.py
                               --do_predict
                               --data_dir 数据
                               --model_type布局lm
                               --模型名称或路径输出
                               --output_dir 输出
                               --标签数据/labels.txt \
                               --fp16

我收到以下错误。
回溯（最近一次调用最后一次）：
  文件“unilm\\layoutlm\\examples\\seq_labeling\\run_seq_labeling.py”，第53行，在&lt;module&gt;中。
    从layoutlm导入FunsdDataset、LayoutlmConfig、LayoutlmForTokenClassification
ImportError：无法从“layoutlm”导入名称“LayoutlmConfig”(c:\Users\jyoti\anaconda3\lib\site-packages\layoutlm\__init__.py)
]]></description>
      <guid>https://stackoverflow.com/questions/72480985/importerror-cannot-import-name-layoutlmconfig-from-layoutlm</guid>
      <pubDate>Thu, 02 Jun 2022 18:47:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sklearn 中的岭和套索回归需要 random_state？</title>
      <link>https://stackoverflow.com/questions/48909927/why-is-random-state-required-for-ridge-lasso-regression-in-sklearn</link>
      <description><![CDATA[在 scikit-learn 中，Lasso 和 Ridge 回归是两种具有 random_state 属性的回归方法。为什么这两个方法需要这个属性？
来自文档：
class sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001 ，warm_start = False，positive = False，random_state =无，selection =&#39;循环&#39;）


sklearn. Linear_model.Ridge 类（alpha=1.0，fit_intercept=True，normalize=False，copy_X=True，max_iter=None，tol=0.001，solver=&#39;auto&#39;，random_state=None）
]]></description>
      <guid>https://stackoverflow.com/questions/48909927/why-is-random-state-required-for-ridge-lasso-regression-in-sklearn</guid>
      <pubDate>Wed, 21 Feb 2018 15:43:31 GMT</pubDate>
    </item>
    </channel>
</rss>