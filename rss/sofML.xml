<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 21 Jul 2024 15:16:01 GMT</lastBuildDate>
    <item>
      <title>哪里可以最好地学习深度学习的 MLX？</title>
      <link>https://stackoverflow.com/questions/78775410/where-to-best-learn-mlx-for-deep-learning</link>
      <description><![CDATA[我仍在参加在线培训课程，以学习深度学习，正如你们所知，我还有很多其他东西要学。
但作为 MacOS 的粉丝，我希望能够使用 Apple 的 MLX，我相信这是一个非常好的模型模拟框架，许多人都说这是深度学习工程和研究中非常重要的一步。
有人能给我指出一个好的资源来学习 MLX 框架吗？我在网上找到了非常基础且不太详细的训练营，但 MLX 似乎比任何这些资源愿意分享的都要完整得多。
PyTorch、Keras 和 TensorFlow 在网上都面临相同的基本介绍，但由于它们更受欢迎，因此也不难找到比大多数课程更深入的在线培训课程。
我希望有人可以帮助我，如果您有任何意见或建议，我会非常乐意听到并向大家学习。
谢谢，
Alexandre。
我试图在网上找到好的、深入的培训课程，通过Coursera 或 Udemy 以及 Medium 和 YouTube 等网站，但每门课程都只向学习者介绍非常基础的深度学习和机器学习 MLX 功能。]]></description>
      <guid>https://stackoverflow.com/questions/78775410/where-to-best-learn-mlx-for-deep-learning</guid>
      <pubDate>Sun, 21 Jul 2024 14:06:48 GMT</pubDate>
    </item>
    <item>
      <title>时间序列模型中的极端 RMSE 验证分数</title>
      <link>https://stackoverflow.com/questions/78775154/extreme-rmse-validation-score-in-time-series-model</link>
      <description><![CDATA[我有一个包含每小时数据的数据集，有 4000 行和 3 个数字列。它没有明显的趋势或季节性。我在下面分享了 stl 分解图以及一个目标列的原始线图。
这是一列目标的图表
我使用此代码进行训练：
tscv = TimeSeriesSplit(n_splits=5,gap=24)
train_rmse_scores = []
val_rmse_scores = []

for fold, (train_index, test_index) in enumerate(tscv.split(melen_forecast_df), start=1):
train_df, test_df = melen_forecast_df.iloc[train_index], melen_forecast_df.iloc[test_index]

# 仅使用训练集创建特征
X_train = create_all_features(train_df)
y_train = train_df[targets]

# 为测试集创建特征
X_test = create_all_features(test_df)
y_test = test_df[targets]

X_train = X_train.iloc[4:]
y_train = y_train.iloc[4:]
X_test = X_test.iloc[4:]
y_test = y_test.iloc[4:]

print(f&quot;Fold {fold} - 训练数据形状：{X_train.shape}, 验证数据形状：{X_test.shape}&quot;)

model = MultiOutputRegressor(xgb.XGBRegressor(objective=&#39;reg:squarederror&#39;,n_estimators=500,learning_rate=0.015))
# 训练模型
model.fit(X_train, y_train)

# 预测并计算训练集的 RMSE
y_train_pred = model.predict(X_train)
train_rmse_per_target = [np.sqrt(mean_squared_error(y_train.iloc[:, i], y_train_pred[:, i])) 
for i in range(y_train.shape[1])]
train_rmse_scores.append(train_rmse_per_target)

for i, rmse in enumerate(train_rmse_per_target, start=1):
print(f&quot;Fold {fold} - Training Target {i} RMSE: {rmse:.4f}&quot;)

# 预测并计算验证集的 RMSE
y_pred = model.predict(X_test)
val_rmse_per_target = [np.sqrt(mean_squared_error(y_test.iloc[:, i], y_pred[:, i])) 
for i in range(y_test.shape[1])]
val_rmse_scores.append(val_rmse_per_target)

for i, rmse in enumerate(val_rmse_per_target, start=1):
print(f&quot;Fold {fold} - Validation Target {i} RMSE: {rmse:.4f}&quot;)

# 计算并打印所有折叠的平均 RMSE
avg_train_rmse = np.mean(train_rmse_scores, axis=0)
avg_val_rmse = np.mean(val_rmse_scores, axis=0)

我正在尝试使用 MultiOutputRegressor 训练这 3 个目标列，包装XGBoostRegressor。我的问题是 RMSE 分数对于训练和验证来说都太高了。即使使用 optuna 调整超参数后，效果似乎也不好。我甚至看到验证 RMSE 等于 7000。此时我无法确定我的模型是过度拟合还是欠拟合，因为如果我开始使用基本特征进行训练，我的验证分数会从非常高的验证 RMSE 开始，然后继续下去。我想我在某个时候犯了严重的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78775154/extreme-rmse-validation-score-in-time-series-model</guid>
      <pubDate>Sun, 21 Jul 2024 12:14:40 GMT</pubDate>
    </item>
    <item>
      <title>我正在进行多类分类，但是在如何通过参数调整进行特征和模型选择方面遇到了困难</title>
      <link>https://stackoverflow.com/questions/78775112/i-am-doing-multiclass-classification-but-i-am-having-hard-time-with-how-to-do-t</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78775112/i-am-doing-multiclass-classification-but-i-am-having-hard-time-with-how-to-do-t</guid>
      <pubDate>Sun, 21 Jul 2024 11:54:53 GMT</pubDate>
    </item>
    <item>
      <title>尽管训练准确率很高，Transformer 模型在推理过程中仍重复相同的密码子</title>
      <link>https://stackoverflow.com/questions/78775009/transformer-model-repeating-same-codon-during-inference-despite-high-training-ac</link>
      <description><![CDATA[我正在开发一个基于转换器的模型，将氨基酸转化为密码子。在训练和验证过程中，我的模型的准确率达到了 95-98%。然而，在推理过程中，我遇到了一个问题，即输出序列由一遍又一遍重复的相同密码子组成，如下所示：
gcc gcc gcc gcc gcc gcc gcc gcc gcc gcc gcc gcc ...
这是我的推理代码：
定义推理函数
def infer(model, path_infer, start_token_id=2, output_level=&#39;DNA&#39;): 
if output_level == &#39;DNA&#39;:
tokenizer = Tokenizer.from_file(tokenizer_DNAfile)
else:
tokenizer = Tokenizer.from_file(tokenizer_RNAfile)
model.eval()
infer_data = s.fasta_to_list(path_infer, seq_to_codon=False, Separate_aa=True, sos_eos=False)
fast_tokenizer = PreTrainedTokenizerFast(tokenizer_file=tokenizer_AAfile)
src = fast_tokenizer.encode(infer_data[0], padding=&#39;max_length&#39;, return_tensors=&quot;pt&quot;, max_length=config[&#39;input_length&#39;])
max_length = torch.count_nonzero(src).item()

使用 torch.no_grad():
src_embed = model.src_embedding(src)
memory = model.encoder(src_embed)
tgt_input = torch.LongTensor([[start_token_id]])
output_sequence = [start_token_id]

for _ in range(max_length):
tgt_embed = model.tgt_embedding(tgt_input)
coder_output = model.decoder(memory, tgt_embed)
output_logits = model.fc_out(decoder_output[:, -1, :])
next_token = output_logits.argmax(dim=-1).item()
output_sequence.append(next_token)
tgt_input = torch.cat((tgt_input, torch.LongTensor([[next_token]])), dim=1)

return tokenizer.decode(output_sequence[1:], skip_special_tokens=True)

loading_path = os.path.join(checkpoint_dir, config[&#39;model_name&#39;])
model.load_checkpoint(loading_path, model, optimizer)
z = infer(model, path_infer)
print(z)

详细信息：

框架： PyTorch

模型：Transformer

Tokenizer：用于氨基酸的 PreTrainedTokenizerFast，用于 DNA/RNA 的自定义 tokenizer

训练准确率：95-98%

推理输出：重复序列（例如，“gcc gcc gcc...”）


我已采取的步骤：

检查训练和验证阶段：该模型表现良好，准确率高。

检查推理代码：确保它遵循标准 Transformer 推理实践。


问题：
在推理过程中，模型输出重复的密码子，这是在训练和验证期间的高精度下不期望的。
问题：

什么可能导致模型在推理过程中生成重复序列？

Transformer 推理中是否存在可能导致此行为的常见陷阱？

我如何修改推理函数以解决此问题？


其他信息：

使用 argmax 进行下一个标记选择。

模型已正确加载并设置为评估模式。


任何见解或建议都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78775009/transformer-model-repeating-same-codon-during-inference-despite-high-training-ac</guid>
      <pubDate>Sun, 21 Jul 2024 11:06:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在 8 个 GPU 上并行化机器翻译的 Transformer 模型？</title>
      <link>https://stackoverflow.com/questions/78774602/how-to-parallelize-transformer-model-for-machine-translation-on-8-gpus</link>
      <description><![CDATA[我正尝试使用 transformer 模型以与原始文章几乎相同的方式执行机器翻译。虽然该模型运行良好，但它需要更大的计算资源。为了解决这个问题，我在一台有 8 个 GPU 处理器的计算机上运行了该模型，但我缺乏这方面的经验。
我尝试对并行化进行必要的调整：
transformer = nn.DataParallel(transformer)
transformer = transformer.to(DEVICE)

然而，由于我缺乏经验，事情进展不顺利。具体来说，我在以下错误消息上停留了很长时间：
File &quot;C:\Projects\MT005\.venv\Lib\site-packages\torch\nn\ functional.py&quot;, line 5382, 
in multi_head_attention_forward raise RuntimeError(f&quot;2D attn_mask 的形状是 {attn_mask.shape}，但应该是 {correct_2d_size}。&quot;) 
RuntimeError: 2D attn_mask 的形状是 torch.Size([8, 64])，但应该是 (4, 4)。

有人能帮我解决这个问题并让模型在所有 8 个 GPU 上运行吗？]]></description>
      <guid>https://stackoverflow.com/questions/78774602/how-to-parallelize-transformer-model-for-machine-translation-on-8-gpus</guid>
      <pubDate>Sun, 21 Jul 2024 07:14:42 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证函数返回“未知标签类型：（array（[0.0, 1.0]，dtype = object），）”</title>
      <link>https://stackoverflow.com/questions/78773942/cross-validation-function-returns-unknown-label-type-array0-0-1-0-dtype</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78773942/cross-validation-function-returns-unknown-label-type-array0-0-1-0-dtype</guid>
      <pubDate>Sat, 20 Jul 2024 21:29:48 GMT</pubDate>
    </item>
    <item>
      <title>你知道 iOS 是否有用于模糊图像中人脸和裸露部分的库吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78773917/do-you-know-if-there-are-libraries-for-blurring-faces-and-nudity-in-images-for-i</link>
      <description><![CDATA[我正在寻找一个库或 ML 模型，可用于模糊图像中存在的面部和裸体。您对此类库或模型有什么建议吗？
或者您将如何为此目的训练 ML 模型？我对 ML 还很陌生，因此如果我必须创建自己的 ML 模型或库，我将非常感激示例和教程。
提前感谢您的任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/78773917/do-you-know-if-there-are-libraries-for-blurring-faces-and-nudity-in-images-for-i</guid>
      <pubDate>Sat, 20 Jul 2024 21:07:35 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习方法检测玩具车中的未知缺陷</title>
      <link>https://stackoverflow.com/questions/78773870/detecting-unknown-defects-in-toy-car-using-deep-learning-methods</link>
      <description><![CDATA[问题：
我们需要根据玩具车图片判断汽车是否有缺陷。我们没有缺陷汽车的图片，也无法提前知道这些汽车可能存在哪些缺陷。
我们可以使用各种技巧拍摄数千张完好无损的汽车照片。此外，我们还可以自动拍摄数千/数万张汽车 CAD 图像快照。
我尝试过的方法：

在传统方法中，我尝试过 OpenCV，但它对所有事物都过于敏感，而且只能应用于以完全相同方式拍摄的两张照片。 :(

Siamese Network 和 Sentence Transformers（余弦相似度等...）也不适合，因为它们对摄影产生的差异很敏感。 :(

Autoencoder 有两种不同的方法：

3.1. 我用基于 CAD 的快照训练了一个自动编码器，然后在真实的有缺陷和无缺陷的图像上对其进行了测试，根据这些重建误差的分布从两个方向切断异常值。这个想法来自这里：https://github.com/sohamk10/Image-reconstruction-and-Anomaly-detection。不是很好解决方案。

3.2. 我用原始照片（大约 10,000 张照片，仅从一个视角拍摄）创建了一个自动编码器模型，其中解码器部分是从 ResNet50 拍摄（并冻结）的，我只训练了编码器部分。我也尝试了其他模型（MobileNetV3、EfficientNet-B3）。结果非常令人满意：它根据重建误差独立于照片环境识别训练过的对象，但它也将那些有轻微缺陷的对象识别为好对象，而它不应该这样做。



YOLO v7：产生与上一点（3.2.）中提到的自动编码器类似的结果。因此，它识别了物体，但不幸的是，它也会识别有缺陷的物体。


如何使用人工智能甚至不使用人工智能来解决这个业余项目问题？
如何修改第 3.2 点中提到的自动编码器。以在训练期间提供较低的 loss 和 val_loss 值（目前约为 0.6，但在 MNIST 数据集上为 0.02...）？]]></description>
      <guid>https://stackoverflow.com/questions/78773870/detecting-unknown-defects-in-toy-car-using-deep-learning-methods</guid>
      <pubDate>Sat, 20 Jul 2024 20:36:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么我通过 Mediapipe Model Maker 训练制作的自定义模型会将人检测为我的对象？</title>
      <link>https://stackoverflow.com/questions/78773679/why-does-my-custom-model-made-by-training-through-mediapipe-model-maker-detect-p</link>
      <description><![CDATA[所以我有一个想要检测的软玩具。我使用 Mediapipe Model Maker 对大约 100 张图像进行了训练。结果还不错。该模型大多数时候都能从正面识别我的玩具。但问题是，它似乎认为任何人（人的侧面或正面）都是我的玩具，而且比例很高（比如 &gt;90%）。
我不明白为什么会发生这种情况，我该怎么做才能微调我的模型，以便它不会将人检测为我的玩具。我已将我的玩具和检测示例的图像附在下面。

]]></description>
      <guid>https://stackoverflow.com/questions/78773679/why-does-my-custom-model-made-by-training-through-mediapipe-model-maker-detect-p</guid>
      <pubDate>Sat, 20 Jul 2024 19:04:20 GMT</pubDate>
    </item>
    <item>
      <title>将三个经过训练的二分类模型组合成 Keras 中的单个多分类模型</title>
      <link>https://stackoverflow.com/questions/78773489/combine-three-trained-binary-classification-models-into-single-multiclassificati</link>
      <description><![CDATA[我有三个经过训练的二分类模型，它们在输出层使用 Sigmoid 激活函数进行训练。

第一个模型返回从 0 到 1 的概率标量，以检查图像是否为数字 ZERO。
第二个模型返回从 0 到 1 的概率标量，以检查图像是否为数字 ONE。
第三个模型返回从 0 到 1 的概率标量，以检查图像是否为数字 TWO。


我知道我可以使用 softmax 训练它们，在输出层构建三个神经元的模型。但假设我遇到一种情况，由于模型复杂，训练它们的权重确实需要很长时间，我只有它们各自的二分类模型。或者，我想提取它们在隐藏层的隐藏表示特征，例如 model_0（二分类检查图像是否为零）。
那么，如何将它们连接/组合/合并为单个模型？
我的代码目前卡在了这一点：
model_0 = init_binary_classification_model((28,28))
model_0.load_weights(&#39;trained_weight_of_binary_classification_to_check_whether_image_is_zero.h5&#39;)

model_1 = init_binary_classification_model((28,28))
model_1.load_weights(&#39;trained_weight_of_binary_classification_to_check_whether_image_is_one.h5&#39;)

model_2 = init_binary_classification_model((28,28))
model_2.load_weights(&#39;trained_weight_of_binary_classification_to_check_whether_image_is_two.h5&#39;)

其中：
def init_binary_classification_model(input_shape=(28,28)):
input_layer = Input(shape=input_shape)
tensor = Flatten()(input_layer)
tensor = Dense(16,activation=&#39;relu&#39;)(tensor)
tensor = Dense(8,activation=&#39;relu&#39;)(tensor)
output_layer = Dense(1,activation=&#39;sigmoid&#39;)(tensor)

return Model(inputs=input_layer,outputs=output_layer)

我期望多分类模型具有相同的输入形状(28,28)和不同的输出形状(3)，并且我不需要重新训练模型（如果可能的话）。
完整代码可在https://colab.research.google.com/drive/1y1mvAzebIFU_cuEQo8Q60L1I6uT8i2Ce?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78773489/combine-three-trained-binary-classification-models-into-single-multiclassificati</guid>
      <pubDate>Sat, 20 Jul 2024 17:44:05 GMT</pubDate>
    </item>
    <item>
      <title>我的 RandomForestRegressor 上的 MAE 和 MSE 非常高</title>
      <link>https://stackoverflow.com/questions/78770230/very-high-mae-and-mse-on-my-randomforestregressor</link>
      <description><![CDATA[我得到了一个航班预测数据集，我想试试我的机器学习技能。
我清理了数据，修复了一些新功能，删除了其他功能
我还得到了一些有价值的数据。但当我尝试进行预测并评估我的模型时
这就是我得到的答案！那是在我使用 SearchGridCV 调整模型之后
测试集上的回归指标
r2：82.10%
mean_absolute_error：1229.1407307097613
mean_squared_error：2933265.159841384

model = RandomForestRegressor(
max_depth=20,
max_features=&#39;sqrt&#39;,
min_samples_leaf=2,
min_samples_split=5,
n_estimators=200
)

X = df.drop(&#39;Price&#39;,axis=1)
y = df[&#39;Price&#39;]

X_train, X_test, y_train, y_test = train_test_split(
pd.get_dummies(X)
, y, test_size=0.2, random_state=42)

model.fit(X_train,y_train)
y_preds = model.predict(X_test)

我尝试修改超参数并删除一些异常值
def remove_outliers_iqr(df, column):
Q1 = df[column].quantile(0.25)
Q3 = df[column].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
return df[(df[column] &gt;= lower_bound) &amp; (df[column] &lt;= upper_bound)]

numerical_columns = [&#39;Price&#39;, &#39;Dep_hours&#39;, &#39;Dep_min&#39;, &#39;Arrival_hours&#39;, &#39;Arrival_min&#39;, &#39;Duration_hours&#39;, &#39;Duration_min&#39;]
for column in numeric_columns:
df = remove_outliers_iqr(df, column)

但我仍然得到相同的结果
这是完整的笔记本，因为我不知道如何以笔记本的方式在此处附加整个代码
https://github.com/jamhus/ztm-course/blob/master/Test%20projects/fligt%20prices%20analysis/flight%20prices.ipynb]]></description>
      <guid>https://stackoverflow.com/questions/78770230/very-high-mae-and-mse-on-my-randomforestregressor</guid>
      <pubDate>Fri, 19 Jul 2024 15:47:43 GMT</pubDate>
    </item>
    <item>
      <title>通过向 CNN 输入添加位置和字符信息来增强文档布局分析</title>
      <link>https://stackoverflow.com/questions/78739816/enhancing-document-layout-analysis-by-adding-positional-and-character-informatio</link>
      <description><![CDATA[我正在研究文档布局分析，并一直在探索 CNN 和基于 Transformer 的网络来完成这项任务。通常，图像作为 3 通道 RGB 输入传递给这些网络。但是，我的数据源是 PDF 格式，我可以直接从中提取准确的位置和字符信息。
我担心将这些 PDF 数据转换为图像进行分析会导致宝贵的位置和字符信息丢失。我的想法是将 CNN 的输入维度从标准的 3 RGB 通道修改为包含这些额外位置和字符信息的更高维度输入。
我了解 CNN 的工作原理，并高度怀疑这种方法可能行不通，但我很感谢社区的任何反馈或建议。有没有人尝试过以这种方式增强输入通道，或者有没有人对将位置和字符数据直接集成到 CNN 中有什么见解？]]></description>
      <guid>https://stackoverflow.com/questions/78739816/enhancing-document-layout-analysis-by-adding-positional-and-character-informatio</guid>
      <pubDate>Fri, 12 Jul 2024 10:17:29 GMT</pubDate>
    </item>
    <item>
      <title>Python机器学习pytorch测试/训练epoch结果问题</title>
      <link>https://stackoverflow.com/questions/77977231/python-machine-learning-pytorch-test-train-epoch-results-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77977231/python-machine-learning-pytorch-test-train-epoch-results-problem</guid>
      <pubDate>Sun, 11 Feb 2024 15:07:50 GMT</pubDate>
    </item>
    <item>
      <title>RNN 中未找到 rnn_utils 模块</title>
      <link>https://stackoverflow.com/questions/61175064/module-not-found-rnn-utils-in-rnn</link>
      <description><![CDATA[我需要使用这个库来构建我的模型，但是我遇到了这个错误。
from rnn_utils import *

没有名为“rnn_utils”的模块]]></description>
      <guid>https://stackoverflow.com/questions/61175064/module-not-found-rnn-utils-in-rnn</guid>
      <pubDate>Sun, 12 Apr 2020 17:00:00 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 聚类：预测（X）与 fit_predict（X）</title>
      <link>https://stackoverflow.com/questions/37106983/scikit-learn-clustering-predictx-vs-fit-predictx</link>
      <description><![CDATA[在 scikit-learn 中，一些聚类算法同时具有 predict(X) 和 fit_predict(X) 方法，例如 KMeans 和 MeanShift，而其他算法仅具有后者，例如 SpectralClustering。根据文档：
fit_predict(X[, y]): 对 X 执行聚类并返回聚类标签。
predict(X): 预测 X 中每个样本所属的最接近聚类。

我不太明白这两者之间的区别，在我看来它们似乎是等价的。]]></description>
      <guid>https://stackoverflow.com/questions/37106983/scikit-learn-clustering-predictx-vs-fit-predictx</guid>
      <pubDate>Mon, 09 May 2016 02:25:29 GMT</pubDate>
    </item>
    </channel>
</rss>