<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 24 Jul 2024 12:28:43 GMT</lastBuildDate>
    <item>
      <title>如何在窗口上聚合 RESNET50 全局特征？</title>
      <link>https://stackoverflow.com/questions/78788243/how-to-aggregate-resnet50-global-features-over-a-window</link>
      <description><![CDATA[我有一项任务，需要对时间序列凝视数据集进行人员识别。我有正在观看视频的人的凝视信息，对于每个时间戳，我都会从视频中获取一个裁剪的帧，以了解人员正在看哪里，然后将其提供给 RESNET-50 预训练模型以提取其特征。从模型中删除最后一个分类层，以便我获得每个图像的 2048 维向量。
最后，我有一个带有时间戳的时间序列数据，对于每一行，凝视信息 + 2048 个来自 RESNET 模型的特征。我的目标是使用凝视特征进行人员识别，并在这些凝视特征之上，输出 RESNET 特征。
现在，我想进行特征聚合，可能在窗口大小上进行。我一直在研究像 Fischer 向量这样的局部特征聚合方法，但我拥有的是图像的全局特征。
TL;DR，有没有一种好的方法可以在窗口大小上聚合 RESNET-50 特征？
我尝试过使用常见的聚合方法，如均值和方差、最大最小值等，但不确定聚合结果是否对应有意义的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78788243/how-to-aggregate-resnet50-global-features-over-a-window</guid>
      <pubDate>Wed, 24 Jul 2024 12:07:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 SHAP 值生成的蜂群图中点的可见性问题</title>
      <link>https://stackoverflow.com/questions/78788072/issue-with-visibility-of-points-in-beeswarm-plot-generated-using-shap-values</link>
      <description><![CDATA[我理解，在蜂群图中，实例以点/点来表示。因此，人们可以根据 SHAP 值找到水平分布（沿 x 轴）的点簇，当 SHAP 值密度较高时，这些点簇垂直堆叠（沿 y 轴）。
在大多数文档中，我看到蜂群图看起来像这样（https://www.aidancooper.co.uk/a-non-technical-guide-to-interpreting-shap-analyses/）：

创建蜂群图后，我看不到点。我注意到形状点的边缘形成了更平滑的表面。我不确定我做对了什么或做错了什么，如果您能帮助我改变这一点，我将不胜感激。
这是我运行的代码。
shap_values = explainer.shap_values(X.iloc[0:N_VAL,:], nsamples=NSHAP_SAMPLES)

shap.summary_plot(shap_values, X.iloc[:N_VAL, :], plot_type=&quot;violin&quot;, max_display=21, show=False)

# 调整图形大小以确保所有内容都适合
plt.gcf().set_size_inches(15, 10) # 根据需要调整大小

# 显示图表
plt.show()

代码生成下面的图表

如何处理此问题？]]></description>
      <guid>https://stackoverflow.com/questions/78788072/issue-with-visibility-of-points-in-beeswarm-plot-generated-using-shap-values</guid>
      <pubDate>Wed, 24 Jul 2024 11:33:37 GMT</pubDate>
    </item>
    <item>
      <title>数据交叉验证</title>
      <link>https://stackoverflow.com/questions/78787891/cross-validation-on-data</link>
      <description><![CDATA[我有两个文件，一个是 train.csv，另一个是 test.csv。test.csv 是看不见的数据，我们不会在训练中使用它。所以我使用 train.csv，我使用训练分割将其进一步分割为 train_1 和验证集。我想应用交叉验证 (K-Fold)。我应该对 train_1 还是对整个训练数据（即 train.csv）应用交叉验证？我很困惑。关于超参数调整还有一件事。我正在使用 RandomizedSerachCV，如果我想给 cv=None，那么没问题，因为我不想再次应用交叉验证。
我正在尝试检查模型的稳健性并进行一些超参数调整。]]></description>
      <guid>https://stackoverflow.com/questions/78787891/cross-validation-on-data</guid>
      <pubDate>Wed, 24 Jul 2024 10:50:12 GMT</pubDate>
    </item>
    <item>
      <title>从 R 中的空间数据框中识别横断面上的点</title>
      <link>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</link>
      <description><![CDATA[我有调查数据，沿着与海岸垂直的平行横断面每隔 1 海里记录一次。对于每条记录，我都有纬度和经度、速度、方位等信息。沿着横断面，速度约为 10 节。我还在样条间（速度可能不同，方位肯定不同）处有一些点，如果进行了拖网，我还在样条外有一些点。
我想要做的是将属于同一样条的所有点分组（例如，参见图）：

这只是使用 1 NM 点间距离完成的，正如您在图中看到的那样，这实际上不起作用，因为只要有样条间（如样条 5），它就会与样条本身分组在一起。此外，在横断面 13 中，由于某种原因，2 个后续记录之间的距离略大于 1 海里，因此这些点被分成 2 个横断面（您可以看到颜色略有不同）。
此处显示的数据框示例：
 |year |datetime |xkm |ykm |logdiff |time_diff |distance |bearing |speed |
|&lt;dbl&gt; |&lt;dttm&gt; |&lt;dbl&gt; |&lt;dbl&gt; |&lt;dbl&gt;| &lt;dbl&gt;| &lt;drtn&gt; | &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;| &lt;dbl&gt;|
|------|---------- |------|-----|--------|------ --|---------|--------|------|
|2023 |2023-09-26 15:03:00 |221. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:08:00 |223. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:14:00 |225. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:19:00 |227. |1606.| 1| 300 秒 | 1| -1.58| 12|
|2023 |2023-09-26 15:25:00 |229. |1606.| 1| 360 秒 | 1| -1.84| 10|
|2023 |2023-09-26 15:30:00 |231. |1606.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:36:00 |233. |1606.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:41:00 |234. |1605.| 1| 300 秒 | 1| -1.85| 12|
|2023 |2023-09-26 15:47:00 |236. |1605.| 1| 360 秒 | 1| -1.58| 10|
|2023 |2023-09-26 15:52:00 |238. |1605.| 1| 300 秒 | 1| -1.58| 12|

在 R 中解决这个问题的最佳方法是什么？我考虑过一些无监督的机器学习算法，比如使用 dbscan 进行聚类，但我不确定我是否正确使用了它。除了点之间的距离，我还想使用其他参数来对点是否属于横断面进行分类（例如方位和速度）。
我的尝试：
# 准备聚类数据
clustering_data &lt;- df %&gt;% select(year, speed, bearing, xkm, ykm)

# 应用 DBSCAN 聚类
set.seed(123)
db &lt;- dbscan(clu​​stering_data, eps = 1.8, minPts = 5)


有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78787801/identify-points-lying-on-transects-from-a-spatial-dataframe-in-r</guid>
      <pubDate>Wed, 24 Jul 2024 10:33:52 GMT</pubDate>
    </item>
    <item>
      <title>如何创建数据集以使用 Tensorflow 进行文本生成</title>
      <link>https://stackoverflow.com/questions/78787403/how-to-create-the-dataset-to-use-tensorflow-for-text-generation</link>
      <description><![CDATA[我正在构建一个 Tensorflow 模型，根据项目名称生成文本。但是，我不知道如何为此目的创建数据集。
我的数据集中有三个特征，将根据这些特征创建文本。那么我该怎么办？
此外，我如何增加模型生成的文本的长度。
我已经创建了大约 18000 行的数据集，其中第一个特征有 12 个类别，第二个特征有 2 个类别，第三个特征有 78 个类别。目标列是与特征相关的测试，经过训练后，将预测模型中的文本生成。
由此，我希望输入将给出 3 个特征，并基于这些输入生成文本，但语言变化和修改与训练数据不完全相同。]]></description>
      <guid>https://stackoverflow.com/questions/78787403/how-to-create-the-dataset-to-use-tensorflow-for-text-generation</guid>
      <pubDate>Wed, 24 Jul 2024 09:15:38 GMT</pubDate>
    </item>
    <item>
      <title>使用适配器在 CNN/DailyMail 数据集上微调 BART 时，性能不佳且有过度拟合的迹象</title>
      <link>https://stackoverflow.com/questions/78787294/poor-performance-and-signs-of-overfitting-when-fine-tuning-bart-with-adapters-on</link>
      <description><![CDATA[我目前正在使用 CNN/DailyMail 数据集对 BART 模型进行微调，并使用适配器完成摘要任务。我注意到该模型性能不佳，并且有过度拟合的迹象。下面是我的设置和相关代码片段。我已经尝试了不同的学习率和训练数据量。如有任何关于导致此问题的原因或如何改善模型性能的建议，我们将不胜感激。
from datasets import load_dataset, DatasetDict
from transformers import TrainingArguments, EvalPrediction
from adapters import AutoAdapterModel, AdapterTrainer
import torch

# 加载 CNN/DailyMail 数据集的子集
small_train_dataset = load_dataset(&quot;cnn_dailymail&quot;, &quot;3.0.0&quot;, split=&quot;train[:5%]&quot;)

# 拆分数据集
train_size = 0.8
valid_size = 0.2
train_valid_split = small_train_dataset.train_test_split(test_size=valid_size)
split_dataset = DatasetDict({
&#39;train&#39;: train_valid_split[&#39;train&#39;],
&#39;validation&#39;: train_valid_split[&#39;test&#39;]
})

# 预处理和标记数据
def preprocess_function(examples):
# 假设“tokenizer”已实例化
return {
&#39;input_ids&#39;: tokenizer(examples[&#39;article&#39;], padding=&quot;max_length&quot;, truncation=True, max_length=128),
&#39;labels&#39;: tokenizer(examples[&#39;highlights&#39;], padding=&quot;max_length&quot;, truncation=True, max_length=128)[&quot;input_ids&quot;]
}

# 使用适配器初始化 BART 模型
model = AutoAdapterModel.from_pretrained(&quot;facebook/bart-base&quot;)
model.add_adapter(&quot;cnn_dailymail&quot;, config=&quot;lora&quot;)
model.add_seq2seq_lm_head(&quot;cnn_dailymail&quot;)
model.train_adapter(&quot;cnn_dailymail&quot;)

# 训练设置
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
model.to(device)
training_args = TrainingArguments(
learning_rate=5e-5,
num_train_epochs=1,
per_device_train_batch_size=32,
logs_steps=10,
output_dir=&quot;./training_output&quot;,
overwrite_output_dir=True,
remove_unused_columns=False,
gradient_accumulation_steps=4
)

trainer = AdapterTrainer(
model=model,
args=training_args,
train_dataset=split_dataset[&#39;train&#39;],
eval_dataset=split_dataset[&#39;validation&#39;]
)

# 开始训练
trainer.train()
]]></description>
      <guid>https://stackoverflow.com/questions/78787294/poor-performance-and-signs-of-overfitting-when-fine-tuning-bart-with-adapters-on</guid>
      <pubDate>Wed, 24 Jul 2024 08:52:39 GMT</pubDate>
    </item>
    <item>
      <title>在 keras.metrics.TruePositives 中，TruePositive 怎么会是十进制数？</title>
      <link>https://stackoverflow.com/questions/78787112/how-can-truepositive-be-a-decimal-number-in-keras-metrics-truepositives</link>
      <description><![CDATA[我正在尝试在图像数据集上训练 CNN 模型，但是我无法获得 TruePositives、TrueNegatives、FalsePositives 和 FalseNegatives 的十进制值。这怎么可能呢？
ERROR sample
Epoch 1/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━ 69s 2s/step - false_negatives: 30.1351 - false_positives: 35.3784 - loss: 2.1995 - true_negatives: 389.0540 - true_positives: 437.6487


有一些（tp+tn+fp+tn）不等于样本总数。
完整代码

import pandas as pd
将 tensorflow 导入为 tf
从 tensorflow.keras.preprocessing.image 导入 ImageDataGenerator

从 tensorflow.keras.layers 导入 Dense、Flatten、InputLayer、Conv2D、MaxPooling2D、Concatenate、Input、BatchNormalization
从 tensorflow.keras.models 导入 Sequential、Model
从 tensorflow.keras.losses 导入 BinaryCrossentropy、CategoricalCrossentropy
从 tensorflow.keras.optimizers 导入 Adam
将 matplotlib.pyplot 导入为 plt
从 tensorflow.keras.models 导入 Model
从 sklearn.metrics 导入 Classification_report
从 tensorflow.keras.callbacks 导入EarlyStopping

datagen=ImageDataGenerator(rescale=1.0/255.0)
train_gen=datagen.flow_from_directory(&#39;train&#39;,class_mode=&#39;binary&#39;,
target_size=(224,224),batch_size=32,shuffle=True)


输出：

找到属于 2 个类别的 1146 张图像。

tp = tf.keras.metrics.TruePositives()
tn = tf.keras.metrics.TrueNegatives()
fp = tf.keras.metrics.FalsePositives()
fn = tf.keras.metrics.FalseNegatives()
tp.update_state([0.4, .9, .7, .8], [1.0, 0.0, 1.0, 1.0])
tp.result()

输出
&lt;tf.Tensor: shape=(), dtype=float32, numpy=3.0&gt;

model_input=Input(shape=(224,224,3))

x=Conv2D(filters=32, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(model_input)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=Conv2D(filters=64, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(x)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=BatchNormalization()(x)
x=Conv2D(filters=64, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(x)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=BatchNormalization()(x)
x=Flatten()(x)
x=Dense(units=1000,activation=&#39;relu&#39;)(x)
output=Dense(units=1,activation=&#39;sigmoid&#39;)(x)
model=Model(inputs=model_input,outputs=output)

model.compile(optimizer=Adam(),loss=BinaryCrossentropy(),metrics=[tp,fp,fn,tn])
early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, waiting=2,restore_best_weights=True)

history=model.fit(x=train_gen,epochs=3,callbacks=[early_stopping])

十进制值错误
Epoch 1/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━━ 69s 2s/step - false_negatives: 30.1351 - false_positives: 35.3784 - loss: 2.1995 - true_negatives: 389.0540 - true_positives: 437.6487
Epoch 2/3
36/36 ━━━━━━━━━━━━━━━━━━━━━ 61s 2s/步 - 假阴性：7.8378 - 假阳性：13.5135 - 损失：0.1692 - 真阴性：283.1081 - 真阳性：300.4054
Epoch 3/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━━ 65s 2s/步 - 假阴性： 2.3243 - 假阳性：3.0811 - 损失：0.0546 - 真阴性：289.8108 - 真阳性：308.3513

]]></description>
      <guid>https://stackoverflow.com/questions/78787112/how-can-truepositive-be-a-decimal-number-in-keras-metrics-truepositives</guid>
      <pubDate>Wed, 24 Jul 2024 08:14:02 GMT</pubDate>
    </item>
    <item>
      <title>安装 tf-models-official 时出现元数据生成失败</title>
      <link>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</link>
      <description><![CDATA[我尝试使用 !pip install tf-models-official 安装 tf-models-official，当它开始收集 kaggle&gt;=1.3.9 时，它返回以下错误：
收集 kaggle&gt;=1.3.9（来自 tf-models-official）
使用缓存的 kaggle-1.6.15.tar.gz (9.1 kB)
安装构建依赖项...完成
获取构建 wheel 的要求...完成
准备元数据（pyproject.toml）...错误
错误：子进程退出并出现错误

× 准备元数据（pyproject.toml）未成功运行。
│ 退出代码：1
╰─&gt; [35 行输出]
回溯（最近一次调用）：
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 353 行，位于 &lt;module&gt;
main()
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 335 行，在 main 中
json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 152 行，在 prepare_metadata_for_build_wheel 中
whl_basename = backend.build_wheel(metadata_directory, config_settings)
文件&quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/build.py&quot;，第 58 行，在 build_wheel 中
return os.path.basename(next(builder.build(directory=wheel_directory,versions=[&#39;standard&#39;])))
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;，第 155 行，在 build 中
artifact = version_api[version](directory,**build_data)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 475 行，在build_standard
for included_file in self.recurse_included_files():
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 176, in recurse_included_files
Yield from self.recurse_selected_project_files()
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 180, in recurse_selected_project_files
if self.config.only_include:
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/config.py&quot;，第 806 行，在 only_include 中
only_include = only_include_config.get(&#39;only-include&#39;, self.default_only_include()) 或 self.packages
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 260 行，在 default_only_include 中
return self.default_file_selection_options.only_include
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/functools.py&quot;，第 981 行，在__get__
val = self.func(instance)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 248 行，位于 default_file_selection_options
raise ValueError(message)
ValueError：无法使用以下启发式方法确定要将哪些文件发送到 wheel 内：https://hatch.py​​pa.io/latest/plugins/builder/wheel/#default-file-selection

最可能的原因是没有与您的项目 (kaggle) 名称匹配的目录。

必须在 `tool.hatch.build.targets.wheel` 表中定义至少一个文件选择选项，请参阅：https://hatch.py​​pa.io/latest/config/build/

例如，如果您打算发送一个名为 `foo` 的目录，该目录位于项目根目录的 `src` 目录中，则可以定义以下内容：

[tool.hatch.build.targets.wheel]
packages = [&quot;src/foo&quot;]
[输出结束]

注意：此错误源自子进程，可能不是 pip 的问题。
错误：metadata-generation-failed

× 生成包元数据时遇到错误。
╰─&gt; 请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip。
提示：请参阅上文了解详情。

我能够在 2 周前安装，现在在新的 jupyter 笔记本内核上突然无法安装。我尝试在旧内核上重新安装，也出现了同样的错误。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</guid>
      <pubDate>Wed, 24 Jul 2024 07:02:59 GMT</pubDate>
    </item>
    <item>
      <title>即使管道运行正常，管道输出仍为空</title>
      <link>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</link>
      <description><![CDATA[以下代码模拟了一个简单的 TFX 管道，它提取 CSV 文件并将其转换为 TFRecord。
您还可以查看相应的笔记本：https://colab.research.google.com/drive/1GEytZjnNZZ7r_f9QQ9FbauohKNLGSooC?usp=sharing
output_config = example_gen_pb2.Output(split_config=
example_gen_pb2.SplitConfig(splits=[
example_gen_pb2.SplitConfig.Split(name=&#39;train&#39;, hash_buckets=8),
example_gen_pb2.SplitConfig.Split(name=&#39;eval&#39;, hash_buckets=2)
])
)

example_gen = CsvExampleGen(
input_base=&#39;data&#39;,
output_config=output_config
)

pipeline_root = &#39;artifacts&#39;

pipeline = Pipeline(
pipeline_name=&#39;testing pipeline&#39;,
pipeline_root=pipeline_root,
components=[example_gen],
enable_cache=True,
metadata_connection_config=metadata.sqlite_metadata_connection_config(
os.path.join(&#39;artifacts&#39;, &#39;metadata.sqlite&#39;)
)
)

LocalDagRunner().run(pipeline)

我已手动验证 TFRecord 已正确生成。但是，管道的输出字典是空的。
print(pipeline.outputs)
# output: {}
print(example_gen.outputs[&#39;examples&#39;].get())
# output: []

此问题在 .ipynb 笔记本和 .py 文件中都存在。
有趣的是，InteractiveContext 没有这个问题。
是什么原因造成的？]]></description>
      <guid>https://stackoverflow.com/questions/78658886/pipeline-outputs-is-empty-even-though-the-pipeline-is-running-correctly</guid>
      <pubDate>Sun, 23 Jun 2024 14:03:09 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用函数转换器对我的目标列进行特征转换，但我不知道如何将其传递给函数？</title>
      <link>https://stackoverflow.com/questions/78274143/i-am-doing-feature-transformation-of-my-target-column-using-function-transformer</link>
      <description><![CDATA[该代码用于获取我的目标列，即 Time_taken(min)，其值为 (min) 36、(min) 54、(min) 65 ... 等等。所以我想创建一个新列“Time Taken”其值将为 36、54、65....并使用 Function Transformers 删除 Time_taken(min)。
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline

class TimeTakenTransformer(BaseEstimator, TransformerMixin):
def __init__(self, input_column):
self.input_column = input_column
def fit(self, X, y=None):
return self

def transform(self, X):
X = X.copy()
op = []
for i in X[self.input_column]:
a = i.split()
op.append(int(a[1]))
X[&#39;Time_taken&#39;] = op
X.drop([self.input_column], axis=1, inplace=True)
return X

Target_column = Pipeline([(&#39;替换值&#39;, TimeTakenTransformer(input_column=&quot;TARGET_COLUMN_NAME&quot;))])

Target_column = Pipeline([(&#39;替换值&#39;, TimeTakenTransformer(input_column=&quot;TARGET_COLUMN_NAME&quot;))])

TARGET_COLUMN_NAME = &quot;Time_taken(min)&quot; # 假设这是正确的列名

# 假设 df 是您的 DataFrame，应用转换
df_transformed = Target_column.fit_transform(df[[TARGET_COLUMN_NAME]])

# 用转换后的列替换原始列
df[&quot;Time_Taken&quot;] = df_transformed

我无法确定传递输入的正确方法。如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78274143/i-am-doing-feature-transformation-of-my-target-column-using-function-transformer</guid>
      <pubDate>Thu, 04 Apr 2024 13:19:38 GMT</pubDate>
    </item>
    <item>
      <title>将自动编码器转变为另一个模型</title>
      <link>https://stackoverflow.com/questions/78190758/turning-an-autoencoder-into-another-model</link>
      <description><![CDATA[根据我目前所读和所见，自动编码器神经网络的一个优点和用途是找到/挑选有用的特征。如果自动编码器训练良好，那么包含压缩数据的内层（即潜在层或瓶颈）中就有非常有价值的数据。
此层可用作另一个网络的输入，使另一个网络训练更容易/更快/更准确。
换句话说，我们摆脱了解码器部分，并将新层附加到编码器部分。
问题：

新层可以/应该具有不同的激活函数吗？

在潜在层之后，模型是否有任何合理的理由在每个层上添加更多节点数？ （我的意思是，当使用潜在作为新网络的输入时，再次扩大网络是否有意义？）

如何使用 keras 完成此过程？
我知道如何训练模型和自动编码器，但我究竟如何将它们结合起来？


我已经训练了自动编码器，并且知道新网络所需输出的形式。我只知道如何在 keras 和 tensorflow 中使用顺序方法创建网络。]]></description>
      <guid>https://stackoverflow.com/questions/78190758/turning-an-autoencoder-into-another-model</guid>
      <pubDate>Wed, 20 Mar 2024 03:42:57 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret：目标列中出现缺失值错误</title>
      <link>https://stackoverflow.com/questions/78099026/pycaret-got-missing-value-error-in-target-col</link>
      <description><![CDATA[如果目标列包含 NaN，并且当将其作为 Pycaret 中的目标列传递时，它会显示缺失值错误；所有可用的插补方法都适用于其余列，而不适用于所选目标列。
s = setup(df, target = &#39;Life expectancy&#39;, numeric_imputation=&quot;mean&quot;)


ValueError: 在目标列中发现 10 个缺失值：预期寿命。要继续，请从数据中删除相应的行。


目标列包含 NaN，当在 Pycaret 中将其作为目标列传递时，它会显示缺失值错误，如何处理目标列中的缺失值？]]></description>
      <guid>https://stackoverflow.com/questions/78099026/pycaret-got-missing-value-error-in-target-col</guid>
      <pubDate>Mon, 04 Mar 2024 04:54:10 GMT</pubDate>
    </item>
    <item>
      <title>训练特征矩阵与真实输入</title>
      <link>https://stackoverflow.com/questions/77977567/training-feature-matrix-vs-real-input</link>
      <description><![CDATA[我在尝试将我的模型应用于实际场景时遇到了问题。用于训练的原始特征矩阵大于输入数据。
请纠正我，我知道实际应用中的输入可能在大小上要小得多，并且在更糟糕的情况下具有一些不同的特征。
示例：我的数据集是数千个文本文件，它们有两个类别（备忘录 (0) 或字母 (1)）。我使用 linearSVC 训练模型来对这些文件进行分类。
使用 train_test_split 的结果很棒，现在我想用实际场景测试它。实际场景中的输入将是一个文件。该文件将具有较少的特征，并且可能具有不同的特征。在我的上一次测试中，我使用 4500 个特征进行训练，而实际场景中的输入有 350 个特征。
ValueError：X 有 350 个特征，但 LinearSVC 需要 4500 个特征作为输入。
我该如何处理此类问题？]]></description>
      <guid>https://stackoverflow.com/questions/77977567/training-feature-matrix-vs-real-input</guid>
      <pubDate>Sun, 11 Feb 2024 16:49:49 GMT</pubDate>
    </item>
    <item>
      <title>我不明白 sckit-learn 的 tfidfvectorizer 的工作原理</title>
      <link>https://stackoverflow.com/questions/77541978/i-do-not-understand-the-working-of-tfidfvectorizer-of-sckit-learn</link>
      <description><![CDATA[我知道的计算 tf-idf 的公式是 TF * IDF，其中 TF 是该词在文档 D 中出现的次数，IDF 是文档数/包含该词的文档数 + 1。
这是我的数据集。
corpus = [ &#39;这是第一个文档。&#39;, &#39;这个文档是第二个文档。&#39;, &#39;这是第三个文档。&#39;, &#39;这是第一个文档吗？&#39;, ]
现在我计算了文档 1 中单词“document”的 td-idf，输出为 0.22。
但是当我使用 sckit 的 tfidf 矢量化器时，输出为：
1.22314355
我使用的矢量化器具有以下参数：
vectorizer = TfidfVectorizer(norm=None) 
请解释为什么答案不同。]]></description>
      <guid>https://stackoverflow.com/questions/77541978/i-do-not-understand-the-working-of-tfidfvectorizer-of-sckit-learn</guid>
      <pubDate>Fri, 24 Nov 2023 09:16:18 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 自动编码器数据缩放指南</title>
      <link>https://stackoverflow.com/questions/76866677/guidance-on-data-scaling-for-lstm-autoencoder</link>
      <description><![CDATA[我正在处理一个包含 9 个特征的数据集。其中 8 个特征的值范围为 0-255，但一个特征的值明显不同。我正在将此数据集与 LSTM 自动编码器一起使用以进行异常检测，并且对缩放有几个问题：
虽然建议使用 RobustScaler 来处理异常值，但我发现 StandardScaler 在我的测试中表现更好。您能解释一下为什么会这样吗？
我尝试使用 RobustScaler 来处理发散特征，使用 StandardScaler 来处理其余特征。这种方法似乎很有希望。您会推荐这种混合缩放方法吗，还是我应该坚持对所有特征使用一个缩放器？]]></description>
      <guid>https://stackoverflow.com/questions/76866677/guidance-on-data-scaling-for-lstm-autoencoder</guid>
      <pubDate>Wed, 09 Aug 2023 10:06:05 GMT</pubDate>
    </item>
    </channel>
</rss>