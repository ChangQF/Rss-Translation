<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 06 Mar 2024 18:17:26 GMT</lastBuildDate>
    <item>
      <title>为什么我的训练损失和验证损失非常低，但新数据集的均方误差却很高？</title>
      <link>https://stackoverflow.com/questions/78116573/why-my-training-loss-and-validation-loss-very-low-but-the-mse-for-a-new-dataset</link>
      <description><![CDATA[来自tensorflow.keras导入层
从tensorflow.keras.layers导入Dense
从tensorflow.keras.layers导入LSTM
从tensorflow.keras.models导入顺序
从tensorflow.keras导入正则化器


模型=顺序（[
    LSTM(单位=64, input_shape=(len(x.columns),1), kernel_regularizer=regularizers.l2(0.01)),
    密集(1)
]）

model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizationr=tf.keras.optimizers.Adam())
历史=模型.fit（x_train，y_train，validation_data =（x_val，y_val），epochs = 100，verbose = 1，batch_size = 32）
mse=model.evaluate(x_test, y_test)
打印（毫秒）

这是我得到的损失图
我得到的值非常高（30.2344）]]></description>
      <guid>https://stackoverflow.com/questions/78116573/why-my-training-loss-and-validation-loss-very-low-but-the-mse-for-a-new-dataset</guid>
      <pubDate>Wed, 06 Mar 2024 18:14:44 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 与 RTX 4090 训练时间差异巨大</title>
      <link>https://stackoverflow.com/questions/78116561/pytorch-with-rtx-4090-huge-difference-in-training-time</link>
      <description><![CDATA[我在大学计算机（4090 和 13900KF）上用 pytorch 训练了一个模型 48 个 epoch，大约需要 8 分钟。
我现在在家装了一台新 PC（4090 和 14900KF），但训练时间明显更长，48 个 epoch 大约需要 17.5 分钟。
我在两者上使用了相同的代码，并且没有更改训练的任何其他参数。
原因可能是什么？不幸的是，我无法再使用大学计算机，因为我们使用它们的课程已经结束了。]]></description>
      <guid>https://stackoverflow.com/questions/78116561/pytorch-with-rtx-4090-huge-difference-in-training-time</guid>
      <pubDate>Wed, 06 Mar 2024 18:12:11 GMT</pubDate>
    </item>
    <item>
      <title>强化学习神经网络概率没有改变</title>
      <link>https://stackoverflow.com/questions/78116374/reinforcement-learning-neural-network-probabilities-arent-changing</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78116374/reinforcement-learning-neural-network-probabilities-arent-changing</guid>
      <pubDate>Wed, 06 Mar 2024 17:35:37 GMT</pubDate>
    </item>
    <item>
      <title>在 MLJ 中找不到适合我的数据类型的模型</title>
      <link>https://stackoverflow.com/questions/78116043/can-not-find-a-model-in-mlj-suitable-for-my-data-type</link>
      <description><![CDATA[我想在 MLJ 中使用 RandomForestRegressor，但我的数据类型总是出现错误。
这是我的数据类型：
# X 的类型
500×1矩阵{Float64}：
 0.002
 0.004
 0.006
 0.008
 0.01
 ⋮
 0.992
 0.994
 0.996
 0.998
 1.0

#y 的类型
500 元素向量{任意}：
 [-26.12471826402402、-0.00019238911241092893、-8.487354458186491e-6、-4.247928689027347e-6、-1.4735850473179823e-6、-5.5989652116 83904e-6]
 [-26.124690243484718、-2.813962224679223e-5、0.00014993993007544892、-3.972667350815584e-5、-4.415345127384285e-5、4.7755059188 858695e-5]
 [-26.124700578434716、0.00020304547366412073、-1.941266595367752e-5、-6.8228290228677935e-6、-2.8075749891054436e-6、-5.95726165 1756696e-7]
 [-26.12470127817773、-0.0002052884039169811、-1.53​​54293043945422e-5、5.457931474439626e-6、-1.0654739228677101e-6、1.3601831927 445573e-6]
 [-26.124689854622336、-0.0001879523626138191、5.983618996563411e-6、-2.412535654516823e-5、1.7942953590588395e-5、-1.3323422657 25206e-5]
 ⋮
 [-26.12470204971627、-0.00020642317364671925、-1.6756339903056805e-5、7.454364967629523e-6、-2.539052483596649e-6、1.8465582632 964939e-6]
 [-26.12469951981032、0.00020256742611590717、-1.9380595701112835e-5、-6.199351626712257e-6、-3.5935735922532075e-6、-1.153947443 044423e-6]
 [-26.124700578434716、0.00020304547366412073、-1.9412665953733033e-5、-6.8228290228677935e-6、-2.8075749891054436e-6、-5.9572616 58418034e-7]
 [-26.124701332004584、-0.00020670402366529395、-1.6873028843567006e-5、7.897781219456945e-6、-3.3466380342517255e-6、1.43543246 5890507e-6]
 [-26.124682551931944、0.0001869595100869592、5.027911548549646e-6、1.9320833163805062e-5、1.57188​​013177878e-5、6.48586574647 5028e-6]

上面的数据可以在DecisionTree.jl中使用，但在MLJ.jl中不起作用。
这是我的 DecisionTree.jl 代码，它运行良好
模型 = build_forest(y, X)
apply_forest（模型，[0.75]）

这是我的 MLJ.jl 代码。
RandomForest = MLJ.@load RandomForestRegressor pkg = DecisionTree
myrandforest = 随机森林()
马赫=机器（myrandforest，X，y）|&gt; MLJ.适合！

和错误消息：
导入 MLJDecisionTreeInterface ✔
┌ 警告：数据参数的数量和/或类型与指定模型不匹配
│ 支持。通过指定“scitype_check_level=0”来抑制此类型检查。
│
│ 运行“@doc DecisionTree.RandomForestRegressor”以了解有关模型要求的更多信息。
│
│ 通常但非唯一地，监督模型是使用以下语法构建的
│ `machine(model, X, y)` 或 `machine(model, X, y, w)` 而大多数其他模型是
│ 用 `machine(model, X)` 构造。这里“X”是特征，“y”是目标，“w”
│ 样本或类别权重。
│
│ 一般来说，`machine(model, data...)`中的数据预计满足
│
│ scitype(数据) &lt;: MLJ.fit_data_scitype(模型)
│
│ 在本案中：
│
│ scitype(数据) = Tuple{AbstractMatrix{连续}, AbstractVector{AbstractVector{连续}}}
│
│ fit_data_scitype(model) = Tuple{Table{&lt;:Union{AbstractVector{&lt;:连续}, AbstractVector{&lt;:Count}, AbstractVector{&lt;:OrderedFactor}}}, AbstractVector{连续}}
└ @ MLJBase ~/.julia/packages/MLJBase/eCnWm/src/machines.jl:231
错误：ArgumentError：“Matrix{Float64}”不是表；有关将 AbstractVecOrMat 视为表的方法，请参阅“?Tables.table”
堆栈跟踪：
  [1] 列(m::Matrix{Float64})
    @表〜/.julia/packages/Tables/NSGZI/src/matrix.jl:6
  [2] Tables.Columns(x::Matrix{Float64})
    @表〜/.julia/packages/Tables/NSGZI/src/Tables.jl:271
  [3] 矩阵(表::Matrix{Float64};转置::Bool)
    @表〜/.julia/packages/Tables/NSGZI/src/matrix.jl:85
  [4] 矩阵(表::矩阵{Float64})
    @表〜/.julia/packages/Tables/NSGZI/src/matrix.jl:84
  [5] 重新格式化(::MLJDecisionTreeInterface.RandomForestRegressor, X::Matrix{Float64}, y::Vector{Any})
    @ MLJDecisionTreeInterface ~/.julia/packages/MLJDecisionTreeInterface/kPIDf/src/MLJDecisionTreeInterface.jl:460
  [6] fit_only!(mach::Machine{…}; rows::Nothing，verbosity::Int64，force::Bool，composite::Nothing)
    @ MLJBase ~/.julia/packages/MLJBase/eCnWm/src/machines.jl:659
  [7] 只适合！
    @ MLJBase ~/.julia/packages/MLJBase/eCnWm/src/machines.jl:607 [内联]
  [8] #适合！#63
    @ MLJBase ~/.julia/packages/MLJBase/eCnWm/src/machines.jl:778 [内联]
  [9] 适合！
    @ MLJBase ~/.julia/packages/MLJBase/eCnWm/src/machines.jl:775 [内联]
 [10] |&gt;(x::Machine{MLJDecisionTreeInterface.RandomForestRegressor, true}, f::typeof(StatsAPI.fit!))
    @基地./operators.jl:917
 [11] Mainf()
    @主要~/Code/JuliaML/src/dt.jl:53
 [12] 顶级范围
    @〜/代码/JuliaML/src/dt.jl:58
某些类型信息被截断。使用 show(err) 查看完整类型。

它不适用于 MLJ.jl。我想使用 RandomForestRegressor 预测一个包含 5 或 6 个浮点数的向量，模型必须是 RF。]]></description>
      <guid>https://stackoverflow.com/questions/78116043/can-not-find-a-model-in-mlj-suitable-for-my-data-type</guid>
      <pubDate>Wed, 06 Mar 2024 16:41:59 GMT</pubDate>
    </item>
    <item>
      <title>我在尝试运行高级自动训练时遇到错误</title>
      <link>https://stackoverflow.com/questions/78115600/i-am-getting-an-error-while-trying-to-run-autotrain-advanced</link>
      <description><![CDATA[我使用 Llama-2-7B-Chat-Hf 模型作为基础，Orca Math Word Problems 作为训练数据。我遇到错误 - UnicodeDecodeError: &#39;utf-8&#39; 编解码器无法解码位置 7 中的字节 0x92: 无效的起始字节。
如何解决这个问题？
这是我尝试的图像 - 我尝试构建的图像&lt; /p&gt;
这是完整的错误：
回溯（最近一次调用最后一次）：
  文件“/app/env/lib/python3.10/site-packages/uvicorn/protocols/http/h11_impl.py”，第 428 行，在 run_asgi 中
    结果=等待应用程序（＃类型：忽略[func-returns-value]
  文件“/app/env/lib/python3.10/site-packages/uvicorn/middleware/proxy_headers.py”，第 78 行，在 __call__ 中
    返回等待 self.app（范围，接收，发送）
  文件“/app/env/lib/python3.10/site-packages/fastapi/applications.py”，第 1106 行，在 __call__ 中
    等待超级（）.__call__（范围，接收，发送）
  文件“/app/env/lib/python3.10/site-packages/starlette/applications.py”，第 122 行，在 __call__ 中
    等待 self.middleware_stack（范围，接收，发送）
  文件“/app/env/lib/python3.10/site-packages/starlette/middleware/errors.py”，第 184 行，在 __call__ 中
    提高执行力
  文件“/app/env/lib/python3.10/site-packages/starlette/middleware/errors.py”，第 162 行，在 __call__ 中
    等待 self.app（范围，接收，_发送）
  文件“/app/env/lib/python3.10/site-packages/starlette/middleware/sessions.py”，第 86 行，在 __call__ 中
    等待 self.app（范围，接收，send_wrapper）
  文件“/app/env/lib/python3.10/site-packages/starlette/middleware/exceptions.py”，第 79 行，在 __call__ 中
    提高执行力
  文件“/app/env/lib/python3.10/site-packages/starlette/middleware/exceptions.py”，第 68 行，在 __call__ 中
    等待 self.app（范围、接收、发送者）
  文件“/app/env/lib/python3.10/site-packages/fastapi/middleware/asyncexitstack.py”，第 20 行，在 __call__ 中
    提高e
  文件“/app/env/lib/python3.10/site-packages/fastapi/middleware/asyncexitstack.py”，第 17 行，在 __call__ 中
    等待 self.app（范围、接收、发送）
  文件“/app/env/lib/python3.10/site-packages/starlette/routing.py”，第 718 行，在 __call__ 中
    等待route.handle（范围，接收，发送）
  文件“/app/env/lib/python3.10/site-packages/starlette/routing.py”，第 276 行，在句柄中
    等待 self.app（范围、接收、发送）
  文件“/app/env/lib/python3.10/site-packages/starlette/routing.py”，第 66 行，在应用程序中
    响应=等待函数（请求）
  文件“/app/env/lib/python3.10/site-packages/fastapi/routing.py”，第 274 行，在应用程序中
    raw_response = 等待 run_endpoint_function(
  文件“/app/env/lib/python3.10/site-packages/fastapi/routing.py”，第 191 行，在 run_endpoint_function 中
    返回等待 dependent.call(**值)
  文件“/app/env/lib/python3.10/site-packages/autotrain/app.py”，第 452 行，handle_form
    dset = AutoTrainDataset(**dset_args)
  文件“”，第 13 行，位于 __init__ 中
  文件“/app/env/lib/python3.10/site-packages/autotrain/dataset.py”，第 204 行，在 __post_init__ 中
    self.train_df, self.valid_df = self._preprocess_data()
  文件“/app/env/lib/python3.10/site-packages/autotrain/dataset.py”，第 213 行，位于 _preprocess_data
    train_df.append(pd.read_csv(文件))
  文件“/app/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py”，第 1026 行，在 read_csv 中
    返回_read（文件路径或缓冲区，kwds）
  文件“/app/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py”，第 620 行，在 _read 中
    解析器 = TextFileReader(filepath_or_buffer, **kwds)
  文件“/app/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py”，第 1620 行，位于 __init__ 中
    self._engine = self._make_engine(f, self.engine)
  文件“/app/env/lib/python3.10/site-packages/pandas/io/parsers/readers.py”，第 1898 行，在 _make_engine 中
    返回映射[引擎](f, **self.options)
  文件“/app/env/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py”，第 93 行，在 __init__ 中
    self._reader = parsers.TextReader(src, **kwds)
  文件“parsers.pyx”，第 574 行，位于 pandas._libs.parsers.TextReader.__cinit__ 中
  文件“parsers.pyx”，第 663 行，位于 pandas._libs.parsers.TextReader._get_header
  文件“parsers.pyx”，第 874 行，位于 pandas._libs.parsers.TextReader._tokenize_rows 中
  文件“parsers.pyx”，第 891 行，位于 pandas._libs.parsers.TextReader._check_tokenize_status
  文件“parsers.pyx”，第 2053 行，位于 pandas._libs.parsers.raise_parser_error
UnicodeDecodeError：“utf-8”编解码器无法解码位置 7 中的字节 0x92：起始字节无效
]]></description>
      <guid>https://stackoverflow.com/questions/78115600/i-am-getting-an-error-while-trying-to-run-autotrain-advanced</guid>
      <pubDate>Wed, 06 Mar 2024 15:30:30 GMT</pubDate>
    </item>
    <item>
      <title>使用自然语言处理自动标题分组[关闭]</title>
      <link>https://stackoverflow.com/questions/78115517/automatic-headline-grouping-with-natural-language-processing</link>
      <description><![CDATA[我正在开发一个网络应用程序，该应用程序可以抓取金融文章并将其分类为“事件”。我对来自不同来源的约 200 篇文章进行了网络抓取。我想使用 NLP 模型将这些文章分组为“事件”并提供从文章中生成的摘要。
例如，假设一位首席执行官被解雇，并且有 10 / 200 篇关于该事件的文章，我称之为事件。我希望模型自动将文章分组为 n 个事件。
我不确定从哪里开始，因为我发现的大多数文本分组都需要我设置类别数。]]></description>
      <guid>https://stackoverflow.com/questions/78115517/automatic-headline-grouping-with-natural-language-processing</guid>
      <pubDate>Wed, 06 Mar 2024 15:18:56 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程数据错误</title>
      <link>https://stackoverflow.com/questions/78115412/gaussian-process-data-errors</link>
      <description><![CDATA[如何在matlab的fitrgp函数中插入误差数组来进行高斯过程回归？我有一个数组 x、其他数组 y 以及与 y 关联的标准差数组 delta_y。
只有 x 和 y，我可以使用 gprMdl = fitrgp(x,y)，但如何添加 delta_y 数组作为 y 的误差条？]]></description>
      <guid>https://stackoverflow.com/questions/78115412/gaussian-process-data-errors</guid>
      <pubDate>Wed, 06 Mar 2024 15:02:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在 RGB 图像中应用多头注意力？</title>
      <link>https://stackoverflow.com/questions/78115215/how-to-apply-multiheadattention-in-rgb-image</link>
      <description><![CDATA[我想在卷积网络中使用多头注意力。
将(3,360,360)（RGB、高、宽）的图像作为多头注意力的输入，然后连接到Conv2d。但我有一些问题。
首先，从输入为 2D（seq、embedding 或 d_model）的情况开始，如 (6, 512)。
shape = (6,512) #（seq、嵌入或 d_model）
# 定义输入层
输入矩阵=输入（形状=形状）

# 使用 MultiHeadAttention 进行自注意力
层= MultiHeadAttention（num_heads = 4，key_dim = 2，use_bias = False）
注意输出，权重=层（输入矩阵，输入矩阵，return_attention_scores = True）

# 创建模型
模型 = tf.keras.Model(输入=input_matrix, 输出=attention_output)

weight_names = [&#39;查询&#39;, &#39;键&#39;, &#39;值&#39;, &#39;项目&#39;]
对于名称，在 zip(weight_names,layer.get_weights()) 中输出：
    print(名称, 输出形状)
打印（权重.形状）
--------------------
查询 (512, 4, 2) （为什么这里是嵌入数？, Heads, d_k）
键（512、4、2）
值 (512, 4, 2)
项目 (4, 2, 512)
（无、4、6、6）（批次、头、seq、seq）

这有助于我理解。
在此处输入图像描述
这是我的代码
将张量流导入为 tf
从tensorflow.keras.layers导入输入、Conv2D、MultiHeadAttention、Reshape
从tensorflow.keras导入后端
backend.set_image_data_format(&#39;channels_first&#39;)

形状 = (3,450,450) # (RGB, 高, 宽)
# 定义输入层
输入矩阵=输入（形状=形状）

# 使用 MultiHeadAttention 进行自注意力
层= MultiHeadAttention（num_heads = 4，key_dim = 2，use_bias = False，attention_axes =（1,2））
注意输出，权重=层（输入矩阵，输入矩阵，return_attention_scores = True）

# 使用Conv2D进行卷积运算
conv_output = Conv2D(filters=128, kernel_size=(2, 2),strides=(2,2),activation=&#39;relu&#39;)(attention_output)

# 创建模型
模型= tf.keras.Model（输入= input_matrix，输出= conv_output）

它可以运行，但我不确定它是否按照我的想法运行。因为权重（q，k，v）和attention_scores维度让我很困惑。首先，我认为 (None, 4, 3, 450, 3, 450) 应该是 (None, 4, 450, 450, 450, 450) (batch, Heads, height, width, height, width)，类似于 ( None,4,6,6)(batch,heads,seq,seq)，表示单词之间的关系。图像大小应该代表像素之间的关系。我该如何修改我的代码？其次，为什么权重(q,k,v)的维度没有改变？
weight_names = [&#39;查询&#39;, &#39;键&#39;, &#39;值&#39;, &#39;项目&#39;]
对于名称，在 zip(weight_names,layer.get_weights()) 中输出：
    print(名称, 输出形状)
打印（权重.形状）
--------------------------------
查询 (450, 4, 2)
键（450、4、2）
值（450、4、2）
项目（4、2、450）
（无、4、3、450、3、450）
]]></description>
      <guid>https://stackoverflow.com/questions/78115215/how-to-apply-multiheadattention-in-rgb-image</guid>
      <pubDate>Wed, 06 Mar 2024 14:34:58 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降权重不断变大</title>
      <link>https://stackoverflow.com/questions/78115138/gradient-descent-weights-keep-getting-larger</link>
      <description><![CDATA[为了熟悉梯度下降算法，我尝试创建自己的线性回归模型。对于少数数据点来说它效果很好。但是当尝试使用更多数据来拟合它时，w0 和 w1 的大小总是增加。有人可以解释一下这种现象吗？
类线性回归：
    def __init__(自身, x_向量, y_向量):

        self.x_vector = np.array(x_vector, dtype=np.float64)
        self.y_向量 = np.array(y_向量, dtype=np.float64)
        自身.w0 = 0
        自身.w1 = 0

    def _get_predicted_values(self, x):
        公式 = lambda x: self.w0 + self.w1 * x
        返回公式(x)

    def_get_gradient_matrix（自身）：
        预测 = self._get_predicted_values(self.x_vector)
        w0_hat = sum((self.y_向量 - 预测))
        w1_hat = sum((self.y_向量 - 预测) * self.x_向量)

        梯度矩阵 = np.array([w0_hat, w1_hat])
        梯度矩阵 = -2 * 梯度矩阵

        返回梯度矩阵

    def fit(自我，step_size=0.001，num_iterations=500)：
        for _ in range(1, num_iterations):
            梯度矩阵 = self._get_gradient_matrix()
            self.w0 -= 步长大小 * (梯度矩阵[0])
            self.w1 -= 步长大小 * (梯度矩阵[1])

    def _show_coeffiecients（自身）：
        print(f&quot;w0: {self.w0}\tw1: {self.w1}\t&quot;)

    def 预测（自身，x）：
        y = 自身.w0 + 自身.w1 * x
        返回y

# 这工作正常
x = [x 表示 x 在范围 (-3, 3) 内]
f = 拉姆达 x: 5 * x - 7
y = [f(x_val) for x_val in x]

模型 = 线性回归(x, y)
模型.fit(num_iterations=3000)

model.show_coeffiecients() #输出：w0：-6.99999999999994 w1：5.00000000000002

#虽然这不是
x = [x for x in range(-50, 50)] # 增加 x 值的数量
f = 拉姆达 x: 5 * x - 7
y = [f(x_val) for x_val in x]

模型 = 线性回归(x, y)
模型.fit(num_iterations=3000)

model.show_coefficients()

最后一行产生警告：
运行时警告：乘法中遇到溢出
w1_hat = sum((self.y_向量 - 预测) * self.x_向量)
公式 = lambda x: self.w0 + self.w1 * x
]]></description>
      <guid>https://stackoverflow.com/questions/78115138/gradient-descent-weights-keep-getting-larger</guid>
      <pubDate>Wed, 06 Mar 2024 14:22:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用自定义选择器正确堆叠 sklearn 管道</title>
      <link>https://stackoverflow.com/questions/78114397/how-to-correctly-stack-sklearn-pipeline-with-custom-selector</link>
      <description><![CDATA[我想使用 sklearn 中的 StackingClassifier 类来创建一个集成学习器。
具体来说，我有两种不同类型的数据：二维图像和经典表格数据。我想对 2D 图像使用 MLP 分类器，对表格数据使用 RandomForest 分类器。然后我想使用随机森林分类器将上述两个模型的预测结合到我的最终预测中。
由于无法为 StackingClassifier 实例提供单独的训练数据，我采用了以下技巧：我使用自定义选择器创建了两个 Pipeline从字典返回一个值。虽然我可以单独拟合和预测管道，但当我尝试拟合和预测堆叠模型时，出现了 ValueError: Found input Variables with不一致数量的样本。
下面是我使用的代码：
将 numpy 导入为 np
从 sklearn.model_selection 导入 train_test_split
从 sklearn.neural_network 导入 MLPClassifier
从 sklearn.base 导入 BaseEstimator、TransformerMixin
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.ensemble 导入 StackingClassifier
从 sklearn.datasets 导入 load_iris
从 sklearn.metrics 导入 precision_score
从 sklearn.pipeline 导入管道

#定制选择器
类 DictionarySelector(BaseEstimator, TransformerMixin):
    def __init__(self, in_dict, key):

        self.in_dict = in_dict
        self.key = 密钥
        
    def fit(self, x, y = None):
        返回（自己）
    
    def 变换（自身，键）：
        return(self.in_dict[self.key])
    
    
        

# 生成一些示例数据
# 出于演示目的，我使用 Iris 数据集
数据 = load_iris()
X_images = data.data[:, :2] # 假设这些是我的图像
X_vector = data.data[:, 2:] # 一维向量
y = data.target # 目标类（3类）

# 将数据分为训练集和测试集
X_images_train，X_images_test，X_vector_train，X_vector_test，y_train，y_test = train_test_split（
    X_图像、X_向量、y、test_size=0.2、random_state=42
）

# 定义图像的 MLP
image_model = MLPClassifier(hidden_​​layer_sizes=(64, 32), 激活=“relu”, max_iter=1000)

# 定义向量的随机森林
矢量模型 = RandomForestClassifier(n_estimators=100, criteria=“基尼”, max_depth=None)
#用两种数据类型创建字典
in_dict = {&#39;图像&#39;：X_images_train，&#39;矢量&#39;：X_vector_train}
#MLP 图像管道
管道图像=管道（[
    (&#39;选择&#39;, DictionarySelector(in_dict, &#39;图像&#39;)),
    （&#39;clf&#39;，图像模型）
]）

#检查：它有效
打印（pipe_images.fit（X_images_train，y_train）.预测（X_images_test））

#特征管道
管道向量=管道（[
    (&#39;选择&#39;, DictionarySelector(in_dict, &#39;向量&#39;)),
    （&#39;clf&#39;，向量模型）
]）
#检查：它有效
打印（pipe_images.fit（X_vector_train，y_train）.predict（X_vector_test））

# 创建一个堆叠模型
stacked_model = StackingClassifier(
    估计量=[
        （“image_mlp”，pipe_images），
        (“向量_rf”，管道_向量)，
    ],
    Final_estimator=RandomForestClassifier(n_estimators=100),
）

#堆叠模型抛出ValueError
stacked_model.fit(in_dict, y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/78114397/how-to-correctly-stack-sklearn-pipeline-with-custom-selector</guid>
      <pubDate>Wed, 06 Mar 2024 12:29:37 GMT</pubDate>
    </item>
    <item>
      <title>为每月数据编写时间滞后，以合并训练测试分割模型的情绪和市场分析[关闭]</title>
      <link>https://stackoverflow.com/questions/78113308/coding-a-time-lag-for-monthly-data-to-merge-a-sentiment-and-market-analysis-for</link>
      <description><![CDATA[我们的教授为我们提供了以下代码：
代码1：
sentiment=pd.read_csv(&#39;/content/drive/MyDrive/Colab Notebooks/Python Code/Sentiment_quarterly.csv&#39;).drop(&#39;未命名：0&#39;,axis=1)
情绪
从日期时间导入日期时间
数据[&#39;数据&#39;]=0

代码2：
for k in tqdm(range(len(data[&#39;Datum&#39;])))：
    test_date=str(int(data.loc[k,&#39;bewertungsjahr&#39;]))+&#39;.&#39;+str(int(data.loc[k,&#39;bewertungsquartal&#39;]*3))
    data.loc[k,&#39;Datum&#39;]=str(pd.Timestamp(datetime.strptime(test_date, &#39;%Y.%m&#39;).date()).to_period(&#39;Q&#39;))

数据[&#39;数据&#39;][0]

代码3：
for k in tqdm(range(len(sentiment[&#39;Time&#39;]))):
    test_date=str(int(sentiment.loc[k,&#39;时间&#39;][0:4]))+&#39;.&#39;+str(int(sentiment.loc[k,&#39;时间&#39;][5])*3)
    情感.loc[k,&#39;Time&#39;]=pd.Timestamp(datetime.strptime(test_date, &#39;%Y.%m&#39;).date()).to_period(&#39;Q&#39;)

情绪[&#39;时间&#39;][0]

我们不想使用季度情绪.csv，而是使用每月.csv
季度数据中的时间格式是例如2014Q1 和月度数据显示 2014-01、2014-02...
如何调整代码以使其正常工作？
我尝试添加此&#39;.&#39;+str(int(data.loc[k,&#39;bewertungsquartal&#39;]*12))，这样也许还需要考虑几个月。]]></description>
      <guid>https://stackoverflow.com/questions/78113308/coding-a-time-lag-for-monthly-data-to-merge-a-sentiment-and-market-analysis-for</guid>
      <pubDate>Wed, 06 Mar 2024 09:47:41 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降最小二乘代码问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78112607/problem-with-gradient-descent-least-squares-code</link>
      <description><![CDATA[我正在尝试在数据集上使用梯度下降。我写的是
&lt;前&gt;&lt;代码&gt;导入numpy
将 pandas 导入为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

数据 = pd.read_csv(&#39;C:/Users/Teacher/Downloads/data.csv&#39;)
X = data.iloc[:, 0] # 选择 data 中第一列的所有数据
Y = data.iloc[:, 1]
plt.scatter(X,Y)
plt.show()
n = 长度 (X)

a = 0
b = 0
L = .001

对于范围（1000）内的 i：
    y_预测 = a * X + b
    pd_a = (1 / n) * sum((y_预测 - Y) * X)
    pd_b = (1 / n) * sum(y_预测 - Y)
    a = a - L * pd_a
    b = b - L * pd_b
打印（a，b）
plt.scatter(X, Y)
c, d = numpy.polyfit(X, Y, 1)
打印（c，d）
plt.plot([min(X), max(X)], [a * x + b for x in [min(X), max(X)]], [c * x + d for x in [min( X), 最大值(X)]])
plt.show()

如果我定义 X 和 Y = np.random.rand(20)，那么一切似乎都工作正常，所以问题似乎出在 csv 的输入上。
然而，X 和 Y 的散点图仍然很好，即使我将它们定义为数据集的第一列和第二列，所以我不确定发生了什么。
编辑：这是定义 X = data.iloc[:, 0] 后的散点图图像
Y = data.iloc[:, 1]

这是代码末尾的绘图和线条的图像。

print(data.head())的结果：

编辑：仅读取 csv 的一行：

]]></description>
      <guid>https://stackoverflow.com/questions/78112607/problem-with-gradient-descent-least-squares-code</guid>
      <pubDate>Wed, 06 Mar 2024 07:48:04 GMT</pubDate>
    </item>
    <item>
      <title>如何消除在张量流的 Tape.gradient 方法中将虚数转换为实值的警告？</title>
      <link>https://stackoverflow.com/questions/77185089/how-to-remove-this-warning-of-casting-imaginary-into-real-values-within-tape-gra</link>
      <description><![CDATA[我正在使用tape.gradient方法来优化一些神经网络。它按预期工作，但当我在单次迭代中多次使用 Tape.gradients 计算梯度时，不断发出此警告。这意味着在单个循环内，在执行 back prop 时，它会在某个地方摆弄复数。
警告：tensorflow：您正在将complex64类型的输入转换为不兼容的dtype float64。这将丢弃虚部，并且可能不是您想要的。

cost_progress=[]
跟踪进度=[]
对于我在范围内（次数）：

  使用 tf.GradientTape() 作为磁带：
    磁带.watch(参数)
    损失，跟踪 = 成本（参数，比率）
    trace_progress.append(trace)
    cost_progress.append(损失)

  梯度 = Tape.gradient(loss, params)
  opt.apply_gradients(zip([渐变], [参数]))

现在，所有参数和损失都是 tf.float64，但仍在 Tape.gradient() 中给出了一些复杂类型，我想手动将它们转换为真实值，以便此警告停止显示在我的屏幕上。但我无法找到如何投射以免弄乱。
强制gradients = tf.cast(tape.gradient(loss, params),tf.float64)不起作用。我已验证 gradients = Tape.gradient(loss, params) 发出警告，并且 loss 和 params 均为 tf.float64 类型。]]></description>
      <guid>https://stackoverflow.com/questions/77185089/how-to-remove-this-warning-of-casting-imaginary-into-real-values-within-tape-gra</guid>
      <pubDate>Wed, 27 Sep 2023 06:26:47 GMT</pubDate>
    </item>
    <item>
      <title>Handpose tfjs 错误 - 在注册表中找不到后端</title>
      <link>https://stackoverflow.com/questions/62134812/handpose-tfjs-error-no-backend-found-in-registry</link>
      <description><![CDATA[尝试运行 Handpose tfjs 演示项目时，出现以下错误。

我的 package.json 文件具有以下依赖项：

&lt;前&gt;&lt;代码&gt;{
“名称”：“tensorflowJs”，
“版本”：“1.0.0”，
“描述”： ””，
“主要”：“index.js”，
“脚本”：{
  &quot;watch&quot;: &quot;跨环境 NODE_ENV=开发包index.html --no-hmr &quot;,
  &quot;build&quot;: &quot;cross-env NODE_ENV=生产包构建index.html --public-url ./&quot;
 },
“浏览器”：{
“加密”：假
 },
“关键字”：[]，
“作者”： ””，
“许可证”：“ISC”，
“依赖项”：{
  “@tensorflow-models/handpose”：“0.0.4”，
  &quot;@tensorflow/tfjs-backend-wasm&quot;: &quot;^2.0.0&quot;,
  &quot;@tensorflow/tfjs-converter&quot;: &quot;^1.7.4&quot;,
  &quot;@tensorflow/tfjs-core&quot;: &quot;^2.0.0&quot;,
  &quot;@tensorflow/tfjs-node&quot;: &quot;^2.0.0&quot;,
  &quot;引导程序&quot;: &quot;^4.5.0&quot;,
  “跨环境”：“^7.0.2”
 },
“开发依赖项”：{
  &quot;@babel/cli&quot;: &quot;^7.10.1&quot;,
  &quot;@babel/core&quot;: &quot;^7.10.2&quot;,
  &quot;@babel/plugin-transform-runtime&quot;: &quot;^7.10.1&quot;,
  &quot;@babel/polyfill&quot;: &quot;^7.10.1&quot;,
  &quot;@babel/preset-env&quot;: &quot;^7.10.2&quot;,
  &quot;babel-preset-env&quot;: &quot;^1.7.0&quot;,
  “包裹捆绑器”：“^1.12.4”
 }
}

注册表问题应该在版本 0.10.3 之后得到解决，但即使对于版本 2，我仍然面临这个问题。有谁知道为什么会出现这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/62134812/handpose-tfjs-error-no-backend-found-in-registry</guid>
      <pubDate>Mon, 01 Jun 2020 14:46:38 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程的平方协方差函数</title>
      <link>https://stackoverflow.com/questions/44085001/squared-covariance-function-of-gaussian-process</link>
      <description><![CDATA[这是我第一次尝试编写协方差函数。我有以下价值观，
&lt;预&gt;&lt;代码&gt;x = [-1.50 -1.0 -.75 -.40 -.25 0.00];
SF=1.27；
埃尔 = 1;
SN = 0.3;

平方指数协方差函数的公式为

我编写的 matlab 代码为：
K = sf^2*exp(-0.5*(squareform(pdist(x)).^2)/ell^2)+(sn)^2*eye(Ntr,Ntr);

其中，sf 是信号标准差，ell 是特征长度尺度，sn 是噪声标准差，Ntr code&gt; 训练输入数据的长度x。
但这没有给我任何结果。我的编码有什么错误吗？
一旦我计算出来，我想总结成矩阵形式，如下所示，

如果x_ = 0.2那么我们如何计算：
a) K_ =[k(x_,x1) k(x_,x2).........k(x_,xn)] 和 
b) K__ = k(x_,x_)
使用matlab？]]></description>
      <guid>https://stackoverflow.com/questions/44085001/squared-covariance-function-of-gaussian-process</guid>
      <pubDate>Sat, 20 May 2017 10:53:42 GMT</pubDate>
    </item>
    </channel>
</rss>