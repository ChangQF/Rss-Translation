<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 24 Sep 2024 09:18:28 GMT</lastBuildDate>
    <item>
      <title>如何练习机器学习技能</title>
      <link>https://stackoverflow.com/questions/79017837/how-to-practice-ml-skills</link>
      <description><![CDATA[我是一名 IT 专业人士，有 Python 经验，对机器学习也有过短暂的了解。我渴望更深入地研究机器学习领域；但是，到目前为止，我从事的项目并没有重点关注机器学习。如果您能就如何练习我的机器学习技能以及我应该涵盖哪些关键概念才能在这个领域脱颖而出提出建议，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/79017837/how-to-practice-ml-skills</guid>
      <pubDate>Tue, 24 Sep 2024 09:10:57 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型预测训练标签本身作为结果[关闭]</title>
      <link>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</link>
      <description><![CDATA[我正在尝试根据具有“消息”、“尾巴”和“手指”特征的数据构建一个模型来预测“物种”，并标记“物种”（参见下面 data.csv 的前几行）：



消息
手指
尾巴
物种




pluvia arbor aquos
4
no
Aquari


cosmix xeno nebuz odbitaz
5
是
Zorblax


solarix glixx novum galaxum quasar
5
是
Zorblax


arborsectus pesros ekos dootix nimbus
2
是
Florian



我的代码是：
import warnings
warnings.simplefilter(&quot;ignore&quot;)
import pandas as pd
import numpy as np
将 matplotlib.pyplot 导入为 plt
从 sklearn.preprocessing 导入 LabelEncoder
从 sklearn.feature_extraction.text 导入 CountVectorizer
从 sklearn.naive_bayes 导入 MultinomialNB

df = pd.read_csv(&quot;data.csv&quot;)
X = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
X = [str (item) for item in X]
y = df[&quot;species&quot;]

le = LabelEncoder()
y = le.fit_transform(y)

cv = CountVectorizer()
X = cv.fit_transform(X).toarray()

model = MultinomialNB()
model.fit(X, y)

test_data = pd.read_csv(&#39;test.csv&#39;)
test_data_array = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
test_data_array = [str (item) for item in test_data_array]
test_data_array = cv.fit_transform(test_data_array).toarray()

y_prediction = model.predict(test_data_array)
y_prediction = le.inverse_transform(y_prediction)

print(y_prediction)

我按照本教程进行操作一样。
问题是，当我尝试运行它时，除了一些差异外，它只是逐字逐句地输出原始训练数据的物种列（有 493 个结果，而测试数据包含 299 个条目，训练数据包含 500 个条目）。它实际上并没有为测试数据预测任何内容。我不明白为什么代码不起作用。有人能帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</guid>
      <pubDate>Tue, 24 Sep 2024 04:08:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 smote 将过采样数据存储在单独的变量中？</title>
      <link>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</link>
      <description><![CDATA[如何使用 smote 在单独的变量中存储过采样数据？
import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
dataset = pd.read_csv(&#39;https://archive.ics.uci.edu/static/public/17/data.csv&#39;)
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values
le = LabelEncoder()
y = le.fit_transform(y)
smt = SMOTE()
X1, y1 = smt.fit_resample(X, y)
#使用 smote 在单独的变量中过采样数据
#X2 = ?
#y2 = ?

]]></description>
      <guid>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</guid>
      <pubDate>Tue, 24 Sep 2024 04:07:41 GMT</pubDate>
    </item>
    <item>
      <title>CRM潜在客户评分机器学习模型</title>
      <link>https://stackoverflow.com/questions/79016613/crm-lead-scoring-machine-learning-model</link>
      <description><![CDATA[Crm 初创企业潜在客户评分模型。
我们正在开发一个 crm 工具，下面是挑战。
我正在研究 ml 部分，我们有一系列
要实施的事情，其中​​首先是潜在客户评分，然后是客户细分、客户流失预测和销售预测。

冷启动，我们没有任何历史数据。
在这里，我们正在开发一种工具，该工具应该服务于不同领域的不同客户。所以我们可以使用一个单一的模型，还是我们需要为每个客户开发单独的模型。

如果我们对所有客户使用一个大型模型，请推荐使用哪些模型。]]></description>
      <guid>https://stackoverflow.com/questions/79016613/crm-lead-scoring-machine-learning-model</guid>
      <pubDate>Tue, 24 Sep 2024 00:20:12 GMT</pubDate>
    </item>
    <item>
      <title>在语言检测中使用数组作为特征时出现 KeyError</title>
      <link>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</link>
      <description><![CDATA[我正在按照此教程使用机器学习进行语言检测。然而，在我使用的数据集中，有多个变量作为特征。我尝试用 X = data[&quot;Text&quot;] 代替 X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]（message、fingers 和 tail 是我正在使用的三个特征变量），但它会抛出 KeyError；
Traceback（最近一次调用最后一次）：
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;，第 3805 行，在 get_loc
return self._engine.get_loc(casted_key)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;index.pyx&quot;，第 167 行，在pandas._libs.index.IndexEngine.get_loc
文件“index.pyx”，第 196 行，位于 pandas._libs.index.IndexEngine.get_loc
文件“pandas\\_libs\\hashtable_class_helper.pxi”，第 7081 行，位于 pandas._libs.hashtable.PyObjectHashTable.get_item
文件“pandas\\_libs\\hashtable_class_helper.pxi”，第 7089 行，位于 pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

上述异常是导致以下异常的直接原因：

回溯（最近一次调用）：
文件&lt;module&gt; 中的 &quot;c:\Users\usr\Downloads\thecode.py&quot;，第 13 行
X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]
~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py&quot;, 第 4102 行, 位于 __getitem__
indexer = self.columns.get_loc(key)
^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;, 第 3812 行, 位于 get_loc
引发 KeyError(key) err
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

我应该如何实现代码才能使用所有功能而不抛出错误？]]></description>
      <guid>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</guid>
      <pubDate>Mon, 23 Sep 2024 22:15:21 GMT</pubDate>
    </item>
    <item>
      <title>使用斑点检测/openCV 计算黑色圆形种子数量</title>
      <link>https://stackoverflow.com/questions/79016356/counting-black-round-seeds-with-blob-detection-opencv</link>
      <description><![CDATA[我没有接受过 CV 方面的培训，但我想尝试一下 OpenCV 或类似技术，以便能够计算简单的黑色球体（种子，在本例中为拟花椒）。
其他时候，种子中间的白色反射较少，但主要特征是它是“圆形”的、黑色的，几乎总是具有相同的尺寸，并且可以（或有时没有）一个白色的小斑点。





我应该从哪里开始才能让 5 张照片的种子数量大致相同（或者最好是完全相同）？（种子数量相同，我只是在拍摄照片之间摇晃了一下容器）
CV 还是 ML？从哪里开始？
附言：如果有帮助，我也可以尝试物理去除较小的黑色棍子和不好的种子……但理论上，如果可以有可靠的方法可以忽略这些小的“非种子”暗元素，那就太好了……
附言：如果这也能有帮助，我还可以修改拍照的方式……]]></description>
      <guid>https://stackoverflow.com/questions/79016356/counting-black-round-seeds-with-blob-detection-opencv</guid>
      <pubDate>Mon, 23 Sep 2024 21:30:43 GMT</pubDate>
    </item>
    <item>
      <title>量化和混合精度训练</title>
      <link>https://stackoverflow.com/questions/79016046/quantization-and-mixed-precision-training</link>
      <description><![CDATA[如果我使用 bitsandbytes 加载 4 位量化模型，那么使用 fp16 的混合精度训练是否有用，因为我认为混合精度训练会将我的 4 位量化权重膨胀为 16 位精度？如何并行使用量化和混合精度训练？
我尝试使用 fp16 的混合精度训练进行 4 位量化。我这样做的目的是在内存有限的环境中微调 colab 中的 LLM]]></description>
      <guid>https://stackoverflow.com/questions/79016046/quantization-and-mixed-precision-training</guid>
      <pubDate>Mon, 23 Sep 2024 19:33:46 GMT</pubDate>
    </item>
    <item>
      <title>有人知道如何修复库错误吗？</title>
      <link>https://stackoverflow.com/questions/79015388/does-anyone-know-how-to-fix-library-error</link>
      <description><![CDATA[我遇到了这个错误，尝试了所有方法，但还是无法解决：
ModuleNotFoundError Traceback (most recent call last)
&lt;ipython-input-13-6c7180fd4822&gt; in &lt;cell line: 1&gt;()
----&gt; 1 from crewapi_module import CrewAPI # 用正确的导入路径替换
2 
3 crew_api = CrewAPI(api_key=&quot;your_crewai_api_key&quot;)
4 
5 # 现在您可以与 API 交互，例如：

ModuleNotFoundError：没有名为“crewapi_module”的模块
]]></description>
      <guid>https://stackoverflow.com/questions/79015388/does-anyone-know-how-to-fix-library-error</guid>
      <pubDate>Mon, 23 Sep 2024 15:52:13 GMT</pubDate>
    </item>
    <item>
      <title>受不同聚类大小约束的 KMeans</title>
      <link>https://stackoverflow.com/questions/79015120/kmeans-constrained-with-different-cluster-size</link>
      <description><![CDATA[我有一个包含商店坐标的数据框，我想根据供应商应该访问该商店的日期将它们划分为簇。例如，假设供应商应该访问 180 家商店。他应该在周一到周五访问 30-34 家商店，周六，他应该访问其他日子的 60%。
我该怎么做？使用 kmeans-constrained，我只能将它们划分为大小相等的簇。也许我需要使用某种解算器或在集群之间移动点以达到我想要的数字，但我不知道如何做到这一点。
以下是将它们均等划分的代码：
# 循环遍历供应商集群
for vendor in df[&quot;vendor&quot;].unique():

# 每个供应商的商店数量
n_shops = df.loc[df[&quot;vendor&quot;] == vendor][&quot;cod_shop&quot;].count()

# 索引
idx = df.loc[df[&quot;vendor&quot;] == vendor].index

# 一周中各天的集群数量
num_clusters = 5 # 星期一至星期五

# 集群的平均大小
avg_size = n_shops / (num_clusters + 0.6)

# 定义限制
min_shops = round(avg_size - n_shops * pct, 0)
max_shops = math.ceil(avg_size + n_shops * pct)

# 模型
kmeans = KMeansConstrained(n_clusters=num_clusters, size_min=min_shops, size_max=max_shops, random_state=42)
labels = kmeans.fit_predict(df.loc[df[&quot;vendor&quot;] == vendor][[&quot;latitude&quot;, &quot;longitude&quot;]])

# 向数据框添加标签
df.loc[idx, &quot;visit_day&quot;] = labels
]]></description>
      <guid>https://stackoverflow.com/questions/79015120/kmeans-constrained-with-different-cluster-size</guid>
      <pubDate>Mon, 23 Sep 2024 14:42:09 GMT</pubDate>
    </item>
    <item>
      <title>图像拼接中的泊松混合导致图像模糊、鬼影重重</title>
      <link>https://stackoverflow.com/questions/79014990/poisson-blending-in-image-stitching-results-in-blurred-ghostly-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79014990/poisson-blending-in-image-stitching-results-in-blurred-ghostly-images</guid>
      <pubDate>Mon, 23 Sep 2024 14:11:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 NumPy 实现基本神经网络的问题</title>
      <link>https://stackoverflow.com/questions/79014083/problem-implementing-a-basic-neural-network-with-numpy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79014083/problem-implementing-a-basic-neural-network-with-numpy</guid>
      <pubDate>Mon, 23 Sep 2024 09:49:44 GMT</pubDate>
    </item>
    <item>
      <title>构建 OCR 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/79013996/building-ocr-model</link>
      <description><![CDATA[我正在研究一个机器学习模型，其中输入是图像和实体名称，目标是从图像中提取相应的实体值。例如，如果实体名称是“高度”，并且图像包含门的高度，则模型应提取此值（例如 6 英尺）以及正确的单位。
输入：
图像：包含对象（例如门）和相关信息（例如高度或其他相关测量值）。
实体名称：关键字，例如“高度”或“重量”，指定要从图像中提取的值。
输出：
与图像中的实体相对应的值及其单位（例如“6 英尺”）。
挑战：
实体值可以出现在图像的不同部分，具有不同的文本格式、字体或样式。
需要识别和提取测量单位（例如，米、英尺）以及值。
问题：

处理此类任务的最佳方法或模型架构是什么？
是否有任何特定技术或预训练模型可以帮助将图像和实体名称组合为输入，以从图像中提取相应的值？
我应该如何预处理图像和标签以训练此类任务的模型？
是否有任何关于框架和工具的指导、参考或建议？

我尝试使用带有 CTC 损失的 CNN+RNN，但我的损失接近 20 并且没有进一步减少
这里我附上了我的 google cloab 链接
笔记本链接]]></description>
      <guid>https://stackoverflow.com/questions/79013996/building-ocr-model</guid>
      <pubDate>Mon, 23 Sep 2024 09:27:35 GMT</pubDate>
    </item>
    <item>
      <title>将音频文件分割成块，跳过小于所需时间长度的块，并预测整个音频文件的情感</title>
      <link>https://stackoverflow.com/questions/76253683/split-an-audio-file-into-chunks-skip-the-chunks-less-than-desired-time-duration</link>
      <description><![CDATA[我正在将音频信号分类为情绪类，并使用 hugginface 的模型，该模型仅接收 8 秒的音频。所以我将音频分成 8 秒的文件。
我已将文件“A”分成 a1、a2、a3、a4、a5、a6、a7、a8
现在我使用该模型对每个音频进行分类，但我需要通过取文件 a1-a8 的预测平均值来找到音频文件“A”的总体类别。
我该怎么做，请帮帮我。
names = []
# 使用 Ridzuan/Audio_Emotion_Classifier(huggingface) 将音频文件的大小调整为 &lt;8 秒，以便进行预测
for file in tqdm(Path(&quot;D:/program/SER_DATA_sample/exg/&quot;).glob(&quot;**/*.wav&quot;)):
name = os.path.basename(file).split(&#39;.&#39;)[0]
names.append(names)
names_df = pd.DataFrame(names)

temp = name
path = []
audio_path = &#39;C:/Users/XTEND/PycharmProjects/DATA_EVAL/RESAMPLE/&#39;
dir_list = os.listdir(audio_path)
# label = os.path.basename(audio_path).split(&#39;_&#39;)[1].split(&#39;.&#39;)[0]

audio = AudioSegment.from_file(file)
length_audio = len(audio)
print(&quot;音频文件长度&quot;, length_audio)

start = 0
# 以毫秒为单位，这将截取 7 秒的音频
Threshold = 7000
end = 0
counter = 0
num_split = length_audio/threshold
print(num_split)

while start &lt; len(audio):
end += 阈值
print(start, end)
file = audio[start:end]
filename = f&#39;RESAMPLE/{counter}{name}.wav&#39;
file.export(filename, format=&quot;wav&quot;)
print(file)
counter += 1
start += 阈值

file_path = &#39;C:/Users/XTEND/PycharmProjects/DATA_EVAL/RESAMPLE/&#39;
# file_path = &#39;D:/program/XTEND_AUDIO_DATASET/ps/&#39;
dir_list = os.listdir(file_path)
number_files = len(dir_list)
print(number_files)

emo_df = []
routes = []
count = 1

for i in dir_list:
audio_data = file_path + i
routes.append(audio_data)
audio_path_df = pd.DataFrame(paths, columns=[&#39;Path&#39;])
count += 1
print(count, audio_data)

data_ori, sample_rate = librosa.load(audio_data)
data, _ = librosa.effects.trim(data_ori)

test = prepare_test(audio_data)
pred = classifier.predict(test)
pred_df = pd.DataFrame(pred.T, index=[&#39;anger&#39;, &#39;happiness&#39;, &#39;neutral&#39;, &#39;sadness&#39;, &#39;surprised&#39;],
columns=[&#39;Scores&#39;])
print(pred_df)
emo = pred_df[pred_df[&#39;Scores&#39;] == pred_df.max().values[0]].index[0]
print(emo)
emo_df.append(emo)
]]></description>
      <guid>https://stackoverflow.com/questions/76253683/split-an-audio-file-into-chunks-skip-the-chunks-less-than-desired-time-duration</guid>
      <pubDate>Mon, 15 May 2023 11:40:33 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法将 Google Colab 代码转换为 Web 服务或 REST API</title>
      <link>https://stackoverflow.com/questions/60443948/is-there-a-way-to-turn-google-colab-code-into-web-services-or-rest-apis</link>
      <description><![CDATA[我有一个机器学习模块，它使用 Google Colab 的免费 G​​PU 执行 NLP 任务，我想用它制作一个 Web 应用程序。我一直在考虑使用 React js 作为前端，使用 spring boot 作为后端，想知道是否有办法将 Google Colab 的代码与后端连接起来。
想知道在 Colab 中构建包含 ML 模块的 Web 应用程序的其他替代建议。任何形式的帮助都值得赞赏。]]></description>
      <guid>https://stackoverflow.com/questions/60443948/is-there-a-way-to-turn-google-colab-code-into-web-services-or-rest-apis</guid>
      <pubDate>Fri, 28 Feb 2020 01:10:30 GMT</pubDate>
    </item>
    <item>
      <title>面临 ValueError：目标是多类但平均值='二进制'</title>
      <link>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</link>
      <description><![CDATA[我正在尝试对我的数据集使用朴素贝叶斯算法。我能够找出准确率，但试图找出相同的精确度和召回率。但是，它抛出了以下错误：
ValueError：目标是多类，但平均值=&#39;binary&#39;。请选择其他平均设置。

有人可以建议我如何继续吗？我尝试在精确度和召回率分数中使用average =&#39;micro&#39;。它没有任何错误，但它给出了相同的准确度、精确度和召回率分数。
我的数据集：
train_data.csv：
review,label
颜色和清晰度极佳，正面
可惜图片不如我的 40 英寸三星清晰明亮，负面

test_data.csv：
review,label
图片清晰漂亮，正面
图片不清晰，负面

我的代码：
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confused_matrix

X_train, y_train = pd.read_csv(&#39;train_data.csv&#39;)
X_test, y_test = pd.read_csv(&#39;test_data.csv&#39;)

vec = CountVectorizer() 
X_train_transformed = vec.fit_transform(X_train) 
X_test_transformed = vec.transform(X_test)

clf = MultinomialNB()
clf.fit(X_train_transformed, y_train)

score = clf.score(X_test_transformed, y_test)

y_pred = clf.predict(X_test_transformed)
cm = confused_matrix(y_test, y_pred)

precision = precision_score(y_test, y_pred, pos_label=&#39;positive&#39;)
recall = recall_score(y_test, y_pred, pos_label=&#39;positive&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</guid>
      <pubDate>Tue, 11 Sep 2018 05:28:04 GMT</pubDate>
    </item>
    </channel>
</rss>