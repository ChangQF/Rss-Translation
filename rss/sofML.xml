<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 07 Nov 2024 18:21:54 GMT</lastBuildDate>
    <item>
      <title>支持向量机[关闭]</title>
      <link>https://stackoverflow.com/questions/79167180/support-vector-machine</link>
      <description><![CDATA[在支持向量机中，我们是否已经给出了数据集的决策边界，然后我们是否会调整给定的决策边界以最大化边际？]]></description>
      <guid>https://stackoverflow.com/questions/79167180/support-vector-machine</guid>
      <pubDate>Thu, 07 Nov 2024 15:41:52 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用 Keras 函数式 API 时发生 CUDAs 错误 [关闭]</title>
      <link>https://stackoverflow.com/questions/79166940/cudas-error-trying-to-use-keras-functional-api</link>
      <description><![CDATA[我的 tensorflow 安装无法检测到我的 GPU，即使我已确保我的 Linux 操作系统（它是一个双启动系统）目前正在使用它。
这是我到目前为止执行的代码，以及相应的输出。



以上是我似乎无法解决的错误。
Python 版本 - 3.9（在我工作的虚拟环境中）。
操作系统 - Ubuntu 24.04 LTS]]></description>
      <guid>https://stackoverflow.com/questions/79166940/cudas-error-trying-to-use-keras-functional-api</guid>
      <pubDate>Thu, 07 Nov 2024 14:39:48 GMT</pubDate>
    </item>
    <item>
      <title>我如何正确设置“random_state”以使结果始终相同？</title>
      <link>https://stackoverflow.com/questions/79165974/how-do-i-set-random-state-correctly-so-that-my-results-are-always-the-same</link>
      <description><![CDATA[例如，如果我有以下代码片段：
knn = KNeighborsClassifier()
grid_search_knn = GridSearchCV(
estimator=knn,
n_jobs=-1)

我是否必须像这样设置：
knn = KNeighborsClassifier(random_state=42)

grid_search_knn = GridSearchCV(
estimator=knn,
n_jobs=-1
)

或者我是否必须像这样设置？
knn = KNeighborsClassifier(random_state=42)

grid_search_knn = GridSearchCV(
estimator=knn,
random_state=42,
n_jobs=-1
)

正确的为什么是什么？如果我使用随机搜索而不是网格搜索会怎样？]]></description>
      <guid>https://stackoverflow.com/questions/79165974/how-do-i-set-random-state-correctly-so-that-my-results-are-always-the-same</guid>
      <pubDate>Thu, 07 Nov 2024 10:17:56 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中为 Nvidia GeForce RTX 3050 Ti 启用 CUDA？</title>
      <link>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</link>
      <description><![CDATA[我想在我的显卡（Nvidia GeForce RTX 3050 Ti）上运行 PyTorch 库（我在 PyCharm 的虚拟环境中运行该库）。但是，它在 CPU 上运行，每当我使用命令 import torch 和 print(&quot;cuda is available:&quot;, torch.cuda.is_available()) 时，它总是返回 False。
我安装了 CUDA 版本 12.6。我还安装了 PyTorch for CUDA 版本 12.4，因为它是 PyTorch 网站上可用的最新版本。考虑到我的显卡类型，我应该安装什么？]]></description>
      <guid>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</guid>
      <pubDate>Thu, 07 Nov 2024 04:30:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 Flask 进行机器学习项目时出现“TemplateNotFound：index.html”错误</title>
      <link>https://stackoverflow.com/questions/79164308/getting-templatenotfound-index-html-error-while-doing-a-machine-learning-proj</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79164308/getting-templatenotfound-index-html-error-while-doing-a-machine-learning-proj</guid>
      <pubDate>Wed, 06 Nov 2024 21:07:11 GMT</pubDate>
    </item>
    <item>
      <title>如何根据workflow_map结果拟合和预测每个模型？</title>
      <link>https://stackoverflow.com/questions/79164281/how-can-i-fit-and-predict-each-model-from-workflow-map-results</link>
      <description><![CDATA[我正在使用 tidymodels 训练各种分类模型，并使用 parsnip 调整这些模型中的超参数。作为 tidymodels 的新手，我按照教程完成了一些任务。但是，我不确定如何使用 workflow_map 中调整后的超参数来拟合和预测每个模型，而不是仅提取最佳工作流并进行拟合。我感兴趣的是了解每个模型的拟合和预测结果，并识别任何未预测的情况。我目前无法弄清楚如何使用复合函数（如 workflow_map）来拟合和预测具有一组超参数的一系列工作流。我目前的方法是手动替换每一个，这可能有点低效。这是我的部分代码（实际上，我用了 16 个模型，这里我粘贴了其中 2 个）：
set.seed(123)
splits &lt;- initial_split(Mydata, strata = Y,prop = 0.70)
TrainData &lt;- training(splits)
TestData &lt;- testing(splits)

base_rec &lt;- recipe( Y ~ ., data = TrainData)
dummy_rec&lt;-recipe( Y ~ ., data = TrainData)%&gt;%
step_dummy(all_nominal_predictors())

library(ranger)
rf_spec &lt;- 
rand_forest(
mtry = tune(),
min_n = tune(),
trees = tune()
) %&gt;% 
set_engine(&quot;ranger&quot;) %&gt;% 
set_mode(&quot;classification&quot;)%&gt;% 
翻译()

bt_spec &lt;- 
bart(
trees = tune(),
Prior_terminal_node_coef = tune(),
Prior_terminal_node_expo = tune(),
Prior_outcome_range = tune()
) %&gt;% 
set_engine(&quot;dbarts&quot;)%&gt;% 
set_mode(&quot;classification&quot;) %&gt;% 
翻译()

all_workflows &lt;- 
Workflow_set(
preproc = list(base_recipe = base_rec),
models = list(
rf=rf_spec, bart=bt_spec)
)%&gt;%
option_add(control = control_grid(
extract = function(x) x,
parallel_over = &quot;resamples&quot;,
save_pred = TRUE,
save_workflow = TRUE))

#创建重采样对象以供以后调整
set.seed(123)
folds &lt;- vfold_cv(TrainData, v = 5)

wf_tuning &lt;- 
all_workflows %&gt;% 
working_map(&quot;tune_grid&quot;, 
seed=12345, 
resamples = folds, 
grid = 25, 
metrics = metric_set(accuracy), 
verbose = TRUE)
autoplot(wf_tuning)

如果我手动提取调整后的超参数，然后拟合并预测模型，我应该执行相同的程序 25*16 次。您能否提供一些更有效的方法的建议？]]></description>
      <guid>https://stackoverflow.com/questions/79164281/how-can-i-fit-and-predict-each-model-from-workflow-map-results</guid>
      <pubDate>Wed, 06 Nov 2024 21:00:33 GMT</pubDate>
    </item>
    <item>
      <title>FLAML automl 预测概率与预测不匹配</title>
      <link>https://stackoverflow.com/questions/79163315/flaml-automl-prediction-probabilities-do-not-match-the-prediction</link>
      <description><![CDATA[我正在 Fabric 上使用 flaml automl 进行分类练习。
为了利用 spark，我必须使用 to_pandas_on_spark。
这些特征已经组装在一个向量中。
from flaml.automl.spark.utils import to_pandas_on_spark
psdf = to_pandas_on_spark(train_df)

拟合成功，所以我想预测我的测试数据。最佳估计器是 lgbm_spark。
接下来，为了进行评估，我需要一个最终数据框，其中包括目标 alpha 列、预测和概率，以及 test_df（pdate &amp; zm）中存在的 id 列。
psdf_test = to_pandas_on_spark(test_df.select(&quot;features&quot;))
y_pred = automl.predict(psdf_test) 

以上将返回一个带有一列预测的 pyspark.pandas.series.Series
y_pred_prob = automl.predict_proba(psdf_test)

以上将返回一个 pyspark.pandas.series.Series，其中每行都是三个概率的列表。
通常第一个是类别 0 的概率，第二个是类别 1 的概率，第三个是类别 2 的概率。
为了将所有内容整合在一起，我计划将所有内容转换为 pandas 数据框，然后连接起来。
#predictions
y_pred_pd = y_pred.to_pandas() # 转换为 pandas 系列
y_pred_pd = y_pred_pd.to_frame(name=&quot;prediction&quot;) # 转换为列名为“prediction”的 pandas 数据框

# probabilities
y_pred_prob_pd = y_pred_prob.to_pandas() # 转换为 pandas 系列
#y_pred_prob_pd = y_pred_prob_pd.to_frame(name=&quot;probability&quot;) # 转换为列名为“dataframe”的 DataFrame &#39;probability&#39;

# 将 test_df 转换为 pandas DataFrame 以使用标识符重新连接
test_df_pd = test_df.toPandas()

# 连接三个数据框
result_df = pd.concat([test_df_pd, y_pred_pd, y_pred_prob_pd], axis=1)

它有效，但问题是：最高概率与预测不匹配。

请注意，即使假设的类顺序不正确，预测仍然与最高概率不一致概率。

为什么会有差异？
有没有更简洁的方法来实现我想要的结果？
]]></description>
      <guid>https://stackoverflow.com/questions/79163315/flaml-automl-prediction-probabilities-do-not-match-the-prediction</guid>
      <pubDate>Wed, 06 Nov 2024 15:49:17 GMT</pubDate>
    </item>
    <item>
      <title>YOLOX 不在 mmengine::model 注册表中</title>
      <link>https://stackoverflow.com/questions/79163058/yolox-is-not-in-the-mmenginemodel-registry</link>
      <description><![CDATA[这是我的配置文件：
model = dict(
type=&#39;YOLOX&#39;, # YOLOX 架构
backbone=dict(type=&#39;CSPDarknet&#39;, deep_factor=1.0, widen_factor=1.0), # YOLOX 主干
neck=dict(type=&#39;YOLOXPAFPN&#39;, in_channels=[256, 512, 1024], out_channels=[256, 512, 1024]),
bbox_head=dict(
type=&#39;YOLOXHead&#39;,
num_classes=1, # 根据数据集中的类数更新此文件
in_channels=256,
feat_channels=256
),
train_cfg=dict(assigner=dict(type=&#39;SimOTAAssigner&#39;, center_radius=2.5)),
test_cfg=dict(score_thr=0.01, nms=dict(type=&#39;nms&#39;, iou_threshold=0.65))
)

以下代码列出了 YOLOX：
from mmdet.registry import MODELS

# 打印注册表中所有可用模型
print(MODELS.module_dict.keys())

但是，运行此代码：
from mmengine.config import Config
from mmengine.runner import Runner
from mmdet.utils import register_all_modules

# 注册 MMYOLO 和 MMDetection 的所有模块
register_all_modules()

def train_model(config_file):
# 加载配置
cfg = Config.fromfile(config_file)

# 确保检查点和日志的工作目录
cfg.work_dir = &#39;./checkpoints&#39; 

# 构建运行器
runner = Runner.from_cfg(cfg)

# 开始训练
runner.train()
print(&quot;训练完成！检查点已保存到 &#39;./checkpoints&#39;。&quot;)

# 配置文件路径
config_file = &#39;configs/yolov7/yolox_subset_coco.py&#39;

# 训练模型
train_model(config_file)

产生此错误：
KeyError: &#39;YOLOX 不在 mmengine::model 注册表中。请检查 `YOLOX` 的值是否正确或是否按预期注册。更多详细信息请参阅 https://mmengine.readthedocs.io/en/latest/advanced_tutorials/config.html#import-the-custom-module&#39;

YOLOv7 模型也是如此，事实上，这也是我想要使用的模型。您认为这里的错误是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79163058/yolox-is-not-in-the-mmenginemodel-registry</guid>
      <pubDate>Wed, 06 Nov 2024 14:32:15 GMT</pubDate>
    </item>
    <item>
      <title>比较两幅相似图像的有效方法[关闭]</title>
      <link>https://stackoverflow.com/questions/79162036/efficient-way-to-compare-two-similar-images</link>
      <description><![CDATA[我想识别图像中的方框。我有一个这些方框的数据库，存储它们的 ocr 和图像。我使用 ocr 搜索并粗略地转换了脸部。大多数时候它都能正常工作，但有时会返回错误的脸部和错误的转换。由于我有源图像，我想利用它们来评估搜索识别结果。我将检测到的方框区域转换为源图像并将它们调整为相同大小（因此它们从相似的角度看，大小也相似）。我使用 hog、alexnet 的倒数第二层、vitmae 和我自己训练的卷积网络作为嵌入特征。但它们都不太好用。我也尝试了关键点特征。但它花费的时间比要求的要长得多。当区分具有相同字体但不同大小的脸部时，它也会失败。
还有其他有效的方法来比较两张相似的图像吗？]]></description>
      <guid>https://stackoverflow.com/questions/79162036/efficient-way-to-compare-two-similar-images</guid>
      <pubDate>Wed, 06 Nov 2024 09:41:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 JAX 训练模型时跟踪测试/验证损失</title>
      <link>https://stackoverflow.com/questions/79158791/tracking-test-val-loss-when-training-a-model-with-jax</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79158791/tracking-test-val-loss-when-training-a-model-with-jax</guid>
      <pubDate>Tue, 05 Nov 2024 10:58:38 GMT</pubDate>
    </item>
    <item>
      <title>需要从图像中分别分割出每个数字</title>
      <link>https://stackoverflow.com/questions/79147122/need-to-segment-each-number-from-the-image-separately</link>
      <description><![CDATA[我使用 MNIST 数据集创建了一个 CNN 模型。我想对图像中存在的数字序列进行预测。该技术涉及分割每张图像并将其输入到模型中，但我在从图像中分割数字时遇到了困难，因为存在两种不同类型的图像。我需要一种强大的技术来消除图像中存在的所有噪音和阴影并分别分割每个数字。
我也在这里分享这些图片。
我正在寻找强大的技术和代码。





更新问题
分割的主要目标
我正在寻找一种从上面的图像中分割或分离每个数字的方法。我相信一定有一种独特或强大的方法可以用于所有类型的图像（如上所示）。我可以对二值图像和彩色图像应用单独的方法，但我想学习一种适用于上述图像的单一方法。]]></description>
      <guid>https://stackoverflow.com/questions/79147122/need-to-segment-each-number-from-the-image-separately</guid>
      <pubDate>Fri, 01 Nov 2024 06:27:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 ImageDataGenerator 训练 CNN，第二次训练后失败</title>
      <link>https://stackoverflow.com/questions/78861705/training-a-cnn-using-imagedatagenerator-and-training-fails-after-the-2nd-epoch</link>
      <description><![CDATA[我使用 ImageDataGenerator 训练 CNN 时遇到了这个问题，在第二个 Epoch 之后出现了属性错误。
模型如下
模型
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop

def create_model():
&#39;&#39;&#39;创建一个具有 4 个卷积层的 CNN&#39;&#39;&#39;
model = tf.keras.models.Sequential([
tf.keras.layers.Conv2D(32, (3,3),activation=&#39;relu&#39;, input_shape=(150, 150, 3)),
tf.keras.layers.MaxPooling2D(2, 2),
tf.keras.layers.Conv2D(64, (3,3),activation=&#39;relu&#39;),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Conv2D(128, (3,3), 激活=&#39;relu&#39;),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Conv2D(128, (3,3), 激活=&#39;relu&#39;),
tf.keras.layers.MaxPooling2D(2,2),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(512, 激活=&#39;relu&#39;),
tf.keras.layers.Dense(1, 激活=&#39;sigmoid&#39;)
])

model.compile(loss=&#39;binary_crossentropy&#39;,
optimizer=RMSprop(learning_rate=1e-4),
metrics=[&#39;accuracy&#39;])

返回模型

来自 tensorflow.keras.preprocessing.image 导入 ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
train_dir, # 这是训练图像的源目录
target_size=(150, 150), # 所有图像将调整为 150x150
batch_size=20,
# 由于我们使用 binary_crossentropy 损失，我们需要二进制标签
class_mode=&#39;binary&#39;)

validation_generator = test_datagen.flow_from_directory(
validation_dir,
target_size=(150, 150),
batch_size=20,
class_mode=&#39;binary&#39;,
shuffle= False)

EPOCHS = 20

model = create_model()

history = model.fit(
train_generator,
steps_per_epoch=100, # 2000 images = batch_size * steps
epochs=EPOCHS,
validation_data=validation_generator,
validation_steps=50, # 1000 images = batch_size * steps
verbose=2)

输出
AttributeError Traceback（最近一次调用最后一次）
Cell In[15]，第 8 行
5 model = create_model()
7 # 训练模型
----&gt; 8 history = model.fit(
9 train_generator,
10 steps_per_epoch=100, # 2000 图像 = batch_size * 步骤
11 epochs=EPOCHS,
12 validation_data=validation_generator,
13 validation_steps=50, # 1000 图像 = batch_size * 步骤
14 verbose=2)

文件 ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
-&gt; 122 从 None 中引发 e.with_traceback(filtered_tb)
123 最后：
124 delfiltered_tb

文件 ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\keras\src\backend\tensorflow\trainer.py:354，位于 TensorFlowTrainer.fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)
333 self._eval_epoch_iterator = TFEpochIterator(
334 x=val_x,
335 y=val_y,
...
355 }
356 epoch_logs.update(val_logs)
358 callbacks.on_epoch_end(epoch, epoch_logs)

AttributeError: &#39;NoneType&#39; 对象没有属性 &#39;items&#39;

输出被截断。以可滚动元素形式查看或在文本编辑器中打开。调整单元格输出设置...

我尝试了以下调试步骤：

升级 Tensorflow 和 Keras
尝试使用更简单的神经网络查看是否存在相同问题，但效果很好。
没有将 validation_generator 传递给 model.fit()，而是使用 numpy 手动执行，但这也没有奏效，因为对于它来说，训练数据的准确性和错误在偶数个时期都为 0仅。

还检查了验证数据是否已正确加载。
Python 版本：3.11.9
Tensorflow 版本：2.17.0
Keras 版本：3.4.1]]></description>
      <guid>https://stackoverflow.com/questions/78861705/training-a-cnn-using-imagedatagenerator-and-training-fails-after-the-2nd-epoch</guid>
      <pubDate>Mon, 12 Aug 2024 12:33:51 GMT</pubDate>
    </item>
    <item>
      <title>Pyinstaller创建的exe文件无法使用joblib加载决策树模型</title>
      <link>https://stackoverflow.com/questions/73771548/pyinstaller-created-exe-file-cannot-load-decision-tree-model-using-joblib</link>
      <description><![CDATA[我使用以下命令创建了我的大型 Python 脚本的 exe 文件 -
pyinstaller gui_final.py --onefile --hidden-import=sklearn --hidden-import=ipaddress --hidden-import=PIL --hidden-import=pickle --hidden-import=shutil --hidden-import=joblib
在我使用 JOBLIB 加载决策树模型文件 (dtree.joblib) 之前，exe 文件运行正常。
clf = joblib.load(&quot;dtree.joblib&quot;)

弹出以下错误 - 这是终端中的完整错误:
ModuleNotFoundError：没有名为“sklearn.ensemble._weight_boosting”的模块

我尝试通过稍后将 sklearn.ensemble 和 sklearn.ensemble._weight_boostin 添加到 exe 的 spec 文件中来更新 hidden_​​imports，具体操作请按照此 答案中的步骤进行。步骤也在下面给出
from PyInstaller.utils.hooks import collect_submodules

hidden_​​imports = collect_submodules(&#39;sklearn.ensemble&#39;) #(&#39;sklearn.ensemble._weight_boosting&#39;)

a = Analysis([&#39;gui_final.py&#39;],
binaries=None,
datas=[],
hiddenimports=hidden_​​imports,
.
.

通过运行命令：
pyinstaller gui_final.spec

但运行 exe 后仍然出现与之前相同的 ModuleNotFoundError。
我尝试使用 pyinstaller 查看有关 joblib 的一些问题，但没有找到任何合适的问题或解决方案。
有人可以建议制作脚本 exe 的步骤吗可运行吗？]]></description>
      <guid>https://stackoverflow.com/questions/73771548/pyinstaller-created-exe-file-cannot-load-decision-tree-model-using-joblib</guid>
      <pubDate>Mon, 19 Sep 2022 09:50:06 GMT</pubDate>
    </item>
    <item>
      <title>尝试导出引用“未跟踪”资源的函数 Tensor(“272554:0”, shape=(), dtype=resource)</title>
      <link>https://stackoverflow.com/questions/72313812/tried-to-export-a-function-which-references-untracked-resource-tensor272554</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/72313812/tried-to-export-a-function-which-references-untracked-resource-tensor272554</guid>
      <pubDate>Fri, 20 May 2022 05:07:08 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pytorch 进行随机选择？</title>
      <link>https://stackoverflow.com/questions/59461811/random-choice-with-pytorch</link>
      <description><![CDATA[我有一个图片张量，想从中随机选择。我正在寻找 np.random.choice() 的等价物。
import torch

pictures = torch.randint(0, 256, (1000, 28, 28, 3))

假设我想要 10 张这样的图片。]]></description>
      <guid>https://stackoverflow.com/questions/59461811/random-choice-with-pytorch</guid>
      <pubDate>Mon, 23 Dec 2019 22:14:52 GMT</pubDate>
    </item>
    </channel>
</rss>