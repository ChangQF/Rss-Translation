<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 03 May 2024 09:15:08 GMT</lastBuildDate>
    <item>
      <title>如何向 Polars 列添加新类别？</title>
      <link>https://stackoverflow.com/questions/78423364/how-to-add-a-new-category-to-a-polars-column</link>
      <description><![CDATA[我在 Polars 中有一个分类列，其中包含 3 个类别 &#39;A&#39;、&#39;B&#39; 和 &#39;C&#39;，这些类别是从训练数据集推断出来的。
现在假设我的测试集中存在一个以前未见过的类别 &#39;X&#39;。我想这样处理它：

向训练列添加一个 &#39;Unknown&#39; 类别
对于测试集中任何未见过的类别（例如 &#39;X&#39;），将它们设置为 &#39;Unknown&#39;。

如何实现？]]></description>
      <guid>https://stackoverflow.com/questions/78423364/how-to-add-a-new-category-to-a-polars-column</guid>
      <pubDate>Fri, 03 May 2024 07:54:23 GMT</pubDate>
    </item>
    <item>
      <title>是否有可能数据集不适合构建准确的模型？</title>
      <link>https://stackoverflow.com/questions/78423313/is-there-a-possibility-dataset-is-just-not-suitable-for-building-accurate-model</link>
      <description><![CDATA[我正在尝试通过使用糖尿病健康指标数据集（https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset）。我使用 Azure 机器学习工作室（经典），在那里我尝试了“训练模型”和“训练模型”。和“调整模型超参数” （随机扫描）方法，但我无法达到 cca 72% 以上的准确性和/或其他指标。数据集是平衡的（0 为 35346 个实例，1 为 35346 个实例），其大多数特征只是 0 或 1。我删除了其中一些特征，它们对糖尿病预测并不重要（CholCheck、AnyHealthCare、NoDocbcCost、教育、收入）。&lt; /p&gt;
https://i.ibb.co/Wn5cSY9/Bez-naslova.png 
该数据集是否适合准确预测，或者我必须改变解决问题的方法？]]></description>
      <guid>https://stackoverflow.com/questions/78423313/is-there-a-possibility-dataset-is-just-not-suitable-for-building-accurate-model</guid>
      <pubDate>Fri, 03 May 2024 07:42:26 GMT</pubDate>
    </item>
    <item>
      <title>如何将数据从 CFF 资源管理器导出到 csv 或 xlsx 文件？</title>
      <link>https://stackoverflow.com/questions/78422974/how-do-i-export-data-from-cff-explorer-to-a-csv-or-xlsx-file</link>
      <description><![CDATA[我正在尝试从 CFF 资源管理器获取数据进行一些分析。如何导出数据？
我尝试查看不同的东西，但没有可用的来源。是否有可用的扩展或者我必须为此专门编写代码？如果是的话怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/78422974/how-do-i-export-data-from-cff-explorer-to-a-csv-or-xlsx-file</guid>
      <pubDate>Fri, 03 May 2024 06:17:11 GMT</pubDate>
    </item>
    <item>
      <title>哪种机器学习算法最适合此类数据？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78422849/which-machine-learning-algorithm-will-be-best-for-this-type-of-data</link>
      <description><![CDATA[数据集配对图
这是我的数据的配对图，其中 Qmax、0.2max、0.1Qmax 和 3Qmin 构成特征集，Qmin 是要预测的值。
查看绘图和数据集，我可以说它是非线性的，如果我尝试构建预测模型，简单的回归将不起作用。因此，我需要关于应该尝试哪些算法来获得此类数据的最佳模型的建议。
我尝试使用多项式回归、RidgeCV 和 LassoCV，其中 LassoCV 给出了最好的结果，但误差仍然存在，而且明显很大。]]></description>
      <guid>https://stackoverflow.com/questions/78422849/which-machine-learning-algorithm-will-be-best-for-this-type-of-data</guid>
      <pubDate>Fri, 03 May 2024 05:33:41 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助切换到新的工作角色[关闭]</title>
      <link>https://stackoverflow.com/questions/78422693/need-help-in-switching-to-a-new-job-role</link>
      <description><![CDATA[我担任数据分析师已经两年了，我正在考虑换工作。我想到了三个选择：数据工程、机器学习和 DevOps。您能告诉我哪一款需求量大且报酬丰厚吗？
我无法弄清楚哪一个适合我。大家可以推荐一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/78422693/need-help-in-switching-to-a-new-job-role</guid>
      <pubDate>Fri, 03 May 2024 04:35:06 GMT</pubDate>
    </item>
    <item>
      <title>VGG 上的迁移学习能否更好地与《蜘蛛侠：平行宇宙》的风格保持一致，从而改善风格迁移？[关闭]</title>
      <link>https://stackoverflow.com/questions/78422590/can-transfer-learning-on-vgg-better-align-with-across-the-spider-verse-styles-fo</link>
      <description><![CDATA[我们的项目正在致力于使用 Across the Spider-verse 中的样式来实现样式迁移。到目前为止，我们已经获得了一些不错的输出，但我们想知道是否可以更好地将 VGG 模型与我们所依赖的宇宙中的样式保持一致，以获得更好的输出。
这个想法是通过在 VGG 上使用迁移学习来识别电影中的不同宇宙，我们可以调整 VGG 以注意到每个不同宇宙中使用的一些特征（例如更好地识别格温的画笔笔触或迈尔斯的半色调） .
我们对此进行了实验，最终得到了一个似乎难以识别内容的 VGG 模型 - 当我们运行整个模型时，我们的图像已删除所有细节（例如极其模糊或块状）。
这让我们想知道这种实现是否可行。似乎没有任何其他论文使用除 VGG 之外的任何内容（1).]]></description>
      <guid>https://stackoverflow.com/questions/78422590/can-transfer-learning-on-vgg-better-align-with-across-the-spider-verse-styles-fo</guid>
      <pubDate>Fri, 03 May 2024 03:43:46 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 和 Keras 以及 TensorFlow 进行 Epoch 数据训练 [关闭]</title>
      <link>https://stackoverflow.com/questions/78422261/epoch-data-training-using-python-and-keras-and-tensorflow</link>
      <description><![CDATA[我在尝试训练数据时遇到这样的错误
我希望得到一个解决方案，以便我的纪元训练可以恢复处理图像
还有一条消息出现在 Epoch 1/10
C:\Users\LISA\AppData\Roaming\Python\Python311\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.py:121: UserWarning: 你的 `PyDataset` 类应该调用 `super().__init__(* *kwargs)` 在其构造函数中。 `**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。不要将这些参数传递给“fit()”，因为它们将被忽略。
  self._warn_if_super_not_used()
737/737 ────────────────────────────── 0s 3s/步 - 准确度：0.9137 - 损失：0.3580
Epoch 1：val_accuracy 从 -inf 提高到 0.90875，将模型保存到 vgg16_uas_classsification.keras
737/737 ────────────────────────────── 2388s 3s/步 - 准确度：0.9137 - 损失：0.3580 - val_accuracy：0.9087 - val_loss：0.3 562
纪元 2/10
c:\Program Files\Python311\Lib\contextlib.py:158: UserWarning: 您的输入数据不足；中断训练。确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次。构建数据集时，您可能需要使用“.repeat()”函数。
  self.gen.throw（类型，值，回溯）
]]></description>
      <guid>https://stackoverflow.com/questions/78422261/epoch-data-training-using-python-and-keras-and-tensorflow</guid>
      <pubDate>Fri, 03 May 2024 00:57:09 GMT</pubDate>
    </item>
    <item>
      <title>机器学习部署和测试的问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78422251/issues-with-machine-learning-deployment-and-testing</link>
      <description><![CDATA[我目前正在构建一个机器学习模型，并使用 Python Flask 将其与网站集成进行部署。我已经成功地训练了模型，并在训练过程中将数据处理成特征和特定数据类型。但是，我不确定如何在预测期间处理实时用户输入数据。有人可以指导我如何在使用 Flask 部署期间将用户输入转换为模型所需的功能和数据类型吗？任何见解或代码示例将不胜感激。
谢谢！”
这就是我正在尝试做的事情。使用xgb_model
fromflask导入Flask、request、jsonify、render_template
将 pandas 导入为 pd
将 numpy 导入为 np
进口泡菜
从类别_编码器导入 TargetEncoder
导入操作系统

base_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_dir, &#39;fraudpredict.pickle.pkl&#39;)

# 加载模型
model = pickle.load(open(&#39;fraudpredict.pickle&#39;, &#39;rb&#39;))

应用程序 = Flask(__name__)


def 预处理(df):
    df = df.replace(&#39;?&#39;, np.NaN)
    df[&#39;collision_type&#39;].fillna(df[&#39;collision_type&#39;].mode()[0], inplace=True)
    df[&#39;property_damage&#39;].fillna(&#39;NO&#39;, inplace=True)
    df[&#39;police_report_available&#39;].fillna(&#39;NO&#39;, inplace=True)
    df[&#39;authorities_contacted&#39;].fillna(&#39;NO&#39;, inplace=True)
    df = df.drop(
        columns=[&#39;_c39&#39;、&#39;policy_number&#39;、&#39;policy_bind_date&#39;、&#39;incident_date&#39;、&#39;incident_location&#39;、&#39;auto_model&#39;])
    df[&#39;incident_month&#39;] = pd.to_datetime(df[&#39;incident_date&#39;], error=&#39;coerce&#39;).dt.month
    df[&#39;incident_day&#39;] = pd.to_datetime(df[&#39;incident_date&#39;], error=&#39;coerce&#39;).dt.day
    df[&#39;fraud_reported&#39;] = df[&#39;fraud_reported&#39;].replace((&#39;Y&#39;, &#39;N&#39;), (0, 1))

    # 对分类变量进行编码
    编码器=目标编码器()
    categorical_features = [&#39;auto_make&#39;, &#39;police_report_available&#39;, &#39;property_damage&#39;,
                            &#39;incident_city&#39;, &#39;incident_state&#39;, &#39;authorities_contacted&#39;, &#39;incident_severity&#39;,
                            &#39;collision_type&#39;, &#39;incident_type&#39;, &#39;insured_relationship&#39;, &#39;insured_hobbies&#39;,
                            &#39;受保职业&#39;、&#39;受保教育级别&#39;、&#39;受保性别&#39;、&#39;保单_csl&#39;、
                            &#39;政策状态&#39;]
    对于 categorical_features 中的特征：
        df[特征] = 编码器.fit_transform(df[特征], df[&#39;fraud_reported&#39;])

    返回df


@application.route(&#39;/&#39;)
定义索引（）：
    # 渲染输入表单
    返回 render_template(&#39;index.html&#39;)


@application.route(&#39;/predict&#39;,methods=[&#39;POST&#39;])
def 预测（）：
    data = request.form.to_dict() # 从表单中收集数据
    df = pd.DataFrame([数据])
    df_processed = 预处理(df)
    预测 = model.predict(df_processed)
    如果预测[0] == 1，则结果 =“检测到欺诈”，否则“未检测到欺诈”
    返回 render_template(&#39;index.html&#39;, 结果=结果)


如果 __name__ == &#39;__main__&#39;:
    应用程序.运行（调试= True）
]]></description>
      <guid>https://stackoverflow.com/questions/78422251/issues-with-machine-learning-deployment-and-testing</guid>
      <pubDate>Fri, 03 May 2024 00:51:23 GMT</pubDate>
    </item>
    <item>
      <title>Unsloth 未检测到 CUDA 和“str2optimizer32bit”</title>
      <link>https://stackoverflow.com/questions/78420830/unsloth-not-detecting-cuda-and-str2optimizer32bit</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78420830/unsloth-not-detecting-cuda-and-str2optimizer32bit</guid>
      <pubDate>Thu, 02 May 2024 17:30:58 GMT</pubDate>
    </item>
    <item>
      <title>从 json 文件创建 BIO 格式的句子 - 训练 NER 模型</title>
      <link>https://stackoverflow.com/questions/78420651/create-bio-format-to-a-sentence-from-a-json-file-to-train-ner-model</link>
      <description><![CDATA[我有一个 JSON 文件，将用作 NER 模型的数据。
它有一个句子和该特定句子中的相关实体。
我想创建一个函数，根据实体为每个句子生成 BIO 标记的字符串
例如 JSON 文件中的以下对象
&lt;代码&gt;{
      &quot;request&quot;: &quot;我想13.3 飞往纽约&quot;,
      “实体”：[
        {“start”: 16, “end”: 23, “text”: “纽约”, “category”: “DESTINATION”},
        {“开始”：32，“结束”：35，“文本”：“13.3”，“类别”：“日期”}
      ]
}

“我想乘坐 13.3 号飞往纽约”
相应的BIO标签将是
“O O O O O B-目的地 I-目的地 O O B-日期”
其中 B 类别是该类别的开头
I 类代表内部，O 类代表外部。
我正在寻找一个 Python 代码来迭代 JSON 文件中的每个对象，从而为其生成 BIO 标签。
如有必要，更改 JSON 格式]]></description>
      <guid>https://stackoverflow.com/questions/78420651/create-bio-format-to-a-sentence-from-a-json-file-to-train-ner-model</guid>
      <pubDate>Thu, 02 May 2024 16:56:56 GMT</pubDate>
    </item>
    <item>
      <title>尝试训练 GAN 模型时出现 ValueError</title>
      <link>https://stackoverflow.com/questions/78420289/getting-valueerror-while-trying-to-train-gan-model</link>
      <description><![CDATA[我正在尝试训练 GAN 模型来检测糖尿病视网膜病变图像，但它抛出错误。请帮忙。
图像数据集不为空我已尝试查看它
错误是：-
纪元 1/50
回溯（最近一次调用最后一次）：
  文件“C:\Users\asus\OneDrive\Desktop\project\DR-GAN\TrainModel.py”，第 65 行，在  中
    分类器.fit（X，Y，batch_size = 32，epochs = 50）
  文件“C:\Users\asus\AppData\Roaming\Python\Python312\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
    从 None 引发 e.with_traceback(filtered_tb)
  文件“C:\Users\asus\AppData\Roaming\Python\Python312\site-packages\keras\src\backend\tensorflow\nn.py”，第 553 行，在 categorical_crossentropy 中
    引发值错误（
ValueError：参数“target”和“output”必须具有相同的形状。收到：target.shape=(无，3)，output.shape=(无，5)

火车模型文件的代码是：
将 numpy 导入为 np
导入imutils
导入系统
导入CV2
导入操作系统
从tensorflow.keras.utils导入to_categorical
从 keras.models 导入 model_from_json
从 keras.layers 导入 MaxPooling2D
from keras.layers import Dense、Dropout、Activation、Flatten
从 keras.layers 导入 Convolution2D
从 keras.models 导入顺序

图片 = []
图像标签 = []
目录=&#39;数据集&#39;
文件列表 = os.listdir(目录)
索引 = 0
对于 list_of_files 中的文件：
    子文件 = os.listdir(目录+&#39;/&#39;+文件)
    对于子文件中的子项：
        路径=目录+&#39;/&#39;+文件+&#39;/&#39;+子
        img = cv2.imread(路径)
        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        如果 img 为 None：
          print(&#39;路径错误：&#39;, 路径)
        别的：
         img = cv2.resize(img, (32,32))
         im2arr = np.array(img)
         im2arr = im2arr.reshape(32,32,3)
         图像.append(im2arr)
         image_labels.append(文件)
    打印（文件）

X = np.asarray(图像)
Y = np.asarray(image_labels)
Y = to_categorical(Y)
img = X[20].reshape(32,32,3)
cv2.imshow(&#39;ff&#39;,cv2.resize(img,(250,250)))
cv2.waitKey(0)
print(&quot;形状 == &quot;+str(X.shape))
print(&quot;形状==&quot;+str(Y.shape))
打印（Y）
X = X.astype(&#39;float32&#39;)
X = X/255

np.save(“model/img_data.txt”,X)
np.save(“model/img_label.txt”,Y)

X = np.load(&#39;model/img_data.txt.npy&#39;)
Y = np.load(&#39;model/img_label.txt.npy&#39;)
打印（Y）
img = X[20].reshape(32,32,3)
cv2.imshow(&#39;ff&#39;,cv2.resize(img,(250,250)))
cv2.waitKey(0)

classifier = Sequential() #alexnet 迁移学习代码在这里
classifier.add(Convolution2D(32, 3, 3, input_shape = (32, 32, 3), 激活 = &#39;relu&#39;))
classifier.add(MaxPooling2D((2, 2) , padding=&#39;相同&#39;))
classifier.add(Convolution2D(32, 3, 3, 激活 = &#39;relu&#39;))
classifier.add(MaxPooling2D((2, 2) , padding=&#39;相同&#39;))
分类器.add(Flatten())
classifier.add（密集（单位= 128，激活=&#39;relu&#39;））
classifier.add(Dense(单位 = 5, 激活 = &#39;softmax&#39;))
classifier.compile（优化器=&#39;adam&#39;，损失=&#39;categorical_crossentropy&#39;，指标= [&#39;准确性&#39;]）
分类器.fit（X，Y，batch_size = 32，epochs = 50）

我尝试过更改尺寸，但它不起作用，我无法理解这是版本错误还是代码错误，因此为了解决同样的问题，请提供解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78420289/getting-valueerror-while-trying-to-train-gan-model</guid>
      <pubDate>Thu, 02 May 2024 15:39:54 GMT</pubDate>
    </item>
    <item>
      <title>Visual Studio Code 中的 PyLance 无法识别 TensorFlow.keras 命名空间</title>
      <link>https://stackoverflow.com/questions/78419755/tensorflow-keras-namespace-not-recognized-by-pylance-in-visual-studio-code</link>
      <description><![CDATA[我在 Visual Studio Code 中遇到 PyLance 问题，其中tensorflow.keras 命名空间无法被识别，导致 IntelliSense 和自动完成不完整。看来这个问题源于 TensorFlow 利用延迟加载功能 (_KerasLazyLoader) 推迟加载不必要的包，直到需要它们为止。
我搜索了有关该主题的现有问题，但我发现的最新讨论可以追溯到 2023 年底。此外，提议的解决方案主要涉及从长远来看可能不可靠的解决方法。
是否有官方解决方案来确保 PyLance 正确识别 tensorflow.keras 命名空间？我无法想象延迟加载通常会破坏 VSCode 智能感知（尽管我肯定是错的）。或者，是否有任何可靠的解决方法在未来的更新中不太可能被破坏？任何见解或指导将不胜感激。
软件：
MacOS 索诺玛 14.1.2
Python 3.12
张量流2.16.1
参考之前发布的问题/问题：

https://github.com/microsoft/pylance-release/issues/3249 
VSCode 自动完成和建议 (IntelliSense) 不支持适用于 Tensorflow 和 Keras 库吗？
https://community.deeplearning.ai/t/unable-to-import-tensorflow-keras-pylinte0401-import-error-in-visual-studio-code/512586
https://jagaimox.wordpress.com/2020/12/28/configure-python-intellisense-on-vscode-for-tensorflow-1-14-or-1-15/ （张量流1.14/1.15）

我在上面的链接中尝试了几种解决方案，但它们对我不起作用。其中一些可能需要一些我需要做但我没有做的额外配置（例如，在tensorflow.init中引用了 _typing 但尚未定义 _typing - 可能已过时） .]]></description>
      <guid>https://stackoverflow.com/questions/78419755/tensorflow-keras-namespace-not-recognized-by-pylance-in-visual-studio-code</guid>
      <pubDate>Thu, 02 May 2024 14:11:58 GMT</pubDate>
    </item>
    <item>
      <title>ConvLSTM 模型的数据预处理过程中遇到问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78418879/having-trouble-during-preprocessing-of-data-for-a-convlstm-model</link>
      <description><![CDATA[我有 10 年（2014-24）的 GHRSST 数据，我将其分为两部分：训练（2014-2021）和测试（2021-2024）数据集。训练数据集大小为 4.18GB，测试数据集大小为 1.98GB。我正在尝试构建一个 ConvLSTM 模型来预测未来几天的 SST 数据，但是我似乎无法通过预处理阶段。我正在尝试在 google colab 上执行以下代码：
导入火炬
将 numpy 导入为 np
进口达斯克

# NetCDF 文件的路径
dataset_path = &#39;/content/drive/MyDrive/train_dataset_10.nc&#39;
# 使用 dask chunks 打开数据集
ds = xr.open_mfdataset(dataset_path, chunks={&#39;时间&#39;: 1, &#39;纬度&#39;: 50, &#39;经度&#39;: 50})

# 提取SST数据；假设变量名为“analysis_sst”，并使用计算将其转换为 numpy 来加载数据
sst_data = ds[&#39;analysisd_sst&#39;].compute() # 这将确保数据加载到内存中

上述代码需要 30 分钟执行，并占用 10.2/12.7GB 可用系统 RAM。这也会导致以下代码出现问题，该代码使用过多的 CPU（尽管 GPU 处于打开状态）并且由于缺少 RAM 而导致内核崩溃：
# 清除 CUDA 中所有未使用的内存
torch.cuda.empty_cache()

# 将数据转换为张量，出于兼容性原因确保它首先在 CPU 上
sst_tensor = torch.tensor(sst_data.values, dtype=torch.float32)

# 如果有可用的 GPU，则将张量传输到 GPU
如果 torch.cuda.is_available():
    sst_tensor = sst_tensor.to(&#39;cuda&#39;)

print(&quot;SST 张量的形状：&quot;, sst_tensor.shape)

defscale_data_gpu(data_tensor,batch_size):
    scaled_data = torch.full_like(data_tensor, float(&#39;nan&#39;)) # 为填充 NaN 的缩放数据初始化张量

    # 批量处理数据
    对于范围内的开始（0，data_tensor.shape [0]，batch_size）：
        结束 = 开始 + 批次大小
        批处理 = data_tensor[开始:结束]

        # 为有效（非 NaN）数据点创建掩码
        valid_mask = ~torch.isnan(batch)

        if valid_mask.any(): # 确保至少有一些有效数据
            data_min = torch.min(batch[valid_mask])
            data_max = torch.max(batch[valid_mask])

            # 缩放批次，但仅在有效的情况下应用
            batch_scaled = (batch - data_min) / (data_max - data_min)
            scaled_data[开始:结束][valid_mask] = batch_scaled[valid_mask]

    返回缩放数据

# 在 GPU 上应用缩放，仅考虑有效（非 NaN）值
使用 torch.no_grad()：
  sst_scaled_tensor = scale_adata_gpu（data_tensor = sst_tensor，batch_size = 64）

在上面的代码中，我试图掩盖标记为“NaN”的值因为它代表了我的数据集中的地形，然后缩放数据并批量处理它以准备训练。
我该如何进行这项工作？这个过程需要多长时间？有更有效的方法吗？
我尝试过使用 Dask，但没有成功，而且 GEE 不支持 CNN。]]></description>
      <guid>https://stackoverflow.com/questions/78418879/having-trouble-during-preprocessing-of-data-for-a-convlstm-model</guid>
      <pubDate>Thu, 02 May 2024 11:34:30 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用 YOLOv8 进行训练后出现多处理错误</title>
      <link>https://stackoverflow.com/questions/78412108/multiprocessing-error-after-trying-to-train-with-yolov8</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78412108/multiprocessing-error-after-trying-to-train-with-yolov8</guid>
      <pubDate>Wed, 01 May 2024 05:10:52 GMT</pubDate>
    </item>
    <item>
      <title>预测新数据时保存的 GAMLSS 模型出现问题</title>
      <link>https://stackoverflow.com/questions/77837026/issue-with-saved-gamlss-model-while-predicting-for-new-data</link>
      <description><![CDATA[我有一个经过 GAMLSS 训练的模型，我已使用 saveRDS() 以 .rda 格式保存了该模型。
例如，我训练的模型如下：
gamlss_model&lt;- gamlss(res~pb(x)+pb(y), family=BCTo, data = test) 

当我在清除所有环境变量后加载上述模型，并使用预测函数获取新数据时：
predict(model_old, newdata = new_data) 

我收到以下错误：
eval(Call$data) 中的错误：未找到对象“test” 

但这个测试是旧数据集，在这里不应该有任何意义。我无法理解这有什么问题。因此，我无法运行 REST API。
当 GAMLSS 模型训练完成后，我的所有环境变量都存在，然后我立即使用预测，它就可以正常工作！但我想稍后再使用预测。]]></description>
      <guid>https://stackoverflow.com/questions/77837026/issue-with-saved-gamlss-model-while-predicting-for-new-data</guid>
      <pubDate>Thu, 18 Jan 2024 05:10:18 GMT</pubDate>
    </item>
    </channel>
</rss>