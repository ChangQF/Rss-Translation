<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 20 Jul 2024 18:20:22 GMT</lastBuildDate>
    <item>
      <title>将三个经过训练的二分类模型组合成 Keras 中的单个多分类模型</title>
      <link>https://stackoverflow.com/questions/78773489/combine-three-trained-binary-classification-models-into-single-multiclassificati</link>
      <description><![CDATA[这个问题只是为了学习目的。我有三个经过训练的二分类模型，它们在输出层使用 sigmoid 激活进行训练。

第一个模型返回从 0 到 1 的概率标量，以检查图像是否为数字 ZERO。
第二个模型返回从 0 到 1 的概率标量，以检查图像是否为数字 ONE。
第三个模型返回从 0 到 1 的概率标量，以检查图像是否为数字 TWO。


我知道我可以用softmax 在输出层构建三个神经元的模型。但假设我遇到一种情况，由于模型复杂，训练它们的权重确实需要很长时间，我只有它们各自的二元分类模型。或者，我想提取它们在隐藏层的隐藏表示特征，例如 model_0（二元分类检查图像是否为零）。
那么，如何将它们连接/组合/合并为单个模型？
我的代码目前卡在了这一点：
model_0 = init_binary_classification_model((28,28))
model_0.load_weights(&#39;trained_weight_of_binary_classification_to_check_whether_image_is_zero.h5&#39;)

model_1 = init_binary_classification_model((28,28))
model_1.load_weights(&#39;trained_weight_of_binary_classification_to_check_whether_image_is_one.h5&#39;)

model_2 = init_binary_classification_model((28,28))
model_2.load_weights(&#39;trained_weight_of_binary_classification_to_check_whether_image_is_two.h5&#39;)

其中：
def init_binary_classification_model(input_shape=(28,28)):
input_layer = Input(shape=input_shape)
tensor = Flatten()(input_layer)
tensor = Dense(16,activation=&#39;relu&#39;)(tensor)
tensor = Dense(8,activation=&#39;relu&#39;)(tensor)
output_layer = Dense(1,activation=&#39;sigmoid&#39;)(tensor)

return Model(inputs=input_layer,outputs=output_layer)

我期望多分类模型具有相同的输入形状(28,28)和不同的输出形状(3)，并且我不需要重新训练模型（如果可能的话）。
完整代码可在以下网址获取：https://colab.research.google.com/drive/1y1mvAzebIFU_cuEQo8Q60L1I6uT8i2Ce?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78773489/combine-three-trained-binary-classification-models-into-single-multiclassificati</guid>
      <pubDate>Sat, 20 Jul 2024 17:44:05 GMT</pubDate>
    </item>
    <item>
      <title>如何将职位名称与职位空缺名称或职位空缺描述进行匹配？</title>
      <link>https://stackoverflow.com/questions/78772979/how-to-match-job-title-with-vacancies-name-or-vacancy-descriptions</link>
      <description><![CDATA[如何将 400 个职业与 10,000 个职位空缺进行匹配？我有两个文件：一个文件包含职业名称及其所属部门，第二个文件是来自 hh.kz 的 10,000 个职位空缺，包含职位名称及其描述。我需要将 400 个职业分配到适当的职位空缺，例如，将“高级前端开发人员”与“Web 开发人员”、“UI/UX 设计师”与“Web 设计师”等进行匹配。我已经清理和规范化了数据，使用了词嵌入，但效果不佳。我还能尝试什么？
我尝试使用关键字，但对我来说不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78772979/how-to-match-job-title-with-vacancies-name-or-vacancy-descriptions</guid>
      <pubDate>Sat, 20 Jul 2024 14:06:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们在 Unet 中使用连接？[关闭]</title>
      <link>https://stackoverflow.com/questions/78772734/why-we-use-concatenation-in-unet</link>
      <description><![CDATA[
为什么我们在 unet 中使用连接，以及我们是如何得到这些灰线的。有人可以详细解释一下吗，我是新手
我尝试了 Unet 架构，但我无法理解我们如何得到灰线，即分割图像。
有人可以解释一下这是如何工作的吗？]]></description>
      <guid>https://stackoverflow.com/questions/78772734/why-we-use-concatenation-in-unet</guid>
      <pubDate>Sat, 20 Jul 2024 12:20:56 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型分类变量热编码背后的逻辑</title>
      <link>https://stackoverflow.com/questions/78772604/logic-behind-the-categorical-variables-hot-encoding-for-machine-learning-models</link>
      <description><![CDATA[我不明白在机器学习中，对于分类变量，例如分类变量“Is_available”（具有 2 个唯一值，是和否），我们只是将“是”替换为 1，将“否”替换为 0，并且我们不对具有“是”和“否”等值的此类分类变量使用任何热编码。但对于分类变量，例如“性别”（具有 2 个唯一值男性和女性），我们使用热编码。为什么不对“Is_available”列使用热编码，为什么对“性别”列使用热编码？
这背后的逻辑是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78772604/logic-behind-the-categorical-variables-hot-encoding-for-machine-learning-models</guid>
      <pubDate>Sat, 20 Jul 2024 11:25:51 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习进行手语字母识别给出错误预测[关闭]</title>
      <link>https://stackoverflow.com/questions/78772476/sign-language-alphabet-identification-using-machine-learning-giving-wrong-predic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78772476/sign-language-alphabet-identification-using-machine-learning-giving-wrong-predic</guid>
      <pubDate>Sat, 20 Jul 2024 10:17:39 GMT</pubDate>
    </item>
    <item>
      <title>二元分类：准确率始终等于 1 [关闭]</title>
      <link>https://stackoverflow.com/questions/78771535/binary-classification-accuracy-always-equal-to-1</link>
      <description><![CDATA[为二元图像分类任务训练 CNN。然而，在验证和测试分数上，准确率始终显示为 1。不过，损失曲线并未显示过度拟合。
尝试添加类别权重来平衡类别权重。]]></description>
      <guid>https://stackoverflow.com/questions/78771535/binary-classification-accuracy-always-equal-to-1</guid>
      <pubDate>Sat, 20 Jul 2024 00:17:14 GMT</pubDate>
    </item>
    <item>
      <title>R 中的神经网络代码</title>
      <link>https://stackoverflow.com/questions/78771276/neural-network-codes-in-r</link>
      <description><![CDATA[我正在 R 中运行我的神经网络代码来处理我的生存数据。我可以运行这些代码，但我需要计算神经网络模型的指标（精度、准确度、灵敏度、特异性），并且我应该计算混淆矩阵并绘制 Roc 曲线。你能帮我写一下这部分代码吗？
library(survival)
library(nnet)
library(readxl)
df2 &lt;- read_excel(&quot;E:/SOLMAZ/BS DATA/data BS.xlsx&quot;)
df2
# 将数据分成训练集和测试集
train.index &lt;- sample(1:nrow(df2), round(0.8*nrow(df2)))
train.data &lt;- df2[train.index,]
test.data &lt;- df2[-train.index,]

# 定义一个隐藏层的神经网络模型
nn.model&lt;- nnet(Surv(time_15year,BS_death) ~ age +sex +edu +job +place + cvahis +mihis + bphis+ heartdis + diabhis +hlphis +smok +pastsmok +pasive + activity + waterpip + cvatype, data = train.data, size = 5, maxit = 1000)

# 在测试集上生成预测
test.data$pred &lt;- predict(nn.model, newdata =test.data)
test.data$pred &lt;- ifelse(test.data$pred&gt;median(test.data$pred, na.rm = TRUE),1,0)
print(head(test.data))
table(as.factor(test.data$BS_death),as.factor(test.data$pred[,&quot;status&quot;]))
]]></description>
      <guid>https://stackoverflow.com/questions/78771276/neural-network-codes-in-r</guid>
      <pubDate>Fri, 19 Jul 2024 21:29:13 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音转文本和翻译（直播）</title>
      <link>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</link>
      <description><![CDATA[我有一个用例，我将在直播中录制一段演讲，并且我希望实时获得音频的文本转录，然​​后翻译该转录。
我是否需要使用 Google 的语音转文本 API，然后将生成的文本发送到翻译 API，还是可以在一行中完成？]]></description>
      <guid>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</guid>
      <pubDate>Thu, 18 Jul 2024 17:21:16 GMT</pubDate>
    </item>
    <item>
      <title>KLDivLoss 的输入是什么</title>
      <link>https://stackoverflow.com/questions/78753296/what-input-for-kldivloss</link>
      <description><![CDATA[我有一个 CNN 架构，希望使用 Kullback-Leibler 损失（来自 pytorch 的 KLDivLoss）来比较输出张量和目标张量（灰度图像）。
我有点困惑，不知道输入到损失函数的图像应该是什么格式。我理解它不应该直接是像素值，而应该是一个概率分布。
这里有一些我犹豫要不要使用的可能性，但我不确定它们是否正确：

保持图像尺寸并用其概率替换像素值（用 count(pixel_value)/total_number_of_pixels 替换每个像素值）
只需应用 softmax（但最高概率与更高的像素值相关联，这在我的例子中并不十分相关）
用大小为 256 的向量作为损失函数，其每个元素都是图像中相应像素值的概率（count(pixel_value)/total_number_of_pixels）

我的图像在 0 和 1 之间标准化。]]></description>
      <guid>https://stackoverflow.com/questions/78753296/what-input-for-kldivloss</guid>
      <pubDate>Tue, 16 Jul 2024 07:54:06 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 模型无法训练</title>
      <link>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</link>
      <description><![CDATA[我正在尝试使用深度学习来查找粒子的化学状态。作为输入，我有粒子在 X_train 中随时间的位置，形状为 (num_train,sequence_length)。 （我的序列长度为 100），输出是形状为 (num_train,1) 的 Y_train 中包含的转换帧（介于 1 和 100 之间）。
这是一个序列示例（https://i.sstatic.net/Ddmhjc24.jpg），转换位于第 84 帧。
所有数据都是用非常具体的算法生成的，但是该算法不会生成非常复杂的数据，我认为自己很容易找到转换，但我希望这个深度学习模型能够正常工作。
这是 LSTM 代码：
# 过滤

# 定义 LSTM 模型
model = Sequential([
LSTM(64, input_shape=(sequence_length, 1), return_sequences=False), Dense(64,activation=&#39;relu&#39;), Dense(1) ]) # 模型编译器 model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;) # 回归的均方误差 # 模型摘要 model.summary() # 模型模型嵌入 model.fit( X_train, Y_train, epochs=40, batch_size=32,validation_data=(X_test, Y_test)) # 新预测示例预测= model.predict(X_test) print(prediction)  结果： 模型：“sequential”
_________________________________________________________________
层（类型）输出形状参数 # 
====================================================================
lstm (LSTM) (无，64) 16896 

密集 (密集) (无，64) 4160 

密集_1 (密集) (无，1) 65 

============================================================================
总参数：21121 (82.50 KB)
可训练参数： 21121 (82.50 KB)
不可训练参数：0 (0.00 字节)
_________________________________________________________________
Epoch 1/10
631/631 [==============================] - 35s 50ms/step - 损失：1043.6710 - val_loss：840.6771
Epoch 2/10
631/631 [==============================] - 30s 48ms/step - 损失：840.9444 - val_loss：839.9596
Epoch 3/10
631/631 [===============================] - 32s 50ms/步 - 损失：841.6289 - val_loss：840.7188
Epoch 4/10
631/631 [=============================] - 30s 48ms/步 - 损失：840.9946 - val_loss：840.6344
Epoch 5/10
631/631 [===============================] - 33s 52ms/步 - 损失：841.8745 - val_loss：839.9298
Epoch 6/10
631/631 [==============================] - 31s 49ms/步 - 损失：841.6499 - val_loss：839.8434
Epoch 7/10
631/631 [=============================] - 31s 49ms/步 - 损失：841.2045 - val_loss：840.0717
Epoch 8/10
631/631 [===============================] - 30s 48ms/步 - 损失：842.0576 - val_loss： 840.2137
纪元 9/10
631/631 [=============================] - 33s 52ms/步 - 损失：842.7056 - val_loss：840.5657
纪元 10/10
631/631 [=============================] - 30s 48ms/步 - 损失：841.5714 - val_loss：839.8404
70/70 [================================] - 2s 16ms/步
[[52.569366]
[52.569286]
[52.569378]
...
[52.569344]
[52.569313]
[52.56937 ]]

如您所见，当我测试训练后的模型时，无论输入是什么，输出都是相同的。 val_loss 不会随着 epoch 数的增加而改善。这就是问题所在，我不明白发生了什么。
我反复检查了我的数据，X_train 已标准化，我尝试在模型上添加一些 drop out 和其他层，但没有任何变化。
也许使用 LSTM 无法做到这一点，但我认为数据非常简单。我真的想尝试找到一种方法来使用深度学习来找到它。]]></description>
      <guid>https://stackoverflow.com/questions/78753201/lstm-model-doesnt-train</guid>
      <pubDate>Tue, 16 Jul 2024 07:31:40 GMT</pubDate>
    </item>
    <item>
      <title>如何从 CLIP 模型获取多模态嵌入？</title>
      <link>https://stackoverflow.com/questions/78751682/how-to-get-multimodal-embeddings-from-clip-model</link>
      <description><![CDATA[我希望使用 CLIP 来获取多模态（图像和文本）数据行的单个嵌入。
假设我有以下模型：
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel
import torchvision.transforms as transforms

model = CLIPModel.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)
processor = CLIPProcessor.from_pretrained(&quot;openai/clip-vit-base-patch32&quot;)

def convert_image_data_to_tensor(image_data):
return torch.tensor(image_data)

dataset = df[[&#39;image_data&#39;, &#39;text_data&#39;]].to_dict(&#39;records&#39;)

embeddings = []
for data in dataset:
image_tensor = convert_image_data_to_tensor(data[&#39;image_data&#39;])
text = data[&#39;text_data&#39;]

input = processing(text=text, images=image_tensor, return_tensors=True)
with torch.no_grad():
output = model(**inputs)

我想获取 output 中计算的嵌入。我知道 output 具有附加属性 text_embeddings 和 image_embeddings，但我不确定它们以后如何交互。如果我想为每个记录获取单个嵌入，我应该将这些属性连接在一起吗？是否有其他属性以其他方式将两者结合起来？
这些是存储在输出中的属性：
print(dir(output))

[&#39;__annotations__&#39;, &#39;__class__&#39;, &#39;__contains__&#39;, &#39;__dataclass_fields__&#39;, &#39;__dataclass_params__&#39;, &#39;__delattr__&#39;, &#39;__delitem__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__getitem__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__len__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__post_init__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__reversed__&#39;, &#39;__setattr__&#39;, &#39;__setitem__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;clear&#39;, &#39;copy&#39;, &#39;fromkeys&#39;, &#39;get&#39;, &#39;image_embeds&#39;, &#39;items&#39;, &#39;keys&#39;, &#39;logits_per_image&#39;, &#39;logits_per_text&#39;, &#39;loss&#39;, &#39;move_to_end&#39;, &#39;pop&#39;, &#39;popitem&#39;, &#39;setdefault&#39;, &#39;text_embeds&#39;, &#39;text_model_output&#39;, &#39;to_tuple&#39;, &#39;update&#39;, &#39;values&#39;, &#39;vision_model_output&#39;]

此外，有没有办法指定 CLIP 输出的嵌入的大小？类似于如何在 BERT 配置中指定嵌入大小？
在此先感谢您的帮助。如果我误解了这里任何关键内容，请随时纠正我。]]></description>
      <guid>https://stackoverflow.com/questions/78751682/how-to-get-multimodal-embeddings-from-clip-model</guid>
      <pubDate>Mon, 15 Jul 2024 19:53:18 GMT</pubDate>
    </item>
    <item>
      <title>无法加载可教机器模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78237621/unable-to-load-the-teachable-machine-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78237621/unable-to-load-the-teachable-machine-model</guid>
      <pubDate>Thu, 28 Mar 2024 10:51:19 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试使用数据集包创建数据集时，出现“无法转换，因为列名不匹配”错误</title>
      <link>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</link>
      <description><![CDATA[DataFrame 结构
上图显示了我的数据的结构。
from sklearn.model_selection import train_test_split
from datasets import Features, ClassLabel, Value, Dataset, DatasetDict

df_train, df_tmp = train_test_split(
movie_df,stratify=movie_df[&quot;label&quot;], test_size=0.2)

df_val, df_test = train_test_split(
df_tmp,stratify=df_tmp[&quot;label&quot;], test_size=0.5)

ds_features = Features({&quot;text&quot;: Value(&quot;string&quot;), &quot;label&quot;: ClassLabel(names=labels)})

dataset = DatasetDict({
&quot;train&quot;: Dataset.from_pandas(df_train.reset_index(drop=True),features=ds_features),
&quot;valid&quot;: Dataset.from_pandas(df_val.reset_index(drop=True),features=ds_features),
&quot;test&quot;: Dataset.from_pandas(df_test.reset_index(drop=True),features=ds_features)})

dataset

此代码给我一个值错误，如下所示：
错误
错误
我期望得到类似的东西，但值不一样：
DatasetDict({
train: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 13267
})
valid: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1658
})
test: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1659
})
})

有人能告诉我我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</guid>
      <pubDate>Wed, 13 Mar 2024 04:00:13 GMT</pubDate>
    </item>
    <item>
      <title>使用 Anaconda 在 docker 中为 k8s 开发机器学习 Python 应用程序</title>
      <link>https://stackoverflow.com/questions/71767475/machine-learning-python-app-in-docker-with-anaconda-for-k8s</link>
      <description><![CDATA[开发人员在 docker 中运行了一个用于机器学习的 Python 应用程序。特别是 Azure 容器实例。他们使用 micromamba:0.15.3，并且在 dockerfile 中还为 Web 服务器安装了 nginx。
Docker 文件末尾将运行：CMD [&quot;./start.sh&quot;]
以及其中的脚本：
service nginx start 
streamlit run app.py --theme.base &quot;dark&quot; --server.address localhost --server.port 5000 --server.enableCORS=false

我还看到他们在本地使用 anaconda 来运行 Web 应用程序。这也会运行 streamlit
现在我将删除 dockerfile 中的 nginx 部分，因为将迁移到 k8s，并将使用 nginx ingress controller + ingres 作为 vhost，它将指向正在运行的 python 服务
我应该为此使用哪个 Docker 映像？使用 conda、miniconda 或 python 官方映像有什么区别？我是否只需要一个可以添加 streamlit 的 python 图像，例如这里？
https://hub.docker.com/r/mambaorg/micromamba
https://hub.docker.com/_/python]]></description>
      <guid>https://stackoverflow.com/questions/71767475/machine-learning-python-app-in-docker-with-anaconda-for-k8s</guid>
      <pubDate>Wed, 06 Apr 2022 13:16:33 GMT</pubDate>
    </item>
    <item>
      <title>在 RNN 中未找到 rnn_utils 模块</title>
      <link>https://stackoverflow.com/questions/61175064/module-not-found-rnn-utils-in-rnn</link>
      <description><![CDATA[我需要使用这个库来构建我的模型，但是我遇到了这个错误。
from rnn_utils import *

没有名为“rnn_utils”的模块]]></description>
      <guid>https://stackoverflow.com/questions/61175064/module-not-found-rnn-utils-in-rnn</guid>
      <pubDate>Sun, 12 Apr 2020 17:00:00 GMT</pubDate>
    </item>
    </channel>
</rss>