<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 26 Apr 2024 18:17:10 GMT</lastBuildDate>
    <item>
      <title>无法为 RandomForest ML 模型提供自定义输入</title>
      <link>https://stackoverflow.com/questions/78392007/unable-to-give-custom-input-to-randomforest-ml-model</link>
      <description><![CDATA[我目前正在使用 RandomForestClassifier 开发分类模型，我从 YouTube 上自己学习了算法，所以我在这个项目上工作有点困难，所以我设计了模型并在测试集上进行了测试我从原始数据集中分离出来，我也得到了96%的准确率。问题是，当我尝试提供自定义输入时，我遇到一个错误，指出您提供的数组是一维数组，而模型需要一个二维数组作为输入。
我尝试使用“custom_input_2d = custom_input.reshape(1, -1)”将输入转换为二维数组，但随后弹出一个新错误：“发现样本数量不一致的输入变量：[528, 1]”。我该怎么办，我给出的输入是：[[ 21.008297 0.1.723587 131.92972 2.1.
3.3.0.0.1.683448 1.
1.2.3.]]。该模型需要输入 15 个特征，请帮我看看，我需要以哪种格式给模型输入，如果可能，请给出自定义输入作为示例。]]></description>
      <guid>https://stackoverflow.com/questions/78392007/unable-to-give-custom-input-to-randomforest-ml-model</guid>
      <pubDate>Fri, 26 Apr 2024 17:01:37 GMT</pubDate>
    </item>
    <item>
      <title>如何解决问题。帮助我[关闭]</title>
      <link>https://stackoverflow.com/questions/78391920/how-to-fix-the-problems-help-me</link>
      <description><![CDATA[我想创建一个决策树图
class_names = model.classes\_.astype(str)

plt.figure(figsize=(20,10))

plot_tree(模型，feature_names=X.columns，class_names=class_names，filled=True，rounded=True)

plt.show()

InvalidParameterError Traceback（最近一次调用最后一次）
单元格 In[73]，第 4 行
      1 类名 = model.classes_.astype(str)
      3 plt.figure(figsize=(20,10))
----&gt; 4plot_tree(模型，feature_names=X.columns，class_names=class_names，filled=True，rounded=True)
      5 plt.show()

文件 ~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:201，在 validate_params..decorator..wrapper(*args, **kwargs)
    198 to_ignore + = [“自我”，“cls”]
    199 params = {k: v for k, v in params.arguments.items() if k not in to_ignore}
--&gt; 201 验证参数约束（
    第202章
    第203章）
    205 尝试：
    206 与 config_context(
    第207章
    第208章
    209）
    210）：

文件〜/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95，在validate_parameter_constraints（parameter_constraints，params，caller_name）中
     89 其他：
     90 约束_str = (
     [第 91 回]
     92f” {约束[-1]}”
     93）
---&gt; 95 引发无效参数错误（
     96 f“{caller_name}的{param_name！r}参数必须是”
     97 f” {constraints_str}。而是得到了 {param_val!r}。”
     98）

InvalidParameterError：plot_tree 的“feature_names”参数必须是“list”或 None 的实例。 Got Index([&#39;未命名：0&#39;, &#39;专业&#39;, &#39;奖学金&#39;, &#39;交通&#39;, &#39;出勤&#39;,
       &#39;项目_工作&#39;，&#39;点&#39;]，
      dtype=&#39;object&#39;) 代替。

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78391920/how-to-fix-the-problems-help-me</guid>
      <pubDate>Fri, 26 Apr 2024 16:41:48 GMT</pubDate>
    </item>
    <item>
      <title>检查给定图像是否是另一个更大图像的裁剪</title>
      <link>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</link>
      <description><![CDATA[我有一些图片。其中一些图像是裁剪版本。
就像这里是原始图片大图
和裁剪后的图像小图像。
请注意，图像的形状（分辨率）不相同。
我有几双这样的。原始图像保存在一个文件夹中，裁剪后的图像保存在另一个文件夹中。
最终我想从这些图像中找到原始图像和裁剪图像对。
所以我想迭代这两个文件夹中的图像，并检查裁剪后的图像是否是更大图像的一部分。
但是我找不到任何算法可以用不同形状（分辨率）的图像给出这样的结果。
我已经尝试过cv2.matchTemplate和skimage.metrics.structural_similarity
但它们仅适用于形状（分辨率）相似的图像。]]></description>
      <guid>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</guid>
      <pubDate>Fri, 26 Apr 2024 10:32:29 GMT</pubDate>
    </item>
    <item>
      <title>数据科学中如何处理基于测验的数据？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78389543/how-to-deal-with-data-based-on-quiz-in-data-science</link>
      <description><![CDATA[这是我第一次使用真实数据处理真实项目，现在我正在处理一个数据科学项目（推荐系统），并且基于测验有很多关于客户的信息，所以探针是如何处理它吗？我应该给出答案缩写然后进行计算吗？我找不到像我这样的项目的例子，请分享任何答案，或者只是一个链接可以帮助我进行研究，我将不胜感激
我尝试将问题指定为功能，答案是值，但我不确定！
有些答案太长，无法作为一个值；我应该使用缩写吗？]]></description>
      <guid>https://stackoverflow.com/questions/78389543/how-to-deal-with-data-based-on-quiz-in-data-science</guid>
      <pubDate>Fri, 26 Apr 2024 09:36:13 GMT</pubDate>
    </item>
    <item>
      <title>如何在数学方程中表示使用样条变换器 + 线性回归拟合的模型。数据是高维的</title>
      <link>https://stackoverflow.com/questions/78389349/how-to-represent-a-model-fitted-using-spline-transformer-linear-regression-in</link>
      <description><![CDATA[我有一个由 5 个特征和 1 个目标组成的数据集。我使用样条变换器来转换特征，然后使用线性回归对其进行拟合。我正在使用 1 度和 5 节样条变换特征来拟合数据。现在我想用数学方程表示模型拟合，其中包括各个项以及交互项。
我怎样才能做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78389349/how-to-represent-a-model-fitted-using-spline-transformer-linear-regression-in</guid>
      <pubDate>Fri, 26 Apr 2024 09:02:21 GMT</pubDate>
    </item>
    <item>
      <title>寻求有关优化建筑平面图中门类型分析超参数的建议</title>
      <link>https://stackoverflow.com/questions/78389255/seeking-advice-on-optimizing-hyperparameters-for-door-type-analysis-in-architect</link>
      <description><![CDATA[我目前正在处理一个具有挑战性的项目，其中涉及检测建筑平面图中的门。虽然门的检测精度相当不错，但我在分析门类型时遇到了困难。
有超过 25 类门类型，例如 barn_single、bifold_double、swing_single_right_hand、swing_single_left_hand 等。每个类代表不同类型的门，这增加了任务的复杂性。
我有一个包含大约 5000 张平面图图像的数据集，我用它来训练模型。
我正在开发基于 Windows 的系统，如果您能帮助我确定超参数以改善门类型分析的结果，我将不胜感激。超参数是控制模型学习过程的设置，例如学习率、批量大小和训练周期数。
我使用 YOLOv7 作为预训练模型。
如果您熟悉机器学习或计算机视觉技术，任何有关调整这些超参数以获得更好结果的建议都将非常宝贵。此外，如果有任何不清楚的地方或者您需要更多详细信息，请告诉我，我将提供更多信息。
我尝试将学习率设置为

0.01
0.001
0.02
等等..

但最高可达68%。这是相当低的。主要原因是门型分类错误。检测门的准确率约为 96%。到目前为止，这是相当有效的。]]></description>
      <guid>https://stackoverflow.com/questions/78389255/seeking-advice-on-optimizing-hyperparameters-for-door-type-analysis-in-architect</guid>
      <pubDate>Fri, 26 Apr 2024 08:44:38 GMT</pubDate>
    </item>
    <item>
      <title>寻找最佳路由解决方案[关闭]</title>
      <link>https://stackoverflow.com/questions/78388418/looking-for-best-routing-solution</link>
      <description><![CDATA[我正在处理呼叫路由问题陈述。这里的呼叫路由意味着，当客户呼叫到达客户服务时，自定义将根据客户选择的菜单选项路由到代理。
我遇到的问题比这更复杂。
客户信息将包括位置、所选菜单选项、世界各地的语言。理想的代理应该是具有相同语言能力、能够解决所选菜单选项的人。
但智能体也并不复杂，智能体可能拥有不止一种语言技能，并且更擅长解决多个问题。如果来自美国的人打电话（即英语），则代理可能具有英语、俄语技能。因此，如果位置是俄罗斯，也应该根据代理的可用性，将此人作为目标，否则会转到语言为俄语的其他代理。
遇到这样的问题我该如何解决？有什么帮助或资源吗？]]></description>
      <guid>https://stackoverflow.com/questions/78388418/looking-for-best-routing-solution</guid>
      <pubDate>Fri, 26 Apr 2024 05:32:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么 50 个预测中只有 45 个，这里预测的是哪一列？</title>
      <link>https://stackoverflow.com/questions/78388371/why-is-there-only-45-predictions-out-of-50-and-which-column-is-predicted-here</link>
      <description><![CDATA[我在为自己的数据编码时使用了张量流教程。代码如下：
训练、验证、测试 = 数据[:420]、数据[420:450]、数据[450:]

类窗口生成器（）：
  def __init__(自我，输入宽度，标签宽度，移位，
             训练、验证、测试）：
    self.train = 火车
    self.val = val
    自测=测试
    self.input_width = input_width
    self.label_width = label_width
    self.shift = 移位
    self.total_window_size = input_width + 移位
    self.input_slice = 切片(0,input_width)
    self.input_indices = np.arange(self.total_window_size)[self.input_slice]
    self.label_start = self.total_window_size-self.label_width
    self.labels_slice = slice(self.label_start,无)
    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]

  def __repr__(自我):
    返回 &#39;​​\n&#39;.join([
        f&#39;总window_size: {self.total_window_size}&#39;,
        f&#39;输入索引：{self.input_indices}&#39;,
        f&#39;标签索引：{self.label_indices}&#39;])

  def split_window(自身,特征):
    输入=特征[:,self.input_slice,:]
    标签 = 特征[:,self.labels_slice,:]
    input.set_shape([无,self.input_width,无])
    labels.set_shape([无,self.label_width,无])
    返回输入、标签

  def make_dataset(自身,数据):
    数据 = np.array(数据,dtype=np.float32)
    ds = tf.keras.utils.timeseries_dataset_from_array(数据=数据，
                                                    目标=无，
                                                    序列长度 = self.total_window_size,
                                                    序列步幅 = 1,
                                                    随机播放=真，
                                                    批量大小 = 32,)
    ds = ds.map(self.split_window)
    返回数据

  @财产
  def train_(自身):
    返回 self.make_dataset(self.train)
  @财产
  def val_(自身):
    返回 self.make_dataset(self.val)
  @财产
  def test_(自我):
    返回 self.make_dataset(self.test)
最大纪元 = 100
defcompile_and_fit（模型，窗口，耐心= 30）：
  Early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;,
                               耐心=耐心，
                               模式=&#39;分钟&#39;,
                              详细 =1)
  reduce_lr =ReduceLROnPlateau(监视器=&#39;val_loss&#39;,因子=0.1,耐心=10,min_lr=1e-6,详细=1)
  model.compile(loss=MeanSquaredError(), 优化器 = Adam(), 指标=[MeanAbsoluteError()])
  历史= model.fit(window.train_,epochs=MAX_EPOCHS,validation_data=window.val_,callbacks=[early_stopping,reduce_lr])
  返回历史记录
Wide_window = WindowGenerator(input_width = 5,
                          标签宽度=1，
                          移位= 1，
                          火车=火车，
                          值=值，
                          测试=测试）
conv_model = 顺序（[输入（形状=（5,2），名称=&#39;编码器输入&#39;），
                     Conv1D(filters=32,kernel_size=5,activation=&#39;relu&#39;,name=&#39;conv1D&#39;),
                    密集（32，激活=&#39;relu&#39;，名称=&#39;dense1&#39;），
                    密集(1,name=&#39;dense2&#39;)])
历史=compile_and_fit(conv_model,wide_window)
y_pred = conv_model.predict(wide_window.test_)`

现在，输出是 (45,1,1)。由于测试大小为 50，输出大小不应该为 50 吗？当我将密集2单位保持为1时，这里预测的是哪一个？
我尝试阅读 timeseries_dataset_from_array 的文档，但仍然无法找出问题或解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78388371/why-is-there-only-45-predictions-out-of-50-and-which-column-is-predicted-here</guid>
      <pubDate>Fri, 26 Apr 2024 05:17:53 GMT</pubDate>
    </item>
    <item>
      <title>CNN 模型准确率达到 0% [已关闭]</title>
      <link>https://stackoverflow.com/questions/78388352/geeting-0-accuracy-in-cnn-model</link>
      <description><![CDATA[我正在尝试开发一个用于多类图像分类的顺序 CNN 模型。开发模型后，当我开始训练时，模型在第一个时期给出了准确性，但在第二个时期我没有获得任何准确性。但在第三个时期，我再次获得了准确性。为什么会发生这种情况？还有一个问题，您能否建议我如何提高模型的 f1 分数、精确度和召回率。
https://i.sstatic.net/bwt4nfUr.png
https://i.sstatic.net/Jpn1fW72.png)]]></description>
      <guid>https://stackoverflow.com/questions/78388352/geeting-0-accuracy-in-cnn-model</guid>
      <pubDate>Fri, 26 Apr 2024 05:12:05 GMT</pubDate>
    </item>
    <item>
      <title>推理时出现意外的输出图像</title>
      <link>https://stackoverflow.com/questions/78387970/unexpected-output-image-on-inference</link>
      <description><![CDATA[我正在尝试在颤动中升级图像。但我在输出图像中得到了意想不到的结果。请有人帮忙。我尝试了一些修改但卡住了。
模型形状：
输入名称：输入，形状：[0, 3, 0, 0]
输出名称：输出，形状：[0, 3, 0, 0]
原始图片
输出图像
LOG：I/flutter ( 592)：图像转换为标准化 Float32List
I/flutter ( 592)：图像标准化成功。
I/flutter ( 592)：输入张量创建成功。
I/颤动（592）：高2880宽1640

原图：高720宽210

这是我尝试过的代码：
 未来;推理（）异步{
    if (selectedImage == null) {
      debugPrint(&#39;未选择图像&#39;);
      返回;
    }

    var 预处理图像 =
    NormalizeImage.imageToNormalizedFloat32List(selectedImage!);

    最终形状 = [1, 3, selectedImage!.height, selectedImage!.width];

    debugPrint(&#39;图像标准化成功。&#39;);

    最终输入Ort =
    OrtValueTensor.createTensorWithDataList(preprocessedImage, shape);

    最终输入 = {&#39;input&#39;: inputOrt};

    debugPrint(&#39;输入张量创建成功。&#39;);

    最终 runOptions = OrtRunOptions();
    最终输出=等待ortSession.runAsync（runOptions，输入）；

    inputOrt.release();
    runOptions.release();


    输出？.forEach((元素) {
      最终输出值=元素？.值；
      if (outputValue 为 List&gt;&gt;) {
        img.Image generatedImage =generateImageFromOutput(outputValue);
        列表 pngBytes = img.encodePng( generatedImage);
        img.Image解码图像 = img.decodeImage(Uint8List.fromList(pngBytes))!;

        显示对话框（
          上下文：上下文，
          构建器：（BuildContext 上下文）{
            返回对话框（
              孩子：大小框（
                宽度：200，
                高度：200，
                子: Image.memory(Uint8List.fromList(img.encodePng(decodedImage))),
              ),
            ）；
          },
        ）；
      } 别的 {
        debugPrint(“输出类型未知”);
      }
      元素？.release();
    });
  }
    img.ImagegenerateImageFromOutput(List&gt;&gt;输出) {
    最终宽度=输出[0][0].长度；
    最终高度=输出[0][0][0].长度；
    最终通道=输出[0].长度； // 通道数

    debugPrint(“高度：$height，宽度：$width，通道：$channels”);

    // 创建具有指定尺寸的新图像
    img.Image imgData = img.Image(宽度, 高度);


    for (int y = 0; y &lt; 高度; y++) {
      for (int x = 0; x &lt; 宽度; x++) {
        双红=输出[0][y][x][0]；
        双绿 = 输出[0][y][x][1]；
        双蓝色=输出[0][y][x][2];

        // 将双精度值转换为整数
        int r = (红色 * 255).toInt().clamp(0, 255);
        int g = (绿色 * 255).toInt().clamp(0, 255);
        int b = (蓝色 * 255).toInt().clamp(0, 255);

        // 设置图像中的像素颜色
        imgData.setPixel(x, y, img.getColor(r, g, b));

        // 调试语句
        print(&#39;($x, $y) 处的像素&#39;);
        print(&#39;红色: $red, 绿色: $green, 蓝色: $blue&#39;);
        print(&#39;转换后的 RGB 值: ($r, $g, $b)&#39;);
      }
    }

    返回img数据；
  }

标准化类别
class NormalizeImage {
  静态Float32List imageToNormalizedFloat32List（图像图像）{
    最终 int 高度 = image.height;
    最终 int 宽度 = image.width;

    Float32List float32Image = Float32List(3 * 高度 * 宽度);

    for (int i = 0; i &lt; 高度; i++) {
      for (int j = 0; j &lt; 宽度; j++) {
        最终 int 像素索引 = (i * 宽度 + j) * 3;
        最终 int 像素 = image.getPixel(j, i);

        float32Image[像素索引] = getRed(像素) / 255.0;
        float32Image[像素索引 + 1] = getGreen(像素) / 255.0;
        float32Image[像素索引 + 2] = getBlue(像素) / 255.0;
      }
    }

    print(&quot;图像转换为规范化的 Float32List&quot;);
    返回 float32Image；
  }
}

]]></description>
      <guid>https://stackoverflow.com/questions/78387970/unexpected-output-image-on-inference</guid>
      <pubDate>Fri, 26 Apr 2024 02:39:43 GMT</pubDate>
    </item>
    <item>
      <title>识别图像中红色粒子占据的像素</title>
      <link>https://stackoverflow.com/questions/78387055/identify-pixels-occupied-by-red-particles-in-image</link>
      <description><![CDATA[我有一些塑料颗粒和水波实验的图像。目标是自动识别塑料颗粒。它们有时会重叠，我不需要找到单个粒子，找到那些包含塑料的像素就足够了。
由于粒子是红色的，并且背景大多是白色或黑色，我想我可以进行简单的阈值处理，如果R &gt; &gt;，则说像素是塑料。 5*B 和 R&gt; 0.25，其中 R 和 B 是红色和蓝色通道。然而，不同实验之间的曝光差异很大，有时在实验中，当部分表面被水覆盖时，所以我的方法不能非常一致地工作，有时会错误地识别侧面的黑色裂缝。
我想知道还有什么其他选择。我对神经网络的经验有限，所以我不确定这是否可行（需要付出合理的努力）。特别是，我认为形状不会有太大帮助，因为粒子靠近在一起并且部分重叠，它们之间的对比度很差，但也许颜色就足够了？
示例图像：


]]></description>
      <guid>https://stackoverflow.com/questions/78387055/identify-pixels-occupied-by-red-particles-in-image</guid>
      <pubDate>Thu, 25 Apr 2024 20:14:01 GMT</pubDate>
    </item>
    <item>
      <title>呼吸信号的对数功率谱</title>
      <link>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</link>
      <description><![CDATA[我的数据集是噪声频谱的LPS，我的标签是干净频谱的LPS，每个图片大小是（1025*1292）。我使用unet作为我的模型。
型号：
导入火炬
将 torch.nn 导入为 nn

解码器类（nn.Module）：
    def __init__(self, in_channels,out_features, kernel_size, maxpoolindex, apply_dropout,stride):
        super(解码器, self).__init__()
        self.conv = nn.Conv2d(in_channels=in_channels、out_channels=out_features、kernel_size=kernel_size、stride=stride、padding=0、bias=True)
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.LeakyReLU(负斜率=0.2)
        self.dropout = nn.Dropout(p=0.1)
        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) 如果 maxpoolindex == 1 否则无

    def 前向（自身，x）：
        x = self.conv(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        如果 self.maxpool 不是 None：
            x = self.maxpool(x)
        返回x

编码器类（nn.Module）：
    def __init__(self,in_channels, out_features, kernel_size, apply_dropout):
        super(编码器, self).__init__()
        self.conv_transpose = nn.ConvTranspose2d（in_channels = in_channels，out_channels = out_features，kernel_size = kernel_size，stride = 2，padding = 0，bias = True）
        self.batch_norm = nn.BatchNorm2d(out_features)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.1)

    def 前向（自身，x）：
        x = self.conv_transpose(x)
        x = self.batch_norm(x)
        x = self.relu(x)
        如果 self.dropout 不是 None：
            x = self.dropout(x)
        返回x

class DenoiseUnet(nn.Module):#除到第一个奇数停止的设计
    def __init__(自身):
        超级（DenoiseUnet，自我）.__init__()
        self.down_procedure = nn.ModuleList([
            解码器(1,8,2,0,0,2),
            解码器(8,16,2,0,0,2),
            解码器(16,32,2,0,0,2),
            解码器(32,128,2,0,0,2),
            解码器(128,128,1,0,0,1)
        ]）
        self.up_procedure = nn.ModuleList([
            编码器(2​​56,32,2,0),
            编码器(64,16,2,0),
            编码器(32,8,2,0),
            编码器(16,4,2,0),
        ]）
        self.convert = nn.ConvTranspose2d(4, 1, kernel_size=1, stride=1, padding=0)


    def 前向（自身，x）：
        连接=[]
        对于 self.down_procedure 中的 down：
            x = 向下(x)
            连接.append(x)

        连接=列表（反转（连接[：-1]））
        对于 up，在 zip(self.up_procedure, connection) 中连接：


            如果 x.shape[2] &lt;连接.形状[2]：
              连接 = 连接[:, :, :x.shape[2], :]
            别的：
              x = x[:, :, :connect.shape[2], :]

            如果 x.shape[3] &lt;连接.形状[3]：
              连接 = 连接[:, :, :, :x.shape[3]]
            别的：
              x = x[:, :, :, :connect.shape[3]]



            x = torch.cat([x, 连接], 暗淡=1)
            x = 上(x)

        y = self.convert(x)
        返回y


模型 = DenoiseUnet()
打印（模型）

但是经过 10 轮训练后，我得到这样的结果：
https://i.sstatic.net/b8DxXHUr.png
https://i.sstatic.net/UDhZNKHE.png
一个是预测结果，一个是测试，任何人都可以帮我找出问题所在吗？
数据集数量不同，看起来是一样的。]]></description>
      <guid>https://stackoverflow.com/questions/78386374/log-power-spectrum-for-breath-signal</guid>
      <pubDate>Thu, 25 Apr 2024 17:43:28 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 TimeSeriesSplit 处理面板数据？</title>
      <link>https://stackoverflow.com/questions/78370489/how-to-use-timeseriessplit-for-panel-data</link>
      <description><![CDATA[我一直在尝试使用TimeSeriesSplit对于面板数据。我所说的面板数据是指人口的年度图片。我对多年来的数据分割很感兴趣。该人口正在不断变化，每年的人口规模并不相同。因此，直接使用 TimeSeriesSplit 是不可能的。
基本上我试图获得以下简历方案：

我设法使用以下代码来做到这一点：
将 pandas 导入为 pd，将 numpy 导入为 np
将seaborn导入为sns，将matplotlib.pyplot导入为plt

从 sklearn.datasets 导入 make_regression
从 sklearn.dummy 导入 DummyRegressor
从 sklearn.metrics 导入mean_squared_error
从 sklearn.model_selection 导入 TimeSeriesSplit

X_测试，y_测试 = []，[]

开始年份 = 2010
年底 = 2020 年

对于 np.arange(start_year, end_year+1) 中的年份：
    X_year, y_year = make_regression(n_samples=5+year-start_year, n_features=2, 偏差=100, 噪声=1, random_state=year)
    X_year = pd.DataFrame(X_year).rename(columns={0:&#39;X1&#39;, 1:&#39;X2&#39;})
    X_year[&#39;年份&#39;] = 年
    y_year = pd.Series(y_year)
    X_test.append(X_year)
    y_test.append(y_year)
    
X_test, y_test = pd.concat(X_test), pd.concat(y_test)

# 建模

X = X_测试
y = y_测试
年 = np.unique(X_test[&#39;year&#39;])

# 建模
模型= DummyRegressor（策略=“平均值”）
指标=均方误差
cv = TimeSeriesSplit(n_splits=len(年)-1)

年数=[]
分辨率=[]

对于 i，枚举（cv.split（years））中的（train_year，test_year）：
    
    print(f&quot;折叠 {i}:&quot;)
    print(f&quot;火车：索引={years[train_year]}&quot;)
    print(f&quot;测试：index={years[test_year]}&quot;)
    
    years_folds.append((years[train_year],years[test_year]))
    
    train_filter = X[&#39;year&#39;].isin(years[train_year])
    test_filter = X[&#39;year&#39;].isin(years[test_year])
    
    X_train, y_train = X.loc[train_filter.values], y[train_filter.values]
    X_test, y_test = X.loc[test_filter.values], y[test_filter.values]
    
    model.fit(X_train, y_train)
    分数 = 指标(model.predict(X_test), y_test)
    print(f&#39; {score=:.3}&#39;)
    res.append((年份[test_year][0], 分数))

情节_年份_折叠（年份_折叠）
    
Folds_res = pd.DataFrame(res,columns=[&#39;test_year&#39;, metric.__name__])
Folds_res.plot.scatter(x=&#39;test_year&#39;, y=metric.__name__, title=f&#39;{metric.__name__} over test_year&#39;);

注意：我使用虚拟数据集和虚拟模型是为了提供运行示例。这不是我帖子的主题。
正如您所注意到的，我必须使用一个技巧：我分割年份而不是数据。我想知道：是否有一种标准方法可以使用 sklearn cv 对象分割数据？目标是在 cross_val_score 函数中使用它。]]></description>
      <guid>https://stackoverflow.com/questions/78370489/how-to-use-timeseriessplit-for-panel-data</guid>
      <pubDate>Tue, 23 Apr 2024 07:14:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Flower 和 Tensorflow 向联邦学习中的服务器发送额外参数？</title>
      <link>https://stackoverflow.com/questions/78221905/how-to-send-extra-parameters-to-server-in-federated-learning-with-flower-and-ten</link>
      <description><![CDATA[我想将带有模型更新的额外参数发送到服务器，然后在服务器中将这些额外参数用于其他目的。我在这个项目中使用 Flower 和 Tensorflow。在发送额外参数之前，我的模型运行正常。目前我有这些代码客户端模型server.py。
如何在服务器中成功发送额外参数或值并接收它？
谢谢你的帮助。
我尝试在 get_parameter 方法中发送其他参数，并使用 FedAvg 策略接收它。但我一次又一次收到这个错误。 错误]]></description>
      <guid>https://stackoverflow.com/questions/78221905/how-to-send-extra-parameters-to-server-in-federated-learning-with-flower-and-ten</guid>
      <pubDate>Mon, 25 Mar 2024 21:38:40 GMT</pubDate>
    </item>
    <item>
      <title>惰性预测.监督.惰性分类器。 ImportError：无法从“sklearn.utils.deprecation”导入名称“_raise_dep_warning_if_not_pytest”</title>
      <link>https://stackoverflow.com/questions/67305004/lazypredict-supervised-lazyclassifier-importerror-cannot-import-name-raise-d</link>
      <description><![CDATA[我尝试过：
from lazypredict.Supervised import LazyClassifier

但得到以下回溯：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-1-f518cae57501&gt;在&lt;模块&gt;中
     10 从sklearn.linear_model导入LogisticRegression
     11 从 sklearn.ensemble 导入 RandomForestClassifier
---&gt; 12 从lazypredict.Supervised导入LazyClassifier
     13 从sklearn.model_selection导入GridSearchCV
     14 从sklearn.metrics导入accuracy_score

 中的 ~\AppData\Roaming\Python\Python38\site-packages\lazypredict\Supervised.py
     14 从sklearn.preprocessing导入StandardScaler、OneHotEncoder、OrdinalEncoder
     15 从 sklearn.compose 导入 ColumnTransformer
---&gt; 16 从 sklearn.utils.testing 导入 all_estimators
     17 从 sklearn.base 导入 RegressorMixin
     18 从 sklearn.base 导入 ClassifierMixin

S:\anaconda\lib\site-packages\sklearn\utils\testing.py 在  中
      5 来自 . import _testing # 类型：忽略
      6 从 ..externals._pep562 导入 Pep562
----&gt; 7 从 ..utils.deprecation 导入 _raise_dep_warning_if_not_pytest
      8
      9 deprecated_pa​​th = &#39;sklearn.utils.testing&#39;

ImportError：无法从“sklearn.utils.deprecation”导入名称“_raise_dep_warning_if_not_pytest”（S：\ anaconda \ lib \ site-packages \ sklearn \ utils \ deprecation.py）

我当时在 Jupyter 笔记本上工作，并且也已经尝试升级 scikit-learn。]]></description>
      <guid>https://stackoverflow.com/questions/67305004/lazypredict-supervised-lazyclassifier-importerror-cannot-import-name-raise-d</guid>
      <pubDate>Wed, 28 Apr 2021 17:22:07 GMT</pubDate>
    </item>
    </channel>
</rss>