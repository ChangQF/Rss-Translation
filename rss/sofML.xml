<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 25 Apr 2024 15:14:36 GMT</lastBuildDate>
    <item>
      <title>我的预测结果中缺少值（NaN），但数据集中没有 NaN 值</title>
      <link>https://stackoverflow.com/questions/78385503/i-have-missing-valuesnan-in-my-prediction-result-but-theres-no-nan-value-in-t</link>
      <description><![CDATA[我正在处理两个数据集（train.csv 和 test.csv）。
我已对这两个文件执行了 EDA。
我已经训练了我的模型并且它运行良好。
但是我对 test.csv 的一些预测结果显示 NaN，我无法弄清楚问题出在哪里。



test_df_copy2 = test_df_copy.drop([“Id”], axis = 1)

#逻辑回归
logPred = log_reg.predict(test_df_copy2)
＃决策树
dec_tree_predict = dec_tree.predict(test_df_copy2)
#SVC 预测
svc_predict = svc_model.predict(test_df_copy2)
#随机森林
rf_predict = random_forest.predict(test_df_copy2)

#将我们的预测结果转换为数据帧
Log_predict_df =pd.DataFrame(logPred)
dec_tree_predict_df =pd.DataFrame(dec_tree_predict)
svc_predict_df =pd.DataFrame(svc_predict)
rf_predict_df =pd.DataFrame(rf_predict)

#将我们的预测添加到我们的数据集中
测试结果=测试df_copy
test_result[&#39;log_pred&#39;] = Log_predict_df
test_result[&#39;tree_pred&#39;] = dec_tree_predict_df
test_result[&#39;svc_pred&#39;] = svc_predict_df
test_result[&#39;rf_pred&#39;] = rf_predict_df
]]></description>
      <guid>https://stackoverflow.com/questions/78385503/i-have-missing-valuesnan-in-my-prediction-result-but-theres-no-nan-value-in-t</guid>
      <pubDate>Thu, 25 Apr 2024 14:56:30 GMT</pubDate>
    </item>
    <item>
      <title>改进长尾数据的回归模型</title>
      <link>https://stackoverflow.com/questions/78384887/improving-a-regression-model-for-long-tailed-data</link>
      <description><![CDATA[我正在对来自信贷持有的预测收入数据进行建模。正如预期的那样，数据是长尾的，收入较高的数据要小得多。在下图中，它是这些收入在申报收入和预测收入之间的分布。 申报收入与预测收入
正如您所看到的，该模型将低收入向上移动，但没有捕捉到长尾。我完成了一些特征工程步骤，例如对任何货币值进行对数转换、查找不同风险因素（例如信用评分）的收入中位数、查找区域收入中位数等。
模型参数如下：调优的catboost模型
{&#39;迭代&#39;：300，&#39;学习率&#39;：0.1，&#39;深度&#39;：8，&#39;损失函数&#39;：&#39;RMSE&#39;}
我选择了 catboost，因为就 RMSE 而言，它是使用 Pycaret 时最好的模型。
任何具有长尾数据建模经验并愿意提供指导的人将不胜感激]]></description>
      <guid>https://stackoverflow.com/questions/78384887/improving-a-regression-model-for-long-tailed-data</guid>
      <pubDate>Thu, 25 Apr 2024 13:09:19 GMT</pubDate>
    </item>
    <item>
      <title>当我关心 venv 时，我遇到了这个问题：此时是意外的</title>
      <link>https://stackoverflow.com/questions/78384811/when-i-careate-venv-i-got-this-issue-was-unexpected-at-this-time</link>
      <description><![CDATA[
conda create -p venv python==3.10 -y
或y
conda 激活 venv/
然后我得到了错误：此时是意外的

这个问题有什么解决办法吗？
如果有人知道如何解决此问题，请提供我应该遵循的步骤。]]></description>
      <guid>https://stackoverflow.com/questions/78384811/when-i-careate-venv-i-got-this-issue-was-unexpected-at-this-time</guid>
      <pubDate>Thu, 25 Apr 2024 12:54:19 GMT</pubDate>
    </item>
    <item>
      <title>在 Android 上使用自定义后端匹配相机源中的多个对象以实现 AR 效果 [关闭]</title>
      <link>https://stackoverflow.com/questions/78384532/matching-multiple-objects-in-camera-feed-on-android-with-custom-backend-for-ar-e</link>
      <description><![CDATA[我们的团队正在开发一款 Android 应用，我们需要将摄像头馈送的多个对象与自定义后端进行匹配。后端有一个包含不同图像及其各自 AR 效果（如视频或 3D 模型）的数据库。当在摄像头源中检测到对象/图像时，我们希望在摄像头源中显示该对象/图像上的相应 AR 效果。
Android 应用端：

如何在 Android 应用端实现此目标？
我们应该使用哪种框架或库来：
捕获摄像头源？
将摄像头源发送到后端进行处理。
从后端接收结果？
在检测到的对象/图像上显示 AR 效果（视频、3D 模型）。

自定义后端：

我们如何有效地将摄像头框架中的对象与存储在数据库中的图像进行匹配？
我们如何将每个匹配的对象与相应的 AR 效果（视频或 3D 模型）关联起来？
我们应该向 Android 应用公开哪些 API 协议来发送摄像头馈送、接收结果并获取相对于标记/相应图像的位置的 AR 效果？

我们尝试了 ARCore 和一些 REST API 等，但结果尚未令人满意。]]></description>
      <guid>https://stackoverflow.com/questions/78384532/matching-multiple-objects-in-camera-feed-on-android-with-custom-backend-for-ar-e</guid>
      <pubDate>Thu, 25 Apr 2024 12:04:11 GMT</pubDate>
    </item>
    <item>
      <title>R 中 Caret、Yardstick 和 MLeval 之间关于精确召回的差异</title>
      <link>https://stackoverflow.com/questions/78384468/discrepancy-between-caret-yardstick-and-mleval-in-r-regarding-precision-recall</link>
      <description><![CDATA[我正在尝试绘制精确召回曲线并测量插入符交叉验证的火车对象的曲线下面积。只需调用对象名称即可生成精确召回曲线下面积的一些值，如下所示：
&lt;前&gt;&lt;代码&gt;&gt;射频

随机森林

807 个样本
 11 预测器
  2 个类别：“X0”、“X1”

无需预处理
重采样：交叉验证（10 倍）
样本量摘要：727, 726, 727, 726, 727, 726, ...
跨调整参数重新采样结果：

  mtry splitrule AUC 精确召回率 F
   2 基尼系数 0.8179379 0.8618888 0.6713675 ​​0.7494214
   2 个额外树 0.8061601 0.8960233 0.5725071 0.6901257
   7 基尼系数 0.7798593 0.8775955 0.8037037 0.8360293
   7 个额外树 0.8004585 0.8587664 0.7696581 0.8090205
  12 基尼 0.7659204 0.8578710 0.8229345 0.8364962
  12 个额外树 0.7840497 0.8498209 0.7925926 0.8167108

调整参数“min.node.size”保持恒定为 1
AUC 用于使用最大值来选择最佳模型。
该模型使用的最终值为 mtry = 2、splitrule = gini 和 min.node.size = 1。

但是，当我尝试使用尺度绘制实际曲线时，我得到了完全不同的结果。
prRf &lt;- pr_curve(rf$pred, X0, true = obs)

ggplot() +
  geom_path(aes(x = 召回率，y = 精度)，颜色 = “蓝色”，线型 = 1，数据 = prRf) +
  xlab(“召回”) +
  ylab(“精度”) +
  theme_minimal() +
  ylim(0,1)

pr_auc(rf$pred, X0, 真相 = obs)

在这里，曲线看起来“更好”了很多。与插入符给出的内部 AUPR 相比，AUPR 更高（0.878 与 0.817）。对于 MLeval 的简单运行也是如此，它同样给出了“更好”的结果。结果。
&lt;前&gt;&lt;代码&gt;evalm(rf)

所有这些都让我很困惑，我觉得我可能正在以某种方式在样本内进行测试，但我不确定如何在不事先拆分数据的情况下正确地进行测试。如有任何帮助，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78384468/discrepancy-between-caret-yardstick-and-mleval-in-r-regarding-precision-recall</guid>
      <pubDate>Thu, 25 Apr 2024 11:51:30 GMT</pubDate>
    </item>
    <item>
      <title>在数据分割过程中保留数据的空间分布</title>
      <link>https://stackoverflow.com/questions/78383883/preserving-spatial-distribution-of-data-during-data-splitting</link>
      <description><![CDATA[我正在尝试使用随机森林模型来模拟德国巴伐利亚河流中的硝酸盐浓度。我使用 Python，主要使用 sklearn。我有 490 个水质站的数据。我遵循 LongzhuQ.Shen 等人论文中的方法，该论文可以在这里找到：https://www.nature.com/articles/s41597-020-0478-7
我想将数据集分成训练集和测试集，以便两个集中数据的空间分布相同。这个想法是，如果数据分割忽略空间分布，则训练集可能最终会集中来自人口稠密区域的点，而忽略稀疏区域。这可能会扭曲模型的学习过程，使其在整个感兴趣领域的准确性或概括性降低。 sklearn train_test_split只是将数据随机划分为训练集和测试集，并且不考虑数据中的空间模式。
我上面提到的论文遵循了这种方法：“我们将完整的数据集分为两个子数据集，分别是训练和测试。为了考虑监测站空间分布的异质性，我们在数据分割步骤中采用了空间密度估计技术，通过使用带宽为 50 km 的高斯核（使用 GRASS GIS33 中可用的 v.kernel）构建密度表面来计算每个物种和季节。所得密度表面的像素值用作权重因子，将数据分成具有相同空间分布的训练和测试子集。”
我想遵循相同的方法，但我不使用草地 GIS，而是自己用 Python 构建密度表面。我还提取了概率密度值和站点的权重。 （附图）
现在我面临的唯一问题是如何使用这些权重将数据分成训练集和测试集？我检查了sklearn train_test_split函数中没有可以考虑权重的关键字。我也与GPT 4聊天来回，但它也无法给我一个明确的答案。我在互联网上也没有找到任何关于此的具体信息。也许我错过了一些东西。
还有其他函数可以用来执行此操作吗？或者我必须编写自己的算法来进行分割？如果是后者，您能否建议我一种方法，以便我自己编写代码？
在附图中您可以看到站点的位置以及使用核密度估计方法（使用高斯核）生成的概率密度面。
还附上我的数据框的屏幕截图，让您了解数据结构。 （经度（‘lon’）列之后的所有列都用作特征。NO3 列用作目标变量。）
如果有任何答案，我将不胜感激。
请查找附件图片以供参考。
使用高斯核的核密度估计方法生成的概率密度曲面。&lt; /p&gt;
我用来模拟硝酸盐浓度的数据集]]></description>
      <guid>https://stackoverflow.com/questions/78383883/preserving-spatial-distribution-of-data-during-data-splitting</guid>
      <pubDate>Thu, 25 Apr 2024 10:10:26 GMT</pubDate>
    </item>
    <item>
      <title>在 lightgbm 中，当数据集构建中已经存在时，为什么 train 和 cv API 接受 categorical_feature 参数</title>
      <link>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</link>
      <description><![CDATA[以下是.cv lightgbm的API
&lt;块引用&gt;
lightgbm.cv（params，train_set，num_boost_round = 100，folds = None，nfold = 5，stratified = True，shuffle = True，metrics = None，feval = None，init_model = None，feature_name =&#39;auto&#39;，categorical_feature =&#39;auto&#39;，fpreproc=None，seed=0，callbacks=None，eval_train_metric=False，return_cvbooster=False）

有一个参数cateogrical_feature
&lt;块引用&gt;
分类特征。如果是 int 列表，则解释为索引。如果是 str 列表，则解释为功能名称（还需要指定 feature_name）。

现在是 .train API 
&lt;块引用&gt;
lightgbm.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, keep_training_booster=False, 回调=None ）

这里还有一个categorical_feature参数。这方面的文档与上面相同
现在，您注意到这两个 API 都使用 lightgbm 数据集 本身带有一个categorical_feature 参数。文档完全一样
问题：

如果两者都指定，哪一个优先？
建议在哪一个位置指定 categorical_feature？
这两种选择在 lightgbm 管道的工作内部有什么不同吗？
]]></description>
      <guid>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</guid>
      <pubDate>Thu, 25 Apr 2024 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>培训法学硕士执行职能</title>
      <link>https://stackoverflow.com/questions/78383583/training-a-llm-to-execute-functions</link>
      <description><![CDATA[我想开发一个能够在给定智能家居环境中执行操作并回答问题的聊天机器人。
我很好奇如何通过法学硕士来做到这一点。如何定制/训练模型来执行代码？
举一个简单的例子：当我告诉聊天机器人“打开客厅的灯”时它应该回答“我会打开客厅的灯”并同时在后台打开它（假设我有一个可以调用的 API/代码）。
您可以分享一些资源甚至示例来了解该流程吗？
我了解一些关于自定义模型的知识，例如添加系统消息或调整模型的温度，并且我之前还培训了法学硕士来生成软件需求。但我不知道如何训练模型来执行打开或关闭智能设备等操作。
我目前正在使用 Ollama 来管理和自定义模型。]]></description>
      <guid>https://stackoverflow.com/questions/78383583/training-a-llm-to-execute-functions</guid>
      <pubDate>Thu, 25 Apr 2024 09:23:07 GMT</pubDate>
    </item>
    <item>
      <title>Randforest，关于“对于每个节点，选择不替换的特征”的问题</title>
      <link>https://stackoverflow.com/questions/78383228/randforest-question-on-for-each-node-select-features-without-replacement</link>
      <description><![CDATA[从书籍（与chatGPT仔细检查）中，随机森林的步骤可以总结如下：
&lt;块引用&gt;

绘制大小为 n 的随机引导样本（随机选择 n 个示例
来自带有替换的训练数据集）。
从引导样本中生成决策树。在每个节点：

&lt;块引用&gt;
a)。随机选择d个特征，不进行替换。
b).使用提供最佳分割的功能来分割节点
例如，最大化信息增益的目标函数。
3. 重复步骤 1-2 k 次。
...


我的问题来自粗体字：既然特征是无替换选择的，如果选择了所有特征，树会停止生长吗（因为没有可供选择的特征）？ ——看来这不是真的。但这一步怎么理解呢？]]></description>
      <guid>https://stackoverflow.com/questions/78383228/randforest-question-on-for-each-node-select-features-without-replacement</guid>
      <pubDate>Thu, 25 Apr 2024 08:20:17 GMT</pubDate>
    </item>
    <item>
      <title>如何向 DBSCAN 添加自定义参数</title>
      <link>https://stackoverflow.com/questions/78383085/how-to-add-custom-parameter-to-dbscan</link>
      <description><![CDATA[我一直在努力创建一个自定义 DBSCAN，在其中我可以创建一个自定义参数来根据出租车 ID 过滤距离，以查看哪些出租车造成了交通堵塞。我添加了时间和距离矩阵，但我不知道如何创建一个新的 eps 来根据 ID 过滤出租车。如果 eps 值较高，则应对不同的 Taix ID 进行聚类，如果较低，则应对同一出租车进行聚类。有关如何进行的任何提示？谢谢
time_dist = pdist(X[:, 0].reshape(n, 1), metric=self.metric)
euc_dist = pdist(X[:, 1:], metric=self.metric)


# 使用 time_dist 过滤 euc_dist 矩阵
dist = np.where(time_dist &lt;= self.eps2, euc_dist, 2 * self.eps1)

db = DBSCAN(eps=self.eps1,
            min_samples=self.min_samples,
            指标=&#39;预先计算&#39;）
db.fit(正方形(距离))

self.labels = db.labels_
]]></description>
      <guid>https://stackoverflow.com/questions/78383085/how-to-add-custom-parameter-to-dbscan</guid>
      <pubDate>Thu, 25 Apr 2024 07:54:41 GMT</pubDate>
    </item>
    <item>
      <title>我可以做些什么来优化 C++ 中的 CatBoost（或其他）模型？</title>
      <link>https://stackoverflow.com/questions/78382887/what-can-i-do-to-optimizing-catboost-or-other-model-in-c</link>
      <description><![CDATA[我的 C++ 程序从 .cbm 文件加载 CatBoost 模型并进行预测。但该模型对我来说花费了太多时间，我想减少它的延迟。
我想知道我可以在 C++ 中做什么来优化此类模型的延迟。
#include “wrapped_calcer.h”

结构模型{

    静态内联 ModelCalcerWrapper 模型 = ModelCalcerWrapper(&quot;./model/model.cbm&quot;);

    std::向量 xdataArray；

    无效 updateXData() {
        // 更新xdataArray中的数据
        // 我将计算一些值并将其放入模型中
    }

    双预测（）{
        // 我认为这一步对我来说花费了太多时间
        返回 model.Calc(xdataArray, {});
    }

};
]]></description>
      <guid>https://stackoverflow.com/questions/78382887/what-can-i-do-to-optimizing-catboost-or-other-model-in-c</guid>
      <pubDate>Thu, 25 Apr 2024 07:17:43 GMT</pubDate>
    </item>
    <item>
      <title>尝试将自定义模型部署到 OpenSearch 中会引发 RuntimeError: KeyError: token_type_ids</title>
      <link>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</guid>
      <pubDate>Fri, 19 Apr 2024 13:36:18 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn import 无法在 python 中导入名称“METRIC_MAPPING64”</title>
      <link>https://stackoverflow.com/questions/78327535/scikit-learn-import-cannot-import-name-metric-mapping64-in-python</link>
      <description><![CDATA[我试图将 scikit-learn 中的线性模型导入到 vscode 中的 python 代码中，并收到意外的错误消息。
导入sklearn
从sklearn导入线性模型

错误：
无法从“sklearn.metrics._dist_metrics”导入名称“METRIC_MAPPING64”

我不想导入这些指标，如何解决这个问题？
使用的scikit-learn版本是1.1.3。]]></description>
      <guid>https://stackoverflow.com/questions/78327535/scikit-learn-import-cannot-import-name-metric-mapping64-in-python</guid>
      <pubDate>Mon, 15 Apr 2024 09:54:33 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 生存模型</title>
      <link>https://stackoverflow.com/questions/75010397/xgboost-survival-model</link>
      <description><![CDATA[我正在尝试开发 XGBoost 生存模型。这是我的代码的快速快照：
X = df_High_School[[&#39;Gender&#39;, &#39;Lived_both_Parents&#39;, &#39;Moth_Born_in_Canada&#39;, &#39;Father_Born_in_Canada&#39;,&#39;Born_in_Canada&#39;,&#39;Aboriginal&#39;,&#39;Visible_Minority&#39;]] # 协变量
y = df_High_School[[&#39;time_to_event&#39;, &#39;event&#39;]] # 事件发生时间和事件指示器

#将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

#开发模型
model = xgb.XGBRegressor(objective=&#39;survival:cox&#39;)

它给了我以下错误：
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-9-1c5a15fa4b2b&gt;在&lt;模块&gt;中
     18
     19 # 将模型拟合到训练数据
---&gt; 20 model.fit(X_train, y_train)
     21
     22 # 对测试集进行预测

2帧
_maybe_pandas_label（标签）中的/usr/local/lib/python3.8/dist-packages/xgboost/core.py
    261 if isinstance(标签，数据帧)：
    262 if len(标签.列)&gt; 1：
--&gt; 263 raise ValueError（&#39;标签的数据帧不能有多列&#39;）
    264
    第265章

ValueError：标签的数据帧不能有多列

由于这是一个生存模型，我需要两列 t 来指示事件和 time_to_event。我还尝试将 Dataframes 转换为 Numpy 但它也不起作用。
有什么线索吗？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/75010397/xgboost-survival-model</guid>
      <pubDate>Wed, 04 Jan 2023 19:32:04 GMT</pubDate>
    </item>
    <item>
      <title>如何防止 Keras 在训练期间计算指标</title>
      <link>https://stackoverflow.com/questions/71412499/how-to-prevent-keras-from-computing-metrics-during-training</link>
      <description><![CDATA[我正在使用 Tensorflow/Keras 2.4.1，并且我有一个（无监督的）自定义指标，它将我的多个模型输入作为参数，例如：
model = build_model() # 返回一个 tf.keras.Model 对象
my_metric = custom_metric(model.output, model.input[0], model.input[1])
模型.add_metric(my_metric)
[...]
model.fit([...]) # 使用 fit 进行训练

但是，custom_metric 非常昂贵，因此我希望仅在验证期间计算它。我找到了这个答案，但我几乎不明白如何使解决方案适应我的指标，该指标使用多个模型输入作为参数，因为update_state 方法似乎不太灵活。
在我的上下文中，除了编写我自己的训练循环之外，是否有办法避免在训练期间计算我的指标？
另外，我很惊讶我们无法本机指定 Tensorflow 某些指标只能在验证时计算，这有什么原因吗？
此外，由于模型经过训练来优化损失，并且训练数据集不应用于评估模型，我什至不明白为什么默认情况下 Tensorflow 在训练期间计算指标。]]></description>
      <guid>https://stackoverflow.com/questions/71412499/how-to-prevent-keras-from-computing-metrics-during-training</guid>
      <pubDate>Wed, 09 Mar 2022 16:11:26 GMT</pubDate>
    </item>
    </channel>
</rss>