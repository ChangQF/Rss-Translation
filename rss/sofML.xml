<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 31 Mar 2024 01:03:16 GMT</lastBuildDate>
    <item>
      <title>如何将 flax.linen.Module 转换为 torch.nn.Module？</title>
      <link>https://stackoverflow.com/questions/78249695/how-can-i-convert-a-flax-linen-module-to-a-torch-nn-module</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78249695/how-can-i-convert-a-flax-linen-module-to-a-torch-nn-module</guid>
      <pubDate>Sat, 30 Mar 2024 22:24:42 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“顺序”对象没有属性“predict_classes”。您的意思是：“predict_step”吗？ [复制]</title>
      <link>https://stackoverflow.com/questions/78249508/attributeerror-sequential-object-has-no-attribute-predict-classes-did-you</link>
      <description><![CDATA[我在测试交通标志检测模型时遇到了上述错误。我只是学习模型火车的初学者。我在 YouTube 上观看了测试，你进展顺利，但视频可能是 4 年前的，这就是为什么我面临这个错误，我不知道该怎么办，如果有人可以回答我。谢谢
 # 处理图像
img = np.asarray(imgOrignal)
img = cv2.resize(img, (32, 32))
img = 预处理(img)
cv2.imshow(“处理后的图像”, img)
img = img.reshape(1, 32, 32, 1)
cv2.putText(imgOrignal, &quot;类别: &quot;, (20, 35), 字体, 0.75, (0, 0, 255), 2, cv2.LINE_AA)
cv2.putText(imgOrignal, &quot;概率: &quot;, (20, 75), 字体, 0.75, (0, 0, 255), 2, cv2.LINE_AA)
# 预测图像
预测 = model.predict(img)
classIndex = model.predict_classes(img)
概率值 =np.amax(预测)
cv2.putText(imgOrignal,str(classIndex)+&quot; &quot;+str(getCalssName(classIndex)), (120, 35), 字体, 0.75, (0, 0, 255), 2, cv2.LINE_AA)
cv2.putText(imgOrignal, str(round(probabilityValue*100,2) )+&quot;%&quot;, (180, 75), 字体, 0.75, (0, 0, 255), 2, cv2.LINE_AA)
cv2.imshow(“结果”, imgOrignal)

k=cv2.waitKey(1)
如果 k== ord(&#39;q&#39;):
    休息

cv2.destroyAllWindows()
cap.release()
]]></description>
      <guid>https://stackoverflow.com/questions/78249508/attributeerror-sequential-object-has-no-attribute-predict-classes-did-you</guid>
      <pubDate>Sat, 30 Mar 2024 21:11:05 GMT</pubDate>
    </item>
    <item>
      <title>ReLu、PreReLu、Leaky ReLU [关闭]</title>
      <link>https://stackoverflow.com/questions/78249016/relu-prerelu-leacky-relu</link>
      <description><![CDATA[Leacky ReLU 相对于 ReLU 的优势是什么？
我读过一些研究论文，但没有找到或更有价值的答案。
有时发现与 Leacky ReLU 相比，ReLU 和 Pre-ReLU 有助于更多的模型优化。为什么？]]></description>
      <guid>https://stackoverflow.com/questions/78249016/relu-prerelu-leacky-relu</guid>
      <pubDate>Sat, 30 Mar 2024 18:19:37 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机分类的增量学习[关闭]</title>
      <link>https://stackoverflow.com/questions/78248733/incremental-learning-for-support-vector-machines-classification</link>
      <description><![CDATA[我目前正在尝试为 Cawenbergs 和 Poggio 的增量和减量 SVM 算法找到一个好的实现。我找到了这个： Incremental-SVM-Learning-in- MATLAB，但我不太明白该算法在MatLab代码中是如何实现的。
我试图深入分析它并研究它，但仍然没有成功地理解它。我正在寻求一些帮助来理解代码，甚至寻求其他具有更清晰实现的解决方案。
非常欢迎任何帮助，你会给我一个很大的帮助！
这是我目前关注的算法：
Cawenbergs 和 Poggio 算法]]></description>
      <guid>https://stackoverflow.com/questions/78248733/incremental-learning-for-support-vector-machines-classification</guid>
      <pubDate>Sat, 30 Mar 2024 16:45:09 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 数据加载器中的 Snuffle</title>
      <link>https://stackoverflow.com/questions/78248552/snuffle-in-pytorch-dataloader</link>
      <description><![CDATA[我在 PyTorch 中有一个返回文本和图像的自定义数据集。我有一个关于数据加载器中的鼻烟的问题。他能不能把文字和对应的图片混合起来，也就是让图片和文字不匹配？
我不知道我能用它做什么]]></description>
      <guid>https://stackoverflow.com/questions/78248552/snuffle-in-pytorch-dataloader</guid>
      <pubDate>Sat, 30 Mar 2024 15:54:18 GMT</pubDate>
    </item>
    <item>
      <title>Pyarrow：导入错误：/lib/x86_64-linux-gnu/libc.so.6：找不到版本“GLIBC_2.28”</title>
      <link>https://stackoverflow.com/questions/78248485/pyarrow-importerror-lib-x86-64-linux-gnu-libc-so-6-version-glibc-2-28-not</link>
      <description><![CDATA[我正在尝试重现液体 s4 纸的结果，但遇到了无法导入 Pyarrow 的问题。整个错误消息为：import pyarrow as pa
回溯（最近一次调用最后一次）：
  文件“”，第 1 行，位于  中。
  文件“/home/nfs/state_space_model/.local/lib/python3.10/site-packages/pyarrow/__init__.py”，第 65 行，在  中
    将 pyarrow.lib 导入为 _lib
ImportError：/lib/x86_64-linux-gnu/libc.so.6：找不到版本“GLIBC_2.28”（/home/nfs/path/.local/lib/python3.10/site-packages/pyarrow/需要） libarrow.so.1500)

这似乎与我的linux系统有关。但我不知道从哪里开始。以下是我当前的环境设置和有关我的 GPU 的信息。
&lt;前&gt;&lt;代码&gt;absl-py==1.4.0
aiohttp==3.9.3
aiosignal==1.3.1
antlr4-python3-runtime==4.9.3
应用程序目录==1.4.4
异步超时==4.0.3
属性==23.2.0
证书==2024.2.2
字符集标准化器==3.3.2
切克斯==0.1.6
点击==8.1.7
cmake==3.29.0.1
轮廓py==1.2.0
循环仪==0.12.1
数据集==2.18.0
莳萝==0.3.8
dm-树==0.1.8
docker-pycreds==0.4.0
埃诺普斯==0.7.0
文件锁==3.13.1
字体工具==4.50.0
冻结列表==1.4.1
fsspec==2024.2.0
未来==1.0.0
gitdb==4.0.11
GitPython==3.1.42
googleapis-common-protos==1.63.0
grpcio==1.62.1
拥抱脸集线器==0.21.4
Hydra 核心==1.3.2
idna==3.6
Jinja2==3.1.3
joblib==1.3.2
keopscore==2.2.2
奇异解算器==1.4.5
闪电实用程序==0.11.2
降价==3.6
markdown-it-py==3.0.0
标记安全==2.1.5
matplotlib==3.8.3
mdurl==0.1.2
ml-dtypes==0.3.2
mpmath==1.3.0
消息包==1.0.8
多重字典==6.0.5
多进程==0.70.16
网络x==3.2.1
numpy==1.26.4
nvidia-cublas-cu12==12.1.3.1
nvidia-cuda-cupti-cu12==12.1.105
nvidia-cuda-nvrtc-cu12==12.1.105
nvidia-cuda-runtime-cu12==12.1.105
nvidia-cudnn-cu12==8.9.2.26
nvidia-cufft-cu12==11.0.2.54
nvidia-curand-cu12==10.3.2.106
nvidia-cusolver-cu12==11.4.5.107
nvidia-cusparse-cu12==12.1.0.106
nvidia-nccl-cu12==2.19.3
nvidia-nvjitlink-cu12==12.4.99
nvidia-nvtx-cu12==12.1.105
omegaconf==2.3.0
opt-einsum==3.3.0
光通量==0.1.7
包装==24.0
熊猫==2.2.1
枕头==10.2.0
承诺==2.3
协议缓冲区==3.20.3
psutil==5.9.8
pyarrow==15.0.2
pyarrow-修补程序==0.6
pybind11==2.12.0
pyDeprecate==0.3.1
pydub==0.25.1
皮格门斯==2.17.2
pykeops==2.2.2
pyparsing==3.1.2
python-dateutil==2.9.0.post0
pytorch-闪电==1.5.10
pytz==2024.1
PyYAML==6.0.1
正则表达式==2023.12.25
请求==2.31.0
丰富==13.7.1
安全张量==0.4.2
scikit-learn==1.4.1.post1
scipy==1.12.0
哨兵-sdk==1.44.0
setproctitle==1.3.3
六==1.16.0
smmap==5.0.1
sympy==1.12
张量板==2.16.2
张量板数据服务器==0.7.2
张量流数据集==4.5.2
张量流元数据==1.14.0
术语颜色==2.4.0
threadpoolctl==3.4.0
分词器==0.15.2
工具z==0.12.1
火炬==2.2.1
火炬音频==2.2.1
火炬数据==0.7.1
火炬测量==1.3.2
火炬文本==0.17.1
火炬视觉==0.17.1
tqdm==4.66.2
变形金刚==4.39.2
海卫一==2.2.0
打字扩展==4.10.0
tzdata==2024.1
urllib3==2.2.1
万宝==0.16.5
武器==3.0.1
xxhash==3.4.1
雅尔==1.9.4

我使用的是 RTX3060 GPU。
&lt;前&gt;&lt;代码&gt;+-------------------------------------------------------- ----------------------------------+
| NVIDIA-SMI 525.60.13 驱动程序版本：525.60.13 CUDA 版本：12.0 |
|------------------------------------------+----------------- ---+----------------------+
| GPU 名称持久性-M|总线 ID Disp.A |挥发性未校正。 ECC |
|风扇温度性能功率：使用/上限|内存使用情况 | GPU-Util 计算 M。
| | |米格·M。
|================================+================== ====+======================|
| 0 NVIDIA GeForce ... 开 | 00000000:01:00.0 关闭 |不适用 |
| 30% 33C P8 13W / 170W | 1MiB / 12288MiB | 0% 默认 |
| | |不适用 |
+--------------------------------------------+----------------- ---+----------------------+
                                                                               
+------------------------------------------------ ----------------------------+
|流程： |
| GPU GI CI PID 类型 进程名称 GPU 内存 |
| ID ID 用途 |
|=================================================== ============================|
|未找到正在运行的进程 |
+------------------------------------------------ ----------------------------+

有谁知道可能出现什么问题以及如何修复它们？任何帮助表示赞赏。如果您需要更多信息，请告诉我。]]></description>
      <guid>https://stackoverflow.com/questions/78248485/pyarrow-importerror-lib-x86-64-linux-gnu-libc-so-6-version-glibc-2-28-not</guid>
      <pubDate>Sat, 30 Mar 2024 15:30:54 GMT</pubDate>
    </item>
    <item>
      <title>建议将 Gymnasium 与神经网络结合使用，以避免 model.fit 和 model.predict 中的开销</title>
      <link>https://stackoverflow.com/questions/78248300/recommended-way-to-use-gymnasium-with-neural-networks-to-avoid-overheads-in-mode</link>
      <description><![CDATA[我正在尝试 Sutton &amp; 的情景半梯度 Sarsa。 Barto 第 10 章（第二版）使用 Gymnasium 的 CartPole 问题。对于函数逼近，我使用带有 keras 的神经网络。然而，忠实地实现该算法迫使我使用批量大小 1 进行拟合和预测，这会导致代码极其缓慢。另一种方法是首先运行代码从体育馆收集数据，然后使用这些数据离线训练神经网络。是否建议这样做 - 如果我理解正确的话，它会离线但仍然符合政策）？或者是否有其他标准方法可以在 Gymnasium 中使用神经网络而不影响性能？

我当前尝试的概述 -
将gymnasium导入为gym
从 numpy.random 导入选择作为 random_choice
从 numpy 导入数组，argmax

我将算法编写为以下 python 代码：
env =gym.make(&#39;CartPole-v1&#39;)

对于范围内的 ep_idx（num_episodes）：
    终止=假
    状态, _ = env.reset()
    动作 = env.action_space.sample()
    未终止时：
        action_=policy.take_action（状态，qvalue，ep_idx）
        状态_，奖励，终止，_，_ = env.step(action_)
        如果终止：
            qvalue.update(状态、动作、奖励、无、无)
        别的：
            qvalue.update(状态、动作、奖励、state_、action_)
        状态，动作 = 状态_，动作_

对于函数逼近，我决定使用 Keras。这是在 qvalue.update 内部实现的，如下所示：
类 QValueFunction：
    def __init__(自我、折扣、学习率、num_actions、*state_vector_dim):
        # 为简洁起见，此处未显示
    def __call__(自我，状态，动作=无)：
        # 为简洁起见，此处未显示
    def更新（自我，s，a，r，s_，a_）：
        model = self._model # keras.models.Model 的实例
        gamma = self._discount # 浮动
        update_targets = self._update_targets # 预分配的 numpy 数组
        q = 自身
        update_targets[:] = q(s, 无)
        self._s[:] = s
        s = self._s
        如果 s_ 为 None 并且 a_ 为 None：
            update_targets[0, a] = r
        别的：
            update_targets[0, a] = r + gamma * q(s_, a_)
        model.fit(s、update_targets、batch_size=1、verbose=0)

并且 policy 是 EpsilonGreedyPolicy 的实例：
类 EpsilonGreedyPolicy：
    def __init__(self, epsilon):
        self.eps = epsilon
    def take_action(self, 状态, qvalue, ep=None):
        num_actions = qvalue.num_actions
        如果可调用(self.eps): eps = self.eps(ep+1)
        否则： eps = self.eps
        如果 rand() &lt;每股收益：
            返回随机选择(num_actions)
        别的：
            qvalues = qvalue(状态)
            返回 argmax(qvalues)

上面的代码在我的笔记本电脑上以每 10 秒大约 1 集的速度运行（仅 CPU）。为了检查代码实际运行的速度，我尝试使用随机策略 (eps=1) 生成 1000 个剧集的数据，生成 20000 多个 (s, a, r, s_, a_) 元组 。这仅需要大约 10 秒。接下来，我使用这些数据分别训练神经网络，通过将所有数据一次传递到 model.predict 和 model.fit&lt;，每 10000 个数据点大约需要 1 秒Keras 的 /code&gt;。本质上，使用批量大小为 1 的 model.fit 和 model.predict 忠实地按照算法运行代码需要 10000 秒，而按 (i) 首先生成数据 (ii) 接下来训练神经网络的方式运行则需要 10 到 100 秒秒。
有没有推荐的方法在 Gymnasium 中使用神经网络来避免如此沉重的开销？]]></description>
      <guid>https://stackoverflow.com/questions/78248300/recommended-way-to-use-gymnasium-with-neural-networks-to-avoid-overheads-in-mode</guid>
      <pubDate>Sat, 30 Mar 2024 14:32:09 GMT</pubDate>
    </item>
    <item>
      <title>我如何在 coursera 上编辑“唤醒词检测笔记本”，使其适合我自己的单词？</title>
      <link>https://stackoverflow.com/questions/78248216/how-can-i-edit-the-wake-word-detection-notebook-on-coursera-so-it-fit-my-own-w</link>
      <description><![CDATA[我已经理解并解决了 Coursera 上 Andrew Ng 提供的深度学习专业化（序列模型课程）笔记本。
在笔记本中，他提供了构建唤醒词检测模型的详细演练。然而，最后，他加载了一个针对“激活”一词进行训练的预训练模型。
我尝试使用 Google Colab 和我自己的数据。我收集了 369 个人们说“Alexa”的声音。这些都可以在 Kaggle 上找到。然而，它们的采样率为 16000KHz。
我还使用 Google 语音命令作为负面声音，并从 YouTube 收集了一些包含各种环境声音的剪辑。
我完全按照说明执行了所有步骤，并且我正在使用 google colab 进行训练。但是当我尝试创建数据集时，RAM 很快就填满了，并且我无法创建 Andrew 在他的笔记本中提到的 4000 个样本。
这是我的“create_training_examples”代码：
&lt;前&gt;&lt;代码&gt;n 样本 = 4000
X_train = []
Y_train=[]
X_测试 = []
Y_测试 = []
火车计数 = 0
测试计数 = 0

测试=假
对于范围内的 i（0，nsamples）：

    如果我％500==0：
      打印（一）
    兰特 = random.randint(0,61)

    如果 i%5 == 0:


      x, y = create_data_example(backgrounds_list[rand], alexa_list, negatives_list, Ty, name=str(i),to_test = True)
      X_test.append(x.swapaxes(0,1))
      Y_test.append(y.swapaxes(0,1))
      测试计数+=1

    别的：

      x, y = create_data_example(backgrounds_list[rand], alexa_list, negatives_list, Ty, name=str(i),to_test = False)
      X_train.append(x.swapaxes(0,1))
      Y_train.append(y.swapaxes(0,1))
      火车计数+=1


print(&quot;训练样本数：&quot;, train_count)
print(&quot;测试样本数：&quot;, test_count)


X_train = np.array(X_train)
Y_train = np.array(Y_train)

np.save(&#39;XY_train/X_train.npy&#39;, X_train)
np.save(&#39;XY_train/Y_train.npy&#39;, Y_train)


X_test = np.array(X_test)
Y_test = np.array(Y_test)
np.save(&#39;XY_test/X_test.npy&#39;, X_test)
np.save(&#39;XY_test/Y_test.npy&#39;, Y_test)


print(&#39;保存完毕&#39;)

print(&#39;X_train.shape: &#39;,X_train.shape)
print(&#39;Y_train.shape: &#39;,Y_train.shape)



这是我使用的模型：
def 模型(input_shape):

    
    X_input = 输入（形状 = input_shape）
    

    X = Conv1D(196,15,步长=4)(X_输入)
    X = BatchNormalization()(X)
    X = 激活(&#39;relu&#39;)(X)
    X = 辍学(0.8)(X)

    
    X = GRU(128,return_sequences = True)(X)
    X = 辍学(0.8)(X)
    X = BatchNormalization()(X)
    
    
    X = GRU(128,return_sequences=True)(X)
    X = 辍学(0.8)(X)
    X = BatchNormalization()(X)
    X = 辍学(0.8)(X)
    
    X = TimeDistributed(Dense(1,activation = &quot;sigmoid&quot;))(X) # 时间分布 (sigmoid)


    模型 = 模型（输入 = X_输入，输出 = X）
    
    返回模型



以及训练：
opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, 衰减=0.01)
model.compile(loss=&#39;binary_crossentropy&#39;, 优化器=opt, 指标=[“准确度”])
model.fit（X_train，Y_train，batch_size = 5，epochs = 20，validation_data =（X_test，Y_test））



我按原样使用笔记本，甚至采用相同的方法进行特征提取。 我唯一修改的是训练数据，使用的是我自己的数据。但是，RAM 很快就被填满了。当我将样本数量减少到 1600KHz 或 8000KHz 时，我根本没有得到好的结果。
我还尝试编辑batch_size、learning_rate。
没有任何改变..
我做错了什么吗？
请问您有什么意见或建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78248216/how-can-i-edit-the-wake-word-detection-notebook-on-coursera-so-it-fit-my-own-w</guid>
      <pubDate>Sat, 30 Mar 2024 14:03:37 GMT</pubDate>
    </item>
    <item>
      <title>python中的批量梯度下降算法返回巨大的值</title>
      <link>https://stackoverflow.com/questions/78248203/batch-gradient-descent-algorithm-in-python-is-returning-huge-values</link>
      <description><![CDATA[我正在尝试在 python 中实现批量梯度下降算法，该算法将训练集、学习率和迭代次数作为输入参数，并返回权重。然而，当我运行它时，在几次迭代内，参数的值呈指数级增长，最终返回“nan”。
x = [[2104] [1600] [2400] [1416] [3000] [1985] [1534] [1427] [1380] [1494] [1940] [2000] [1890] [4478] [1268 ] [2300] [1320] [1236] [2609] [3031] [1767] [1888] [1604] [1962] [3890] [1100] [1458] [2526] [2200] [2637] [1839] [ 1000][2040][3137][1811][1437][1239][2132][4215][2162][1664][2238][2567][1200][852][1852][1203]]
y = [399900 329900 369000 232000 539900 299900 314900 198999 212000 242500 239999 347000 329999 699900 259900 449900 299900 199900 499998 599000 252900 255000 242900 259900 573900 249900 464500 469000 475000 299900 349900 169900 314900 579900 28590 0 249900 229900 345000 549000 287000 368500 329900 314000 299000 179900 299900 239500]
a = 0.01
num_iter = 100
def BGD ( x, y, a, num_iter):
    m = len(x) #样本数
    n = x.shape[1] #特征数量
    p = np.zeros(n)
    b = 0
    对于 _ 在范围内（num_iter）：
        sum_p = np.zeros(n)
        总和 = 0
        对于范围 (m) 内的 i：
            sum_p = sum_p + ((np.dot(p,x[i])+b) - y[i]) * x[i]
            sum_b = sum_b + (((np.dot(p,x[i])+b) - y[i]))
        p = p - (a * (1/m) * sum_p)
        b = b - (a * (1/m) * sum_b)
    返回 p、b

p, b = BGD(x, y, 0.01, 100)
打印（页）
打印(b)

我得到以下信息：
RuntimeWarning：add 中遇到溢出
sum_p = sum_p + ((np.dot(p,x[i])+b) - y[i]) * x[i]
RuntimeWarning：减法中遇到无效值
p = p - (a * (1/m) * sum_p)
[楠]
楠]]></description>
      <guid>https://stackoverflow.com/questions/78248203/batch-gradient-descent-algorithm-in-python-is-returning-huge-values</guid>
      <pubDate>Sat, 30 Mar 2024 14:00:37 GMT</pubDate>
    </item>
    <item>
      <title>计算explained_variance_score，手动方法和函数调用结果不同</title>
      <link>https://stackoverflow.com/questions/78246746/calculating-explained-variance-score-result-are-different-between-manual-method</link>
      <description><![CDATA[根据官方页面的公式
https://scikit-learn.org/stable/modules/ model_evaluation.html#explained-variance-score，以便计算数据集的以下 EVS：
y_true = [1, 2, 3, 4, 5] y_pred = [6, 7, 8, 9, 10]

手动：evs = 1 - var(y_true - y_pred)/var(y_true) = -11.5
使用代码：evs = 1
从 sklearn.metrics 导入解释_方差_分数

y_true = [1, 2, 3, 4, 5]
y_pred = [6, 7, 8, 9, 10]

解释的方差 = 解释的方差_分数(y_true, y_pred)

为什么结果不同？]]></description>
      <guid>https://stackoverflow.com/questions/78246746/calculating-explained-variance-score-result-are-different-between-manual-method</guid>
      <pubDate>Sat, 30 Mar 2024 03:26:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用时间戳对整数和整数数组进行加/减</title>
      <link>https://stackoverflow.com/questions/78245499/how-can-i-add-substract-integers-and-integer-arrays-with-timestamp</link>
      <description><![CDATA[#first block：计算上次购买日期
从日期时间导入时间增量
最后购买日期 = (sales_data[&#39;TRANSAC_DATE&#39;].max()) + timedelta(天=1)


print(&quot;上次购买日期：&quot;, sales_data[&#39;TRANSAC_DATE&#39;].max())
print(“最近/上次购买日期：”, last_purchase_date)



#第二块：在 RFM 分析中计算上次购买的新近度
RFM = sales_data.groupby([&#39;CLIENT_ID&#39;]).agg({
    &#39;CLIENT_ID&#39;: lambda x: (last_purchase_date - x.max()).days,
    &#39;Transaction_ID&#39;: &#39;计数&#39;,
    &#39;网络&#39;：&#39;总和&#39;
})

#错误行：lambda x: (last_purchase_date - x.max()).days

RFM.rename(columns={&#39;CLIENT_ID&#39;: &#39;Recency&#39;, &#39;Transaction_ID&#39;: &#39;Frequency&#39;, &#39;NET&#39;: &#39;MonetaryValue&#39;}, inplace= True)
显示(RFM)

问题：我想要以天为单位的新近度，但我无法从last_purchase_date（时间戳）中减去整数数组中的输出 x.max()
#错误行： lambda x: (last_purchase_date - x.max()).days
#Error msg: 不再支持带有时间戳的整数和整数数组的加法/减法。使用 n * obj.freq 代替加/减 n]]></description>
      <guid>https://stackoverflow.com/questions/78245499/how-can-i-add-substract-integers-and-integer-arrays-with-timestamp</guid>
      <pubDate>Fri, 29 Mar 2024 19:08:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 中模拟 Microsoft Excel 的求解器功能（GRG 非线性）？</title>
      <link>https://stackoverflow.com/questions/78244486/how-can-i-emulate-microsoft-excels-solver-functionality-grg-nonlinear-in-pyth</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78244486/how-can-i-emulate-microsoft-excels-solver-functionality-grg-nonlinear-in-pyth</guid>
      <pubDate>Fri, 29 Mar 2024 15:08:18 GMT</pubDate>
    </item>
    <item>
      <title>解决从 Jupyter Notebook 到 .py 文件的自定义管道类转换中的 OneHotEncoder 问题</title>
      <link>https://stackoverflow.com/questions/78219825/troubleshooting-onehotencoder-issue-in-custom-pipeline-class-conversion-from-jup</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78219825/troubleshooting-onehotencoder-issue-in-custom-pipeline-class-conversion-from-jup</guid>
      <pubDate>Mon, 25 Mar 2024 14:32:03 GMT</pubDate>
    </item>
    <item>
      <title>无法从“jax”导入名称“linear_util”</title>
      <link>https://stackoverflow.com/questions/78210393/cannot-import-name-linear-util-from-jax</link>
      <description><![CDATA[我正在尝试重现S5模型的实验，https://github.com/lindermanlab/ S5，但是在解决环境的时候遇到了一些问题。当我运行 shell 脚本./run_lra_cifar.sh时，出现以下错误
回溯（最近一次调用最后一次）：
  文件“/Path/S5/run_train.py”，第3行，在&lt;module&gt;中。
    从 s5.train 导入火车
  文件“/Path/S5/s5/train.py”，第7行，在&lt;module&gt;中。
    从.train_helpers导入create_train_state，reduce_lr_on_plateau，\
  文件“/Path/train_helpers.py”，第 6 行，在  中。
    从 flax.training 导入 train_state
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/__init__.py”，第 19 行，在  中
    从 。导入核心
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/core/__init__.py”，第 15 行，在  中
    从 .axes_scan 导入广播
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/core/axes_scan.py”，第 22 行，在  中
    从 jax 导入 Linear_util 作为 lu
ImportError：无法从“jax”导入名称“linear_util”（/Path/miniconda3/lib/python3.12/site-packages/jax/__init__.py）

我在 RTX4090 上运行它，我的 CUDA 版本是 11.8。我的jax版本是0.4.25，jaxlib版本是0.4.25+cuda11.cudnn86
我首先尝试使用作者的安装依赖项
pip install -rrequirements_gpu.txt

但是，这似乎不适用于我的情况，因为我什至无法导入 jax。所以我根据 https://jax.readthedocs.io/en 上的说明安装了 jax /latest/installation.html
通过输入
pip install --upgrade pip
pip install --upgrade “jax[cuda11_pip]” -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

到目前为止我已经尝试过：

使用较旧的 GPU（3060 和 2070）
将 python 降级到 3.9

有谁知道可能出了什么问题吗？感谢任何帮助]]></description>
      <guid>https://stackoverflow.com/questions/78210393/cannot-import-name-linear-util-from-jax</guid>
      <pubDate>Sat, 23 Mar 2024 09:57:12 GMT</pubDate>
    </item>
    <item>
      <title>机器学习：结合二进制编码器和 RobustScaler</title>
      <link>https://stackoverflow.com/questions/74480076/machine-learning-combining-binary-encoder-and-robustscaler</link>
      <description><![CDATA[我有一个包含数值和分类数据的数据集。数据包括大纲，这对于以后的解释至关重要。我对分类数据进行了二进制编码，并对数值数据使用了 RobustScaler。
分类二进制编码数据不会缩放。这种组合可能还是存在逻辑错误？]]></description>
      <guid>https://stackoverflow.com/questions/74480076/machine-learning-combining-binary-encoder-and-robustscaler</guid>
      <pubDate>Thu, 17 Nov 2022 18:01:29 GMT</pubDate>
    </item>
    </channel>
</rss>