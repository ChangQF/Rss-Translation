<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 12 Apr 2024 03:15:31 GMT</lastBuildDate>
    <item>
      <title>交叉验证可视化功能</title>
      <link>https://stackoverflow.com/questions/78313982/cross-validation-visualization-mulfunctions</link>
      <description><![CDATA[我受到 scikit-learn 的 交叉验证可视化指南，用于可视化每个 CV 分割中训练和测试索引的分布：
cmap_data = plt.cm.Paired
cmap_cv = plt.cm.coolwarm
defplot_cv_indices（cv，X，y，组，ax，n_splits，lw = 10）：
    “”“”为交叉验证对象的索引创建样本图。“”“”

    # 为每个 CV 分割生成训练/测试可视化
    对于 ii，枚举（cv.split（X = X，y = y，groups = group））中的（tr，tt）：
        # 用训练/测试组填写索引
        索引 = np.array([np.nan] * len(X))
        索引[tt] = 1
        索引[tr] = 0

        # 可视化结果
        斧头.分散（
            范围（len（索引）），
            [ii + 0.5] * len(索引),
            c=指数，
            标记=“_”，
            lw=lw,
            cmap=cmap_cv,
            vmin=-0.2,
            vmax=1.2，
        ）

    # 最后绘制数据类和组
    斧头.分散（
        范围(len(X)), [ii + 1.5] * len(X), c=y, 标记=“_”, lw=lw, cmap=cmap_data
    ）

    斧头.分散（
        范围(len(X)), [ii + 2.5] * len(X), c=组, 标记=“_”, lw=lw, cmap=cmap_data
    ）

    # 格式化
    yticklabels = list(range(n_splits)) + [“类”, “组”]
    斧头.设置（
        yticks=np.arange(n_splits + 2) + 0.5,
        yticklabels=yticklabels,
        xlabel=&quot;样本索引&quot;,
        ylabel=“CV迭代”，
        ylim=[n_splits + 2.2, -0.2],
        xlim=[0, 100],
    ）
    ax.set_title(“{}”.format(type(cv).__name__), fontsize=15)
    plt.show()

from sklearn.datasets import make_classification
从 sklearn.model_selection 导入 TimeSeriesSplit、KFold

图, ax = plt.subplots(figsize=(12, 5))
X, y = make_classification(
    n_样本=1000，
    n_特征=10，
    n_信息=3，
    n_冗余=0，
    n_重复=0，
    n_classes=2,
    随机状态=42，
    随机播放=假，
）
绘图CV索引（
    TimeSeriesSplit(n_splits=5, 间隙=10),
    X=X,
    y=y,
    组=无，
    斧头=斧头，
    n_splits=5,
）

上面的代码给了我：

我在寻找：

预期图的想法是，该图成功地可视化了每个分组中训练集和测试集之间的差距。此外，我在正常的 KFold 上运行了一个测试用例，而且 plot_cv_indices 函数似乎也无法正常运行。]]></description>
      <guid>https://stackoverflow.com/questions/78313982/cross-validation-visualization-mulfunctions</guid>
      <pubDate>Fri, 12 Apr 2024 03:12:54 GMT</pubDate>
    </item>
    <item>
      <title>手语项目（Ai）</title>
      <link>https://stackoverflow.com/questions/78313876/sign-language-project-ai</link>
      <description><![CDATA[目前，我们是一个团队在做毕业设计，做一个手语应用，当我们完成2个模型的训练和评估后，我们想把这2个模型放在main函数中，以便交给后端团队将模型链接到应用程序。这里的问题是
我们如何制作主函数以及完成它需要哪些步骤和库主函数？]]></description>
      <guid>https://stackoverflow.com/questions/78313876/sign-language-project-ai</guid>
      <pubDate>Fri, 12 Apr 2024 02:31:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么SAC算法在计算q函数的损失时只采样一个“下一步动作”？</title>
      <link>https://stackoverflow.com/questions/78313821/why-sac-algorithm-only-sample-one-next-action-when-computing-the-loss-of-q-fun</link>
      <description><![CDATA[在SAC的原论文中，Q-value的损失函数写为：

在实际算法实现中，将V(s_{t+1})项替换为Q(s_{t+1}, a{t+1})，损失函数写为：
next_q1 = self.networks.q1_target(obs2, next_act)
next_q2 = self.networks.q2_target(obs2, next_act)
next_q = torch.min(next_q1, next_q2)
备份 = rew + (1 - 完成) * self.gamma * (next_q - self.__get_alpha() * next_logp)

我知道这两个公式在期望上是相等的，但第二个公式显然具有更高的方差，因为它只需要 a_{t+1} 的一个样本。考虑到 SAC 的策略是随机的，我想知道在这种情况下对多个操作（或 Q_next）进行采样是否会更好？
虽然会花费更多的时间，但可以显着降低Q的梯度方差。
有关于这个问题的研究或论文吗？最好能结合实验结果进行理论解释。]]></description>
      <guid>https://stackoverflow.com/questions/78313821/why-sac-algorithm-only-sample-one-next-action-when-computing-the-loss-of-q-fun</guid>
      <pubDate>Fri, 12 Apr 2024 02:10:58 GMT</pubDate>
    </item>
    <item>
      <title>训练时间融合网络 - 多少数据？</title>
      <link>https://stackoverflow.com/questions/78313682/training-temporal-fusion-network-how-much-data</link>
      <description><![CDATA[关于多少数据足以训练时间融合变压器，是否有任何经验法则？更具体地说，我有大约 20 个特征，数据集大约有 50 万。这足够吗？对于多大的模型来说？
或者，我有大约 20 个产品，每个产品大约有 500k 行，而不是为每个“产品”训练不同的模型。也许我应该为所有产品训练一个模型以获得一个模型，然后定制它？
我知道这是非常高水平和模糊的，我只是在寻找一些经验法则和指导 - 我是否处于正确的范围，或者我应该去哪里。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78313682/training-temporal-fusion-network-how-much-data</guid>
      <pubDate>Fri, 12 Apr 2024 01:13:06 GMT</pubDate>
    </item>
    <item>
      <title>意外的关键字参数“metaclass”--在 conda 中导入 keras 时出现问题</title>
      <link>https://stackoverflow.com/questions/78312976/unexpected-keyword-argument-metaclass-problems-when-importing-keras-in-conda</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78312976/unexpected-keyword-argument-metaclass-problems-when-importing-keras-in-conda</guid>
      <pubDate>Thu, 11 Apr 2024 20:51:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyOD 中的 Decision_function 进行异常评分计算</title>
      <link>https://stackoverflow.com/questions/78312583/anomaly-scores-computation-using-decision-function-in-pyod</link>
      <description><![CDATA[我发现一篇文章警告 sklearn 用户 OCSVM 中的 Decision_function 输出的异常分数：
https://activisiongamescience.github.io/2015/12/23/Unsupervised-Anomaly-Detection-SOD-vs-One-class-SVM/#sklearn-Users-Beware
但是，我正在使用 PyOD 进行无监督异常值检测，并想知道 Decision_function 的输出是否需要相同的转换。是否有任何参考资料指定如何为 PyOD 中的各种算法计算 Decision_function 值？ （我专门寻找 KNN、OCSVM、CBLOF 和 IForest）。]]></description>
      <guid>https://stackoverflow.com/questions/78312583/anomaly-scores-computation-using-decision-function-in-pyod</guid>
      <pubDate>Thu, 11 Apr 2024 19:08:37 GMT</pubDate>
    </item>
    <item>
      <title>在运行 ML 项目时如何使用存储在 google Drive 中的数据集？</title>
      <link>https://stackoverflow.com/questions/78312337/how-can-i-use-the-dataset-that-is-stored-in-google-drive-while-running-ml-projec</link>
      <description><![CDATA[我正在运行 SoccerNet 项目，该项目为足球视频生成字幕。
我正在尝试将路径传递到存储数据集的Google Drive，即**https://drive.google.com/drive/folders/{folder_id} **
我正在运行的命令如下。
python main.py --SoccerNet_path=“https://drive.google.com/drive/folders/{folder_id}” --model_name=new_model --features=baidu_soccer_embeddings.npy --framerate=1 --pool=NetVLAD --window_size_caption=45 --window_size_spotting=15 --NMS_window=30 --num_layers=4 --first_stage=caption --pretrain --GPU=0


我收到操作系统错误：如下
OSError: [Errno 22] 无效参数: &#39;https:https://drive.google.com/drive/folders/{folder_id}?usp=drive_link\\england_epl\\2014-2015\\2015 -02-21 - 18-00 切尔西 1 - 1 伯恩利\\1_baidu_soccer_embeddings.npy&#39;

我尝试使用 google colab，但我没有得到 colab 中预期的输出，因为它没有生成应包含预期字幕的 json 文件。
我现在使用 VS code。]]></description>
      <guid>https://stackoverflow.com/questions/78312337/how-can-i-use-the-dataset-that-is-stored-in-google-drive-while-running-ml-projec</guid>
      <pubDate>Thu, 11 Apr 2024 18:15:53 GMT</pubDate>
    </item>
    <item>
      <title>我在重塑图像数据集时遇到错误</title>
      <link>https://stackoverflow.com/questions/78312092/i-am-facing-error-in-reshaping-our-image-dataset</link>
      <description><![CDATA[我遇到此错误文件“C:\Users\Kanishka Patel\anaconda3\Lib\site-packages\keras\src\ saving\serialization_lib.py”，第 600 行，在 deserialize_keras_object return deserialize_keras_object( ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^ 文件“C:\Users\Kanishka Patel\anaconda3\Lib\site-packages\ker
我尝试将 217560 重塑为 [224,224,3]]]></description>
      <guid>https://stackoverflow.com/questions/78312092/i-am-facing-error-in-reshaping-our-image-dataset</guid>
      <pubDate>Thu, 11 Apr 2024 17:27:34 GMT</pubDate>
    </item>
    <item>
      <title>如何让 Matrox Model Finder 在单个图像中多次查找同一模型？</title>
      <link>https://stackoverflow.com/questions/78311681/how-do-i-make-the-matrox-model-finder-look-for-the-same-model-multiple-times-in</link>
      <description><![CDATA[我是 Matrox 新手，所以这可能是一个非常初学者的问题。
我有一个托盘，里面有多个相同型号的物品。当我将 ModelFinder 步骤添加到程序中时，我添加了我正在寻找的模型，但它只显示了我注册的模型，我猜测是因为相机的扭曲。我如何让 Matrox 知道还有更多项目并且它们也是同一型号？

我添加了一个必须找到它的搜索区域，并且我选择了它的选项来查找所有出现的情况，但它只显示了一个而不是实际存在的 3/4。
]]></description>
      <guid>https://stackoverflow.com/questions/78311681/how-do-i-make-the-matrox-model-finder-look-for-the-same-model-multiple-times-in</guid>
      <pubDate>Thu, 11 Apr 2024 16:02:48 GMT</pubDate>
    </item>
    <item>
      <title>用最少层数训练绝对函数的神经网络</title>
      <link>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</link>
      <description><![CDATA[我正在尝试训练神经网络来学习 y = |x|功能。我们知道，绝对函数有两条不同的线在零点处相互连接。所以我尝试使用以下顺序模型：
隐藏层：
2 致密层（激活relu）
输出层：
1 致密层
训练模型后，它只拟合函数的一半边。大多数时候是右手边，有时是左手边。一旦我在隐藏层中再添加 1 层，那么我就用 3 层代替 2 层，它就完全符合该功能了。谁能解释为什么当绝对函数只有一次切割时需要额外的一层？
这是代码：
将 numpy 导入为 np


X = np.linspace(-1000,1000,400)
np.random.shuffle(X)
Y = np.abs(X)

# 重塑数据以适应模型输入
X = X.reshape(-1, 1)
Y = Y.重塑(-1, 1)

将张量流导入为 tf
将张量流导入为 tf
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

# 构建模型
模型 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(2, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(1)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;])
model.fit(X, Y, epochs=1000)
# 使用模型进行预测
Y_pred = model.predict(X)

# 绘制结果
plt.scatter(X, Y, color=&#39;blue&#39;, label=&#39;实际&#39;)
plt.scatter(X, Y_pred, color=&#39;red&#39;, label=&#39;预测&#39;)
plt.title(&#39;实际与预测&#39;)
plt.xlabel(&#39;X&#39;)
plt.ylabel(&#39;Y&#39;)
plt.图例()
plt.show()

2 个密集层的绘图：

3 个密集层的绘图：
]]></description>
      <guid>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</guid>
      <pubDate>Thu, 11 Apr 2024 15:34:01 GMT</pubDate>
    </item>
    <item>
      <title>如何对机器学习项目进行建模？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78311330/how-to-model-a-machine-learning-project</link>
      <description><![CDATA[我有 200 个不同的传感器，有 3 种测量原理。这些可以概括如下：

&lt;标题&gt;

传感器类型
测量类型 1
测量类型 2
测量类型 3


&lt;正文&gt;

类型 1
1.1
2.1
3.1


类型 2
1.2
2.2
3.2


...
...
...
...



输出要求：整体传感器状态（好/绿，坏/红，好/黄）
应该如何开始这样一个机器学习项目。
需要考虑的一些注意事项：

没有基本事实
每种测量类型都有阈值

每种传感器类型对于每种测量类型都有不同的阈值
所有测量结果都是时间序列表格数据

感谢任何帮助:)]]></description>
      <guid>https://stackoverflow.com/questions/78311330/how-to-model-a-machine-learning-project</guid>
      <pubDate>Thu, 11 Apr 2024 15:04:54 GMT</pubDate>
    </item>
    <item>
      <title>PyCaret Predict_model 数据集兼容性</title>
      <link>https://stackoverflow.com/questions/78308672/pycaret-predict-model-dataset-compatibility</link>
      <description><![CDATA[我正在尝试使用 pycaret 使用看不见的数据来预测分数。我确信我看不见的数据框具有模型中包含的所有功能，但我仍然收到此错误：
CatBoostError：catboost/libs/data/model_dataset_compatibility.cpp:81：位置 1 应该是名为 CUSTOMER_MOB 的功能（找到 PAYROLL_MOB）

数据框列的屏幕截图
上面的屏幕截图显示了我看不见的数据框中的列，如您所见，CUSTOMER_MOB 列位于 PAYROLL_MOB 旁边。
当我使用 model.features_names_in_ 检查时，我发现这两个特征都在模型中，所以我不知道问题是什么。
我尝试交换两列的位置，但没有成功。我也尝试删除任一列，但随后遇到了不同的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78308672/pycaret-predict-model-dataset-compatibility</guid>
      <pubDate>Thu, 11 Apr 2024 07:07:14 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec Hierarchical Softmax 中的内部顶点是什么？</title>
      <link>https://stackoverflow.com/questions/78285447/whats-inside-inner-vertices-in-word2vec-hierarchical-softmax</link>
      <description><![CDATA[我有一个关于分层 Softmax 的问题。实际上，我不太明白内部顶点（不是叶顶点）中存储的内容。我清楚地理解这个算法的主要思想，但是每一步我们都计算输入词嵌入与内部顶点的词嵌入的点积。那么这些内部顶点内部有哪些向量呢？是否是大小等于 embedding_size 的随机初始化向量，然后它们的坐标由于反向传播步骤而变化，直到我们停止？]]></description>
      <guid>https://stackoverflow.com/questions/78285447/whats-inside-inner-vertices-in-word2vec-hierarchical-softmax</guid>
      <pubDate>Sat, 06 Apr 2024 18:15:41 GMT</pubDate>
    </item>
    <item>
      <title>python中的批量梯度下降算法返回巨大的值</title>
      <link>https://stackoverflow.com/questions/78248203/batch-gradient-descent-algorithm-in-python-is-returning-huge-values</link>
      <description><![CDATA[我正在尝试在 python 中实现批量梯度下降算法，该算法将训练集、学习率和迭代次数作为输入参数，并返回权重。然而，当我运行它时，在几次迭代内，参数的值呈指数级增长，最终返回“nan”。
将 numpy 导入为 np

x = np.array([[2104], [1600], [2400], [1416], [3000], [1985], [1534], [1427], [1380], [1494], [1940] , [2000], [1890], [4478], [1268], [2300], [1320], [1236], [2609], [3031], [1767], [1888], [1604], [ 1962]、[3890]、[1100]、[1458]、[2526]、[2200]、[2637]、[1839]、[1000]、[2040]、[3137]、[1811]、[1437] 、[1239]、[2132]、[4215]、[2162]、[1664]、[2238]、[2567]、[1200]、[852]、[1852]、[1203]]）

y = np.array([399900, 329900, 369000, 232000, 539900, 299900, 314900, 198999, 212000, 242500, 239999, 347000, 329999, 699900, 259 900、449900、299900、199900、499998、599000、252900、255000 , 242900, 259900, 573900, 249900, 464500, 469000, 475000, 299900, 349900, 169900, 314900, 579900, 285900, 249900, 229900, 3 45000、549000、287000、368500、329900、314000、299000、179900、299900、239500 ]）

a = 0.01

迭代次数 = 100

def BGD ( x, y, a, num_iter):
    m = len(x) #样本数
    n = x.shape[1] #特征数量
    p = np.zeros(n)
    b = 0
    对于 _ 在范围内（num_iter）：
        sum_p = np.zeros(n)
        总和 = 0
        对于范围 (m) 内的 i：
            sum_p = sum_p + ((np.dot(p,x[i])+b) - y[i]) * x[i]
            sum_b = sum_b + (((np.dot(p,x[i])+b) - y[i]))
        p = p - (a * (1/m) * sum_p)
        b = b - (a * (1/m) * sum_b)
    返回 p、b

p, b = BGD(x, y, 0.01, 100)
打印（页）
打印(b)

我得到以下信息：
RuntimeWarning: add 中遇到溢出
  sum_p = sum_p + ((np.dot(p,x[i])+b) - y[i]) * x[i]
RuntimeWarning：减法中遇到无效值
  p = p - (a * (1/m) * sum_p)
[南]
南
]]></description>
      <guid>https://stackoverflow.com/questions/78248203/batch-gradient-descent-algorithm-in-python-is-returning-huge-values</guid>
      <pubDate>Sat, 30 Mar 2024 14:00:37 GMT</pubDate>
    </item>
    <item>
      <title>在变压器中加载安全张量文件</title>
      <link>https://stackoverflow.com/questions/76247802/loading-a-safetensor-file-in-transformers</link>
      <description><![CDATA[我已经从 Huggingface 下载了这个模型。我正在尝试在变压器中加载这个模型，以便我可以进行推理：
从变压器导入 AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(“path_to/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g”)

模型 = AutoModelForCausalLM.from_pretrained(“path_to/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g”)

但我收到错误消息，说它需要 .bin 或 .h5 或 .ckpt 文件，但上面只有 .safetensors 或 .pt 文件
如何加载模型？]]></description>
      <guid>https://stackoverflow.com/questions/76247802/loading-a-safetensor-file-in-transformers</guid>
      <pubDate>Sun, 14 May 2023 13:46:18 GMT</pubDate>
    </item>
    </channel>
</rss>