<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 12:26:04 GMT</lastBuildDate>
    <item>
      <title>TypeError：只有整数标量数组才能用 numpy/shap 转换为标量索引</title>
      <link>https://stackoverflow.com/questions/78716908/typeerror-only-integer-scalar-arrays-can-be-converted-to-a-scalar-index-with-nu</link>
      <description><![CDATA[我正在写这段代码：
# 部分依赖图
fig, ax = plt.subplots(figsize=(12, 8))
features_to_plot = list(range(min(3, len(feature_names)))) # 绘制最多 3 个特征
PartialDependenceDisplay.from_estimator(best_rf_model, X_test_scaled, features=features_to_plot,
feature_names=feature_names, ax=ax)
plt.show()

# SHAP 值
explainer = shap.TreeExplainer(best_rf_model)
shap_values = explainer.shap_values(X_test_scaled)

# 处理不同的 SHAP 值形状
if isinstance(shap_values, list):
# 对于多类问题
print(&quot;多类 SHAP 值检测到&quot;)
for i, class_shap_values in enumerate(shap_values):
plt.figure(figsize=(12, 8))
shap.summary_plot(class_shap_values, X_test_scaled, plot_type=&quot;bar&quot;, feature_names=feature_names, show=False)
plt.title(f&quot;SHAP Feature Importance for Class {i}&quot;)

我一直收到我在标题中描述的错误。
我发现这真的很奇怪，因为我已经确保它是 1d 并且所有元素都是整数，所以我应该怎么做才能解决这个问题？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78716908/typeerror-only-integer-scalar-arrays-can-be-converted-to-a-scalar-index-with-nu</guid>
      <pubDate>Sun, 07 Jul 2024 09:26:47 GMT</pubDate>
    </item>
    <item>
      <title>eval（predvars、data、env）中出现错误：未找到对象“s_id”</title>
      <link>https://stackoverflow.com/questions/78715689/error-in-evalpredvars-data-env-object-s-id-not-found</link>
      <description><![CDATA[我正在尝试使用 tidymodels 拟合多层模型。当我拟合单个模型时，我没有遇到问题，但当我将它们组合到工作流集中时，我得到了这些错误。
我看到过有类似错误的帖子，并尝试更新我的代码，但似乎仍然不起作用。
当我在应用配方后查看训练和验证集时，我确实在数据框中找到所有列。不确定错误持续存在的原因。
我希望有人能帮助解决此错误：
pacman::p_load(labelled,forcats,rstanarm,tidymodels,dplyr,parsnip,baguette,future,finetune,rules,rsample,
multilevelmod,ranger,earth,readr,stacks)

plan(multisession)

load(url(&quot;http://alecri.github.io/downloads/data/dental.RData&quot;))

dental_long &lt;- pivot_longer(dental, cols = starts_with(&quot;y&quot;), 
names_to = &quot;measurement&quot;, values_to = &quot;distance&quot;) %&gt;% 
mutate(
age = parse_number(measurement),
measure = fct_inorder(paste(&quot;测量年龄&quot;, age)),
s_id=as.factor(id)
) %&gt;% 
set_variable_labels(
age = &quot;测量时孩子的年龄&quot;,
measure = &quot;时间测量标签&quot;,
distance = &quot;测量值&quot;
) %&gt;% select(-measurement,-id)

#将数据拆分为训练集、验证集和测试集
set.seed(11)
splitsx &lt;- group_initial_split(dental_long, group = s_id,prop = 0.8)

dental_train &lt;- training(splitsx)
dental_val &lt;- testing(splitsx)

#创建交叉验证折叠
foldsx &lt;- group_vfold_cv(dental_train, v = 3,group = s_id,repeats = 3)

#创建简单的建模配方
simple_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
update_role(s_id,new_role = &#39;id&#39;)

#带有多项式项的配方
poly_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
update_role(s_id,new_role = &#39;id&#39;) %&gt;%
step_scale(all_numeric_predictors()) %&gt;%
step_poly(all_numeric_predictors(),degree = 2,keep_original_cols = F) %&gt;%
step_dummy(all_nominal_predictors()) %&gt;% 
step_interact(~all_numeric_predictors():all_numeric_predictors())

mixed_basic_recipex &lt;- recipe(distance ~ ., data = dental_train)

mixed_poly_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
step_scale(all_numeric_predictors()) %&gt;%
step_poly(all_numeric_predictors(),degree = 2,keep_original_cols = F) %&gt;%
step_dummy(all_nominal_predictors() &amp; !matches(&#39;s_id&#39;)) #%&gt;% 
# step_interact(~all_numeric_predictors():all_numeric_predictors() )

# df1 &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

#mixed model
lmer_specx &lt;-
linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;lmer&quot;)

bayes_specx &lt;- linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;stan_glmer&quot;)

fullx &lt;- 
workflow_set(
preproc = list(mixed_poly = poly_recipex
), 
models = list(bayesMixed = bayes_specx,lmmixed = lmer_specx

)
)

#贝叶斯调整和度量的设置
bayes_ctrl &lt;-
control_bayes(
save_pred = TRUE,
parallel_over = &quot;everything&quot;,
save_workflow = TRUE,
verbose = TRUE,
no_improve = 20
)
rmse_res &lt;- metric_set(rmse,rsq)

basicbkx &lt;- prep(mixed_basic_recipex) %&gt;% bake(dental_train)
polybkx &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

polyform &lt;- reformulate(c(setdiff(colnames(polybkx), c(&quot;距离&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)
basicform &lt;- reformulate(c(setdiff(colnames(basicbkx), c(&quot;distance&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)

all_wfx1 &lt;- fullx %&gt;% 
# update_workflow_model(id=&#39;basic_bayesMixed&#39;,spec=bayes_specx,
# formula = basicform) %&gt;% 
update_workflow_model(id=&#39;mixed_poly_bayesMixed&#39;,spec=bayes_specx,
formula = polyform) %&gt;%
# update_workflow_model(id=&#39;basic_lmmixed&#39;,spec=lmer_specx,
# formula = basicform) %&gt;%
update_workflow_model(id=&#39;mixed_poly_lmmixed&#39;,spec=lmer_specx,
formula = polyform)

test_results &lt;-
all_wfx1 %&gt;%
working_map(
&quot;tune_bayes&quot;,
seed = 10,
resamples = foldsx,
control = bayes_ctrl
)
]]></description>
      <guid>https://stackoverflow.com/questions/78715689/error-in-evalpredvars-data-env-object-s-id-not-found</guid>
      <pubDate>Sat, 06 Jul 2024 19:11:58 GMT</pubDate>
    </item>
    <item>
      <title>从 UE5 中的动作分类器模型获取输入</title>
      <link>https://stackoverflow.com/questions/78714836/taking-input-from-an-action-classifier-model-in-ue5</link>
      <description><![CDATA[我已经训练了一个动作分类器模型，该模型可以实时使用网络摄像头对玩家的动作进行分类。
它使用媒体管道检测人的姿势，并向模型提供 x、y、深度和可见性参数。该模型对人正在执行的动作进行分类。现在我想将此模型的结果输入为游戏中的按钮按下事件。此输入将用于控制我的游戏角色。例如：如果模型检测到拳击动作，则游戏角色将出拳。
解决此问题的最佳方法是什么，以便我在模型决策和游戏动作之间获得尽可能低的延迟？
我研究了虚幻引擎 5 的 NNI 插件，但它似乎无法解决我的问题。我想到使用的一种方法是运行一个 python 脚本，该脚本在检测到动作时按下相关按钮。它将与游戏并行运行。还有其他更好的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78714836/taking-input-from-an-action-classifier-model-in-ue5</guid>
      <pubDate>Sat, 06 Jul 2024 12:29:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 StandardScaler 转换 x_test 数据时收到不合理警告</title>
      <link>https://stackoverflow.com/questions/78714642/getting-unreasonable-warning-while-transforming-the-x-test-data-using-standardsc</link>
      <description><![CDATA[import numpy as np
import pandas as pd
df = pd.read_csv(&#39;C:/Users/sayed/Downloads/placement.csv&#39;)
df = df.iloc[:, 1:]

X = df.iloc[:, 0:2]
Y = df.iloc[:,-1]

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

最后一行给出此警告：
UserWarning: X没有有效的功能名称，但 StandardScaler 配有功能名称 warnings.warn(

我确实向 ChatGPT 询问过这个问题，它给出了以下答案

您收到的警告是由于缩放器的安装方式与使用方式不匹配造成的

我仍然不清楚该警告。如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78714642/getting-unreasonable-warning-while-transforming-the-x-test-data-using-standardsc</guid>
      <pubDate>Sat, 06 Jul 2024 11:01:20 GMT</pubDate>
    </item>
    <item>
      <title>在自定义环境中，Actor-Critic 模型中的奖励没有增加</title>
      <link>https://stackoverflow.com/questions/78714452/rewards-not-increasing-in-actor-critic-model-in-a-custom-environment</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78714452/rewards-not-increasing-in-actor-critic-model-in-a-custom-environment</guid>
      <pubDate>Sat, 06 Jul 2024 09:38:19 GMT</pubDate>
    </item>
    <item>
      <title>AlexNet 的顶层和底层如何通信？</title>
      <link>https://stackoverflow.com/questions/78713337/how-do-the-top-and-bottom-layers-of-alexnet-communicate</link>
      <description><![CDATA[我正在尝试使用 PyTorch 重新实现 Krizhevsky et al. (2012)，并且我对 AlexNet 模型的第二和第三卷积层如何精确通信感到困惑（第五层到第六层以及第六层到第七层的输入也是如此，尽管我在这里的问题中省略了这一点）。
在下图中，有两个&quot;过滤器&quot;，它们将输出从上半部分传递到下一个上半部分，但也传递到下半部分。同样，下半部分也有两个&quot;过滤器&quot;将输出传递到下一个下半部分和上半部分。
我没有足够的声誉点来嵌入图像，所以这里是Krizhevsky et al. (2012) 的图 1 的部分屏幕截图。
第二层的输出如何传递到第三层？
我读了这篇论文，除非我错过了什么，否则作者似乎没有准确概述输出是如何从第二层传递到第三层的。我浏览了大量博客文章和 git 存储库，大多数描述都是高级的，大多数实现似乎没有将模型拆分到两个 GPU 之间。
我能找到的最相关的内容是来自 convnet2 readme 的以下句子：

这里，层 conv2a 和 conv2b 将 conv1a 和 conv1b 都作为输入。执行隐式复制操作，以便将 conv1a 的输出放入 conv2b 的输入中，以及将 conv1b 的输出放入 conv2a 的输入中。

我最好的猜测是第二层中的 out_channels 参数实际上应该是 64 而不是 128，然后顶层和底层的输出应该连接为 torch.cat([output_from_top_half, output_from_bottom_half], dim=1) 并传递给第三层的上半部分和下半部分。但我不确定我的理解是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/78713337/how-do-the-top-and-bottom-layers-of-alexnet-communicate</guid>
      <pubDate>Fri, 05 Jul 2024 21:44:17 GMT</pubDate>
    </item>
    <item>
      <title>CNN 模型中的损失函数没有减少吗？</title>
      <link>https://stackoverflow.com/questions/78712668/loss-function-not-decreasing-on-a-cnn-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78712668/loss-function-not-decreasing-on-a-cnn-model</guid>
      <pubDate>Fri, 05 Jul 2024 17:20:29 GMT</pubDate>
    </item>
    <item>
      <title>Darknet Yolov4-tiny（灰度输入）到 Tensorflow 权重，转换</title>
      <link>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</link>
      <description><![CDATA[TL;DR:
1 通道 TF 模型的行为与 3 通道模型不同。两者都成功从 Darknet -&gt; TF 转换，但 1 通道模型的表现不如转换前。
手头的任务和声明：
我有两个经过训练的 yolov4-tiny darknet 权重文件 (.weights)，一个有灰度输入（1 通道），另一个有颜色输入（3 通道）。我正在将两个权重文件转换为 Tensorflow 检查点格式，使用一个通用存储库（用于此任务），该存储库位于：
https://github.com/hunglc007/tensorflow-yolov4-tflite.git
两种模型的性能都已通过 c++ opencv readNetFromDarknet() 和 Python 等效项进行了测试。这两个模型本质上都是用灰度图像进行训练的，并且对灰度图像进行操作。3 通道模型的输入只是缩放到 3 通道的灰度图像。
Python 版本：3.10.11
TF 版本：2.10.1
问题陈述：
使用 tf.keras.Models.load_model(X) 加载时，带有颜色输入的权重文件转换良好，之后运行良好，但是当转换灰度输入权重文件时，使用 Tensorflow 加载时模型的性能急剧下降，我的意思是在最明显的情况下，带有颜色输入的模型运行完美，检测效果很差或不存在。值得注意的是，框不会错位，这意味着当发现检测结果时，它们大约在正确的位置，但例如宽度和高度可能会偏离。
我知道这个存储库的常见问题（硬编码内容等），并相应地更改了每次转换/模型加载的参数，并且在转换或模型加载期间不会发生任何错误。
我已经确认了输入层：

灰度：（无，640,640,1）
颜色：（无，640,640,3）

测试图像（用于性能测试）使用 opencv-python 加载，并且它们的有效性也已审查，即使将错误维度的数据插入到输入层也会出现错误。
除输入层之外的架构相同，已使用 model.summary() 确认。
我注意到，几年前我用不同的 TF 版本转换的 3 通道模型由 model.summary() 生成的架构有些不同。一些图块层似乎缺失了。此外，一些 tf 操作的名称也不同，但这可能只是 TF 版本不同。
旧颜色模型：
 tf_op_layer_Sigmoid (TensorFlo (None, 40, 40, 3, 2 0 [&#39;tf_op_layer_split_3[0][0]&#39;]
wOpLayer) )

tf_op_layer_Tile/multiples (Te (5,) 0 [&#39;tf_op_layer_strided_slice[0][0]
nsorFlowOpLayer) &#39;]

tf_op_layer_Sigmoid_3 (TensorF (None, 20, 20, 3, 2 0 [&#39;tf_op_layer_split_4[0][0]&#39;]
lowOpLayer) ) )

新灰度模型：
 tf.math.sigmoid (TFOpLambda) (无，40，40，3，2 0 [&#39;tf.split_3[0][0]&#39;]
)

---此处缺少图块层---

tf.math.sigmoid_3 (TFOpLambda) (无，20，20，3，2 0 [&#39;tf.split_4[0][0]&#39;]
)

我现在很卡。有什么帮助吗？
一些反复试验：

使用 Yolov4-tiny Head 解码块 -&gt;即使在模型能够加载的情况下也没有变化（解码时错误的尺寸会引发错误）
之前提到的旧 3 通道模型（几年前已转换为 Darknet -&gt; TF），当以与新模型相同的方式加载时，可以完美运行
]]></description>
      <guid>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</guid>
      <pubDate>Fri, 05 Jul 2024 13:54:37 GMT</pubDate>
    </item>
    <item>
      <title>关于将深度学习存储库称为上游或下游的澄清[关闭]</title>
      <link>https://stackoverflow.com/questions/78711787/clarification-on-referring-to-deep-learning-repositories-as-upstream-or-downstre</link>
      <description><![CDATA[我正在努力理解深度学习模型背景下不同存储库之间的关系。具体来说，我对要使用的适当术语感到好奇。
目前，存在许多深度学习模型存储库，其中上传了用于下游任务的模型，例如 Hugging Face 或 TensorFlow Hub。我相信还有一些存储库存储了用于训练这些模型的代码，通常在 GitHub 等平台上。
我的问题是：
我们可以将深度学习模型存储库（例如 Hugging Face）称为下游存储库，将代码存储库（例如 GitHub）称为上游存储库吗？
我想确保在讨论这些关系时使用正确的术语。任何有关此主题的澄清或资源都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78711787/clarification-on-referring-to-deep-learning-repositories-as-upstream-or-downstre</guid>
      <pubDate>Fri, 05 Jul 2024 13:40:14 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入技术从数据库中进行人脸识别</title>
      <link>https://stackoverflow.com/questions/78688976/face-recognize-from-the-database-using-embedding-technique</link>
      <description><![CDATA[我正在开展一个项目，旨在识别大学记录中是否存在任何个人的照片。所提出的方法涉及将每个学生照片的嵌入及其详细信息存储在矢量数据库中。当需要比较照片时，系统将生成该照片的嵌入值，然后将该值与数据库进行比较。如果该值在特定阈值内，则表明该个人存在于记录中。
我正在寻求专家建议，以确定这种方法是否可行。如果对这种方法有任何疑虑，我将不胜感激最佳解决方案的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78688976/face-recognize-from-the-database-using-embedding-technique</guid>
      <pubDate>Sun, 30 Jun 2024 15:09:55 GMT</pubDate>
    </item>
    <item>
      <title>在具有标准化变量的模型中缩放样本外预测：恢复到原始比例</title>
      <link>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</link>
      <description><![CDATA[我正在使用一个模型进行预测，其中变量按 $ x_i = \frac{{x_i - \text{mean}(x_i)}}{{\text{sd}(x_i)}} $ 缩放，并且我保存了平均值和标准差。现在，对于样本外预测，假设目标变量 $ ( x_i )$，基于缩放模型，我该如何缩小预测值？
我是否应该使用样本内 $ \text{Mean}(x_i) $ 和 $ \text{sd}(x_i) $ 来缩小样本外预测值，以便：
$ \text{重新缩放的样本外预测} = \text{缩放的预测} \times \text{sd}(x_i) + \text{mean}(x_i) $
这里的适当程序是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</guid>
      <pubDate>Tue, 04 Jun 2024 15:17:14 GMT</pubDate>
    </item>
    <item>
      <title>SHAP - 具有多个维度的实例</title>
      <link>https://stackoverflow.com/questions/76083485/shap-instances-that-have-more-than-one-dimension</link>
      <description><![CDATA[我对 SHAP 还很陌生，我想尝试一下，但遇到了一些困难。
该模型已经过训练，似乎表现良好。然后我使用训练数据来测试 SHAP。它看起来像这样：
 var_Braeburn var_Cripps Pink var_Dazzle var_Fuji var_Granny Smith \
0 1 0 0 0 0 
1 0 1 0 0 0 
2 0 1 0 0 0 
3 0 1 0 0 0 
4 0 1 0 0 0 

var_Other Variety var_Royal Gala (Tenroy) root_CG202 root_M793 \
0 0 0 0 0 
1 0 0 1 0 
2 0 0 1 0 
3 0 0 0 0 
4 0 0 0 0 

root_MM106 ... frt_BioRich Organic Compost_single \
0 1 ... 0 
1 0 ... 0
2 0 ... 0 
3 1 ... 0 
4 1 ... 0 

frt_Biomin Boron_single frt_Biomin Zinc_single \
0 0 1 
1 0 0 
2 0 0 
3 0 0 
4 0 0 

frt_Fertco Brimstone90 sulphur_single frt_Fertco Guano _single \
0 0 0 
1 0 0 
2 0 0 
3 0 0 
4 0 0 

frt_Gro Mn_multiple frt_Gro Mn_single frt_Organic Mag Super_multiple \
0 0 0 0 
1 1 0 1 
2 1 0 1 
3 1 0 1 
4 1 0 1

frt_Organic Mag Super_single frt_Other Fertiliser 
0 0 0 
1 0 0 
2 0 0 
3 0 0 
4 0 0 

然后我执行 explainer = shap.Explainer(model) 和 shap_values = explainer(X_train)
此操作运行无错误，shap_values 给出以下结果：
.values =
array([[[ 0.00775555, -0.00775555],
[-0.03221035, 0.03221035],
[-0.0027203 , 0.0027203 ],
...,
[ 0.00259787, -0.00259787],
[-0.00459262, 0.00459262],
[-0.0303394 , 0.0303394 ]],

[[-0.00068313, 0.00068313],
[-0.03006355, 0.03006355],
[-0.00245706, 0.00245706],
...,
[-0.00418809, 0.00418809],
[-0.00088372, 0.00088372],
[-0.00030019, 0.00030019]],

[[-0.00068313, 0.00068313],
[-0.03006355, 0.03006355],
[-0.00245706, 0.00245706],
...,
[-0.00418809, 0.00418809],
[-0.00088372, 0.00088372],
[-0.00030019, 0.00030019]],

...,

但是，当我运行 shap.plots.beeswarm(shap_values) 时，出现以下错误：
ValueError: beeswarm plot 不支持绘制具有多个维度的实例的解释！
我在这里做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/76083485/shap-instances-that-have-more-than-one-dimension</guid>
      <pubDate>Sun, 23 Apr 2023 06:49:07 GMT</pubDate>
    </item>
    <item>
      <title>YOLO v8 的默认网格大小</title>
      <link>https://stackoverflow.com/questions/75904407/default-grid-size-for-yolo-v8</link>
      <description><![CDATA[YOLO 使用网格来分配检测到的对象的中心。在最初的论文中，网格是 7x7
Yolo v8 中的网格大小是多少？
我问这个问题的原因是因为无锚检测，因为它不再根据锚框的偏移量进行计算，而是使用中心。]]></description>
      <guid>https://stackoverflow.com/questions/75904407/default-grid-size-for-yolo-v8</guid>
      <pubDate>Sat, 01 Apr 2023 05:19:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 Huggingface Trainer 进行训练时，如何选择 eval_dataset 的子集？</title>
      <link>https://stackoverflow.com/questions/74257764/how-to-select-a-subset-of-the-eval-dataset-when-training-with-huggingface-traine</link>
      <description><![CDATA[当使用 Huggingface 变换器的 Trainer 时，例如
# 设置训练参数 - 这些参数并没有真正调整，可以随意更改
training_args = Seq2SeqTrainingArguments(
output_dir=&quot;./&quot;,
evaluation_strategy=&quot;steps&quot;,
per_device_train_batch_size=50,
per_device_eval_batch_size=10,
predict_with_generate=True,
logs_steps=2, # 设置为 1000 进行完整训练
save_steps=16, # 设置为 500 进行完整训练
eval_steps=4, # 设置为 8000 进行完整训练
warmup_steps=1, # 设置为 2000 以进行完整训练
max_steps=16, # 删除以进行完整训练
# overwrite_output_dir=True,
save_total_limit=1,
#fp16=True, 
)

# 实例化训练器
trainer = Seq2SeqTrainer(
model=multibert,
tokenizer=tokenizer,
args=training_args,
train_dataset=train_data.with_format(&quot;torch&quot;),
eval_dataset=eval_data.with_format(&quot;torch&quot;),
)

是否有某种方法可以在每 n 个 eval_steps 中从 eval_data 中随机选择/采样？
例如我试过了
eval_data = eval_data.select(range(3000))

...

trainer = Seq2SeqTrainer(
model=multibert,
tokenizer=tokenizer,
args=training_args,
train_dataset=train_data.with_format(&quot;torch&quot;),
eval_dataset=eval_data.with_format(&quot;torch&quot;),
)

但这会在训练之前静态定义 eval_data 子集。
是否可以在训练期间进行选择并使其在每个评估点选择不同的子集？]]></description>
      <guid>https://stackoverflow.com/questions/74257764/how-to-select-a-subset-of-the-eval-dataset-when-training-with-huggingface-traine</guid>
      <pubDate>Mon, 31 Oct 2022 00:42:20 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中使用排名数据</title>
      <link>https://stackoverflow.com/questions/22117692/using-ranking-data-in-logistic-regression</link>
      <description><![CDATA[我正在尝试在逻辑回归中使用一些排名数据。我想使用机器学习来制作一个简单的分类器，以确定网页是否“好”。这只是一个学习练习，所以我不期望获得很好的结果；只是希望学习“过程”和编码技术。
我已将我的数据放入 .csv 中，如下所示：
URL WebsiteText AlexaRank GooglePageRank

在我的测试 CSV 中，我们有：
URL WebsiteText AlexaRank GooglePageRank 标签

标签是二进制分类，用 1 表示“好”，用 0 表示“坏”。
我目前仅使用网站文本运行 LR；我在其上运行了 TF-IDF。
我有两个问题需要帮助：

如何规范化我的 AlexaRank 排名数据？我有一组 10,000 个网页，我有所有网页的 Alexa 排名；但是它们的排名不是 1-10,000。它们在整个互联网中排名靠前，因此虽然 http://www.google.com 可能排名 #1，但 http://www.notasite.com 可能排名 #83904803289480。如何在 Scikit learn 中对此进行规范化，以便从我的数据中获得最佳结果？

我以这种方式运行我的逻辑回归；我几乎可以肯定我做错了。我试图对网站文本进行 TF-IDF，然后添加另外两个相关列并拟合逻辑回归。如果有人能快速验证我是否正确地采用了我想在 LR 中使用的三列，我将不胜感激。
 loadData = lambda f: np.genfromtxt(open(f,&#39;r&#39;), delimiter=&#39; &#39;)

print &quot;loading data..&quot;
traindata = list(np.array(p.read_table(&#39;train.tsv&#39;))[:,2])#Reading WebsiteText 列进行 TF-IDF。
testdata = list(np.array(p.read_table(&#39;test.tsv&#39;))[:,2])
y = np.array(p.read_table(&#39;train.tsv&#39;))[:,-1] #读取标签

tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents=&#39;unicode&#39;, analyzer=&#39;word&#39;,

token_pattern=r&#39;\w{1,}&#39;, ngram_range=(1, 2), use_idf=1, smooth_idf=1,sublinear_tf=1)

rd = lm.LogisticRegression(penalty=&#39;l2&#39;, dual=True, tol=0.0001, C=1, fit_intercept=True, intercept_scaling=1.0, class_weight=None, random_state=None)

X_all = traindata + testdata
lentrain = len(traindata)

print &quot;fitting pipeline&quot;
tfv.fit(X_all)
print &quot;transforming data&quot;
X_all = tfv.transform(X_all)
X = X_all[:lentrain]
X_test = X_all[lentrain:]

print &quot;20 Fold CV Score: &quot;, np.mean(cross_validation.cross_val_score(rd, X, y, cv=20,scoring=&#39;roc_auc&#39;))

#添加两个整数列
AlexaAndGoogleTrainData = list(np.array(p.read_table(&#39;train.tsv&#39;))[2:,3])#不确定我是否做对了。期望它包含 AlexaRank 和 GooglePageRank 列。
AlexaAndGoogleTestData = list(np.array(p.read_table(&#39;test.tsv&#39;))[2:,3])
AllAlexaAndGoogleInfo = AlexaAndGoogleTestData + AlexaAndGoogleTrainData

#向 X 添加两列。
X = np.append(X, AllAlexaAndGoogleInfo, 1) #我认为我做错了。

print &quot;training on full data&quot;
rd.fit(X,y)
pred = rd.predict_proba(X_test)[:,1]
testfile = p.read_csv(&#39;test.tsv&#39;, sep=&quot;\t&quot;, na_values=[&#39;?&#39;], index_col=1)
pred_df = p.DataFrame(pred, index=testfile.index, columns=[&#39;label&#39;])
pred_df.to_csv(&#39;benchmark.csv&#39;)
print &quot;提交文件已创建..&quot;`


]]></description>
      <guid>https://stackoverflow.com/questions/22117692/using-ranking-data-in-logistic-regression</guid>
      <pubDate>Sat, 01 Mar 2014 17:25:19 GMT</pubDate>
    </item>
    </channel>
</rss>