<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 14 Jan 2024 15:13:30 GMT</lastBuildDate>
    <item>
      <title>GridSearchCV 和 VotingClassifier 拟合问题</title>
      <link>https://stackoverflow.com/questions/77815549/problem-with-fitting-gridsearchcv-and-votingclassifier</link>
      <description><![CDATA[我在 Sklearn 中使用 GreadSearch 时遇到问题。这是我的 2 段代码：
from sklearn.compose import ColumnTransformer, make_column_selector
从 sklearn.preprocessing 导入 StandardScaler

哦= OneHotEncoder（）
定标器=标准定标器()

numeric_columns = make_column_selector(dtype_include=&#39;number&#39;)(X_ros)

变压器 = ColumnTransformer([
    （&#39;编码器&#39;，哦，object_columns），
    （&#39;缩放器&#39;，缩放器，数字列）
]）

&lt;前&gt;&lt;代码&gt;
从 sklearn. Linear_model 导入 LogisticRegressionCV
从 sklearn.neighbors 导入 KNeighborsClassifier
从 sklearn.ensemble 导入 VotingClassifier
从 sklearn.model_selection 导入 GridSearchCV

分类器={
    &#39;logistic_reg&#39;: LogisticRegressionCV(solver=&#39;saga&#39;),
    &#39;knn&#39;: KNeighborsClassifier()
}
模型=管道（[
    （&#39;预处理器&#39;，变压器），
    (&#39;分类器&#39;, VotingClassifier(分类器))
]）

参数 = [{
    &#39;logistic_reg__Cs&#39;: 列表(范围(1, 11)),
    &#39;logistic_reg__penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;],
    &#39;logistic_reg__class_weight&#39;：[无，&#39;平衡&#39;]，
    &#39;knn__n_neighbors&#39;: 列表(范围(1, 16)),
    &#39;knn__weights&#39;: [&#39;均匀&#39;, &#39;距离&#39;]
}
gridsearch = GridSearchCV(模型，参数，评分=&#39;f1&#39;，n_jobs=-1，cv=5)

但是我们有一个错误。错误：
ValueError：需要解压的值太多（预期为 2）

如果它能工作那就太酷了，因为编码时间更少。你能帮我解决这个问题吗？感谢您的关注。]]></description>
      <guid>https://stackoverflow.com/questions/77815549/problem-with-fitting-gridsearchcv-and-votingclassifier</guid>
      <pubDate>Sun, 14 Jan 2024 15:07:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 SMOTENC 生成多数类和少数类的综合数据</title>
      <link>https://stackoverflow.com/questions/77815288/generate-synthetic-data-for-majority-and-minority-classes-using-smotenc</link>
      <description><![CDATA[我正在研究一个分类问题，我尝试为多数类和少数类生成合成数据，因为我想在合成数据上训练我的模型并在实际数据上进行测试，我正在使用下面的代码，但是我无法生成多数类的合成数据，我该怎么办？
代码：
每种类型的 # 列
Continuous_cols = [&#39;amt&#39;, &#39;BAL&#39;, &#39;MOB&#39;, &#39;TPOP&#39;]
boolean_cols = [&#39;EVER_L3M&#39;,&#39;EVER_L3M&#39;,&#39;EVER_L6M&#39;]
target_col = &#39;目标&#39;

将 pandas 导入为 pd
从 imblearn.over_sampling 导入 SMOTENC，RandomOverSampler

def oversample_both_classes(df, Continuous_cols, boolean_cols, target_col):
    # 单独的特征和目标
    X = df.drop(target_col, 轴=1)
    y = df[目标列]

    # 计算布尔索引和连续索引
    boolean_indices = [X.columns.get_loc(col) for col in boolean_cols]
    Continuous_indices = [X.columns.get_loc(col) for col in Continuous_cols]

    
    分类索引 = 布尔索引 + 连续索引

    # 使用 SMOTENC 对少数类进行过采样
    smotenc = SMOTENC(random_state=42, categorical_features=boolean_indices)
    X_resampled_minority, y_resampled_minority = smotenc.fit_resample(X, y)

    # 使用 RandomOverSampler 对多数类进行过采样
    ros = RandomOverSampler(random_state=42)
    X_resampled_majority, y_resampled_majority = ros.fit_resample(X, y)

    
    X_resampled = pd.concat([pd.DataFrame(X_resampled_minority, columns=X.columns),
                            pd.DataFrame(X_resampled_majority, columns=X.columns)])
    y_resampled = pd.concat([pd.Series(y_resampled_minority), pd.Series(y_resampled_majority)])

    
    resampled_df = pd.DataFrame(X_resampled, columns=X.columns)
    resampled_df[target_col] = y_resampled

    返回重采样_df


oversampled_df_PL = oversample_both_classes(df, Continuous_cols, boolean_cols, target_col)
]]></description>
      <guid>https://stackoverflow.com/questions/77815288/generate-synthetic-data-for-majority-and-minority-classes-using-smotenc</guid>
      <pubDate>Sun, 14 Jan 2024 13:50:11 GMT</pubDate>
    </item>
    <item>
      <title>在运行中构建机器学习预测模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77815159/building-machine-learning-predictive-models-on-the-run</link>
      <description><![CDATA[我想将机器学习预测功能添加到现有应用程序中；用于训练模型的数据存储在数据库中。
我的问题如下：

在典型的机器学习项目中，您有一组用于训练模型的特征，以及一个作为目标的列。就我而言，大多数列都可以作为目标；例如，用户可以选择“销售”。在这种情况下，“销售”是指“销售额”。列将是目标，并且不会用作训练中的特征。另一方面，如果用户想要预测另一列的“数量”，则可以预测“销售额”。列将是用于培训等的功能，并且一旦部署，用户将需要提供“销售”列。值来预测实现该销售额所需的数量。由于我有 20 多个列可以是功能或目标，我该如何解决这个问题？

应该为每个客户定制机器学习模型；由于数据驻留要求，我无法访问每个用户的数据，因此模型的训练需要在客户的本地动态进行，有什么方法可以保证模型的性能吗？


我考虑过训练 CAT boost 模型或任何其他在运行时具有合理默认值的模型，将其存储在某个地方并在需要时再次使用它。但是，我无法确保模型的性能。我所需要的只是一些关于如何解决这个问题的提示，以便我可以阅读更多内容。]]></description>
      <guid>https://stackoverflow.com/questions/77815159/building-machine-learning-predictive-models-on-the-run</guid>
      <pubDate>Sun, 14 Jan 2024 13:08:47 GMT</pubDate>
    </item>
    <item>
      <title>多类图像分类堆栈[关闭]</title>
      <link>https://stackoverflow.com/questions/77814090/multiclass-image-classification-stack</link>
      <description><![CDATA[在制作 inagewoof 数据集时，我无法获得超过 70% 的准确度，该数据集包含 Imagenet 中 10 个类别的子集，这些类别不太容易分类，因为它们都是狗品种。品种有：澳大利亚梗、边境梗、萨摩耶、比格犬、西施犬、英国猎狐犬、罗得西亚脊背犬、野狗、金毛猎犬、古代英国牧羊犬。
我需要做一个实验，但到目前为止我还没有开始，因为我的基本模型每次运行仅获得 30-40% 的准确率。







我已经尝试了添加卷积层的所有方法。这只是实验的基本模型，但我什至还没有触及 70%，所以我非常绝望。请注意，我正在使用 Google Collaborator]]></description>
      <guid>https://stackoverflow.com/questions/77814090/multiclass-image-classification-stack</guid>
      <pubDate>Sun, 14 Jan 2024 06:05:58 GMT</pubDate>
    </item>
    <item>
      <title>是否可以建立自变量和因变量均为日期时间的回归模型或时间序列预测模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77814061/is-it-possible-to-make-regression-models-or-time-series-forecast-models-where-bo</link>
      <description><![CDATA[我有一个小数据框，其中两列都是日期时间数据类型，因此如果我要绘图，x 和 y 都是日期时间。
我基本上想建立一个模型，纯粹根据开始日期来预测某物的交付/到期日。
我尝试的一切似乎都不起作用。有人有什么想法吗？这样的事情可能吗？
（我已经通过 sklearn 和 ARIMA 建模尝试过 LinearRegression，但被我的数据集困住了。）
我的 df 看起来像这样：
 收到日期 截止日期
2474 2021-06-25 2021-06-28
2475 2021-06-29 2021-06-29
2476 2021-06-29 2021-06-29
2477 2021-06-29 2021-06-29
2479 2021-06-30 2021-08-23
2480 2021-06-30 2021-07-06
2485 2021-07-01 2021-07-01
2486 2021-07-01 2021-07-06
]]></description>
      <guid>https://stackoverflow.com/questions/77814061/is-it-possible-to-make-regression-models-or-time-series-forecast-models-where-bo</guid>
      <pubDate>Sun, 14 Jan 2024 05:48:53 GMT</pubDate>
    </item>
    <item>
      <title>提高自动完成模型的准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/77814040/improving-accuracy-of-the-autocomplete-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77814040/improving-accuracy-of-the-autocomplete-model</guid>
      <pubDate>Sun, 14 Jan 2024 05:35:08 GMT</pubDate>
    </item>
    <item>
      <title>如何将 python 代码构建为 .tflite 模型，以便可以在我的 Flutter 应用程序中使用它</title>
      <link>https://stackoverflow.com/questions/77813406/how-can-i-build-python-code-to-a-tflite-model-so-it-can-be-used-in-my-flutter-a</link>
      <description><![CDATA[我正在开发一个文本摘要应用程序，我已经编写了以下代码：
导入spacy
导入 pytextrank
从变压器进口管道

#定义典型的spacy管道

nlp = spacy.load(“en_core_web_sm”)

nlp.add_pipe(“textrank”)

当我运行它时：
example_text=“”“深度学习。

深度学习是一类机器学习算法，[9]: 199–200 使用多个层从原始输入中逐步提取更高级别的特征。例如，在图像处理中，较低层可以识别边缘，而较高层可以识别与人类相关的概念，例如数字、字母或面部。

从另一个角度看深度学习，深度学习指的是“计算机模拟”的学习。或“自动化”人类的学习过程是从源（例如狗的图像）到学习对象（狗）。因此，创造了“更深”的概念。学习或“最深的”学习[10]是有道理的。最深度的学习是指从源到最终学习对象的全自动学习。因此，深度学习是指混合学习过程：从源到学习的半对象的人类学习过程，然后是从人类学习的半对象到最终学习对象的计算机学习过程。
概述

大多数现代深度学习模型都基于多层人工神经网络，例如卷积神经网络和变压器，尽管它们也可以包括在深度生成模型中分层组织的命题公式或潜在变量，例如深度信念网络和深度神经网络中的节点。玻尔兹曼机。[11]

在深度学习中，每个级别都会学习将其输入数据转换为稍微更抽象和复合的表示形式。在图像识别应用中，原始输入可能是像素矩阵；第一表示层可以抽象像素并对边缘进行编码；第二层可以对边缘的排列进行组合和编码；第三层可以编码鼻子和眼睛；第四层可以识别出图像中包含人脸。重要的是，深度学习过程可以自行学习将哪些特征最佳地放置在哪个级别。这并不能消除手动调整的需要；例如，不同的层数和层大小可以提供不同程度的抽象。[12][13]

“深”字在“深度学习”中指数据转换的层数。更准确地说，深度学习系统具有相当大的学分分配路径（CAP）深度。 CAP 是从输入到输出的转换链。 CAP 描述了输入和输出之间的潜在因果关系。对于前馈神经网络，CAP 的深度就是网络的深度，并且是隐藏层的数量加一（因为输出层也是参数化的）。对于循环神经网络，信号可能多次传播通过一层，CAP 深度可能是无限的。 [14]没有普遍认可的深度阈值来区分浅层学习和深度学习，但大多数研究人员都认为深度学习涉及的 CAP 深度高于
2. 深度为 2 的 CAP 已被证明是通用逼近器，因为它可以模拟任何函数。 [15]除此之外，更多的层并不会增加网络的函数逼近能力。深层模型（CAP &gt; 2）能够比浅层模型提取更好的特征，因此，
额外的层有助于有效地学习特征。 ”“”


doc=nlp(示例文本)
在 doc._.textrank.summary(limit_phrases=2,limit_sentences=2) 中发送：
    打印（已发送）

输出：
深度学习是一类机器学习算法，[9]: 199–200  使用多个层从原始输入中逐步提取更高级别的特征。

这对我来说很好，我现在的问题是，如何将此代码构建到 ,tflite 模型中，以便我可以在我的 Flutter 应用程序中使用它]]></description>
      <guid>https://stackoverflow.com/questions/77813406/how-can-i-build-python-code-to-a-tflite-model-so-it-can-be-used-in-my-flutter-a</guid>
      <pubDate>Sat, 13 Jan 2024 23:02:05 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林进行 R Tidymodels 分类：预测目标变量时出错</title>
      <link>https://stackoverflow.com/questions/77813309/r-tidymodels-classification-with-random-forest-error-while-predicting-target-va</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77813309/r-tidymodels-classification-with-random-forest-error-while-predicting-target-va</guid>
      <pubDate>Sat, 13 Jan 2024 22:25:19 GMT</pubDate>
    </item>
    <item>
      <title>如何处理图神经网络中损失被限制的情况？</title>
      <link>https://stackoverflow.com/questions/77813001/how-to-deal-with-loss-gettting-clamped-in-graph-neural-networks</link>
      <description><![CDATA[我使用 pytorch 在具有相同边缘索引的图上训练了以下模型（任务是电子健康记录上的图分类，其中每个图代表患者数据，并且节点向量是从组合知识图导出的）
class mdl(torch.nn.Module):
    def _init_（自身，输入大小，隐藏大小，输出大小，丢失率）：
        超级（GCNClassifier，自我）。_init_（）
        self.conv1 = GCNConv(输入大小, 隐藏大小)
        self.conv2 = GCNConv(隐藏大小, 输出大小)
        self.dropout = torch.nn.Dropout(dropout_rate)


    defforward（自身，x，edge_index）：
        x = self.conv1(x, 边缘索引)
        x = F.relu(x)
        x = self.dropout(x)
        x = self.conv2(x, 边缘索引)
        x = torch.mean(x, dim=0, keepdim=True)
        返回x

问题是损失被限制在一个特定的值
我尝试了各种学习率值，并尝试了各种技术，例如动量和学习率调度，但损失仍然保持不变
我尝试使用以下循环训练上述模型
#training (graphVec) 800 个图（每个图的形状为 [5,20]）
#y_train是形状为[800,1]的0和1的张量，用于二元分类

纪元数 = 100
对于范围内的纪元（num_epochs）：
    模型.train()
    

    for i in range(len(graphVec)): # 在每次迭代中通过模型传递每个图
        输出 = 模型（graphVec[i]，edge_index）
        损失 = 标准(输出, y_train[i])
        loss.backward()
        优化器.step()
        优化器.zero_grad()
    # StepLR 调度步骤
    
    调度程序.step()
    打印（输出）
    # 打印每个epoch的损失和学习率
    current_lr = optimizer.param_groups[0][&#39;lr&#39;]
    print(f&#39;Epoch [{epoch + 1}/{num_epochs}], 损失: {loss.item()}, 学习率: {current_lr}&#39;)

但是我的损失被严重限制了（损失并没有随着时代的推移而减少）
我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/77813001/how-to-deal-with-loss-gettting-clamped-in-graph-neural-networks</guid>
      <pubDate>Sat, 13 Jan 2024 20:33:22 GMT</pubDate>
    </item>
    <item>
      <title>上采样，然后进行 Conv2d</title>
      <link>https://stackoverflow.com/questions/77812921/upsample-followed-by-conv2d</link>
      <description><![CDATA[在UNet架构的解码器部分，Upsampling层后面通常跟着Conv2d。
这是一个例子：
类 UpConv(nn.Module):
    def __init__(自身, in_chans, out_chans):
        超级().__init__()
        self.up = nn.Sequential(
            nn.Upsample（scale_factor = 2，mode =“双线性”，align_corners = True），
            nn.Conv2d(in_chans, out_chans, kernel_size = 1),
        ）
        self.conv = DoubleConv(out_chans*2, out_chans)
...

有人可以解释一下为什么我们需要 Conv2d 吗？
我读到 Conv2d 层允许学习上采样特征图中的空间层次结构。但我不明白为什么它是相关的，因为在编码过程中应用了 2D 卷积，这意味着已经学习了空间信息。
我的猜测是Conv2d是用来调整输出通道数的。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/77812921/upsample-followed-by-conv2d</guid>
      <pubDate>Sat, 13 Jan 2024 20:05:19 GMT</pubDate>
    </item>
    <item>
      <title>数据加载减慢模型训练[关闭]</title>
      <link>https://stackoverflow.com/questions/77812244/data-loading-slowing-down-model-training</link>
      <description><![CDATA[当我开始训练模型时，我注意到第一个时期非常慢，但接下来的时期很快。当使用通常的数据加载方法时，它不需要第一个纪元，所以我怀疑错误出在我的加载器中。
请看看我的加载器：
def load_image(文件名, target_shape=(300,300,3)):
    image_string = tf.io.read_file(文件名)
    图像 = tf.image.decode_jpeg(image_string, 通道=3)
    图像 = tf.keras.applications.efficientnet_v2.preprocess_input(图像)

    # 调整图像大小，使其较大尺寸与目标尺寸匹配
    形状 = tf.shape(图像)
    比率 = tf.cast(target_shape[0], tf.float32) / tf.cast(tf.maximum(shape[0], shape[1]), tf.float32)
    new_shape = tf.cast(tf.cast(shape[:2], tf.float32) * 比率, tf.int32)
    图像 = tf.image.resize(图像, new_shape)

    # 将图像填充到目标形状
    pad_height = target_shape[0] - new_shape[0]
    pad_width = target_shape[1] - new_shape[1]
    pad_top = pad_height // 2
    pad_bottom = pad_height - pad_top
    pad_left = pad_width // 2
    pad_right = pad_width - pad_left
    图像 = tf.pad(图像, [[pad_top, pad_bottom], [pad_left, pad_right], [0, 0]], Constant_values=0)

    返回图像

def preprocess_triplets(锚点、正值、负值):
    返回 （
        加载图像（锚点），
        加载图像（正），
        加载图像（负），
    ）

我的问题是，是否有一些更有效的方法可以手动在数据集中创建批次，并且仍然受益于 tf.data 的速度。因为我现在实施的数据加载正在减慢训练速度。另外，我需要对每个批次内的数据进行洗牌，因为在洗牌整个数据集时，批次会混合。正如我所说，只有第一个纪元是缓慢的。我怀疑它然后缓存在我的内存中，但我知道整个数据集不适合我的内存。第一个 epoch 花了 25 分钟，接下来的 epoch 花了 7 分钟。]]></description>
      <guid>https://stackoverflow.com/questions/77812244/data-loading-slowing-down-model-training</guid>
      <pubDate>Sat, 13 Jan 2024 16:40:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Roberta 计算单词和句子嵌入？</title>
      <link>https://stackoverflow.com/questions/77805776/how-to-calculate-word-and-sentence-embedding-using-roberta</link>
      <description><![CDATA[我正在尝试使用 Roberta 计算单词和句子嵌入，对于单词嵌入，我从 RobertaModel 类中提取最后一个隐藏状态 outputs[0]，但是我不确定这是否是正确的计算方法。
至于句子嵌入，我不知道如何计算它们，这是我尝试过的代码：
从 Transformers 导入 RobertaModel、RobertaTokenizer
进口火炬

模型 = RobertaModel.from_pretrained(&#39;roberta-base&#39;)
tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;)
Captions = [“示例标题”、“lorem ipsum”、“这只鸟是黄色的，有红色翅膀”、“嗨”、“示例”]

encoded_captions = [tokenizer.encode(caption) 用于字幕中的字幕]

# 用 0 将序列填充到相同的长度
max_len = max(len(seq) 用于编码字幕中的 seq)
padded_captions = [seq + [0] * (max_len - len(seq)) 对于encoded_captions中的seq]

# 转换为批量大小为 5 的 PyTorch 张量
input_ids = torch.tensor(padded_captions)

输出=模型(input_ids)
word_embedding = 输出[0].连续()
句子嵌入 = ??????

如何使用 Roberta 计算单词和句子嵌入？]]></description>
      <guid>https://stackoverflow.com/questions/77805776/how-to-calculate-word-and-sentence-embedding-using-roberta</guid>
      <pubDate>Fri, 12 Jan 2024 10:05:01 GMT</pubDate>
    </item>
    <item>
      <title>将 XGBoost Shapely 值转换为“SHAP”的解释对象</title>
      <link>https://stackoverflow.com/questions/77800583/converting-xgboost-shapely-values-to-shaps-explanation-object</link>
      <description><![CDATA[我正在尝试将 XGBoost 形状值转换为 SHAP 解释器对象。将[此处][1]的示例与内置 SHAP 库一起使用需要几天的时间（即使在二次采样数据集上），而 XGBoost 库则需要几分钟。然而。我想输出一个与[此处][2]示例中显示的类似的蜂群图。
我的想法是，我可以使用 XGBoost 库来恢复形状值，然后使用 SHAP 库绘制它们，但蜂群图需要一个解释器对象。如何将我的 XGBoost 助推器对象转换为解释器对象？
这是我尝试过的：
导入形状
助推器 = model.get_booster()
d_test = xgboost.DMatrix(X_test[0:100], y_test[0:100])
shap_values = booster.predict(d_test, pred_contribs=True)
shap.plots.beeswarm(shap_values)

返回结果：
类型错误：蜂群图需要一个“Explanation”对象作为“shap_values”参数。

为了澄清，如果可能的话，我想用 xgboost 内置库生成的值创建解释器对象。避免 shap.explainer 或 shap.TreeExplainer 函数调用是一个优先事项，因为它们需要更长的时间（几天）而不是几分钟才能返回。
[1]: https: //shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Python%20Version%20of%20Tree%20SHAP.html
[2]:  https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/beeswarm.html#A-simple-beeswarm-summary-plot]]></description>
      <guid>https://stackoverflow.com/questions/77800583/converting-xgboost-shapely-values-to-shaps-explanation-object</guid>
      <pubDate>Thu, 11 Jan 2024 13:55:27 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：检查模型目标时出错：预期 volution2d_2 具有形状（无、26、26、64），但得到的数组具有形状（250、227、227、1）</title>
      <link>https://stackoverflow.com/questions/42720236/valueerror-error-when-checking-model-target-expected-convolution2d-2-to-have-s</link>
      <description><![CDATA[我使用 Keras 和 Tensorflow 作为后端，这是我的代码：
#图像加载和预处理
导入操作系统
从 PIL 导入图像作为图像
将 numpy 导入为 np

#files 是图像列表
files = [os.path.join(&#39;保存&#39;, file_i)
 for file_i in os.listdir(&#39;保存&#39;)
 如果 file_i 中有“.jpg”]

图片 = []
对于文件中的图像：
    img = Image.open(图像)
    img = img.resize((227,227),Image.BILINEAR)
    img = img.convert(&#39;L&#39;)

    img = np.asarray(img)

    数组 = img.astype(&#39;float32&#39;)
    数组 /= 255
    imgs.append(数组)

imgs = np.asarray(imgs)

The_data = imgs.reshape(imgs.shape[0], 227, 227,1)
The_data = The_data.reshape(10, 25, 227, 227, 1)

从 keras.models 导入顺序
从 keras.layers.convolutional 导入 Convolution2D、Deconvolution2D
从 keras.layers.convolutional_recurrent 导入 ConvLSTM2D
从 keras.layers.normalization 导入 BatchNormalization
从 keras.layers.wrappers 导入 TimeDistributed
将 numpy 导入为 np
将 pylab 导入为 plt



模型=顺序（）
#2 卷积层


model.add(TimeDistributed(Convolution2D(128, 11, 11 , border_mode=&#39;相同&#39;, 子样本 = (4,4)), input_shape=(无,227, 227, 1)))
model.add(TimeDistributed(Convolution2D(64, 5, 5, border_mode=&#39;相同&#39;, 子样本 = (2,2))))

model.add(TimeDistributed(ConvLSTM2D(nb_filter=64, nb_row=3, nb_col=3,
                   border_mode =&#39;相同&#39;，return_sequences = True）））
model.add(BatchNormalization())
model.add(TimeDistributed(ConvLSTM2D(nb_filter=32, nb_row=3, nb_col=3,
                   border_mode =&#39;相同&#39;，return_sequences = True）））
model.add(BatchNormalization())
model.add(TimeDistributed(ConvLSTM2D(nb_filter=64, nb_row=3, nb_col=3,
                   border_mode =&#39;相同&#39;，return_sequences = True）））
model.add(BatchNormalization())

model.add(TimeDistributed(Devolved2D(128, 5, 5,border_mode=&#39;相同&#39;, output_shape=(无,57, 57, 128), 子样本 = (2,2))))
model.add(TimeDistributed(Devolved2D(1, 11, 11,border_mode=&#39;相同&#39;, output_shape=(无,227, 227, 1), 子样本 = (4,4))))


model.compile(optimizer=&#39;adadelta&#39;, loss=&#39;binary_crossentropy&#39;)
model.fit(The_data,The_data,batch_size=5,nb_epoch=1)
模型.summary()


&lt;小时/&gt;

我正在尝试读取一些图像并对它们进行一些预处理，然后应用 (A) 2 个卷积层、(B) 三个 ConvLSTM 层和 (C) 2 个反卷积层。
我正在尝试实现本研究中使用的算法论文
但我发现每个层（conv，deconv，convlstm）都需要不同的东西，我已经搜索并知道convlstm需要5维输入（帧数）但如何更改它的输入形状，因为它不是模型中的第一层。
算法概述
我这里有三个主要问题：
1-Convul​​tion2d 抛出该错误

&lt;块引用&gt;
  检查模型目标时出错：预期 volution2d_2 有
  形状 (None, 26, 26, 64)但得到了形状为数组(250, 227, 227,
  1)`

2-我评论了 ConvLSTM2D，因为它抛出了该错误 

&lt;块引用&gt;
  ValueError：输入 0 与层 convlstm2d_1 不兼容：预期
  ndim=5，找到ndim=4

我还评论了反卷积，因为我不知道output_shape应该是什么。
我知道最后我应该重建输入图像。
3- 在 model.fit 中，我没有标记数据，因为我正在进行无监督学习，我应该保持这种方式还是什么？]]></description>
      <guid>https://stackoverflow.com/questions/42720236/valueerror-error-when-checking-model-target-expected-convolution2d-2-to-have-s</guid>
      <pubDate>Fri, 10 Mar 2017 14:03:34 GMT</pubDate>
    </item>
    <item>
      <title>pandas 中的列连接不正确</title>
      <link>https://stackoverflow.com/questions/22139189/joining-columns-in-pandas-incorrectly</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/22139189/joining-columns-in-pandas-incorrectly</guid>
      <pubDate>Mon, 03 Mar 2014 05:19:40 GMT</pubDate>
    </item>
    </channel>
</rss>