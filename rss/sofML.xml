<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 21 May 2024 03:16:08 GMT</lastBuildDate>
    <item>
      <title>如何在Unity中使用Python训练的机器学习模型？</title>
      <link>https://stackoverflow.com/questions/78509446/how-to-using-machine-learning-model-trained-in-python-within-unity</link>
      <description><![CDATA[我有一项任务需要在 Unity 中使用用 Python 训练的机器学习模型。我仍在研究其可行性，并发现可以使用 IronPython，但网上关于此类任务的信息很少，因此我预计我的方法是非主流的。
有人对主流方法有任何经验或其他建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78509446/how-to-using-machine-learning-model-trained-in-python-within-unity</guid>
      <pubDate>Tue, 21 May 2024 02:36:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 和 SARIMAX 或其他方法预测手机销量 [关闭]</title>
      <link>https://stackoverflow.com/questions/78509245/predicting-phone-sales-with-python-and-sarimax-or-other</link>
      <description><![CDATA[我正在尝试预测手机的销量，有几个因素。

发布日的销售额可能达到数月至 6 个月的销售额

季节性起着巨大的作用，我有大约 5 年的数据

有时销售会因为手机缺货而停止（但除此之外还有需求）

特定模型的寿命通常较短，因此数据不多，主要使用 2-6 个月的数据


我一直在使用 SARIMAX 将 2 和 4 很好地结合在一起。但我无法解析我的数据的 1 和 3。
你有什么建议？
我尝试阅读 SARIMAX 文档和烦人的 ChatGPT 来寻求解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78509245/predicting-phone-sales-with-python-and-sarimax-or-other</guid>
      <pubDate>Tue, 21 May 2024 00:45:07 GMT</pubDate>
    </item>
    <item>
      <title>keras 指标和 sklearn 指标之间的差异</title>
      <link>https://stackoverflow.com/questions/78509105/discrepancy-between-keras-metrics-and-sklearn-metrics</link>
      <description><![CDATA[我使用 InceptionV3 训练了一个 cnn 网络模型，对图像进行分类，以检测胸部 X 光片中的肺结核。
问题在于，在训练时，指标似乎进展顺利。但在评估时却发现了很大的差异。
首先使用此方法使用验证数据生成器评估模型。
## 模型评估
损失、准确度、精确度、召回率、auc = model.evaluate(valid_generator)
print(f&#39;损失: {loss}, 准确度: {accuracy}, 精度: { precision}, 召回率: {recall}, AUC: {auc}&#39;)

它给了我以下结果：
38/38 [================================] - 5s 128ms/步 - 损耗：0.1684 - 准确度：0.9339 - 精确度：0.9978 - 召回率：0.8515 - auc：0.9952
损失：0.16840478777885437，准确度：0.9339389204978943，精度：0.9977973699569702，召回率：0.8515037298202515，AUC：0.9952080845832825

还可以通过以下代码使用 sklearn.metrics 评估模型：
从sklearn.metrics导入classification_report，confusion_matrix
将 numpy 导入为 np
导入 sklearn.metrics

##获取验证数据集的预测
valid_generator.reset()
Y_pred = model.predict（valid_generator，steps=len（valid_generator），verbose=1）
Y_pred = np.round(Y_pred)

##将真实标签转换为数组格式
Y_true = valid_generator.classes

print(&quot;分类报告：\n&quot;,classification_report(Y_true, Y_pred))

# 混淆矩阵
conf_mat = 混淆矩阵(Y_true, Y_pred)
print(&quot;混淆矩阵:\n&quot;, conf_mat)

它给了我这个结果：
38/38 [================================] - 5s 130ms/步
分类报告：
               精确召回率 f1-score 支持

           0 0.57 0.64 0.60 679
           1 0.46 0.39 0.42 532

    精度 0.53 1211
   宏观平均 0.51 0.51 0.51 1211
加权平均值 0.52 0.53 0.52 1211

混淆矩阵：
 [[432247]
 [325207]]

显然这些不同的评估方法的结果存在差异，哪一个是正确的？
按如下方式编译和训练我的模型：
&lt;前&gt;&lt;代码&gt;#InceptionV3
base_model = InceptionV3(权重=&#39;imagenet&#39;, include_top=False, input_shape=(299, 299, 3))
x = 基础模型.输出
x = GlobalAveragePooling2D()(x)
x = 密集（1024，激活=&#39;relu&#39;）（x）
预测=密集（1，激活=&#39;sigmoid&#39;）（x）

模型 = 模型（输入=base_model.输入，输出=预测）

对于 base_model.layers 中的图层：
    可训练层 = False

model.compile(优化器=Adam(learning_rate=0.0001),
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确率&#39;, tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()])

历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    验证数据=有效生成器，
    valid_steps=valid_generator.samples // valid_generator.batch_size,
    纪元=50
）

应该记住，我只对 2 个类别进行分类。

希望您能帮我解决这个疑惑。提前致谢。
能够知道要使用哪些评估指标以及哪些是正确的。]]></description>
      <guid>https://stackoverflow.com/questions/78509105/discrepancy-between-keras-metrics-and-sklearn-metrics</guid>
      <pubDate>Mon, 20 May 2024 23:24:26 GMT</pubDate>
    </item>
    <item>
      <title>探索医学影像中血癌和结核病检测的 AI 解决方案 [关闭]</title>
      <link>https://stackoverflow.com/questions/78507838/exploring-ai-solutions-for-blood-cancer-and-tb-detection-in-medical-imaging</link>
      <description><![CDATA[我正在研究我的最后一年项目 (FYP)，并且可以使用一些建议来为其选择最佳的人工智能系统。我的项目涉及以下任务之一：
血癌检测：
数据：血液样本的显微图像。
目标：利用图像分析准确检测不同类型的血癌。
结核病 (TB) 检测：
数据：X 射线图像。
目标：开发一种可靠的系统，通过胸部 X 光检查检测结核病。
鉴于这些任务，我需要一个能够有效处理医学图像分析的人工智能系统。以下是我正在考虑的一些具体事项：
预训练模型：是否有任何预训练模型或框架特别适合这些领域的医学图像分析？
框架：在 TensorFlow 和 PyTorch（或任何其他框架）之间，哪一个为处理医学图像提供更好的支持和工具？
性能：关于不同的人工智能系统如何专门用于使用 X 射线进行血癌检测或结核病检测，有什么见解吗？
易于使用：由于这是我最后一年的项目，因此一个相对易于实施且拥有良好社区支持的系统将会非常有帮助。
资源：对于有助于开发这些系统的数据集、库或其他工具有什么建议吗？
如果您能分享任何意见、建议或经验，我将不胜感激。非常感谢！
我还没有尝试过人工智能方面的任何东西，但我已经对在血癌和结核病领域使用人工智能进行了深入的研究。我渴望从头开始构建自己的人工智能项目，并沉浸在人工智能的世界中。]]></description>
      <guid>https://stackoverflow.com/questions/78507838/exploring-ai-solutions-for-blood-cancer-and-tb-detection-in-medical-imaging</guid>
      <pubDate>Mon, 20 May 2024 16:54:15 GMT</pubDate>
    </item>
    <item>
      <title>OSError：[Errno 95] 操作不支持：</title>
      <link>https://stackoverflow.com/questions/78507703/oserror-errno-95-operation-not-supported</link>
      <description><![CDATA[我将图像数据放入我的google驱动文件中并转动yolo模型，但出现以下错误
OSError：[Errno 95] 不支持操作：&#39;/content/drive/.shortcut-targets-by-id/1PcS8XwYChBkiYMDD3ruAWArX4lmnMPKu/train.cache.npy&#39;

我按照我在chatgpt中告诉的那样更改了如下代码，但它不起作用
cache=True -&gt;缓存=假
]]></description>
      <guid>https://stackoverflow.com/questions/78507703/oserror-errno-95-operation-not-supported</guid>
      <pubDate>Mon, 20 May 2024 16:19:19 GMT</pubDate>
    </item>
    <item>
      <title>sklearn PolynomialFeatures：如果 LinearRegression 生成 y 截距，是否需要偏差</title>
      <link>https://stackoverflow.com/questions/78507382/sklearn-polynomialfeatures-is-the-bias-required-if-linearregression-generates-a</link>
      <description><![CDATA[我是机器学习的新手，因此我一直在尝试一些模型，试图获得更好的理解。
当我创建特征矩阵时：
X_Poly3（X_Poly3 = 多项式特征（3））

其中 X 是 2 列矩阵，生成的 X_Poly3 包含 10 列：
X1、X2、X1^2、X1.X2、X2^2、X1^3、X1^2.X2、X2^2.X1、X2^3 加上“偏差” 1 列。
当我将 LinearRegression() 拟合到该矩阵时，我最终得到 10 个系数加上 y 截距变量。
我认为 1 的偏差列将充当乘数来创建 y 截距，但如果 LinearRegression 创建 y 截距作为标准，是否需要偏差列？
我创建了一个多项式线性回归模型，但最终得到了看起来与 y 截距相关的 2 个变量。
将 numpy 导入为 np
从 sklearn.preprocessing 导入多项式特征

X = np.arange(6).reshape(3, 2)

poly = 多项式特征(3)
X_Poly3 = poly.fit_transform(X)

从 sklearn. Linear_model 导入 LinearRegression
y_train = np.arange(3).reshape(3, 1)

回归器=线性回归()
regressor.fit(X_Poly3, y_train)

print(regressor.intercept_)
打印（回归器.coef_）
]]></description>
      <guid>https://stackoverflow.com/questions/78507382/sklearn-polynomialfeatures-is-the-bias-required-if-linearregression-generates-a</guid>
      <pubDate>Mon, 20 May 2024 15:10:48 GMT</pubDate>
    </item>
    <item>
      <title>我在数据集上运行了多项式多元回归模型。该模型给出负 r2 值以及正 r2 [关闭]</title>
      <link>https://stackoverflow.com/questions/78507156/i-ran-a-polynomial-multiple-regression-model-on-a-dataset-the-model-give-negati</link>
      <description><![CDATA[我在只有 98 个点的数据集上运行了多项式多元回归模型。当我在不同的数据子集（训练和测试）上运行模型时。它给了我从负到正的 r2 值。我知道我的数据点数量较少。我想问我是否可以坚持以最高的正r2值运行。另外，如果以后需要运行该模型，如何保存该模型？因为当我关闭 r 窗口并再次运行代码时，我没有得到相同的 r2 值和结果，而是得到不同的最高正 r2。
我在 r 中工作，我也尝试了其他不同的模型，例如随机森林和 SVM。但我发现 PMLR 最好。但我得到的 r2 值不一致。]]></description>
      <guid>https://stackoverflow.com/questions/78507156/i-ran-a-polynomial-multiple-regression-model-on-a-dataset-the-model-give-negati</guid>
      <pubDate>Mon, 20 May 2024 14:23:51 GMT</pubDate>
    </item>
    <item>
      <title>通过 Databricks API 创建存储库时出错，缺少所需权限</title>
      <link>https://stackoverflow.com/questions/78506814/error-creating-repo-via-databricks-api-missing-required-permissions</link>
      <description><![CDATA[我使用服务主体创建从 azure devops 到 Azure Databricks 的存储库
curl --location &#39;{{DatabricksHost}}/api/2.0/repos&#39; 
--header &#39;授权：{{DATABRICKS_TOKEN}}&#39; 
--header &#39;内容类型：application/json&#39; 
--header &#39;X-Databricks-Azure-SP-管理令牌：{{AAD_TOKEN}}&#39; 
--header &#39;X-Databricks-Azure-Workspace-Resource-Id: /subscriptions/{{SUB}}resourceGroups/{{RG}}/providers/Microsoft.Databricks/workspaces/{{WORKSPACE}}&#39; 
 - 数据 &#39;{
“url”：“https://dev.azure.com/URL/ORG/_git/REPO”，
“提供商”：“azureDevOpsServices”，
“路径”：“/Repos”，
“sparse_checkout”：{
“模式”：[
“父文件夹/子文件夹”
]
}
}&#39;
&lt;小时/&gt;
我用来获取令牌的命令：

Databricks_token：az account get-access-token --scope 499b84ac-1321-427f-aa17-267ca6975798/.default --query &quot;accessToken&quot; --输出tsv

AAD_TOKEN：az account get-access-token --resource  https://management.core.windows.net/ --query“accessToken” -o tsv


我收到此错误：
在 ID 为“0”的节点上缺少所需的权限 [查看]

或者有时我收到错误
“Git 提供程序凭据无效。转到用户设置&gt; Git 集成可确保：\n1.您已输入带有 Git 提供商凭据的用户名。\n2.您已使用您的凭据选择了正确的 Git 提供程序。\n3.您的个人访问令牌或应用密码具有正确的存储库访问权限。\n4.您的个人访问令牌尚未过期。\n5.如果您的 Git 提供商启用了 SSO，请务必授权您的令牌。””

我之前确实成功创建了 git 凭据，我的服务主体对订阅有贡献者，并且在 Databricks 工作区中拥有管理员和用户的权限]]></description>
      <guid>https://stackoverflow.com/questions/78506814/error-creating-repo-via-databricks-api-missing-required-permissions</guid>
      <pubDate>Mon, 20 May 2024 13:11:31 GMT</pubDate>
    </item>
    <item>
      <title>k-最近分类概率估计问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78506193/k-nearest-classification-probability-estimation-problem</link>
      <description><![CDATA[已知邻居连接方法对噪声敏感。我们将考虑训练样本的一个属性和两个对象的二元分类模型问题：（x_1 = 0.2），（x_2 = 0.7）。第一个对象属于第一类，第二个对象属于第二类。
让我们向对象添加一个新的噪声特征，均匀分布在段 ([0, 1]) 上。现在每个对象都由两个侧面来描述。需要使用具有欧几里德度量的最近邻方法对该空间中的新对象（ u = (0, 0) ）进行分类。
添加第二个噪声对象后，它比第一个更接近对象（u）的概率是多少？
如果可能的话，我想了解使用哪种方法来求解以及应该使用哪些概率和机器学习公式]]></description>
      <guid>https://stackoverflow.com/questions/78506193/k-nearest-classification-probability-estimation-problem</guid>
      <pubDate>Mon, 20 May 2024 10:54:59 GMT</pubDate>
    </item>
    <item>
      <title>SpaCy transformer NER 训练——transformer 上零损失，未经训练</title>
      <link>https://stackoverflow.com/questions/78506114/spacy-transformer-ner-training-zero-loss-on-transformer-not-trained</link>
      <description><![CDATA[我正在使用 [&#39;transformer&#39;, &#39;ner&#39;] 组件训练 SpaCy 管道，ner 训练得很好，但 Transformer 的损失为 0，并且我假设它没有进行训练。 
这是我的配置：
&lt;代码&gt;[路径]
矢量=“en_core_web_trf”
init_tok2vec = null
火车=“/home/sxdadmin/spacy/input/train.spacy”
dev =“/home/sxdadmin/spacy/input/dev.spacy”

[系统]
gpu_allocator =“pytorch”；
种子 = 0

[自然语言处理]
lang =“en”；
pipeline = [“变压器”, “ner”]
批量大小 = 512
禁用 = []
创建之前 = null
创建后=空
after_pipeline_creation = null
tokenizer = {“@tokenizers”：“spacy.Tokenizer.v1”}
向量 = {“@vectors”：“spacy.Vectors.v1”}

#################################################### ####################
[成分]
#################################################### ####################

[组件.变压器]
工厂=“变压器”
最大批次项 = 4096

[组件.变压器.模型]
@architectures = “spacy-transformers.TransformerModel.v1”
name = “bert-base-cased”；
tokenizer_config = {“use_fast”：true}

[组件.transformer.model.get_spans]
@span_getters = “spacy-transformers.doc_spans.v1”

[components.transformer.set_extra_annotations]
@annotation_setters = “spacy-transformers.null_annotation_setter.v1”

#################################################### ####################

[组件.ner]
工厂=“ner”
不正确的跨度键 = null
移动=空
计分器 = {“@scorers”：“spacy.ner_scorer.v1”}
update_with_oracle_cut_size = 100

[组件.ner.模型]
@architectures = “spacy.TransitionBasedParser.v2”
state_type =“ner”；
extra_state_tokens = false
隐藏宽度 = 64
最大输出件数 = 2
use_upper = true
nO = 空

#################################################### ####################
[语料库]
#################################################### ####################

[语料库.train]
@readers =“spacy.Corpus.v1”
路径 = ${paths.train}
最大长度 = 3000
gold_preproc = false
限制 = 0
增强器 = null

[语料库.dev]
@readers =“spacy.Corpus.v1”
路径 = ${paths.dev}
最大长度 = 3000
gold_preproc = false
限制 = 0
增强器 = null

#################################################### ####################
[训练]
#################################################### ####################

dev_corpus = “corpora.dev”;
train_corpus = “语料库.train”;
种子 = 0
gpu_allocator =“pytorch”；
辍学率 = 0.1
累积梯度= 1
耐心=1600
最大纪元 = 0
最大步数 = 20000
评估频率 = 200
冻结组件 = []
注释组件 = []
before_to_disk = null
更新前=空

#################################################### ####################

[训练.batcher]
@batchers = “spacy.batch_by_words.v1”
丢弃尺寸过大= false
公差 = 0.2
获取长度=空

[训练.batcher.大小]
@schedules =“compounding.v1”；
开始 = 64
停止= 512
化合物 = 1.001
t = 0.0

#################################################### ####################

[训练记录器]
@loggers = “spacy.ConsoleLogger.v1”
进度条=假

[训练.优化器]
@optimizers =“Adam.v1”；
贝塔1 = 0.9
贝塔2 = 0.999
L2_is_weight_decay = true
L2 = 0.01
梯度剪辑 = 1.0
使用平均值 = false
每股收益 = 0.00000001
学习率 = 0.001

[训练.score_weights]
ents_f = 1.0
ents_p = 0.0
ents_r = 0.0
ents_per_type = null

#################################################### ####################
[预训练]
#################################################### ####################

[初始化]
矢量=“en_core_web_lg”
init_tok2vec = null
词汇数据=空
查找=空
before_init = null
after_init = null

[初始化.组件]
[初始化.组件.变压器]
[初始化.tokenizer]

和输出：

所有警告均得到满足，著名的 Bert 的 max_length 512 个 token 就是通过文本分割实现的。数据之前已在 [tok2vec, ner] 设置上进行了测试。
请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78506114/spacy-transformer-ner-training-zero-loss-on-transformer-not-trained</guid>
      <pubDate>Mon, 20 May 2024 10:39:58 GMT</pubDate>
    </item>
    <item>
      <title>文本到 Openpose 和奇怪的 RNN 错误</title>
      <link>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</link>
      <description><![CDATA[我想创建一个人工智能，它可以根据文本描述生成 openpose，例如，如果输入“a man running”输出将类似于我提供的图像有没有为我推荐的模型架构？
我的数据状况是

canvas_width：900px
canvas_height：300px
帧数：5（5 人）

预期输出
我尝试训练 RNN 来完成此任务，并使用句子转换器来嵌入文本，然后传递给 RNN，损失如下图所示
from Sentence_transformers import SentenceTransformer
Sentence_model = SentenceTransformer(“all-MiniLM-L6-v2”)
text = “一个男人在奔跑”
text_input = torch.tensor(sentence_model.encode(text), dtype=torch.float)

损失图像，num_layers=3
我的 RNN 设置
&lt;前&gt;&lt;代码&gt;embedding_dim = 384
隐藏暗淡 = 512
层数 = 3
输出暗度 = 180
纪元数 = 100
学习率 = 0.001
rnn_model = RNN(embedding_dim,hidden_​​dim,num_layers,output_dim)

但问题是无论我输入什么，输出每次都是一样的！但是当我尝试将 num_layers 更改为 1 并保持其他设置相同时，如下所示
&lt;前&gt;&lt;代码&gt;embedding_dim = 384
隐藏暗淡 = 512
层数 = 1
输出暗度 = 180
纪元数 = 100
学习率 = 0.001
rnn_model = RNN(embedding_dim,hidden_​​dim,num_layers,output_dim)

损失现在看起来像这样
损失图像 num_layers=1
现在问题消失了！！
我还尝试检查“每次输出都相同”的原因问题我检查了数据加载器和其他代码，但没有发现问题，只有 num_layers=3 导致问题 num_layers=1 修复了它
这是我的训练循环
标准 = nn.MSELoss()
优化器 = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)

trainingEpoch_loss = []
validepoch_loss = []

对于范围内的纪元（num_epochs）：
步骤损失=[]
rnn_model.train()
对于 idx，枚举中的 train_inputs(train_dataloader)：
优化器.zero_grad()
输出 = rnn_model(torch.unsqueeze(train_inputs[&#39;text&#39;], dim=0))
训练损失 = 标准（输出，train_inputs[&#39;poses&#39;]）
Training_loss.backward()
优化器.step()
step_loss.append(training_loss.item())

if (idx+1) % 1 == 0: print (f&#39;Epoch [{epoch+1}/{num_epochs}], 步骤 [{idx+1}/{len(train_dataloader)}], 损失: {training_loss.项目():.4f}&#39;)
TrainingEpoch_loss.append(np.array(step_loss).mean())

rnn_model.eval()
对于 idx，枚举中的 val_inputs(val_dataloader)：
验证步骤损失 = []
输出 = rnn_model(torch.unsqueeze(val_inputs[&#39;text&#39;], dim=0))
val_loss = 标准(输出, val_inputs[&#39;poses&#39;])
validStep_loss.append(val_loss.item())
validationEpoch_loss.append(np.array(validationStep_loss).mean())

这是我的推论
text = “一个男人正在奔跑”
processed_text = torch.tensor(sentence_model.encode(text), dtype=torch.float)
output_poses = rnn_model(processed_text.unsqueeze(0))
print(output_poses.shape) #shape=(1, 180) 1 人是 36 （1 人的原始数据是 54，但我改为 36，因为我只想要 x 和 y 而不是 z，所以剪掉 z 轴）并且有5 人所以 5*36 = 180

我的问题是

除了 RNN 之外，还有适合此任务的任何模型架构推荐吗？
为什么无论我输入什么，每次 num_layers=3 时输出都是相同的，我很困惑，因为如果模型给出相同的输出，损失不会下降，对吗？这意味着它在推理阶段给出相同的输出

预期答案

最适合我的任务的模型架构，任何与我相关的论文或 github 存储库都将受到赞赏
回答为什么当 num_layers=3 时，无论我输入什么，每次输出都是相同的
]]></description>
      <guid>https://stackoverflow.com/questions/78503423/text-to-openpose-and-weird-rnn-bugs</guid>
      <pubDate>Sun, 19 May 2024 17:37:20 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker 不认可训练作业来启动推理</title>
      <link>https://stackoverflow.com/questions/78497836/sagemaker-does-not-recognize-training-job-to-launch-inference</link>
      <description><![CDATA[我成功在 sagemaker 中启动了培训工作。但是，当我尝试使用该模型进行推理时，sagemaker 无法找到该模型。
导入 sagemaker
从 sagemaker.transformer 导入 Transformer
从 sagemaker.model 导入模型

# 设置会话参数
sagemaker_session = sagemaker.Session()
角色 = sagemaker.get_execution_role()

# 输入路径
model_s3_path = &#39;s3://sagemaker-us-west-1-6584743930/pytorch-training-2024-05-16-15-18-34-042/source/sourcedir.tar.gz&#39;
input_s3_path = &#39;s3://some-bucket/inference/beauty_annotations_simple_transformer.csv&#39;
output_s3_path = &#39;s3://some-bucket/inference/ouput/&#39;

# 定义实例类型
instance_type = &#39;ml.m5.large&#39;

＃ 模型
模型 = 模型（
    model_data=model_s3_path,
    角色=角色，
    Framework_version=&#39;2.0&#39;,
    Entry_point=&#39;推理.py&#39;,
    source_dir=&#39;./source_dir&#39;
）

# 变压器
变压器 = 变压器（
    model_name=模型.name,
    实例计数=1，
    实例类型=实例类型，
    输出路径=输出_s3_路径，
    assemble_with=&#39;Line&#39;, # 输出组装的方法
    Accept=&#39;application/jsonlines&#39;, # 输出格式
）

# 启动批量转换作业
变压器.变换(
    数据=input_s3_path，
    content_type=&#39;text/csv&#39;, # 输入格式
    split_type=&#39;Line&#39;, # 输出分割方式
）

# 作业等待
变压器.wait()

错误
&lt;块引用&gt;
ValueError：无法获取模型信息
pytorch-training-2024-05-16-15-18-34-042。请确保型号
存在。本地实例类型需要本地创建的模型。
]]></description>
      <guid>https://stackoverflow.com/questions/78497836/sagemaker-does-not-recognize-training-job-to-launch-inference</guid>
      <pubDate>Fri, 17 May 2024 20:29:40 GMT</pubDate>
    </item>
    <item>
      <title>LLM Studio 无法下载模型并出现错误：无法获取本地颁发者证书</title>
      <link>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</link>
      <description><![CDATA[在LLM studio中，当我尝试下载任何模型时，我遇到以下错误：
下载失败：无法获取本地颁发者证书
]]></description>
      <guid>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</guid>
      <pubDate>Wed, 24 Apr 2024 16:03:26 GMT</pubDate>
    </item>
    <item>
      <title>验证错误：无法实例化 GPT4AllEmbeddings 模型</title>
      <link>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</link>
      <description><![CDATA[我在尝试创建 GPT4AllEmbeddings 实例时遇到问题。但是我不断收到以下错误
单元格 In[15]，第 1 行
----&gt; 1 vectorstore = Chroma.from_documents(文档 = 分割, 嵌入 = GPT4AllEmbeddings())
      2 检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
      3检索文档=检索器.get_relevant_documents（“你是什么？”）

文件 ~\anaconda3\Lib\site-packages\pydantic\main.py:341，在 pydantic.main.BaseModel.__init__() 中

ValidationError：GPT4AllEmbeddings 出现 1 个验证错误
__根__
  无法实例化模型（type=value_error）

这是相关的代码片段
vectorstore = Chroma.from_documents(documents = splits, embeddings = GPT4AllEmbeddings())
检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
retrieved_docs =retrieve.get_relevant_documents(“什么是Young Decade？”)
打印（len（检索文档））
打印（retrieve_docs[0].page_content）

如何解决这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</guid>
      <pubDate>Wed, 13 Mar 2024 09:36:07 GMT</pubDate>
    </item>
    <item>
      <title>测试和训练数据具有不同的城市，如何查找差异并在测试和训练数据的两列上使用相同的编码系统进行编码</title>
      <link>https://stackoverflow.com/questions/77351990/test-and-train-data-have-different-cities-how-to-find-and-differences-and-encod</link>
      <description><![CDATA[我有一个测试集和训练集。他们有一个城市列，其中一个（火车）有 290 个唯一的，测试有 30 个。我希望有重叠，即伦敦、布里斯托尔都在两组中，但格洛斯特可能在一组上，而不是另一组上。
我还想将这些城市编码为两个集合之间相关的数值，因此伦敦应该在测试和训练中编码为 1。
我查看了 LabelEncoder，但不知道如何让两个集合对它们共享的城市使用相同的编号。
LabelEncoder 工作正常，但两组之间没有相关性。
之前：
df_train[&#39;城市&#39;]
“伦敦”、“布里斯托尔”、“巴黎”、“罗马”、“伦敦”、“伍斯特”

df_test[&#39;城市&#39;]
“巴黎”、“罗马”、“罗马”、“伦敦”、“格洛斯特”

输出：
df_train[&#39;城市&#39;]
1 2 3 4 1 6

df_test[&#39;城市&#39;]
3 4 4 1 7
]]></description>
      <guid>https://stackoverflow.com/questions/77351990/test-and-train-data-have-different-cities-how-to-find-and-differences-and-encod</guid>
      <pubDate>Tue, 24 Oct 2023 12:19:41 GMT</pubDate>
    </item>
    </channel>
</rss>