<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 29 Dec 2024 06:22:20 GMT</lastBuildDate>
    <item>
      <title>如何防止 C# SoftMax 实现中出现溢出？</title>
      <link>https://stackoverflow.com/questions/79314811/how-do-i-prevent-overflows-in-my-c-sharp-softmax-implementation</link>
      <description><![CDATA[为了从“第一原理”的角度更好地理解机器学习，我正在实现自己的 ML 相关函数。目前，我正在尝试实现 SoftMax：
IEnumerable&lt;double&gt; SoftMax(IEnumerable&lt;double&gt; vector)
{
var exps = vector.Select(v =&gt; Math.Exp(v));
var sumExps = exps.Sum();
return exps.Select(exp =&gt; exp / sumExps);
}

如果我正确理解了 SoftMax，如果我将此函数的结果相加，即 SoftMax(vector).Sum()，则输出应始终为 1。
然而，在几乎所有情况下，这都会返回一个略大于或略小于 1 的值。通常，类似于 1.0568102998178908 或 0.9758570985704772。
我听说这种情况并不罕见（基本上是溢出问题），可以通过从输入到 Math.Exp() 的值中减去输入的最大元素来解决。所以我根据建议想出了这个实现：
IEnumerable&lt;double&gt; SoftMax(IEnumerable&lt;double&gt; vector)
{
var maxVal = vector.Max();
var exps = vector.Select(v =&gt; Math.Exp(v - maxVal));
var sumExps = exps.Sum();
return exps.Select(exp =&gt; exp / sumExps);
}

在测试我的实现时，我传入了一个随机的双精度数集合，如下所示：
IEnumerable&lt;double&gt; vector = Enumerable.Range(0, 100).Select(n =&gt; new Random().NextDouble());
var softMaxVec = SoftMax(vector);
Console.WriteLine(softMaxVec.Sum());

但是我改进后的实现仍然给我带来了同样的问题。我做错了什么？还是我误解了 SoftMax 的工作原理？]]></description>
      <guid>https://stackoverflow.com/questions/79314811/how-do-i-prevent-overflows-in-my-c-sharp-softmax-implementation</guid>
      <pubDate>Sun, 29 Dec 2024 01:01:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的代码输出“audio_features 为空。跳过 LSTM 准备。”</title>
      <link>https://stackoverflow.com/questions/79314222/why-is-my-code-outputting-audio-features-is-empty-skipping-lstm-preparation</link>
      <description><![CDATA[我尝试将 librispeech 数据集导入我的代码，然后使用它进行训练，但我一直收到：

audio_features 为空。跳过 LSTM 准备。

librispeech 文件夹包含顶部的 .txt 和位于 .txt 文件下方的 .flac 文件。
import librosa
import os
import numpy as np

def load_librispeech_dataset(directory):
audio_files = []
labels = []
for root, _, files in os.walk(directory):
for file in files:
if file.endswith(&#39;.flac&#39;):
file_path = os.path.join(root, file)
try:
audio, sr = librosa.load(file_path, sr=None)
mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)
audio_files.append(np.mean(mfccs.T, axis=0))

# 假设标签（转录）位于相应的文本文件中
label_path = file_path.replace(&#39;.flac&#39;, &#39;.txt&#39;)
with open(label_path, &#39;r&#39;) as label_file:
label = label_file.read().strip()
labels.append(label)
except Exception as e:
print(f&quot;Error processing {file_path}: {e}&quot;)

return np.array(audio_files), labels # 缩进已更正：处理所有文件后返回

dataset_directory = &#39;C:\\Users\\rowro\\Downloads\\train-clean-100\\LibriSpeech\\train-clean-100&#39;
audio_features, transcriptions = load_librispeech_dataset(dataset_directory)
import tensorflow as tf
从 tensorflow.keras.models 导入 Sequential
从 tensorflow.keras.layers 导入 Dense、LSTM、Dropout
从 tensorflow.keras.utils 导入 to_categorical # 导入 to_categorical

如果 audio_features.size == 0:
print(&quot;audio_features 为空。跳过 LSTM 准备。）
否则：

audio_features = audio_features.reshape(audio_features.shape[0], 1, audio_features.shape[1]) # 重塑 LSTM

词汇 = sorted(list(set(transcriptions)))

transcription_to_index = {transcription: index for index, transcription in enumerate(vocabulary)}

indexed_transcriptions = [transcription_to_index[transcription] for transcription in transcriptions]

one_hot_transcriptions = to_categorical(indexed_transcriptions, num_classes=len(vocabulary))

dataset = tf.data.Dataset.from_tensor_slices((audio_features, one_hot_transcriptions))

epochs = 50
]]></description>
      <guid>https://stackoverflow.com/questions/79314222/why-is-my-code-outputting-audio-features-is-empty-skipping-lstm-preparation</guid>
      <pubDate>Sat, 28 Dec 2024 17:06:32 GMT</pubDate>
    </item>
    <item>
      <title>*准确*从复杂的 PDF 中提取信息 - 企业所得税申报表 [关闭]</title>
      <link>https://stackoverflow.com/questions/79314143/accurate-extraction-of-information-from-complex-pdfs-corporate-income-tax-re</link>
      <description><![CDATA[寻找如何准确地从复杂的 PDF 文件中提取数据的想法，特别是公司纳税申报单中包含的规定表格/附表。
以下是美国公司纳税申报单附表 L 部分的屏幕截图（第 1 项）、结果输出和我的代码（第 2 项）以及我的代码摘录（第 3 项）。
结果很差 - 错过了整列，甚至没有识别表格下半部分的“负债和股东权益”。
美国国税局（和其他税务机关）发布了开发人员在创建税务合规软件应用程序时使用的样式表。请参阅下面的第 4 项。可以利用这些吗？ AI/ML??

屏幕截图 - 美国公司纳税申报表

输出

代码摘录：


使用的软件包：
&quot;pymupdf&quot;，# 用于 PDF 解析
&quot;pdfplumber&quot;，# 用于表格提取
&quot;pytesseract&quot;，# 用于 OCR
&quot;Pillow&quot;，# 用于图像处理
&quot;pandas&quot;，# 用于数据处理
# 步骤 1：从 PDF 中提取文本和图像
def extract_text_and_images(pdf_path):
doc = fitz.open(pdf_path)
text_blocks = []
images = []
for page_num, page in enumerate(doc):
text_blocks.extend(page.get_text(&quot;blocks&quot;))
for img_index, img in enumerate(page.get_images(full=True)):
xref = img[0]
base_image = doc.extract_image(xref)
image_bytes = base_image[&quot;image&quot;]
image = Image.open(io.BytesIO(image_bytes))
images.append((page_num, img_index, image))
doc.close()
return text_blocks, images

# 步骤 2：对嵌入或扫描的图像进行 OCR
def perform_ocr(images):
ocr_results = []
for page_num, img_index, image in images:
text = pytesseract.image_to_string(image, lang=&quot;eng&quot;)
ocr_results.append({&quot;page&quot;: page_num, &quot;index&quot;: img_index, &quot;text&quot;: text})
return ocr_results

# 步骤 3：使用 pdfplumber 提取表格
def extract_tables(pdf_path):
tables = []
with pdfplumber.open(pdf_path) as pdf:
for page in pdf.pages:
page_tables = page.extract_tables()
tables.extend(page_tables)
return tables

# 步骤 4：解析提取的数据并清理
def parse_data(text_blocks, ocr_results, tables):
extracted_text = &quot; &quot;.join([block[4] for block in text_blocks])
for ocr_result in ocr_results:
extracted_text += &quot; &quot; + ocr_result[&quot;text&quot;]
labels_and_values = re.findall(r&#39;([A-Za-z\s]+)\s*([\d,]+(?:\.\d+)?)&#39;, extracted_text)
table_data = [pd.DataFrame(table) for table in tables]
return labels_and_values, table_data

# 步骤 5：保存并验证结果
def save_results(labels_and_values, table_data):
labels_df = pd.DataFrame(labels_and_values, columns=[&quot;Label&quot;, &quot;Value&quot;])
labels_df.to_csv(&quot;output/extracted_labels.csv&quot;, index=False)
for idx, table in enumerate(table_data):
table.to_csv(f&quot;output/table_{idx}.csv&quot;, index=False)


** 附表 L 的 IRS xsl 摘录**

IRS 860875_IRS990ScheduleL.xsl 的屏幕截图]]></description>
      <guid>https://stackoverflow.com/questions/79314143/accurate-extraction-of-information-from-complex-pdfs-corporate-income-tax-re</guid>
      <pubDate>Sat, 28 Dec 2024 16:24:52 GMT</pubDate>
    </item>
    <item>
      <title>MMPoseInferrer 输出</title>
      <link>https://stackoverflow.com/questions/79314096/mmposeinferrer-output</link>
      <description><![CDATA[MMPoseInferrer 推理输出问题：有些预训练模型可以用来估计 3D 人体关键点，比如 Motionbert on H36m 模型。那么模型输出的是什么形式的坐标-&gt; 是归一化的坐标吗，还是没有，或者用什么方法归一化。我在文档中没有找到相关内容，有提到吗？以下面的关键点输出为例：
[
[
-0.0,
0.0,
0.7555395364761353
],
[
0.08776745945215225,
0.014697499573230743,
0.7559494376182556
],
[
0.06877514719 963074,
0.13456907868385315,
0.37831956148147583
],
[
0.06537707149982452,
0.2487216591835022,
0.00843822956085205
],
[
-0.08800487965345383,
- 0.010408030822873116,
0.7716540098190308
],
[
-0.09889209270477295,
0.09682958573102951,
0.38313865661621094
],
[
-0.09353649616241455,
0.19728 45494747162,
0.0
],
[
-0.0012864989694207907,
-0.03291667625308037,
0.9549297094345093
],
[
9.643554949434474e-05,
-0.10887715220451355,
1.14922 55926132202
],
[
0.015108276158571243,
-0.15547998249530792,
1.2797507047653198
],
[
0.020197754725813866,
-0.15980219841003418,
1.316202998161 316
],
[
-0.12787023186683655,
-0.11175356805324554,
1.135298252105713
],
[
-0.17331457138061523,
0.027008552104234695,
0.9562594890594482
],
[
-0.17505957186222076,
-0.04972240328788757,
0.7927475571632385
],
[
0.13157495856285095,
-0.07964363694190979,
1.1331491470336914
],
[
0.159474 84970092773,
0.08672922104597092,
0.9380651712417603
],
[
0.1455722600221634,
0.029887964949011803,
0.779397189617157
]
]

我尝试将其反规范化为正常的世界坐标，但仍然出现了一些问题]]></description>
      <guid>https://stackoverflow.com/questions/79314096/mmposeinferrer-output</guid>
      <pubDate>Sat, 28 Dec 2024 16:02:56 GMT</pubDate>
    </item>
    <item>
      <title>确定在提供的视频中同一辆车被拍摄的次数</title>
      <link>https://stackoverflow.com/questions/79313854/identify-how-many-times-same-vehicle-was-captured-in-the-provided-video</link>
      <description><![CDATA[正在进行视频分析作业，我需要捕捉在给定视频中同一车辆被拍摄的次数。
到目前为止，使用 YOLO11 能够识别汽车、自行车、公共汽车和卡车等车辆。相应地，在视频帧中绘制车辆的矩形。
我不明白如何用一些识别码标记车辆。这样，当同一辆车出现在视频帧中时，我可以增加该车辆的数量。
添加我尝试过的代码
from ultralytics import YOLO
import cv2
from enum import Enum

class DetectionType(Enum):
CAR = 2
MOTORCYCLE = 3
BUS = 5
TRUCK = 6

coco_model = YOLO(&#39;yolo11n.pt&#39;)
cap = cv2.VideoCapture(&#39;testVideo.mp4&#39;)

vehicles = [
DetectionType.CAR.value, 
DetectionType.MOTORCYCLE.value, 
DetectionType.BUS.value,
DetectionType.TRUCK.value
]

ret = True

while ret:
ret, frame = cap.read()

if ret:
#detect vehicle
detections_model = coco_model(frame)[0]

for detection in detections_model.boxes.data.tolist():
x1, y1, x2, y2, score, class_id = detection

if int(class_id) in vehicles:
x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

# 在窗口中显示帧 
cv2.imshow(&#39;video&#39;, frame)

if cv2.waitKey(33) == 27:
break

cap.release()
cv2.destroyAllWindows() 

任何建议或代码片段都会帮助我完成这项作业。]]></description>
      <guid>https://stackoverflow.com/questions/79313854/identify-how-many-times-same-vehicle-was-captured-in-the-provided-video</guid>
      <pubDate>Sat, 28 Dec 2024 13:29:54 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型勉强优化了截距b</title>
      <link>https://stackoverflow.com/questions/79312660/linear-regression-model-barely-optimizes-the-intercept-b</link>
      <description><![CDATA[我从头开始编写了一个线性回归模型。我使用“残差平方和”作为梯度下降的损失函数。为了进行测试，我使用线性数据 (y=x)
运行算法时，截距 b 几乎没有变化。因此斜率 m 计算不正确。
%matplotlib qt5 
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
y = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12345)

class LinearRegression():
def __init__(self):
self.X = None
self.y = None

def ssr(self, m, b):
sum = 0
for i in range(len(self.X)):
sum += (self.y[i] - (m * self.X[i] + b) ) ** 2

return sum

def ssr_gradient(self, m, b):
sum_m = 0
sum_b = 0
n = len(self.X)
for i in range(n):
error = self.y[i] - (m * self.X[i] + b)
derivative_m = -(2/n) * self.X[i] * error # 相对于 m 的导数
derivative_b = -(2/n) * error # 相对于 m 的导数b
sum_m += derived_m
sum_b += derived_b

return sum_m, sum_b

def fit(self, X, y, m, b): # 梯度下降
self.X = X
self.y = y

M, B = np.meshgrid(np.arange(-10, 10, 0.1), np.arange(-10, 10, 0.1))
SSR = np.zeros_like(M)
for i in range(M.shape[0]):
for j in range(M.shape[1]):
SSR[i, j] = self.ssr(M[i, j], B[i, j])

fig, axis = plt.subplots(1, 2, figsize=(12, 6))
gd_model = fig.add_subplot(121,投影=“3d”，computed_zorder=False)
lin_reg_model = axis[1] 

current_pos = (m, b, self.ssr(m, b))
learning_rate = 0.001
min_step_size = 0.001
max_steps = 1000
current_steps = 0

while(current_steps &lt; max_steps):
M_derivative, B_derivative = self.ssr_gradient(current_pos[0], current_pos[1])
M_step_size, B_step_size = M_derivative * learning_rate, B_derivative * learning_rate

if abs(M_step_size) &lt; min_step_size 或 abs(B_step_size) &lt; min_step_size:
break

M_new, B_new = current_pos[0] - M_step_size, current_pos[1] - B_step_size

current_pos = (M_new, B_new, self.ssr(M_new, B_new))

print(f&quot;参数：m：{current_pos[0]}; b：{current_pos[1]}; SSR：{current_pos[2]}&quot;)

current_steps += 1

x = np.arange(0, 10, 1)
y = current_pos[0] * x + current_pos[1]
lin_reg_model.scatter(X_train, y_train, label=&quot;Train&quot;, s=75, c=&quot;#1f77b4&quot;)
lin_reg_model.plot(x, y)

gd_model.plot_surface(M, B, SSR, cmap=&quot;viridis&quot;, zorder=0)
gd_model.scatter(current_pos[0], current_pos[1], current_pos[2], c=&quot;red&quot;, zorder=1)
gd_model.set_xlabel(&quot;斜率 m&quot;)
gd_model.set_ylabel(&quot;截距 b&quot;)
gd_model.set_zlabel(&quot;残差平方和&quot;)

plt.tight_layout()
plt.pause(0.001)

gd_model.clear()
lin_reg_model.clear()

self.m = current_pos[0]
self.b = current_pos[1]

def predict(self, X_test):
return self.m * X_test + self.b

lin_reg_model = LinearRegression()
lin_reg_model.fit(X_train, y_train, 1, 10)


这是初始值 m=1 和 b=10 的结果：
参数：m：-0.45129949840919587；b：9.50972664859535；SSR：145.06534359577407

显然这不是最佳的，因为我的数据是线性的。因此最佳参数应该是 m=1 和 b=0
但我在代码中找不到问题。该算法根据初始值打印不同的结果，但只要 SSR 函数恰好有一个最小值，它就应该一遍又一遍地打印相同的结果。
我尝试使用不同的学习率，但问题仍然存在。]]></description>
      <guid>https://stackoverflow.com/questions/79312660/linear-regression-model-barely-optimizes-the-intercept-b</guid>
      <pubDate>Fri, 27 Dec 2024 19:40:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多类数据集训练模型来预测工作角色？[关闭]</title>
      <link>https://stackoverflow.com/questions/79312226/how-to-train-a-model-to-predict-job-roles-with-multi-class-dataset</link>
      <description><![CDATA[我正在开展一个项目，根据包含39 个特征和33 个独特工作角色作为目标标签的数据集来预测工作角色。数据集有 20,000 行，包括数值列和分类列。
以下是数据集的摘要：

数值特征 (14)：学术科目（例如操作系统、算法）的百分比、逻辑商评分、参加的黑客马拉松等。
二进制特征 (16)：诸如“可以在系统之前长时间工作吗？”，“自学能力？”等问题。
分类特征 (8)：包括“认证”、“记忆能力”分数”、“感兴趣的职业领域”等。
目标变量：建议的工作角色（例如，“数据库开发人员”、“软件工程师”等）。

问题：
我预处理了数据集并尝试了随机森林、SVM和XGBoost等训练模型，但准确率仍然一直很低（约 3%）。我怀疑我的预处理、模型选择或超参数调整可能存在问题。
预处理管道：
以下是我预处理数据的方法：
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler

def transform_data(df):
X = df.drop(&#39;Suggested Job Role&#39;, axis=1)
y = df[&#39;Suggested Job Role&#39;]

# 特征类型
two_category_features = [&#39;can work long time before system?&#39;, &#39;self-learning capacity?&#39;, 
&#39;Extra-courses did&#39;, &#39;talenttests taken?&#39;, &#39;olympiads&#39;, &#39;Job/Higher学习？&#39;,
&#39;从年长者或长辈那里获取信息&#39;, &#39;对游戏感兴趣&#39;, &#39;期望薪资范围&#39;, 
&#39;处于恋爱关系中？&#39;, &#39;行为温和还是强硬？&#39;, &#39;管理或技术&#39;, 
&#39;薪水/工作&#39;, &#39;努力/聪明的员工&#39;, &#39;曾经在团队中工作过吗？&#39;, &#39;内向&#39;]

categorical_features = [&#39;认证&#39;, &#39;研讨会&#39;, &#39;阅读和写作技能&#39;, 
&#39;记忆能力得分&#39;, &#39;感兴趣的科目&#39;, 
&#39;感兴趣的职业领域&#39;, &#39;想要在哪家公司安顿下来？&#39;, 
&#39;感兴趣的书籍类型&#39;]

numeric_features = [&#39;操作系统中的学术百分比&#39;, &#39;算法中的百分比&#39;, 
&#39;编程概念中的百分比&#39;, &#39;软件工程中的百分比&#39;,
&#39;计算机网络占比&#39;, &#39;电子学科占比&#39;, 
&#39;计算机架构占比&#39;, &#39;数学占比&#39;, 
&#39;沟通技巧占比&#39;, &#39;逻辑商评分&#39;, 
&#39;黑客马拉松&#39;, &#39;编码技能评分&#39;, &#39;公开演讲要点&#39;, &#39;每天工作时间&#39;]

# 预处理管道
two_category_transformer = Pipeline(steps=[
(&#39;ordinal&#39;, OrdinalEncoder())
])
categorical_transformer = Pipeline(steps=[
(&#39;onehot&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))
])
numeric_transformer = Pipeline(steps=[
(&#39;minmax&#39;, MinMaxScaler())
])

# 组合转换
preprocessor = ColumnTransformer(transformers=[
(&#39;two_cat&#39;, two_category_transformer, two_category_features),
(&#39;cat&#39;, categorical_transformer, categorical_features),
(&#39;minmax&#39;, numeric_transformer, numeric_features)
])

formed_X = preprocessor.fit_transform(X)
return formed_X, y

尝试的模型：

随机森林：使用默认参数。
SVM：尝试使用 RBF 内核，默认超参数。
XGBoost：默认参数。

尽管尝试了这些模型，准确率仍然停留在 3% 左右。

问题：

为什么模型在这个数据集上表现不佳？
我应该尝试哪些特定的技术或方法（例如，超参数调整、特征选择、过采样）？
我如何更好地处理目标变量的高基数（33 个独特的工作角色）？
]]></description>
      <guid>https://stackoverflow.com/questions/79312226/how-to-train-a-model-to-predict-job-roles-with-multi-class-dataset</guid>
      <pubDate>Fri, 27 Dec 2024 15:48:34 GMT</pubDate>
    </item>
    <item>
      <title>需要 chromadb 和 transformers 一起使用，但要求有冲突，因为 chromadb 需要 0.20 版本的 tokenizers，而后者需要 0.21 版本</title>
      <link>https://stackoverflow.com/questions/79309306/need-chromadb-transformers-together-but-have-conflicting-requirements-as-chrom</link>
      <description><![CDATA[我必须在一个项目中同时使用 chromadb 和 transformers，但 chromadb 需要 &lt;=0.20.3 版本的 tokenizers，而 transformers 需要 &gt;=0.21 版本的 tokenizers，并且与 chromadb 兼容的旧版本 transformers 需要 rust 编译器，因此这也不是一种选择。
我尝试升级 transformers、tokenizers，也尝试降级 transformers，但都不起作用，而对于所有这些，我都在使用虚拟环境。]]></description>
      <guid>https://stackoverflow.com/questions/79309306/need-chromadb-transformers-together-but-have-conflicting-requirements-as-chrom</guid>
      <pubDate>Thu, 26 Dec 2024 11:03:46 GMT</pubDate>
    </item>
    <item>
      <title>分离图像内的盲文字符</title>
      <link>https://stackoverflow.com/questions/79306951/separation-of-braille-characters-inside-of-an-image</link>
      <description><![CDATA[我正在做一个将盲文转换为文本的项目。我已经编写了从图像中识别盲文点的代码，但我不知道如何将盲文分割成单元格。
这部分是识别图像中的斑点（较小的低质量图像目前不起作用）
import cv2
import numpy as np
from sklearn.cluster import KMeans

# 加载图像
image_path = &quot;braille.jpg&quot;
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# 设置 SimpleBlobDetector
params = cv2.SimpleBlobDetector_Params()

# 按区域过滤（斑点大小）
params.filterByArea = True
params.minArea = 100 # 根据点大小进行调整
params.maxArea = 1000

# 按圆度过滤
params.filterByCircularity = True
params.minCircularity = 0.9 # 调整点的形状

# 按凸度过滤
params.filterByConvexity = False
params.minConvexity = 0.7

# 按惯性过滤（圆度）
params.filterByInertia = True
params.minInertiaRatio = 0.95

# 使用参数创建检测器
detector = cv2.SimpleBlobDetector_create(params)

# 检测斑点
keypoints = detector.detect(image)

# 将检测到的斑点绘制为红色圆圈
output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
output_image = cv2.drawKeypoints(output_image, keypoints, np.array([]),
(0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

print(&quot;输出图像&quot;)
cv2.imshow(&quot;输出图像&quot;,output_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

print(f&quot;检测到的斑点数量：{len(keypoints)}&quot;)

以下代码将 blob 的坐标放在图形上（认为这种方式可能更容易操作）
#将图像转换为图形

import matplotlib.pyplot as plt
import numpy

blob_coords = np.array([kp.pt for kp in keypoints]) #blob 的坐标
rounded_coords = np.round(blob_coords).astype(int) #四舍五入的坐标

x_coords = rounded_coords[:, 0]
y_coords = rounded_coords[:, 1]

# 基于邻近度的分组
# 如果 X 距离小于最小距离
# 如果 Y 距离小于最小距离
# 存储 X 和 Y 坐标

# 计算最小 x 和 y差异（尝试基于接近度）
minx = 10000
miny = 10000
for i in x_coords:
for j in x_coords:
if abs(i - j) &lt;= minx and (15 &lt; abs(i - j)): # 单元格宽度阈值
minx = abs(i - j)

for i in y_coords:
for j in y_coords:
if abs(i - j) &lt;= miny and (15 &lt; abs(i - j)): # 单元格高度阈值
miny = abs(i - j)

print(f&quot;Smallest x difference: {minx}, Smallest y difference: {miny}&quot;,)

# 绘图
fig, ax = plt.subplots()
ax.scatter(x_coords, y_coords, color=&quot;blue&quot;) # 绘制斑点
ax.invert_yaxis()
plt.title(&quot;Braille Cell Detection&quot;)
plt.show()

尝试通过接近度将它们分开（位于我尝试将距离很近的物体分组到一起（我将距离很近的物体分组到一起），但我无法理解其中的逻辑。我也尝试了组聚类 (Kmeans)，但它不是很准确，并且不适用于具有不同字符数的图像，因为它需要不断知道要形成多少个簇。
# 尝试 kmeans 聚类方法
# kmeans 不起作用（无法从图像中找出簇的数量）
# 如果可以找出 nclusters，则可以工作

导入数学
从 sklearn.cluster 导入 KMeans

blob_coords = np.array([kp.pt for kp in keypoints]) # 提取 blob 的 (x, y) 位置
rounded_coords = np.round(blob_coords).astype(int) # 为简单起见，对坐标进行四舍五入

x_coords = rounded_coords[:, 0]
y_coords = rounded_coords[:, 1]

fig, ax = plt.subplots()
ax.scatter(x_coords, y_coords, color=&quot;blue&quot;) # 绘制斑点

ax.invert_yaxis() # 反转 Y 轴以获得类似图像的坐标
plt.title(&quot;盲文单元检测&quot;)
plt.show()

inertias = []

# 2
kmeans = KMeans(n_clusters=26)
kmeans.fit(rounded_coords)

plt.scatter(x_coords,y_coords, c=kmeans.labels_)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79306951/separation-of-braille-characters-inside-of-an-image</guid>
      <pubDate>Wed, 25 Dec 2024 05:54:00 GMT</pubDate>
    </item>
    <item>
      <title>“使用 YOLO 和 EasyOCR 进行车牌识别时遇到的文本识别问题”</title>
      <link>https://stackoverflow.com/questions/79291987/text-recognition-issues-in-license-plate-recognition-using-yolo-and-easyocr</link>
      <description><![CDATA[问题
我正在开发一个车牌识别系统，使用 YOLOv8 进行检测，使用 EasyOCR 进行文本识别。虽然 YOLO 可以正确检测车牌区域，但 OCR 结果对于阿拉伯语文本和数字通常不准确。
检测到的文本示例：
检测到：“اباز”，这是无关紧要的。
检测到：“الراق”，与“العراق”部分匹配。
像“٢٦٠٤٩٩”这样的数字被准确检测到。
我尝试过的
管道设置：
YOLOv8 检测车牌并提取其边界框。
EasyOCR 处理裁剪后的车牌以进行文本识别。
文本校正：
使用 difflib.get_close_matches() 将 OCR 检测到的文本与预定义单词进行匹配（例如，“العراق”、“دهوك”）。
应用置信度阈值来过滤低置信度结果。
图像预处理：
将车牌区域转换为灰度。
调整区域大小以增强 OCR 性能。
最小可重现示例
import cv2
import easyocr
from ultralytics import YOLO

def detect_plate_with_yolo(image_path, model_path=&quot;yolov8n.pt&quot;):
model = YOLO(model_path)
img = cv2.imread(image_path)
results = model(img)
detections = results[0].boxes.xyxy.cpu().numpy()
if detections:
x1, y1, x2, y2 = map(int, detections[0])
return img[y1:y2, x1:x2]
return None

def perform_ocr_on_plate(plate_img):
reader = easyocr.Reader([&#39;ar&#39;, &#39;en&#39;], gpu=False)
plate_gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
return reader.readtext(plate_gray, detail=1)

plate_img = detect_plate_with_yolo(&quot;path/to/image.jpg&quot;)
if plate_img is not None:
detected_text = perform_ocr_on_plate(plate_img)
print(detected_text)

预期与实际行为
预期：正确识别阿拉伯语文本和数字（例如，&quot;العراق&quot;）。
实际：部分匹配（例如，&quot;الراق&quot;）或不相关的结果（例如，&quot;اباز&quot;）。
问题
如何使用 EasyOCR 提高阿拉伯语车牌的 OCR 准确率？
有没有比 difflib.get_close_matches() 更好的文本校正替代方案？
哪些额外的预处理步骤可能有助于提高 OCR 性能？]]></description>
      <guid>https://stackoverflow.com/questions/79291987/text-recognition-issues-in-license-plate-recognition-using-yolo-and-easyocr</guid>
      <pubDate>Wed, 18 Dec 2024 17:26:40 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类器的修改</title>
      <link>https://stackoverflow.com/questions/79290974/modification-of-random-forest-classifier</link>
      <description><![CDATA[我正在尝试更改随机森林分类器的功能。虽然通常每次分割都会随机选择特征，但我希望每次分割时都评估一个特定特征。我知道这会影响性能，但我想尝试一下这在非常具体的用例中是否是个好主意。因此，调整的结果应为：用于分割的特征是随机选择的（像往常一样），但始终会考虑一个特定特征（例如索引 15）（不一定使用）。据我所知，没有允许我指定该功能的函数（如果有，请告诉我）。]]></description>
      <guid>https://stackoverflow.com/questions/79290974/modification-of-random-forest-classifier</guid>
      <pubDate>Wed, 18 Dec 2024 11:48:27 GMT</pubDate>
    </item>
    <item>
      <title>‘super’ 对象没有属性‘__sklearn_tags__’</title>
      <link>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</link>
      <description><![CDATA[我在使用 Scikit-learn 中的 RandomizedSearchCV 拟合 XGBRegressor 时遇到了 AttributeError。错误消息指出：
&#39;super&#39; 对象没有属性 &#39;\_\_sklearn_tags__&#39;。

当我在 RandomizedSearchCV 对象上调用 fit 方法时会发生这种情况。我怀疑它可能与 Scikit-learn 和 XGBoost 或 Python 版本之间的兼容性问题有关。我使用的是 Python 3.12，并且 Scikit-learn 和 XGBoost 都安装了最新版本。
我尝试使用 Scikit-learn 中的 RandomizedSearchCV 调整 XGBRegressor 的超参数。我希望模型能够毫无问题地拟合训练数据，并在交叉验证后提供最佳参数。
我还检查了兼容性问题，确保库是最新的，并重新安装了 Scikit-learn 和 XGBoost，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</guid>
      <pubDate>Wed, 18 Dec 2024 11:45:52 GMT</pubDate>
    </item>
    <item>
      <title>EEG时域特征选择</title>
      <link>https://stackoverflow.com/questions/78833629/eeg-time-domain-features-selection</link>
      <description><![CDATA[我目前正在研究 EEG 数据并尝试对其进行分类。我想知道是否可以将每个时间步骤用作特征。这似乎不适合我，但我得到了不错的结果，所以我有点迷茫。
我有 16 个通道和 300 条记录，每条记录对应 4 个标签之一。我从时间域开始，因为我读到这个域可以用于分类（与其他域一起）。我做了一些预处理，比如过滤，但我在想：是否可以将每个通道用作观察值并将“EEG 时间序列”用作特征，以便每个特征都是一个时间步骤？
例如，如果我的录音时长为 2 秒，并且每 0.008 秒有一个值，那么我将有 2 / 0.008 = 250 个特征]]></description>
      <guid>https://stackoverflow.com/questions/78833629/eeg-time-domain-features-selection</guid>
      <pubDate>Mon, 05 Aug 2024 09:02:52 GMT</pubDate>
    </item>
    <item>
      <title>独热编码掩码的 resample_poly</title>
      <link>https://stackoverflow.com/questions/78827743/resample-poly-of-one-hot-encoded-masking</link>
      <description><![CDATA[我有这些张量：
X_test = X_unseen_flutter[0,0,:][None, :] # (批次大小，振幅长度) -&gt; (1, 3208)
y_true = y_unseen_flutter[0,0,:][None, :] # (批次大小，掩码长度，类别数量) -&gt; (1, 3208, 4) (独热编码)

我可以对 X_test 进行重新采样，但我不知道 y_true：
from scipy.signal import resample_poly

X_test_resampled = resample_poly(X_test, up=512, down=3208, axis=1) # (1, 512)
y_true_resampled = # ??? 我期望形状 (1, 512, 4)

除了独热编码标签外，resample_poly 的等价物是什么？
我希望有一个函数可以做到这一点，它接受 tensor, up, down, mask_axis, class_axis]]></description>
      <guid>https://stackoverflow.com/questions/78827743/resample-poly-of-one-hot-encoded-masking</guid>
      <pubDate>Sat, 03 Aug 2024 03:21:27 GMT</pubDate>
    </item>
    <item>
      <title>如何逐步训练朴素贝叶斯分类器？</title>
      <link>https://stackoverflow.com/questions/40639034/how-can-i-train-a-naivebayes-classifier-incrementally</link>
      <description><![CDATA[使用 Accord.NET，我创建了一个 NaiveBayes 分类器。它将根据 6 组左右的图像处理结果对像素进行分类。我的图像是 5MP，因此 50 张图像的训练集会创建一组非常大的训练数据。
每个像素 6 个 int 数组 * 500 万像素 * 50 张图像。
除了尝试将所有数据存储在内存中之外，有没有办法逐步训练 NaiveBayes 分类器？多次调用 Learn() 每次都会覆盖旧数据，而不是添加数据。]]></description>
      <guid>https://stackoverflow.com/questions/40639034/how-can-i-train-a-naivebayes-classifier-incrementally</guid>
      <pubDate>Wed, 16 Nov 2016 17:56:08 GMT</pubDate>
    </item>
    </channel>
</rss>