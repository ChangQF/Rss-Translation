<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 07 Apr 2024 03:14:30 GMT</lastBuildDate>
    <item>
      <title>将 Python 推荐系统连接到 Laravel 应用程序</title>
      <link>https://stackoverflow.com/questions/78286410/connecting-python-recommendation-system-to-laravel-application</link>
      <description><![CDATA[我使用 Python 和余弦相似度算法开发了一个基本的推荐系统。现在，我有兴趣创建一个 Laravel 应用程序来集成这个推荐系统。但是，我不确定如何在两者之间建立联系。
任何帮助将不胜感激！
我没有找到任何可以开始的东西！！]]></description>
      <guid>https://stackoverflow.com/questions/78286410/connecting-python-recommendation-system-to-laravel-application</guid>
      <pubDate>Sun, 07 Apr 2024 01:54:56 GMT</pubDate>
    </item>
    <item>
      <title>所有模型的训练、验证集和测试集的 F1 分数、精确度和召回率均较高</title>
      <link>https://stackoverflow.com/questions/78286020/high-f1-score-precision-and-recall-on-training-validation-set-and-test-set-on</link>
      <description><![CDATA[我正在研究一个关于 Kaggle。有一些特征，例如燃料消耗、燃料等。我尝试根据该数据集进行分类任务，将排放量高于 160 定义为不可接受 (1)，低于 160 定义为可接受 (0)。数据不平衡，可接受类有13269个数据，不可接受类有9287个数据。我尝试使用不同的分类模型，例如随机森林分类器、决策树分类器和逻辑回归，所有这些模型在训练集、验证集甚至测试集上都实现了接近 1 的 f1 分数，这看起来很奇怪。数据没有缺失值或空值，并且在将其输入模型之前由标准定标器进行标准化。
在此处输入图像说明在此处输入图像描述
我的第一个假设是当所有模型都这样执行时数据泄漏。我多次检查了代码，甚至用函数检查了数据集，训练集和测试集之间没有重复的行。我尝试使用所有特征，然后使用随机森林发现最相关的一些特征，例如“COMB（L/100 km）”、“COMB（mpg）”、“燃油消耗”、“HWY（L/100 km）” 100 公里）”、“气缸”、“发动机尺寸”和他们玩了一下，但在所有精确度、召回率和 f1 上仍然获得了高分。我通过偶然从较大的类中删除一些数据来平衡数据集。我使用网格搜索制作模型，因此我尝试通过定义不同的参数网格以及手动定义来使模型更加复杂和简单。我还通过阈值检查了精度和召回率。
在此处输入图片说明
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78286020/high-f1-score-precision-and-recall-on-training-validation-set-and-test-set-on</guid>
      <pubDate>Sat, 06 Apr 2024 21:57:10 GMT</pubDate>
    </item>
    <item>
      <title>循环图像时出现 TensorFlow InvalidArgumentError</title>
      <link>https://stackoverflow.com/questions/78285543/tensorflow-invalidargumenterror-while-looping-over-images</link>
      <description><![CDATA[迭代图像时出现以下错误：
InvalidArgumentError: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} 图像中固有的通道数必须为 1、3 或 4，为 2
     [[{{节点decode_image/DecodeImage}}]] [Op:IteratorGetNext]名称：

我用来定义数据和迭代图像的代码：
data=tf.keras.utils.image_dataset_from_directory（main_path，batch_size=None）

形状=[]
对于枚举（数据）中的 i，（图像，标签）：
    尝试：
        通道大小=图像.形状
        形状.append（通道大小）
    除了 tf.errors.InvalidArgumentError 为 e：
        打印（一）
    

即使指定批量大小，我也会遇到相同的错误。
我使用的数据集是来自 Kaggle 的猫和狗分类数据集。
我最好的猜测是，数据中存在错误的图像，这导致了错误，我想通过循环所有图像来找到该图像。我仍然收到 Try/Except 块的错误。
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78285543/tensorflow-invalidargumenterror-while-looping-over-images</guid>
      <pubDate>Sat, 06 Apr 2024 18:53:39 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec Hierarchical Softmax 中的内部顶点是什么？</title>
      <link>https://stackoverflow.com/questions/78285447/whats-inside-inner-vertices-in-word2vec-hierarchical-softmax</link>
      <description><![CDATA[我有一个关于分层 Softmax 的问题。实际上，我不太明白内部顶点（不是叶顶点）中存储的内容。我清楚地理解这个算法的主要思想，但是每一步我们都计算输入词嵌入与内部顶点的词嵌入的点积。那么这些内部顶点内部有哪些向量呢？是否是大小等于 embedding_size 的随机初始化向量，然后它们的坐标由于反向传播步骤而变化，直到我们停止？]]></description>
      <guid>https://stackoverflow.com/questions/78285447/whats-inside-inner-vertices-in-word2vec-hierarchical-softmax</guid>
      <pubDate>Sat, 06 Apr 2024 18:15:41 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 pycaret 获得第二最佳模型参数？</title>
      <link>https://stackoverflow.com/questions/78285377/how-to-get-the-second-best-model-parameter-using-pycaret</link>
      <description><![CDATA[这是我在 google collab 上的代码
# 导入库
从 pycaret.classification 导入 *


exp_clf = 设置（数据，目标=&#39;目标&#39;，规范化=True）


最佳模型 = 比较模型()

这就是结果

此代码将显示最佳模型参数
显示(best_model)

这就是结果

我想知道其他模型参数而不是最佳模型（光梯度增强机），因为 AUC 对我来说不够高。如何显示随机森林分类器的参数？
我尝试了这个，希望它能向我显示第二最佳模型（随机森林）的参数
 显示(best_model[1])

这就是结果
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-20-63c1d322b8ae&gt;在&lt;细胞系：1&gt;()
----&gt; 1 个显示器（best_model[1]）

类型错误：“LGBMClassifier”对象不可下标
]]></description>
      <guid>https://stackoverflow.com/questions/78285377/how-to-get-the-second-best-model-parameter-using-pycaret</guid>
      <pubDate>Sat, 06 Apr 2024 17:53:04 GMT</pubDate>
    </item>
    <item>
      <title>我认为我的模型过度拟合？有什么建议么？</title>
      <link>https://stackoverflow.com/questions/78285324/i-think-my-model-is-overfitting-any-suggestions</link>
      <description><![CDATA[所以我正在使用来自kaggle的deepfake检测数据集，我的模型似乎过度拟合，大约有2000张图像，其中1k用于“真实”类，1k用于“假”类。所有图像都是面孔。我使用的是 VGG16，因为它众所周知适合深度伪造面部检测。
以下是过去 10 个周期的结果：
找到属于 2 个类别的 1632 个图像。
找到属于 2 个类别的 204 张图像。
找到属于 2 个类别的 205 张图像。
纪元 1/10
51/51 [==============================] - 1234s 24s/步 - 损失：0.1841 - 准确度：0.9577 - val_loss ：0.7258 - val_accuracy：0.6719
纪元 2/10
51/51 [================================] - 1168s 23s/步 - 损失：0.1397 - 准确度：0.9712 - val_loss ：0.7331 - val_accuracy：0.6406
纪元 3/10
51/51 [================================] - 1186s 23s/步 - 损失：0.1215 - 准确度：0.9743 - val_loss ：0.7938 - val_accuracy：0.6719
纪元 4/10
51/51 [==============================] - 1187s 23s/步 - 损失：0.0914 - 准确度：0.9884 - val_loss ：0.8304 - val_accuracy：0.6615
纪元 5/10
51/51 [================================] - 1188s 23s/步 - 损失：0.0705 - 准确度：0.9939 - val_loss ：0.9022 - val_accuracy：0.6562
纪元 6/10
51/51 [================================] - 1155s 23s/步 - 损失：0.0683 - 准确度：0.9896 - val_loss ：0.9072 - val_accuracy：0.6354
纪元 7/10
51/51 [==============================] - 1154s 23s/步 - 损失：0.0541 - 准确度：0.9951 - val_loss ：0.8924 - val_accuracy：0.6719
纪元 8/10
51/51 [==============================] - 1175s 23s/步 - 损失：0.0403 - 准确度：0.9975 - val_loss ：0.9353 - val_accuracy：0.6510
纪元 9/10
51/51 [==============================] - 1189s 23s/步 - 损失：0.0420 - 准确度：0.9969 - val_loss ：1.0692 - val_accuracy：0.6198
纪元 10/10
51/51 [==============================] - 1185s 23s/步 - 损失：0.0288 - 准确度：0.9988 - val_loss ：1.0250 - val_accuracy：0.6510
/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103：UserWarning：您正在通过“model.save()”将模型保存为 HDF5 文件。此文件格式被视为旧格式。我们建议使用原生 Keras 格式，例如`model.save(&#39;my_model.keras&#39;)`。
  saving_api.save_model(
6/6 [================================] - 135s 21s/步 - 损失：1.1160 - 准确度：0.6042
测试精度：0.6041666865348816，结果如下

如果有人想知道，这里是过去 10 个时期的代码：
从 google.colab 导入驱动器
导入操作系统
将张量流导入为 tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入load_model

train_dir = &#39;/content/drive/MyDrive/dataset/train&#39;
val_dir = &#39;/content/drive/MyDrive/dataset/val&#39;
test_dir = &#39;/content/drive/MyDrive/dataset/test&#39;

＃参数
批量大小 = 32
历元 = 5
图像形状 = (224, 224)

save_model_path = &#39;/content/drive/MyDrive/dataset/trained_model_updated.h5&#39;
模型 = load_model(保存的模型路径)

#预处理
train_datagen = ImageDataGenerator(重新缩放=1./255)
val_datagen = ImageDataGenerator(重新缩放=1./255)
test_datagen = ImageDataGenerator（重新缩放=1./255）

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）

val_generator = val_datagen.flow_from_directory(
    val_dir,
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）

test_generator = test_datagen.flow_from_directory(
    测试目录，
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）


model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])


历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=纪元，
    验证数据=val_generator，
    validation_steps=val_generator.samples //batch_size
）


model.save(&#39;/content/drive/MyDrive/dataset/trained_model_updated.h5&#39;)

test_loss, test_acc = model.evaluate(test_generator,steps=test_generator.samples //batch_size)
print(f&#39;测试准确度：{test_acc}&#39;)


我运行了该模型大约 20 个 epoch，并不断更改参数，应用数据增强。尽管该模型对训练数据产生了良好的准确性，但对验证和测试集而言仍停滞在 67% 左右。
在前 5 个 epoch 中，模型的验证准确率确实从 53% 提高到 67%，但在最后 15 个 epoch 中仍然停滞不前。
为了确认，我还尝试使用来自互联网的一些图像，但它没有正确识别这些图像，并且会错误地将一些假图像分类为“真实”。
我很确定它的过度拟合是正确的吗？
我没有计算资源来训练更大的数据集，除了增加数据集大小之外还有其他解决方案吗？任何建议，将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78285324/i-think-my-model-is-overfitting-any-suggestions</guid>
      <pubDate>Sat, 06 Apr 2024 17:38:39 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：“密集”层需要 1 个输入。收到了 2 个</title>
      <link>https://stackoverflow.com/questions/78285249/valueerror-layer-dense-expected-1-inputs-received-2-instead</link>
      <description><![CDATA[我正在尝试训练 VGG16 模型来识别狗的品种。问题是我在训练模型后无法加载模型。我不断收到此错误：ValueError：层“密集”需要 1 个输入。收到了 2 个
从 keras.src.legacy.preprocessing.image 导入 ImageDataGenerator
从 keras.src. saving 导入 load_model
从 sklearn.preprocessing 导入 LabelEncoder
从 keras.utils 导入到_categorical
从 keras.applications 导入 VGG16
从 keras 导入图层、模型

def load_and_crop_image(image_path、annotation_path、save_dir=&#39;cropped_images&#39;):

    # 解析 XML 文件的边界框
    树 = ET.parse(annotation_path)
    根 = 树.getroot()
    bndbox = root.find(&quot;.//object/bndbox&quot;)
    xmin = int(bndbox.find(&#39;xmin&#39;).text)
    ymin = int(bndbox.find(&#39;ymin&#39;).text)
    xmax = int(bndbox.find(&#39;xmax&#39;).text)
    ymax = int(bndbox.find(&#39;ymax&#39;).text)

    # 加载并裁剪图像
    图像 = Image.open(图像路径)
    裁剪图像 = image.crop((xmin, ymin, xmax, ymax))
    cropped_image_resized =cropped_image.resize((224, 224)) # 调整大小以适合 VGG16 输入大小

    如果不是 os.path.exists(save_dir):
        os.makedirs（保存目录）

    image_file_name = os.path.basename(image_path)
    save_path = os.path.join(save_dir, image_file_name)

    #cropped_image_resized.save(save_path)

    # print(f“将裁剪后的图像保存到：{save_path}”)

    返回 np.array(cropped_image_resized)


def load_dataset（images_dir，annotations_dir）：
    图片 = []
    标签=[]

    对于 os.listdir(annotations_dir) 中的品种：
        breed_annotations_dir = os.path.join（annotations_dir，breed）
        breed_images_dir = os.path.join（images_dir，breed）

        对于os.listdir(breed_annotations_dir)中的annotation_file：
            注释路径 = os.path.join(breed_annotations_dir, 注释文件)
            image_file_name = comment_file.split(&#39;.&#39;)[0] + &#39;.jpg&#39;
            image_path = os.path.join(breed_images_dir, image_file_name)

            如果 os.path.exists(image_path):
                图像 = load_and_crop_image(图像路径, 注释路径)
                图像.追加（图像）

                labels.append(品种)

    返回 np.array(图像), np.array(标签)

images_dir = &#39;图像&#39;
注释_dir = &#39;注释&#39;
图像，标签= load_dataset（images_dir，annotations_dir）

# 对标签进行编码
label_encoder = LabelEncoder()
编码标签 = label_encoder.fit_transform(标签)
分类标签 = to_categorical(编码标签)

def create_model(num_classes):
    基础模型 = VGG16(权重=&#39;imagenet&#39;, include_top=False, input_shape=(224, 224, 3))
    base_model.trainable = False # 冻结基础模型

    模型 = models.Sequential([
        基本模型，
        图层.GlobalAveragePooling2D(),
        层.Dense（1024，激活=&#39;relu&#39;），
        层数.Dropout(0.5),
        层.Dense（num_classes，激活=&#39;softmax&#39;）
    ]）

    model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
    返回模型


模型 = create_model(num_classes=categorical_labels.shape[1])

数据生成 = ImageDataGenerator(重新缩放=1。/ 255,
                             验证分割=0.1，
                             旋转范围=10，
                             width_shift_range=0.1,
                             height_shift_range=0.1，
                             剪切范围=0.1，
                             缩放范围=0.1，
                             水平翻转=真，
                             垂直翻转=真
                             ）
train_generator = datagen.flow(图像、​​categorical_labels、batch_size=32、subset=&#39;training&#39;)
validation_generator = datagen.flow(图像、​​categorical_labels、batch_size=32、subset=&#39;validation&#39;)




历史= model.fit（train_generator，epochs = 1，validation_data = validation_generator）

model.save(&#39;dog_breed_classifier.keras&#39;, overwrite=True)

print(&quot;模型保存成功。&quot;)

尝试：
    模型 = load_model(&#39;dog_breed_classifier.keras&#39;)
    print(“模型加载成功。”)
除了异常 e：
    print(f“加载模型时发生错误：{e}”)

如果我注释掉这一行history = model.fit(train_generator, epochs=1,validation_data=validation_generator)，那么模型就会成功加载。
如果我在 model.fit(...) 之前保存并加载模型，则会收到相同的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78285249/valueerror-layer-dense-expected-1-inputs-received-2-instead</guid>
      <pubDate>Sat, 06 Apr 2024 17:14:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 make_classification 生成数据时可以设置特征的重要性吗？ make_classif 认为哪些功能很重要？</title>
      <link>https://stackoverflow.com/questions/78285036/can-i-set-the-importance-of-the-features-when-generating-data-with-make-classifi</link>
      <description><![CDATA[我有一个关于 scikit-learn 的 make_classification 的问题。
我使用 make_classification 创建了一个数据集，以测试不同模型区分重要特征和不太重要特征的能力。
所以我想相应地设置 make_classification 中的功能。这意味着，我想预先知道哪些是更重要的功能，哪些是不太重要的功能。
如果可能的话，我还想设置或调整哪些是更重要的功能。
我设置了以下内容：
&lt;前&gt;&lt;代码&gt;
X,y = make_classification(n_samples=50000, n_features=10, n_informative=5,
                    n_redundant=2、n_repeated=0、n_classes=2、n_clusters_per_class=2、
                          类间隔=1，
                   Flip_y=0.01，权重=[0.9,0.1]，shuffle=True，random_state=42）

在 make_classification 的文档中，有关于权重和比例的信息，但这似乎不适合了解或塑造特征的重要性。
我的问题不是关于在使用特定模型或不同模型时如何确定特征重要性。
我的问题是：

在使用 make_classification 生成数据时，我可以确定特征的重要性吗？ make_classification 认为哪些功能很重要？
是否可以设置或影响 make_classification 中变量的重要性？
所有信息功能都很重要吗？达到同样程度？他们之间有秩序吗？我可以通过某种方式对此进行调整吗？
我如何识别哪些信息丰富？

后续问题：

是否有另一种方法来生成合成数据来满足定义特征重要性的要求/或预先知道哪些特征更重要？

谢谢您，我们非常感谢任何想法或建议。]]></description>
      <guid>https://stackoverflow.com/questions/78285036/can-i-set-the-importance-of-the-features-when-generating-data-with-make-classifi</guid>
      <pubDate>Sat, 06 Apr 2024 16:04:55 GMT</pubDate>
    </item>
    <item>
      <title>神经网络对不同输入的相同预测</title>
      <link>https://stackoverflow.com/questions/78284988/neural-network-same-prediction-for-different-inputs</link>
      <description><![CDATA[我正在尝试在 Matlab 中构建一个神经网络，而不使用深度学习工具箱，其中一个隐藏层可以预测图像显示的是脑肿瘤还是健康的大脑。我使用的数据库包含 4000 张图像（2000 张脑肿瘤图像和 2000 张健康大脑图像）。
我面临的问题是准确率为 50%，并且每张图像的预测都是相同的。结果，混淆矩阵的一列始终为 0。我尝试更改学习率，尝试更改隐藏层上的神经元数量，但没有任何改变输出。我使用的隐藏层和输出层的激活函数都是 sigmoid，并且使用的优化算法是梯度下降。]]></description>
      <guid>https://stackoverflow.com/questions/78284988/neural-network-same-prediction-for-different-inputs</guid>
      <pubDate>Sat, 06 Apr 2024 15:52:17 GMT</pubDate>
    </item>
    <item>
      <title>需要有关使用梯度带的张量流手动反向传播的帮助</title>
      <link>https://stackoverflow.com/questions/78284916/need-help-regarding-tensorflow-manual-back-propagation-using-gradient-tape</link>
      <description><![CDATA[我的问题与这些事情有关：强化学习和张量流手动反向传播。
我的问题是：我正在研究强化学习系统。我通常批量收集经验，然后使用奖励进行反向传播。我使用我自己的自定义损失函数。我使用 EPSILON-GREEDY 策略进行探索。
现在的问题是，我的模型一直以高概率预测一类，我想问题是，我的模型根本不关心随机动作。这是因为，我使用所采取行动的概率来计算损失，因此，如果我从预测中获取随机概率，可以说[0.1,0.3,0.6]，例如我的随机行动是0，概率为0.1。假设它是对该状态的正确预测，所以我给出高奖励和低损失，现在我的模型在某种程度上认为它由于其 ARGMAX 值而获得了高奖励，即 0.6 概率或动作 3，但事实并非如此知道它因为随机动作 0 而获得了那么高的奖励。
我只是想知道如何解决这个问题。因为这是上周发生的事情。我尝试了chat-gpt和gemini建议的所有方法，但它们不起作用，现在我需要一个擅长keas和tensorflow的人，一个有使用tensorflow经验的人
提前谢谢您:)]]></description>
      <guid>https://stackoverflow.com/questions/78284916/need-help-regarding-tensorflow-manual-back-propagation-using-gradient-tape</guid>
      <pubDate>Sat, 06 Apr 2024 15:29:53 GMT</pubDate>
    </item>
    <item>
      <title>如何正确表示模型的数据</title>
      <link>https://stackoverflow.com/questions/78284870/how-to-correctly-represent-data-for-a-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78284870/how-to-correctly-represent-data-for-a-model</guid>
      <pubDate>Sat, 06 Apr 2024 15:16:11 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow.python.keras.layers”没有属性“BatchNormalization”</title>
      <link>https://stackoverflow.com/questions/78284460/attributeerror-module-tensorflow-python-keras-layers-has-no-attribute-batchn</link>
      <description><![CDATA[我目前正在开发一个项目，需要在 TensorFlow Keras 中使用 BatchNormalization。我已经从tensorflow.python.keras导入了层，但是当我尝试使用BatchNormalization时，遇到以下错误：
AttributeError：模块“tensorflow.python.keras.layers”没有属性“BatchNormalization”
这是我的代码片段：
从tensorflow.python.keras导入模型，输入
从tensorflow.python.keras.optimizers导入adam_v2作为Adam
从tensorflow.python.keras导入层
类 InceptionBlock(layers.Layer):
    def __init__(self, f, pooling=True):
        super(InceptionBlock, self).__init__()
        
        self.f = f
        self.pooling = 池化
   
        self.conva0 = 层.Conv2D(self.f, (1, 1), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma0=layers.BatchNormalization()
        self.conva1 = 层.Conv2D(self.f, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma1=layers.BatchNormalization()
        self.conva2 = 层.Conv2D(self.f, (1, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma2=layers.BatchNormalization()
        self.poola = groups.MaxPooling2D(pool_size=(2, 2))
        self.conva3 = 层.Conv2D(self.f, (3, 1), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;)
        self.batch_norma3=layers.BatchNormalization()
            

我的tensorflow版本是2.16.1，python版本是3.11.9。我检查了文档，似乎 BatchNormalization 应该在图层模块中可用。有人能解释一下为什么我可能会遇到这个错误吗？我应该使用其他方法在 TensorFlow Keras 中导入 BatchNormalization 吗？
如有任何帮助，我们将不胜感激。
谢谢！
我正在尝试在我的 InceptionBlock 路径中使用 BatchNormalization。]]></description>
      <guid>https://stackoverflow.com/questions/78284460/attributeerror-module-tensorflow-python-keras-layers-has-no-attribute-batchn</guid>
      <pubDate>Sat, 06 Apr 2024 13:00:44 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 中的恒定预测值</title>
      <link>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</link>
      <description><![CDATA[我正在尝试使用 LightGBM 回归来预测变量 (Y)。然而我的预测值都是相同的（即常数）。有人可以帮忙检测问题吗？
data_x = [[2021,5,368.92],[2023,11,356.82],[2022,10,352.49],[2023,5,343.63],[2023,10,324.91],[2022,12,352.02],[2021,6,370.7 9] ,[2022,5,386.59],[2019,2,301.56],[2021,4,353.7],[2021,1,303.93],[2021,9,371.94],[2019,4,310.77],[2021,3,345.3],[2020,5,249。 63],[ 2022,4,381.16],[2023,4,363.14],[2019,7,304.19],[2020,7,258.43],[2022,2,412.47],[2022,8,353.43],[2019,6,302.34],[2020,1,319。 88]，[2022年， 7,361.66],[2020,9,265.39],[2022,3,408.72],[2022,1,417.47],[2022,6,351.92],[2022,9,344.06],[2022,11,373.75],[2019,9,314.97], [2019,11,324.14] ,[2023,2,377.23],[2021,11,380.83],[2021,12,403.12],[2023,7,368.73],[2023,1,379.76],[2019,5,295.02],[2023,9,343.78],[2020,4, 248.54],[ 2019,10,314.79],[2019,8,295.92],[2023,3,354.09],[2023,6,357.35],[2021,2,324.31],[2020,3,246.26],[2019,3,295.36],[2020,12,30 6.27]，[2021， 8,376.54],[2020,6,258.21],[2023,8,352.35],[2021,7,370.21],[2020,10,259.13],[2020,8,275.66],[2019,12,315.47],[2020,11,301.27 ],[2021,10,389.23] ,[2019,1,291.94],[2020,2,302.38]]

df_x = pd.DataFrame(data_x, columns=[&#39;年&#39;, &#39;月&#39;, &#39;关闭&#39;])

data_y = [[1479.42],[1654.53],[1537.76],[1621.22],[1567.62],[1528.39],[1444.63],[1562.17],[1356.81],[1463.48],[1558.9],[1463.96] ,[1362.03],[1432.7],[1502.46],[1524.71],[1592.68],[1342.74],[1467.48],[1553.66],[1609.19],[1349.1],[1379.39],[1496.12],[ 1448.08]、[1562.96]、[1525.25]、[1575.06]、[1591.15]、[1544.66]、[1319.9]、[1366.73]、[1482.72]、[1520.73]、[1557.03]、[1577.37]、[1624 .74] ,[1402.05],[1614.94],[1482.28],[1338.88],[1354.6],[1553.65],[1606.36],[1510.78],[1348.05],[1323.39],[1542.95],[1411.64],[ 1493.44],[1563.53],[1414.8],[1452.67],[1491.7],[1451.43],[1467.23],[1477.13],[1360.29],[1386.48]]

df_y = pd.DataFrame(data_y, columns=[&#39;值&#39;])

X_df_earn_ind_fin_train，X_df_earn_ind_fin_test，y_df_earn_ind_fin_train，y_df_earn_ind_fin_test = train_test_split（df_x，df_y，test_size = 0.3，random_state = 21）

hyper_params = {
    &#39;任务&#39;：&#39;训练&#39;，
    &#39;boosting_type&#39;：&#39;gbdt&#39;，
    &#39;目标&#39;：&#39;回归&#39;，
    &#39;公制&#39;：[&#39;mape&#39;，&#39;auc&#39;]，
    “学习率”：0.01，
    “特征分数”：0.9，
    &#39;bagging_fraction&#39;：0.7，
    &#39;bagging_freq&#39;：10，
    “详细”：0，
    &#39;详细评估&#39;：-1，
    “最大深度”：10，
    “叶子数”：96，
    “max_bin”：256，
    “迭代次数”：1000，
    “n_估计器”：250
}

gbm = lgm.LGBMRegressor(**hyper_params)
gbm.fit(X_df_earn_ind_fin_train, y_df_earn_ind_fin_train,
        eval_set=[(X_df_earn_ind_fin_test, y_df_earn_ind_fin_test)],
        eval_metric=&#39;mape&#39;)

y_pred_df_earn_ind_test = gbm.predict(X_df_earn_ind_fin_test)


但是我的输出只是一个常量值的数组
y_pred_df_earn_ind_test =
数组([1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863])


如何纠正这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</guid>
      <pubDate>Mon, 01 Apr 2024 21:17:37 GMT</pubDate>
    </item>
    <item>
      <title>pytorch和cuda安装问题</title>
      <link>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</link>
      <description><![CDATA[我正在尝试在 Windows 11 上使用 Anaconda3 安装带有 Cuda 的 PyTorch
我的nvidia-smi输出驱动程序版本：551.76，CUDA版本：12.4
我的火炬版本是我从官方网站安装的 12.2
&lt;前&gt;&lt;代码&gt;火炬2.2.1+cu121
火炬音频2.2.1+cu121
火炬视觉 0.17.1+cu121

但问题是，当我运行 torch.cuda.is_available() 时，它显示 false 作为输出。这里出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</guid>
      <pubDate>Wed, 20 Mar 2024 10:58:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 ImageDataGenerator() 表现不佳？</title>
      <link>https://stackoverflow.com/questions/58562089/why-is-imagedatagenerator-performing-poorly</link>
      <description><![CDATA[我正在尝试使用 ImageDataGenerator() 构建图像分类模型。
该模型的训练和表现似乎很差。训练损失保持在 15 左右，准确率只有 10%，验证也差不多。
为了看看会发生什么，我尝试在不使用 ImageDataGenerator() 的情况下进行训练，并以类似的方式设置数据。它在训练、验证和测试方面表现得更好。训练损失为 0.71，准确度为 75%；验证损失为 0.8，准确度为 72%。 
我需要使用数据生成器计算出这个模型，因为我将转向更大的数据集，而该数据集无法装入内存。
所以，我想我的问题是我对 ImageDataGenerator() 做错了什么，它的性能如此糟糕，我该如何改善结果？
设置文件时（在所有“训练”、“测试”、“验证”文件夹中），有些类拥有自己的文件夹，这些文件夹中就是图像所在的位置。 
这是代码：
导入tensorflow为tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
进口泡菜
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入密集，激活，扁平化，Conv2D，MaxPooling2D，Dropout

data_gen = 图像数据生成器()
IMG_SIZE = 100
train_it = data_gen.flow_from_directory(&#39;D:/.../Train/&#39;, class_mode=&#39;稀疏&#39;,
                                       target_size=(IMG_SIZE, IMG_SIZE),color_mode=&#39;灰度&#39;,shuffle=True,batch_size=32)
val_it = data_gen.flow_from_directory(&#39;D:/.../Validation/&#39;, class_mode=&#39;稀疏&#39;,
                                     target_size=(IMG_SIZE, IMG_SIZE),color_mode=&#39;灰度&#39;,shuffle=True,batch_size=32)

图像大小 = [100, 100]

模型=顺序()
model.add(Conv2D(32,(3,3), input_shape=[*IMAGE_SIZE, 1]))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

模型.add(压平())
model.add(Dense(len(train_it.class_indices), 激活=&#39;softmax&#39;))

model.compile（损失=&#39;sparse_categorical_crossentropy&#39;，优化器=&#39;adam&#39;，指标=[&#39;准确性&#39;]）
model.fit_generator（train_it，epochs = 20，validation_data = val_it）

这是我没有 ImageDataGenerator() 的代码：
使用 OpenCV 设置数据
DATADIR=&#39;D:\...\Train&#39;
CATEGORIES = pickle.load(open(&quot;CATEGORIES.p&quot; , &quot;rb&quot;))
打印（长度（类别））
IMG_SIZE = 100
训练数据=[]

def create_training_data():
    对于类别中的类别：
        路径 = os.path.join(DATADIR,类别)
        class_num = CATEGORIES.index(类别)
        对于 os.listdir(path) 中的 img：
            尝试：
                img_array = cv2.imread(os.path.join(路径,img),cv2.IMREAD_GRAYSCALE)
                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
                Training_data.append([new_array, class_num])
            除了：
                打印（类别）
                打印（图像）

创建训练数据（）

随机播放（训练数据）

X=[]
y=[]
对于特征，训练数据中的标签：
    X.append（功能）
    y.append(标签)

X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 1)
X=X/255.0

模型设置：

&lt;前&gt;&lt;代码&gt;模型=顺序()
model.add(Conv2D(32,(3,3), input_shape=[*IMAGE_SIZE, 1]))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

模型.add(压平())
model.add(Dense(len(CATEGORIES), 激活=&#39;softmax&#39;))

model.compile（损失=&#39;sparse_categorical_crossentropy&#39;，优化器=&#39;adam&#39;，指标=[&#39;准确性&#39;]）
model.fit（X，y，epochs = 20，batch_size = 32，validation_split = 0.1）
]]></description>
      <guid>https://stackoverflow.com/questions/58562089/why-is-imagedatagenerator-performing-poorly</guid>
      <pubDate>Fri, 25 Oct 2019 16:05:15 GMT</pubDate>
    </item>
    </channel>
</rss>