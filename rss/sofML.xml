<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 24 Jul 2024 09:16:10 GMT</lastBuildDate>
    <item>
      <title>使用适配器在 CNN/DailyMail 数据集上微调 BART 时，性能不佳且有过度拟合的迹象</title>
      <link>https://stackoverflow.com/questions/78787294/poor-performance-and-signs-of-overfitting-when-fine-tuning-bart-with-adapters-on</link>
      <description><![CDATA[我目前正在使用 CNN/DailyMail 数据集对 BART 模型进行微调，并使用适配器完成摘要任务。我注意到该模型性能不佳，并且有过度拟合的迹象。下面是我的设置和相关代码片段。我已经尝试了不同的学习率和训练数据量。如有任何关于导致此问题的原因或如何改善模型性能的建议，我们将不胜感激。
from datasets import load_dataset, DatasetDict
from transformers import TrainingArguments, EvalPrediction
from adapters import AutoAdapterModel, AdapterTrainer
import torch

# 加载 CNN/DailyMail 数据集的子集
small_train_dataset = load_dataset(&quot;cnn_dailymail&quot;, &quot;3.0.0&quot;, split=&quot;train[:5%]&quot;)

# 拆分数据集
train_size = 0.8
valid_size = 0.2
train_valid_split = small_train_dataset.train_test_split(test_size=valid_size)
split_dataset = DatasetDict({
&#39;train&#39;: train_valid_split[&#39;train&#39;],
&#39;validation&#39;: train_valid_split[&#39;test&#39;]
})

# 预处理和标记数据
def preprocess_function(examples):
# 假设“tokenizer”已实例化
return {
&#39;input_ids&#39;: tokenizer(examples[&#39;article&#39;], padding=&quot;max_length&quot;, truncation=True, max_length=128),
&#39;labels&#39;: tokenizer(examples[&#39;highlights&#39;], padding=&quot;max_length&quot;, truncation=True, max_length=128)[&quot;input_ids&quot;]
}

# 使用适配器初始化 BART 模型
model = AutoAdapterModel.from_pretrained(&quot;facebook/bart-base&quot;)
model.add_adapter(&quot;cnn_dailymail&quot;, config=&quot;lora&quot;)
model.add_seq2seq_lm_head(&quot;cnn_dailymail&quot;)
model.train_adapter(&quot;cnn_dailymail&quot;)

# 训练设置
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
model.to(device)
training_args = TrainingArguments(
learning_rate=5e-5,
num_train_epochs=1,
per_device_train_batch_size=32,
logs_steps=10,
output_dir=&quot;./training_output&quot;,
overwrite_output_dir=True,
remove_unused_columns=False,
gradient_accumulation_steps=4
)

trainer = AdapterTrainer(
model=model,
args=training_args,
train_dataset=split_dataset[&#39;train&#39;],
eval_dataset=split_dataset[&#39;validation&#39;]
)

# 开始训练
trainer.train()
]]></description>
      <guid>https://stackoverflow.com/questions/78787294/poor-performance-and-signs-of-overfitting-when-fine-tuning-bart-with-adapters-on</guid>
      <pubDate>Wed, 24 Jul 2024 08:52:39 GMT</pubDate>
    </item>
    <item>
      <title>在 keras.metrics.TruePositives 中，TruePositive 怎么会是十进制数？</title>
      <link>https://stackoverflow.com/questions/78787112/how-can-truepositive-be-a-decimal-number-in-keras-metrics-truepositives</link>
      <description><![CDATA[我正尝试在图像数据集上训练 CNN 模型，但一直无法获得 TruePositives、TrueNegatives、FalsePositives 和 FalseNegatives 的十进制值。这怎么可能呢？
ERROR 示例
Epoch 1/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━ 69s 2s/step - false_negatives：30.1351 - false_positives：35.3784 - loss：2.1995 - true_negatives：389.0540 - true_positives：437.6487


有一些（tp+tn+fp+tn）不等于样本总数。
完整代码

import pandas as pd
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.layers import Dense,Flatten,InputLayer,Conv2D,MaxPooling2D,Concatenate,Input,BatchNormalization
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.losses import BinaryCrossentropy,CategoricalCrossentropy
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from sklearn.metrics import classes_report
from tensorflow.keras.callbacks import EarlyStopping

datagen=ImageDataGenerator(rescale=1.0/255.0)
train_gen=datagen.flow_from_directory(&#39;train&#39;,class_mode=&#39;binary&#39;,
target_size=(224,224),batch_size=32,shuffle=True)


output
找到属于 2 个类别的 1146 张图像。

tp = tf.keras.metrics.TruePositives()
tn = tf.keras.metrics.TrueNegatives()
fp = tf.keras.metrics.FalsePositives()
fn = tf.keras.metrics.FalseNegatives()
tp.update_state([0.4, .9, .7, .8], [1.0, 0.0, 1.0, 1.0])
tp.result()

输出
&lt;tf.Tensor: shape=(), dtype=float32, numpy=3.0&gt;

model_input=Input(shape=(224,224,3))

x=Conv2D(filters=32, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(model_input)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=Conv2D(filters=64, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(x)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=BatchNormalization()(x)
x=Conv2D(filters=64, kernel_size=(3,3),activation=&#39;relu&#39;,padding=&#39;valid&#39;)(x)
x=MaxPooling2D(pool_size=(2,2),strides=2)(x)
x=BatchNormalization()(x)
x=Flatten()(x)
x=Dense(units=1000,activation=&#39;relu&#39;)(x)
output=Dense(units=1,activation=&#39;sigmoid&#39;)(x)
model=Model(inputs=model_input,outputs=output)

model.compile(optimizer=Adam(),loss=BinaryCrossentropy(),metrics=[tp,fp,fn,tn])
early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, waiting=2,restore_best_weights=True)

history=model.fit(x=train_gen,epochs=3,callbacks=[early_stopping])

十进制值错误
Epoch 1/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━━ 69s 2s/step - false_negatives: 30.1351 - false_positives: 35.3784 - loss: 2.1995 - true_negatives: 389.0540 - true_positives: 437.6487
Epoch 2/3
36/36 ━━━━━━━━━━━━━━━━━━━━━ 61s 2s/步 - 假阴性：7.8378 - 假阳性：13.5135 - 损失：0.1692 - 真阴性：283.1081 - 真阳性：300.4054
Epoch 3/3
36/36 ━━━━━━━━━━━━━━━━━━━━━━━ 65s 2s/步 - 假阴性： 2.3243 - 假阳性：3.0811 - 损失：0.0546 - 真阴性：289.8108 - 真阳性：308.3513

]]></description>
      <guid>https://stackoverflow.com/questions/78787112/how-can-truepositive-be-a-decimal-number-in-keras-metrics-truepositives</guid>
      <pubDate>Wed, 24 Jul 2024 08:14:02 GMT</pubDate>
    </item>
    <item>
      <title>安装 tf-models-official 时出现元数据生成失败</title>
      <link>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</link>
      <description><![CDATA[我尝试使用 !pip install tf-models-official 安装 tf-models-official，当它开始收集 kaggle&gt;=1.3.9 时，它返回以下错误：
收集 kaggle&gt;=1.3.9（来自 tf-models-official）
使用缓存的 kaggle-1.6.15.tar.gz (9.1 kB)
安装构建依赖项...完成
获取构建 wheel 的要求...完成
准备元数据（pyproject.toml）...错误
错误：子进程退出并出现错误

× 准备元数据（pyproject.toml）未成功运行。
│ 退出代码：1
╰─&gt; [35 行输出]
回溯（最近一次调用）：
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 353 行，位于 &lt;module&gt;
main()
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 335 行，在 main 中
json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py&quot;，第 152 行，在 prepare_metadata_for_build_wheel 中
whl_basename = backend.build_wheel(metadata_directory, config_settings)
文件&quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/build.py&quot;，第 58 行，在 build_wheel 中
return os.path.basename(next(builder.build(directory=wheel_directory,versions=[&#39;standard&#39;])))
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;，第 155 行，在 build 中
artifact = version_api[version](directory,**build_data)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 475 行，在build_standard
for included_file in self.recurse_included_files():
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 176, in recurse_included_files
Yield from self.recurse_selected_project_files()
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/plugin/interface.py&quot;, line 180, in recurse_selected_project_files
if self.config.only_include:
File &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/config.py&quot;，第 806 行，在 only_include 中
only_include = only_include_config.get(&#39;only-include&#39;, self.default_only_include()) 或 self.packages
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 260 行，在 default_only_include 中
return self.default_file_selection_options.only_include
文件 &quot;/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/functools.py&quot;，第 981 行，在__get__
val = self.func(instance)
文件 &quot;/tmp/pip-build-env-fqrzl9xw/overlay/lib/python3.10/site-packages/hatchling/builders/wheel.py&quot;，第 248 行，位于 default_file_selection_options
raise ValueError(message)
ValueError：无法使用以下启发式方法确定要将哪些文件发送到 wheel 内：https://hatch.py​​pa.io/latest/plugins/builder/wheel/#default-file-selection

最可能的原因是没有与您的项目 (kaggle) 名称匹配的目录。

必须在 `tool.hatch.build.targets.wheel` 表中定义至少一个文件选择选项，请参阅：https://hatch.py​​pa.io/latest/config/build/

例如，如果您打算发送一个名为 `foo` 的目录，该目录位于项目根目录的 `src` 目录中，则可以定义以下内容：

[tool.hatch.build.targets.wheel]
packages = [&quot;src/foo&quot;]
[输出结束]

注意：此错误源自子进程，可能不是 pip 的问题。
错误：metadata-generation-failed

× 生成包元数据时遇到错误。
╰─&gt; 请参阅上面的输出。

注意：这是上面提到的包的问题，​​而不是 pip。
提示：请参阅上文了解详情。

我能够在 2 周前安装，现在在新的 jupyter 笔记本内核上突然无法安装。我尝试在旧内核上重新安装，也出现了同样的错误。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78786800/metadata-generation-failed-when-installing-tf-models-official</guid>
      <pubDate>Wed, 24 Jul 2024 07:02:59 GMT</pubDate>
    </item>
    <item>
      <title>创建具有标量特征和 N 维坐标向量特征的机器学习 Numpy 数组</title>
      <link>https://stackoverflow.com/questions/78785643/create-a-machine-learning-numpy-array-with-scalar-features-and-an-n-dimensional</link>
      <description><![CDATA[我正在尝试为 ML 程序格式化我的数据。有 33,000 个事件，每个事件都有 3 个我想考虑的事情：质量、能量、坐标。
质量的形状为 (33000,)，看起来像：[188.9 189.0 125.7 ... 127.4 201.0 210.1]。
能量也是 (33000,)，看起来相同：[1 2 3 ... 8 9 10]。然后，我还有一个形状为 (33000,10) 的 10 维坐标向量
每个坐标都是一个包含 10 个坐标点的 10 维向量：
坐标数组：
 [[19.9 613.0 6.5 127.4 486.4 54.3 194.0 19.4 194.0 32.3]
[1.89 1.01 4.9 ... 2.3 2.3 2.3]
[1.2 6.1 4.0 ... 1.7 1.7 1.7]
...
]

我想将这些输入到机器学习程序中。但是，我不想创建一个将 10 维坐标压缩为一组平面浮点值的数组，如下所示：
 [188.9 1 19.9 613.0 6.5 127.4 486.4 54.3 194.0 19.4 194.0 32.3\]
[189.0 2 1.89 1.01 4.9 ... 2.3 2.3 2.3\]
...

这会丢失最后 10 个值本质上联系在一起的信息，因为它们是一个坐标。相反，我想创建一个 numpy 数组，该数组中间有一个向量
 [188.9 1 [19.9 613.0 6.5 127.4 486.4 54.3 194.0 19.4 194.0 32.3]]
[189.0 2 [1.89 1.01 4.9 ... 2.3 2.3 2.3]]
...

这样，机器学习程序就知道将坐标向量视为其自身的特征，而不是一组不同的特征。因此实际形状可能是 (33000,3) 而不是 (33000,13) 这可能吗？
我尝试过 dstack、concatenate、stack 等。所有方法都存在“轴必须完全匹配”的问题。在我的例子中，轴不匹配。一个特征的轴为 10，而其他特征要么没有轴（33000，），要么有 1 个轴（33000,1）（如果你强制它有一个轴）。我不确定我是否遗漏了某个 numpy 数组事实，或者这是否是不可能的。]]></description>
      <guid>https://stackoverflow.com/questions/78785643/create-a-machine-learning-numpy-array-with-scalar-features-and-an-n-dimensional</guid>
      <pubDate>Tue, 23 Jul 2024 21:28:52 GMT</pubDate>
    </item>
    <item>
      <title>HPCC 系统 ECL：使用 LinearRegression 时出现访问权限不足错误</title>
      <link>https://stackoverflow.com/questions/78784047/hpcc-systems-ecl-insufficient-access-rights-error-using-linearregression</link>
      <description><![CDATA[我正在使用 HPCC Systems 和 ECL 进行机器学习项目以执行线性回归。我的数据集包含心理健康患病率数据。在尝试使用 LinearRegression.OLS 训练我的模型时，我遇到了以下错误：
错误：访问权限不足，无法使用嵌入代码 
(125, 34 - C:\Users\LENOVO\AppData\Roaming\HPCCSystems\bundles_versions\PBblas\V3_0_2\PBblas\internal\Converted.ecl)

这意味着包含在 ECL 脚本中的代码需要特殊权限或访问级别才能运行。
错误指向 HPCC Systems 安装中的特定文件，在本例中是 PBblas 库 (Converted.ecl) 的一部分。
我的代码：
IMPORT ML_Core;
IMPORT LinearRegression;
IMPORT $;

// 输入数据集的记录结构
MentalHealthRecord := RECORD
STRING Entity;
STRING Code;
INTEGER Year;
REAL8 Schizophrenia;
REAL8 Depression;
REAL8 Anxiety;
REAL8 Bipolar;
REAL8 EatingDisorders;
END;

// 根据记录输入数据集
MentalHealthDs := DATASET(&#39;~asn::testing::1-mental-illnesses-prevalence.csv&#39;,
MentalHealthRecord,
CSV(HEADING(1),
SEPARATOR(&#39;,&#39;),
TERMINATOR([&#39;\n&#39;, &#39;\r\n&#39;, &#39;\n\r&#39;])));

OUTPUT(MentalHealthDs, NAMED(&#39;InputDataset&#39;)); 

// 数据集中的记录数。训练：测试的分割比率为小数。
recordCount := COUNT(MentalHealthDs);
splitRatio := 0.8; // 80% 用于训练，20% 用于测试

// 继承包含随机数的数据集记录的记录结构
Shuffler := RECORD
MentalHealthRecord;
UNSIGNED4 rnd; // 一个随机数
END;

// 为包含随机数的数据添加一个属性
newDs := PROJECT(MentalHealthDs, TRANSFORM(Shuffler, SELF.rnd := RANDOM(), SELF := LEFT));

// 根据随机数对数据集进行排序，进行随机排序
shuffledDs := SORT(newDs, rnd);

// 拆分训练和测试数据集，同时仅获取输入记录属性
TrainDs := PROJECT(shuffledDs[1..(recordCount * splitRatio)], RECORDOF(MentalHealthDs));
TestDs := PROJECT(shuffledDs[(recordCount * splitRatio + 1)..recordCount], RECORDOF(MentalHealthDs));

OUTPUT(TrainDs, NAMED(&#39;TrainDataset&#39;));
OUTPUT(TestDs, NAMED(&#39;TestDataset&#39;));

// 将顺序 ID 附加到训练和测试数据集
ML_Core.AppendSeqID(TrainDs, id, newTrain);
ML_Core.AppendSeqID(TestDs, id, newTest);

OUTPUT(newTrain, NAMED(&#39;TrainDatasetID&#39;));
OUTPUT(newTest, NAMED(&#39;TestDatasetID&#39;));

// 将数据集转换为数字字段以进行训练
ML_Core.ToField(newTrain, TrainNF);
ML_Core.ToField(newTest, TestNF);

OUTPUT(TrainNF, NAMED(&#39;TrainNumericField&#39;));
OUTPUT(TestNF, NAMED(&#39;TestNumericField&#39;));

// 根据独立列的数量拆分转换后的数字字段数据集，以获取用于训练的 X 和 Y 
independent_cols := 4; // 精神分裂症、焦虑症、躁郁症、饮食失调症

X_train := TrainNF(number &lt; independent_cols + 1);
y_train := PROJECT(TrainNF(number = independent_cols + 1), TRANSFORM(RECORDOF(LEFT), SELF.number := 1, SELF := LEFT));

X_test := TestNF(number &lt; independent_cols + 1);
y_test := PROJECT(TestNF(number = independent_cols + 1), TRANSFORM(RECORDOF(LEFT), SELF.number := 1, SELF := LEFT));

OUTPUT(y_test, NAMED(&#39;ActualY&#39;));

// 通过拟合模型构建回归器并使用测试数据集进行预测
regressor := LinearRegression.OLS(X_train, y_train).GetModel;
predicted := LinearRegression.OLS().Predict(X_test, regressor);

OUTPUT(predicted, NAMED(&#39;PredictedY&#39;));


我已检查我的访问权限，但问题仍然存在。
为什么我会收到“访问权限不足”错误以及如何解决？
如何正确使用 LinearRegression.OLS 来训练模型？
HPCC Systems ECL 中是否有其他方法或配置可以执行线性回归而不会遇到访问权限问题？]]></description>
      <guid>https://stackoverflow.com/questions/78784047/hpcc-systems-ecl-insufficient-access-rights-error-using-linearregression</guid>
      <pubDate>Tue, 23 Jul 2024 14:29:53 GMT</pubDate>
    </item>
    <item>
      <title>多输出回归可根据 ROAS 和其他功能预测成本和收入</title>
      <link>https://stackoverflow.com/questions/78783100/multi-output-regression-to-predict-cost-and-revenue-from-roas-and-other-features</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78783100/multi-output-regression-to-predict-cost-and-revenue-from-roas-and-other-features</guid>
      <pubDate>Tue, 23 Jul 2024 11:10:59 GMT</pubDate>
    </item>
    <item>
      <title>如何防止人工智能模型检测特定对象</title>
      <link>https://stackoverflow.com/questions/78781272/how-to-prevent-the-ai-model-from-detecting-a-specific-object</link>
      <description><![CDATA[我正在做一个 AI 项目。有一个特定的物体我想让它不被检测到，所以正在寻找解决方案。
已经完成了两个物体的标记，并使用这两个标签训练了模型。还没有对物体进行标记，我很快就会这样做。
我认为这可能有效：

在使用我想要不被检测到的物体的标签训练预训练模型后，每当使用 AI 模型时，我都不会包含该物体的标签。

不确定这是否正确。你能对此提出任何意见吗？]]></description>
      <guid>https://stackoverflow.com/questions/78781272/how-to-prevent-the-ai-model-from-detecting-a-specific-object</guid>
      <pubDate>Tue, 23 Jul 2024 01:48:35 GMT</pubDate>
    </item>
    <item>
      <title>具有多输出回归和自定义损失函数的 LightGBM</title>
      <link>https://stackoverflow.com/questions/78310990/lightgbm-with-multi-output-regression-and-custom-loss-function</link>
      <description><![CDATA[我可以将 LightGBM 与多输出回归和自定义损失函数一起使用吗？
问题是我必须使用 LightGBM。
我知道我可以使用 sklearn 的 MultiOutputRegression 来包装 LightGBM，但这不允许我定义自定义损失函数，因为我可以使用 Keras 来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78310990/lightgbm-with-multi-output-regression-and-custom-loss-function</guid>
      <pubDate>Thu, 11 Apr 2024 14:15:26 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用函数转换器对我的目标列进行特征转换，但我不知道如何将其传递给函数？</title>
      <link>https://stackoverflow.com/questions/78274143/i-am-doing-feature-transformation-of-my-target-column-using-function-transformer</link>
      <description><![CDATA[该代码用于获取我的目标列，即 Time_taken(min)，其值为 (min) 36、(min) 54、(min) 65 ... 等等。所以我想创建一个新列“Time Taken”其值将为 36、54、65....并使用 Function Transformers 删除 Time_taken(min)。
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline

class TimeTakenTransformer(BaseEstimator, TransformerMixin):
def __init__(self, input_column):
self.input_column = input_column
def fit(self, X, y=None):
return self

def transform(self, X):
X = X.copy()
op = []
for i in X[self.input_column]:
a = i.split()
op.append(int(a[1]))
X[&#39;Time_taken&#39;] = op
X.drop([self.input_column], axis=1, inplace=True)
return X

Target_column = Pipeline([(&#39;替换值&#39;, TimeTakenTransformer(input_column=&quot;TARGET_COLUMN_NAME&quot;))])

Target_column = Pipeline([(&#39;替换值&#39;, TimeTakenTransformer(input_column=&quot;TARGET_COLUMN_NAME&quot;))])

TARGET_COLUMN_NAME = &quot;Time_taken(min)&quot; # 假设这是正确的列名

# 假设 df 是您的 DataFrame，应用转换
df_transformed = Target_column.fit_transform(df[[TARGET_COLUMN_NAME]])

# 用转换后的列替换原始列
df[&quot;Time_Taken&quot;] = df_transformed

我无法确定传递输入的正确方法。如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78274143/i-am-doing-feature-transformation-of-my-target-column-using-function-transformer</guid>
      <pubDate>Thu, 04 Apr 2024 13:19:38 GMT</pubDate>
    </item>
    <item>
      <title>将自动编码器转变为另一个模型</title>
      <link>https://stackoverflow.com/questions/78190758/turning-an-autoencoder-into-another-model</link>
      <description><![CDATA[根据我目前所读和所见，自动编码器神经网络的一个优点和用途是找到/挑选有用的特征。如果自动编码器训练良好，那么包含压缩数据的内层（即潜在层或瓶颈）中就有非常有价值的数据。
此层可用作另一个网络的输入，使另一个网络训练更容易/更快/更准确。
换句话说，我们摆脱了解码器部分，并将新层附加到编码器部分。
问题：

新层可以/应该具有不同的激活函数吗？

在潜在层之后，模型是否有任何合理的理由在每个层上添加更多节点数？ （我的意思是，当使用潜在作为新网络的输入时，再次扩大网络是否有意义？）

如何使用 keras 完成此过程？
我知道如何训练模型和自动编码器，但我究竟如何将它们结合起来？


我已经训练了自动编码器，并且知道新网络所需输出的形式。我只知道如何在 keras 和 tensorflow 中使用顺序方法创建网络。]]></description>
      <guid>https://stackoverflow.com/questions/78190758/turning-an-autoencoder-into-another-model</guid>
      <pubDate>Wed, 20 Mar 2024 03:42:57 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret：目标列中出现缺失值错误</title>
      <link>https://stackoverflow.com/questions/78099026/pycaret-got-missing-value-error-in-target-col</link>
      <description><![CDATA[如果目标列包含 NaN，并且当将其作为 Pycaret 中的目标列传递时，它会显示缺失值错误；所有可用的插补方法都适用于其余列，而不适用于所选目标列。
s = setup(df, target = &#39;Life expectancy&#39;, numeric_imputation=&quot;mean&quot;)


ValueError: 在目标列中发现 10 个缺失值：预期寿命。要继续，请从数据中删除相应的行。


目标列包含 NaN，当在 Pycaret 中将其作为目标列传递时，它会显示缺失值错误，如何处理目标列中的缺失值？]]></description>
      <guid>https://stackoverflow.com/questions/78099026/pycaret-got-missing-value-error-in-target-col</guid>
      <pubDate>Mon, 04 Mar 2024 04:54:10 GMT</pubDate>
    </item>
    <item>
      <title>训练特征矩阵 vs 真实输入</title>
      <link>https://stackoverflow.com/questions/77977567/training-feature-matrix-vs-real-input</link>
      <description><![CDATA[我在尝试将我的模型应用于实际场景时遇到了问题。用于训练的原始特征矩阵大于输入数据。
请纠正我，我知道实际应用中的输入可能在大小上要小得多，并且在更糟糕的情况下具有一些不同的特征。
示例：我的数据集是数千个文本文件，它们有两个类别（备忘录 (0) 或字母 (1)）。我使用 linearSVC 训练模型来对这些文件进行分类。
使用 train_test_split 的结果很棒，现在我想用实际场景测试它。实际场景中的输入将是一个文件。该文件将具有较少的特征，并且可能具有不同的特征。在我的上一次测试中，我使用 4500 个特征进行训练，而实际场景中的输入有 350 个特征。
ValueError：X 有 350 个特征，但 LinearSVC 需要 4500 个特征作为输入。
我该如何处理此类问题？]]></description>
      <guid>https://stackoverflow.com/questions/77977567/training-feature-matrix-vs-real-input</guid>
      <pubDate>Sun, 11 Feb 2024 16:49:49 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 自动编码器数据缩放指南</title>
      <link>https://stackoverflow.com/questions/76866677/guidance-on-data-scaling-for-lstm-autoencoder</link>
      <description><![CDATA[我正在处理一个包含 9 个特征的数据集。其中 8 个特征的值范围为 0-255，但一个特征的值明显不同。我正在将此数据集与 LSTM 自动编码器一起使用以进行异常检测，并且对缩放有几个问题：
虽然建议使用 RobustScaler 来处理异常值，但我发现 StandardScaler 在我的测试中表现更好。您能解释一下为什么会这样吗？
我尝试使用 RobustScaler 来处理发散特征，使用 StandardScaler 来处理其余特征。这种方法似乎很有希望。您会推荐这种混合缩放方法吗，还是我应该坚持对所有特征使用一个缩放器？]]></description>
      <guid>https://stackoverflow.com/questions/76866677/guidance-on-data-scaling-for-lstm-autoencoder</guid>
      <pubDate>Wed, 09 Aug 2023 10:06:05 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 使用 RNN 生成路径 - 与输入、输出、隐藏和批量大小混淆</title>
      <link>https://stackoverflow.com/questions/62305941/pytorch-path-generation-with-rnn-confusion-with-input-output-hidden-and-batc</link>
      <description><![CDATA[我按照 RNN 的句子生成教程进行操作，并尝试对其进行修改以生成位置序列，但是我在定义正确的模型参数（例如 input_size、output_size、hidden_​​dim、batch_size）时遇到了麻烦。
背景：
我有 596 个 x、y 位置序列，每个序列看起来像 [[x1,y1],[x2,y2],...,[xn,yn]]。每个序列代表车辆的 2D 路径。我想训练一个模型，给定一个起点（或部分序列），就可以生成其中一个序列。
-我已经填充/截断了序列，使它们的长度都为 50，这意味着每个序列都是形状为 [50,2] 的数组
-然后我将这些数据分为 input_seq 和 target_seq：
input_seq：torch.Size([596, 49, 2]) 的张量。包含所有 596 个序列，每个序列都没有其最后一个位置。
target_seq：torch.Size([596, 49, 2]) 的张量。包含所有 596 个序列，每个序列都没有其第一个位置。
模型类：
class Model(nn.Module):
def __init__(self, input_size, output_size, hidden_​​dim, n_layers):
super(Model, self).__init__()
# 定义一些参数
self.hidden_​​dim = hidden_​​dim
self.n_layers = n_layers
# 定义层
# RNN 层
self.rnn = nn.RNN(input_size, hidden_​​dim, n_layers, batch_first=True)
# 完全连接层
self.fc = nn.Linear(hidden_​​dim, output_size)

def forward(self, x):
batch_size = x.size(0) 
# 使用下面定义的方法初始化第一个输入的隐藏状态
hidden = self.init_hidden(batch_size)
#将输入和隐藏状态传入模型并获取输出
out, hidden = self.rnn(x, hidden)
# 重塑输出，使其适合全连接层
out = out.contiguous().view(-1, self.hidden_​​dim)
out = self.fc(out) 
return out, hidden

def init_hidden(self, batch_size):
# 此方法生成第一个隐藏状态为零的函数，我们将在前向传递中使用它
# 我们还将保存隐藏状态的张量发送到我们之前指定的设备
hidden = torch.zeros(self.n_layers, batch_size, self.hidden_​​dim)
return hidden

我使用以下参数实例化模型：
input_size 为 2（[x,y] 位置）
output_size 为 2（[x,y]位置）
hidden_​​dim 为 2（[x,y] 位置）（或者这应该是 50，就像完整序列的长度一样？）
model = Model(input_size=2, output_size=2, hidden_​​dim=2, n_layers=1)
n_epochs = 100
lr=0.01
# 定义损失、优化器
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=lr)

# 训练运行
for epoch in range(1, n_epochs + 1):
optimizer.zero_grad() # 清除上一个 epoch 的现有梯度
output, hidden = model(input_seq)
loss = criterion(output, target_seq.view(-1).long())
loss.backward() # 是否反向传播并计算梯度
optimizer.step() # 相应地更新权重
if epoch%10 == 0:
print(&#39;Epoch: {}/{}.............&#39;.format(epoch, n_epochs), end=&#39; &#39;)
print(&quot;Loss: {:.4f}&quot;.format(loss.item()))

当我运行训练循环时，它会失败并出现此错误：
ValueError Traceback (most recent call last)
&lt;ipython-input-9-ad1575e0914b&gt; in &lt;module&gt;
3 optimizer.zero_grad() # 清除上一个 epoch 的现有梯度
4 output, hidden = model(input_seq)
----&gt; 5 loss = criterion(output, target_seq.view(-1).long())
6 loss.backward() # 进行反向传播并计算梯度
7 optimizer.step() # 相应地更新权重
...

ValueError: 预期输入 batch_size (29204) 与目标 batch_size (58408) 匹配。

我尝试修改 input_size、output_size、hidden_​​dim 和 batch_size 并重塑张量，但我尝试得越多，就越困惑。有人能指出我做错了什么吗？
此外，由于批次大小在 Model.forward(self,x) 中定义为 x.size(0)，这意味着我只有一个大小为 596 的批次，对吗？拥有多个较小批次的正确方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/62305941/pytorch-path-generation-with-rnn-confusion-with-input-output-hidden-and-batc</guid>
      <pubDate>Wed, 10 Jun 2020 14:22:24 GMT</pubDate>
    </item>
    <item>
      <title>将堆叠的 RNN 输出馈入全连接层</title>
      <link>https://stackoverflow.com/questions/49811006/feed-stacked-rnn-output-into-fully-connected-layer</link>
      <description><![CDATA[我正在尝试使用 TensorFlow 中的堆叠 RNN 解决回归问题。RNN 输出应输入到完全连接层以进行最终预测。目前，我正在努力研究如何将 RNN 输出输入到最终的完全连接层。
我的输入形状为 [batch_size, max_sequence_length, num_features]
RNN 层创建如下：
cells = []
for i in range(num_rnn_layers):
cell = tf.contrib.rnn.LSTMCell(num_rnn_units)
cells.append(cell)

multi_rnn_cell = tf.contrib.rnn.MultiRNNCell(cells)

outputs, states = tf.nn.dynamic_rnn(cell=multi_rnn_cell,
input=Bx_rnn,dtype=tf.float32)

输出形状为 [batch_size, max_sequence_length, num_rnn_units]
我尝试仅使用最后一个时间步的输出，例如这个：
final_outputs = tf.contrib.layers.fully_connected(
output[:,-1,:],
n_targets,
activation_fn=None)

我还找到了一些例子和书籍，建议像这样重塑输出和目标：
rnn_outputs = tf.reshape(outputs, [-1, num_rnn_units])
y_reshaped = tf.reshape(y, [-1])

由于我目前使用的批量大小为 500，序列长度为 10000，这会导致矩阵巨大，训练时间非常长，内存消耗巨大。 
我还发现许多文章建议将输入拆分并再次堆叠输出，但由于形状不匹配，我无法实现这一点。
将 RNN 输出馈送到全连接层的正确方法是什么？或者我应该使用 RNN 状态而不是输出？
编辑：
澄清一下：我确实需要这些长序列，因为我正在尝试建模一个物理系统。输入是一个单一特征，由白噪声组成。我有多个输出（在这个特定系统中有 45 个）。脉冲影响系统状态大约 10.000 个时间步骤。
即，目前我正在尝试建模一个由振动器动画化的汽车齿轮桥接。 15 个加速度传感器测量 3 个方向（X、Y 和 Z）的输出。
批量大小 500 是任意选择的。
无论长序列可能消失的梯度或潜在的内存问题如何，我都对如何正确提供数据感兴趣。我们确实有合适的硬件（即 Nvidia Titan V）。此外，我们已经能够通过经典 DNN 以 &gt;3000 个时间步长的滞后以良好的精度对系统行为进行建模。]]></description>
      <guid>https://stackoverflow.com/questions/49811006/feed-stacked-rnn-output-into-fully-connected-layer</guid>
      <pubDate>Fri, 13 Apr 2018 06:56:11 GMT</pubDate>
    </item>
    </channel>
</rss>