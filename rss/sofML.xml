<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 25 Mar 2024 09:13:45 GMT</lastBuildDate>
    <item>
      <title>什么是逐点优化器和非逐点优化器？</title>
      <link>https://stackoverflow.com/questions/78217872/what-are-pointwise-optimizers-and-non-pointwise-optimizers</link>
      <description><![CDATA[我最近阅读了有关 fairscale FSDP 的文档
高效的内存管理
提到的地方

结果应与使用逐点优化器（例如 Adam、AdamW、Adadelta、Adamax、SGD 等）的 DDP 相同。但是，当使用非逐点优化器（例如 Adagrad、Adafactor）时，分片会导致结果略有不同、LAMB等

我确实了解 adam 和 adagrad 是如何工作的，但我不完全理解是什么导致了点式优化器和非点式优化器之间的差异？]]></description>
      <guid>https://stackoverflow.com/questions/78217872/what-are-pointwise-optimizers-and-non-pointwise-optimizers</guid>
      <pubDate>Mon, 25 Mar 2024 08:38:11 GMT</pubDate>
    </item>
    <item>
      <title>中等长度 (100bp) DNA 序列的聚类</title>
      <link>https://stackoverflow.com/questions/78217775/clustering-medium-length-100bp-dna-sequences</link>
      <description><![CDATA[您好，我正在尝试对长度约为 100 bp (GCAT) 的 70 个 DNA 序列 fasta 文件进行聚类，以便将基因型簇与我的表型簇进行比较，从而验证表型结果。
您认为采用单热编码和 kmeans 聚类算法来实现这一目标的可行性如何？
我在使用当前的序列聚类软件（DBSCAN、ALFATCLUST）时遇到的一些问题是，它们似乎主要关注较长的 DNA 序列，这意味着它总是将所有序列归为一组，或者仅将序列归为一组。一起出来。一般来说，这些算法对噪声（DNA seq 固有的）也非常敏感，这通常会导致聚类不准确。
有什么想法可以解决这个问题吗？
我尝试使用 DBSCAN、kmeans、cmeans、ALFATCLUST 等进行聚类，但得到了错误的聚类。]]></description>
      <guid>https://stackoverflow.com/questions/78217775/clustering-medium-length-100bp-dna-sequences</guid>
      <pubDate>Mon, 25 Mar 2024 08:15:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的验证准确性不如验证损失那么平滑？</title>
      <link>https://stackoverflow.com/questions/78217319/why-is-my-validation-accuracy-not-as-smooth-as-my-validation-loss</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78217319/why-is-my-validation-accuracy-not-as-smooth-as-my-validation-loss</guid>
      <pubDate>Mon, 25 Mar 2024 06:21:29 GMT</pubDate>
    </item>
    <item>
      <title>文本数据转换为数字格式的问题</title>
      <link>https://stackoverflow.com/questions/78217028/issue-in-text-data-conversion-into-numerical-format</link>
      <description><![CDATA[我正在尝试将数据集中存在的文本句子转换为数字格式，以便它可以作为我的 ML 模型的输入。
我觉得理解 ECL 中的 TextVector 有点困难 https ://hpccsystems.com/resources/textvectors-machine-learning-for-textual-data/任何人都可以提供有关此概念的更多详细信息吗？如果有任何示例，请分享文档。]]></description>
      <guid>https://stackoverflow.com/questions/78217028/issue-in-text-data-conversion-into-numerical-format</guid>
      <pubDate>Mon, 25 Mar 2024 04:07:16 GMT</pubDate>
    </item>
    <item>
      <title>如何预测两个标签是否具有相同的图形</title>
      <link>https://stackoverflow.com/questions/78216988/how-to-predict-if-two-lables-have-same-graphs</link>
      <description><![CDATA[我遇到了一个挑战，与标签相比，特征集的可视化显示了所有图表中惊人相似的路径。这种一致性提出了一个重大障碍，因为它表明在预测标签时特征之间缺乏区分力。尽管尝试通过使用 K 最近邻 (KNN) 来缓解此问题，但该方法产生的结果并不令人满意，表明该方法在我们的环境中无效。
这是我的功能和标签的图片
图表]]></description>
      <guid>https://stackoverflow.com/questions/78216988/how-to-predict-if-two-lables-have-same-graphs</guid>
      <pubDate>Mon, 25 Mar 2024 03:47:36 GMT</pubDate>
    </item>
    <item>
      <title>谁能帮助我评估我的人工智能学校项目的架构？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78216842/can-anyone-help-me-evaluate-this-architecture-for-my-ai-school-project</link>
      <description><![CDATA[我计划为医疗保健行业开发一种人工智能，可以帮助专业人士为患者提供诊断和预后。将有一系列模型将集成到该系统中。在第一部分中，我希望系统能够根据输入（这将是实验室测试结果的图像，和/或手动输入文本数据）来预测患者是否有很高的机会患有糖尿病、肾病和心血管疾病。它将总结和分析数据集，以解决某些疾病的概率。然后，处理和分析这些数据的算法将由外部强化学习模型进行评估，以改进每个模型的学习过程。我希望我的解释是有道理的。
注意：我计划使用多模态模型单独处理图像中的文本，使用 CNN 处理 X 射线、核磁共振等图像，使用 RNN 处理手动文本输入。
期待您的批评，以进一步提高我的知识。谢谢！！
我创建了模型的流程图，它将帮助我可视化实现系统目标所需的过程。]]></description>
      <guid>https://stackoverflow.com/questions/78216842/can-anyone-help-me-evaluate-this-architecture-for-my-ai-school-project</guid>
      <pubDate>Mon, 25 Mar 2024 02:39:55 GMT</pubDate>
    </item>
    <item>
      <title>构建用于机器学习的定制 PC：GPU 选择所需的帮助 [关闭]</title>
      <link>https://stackoverflow.com/questions/78216358/building-a-custom-pc-for-machine-learning-help-needed-with-gpu-selection</link>
      <description><![CDATA[“我正在规划我的定制 PC 构建，专门用于深入研究机器学习、深度学习和法学硕士。以下是我正在考虑的规格：

英特尔酷睿 i7 14700K 处理器
微星Pro Z790-A Max WIFI主板
威刚 XPG Lancer RGB DDR5 32GB (16x2) 5200MHz 白色
技嘉 RTX 4060 Ti Aero OC 8GB 显卡
NZXT Kraken 360mm RGB CPU 液冷散热器（带 LCD 显示屏）（白色）
西部数据 Blue SN580 1TB M.2 NVMe 内置 SSD
Cooler Master MWE 750 V2 80+ 金牌全模块化电源（750W）
联力 O11 Vision (E-ATX) 中塔机柜（白色）
NZXT F120 RGB 核心 120 毫米三重装机柜风扇白色
Nzxt F120 RGB 核心 120mm 机柜风扇 - 白色（单包）
Cooler Master Master Gel Pro（免费）

但是，我在 GPU 的选择上面临着两难的境地。我目前正在考虑 RTX 4060Ti，但我不确定它是否能满足我的需求，或者我是否应该选择更高端的型号，如 4070、4080 甚至 4090。我愿意延长我的时间如有必要，请进行预算，因为我打算仅将这台电脑用于机器学习目的。虽然我知道像 Google Colab 这样的替代品，但我仍然更喜欢构建自己的机器。我将非常感谢有关此事的任何见解或建议。谢谢！”]]></description>
      <guid>https://stackoverflow.com/questions/78216358/building-a-custom-pc-for-machine-learning-help-needed-with-gpu-selection</guid>
      <pubDate>Sun, 24 Mar 2024 22:39:23 GMT</pubDate>
    </item>
    <item>
      <title>python sklearn ValueError：用序列设置数组元素</title>
      <link>https://stackoverflow.com/questions/78216115/python-sklearn-valueerror-setting-an-array-element-with-a-sequence</link>
      <description><![CDATA[训练 sklearn sgd 分类器。根据数组中的姓名和年龄，获得颜色。乙
sgdclassifier 的 .fit() 错误。错误：“使用序列设置数组元素。”意思是？这是否意味着 sklearn 中的 sgd 分类器不能将数组的数组作为输入？
但是，如果名称和年龄不是数组（而只是单个元素），则不会出现错误。
from sklearn.model_selection import train_test_split
将 pandas 导入为 pd
将 numpy 导入为 np`

a=np.array([0, 2, 5, 2])
b=np.array( [0, 5, 0, 2])
c=np.array([2,2,0,0])
d=np.array([5,2,5,0])


age_a=np.array([5, 10, 7, 6])
Age_b=np.array([3, 7, 11,8])
age_c=np.array([15, 10, 17, 2])
Age_d=np.array([2, 8, 12,7])

color_a=np.array([0,2,1,1])
color_b=np.array([1,12,0,1])
color_c=np.array([0,1,1,0])
color_d=np.array([1,0,0,1])

#data2={&#39;姓名&#39;:[a,b,c,d],&#39;年龄&#39;:[年龄_a,年龄_b,年龄_c,年龄_d],&#39;颜色&#39;:[颜色_a,颜色_b,颜色_c,颜色_d]}

data2={&#39;姓名&#39;:[a,b,c,d],&#39;年龄&#39;:[age_a,age_b,age_c,age_d],&#39;颜色&#39;:[0,1,0,1]}
new2 = pd.DataFrame.from_dict(data2)

打印（新2）

x = new2.loc[:, new2.columns != &#39;颜色&#39;]
y = new2.loc[:, &#39;颜色&#39;]

x=np.array(x,dtype=对象)
y=np.array(y)



x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)



从 sklearn.linear_model 导入 SGDClassifier

sgd_clf=SGDClassifier(random_state=42)
sgd_clf.fit(x_train, y_train)
sgd_clf.预测（x_test）`

`
TypeError Traceback（最近一次调用最后一次）
类型错误：float() 参数必须是字符串或实数，而不是“列表”
上述异常是导致以下异常的直接原因：

ValueError Traceback（最近一次调用最后一次）
[117] 中的单元格，第 25 行
     21 打印（y_测试）
     24 clf = SGDClassifier(loss=“hinge”,penalty=“l2”,max_iter=5)
     25 clf.fit(x_train, y_train)
     26 #SGDClassifier(max_iter=100)
     28 clf.predict([[2., 2.]])


ValueError：使用序列设置数组元素。
]]></description>
      <guid>https://stackoverflow.com/questions/78216115/python-sklearn-valueerror-setting-an-array-element-with-a-sequence</guid>
      <pubDate>Sun, 24 Mar 2024 21:08:03 GMT</pubDate>
    </item>
    <item>
      <title>KeyError：“[‘建筑年龄’、‘楼层’、‘楼层数’]不在索引中”</title>
      <link>https://stackoverflow.com/questions/78215783/keyerror-building-age-floor-number-of-floors-not-in-index</link>
      <description><![CDATA[导入 pandas 作为 pd
将 numpy 导入为 np
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.metrics 导入mean_squared_error, r2_score
将类别编码器导入为 ce

# 读取数据
transactions_master_df = pd.read_csv(&#39;my_data.csv&#39;)

# 计算各区平均房价
avg_price_per_district = transactions_master_df.groupby(&#39;地区&#39;)[&#39;价格&#39;].mean().reset_index()
avg_price_per_district.rename(columns={&#39;Price&#39;: &#39;AvgPrice&#39;}, inplace=True)

#打印每个地区的平均价格，旁边是地区列
打印（每个地区的平均价格）

# 将平均价格信息与原始DataFrame合并
transactions_master_df = pd.merge(transactions_master_df, avg_price_per_district, on=&#39;地区&#39;, how=&#39;左&#39;)

# 对“District”特征进行二进制编码
编码器 = ce.BinaryEncoder(cols=[&#39;District&#39;], base=6)
transactions_encoded = 编码器.fit_transform(transactions_master_df)

# 将附加功能连接到编码的 DataFrame
extra_features = [&#39;建筑年龄&#39;,&#39;楼层&#39;,&#39;楼层数&#39;,&#39;电梯&#39;,
                      &#39;浴室数量&#39;, &#39;Otopark&#39;, &#39;陡峭的小巷&#39;,
                      “用料和奢华”、“景观”、
                      “该地区及其周边地区的声望”]

# 检查 transactions_encoded DataFrame 中是否存在其他功能
对于additional_features中的功能：
    如果功能不在 transactions_encoded.columns 中：
        print(f“警告：在 transactions_encoded DataFrame 中找不到 {feature} 列。”)

# 将附加功能连接到编码的 DataFrame
Final_features = pd.concat([transactions_encoded[[&#39;District_0&#39;, &#39;District_1&#39;, &#39;District_2&#39;, &#39;SquareMeter&#39;]],
                            transactions_encoded[additional_features]]，轴=1）

# 确保“final_features”包含训练所需的列
打印（final_features.head（））



你好，
在这段代码中，我正在为我的房价数据集构建一个模型。首先，我对一些非数字特征进行编码，然后当我连接其余特征以接收 Final_features 变量时，出现以下错误：
final_features = pd.concat([transactions_encoded[[&#39;District_0&#39;, &#39;District_1&#39;, &#39;District_2&#39;, &#39;SquareMeter&#39;]],
---&gt; 38 transactions_encoded[additional_features]], axis=1)
KeyError：“[&#39;建筑年龄&#39;，&#39;楼层&#39;，&#39;楼层数&#39;]不在索引中”


奇怪的是，这些功能存在于我的数据集中，但我不知道为什么它会给我这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/78215783/keyerror-building-age-floor-number-of-floors-not-in-index</guid>
      <pubDate>Sun, 24 Mar 2024 19:10:52 GMT</pubDate>
    </item>
    <item>
      <title>从 Pytorch 中加载 EMNIST 数据集</title>
      <link>https://stackoverflow.com/questions/78215347/load-emnist-dataset-from-within-the-pytorch</link>
      <description><![CDATA[我正在处理 EMNIST 数据集，并希望从 PyTorch 加载它，但它返回一个奇怪的错误：
&lt;块引用&gt;
运行时错误：文件未找到或已损坏。

这是我尝试加载数据集的方法：
trainset = torchvision.datasets.EMNIST(root=“emnist”,
                                   split=“字母”，
                                   火车=真，
                                   下载=真，
                                   变换=transforms.ToTensor())

可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78215347/load-emnist-dataset-from-within-the-pytorch</guid>
      <pubDate>Sun, 24 Mar 2024 16:53:53 GMT</pubDate>
    </item>
    <item>
      <title>如果文件夹已存在 ChromaDB，则防止创建嵌入</title>
      <link>https://stackoverflow.com/questions/78214495/prevent-create-embeddings-if-folder-already-present-chromadb</link>
      <description><![CDATA[这是我第一次尝试RAG应用。我正在尝试使用法学硕士进行问答。我将在下面粘贴运行良好的代码。我的问题是每次运行 python 代码时都会运行生成嵌入的代码。有没有办法只运行一次或检查嵌入文件夹是否为空，然后运行该代码。
from langchain_community.document_loaders import WebBaseLoader
从 langchain_community.document_loaders 导入 TextLoader
从 langchain_community.vectorstores 导入 Chroma
从 langchain_community 导入嵌入
从 langchain_community.chat_models 导入 ChatOllama
从 langchain_core.runnables 导入 RunnablePassthrough
从 langchain_core.output_parsers 导入 StrOutputParser
从 langchain_core.prompts 导入 ChatPromptTemplate
从 langchain.output_parsers 导入 PydanticOutputParser
从 langchain.text_splitter 导入 CharacterTextSplitter
从 langchain_community.embeddings 导入 OllamaEmbeddings

model_local = ChatOllama(model=&quot;codellama:7b&quot;)

loader = TextLoader(“remedy.txt”)
raw_doc = loader.load()

# 将文本文件内容分割成块
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
splitted_docs = text_splitter.split_documents(raw_doc)

# 使用嵌入函数将它们存储在向量数据库中
ollamaEmbeddings = embeddings.ollama.OllamaEmbeddings(model=“nomic-embed-text”)


# 使用色度向量数据库来存储数据
矢量存储 = Chroma.from_documents(
    文档=splitted_docs，
    嵌入=ollamaEmbeddings，
    persist_directory=&quot;./vector/my_data&quot;,
）

# 这会将数据写入本地
检索器 = vectorstore.as_retriever()

# 4. RAG 之后
print(&quot;RAG 之后\n&quot;)
after_rag_template = “””
    仅根据以下上下文回答问题：
    {语境}
    问题{问题}？
”“”
after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)
after_rag_chain = (
    {“上下文”：检索器，“问题”：RunnablePassthrough()}
    | after_rag_prompt
    |模型本地
    | StrOutputParser()
）
print(after_rag_chain.invoke(“普通感冒的家庭疗法是什么？”))
]]></description>
      <guid>https://stackoverflow.com/questions/78214495/prevent-create-embeddings-if-folder-already-present-chromadb</guid>
      <pubDate>Sun, 24 Mar 2024 12:31:15 GMT</pubDate>
    </item>
    <item>
      <title>TPU 连接问题 训练 TF 模型 Google Colab</title>
      <link>https://stackoverflow.com/questions/78209293/tpu-connectivity-issue-training-tf-model-google-colab</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78209293/tpu-connectivity-issue-training-tf-model-google-colab</guid>
      <pubDate>Fri, 22 Mar 2024 23:57:10 GMT</pubDate>
    </item>
    <item>
      <title>为新数据集创建梯度下降模型时出错[关闭]</title>
      <link>https://stackoverflow.com/questions/78120856/error-while-creating-gradient-descent-model-for-a-new-dataset</link>
      <description><![CDATA[导入 pandas 作为 pd

文件 = pd.read_excel(&#39;slr06.xlsx&#39;)
＃ 数据
x = pd.DataFrame(文件, 列=[&#39;X&#39;])
y = pd.DataFrame(文件, 列=[&#39;Y&#39;])
＃ 参数
w = 0.0
b = 0.0
# 超参数
学习率 = 0.01

# 创建梯度下降

def Descend(x, y, w, b, 学习率):
    dl_dw = 0.0
    dl_db = 0.0
    n = x.形状[0]
    # 损失 = (y-yhat)**2
    对于 zip(x, y) 中的 xi, yi：
        dl_dw = -2*xi*(yi-(w*xi+b))
        dl_db = -2*(yi-(w*xi+b))
    # 进行更新
    w = w - 学习率*(1/n)*dl_dw
    b = b - 学习率*(1/n)*dl_db
    
    返回w,b
# 迭代更新
对于范围（500）内的纪元：
    w, b = 下降(x, y, w, b, 学习率)
    yhat = w * x + b
    损失 = np.divide(np.sum((y - yhat)**2, axis=0), x.shape[0])
    print(f&quot;{epoch} 损失是 {loss} 参数 w: {w} | b:{b}&quot;)


我是机器学习新手，在使用数据集进行练习时遇到了错误
这是数据集的图片 - 
这是错误图片 - 
我正在创建一个梯度下降模型，我之前已经使用不同的数据集练习过该模型。我尝试使用随机数据来练习并更好地理解梯度下降]]></description>
      <guid>https://stackoverflow.com/questions/78120856/error-while-creating-gradient-descent-model-for-a-new-dataset</guid>
      <pubDate>Thu, 07 Mar 2024 11:08:58 GMT</pubDate>
    </item>
    <item>
      <title>CatBoostRegressor 与 loss_function='Lq'</title>
      <link>https://stackoverflow.com/questions/76498616/catboostregressor-with-loss-function-lq</link>
      <description><![CDATA[我不知道如何指定“q” “Lq”中的变量损失函数。我收到以下错误消息：
CatBoostError：/src/catboost/catboost/private/libs/options/catboost_options.cpp:82：参数 q 对于 Lq 丢失是必需的

我的代码如下：
from catboost import CatBoostRegressor
从 sklearn.datasets 导入 make_regression
从 sklearn.model_selection 导入 train_test_split
将 numpy 导入为 np

# 生成人工回归数据集
X, y = make_regression(n_samples=1000, n_features=10, random_state=42)

# 将数据集分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建一个 CatBoostRegressor 对象
模型 = CatBoostRegressor(loss_function=&#39;Lq&#39;)

# 拟合模型
model.fit(X_train, y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/76498616/catboostregressor-with-loss-function-lq</guid>
      <pubDate>Sun, 18 Jun 2023 00:20:48 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch mat1和mat2必须具有相同的dtype mlp</title>
      <link>https://stackoverflow.com/questions/75259774/pytorch-mat1-and-mat2-must-have-the-same-dtype-mlp</link>
      <description><![CDATA[所以我正在尝试做一个使用 PyTorch 训练 mlp 的函数。
我的代码如下：
def mlp_gradient_descent(x,y, 模型, eta = 1e-6, nb_iter = 30000) :

    损失下降= []
    dtype = torch.float
    设备 = torch.device(“CPU”)
    x = torch.from_numpy(x)
    y = torch.from_numpy(y)

    params = model.parameters()

    学习率 = eta
    对于范围内的 t(nb_iter)：
        y_pred = 模型(x)
        损失 = (y_pred - y).pow(2).sum()
        打印（丢失）
        如果 t % 100 == 99：
            打印（t，loss.item（））
            loss_descent.append([t, loss.item()])
        loss.backward()
        使用 torch.no_grad()：
            对于 params 中的参数：
                param -= Learning_rat*param.grad
            对于 params 中的参数：
                参数=无

我遇到了这个错误：
mat1 和 mat2 必须具有相同的 dtype

请注意：问题来自 model(x)，x 和 y 是 numpy 数组。
谢谢大家。
祝你有美好的一天。]]></description>
      <guid>https://stackoverflow.com/questions/75259774/pytorch-mat1-and-mat2-must-have-the-same-dtype-mlp</guid>
      <pubDate>Fri, 27 Jan 2023 14:54:14 GMT</pubDate>
    </item>
    </channel>
</rss>