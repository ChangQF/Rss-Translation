<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 04 Jan 2024 09:13:39 GMT</lastBuildDate>
    <item>
      <title>使用机器学习的 YAML 文件审查系统</title>
      <link>https://stackoverflow.com/questions/77756484/yaml-file-review-system-using-machine-learning</link>
      <description><![CDATA[想要使用机器学习创建一个 YAML 审核系统。该系统可以分析YAML条目（正确与否），并根据结果得出结果。请就哪种机器学习算法和机器学习框架最适合此目的提出任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/77756484/yaml-file-review-system-using-machine-learning</guid>
      <pubDate>Thu, 04 Jan 2024 07:18:08 GMT</pubDate>
    </item>
    <item>
      <title>多元数据排序算法设计[关闭]</title>
      <link>https://stackoverflow.com/questions/77756234/multivariate-data-ranking-algorithm-design</link>
      <description><![CDATA[目前我已经收集了很多学校的相关数据。每个学校都有教师人数、学生人数、硬件设施等十个评价指标，每个指标的权重我不知道。现在我们想用机器学习算法来自动对高校综合实力进行排名，而不需要参考任何知名的国际排名，比如QS。]]></description>
      <guid>https://stackoverflow.com/questions/77756234/multivariate-data-ranking-algorithm-design</guid>
      <pubDate>Thu, 04 Jan 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>face_recognition 和 pytorch 模块冲突</title>
      <link>https://stackoverflow.com/questions/77755812/face-recognition-and-pytorch-module-conflict</link>
      <description><![CDATA[导入操作系统，pathlib
将streamlit导入为st
导入操作系统、日期时间、json、sys、pathlib、shutil
将 pandas 导入为 pd
将streamlit导入为st
导入CV2
导入人脸识别
将 numpy 导入为 np
从 PIL 导入图像
进口火炬
导入 torch.nn.function 作为 F
从 torch.nn 导入 Linear、Conv2d、BatchNorm1d、BatchNorm2d、PReLU、ReLU、Sigmoid、AdaptiveAvgPool2d、顺序、模块
颜色_暗 = (0, 0, 153)
颜色_白色 = (255, 255, 255)
def BGR_to_RGB(image_in_array):
    返回 cv2.cvtColor(image_in_array, cv2.COLOR_BGR2RGB)
def main():
    #################################################### #
    st.sidebar.header(“关于”)
    st.sidebar.info(“这个网络应用程序提供了访客监控的演示”
                    “使用“面部识别”和 Streamlit 的 Web 应用程序”）
    ####################################################
    ## 读取相机图像
    img_file_buffer = st.camera_input(&quot;拍照&quot;)

    如果 img_file_buffer 不是 None：
        bytes_data = img_file_buffer.getvalue()

        # 将打开文件中的图像转换为 np.array
        image_array = cv2.imdecode(np.frombuffer(bytes_data,
                                                            np.uint8),
                                            CV2.IMREAD_COLOR)
        image_array_copy = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
        # st.image(cv2_img)
        ## 保存访客历史记录

        ## 验证图像
        # 检测加载图像中的人脸
        最大面数 = 0
        rois = [] # 感兴趣区域（面部区域数组）

        ## 从图像中获取人脸位置
        面部位置 = 面部识别.面部位置（图像数组）
        ## 将图像编码为数字格式
        编码CurFrame=face_recognition.face_encodings(image_array,
                                                            面部位置）

        ## 在图像上生成矩形红框
        对于 idx，枚举（face_locations）中的（上、右、下、左）：
            # 保存脸部的感兴趣区域
            rois.append(image_array[上:下,左:右].copy())

            # 在脸部周围画一个框并为其添加标签
            cv2.rectangle(image_array, (左, 上), (右, 下), COLOR_DARK, 2)
            cv2.rectangle(image_array, (左, 下 + 35), (右, 下), COLOR_DARK, cv2.FILLED)
            字体= cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(image_array, f&quot;#{idx}&quot;, (左 + 5, 下 + 25), 字体, .55, COLOR_WHITE, 1)

        ## 显示图像
        st.image(BGR_to_RGB(image_array)，宽度=720)

        ## 识别的人脸数量
        max_faces = len(face_locations)

        如果 max_faces &gt; 0:
            col1, col2 = st.columns(2)

            # 选择图片中选定的面孔
            face_idxs = col1.multiselect(“选择面#”, range(max_faces),
                                            默认=范围(max_faces))

            ## 过滤超出阈值的相似度
            相似度阈值 = col2.slider(&#39;选择相似度阈值&#39;,
                                                    最小值=0.0，最大值=1.0，
                                                    值=0.5）
                                            ## 检查相似性置信度是否大于此阈值

            标志显示=假

#################################################### #####
如果 __name__ == “__main__”：
    主要的（）
#################################################### #####

我不确定为什么当我同时使用 PyTorch 模块和 Face_recognition 模块时我的代码会崩溃而没有任何日志。除了提出这个问题之外，我没有做过任何研究，但我发现只有一次导入其中一个模块时，代码才会运行。
我想创建一个streamlit应用程序，能够拍照并检测其上的面部编码。]]></description>
      <guid>https://stackoverflow.com/questions/77755812/face-recognition-and-pytorch-module-conflict</guid>
      <pubDate>Thu, 04 Jan 2024 03:57:35 GMT</pubDate>
    </item>
    <item>
      <title>Python 中带有否定词的词袋</title>
      <link>https://stackoverflow.com/questions/77755646/bag-of-words-with-negative-words-in-python</link>
      <description><![CDATA[我有这个文件
这不是普通的文本
这是科学术语的文本
这些文档的正文是这样的
&lt;前&gt;&lt;代码&gt;RepID,Txt

1、K9G3P9 4H477 -Q207KL41 98464 ... Q207KL41
2、D84T8X4 -D9W4S2 -D9W4S2 8E8E65 ... D9W4S2
3、-05L8NJ38 K2DD949 0W28DZ48 207441 ... K2D28K84

我可以使用 BOW 算法构建功能集
这是我的代码
def BOW(df):
  CountVec = CountVectorizer() # 仅使用二元组 ngram_range=(2,2)
  Count_data = CountVec.fit_transform(df)
  Count_data = Count_data.astype(np.uint8)
  cv_dataframe=pd.DataFrame(Count_data.toarray(), columns=CountVec.get_feature_names_out(), index=df.index) # &lt;- 这里
  返回 cv_dataframe.astype(np.uint8)

df_reps = pd.read_csv(“c:\\file.csv”)
df = BOW(df_reps[“Txt”])

结果将是“Txt”中的字数。专栏。
&lt;预&gt;&lt;代码&gt;RepID K9G3P9 4H477 -Q207KL41 98464 ... Q207KL41
1 2 8 3 2 ... 1
2 0 1 2 4 ... 2

这里我需要帮助的地方是，其中一些术语前面有一个-，这应该算作负值
因此，如果文本具有这些值Q207KL41 -Q207KL41 -Q207KL41
在这种情况下，以 - 开头的项应计为负数，因此 Q207KL41 的 BOW 为 -1
而不是具有Q207KL41和-Q207KL41的功能
它们都计入相同的术语Q207KL41，但具有正数和负数
所以 BOW 之后的数据集将如下所示
&lt;预&gt;&lt;代码&gt;RepID K9G3P9 4H477 Q207KL41 98464 ...
1 2 8 -2 2 ...
2 0 1 0 4 ...

如何做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/77755646/bag-of-words-with-negative-words-in-python</guid>
      <pubDate>Thu, 04 Jan 2024 02:56:20 GMT</pubDate>
    </item>
    <item>
      <title>Brain.js 可以将一个单词转换为另一个单词吗？</title>
      <link>https://stackoverflow.com/questions/77755432/can-brain-js-convert-one-word-into-another</link>
      <description><![CDATA[我注意到 LSTM 网络可能不适合分类任务，因为它们有时会产生奇怪的输出。所以，我决定看看它们是否适合将常规单词转换为有趣和粗俗的版本，因为“Floptok”社区（说唱歌手 CupcakKe 的粉丝）中有一个模因，他们将普通单词转换为幽默和粗俗的版本一。例如：Reddit = Reddick 或 Jennie = Jennitals。
const net = new Brain.recurrent.LSTM();
常量训练数据= [
{ 输入：“Google”，输出：“Googulp” },
{ 输入：“亚马逊”，输出：“Amoanzon” },
{ 输入：“Alexa”，输出：“Asexa” },
{ 输入：“Cortana”，输出：“Cvmtana” },
{ 输入：“台湾”，输出：“Tightwan” },
{ 输入：“越南”，输出：“Viethong” },
{ 输入：“柬埔寨”，输出：“柬埔寨” },
{ 输入：“马来西亚”，输出：“Moanslaysia” },
{ 输入：“泰国”，输出：“Tightland” },
{ 输入：“菲律宾”，输出：“菲律宾” },
{ 输入：“新加坡”，输出：“新加坡” },
{ 输入：“巧克力”，输出：“Cookcolate” },
// 更多示例（总计：201）
];
net.train(trainingData, { 迭代次数: 5000, log: true });
const result = net.run(“钛”);
// 预期结果：Twatanium
console.log(结果);
// 结果：“Camhoedia”、“TitaniumTighland”、“Coog”或空输出。
`
我做错了什么吗？我的数据集太小了吗？我需要配置一些参数吗？如果有，是哪些？我期待您的回复。
我已经尝试添加更多神经元，但没有发生任何新的情况。]]></description>
      <guid>https://stackoverflow.com/questions/77755432/can-brain-js-convert-one-word-into-another</guid>
      <pubDate>Thu, 04 Jan 2024 01:31:42 GMT</pubDate>
    </item>
    <item>
      <title>DataFrame'对象没有属性'符号</title>
      <link>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</link>
      <description><![CDATA[我想使用机器学习创建股票价格预测，但出现“‘DataFrame’对象没有属性‘符号’”我的错误是什么以及如何修复它
` `将 numpy 导入为 np
      将 pandas 导入为 pd
      从sklearn导入预处理
      从 sklearn.model_selection 导入 train_test_split
      从 sklearn. Linear_model 导入 LinearRegression

      def prepare_data(df,forecast_col,forecast_out,test_size) :
    label = df[forecast_col].shift(-forecast_out) #创建名为 label 的新列，最后 5 行为 nan
         X = np.array(df [[forecast_col]]) #创建特征数组
         X = preprocessing.scale(X) #处理特征数组
         X_lately = X[-forecast_out:] #创建我想稍后在预测方法中使用的列
         X = X[:-forecast_out] # X 将包含训练和测试
         label.dropna(inplace=True) #删除na值
         y = np.array(label) # 分配 Y
         X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=test_size, random_state=0) #交叉验证

        响应 = [X_train,X_test,Y_train,Y_test,X_lately]
        返回响应

    df = pd.read_csv(“GOOG.csv”)
    df = df[df.symbol == &quot;GOOG&quot;]- &quot;错误信息出现的位置&quot;
   Forecast_col = “关闭”
   预测输出 = 5
   

测试大小 = 0,2

X_train、X_test、Y_train、Y_test、X_lately = 准备数据（df、forecast_col、forecast_out、test_size）
学习者 = 线性回归()
learner.fit (X_train,Y_train )
Score=learner.score(X_test,Y_test)#测试线性回归模型
Forecast= learner.predict(X_lately) #将包含预测数据的集合
响应={}#creting json 对象
    响应[&#39;test_score&#39;]=分数
    响应[&#39;forecast_set&#39;]=预测`

打印（响应）`
]]></description>
      <guid>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</guid>
      <pubDate>Thu, 04 Jan 2024 01:24:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在Elasticnet机器学习模型上使用SHAP？</title>
      <link>https://stackoverflow.com/questions/77754925/how-to-use-shap-on-elasticnet-machine-learning-model</link>
      <description><![CDATA[我正在 RStudio 中使用弹性网络 (glmnet) 运行机器学习分析。我想使用 shapr 包来查找我的模型的预测蛋白。我用 5 次重复和 5 次折叠训练了我的模型，然后基于此训练了最终模型。下面是我使用的代码。我遇到的问题是 shapr 不能在自定义模型上使用。与 Xgboost 相比，我更喜欢 Elastic Net，我认为它希望我使用 Elastic Net。
库(glmnet)
库（pROC）
图书馆（夏普）
库（插入符号）

#计算 SHAP（内核）以确定哪些特征对该模型很重要
#使用高斯方法

解释器 &lt;- shapr(train_data, Final_model)

target_variable &lt;- as.numeric(target_variable)

p &lt;- 平均值（目标变量）

解释高斯 &lt;- 解释（
  测试数据，
  方法=“高斯”，
  解释者 = 解释者,
  预测_零 = p
）

#绘制观察结果 1 和 6 的解释

绘图（解释高斯，plot_phi0 = FALSE，index_x_test = c（1, 6））

get_model_specs(model) 中的错误：
  您将模型传递给 shapr，但本机不支持该模型 请参阅 ?shapr::shapr 或小插图
有关如何使用自定义模型运行 shapr 的更多信息。
]]></description>
      <guid>https://stackoverflow.com/questions/77754925/how-to-use-shap-on-elasticnet-machine-learning-model</guid>
      <pubDate>Wed, 03 Jan 2024 22:22:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 html 将逗号分隔值插入 numpy 数组中进行预测</title>
      <link>https://stackoverflow.com/questions/77753838/how-to-use-html-to-insert-comma-seperated-values-into-a-numpy-array-for-predicti</link>
      <description><![CDATA[我试过了
&lt;输入类型=“文本” name=“n1”&gt;&lt;/td&gt;

接受输入。
&lt;预&gt;&lt;代码&gt;17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0。 01587,0.03003,0.006193,25.38,17.33, 184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189

我将其输入到 view.py 中的 numpy 数组中。
np.array((request.GET[&#39;n1&#39;]))

但我收到以下错误消息。
/预测/输出处的值错误
预期是二维数组，却得到一维数组：
数组=[&#39;17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01 587,0.03003,0.006193,25.38,17.33,184.6, 2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189&#39;]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

view.py（v1 = np.array((request.GET[&#39;n1&#39;])) 在第 8 行）
def 输出（请求）：
    dff = pd.read_csv(r&#39;C:\Users\Downloads\data.csv&#39;)
    y = dff[&#39;诊断&#39;].值
    x = dff.drop(&#39;诊断&#39;, axis=1).values
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.40)
    模型=逻辑回归()
    model.fit(x_train, y_train)
    v1 = np.array((request.GET[&#39;n1&#39;]))

pred = model.predict([v1])
    pred1 = &quot;&quot;;
    如果 pred==[1]:
        pred1 =“阳性”
    别的：
        pred1 =“阴性”
return render(request, &#39;prediction.html&#39;, {&quot;predictResult&quot;:**pred1**})


prediction.html（第6行是获取输入）
;
    &lt;表单动作＝“输出”&gt;
        &lt;表&gt;
            &lt;tr&gt;
                &lt;tdalign=“右”&gt;怀孕&lt;/td&gt;
               &lt;输入类型=“文本” name=“n1”&gt;&lt;/td&gt;
            
    &lt;/表&gt;
     &lt;输入类型=“提交”&gt;
    &lt;/表格&gt;

    结果：{{ 预测结果 }}

]]></description>
      <guid>https://stackoverflow.com/questions/77753838/how-to-use-html-to-insert-comma-seperated-values-into-a-numpy-array-for-predicti</guid>
      <pubDate>Wed, 03 Jan 2024 18:02:59 GMT</pubDate>
    </item>
    <item>
      <title>用于具有非常小的值的回归问题的度量[关闭]</title>
      <link>https://stackoverflow.com/questions/77753161/metric-to-use-for-regression-problems-with-very-small-values</link>
      <description><![CDATA[我正在研究一个回归问题，目标列中的值范围在 0.01 到 0.1 之间。我正在尝试找到正确的指标来评估训练模型的性能。
r2 分数似乎不太适合它。任何人都可以为这种情况推荐一个吗？]]></description>
      <guid>https://stackoverflow.com/questions/77753161/metric-to-use-for-regression-problems-with-very-small-values</guid>
      <pubDate>Wed, 03 Jan 2024 16:08:24 GMT</pubDate>
    </item>
    <item>
      <title>用于支持向量数据描述的Python包[关闭]</title>
      <link>https://stackoverflow.com/questions/77752655/python-package-for-support-vector-data-description</link>
      <description><![CDATA[在寻找支持向量数据描述（SVDD）代码示例时，我发现了这个代码示例页面，其中 SVDD 显示为实用程序，可能位于 python 中的包 libsvm 下。但在包手册页中发现没有类似的东西存在。我发现的其他软件包是 libsvm-svdd 和 SVDD-python 但我无法按照描述使用它们。请建议一个可用的 SVDD 包，我将在疾病数据的研究工作中使用它。]]></description>
      <guid>https://stackoverflow.com/questions/77752655/python-package-for-support-vector-data-description</guid>
      <pubDate>Wed, 03 Jan 2024 14:43:53 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 中使用 StandardScaler 时 CustomScaler 中出现类型错误</title>
      <link>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</link>
      <description><![CDATA[我在使用 scikit-learn 的 Python 中遇到自定义缩放器类的问题。我有一个继承自 BaseEstimator 和 TransformerMixin 的 CustomScaler 类，它使用 StandardScaler。但是，我在初始化过程中遇到了类型错误。相关代码如下：
从 sklearn.base 导入 BaseEstimator、TransformerMixin
从 sklearn.preprocessing 导入 StandardScaler

类 CustomScaler(BaseEstimator,TransformerMixin):
    
    def __init__(self,columns,copy=True,with_mean=True,with_std=True):
        self.scaler = StandardScaler(复制,with_mean,with_std)
        self.columns = 列
        self.mean_ = 无
        self.var_ = 无

    def fit(self, X, y=None):
        self.scaler.fit(X[self.columns], y)
        self.mean_ = np.mean(X[self.columns])
        self.var_ = np.var(X[self.columns])
        返回自我

    def 变换（自身，X，y=无，复制=无）：
        init_col_order = X.列
        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)
        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]
        返回 pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]


unscaled_input.columns.values
columns_to_scale = [&#39;月份值&#39;,
       “星期几”、“交通费用”、“上班距离”、
       ‘年龄’、‘每日平均工作负荷’、‘体重指数’、‘儿童’、‘宠物’]

absenteeism_scaler = CustomScaler(columns= columns_to_scale) // 这一步出错
缺席主义_scaler.fit（unscaled_input）

我检查了 StandardScaler 类的 scikit-learn 文档以确保正确使用，但我找不到此错误的任何解决方案。
什么可能导致此问题？有其他方法可以解决这个问题吗？
错误消息：
TypeError Traceback（最近一次调用最后一次）
单元格 In[24]，第 1 行
----&gt; 1 缺勤缩放器 = CustomScaler(columns_to_scale)

Cell In[20]，第 7 行，在 CustomScaler.__init__(self, columns, copy, with_mean, with_std)
      6 def __init__(self, columns, copy=True, with_mean=True, with_std=True):
----&gt; 7 self.scaler = StandardScaler(copy, with_mean, with_std)
      8 self.columns = 列
      9 self.mean_ = 无

TypeError: __init__() 采用 1 个位置参数，但给出了 4 个
]]></description>
      <guid>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</guid>
      <pubDate>Wed, 03 Jan 2024 10:34:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用GPT-2计算单词和句子嵌入？</title>
      <link>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</link>
      <description><![CDATA[我正在开发一个使用 GPT-2（特别是 GPT2Model 类）计算单词和句子嵌入的程序。对于词嵌入，我在转发 input_ids 后提取最后一个隐藏状态 outputs[0]，其形状为 batch size x seq len ，到 GPT2Model 类。至于句子嵌入，我在序列末尾提取单词的隐藏状态。这是我尝试过的代码：
从变压器导入 GPT2Tokenizer、GPT2Model
进口火炬

tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)
模型 = GPT2Model.from_pretrained(&#39;gpt2&#39;)
Captions = [“示例标题”、“示例鸟”、“鸟是黄色的，有红色翅膀”、“嗨”、“非常好”]

encoded_captions = [tokenizer.encode(caption) 用于字幕中的字幕]

# 用 0 将序列填充到相同的长度
max_len = max(len(seq) 用于编码字幕中的 seq)
padded_captions = [seq + [0] * (max_len - len(seq)) 对于encoded_captions中的seq]

# 转换为批量大小为 5 的 PyTorch 张量
input_ids = torch.tensor(padded_captions)

输出=模型(input_ids)
word_embedding = 输出[0].连续()
句子嵌入 = word_embedding[ :, -1, : ].contigious()


我不确定我对单词和句子嵌入的计算是否正确，有人可以帮我确认一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</guid>
      <pubDate>Tue, 02 Jan 2024 21:55:52 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Keras ValueError：“predict_function”的意外结果（空batch_outputs）</title>
      <link>https://stackoverflow.com/questions/77745874/tensorflow-keras-valueerror-unexpected-result-of-predict-function-empty-batc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77745874/tensorflow-keras-valueerror-unexpected-result-of-predict-function-empty-batc</guid>
      <pubDate>Tue, 02 Jan 2024 11:47:52 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：无法打开 shape_predictor_68_face_landmarks.dat，但没有任何帖子有帮助</title>
      <link>https://stackoverflow.com/questions/76096228/runtimeerror-unable-to-open-shape-predictor-68-face-landmarks-dat-but-none-of</link>
      <description><![CDATA[导入 dlib
导入CV2

# 加载检测器
检测器 = dlib.get_frontal_face_ detector()

# 加载预测器
预测器 = dlib.shape_predictor(“shape_predictor_68_face_landmarks.dat”)

# 加载图像
图片 = cv2.imread(“32_172.jpg.jpg”)

# 将图像转换为灰度图
灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

# 检测图像中的人脸
面孔 = 探测器（灰色）

# 循环脸部
对于面孔中的面孔：
    # 获取方框 d 中脸部的标志/部位。
    地标 = 预测器（灰色，脸部）

    # 循环地标并将它们绘制在原始图像上
    对于范围 (0, 68) 内的 n：
        x = 地标.part(n).x
        y = 地标.part(n).y
        cv2.circle(图像, (x, y), 1, (0, 255, 0), -1)

# 显示带有面部标志的图像
cv2.imshow(“面部标志”，图像)
cv2.waitKey(0)

代码在这里，我试图从图像中提取特征，但错误不断出现。我尝试了堆栈中的一些东西，但它不起作用。顺便说一句，我正在使用 jupyter 笔记本
!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 # 下载链接

!bunzip2 /content/shape_predictor_68_face_landmarks.dat.bz2

datFile =“/content/shape_predictor_68_face_landmarks.dat”

我尝试运行它们，但没有帮助]]></description>
      <guid>https://stackoverflow.com/questions/76096228/runtimeerror-unable-to-open-shape-predictor-68-face-landmarks-dat-but-none-of</guid>
      <pubDate>Mon, 24 Apr 2023 21:27:01 GMT</pubDate>
    </item>
    <item>
      <title>开始微调时的损失高于迁移学习的损失</title>
      <link>https://stackoverflow.com/questions/72548173/loss-when-starting-fine-tuning-is-higher-than-loss-from-transfer-learning</link>
      <description><![CDATA[由于我开始使用通过迁移学习学到的权重进行微调，我预计损失会相同或更少。然而，看起来它开始使用一组不同的起始权重进行微调。
启动迁移学习的代码：
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                              include_top=假，
                                              权重=&#39;imagenet&#39;）
base_model.trainable = False

模型 = tf.keras.Sequential([
  基本模型，
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(单位=3，激活=&#39;sigmoid&#39;)
]）

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

历元 = 1000
回调= tf.keras.callbacks.EarlyStopping（耐心= 10，restore_best_weights = True）
历史 = model.fit(train_generator,
                    steps_per_epoch=len(train_generator),
                    纪元=纪元，
                    验证数据=val_generator，
                    验证步骤=len(val_generator),
                    回调=[回调],)

上一个纪元的输出：
纪元 29/1000
232/232 [================================] - 492s 2s/步 - 损失：0.1298 - 准确度：0.8940 - val_loss ：0.1220 - val_accuracy：0.8937

开始微调的代码：
model.trainable = True

# 从这一层开始进行微调
微调 = -20

# 冻结 `fine_tune_at` 层之前的所有层
对于 model.layers[:fine_tune_at] 中的图层：
  可训练层 = False

model.compile(优化器=tf.keras.optimizers.Adam(1e-5),
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

History_fine = model.fit(train_generator,
                         steps_per_epoch=len(train_generator),
                         纪元=纪元，
                         验证数据=val_generator，
                         验证步骤=len(val_generator),
                         回调=[回调],)

但这就是我在前几个时期看到的情况：
纪元 1/1000
232/232 [==============================] - ETA：0秒 - 损失：0.3459 - 准确度：0.8409/usr/ local/lib/python3.7/dist-packages/PIL/Image.py:960：UserWarning：以字节表示透明度的调色板图像应转换为 RGBA 图像
  “以字节表示透明度的调色板图像应该是”
232/232 [==============================] - 509s 2s/步 - 损失：0.3459 - 准确度：0.8409 - val_loss ：0.7755 - val_accuracy：0.7262
纪元 2/1000
232/232 [================================] - 502s 2s/步 - 损失：0.1889 - 准确度：0.9066 - val_loss ：0.5628 - val_accuracy：0.8881

最终损失下降并超过了迁移学习损失：
纪元 87/1000
232/232 [================================] - 521s 2s/步 - 损失：0.0232 - 准确度：0.8312 - val_loss ：0.0481 - val_accuracy：0.8563

为什么第一个微调时期的损失高于迁移学习的最后一个损失？]]></description>
      <guid>https://stackoverflow.com/questions/72548173/loss-when-starting-fine-tuning-is-higher-than-loss-from-transfer-learning</guid>
      <pubDate>Wed, 08 Jun 2022 15:12:54 GMT</pubDate>
    </item>
    </channel>
</rss>