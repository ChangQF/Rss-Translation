<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 02 Aug 2024 21:15:23 GMT</lastBuildDate>
    <item>
      <title>如何针对 JavaScript 框架微调轻量级 LLM？</title>
      <link>https://stackoverflow.com/questions/78827245/how-can-i-fine-tune-a-lightweight-llm-specifically-for-javascript-frameworks</link>
      <description><![CDATA[我做技术架构师已经很多年了，但对机器学习还是个新手。我需要专门针对 JavaScript 堆栈微调一个模型。目前，所有大型 LLM 都是通用的，但我想要一个只针对我每天使用的 JavaScript 框架进行训练的自定义模型。我的目标是拥有一个小型、高效的模型，它可以在我的 MacBook Pro 上运行，并严格协助完成编码任务。以下是我正在寻找的具体功能：

代码完成
代码说明
代码文档（可选）
代码审查和优化建议（基于最佳实践）
错误查找和修复
特定于框架的响应（例如，指定时响应仅限于 Express.js）
针对编码问题的交互式问答
了解我的代码库并提供上下文答案

我的目标是使其成为一个开源项目，而不依赖主要提供商的昂贵解决方案。以下是我对社区的具体问题：

基础模型选择：我应该选择哪种基础模型？该模型应该是轻量级的，能够进行微调，并且针对编码任务进行了优化，没有不必要的功能。
指导与基础模型：如果我想与它进行对话式交互，我应该选择基础模型还是指导就绪模型？
微调方法：根据我的需求微调模型的最佳方法是什么？
训练资源：训练模型的最佳资源是什么？
数据集：我应该使用哪些数据集进行训练，包括最佳实践文档？我找到了SRI Lab 的 150k JavaScript 数据集，但我不确定它的质量。有人可以提供见解或推荐其他数据集吗？
硬件要求：我有一台 MacBook Pro M2，内存为 32 GB。这足以进行训练吗？还是我需要付费解决方案？如果是这样，您会推荐哪些经济实惠的解决方案？
其他注意事项：在此过程中我还应该考虑其他因素吗？

提前感谢您的支持！]]></description>
      <guid>https://stackoverflow.com/questions/78827245/how-can-i-fine-tune-a-lightweight-llm-specifically-for-javascript-frameworks</guid>
      <pubDate>Fri, 02 Aug 2024 21:08:50 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中影响年度数据的多个月份模型</title>
      <link>https://stackoverflow.com/questions/78827204/model-for-multiple-months-that-impact-an-annual-number-in-machine-learning</link>
      <description><![CDATA[我正在寻找一种机器学习模型的建议，该模型可以解决我即将概述的问题。我最熟悉的两个模型是线性回归和逻辑回归，但似乎不是合适的模型。
我试图预测每月天气数据如何影响年度苹果产量。每个月都有自己的一组天气变量（降雨量、低温、平均温度和高温），一年中月份的组合会影响年产量。我有 X 年的月度数据，年份目前也是我数据中的一个变量。
然而，在设置数据时，使用线性回归将相同数量的年度苹果分配给给定年份的每个月是行不通的，因为模型认为变量的波动不会影响产量，因为它们都被分配了相同的生产值（澄清一下，这是因为每个月的年份都相同）。
有没有什么办法可以解决这个问题，或者我应该使用什么模型？我本质上希望有可能有一个字典数据框，其中模型接收 12 个字典输入（我知道这实际上没有什么意义），以便将每个月对全年苹果产量的影响考虑在内。
谢谢！
（我尝试了线性回归，它基本上将所有类别的权重视为具有完全相同的影响，具有负的 r 平方值，并预测我输入的年份月份和天气条件下的苹果产量为负数！这也让我回想起，我怎样才能输入所有 12 个月，而不是在预测全年时只选择一个？）]]></description>
      <guid>https://stackoverflow.com/questions/78827204/model-for-multiple-months-that-impact-an-annual-number-in-machine-learning</guid>
      <pubDate>Fri, 02 Aug 2024 20:52:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中使用 WordNet 查找或训练分层数据的 Mamba 模型</title>
      <link>https://stackoverflow.com/questions/78826929/how-to-find-or-train-a-mamba-model-for-hierarchical-data-using-wordnet-in-python</link>
      <description><![CDATA[我正在用 Python 开发一个机器学习项目，涉及表示来自 WordNet 的分层数据。我对此目的感兴趣，因为它适用于分层结构，因此我有兴趣使用 Mamba 模型。
我需要帮助：
我正在寻找一个预先训练好的 Mamba 模型，该模型专门针对 WordNet 数据进行训练。有人知道是否有这样的模型，或者如果没有，我该如何训练它？
我尝试过的方法：

我在 Hugging Face 和其他 ML 模型存储库中搜索过，但没有找到在 WordNet 上训练的明确提及为“Mamba”的模型。
我尝试在 WordNet 的一个子集上训练一个基本的图形神经网络模型，但我不确定我是否走在正确的轨道上。
]]></description>
      <guid>https://stackoverflow.com/questions/78826929/how-to-find-or-train-a-mamba-model-for-hierarchical-data-using-wordnet-in-python</guid>
      <pubDate>Fri, 02 Aug 2024 19:14:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么在时间序列机器学习模型中以一阶差分而不是实际变量为目标？</title>
      <link>https://stackoverflow.com/questions/78826341/why-target-the-first-difference-instead-of-the-actual-variable-in-time-series-ma</link>
      <description><![CDATA[我正在使用 LSTM 和 ANN 模型进行时间序列预测项目，我遇到的建议是，我应该以时间序列数据的一阶差分而不是实际变量为目标。
我熟悉差分以实现平稳性的概念，但我不确定为什么在使用具有滞后特征的 LSTM 和 ANN 等机器学习模型时特别推荐此步骤。
在我的实验中，当我使用实际变量而不是一阶差分作为目标时，指标似乎更好。
实际变量作为目标变量
一阶差分作为目标变量]]></description>
      <guid>https://stackoverflow.com/questions/78826341/why-target-the-first-difference-instead-of-the-actual-variable-in-time-series-ma</guid>
      <pubDate>Fri, 02 Aug 2024 16:02:27 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 ApplePersistenceIgnoreState 错误？</title>
      <link>https://stackoverflow.com/questions/78826248/how-to-fix-applepersistenceignorestate-error</link>
      <description><![CDATA[我正在学习一个关于如何使用神经网络进行图像分类的 Neuralnine 教程。
我正在使用 Imac。
下面是代码：
import cv2 as cv
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import datasets, layer, models
#准备数据
(training_images, training_labels), (testing_images, testing_labels) = datasets.cifar10.load_data()
training_images, testing_images = training_images / 255, testing_images / 255

class_names = [&#39;Plane&#39;, &#39;Car&#39;, &#39;Bird&#39;, &#39;Cat&#39;, &#39;Deer&#39;, &#39;Dog&#39;, &#39;Frog&#39;, &#39;Horse&#39;, &#39;Ship&#39;, &#39;Truck&#39;]

for i in range(16):
plt.subplot(4,4,i+1)
plt.xticks([])
plt.yticks([])
plt.imshow(training_images[i], cmap=plt.cm.binary)
plt.xlabel(class_names[training_labels[i][0]])

plt.show()

training_images = training_images[:5000] #节省时间
training_labels = training_labels[:5000]
testing_images = testing_images[:4000]
testing_labels = testing_labels[:4000]

model = models.Sequential()
model.add(layers.Conv2D(32, (3,3),activation=&#39;relu&#39;, input_shape=(32,32,3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3),激活=&#39;relu&#39;))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64, (3,3), 激活=&#39;relu&#39;))
model.add(layers.Flatten())
model.add(layers.Dense(64, 激活=&#39;relu&#39;))
model.add(layers.Dense(10, 激活=&#39;softmax&#39;))

model.compile(optimizer=&#39;adam&#39;, loss=&#39;sparse_categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

model.fit(training_images, training_labels, epochs=10, validation_data=(testing_images, testing_labels))

我在终端中收到以下消息：
ApplePersistenceIgnoreState：现有状态将不会已触及。新状态将写入 /var/folders/2g/.../T/org.python.python.savedState
2024-08-02 16:29:19.788 Python[48146:6869495] 警告：未启用可恢复状态的安全编码！通过实现 NSApplicationDelegate.applicationSupportsSecureRestorableState: 并返回 YES 来启用安全编码。

完全不知道该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/78826248/how-to-fix-applepersistenceignorestate-error</guid>
      <pubDate>Fri, 02 Aug 2024 15:36:34 GMT</pubDate>
    </item>
    <item>
      <title>如何优化 SageMaker/Hugging Face 端点以生成 Cypher 查询？</title>
      <link>https://stackoverflow.com/questions/78826111/how-to-optimize-sagemaker-hugging-face-endpoint-for-cypher-query-generation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78826111/how-to-optimize-sagemaker-hugging-face-endpoint-for-cypher-query-generation</guid>
      <pubDate>Fri, 02 Aug 2024 15:00:50 GMT</pubDate>
    </item>
    <item>
      <title>分类器 ML 基于特征和连续变量值预测类别的算法</title>
      <link>https://stackoverflow.com/questions/78825453/classifier-ml-algorithm-for-predicting-class-based-on-features-and-the-value-of</link>
      <description><![CDATA[我正在尝试编写一个分类器，我可以训练它来查看问题实例，并根据其特征和特定变量的值预测问题属于哪个类。我不是在寻找问题的答案，而只是寻找一些关于我应该专注于研究哪种 ML 算法的指导。
这是一个示例问题。假设我们有一些蛋糕食谱。它们具有以下连续变量特征：

面粉量
牛奶量
鸡蛋数量
糖的量

我们还有一个二进制变量：

蛋糕是用燃气还是电烤箱烤的？ （假设燃气为 1，电为 0）
每个食谱都烹制了两次，一次使用燃气，一次使用电

还通过让一些人吃蛋糕来测试蛋糕，每个人都给每个蛋糕一个“美味”指数。这也是一个连续变量，值越高，人们就越喜欢这个蛋糕。
我多次运行这个程序，最终得到一个数据集，每个食谱有两个条目（一个燃气，一个电），每个食谱都有各自的“美味指数”。我们会发现，对于每道菜谱，人们倾向于用燃气或电烹饪，这反映在口味指数中。
现在，我知道这是不现实的，但这是一种说明我想做什么的简单方法。
在训练系统执行此操作后，我现在想让系统采用一种新食谱，并根据具有相似（不一定相同）特征的过去食谱以及燃气或电是否提供最高的口味指数来预测应该使用燃气还是电烹饪。
任何关于哪种机器学习算法最适合此任务的建议都将不胜感激。如前所述，我只是想缩小我的研究范围，而不一定是被灌输答案。
到目前为止，我已经使用 Scikit-learn 在 Python 中尝试了几种 ML 算法。事实证明，KNN 在基于特征预测类别方面最准确，但我不确定如何将“口味指数”反映到其中。此外，这似乎是监督机器学习的一个例子，因为数据被标记（天然气或电力）。]]></description>
      <guid>https://stackoverflow.com/questions/78825453/classifier-ml-algorithm-for-predicting-class-based-on-features-and-the-value-of</guid>
      <pubDate>Fri, 02 Aug 2024 12:17:07 GMT</pubDate>
    </item>
    <item>
      <title>如何通过调整函数的一个输入参数来训练函数输出正确的值（基于训练数据）？[关闭]</title>
      <link>https://stackoverflow.com/questions/78824490/how-to-train-a-function-to-output-a-correct-value-based-on-training-data-by-ad</link>
      <description><![CDATA[我是机器学习的新手。我有一个项目，需要帮助选择合适的机器学习算法。
我有一个包含三个输入（x、y 和 N）的函数：
F(x, y, N) → R
我希望软件自动调整并给出 N 的值（基于输入值 x 和 y），以便函数给出正确的值 R。
我有一个如下所示的训练数据集：



x
y
R




7
2
20


8
5
6


15
6
13


...
...



你对我应该寻找哪种合适的机器学习算法？如果神经网络合适，您对从多少层/节点开始有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78824490/how-to-train-a-function-to-output-a-correct-value-based-on-training-data-by-ad</guid>
      <pubDate>Fri, 02 Aug 2024 08:29:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么我用 Python 实现的 Skip-Gram 产生了错误的结果？</title>
      <link>https://stackoverflow.com/questions/78824197/why-is-my-skip-gram-implementation-in-python-producing-incorrect-results</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78824197/why-is-my-skip-gram-implementation-in-python-producing-incorrect-results</guid>
      <pubDate>Fri, 02 Aug 2024 07:15:07 GMT</pubDate>
    </item>
    <item>
      <title>更清晰的分割 SAM (Segment Anything)</title>
      <link>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</link>
      <description><![CDATA[我需要像这样分割图像上的对象：
图像 1
图像 2
我选择使用 Meta 的 AI SAM（Segment Anything）来裁剪这些对象。
我的代码如下所示：
import cv2
import numpy as np
import sys, os
from pathlib import Path
import torch
import surveillance as sv
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor

# 获取命令行参数
num = sys.argv[2]
img_path = sys.argv[1]
folder_path = sys.argv[3]

# 从给定路径加载图像
img = cv2.imread(img_path)

# 用于预处理图像以进行裁剪的函数
def preprocess_image_cut(img):
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
return gray

# 用于获取干净图像的函数
def get_clean_image(img, filter_level=1):
gray = preprocess_image_cut(img)
blurred_image = cv2.GaussianBlur(gray, (3, 3), 0)
_, binary_image = cv2.threshold(blurred_image, 210, 255, cv2.THRESH_BINARY)

kernel = np.ones((1, 1), np.uint8)
result_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)
result_image = cv2.medianBlur(result_image, filter_level)

output_image = cv2.bitwise_or(gray, result_image)
return output_image

# 设置管道的函数
def setup_pipeline():
HOME = &#39;C:/&#39;
CHECKPOINT_PATH = os.path.join(HOME, &#39;weights&#39;, &#39;sam_vit_h_4b8939.pth&#39;)
DEVICE = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
MODEL_TYPE = &quot;vit_h&quot;

sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)
mask_generator = SamAutomaticMaskGenerator(sam)
return mask_generator

# 运行 SAM 模型的函数
def run_sam(mask_generator, clean_image):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
sam_result = mask_generator.generate(image_rgb)
mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)
detections = sv.Detections.from_sam(sam_result=sam_result)

annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)

masks = [mask[&#39;segmentation&#39;] for mask in sorted(sam_result, key=lambda x: x[&#39;area&#39;, reverse=True])]
return mask

# 设置掩码生成器
mask_generator = setup_pipeline()

if __name__ == &quot;__main__&quot;:
if img_path.endswith(&quot;.png&quot;):
save_path = folder_path
os.makedirs(save_path, exist_ok=True)
if os.path.isdir(f&#39;{folder_path}/PROCESSED&#39;):
os.makedirs(f&#39;{folder_path}/PROCESSED&#39;, exist_ok=True)
img = cv2.imread(img_path)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
clean_image = get_clean_image(img, 3)

print(&quot;开始生成掩码&quot;)
mask = run_sam(mask_generator, clean_image)

for i, mask in enumerate(masks):
image_rgb = cv2.cvtColor(clean_image, cv2.COLOR_BGR2RGB)
image_bgra = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGRA)
extract_region = np.zeros_like(image_bgra)
extract_region[mask] = image_bgra[mask]
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
extract_region = extract_region[y:y+h, x:x+w]
extracted_region[:, :, 3] = (mask[y:y+h, x:x+w] &gt; 0) * 255
save_path2 = f&#39;{folder_path}/PROCESSED/img_{x}_{y}_{w}_{h}.png&#39;
cv2.imwrite(save_path2, extracted_region)

print(&quot;Finished&quot;)

但我在一些问题上遇到了困难，比如我不想让 Sam 分割数字，也不想分割将对象与数字联系起来的线条。
有人能就这个问题提出一些想法吗？也接受其他方法来分割图像。]]></description>
      <guid>https://stackoverflow.com/questions/78822914/sharper-segmentation-sam-segment-anything</guid>
      <pubDate>Thu, 01 Aug 2024 20:21:17 GMT</pubDate>
    </item>
    <item>
      <title>Pyannote：离线加载并应用说话人区分</title>
      <link>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</link>
      <description><![CDATA[我尝试离线使用 Pyannotes 模型。
我是这样加载和应用模型的：
from pyannote.audio import Pipeline

access_token = &#39;xxxxxxxxxxx&#39;

model = Pipeline.from_pretrained(
&quot;pyannote/speaker-diarization-3.1&quot;,
use_auth_token=access_token)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

这样就没问题了。
但是现在我按照离线使用的说明操作：https://github.com/pyannote/pyannote-audio/blob/develop/tutorials/applying_a_pipeline.ipynb
我的目录结构如下：
src-
     |-pyannote_offline_config.yaml
     |-pyannote_pytorch_model.bin
---- YAML ----
version: 3.1.0

pipeline:
name: pyannote.audio.pipelines.SpeakerDiarization
params:
clustering: AgglomerativeClustering
embedding: pyannote/wespeaker-voxceleb-resnet34-LM
embedding_batch_size: 32
embedding_exclude_overlap: true
分段：src/pyannote_pytorch_model.bin
分段批处理大小：32

参数：
聚类：
方法：质心
min_cluster_size：12
阈值：0.7045654963945799
分段：
min_duration_off：0.0

---- 正在加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但结果却是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
好的，下次尝试：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

params = {&#39;clustering&#39;:
{&#39;method&#39;: &#39;centroid&#39;,
&#39;min_cluster_size&#39;: 12,
&#39;threshold&#39;: 0.7045654963945799},
&#39;segmentation&#39;:
{&#39;min_duration_off&#39;: 0.0}}

pipeline = model.instantiate(params)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

pipeline(path_in,
num_speakers=num_speakers).labels()

但结果是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
我不明白问题所在。
如果我这样做，它就会起作用：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;, path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但上传到 gitlab 后，测试管道显示：“无法下载‘pyannote/speaker-diarization-3.1’管道。
这可能是因为管道是私有的或封闭的，因此请确保进行身份验证。访问 https://hf.co/settings/tokens
创建您的访问令牌并重试：
Pipeline.from_pretrained(&#39;pyannote/speaker-diarization-3.1&#39;,
... use_auth_token=YOUR_AUTH_TOKEN)&quot;
因此，似乎我的本地计算机上有一些东西没有通过 pip 安装下载。例如，如果我不使用 yaml 加载它，而只使用 model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;)，它也会起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</guid>
      <pubDate>Thu, 01 Aug 2024 12:28:41 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 llama 3 8b 训练 LLaVA-NeXT</title>
      <link>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</guid>
      <pubDate>Thu, 01 Aug 2024 11:56:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在人工神经网络中进行样本外预测？</title>
      <link>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820463/how-to-make-out-of-sample-forecast-in-artificial-neural-network</guid>
      <pubDate>Thu, 01 Aug 2024 10:36:16 GMT</pubDate>
    </item>
    <item>
      <title>NotImplementedError：无法将符号张量（up_sampling2d_4_target：0）转换为 numpy 数组</title>
      <link>https://stackoverflow.com/questions/60430561/notimplementederror-cannot-convert-a-symbolic-tensor-up-sampling2d-4-target0</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/60430561/notimplementederror-cannot-convert-a-symbolic-tensor-up-sampling2d-4-target0</guid>
      <pubDate>Thu, 27 Feb 2020 09:59:10 GMT</pubDate>
    </item>
    <item>
      <title>NotFittedError：估计器不适合，在利用模型之前调用“fit”</title>
      <link>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</link>
      <description><![CDATA[我在 Macbook OSX 10.2.1 (Sierra) 上运行 Python 3.5.2。
尝试运行 Kaggle 的 Titanic 数据集的一些代码时，我不断收到以下错误：


NotFittedError Traceback (most recent call
last) in ()
6 
7 # 使用测试集进行预测并打印它们。
----&gt; 8 my_prediction = my_tree_one.predict(test_features)
9 print(my_prediction)
10 
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
在 _validate_X_predict(self, X, check_input) 中
429 &quot;&quot;&quot;
430 
--&gt; 431 X = self._validate_X_predict(X, check_input)
432 proba = self.tree_.predict(X)
433 n_samples = X.shape[0]
/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/tree/tree.py
在 _validate_X_predict(self, X, check_input)
386 “”“每当有人试图预测、应用、predict_proba 时验证 X”””
387 if self.tree_ is None:
--&gt; 388 raise NotFittedError(“估算器未安装，&quot;
389 “在利用模型之前调用 fit。”)
390 
NotFittedError：估算器未安装，在利用
模型之前调用 fit。

有问题的代码似乎是这样的：
# 用中位数估算缺失值
test.Fare[152] = test.Fare.median()

# 从测试集中提取特征：Pclass、Sex、Age 和 Fare。
test_features = test[[&quot;Pclass&quot;, &quot;Sex&quot;, &quot;Age&quot;, &quot;Fare&quot;]].values

# 使用测试集进行预测并打印。
my_prediction = my_tree_one.predict(test_features)
print(my_prediction)

# 创建一个包含两列的数据框：PassengerId 和 Survived。 Survived 包含您的预测
PassengerId =np.array(test[&quot;PassengerId&quot;]).astype(int)
my_solution = pd.DataFrame(my_prediction, PassengerId, columns = [&quot;Survived&quot;])
print(my_solution)

# 检查您的数据框是否有 418 个条目
print(my_solution.shape)

# 将您的解决方案写入名为 my_solution.csv 的 csv 文件
my_solution.to_csv(&quot;my_solution_one.csv&quot;, index_label = [&quot;PassengerId&quot;])

以下是其余部分的链接 代码。
由于我已经调用了“fit”函数，我无法理解此错误消息。我哪里做错了？感谢您的时间。
编辑：
结果发现该问题继承自上一个代码块。
# 拟合您的第一个决策树：my_tree_one
my_tree_one = tree.DecisionTreeClassifier()
my_tree_one = my_tree_one.fit(features_one, target)

# 查看所包含特征的重要性和分数
print(my_tree_one.feature_importances_)
print(my_tree_one.score(features_one, target))

使用以下行：
my_tree_one = my_tree_one.fit(features_one, target)
生成错误：

ValueError：输入包含 NaN、无穷大或对于
dtype(&#39;float32&#39;)。
]]></description>
      <guid>https://stackoverflow.com/questions/40937543/notfittederror-estimator-not-fitted-call-fit-before-exploiting-the-model</guid>
      <pubDate>Fri, 02 Dec 2016 17:10:22 GMT</pubDate>
    </item>
    </channel>
</rss>