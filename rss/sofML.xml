<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 05 Mar 2024 09:13:30 GMT</lastBuildDate>
    <item>
      <title>如何部署机器学习算法</title>
      <link>https://stackoverflow.com/questions/78106414/how-to-deploy-machine-learning-algorithm</link>
      <description><![CDATA[所以我有一个 ML 算法，它使用两个文本之间的余弦相似度并返回相似度分数，我的问题是我们可以像在 aws sagemaker 或任何 EC2 实例上部署机器学习模型一样部署这个算法吗？没有训练脚本，也没有 model.pkl 文件，因为这纯粹是一种算法，我在其中获取文本输入并匹配存储在 postgres 数据库中的文本......
我们有什么办法可以实现这一点，或者我需要将此代码合并到我的后端逻辑中以部署在 AWS 上？
我尝试使用MLflow来达到预期的结果，但所有的努力都是徒劳的。]]></description>
      <guid>https://stackoverflow.com/questions/78106414/how-to-deploy-machine-learning-algorithm</guid>
      <pubDate>Tue, 05 Mar 2024 08:52:29 GMT</pubDate>
    </item>
    <item>
      <title>PPO 网络概率太低并且变化不大</title>
      <link>https://stackoverflow.com/questions/78106390/ppo-network-probabilities-are-too-low-and-arent-changing-a-lot</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78106390/ppo-network-probabilities-are-too-low-and-arent-changing-a-lot</guid>
      <pubDate>Tue, 05 Mar 2024 08:48:07 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV Python 中的不规则形状检测和测量</title>
      <link>https://stackoverflow.com/questions/78105770/irregular-shape-detection-and-measurement-in-opencv-python</link>
      <description><![CDATA[我正在尝试使用 OpenCV Python 对榴莲水果进行一些图像分析，但这些图像很难分割。你们能推荐一些图像处理技术，我可以用它来分割和计算水果上的果皮/小室的数量吗？
原始图像如下所示：
原始图片
分割后的图像应如下所示：
理想输出
如果每个外皮都上色就更好了。
我对Python中的图像处理技术很不熟悉。我尝试应用精明的边缘检测来强调边缘，看看是否有任何可能的特征可以从图像中提取，但我认为没有基于我使用的算法。
灰度图像上的 Canny 边缘检测]]></description>
      <guid>https://stackoverflow.com/questions/78105770/irregular-shape-detection-and-measurement-in-opencv-python</guid>
      <pubDate>Tue, 05 Mar 2024 06:37:51 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用像素化、图像加扰等技术创建/转换仅由人类而非 OCR 理解的图像</title>
      <link>https://stackoverflow.com/questions/78105607/is-it-possible-to-create-convert-an-image-that-is-only-understand-by-human-and-n</link>
      <description><![CDATA[是否可以通过使用像素化、图像置乱等技术来创建/转换仅由人类而非 OCR 理解的图像？
是否可以转换混淆 OCR 且无法使用 OCR 扫描该图像中的文本的图像？ （或者）在使用相机时图像变得难以理解。
我尝试对图像进行像素化，但使用 OCR 后它变得难以理解，但问题是像素化图像既不被人类理解。]]></description>
      <guid>https://stackoverflow.com/questions/78105607/is-it-possible-to-create-convert-an-image-that-is-only-understand-by-human-and-n</guid>
      <pubDate>Tue, 05 Mar 2024 06:02:28 GMT</pubDate>
    </item>
    <item>
      <title>time_strech()-Librosa 中的参数编号问题</title>
      <link>https://stackoverflow.com/questions/78105567/argument-number-issue-in-time-strech-librosa</link>
      <description><![CDATA[当我像这样定义stretch()函数时：
def 拉伸（数据，速率=0.8）：
    返回 librosa.effects.time_stretch(数据，速率)

它给出了错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
TypeError Traceback（最近一次调用最后一次）
[56] 中的单元格，第 6 行
      4 y = []
      5 for i in range(len(audio_df))：
----&gt; 6 feature=get_features(audio_df[&#39;Arrays&#39;].iloc[i]);
      7 表示特征中的 j：
      8 x.追加（j）

Cell In[55]，第 14 行，在 get_features(data) 中
     11 结果.追加（res2）
     13#带伸展和俯仰
---&gt; 14 new_data = 拉伸（数据）
     15 data_stretch_pitch = 音调（new_data，sr）
     16 res3 = extract_features（data_stretch_pitch）

单元格 In[53]，第 7 行，拉伸（数据，速率）
      6 def 拉伸（数据，速率=0.8）：
----&gt; 7 返回 librosa.effects.time_stretch(数据, 速率)

类型错误：time_stretch() 需要 1 个位置参数，但给出了 2 个

但是当我删除“rate”参数时，它会给出错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
TypeError Traceback（最近一次调用最后一次）
单元格 In[58]，第 6 行
      4 y = []
      5 for i in range(len(audio_df))：
----&gt; 6 feature=get_features(audio_df[&#39;Arrays&#39;].iloc[i]);
      7 表示特征中的 j：
      8 x.追加（j）

Cell In[55]，第 14 行，在 get_features(data) 中
     11 结果.追加（res2）
     13#带伸展和俯仰
---&gt; 14 new_data =拉伸（数据）
     15 data_stretch_pitch = 音调（new_data，sr）
     16 res3 = extract_features（data_stretch_pitch）

单元格 In[57]，第 7 行，拉伸（数据，速率）
      6 def 拉伸（数据，速率=0.8）：
----&gt; 7 返回 librosa.effects.time_stretch(data)

类型错误：time_stretch() 缺少 1 个必需的仅关键字参数：“rate”

我删除了“rate”参数以尝试使用默认值（即使这会对数据产生任何影响），但它仍然给出错误。
我可能是错的，但根据我的说法，当我给出 2 个参数时，它说它只需要 1 个，当我给出 1 个参数时，它说我缺少一个参数，我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/78105567/argument-number-issue-in-time-strech-librosa</guid>
      <pubDate>Tue, 05 Mar 2024 05:50:49 GMT</pubDate>
    </item>
    <item>
      <title>文字识别</title>
      <link>https://stackoverflow.com/questions/78105221/text-recognition</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78105221/text-recognition</guid>
      <pubDate>Tue, 05 Mar 2024 03:48:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在 train() 函数内使用重复的随机训练/测试分割集？</title>
      <link>https://stackoverflow.com/questions/78103028/how-to-use-repeated-random-training-test-splits-sets-inside-train-function</link>
      <description><![CDATA[我想使用重复的随机 80%/20% 分割作为训练集，因为我的数据集只有大约 800 个人，事件率为 5%。
#示例数据
dd_cleannames = data.frame(class = 样本(c(0,1),100,替换 = TRUE),var1 = 样本(c(1:5),100,替换= TRUE),var2 = 样本(c(10: 20),100,替换=真))

#为5个随机训练集创建数据分区
设置种子(100)
索引 &lt;- 插入符::createDataPartition(dd_cleannames$class, p = 0.8,times = 5,list = FALSE)

在另一个SO线程中，我找到了这个答案：https://stackoverflow.com/a/59276788/4685471&lt; /p&gt;
resample_data &lt;- tibble(
  training_sets = map(indices, ~ dd_cleannames[.x, ]),
  test_sets = map(索引, ~ dd_cleannames[-.x, ])
）

现在我创建我的控件：
ctrl = trainControl(method = &quot;LGOCV&quot;,
                    数量 = 5,
                    p = 0.8，
                    类概率 = TRUE,
                    摘要函数=两个类摘要）

但是当我尝试实现广义提升模型时，出现错误：
gbm = train(class ~ ., data = resample_data$training_sets,
            方法=“gbm”，
            trControl = ctrl,
            详细=假）
terms.formula(公式，数据 = 数据) 中的错误：
  使用“.”在数据框中重复名称“var1”

或者，除了在 createDataPartition 函数中使用 list = TRUE 之外，我尝试了相同的工作流程，但出现以下错误：
set.seed(100)
索引 &lt;- 插入符::createDataPartition(dd_cleannames$class, p = 0.8,times = 5,list = TRUE)

resample_data &lt;- tibble(
  training_sets = map(indices, ~ dd_cleannames[.x, ]),
  test_sets = map(索引, ~ dd_cleannames[-.x, ])
）


ctrl = trainControl(方法 = “LGOCV”,
                    数量 = 5,
                    p = 0.8，
                    类概率 = TRUE,
                    摘要函数=两个类摘要）


gbm = train(类 ~ ., 数据 = resample_data$training_sets,
            方法=“gbm”，
            trControl = ctrl,
            详细=假）
eval(predvars, data, env) 中的错误：未找到对象“Resample1.class”

然后我收到此错误：
eval(predvars, data, env) 中出现错误：未找到对象“Resample1.class”

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78103028/how-to-use-repeated-random-training-test-splits-sets-inside-train-function</guid>
      <pubDate>Mon, 04 Mar 2024 17:16:26 GMT</pubDate>
    </item>
    <item>
      <title>我应该如何使代码匹配以通过文档测试？</title>
      <link>https://stackoverflow.com/questions/78102706/how-should-i-make-the-code-match-up-to-pass-doctests</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78102706/how-should-i-make-the-code-match-up-to-pass-doctests</guid>
      <pubDate>Mon, 04 Mar 2024 16:23:09 GMT</pubDate>
    </item>
    <item>
      <title>YOLOV5 - 自定义模型训练 - 字符串到浮点错误[关闭]</title>
      <link>https://stackoverflow.com/questions/78101832/yolov5-custom-model-training-string-to-float-error</link>
      <description><![CDATA[快速解决方案将不胜感激
我想通过yolov5检测7个图像类别。我克隆了 yolov5 并把我的图像、标签和
将classes.txt放入yolov5的数据文件夹中，并制作data.yaml，其中包含有关数据集的基本信息。
我有多个图像及其相应的标签，但我提供示例：
示例 nh00001.txt：
白细胞 0.525625 0.034167 0.031250 0.038333
霉菌 0.146250 0.043333 0.032500 0.050000
红宝石 0.218125 0.043333 0.028750 0.036667
白细胞 0.726875 0.110833 0.033750 0.061667
红宝石 0.500625 0.205000 0.031250 0.040000
霉菌 0.157500 0.324167 0.027500 0.041667
白细胞 0.819375 0.347500 0.031250 0.045000
红宝石 0.702500 0.344167 0.032500 0.035000
霉菌 0.468750 0.394167 0.027500 0.045000
白细胞 0.504375 0.408333 0.036250 0.046667
红宝石 0.962500 0.429167 0.032500 0.048333
白细胞 0.534375 0.433333 0.036250 0.050000
白细胞 0.859375 0.596667 0.046250 0.056667
白细胞 0.630000 0.604167 0.032500 0.041667
白细胞 0.868125 0.689167 0.033750 0.045000
红宝石 0.094375 0.752500 0.028750 0.038333
霉菌0.519375 0.830000 0.026250 0.036667
classes.txt：
投掷
水晶
上皮
上皮
埃里斯
白细胞
霉菌
data.yaml：
train: data\images # 图像目录的路径
val: # 验证图像目录的路径（如果不使用则留空）
nc: 7 # 类数
name: [&#39;cast&#39;, &#39;cryst&#39;, &#39;epith&#39;, &#39;epithn&#39;, &#39;eryth&#39;, &#39;leuko&#39;, &#39;mycete&#39;] # 类名列表
设置数据后我正在运行以下命令：
python train.py --img 640 --batch 16 --epochs 50 --data data.yaml --cfg models/yolov5s.yaml --weights &#39;yolov5s.pt&#39;
它获取yolov5s.pt，但图像中出现此错误：要浮动的字符串
我解释了我在做什么，并给出了我的错误，我希望有人能给出解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78101832/yolov5-custom-model-training-string-to-float-error</guid>
      <pubDate>Mon, 04 Mar 2024 14:08:52 GMT</pubDate>
    </item>
    <item>
      <title>shap 与 PolynomialFeatures(level=1) 兼容吗？</title>
      <link>https://stackoverflow.com/questions/78099333/is-shap-compatible-with-polynomialfeaturesdegree-1</link>
      <description><![CDATA[我正在尝试绘制 shap.summary_plot 进行多项式回归，但它给出了尺寸错误
;形状 (12,) 和 (11,) 未对齐： 12(dim 0)!= 11(dim 0)

模型=多项式特征（度=1）

解释器= shap.Explainer（模型=模型，feature_names=df.columns，算法=&#39;自动&#39;）

当我尝试使用 LinearExplainer 时仍然遇到相同的错误
explainer = shap.Explainer(model = model, Algorithm = &#39;auto&#39;)
解释器 = shap.LinearExplainer(模型 = 模型)


shap_values = 解释器.shap_values(df)

我只是想知道 shap 是否与多项式回归兼容。如果兼容如何构建解释器]]></description>
      <guid>https://stackoverflow.com/questions/78099333/is-shap-compatible-with-polynomialfeaturesdegree-1</guid>
      <pubDate>Mon, 04 Mar 2024 06:34:57 GMT</pubDate>
    </item>
    <item>
      <title>SVM损失函数实现中如何更新梯度？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78092500/how-to-update-the-gradient-in-svm-loss-function-implementation</link>
      <description><![CDATA[我有这部分代码，试图为 svm 模型实现损失函数：
来自内置导入范围
将 numpy 导入为 np
从随机导入随机播放
从过去的内置导入 xrange


def svm_loss_naive(W, X, y, reg):
    ”“”
    结构化 SVM 损失函数，简单实现（带循环）。

    输入具有 D 维，有 C 类，我们对小批量进行操作
    N 个例子。

    输入：
    - W：包含权重的形状（D，C）的numpy数组。
    - X：形状 (N, D) 的 numpy 数组，包含小批量数据。
    - y：包含训练标签的形状 (N,) 的 numpy 数组； y[i] = c 意味着
      X[i] 具有标签 c，其中 0 &lt;= c &lt; C。
    - reg：（浮点数）正则化强度

    返回一个元组：
    - 单个浮点损失
    - 相对于权重 W 的梯度；与 W 形状相同的数组
    ”“”
    dW = np.zeros(W.shape) # 将梯度初始化为零

    # 计算损失和梯度
    num_classes = W.shape[1]
    num_train = X.shape[0]
    损失 = 0.0
    对于范围内的 i（num_train）：
        分数 = X[i].dot(W)
        Correct_class_score = 分数[y[i]]
        对于范围内的 j（num_classes）：
            如果 j == y[i]：
                继续
            margin = Scores[j] - Correct_class_score + 1 # 注意 delta = 1
            如果保证金&gt; 0:
                损失+=保证金
                **dW[:, j] += X[i]
                dW[:, y[i]] -= X[i]**

    # 现在损失是所有训练样本的总和，但我们想要它
    # 取平均值，所以我们除以 num_train。
    损失 /= num_train

    # 为损失添加正则化。
    loss += reg * np.sum(W * W) # reg 是 &#39;lambda&#39; 或 1/c，sum(w*w) 是 L2 范数
    

    dW /= num_train # 缩放梯度 ovr 样本数
    dW += 2 * reg * W


   回波损耗，dW

我不太明白这两行：
&lt;前&gt;&lt;代码&gt; dW[:, j] += X[i]
     dW[:, y[i]] -= X[i]

为什么我们要采用这种方式更新梯度项？我没有看到与数学理论和术语的关系。我确信解释非常简单，但我确实还没有看到它。 （我了解这些代码行的作用，但不知道它们为何存在）。
它运行良好，但我想更好地理解它。
有人在某处发布了此内容：
&lt;块引用&gt;
我没有足够的声誉来发表评论，所以我在这里回答。每当您计算第 i 个训练示例的 x[i] 的损失向量并获得一些非零损失时，这意味着您应该将错误类别 (j != y[i]) 的权重向量移开 x[i]，并在同时，将权重或超平面移动到 x[i] 附近的正确类别 (j==y[i])。根据平行四边形定律，w + x 位于 w 和 x 之间。因此，每次发现损失&gt;0时，w[y[i]]都会尝试接近x[i]。

因此，dW[:,y[i]] += -X[i] 和 dW[:,j] += X[i] 是在循环中完成的，但是在更新时，我们将按照梯度下降，因此我们本质上是添加 X[i] 来纠正类别权重，并通过 X[i] 消除未分类的权重。
但我仍然想看看 svm 损失函数计算背后的数学术语和理论的实际联系。上面提到的解释对我来说还不够澄清，它可能还是太抽象了。]]></description>
      <guid>https://stackoverflow.com/questions/78092500/how-to-update-the-gradient-in-svm-loss-function-implementation</guid>
      <pubDate>Sat, 02 Mar 2024 11:36:47 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 中二元分类目标的精确定义</title>
      <link>https://stackoverflow.com/questions/78064980/exact-definition-of-the-binary-classifctation-objective-in-xgboost</link>
      <description><![CDATA[在 XGBoost 的源代码中，我可以在哪里找到二元逻辑分类问题（对数损失）的目标函数的确切拼写和定义，包括对股票附带的超参数（例如scale_pos_weight）的所有显式引用XGBoost 版本？]]></description>
      <guid>https://stackoverflow.com/questions/78064980/exact-definition-of-the-binary-classifctation-objective-in-xgboost</guid>
      <pubDate>Tue, 27 Feb 2024 03:19:57 GMT</pubDate>
    </item>
    <item>
      <title>如何得到PLS分类的预测概率？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78061203/how-to-get-predicted-probabilities-of-pls-classification</link>
      <description><![CDATA[我正在尝试使用不同的分类器（SVC、RandomForest、PLS）对数据进行二元分类，并绘制模型的 ROC 和 PR 曲线（与 这个）之后。
我的 ROC 和 PR 曲线代码适用于除 PLS 之外的每个分类器（SVC、RandomForest）。问题在于 PLSRegression 缺少 .predict_proba，所以我认为使用 CaliberatedClassifierCV 可以解决这个问题。但是，要么我又做错了什么，要么我将 CalibatedClassifierCV 与 PLSRegression 一起使用的意图是错误的。
是否可以将 CalibrateClassifiedCV 与 PLS 结合使用来为我提供 PLS 分类模型的预测概率，以便我可以绘制所需的曲线？或者还有其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78061203/how-to-get-predicted-probabilities-of-pls-classification</guid>
      <pubDate>Mon, 26 Feb 2024 13:17:56 GMT</pubDate>
    </item>
    <item>
      <title>检测视频中的手部方向（旋转）</title>
      <link>https://stackoverflow.com/questions/75908800/detect-hand-orientation-rotation-in-a-video</link>
      <description><![CDATA[我想检测视频中我的手的旋转，但我仍然不知道如何正确地做到这一点。
我尝试使用 PCA 方法，但它仅适用于图像，不适用于视频。
我可以正确检测到手及其地标]]></description>
      <guid>https://stackoverflow.com/questions/75908800/detect-hand-orientation-rotation-in-a-video</guid>
      <pubDate>Sat, 01 Apr 2023 20:54:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 询问脑电图分类的建议</title>
      <link>https://stackoverflow.com/questions/67236791/asking-advice-on-eeg-classification-using-keras</link>
      <description><![CDATA[我有一个脑电图数据集，形状如下：
&lt;前&gt;&lt;代码&gt;(11,1158, 200)

哪里
11为EEG通道数
1158是每个任务的编号
200是每个任务的时间间隔

例如，如果您绘制一个任务，您将得到（请注意，数据已标准化）：

该任务代表一个带有类的任务。 （例如，查看第 2 类的图片，我的数据集中的类总数为 5）。
现在我将数组转换为这种形状：
&lt;前&gt;&lt;代码&gt;(1158, 200, 11)

以便模型能够区分每个任务。这是我使用的模型：
opt = keras.optimizers.Adam(learning_rate=1e-4)

模型=顺序（）
model.add(Conv1D(filters=128, kernel_size=64,activation=&#39;relu&#39;, input_shape=(200, 11)))
model.add(Conv1D(filters=64, kernel_size=8,activation=&#39;relu&#39;))
模型.add(Dropout(0.5))
model.add(MaxPooling1D(pool_size=2))
模型.add(压平())
model.add（密集（100，激活=&#39;relu&#39;））
model.add（密集（5，激活=&#39;softmax&#39;））
model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=opt, 指标=[&#39;accuracy&#39;])
model.fit（x_train，y_train，validation_data =（x_valid，y_valid），epochs = 50，batch_size = 16）

我尝试了许多不同的超参数，但我所有的结果都有点像这样：
纪元 50/50
58/58 [==============================] - 0s 5ms/步 - 损失：0.1281 - 准确度：0.9946 - val_loss ：2.7850 - val_accuracy：0.1897

训练准确率很高，但验证准确率在 20% 到 25% 之间（100/5 = 20，其中 5 是类数）；这基本上意味着模型预测随机的东西。我的做法有错吗？如果是这样，我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/67236791/asking-advice-on-eeg-classification-using-keras</guid>
      <pubDate>Fri, 23 Apr 2021 21:01:51 GMT</pubDate>
    </item>
    </channel>
</rss>