<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Dec 2024 03:35:16 GMT</lastBuildDate>
    <item>
      <title>如何将原始二进制图像数据转换为 TexImageSource</title>
      <link>https://stackoverflow.com/questions/79245288/how-do-i-convert-raw-binary-image-data-to-teximagesource</link>
      <description><![CDATA[所以我有一个带 Wi-Fi 的微控制器。我正在向托管在我电脑上的 Web 服务器发送 HTTP 请求，该服务器托管一个对象检测模型。此 HTTP 请求包含原始二进制图像数据，但 Mediapipe（我用来运行该模型的库）需要 TexImageSource，但我不确定如何将二进制图像数据转换为 TexImageSource 以在 mediapipe.s 中使用]]></description>
      <guid>https://stackoverflow.com/questions/79245288/how-do-i-convert-raw-binary-image-data-to-teximagesource</guid>
      <pubDate>Mon, 02 Dec 2024 19:08:10 GMT</pubDate>
    </item>
    <item>
      <title>CNN 中的可变大小输入</title>
      <link>https://stackoverflow.com/questions/79245135/variable-sized-input-in-cnn</link>
      <description><![CDATA[我有一个包含不同分辨率图像的数据集。我想将它们缩放为固定分辨率。有没有关于缩放图像的最佳尺寸的建议？
我想到的是取平均值、最大值或均值作为固定分辨率。]]></description>
      <guid>https://stackoverflow.com/questions/79245135/variable-sized-input-in-cnn</guid>
      <pubDate>Mon, 02 Dec 2024 18:10:59 GMT</pubDate>
    </item>
    <item>
      <title>SVHN 数据集中的标签错误？</title>
      <link>https://stackoverflow.com/questions/79244553/wrong-labels-in-svhn-dataset</link>
      <description><![CDATA[我一直在对 SVHN 数据集进行一些实验，主要是我想在进行一些训练之前裁剪出每个数字，这时我偶然发现测试数据集中的图像 53.png 有错误的标签（9 和 3，而不是 3 和 3）。
我很好奇是否有人也可以复制该问题，如果标签真的错了，也许可以建议如何处理它？&lt;​​/p&gt;
我从官方网站下载了数据集，解压缩并尝试读取 digitStruct.mat。
我的代码（假设所有数据都在 data/train 文件夹中）：
import os
from PIL import Image
from pymatreader import read_mat
import matplotlib.pyplot as plt
train_mat = read_mat(&#39;data/train/digitStruct.mat&#39;)

print(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][52])
print(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][52])

返回
&gt;&gt;53.png
&gt;&gt;{&#39;label&#39;: [9.0, 3.0], &#39;height&#39;: [84.0, 84.0], &#39;width&#39;: [59.0, 52.0], &#39;left&#39;: [160.0, 208.0], &#39;top&#39;: [34.0, 18.0]}

我还尝试显示其他图像以防出现类似异常，但我没有发现任何问题。
import cv2 
from matplotlib import pyplot as plt 

fig = plt.figure(figsize=(10, 7))

# 使用 OpenCV 读取图像（OpenCV 以 BGR 格式加载图像）
image1 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][0])
image2 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][27])
image3 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][52])
image4 = cv2.imread(&#39;data/train/&#39; + train_mat[&#39;digitStruct&#39;][&#39;name&#39;][90])

# 将图像从 BGR 转换为 RGB 格式，以便 Matplotlib 可以正确显示它们
image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)
image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)
image3 = cv2.cvtColor(image3, cv2.COLOR_BGR2RGB)
image4 = cv2.cvtColor(image4, cv2.COLOR_BGR2RGB)

# 将第一幅图像添加到图中（左上角位置）
plt.subplot(2, 2, 1) # 2 行，2 列，第一个位置
plt.imshow(image1) 
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][0] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][0][&#39;label&#39;]))

# 将第二幅图像添加到图中（右上位置）
plt.subplot(2, 2, 2) # 2 行，2 列，第二个位置
plt.imshow(image2) 
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][27] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][27][&#39;label&#39;])) 

# 将第三幅图像添加到图中（左下位置）
plt.subplot(2, 2, 3) # 2 行，2 列，第三个位置
plt.imshow(image3)
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][52] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][52][&#39;label&#39;])) 
# 将第四幅图像添加到图中（右下角位置）
plt.subplot(2, 2, 4) # 2 行，2 列，第四个位置
plt.imshow(image4) 
plt.axis(&#39;off&#39;) # 隐藏轴标签
plt.title(train_mat[&#39;digitStruct&#39;][&#39;name&#39;][90] + &#39;\n&#39; + str(train_mat[&#39;digitStruct&#39;][&#39;bbox&#39;][90][&#39;label&#39;]))

输出：SVHN 比较]]></description>
      <guid>https://stackoverflow.com/questions/79244553/wrong-labels-in-svhn-dataset</guid>
      <pubDate>Mon, 02 Dec 2024 15:03:58 GMT</pubDate>
    </item>
    <item>
      <title>anomalib 的零样本 winCLIP 不起作用</title>
      <link>https://stackoverflow.com/questions/79244492/zero-shot-winclip-from-anomalib-not-working</link>
      <description><![CDATA[随着异常分类/分割的最新进展，我想尝试新的 winCLIP 模型，anomalib 库也有一个实现。
由于这是一个零样本模型，我认为它很容易开箱即用。有人知道如何测试零样本或为少样本提供几张“正常/健康”图像吗？我无法让它工作。这是我当前的代码：

从 anomalib.models.image 导入 WinClip
从 anomalib.engine 导入 Engine

# 导入数据模块
从 anomalib.data 导入 Folder
从 anomalib.data.utils 导入 TestSplitMode

# 创建数据模块
datamodule = Folder(
name=&quot;lasercut_plank&quot;,
root=&quot;./DATA_0shot&quot;,
normal_dir=&quot;normal&quot;,
test_split_mode=TestSplitMode.NONE
)

# 设置数据模块
datamodule.setup()

# 访问数据集
train_dataset = datamodule.train_data

# 访问数据加载器
train_dataloader = datamodule.train_dataloader()

# 创建模型和引擎
model = WinClip(class_name=&quot;lasercut_plank&quot;)
engine = Engine(task=&quot;segmentation&quot;)

# 在给定的数据模块上训练 Patchcore 模型
engine.train(datamodule=datamodule, model=model)

]]></description>
      <guid>https://stackoverflow.com/questions/79244492/zero-shot-winclip-from-anomalib-not-working</guid>
      <pubDate>Mon, 02 Dec 2024 14:43:56 GMT</pubDate>
    </item>
    <item>
      <title>开始一个项目 [关闭]</title>
      <link>https://stackoverflow.com/questions/79244312/getting-started-with-a-project</link>
      <description><![CDATA[我该如何着手构建一个数据科学中的机器学习项目，我需要指导如何正确进入它。
我还没有开始，但是，这就是我想要进入的。得到答案将是一件令人高兴的事。]]></description>
      <guid>https://stackoverflow.com/questions/79244312/getting-started-with-a-project</guid>
      <pubDate>Mon, 02 Dec 2024 13:43:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么预先训练的 Swin Transformer 编码器在 TPU 上失败但在 Colab 中的 CPU 上可以运行？</title>
      <link>https://stackoverflow.com/questions/79244294/why-does-pre-trained-swin-transformer-encoder-fail-on-tpu-but-works-on-cpu-in-co</link>
      <description><![CDATA[我正在处理图像分割任务，并尝试使用预先训练的 Swin Transformer Large (Swin-L) 编码器作为特征提取主干。代码在 Colab 中的 CPU 上完美运行。但是，当切换到 TPU 时，它会抛出如下所示的错误。
代码：
from tensorflow.keras import layer, Model, Input
from tfswin import SwinTransformerLarge224

def load_swin_encoder(input_shape=(512, 512, 3)):
# 加载预训练的 Swin-L 模型
swin_encoder = SwinTransformerLarge224(include_top=False, weights=&#39;imagenet&#39;,
input_shape=input_shape)

# 冻结预训练层
for layer in swin_encoder.layers:
layer.trainable = False

# 从四个阶段提取输出
stage_outputs = [
swin_encoder.get_layer(&#39;normalize&#39;).output, # 从 0 阶段输出
swin_encoder.get_layer(&#39;layers.0&#39;).output, # 第一阶段的输出
swin_encoder.get_layer(&#39;layers.1&#39;).output, # 第二阶段的输出
swin_encoder.get_layer(&#39;layers.2&#39;).output, # 第三阶段的输出
swin_encoder.get_layer(&#39;layers.3&#39;).output, # 第四阶段的输出
]
return Model(swin_encoder.input, stage_outputs, name=&quot;SwinTransformerEncoder&quot;)

# 测试代码
encoder = load_swin_encoder(input_shape=(512, 512, 3))
dummy_input = tf.random.uniform((1, 512, 512, 3))
encoder_outputs =coder(dummy_input)

for i, output in enumerate(encoder_outputs):
print(f&quot;阶段 {i + 1} 输出形状：{output.shape}&quot;)


错误：
代码在 TPU 上抛出以下错误：
------------------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-28-3cb122d32678&gt; 在 &lt;cell line: 2&gt;()
1 # 加载健全性检查
----&gt; 2 编码器 = load_swin_encoder(input_shape=(512, 512, 3))
3 dummy_input = tf.random.uniform((1, 512, 512, 3))
4 编码器输出 = 编码器(dummy_input)
5 

2 帧
/usr/local/lib/python3.10/dist-packages/keras/src/models/ functional.py in __init__(self, 输入, 输出, 名称, **kwargs)
117 for x in flat_inputs:
118 if not isinstance(x, backend.KerasTensor):
-&gt; 119 引发 ValueError(
120 “所有 `inputs` 值都必须是 KerasTensors。已收到：”
121 f“inputs={inputs} 包括无效值 {x}”

ValueError：所有 `inputs` 值都必须是 KerasTensors。已收到：inputs=KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=&#39;input_4&#39;), name=&#39;input_4&#39;, description=“由层 &#39;input_4&#39; 创建”) 包括无效值 KerasTensor(type_spec=TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=&#39;input_4&#39;), name=&#39;input_4&#39;, description=“由层创建” &#39;input_4&#39;&quot;) 类型为 &lt;class &#39;tf_keras.src.engine.keras_tensor.KerasTensor&#39;&gt;


问题：
为什么此代码在 Colab 中的 CPU 上有效，但在 TPU 上失败？我该如何修复此问题以使其与 TPU 执行兼容？
任何见解或指导都将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79244294/why-does-pre-trained-swin-transformer-encoder-fail-on-tpu-but-works-on-cpu-in-co</guid>
      <pubDate>Mon, 02 Dec 2024 13:35:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 MNIST 训练模型对自定义图像进行了错误分类？</title>
      <link>https://stackoverflow.com/questions/79243340/why-is-my-mnist-trained-model-misclassifying-a-custom-image</link>
      <description><![CDATA[我使用 MNIST 数据集训练了一个神经网络模型来识别手写数字。该模型在 MNIST 测试集上的准确率达到 97%，但无法正确预测自定义图像文件中的数字。例如，下图包含数字 8，但模型的预测始终不正确。
我在预处理步骤中做错了什么，如何正确准备自定义图像以匹配 MNIST 数据格式？
import cv2
import numpy as np
import os
from keras.api.datasets import mnist
from keras.api.models import Sequential
from keras.api.layers import Dense, Flatten
from keras.api.utils import to_categorical
from PIL import Image

# 加载 MNIST 数据集
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# 将 mnist 数据集从 uint8 转换为 float32，因为大多数深度学习框架都希望输入数据为浮点格式。
train_images = train_images.astype(&#39;float32&#39;) / 255
test_images = test_images.astype(&#39;float32&#39;) / 255

# 添加新的通道维度，得到形状 (num_samples, 28, 28, 1)
train_images = np.expand_dims(train_images, axis=-1)
test_images = np.expand_dims(test_images, axis=-1)

# 对标签进行独热编码
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

# 构建模型
model = Sequential([
Flatten(input_shape=(28, 28, 1)),
Dense(128,activation=&#39;relu&#39;),
Dense(10,activation=&#39;softmax&#39;)
])

#编译模型
model.compile(optimizer=&#39;adam&#39;,
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

# 训练模型
print(&quot;训练模型...&quot;)
model.fit(train_images, train_labels, epochs=5, batch_size=128)

# 评估模型
loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)
print(f&quot;测试准确率：{accuracy * 100:.2f}%&quot;)

# 加载图像进行预测
image_path = &#39;digit.png&#39; # 替换为您的图像路径
print(f&quot;加载并预测 {image_path}...&quot;)

try:
# 以灰度读取图像
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

if image is None:
raise IOError(f&quot;Error loading image at {image_path}&quot;)

# 将图像大小调整为 28x28
image = cv2.resize(image, (28, 28))

# 反转颜色（如果需要）
image = cv2.bitwise_not(image)

# 标准化图像
image_normalized = image.astype(&#39;float32&#39;) / 255

# 转换为可以保存为 PNG 的格式（值 0 到 255）
image_for_saving = (image_normalized * 255).astype(np.uint8)

# 定义保存图像的路径
preprocessed_image_path = &quot;preprocessed_digit.png&quot;

# 确保目录存在（当前目录）
output_directory = os.path.dirname(preprocessed_image_path)
if not os.path.exists(output_directory) and output_directory != &#39;&#39;:
os.makedirs(output_directory)

# 使用 PIL 保存图像
pil_image = Image.fromarray(image_for_saving)
pil_image.save(preprocessed_image_path)
print(f&quot;已将预处理图像保存到 {preprocessed_image_path}&quot;)

# 使用模型预测数字（假设模型已加载）
# 必要时将图像重塑为模型输入格式
image_input = np.expand_dims(image_normalized, axis=0)
image_input = np.expand_dims(image_input, axis=-1)
prediction = np.argmax(model.predict(image_input))
print(&quot;预测数字：&quot;, prediction)

except Exception as e:
print(f&quot;处理图像时出错：{e}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/79243340/why-is-my-mnist-trained-model-misclassifying-a-custom-image</guid>
      <pubDate>Mon, 02 Dec 2024 08:03:19 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中使用 ImageAI 加载自定义训练的 ResNet50 模型？</title>
      <link>https://stackoverflow.com/questions/79242938/how-to-load-a-custom-trained-resnet50-model-with-imageai-in-python</link>
      <description><![CDATA[我正在使用 ImageAI 的自定义训练 ResNet50 模型进行图像分类项目，但遇到了持续的加载错误，导致我无法使用训练好的模型进行预测。该错误表明在尝试将自定义训练的 PyTorch 模型加载到 ImageAI 框架时存在兼容性问题或缺少特定方法。
我尝试使用 ImageAI 的标准模型加载程序加载自定义训练的 ResNet50 模型：
from imageai.Classification import ImageClassification

classifier = ImageClassification()
classifier.setModelPath(&quot;path/to/custom/model.pt&quot;)
classifier.setModelTypeAsResNet50()
classifier.loadModel() # 预计会成功加载模型

我期望的是一个类似于使用预训练模型的简单模型加载过程。相反，我收到了一个令人沮丧的错误：
分类失败：模型尚未加载。执行图像分类之前，您需要调用 &#39;.loadModel()&#39;


我的环境详情：

Python 3.12
ImageAI 3.0.3
PyTorch 2.5.1+cu118
Windows 11

我已确认：

模型路径正确
模型已保存为有效的 .pt 文件
该模型使用 ResNet50 架构在自定义数据集上进行训练

具体问题：

ImageAI 中是否有加载自定义训练模型的特定方法？
自定义模型是否有任何特殊的导出或转换要求？
我需要修改我的模型的状态字典或使用特定的导出格式？
]]></description>
      <guid>https://stackoverflow.com/questions/79242938/how-to-load-a-custom-trained-resnet50-model-with-imageai-in-python</guid>
      <pubDate>Mon, 02 Dec 2024 04:07:18 GMT</pubDate>
    </item>
    <item>
      <title>通过 Streamlit 上的 YFinance 获取数据 [关闭]</title>
      <link>https://stackoverflow.com/questions/79242889/fetching-data-via-yfinance-on-streamlit</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79242889/fetching-data-via-yfinance-on-streamlit</guid>
      <pubDate>Mon, 02 Dec 2024 03:31:17 GMT</pubDate>
    </item>
    <item>
      <title>set_transform 或 with_transform 之后 transformer 的数据集结构出现意外</title>
      <link>https://stackoverflow.com/questions/79241735/unexpected-transformers-dataset-structure-after-set-transform-or-with-transform</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79241735/unexpected-transformers-dataset-structure-after-set-transform-or-with-transform</guid>
      <pubDate>Sun, 01 Dec 2024 14:07:14 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 不接受数据集生成器的列表类型</title>
      <link>https://stackoverflow.com/questions/79241634/tensorflow-does-not-accept-list-type-for-dataset-generator</link>
      <description><![CDATA[我正在构建一个神经网络。我无法一次性将所有训练数据加载到内存中，因此我使用 TensorFlow 的 tf.data.Dataset.from_generator 函数逐步加载数据。但是，它会抛出一个错误，指出它不接受张量列表作为类型。
TypeError：`output_signature` 必须包含属于 
`tf.TypeSpec` 子类的对象，但发现 &lt;class &#39;list&#39;&gt; 不是。

我的神经网络的输入是 151 个独立张量的列表。我如何在生成器中表示它？我的代码如下：
def generator(file_paths, batch_size, files_per_batch, tam, value):
return tf.data.Dataset.from_generator(
lambda: data_generator(file_paths, batch_size, files_per_batch, tam, value),
output_signature=(
[tf.TensorSpec(shape=(batch_size, tam), dtype=tf.float32) for _ in range(tam+1)], # 151 个张量列表
tf.TensorSpec(shape=(batch_size, tam), dtype=tf.float32) # 数组
)
)

inputArray = [Input(shape=(tam,)) for _ in range(tam + 1)]

train_dataset = generator(file_paths, batch_size, files_per_batch, tam, False)
train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)

model.fit(train_dataset, epochs=1000, validation_split=0.2, verbose=1)

我尝试使用 tf.data.Dataset.from_generator 将数据批量输入到我的神经网络中，因为我无法一次将所有数据加载到内存中。
但是，我遇到了一个错误：
TypeError：output_signature 必须包含属于 tf.TypeSpec 子类的对象，但发现 &lt;class &#39;list&#39;&gt; 不是。
]]></description>
      <guid>https://stackoverflow.com/questions/79241634/tensorflow-does-not-accept-list-type-for-dataset-generator</guid>
      <pubDate>Sun, 01 Dec 2024 13:13:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中实现 Softmax，其中输入是有符号的 8 个整数</title>
      <link>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</link>
      <description><![CDATA[我正在尝试实现一个softmax 函数，该函数接受有符号的 int8 输入并返回有符号的 int8 输出数组。
我目前正在进行的实现是这样的，
 import numpy as np

def softmax_int8(inputs):
input = np.array(inputs, dtype=np.int8)

x = input.astype(np.int32)
x_max = np.max(x)
x_shifted = x - x_max
scale_factor = 2 ** 14
exp_limit = 16
exp_x = np.clip(x_shifted + exp_limit, 0, None)
exp_x = (1 &lt;&lt; exp_x)
sum_exp_x = np.sum(exp_x)

如果 sum_exp_x == 0:
sum_exp_x = 1

softmax_probs = (exp_x * scale_factor) // sum_exp_x
max_prob = np.max(softmax_probs)
min_prob = np.min(softmax_probs)
range_prob = max_prob - min_prob 如果 max_prob != min_prob 否则 1

scaled_probs = ((softmax_probs - min_prob) * 255) // range_prob - 128
output = scaled_probs.astype(np.int8)

返回输出

我使用此输入进行测试，Input = [101, 49, 6, -34, -75, -79, -38, 120, -55, 115]
但我得到此输出 array([-128, -128, -128, -128, -128, -128, -128, 127, -128, -121],dtype=int8)。
我的预期输出是 array([-57, -70, -79, -86, -92, -94, -88, -54, -91, -56], dtype=int8)。
我在这里做错了什么，我该如何修复？]]></description>
      <guid>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</guid>
      <pubDate>Sat, 30 Nov 2024 09:37:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bootstrap 重采样、LASSO 和逐步回归进行特征选择</title>
      <link>https://stackoverflow.com/questions/76204705/feature-selection-using-bootstrap-resampling-lasso-and-stepwise-regression</link>
      <description><![CDATA[在本文中，作者通过以下方式进行放射组学特征选择以预测生存：

使用 Bootstrap 重采样数据集 x 1000
将交叉验证的 LASSO 模型拟合到每个重采样数据集
在所有 1000 个模型中保留 10 个最常见的非零系数特征
使用十个选定的特征对重采样数据集（与步骤 1 中生成的数据集相同）进行反向逐步回归拟合
根据最常见的 cox 回归模型选择最终特征。

我想复制这种方法（尽管是针对逻辑回归而不是cox-regression)。
我能够使用以下 R 代码，使用“boot”库从 Lasso 模型中获取前 K 个特征：
lasso_Select &lt;- function(x, indices){ 
x &lt;- x[indices,]
y &lt;- x$Outcome
x = subset(x, select = -Outcome)
x2 &lt;- as.matrix(x)
fit &lt;- glmnet(x2, y , family=&quot;binomial&quot;,alpha=1, standardize=TRUE)
cv &lt;- cv.glmnet(x2, y, family=&quot;binomial&quot;,alpha=1, standardize=TRUE)
fit &lt;- glmnet(x2, y, family=&quot;binomial&quot;,alpha=1, lambda=cv$lambda.min, standardize=TRUE)
return(coef(fit)[,1])
}

myBootstrap &lt;- boot(scaled_train, lasso_Select, R = 1000, parallel = &quot;multicore&quot;, ncpus=5)

但是，我认为我无法访问单个重采样数据集，然后运行多个逻辑回归模型并选择最常见的模型。
关于如何处理这个问题，有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/76204705/feature-selection-using-bootstrap-resampling-lasso-and-stepwise-regression</guid>
      <pubDate>Mon, 08 May 2023 21:06:44 GMT</pubDate>
    </item>
    <item>
      <title>计算多标签分类问题的 ROC 曲线、分类报告和混淆矩阵</title>
      <link>https://stackoverflow.com/questions/60857415/calculate-roc-curve-classification-report-and-confusion-matrix-for-multilabel-c</link>
      <description><![CDATA[我正在尝试了解如何为我的多标签分类问题创建混淆矩阵和 ROC 曲线。我正在构建一个神经网络。
以下是我的类别：
mlb = MultiLabelBinarizer()
ohe = mlb.fit_transform(as_list)
# 循环遍历每个可能的类别标签并显示它们
for (i, label) in enumerate(mlb.classes_):
print(&quot;{}. {}&quot;.format(i + 1, label))

[INFO] 类别标签：
1. class1
2. class2
3. class3
4. class4
5. class5
6. class6

我的标签已转换：
ohe
array([[0, 1, 0, 0, 1, 1],
[0, 1, 1, 1, 1, 0],
[1, 1, 1, 0, 1, 0],
[0, 1, 1, 1, 0, 1],...]]

训练数据：
array([[[[ 1.93965047e+04, 8.49532852e-01],
[ 1.93965047e+04, 8.49463479e-01],
[ 1.93965047e+04, 8.49474722e-01],
...,

模型：
model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=opt,metrics=[&quot;accuracy&quot;])
H = model.fit(trainX, trainY, batch_size=BS,
validation_data=(testX, testY),
epochs=EPOCHS, verbose=1)

我能够获得百分比，但我对如何计算混淆矩阵或 ROC 曲线或获取分类报告有点不知所措。
以下是百分比：
proba = model.predict(testX)
idxs = np.argsort(proba)[::-1][:2]

for i in proba:
print (&#39;\n&#39;)
for (label, p) in zip(mlb.classes_, i):
print(&quot;{}: {:.2f}%&quot;.format(label, p * 100))

class1: 69.41%
class2: 76.41%
class3: 58.02%
class4: 63.97%
class5: 48.91%
class6: 58.28%

class1: 69.37%
class2: 76.42%
class3: 58.01%
class4: 63.92%
class5: 48.88%
class6: 58.26%

如何操作，最好有例子？]]></description>
      <guid>https://stackoverflow.com/questions/60857415/calculate-roc-curve-classification-report-and-confusion-matrix-for-multilabel-c</guid>
      <pubDate>Wed, 25 Mar 2020 21:07:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit-learn 训练期间显示损失值？</title>
      <link>https://stackoverflow.com/questions/44443479/how-to-show-loss-values-during-training-in-scikit-learn</link>
      <description><![CDATA[我想在训练期间检查我的损失值，这样我就可以观察每次迭代的损失。到目前为止，我还没有找到一种简单的方法让 scikit learn 给我一个损失值的历史记录，也没有找到 scikit 中已有的为我绘制损失的功能。
如果没有办法绘制这个，如果我能在 classifier.fit 的末尾简单地获取最终的损失值就太好了。
注意：我知道有些解决方案是封闭形式的。我正在使用几个没有分析解决方案的分类器，例如逻辑回归和 svm。
有人有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/44443479/how-to-show-loss-values-during-training-in-scikit-learn</guid>
      <pubDate>Thu, 08 Jun 2017 18:50:55 GMT</pubDate>
    </item>
    </channel>
</rss>