<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Fri, 28 Feb 2025 09:18:46 GMT</lastBuildDate>
    <item>
      <title>无监督环境中的异常检测</title>
      <link>https://stackoverflow.com/questions/79474732/anomaly-detection-in-unsupervised-setting</link>
      <description><![CDATA[我一直在试图在无监督的设置中解决异常检测问题，看来我的心脏变量很高，我想使用数据来微调Mistral 7b。
我有这样的数据，每个变量似乎都分类，除了“纬度”，“经度”
我们如何找到解决方案的解决方法，这也是具有许多独特设备的时间序列数据。我无法在数据上找到分类嵌入。我也被困在这里，我选择了自动编码器，以便我们可以找到复杂的模式。这是带有字段的表格数据。
同一输入将是有益的
&#39;reqtimeconverted&#39;，&#39;deviceifa&#39;，&#39;os&#39;，
&#39;osv&#39;，&#39;normalized_osv&#39;，&#39;ipaddress&#39;，&#39;carrier&#39;，&#39;connectionType&#39;，
&#39;device_vendor&#39;，&#39;device_model&#39;，&#39;device_height&#39;，&#39;device_width&#39;，
&#39;deviceType&#39;，&#39;location_type&#39;，&#39;latitude&#39;，&#39;atitude&#39;，&#39;appbundle&#39;device_country_code&#39;，&#39;ua&#39;，
我们尝试了隔离林，一旦SVM，局部离群因素，但没有结果我们现在转向神经网络。
我们一直在寻找解决方案。
请帮助我了解我们的方法是否有任何形式的架构和评论]]></description>
      <guid>https://stackoverflow.com/questions/79474732/anomaly-detection-in-unsupervised-setting</guid>
      <pubDate>Fri, 28 Feb 2025 07:00:03 GMT</pubDate>
    </item>
    <item>
      <title>我们如何平衡AI模型透明度和关键应用程序性能之间的权衡？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79474671/how-do-we-balance-the-trade-off-between-ai-model-transparency-and-performance-in</link>
      <description><![CDATA[近年来，我们目睹了深度学习模型的性能激增，尤其是在医疗保健，金融和自治系统等关键领域。但是，这种表现通常以可解释性和透明度为代价，尤其是在深层神经网络等复杂模型中。。
问题
在高风险环境中使用黑框模型的含义是什么？ ]]></description>
      <guid>https://stackoverflow.com/questions/79474671/how-do-we-balance-the-trade-off-between-ai-model-transparency-and-performance-in</guid>
      <pubDate>Fri, 28 Feb 2025 06:13:01 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的KERAS模型显示4个参数而不是2个参数？</title>
      <link>https://stackoverflow.com/questions/79474503/why-does-my-keras-model-show-4-parameters-instead-of-2</link>
      <description><![CDATA[我正在训练一个具有一个密集层的简单keras模型，但是当我调用Model.Summary（）时，它显示了4个参数，而不是2个参数。
 将TensorFlow导入为TF
导入numpy作为NP

＃生成虚拟数据
x_train = np.random.rand（40）＃shape（40，）
y_train = np.random.rand（40）

＃定义一个简单的模型
模型= tf.keras.Sequeential（[[
    tf.keras.layers.dense（1）
）））

＃编译模型
model.compile（损失= tf.keras.losses.mae，
              优化器= tf.keras.optimizers.sgd（），
              指标= [＆quot; mae;]）

＃训练模型
model.fit（tf.expand_dims（x_train，axis = -1），y_train，epochs = 100）

＃检查模型摘要
model.summary（）
 
由于密集（1）应该具有1个权重 + 1个偏见，所以我期望2个参数，而不是4。
为什么通过1D输入（Shape =（40，））会导致Keras使用4个参数而不是2个参数？
Keras是否会以复制参数的方式自动处理输入形状？
这是结果：
    ]]></description>
      <guid>https://stackoverflow.com/questions/79474503/why-does-my-keras-model-show-4-parameters-instead-of-2</guid>
      <pubDate>Fri, 28 Feb 2025 04:18:51 GMT</pubDate>
    </item>
    <item>
      <title>为什么投票表决为“努力”的投票表现有所不同？</title>
      <link>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</link>
      <description><![CDATA[我想从Sklearn和不同参数进行比较性能测试投票classifier。我使用了param网格，然后发现一些难以理解的东西。
我准备了三个分类器
  gnb = gaussiannb（）＃准确性0.795
lr = logisticRegress（）＃准确性0.7925
RFC = RandomforestClassifier（）＃准确性0.94

 
然后我做了两个VaitingClassifiers。两者都有有效的设置为“硬”。但是重量不同。该决定是由多数投票做出的，但其准确性是不同的，这是如何可能的？
  vc_hard_equals = fotingClassifier（estingators = [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （&#39;Randomforest＆quot＆quot; rfc）
    ]，， 
    投票=“硬＆quot” 
    权重=（1，1，1），＃等于权重
    ）
vc_hard_forest_priority = fotingClassifier（估算= [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （“ rancomforest”，rfc），]， 
    投票=“硬＆quot” 
    权重=（1，1，3），＃更大的随机孔（在这种情况下最好的型号）
    ）

vc_hard_equals.fit（x_train，y_train）
vc_hard_forest_priority.fit（x_train，y_train）

print（vc_hard_equals.score（x_test，y_test））＃0.832
print（vc_hard_forest_priority.score（x_test，y_test））＃0.915
 ]]></description>
      <guid>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</guid>
      <pubDate>Fri, 28 Feb 2025 02:14:28 GMT</pubDate>
    </item>
    <item>
      <title>安装Llava</title>
      <link>https://stackoverflow.com/questions/79474039/installing-llava</link>
      <description><![CDATA[是否有人找到了LLAVA的正确依赖关系和安装顺序？我已经尝试了多个选项，但是在尝试采购模型时继续遇到以下错误：
 代码： 
 来自llava.model.builder import load_pretratained_model
来自llava.mm_utils import get_model_name_from_path
model_path =＆quot; liuhaotian/llava-v1.5-7b; quot  ＃7B Llava模型在拥抱面上
tokenizer，model，image_processor，context_len = load_pretrataining_model（
model_path = model_path，
model_base = none，
model_name = get_model_name_from_path（model_path）
）
 
 错误：
无法导入“ llava.model” 的名称“ llavallamaforcausallm”
我遵循了正式文档中的每一个指令，但到目前为止没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/79474039/installing-llava</guid>
      <pubDate>Thu, 27 Feb 2025 22:07:50 GMT</pubDate>
    </item>
    <item>
      <title>稳定的割炬，超级分析，张量子流包装。</title>
      <link>https://stackoverflow.com/questions/79473712/stable-torch-ultralytics-tensorflow-packages-for-requirements-txt</link>
      <description><![CDATA[我正在为实时体育视频分析项目编写要求。
我尝试了多个Python版本，但遇到了兼容性问题。
我应该安装哪些版本？
要求

火炬== 2.1.2 
 torchvision == 0.16.2 
 Ultrytics == 8.3.80 
 opencv-python == 4.9.0.80 

示例代码
 从超级物质导入YOLO
导入CV2
导入操作系统
进口地球


frame_dir =＆quot; data/videos/res/720p＆quot;
output_dir =“数据/视频/检测”
OS.Makedirs（output_dir，equent_ok = true）


型号= yolo（＆quot; yolov8n.pt;）

target_classes = {
    ＆quot“运动球”：32，
    “人＆quot”：0，
}


对于排序中的frame_path（glob.glob（os.path.join）（frame_dir，*。
    帧= cv2.imread（frame_path）
    结果=模型（帧）

    结果结果：
        对于结果中的框。盒子：
            cls_id = int（box.cls [0]）
            如果target_classes.values（）中的cls_id：
                x1，y1，x2，y2 = map（int，box.xyxy [0]）
                label = [k，v in target_classes.items（）如果v == cls_id] [0]
                cv2.Rectangle（框架，（x1，y1），（x2，y2），（0，255，0），2）
                cv2.putText（帧，标签，（x1，y1-5），cv2.font_hershey_simplex，0.5，（0，255，0），2）

    output_path = os.path.join（output_dir，os.path.basename（frame_path））
    cv2.imwrite（output_path，框架）

打印（output_dir）

 
跟踪
  python -c＆quot“ intimp ultrytics;打印（Ultrytics .__版本__）＆quot;

使用numpy 1.x编译的模块无法运行
Numpy 2.1.1可能会崩溃。支持1.x和2.x
Numpy的版本，必须使用Numpy 2.0编译模块。
一些模块可能需要重建，例如使用&#39;pybind11＆gt; = 2.12&#39;。

如果您是模块的用户，最简单的解决方案将是
降级到&#39;numpy＆lt; 2&#39;或尝试升级受影响的模块。
我们希望有些模块需要时间来支持Numpy 2。

Trackback（最近的最新通话）：file＆quot&#39;string＆gt;＆quort 1，第1行，in＆lt; module＆gt;
  file＆quot＆quort＆quot＆quote＆quote＆quotions/my_projements/venv/lib/python3.11/site-packages/ultralytics/__ init __ init __. py＆quot＆quort&#39;&#39;第11行，in＆lt; lt; module＆gt; gt;
    从Ultrytics.Models进口NAS，RTDETR，SAM，YOLO，FASTSAM，YOLOWORLD
  file＆quot＆quort＆quot＆quort＆quot＆quot＆quot＆quotitys/my_projements/venv/lib/python3.11/site-packages/ultralytics/models/models/__ init __ Init __ init __ py＆quort&#39;py＆quort of第3行，in＆lt; module＆gt;
    来自.fastSAM进口FastSAM
  file＆quot＆quot＆quot＆quort＆quot＆quot＆quotiments/my_projements/venv/lib/python3.11/site-packages/ultralytics/models/models/fastsam/fastsam/__ init __ init __. py＆quort;
    来自.model进口FastSAM
  file＆quot＆quort＆quot＆quot＆quot＆quot＆quotiments/my_projements/venv/lib/python3.11/site-packages/ultralytics/models/models/fastsam/fastsam/model.py&quot;&quot;＆quot＆quot＆quot＆quot＆line 5，in＆lt; lt; module＆gt; gt; gt;
    来自ultrytics.engine.model进口模型
  file＆quort＆quort＆quot＆quot＆quot＆quot＆quotments/my_projements/venv/lib/python3.11/site-packages/ultralalytics/engine/model.py&amp;py&quot; line 8，in 8 in＆lt; lt; module＆gt; gt;
    导入火炬
  file＆quort＆quort＆quot＆quote＆quote＆quotiments/my_projements/venv/lib/python3.11/site-packages/torch/__ init __ init __. py＆quort&#39;&#39;&#39;&#39;&#39;第1477行，in＆lt; module＆gt; gt;
    来自。功能导入 *＃noqa：f403
  文件＆quot＆quort＆quot＆quot＆quotiments/my_projements/venv/lib/python3.11/site-packages/torch/functional.py＆quot＆quot;，第9行，in＆lt; module＆gt;
    导入Torch.nn.功能为f
  file＆quot＆quort＆quot＆quote＆quote＆quote＆quotiments/my_projements/venv/lib/python3.11/site-packages/torch/torch/nn/__ init __.
    来自.modules导入 *＃noqa：f403
  file＆quot＆quot＆quot＆quot＆quot＆quotiments/my_projements/venv/venv/lib/python3.11/site-packages/torch/nn/modules/modules/__ init __ init __. py＆quort&#39;＆quort 35，in＆lt; lt; lt; gt; gt;
    来自.transformer导入transformerencoder，trransformerDecoder，\
  file＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quotions/my_projements/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py&quot;＆quot＆quot;
    设备：torch.device = torch.device（torch._c._get_default_device（）），＃torch.device（&#39;cpu&#39;），
/library/webserver/documents/my_projement/venv/lib/python3.11/site-packages/torch/torch/nn/modules/transformer.py：20：userWarning：userwarning：userwarning：dropinize nucpy：_array_api：_array_api（_array_api note trigger trigger trigger at in trigger at in triggt at in trigger at in trigger at in trigger at in /users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84。
  设备：torch.device = torch.device（torch._c._get_default_device（）），＃torch.device（&#39;cpu&#39;），
8.3.80
 ]]></description>
      <guid>https://stackoverflow.com/questions/79473712/stable-torch-ultralytics-tensorflow-packages-for-requirements-txt</guid>
      <pubDate>Thu, 27 Feb 2025 19:19:40 GMT</pubDate>
    </item>
    <item>
      <title>如何让pytorch学习系数变量，以使nn.module之外的丢失？</title>
      <link>https://stackoverflow.com/questions/79473125/how-to-let-pytorch-learn-coefficients-variables-for-the-loss-outside-of-nn-modul</link>
      <description><![CDATA[我有这样的损失弹性：
 损失= alpha * loss0 + beta * loss1 + gamma * loss2 + delta * loss3
 
我想制作Alpha，Beta，Gamma和Delta可学习的参数。请注意，Alpha，Beta，Gamma和Delta在NN.Module之外。我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/79473125/how-to-let-pytorch-learn-coefficients-variables-for-the-loss-outside-of-nn-modul</guid>
      <pubDate>Thu, 27 Feb 2025 15:16:32 GMT</pubDate>
    </item>
    <item>
      <title>没有或几个异常的异常检测ML训练[封闭]</title>
      <link>https://stackoverflow.com/questions/79472624/anomaly-detection-ml-training-with-none-or-few-anomalies</link>
      <description><![CDATA[使用隔离森林对无监督的非序列数据进行异常检测时，局部离群因子具有低变化变量，例如温度和湿度。
，我们通过读取模型来训练该模型，这些读数可以被认为是我们案件正常的读数。因此，几乎没有我们的目标“异常”。
它会使模型更敏感地将值标记为异常吗？
可以通过“种植”来解决此类问题。拥有异常。
例如。从温度，二氧化碳，湿度等房间收集读数时，我们会燃烧与之旁边的匹配项，或者亲自更改数据。]]></description>
      <guid>https://stackoverflow.com/questions/79472624/anomaly-detection-ml-training-with-none-or-few-anomalies</guid>
      <pubDate>Thu, 27 Feb 2025 12:07:53 GMT</pubDate>
    </item>
    <item>
      <title>在序列编码中，whand_unknown = use_encoded_values做什么？</title>
      <link>https://stackoverflow.com/questions/79471646/in-ordinal-encoder-what-does-handle-unknown-use-encoded-values-do</link>
      <description><![CDATA[我已经完成了研究，但我对文档和双子座的答案不满意。  use_encoded_value 它是什么意思？我必须通过一个论点作为编码值吗？如果是这样，您可以举例说明它的用法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79471646/in-ordinal-encoder-what-does-handle-unknown-use-encoded-values-do</guid>
      <pubDate>Thu, 27 Feb 2025 05:09:19 GMT</pubDate>
    </item>
    <item>
      <title>pytorch pascalvoc数据集中的数据加载器错误：runtimeerror：批次列表中的每个元素都应相等</title>
      <link>https://stackoverflow.com/questions/78620402/dataloader-error-in-pytorch-pascalvoc-dataset-runtimeerror-each-element-in-lis</link>
      <description><![CDATA[尝试实现Yolo算法时，其中一个步骤是将每个图像大小调整到（448，448）。但是即使使用转换，数据集加载器都抛出了有关数据集中大小差的例外。
确切的错误消息：&#39;runtimeError：批次列表中的每个元素应为相等的
 来自torchvision导入数据集
从torchvision.transforms导入v2，totensor

来自torch.utils.data导入数据加载程序

验证_data = datasets.voc.vocdetection（
    root =&#39;。data/&#39;，
    下载= false，
    image_set =; val＆quot;
    transform = v2.compose（[v2.Resize（size =（448，448））），totensor（）））
）

batch_size = 64

验证_dataloader = dataloader（验证_data，batch_size = batch_size）

对于x，y在验证_dataloader中：
    打印（x [n，c，h，w]的f＆quot：{x.shape}＆quot;）
    休息
 ]]></description>
      <guid>https://stackoverflow.com/questions/78620402/dataloader-error-in-pytorch-pascalvoc-dataset-runtimeerror-each-element-in-lis</guid>
      <pubDate>Thu, 13 Jun 2024 22:43:49 GMT</pubDate>
    </item>
    <item>
      <title>KeyError：Hugginface Trainer中的“ eval_loss”</title>
      <link>https://stackoverflow.com/questions/74239556/keyerror-eval-loss-in-hugginface-trainer</link>
      <description><![CDATA[我正在尝试使用Hugginface Framework构建一个问题回答管道，但面对 keyError：&#39;eval_loss&#39;错误。我的目标是终于训练和保存最佳模型，并在加载模型上评估验证测试。我的教练配置看起来像这样：
  args = trainingarguments（f&#39;model_training&#39;，
                      evalution_strategy =&#39;epoch; quot;
                      label_names = [&#39;start_positions; quot&#39;end_positions;]，
                      logging_steps = 1，
                      Learning_rate = 2e-5，
                      num_train_epochs = epochs，
                      save_total_limit = 2，
                      load_best_model_at_end = true，
                      save_strategy =&#39;epoch; quot;
                      logging_strategy =＆quot; epoch;
                      report_to =; none＆quort;;
                      weight_decay = 0.01，
                      fp16 = true，
                      push_to_hub = false）
 
训练时，遇到此错误：
  trackback（最近的最新通话）：
  文件“ qa_pipe.py”，第286行，in＆lt; module＆gt;
    管道。训练（train_d，val_d，epochs = 2）
  文件“ qa_pipe.py”，第263行，在培训中
    self.trainer.train（）
  file＆quot＆quot＆quot&#39;
    ignore_keys_for_eval = improre_keys_for_eval，
  file＆quot＆quort＆quort＆quot＆quot python3.7/site-packages/transformers/trainer.py&quot; line 1838，in _inner_training_loop
    self。
  file＆quot＆quort＆quort＆quot＆quot＆quot pytransformers/transformers/trainer.py&quot;，第2090行，在_maybe_log_save_evaluate中
    self._save_checkpoint（模型，试用，指标=指标）
  file＆quot＆quot＆quot＆quot＆quot in _save_checkpoint，第2193行
    metric_value =度量[metric_to_check]
KeyError：&#39;eval_loss&#39;
 
在如何避免此错误并终于保存最佳模型？]]></description>
      <guid>https://stackoverflow.com/questions/74239556/keyerror-eval-loss-in-hugginface-trainer</guid>
      <pubDate>Fri, 28 Oct 2022 18:30:28 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：不可用的类型：pd.get_dummies的“系列”</title>
      <link>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</link>
      <description><![CDATA[我试图在我拥有的数据框中的某些名义数据上使用 pd.get_dummies （从Kaggle回归）。我将所有名义类别分为列名列表，&#39;obj_nominal&#39;。
我打电话
  pd.get_dummies（df，columns = obj_nominal）
 
我遇到了错误：
  typeError：不可用的类型：&#39;系列&#39;。
 
到目前为止，我唯一完成的预处理是删除数据集中的空值。我还尝试使用sklearn  onehotencoder ，并且会产生相同的错误。
我还尝试使用：进行单独的数据帧
  x = df.iloc [：,, obj_nominal]
 
和在数据框架上通过get_dummies：
  pd.get_dummies（data = x）
 
但仍然没有运气... 
The data is downloadable at https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data]]></description>
      <guid>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</guid>
      <pubDate>Fri, 07 Jan 2022 05:51:22 GMT</pubDate>
    </item>
    <item>
      <title>如何将边界框（X1，Y1，X2，Y2）转换为Yolo样式（X，Y，W，H）</title>
      <link>https://stackoverflow.com/questions/56115874/how-to-convert-bounding-box-x1-y1-x2-y2-to-yolo-style-x-y-w-h</link>
      <description><![CDATA[我正在训练Yolo模型，我的边界框以这种格式： -  
  x1，y1，x2，y2 =＆gt;例如（100、100、200、200）
 
我需要将其转换为yolo格式，以便是： -  
  x，y，w，h =＆gt; 0.436262 0.474010 0.383663 0.178218
 
我已经计算了中心点X，Y，高度H和重量W。
但是仍然需要一个客场将它们转换为提到的浮数。]]></description>
      <guid>https://stackoverflow.com/questions/56115874/how-to-convert-bounding-box-x1-y1-x2-y2-to-yolo-style-x-y-w-h</guid>
      <pubDate>Mon, 13 May 2019 15:52:12 GMT</pubDate>
    </item>
    <item>
      <title>来自_logits = try或false的含义是什么？</title>
      <link>https://stackoverflow.com/questions/55290709/what-does-from-logits-true-or-false-mean-in-sparse-categorical-crossentropy-of</link>
      <description><![CDATA[在Tensorflow 2.0中，
有一个称为的损失功能
  tf.keras.losses.sparse_categorical_crossentropy（标签，目标，from_logits = false）
 
设置 from_logits = true 或 false ？之间有什么区别
我的猜测是，当传入值是logits时，您将从_logits = true设置，并且如果传入值是概率（通过softmax等），则您只需设置from_logits = false（这是默认设置）。。
但是为什么？损失只是一些计算。为什么它需要通过其传入价值而有所不同？
我还在Google的Tensorflow教程中看到
 htttps://wwwww.tensorflow.org/alpha/alpha/alpha/tutorials/tutorials/sequences/sequences/sequences/sequences/textex_gentex_gentex_genert_genert_genert_generat_generatex_generatex_generatex_generatex_generatex_generatect_generation    &gt;
即使最后一层的传入值是logits，它也不会从_logits = true设置。
这是代码
 @tf.function
def train_step（INP，目标）：
  用tf.gradienttape（）作为磁带：
    预测=模型（INP）
    损失= tf.reduce_mean（
        tf.keras.losses.sparse_categorical_crossentropy（目标，预测））
  grads = tape.Gradient（损失，模型。Trainable_variables）
  优化器。Apply_gradients（zip（grads，model.trainable_variables））

  回报损失
 
模型为
 模型= tf.keras.Sequeential（[[[
    tf.keras.layers.embedding（vocab_size，embedding_dim， 
                              batch_input_shape = [batch_size，none]），），
    tf.keras.layers.lstm（rnn_units， 
                        return_sequences = true， 
                        状态= true， 
                        recurrent_initializer =&#39;glorot_uniform&#39;），
    tf.keras.layers.dense（vocab_size）
  ）））
 
没有softmax的最后一层。
（另外，在教程的另一部分中，它设置了 from_logits = true ）
所以，我是否将其设置为 true ？都没有关系？]]></description>
      <guid>https://stackoverflow.com/questions/55290709/what-does-from-logits-true-or-false-mean-in-sparse-categorical-crossentropy-of</guid>
      <pubDate>Thu, 21 Mar 2019 23:26:35 GMT</pubDate>
    </item>
    <item>
      <title>文档分析和标记[封闭]</title>
      <link>https://stackoverflow.com/questions/5107371/document-analysis-and-tagging</link>
      <description><![CDATA[假设我有一堆我想标记，分类等的论文（数千）。理想情况下，我想通过手动对几百个进行分类/标记来训练   ，然后让事物放松。 。
您会推荐哪些资源（书籍，博客，语言）进行此类任务？  我的一部分认为这非常适合 href =“ http://en.wikipedia.org/wiki/latent_semantic_analysis” rel =“ nofollow noreferrer”&gt;潜在的语义分析，但我对几个 ruby​​   gems 。。
贝叶斯分类器可以解决这样的事情吗？  我应该更多地研究语义分析/自然语言处理吗？  或者，我应该只是在寻找关键字密度和映射吗？]]></description>
      <guid>https://stackoverflow.com/questions/5107371/document-analysis-and-tagging</guid>
      <pubDate>Thu, 24 Feb 2011 16:20:43 GMT</pubDate>
    </item>
    </channel>
</rss>