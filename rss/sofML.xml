<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 09:16:12 GMT</lastBuildDate>
    <item>
      <title>强化学习代理没有采取现实行动</title>
      <link>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</link>
      <description><![CDATA[我在 Simulink 环境中使用 PPO 代理，但代理产生的操作似乎是离散的。具体来说，代理仅输出上限或下限。您知道为什么会发生这种情况吗？我正在使用 RL Toolbox 进行训练。
以下是有关我的设置的一些详细信息：
我正在使用带有 ode23t 求解器的可变步长 Simulink 模型。
我的 Simulink 模型使用 Simscape 热流体库并模拟简化的区域供热网络。DHN 有 2 个分支：北 (NORD) 和南 (SUD)。
我正在尝试使用 RL 代理来优化控制，最初专注于通过改变分支中的质量流量来最大限度地降低能源成本。
关于代理的超参数，我使用的是 RL Toolbox，其参数如下：
采样时间 = 3600
折扣因子 = 0.99
GPU
批量大小 = 512
学习率 = 1e-3（对于演员和评论家）
我怀疑我的模型或代理可能存在问题。我将附上 Simulink 模型（应事先加载属性表）。我希望问题清楚，有人可以提供帮助！
​​提前谢谢您！
我尝试更改超参数，但没有任何变化]]></description>
      <guid>https://stackoverflow.com/questions/78724550/reinforcement-learning-agent-not-taking-realistic-actions</guid>
      <pubDate>Tue, 09 Jul 2024 08:41:06 GMT</pubDate>
    </item>
    <item>
      <title>eval（predvars、data、env）中出现错误：未找到对象“s_id”</title>
      <link>https://stackoverflow.com/questions/78722442/error-in-evalpredvars-data-env-object-s-id-not-found</link>
      <description><![CDATA[我正在尝试使用 tidymodels 拟合多层模型。当我拟合单个模型时，我没有遇到问题，但当我将它们组合到工作流集中时，我得到了这些错误。
我看到过有类似错误的帖子，并尝试更新我的代码，但似乎仍然不起作用。
当我在应用配方后查看训练和验证集时，我确实在数据框中找到所有列。不确定为什么错误仍然存​​在。当我使用非多级算法时，不会出现此错误。
我希望有人可以帮助解决此错误：
pacman::p_load(labelled,forcats,rstanarm,tidymodels,dplyr,parsnip,baguette,future,finetune,rules,rsample,
multilevelmod,ranger,earth,readr,stacks)

plan(multisession)

load(url(&quot;http://alecri.github.io/downloads/data/dental.RData&quot;))

dental_long &lt;- pivot_longer(dental, cols = starts_with(&quot;y&quot;), 
names_to = &quot;measurement&quot;, values_to = &quot;distance&quot;) %&gt;% 
mutate(
age = parse_number(measurement),
measure = fct_inorder(paste(&quot;测量年龄&quot;, age)),
s_id=as.factor(id)
) %&gt;% 
set_variable_labels(
age = &quot;测量时孩子的年龄&quot;,
measure = &quot;时间测量标签&quot;,
distance = &quot;测量值&quot;
) %&gt;% select(-measurement,-id)

#将数据拆分为训练集、验证集和测试集
set.seed(11)
splitsx &lt;- group_initial_split(dental_long, group = s_id,prop = 0.8)

dental_train &lt;- training(splitsx)
dental_val &lt;- testing(splitsx)

#创建交叉验证折叠
foldsx &lt;- group_vfold_cv(dental_train, v = 3,group = s_id，重复次数 = 3)

mixed_basic_recipex &lt;- recipe(distance ~ ., data = dental_train)

mixed_poly_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
step_scale(all_numeric_predictors()) %&gt;%
step_poly(all_numeric_predictors(),degree = 2,keep_original_cols = F) %&gt;%
step_dummy(all_nominal_predictors() &amp; !matches(&#39;s_id&#39;)) #%&gt;% 
# step_interact(~all_numeric_predictors():all_numeric_predictors() )

# df1 &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

#mixed model
lmer_specx &lt;-
linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;lmer&quot;)

bayes_specx &lt;- linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;stan_glmer&quot;)

fullx &lt;- 
workflow_set(
preproc = list( mixed_poly = mix_poly_recipex
), 
models = list(bayesMixed = bayes_specx,lmmixed = lmer_specx

)
)

#贝叶斯调整和度量的设置
bayes_ctrl &lt;-
control_bayes(
save_pred = TRUE,
parallel_over = &quot;everything&quot;,
save_workflow = TRUE,
verbose = TRUE,
no_improve = 20
)
rmse_res &lt;- metric_set(rmse,rsq)

basicbkx &lt;- prep(mixed_basic_recipex) %&gt;% bake(dental_train)
polybkx &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

polyform &lt;- reformulate(c(setdiff(colnames(polybkx), c(&quot;距离&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)
basicform &lt;- reformulate(c(setdiff(colnames(basicbkx), c(&quot;distance&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)

all_wfx1 &lt;- fullx %&gt;% 
# update_workflow_model(id=&#39;basic_bayesMixed&#39;,spec=bayes_specx,
# formula = basicform) %&gt;% 
update_workflow_model(id=&#39;mixed_poly_bayesMixed&#39;,spec=bayes_specx,
formula = polyform) %&gt;%
# update_workflow_model(id=&#39;basic_lmmixed&#39;,spec=lmer_specx,
# formula = basicform) %&gt;%
update_workflow_model(id=&#39;mixed_poly_lmmixed&#39;,spec=lmer_specx,
formula = polyform)

test_results &lt;-
all_wfx1 %&gt;%
working_map(
&quot;tune_bayes&quot;,
seed = 10,
resamples = foldsx,
control = bayes_ctrl
)

编辑：
我尝试了不同的方法。我在添加公式之前使用 update_workflow_recipe 添加了配方。这似乎适用于混合模型，但我对贝叶斯模型有一个不同的错误
这是更新的位：
all_wfx1 &lt;- fullx %&gt;% 
update_workflow_recipe(id=&#39;mixed_poly_lmmixed&#39;,recipe = hybrid_poly_recipex) %&gt;%
update_workflow_model(id=&#39;mixed_poly_lmmixed&#39;,spec=lmer_specx,
formula = distance ~ . -s_id + (1 | s_id)) %&gt;%

update_workflow_recipe(id=&#39;mixed_poly_bayesMixed&#39;,recipe = hybrid_poly_recipex) %&gt;%
update_workflow_model(id=&#39;mixed_poly_bayesMixed&#39;,spec=bayes_specx,
formula = distance ~ . -s_id + (1 | s_id))

新的错误是 terms.formula(formula(x, fixed.only = TRUE) 中的错误：公式中的 &#39;.&#39; 且没有 &#39;data&#39; 参数]]></description>
      <guid>https://stackoverflow.com/questions/78722442/error-in-evalpredvars-data-env-object-s-id-not-found</guid>
      <pubDate>Mon, 08 Jul 2024 18:42:06 GMT</pubDate>
    </item>
    <item>
      <title>scikit学习交叉验证分数负值</title>
      <link>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</link>
      <description><![CDATA[我试图建立一个线性回归模型来预测房价，以便从机器学习开始，但在使用以下代码中的交叉验证时遇到负分数值：
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
x = df.drop([&#39;MedHouseVal&#39;], axis=1)
y = df[&#39;MedHouseVal&#39;]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
model = LinearRegression()
model.fit(x_train, y_train)
model.score(x_test, y_test)
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=100)
plt.plot(scores)

我注意到，随着 cv 的增加，平均分数下降。因此，我决定绘制它，并意识到分数在某些时候会呈现负值，但真实预测/样本大小怎么会是负数呢？它是用 (TP + TN - FP - FN)/样本大小计算的吗？
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</guid>
      <pubDate>Mon, 08 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>我的预测张量值太低</title>
      <link>https://stackoverflow.com/questions/78721417/my-tensor-values-in-the-prediction-are-too-low</link>
      <description><![CDATA[我正在训练一个语义分割模型，使用 PyTorch 和 U-net 架构。数据集由视网膜摄影图像组成，带有渗出性疾病的掩码。我遇到了张量值不一致的问题，当我尝试进行新的预测时，我在训练时跟踪了张量，并且在训练期间值是一致的，但在执行新的预测时，值不一致且奇怪，导致掩码毫无意义。
def train_epoch(model, loader, criterion, optimizer, device):
model.train()
epoch_loss = 0

for i, (images, mask) in enumerate(loader):
unique_values = torch.unique(masks)
assert unique_values.numel() == 2, f&quot;Expected mask values to be either 0 or 1, but got {unique_values}&quot;

images = images.to(device)
mask = mask.to(device)

output = model(images)
unique_values_output_train = torch.unique(outputs)
print(f&#39;唯一值输出训练：{unique_values_output_train}&#39;)

output_bin = torch.sigmoid(outputs)
unique_values_output_bin = torch.unique(outputs_bin)
print(f&#39;唯一值输出训练 BIN：{unique_values_output_bin}&#39;)

loss = criterion(outputs, mask)
unique_values_loss_train = torch.unique(loss)
print(f&#39;值损失训练：{unique_values_loss_train}&#39;)

optimizer.zero_grad()
loss.backward()
optimizer.step()

epoch_loss += loss.item()

return epoch_loss / len(loader)


唯一值输出训练：张量（[-1.6558, -1.6541, -1.6541, ..., 0.4275, 0.4280, 0.4322],
device=&#39;cuda:0&#39;, grad_fn=&lt;Unique2Backward0&gt;)
唯一值输出训练 BIN：张量（[0.1474, 0.1475, 0.1475, ..., 0.7301, 0.7314, 0.7320], device=&#39;cuda:0&#39;,
grad_fn=&lt;Unique2Backward0&gt;)

def plot_predictions(dataset, model, device, num_samples=3):
model.eval()
fig, axs = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))

with torch.no_grad():
for i in range(num_samples):
idx = np.random.randint(0, len(dataset)) 
image, mask = dataset[idx]
image = image.to(device).unsqueeze(0)
mask = mask.to(device)

preds = torch.sigmoid(model(image))
print(f&#39;预测值：{preds}&#39;)

preds = (preds &gt; 0.5).float().cpu().numpy().squeeze(0)
unique_values_sigmoid = np.unique(preds)
print(f&#39;唯一值 sigmoid：{unique_values_sigmoid}&#39;)

image_np = image.cpu().squeeze(0).permute(1, 2, 0).numpy()
if image_np.shape[-1] == 1: 
image_np = image_np.squeeze(-1)

axs[i][0].imshow(image_np, cmap=&#39;gray&#39; if image_np.ndim == 2 else None)
axs[i][0].set_title(f&#39;图像 {idx}&#39;)
axs[i][0].axis(&#39;off&#39;)

mask_np = mask.cpu().numpy()
if mask_np.ndim == 3 和 mask_np.shape[0] == 1: 
mask_np = mask_np.squeeze(0)
elif mask_np.ndim == 3 和 mask_np.shape[-1] == 1:
mask_np = mask_np.squeeze(-1)

axs[i][1].imshow(mask_np, cmap=&#39;gray&#39;)
axs[i][1].set_title(f&#39;Mask {idx}&#39;)
axs[i][1].axis(&#39;off&#39;)

如果 preds.ndim == 3 和 preds.shape[0] == 1:
preds = preds.squeeze(0)

axs[i][2].imshow(preds, cmap=&#39;gray&#39;)
axs[i][2].set_title(f&#39;Prediction {idx}&#39;)
axs[i][2].axis(&#39;off&#39;)

plt.tight_layout()
plt.show()

预测值：张量([[[[0.0970, 0.0935, 0.0969, ..., 0.0962, 0.0990, 0.1000],
[0.0958, 0.0983, 0.1032, ..., 0.1014, 0.1013, 0.1044],
[0.0990, 0.0993, 0.1037, ..., 0.0998, 0.0996, 0.1008],
...,
[0.0981, 0.0985, 0.1002, ..., 0.1003, 0.0990, 0.1010],
[0.0986, 0.0993, 0.0993, ..., 0.1000, 0.0990, 0.1008],
[0.0917, 0.0949, 0.0965, ..., 0.0961, 0.0943, 0.0984]]]],
device=&#39;cuda:0&#39;)
唯一值 sigmoid：[0.]

我做了几次尝试，例如使用另一个损失函数、将 sigmoid 直接应用于 U-net 架构、更改 sigmoid 二值化值、将二值化应用于掩码等。]]></description>
      <guid>https://stackoverflow.com/questions/78721417/my-tensor-values-in-the-prediction-are-too-low</guid>
      <pubDate>Mon, 08 Jul 2024 14:28:47 GMT</pubDate>
    </item>
    <item>
      <title>经过微调的 Mask2Former 模型在训练后仅返回空张量</title>
      <link>https://stackoverflow.com/questions/78721111/fine-tuned-mask2former-model-only-returning-null-tensors-after-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78721111/fine-tuned-mask2former-model-only-returning-null-tensors-after-training</guid>
      <pubDate>Mon, 08 Jul 2024 13:25:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用预训练模型改进森林卫星图像中的树木检测和计数？[关闭]</title>
      <link>https://stackoverflow.com/questions/78720461/how-to-improve-tree-detection-and-counting-in-forest-satellite-imagery-using-pre</link>
      <description><![CDATA[我正在开发一个人工智能林业管理系统，使用来自 Google Earth 的卫星图像来监测和分析树木种群。主要目标是准确计数树木并识别濒危或本土物种。我已经实施了一个用于图像分割的 U-Net 模型，但准确性并不令人满意，许多树木被遗漏或错误计数。
我当前的工作流程：

数据采集：从 Google Earth 收集卫星图像。
预处理：规范化和增强图像。
图像分割：使用 U-Net 进行初始树冠分割。
树木计数：应用轮廓检测​​来计数树木。
物种识别：旨在根据分割区域对树种进行分类（尚未实施）。

我面临的问题

准确性：U-Net 模型无法准确检测和计数树木。

我尝试过的方法：

实施 U-Net 进行分割。
尝试使用来自segmentation_models 库的预训练 U-Net 模型，但面临层形状和输入维度错误。

问题：

预训练模型：可用于卫星图像中树木检测的最佳预训练模型有哪些，我如何有效地将它们集成到我的项目中？
在哪里可以找到高质量的数据集用于卫星或航空图像中的树木检测和物种识别？
我可以采取哪些技术或其他预处理步骤来提高树木检测和计数的准确性？

其他信息：

我正在使用 Python 和 TensorFlow、Keras 和 OpenCV 等库。

我探索了各种数据集，但不确定哪些数据集对于训练稳健模型最有效。

]]></description>
      <guid>https://stackoverflow.com/questions/78720461/how-to-improve-tree-detection-and-counting-in-forest-satellite-imagery-using-pre</guid>
      <pubDate>Mon, 08 Jul 2024 11:02:08 GMT</pubDate>
    </item>
    <item>
      <title>术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可运行程序的名称</title>
      <link>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</link>
      <description><![CDATA[在运行此最终命令时，我在本地笔记本电脑上执行自定义数据集上的 yolov3 操作，所有操作均已完成
./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg darknet53.conv.74

当我使用 Windows Power Shell 时，出现错误，即
./darknet：术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可操作程序的名称。请检查名称的拼写，或者如果包含路径，请验证路径是否正确，然后重试。
在第 1 行，字符：1
+ ./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg darknet5 ...
+ ~~~~~~~~~
+ CategoryInfo : ObjectNotFound: (./darknet:String) [], CommandNotFoundException
+ FullyQualifiedErrorId : CommandNotFoundException

那么我该如何解决此错误
我尝试更改系统环境变量路径，也尝试运行某些命令，但仍然抛出相同的错误，那么我应该尝试什么呢]]></description>
      <guid>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</guid>
      <pubDate>Mon, 08 Jul 2024 08:00:10 GMT</pubDate>
    </item>
    <item>
      <title>生存分析 - 估计预期寿命</title>
      <link>https://stackoverflow.com/questions/78719590/survival-analysis-estimating-life-expectancy</link>
      <description><![CDATA[我正在探索生存分析，我的目标是找到一个预测预期寿命（以年为单位）的模型，而不是基于几种生活方式变量的风险比。我有很多饮食变量和二元变量——死亡率。
我使用 Kaplan Meyer 并计算间隔内的 AUC（死亡年龄/审查直到队列的最后一个年龄）来估计预期寿命损失年数。但是，我无法用这种方法使用这些变量。
我也看到了 Cox 比例模型中的函数 predict_survival_function，但曲线没有收敛到 0，因此计算 AUC 没有意义。
我遇到了加速失效时间模型，它似乎允许考虑变量并计算生存时间。有人将它用于类似的目的吗？
有人对预期寿命估计有什么建议吗？有人探索过与随机生存森林相关的任何内容吗？]]></description>
      <guid>https://stackoverflow.com/questions/78719590/survival-analysis-estimating-life-expectancy</guid>
      <pubDate>Mon, 08 Jul 2024 07:31:51 GMT</pubDate>
    </item>
    <item>
      <title>Darknet Yolov4-tiny（灰度输入）到 Tensorflow 权重，转换</title>
      <link>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</link>
      <description><![CDATA[TL;DR:
1 通道 TF 模型的行为与 3 通道模型不同。两者都成功从 Darknet -&gt; TF 转换，但 1 通道模型的表现不如转换前。
手头的任务和声明：
我有两个经过训练的 yolov4-tiny darknet 权重文件 (.weights)，一个有灰度输入（1 通道），另一个有颜色输入（3 通道）。我正在将两个权重文件转换为 Tensorflow 检查点格式，使用一个通用存储库（用于此任务），该存储库位于：
https://github.com/hunglc007/tensorflow-yolov4-tflite.git
两种模型的性能都已通过 c++ opencv readNetFromDarknet() 和 Python 等效项进行了测试。这两个模型都是用灰度图像进行训练的，并且对灰度图像进行操作。3 通道模型的输入只是缩放到 3 通道的灰度图像。
Python 版本：3.10.11
TF 版本：2.10.1
问题陈述：
使用 tf.keras.Models.load_model(X) 加载时，带有颜色输入的权重文件转换良好，之后运行良好，但是当转换灰度输入权重文件时，使用 Tensorflow 加载时模型的性能急剧下降，我的意思是在最明显的情况下，检测结果很差或不存在，而带有颜色输入的模型运行完美。值得注意的是，框不会错位，这意味着当发现检测结果时，它们大致处于正确的位置，但例如宽度和高度可能会偏离。
我知道这个存储库的常见问题（硬编码内容等），并相应地更改了每次转换/模型加载的参数，并且在转换或模型加载期间不会发生任何错误。
我已经确认了输入层：

灰度：（无，640,640,1）
颜色：（无，640,640,3）

测试图像（用于性能测试）使用 opencv-python 加载，并且它们的有效性也已审查，即使将错误维度的数据插入到输入层也会出现错误。
除输入层之外的架构相同，已使用 model.summary() 确认。
我注意到，几年前我用不同的 TF 版本转换的 3 通道模型由 model.summary() 生成的架构有些不同。一些图块层似乎缺失了。此外，一些 tf 操作的名称也不同，但这可能只是 TF 版本不同。
旧颜色模型：
 tf_op_layer_Sigmoid (TensorFlo (None, 40, 40, 3, 2 0 [&#39;tf_op_layer_split_3[0][0]&#39;]
wOpLayer) )

tf_op_layer_Tile/multiples (Te (5,) 0 [&#39;tf_op_layer_strided_slice[0][0]
nsorFlowOpLayer) &#39;]

tf_op_layer_Sigmoid_3 (TensorF (None, 20, 20, 3, 2 0 [&#39;tf_op_layer_split_4[0][0]&#39;]
lowOpLayer) ) )

新灰度模型：
 tf.math.sigmoid (TFOpLambda) (无，40，40，3，2 0 [&#39;tf.split_3[0][0]&#39;]
)

---此处缺少图块层---

tf.math.sigmoid_3 (TFOpLambda) (无，20，20，3，2 0 [&#39;tf.split_4[0][0]&#39;]
)

我现在很卡。有什么帮助吗？
一些反复试验：

使用 Yolov4-tiny Head 解码块 -&gt;即使在模型能够加载的情况下也没有变化（解码时错误的尺寸会引发错误）
之前提到的较旧的 3 通道模型（几年前已转换为 Darknet -&gt; TF），当以与新模型相同的方式加载时，可以完美运行

解决方案：
我从 c++ 打印了带有形状的图层，因为模型在那里工作，我很想知道形状是否完全不同。第一个卷积层根本没有缩小。我检查了 Darknet 用于解析模型的 .cfg 文件，第一个卷积层上有一行“size=3stride=2”。大小解析正确，但步幅解析不正确，并且默认为 1，这使得第一个卷积层的形状为 (640,640,32)，而不是预期的（正确的）(320,320,32)。当我将权重加载到正确的架构时，它当然表现不佳，因为它是用另一种布局训练的。我怀疑我用没有这个错误的 .cfg 训练了 3 通道模型，这就是它完美运行的原因。]]></description>
      <guid>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</guid>
      <pubDate>Fri, 05 Jul 2024 13:54:37 GMT</pubDate>
    </item>
    <item>
      <title>在具有标准化变量的模型中缩放样本外预测：恢复到原始比例</title>
      <link>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</link>
      <description><![CDATA[我正在使用一个模型进行预测，其中变量按 $ x_i = \frac{{x_i - \text{mean}(x_i)}}{{\text{sd}(x_i)}} $ 缩放，并且我保存了平均值和标准差。现在，对于样本外预测，假设目标变量 $ ( x_i )$，基于缩放模型，我该如何缩小预测范围？
我是否应该使用样本内 $ \text{Mean}(x_i) $ 和 $ \text{sd}(x_i) $ 来缩小样本外预测范围，以便：
$ \text{重新缩放的样本外预测} = \text{缩放的预测} \times \text{sd}(x_i) + \text{mean}(x_i) $
这里的适当程序是什么？
Python 示例：
X = np.random.randn(100, 1) * 10 + 50 # 特征
y = 2 * X + 1 + np.random.randn(100, 1) * 5 # 目标变量
X_train, X_test = X[:80], X[80:]
y_train, y_test = y[:80], y[80:]

scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
y_train_scaled = scaler_y.fit_transform(y_train)

model = LinearRegression()
model.fit(X_train_scaled, y_train_scaled)
]]></description>
      <guid>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</guid>
      <pubDate>Tue, 04 Jun 2024 15:17:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Spark 中获取 spark.ml NaiveBayes 概率向量而非 [0-1] 类？</title>
      <link>https://stackoverflow.com/questions/65653286/how-to-get-spark-ml-naivebayes-probability-vector-not-0-1-class-in-spark</link>
      <description><![CDATA[我正在研究 NaiveBayes 分类器，我可以使用训练后的模型预测单个数据点的值，但我想获取概率值。
数据仅分为两类。并且预测函数返回 0 或 1。
import org.apache.log4j.{Level, Logger}
import org.apache.spark.ml.classification.{NaiveBayes, NaiveBayesModel}
import org.apache.spark.ml.feature.LabeledPoint
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.sql.SparkSession

object Test {
def main(args: Array[String]): Unit = {
Logger.getLogger(&quot;org&quot;).setLevel(Level.OFF)
Logger.getLogger(&quot;akka&quot;).setLevel(Level.OFF)
val spark = SparkSession.builder.appName(&quot;Test&quot;).master(&quot;local[4]&quot;).getOrCreate
val dataset = spark.read.option(&quot;inferSchema&quot;, &quot;true&quot;).csv(&quot;data/labelled.csv&quot;).toDF()

import spark.sqlContext.implicits._
val output = dataset.map(row =&gt; {
LabeledPoint(row.getInt(2), Vectors.dense( row.getInt(0) , row.getInt(1)))
})
val Array(training, test) = output.randomSplit(Array(0.7, 0.3),seed = 11L)
training.cache()

val model : NaiveBayesModel = new NaiveBayes().fit(training)
val speed = 110
val hour = 11
val label1 : Double = model.predict(Vectors.dense(speed,hour))
// 更新
val label = model.predictProbability(Vectors.dense(speed,hour)) // 这不起作用并引发错误[1]
}
}

[1] 使用 model.predictProbability 时引发的错误

错误：(24, 23) 类 ProbabilisticClassificationModel 中的方法 predictProbability 无法在 org.apache.spark.ml.classification.NaiveBayesModel 中访问。无法访问受保护的方法 predictProbability，因为封闭的对象 Test 不是包分类中类 ProbabilisticClassificationModel 的子类，其中定义了目标 val label = model.predictProbability(Vectors.dense(speed,hour))
]]></description>
      <guid>https://stackoverflow.com/questions/65653286/how-to-get-spark-ml-naivebayes-probability-vector-not-0-1-class-in-spark</guid>
      <pubDate>Sun, 10 Jan 2021 12:30:28 GMT</pubDate>
    </item>
    <item>
      <title>SVM.SVC() 中的 gamma 参数实际上起什么作用</title>
      <link>https://stackoverflow.com/questions/59594653/what-does-the-gamma-parameter-in-svm-svc-actually-do</link>
      <description><![CDATA[我正在尝试调整我的 SVM 模型，该模型是我使用不同的 gamma 和 C 值构建的。
此外，我还使用了缩放的输入数据进行模型训练。
在尝试了多种组合后，我确实找到了一种 gamma 和 C 的组合，它提供了最佳准确性，尽管我完全不知道 gamma 的作用；PFB：
svc = svm.SVC(gamma=0.025, C=25)

我阅读了文档以了解 gamma 的实际作用（其中说，“‘rbf’、‘poly’ 和 ‘sigmoid’ 的核系数”），现在我更加困惑了。
任何帮助都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/59594653/what-does-the-gamma-parameter-in-svm-svc-actually-do</guid>
      <pubDate>Sat, 04 Jan 2020 20:40:18 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit learn 中实现自定义损失函数</title>
      <link>https://stackoverflow.com/questions/54267745/implementing-custom-loss-function-in-scikit-learn</link>
      <description><![CDATA[我想在 scikit learn 中实现自定义损失函数。我使用以下代码片段：
def my_custom_loss_func(y_true,y_pred):
diff3=max((abs(y_true-y_pred))*y_true)
return diff3

score=make_scorer(my_custom_loss_func,greater_ is_better=False)
clf=RandomForestRegressor()
mnn= GridSearchCV(clf,score)
knn = mnn.fit(feam,labm) 

传递给 my_custom_loss_func 的参数应该是什么？我的标签矩阵称为 labm。我想计算实际输出与预测输出（由模型）乘以真实输出之间的差值。如果我使用 labm 代替 y_true，那么我应该使用什么代替 y_pred？]]></description>
      <guid>https://stackoverflow.com/questions/54267745/implementing-custom-loss-function-in-scikit-learn</guid>
      <pubDate>Sat, 19 Jan 2019 13:47:47 GMT</pubDate>
    </item>
    <item>
      <title>ImportError（'无法导入 PIL.Image。'与 keras-ternsorflow 合作</title>
      <link>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</link>
      <description><![CDATA[我正在学习 lynda.com 上的一些关于在 PyCharmCE 环境中使用 Keras-TensorFlow 进行深度学习的讲座，他们没有遇到这个问题。
我收到此错误：

raise ImportError(&#39;无法导入 PIL.Image。&#39;
ImportError：无法导入 PIL.Image。使用 array_to_img 需要 PIL。

我检查过其他人是否也遇到同样的错误，但对于我来说，使用 pip 安装枕头，命令 pip install Pillow 无法解决任何问题。

MacBook-Pro-de-Rogelio:~ Rogelio$ pip install Pillow
要求已满足：./anaconda3/lib/python3.6/site-packages 中的枕头
MacBook-Pro-de-Rogelio:~ Rogelio$

有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/48225729/importerrorcould-not-import-pil-image-working-with-keras-ternsorflow</guid>
      <pubDate>Fri, 12 Jan 2018 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.decomposition.PCA 的特征向量简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我试图了解主成分分析的工作原理，并在sklearn.datasets.load_iris数据集上对其进行测试。我了解每个步骤的工作原理（例如，标准化数据、协方差、特征分解、按最高特征值排序、使用K个选定维度将原始数据转换为新轴）。
下一步是可视化这些特征向量在数据集上投影的位置（在PC1 vs. PC2 图上，对吗？）。
有人可以解释如何在降维数据集的 3D 图上绘制 [PC1、PC2、PC3] 特征向量吗？
此外，我是否正确绘制了这个 2D 版本？我不确定为什么我的第一个特征向量的长度较短。我应该乘以特征值吗？

以下是我为实现此目标所做的一些研究：
我遵循的 PCA 方法来自：
https://plot.ly/ipython-notebooks/principal-component-analysis/#Shortcut---PCA-in-scikit-learn（虽然我不想使用 plotly。我想坚持使用 pandas、numpy、sklearn、matplotlib、scipy 和 seaborn）
我一直在遵循这个绘制特征向量的教程，它看起来很不错简单：使用 matplotlib 进行 PCA 的基本示例，但我似乎无法用我的数据复制结果。
我发现了这一点，但对于我想做的事情来说，它似乎过于复杂，而且我不想创建一个 FancyArrowPatch：使用 matplotlib 和 np.linalg 绘制协方差矩阵的特征向量

我试图让我的代码尽可能简单，以便遵循其他教程：
导入 numpy 作为 np
导入 pandas 作为 pd
导入 matplotlib.pyplot 作为 plt
从 sklearn.datasets 导入 load_iris
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn 导入 decomposition
导入 seaborn 作为 sns； sns.set_style(&quot;whitegrid&quot;, {&#39;axes.grid&#39; : False})

%matplotlib inline
np.random.seed(0)

# 鸢尾花数据集
DF_data = pd.DataFrame(load_iris().data, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])],
columns = load_iris().feature_names)

Se_targets = pd.Series(load_iris().target, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])], 
name = &quot;Species&quot;)

# 缩放平均值 = 0, var = 1
DF_standard = pd.DataFrame(StandardScaler().fit_transform(DF_data), 
index = DF_data.index,
columns = DF_data.columns)

# Sklearn 用于主成分分析

# 维度
m = DF_standard.shape[1]
K = 2

# PCA（我倾向于如何设置它）
M_PCA = decomposition.PCA(n_components=m)
DF_PCA = pd.DataFrame(M_PCA.fit_transform(DF_standard), 
columns=[&quot;PC%d&quot; % k for k in range(1,m + 1)]).iloc[:,:K]

# 绘制特征向量
#https://stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

# 这就是事情变得奇怪的地方...
data = DF_standard

mu = data.mean(axis=0)
特征向量，特征值 = M_PCA.components_, M_PCA.explained_variance_ #eigenvectors, eigenvalues, V = np.linalg.svd(data.T, full_matrices=False)
projected_data = DF_PCA #np.dot(data, eigenvectors)

sigma = projected_data.std(axis=0).mean()

fig, ax = plt.subplots(figsize=(10,10))
ax.scatter(projected_data[&quot;PC1&quot;], projected_data[&quot;PC2&quot;])
for axis, color in zip(eigenvectors[:K], [&quot;red&quot;,&quot;green&quot;]):
# start, end = mu, mu + sigma * axis ### 导致 &quot;ValueError: 需要解压的值太多（预期为 2）&quot;

# 所以我尝试了这个但我认为它不正确
start, end = (mu)[:K], (mu + sigma * axis)[:K] 
ax.annotate(&#39;&#39;, xy=end,xytext=start, arrowprops=dict(facecolor=color, width=1.0))

ax.set_aspect(&#39;equal&#39;)
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    </channel>
</rss>