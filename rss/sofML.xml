<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 25 Mar 2024 18:17:43 GMT</lastBuildDate>
    <item>
      <title>从 9 年的 Java 经验转向 AI/ML 职业道路是一个明智的决定吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78220858/is-it-good-decision-to-move-to-ai-ml-career-path-from-9-years-of-java-experience</link>
      <description><![CDATA[您好，我作为软件开发人员和 API 开发人员拥有 9 年的 Java 经验。
现在，在这个不断变化的技术时代，每个人都在谈论人工智能。
那么，将职业道路转向与 AI/ML 相关的方向是个好决定吗？
搜索了很多youtybe]]></description>
      <guid>https://stackoverflow.com/questions/78220858/is-it-good-decision-to-move-to-ai-ml-career-path-from-9-years-of-java-experience</guid>
      <pubDate>Mon, 25 Mar 2024 17:42:06 GMT</pubDate>
    </item>
    <item>
      <title>使用变压器模型改进列车准点预测：模型设置和性能问题</title>
      <link>https://stackoverflow.com/questions/78220853/improving-train-punctuality-prediction-using-a-transformer-model-model-setup-an</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78220853/improving-train-punctuality-prediction-using-a-transformer-model-model-setup-an</guid>
      <pubDate>Mon, 25 Mar 2024 17:41:18 GMT</pubDate>
    </item>
    <item>
      <title>波士顿房价数据集的 ANN 损失并未减少</title>
      <link>https://stackoverflow.com/questions/78220834/ann-loss-not-reducing-for-boston-house-price-data-set</link>
      <description><![CDATA[from sklearn.datasets import load_boston

波士顿 = load_boston()
boston_data = pd.DataFrame(boston.data)
boston_data.columns=boston.feature_names

boston_data[&#39;PRICE&#39;]=boston.target # 因变量，要预测的值

# 对于当前数据集，进行对数转换以减少异常值，然后对数据集进行归一化

boston_data_log=np.log1p(boston_data)
boston_data_log=(boston_data_log-boston_data_log.min())/(boston_data_log.max()-boston_data_log.min())
boston_data_log[&#39;价格&#39;]=boston_data[&#39;价格&#39;]

## 构建人工神经网络

# Log_transformed 和标准化数据集

从 sklearn.model_selection 导入 train_test_split
x_train,x_test,y_train,y_test=train_test_split(boston_data_log.drop(columns=[&#39;PRICE&#39;]).values,boston_data_log[&#39;PRICE&#39;].values,test_size=0.2)


x_train=torch.FloatTensor(x_train)
x_test=torch.FloatTensor(x_test)

y_train=torch.FloatTensor(y_train)
y_test=torch.FloatTensor(y_test)

进口火炬
将 torch.nn 导入为 nn
导入 torch.nn.function 作为 F

ANN 类（nn.Module）：
    def __init__(自身,输入层,隐藏层_1,隐藏层_2,隐藏层_3,隐藏层_4,隐藏层_5,输出层):
        超级().__init__()
        self.full_connected_1=nn.Linear(input_layer,hidden_​​layer_1)
        self.full_connected_2=nn.Linear(hidden_​​layer_1,hidden_​​layer_2)
        self.full_connected_3=nn.Linear(hidden_​​layer_2,hidden_​​layer_3)
        self.full_connected_4=nn.Linear(hidden_​​layer_3,hidden_​​layer_4)
        self.full_connected_5=nn.Linear(hidden_​​layer_4,hidden_​​layer_5)
        self.output_layer=nn.Linear(hidden_​​layer_5,output_layer)
    defforward_prop（自身，x）：
        x=F.relu(self.complete_connected_1(x))
        x=F.relu(self.complete_connected_2(x))
        x=F.relu(self.complete_connected_3(x))
        x=F.relu(self.complete_connected_4(x))
        x=F.relu(self.complete_connected_5(x))
        x=self.output_layer(x)
        返回x
        

火炬.manual_seed(20)
模型=ANN(x_train.shape[1],200,200,200,200,200,1)

loss_function=nn.MSELoss()
优化器=torch.optim.Adam(model.parameters(),lr=0.01)

纪元=500
loss_cumul_list=[]
循环列表=[]
对于范围内的 i（纪元）：
    y_pred=model.forward_prop(x_train)
    损失=loss_function(y_pred,y_train)
    loss_cumul_list.append(loss.item())
    循环列表.append(i+1)
    优化器.zero_grad()
    loss.backward()
    优化器.step()

损失累积列表

预测=[]
使用 torch.no_grad()：
    对于 i，枚举（x_test）中的数据：
        y_pred=model.forward_prop(数据)
        预测.append(y_pred.item())

从 sklearn.metrics 导入 r2_score,mean_squared_error,mean_absolute_error
error_r2=r2_score(y_test,预测)
error_mse=mean_squared_error(y_test,预测)
error_mae=mean_absolute_error(y_test,预测)

我一直试图使用 Pytorch 在波士顿房价数据集上应用 ANN，但在 50 个 epoch 后，损失并没有进一步减少太多。在网上看到过一些使用张量流的类似笔记本，但模型在那里工作得很好。无法理解这里的问题。
我一直试图使用 Pytorch 在波士顿房价数据集上应用 ANN，但在 50 个 epoch 后，损失并没有进一步减少太多。在网上看到过一些使用张量流的类似笔记本，但模型在那里工作得很好。无法理解这里的问题。]]></description>
      <guid>https://stackoverflow.com/questions/78220834/ann-loss-not-reducing-for-boston-house-price-data-set</guid>
      <pubDate>Mon, 25 Mar 2024 17:39:02 GMT</pubDate>
    </item>
    <item>
      <title>Walker2d AI Gym 好像不会学习</title>
      <link>https://stackoverflow.com/questions/78220075/walker2d-ai-gym-doesnt-seem-to-learn</link>
      <description><![CDATA[我一直在尝试在 MuJoCO Walker2D 环境中进行基本的演员评论家代理学习。在模型、损失、超参数发生许多变化之后，我似乎没有取得任何进展（代理在 25 万步上没有任何明显的差异。
我意识到我可能有很多错误/问题，但我真的完全不知道下一步要尝试什么。
我最近的代理如下：
&lt;前&gt;&lt;代码&gt; def __init__(
      自己，
      num_actions: int):
    “”“初始化。”“”
    超级().__init__()
    self.common=layers.Dense(20，激活=“relu”，kernel_initializer=&#39;random_normal&#39;)
    self.common4 = 层.Dense(20, 激活=“relu”, kernel_initializer=&#39;random_normal&#39;)
    self.actor_means=layers.Dense(num_actions,activation=“tanh”,kernel_initializer=&#39;random_normal&#39;)
    self.critic=layers.Dense(1,activation=“线性”)#1个节点给出策略的值估计
    #下几行是给独立的第二评论家的
    self.crit_dense1 = 层.Dense(20, 激活=“relu”, kernel_initializer=&#39;random_normal&#39;)
    self.crit2 = 层.Dense(1, 激活=“线性”, kernel_initializer=&#39;random_normal&#39;)

  def call(self, 输入：tf.Tensor) -&gt;元组[tf.张量，tf.张量，tf.张量]：
    a = tf.expand_dims(输入, 0)
    b = self.common(a)
    d = self.common4(b)
    手段 = self.actor_means(d)
    q2 = self.crit_dense1(a)
    q2 = self.crit2(q2)
    返回方式，q2

情节是：
 for t in tf.range(max_steps)：
    # 运行模型并获取动作概率和批评值
    action_dist_t，值=模型（状态）
    值 = value.write(t, 值)
    dist = tfd.Normal(loc=action_dist_t, 比例=[0.1,0.1,0.1,0.1,0.1,0.1])
    动作=dist.sample([1])[0]

    动作 = tf.clip_by_value(动作, -0.99, 0.99)
    action_probs = action_probs.write(t, dist.prob(action_dist_t))#- 动作
    actions = actions.write(t, 动作)
    # 对环境应用动作以获得下一个状态和奖励

    状态，奖励，完成= env_step(tf.cast(tf.squeeze(action), tf.float32)) #
    #tf.print(str(奖励))
    状态.set_shape(初始状态_形状)
    # 储存奖励
    奖励 = 奖励.write(t, 奖励)

    如果 tf.cast(完成, tf.bool):
      休息


损失为：
defcompute_loss(
    action_probs：tf.张量，
    值：tf.张量，
    返回：tf.张量，
    动作：tf.张量
  ）-&gt; tf.张量：#
  “”“计算演员-评论家的综合损失。”“”“

  优势 =（返回 - 值）#+ 0.01
  actor_loss = -tf.math.reduce_sum(优势*action_probs, axis=-1) #tf.math.abs

  Criteria_loss = huber_loss（值，回报）


  返回 actor_loss + Criteria_loss

和训练步骤：
def train_step(
    初始状态：tf.张量，
    模型：tf.keras.Model，
    优化器：tf.keras.optimizers.Optimizer，
    伽玛：浮动，
    max_steps_per_episode: int) -&gt;; tf.张量：
  “”““运行模型训练步骤。”“”

  使用 tf.GradientTape() 作为磁带：

    # 运行模型一集以收集训练数据
    action_probs、值、奖励、动作 = run_episode(
        初始状态、模型、每集最大步数）

    # 计算预期收益
    返回 = get_expected_return(奖励, 伽马)

    # 将训练数据转换为适当的 TF 张量形状
    action_probs、值、回报、动作 = [
        tf.expand_dims(x, 1) for x in [action_probs, 值, 返回, 动作]]

    # 计算损失值以更新我们的网络
    损失=计算损失（action_probs，值，回报，行动）

  grads = Tape.gradient(loss, model.trainable_variables)
  grads = [tf.clip_by_value(grad, -0.5, 0.5) for grads]
  #grads,_ = tf.clip_by_global_norm(grads, -3)
  # 计算损失的梯度

  #for var, zip 中的 grad(model.trainable_variables, grads):
   # print(f&quot;变量: {var.name}, 梯度范数: {tf.norm(grad)}&quot;)
  # 将梯度应用于模型参数
  优化器.apply_gradients(zip(grads, model.trainable_variables))

  Episode_reward = tf.math.reduce_sum(奖励)
  批评者估计 = tf.math.reduce_sum(值)

我尝试过替代损失（NLL，CoPilot 建议的自定义损失）。我尝试过不同的模型架构（更多层、更宽层、输出分布）和一系列超参数（伽玛范围（0.25-0.99）、学习率（0.1,0.01,0.001）。我也尝试过使用和不使用梯度裁剪，总和而不是均值减少。最大奖励保持 &lt;5。]]></description>
      <guid>https://stackoverflow.com/questions/78220075/walker2d-ai-gym-doesnt-seem-to-learn</guid>
      <pubDate>Mon, 25 Mar 2024 15:16:46 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中将管道重新编写为类时出错</title>
      <link>https://stackoverflow.com/questions/78219825/error-when-rewiriting-a-pipeline-as-a-class-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78219825/error-when-rewiriting-a-pipeline-as-a-class-in-python</guid>
      <pubDate>Mon, 25 Mar 2024 14:32:03 GMT</pubDate>
    </item>
    <item>
      <title>“MENACE”tictax脚趾计算机需要多少场比赛来训练</title>
      <link>https://stackoverflow.com/questions/78219696/how-many-games-will-a-menace-tic-tax-toe-computer-take-to-train</link>
      <description><![CDATA[我最近读到了唐纳德·米奇 (Donald Michie) 设计的用火柴盒建造的“计算机”，它可以自学如何玩井字游戏。这是关于它的维基百科文章：
https://en.m.wikipedia.org/wiki/Matchbox_Educable_Noughts_and_Crosses_Engine 
我觉得它看起来很有趣，所以我决定用 Python 制作一个数字版本，以供娱乐和练习。我已经让它对随机动作进行了大约 10,000 场比赛，但它仍然经常输给我。
需要玩多少场游戏才能让“火柴盒电脑”的工作方式与 Michie 设计的完美匹配？带有实际火柴盒的原始计算机是否达到了完美的播放效果？
我问这个问题是因为我担心我的程序可能无法正常工作。]]></description>
      <guid>https://stackoverflow.com/questions/78219696/how-many-games-will-a-menace-tic-tax-toe-computer-take-to-train</guid>
      <pubDate>Mon, 25 Mar 2024 14:12:37 GMT</pubDate>
    </item>
    <item>
      <title>如何删除 Huggingface 的 Transformers GPT2 预训练模型中的层？</title>
      <link>https://stackoverflow.com/questions/78219076/how-to-remove-layers-in-huggingfaces-transformers-gpt2-pre-trained-models</link>
      <description><![CDATA[我的代码：
从转换器导入 GPT2Config、GPT2Model
从变压器导入 AutoTokenizer、AutoModelForMaskedLM、AutoModelForCausalLM
模型 = AutoModelForCausalLM.from_pretrained(“openai-community/gpt2”)
打印（解码器）

这是控制台的输出，列出了模型架构：
&lt;前&gt;&lt;代码&gt;GPT2LMHeadModel(
  （变压器）：GPT2Model（
    (wte)：嵌入(50257, 768)
    (wpe)：嵌入(1024, 768)
    (drop): Dropout(p=0.1, inplace=False)
    (h): 模块列表(
      (0-11): 12 x GPT2Block(
        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (attn): GPT2Attention(
          (c_attn): Conv1D()
          (c_proj): Conv1D()
          (attn_dropout): Dropout(p=0.1, inplace=False)
          (resid_dropout): Dropout(p=0.1, inplace=False)
        ）
        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (mlp): GPT2MLP(
          (c_fc): Conv1D()
          (c_proj): Conv1D()
          (动作): NewGELUActivation()
          (dropout): Dropout(p=0.1, inplace=False)
        ）
      ）
    ）
    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  ）
  （lm_head）：线性（in_features = 768，out_features = 50257，偏差= False）
）

我想删除第一层：
(wte)：嵌入(50257, 768)

我尝试过以下方法：
def deleteEncodingLayers(model, num_layers_to_keep): # 必须传入完整的bert模型
    oldModuleList = model.bert.encoder.layer
    newModuleList = nn.ModuleList()

    # 现在迭代所有层，只保留相关层。
    对于范围内的 i(0, len(num_layers_to_keep))：
        newModuleList.append(oldModuleList[i])

    # 创建模型的副本，使用新列表修改它，然后返回
    copyOfModel = copy.deepcopy(模型)
    copyOfModel.bert.encoder.layer = newModuleList

    返回模型副本

但是没有成功。谁知道怎么解决？]]></description>
      <guid>https://stackoverflow.com/questions/78219076/how-to-remove-layers-in-huggingfaces-transformers-gpt2-pre-trained-models</guid>
      <pubDate>Mon, 25 Mar 2024 12:28:15 GMT</pubDate>
    </item>
    <item>
      <title>将 ONNX 模型转换为 Tensorflow Lite - 不支持 pytorch_half_pixel</title>
      <link>https://stackoverflow.com/questions/78218890/converting-onnx-model-to-tensorflow-lite-pytorch-half-pixel-not-supported</link>
      <description><![CDATA[我正在尝试将 ONNX 模型转换为 Tensorflow Lite 格式。简单的代码但出现此错误。我更新了我的 onnx 版本，但没有成功
导入onnx
将张量流导入为 tf
导入onnx_tf
#
#
# 自述文件：此文件将 onnx 模型转换为 tflite
#
#
#

onnx_model_path = &#39;/home/sfrye/segmentation/segmentation_checkpoints/efficientnet/modified-new.onnx&#39;

onnx_model = onnx.load(onnx_model_path)

tf_model = onnx_tf.backend.prepare(onnx_model)
tf_model.export_graph(“tflite_model.tf”)

这是错误
&lt;前&gt;&lt;代码&gt;
运行时错误：在用户代码中：

    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/backend_tf_module.py”，第 99 行，位于 __call__ *
        output_ops = self.backend._onnx_node_to_tensorflow_op(onnx_node,
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/backend.py”，第 347 行，在 _onnx_node_to_tensorflow_op *
        返回处理程序.handle(节点,tensor_dict=tensor_dict,strict=strict)
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/handlers/handler.py”，第 58 行，句柄 *
        cls.args_check（节点，**kwargs）
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/handlers/backend/resize.py”，第 125 行，位于 args_check *
        异常。OP_UNSUPPORTED_EXCEPT(
    文件“/home/sfrye/miniconda3/envs/mars_env/lib/python3.8/site-packages/onnx_tf/common/exception.py”，第 50 行，位于 __call__ *
        引发 self._func(self.get_message(op, 框架))

    运行时错误：Tensorflow 不支持调整坐标_transformation_mode=pytorch_half_pixel 的大小。


我尝试更新我的 onnx，因为这解决了某人使用此错误代码的问题]]></description>
      <guid>https://stackoverflow.com/questions/78218890/converting-onnx-model-to-tensorflow-lite-pytorch-half-pixel-not-supported</guid>
      <pubDate>Mon, 25 Mar 2024 11:55:44 GMT</pubDate>
    </item>
    <item>
      <title>用于物体方向估计的模板匹配模型仅在平面内旋转时快速收敛，但在全 3D 方向时失败</title>
      <link>https://stackoverflow.com/questions/78218374/template-matching-model-for-object-orientation-estimation-converges-fast-with-in</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78218374/template-matching-model-for-object-orientation-estimation-converges-fast-with-in</guid>
      <pubDate>Mon, 25 Mar 2024 10:23:10 GMT</pubDate>
    </item>
    <item>
      <title>在时间序列 ARIMA 分析中出现错误“TypeError：没有要绘制的数值数据”</title>
      <link>https://stackoverflow.com/questions/78218276/getting-error-typeerror-no-numeric-data-to-plot-in-a-time-series-arima-analys</link>
      <description><![CDATA[我正在尝试遵循一个教程，其中使用差异数据进行 ARIMA 时间序列分析：
以下是python代码：
def 差异（数据集）：
    差异=列表（）
    对于范围内的 i(1, len(数据集))：
        值 = 数据集[i] - 数据集[i - 1]
        diff.append(值)
    返回系列（差异）

系列 = pd.read_csv(&#39;dataset.csv&#39;)
X = series.values # 构建列表的错误可以在这里看到
X = X.astype(&#39;float32&#39;)
平稳 = 差值(X)
固定.索引 = 系列.索引[1:]
...
固定.plot()
pyplot.show()

当过程到达绘图阶段时，我收到错误：
&lt;块引用&gt;
类型错误：没有要绘制的数字数据

回溯起来，我发现正在解析的数据产生了一个数组的集合。将集合stationary保存为*.csv文件会给我一个如下列表：
&lt;前&gt;&lt;代码&gt;[11.]
[0.]
[16.]
[45.]
[27.]
[-141。]
[46]

有人可以告诉我这里出了什么问题吗？
PS。我已经排除了库导入的部分
编辑 1
数据集的一部分复制如下：
年份，观测值
1994,21
1995,62
1996,56
1997,29
1998,38
1999,201
]]></description>
      <guid>https://stackoverflow.com/questions/78218276/getting-error-typeerror-no-numeric-data-to-plot-in-a-time-series-arima-analys</guid>
      <pubDate>Mon, 25 Mar 2024 10:07:18 GMT</pubDate>
    </item>
    <item>
      <title>Kohya_SS 和多个 python 版本</title>
      <link>https://stackoverflow.com/questions/78218164/kohya-ss-and-multiple-python-versions</link>
      <description><![CDATA[10:20:10-098640 ERROR 当前版本的 python 不适合运行
                         Kohya_ss 图形用户界面
10:20:10-098956 错误 python 版本需要大于或等于
                         3.10.9 且小于 3.11.0
验证失败。正在退出...

尽管我确信我安装了多个 Python 版本并且可以切换到它应该使用的版本，但我不断收到错误？
user@Name-MacBook-Pro ~ % alias python3=“python3.10”
用户@名称-MacBook-Pro ~ % python3 --version
Python 3.10.14

通过 Dreambooth/Lora 界面训练模型，我前一天就可以打开]]></description>
      <guid>https://stackoverflow.com/questions/78218164/kohya-ss-and-multiple-python-versions</guid>
      <pubDate>Mon, 25 Mar 2024 09:42:00 GMT</pubDate>
    </item>
    <item>
      <title>尝试在用于虹膜识别的自注释数据集上训练用于虹膜识别的神经网络[关闭]</title>
      <link>https://stackoverflow.com/questions/78199835/trying-to-train-a-neural-network-for-iris-recognition-on-a-self-annotated-datase</link>
      <description><![CDATA[classloss = tf.keras.losses.BinaryCrossentropy()
回归损失 = 本地化损失
类损失（y\[0\]，类）

hist = model.fit(train, epochs=15,validation_data=val,callbacks=\[tensorboard_callback\])


model.fit 抛出以下错误：
batch_classloss = self.cless(y[0], 类)
batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), 坐标)
总损失batch_localizationloss+0.5batch_classloss

ValueError：无法获取未知等级的形状长度。
为什么会出现错误]]></description>
      <guid>https://stackoverflow.com/questions/78199835/trying-to-train-a-neural-network-for-iris-recognition-on-a-self-annotated-datase</guid>
      <pubDate>Thu, 21 Mar 2024 12:07:19 GMT</pubDate>
    </item>
    <item>
      <title>层顺序从未被调用，因此没有定义的输入</title>
      <link>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</link>
      <description><![CDATA[我正在 Anaconda 虚拟环境中运行一个简单的脚本
从 deepface 导入 DeepFace

face_analysis = DeepFace.analyze(img_path = “face3.jpeg”)
打印（面部分析）

但我不断收到此错误。
行动：年龄：25%|██████████████████████████▊ | 1/4 [00:02&lt;00:06, 2.08s/it]
回溯（最近一次调用最后一次）：
  文件“C:\Users\Ctrend.pk\Cheer-Check\test2.py”，第 9 行，在  中
    分析 = DeepFace.analyze(img_path)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\DeepFace.py”，第 222 行，在分析中
    返回人口统计分析（
           ^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\modules\demography.py”，第 157 行，位于分析
    表观年龄 = modeling.build_model(“年龄”).predict(img_content)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\modules\modeling.py”，第 57 行，位于构建模型
    model_obj[模型名称] = model()
                            ^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\extendedmodels\Age.py”，第 32 行，位于__在里面__
    self.model = load_model()
                 ^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\deepface\extendedmodels\Age.py”，第 61 行，位于加载模型
    年龄模型=模型（输入=模型.输入，输出=基本模型输出）
                             ^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\ops\operation.py”，第 228 行，在输入中
    返回 self._get_node_attribute_at_index(0, “input_tensors”, “input”)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^
  文件“C:\Users\Ctrend.pk\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\LocalCache\local-packages\Python312\site-packages\keras\src\ops\operation.py”，第 259 行，在 _get_node_attribute_at_index 中
    引发值错误（
ValueError：层equential_1从未被调用，因此没有定义的输入。

Deepface版本：0.0.87
张量流
版本：2.16.1
我认为它获取了年龄，但随后没有继续。我错过了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</guid>
      <pubDate>Wed, 20 Mar 2024 22:50:10 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将 Azure Form Recognizer Studio 界面直接集成到我们的应用程序中吗？</title>
      <link>https://stackoverflow.com/questions/75184059/can-we-integrate-azure-form-recognizer-studio-interface-directly-into-our-applic</link>
      <description><![CDATA[据我所知，Form Recognizer Studio 是一个在线工具，用于直观地探索、理解 Form Recognizer 服务的功能并将其集成到您的应用程序中。但是我们可以将 studio 工具直接集成到我们的 Web 应用程序中以进行可视化、培训和测试吗？
我尝试查看微软论坛，但没有得到确切的答案。]]></description>
      <guid>https://stackoverflow.com/questions/75184059/can-we-integrate-azure-form-recognizer-studio-interface-directly-into-our-applic</guid>
      <pubDate>Fri, 20 Jan 2023 12:30:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 OneClassSVM 绘制 SHAP 绘图需要很长时间</title>
      <link>https://stackoverflow.com/questions/73279201/shap-plots-taking-ages-with-oneclasssvm</link>
      <description><![CDATA[我正在尝试解释我的 OneClassSVM 模型，但计算时间非常长。我使用了 36 次折叠的交叉验证，因此希望将所有折叠的结果合并到一个 SHAP 图上，以便我可以充分解释哪些特征对模型贡献最大。
到目前为止，我认为对我想要解释的数据进行采样会加快处理速度（确实减少了时间），但折叠一次仍然需要大约 8 小时，并且有 36 次折叠。
请注意，我的训练集约为 2400 个，测试集约为 1400 个，每个集有 88 个特征。
导入形状
从 sklearn.svm 导入 OneClassSVM
将 numpy 导入为 np

# 这些是二维数组，其中每个元素都是用于训练/测试折叠的所选数据的 DataFrame
shap_train = np.load(&#39;shap_train.npy&#39;,allow_pickle=True)
shap_test = np.load(&#39;shap_test.npy&#39;,allow_pickle=True)

clf = OneClassSVM(nu=0.35)

折叠 = len(shap_train)
形状值 = []
shap_data_test = []

对于范围内的折叠（折叠）：
        解释器 = shap.Explainer(clf.fit_predict, shap_train[fold])
        # 采样1/3的数据
        数据 = shap_test[fold].sample(frac=(1/3))
        shap_values.append(解释器(数据))
        shap_data_test.append（数据）

# 存储稍后绘图的 SHAP 值
np.save(&#39;shap_data.npy&#39;, np.array(shap_values))
np.save(&#39;shap_data_test.npy&#39;, np.array(shap_data_test))


我对需要为所有折叠生成形状值的方法提出了质疑，但我知道某些折叠的性能比其他折叠更好，因此希望全面了解哪些功能贡献最大。
我将此脚本部署在具有 Intel(R) Xeon(R) CPU E5-2667 v4 @ 3.20GHz 和 64GB RAM 的 Debian 服务器上。]]></description>
      <guid>https://stackoverflow.com/questions/73279201/shap-plots-taking-ages-with-oneclasssvm</guid>
      <pubDate>Mon, 08 Aug 2022 14:06:46 GMT</pubDate>
    </item>
    </channel>
</rss>