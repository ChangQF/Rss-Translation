<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 02 May 2024 03:15:10 GMT</lastBuildDate>
    <item>
      <title>通过图像分析发现印刷适性</title>
      <link>https://stackoverflow.com/questions/78416596/image-analysis-to-find-printability</link>
      <description><![CDATA[我是编码新手。我有一张 cad 图像 cad.png。 3D 打印后的 CAD 图像 print.png 后的几张图像。
我想将 cad 图像与打印图像进行比较，看看打印是否准确。匹配的百分比是多少。
稍后，如果可能的话，尝试预测它是叠印还是印刷不足。
图像有不同的尺寸。我需要任何参考点来测量图像中的对象吗？
我应该如何进行？]]></description>
      <guid>https://stackoverflow.com/questions/78416596/image-analysis-to-find-printability</guid>
      <pubDate>Thu, 02 May 2024 01:31:25 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 上的推理困难</title>
      <link>https://stackoverflow.com/questions/78416324/difficulty-performing-inference-on-lstm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78416324/difficulty-performing-inference-on-lstm</guid>
      <pubDate>Wed, 01 May 2024 23:08:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习 - 神经网络</title>
      <link>https://stackoverflow.com/questions/78416266/machine-learning-neural-network</link>
      <description><![CDATA[我是初学者。我正在尝试创建一个具有一个隐藏层的神经网络，该网络将图像分为 12 个不同的类别。当我尝试使用梯度下降函数运行代码以开始训练模型时，代码根本不输出任何内容并移动到下一个单元格。
def initialize_parameters(hidden_​​units):
w1 = np.random.randn(hidden_​​units, 640 * 480 * 3) * 0.01
b1 = np.zeros((hidden_​​units, 1))
w2 = np.random.randn(12, hidden_​​units) * 0.01
b2 = np.zeros((12, 1))
return w1, b1, w2, b2

def ReLU(Z):
return np.maximum(0, Z)

def softmax(Z):
expZ = np.exp(Z)
return expZ / np.sum(expZ, axis=0, keepdims=True)

def forward_propagation(w1, b1, w2, b2, X):
z1 = np.dot(w1, X) + b1
a1 = ReLU(z1)
z2 = np.dot(w2, a1) + b2 
a2 = softmax(z2)
返回 z1, a1, z2, a2 

def onehotencoding(Y): 
one_hot_Y = np.zeros((Y.size, Y.max() + 1))
one_hot_Y[np.arange(Y.size), Y] = 1
one_hot_Y = one_hot_Y.T
返回 one_hot_Y

def derivedReLU(Z): 
返回 Z &gt; 0

def back_propagation(w2, a1, z1, a2, X, Y):
m = Y.size 
one_hot_Y = onehotencoding(Y)
dz2 = a2 - one_hot_Y
dw2 = 1 / m * np.dot(dz2, a1.T)
db2 = 1 / m * np.sum(dz2, axis=1, keepdims=True)
dz1 = np.dot(w2.T, dz2) * derivedReLU(z1)
dw1 = 1 / m * np.dot(dz1, X.T)
db1 = 1 / m * np.sum(dz1, axis=1, keepdims=True)
return dw1, db1, dw2, db2 

def update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha): 
w1 = w1 - alpha * dw1 
b1 = b1 - alpha * db1 
w2 = w2 - alpha * dw2 
b2 = b2 - alpha * db2 
return w1, b1, w2, b2

此代码单元到此结束，后面跟着此代码块。
def get_predictions(a2): 
return np.argmax(a2, axis=0)

def get_accuracy(predictions, Y): 
return np.sum(predictions == Y) / Y.size

def gradient_descent(X, Y, hidden_​​units, iterations, alpha): 
w1, b1, w2, b2 = initialize_parameters(hidden_​​units)
for i in range(iterations): 
z1, a1, z2, a2 = forward_propagation(w1, b1, w2, b2, X)
dw1, db1, dw2, db2 = back_propagation(w2, a1, z1, a2, X, Y)
w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)
if i % 10 == 0: 
predictions = get_predictions(a2)
accuracy = get_accuracy(predictions, Y)
print(&quot;Iteration: &quot;, i)
print(&quot;Accuracy: &quot;, accuracy)
return w1, b1, w2, b2


这是开始训练的梯度下降函数。
w1, b1, w2, b2 =梯度下降（X_train，Y_train，500，迭代次数=1000，alpha=0.1）]]></description>
      <guid>https://stackoverflow.com/questions/78416266/machine-learning-neural-network</guid>
      <pubDate>Wed, 01 May 2024 22:43:52 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM - 我实际上有多少棵树？</title>
      <link>https://stackoverflow.com/questions/78416214/lightgbm-how-many-trees-do-i-actually-have</link>
      <description><![CDATA[初学者在这里尝试 LGBM。我的代码看起来像这样
clf = lgb.LGBMClassifier(max_深度=3，详细程度=-1，n_estimators=3)
clf.fit(train_data[特征],train_data[&#39;y&#39;],sample_weight=train_data[&#39;权重&#39;])
print (f“我有 {clf.n_estimators_} 估计器”)
图，ax = plt.subplots（nrows = 4，figsize =（50,36），sharex = True）
lgb.plot_tree(clf, tree_index=7, dpi=600, ax=ax[0]) # 为什么有第七棵树？
lgb.plot_tree(clf, tree_index=8, dpi=600, ax=ax[1]) # 为什么它有第 8 棵树？
#lgb.plot_tree(clf, tree_index=9, dpi=600, ax=ax[2]) # 崩溃
#lgb.plot_tree(clf, tree_index=10, dpi=600, ax=ax[3]) # 崩溃

令我惊讶的是，尽管有 n_estimators=3，但我似乎有 9 棵树？我如何实际设置树的数量，以及与之相关的，n_estimators 是做什么的？我读过文档，我以为是树的数量，但似乎是别的东西。
另外，我如何解释单独的树及其顺序 0、1、2 等。我了解随机森林，以及每棵树如何同等重要。在 boosting 中，第一棵树最重要，下一棵树的重要性要低得多，下一棵树的重要性要低得多。所以在我的脑海中，当我查看树形图时，我该如何“模拟” LightGBM 推理过程？]]></description>
      <guid>https://stackoverflow.com/questions/78416214/lightgbm-how-many-trees-do-i-actually-have</guid>
      <pubDate>Wed, 01 May 2024 22:24:21 GMT</pubDate>
    </item>
    <item>
      <title>当不打乱测试数据时，Torchmetrics 的准确性问题。为什么？</title>
      <link>https://stackoverflow.com/questions/78415660/torchmetrics-accuracy-issue-when-dont-shuffle-test-data-why</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78415660/torchmetrics-accuracy-issue-when-dont-shuffle-test-data-why</guid>
      <pubDate>Wed, 01 May 2024 19:45:02 GMT</pubDate>
    </item>
    <item>
      <title>如何微调代码bert模型/建议可以生成yaml代码的模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</link>
      <description><![CDATA[任何人都可以建议我如何微调 Codebert 模型。有相关文件吗？请给我一些建议。
我想知道 codebert 是开源的，我们可以使用 cpu 运行它吗？可以生成 ymal 代码吗？或者请推荐适合生成ymal代码的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</guid>
      <pubDate>Wed, 01 May 2024 17:45:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 torch autograd 与 functorch 计算的梯度之间存在微小差异？</title>
      <link>https://stackoverflow.com/questions/78414800/why-is-there-a-small-difference-between-gradients-calculated-using-torch-autogra</link>
      <description><![CDATA[我正在使用这个链接解决方案来自上一个问题，比手动循环更有效地计算梯度。
我注意到使用两种方法计算的梯度存在一些细微差别（即 torch.abs(grads_torch - grads_func).sum() 返回 ~10e-06）。什么可以解释这种差异？一种解决方案比另一种更正确吗？
MWE
导入火炬
从torchvision导入数据集，转换
将 torch.nn 导入为 nn

＃＃＃＃＃＃ 设置 ＃＃＃＃＃＃

类 MLP(nn.Module):
    def __init__(自身，输入大小，隐藏大小，输出大小)：
        超级（MLP，自我）.__init__()
        self.fc1 = nn.Linear(输入大小，隐藏大小)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(隐藏大小, 输出大小)
        
    def 前向（自身，x）：
        h = self.fc1(x)
        pred = self.fc2(self.relu(h))
        返回预测值
    
train_dataset = datasets.MNIST(root=&#39;./data&#39;, train=True, download=True,
                            变换=变换.Compose(
                                [transforms.ToTensor(),
                                    变换.Normalize((0.5,),(0.5,))
        ]))

train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=2,shuffle=False)

X, y = next(iter(train_dataloader)) # 随机获取一批数据

net = MLP(28*28, 20, 10) # 定义一个网络


###### 使用 Torch AUTOGRAD GRAD 计算梯度 ######
def计算梯度（模型，X）：
    # 创建一个张量来保存梯度
    梯度 = torch.zeros(X.shape[0], 10, sum(p.numel() for p in model.parameters()))

    # 计算每个输入和目标维度的梯度
    对于范围内的 i(X.shape[0])：
        对于范围 (10) 内的 j：
            model.zero_grad()
            输出 = 模型(X[i])
            # 计算梯度
            grads = torch.autograd.grad(输出[j], model.parameters())
            # 压平梯度并存储它们
            梯度[i, j, :] = torch.cat([g.view(-1) for g in grads])
            
    返回梯度

grads_torch =calculate_gradients(net, X.view(X.shape[0], -1))

###### 现在使用 FUNCTORCH 计算相同的梯度 ######
# 提取函数调用的参数和缓冲区
params = {k: v.detach() for k, v in net.named_pa​​rameters()}
buffers = {k: v.detach() for k, v in net.named_buffers()}

def one_sample(样本):
    # 这将计算单个样本的梯度
    # 我们希望每个输出的梯度与参数相关
    # 这与网络参数的雅可比矩阵相同

    # 定义一个函数，以输入作为返回网络的输出
    call = lambda x: torch.func.function_call(net, (x, 缓冲区), 样本)
    
    # 计算网络与参数的雅可比矩阵
    J = torch.func.jacrev(call)(params)
    
    # J 是一个字典，其中键为参数名称，值为梯度
    # 我们想要一个张量
    grads = torch.cat([v.flatten(1) for v in J.values()],-1)
    返回毕业生

# 不，我们可以使用 vmap 一次性计算所有样本的梯度
grads_func = torch.vmap(one_sample)(X.flatten(1))

print(torch.allclose(grads_torch, grads_func)) # 返回 True
print(torch.abs(grads_torch - grads_func).sum()) # 返回张量(1.4454e-05)
]]></description>
      <guid>https://stackoverflow.com/questions/78414800/why-is-there-a-small-difference-between-gradients-calculated-using-torch-autogra</guid>
      <pubDate>Wed, 01 May 2024 16:14:45 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“ParticleSwarmOptimization”对象没有属性“global_best_fitnes”</title>
      <link>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</link>
      <description><![CDATA[用于特征选择的执行代码 PSO 出错
def 健身（位置）：
    selected_features = np.array(位置, dtype=bool)
    X_selected = X.iloc[:, selected_features]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    分类器 = KNeighborsClassifier()
    分类器.fit(X_train, y_train)
    y_pred = 分类器.预测(X_test)
    准确度=准确度_分数（y_test，y_pred）
    返回精度

将 numpy 导入为 np

粒子群优化类：
    def __init__(自身、n_粒子、n_特征、n_迭代、fitness_function、w=0.5、c1=1、c2=2)：
        self.n_粒子 = n_粒子
        self.n_features = n_features
        self.n_iterations = n_iterations
        self.fitness_function = 健身函数
        自我.w = w
        自身.c1 = c1
        自身.c2 = c2

    def 初始化粒子（自身）：
        返回 np.random.choice([0, 1], size=(self.n_articles, self.n_features))

    def update_velocity(自身、速度、个人最佳、全局最佳、位置)：
        认知 = self.c1 * np.random.rand() * (personal_best - 位置)
        社会 = self.c2 * np.random.rand() * (global_best - 位置)
        返回 self.w * 速度 + 认知 + 社交

    def update_position（自身，位置，速度）：
        返回 np.round(1 / (1 + np.exp(-velocity))).astype(int)

    def 优化（自我）：
        self.best_fitness_history = [] # 添加此行来存储健身历史记录

        # 初始化粒子
        位置 = self.initialize_articles()
        速度 = np.zeros((self.n_articles, self.n_features))

        个人最佳 = 位置.copy()
        Personal_best_fitness = np.array([self.fitness_function(pos) for pos in individual_best])

        self.global_best = individual_best[np.argmax(personal_best_fitness)]
        self.global_best_fitness = np.max(personal_best_fitness)

        对于范围内的迭代（self.n_iterations）：
            对于范围内的 i(self.n_articles)：
                # 更新速度和位置
                速度[i] = self.update_velocity(速度[i], individual_best[i], self.global_best, 位置[i])
                位置[i] = self.update_position(位置[i], 速度[i])

                # 更新个人最好成绩
                current_fitness = self.fitness_function(position[i])
                如果 current_fitness &gt;个人最佳健身[i]：
                    个人最佳[i] = 位置[i].copy()
                    个人最佳健康度[i] = 当前健康度

                    # 更新全局最佳值
                    如果 current_fitness &gt; self.global_best_fitness：
                        self.global_best = 位置[i].copy()
                        self.global_best_fitness = current_fitness
                        
                        self.best_fitness_history.append(self.global_best_fitness)

        返回 self.global_best, self.global_best_fitnes
]]></description>
      <guid>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</guid>
      <pubDate>Wed, 01 May 2024 13:57:37 GMT</pubDate>
    </item>
    <item>
      <title>尝试将 DETR 模型转换为 Tensorflow Lite</title>
      <link>https://stackoverflow.com/questions/78413651/trying-to-convert-a-detr-model-to-tensorflow-lite</link>
      <description><![CDATA[我正在尝试使用 Android 应用程序的 Optimum 将 DETR 拥抱脸部模型转换为 Tensorflow Lite 模型。我安装了要求：
!pip install optimization
!pip 安装最佳[exporters-tf]

然后我尝试了一个转换预训练模型的示例，它可以工作，但在我的模型上：
!optimum-cli export tflite --model /content/drive/MyDrive/Modele/model-litter --sequence_length 128 --task 对象检测 Model_Litter/

Transformer 模块发生错误，原因是没有名为 TFAutoModelForObjectDetection 的属性
2024-05-01 11:53:55.895865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT 警告：找不到 TensorRT
2024-05-01 11:54:01.347392：W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT 警告：找不到 TensorRT
回溯（最近一次调用最后一次）：
  文件“/usr/lib/python3.10/runpy.py”，第 196 行，在 _run_module_as_main 中
    返回_run_code（代码，main_globals，无，
  文件“/usr/lib/python3.10/runpy.py”，第 86 行，在 _run_code 中
    执行（代码，run_globals）
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tflite/__main__.py”，第 148 行，在  中
    主要的（）
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tflite/__main__.py”，第 61 行，在 main 中
    模型 = TasksManager.get_model_from_task(
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py”，第 1905 行，在 get_model_from_task 中
    model_class = TasksManager.get_model_class_for_task(
  文件“/usr/local/lib/python3.10/dist-packages/optimum/exporters/tasks.py”，第 1375 行，在 get_model_class_for_task 中
    返回 getattr(loaded_library, model_class_name)
  文件“/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py”，第 1503 行，在 __getattr__ 中
    raise AttributeError(f&quot;模块 {self.__name__} 没有属性 {name}&quot;)
AttributeError：模块转换器没有属性 TFAutoModelForObjectDetection
回溯（最近一次调用最后一次）：
  文件“/usr/local/bin/optimum-cli”，第 8 行，在  中。
    系统退出（主（））
  文件“/usr/local/lib/python3.10/dist-packages/optimum/commands/optimum_cli.py”，第 163 行，在 main 中
    服务.run()
  文件“/usr/local/lib/python3.10/dist-packages/optimum/commands/export/tflite.py”，第 243 行，运行中
    subprocess.run(full_command, shell=True, check=True)
  文件“/usr/lib/python3.10/subprocess.py”，第 526 行，运行中
    引发 CalledProcessError(retcode, process.args,
subprocess.CalledProcessError：命令&#39;python3 -moptimum.exporters.tflite --model /content/drive/MyDrive/Modele/model-litter --sequence_length 128 --task object-detection Model_Litter/&#39;返回非零退出状态1

我在一些论坛上看到这个错误可能是因为我没有更新 Transformer 模块，但即使我更新了模块，错误仍然发生。]]></description>
      <guid>https://stackoverflow.com/questions/78413651/trying-to-convert-a-detr-model-to-tensorflow-lite</guid>
      <pubDate>Wed, 01 May 2024 12:09:14 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch YoloV5 模型无法识别物体</title>
      <link>https://stackoverflow.com/questions/78413618/pytorch-yolov5-model-does-not-recognize-objects</link>
      <description><![CDATA[我正在尝试使用模型汽车的部件构建 yolov5 对象检测模型。我为每个部分拍摄了 200 张照片，对其进行了注释，并对模型进行了 50 轮训练。现在，模型根本无法很好地识别零件，我不知道为什么。
奇怪的是，我之前训练的图像总共只少了 111 张，而且模型当时效果很好（除了一个汽车部件）。我可以做些什么来改善结果？
这是代码：
导入火炬
导入CV2
将 numpy 导入为 np

model = torch.hub.load(&#39;ultralytics_yolov5_master&#39;, &#39;custom&#39;, path=&#39;ultralytics_yolov5_master/runs/train/exp3/weights/best.pt&#39;, source=&#39;local&#39;, force_reload=True)
上限 = cv2.VideoCapture(0)
而 cap.isOpened():
    ret, 框架 = cap.read()
    结果=模型（框架）
    cv2.imshow(“YOLO”, np.squeeze(results.render()))

    如果 cv2.waitKey(10) &amp; 0xFF == ord(“q”)：
        休息
cap.release()
cv2.destroyAllWindows()

这些是一些示例训练图像：

结果如下：
]]></description>
      <guid>https://stackoverflow.com/questions/78413618/pytorch-yolov5-model-does-not-recognize-objects</guid>
      <pubDate>Wed, 01 May 2024 12:03:13 GMT</pubDate>
    </item>
    <item>
      <title>ValueError（不匹配的列）持续存在</title>
      <link>https://stackoverflow.com/questions/78410491/valueerrormismatched-columns-is-persisting</link>
      <description><![CDATA[在我的代码中，我尝试使用以下代码将数据从数据表放入 df 表（最初为空，仅包含代码定义的 header_row）：
 df = pd.DataFrame(columns=[&#39;time&#39;] + list(map(str, range(30))))
    对于 i，enumerate(sorted(set(data.index.time))) 中的时间：
     df.loc[i] = [time.strftime(format=&#39;%H:%M:%S&#39;)] + list(data.at_time(time)[&#39;load&#39;].values)[:31]

现在数据表看起来（类似地有 30 天的数据）：
导入请求
导入 csv
导入操作系统
从 bs4 导入 BeautifulSoup
从日期时间导入日期时间，时间增量

def get_load_data(日期):
    url = &#39;http://www.delhisldc.org/Loaddata.aspx?mode=&#39;
    print(&#39;抓取&#39;, 日期)
    resp = requests.get(url+date) # 向url发送get请求，获取响应
    soup = BeautifulSoup(resp.text, &#39;lxml&#39;) # 美味的 HTML 汤
    table = soup.find(&#39;table&#39;, {&#39;id&#39;:&#39;ContentPlaceHolder3_DGGridAv&#39;}) # 从html中获取表格
    trs = table.findAll(&#39;tr&#39;) # 提取表的所有行
    if len(trs[1:])!=0: # 如果没有数据，则无需创建 2017 年 8 月的 csv 文件
        csv_filename = &#39;月份数据.csv&#39;
        将 open(csv_filename, &#39;a&#39;) 作为 f：
            作家 = csv.writer(f)
            计数=0
            对于 trs[1:] 中的 tr：
                时间，德里 = tr.findChildren(&#39;font&#39;)[:2]
                writer.writerow([日期+&#39; &#39;+时间.文本, 德里.文本])
                计数+=1
    如果计数！= 288：
        print(&#39;某些负载值丢失..&#39;)
    别的：
        打印（&#39;完成&#39;）

# 日期 = 日期.split(&#39;/&#39;)
# 日期.reverse()
&#39;&#39;.加入（日期）
对于范围 (31, 0, -1) 内的 i：
    昨天 = datetime.today() - timedelta(i)
    昨天 = 昨天.strftime(&#39;%d/01/2023&#39;) #在这里你可以更改日期。到你的数据
    获取加载数据（昨天）


!head 月数据.csv
数据= pd.read_csv（&#39;monthdata.csv&#39;，标题=无，名称= [&#39;日期时间&#39;，&#39;加载&#39;]，index_col = [0]，parse_dates = [0]，infer_datetime_format = True）

现在我希望 df 是这样的（header_row 代表一个月的时间和日期）：

现在，即使 df 和列表（日期+1）具有相同的列，我也不知道为什么会出现此错误（对于本文中的第一个代码块）：
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-165-10ddc3e7faf7&gt;在&lt;细胞系：2&gt;()
      1 df = pd.DataFrame(columns=[&#39;时间&#39;] + list(map(str, range(30))))
      2 对于 i，enumerate(sorted(set(data.index.time))) 中的时间：
----&gt; 3 df.loc[i] = [time.strftime(format=&#39;%H:%M:%S&#39;)] + list(data.at_time(time)[&#39;load&#39;].values)[:31]
      4 # # data.at_time(time).plot()
      5 # # 如果 idx&gt;10: 中断

2帧
_setitem_with_indexer_missing 中的/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py（自身，索引器，值）
   第2156章
   第2157章
-&gt;第2158章
   2159
   第2160章

ValueError：无法设置列不匹配的行

提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78410491/valueerrormismatched-columns-is-persisting</guid>
      <pubDate>Tue, 30 Apr 2024 18:40:39 GMT</pubDate>
    </item>
    <item>
      <title>Google Ads 数据的数据科学/机器学习分析 [关闭]</title>
      <link>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</link>
      <description><![CDATA[我们希望对 Google Ads 数据进行一些 ML 分析，以微调我们的营销效果。有人对方法有什么建议吗？
是否有任何现有的资源，其中有认真的 DS/ML 从业者正在使用来自 Google Ads 的数据，也许还添加了其他来源（YouTube 等），以生成预测分析，从而最大化转化价值。
我们正在考虑：
识别然后可能调整不同的关键字值
识别每个广告系列或广告中可能解释效果的不同特征
通过识别“趋势”主题、主题标签等（而不是被动方法）探索“套利”关键字值的可能性
生成因果发现/因果推理分析以解释事件之间关系的强度
我们理想情况下寻找可以向我们展示该领域现有思想的最佳实践/权威分析师/资源。任何提供分析方法的 GitHub 存储库的建议都将不胜感激。
我们从“Google Ads”的角度在 Google 上搜索了这个问题，并查看了 Reddit，但有很多噪音和“黑盒”解决方案，所以我们决定从严肃的 DS 从业者的角度来解决这个问题……希望你能帮忙。
我们已经将 Google Ads 广告系列、广告和关键字数据通过 PyCaret ML 回归分析，并得到了一些基础结果，但我们现在正在寻找如何推进这一工作的指导。]]></description>
      <guid>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</guid>
      <pubDate>Tue, 30 Apr 2024 16:38:08 GMT</pubDate>
    </item>
    <item>
      <title>如何解释每个批次预测的相同类别</title>
      <link>https://stackoverflow.com/questions/78406828/how-to-interpret-that-for-each-batch-the-same-class-is-predicted</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78406828/how-to-interpret-that-for-each-batch-the-same-class-is-predicted</guid>
      <pubDate>Tue, 30 Apr 2024 07:12:44 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    <item>
      <title>训练精度高 测试精度差</title>
      <link>https://stackoverflow.com/questions/61464796/high-train-accuracy-poor-test-accuracy</link>
      <description><![CDATA[我有一个对 3 个输出进行分类的神经网络。我的数据集非常小，我有 340 张图像用于训练，60 张图像用于测试。我构建了一个模型，当我编译时，结果是这样的：
&lt;前&gt;&lt;代码&gt;纪元 97/100
306/306 [================================] - 46s 151ms/步 - 损失：0.2453 - 准确度：0.8824 - val_loss ：0.3557 - val_accuracy：0.8922
98/100 纪元
306/306 [==============================] - 47s 152ms/步 - 损失：0.2096 - 准确度：0.9031 - val_loss ：0.3795 - val_accuracy：0.8824
99/100 纪元
306/306 [==============================] - 47s 153ms/步 - 损失：0.2885 - 准确度：0.8627 - val_loss ：0.4501 - val_accuracy：0.7745
纪元 100/100
306/306 [================================] - 46s 152ms/步 - 损失：0.1998 - 准确度：0.9150 - val_loss ：0.4586 - val_accuracy：0.8627

当我预测测试图像时，测试精度很差。
我应该怎么办 ？我也使用 ImageDatagenerator 进行数据增强，但结果是相同的。是否因为我的数据集较小。]]></description>
      <guid>https://stackoverflow.com/questions/61464796/high-train-accuracy-poor-test-accuracy</guid>
      <pubDate>Mon, 27 Apr 2020 17:31:25 GMT</pubDate>
    </item>
    </channel>
</rss>