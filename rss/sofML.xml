<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 13 Feb 2024 09:13:15 GMT</lastBuildDate>
    <item>
      <title>删除 DCA 曲线中的“Treat All”和“Treat None”</title>
      <link>https://stackoverflow.com/questions/77986685/remove-treat-all-and-treat-none-in-dca-curve</link>
      <description><![CDATA[在此处输入图像描述
绘制 DCA 曲线
库（dcurves）
# dca(AS1min ~ knn + Boosting, data= data.set)
dcaoutput = dca(AS1min ~ knn + Boosting, data= data.set,
  阈值 = seq(0, 0.99, by = 0.01))

dca输出%&gt;%
  绘图（类型 = &#39;net_benefit&#39;，平滑 = TRUE，show_ggplot_code = FALSE）

美好的一天。我目前正在尝试在 R 中绘制 DCA 曲线，我的问题是如何删除“Treat All”和“不治疗”图中的变量？]]></description>
      <guid>https://stackoverflow.com/questions/77986685/remove-treat-all-and-treat-none-in-dca-curve</guid>
      <pubDate>Tue, 13 Feb 2024 09:06:37 GMT</pubDate>
    </item>
    <item>
      <title>对从 PID 控制器传感器接收到的数据进行标记</title>
      <link>https://stackoverflow.com/questions/77986583/tagging-of-data-received-from-sensors-of-pid-controller</link>
      <description><![CDATA[我正在处理来自制造领域的数据集，其中包含传感器数据和一些来自 PID 控制器的标签，我想创建一种可以自动进行数据标记的方法。
为了给您提供上下文，标签可以是AE1701A，268-IE-A-2ND-FFA-LC等，传感器可以测量温度，压力，湿度，pH等，数据的形状为（100000,1000 ）它可以超过 1000 列，我想根据机器或流程或操作序列来聚类或查找相似的数据点，并相应地标记数据。
我在这里找到了与此类似的内容：但我无法理解如何做到这一点。
任何人都可以帮助我了解该方法以及可以使用什么来实现这一目标？
我尝试使用基本的 NLP 技术，但我不确定什么方法可以让我达到所需的目标]]></description>
      <guid>https://stackoverflow.com/questions/77986583/tagging-of-data-received-from-sensors-of-pid-controller</guid>
      <pubDate>Tue, 13 Feb 2024 08:48:25 GMT</pubDate>
    </item>
    <item>
      <title>数据增强不会增加数据集大小</title>
      <link>https://stackoverflow.com/questions/77986399/data-augmentation-not-increasing-dataset-size</link>
      <description><![CDATA[我正在创建一个机器学习模型来对图像进行分类，并且正在创建我的数据集。我有一个文件夹，其中包含我的训练、测试和验证数据集（分别为 train_ds、test_ds、val_ds）。然后，我将数据增强定义如下：
tf.random.set_seed(42)

data_augmentation = tf.keras.Sequential([
    Layers.RandomFlip(“horizo​​ntal_and_vertical”),
    层.实验.预处理.RandomRotation(0.2),
    层.实验.预处理.RandomZoom(
        高度系数=(-0.3,-0.03),
        宽度因子=无），
]）

我更改了我的 train_ds 以考虑数据增强，如下所示。此代码还对 train_ds 进行洗牌并对所有 ds 应用自动调整：
AUTOTUNE = tf.data.AUTOTUNE

resize_and_rescale = keras.Sequential([
  调整大小(224, 224),
  图层.重新缩放(1./255)
]）

def 准备（ds，shuffle=False，augment=False）：
  # 调整所有数据集的大小和比例。
  ds = ds.map(lambda x, y: (resize_and_rescale(x), y),
              num_parallel_calls=自动调谐）

  如果随机播放：
    ds = ds.shuffle(1000)

  # 仅在训练集上使用数据增强。
  如果增加：
    ds = ds.map(lambda x, y: (data_augmentation(x, 训练=True), y),
                num_parallel_calls=自动调谐）

  # 对所有数据集使用缓冲预取。
  返回 ds.prefetch(buffer_size=AUTOTUNE)


train_ds = 准备（train_ds，shuffle=True，augment=True）
val_ds = 准备(val_ds)
测试_ds = 准备（测试_ds）

当我检查增强后的 train_ds 大小时，它仍然保持增强前的原始大小。由于应用了3数据增强方法，它不应该至少4倍原始大小吗？
注释 1：我定义数据集如下：
导入tensorflow为tf

# 定义数据目录
train_dir = &#39;我的数据库/train/&#39;
val_dir = &#39;我的数据库/val/&#39;
test_dir = &#39;我的数据库/测试/&#39;

# 生成数据集
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    火车目录，
    批量大小=批量大小，
    ）

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    val_dir,
    批量大小=批量大小，
    ）

test_ds = tf.keras.preprocessing.image_dataset_from_directory(
    测试目录，
    批量大小=批量大小，
    ）


注释 2：我不想在模型的图层中添加 data_augmentation，因为我想将数据集单独保存在文件夹中，而不是每次运行模型时都应用增强。
要查看数据集大小，我首先使用粗略计算，将基数乘以批量大小：
train_size = tf.data.experimental.cardinality(train_ds).numpy()
打印（训练大小*批量大小）

val_size = tf.data.experimental.cardinality(val_ds).numpy()
打印（val_size*batch_size）

test_size = tf.data.experimental.cardinality(test_ds).numpy()
打印（测试大小*批量大小）

train_ds 中的图像数量在增强前后相同。
当我将 train_ds 与 augmneted_ds 合并时，如下所示，我只得到双大小，而不是原始数据集大小的4倍。
augmented_ds = 准备(train_ds, shuffle=True,augment=True) # augmnet the train_ds
train_ds =prepare(train_ds, shuffle=True,augment=False) #保留原来的train_ds
val_ds = 准备(val_ds)
测试_ds = 准备（测试_ds）

组合_ds = tf.data.Dataset.concatenate(augmented_ds, train_ds)

而且我觉得我不应该合并数据集。]]></description>
      <guid>https://stackoverflow.com/questions/77986399/data-augmentation-not-increasing-dataset-size</guid>
      <pubDate>Tue, 13 Feb 2024 08:16:25 GMT</pubDate>
    </item>
    <item>
      <title>我使用 sklearn 生成一个包含 7 个类的混淆矩阵，但只有第一行被填满</title>
      <link>https://stackoverflow.com/questions/77986103/im-generating-a-confusion-matrix-with-7-classes-using-sklearn-but-only-the-first</link>
      <description><![CDATA[热图似乎是正确的，但数字并没有显示。
conf_matrix = fusion_matrix(y_true, y_pred, labels=range(7))
plt.figure(figsize=(10,7))
sns.set(font_scale=1.4)
sns.heatmap(conf_matrix, annot=True, annot_kws={&quot;size&quot;: 16}, cmap=&quot;Blues&quot;, fmt=&#39;g&#39;)
plt.xlabel(&#39;预测&#39;)
plt.ylabel(&#39;真&#39;)
plt.title(&#39;混淆矩阵&#39;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/77986103/im-generating-a-confusion-matrix-with-7-classes-using-sklearn-but-only-the-first</guid>
      <pubDate>Tue, 13 Feb 2024 07:18:16 GMT</pubDate>
    </item>
    <item>
      <title>哪种 ML 模型可以处理多个输入和一个输出</title>
      <link>https://stackoverflow.com/questions/77986009/which-ml-model-can-handle-multiple-input-and-one-output</link>
      <description><![CDATA[我有一个机器学习问题。我得到的数据如下

&lt;标题&gt;

前一天
潮湿
阴
风速
城市最近下雨
最近下雨的天数


&lt;正文&gt;

第一天
60
是
&lt; 50米/秒
城市A
3


第二天
20
没有
&gt; 50米/秒
B市
1



...可以有多行。
输出是 Z 市下雨
是的
不
也许
对于 Z 市的 N 天，我有时有 2 天前的数据。有时我有 3 天前的数据。有时是 10 天前的数据。
下面是示例
13/03/2023 - Z 市下雨 - 是

&lt;标题&gt;

前一天
潮湿
阴
风速
城市最近下雨
最近下雨的天数


&lt;正文&gt;

第一天
60
是
&lt; 50米/秒
城市A
3


第二天
20
没有
&gt; 50米/秒
B市
1



2023 年 9 月 19 日 - Z 市下雨 - 否

&lt;标题&gt;

前一天
潮湿
阴
风速
城市最近下雨
最近下雨的天数


&lt;正文&gt;

第一天
60
是
&lt; 50米/秒
城市A
3


第一天
20
没有
&gt; 50米/秒
C市
1


第四天
30
是
&gt; 20米/秒
D市
5


第六天
10
没有
&lt; 50米/秒
城市Q
3



对于当前 X 天，我可以有任意数量的行，并且我想预测是否可能下雨。我该如何做到这一点以及使用哪种模型
尝试阅读可以应用的不同机器学习模型，但无法理解一个可以接受许多输入行、自动决定权重并​​预测降雨的模型。
例如，几乎可以肯定，如果第一天 A 市下雨，Z 市也会下雨]]></description>
      <guid>https://stackoverflow.com/questions/77986009/which-ml-model-can-handle-multiple-input-and-one-output</guid>
      <pubDate>Tue, 13 Feb 2024 06:58:07 GMT</pubDate>
    </item>
    <item>
      <title>通过 3dskullstripping 无 Nifiti 生成 MRI</title>
      <link>https://stackoverflow.com/questions/77985923/no-nifiti-generation-of-mri-via-3dskullstripping</link>
      <description><![CDATA[以下代码不会生成 nifiti 剥离头骨 MRI 图像。
目录看起来像这样 /4-Resample/LGG101/LGG102flair.nii.gz
“4-Resasmple”内有两个文件夹，文件夹内有一个 nifti 文件。
头骨条纹后，它会在“Skull_strpping_folder”中创建类似的文件夹和类似的nifiti文件。但以下代码没有创建任何内容。
导入操作系统
导入子流程
从 tqdm 导入 tqdm
导入时间

`# 定义输入和输出文件夹的路径
input_folder =“D：/AID/1-Anum（预处理）/Dataset-20240202T042956Z-001/Dataset/Sumaiya/4-Resampled/”
头骨_stripped_folder =“D：/AID/1-Anum（预处理）/Dataset-20240202T042956Z-001/Dataset/Sumaiya/5-Skull_Stripped/brain/”
mask_folder =“D：/AID/1-Anum（预处理）/Dataset-20240202T042956Z-001/Dataset/Sumaiya/5-Skull_Stripped/brain_mask/”

# 处理子文件夹中的 NIfTI 文件的函数
def process_subfolders(子文件夹路径):
    对于 os.walk(subfolder_path) 中的 root、_、文件：
        对于 tqdm(files) 中的文件名：
            if filename.endswith(“.nii.gz”):
                input_file = os.path.join(root, 文件名).replace(&quot;\\&quot;,&quot;/&quot;)
                打印（输入文件）
                relative_path = os.path.relpath(input_file,input_folder).replace(&quot;\\&quot;,&quot;/&quot;)
                打印（相对路径）
                头骨_stripped_output = os.path.join(skull_stripped_folder, 相对路径)
                打印（头骨剥离输出）
                mask_output = os.path.join(mask_folder, 相对路径)
# 打印（掩码输出）
                # 如果输出文件夹不存在则创建子文件夹
                os.makedirs（os.path.dirname（skull_stripped_output），exist_ok = True）
                os.makedirs(os.path.dirname(mask_output),exist_ok=True)

                # 定义 3dSkullStrip 命令
                skullstrip_cmd = f“3dSkullStrip -input {input_file} -prefix {skull_stripped_output}”

                # 运行 3dSkullStrip 命令
                subprocess.run(skullstrip_cmd, shell=True)

                # 定义 3dcalc 命令来创建二进制掩码
                calc_cmd = f“3dcalc -a {skull_stripped_output} -expr &#39;step(a)&#39; -prefix {mask_output}”`

                # 运行 3dcalc 命令
                subprocess.run(calc_cmd, shell=True)


# 处理输入文件夹子文件夹中的 NIfTI 文件
对于 os.listdir(input_folder) 中的子文件夹：
    subfolder_path = os.path.join(input_folder, subfolder).replace(&quot;\\&quot;,&quot;/&quot;)
    如果 os.path.isdir(子文件夹路径):
        进程子文件夹（子文件夹路径）
        打印（子文件夹路径）```

找出代码中的错误。
]]></description>
      <guid>https://stackoverflow.com/questions/77985923/no-nifiti-generation-of-mri-via-3dskullstripping</guid>
      <pubDate>Tue, 13 Feb 2024 06:35:05 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：无法将字符串转换为浮点数：'Guntur'[关闭]</title>
      <link>https://stackoverflow.com/questions/77985609/valueerror-could-not-convert-string-to-float-guntur</link>
      <description><![CDATA[我是一名学生，我尝试使用读取操作对数据集进行编程。
这是我的代码
 from sklearn.linear_model import LogisticRegression
    Lr = LogisticRegression(求解器=&#39;lbfgs&#39;, max_iter=1000,random_state=42)
    X = X.apply(pd.to_numeric, 错误=&#39;强制&#39;)
    y = y.apply(pd.to_numeric, 错误=&#39;强制&#39;)
    Lr.fit(X_train,y_train)
    y_pred = Lr.预测(X_test)
    model.append(&#39;逻辑回归&#39;)
    x = 准确度分数(y_test,y_pred)
    准确度.append(x)
    print(&#39;准确率分数为：&#39;,x)

我的错误是
 ValueError Traceback（最近一次调用最后一次）
    &lt;ipython-input-34-0b7b88828cb8&gt;在&lt;细胞系：5&gt;()
          3 X = X.apply(pd.to_numeric, 错误=&#39;强制&#39;)
          4 y = y.apply(pd.to_numeric, 错误=&#39;强制&#39;)
    ----&gt; 5 Lr.fit(X_train,y_train)
          6 y_pred = Lr.预测(X_test)
          7 model.append(&#39;逻辑回归&#39;)

    /usr/local/lib/python3.10/dist-packages/pandas/core/generic.py 在 __array__(self, dtype)
       2068
       第2069章np.ndarray：
    -&gt;第2070章
       2071
       第2072章

    ValueError：无法将字符串转换为浮点数：&#39;Guntur&#39;


我已经尝试使用 drop 函数来解决问题，并且可能通过填充空值来解决其他函数。
我期待线性回归的运算并且必须显示精度。我正在尝试解决这个错误 2 天]]></description>
      <guid>https://stackoverflow.com/questions/77985609/valueerror-could-not-convert-string-to-float-guntur</guid>
      <pubDate>Tue, 13 Feb 2024 04:52:45 GMT</pubDate>
    </item>
    <item>
      <title>lib/libtpu.so：使用 Google Cloud TPU VM 导入tensorflow as tf 时未定义符号</title>
      <link>https://stackoverflow.com/questions/77985557/lib-libtpu-so-undefined-symbol-in-import-tensorflow-as-tf-with-google-cloud-tpu</link>
      <description><![CDATA[我正在尝试使用 TensorFlow 在 Google Cloud TPU 虚拟机 (3-8) 上创建模型训练。将我的环境变量（Debian）设置为 export TPU_NAME=local、export NEXT_PLUGGABLE_DEVICE_USE_C_API=true 和 export TF_PLUGGABLE_DEVICE_LIBRARY_PATH=/lib/libtpu.so &gt;，我已经尝试了MNIST 入门指南（遵循其余的说明）和自定义模型（我实际上正在尝试训练的模型）。在这两种情况下，我都遇到了以下错误：
回溯（最近一次调用最后一次）：
  文件“/usr/share/tpu/models/official/legacy/image_classification/mnist_main.py”，第26行，在&lt;module&gt;中。
    将张量流导入为 tf
  文件“/home/icyseas_outlook_com/.local/lib/python3.10/site-packages/tensorflow/__init__.py”，第 460 行，在  中
    _ll.load_pluggable_device_library(
  文件“/home/icyseas_outlook_com/.local/lib/python3.10/site-packages/tensorflow/python/framework/load_library.py”，第 189 行，位于 load_pluggable_device_library
    py_tf.TF_LoadPluggableDeviceLibrary(lib)
tensorflow.python.framework.errors_impl.NotFoundError：/lib/libtpu.so：未定义符号：_ZN6proto27contrib11fingerprint29MaybeGenerateProtoFingerprintERKNS_7MessageE


无论我使用示例还是我自己的代码来尝试，未定义的符号都是相同的。
就其价值而言，这是我自己的代码的第一部分：
将 numpy 导入为 np
将 pandas 导入为 pd
导入PIL
将 matplotlib.pyplot 导入为 plt
将张量流导入为 tf
将 keras_tuner 导入为 kt
导入张量板
导入日志记录

# 设置日志记录

日志记录.basicConfig（级别=日志记录.INFO）

logging.info(“\n导入完成”)
logging.info(“使用 NumPy 版本 %s”, np.__version__)
logging.info(“使用 TensorFlow 版本 %s”, tf.__version__)
logging.info(“使用 Pandas 版本 %s”, pd.__version__)
logging.info(“使用 PIL 版本 %s”, PIL.__version__)

打印（tf.config.list_physical_devices（））

解析器 = tf.distribute.cluster_resolver.TPUClusterResolver(
    tpu=“本地”
）
tf.config.experimental_connect_to_cluster（解析器）
tf.tpu.experimental.initialize_tpu_system（解析器）
print(&quot;所有 TPU 设备：&quot;, tf.config.list_logic_devices(&quot;TPU&quot;))
策略 = tf.distribute.experimental.TPUStrategy(解析器)

错误发生在import tensorflow as tf行上，导致其余代码无法执行。我在 Python 3.11.0 上使用 Tensorflow 2.15.0。我的 Cloud TPU 软件版本是 tpu-vm-tf-2.15.0-pjrt。如果我尝试像以前一样不设置环境变量，则错误不会显示，但我的 TPU 也不会被识别。]]></description>
      <guid>https://stackoverflow.com/questions/77985557/lib-libtpu-so-undefined-symbol-in-import-tensorflow-as-tf-with-google-cloud-tpu</guid>
      <pubDate>Tue, 13 Feb 2024 04:28:18 GMT</pubDate>
    </item>
    <item>
      <title>如何正确准备数据集，设置 EfficientNetV2B0 模型以使用 Tensorflow 在自定义数据集上进行训练</title>
      <link>https://stackoverflow.com/questions/77985276/how-to-properly-prepare-dataset-setting-up-efficientnetv2b0-model-for-training</link>
      <description><![CDATA[我对机器学习还是新手。我想问我的代码有什么问题，结果模型没有正确分类苹果叶病。我在 4 个类的 7k 图像数据集上进行了训练，每个类都有大约 1.8k 的图像。每个类的总图像不相等，这会影响训练结果吗？或者我下面的代码有问题吗？
从 google.colab 导入驱动器
驱动器.mount(&#39;/content/gdrive&#39;)


导入压缩文件
zip_ref = zipfile.ZipFile(&#39;/content/gdrive/MyDrive/dataset/data9k.zip&#39;, &#39;r&#39;)
zip_ref.extractall(“/内容/数据集”)
zip_ref.close()


将张量流导入为 tf
从tensorflow.keras.applications.imagenet_utils导入preprocess_input
将 matplotlib.pyplot 导入为 plt


train_dataset = tf.keras.utils.image_dataset_from_directory(
&#39;/内容/数据集/数据集/火车&#39;,
批量大小=10，
图像大小=(224, 224),
标签=&#39;推断&#39;,
label_mode=&#39;分类&#39;
）


validation_dataset = tf.keras.utils.image_dataset_from_directory(
&#39;/内容/数据集/数据集/测试&#39;,
批量大小=10，
图像大小=(224, 224),
标签=&#39;推断&#39;,
label_mode=&#39;分类&#39;
）


val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = valid_dataset.take(val_batches // 5)
validation_dataset =validation_dataset.skip(val_batches // 5)


自动调谐 = tf.data.AUTOTUNE
train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset =validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)


data_augmentation = tf.keras.Sequential(
[tf.keras.layers.RandomFlip(&#39;水平&#39;),
tf.keras.layers.RandomRotation(0.2)]
）


模型 = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
include_top=假，
权重=无，
输入张量=无，
输入形状=(224, 224, 3),
池=&#39;平均&#39;，
include_preprocessing=True
）


#model.trainable=False


Prediction_layer = tf.keras.layers.Dense(4, 激活=&#39;softmax&#39;)


输入 = tf.keras.Input(形状=(224, 224, 3))
x = 数据增强（输入）
#x = 预处理输入(x)
x = 模型(x)
x = tf.keras.layers.Dropout(0.2)(x)
输出=预测层(x)
模型= tf.keras.Model（输入，输出）


模型.编译(
优化器=tf.keras.optimizers.Adam(learning_rate=1e-4),
损失=tf.keras.losses.CategoricalCrossentropy(),
指标=[&#39;准确性&#39;]
）


模型.拟合(
训练数据集，
验证数据=验证数据集，
纪元=10
）


将 numpy 导入为 np
从tensorflow.keras.preprocessing导入图像


img_path = &#39;gdrive/MyDrive/dataset/rust.jpg&#39;
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, 轴=0)


预测 = model.predict(img_array)


class_names = [&#39;apple_scab&#39;, &#39;black_rot&#39;, &#39;cedar_apple_rust&#39;, &#39;healthy&#39;]


Predicted_index = np.argmax(预测[0])
标签=类名[预测索引]
print(&quot;预测标签：&quot;, label)
]]></description>
      <guid>https://stackoverflow.com/questions/77985276/how-to-properly-prepare-dataset-setting-up-efficientnetv2b0-model-for-training</guid>
      <pubDate>Tue, 13 Feb 2024 02:23:46 GMT</pubDate>
    </item>
    <item>
      <title>R² 与解释方差 - 它们的数学公式完全相同，结果为何会不同？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77984814/r%c2%b2-vs-explained-variance-their-mathematical-formulas-are-exactly-the-same-how</link>
      <description><![CDATA[在机器学习 (ML) 和数据科学中的预测值评估中，有两种测量方法可以评估预测变量 R² 和解释值。我注意到R²的数学公式和解释的值是完全一样的：
在此处输入图像描述
在此处输入图像描述
但是基于Python中的Scikit-learn库以及我在网上查到的几篇参考文献，它们的结果值可能不同，为什么计算这些值的数学公式相同但结果可能不同？
我实际上在带有 Scikit 库的 Python 上尝试了这两个，结果可能真的不同！太奇怪了！]]></description>
      <guid>https://stackoverflow.com/questions/77984814/r%c2%b2-vs-explained-variance-their-mathematical-formulas-are-exactly-the-same-how</guid>
      <pubDate>Mon, 12 Feb 2024 23:20:15 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPytorch 的多输出 GP</title>
      <link>https://stackoverflow.com/questions/77985900/multiple-output-gp-using-gpytorch</link>
      <description><![CDATA[我正在尝试按照基本教程为下面的数据训练高斯过程https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html
train_x=[4058, 12] 的张量
train_y=[4058, 140] 的张量

我在损失计算中遇到错误：
loss = -mll(输出, train_y)

表示output (model(train_x)) 和train_y 没有相同的维度。鉴于此，我尝试了 MultitaskGPModel https:// /docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html 出现非常相似的错误
运行时错误：张量 a (568120) 的大小必须与非单维 0 处张量 b (8116) 的大小匹配

显然MultitaskGPModel要求相同的条目总数相等。有没有办法培养多次入境的全科医生？]]></description>
      <guid>https://stackoverflow.com/questions/77985900/multiple-output-gp-using-gpytorch</guid>
      <pubDate>Mon, 12 Feb 2024 22:47:00 GMT</pubDate>
    </item>
    <item>
      <title>MLFlow 可以在没有“with mlflow.start_run()”块的情况下使用吗？</title>
      <link>https://stackoverflow.com/questions/77983736/can-mlflow-be-used-without-the-with-mlflow-start-run-block</link>
      <description><![CDATA[我想跟踪整个笔记本并记录训练模型之前发生的清洁步骤的参数。我想使用 mlflow 来执行此操作，但在所有文档中，您似乎必须使用此格式跟踪模型：
与 mlflow.start_run():
    ...

有没有办法使用 mlflow 跟踪整个笔记本而不使用 with 块？]]></description>
      <guid>https://stackoverflow.com/questions/77983736/can-mlflow-be-used-without-the-with-mlflow-start-run-block</guid>
      <pubDate>Mon, 12 Feb 2024 19:05:13 GMT</pubDate>
    </item>
    <item>
      <title>二元预测的预测结果是否定的</title>
      <link>https://stackoverflow.com/questions/77982419/the-predictions-of-a-binary-prediction-are-negative</link>
      <description><![CDATA[我正在努力创建一个二进制模型。我以为一切正常，但当我发现模型关闭的频率很奇怪时，但当我尝试调整阈值时，我发现没有任何变化，所以就在那时我开始调查。
我检查了二元分类的预测值，发现其中大多数都是负值。
这是我的模型：
 public ITransformer TrainCategorialModel(IEnumerabletrainingData)
    {

        var 列名称 = typeof(TrainingCategorial)
            .GetProperties()
            .Where(property =&gt; property.DeclaringType != typeof(TrainingCategorial))
            .Select(属性 =&gt; 属性.名称)
            .ToArray();

        // 检查训练数据中的空值
        
        if (trainingData.Any(item =&gt; item == null))
        {
            throw new ArgumentException(“训练数据包含空值。”);
        }

        var pipeline = mLContext.Transforms.Concatenate(“特征”, columnNames)
            .Append(mLContext.BinaryClassification.Trainers.SdcaNonCalibrate(labelColumnName: &quot;CHPlabels&quot;, featureColumnName: &quot;Features&quot;));

        var data = mLContext.Data.LoadFromEnumerable(trainingData);

        var model = pipeline.Fit(data);

        返回模型；
    }

我的特征基于另一个类中的参数模型。
我的预测如下：
 公共列表; PredictCategorialModel（ITransformer 模型，IEnumerable 输入）
    {
        // 4. 转换数据
        IDataView 测试数据 = mLContext.Data.LoadFromEnumerable(input);

        // 5. 根据特征预测新值。
        列表&lt;浮动&gt; PredictedValues = mLContext.Data.CreateEnumerable(
            model.Transform(testingData),reuseRowObject: false)
            .Select(row =&gt; row.LabelPrediction)
            .ToList();

        // 应用阈值（例如 0.5）将分数转换为布尔预测
        变量阈值 = 0.3；
            列表&lt;布尔&gt; PredictedLabels = PredictedValues.Select(LabelPrediction =&gt; LabelPrediction &gt; 阈值).ToList();

        返回预测标签；
    }

我检查了我的数据，看起来没问题。如何解决这个问题？
更新：我认为问题出在模型中，我尝试了其他方法来创建预测布尔值，但遇到了相同的错误。我尝试过 LightGBM，因为我知道该模型不应该是线性的，但这产生了全新的问题（我对此也有一个未解答的问题）。有谁知道检查模型是否有效的好方法？]]></description>
      <guid>https://stackoverflow.com/questions/77982419/the-predictions-of-a-binary-prediction-are-negative</guid>
      <pubDate>Mon, 12 Feb 2024 15:09:31 GMT</pubDate>
    </item>
    <item>
      <title>在 Databricks MLFlow 中部署 ML 模型</title>
      <link>https://stackoverflow.com/questions/77982112/deploy-ml-model-in-databricks-mlflow</link>
      <description><![CDATA[我有一个在开发环境中训练的 ML 模型，现在我想将其部署在具有不同 URL 的 PROD databricks 中。我可以下载开发模型，然后手动将 pkl 文件上传到 PROD DBFS。下载模型后，如何在产品 MLFlow 中部署？
要下载我使用以下代码的模型
导入操作系统
导入流量
从 mlflow.store.artifact.models_artifact_repo 导入 ModelsArtifactRepository
mlflow.set_tracking_uri(“databricks”)
model_name = “测试模型”
model_stage = “无”
os.makedirs(“model2”,exist_ok=True)
local_path = ModelsArtifactRepository(f&#39;models:/{model_name}/{model_stage}&#39;).download_artifacts(“”, dst_path=&#39;model2&#39;)
print(f&#39;{model_stage} 模型 {model_name} 已在 {local_path} 下载&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/77982112/deploy-ml-model-in-databricks-mlflow</guid>
      <pubDate>Mon, 12 Feb 2024 14:21:56 GMT</pubDate>
    </item>
    <item>
      <title>如何包装 keras 模型以供 scikit-learn 堆叠集成使用</title>
      <link>https://stackoverflow.com/questions/77982056/how-to-wrap-keras-models-for-scikit-learn-stacking-ensemble-usages</link>
      <description><![CDATA[我有一个已经训练过的 keras 模型列表。我想在 scikit learn 中将它们与 StackingClassifier 一起使用。由于 keras 没有 Predict_proba 方法，我创建了一个包装器。
如果使用我的为 VotingClassifier 包装的模型以及软方法和硬方法，它就可以工作。
但是当我使用堆叠模型时，第一次运行后，它会显示此错误。我没有找到任何相关信息。
类 KerasWrapperWithEncoder(BaseEstimator, ClassifierMixin):
    def __init__(自身，keras_model，classes_)：
        self.keras_model = keras_model
        self.encoder = OneHotEncoder(sparse_output=False)
        # L&#39;encoder OneHotEncoder 已经过去了
        self.classes_ = classes_ # 定义可分配类

    def fit(自身, X, y):
        # 模型已安装，不再适合
        y_reshape = y.reshape(-1, 1)
        self.encoder.fit(y_reshape)
        返回自我

    def 预测（自身，X）：
        # 利用 les modèles entraînés pour faire des predictions
        预测 = self.keras_model.predict(X)
        np_argmax = np.argmax(预测，轴=1)
        打印（预测）
        打印（np_argmax）
        返回 np_argmax

    def Predict_proba(自身, X):
        # 返回分类模型的类别概率
        概率 = self.keras_model.predict(X)
        print(&quot;概率形状：&quot;, probabilities.shape) # 调试
        返回概率


keras_wrapped_models_with_encoder = [
    (name.replace(&#39; &#39;, &#39;_&#39;).replace(&#39;__&#39;, &#39;_&#39;), KerasWrapperWithEncoder(model, _target_classes_))
    对于 keras_models.items() 中的名称、模型
]

vote_clf = 投票分类器(
         估计器=all_估计器，
         投票=&#39;软&#39;，
         n_职位=3，
         详细=真）
vote_clf .fit(X_train, y_train) # 完美运行

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
keras_stacking_models_current_year = StackingClassifier(
    估计器=all_估计器，
    Final_estimator=LogisticRegression(),
    简历=简历，
    详细=3，
    # n_jobs=2
）


keras_stacking_models_current_year.fit(X_train, y_train) # 抛出错误


&lt;前&gt;&lt;代码&gt;========================================stacking_models_all_models===== =======================
12105/12105 [================================] - 25s 2ms/步
概率形状：(387348, 3)
训练折叠 (1) 中的类数与类总数 (3) 不匹配。结果可能不适合您的用例。要解决此问题，请使用交叉验证技术来产生正确分层的折叠
_enforce_prediction_order（类、预测、n_classes、方法）
   第1457章
   第1458章）
-&gt;第1459章
   第1460章 1460
   第1461章 回归预测

ValueError：形状不匹配：形状（387348,3）的值数组无法广播到形状（387348,1,3）的索引结果
]]></description>
      <guid>https://stackoverflow.com/questions/77982056/how-to-wrap-keras-models-for-scikit-learn-stacking-ensemble-usages</guid>
      <pubDate>Mon, 12 Feb 2024 14:12:27 GMT</pubDate>
    </item>
    </channel>
</rss>