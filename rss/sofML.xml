<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 01 Feb 2024 18:16:38 GMT</lastBuildDate>
    <item>
      <title>用于头影测量标志检测的数据预处理</title>
      <link>https://stackoverflow.com/questions/77922370/data-preprocessing-for-cephalometric-landmark-detection</link>
      <description><![CDATA[我的任务是通过 resnet50 模型进行头影测量地标定位，但该模型在训练和测试集中有很高的误差。
接下来我已经找到了有关感兴趣区域（ROI）的信息，它在训练模型之前裁剪具有标签（坐标x，y）的区域。
我的图像路径的坐标显示在此数据框中。

&lt;表类=“s-表”&gt;
&lt;标题&gt;

文件路径
原始坐标X（像素）
原始坐标 Y（像素）


&lt;正文&gt;

/Images_data/img0006.png
89
80


/Images_data/img0008.png
37
70




图像数据示例（681x481 像素）。在此处输入图像描述&lt; /p&gt;
感兴趣区域的示例（224x224 像素）。在此处输入图像描述 
我的问题是，如何预处理感兴趣区域的图像数据和坐标数据？
裁剪感兴趣区域后，我应该在训练数据集的裁剪图像上标记新坐标 x,y 吗？
或者裁剪感兴趣区域并使用原始坐标 x,y 作为训练数据集？]]></description>
      <guid>https://stackoverflow.com/questions/77922370/data-preprocessing-for-cephalometric-landmark-detection</guid>
      <pubDate>Thu, 01 Feb 2024 17:52:48 GMT</pubDate>
    </item>
    <item>
      <title>在google colab上使用tensorflow的问题</title>
      <link>https://stackoverflow.com/questions/77922080/problems-with-using-tensorflow-on-google-colab</link>
      <description><![CDATA[我对这一切都很陌生。有人可以告诉我发生了什么事吗？那么我该如何解决这个问题呢？
在此处输入图像描述
基本上，我想使用 tf，但我被卡住了。因为我以前从未使用过它。
我想将它与我的检测模型一起使用。
感谢大家的帮助。
谨此致以崇高敬意，祝大家好运。]]></description>
      <guid>https://stackoverflow.com/questions/77922080/problems-with-using-tensorflow-on-google-colab</guid>
      <pubDate>Thu, 01 Feb 2024 17:05:18 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn 线性回归中的 R² 分数差异</title>
      <link>https://stackoverflow.com/questions/77921865/r%c2%b2-score-discrepancy-in-linear-regression-with-sklearn</link>
      <description><![CDATA[我正在与 艾姆斯房价数据集并以两种方式拟合线性回归模型：

使用 fit_intercept=False 拟合模型，并手动将截距项添加到我的特征矩阵中。
使用 fit_intercept=True 拟合模型，无需手动添加截距项。

以下是这两种方法的代码：
# 方法1
X_train_with_intercept = np.concatenate([np.ones((X_train.shape[0], 1)), X_train], axis=1)
X_test_with_intercept = np.concatenate([np.ones((X_test.shape[0], 1)), X_test], axis=1)

lr = 线性回归(fit_intercept=False)
lr.fit(X_train_with_intercept, y_train)
lr.score(X_test_with_intercept, y_test)



# 方法2
lr = 线性回归(fit_intercept=True)
lr.fit(X_train, y_train)
r2_2 = lr.score(X_test, y_test)

我预计这两种方法都会给我相同的 R² 分数，因为理论上它们应该是相等的。然而，我发现结果存在显着差异。第一种方法给出的 R² 分数为 0.87。但第二种方法给了我一个很大的负数，表明该模型的性能比简单的均值模型差。
有趣的是，这两种方法在波士顿住房数据集上给出了逐位相同的答案。
为什么艾姆斯房价数据集的结果存在如此大的差异？]]></description>
      <guid>https://stackoverflow.com/questions/77921865/r%c2%b2-score-discrepancy-in-linear-regression-with-sklearn</guid>
      <pubDate>Thu, 01 Feb 2024 16:31:09 GMT</pubDate>
    </item>
    <item>
      <title>Python单变量线性回归给出水平斜率和高成本</title>
      <link>https://stackoverflow.com/questions/77921840/python-univariate-linear-regression-gives-horizontal-slope-and-high-cost</link>
      <description><![CDATA[我正在做线性回归的作业，但我的预测斜率遇到了问题。无论我做什么，它都会显示为一条水平线。成本也停留在 908787，没有任何改善。我遵循教授的职能，因为他希望这个模型从头开始编码。谁能告诉我我做错了什么？
将 numpy 导入为 np
从 sklearn.datasets 导入 load_diabetes
将 matplotlib.pyplot 导入为 plt

#数据集准备
糖尿病 = load_diabetes()
X = 糖尿病.数据
Y = 糖尿病.目标

# 仅使用一个特征（BMI）
X = X[:, np.newaxis, 2]
X = X.reshape((-1,1))

Y = np.expand_dims(Y, 1)
数据 = np.append(X, Y, 1)

# 随机洗牌
np.随机.种子(1201)
np.random.shuffle(数据)

# 分割数据
总样本 = len(数据)
训练 = 数据[:int(total_sample*0.70)]
dev = 数据[int(total_sample*0.70):int(total_sample*0.85)]
测试=数据[int(total_sample*0.85):]

def get_features_and_labels(数据):
  特征=数据[:,:-1]
  标签=数据[:,-1]
  返回特征、标签

train_x, train_y = get_features_and_labels(train)
dev_x, dev_y = get_features_and_labels(dev)
test_x, test_y = get_features_and_labels(测试)

# 线性回归模型

def univariate_线性_回归（theta，输入）：
  pred = theta[0] + theta[1]*输入
  返回预测值

# 成本函数
defcompute_cost(Y_pred, Y_true):
  J = 1/(2*m) * np.sum((Y_pred - Y_true)**2) # 均方误差
  返回J

def update_theta(theta, X, Y_true, Y_pred, lr):
  theta[0] = theta[0] - (lr * (1/m) * np.sum(Y_pred - Y_true))
  theta[1] = theta[1] - (lr * (1/m) * np.sum((Y_pred - Y_true) * X))
  返回θ

&lt;前&gt;&lt;代码&gt;theta = [0.0, 0.0]
lr = 0.0001
m = len(train_y)
k = 0
plt.figure(figsize=(30, 30))

对于范围（500）内的 i：
  pred = 单变量_线性_回归（theta，train_x）
  成本=compute_cost(pred,train_y)
  theta = update_theta(theta, train_x, train_y, pred, lr)


  如果（i%20==0）：
    print(f&quot;迭代 {i}, 成本: {cost}, Theta: {theta}&quot;)
    k+=1
    plt.子图(5, 5, k)
    plt.scatter(train_x, train_y, color=&#39;b&#39;)
    plt.plot(train_x, pred, &#39;g&#39;)

 s = &#39;theta:[%.4f, %.4f]&#39; %(theta[0], theta[1])
    c = &#39;成本：%.4f&#39; %成本
    plt.title(s+&#39;\n&#39;+c)

图形输出
我尝试使用学习曲线和初始 theta，但结果仍然相同。]]></description>
      <guid>https://stackoverflow.com/questions/77921840/python-univariate-linear-regression-gives-horizontal-slope-and-high-cost</guid>
      <pubDate>Thu, 01 Feb 2024 16:26:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么在尝试使用 shap.prep 查找 shap 值时会出现类强制错误？</title>
      <link>https://stackoverflow.com/questions/77921825/why-do-i-get-a-class-coercion-error-when-trying-to-use-shap-prep-to-find-shap-va</link>
      <description><![CDATA[我使用数据矩阵训练了 xgBoost 模型 bst_final：
dtrain &lt;- xgb.DMatrix(data = as.matrix(train_data[,
 c(1:6,8:ncol(train_data))]), 标签 = as.numeric(train_data$win_boule))

运行模型后，我尝试通过以下方式计算形状重要性：
shap_result &lt;- shap.score.rank(xgb_model = bst_final,
                X_train = dtrain,
                shap_approx = F)

结果很好，但是当我使用以下方法获得更广泛的结果集时：
shap_long = shap.prep(shap = shap_result,
                       X_train = dtrain,
                       顶部 n = 25)

我收到错误：
as.data.frame.default(x, ...) 中的错误：
  无法将类“xgb.DMatrix”强制转换为 data.frame

已经尝试了六次修复来尝试使其工作，有什么建议吗？
我尝试将 shap_result 和 shap_long 的 X_train 更改为更基本的 model.matrix，并使用更多选定的变量重新运行 xgboost 模型，以查看原始数据中是否存在问题。]]></description>
      <guid>https://stackoverflow.com/questions/77921825/why-do-i-get-a-class-coercion-error-when-trying-to-use-shap-prep-to-find-shap-va</guid>
      <pubDate>Thu, 01 Feb 2024 16:23:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在 mediapipe_model_maker 中指定增强数据类型？</title>
      <link>https://stackoverflow.com/questions/77921360/how-to-specific-augmentation-data-types-in-mediapipe-model-maker</link>
      <description><![CDATA[我正在尝试使用 mediapipe_model_maker 中的 image_classifier 来训练自定义 tflite 图像分类模型。我所看到的数据增强只是一个布尔值，可以在名为“do_data_augmentation”的选项中传递。进行随机增强（裁剪、翻转等）。
spec = image_classifier.SupportedModels.MOBILENET_V2
hparams=image_classifier.HParams(epochs=100,export_dir=“exported_model_2”,do_data_augmentation=False)
选项 = image_classifier.ImageClassifierOptions(supported_model=spec, hparams=hparams)

模型 = image_classifier.ImageClassifier.create(
    训练数据=训练数据，
    验证数据=验证数据，
    选项=选项，
）

我想具体说明数据增强，并且只保留翻转、曝光和模糊。那可能吗？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/77921360/how-to-specific-augmentation-data-types-in-mediapipe-model-maker</guid>
      <pubDate>Thu, 01 Feb 2024 15:20:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 XGBRegressor 预测未来数据</title>
      <link>https://stackoverflow.com/questions/77920944/how-to-predict-future-data-with-xgbregressor</link>
      <description><![CDATA[我有一个数据集，分割为 80/20，准确率约为 95%。我想使用现有数据来预测下个月的数据并看看它的进展如何。我将数据集与适当的时间行连接起来，并将我想要预测的列保留为 0。结果每天都返回相同的数字，与我在原始测试中看到的完全不同。
所以它看起来像：
时间壮举1壮举2
20240201 10 3
20240202 5 4
20240203 7 2
...

高精度预测
时间壮举1壮举2
20240201 10 3
20240202 5 4
20240203 7 2
...
20240301 0 0
20240302 0 0
20240203 0 0

每行预测相同的数字]]></description>
      <guid>https://stackoverflow.com/questions/77920944/how-to-predict-future-data-with-xgbregressor</guid>
      <pubDate>Thu, 01 Feb 2024 14:23:54 GMT</pubDate>
    </item>
    <item>
      <title>如何实现医疗疾病聊天机器人？需要帮助开始[关闭]</title>
      <link>https://stackoverflow.com/questions/77920821/how-to-implement-a-medical-disease-chatbot-need-help-starting</link>
      <description><![CDATA[我正在尝试创建一个结合 NLP 和计算机视觉的医疗疾病检测聊天机器人。我完成了 CV 部分，但对如何开始 NLP 部分感到困惑。
我设想的是一个聊天机器人，可以了解您的症状并帮助检测您的问题。我还希望聊天机器人可以选择获取医学 X 射线图像来帮助对疾病进行分类（也许可以将图像的分类与用户症状的分类结合起来）。对于图像分类，我使用了 Kaggle 的 X 射线数据集，并成功创建了一个根据 X 射线对疾病进行分类的模型。
现在，我需要使用 NLP 启动聊天机器人部分，但我不知道从哪里开始..

首先，这个医疗聊天机器人是否可以作为一个副项目来实现？我找不到类似的教程。
在哪里可以找到训练该模型的数据？或者使用像 BERT 这样的东西？
如果这个项目看起来可行，那么第一步是什么？数据怎么样？型号？

我尝试寻找数据集来训练医疗聊天机器人，但找不到任何内容。我在哪里可以找到这样的数据集？我可以微调 BERT 之类的东西吗？]]></description>
      <guid>https://stackoverflow.com/questions/77920821/how-to-implement-a-medical-disease-chatbot-need-help-starting</guid>
      <pubDate>Thu, 01 Feb 2024 14:07:25 GMT</pubDate>
    </item>
    <item>
      <title>培训师的表现就像是从头开始培训</title>
      <link>https://stackoverflow.com/questions/77919591/trainer-acts-as-if-its-training-from-scratch</link>
      <description><![CDATA[我正在使用 Huggingface 训练器训练模型，并为 resume_from_checkpoint 参数指定了检查点文件夹。
但是，当它继续训练时，它仍然会使用与第一个保存步骤相对应的名称保存检查点（例如 checkpoint-4，即使 resume_from_checkpoint 应从  开始检查点-4096）。进度条还显示所有 max_steps，尽管我不希望它从头开始。
这是一个常见问题吗？我该如何解决这个问题？
我将训练参数保存在 yaml 文件中：
training_args：
   学习率：!!float 1e-4
   do_train：正确
   每个设备训练批次大小：8
   每设备评估批量大小：8
   记录步骤：1024
   输出目录：/path/to/training_output/
   overwrite_output_dir：假
   删除未使用的列：假
   保存策略：步骤
   评估策略：步骤
   保存步骤：1024
   load_best_model_at_end：真
   热身步数：100
   最大步数：65536
   种子：22
   resume_from_checkpoint：/path/to/checkpoint-4096

然后通过使用 **kwargs 初始化 TrainingArguments 对象来训练模型。
但是终端显示：
将模型检查点保存到 /path/to/checkpoint-4

进度条显示了所有步骤，即使我需要它从步骤 4096 开始。]]></description>
      <guid>https://stackoverflow.com/questions/77919591/trainer-acts-as-if-its-training-from-scratch</guid>
      <pubDate>Thu, 01 Feb 2024 10:58:33 GMT</pubDate>
    </item>
    <item>
      <title>YOLO 标签格式</title>
      <link>https://stackoverflow.com/questions/77918107/yolo-labeling-formats</link>
      <description><![CDATA[我对“YOLO”进行了研究，并参与了一些涉及对象检测的示例项目。 “YOLO”注释格式通常遵循模式。 &lt;x&gt; &lt;y&gt; &lt;宽度&gt; &lt;高度&gt;。但是，我正在使用的标记工具“MakeSenseAI”仅允许导出边界框注释。
我的目标是使用线条和样条曲线来标记图像，而不仅仅是边界框。 YOLOv5 可以做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/77918107/yolo-labeling-formats</guid>
      <pubDate>Thu, 01 Feb 2024 06:36:57 GMT</pubDate>
    </item>
    <item>
      <title>从预测数组重建图像 - 填充相同显示重建图像中的网格图块</title>
      <link>https://stackoverflow.com/questions/77878901/image-reconstruction-from-predicted-array-padding-same-shows-grid-tiles-in-rec</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77878901/image-reconstruction-from-predicted-array-padding-same-shows-grid-tiles-in-rec</guid>
      <pubDate>Thu, 25 Jan 2024 09:43:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么提供训练和测试数据有助于在拟合模型 (LSTM) 时比使用 Timeseriesgenerator 实现更高的准确性？</title>
      <link>https://stackoverflow.com/questions/76506159/why-giving-the-train-and-test-data-helps-to-achieve-more-accuracy-while-fitting</link>
      <description><![CDATA[我正在尝试建立一个预测模型，如果我尝试使用 x_train 和 Y_train 拟合模型，它会比使用 train_generator 和 test_generator 产生更准确的输出。
获取 x_test 和 y_test：
x_train，x_test，y_train，y_test = train_test_split（特征，目标，test_size = 0.2，random_state = 123，shuffle = False）

获取训练和测试生成器：
train_generator = TimeseriesGenerator(x_train、y_train、长度= win_length、sampling_rate=1、batch_size=batch_size)
test_generator = TimeseriesGenerator(x_test、y_test、长度= win_length、采样率=1、batch_size=batch_size)

使用训练和测试数据拟合模型：
# 拟合模型
model.fit（x_train，y_train，batch_size = 16，epochs = 34，shuffle = False）

使用生成器拟合模型：
model.fit_generator(train_generator, epochs = 34,
        验证数据=测试生成器，
        随机播放=假）

所以我尝试使用这两种方法，第一种方法给出的 RMSE 为 6.3454423，第二种方法给出的 RMSE 为 13.4363478。这背后的原因可能是什么？]]></description>
      <guid>https://stackoverflow.com/questions/76506159/why-giving-the-train-and-test-data-helps-to-achieve-more-accuracy-while-fitting</guid>
      <pubDate>Mon, 19 Jun 2023 11:26:09 GMT</pubDate>
    </item>
    <item>
      <title>K-Fold交叉验证的应用和部署</title>
      <link>https://stackoverflow.com/questions/72319891/application-and-deployment-of-k-fold-cross-validation</link>
      <description><![CDATA[K 折叠交叉验证是一种用于将数据分割成 K 个折叠以进行测试和训练的技术。目标是估计机器学习模型的通用性。该模型经过 K 次训练，每个训练折叠训练一次，然后在相应的测试折叠上进行测试。
假设我想在某个具有 10 折的任意数据集上比较决策树和逻辑回归模型。假设在对 10 个折叠中的每个折叠训练每个模型并获得相应的测试精度后，逻辑回归在测试折叠中具有更高的平均精度，表明它是数据集更好的模型。
现在，进行应用和部署。我是在所有数据上重新训练 Logistic 回归模型，还是从在 K-Fold 上训练的 10 个 Logistic 回归模型创建一个整体？]]></description>
      <guid>https://stackoverflow.com/questions/72319891/application-and-deployment-of-k-fold-cross-validation</guid>
      <pubDate>Fri, 20 May 2022 13:39:25 GMT</pubDate>
    </item>
    <item>
      <title>在 bert 上训练新数据集</title>
      <link>https://stackoverflow.com/questions/69423258/training-a-new-dataset-on-bert</link>
      <description><![CDATA[我有一个亚马逊评论数据集，我想根据评论预测星级
我知道我可以使用预训练的 bert 模型，如下所示此处
但是我想在我自己的数据集上训练 bert 模型。这是这里正在做的事情 ？我可以在任何数据集的预训练模型上应用这种类型的“微调”以获得更准确的结果，还是我必须做其他事情来从头开始训练模型
如果我确实想从头开始训练模型，我会从哪里开始]]></description>
      <guid>https://stackoverflow.com/questions/69423258/training-a-new-dataset-on-bert</guid>
      <pubDate>Sun, 03 Oct 2021 08:30:00 GMT</pubDate>
    </item>
    <item>
      <title>您可以使用特定于任务的架构从头开始训练 BERT 模型吗？</title>
      <link>https://stackoverflow.com/questions/61826824/can-you-train-a-bert-model-from-scratch-with-task-specific-architecture</link>
      <description><![CDATA[基础模型的 BERT 预训练是通过语言建模方法完成的，我们在句子中屏蔽了一定比例的标记，然后让模型学习那些缺失的屏蔽。然后，我认为为了完成下游任务，我们添加一个新初始化的层并对模型进行微调。
但是，假设我们有一个巨大的句子分类数据集。理论上，我们是否可以从头开始初始化 BERT 基础架构，仅用这个句子分类数据集从头开始训练附加的下游任务特定层 + 基础模型权重，并且仍然取得良好的结果？]]></description>
      <guid>https://stackoverflow.com/questions/61826824/can-you-train-a-bert-model-from-scratch-with-task-specific-architecture</guid>
      <pubDate>Fri, 15 May 2020 19:21:56 GMT</pubDate>
    </item>
    </channel>
</rss>