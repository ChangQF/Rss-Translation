<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 21 Dec 2023 18:15:17 GMT</lastBuildDate>
    <item>
      <title>tf Keras：model.fit 错误“未实现：不支持将字符串转换为浮点数”</title>
      <link>https://stackoverflow.com/questions/77699401/tf-keras-model-fit-error-unimplemented-cast-string-to-float-is-not-supported</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77699401/tf-keras-model-fit-error-unimplemented-cast-string-to-float-is-not-supported</guid>
      <pubDate>Thu, 21 Dec 2023 16:49:56 GMT</pubDate>
    </item>
    <item>
      <title>另一幅图像中的图像识别[关闭]</title>
      <link>https://stackoverflow.com/questions/77699133/image-identification-within-another-image</link>
      <description><![CDATA[我有一个网站的屏幕截图。
我还有 10-15 个品牌徽标/商标图像。
假设有5个这样的品牌。
我总共有大约 60 个徽标/商标图像。
现在我的任务是以某种方式识别网站屏幕截图是否具有这些徽标，然后相应地告诉屏幕截图所属的品牌。
我想要一个还返回结果的解决方案，因为如果网站不包含我拥有的徽标，则找不到熟悉的徽标。
我应该采取什么方法？
图像比例和徽标图像比例可能会有很大差异。
我尝试过使用opencv模板匹配，但结果不太好。它给出了很多误报，例如徽标的置​​信度很高，即使它不存在，并且它用于指示错误的品牌。
我希望这是高度准确的。如果系统有疑问，它可以跳过网站图像，但应该减少错误答案。]]></description>
      <guid>https://stackoverflow.com/questions/77699133/image-identification-within-another-image</guid>
      <pubDate>Thu, 21 Dec 2023 16:01:33 GMT</pubDate>
    </item>
    <item>
      <title>用于批量 RNAseq 数据和随机森林模型的机器学习的 R 代码</title>
      <link>https://stackoverflow.com/questions/77698532/r-code-for-machine-learning-of-bulk-rnaseq-data-and-random-forest-model</link>
      <description><![CDATA[我想从批量 RNAseq 数据（使用 R 代码）和随机森林模型进行机器学习，并且我需要一个完整的 R 代码，用于使用此模型进行机器学习，其中包括我的 RNAseq 数据的最佳预处理（a批量RNAseq文件training_data.csv），看看大约有多少基因。它可以或应该被包含在内，例如能够对数据中不同类型的细胞进行分类等。此外，还可以了解除了随机森林之外对于此类数据使用的最佳模型是什么。]]></description>
      <guid>https://stackoverflow.com/questions/77698532/r-code-for-machine-learning-of-bulk-rnaseq-data-and-random-forest-model</guid>
      <pubDate>Thu, 21 Dec 2023 14:12:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 EmbeddingSimilarityEvaluator() 解释增强 SBERT 训练的评估值 [关闭]</title>
      <link>https://stackoverflow.com/questions/77698048/interpretation-of-evaluation-values-of-augmented-sbert-training-with-embeddingsi</link>
      <description><![CDATA[我训练 BI 编码器以获得增强型 SBERT，并获得最终训练结果。
如何解释最终训练结果的以下输出？
EmbeddingSimilarityEvaluator：评估测试数据集上的模型：
余弦相似度：Pearson：0.8115 Spearman：0.7777
曼哈顿距离：皮尔逊：0.7318 斯皮尔曼：0.6822
欧几里得距离：Pearson：0.7332 Spearman：0.6835
点积相似度： Pearson：0.7780 Spearman：0.7543

0.7777387754875323 # test_evaluator(...) 的输出

以下代码片段的输出结果：
# 加载存储的augmented-sbert模型
bi_encoder = SentenceTransformer(bi_encoder_path)
test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_samples, name=&#39;sts-test&#39;)
test_evaluator（bi_encoder，output_path = bi_encoder_path）

是高人还是低人。斯皮尔曼比较好？他们提供有关相关性的信息。]]></description>
      <guid>https://stackoverflow.com/questions/77698048/interpretation-of-evaluation-values-of-augmented-sbert-training-with-embeddingsi</guid>
      <pubDate>Thu, 21 Dec 2023 12:43:54 GMT</pubDate>
    </item>
    <item>
      <title>Xgboost 多类单调约束</title>
      <link>https://stackoverflow.com/questions/77697642/xgboost-multiclass-monotonic-constraints</link>
      <description><![CDATA[我有一个问题，我的价格是可变的，我需要将此价格分类为获胜/未获胜。如果价格上涨，概率应该单调下降。我使用工作正常的单调约束（xgboost库参数 https://xgboost .readthedocs.io/en/stable/tutorials/monotonic.html)
我使用的是 xgboost python 包版本 2.0.1。
现在，我正在尝试将我的解决方案升级为多类分类问题。现在，对于每个价格，我想知道属于第 1 类（获胜）、第 2 类（第二名）和第 3 类（其余位置）的概率。
使用 xgboost &#39;objective&#39; = &#39;multi:softprob&#39; 我得到了相当好的结果。但是， &#39;monotone_constraints&#39; = {&quot;price&quot;: -1} 没有任何效果。
是否有保证多类分类问题中的单调约束？ xgboost 是解决这个问题的最佳库吗？是否还需要确保单调约束？]]></description>
      <guid>https://stackoverflow.com/questions/77697642/xgboost-multiclass-monotonic-constraints</guid>
      <pubDate>Thu, 21 Dec 2023 11:24:57 GMT</pubDate>
    </item>
    <item>
      <title>如何从具有一对多关系的数据集开始创建用于机器学习的数据集？</title>
      <link>https://stackoverflow.com/questions/77696639/how-do-i-create-a-dataset-for-machine-learning-starting-from-datasets-that-have</link>
      <description><![CDATA[我有一个数据集（我们称之为 dataset1，它是一个 3000x6 数据集），结构如下：
X1,X2,X3,X4,X5,观察索引
D,3,3,0.12,0.3,0
B,2,3,0.2,0.27,1
B,4,5,0.2,0.18,2
A,3,5,0.28,0.24,3
B,3,5,0.17,0.29,4
列“ObservationIndex”包含一个扩展的整数序列，用作包含许多行（准确地说是 191 行）的 CSV 文件的索引。
因此，对于 dataset1 中的每一行，都存在一个对应的包含 191 行的 CSV 文件。
每个对应的 191 行 csv 的结构如下：
head_id,tail_id,initial_condition,目标变量
152331933,152432928,假,假
152331933,152432917,假,假
152331933,152331936,假,假
152331936,152943327,假,假
目的是预测目标变量，可以是 1 或 0。
如何创建可输入机器学习模型的数据集？
我的想法围绕着需要以某种方式创建新特征以形成正确的数据集。但是这个目标变量应该是什么？我已经排除了将所有 CSV 文件合并在一起的可能性，因为这会生成巨大的数据集。但是，我不确定在使用这些新功能训练模型后，如何恢复到对原始目标变量进行分类的原始问题。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77696639/how-do-i-create-a-dataset-for-machine-learning-starting-from-datasets-that-have</guid>
      <pubDate>Thu, 21 Dec 2023 08:31:21 GMT</pubDate>
    </item>
    <item>
      <title>如何将预测与标签相匹配 [CNN]？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77696572/how-do-i-match-predictions-with-labels-cnn</link>
      <description><![CDATA[我在 https://www.kaggle.com/datasets/iamsouravbanerjee/indian-food-images-dataset/data
Colab 文件：
https://colab.research.google.com/drive/1HWnVTUFf- CpZmNc16ZlQU_O5zwz_Elf4?usp=共享
我能够获得预测，但无法将其转换为菜名。我的项目需要它获取菜名，这样我才能获取它的营养。
如何让标签适用于此模型？或者这只是模型的错误
从tensorflow.keras.models导入load_model
从tensorflow.keras.preprocessing导入图像
从tensorflow.keras.applications.xception导入preprocess_input，decode_predictions
将 numpy 导入为 np

all_classes = [&#39;modak&#39;、&#39;bhindi_masala&#39;、&#39;butter_chicken&#39;、&#39;sohan_halwa&#39;、&#39;bhatura&#39;、&#39;poha&#39;、&#39;chicken_razala&#39;、&#39;imarti&#39;、&#39;qubani_ka_meetha&#39;、&#39;kajjikaya&#39;、&#39;makki_di_roti_sarson_da_saag&#39;、&#39;misi_roti&#39; , &#39;palak_paneer&#39;, &#39;naan&#39;, &#39;chikki&#39;, &#39;kachori&#39;, &#39;poornalu&#39;, &#39;anarsa&#39;, &#39;lassi&#39;, &#39;pithe&#39;, &#39;ghevar&#39;, &#39;sohan_papdi&#39;, &#39;chicken_tikka_masala&#39;, &#39;kadai_paneer&#39;, &#39; chhena_kheeri&#39;、&#39;rasgulla&#39;、&#39;lyangcha&#39;、&#39;chak_hao_kheer&#39;、&#39;aloo_gobi&#39;、&#39;navrattan_korma&#39;、&#39;daal_puri&#39;、&#39;phirni&#39;、&#39;chana_masala&#39;、&#39;kofta&#39;、&#39;dharwad_pedha&#39;、&#39;aloo_shimla_mirch&#39;、&#39;paneer_butter_masala &#39; , &#39;sandesh&#39;, &#39;double_ka_meetha&#39;, &#39;karela_bharta&#39;, &#39;maach_jhol&#39;, &#39;sheera&#39;, &#39;chicken_tikka&#39;, &#39;kalakand&#39;, &#39;misti_doi&#39;, &#39;biryani&#39;, &#39;ras_malai&#39;, &#39;daal_baati_churma&#39;, &#39;pootharekulu&#39;, &#39; gajar_ka_halwa&#39;、&#39;rabri&#39;、&#39;boondi&#39;、&#39;sutar_feni&#39;、&#39;aloo_tikki&#39;、&#39;malapua&#39;、&#39;薄饼&#39;、&#39;gulab_jamun&#39;、&#39;shankarpali&#39;、&#39;dal_makhani&#39;、&#39;ledikeni&#39;、&#39;kadhi_pakoda&#39;、&#39;shrikhand&#39; , &#39;cham_cham&#39;, &#39;bandar_laddu&#39;, &#39;unni_appam&#39;, &#39;aloo_matar&#39;, &#39;doodhpak&#39;, &#39;adhirasam&#39;, &#39;basundi&#39;, &#39;sheer_korma&#39;, &#39;mysore_pak&#39;, &#39;aloo_methi&#39;, &#39;dal_tadka&#39;, &#39;kakinada_khaja&#39;, &#39; gavvalu&#39;、&#39;dum_aloo&#39;、&#39;litti_chokha&#39;、&#39;ariselu&#39;、&#39;jalebi&#39;、&#39;kuzhi_paniyaram&#39;]
img_path = &#39;/content/JalebiIndia.jpg&#39; # 替换为图像路径
img = image.load_img(img_path, target_size=(100, 100)) # 调整大小以匹配模型的预期输入大小
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, 轴=0)
img_array = 预处理_输入(img_array)

# 获取模型预测
预测 = model_Xception.predict(img_array)

# 获取预测的类别索引
Predicted_class_index = np.argmax(预测)

# 将预测的类索引映射到您的自定义类标签
预测类标签 = 所有类[预测类索引]

print(&quot;预测类别：&quot;)
打印（预测的类标签）
]]></description>
      <guid>https://stackoverflow.com/questions/77696572/how-do-i-match-predictions-with-labels-cnn</guid>
      <pubDate>Thu, 21 Dec 2023 08:13:17 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker 端点 - 创建 ML 指标和仪表板</title>
      <link>https://stackoverflow.com/questions/77696324/sagemaker-endpoints-creating-ml-metrics-and-dashboards</link>
      <description><![CDATA[我部署了一个 sagemaker 端点。该模型是我创建的自定义随机森林模型。
日志被推送到 Cloudwatch，我手动添加了一个日志，显示提取的特征和模型得分。
我的最终目标是创建一个仪表板，我可以在其中评估模型的稳定性并查找数据或模型漂移。
关于如何做到这一点有什么建议吗？
现在我有一个 jupyter 笔记本，它查询写入分数（仅分数）的 mongoDB，并让我了解正在发生的事情。
这是一个手动过程，因为我们有多个端点写入不同类型的数据库，所以最好的办法是将 cloudwatch 作为源。]]></description>
      <guid>https://stackoverflow.com/questions/77696324/sagemaker-endpoints-creating-ml-metrics-and-dashboards</guid>
      <pubDate>Thu, 21 Dec 2023 07:16:53 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch中的动态量化量化后开始随机训练</title>
      <link>https://stackoverflow.com/questions/77692089/dynamic-quantization-in-pytorch-starts-random-training-after-quantization</link>
      <description><![CDATA[当我运行以下动态量化代码时，它开始使用一些随机自然图像进行 100 个时期的训练，我不想再次进行训练。我有预训练的权重，我只是想量化我的预训练的权重以减少推理时间：
从 ultralytics 导入 YOLO
进口火炬
导入火炬.量化

模型=YOLO(&#39;pre_trained_weights.pt&#39;)

model.load_state_dict(torch.load(&#39;checkpoint.pth&#39;)) #不知道这一步是否必要

qmodel = torch.quantization.quantize_dynamic(模型, dtype = torch.quint8)

我尝试了上面的代码，我希望我只是想量化我的预训练权重以减少推理时间]]></description>
      <guid>https://stackoverflow.com/questions/77692089/dynamic-quantization-in-pytorch-starts-random-training-after-quantization</guid>
      <pubDate>Wed, 20 Dec 2023 13:53:49 GMT</pubDate>
    </item>
    <item>
      <title>机器学习后出现相同指标结果的问题[关闭]</title>
      <link>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</guid>
      <pubDate>Tue, 19 Dec 2023 15:36:36 GMT</pubDate>
    </item>
    <item>
      <title>将变量从一个模块导入到另一个模块[关闭]</title>
      <link>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</guid>
      <pubDate>Mon, 18 Dec 2023 10:44:18 GMT</pubDate>
    </item>
    <item>
      <title>如何为此笔记本创建 Sagemaker 端点？</title>
      <link>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-notebook</link>
      <description><![CDATA[我创建了一个 VectorDB (FAISS) 并将 PDF 输入到其中。然后我使用 AWS Bedrock 的 Langchain 包装器来调用它。我知道现在存在 Kowledge Base，但至少在 SageMaker 笔记本中，我有更多的控制权。该模型在 SageMaker Notebook 中完美运行，当我提出问题时，它会返回答案。
我想做的是创建一个小网页（并通过 HTTP/REST API），只需在文本字段中提交问题并在文本字段中接收答案。我猜如果链中某个地方没有 Lambda 函数，这很难做到，或者也许不是？
当我查看 Sagemaker 控制台的推理选项卡下时，没有模型或没有端点，或者没有&lt; /strong&gt; 端点配置（因为我没有从 Sagemaker 选择模型，所以我只是在 Python 笔记本中使用 langchain LLM 和 Bedrock，如下所示）。
&lt;前&gt;&lt;代码&gt;导入boto3
导入 json

bedrock = boto3.client(service_name=&quot;bedrock&quot;)
bedrock_runtime = boto3.client(service_name=“bedrock-runtime”)



从 langchain.llms.bedrock 导入 Bedrock
从 langchain.chains 导入 RetrievalQA
从 langchain.prompts 导入 PromptTemplate

嵌入 = BedrockEmbeddings(model_id=“amazon.titan-embed-text-v1”,
                               客户端=bedrock_runtime）

最终我将文档嵌入到 FAISS Vector 数据库中，我查询的就是这个数据库
db = FAISS.from_documents（文档，嵌入）


模型泰坦 = {
    “最大令牌计数”：512，
    “停止序列”：[]，
    “温度”：0.0，
    “顶部P”：0.5
}

# 亚马逊泰坦模型
llm = 基岩(
    model_id=&quot;amazon.titan-text-express-v1&quot;,
    客户端=bedrock_runtime，
    model_kwargs=model_titan,
）

然后定义一个提示......
提示 = 提示模板(
    template=prompt_template, input_variables=[“上下文”, “问题”]
）

并查询数据库：
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type=“东西”，
    检索器=db.as_retriever(
        search_type=“相似度”，
    ),
    return_source_documents=真，
    chain_type_kwargs={“提示”: 提示},
）



query =“未来的技术是什么样的？”

结果 = qa({“查询”: 查询})

print(f&#39;查询: {结果[“查询”]}\n&#39;)
print(f&#39;结果: {结果[“结果”]}\n&#39;)
print(f&#39;上下文文档：&#39;)
对于结果 [“source_documents”] 中的 srcdoc：
      打印（f&#39;{srcdoc}\n&#39;）

这恰好返回了我在 Sagemaker 中需要的内容，我只需要从外部查询数据库即可。
我不想让 lambda 函数每次都重建链。我考虑的是效率，我需要的只是在 lambda 函数中传递查询并返回结果。
]]></description>
      <guid>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-notebook</guid>
      <pubDate>Thu, 14 Dec 2023 14:49:20 GMT</pubDate>
    </item>
    <item>
      <title>无法导出yolov8的输出</title>
      <link>https://stackoverflow.com/questions/76617086/unable-to-export-the-output-of-yolov8</link>
      <description><![CDATA[我在人脸识别项目的数据集上训练了yolov8模型，该模型运行良好并且模型的预测良好，但我无法导出预测图像的输出。
我提到了下面的代码：
# 导入 ultralytics 库

从 ultralytics 导入 YOLO

# 加载预训练的YOLOV8模型

模型 = YOLO(r&quot;C:\Users\Administrator\Desktop\YoloV8\runs\detect\yolov8s_custom3\weights\best.pt&quot;)
  
# 使用模型从实时网络摄像头进行预测、检测和跟踪

结果 = model.track(source=“0”,show=True)
#打印（结果）

我期望模型检测到的面部/人名能够导出到 csv 或 excel 文件中。但模型的输出是以数组形式存储的（结果）]]></description>
      <guid>https://stackoverflow.com/questions/76617086/unable-to-export-the-output-of-yolov8</guid>
      <pubDate>Wed, 05 Jul 2023 04:21:18 GMT</pubDate>
    </item>
    <item>
      <title>HuggingFace AutoModelForCasualLM “仅解码器架构”警告，即使在设置 padding_side='left' 后也是如此</title>
      <link>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</link>
      <description><![CDATA[我正在使用
AutoModelForCausalLM 和 AutoTokenizer 使用 DialoGPT 生成文本输出。
无论出于何种原因，即使使用 Huggingface 提供的示例，我也会收到此警告：
&lt;块引用&gt;
正在使用仅解码器架构，但检测到右填充！为了正确的生成结果，请在初始化分词器时设置 padding_side=&#39;left&#39;。

从变压器导入 AutoModelForCausalLM, AutoTokenizer
进口火炬


tokenizer = AutoTokenizer.from_pretrained(“microsoft/DialoGPT-medium”)
模型 = AutoModelForCausalLM.from_pretrained(“microsoft/DialoGPT-medium”)

# 我们聊5行吧
对于范围（5）中的步骤：
    # 对新的用户输入进行编码，添加 eos_token 并在 Pytorch 中返回一个张量
    new_user_input_ids = tokenizer.encode(input(“&gt;&gt;用户:”) + tokenizer.eos_token, return_tensors=&#39;pt&#39;)

    # 将新的用户输入标记附加到聊天历史记录中
    bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) 如果步骤 &gt; 0 其他 new_user_input_ids

    # 生成响应，同时将总聊天历史记录限制为 1000 个令牌，
    chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)

    # 漂亮地打印机器人最后的输出令牌
    print(“DialoGPT: {}”.format(tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0],skip_special_tokens=True)))

代码由 微软在 Huggingface 的模型卡上
我尝试将 padding_side=&#39;left&#39; 添加到标记生成器，但这不会改变任何内容。
显然（从一些阅读来看）DialoGPT 无论如何都希望在右侧填充？
我无法弄清楚这一点，当我尝试谷歌搜索时几乎没有结果。
我能够像这样抑制警告：
from Transformers.utils 导入日志记录

记录.set_verbosity_info()

但这似乎不是最好的答案？]]></description>
      <guid>https://stackoverflow.com/questions/74748116/huggingface-automodelforcasuallm-decoder-only-architecture-warning-even-after</guid>
      <pubDate>Fri, 09 Dec 2022 20:39:39 GMT</pubDate>
    </item>
    <item>
      <title>将 Superpoint 的 Tensorflow 模型转换为 Android 的 tflite 模型时出现问题</title>
      <link>https://stackoverflow.com/questions/63131283/problem-with-converting-tensorflow-model-of-superpoint-to-tflite-model-for-andro</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/63131283/problem-with-converting-tensorflow-model-of-superpoint-to-tflite-model-for-andro</guid>
      <pubDate>Tue, 28 Jul 2020 09:42:45 GMT</pubDate>
    </item>
    </channel>
</rss>