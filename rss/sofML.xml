<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 14 Jun 2024 09:16:03 GMT</lastBuildDate>
    <item>
      <title>ML.NET 中的 Essentia 模型无法预测</title>
      <link>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</link>
      <description><![CDATA[我正在尝试使用 Essentia discogs_track_embeddings-effnet-bs64 模型和 ML.NET 进行预测。我尝试过使用 tensorflow 和 onnx，但当我尝试预测任何东西时，我都遇到了问题
抛出异常：Microsoft.ML.Data.dll 中的“System.InvalidOperationException”
Microsoft.ML.Data.dll 中发生了未处理的“System.InvalidOperationException”类型的异常
拆分器/合并器工作程序在使用源数据时遇到异常

目前，我正在使用 onnx，因此其余部分将是该尝试的堆栈跟踪和代码。
完整调用堆栈：
 在 Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)
在 Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()
在 Microsoft.ML.Data.RootCursorBase.MoveNext()
在Microsoft.ML.Data.ColumnCursorExtensions.&lt;GetColumnArrayDirect&gt;d__4`1.MoveNext()
在 System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)
在 System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)
在 Program.&lt;Main&gt;$(String[] args) 中的 Program.cs:line 122

在行上：var embeddingColumn = perceivedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
onnx 加载和预测代码：
Console.WriteLine($&quot;[+] Loading Model&quot;);
var mlContext = new MLContext();

// 将 melspectrogram 数据加载到管道中
var modelPath = &quot;discogs_track_embeddings-effnet-bs64-1.onnx&quot;;
var pipeline = mlContext.Transforms.ApplyOnnxModel(
modelFile: modelPath,
fallbackToCpu: true
);
IDataView mockData = mlContext.Data.LoadFromEnumerable(new List&lt;ModelInput&gt;() { new ModelInput() });
var model = pipeline.Fit(mockData);

var schema = model.Transform(mockData).Schema;
Console.WriteLine(&quot;[*] Model Schema:&quot;);
foreach (var column in schema)
{
Console.WriteLine($&quot;Column Name: {column.Name}, Column Type: {column.Type}&quot;);
}

//PredictionEngine&lt;MelspectrogramData, OutputData&gt; predictionEngine = mlContext.Model.CreatePredictionEngine&lt;MelspectrogramData, OutputData&gt;(estimator);

//var predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput, ModelOutput&gt;(mo​​del);

List&lt;ModelOutput&gt; allPredictions = new List&lt;ModelOutput&gt;();

foreach (var fragment in melSpectrogram)
{
var seg = MelSpectrogramGenerator.ConvertToFloat(segment);
for (int i = 0; i &lt; seg.GetLength(0); i++)
{
for (int j = 0; j &lt; seg.GetLength(1); j++)
{
for (int k = 0; k &lt; seg.GetLength(2); k++)
{
// 用您的特定检查替换条件
if (double.IsNaN(seg[i, j, k]) || seg[i, j, k] == null)
{
Console.WriteLine($&quot;NaN found at ({i}, {j}, {k})&quot;);
}
}
}
var data = new ModelInput
{
Melspectrogram = seg
};
IDataView dataView = mlContext.Data.LoadFromEnumerable(new [] { data });
var perceivedData = model.Transform(dataView);

// 检索嵌入
var embeddingColumn = formedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
foreach (var value in embeddingColumn.First())
{
Console.Write($&quot;{value} &quot;);
}
//allPredictions.Add(scoredData.);
Console.WriteLine(&quot;Wheee&quot;);
}

public class ModelInput
{
[VectorType(64, 128, 96)]
[ColumnName(&quot;melspectrogram&quot;)]
public float[,,] Melspectrogram { get; set; }
public ModelInput()
{
Melspectrogram = new float[64, 128, 96];
}
}

// 定义输出模式
public class ModelOutput
{
[VectorType(64, 512)]
[ColumnName(&quot;embeddings&quot;)]
public float[,] Embeddings { get; set; }
public ModelOutput()
{
Embeddings = new float[64, 512];
}
}

目前在 Microsoft.ML 3.0.1、Microsoft.ML.OnnxRuntime.Managed 1.18.0 上
我检查过，我的数据中没有 NaN，而且我的变量都不是 Null。我非常迷茫，不知道如何修复这个问题，甚至不知道如何继续进行故障排除。]]></description>
      <guid>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</guid>
      <pubDate>Fri, 14 Jun 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>在 tfjs tensorflow.js 中设置残差神经网络块</title>
      <link>https://stackoverflow.com/questions/78621757/setup-a-residual-neural-network-block-in-tfjs-tensorflow-js</link>
      <description><![CDATA[我正在尝试在 tensorflow.js 中实现 ResNet（残差神经网络）的行为。我希望知道他们在做什么的人能给我指明正确的方向。以下代码是否会有效地将第 3、4、5 层变成残差块？更具体地说，我包含的连接层是否像文献中描述的身份跳过连接一样起作用？TFJS 是否自动知道如何通过连接层传递反向传播信号？
 const density_layer_1 = TENSORFLOW.layers.dense({ unit: 1600,activation: &quot;relu&quot;, useBias: true }).apply(input);
const density_layer_2 = TENSORFLOW.layers.dense({ unit: 800,activation: &quot;relu&quot;, useBias: true }).apply(dense_layer_1);
const density_layer_3 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_2);
const density_layer_4 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_3);
const density_layer_5 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_4);
const density_layer_6 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_5);
const concat_layer1 = TENSORFLOW.layers.concatenate().apply([dense_layer_2, density_layer_6]);
const density_layer_7 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(concat_layer1);
const density_layer_8 = TENSORFLOW.layers.dense({ 单位：800，激活：“relu”，useBias：true }).apply(dense_layer_7);
const output = TENSORFLOW.layers.dense({ 单位：1，激活：“线性”，useBias：true }).apply(dense_layer_8);
const residual_model = TENSORFLOW.model({ 输入：输入，输出：输出 });```
]]></description>
      <guid>https://stackoverflow.com/questions/78621757/setup-a-residual-neural-network-block-in-tfjs-tensorflow-js</guid>
      <pubDate>Fri, 14 Jun 2024 08:03:45 GMT</pubDate>
    </item>
    <item>
      <title>Vitas AI(Pytorch)：在模型量化期间出现错误 - AttributeError：无法设置属性</title>
      <link>https://stackoverflow.com/questions/78621742/vitas-aipytorch-getting-error-attributeerror-cant-set-attribute-during-q</link>
      <description><![CDATA[我有一个 Python 版的 LSTM 模型，我正在尝试使用 Vitis AI (Pytorch) 将其部署到 ZCU104 板上。我在量化模型时遇到错误。我收到以下行的错误：
quantizer.export_xmodel(output_dir=&quot;quantize_result&quot;, deploy_check=True)
错误是：
[VAIQ_NOTE]: =&gt;Converting to xmodel ...

回溯（最近一次调用最后一次）：

文件“lstm_quant.py”，第 118 行，位于 &lt;module&gt;

main(args)

文件“lstm_quant.py”，第 107 行，在 main 中

quantizer.export_xmodel(output_dir=“quantize_result”，deploy_check=True)

文件“/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/apis.py”，第 148 行，在 export_xmodel 中

self.processor.export_xmodel(output_dir, deploy_check, dynamic_batch)

文件“/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/base.py”，第 368 行，在 export_xmodel 中

dump_xmodel(output_dir, deploy_check, self._lstm_app)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/base.py&quot;，第 505 行，位于 dump_xmodel

deploy_graphs, _ = get_deploy_graph_list(quantizer.quant_model, quantizer.Nndctgraph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/utils.py&quot;，第 463 行，位于 get_deploy_graph_list

return _deploy_optimize(quant_model, nndct_graph, need_pa​​rtition)

文件&quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/pytorch_nndct/qproc/utils.py&quot;，第 419 行，在 _deploy_optimize

g_optmizer = DevGraphOptimizer(nndct_graph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/compile/deploy_optimizer.py&quot;，第 92 行，在 __init__

self._dev_graph.clone_from(nndct_graph)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_graph.py&quot;，第133，在 clone_from 中

self._top_block.clone_from(src_graph.block, local_map, converted_nodes)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_block.py&quot;，第 47 行，在 clone_from 中

self.append_node(self.owning_graph.create_node_from(node, local_map, converted_nodes))

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_graph.py&quot;，第 161 行，在 create_node_from 中

node.clone_from(src_node, local_map)

文件&quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_node.py&quot;，第 120 行，在 clone_from 中

self.op.clone_from(src_node.op, local_map)

文件 &quot;/opt/vitis_​​ai/conda/envs/vitis-ai-pytorch/lib/python3.8/site-packages/nndct_shared/nndct_graph/base_operator.py&quot;，第 214 行，在 clone_from 中

setattr(self, config, new_value)

AttributeError：无法设置属性

在以下 Google 链接中附加完整错误、模型代码和量化脚本：
量化脚本：
https://docs.google.com/document/d/1jRYmPH2z70ovpc_FJIBpUQaTHUPRrTgnPVxlQJ1JLug/edit?usp=sharing
模型脚本：
https://docs.google.com/document/d/1OBZw4XhdHpVhA0gKcJn2NzR_WA7ZczQ3hL42f_sMKug/edit?usp=sharing
完整错误：
https://docs.google.com/document/d/1kI1WJqq9pp3aSsGLpNGjf22mzK6swIiZbIXwfUeTGto/edit?usp=sharing
尝试更改 base_operator.py，但没有成功。也尝试简化模型，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78621742/vitas-aipytorch-getting-error-attributeerror-cant-set-attribute-during-q</guid>
      <pubDate>Fri, 14 Jun 2024 08:00:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 pandas 数据框中的 lambda 函数在列之间执行多项计算</title>
      <link>https://stackoverflow.com/questions/78621386/perform-multiple-calculations-among-columns-using-lambda-function-in-pandas-data</link>
      <description><![CDATA[我有一个包含多列的数据框。有一列名为“remaining_lease”，其中 75% 为 Nan。我不想删除该列。因此，我想使用另外两列“lease_commense_date”和“current_year”来计算“remaining_lease”。公式如下：
remaining_lease = 99 - ( current_year - lease_commense_date)
例如：current_year = 2022 和 lease_commense_date = 1979
则 remaining_lease = 99 - (2022 - 1979) = 56
我编写了一个函数来执行此操作。
def remaining_lease_year(x, current_year, commense_year):
if math.isnan(x): # 如果值为 nan
lease_year = 99 - (current_year - commense_year)
return lease_year
else: # 如果值不是 nan
return x
df[&#39;remaining_lease&#39;] = df[&#39;remaining_lease&#39;].apply(lambda x: remaining_lease_year(x, df[&#39;current_year&#39;], df[&#39;lease_commence_date&#39;]))

但是我收到错误：
MemoryError：无法为形状为 (927465,) 且数据类型为 int64 的数组分配 7.08 MiB
还有其他方法可以实现吗？如能提供帮助，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78621386/perform-multiple-calculations-among-columns-using-lambda-function-in-pandas-data</guid>
      <pubDate>Fri, 14 Jun 2024 06:33:10 GMT</pubDate>
    </item>
    <item>
      <title>未找到 keras.utils.PyDataset</title>
      <link>https://stackoverflow.com/questions/78621236/keras-utils-pydataset-not-found</link>
      <description><![CDATA[class BatchedDataset(tf.keras.utils.PyDataSet):
使用 keras PyDataset 时，我不断收到此错误。我尝试更新 tensorflow 并使用 tf.keras.api._v2。这些都不起作用
我正在使用 google colab
]]></description>
      <guid>https://stackoverflow.com/questions/78621236/keras-utils-pydataset-not-found</guid>
      <pubDate>Fri, 14 Jun 2024 05:43:38 GMT</pubDate>
    </item>
    <item>
      <title>贝叶斯优化中的探索与利用权衡</title>
      <link>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</link>
      <description><![CDATA[最近我在研究贝叶斯优化，但有些东西我不太明白。我知道 BO 使用获取函数来平衡探索和利用。我们可以添加一个参数（epsilon）来调整我们想要更多的探索还是利用。但参数是如何做到的？就像 PI 和 EI 获取函数一样，为什么大的 epsilon 可以使算法更具探索性，反之亦然？]]></description>
      <guid>https://stackoverflow.com/questions/78620985/exploration-and-exploitation-tradeoff-in-bayesian-optimization</guid>
      <pubDate>Fri, 14 Jun 2024 04:07:57 GMT</pubDate>
    </item>
    <item>
      <title>该数据集需要进行哪些预处理？[关闭]</title>
      <link>https://stackoverflow.com/questions/78620975/which-are-the-preprocessing-required-on-this-dataset</link>
      <description><![CDATA[数据集链接：- https://www.kaggle.com/datasets/nijpadariya/cardiovascular-disease/data
笔记本链接：- https://colab.research.google.com/drive/1h8wa2yUGQJMyZcoifgD-5PsG6XvyvlB2?usp=sharing
上面的笔记本代表了我迄今为止在数据集上所做的工作
因为我必须使用这个数据集，但我不知道我可以显示什么，也不知道这些数据需要哪些预处理步骤，以及如何使用属性来显示一些结果。
有人能帮我找到吗？
有什么帮助可以找到数据集上的结果和预处理步骤所需的]]></description>
      <guid>https://stackoverflow.com/questions/78620975/which-are-the-preprocessing-required-on-this-dataset</guid>
      <pubDate>Fri, 14 Jun 2024 04:01:34 GMT</pubDate>
    </item>
    <item>
      <title>我如何将所有 csv 文件数据绘制到一张图表中并以可解释的方式表示它？</title>
      <link>https://stackoverflow.com/questions/78620038/how-can-i-plot-all-csv-files-data-into-one-graph-and-represent-it-in-such-a-way</link>
      <description><![CDATA[我使用一些传感器收集了时间序列数据。数据集包含两个类别的 60 个样本，每个类别有 30 个样本。每个样本有 50 行和 11 列，标签以注释方式完成，即样本的文件名是样本数据的标签。现在，我想以一种应该表示与时间相关的数据的方式来可视化数据。 （例如 x 轴上的时间和 y 轴上的传感器值）。
这是来自数据集的样本图像（样本图像 1）（样本图像 2）
这是我的数据集的链接：https://drive.google.com/drive/folders/1aRIR5ei3Gr0RdS8QXM6hrqPQ2cJdRyEp
我还提供了代码，我曾尝试将其可视化，但帮助不大。
提供的代码未提供所需的输出。输出图像之一是：

此图是通过更改 go.Scatter() 中的 x=df.columns、y=df.iloc[0] 的值生成的
我想生成一个图表，其中 x 轴上有 50 个点（50 行）作为时间点，y 轴上绘制有 11 列数据。
任何帮助都将不胜感激！谢谢 &amp;问候
代码：
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import plotly.offline as pyo
import os

# 获取目录中的 csv 文件列表
PATH = &quot;E:\\Sankalp\\Practice_Stuff\\DummyData\\&quot;
fileNames = os.listdir(PATH)
fileNames = [file for file in fileNames if &#39;.csv&#39; in file]

# 创建图形
fig = go.Figure()
x_axis_values = list(range(50))

# 循环遍历每个 csv 文件并向图形添加轨迹
for file in fileNames:
if file.startswith(&#39;bye bye&#39;): 
df = pd.read_csv(os.path.join(PATH, file),header=None)
fig.add_trace(go.Scatter(x=x_axis_values, y=df.iloc[:,:], name=file, mode=&#39;lines+markers&#39;,line=dict(color=&quot;#2efd70&quot;)))
elif file.startswith(&#39;welcome&#39;):
df = pd.read_csv(os.path.join(PATH, file),header=None)
fig.add_trace(go.Scatter(x=x_axis_values, y=df.iloc[:,:], name=file, mode=&#39;lines+markers&#39;,line=dict(color=&quot;#ff0000&quot;)))

# 显示图表
fig.update_layout(title=&#39;\&#39;Welcome\&#39;&#39; 的趋势图, xaxis_title=&#39;Time&#39;, yaxis_title=&#39;Values&#39;)
fig.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78620038/how-can-i-plot-all-csv-files-data-into-one-graph-and-represent-it-in-such-a-way</guid>
      <pubDate>Thu, 13 Jun 2024 20:25:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 S3 存储桶中的训练数据训练 YOLOv8？</title>
      <link>https://stackoverflow.com/questions/78619753/how-to-train-yolov8-with-traingin-data-in-s3-bucket</link>
      <description><![CDATA[似乎 model.train 需要 data.yml 文件的路径，并且该文件需要有训练和验证集的路径。s3 引用似乎不是实际路径，我看到人们使用数据生成器使用 S3 进行训练。有人知道如何使用 YOLOv8 做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/78619753/how-to-train-yolov8-with-traingin-data-in-s3-bucket</guid>
      <pubDate>Thu, 13 Jun 2024 19:08:12 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 datumaro 合并 comment.xml 和视频以获取仅具有标记图像的 yolo 数据集？</title>
      <link>https://stackoverflow.com/questions/78619747/how-can-i-use-datumaro-to-merge-the-annotations-xml-video-to-get-a-yolo-datase</link>
      <description><![CDATA[我是机器学习领域的新手，我刚刚发现这些
datum project import --format cvat -n cvat1 comments.xml
datum project import --format video_frames -n vid1 video.mp4

我发现https://github.com/cvat-ai/cvat/issues/1251这个
datum project export -e &#39;/item/annotation&#39; --filter-mode &#39;i+a&#39; -f --save-images &lt; your_target_format &gt; --

但我不知道如何实现这一点

https://openvinotoolkit.github.io/datumaro/latest/docs/data-formats/formats/yolo_ultralytics.html

为什么

cvat 在 docker 中运行，比主机 (macOS) 慢
cvat 导出帧很慢，每次导出图像都需要准备所有帧，即使是一点点标签更改
我希望我可以使用 annotations.xml+video/frames 来获得更快的导出
我希望我可以使用 jpg 而不是 png - MP4 视频，jpg 较好，png 很大。
]]></description>
      <guid>https://stackoverflow.com/questions/78619747/how-can-i-use-datumaro-to-merge-the-annotations-xml-video-to-get-a-yolo-datase</guid>
      <pubDate>Thu, 13 Jun 2024 19:07:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 detector2 区分灰度图像中的两种颜色并掩盖它们？</title>
      <link>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</link>
      <description><![CDATA[我刚开始使用detectron2，我计划将它用于一个项目。该项目包括使用该模型区分灰度图像中的对象。该图像由形状奇怪的灰色单元格组成，而其余空间为黑色。我的任务是使用该模型并描绘出灰色单元格的形状。
示例图像：
单元格的灰度图像
我曾尝试使用预先存在的模型来解决这个问题，但它们无法识别出物体的存在。解决这个问题的最佳方法是什么？
此外，我愿意使用不同的机器学习模型。我只是想找到一种区分灰色和黑色的方法。
提前非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</guid>
      <pubDate>Thu, 13 Jun 2024 17:36:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习视觉模型以 95% 的准确率预测新数据相同的标签</title>
      <link>https://stackoverflow.com/questions/78619195/machine-learning-visual-model-with-95-accuracy-predicts-new-data-the-same-label</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78619195/machine-learning-visual-model-with-95-accuracy-predicts-new-data-the-same-label</guid>
      <pubDate>Thu, 13 Jun 2024 16:45:35 GMT</pubDate>
    </item>
    <item>
      <title>如何按照物体在最顶层的顺序检测和识别它们，然后对它们进行分层并为它们分配 ID？</title>
      <link>https://stackoverflow.com/questions/78605533/how-to-detect-and-identify-objects-in-the-order-that-they-are-on-top-then-layer</link>
      <description><![CDATA[
我尝试过过滤掉它们的线条，现在该如何确定哪个物体被隐藏了
我也尝试过使用 yoloV8 来过滤物体，但仍然无法确定哪个物体被另一个物体遮挡了，有人能帮我吗？
CODE:
import cv2
import numpy as np

# 加载图像 + mask、灰度、高斯模糊、Otsu 阈值
image = cv2.imread(&quot;./anhtest/11.png&quot;) # 这是原始图像
original = image.copy()
mask = cv2.imread(&quot;./anhtest/11.png&quot;) # 这是从 U-2-Net 生成的掩码
gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
bg_removed = cv2.bitwise_and(image, image, mask=thresh)

# HSV 颜色阈值
hsv = cv2.cvtColor(bg_removed, cv2.COLOR_BGR2HSV)
lower = np.array([0, 0, 0])
upper = np.array([179, 33, 255])
hsv_mask = cv2.inRange(hsv, lower, upper)
isolated = cv2.bitwise_and(bg_removed, bg_removed, mask=hsv_mask)
isolated = cv2.cvtColor(isolated, cv2.COLOR_BGR2GRAY)
isolated = cv2.threshold(isolated, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]

# 变形操作以去除小伪影和噪音
open_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
opening = cv2.morphologyEx(isolated, cv2.MORPH_OPEN, open_kernel, iterations=1)
close_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
close = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, close_kernel, iterations=1)

# 查找轮廓并按最大轮廓面积排序
cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = cnts[0] if len(cnts) == 2 else cnts[1]
cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
for c in cnts:
cv2.drawContours(original, [c], -1, (36,255,12), 3)
break

cv2.imshow(&quot;bg_removed&quot;, bg_removed)
cv2.imshow(&quot;hsv_mask&quot;, hsv_mask)
cv2.imshow(&#39;isolated&#39;,isolated)
cv2.imshow(&#39;original&#39;,original)
cv2.waitKey()
]]></description>
      <guid>https://stackoverflow.com/questions/78605533/how-to-detect-and-identify-objects-in-the-order-that-they-are-on-top-then-layer</guid>
      <pubDate>Tue, 11 Jun 2024 05:23:24 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Pytorch 中手动对某一层的输出进行反量化，并为下一层重新量化？</title>
      <link>https://stackoverflow.com/questions/78239906/how-to-manually-dequantize-the-output-of-a-layer-and-requantize-it-for-the-next</link>
      <description><![CDATA[我正在做一个学校项目，需要我对模型的每一层进行手动量化。具体来说，我想手动实现：

量化激活，结合量化权重 A - 层 A -
量化输出 - 去量化输出 - 重新量化输出，结合量化权重 B - 层 B - ...

我知道 Pytorch 已经有一个量化函数，但该函数仅限于 int8。我想执行从 bit = 16 到 bit = 2 的量化，然后比较它们的准确性。
我遇到的问题是，量化后，层的输出大了几个量级（bit = 16），我不知道如何将其去量化。我正在使用激活和权重的相同最小值和最大值执行量化。因此，这里有一个例子：
激活 = [1,2,3,4]
权重 = [5,6,7,8]
激活和权重的最小值和最大值 = 1, 8
预期的非量化输出 = 70

使用位量化 = 16
量化激活 = [-32768, -23406, -14044, -4681]
量化权重 = [4681, 14043, 23405, 32767]
量化输出 = -964159613
使用最小值 = 1、最大值 = 8 反量化输出 = -102980

这个计算对我来说很有意义，因为输出涉及激活和权重的乘积，它们的幅度增加也相乘。如果我使用原始的最小值和最大值执行一次反量化，则输出会大得多，这是合理的。
Pytorch 如何处理反量化？我试图找到 Pytorch 的量化，但找不到它。如何对输出进行反量化？]]></description>
      <guid>https://stackoverflow.com/questions/78239906/how-to-manually-dequantize-the-output-of-a-layer-and-requantize-it-for-the-next</guid>
      <pubDate>Thu, 28 Mar 2024 17:17:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 中使用 opencv 计算车辆数量？</title>
      <link>https://stackoverflow.com/questions/58628229/how-to-count-vehicles-using-opencv-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/58628229/how-to-count-vehicles-using-opencv-in-python</guid>
      <pubDate>Wed, 30 Oct 2019 15:00:11 GMT</pubDate>
    </item>
    </channel>
</rss>