<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 15 Aug 2024 15:15:37 GMT</lastBuildDate>
    <item>
      <title>迁移学习预训练模型</title>
      <link>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</link>
      <description><![CDATA[我目前正在 Google Colab 上拟合迁移学习模型。但是，我在代码中遇到了一条警告消息
Epoch 1/30
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121：UserWarning：您的 PyDataset 类应在其构造函数中调用 super().__init__(**kwargs)。**kwargs 可以包括 workers、use_multiprocessing、max_queue_size。请勿将这些参数传递给 fit()，因为它们将被忽略。
self._warn_if_super_not_called()
在第一个 epoch 之后，我收到以下错误：

KeyboardInterrupt Traceback（最近一次调用最后一次）
in &lt;cell line: 16&gt;()
14 # 拟合模型
15 # 运行单元。执行需要一些时间
---&gt; 16 training_history = model_efficientnet.fit(
17 training_set,
18 validation_data=validate_set,
值得一提的是，我已经成功地拟合了其他六个迁移学习模型，没有任何问题，而且它们的准确度令人满意。
我将不胜感激任何有关如何解决此问题的指导或建议。
谢谢！
我希望获得训练准确度和验证准确度]]></description>
      <guid>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</guid>
      <pubDate>Thu, 15 Aug 2024 14:49:45 GMT</pubDate>
    </item>
    <item>
      <title>我对神经网络回归模型结果的解释</title>
      <link>https://stackoverflow.com/questions/78874398/interpretation-of-my-result-of-the-neural-network-regression-model</link>
      <description><![CDATA[我自定义的网络使用线性层，中间有 dropout 层。我知道在评估阶段，dropout 层不活跃，这通常会导致验证损失高于训练损失。为了更好地理解损失值，我计算了训练损失和验证损失之间的平均绝对差。是否有针对这种差异的一般规则或指导方针可用于改进我的模型？
我也使用此设置进行训练
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=lr)
scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=&#39;min&#39;)

计算绝对差异（距离）：
fold_dist_rmse = np.mean(np.abs(np.subtract(fold_train_losses, fold_val_losses)))
fold_dist_r2 = np.mean(np.abs(np.subtract(fold_train_r2, fold_val_r2)))

这是我的结果模型：
折叠 1/6：训练 RMSE：35.93554242793712 | 有效 RMSE：29.25876541711503 | 距离：6.769316131166423
折叠 1/6：训练 $R^2$：0.9707746378183365 | 有效 $R^2$：0.9887450106143951 | 距离：0.01803360450267792
折叠 2/6：训练 RMSE：33.979019073410804 | 有效 RMSE：37.212038090521546 |距离：6.741708392705943
折叠 2/6：训练 $R^2$：0.9723036136627198 | 有效 $R^2$：0.9756944441795349 | 距离：0.01469032382965088
折叠 3/6：训练 RMSE：32.49953081599383 | 有效 RMSE：42.565526526587355 | 距离：12.88033462681533
折叠 3/6：训练 $R^2$：0.9757700593471527 |有效 $R^2$：0.9610446383953094 | 距离：0.03205667233467102
折叠 4/6：训练 RMSE：32.936544826006646 | 有效 RMSE：55.71217012745017 | 距离：25.01426354134579
折叠 4/6：训练 $R^2$：0.9724288802146912 | 有效 $R^2$：0.9643870314359665 |距离：0.024146793484687804
我正在寻找某人来解释训练和验证损失之间的平均绝对差异是否是分析我的模型的良好指标。此外，我非常感谢任何有关如何改进我的模型以实现 RMSE 低于 10 的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78874398/interpretation-of-my-result-of-the-neural-network-regression-model</guid>
      <pubDate>Thu, 15 Aug 2024 09:12:26 GMT</pubDate>
    </item>
    <item>
      <title>如何将带有自定义二进制分类头的“transformers.TFRobertaForSequenceClassification”放入没有新层的“tensorflow.keras.Model”中？</title>
      <link>https://stackoverflow.com/questions/78874099/how-to-put-transformers-tfrobertaforsequenceclassification-with-custom-binary</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78874099/how-to-put-transformers-tfrobertaforsequenceclassification-with-custom-binary</guid>
      <pubDate>Thu, 15 Aug 2024 07:41:56 GMT</pubDate>
    </item>
    <item>
      <title>ML 项目想法（机器学习中的推荐系统项目是否仍然值得做？在这样的项目中可以展示什么新颖之处？[关闭]</title>
      <link>https://stackoverflow.com/questions/78873904/ml-project-idea-are-recommender-systems-project-in-machine-learning-still-worth</link>
      <description><![CDATA[我目前是 B.Tech 的三年级学生，我必须为机器学习方法课程做一个小项目。我选择了推荐系统作为标题，但我怀疑在当今技术时代是否值得做这个？如果不值得，您有什么建议，可以学习并发展自己以将其添加到简历中的最佳项目创意。
我看到许多代码库都写了代码但没什么有趣的，我想听听您关于在这样的项目中可以引入哪些新奇事物的意见。]]></description>
      <guid>https://stackoverflow.com/questions/78873904/ml-project-idea-are-recommender-systems-project-in-machine-learning-still-worth</guid>
      <pubDate>Thu, 15 Aug 2024 06:39:08 GMT</pubDate>
    </item>
    <item>
      <title>对列应用对数变换</title>
      <link>https://stackoverflow.com/questions/78873685/applying-log-transformation-to-a-column</link>
      <description><![CDATA[
我已使用 OneHotEncoder 对性别列进行编码。我想仅对 Female[0] 列应用对数转换，但它却对所有列都应用了对数转换 — 为什么？
我的代码：
import pandas as p
from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
from sklearn.compose import ColumnTransformer
import numpy as n

customer=p.read_csv(&#39;/content/Customers.csv&#39;)
customer.drop([&#39;CustomerID&#39;,&#39;Profession&#39;,&#39;Family Size&#39;,&#39;Work Experience&#39;],axis=1,inplace=True)
column=ColumnTransformer(
[
(&#39;ohe_gender&#39;,OneHotEncoder(sparse=False,dtype=n.int32),[0])
],remainder=&#39;passthrough&#39;
)
function=ColumnTransformer(
[
(&#39;function&#39;,FunctionTransformer(n.log1p),[0,1])
],remainder=&#39;passthrough&#39;
)
s=column.fit_transform(customer)
function.fit_transform(s)

输出：
 array([[0.00000000e+00, 6.93147181e-01, 1.90000000e+01, 1.50000000e+04, 3.90000000e+01],
[0.00000000e+00, 6.93147181e-01, 2.10000000e+01, 3.50000000e+04, 8.10000000e+01],
[6.93147181e-01, 0.00000000e+00, 2.00000000e+01, 8.60000000e+04, 6.00000000e+00],
...,
[0.00000000e+00, 6.93147181e-01, 8.70000000e+01, 9.09610000e+04, 1.40000000e+01],
[0.00000000e+00, 6.93147181e-01, 7.70000000e+01, 1.82109000e+05, 4.00000000e+00],
[0.00000000e+00, 6.93147181e-01, 9.00000000e+01, 1.10610000e+05, 5.20000000e+01]]

在 FunctionTransformer 之前进行编码 (OHE) 后，输出为
array([[ 0, 1, 19, 15000, 39],
[ 0, 1, 21, 35000, 81],
[ 1, 0, 20, 86000, 6],
...,
[ 0, 1, 87, 90961, 14],
[ 0, 1, 77, 182109, 4],
[ 0, 1, 90, 110610, 52]])

我确实想在上述数组的第 0 个索引中应用对数变换，但正如您在第一个输出中看到的那样，它应用于所有值，尽管我在列变换器中指定了 [0]，为什么？我希望输出只有 [0] 索引的对数。]]></description>
      <guid>https://stackoverflow.com/questions/78873685/applying-log-transformation-to-a-column</guid>
      <pubDate>Thu, 15 Aug 2024 04:58:50 GMT</pubDate>
    </item>
    <item>
      <title>嗨！我如何确定机器学习模型的训练和测试准确度结果是好还是坏？[关闭]</title>
      <link>https://stackoverflow.com/questions/78873404/hi-how-do-i-determine-the-train-and-test-accuracy-result-for-a-machine-learning</link>
      <description><![CDATA[我正在使用几种机器学习模型（例如 svm、ann、随机森林和 knn）对 covid 19 疫情进行预测。我很困惑如何比较哪个是准确度最高的模型，以及训练和测试准确度结果、均方误差和 r 平方。还有一个问题，训练和测试准确度结果通常首选的单位是什么？是百分比/整数还是小数点
对上述问题进行清晰解释]]></description>
      <guid>https://stackoverflow.com/questions/78873404/hi-how-do-i-determine-the-train-and-test-accuracy-result-for-a-machine-learning</guid>
      <pubDate>Thu, 15 Aug 2024 01:55:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在不使用 for 循环的情况下直接从 Claude API 对多个完成（n）进行采样？</title>
      <link>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</link>
      <description><![CDATA[我正在使用 Anthropic Claude API，并尝试在单个 API 调用中为给定的提示生成多个完成（n 个完成）。 OpenAI 的 API 在其采样设置中提供了一个 n 参数来实现这一点，但我在 Claude API 中找不到等效选项。
我目前的方法：
我目前正在使用重试机制来处理 API 调用期间的潜在错误，如下所示：
from tenacity import retry, stop_after_attempt, wait_exponential

def before_sleep(retry_state):
print(f&quot;(Tenacity) Retry, error that cause it: {retry_state.outcome.exception()}&quot;)

def retry_error_callback(retry_state):
exception = retry_state.outcome.exception()
exception_str = str(exception)
if &quot;prompt is too long&quot; in exception_str and &quot;400&quot;在 exception_str 中：
引发异常
返回“没有需要我们提前退出的错误。”

@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator, prompt: str) -&gt;; dict:
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n, # 旨在生成多个完成
stop_sequences=gen.sampling_params.stop[:3],
)
return response

问题：
我在 Anthropic API 中找不到 n 参数允许在一个请求中生成多个完成的文档。
问题：

Claude API 是否支持在单个 API 调用中直接生成多个完成（n 个完成）？
如果不支持，是否有推荐的解决方法或最佳实践来实现此目的，而无需循环多个请求？
任何指导或建议都将不胜感激！

cross discord：https://discord.com/channels/1072196207201501266/1213976011998498816/threads/1273440866861846549
cross：https://dev.to/brando90/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-loop-2m1e

现在这样做：
@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator，提示：str) -&gt; dict:
# max_tokens=8192, # Claude 3.5 的 max_tokens https://docs.anthropic.com/en/docs/about-claude/models#model-comparison
# client = anthropic.Anthropic(api_key=gen.api_key)
# response = client.messages.create(
# response_text: str = gen.llm.messages.create(
# model=gen.sampling_params.model,
# max_tokens=gen.sampling_params.max_tokens,
# #temperature=temperature, # 注意提示生成器不会将其作为输入
# system=gen.sampling_params.system,
# messages=[
# {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
# ],
#temperature=gen.sampling_params.temperature,
#top_p=gen.sampling_params.top_p,
#n=gen.sampling_params.n,
#stop=gen.sampling_params.stop[:3],
# ).content[0].text
if not hasattr(gen.sampling_params, &#39;n&#39;):
gen.sampling_params.n = 1
content: list[dict] = [] 
for _ in range(gen.sampling_params.n):
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n,
stop_sequences=gen.sampling_params.stop[:3],
)
content.append(response)
response = dict(content=content)
# 消息示例：https://docs.anthropic.com/en/api/messages-examples
返回响应
]]></description>
      <guid>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</guid>
      <pubDate>Thu, 15 Aug 2024 00:37:53 GMT</pubDate>
    </item>
    <item>
      <title>Python mediappe手部识别方块优化</title>
      <link>https://stackoverflow.com/questions/78872856/python-mediappe-hand-recognition-square-optimization</link>
      <description><![CDATA[所以 python 有 mediapupe lib，它提供了识别照片/视频上手的工具
我在我的项目中使用它。但我正在考虑优化 - 所以它会运行得更快。
我们知道，如果在 1 帧上有一只手 - 它在另一帧中不会太远 - 所以没有必要重复整个照片 - 手周围的区域就足够了（包括测量它的角速度和径向速度）
mediapype 是否包含一些优化方法？或者它只是愚蠢地让代码愚蠢地检查整张照片？
我还没有搜索过有关这方面的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78872856/python-mediappe-hand-recognition-square-optimization</guid>
      <pubDate>Wed, 14 Aug 2024 20:38:41 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用图像分类来自动检测网页是否正常显示吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78870242/can-i-use-image-classification-to-automatically-detect-if-a-web-page-is-display</link>
      <description><![CDATA[在自动化测试中，有些情况需要手动检查截图，判断页面在窗口大小改变时是否存在缺页、文字溢出等异常情况。
我想训练一个图像分类的模型来检查网页，但是我没有截断或重叠或页面丢失等情况的截图……不知道这种方式可行吗？]]></description>
      <guid>https://stackoverflow.com/questions/78870242/can-i-use-image-classification-to-automatically-detect-if-a-web-page-is-display</guid>
      <pubDate>Wed, 14 Aug 2024 09:47:18 GMT</pubDate>
    </item>
    <item>
      <title>Android 中的 Movenet Singlepose 照明模型：“不支持的图像格式：1”错误</title>
      <link>https://stackoverflow.com/questions/78636622/movenets-singlepose-lighting-model-in-android-unsupported-image-format-1-e</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78636622/movenets-singlepose-lighting-model-in-android-unsupported-image-format-1-e</guid>
      <pubDate>Tue, 18 Jun 2024 09:42:32 GMT</pubDate>
    </item>
    <item>
      <title>ML 查找四边形的角</title>
      <link>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</link>
      <description><![CDATA[我的作业是使用 ML 模型找到四边形角的 4 个点。有时四边形的一个角会丢失（例如页面的折叠角）。
首先，我尝试使用 MobileNetV3Small 作为主干进行图像分割，因为该模型应该小而快。效果很好，但找到角仍然是一个问题。我曾尝试按照官方 keras 关键点检测、中等教程和许多其他来源等示例查找图像的关键点，但似乎对我都不起作用。我尝试过多次修改它们。损失函数在测试和验证中都下降了，但输出甚至没有接近所需的位置。也尝试了类似下面的方法：
def conv(model, size, conv2d_kernel, dilation_rate=(1, 1), pooling_size=(2, 2)):
model.add(Conv2D(size, conv2d_kernel, dilation_rate=dilation_rate))
model.add(Activation(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=max_pooling))
model.add(Dropout(0.1))

def density(model, unit):
model.add(Dense(units))
model.add(Activation(&#39;relu&#39;))
model.add(Dropout(0.1))

model = Sequential()
model.add(InputLayer(shape=(224, 224, 3)))

conv(model, size=32, conv2d_kernel=(2, 2))
conv(model, size=64, conv2d_kernel=(3, 3))
conv(model, size=128, conv2d_kernel=(3, 3))

model.add(Flatten())
dense(model, 20)
dense(model, 20)

model.add(Dense(8))
model.compile(optimizer=RMSprop(),
loss=losses.MeanSquaredLogarithmicError(),
metrics=[metrics.MeanAbsoluteError()])

还尝试了输出形状 (8) 和 (4,2)，但似乎没有任何效果。任何帮助都将不胜感激。
PS：还忘记补充一点，数据集的注释是正确的，或者至少这是我在图表上看到的。还尝试将坐标标准化为 0 到 1 之间。我的输入是 (224,224,3)。]]></description>
      <guid>https://stackoverflow.com/questions/78321889/ml-find-corners-of-quadrilateral</guid>
      <pubDate>Sat, 13 Apr 2024 20:06:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SHAP 从 ML 模型中提取最重要的特征 - 为什么我的所有列名都是空的？</title>
      <link>https://stackoverflow.com/questions/72599807/how-to-extract-the-most-important-features-from-a-ml-model-using-shap-why-are</link>
      <description><![CDATA[我想使用 shap 在我的模型中找到最重要的特征。
我有这段代码：
来自 sklearn.model_selection 导入 train_test_split
来自 sklearn.datasets 导入 load_breast_cancer
来自 sklearn.ensemble 导入 RandomForestClassifier
来自 sklearn.model_selection 导入 KFold
导入 shap
导入 pandas 作为 pd
导入 numpy 作为 np

#加载和准备数据
iris = load_breast_cancer()
X = iris.data
y = iris.target
columns = iris.feature_names
#如果不进行随机排序，则不需要跟踪 test_index，但我认为
#随机排序数据始终是一种很好的做法
kf = KFold(n_splits=2,shuffle=True)

list_shap_values = list()
list_test_sets = list()
for train_index, test_index in kf.split(X):
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
X_train = pd.DataFrame(X_train,columns=columns)
X_test = pd.DataFrame(X_test,columns=columns)

#训练模型
clf = RandomForestClassifier(random_state=0)
clf.fit(X_train, y_train)

#解释模型
explainer = shap.TreeExplainer(clf)
shap_values = explainer.shap_values(X_test)
#对于每次迭代，我们保存 test_set 索引和 shap_values
list_shap_values.append(shap_values)
list_test_sets.append(test_index)

#合并所有迭代的结果
test_set = list_test_sets[0]
shap_values = np.array(list_shap_values[0])
for i in range(1,len(list_test_sets)):
test_set = np.concatenate((test_set,list_test_sets[i]),axis=0)
shap_values = np.concatenate((shap_values,np.array(list_shap_values[i])),axis=1)
#恢复变量名称
X_test = pd.DataFrame(X[test_set],columns=columns)

#为整个实验创建解释图，shap_values 中的第一个维度表示我们预测的类别（0=0， 1=1)
#shap.summary_plot(shap_values[1], X_test)

shap_sum = np.abs(shap_values).mean(axis=0)
#columns = full_X_train.columns
X_test = pd.DataFrame(X[test_set],columns=columns)
importance_df = pd.DataFrame([X_test.columns.tolist(),shap_sum.tolist()]).T
importance_df.columns = [&#39;column_name&#39;,&#39;shap_importance&#39;]
importance_df = significance_df.sort_values(&#39;shap_importance&#39;,ascending=False)
print(importance_df)

输出结果为：
390 None [0.07973283098297632, 0.012745693741197047, 0....
477 无 [0.07639585953247056, 0.012705549054148915, 0....
542 无 [0.07263038600009886, 0.004509187889530952, 0....
359 无 [0.07006782821092902, 0.008022265024270826, 0....
292 无 [0.06501143916982145, 0.014648801487419996, 0....
.. ... ...
129 无 [0.001207252383050206, 0.005154096692481416, 0...
68 无 [0.000537261423323933, 0.000554437257101772, 0...
229 无 [0.00046312350178067416, 0.0171676941721087, 0...
94 无 [0.00016002701188627102, 0.015384623641506117,...
97 无[0.0001434577248065334, 0.01162161896706629, 0...

这不正确，列名都是 None，我不清楚 shap 值是什么（我期望每列都有一个数字，按打印内容顶部最重要的特征排序 - 而不是列表）。
我希望得到更像这样的东西：
列 Shap 值
年龄 0.3
性别 0.2

有人可以告诉我我哪里出错了，以及如何使用此方法列出我的模型的重要特征吗？]]></description>
      <guid>https://stackoverflow.com/questions/72599807/how-to-extract-the-most-important-features-from-a-ml-model-using-shap-why-are</guid>
      <pubDate>Mon, 13 Jun 2022 08:28:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 shap 包获取数据框中特征的瀑布图值</title>
      <link>https://stackoverflow.com/questions/71751251/get-waterfall-plot-values-of-a-feature-in-a-dataframe-using-shap-package</link>
      <description><![CDATA[我正在研究使用随机森林模型、神经网络进行二元分类，其中使用 SHAP 来解释模型预测。我按照教程编写了以下代码来获取如下所示的瀑布图
在 Sergey Bushmanaov 的 SO 帖子此处的帮助下，我成功导出了瀑布图到数据框。但这不会复制列的特征值。它只复制 shap 值、expected_value 和特征名称。但我也想要特征名称。所以，我尝试了下面的方法
shap.waterfall_plot(shap.Explanation(values=shap_values[1])[4],base_values=explainer.expected_value[1],data=ord_test_t.iloc[4],feature_names=ord_test_t.columns.tolist())

但这引发了一个错误

TypeError: falls() 获得了一个意外的关键字参数
&#39;base_values&#39;

我希望我的输出如下所示。我使用了 1 点的背景来计算基值。但您也可以自由使用背景 1、10 或 100。在下面的输出中，我将值和特征存储在名为 Feature 的列中。这类似于 LIME。但不确定 SHAP 是否具有这种灵活性？

更新 - 绘图

更新代码 - 内核解释器瀑布图到数据框
masker = Independent(X_train, max_samples=100)
explainer = KernelExplainer(rf_boruta.predict,X_train)
bv = explainer.expected_value
sv = explainer.shap_values(X_train)

sdf_train = pd.DataFrame({
&#39;row_id&#39;: X_train.index.values.repeat(X_train.shape[1]),
&#39;feature&#39;: X_train.columns.to_list() * X_train.shape[0],
&#39;feature_value&#39;: X_train.values.flatten(),
&#39;base_value&#39;: bv,
&#39;shap_values&#39;: sv.values[:,:,1].flatten() # 我将其更改为 pd.DataFrame(sv).values[:,1].flatten()
})
]]></description>
      <guid>https://stackoverflow.com/questions/71751251/get-waterfall-plot-values-of-a-feature-in-a-dataframe-using-shap-package</guid>
      <pubDate>Tue, 05 Apr 2022 11:49:16 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow：你的输入数据不足</title>
      <link>https://stackoverflow.com/questions/59864408/tensorflowyour-input-ran-out-of-data</link>
      <description><![CDATA[我正在研究 seq2seq keras/tensorflow 2.0 模型。每次用户输入某些内容时，我的模型都会完美地打印响应。但是在每个响应的最后一行我都会得到这个：

您：警告：tensorflow：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 steps_per_epoch * epochs 个批次（在本例中为 2 个批次）。您可能需要在构建数据集时使用 repeat() 函数。

“您：”是我的最后一个输出，在用户应该输入新内容之前。该模型运行良好，但我想没有错误永远是好事，但我不太明白这个错误。它说“中断训练”，但我没有训练任何东西，这个程序加载了一个已经训练过的模型。我猜这就是为什么错误没有停止程序的原因？
如果有帮助的话，我的模型如下所示：
intent_model = keras.Sequential([
keras.layers.Dense(8, input_shape=[len(train_x[0])]), # 输入层
keras.layers.Dense(8), # 隐藏层
keras.layers.Dense(len(train_y[0]),activation=&quot;softmax&quot;), # 输出层
])

intent_model.compile(optimizer=&quot;adam&quot;, loss=&quot;categorical_crossentropy&quot;, metrics=[&quot;accuracy&quot;])
intent_model.fit(train_x, train_y, epochs=epochs)

test_loss, test_acc = intent_model.evaluate(train_x, train_y)
print(&quot;测试的 Acc:&quot;, test_acc)

intent_model.save(&quot;models/intent_model.h5&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/59864408/tensorflowyour-input-ran-out-of-data</guid>
      <pubDate>Wed, 22 Jan 2020 16:40:42 GMT</pubDate>
    </item>
    <item>
      <title>如何使 RandomForestClassifier 更快？</title>
      <link>https://stackoverflow.com/questions/43640546/how-to-make-randomforestclassifier-faster</link>
      <description><![CDATA[我正在尝试使用大约有 1M 原始数据的 Twitter 情绪数据从 kaggle 网站实现词袋模型。我已经清理了它，但在最后一部分，当我将特征向量和情绪应用于随机森林分类器时，它花费了太多时间。这是我的代码...
from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 100,verbose=3)
forest = forest.fit( train_data_features, train[&quot;Sentiment&quot;] )

train_data_features 是 1048575x5000 稀疏矩阵。我试图将其转换为数组，但执行时显示内存错误。
我哪里做错了？有人可以建议我一些来源或其他更快的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/43640546/how-to-make-randomforestclassifier-faster</guid>
      <pubDate>Wed, 26 Apr 2017 17:09:55 GMT</pubDate>
    </item>
    </channel>
</rss>