<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 15 Mar 2024 18:17:37 GMT</lastBuildDate>
    <item>
      <title>使用 LSTM 进行异常检测的重构误差计算结果不一致</title>
      <link>https://stackoverflow.com/questions/78168724/inconsistent-results-in-reconstruction-error-calculation-for-anomaly-detection-w</link>
      <description><![CDATA[我在使用 LSTM 模型进行异常检测时遇到问题。尽管对具有不同分布的不同数据集进行了训练和测试，但我注意到攻击（测试）数据的重建误差存在变化。有人可以帮助我理解为什么会出现这种差异并提出潜在的解决方案吗？
我的异常检测系统遇到问题，特别是与重建误差的计算相关的问题。我使用 TensorFlow/Keras 实现了一个基于自动编码器的异常检测模型。该模型在包含正常和异常数据样本的数据集上进行训练。
我面临的问题是，每次运行模型并计算异常数据样本的重建误差（reconstruction_error_attack）时，我都会得到不同的结果。但是，我在运行之间没有对代码或数据集进行任何更改。
以下是我正在采取的步骤的摘要：
预处理数据：使用 StandardScaler 缩放数据并将其重塑为序列。
构建自动编码器模型：我使用一个简单的基于 LSTM 的自动编码器架构。
训练模型：我在正常数据样本（df_normal）上训练自动编码器。
测试模型：我使用经过训练的自动编码器计算异常数据样本 (df_attack) 的重建误差。
每次计算异常数据样本的重建误差时，都会得到不同的结果。但是，在计算正常数据样本的重建误差（reconstruction_error_normal）时，我没有遇到这个问题。异常数据样本的重建误差是否有可能受到正常数据样本重建误差的影响？
我找不到静态的顶部和底部：dynamic_threshold_bottom、dynamic_threshold_top
我尝试根据攻击重建误差的百分位数定义动态阈值，然后识别高于和低于这些阈值的异常点。我希望将重建误差与动态阈值一起可视化，并相应地突出显示异常点。然而，得到的异常点似乎与我的预期不一致。
df_normal_scaled = scaler.fit_transform(df_normal)
df_attack_scaled = 缩放器.transform(df_attack)

# 将数据重塑为序列
def reshape_data(数据):
    返回 data.reshape(data.shape[0], 1, data.shape[1])
X_train = reshape_data(df_normal_scaled)
X_test = reshape_data(df_attack_scaled)
# 测试
defcalculate_reconstruction_error（模型，数据）：
    重建 = model.predict(data)
    误差 = np.mean(np.square(数据 - 重建), axis=(1,2))
    返回错误

Attack_reconstruction_error = 计算_reconstruction_error（自动编码器，X_test）

# 定义动态阈值
Dynamic_threshold_top = np.percentile(attack_reconstruction_error, 99)
Dynamic_threshold_bottom = np.percentile(attack_reconstruction_error, 30)
#dynamic_threshold_top = np.percentile(attack_reconstruction_error, 70)
#dynamic_threshold_bottom = np.percentile(attack_reconstruction_error, 1)
# 寻找异常点
anomaly_points_top = np.where（attack_reconstruction_error＆gt;dynamic_threshold_top）[0]
anomaly_points_bottom = np.where(attack_reconstruction_error ]]></description>
      <guid>https://stackoverflow.com/questions/78168724/inconsistent-results-in-reconstruction-error-calculation-for-anomaly-detection-w</guid>
      <pubDate>Fri, 15 Mar 2024 17:32:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在 ML 中为基于文本的数据创建管道？</title>
      <link>https://stackoverflow.com/questions/78168474/how-to-create-a-pipeline-for-text-based-data-in-ml</link>
      <description><![CDATA[我想为机器学习中基于文本的数据集编写一个管道。我不明白如何写以及用什么来获得它？
有人可以帮我解决这个问题吗？
我尝试使用普通模型
我想要这样，但它来自数字数据]]></description>
      <guid>https://stackoverflow.com/questions/78168474/how-to-create-a-pipeline-for-text-based-data-in-ml</guid>
      <pubDate>Fri, 15 Mar 2024 16:43:47 GMT</pubDate>
    </item>
    <item>
      <title>MRI 组织图像分割 [关闭]</title>
      <link>https://stackoverflow.com/questions/78167997/mri-tissue-image-segmentation</link>
      <description><![CDATA[我正在就我正在处理的一项任务寻求建议。任何提示或见解将不胜感激。您的意见可能会对我完成这项任务的方式产生很大影响。预先感谢您的帮助！
作业：
我们获得了人类受试者 T1 加权 MRI 的 10 个连续轴向横截面。任务是使用 MATLAB 文件分割出 5 个组织层。每个切片为 362x434 像素，间隔 1 毫米，覆盖 10 毫米跨度。我在下面提供了 T1 加权 MRI 的图片和标记数据。
T1 加权数据
标记数据
区域标签所在位置：
标签 0 = 空气
标签 1 = 皮肤/头皮
标签 2 = 头骨
标签 3 = 脑脊液
标签 4 = 灰色物质
标签 5 = 白色物质。
处理数据后：
我在预处理中使用了强度归一化和高斯滤波器，在分割时我尝试使用大津阈值。
我的结果
这是我使用 Otsu Thresholding 进行分割的结果。我需要另一种方法来解决这个问题。您能否告诉我需要使用哪种预处理方法以及哪种分割方法最适合此类问题？这些方法的组合也是优选的。
谢谢！
我需要另一种方法来解决这个问题。您能否告诉我需要使用哪种预处理方法以及哪种分割方法最适合此类问题？这些方法的组合也是优选的。]]></description>
      <guid>https://stackoverflow.com/questions/78167997/mri-tissue-image-segmentation</guid>
      <pubDate>Fri, 15 Mar 2024 15:23:27 GMT</pubDate>
    </item>
    <item>
      <title>连续数据的过采样</title>
      <link>https://stackoverflow.com/questions/78167792/oversampling-for-continuos-data</link>
      <description><![CDATA[有一些工具可以为我的数据帧构建合成数据吗？我没有足够的小类示例，我无法使用 SMOTE 或类似的东西，因为它们只接受离散数据
我不想让我的连续数据变得离散，但我找不到更好的选择]]></description>
      <guid>https://stackoverflow.com/questions/78167792/oversampling-for-continuos-data</guid>
      <pubDate>Fri, 15 Mar 2024 14:51:35 GMT</pubDate>
    </item>
    <item>
      <title>Fabric Notebook 在使用 TSfresh 进行特征提取时遇到错误</title>
      <link>https://stackoverflow.com/questions/78167696/fabric-notebook-running-into-error-while-using-tsfresh-for-feature-extraction</link>
      <description><![CDATA[我目前正在尝试使用 Fabric Notebooks 构建我的第一个机器学习算法，但我一直遇到一个似乎不存在答案的问题。
当我尝试调用 tsfresh 的函数 extract_features 时，我不断遇到相同的错误/警告：
“请确保通过调用 set_mlflow_env_config 将环境 EnvConfig 传递给工作人员，以便正确触发工作人员上的 mlflow。”
这特别奇怪，因为此时我什至还没有导入 mlflow
我尝试过在导入和不导入 MLflow 的情况下运行它，两者都会产生相同的结果。在文档中，我似乎找不到名为“set_mlflow_env_config”的函数我很迷失。
任何人有任何想法，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78167696/fabric-notebook-running-into-error-while-using-tsfresh-for-feature-extraction</guid>
      <pubDate>Fri, 15 Mar 2024 14:35:49 GMT</pubDate>
    </item>
    <item>
      <title>根据内容检测图像焦点区域</title>
      <link>https://stackoverflow.com/questions/78167413/detect-image-focus-area-based-on-content</link>
      <description><![CDATA[“焦点区域”定义为包含图像主题的图像区域（边界框）。它可以是任何东西，比如人、汽车、植物、艺术品等。
目前该区域是由人类选择的。给定一个包含这些边界框的大型（？50K 图像）数据集，训练某种以类似方式自动选择边界框的图像识别模型是否可行？
我对对象检测和图像分割进行了一些研究，但这两项任务似乎与我想要实现的目标非常不同。我完全天真的方法是训练具有单类“焦点区域”的对象检测模型。但我无法评估这是否是正确的方法，并且我未能找到有关此类问题的任何信息。
如果这种方法可行，那么在框架/模型/架构方面实现这种方法的最先进技术是什么。
或者是否有更好的方法/模型来完成此类任务？]]></description>
      <guid>https://stackoverflow.com/questions/78167413/detect-image-focus-area-based-on-content</guid>
      <pubDate>Fri, 15 Mar 2024 13:52:13 GMT</pubDate>
    </item>
    <item>
      <title>部分依赖图 - 使用缩放数据开发的模型，如何取消 PDP 缩放？</title>
      <link>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</link>
      <description><![CDATA[我已经用Python制作了一个随机森林分类器模型，现在想要制作部分依赖图（PDP）。我使用缩放数据来训练和测试模型，并使 PDP 如下所示：
PartialDependenceDisplay.from_estimator(best_clf, X_test_final, best_features)。但是，x 轴值经过缩放，这限制了可解释性。
在调用 PartialDependenceDisplay 之前取消缩放数据 X_test_final 不起作用，有关如何将 x 轴值从缩放更改为未缩放的任何建议？我已使用 StandardScaler() 缩放了我的数据。]]></description>
      <guid>https://stackoverflow.com/questions/78167199/partial-dependence-plot-model-developed-using-scaled-data-how-to-unscale-for</guid>
      <pubDate>Fri, 15 Mar 2024 13:15:52 GMT</pubDate>
    </item>
    <item>
      <title>将 fit_resamples 与自定义分割数据一起使用？</title>
      <link>https://stackoverflow.com/questions/78167178/use-fit-resamples-with-custom-split-data</link>
      <description><![CDATA[我有一个自定义函数，可以根据各种标准和规则将数据分成训练集和测试集。我想在 tidymodels 工作流程中与 fit_resamples 一起使用此函数。但是，当我可以使我的列表看起来像用 vfold_cv 制作的列表时，它似乎不起作用。我正在使用的示例代码：
data(ames, package = “modeldata”)

split_data &lt;- 函数(df, n) {
  set.seed(123) # 为了重现性
  df$id &lt;- seq.int(nrow(df))
  list_of_splits &lt;- list()
  
  for(i in 1:n) {
    train_index &lt;- 样本(df$id, size=ceiling(nrow(df)*.8))
    train_set &lt;- df[train_index,]
    test_set &lt;- df[-train_index,]
    list_of_splits[[i]] &lt;- list(train_set = train_set, test_set = test_set)
  }
  
  返回（分割列表）
}

分割 &lt;- split_data(ames, 5)

重新采样 &lt;- map(splits, ~rsample::make_splits(
  x = .$train_set |&gt;选择(colnames(.$test_set)),
  评估=.$test_set
））

名称（重新采样）&lt;-paste0（“折叠”，seq_along（重新采样））

重新采样 &lt;- tibble::tibble(splits = 重新采样,
                            id = 名称（重新采样））

lm_model &lt;-
  Linear_reg() %&gt;%
  set_engine(“lm”)

lm_wflow &lt;-
  工作流程() %&gt;%
  add_model(lm_model) %&gt;%
  add_formula(Sale_Price ~ 经度 + 纬度)

res &lt;- lm_wflow %&gt;%
  fit_resamples（重新采样=重新采样）

运行最后一行后返回的错误是：
`check_rset()` 中出现错误：
！ “resamples”参数应该是一个“rset”对象，例如由“vfold_cv()”或其他“rsample”函数生成的类型。

如果我尝试强制该类“rset” class(resamples) &lt;- “rset”，列表看起来不再正确，我得到了相同的错误。
使用自定义交叉折叠数据集的正确方法是什么？
注意 - 附加问题：在上面的示例代码中，测试集和训练集的大小在折叠中是一致的。在我的实际数据中，这会略有不同 - 这有关系吗？
基于以下答案的解决方案：
data(ames, package = “modeldata”)

split_data &lt;- 函数(df, n) {
  set.seed(123) # 为了重现性
  df$id &lt;- seq.int(nrow(df))
  list_of_splits &lt;- list()
  
  for(i in 1:n) {
    train_index &lt;- 样本(df$id, size=ceiling(nrow(df)*.8))
    train_set &lt;- df[train_index,]
    test_set &lt;- df[-train_index,]
    list_of_splits[[i]] &lt;- list(train_set = train_set, test_set = test_set)
  }
  
  返回（分割列表）
}

分割 &lt;- split_data(ames, 5)

重新采样 &lt;- map(splits, ~list(
  分析 = .$train_set |&gt;选择(colnames(.$test_set)) |&gt;拉（id），
  评估 = .$test_set$id
））

splits &lt;- lapply（重新采样，make_splits，数据= ames）

Final_split &lt;- Manual_rset(splits, Paste(“Split”, seq(1:5)))

lm_model &lt;-
  Linear_reg() %&gt;%
  set_engine(“lm”)

lm_wflow &lt;-
  工作流程() %&gt;%
  add_model(lm_model) %&gt;%
  add_formula(Sale_Price ~ 经度 + 纬度)

res &lt;- lm_wflow %&gt;%
  fit_resamples（重新采样= Final_split）

收集指标（res）
]]></description>
      <guid>https://stackoverflow.com/questions/78167178/use-fit-resamples-with-custom-split-data</guid>
      <pubDate>Fri, 15 Mar 2024 13:11:15 GMT</pubDate>
    </item>
    <item>
      <title>将图像转换为字符串[关闭]</title>
      <link>https://stackoverflow.com/questions/78164594/image-into-string</link>
      <description><![CDATA[从一组特定图像中提取文本的最佳方法是什么？
我做了一些研究，发现 tesseract 不能处理未扫描的文本。
也就是说，解决问题的最佳方法是通过神经网络，对吧？
是否有预先训练的模型可以根据我的特定图像类型令人满意地提取文本？
或者最好的方法是使用仅包含此类图像的数据集从头开始训练神经网络？
我忘了提到，在实现系统时没有互联网连接，所以我必须在本地运行模型。
我附上了一个示例图像，我需要从中提取文本。
我还没有尝试过任何东西，我坚持这个想法。
]]></description>
      <guid>https://stackoverflow.com/questions/78164594/image-into-string</guid>
      <pubDate>Fri, 15 Mar 2024 03:55:39 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习预测未来股票价格[关闭]</title>
      <link>https://stackoverflow.com/questions/78163298/predicting-future-stock-prices-using-machine-learning</link>
      <description><![CDATA[我正在尝试用 python 训练机器学习模型（xgb）来预测股票价格。我首先获取股票价格，然后计算技术指标以用作特征。然后，我将数据拆分为训练集和测试集，其中特征（modeling_df）为 X，收盘价（closes）为 Y。
我的问题是，我不确定该模型实际上是根据过去的价格来预测价格，但该模型是通过查看当前时间的特征来预测价格。我还想确保它使用“滚动窗口”，因此，如果有 30 个值，则值 11-20 应基于 0-10，而 21-30 应基于 0- 20.
如果有人知道神经网络的解决方案是否不同，那么我们也将不胜感激！
scaled_features = scaler.fit_transform(modeling_df)

X = 缩放特征
Y = 关闭

x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.05,shuffle=False)

然后我使用：
final_model = xgb.XGBRegressor(**best_params)
Final_model.fit(x_train,y_train, )

预测 = Final_model.predict(x_test)

然后我使用 matplotlib 显示它。
我尝试将整个数据集移动 10（和其他值），以尝试预测未来的 10 个数据点，但我不确定如何验证它是否确实有效。
这是我的图表（数据集没有被移动）。
烛台 + 蓝线 = 实际价格
紫色线 = 预测价格
图表：

这里有一些数据：
功能和价格（不变）：

&lt;标题&gt;

时间
Og 价格
RSI


&lt;正文&gt;

11:02
3.61
51.07


11:03
3.62
57.89


11:04
3.62
60.28


11:05
3.61
62.92



预测与原价：

&lt;标题&gt;

时间
Og 价格
预测


&lt;正文&gt;

11:02
3.6
3.61


11:03
3.61
3.62


11:04
3.61
3.62


11:05
3.61
3.61



本质上，我想确保我的模型没有使用 11:02-05 的 RSI 来预测 11:05 的值。我希望它使用 11:02-04 的值来预测 11:05 的值，以便它预测未来。]]></description>
      <guid>https://stackoverflow.com/questions/78163298/predicting-future-stock-prices-using-machine-learning</guid>
      <pubDate>Thu, 14 Mar 2024 20:30:48 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Plot 中 GBT 的值表示什么？</title>
      <link>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</link>
      <description><![CDATA[我使用 tfdf.keras.GradientBoostedTreesModel 进行二元分类，并在使用 tfdf.model_plotter.plot_model_in_colab 绘制它时，它显示了分割条件下的值：有值的节点
这个“价值”是什么？意思是？
我已经阅读了 gbt 模型和绘图仪的文档，但找不到有关此值的任何内容。]]></description>
      <guid>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</guid>
      <pubDate>Thu, 14 Mar 2024 13:26:35 GMT</pubDate>
    </item>
    <item>
      <title>在对象跟踪上使用预训练模型的问题</title>
      <link>https://stackoverflow.com/questions/78156883/problem-using-pre-trained-model-on-object-trackin</link>
      <description><![CDATA[我们正在使用 volov8-seg.pt 运行对象跟踪，效果很好。但是，当加载预训练模型（best.pt）时，系统尝试访问：没有名为“ultralytics.nn.modules.conv”的模块。该模块的源代码位于 GitHub 上，但不在 ultralytics 树中，因此 pip install ultralytics.nn.modules.conv 不起作用。任何有关如何处理此问题的想法将不胜感激。
尝试过 pip install &#39;ultralytics.nn.modules.conv。
结果：
错误：找不到满足 ultralytics.nn.modules.conv 要求的版本（来自版本：无）
错误：未找到 ultralytics.nn.modules.conv 的匹配分布]]></description>
      <guid>https://stackoverflow.com/questions/78156883/problem-using-pre-trained-model-on-object-trackin</guid>
      <pubDate>Wed, 13 Mar 2024 21:21:50 GMT</pubDate>
    </item>
    <item>
      <title>嵌入后无法将序列数据转换为 3D 张量</title>
      <link>https://stackoverflow.com/questions/78153453/failed-to-convert-sequence-data-to-a-3d-tensor-after-the-embedding</link>
      <description><![CDATA[我正在使用序列数据（RNA序列）进行分类任务，所以我想尝试CNN，我只是发现在数据编码（我使用序数编码）之后我必须将输入数据编码转换为3D 张量，我仍然不明白如何做到这一点，因此输入形状将是（batch_size，sequence_lenght，num_features）
这是我的输入数据代码：
# 用提供的字符“_”填充右侧的序列至 11420 nt
pad_list = df[&#39;Seq&#39;].str.ljust(11420,&#39;_&#39;)
# 减少过长序列的长度
pad_list = pad_list.map(lambda x: x[0:11420])
 
# 使用序数编码将核苷酸编码为整数
类别=[“A”、“C”、“G”、“U” 、“T”、“N”、“R”、“K”、“S”、“Y”、“M”、“W”、“D”、“_” ]
ordi = OrdinalEncoder(handle_unknown=“use_encoded_value”,unknown_value=15)
ordi.fit(np.array(列表(类别)).reshape(-1, 1))
 
pad_list= pad_list.map(lambda seq: ordi.transform(np.array(list(seq)).reshape(-1, 1)))
 
#将序列转换为整数列表列表而不是矩阵
sequence_input= np.array(pad_list.to_list()).reshape((len(pad_list), len(pad_list[0])))`

我真的尝试使用 cnn 模型查找此类数据的代码，但没有找到好的代码，而且我是这个领域的新手，所以我真的想了解如何在 cnn 中使用序列数据]]></description>
      <guid>https://stackoverflow.com/questions/78153453/failed-to-convert-sequence-data-to-a-3d-tensor-after-the-embedding</guid>
      <pubDate>Wed, 13 Mar 2024 11:35:10 GMT</pubDate>
    </item>
    <item>
      <title>比较两个名字的相似度并使用神经网络识别重复项</title>
      <link>https://stackoverflow.com/questions/72914328/compare-similarity-of-two-names-and-identify-duplicates-with-neural-network</link>
      <description><![CDATA[我有一个包含成对名称的数据集，它看起来像这样：
&lt;前&gt;&lt;代码&gt;ID；姓名1；姓名2
1;迈克·米勒；迈克·米勒
2；约翰·多伊；皮特·麦吉伦
3；萨拉·约翰逊；伊迪塔·约翰逊
4；约翰·莱蒙德-李·彼得；约翰·LL.彼得
5；玛塔·桑兹；玛莎桑德
6；约翰·彼得；约翰娜·彼得拉
7；乔安娜·内姆齐克；乔安娜·尼姆齐克

我有一些案例，已贴上标签。所以我手动检查它们并确定它们是否重复。这些情况下的手动判断将是：
1：是重复的
2：不重复
3：不重复
4：是重复的
5：不重复
6：不重复
7：是重复的

（第七个案例是一个具体案例，因为这里语音也参与了游戏。但这不是主要问题，我可以忽略语音。）
第一种方法是计算每对的编辑距离并将其标记为重复项，其中编辑距离例如小于或等于 2。这将导致以下输出：
1：编辑距离：2 =&gt;复制
2：编辑距离：11 =&gt;不是重复的
3：编辑距离：4 =&gt;不是重复的
4：编辑距离：8 =&gt;不是重复的
5：编辑距离：2 =&gt;复制
6：编辑距离：4 =&gt;不是重复的
7：编辑距离：2 =&gt;复制

这将是一种使用“固定”的方法。基于Levinshtein距离的算法。
现在，我想使用神经网络/机器学习来完成此任务：
我不需要神经网络来检测语义相似性，例如“医院”和“临床”。然而，我想避免 Levenshtein 距离，因为我希望 ML 算法能够检测“John Lemond-Lee Peter”。和“约翰·LL。彼得”作为潜在的重复，也不是 100% 确定。在这种情况下，编辑距离会导致相对较高的数字 (8)，因为需要添加相当多的字符。在像“约翰·彼得”这样的情况下，和“约翰娜彼得拉”编辑距离会导致较小的数字 (4)，但这实际上不是重复的，对于这种情况，我希望 ML 算法能够检测到这可能不是重复的。所以我需要 ML 算法来“学习我需要检查重复项的方式”。通过我的标签，我将作为输入给出 ML 算法我想要的方向。
我实际上认为这对于机器学习算法/神经网络来说应该是一个简单的任务，但我不确定。
如何实现神经网络来比较名称对并识别重复项，而不使用显式距离度量（例如编辑距离、欧几里德距离等）？
我认为可以将字符串转换为数字，并且神经网络可以处理它并学习根据我的标签风格检测重复项。因此不必指定距离度量。 我想到了一个人：我会把这个任务交给一个人，这个人会判断并做出决定。此人对编辑距离或任何其他数学概念一无所知。所以我只是想训练神经网络学会做人类正在做的事情。当然，每个人都是不同的，这也取决于我的标签。
（编辑：到目前为止我见过的机器学习/神经网络解决方案（例如this) 使用像 levenshtein 这样的度量作为特征输入。但正如我所说，我认为应该可以教会神经网络“学习”。 “人类判断”而不使用这样的距离度量？关于我的具有名称对的具体情况：使用编辑距离作为特征的 ML 方法有什么好处？因为它只会将这些名称对检测为具有低编辑距离的重复。因此，如果两个名称之间的编辑距离小于 x，我可以使用一个简单的算法将一对标记为重复。为什么要使用 ML，额外的好处是什么？）]]></description>
      <guid>https://stackoverflow.com/questions/72914328/compare-similarity-of-two-names-and-identify-duplicates-with-neural-network</guid>
      <pubDate>Fri, 08 Jul 2022 16:25:04 GMT</pubDate>
    </item>
    <item>
      <title>torch.transforms.normalize 中的数字是什么以及如何选择它们？</title>
      <link>https://stackoverflow.com/questions/65467621/what-are-the-numbers-in-torch-transforms-normalize-and-how-to-select-them</link>
      <description><![CDATA[我以下 一些 教程，我在 transforms 部分不断看到不同的数字，这些数字对我来说似乎相当随意
即，
transform = Transforms.Compose([transforms.ToTensor(), Transforms.Normalize((0.5,), (0.5,))])

或
transform =transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])

或
transform = 变换.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

或其他。
我想知道这些数字是从哪里出现的，以及如何知道选择正确的数字？
我即将使用 MNIST 来保持理智，但很快就会使用我自己独特的数据集，并且可能需要我自己的标准化。]]></description>
      <guid>https://stackoverflow.com/questions/65467621/what-are-the-numbers-in-torch-transforms-normalize-and-how-to-select-them</guid>
      <pubDate>Sun, 27 Dec 2020 15:57:14 GMT</pubDate>
    </item>
    </channel>
</rss>