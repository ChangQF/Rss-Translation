<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 21 Apr 2024 12:24:38 GMT</lastBuildDate>
    <item>
      <title>是否可以在微控制器上以低延迟进行音频干分离？</title>
      <link>https://stackoverflow.com/questions/78361504/is-it-possible-to-do-audio-stem-separation-on-a-microcontroller-with-low-latency</link>
      <description><![CDATA[是否可以在微控制器上以低延迟（即几秒）运行像 Demucs 这样的开源模型来执行音频干分离？
我尝试在我的电脑上运行它，3 分钟的曲目需要一分钟来处理。
像 Akai pro MPC one 或 live 这样的设备表示，它可以使用其 MPC 茎工具在几秒钟内处理一首曲目，而且它们似乎在四核 ARM 处理器上运行。
那么诀窍是什么呢？他们运行自己的超高效模型吗？
谢谢
尝试在 PC 上运行工具，以及 Lalal.ai 等在线服务，它们需要一段时间才能处理，因此不确定微控制器如何处理它。]]></description>
      <guid>https://stackoverflow.com/questions/78361504/is-it-possible-to-do-audio-stem-separation-on-a-microcontroller-with-low-latency</guid>
      <pubDate>Sun, 21 Apr 2024 12:13:31 GMT</pubDate>
    </item>
    <item>
      <title>valueerror: 层“model_2”的输入 0 与该层不兼容：预期形状=(none, 128, 128, 3)，发现形状=(1, 224, 224, 3)</title>
      <link>https://stackoverflow.com/questions/78361052/valueerror-input-0-of-layer-model-2-is-incompatible-with-the-layer-expected</link>
      <description><![CDATA[我正在尝试使用 cnn 模型和 Streamlit UI 进行疟疾检测。但它显示“valueerror：层“model_2”的输入0”的错误与层不兼容：预期形状=(无, 128, 128, 3)，发现形状=(1, 224, 224, 3)”用于预测。
错误消息：
ValueError：层“model_2”的输入 0与图层不兼容：预期形状=(无, 128, 128, 3)，发现形状=(1, 224, 224, 3)

回溯：
文件“C:\Users\HP.conda\envs\DiseasePredictionSystem\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py”，第 584 行，位于 _run_script
exec（代码，模块。字典）
文件“C:\Users\HP\Desktop\多种疾病预测系统\多种疾病 pred.py”，第 361 行，位于
结果 = malaria_model.predict(final_image)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\HP.conda\envs\DiseasePredictionSystem\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件“C:\Users\HP.conda\envs\DiseasePredictionSystem\Lib\site-packages\keras\src\layers\input_spec.py”，第 245 行，位于assert_input_compatibility 中
引发值错误（
由于我是机器学习新手，这是第一次为该项目学习 CNN，所以我不明白如何修复错误。如果有我需要学习的参考资料，请发给我。
这是我与 cnn 模型交互的 UI 
这是我用于该项目的 UI 文件。
malaria_model = tf.keras.models.load_model(r&#39;C:\Users\HP\Desktop\多种疾病预测系统\保存的模型\malaria.h5&#39;)
#疟疾预测页面
如果选择==“疟疾疾病预测”：
 #页面标题
 st.title(&#39;使用机器学习预测疟疾&#39;)
 
 IMG_大小 = 224
 def resize_rescale(图像):
      返回 tf.image.resize(图像, (IMG_SIZE, IMG_SIZE))/255.0

 uploaded_image = st.file_uploader(&quot;上传图片&quot;, type=[&quot;jpg&quot;, &quot;png&quot;, &quot;jpeg&quot;])

 如果 uploaded_image 不是 None：
# 显示上传的图片
     st.image（uploaded_image，caption =“上传的图像”，use_column_width = False）
     图像 = Image.open(上传的图像)

# 处理图像（例如，执行图像分析）

 if st.button(“PREDICT”)：
     image_array = tf.keras.preprocessing.image.img_to_array(图像)

# 将 NumPy 数组转换为 TensorFlow 张量
     张量图像 = tf.convert_to_tensor(image_array)
     张量图像 = tf.expand_dims(张量图像，轴=0)

     最终图像=调整大小重新缩放（张量图像）

     结果 = malaria_model.predict(final_image)

     如果结果[0][0] &lt; 0.5：
        st.header(“寄生虫”)
     别的：
        st.header(“未感染”)

[这是我用于该项目的参考代码文件]
(https://github.com/kanchitank /Medibuddy-Smart-Disease-Predictor/blob/main/notebooks/malaria.ipynb)]]></description>
      <guid>https://stackoverflow.com/questions/78361052/valueerror-input-0-of-layer-model-2-is-incompatible-with-the-layer-expected</guid>
      <pubDate>Sun, 21 Apr 2024 09:40:42 GMT</pubDate>
    </item>
    <item>
      <title>cross_validate 和 RocCurveDisplay 获得的 auc 值不同</title>
      <link>https://stackoverflow.com/questions/78361038/different-values-between-auc-obtained-from-cross-validate-and-roccurvedisplay</link>
      <description><![CDATA[在训练随机森林分类器后，我尝试了两种计算 AUC 分数的方法。第一个是从 cross_validate 函数获取指标：
numeric_transformer = make_pipeline(
    IterativeImputer（估计器=RandomForestRegressor（），random_state=0），
    标准定标器()
）
预处理器 = make_column_transformer(
    （数字转换器，数字列）
）


管道=管道（步骤=[
    （&#39;预处理器&#39;，预处理器），
    （&#39;clf&#39;，随机森林分类器（））
]）

得分 = {
    &#39;AUC&#39;: &#39;roc_auc&#39;,
    &#39;准确度&#39;：&#39;准确度&#39;，
    &#39;F1_SCORE&#39;: &#39;f1&#39;,
    &#39;精度&#39;：&#39;精度&#39;，
    &#39;召回&#39;：&#39;召回&#39;
}
打印（评分）

cv = 分层KFold(n_splits=5)
cv_scores_RF = cross_validate(管道, X, y, cv=cv, 评分=评分, return_estimator=True)

print(&quot;随机森林指标&quot;)
print(f&quot;AUC: {abs(cv_scores_RF[&#39;test_AUC&#39;]).mean()}&quot;)
print(f&quot;准确度: {cv_scores_RF[&#39;test_ACCURACY&#39;].mean()}&quot;)
print(f&quot;F1 SCORE: {abs(cv_scores_RF[&#39;test_F1_SCORE&#39;]).mean()}&quot;)
print(f&quot;精度: {abs(cv_scores_RF[&#39;test_PRECISION&#39;]).mean()}&quot;)
print(f&quot;RECALL: {abs(cv_scores_RF[&#39;test_RECALL&#39;]).mean()}&quot;)


通过上面的代码，我获得了 0.72 的 AUC。
然后我用函数 RocCurveDisplay 绘制了 ROC 曲线：
导入 matplotlib.pyplot 作为 plt
从 sklearn.metrics 导入 RocCurveDisplay


plt.figure(figsize=(8, 6))


tprs = []
曲线面积=[]


对于 i，枚举中的估计器（cv_scores_RF[&#39;estimator&#39;]）：
    viz = RocCurveDisplay.from_estimator(估计器, X, y, ax=plt.gca(), name=f&#39;ROC 折叠 {i+1}&#39;)
    
    roc_auc = auc(即.fpr, 即.tpr)
    aucs.append(roc_auc)

    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)
    interp_tpr[0] = 0.0
    tprs.append(interp_tpr)

mean_tpr = np.mean(tprs, 轴=0)
mean_auc = np.mean(aucs)

plt.plot(mean_fpr,mean_tpr,color=&#39;b&#39;,linestyle=&#39;--&#39;,lw=2,label=f&#39;平均ROC (AUC = {mean_auc:.2f})&#39;)

plt.xlabel(&#39;误报率&#39;)
plt.ylabel(&#39;真阳性率&#39;)
plt.title(&#39;接收器工作特性 (ROC) - RF&#39;)
plt.legend(loc=&#39;右下&#39;)

plt.show()

print(f“平均 AUC: {mean_auc:.2f}”)


但是绘制曲线，我在图中得到的 AUC 为 0.97。为什么会出现这种情况？
我期望得到类似的值，例如我将分类器更改为 SVM，也得到了不同的值。从 cross_validate 获得的指标中，我得到了 0.53 AUC，但从 RocCurveDisplay 中得到了 0.71。还尝试使用朴素贝叶斯，在这种情况下，我得到了非常相似的值，分别为 0.66 和 0.68。]]></description>
      <guid>https://stackoverflow.com/questions/78361038/different-values-between-auc-obtained-from-cross-validate-and-roccurvedisplay</guid>
      <pubDate>Sun, 21 Apr 2024 09:35:49 GMT</pubDate>
    </item>
    <item>
      <title>只有输入张量可以作为位置参数传递</title>
      <link>https://stackoverflow.com/questions/78360982/only-input-tensors-may-be-passed-as-positional-arguments</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78360982/only-input-tensors-may-be-passed-as-positional-arguments</guid>
      <pubDate>Sun, 21 Apr 2024 09:15:40 GMT</pubDate>
    </item>
    <item>
      <title>如何将我的 ML 模型从 Google Drive 集成到生产后端？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78360641/how-can-i-integrate-my-ml-model-from-google-drive-to-the-production-backend</link>
      <description><![CDATA[我遇到了一个问题，即我的模型尺寸很大，因此我使用 dvc 对其进行跟踪。现在我想直接从云平台使用它，所以我将模型推送到Google Drive。但如何不下载而直接从Google Drive使用它呢？如果没有，是否有其他免费平台可以存储模型并直接使用它们？
我尝试了 chatgpt 但失败了：
drive_link = &#39;https://drive.google.com/file/d/1ofu7smGB7D2rwce_-1Tiz4tk8Wfwjpqn/view?usp=sharing&#39;
model_path = get_file(&#39;model.h5&#39;,drive_link,cache_dir=&#39;./&#39;)
模型 = tf.keras.models.load_model(model_path)
]]></description>
      <guid>https://stackoverflow.com/questions/78360641/how-can-i-integrate-my-ml-model-from-google-drive-to-the-production-backend</guid>
      <pubDate>Sun, 21 Apr 2024 06:44:41 GMT</pubDate>
    </item>
    <item>
      <title>像宠物一样的健身功能[关闭]</title>
      <link>https://stackoverflow.com/questions/78360524/fitness-function-to-be-like-a-pet</link>
      <description><![CDATA[我想对一个应该像宠物一样行动的机器人使用强化学习。健身函数基本上是什么样子的（不需要精确的代码）？你很难衡量宠物对主人产生的感受。如果有关于这个主题的任何科学研究，如果有人能给我一个链接，那就太好了，因为我还没有发现任何东西？]]></description>
      <guid>https://stackoverflow.com/questions/78360524/fitness-function-to-be-like-a-pet</guid>
      <pubDate>Sun, 21 Apr 2024 05:42:20 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：float() 参数必须是字符串或实数，而不是“方法”[关闭]</title>
      <link>https://stackoverflow.com/questions/78360484/typeerror-float-argument-must-be-a-string-or-a-real-number-not-method</link>
      <description><![CDATA[我正在对泰坦尼克号数据集进行决策树分类。
&lt;前&gt;&lt;代码&gt;代码：
`model.fit(X_train,y_train)`
输出 ：
TypeError Traceback（最近一次调用最后一次）
〜\ AppData \ Local \ Temp \ ipykernel_19572 \ 2721349307.py 在？（）
----&gt; 1 model.fit(X_train,y_train)

c:\Users\Dell\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py 中？（估计器，*args，**kwargs）
   第1470章
   第1471章
   第1472章
   第1473章）：
-&gt;第1474章

c:\Users\Dell\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\tree\_classes.py 中？(self、X、y、sample_weight、check_input)
   1005 self：决策树分类器
   1006 拟合估计器。
   第1007章
   1008
-&gt;第1009章
   1010X，
   1011 年，
   第1012章

c:\Users\Dell\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\tree\_classes.py 中？(self、X、y、sample_weight、check_input、missing_values_in_feature_mask)
    第248章
    249 dtype=DTYPE，accept_sparse=“csc”，force_all_finite=False
...
   第2154章
   第2155章
   第2156章

类型错误：float() 参数必须是字符串或实数，而不是“方法”
输出被截断。作为可滚动元素查看或在文本编辑器中打开。调整单元格输出设置...

我期待正确的输出。]]></description>
      <guid>https://stackoverflow.com/questions/78360484/typeerror-float-argument-must-be-a-string-or-a-real-number-not-method</guid>
      <pubDate>Sun, 21 Apr 2024 05:18:20 GMT</pubDate>
    </item>
    <item>
      <title>Python-KNN预测误差和数据标准化</title>
      <link>https://stackoverflow.com/questions/78360476/python-knn-predict-error-and-data-normalization</link>
      <description><![CDATA[我是 M,L 的初学者，正在做我的第一份作业。即使在执行教程指示的所有操作时，我也无法使预测正常工作。
从 sklearn.neighbors 导入 KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=3, metric=&#39;euclidean&#39;)
knn_model.fit(train_val_process, merge_labels.label)
y_pred_knn = knn.predict(test_data_process)
准确度=metrics.accuracy_score(y_test, y_pred_knn)
print(&#39;准确度报告：&#39;, 准确度)

错误如下：
类型错误：KNeighborsClassifier.predict() 缺少 1 个必需的位置参数：&#39;X&#39;
我应该将数据均值标准化为 1 std 0。这样好吗？
from sklearn.preprocessing import StandardScaler
定标器=标准定标器()
缩放器.fit(pd.concat([train_data, val_data]))
train_data_process = pd.DataFrame(scaler.transform(train_data), columns=train_data.columns)
val_data_process = pd.DataFrame(scaler.transform(val_data), columns=val_data.columns)
train_val_process = pd.concat([train_data, val_data])
test_data_process = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns)
y_test = test_labels.label

我期待它能够预测并完成这项工作。]]></description>
      <guid>https://stackoverflow.com/questions/78360476/python-knn-predict-error-and-data-normalization</guid>
      <pubDate>Sun, 21 Apr 2024 05:13:50 GMT</pubDate>
    </item>
    <item>
      <title>如何将机器学习融入我的个人财务管理？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78360262/how-can-i-incorporate-machine-learning-into-my-personal-finance-management</link>
      <description><![CDATA[我有兴趣利用机器学习技术来优化我的个人财务管理。是否有专门为此目的而定制的现有工具、库或框架？此外，将机器学习算法应用于预算、费用跟踪、投资组合管理或个人理财风险评估等任务时，有哪些关键考虑因素或最佳实践？任何指导或建议将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78360262/how-can-i-incorporate-machine-learning-into-my-personal-finance-management</guid>
      <pubDate>Sun, 21 Apr 2024 02:55:48 GMT</pubDate>
    </item>
    <item>
      <title>多类问题的层次分类方法</title>
      <link>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</link>
      <description><![CDATA[有一个多类分类任务。我的目标是使用每父节点本地分类器 (LCPN) 方法来解决这个问题。
让我解释一下如何使用 MWE。
假设我有这个虚拟数据集：
将 numpy 导入为 np
从 sklearn.datasets 导入 make_classification
从 scipy.cluster 导入层次结构

X, y = make_classification(n_samples=1000, n_features=10, n_classes=5,
                             n_信息=4）

我想出了这些类之间的距离矩阵：
d = np.array(
[[ 0.、201.537、197.294、200.823、194.517]、
 [201.537, 0., 199.449, 202.941, 196.703],
 [197.294, 199.449, 0., 198.728, 192.354],
 [200.823, 202.941, 198.728, 0., 195.972],
[[194.517, 196.703, 192.354, 195.972, 0.]]
）

因此，我确定了类层次结构，如下所示：
hc = hierarchy.linkage(d, method=&#39;complete&#39;)

得到的树状图如下：
dendrogram = hierarchy.dendrogram(hc, labels=[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;, &#39;D&#39;, &#39;F&#39;])
树状图


我用hierarchy.to_tree()以树状结构进行说明：

我的问题：
如何按照 LCPN 方法在每个内部节点（包括根）处安装分类器，例如 DecisionTreeClassifier 或 SVM，以像在树中一样进行上图？]]></description>
      <guid>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</guid>
      <pubDate>Sat, 20 Apr 2024 14:08:05 GMT</pubDate>
    </item>
    <item>
      <title>在weka中重新采样过滤器</title>
      <link>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</link>
      <description><![CDATA[我的数据集中的数据实例数量很少。所以，我尝试了“重新采样” Weka中的过滤器可以增加数据量，从而提高模型性能。样本量百分比设置为200可以吗？因为那时我在交叉验证测试中获得了良好的相关系数。
我想知道将样本大小百分比设置为 200 时，重新采样过滤器是否工作正常。
使用此过滤器后，我的模型会准确预测吗？
由于数据量较少，是否有其他增强方法可以增强模型的性能？]]></description>
      <guid>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</guid>
      <pubDate>Sat, 20 Apr 2024 04:29:50 GMT</pubDate>
    </item>
    <item>
      <title>我尝试运行遗传算法来优化 ANN keras 模型的超参数。但我遇到很多错误</title>
      <link>https://stackoverflow.com/questions/78340561/i-try-to-run-genetic-algorithm-for-optimize-hyperparameters-of-ann-keras-model</link>
      <description><![CDATA[我正在尝试使用遗传算法优化我的 ANN 模型。我写的代码是：
# 创建模型的函数，KerasClassifier 所需
def create_model():
 # 创建模型
 模型=顺序（）
 model.add(Dense( 6, input_shape = (29,) , 激活 = &#39;relu&#39;, kernel_initializer = &#39;uniform&#39;))
 model.add(Dense(6, 激活 = &#39;relu&#39;, kernel_initializer = &#39;uniform&#39;))
 model.add(Dense(1, 激活=&#39;sigmoid&#39;, kernel_initializer = &#39;uniform&#39;))
# 编译模型
 model.compile（损失=&#39;binary_crossentropy&#39;，优化器=&#39;Adam&#39;，指标=[&#39;准确性&#39;]）
 返回模型

# 创建模型
模型= KerasClassifier（模型= create_model，详细= 0）

param_grid = {&#39;activation&#39;: [&quot;logistic&quot;, &quot;relu&quot;, &quot;Tanh&quot;],
              &#39;hidden_​​layer_sizes&#39;: [(50,),(100,), (50,70), (100,70), (100,100)],
              &#39;learning_rate&#39;: [&#39;常量&#39;,&#39;invscaling&#39;,&#39;自适应&#39;],
              }

cv = StratifiedKFold(n_splits=3, shuffle=True)

evolved_estimator = GASearchCV(估计器=模型，
                               简历=简历，
                               评分=&#39;准确率&#39;,
                               人口规模=10，
                               世代=35，
                               锦标赛大小=3，
                               精英主义=正确的，
                               交叉概率=0.8，
                               突变概率=0.1，
                               参数网格=参数网格，
                               标准=&#39;最大&#39;，
                               算法=&#39;eaMuPlusLambda&#39;,
                               n_工作=-1，
                               详细=真，
                               keep_top_k=4)

但是当运行它时，会显示：
ValueError：激活必须是整数、分类或连续类的有效实例
我尝试修复此错误。
经过搜索，我发现可以这样写（虽然我必须更改hidden_​​layer_sizes参数）：
param_grid = {&#39;activation&#39;: Categorical([&quot;logistic&quot;, &quot;relu&quot;, &quot;Tanh&quot;]),
              &#39;hidden_​​layer_sizes&#39;：整数（50,100），
              &#39;learning_rate&#39;：分类（[&#39;常量&#39;，&#39;invscaling&#39;，&#39;自适应&#39;]），
              }

cv = StratifiedKFold(n_splits=3, shuffle=True)

evolved_estimator = GASearchCV(估计器=模型，
                               简历=简历，
                               评分=&#39;准确率&#39;,
                               人口规模=10，
                               世代=35，
                               锦标赛大小=3，
                               精英主义=正确的，
                               交叉概率=0.8，
                               突变概率=0.1，
                               参数网格=参数网格，
                               标准=&#39;最大&#39;，
                               算法=&#39;eaMuPlusLambda&#39;,
                               n_工作=-1，
                               详细=真，
                               keep_top_k=4)

这部分代码被执行了。但是当我尝试在训练数据上拟合优化模型时，它给了我这个错误：
GA_result =volved_estimator.fit(x_train, y_train)

ValueError：估计器 KerasClassifier 的参数激活无效。通过在 KerasClassifier 构造函数中设置此参数可能可以解决此问题：KerasClassifier(activation=Tanh) 使用 estimator.get_params().keys() 检查可用参数列表
我真的很困惑。谁能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/78340561/i-try-to-run-genetic-algorithm-for-optimize-hyperparameters-of-ann-keras-model</guid>
      <pubDate>Wed, 17 Apr 2024 11:14:52 GMT</pubDate>
    </item>
    <item>
      <title>当我一次读取 3 个或更多 rtsp 流时，OpenCV VideoCapture 出现灰屏</title>
      <link>https://stackoverflow.com/questions/76736531/opencv-videocapture-gives-me-a-gray-screen-when-im-reading-from-3-or-more-rtsp</link>
      <description><![CDATA[我正在 LAN 网络上读取 rtsp 流。当它是单个或 2 个流时，它运行平稳，但当我在 2 个以上的流上尝试它时，它开始给我一个灰色的屏幕，其中几乎没有可见的像素。
cap = cv2.VideoCapture(rtsp_uri)
cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)

fps = cap.get(cv2.CAP_PROP_FPS)
每帧后延迟 = 1/fps
打印（每个帧后延迟）

而真实：
    尝试：
        ret, 框架 = cap.read()
    除了：
        经过

    如果 self.stopper[camera_id]:
        del self.stopper[camera_id]
        返回

    如果不转：
        继续

    帧 = cv2.cvtColor(src=frame, 代码=cv2.COLOR_BGR2RGB)
    框架= cv2.调整大小（
        框架，
        (self.config.frame_width, self.config.frame_height)
    ）
    队列.入队（帧）
    time.sleep(delay_after_each_frame)

这里我使用队列来存储帧，并且该脚本在线程中运行。
有什么方法可以让我一次从多个摄像机读取流而没有那些灰色帧。
这是我得到的框架。

用于多个流和输出的代码。
self.config.get_camera_ids() 中的camera_id：
    如果camera_id不在self.threads中：
        self.threads[camera_id] = 线程(
            目标=self.process_rtsp_stream，
            args=(self.config.get_rtsp(camera_id),
                    self.queues[camera_id],camera_id)
        ）
        self.threads[camera_id].daemon = True
        self.threads[camera_id].start()

# 删除已删除相机的线程
对于 self.threads 中的camera_id：
    如果camera_id不在self.config.get_camera_ids()中：
        del self.threads[camera_id]
]]></description>
      <guid>https://stackoverflow.com/questions/76736531/opencv-videocapture-gives-me-a-gray-screen-when-im-reading-from-3-or-more-rtsp</guid>
      <pubDate>Fri, 21 Jul 2023 08:58:28 GMT</pubDate>
    </item>
    <item>
      <title>使用 ffmpeg 或 Python 从视频中删除随机背景</title>
      <link>https://stackoverflow.com/questions/55916977/remove-random-background-from-video-using-ffmpeg-or-python</link>
      <description><![CDATA[我想使用 ffmpeg 或 Python 从某人的视频中删除背景。如果我在任何地方录制视频，请检测视频中的人，然后删除除该人之外的所有内容。不要求绿色或单色背景，因为这可以通过色度键来完成，我不寻找这样的背景。
我已经尝试过这个（https:// tryolabs.com/blog/2018/04/17/announcing-luminoth-0-1/）方法，但它给了我矩形框的输出。由于要探索的区域足够窄，因此它提供了足够的信息，但仍然需要消除总体背景。
我还尝试了 grabcut (https: //docs.opencv.org/4.1.0/d8/d83/tutorial_py_grabcut.html），但需要用户交互，否则结果不太好。
我还尝试使用 ffmpeg 并找到了这个示例（http://oioiiooixiii.blogspot.com/2016/09/ffmpeg-extract-foreground-moving.html），但它需要静态图像，所以我尝试在录制视频之前拍摄背景图片一个人，但要区分背景图像和视频帧需要很多东西。
对于opencv方法，我已经尝试过了。
img = cv.imread(&#39;pic.png&#39;)
mask = np.zeros(img.shape[:2], np.uint8)
bgdModel = np.zeros((1, 65), np.float64)
fgdModel = np.zeros((1, 65), np.float64)
直角 = (39, 355, 1977, 2638)
cv.grabCut（img，掩码，矩形，bgdModel，fgdModel，5，cv.GC_INIT_WITH_RECT）
mask2 = np.where((mask==2)|(mask==0), 0, 1).astype(&#39;uint8&#39;)
img = img*mask2[:, :, np.newaxis]
plt.imshow(img)、plt.colorbar()、plt.show()

但它也消除了人的一些部分。
还尝试了 ffmpeg 方式，但效果不佳。
ffmpeg -report -y -i &quot;img.jpg&quot; -i &quot;vid.mov&quot; -filter_complex &quot;[1:v]format=yuva444p,lut=c3=128[video2withAlpha],[0:v ][video2withAlpha]blend=all_mode=difference[out]&quot; -map &quot;[out]&quot; &quot;output.mp4&quot;

我所需要的只是一个人在任何正常背景下拍摄的图像/视频，无需用户交互，例如区域选择或任何其他类似的事情。 Luminoth 有经过训练的数据，但是给出的人框不是确切的人，以便我可以删除。任何有关删除背景的帮助或指导将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/55916977/remove-random-background-from-video-using-ffmpeg-or-python</guid>
      <pubDate>Tue, 30 Apr 2019 08:39:08 GMT</pubDate>
    </item>
    <item>
      <title>在决策树 ID3 算法中选择分区背后的直觉</title>
      <link>https://stackoverflow.com/questions/36105633/intuition-behind-choosing-partition-in-decision-tree-id3-algorithm</link>
      <description><![CDATA[我试图理解机器学习中决策树分类器背后的直觉。我知道决策树中每个节点的目标是进一步划分可能标签的当前空间，以便根据该节点给定问题的答案消除尽可能多的候选标签。但这与根据最小化分区“熵”的属性选择分区有什么关系呢？其中“熵”定义如下：
H(S) = −p_1*log2(p_1) −... −p_n*log2(p_n)

和分区熵：

&lt;前&gt;&lt;代码&gt;H = q_1*H(S_1) +...+ q_m*H(S_m)

其中 H(S)：给定子集的熵
     H：分区熵
     p_i&#39;s：属于 i 类的数据比例
     q_i&#39;s：基于给定分区属于子集 i 的数据比例

此外，每个节点的“问题”是否必须是是/否问题，从而将当前标签空间分成2部分？而不是 3 个或更多子集？任何清晰的例子将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/36105633/intuition-behind-choosing-partition-in-decision-tree-id3-algorithm</guid>
      <pubDate>Sat, 19 Mar 2016 18:41:37 GMT</pubDate>
    </item>
    </channel>
</rss>