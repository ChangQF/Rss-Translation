<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Fri, 07 Mar 2025 15:18:48 GMT</lastBuildDate>
    <item>
      <title>服务器内部错误进行查询时</title>
      <link>https://stackoverflow.com/questions/79492607/server-internal-error-when-making-an-agent-query</link>
      <description><![CDATA[我试图让代理读取文件并根据他阅读的内容生成代码（我使用抹布）。
我正在收到此错误。
 （ai）user@linux-warpop：〜/代码生成$/home/home/user/code生成/ai/bin/python＆quot; ＆quot/home/用户/代码生成/main.py＆quot;
开始在JOB_ID下解析该文件0AD5F204-D3C1-4D60-94A7-E50EE2EDB112
输入提示（q退出）：读取test.py的内容并编写一个调用帖子端点以制作新项目的python脚本
发生错误，重试＃1服务器错误&#39;500内部服务器错误&#39;for URL&#39;http：// localhost：11434/api/chat&#39;
有关更多信息检查：https：//developer.mozilla.org/en-us/docs/web/http/status/500
发生错误，重试＃2服务器错误&#39;500内部服务器错误&#39;for URL&#39;http：// localhost：11434/api/chat&#39;
有关更多信息检查：https：//developer.mozilla.org/en-us/docs/web/http/status/500
发生错误，重试＃3服务器错误&#39;500内部服务器错误&#39;for URL&#39;http：// localhost：11434/api/chat&#39;
有关更多信息检查：https：//developer.mozilla.org/en-us/docs/web/http/status/500
无法处理请求，重试...
输入提示（q to退出）： 
 
我使用ollama和llama_index。
任何人都可以支持如何解决吗？
基本上URL返回错误，如果有另一个URL我可以使用，则不知道]]></description>
      <guid>https://stackoverflow.com/questions/79492607/server-internal-error-when-making-an-agent-query</guid>
      <pubDate>Fri, 07 Mar 2025 14:19:45 GMT</pubDate>
    </item>
    <item>
      <title>模型的雪花ML注册表解释性：`valueerror：模型类型<类'nontype'>在记录管道时不支持``不支持</title>
      <link>https://stackoverflow.com/questions/79490841/snowflake-ml-registry-for-model-explainability-valueerror-model-type-class</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79490841/snowflake-ml-registry-for-model-explainability-valueerror-model-type-class</guid>
      <pubDate>Thu, 06 Mar 2025 22:28:30 GMT</pubDate>
    </item>
    <item>
      <title>何时将数据集拆分为火车和测试？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79490089/when-to-split-the-dataset-into-train-and-test</link>
      <description><![CDATA[是否有“通用”订单在分配数据集进行训练和测试时减少过度拟合？获得新的DF以拆分数据时，您是第一件事吗？或者可以丢弃重复的行，创建新列，依此类推。每次分配的百分比还有一个经验法则吗？我通常这样做：80％的火车和20％的测试。使用验证时：80％的火车，10％Val和10％测试。
但是什么时候尽快分裂而不需要三次拆分？
 ps：我知道您绝不应该在分裂前算中nan，在分裂前嵌入，等等，等等。而仅从该特定数据组中归纳值。所以我们应该尽快做。]]></description>
      <guid>https://stackoverflow.com/questions/79490089/when-to-split-the-dataset-into-train-and-test</guid>
      <pubDate>Thu, 06 Mar 2025 16:43:42 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：无法生成图像嵌入：张量A（1246）的大小必须匹配张量B（77）在非辛格尔顿维度1</title>
      <link>https://stackoverflow.com/questions/79489546/runtimeerror-failed-to-generate-image-embeddings-the-size-of-tensor-a-1246-m</link>
      <description><![CDATA[我正在使用句子转换器模型来嵌入图像文件（pil ImageFile）。但是，它在标题中给出了错误。我尝试了很多事情来解决它，但无济于事。
我知道这与张量的大小有关，因此我尝试将其截断，但我做了一些研究，但找不到截断的方法，而无需更改代码。我认为可能有一个简单的解决方案，但找不到。
代码分析一个文件夹，（应该）返回其中图像的嵌入。
 将大熊猫作为pd导入
从stone_transformers导入句子词术语
导入操作系统
导入numpy作为NP
从pil导入图像，imageFile

imageFile.load_truncated_images = true

image_files = [&#39;.jpg&#39;，&#39;.jpeg&#39;，&#39;.png&#39;]

班级分析仪：

    def __init __（自我）：
        self.image_model = sencencetransformer（&#39;clip-vit-b-32＆quot）
        
    def Analyze_directory（自我，路径）：

        files_data = []
        
        使用os.scandir（路径）作为dir_iter：
            要进入dir_iter：
                尝试：
                    如果entry.is_file（）：
                        _，ext = os.path.splitext（entry.name）
                        如果在image_files中进行ext：
                            尝试：
                                使用image.open（os.path.join（path，entry.name））作为img：
                                    img.convert（“ RGB”）
                                    file_data = {
                                        ＆quot“ path＆quot”：entry.name，
                                        ＆quot“ content＆quot”：img，
                                        “类型”：“图像”
                                    }
                            除例外为E：
                                file_data = {
                                    ＆quot“ path＆quot”：entry.name，
                                    ＆quot“ content＆quot”：“”
                                    “类型”：“图像”
                                }

                        别的：
                            file_data = {
                                ＆quot“ path＆quot”：entry.name，
                                ＆quot“ content＆quot”：“”
                                “类型”：“未知”
                            }
                        
                    files_data.append（file_data）
                
                除例外为E：
                    继续
        
        df = pd.dataframe（files_data）

        嵌入= []
        对于_，在df.iterrows（）中行列：
            如果行[type; quot&#39;] ==;
                尝试：
                    img = img.resize（（224，224））
                    ＃将pil图像转换为张量
                    img_tensor = np.array（img）
                    ＃将像素值标准化为[-1，1]范围通过剪辑期望的范围
                    img_normalized =（img_tensor / 255.0 * 2.0） -  1.0
                    img_batch = np.expand_dims（img_normalized，axis = 0）
                    嵌入= self.image_model.encode（str（img_batch））。numpy（）[0]
                除例外为E：
                    提高RuntimeError（f＆quot“无法生成图像嵌入：{str（e）};）
            别的：
                ＃处理未知类型
                嵌入= np .eros（384）

            embeddings.Append（嵌入）
        
        嵌入= np.array（嵌入）
        
        返回嵌入
 
我尝试截断张量，但找不到方法。
我认为仅预处理图像可以解决它，但它没有
错误消息：
  trackback（最近的最新通话）：
  file＆quort＆lt; frozen runpy＆gt;＆quot，line 198，in _run_module_as_main
  file＆quort＆lt; frozen runpy＆gt;＆quot，line 88，in _run_code in _run_code
  file＆quot＆quot c：\ users \ ... \ src \ document_analyzer \ main.py ,, 15，in＆lt; module＆gt;
    主要的（）
    ~~~~ ^^
  file＆quot c：\ users \ ... \ src \ document_analyzer \ main.py，&#39;第6行，在main中
    folder_structure = Analyzer.Analyze_directory（路径）
  file＆quort c：\ users \ ... \ src \ document_analyzer \ andaryzer.py ,， 69，在Analyze_directory中
    提高RuntimeError（f＆quot“无法生成图像嵌入：{str（e）};）
RuntimeError：无法生成图像嵌入：张量A（1203）的大小必须匹配张量B（77）在非辛格尔顿尺寸1
 ]]></description>
      <guid>https://stackoverflow.com/questions/79489546/runtimeerror-failed-to-generate-image-embeddings-the-size-of-tensor-a-1246-m</guid>
      <pubDate>Thu, 06 Mar 2025 13:35:10 GMT</pubDate>
    </item>
    <item>
      <title>数据科学和ML [关闭]</title>
      <link>https://stackoverflow.com/questions/79489029/data-science-and-ml</link>
      <description><![CDATA[如何进行预处理和构建ML模型，该模型分析每个文件具有唯一/看不见的属性（列）的异质CSV文件，并且该模型必须动态地适应这些不同的模式以产生结果？
示例方案：
 csv 1：列=“温度”，“湿度”，“城市”→“]→目标=天气状况（例如，“下雨”。
 csv 2：columns = [销售;
期望适应任何CSV模式，跨看不见的属性，并提供有意义的预测，尽管模式可变性。 ，]]></description>
      <guid>https://stackoverflow.com/questions/79489029/data-science-and-ml</guid>
      <pubDate>Thu, 06 Mar 2025 10:35:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Python中的面部识别模型[闭合]检测实时图像，屏幕截图和下载图像之间的差异</title>
      <link>https://stackoverflow.com/questions/79488408/how-to-detect-the-differences-between-the-live-image-screenshot-and-a-downloade</link>
      <description><![CDATA[有关该项目的小信息：
该项目是一个面部识别系统，可以分析保存的图像文件和网络摄像头输入的图像。该模型检测到给定的图像是来自现场摄像头，下载的图像还是屏幕截图。它使用Insightface的面部嵌入以及图像分析技术，例如边缘检测，亮度测量和频域分析（FFT）来区分这些图像类型。该系统还根据训练有素的数据集将面部归类为已知或未知的面孔。但是，当我为文件夹中存储的屏幕快照图像提供了一条路径时，该模型无法预测为屏幕截图图像，而是将其视为实时相机图像。如何解决此错误检测？]]></description>
      <guid>https://stackoverflow.com/questions/79488408/how-to-detect-the-differences-between-the-live-image-screenshot-and-a-downloade</guid>
      <pubDate>Thu, 06 Mar 2025 06:07:37 GMT</pubDate>
    </item>
    <item>
      <title>努力从“共识游戏”纸复制结果</title>
      <link>https://stackoverflow.com/questions/79487352/struggling-to-reproduce-results-from-the-consensus-game-paper</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79487352/struggling-to-reproduce-results-from-the-consensus-game-paper</guid>
      <pubDate>Wed, 05 Mar 2025 18:18:31 GMT</pubDate>
    </item>
    <item>
      <title>MediaPipe rtlite对象检测模型中的输出层[封闭]</title>
      <link>https://stackoverflow.com/questions/79486927/output-layers-in-mediapipe-rtlite-object-detection-model</link>
      <description><![CDATA[我根据MediaPipe给出的示例示例训练了我的自定义模型： https://colab.research.google.com/github/googlesamples/mediapipe/mediapipe/blob/main/examples/customization/customization/object_ipynb#scrollto = eolnzgoafs5bs5b 。
问题：我无法理解输出的组织方式，因此我可以从解释器中获取以下方式：
  tfliteTensor *output_locations =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[0]）;
 tfliteTensor *output_classes =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[1]）;
 tfliteTensor *output_scores =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[2]）;
 tfliteTensor *output_detections =
     解释器 - ＆gt; tensor（解释器 - ＆gt; outputs（）[3]）;
 
我发现上述COLAB的自定义训练的模型只有两个输出层，其中一个介绍了4个边界盒坐标，而另一种则给出了对我没有任何意义的东西。有人请向我解释如何学习和弄清楚这一点。关于rtlite的文档尚不清楚，我迷路了。]]></description>
      <guid>https://stackoverflow.com/questions/79486927/output-layers-in-mediapipe-rtlite-object-detection-model</guid>
      <pubDate>Wed, 05 Mar 2025 15:25:16 GMT</pubDate>
    </item>
    <item>
      <title>'numpy.ndarray'对象没有属性'groupby'</title>
      <link>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</link>
      <description><![CDATA[我正在尝试使用 category_encoders.targetencoder 在Python中应用目标编码。但是，我一直遇到以下错误：
  attributeError：&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39;
 
 来自category_encoder
来自sklearn.model_selection导入train_test_split

＃目标编码的功能
encoding_cols = [&#39;等级&#39;，&#39;sub_grade&#39;，&#39;home_ownhip&#39;，&#39;verification_status&#39;， 
                 “目的”，“ application_type”，“ zipcode”]

＃火车测试拆分
x_train_cv，x_test，y_train_cv，y_test = train_test_split（x，y，test_size = 0.25，andury_state = 1）
x_train，x_test_cv，y_train，y_test_cv = train_test_split（x_train_cv，y_train_cv，test_size = 0.25，andury_state = 1）

＃初始化目标编码器
encoder = targetencoder（）

＃应用目标编码
因为我在encoding_cols中：
    x_train [i] = encoder.fit_transform（x_train [i]，y_train）＃**错误在这里发生**
    x_test_cv [i] = encoder.transform（x_test_cv [i]）
    x_test [i] = encoder.transform（x_test [i]）
 
想要成功地将目标编码应用于分类列，而不会遇到&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39; error。]]></description>
      <guid>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</guid>
      <pubDate>Tue, 04 Mar 2025 08:00:57 GMT</pubDate>
    </item>
    <item>
      <title>伯（Bertopic）将主题分配给数据框架</title>
      <link>https://stackoverflow.com/questions/74151249/bertopic-assign-topics-to-data-frame</link>
      <description><![CDATA[我已经建立了一个主题模型。
获得主题后，我如何将它们分配到数据集。
我的主要目的是将无监督的主题建模转换为监督的多标签分类问题。]]></description>
      <guid>https://stackoverflow.com/questions/74151249/bertopic-assign-topics-to-data-frame</guid>
      <pubDate>Fri, 21 Oct 2022 09:02:15 GMT</pubDate>
    </item>
    <item>
      <title>将数据集拆分为火车，并使用TensorFlow进行测试</title>
      <link>https://stackoverflow.com/questions/64848149/split-dataset-into-train-and-test-using-tensorflow</link>
      <description><![CDATA[如何使用TensorFlow洗牌并将完整的数据集分为火车和测试集？我不想使用Scikit-Learn的火车测试时间。]]></description>
      <guid>https://stackoverflow.com/questions/64848149/split-dataset-into-train-and-test-using-tensorflow</guid>
      <pubDate>Sun, 15 Nov 2020 18:20:31 GMT</pubDate>
    </item>
    <item>
      <title>线性与非线性神经网络？ [关闭]</title>
      <link>https://stackoverflow.com/questions/41244421/linear-vs-nonlinear-neural-network</link>
      <description><![CDATA[我知道如何构建非线性分​​类模型，但是我当前的问题具有连续的输出。我一直在搜索有关神经网络回归的信息，但是我遇到的只是有关 Linear 回归的信息 -   nonlinear 情况都没有。哪个很奇怪，因为为什么有人会使用神经网络来解决简单的线性回归？这不像用核弹杀死苍蝇吗？
所以我的问题是：是什么使神经网络非线性？ （隐藏层？非线性激活功能？）或我对“线性”一词有完全错误的理解。 - 线性回归可以准确地模拟比y = ax+b更复杂的数据集吗？是“线性”一词。用作“ logistic”？的对立面
（我打算使用TensorFlow，但是TensorFlow线性模型教程以二进制分类问题为例，这也无济于事。）]]></description>
      <guid>https://stackoverflow.com/questions/41244421/linear-vs-nonlinear-neural-network</guid>
      <pubDate>Tue, 20 Dec 2016 14:17:17 GMT</pubDate>
    </item>
    <item>
      <title>如何将GridSearchCV与Sklearn中的自定义估算器一起使用？</title>
      <link>https://stackoverflow.com/questions/29393739/how-to-use-gridsearchcv-with-custom-estimator-in-sklearn</link>
      <description><![CDATA[我有一个应与Sklearn API兼容的估计器。我试图使用 GridSearchCV 拟合此估算器的一个参数，但我不明白该怎么做。
这是我的代码：
 导入numpy作为NP
进口Sklearn作为SK

来自sklearn.linear_model导入linearrecression，lassolarscv，ridgecv
来自sklearn.linear_model.base导入linearclassifiermixin，sparsecoefmixin，sparesEstimator


类ELM（质估计器）：

    def __init __（self，n_nodes，link =&#39;rbf&#39;，output_function =&#39;lasso&#39;，n_jobs = 1，c = 1）：
        self.n_jobs = n_jobs
        self.n_nodes = n_nodes
        self.c = c

        如果link ==&#39;rbf&#39;：
            self.link = lambda z：np.exp（-z*z）
        elif link ==&#39;sig&#39;：
            self.link = lambda Z：1./(1 + np.exp（-z）） 
        elif link ==&#39;id&#39;：
            self.link = lambda Z：Z
        别的：
            self.link =链接

        如果output_function ==&#39;lasso&#39;：
            self.output_function = lassolarscv（cv = 10，n_jobs = self.n_jobs）
        elif output_function ==&#39;lr&#39;：
            self.output_function = linearregression（n_jobs = self.n_jobs）

        elif output_function ==&#39;ridge&#39;：
            self.output_function = ridgecv（cv = 10）

        别的：
            self.output_function = output_function

        返回 


    def H（self，x）：

        n，p = X.Shape
        xw = np.dot（x，self.w.t）
        xw = xw + np.ones（（n，1））。点（self.b.t）
        返回self.link（xw）

    def fit（self，x，y，w = none）：

        n，p = X.Shape
        self.mean_y = y.mean（）
        如果w ==无：
            self.w = np.random.uniform（-self.c，self.c，（self.n_nodes，p））
        别的：
            self.w = w

        self.b = np.random.uniform（-self.c，self.c，（self.n_nodes，1））
        self.h_train = self.h（x）
        self.output_function.fit（self.h_train，y）

        返回自我

    def预测（self，x）：
        self.h_predict = self.h（x）
        返回self.output_function.predict（self.h_predict）

    def get_params（self，deep = true）：
        返回{“ n_nodes”：self.n_nodes， 
                “链接”：self.link，
                “ output_function”：self.output_function，
                “ n_jobs”：self.n_jobs， 
                “ C”：self.c}

    def set_params（self，**参数）：
        对于参数，parameters.items（）中的值：
            setAttr（self，parameter，value）



###适合C参数### 
x = np.random.normal（0，1，（100,5））
y = x [：，1] * x [：，2] + np.random.normal（0，.1，100） 

gs = sk.grid_search.gridsearchcv（elm（n_nodes = 20，output_function =&#39;lr&#39;）， 
                                 cv = 5， 
                                 param_grid = {“ c”：np.linspace（0.0001,1,10）}，
                                 fit_params = {}）

＃gs.fit（x，y）＃错误
 ]]></description>
      <guid>https://stackoverflow.com/questions/29393739/how-to-use-gridsearchcv-with-custom-estimator-in-sklearn</guid>
      <pubDate>Wed, 01 Apr 2015 14:39:33 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec中负抽采样的概念是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/27860652/what-is-the-concept-of-negative-sampling-in-word2vec</link>
      <description><![CDATA[我正在阅读2014年论文  word2vec解释：派生Mikolov等人。
负抽采样单词 - 插入方法 （注意：直接下载链接），并引用了“否定抽样”的概念：

 Mikolov等。呈现负面采样方法作为更有效的
得出单词嵌入的方式。否定采样是基于
Skip-gram模型，实际上是在优化不同的目标。

我有一些问题理解负面采样的概念。
  httpps://arxiv.org/pdf/1402.3722v1.pd1.pdf 
任何人都可以用外行的术语解释什么是负面采样？]]></description>
      <guid>https://stackoverflow.com/questions/27860652/what-is-the-concept-of-negative-sampling-in-word2vec</guid>
      <pubDate>Fri, 09 Jan 2015 12:31:25 GMT</pubDate>
    </item>
    <item>
      <title>句子之间的语义相似性[关闭]</title>
      <link>https://stackoverflow.com/questions/2037832/semantic-similarity-between-sentences</link>
      <description><![CDATA[我正在做一个项目。我需要任何OpenSource工具或技术来找到两个句子的语义相似性，在该句子中，我将两个句子作为输入，并接收分数（即语义相似性）作为输出。有帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/2037832/semantic-similarity-between-sentences</guid>
      <pubDate>Sun, 10 Jan 2010 17:29:44 GMT</pubDate>
    </item>
    </channel>
</rss>