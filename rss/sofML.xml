<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 15 Jan 2024 18:17:33 GMT</lastBuildDate>
    <item>
      <title>需要帮助 - 检查输入时出错：期望 flatten_input 有 3 个维度，但得到形状为 (4, 1) 的数组</title>
      <link>https://stackoverflow.com/questions/77821619/need-help-error-when-checking-input-expected-flatten-input-to-have-3-dimensio</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77821619/need-help-error-when-checking-input-expected-flatten-input-to-have-3-dimensio</guid>
      <pubDate>Mon, 15 Jan 2024 18:10:17 GMT</pubDate>
    </item>
    <item>
      <title>如何快速降低因子水平？</title>
      <link>https://stackoverflow.com/questions/77821577/how-can-i-reduce-factor-levels-quickly</link>
      <description><![CDATA[我正在尝试减少具有 741 个级别的变量 (city) 的因子级别数量。这似乎需要很长时间。
库（factorMerger）

reducelevels &lt;- mergeFactors( 响应 = DF2$finalWorth, 因子 = df2$city)

绘图（reduce_levels，面板=&#39;GIC&#39;，标题=&#39;&#39;，panelGrid = FALSE）

og= cutTree(reduce_levels)

DF2$城市 = og
]]></description>
      <guid>https://stackoverflow.com/questions/77821577/how-can-i-reduce-factor-levels-quickly</guid>
      <pubDate>Mon, 15 Jan 2024 17:59:46 GMT</pubDate>
    </item>
    <item>
      <title>Python - TicTacToe 的表格 Q-Learning - 仅最后一个状态/动作对存储在 Q-Table 字典中，其值不为 0</title>
      <link>https://stackoverflow.com/questions/77821339/python-tabular-q-learning-for-tictactoe-only-the-last-state-action-pair-is-s</link>
      <description><![CDATA[我的 tictactoe 3x3 板的表格 q-learning 实现存在问题。
问题在于，只有最后一步（获胜、失败、平局）及其各自的棋盘状态存储在 q 值不是“0.0”的 q 表中。导致最后移动的所有其他状态和动作对仍然具有值“0.0”。我在下面添加了 q 表，其中显示最后一步的值为“0.2”。但之前所有的移动的值为“0.0”。这只是第一集。即使增加了剧集也不会改变任何事情。只有最后一个动作的 q 值不是“0.0”
类标记（enum.StrEnum）：
    十字＝“X”
    NAUGHT=“O”
    空=“_”


类奖励（enum.IntEnum）：
    获胜=1
    输=-1
    平局 = -0.065
    非终端 = -0.01


# Q-Learning 的常量
EPSILON = 0.1 # 探索因子
ALPHA = 0.2 # 学习率
GAMMA = 0.95 # 折扣系数

TOTAL_EPISODES = 1 # 代理将玩的游戏总数

BOARD = np.array([Mark.EMPTY] * BOARD_SIZE)

def update_q_table(board、action、reward、new_board)：
    board_key = &quot;&quot;.join(board)
    new_board_key = &quot;&quot;.join(new_board)

    旧值 = Q_TABLE_DICT.get((board_key, 操作), 0)

    如果游戏结束（新棋盘）：
        # 如果是最终状态，则无需考虑未来的奖励
        下一个最大= 0
    别的：
        # 估计最优未来值
        下一个最大=最大（
            Q_TABLE_DICT.get((new_board_key, a), 0) for a in possible_moves(new_board)
        ）

    # 使用贝尔曼方程更新当前状态-动作对的 Q 值
    q_value = old_value + ALPHA * (奖励 + GAMMA * next_max - old_value)
    Q_TABLE_DICT[(board_key, 操作)] = q_value

def train_q_learning_agent():
    对于范围内的剧集（TOTAL_EPISODES）：
        board = np.array([Mark.EMPTY] * BOARD_SIZE) # 重置板
        当前标记 = 标记.CROSS

        而不是游戏结束（棋盘）：
            # Q-学习代理 (X) 采取行动
            如果 current_mark == Mark.CROSS:
                动作=选择_动作_q_学习（板，训练=真）
                new_board = make_move_to(板、操作、当前标记)
                奖励 = get_reward(new_board, current_mark)
                打印（新板）
                update_q_table（板、操作、奖励、new_board）

            # 随机玩家 (O) 采取行动
            别的：
                动作= get_random_move（板）
                new_board = make_move_to(板、操作、当前标记)

            板=新板
            current_mark = Mark.NAUGHT 如果 current_mark == Mark.CROSS else Mark.CROSS

def Choose_action_q_learning(board, Training=True) -&gt; &gt;整数：
    如果训练且 random.uniform(0, 1) &lt;厄普西隆：
        # 探索：选择一个随机动作
        返回 np.random.choice(possible_moves(board))
    别的：
        # 利用：根据当前 Q 表选择最佳操作
        board_key = &quot;&quot;.join(board)
        q_值 = {
            动作： Q_TABLE_DICT.get((board_key, 动作), 0)
            对于 possible_moves(board) 中的操作
        }
        返回 max(q_values, key=q_values.get)

第一集的 Q-Table 字典为 json：
&lt;前&gt;&lt;代码&gt;{
    “(&#39;_________&#39;, 0)”: 0.0,
    “（&#39;XO_______&#39;，2）”：0.0，
    “(&#39;XOX____O_&#39;, 3)”: 0.0,
    “(&#39;XOXX___OO&#39;, 4)”: 0.0,
    “（&#39;XOXXXO_OO&#39;，6）”：0.2
}
]]></description>
      <guid>https://stackoverflow.com/questions/77821339/python-tabular-q-learning-for-tictactoe-only-the-last-state-action-pair-is-s</guid>
      <pubDate>Mon, 15 Jan 2024 17:10:26 GMT</pubDate>
    </item>
    <item>
      <title>如何用python分析视频</title>
      <link>https://stackoverflow.com/questions/77821244/how-to-analyze-video-with-python</link>
      <description><![CDATA[我是一名 Python 开发人员，想要创建一个应用程序，我可以在其中检测用户在执行活动时在各个点上的姿势并向其提供建议。 （即玩特定游戏）我知道游戏规则，例如如何站立和做什么。我想开发一个应用程序，用户可以上传视频，他们可以在玩游戏的不同时刻获得建议。视频时长约为 5-9 秒。如何实现此功能以及如何实现这一点。我没有机器学习经验。
我尝试使用 mediapipe 获取身体部位的坐标并尝试进行分析。但我不确定这是否是解决这个问题的正确方法。如果有关于如何实现这个使用什么等的任何建议，那就太好了。]]></description>
      <guid>https://stackoverflow.com/questions/77821244/how-to-analyze-video-with-python</guid>
      <pubDate>Mon, 15 Jan 2024 16:51:36 GMT</pubDate>
    </item>
    <item>
      <title>当尝试使用tuner.search运行GridTuner类时我遇到了问题</title>
      <link>https://stackoverflow.com/questions/77821202/when-trying-to-run-gridtuner-class-using-tuner-search-%c4%b1-am-having-problem</link>
      <description><![CDATA[`类 GridTuner(keras_tuner.GridSearch):
def init(self, hypermodel, **kwargs):
super().init（超级模型，**kwargs）
def run_Trial(self, Trial, *args, **kwargs):
    hp = 试验.超参数
    模型 = self.hypermodel.build(hp)
    返回 self.hypermodel.fit(hp, model, *args, **kwargs)
            调谐器 = GridTuner(
            构建模型，
            目标=&#39;val_loss&#39;,
            覆盖=真，
            目录=“D:\\kaggle\\working\\hyperparameters”,
            project_name=f“driams-{有机体}-{抗菌剂}”，

)
&lt;前&gt;&lt;代码&gt;tuner.search_space_summary()



            调谐器. 搜索(
                X_火车，
                y_火车，
                验证数据=（X_val，y_val），
                批量大小=128，
                纪元=100，
                类别权重=类别权重，
                回调=[提前停止(耐心=15)]

)
 best_hp =tuner.get_best_hyperparameters()[0]
        best_model =tuner.hypermodel.build(best_hp)
        best_model.summary()

所以我正在尝试运行有关超参数的试验，我遇到以下错误；
文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\streamlit\\runtime\\scriptrunner\ \script_runner.py”，第 534 行，在 \_run_script exec(code, module.__dict__) 文件“C:\\Users\\90507\\OneDrive\\Masaüstü\\demo\\app.py”，第 266 行，在\&lt;模块\&gt;; main() 文件“C:\\Users\\90507\\OneDrive\\Masaüstü\\demo\\app.py”，第 234 行，在 maintuner.search( 文件“C:\\Users\\90507”中\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py”，第 234 行，在搜索 self.on_Trial_end(Trial)文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py”，第 338 行，在 on_trial_end self.oracle.end_trial(Trial) 文件 &quot;C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner \\src\\engine\\oracle.py”，第 108 行，wrapped_func ret_val = func(\*args, \*\*kwargs) ^^^^^^^^^^^^^^^^^^ ^^^ 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\tuners\\gridsearch.txt” py”，第 318 行，在 end_Trial super().end_Trial(Trial) 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages \\keras_tuner\\src\\engine\\oracle.py”，第 108 行，wrapped_func ret_val = func(\*args, \*\*kwargs) ^^^^^^^^^^^^^^^^ ^^^^^^ 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\ \oracle.py”，第 586 行，end_Trial self.\_check_consecutive_failures() 文件“C:\\Users\\90507\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site- packages\\keras_tuner\\src\\engine\\oracle.py”，第 543 行，在 \_check_consecutive_failures 中引发 RuntimeError( ValueError: 无法将 NumPy 数组转换为张量（不支持的对象类型 NoneType）。
我尝试查看数据集内部，检查导入、库并尝试更改代码。我正在尝试这个 https://www.kaggle.com/code/ hlysine/driams-maldi-tof-classifier 代码来制作有关 ML 的 Web 应用程序，我正在使用 Streamlit。]]></description>
      <guid>https://stackoverflow.com/questions/77821202/when-trying-to-run-gridtuner-class-using-tuner-search-%c4%b1-am-having-problem</guid>
      <pubDate>Mon, 15 Jan 2024 16:43:50 GMT</pubDate>
    </item>
    <item>
      <title>RMSE 训练和 MAE 预测</title>
      <link>https://stackoverflow.com/questions/77821170/rmse-training-mae-prediction</link>
      <description><![CDATA[我想问一下，如果我使用 RMSE 损失训练梯度提升回归模型，然后使用 MAE 进行预测，我的模型会成立吗？我问这个问题是因为我这样做了，结果看起来不错，但这纯粹是偶然吗？
另一件事，使用它可能会遇到一些陷阱。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77821170/rmse-training-mae-prediction</guid>
      <pubDate>Mon, 15 Jan 2024 16:38:31 GMT</pubDate>
    </item>
    <item>
      <title>有效计算不同目标的输入梯度</title>
      <link>https://stackoverflow.com/questions/77820641/computing-input-gradients-for-different-targets-efficiently</link>
      <description><![CDATA[我正在研究一个类似于对抗性例子的问题。在我的设置中，我想根据不同类的梯度计算输入样本的梯度掩码。更具体地说，我有一个输入图像 x，并且想要计算给定目标类别为 0、1、2、... 的各个像素损失梯度。
我当前的解决方案类似于这个玩具示例：
net = torch.nn.Sequential(torch.nn.Linear(10, 10), torch.nn.ReLU(), torch.nn.Linear(10, 5))
x = 火炬.randn(1, 10)
x.requires_grad = True

y = 净值(x)
损失 = torch.nn.function.mse_loss(y, torch.tensor([0., 1., 2., 3., 4.]), 减少=&#39;无&#39;)[0]
梯度= []
对于损失中的损失：
    loss.backward(retain_graph=True)
    渐变.append(x.grad.clone().detach())
    x.grad.zero_()

由于损失目前是针对每个目标值顺序反向传播的，因此运行时间并不是很好。有没有更有效的方法来在一次向后传递中计算不同类的梯度？由于我的内存也有些有限，因此简单地复制输入示例并并行运行多次是行不通的。
我已经尝试复制输入以并行运行向后传递。不幸的是，我的 GPU 内存在此设置中受到限制。]]></description>
      <guid>https://stackoverflow.com/questions/77820641/computing-input-gradients-for-different-targets-efficiently</guid>
      <pubDate>Mon, 15 Jan 2024 15:00:00 GMT</pubDate>
    </item>
    <item>
      <title>直接从x_t获取x_0和用它按照t-1,t-2,...的顺序获取x_0有什么区别？ 。 。和 DDPM 中的 0？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77820598/what-is-the-difference-between-getting-x-0-directly-from-x-t-and-using-it-to-get</link>
      <description><![CDATA[根据DDPM，我们可以通过重新参数化技巧直接从x_t获取x_0。
利用这个 x_t, x_0 我们可以得到 x_(t-1)，对吗？
重复此操作，我们可以得到x_0。
那么，这些x_0有什么区别呢？为什么我们不直接获取x_0？]]></description>
      <guid>https://stackoverflow.com/questions/77820598/what-is-the-difference-between-getting-x-0-directly-from-x-t-and-using-it-to-get</guid>
      <pubDate>Mon, 15 Jan 2024 14:50:47 GMT</pubDate>
    </item>
    <item>
      <title>过采样产生奇怪的结果[关闭]</title>
      <link>https://stackoverflow.com/questions/77820366/oversampling-with-strange-results</link>
      <description><![CDATA[为了通过机器学习来学习不平衡数据，
使用train_test_split分离训练集和测试集
在此处输入图像描述
然后，偶然的机会，如下所示，X 和 y 首先以我创建的集合的形式进行了过采样。
我使用过采样训练集 X_train_sm 和 y_train_sm 通过 LGBMClassifier 学习了一个模型，然后使用非过采样测试集 X_test 和 y_test 评估了性能，并获得了改进的性能值。
我很好奇为什么结果是这样，以及使用这种方法是否可以。
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/77820366/oversampling-with-strange-results</guid>
      <pubDate>Mon, 15 Jan 2024 14:10:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的线性回归模型返回负 R2 分数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77820300/why-is-my-linearregression-model-returning-negative-r2-score</link>
      <description><![CDATA[我正在尝试训练一个模型来预测客户的总购买金额。这次我尝试了不同的算法，线性回归。
我的数据如下所示：https://i.stack.imgur.com/JbM9J .png
以下是进一步的步骤：
# 预处理

def preprocess_input(df):
  df = df.copy()

  #删除不必要的列
  df = df.drop(“购买日期”, axis=1)
  df = df.drop(“客户名称”, axis=1)
  df = df.drop(“客户ID”, axis=1)
# df = df.drop(“数量”, axis=1)

  #二进制编码
  df[“性别”] = df[“性别”].replace({“女”:0, “男”:1})

  #One 热门编码
  ohe = OneHotEncoder(sparse_output=False, handle_unknown=“忽略”).set_output(transform=“pandas”)
  x_cat = df.select_dtypes(include=&#39;object&#39;)
  x_encoded = ohe.fit_transform(x_cat)

  df = df.drop(“产品类别”, axis=1)
  df = pd.concat([df, x_encoded], 轴=1)

  #将 df 分割为 x 和 y
  y = df[“总购买金额”]
  X = df.drop([“总购买金额”], axis=1)

  #训练-测试分割
  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

  #缩放x
  定标器=标准定标器()
  缩放器.fit(x_train)
  x_train = pd.DataFrame(scaler.transform(x_train),index=x_train.index,columns=x_train.columns)
  x_test = pd.DataFrame(scaler.transform(x_test),index=x_test.index,columns=x_test.columns)

  返回x_train、x_test、y_train、y_test

x_train, x_test, y_train, y_test = preprocess_input(数据)

# 训练/结果

从sklearn导入线性模型
从 sklearn.metrics 导入mean_squared_error, r2_score

模型 = Linear_model.LinearRegression()
model.fit(x_train, y_train)

y_lr_train_pred = model.predict(x_train)
y_lr_test_pred = model.predict(x_test)

lr_train_mse =mean_squared_error(y_train, y_lr_train_pred)
lr_train_r2 = r2_score(y_train, y_lr_train_pred)

lr_test_mse =mean_squared_error(y_test, y_lr_test_pred)
lr_test_r2 = r2_score(y_test, y_lr_test_pred)

lr_results = pd.DataFrame([“线性回归”, lr_train_mse, lr_train_r2, lr_test_mse, lr_test_r2]).transpose()
lr_results.columns = [“方法”、“训练 MSE”、“训练 R2”、“测试 MSE”、“测试 R2”]

打印（lr_结果）

y_pred = model.predict(x_test)

_preds_df = pd.DataFrame(dict(观察=y_test, 预测=y_pred))
_preds_df.head()

但是结果是


训练 MSE：1981065.009898
训练 R2：0.015117
测试MSE：2036338.881142
测试R2：-0.021321




&lt;表类=“s-表”&gt;
&lt;标题&gt;

观察
预测


&lt;正文&gt;

5010
2575.423427


1420
2891.011360


2174
2865.481353


3470
2449.776070


3274
2748.318404




准确性和结果似乎不对，这里可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77820300/why-is-my-linearregression-model-returning-negative-r2-score</guid>
      <pubDate>Mon, 15 Jan 2024 13:59:14 GMT</pubDate>
    </item>
    <item>
      <title>哪种方法可以用于多时间序列机器学习问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77820208/which-approach-can-be-used-for-multi-time-series-machine-learning-problem</link>
      <description><![CDATA[我正在尝试结合有限元模拟来实现机器学习问题。
我有一组模拟（~5000），每个模拟都有多个时间步长（~20），对于每个时间步长，我想预测~50个节点的坐标。我使用每个节点作为观察，因此这将是一个多输出回归问题，其目标是预测每个节点的 x、y 和 z 坐标。我按节点组织数据集，因此每个节点都属于特定的时间步和特定的模拟。
在这种情况下使用的最佳模型/方法是什么？
我考虑过使用 LSTM 和多时间序列，但由于我正在处理彼此不相关的小型时间序列模拟，所以我不太确定如何实现它。这不是一个常见的预测问题，因为我只有 t=0 的信息，并且希望基于该信息构建整个时间序列。
我也研究过图神经网络，但它们主要用于分类问题，并且每个模拟的每个时间步长我都会有一个小图（约 50 个节点之间的连接）。]]></description>
      <guid>https://stackoverflow.com/questions/77820208/which-approach-can-be-used-for-multi-time-series-machine-learning-problem</guid>
      <pubDate>Mon, 15 Jan 2024 13:42:00 GMT</pubDate>
    </item>
    <item>
      <title>带有我自己的预训练模型的 Sagemaker 批处理变压器</title>
      <link>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:54:18 GMT</pubDate>
    </item>
    <item>
      <title>回溯（最近一次调用）<module> 中的 <ipython-input-45-49fddc3d53e6>，IndexError：（列表索引超出范围）</title>
      <link>https://stackoverflow.com/questions/68893169/traceback-most-recent-call-last-ipython-input-45-49fddc3d53e6-in-module-i</link>
      <description><![CDATA[我正在尝试运行此代码，但是出现错误，但我不确定该错误是由于地址文件还是其他原因造成的。
数据集文件包含子宫颈图像。
图像按其标记类别进行组织：Type_1、Type_2 和 Type_3
这是代码：
&lt;小时/&gt;
def im_multi(路径):
   尝试：
       im_stats_im_ = Image.open(路径)
       返回[路径，{&#39;size&#39;：im_stats_im_.size}]
除了：
    打印（路径）
    返回 [路径, {&#39;size&#39;: [0,0]}]

def im_stats(im_stats_df):
im_stats_d = {}
p = 池(cpu_count())
ret = p.map(im_multi, im_stats_df[&#39;路径&#39;])
对于范围内的 i(len(ret))：
    im_stats_d[ret[i][0]] = ret[i][1]
im_stats_df[&#39;size&#39;] = im_stats_df[&#39;path&#39;].map(lambda x: &#39; &#39;.join(str(s) for s in im_stats_d[x][&#39;size&#39;]))
返回im_stats_df

def get_im_cv2(路径):
img = cv2.imread(路径)
调整大小 = cv2.resize(img, (32, 32), cv2.INTER_LINEAR) #使用 cv2.resize(img, (64, 64), cv2.INTER_LINEAR)
返回[路径，已调整大小]

def normalize_image_features(路径):
IMF_d = {}
p = 池(cpu_count())
ret = p.map(get_im_cv2, 路径)
对于范围内的 i(len(ret))：
    imf_d[ret[i][0]] = ret[i][1]
回退=[]
fdata = [imf_d[f] 对于路径中的 f]
fdata = np.array(fdata, dtype=np.uint8)
fdata = fdata.transpose((0, 3, 1, 2))
fdata = fdata.astype(&#39;float32&#39;)
f 数据 = f 数据 / 255
返回fdata

#train = glob.glob(&#39;../input/train/**/*.jpg&#39;) + glob.glob(&#39;../input/additional/**/*.jpg&#39;)
train=glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\train\\Type_1\\*.jpg&#39;)
+glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\train\\Type_2\\*.jpg&#39;) +glob.glob(&#39;D:\\Test
cods\\KerasCNNClean\\data\\train\\Type_3\\*.jpg&#39;)

train = pd.DataFrame([[p.split(&#39;/&#39;)[3],p.split(&#39;/&#39;)[4],p] for p in train], columns =
[&#39;type&#39;,&#39;image&#39;,&#39;path&#39;])[::5] Kaggle 演示的 #limit
火车 = im_stats(火车)
train = train[train[&#39;size&#39;] != &#39;0 0&#39;].reset_index(drop=True) #删除损坏的图像
print(&quot;不良图像已删除&quot;)
print(&quot;加载测试数据&quot;)

train_data = normalize_image_features(train[&#39;path&#39;])
print(&quot;测试数据已加载&quot;)

#np.save（&#39;train.npy&#39;，train_data，allow_pickle = True，fix_imports = True）
np.save（r&#39;D：/测试cods/KerasCNNClean/npyTrain.train.npy&#39;，train_data，allow_pickle = True，
修复导入=真）

le = 标签编码器()
train_target = le.fit_transform(train[&#39;type&#39;].values)
print(le.classes_)

#np.save（&#39;train_target.npy&#39;，train_target，allow_pickle = True，fix_imports = True）
np.save(r&#39;D:/测试 cods/KerasCNNClean/npyTrain.train_target.npy&#39;, train_target,
允许_pickle = True，fix_imports = True）

我找不到问题所在：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
IndexError Traceback（最近一次调用最后一次）
&lt;ipython-input-46-4f89beac4d83&gt;在&lt;模块&gt;中
      1 test = glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\test\\*.jpg&#39;)
----&gt; 2 test = pd.DataFrame([[p.split(&#39;/&#39;)[3],p] for p in test], columns = [&#39;image&#39;,&#39;path&#39;]) #[::20] #limit for Kaggle 演示
      3 print(&quot;加载列车数据&quot;)
      4 test_data = normalize_image_features(测试[&#39;路径&#39;])
      5 np.save（r&#39;D：/测试cods/KerasCNNClean/npyTest.test.npy&#39;，test_data，allow_pickle = True，fix_imports = True）

&lt;ipython-input-46-4f89beac4d83&gt;在 (.0) 中
      1 test = glob.glob(&#39;D:\\Test cods\\KerasCNNClean\\data\\test\\*.jpg&#39;)
----&gt; 2 test = pd.DataFrame([[p.split(&#39;/&#39;)[3],p] for p in test], columns = [&#39;image&#39;,&#39;path&#39;]) #[::20] #limit for Kaggle 演示
      3 print(&quot;加载列车数据&quot;)
      4 test_data = normalize_image_features(测试[&#39;路径&#39;])
      5 np.save（r&#39;D：/测试cods/KerasCNNClean/npyTest.test.npy&#39;，test_data，allow_pickle = True，fix_imports = True）

IndexError：列表索引超出范围
]]></description>
      <guid>https://stackoverflow.com/questions/68893169/traceback-most-recent-call-last-ipython-input-45-49fddc3d53e6-in-module-i</guid>
      <pubDate>Mon, 23 Aug 2021 12:59:13 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 错误 - 提供分类类型时，DMatrix 参数“enable_categorical”必须设置为“True”</title>
      <link>https://stackoverflow.com/questions/67080149/xgboost-error-when-categorical-type-is-supplied-dmatrix-parameter-enable-cat</link>
      <description><![CDATA[我有四个类别特征和第五个数字特征 (Var5)。当我尝试以下代码时：
cat_attribs = [&#39;var1&#39;,&#39;var2&#39;,&#39;var3&#39;,&#39;var4&#39;]

full_pipeline = ColumnTransformer([(&#39;cat&#39;, OneHotEncoder(handle_unknown = &#39;ignore&#39;), cat_attribs)], 剩余 = &#39;passthrough&#39;)
X_train = full_pipeline.fit_transform(X_train)

模型= XGBRegressor（n_estimators = 10，max_深度= 20，详细程度= 2）
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

当模型尝试进行预测时，我收到以下错误消息：
&lt;块引用&gt;
ValueError：数据的 DataFrame.dtypes 必须是 int、float、bool 或 categorical。什么时候
提供分类类型，DMatrix 参数
enable_categorical 必须设置为 True。Var1、Var2、Var3、Var4

有人知道这里出了什么问题吗？
如果有帮助的话，这里是 X_train 数据和 y_train 数据的一个小样本：
&lt;预置&gt;&lt;代码&gt; Var1 Var2 Var3 Var4 Var5
1507856 日本 2009 6581 OME 325.787218
839624 法国 2018 5783 I_S 11.956326
1395729 2015 年 6719 OME 42.888565
1971169 DK 2011 3506 RPP 70.094146
1140120 AT 2019 5474 NMM 270.082738

和：
&lt;前&gt;&lt;代码&gt; Ind_Var
1507856 8.013558
839624 4.105559
1395729 7.830077
1971169 83.000000
1140120 51.710526
]]></description>
      <guid>https://stackoverflow.com/questions/67080149/xgboost-error-when-categorical-type-is-supplied-dmatrix-parameter-enable-cat</guid>
      <pubDate>Tue, 13 Apr 2021 18:03:12 GMT</pubDate>
    </item>
    <item>
      <title>通过机器学习提取重叠类别</title>
      <link>https://stackoverflow.com/questions/26226178/extracting-overlapping-categories-through-machine-learning</link>
      <description><![CDATA[我正在尝试获取可能重叠的产品属性。&lt;​​/p&gt;
根据标题、制造商、描述，我需要知道该产品是牛仔裤还是其他类型的牛仔裤，甚至是紧身牛仔裤还是其他类型的牛仔裤。通过 scikit-learn 练习，我似乎一次只能预测一个类别，这不适用于我的情况。关于如何解决这个问题有什么建议吗？
我现在想到的是为每个类别提供训练数据，例如：
Jeans = [&#39;牛仔裤 1 的描述&#39;, &#39;牛仔裤 2 的描述&#39;]
紧身牛仔裤 [&#39;紧身牛仔裤 1 的描述&#39;, &#39;紧身牛仔裤 2 的描述&#39;]

利用这些训练数据，我会询问给定未知产品的概率，并期望以匹配百分比的形式得到此类答案：
Unknown_Product_1 = {
    “牛仔裤”：93，
    “紧身牛仔裤”：80，
    “T 恤”：5
}

我离基地太远了吗？如果这是一条正确的道路，如果是的话，我该如何实现它？]]></description>
      <guid>https://stackoverflow.com/questions/26226178/extracting-overlapping-categories-through-machine-learning</guid>
      <pubDate>Mon, 06 Oct 2014 23:03:15 GMT</pubDate>
    </item>
    </channel>
</rss>