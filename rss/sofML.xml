<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 31 Aug 2024 18:19:15 GMT</lastBuildDate>
    <item>
      <title>（BPE）标记器不适用于具有共同开头的标记</title>
      <link>https://stackoverflow.com/questions/78935444/bpetokenizer-not-working-for-tokens-with-common-beginning</link>
      <description><![CDATA[考虑代码
from tokenizers import Tokenizer, pre_tokenizers
from tokenizers.models import BPE

tokens = [&#39;A&#39;, &#39;A+&#39;, &#39;+&#39;]

tokenizer = Tokenizer(BPE(unk_token=&quot;[UNK]&quot;,
vocab = {token: i for i, token in enumerate(tokens)}, 
merges=[(&#39;A&#39;,&#39;+&#39;)]))

tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()

encoded = tokenizer.encode(&quot;A A+&quot;)
print(encoded.tokens)

我得到 [&#39;A&#39;, &#39;A&#39;, &#39;+&#39;] 作为输出，但我想要[&#39;A&#39;, &#39;A+&#39;]。
问题在于一个标记是另一个标记的开头，因此较长的标记永远不会被识别为一个标记。我不明白为什么 merges 没有帮助。我尝试过其他标记器，例如 WordLevel，但没有成功。
换句话说，我正在寻找一个非贪婪的标记器。]]></description>
      <guid>https://stackoverflow.com/questions/78935444/bpetokenizer-not-working-for-tokens-with-common-beginning</guid>
      <pubDate>Sat, 31 Aug 2024 15:01:53 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 验证拆分导致 75% 的类别过度拟合，25% 的类别为随机噪声</title>
      <link>https://stackoverflow.com/questions/78934378/tensorflow-validation-split-leading-to-75-of-classes-overfitted-25-random-noi</link>
      <description><![CDATA[我正在执行机器学习任务，其中验证分割似乎存在数据泄漏。如果我调整分割，它会移动过度拟合的类的数量。
X_train = resize_images(X_train, (512, 512))
y_train = label_enc.transform(y_train)
n_classes = len(list(label_enc.classes_))
X_train = np.asarray(X_train)
X_train, y_train = add_extra_dim(X_train, y_train, n_classes)
model = build_model()
model.fit(X_train, y_train, epochs=50, validation_split = 0.25, callbacks=[callback])
def build_model():
model = ATCNet(shape=(100, 100, 1), n_classes=n_classes)
top3 = tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=&quot;top3&quot;)
top5 = tf.keras.metrics.TopKCategoricalAccuracy(k=5, name=&quot;top5&quot;)
model.compile(optimizer=Adam(), 
loss=&#39;categorical_crossentropy&#39;, 
metrics=[&#39;accuracy&#39;, top3, top5])
返回模型

[[输入图片描述在此输入图片描述在此描述](https://i.sstatic.net/nS2vvCJP.png)](https://i.sstatic.net/oCSLgoA4.png)
我已测试，不存在任何数据泄露。
我已将问题隔离到验证拆分，但我找不到任何有关如何修复它或我做错了什么的信息]]></description>
      <guid>https://stackoverflow.com/questions/78934378/tensorflow-validation-split-leading-to-75-of-classes-overfitted-25-random-noi</guid>
      <pubDate>Sat, 31 Aug 2024 05:41:32 GMT</pubDate>
    </item>
    <item>
      <title>transformers/LLM 与 pytorch 内存不足</title>
      <link>https://stackoverflow.com/questions/78934229/transformers-llm-with-pytorch-running-out-of-memory</link>
      <description><![CDATA[我改编了 https://pub.towardsai.net/build-your-own-large-language-model-llm-from-scratch-using-pytorch-9e9945c24858 中的转换器，用于将另一种语言翻译成我自己的两种形式语言（每种语言的词汇量为 23）。

最大输入长度约为 600，最大输出长度约为 3000，因此我选择了略大于 3000 的联合序列长度。
训练和验证的批量大小均为 1。
嵌入维度为 8，前馈维度为 32，头数为 8，块数为 6。
数据类型为 int64。

使用这些超参数，训练在我的 CPU 上使用 ~15 GiB RAM。一旦训练的批处理大小 &gt; 1，它就会尝试分配超过 40 GiB 并崩溃。因此，在 Colab 上进行免费训练是不可行的。

我做错了什么？我改编的转换器具有更大的超参数和词汇，网站声称可以在 Colab 上对其进行训练。也许其中一个原因是我的文本太长了？（我无法轻松地在测试较短的文本上进行训练，因为我的数据集不包含很多文本。）
如何减少内存占用？
]]></description>
      <guid>https://stackoverflow.com/questions/78934229/transformers-llm-with-pytorch-running-out-of-memory</guid>
      <pubDate>Sat, 31 Aug 2024 03:08:19 GMT</pubDate>
    </item>
    <item>
      <title>在 colab 上安装 nvstrings</title>
      <link>https://stackoverflow.com/questions/78933173/installing-nvstrings-on-colab</link>
      <description><![CDATA[我尝试在 Google Colab 笔记本上运行 !pip install nvstrings，但遇到了错误
收集 nvstrings
使用缓存的 nvstrings-0.6.1.post1.tar.gz (1.2 kB)
准备元数据 (setup.py) ... 完成
为收集的包构建 wheel：nvstrings
错误：subprocess-exited-with-error

× python setup.py bdist_wheel 未成功运行。
│ 退出代码：1
╰─&gt; 请参阅上面的输出。

注意：此错误源自子进程，可能不是 pip 的问题。
为 nvstrings 构建 wheel (setup.py) ... 错误
错误：为 nvstrings 构建 wheel 失败
运行 setup.py clean 以清除 nvstrings
构建 nvstrings 失败
错误：错误：无法为某些基于 pyproject.toml 的项目 (nvstrings) 构建可安装的 wheel

如何克服这个问题？
我正在使用托管在 colab 免费层 gpu 上的 spacy en_core_web_trf 开发文档解析器模型，它需要 gpu 设备上的输入字符串，即为什么我需要安装 nvstrings 库。我已经在笔记本电脑上安装了 nvidia RAPIDS 库，但它似乎不包含 nvstrings 库。]]></description>
      <guid>https://stackoverflow.com/questions/78933173/installing-nvstrings-on-colab</guid>
      <pubDate>Fri, 30 Aug 2024 17:30:48 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络在测试数据上的表现很差，但在训练数据上准确率却很高，这是什么原因造成的？</title>
      <link>https://stackoverflow.com/questions/75902400/what-can-be-the-cause-of-poor-performance-of-my-neural-network-on-testing-data</link>
      <description><![CDATA[我尝试开发一个简单的模型来解决多分类问题。我在 Kaggle 上找到了一个数据集，其中包含 25k+ 条带有文本情绪（积极、中性、消极）的推文。我处理了这些数据并提出了一个简单的网络模型。该网络在训练数据上的准确率约为 98-99%，但在测试数据上的准确率约为 60%。造成这种性能差异的原因可能是什么？我该如何优化模型以获得更好的评估性能？
代码如下：
df = pd.read_csv(&#39;Tweets.csv&#39;);

df = df.drop(columns=[&#39;textID&#39;, &#39;selected_text&#39;])

data = df[&#39;text&#39;]
labels = df[&#39;sentiment&#39;]

labels = np.unique(labels, return_inverse=True)
lookup = labels[0]
labels = labels[1]

data = np.array(data).astype(str)
tokenizer = keras_preprocessing.text.Tokenizer(num_words=10000)
tokenizer.fit_on_texts(data)
sequences = tokenizer.texts_to_sequences(data)
one_hot_results = tokenizer.texts_to_matrix(data, mode=&#39;binary&#39;)

all_tweets = one_hot_results[:20000]
all_labels =标签[:20000]

train_data = all_tweets[:10000]
test_data = all_tweets[10000:]

train_labels = all_labels[:10000]
test_labels = all_labels[10000:]

model = models.Sequential()
model.add(layers.Dense(64, 激活=&#39;relu&#39;, 输入形状=(10000, )))
model.add(layers.Dense(64, 激活=&#39;relu&#39;))
model.add(layers.Dense(3, 激活=&#39;softmax&#39;))
model.compile(优化器=&#39;rmsprop&#39;, 损失=&#39;sparse_categorical_crossentropy&#39;, 指标=[&#39;accuracy&#39;])

model.fit(train_data, train_labels, batch_size=512, epochs=20, validation_split=0.3)

test_loss, test_acc = model.evaluate(test_data, test_labels)
print(&quot;test_acc:&quot;, test_acc)

这是我的控制台输出：
Epoch 19/20
14/14 [===============================] - 0s 14ms/step - loss: 0.0423 - accuracy: 0.9903 - val_loss: 1.9351 - val_accuracy: 0.6063
Epoch 20/20
14/14 [================================] - 0s 14ms/step - loss: 0.0365 - 准确度：0.9920 - val_loss：2.0434 - val_accuracy：0.6013
313/313 [==============================] - 1s 3ms/step - 损失：1.9856 - 准确度：0.6086
test_acc：0.6086000204086304

我尝试过改变层数、层大小、批次大小、时期数，调整矢量化测试数据的词汇量，但似乎没有什么能改善评估。]]></description>
      <guid>https://stackoverflow.com/questions/75902400/what-can-be-the-cause-of-poor-performance-of-my-neural-network-on-testing-data</guid>
      <pubDate>Fri, 31 Mar 2023 20:09:00 GMT</pubDate>
    </item>
    <item>
      <title>transform 和 fit_transform 之间的区别</title>
      <link>https://stackoverflow.com/questions/65057140/difference-between-transform-and-fit-transform</link>
      <description><![CDATA[我一直在学习 Kaggle 的中级机器学习课程。在解释中，为了标记分类数据，他们使用了 sklearn.preprocessing 中的 LabelEncoder 库。

在这里，对于训练数据集，他们使用了 fit_transform，而对于验证数据集，他们只使用了 transform，为什么会这样？
此外，在处理空值时，在训练数据集中他们使用了 fit_transform，而对于验证数据集他们使用了 transform。

那么 fit_transform 和 transform 之间有什么区别，它们可以在什么情况下使用？]]></description>
      <guid>https://stackoverflow.com/questions/65057140/difference-between-transform-and-fit-transform</guid>
      <pubDate>Sun, 29 Nov 2020 04:54:52 GMT</pubDate>
    </item>
    <item>
      <title>尝试加载我的 Google 可教机器模型时出现 ValueError：('无法识别的关键字参数：'，dict_keys(['ragged']))</title>
      <link>https://stackoverflow.com/questions/63847435/valueerror-unrecognized-keyword-arguments-dict-keysragged-when-tryi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/63847435/valueerror-unrecognized-keyword-arguments-dict-keysragged-when-tryi</guid>
      <pubDate>Fri, 11 Sep 2020 12:50:45 GMT</pubDate>
    </item>
    <item>
      <title>使用 pytorch 计算特征中心时 GPU 内存不足</title>
      <link>https://stackoverflow.com/questions/63734506/the-gpu-memory-is-not-enough-when-computing-feature-centers-using-pytorch</link>
      <description><![CDATA[使用 pytorch 时，我想在损失函数中使用类特征中心。但是当我计算中心时，GPU 内存不够。我该如何解决？代码如下：
for epoch in range((args.start_epoch+1), args.epochs):
Center= computer_Center(model,dataloader, classnum)
for input, target in train_loader:
target = target.cuda()
input = input.cuda()
input_var = torch.autograd.Variable(input)
target_var = torch.autograd.Variable(target)
outputs, feature = model(input_var)
l = criterion(feature,target_var, Center) .forward()
l.backward(retain_graph=True)

def computer_Center(model,dataloader, classnum):
model.train()
for i in range(classnum):
j=0
for input,target in dataloader:
target=target.cuda()
input = input.cuda()
input_var = torch.autograd.Variable(input)
target=torch.autograd.Variable(target)
_, feature_ext = model(input_var)
ind=torch.where(target==i)[0]
if ind.shape[0]&gt;0:
if j==0:
feature_mid = feature_ext[ind, :]
feature_sum_mid=feature_mid.sum(0)
else:
feature_mid = feature_ext[ind, :]
feature_sum_mid = feature_sum_mid+feature_mid.sum(0)
j=j+1

feature_sum_mid=feature_sum_mid.unsqueeze(0)
if i==0:
feature_sum=feature_sum_mid
else:
feature_sum=torch.cat([feature_sum,feature_sum_mid],dim=0)

Center=feature_sum
for i in range(7):
Center[i,:]=feature_sum[i,:]/ClaSamNum[i]

返回中心
]]></description>
      <guid>https://stackoverflow.com/questions/63734506/the-gpu-memory-is-not-enough-when-computing-feature-centers-using-pytorch</guid>
      <pubDate>Fri, 04 Sep 2020 03:37:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在基于 TensorFlow Lite 对象检测 Android 的应用程序中添加文本转语音功能？</title>
      <link>https://stackoverflow.com/questions/62623547/how-can-i-add-text-to-speech-in-tensorflow-lite-object-detection-android-based-a</link>
      <description><![CDATA[我正在尝试构建一款应用，帮助视障人士检测路上的物体​​/障碍物。因此，一旦检测到物体，使用 TensorFlow 库和 Android 文本转语音，应用程序就会让用户知道该物体是什么。我目前正在尝试构建 TensorFlow 提供的 Android 对象检测示例，但我很难找到边界框标签字符串的存储位置，以便在运行文本转语音时调用它]]></description>
      <guid>https://stackoverflow.com/questions/62623547/how-can-i-add-text-to-speech-in-tensorflow-lite-object-detection-android-based-a</guid>
      <pubDate>Sun, 28 Jun 2020 13:59:07 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：（'无法识别的关键字参数：'，dict_keys（['ragged']））</title>
      <link>https://stackoverflow.com/questions/61934272/valueerror-unrecognized-keyword-arguments-dict-keysragged</link>
      <description><![CDATA[我在 google colab 上训练了一个细胞分割模型，一个使用 tensorflow 版本 1.x，另一个使用 2.x。我下载了这个模型，现在正尝试加载它并预测我下载的预选图像。训练和建立模型，我用的是 tf.keras.layers.layername 代码如下：
import numpy as np
import cv2
import tensorflow as tf
import keras
from tensorflow.python.keras.models import load_model
from tensorflow.python.keras.utils import CustomObjectScope
from tensorflow.python.keras.initializers import glorot_uniform

def prepare(filepath):
IMG_SIZE = 100
img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)
new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)

#def load_model():
with CustomObjectScope({&#39;GlorotUniform&#39;:glorot_uniform()}):
model = tf.keras.models.load_model(&quot;./models/nuclei_1-15.h5&quot;, compile=False)

def predict():
prediction = model.predict([prepare(&quot;./images/cell.jpeg&quot;)])
print(prediction)

predict()

出现以下错误：
回溯（最近一次调用）：
文件“model_werk.py”，第 20 行，位于 &lt;module&gt;
model = tf.keras.models.load_model(&quot;./models/nuclei_1-15.h5&quot;, compile=False)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/models.py”，第 246 行，位于 load_model
model = model_from_config(model_config, custom_objects=custom_objects)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/models.py”，第 324 行，位于 model_from_config
返回 layer_module.deserialize(config, custom_objects=custom_objects)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/serialization.py”，第 63 行，位于 deserialize
printable_module_name=&#39;layer&#39;)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/utils/generic_utils.py”，第 164 行，位于 deserialize_keras_object
list(custom_objects.items())))
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py”，第 975 行，位于 from_config
process_layer(layer_data)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py”，第 961 行，位于 process_layer
layer = deserialize_layer(layer_data, custom_objects=custom_objects)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/layers/serialization.py”，第63，在 deserialize 中
printable_module_name=&#39;layer&#39;)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/utils/generic_utils.py”，第 166 行，在 deserialize_keras_object 中
return cls.from_config(config[&#39;config&#39;])
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py”，第 483 行，在 from_config 中
return cls(**config)
文件“/home/hmrbcnt/Documents/thesis/try_2.1.5/trial/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py”，第 524 行，在 __init__ 中
raise ValueError(&#39;无法识别的关键字参数：&#39;, kwargs.keys())
ValueError: (&#39;无法识别的关键字参数：&#39;, dict_keys([&#39;ragged&#39;]))


我使用 tensorflow.python.keras 而不是 tensorflow.keras 的原因是使用 tensorflow.keras 会返回 ModuleNotFound 错误。
tensorflow 的版本是 1.5，keras 是 2.2.4。我不能使用高于 1.5 的 tensorflow 版本，因为我的 CPU 很旧，它不支持 avx 指令。
任何帮助都将不胜感激。谢谢！
编辑：更改了错误和一行代码，因为我忽略了一些东西，现在得到了类似但不同的错误]]></description>
      <guid>https://stackoverflow.com/questions/61934272/valueerror-unrecognized-keyword-arguments-dict-keysragged</guid>
      <pubDate>Thu, 21 May 2020 12:12:38 GMT</pubDate>
    </item>
    <item>
      <title>选择权重进行加权损失计算的逻辑是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/59433485/logic-behind-choosing-weight-for-weighted-loss-calculation</link>
      <description><![CDATA[在计算加权 S 型交叉熵损失时，或者在数据集不平衡的情况下，选择权重的一般逻辑是什么？问题领域基于视觉/图像分类。]]></description>
      <guid>https://stackoverflow.com/questions/59433485/logic-behind-choosing-weight-for-weighted-loss-calculation</guid>
      <pubDate>Sat, 21 Dec 2019 04:26:57 GMT</pubDate>
    </item>
    <item>
      <title>如何从 vgg19 中删除自适应平均池层？</title>
      <link>https://stackoverflow.com/questions/59269140/how-to-remove-the-adaptive-average-pool-layer-from-vgg19</link>
      <description><![CDATA[我已加载 vgg19 预训练模型。如何删除分类器之前的自适应平均池化层？]]></description>
      <guid>https://stackoverflow.com/questions/59269140/how-to-remove-the-adaptive-average-pool-layer-from-vgg19</guid>
      <pubDate>Tue, 10 Dec 2019 14:10:12 GMT</pubDate>
    </item>
    <item>
      <title>对坐标数据进行非规范化 Tensorflow、Tflite - Python</title>
      <link>https://stackoverflow.com/questions/58539579/denormalize-coordinate-data-tensorflow-tflite-python</link>
      <description><![CDATA[我目前正在开发一款物体检测应用，该应用能够检测轮胎是否损坏。为此，我使用了 Google 的 AutoML edge，它可以导出 TFlite 模型。现在我想在我的代码中实现这个模型，但显然它预测的坐标是标准化的，而我却无法对其进行非标准化处理
在这里查看我的代码：
import tensorflow as tf
import numpy as np
import cv2

MODEL_PATH = &#39;Resources/model_v1_OD.tflite&#39;
LABEL_PATH = &#39;Resources/model_v1_OD.txt&#39;

class TFTireModel():
labels = []
intepreter = None
input_details = []
output_details = []
height = 0
width = 0

def __init__(self):
with open(LABEL_PATH, &#39;r&#39;) as f:
self.labels = [line.strip() for line in f.readlines()]

# 初始化 TFlite 解释器
self.interpreter = tf.lite.Interpreter(model_path=MODEL_PATH)
self.interpreter.allocate_tensors()

# 获取输入和输出张量。
self.input_details = self.interpreter.get_input_details()
self.output_details = self.interpreter.get_output_details()
# 获取输入尺寸
self.height = self.input_details[0][&#39;shape&#39;][1]
self.width = self.input_details[0][&#39;shape&#39;][2]

def predict(self, img, Threshold=0.3):
# 将图像调整为输入尺寸
img = cv2.resize(img, (self.width, self.height))
img = np.expand_dims(img, axis=0)
img = (2.0 / 255.0) * img - 1.0
img = img.astype(&#39;uint8&#39;)

# 预测图像
self.interpreter.set_tensor(self.input_details[0][&#39;index&#39;], img)
self.interpreter.invoke()

# 获取结果
boxes = self.interpreter.get_tensor(
self.output_details[0][&#39;index&#39;])
print(f&quot;boxes: {boxes}&quot;)

classes = self.interpreter.get_tensor(
self.output_details[1][&#39;index&#39;])

scores = self.interpreter.get_tensor(
self.output_details[2][&#39;index&#39;])

num = self.interpreter.get_tensor(
self.output_details[3][&#39;index&#39;])

# 获取输出
output =self._boxes_coordinates(boxes=np.squeeze(boxes[0]),
classes=np.squeeze(classes[0]+1).astype(np.int32),
scores=np.squeeze(scores[0]),
im_width=self.width,
im_height=self.height,
min_score_thresh=threshold)

print(f&quot;output: {output}&quot;)

# 格式化输出
返回输出

def _boxes_coordinates(self,
boxes,
classes,
scores,
im_width,
im_height,
max_boxes_to_draw=4,
min_score_thresh=0.4):

print(f&quot;width: {im_width}, height {im_height}&quot; )
if not max_boxes_to_draw:
max_boxes_to_draw = boxes.shape[0]
number_boxes = min(max_boxes_to_draw, boxes.shape[0])
tire_boxes = []
# person_labels = []
for i in range(number_boxes):
if scores is None or scores[i] &gt; min_score_thresh:
box = tuple(boxes[i].tolist())
ymin, xmin, ymax, xmax = box
xmin, ymin, xmax, ymax = (int(xmin * im_width), int(xmax * im_width), int(ymin * im_height), int(ymax * im_height)) #TODO：做一个循环

#tire_boxes.append([(ymin, xmin, ymax, xmax), scores[i], self.labels[classes[i]]]) #更完整
tire_boxes.append((xmin, ymin, xmax, ymax))
return tire_boxes

出错的地方：
 boxes = self.interpreter.get_tensor(
self.output_details[0][&#39;index&#39;])
print(f&quot;盒子：{盒子}&quot;

盒子：[[[ 0.00263482 0.50020593 0.3734043 0.83953816]
[ 0.12580797 0.14952084 0.65327024 0.61710536]
[ 0.13584864 0.38896233 0.6485662 0.85324436]
[ 0.31914377 0.3945622 0.87147605 0.8458656 ]
[ 0.01334581 0.03666234 0.46443292 0.55461186]
[ 0.1018104 -0.08279537 0.6541427 0.37984413]

由于此处的输出已标准化，我不知道如何对其进行非标准化。所需的输出是宽度和高度的百分比，如 _boxes_coordinates 函数中所示。]]></description>
      <guid>https://stackoverflow.com/questions/58539579/denormalize-coordinate-data-tensorflow-tflite-python</guid>
      <pubDate>Thu, 24 Oct 2019 10:42:04 GMT</pubDate>
    </item>
    <item>
      <title>获取 5 个随机裁剪 - TypeError：pic 应为 PIL Image 或 ndarray。获取 <type ‘tuple’></title>
      <link>https://stackoverflow.com/questions/55323821/getting-5-random-crops-typeerror-pic-should-be-pil-image-or-ndarray-got-typ</link>
      <description><![CDATA[我对图像进行如下转换（与 RandCrop 配合使用）：（来自此数据加载器脚本：https://github.com/jeffreyhuang1/two-stream-action-recognition/blob/master/dataloader/motion_dataloader.py）
def train(self):
training_set = motion_dataset(dic=self.dic_video_train, in_channel=self.in_channel, root_dir=self.data_path,
mode=‘train’,
transform = transforms.Compose([
transforms.Resize([256,256]),
transforms.FiveCrop([224, 224]),
#transforms.RandomCrop([224, 224]),
transforms.ToTensor(),
#transforms.Normalize([0.5], [0.5])
]))
打印‘==&gt;训练数据：’，len(training_set)，’ 视频’，training_set[1][0].size()

train_loader = DataLoader(
dataset=training_set, 
batch_size=self.BATCH_SIZE,
shuffle=True,
num_workers=self.num_workers,
pin_memory=True
)

return train_loader

但是当我尝试获取 Five Crops 时，我收到此错误：
回溯（最近一次调用最后一次）：
文件“motion_cnn.py”，第 267 行，在 
main()
文件“motion_cnn.py”，第 51 行，在 main
train_loader,test_loader, test_video = data_loader.run()
文件“/media/d/DATA_2/two-stream-action-recognition-master/dataloader/motion_dataloader.py”，第 120 行，正在运行
train_loader = self.train()
文件“/media/d/DATA_2/two-stream-action-recognition-master/dataloader/motion_dataloader.py”，第 156 行，正在训练
print ‘==&gt;训练数据：’,len(training_set),’ videos’,training_set[1][0].size()
文件“/media/d/DATA_2/two-stream-action-recognition-master/dataloader/motion_dataloader.py”，第 77 行，在 getitem 中
data = self.stackopf()
文件“/media/d/DATA_2/two-stream-action-recognition-master/dataloader/motion_dataloader.py”，第 51 行，在 stackopf 中
H = self.transform(imgH)
文件“/media/d/DATA_2/two-stream-action-recognition-master/venv/local/lib/python2.7/site-packages/torchvision/transforms/transforms.py”，第 60 行，在 call 中
img = t(img)
文件“/media/d/DATA_2/two-stream-action-recognition-master/venv/local/lib/python2.7/site-packages/torchvision/transforms/transforms.py”，第 91 行，在调用中
return F.to_tensor(pic)
文件“/media/d/DATA_2/two-stream-action-recognition-master/venv/local/lib/python2.7/site-packages/torchvision/transforms/ functional.py”，第 50 行，在 to_tensor 中
raise TypeError(‘pic 应为 PIL 图像或 ndarray。得到 {}’.format(type(pic)))
TypeError：pic 应为 PIL 图像或 ndarray。得到 &lt;type ‘tuple’&gt;

获取 5 个随机裁剪，我应该处理一组图像而不是 PIL 图像 - 所以我使用 Lambda，但随后我得到了错误，在
 第 55 行，在 stackopf
flow[2*(j),:,:] = H
RuntimeError: expand(torch.FloatTensor{[5, 1, 224, 224]}, size=[224,224]): 提供的尺寸数量 (2) 必须大于或等于张量中的维数 (4)

当我尝试设置 flow = torch.FloatTensor(5, 2*self.in_channel,self.img_rows,self.img_cols)
我得到了
 motion_dataloader.py&quot;，第 55 行，在 stackopf 中
flow[:,2*(j),:,:] = H
RuntimeError: expand(torch.FloatTensor{[5, 1, 224, 224]}, size=[5, 224, 224]): 提供的尺寸数量 (3) 必须大于或等于张量中的维数 (4)

当我将返回的训练批次大小乘以 5 时，我也得到了同样的错误。]]></description>
      <guid>https://stackoverflow.com/questions/55323821/getting-5-random-crops-typeerror-pic-should-be-pil-image-or-ndarray-got-typ</guid>
      <pubDate>Sun, 24 Mar 2019 12:31:25 GMT</pubDate>
    </item>
    <item>
      <title>检测纸上的符号</title>
      <link>https://stackoverflow.com/questions/11727485/detect-symbol-on-paper</link>
      <description><![CDATA[我想检测用户在纸上绘制的符号。文档将指定此符号，因此每个用户都会绘制相同的符号，但由于每个用户的笔迹不同，因此当然会存在差异。

我应该选择哪种符号？哪种符号易于识别，但也能使检测容忍微小修改（每个用户的手写）？
我应该使用哪种模式匹配方法/算法来检测文档图像中的符号？
]]></description>
      <guid>https://stackoverflow.com/questions/11727485/detect-symbol-on-paper</guid>
      <pubDate>Mon, 30 Jul 2012 18:34:44 GMT</pubDate>
    </item>
    </channel>
</rss>