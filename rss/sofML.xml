<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 23 Jul 2024 15:17:04 GMT</lastBuildDate>
    <item>
      <title>HPCC 系统 ECL：使用 LinearRegression 时出现访问权限不足错误</title>
      <link>https://stackoverflow.com/questions/78784047/hpcc-systems-ecl-insufficient-access-rights-error-using-linearregression</link>
      <description><![CDATA[我正在使用 HPCC Systems 和 ECL 进行机器学习项目以执行线性回归。我的数据集包含心理健康患病率数据。在尝试使用 LinearRegression.OLS 训练我的模型时，我遇到了以下错误：
错误：访问权限不足，无法使用嵌入代码（125，34 - C:\Users\LENOVO\AppData\Roaming\HPCCSystems\bundles_versions\PBblas\V3_0_2\PBblas\internal\Converted.ecl）
这意味着包含在 ECL 脚本中的代码需要特殊权限或访问级别才能运行。
错误指向 HPCC Systems 安装中的特定文件，在本例中是 PBblas 库 (Converted.ecl) 的一部分。
我的代码：
``IMPORT ML_Core;
IMPORT LinearRegression;
IMPORT $;

// 输入数据集的记录结构
MentalHealthRecord := RECORD
STRING Entity;
STRING Code;
INTEGER Year;
REAL8 Schizophrenia;
REAL8 Depression;
REAL8 Anxiety;
REAL8 Bipolar;
REAL8 EatingDisorders;
END;

// 根据记录输入数据集
MentalHealthDs := DATASET(&#39;~asn::testing::1-mental-illnesses-prevalence.csv&#39;,
MentalHealthRecord,
CSV(HEADING(1),
SEPARATOR(&#39;,&#39;),
TERMINATOR([&#39;\n&#39;, &#39;\r\n&#39;, &#39;\n\r&#39;])));

OUTPUT(MentalHealthDs, NAMED(&#39;InputDataset&#39;));

// 数据集中的记录数。训练：测试的分割比率，以小数表示。
recordCount := COUNT(MentalHealthDs);
splitRatio := 0.8; // 80% 用于训练，20% 用于测试

// 继承包含随机数的数据集记录的记录结构
Shuffler := RECORD
MentalHealthRecord;
UNSIGNED4 rnd; // 随机数
END;

// 向包含随机数的数据添加属性
newDs := PROJECT(MentalHealthDs, TRANSFORM(Shuffler, SELF.rnd := RANDOM(), SELF := LEFT));

// 根据随机数对数据集进行排序，进行随机排序
shuffledDs := SORT(newDs, rnd);

// 分割训练和测试数据集，同时仅采用输入记录属性
TrainDs := PROJECT(shuffledDs[1..(recordCount * splitRatio)], RECORDOF(MentalHealthDs));
TestDs := PROJECT(shuffledDs[(recordCount * splitRatio + 1)..recordCount], RECORDOF(MentalHealthDs));

OUTPUT(TrainDs, NAMED(&#39;TrainDataset&#39;));
OUTPUT(TestDs, NAMED(&#39;TestDataset&#39;));

// 将顺序 ID 附加到训练和测试数据集
ML_Core.AppendSeqID(TrainDs, id, newTrain);
ML_Core.AppendSeqID(TestDs, id, newTest);

OUTPUT(newTrain, NAMED(&#39;TrainDatasetID&#39;));
OUTPUT(newTest, NAMED(&#39;TestDatasetID&#39;));

// 将数据集转换为数字字段以进行训练
ML_Core.ToField(newTrain, TrainNF);
ML_Core.ToField(newTest, TestNF);

OUTPUT(TrainNF, NAMED(&#39;TrainNumericField&#39;));
OUTPUT(TestNF, NAMED(&#39;TestNumericField&#39;));

// 根据独立列的数量拆分转换后的数字字段数据集以获取用于训练的 X 和 Y 
independent_cols := 4; // 精神分裂症、焦虑症、躁郁症、饮食失调

X_train := TrainNF(number &lt; independent_cols + 1);
y_train := PROJECT(TrainNF(number = independent_cols + 1), TRANSFORM(RECORDOF(LEFT), SELF.number := 1, SELF := LEFT));

X_test := TestNF(number &lt; independent_cols + 1);
y_test := PROJECT(TestNF(number = independent_cols + 1), TRANSFORM(RECORDOF(LEFT), SELF.number := 1, SELF := LEFT));

OUTPUT(y_test, NAMED(&#39;ActualY&#39;));

// 通过拟合模型构建回归器并使用测试数据集进行预测
regressor := LinearRegression.OLS(X_train, y_train).GetModel;
predicted := LinearRegression.OLS().Predict(X_test, regressor);

OUTPUT(predicted, NAMED(&#39;PredictedY&#39;));
``

我已检查我的访问权限，但问题仍然存在。
我希望了解为什么我会收到“访问权限不足”错误以及如何解决它。
如何正确使用 LinearRegression.OLS 来训练模型？
HPCC Systems ECL 中是否有其他方法或配置可以执行线性回归而不会遇到访问权限问题？
如果有人可以指导我完成这项工作，那将是一个很大的帮助。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78784047/hpcc-systems-ecl-insufficient-access-rights-error-using-linearregression</guid>
      <pubDate>Tue, 23 Jul 2024 14:29:53 GMT</pubDate>
    </item>
    <item>
      <title>pointnet++的实现</title>
      <link>https://stackoverflow.com/questions/78783587/implementation-of-pointnet</link>
      <description><![CDATA[这是我的错误。我已经实现了所有代码，但得到的结果是这样的。掩码张量的形状与被索引的张量的形状不匹配。具体来说，掩码张量的形状为 [8, 512, 3]，而被索引的张量的形状为 [8, 512, 16]。我不知道如何解决这个问题。请给我一些逻辑，或者我应该如何继续，因为我已经使用了 chatgpt，但我也找不到答案
/usr/bin/python3.10 /home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/centerline_pn.py 
回溯（最近一次调用最后一次）：
文件“/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/centerline_pn.py”，第 265 行，位于 &lt;module&gt;
main()
文件 &quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/centerline_pn.py&quot;，第 217 行，在 main
输出，_ = model(points)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1532 行，在 _wrapped_call_impl
返回 self._call_impl(*args, **kwargs)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1541 行，在 _call_impl
返回 forward_call(*args, **kwargs)
文件&quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/models/pointnet2_cls_msg.py&quot;，第 32 行，在 forward 中
l1_xyz, l1_points = self.sa1(xyz, norm)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1532 行，在 _wrapped_call_impl 中
return self._call_impl(*args, **kwargs)
文件 &quot;/home/aniruddha/.local/lib/python3.10/site-packages/torch/nn/modules/module.py&quot;，第 1541 行，在 _call_impl 中
return forward_call(*args, **kwargs)
文件&quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/models/pointnet2_utils.py&quot;，第 283 行，在 forward 中
group_idx = query_ball_point(radius, K, xyz, new_xyz)
文件 &quot;/home/aniruddha/PycharmProjects/Pointnet_Pointnet2_pytorch/models/pointnet2_utils.py&quot;，第 148 行，在 query_ball_point 中
group_idx[mask] = group_first[mask]
IndexError：索引 2 处的掩码 [8, 512, 3] 的形状与索引 2 处的索引张量 [8, 512, 16] 的形状不匹配

进程以退出代码 1 结束


def query_ball_point(radius, nsample, xyz, new_xyz):
&quot;&quot;&quot;
输入：
radius：局部区域半径
nsample：局部区域最大样本数
xyz：所有点，[B, N, 3]
new_xyz：查询点，[B, S, 3]
返回：
group_idx：分组点索引，[B, S, nsample]
&quot;&quot;&quot;
device = xyz.device
B, N, C = xyz.shape
_, S, _ = new_xyz.shape
group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])
sqrdists = square_distance(new_xyz, xyz)
group_idx[sqrdists &gt; radius ** 2] = N
group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]
group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])
mask = group_idx == N
group_idx[mask] = group_first[mask]
return group_idx

def square_distance(src, dst):
&quot;&quot;&quot;
计算每两点之间的欧几里得距离。

src^T * dst = xn * xm + yn * ym + zn * zm；
sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;
sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;
dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2
= sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst

输入：
src：源点，[B, N, C]
dst：目标点，[B, M, C]
输出：
dist：每个点的平方距离，[B, N, M]
&quot;&quot;&quot;
B, N, _ = src.shape
_, M, _ = dst.shape
dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))
dist += torch.sum(src ** 2, -1).view(B, N, 1)
dist += torch.sum(dst ** 2, -1).view(B, 1, M)
返回 dist

]]></description>
      <guid>https://stackoverflow.com/questions/78783587/implementation-of-pointnet</guid>
      <pubDate>Tue, 23 Jul 2024 12:58:50 GMT</pubDate>
    </item>
    <item>
      <title>多输出回归可根据 ROAS 和其他功能预测成本和收入</title>
      <link>https://stackoverflow.com/questions/78783100/multi-output-regression-to-predict-cost-and-revenue-from-roas-and-other-features</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78783100/multi-output-regression-to-predict-cost-and-revenue-from-roas-and-other-features</guid>
      <pubDate>Tue, 23 Jul 2024 11:10:59 GMT</pubDate>
    </item>
    <item>
      <title>找到正确的数据初始化形状，无需大量填充或减少数据</title>
      <link>https://stackoverflow.com/questions/78783065/finding-the-right-shape-for-data-initialization-without-padding-a-lot-or-without</link>
      <description><![CDATA[我正在构建一个 RNN 模型，用于分析第二天的降雨概率，以及每天的降雨量。我有一个张量 (1, 542375)，我想将其重塑为 (状态数，46, 366)（46 年，每年 366 天）。问题是，当我想要训练时，将状态数转换为批大小是一项艰巨的任务，因为 batch_size 需要为 2^n，而状态数远不及这个数字......我相信我有两个选择：或者我将批大小设为 64，我必须填充 500000 个输入，这在计算上效率较低；或者我将批大小设为 32，如果我的数据为 3623 个输入，我必须删除 3623 个输入...还有其他选择吗？在哪里可以了解有关组织数据的更多信息？
32 * 46 * 366 = 548 752
542375 - 538752 = 3623
64 * 46 * 366 = 1077504
10777594 - 542375 = 535129
填充 535129 个输入
或
删除 3623 个参数]]></description>
      <guid>https://stackoverflow.com/questions/78783065/finding-the-right-shape-for-data-initialization-without-padding-a-lot-or-without</guid>
      <pubDate>Tue, 23 Jul 2024 11:02:21 GMT</pubDate>
    </item>
    <item>
      <title>MediaPipe 手势检测中的抖动</title>
      <link>https://stackoverflow.com/questions/78782336/jitter-in-mediapipe-hand-pose-detection</link>
      <description><![CDATA[使用 Python、OpenCV 和 MediaPipe，我编写了以下代码：
import mediapipe as mp
import cv2

# 初始 MediaPipe 手部检测
mp_hand = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hand.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)

# 初始网络摄像头读取
cap = cv2.VideoCapture(0)
assert cap.isOpened(), &quot;Camera not found&quot;

while cap.isOpened():
# 从网络摄像头读取图像
成功，img = cap.read()
如果失败：
break

# 将图像颜色从 BGR 转换为 RGB
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# 通过 MediaPipe 检测手
results = hands.process(img_rgb)

# 绘制手部标志
if results.multi_hand_landmarks:
for hand_landmarks in results.multi_hand_landmarks:
mp_drawing.draw_landmarks(img, hand_landmarks, mp_hand.HAND_CONNECTIONS)

# 显示结果
cv2.imshow(&#39;webcam&#39;, img)

if cv2.waitKey(1) &amp; 0xff == ord(&#39;q&#39;):
break

# 释放资源
cap.release()
cv2.destroyAllWindows()

输出：

我想在检测过程中防止这种轻微的振动。我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/78782336/jitter-in-mediapipe-hand-pose-detection</guid>
      <pubDate>Tue, 23 Jul 2024 08:18:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们使用正确的参数网格来微调预测精度？</title>
      <link>https://stackoverflow.com/questions/78781865/why-we-use-correct-parameter-grid-for-fine-tune-a-prediction-accuracy</link>
      <description><![CDATA[parameters = {
&#39;n_estimators&#39;: [100, 200],
&#39;learning_rate&#39;: [0.01, 0.1],
&#39;max_depth&#39;: [3, 5],
&#39;subsample&#39;: [0.8, 1.0],
&#39;colsample_bytree&#39;: [0.8, 1.0],
&#39;gamma&#39;: [0, 0.1],
&#39;min_child_weight&#39;: [1, 2]
}

并且需要更多时间来拟合
对此的解释和用例。
grid_search.fit(X_train, y_train) 当我执行此行时，它需要超过 45 分钟，但仍然没有完成
什么是 GridSearchCV？它的用例？什么是 cv=3，为什么我们给它以及什么是评分？为什么我们使用 GridSearchCV？]]></description>
      <guid>https://stackoverflow.com/questions/78781865/why-we-use-correct-parameter-grid-for-fine-tune-a-prediction-accuracy</guid>
      <pubDate>Tue, 23 Jul 2024 06:28:25 GMT</pubDate>
    </item>
    <item>
      <title>使用数组作为特征/独立变量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78781575/using-an-array-as-a-feature-independent-variable</link>
      <description><![CDATA[假设我有一个数据框：

主题 ID (int)
年龄 (int)
性别 (int 1- 代表男性，2- 代表女性)
Pearson CC 表示功能网络 (矩阵)

这意味着我有一个 PearsonCC 数组数组。例如：



p_id
性别
PearsonCorrelationCoefficient




128_S_0200
M
[0.5052435694128596, 0.3375816208945487, 0.206...


003_S_0908
F
[-0.18955977794142087, 0.01652734870786999, -0...


141_S_1052
F
[0.0562331642358682, 0.5698911953687733, -0.17... -0...



所以我明白我们需要展平矩阵/矢量化上三角以将数据处理成一维数组。但是，有没有什么方法可以将这个一维数组用作我的 ML 模型的特征/预测器？
我知道我们可以将一维数组转换为单独的列，但这会导致近 5000 列（矢量化矩阵的每个数组长度为 4950）。我也知道我们可以通过 PCA 等技术降低维数，但我不太确定是否要摆脱原始矩阵中的重要连接。
还有其他方法可以解决这个问题吗？
任何帮助都将不胜感激！
如果我使用 sklearn 的 Logistic 回归：
model = LogisticRegression(max_iter=1000)
model.fit(X_train_final, y_train)
我收到一个错误，表明 PearsonCC 列可能不被接受为数组 &amp;只能是 int/float 才能适合：
TypeError Traceback（最近一次调用最后一次）
TypeError：只有 size-1 数组才能转换为 Python 标量
]]></description>
      <guid>https://stackoverflow.com/questions/78781575/using-an-array-as-a-feature-independent-variable</guid>
      <pubDate>Tue, 23 Jul 2024 04:35:17 GMT</pubDate>
    </item>
    <item>
      <title>人工智能是出路吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78781284/is-artificial-intelligence-the-way-to-go</link>
      <description><![CDATA[大家好吗？我是一名电影行业专业人士，每个人都知道，目前从事这个行业很糟糕。有一件事让我着迷，那就是人工智能。我认为它远没有现在被描绘成的可怕流行语那么可怕。就我个人而言，我相信对于适应的电影制作人来说，它将是一个很好的工具。问题是，大多数人不会因为恐惧而适应。
话虽如此，我想更多地了解人工智能。我不知道从哪里开始，在这方面我完全是个新手。我希望真正熟练掌握它，这样我在未来几年就会有优势。有人有什么建议吗？我应该学习什么关于人工智能的知识？我应该学习如何使用生成式人工智能吗？如何“制造”生成式人工智能？目标应该是放弃电影制作事业，转而进入一家更依赖人工智能的公司吗？
请记住，我是一个完全的新手。目标是获得一套有用的新技能。
我还没有尝试任何东西，因为我不确定如何开始。我应该进入机器学习领域吗？我应该学习 Python 吗？有什么期刊我应该关注吗？]]></description>
      <guid>https://stackoverflow.com/questions/78781284/is-artificial-intelligence-the-way-to-go</guid>
      <pubDate>Tue, 23 Jul 2024 01:55:46 GMT</pubDate>
    </item>
    <item>
      <title>使用按位或自定义损失函数进行多标签分类</title>
      <link>https://stackoverflow.com/questions/78771566/multi-label-classification-using-bit-wise-or-custom-loss-function</link>
      <description><![CDATA[我对这个公式和多标签分类的按位或有疑问。我应该在这里对所有 R 使用连续输出值，还是只需要它们来计算 N，并在 A = ... 中对 R 使用二进制阈值？因为描述令人困惑，首先它指出“L 和 R 是 N × c 二进制矩阵，由独热编码的地面实况标签和阈值模型输出分数组成”，然后在 N 的等式中“二进制矩阵 R 现在可以使用原始输出分数 pc 替换为其连续等效值，如下所示”。 （Vicar 等人的论文“使用具有全局跳过连接和自定义损失函数的卷积网络进行心电图异常识别”）
]]></description>
      <guid>https://stackoverflow.com/questions/78771566/multi-label-classification-using-bit-wise-or-custom-loss-function</guid>
      <pubDate>Sat, 20 Jul 2024 00:39:15 GMT</pubDate>
    </item>
    <item>
      <title>如何纠正 Reshape 函数中的错误</title>
      <link>https://stackoverflow.com/questions/78749448/how-do-you-correct-the-error-in-reshape-function</link>
      <description><![CDATA[当我拟合各种人工神经网络时，TLNN 的代码显示不正确，尤其是包含重塑函数的行。这有什么问题吗？更改数据集是否意​​味着重塑函数不起作用并显示此错误
def Forecast_TLNN(model, time_lagged_points, last_sequence, Future_steps):
Forecasted_values = []
max_lag = max(time_lagged_points)
for i in range(future_steps):
input_sequence = [last_sequence[max_lag - p] for p in time_lagged_points]
Forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
Forecasted_values.append(forecasted_value[0][0])
last_sequence = last_sequence[1:] + [forecasted_value[0][0]]
return Forecasted_values

错误显示在以下行中：forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
我似乎无法在互联网上找到有关此代码的任何更正。
 ---------------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Cell In[83], line 13
10 # look_back, hidden_​​nodes, output_nodes, epochs, batch_size, future_steps
11 parameters_LSTM = [[1,2,3,4,5,6,7,8,9,10,11,12,13], [3,4,5,6], [1], [300], [20], [future_steps]]
---&gt; 13 RMSE_info = compare_ANN_methods(rainfall_data, test_rainfall_data, scaler, parameters_FNN, parameters_TLNN, parameters_SANN, parameters_LSTM, future_steps)

单元格 In[79]，第 6 行，在 compare_ANN_methods(rainfall_data, test_rainfall_data, scaler, parameters_FNN, parameters_TLNN, parameters_SANN, parameters_LSTM, future_steps) 中
3 information_FNN_df = get_accuracies_FNN(rainfall_data, test_rainfall_data, parameters_FNN, scaler)
4 optimal_params_FNN = analyze_results(information_FNN_df, test_rainfall_data, &#39;FNN&#39;)
----&gt; 6 information_TLNN_df = get_accuracies_TLNN(rainfall_data, test_rainfall_data, parameters_TLNN, scaler)
7 optimal_params_TLNN = analyze_results(information_TLNN_df, test_rainfall_data, &#39;TLNN&#39;)
9 information_SANN_df = get_accuracies_SANN(rainfall_data, test_rainfall_data, parameters_SANN, scaler)

单元格 In[55]，第 21 行，在 get_accuracies_TLNN(rainfall_data, test_rainfall_data, parameters, scaler)
18 batch_size = param[4]
19 future_steps = param[5]
---&gt; 21 model_TLNN, Forecasted_values_TLNN = TLNN(rainfall_data, time_lagged_points, hidden_​​nodes, output_nodes, epochs, batch_size, Future_steps, scaler)
23 y_true = test_rainfall_data.iloc[:future_steps].Precipitation
24 mse, mae, mape, rmse = calculate_performance(y_true, Forecasted_values_TLNN)

单元格 In[53]，第 9 行，在 TLNN(data, time_lagged_points, hidden_​​nodes, output_nodes, epochs, batch_size, Future_steps, scaler)
6 model_TLNN = train_model(model_TLNN, X_train, y_train, epochs, batch_size)
8 max_lag = max(time_lagged_points)
----&gt; 9 预测值_TLNN = 预测值_TLNN(model_TLNN, time_lagged_points, 
10 列表(数据[-max_lag:]), 未来步骤=未来步骤)
11 预测值_TLNN = 列表(scaler.inverse_transform([预测值_TLNN])[0])
13 返回 model_TLNN, 预测值_TLNN

单元格 In[51]，第 6 行，在预测值_TLNN(模型, time_lagged_points, last_sequence, 未来步骤)
4 for i in range(future_steps):
5 输入序列 = [last_sequence[max_lag - p] for p in time_lagged_points]
----&gt; 6 Forecasted_value = model.predict((np.reshape(input_sequence, (1, len(input_sequence)))))
7 Forecasted_values.append(forecasted_value[0][0])
8 last_sequence = last_sequence[1:] + [forecasted_value[0][0]]

文件 ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:285，在 reshape(a, newshape, order) 中
200 @array_function_dispatch(_reshape_dispatcher)
201 def reshape(a, newshape, order=&#39;C&#39;):
202 &quot;&quot;&quot;
203 为数组赋予新形状而不更改其数据。
204 
(...)
283 [5, 6]])
284 &quot;&quot;&quot;
--&gt; 285 返回 _wrapfunc(a, &#39;reshape&#39;, newshape, order=order)

文件 ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:56，位于 _wrapfunc(obj, method, *args, **kwds)
54 bound = getattr(obj, method, None)
55 如果 bound 为 None:
---&gt; 56 return _wrapit(obj, method, *args, **kwds)
58 try:
59 return bound(*args, **kwds)

File ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:45, in _wrapit(obj, method, *args, **kwds)
43 except AttributeError:
44 wrap = None
---&gt; 45 result = getattr(asarray(obj), method)(*args, **kwds)
46 if wrap:
47 if not isinstance(result, mu.ndarray):

ValueError: 设置带有序列的数组元素。请求的数组在 1 维之后具有非均匀形状。检测到的形状为 (5,) + 非均匀部分。
]]></description>
      <guid>https://stackoverflow.com/questions/78749448/how-do-you-correct-the-error-in-reshape-function</guid>
      <pubDate>Mon, 15 Jul 2024 10:54:58 GMT</pubDate>
    </item>
    <item>
      <title>如何在全连接物理信息神经网络中选择超参数？[关闭]</title>
      <link>https://stackoverflow.com/questions/78739152/how-to-select-hyperparameters-in-fully-connected-physics-informed-neural-network</link>
      <description><![CDATA[我创建了具有物理约束的全连接 NN（即物理信息神经网络或 PINN）。但我完全不明白每层应该使用多少层和多少个神经元？
我尝试了不同数量的层（5-9），每层有不同数量的神经元（100-200）。据我所知，这也取决于输出大小。您在 PINN 方面有经验吗？可以建议最佳超参数吗？]]></description>
      <guid>https://stackoverflow.com/questions/78739152/how-to-select-hyperparameters-in-fully-connected-physics-informed-neural-network</guid>
      <pubDate>Fri, 12 Jul 2024 07:47:06 GMT</pubDate>
    </item>
    <item>
      <title>这个 elasticsearch 设置甚至使用 ML 节点吗？</title>
      <link>https://stackoverflow.com/questions/77923033/does-this-elasticsearch-setup-even-use-ml-node</link>
      <description><![CDATA[我按照此示例设置了 Elasticsearch 集群以进行图像相似性搜索：https://github.com/radoondas/flask-elastic-image-search
由于不熟悉 elasticsearch，我盲目地遵循了这个示例，其中包括一个带有预训练模型的 ML 节点。它运行良好。但是，我怀疑我们实际上并没有使用 ML 节点。
我提取应用程序中的密集向量，然后对它们进行索引，并且在查询时也提取应用程序中的向量。我不使用 elasticsearch 来提取密集向量。
当我索引密集向量或执行 KNN 查询时，是否有任何“魔法”可以让 elasticsearch 在后台使用预训练模型？或者预训练模型和 ML 节点都是我们实现中不需要的额外东西？]]></description>
      <guid>https://stackoverflow.com/questions/77923033/does-this-elasticsearch-setup-even-use-ml-node</guid>
      <pubDate>Thu, 01 Feb 2024 20:00:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Tensorflow/keras 上添加 InstanceNormalization</title>
      <link>https://stackoverflow.com/questions/68088889/how-to-add-instancenormalization-on-tensorflow-keras</link>
      <description><![CDATA[我是 TensorFlow 和 Keras 的新手，我一直在制作扩张的 resnet，并想在层上添加实例规范化，但我做不到，因为它一直抛出错误。
我正在使用 tensorflow 1.15 和 keras 2.1。我注释掉了可以工作的 BatchNormalization 部分，并尝试添加实例规范化，但找不到模块。
非常感谢您的建议


来自 keras.layers 导入 Conv2D
来自 keras.layers.normalization 导入 BatchNormalization
来自 keras.optimizers 导入 Nadam、Adam
来自 keras.layers 导入 Input、Dense、Reshape、Activation、Flatten、Embedding、Dropout、Lambda、add、concatenate、Concatenate、ConvLSTM2D、LSTM、average、MaxPooling2D、multiply、MaxPooling3D
来自 keras.layers 导入 GlobalAveragePooling2D、Permute
来自 keras.layers.advanced_activations 导入 LeakyReLU、PReLU
来自 keras.layers.convolutional 导入 UpSampling2D、Conv2D、 Conv1D
从 keras.models 导入 Sequential、Model
从 keras.utils 导入 multi_gpu_model
从 keras.utils.generic_utils 导入 Progbar
从 keras.constraints 导入 maxnorm
从 keras.activations 导入 tanh、softmax
从 keras 导入 metrics、initializers、utils、regularizers
将 tensorflow 导入为 tf
将 numpy 导入为 np
导入 math
导入 os
导入 sys
导入 random
将 keras.backend 导入为 K
epsilon = K.epsilon()

def basic_block_conv2D_norm_elu(filters、kernel_size、kernel_regularizer=regularizers.l2(1e-4)、act_func=&quot;elu&quot;、normalize=&quot;Instance&quot;、dropout=&#39;0.15&#39;,
strides=1、use_bias = True,kernel_initializer = &quot;he_normal&quot;,_dilation_rate=0):
def f(input):
if kernel_regularizer == None:
if _dilation_rate == 0:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
padding=&quot;same&quot;, use_bias=use_bias)(input)
else:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
padding=&quot;same&quot;, use_bias=use_bias,dilation_rate=_dilation_rate)(input)
else:
if _dilation_rate == 0:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
kernel_initializer=kernel_initializer, padding=&quot;same&quot;, use_bias=use_bias,
kernel_regularizer=kernel_regularizer)(输入)
else:
conv = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides,
kernel_initializer=kernel_initializer, padding=&quot;same&quot;, use_bias=use_bias,
kernel_regularizer=kernel_regularizer, dilation_rate=_dilation_rate)(输入)
if dropout != None:
dropout_layer = Dropout(0.15)(conv)

if normalize == None 且 dropout != None:
norm_layer = conv(dropout_layer)
else:
norm_layer = InstanceNormalization()(dropout_layer)
# norm_layer = BatchNormalization()(dropout_layer)
return激活（act_func）（norm_layer）
返回 f
]]></description>
      <guid>https://stackoverflow.com/questions/68088889/how-to-add-instancenormalization-on-tensorflow-keras</guid>
      <pubDate>Tue, 22 Jun 2021 18:14:05 GMT</pubDate>
    </item>
    <item>
      <title>在 MultiLabelBinarizer 中获取计数</title>
      <link>https://stackoverflow.com/questions/56372324/getting-counts-in-multilabelbinarizer</link>
      <description><![CDATA[如何获取 MultiLabelBinarizer 中的项目数？
import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
mlb = MultiLabelBinarizer()

pd.DataFrame(mlb.fit_transform([(1,1,2), (3,3,2,5)]),columns=mlb.classes_)

Out[0]: 
1 2 3 5
0 1 1 0 0
1 0 1 1 1

与此相反，我想要获取
Out[0]: 
1 2 3 5
0 2 1 0 0
1 0 1 2 1

因为 1 在第 1 行重复 2 次，而 3 在第 1 行重复 2 次]]></description>
      <guid>https://stackoverflow.com/questions/56372324/getting-counts-in-multilabelbinarizer</guid>
      <pubDate>Thu, 30 May 2019 05:47:14 GMT</pubDate>
    </item>
    <item>
      <title>序列长度在 LSTM 中的作用</title>
      <link>https://stackoverflow.com/questions/46980058/the-role-of-sequence-length-in-lstms</link>
      <description><![CDATA[我有时间序列数据，一个很长的序列，比如说有 30,000 个数据点。
对于 Tensorflow 中的 LSTM，输入形状为 [batch_size、time_steps、features]。我的批处理大小等于 1，因为我只有一个时间序列。
现在我的问题是关于序列长度的作用。
我可以使用 timestep=1 将整个时间序列传递到 tensorflow LSTM 中，在这种情况下，整个时间序列将逐一插入到 LSTM 中。或者我可以使用一些 &gt;1 的时间步长，并使其成为序列到序列模型。
这样，我可以一次插入 7 个数据点（= 一周的数据）并预测 7 个输出（= 未来一周）。
问题是，我们知道 LSTM 的隐藏状态最终会记住整个数据集（如果我们进行足够多的训练）。那么两者之间有什么区别呢？
a) timesteps=1，我预测一个时期，并将预测重新插入神经网络 7 次，
b) timesteps=7，我预测一个 7 的序列（= 一周）。]]></description>
      <guid>https://stackoverflow.com/questions/46980058/the-role-of-sequence-length-in-lstms</guid>
      <pubDate>Fri, 27 Oct 2017 16:55:09 GMT</pubDate>
    </item>
    </channel>
</rss>