<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 08 Jul 2024 09:17:55 GMT</lastBuildDate>
    <item>
      <title>拟合函数是否存在问题或模型是否存在问题</title>
      <link>https://stackoverflow.com/questions/78719748/is-there-some-issue-with-fit-function-or-some-issue-in-model</link>
      <description><![CDATA[我正在训练唇读模型，但它给出了以下错误图形执行错误
这是 colab 链接文本
我只是不明白问题是什么，请帮我解决这个问题😭
我正在关注 nicholas 的这个文本lipNet 教程。但同样的代码对我来说不起作用。帮助我，我是初学者]]></description>
      <guid>https://stackoverflow.com/questions/78719748/is-there-some-issue-with-fit-function-or-some-issue-in-model</guid>
      <pubDate>Mon, 08 Jul 2024 08:12:54 GMT</pubDate>
    </item>
    <item>
      <title>术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可运行程序的名称</title>
      <link>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</link>
      <description><![CDATA[在运行此最终命令时，我在本地笔记本电脑上执行自定义数据集上的 yolov3 操作，所有操作均已完成
./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg
darknet53.conv.74
当我使用 Windows Power Shell 时，出现错误，即
./darknet：术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可操作程序的名称。请检查名称的拼写，或者如果包含路径，请验证路径是否正确，然后重试。
在第 1 行，字符：1

./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg darknet5 ...

 + CategoryInfo : ObjectNotFound: (./darknet:String) [], CommandNotFoundException
+ FullyQualifiedErrorId : CommandNotFoundException




那么我该如何解决这个错误呢
我尝试过更改系统环境变量路径，也尝试过运行一些命令，但仍然抛出相同的错误，那么我应该尝试什么呢]]></description>
      <guid>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</guid>
      <pubDate>Mon, 08 Jul 2024 08:00:10 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型输入形状与层不兼容（尽管是兼容形状）</title>
      <link>https://stackoverflow.com/questions/78719585/keras-model-input-shapes-are-incompatible-with-the-layer-despite-being-a-compat</link>
      <description><![CDATA[为了解决这个问题，我在过去两天里费尽心机。我创建了一个文件 test.py，通过预测单个样本来测试我的模型：
import os
import keras
import numpy as np
import tensorflow as tf
from main_copy import path_to_fft

model = keras.models.load_model(os.path.join(os.getcwd(), &quot;model.keras&quot;))

model.summary()
model.summary(expand_nested=True)

first_sample = path_to_fft(os.path.join(os.getcwd(), &#39;Sounds&#39;, &#39;Thomas&#39;, &#39;thomas_original.wav&#39;))
second_sample = path_to_fft(os.path.join(os.getcwd(), &#39;Sounds&#39;, &#39;Thomas&#39;, &#39;thomas_original.wav&#39;))

print(&quot;First: &quot;, first_sample.shape)

print(&quot;Second: &quot;, second_sample.shape)

prediction = model.predict([first_sample, second_sample])
print(prediction)

path_to_fft 函数解码 .wav 文件并应用快速傅里叶变换，然后返回该变换的前半部分正频率，将 5 秒 16kHz 音频从形状 (80000, 1) 转换为 (40000, 1)，这是我的模型的正确大小。但是，当我尝试使用 model.predict 预测两个样本之间的距离时，我收到此错误消息：
Model: &quot; functional&quot;
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ ━ ...�
┃ 层（类型） ┃ 输出形状 ┃ 参数编号 ┃ 连接到┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━ ━━━━━━━╇━ ...输入A (输入层) │ (无，40000，1) │ 0 │ - │
│ ...输入A[0][0]，输入B[0][0] │
═──────────────────────────────┼──────────────────────────┼──────────────────────┼──────────────────────────┤
│ lambda (Lambda) │ (None, 1) │ 0 │ SiameseBranch[0][0]，│
│ │ │ │ SiameseBranch[1][0] │
└────────────────────────────┴────────────────────────┴──────────────────────┴────────────────────────┘

层“SiameseBranch”的输入 0与层不兼容：预期形状=(None, 40000, 1)，发现形状=(32, 1)

Functional.call() 接收的参数：
• 输入=(&#39;tf.Tensor(shape=(32, 1), dtype=float32)&#39;, &#39;tf.Tensor(shape=(32, 1), dtype=float32)&#39;)
• 训练=False
• 掩码=(&#39;None&#39;, &#39;None&#39;)

向上滚动时，我看到 Tensorflow 生成了三个 (?????) 参数：
级别 1：tensorflow：为 Python 函数 &lt;function StructuredFunctionWrapper.__init__.&lt;locals&gt;.trace_tf_function.&lt;locals&gt;.wrapped_fn at 创建新的 FuncGraph 0x0000027A795AE480&gt; (key: FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0), scope_type=&lt;ScopeType.VARIABLE_CREATION: 2&gt;), 输入参数:
args_0 (POSITIONAL_ONLY): TensorSpec(shape=(32,), dtype=tf.int64, name=None)
args_1 (POSITIONAL_ONLY): TensorSpec(shape=(40000, 1), dtype=tf.float32, name=None)
args_2 (POSITIONAL_ONLY): TensorSpec(shape=(40000, 1), dtype=tf.float32, name=None)
输出类型:
无
捕获:
无)

我完全不知道该做什么或如何处理这些错误日志。这是我第一次使用已保存为文件的模型，这绝对是一场噩梦。
作为参考，这里是 GitHub 存储库的链接（包含 path_to_fft 函数和用于拟合模型的代码以及模型本身）：https://github.com/brainage04/WestpacHackathon
这是运行 test.py 函数的完整错误日志，从头到尾：https://pastebin.com/iVZ7dUWn]]></description>
      <guid>https://stackoverflow.com/questions/78719585/keras-model-input-shapes-are-incompatible-with-the-layer-despite-being-a-compat</guid>
      <pubDate>Mon, 08 Jul 2024 07:30:43 GMT</pubDate>
    </item>
    <item>
      <title>POintNet++ 实现</title>
      <link>https://stackoverflow.com/questions/78719320/pointnet-implementation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78719320/pointnet-implementation</guid>
      <pubDate>Mon, 08 Jul 2024 06:10:06 GMT</pubDate>
    </item>
    <item>
      <title>如何提高解决嘈杂文本 CAPTCHA 图像的 OCR 准确率？[关闭]</title>
      <link>https://stackoverflow.com/questions/78718889/how-to-improve-ocr-accuracy-for-solving-noisy-text-captcha-images</link>
      <description><![CDATA[我正在开发一个名为 CAPTCHA 解算器的函数，该函数会获取一张包含 5 个黑色随机数且背景为红线的图像。有时我当前的实现在第一次尝试后就能成功。但有时，它会在 2-4 次尝试后成功。我想提高它的准确性。以下是 Captcha 图像的示例：

我实现了一个函数来处理 Captcha 解算，它在使用 Tesseract OCR 进行文本提取之前对 Captcha 图像进行预处理。我循环运行 CaptchaSolver()，这样如果它第一次预测错误，它会再次检查。我期望该函数能够始终如一地预测正确的验证码文本，但它经常失败。
这是解决验证码的函数：
def CaptchaSolver(image_path): # 验证码处理
captcha_image = Image.open(image_path)
captcha_image_np = np.array(captcha_image)
gray = cv2.cvtColor(captcha_image_np, cv2.COLOR_BGR2GRAY)
_, mask_black = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)
result = cv2.GaussianBlur(mask_black, (9,9), 0)

config = r&#39;--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789&#39;
captcha_text = pytesseract.image_to_string(result, config=config)
返回 captcha_text
]]></description>
      <guid>https://stackoverflow.com/questions/78718889/how-to-improve-ocr-accuracy-for-solving-noisy-text-captcha-images</guid>
      <pubDate>Mon, 08 Jul 2024 02:15:12 GMT</pubDate>
    </item>
    <item>
      <title>如何将模板草图与制造零件的图像进行比较？[关闭]</title>
      <link>https://stackoverflow.com/questions/78718809/how-do-i-compare-a-template-sketch-to-an-image-of-a-manufactured-part</link>
      <description><![CDATA[我有一个模板图像，用作基准来确定零件在电路板上的焊接位置。我无法保证图像具有相同的大小或比例。基准图像由外部来源提供给我，我自己焊接零件。焊接板的图像是我拍摄的。我想快速检查错误 - 应该放置但实际上没有放置的零件、应该跳过但实际上没有放置的零件等。
我希望在错误的零件上有一个边界框。我已附上两张描绘有问题的图像的图像（根据我的工作政策，我无法提供真实图像）。PCB 和 模板。
红色方框表示我不应该放置的部件，绿色方框表示我应该放置的部件。
我遵循了此处的信息。我尝试使用结构相似性指数。由于图像彼此之间差异很大，因此效果不佳。
我不认为密集向量表示对我有用，因为它会得出相似性分数，而不是暴露所犯的任何错误。
理想情况下，我可以从 SSI 方法生成输出以显示遗漏了哪些问题。]]></description>
      <guid>https://stackoverflow.com/questions/78718809/how-do-i-compare-a-template-sketch-to-an-image-of-a-manufactured-part</guid>
      <pubDate>Mon, 08 Jul 2024 01:28:36 GMT</pubDate>
    </item>
    <item>
      <title>对键盘上的按键数据历史进行分类，以识别不适当的内容（对计算机有危险）</title>
      <link>https://stackoverflow.com/questions/78718328/classification-of-key-press-data-history-on-the-keyboard-to-identify-inappropria</link>
      <description><![CDATA[最近，我从计算机视觉转向了 NLP 任务。
我收集了一组以 ASCII 文本文件形式记录的按键数据历史记录，记录了用户在会话期间的每次击键。目标是对这些数据进行分类，以检测不适当的内容，例如尝试下载病毒、访问非法网站等。
注意：

高噪声水平：按键数据历史文件包含大量噪声，这是由于频繁的嘈杂按键（例如，用户在玩游戏时按“wasd”）造成的，因此很难提取有意义的文本。

多语言输入：我想为多种语言进行输入。
例如，用户可能会输入“crfxfnm dbhec” （另一种语言的短语，含义为“下载病毒”，使用经典英语键盘布局）


我尝试使用预训练的 BERT 模型对原始数据进行文本分类，预测两个类别：正上下文和负上下文。但是，这种方法不起作用。
此外，我还探索了原始数据（相同的预训练 BERT 模型）上的 token 分类结果，噪声数据中的真实单词被突出显示。仍然希望能够准确识别 token。
基于 Transformer 的分类器（例如 Hugging Face 的 BERT）能否有效处理和标记这种类型的噪声和多语言输入？token 分类任务是否可行？因此，我们有原始数据的 token 分类任务
是否应该清理数据集以删除这些噪声字符，如何清理？训练模型进行文本分类之后如何清理？因此，我们有两个主要步骤：过滤 + 文本分类任务。使用经典 ML + NN 进行过滤以进行文本分类？
是否有必要为每种语言训练单独的模型，在训练之前可能将字符转换为其真实语言？
如何为训练模型形成合成数据集？手动标记听起来很疯狂]]></description>
      <guid>https://stackoverflow.com/questions/78718328/classification-of-key-press-data-history-on-the-keyboard-to-identify-inappropria</guid>
      <pubDate>Sun, 07 Jul 2024 20:15:34 GMT</pubDate>
    </item>
    <item>
      <title>评估无监督学习 - 播放列表生成器应用程序[关闭]</title>
      <link>https://stackoverflow.com/questions/78718024/evaluate-unsupervised-learning-playlist-generator-app</link>
      <description><![CDATA[我正在为我的简历做一个项目，我想创建一个播放列表生成器应用程序。该应用程序将接收一个播放列表作为输入，并生成一个适合作为输出的播放列表。我的数据将包括从 Spotify for Developers API 中提取的歌曲名称、歌词和歌曲属性，数据集大小约为 150K 个条目。
我正在考虑使用 K-means 来完成这个无监督任务（或另一种无监督算法），以便对于给定的播放列表输入，我可以将歌曲分类为标签，然后从同一标签中选择相似的歌曲。然而，我开始认为这可能会有问题，因为我不知道事后如何评估我的模型。我无法手动创建带标签的测试数据，因为这对我来说不可行，即使可以，给定的播放列表也没有基本事实。
那么当我完成后，我怎么知道我的模型是否在发挥作用？]]></description>
      <guid>https://stackoverflow.com/questions/78718024/evaluate-unsupervised-learning-playlist-generator-app</guid>
      <pubDate>Sun, 07 Jul 2024 17:53:45 GMT</pubDate>
    </item>
    <item>
      <title>ValuerError：发现输入变量的样本数量不一致</title>
      <link>https://stackoverflow.com/questions/78717924/valuererror-found-input-variables-with-inconsistent-numbers-of-samples</link>
      <description><![CDATA[我编写了以下代码来学习机器学习方法中的分数。但是我收到了以下错误。原因是什么？？
ValueError: 发现输入变量的样本数量不一致：[6396, 1599]

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

df = pd.read_csv(&#39;亚美尼亚市场汽车价格.csv&#39;)

df[&#39;汽车名称&#39;] = df[&#39;汽车名称&#39;].astype(&#39;category&#39;).cat.codes

df = df.join(pd.get_dummies(df.FuelType, dtype=int))
df = df.drop(&#39;FuelType&#39;, axis=1)

df[&#39;Region&#39;] = df[&#39;Region&#39;].astype(&#39;category&#39;).cat.codes

df[&#39;价格&#39;] = df.pop(&#39;Price&#39;)

X = df.drop(&#39;Price&#39;, axis=1)
y = df[&#39;Price&#39;]

来自 sklearn.model_selection 导入 train_test_split
来自 sklearn.linear_model 导入 LinearRegression

X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2)
model = LinearRegression()

model.fit(X_train, y_train)

-------------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
Cell In[358]，第 1 行
----&gt; 1 model.fit(X_train, y_train)

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py:1473，在 _fit_context.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(estimator, *args, **kwargs)
1466 estimator._validate_params()
1468 使用 config_context(
1469 skip_parameter_validation=(
1470 prefer_skip_nested_validation 或 global_skip_validation
1471 )
1472 ):
-&gt; 1473 返回 fit_method(estimator, *args, **kwargs)

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\linear_model\_base.py:609，位于 LinearRegression.fit(self, X, y, sample_weight)
605 n_jobs_ = self.n_jobs
607 accept_sparse = False if self.positive else [&quot;csr&quot;, &quot;csc&quot;, &quot;coo&quot;]
--&gt; 609 X, y = self._validate_data(
610 X, y, accept_sparse=accept_sparse, y_numeric=True, multi_output=True
611 )
613 has_sw = sample_weight 不为 None
614 if has_sw:

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py:650，位于 BaseEstimator._validate_data(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)
648 y = check_array(y, input_name=&quot;y&quot;, **check_y_params)
649 else:
--&gt; 650 X, y = check_X_y(X, y, **check_params)
651 out = X, y
653 如果不是 no_val_X 且 check_params.get(&quot;ensure_2d&quot;, True):

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\utils\validation.py:1291，在 check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, Ensure_2d, allow_nd, multi_output, Ensure_min_samples, Ensure_min_features, y_numeric, estimator)
1273 X = check_array(
1274 X,
1275 accept_sparse=accept_sparse,
(...)
1286 input_name=&quot;X&quot;,
1287 )
1289 y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)
-&gt; 1291 check_consistent_length(X, y)
1293 return X, y

文件 ~\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\utils\validation.py:460，位于 check_consistent_length(*arrays)
458 uniques = np.unique(lengths)
459 if len(uniques) &gt; 1:
-&gt; 460 raise ValueError(
461 &quot;找到样本数量不一致的输入变量：%r&quot;
462 % [int(l) for l in lengths]
463 )

ValueError：找到样本数量不一致的输入变量：[6396, 1599]

我尝试了所有方法，但都没有用，或者我不知道如何解决问题。
Jupyternaut：

您提供的错误消息表明输入数据存在问题。具体来说，似乎有两个不同版本的输入数据，一个有 6396 个样本，另一个有 1599 个样本。这可能会在尝试拟合模型或对数据执行其他操作时导致问题。
要解决此问题，您可能需要检查代码并确保对每个操作使用正确版本的输入数据。您可能还想尝试清理输入数据，删除任何重复或不一致的数据。
]]></description>
      <guid>https://stackoverflow.com/questions/78717924/valuererror-found-input-variables-with-inconsistent-numbers-of-samples</guid>
      <pubDate>Sun, 07 Jul 2024 17:09:03 GMT</pubDate>
    </item>
    <item>
      <title>在生物学项目中使用人体细胞实例分割</title>
      <link>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</link>
      <description><![CDATA[我被困在为与生物学相关的项目进行实例分割的过程中。
我有一些人类细胞的图片（每张图片大约有 5 个细胞），我想要实现的是创建一个模型来拍摄这些图片并识别这些细胞。我面临的问题是：我可以让模型识别细胞，但它无法区分不同的细胞。（这意味着作为输出，我得到的 .png 图片要么是 0 代表背景，要么是 1 代表细胞；所以我没有得到关于它们分离的信息）。例如，如果我想计算图片上有多少个单元格，那么这将是一个问题。
澄清一下：我手头有：单元格图片（RGB，.jpg）和 2 种类型的蒙版：第一种是灰度（背景为 0，单元格全部为 1，.png）和 RGB 图片，其中所有单元格都有不同的 RGB 值（如果图片上有 4 个单元格，则存在 4 个不同的 RGB 值；背景始终为 0）。也是 .png。
使用 fastai，我的 DataBlock 如下所示：
dblock = DataBlock(blocks = (ImageBlock, MaskBlock(codes)),
get_items = get_image_files,
splitter = RandomSplitter(),
get_y = get_label,
item_tfms = Resize(224))

dls = dblock.dataloaders(path, bs=5)

问题：我知道此代码无法工作，因为模型输入的灰度图像只有 0 和 1。但我不知道如何合并其他类型的掩码，该掩码实际上包含有关不同细胞分离的信息（所有细胞都是同一类型）。]]></description>
      <guid>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</guid>
      <pubDate>Fri, 05 Jul 2024 10:24:16 GMT</pubDate>
    </item>
    <item>
      <title>如何转换日期格式</title>
      <link>https://stackoverflow.com/questions/78708002/how-to-convert-date-formet</link>
      <description><![CDATA[我正在用 Python 训练模型，下面是我的代码。
#将数据拆分为 x 和 y
x = tsla.drop(&quot;Date&quot;, axis=1)
y = tsla[&#39;Date&#39;]

#将数据拆分为训练和测试
x_train, x_test, y_train, y_tset = train_test_split(x,y, test_size=0.2, random_state=42)

# 模型 
model = LinearRegression()
model.fit(x_train, y_train)

我尝试在 x y 上训练模型。
但这是我的代码得到的错误：
ValueError：无法将字符串转换为浮点数：&#39;2020-03-24&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/78708002/how-to-convert-date-formet</guid>
      <pubDate>Thu, 04 Jul 2024 15:47:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Pytorch 从多幅图像中获取一定数量图像的梯度？而不是所有输入图像的梯度？</title>
      <link>https://stackoverflow.com/questions/78705415/how-can-i-get-the-gradient-of-a-certain-number-of-image-out-of-multiple-images-w</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78705415/how-can-i-get-the-gradient-of-a-certain-number-of-image-out-of-multiple-images-w</guid>
      <pubDate>Thu, 04 Jul 2024 06:39:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 tflite_audio 在 Flutter 中运行 TFLite 模型，原始代码适用于 Python</title>
      <link>https://stackoverflow.com/questions/77054443/running-a-tflite-model-in-flutter-using-tflite-audio-original-code-is-for-pytho</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77054443/running-a-tflite-model-in-flutter-using-tflite-audio-original-code-is-for-pytho</guid>
      <pubDate>Wed, 06 Sep 2023 18:30:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我定义自己的调用函数而没有参数“training”时，我可以使用 model(x, training =True)？</title>
      <link>https://stackoverflow.com/questions/72716154/why-can-i-use-modelx-training-true-when-i-define-my-own-call-function-withou</link>
      <description><![CDATA[请注意，当我创建模型时，我使用参数 something = False 定义了调用函数，当我在函数 train_step 中使用该模型时，我输入了“something =True, training = True”，训练未在我的调用中定义，但它在默认的 tf.keras.model 调用中。
为什么我能够毫无错误地执行此操作？输出基本上打印了一堆“我的调用”。
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

# 添加通道维度
x_train = x_train[..., tf.newaxis].astype(&quot;float32&quot;)
x_test = x_test[..., tf.newaxis].astype(&quot;float32&quot;)

train_ds = tf.data.Dataset.from_tensor_slices(
(x_train, y_train)).shuffle(10000).batch(32)

class MyModel(Model):
def __init__(self):
super(MyModel, self).__init__()
self.fl = Flatten()
self.d = Dense(10)

######我的问题#######
def call(self, x, something=False):
if something:
tf.print(&#39;my call&#39;)
x = self.fl(x)
return self.d(x)

model = MyModel()
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.Adam()

@tf.function
def train_step(X,Y):
with tf.GradientTape() as tape:
######我的问题#######
predictions = model(X, something =True, training = True)
loss = loss_object(Y, predictions)
gradients = tape.gradient(loss, model.trainable_variables)
optimizer.apply_gradients(zip(gradients, model.trainable_variables))

对于范围 (3) 中的 epoch：

对于 train_ds 中的 X、Y：
train_step(X,Y)
]]></description>
      <guid>https://stackoverflow.com/questions/72716154/why-can-i-use-modelx-training-true-when-i-define-my-own-call-function-withou</guid>
      <pubDate>Wed, 22 Jun 2022 13:10:23 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中的 pipeline 和 make_pipeline 有什么区别？</title>
      <link>https://stackoverflow.com/questions/40708077/what-is-the-difference-between-pipeline-and-make-pipeline-in-scikit-learn</link>
      <description><![CDATA[我从 sklearn 网页上获得此信息：

Pipeline：具有最终估算器的转换管道

Make_pipeline：根据给定的估算器构造管道。这是 Pipeline 构造函数的简写。


但我仍然不明白何时必须使用每个管道。有人可以给我举个例子吗？]]></description>
      <guid>https://stackoverflow.com/questions/40708077/what-is-the-difference-between-pipeline-and-make-pipeline-in-scikit-learn</guid>
      <pubDate>Sun, 20 Nov 2016 18:56:16 GMT</pubDate>
    </item>
    </channel>
</rss>