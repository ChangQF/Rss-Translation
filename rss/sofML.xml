<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 19 Jan 2024 12:26:07 GMT</lastBuildDate>
    <item>
      <title>使用 keras 预测任何数字（没有类/标签）</title>
      <link>https://stackoverflow.com/questions/77846035/using-keras-to-predict-any-number-without-classes-labels</link>
      <description><![CDATA[我是 keras 新手，我正在尝试制作一个可以预测人年龄的模型。
有没有办法让 .predict() 预测任何数字，而不是必须给它一个范围或桶（类）来从中选择（预测概率）？
我尝试了（许多变体）提供类/标签，并且预测概率与我的范围（如 0 岁到 100 岁）成线性比例。我也尝试了一整个星期来搜索类似的问题。]]></description>
      <guid>https://stackoverflow.com/questions/77846035/using-keras-to-predict-any-number-without-classes-labels</guid>
      <pubDate>Fri, 19 Jan 2024 12:21:08 GMT</pubDate>
    </item>
    <item>
      <title>基于类的文本生成的最新技术是什么？</title>
      <link>https://stackoverflow.com/questions/77845982/whats-the-state-of-the-art-for-class-based-text-generation</link>
      <description><![CDATA[我正在开发一个项目，我想训练（即微调）一个文本生成模块，类似于马尔可夫链用于文本预测的工作方式。特别是，我有一个由几个类组成的数据集，其中每个类都有一定数量的实例。例如，它可能类似于具有“解释”、“证明”、“QnA”等类别的论文集合。我希望模型能够同时在所有类别上进行微调，并分别预测每个类别的相似文本，而不是在每个类别上训练不同的模型。
我已经使用 LLaMA 搜索了一些解决方案，但我还没有找到任何可以执行此多类任务的东西（也就是说，除了聊天机器人之类的东西，但似乎直接微调是更好的方法）。有没有任何模型能够处理这项任务？或者，在一种元学习方法中微调模型是否是更好的做法，其中训练样本包含带有类名的前缀？]]></description>
      <guid>https://stackoverflow.com/questions/77845982/whats-the-state-of-the-art-for-class-based-text-generation</guid>
      <pubDate>Fri, 19 Jan 2024 12:12:50 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“numpy.ndarray”对象没有属性“_validate_params”</title>
      <link>https://stackoverflow.com/questions/77845905/attributeerror-numpy-ndarray-object-has-no-attribute-validate-params</link>
      <description><![CDATA[当代码调试到这行： self.meta_learner.fit(self.X_train[:, idx[0]], self.y_train) 时，报错：AttributeError: &#39;numpy.ndarray&#39; object has没有属性“_validate_params”
我检查了参数格式没有错误，这和numpy或者scikit-learn的版本有关系吗？]]></description>
      <guid>https://stackoverflow.com/questions/77845905/attributeerror-numpy-ndarray-object-has-no-attribute-validate-params</guid>
      <pubDate>Fri, 19 Jan 2024 12:00:35 GMT</pubDate>
    </item>
    <item>
      <title>在 kaggle 中运行 .ipynb 文件时出现查找错误</title>
      <link>https://stackoverflow.com/questions/77845629/lookup-error-while-running-the-ipynb-file-in-kaggle</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77845629/lookup-error-while-running-the-ipynb-file-in-kaggle</guid>
      <pubDate>Fri, 19 Jan 2024 11:11:35 GMT</pubDate>
    </item>
    <item>
      <title>NLP 的生命周期有哪些不同阶段？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77845526/what-are-different-lifecycle-stages-of-nlp</link>
      <description><![CDATA[NLP 的不同生命周期阶段是什么？
我想要简要解释 NLP 及其生命周期 NLP 及其不同的生命周期 Natural Language API 允许您轻松地将 NLU 应用到您的应用程序中。自然语言 API 使用机器学习来揭示含义和含义。 text.API的结构]]></description>
      <guid>https://stackoverflow.com/questions/77845526/what-are-different-lifecycle-stages-of-nlp</guid>
      <pubDate>Fri, 19 Jan 2024 10:54:21 GMT</pubDate>
    </item>
    <item>
      <title>我有一个由 12 列组成的数据集，现在我想训练我的模型，这样如果输入任何类型的提示，它就会从 1 列生成信息 [关闭]</title>
      <link>https://stackoverflow.com/questions/77845089/i-have-a-dataset-which-consists-of-12-columns-now-i-want-train-my-model-such-th</link>
      <description><![CDATA[我的列是：主题；描述;介绍; SOW（工作范围）；除外情况；标题;描述1；描述2；产品;描述3；描述4；描述5.现在，我想在这个数据集上训练我的模型，当我在 Prompt 中输入任何列的信息时，它会生成并给我 SOW，即使 Prompt 包含不属于训练数据集的内容，它也会生成 SOW。至少尝试产生某种类型的工作范围。
下面是数据集的示例，即它是数据集的一行：
例如
主题：空调改造
描述：不适用
简介：根据您的请求和我们的后续调查。我们现在很高兴提交报价，以便在上述地址进行机械服务修改
母猪：--&gt; 4个寄存器的搬迁--&gt;供应和安装 1 个收银机 --&gt; 供应和安装 3 个门传递格栅
排除情况：--&gt;除非另有说明，否则在正常工作时间之外工作。 --&gt;未列入上述范围的作品 --&gt;系统安装所需以外的建筑工程 --&gt;绘画或修补 --&gt;如有必要，对配电盘或电源进行电气升级 --&gt;现有管道系统和调节器的空气平衡（如有必要） --&gt;除非另有说明，否则保留、违约金和间接损失除外。 --&gt;除非另有说明，提供设备的安全访问仍然是建筑物业主及其代理人的责任。 --&gt;如果在执行报价工作时发现有缺陷，则对上述报价中未详细说明的任何设备进行维修或更换。
标题：St. Vincent&#39;s - 用于楼梯间增压风扇 3-2 的 VSD
描述1：St. Vincent&#39;s - 楼梯间增压风机3-2的VSD
描述2：不适用
产品：管道工程/格栅/Flexs
描述3：EC电源
描述4：大金FDYQ160LB-AV
描述5：每次测试成本 5.50 美元
我尝试通过引用其他列来训练模型，但生成的输出无法生成 SOW，而我只想要 SOW。]]></description>
      <guid>https://stackoverflow.com/questions/77845089/i-have-a-dataset-which-consists-of-12-columns-now-i-want-train-my-model-such-th</guid>
      <pubDate>Fri, 19 Jan 2024 09:42:32 GMT</pubDate>
    </item>
    <item>
      <title>OpenFL 连接/设置</title>
      <link>https://stackoverflow.com/questions/77845060/openfl-connection-setup</link>
      <description><![CDATA[我们对联合学习非常陌生，我们希望使用 OpenFL 框架设置 2 个不同的设备（笔记本电脑）作为聚合器和协作器。我们已经为同一任务安装了所有必需的库，但没有找到任何教程可以帮助我们解决同样的问题。有人可以帮助我们解决这个问题吗？
我们甚至不确定如何开始解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77845060/openfl-connection-setup</guid>
      <pubDate>Fri, 19 Jan 2024 09:37:39 GMT</pubDate>
    </item>
    <item>
      <title>多个数据帧的机器学习模型选择[关闭]</title>
      <link>https://stackoverflow.com/questions/77844465/machine-learning-model-selection-for-multiple-dataframes</link>
      <description><![CDATA[我需要帮助

为不在单个数据框中的数据选择并创建模型。
应如何构建数据以便在所选模型中使用

现在，我有 365 个数据帧，每个数据帧包含 30 行。每一行代表未来的一天。
数据框包含 4 个特征和目标。主要特征是未来30天每天的订单量。
目标是实际销量。其他功能与此处无关。
为此目的最好的模型是什么，其目的是预测未来的销售额，
当我们知道未来 30 天内有多少订单并且我们还有其他 4 个功能可用时。
可以通过 Randomforest/Gradboost 等以某种方式完成此操作，以便模型能够学习该行为吗？
我想这些类型的模型的数据必须位于单个数据框中？
或者这应该通过某种类型的神经网络来完成？什么类型的神经网络最适合？
欢迎任何有关如何组织输入数据以及应使用什么类型的模型的 Python 示例！
编辑！
例如，对于日期 2016-03-03 和 2016-03-04 数据框的头部如下所示（实际销售额是目标，其他是功能）：

]]></description>
      <guid>https://stackoverflow.com/questions/77844465/machine-learning-model-selection-for-multiple-dataframes</guid>
      <pubDate>Fri, 19 Jan 2024 07:49:02 GMT</pubDate>
    </item>
    <item>
      <title>神经网络无法正确学习[关闭]</title>
      <link>https://stackoverflow.com/questions/77844067/neural-network-not-learning-properly</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77844067/neural-network-not-learning-properly</guid>
      <pubDate>Fri, 19 Jan 2024 06:15:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么过滤pandas文件的输出变成NaN？</title>
      <link>https://stackoverflow.com/questions/77843589/why-the-output-of-filtering-pandas-file-becomes-nan</link>
      <description><![CDATA[我希望输出变为非 NaN 值。
这一行的问题
f_bp_max.loc[l, &#39;max&#39;] = df_frcst[df_frcst[&#39;日期时间&#39;].dt.year == k][&#39;预测&#39;].max()

当我打印这个时：
df_frcst[df_frcst[&#39;日期时间&#39;].dt.year == k][&#39;预测&#39;]

输出是：
系列（[]，名称：预测，dtype：float64）

导入 pandas 作为 pd
导入时间
导入日期时间
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
从 scipy.optimize 导入最小化标量

开始时间 = 时间.time()

pct_选择 = 0.98

#* 数据预测
df_frcst = pd.read_csv(&#39;lstm_forecast_results.csv&#39;)
df_frcst[&#39;日期时间&#39;] = pd.to_datetime(df_frcst[&#39;日期时间&#39;])
df_frcst_simple = df_frcst[[&#39;日期时间&#39;, &#39;预测&#39;]]
df_frcst_simple = df_frcst_simple.rename({&#39;日期时间&#39;:&#39;waktu&#39;, &#39;预测&#39;:&#39;bp&#39; }, axis = 1)



df_bp_max = pd.DataFrame()
对于范围 (2024, 2034, 1) 内的 k：
    l = k - 2024
    df_bp_max.loc[l, &#39;tahun&#39;] = str(k)
    df_bp_max.loc[l, &#39;max&#39;] = df_frcst[df_frcst[&#39;日期时间&#39;].dt.year == k][&#39;预测&#39;].max()
    df_bp_max.loc[l, &#39;min&#39;] = df_frcst[df_frcst[&#39;日期时间&#39;].dt.year == k][&#39;预测&#39;].min()
#df_bp_max[&#39;LF&#39;] = df_bp_max[&#39;min&#39;]/df_bp_max[&#39;max&#39;]
df_bp_max[&#39;tahun&#39;] = df_bp_max[&#39;tahun&#39;].apply(str)
#df_bp_max = df_bp_max.set_index(&#39;tahun&#39;)

打印（“================================================ ================》）
打印（df_bp_max）

输入文件
日期时间、实际、预测
2022-01-01 12:30:00,17809.0,17343.484
2022-01-01 13:00:00,17772.61,17382.861
2022-01-01 13:30:00,17867.8,17414.637
2022-01-01 14:00:00,17773.68,17504.357
2022-01-01 14:30:00,17869.88,17530.559
2022-01-01 15:00:00,17786.7,17592.822
2022-01-01 15:30:00,17943.11,17626.775
2022-01-01 16:00:00,18125.29,17686.678
2022-01-01 16:30:00,18463.05,17760.666
2022-01-01 17:00:00,18786.99,17892.475
2022-01-01 17:30:00,19238.97,18048.4
2022年1月1日 18
......

输出：
&lt;前&gt;&lt;代码&gt;============================================== =================
  塔洪最大最小值
0 2024 南 南
1 2025 南 南
2 2026 南 南
3 2027 南 南
4 2028 南 南
5 2029 南 南
6 2030 南 南
7 2031 南 南
8 2032 南 南
9 2033 南 南

这一行都没有 NaN 值，因为我的输入文件不为空]]></description>
      <guid>https://stackoverflow.com/questions/77843589/why-the-output-of-filtering-pandas-file-becomes-nan</guid>
      <pubDate>Fri, 19 Jan 2024 03:40:25 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：给定 groups=1，权重大小为 [128, 64, 4, 4]，预期输入 [1, 128, 65, 65] 有 64 个通道，但得到了 128 个通道</title>
      <link>https://stackoverflow.com/questions/77843263/runtimeerror-given-groups-1-weight-of-size-128-64-4-4-expected-input1</link>
      <description><![CDATA[运行以下代码时：
类 NLayerDiscriminator(nn.Module):
    def __init__(self, input_nc, ndf=64, n_layers=3,norm_layer=nn.BatchNorm2d, use_sigmoid=False):
        超级（NLayerDiscriminator，自我）.__init__（）
        self.n_layers = n_layers

        千瓦=4
        padw = int(np.ceil((kw-1.0)/2))
        self.conv1=nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw)
        self.act=nn.LeakyReLU(0.2, True)
        
        nf=min(ndf*2,512)
        self.conv2=nn.Conv2d(ndf, nf, kernel_size=kw, stride=2, padding=padw)
        self.norm1=norm_layer(nf)
        
        ngf=min(nf*2,512)
        self.conv3=nn.Conv2d(nf, ngf, kernel_size=kw, stride=1, padding=padw)
        self.norm2=norm_layer(ngf)
        self.conv4=nn.Conv2d(ngf, 1, kernel_size=kw, stride=1, padding=padw)
        self.sig=nn.Sigmoid()
        

    def 前向（自身，输入）：
        x=self.conv1(输入)
        x=self.act(x)
        
        对于范围 (1, 3) 中的 n：
            x=self.conv2(x)
            x=self.norm1(x)
            x=self.act(x)
        
        x=self.conv3(x)
        x=self.norm(x)
        x=self.act(x)
        x=self.conv4(x)
        如果使用_sigmoid：
            x=self.sig(x)
        返回x

我收到以下错误
RuntimeError：给定 groups=1，权重大小为 [128, 64, 4, 4]，预期输入 [1, 128, 65, 65] 有 64 个通道，但得到了 128 个通道]]></description>
      <guid>https://stackoverflow.com/questions/77843263/runtimeerror-given-groups-1-weight-of-size-128-64-4-4-expected-input1</guid>
      <pubDate>Fri, 19 Jan 2024 01:31:36 GMT</pubDate>
    </item>
    <item>
      <title>在 VertexAI 多线程上部署 ML 模型</title>
      <link>https://stackoverflow.com/questions/77839685/deployed-ml-model-on-vertexai-multithreading</link>
      <description><![CDATA[我需要将模型部署到 VertexAI。预测端点将被不同的 Kubernetes Pod 多次调用。
我想了解部署的模型处理并发的能力如何。托管模型的实例是否会根据每个请求将模型加载到内存中？多个请求能得到很好的处理吗？在深入了解工作流程之前，我试图了解这一点。
进行了大量的研究，但目前还没有明确的答案。我发现下面的文章中用户似乎处理并发请求。然而，我仍然很困惑。在线预测似乎是同步的，所以我认为它无法处理并发请求。 
https://medium.com/mlearning-ai/serverless-prediction-at-scale-part-2-custom-container-deployment-on-vertex-ai-103a43d0a290]]></description>
      <guid>https://stackoverflow.com/questions/77839685/deployed-ml-model-on-vertexai-multithreading</guid>
      <pubDate>Thu, 18 Jan 2024 13:15:04 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit-learn 中对线性回归模型使用交叉验证</title>
      <link>https://stackoverflow.com/questions/77829091/how-to-use-cross-validation-on-linear-regression-model-in-scikit-learn</link>
      <description><![CDATA[我想在 scikit learn 中使用网格搜索交叉验证进行训练线性回归模型可以说是 10 倍，就像我分享的图像中一样。
但是当我这样做时，我得到：
spipe = 管道([
    （&#39;缩放&#39;，StandardScaler（）），
    (&#39;模型&#39;, 线性回归())
]）

网格 = GridSearchCV(
    估计器=管道，
    简历=4
）

网格.fit(X,Y)

类型错误：GridSearchCV.__init__() 缺少 1 个必需参数：&#39;param_grid&#39;

所以我的理解是它想要迭代 LinearRegression 模型的可能参数，我应该将它们放入 param_grid 中。
但我不想为每次折叠调整参数。相反，我想简单地按照照片所示进行操作：进行 10 次折叠并对其进行 10 次训练和验证，以便模型微调 1 个线性回归多项式（我想这就是模型内部发生的情况）。
我尝试使用cross_val_score，但它似乎在 10 次折叠上训练 10 次，因为它返回 10 个分数而不是 1 个分数（所以我猜测 10 个线性回归多项式，每个折叠 1 个）。 
总而言之，如何将折叠交叉验证方法与线性回归结合使用？
如果有人需要，这里是设置：
从 sklearn.linear_model 导入 LinearRegression
从 sklearn.datasets 导入 fetch_california_housing
将 pandas 导入为 pd
从 sklearn.pipeline 导入管道
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.model_selection 导入 GridSearchCV

加利福尼亚州 = fetch_california_housing()

pd.set_option(&#39;显示.精度&#39;, 4)
pd.set_option(&#39;display.max_columns&#39;, 9)
pd.set_option(&#39;display.width&#39;, None)
california_df = pd.DataFrame(california.data,
                             列=加利福尼亚.feature_names）
california_df[&#39;MedHouseValue&#39;] = pd.Series(california.target)
X = 加利福尼亚州. 数据
Y = 加利福尼亚.目标
]]></description>
      <guid>https://stackoverflow.com/questions/77829091/how-to-use-cross-validation-on-linear-regression-model-in-scikit-learn</guid>
      <pubDate>Tue, 16 Jan 2024 22:44:50 GMT</pubDate>
    </item>
    <item>
      <title>子类化 keras.model 以创建具有多列输入的自定义自回归 LSTM 模型</title>
      <link>https://stackoverflow.com/questions/76957152/subclassing-keras-model-to-create-a-custom-autoregressive-lstm-model-with-multi</link>
      <description><![CDATA[我正在尝试创建一个模型来根据天气数据预测能源电网负载（电网消耗的净电量）。在生产中，我们没有负载数据来进行标准批量预测。我们正在尝试一种自回归方法，以便我们可以向其提供最后报告的负载读数和未来 24 小时的预测天气数据，以生成 24 小时的负载预测。
我正在使用本教程，建议对模型进行子类化类进行逐步预测。我相信 model.fit 文档也建议子类化。
上面的教程创建了一个名为 Feedback 的 keras.model 子类，并覆盖了 model.call() 方法，该方法在训练和预测期间调用。
def call(自我，输入，训练=无)：
  # 使用 TensorArray 捕获动态展开的输出。
  预测=[]
  # 初始化 LSTM 状态。
  预测，状态 = self.warmup(输入)

  # 插入第一个预测。
  预测.append(预测)

  # 运行其余的预测步骤。
  对于范围内的n（1，self.out_steps）：
    # 使用最后的预测作为输入。
    x = 预测
    # 执行一个lstm步骤。
    x，状态= self.lstm_cell（x，状态=状态，
                              训练=训练）
    # 将 lstm 输出转换为预测。
    预测 = self.dense(x)
    # 将预测添加到输出中。
    预测.append(预测)

  # 预测.shape =&gt; （时间、批次、特征）
  预测 = tf.stack(预测)
  # 预测.shape =&gt; （批次、时间、特征）
  预测 = tf.transpose(预测, [1, 0, 2])
  返回预测


调用 fit() 时，我传入数据集进行训练和验证。通过 keras.utils.timeseries_dataset_from_array() 创建的数据集。
history = model.fit(dataset_train, epochs=epochs,
                    验证数据=数据集_val，
                    回调=[es_callback, modelckpt_callback])

我的数据形状是每小时的时间序列数据、11列天气数据和1列目标。我使用的窗口大小为两个小时。
我的问题是，for 循环中的预测调用似乎仅使用先前的预测作为输入。我不明白他们如何访问训练或验证数据集。
我尝试在 Pycharm 调试器中查找访问数据集的方法，但没有找到任何内容。我也尝试寻找进行类似子类化的人，但本教程是我能找到的最好的教程。
如果需要运行示例，该教程将介绍数据集创建和子类实现。我希望有人可以解释如何正确地对 keras.model 进行子类化（以与该教程类似的方式）以获取多列输入并进行自回归预测。 call() 方法的重写是我最困惑的地方。]]></description>
      <guid>https://stackoverflow.com/questions/76957152/subclassing-keras-model-to-create-a-custom-autoregressive-lstm-model-with-multi</guid>
      <pubDate>Tue, 22 Aug 2023 22:18:42 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 简单线性 Sigmoid 网络不学习</title>
      <link>https://stackoverflow.com/questions/64269084/pytorch-simple-linear-sigmoid-network-not-learning</link>
      <description><![CDATA[我正在学习 pytorch 并尝试将网络训练为异或门。一切都进行得很顺利，但它就是不学习。它确实改变了它的权重，但它会收敛到每个输入的结果，这远远超出了预期结果。
我尝试过许多学习率和权重初始化。
因此输入是 A 门和 B 门，如果两者相等则应返回 1，否则应返回 0，如下所示：
&lt;前&gt;

    [0,0] =&gt; 1
    [0,1] =&gt; 0
    [1,0] =&gt; 0
    [1,1] =&gt; 1


这是我对模型进行建模和训练的尝试：
&lt;前&gt;

    导入火炬作为火炬
    将 torch.nn 导入为 nn
    
    网络类（nn.Module）：
        
        def __init__(自身):
            超级（网络，自我）.__init__()
            self.x1 = nn.Linear(2,4)
            self.s1 = nn.Sigmoid()
            self.x2 = nn.Linear(4,1)
            self.s2 = nn.Sigmoid()
        
        定义初始化（自身）：
            nn.init.uniform_(self.x1.weight)
            nn.init.uniform_(self.x2.weight)
    
        def前锋（自我，功绩）：
            f1 = torch.tensor(feats).float()
            xr1= 自身.x1(f1)
            xs1= self.s1(xr1)
            xr2= 自身.x2(xs1)
            输出 = self.s2(xr2)
            返回
    
        def 火车（自我，val_expected，feats_next）：
            val_expected_tensor = torch.tensor(val_expected)
            标准 = nn.MSELoss()
            优化器 = torch.optim.SGD(self.parameters(), lr=0.01)
            def 闭包():
                优化器.zero_grad()
                resp = self.forward(feats_next)
                误差 = 标准（分别，val_expected_tensor）
                error.backward()
                返回错误
            优化器.step(闭包)
    
    网络=网络（）
    .net.init()
    
    对于 ([0.,0.],[0.,1.],[1.,0.],[1.,1.]) 中的输入：
        响应=net.forward（输入）
        打印（响应）
    
    打印（“--火车开始-”）
    对于范围（1000）内的 i：
        net.train([1.],[0.,0.])
        net.train([0.],[1.,0.])
        net.train([0.],[0.,1.])
        net.train([1.],[1.,1.])
    print (&quot;---火车结束---&quot;)
    
    对于 ([0.,0.],[0.,1.],[1.,0.],[1.,1.]) 中的输入：
        响应=net.forward（输入）
        打印（响应）


这是一次以 0.001 学习率进行 100000 次迭代的运行：
&lt;前&gt;

    张量([0.7726], grad_fn=)
    张量([0.7954], grad_fn=)
    张量([0.8229], grad_fn=)
    张量([0.8410], grad_fn=)
    --列车启动-
    *.........*........*.........*.........*......... *.........*........*.........*.........*.........
    ---火车结束---
    张量([0.6311], grad_fn=)
    张量([0.6459], grad_fn=)
    张量([0.6770], grad_fn=)
    张量([0.6906], grad_fn=)


我真的迷路了。这不应该起作用吗？]]></description>
      <guid>https://stackoverflow.com/questions/64269084/pytorch-simple-linear-sigmoid-network-not-learning</guid>
      <pubDate>Thu, 08 Oct 2020 19:04:05 GMT</pubDate>
    </item>
    </channel>
</rss>