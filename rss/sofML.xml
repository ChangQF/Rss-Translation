<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Mon, 30 Sep 2024 01:18:08 GMT</lastBuildDate>
    <item>
      <title>Ibm Watson/IBM cloud pak æ•°æ®é”™è¯¯</title>
      <link>https://stackoverflow.com/questions/79036541/error-in-ibm-watson-ibm-cloud-pak-for-data</link>
      <description><![CDATA[æˆ‘é‡åˆ°äº†æ­¤é”™è¯¯ï¼šé”™è¯¯ï¼šæå–æ•°æ®å•ä¸ªä½ç½®ç´¢å¼•å™¨è¶…å‡ºèŒƒå›´ã€‚
æˆ‘ä¸ç¡®å®šä¸ºä»€ä¹ˆã€‚æˆ‘çš„ CSV æ–‡ä»¶æ˜¯ 3 åˆ— X 200 è¡Œã€‚è¿™æ˜¯æ–‡ä»¶å†…å®¹çš„ç¤ºä¾‹ï¼š
å•è¯åç§°é¢œè‰²
â€œAardvarkâ€ â€œAlabama Crimsonâ€ â€œ#a32638â€ 

æˆ‘é—æ¼äº†ä»€ä¹ˆï¼Ÿæˆ‘è¯¥å¦‚ä½•çº æ­£æ­¤é”™è¯¯ï¼Ÿ
æˆ‘åˆå¹¶äº†ä¸¤ä¸ªæ•°æ®é›†ï¼Œç„¶åç¼©çŸ­äº†æ•°æ®é›†ä»¥è§£å†³ä¹‹å‰çš„é”™è¯¯ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79036541/error-in-ibm-watson-ibm-cloud-pak-for-data</guid>
      <pubDate>Sun, 29 Sep 2024 13:47:17 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨æ¨¡ç³Šé€»è¾‘å’Œäººå·¥æ™ºèƒ½è¿›è¡Œåç§°åŒ¹é…è¯„åˆ†</title>
      <link>https://stackoverflow.com/questions/79036523/name-matching-score-using-fuzzy-logic-and-ai</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ª excelï¼Œé‡Œé¢æœ‰ä¸¤ä¸ªå§“ååˆ—å’Œä¸€ä¸ªæ˜¾ç¤ºä¸¤ä¸ªå§“åçš„å§“ååŒ¹é…åˆ†æ•°çš„åˆ—ï¼Œå³ä¸¤ä¸ªæ•°å­—åŒ¹é…çš„ç™¾åˆ†æ¯”ã€‚
æˆ‘éœ€è¦ä¸€ä¸ªç”¨ Python ç¼–å†™çš„æœºå™¨å­¦ä¹ ä»£ç ï¼Œè¯¥ä»£ç å¯ä»¥åœ¨è¿™ä¸ª excel ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”èƒ½å¤Ÿé¢„æµ‹å§“ååŒ¹é…åˆ†æ•°çš„è¿›ä¸€æ­¥å€¼ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79036523/name-matching-score-using-fuzzy-logic-and-ai</guid>
      <pubDate>Sun, 29 Sep 2024 13:44:05 GMT</pubDate>
    </item>
    <item>
      <title>XFormersMetadata.__init__() æ”¶åˆ°æ„å¤–çš„å…³é”®å­—å‚æ•°â€œis_promptâ€</title>
      <link>https://stackoverflow.com/questions/79036452/xformersmetadata-init-got-an-unexpected-keyword-argument-is-prompt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79036452/xformersmetadata-init-got-an-unexpected-keyword-argument-is-prompt</guid>
      <pubDate>Sun, 29 Sep 2024 13:03:20 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨ R pROC ä¸­å»ºç«‹å¤šå› ç´ æ¨¡å‹ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79036243/how-to-make-a-multifactor-model-in-r-proc</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªæ•°æ®è¡¨ï¼Œå…¶ä¸­åŒ…å«å“åº”â€œyâ€å’Œä¸€äº›é¢„æµ‹å˜é‡ï¼Œå…¶ä¸­åŒ…æ‹¬â€œX1â€å’Œâ€œX2â€ã€‚æˆ‘å¯ä»¥ä½¿ç”¨ pROC åˆ›å»ºä¸¤ä¸ªå•å› ç´ æ¨¡å‹ï¼š
roc1 &lt;- roc(data$y, data$X1)
roc2 &lt;- roc(data$y, data$X2)

ä½†æˆ‘æ­£åœ¨å°è¯•è®¡ç®—åŒå› ç´ æ¨¡å‹çš„ ROC AUCï¼š
t1 = data$X1
t2 = data$X2
t12 = cbind(t1, t2)
roc12 &lt;- roc(data$y, t12)

å¹¶æ”¶åˆ°ä¸€æ¡é”™è¯¯æ¶ˆæ¯ï¼š
å“åº”å’Œé¢„æµ‹å˜é‡å¿…é¡»æ˜¯é•¿åº¦ç›¸åŒçš„å‘é‡ã€‚

æœ‰æ²¡æœ‰åŠæ³•åœ¨ pROC ä¸­åˆ¶ä½œå¤šå› ç´ æ¨¡å‹ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79036243/how-to-make-a-multifactor-model-in-r-proc</guid>
      <pubDate>Sun, 29 Sep 2024 11:16:18 GMT</pubDate>
    </item>
    <item>
      <title>RubixML æ¨¡å‹åœ¨ PHP ä¸­å§‹ç»ˆè¿”å›ç›¸åŒçš„é¢„æµ‹</title>
      <link>https://stackoverflow.com/questions/79035928/rubixml-model-always-return-the-same-prediction-in-php</link>
      <description><![CDATA[æˆ‘å°è¯•ä½¿ç”¨ https://rubixml.com/ æå–ä¸åŒå¥å­çš„äº§å“ä»·æ ¼ï¼Œä½†å®ƒæ€»æ˜¯è¿”å› 260ï¼Œè¿™æ˜¯æˆ‘ç»™å®ƒçš„ç¬¬ä¸€ä¸ªæ ‡ç­¾
&lt;?php
include_once &#39;../vendor/autoload.php&#39;;

use Rubix\ML\Datasets\Labeled;
use Rubix\ML\Datasets\Unlabeled;
use Rubix\ML\Classifiers\KNearestNeighbors;
use Rubix\ML\Transformers\WordCountVectorizer;
use Rubix\ML\Transformers\TfIdfTransformer;
use Rubix\ML\Pipeline;
use Rubix\ML\Extractors\CSV;

$samples= [&#39;ä»·æ ¼æ˜¯ 260&#39;,&#39;æˆæœ¬æ˜¯ 500&#39;,&#39;è¿™ä»¶è¡¬è¡«çš„æˆæœ¬æ˜¯ 300&#39;,&#39;è¿™ä»¶å•†å“çš„ä»·å€¼æ˜¯ 450&#39;,&#39;å”®ä»· 150 ç¾å…ƒ&#39;];
$labels = [&#39;260&#39;, &#39;500&#39;, &#39;300&#39;, &#39;450&#39;, &#39;150&#39;];

$dataset = new Labeled($samples, $labels);

// ç”Ÿæˆæ¨¡å‹
$pipeline = new Pipeline([
new WordCountVectorizer(100),
new TfIdfTransformer(),
], new KNearestNeighbors(3));

// ä½¿ç”¨æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
$pipeline-&gt;train($dataset);

// åˆ†ææ–°çš„ frace
$new = Unlabeled::build([
[&#39;ä»·æ ¼ï¼š1200&#39;],
]);

// é¢„æµ‹
$predictions = $pipeline-&gt;predict($new);
var_dump($predictions);

æˆ‘æ›´æ”¹äº† KNearestNeighbors çš„å€¼ï¼Œä¸ºè®­ç»ƒæ•°æ®é›†æä¾›äº†æ›´å¤§çš„è¾“å…¥ï¼Œæ›´æ”¹äº† Vectorizerã€‚ä½†ä»€ä¹ˆéƒ½æ²¡æœ‰æ”¹å˜ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79035928/rubixml-model-always-return-the-same-prediction-in-php</guid>
      <pubDate>Sun, 29 Sep 2024 08:25:35 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ python å’Œ scikit-image åœ¨ xray å›¾åƒä¸Šåˆ†å‰²è‚ºéƒ¨å¯¹è±¡æ—¶å‡ºç°é—®é¢˜[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79035911/problem-when-segmenting-lung-objects-on-xray-images-using-python-and-scikit-ima</link>
      <description><![CDATA[å¦‚ä½•åˆ†å‰²è‚ºéƒ¨åˆ‡ç‰‡ï¼Ÿæˆ‘å°è¯•äº†å‡ æ¬¡ï¼Œä½†æ•ˆæœå¹¶ä¸å®Œç¾ã€‚è¿™æ˜¯å› ä¸ºè‚ºéƒ¨å‰éƒ¨çš„éª¨å¤´éƒ¨åˆ†ã€‚
è‚ºéƒ¨å›¾åƒ
æˆ‘å°è¯•æ¨¡ç³Šå›¾åƒä»¥ä½¿éª¨å¤´æ›´é€æ˜ï¼Œä½†å®ƒå½±å“äº†ç‰©ä½“çš„å‘¨å›´ç¯å¢ƒã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79035911/problem-when-segmenting-lung-objects-on-xray-images-using-python-and-scikit-ima</guid>
      <pubDate>Sun, 29 Sep 2024 08:16:12 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•é’ˆå¯¹æ¯ä¸ªæ•°æ®é›†çš„æ¯æ¬¡è®­ç»ƒè¿­ä»£è®­ç»ƒ LSTM è‡ªåŠ¨ç¼–ç å™¨</title>
      <link>https://stackoverflow.com/questions/79035730/how-can-i-train-an-lstm-autoencoder-for-each-iteration-of-training-with-each-dat</link>
      <description><![CDATA[æè¿°
æˆ‘ä¸€ç›´åœ¨å°è¯•æ„å»ºå’Œè®­ç»ƒ LSTM è‡ªåŠ¨ç¼–ç å™¨ã€‚è™½ç„¶æˆ‘ä½¿ç”¨çš„å‚è€ƒä»…è®­ç»ƒäº†ä¸€æ¬¡æ¨¡å‹ï¼Œä½†æˆ‘æ·»åŠ äº†ä¸€ä¸ªå‡½æ•°ï¼Œå¦‚æœæ¯ä¸ªæ•°æ®é›†çš„æ¯æ¬¡è®­ç»ƒè¿­ä»£éƒ½ç»“æŸï¼Œåˆ™å¤šæ¬¡è¿è¡Œè®­ç»ƒã€‚
ä¸è¿‡ï¼Œæˆ‘å¹¶ä¸ç¡®å®šæˆ‘æ˜¯å¦èµ°åœ¨æ­£ç¡®çš„è½¨é“ä¸Šã€‚æ„Ÿè§‰æˆ‘çš„ä»£ç åœ¨æ¯æ¬¡è¿­ä»£æ—¶éƒ½æœ‰å¯èƒ½è¦†ç›–è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚
é—®é¢˜
æ‰€ä»¥æˆ‘æƒ³é—®ä¸€ä¸‹ä¸‹é¢çš„ Python ä»£ç æ˜¯å¦çœŸçš„åœ¨ç”¨æ¯ä¸ªæ•°æ®é›†å¯¹æ¯ä¸ªè¿­ä»£è¿›è¡Œè®­ç»ƒï¼ˆæœ‰ 75 ä¸ª CSV æ–‡ä»¶å¯ç”¨äºè®­ç»ƒæ­¤æ¨¡å‹ï¼‰ã€‚
ä»¥ä¸‹æ˜¯æˆ‘åœ¨å•ä¸ªå‡½æ•°ï¼ˆtrainModel()ï¼‰å†…æ·»åŠ çš„ç”¨äºæ„å»ºå’Œè®­ç»ƒæ¨¡å‹çš„ Python ä»£ç 
from sklearn.preprocessing import StandardScaler 
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout, RepeatVector, TimeDistributed
from tensorflow.keras.callbacks import EarlyStopping

# LSTM ç½‘ç»œä»¥è¾“å…¥å½¢çŠ¶ç›¸ç­‰é—´éš”çš„å­åºåˆ—çš„å½¢å¼è·å–è¾“å…¥ï¼ˆn_sampleã€n_timestepsã€featuresï¼‰ã€‚
# æˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹è‡ªå®šä¹‰å‡½æ•°æ¥åˆ›å»ºè¿™äº›åºåˆ—
def create_sequences(X, y, time_steps=1):
Xs, ys = [], []
for i in range(len(X) - time_steps):
v = X.iloc[i:(i + time_steps)].values
Xs.append(v)
ys.append(y.iloc[i + time_steps])
return np.array(Xs), np.array(ys)

def trainModel():
for i in range(75):
fileList = pd.read_csv(&quot;/content/drive/MyDrive/fileList.csv&quot;)
filename = fileList.iloc[i, 0]
temp = pd.read_csv(&quot;/content/drive/MyDrive/dataFolder/&quot;+filename+&quot;.csv&quot;)
train_size = int(len(temp[[&quot;time_abs(%Y-%m-%dT%H:%M:%S.%f)&quot;, &quot;velocity(m/s)&quot;]]))
train = df.iloc[0:train_size]

# è§„èŒƒåŒ–æ•°æ®
scalar = StandardScaler()
scalar = scalar.fit(train[[&#39;velocity(m/s)&#39;]])

train[&#39;velocity(m/s)&#39;] = scalar.transform(train[[&#39;velocity(m/s)&#39;]])

time_steps = 30

X_train, y_train = create_sequences(train[[&#39;velocity(m/s)&#39;]],train[&#39;velocity(m/s)&#39;],time_steps)

# æ„å»º LSTM è‡ªåŠ¨ç¼–ç å™¨

# è‡ªåŠ¨ç¼–ç å™¨æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œæ¨¡å‹æ—¨åœ¨å­¦ä¹ è¾“å…¥çš„å‹ç¼©è¡¨ç¤ºã€‚
# å®ƒä»¬ä½¿ç”¨ç›‘ç£å­¦ä¹ æ–¹æ³•è¿›è¡Œè®­ç»ƒï¼Œç§°ä¸ºè‡ªç›‘ç£ã€‚
# åœ¨è¿™ç§æ¶æ„ä¸­ï¼Œç¼–ç å™¨ LSTM æ¨¡å‹é€æ­¥è¯»å–è¾“å…¥åºåˆ—ã€‚
# è¯»å–æ•´ä¸ªè¾“å…¥åºåˆ—åï¼Œæ­¤æ¨¡å‹çš„éšè—çŠ¶æ€æˆ–è¾“å‡ºè¡¨ç¤º
# æ•´ä¸ªè¾“å…¥åºåˆ—çš„å†…éƒ¨å­¦ä¹ è¡¨ç¤ºä¸ºå›ºå®šé•¿åº¦å‘é‡ã€‚
# ç„¶åå°†æ­¤å‘é‡ä½œä¸ºè¾“å…¥æä¾›ç»™è§£ç å™¨æ¨¡å‹ï¼Œè§£ç å™¨æ¨¡å‹å°†å…¶è§£é‡Šä¸ºè¾“å‡ºåºåˆ—ä¸­çš„æ¯ä¸ªæ­¥éª¤
# ç”Ÿæˆã€‚
# timesteps = X_train.shape[1]
num_features = X_train.shape[2]

model = Sequential()
model.add(LSTM(128,input_shape=(timesteps,num_features)))
model.add(Dropout(0.2))
model.add(RepeatVector(timesteps)) # é‡å¤è¾“å…¥ n æ¬¡ã€‚
model.add(LSTM(128,return_sequences=True))
model.add(Dropout(0.2))
model.add(TimeDistributed(Dense(num_features))) # å°†å±‚åº”ç”¨äºè¾“å…¥çš„æ¯ä¸ªæ—¶é—´ç‰‡æ®µã€‚

model.compile(loss=&#39;mae&#39;,optimizer=&#39;adam&#39;)

# è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨
early_stop = EarlyStopping(monitor=&#39;val_loss&#39;,patience=3,mode=&#39;min&#39;) # å¦‚æœç›‘æ§æŒ‡æ ‡ç›¸å¯¹äºåº”ç”¨çš„ 3 ä¸ªæ—¶æœŸçš„æ¨¡å¼æ²¡æœ‰å˜åŒ–ï¼Œåˆ™åœæ­¢è®­ç»ƒ
history = model.fit(X_train,y_train,epochs=100,batch_size=32,validation_split=0.1,callbacks=[early_stop],shuffle=False)

model.save(&#39;anomaly_model.h5&#39;, overwrite=False)
model.save(&#39;anomaly_model_&#39;+ i +&#39;.h5&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/79035730/how-can-i-train-an-lstm-autoencoder-for-each-iteration-of-training-with-each-dat</guid>
      <pubDate>Sun, 29 Sep 2024 06:28:59 GMT</pubDate>
    </item>
    <item>
      <title>Keras æ¨¡å‹ä¸­çš„è‡ªå®šä¹‰ç¼–ç å™¨å’Œè§£ç å™¨å±‚æ˜¾ç¤ºä¸ºæœªæ„å»º</title>
      <link>https://stackoverflow.com/questions/79034907/custom-encoder-and-decoder-layers-within-keras-model-show-as-unbuilt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79034907/custom-encoder-and-decoder-layers-within-keras-model-show-as-unbuilt</guid>
      <pubDate>Sat, 28 Sep 2024 18:27:22 GMT</pubDate>
    </item>
    <item>
      <title>å˜å‹å™¨æ•°æ®é›†</title>
      <link>https://stackoverflow.com/questions/79034901/dataset-for-transformer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79034901/dataset-for-transformer</guid>
      <pubDate>Sat, 28 Sep 2024 18:25:45 GMT</pubDate>
    </item>
    <item>
      <title>å®‰è£… CausalML æ—¶é‡åˆ°é—®é¢˜</title>
      <link>https://stackoverflow.com/questions/79033786/trouble-installing-causalml</link>
      <description><![CDATA[æˆ‘å°è¯•ä½¿ç”¨ Python 3.12 åœ¨æˆ‘çš„ Windows æœºå™¨ä¸Šå®‰è£… causalmlï¼Œå‘½ä»¤ä¸º pip install causalmlã€‚
ä½†åœ¨å°è¯•ä¸º causalml æ„å»º wheel æ—¶å®‰è£…å¤±è´¥ã€‚ä»¥ä¸‹æ˜¯é”™è¯¯ç‰‡æ®µï¼š
æ³¨æ„ï¼šæ­¤é”™è¯¯æºè‡ªå­è¿›ç¨‹ï¼Œå¯èƒ½ä¸æ˜¯ pip çš„é—®é¢˜ã€‚
é”™è¯¯ï¼šæ— æ³•ä¸º causalml æ„å»º wheel
æ— æ³•æ„å»º causalml
é”™è¯¯ï¼šé”™è¯¯ï¼šæ— æ³•ä¸ºæŸäº›åŸºäº pyproject.toml çš„é¡¹ç›® (causalml) æ„å»ºå¯å®‰è£…çš„ wheel

æˆ‘å·²å°†é”™è¯¯é™„åŠ åˆ° pastebin ä¸Šï¼š
https://pastebin.com/dehRfgrk
ä½†å…³é”®é”™è¯¯æ¶ˆæ¯æ˜¯ï¼š
&#39;use_tracing&#39;ï¼šä¸æ˜¯ causalml/inference/tree/_tree/_tree.cpp ä¸­ &#39;_PyCFrame&#39; çš„æˆå‘˜ã€‚
å‘½ä»¤â€œcl.exeâ€å¤±è´¥ï¼Œé€€å‡ºä»£ç ä¸º 2ã€‚
å…³äºå¼ƒç”¨çš„ NumPy API å’Œ Python 2.7 é€‰é¡¹ä½¿ç”¨çš„è­¦å‘Šï¼ˆbdist_wheel.universal å·²å¼ƒç”¨ï¼‰ã€‚
Setuptools è­¦å‘ŠåŒ…é…ç½®ä¸­ç¼ºå°‘åŒ…ï¼ˆcausalml.inference.tree ç­‰ï¼‰

æˆ‘æ­£åœ¨ä½¿ç”¨ï¼š
Python ç‰ˆæœ¬ï¼š3.12ã€‚
æ“ä½œç³»ç»Ÿï¼šWindows 10ã€‚
ç¼–è¯‘å™¨ï¼šMicrosoft Visual Studio 2022 æ„å»ºå·¥å…·ã€‚
ç¯å¢ƒï¼šAnaconda 3ã€‚
NumPy ç‰ˆæœ¬ï¼š1.26.4ã€‚
æˆ‘å°è¯•æ›´æ–° Visual Studio æ„å»ºå·¥å…·å¹¶å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬å¹¶ç¡®ä¿åŒ…å« C++ æ„å»ºå·¥å…·ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79033786/trouble-installing-causalml</guid>
      <pubDate>Sat, 28 Sep 2024 08:47:08 GMT</pubDate>
    </item>
    <item>
      <title>å½“æ­¥é•¿ä¸ºå°æ•°æ—¶ï¼Œä¼šå‘ä¸‹èˆå…¥å—ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79033026/do-steps-round-down-when-its-fractional</link>
      <description><![CDATA[æˆ‘å¼€å§‹å°è¯•è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå¹¶å¯¹è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ—¶æœŸå’Œæ­¥éª¤æ¦‚å¿µæ„Ÿåˆ°å›°æƒ‘ã€‚åœ¨ç½‘ä¸Šæœç´¢æ—¶ï¼Œæˆ‘å¶ç„¶å‘ç°äº†ä¸€ä¸ªä¸æ—¶æœŸã€æ­¥éª¤å’Œæ‰¹æ¬¡å¤§å°ç›¸å…³çš„å…¬å¼ (ğœ = (ğœ€ Ã— ğœ‚) Ã· ğ›½)ã€‚å°†æ­¤å…¬å¼åº”ç”¨äºæˆ‘è‡ªå·±çš„æ•°æ®é›†ä¼šå¾—åˆ°å°æ•°ä¸ªæ­¥éª¤ï¼Œè¿™è®©æˆ‘å¯¹å®é™…ä¸­é€šå¸¸å¦‚ä½•å¤„ç†æ­¥éª¤äº§ç”Ÿäº†ç–‘é—®ã€‚æˆ‘ä¸ç¡®å®šå°æ•°æ­¥éª¤æ˜¯å¦å‘ä¸‹èˆå…¥ï¼Œæˆ–è€…è¿™å¦‚ä½•å‡†ç¡®åœ°è½¬åŒ–ä¸ºå®é™…çš„è®­ç»ƒè¿‡ç¨‹ã€‚æˆ‘ç¼ºä¹å®æ–½è®­ç»ƒå¾ªç¯çš„å®è·µç»éªŒï¼Œå› æ­¤å¾ˆéš¾ç›´è§‚åœ°æŒæ¡è¿™äº›æ¦‚å¿µå¦‚ä½•æ˜ å°„åˆ°ç°å®ä¸–ç•Œçš„æ¨¡å‹è®­ç»ƒåœºæ™¯ã€‚
ä¸ºäº†æ›´å¥½åœ°ç†è§£ epochã€steps å’Œ batch size ä¹‹é—´çš„å…³ç³»ï¼Œæˆ‘å°è¯•å°†æˆ‘æ‰¾åˆ°çš„å…¬å¼ (ğœ = (ğœ€ Ã— ğœ‚) Ã· ğ›½) åº”ç”¨äºæ•°æ®é›†ï¼ˆè¿™åªæ˜¯ä¸€ä¸ªç†è®ºç¤ºä¾‹æ•°æ®é›†ï¼‰ï¼š
total_samples = 10000 # æˆ‘çš„æ•°æ®é›†ä¸­çš„æ ·æœ¬æ€»æ•°
batch_size = 32 # æˆ‘è®¡åˆ’ä½¿ç”¨çš„ batch size
epochs = 10 # æˆ‘æƒ³è¦è®­ç»ƒçš„ epoch æ•°é‡

steps_per_epoch = total_samples / batch_size
total_steps = (epochs * total_samples) / batch_size

print(f&quot;Steps per epoch: {steps_per_epoch}&quot;)
print(f&quot;Totalæ­¥éª¤ï¼š{total_steps}&quot;)

è¿™äº§ç”Ÿäº†ä»¥ä¸‹è¾“å‡ºï¼š
æ¯è½®æ­¥éª¤ï¼š312.5
æ€»æ­¥éª¤ï¼š3125.0

æ¯è½®æ­¥éª¤çš„åˆ†æ•°ç»“æœï¼ˆ312.5ï¼‰è®©æˆ‘ä¸ç¡®å®šè¿™å°†å¦‚ä½•åœ¨å®é™…è®­ç»ƒå¾ªç¯ä¸­å®ç°ã€‚å…·ä½“æ¥è¯´ï¼š

åœ¨å®è·µä¸­ï¼Œåˆ†æ•°æ­¥éª¤é€šå¸¸ä¼šå‘ä¸‹èˆå…¥å—ï¼Ÿ
å¦‚æœå‘ç”Ÿèˆå…¥ï¼Œè¿™æ˜¯å¦æ„å‘³ç€æ¯ä¸ªæ—¶æœŸå¯èƒ½ä¼šè·³è¿‡ä¸€äº›æ•°æ®æ ·æœ¬ï¼Ÿ
å¸¸è§çš„æœºå™¨å­¦ä¹ æ¡†æ¶å¦‚ä½•å¤„ç†è¿™ç§æƒ…å†µï¼Ÿ

æˆ‘è¿˜æ²¡æœ‰çœŸæ­£å®ç°è®­ç»ƒå¾ªç¯ï¼Œæ‰€ä»¥æˆ‘ä¸ç¡®å®šè¿™äº›åˆ†æ•°æ­¥éª¤å°†å¦‚ä½•åœ¨ä»£ç ä¸­å¤„ç†ã€‚æˆ‘çš„ä¸»è¦å›°éš¾æ˜¯å¼¥åˆç†è®ºè®¡ç®—ä¸å…¶åœ¨æ¨¡å‹è®­ç»ƒä¸­çš„å®é™…åº”ç”¨ä¹‹é—´çš„å·®è·ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79033026/do-steps-round-down-when-its-fractional</guid>
      <pubDate>Fri, 27 Sep 2024 22:03:59 GMT</pubDate>
    </item>
    <item>
      <title>åŠ è½½å˜å‹å™¨æ—¶å‡ºç°é—®é¢˜ï¼›ModuleNotFoundErrorï¼šæ²¡æœ‰åä¸ºâ€œtransformersâ€çš„æ¨¡å—</title>
      <link>https://stackoverflow.com/questions/79031959/problem-loading-transformers-modulenotfounderror-no-module-named-transformers</link>
      <description><![CDATA[æˆ‘æƒ³ä½¿ç”¨ huggingface æä¾›çš„ä¸€äº›æ¨¡å‹ã€‚æˆ‘ç”šè‡³åœ¨å¼€å§‹çš„æ—¶å€™éƒ½é‡åˆ°äº†æœ€å¤§çš„å›°éš¾ã€‚æœ‰äººèƒ½å¸®æˆ‘è¯†åˆ«å’Œè§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿ
æˆ‘æ­£åœ¨ä½¿ç”¨ Kubuntu 24.04ã€‚

é¦–å…ˆï¼Œæˆ‘åˆ›å»ºå¹¶æ¿€æ´»ä¸€ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œåœ¨å…¶ä¸­å®‰è£…å˜å‹å™¨ã€‚
python3 -m venv .env
source .env/bin/activate

è¿™æ˜¯æˆåŠŸçš„ï¼Œå› ä¸ºç°åœ¨æˆ‘åœ¨ Visual Code Studio ä¸­çš„ç»ˆç«¯æœ‰å‰ç¼€â€œ(.env)â€ã€‚
æ¥ä¸‹æ¥ï¼Œæˆ‘ä» github å®‰è£…æœ€æ–°çš„å˜å‹å™¨ï¼š
pip install git+https://github.com/huggingface/transformers

è¾“å‡ºæˆåŠŸã€‚ç„¶åï¼Œæˆ‘ä½¿ç”¨ hugginface.co ä¸Šæ¨èçš„æ–¹æ³•æµ‹è¯•å…¶æˆåŠŸç‡ï¼š
python3 -c &quot;from transformers import pipeline; print(pipeline(&#39;sentiment-analysis&#39;)(&#39;I love you&#39;))&quot;

è¾“å‡ºå¯¹æˆ‘æ¥è¯´çœ‹èµ·æ¥æ­£ç¡®ï¼š
æœªæä¾›æ¨¡å‹ï¼Œé»˜è®¤ä¸º distilbert/distilbert-base-uncased-finetuned-sst-2-english å’Œä¿®è®¢ç‰ˆæœ¬ 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english)ã€‚
ä¸å»ºè®®åœ¨ç”Ÿäº§ä¸­ä½¿ç”¨æœªæŒ‡å®šæ¨¡å‹åç§°å’Œä¿®è®¢ç‰ˆæœ¬çš„ç®¡é“ã€‚
ç¡¬ä»¶åŠ é€Ÿå™¨ï¼ˆä¾‹å¦‚ GPUï¼‰åœ¨ç¯å¢ƒä¸­å¯ç”¨ï¼Œä½†æ²¡æœ‰å°†â€œè®¾å¤‡â€å‚æ•°ä¼ é€’ç»™â€œç®¡é“â€å¯¹è±¡ã€‚æ¨¡å‹å°†åœ¨ CPU ä¸Šã€‚
[{&#39;label&#39;: &#39;POSITIVE&#39;, &#39;score&#39;: 0.9998656511306763}]

ä»é‚£é‡Œï¼Œæˆ‘å°è¯•è¿è¡Œä»¥ä¸‹ä»£ç ï¼š
from transformers import pipeline

ä½†æ¯æ¬¡æˆ‘éƒ½ä¼šå¾—åˆ°ä»¥ä¸‹è¾“å‡ºï¼š
/bin/python3 /path-to/main.py
å›æº¯ï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰ï¼š
æ–‡ä»¶&quot;/path-to/main.py&quot;ï¼Œç¬¬ 5 è¡Œï¼Œåœ¨&lt;module&gt;
from transformers import pipeline
ModuleNotFoundErrorï¼šæ²¡æœ‰åä¸ºâ€œtransformersâ€çš„æ¨¡å—
]]></description>
      <guid>https://stackoverflow.com/questions/79031959/problem-loading-transformers-modulenotfounderror-no-module-named-transformers</guid>
      <pubDate>Fri, 27 Sep 2024 15:09:24 GMT</pubDate>
    </item>
    <item>
      <title>å°†åŸºäº Bert çš„ PyTorch æ¨¡å‹å¯¼å‡ºåˆ° CoreMLã€‚å¦‚ä½•è®© CoreML æ¨¡å‹é€‚ç”¨äºä»»ä½•è¾“å…¥ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/78704542/exporting-a-bert-based-pytorch-model-to-coreml-how-can-i-make-the-coreml-model</link>
      <description><![CDATA[æˆ‘ä½¿ç”¨ä»¥ä¸‹ä»£ç å°†åŸºäº Bert çš„ PyTorch æ¨¡å‹å¯¼å‡ºåˆ° CoreMLã€‚
ç”±äºæˆ‘ä½¿ç”¨
dummy_input = tokenizer(&quot;A French fan&quot;, return_tensors=&quot;pt&quot;)

åœ¨ macOS ä¸Šæµ‹è¯•æ—¶ï¼ŒCoreML æ¨¡å‹ä»…é€‚ç”¨äºè¯¥è¾“å…¥ã€‚å¦‚ä½•è®© CoreML æ¨¡å‹é€‚ç”¨äºä»»ä½•è¾“å…¥ï¼ˆå³ä»»ä½•æ–‡æœ¬ï¼‰ï¼Ÿ

å¯¼å‡ºè„šæœ¬ï¼š
# -*- coding: utf-8 -*-
&quot;&quot;&quot;Core ML Export
pip install trâ€‹â€‹ansformers torch coremltools nltk
&quot;&quot;&quot;
å¯¼å…¥ os
ä» transformers å¯¼å…¥ AutoModelForTokenClassificationã€AutoTokenizer
å¯¼å…¥ torch
å¯¼å…¥ torch.nn ä½œä¸º nn
å¯¼å…¥ nltk
å¯¼å…¥ coremltools ä½œä¸º ct
nltk.download(&#39;punkt&#39;)
# åŠ è½½æ¨¡å‹å’Œ tokenizer
model_path = os.path.join(&#39;model&#39;)
model = AutoModelForTokenClassification.from_pretrained(model_path, local_files_only=True)
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
# ä¿®æ”¹æ¨¡å‹çš„ forward æ–¹æ³•ä»¥è¿”å›å…ƒç»„
class ModifiedModel(nn.Module):
def __init__(self, model):
super(ModifiedModel, self).__init__()
self.model = model
self.device = model.device # æ·»åŠ è®¾å¤‡å±æ€§

def forward(self, input_ids,tention_mask, token_type_ids=None):
outputs = self.model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)
returnoutputs.logits

modified_model = ModifiedModel(model)

# å¯¼å‡ºåˆ° Core ML
def convert_to_coreml(model, tokenizer):
# å®šä¹‰ç”¨äºè·Ÿè¸ªçš„è™šæ‹Ÿè¾“å…¥
dummy_input = tokenizer(&quot;A French fan&quot;, return_tensors=&quot;pt&quot;)
dummy_input = {k: v.to(model.device) for k, v in dummy_input.items()}

# ä½¿ç”¨è™šæ‹Ÿè¾“å…¥è·Ÿè¸ªæ¨¡å‹
traced_model = torch.jit.trace(model,(
dummy_input[&#39;input_ids&#39;],dummy_input[&#39;attention_mask&#39;], dummy_input.get(&#39;token_type_ids&#39;)))

# è½¬æ¢ä¸º Core ML
è¾“å…¥ = [
ct.TensorType(name=&quot;input_ids&quot;, shape=dummy_input[&#39;input_ids&#39;].shape),
ct.TensorType(name=&quot;attention_mask&quot;, shape=dummy_input[&#39;attention_mask&#39;].shape)
]
if &#39;token_type_ids&#39; in dummy_input:
è¾“å…¥.append(ct.TensorType(name=&quot;token_type_ids&quot;, shape=dummy_input[&#39;token_type_ids&#39;].shape))

mlmodel = ct.convert(traced_model, è¾“å…¥=inputs)

# ä¿å­˜ Core ML æ¨¡å‹
mlmodel.save(&quot;model.mlmodel&quot;)
print(&quot;æ¨¡å‹å¯¼å‡ºåˆ° Core MLæˆåŠŸ&quot;)

convert_to_coreml(modified_model, tokenizer)

è¦ä½¿ç”¨å¯¼å‡ºçš„æ¨¡å‹ï¼š
import os
from transformers import AutoModelForTokenClassification, AutoTokenizer
import torch
import torch.nn as nn
import nltk
import coremltools as ct
from coremltools.models import MLModel
import numpy as np
from transformers import AutoTokenizer
import nltk

nltk.download(&#39;punkt&#39;)

# åŠ è½½ Core ML æ¨¡å‹
model = MLModel(&#39;model.mlmodel&#39;)

# åŠ è½½ tokenizer
model_path = &#39;model&#39;
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)

def prepare_input(text, tokenizer):
tokens = nltk.tokenize.word_tokenize(text)
tokenized_inputs = tokenizer(tokens, is_split_into_words=True, return_tensors=&quot;np&quot;)
input_ids = tokenized_inputs[&#39;input_ids&#39;].astype(np.int32)
tention_mask = tokenized_inputs[&#39;attention_mask&#39;].astype(np.int32)

input_data = {
&#39;input_ids&#39;: input_ids,
&#39;attention_mask&#39;:tention_mask
}

if &#39;token_type_ids&#39; in tokenized_inputs:
input_data[&#39;token_type_ids&#39;] = tokenized_inputs[&#39;token_type_ids&#39;].astype(np.int32)

return input_data, tokens

def predict(text):
# å‡†å¤‡è¾“å…¥
input_data, tokens = prepare_input(text, tokenizer)

# è¿›è¡Œé¢„æµ‹
prediction = model.predict(input_data)

# æå–é¢„æµ‹æ ‡ç­¾
logits = prediction[&#39;output&#39;] # æ ¹æ®æ¨¡å‹çš„è¾“å‡ºè°ƒæ•´æ­¤é”®
predicted_label = np.argmax(logits, axis=-1)[0]

# æ˜¾ç¤ºç»“æœ
for word, label in zip(tokens, predicted_label):
print(f&quot;{word}: {model.model_description.outputDescriptions[0].dictionaryType.int64KeyType.stringDictionary[label]}&quot;)

# ç”¨ä¸€ä¸ªå¥å­æµ‹è¯•æ¨¡å‹
predict(&quot;A French fan&quot;)

è¯¥è„šæœ¬ä»…é€‚ç”¨äºç¤ºä¾‹â€œA French Fanâ€ã€‚å½“æˆ‘å°è¯•å¦ä¸€ä¸ªç¤ºä¾‹ predict(&quot;A football fan is standing in the stadium.&quot;) æ—¶ï¼Œå®ƒä¼šè§¦å‘é”™è¯¯ï¼š
NSLocalizedDescription = &quot;MultiArray shape (1 x 12) does not match the shape (1 x 5) specified in the model description&quot;;


ç¯å¢ƒï¼š

å¯¼å‡ºè„šæœ¬ï¼šåœ¨ Ubuntu 20.04 ä¸Šæµ‹è¯•äº† Python 3.10 å’Œ torch 2.3.1ï¼ˆåœ¨ Windows 10 ä¸Šä¸èµ·ä½œç”¨ï¼‰ã€‚
é¢„æµ‹è„šæœ¬ï¼šå¿…é¡»åœ¨ macOS 10.13+ ä¸Šè¿è¡Œï¼Œå› ä¸º CoreML æ¨¡å‹ä»…æ”¯æŒåœ¨ macOS 10.13+ ä¸Šè¿›è¡Œé¢„æµ‹ã€‚
]]></description>
      <guid>https://stackoverflow.com/questions/78704542/exporting-a-bert-based-pytorch-model-to-coreml-how-can-i-make-the-coreml-model</guid>
      <pubDate>Wed, 03 Jul 2024 23:39:36 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ Keras è¿›è¡Œè¿ç§»å­¦ä¹ è¿›è¡Œå›¾åƒåˆ†ç±»</title>
      <link>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨å·²ç»è®­ç»ƒè¿‡çš„æ¨¡å‹å°†å­¦ä¹ è½¬ç§»åˆ°æˆ‘å°†è¦åˆ›å»ºçš„æ¨¡å‹ä¸­ï¼Œå¹¶ä¸”åªä¿®æ”¹æœ€åå‡ å±‚ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯ä½¿ç”¨å·²ç»è®­ç»ƒè¿‡çš„æ¨¡å‹ï¼ˆå·²ç»åœ¨æ•°ç™¾ä¸‡å¼ å›¾åƒä¸Šè®­ç»ƒè¿‡ï¼‰æ¥å¸®åŠ©æˆ‘çš„æ¨¡å‹å¯¹é£Ÿç‰©é¡¹ç›®è¯†åˆ«è¿›è¡Œåˆ†ç±»ã€‚æˆ‘å¯¹ Keras è¿˜å¾ˆé™Œç”Ÿï¼Œæˆ‘é‡åˆ°äº†ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ç°åœ¨å¼€å§‹ç†è§£å®ƒï¼Œä½†ä¸çŸ¥é“å¦‚ä½•è§£å†³
# ä» TensorFlow Hub åŠ è½½æ¨¡å‹
model_url = &quot;https://www.kaggle.com/models/tensorflow/resnet-50/TensorFlow2/classification/1&quot;
hub_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3))

# åˆ›å»º Sequential æ¨¡å‹
model = tf.keras.Sequential()

# å°† TensorFlow Hub å±‚æ·»åŠ åˆ° Sequential æ¨¡å‹
model.add(hub_layer)

# æ„å»º Sequential æ¨¡å‹
model.build((None, 224, 224, 3))

# æ¨¡å‹æ‘˜è¦
model.summary()

é”™è¯¯ï¼š
-------------------------------------------------------------------------------
ValueError Tracebackï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰
Cell In[56]ï¼Œç¬¬ 9 è¡Œ
6 model = tf.keras.Sequential()
8 # å°† TensorFlow Hub å±‚æ·»åŠ åˆ° Sequential æ¨¡å‹
----&gt; 9 model.add(hub_layer)
11 # æ„å»º Sequential æ¨¡å‹
12 model.build((None, 224, 224, 3))

æ–‡ä»¶ c:\Users\Karim\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\sequential.py:95ï¼Œä½äº Sequential.add(self, layer, rebuild)
93 layer = origin_layer
94 if not isinstance(layer, Layer):
---&gt; 95 raise ValueError(
96 &quot;åªæœ‰ `keras.Layer` çš„å®ä¾‹å¯ä»¥ &quot;
97 f&quot;æ·»åŠ åˆ° Sequential æ¨¡å‹ä¸­ã€‚æ”¶åˆ°ï¼š{layer} &quot;
98 f&quot;ï¼ˆç±»å‹ä¸º {type(layer)}ï¼‰&quot;
99 )
100 if not self._is_layer_name_unique(layer):
101 raise ValueError(
102 &quot;æ·»åŠ åˆ° Sequential æ¨¡å‹çš„æ‰€æœ‰å±‚ &quot;
103 f&quot;åº”å…·æœ‰å”¯ä¸€åç§°ã€‚åç§° &#39;{layer.name}&#39; å·²ç»æ˜¯ &quot;
104 &quot;æ­¤æ¨¡å‹ä¸­å±‚çš„åç§°ã€‚æ›´æ–° `name` å‚æ•° &quot;
105 &quot;ä»¥ä¼ é€’å”¯ä¸€åç§°ã€‚&quot;
106 )

ValueErrorï¼šåªæœ‰ `keras.Layer` çš„å®ä¾‹å¯ä»¥æ·»åŠ åˆ° Sequential æ¨¡å‹ä¸­ã€‚å·²æ”¶åˆ°ï¼š&lt;tensorflow_hub.keras_layer.KerasLayer å¯¹è±¡ä½äº 0x00000190C6B8AD20&gt;ï¼ˆç±»å‹ä¸º &lt;class &#39;tensorflow_hub.keras_layer.KerasLayer&#39;&gt;ï¼‰
]]></description>
      <guid>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</guid>
      <pubDate>Mon, 29 Apr 2024 09:15:19 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker æ‰¹é‡è½¬æ¢å™¨ä¸æˆ‘è‡ªå·±çš„é¢„è®­ç»ƒæ¨¡å‹</title>
      <link>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:54:18 GMT</pubDate>
    </item>
    </channel>
</rss>