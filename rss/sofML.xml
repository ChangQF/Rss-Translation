<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 16 Nov 2024 15:16:47 GMT</lastBuildDate>
    <item>
      <title>BERTopic partial_fit 占位符集群表示</title>
      <link>https://stackoverflow.com/questions/79195169/bertopic-partial-fit-placeholder-cluster-representation</link>
      <description><![CDATA[我有大约 2M 个文本文档，每个文档都很小，我想对它们进行聚类。（最终将增长到大约 500M。）虽然我愿意接受建议，但我目前正在使用 Python3 包 BERTopic 的在线技术。在对 140 个 15k 个文档块使用 partial_fit 后，我只剩下对 topic_model.get_topic_info() 的调用，它返回未完成的集群表示。也就是说，我看到集群名称 0____ 的表示为 [,,,,,,,,]。我看到大多数集群都是这样的。我从 Google Gemini 得到的建议是对我的所有文档调用 topic_model.fit(all_documents)，这些文档目前在磁盘上压缩后只有 86 GB，对于 RAM 来说太多了。我该如何填写这些集群的表示？]]></description>
      <guid>https://stackoverflow.com/questions/79195169/bertopic-partial-fit-placeholder-cluster-representation</guid>
      <pubDate>Sat, 16 Nov 2024 12:50:38 GMT</pubDate>
    </item>
    <item>
      <title>小数据集的音频微调配置</title>
      <link>https://stackoverflow.com/questions/79195104/audio-fine-tuning-configuration-for-small-data-set</link>
      <description><![CDATA[我是数据训练方面的新手，尤其是在微调方面。我想尝试使用 vits 对音频数据进行微调，数据集小于 100 个音频文件，每个音频文件小于 10 秒，问题就在这里，我已经尝试了几种情况，例如调整

Epoch
Batch Size
Learning Rate
Betas
Warm up Epochs
Mel Processing data

但不知何故它仍然没有给出我想要的结果。我读了文档，它说给出大约 600-1000 个 epoch 可以得到很好的结果，但就我而言，情况仍然不是这样。我尝试了大约 4 天来训练几种情况：
第一次：

注释：这是我第一次进行微调项目
批次大小：16
时期：200
时间：~20 分钟
结果：我听到了很多像机器一样的声音，有些声音捕捉正确，但如果不集中注意力，声音太小而无法注意到

第二次：

注释：我读了几篇文章，似乎较小的批次可以为小数据量提供更紧密的结果，至于时期，我需要确保不要过度拟合，所以我尝试在这里实现它
批次大小：8
时期： 300
时间：~30 分钟
结果：使用这种方法，我开始听到一些声音，尽管它仍然有很多类似机器的模式，但开始在这个案例上有所启发

第三：

注释：根据第二种情况的结果，我认为增加 epoch 可以得到更好的结果，因为范围很广，所以在这种情况下，我尝试遵循推荐的配置（16 批次 &amp; 10000 个 epoch），但尝试使 epoch 更小
批次大小：8
epoch：3000
时间：~8-9 小时
结果：不知何故，在这个结果中，它开始听起来不像机器那样，大约 25%，所以如果我想添加 epoch，也许增加批次大小会有所帮助

第四次：

注意：基于最后的情况，我尝试增加批次大小，因为我的规格不是那么糟糕（我将在本节下方提供其他信息）
批次大小：16
epoch：4000
时间：~7-8 小时
结果：在这种情况下，不知何故它让声音变得非常奇怪，就像减少了性能

基于此，我想问一下，如何正确计算训练的值以获得至少不错的结果？我对第一次微调有点困惑
至于我的PC 规格，这里是：

NVidia RTX 3060 12 GB DDR6 配备 64 GB RAM &amp;第 12 代英特尔 I7-12700F

我曾尝试从 GPT 获取我的设置的最佳配置，但不知何故结果仍然相同，它给出了以下参数：
 &quot;train&quot;: {
&quot;log_interval&quot;: 50,
&quot;eval_interval&quot;: 200,
&quot;seed&quot;: 1234,
&quot;epochs&quot;: 1000,
&quot;learning_rate&quot;: 1e-4,
&quot;betas&quot;: [0.9, 0.98],
&quot;eps&quot;: 1e-9,
&quot;batch_size&quot;: 4,
&quot;fp16_run&quot;: true,
&quot;lr_decay&quot;: 0.9999,
&quot;segment_size&quot;: 8192,
&quot;init_lr_ratio&quot;: 1,
&quot;warmup_epochs&quot;: 5,
&quot;c_mel&quot;: 30,
&quot;c_kl&quot;: 1.0
}

截至存储库默认配置，给出的内容如下：
 &quot;train&quot;: {
&quot;log_interval&quot;: 200,
&quot;eval_interval&quot;: 1000,
&quot;seed&quot;: 1234,
&quot;epochs&quot;: 10000,
&quot;learning_rate&quot;: 2e-5,
&quot;betas&quot;: [0.8, 0.99],
&quot;eps&quot;: 1e-9,
&quot;batch_size&quot;: 16,
&quot;fp16_run&quot;: true,
&quot;lr_decay&quot;: 0.999875,
&quot;segment_size&quot;: 8192,
&quot;init_lr_ratio&quot;: 1,
&quot;warmup_epochs&quot;: 0,
&quot;c_mel&quot;: 45,
&quot;c_kl&quot;: 1.0
}

所以这里有一些我想问的问题：
有没有针对 100 个数据集以下音频文件的微调配置建议？最大批次大小是否应始终低于样本数据总量？]]></description>
      <guid>https://stackoverflow.com/questions/79195104/audio-fine-tuning-configuration-for-small-data-set</guid>
      <pubDate>Sat, 16 Nov 2024 12:03:58 GMT</pubDate>
    </item>
    <item>
      <title>如何使用神经网络找到下图中所有交点的坐标？</title>
      <link>https://stackoverflow.com/questions/79194488/how-can-i-find-coordinate-of-all-intersection-points-in-the-following-image-with</link>
      <description><![CDATA[我想使用神经网络找到下图中的所有交点。有人知道我该如何实现吗？

目前，我使用 openCV 阈值或边缘检测，但在某些情况下效果不佳。所以，我想使用神经网络来做到这一点，但我就是不知道如何使用神经网络来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/79194488/how-can-i-find-coordinate-of-all-intersection-points-in-the-following-image-with</guid>
      <pubDate>Sat, 16 Nov 2024 03:55:18 GMT</pubDate>
    </item>
    <item>
      <title>Rectools‘Dataset’对象没有属性‘from_dataset’</title>
      <link>https://stackoverflow.com/questions/79194068/rectools-dataset-object-has-no-attribute-from-dataset</link>
      <description><![CDATA[我尝试使用 Python 库 Rectools 中的 DSSMModel，但遇到了一些问题。
sparse_features_dataset = Dataset.construct(
train_data,
user_features_df=users_data,
cat_user_features=[&quot;gender&quot;, &quot;age&quot;],
item_features_df=items_data,
cat_item_features=&#39;source_id&#39;
)

model = DSSMModel(sparse_features_dataset, 
max_epochs = 10,
batch_size = 64)

#此行导致问题：
model.fit(sparse_features_dataset)

你能告诉我哪里出了问题吗？
当我使用此库中的其他模型时，一切都正常，但这个模型有问题]]></description>
      <guid>https://stackoverflow.com/questions/79194068/rectools-dataset-object-has-no-attribute-from-dataset</guid>
      <pubDate>Fri, 15 Nov 2024 21:56:55 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 错误检查失败：m == 1 || n == 1：</title>
      <link>https://stackoverflow.com/questions/79193653/xgboost-error-check-failed-m-1-n-1</link>
      <description><![CDATA[嗨，我正在尝试通过 XGBoostClassifier 运行我的数据，但遇到了以下问题。请帮忙。
!pip install xgboost
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()
y_train=encoder.fit_transform(y_train)
model=XGBClassifier(objective=&quot;binary:logistic&quot;,n_estimators=10,max_depth=3, learning_rate=.1)
model.fit(X_train,y_train)
y_pred=model.predict(X_test)
print(classification_report(y_test,y_pred))`

我尝试添加标签编码器。我得到的错误如下
XGBoostError: [12:07:18] C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling- group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\data\array_interface.h:218: 检查失败: m == 1 || n == 1: 

​]]></description>
      <guid>https://stackoverflow.com/questions/79193653/xgboost-error-check-failed-m-1-n-1</guid>
      <pubDate>Fri, 15 Nov 2024 18:59:05 GMT</pubDate>
    </item>
    <item>
      <title>尝试在 R 中使用 tensorflow 和 teras 进行图像识别时出错</title>
      <link>https://stackoverflow.com/questions/79193329/error-trying-to-do-image-recognition-using-tensorflow-and-teras-in-r</link>
      <description><![CDATA[我正在按照本教程进行操作 -
https://www.r-bloggers.com/2021/03/how-to-build-your-own-image-recognition-app-with-r-part-1/amp/
但是遇到了一个错误。
model_function &lt;- function(learning_rate = 0.001, 
dropoutrate=0.2, n_dense=1024){

k_clear_session()

model &lt;- keras_model_sequence() %&gt;%
mod_base %&gt;% 
layer_global_average_pooling_2d() %&gt;% 
layer_dense(units = n_dense) %&gt;%
layer_activation(&quot;relu&quot;) %&gt;%
layer_dropout(dropoutrate) %&gt;%
layer_dense(units=output_n,activation=&quot;softmax&quot;)

model %&gt;% compile(
loss = &quot;categorical_crossentropy&quot;,
optimizer = optimizer_adam(lr = learning_rate),
metrics = &quot;accuracy&quot;
)

return(model)

}

model &lt;- model_function()

此代码的最后一行出现以下错误 -
py_call_impl(callable, call_args$unnamed, call_args$named) 中的错误: 
ValueError：层的输入应为张量。层“xception”的输入为“&lt;Sequential name=sequential,built=False&gt;”（类型为&lt;class&#39;keras.src.models.sequential.Sequential&#39;&gt;）。
运行`reticulate::py_last_error()`了解详情。

有人知道我该如何修复这个问题吗？或者有其他教程可以推荐吗？]]></description>
      <guid>https://stackoverflow.com/questions/79193329/error-trying-to-do-image-recognition-using-tensorflow-and-teras-in-r</guid>
      <pubDate>Fri, 15 Nov 2024 17:01:55 GMT</pubDate>
    </item>
    <item>
      <title>是否应将规范化应用于交互特征或交互项</title>
      <link>https://stackoverflow.com/questions/79192800/should-normalization-be-applied-on-interaction-feature-or-interaction-term</link>
      <description><![CDATA[我正在机器学习模型中使用交互特征，通过将数值变量与编码分类特征相乘来创建新特征。我的问题是：
是否应该对这些交互项应用规范化？

如果是，那么规范化不会改变交互项的含义吗？具体来说，当我先对数值特征进行归一化，然后创建交互项时，交互项是否仍表示其最初要捕获的关系？

如果在创建交互项之前对数值变量进行归一化，交互项是否会失去其真实比例或含义？


例如，如果我将归一化数值特征与分类变量（可以是独热编码）相乘，我是否会扭曲数值特征与类别之间的原始关系？
我希望澄清交互项是否应归一化或保持原样，特别是在交互项在捕获特定关系中起关键作用的情况下。
谢谢！
我尝试了什么：
我尝试在创建交互项之前对数值特征进行归一化。具体来说，我先对数值变量进行归一化，然后将其与编码的分类特征相乘。我还尝试在不先对数值变量进行归一化的情况下创建交互特征，以比较这两种方法。
我期望什么？
我希望了解在创建交互项之前对数值特征进行归一化是否会影响模型捕捉数值和分类特征之间预期关系的能力。我还很好奇，由于数值特征的归一化，交互项的含义是否会保留或扭曲。我希望了解归一化是否会导致交互项失去其原始规模和重要性，或者它是否有利于模型收敛和性能。]]></description>
      <guid>https://stackoverflow.com/questions/79192800/should-normalization-be-applied-on-interaction-feature-or-interaction-term</guid>
      <pubDate>Fri, 15 Nov 2024 14:28:44 GMT</pubDate>
    </item>
    <item>
      <title>如何从头开始创建模型以从扫描的发票中提取文本和表格数据</title>
      <link>https://stackoverflow.com/questions/79192367/how-can-i-create-a-model-from-scratch-to-extract-text-and-table-data-from-scanne</link>
      <description><![CDATA[所以我目前正在做一个项目，我们收到了 25 种不同的发票类型，全部都经过了扫描。最终目标是从发票中提取文本和表格数据，然后最终将这些数据解析为 Excel。发票类型采用不同的格式。我们如何提取表格数据 + 文本？我们可以为 25 种发票类型创建 1 个模型来执行此操作吗？还是我们需要 25 个模型。]]></description>
      <guid>https://stackoverflow.com/questions/79192367/how-can-i-create-a-model-from-scratch-to-extract-text-and-table-data-from-scanne</guid>
      <pubDate>Fri, 15 Nov 2024 12:24:08 GMT</pubDate>
    </item>
    <item>
      <title>如何从 CoreML 预测中获取置信度变量</title>
      <link>https://stackoverflow.com/questions/79192127/how-can-i-get-the-confidence-variable-from-a-coreml-prediction</link>
      <description><![CDATA[我正在使用 CreateML 工具训练文本分类器，当我使用预览功能并输入一个句子时，它会给我一个预测以及一个置信度变量
以下是我在应用程序上使用该模型的方式
import CoreML
...

func predict(phrase:String) -&gt; String {
guard let rollModel = try? Roll(configuration: MLModelConfiguration()) else {
return &quot;Failed to load the Roll Model.&quot;
}

let rollModelInput = RollInput(text: phrase)

guard let prediction = try? rollModel.prediction(input: rollModelInput, options: MLPredictionOptions()) else {
return &quot;Roll Model Prediction Failed&quot;
}

return prediction.label
}

这有效，它提供了预测。
我的数据是标准文本/标签格式
即使我将模型导出到 xcode 并在 xcode 中运行预览，置信度变量仍然存在。
当我在设备上运行预测时，我想知道置信度变量是什么，我如何获取访问权限？
]]></description>
      <guid>https://stackoverflow.com/questions/79192127/how-can-i-get-the-confidence-variable-from-a-coreml-prediction</guid>
      <pubDate>Fri, 15 Nov 2024 11:13:21 GMT</pubDate>
    </item>
    <item>
      <title>回答 Tensor Flow 警告 - 警告：TensorFlow：您的输入数据不足；中断训练</title>
      <link>https://stackoverflow.com/questions/79191359/answer-tensor-flow-warning-warningtensorflowyour-input-ran-out-of-data-inte</link>
      <description><![CDATA[结果
使用微调进行训练
每轮训练步骤：18
每轮验证步骤：4
训练生成器批量大小：32
总训练样本：576
总验证样本：144
轮次 1/5
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121：UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()
18/18 ━━━━━━━━━━━━━━━━━━━━━ 399s 19s/step - 准确率：0.1593 - 损失：2.1888 - val_accuracy：0.3281 - val_loss：1.8363
Epoch 2/5
/usr/lib/python3.10/contextlib.py:153: UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 `steps_per_epoch * epochs` 批次。构建数据集时可能需要使用 `.repeat()` 函数。
self.gen.throw(typ, value, traceback)
18/18 ━━━━━━━━━━━━━━━━━━━━━━ 5s 294ms/step - 准确度：0.0000e+00 - 损失：0.0000e+00 - val_accuracy：0.3750 - val_loss：1.8651
Epoch 3/5
18/18 ━━━━━━━━━━━━━━━━━━━━━━━ 361s 18s/step - 准确度：0.3593 - 损失： 1.7475 - val_accuracy：0.4141 - val_loss：1.6302
Epoch 4/5
18/18 ━━━━━━━━━━━━━━━━━━━━━━ 41s 2s/步 - 准确度：0.0000e+00 - 损失：0.0000e+00 - val_accuracy：0.4375 - val_loss：1.4419
Epoch 5/5
18/18 ━━━━━━━━━━━━━━━━━━━━━ 322s 18s/step - 准确率：0.5175 - 损失：1.4328 - val_accuracy：0.3984 - val_loss：1.4993

完整代码
(https://drive.google.com/file/d/1jHqDnCnLMHeIZ9nn4Y9O8qZUhcvFtW4k/view?usp=sharing)
您能帮我解决错误吗]]></description>
      <guid>https://stackoverflow.com/questions/79191359/answer-tensor-flow-warning-warningtensorflowyour-input-ran-out-of-data-inte</guid>
      <pubDate>Fri, 15 Nov 2024 06:58:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 HMM 模型对某些动作进行门预测？</title>
      <link>https://stackoverflow.com/questions/79190691/how-to-make-gate-predictions-for-certain-movements-using-hmm-model</link>
      <description><![CDATA[我想使用 IMU 传感器来预测用户接下来要进入哪个门（用于行走、跑步、跳跃等）。根据我的研究，HMM 似乎是状态预测的最佳机器学习模型。但我在网上看到的所有模型都是基于预先记录的静态数据，而不是正在记录的实时数据。我应该如何实现这一点？
我已经实现了一个滚动窗口，它使用最后捕获的 30 条数据记录进行下一次预测，并对它们进行了规范化。
我已经确定了我想要识别的每个动作的门，并且我已经设置了一个分类算法，该算法遍历每个窗口并使用它来对当前动作进行分类。
我打算用它们来验证我将要做出的预测（或者甚至在需要时将其用作输入来预测人的下一个动作）。]]></description>
      <guid>https://stackoverflow.com/questions/79190691/how-to-make-gate-predictions-for-certain-movements-using-hmm-model</guid>
      <pubDate>Thu, 14 Nov 2024 23:15:03 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 提前停止轮次</title>
      <link>https://stackoverflow.com/questions/79189607/xgboost-early-stopping-rounds</link>
      <description><![CDATA[下面的代码一直在崩溃，我不知道发生了什么
import optuna
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 假设 `X` 和 `y` 是你的特征矩阵和目标数组
X_train, X_valid, y_train, y_valid = train_test_split(df_combined, y, test_size=0.2, random_state=42)

# 为 Optuna 定义目标函数
def objective(trial):
# 为超参数建议值
params = {
&quot;objective&quot;: &quot;reg:squarederror&quot;,
&quot;eval_metric&quot;: &quot;rmse&quot;,
&quot;tree_method&quot;: &quot;hist&quot;, # 使用 hist 方法
&quot;device&quot;: &quot;cuda&quot;, # 指定使用 GPU
&quot;learning_rate&quot;: trial.suggest_float(&quot;learning_rate&quot;, 0.01, 0.3, log=True),
&quot;max_depth&quot;: trial.suggest_int(&quot;max_depth&quot;, 3, 10),
&quot;min_child_weight&quot;: trial.suggest_float(&quot;min_child_weight&quot;, 1, 10),
&quot;gamma&quot;: trial.suggest_float(&quot;gamma&quot;, 0, 1),
&quot;subsample&quot;: trial.suggest_float(&quot;subsample&quot;, 0.5, 1.0),
&quot;colsample_bytree&quot;: trial.suggest_float(&quot;colsample_bytree&quot;, 0.5, 1.0),
&quot;lambda&quot;: trial.suggest_float(&quot;lambda&quot;, 1e-3, 10.0, log=True),
&quot;alpha&quot;: trial.suggest_float(&quot;alpha&quot;, 1e-3, 10.0, log=True),
&quot;n_estimators&quot;: 1000 # 在模型初始化中定义 n_estimators
}

# 初始化模型
model = xgb.XGBRegressor(**params)

# 使用早期停止回调训练模型
model.fit(
X_train,
y_train,
eval_set=[(X_valid, y_valid)],
verbose=False,
early_stopping_rounds=50 # 如果之后没有改进则停止50 轮
)

# 预测并计算验证集的 RMSE
preds = model.predict(X_valid)
rmse = mean_squared_error(y_valid, preds, squared=False)

return rmse # Optuna 将其最小化

# 设置 Optuna 研究
study = optuna.create_study(direction=&quot;minimize&quot;)

# 优化超参数
study.optimize(objective, n_trials=100, n_jobs=40) # 100 次试验，40 次并行作业

# 显示最佳试验
print(&quot;最佳试验：&quot;)
trial = study.best_trial
print(f&quot;值 (RMSE)：{trial.value}&quot;)
print(&quot; 参数：&quot;)
for key, value in trial.params.items():
print(f&quot; {key}: {value}&quot;)

我得到
TypeError：XGBModel.fit() 获得意外的关键字参数“early_stopping_rounds”

我已更新所有内容以确保我拥有所有更新的库。
提前停止轮次是正确的（我认为），但由于某种原因，它会爆炸。]]></description>
      <guid>https://stackoverflow.com/questions/79189607/xgboost-early-stopping-rounds</guid>
      <pubDate>Thu, 14 Nov 2024 16:14:40 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用 FastAPI 在 model.predict() 中直接使用 Pydantic 模型（BaseModel）吗？如果不行，为什么？</title>
      <link>https://stackoverflow.com/questions/71849683/can-we-use-pydantic-models-basemodel-directly-inside-model-predict-using-fas</link>
      <description><![CDATA[我正在使用带有 FastAPI 的 Pydantic 模型 (Basemodel)，并将输入转换为 dictionary，然后将其转换为 Pandas DataFrame，以便将其传递到 model.predict() 函数中进行机器学习预测，如下所示：
from fastapi import FastAPI
import uvicorn
from pydantic import BaseModel
import pandas as pd
from typing import List

class Inputs(BaseModel):
f1: float,
f2: float,
f3: str

@app.post(&#39;/predict&#39;)
def predict(features: List[Inputs]):
output = []

# 循环输入特征列表
for data in features:
result = {}

# 将数据转换为 dict()，然后转换为 DataFrame
data = data.dict()
df = pd.DataFrame([data])

# 获取预测
prediction = classifier.predict(df)[0]

# 获取概率
probability = classifier.predict_proba(df).max()

# 分配给字典 
result[&quot;prediction&quot;] = prediction
result[&quot;probability&quot;] = probability

# 将字典附加到列表（许多输出）
output.append(result)

返回输出

它运行良好，只是我不太确定它是否优化或是否是正确的方法，因为我将输入转换两次以获得预测。此外，我不确定在输入数量巨大的情况下它是否会快速地工作。对此有什么改进吗？如果有办法（甚至除了使用 Pydantic 模型之外），我可以直接工作并避免经过转换和循环。]]></description>
      <guid>https://stackoverflow.com/questions/71849683/can-we-use-pydantic-models-basemodel-directly-inside-model-predict-using-fas</guid>
      <pubDate>Tue, 12 Apr 2022 22:11:19 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练时我的 Keras 模型的准确率始终为 0？</title>
      <link>https://stackoverflow.com/questions/45632549/why-is-the-accuracy-for-my-keras-model-always-0-when-training</link>
      <description><![CDATA[我构建了一个简单的 Keras 网络：
import numpy as np;

from keras.models import Sequential;
from keras.layers import Dense,Activation;

data= np.genfromtxt(&quot;./kerastests/mydata.csv&quot;, delimiter=&#39;;&#39;)
x_target=data[:,29]
x_training=np.delete(data,6,axis=1)
x_training=np.delete(x_training,28,axis=1)

model=Sequential()
model.add(Dense(20,activation=&#39;relu&#39;, input_dim=x_training.shape[1]))
model.add(Dense(10,activation=&#39;relu&#39;))
model.add(Dense(1));

model.compile(optimizer=&#39;adam&#39;,loss=&#39;mean_squared_error&#39;,metrics=[&#39;accuracy&#39;])
model.fit(x_training, x_target)

如您所见，从我的源数据中，我删除了 2 列。一列是带有字符串格式日期的列（在数据集中，除此之外，我还有表示日期的列、表示月份的列和表示年份的列，因此我不需要该列），另一列是我用作模型目标的列）。
当我训练这个模型时，我得到了这个输出：
32/816 [&gt;.............................] - ETA：23s - loss：13541942.0000 - acc：0.0000e+00
800/816 [===========================&gt;.] - ETA：0s - loss：11575466.0400 - acc：0.0000e+00 
816/816 [================================] - 1s - 损失：11536905.2353 - 精度：0.0000e+00 
纪元 2/10
32/816 [&gt;.............................] - ETA：0s - 损失：6794785.0000 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5381360.4314 - 精度：0.0000e+00 
纪元 3/10
32/816 [&gt;.............................] - ETA：0s - 损失： 6235184.0000 - 精度：0.0000e+00
800/816 [============================&gt;.] - ETA：0s - 损失：5199512.8700 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5192977.4216 - 精度：0.0000e+00 
纪元 4/10
32/816 [&gt;.............................] - ETA：0s - 损失：4680165.5000 - 精度： 0.0000e+00
736/816 [===========================&gt;...] - ETA：0s - 损失：5050110.3043 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5168771.5490 - 精度：0.0000e+00 
纪元 5/10
32/816 [&gt;.............................] - ETA：0s - 损失：5932391.0000 - 精度：0.0000e+00
768/816 [============================&gt;..] - ETA：0 秒 - 损失：5198882.9167 - 精度：0.0000e+00
816/816 [==============================] - 0 秒 - 损失：5159585.9020 - 精度：0.0000e+00 
纪元 6/10
32/816 [&gt;.............................] - ETA：0 秒 - 损失：4488318.0000 - 精度：0.0000e+00
768/816 [============================&gt;..] - ETA：0s - 损失：5144843.8333 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5151492.1765 - 精度：0.0000e+00 
纪元 7/10
32/816 [&gt;.............................] - ETA：0s - 损失：6920405.0000 - 精度：0.0000e+00
800/816 [=============================&gt;.] - ETA：0s - 损失：5139358.5000 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5169839.2941 - 精度：0.0000e+00 
纪元 8/10
32/816 [&gt;.............................] - ETA：0s - 损失：3973038.7500 - 精度：0.0000e+00
672/816 [==========================&gt;......] - ETA：0s - 损失：5183285.3690 - 精度：0.0000e+00
816/816 [==============================] - 0s - 损失：5141417.0000 - 精度：0.0000e+00 
Epoch 9/10
32/816 [&gt;.............................] - ETA：0s - 损失：4969548.5000 - 精度：0.0000e+00
768/816 [===========================&gt;..] - ETA：0s - 损失：5126550.1667 - 精度： 0.0000e+00
816/816 [===============================] - 0s - 损失：5136524.5098 - 精度：0.0000e+00 
纪元 10/10
32/816 [&gt;.............................] - ETA：0s - 损失：6334703.5000 - 精度：0.0000e+00
768/816 [===========================&gt;..] - ETA：0s - 损失：5197778.8229 - 精度：0.0000e+00
816/816 [===============================] - 0s - 损失：5141391.2059 - 准确率：0.0000e+00 

为什么会发生这种情况？我的数据是时间序列。我知道对于时间序列，人们通常不使用 Dense 神经元，但这只是一个测试。真正让我困惑的是准确率始终为 0。而且，在其他测试中，我甚至输了：得到一个“NAN”值。
有人能帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/45632549/why-is-the-accuracy-for-my-keras-model-always-0-when-training</guid>
      <pubDate>Fri, 11 Aug 2017 10:08:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Weka 中使用 MFCC 进行音频分类？</title>
      <link>https://stackoverflow.com/questions/45224049/how-to-use-mfccs-in-weka-for-audio-classification</link>
      <description><![CDATA[我正在尝试开发一种使用 Weka 中的 MFCC 对音频进行分类的方法。我拥有的 MFCC 是用 1024 的缓冲区大小生成的，因此每个音频记录都有一系列 MFCC 系数。我想将这些系数转换为 Weka 的 ARFF 数据格式，但我不确定如何解决这个问题。
我还问了一个关于合并数据的问题，因为我觉得这可能会影响数据转换为 ARFF 格式。
我知道对于 ARFF，数据需要通过属性列出。MFCC 的每个系数应该是单独的属性还是作为单个属性的系数数组？每个数据应该代表单个 MFCC、时间窗口还是整个文件或声音？下面，我写出了我认为如果只考虑一个 MFCC 应该是什么样子，我认为这无法对整个声音进行分类。
@relation audio

@attribute mfcc1 real
@attribute mfcc2 real
@attribute mfcc3 real
@attribute mfcc4 real
@attribute mfcc5 real
@attribute mfcc6 real
@attribute mfcc7 real
@attribute mfcc8 real
@attribute mfcc9 real
@attribute mfcc10 real
@attribute mfcc11 real
@attribute mfcc12 real
@attribute mfcc13 real
@attribute class {bark, honk, talking, wind}

@data
126.347275, -9.709645, 4.2038302, -11.606304, -2.4174862, -3.703139, 12.748064, -5.297932, -1.3114156, 2.1852574, -2.1628475, -3.622149, 5.851326, bark

如能提供任何帮助，我们将不胜感激。
编辑：
我已生成一些 ARFF 文件使用 Weka 使用 openSMILE 按照此 网站中的方法，但我不确定如何使用这些数据对音频进行分类，因为每行数据都是来自同一文件的 10 毫秒音频。每行的名称属性都是“未知”，我认为这是数据将尝试分类的属性。我如何才能对整体声音（而不是 10 毫秒）进行分类并将其与其他几个整体声音进行比较？

编辑 #2：成功！
在更彻底地阅读我找到的网站后，我看到了 Accumulate 脚本以及测试和训练数据文件。accumulate 脚本将来自不同音频文件的每个 MFCC 数据集合生成的所有文件放在一个 ARFF 文件中。他们的文件由大约 200 个属性组成，其中包含 12 个 MFCC 的统计数据。虽然我无法使用 OpenSmile 检索这些统计数据，但我使用了 Python 库来执行此操作。统计数据包括最大值、最小值、峰度、范围、标准差等。我使用 Weka 中的 BayesNet 和多层感知器准确地对我的音频文件进行了分类，这两项方法都为我带来了 100% 的准确率。]]></description>
      <guid>https://stackoverflow.com/questions/45224049/how-to-use-mfccs-in-weka-for-audio-classification</guid>
      <pubDate>Thu, 20 Jul 2017 19:52:54 GMT</pubDate>
    </item>
    </channel>
</rss>