<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 22 Jan 2024 18:18:22 GMT</lastBuildDate>
    <item>
      <title>LogisitcLoss 类中的梯度函数</title>
      <link>https://stackoverflow.com/questions/77861514/gradient-function-in-logisitcloss-class</link>
      <description><![CDATA[我正在从头开始编写 XGBoost 代码，我指的是这个存储库 此处
对数损失函数由下式给出
对数损失函数
关于 y_pred 区分上述函数（指上面存储库中 LogisitcLoss() 下的确切变量），我得到的梯度为 (y - p) 但代码显示 -(y - p) .
我从损失函数中导出了梯度，看起来答案的符号与我得到的结果相反。我想知道我的损失函数是否正确。如果我的损失函数正确，我还想知道找到梯度的分步解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/77861514/gradient-function-in-logisitcloss-class</guid>
      <pubDate>Mon, 22 Jan 2024 17:03:32 GMT</pubDate>
    </item>
    <item>
      <title>极端类不平衡的稳健机器学习模型的数学和编码[关闭]</title>
      <link>https://stackoverflow.com/questions/77861478/mathematics-and-coding-for-robust-machine-learning-models-for-extreme-class-imba</link>
      <description><![CDATA[我的任务是解决二元分类问题中的极端类别不平衡问题，其中正类仅占总样本的 0.05%。假设您有一个包含 N 个样本和 D 个特征的数据集。
数学（50 分）：推导明确考虑类别不平衡的成本函数的数学公式。加入正则化术语并解释它如何有助于防止过度拟合。为成本函数中的每一项提供逐步推导和基本原理。
算法设计（30 分）：提出一种新颖的算法或对现有算法进行修改，专门针对极端类别不平衡的情况。提供伪代码或关于您的方法如何工作的详细算法描述。突出显示所有关键超参数及其重要性。
编码实现（20 分）：使用您选择的编程语言（例如 Python）实现您提出的算法。将算法应用于提供的数据集，并确保您的代码有完整的文档记录。使用适当的指标和可视化技术评估模型性能。讨论结果和任何观察到的权衡。
数学：
我试图推导出一个成本函数来解释极端的类别不平衡，并结合一个正则化项来防止过度拟合。我期望对成本函数中的每个术语进行全面、逐步的解释，展示对机器学习数学基础的深刻理解。
算法设计：
我提出了一种新颖的算法或对现有算法的修改，专门解决极端的类别不平衡问题。我期望提供清晰详细的算法描述，包括伪代码，并强调关键超参数的重要性。我的目的是展示创造性思维和对算法设计原理的深入理解。
编码实现：
我使用我选择的编程语言实现了所提出的算法，确保代码有良好的文档记录。我将该算法应用于提供的数据集，使用适当的指标和可视化技术评估模型性能。我希望展示强大的编码技能，展示所提出的算法的应用，并讨论观察到的结果和任何权衡。]]></description>
      <guid>https://stackoverflow.com/questions/77861478/mathematics-and-coding-for-robust-machine-learning-models-for-extreme-class-imba</guid>
      <pubDate>Mon, 22 Jan 2024 16:55:06 GMT</pubDate>
    </item>
    <item>
      <title>没有Python库的LSTM模型</title>
      <link>https://stackoverflow.com/questions/77861406/lstm-model-with-no-libraries-in-python</link>
      <description><![CDATA[我想使用 numpy 和 pandas 在 python 中创建一个 LSTM 机器学习模型，该模型用于音乐推荐引擎，该引擎采用 Spotify 音乐功能接收特定长度的流媒体历史记录。在 python 中使用 OOP 解决这个问题最有效的方法是什么，我想将它与预训练的模型进行比较，看看它在专门为此训练时是否表现得更好。我在这个领域相对较新，这是一个学校项目。
# 导入库
将 numpy 导入为 np
将 pandas 导入为 pd


班级网络：
    def __init__(自身):
        ”“”
        用于机器学习算法形成建议的神经网络
        ”“”
        # 导入训练数据
        self.data = np.array(pd.read_csv(&#39;train_clean.csv&#39;))
        # 获取数据数组的大小
        self.m, self.n = self.data.shape
        # 随机化训练数据的顺序
        np.random.shuffle(self.data)


网络=网络（）

这是我开始使用的类布局，任何有关如何解决此问题的想法将不胜感激，或者我也可以使用现有模型进行基准测试。]]></description>
      <guid>https://stackoverflow.com/questions/77861406/lstm-model-with-no-libraries-in-python</guid>
      <pubDate>Mon, 22 Jan 2024 16:42:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 R 中的 iml 包在经过训练的随机森林模型上创建 2D 部分依赖图？</title>
      <link>https://stackoverflow.com/questions/77860945/how-to-create-a-2d-partial-dependence-plot-on-a-trained-random-forest-model-usin</link>
      <description><![CDATA[我使用 R 中的 mlr3 包训练了 randomForest 模型，并成功使用 iml 包创建了部分依赖 (PDP) 和累积局部效应 (ALE) 的一维图来解释训练后的 ML 模型。我已经看到可以使用《可解释机器学习》一书中的 iml 包创建 2D 绘图（这里）其中写到其中使用了iml包（不幸的是，似乎没有提供代码）。但是，我真的找不到如何创建 2D 绘图（例如要使用哪个函数/参数），也找不到任何 2D 代码示例。
这是我创建一维图的示例代码（主要来自 iml 手册）。
库(“randomForest”)
库（“iml”）

# 在波士顿数据集上训练随机森林回归：
数据（“波士顿”，包=“MASS”）
rf &lt;- randomForest(medv ~ ., 数据 = 波士顿, ntree = 50)
mod &lt;- Predictor$new(rf, 数据 = 波士顿)

# 等离子显示
eff &lt;- FeatureEffects$new(mod, method=“pdp”)
eff$plot(features = c(“lstat”,“rm”))

# 啤酒
eff &lt;- FeatureEffects$new(mod, method=“ale”)
eff$plot(features = c(“lstat”,“rm”))
]]></description>
      <guid>https://stackoverflow.com/questions/77860945/how-to-create-a-2d-partial-dependence-plot-on-a-trained-random-forest-model-usin</guid>
      <pubDate>Mon, 22 Jan 2024 15:25:34 GMT</pubDate>
    </item>
    <item>
      <title>是否有可用于情感分析（特别是“快乐”和“悲伤”）的新闻摘要或标题的带注释数据集？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77860239/is-there-an-annotated-dataset-available-of-news-summary-or-headlines-for-sentime</link>
      <description><![CDATA[我想训练一个机器学习模型，将新闻标题或摘要分类为快乐或悲伤。为此，我需要真实且带注释的数据来训练我的模型。
我试图在谷歌上找到它，但没有成功！]]></description>
      <guid>https://stackoverflow.com/questions/77860239/is-there-an-annotated-dataset-available-of-news-summary-or-headlines-for-sentime</guid>
      <pubDate>Mon, 22 Jan 2024 13:31:14 GMT</pubDate>
    </item>
    <item>
      <title>添加 2 个模型作为另一个模型的输入（图表已断开连接）</title>
      <link>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</link>
      <description><![CDATA[我有两个模型：model_A 和 model_B。
我想对这两个模型进行元素明智加法，并将结果用作 model_C 的输入。
所以，我有这个代码：
从tensorflow.keras.layers导入Conv2D，BatchNormalization，\
    激活、输入、添加
从tensorflow.keras.models导入模型
将 numpy 导入为 np
将张量流导入为 tf

def model_A（输入）：
    x1 = Conv2D(32, 3, padding=&#39;相同&#39;)(输入)
    x1 = BatchNormalization()(x1)
    x1 = 激活(&#39;relu&#39;)(x1)
    
    x2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(x1)
    模型=模型（输入=输入，输出=x​​2，名称=&#39;model_A&#39;）
    返回模型
    

def model_B（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(f1)

    模型=模型（输入=输入，输出=f2，名称=&#39;model_B&#39;）
    返回模型

def model_C（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(16, 3, 填充=&#39;相同&#39;)(f1)
    f2 = BatchNormalization()(f2)
    f2 = 激活(&#39;relu&#39;)(f2)

    f3 = Conv2D(1, 3, 填充=&#39;相同&#39;)(f2)

    模型=模型（输入=输入，输出=f3，名称=&#39;model_C&#39;）
    返回模型
    
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    modelC = model_C（加法）
    
    返回模型（输入，modelC.输出）
    
a = np.random.uniform(0, 1, (100, 32, 32, 3))
b = np.random.uniform(0, 1, (100, 32, 32, 3))
c = np.random.uniform(0, 1, (100, 32, 32, 3))
    
模型 = model_final(32, 32, 3)

优化器 = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(优化器=优化器,
              损失=&#39;mae&#39;,
              指标=[&#39;mae&#39;])
    

如果我运行代码，我会在 Model(inputs=inputs,outputs=f3, name=&#39;model_C&#39;) 处收到 Graph Disconnected。
所以，为了解决这个问题，我正在做：
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    input_C = 输入((高度,宽度,32))
    modelC = model_C(输入_C)
    modelC = modelC(加法)
    
    模型=模型（输入，模型C）
    返回模型

编译得很好。
但是，我不确定这是否正确。如果这样做的逻辑是正确的！]]></description>
      <guid>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</guid>
      <pubDate>Mon, 22 Jan 2024 12:34:03 GMT</pubDate>
    </item>
    <item>
      <title>在本地部署 Azure autoML 模型</title>
      <link>https://stackoverflow.com/questions/77859735/deploying-azure-automl-model-locally</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77859735/deploying-azure-automl-model-locally</guid>
      <pubDate>Mon, 22 Jan 2024 12:07:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 图像处理，使用时尚品牌的历史数据和非线性预测模型进行销售预测 [关闭]</title>
      <link>https://stackoverflow.com/questions/77859348/using-image-processing-with-cnn-for-sales-forecasting-using-historical-data-and</link>
      <description><![CDATA[我想开发一种算法，使用图像处理将具有详尽历史数据的旧产品图像与没有历史数据的新产品图像进行匹配，并预测这些新图像的销量。我想了解我应该使用什么模型，图像处理是否可行，图像处理和随后的 cnn 聚类会导致大量数据丢失，是否有其他方法执行此过程，因为我需要考虑面料的坠落、服装的颜色、廓形等
我想尝试使用像 Inception v3 这样的机器学习模型进行图像处理，但是准确度水平低于标准，我需要更高的准确度才能做出更好的预测，这些预测直接影响库存计划]]></description>
      <guid>https://stackoverflow.com/questions/77859348/using-image-processing-with-cnn-for-sales-forecasting-using-historical-data-and</guid>
      <pubDate>Mon, 22 Jan 2024 11:00:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么感知器没有按预期进行训练？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77858926/why-is-the-perceptron-not-training-as-expected</link>
      <description><![CDATA[我试图学习神经网络，并从感知器开始。
我看了一些教程并完全按照它们进行操作，但它对我不起作用。


var canvas = document.querySelector(&#39;canvas&#39;)
画布宽度=内部宽度；
画布高度=内部高度；
var c = canvas.getContext(&#39;2d&#39;)



函数符号（val）{
  如果（值&gt;= 0）{
    返回1
  } 别的 {
    返回-1
  }
}

类感知器{
  构造函数（数字）{
    this.权重 = []
    这个.lr = 0.1

    for (var i = 0; i &lt; num; i++) {
      this.weights.push(Math.random() * 2 - 1)
    }
  }

  猜测（输入）{
    变量总和 = 0
    for (var i = 0; i &lt; this.weights.length; i++) {
      sum += this.weights[i] * 输入[i]
    }
    var 输出 = 符号（总和）
    返回输出
  }

  训练（输入，目标）{
    var 猜测 = this.guess(输入)
    var 错误 = 目标 - 猜测

    for (var i = 0; i &lt; this.weights.length; i++) {
      this.weights[i] += 错误 * 输入[i] * this.lr
    }
  }
}

var Brain = 新感知器(2)

变量点 = []


类点{
  构造函数（x，y）{
    这个.x = x
    这个.y = y
    这个.标签 = 0

    c.线宽=2

    if (this.y &lt; canvas.height / 2) {
      这个.标签 = 1
    } else if (this.y &gt; canvas.height / 2) {
      这个.标签 = -1
    }
  }
  画（） {
    c.beginPath()
    c.arc(this.x, this.y, 10, 0, Math.PI * 2, false)
    c.fill()
    if (this.label == 1) {
      c.中风()
    }
  }
  更新（） {



    this.draw()
  }
}

for (var i = 0; i &lt; 100; i++) {
  point.push(new Point(Math.random() * canvas.width, Math.random() * canvas.height))
}


函数动画（）{
  请求动画帧（动画）
  c.clearRect(0, 0, canvas.width, canvas.height)
  点.forEach(点=&gt;{


    Brain.train([point.x, point.y], point.label)
    var猜测 = Brain.guess([point.x, point.y])
    if (猜测==点.标签) {
      c.fillStyle = &quot;绿色&quot;
    } 别的 {
      c.fillStyle = &quot;红色&quot;
    }
    点.update()
  })
}

动画（）
&lt;代码&gt;* {
  保证金：0；
  填充：0；
}

帆布 {
  位置：绝对；
}




这是我的代码
谁能告诉我这是怎么回事吗？
我的目标是让感知器对点进行分类，其中屏幕一半以上的点应具有 1 的值，而屏幕一半以下的点应具有 -1 的值]]></description>
      <guid>https://stackoverflow.com/questions/77858926/why-is-the-perceptron-not-training-as-expected</guid>
      <pubDate>Mon, 22 Jan 2024 09:48:47 GMT</pubDate>
    </item>
    <item>
      <title>wandb：如何在高级图例部分显示分组平均值</title>
      <link>https://stackoverflow.com/questions/77858891/wandb-how-to-show-grouped-avarage-in-the-advanced-legend-section</link>
      <description><![CDATA[我正在努力记录我的种子机器学习训练的等待和偏差，我可以看到我所做的事情的良好可视化。
在高级图例部分我可以看到。
[[ ${mean} σ ${stddev} (${min}, ${max}) ]] ${run:displayName}
其中 [[ ${mean} σ ${stddev} (${min}, ${max}) ]] 部分在我悬停时可见。
如何将此值附加到如下所示的文本
 [[ ${mean} σ ${stddev} (${min}, ${max}) ]] ${run:displayName} - ${mean} σ ${stddev} 
感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/77858891/wandb-how-to-show-grouped-avarage-in-the-advanced-legend-section</guid>
      <pubDate>Mon, 22 Jan 2024 09:41:42 GMT</pubDate>
    </item>
    <item>
      <title>将 Pytorch .pth 模型的权重保存到 .txt 或 .json 中</title>
      <link>https://stackoverflow.com/questions/72222557/saving-the-weights-of-a-pytorch-pth-model-into-a-txt-or-json</link>
      <description><![CDATA[我正在尝试将 pytorch 模型的权重保存到 .txt 或 .json 中。将其写入 .txt 时，
#导入火炬
model = torch.load(“model_path”)
字符串 = str(模型)
以 open(&#39;some_file.txt&#39;, &#39;w&#39;) 作为 fp：
     fp.write(字符串)

我得到一个文件，其中并未保存所有权重，即整个文本文件中有省略号。我无法将其写入 JSON，因为模型具有张量，这些张量不可 JSON 序列化 [除非有一种我不知道的方法？] 如何将 .pth 文件中的权重保存为某种格式，以便不显示任何信息丢失了，并且很容易被看到？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/72222557/saving-the-weights-of-a-pytorch-pth-model-into-a-txt-or-json</guid>
      <pubDate>Thu, 12 May 2022 22:09:31 GMT</pubDate>
    </item>
    <item>
      <title>是否有可用于无监督训练的情绪论坛数据集？</title>
      <link>https://stackoverflow.com/questions/52849649/is-there-any-sentiment-forum-dataset-for-unsupervised-training-available</link>
      <description><![CDATA[我最近完成了机器学习课程，想做一个论坛情绪分析工具，应用在股票相关的论坛上。
这个想法是：

捕获（文本挖掘）用户的评论，并评估他们评论的情绪（正面、负面、中立）。
捕捉这些评论后发生的情况（股票市场），并相应地为用户分配权重（如果用户的情绪准确并且市场遵循相同的方向，则权重更大）
将评论用作预测市场方向的工具。

实际上，我自己这样做（关注论坛）加上我自己的技术分析和强制性尽职调查，这对我来说效果很好。我只是想尝试使其自动化一点，甚至可能允许程序使用我的一些帐户（首先是模拟交易，如果它表现良好，则在真实帐户中分配一些资金）
这将是我的第一个机器学习项目（只是作为概念验证），因此我们将非常感谢任何评论。
我发现的最大问题是我想要进行无监督训练，并且我需要一个样本数据集来进行训练。
是否有任何已知的论坛情绪数据集可用于无监督训练？
我发现了几个情感数据集（twitter、imbd、亚马逊评论），但它们非常适合自己的利基市场（短信、电影、产品...），但我正在寻找更通用的东西。]]></description>
      <guid>https://stackoverflow.com/questions/52849649/is-there-any-sentiment-forum-dataset-for-unsupervised-training-available</guid>
      <pubDate>Wed, 17 Oct 2018 07:41:46 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Pandas 对同一 column_id 进行多行 One-hot 编码？</title>
      <link>https://stackoverflow.com/questions/45556281/how-to-do-one-hot-encoding-with-multiple-rows-for-same-column-id-using-pandas</link>
      <description><![CDATA[我有一个 df 格式：
 User_id 技能
0 1 蟒蛇
1 1 爪哇
2 4 爪哇

正在做
df=pd.concat([df,pd.get_dummies(df[&#39;skill&#39;],prefix=&#39;skill&#39;)],axis=1)
 df

输出：
 User_id Skill_python Skill_java
0 1 1 0
1 1 0 1
2 4 0 1

我想获得以下格式的输出：
 User_id Skill_python Skill_java
0 1 1 1
1 4 0 1

如何使用 pandas 做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/45556281/how-to-do-one-hot-encoding-with-multiple-rows-for-same-column-id-using-pandas</guid>
      <pubDate>Mon, 07 Aug 2017 21:54:32 GMT</pubDate>
    </item>
    <item>
      <title>参加 Microsoft Research 句子完成挑战</title>
      <link>https://stackoverflow.com/questions/44373470/get-the-microsoft-research-sentence-completion-challenge</link>
      <description><![CDATA[我目前正在从事学术目的的自然语言处理工作，我想获取 Microsoft Research Sentence Completion Challenge 数据集。
不幸的是，它似乎不再可用在微软网站：当我点击两个链接中的任何一个来获取训练或测试数据时，我会被重定向到微软研究院的主页。我尝试联系微软的技术支持，但他们没有回复我，而且我在其他网站上也找不到该数据集。
你知道我在哪里可以找到这个数据集（我主要对测试集感兴趣）吗？
预先感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/44373470/get-the-microsoft-research-sentence-completion-challenge</guid>
      <pubDate>Mon, 05 Jun 2017 16:30:07 GMT</pubDate>
    </item>
    <item>
      <title>在Weka中从文本文件创建一个arff文件</title>
      <link>https://stackoverflow.com/questions/34460646/in-weka-make-a-arff-file-from-text-file</link>
      <description><![CDATA[在天真的再见分类器中，我想从我的训练和测试中找出准确性。但我的火车就像
快乐：宽恕丰富丰富的荣誉伴奏完成成就成就成就杂技演员令人钦佩的钦佩可爱的崇拜爱先进的出现倡导美学情感富裕生活诱惑阿罗哈 
悲伤：遗弃遗弃遗弃绑架堕胎流产脓肿缺勤缺勤虐待深渊事故被诅咒的疼痛疼痛毒蛇漂流通奸不利逆境痛苦痛苦侮辱后果加重 
愤怒：被遗弃、被遗弃、憎恶、废除、可憎、滥用、被指控、被指控、指控者、指控者、对手、逆境、倡导、侮辱、后果、加剧、加剧、侵略、侵略、侵略者、激动、痛苦、酗酒、疏远、疏远 
对于测试集
data: 2014年12月7日 ... 这首著名的童谣可以帮助孩子练习情绪，比如快乐、悲伤、害怕、疲倦和愤怒。如果你很快乐并且你知道它是......
现在的问题是如何将它们转换成arff文件]]></description>
      <guid>https://stackoverflow.com/questions/34460646/in-weka-make-a-arff-file-from-text-file</guid>
      <pubDate>Fri, 25 Dec 2015 06:43:45 GMT</pubDate>
    </item>
    </channel>
</rss>