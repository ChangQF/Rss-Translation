<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 04 Feb 2024 03:15:06 GMT</lastBuildDate>
    <item>
      <title>根据分类变量对目标变量的影响创建新变量</title>
      <link>https://stackoverflow.com/questions/77933803/creating-new-variable-based-on-categorical-variable-impact-on-target-variable</link>
      <description><![CDATA[我想创建一个价格预测机器学习模型。
当我用目标变量分析分类变量时，目标变量的平均值和中值在分类变量的类别之间差异很大。
&lt;前&gt;&lt;代码&gt;目标中位数
商家来源名称
商户来源 - 1 5.00
商家来源 - 2 6.00
商户来源 - 3 106.00




                         TARGET_MEAN
商家来源名称
商户来源 - 1 220.25
商家来源 - 2 42.95
商户来源 - 3 5862.66


所以我想创建一个依赖于这个分类变量和目标变量的新变量。目标变量呈偏态分布。那么，如果我使用类的中值创建一个新的数值变量是否有意义？
例如；
df[“merchant_source_name_target_median”] = df.groupby(“merchant_source_name”)[“net_ payment_count”].transform(“median”) 
您还有其他建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77933803/creating-new-variable-based-on-categorical-variable-impact-on-target-variable</guid>
      <pubDate>Sat, 03 Feb 2024 21:25:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Roberta 计算最后 4 个隐藏层的加权和？</title>
      <link>https://stackoverflow.com/questions/77933640/how-to-calculate-the-weighted-sum-of-last-4-hidden-layers-using-roberta</link>
      <description><![CDATA[这篇论文中的表格解释了获得嵌入的各种方法，我认为这些方法也适用于 Roberta：

我正在尝试使用 Roberta 计算最后 4 个隐藏层的加权和来获得令牌嵌入，但我不知道这是否是正确的方法，这是我尝试过的代码：
从变压器导入 RobertaTokenizer, RobertaModel
进口火炬

tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;)
模型 = RobertaModel.from_pretrained(&#39;roberta-base&#39;)
Caption = [&#39;这是一只黄色的鸟&#39;, &#39;示例标题&#39;]

tokens = tokenizer(标题, return_tensors=&#39;pt&#39;, padding=True)

input_ids = 标记[&#39;input_ids&#39;]
注意掩码 = 标记[&#39;注意掩码&#39;]

输出=模型（input_ids，attention_mask，output_hidden_​​states = True）

状态 = 输出.hidden_​​states
token_emb = torch.stack([states[i] for i in [-4, -3, -2, -1]]).sum(0).squeeze()
]]></description>
      <guid>https://stackoverflow.com/questions/77933640/how-to-calculate-the-weighted-sum-of-last-4-hidden-layers-using-roberta</guid>
      <pubDate>Sat, 03 Feb 2024 20:34:36 GMT</pubDate>
    </item>
    <item>
      <title>我不断收到 ValueError: 数组长度 2643 与索引长度 3281 不匹配</title>
      <link>https://stackoverflow.com/questions/77933401/i-keep-getting-valueerror-array-length-2643-does-not-match-index-length-3281</link>
      <description><![CDATA[这是我的代码：
# 目标列或我的数据集中的 AnyNan 值
Training_data.dropna(inplace=True, axis=0)
test_data.dropna(inplace=True, axis=0)

# 在 HomePlanet 上执行一次热编码，

功能 = [&#39;HomePlanet&#39;, &#39;目的地&#39;, &#39;CryoSleep&#39;, &#39;VIP&#39; ]
X= pd.get_dummies(training_data[features]).astype(int)
y = pd.get_dummies(training_data.Transported).astype(int)
x_test = 测试数据[特征]

# 创建我的模型

X_train，X_test，y_train，y_test = train_test_split（X，y，train_size = 0.6，test_size = 0.4，random_state = 42）
rt_model = RandomForestRegressor()
rt_model.fit(X_train,y_train)
预测 = rt_model.predict(X_test)

#保存csv

输出= pd.DataFrame（{&#39;PassengerId&#39;：testing_data.PassengerId，&#39;运输&#39;：预测}）
output.to_csv(&#39;提交.csv&#39;, index=False)
print(&quot;您的提交已成功保存！&quot;)

当我在训练测试分割后打印 X 、 y 和 X_train、y_train 的长度时得到：
&lt;前&gt;&lt;代码&gt;6606 6606
3963 3963
2643 2643

我尝试重塑 X 和 y。
我尝试在我的 x_test 数据帧 上执行一种热编码。
我在数组上执行了 iloc 方法。
问题仅来自于试图将其保存为 csv 的最后一部分。]]></description>
      <guid>https://stackoverflow.com/questions/77933401/i-keep-getting-valueerror-array-length-2643-does-not-match-index-length-3281</guid>
      <pubDate>Sat, 03 Feb 2024 19:17:26 GMT</pubDate>
    </item>
    <item>
      <title>用于头影测量标志检测的随机作物数据预处理</title>
      <link>https://stackoverflow.com/questions/77933062/random-crop-data-preprocessing-for-cephalometric-landmark-detection</link>
      <description><![CDATA[我的任务是头影测量地标定位。我的图像路径的坐标显示在此数据框中。

&lt;表类=“s-表”&gt;
&lt;标题&gt;

文件名
X1
Y1


&lt;正文&gt;

/Images_data/Img0006.png
89
80


/Images_data/Img0008.png
37
70


/Images_data/Img0007.png
50
76


/Images_data/Img0003.png
55
92


/Images_data/Img0005.png
91
64


/Images_data/Img0004.png
100
76




我想在训练图中所示的模型之前在数据预处理步骤中使用随机裁剪。
在此处输入图片描述
我尝试使用随机裁剪来提取 10 个图像块。
从 PIL 导入图像
从随机导入 randrange

img = Image.open(r&quot;/Images_data/Img0006.png&quot;)
a, b = 图片大小

矩阵 = 250
样本=10
样本列表 = []

对于范围内的 i（样本）：
    a1 = randrange(0, a - 矩阵)
    b1 = randrange(0, b - 矩阵)
    Sample_list.append(img.crop((a1, b1, a1 + 矩阵, b1 + 矩阵)))

如何将坐标为 x1,y1 的随机裁剪图像块放入深度学习模型？]]></description>
      <guid>https://stackoverflow.com/questions/77933062/random-crop-data-preprocessing-for-cephalometric-landmark-detection</guid>
      <pubDate>Sat, 03 Feb 2024 17:24:43 GMT</pubDate>
    </item>
    <item>
      <title>对看起来像噪音的图像进行分类[关闭]</title>
      <link>https://stackoverflow.com/questions/77932725/classifying-images-that-look-like-noise</link>
      <description><![CDATA[我即将构建一个系统，该系统应该评估如下所示的图像 (900 x 150)，并将其分类为五个类别之一：
看起来像噪音的图像
如果您想知道，它们是 DNA 测序仪流动池中聚类分布的快照。目前正在标记的总数据集约为 30000 张图像。
让系统对这些图像进行分类的最有效方法是什么？
我最初的想法是微调现有的视觉模型（例如，拥抱脸部模型之一），但我对这是否合适存在一些疑问；大多数视觉模型都是根据世界上人和事物的照片进行训练的，因此似乎尝试微调其中一个模型来识别看起来像噪音的图像是行不通的。
如果这个假设是正确的，那么从头开始训练基于 CNN 的模型会是更好的方法吗？也许是 CNN 的修改版本？我读了一篇有趣的研究论文＆quot;使用卷积的图像噪声类型识别具有主成分分析的神经网络”作者将 PCA 融入到他们的 CNN 中。
或者还有其他选择吗？]]></description>
      <guid>https://stackoverflow.com/questions/77932725/classifying-images-that-look-like-noise</guid>
      <pubDate>Sat, 03 Feb 2024 15:43:44 GMT</pubDate>
    </item>
    <item>
      <title>在 Rust-linfa 中加载用于预测的线性回归模型</title>
      <link>https://stackoverflow.com/questions/77932307/loading-a-linear-regression-model-back-up-for-prediction-in-rust-linfa</link>
      <description><![CDATA[我一直在研究 Rust 机器学习的 linfa，特别是线性回归模型。我希望能够保存和加载经过训练的线性回归模型，但我无法找到实现此目的的方法。
到目前为止，我的方法是获取训练中涉及的主要参数，这些参数可以从 linfa 的线性回归实现中获取，并将它们存储在一个可以存储为 JSON 文件的结构中（通过 serde_json 完成）。然而，在此之后我不知道如何将其加载回来进行训练。
以上内容详情如下：
存储训练参数的结构：
struct ModelJson {
    系数：Vec f64 ，
    拦截：f64，
}

存储过程：
let model = lin_reg.fit(&amp;dataset)?;
让 model_json = ModelJson {
    系数： model.params().to_vec(),
    拦截： model.intercept(),
};

存储的数据看起来如何：
{“系数”:[-0.00017907873576254802,-0.00100659702068151,-0.0008275037845519519,0.0004613216043979551,0.00103006349345 99436]，“拦截”：50.525680622870084}

关于序列化和反序列化整个模型，我发现以下信息表明 linfa 中支持相同的操作。
加载和保存模型
这引出了我的第二种方法，其中我使用了 linfa-linear 的 serde 功能（包含 LinearRegression 模型），首先在我的 Cargo.toml 中包含以下内容：
linfa-clustering = {version=&quot;0.7.0&quot;, features=[&quot;serde&quot;]}
根据我对实现的理解，此功能为 LinearRegression 实现了以下功能：
Serde 序列化和反序列化实现 - 派生
上述实现：
&lt;前&gt;&lt;代码&gt;#[cfg_attr(
    特征=“serde”，
    派生（序列化，反序列化），
    serde(crate = “serde_crate”)
)]
/// 可用于进行预测的拟合线性回归模型。
pub struct FittedLinearRegression; {
    截距：F，
    参数：Array1,
}

发现于： linfa-线性导出实现
我的实现如下：
let model = lin_reg.fit(&amp;dataset)?;
让序列化 = serde_json::to_string(&amp;model).unwrap();

但是此方法出现以下错误：
不满足特征边界 `FittedLinearRegression: serde::ser::Serialize`
以下其他类型实现了特征 `serde::ser::Serialize`：
  布尔值
  字符
  大小
  i8
  i16
  i32
  i64
  i128
和其他 133 个rustcClick 以获取完整的编译器诊断
main.rs(82, 22)：此调用引入的绑定所需

是否有其他方法可以做到这一点，或者是否有某种方法可以使这些方法之一发挥作用？]]></description>
      <guid>https://stackoverflow.com/questions/77932307/loading-a-linear-regression-model-back-up-for-prediction-in-rust-linfa</guid>
      <pubDate>Sat, 03 Feb 2024 13:44:24 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的数据集，至少包含 100 列和 10,000 个原始数据 [已关闭]</title>
      <link>https://stackoverflow.com/questions/77931469/data-set-for-machine-learning-with-minimum-100-columns-and-10-000-raws</link>
      <description><![CDATA[我想要一个至少包含 100 列和 10000 行的数据集。您不能使用任何编程语言来生成它，因为它将用于机器学习实践
提前感谢您的帮助🙏]]></description>
      <guid>https://stackoverflow.com/questions/77931469/data-set-for-machine-learning-with-minimum-100-columns-and-10-000-raws</guid>
      <pubDate>Sat, 03 Feb 2024 09:03:55 GMT</pubDate>
    </item>
    <item>
      <title>在其他层而不是第一层使用 BatchNorm2d 的目的是什么？</title>
      <link>https://stackoverflow.com/questions/77931391/what-is-the-purpose-of-using-batchnorm2d-in-the-other-layers-but-not-in-first</link>
      <description><![CDATA[我正在设计Discriminator类，我在github上看到有人的实现，我无法向自己解释为什么batchnormalization被用在conv2，conv3中，但特别是在第一个卷积层中没有，我为您提供了代码类还有转换函数
类鉴别器（nn.Module）：
    def __init__(self, conv_dim = 32):
        super(鉴别器, self).__init__()

        self.conv_dim = conv_dim
        
        self.conv1 = conv(
            3、conv_dim、4、batch_norm = False
        ）
        self.conv2 = conv(
            转换亮度, 转换亮度 * 2, 4
        ）
        self.conv3 = conv(
            转换亮度 * 2, 转换亮度 * 4, 4
        ）
        self.fc = nn.Linear(
            卷积暗度 * 4 * 4 * 4, 1
        ）
    def 前向（自身，x）：
        leaky_relu = F.leaky_relu
        输出=leaky_relu（
            自转换1(x), 0.2
        ）
        输出=leaky_relu（
            self.conv2(输出), 0.2
        ）
        输出=leaky_relu（
            self.conv3(输出), 0.2
        ）
        输出 = out.view(-1, self.conv_dim * 4 * 4 * 4)
        输出 = self.fc(输出)
        返回

我尝试询问 ChatGPT，但它没有给出一致的答案]]></description>
      <guid>https://stackoverflow.com/questions/77931391/what-is-the-purpose-of-using-batchnorm2d-in-the-other-layers-but-not-in-first</guid>
      <pubDate>Sat, 03 Feb 2024 08:35:38 GMT</pubDate>
    </item>
    <item>
      <title>在 TensorFlow 中使用神经网络进行动物检测</title>
      <link>https://stackoverflow.com/questions/77931021/animal-detection-using-neural-network-in-tensorflow</link>
      <description><![CDATA[当我运行最后一部分来训练模型时，我无法检查图像是否有错误。正如你所看到的，我想检测我是否能够训练我的模型来检测动物，例如动物。猫和狗之间。 数据集。
将 pandas 导入为 pd
将 numpy 导入为 np
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D
从tensorflow.keras.layers导入MaxPooling2D
从tensorflow.keras.layers导入Flatten
从tensorflow.keras.layers导入Dense

# 初始化 CNN
分类器=顺序（）

＃卷积
classifier.add(Conv2D(32,(3,3), input_shape = (64, 64, 3), 激活 = &#39;relu&#39;))

# 池化
classifier.add(MaxPooling2D(pool_size = (2,2)))

# 添加第二个卷积层
classifier.add(Conv2D(32, (3,3), 激活 = &#39;relu&#39;))
classifier.add(MaxPooling2D(pool_size = (2,2)))

# 展平
分类器.add(Flatten())

# 全连接
classifier.add（密集（单位= 128，激活=&#39;relu&#39;））
classifier.add(Dense(单位 = 1, 激活 = &#39;sigmoid&#39;))

# 编译 CNN
classifier.compile（优化器=&#39;adam&#39;，损失=&#39;binary_crossentropy&#39;，指标= [&#39;准确性&#39;]）

# 将 CNN 拟合到图像上

从 keras.preprocessing.image 导入 ImageDataGenerator
train_datagen = ImageDataGenerator(重新缩放 = 1./255,
                                  剪切范围 = 0.2,
                                  缩放范围 = 0.2,
                                  水平翻转=真）

training_set = train_datagen.flow_from_directory(r&quot;D:\神经网络\神经网络完整课程-20240203T042209Z-001\神经网络完整课程-复制\神经网络\training_set&quot;,
                                                目标大小= (64,64),
                                                批量大小 = 32,
                                                类模式 = &#39;分类&#39;)

test_datagen = ImageDataGenerator（重新缩放= 1./255）
test_set = test_datagen.flow_from_directory(r&quot;D:\神经网络\神经网络完整课程-20240203T042209Z-001\神经网络完整课程-复制\神经网络\test_set&quot;,
                                                目标大小= (64,64),
                                                批量大小 = 32,
                                                类模式 = &#39;分类&#39;)

分类器.fit（训练集，
               每纪元的步数=700，
               纪元=10，
               验证数据=测试集，
               验证步骤=10)
train_datagen = ImageDataGenerator(重新缩放 = 1./255,
                                  剪切范围 = 0.2,
                                  缩放范围 = 0.2,
                                  水平翻转=真）

training_set = train_datagen.flow_from_directory(r&quot;D:\神经网络\神经网络完整课程-20240203T042209Z-001\神经网络完整课程-复制\神经网络\training_set&quot;,
                                                目标大小= (64,64),
                                                批量大小 = 32,
                                                类模式 = &#39;分类&#39;)

test_datagen = ImageDataGenerator（重新缩放= 1./255）
test_set = test_datagen.flow_from_directory(r&quot;D:\神经网络\神经网络完整课程-20240203T042209Z-001\神经网络完整课程-复制\神经网络\test_set&quot;,
                                                目标大小= (64,64),
                                                批量大小 = 32,
                                                类模式 = &#39;分类&#39;)

##### 这里我收到错误
分类器.fit（训练集，
               每纪元的步数=700，
               纪元=10，
               验证数据=测试集，
               验证步骤=10)

错误：
]]></description>
      <guid>https://stackoverflow.com/questions/77931021/animal-detection-using-neural-network-in-tensorflow</guid>
      <pubDate>Sat, 03 Feb 2024 05:55:16 GMT</pubDate>
    </item>
    <item>
      <title>VertexAIException - 调用 Gemini-Pro API 时列表索引超出范围错误</title>
      <link>https://stackoverflow.com/questions/77930819/vertexaiexception-list-index-out-of-range-error-when-calling-gemini-pro-api</link>
      <description><![CDATA[我正在以连续的方式调用 Google Gemini-Pro API（大约每分钟 50 个查询）。我相信我已经正确设置了我的 VertexAI 项目和凭据。当我使用的连续查询数量低于恒定条时，查询将运行并且可以很好地收到响应。但是，一旦查询数量超过上述栏，就会出现以下错误：
&lt;块引用&gt;
索引错误 - 列表索引超出范围

请注意，查询数量“bar”是发生此错误的时间取决于每个查询的长度，并且如果查询长度在程序执行期间保持相同，则该错误是一致的。例如，在尝试将查询长度增加大约 20% 后，查询长度从大约 330 个查询下降到大约 60 个查询。
&lt;块引用&gt;
文件
“/Users/user/anaconda3/envs/chat1/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py”，
第 1315 行，文本
返回 self.candidates[0].text
~~~~~~~~~~~~~~~^^^ IndexError：列表索引超出范围

这是什么原因造成的？我已将 VertexAI 服务器位置设置为：“us-central1”，据我所知，该位置的配额应该为 300 个查询/分钟。由于我连续执行 API 调用，但低于每分钟 60 次查询的速率，因此我认为我处于使用正常范围。我目前正在使用免费的 VertexAI 试用帐户（有 300 美元的免费信用）。
我写的Gemini Pro API调用函数是：
def gemini_response(message: str) -&gt; &gt;字符串：
    # 初始化顶点AI
    vertexai.init(project=“project-id-0123”, location=“us-central1”)

    # 加载模型
    模型 = GenerativeModel(“gemini-pro”)

    # 查询模型
    响应 = model.generate_content(消息)
    返回响应.文本

在调试 candidates 变量的问题时，变量检查结果如下所示：
&lt;前&gt;&lt;代码&gt;&gt;自己
&gt;提示_反馈{block_reason：其他}
&gt;使用元数据{prompt_token_count：505total_token_count：505}

&gt;自我候选人
&gt; []

&gt; self._raw_response
&gt;提示_反馈{block_reason：其他}
&gt;使用元数据{prompt_token_count：505total_token_count：505}
]]></description>
      <guid>https://stackoverflow.com/questions/77930819/vertexaiexception-list-index-out-of-range-error-when-calling-gemini-pro-api</guid>
      <pubDate>Sat, 03 Feb 2024 04:05:38 GMT</pubDate>
    </item>
    <item>
      <title>RNN 中的输入编码</title>
      <link>https://stackoverflow.com/questions/77929678/input-encoding-in-rnns</link>
      <description><![CDATA[我正在开发一个循环神经网络 (RNN)，它执行以下任务：有 4 个灯，在每次试验期间，打开其中一盏灯，然后打开另一盏灯。目标是根据灯光的组合做出决定。下面是一个试验示例。

我想知道如何对 RNN 的输入数据进行编码：我应该使用相同的 4 个维度来表示灯打开的第一个和第二个实例，还是应该单独表示它们，即使用 8 个维度？]]></description>
      <guid>https://stackoverflow.com/questions/77929678/input-encoding-in-rnns</guid>
      <pubDate>Fri, 02 Feb 2024 20:25:15 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 CIDEr 评估指标来评估图像字幕模型。即使两个句子相同，它也会输出 0.0 [关闭]</title>
      <link>https://stackoverflow.com/questions/77927272/im-using-cider-evaluation-metric-for-image-captioning-model-it-outputs-0-0-eve</link>
      <description><![CDATA[从 pycocoevalcap.cider.cider 导入 Cider
导入 json

# 加载您的参考和候选标题
# 参考标题的格式应为：{image_id: [caption1, caption2, ...]}
# 候选标题的格式应为：[{image_id, Caption}]

Reference_file = &#39;/content/ref.json&#39;
候选文件 = &#39;/content/preds.json&#39;

将 open(reference_file, &#39;r&#39;) 作为 f：
    引用 = json.load(f)

以 open(candidate_file, &#39;r&#39;) 作为 f：
    候选人 = json.load(f)
打印（候选人）
# 创建 CIDEr 记分器
cider_scorer = 苹果酒()

# 计算 CIDEr 分数
cider_score, cider_scores = cider_scorer.compute_score(参考文献, 参考文献)

# 打印 CIDEr 分数
print(&quot;CIDEr 分数：&quot;, cider_score)


它给出输出 0.0。
ref.json 有以下数据
{&#39;1087539207_9f77ab3aaf.jpg&#39;: [&#39;三个人在背景有树木的田野里骑着全地形车&#39;]}&#39;

preds.json 具有以下数据
{&#39;1087539207_9f77ab3aaf.jpg&#39;: [&#39;三个人在背景有树木的田野里骑着全地形车&#39;]}&#39;

Pycocoevalcap 是一个 github 存储库，它实现了 CIDEr，即基于共识的图像描述评估]]></description>
      <guid>https://stackoverflow.com/questions/77927272/im-using-cider-evaluation-metric-for-image-captioning-model-it-outputs-0-0-eve</guid>
      <pubDate>Fri, 02 Feb 2024 13:18:02 GMT</pubDate>
    </item>
    <item>
      <title>MLflow 代理工件访问：无法找到凭据</title>
      <link>https://stackoverflow.com/questions/72886409/mlflow-proxied-artifact-access-unable-to-locate-credentials</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/72886409/mlflow-proxied-artifact-access-unable-to-locate-credentials</guid>
      <pubDate>Wed, 06 Jul 2022 15:40:30 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 用于多标签分类？</title>
      <link>https://stackoverflow.com/questions/40916939/xgboost-for-multilabel-classification</link>
      <description><![CDATA[是否可以使用XGBoost进行多标签分类？现在，我使用 OneVsRestClassifier 而不是 sklearn 中的 GradientBoostingClassifier。它可以工作，但只使用我的 CPU 的一个核心。在我的数据中，我有大约 45 个特征，任务是用二进制（布尔）数据预测大约 20 列。指标是平均精度 (map@7)。如果您有一个简短的代码示例可供分享，那就太好了。]]></description>
      <guid>https://stackoverflow.com/questions/40916939/xgboost-for-multilabel-classification</guid>
      <pubDate>Thu, 01 Dec 2016 17:33:32 GMT</pubDate>
    </item>
    <item>
      <title>如何获取 Tensorflow 张量尺寸（形状）作为 int 值？</title>
      <link>https://stackoverflow.com/questions/40666316/how-to-get-tensorflow-tensor-dimensions-shape-as-int-values</link>
      <description><![CDATA[假设我有一个 Tensorflow 张量。如何获取张量的尺寸（形状）作为整数值？我知道有两种方法，tensor.get_shape()和tf.shape(tensor)，但我无法获取整数int32&lt;的形状值/code&gt; 值。
例如，下面我创建了一个二维张量，我需要获取 int32 的行数和列数，以便我可以调用 reshape() 创建形状为 (num_rows * num_cols, 1) 的张量。但是，tensor.get_shape() 方法以 Dimension 类型返回值，而不是 int32。
导入tensorflow为tf
将 numpy 导入为 np

sess = tf.Session()
张量 = tf.convert_to_tensor(np.array([[1001,1002,1003],[3,4,5]]), dtype=tf.float32)

sess.run（张量）
# 数组([[ 1001., 1002., 1003.],
# [ 3., 4., 5.]], dtype=float32)

张量形状 = 张量.get_shape()
张量形状
# TensorShape([维度(2), 维度(3)])
打印张量形状
# (2, 3)

num_rows = 张量_形状[0] # ???
num_cols = 张量_形状[1] # ???

张量2 = tf.reshape(张量, (num_rows*num_cols, 1))
# 回溯（最近一次调用最后一次）：
# 文件“”，第 1 行，在  中
# 文件“/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py”，第 1750 行，重塑
# 名字=名字）
# 文件“/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py”，第 454 行，在 apply_op 中
# as_ref=input_arg.is_ref)
# 文件“/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py”，第 621 行，convert_to_tensor
# ret = conversion_func(值, dtype=dtype, name=name, as_ref=as_ref)
# 文件“/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py”，第 180 行，在 _constant_tensor_conversion_function 中
# 返回常量(v, dtype=dtype, name=name)
# 文件“/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py”，第 163 行，常量中
#tensor_util.make_tensor_proto(值, dtype=dtype, shape=shape))
# 文件“/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py”，第 353 行，在 make_tensor_proto 中
# _AssertCompatible(值, dtype)
# 文件“/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py”，第 290 行，在 _AssertCompatible 中
# (dtype.name, repr(不匹配), 类型(不匹配).__name__))
# TypeError: 应为 int32，却得到了“Dimension”类型的 Dimension(6)。
]]></description>
      <guid>https://stackoverflow.com/questions/40666316/how-to-get-tensorflow-tensor-dimensions-shape-as-int-values</guid>
      <pubDate>Thu, 17 Nov 2016 22:37:28 GMT</pubDate>
    </item>
    </channel>
</rss>