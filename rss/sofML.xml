<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 28 Mar 2024 21:13:04 GMT</lastBuildDate>
    <item>
      <title>Meta在视频流平台上的无缝通信模型？</title>
      <link>https://stackoverflow.com/questions/78240811/metas-seamless-communication-model-on-video-streaming-platform</link>
      <description><![CDATA[我想知道如何在youtube或其他平台等视频流媒体平台上使用meta的无缝通信模型？有谁知道怎么做吗？
目前我可以使用存储的音频/视频在本地计算机上运行它。我不知道如何在流媒体平台上运行它。]]></description>
      <guid>https://stackoverflow.com/questions/78240811/metas-seamless-communication-model-on-video-streaming-platform</guid>
      <pubDate>Thu, 28 Mar 2024 20:51:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 MAPIE 进行保形预测，当 alpha 很大时，我得到空的预测集</title>
      <link>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</link>
      <description><![CDATA[我正在使用 MAPIE Python 库进行保形预测。在 MapieClassifier 中，我选择 method=&#39;score&#39;。当 alpha 很小时（1% 到 5% 之间），我得到非空预测集。然而，当我查看从 1% 到 99% 的整个 alpha 范围（例如 alphas = np.arange(0.01,1.00,0.01)）时，预测集中的平均类数逐渐下降为零，尽管 C. Molnar 的书 Python 保形预测简介 (2023) 第 27 页指出 « 用于多类任务的预测集是一组一个或多个类。 »，即它是目标模式集的非空子集。我在两个分类数据集上使用了默认的 XGBoost 模型，并得到了带有大 alpha 的空预测集的现象，其中之一是 Dry Bean 数据集。
这是预测集的平均基数作为 alpha 函数的图表。

据我们观察，平均值最终会低于 1。
我还尝试了 Molnar 书中第 25-28 页的代码，该代码没有明确使用 MAPIE，但进行了类似的计算，并得到了相同的结果：当 alpha 变大时，预测集最终为空。正如 Molnar 书中第 27 页所述，我期望得到非空预测集。我观察到，当 alpha 变大时，q_level 会下降，这反过来又会使 q_hat 变小。当 q_level 在 0.7 到 0.9 之间时，作为 q_level 函数的 q_hat 似乎下降得很快（见下图）。

问题：

随着 alpha 变大，预测集会变空，这是可以预料到的吗？
我是否应该将 method=&#39;score&#39; 更改为其他方法来获取非空预测集？
我缺少关于 MAPIE 的良好实践吗？也许人们应该避免使用大阿尔法，或使用方法 score 或其他方法。直觉上，在我看来，我应该总是得到一个非空的预测集。
]]></description>
      <guid>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</guid>
      <pubDate>Thu, 28 Mar 2024 20:28:12 GMT</pubDate>
    </item>
    <item>
      <title>难以理解如何使用机器学习数据集中的字符串数据列表 - 在进行预测之前扩展的功能</title>
      <link>https://stackoverflow.com/questions/78240648/trouble-understanding-how-to-use-list-of-string-data-in-a-machine-learning-datas</link>
      <description><![CDATA[我已经花了几个周末试图解决这个问题，我一直在观看一些教程并阅读，但我仍然缺少数据集实际可行的关键部分。我一直在努力寻找有关实际数据集创建的任何资源。所有教程似乎都只是使用即插即用数据集，没有任何数据背后的推理。
我一直在尝试创建一个预测模型来预测 Google Colab + Tensorflow、Pandas 和 Numpy 中的足球赛事。例如，在此数据集上，这是为了预测玩家是否会在游戏中投篮。
我最初将所有这些都采用嵌套 JSON 格式。我首先使用 Pandas json_normalize() 方法进行了尝试。
我遇到的问题是，当涉及到实际预测时，模型的输入大约是 20,000 个特征或类似的高值。
所以我尝试扁平化我的结构，并使所有内容尽可能通用。不过，我仍然在为同样的事情而苦苦挣扎，因为这些功能的规模正在爆炸式增长。所以我认为我的完整数据集有 153 个不同的列，包括结果列。
存在多种类型的数据
例如：

&lt;标题&gt;

列名称
类型
示例数据
注释


&lt;正文&gt;

PlayerTeam_HomeOrAway
字符串
首页
价值观是“在家”或“离开”。可以转换为数字/布尔值


玩家团队游戏分析
数量
5



玩家团队平均投篮次数
十进制
9.6



位置
字符串
固件
不同的球员位置，FW、DC、MC等


gamesWithShots_game_1_sub
布尔值
错误



PlayerStyles_Strengths_Strong
列表
传球、持球、空中决斗
根据相关玩家的不同，长度可以不同。



所以我认为问题出在 PlayerStyles_Strengths_Strong 等列上。我已经设法将嵌套结构分解为单个值。我有很多这样的专栏，内容涉及弱点、团队优势等。
但是我不明白如何在 CSV 文件中构造这些数据。我希望将其视为单个记录，但它似乎是每个新记录的“热编码”。我在这里可能完全错了，这只是我迄今为止的初步研究。这就是为什么当我尝试使用相同的数据集结构运行预测时，它告诉我功能不匹配。
我不确定这是否是我需要直接使用 Pandas、Tensorflow 做的事情，或者是否是 CSV 结构问题。
我的第一个解决方案想法是为每种类型的力量等添加一列。然后，如果玩家/团队具有该特征，则将 1 / 0 分配到该字段中。我会将其写入将 JSON 转换为 CSV 的 Python 脚本中。在我经历这个费力的过程之前，我想我应该尝试一下，看看是否有一些明显的我遗漏的东西，我的人工智能建模知识正如上面提到的，是我从 YouTube、Udemy 和一些网站上拼凑起来的。 Medium + GeekForGeek 文章。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78240648/trouble-understanding-how-to-use-list-of-string-data-in-a-machine-learning-datas</guid>
      <pubDate>Thu, 28 Mar 2024 20:11:40 GMT</pubDate>
    </item>
    <item>
      <title>集成学习[关闭]</title>
      <link>https://stackoverflow.com/questions/78240346/ensemble-learning</link>
      <description><![CDATA[我有许多不同的数据（图像、时间序列等），我将分别使用它们来创建模型，并且我找到了以下代码作为示例。如果我使用这样的算法，我会做正确的事情吗？或者还有其他方法吗？
将 numpy 导入为 np
从 sklearn.ensemble 导入 VotingClassifier
从 sklearn.linear_model 导入 LogisticRegression
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 precision_score

# 图像数据训练模型
图像模型类：
    def __init__(自身):
        # 此处必须包含经过训练的图像模型
        经过

    def 预测（自身，X）：
        # 例如，我们在这里进行随机猜测
        返回 np.random.randint(0, 2, size=len(X))

# 时间序列数据的训练模型
类时间序列模型：
    def __init__(自身):
        # 这里需要涉及一个经过训练的时间序列模型
        经过

    def 预测（自身，X）：
        # 例如，我们在这里进行随机猜测
        返回 np.random.randint(0, 2, size=len(X))

# 数据加载和准备（使用的示例数据）
X_image = np.random.rand(100, 10) # 样本图像数据（100个样本，每个样本10个）
X_time_series = np.random.rand(100, 20) # 样本时间序列数据（100个样本，每个20个特征）
y = np.random.randint(0, 2, size=100) # 随机标签

# 创建模型
图像模型=图像模型()
time_series_model = TimeSeriesModel()

# 创建集成学习模型
ensemble_model = VotingClassifier(估计器=[
    （&#39;图像模型&#39;，图像模型），
    (&#39;时间系列模型&#39;, 时间系列模型)
]，投票=&#39;硬&#39;）

# 训练模型（这里应该使用用真实数据训练的模型）
ensemble_model.fit([X_image, X_time_series], y)

# 进行预测（这里应该用真实数据进行预测）
y_pred = ensemble_model.predict([X_image, X_time_series])

# 评估模型的成功
准确度=准确度_得分（y，y_pred）
print(&quot;集成学习模型的准确率得分：&quot;, 准确度)


基于这个示例代码，我有很多不同的数据，我如何用它们创建模型，这就是我想问的。我在上面找到了一个示例代码，但我不能确定它的准确性。它在使用Fit方法的同时结合了特征。不知道这个说法对不对。]]></description>
      <guid>https://stackoverflow.com/questions/78240346/ensemble-learning</guid>
      <pubDate>Thu, 28 Mar 2024 19:00:25 GMT</pubDate>
    </item>
    <item>
      <title>如何输入 4 个值（“开盘价”、“最高价”、“最低价”、“总交易量”）来建模并预测未来 x 天的相同 4 个值？</title>
      <link>https://stackoverflow.com/questions/78240071/how-to-input-4-values-open-price-high-price-low-price-total-traded-qu</link>
      <description><![CDATA[我正在开发一个 ML 模型，该模型应该输入并预测以下股票数据：
&#39;开盘价&#39;、&#39;最高价&#39;、&#39;最低价&#39;、&#39;总交易量&#39;
我认为我的代码有问题。如何正确预测未来 x 天的情况？
运行代码的先决条件：
!git 克隆 https://github.com/NSEDownload/NSEDownload
#安装NSEDownload库
!pip3 install NSEDownload/dist/*

以下是我的代码：
from sklearn.model_selection import TimeSeriesSplit
从 sklearn.preprocessing 导入 MinMaxScaler
将 pandas 导入为 pd
将 numpy 导入为 np
从 keras.models 导入顺序
从 keras.layers 导入 LSTM，密集
将 matplotlib.pyplot 导入为 plt
将 matplotlib.dates 导入为 mdates
从 NSE 下载进口库存

股票名称 = &#39;TCS&#39;

# 获取股票数据
df = stocks.get_data(stock_symbol=stock_name, full_data=True)
df.index = pd.to_datetime(df.index)
df.to_csv(f&#39;{stock_name}.csv&#39;)

# 使用过去的天数
n_天 = 10

print(&quot;数据框形状（行、列）：&quot;, df.shape)
print(“是否存在空值？”, df.isnull().values.any())

# 设置目标变量
Training_df = pd.DataFrame(df[&#39;最后价格&#39;])
#选择特征
features = [&#39;开盘价&#39;, &#39;最高价&#39;, &#39;最低价&#39;, &#39;总交易量&#39;]

# 缩放（标准化）
缩放器 = MinMaxScaler()
Training_df_transform = scaler.fit_transform(df[特征])
Training_df_transform= pd.DataFrame(列=特征，数据=training_df_transform，索引=df.index)

时间分割= TimeSeriesSplit(n_splits=10)
对于 timesplit.split(df.index) 中的 train_index、test_index：
    X_train, X_test = Training_df_transform.iloc[:len(train_index)], Training_df_transform.iloc[len(train_index): (len(train_index) + len(test_index))]
    y_train, y_test = Training_df.iloc[:len(train_index)].values.ravel(), Training_df.iloc[len(train_index): (len(train_index) + len(test_index))].values.ravel()

# 创建长度为 n_days 的序列
X_train = np.array([X_train[i : i + n_days] for i in range(len(X_train) - n_days)])
X_test = np.array([X_test[i : i + n_days] for i in range(len(X_test) - n_days)])

# 调整 y_train 和 y_test 以匹配新的 X_train 和 X_test
y_train = y_train[n_days:]
y_test = y_test[n_days:]

# 重塑 X_train 和 X_test 以匹配模型期望的形状
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))

# 定义并训练模型
模型=顺序（）
model.add(LSTM(32，input_shape=(n_days，X_train.shape[2])，activation=&#39;relu&#39;，return_sequences=False))
model.add(Dense(4)) # 更改此设置以匹配输出特征的数量
model.compile(loss=&#39;mean_squared_error&#39;, 优化器=&#39;adam&#39;)
model.fit（X_train，y_train，epochs = 50，batch_size = 8，verbose = 1，shuffle = False）

＃ 预测
y_pred = model.predict(X_test)
# 绘制代码
plt.plot(df.index[-len(y_test):], y_test, label=&#39;实际收盘价&#39;)
plt.plot(df.index[-len(y_test):], y_pred[:, 0], label=&#39;预测收盘价&#39;)
# 设置 x 轴的主要定位器和格式化程序
plt.gca().xaxis.set_major_locator(mdates.MonthLocator(间隔=2))
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %Y&#39;))
plt.title(&#39;测试模型预测&#39; + stock_name)
plt.xlabel(&#39;月份&#39;)
plt.ylabel(&#39;股票价格（卢比）&#39;)
plt.图例()
# 旋转 x 轴标签以获得更好的可读性
plt.xticks（旋转=45）
plt.tight_layout()
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78240071/how-to-input-4-values-open-price-high-price-low-price-total-traded-qu</guid>
      <pubDate>Thu, 28 Mar 2024 17:51:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中加载非常大的时间序列文件进行分析？</title>
      <link>https://stackoverflow.com/questions/78240015/how-to-load-very-big-timeseries-files-in-python-to-do-analysis</link>
      <description><![CDATA[我有一些 .gz 文件，它们包含一些时间序列的数据。当然，我想对此做一些时间序列分析。
我尝试过这个：
导入gzip f=gzip.open(&#39;data.csv.gz&#39;,&#39;r&#39;) file_content=f.read() print(file_content)
但是它加载了 20 分钟，我手动停止了它。
我的问题是，我应该如何阅读这个？我对使用 Dask、Spark 有一些想法，还是应该直接放弃这些行？
尝试查找互联网行业标准。]]></description>
      <guid>https://stackoverflow.com/questions/78240015/how-to-load-very-big-timeseries-files-in-python-to-do-analysis</guid>
      <pubDate>Thu, 28 Mar 2024 17:38:55 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Pytorch 中手动对某一层的输出进行反量化并为下一层重新量化？</title>
      <link>https://stackoverflow.com/questions/78239906/how-to-manually-dequantize-the-output-of-a-layer-and-requantize-it-for-the-next</link>
      <description><![CDATA[我正在开展学校项目，该项目要求我对模型的每一层执行手动量化。具体来说，我想手动实现：
&lt;块引用&gt;
量化激活，结合量化权重A-A层-
量化输出 - 反量化输出 - 重新量化输出，组合
量化权重 B - 层 B - ...

我知道Pytorch已经有量化函数，但该函数仅限于int8。我想从bit = 16到bit = 2进行量化，然后比较它们的准确性。
我遇到的问题是，量化后，某个层的输出变大了多个数量级（bit = 16），并且我不知道如何将其反量化回来。我正在使用相同的激活和权重的最小值和最大值来执行量化。这是一个例子：
激活 = [1,2,3,4]
权重 = [5,6,7,8]
激活和权重的最小值和最大值 = 1, 8
预期的非量化输出 = **260**

量化位 = 16
量化激活 = [-32768, -23406, -14044, -4681]
量化权重 = [4681, 14043, 23405, 32767]
量化输出 = -5609635504
反量化输出，最小值 = 1，最大值 = 8 = **-599178.3750**

这个计算对我来说很有意义，因为输出涉及激活值和权重的相乘，它们的幅度增加也相乘。如果我用原始的最小值和最大值执行一次反量化，那么有一个更大的输出是合理的。
Pytorch 如何处理反量化？我尝试定位Pytorch的量化，但是找不到。如何对输出进行反量化？]]></description>
      <guid>https://stackoverflow.com/questions/78239906/how-to-manually-dequantize-the-output-of-a-layer-and-requantize-it-for-the-next</guid>
      <pubDate>Thu, 28 Mar 2024 17:17:53 GMT</pubDate>
    </item>
    <item>
      <title>网络抓取项目[关闭]</title>
      <link>https://stackoverflow.com/questions/78238872/web-scraping-project</link>
      <description><![CDATA[我正在构建一个项目，该项目从包含远程作业的网站上抓取作业详细信息（主要关注远程开发人员作业）。这是链接：https://remote.co/remote-jobs/developer/ 
到目前为止，我已经能够获取职位名称、公司、薪水以及指向包含有关特定职位发布的更多信息的各个页面的链接，我已经能够将结果存储在 Pandas DataFrame 中，然后存储在Excel 文件。为此，我使用了 BeautifulSoup、Requests 和 Pandas 库。
我的数据框的图像
对于一些职位发布，工资没有列出（要么是 0 美元，要么没有给出），所以这给了我一个进一步推进项目的机会。我想进入每个职位发布的每个网页并提取更多特征，例如所需的经验年限，职位级​​别，公司规模，所需的技术（我打算将这部分分解为多个特征，例如所需的前端知识，后端知识所需的云知识、所需的 DevOps 知识等）以及我可以提取的任何其他可能的功能，并使用它们来训练一个模型，我可以用它来预测未指定薪资的职位发布的价格。
但是，我在知道如何解决这个问题时遇到了一些麻烦，每个单独的职位列表页面都有不同的结构，因此很难编写正确抓取所需信息的代码。
我希望 Stack Overflow 上的一些人可以帮助我，我也愿意接受与此无关的任何建议，这些建议可以使我的项目变得更好。
谢谢！
我现在陷入困境，不知道如何实现我的想法。]]></description>
      <guid>https://stackoverflow.com/questions/78238872/web-scraping-project</guid>
      <pubDate>Thu, 28 Mar 2024 14:24:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 Geotiff 图像分割</title>
      <link>https://stackoverflow.com/questions/78238294/segmentation-with-geotiff-image</link>
      <description><![CDATA[我想用 python 进行 k-means 分割。我的代码适用于 jpg 图像，但是当我尝试使用 geotiff 时，它只会使图像变成黑白。我怎么解决这个问题？下面是我的代码；
导入 matplotlib 作为 mpl
将 matplotlib.pyplot 导入为 plt
将 matplotlib.image 导入为 mpimg
从 sklearn.cluster 导入 KMeans

从 PIL 导入图像
Image.MAX_IMAGE_PIXELS = 无

从 google.colab 导入驱动器
驱动器.mount（&#39;/内容/驱动器&#39;）

# Dosya yolu，Google Drive&#39;ınızda dosyanın bulunduğu yol

file_path = &#39;/content/drive/MyDrive/Colab Notebooks/ortofoto.tif&#39;

# TIFF dosyasını oku
图像 = mpimg.imread(文件路径)
[文本]([https://stackoverflow.com](https://stackoverflow.com))

# 多斯亚伊·戈斯特
plt.imshow(图像)
plt.show()

X=图像.reshape(-1, 4)
kmeans=KMeans(n_clusters=2, n_init=10).fit(X)

segmented_img=kmeans.cluster_centers_[kmeans.labels_]
splited_img=segmented_img.reshape(image.shape)
plt.imshow(segmented_img/255)
]]></description>
      <guid>https://stackoverflow.com/questions/78238294/segmentation-with-geotiff-image</guid>
      <pubDate>Thu, 28 Mar 2024 12:48:44 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用经过训练的layoutlmv3时出现问题</title>
      <link>https://stackoverflow.com/questions/78237278/issue-when-trying-to-use-trained-layoutlmv3</link>
      <description><![CDATA[我正在尝试布局我训练的模型，但我不知道该怎么做。
我混合了互联网上的一些想法来做到这一点，但当我运行它时，结果完全错误。尽管在训练期间我的 F1 分数为 0.924242，准确度分数为 0.948276，但这些框根本不匹配。我在 80 个图像数据集上训练了我的模型。
我一直在尝试使用我经过培训的layoutlmv3模型，以便在我的学校项目中本地使用
如果有人能提供帮助，那就太棒了，我是机器学习的初学者。很多TKS
我一直在尝试的代码：
model_name = “checkpoint-1000”
模型 = AutoModelForTokenClassification.from_pretrained(model_name)
处理器 = AutoProcessor.from_pretrained(“microsoft/layoutlmv3-base”, apply_ocr=True)

id2label = {0: &#39;key_achats_marchandises&#39;, 1: &#39;key_actif_circulant&#39;, 2: &#39;key_actif_immobilise&#39;, 3: &#39;key_ca&#39;, 4: &#39;key_charges_sociales&#39;, 5: &#39;key_date_cloture&#39;, 6: &#39;key_dette&#39;, 7: &#39;key_disponibilites&#39; , 8: &#39;key_dotations_immobilizes&#39;, 9: &#39;key_impots&#39;, 10: &#39;key_passif_circulant&#39;, 11: &#39;key_resultat_exploitations&#39;, 12: &#39;key_rn&#39;, 13: &#39;key_salaire&#39;, 14: &#39;key_transports_expeditions&#39;,}

label2color = {“key_achats_marchandises”：“蓝色”，“key_actif_circulant”：“绿色”，“key_actif_immobilise”：“橙色”，“key_ca”：“红色”，“key_charges_sociales”：“紫色”、“key_date_cloture”：“青色”、“key_dette”：“品红色”、“key_disponibilites”：“黄色”、“key_dotations_immobilizes”：“蓝色”、“key_impots”：“紫色”绿色”、“key_passif_circulant”：“橙色”、“key_resultat_exploitations”：“红色”、“key_rn”：“紫色”、“key_salaire”：“青色”、“key_transports_expeditions”：“洋红色”,}

def unnormalize_box(bbox, 宽度, 高度):
     返回 [ 宽度 * (bbox[0] / 1000), 高度 * (bbox[1] / 1000), 宽度 * (bbox[2] / 1000), 高度 * (bbox[3] / 1000), ]

def iob_to_label(标签):
      退货标签

def process_image(图像):
      image = Image.open(image).convert(“RGB”) print(type(image)) 宽度，高度 = image.size
      编码=处理器（图像，截断= True，return_offsets_mapping = True，return_tensors =“pt”）
      offset_mapping = 编码.pop(&#39;offset_mapping&#39;)

      输出=模型（**编码）

      预测=outputs.logits.argmax(-1).squeeze().tolist()
      token_boxes=encoding.bbox.squeeze().tolist()
      打印（预测）
      is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0
      true_predictions = [id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]
      true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]
      打印（真实预测）
      绘制 = ImageDraw.Draw(图像)
      字体 = ImageFont.load_default()
      对于预测，zip 中的框（true_predictions，true_boxes）：
          预测标签 = iob_to_label(预测)
          绘制.矩形（盒子，轮廓= label2color [预测标签]）
          draw.text((box[0]+10, box[1]-10), text=predicted_label, fill=label2color[predicted_label], font=font)

      返回图像
process_image(“bilans_842953788_2019-02-28_C_2020-01-31_page_5.png”)
]]></description>
      <guid>https://stackoverflow.com/questions/78237278/issue-when-trying-to-use-trained-layoutlmv3</guid>
      <pubDate>Thu, 28 Mar 2024 09:56:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用动态输入形状在onnx运行时Web中调用onnx（忽略输入形状检查）</title>
      <link>https://stackoverflow.com/questions/78237036/how-to-call-onnx-in-onnx-runtime-web-with-dynamic-input-shapeignoring-input-sha</link>
      <description><![CDATA[我使用 python 获取我的 onnx 输入形状
providers = [&#39;AzureExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;] # 指定您所需的提供程序
sess_options = onnxruntime.SessionOptions()
sess = onnxruntime.InferenceSession(model_path、sess_options、providers=providers)
input_shape = sess.get_inputs()[0].shape
print(f&quot;输入形状：{input_shape}&quot;)

显示
输入形状：[&#39;input_dynamic_axes_1&#39;, &#39;input_dynamic_axes_2&#39;, &#39;input_dynamic_axes_3&#39;, &#39;input_dynamic_axes_4&#39;]

当我在js中运行onnx时
 const session = wait ort.InferenceSession.create(model, {
    executionProviders：[“webgpu”，“webgl”]，
  });
  常量提要：任意 = {}；
  const inputNames = session.inputNames;
  feeds[inputNames[0]] = inputTensor;
  const 结果 = 等待 session.run(feeds);
  const outputData = 结果[session.outputNames[0]].data;
  返回任意的输出数据；

它引发错误
 未捕获（承诺中）错误：输入张量 [0] 检查失败：预期形状 &#39;[,,,]&#39; 但得到 [1,3,800,400]
      验证输入张量尺寸
      规范化和验证输入
      （匿名函数）
      事件
      跑步
      跑步
      跑步
      运行推理

我认为原因是onnx输入形状是动态的，所以下面的onnx js代码总是设置expectedDim == [null, null,null,null]
 私有 validateInputTensorDims(
      graphInputDims: Array&lt;只读数字[]&gt;,给定输入: Tensor[], noneDimSupported: boolean) {
    for (让 i = 0; i 
所以我的问题是：如何使用动态输入形状在onnx运行时网络中调用onnx（忽略输入形状检查）]]></description>
      <guid>https://stackoverflow.com/questions/78237036/how-to-call-onnx-in-onnx-runtime-web-with-dynamic-input-shapeignoring-input-sha</guid>
      <pubDate>Thu, 28 Mar 2024 09:15:04 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tfidfvectorizer 的功能从英语修改为西班牙语</title>
      <link>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</link>
      <description><![CDATA[我有一个 tfidfvectorizer，它适合英语文本数据来预测英语通话的情绪。任务是将其转换为西班牙语。我想使用此 tfidfvectorizers 的权重，并希望将功能从英语转换为西班牙语，例如“谢谢”变成“gracias”并使用旧的权重。所以本质上我想使用相同的 tfidf 矢量器，但修改了特征名称。有人可以建议一些方法在 Python 中做到这一点吗？
编辑：我已经将功能从英语转换为西班牙语，并在英语文本上训练了 tfidf。我需要一种使用旧权重和新功能构建 tfidf 的方法，而不使用 fit 函数或将所有文本转换为西班牙语。]]></description>
      <guid>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</guid>
      <pubDate>Wed, 27 Mar 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>解决从 Jupyter Notebook 到 .py 文件的自定义管道类转换中的 OneHotEncoder 问题</title>
      <link>https://stackoverflow.com/questions/78219825/troubleshooting-onehotencoder-issue-in-custom-pipeline-class-conversion-from-jup</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78219825/troubleshooting-onehotencoder-issue-in-custom-pipeline-class-conversion-from-jup</guid>
      <pubDate>Mon, 25 Mar 2024 14:32:03 GMT</pubDate>
    </item>
    <item>
      <title>scikeras.wrappers.KerasClassifier 返回 ValueError：无法解释指标标识符：loss</title>
      <link>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</link>
      <description><![CDATA[我正在研究 KerasClassifier，因为我想将其插入 scikit-learn 管道中，但我收到了前面提到的 ValueError。
以下代码应该能够重现我遇到的错误：
从 sklearn.model_selection 导入 KFold，cross_val_score
从 sklearn.preprocessing 导入 StandardScaler
从 scikeras.wrappers 导入 KerasClassifier
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从 sklearn.datasets 导入 load_iris
将 numpy 导入为 np

数据 = load_iris()
X = 数据.数据
y = 数据.目标

def create_model():
    模型=顺序（）
    model.add（密集（8，input_dim = 4，激活=&#39;relu&#39;））
    model.add（密集（3，激活=&#39;softmax&#39;））
    model.compile(loss=&#39;sparse_categorical_crossentropy&#39;,
                  优化器=&#39;亚当&#39;,
                  指标=[&#39;准确性&#39;])
    返回模型

clf = KerasClassifier(build_fn=create_model,
                      纪元=100，
                      批量大小=10，
                      详细=1)

管道=管道（[
    (&#39;缩放器&#39;, StandardScaler()),
    （&#39;clf&#39;，clf）
]）

kf = KFold(n_splits=5, shuffle=True, random_state=42)
结果= cross_val_score（管道，X，y，cv = kf）
print(&quot;交叉验证准确度：&quot;, np.mean(结果))

似乎我的模型正在随着纪元的运行而被编译。但是，之后我收到错误：
ValueError：无法解释指标标识符：丢失

tensorflow 和 scikeras 库的版本是：
scikeras==0.12.0
张量流==2.15.0

编辑：
最终我尝试了不同的库版本，以下内容让我成功运行了代码，看来问题是由 scikit-learn 的版本引起的：
scikeras==0.12.0
张量流==2.15.0
scikit学习==1.4.1
]]></description>
      <guid>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</guid>
      <pubDate>Fri, 01 Mar 2024 17:03:39 GMT</pubDate>
    </item>
    <item>
      <title>模块“keras.engine”没有属性“Layer”</title>
      <link>https://stackoverflow.com/questions/67905185/module-keras-engine-has-no-attribute-layer</link>
      <description><![CDATA[我尝试运行matterport/MaskRCNN代码，但遇到以下错误
&lt;前&gt;&lt;代码&gt;----&gt; 6 从mrcnn.model导入MaskRCNN

() 中的 /usr/local/lib/python3.7/dist-packages/mrcnn/model.py
    第253章
    第254章
--&gt; 255类ProposalLayer（KE.Layer）：
    256 &quot;&quot;&quot;接收锚分数并选择一个子集作为提案传递
    257 进入第二阶段。过滤是根据锚点分数完成的

AttributeError：模块“keras.engine”没有属性“Layer”
]]></description>
      <guid>https://stackoverflow.com/questions/67905185/module-keras-engine-has-no-attribute-layer</guid>
      <pubDate>Wed, 09 Jun 2021 13:32:37 GMT</pubDate>
    </item>
    </channel>
</rss>