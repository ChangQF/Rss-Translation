<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 23 Aug 2024 18:20:14 GMT</lastBuildDate>
    <item>
      <title>有没有办法在使用带有 GPU 的 Colab 时在 CPU 上运行特定单元？</title>
      <link>https://stackoverflow.com/questions/78907042/is-there-a-way-to-run-a-particular-cell-on-the-cpu-while-using-colab-with-a-gpu</link>
      <description><![CDATA[我正在使用 CoLab 运行一些机器学习模型。我正在使用 pip 安装库，使用 GPU 时，有些库需要很长时间才能安装。有没有办法在 CPU 上运行一个特定的单元来加快速度？]]></description>
      <guid>https://stackoverflow.com/questions/78907042/is-there-a-way-to-run-a-particular-cell-on-the-cpu-while-using-colab-with-a-gpu</guid>
      <pubDate>Fri, 23 Aug 2024 17:41:39 GMT</pubDate>
    </item>
    <item>
      <title>Python Matplotlib ROC 图表</title>
      <link>https://stackoverflow.com/questions/78906819/python-matplotlib-roc-chart</link>
      <description><![CDATA[我正在使用机器学习模型，其中我已经通过对未见数据的测试生成了结果。我正在尝试使用 sklearn 创建 ROC 曲线，但对应该使用哪些列感到有些困惑。有人可以确认我是否做对了吗？我使用了两个类（0 = 真实和 1 = 假）。结果的准确率为 57%。0.61% 的 AUC 看起来差不多，但我是否使用了正确的列？
我已经阅读了 sklearn 网站上有关 roc_curve 函数的说明，但我不清楚。例如，y_score 参数提到目标分数应该是正类的概率估计。我需要对我的 CSV 进行子集化吗？如果需要，我应该如何最好地应用它？
下图是 CSV 文件结构的屏幕截图，其中包含测试结果。该模型将结果保存到 CSV 文件中，然后将其读回以创建 ROC 图表。

plt.rcParams.update({&#39;font.size&#39;: 7})
plt.subplot(2, 5, 4) 
fpr, tpr, 阈值 = metrics.roc_curve(data[&#39;Correct&#39;], data[&#39;P1 Probability&#39;], drop_intermediate=True, pos_label=1)
auc3 = metrics.roc_auc_score(data[&#39;Correct&#39;], data[&#39;P1 Probability&#39;])
plt.plot(fpr,tpr,label=&quot;data 1, auc=&quot; + str(auc3), marker=&#39;o&#39;, color = &quot;gray&quot;, linewidth=1)
plt.plot([0, 1], [0, 1], &#39;k--&#39;)
for xitem,yitem in np.nditer([fpr,tpr]):
etiqueta = &quot;({:.2f}, {:.2f})&quot;.format(xitem, yitem)
plt.annotate(etiqueta, (xitem,yitem), textcoords=&quot;offset pixels&quot;,xytext=(0,10),ha=&quot;center&quot;, color = &quot;b&quot;)
plt.legend(loc=4)
plt.xlabel(&#39;假阳性率&#39;)
plt.ylabel(&#39;真阳性率&#39;)
plt.title(&#39;ROC 曲线 - 阳性类别（假）&#39;)
plt.savefig(&#39;ROC&#39;,dpi=300)


plt.rcParams.update({&#39;font.size&#39;: 7})
plt.subplot(2, 5, 4) 
fpr, tpr, 阈值 = metrics.roc_curve(data[&#39;Actual&#39;], data[&#39;P1 Probability&#39;], drop_intermediate=True, pos_label=1)
auc3 = metrics.roc_auc_score(data[&#39;Actual&#39;], data[&#39;P1概率&#39;])
plt.plot(fpr,tpr,label=&quot;data 1, auc=&quot; + str(auc3), marker=&#39;o&#39;, color = &quot;gray&quot;, linewidth=1)
plt.plot([0, 1], [0, 1], &#39;k--&#39;)
for xitem,yitem in np.nditer([fpr,tpr]):
etiqueta = &quot;({:.2f}, {:.2f})&quot;.format(xitem, yitem)
plt.annotate(etiqueta, (xitem,yitem), textcoords=&quot;offset pixels&quot;,xytext=(0,10),ha=&quot;center&quot;, color = &quot;b&quot;)
plt.legend(loc=4)
plt.xlabel(&#39;假阳性率&#39;)
plt.ylabel(&#39;真阳性率&#39;)
plt.title(&#39;ROC 曲线 - 阳性类别（假）&#39;)
plt.savefig(&#39;ROC&#39;,dpi=300)


如有任何建议，不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78906819/python-matplotlib-roc-chart</guid>
      <pubDate>Fri, 23 Aug 2024 16:35:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 glue mrpc 基准上检查 GTP 模型？</title>
      <link>https://stackoverflow.com/questions/78906413/how-is-the-gtp-model-checked-on-the-glue-mrpc-benchmark</link>
      <description><![CDATA[GPT 建立在 Transformer 解码器上，这意味着模型以自回归的方式处理数据序列，根据前一个单词预测下一个单词。它只使用 Transformer 的解码器部分，与也使用编码器的模型不同。微软研究释义语料库 (MRPC) 是一个基准数据集，广泛用于自然语言处理 (NLP) 任务，特别是用于评估释义识别模型。释义识别是确定两个句子是否具有相同含义的任务。
示例：
| idx | 标签 | 句子 1 | 句子 2 |
|-----|-------|----------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------|
| 0 | 0 | 相同的探测车将充当机器人地质学家，寻找过去水的证据。| 探测车充当机器人地质学家，在六个轮子上移动。|
| 1 | 0 |在 OfficeMax 收购完成后，博伊西的销售额中不到 20% 将来自木材和纸张的生产。| 在 OfficeMax 收购完成后，假设这些业务没有出售，博伊西的销售额中不到 20% 将来自木材和纸张的生产。|
但是，蓝色基准被准备为 2 个序列，并检查它们是否相似。
如何检查胶水上的 GTP 性能？您是否必须以某种方式解开最后一层 GPT？您是否需要修改 GPT 架构？]]></description>
      <guid>https://stackoverflow.com/questions/78906413/how-is-the-gtp-model-checked-on-the-glue-mrpc-benchmark</guid>
      <pubDate>Fri, 23 Aug 2024 14:35:39 GMT</pubDate>
    </item>
    <item>
      <title>关键点/地标检测</title>
      <link>https://stackoverflow.com/questions/78906351/keypoints-landmarks-detection</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78906351/keypoints-landmarks-detection</guid>
      <pubDate>Fri, 23 Aug 2024 14:19:21 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 ResourceExhaustedError：图形执行错误？</title>
      <link>https://stackoverflow.com/questions/78906162/how-to-resolve-resourceexhaustederror-graph-execution-error</link>
      <description><![CDATA[我在对新数据进行预测时遇到错误
model.predict(X_val)
错误内容：
ResourceExhaustedError

ResourceExhaustedError：图形执行错误：

我正在使用 tensorflow，并使用了减少批量大小、使用数据生成器等方法，但没有成功解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78906162/how-to-resolve-resourceexhaustederror-graph-execution-error</guid>
      <pubDate>Fri, 23 Aug 2024 13:29:34 GMT</pubDate>
    </item>
    <item>
      <title>ML 模型训练 - 系统内存使用量随时间增加</title>
      <link>https://stackoverflow.com/questions/78905671/ml-model-training-system-memory-usage-increasing-over-epoch</link>
      <description><![CDATA[我正在使用 sagemaker 特别是 aws ml.g4.xlarge 机器实现一个简单的 MLP，我注意到 RAM 内存随着时间推移不断增加。我正在使用 pytorch.lightning 作为 ML 模型架构。我正在使用一个有 64 个 worker 的数据加载器。
ML Flow - 系统指标
发生的事情是，当模型达到 70% 的训练时，机器崩溃，说它已达到内存最大限制。正如您所看到的，在批次之间内存在增加 - 我的理解是，在批次之间，每个批次都被使用，然后从内存中删除，因此批次之间唯一改变的是权重更新。因此内存使用量不应随步骤增加。
我尝试删除日志，但没有任何变化。虽然这可能是工人的数量，但只增加了一个工人，内存使用量随着时间的推移不断增加。但是，当 num_workers=0 时，它会稳定下来，不会随着时间的推移而增加 - 但训练需要大量时间
ML Flow - 系统指标 - num_workers=0
我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78905671/ml-model-training-system-memory-usage-increasing-over-epoch</guid>
      <pubDate>Fri, 23 Aug 2024 11:28:19 GMT</pubDate>
    </item>
    <item>
      <title>KNN 归纳模型对所有缺失值单元格返回“nan”值，而不是分类列中的类别</title>
      <link>https://stackoverflow.com/questions/78905500/knn-imputation-model-returns-nan-value-for-all-missing-value-cells-instead-of</link>
      <description><![CDATA[**在数据预处理步骤中，我使用 KNN 插补模型来填充分类列中的缺失值。但是，我的代码在所有缺失值单元格中都插补了“nan”，而不是非缺失值单元格中的其他类别**。希望您能帮上忙
数据源文件：https://drive.google.com/file/d/1GvwzPrDfqvkg0l7yLz6_gYv2aLSLbYtR/view?usp=sharing
python来了：
import pandas as pd
from sklearn.impute import KNNImputer
from sklearn.preprocessing import LabelEncoder

# 加载数据集
df_train = pd.read_csv(r&quot;F:\OneDrive - CTY CP DP Pharmacity\Documents\Minh 2024\Kaggle\House_Prices\train.csv&quot;)

# 包含缺失值的列列表，用于估算
columns_with_missing = [&#39;BsmtQual&#39;, &#39;BsmtCond&#39;, &#39;BsmtExposure&#39;, &#39;BsmtFinType1&#39;]

# 用于编码和估算缺失值的函数
def encode_and_impute(df, columns):
label_encoders = {}
df_encoded = df.copy()

# 对分类列进行编码
for col in columns:
le = LabelEncoder()
df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
label_encoders[col] = le

# 应用 KNN 估算器
knn_imputer = KNNImputer(n_neighbors=5)
df_imputed = pd.DataFrame(knn_imputer.fit_transform(df_encoded[columns]), columns=columns)

# 将插补的列解码回原始类别
for col in columns:
df_imputed[col] = label_encoders[col].inverse_transform(df_imputed[col].astype(int))

return df_imputed

# 插补缺失值并更新原始 DataFrame
df_train[columns_with_missing] = encode_and_impute(df_train, columns_with_missing)

# 显示结果以进行检查
df_check = df_train[columns_with_missing]
print(df_check[df_check[&#39;BsmtQual&#39;]== &#39;nan&#39;].head(10))


当前输出：
 BsmtQual BsmtCond BsmtExposure BsmtFinType1 17 南南南南 39 南南南南 90 南南南南 102 南南南南 156 南南南南 182 南南南南南 259 南南南南 342 南南南南 362 南南nan 371 nan nan nan nan  预期输出： 所有“nan”值将与相应列中的其他类别一起]]></description>
      <guid>https://stackoverflow.com/questions/78905500/knn-imputation-model-returns-nan-value-for-all-missing-value-cells-instead-of</guid>
      <pubDate>Fri, 23 Aug 2024 10:41:32 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv10：如何解读训练进度信息？</title>
      <link>https://stackoverflow.com/questions/78904715/yolov10-how-to-interpret-training-progress-info</link>
      <description><![CDATA[我正在用这个代码训练 YOLOv10：
model.train(
.........
epochs=250,
batch=16,
verbose=True,
save=True,
save_period=1,
time=4,
.........
)

我正在尝试各种 VM/GPU 选项来计算最具成本效益的训练选项，所以我运行它很多次，同时我更改 batch 以填充接近 90% 的 GPU RAM。
在训练期间，除了其他输出外，我还获得了类似屏幕截图的信息。

问题：

为什么计划的 epoch 数量 (1) 被更改 (2)？我相信这可能是因为分配给训练的时间有限，所以训练过程会计算在此期间可以运行多少个 epoch，但我不确定。
我相信 (3) 是每个 epoch 的批次数量，这个数字会根据批次大小和 GPU RAM 使用情况而变化。这是正确的吗？
如何估计在特定 GPU/批次设置上训练过程需要多长时间（假设没有配置时间限制）？我尝试将 (4) 和 (5) 相加，然后乘以更改后的周期数 (2)，但在所有实验中，我得到的时间总是接近配置的限制。
是否有文档解释屏幕截图上的所有其他数据以及其他训练输出？有些值是不言自明的，有些则不是，所以我宁愿避免猜测。我检查了 https://docs.ultralytics.com/modes/train/，但没有找到解释。
]]></description>
      <guid>https://stackoverflow.com/questions/78904715/yolov10-how-to-interpret-training-progress-info</guid>
      <pubDate>Fri, 23 Aug 2024 07:12:32 GMT</pubDate>
    </item>
    <item>
      <title>随机森林测试分割</title>
      <link>https://stackoverflow.com/questions/78903794/random-forest-test-split</link>
      <description><![CDATA[我使用六月数据集训练了随机森林模型来预测员工的status_value，并使用0.3分割进行test_size。我包含了代码片段，因为代码本身运行良好，没有任何错误
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
rf = RandomForestClassifier()
rf.fit(X_resampled,y_resampled)
y_pred = rf.predict(X_test)

当我使用经过训练的 RF 模型来预测 status_value 而不拆分 7 月数据集时，它仍然只能预测 30% 的员工，而不是完整的数据集。
ml_cols = [&#39;age&#39;,&#39;months tenure&#39;,&#39;salary_deviation&#39;,&#39;review_rating&#39;,&#39;term Reason enc&#39;,&#39;color_rating&#39;,&#39;satisfaction分数&#39;、&#39;年初至今佣金&#39;、&#39;销售活动&#39;、&#39;销售通话时长&#39;、&#39;销售通话里程&#39;、&#39;推荐&#39;、&#39;承认&#39;]
ml_df_pred =merged_df_pred[ml_cols]
X_pred = ml_df_pred[ml_cols]
y_fcst = merged_df_pred[&#39;status_value&#39;]
y_pred = rf.predict(X_pred)

我该如何确保它不会拆分 7 月份的数据，并对 7 月份数据集中列出的所有 180 名员工进行预测？]]></description>
      <guid>https://stackoverflow.com/questions/78903794/random-forest-test-split</guid>
      <pubDate>Thu, 22 Aug 2024 22:54:38 GMT</pubDate>
    </item>
    <item>
      <title>你能在保持梯度流的同时仿射扭曲张量吗？</title>
      <link>https://stackoverflow.com/questions/78903793/can-you-affine-warp-a-tensor-while-preserving-gradient-flow</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78903793/can-you-affine-warp-a-tensor-while-preserving-gradient-flow</guid>
      <pubDate>Thu, 22 Aug 2024 22:54:33 GMT</pubDate>
    </item>
    <item>
      <title>Azure ML Studio 上的 Pytorch 出现错误：mpirun 检测到一个或多个进程以非零状态退出，从而导致作业终止</title>
      <link>https://stackoverflow.com/questions/78901891/pytorch-on-azure-ml-studio-gives-error-mpirun-detected-that-one-or-more-process</link>
      <description><![CDATA[有人知道为什么它不起作用以及我该如何解决这个问题吗？我使用的数据集已经准备好并清理过，因此所有文件都符合所需的参数，即正确的格式、大小和形状。
我正在使用 Azure 提供的 DenseNet 图像分类管道。我使用的数据集包含 223 幅图像。

]]></description>
      <guid>https://stackoverflow.com/questions/78901891/pytorch-on-azure-ml-studio-gives-error-mpirun-detected-that-one-or-more-process</guid>
      <pubDate>Thu, 22 Aug 2024 13:43:15 GMT</pubDate>
    </item>
    <item>
      <title>如何在一个 cv2 相机屏幕中运行两个计算机视觉模型</title>
      <link>https://stackoverflow.com/questions/78894715/how-to-run-two-computer-vision-models-in-one-cv2-camera-screen</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78894715/how-to-run-two-computer-vision-models-in-one-cv2-camera-screen</guid>
      <pubDate>Tue, 20 Aug 2024 23:51:16 GMT</pubDate>
    </item>
    <item>
      <title>对列应用对数变换</title>
      <link>https://stackoverflow.com/questions/78873685/applying-log-transformation-to-a-column</link>
      <description><![CDATA[
我已使用 OneHotEncoder 对性别列进行编码。我只想对 Female[0] 列应用对数转换，但它对所有列都应用了对数转换 — 为什么？
我的代码：
import pandas as p
from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
from sklearn.compose import ColumnTransformer
import numpy as n

customer=p.read_csv(&#39;/content/Customers.csv&#39;)
customer.drop([&#39;CustomerID&#39;,&#39;Profession&#39;,&#39;Family Size&#39;,&#39;Work Experience&#39;],axis=1,inplace=True)
column=ColumnTransformer(
[
(&#39;ohe_gender&#39;,OneHotEncoder(sparse=False,dtype=n.int32),[0])
],remainder=&#39;passthrough&#39;
)
function=ColumnTransformer(
[
(&#39;function&#39;,FunctionTransformer(n.log1p),[0])
],remainder=&#39;passthrough&#39;
)
s=column.fit_transform(customer)
function.fit_transform(s)

输出：
 array([[0.00000000e+00, 6.93147181e-01, 1.90000000e+01, 1.50000000e+04, 3.90000000e+01],
[0.00000000e+00, 6.93147181e-01, 2.10000000e+01, 3.50000000e+04, 8.10000000e+01],
[6.93147181e-01, 0.00000000e+00, 2.00000000e+01, 8.60000000e+04, 6.00000000e+00],
...,
[0.00000000e+00, 6.93147181e-01, 8.70000000e+01, 9.09610000e+04, 1.40000000e+01],
[0.00000000e+00, 6.93147181e-01, 7.70000000e+01, 1.82109000e+05, 4.00000000e+00],
[0.00000000e+00, 6.93147181e-01, 9.00000000e+01, 1.10610000e+05, 5.20000000e+01]]

在 FunctionTransformer 之前进行编码 (OHE) 后，输出为
array([[ 0, 1, 19, 15000, 39],
[ 0, 1, 21, 35000, 81],
[ 1, 0, 20, 86000, 6],
...,
[ 0, 1, 87, 90961, 14],
[ 0, 1, 77, 182109, 4],
[ 0, 1, 90, 110610, 52]])

我确实想在上述数组的第 0 个索引中应用对数变换，但正如您在第一个输出中看到的那样，它应用于所有值，尽管我在列变换器中指定了 [0]，为什么？我希望输出只有 [0] 索引的对数。]]></description>
      <guid>https://stackoverflow.com/questions/78873685/applying-log-transformation-to-a-column</guid>
      <pubDate>Thu, 15 Aug 2024 04:58:50 GMT</pubDate>
    </item>
    <item>
      <title>我在使用 ydata-profiling-4.4.0 时收到导入错误：`BaseSettings` 已移至 `pydantic-settings` 包</title>
      <link>https://stackoverflow.com/questions/76844229/im-getting-an-import-error-with-ydata-profiling-4-4-0-basesettings-has-been</link>
      <description><![CDATA[我知道 Pydantic V2 引入了新的东西，使其与 V1 不兼容，所以我从 pandas_profiling 切换到 ydata_profiling。因此，我不得不切换依赖项的版本，但现在我遇到了一个复杂的错误，这似乎无法同时解决我导致的所有三个错误：
pydantic-settings 2.0.2 需要 pydantic&gt;=2.0.1，但您有 pydantic 1.8.1，它不兼容。
ydata-profiling 4.4.0 需要 pydantic&lt;2,&gt;=1.8.1，但您有 pydantic 2.1.1，它不兼容。

有没有办法让此代码使用 ydata 工作，或者我应该切换到其他库。目前在 Windows 11 和 Python 版本 3.11.0 上。
from ydata_profiling import ProfileReport

choice = st.radio(&quot;Navigation&quot;, [&quot;Upload&quot;, &quot;Profiling&quot;, &quot;ML&quot;, &quot;Download&quot;, &quot;Predictions&quot;])

if choice == &quot;Profiling&quot;:
profile_report = ProfileReport(df, title=&quot;Profiling Report&quot;)
st_profile_report(profile_report)
#从 ydata_profiling 导入了 ProfileReport 函数，导致之前显示的错误。
]]></description>
      <guid>https://stackoverflow.com/questions/76844229/im-getting-an-import-error-with-ydata-profiling-4-4-0-basesettings-has-been</guid>
      <pubDate>Sun, 06 Aug 2023 02:32:36 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”</title>
      <link>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</link>
      <description><![CDATA[我正在尝试使用最新的可用资源开发一些时间序列序列预测。为此，我确实检查了 TensorFlow 时间序列的示例代码，但我收到了此错误：
AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”

我正在使用 Anaconda。当前环境是 Python 3.5 和 TensorFlow 1.2.1。还尝试了 TensorFlow 1.3，但没有任何变化。
这是我尝试运行的代码。我在 Google 上没有找到与该问题相关的任何有用信息。关于如何解决这个问题您有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</guid>
      <pubDate>Sat, 02 Sep 2017 04:48:51 GMT</pubDate>
    </item>
    </channel>
</rss>