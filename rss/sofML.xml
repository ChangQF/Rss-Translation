<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 27 May 2024 15:16:31 GMT</lastBuildDate>
    <item>
      <title>无法从 feature_extractor 获取正确的输入形状</title>
      <link>https://stackoverflow.com/questions/78539772/unable-to-get-correct-shape-of-input-from-feature-extractor</link>
      <description><![CDATA[我尝试从音频片段中提取特征。现在我有 90 个段，它们已填充到相同的长度 48000。所以形状是 (90, 48000)。但是，当我尝试将其输入 feature_extractor 时，出现错误：
运行时错误：需要 2D（未批处理）或 3D（批处理）输入到 conv1d，但得到的输入大小为：[1, 1, 90, 48000]
另外生成了两个维度。有人能帮我吗？谢谢！
processor = AutoProcessor.from_pretrained(“microsoft/wavlm-base-plus-sd”)
使用 autocast()、torch.no_grad()：
                word_wavs = pad_sequence(word_wavs, batch_first=True, padding_value=0) # 90(6windowsize*15words) x 48000(16k*3s)
                word_lens = torch.stack(word_lens)
                输入=处理器（word_wavs，return_tensors =&#39;pt&#39;，sampling_rate = sr，padding = True）

我打印出了输入的形状，注意掩模的形状为 (1, 90)，input_values 的形状为 (1, 90, 48000)。]]></description>
      <guid>https://stackoverflow.com/questions/78539772/unable-to-get-correct-shape-of-input-from-feature-extractor</guid>
      <pubDate>Mon, 27 May 2024 14:51:02 GMT</pubDate>
    </item>
    <item>
      <title>监督异常检测问题中的平衡和不平衡</title>
      <link>https://stackoverflow.com/questions/78539548/balancing-and-imbalancing-in-supervised-anomaly-detection-probelm</link>
      <description><![CDATA[我正在处理一个监督异常检测问题，其中标签为 0 表示正常，1 表示异常。数据集的默认分布高度不平衡，正常和异常的比例分别为 96:4。
因此，我应用随机欠采样将正常和异常的比率降低到 55:45。现在，准确度为 98%，如下面还提供的其他指标所示。这个概念是正确的还是我错了？
准确度：0.98467329
精度：0.98027553
召回率：0.98755102
F1-分数：0.98389996
曲线下面积：0.98500429
卡帕：0.97917268]]></description>
      <guid>https://stackoverflow.com/questions/78539548/balancing-and-imbalancing-in-supervised-anomaly-detection-probelm</guid>
      <pubDate>Mon, 27 May 2024 14:03:46 GMT</pubDate>
    </item>
    <item>
      <title>Python 中导入的 Orange 模型无法正确获取输入数据</title>
      <link>https://stackoverflow.com/questions/78539448/orange-model-imported-in-python-doesnt-get-the-input-data-right</link>
      <description><![CDATA[我通过 Orange 数据挖掘训练了一个模型。这很简单，它只是根据申请人的一些信息来预测他是否可以获得贷款。我想把它放在Python中，但我不明白如何传递数据。此外，我认为我在数据标准化方面犯了错误，比如字符串（因此橙色上的分类值）可能应该变成数字，等等。
我尝试通过表单填充的向量传递数据；直接来自 Excel 文件；我自己输入数据只是为了看看是否发生了变化。似乎没有什么工作正常。在网上冲浪时，我发现了一些有关 .tab 文件的信息（部署 Orange 3 模型），但我不明白如何具体转换为该扩展名。]]></description>
      <guid>https://stackoverflow.com/questions/78539448/orange-model-imported-in-python-doesnt-get-the-input-data-right</guid>
      <pubDate>Mon, 27 May 2024 13:45:24 GMT</pubDate>
    </item>
    <item>
      <title>在与我之前训练的数据集不同的数据集上训练 yolov8 变得非常慢</title>
      <link>https://stackoverflow.com/questions/78539266/training-yolov8-on-a-different-data-set-than-i-had-previously-trained-it-on-beca</link>
      <description><![CDATA[我正在尝试在与我之前训练过的数据集不同的数据集上训练 yolov8。尽管这是一个较小的数据集，但即使 1 个 epoch 也需要极长的时间才能完成。还有其他人遇到这个问题吗？我可能哪里出错了？
我正在尝试在与我之前训练过的数据集不同的数据集上训练 yolov8。尽管这是一个较小的数据集，但即使 1 个 epoch 也需要非常长的时间才能完成。]]></description>
      <guid>https://stackoverflow.com/questions/78539266/training-yolov8-on-a-different-data-set-than-i-had-previously-trained-it-on-beca</guid>
      <pubDate>Mon, 27 May 2024 13:08:40 GMT</pubDate>
    </item>
    <item>
      <title>Unet图像分割的过拟合问题</title>
      <link>https://stackoverflow.com/questions/78539247/overfitting-problem-of-image-segmentation-with-unet</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78539247/overfitting-problem-of-image-segmentation-with-unet</guid>
      <pubDate>Mon, 27 May 2024 13:03:48 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助根据加速度计数据确定步节奏[关闭]</title>
      <link>https://stackoverflow.com/questions/78538684/need-help-determining-step-rhythm-from-accelerometer-data</link>
      <description><![CDATA[上下文：
我目前正在开展一个项目，其中有来自连接到马前腿的 MetaWear 加速计传感器的数据。该数据包括所有三个轴点的时间序列信息，并在马持续慢跑时记录。我之前使用梯度增强机 (GBM) 进行了特征提取，以识别马是否处于慢跑状态或其他步态。
目标：
我的目标是仅根据加速度计数据来确定马慢跑时的节奏。例如，马可以非常慢地慢跑或非常快地慢跑，我希望能够通过测量每分钟的步数来捕获慢跑速度的变化。本质上，我想了解在给定时间范围内步伐节奏重复的频率。
挑战：
我的数据没有标记，但我可以直观地识别重复模式。
我需要一种有效的方法来标记数据，最好不要手动标记所有重复项。
我研究过 Grafana 等工具，但发现它们不能满足我的需求。
问题：
从给定的加速度计数据确定节奏（每分钟的节拍或步数）的最佳方法是什么？
是否有任何拖放标签工具可以帮助有效地标记大约 100 次重复？或者，是否有任何技术可以避免手动标记？
您会推荐任何其他策略来以不同的方式解决这个问题吗？
其他信息：
这是一个链接 https://docs .google.com/document/d/1iAnwyA9y2AlG2p_CiVEAYdeVEJjL9QKPrbyegsFpCJ8/edit?usp=sharing到我的数据屏幕截图以提供更多背景信息。]]></description>
      <guid>https://stackoverflow.com/questions/78538684/need-help-determining-step-rhythm-from-accelerometer-data</guid>
      <pubDate>Mon, 27 May 2024 11:04:47 GMT</pubDate>
    </item>
    <item>
      <title>MNIST手写数字数据库应该使用GaussianNB还是BernoulliNB来分类？为什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78538647/mnist-database-of-handwritten-digits-should-using-gaussiannb-or-bernoullinb-to-c</link>
      <description><![CDATA[我正在使用 MNIST 数据集，我不知道这是连续数据类型还是离散数据类型以使用正确的分类模型。当我打印图像时，数字 7 图像如下所示。我不知道这是黑白图像还是RGB彩色图像。如果是彩色图像，可以使用GaussianNB，因为它是连续数据，但如果是黑白图像，那么它是离散数据，可以使用伯努利。我想知道这个问题在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78538647/mnist-database-of-handwritten-digits-should-using-gaussiannb-or-bernoullinb-to-c</guid>
      <pubDate>Mon, 27 May 2024 10:55:30 GMT</pubDate>
    </item>
    <item>
      <title>在 python Google Colab 中安装滑板包时出现 2 个错误，这些错误是依赖项冲突和解决不可能错误</title>
      <link>https://stackoverflow.com/questions/78538485/getting-2-errors-while-installing-skater-package-in-python-google-colab-the-err</link>
      <description><![CDATA[!pip installskaker

收集滑冰者

  下载skater-1.1.2.tar.gz (96 kB)

     ──────────────────────────────────────────────────────────────────── 96.7/96.7 kB 1.0 MB/秒 eta 0 :00:00

  准备元数据（setup.py）...完成

已满足要求：/usr/local/lib/python3.10/dist-packages 中的 scikit-learn&gt;=0.18 （来自滑板者）(1.2.2)

收集 scikit-image==0.14 （来自滑板手）

  下载 scikit-image-0.14.0.tar.gz (27.0 MB)

     ────────────────────────────────────────────────────────────────── 27.0/27.0 MB 17.4 MB/秒 eta 0 :00:00

  准备元数据（setup.py）...完成

已满足要求： /usr/local/lib/python3.10/dist-packages 中的 pandas&gt;=0.22.0 （来自滑板者）（2.0.3）

信息：pip 正在查看 Skaker 的多个版本，以确定哪个版本与其他要求兼容。这可能需要一段时间。

收集滑冰者

  下载skater-1.1.0.tar.gz (52 kB)

     ────────────────────────────────────────────────────────────────── 52.5/52.5 kB 1.1 MB/秒 eta 0 :00:00

  准备元数据（setup.py）...完成

  下载skaker-1.0.4.tar.gz (41 kB)

     ────────────────────────────────────────────────────────────────── 41.4/41.4 kB 687.0 kB/s eta 0 :00:00

  准备元数据（setup.py）...完成

  下载skaker-1.0.2.tar.gz (37 kB)

  准备元数据（setup.py）...完成

  下载skaker-1.0.1.tar.gz (36 kB)

  准备元数据（setup.py）...完成

错误：无法安装skate==1.0.1、skate==1.0.2、skate==1.0.4、skate==1.1.0 和skate==1.1.2，因为这些包版本具有冲突的依赖项。



冲突的原因是：

    溜冰者 1.1.2 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.1.0 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.0.4 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.0.2 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.0.1 取决于 ds-lime&gt;=0.1.1.21



要解决此问题，您可以尝试：

1.放宽您指定的软件包版本范围

2.删除软件包版本以允许pip尝试解决依赖冲突



错误：分辨率不可能：如需帮助，请访问 https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts

我尝试在 python Google Colab 中安装skaker 包，但出现上述两个错误。我已访问提到的链接，但无法理解如何解决此问题。]]></description>
      <guid>https://stackoverflow.com/questions/78538485/getting-2-errors-while-installing-skater-package-in-python-google-colab-the-err</guid>
      <pubDate>Mon, 27 May 2024 10:17:51 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模型只学习数据不平衡</title>
      <link>https://stackoverflow.com/questions/78538318/pytorch-model-learns-just-data-imbalance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78538318/pytorch-model-learns-just-data-imbalance</guid>
      <pubDate>Mon, 27 May 2024 09:40:30 GMT</pubDate>
    </item>
    <item>
      <title>验证码解决：-任何人都可以帮我解决这个验证码问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78537910/captcha-solving-can-anyone-help-me-to-solve-this-captcha-problem</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;导入cv2
导入 pytesseract
从 PIL 导入图像

image = cv2.imread(&#39;D:\Automation\captchas\captcha.png&#39;)
如果图像为无：
    print(&quot;错误：无法加载图像。请检查文件路径是否正确以及文件是否存在。&quot;)
别的：
    灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

    _, 阈值 = cv2.threshold(灰色, 8, 255, cv2.THRESH_BINARY)

    内核 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    morphed = cv2.morphologyEx（阈值，cv2.MORPH_CLOSE，内核）
    中值 = cv2.medianBlur(变形, 3)

    
    cv2.imshow(&#39;处理后的图像&#39;, 中位数)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    cv2.imwrite(&#39;D:\Automation\captchas\morphed_image.png&#39;, 中值)

    pytesseract.pytesseract.tesseract_cmd = r&#39;C:/Program Files/Tesseract-OCR/tesseract.exe&#39;
    image_path = “D:\Automation\captchas\morphed_image.png”
    使用 Image.open(image_path) 作为 img：
        文本 = pytesseract.image_to_string(image_path, config=&#39; -c tessedit_char_whitelist=0123456789&#39;)
    打印（“文本：”，文本）

在此处输入图片说明
请我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78537910/captcha-solving-can-anyone-help-me-to-solve-this-captcha-problem</guid>
      <pubDate>Mon, 27 May 2024 08:18:20 GMT</pubDate>
    </item>
    <item>
      <title>如何将张量（pytorch）作为ndarray放入函数中，在每次操作后保留梯度函数？</title>
      <link>https://stackoverflow.com/questions/78536832/how-put-a-tensor-pytorch-as-ndarray-in-a-function-keep-a-gradient-function-af</link>
      <description><![CDATA[如何将 PyTorch 张量作为 ndarray 传递给模拟函数而不丢失梯度信息，或者是否有一种解决方法允许该函数接受张量，同时保留前向和反向传播的必要属性？
TypeError: &#39;model&#39; 必须是 array_like，数据类型为 ， 
得到

导入simulation.dc作为dc
将 numpy 导入为 np

?model = import(//模型路径)
模型=张量（...，requiere_true = True）
dpred = dc.fields.make_a_sintetic_data(模型)
打印（类型（dpred））

＃ 输出：
&gt;&gt;&gt;张量，fn_gradient(...) 
]]></description>
      <guid>https://stackoverflow.com/questions/78536832/how-put-a-tensor-pytorch-as-ndarray-in-a-function-keep-a-gradient-function-af</guid>
      <pubDate>Mon, 27 May 2024 00:59:11 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 保存模型有效，但加载模型无效</title>
      <link>https://stackoverflow.com/questions/78535919/tensorflow-saving-model-works-but-loading-it-doesnt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78535919/tensorflow-saving-model-works-but-loading-it-doesnt</guid>
      <pubDate>Sun, 26 May 2024 16:58:03 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：预期标量类型 Long 但发现 Int</title>
      <link>https://stackoverflow.com/questions/78535309/runtimeerror-expected-scalar-type-long-but-found-int</link>
      <description><![CDATA[我正在运行此笔记本在我的电脑上，它使用 wav2vec2 基本模型处理音频分类，
并在步骤 trainer.evaluate() 中收到此错误：
&lt;块引用&gt;
运行时错误：预期标量类型 Long 但发现 Int
]]></description>
      <guid>https://stackoverflow.com/questions/78535309/runtimeerror-expected-scalar-type-long-but-found-int</guid>
      <pubDate>Sun, 26 May 2024 12:50:55 GMT</pubDate>
    </item>
    <item>
      <title>如何将图像分割成一系列补丁而不丢弃剩余像素</title>
      <link>https://stackoverflow.com/questions/78534650/how-to-split-an-image-into-a-series-of-patches-without-discarding-leftover-pixel</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78534650/how-to-split-an-image-into-a-series-of-patches-without-discarding-leftover-pixel</guid>
      <pubDate>Sun, 26 May 2024 08:09:57 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中却不行 [关闭]</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 Python 编写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def 预处理图像（图像路径）：
    # 加载图像
    img = Image.open(图像路径)
    # 调整图像大小并将其转换为灰度
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将图像转换为 numpy 数组并调整大小为单个向量
    img_array = np.array(img).reshape(1, -1)
    返回img_array
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;成功模型&quot;)
    # 上传并预处理图像
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # 预测班级
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

在橙色工作流程中，我使用了逻辑回归，该模型的准确性相当高。在图像嵌入中我使用了 Inception v3。  这是我获取数据集的位置。我认为我预处理图像的方式有问题，也许它与 Orange 的做法不同，但我找不到有关 Orange 如何做法的任何信息 这是 Orange 工作流程的图像。
编辑：我还尝试在输入中提供一个图像文件夹，结果并不总是相同，但在包含 500 张猫和狗照片的文件夹中，模型仅识别 10 只狗（对绝大多数狗进行错误分类）]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    </channel>
</rss>