<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 06 Apr 2024 00:56:44 GMT</lastBuildDate>
    <item>
      <title>编写成本/损失函数</title>
      <link>https://stackoverflow.com/questions/78282847/writing-the-cost-lost-function</link>
      <description><![CDATA[我有以下训练数据集代码：
# 数组格式的数据
train_data = [[3370,4.5,1],[2949,5.4,1],[4020,5.5,1],[4337,4.7,1],[2519,3.6,1],[4461,5.4,1] ,[2755,5.1,1],[3317,3.2,1],[2672,4.3,1],[2854,4.7,1],
 [3663,2.6,1],[3497,3.2,1],[4603,8.2,1],[2780,3.4,1],[5074,2.5,1],[3354,4.9,1],[4732 ,2.7,1],[5506,3.3,1],[4091,5.6,1],[2890,3.4,1],
  [5873,3.2,0],[5400,3.3,0],[5707,2.2,0],[6408,1.5,0],[8019,1.9,0],[7319,1.9,0],[6212 ,3.6,0],[5918,2.7,0],[8621,3.4,0],[8967,1.7,0],
   [4976,2.1,0],[5477,3.6,0],[5302,5.6,0],[7450,4.0,0],[8580,2.3,0],[7496,3.8,0],[6444 ,3.5,0],[5087,2.7,0],[5791,2.7,0],[4812,2.4,0]]
# pytorch 张量格式的数据
train_X, train_y = torch.tensor(train_data)[:,:2], torch.tensor(train_data)[:,2:3]

绘图数据（train_X，train_y）

现在我不知道如何用这个函数编写成本/损失函数
def J(X, y, w, b):

任何人都可以帮我使用 pytorch 编写代码吗？非常感谢
我可以得到代码]]></description>
      <guid>https://stackoverflow.com/questions/78282847/writing-the-cost-lost-function</guid>
      <pubDate>Sat, 06 Apr 2024 00:37:40 GMT</pubDate>
    </item>
    <item>
      <title>验证的准确性比测试更高</title>
      <link>https://stackoverflow.com/questions/78282544/higher-accuracy-in-validation-that-test</link>
      <description><![CDATA[我使用 80/10/10 分割规则训练了一个模型。我的验证准确度约为 80%（皮尔逊相关），我的测试数据集的准确度约为 83%。这样可以吗？
我尝试了不同的正则化技术来从验证数据集中获得最佳结果，但是，我也不期望在测试数据集中获得更高的准确性]]></description>
      <guid>https://stackoverflow.com/questions/78282544/higher-accuracy-in-validation-that-test</guid>
      <pubDate>Fri, 05 Apr 2024 22:12:48 GMT</pubDate>
    </item>
    <item>
      <title>如何提高基于 Keras 的 CNN 眼底图像分类的训练和测试准确性？</title>
      <link>https://stackoverflow.com/questions/78281500/how-can-i-improve-my-keras-based-cnns-training-and-testing-accuracy-for-fundus</link>
      <description><![CDATA[``我一直致力于使用包含 400 张图像的眼底图像集（来自 MESSIDOR）创建糖尿病视网膜病变分类模型，分级范围为 0-3（4 个类别）。我尝试过使用增强、dropout 和正则化器来更改模型架构、复杂性、输出特征，但我的模型训练和验证准确度似乎无法超过 50%。
这是我的代码：&#39;`
#将数据拆分为训练集和验证集X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)
#定义模型结构
&lt;前&gt;&lt;代码&gt;模型 = 顺序()

#转换层
model.add(Conv2D(64, kernel_size=(3, 3), activate=&#39;relu&#39;, input_shape=(250, 250, 3), kernel_regularizer=regularizers.l2(0.0001)))#输出滤波器为 32)
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, (3, 3), 激活=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.001)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(256, (3, 3), 激活=&#39;relu&#39;, kernel_regularizer=regularizers.l2(0.001)))
model.add(MaxPooling2D(pool_size=(2, 2)))
模型.add(压平())
#密集层
model.add（密集（64，激活=&#39;relu&#39;））
模型.add(Dropout(0.45))
model.add（密集（4，激活=&#39;softmax&#39;））

`**# 编译模型
**`opt = keras.optimizers.Adam(learning_rate=0.00001)
model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=opt, 指标=[&#39;accuracy&#39;])

打印（模型.摘要（））

`***# 数据增强
**`数据生成=图像数据生成器（
    旋转范围=30，
    宽度偏移范围=0.2，
    height_shift_range=0.2，
    水平翻转=真，
    fill_mode=&#39;最近&#39;
）

历史= model.fit（datagen.flow（X_train，y_train，batch_size = 2），epochs = 30，validation_data
（X_测试，y_测试），随机播放=真）

model.evaluate(X_test, y_test)



所附图像的准确性和丢失结果[在此处输入图像描述](https://i.stack.imgur.com/dgbal.png&lt; /a&gt;)]]></description>
      <guid>https://stackoverflow.com/questions/78281500/how-can-i-improve-my-keras-based-cnns-training-and-testing-accuracy-for-fundus</guid>
      <pubDate>Fri, 05 Apr 2024 17:25:53 GMT</pubDate>
    </item>
    <item>
      <title>如何解释神经网络中的分布式表示（隐藏神经元的输出）？</title>
      <link>https://stackoverflow.com/questions/78281488/how-to-interpret-distributed-representationsoutputs-of-the-hidden-neurons-in-a</link>
      <description><![CDATA[训练具有 1 个隐藏层（由 2 个神经元组成）的 FNN：
模型 = train1([2])
绘制每个隐藏神经元的拟合以及输出：
plot1(X1, y1, label=&quot;train&quot;)
图1（X1测试，y1测试，标签=“测试”）
plot1fit(torch.linspace(0, 13, 500).unsqueeze(1), 模型, 隐藏=True, 比例=False)

输出如下：

当使用 3 个隐藏神经元进行训练时：

如何解释图表和每个隐藏神经元的输出的拟合情况？将上述视为分布式表示/嵌入，它真的很直观吗？]]></description>
      <guid>https://stackoverflow.com/questions/78281488/how-to-interpret-distributed-representationsoutputs-of-the-hidden-neurons-in-a</guid>
      <pubDate>Fri, 05 Apr 2024 17:23:10 GMT</pubDate>
    </item>
    <item>
      <title>在神经网络中创建并加载数据集</title>
      <link>https://stackoverflow.com/questions/78281439/creating-and-loading-the-dataset-in-neural-network</link>
      <description><![CDATA[我是深度学习的初学者...我想做图像分类，我的文件夹中有很多图像...
将 numpy 导入为 np
从张量流导入keras
将 matplotlib.pyplot 导入为 plt
导入keras
数据=keras.datasets.fashion_mnist
(train_images,train_labels),(test_images,test_labels)=data.load_data()

火车图像=火车图像/255.0
测试图像=测试图像/255.0


plt.imshow(train_images[0],cmap=plt.cm.binary)
plt.show()

名称=[&#39;T恤&#39;，&#39;裤子&#39;，&#39;套头衫&#39;，&#39;连衣裙&#39;，&#39;外套&#39;，&#39;凉鞋&#39;，&#39;衬衫&#39;，&#39;运动鞋&#39;，&#39;包&#39;，&#39;踝靴&#39;]
模型=keras.Sequential([
    keras.layers.Flatten(input_shape=(28,28)),
    keras.layers.Dense(10,activation=“softmax”)
]）
model.compile(optimizer=“adam”,loss=“sparse_categorical_crossentropy”,metrics=[“accuracy”])

model.fit(train_images,train_labels,epochs=5)

预测=模型.预测(test_images)

对于范围 (4) 内的 i：
    plt.网格（假）
    plt.imshow(test_images[i],cmap=plt.cm.binary)
    plt.xlabel(“实际：”+names[test_labels[i]])
    plt.title(“预测：”+names[np.argmax(预测[i])])
    plt.show()


现在上面的程序基本上是从 MNIST 加载数据集...现在我创建了一个文件夹并将图像放入该文件夹中...现在如何加载该数据集并对其进行预处理？
附：我会给出类名。请有人帮助我。
我尝试了几种方法，但我没有得到它..请有人帮助我]]></description>
      <guid>https://stackoverflow.com/questions/78281439/creating-and-loading-the-dataset-in-neural-network</guid>
      <pubDate>Fri, 05 Apr 2024 17:10:33 GMT</pubDate>
    </item>
    <item>
      <title>由于内存违规或花费太长时间而导致测试用例错误</title>
      <link>https://stackoverflow.com/questions/78281410/error-in-the-test-case-due-to-memory-violation-or-it-took-too-long</link>
      <description><![CDATA[我正在做一个程序，结果是正确的，但对于一个案例测试它不起作用，我不知道到底为什么。
原因是由于内存违规或输出结果花费的时间太长。
我的程序是关于机器学习的，我需要根据学生的行为，使用点之间的距离来查看是否获得批准。
#include ;
#include ;
#include ; // 使用malloc
#定义 MAX_SAMPLES 300000
#定义 MAX_STUDENTS 300000

类型定义结构{
    浮动学习时间；
    浮动平均成绩；
    int pass_or_fail;
    浮动距离；
} 样品；

类型定义结构{
    浮动学习时间；
    浮动平均成绩；
} 评估；

// 调整最大堆的函数
void heapify(样本sample_array[], int n, int i) {
    int 最大 = i; // 将最大的初始化为root
    int 左 = 2 * i + 1; // 左孩子的索引
    int 右 = 2 * i + 2; // 右子节点的索引

    // 如果左孩子大于根
    if (left &lt; n &amp;&amp; 样本数组[左].距离&gt; 样本数组[最大].距离)
        最大=左；

    // 如果右孩子大于迄今为止最大的孩子
    if (右 &lt; n &amp;&amp; 样本数组[右].距离 &gt; 样本数组[最大].距离)
        最大=右；

    // 如果最大的不是根
    如果（最大！=我）{
        // 将最大的与根交换
        样本温度=样本数组[i]；
        样本数组[i] = 样本数组[最大];
        样本数组[最大] = 临时；

        // 递归调整受影响的堆
        heapify(sample_array, n, 最大);
    }
}

// 堆排序的主要函数
void heapSort(样本sample_array[], int n) {
    // 构建最大堆
    for (int i = n / 2 - 1; i &gt;= 0; i--)
        heapify（样本数组，n，i）；

    // 从堆中逐个取出元素
    for (int i = n - 1; i &gt; 0; i--) {
        // 将当前根移动到末尾
        样本温度=样本数组[0]；
        样本数组[0] = 样本数组[i];
        样本数组[i] = 临时；

        // 在缩减堆上调用 max heapify
        heapify(sample_array, i, 0);
    }
}

int main() {
    int n_样本；
    int n_students_be_evaluated;
    整数 k；
    int pass_count；
    int 失败计数；

    scanf(“%d %d %d”, &amp;n_samples, &amp;n_students_to_be_evaluated, &amp;k);

   样本sample_array[MAX_SAMPLES]；
   评估的valued_array[MAX_STUDENTS]；

    // 读取样本
    for (int j = 0; j &lt; n_samples; j++) {
        scanf(“%f %f %d”, &amp;sample_array[j].average_grade, &amp;sample_array[j].study_hours, &amp;sample_array[j].pass_or_fail);
    }

    // 读取待评价的学生
    for (int i = 0; i &lt; n_students_to_be_evaluated; i++) {
        scanf(“%f %f”, &amp;evaluated_array[i].average_grade, &amp;evaluated_array[i].study_hours);
    }

    // 加工
    for (int i = 0; i &lt; n_students_to_be_evaluated; i++) {
        通行数=0；
        失败计数=0；

        // 计算距离并使用堆排序进行排序
        for (int j = 0; j &lt; n_samples; j++) {
            样本数组[j].距离 = sqrt(((evaluated_array[i].study_hours - 样本_array[j].study_hours)*(evaluated_array[i].study_hours - 样本_array[j].study_hours)) +
                                              ((evaluated_array[i].average_grade -sample_array[j].average_grade)*(evaluated_array[i].average_grade -sample_array[j].average_grade)));
        }

        heapSort(sample_array, n_samples);

        // 统计最近的k个中通过和失败的数量
        for (int g = 0; g &lt; k; g++) {
            if (sample_array[g].pass_or_fail == 1)
                通过计数++；
            别的
                失败计数++；
        }

        // 检查学生是否通过
        如果（通过计数&gt;失败计数）{
            printf(“学生%d：(%.2f，%.2f) = 通过\n”，i，evaluated_array[i].average_grade，evaluated_array[i].study_hours);
        } 别的 {
            printf(“学生%d：(%.2f，%.2f) = 失败\n”，i，evaluated_array[i].average_grade，evaluated_array[i].study_hours);
        }
    }


    返回0；
}


我尝试动态分配并使用合并排序。还尝试以静态形式增加数组的大小]]></description>
      <guid>https://stackoverflow.com/questions/78281410/error-in-the-test-case-due-to-memory-violation-or-it-took-too-long</guid>
      <pubDate>Fri, 05 Apr 2024 17:04:20 GMT</pubDate>
    </item>
    <item>
      <title>NeuralProphet 中的多变量预测</title>
      <link>https://stackoverflow.com/questions/78281016/multivariate-forecast-in-neuralprophet</link>
      <description><![CDATA[我正在尝试构建一个全局模型来同时预测两个时间序列。下面的代码运行没有错误。但预测数据帧的所有 NaN 都对应于两个 ID 之一（即有两个时间序列）。 yhat 值也全部为 NaN。我做错了什么或遗漏了什么吗？
m = NeuralProphet(
    yearly_seasonality=真，
    week_seasonality=真，
    daily_seasonality=假，
    分位数=分位数，
    n_lags=60,
    纪元=100，
    n_预测=30，
    loss_func=&#39;胡贝尔&#39;,
）
m.set_plotting_backend(&#39;绘图&#39;)
m.highlight_nth_step_ahead_of_each_forecast(step_number=10)

指标 = m.fit(train_df[[&#39;ds&#39;, &#39;y&#39;, &#39;ID&#39;]])

df_future = m.make_future_dataframe(
    火车_df，
    n_historic_predictions=真，
）

预测 = m.predict(df_future)
]]></description>
      <guid>https://stackoverflow.com/questions/78281016/multivariate-forecast-in-neuralprophet</guid>
      <pubDate>Fri, 05 Apr 2024 15:44:18 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 TF-IDF 功能和微调嵌入模型复制 PECOS XR-Linear 性能</title>
      <link>https://stackoverflow.com/questions/78278617/cannot-replicate-pecos-xr-linear-performance-with-tf-idf-features-and-a-fine-tun</link>
      <description><![CDATA[我正在尝试使用 TFIDF 和 BGE 模型中的预训练嵌入来复制 XR-Linear。
parsed_result = Preprocessor.load_data_from_file(input_text_path, output_text_path)
Y = parsed_result[“label_matrix”]
语料库 = parsed_result[“语料库”]

预处理器 = Preprocessor.train(corpus, {&quot;type&quot;: &quot;tfidf&quot;})
tfidf_X = 预处理器.预测(语料库)

从句子转换器导入句子转换器
模型 = SentenceTransformer(&#39;BAAI/bge-small-en-v1.5&#39;)
嵌入= model.encode（data.query_string.values，show_progress_bar = True，batch_size = 2048）
打印（嵌入.形状）

我将 TFIDF 特征与 BGE 嵌入水平连接起来，如下所示：
X = scipy.sparse.csr_matrix(scipy.sparse.hstack((tfidf_X,embeddings)))

模型训练：
label_feat = LabelEmbeddingFactory.create(Y, X, method=“pifa”)
cluster_chain = Indexer.gen(label_feat, nr_splits=4)
xlinear_model = XLinearModel.train(X, Y, C=cluster_chain,negative_sampling_scheme=“tfn”)

预测：
def process_query_and_predict（查询，use_cpu_threads）：
    tfidf_vector = 预处理器.predict(查询)
    bge_embedding = model.encode(查询)
    pred_X = scipy.sparse.csr_matrix(scipy.sparse.hstack((tfidf_vector,bge_embedding)))
    Y_pred = xlinear_model.predict(pred_X)
    返回 smat_util.sorted_csr(Y_pred)

但是，令人惊讶的是，与在独立 TF-IDF 向量上训练的模型相比，模型的表现相当差。我看到了 PECOS XR-Linear。我试图复制所执行的过程。我想通过 BGE 模型引入语义功能，而不是 AttnXML。

我哪里出错了？如何将 tf-idf 特征与 BGE 嵌入合并。]]></description>
      <guid>https://stackoverflow.com/questions/78278617/cannot-replicate-pecos-xr-linear-performance-with-tf-idf-features-and-a-fine-tun</guid>
      <pubDate>Fri, 05 Apr 2024 08:22:32 GMT</pubDate>
    </item>
    <item>
      <title>如何找到不同公司竞争对手产品矩阵与特定品牌数据集的相关性？有机器学习来预测适合度吗？</title>
      <link>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</link>
      <description><![CDATA[我试图找到一个数据集（矩阵）的相关性，该数据集（矩阵）包含行上的客户和他们按列拥有的竞争对手产品（拥有=&#39;是&#39;，不拥有=&#39;否&#39;）和另一个客户数据集拥有我们的品牌（拥有=1，不拥有=0）。请记住，我们品牌数据集中的所有零值都是潜在客户。
我尝试了随机森林，但我们对拥有我们品牌的客户的所有价值观都是积极的，我如何根据所有积极的价值观来预测适合度？]]></description>
      <guid>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</guid>
      <pubDate>Fri, 05 Apr 2024 00:53:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 MAPIE 进行保形预测，当 alpha 很大时，我得到空的预测集</title>
      <link>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78240714/using-mapie-for-conformal-predictions-i-get-empty-predictions-sets-when-alpha-is</guid>
      <pubDate>Thu, 28 Mar 2024 20:28:12 GMT</pubDate>
    </item>
    <item>
      <title>如何为自定义变压器创建 pandas 输出？</title>
      <link>https://stackoverflow.com/questions/75026592/how-to-create-pandas-output-for-custom-transformers</link>
      <description><![CDATA[scikit-learn 1.2.0 中有很多变化，它支持所有变压器的 pandas 输出，但如何在自定义变压器中使用它？
在[1]中：这是我的自定义转换器，它是一个标准缩放器：
从 sklearn.base 导入 BaseEstimator、TransformerMixin
将 numpy 导入为 np

类 StandardScalerCustom（BaseEstimator，TransformerMixin）：
    def fit(self, X, y=None):
        self.mean = np.mean(X, 轴=0)
        self.std = np.std(X, 轴=0)
        返回自我

    def 变换（自身，X）：
        返回 (X - self.mean) / self.std

在 [2] 中：创建了特定的规模管道
scale_pipe = make_pipeline(StandardScalerCustom())

在[3]中：添加到完整的管道中，它可能与缩放器、输入器、编码器等混合。
full_pipeline = ColumnTransformer([
    (“imputer”, impute_pipe, [&#39;column_1&#39;])
    （“缩放器”，scale_pipe，[&#39;column_2&#39;]）
]）

# 来自文档
full_pipeline.set_output(transform=&quot;pandas&quot;)

出现此错误：
ValueError：无法配置 StandardScalerCustom() 的输出，因为 set_output 不可用。
&lt;小时/&gt;
有一个解决方案，它可以是：
set_config(transform_output=&quot;pandas&quot;) 
但是在具体情况的基础上，如何在 StandardScalerCustom() 类中创建一个可以修复上述错误的函数？]]></description>
      <guid>https://stackoverflow.com/questions/75026592/how-to-create-pandas-output-for-custom-transformers</guid>
      <pubDate>Fri, 06 Jan 2023 03:14:45 GMT</pubDate>
    </item>
    <item>
      <title>如何将极坐标数据框与 scikit-learn 一起使用？</title>
      <link>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</link>
      <description><![CDATA[我无法将极坐标数据帧与 scikitlearn 一起使用进行机器学习训练。
目前，我正在极坐标中进行所有数据帧预处理，在模型训练期间，我将其转换为 pandas 数据帧以使其正常工作。
是否有任何方法可以直接使用 Polars 数据帧进行 ML 训练而不将其更改为 pandas？]]></description>
      <guid>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</guid>
      <pubDate>Fri, 11 Nov 2022 05:59:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 Conda + Poetry 有意义吗？</title>
      <link>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</link>
      <description><![CDATA[在机器学习项目中使用 Conda + Poetry 有意义吗？让我分享一下我（新手）的理解，请指正或赐教：
据我了解，Conda 和 Poetry 有不同的目的，但很大程度上是多余的：

Conda 主要是一个环境管理器（实际上不一定是 Python），但它也可以管理包和依赖项。
Poetry 主要是一个 Python 包管理器（例如，pip 的升级版），但它也可以创建和管理 Python 环境（例如，Pyenv 的升级版） .

我的想法是同时使用两者并划分它们的角色：让 Conda 担任环境管理器，让 Poetry 担任包管理器。我的推理是（听起来）Conda 最适合管理环境，可用于编译和安装非 python 包，尤其是 CUDA 驱动程序（用于 GPU 功能），而 Poetry 作为 Python 包管理器比 Conda 更强大。 
通过在 Conda 环境中使用 Poetry，我成功地相当轻松地完成了这项工作。诀窍是不使用 Poetry 来管理 Python 环境：我没有使用诸如 poetry shell 或 poetry run 这样的命令，只使用 poetry init 、poetry install 等（激活Conda环境后）。
为了充分披露，我的 environment.yml 文件（针对 Conda）如下所示：
&lt;前&gt;&lt;代码&gt;名称：N

渠道：
  - 默认值
  - 康达锻造

依赖项：
  - 蟒蛇=3.9
  -cuda工具包
  - 库德恩

我的poetry.toml文件看起来像这样：
&lt;前&gt;&lt;代码&gt;[工具.诗歌]
名称=“N”
作者 = [“B”]

[工具.诗歌.依赖项]
蟒蛇=“3.9”
火炬 =“^1.10.1”

[构建系统]
需要= [“诗歌核心&gt;=1.0.0”]
构建后端=“poetry.core.masonry.api”

说实话，我这样做的原因之一是我在没有 Conda 的情况下很难安装 CUDA（用于 GPU 支持）。
您认为这个项目设计合理吗？]]></description>
      <guid>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</guid>
      <pubDate>Tue, 25 Jan 2022 15:09:43 GMT</pubDate>
    </item>
    <item>
      <title>Keras 损失：0.0000e+00 并且精度保持不变</title>
      <link>https://stackoverflow.com/questions/70589997/keras-loss-0-0000e00-and-accuracy-stays-constant</link>
      <description><![CDATA[我有 101 个文件夹（从 0 到 100），其中包含合成训练图像。
这是我的代码：
数据集 = tf.keras.utils.image_dataset_from_directory(
&#39;图片/synthdataset5&#39;，labels=&#39;推断&#39;，label_mode=&#39;int&#39;，class_names=None，color_mode=&#39;rgb&#39;，batch_size=32，image_size=(128,128)，shuffle=True，seed=None，validation_split=None，子集=无，插值=&#39;双线性&#39;，follow_links=False，crop_to_aspect_ratio=False
）

从 keras.models 导入顺序
从 keras.layers 导入 Dense、Conv2D、Flatten

模型=顺序（）

model.add(Conv2D(32, kernel_size=5, 激活=&#39;relu&#39;, input_shape=(128,128,3)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, kernel_size=5, 激活=&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128，kernel_size=3，激活=&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(256，kernel_size=3，激活=&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2, 2)))
模型.add(压平())
model.add（密集（1，激活=&#39;sigmoid&#39;））

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

model.fit(数据集,epochs=75)

每个时期我总是得到相同的结果：
&lt;前&gt;&lt;代码&gt;纪元 1/75
469/469 [================================] - 632s 1s/步 - 损耗：0.0000e+00 - 精度： 0.0098

怎么了？？？]]></description>
      <guid>https://stackoverflow.com/questions/70589997/keras-loss-0-0000e00-and-accuracy-stays-constant</guid>
      <pubDate>Wed, 05 Jan 2022 08:46:51 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我创建新项目时，Unity Visual Studio 无法识别“使用 MlAgents”，但可以在演示项目中识别它？</title>
      <link>https://stackoverflow.com/questions/57019163/why-unity-visual-studio-doesnt-recognise-using-mlagents-when-i-create-a-new-p</link>
      <description><![CDATA[我一直在尝试在我的系统上安装 Unity 的 MLAgents。
阅读详细指南后“https:// /github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation-Windows.md”我成功地让“3D Ball”等演示项目成功运行和训练。
我的问题是，当我创建一个新项目时，当我包含“使用 MlAgents”时，会突出显示一个错误，其中指出“找不到命名空间名称“mlagents”的类型”。
我对 Unity 没有太多经验，所以我希望这是我错过的一件愚蠢的事情，例如您可能必须导入包，但我不知道如何导入？
我发现的所有教程都已经过时了，所以这是我最后的手段。如有任何帮助或建议，我们将不胜感激。
我不明白演示项目如何在“使用 mlagents”时没有错误，但新项目却有错误。]]></description>
      <guid>https://stackoverflow.com/questions/57019163/why-unity-visual-studio-doesnt-recognise-using-mlagents-when-i-create-a-new-p</guid>
      <pubDate>Sat, 13 Jul 2019 12:27:17 GMT</pubDate>
    </item>
    </channel>
</rss>