<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 07 May 2024 01:00:39 GMT</lastBuildDate>
    <item>
      <title>为 Windows 11 和 AMD GPU 安装 Pytorch</title>
      <link>https://stackoverflow.com/questions/78439640/installing-pytorch-for-windows-11-and-amd-gpu</link>
      <description><![CDATA[有人可以帮我安装 Pytorch 吗？我的设备当前使用 Windows 操作系统和 AMD GPU。但是，Pytorch 安装不支持与 ROCm 组合的 Windows 操作系统。只有选择Linux操作系统时，ROCm选项才可用。
我可以使用 CUDA 工具包来替代 ROCm 吗？或者我是否可以将我的操作系统更改为Linux？有没有办法绕过所有这些并且仍然能够使用 Pytorch？
任何建议将不胜感激！
我尝试在 youtube 上寻找安装教程，但他们没有与我相同的操作系统和 GPU 组合。 （即Windows操作系统和AMD GPU）]]></description>
      <guid>https://stackoverflow.com/questions/78439640/installing-pytorch-for-windows-11-and-amd-gpu</guid>
      <pubDate>Tue, 07 May 2024 00:46:02 GMT</pubDate>
    </item>
    <item>
      <title>关于 ML + 计算机视觉项目的建议</title>
      <link>https://stackoverflow.com/questions/78439584/advice-regarding-a-ml-computer-vision-project</link>
      <description><![CDATA[我正在研究制作考勤系统的方法，教授点击几张照片（2到3张）
并上传到应用程序，大约 80 名学生会自动出勤。我的训练数据有限，这是我们需要应对的最大缺点和主要问题。我制作了一个用于训练和标记出勤率的基本模型。
我需要帮助来改进它和所有步骤，例如 -
CNN 在这方面有何帮助？
我如何训练它像奖励惩罚系统一样工作，我可以手动告诉它它无法识别的人是谁，以便它在途中学习。
任何帮助、意见或建议。
这是我的第一个研究项目，请详细回答所有内容，我仍在学习中。 0_0]]></description>
      <guid>https://stackoverflow.com/questions/78439584/advice-regarding-a-ml-computer-vision-project</guid>
      <pubDate>Tue, 07 May 2024 00:12:44 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 PCA 时间序列索引：分数图与预期索引不匹配</title>
      <link>https://stackoverflow.com/questions/78439533/pca-time-series-index-in-r-score-plot-doesnt-match-expected-index</link>
      <description><![CDATA[我正在致力于在 R 中创建 PCA 索引以了解它的工作原理。为此，我使用了“弥补”数据。然而，当我绘制第一个组件的分数时，结果并不符合预期。具体来说，分数图显示该指数在第一年表现不佳，然后随着时间的推移迅速提高，这与我的预期相反。
pca &lt;- prcomp（数据，比例= TRUE，中心= TRUE）
分数 &lt;- 比例（数据）%*% pca$rotation[, 1]
情节（分数）

我试图找出我可能做错了什么，或者如何更好地解释结果。任何见解或建议将不胜感激。

数据在这里]]></description>
      <guid>https://stackoverflow.com/questions/78439533/pca-time-series-index-in-r-score-plot-doesnt-match-expected-index</guid>
      <pubDate>Mon, 06 May 2024 23:48:12 GMT</pubDate>
    </item>
    <item>
      <title>当 num_workers>0 时出现 OOM</title>
      <link>https://stackoverflow.com/questions/78439442/oom-when-num-workers0</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78439442/oom-when-num-workers0</guid>
      <pubDate>Mon, 06 May 2024 22:58:51 GMT</pubDate>
    </item>
    <item>
      <title>将 NumPy 函数转换为 TensorFlow 操作时的图形执行问题</title>
      <link>https://stackoverflow.com/questions/78439375/graph-execution-issue-with-converting-numpy-function-to-tensorflow-ops</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78439375/graph-execution-issue-with-converting-numpy-function-to-tensorflow-ops</guid>
      <pubDate>Mon, 06 May 2024 22:24:20 GMT</pubDate>
    </item>
    <item>
      <title>Transformers.js 扩展在关闭扩展选项卡后一次又一次地重新下载模型</title>
      <link>https://stackoverflow.com/questions/78439242/transformers-js-extension-is-redownloading-the-model-again-and-again-after-closi</link>
      <description><![CDATA[我正在尝试使用 Transformers.js 库构建一个 Chrome 扩展，以测试其限制并查看 onDevice ML 在某些情况下是否可以作为选择。
根据他们的官方仓库中提供的示例，我添加新功能。
当我添加翻译管道时，我看到了一些奇怪的事情，即每次打开和关闭浏览器后模型都会一次又一次下载。
class MyTranslationPipeline {
静态任务=“翻译”；
静态模型＝“Xenova/nllb-200-distilled-600M”；
静态实例=空；

静态异步 getInstance(progress_callback = null) {
    if (this.instance === null) {
        console.log(“正在加载翻译管道...”);
        this.instance = pipeline(this.task, this.model, {progress_callback});
    }

    返回这个实例；
 }
}

原始示例展示了 env.allowLocalModels = false; 但我将其设置回 true，但它不起作用，我希望当我重新打开浏览器时，将从中加载模型缓存它已经在的地方。
缓存条目]]></description>
      <guid>https://stackoverflow.com/questions/78439242/transformers-js-extension-is-redownloading-the-model-again-and-again-after-closi</guid>
      <pubDate>Mon, 06 May 2024 21:40:33 GMT</pubDate>
    </item>
    <item>
      <title>RNN/LSTM 损失函数</title>
      <link>https://stackoverflow.com/questions/78438859/rnn-lstm-loss-function</link>
      <description><![CDATA[我正在尝试生成一个 RNN，它能够在给定按时间顺序排列的输入列表的情况下随着时间的推移预测某些值。问题是这些值太随机了，我无法用 Keras 中的损失函数来拟合这些值。新的想法是尝试生成基于快速傅立叶变换的损失函数。这可能吗？我不知道如何生成在模型中使用的自定义损失函数。
我留下了我测试过的一次测试运行的图表，在本例中我使用 MSE 作为函数，结果很清楚，但您也可以看到最后 200 个值的随机性​​我为了测试而分开的
使用最后 200 个数字进行测试
使用 FFT 生成损失函数是否可行？您还可以建议什么来获得更精确的结果？]]></description>
      <guid>https://stackoverflow.com/questions/78438859/rnn-lstm-loss-function</guid>
      <pubDate>Mon, 06 May 2024 19:57:04 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中 2D 输入的集成梯度实现</title>
      <link>https://stackoverflow.com/questions/78438413/integrated-gradients-implementation-for-2d-input-in-pytorch</link>
      <description><![CDATA[我正在尝试为 GNN 实现积分梯度计算（在文章中描述）我正在与.具体来说，我使用论文中的Eq3
我的网络输入是一个 NxM 矩阵，表示 N 个顶点的图，每个顶点都有一个 M 维的特征向量。
如何扩展论文中的方法，考虑到他们是针对 N 维的输入导出该方法的，在我的例子中，我想为每个节点获得一个分数？
在我当前的实现中，我获得了一个 NxM 矩阵，通过执行 torch.sum(dim=1) 来折叠该矩阵，但这感觉并不那么干净
这是我当前在 PyTorch 中的实现
graph_copy = input_graph.detach().clone()
# 公式中的k/m
k_m = torch.linspace(0, 1, n_steps)
# 存储样本的数组
input_features = [baseline.clone()] # 第一个样本是基线
# x-x&#39;
diff = 原始输入特征 - 基线

# 填充样本数组
对于范围内的 i(1, k_m.shape[0])：
    temp = 基线 + k_m[i] * diff
    input_features_path.append（临时）

梯度= []
对于范围内的 i(k_m.shape[0])：
    ### 将每个输入的向量梯度归零
    input_features[i].requires_grad = True
    model.zero_grad()
    任务.zero_grad()
    
    temp_model_out = 模型（图 = graph_copy，输入 = input_features[i]）[&#39;graph_feature&#39;][0]
    temp_mlp_output = 任务.mlp(temp_model_out)
    temp_prob = Softmax(temp_mlp_output, 暗淡 = 0)

    temp_gradient = grad(输出 = temp_prob[true_label_id], 输入 = input_features_path[i])
    梯度.append(temp_gradient[0])

    input_features_path[i].requires_grad = False

使用 torch.no_grad()：
    ig_scores = original_input_feature * torch.stack(梯度, 暗淡 = 2). 平均值(暗淡 = 2)
    Final_ig_scores = ig_scores.sum(dim = 1)
    排序，索引= torch.sort（final_ig_scores，降序= True）

]]></description>
      <guid>https://stackoverflow.com/questions/78438413/integrated-gradients-implementation-for-2d-input-in-pytorch</guid>
      <pubDate>Mon, 06 May 2024 18:08:43 GMT</pubDate>
    </item>
    <item>
      <title>有没有更好的方法使用 python 解析非结构化 excel 表？[关闭]</title>
      <link>https://stackoverflow.com/questions/78438227/is-there-a-better-way-of-parsing-unstructured-excel-tables-using-python</link>
      <description><![CDATA[我正在尝试从 Excel 工作表中提取一些表格信息。我有多个表，每个 Excel 工作表中都有多个表，并且整个 Excel 工作表中的表结构往往不同。我想出了一种仅适用于一张表的逻辑，但每个 Excel 在文件中都有不同的结构。有什么方法可以提取所有子表，无论结构是什么？我正在寻找一种通用的方法，而当前现有的库不适合这项任务。
]]></description>
      <guid>https://stackoverflow.com/questions/78438227/is-there-a-better-way-of-parsing-unstructured-excel-tables-using-python</guid>
      <pubDate>Mon, 06 May 2024 17:28:19 GMT</pubDate>
    </item>
    <item>
      <title>关于食谱成分提取的 spaCy NER 模型注释的反馈</title>
      <link>https://stackoverflow.com/questions/78437443/feedback-on-spacy-ner-model-annotations-for-recipe-ingredient-extraction</link>
      <description><![CDATA[我正在训练一个 spaCy NER 模型来专门识别和分类食谱中的成分线。目标是从各种食谱中准确提取成分及其数量、单位和制备说明。下面是我如何注释数据的概述：
跨越标签

数量：与单位相关的数字（例如“2”、“3/4”）
成分：实际成分名称（例如“糖”、“牛奶”）
测量单位：测量单位（例如“杯”、“汤匙”）
说明：准备说明（例如“切细丁”、“分开”）

关系标签

quantity_of：将量程标签数量与成分关联起来
action_to：将跨度标签说明与成分关联起来
unit_of：将跨度标签测量单位与数量相关

我提供了两个示例：一个简单的成分系列和一个复杂的成分系列。
简单行
复杂线
我正在寻求有关以下几点的反馈：

注释过度：是否存在太多类别或过于详细的注释，无法有效学习和实际应用？是否应该合并或省略某些类别？
训练数据量：通常建议使用多少带注释的数据来在此类 NER 任务中实现稳健的模型？我想确保该模型在各种配方格式中都是可靠的。

我尝试过的：
我使用类似的标签设置训练了一个模型，减去关系标签和“测量单位”。跨越标签。我使用来自随机食谱的约 700 个样本对模型进行了训练。结果不佳；该模型很难识别某些方面，特别是在数量及其单位不相邻的情况下（例如 3 瓣大蒜）]]></description>
      <guid>https://stackoverflow.com/questions/78437443/feedback-on-spacy-ner-model-annotations-for-recipe-ingredient-extraction</guid>
      <pubDate>Mon, 06 May 2024 14:52:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么这个模型在某些目标上表现良好，但在某些目标上却表现不佳？</title>
      <link>https://stackoverflow.com/questions/78435762/why-is-this-model-peforming-on-some-targets-well-but-on-some-not</link>
      <description><![CDATA[我正在开发一个监督机器学习项目。我将 horse_data(size,weight,peformance,...) 作为输入，并将配方的成分作为输出。我想预测给定马数据的成分。
这是我的 horse_data 的摘要：HorseData
这是我的目标（秘诀）的摘要：
FirstPartTargets
第二部分目标
第三方目标
我想用这些数据训练一个机器学习模型。在本例中是随机森林回归器，因为输入有许多分类变量（保留、性能、工作类型、种族和种族类型）。
resDf = pd.DataFrame(columns=[&#39;训练 R^2 分数&#39;,&#39;测试 R^2 分数&#39;,&#39;训练 MSE&#39;,&#39;测试 MSE&#39;,&#39;训练 RMSE&#39;,&#39;测试 RMSE&#39; ,&#39;训练 MSAE&#39;,&#39;测试 MSAE&#39;])

参数网格 = {
    &#39;n_estimators&#39;: [100,200,1000],
    &#39;最大深度&#39;: [10,20,30],
    &#39;min_samples_split&#39;:[2,5,10],
    &#39;min_samples_leaf&#39;:[1,2,4]
}
对于 Y.columns 中的 ing：
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y[ing], test_size=0.2, random_state=52)

    gridModel = make_pipeline(GridSearchCV(估计器=RandomForestRegressor(),cv=10,param_grid=param_grid,n_jobs=-1,scoring=&#39;neg_mean_squared_error&#39;,verbose=True))
    gridModel.fit(X_train,Y_train)
    y_pred_train = gridModel.predict(X_train)
    
    train_mse_error =mean_squared_error(y_pred=y_pred_train,y_true=Y_train)
    train_mse_absoulte_error = Mean_absolute_error(y_pred=y_pred_train,y_true=Y_train)
    train_r2_score = r2_score(y_pred=y_pred_train,y_true=Y_train)
    train_rmse = train_mse_error ** (0.5)
    
    y_pred = gridModel.predict(X_test)
    test_mse_error =mean_squared_error(y_pred=y_pred,y_true=Y_test)
    test_mse_absoulte_error = Mean_absolute_error(y_pred=y_pred,y_true=Y_test)
    test_r2_score = r2_score(y_pred=y_pred,y_true=Y_test)
    test_rmse = test_mse_error ** (0.5)
    resDf.loc[ing] = [train_r2_score,test_r2_score,train_mse_error,test_mse_error,train_rmse,test_rmse,train_mse_absoulte_error,test_mse_absoulte_error]

结果如下：
FirstPartResult
第二部分结果
问题是有时我不明白结果。我的理解是我的模型过度拟合，因为在每一行中，测试集上的分数和错误都高于训练集上的分数和错误。但有些行我不明白。 VitaminA 在训练集上有很好的 r2 分数，但在测试集上很差（对我来说，这是过度拟合）。
但是训练集和测试集的 RMSE 都非常高。
同样令人困惑的是“schwefel”。它在训练集上的 r2score 很差，在测试集上的得分也很糟糕。但我在系统中看不到为什么会得到这些结果。
问题是特征还是目标有时范围很大？]]></description>
      <guid>https://stackoverflow.com/questions/78435762/why-is-this-model-peforming-on-some-targets-well-but-on-some-not</guid>
      <pubDate>Mon, 06 May 2024 09:34:58 GMT</pubDate>
    </item>
    <item>
      <title>指导法学硕士 - 从文本中错误地提取数据继续</title>
      <link>https://stackoverflow.com/questions/78435586/instruct-llms-extract-data-from-text-wrongly-continues</link>
      <description><![CDATA[我正在尝试微调开源 LLM，现在让我们继续使用 Mistral-7b-instruct 模型。
我的任务如下：我有电子邮件，代表“价格请求”对于我们的客户发送的货物。
客户在邮件中告诉我们取货地址、发货人、收货人等信息。
我最初的想法是使用 DORA 训练不同的适配器，每个适配器都接受从电子邮件中提取不同实体的训练。
我的数据集创建如下：我有电子邮件和注释“基于电子邮件，我找到了这个 [ENTITY]：entity_here”
我已经创建了一条系统消息，并使用 chat_template 以 Mistral 接受的方式创建数据集，使用此 chat_template：
“{%- for messages in messages %}”
  “{%- if message[&#39;角色&#39;] == &#39;系统&#39;-%}”
      ”{{- &#39;&#39; + 消息[&#39;内容&#39;] -}}”
  “{%-else-%}”
      “{%- if message[&#39;角色&#39;] == &#39;用户&#39;-%}”
          “{{-&#39;[INST]&#39; + message[&#39;content&#39;].rstrip() + &#39;[/INST]&#39;-}}”
      “{%-else-%}”
          ”{{-&#39;&#39; + 消息[&#39;内容&#39;] + &#39;&#39; -}}”
      “{%-endif-%}”
  “{%-endif-%}”
“{%-endfor-%}”
“{%- if add_ Generation_prompt -%}”
    “{{-&#39;&#39;-}}”
“{%-endif-%}”

现在解决问题了。该模型似乎了解了需要提取的内容，它生成了不错的答案，其格式与训练它的助手相同，问题是在生成答案后，它不断生成与电子邮件无关的附加文本到任务，E.G. “请联系我们......”
例如，当我针对同一任务微调 GPT3.5 时，模型能够准确提取我需要的内容，这表明我做错了什么。
有人对我哪里出错有建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435586/instruct-llms-extract-data-from-text-wrongly-continues</guid>
      <pubDate>Mon, 06 May 2024 09:01:03 GMT</pubDate>
    </item>
    <item>
      <title>向 Python Streamlit 饮食推荐应用程序添加饮食偏好按钮 [关闭]</title>
      <link>https://stackoverflow.com/questions/78433479/adding-dietary-preference-button-to-python-streamlit-diet-recommendation-app</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78433479/adding-dietary-preference-button-to-python-streamlit-diet-recommendation-app</guid>
      <pubDate>Sun, 05 May 2024 19:19:19 GMT</pubDate>
    </item>
    <item>
      <title>如何导入 Gensim？ Pip Install 有效，但我无法在没有出现 ImportError: Cannot import name 'triu' 错误的情况下运行 Import Gensim</title>
      <link>https://stackoverflow.com/questions/78427675/how-do-i-import-gensim-pip-install-worked-but-i-cant-run-import-gensim-withou</link>
      <description><![CDATA[我正在尝试执行此 Word2Vec 代码并收到错误：
&lt;块引用&gt;
名称错误：名称“gensim”未定义`

w2v_model = gensim.models.Word2Vec（docgen，min_count = 5，sg = 1，seed = 22122，workers = 1）

当我导入 gensim 时，出现此错误：ImportError: Cannot import name &#39;triu&#39; from &#39;scipy.linalg&#39; (/opt/conda/lib/python3.9/site-packages/scipy/ linalg/__init__.py)
如何修复代码以便能够调用 Gensim？我需要 Word2Vec 才能运行，之前没有遇到过这个问题；我今天早上运行这个模型，一切都很好，但现在突然出现错误。
我看到你必须升级 Scipy，而且它似乎有效。这是完整的代码：
!pip install scipy==1.10.1
!pip 安装 gensim

from numpy import triu
导入gensim
从 gensim 导入语料库、模型

w2v_model = gensim.models.Word2Vec(docgen, min_count=3, sg=1, 种子=22122, 工人=1)
]]></description>
      <guid>https://stackoverflow.com/questions/78427675/how-do-i-import-gensim-pip-install-worked-but-i-cant-run-import-gensim-withou</guid>
      <pubDate>Sat, 04 May 2024 03:23:37 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    </channel>
</rss>