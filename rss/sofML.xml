<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 13 Nov 2024 18:22:37 GMT</lastBuildDate>
    <item>
      <title>使用《Python 深度学习》中的 Keras 进行多类分类的准确率与教科书上的准确率相差甚远</title>
      <link>https://stackoverflow.com/questions/79185545/multiclass-classifier-using-keras-from-deep-learning-with-python-yields-very-d</link>
      <description><![CDATA[以下是 François Chollet 所著《使用 Python 进行深度学习》第 4 章中多类分类器的代码。教科书提到此代码将产生 &gt;95% 的准确率，但我的环境似乎停留在 50%。
Keras 版本 - 3.6
Tensorflow - 2.18
硬件 - Apple M1 Pro
import keras
from tensorflow.keras.datasets import reuters
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
import numpy as np

(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)

# 多热编码文本。每个序列都是一篇新闻文章

def vectorize_sequences(sequences, dimension=10000):
results = np.zeros((len(sequences), dimension))
for i, serial in enumerate(sequences):
for j in serial:
results[i, j] = 1.
return results

x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)

# 模型定义

model = keras.Sequential([
layer.Dense(64,activation=&quot;relu&quot;),
layer.Dense(64,activation=&quot;relu&quot;),
layer.Dense(46,activation=&quot;softmax&quot;)
])

model.compile(
optimizer=&quot;rmsprop&quot;,
loss=&quot;categorical_crossentropy&quot;,
metrics=[&quot;accuracy&quot;]
)

# 留出验证集
x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = y_train[:1000]
partial_y_train = y_train[1000:]

# 训练模型

history = model.fit(
partial_x_train,
partial_y_train,
epochs=20,
batch_size=512,
validation_data=(x_val,y_val)
)

# 绘制准确度

acc = history_dict[&quot;accuracy&quot;]
val_acc = history_dict[&quot;val_accuracy&quot;]
plt.plot(epochs, acc, &quot;bo&quot;, label=&quot;Training acc&quot;)
plt.plot(epochs, val_acc, &quot;b&quot;, label=&quot;验证 acc&quot;)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;准确度&quot;)
plt.legend()
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/79185545/multiclass-classifier-using-keras-from-deep-learning-with-python-yields-very-d</guid>
      <pubDate>Wed, 13 Nov 2024 15:19:50 GMT</pubDate>
    </item>
    <item>
      <title>如何仅考虑直到 best_iteration 的迭代来计算 XGBoost 上的 feature_importances_？</title>
      <link>https://stackoverflow.com/questions/79184686/how-to-compute-feature-importances-on-xgboost-considering-only-iterations-up-to</link>
      <description><![CDATA[我训练了一个带有提前停止的 XGBRegressor 模型。据我所知，model.feature_importances_ 会根据所有历史记录计算特征重要性（即还考虑由 early_stopping_rounds 量化的“耐心”迭代）。尽管如此，我只需要在模型上计算出 best_iteration 之前的特征重要性。
这是一个示例代码：
from xgboost import XGBRegressor
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 准备数据
X, y = make_regression(n_samples=1000, n_features=20, noise=0.1)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# 使用早期停止训练模型
xgb_model = XGBRegressor(n_estimators=1000, early_stopping_rounds=100, eval_metric=&quot;rmse&quot;)
xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)
xgb_model.feature_importances_

但是这给了我考虑整个模型的特征重要性，而不仅仅是 best_iteration:
best_iteration = xgb_model.best_iteration

我无法使用 n_estimators=best_iteration 重新训练新的 XGBRegressor，因为它几乎会使运行时间翻倍（此代码段是更大代码的一部分）。
有没有办法在不重新训练的情况下实现这一点？
请注意，不幸的是，.feature_importances_ 没有 iteration_range 选项。]]></description>
      <guid>https://stackoverflow.com/questions/79184686/how-to-compute-feature-importances-on-xgboost-considering-only-iterations-up-to</guid>
      <pubDate>Wed, 13 Nov 2024 11:28:59 GMT</pubDate>
    </item>
    <item>
      <title>与 ChatGPT 的实时屏幕共享集成 [关闭]</title>
      <link>https://stackoverflow.com/questions/79184307/real-time-screen-sharing-integration-with-chatgpt</link>
      <description><![CDATA[我正在寻找一种与 ChatGPT 实时共享屏幕的方法，以便 AI 助手可以看到屏幕上发生的一切，并逐步指导我完成特定任务。
理想情况下，我正在寻找具有以下功能的集成或软件解决方案：
直接在 ChatGPT 内或以最少的设置进行实时屏幕共享，以便 ChatGPT 可以响应我屏幕上的内容。
安全稳定的连接，以确保数据隐私和安全。
如果可能的话，可以选择聊天或音频通信以提高互动性。
有没有人知道这样的解决方案或对如何使用 ChatGPT 实现这一点有建议？我很感激任何建议或其他想法！
提前谢谢！
我一直尝试截取屏幕截图并将其放入 GPT，但这非常耗时。]]></description>
      <guid>https://stackoverflow.com/questions/79184307/real-time-screen-sharing-integration-with-chatgpt</guid>
      <pubDate>Wed, 13 Nov 2024 09:50:49 GMT</pubDate>
    </item>
    <item>
      <title>模型严重偏向少数类，但准确率、召回率和精确率得分都很好</title>
      <link>https://stackoverflow.com/questions/79184102/model-extremely-biased-towards-the-minority-class-but-the-accuracy-recall-and-pr</link>
      <description><![CDATA[我正在使用 xgboost 分类器来预测下一次事件发生的时间。这是一个二元分类，0:1 的比例是 1.6:1
验证集和验证预测中的类分布相似，性能指标非常好，但是混淆矩阵显示几乎所有样本都被归入类 1（少数类），而不是 0（多数类），你们知道这是为什么吗？
我尝试处理 scale_pos_weight：

我首先将 scale_pos_weight 提高到 1.6，但它给了我更多类 1 偏斜的结果。
我将 scale_pos_weight 降低到 0.25。对于类别 0，我得到了真阳性结果，并且假阳性明显较少，但对于类别 1，我得到了相等的真阳性和假阳性。它们加起来占样本的约 55%，这意味着模型仍然偏向类别 0。
]]></description>
      <guid>https://stackoverflow.com/questions/79184102/model-extremely-biased-towards-the-minority-class-but-the-accuracy-recall-and-pr</guid>
      <pubDate>Wed, 13 Nov 2024 09:01:14 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Python 通过决策路径复制随机森林回归预测？</title>
      <link>https://stackoverflow.com/questions/79183884/how-to-use-python-to-replicate-random-forest-regression-prediction-using-decisio</link>
      <description><![CDATA[我试图测试我是否理解了 RandomForestRegressor 在模型拟合后产生预测的方式。我使用加州住房示例来训练一个简单的模型并预测我的测试集中的第一个值。然后我使用 apply() 获取所有训练数据的节点和每个回归树中感兴趣的测试样本。预测结果为1.41307
from sklearn import datasets
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import numpy as np

X, y = datasets.fetch_california_housing(as_frame=True, return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

rf = RandomForestRegressor(random_state=0)
rf.fit(X_train, y_train)

training_nodes = rf.apply(X_train)
test_nodes = rf.apply(X_test.iloc[[0]])

rf.predict( X_test.iloc[[0]] )
array([1.41307])


要复制预测，我需要：1. 在所有回归树中找到我感兴趣的测试数据的节点 2. 在所有回归树中找到与我感兴趣的测试数据共享相同节点的所有训练数据。3. 对于每棵树，计算 y_train 的平均值并存储它们。4. 计算存储的平均 y_train 的平均值。我得到的结果是 1.4053，与 rf.predict 相比有很大差异。有人能告诉我我错在哪里吗，正确的步骤是什么？
matching_samples_per_tree = []

target_values_per_tree = []

for tree_idx in range(training_nodes.shape[1]):
# 查找训练样本与此树中的测试样本属于同一叶子的索引
matching_indices = np.where(training_nodes[:, tree_idx] == test_nodes[0][tree_idx])[0]

matching_samples_per_tree.append(matching_indices)

# 检索并存储这些匹配训练样本的目标值
target_values_per_tree.append(y_train.iloc[matching_indices].values)

means_of_each_array = []

for vals in target_values_per_tree:
mean_value = np.mean(vals)
means_of_each_array.append(mean_value)

np.mean(means_of_each_array) 
#1.405348333333333
]]></description>
      <guid>https://stackoverflow.com/questions/79183884/how-to-use-python-to-replicate-random-forest-regression-prediction-using-decisio</guid>
      <pubDate>Wed, 13 Nov 2024 07:55:53 GMT</pubDate>
    </item>
    <item>
      <title>为什么从直觉上讲，规范化有利于神经网络的学习？[关闭]</title>
      <link>https://stackoverflow.com/questions/79183566/why-normalisation-is-good-for-learning-in-neural-netwrok-in-intutive-sense</link>
      <description><![CDATA[我一直在想这个问题，当我们进行标准化时，我们会丢失信息的幅度部分，而只保留方向信息，那么为什么丢失这个幅度信息不会影响学习，梯度的幅度部分代表什么？]]></description>
      <guid>https://stackoverflow.com/questions/79183566/why-normalisation-is-good-for-learning-in-neural-netwrok-in-intutive-sense</guid>
      <pubDate>Wed, 13 Nov 2024 05:52:27 GMT</pubDate>
    </item>
    <item>
      <title>VSCode 安装 hugginface relik 库时出错</title>
      <link>https://stackoverflow.com/questions/79182549/vscode-install-error-for-the-hugginface-relik-library</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79182549/vscode-install-error-for-the-hugginface-relik-library</guid>
      <pubDate>Tue, 12 Nov 2024 19:53:20 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch + Ray Tune 报告 ImplicitFunc 太大，不知道哪个引用很大</title>
      <link>https://stackoverflow.com/questions/79181943/pytorch-ray-tune-reporting-implicitfunc-is-too-large-no-idea-which-reference</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79181943/pytorch-ray-tune-reporting-implicitfunc-is-too-large-no-idea-which-reference</guid>
      <pubDate>Tue, 12 Nov 2024 16:21:39 GMT</pubDate>
    </item>
    <item>
      <title>输入数据类型与 SHAP 中请求的输入类型不匹配</title>
      <link>https://stackoverflow.com/questions/79181696/input-data-type-does-not-match-the-requested-input-type-in-shap</link>
      <description><![CDATA[我创建了一个自动编码器模型，而不是使用 Model()。
但我想分析输入矩阵的元素特征，以估计每个元素对潜在空间值的贡献。我使用 SHAP 深度解释器进行分析。但我自己创建的模型与 SHAP 中请求的数据类型不匹配。
我想问是否有其他 SHAP 算法可以使用 tensorflow.tensor 而不是 keras.tensor。
错误信息：
raise ValueError(
ValueError：所有 `inputs` 值都必须是 KerasTensors。收到：inputs=[[[ 0.5075143 1.1158173 0.27439427 ... 0.44567809 0.82088786

warnings.warn(&quot;您的 TensorFlow 版本比 2.4.0 新，因此图形支持已在 Eager 模式下被移除，并且一些静态图可能不受支持。请参阅 PR #1483 进行讨论。&quot;)
multiprocessing.pool.RemoteTraceback: 

]]></description>
      <guid>https://stackoverflow.com/questions/79181696/input-data-type-does-not-match-the-requested-input-type-in-shap</guid>
      <pubDate>Tue, 12 Nov 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>当我想运行 HuggingFace 模型时，Jupyter Notebook 崩溃了</title>
      <link>https://stackoverflow.com/questions/79181010/jupyter-notebook-is-crashing-when-i-want-to-run-huggingface-models</link>
      <description><![CDATA[我使用 Jupyter Notebook 运行 HuggingFace 的一些 ML 模型。
我使用的是 Mac（M2 芯片，内存 32 GB）
这是我的代码：
import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline

# 步骤 1：从 Hugging Face 的 Model Hub 中选择一个预先训练的 NER 模型
# 这里我们使用&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;，这是一个在 CoNLL-2003 数据集上微调的常见 NER 模型
model_name = &quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;

# 步骤 2：加载模型和 tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)

在步骤 2 中，我的内核总是崩溃。我尝试了几种模型，但总是一样。这是错误：
内核重新启动
&lt;kernel name&gt; 的内核似乎已死。它将自动重新启动。

你能帮帮我吗？
我的内存没有满，笔记本电脑是全新的。]]></description>
      <guid>https://stackoverflow.com/questions/79181010/jupyter-notebook-is-crashing-when-i-want-to-run-huggingface-models</guid>
      <pubDate>Tue, 12 Nov 2024 12:02:09 GMT</pubDate>
    </item>
    <item>
      <title>值错误：序列模型‘sequential_3’尚未定义输入形状</title>
      <link>https://stackoverflow.com/questions/79180267/value-error-sequential-model-sequential-3-has-no-defined-input-shape-yet</link>
      <description><![CDATA[导致“Sequential 模型没有定义的输入形状 1”错误的常见错误或遗漏是什么？
预处理层（如 resize_and_rescale 或 data_augmentation）是否会影响模型第一层的 input_shape？
Keras Sequential 模型第一层的 input_shape 参数的用途是什么？
input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
n_classes = 3

model = models.Sequential([
resize_and_rescale,
data_augmentation,
layer.Conv2D(32, kernel_size = (3,3),activation=&#39;relu&#39;, input_shape = input_shape),
layers.MaxPooling2D((2, 2)),
层。Conv2D（64，kernel_size =（3,3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，kernel_size =（3,3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Flatten（），
层。Dense（64，激活=&#39;relu&#39;），
层。Dense（n_classes，激活=&#39;softmax&#39;),
])

错误显示
值错误：顺序模型“sequential_3”尚未定义输入形状
]]></description>
      <guid>https://stackoverflow.com/questions/79180267/value-error-sequential-model-sequential-3-has-no-defined-input-shape-yet</guid>
      <pubDate>Tue, 12 Nov 2024 08:02:25 GMT</pubDate>
    </item>
    <item>
      <title>MLmetrics F1_Score 函数</title>
      <link>https://stackoverflow.com/questions/79179803/mlmetrics-f1-score-function</link>
      <description><![CDATA[我试图弄清楚当 y_pred 值非二进制时，MLmetrics 库中的 F1_Score 函数如何工作。
例如：
library(MLmetrics)
y &lt;- c(1,1,1,1,1,0,0,0,0,0)
x &lt;- c(1, 0.8, 0.654, 0.99, 0.75, 0.1, 0.3, 0.6, 0.05, 0.2)
x_preds &lt;- ifelse(x &lt; 0.5, 0, 1)
getF1 &lt;- F1_Score(y_true=y, y_pred=x, positive=&quot;1&quot;)
getF2 &lt;- F1_Score(y_true=y, y_pred=x_preds, positive=&quot;1&quot;)

print(getF1)
print(getF2)

给出 getF1=0.3333333 和 getF2 = 0.9090909
R 文档中提供的函数示例旨在计算我所称的 getF2，其中我已明确指定如何根据 0.5 阈值将概率分数分配给任一类标签。我不清楚的是，如果没有指定此阈值（getF1），它如何计算 F1 分数。有人能解释一下，如果保留概率分数，并且在调用 F1_Score 函数之前不将其转换为二进制，该函数默认会做什么吗？我无论如何也想不出它是如何得到 0.3333333 的。]]></description>
      <guid>https://stackoverflow.com/questions/79179803/mlmetrics-f1-score-function</guid>
      <pubDate>Tue, 12 Nov 2024 04:35:57 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 transformers 在本地加载模型</title>
      <link>https://stackoverflow.com/questions/79169173/fail-to-use-transformers-to-load-model-locally</link>
      <description><![CDATA[我已使用 transformers 函数将整个模型
下载到本地目录：/home/marcus/Desktop/project/OCR_transformer_practices/models/moondream2
代码如下：
from huggingface_hub import snap_download

# 指定模型 ID 和修订版本
model_id = &quot;vikhyatk/moondream2&quot;
revision = &quot;2024-08-26&quot;

# 指定要下载模型的目录
download_directory = &quot;/home/marcus/Desktop/project/OCR_transformer_practices/models/moondream2&quot; # 将其更改为您想要的路径

# 将模型文件下载到指定目录
local_model_path = snapping_download(repo_id=model_id, revision=revision, local_dir=download_directory)

模型保存在目录中：
当我使用以下代码通过 transformers 从本地目录加载模型时：
from PIL import Image
from transformers import AutoTokenizer, AutoModelForCausalLM
from pathlib import Path
import os

# 获取父目录
project_dir = Path(__file__).parent
model_folder_name = &#39;models/moondream2&#39;
model_dir = str(project_dir/model_folder_name)

# 使用正确的模型 ID 加载 tokenizer 和模型
# model_id = &quot;vikhyatk/moondream2&quot;
tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_dir, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained( pretrained_model_name_or_path=model_dir, use_safetensors=True, trust_remote_code=True,)

弹出错误消息：
回溯（最近一次调用最后一次）：
文件“/home/marcus/Desktop/project/OCR_transformer_practices/moondream_test.py”，第 15 行，位于&lt;module&gt;
model = AutoModelForCausalLM.from_pretrained( pretrained_model_name_or_path=model_dir, use_safetensors=True, trust_remote_code=True,)
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py&quot;，第 553 行，在 from_pretrained 中
model_class = get_class_from_dynamic_module(
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;，第 552 行，在 get_class_from_dynamic_module 中
return get_class_in_module(class_name, final_module, force_reload=force_download)
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;，第 237 行，在 get_class_in_module 中
module_files: List[Path] = [module_file] + sorted(map(Path, get_relative_import_files(module_file)))
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;，第 128 行，在 get_relative_import_files 中
new_imports.extend(get_relative_imports(f))
文件&quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;, line 97, in get_relative_imports
with open(module_file, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:
FileNotFoundError: [Errno 2] 没有这样的文件或目录：&#39;/home/marcus/.cache/huggingface/modules/transformers_modules/moondream2/fourier_features.py&#39;

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/79169173/fail-to-use-transformers-to-load-model-locally</guid>
      <pubDate>Fri, 08 Nov 2024 07:38:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 在低资源语言和葡萄牙语之间进行机器翻译的语言模型</title>
      <link>https://stackoverflow.com/questions/78911175/a-language-model-for-machine-translation-between-a-low-resource-language-and-por</link>
      <description><![CDATA[我正在尝试使用 Tensorflow 训练一种语言模型，用于在低资源语言和葡萄牙语之间进行机器翻译。不幸的是，我收到以下错误：
PS C:\Users\myuser\PycharmProjects\teste&gt; python .\tensorflow_model.py 
2024-08-23 21:29:50.839647：I tensorflow/core/platform/cpu_feature_guard.cc:182] 此 TensorFlow 二进制文件经过优化，可在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
回溯（最近一次调用）：
文件“.\tensorflow_model.py”，第 52 行，位于 &lt;module&gt;
数据集 = tf.data.Dataset.from_tensor_slices((src_tensor, tgt_tensor)).shuffle(BUFFER_SIZE)
文件 &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py&quot;，第 831 行，在 from_tensor_slices 中
返回 from_tensor_slices_op._from_tensor_slices(tensors, name)
文件 &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\from_tensor_slices_op.py&quot;，第 25 行，在 _from_tensor_slices 中
返回 _TensorSliceDataset(tensors, name=name)
文件&quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\from_tensor_slices_op.py&quot;，第 45 行，在 __init__
batch_dim.assert_is_compatible_with(
File &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\framework\tensor_shape.py&quot;，第 300 行，在 assert_is_compatible_with
raise ValueError(&quot;Dimensions %s and %s are notcompatible&quot; %
ValueError: Dimensions 21 and 22 are notcompatible

我该如何克服这个错误？
import tensorflow as tf
import numpy as np
import re
import os

# Clean数据
def preprocess_sentence(sentence):
sentence = sentence.lower().strip()
sentence = re.sub(r&quot;([?.!,¿])&quot;, r&quot; \1 &quot;, sentence)
sentence = re.sub(r&#39;[&quot; &quot;]+&#39;, &quot; &quot;, sentence)
sentence = re.sub(r&quot;[^a-zA-Z?.!,¿]+&quot;, &quot; &quot;, sentence)
sentence = sentence.strip()
sentence = &#39;&lt;start&gt; &#39; + sentence + &#39; &lt;end&gt;&#39;
返回句子

#加载数据的函数
def load_data(file_path_src, file_path_tgt):
src_sentences = open(file_path_src, &#39;r&#39;, encoding=&#39;utf-8&#39;).read().strip().split(&#39;\n&#39;)
tgt_sentences = open(file_path_tgt, &#39;r&#39;, encoding=&#39;utf-8&#39;).read().strip().split(&#39;\n&#39;)

src_sentences = [preprocess_sentence(sentence) for sentence in src_sentences]
tgt_sentences = [preprocess_sentence(sentence) for sentence in tgt_sentences]

返回 src_sentences, tgt_sentences

#加载数据
src_sentences, tgt_sentences = load_data(&#39;src_language.txt&#39;, &#39;portuguese.txt&#39;)

#标记化
src_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=&#39;&#39;)
tgt_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=&#39;&#39;)

src_tokenizer.fit_on_texts(src_sentences)
tgt_tokenizer.fit_on_texts(tgt_sentences)

src_tensor = src_tokenizer.texts_to_sequences(src_sentences)
tgt_tensor = tgt_tokenizer.texts_to_sequences(tgt_sentences)

src_tensor = tf.keras.preprocessing.sequence.pad_sequences(src_tensor, padding=&#39;post&#39;)
tgt_tensor = tf.keras.preprocessing.sequence.pad_sequences(tgt_tensor, padding=&#39;post&#39;)

BUFFER_SIZE = len(src_tensor)

#创建数据集
dataset = tf.data.Dataset.from_tensor_slices((src_tensor, tgt_tensor)).shuffle(BUFFER_SIZE) 
]]></description>
      <guid>https://stackoverflow.com/questions/78911175/a-language-model-for-machine-translation-between-a-low-resource-language-and-por</guid>
      <pubDate>Sun, 25 Aug 2024 12:06:55 GMT</pubDate>
    </item>
    <item>
      <title>无法在 python 中安装 lap==0.4.0 库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    </channel>
</rss>