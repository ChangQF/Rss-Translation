<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 08 Feb 2024 21:12:32 GMT</lastBuildDate>
    <item>
      <title>推荐系统的代码可以在jupyter上运行，但不能在.py文件中运行[关闭]</title>
      <link>https://stackoverflow.com/questions/77964268/recommendation-system-s-code-works-on-jupyter-but-dont-works-in-a-py-file</link>
      <description><![CDATA[你好。
我使用jupyter Notebook编写了推荐系统代码
我需要在 django 中使用这个推荐系统。为此，我将 jupyter 代码导出到 .py 文件。
但我的代码在 django （.py 文件）中不起作用，只返回一个空字典
你能告诉我我的代码问题吗？\
&lt;块引用&gt;
注意：该代码是电影推荐系统的代码，我是为这本书定制的，所以有些变量的名称与电影相关。

我的数据集（https://www.kaggle.com/datasets/ arashnic/图书推荐数据集)
我的 .ipynb 文件 (https://drive.google. com/file/d/1Q_i6FnNEfeoTwQWyiqK6gl6PlCZzHciD/view?usp=sharing)
请尽快帮助我，我也非常需要这个系统的工作
非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/77964268/recommendation-system-s-code-works-on-jupyter-but-dont-works-in-a-py-file</guid>
      <pubDate>Thu, 08 Feb 2024 19:19:22 GMT</pubDate>
    </item>
    <item>
      <title>当有多个输入时，如何使用检索器使用 langchain 创建抹布链？</title>
      <link>https://stackoverflow.com/questions/77964228/how-can-i-create-a-rag-chain-with-langchain-using-a-retriever-when-having-multip</link>
      <description><![CDATA[我在尝试了解如何使用“|”时遇到一些问题。声明链时langchain中的管道符号。
prompt_template = “””
  仅根据以下上下文进行响应：
  {语境}

作为负责优化给定项目的经验丰富的专家，您的专业知识至关重要
应对挑战并抓住机遇。

问题和机遇：
{问题和机会}

业务目标：
{业务_目标}

项目介绍：
{描述}

请以 JSON 格式提供全面的回复，包括以下内容
成分：

1. 建议的解决方案：
 - 制定详细的计划来克服已发现的挑战并利用
机会。

2. 技术细节：
 - 对该项目指定的技术进行深入分析。
 - 指定要使用的编程语言、框架和平台。
 - 示例：Python、Azure、Pytorch、Tensorflow、AWS、Openai、LLM...

 示例输出（JSON 格式）：
{{

 &quot;solution&quot;: &quot;这里有您的详细解决方案&quot;,
 “技术”：[“技术1”、“技术2”、...]，
 }}
”“”

提示 = ChatPromptTemplate.from_template(prompt_template)

然后我构建我的检索
retriever = vectordb.as_retriever()

和我的法学硕士
llm = AzureChatOpenAI(
    api_key=openai_api_key,
    api_version=openai_api_version,
    azure_endpoint=openai_api_base,
    模型=llm_模型）

然后我添加我的输出解析器
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
从 langchain.callbacks 导入 get_openai_callback

Solution_schema = ResponseSchema(名称=“解决方案”，描述=“给定的”)
Technologies_schema = ResponseSchema（名称=“技术”，描述=“给定的”）

响应模式= [解决方案模式，
                    技术_架构]

输出解析器 = StructuredOutputParser.from_response_schemas(response_schemas)

最后，当我尝试使用链条将所有这些组合在一起时，我惨遭失败
&lt;前&gt;&lt;代码&gt;rag_chain = (
    {“上下文”：检索器，“问题和机会”：RunnablePassthrough()，“业务目标”：RunnablePassthrough()，“描述”：RunnablePassthrough()}
    |迅速的
    |勒姆
    |输出解析器
）

rag_chain.invoke（问题和机会，业务目标，描述）

收到此错误：
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-30-3a4e499badd2&gt;在&lt;细胞系：1&gt;()
----&gt; 1 rag_chain.invoke（问题和机会，业务目标，描述）

类型错误：RunnableSequence.invoke() 需要 2 到 3 个位置参数，但给出了 4 个
]]></description>
      <guid>https://stackoverflow.com/questions/77964228/how-can-i-create-a-rag-chain-with-langchain-using-a-retriever-when-having-multip</guid>
      <pubDate>Thu, 08 Feb 2024 19:12:09 GMT</pubDate>
    </item>
    <item>
      <title>“AdaBoostClassifier”对象没有属性“estimator_”</title>
      <link>https://stackoverflow.com/questions/77963903/adaboostclassifier-object-has-no-attribute-estimator</link>
      <description><![CDATA[我正在尝试对 adaboost 算法的每一轮进行计时（构建每棵附加树需要多长时间）。我 conda 安装了 scikit-learn 1.4.0（因为在他们的网站上说是这个版本）以及运行代码的所有其他要求。
这是我的代码：
Y, z = parse.getHARData() #返回我的特征 Y 和标签 z

Z_train, Z_test, j_train, j_test = train_test_split(Y, z, test_size=0.30, shuffle=True)

b_estimator = DecisionTreeClassifier(max_深度=深度)

ada = AdaBoostClassifier(估计器=b_估计器，n_估计器=NUMTREES)

经过时间 = []

对于范围内的阶段（NUMTREES）：start_time = time.time()

    # 访问并拟合当前的基本估计器
    base_estimator = ada._make_estimator(append=True, random_state=42)
    base_estimator.fit(Z_train, j_train)
    
    elapsed_time = time.time() - 开始时间
    elapsed_times.append(elapsed_time)

我期望这会启动计时器，使用森林之前的信息种植一棵树，将该树添加到集合中，停止时间，并将经过的时间附加到 elapsed_times 中。
相反，它返回此错误：
AttributeError Traceback（最近一次调用最后一次）
第 7 行 [9] 中的单元格
      4 开始时间 = time.time()
      6 # 访问并拟合当前的基本估计器
----&gt; 7 base_estimatr = ada._make_estimator(append=True, random_state=42)
      8 base_estimatr.fit(Z_train, j_train)
     10 经过时间 = time.time() - 开始时间

文件〜/anaconda3/envs/ADA/lib/python3.11/site-packages/sklearn/ensemble/_base.py:141，在BaseEnsemble._make_estimator（self，append，random_state）中
    135 def _make_estimator（自我，附加=真，随机状态=无）：
    136 &quot;&quot;&quot;制作并配置`estimator_`属性的副本。
    137
    138 警告：此方法应用于正确实例化新的
    139 名次级估算员。
    第140章 140
--&gt; 141 估计器 = 克隆（self.estimator_）
    142 estimator.set_params(**{p: getattr(self, p) for p in self.estimator_params})
    144如果random_state不是None：

AttributeError：“AdaBoostClassifier”对象没有属性“estimator_”
]]></description>
      <guid>https://stackoverflow.com/questions/77963903/adaboostclassifier-object-has-no-attribute-estimator</guid>
      <pubDate>Thu, 08 Feb 2024 18:08:39 GMT</pubDate>
    </item>
    <item>
      <title>信息检索 SOTA 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/77962873/information-retrieval-sota-models</link>
      <description><![CDATA[有人可以告诉我在哪里可以找到信息检索的 sota 模型吗？我的任务是通过嵌入的语义搜索按给定查询对文档进行排名。我知道像 ColBERT、SPLADE 这样的模型可以解决这个问题，但我认为它们现在还不是 SOTA。我试图在paperswithcode上找到SOTA模型，但几乎没有关于这个问题的信息。]]></description>
      <guid>https://stackoverflow.com/questions/77962873/information-retrieval-sota-models</guid>
      <pubDate>Thu, 08 Feb 2024 15:30:34 GMT</pubDate>
    </item>
    <item>
      <title>如何将 pytorch 模型转换为 ONNX</title>
      <link>https://stackoverflow.com/questions/77962736/how-to-convert-a-pytorch-model-to-onnx</link>
      <description><![CDATA[我想将 pytorch 模型转换为 ONNX，因为我需要使用 STM32CubeIDE 将模型移植到嵌入式平台上。
Python 代码：
cp = torch.load(&#39;bestmodelw.pth&#39;)
mymodel.load_state_dict(cp[&#39;state_dict&#39;])
mymodel.eval()

示例 = torch.randn(1, 4, 128)
torch.onnx.export（我的模型，
                  例子，
                  在nx路径上，
                  输入名称 = [&#39;输入&#39;],
                  输出名称 = [&#39;输出&#39;],
                  导出参数=真，
                  详细=真实，
                  opset_版本 = 15)

我获得了一个.onnx文件，但是如果我用Netron打开模型，我可以看到每个卷积层有2个输入（显示图像）。 STM32CubeIDE 不支持具有 2 个输入的卷积层，因此我无法使用此模型。
有人可以帮我吗？
STM32CubeIDE 还支持 .h5 文件，因此我尝试将 .onnx 转换为 keras 模型 (.h5)，但出现此错误消息发生：
KeyError: &#39;ReduceMin&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/77962736/how-to-convert-a-pytorch-model-to-onnx</guid>
      <pubDate>Thu, 08 Feb 2024 15:09:57 GMT</pubDate>
    </item>
    <item>
      <title>数组重塑问题</title>
      <link>https://stackoverflow.com/questions/77962428/issue-with-array-reshape</link>
      <description><![CDATA[将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
从 pandas 导入 read_csv
将张量流导入为 tf
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从tensorflow.keras.layers导入LSTM
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.metrics 导入mean_squared_error
# 将值数组转换为数据集矩阵
def create_dataset(数据集,look_back=1):
    数据X，数据Y = []，[]
    对于范围内的 i（len（数据集）-look_back-1）：
        a = 数据集[i:(i + Look_back),0]
        dataX.append(a)
        dataY.append(数据集[i + Look_back, 0])
    返回 np.array(dataX), np.array(dataY)
# 修复随机种子以提高可重复性
tf.random.set_seed(7)
# 加载数据集
dataframe = read_csv(&#39;airline-passengers.csv&#39;, engine=&#39;python&#39;)
数据集 = dataframe.values
数据集 = dataset.astype(&#39;float32&#39;)
# 标准化数据集
缩放器 = MinMaxScaler(feature_range=(0, 1))
数据集=scaler.fit_transform（数据集）
# 分为训练集和测试集
train_size = int(len(数据集) * 0.67)
test_size = len(数据集) - train_size
训练，测试=数据集[0：train_size，：]，数据集[train_size：len（数据集），：]
# 重塑为 X=t 和 Y=t+1
回望 = 1
trainX，trainY = create_dataset（火车，look_back）
testX，testY = create_dataset（测试，look_back）
# 将输入重塑为[样本、时间步长、特征]
trainX = np.reshape(trainX, (trainX.shape[0],1, trainX.shape[1]))
testX = np.reshape(testX, (testX.shape[0],1, testX.shape[1]))
# 创建并拟合 LSTM 网络
模型=顺序（）
model.add(LSTM(4, input_shape=(look_back, 1)))
model.add(密集(1))
model.compile(loss=&#39;mean_squared_error&#39;, 优化器=&#39;adam&#39;)
model.fit(trainX,trainY,epochs=100,batch_size=1,verbose=2)
＃ 作出预测
trainPredict = model.predict(trainX)
testPredict = model.predict(testX)
# 反转预测（确保 inverse_transform 的形状一致）
trainPredict = scaler.inverse_transform(trainPredict.reshape(-1, 1))

我正在获取
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-804718ba5c36&gt;在&lt;细胞系：54&gt;()
     52 testPredict = 模型.predict(testX)
     53 # 反转预测（确保 inverse_transform 的形状一致）
---&gt; 54 trainPredict =scaler.inverse_transform(trainPredict.reshape(-1, 1))
     55 trainY = 缩放器.inverse_transform(trainY.reshape(-1, 1))
     56 testPredict = 缩放器.inverse_transform(testPredict.reshape(-1, 1))

inverse_transform(self, X) 中的 /usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py
    第539章）
    540
--&gt;第541章
    第542章
    第543章

ValueError：形状为 (94,1) 的不可广播输出操作数与广播形状 (94,2) 不匹配

这是我的代码和 r.我的数据库由两列组成，包括月份和乘客数量。我在重塑数组时遇到错误。请帮助我找到此错误的解决方案。顺便说一句，我是个新手。”“”“”“”“”“”“”“”“”“”“”“” ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` ```````````````````````````````````````````````````````` &#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;&#39;]]></description>
      <guid>https://stackoverflow.com/questions/77962428/issue-with-array-reshape</guid>
      <pubDate>Thu, 08 Feb 2024 14:25:00 GMT</pubDate>
    </item>
    <item>
      <title>无法为 HeteroData 创建 NeighborLoader：“EdgeStorage”对象没有属性“num_nodes”</title>
      <link>https://stackoverflow.com/questions/77961450/cant-create-a-neighborloader-for-heterodata-edgestorage-object-has-no-attrib</link>
      <description><![CDATA[当我尝试为我的数据创建 NeighborLoader 时，出现以下错误。
AttributeError：“EdgeStorage”对象没有属性“num_nodes”

我加载图表并使用 RandomNodeSplit 将其拆分为训练/测试/验证，然后，我尝试将拆分数据传递到 NeighborLoader 中并得到上面的错误。
使用的代码：
data = torch.load(training_config[&#39;data_file&#39;])
目标 = pd.read_pickle(training_config[&#39;targets_file&#39;])
打印（类型（数据））

# 创建训练、测试和 VAL 掩码
split = T.RandomNodeSplit(num_val=training_config[&#39;validation_split&#39;], num_test=training_config[&#39;test_split&#39;])
data_split = 分割（数据）
data_split.num_nodes = data.num_nodes
打印（数据分割）
打印（类型（数据分割））
采样器 = ImbalancedSampler(data_split[&#39;word&#39;].y, input_nodes=data_split[&#39;word&#39;].train_mask)

加载器 = NeighborLoader(
    数据分割，
    num_neighbors=[10] * 2,
    batch_size=training_config[&#39;batch_size&#39;],
    input_nodes=data_split[&#39;word&#39;].train_mask,
    采样器=采样器
）

这是这些打印语句的结果：
&lt;类&#39;torch_geometric.data.hetero_data.HeteroData&#39;&gt;

异质数据（
  num_classes=2,
  num_nodes=59565,
  字={
    y=[39566],
    x=[39566, 2],
    train_mask=[39566],
    val_mask=[39566],
    test_mask=[39566],
  },
  句子={ x=[19999, 1] },
  (word, depGraph, word)={ edge_index=[2, 934] },
  (词, 头, 词)={ edge_index=[2, 934] },
  (单词, previousWord, 单词)={ edge_index=[2, 842] },
  (单词, fromSentence, 句子)={ edge_index=[2, 574] },
  (单词, 下一个单词, 单词)={ edge_index=[2, 842] },
  (word, pos, pos)={ edge_index=[2, 39566] },
  (字, 边, 边)={ edge_index=[2, 39566] },
  (word, feat_aspect, feat_aspect)={ edge_index=[2, 1318] },
  (word, feat_case, feat_case)={ edge_index=[2, 1251] },
  (word, feat_conjtype, feat_conjtype)={ edge_index=[2, 708] },
  (word, feat_definite, feat_definite)={ edge_index=[2, 5349] },
  (单词, feat_ Degree, feat_ Degree )={ edge_index=[2, 2735] },
  (单词, feat_foreign, feat_foreign)={ edge_index=[2, 19] },
  (单词, feat_gender, feat_gender)={ edge_index=[2, 169] },
  (单词, feat_mood, feat_mood)={ edge_index=[2, 307] },
  (单词, feat_number, feat_number)={ edge_index=[2, 14435] },
  (word, feat_numtype, feat_numtype)={ edge_index=[2, 1588] },
  (word, feat_person, feat_person)={ edge_index=[2, 1713] },
  (单词, feat_polity, feat_polarity)={ edge_index=[2, 35] },
  (word, feat_poss, feat_poss)={ edge_index=[2, 142] },
  (单词, feat_prontype, feat_prontype)={ edge_index=[2, 7914] },
  (word, feat_punctside, feat_punctside)={ edge_index=[2, 1344] },
  (单词, feat_puncttype, feat_puncttype)={ edge_index=[2, 3603] },
  (word, feat_tense, feat_tense)={ edge_index=[2, 1895] },
  (单词, feat_verbform, feat_verbform)={ edge_index=[2, 2457] },
  (句子, 下一个句子, 句子)={ edge_index=[2, 39996] }
）

&lt;类“torch_geometric.data.hetero_data.HeteroData”&gt;

完整错误跟踪
回溯（最近一次调用最后一次）：
  文件“/path/PyTorchConvert.py”，第 117 行，位于  中。
    加载器 = NeighborLoader(
  文件“/path/anaconda3/envs/graph_builder/lib/python3.8/site-packages/torch_geometric/loader/neighbor_loader.py”，第 229 行，在 __init__ 中
    neighbor_sampler = NeighborSampler(
  文件“/path/anaconda3/envs/graph_builder/lib/python3.8/site-packages/torch_geometric/sampler/neighbor_sampler.py”，第 101 行，位于 __init__ 中
    colptr_dict, row_dict, self.perm = to_hetero_csc(
  文件“/path/anaconda3/envs/graph_builder/lib/python3.8/site-packages/torch_geometric/sampler/utils.py”，第 101 行，位于 to_hetero_csc
    out = to_csc(存储、设备、share_memory、is_sorted、src_node_time)
  文件“/path/anaconda3/envs/graph_builder/lib/python3.8/site-packages/torch_geometric/sampler/utils.py”，第 66 行，位于 to_csc 中
    colptr = index2ptr(col, data.size(1))
  文件“/path/anaconda3/envs/graph_builder/lib/python3.8/site-packages/torch_geometric/data/storage.py”，第 489 行，大小
    self._parent()[self._key[-1]].num_nodes)
  文件“/path/anaconda3/envs/graph_builder/lib/python3.8/site-packages/torch_geometric/data/storage.py”，第 87 行，在 __getattr__ 中
    引发属性错误（
AttributeError：“EdgeStorage”对象没有属性“num_nodes”

进程已完成，退出代码为 1

所以类型是 HeteroData，但是，NeighborLoader 在某处获取 EdgeStorage，而我无法使用它来批处理我的数据？我可以尝试解决此问题吗？
我可以在不进行批处理的情况下训练 SageConv，但是，我想尝试一下，看看它如何影响我的结果。]]></description>
      <guid>https://stackoverflow.com/questions/77961450/cant-create-a-neighborloader-for-heterodata-edgestorage-object-has-no-attrib</guid>
      <pubDate>Thu, 08 Feb 2024 11:53:39 GMT</pubDate>
    </item>
    <item>
      <title>GitHub CoPilot 引用自定义库代码</title>
      <link>https://stackoverflow.com/questions/77961323/github-copilot-referring-custom-library-code</link>
      <description><![CDATA[我们希望将自定义开源库（来自 GitHub Repo 的 CSS 样式、React 组件、Typescript 规则等）包含到我们的代码生成过程中。我们如何将其添加到 GitHub Copilot 以供代码生成时参考？这将使我们能够生成我们的库固有的定制代码。我们知道不可能为我们的项目需求培训法学硕士。然而，还有其他方法吗？我们使用的是商业版。
我们从 CoPilot 那里得到了针对同一问题的以下回复。但是，我们不确定给定的提示是否合适。
&lt;块引用&gt;
截至目前，GitHub Copilot 不支持在其代码生成过程中包含来自特定 GitHub 存储库的自定义库或代码。它接受过广泛的公共代码的训练，但它不了解特定的代码库、库或框架。它无法访问或引用特定存储库或库来生成代码。它根据训练期间学到的模式生成建议。
]]></description>
      <guid>https://stackoverflow.com/questions/77961323/github-copilot-referring-custom-library-code</guid>
      <pubDate>Thu, 08 Feb 2024 11:33:08 GMT</pubDate>
    </item>
    <item>
      <title>就地修剪 nn.Linear 权重会导致意外错误，需要稍微奇怪的解决方法。需要解释</title>
      <link>https://stackoverflow.com/questions/77959410/pruning-nn-linear-weights-inplace-causes-unexpected-error-requires-slightly-wei</link>
      <description><![CDATA[失败
导入火炬

def 测试1():
  层 = nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试1()

有错误
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
RuntimeError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-bb36a010bd86&gt;在&lt;细胞系：10&gt;()
      8 x = 5 - torch.sum(layer(torch.ones(90)))
      9 x.backward()
---&gt; 10 测试1()
     11 # 这也有效
     12

2帧
/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py 向后（张量，grad_tensors，retain_graph，create_graph，grad_variables，输入）
    249 # 一些 Python 版本打印多行函数的第一行
    [第 250 章]
--&gt; 251 Variable._execution_engine.run_backward( # 调用 C++ 引擎来运行向后传递
    252个张量，
    第253章

RuntimeError: 函数 TBackward0 在索引 0 返回无效渐变 - 得到 [10, 90] 但预期形状与 [10, 100] 兼容

这有效
导入火炬

def test2():
  层 = torch.nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  del x #主要变化
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试2()

这也有效
导入火炬
def test3():
  层 = torch.nn.Linear(100, 10)
  x = 5 - torch.sum(layer(torch.ones(100)))
  x.backward()
  层.权重.数据 = 层.权重.数据[:, :90]
  层.权重.grad.数据 = 层.权重.grad.数据[:, :90]
  layer.weight = torch.nn.Parameter(layer.weight) #主要变化
  x = 5 - torch.sum(layer(torch.ones(90)))
  x.backward()
测试3()

我在尝试实现一篇关于模型修剪的论文时遇到了这个问题。我相信这与 autograd 图有关，但我不确定到底发生了什么。有什么解释可以解释为什么这些几乎相同的代码片段有效或失败吗？]]></description>
      <guid>https://stackoverflow.com/questions/77959410/pruning-nn-linear-weights-inplace-causes-unexpected-error-requires-slightly-wei</guid>
      <pubDate>Thu, 08 Feb 2024 05:17:32 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sklearn 将 PCA 加载称为组件？</title>
      <link>https://stackoverflow.com/questions/77936290/why-does-sklearn-refer-to-pca-loadings-as-components</link>
      <description><![CDATA[也许这是术语上的简单混淆，但我认为PCA组件是每个组件都是正交的简化矩阵。使用sklearn，这是这样完成的，
reduced_data = pd.DataFrame(pca.transform(df_scaled))

我认为PCA负载是分配给原始变量的权重。令人困惑的是，这些是使用以下方法从拟合的 PCA 模型中提取的：
factor_loadings = pd.DataFrame(pca.components_)

我的术语是否错误，或者这些术语可以互换使用吗？]]></description>
      <guid>https://stackoverflow.com/questions/77936290/why-does-sklearn-refer-to-pca-loadings-as-components</guid>
      <pubDate>Sun, 04 Feb 2024 15:00:22 GMT</pubDate>
    </item>
    <item>
      <title>DeepFM 推荐模型日志记录问题</title>
      <link>https://stackoverflow.com/questions/77862051/deepfm-recommender-model-logging-issues</link>
      <description><![CDATA[我正在尝试使用 DeepFM 模型进行推荐。但无法使用tensorflow或mlflow记录模型。
如果有人以前使用过这个模型，你有同样的解决方案吗？
将 pandas 导入为 pd
从 libreco.data 导入 random_split
从 libreco.algorithms 导入 WideDeep,DeepFM
从 sklearn.preprocessing 导入 LabelEncoder、MinMaxScaler
从 libreco.data 导入 random_split、DatasetFeat、DatasetPure、TransformedSet
从 libreco.evaluation 导入评估

train_data, data_info = DatasetFeat.build_trainset(df,user_col=[&#39;用户&#39;,&#39;年龄&#39;], item_col=[&#39;项目&#39;,&#39;流行度&#39;, &#39;运行时&#39;, &#39;投票平均&#39;,&#39;标签&#39;,&#39;流派&#39;],稀疏_col=[&#39;用户&#39;,&#39;项目&#39;,&#39;流派&#39;],dense_col=[&#39;流行度&#39;,&#39;运行时&#39;,&#39;投票平均&#39;,&#39;年龄&#39;,&#39;标签&#39;])

显示（train_data.item_indices.shape，train_data.user_indices.shape，train_data.dense_values.shape，train_data.sparse_indices.shape，train_data.sparse_indices.shape，train_data.labels.shape）

模型= DeepFM（data_info = data_info，任务=&#39;排名&#39;，loss_type =&#39;cross_entropy&#39;，embed_size = 16，n_epochs = 20，lr = 0.001，lr_decay = False，epsilon = 1e-05，batch_size = 256，sampler =&#39;随机&#39;, num_neg=1, use_bn=True, hide_units=(128, 64, 32), multi_sparse_combiner=&#39;sqrtn&#39;)
历史= model.fit（train_data，neg_sampling = True，verbose = 1，shuffle = True，eval_data =无，metrics =无，k = 10，eval_batch_size = 8192，eval_user_num =无，num_workers = 0）
]]></description>
      <guid>https://stackoverflow.com/questions/77862051/deepfm-recommender-model-logging-issues</guid>
      <pubDate>Mon, 22 Jan 2024 18:39:17 GMT</pubDate>
    </item>
    <item>
      <title>基于 Transformers 的推荐系统获取具有项目名称和类型的数据集的有效方法[关闭]</title>
      <link>https://stackoverflow.com/questions/77852593/efficient-methods-for-obtaining-dataset-with-item-names-and-types-for-transforme</link>
      <description><![CDATA[我找不到一种简单的方法（最好是 API）来获取大量项目名称及其类型的数据。例如，电影有其类型（恐怖、爱情、喜剧），游戏有其类型（恐怖、单人），音乐有其类型（古典、钢琴）等。
我能找到的最好办法就是访问 IMDB 等网站，并尝试从网站本身中获取数据（这在大多数地方甚至可能违反 TOS？）。
您是否找到了任何可以获取服务的完整项目列表及其类别等的 API，您能否分享它或者建议一种比抓取网络更简单的方法，因为它已经花费了我更多的时间应该，但在承诺之前我很想听听也许有人有更好的想法..
我试图在 Spotfiy、Google、Steam 等上查找 API，这将使我能够访问所有可能的游戏名称及其类别，但在其 API 中找不到任何此类端点。]]></description>
      <guid>https://stackoverflow.com/questions/77852593/efficient-methods-for-obtaining-dataset-with-item-names-and-types-for-transforme</guid>
      <pubDate>Sat, 20 Jan 2024 20:18:55 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析：分类变量的预测</title>
      <link>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</link>
      <description><![CDATA[我有一台机器在 1 分钟时间间隔内的故障发生数据（以 0 和 1 表示）。 0 代表未发生故障，1 代表发生特定故障。因此，连续0 表示在一段时间内没有发生故障，连续1 表示在一段时间内连续发生故障。
我提供了如下的示例数据结构，现在我如何对下面提供的数据进行时间序列分析故障 A，并根据分析如何进行预测，例如“故障 A 将在未来时间戳中何时发生？” 
# 时间序列多元
将 pandas 导入为 pd
将 numpy 导入为 np

df = pd.DataFrame({&#39;timestamp&#39;:pd.date_range(&#39;2022-05-01 00:01:00&#39;, period=18, freq=&#39;T&#39;),
                   &#39;故障代码&#39;:[&#39;A&#39;]*4+[&#39;B&#39;]*3+[&#39;A&#39;]*2+[&#39;C&#39;]*5+[&#39;B&#39;]*2+[&#39;A&#39;]* 1+[&#39;D&#39;]*1
                  })
df[&#39;脉冲&#39;] = 1

df_ts = df.pivot(index=“时间戳”, columns=“故障代码”, value=“脉冲”)
df_ts = df_ts.fillna(0)
显示（df_ts）



         故障代码 A B C D
时间戳
2022-05-01 00:01:00 1 0 0 0
2022-05-01 00:02:00 1 0 0 0
2022-05-01 00:03:00 1 0 0 0
2022-05-01 00:04:00 1 0 0 0
2022-05-01 00:05:00 0 1 0 0
2022-05-01 00:06:00 0 1 0 0
2022-05-01 00:07:00 0 1 0 0
2022-05-01 00:08:00 1 0 0 0
2022-05-01 00:09:00 1 0 0 0
2022-05-01 00:10:00 0 0 1 0
2022-05-01 00:11:00 0 0 1 0
2022-05-01 00:12:00 0 0 1 0
2022-05-01 00:13:00 0 0 1 0
2022-05-01 00:14:00 0 0 1 0
2022-05-01 00:15:00 0 1 0 0
2022-05-01 00:16:00 0 1 0 0
2022-05-01 00:17:00 1 0 0 0
2022-05-01 00:18:00 0 0 0 1

# 时间序列图
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns

sns.set_theme(style=&quot;whitegrid&quot;) # darkgrid、whitegrid、dark、white 和ticks

故障=[&#39;A&#39;,
        &#39;B&#39;,
        &#39;C&#39;，
        &#39;D&#39;
       ]

plt.figure(figsize = (15,4))
sns.lineplot(数据=df_ts[故障])
plt.show()

上述数据的时间序列图：

我要预测A的故障代码（0或1）
         
时间戳故障代码
2022-05-01 00:19:00 ?
2022-05-01 00:20:00 ?
2022-05-01 00:21:00 ？
2022-05-01 00:22:00 ？
2022-05-01 00:23:00 ？
2022-05-01 00:24:00 ？
2022-05-01 00:25:00 ？
]]></description>
      <guid>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</guid>
      <pubDate>Fri, 03 Jun 2022 10:48:17 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch RuntimeError：CUDA 内存不足且有大量可用内存</title>
      <link>https://stackoverflow.com/questions/71498324/pytorch-runtimeerror-cuda-out-of-memory-with-a-huge-amount-of-free-memory</link>
      <description><![CDATA[在训练模型时，我遇到了以下问题：
运行时错误：CUDA 内存不足。尝试分配 304.00 MiB（GPU 0；8.00 GiB 总容量；已分配 142.76 MiB；6.32 GiB 空闲；PyTorch 总共保留 158.00 MiB）分配的内存尝试设置 max_split_size_mb 以避免碎片。请参阅内存管理和 PYTORCH_CUDA_ALLOC_CONF 的文档
正如我们所看到的，当尝试分配 304 MiB 内存时会发生错误，而 6.32 GiB 是空闲的！问题是什么？正如我所看到的，建议的选项是设置 max_split_size_mb 以避免碎片。它会有帮助吗？如何正确地做到这一点？
这是我的 PyTorch 版本：
火炬==1.10.2+cu113
火炬视觉==0.11.3+cu113
火炬音频===0.10.2+cu113]]></description>
      <guid>https://stackoverflow.com/questions/71498324/pytorch-runtimeerror-cuda-out-of-memory-with-a-huge-amount-of-free-memory</guid>
      <pubDate>Wed, 16 Mar 2022 13:53:45 GMT</pubDate>
    </item>
    <item>
      <title>Mahout 基于项目的推荐引擎，没有偏好值</title>
      <link>https://stackoverflow.com/questions/17712903/mahout-item-based-recommendation-engine-with-no-preference-values</link>
      <description><![CDATA[我正在尝试使用 Mahout 构建一个推荐引擎，该引擎仅根据项目之间的相似性提供推荐，而不考虑用户偏好（即评分）。项目相似度由 mahout 外部的一些其他进程计算并保存到文件中。到目前为止，我已经确定我可以使用该类：
GenericBooleanPrefItemBasedRecommender

...选择项目，文档称其“适合在数据中不存在偏好值概念时使用”。但是，该类仍将其作为输入：
(DataModel dataModel, ItemSimilarity 相似度)

我知道我可以使用 ItemSimilarity 类来提供项目到项目的相似度值，但是在这种情况下我的数据模型是什么？我没有偏好，这似乎正是数据模型所代表的东西。我该如何解决这个问题，或者我在这里看错了东西？]]></description>
      <guid>https://stackoverflow.com/questions/17712903/mahout-item-based-recommendation-engine-with-no-preference-values</guid>
      <pubDate>Thu, 18 Jul 2013 01:13:28 GMT</pubDate>
    </item>
    </channel>
</rss>