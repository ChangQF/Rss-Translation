<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 12 May 2024 01:05:46 GMT</lastBuildDate>
    <item>
      <title>使用torch音频库创建数据集时出错</title>
      <link>https://stackoverflow.com/questions/78466420/error-when-using-torch-audio-library-to-create-a-data-set</link>
      <description><![CDATA[我正在学习 YT 课程，研究使用 torch 音频的城市 8k 数据集。作者编写了完全相同的代码，但在我收到错误时能够获得输出。
以下是我收到的错误：
运行时错误：找不到适当的后端来处理 uri C:\Users\hbhavnag\Documents\Hussain\ASU\collision detector\urban sound\UrbanSound8K\audio\5\100263-2-0-121。 wav 和格式 无。

以下是我的代码：
`从 torch.utils.data 导入数据集
将 pandas 导入为 pd
导入火炬音频
导入操作系统
类 UrbanSoundDataset（数据集）：
def __init__(self,annotation_file,audio_dir):
    self.annotations = pd.read_csv(annotation_file)
    self.audio_dir = 音频_dir

def __len__(自身):
    返回 len(self.annotations)

def __getitem__(自身，索引)：
    audio_sample_path = self._get_audio_sample_path(索引)
    标签 = self._get_audio_sample_label(索引)
    信号，sr = torchaudio.load（audio_sample_path）
    返回信号、标签

def _get_audio_sample_path（自身，索引）：
    Fold = f“fold{self.annotations.iloc[index,5]}”
    路径 = os.path.join(self.audio_dir, 折叠, self.annotations.iloc[index,0])
    返回路径

def _get_audio_sample_label（自身，索引）：
    返回 self.annotations.iloc[index,6]

如果 __name__ == “__main__”：
    注释_文件 = r“C:\Users\hbhavnag\Documents\Hussain\ASU\碰撞检测\城市声音\UrbanSound8K\metadata\UrbanSound8K.csv”
    audio_dir = r&quot;C:\Users\hbhavnag\Documents\Hussain\ASU\碰撞检测\城市声音\UrbanSound8K\audio&quot;
    usd = UrbanSoundDataset（注释文件，音频目录）
    print (f“数据集中有 {len(usd)} 个样本”)

信号，标签=美元[2]`

我尝试查找 torch audio 的文档，但不确定是否有任何内容可以直接帮助我，我假设存在一些版本兼容性问题。
我使用的是 Windows。]]></description>
      <guid>https://stackoverflow.com/questions/78466420/error-when-using-torch-audio-library-to-create-a-data-set</guid>
      <pubDate>Sun, 12 May 2024 00:34:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 HuggingFace Transformers Pipeline 在每个提示（如 vLLM）中生成多个文本补全而不触发错误？</title>
      <link>https://stackoverflow.com/questions/78466376/how-to-generate-multiple-text-completions-per-prompt-like-vllm-using-huggingfa</link>
      <description><![CDATA[我正在使用 HuggingFace Transformers Pipeline 库为给定提示生成多个文本完成。我的目标是利用像 GPT-2 这样的模型来生成不同的可能完成结果，例如 vLLM 中的默认值。但是，当我尝试指定 max_length 和 num_return_sequences 等参数时，我遇到了未使用 model_kwargs 的问题。
这是我正在使用的代码片段：
复制代码
从变压器导入 GPT2Tokenizer、GPT2LMHeadModel、管道
从输入导入列表，字典

def process_prompts(提示: List[str], 模型: GPT2LMHeadModel, tokenizer: GPT2Tokenizer, num_completions: int = 3) -&gt;列表[列表[str]]：
    device = 0 if model.device.type == &#39;cuda&#39; else -1
    text_generator = pipeline(“文本生成”, model=model, tokenizer=tokenizer, device=device)
    输出 = []

    对于提示中的提示：
        尝试：
            结果= text_generator（提示，max_length = 50，num_return_sequences = num_completions，num_beams = num_completions）
            完成 = [结果[&#39;生成的文本&#39;] 结果中的结果]
            输出.追加（完成）
        除了异常 e：
            print(f&quot;处理错误提示{prompt}: {str(e)}&quot;)

    返回输出

如果 __name__ == “__main__”：
    tokenizer = GPT2Tokenizer.from_pretrained(“gpt2”)
    模型 = GPT2LMHeadModel.from_pretrained(“gpt2”)
    model.to(“cuda” if torch.cuda.is_available() else “cpu”)

    example_prompts = [“你好，你好吗？”]
    processed_outputs = process_prompts(example_prompts, model, tokenizer, num_completions=3)
    对于processed_outputs中的输出：
        打印（输出）

还有：
 results = text_generator(prompt, max_length=50, num_return_sequences=num_completions)

当我运行此程序时，出现以下错误：
模型不使用以下`model_kwargs`：[&#39;max_len&#39;]
注意：我知道生成参数中的拼写错误也可能触发此警告，但我已经检查并重新检查了参数名称。

和
 引发 ValueError(
ValueError：没有波束搜索的贪婪方法不支持不同于 1 的 `num_return_sequences`（得到 4）。

什么可能导致此错误，以及如何修复它以使用模型有效地生成多个完成？
交叉：https://discuss.huggingface.co/t/how-to-generate-multiple-text-completions-per-prompt-using-huggingface-transformers-pipeline-without -触发错误/86297]]></description>
      <guid>https://stackoverflow.com/questions/78466376/how-to-generate-multiple-text-completions-per-prompt-like-vllm-using-huggingfa</guid>
      <pubDate>Sun, 12 May 2024 00:06:07 GMT</pubDate>
    </item>
    <item>
      <title>通过 k 均值和分类进行聚类</title>
      <link>https://stackoverflow.com/questions/78466355/clustering-by-k-means-and-classification</link>
      <description><![CDATA[任务分配：
分类是根据类别进行的，这绝对是无监督的（有 5 个类别需要帮助）。
我被分配了这个任务，其中我有一个包含多列形式的数据集.. .
&lt;前&gt;&lt;代码&gt;` D1_16 D1_17 D1_18 D1_19 D1_20 D1_23 D1_24 D1_25 D1_26 D1_27 \
1 1 1 1 1 1 1 1 1 1 1
2 1 1 1 1 1 0 1 0 1 1
3 0 0 0 0 0 0 0 0 0 0
4 0 1 0 1 0 0 1 1 1 0
5 0 0 0 0 0 0 0 0 0 0
……………………………………
29502 0 0 0 0 0 0 0 0 0 0
29504 0 0 0 0 0 0 0 0 0 0
29505 0 0 0 0 0 0 0 0 0 0
29506 0 0 0 0 0 0 0 0 0 0
29507 0 0 0 0 0 0 0 0 0 0

       ... D68_29 D68_30 D68_31 D68_32 D68_33 D68_34 D68_35 D68_36 \
1 ... 0 0 1 0 0 0 0 0
2 ... 0 0 0 0 0 1 0 0
3 ... 0 0 0 0 0 0 0 0
4 ... 0 0 0 0 0 0 0 0
5 ... 0 0 0 0 0 0 0 0
………………………………
29502 ... 0 0 0 0 0 0 0 0
29504 ... 0 0 0 0 0 0 0 0
29505 ... 0 0 0 0 0 0 0 0
29506 ... 0 0 0 0 0 0 0 0
29507 ... 0 0 0 0 0 0 0 1`

我是否正确理解，首先需要进行聚类，例如根据k-means并选择一个合适的类，在此基础上我将数据分为两部分并标记“1”和“0”例如，然后对树进行分类？或者您需要以不同的方式执行聚类。老实说，我不太明白我要做什么，如果有任何想法，我将不胜感激。
我的程序：
best_score = -1
最佳_k = 0

对于范围 (2, 10) 内的 k：
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(df)
    Silhouette_avg = Silhouette_score(df, kmeans.labels_)
    

    如果 Silhouette_avg &gt;最佳得分：
        最佳得分 = 轮廓平均数
        最佳_k = k

kmeans = KMeans(n_clusters=best_k)
kmeans.fit(df)
df[&#39;cluster&#39;] = kmeans.labels_

best_cluster = np.argmax(np.bincount(kmeans.labels_))
df[&#39;目标&#39;] = np.where(df[&#39;簇&#39;] == best_cluster, 0, 1)

X_train, X_test, y_train, y_test = train_test_split(df.drop([&#39;集群&#39;, &#39;目标&#39;], axis=1), df[&#39;目标&#39;], test_size=0.2, random_state=42)

clf = 决策树分类器()
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
准确度=准确度_分数（y_test，y_pred）

数据集：https://filetransfer.io/data-package/Aiawe648#link
我的所有程序： https://onecompiler.com/python/42cxfy2vz
有关聚类和分类的建议]]></description>
      <guid>https://stackoverflow.com/questions/78466355/clustering-by-k-means-and-classification</guid>
      <pubDate>Sat, 11 May 2024 23:54:57 GMT</pubDate>
    </item>
    <item>
      <title>eval(predvars, data, env) 中的错误：未找到对象“适配器”</title>
      <link>https://stackoverflow.com/questions/78466280/error-in-evalpredvars-data-env-object-adapter-not-found</link>
      <description><![CDATA[我正在尝试在 tf-idf 矩阵上训练随机森林分类器，其中的列是评论中的单词。
获得一个想法：
标签...1实际上是适配器
1 0 0.01495934 0.02880089
2 0 0.00000000 0.00000000
3 0 0.00000000 0.00000000

我使用 train_data 训练了模型，其中标签为 [0] 为负，[1] 为正。
这是代码：
set.seed(123)
random_forest_model &lt;- 训练（标签...1 ~ .,
               数据=训练数据，
               方法=“rf”，
               trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 10),
               uneGrid = Expand.grid(mtry = 100),
               n树= 500，
               重要性=真）

我想使用经过训练的模型来预测另一个矩阵的评论是正面还是负面。
使用此代码：
# 对测试集进行预测
y_pred &lt;- 预测（random_forest_model，newdata = test_data）

问题是我收到此错误：
eval(predvars, data, env) 中的错误：未找到对象“适配器”

因为并非train_data中存在的所有单词（列）也存在于test_data中。对test_data的评价不同。
该模型的想法是预测在这种情况下评论是正面还是负面。不可能找到总是具有相同单词的矩阵。
我尝试输入 RF 模型数据框而不是矩阵，因为我读到它更好，但它没有解决问题。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78466280/error-in-evalpredvars-data-env-object-adapter-not-found</guid>
      <pubDate>Sat, 11 May 2024 22:55:59 GMT</pubDate>
    </item>
    <item>
      <title>用于预测前 k 个元素的平均倒数排名 (MRR) 理解</title>
      <link>https://stackoverflow.com/questions/78466130/mean-reciprocal-rank-mrr-understanding-for-predicting-top-k-elements</link>
      <description><![CDATA[我有一篇论文中的以下代码，他们已经实现了 MRR，以使用某种机器学习模型推荐 top-k 元素。
def MRR(test_y, pred_y, k=5):
    预测 = pd.DataFrame([])
    预测[“pred_y”] = pred_y
    预测[“y”] = test_y

    预测=预测.sort_values(“pred_y”,升序=False).reset_index(drop=True)
    预测[“pred_y_rank_index”] = (预测.index) + 1
    预测=预测.sort_values(“y”,升序=False)

    返回 sum(1 / 预测[“pred_y_rank_index”][:k]) / k

我不明白的是 - MRR 是如何根据代码在这里工作的。我从这个维基百科链接了解了 MRR。但是当我预测前 5 个元素时，在最好的情况下，如果预测元素的排名与实际元素的排名匹配 100%，那么 MRR 不应该产生结果 1 吗？但根据这段代码，前 5 个（k=5）元素的结果将是 ((1/1 + 1/2 + 1/3 + 1/4 + 1/5)/5) = 0.4566。
现在根据我的理解，在这种情况下，代码以错误的方式实现 MRR，或者 MRR 不是评估这种情况的正确指标。任何对此的了解或想法将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78466130/mean-reciprocal-rank-mrr-understanding-for-predicting-top-k-elements</guid>
      <pubDate>Sat, 11 May 2024 21:21:38 GMT</pubDate>
    </item>
    <item>
      <title>是否可以根据熟练程度/复杂性对文本进行有效分类？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78465977/is-it-possible-to-efficiently-classify-text-based-on-proficiency-complexity</link>
      <description><![CDATA[我目前正在开发一个项目，该项目需要一个包含大量文本的数据集，这些文本带有标记的文本复杂性/熟练程度、5/6 不同的复杂性级别。我尝试了多种方法，例如 API、可读性公式、搜索现有数据集等。但似乎没有任何效果。
我正在寻找基本文本，例如“她参观动物园”。她看到了很多动物。”，到精通的文本，例如：“他对行为经济学的深入研究细致地研究了影响消费者行为的认知偏差的复杂动态，提出了先进的预测模型来提高预测消费者购买模式的准确性。”&lt; /p&gt;
有人熟悉标记大量文本（50,000-100,000）吗？
如前所述，我尝试使用 API、可读性公式和现有数据集。但似乎没有任何作用。我无法使用任何模型，因为我没有数据集，这就是问题所在。]]></description>
      <guid>https://stackoverflow.com/questions/78465977/is-it-possible-to-efficiently-classify-text-based-on-proficiency-complexity</guid>
      <pubDate>Sat, 11 May 2024 20:11:08 GMT</pubDate>
    </item>
    <item>
      <title>构建分类模型后，如何在数据集中不指定对象定位的情况下执行对象/异常定位？</title>
      <link>https://stackoverflow.com/questions/78465357/how-to-perform-object-anomaly-localization-after-building-a-classification-model</link>
      <description><![CDATA[我已经使用 EfficientNetB4 成功构建了一个分类模型，该模型可以高精度地将医学图像分类为各种类别。现在，我想本地化并提取这些图像中的感兴趣区域（异常），而无需在数据集中添加明确的本地化注释。
我接触过 Grad-CAM、CAM 和引导反向传播等多种技术，但在正确实施它们时遇到了困难。以下是我的设置的简要概述：
模型架构：EfficientNetB4 具有用于分类的附加密集层。
分类准确度：非常高，因此模型区分类别的能力不是问题。
目标：可视化并提取模型用于预测的区域（异常）。
**
我的问题：**
在这种情况下，异常定位的最佳技术是什么？有没有特别适合医学图像的方法？
如何在 TensorFlow/Keras 中实现这些技术？任何示例代码或详细步骤将不胜感激。
在尝试使用这些技术可视化和提取异常时，我应该注意哪些常见陷阱？
**我尝试过的：
**实施 Grad-CAM，但在与我的 EfficientNetB4 模型集成时面临形状不匹配问题。
尝试展平图层并调整输入形状，但仍然遇到错误。]]></description>
      <guid>https://stackoverflow.com/questions/78465357/how-to-perform-object-anomaly-localization-after-building-a-classification-model</guid>
      <pubDate>Sat, 11 May 2024 16:35:06 GMT</pubDate>
    </item>
    <item>
      <title>CreateML 超参数</title>
      <link>https://stackoverflow.com/questions/78465196/createml-hyperparameters</link>
      <description><![CDATA[我尝试为 S&amp;P500 指数中的每只股票创建一些机器学习模型。使用 sklearn（提升树模型）创建模型时，我尝试通过使用 GridSearchCV 执行超参数来使其更成功。创建一种模型需要很长时间，因此我不想考虑创建所有股票模型。我尝试使用 CreateML 和 swift，但看起来它比 python 上的 sklearn 运行时间更长。我的问题是如何使该过程更快？ swift 上的 CreateML 上是否有任何超参数（我在文档中找不到它）以及如何在我的 GPU 上运行此代码？ （应该快得多）。
我对任何想法持开放态度，在 GPU 上运行整个 python，只运行 hyperopt params 部分，或者在 CreateML 中快速创建模型。
我有 MacBook Pro M2]]></description>
      <guid>https://stackoverflow.com/questions/78465196/createml-hyperparameters</guid>
      <pubDate>Sat, 11 May 2024 15:36:45 GMT</pubDate>
    </item>
    <item>
      <title>使用 python spacy 模块的词向量显示错误</title>
      <link>https://stackoverflow.com/questions/78464557/word-vectors-using-spacy-module-of-python-showing-error</link>
      <description><![CDATA[我正在尝试使用 python 的 spacy 模块获取词向量，并使用 en_core_web_lg 创建词向量。
从 sklearn.feature_extraction.text 导入 CountVectorizer
从 sklearn.feature_extraction.text 导入 TfidfVectorizer

tfidf=TfidfVectorizer(小写=False)

df1[&#39;问题1&#39;]=df1[&#39;问题1&#39;].apply(lambda x : str(x))
df1[&#39;问题2&#39;]=df1[&#39;问题2&#39;].apply(lambda x : str(x))

tot_ques=列表(df1[&#39;问题1&#39;]) + 列表(df1[&#39;问题2&#39;])

tfidf.fit(tot_ques)

idfscore=dict(zip(tfidf.get_feature_names_out(),tfidf.idf_))
打印（idf分数）

从 tqdm 导入 tqdm
导入spacy
nlp=spacy.load(&#39;en_core_web_lg&#39;)

向量1 = []
# 迭代每个问题1
对于 tqdm(list(df1[&#39;question1&#39;])) 中的 qu1：
doc1 = nlp（qu1）

# 初始化向量总和以及 IDF 总分
sum_vec = np.zeros(len(doc1[0].vector)) # 第一个单词的向量维度
Total_idf = 0.0 # 初始化IDF总分

# 遍历句子中的每个单词
对于 doc1 中的单词：
    vec = 词.向量
    
    # 计算单词的IDF分数
    尝试：
        idf = idfscore(str(单词))
    除了：
        idf = 0.0
    
    # 累加词向量的加权和
    sum_vec += vec * idf
    
    # 累计IDF总分
    总计 idf += idf

# 如果 IDF 总得分不为零，则计算均值向量
如果total_idf！= 0：
    平均向量 = 向量总和 / 总 idf
别的：
    mean_vec = sum_vec # 如果总 IDF 为零，则回退到 sum_vec

# 将均值向量附加到 vec1
vec1.append(mean_vec)

# 将计算出的向量分配给数据框中的新列“q1”
df1[&#39;q1&#39;] = vec1`

但是当我查看 q1 列的值时，每行都显示 0。]]></description>
      <guid>https://stackoverflow.com/questions/78464557/word-vectors-using-spacy-module-of-python-showing-error</guid>
      <pubDate>Sat, 11 May 2024 12:13:25 GMT</pubDate>
    </item>
    <item>
      <title>有序 Logit 回归的预测如何工作？</title>
      <link>https://stackoverflow.com/questions/78461070/how-does-prediction-for-ordered-logit-regression-work</link>
      <description><![CDATA[我正在学习有序 logit 回归，我想知道预测在数学上是如何工作的以及我如何自己在 python 中完成它。我知道在 python 中我可以简单地使用预测，但我想知道如何仅使用 model.summary() 中的 coef 进行预测。
导入 pandas 作为 pd
从 statsmodels.miscmodels.ordinal_model 导入 OrderedModel


数据 = pd.DataFrame({
    ‘分数’: [3.2, 4.5, 5.6, 6.7, 7.8, 8.9, 9.1],
    “评级”：[1,2,3,4,5,6,6]
})

X = 数据[[&#39;分数&#39;]]
y = 数据[&#39;评级&#39;]


ordinal_model = OrderedModel(y, X, distr=&#39;logit&#39;)


ordinal_results = ordinal_model.fit(method=&#39;bfgs&#39;)


打印（ordinal_results.summary（））


结果是：
时间：17:05:52
观察次数：7
Df 残差：1
DF型号：1
=================================================== ===========================
                 coef std err z P&gt;|z| [0.025 0.975]
-------------------------------------------------- ----------------------------
得分 66.3902 5669.125 0.012 0.991 -1.1e+04 1.12e+04
1/2 285.5835 2.56e+04 0.011 0.991 -4.98e+04 5.04e+04
2/3 4.2698 88.656 0.048 0.962 -169.493 178.032
3/4 4.1879 155.834 0.027 0.979 -301.241 309.617
4/5 4.3867 136.765 0.032 0.974 -263.668 272.442
5/6 3.4706 220.734 0.016 0.987 -429.161 436.102
=================================================== ===========================

使用 coef 向量如何获得与中相同的输出
ordinal_results.model.predict(ordinal_results.params, exog = (4.3))

&lt;预&gt;&lt;代码&gt;[[0.5264086 0.4735914 0.0.0.0.]]


我认为我应该对 coef 和新数据的线性和使用 softmax，但这不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78461070/how-does-prediction-for-ordered-logit-regression-work</guid>
      <pubDate>Fri, 10 May 2024 15:16:52 GMT</pubDate>
    </item>
    <item>
      <title>损失值不断波动，MLP模型的一般问题</title>
      <link>https://stackoverflow.com/questions/78458260/the-value-of-loss-is-keeping-fluctuating-questions-about-mlp-model-in-general</link>
      <description><![CDATA[我正在为 ML 内容构建 MLP 模型，我对模型输出有一个基本问题。
这是我的源代码和结果
纪元 = 50
对于范围内的纪元（纪元）：
    对于输入，train_loader 中的标签：
        输出 = 模型（输入）
        损失=标准（输出，标签）

        优化器.zero_grad()
        loss.backward()
        优化器.step()

    loss_values.append(loss.item())
    print(f&#39;Epoch {epoch + 1}/{epochs}, 损失: {loss.item()}&#39;)

纪元 1/50，损失：0.2941759526729584
纪元 2/50，损失：0.2274172008037567
纪元 3/50，损失：0.1548108160495758
纪元 4/50，损失：0.09923569858074188
纪元 5/50，损失：0.07782179117202759
纪元 6/50，损失：0.08670808374881744
纪元 7/50，损失：0.1000475212931633
纪元 8/50，损失：0.08599527180194855
纪元 9/50，损失：0.06509505957365036
纪元 10/50，损失：0.0660080686211586
纪元 11/50，损失：0.07633966952562332
纪元 12/50，损失：0.06544400751590729
纪元 13/50，损失：0.07453220337629318
纪元 14/50，损失：0.0681438073515892
纪元 15/50，损失：0.07069016247987747
纪元 16/50，损失：0.05649592727422714
纪元 17/50，损失：0.05515648424625397
纪元 18/50，损失：0.05455780029296875
纪元 19/50，损失：0.06591354310512543
20/50 纪元，损失：0.06227065622806549
纪元 21/50，损失：0.050895411521196365
纪元 22/50，损失：0.05813339725136757
纪元 23/50，损失：0.05856814980506897
纪元 24/50，损失：0.056620728224515915
纪元 25/50，损失：0.05406007170677185
纪元 26/50，损失：0.05851085111498833
纪元 27/50，损失：0.04691702872514725
纪元 28/50，损失：0.036375436931848526
纪元 29/50，损失：0.043669767677783966
纪元 30/50，损失：0.047907356172800064
纪元 31/50，损失：0.04583781585097313
纪元 32/50，损失：0.044408515095710754
纪元 33/50，损失：0.04572493955492973
纪元 34/50，损失：0.0413966178894043
纪元 35/50，损失：0.047711536288261414
纪元 36/50，损失：0.046094246208667755
纪元 37/50，损失：0.03935185819864273
纪元 38/50，损失：0.036376748234033585
纪元 39/50，损失：0.04275327920913696
纪元 40/50，损失：0.04050033539533615
纪元 41/50，损失：0.03928723931312561
纪元 42/50，损失：0.038021307438611984
纪元 43/50，损失：0.039322346448898315
纪元 44/50，损失：0.03544142469763756
纪元 45/50，损失：0.03906610235571861
纪元 46/50，损失：0.03384337201714516
纪元 47/50，损失：0.040965259075164795
纪元 48/50，损失：0.038688428699970245
纪元 49/50，损失：0.041332412511110306
纪元 50/50，损失：0.03592131659388542

在此处输入图片描述
正如您所看到的，损失值总体上持续下降，但在某些点上仍然存在波动。这是我第一次构建 MLP 模型，因此我没有任何可以比较的经验。是正常现象吗？它应该在没有波动的情况下减少，还是波动很小很正常？
这是正常现象吗？应该是在没有波动的情况下减少，还是波动很小很正常？]]></description>
      <guid>https://stackoverflow.com/questions/78458260/the-value-of-loss-is-keeping-fluctuating-questions-about-mlp-model-in-general</guid>
      <pubDate>Fri, 10 May 2024 05:54:58 GMT</pubDate>
    </item>
    <item>
      <title>用最少的层数训练神经网络的绝对函数</title>
      <link>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</link>
      <description><![CDATA[我正在尝试训练神经网络来学习 y = |x|功能。我们知道，绝对函数有两条不同的线在零点处相互连接。所以我尝试使用以下顺序模型：
隐藏层：
2 致密层（激活relu）
输出层：
1 致密层
训练模型后，它只拟合函数的一半边。大多数时候是右手边，有时是左手边。一旦我在隐藏层中再添加 1 层，那么我就用 3 层代替 2 层，它就完全符合该功能了。谁能解释为什么当绝对函数只有一次切割时需要额外的一层？
这是代码：
将 numpy 导入为 np


X = np.linspace(-1000,1000,400)
np.random.shuffle(X)
Y = np.abs(X)

# 重塑数据以适应模型输入
X = X.reshape(-1, 1)
Y = Y.重塑(-1, 1)

将张量流导入为 tf
将张量流导入为 tf
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

# 构建模型
模型 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(2, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(1)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;])
model.fit(X, Y, epochs=1000)
# 使用模型进行预测
Y_pred = model.predict(X)

# 绘制结果
plt.scatter(X, Y, color=&#39;blue&#39;, label=&#39;实际&#39;)
plt.scatter(X, Y_pred, color=&#39;red&#39;, label=&#39;预测&#39;)
plt.title(&#39;实际与预测&#39;)
plt.xlabel(&#39;X&#39;)
plt.ylabel(&#39;Y&#39;)
plt.图例()
plt.show()

2 个密集层的绘图：

3 个密集层的绘图：
]]></description>
      <guid>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</guid>
      <pubDate>Thu, 11 Apr 2024 15:34:01 GMT</pubDate>
    </item>
    <item>
      <title>Pycharm 调试不适用于 Tensorflow。我该如何解决？</title>
      <link>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</link>
      <description><![CDATA[我已成功安装以下内容：
tensorflow（最新版本2.16.1）
keras（最新版本3.1.1

我使用的是pycharm 2023.3.5（社区版）。我有一些导入的代码行，包括张量流：
&lt;前&gt;&lt;代码&gt;...
从tensorflow.keras导入后端为K
...

每当我调试代码时，都会收到如下错误：
回溯（最近一次调用最后一次）：
文件“C:\Program Files\JetBrains\PyCharm Community Edition 2023.3.5\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_xml.py”，第 177 行，在 _get_type 中
if isinstance(o, t[0]):
   ^^^^^^^^^^^^^^^^^^^^
文件“C:\Program Files\Python312\Lib\site-packages\tensorflow\python\platform\flags.py”，第 73 行，在 __getattribute__ 中
返回 self.__dict__[&#39;__wrapped&#39;].__getattribute__(name)
       ~~~~~~~~~~~~~^^^^^^^^^^^^^
关键错误：&#39;__wrapped&#39;

我想相信问题不是由张量流引起的，但我似乎无法弄清楚确切的问题。我已经上网但无济于事。我得到的最接近的解决方案是这个 问题，但是，它似乎我作为一个不同的问题。请这个崇高平台上的博学之士来帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</guid>
      <pubDate>Fri, 29 Mar 2024 03:17:26 GMT</pubDate>
    </item>
    <item>
      <title>作为开发人员如何利用 Apple Silicon/M1 处理器上的神经引擎？</title>
      <link>https://stackoverflow.com/questions/69983492/how-to-leverage-the-neural-engine-on-apple-silicon-m1-processors-as-a-developer</link>
      <description><![CDATA[我正在努力在 SO、Google 或 Apple 的开发者文档中找到这个问题的答案。
Apple 是否为任何语言提供 API，允许开发者在 macOS 上利用新型 M1 芯片的神经引擎？
搜索Apple的开发者文档，可以找到Metal Performance Shaders库中的很多函数，似乎使用了GPU加速。
使用标签搜索SO apple-m1 或 apple-silicon 和关键字“neural”没有提供任何有用的东西。
在 r/AppleDevelopers 中搜索“神经”结果什么也没发现。
我认为必须有一些关于如何使用神经核心进行开发的信息。这些内核仅适用于 Apple 开发者和商业合作伙伴吗？]]></description>
      <guid>https://stackoverflow.com/questions/69983492/how-to-leverage-the-neural-engine-on-apple-silicon-m1-processors-as-a-developer</guid>
      <pubDate>Tue, 16 Nov 2021 03:38:01 GMT</pubDate>
    </item>
    <item>
      <title>混淆矩阵错误：错误：“数据”和“参考”应该是具有相同级别的因素</title>
      <link>https://stackoverflow.com/questions/56995048/confusion-matrix-error-error-data-and-reference-should-be-factors-with-the</link>
      <description><![CDATA[我目前正在尝试构建一个神经网络来预测人们在数据中的排名。 
等级系统为：A、B、C、D、E
一切都运行得非常顺利，直到我到达我的混淆矩阵。我收到错误“错误：data 和 reference 应该是具有相同级别的因素。”。我在其他帖子中尝试了许多不同的方法，但似乎都不起作用。
NNPredictions 和 test$Rank 中的级别相同。我用 table() 检查了它们。
库（readxl）
库（插入符号）
图书馆（神经网络）
库（预测）
图书馆（tidyverse）
库（ggplot2）



间接 &lt;-read_excel(&quot;C:/Users/Abdulazizs/Desktop/Projects/Indirect/FIltered Indirect.xlsx&quot;,
    n_最大 = 500)

间接$Direct_or_Indirect &lt;- NULL


间接$parentaccount &lt;- NULL


sum(is.na(间接))


计数 &lt;- 表（间接$排名）



条形图（计数）

总结（计数）



第 2 部分 &lt;- createDataPartition(Indirect$Rank, ti​​mes = 1, p = .8, list = FALSE, groups = min(5, length(Indirect$Rank)))

火车 &lt;- 间接[part2, ]
测试 &lt;- 间接[-part2, ]

设置.种子(1234)

TrainingParameters &lt;- trainControl(方法 = &quot;repeatedcv&quot;, 数量 = 10, 重复 = 10)

as.data.frame(火车)
as.data.frame(测试)

NNModel &lt;- 训练(训练[,-7], 训练$Rank,
                  方法=“nnet”，
                  trControl= 训练参数，
                  预处理=c(&quot;尺度&quot;,&quot;中心&quot;),
                  na.action = na.omit
）

NNPredictions &lt;-预测（NNModel，测试，类型=“原始”）



摘要（NN预测）





fusionMatrix(NNPredictions, 测试$Rank)

长度（NN预测）
长度（测试$排名）

&lt;块引用&gt;
  长度（NN预测）
  [1] 98
  长度（测试$排名）
  [1]98

表（NNPredictions，测试$Rank，useNA =“ifany”）
NN预测 A B C D E
            1 0 0 0 0
            乙 0 6 0 0 0
            0 0 11 0 0
            d 0 0 0 18 0
            E 0 0 0 0 62]]></description>
      <guid>https://stackoverflow.com/questions/56995048/confusion-matrix-error-error-data-and-reference-should-be-factors-with-the</guid>
      <pubDate>Thu, 11 Jul 2019 18:05:03 GMT</pubDate>
    </item>
    </channel>
</rss>