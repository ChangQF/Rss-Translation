<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 09 Jul 2024 06:22:10 GMT</lastBuildDate>
    <item>
      <title>如何为 qdrant fastembed 模型创建通用 BEIR 稀疏嵌入包装器？</title>
      <link>https://stackoverflow.com/questions/78723939/how-to-create-a-generic-beir-sparse-embed-wrapper-for-qdrant-fastembed-models</link>
      <description><![CDATA[我想对 Qdrant FastEmbed 模型进行基准测试，尤其是稀疏模型。这些模型具有嵌入函数签名：
def embed(
self,
documents: Union[str, Iterable[str]],
batch_size: int = 256,
parallel: Optional[int] = None,
**kwargs,
) -&gt; Iterable[SparseEmbedding]:

SparseEmbedding 只是一个数据类，其值和索引为 numpy 数组。
@dataclass
class SparseEmbedding:
values: np.ndarray
indices: np.ndarray

我查看了 beir 中有关评估自定义模型的文档，但它没有记录任何有关稀疏模型的内容。但是他们提供了一个示例，说明如何使用其库中预先训练的 SPARTA 模型。这是将模型代码包装在工具的 SparseSearch 类中的代码的相关部分。
sparse_model = SparseSearch(models.SPARTA(model_path), batch_size=128)
retriever = EvaluateRetrieval(sparse_model)

results = withdrawer.retrieve(corpus, queries)

SparseSearch 类有一个 search() 方法，该方法调用要进行基准测试的模型的 encode_corpus() 和 encode_query() 方法。
def search(self, 
corpus: Dict[str, Dict[str, str]], 
queries: Dict[str, str], 
top_k：int，
score_function：str，
query_weights：bool = False，
*args，**kwargs）-&gt;； Dict[str, Dict[str, float]]:

doc_ids = list(corpus.keys())
query_ids = list(queries.keys())
documents = [corpus[doc_id] for doc_id in doc_ids]
logs.info(&quot;计算文档嵌入并创建稀疏矩阵&quot;)
self.sparse_matrix = self.model.encode_corpus(documents, batch_size=self.batch_size)

logs.info(&quot;开始检索...&quot;)
for start_idx in trange(0, len(queries), desc=&#39;query&#39;):
qid = query_ids[start_idx]
query_tokens = self.model.encode_query(queries[qid])

if query_weights: 
# 用于 uniCOIL，查询权重被考虑！
scores = self.sparse_matrix.dot(query_tokens)
else: 
# 用于 SPARTA，不考虑查询权重（即二进制）！
scores = np.asarray(self.sparse_matrix[query_tokens, :].sum(axis=0)).squeeze(0)

top_k_ind = np.argpartition(scores, -top_k)[-top_k:]
self.results[qid] = {doc_ids[pid]: float(scores[pid]) for pid in top_k_ind if doc_ids[pid] != qid}

return self.results

我无法直观地理解此搜索操作与 qdrant 模型提供的内容之间的逻辑和关系。这是我为 SparseSearch 类创建包装器的失败尝试，但它在执行过程中冻结了。
import numpy as np
from scipy.sparse import csr_matrix

class FastSparse:
def __init__(self, model_name=None, **kwargs):
self.model = SparseTextEmbedding(
model_name=model_name, cache_dir=&quot;.model_cache&quot;
)

def encode_query(self, query: str, **kwargs):
query_embedding = self.model.query_embed(query)
return csr_matrix(
(
query_embedding.values,
query_embedding.indices,
[0, len(query_embedding.indices)],
)
)

def encode_corpus(self, corpus: List[Dict[str, str]], batch_size: int, **kwargs):

sentence = [(doc[&quot;title&quot;] + &quot; &quot; + doc[&quot;text&quot;]).strip() for doc in corpus]
embeddings = self.model.embed(sentences, batch_size=batch_size)

all_indices = np.array([], dtype=int)
all_values = np.array([], dtype=float)
indptr = [0]
for emb in embeddings:
all_indices = np.concatenate((all_indices, emb.indices))
all_values = np.concatenate((all_values, emb.values))
indptr.append(len(all_indices))

返回 csr_matrix((all_values, all_indices, indptr))
]]></description>
      <guid>https://stackoverflow.com/questions/78723939/how-to-create-a-generic-beir-sparse-embed-wrapper-for-qdrant-fastembed-models</guid>
      <pubDate>Tue, 09 Jul 2024 06:19:01 GMT</pubDate>
    </item>
    <item>
      <title>我无法得到正确的 r 平方</title>
      <link>https://stackoverflow.com/questions/78723283/i-cant-get-the-right-r-squared</link>
      <description><![CDATA[首先，我遇到了一个问题，r 平方值出现奇怪的问题。
如果您能先查看代码，我将不胜感激。
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.3,shuffle = True, random_state=42)

parameters = {
&#39;max_depth&#39;: Integer(3, 30),
&#39;n_estimators&#39;: Integer(100, 1000),
&#39;learning_rate&#39;: Real(0.01, 0.5),
&#39;colsample_bytree&#39;: Real(0.1, 1.0),
&#39;subsample&#39;: Real(0.1, 1.0),
&#39;min_child_weight&#39;: Integer(1, 10),
}

xgb_model = XGBRegressor()

cv = KFold(n_splits=10, shuffle=True, random_state=42)
bayes_search = BayesSearchCV(xgb_model, parameters, cv=cv, n_jobs=-1,scoring=&#39;r2&#39;,verbose=5,random_state=42)
bayes_search.fit(X_train, y_train)

best_params = bayes_search.best_params_
print(&quot;最佳超参数：&quot;, best_params)

# CV R^2 分数
cv_results = bayes_search.cv_results_
cv_mean_score = cv_results[&#39;mean_test_score&#39;][bayes_search.best_index_]
print(&quot;CV R 平方分数：&quot;, cv_mean_score)

# 训练R^2
final_model = XGBRegressor(**best_params)
final_model.fit(X_train, y_train)
y_pred1 = final_model.predict(X_train)
train_r2 = r2_score(y_train, y_pred1)
print(&quot;Train R squared:&quot;, train_r2)

# Test R^2
y_pred = final_model.predict(X_test)
test_r2 = r2_score(y_test, y_pred)
print(&quot;Test R squared:&quot;, test_r2)

当我使用这些代码运行 r squared 时，我得到了以下结果。
CV R squared 分数：0.6303，训练 R squared：0.7647，测试 R squared： 0.6337
问题来了：

我尝试了不同的随机状态，结果训练 r^2 &gt; 测试 r^2 &gt; cv r^2。我的常识告诉我，训练 r^2 和 cv r^2 应该具有相同的值，因为它们使用了相同的参数，并且它们应该始终高于对整个数据集进行 30% 计算的测试 r^2，所以我不知道为什么我会得到这组结果 r^2 &gt; 测试 r^2 &gt; cv r^2。

我尝试了贝叶斯搜索和网格搜索、xgboost 和随机森林以及许多其他方法，但我无法使 r 平方超过 0.8。我应该使用不同模型的集成来增加它吗？我将非常感激任何建议。


如果我误解了某个概念或在代码中犯了错误，请告诉我。
这是一篇很长的文章，非常感谢您的阅读。]]></description>
      <guid>https://stackoverflow.com/questions/78723283/i-cant-get-the-right-r-squared</guid>
      <pubDate>Tue, 09 Jul 2024 00:43:11 GMT</pubDate>
    </item>
    <item>
      <title>关于 CIFAR-10 和迁移学习的问题 [关闭]</title>
      <link>https://stackoverflow.com/questions/78722572/issues-about-cifar-10-and-transfer-learning</link>
      <description><![CDATA[我试了很多次，但那一行不起作用：
history = model.fit(train_generator, epochs=200, steps_per_epoch=167,
callbacks=[modelcheckpoint],
validation_data=validation_generator,validation_steps=50)

我收到错误：
ValueError: `logits` 和 `labels` 必须具有相同的形状，收到 ((None, None, None, 1) vs (None,))。

https://drive.google.com/file/d/1r-TznZVZI9HcPGjfS_i-DfpEJ7mBUw0x/view?usp=sharing
我在 X_train 上做了很多改动，并进行了缩放。但什么也没发生！
我操纵了图像读取，但根本不起作用。我甚至找不到根本原因]]></description>
      <guid>https://stackoverflow.com/questions/78722572/issues-about-cifar-10-and-transfer-learning</guid>
      <pubDate>Mon, 08 Jul 2024 19:22:31 GMT</pubDate>
    </item>
    <item>
      <title>scikit学习交叉验证分数负值</title>
      <link>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</link>
      <description><![CDATA[我试图建立一个线性回归模型来预测房价，以便从机器学习开始，但在使用以下代码中的交叉验证时遇到负分数值：
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
x = df.drop([&#39;MedHouseVal&#39;], axis=1)
y = df[&#39;MedHouseVal&#39;]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
model = LinearRegression()
model.fit(x_train, y_train)
model.score(x_test, y_test)
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=100)
plt.plot(scores)

我注意到，随着 cv 的增加，平均分数下降。因此，我决定绘制它，并意识到分数在某些时候会呈现负值，但真实预测/样本大小怎么会是负数呢？它是用 (TP + TN - FP - FN)/样本大小计算的吗？
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78722250/scikit-learn-cross-validation-score-negative-value</guid>
      <pubDate>Mon, 08 Jul 2024 17:40:02 GMT</pubDate>
    </item>
    <item>
      <title>Jupyter Notebook 中的运行时溢出[关闭]</title>
      <link>https://stackoverflow.com/questions/78721859/runtime-overflow-in-jupyter-notebook</link>
      <description><![CDATA[我在计算梯度下降时遇到了这个问题
RuntimeWarning: 在 add theta1_slope = (-2/n) + sum(y - thetas[1]*x)*x) 时遇到溢出

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78721859/runtime-overflow-in-jupyter-notebook</guid>
      <pubDate>Mon, 08 Jul 2024 15:58:56 GMT</pubDate>
    </item>
    <item>
      <title>如何定义/改变非分类卷积神经网络的准确性？</title>
      <link>https://stackoverflow.com/questions/78721703/how-do-i-define-change-the-accuracy-for-a-non-classification-convolutional-neura</link>
      <description><![CDATA[我正在使用 Keras 制作一个预测模型。它接受两个时间序列并输出一个介于 0 和 1 之间的数字。目前，我的准确度非常低，因为只有当模型得到准确的数字时，它才被认为是“正确的”。例如，正确的数字是 0.34，如果它预测 0.35，则会被视为不正确。我希望能够将范围内的所有数字视为正确的，例如：在真实值的 0.05 以内。另一个选择可能是四舍五入，但我遇到了输出 6 位小数的问题。

我如何将范围内的所有数字视为“正确的”准确率是多少？
我该如何对 CNN 的输出进行四舍五入？

这是我的 CNN 代码：
def networkModel():
model = tf.keras.Sequential([

tf.keras.layers.Conv2D(filters = 16, kernel_size=(2, 2),activation=&#39;relu&#39;,padding=&#39;same&#39;),
tf.keras.layers.Conv2D(filters = 9, kernel_size=(2, 2),activation=&#39;relu&#39;,padding=&#39;same&#39;),
tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
tf.keras.layers.Flatten(),
tf.keras.layers.Dense(256,激活=&#39;relu&#39;),
tf.keras.layers.Dense(1, 激活=&#39;sigmoid&#39;)

])

model.compile(optimizer=&#39;adam&#39;,
loss = tf.keras.losses.BinaryCrossentropy(),
metrics=[&#39;accuracy&#39;])

返回模型
]]></description>
      <guid>https://stackoverflow.com/questions/78721703/how-do-i-define-change-the-accuracy-for-a-non-classification-convolutional-neura</guid>
      <pubDate>Mon, 08 Jul 2024 15:24:04 GMT</pubDate>
    </item>
    <item>
      <title>我的预测张量值太低</title>
      <link>https://stackoverflow.com/questions/78721417/my-tensor-values-in-the-prediction-are-too-low</link>
      <description><![CDATA[我正在训练一个语义分割模型，使用 PyTorch 和 U-net 架构。数据集由视网膜摄影图像组成，带有渗出性疾病的掩码。我遇到了张量值不一致的问题，当我尝试进行新的预测时，我在训练时跟踪了张量，并且在训练期间值是一致的，但在执行新的预测时，值不一致且奇怪，导致掩码毫无意义。
def train_epoch(model, loader, criterion, optimizer, device):
model.train()
epoch_loss = 0

for i, (images, mask) in enumerate(loader):
unique_values = torch.unique(masks)
assert unique_values.numel() == 2, f&quot;Expected mask values to be either 0 or 1, but got {unique_values}&quot;

images = images.to(device)
mask = mask.to(device)

output = model(images)
unique_values_output_train = torch.unique(outputs)
print(f&#39;唯一值输出训练：{unique_values_output_train}&#39;)

output_bin = torch.sigmoid(outputs)
unique_values_output_bin = torch.unique(outputs_bin)
print(f&#39;唯一值输出训练 BIN：{unique_values_output_bin}&#39;)

loss = criterion(outputs, mask)
unique_values_loss_train = torch.unique(loss)
print(f&#39;值损失训练：{unique_values_loss_train}&#39;)

optimizer.zero_grad()
loss.backward()
optimizer.step()

epoch_loss += loss.item()

return epoch_loss / len(loader)


唯一值输出训练：张量（[-1.6558, -1.6541, -1.6541, ..., 0.4275, 0.4280, 0.4322],
device=&#39;cuda:0&#39;, grad_fn=&lt;Unique2Backward0&gt;)
唯一值输出训练 BIN：张量（[0.1474, 0.1475, 0.1475, ..., 0.7301, 0.7314, 0.7320], device=&#39;cuda:0&#39;,
grad_fn=&lt;Unique2Backward0&gt;)

def plot_predictions(dataset, model, device, num_samples=3):
model.eval()
fig, axs = plt.subplots(num_samples, 3, figsize=(15, num_samples * 5))

with torch.no_grad():
for i in range(num_samples):
idx = np.random.randint(0, len(dataset)) 
image, mask = dataset[idx]
image = image.to(device).unsqueeze(0)
mask = mask.to(device)

preds = torch.sigmoid(model(image))
print(f&#39;预测值：{preds}&#39;)

preds = (preds &gt; 0.5).float().cpu().numpy().squeeze(0)
unique_values_sigmoid = np.unique(preds)
print(f&#39;唯一值 sigmoid：{unique_values_sigmoid}&#39;)

image_np = image.cpu().squeeze(0).permute(1, 2, 0).numpy()
if image_np.shape[-1] == 1: 
image_np = image_np.squeeze(-1)

axs[i][0].imshow(image_np, cmap=&#39;gray&#39; if image_np.ndim == 2 else None)
axs[i][0].set_title(f&#39;图像 {idx}&#39;)
axs[i][0].axis(&#39;off&#39;)

mask_np = mask.cpu().numpy()
if mask_np.ndim == 3 和 mask_np.shape[0] == 1: 
mask_np = mask_np.squeeze(0)
elif mask_np.ndim == 3 和 mask_np.shape[-1] == 1:
mask_np = mask_np.squeeze(-1)

axs[i][1].imshow(mask_np, cmap=&#39;gray&#39;)
axs[i][1].set_title(f&#39;Mask {idx}&#39;)
axs[i][1].axis(&#39;off&#39;)

如果 preds.ndim == 3 和 preds.shape[0] == 1:
preds = preds.squeeze(0)

axs[i][2].imshow(preds, cmap=&#39;gray&#39;)
axs[i][2].set_title(f&#39;Prediction {idx}&#39;)
axs[i][2].axis(&#39;off&#39;)

plt.tight_layout()
plt.show()

预测值：张量([[[[0.0970, 0.0935, 0.0969, ..., 0.0962, 0.0990, 0.1000],
[0.0958, 0.0983, 0.1032, ..., 0.1014, 0.1013, 0.1044],
[0.0990, 0.0993, 0.1037, ..., 0.0998, 0.0996, 0.1008],
...,
[0.0981, 0.0985, 0.1002, ..., 0.1003, 0.0990, 0.1010],
[0.0986, 0.0993, 0.0993, ..., 0.1000, 0.0990, 0.1008],
[0.0917, 0.0949, 0.0965, ..., 0.0961, 0.0943, 0.0984]]]],
device=&#39;cuda:0&#39;)
唯一值 sigmoid：[0.]

我做了几次尝试，例如使用另一个损失函数、将 sigmoid 直接应用于 U-net 架构、更改 sigmoid 二值化值、将二值化应用于掩码等。]]></description>
      <guid>https://stackoverflow.com/questions/78721417/my-tensor-values-in-the-prediction-are-too-low</guid>
      <pubDate>Mon, 08 Jul 2024 14:28:47 GMT</pubDate>
    </item>
    <item>
      <title>经过微调的 Mask2Former 模型在训练后仅返回空张量</title>
      <link>https://stackoverflow.com/questions/78721111/fine-tuned-mask2former-model-only-returning-null-tensors-after-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78721111/fine-tuned-mask2former-model-only-returning-null-tensors-after-training</guid>
      <pubDate>Mon, 08 Jul 2024 13:25:50 GMT</pubDate>
    </item>
    <item>
      <title>平衡机器学习和移动应用程序开发[关闭]</title>
      <link>https://stackoverflow.com/questions/78720753/balancing-machine-learning-and-mobile-app-development</link>
      <description><![CDATA[我现在是基督大学计算机应用学士学位 (BCA) 的第二年。在探索了技术领域的各个领域后，我对移动应用开发和机器学习产生了浓厚的兴趣。
我陷入了两难境地，希望社区能就以下问题提供一些指导：
重点决策：同时追求机器学习和移动应用开发的专业知识是否可行且实用？还是专注于一个领域以最大限度地提高熟练程度和职业前景会更有益？
学习路径：如果建议平衡这两个领域，我应该从使用 Android Studio 和 Kotlin 进行原生 Android 开发开始，还是从 Flutter 开始更有益？
过渡到 Flutter：如果我从原生开发开始，过渡到 Flutter 有多顺利？业界是否普遍从原生开发开始，然后转向 Flutter，还是专业人士经常直接从 Flutter 开始？
对 Flutter 的需求：业界目前对 Flutter 开发人员的需求如何？Flutter 专业知识是否有重大的机会和增长前景，尤其是与原生 Android 开发相比？
实习策略：考虑到需要获得实习机会，先专注于一个领域，然后再扩展到另一个领域，这是否有利？如果是这样，您会建议优先考虑哪个领域以获得更好的实习机会和职业发展？
您的见解和建议将非常宝贵，可以帮助我做出明智的决定，决定我的学习路径和职业轨迹。]]></description>
      <guid>https://stackoverflow.com/questions/78720753/balancing-machine-learning-and-mobile-app-development</guid>
      <pubDate>Mon, 08 Jul 2024 12:05:36 GMT</pubDate>
    </item>
    <item>
      <title>如何使用预训练模型改进森林卫星图像中的树木检测和计数？[关闭]</title>
      <link>https://stackoverflow.com/questions/78720461/how-to-improve-tree-detection-and-counting-in-forest-satellite-imagery-using-pre</link>
      <description><![CDATA[我正在开发一个人工智能林业管理系统，使用来自 Google Earth 的卫星图像来监测和分析树木种群。主要目标是准确计数树木并识别濒危或本土物种。我已经实施了一个用于图像分割的 U-Net 模型，但准确性并不令人满意，许多树木被遗漏或错误计数。
我当前的工作流程：

数据采集：从 Google Earth 收集卫星图像。
预处理：规范化和增强图像。
图像分割：使用 U-Net 进行初始树冠分割。
树木计数：应用轮廓检测​​来计数树木。
物种识别：旨在根据分割区域对树种进行分类（尚未实施）。

我面临的问题

准确性：U-Net 模型无法准确检测和计数树木。

我尝试过的方法：

实施 U-Net 进行分割。
尝试使用来自segmentation_models 库的预训练 U-Net 模型，但面临层形状和输入维度错误。

问题：

预训练模型：可用于卫星图像中树木检测的最佳预训练模型有哪些，我如何有效地将它们集成到我的项目中？
在哪里可以找到高质量的数据集用于卫星或航空图像中的树木检测和物种识别？
我可以采取哪些技术或其他预处理步骤来提高树木检测和计数的准确性？

其他信息：

我正在使用 Python 和 TensorFlow、Keras 和 OpenCV 等库。

我探索了各种数据集，但不确定哪些数据集对于训练稳健模型最有效。

]]></description>
      <guid>https://stackoverflow.com/questions/78720461/how-to-improve-tree-detection-and-counting-in-forest-satellite-imagery-using-pre</guid>
      <pubDate>Mon, 08 Jul 2024 11:02:08 GMT</pubDate>
    </item>
    <item>
      <title>术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可运行程序的名称</title>
      <link>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</link>
      <description><![CDATA[在运行此最终命令时，我在本地笔记本电脑上执行自定义数据集上的 yolov3 操作，所有操作均已完成
./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg darknet53.conv.74

当我使用 Windows Power Shell 时，出现错误，即
./darknet：术语“./darknet”未被识别为 cmdlet、函数、脚本文件或可操作程序的名称。请检查名称的拼写，或者如果包含路径，请验证路径是否正确，然后重试。
在第 1 行，字符：1
+ ./darknet detector train DATASET/voc.data cfg/yolov3-voc.cfg darknet5 ...
+ ~~~~~~~~~
+ CategoryInfo : ObjectNotFound: (./darknet:String) [], CommandNotFoundException
+ FullyQualifiedErrorId : CommandNotFoundException

那么我该如何解决此错误
我尝试更改系统环境变量路径，也尝试运行某些命令，但仍然抛出相同的错误，那么我应该尝试什么呢]]></description>
      <guid>https://stackoverflow.com/questions/78719712/the-term-darknet-is-not-recognized-as-the-name-of-a-cmdlet-function-script</guid>
      <pubDate>Mon, 08 Jul 2024 08:00:10 GMT</pubDate>
    </item>
    <item>
      <title>生存分析 - 估计预期寿命</title>
      <link>https://stackoverflow.com/questions/78719590/survival-analysis-estimating-life-expectancy</link>
      <description><![CDATA[我正在探索生存分析，我的目标是找到一个预测预期寿命（以年为单位）的模型，而不是基于几种生活方式变量的风险比。我有很多饮食变量和二元变量——死亡率。
我使用 Kaplan Meyer 并计算间隔内的 AUC（死亡年龄/审查直到队列的最后一个年龄）来估计预期寿命损失年数。但是，我无法用这种方法使用这些变量。
我也看到了 Cox 比例模型中的函数 predict_survival_function，但曲线没有收敛到 0，因此计算 AUC 没有意义。
我遇到了加速失效时间模型，它似乎允许考虑变量并计算生存时间。有人将它用于类似的目的吗？
有人对预期寿命估计有什么建议吗？有人探索过与随机生存森林相关的任何内容吗？]]></description>
      <guid>https://stackoverflow.com/questions/78719590/survival-analysis-estimating-life-expectancy</guid>
      <pubDate>Mon, 08 Jul 2024 07:31:51 GMT</pubDate>
    </item>
    <item>
      <title>使用python在机器学习中将未经训练的对象分类为未知对象</title>
      <link>https://stackoverflow.com/questions/53275530/categorize-a-not-trained-object-as-unknown-object-in-machine-learning-using-pyth</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/53275530/categorize-a-not-trained-object-as-unknown-object-in-machine-learning-using-pyth</guid>
      <pubDate>Tue, 13 Nov 2018 07:02:51 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.decomposition.PCA 的特征向量简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我试图了解主成分分析的工作原理，并在sklearn.datasets.load_iris数据集上对其进行测试。我了解每个步骤的工作原理（例如，标准化数据、协方差、特征分解、按最高特征值排序、使用K个选定维度将原始数据转换为新轴）。
下一步是可视化这些特征向量在数据集上投影的位置（在PC1 vs. PC2 图上，对吗？）。
有人可以解释如何在降维数据集的 3D 图上绘制 [PC1、PC2、PC3] 特征向量吗？
此外，我是否正确绘制了这个 2D 版本？我不确定为什么我的第一个特征向量的长度较短。我应该乘以特征值吗？

以下是我为实现此目标所做的一些研究：
我遵循的 PCA 方法来自：
https://plot.ly/ipython-notebooks/principal-component-analysis/#Shortcut---PCA-in-scikit-learn（虽然我不想使用 plotly。我想坚持使用 pandas、numpy、sklearn、matplotlib、scipy 和 seaborn）
我一直在遵循这个绘制特征向量的教程，它看起来很不错简单：使用 matplotlib 进行 PCA 的基本示例，但我似乎无法用我的数据复制结果。
我发现了这一点，但对于我想做的事情来说，它似乎过于复杂，而且我不想创建一个 FancyArrowPatch：使用 matplotlib 和 np.linalg 绘制协方差矩阵的特征向量

我试图让我的代码尽可能简单，以便遵循其他教程：
导入 numpy 作为 np
导入 pandas 作为 pd
导入 matplotlib.pyplot 作为 plt
从 sklearn.datasets 导入 load_iris
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn 导入 decomposition
导入 seaborn 作为 sns； sns.set_style(&quot;whitegrid&quot;, {&#39;axes.grid&#39; : False})

%matplotlib inline
np.random.seed(0)

# 鸢尾花数据集
DF_data = pd.DataFrame(load_iris().data, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])],
columns = load_iris().feature_names)

Se_targets = pd.Series(load_iris().target, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])], 
name = &quot;Species&quot;)

# 缩放平均值 = 0, var = 1
DF_standard = pd.DataFrame(StandardScaler().fit_transform(DF_data), 
index = DF_data.index,
columns = DF_data.columns)

# Sklearn 用于主成分分析

# 维度
m = DF_standard.shape[1]
K = 2

# PCA（我倾向于如何设置它）
M_PCA = decomposition.PCA(n_components=m)
DF_PCA = pd.DataFrame(M_PCA.fit_transform(DF_standard), 
columns=[&quot;PC%d&quot; % k for k in range(1,m + 1)]).iloc[:,:K]

# 绘制特征向量
#https://stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

# 这就是事情变得奇怪的地方...
data = DF_standard

mu = data.mean(axis=0)
特征向量，特征值 = M_PCA.components_, M_PCA.explained_variance_ #eigenvectors, eigenvalues, V = np.linalg.svd(data.T, full_matrices=False)
projected_data = DF_PCA #np.dot(data, eigenvectors)

sigma = projected_data.std(axis=0).mean()

fig, ax = plt.subplots(figsize=(10,10))
ax.scatter(projected_data[&quot;PC1&quot;], projected_data[&quot;PC2&quot;])
for axis, color in zip(eigenvectors[:K], [&quot;red&quot;,&quot;green&quot;]):
# start, end = mu, mu + sigma * axis ### 导致 &quot;ValueError: 需要解压的值太多（预期为 2）&quot;

# 所以我尝试了这个但我认为它不正确
start, end = (mu)[:K], (mu + sigma * axis)[:K] 
ax.annotate(&#39;&#39;, xy=end,xytext=start, arrowprops=dict(facecolor=color, width=1.0))

ax.set_aspect(&#39;equal&#39;)
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制决策边界？</title>
      <link>https://stackoverflow.com/questions/19054923/how-to-plot-decision-boundary</link>
      <description><![CDATA[如何使用 matplotlib 绘制决策边界，即 [w1,w2] 形式的权重向量，它基本上将两个类（比如 C1 和 C2）分开？
这是否像绘制一条从 (0,0) 到点 (w1,w2) 的线一样简单（因为 W 是权重“向量”）如果是的话，如果需要，我该如何在两个方向上延伸它？
现在我所做的就是：
 import matplotlib.pyplot as plt
plt.plot([0,w1],[0,w2])
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/19054923/how-to-plot-decision-boundary</guid>
      <pubDate>Fri, 27 Sep 2013 15:45:08 GMT</pubDate>
    </item>
    </channel>
</rss>