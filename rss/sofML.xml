<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sun, 23 Feb 2025 01:22:22 GMT</lastBuildDate>
    <item>
      <title>有效的网络验证损失Stagnan不会降低，验证精度会提高，但Stagnan [封闭]</title>
      <link>https://stackoverflow.com/questions/79459417/efficientnetb0-validation-loss-stagnan-not-decreases-validation-accuracy-increa</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79459417/efficientnetb0-validation-loss-stagnan-not-decreases-validation-accuracy-increa</guid>
      <pubDate>Sat, 22 Feb 2025 10:14:34 GMT</pubDate>
    </item>
    <item>
      <title>如何设计AI系统来预测Gherkin用户故事的自动测试？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79458762/how-to-design-an-ai-system-to-predict-automated-tests-from-gherkin-user-stories</link>
      <description><![CDATA[我正在构建一个AI驱动系统，以从用户故事中生成自动测试用例。我对AI没有太多知识，所以我需要一些指导
 这是完整的描述： 
来自AI 驱动的用户故事的自动测试的智能预测
 任务：
•分析用户故事并预测测试用例
•过程并归一化测试数据
•探索和使用不同的机器/深度学习模型
•将开发的AI模型集成到HMI中，以预测所需的自动测试
  Technologies 烧瓶，Django，CI/CD（MLOPS），Gherkin，Python，ML/DL，Crisp-DM方法，NLP 
我期待一些指导，并就该项目提供建议，也许是拟议的阶段]]></description>
      <guid>https://stackoverflow.com/questions/79458762/how-to-design-an-ai-system-to-predict-automated-tests-from-gherkin-user-stories</guid>
      <pubDate>Fri, 21 Feb 2025 22:33:13 GMT</pubDate>
    </item>
    <item>
      <title>使用射线调节器进行超参数调整的序列化误差</title>
      <link>https://stackoverflow.com/questions/79457834/serialization-error-using-ray-tuner-for-hyperparameter-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79457834/serialization-error-using-ray-tuner-for-hyperparameter-tuning</guid>
      <pubDate>Fri, 21 Feb 2025 15:18:38 GMT</pubDate>
    </item>
    <item>
      <title>加载CNN模型后的Numpy急切执行问题</title>
      <link>https://stackoverflow.com/questions/79457437/numpy-eager-execution-problem-after-loading-a-cnn-model</link>
      <description><![CDATA[我想保存和加载CNN模型以进一步培训。我已经开发了一个模型，并将其保存为 .h5 文件。首次运行时创建，培训和节省时没有问题。
加载现有 .h5 模型并尝试训练它时，问题存在。以下代码描述了实现和问题。
  import os.path
导入TensorFlow作为TF

＃启用急切的执行
tf.compat.v1.enable_eager_execution（）

...＃删除以供可读性

def train_model（model_name：str，model_handler：tensormodel，Visualiser：Visualiser，logger：logger，x_train，y_train，y_train，x_test，y_test，y_test，batch_size） - ＆gt;元组：
    logger.info（f＆quort启用启用：{tf.executing_eagerly（）};）

    ＃检查模型是否已经受过培训
    如果use_existing_models and os.path..exists（f＆quot; models/{model_name} .h5＆quort;）：
        模型=模型= tf.keras.models.models.load_model（f＆quot; model/{model_name} .h5＆quort;）
        （x_train，y_train），（x_test，y_test）= model_handler.load_data（）
    别的：
        如果model_name ==＆quot; base_model＆quot;：
            model = model_handler.create_cnn（）
        别的：
            model = model_handler.create_cnn（batch_normalisation = true）

    历史= model.fit（x_train，y_train，epochs = num_epochs，batch_size = batch_size，validation_data =（x_test，y_test））
    test_loss，test_acc = model.evaluate（x_test，y_test）
    model.save（f＆quot; model/{model_name} .h5;）
    
    logger.info（f＆quot“模型精度：{test_acc * 100：.2f}％＆quort”）
    Visualiser.plot_training_history（历史记录，model_name）
    返回（model，model_name），（test_acc）
 
以下是产生的错误。
  file＆quot＆quot＆quot＆quod&gt;&#39;
    历史= model.fit（x_train，y_train，epochs = num_epochs，batch_size = batch_size，validation_data =（x_test，y_test））
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^因为^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^因为^^^
  file＆quot＆quot＆quot＆quot＆quotement/machine_learning/machine-learning-real-time-objectification/.venv/lib/python3.12/site-packages/keras/keras/keras/src/src/src/src/utils/traceback_utils.py，1002222 ，在error_handler中
    从无
  file＆quot＆quot＆quot＆quot＆quotevelovermation/machine_learning/machine-learning-real-time-objectification/.venv/lib/python3.12/site-packages/keras/keras/keras/src/backend/backend/backend/tensorflow/core.core.pycore.py&quot;第155行，convert_to_numpy
    返回NP.Array（X）
           ^^^^^^^^^^^^
notimplementedError：numpy（）仅在启用急切执行时可用。
 
日志记录显示急切执行已启用以下内容：
  2025-02-21 13：46：42,505-信息 - 启用：true：true
 
我缺少什么？]]></description>
      <guid>https://stackoverflow.com/questions/79457437/numpy-eager-execution-problem-after-loading-a-cnn-model</guid>
      <pubDate>Fri, 21 Feb 2025 13:00:54 GMT</pubDate>
    </item>
    <item>
      <title>拟合功能在时期1之后停止</title>
      <link>https://stackoverflow.com/questions/79457237/fit-function-stops-after-epoch-1</link>
      <description><![CDATA[我已经实现了此功能以适合模型
  def fit_model（型号，x_train_sequence_tensor，y_train_sequence_tensor，epochs，val_set，time_windows，sualer）：
    
    x_column_list = [val_set.columns.to_list（）中的项目中的项目，如果不在[&#39;date&#39;，&#39;deres&#39;&#39;&#39;，&#39;rank&#39;，&#39;rank_group&#39;，&#39;counts&#39;，&#39;counts&#39;，&#39;target&#39;]]中
    x_val_set = val_set [x_column_list] .Round（2）
                    
    X_VAL_SET [X_VAL_SET.COLUMNS] = SCALER.TRANSFORM（X_VAL_SET [X_VAL_SET.COLUMNS]）
    x_val_sequence = get_feature_array（x_val_set，x_column_list，time_windows）
    X_VAL_SECONCE_TENSOR = TF.CONVERT_TO_TENSOR（X_VAL_SECERESE，dtype = tf.float32）
    
    y_column_list = [&#39;target&#39;]                
    y_val_set = val_set [y_column_list] .Round（2）
    y_val_sequence = get_feature_array（y_val_set，y_column_list，time_windows）
    y_val_sequence_tensor = tf.convert_to_tensor（y_val_sequence，dtype = tf.float32）

                    
    历史= model.fit（x_train_sequence_tensor，y_train_sequence_tensor，epochs， 
                        验证_data =（x_val_secorence_tensor，y_val_sepence_tensor））
    返回模型，历史记录

 
但是当我称其为时
  fitted_model，history = fit_model（模型，x_train_secorence_tensor，y_train_secorce_tensor， 
                    epochs = 100，val_set = val_set，time_windows = 90，scaleer = scaleer）
 
它在第一个时期后停止。它不能按要求所有100个运行。
我试图在函数调用之外打电话给它。
 `＃步骤3.2：安装模型 +我们通过一些验证
                                                ＃监视验证损失和指标
                                                ＃在每个时代的末尾
                    x_val_set = val_set [x_column_list] .Round（2）
                    
                    ＃x_val_set.values = scaler.transform（x_val_set.values）
                    
                    X_VAL_SET [X_VAL_SET.COLUMNS] = SCALER.TRANSFORM（X_VAL_SET [X_VAL_SET.COLUMNS]）
                    x_val_sequence = get_feature_array（x_val_set，x_column_list，90）
                    X_VAL_SECONCE_TENSOR = TF.CONVERT_TO_TENSOR（X_VAL_SECERESE，dtype = tf.float32）
                    
                    y_val_set = val_set [y_column_list] .Round（2）
                    y_val_sequence = get_feature_array（y_val_set，y_column_list，90）
                    y_val_sequence_tensor = tf.convert_to_tensor（y_val_sequence，dtype = tf.float32）

                    
                    triench_history = cnn1d_bilstm_model.fit（x_train_sequence_tensor，y_train_sequence_tensor，epochs = 200， 
                                                            ＃我们通过一些验证
                                                            ＃监视验证损失和指标
                                                            ＃在每个时代的末尾
                                                            验证_data =（x_val_secorence_tensor，y_val_sepence_tensor））
 
我在做什么错？]]></description>
      <guid>https://stackoverflow.com/questions/79457237/fit-function-stops-after-epoch-1</guid>
      <pubDate>Fri, 21 Feb 2025 11:26:50 GMT</pubDate>
    </item>
    <item>
      <title>我面临的问题是阅读Python中的MT数据[关闭]</title>
      <link>https://stackoverflow.com/questions/79456454/i-am-facing-problem-to-read-mt-data-in-python</link>
      <description><![CDATA[错误是
  parserError                               
Trackback（最近的电话最后一次）
[9]中的单元，第1行
----＆gt; 1 data = pd.read_csv（r＆quot; c：\ users \ rosha \ oneDrive \ desktop \ vbox data \ vbox.csv＆quot;

File ~\anaconda3\Lib\site-packages\pandas\io\parsers\readers.py:912, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace， skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, FoqueChar，引用，双语，EscapeChar，评论，编码，encoding_errors，言语，on_bad_lines，delim_whitespace，low_memory，memory_map，float_map，float_precision，storage_options，storage_options，dtype_backend），dtype_backend）
    899 kwds_defaults = _refine_defaults_read（
    900方言，
    901定界符，
   （...）
    908 dtype_backend = dtype_backend，
    909）
    910 kwds.update（kwds_defaults）
 - ＆gt; 912返回_read（filepath_or_buffer，kwds）

文件〜\ anaconda3 \ lib \ site-packages \ pandas \ io \ parsers \ parsers \ readers.py：583，in _read（filepath_or_buffer，kwds）
    580返回解析器
    582与解析器：
 - ＆gt; 583返回parser.Read（nrows）

file〜 \ anaconda3 \ lib \ site-packages \ pandas \ io \ parsers \ parsers \ readers.py：1704，in textfileReader.read.read（self，nrows）
   1697 nrows = validate_integer（&#39;nrows＆quot; nrows）
   1698尝试：
   1699＃错误：“ parserbase”没有“读”属性。
   1700（
   1701索引，
   1702列，
   1703 col_dict，
 - ＆gt; 1704）= self._engine.Read（＃类型：忽略[attr-defined]
   1705 nrows
   1706）
   1707除例外：
   1708 self.close（）

file〜 \ anaconda3 \ lib \ lib \ site-packages \ pandas \ io \ parsers \ c_parser_wrapper.py：234，在cparserwrapper.read（self，nrows）中
    232尝试：
    233如果self.low_memory：
 - ＆gt; 234块= self._reader.read_low_memory（nrows）
    235＃破坏了大块
    236数据= _concatenate_chunks（块）

文件〜\ anaconda3 \ lib \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：814，in pandas._libs.parsers.parsers.textreader.read_low_memory（）

文件〜\ anaconda3 \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：875，在pandas._libs.parsers.parsers.textreader._read_rows（）

文件〜\ anaconda3 \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：850，在pandas._libs.parsers.parsers.textreader._tokenize_rows（）

文件〜\ anaconda3 \ lib \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：861，in pandas._libs.parsers.parsers.textreader._check_tokenize_tokenize_status（）

file〜 \ anaconda3 \ lib \ site-packages \ pandas \ _libs \ parsers.pyx：2029，in pandas._libs.parsers.raise_parser_parser_error（）

ParserError：错误令牌数据。 C错误：第6行中的预期2个字段，Saw 20
 
如何解决它？]]></description>
      <guid>https://stackoverflow.com/questions/79456454/i-am-facing-problem-to-read-mt-data-in-python</guid>
      <pubDate>Fri, 21 Feb 2025 06:01:03 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow模型训练，列表到Numpy阵列转换不均会改变数据形状</title>
      <link>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</link>
      <description><![CDATA[我正在尝试从MRI图像中预测LSDC。对于每个研究_id，都有多个图像。每个研究_id代表每个患者。我想在5个级别上预测5个条件下的3级严重程度。
我正在尝试使用 sequence 类从TensorFlow创建数据集。这是我的DataGenerator类：
 类CustomDatagenerator（序列）：
    def __init __（self，image_dict，num_img，labels_dict = none，batch_size = 8，image_size =（224，224），shuffle = true）：
       self.image_dict = image_dict
       self.labels_dict = labels_dict
       self.batch_size = batch_size
       self.image_size = image_size
       self.shuffle =洗牌
       self.ids = list（image_dict.keys（））
       self.num_img = num_img
       self.on_epoch_end（）

    def __len __（自我）：
       返回int（np.floor（len（self.ids） / self.batch_size））

    def __getItem __（自我，索引）：
       start = index * self.batch_size
       end = min（（索引 + 1） * self.batch_size，len（self.ids））
       batch_ids = self.ids [start：end]
       batch_images = []
       batch_labels = []

       对于batch_ids中的ID_：
           图像= []

           对于self.image_dict.get（id_，[]）中的image_path：
               dicomdata = pydicom.dcmread（image_path）
               图像= dicomdata.pixel_array
               图像= cv2.resize（图像，self.image_size）
               image = np.expand_dims（图像，axis = -1）
               image = image.astype（&#39;float32&#39;） / np.max（图像）
               图像= np.Repeat（图像，3，轴= -1）
               images.append（图像）

           图像= np.Array（图像）

           如果Len（Images）＆lt; self.num_img：
               pad_amount = self.num_img- len（图像）
               padding = [（0，pad_amount）] + [（0，0）] *（len（images.shape） -  1）
               图像= np.pad（图像，填充，模式=&#39;常数&#39;）

           batch_images.append（图像）

           如果self.labels_dict：
               label = np.array（self.labels_dict.get（id_），dtype = np.float32）
               batch_labels.append（标签）

       batch_images = np.stack（batch_images）
       如果self.labels_dict：
           batch_labels = np.array（batch_labels，dtype = np.float32）
           返回batch_images，batch_labels

       返回batch_images

    def on_epoch_end（self）：
       如果self.shuffle：
           np.random.shuffle（self.ids）
 
我的标签字典如下：
  i，sid在枚举中（train_df [&#39;study_id&#39;]）：
        labels_dict [str（sid）] = []
        对于条件下的骗局：
            如果train_df.loc [i，con] ==&#39;normal_mild&#39;：
                labels_dict [str（sid）]。附加（[1，0，0]）
            elif train_df.loc [i，con] ==&#39;严重&#39;：
                labels_dict [str（sid）]。附加（[0，0，1]）
            别的：
                labels_dict [str（sid）]。附加（[0，1，0]）

       labels_dict [str（sid）] = np.array（labels_dict [str（sid）]，dtype = np.float32）
 
我尝试了多种方法将 labels_dict 转换为numpy数组。但是，要么在训练时显示形状错过错误。或试图查看数据时显示错误。
它显示的错误如下：
  -----＆gt; 1 Model.Fit（train_generator，epochs = 2）＃，step_per_epoch = len（train_generator）// 8）

/USR/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py in Error_handler（*args，** kwargs）
    120＃要获取完整的堆栈跟踪，请致电：
    121＃`keras.config.disable_traceback_filtering（）`
 - ＆gt; 122从无
    123最后：
    124 del filtered_tb

＆lt; ipython-Input-12-Cf42609bddda＆gt;在__getItem __（自我，索引）中
     47 batch_images = np.stack（batch_images）
     48如果self.labels_dict：
---＆gt; 49 batch_labels = np.array（batch_labels，dtype = np.float32）
     50返回batch_images，batch_labels
     51 

ValueError：设置具有序列的数组元素。 1个维度后，请求的阵列具有不均匀的形状。检测到的形状为（8，） +不均匀部分。
 
我尝试使用 np.stack 或 batch_labels = batch_labels.reshape（（（batch_labels.shape.shape.shape [0]），len（presition），3），3））），但它显示不同的错误。我的数据没有任何 nan ，所有 labels_dict 均为Shape （batch_size，num_of_condition，severity_class）。即使我尝试从发电机打印数据。生成器数据形状来自 data_x，data_y = next（iter（train_generator））显示模型输入和输出的数据形状。我无法弄清楚这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</guid>
      <pubDate>Thu, 20 Feb 2025 17:02:54 GMT</pubDate>
    </item>
    <item>
      <title>将Python ML模型与Flutter客户端集成</title>
      <link>https://stackoverflow.com/questions/79452057/integrating-python-ml-models-with-flutter-client-locally</link>
      <description><![CDATA[我在工作中面临挑战，我需要在我的客户端应用程序上运行许多Python ML模型，因为使某些模型在服务器上运行。。
除了项目资产中的张量流光模型和实施Python模型的同事告诉我，他不能以Tflite模型导出某些模型。，我没有实验。
有一个软件包（OnnxRuntime）使用ONNX型号，并在我的flutter代码中使用了其中的功能，例如Dart FFI，我以前使用此软件包在我的颤音代码中运行C ++功能，并且可以很好地运行。我的牛头人说，我有同样的问题，他不能将所有模型提取到ONNX模型中，但这让我认为有一种方法可以在我的Flutter应用程序中使用Python代码，例如Dart FFI，我知道它不会一样，因为Python是一种解释语言，我无法从中脱离共享对象，所以我的问题是：是否有一种方法可以在我的客户端应用程序或Python ML模型中使用Python代码，而无需使用TFLITE或OnnxRuntime？]]></description>
      <guid>https://stackoverflow.com/questions/79452057/integrating-python-ml-models-with-flutter-client-locally</guid>
      <pubDate>Wed, 19 Feb 2025 16:13:44 GMT</pubDate>
    </item>
    <item>
      <title>DeepSeek拥抱面模型加载问题</title>
      <link>https://stackoverflow.com/questions/79424312/deepseek-huggingface-model-loading-issue</link>
      <description><![CDATA[我正在使用huggingface的此代码：
此代码直接从 huggingface网站上的页面 是插件代码：
 来自变形金刚导入管道

消息= [
{&#39;&#39;：＆quot“ user quot”内容“：;
这是给出的
pipe = pipeline（＆quort&#39;text-generation＆quort＆quote =&#39;deepSeek-ai/deepseek-r1＆quort; trust_remote_code = true）
管道（消息）
 
，但我无法加载模型。当我这样做时，我会得到这个问题：
  file＆quot＆lt; ...＆gt;/site-packages/transformers/quantizers/auto.py＆quot;，第97行，在from_dict
提高价值Error（

ValueError：未知量化类型，获得FP8-支持类型为： 
[&#39;awq&#39;，&#39;bitsandbytes_4bit&#39;，&#39;bitsandbytes_8bit&#39;，&#39;gptq&#39;，&#39;aqlm&#39;，&#39;quanto&#39;，&#39;eetq&#39;，&#39;eetq&#39;， 
&#39;HQQ&#39;，“压缩张量”，“ fbgemm_fp8&#39;，&#39;torchao&#39;，&#39;bitnet&#39;]
 
我尝试了不同的代码：
 导入火炬
generate_text = pipeline（model =; deepSeek-ai/deepSeek-r1; torch_dtype = torch.bfloat16，trust_remote_code = true，device_map =; auto;
generate_text（消息）
 
这给出以下错误：
raise ValueError( ValueError: Unknown quantization type, got fp8 - supported types are: [&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39; ，&#39;higgs&#39;，&#39;hqq&#39;，&#39;compressed-tensors&#39;，&#39;fbgemm_fp8&#39;， &#39;torchao&#39;，&#39;bitnet&#39;，&#39;vptq&#39;]  
我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/deepseek-huggingface-model-loading-issue</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>比较通过转移学习训练的几种不同Yolov8S模型的重量和偏见</title>
      <link>https://stackoverflow.com/questions/76220101/comparing-the-weights-and-biases-of-several-different-yolov8s-models-trained-thr</link>
      <description><![CDATA[我有3种不同的Yolov8s模型，我想评估：

  yolov8s接受了普通模型训练。Train（）命令

  yolo8vs模型，训练有冷冻骨干

  yolov8s模型，训练有所有层冰冻


我正在使用回调功能冻结重量，请参见下文：
  def freeze_layer（训练器）：
    型号= Trainer.Model
    num_freeze = 10
    打印（f＆quot {num_freeze}层；）
    冻结= [f&#39;model。{x}。&#39;&#39;对于x范围（num_freeze）]＃冻结层
    对于k，v in Model.Named_pa​​rameters（）：
        v.requires_grad = true＃火车所有层
        如果有（x中的x in for x in freeze）：
            打印（f&#39;Freezing {k}&#39;）
            v.requires_grad = false
    打印（f＆quot {num_freeze}层被冷冻。＆quot;）

如果__name__ ==＆quot __ Main __＆quot;：
    模型= Yolo（Yolov8s.pt）
    model.add_callback（＆quot; on_train_start＆quort＆quot; freeze_layer）
    模型。
        data =&#39;coco128.yaml＆quort;
        时代= 300，
        IMGSZ = 640
        ）
 
我希望能够评估这三个神经网络之间的权重和偏见的差异。我想看看哪些神经元在转移学习后死亡，并评估所有三个神经网络之间的主要差异。是否有任何标准解决方案可用于获得对神经网络的这种见解？
我已经比较了Yolo提供的标准培训指标，例如地图和损失，一切都是预期的。冻结的层越多，表现较差。当我冻结整个网络时，性能比其他两个实例要差得多。
我几乎不知道在比较同一网络架构时从哪里开始，但训练有不同的训练。
任何帮助都非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/76220101/comparing-the-weights-and-biases-of-several-different-yolov8s-models-trained-thr</guid>
      <pubDate>Wed, 10 May 2023 15:13:36 GMT</pubDate>
    </item>
    <item>
      <title>如何标记卫星图像以进行图像分割？</title>
      <link>https://stackoverflow.com/questions/64553426/how-to-label-satellite-images-for-image-segmentation</link>
      <description><![CDATA[我想在卫星图像中检测地雷。最初，我构建了一个模型，每个图像具有多个标签并训练它以对图像进行分类。
但是，我想使用以下提到的图像分割技术： https://towardsdataScience.com/dstl-satellite-imagery-contest-on-kaggle-2f3ef7b8ac40  
我通过AWS S3存储桶下载了所需的图像。我想标记我从频段文件生成的多光谱图像的每个像素。
但是，我在如何标记方面面临困难。
是否有任何开源或其他工具可以执行相同的操作？
图像是12个频段多光谱卫星图像。]]></description>
      <guid>https://stackoverflow.com/questions/64553426/how-to-label-satellite-images-for-image-segmentation</guid>
      <pubDate>Tue, 27 Oct 2020 11:25:11 GMT</pubDate>
    </item>
    <item>
      <title>训练芯片和目标图像格式在TensorFlow中</title>
      <link>https://stackoverflow.com/questions/58306578/training-chip-and-target-image-format-in-tensorflow</link>
      <description><![CDATA[我正在尝试为前哨图像构建土地覆盖分类模型。我正在使用的图像通道（频段）是32位浮点。
我需要了解如何最好地格式化图像数据，包括用于培训的芯片/补丁和用于分类的目标图像。我有几个问题：

我需要将原始图像和训练芯片从32位转换为其他深度吗？
我是否需要确保训练芯片/补丁和目标都具有相同的深度（32位，16位或其他）？
我需要转售我的数据吗？我看到了一些论文，其中数据在0-1或0-255之间重新缩放？
数据深度是否影响学习和预测的表现？
]]></description>
      <guid>https://stackoverflow.com/questions/58306578/training-chip-and-target-image-format-in-tensorflow</guid>
      <pubDate>Wed, 09 Oct 2019 14:35:06 GMT</pubDate>
    </item>
    <item>
      <title>如何在R中绘制SVM模型的ROC曲线</title>
      <link>https://stackoverflow.com/questions/46844891/how-to-plot-a-roc-curve-for-a-svm-model-in-r</link>
      <description><![CDATA[我已经使用以下代码培训并测试了模型
 库（E1071）
库（readxl）
图书馆（Caret）

class1.svm.model＆lt;  -  svm（class〜。，data = class1.trainset，成本= 20，cross = 10，type =“ c-classification”，kernel =“ radial”，na.Action = na.omit）
class1.svm.pred＆lt;  - 预测（class1.svm.model，class1.testset）
finalmatrix＆lt; -data.matrix（class1.svm.pred，rownames.force = f）

test＆lt; -table（pred = class1.svm.pred，true = class1.testset [，c（15768）]）

混淆（测试）
 
但无法为模型绘制ROC曲线。请用正确的语法帮助我绘制ROC曲线以查看我的测试数据的性能。]]></description>
      <guid>https://stackoverflow.com/questions/46844891/how-to-plot-a-roc-curve-for-a-svm-model-in-r</guid>
      <pubDate>Fri, 20 Oct 2017 08:11:29 GMT</pubDate>
    </item>
    <item>
      <title>pytorch中的L1/L2正则化</title>
      <link>https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch</link>
      <description><![CDATA[如何在不手动计算的情况下在Pytorch中添加L1/L2正则化？]]></description>
      <guid>https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch</guid>
      <pubDate>Thu, 09 Mar 2017 19:54:19 GMT</pubDate>
    </item>
    <item>
      <title>r分类树与rpart</title>
      <link>https://stackoverflow.com/questions/31154748/r-classification-tree-with-rpart</link>
      <description><![CDATA[我有一些我想细分的数据。
我的第一个想法是从rpart软件包中的r中的分类树。
我的培训数据包括许多解释变量和一个0-1响应变量，称为“已出售”。响应值“ 1”出现在大约80％的行中。
当我尝试使用 rpart（已出售〜。，triagh_data，method =“ class”）构建树时，r无法创建树。我认为原因是它找不到任何彼此之间有很大差异的段。  经过快速检查数据后，我希望我的树看起来像左节点的售出的85％，右节点将有75％的出售。 
有什么方法可以在此类数据集上创建分类树？]]></description>
      <guid>https://stackoverflow.com/questions/31154748/r-classification-tree-with-rpart</guid>
      <pubDate>Wed, 01 Jul 2015 07:11:40 GMT</pubDate>
    </item>
    </channel>
</rss>