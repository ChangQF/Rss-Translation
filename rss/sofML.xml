<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sun, 23 Mar 2025 03:32:21 GMT</lastBuildDate>
    <item>
      <title>T5雇用员工男高音</title>
      <link>https://stackoverflow.com/questions/79528017/t5-fastai-empty-tensors</link>
      <description><![CDATA[为什么我的张量为空，我正在使用T5令牌，在调试时，一切看起来都不错，但是DLS.Train_ds有16个空张量（我的数据集的80％）？
在
    def __init __（self，tokenizer）：
        self.tokenizer = tokenizer

    def编码（self，x）：
        返回self.tokenizer（
            x，
            padding =; max_length＆quot;
            截断= true，
            max_length = 128，
            return_tensors =＆quot; pt; quot;
        ）.input_ids.squeeze（）


dls = datablock（
    blocks =（（
        TextBlock（TransformerStonizer（Tokenizer）），
        TextBlock（TransformerStonizer（Tokenizer）），
    ），
    get_x = colreader（＆quot; input_text; quot;），
    get_y = colreader（&#39;output_xml＆quort;），
）.dataloaders（DF，BS = 2）

＃dsets.train [0]，dsets.valid [0]
＃dls.show_batch（）

（＃16）[（tensortext（[0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0]），TensorText（[0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0]）），
 ]]></description>
      <guid>https://stackoverflow.com/questions/79528017/t5-fastai-empty-tensors</guid>
      <pubDate>Sat, 22 Mar 2025 19:38:47 GMT</pubDate>
    </item>
    <item>
      <title>涉及GAT和GRU层的高级DNN体系结构培训培训中的虚拟二进制分类器问题[封闭]</title>
      <link>https://stackoverflow.com/questions/79527850/dummy-binary-classifier-issue-in-training-of-advanced-dnn-architecture-involving</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79527850/dummy-binary-classifier-issue-in-training-of-advanced-dnn-architecture-involving</guid>
      <pubDate>Sat, 22 Mar 2025 17:43:17 GMT</pubDate>
    </item>
    <item>
      <title>验证准确性和AUC不会增加。请帮助我了解我出错的地方</title>
      <link>https://stackoverflow.com/questions/79527674/validation-accuracy-and-auc-not-increasing-please-help-me-understand-where-i-we</link>
      <description><![CDATA[我是目前正在从事此项目的学生。这是我的体系结构代码：
 ＃加载预训练的InceptionResnetv2
base_model = inceptionResnetv2（weights =&#39;imagenet&#39;，include_top = false，input_shape =（300，300，3））

＃最初冻结所有层
对于base_model.layers中的图层：
    layer.trainable = false  

＃---添加具有多头注意的自定义分类头---
x = base_model.output
x = globalaveragepooling2d（）（x）
x = batchnormatorization（）（x）
x =辍学（0.3）（x）

＃---实施多头注意机制---
＃重塑以准备关注功能
x_reshaped = reshape（（1，x. shape [-1]））（x）

＃实现多头注意（3个主人）
num_heads = 3
head_outputs = []

对于我的范围（num_heads）：
 ＃每个关注头
    注意=密集（64，activation =&#39;relu&#39;，name = f&#39;attention_proctive_ {i}&#39;）（x_reshape）
    注意=密集（1，activation =&#39;tanh&#39;，name = f&#39;attention_score_ {i}&#39;）（注意）
    注意= Flatten（）（注意）
    注意_weights =激活（&#39;softmax&#39;）（注意）
    activation_weights = repotevector（x. shape [-1]）（activation_weights）
    注意_weights = permute（[2，1]）（注意_weights）
    
    ＃施加注意力
    head_output = pulty（）（[x_reshaped，coadivation_weights]）
    head_output = lambda（lambda x：k.sum（x，axis = 1））（head_output）
    head_outputs.append（head_output）

＃结合注意力头
如果num_heads＆gt; 1：
    context_vector = concatenate（）（head_outputs）
    ＃项目回到原始维度
    context_vector =致密（x. shape [-1]，activation =&#39;relu&#39;）（context_vector）
别的：
    context_vector = head_outputs [0]

＃---跳过连接---
＃添加从Globalaverate Pooling After Globalageerpooling到After Pastion之后的Skip Connection
context_vector = add（）（[context_vector，x]）

＃---带有增强正规化的最终层---
X = Gaussiannoise（0.02）（Context_Vector）
x =密集（256，activation =&#39;relu&#39;，kernel_regularizer = tf.keras.regularizers.l2（0.005））（x）
x = batchnormatorization（）（x）
x =辍学（0.3）（x）
x =密集（128，activation =&#39;relu&#39;，kernel_regularizer = tf.keras.regularizers.l2（0.005））（x）
x = batchnormatorization（）（x）
x =辍学（0.3）（x）

＃---输出层---
输出=密集（1，激活=&#39;Sigmoid&#39;）（x）

＃---创建模型---
model =模型（inputs = base_model.input，outputs =输出）

＃---编译模型---
＃添加梯度剪辑以防止爆炸梯度

优化器= ADAM（Learning_rate = 0.0001，clipnorm = 1.0）
model.compile（优化器=优化器，  
              损失=&#39;binary_crossentropy&#39;，  
              量表= [&#39;准确性&#39;，&#39;auc&#39;，&#39;precision&#39;，&#39;回忆&#39;]）

＃＃打印模型摘要
＃print（model.summary（））

＃---增强回调---
lr_scheduler = reducelronplateau（monitor =&#39;val_loss&#39;，因子= 0.5，耐心= 5，冗长= 1）
早期_STOP =早期踩踏（Monitor =&#39;Val_loss&#39;，Patience = 10，Restore_best_weights = true，verbose = 1）
checkpoint = modelCheckpoint（&#39;best_model.h5&#39;，monitor =&#39;val_auc&#39;，mode =&#39;max&#39;， 
                             save_best_only = true，详细= 1）
callbacks_list = [LR_SCHEDULER，早期_STOP，检查点]

＃---训练模型---
历史= model.fit（
    x_train，y_train， 
    时代= 70，  
    验证_data =（x_test，y_test）， 
    batch_size = 16，  
    详细= 1， 
    回调= callbacks_list
）
 
这是我的模型体系结构
数据集概述：1260个彩色图像（铁路轨道缺陷数据集），标记的数据，清洁数据集具有等量的类别（即50％有缺陷和50％的非缺陷）
图像像素已经已归一化（即在进出数据集之前[0,1]。
我尝试的是：

我尝试了 lr_scheduler 余弦衰减，不工作
数据增强略微降低了性能
调整辍学，学习率和高斯噪声的值，但仍无法正常工作
微调基本模型中的后来层

验证精度在0.91-0.92之间固定，而验证AUC的验证精度并未从0.9624提高。我想知道如何提高其性能]]></description>
      <guid>https://stackoverflow.com/questions/79527674/validation-accuracy-and-auc-not-increasing-please-help-me-understand-where-i-we</guid>
      <pubDate>Sat, 22 Mar 2025 15:39:53 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow模型训练，列表到Numpy阵列转换不均会改变数据形状</title>
      <link>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</link>
      <description><![CDATA[我正在尝试从MRI图像中预测LSDC。对于每个 study_id 都有多个图像。每个 study_id 代表每个患者。我想在5个级别上预测5个条件下的3级严重程度。
我正在尝试使用 sequence 类创建数据集。
这是我的 datagenerator 类：
 类CustomDatagenerator（序列）：
    def __init __（self，image_dict，num_img，labels_dict = none，batch_size = 8，image_size =（224，224），shuffle = true）：
       self.image_dict = image_dict
       self.labels_dict = labels_dict
       self.batch_size = batch_size
       self.image_size = image_size
       self.shuffle =洗牌
       self.ids = list（image_dict.keys（））
       self.num_img = num_img
       self.on_epoch_end（）

    def __len __（自我）：
       返回int（np.floor（len（self.ids） / self.batch_size））

    def __getItem __（自我，索引）：
       start = index * self.batch_size
       end = min（（索引 + 1） * self.batch_size，len（self.ids））
       batch_ids = self.ids [start：end]
       batch_images = []
       batch_labels = []

       对于batch_ids中的ID_：
           图像= []

           对于self.image_dict.get（id_，[]）中的image_path：
               dicomdata = pydicom.dcmread（image_path）
               图像= dicomdata.pixel_array
               图像= cv2.resize（图像，self.image_size）
               image = np.expand_dims（图像，axis = -1）
               image = image.astype（&#39;float32&#39;） / np.max（图像）
               图像= np.Repeat（图像，3，轴= -1）
               images.append（图像）

           图像= np.Array（图像）

           如果Len（Images）＆lt; self.num_img：
               pad_amount = self.num_img- len（图像）
               padding = [（0，pad_amount）] + [（0，0）] *（len（images.shape） -  1）
               图像= np.pad（图像，填充，模式=&#39;常数&#39;）

           batch_images.append（图像）

           如果self.labels_dict：
               label = np.array（self.labels_dict.get（id_），dtype = np.float32）
               batch_labels.append（标签）

       batch_images = np.stack（batch_images）
       如果self.labels_dict：
           batch_labels = np.array（batch_labels，dtype = np.float32）
           返回batch_images，batch_labels

       返回batch_images

    def on_epoch_end（self）：
       如果self.shuffle：
           np.random.shuffle（self.ids）
 
我的标签字典如下：
  i，sid在枚举中（train_df [&#39;study_id&#39;]）：
        labels_dict [str（sid）] = []
        对于条件下的骗局：
            如果train_df.loc [i，con] ==&#39;normal_mild&#39;：
                labels_dict [str（sid）]。附加（[1，0，0]）
            elif train_df.loc [i，con] ==&#39;严重&#39;：
                labels_dict [str（sid）]。附加（[0，0，1]）
            别的：
                labels_dict [str（sid）]。附加（[0，1，0]）

       labels_dict [str（sid）] = np.array（labels_dict [str（sid）]，dtype = np.float32）
 
我尝试了多种方法将 labels_dict 转换为numpy数组。但是要么在训练时显示形状不匹配错误。或试图查看数据时显示错误。
这是它显示的错误：
  -----＆gt; 1 Model.Fit（train_generator，epochs = 2）＃，step_per_epoch = len（train_generator）// 8）

/USR/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py in Error_handler（*args，** kwargs）
    120＃要获取完整的堆栈跟踪，请致电：
    121＃`keras.config.disable_traceback_filtering（）`
 - ＆gt; 122从无
    123最后：
    124 del filtered_tb

＆lt; ipython-Input-12-Cf42609bddda＆gt;在__getItem __（自我，索引）中
     47 batch_images = np.stack（batch_images）
     48如果self.labels_dict：
---＆gt; 49 batch_labels = np.array（batch_labels，dtype = np.float32）
     50返回batch_images，batch_labels
     51 

ValueError：设置具有序列的数组元素。 1个维度后，请求的阵列具有不均匀的形状。检测到的形状为（8，） +不均匀部分。
 
我尝试使用 np.stack 或 batch_labels = batch_labels.reshape（（（batch_labels.shape.shape [0]，len（presente），3），3））），但显示出不同的错误。我的数据没有任何 nan ，所有 labels_dict 均为Shape （batch_size，num_of_condition，severity_class）。即使我尝试从发电机打印数据。生成器数据形状来自 data_x，data_y = next（iter（train_generator））显示模型输入和输出的数据形状。我无法弄清楚这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</guid>
      <pubDate>Thu, 20 Feb 2025 17:02:54 GMT</pubDate>
    </item>
    <item>
      <title>训练数据和标签在掩盖应付填充后没有相同的形状</title>
      <link>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</guid>
      <pubDate>Sun, 10 Nov 2024 19:56:09 GMT</pubDate>
    </item>
    <item>
      <title>Fastai预测协作学习模型</title>
      <link>https://stackoverflow.com/questions/66836846/fastai-predict-on-collaboative-learning-model</link>
      <description><![CDATA[我有一个快速的AI协作过滤模型。我想在此模型上预测一个新的元组。
我在预测功能上遇到麻烦
从他们的文档中，
 签名：Learn.predict（item，rm_type_tfms = none，with_input = false）
DocString：对“项目”的预测，完全解码，损失函数解码和概率
文件：〜/playground/virtualenv/lib/python3.8/site-packages/fastai/learner.py
类型：方法
 
如何定义我需要通过的项目。可以说，对于Movielens数据集，对于已经在数据集中的用户来说，我们想推荐一组电影，我们如何通过用户ID？
我试图在这里遵循一些答案 -    Learn.predict（[NP.Array（[3]）]）
 
我似乎遇到了一个错误：
  typeerror：列表索引必须是整数或切片，而不是列表
 ]]></description>
      <guid>https://stackoverflow.com/questions/66836846/fastai-predict-on-collaboative-learning-model</guid>
      <pubDate>Sat, 27 Mar 2021 22:49:20 GMT</pubDate>
    </item>
    <item>
      <title>分类神经网络不学习[闭幕]</title>
      <link>https://stackoverflow.com/questions/60393573/classification-neural-network-does-not-learn</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/60393573/classification-neural-network-does-not-learn</guid>
      <pubDate>Tue, 25 Feb 2020 11:28:15 GMT</pubDate>
    </item>
    <item>
      <title>分类因变量与自变量的组合之间的关系</title>
      <link>https://stackoverflow.com/questions/53204674/relation-between-a-categorical-dependent-variable-and-combination-of-independent</link>
      <description><![CDATA[我正在寻找一种可以帮助我们找到独立变量（ y〜x1*x1*x2+x2*x2*x3+x3*x4 ）之间的关系，在 X1  x1  to to em x4  x4 中，我们很少有分类列。 
我正在处理分类问题，我想检查独立列的哪些组合与依赖列高度相关。 ]]></description>
      <guid>https://stackoverflow.com/questions/53204674/relation-between-a-categorical-dependent-variable-and-combination-of-independent</guid>
      <pubDate>Thu, 08 Nov 2018 09:18:45 GMT</pubDate>
    </item>
    <item>
      <title>神经网络回归</title>
      <link>https://stackoverflow.com/questions/51938859/neural-network-regression</link>
      <description><![CDATA[对于给定的数据集X，带有两个类{0,1}。如果我分别为每个0和1训练两个单独的神经网络NN0和NN1。 NN0可以从1类中预测数据集中的点，即使在类0？上训练了该点？]]></description>
      <guid>https://stackoverflow.com/questions/51938859/neural-network-regression</guid>
      <pubDate>Mon, 20 Aug 2018 21:40:39 GMT</pubDate>
    </item>
    <item>
      <title>用Pytorch实施自定义数据集</title>
      <link>https://stackoverflow.com/questions/51545026/implementing-a-custom-dataset-with-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/51545026/implementing-a-custom-dataset-with-pytorch</guid>
      <pubDate>Thu, 26 Jul 2018 18:04:14 GMT</pubDate>
    </item>
    <item>
      <title>神经网络Pytorch</title>
      <link>https://stackoverflow.com/questions/51234035/neural-networks-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/51234035/neural-networks-pytorch</guid>
      <pubDate>Sun, 08 Jul 2018 16:35:31 GMT</pubDate>
    </item>
    <item>
      <title>使用keras简单的线性回归</title>
      <link>https://stackoverflow.com/questions/51181393/simple-linear-regression-using-keras</link>
      <description><![CDATA[我一直在尝试使用Keras中的神经网络实现一个简单的线性回归模型，以了解我们如何在Keras库中工作。不幸的是，我最终获得了一个非常糟糕的模型。这是实现：
 来自Pylab Import *
来自keras.models导入顺序
来自keras.layers导入密集

#Generate虚拟数据
data = data = linspace（1,2,100）.RESHAPE（-1,1）
y =数据*5

＃定义模型
def baseline_model（）：
   型号=顺序（）
   model.Add（密集（1，激活=&#39;Linear&#39;，input_dim = 1））
   model.compile（优化器=&#39;rmsprop&#39;，loss =&#39;mean_squared_error&#39;，量表= [&#39;cocucy&#39;]）
   返回模型


＃使用模型
regr = baseline_model（）
regr.fit（数据，y，epochs = 200，batch_size = 32）
绘图（Data，regr.predict（data），&#39;b&#39;，data，y，&#39;k。&#39;）
 
生成的图如下：
  有人可以指出上述模型定义中的缺陷（这可以确保更好地拟合）？]]></description>
      <guid>https://stackoverflow.com/questions/51181393/simple-linear-regression-using-keras</guid>
      <pubDate>Wed, 04 Jul 2018 22:27:31 GMT</pubDate>
    </item>
    <item>
      <title>撤离激活的辍学</title>
      <link>https://stackoverflow.com/questions/45504710/dropout-with-relu-activations</link>
      <description><![CDATA[我正在尝试在TensorFlow中使用辍学的神经网络。
  tf.layers.dropout（输入，费率，培训）
 
来自文档：

辍学包括在培训时间期间每个更新时将输入单元的分数随机设置为0，这有助于防止过度拟合。保留的单元按1 /（1-速率）缩放，以使其总和在训练时间和推理时间保持不变。&lt; / p&gt;

现在，我知道这种行为如果在严格高于零高于零的乙状结激活的顶部应用。如果将一半的输入单元零零，则所有输出的总和也将减半，因此将其比例缩放为2是有意义的，以便在下一层之前恢复某种一致性。
现在，如果一个人使用以零为中心的tanh激活该怎么办？上面的推理不再是正确的，所以将辍学的输出扩展到上述因素是否仍然有效？有没有办法防止张量流液位缩放输出？]]></description>
      <guid>https://stackoverflow.com/questions/45504710/dropout-with-relu-activations</guid>
      <pubDate>Fri, 04 Aug 2017 10:41:25 GMT</pubDate>
    </item>
    <item>
      <title>训练后如何用分布的时间来替换嵌入层？</title>
      <link>https://stackoverflow.com/questions/39532572/how-to-replace-an-embedding-layer-with-a-time-distributed-dense-after-training</link>
      <description><![CDATA[我有以下问题：

 我想使用LSTM网络进行文本分类。为了加快训练的速度并使代码更加清楚，我想沿沿 keras.tokenizer 嵌入层以训练我的模型。 
 一旦我训练了我的模型 - 我想计算输出W.R.T.的显着性图。输入。为此，我决定将嵌入层替换为 timeDistributedDense 。 

您知道什么是最好的方法。对于一个简单的模型，我可以简单地使用已知权重的模型来重建模型 - 但我想使其尽可能通用 - 例如替换模型结构的未来并使我的框架尽可能不可知。]]></description>
      <guid>https://stackoverflow.com/questions/39532572/how-to-replace-an-embedding-layer-with-a-time-distributed-dense-after-training</guid>
      <pubDate>Fri, 16 Sep 2016 13:21:25 GMT</pubDate>
    </item>
    <item>
      <title>使用Python分类信号图像</title>
      <link>https://stackoverflow.com/questions/23053365/classify-signal-images-using-python</link>
      <description><![CDATA[我有以下信号图像，我想根据形状进行分类。哪种算法适合这样做？ I have attached 2-2 images of each class. 





 ]]></description>
      <guid>https://stackoverflow.com/questions/23053365/classify-signal-images-using-python</guid>
      <pubDate>Mon, 14 Apr 2014 06:30:28 GMT</pubDate>
    </item>
    </channel>
</rss>