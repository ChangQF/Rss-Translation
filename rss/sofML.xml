<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 16 Aug 2024 03:20:06 GMT</lastBuildDate>
    <item>
      <title>如何分析和检测 CAN 总线跟踪文件 (.blf) 中的模式以进行 DTC 诊断？</title>
      <link>https://stackoverflow.com/questions/78877182/how-to-analyze-and-detect-patterns-in-can-bus-trace-files-blf-for-dtc-diagnos</link>
      <description><![CDATA[我正在开展一个项目，分析 CAN 总线跟踪文件 (.blf 和 .asc)，以检测与车辆 ECU 中的诊断故障代码 (DTC) 相关的模式。目标是识别故障发生时的常见信号模式，以自动进行故障检测和诊断。我们有 VW MQB 和 MEB UNECE 车辆架构车辆跟踪。我也有这些的 DBC 文件。我们正在使用 UDS 和 OBD 作为基于 CAN 的诊断的一部分。
我真的不知道具体要查看哪些特定信号。任何帮助都将不胜感激。
我正在努力识别信号数据中在故障发生之前或发生时出现的一致模式。我不确定如何有效地提取相关特征或应用聚类/无监督学习技术来检测这些模式。任何关于如何处理这个问题的指导，或类似分析的例子，都将不胜感激。
跟踪文件很大，包含来自多个 ECU 的数据，因此很难隔离相关信号。我正在寻找有关如何预处理数据和有效应用机器学习技术的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78877182/how-to-analyze-and-detect-patterns-in-can-bus-trace-files-blf-for-dtc-diagnos</guid>
      <pubDate>Thu, 15 Aug 2024 23:40:15 GMT</pubDate>
    </item>
    <item>
      <title>使用只有一个数据点的数据集来训练神经网络无法完美预测 y 变量？</title>
      <link>https://stackoverflow.com/questions/78876176/using-a-dataset-of-only-one-data-point-to-train-neural-network-cannot-perfectly</link>
      <description><![CDATA[我的样本X_trn和y_trn都只有一个item，我搭建了一个神经网络进行分类，训练模型然后用X_trn进行预测，X_trn的预测结果和y_trn的预测结果不一样。这是否意味着我的神经网络有问题？
#=========================x_trn&amp;y_trn=========================#
print(X_trn)
mom12m
0 -0.334957

print(y_trn)
0 4.0
名称：ret_exc_lead1m_w，dtype：float64

#==========================model=============================#
mod = Sequential()
mod.add(Input(shape = (X_trn.shape[1],)))
mod.add(Dense(1, 激活 = &#39;relu&#39;)) 
mod.add(Dense(1))
opt = Adam(learning_rate=0.1)
mod.compile(loss=&#39;binary_crossentropy&#39;, optimizer=opt, metrics=[&#39;accuracy&#39;])
history = mod.fit(X_trn, y_trn, epochs=5, batch_size=1)

# 预测
y_pred.append(mod.predict(X_trn)[0])

print(y_pred)

[array([1.5509232], dtype=float32), 
array([1.6640353], dtype=float32), 
array([0.], dtype=float32), 
array([0.], dtype=float32)]

我期望模型预测 X_trn 应该得到接近 y_trn 的值。但它完全不同？我哪里可能错了？
即使我将损失函数更改为“mse”，预测值也在 0.5~1.6 左右，每次值都会发生变化并且与 y_trn 不同。]]></description>
      <guid>https://stackoverflow.com/questions/78876176/using-a-dataset-of-only-one-data-point-to-train-neural-network-cannot-perfectly</guid>
      <pubDate>Thu, 15 Aug 2024 17:16:50 GMT</pubDate>
    </item>
    <item>
      <title>TimeSeriesDataSet/TemporalFusionTransformer - 发现类“NoneType”错误，我认为它在“target_scale”数组中</title>
      <link>https://stackoverflow.com/questions/78876125/timeseriesdataset-temporalfusiontransformer-found-class-nonetype-error-i-th</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78876125/timeseriesdataset-temporalfusiontransformer-found-class-nonetype-error-i-th</guid>
      <pubDate>Thu, 15 Aug 2024 16:58:04 GMT</pubDate>
    </item>
    <item>
      <title>如何使用线图作为机器学习特征？[关闭]</title>
      <link>https://stackoverflow.com/questions/78875992/how-to-use-line-plots-as-machine-learning-features</link>
      <description><![CDATA[在机器学习模型中，是否可以输入整个图表作为特征之一？为了便于理解，我希望创建一个机器学习模型，根据变星的光变曲线（光度与时间）对变星类型进行分类。我已经根据它们的 x 和 y（光度和时间）值提取了许多这样的光变曲线，作为坐标对 (x, y) (x, y)。但是要创建一个对线图进行分类的机器学习模型，我应该使用什么？我应该输入多个数据框，每个数据框都包含 x 和 y 值吗？我应该对图表进行傅里叶变换并输入其每个基频吗？还是我应该输入平均值、中位数、众数和范围等值？]]></description>
      <guid>https://stackoverflow.com/questions/78875992/how-to-use-line-plots-as-machine-learning-features</guid>
      <pubDate>Thu, 15 Aug 2024 16:18:35 GMT</pubDate>
    </item>
    <item>
      <title>在 JAX 中跨多个设备恢复优化器状态</title>
      <link>https://stackoverflow.com/questions/78875908/restoring-an-optimizer-state-across-multiple-devices-in-jax</link>
      <description><![CDATA[我正在四个 GPU 上使用 jax 和 optax 训练模型，需要保存和恢复优化器状态，​​但在加载时遇到了问题。优化器状态已初始化 --
optimizer = optax.adamw(0.0001)
class Runner():
self.opt_state = optimizer.init(self.params) # 初始化优化器
self.opt_state = jax.device_put_replicated(self.opt_state, devices) # 将 opt_state 复制到所有设备

然后仅在第一个设备上保存 --
def save(self, save_dir):
params_path = save_dir + &#39;/{}_params.pickle&#39;.format(self.train_step)
opt_state_path = save_dir + &#39;/{}_opt_state.pickle&#39;.format(self.train_step)

with open(params_path, &#39;wb&#39;) as file:
pickle.dump(jax.device_get(jax.tree_map(lambda x: x[0], self.params)), file)
with open(opt_state_path, &#39;wb&#39;) as file:
pickle.dump(jax.device_get(jax.tree_map(lambda x: x[0], self.opt_state)), file)

logs.info(&#39;saved to {}, step {}&#39;.format(save_dir, self.train_step))

稍后，加载参数和优化器状态
def restore(self, save_dir, step, restore_opt_state = True):
opt_state_path = save_dir + &#39;/{}_opt_state.pickle&#39;.format(step)
if restore_opt_state: # True
with open(opt_state_path, &#39;rb&#39;) as file:
opt_state = pickle.load(file)
replicate_opt_state = jax.device_put_replicated(opt_state, self.devices) # 将 opt_state 复制到所有设备
self.opt_state = update_dict(self.opt_state, replicate_opt_state)
logging.info(&#39;restored opt state from {}, step {}&#39;.format(save_dir, step))

其中 update_dict() 定义如下：
def update_dict(params1, params2):
assert type(params1) == type(params2)
if type(params1) == dict:
params1.update(params2)
elif type(params1) == FrozenDict:
p = dict(params1[&#39;params&#39;])
p.update(params2[&#39;params&#39;])
params1 = {&#39;params&#39;: FrozenDict(p)}
else:
raise ValueError(&#39;params1 type {} not implement&#39;.format(type(params1)))
return params1

当我在正确的 save_dir 和 step 上运行 restore 方法时，update_dict() 将其解释为元组，无法恢复优化器状态 (ValueError: params1 type &lt;class &#39;tuple&#39;&gt; not implement)。但我不确定这是为什么，因为 save() 明确只保存第一台设备上的优化器状态。此外，当从单个设备加载参数并在多个设备上复制它们时，此相同设置似乎有效。
我期望与 params 类似的性能，它会作为字典保存和加载。我尝试过将另一个 jax.tree_map(lambda x: x[0] opt_state) 明确添加到 restore_opt_state 上下文管理器，但没有成功。看起来 opt_state 被保存为元组，而不是字典，而 params 则被保存为字典。将元组中的一个元素通过 update_dict() 传递就足够了吗？]]></description>
      <guid>https://stackoverflow.com/questions/78875908/restoring-an-optimizer-state-across-multiple-devices-in-jax</guid>
      <pubDate>Thu, 15 Aug 2024 15:55:30 GMT</pubDate>
    </item>
    <item>
      <title>在 kmeans 每次迭代中显示质心和图像</title>
      <link>https://stackoverflow.com/questions/78875750/displaying-the-centroid-and-the-image-at-each-iteration-of-kmeans</link>
      <description><![CDATA[我已经使用 k-means 无监督学习算法实现了图像压缩，但我想在压缩过程的每次迭代中看到质心和图像，但我不知道该怎么做？
我还想知道这些图像是否可以用来形成动画，显示质心和图像从其初始状态变为其最终状态。]]></description>
      <guid>https://stackoverflow.com/questions/78875750/displaying-the-centroid-and-the-image-at-each-iteration-of-kmeans</guid>
      <pubDate>Thu, 15 Aug 2024 15:15:05 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习预训练模型</title>
      <link>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</link>
      <description><![CDATA[我在 Google Colab 上拟合迁移学习模型。但是，我在代码中遇到了一条警告消息
Epoch 1/30
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: 
UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。
请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()

在第一个 epoch 之后，我收到以下错误：
----------------------------------------------------------------------------------------
KeyboardInterrupt Traceback（最近一次调用最后一次）
&lt;ipython-input-23-962a870d4412&gt; in &lt;cell line: 16&gt;()
14 # 拟合模型
15 # 运行单元。执行需要一些时间
---&gt; 16 training_history = model_efficientnet.fit(
17 training_set,
18 validation_data=validate_set,

我已经成功地拟合了其他六个迁移学习模型，没有任何问题，它们的准确率令人满意。
如何解决这个问题？
我想获得训练准确率和验证准确率]]></description>
      <guid>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</guid>
      <pubDate>Thu, 15 Aug 2024 14:49:45 GMT</pubDate>
    </item>
    <item>
      <title>我对神经网络回归模型结果的解释</title>
      <link>https://stackoverflow.com/questions/78874398/interpretation-of-my-result-of-the-neural-network-regression-model</link>
      <description><![CDATA[我自定义的网络使用线性层，中间有 dropout 层。我知道在评估阶段，dropout 层不活跃，这通常会导致验证损失高于训练损失。为了更好地理解损失值，我计算了训练损失和验证损失之间的平均绝对差。是否有针对这种差异的一般规则或指导方针可用于改进我的模型？
我也使用此设置进行训练
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=lr)
scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=&#39;min&#39;)

计算绝对差异（距离）：
fold_dist_rmse = np.mean(np.abs(np.subtract(fold_train_losses, fold_val_losses)))
fold_dist_r2 = np.mean(np.abs(np.subtract(fold_train_r2, fold_val_r2)))

这是我的结果模型：
折叠 1/6：训练 RMSE：35.93554242793712 | 有效 RMSE：29.25876541711503 | 距离：6.769316131166423
折叠 1/6：训练 $R^2$：0.9707746378183365 | 有效 $R^2$：0.9887450106143951 | 距离：0.01803360450267792

折叠 2/6：训练 RMSE：33.979019073410804 | 有效 RMSE：37.212038090521546 |距离：6.741708392705943
折叠 2/6：训练 $R^2$：0.9723036136627198 | 有效 $R^2$：0.9756944441795349 | 距离：0.01469032382965088

折叠 3/6：训练 RMSE：32.49953081599383 | 有效 RMSE：42.565526526587355 | 距离：12.88033462681533
折叠 3/6：训练 $R^2$：0.9757700593471527 |有效 $R^2$：0.9610446383953094 | 距离：0.03205667233467102

折叠 4/6：训练 RMSE：32.936544826006646 | 有效 RMSE：55.71217012745017 | 距离：25.01426354134579
折叠 4/6：训练 $R^2$：0.9724288802146912 | 有效 $R^2$：0.9643870314359665 |距离：0.024146793484687804

我正在寻找某人来解释训练和验证损失之间的平均绝对差异是否是分析我的模型的良好指标。此外，我非常感谢任何关于如何改进我的模型以实现 RMSE 低于 10 的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78874398/interpretation-of-my-result-of-the-neural-network-regression-model</guid>
      <pubDate>Thu, 15 Aug 2024 09:12:26 GMT</pubDate>
    </item>
    <item>
      <title>对列应用对数变换</title>
      <link>https://stackoverflow.com/questions/78873685/applying-log-transformation-to-a-column</link>
      <description><![CDATA[
我已使用 OneHotEncoder 对性别列进行编码。我想仅对 Female[0] 列应用对数转换，但它却对所有列都应用了对数转换 — 为什么？
我的代码：
import pandas as p
from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
from sklearn.compose import ColumnTransformer
import numpy as n

customer=p.read_csv(&#39;/content/Customers.csv&#39;)
customer.drop([&#39;CustomerID&#39;,&#39;Profession&#39;,&#39;Family Size&#39;,&#39;Work Experience&#39;],axis=1,inplace=True)
column=ColumnTransformer(
[
(&#39;ohe_gender&#39;,OneHotEncoder(sparse=False,dtype=n.int32),[0])
],remainder=&#39;passthrough&#39;
)
function=ColumnTransformer(
[
(&#39;function&#39;,FunctionTransformer(n.log1p),[0,1])
],remainder=&#39;passthrough&#39;
)
s=column.fit_transform(customer)
function.fit_transform(s)

输出：
 array([[0.00000000e+00, 6.93147181e-01, 1.90000000e+01, 1.50000000e+04, 3.90000000e+01],
[0.00000000e+00, 6.93147181e-01, 2.10000000e+01, 3.50000000e+04, 8.10000000e+01],
[6.93147181e-01, 0.00000000e+00, 2.00000000e+01, 8.60000000e+04, 6.00000000e+00],
...,
[0.00000000e+00, 6.93147181e-01, 8.70000000e+01, 9.09610000e+04, 1.40000000e+01],
[0.00000000e+00, 6.93147181e-01, 7.70000000e+01, 1.82109000e+05, 4.00000000e+00],
[0.00000000e+00, 6.93147181e-01, 9.00000000e+01, 1.10610000e+05, 5.20000000e+01]]

在 FunctionTransformer 之前进行编码 (OHE) 后，输出为
array([[ 0, 1, 19, 15000, 39],
[ 0, 1, 21, 35000, 81],
[ 1, 0, 20, 86000, 6],
...,
[ 0, 1, 87, 90961, 14],
[ 0, 1, 77, 182109, 4],
[ 0, 1, 90, 110610, 52]])

我确实想在上述数组的第 0 个索引中应用对数变换，但正如您在第一个输出中看到的那样，它应用于所有值，尽管我在列变换器中指定了 [0]，为什么？我希望输出只有 [0] 索引的对数。]]></description>
      <guid>https://stackoverflow.com/questions/78873685/applying-log-transformation-to-a-column</guid>
      <pubDate>Thu, 15 Aug 2024 04:58:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在不使用 for 循环的情况下直接从 Claude API 对多个完成（n）进行采样？</title>
      <link>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</link>
      <description><![CDATA[我正在使用 Anthropic Claude API，并尝试在单个 API 调用中为给定的提示生成多个完成（n 个完成）。 OpenAI 的 API 在其采样设置中提供了一个 n 参数来实现这一点，但我在 Claude API 中找不到等效选项。
我目前的方法：
我目前正在使用重试机制来处理 API 调用期间的潜在错误，如下所示：
from tenacity import retry, stop_after_attempt, wait_exponential

def before_sleep(retry_state):
print(f&quot;(Tenacity) Retry, error that cause it: {retry_state.outcome.exception()}&quot;)

def retry_error_callback(retry_state):
exception = retry_state.outcome.exception()
exception_str = str(exception)
if &quot;prompt is too long&quot; in exception_str and &quot;400&quot;在 exception_str 中：
引发异常
返回“没有需要我们提前退出的错误。”

@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator, prompt: str) -&gt;; dict:
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n, # 旨在生成多个完成
stop_sequences=gen.sampling_params.stop[:3],
)
return response

问题：
我在 Anthropic API 中找不到 n 参数允许在一次请求中生成多个完成的文档。
问题：

Claude API 是否支持在一次 API 调用中直接生成多个完成（n 个完成）？
如果没有，是否有推荐的解决方法或最佳实践来实现这一点，而无需循环多个请求？

跨 discord：https://discord.com/channels/1072196207201501266/1213976011998498816/threads/1273440866861846549
交叉：https://dev.to/brando90/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-loop-2m1e

现在这样做：
@retry(stop=stop_after_attempt(20), wait=wait_exponential(multiplier=2, max=256), 
before_sleep=before_sleep, retry_error_callback=retry_error_callback)
def call_to_anthropic_client_api_with_retry(gen: AnthropicGenerator, prompt: str) -&gt; dict:
# max_tokens=8192, # Claude 3.5 的 max_tokens https://docs.anthropic.com/en/docs/about-claude/models#model-comparison
# client = anthropic.Anthropic(api_key=gen.api_key)
# response = client.messages.create(
# response_text: str = gen.llm.messages.create(
# model=gen.sampling_params.model,
# max_tokens=gen.sampling_params.max_tokens,
# #temperature=temperature, # 注意提示生成器不会将其作为输入
# system=gen.sampling_params.system,
# messages=[
# {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
# ],
#temperature=gen.sampling_params.temperature,
#top_p=gen.sampling_params.top_p,
#n=gen.sampling_params.n,
#stop=gen.sampling_params.stop[:3],
# ).content[0].text
if not hasattr(gen.sampling_params, &#39;n&#39;):
gen.sampling_params.n = 1
content: list[dict] = [] 
for _ in range(gen.sampling_params.n):
response = gen.llm.messages.create(
model=gen.model,
max_tokens=gen.sampling_params.max_tokens,
system=gen.system_prompt,
messages=[
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt}]}
],
temperature=gen.sampling_params.temperature,
top_p=gen.sampling_params.top_p,
n=gen.sampling_params.n,
stop_sequences=gen.sampling_params.stop[:3],
)
content.append(response)
response = dict(content=content)
# 消息示例：https://docs.anthropic.com/en/api/messages-examples
返回响应
]]></description>
      <guid>https://stackoverflow.com/questions/78873304/how-to-sample-multiple-completions-n-directly-from-claude-api-without-a-for-lo</guid>
      <pubDate>Thu, 15 Aug 2024 00:37:53 GMT</pubDate>
    </item>
    <item>
      <title>层“顺序”需要 1 个输入，但它收到了 48 个输入张量</title>
      <link>https://stackoverflow.com/questions/78872766/layer-sequential-expects-1-inputs-but-it-received-48-input-tensors</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78872766/layer-sequential-expects-1-inputs-but-it-received-48-input-tensors</guid>
      <pubDate>Wed, 14 Aug 2024 20:06:08 GMT</pubDate>
    </item>
    <item>
      <title>语法错误：无效的不可打印字符 U+00A0</title>
      <link>https://stackoverflow.com/questions/78872236/syntaxerror-invalid-non-printable-character-u00a0</link>
      <description><![CDATA[我想建立一个基本的逻辑回归模型，但当我尝试将数据输入模型时，出现了不可打印字符错误
model.fit(X_train, y_train
SyntaxError: 无效的不可打印字符 U+00A0

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78872236/syntaxerror-invalid-non-printable-character-u00a0</guid>
      <pubDate>Wed, 14 Aug 2024 17:20:55 GMT</pubDate>
    </item>
    <item>
      <title>Android 中的 Movenet Singlepose 照明模型：“不支持的图像格式：1”错误</title>
      <link>https://stackoverflow.com/questions/78636622/movenets-singlepose-lighting-model-in-android-unsupported-image-format-1-e</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78636622/movenets-singlepose-lighting-model-in-android-unsupported-image-format-1-e</guid>
      <pubDate>Tue, 18 Jun 2024 09:42:32 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow：你的输入数据不足</title>
      <link>https://stackoverflow.com/questions/59864408/tensorflowyour-input-ran-out-of-data</link>
      <description><![CDATA[我正在研究 seq2seq keras/tensorflow 2.0 模型。每次用户输入某些内容时，我的模型都会完美地打印响应。但是在每个响应的最后一行我都会得到这个：

您：警告：tensorflow：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 steps_per_epoch * epochs 个批次（在本例中为 2 个批次）。您可能需要在构建数据集时使用 repeat() 函数。

“您：”是我的最后一个输出，在用户应该输入新内容之前。该模型运行良好，但我想没有错误永远是好事，但我不太明白这个错误。它说“中断训练”，但我没有训练任何东西，这个程序加载了一个已经训练过的模型。我猜这就是为什么错误没有停止程序的原因？
如果有帮助的话，我的模型如下所示：
intent_model = keras.Sequential([
keras.layers.Dense(8, input_shape=[len(train_x[0])]), # 输入层
keras.layers.Dense(8), # 隐藏层
keras.layers.Dense(len(train_y[0]),activation=&quot;softmax&quot;), # 输出层
])

intent_model.compile(optimizer=&quot;adam&quot;, loss=&quot;categorical_crossentropy&quot;, metrics=[&quot;accuracy&quot;])
intent_model.fit(train_x, train_y, epochs=epochs)

test_loss, test_acc = intent_model.evaluate(train_x, train_y)
print(&quot;测试的 Acc:&quot;, test_acc)

intent_model.save(&quot;models/intent_model.h5&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/59864408/tensorflowyour-input-ran-out-of-data</guid>
      <pubDate>Wed, 22 Jan 2020 16:40:42 GMT</pubDate>
    </item>
    <item>
      <title>如何使 RandomForestClassifier 更快？</title>
      <link>https://stackoverflow.com/questions/43640546/how-to-make-randomforestclassifier-faster</link>
      <description><![CDATA[我正在尝试使用大约有 1M 原始数据的 Twitter 情绪数据从 kaggle 网站实现词袋模型。我已经清理了它，但在最后一部分，当我将特征向量和情绪应用于随机森林分类器时，它花费了太多时间。这是我的代码...
from sklearn.ensemble import RandomForestClassifier
forest = RandomForestClassifier(n_estimators = 100,verbose=3)
forest = forest.fit( train_data_features, train[&quot;Sentiment&quot;] )

train_data_features 是 1048575x5000 稀疏矩阵。我试图将其转换为数组，但执行时显示内存错误。
我哪里做错了？有人可以建议我一些来源或其他更快的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/43640546/how-to-make-randomforestclassifier-faster</guid>
      <pubDate>Wed, 26 Apr 2017 17:09:55 GMT</pubDate>
    </item>
    </channel>
</rss>