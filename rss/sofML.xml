<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 10 Jul 2024 21:14:23 GMT</lastBuildDate>
    <item>
      <title>为什么 Python 中的 GradientBoostedClassifer() 有 random_state 参数？</title>
      <link>https://stackoverflow.com/questions/78732191/why-does-gradientboostedclassifer-in-python-have-random-state-argument</link>
      <description><![CDATA[在 Python 中运行梯度提升分类器：
clf = GradientBoostingClassifier(n_estimators = 100, max_depth = 8, random_state=1000)
我不明白为什么会有 random_state 参数。我想我明白为什么在随机森林集合中需要它，但是其中的“梯度”部分不是消除了算法中的随机性吗？GDB 算法中的随机性是什么？
我有 528 个数据点，其中有 2 个数值特征和 2 个序数分类特征。算法的每次迭代都从随机选择的 80% 数据的 6 倍交叉验证中进行训练，然后对剩余的 20% 数据进行模型测试。虽然更改 random_state 不会改变我的整体模型准确性，但有时会极大地改变我的特征重要性……可以通过在模型训练的多次迭代中平均特征重要性来解决这个问题，无论随机状态如何都会产生一致的结果，但这对我来说仍然没有意义。我仍然不确定算法本身中的随机性是什么。]]></description>
      <guid>https://stackoverflow.com/questions/78732191/why-does-gradientboostedclassifer-in-python-have-random-state-argument</guid>
      <pubDate>Wed, 10 Jul 2024 18:17:57 GMT</pubDate>
    </item>
    <item>
      <title>使用包含数组的特征训练随机森林模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78732000/training-random-forest-model-with-features-containing-arrays</link>
      <description><![CDATA[我正在处理一个包含时域 IQ 数据的数据集。我已将 FFT 应用于 IQ 数据，将其转换为频域，并进一步从中提取功率、幅度和相位角。这些特征中的每一行都包含一个由 1024 个数据点组成的数组。我正在尝试在此数据上训练随机森林分类器模型，但在拟合过程中遇到错误：
错误图像（抱歉图像模糊）：

所有特征都具有相同的形状和大小。
我尝试连接行、展平、转换为列表，但似乎没有任何效果。所以我决定使用这些特征的统计数字来训练模型。有没有办法直接传递 FFT 后获得的特征？这对模型来说会不会太复杂了？]]></description>
      <guid>https://stackoverflow.com/questions/78732000/training-random-forest-model-with-features-containing-arrays</guid>
      <pubDate>Wed, 10 Jul 2024 17:29:51 GMT</pubDate>
    </item>
    <item>
      <title>实时物体检测/跟踪的最佳模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78731761/best-model-for-object-detection-tracking-in-real-time</link>
      <description><![CDATA[我的目标是创建一个可以跟踪和计数物体以及检测物体的模型。
我看过关于 YOLO 版本 7、8 等的研究。
另一方面，我应该买什么样的显卡？
我考虑过 Jetson Nano。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78731761/best-model-for-object-detection-tracking-in-real-time</guid>
      <pubDate>Wed, 10 Jul 2024 16:32:14 GMT</pubDate>
    </item>
    <item>
      <title>BART 配备所有虚拟功能</title>
      <link>https://stackoverflow.com/questions/78731704/bart-with-all-dummy-features</link>
      <description><![CDATA[我正尝试将 BART 应用于分类问题，其中预测变量是虚拟变量以及 y 变量。我知道这是一种不常见的设置，但不幸的是这就是设置。实际上，0 和 1 值是从 -4 到 4 的分类变量中获得的，将负值设置为 0，将正值添加到 1。我还有数据的分类版本，以防它有用。
现在，我的预测变量包含大量 NA 值（即 70%），由 648x48 的 0-1 虚拟变量矩阵组成。我的 y 变量不包含缺失值，有 648 个值。
我目前正在使用 RStudio 在 R 中工作。然而，当我执行下面的代码时，结果却令人失望：
bart_machine = build_bart_machine(predictors, response_var,use_missing_data = TRUE, use_missing_data_dummies_as_covars = TRUE)
bart_machine$confusion_matrix

也就是说，我获得了一个 NULL 混淆矩阵，并且
bartMachine v1.3.4.1 用于回归

缺失数据功能开启
训练数据大小：n = 638 和 p = 96
在 8 个核心、50 棵树、250 个 burn-in 和 1000 个 post 上构建，耗时 5.8 秒。样本

事先对 y 的 sigsq 估计：0.016

老化后的平均 sigsq 估计：0.00314

样本内统计数据：
L1 = 9.91
L2 = 1.01
rmse = 0.04
Pseudo-Rsq = 0.9547
残差的 shapiro-wilk 正态性检验的 p-val：0

零均值噪声的 p-val：0.99451

现在我的问题是：

您是否认为我有太多 NA 值而无法执行 BART？

您认为我的设置至少应该产生一个混淆矩阵吗？

您认为数据的分类版本在这里可能更有帮助还是上述令人失望的结果是否归因于更深层次的原因？

]]></description>
      <guid>https://stackoverflow.com/questions/78731704/bart-with-all-dummy-features</guid>
      <pubDate>Wed, 10 Jul 2024 16:18:19 GMT</pubDate>
    </item>
    <item>
      <title>退出网页后，网络摄像头/Canvas 仍在运行</title>
      <link>https://stackoverflow.com/questions/78731553/webcam-canvas-is-still-running-after-i-exit-a-web-page</link>
      <description><![CDATA[我正在使用 React 上的 ml5 和 p5 创建瑜伽 AI 教练。
我创建了一个加载模型和网络摄像头的组件。该组件的目标是检测某个瑜伽姿势，并且该组件动态返回从网络摄像头检测到的姿势名称。当检测到某个姿势时，该组件还会返回一个倒计时 15 秒的计时器 - 提示用户保持姿势 15 秒。
我注意到，当我退出页面转到网站上的另一个页面时，网络摄像头正在运行。当我退出页面时，它应该停止运行。
我问 ChatGPT 如何解决这个问题，他们说“您需要在组件卸载时明确停止视频流以确保网络摄像头已关闭”。我在我的组件上使用 useEffect 来包装我的函数。我认为这可能是问题所在，但我不太确定。
这是我的代码链接：https://github.com/laura-nguyen/yoga-ai/blob/feature/page-pose-cam/src/components/PoseCam/PoseCam.jsx]]></description>
      <guid>https://stackoverflow.com/questions/78731553/webcam-canvas-is-still-running-after-i-exit-a-web-page</guid>
      <pubDate>Wed, 10 Jul 2024 15:45:22 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow keras Model.fit 返回：ValueError：无法识别的数据类型</title>
      <link>https://stackoverflow.com/questions/78731508/tensorflow-keras-model-fit-returning-valueerror-unrecognized-data-type</link>
      <description><![CDATA[我尝试用 2 个输入来训练 keras 模型：一个图像部分，即 tf.data.Dataset 和一个由 pd.DataFrame 表示的正常部分&gt;
from tensorflow.keras.optimizers import Adam
opt = Adam(learning_rate=1e-3, decay=1e-3 / 200)

model.compile(loss=&quot;mean_absolute_percentage_error&quot;, optimizer=opt)

model.fit(
x=[df.loc[:, df.columns != &#39;target&#39;], ds.batch(8)], y=df[&quot;target&quot;],
epochs=200)

我尝试拟合模型，但我得到了ValueError
ValueError：无法识别的数据类型：x=[...][401059 行 x 52 列]
，&lt;_BatchDataset element_spec=(TensorSpec(shape=(None, 32, 256, 256, 3), 
dtype=tf.float32, name=None), 
TensorSpec(shape=(None, 32, 256, 256, 3), dtype=tf.float32, name=None))&gt;]（类型为 &lt;class &#39;list&#39;&gt;）
]]></description>
      <guid>https://stackoverflow.com/questions/78731508/tensorflow-keras-model-fit-returning-valueerror-unrecognized-data-type</guid>
      <pubDate>Wed, 10 Jul 2024 15:36:58 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助来找到与击键动力学相关的数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/78731494/need-assistance-to-find-a-dataset-related-to-keystroke-dynamics</link>
      <description><![CDATA[我一直在尝试为我的一个项目寻找数据集。我需要一个击键动态数据集。我不能使用合成数据。如果有任何线索可以找到它，我将不胜感激。我试过 Kaggle，但遗憾的是我在那里找到的那​​个被很多人使用，与我的项目不符。我希望我能找到另一个，谢谢！
我试过 kaggle 和 gitthub，遗憾的是到处都是相同的数据集。]]></description>
      <guid>https://stackoverflow.com/questions/78731494/need-assistance-to-find-a-dataset-related-to-keystroke-dynamics</guid>
      <pubDate>Wed, 10 Jul 2024 15:32:38 GMT</pubDate>
    </item>
    <item>
      <title>我被困在项目的这个阶段，我已经安装了 catboost 模块，但它仍然显示错误</title>
      <link>https://stackoverflow.com/questions/78730862/i-am-stuck-in-this-stage-of-my-project-where-i-already-install-the-catboost-modu</link>
      <description><![CDATA[---------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
Cell In[65]，第 2 行
1 # catboost 分类器模型
----&gt; 2 from catboost import CatBoostClassifier
4 # 实例化模型
5 cat = CatBoostClassifier(learning_rate = 0.1, verbose=0)

File c:\Users\Asus\AppData\Local\Programs\Python\Python312\Lib\site-packages\catboost\__init__.py:1
----&gt; 1 从 .core 导入 (
2 FeaturesData、EFstrType、EShapCalcType、EFeaturesSelectionAlgorithm、EFeaturesSelectionGrouping、
3 Pool、CatBoost、CatBoostClassifier、CatBoostRegressor、CatBoostRanker、CatBoostError、cv、sample_gaussian_process、train、
4 sum_models、_have_equal_features、to_regressor、to_classifier、to_ranker、MultiRegressionCustomMetric、
5 MultiRegressionCustomObjective、MultiTargetCustomMetric、MultiTargetCustomObjective
6 ) # noqa
7 从 .version 导入 VERSION 作为 __version__ # noqa
8 __all__ = [
9 &#39;FeaturesData&#39;、&#39;EFstrType&#39;、&#39;EShapCalcType&#39;、&#39;EFeaturesSelectionAlgorithm&#39;， &#39;EFeaturesSelectionGrouping&#39;,
10 &#39;Pool&#39;, &#39;CatBoost&#39;, &#39;CatBoostClassifier&#39;, &#39;CatBoostRegressor&#39;, &#39;CatBoostRanker&#39;, &#39;CatboostError&#39;,
(...)
13 &#39;MultiTargetCustomMetric&#39;, &#39;MultiTargetCustomObjective&#39;
14 ]

文件 c:\Users\Asus\AppData\Local\Programs\Python\Python312\Lib\site-packages\catboost\core.py:45
40 pass
...
9 def try_plot_offline(figs):

文件 _catboost.pyx:1，在 init _catboost() 中

ValueError: numpy.dtype 大小已更改，可能表示二进制不兼容。预期 C 标头为 96，PyObject 为 88
# 输出被截断。以可滚动元素的形式查看或在文本编辑器中打开。调整单元格输出设置...

# catboost 分类器模型
来自 catboost 导入 CatBoostClassifier

# 实例化模型
cat = CatBoostClassifier(learning_rate = 0.1, verbose=0)

# 拟合模型
cat.fit(X_train,y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/78730862/i-am-stuck-in-this-stage-of-my-project-where-i-already-install-the-catboost-modu</guid>
      <pubDate>Wed, 10 Jul 2024 13:27:16 GMT</pubDate>
    </item>
    <item>
      <title>在 Android Studio 中集成已训练的模型</title>
      <link>https://stackoverflow.com/questions/78730286/integration-of-a-trained-model-in-android-studio</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78730286/integration-of-a-trained-model-in-android-studio</guid>
      <pubDate>Wed, 10 Jul 2024 11:31:14 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中的 nestedcv 包中的 nestcv.train 对象上调用 summary() 和 train_summary() 有什么区别？</title>
      <link>https://stackoverflow.com/questions/78729334/what-is-the-difference-between-calling-summary-and-train-summary-on-a-nestcv</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78729334/what-is-the-difference-between-calling-summary-and-train-summary-on-a-nestcv</guid>
      <pubDate>Wed, 10 Jul 2024 08:11:17 GMT</pubDate>
    </item>
    <item>
      <title>加载在自定义数据集上训练的 Yolov9 模型：AttributeError：“str”对象没有属性“shape”</title>
      <link>https://stackoverflow.com/questions/78728869/loading-yolov9-model-trained-on-custom-dataset-attributeerror-str-object-has</link>
      <description><![CDATA[我已经在自定义数据集上训练了一个 yolov9 模型，用于实例分割，现在我想在分割后获得分割区域。
输出如下图所示，但针对图像中分割的每个对象。

from pathlib import Path
import numpy as np
import torch
import cv2

model = torch.hub.load(&#39;.&#39;, &#39;custom&#39;, path=&#39;yolov9-inst/runs/train-seg/gelan-c-seg15/weights/best.pt&#39;, source=&#39;local&#39;) 
# Image
img = &#39;WALL-INSTANCEE-2/test/images/5a243513a69b150001f56c31_emptyroom6_jpeg_jpg.rf.7aa8f6a9aefbb1c76adc60a7b392dcd6.jpg&#39;
# 推理
res = model(img)

但是我在仅查找 res 时收到此错误。
YOLO 🚀 v0.1-104-g5b1ea9a Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA RTX A5000, 24248MiB)

融合层...
gelan-c-seg-custom 摘要：414 层，27364441 个参数，0 个梯度， 144.2 GFLOPs
警告 ⚠️ YOLO SegmentationModel 尚不兼容 AutoShape。您将无法使用此模型运行推理。
------------------------------------------------------------------------------------------
AttributeError Traceback（最近一次调用最后一次）
Cell In[84]，第 6 行
4 img = &#39;WALL-INSTANCEE-2/test/images/5a243513a69b150001f56c31_emptyroom6_jpeg_jpg.rf.7aa8f6a9aefbb1c76adc60a7b392dcd6.jpg&#39;
5 # 推理
----&gt; 6 结果 = model(img)

文件 /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518，位于 Module._wrapped_call_impl(self, *args, **kwargs)
1516 返回 self._compiled_call_impl(*args, **kwargs) # 类型：ignore[misc]
1517 else:
-&gt; 1518 return self._call_impl(*args, **kwargs)

File /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527, in Module._call_impl(self, *args, **kwargs)
1522 # 如果我们没有任何钩子，我们希望跳过此函数中的其余逻辑
1523 # 并只调用 forward。
1524 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks
1525 or _global_backward_pre_hooks or _global_backward_hooks
1526 or _global_forward_hooks or _global_forward_pre_hooks):
-&gt; 1527 返回 forward_call(*args, **kwargs)
1529 尝试：
1530 结果 = 无

文件 /workspace/yolov9-inst/./models/common.py:868，在 DetectMultiBackend.forward(self, im, augment, visualize) 中
866 def forward(self, im, augment=False, visualize=False):
867 # YOLO MultiBackend 推理
--&gt; 868 b, ch, h, w = im.shape # 批次、通道、高度、宽度
869 if self.fp16 and im.dtype != torch.float16:
870 im = im.half() # 到 FP16

AttributeError: &#39;str&#39; 对象没有属性 &#39;shape&#39;

请问有人能帮我解决这个问题吗]]></description>
      <guid>https://stackoverflow.com/questions/78728869/loading-yolov9-model-trained-on-custom-dataset-attributeerror-str-object-has</guid>
      <pubDate>Wed, 10 Jul 2024 06:10:32 GMT</pubDate>
    </item>
    <item>
      <title>从示例数据集重新创建文本嵌入</title>
      <link>https://stackoverflow.com/questions/78728307/recreating-text-embeddings-from-an-example-dataset</link>
      <description><![CDATA[我有一个句子列表，以及一个 25 维向量上的理想嵌入列表。我正在尝试使用神经网络来生成新的编码，但很费劲。虽然模型运行良好，但其输出毫无意义，甚至无法准确复制训练数据！
import numpy as np
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

# 标记化
tokenizer = Tokenizer()
tokenizer.fit_on_texts(sentence_list)
sequences = tokenizer.texts_to_sequences(sentence_list)

# 假设您的向量是 25 维
input_dim = 25

# 定义编码器
input_vec =输入（形状=（max_sequence_length，））
编码 = Dense（25，activation=&#39;tanh&#39;）（输入_vec）# 减少到 16 维的示例
编码器 = 模型（输入_vec，编码）

# 定义解码器
解码 = Dense（输入_dim，activation=&#39;sigmoid&#39;）（编码）
自动编码器 = 模型（输入_vec，解码）

# 编译模型
自动编码器.编译（优化器=Adam（），loss=&#39;mse&#39;）

# 训练模型
自动编码器.fit（padded_sequences，combined_vectors_clean，
epochs=10，
batch_size=32，
shuffle=True，validation_split= 0.2）

据我所知，我的输入和标签没有任何问题，那么我遗漏了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78728307/recreating-text-embeddings-from-an-example-dataset</guid>
      <pubDate>Wed, 10 Jul 2024 01:39:37 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未在未知的 TensorShape 上定义 as_list()。图像和掩码形状看起来正确</title>
      <link>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78727412/valueerror-as-list-is-not-defined-on-an-unknown-tensorshape-image-and-mask-s</guid>
      <pubDate>Tue, 09 Jul 2024 19:17:45 GMT</pubDate>
    </item>
    <item>
      <title>在自定义环境中，Actor-Critic 模型中的奖励没有增加</title>
      <link>https://stackoverflow.com/questions/78714452/rewards-not-increasing-in-actor-critic-model-in-a-custom-environment</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78714452/rewards-not-increasing-in-actor-critic-model-in-a-custom-environment</guid>
      <pubDate>Sat, 06 Jul 2024 09:38:19 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模型未进行训练</title>
      <link>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</link>
      <description><![CDATA[我有一个问题，已经一个星期没法解决了。我正在尝试构建 CIFAR-10 分类器，但每个批次后的损失值都在随机跳跃，而且准确率甚至在同一个批次上也没有提高（我甚至无法用一个批次过度拟合模型），所以我猜唯一可能的原因是 - 权重没有更新。 
我的模块类
class Net(nn.Module):
def __init__(self):
super(Net, self).__init__()
self.conv_pool = nn.Sequential(
nn.Conv2d(3, 64, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(64, 128, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(128, 256, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(256, 512, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(512, 512, 1),
nn.ReLU(),
nn.MaxPool2d(2, 2))

self.fcnn = nn.Sequential(
nn.Linear(512, 2048),
nn.ReLU(),
nn.Linear(2048, 2048),
nn.ReLU(),
nn.Linear(2048, 10)
)

def forward(self, x):
x = self.conv_pool(x)
x = x.view(-1, 512)
x = self.fcnn(x)
return x

我正在使用的优化器：
net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, motivation=0.9)

我的训练函数：
def train():
for epoch in range(5): # 多次循环遍历数据集
for i in range(0, df_size):
# 获取数据

try:
images, labels = loadBatch(ds, i)
except BaseException:
continue

# 包装 
输入 = Variable(images)

optimizer.zero_grad()

输出 = net(inputs)

损失 = criterion(outputs, Variable(labels))

损失.backward()
optimizer.step()
acc = test(images,labels)
print(&quot;损失：&quot; + str(loss.data[0]) + &quot; 准确率 %：&quot; + str(acc) + &quot;迭代：&quot; + str(i))

if i % 40 == 39:
torch.save(net.state_dict(), &quot;model_save_cifar&quot;)

print(&quot;Finished epoch &quot; + str(epoch))

我使用的是 batch_size = 20, image_size = 32 (CIFAR-10)
loadBatch 函数返回 LongTensor 20x3x32x32 的元组（用于图像）和 LongTensor 20x1 的元组（用于标签）
如果您能帮助我或提出可能的解决方案，我将非常高兴（我猜是因为 NN 中的顺序模块，但我传递给优化器的参数似乎是正确的）]]></description>
      <guid>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</guid>
      <pubDate>Thu, 27 Jul 2017 19:07:27 GMT</pubDate>
    </item>
    </channel>
</rss>