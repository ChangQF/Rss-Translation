<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 05 Feb 2024 15:14:00 GMT</lastBuildDate>
    <item>
      <title>对 GAN 中的随机输入向量感到困惑：它们是如何在代码中生成的？</title>
      <link>https://stackoverflow.com/questions/77941732/confused-about-random-input-vectors-in-gans-how-are-they-generated-in-code</link>
      <description><![CDATA[我是 GAN 新手，正在努力理解随机输入向量。我看过一些视频和论文提到概率分布，但这听起来很吓人。
这些向量到底是在代码中的什么位置生成的？
您能提供一个 Python/TensorFlow 的简单示例吗？
您能解释一下噪声分布（例如高斯分布）的作用吗？
我读过一些有关潜在空间的研究论文，并观看了 YouTube 上的一些教程。]]></description>
      <guid>https://stackoverflow.com/questions/77941732/confused-about-random-input-vectors-in-gans-how-are-they-generated-in-code</guid>
      <pubDate>Mon, 05 Feb 2024 14:39:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 算法将相似的名称分组在一起</title>
      <link>https://stackoverflow.com/questions/77941625/group-similar-names-together-using-a-python-algorithm</link>
      <description><![CDATA[我需要一个项目的帮助，我有一个涉及多个产品的名称列表，但有些名称指的是同一产品，只是以不同的方式编写（如下所示）对最相似的名称进行分类的最佳方法是什么帽子很可能指的是同一组产品
示例
只有一种产品可以这样命名：
-EXFORGE 5 MG/160 B/28 COMP
-EXFORGE 5MG /160 Bte 28
-EXFORGE COMP 5 MG _160 B / 28
-Exforge 5 MG 160 B/28 COMP。
尝试了 FuzzyWuzzy 库，但它没有给我一个好的结果
这就是我所做的
来自 fuzzywuzzy 导入过程

# 假设“data”是表格数据中的产品名称列
数据 = [
    &#39;EXFORGE 5 MG/160 B/28 COMP&#39;,
    &#39;EXFORGE 5MG /160 Bte 28&#39;，
    &#39;多利普兰500MG&#39;，
    &#39;多利普兰 5.0 MG&#39;，
    &#39;EXFORGE COMP 5 MG _160 B / 28&#39;,
    &#39;Exforge 5 MG 160 B/28 COMP.&#39;,
    &#39;Doliprane 500MG Comp&#39;，
    &#39;EXFORGE CP.PEL 5MG/160 MG 28&#39;,
    “环丙沙星 500 MG/5 ML IV 100 ML 输注溶液”，
    “环丙沙星 500MG/5ML IV 100 ML Sol for Inf”，
    “输注用环丙沙星溶胶 500 MG/5 ML 100 ML”，
    “环丙沙星 500 MG/5 ML IV 100 ML 输注溶胶”，
    “环丙沙星 500 MG IV 100 ML Sol for Inf”，
    “扑热息痛 500 MG 片剂 30 片”，
    “扑热息痛 500MG 片剂 30 片”，
    “扑热息痛片 500 MG 30 片”，
    “扑热息痛片 500 MG 30 片”，
    “扑热息痛 500 MG 30 片”，
    “赖诺普利 10 MG 片剂 28 片”，
    “赖诺普利 10MG 片剂 28 片”，
    &#39;赖诺普利 Tab 10 MG 28s&#39;，
    &#39;赖诺普利片 10 MG 28s&#39;，
    “赖诺普利 10 MG 28 片”，
    “辛伐他汀 20 MG 片剂 100 片”，
    “辛伐他汀 20MG 片剂 100 片”，
    “辛伐他汀片 20 MG 100s”，
    “辛伐他汀片 20 MG 100s”，
    “辛伐他汀 20 MG 100 片”，
    “奥美拉唑 20 MG 胶囊 28 粒”，
    “奥美拉唑 20MG 胶囊 28 粒”，
    “奥美拉唑胶囊 20 MG 28 粒”，
    “奥美拉唑胶囊 20 MG 28 粒”，
    “奥美拉唑 20 MG 28 粒胶囊”
]

# 定义相似度阈值
阈值 = 87

# 初始化组列表
组 = []

# 将相似名称添加到组中的函数
def add_to_group(组, 名称):
    对于组中的现有名称：
        if process.extractOne(existing_name, [name])[1] &gt;= 阈值：
            返回真
    返回错误

# 迭代数据以形成组
对于数据中的名称：
    添加 = 假
    对于组中的组：
        如果添加到组（组，名称）：
            组.添加(名称)
            添加=真
            休息
    如果没有添加：
        groups.append({名称})

# 打印最相似名称的组
对于 idx，枚举中的组（组，1）：
    print(f&quot;组 {idx}: {group}&quot;)

只有 3 组而不是 7 组，当我将阈值调整为 88 而不是 87 时，它变成了 10 组]]></description>
      <guid>https://stackoverflow.com/questions/77941625/group-similar-names-together-using-a-python-algorithm</guid>
      <pubDate>Mon, 05 Feb 2024 14:22:59 GMT</pubDate>
    </item>
    <item>
      <title>python中有没有可以直接将图像或360度视频片段转换为3d模型的库[关闭]</title>
      <link>https://stackoverflow.com/questions/77941184/is-any-library-in-python-can-directly-convert-image-or-360-degree-video-footage</link>
      <description><![CDATA[我想从图像和 360 度摄像机视频片段创建 3D 模型。我知道它包含深度学习和计算机视觉方面的许多工作，请给我推荐除 Pytorch OpenCV 之外的最佳 3D 建模库。
库名称和任何人的好建议]]></description>
      <guid>https://stackoverflow.com/questions/77941184/is-any-library-in-python-can-directly-convert-image-or-360-degree-video-footage</guid>
      <pubDate>Mon, 05 Feb 2024 13:07:15 GMT</pubDate>
    </item>
    <item>
      <title>merge_batch_to_components() 不再起作用</title>
      <link>https://stackoverflow.com/questions/77941040/merge-batch-to-components-doesnt-work-any-longer</link>
      <description><![CDATA[我正在通过Tensorflow的文档学习GNN，并且我尝试了Tensorflow提供的GNN示例：
https://github.com/tensorflow/gnn/blob/主/示例/笔记本/intro_mutag_example.ipynb
几天前这个例子运行得很好。
但今天我收到一个错误：
AttributeError：“KerasTensor”对象没有属性“merge_batch_to_components”

我不知道为什么 merge_batch_to_components() 不再起作用。
我猜这个功能可能会被删除？
但搜索了更新的消息后，却没有得到任何消息。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77941040/merge-batch-to-components-doesnt-work-any-longer</guid>
      <pubDate>Mon, 05 Feb 2024 12:44:51 GMT</pubDate>
    </item>
    <item>
      <title>AFK 期间如何在 google collab 上训练模型？</title>
      <link>https://stackoverflow.com/questions/77940576/how-do-i-train-model-on-google-collab-while-being-afk</link>
      <description><![CDATA[我想在 Google Collab 上训练模型。问题是它需要大约。训练时间为五个小时，如果我离开电脑，Google Collab 将结束我的训练。因此，我想知道是否有一种方法可以在远离计算机的情况下训练我的模型。
我在网上看到了一些解决方案，但它们来自较旧的帖子，有些人说它们不再起作用。]]></description>
      <guid>https://stackoverflow.com/questions/77940576/how-do-i-train-model-on-google-collab-while-being-afk</guid>
      <pubDate>Mon, 05 Feb 2024 11:29:14 GMT</pubDate>
    </item>
    <item>
      <title>允许模型在二元分类问题中返回中性响应</title>
      <link>https://stackoverflow.com/questions/77940271/allow-model-to-return-a-neutral-response-in-binary-classification-problem</link>
      <description><![CDATA[我正在尝试使用 Keras 的二元分类来解决问题。我想知道是否有任何方法可以通过添加中性响应（例如：跳过）而不是正常响应（是/否）来提高准确性，因此如果我的模型在预测时对提供的数据没有信心，则可以返回跳过。
我尝试构建一个初始的二元分类模型（保持简单以避免过度拟合），然后通过该模型验证所有训练数据，并更新响应表以将行值更改为中性值（如果预测错误）。之后创建一个包含 3 个类别（是、否、跳过）的分类模型。然而，这个新模型的 val_acc 和 val_loss 并没有太大的改进。你们有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77940271/allow-model-to-return-a-neutral-response-in-binary-classification-problem</guid>
      <pubDate>Mon, 05 Feb 2024 10:36:26 GMT</pubDate>
    </item>
    <item>
      <title>加载注释txt格式并与图像匹配</title>
      <link>https://stackoverflow.com/questions/77939896/load-annotation-txt-format-and-match-with-images</link>
      <description><![CDATA[SI 有一组 txt 格式的图像和注释。我正在尝试加载注释，然后将图像匹配，以便稍后打印出图像与图像上的边界框。这个怎么做？在互联网上找不到任何相关信息。
&lt;前&gt;&lt;代码&gt;1
61.5535714286 71.6428571429 96.5535714286 104.5
95.8392857143 71.6428571429 117.982142857 95.9285714286
92.2678571429 85.9285714286 125.839285714 115.214285714

我已经加载了图像和标签。我尝试使用 Path 加载标签并将其放入列表中，但后来我意识到每个 txt 文件上面都有一个奇怪的数字，所以我用 pandas 创建了一个跳行，现在我不知道如何实现pandas 到我的 dict 函数中
导入 matplotlib.pyplot 作为 plt
将 matplotlib.patches 作为补丁导入
从 PIL 导入图像
将 pandas 导入为 pd

# 加载图像
图像 = Image.open(“数据”)

标签 = [路径（“标签”）]


pdlabel =“标签”；
df = pd.read_csv(pdlabel,skiprows=[0])



格式化 = dict(fieldnames=[ &#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;], delimiter=&#39; &#39;)

def process_labels(label_path_list): #TODO 寻找跳过行的新方法
    返回 {
        fop.stem: [dict(a) for a in csv.DictReader(fop.open(), **formatted)]
        对于 label_path_list 中的 fop
    }

标签 = process_labels(df)
打印（标签）
打印（标签）


Fig, ax = plt.subplots()

ax.imshow(图像)

矩形 = patch. 矩形(**标签)

ax.add_patch(矩形)

plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/77939896/load-annotation-txt-format-and-match-with-images</guid>
      <pubDate>Mon, 05 Feb 2024 09:37:51 GMT</pubDate>
    </item>
    <item>
      <title>将机器学习模型部署到云上的工具和技术。使用微软Azure [关闭]</title>
      <link>https://stackoverflow.com/questions/77938824/tools-technique-to-deploy-ml-models-onto-the-cloud-using-microsoft-azure</link>
      <description><![CDATA[我正在寻找有关在 Microsoft Azure 上部署机器学习模型的指南。具体来说，我想知道针对此任务推荐哪些工具和技术。任何有关最佳实践的建议将不胜感激。

在 Microsoft Azure 上部署机器学习模型的推荐工具和技术是什么？

我应该遵循哪些最佳实践来确保顺利部署以及与其他 Azure 服务集成？

如何监控和管理已部署的模型以确保最佳性能和可靠性？

您是否有推荐的教程或资源来帮助您开始在 Azure 上部署机器学习模型？


我使用 Python 和 TensorFlow 或 Scikit-learn 等流行库开发了一个机器学习模型。现在，我需要将此模型部署到 Microsoft Azure 上，以便其他应用程序和服务可以访问和使用它。]]></description>
      <guid>https://stackoverflow.com/questions/77938824/tools-technique-to-deploy-ml-models-onto-the-cloud-using-microsoft-azure</guid>
      <pubDate>Mon, 05 Feb 2024 05:39:56 GMT</pubDate>
    </item>
    <item>
      <title>预处理新数据以根据 PyCaret 中的现有模型进行预测</title>
      <link>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</link>
      <description><![CDATA[我在 PyCaret 中有一个经过训练的模型，并且我能够在 setup() 期间对原始训练/测试拆分的测试数据进行预测。我还知道 Predict_model() 的“data”参数用于传递新的/未见过的数据。
我遇到的问题是：看不见的数据的列结构与模型预期的不同，因为模型执行了许多特征转换和编码。我正在尝试弄清楚如何通过相同的预处理步骤运行我的新的未见数据，以便预测 1) 可能，2) 有意义。
我尝试过跑步
predict_model（最佳，数据= new_test_data）

我收到 KeyErrors：
KeyError：“[&#39;Some Feature 1&#39;] 不在索引中”

我已经阅读了有关 get_config 的文档，也许还阅读了 transform() 成员函数，但尚未成功确保对 new_test_data 执行相同的预处理步骤，以便可以使用现有模型对其进行预测。&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</guid>
      <pubDate>Mon, 05 Feb 2024 03:32:23 GMT</pubDate>
    </item>
    <item>
      <title>RNN 的训练循环在每个 epoch 后返回相同的损失</title>
      <link>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</link>
      <description><![CDATA[我正在尝试借助此存储库从头开始构建 RNN (https: //github.com/nicklashansen/rnn_lstm_from_scratch/tree/master），但每个时期后的训练损失保持不变。训练循环的代码如下：
# 超参数
纪元数 = 1000

# 初始化一个新网络
参数 = init_rnn(hidden_​​size=hidden_​​size, vocab_size=vocab_size)

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 轨迹丢失
训练损失、验证损失 = []、[]

def check_if_params_updated(old_params, new_params):
    # 该函数检查两组参数是否不同
    对于 zip 中的 old_param、new_param(old_params, new_params)：
        如果不是 np.array_equal(old_param, new_param):
            return True # 参数已更新
    return False # 参数尚未更新


# 对于每个纪元
对于范围内的 i（num_epochs）：
    
    # 轨迹丢失
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
     # 对于验证集中的每个句子
    对于输入，val_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，_ =向后传递（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        
        # 更新损失
        epoch_validation_loss += 损失
    
    # 对于训练集中的每个句子
    对于输入，train_loader 中的目标：
        
        # One-hot 编码输入和目标序列
        input_one_hot = one_hot_encode_sequence（输入，vocab_size）
        target_one_hot = one_hot_encode_sequence（目标，vocab_size）
        
        # 重新初始化隐藏状态
        隐藏状态 = np.zeros_like(隐藏状态)

        # 前向传递
        输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）

        # 向后传递
        损失，梯度=backward_pass（inputs_one_hot，输出，hidden_​​states，targets_one_hot，参数）
        打印（inputs_one_hot.shape）
        
        如果 np.isnan(损失):
            raise ValueError(&#39;梯度消失/爆炸！&#39;)
        
        # 更新参数
        params = update_parameters(params, grads, lr=1e-3)
        
        # 更新损失
        epoch_training_loss += 损失
        
    # 保存绘图损失
    Training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # 每 100 个 epoch 打印损失
    如果我％100==0：
        print(f&#39;Epoch {i}, 训练损失: {training_loss[-1]}, 验证损失: {validation_loss[-1]}&#39;)


# 获取测试集中的第一个句子
输入，目标 = test_set[1]

# One-hot 编码输入和目标序列
input_one_hot = one_hot_encode_sequence（输入，vocab_size）
target_one_hot = one_hot_encode_sequence（目标，vocab_size）

# 将隐藏状态初始化为零
隐藏状态 = np.zeros((隐藏大小, 1))

# 前向传递
输出，hidden_​​states =forward_pass（inputs_one_hot，hidden_​​state，params）
output_sentence = [idx_to_word[np.argmax(output)] 用于输出中的输出]
print(&#39;输入句子：&#39;)
打印（输入）

print(&#39;\n目标序列:&#39;)
打印（目标）

print(&#39;\n预测序列:&#39;)
print([idx_to_word[np.argmax(output)] 用于输出中的输出])

# 绘制训练和验证损失图
纪元 = np.arange(len(training_loss))
plt.figure()
plt.plot(epoch, Training_loss, &#39;r&#39;, label=&#39;训练损失&#39;,)
plt.plot(epoch,validation_loss,&#39;b&#39;,label=&#39;验证损失&#39;)
plt.图例()
plt.xlabel(&#39;Epoch&#39;), plt.ylabel(&#39;NLL&#39;)
plt.show()

我尝试检查我的参数是否正在更新，它们确实更新了，还尝试检查梯度，它们并不是指数小。每次迭代后损失都会减少，但总纪元的损失保持不变。您可以在存储库中找到完整的代码，其中包括前向和后向传递(https://github.com/危险dude237/RNN_From_Scratch）。]]></description>
      <guid>https://stackoverflow.com/questions/77938129/training-loop-of-rnn-returning-the-same-loss-after-each-epoch</guid>
      <pubDate>Mon, 05 Feb 2024 00:28:27 GMT</pubDate>
    </item>
    <item>
      <title>在Mini Batch梯度下降中应用StandardScaler，应用错误</title>
      <link>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</link>
      <description><![CDATA[ValueError：需要 2D 数组，却得到 1D 数组：
数组=[0。 0. 0. ... 0. 0. 1.]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

当我尝试运行代码时，我不断收到此错误：
# 分离特征 (X) 和目标变量 (y)
X = np.array(df[&#39;默认&#39;])
y = np.array(df[&#39;默认&#39;])
l = len(X)

# 将数据分为训练集和测试集

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 添加特征标量器 Z 分数标准化

定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)


# 实现小批量梯度

类 mini_batch_gradient_descent:
    
    def create_batch(self,X_train,y_train,batch_size):
        小批量=[]
        数据=np.stack((X_train,y_train),轴=1)
        np.random.shuffle(数据)
        batches=X_train.shape[0]//batch_size
        对于范围内的 i（批次）：
            mini_batch=数据[i*batch_size:(i+1)*batch_size]
            mini_batches.append((mini_batch[:,0], mini_batch[:,1]))
        如果 X_train.shape[0]/batch_size!=0:
            mini_batch=数据[i*batch_size:]
            mini_batches.append((mini_batch[:, 0], mini_batch[:,1]))
        返回小批量
    
    def fit(self,X_train,y_test,alpha,epochs,batch_size):
        self.m=np.random.randn(1,1)
        self.c=np.random.randn(1,1)
        l=len(X_train)
        对于范围内的 i（纪元）：
            批次= self.create_batch（X_train，y_train，batch_size）
            对于批量批次：
                xb=批次[0]
                yb=批次[1]
                xb=xb.reshape(1, xb.shape[0])
                截距=np.sum((np.dot(self.m,xb)+self.c)-yb)
                斜率=np.sum((np.dot(self.m,xb)+self.c)-yb)
                self.m=self.m-alpha*(斜率/l)
                self.c=self.c-alpha*(斜率/l)
    
    def 斜率截距():
        print(f&quot;斜率为 {self.m[0][0]}&quot;)
        print(f&quot;截距为 {self.c[0][0]}&quot;)
        
    
    def 预测（自我，X_test）：
        X_test=X_test.reshape(X_test.shape[0],1)
        self.m=self.m.reshape(self.m.shape[1],self.m.shape[0])
        结果=np.dot(X_test, self.m)+self.c
        返回结果

我尝试使用 loc/iloc，但它一直收到错误。
我正在使用数据帧，然后转换为 np.array 来运行程序。它可以在没有功能缩放器的情况下工作，但当我尝试实现缩放器时，它开始给我错误。不确定在功能扩展方面我还有什么其他选择。]]></description>
      <guid>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</guid>
      <pubDate>Sun, 04 Feb 2024 23:19:53 GMT</pubDate>
    </item>
    <item>
      <title>不知道如何在此 ML 程序中进行用户输入</title>
      <link>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 r2_score、mean_squared_error

# 加载数据集
dp = pd.read_csv(&#39;https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv&#39;)

# 分离特征（x）和目标变量（y）
y = dp[&#39;logS&#39;]
x = dp.drop(&#39;logS&#39;, 轴=1)

# 分割数据
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)

# 线性回归模型
lr = 线性回归()
lr.fit(x_train, y_train)
y_train_pred_lr = lr.predict(x_train)
y_test_pred_lr = lr.predict(x_test)

# 随机森林回归模型
k1 = RandomForestRegressor（最大深度=2，随机状态=100）
k1.fit(x_train, y_train)
y_train_pred_rf = k1.predict(x_train)
y_test_pred_rf = k1.predict(x_test)

# 评估线性回归模型
y_train_mse_lr =mean_squared_error(y_train, y_train_pred_lr)
y_train_r2_lr = r2_score(y_train, y_train_pred_lr)
y_test_mse_lr = 均方误差(y_test, y_test_pred_lr)
y_test_r2_lr = r2_score(y_test, y_test_pred_lr)

# 评估随机森林回归模型
y_train_mse_rf =mean_squared_error(y_train, y_train_pred_rf)
y_train_r2_rf = r2_score(y_train, y_train_pred_rf)
y_test_mse_rf =mean_squared_error(y_test, y_test_pred_rf)
y_test_r2_rf = r2_score(y_test, y_test_pred_rf)

# 创建数据框
rs_lr = pd.DataFrame({“方法”: [“线性回归”],
                      “训练MSE”：[y_train_mse_lr]，
                      “训练R2”：[y_train_r2_lr]，
                      “测试 MSE”：[y_test_mse_lr]，
                      “测试 R2”：[y_test_r2_lr]})

rs_rf = pd.DataFrame({“方法”: [“随机森林回归器”],
                      “训练MSE”：[y_train_mse_rf]，
                      “训练R2”：[y_train_r2_rf]，
                      “测试 MSE”：[y_test_mse_rf]，
                      “测试 R2”：[y_test_r2_rf]})

# 连接数据帧
结局 = pd.concat([rs_lr, rs_rf],ignore_index=True)
打印（结局）

加载数据集：它使用 Pandas 从 URL 加载数据集。该数据集与分子溶解度相关，包含各种分子描述符。
数据准备：它将特征（x）和目标变量（y）从数据集中分离出来。本例中的目标变量是溶解度的对数 (logS)。
数据拆分：它使用 scikit-learn 中的 train_test_split 函数将数据集拆分为训练集和测试集。训练集用于训练模型，测试集用于评估模型的性能。
模型训练：它使用训练数据训练两个回归模型 - 线性回归模型 (lr) 和随机森林回归模型 (k1)。
预测：它使用经过训练的模型对训练集和测试集进行预测。
模型评估：它使用均方误差 (MSE) 和 R 平方 (R2) 分数评估两个模型的性能。这些指标可以深入了解模型对数据的拟合程度。
创建 DataFrame：它创建两个单独的 DataFrame（rs_lr 和 rs_rf）来存储每个模型的评估指标。
串联：它将两个 DataFrame 连接成一个最终的 DataFrame（结局）。此 DataFrame 总结了两种模型的训练和测试性能。
打印结果：最后，它打印串联的 DataFrame（结局），其中包括线性回归和随机森林回归模型的方法名称、训练 MSE、训练 R2、测试 MSE 和测试 R2。
该程序的目标是比较线性回归和随机森林回归模型在根据描述符预测分子溶解度方面的性能。
我希望用户输入值。那么我该如何修改代码呢？]]></description>
      <guid>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</guid>
      <pubDate>Sun, 04 Feb 2024 18:32:58 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的数据集，至少包含 100 列和 10,000 个原始数据 [已关闭]</title>
      <link>https://stackoverflow.com/questions/77931469/data-set-for-machine-learning-with-minimum-100-columns-and-10-000-raws</link>
      <description><![CDATA[我想要一个至少包含 100 列和 10000 行的数据集。您不能使用任何编程语言来生成它，因为它将用于机器学习实践]]></description>
      <guid>https://stackoverflow.com/questions/77931469/data-set-for-machine-learning-with-minimum-100-columns-and-10-000-raws</guid>
      <pubDate>Sat, 03 Feb 2024 09:03:55 GMT</pubDate>
    </item>
    <item>
      <title>训练 GLM Lasso 模型后对新数据进行预测</title>
      <link>https://stackoverflow.com/questions/61193285/make-predictions-on-new-data-after-training-the-glm-lasso-model</link>
      <description><![CDATA[我在 r 的 glmnet 库中使用 lasso 对 13,000 行标签训练了一个分类模型。我检查了我的准确性，看起来不错，现在我想对数据集的其余部分（即 300,000 行）进行预测。我的方法是使用经过训练的模型来标记其余的行。我不确定这是否是进行近似标记的最有效策略。
但是，当我尝试标记其余数据时，我遇到了此错误：
asMethod(object) 中的错误：Cholmod 错误“问题太大”位于文件 ../Core/cholmod_dense.c，第 105 行

即使我将数据集分解为 5000 行进行预测，我仍然会遇到相同的错误。
这是我的代码：
库(glmnet)
#原始数据集的子集
data.text &lt;- data.text_filtered %&gt;% 过滤器(!label1 == &quot;NA&quot;)

#Quanteda 语料库
data_corpus &lt;- corpus(data.text$text, docvars = data.frame(labels = data.text$label1))

设置.种子(1234)

dataShuffled &lt;- corpus_sample(data_corpus, size = 12845)

dataDfm &lt;- dfm_trim( dfm(dataShuffled, verbose = FALSE), min_termfreq = 10)

#训练分类器的模型
套索 &lt;- cv.glmnet(x = dataDfm[1:10000,], y = trainclass[1:10000],
    alpha = 1，nfolds = 5，族 =“二项式”）

#plot 套索图
情节（套索）

#预测
dataPreds &lt;- 预测(lasso, dataDfm[10000:2845,], type=&quot;class&quot;)
(movTable &lt;- 表(dataPreds, docvars(dataShuffled, “标签”)[10000:2845]))

对数据集的其余部分进行预测。该数据集有 300,000 行。
data.text_NAs &lt;- data.text_filtered %&gt;% 过滤器(label1 == &quot;NA&quot;)

data_NADfm &lt;- dfm_trim( dfm(corpus(data.text_NAs$text), verbose = FALSE), min_termfreq = 10)

data.text_filtered &lt;- data.text_filtered %&gt;% mutate(label = Predict(lasso, as.matrix(data_NADfm), type=“class”, s=“lambda.1se”)

]]></description>
      <guid>https://stackoverflow.com/questions/61193285/make-predictions-on-new-data-after-training-the-glm-lasso-model</guid>
      <pubDate>Mon, 13 Apr 2020 17:29:14 GMT</pubDate>
    </item>
    <item>
      <title>无法创建机器学习模型</title>
      <link>https://stackoverflow.com/questions/61084824/cannot-create-model-for-machine-learning</link>
      <description><![CDATA[我正在创建一个用于检测脑肿瘤的 python 应用程序。 
关于数据：
该数据集包含 2 个文件夹：yes 和 no，其中包含 253 个脑部 MRI 图像。 yes 文件夹包含 155 个肿瘤性脑部 MRI 图像，no 文件夹包含 98 个非肿瘤性脑部 MRI 图像。
# 张量板
log_file_name = f&#39;brain_tumor_detection_cnn_{int(time.time())}&#39;
张量板 = TensorBoard(log_dir=f&#39;logs/{log_file_name}&#39;)

# 检查点
# 包含纪元和验证（开发）准确性的唯一文件名
filepath=&quot;cnn-parameters-improvement-{epoch:02d}-{val_acc:.2f}&quot;
# 保存迄今为止最好的验证（开发）精度的模型
checkpoint = ModelCheckpoint(&quot;models/{}.model&quot;.format(filepath, monitor=&#39;val_acc&#39;, verbose=1, save_best_only=True, mode=&#39;max&#39;))


# ## 训练模型

model.fit（x = X_train，y = y_train，batch_size = 32，epochs = 10，validation_data =（X_val，y_val），callbacks = [tensorboard，检查点]）

在训练模型时，出现以下错误：

&lt;前&gt;&lt;代码&gt;纪元 1/10
91/91 [================================] - 预计到达时间：0 秒 - 损失：0.7457 - 准确度：0.6735
-------------------------------------------------- ------------------------
KeyError Traceback（最近一次调用最后一次）
_get_file_path 中的 c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py（自我、纪元、日志）
   攀上漂亮女局长之后1243
-&gt;第1244章
   攀上漂亮女局长之后1245

关键错误：&#39;val_acc&#39;

在处理上述异常的过程中，又出现了一个异常：

KeyError Traceback（最近一次调用最后一次）
&lt;ipython-input-20-b50661a1419b&gt;在&lt;模块&gt;中
      1 开始时间 = time.time()
      2
----&gt; 3 model.fit（x = X_train，y = y_train，batch_size = 32，epochs = 10，validation_data =（X_val，y_val），callbacks = [tensorboard，检查点]）
      4
      5 结束时间 = time.time()

_method_wrapper 中的 c:\python38\lib\site-packages\tensorflow\python\keras\engine\training.py(self, *args, **kwargs)
     64 def _method_wrapper（自我，*args，**kwargs）：
     65 if not self._in_multi_worker_mode(): # pylint: 禁用=受保护的访问
---&gt; 66 返回方法（self，*args，**kwargs）
     67
     68 # 已经在 `run_distribute_coordinator` 中运行。

c:\python38\lib\site-packages\tensorflow\python\keras\engine\training.py 适合（自我，x，y，batch_size，纪元，详细，回调，validation_split，validation_data，shuffle，class_weight，sample_weight，initial_epoch 、steps_per_epoch、validation_steps、validation_batch_size、validation_freq、max_queue_size、workers、use_multiprocessing、**kwargs）
    第811章
    812
--&gt;第813章
    第814章
    第815章 打破

c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py 在 on_epoch_end(self, epoch, 日志)
    363 日志 = self._process_logs(日志)
    364 self.callbacks中的回调：
--&gt;第365章
    第366章
    367 def on_train_batch_begin（自我，批次，日志=无）：

c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py 在 on_epoch_end(self, epoch, 日志)
   第1175章
   第1176章
-&gt;第1177章
   第1178章
   第1179章 1179

_save_model 中的 c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py(self、纪元、日志)
   1194 int) 或 self.epochs_since_last_save &gt;= self.period:
   第1195章
-&gt;第1196章
   1197
   第1198章

_get_file_path 中的 c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py（自我、纪元、日志）
   第1244章
   攀上漂亮女局长之后1245
-&gt; 1246 raise KeyError（&#39;无法格式化此回调文件路径：“{}”。&#39;
   1247 &#39; 原因 : {}&#39;.format(self.filepath, e))
   第1248章

KeyError：&#39;无法格式化此回调文件路径：“models/cnn-parameters-improvement-{epoch:02d}-{val_acc:.2f}.model”。原因：\&#39;val_acc\&#39;&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/61084824/cannot-create-model-for-machine-learning</guid>
      <pubDate>Tue, 07 Apr 2020 16:30:01 GMT</pubDate>
    </item>
    </channel>
</rss>