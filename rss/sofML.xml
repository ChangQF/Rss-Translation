<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 11 May 2024 18:17:37 GMT</lastBuildDate>
    <item>
      <title>构建分类模型后，如何在数据集中不指定对象定位的情况下执行对象/异常定位？</title>
      <link>https://stackoverflow.com/questions/78465357/how-to-perform-object-anomaly-localization-after-building-a-classification-model</link>
      <description><![CDATA[我已经使用 EfficientNetB4 成功构建了一个分类模型，该模型可以高精度地将医学图像分类为各种类别。现在，我想本地化并提取这些图像中的感兴趣区域（异常），而无需在数据集中添加明确的本地化注释。
我接触过 Grad-CAM、CAM 和引导反向传播等多种技术，但在正确实施它们时遇到了困难。以下是我的设置的简要概述：
模型架构：EfficientNetB4 具有用于分类的附加密集层。
分类准确度：非常高，因此模型区分类别的能力不是问题。
目标：可视化并提取模型用于预测的区域（异常）。
**
我的问题：**
在这种情况下，异常定位的最佳技术是什么？有没有特别适合医学图像的方法？
如何在 TensorFlow/Keras 中实现这些技术？任何示例代码或详细步骤将不胜感激。
在尝试使用这些技术可视化和提取异常时，我应该注意哪些常见陷阱？
**我尝试过的：
**实施 Grad-CAM，但在与我的 EfficientNetB4 模型集成时面临形状不匹配问题。
尝试展平图层并调整输入形状，但仍然遇到错误。]]></description>
      <guid>https://stackoverflow.com/questions/78465357/how-to-perform-object-anomaly-localization-after-building-a-classification-model</guid>
      <pubDate>Sat, 11 May 2024 16:35:06 GMT</pubDate>
    </item>
    <item>
      <title>CreateML 超参数</title>
      <link>https://stackoverflow.com/questions/78465196/createml-hyperparameters</link>
      <description><![CDATA[我尝试为 S&amp;P500 指数中的每只股票创建一些机器学习模型。使用 sklearn（提升树模型）创建模型时，我尝试通过使用 GridSearchCV 执行超参数来使其更成功。创建一种模型需要很长时间，因此我不想考虑创建所有股票模型。我尝试使用 CreateML 和 swift，但看起来它比 python 上的 sklearn 运行时间更长。我的问题是如何使该过程更快？ swift 上的 CreateML 上是否有任何超参数（我在文档中找不到它）以及如何在我的 GPU 上运行此代码？ （应该快得多）。
我对任何想法持开放态度，在 GPU 上运行整个 python，只运行 hyperopt params 部分，或者在 CreateML 中快速创建模型。
我有 MacBook Pro M2]]></description>
      <guid>https://stackoverflow.com/questions/78465196/createml-hyperparameters</guid>
      <pubDate>Sat, 11 May 2024 15:36:45 GMT</pubDate>
    </item>
    <item>
      <title>计算伯杰方程函数时出现错误</title>
      <link>https://stackoverflow.com/questions/78464990/error-in-calculating-the-function-of-bergers-equations</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;#burger
defsolve_burgers(X, t, nu):
  定义 f(y):
    返回 torch.exp(-torch.cos(np.pi * y) / (2 * np.pi * nu))
  定义 g(y):
    返回 np.exp(-(y**2) / (4 * nu * t))
  定义乐趣（eta）：
    return torch.sin(np.pi * (x - eta)) * f(x - eta) * g(eta)
  def fun1(eta):
    返回 f(x - eta) * g(eta)
  U = np.zeros_like(X)
  对于范围内的 i(len(X))：
    x = X[[[i]]]
    如果 np.abs(x) != 1:
      uxt = -quad(fun, -np.inf, np.inf)[0] # 使用quad进行积分
      U[i] = uxt /quad(fun1, -np.inf, np.inf)[0]
     # print(&quot;uxt= &quot;,uxt)
  返回U

伯杰方程是根据以下文章求解的。我实现了这个解决方案，但我认为答案是错误的，例如，在t=0 25的时刻，答案总是从0开始，并且有增加的趋势，这不符合逻辑。我不知道为什么计算是正确完成
我需要你提前帮忙。非常感谢。
论文：C. BASDEVANT、M. DEVILLE、P. HALDENWANG、J. M. LACROIX、J. OUAZZANI、R. PEYRET、P. ORLANDI、
A. T. PATERA，“伯格斯方程的光谱和有限差分解”，]]></description>
      <guid>https://stackoverflow.com/questions/78464990/error-in-calculating-the-function-of-bergers-equations</guid>
      <pubDate>Sat, 11 May 2024 14:33:14 GMT</pubDate>
    </item>
    <item>
      <title>预测保证金永远不会给出负值</title>
      <link>https://stackoverflow.com/questions/78464909/predictive-margin-never-gives-negative-values</link>
      <description><![CDATA[我正在使用 Jupyter Notebook 来做随机森林分类模型。模型完成后，我希望它计算并打印预测裕度，它确实做到了，但没有实例的预测裕度为负。
我使用了以下行：
margins_new_data = np.max(proba_values, axis=1) - np.partition(proba_values, -2, axis=1)[:, -2]
从概念上讲，我将预测裕度理解为 1 到 -1 之间的数字，有助于确定模型在预测特定实例时的信心程度（1 表示完全有信心，-1 表示完全没有信心）。
我是否使用了错误的线条或者我误解了这个概念？]]></description>
      <guid>https://stackoverflow.com/questions/78464909/predictive-margin-never-gives-negative-values</guid>
      <pubDate>Sat, 11 May 2024 14:06:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 python spacy 模块的词向量显示错误</title>
      <link>https://stackoverflow.com/questions/78464557/word-vectors-using-spacy-module-of-python-showing-error</link>
      <description><![CDATA[尝试使用Python的spacy模块获取词向量并使用en_core_web_lg创建词向量。
`从 sklearn.feature_extraction.text 导入 CountVectorizer
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
tfidf=TfidfVectorizer(小写=False)
df1[&#39;问题1&#39;]=df1[&#39;问题1&#39;].apply(lambda x : str(x))
df1[&#39;问题2&#39;]=df1[&#39;问题2&#39;].apply(lambda x : str(x))
tot_ques=list(df1[&#39;问题1&#39;]) + list(df1[&#39;问题2&#39;])
tfidf.fit(tot_ques)
idfscore=dict(zip(tfidf.get_feature_names_out(),tfidf.idf_))
打印（idfscore）
从 tqdm 导入 tqdm
导入spacy
nlp=spacy.load(&#39;en_core_web_lg&#39;)
&lt;前&gt;&lt;代码&gt;vec1 = []
# 迭代每个问题1
对于 tqdm(list(df1[&#39;question1&#39;])) 中的 qu1：
doc1 = nlp（qu1）

# 初始化向量总和以及 IDF 总得分
sum_vec = np.zeros(len(doc1[0].vector)) # 第一个单词的向量维度
Total_idf = 0.0 # 初始化IDF总分

# 遍历句子中的每个单词
对于 doc1 中的单词：
    vec = 词.向量
    
    # 计算单词的IDF分数
    尝试：
        idf = idfscore(str(单词))
    除了：
        idf = 0.0
    
    # 累加词向量的加权和
    sum_vec += vec * idf
    
    # 累计IDF总分
    总计 idf += idf

# 如果 IDF 总得分不为零，则计算均值向量
如果total_idf！= 0：
    平均向量 = 向量总和 / 总 idf
别的：
    mean_vec = sum_vec # 如果总 IDF 为零，则回退到 sum_vec

# 将均值向量附加到 vec1
vec1.append(mean_vec)

# 将计算出的向量分配给数据框中的新列“q1”
df1[&#39;q1&#39;] = vec1`

但是当我查看 q1 列的值时，每行都显示 0]]></description>
      <guid>https://stackoverflow.com/questions/78464557/word-vectors-using-spacy-module-of-python-showing-error</guid>
      <pubDate>Sat, 11 May 2024 12:13:25 GMT</pubDate>
    </item>
    <item>
      <title>Inception 在 isic 数据集中给出的准确度非常低</title>
      <link>https://stackoverflow.com/questions/78464120/inception-gives-verylow-accuracy-in-isic-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78464120/inception-gives-verylow-accuracy-in-isic-dataset</guid>
      <pubDate>Sat, 11 May 2024 09:44:43 GMT</pubDate>
    </item>
    <item>
      <title>核逻辑回归 - 错误的预测</title>
      <link>https://stackoverflow.com/questions/78463519/kernel-logistic-regression-wrong-prediction</link>
      <description><![CDATA[我正在研究内核逻辑回归函数，但它们没有返回正确的预期预测。
它还会抛出指数溢出警告，目前已被抑制
&lt;前&gt;&lt;代码&gt;
    将 numpy 导入为 np
    进口警告

    warnings.filterwarnings(&#39;忽略&#39;)

    def monomial_kernel(d):
        def k(x, y, d=d):
            phi_x_y = 0
            prod_xy = np.dot(x.T,y)

            对于范围 (d+1) 中的 n：
                phi_x_y += (prod_xy ** n)

            返回 phi_x_y
            
        返回 k

    def rbf_kernel(西格玛):
        def k(x, y, 西格玛=西格玛):
            分子 = np.linalg.norm(x - y) **2
            分母 = 2 * (西格玛 ** 2)
            
            return np.exp(-分子/分母)

        返回 k

    定义 sigmoid(z):
        如果类型（z）== np.ndarray：
            z = z[0]
        尝试：
            返回 1 / (1 + np.exp(-z))
        除了：
            打印（z）

    def Logistics_regression_with_kernel(X, y, k, alpha, 迭代):

        n_samples, _ = X.shape
        偏差 = 0
        kernel_matrix = np.zeros((n_samples, n_samples))
        beta = np.zeros(n_samples)

        #创建核矩阵
        对于范围内的 i（n_samples）：
            对于 j 在范围内（n_samples）：
                kernel_matrix[i][j] = k(X[i], X[j])
        
        对于 _ 在范围内（迭代）：
            对于范围内的 i（n_samples）：
                总计 = 0
                对于 j 在范围内（n_samples）：
                    总计 += beta[j] * kernel_matrix[i][j]
                总计 += 偏差
                sigmoid_value = sigmoid(总计)
                t = y[i]

                beta += kernel_matrix[i] * alpha * (t - sigmoid_value)
                        
                偏差 += (alpha * (t - (sigmoid_value)))

        def 模型(x, beta=beta, 偏差=bias, k=k, ref=X):
            z = sum([k(ref[i], x) * beta[i] for i in range(ref.shape[0])]) + 偏差

            sig = sigmoid(z)
            # 打印（签名）
            回程(sig)
        返回模型



由于某种原因，它无法正确学习以下测试用例：
 def test4():
        
    f = lambda x, y, z, w: int(x*y*z - y**2*z*w/4 + x**4*w**3/8- y*w/2 &gt;= 0）

    训练示例 = [
        ([0.254, 0.782, 0.254, 0.569], 0),
        ([0.237, 0.026, 0.237, 0.638], 0),
        ([0.814, 0.18, 0.814, 0.707], 1),
        ([0.855, 0.117, 0.855, 0.669], 1),
        ([0.776, 0.643, 0.776, 0.628], 1),
        ([0.701, 0.71, 0.701, 0.982], 0),
        ([0.443, 0.039, 0.443, 0.356], 1),
        ([0.278, 0.105, 0.278, 0.158], 0),
        ([0.394, 0.203, 0.394, 0.909], 0),
        ([0.83, 0.197, 0.83, 0.779], 1),
        ([0.277, 0.415, 0.277, 0.357], 0),
        ([0.683, 0.117, 0.683, 0.455], 1),
        ([0.421, 0.631, 0.421, 0.015], 1)
    ]

    X, y = 地图(np.array, zip(*training_examples))

    h =logistic_regression_with_kernel(X, y, monomial_kernel(10), 0.01, 500)

    测试示例 = [
        ([0.157, 0.715, 0.787, 0.644], 0),
        ([0.79, 0.279, 0.761, 0.886], 1),
        ([0.903, 0.544, 0.138, 0.925], 0),
        ([0.129, 0.01, 0.493, 0.658], 0),
        ([0.673, 0.526, 0.672, 0.489], 1),
        ([0.703, 0.716, 0.088, 0.674], 0),
        ([0.276, 0.174, 0.69, 0.358], 1),
        ([0.199, 0.812, 0.825, 0.653], 0),
        ([0.332, 0.721, 0.148, 0.541], 0),
        ([0.51, 0.956, 0.023, 0.249], 0)
    ]
    print(f&quot;{&#39;x&#39;: ^30}{&#39;预测&#39;: ^11}{&#39;true&#39;: ^6}&quot;)
    对于 test_examples 中的 x、y：
        print(f&quot;{str(x) : ^30}{int(h(x)) : ^11}{y : ^6}&quot;)
    # x 预测为真
    # [0.157, 0.715, 0.787, 0.644] 0 0
    # [0.79, 0.279, 0.761, 0.886] 1 1
    # [0.903, 0.544, 0.138, 0.925] 0 0
    # [0.129, 0.01, 0.493, 0.658] 0 0
    # [0.673, 0.526, 0.672, 0.489] 1 1
    # [0.703, 0.716, 0.088, 0.674] 0 0
    # [0.276, 0.174, 0.69, 0.358] 1 1
    # [0.199, 0.812, 0.825, 0.653] 0 0
    # [0.332, 0.721, 0.148, 0.541] 0 0
    # [0.51, 0.956, 0.023, 0.249] 0 0

我的结果是：

我尝试将迭代次数增加到 4000，但仍然没有产生正确的结果]]></description>
      <guid>https://stackoverflow.com/questions/78463519/kernel-logistic-regression-wrong-prediction</guid>
      <pubDate>Sat, 11 May 2024 05:52:43 GMT</pubDate>
    </item>
    <item>
      <title>不平衡学习管道的哪些部分应用于测试集？</title>
      <link>https://stackoverflow.com/questions/78462616/which-parts-of-the-imbalanced-learn-pipeline-are-applied-to-the-test-set</link>
      <description><![CDATA[我对机器学习领域还很陌生，所以如果这个问题有点基础，请原谅我。
我创建了一个由 RobustScaler、SMOTE-NC、RandomUndersampling 和随机森林分类器组成的不平衡学习管道。
RandomSearchCV 用于选择最佳的超参数。
我想在我的测试集上测试最佳估计器。
cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)

缩放器 = RobustScaler(quantile_range=(25.0, 75.0))
smote = SMOTENC(categorical_features=categorical_features,抽样策略=0.35,random_state=42)
rus = RandomUnderSampler(sampling_strategy=0.35, random_state=42)
分类器 = RandomForestClassifier(random_state=42)

管道=不平衡_make_pipeline（缩放器，smote，rus，分类器）

random_search = RandomizedSearchCV(管道, param_distributions=param, 评分=scoring_metric, cv=cv, n_iter=10, random_state=42, n_jobs=-1)

best_model = random_search.fit(X_train, y_train).best_estimator_

y_pred = best_model.predict(X_test)

据我了解，只有缩放（使用 X_train 获得的设置）和分类器才应应用于测试集。 SMOTE 和 RandomUndersampling 不应应用于 X_test。
这是由不平衡学习管道保证的还是我必须考虑其他事情？]]></description>
      <guid>https://stackoverflow.com/questions/78462616/which-parts-of-the-imbalanced-learn-pipeline-are-applied-to-the-test-set</guid>
      <pubDate>Fri, 10 May 2024 21:28:24 GMT</pubDate>
    </item>
    <item>
      <title>应用一维 CNN 在不同输入标签之间进行插值</title>
      <link>https://stackoverflow.com/questions/78462567/application-of-1d-cnn-to-interpolate-between-different-input-labels</link>
      <description><![CDATA[我正在尝试应用 1d-cnn 来预测穿过不同屏蔽厚度的输出中子通量。我有一堆输入光谱（不同能量下的归一化权重的一维向量）穿过屏蔽并创建通量（也是能量的一维向量（不同能量下的数值））。我的 1d-cnn 能够在不同能量下使用不同的输入权重及其相应的输出权重（不同能量下的通量）进行训练。现在，我有不同厚度下的输入和输出权重（通量）的数据，并且想要预测是否通过给定厚度（不是训练的厚度之一）的一组权重来预测输出通量。基本上是用 1d-cnn 进行插值，可以理解不同厚度屏蔽的衰减能力之间的关系，并预测任意厚度的输出。
问题的第一级是使用 1d-cnn 网络完成的，当时我唯一的变化是作为能量函数的输入和输出通量。现在，我想添加另一个维度（基本上是一个标签）并在不同标签之间插入结果。]]></description>
      <guid>https://stackoverflow.com/questions/78462567/application-of-1d-cnn-to-interpolate-between-different-input-labels</guid>
      <pubDate>Fri, 10 May 2024 21:13:20 GMT</pubDate>
    </item>
    <item>
      <title>FileNotFoundError：[Errno 2]没有这样的文件或目录：'Models\\model_new.json'</title>
      <link>https://stackoverflow.com/questions/78461085/filenotfounderror-errno-2-no-such-file-or-directory-models-model-new-json</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;Models\\model_new.json&#39;[文本]

这是我在下面的代码中遇到的错误。怎么解决呢。项目存储库的 Github 链接发布在底部。
类应用：

    def __init__(自身):

        self.hs = Hunspell(&#39;en_US&#39;)
        self.vs = cv2.VideoCapture(0)
        self.当前图像 = 无
        self.current_image2 = 无
        self.json_file = open(&quot;Models\model_new.json&quot;, &quot;r&quot;)
        self.model_json = self.json_file.read()
        self.json_file.close()

        self.loaded_model = model_from_json(self.model_json)
        self.loaded_model.load_weights(“模型\model_new.h5”)

        self.json_file_dru = open(&quot;Models\model-bw_dru.json&quot; , &quot;r&quot;)
        self.model_json_dru = self.json_file_dru.read()
        self.json_file_dru.close()

        self.loaded_model_dru = model_from_json(self.model_json_dru)
        self.loaded_model_dru.load_weights(“模型\model-bw_dru.h5”)
        self.json_file_tkdi = open(&quot;Models\model-bw_tkdi.json&quot; , &quot;r&quot;)
        self.model_json_tkdi = self.json_file_tkdi.read()
        self.json_file_tkdi.close()

        self.loaded_model_tkdi = model_from_json(self.model_json_tkdi)
        self.loaded_model_tkdi.load_weights(“模型\model-bw_tkdi.h5”)
        self.json_file_smn = open(&quot;Models\model-bw_smn.json&quot; , &quot;r&quot;)
        self.model_json_smn = self.json_file_smn.read()
        self.json_file_smn.close()

        self.loaded_model_smn = model_from_json(self.model_json_smn)
        self.loaded_model_smn.load_weights(“模型\model-bw_smn.h5”)

https://github.com/emnikhil/Sign-Language-To -文本转换
这是我用于最后一年项目的项目，[如果您必须获取我已附加的我从中克隆项目的存储库的任何参考，则会出现此错误]
这个项目是关于使用 CNN 将美国手语转换为文本，并应用高斯模糊滤波器和灰度来减小图像的大小。我找不到问题的任何解决方案，因此我没有尝试或更改任何代码行并寻找问题的解决方案。
]]></description>
      <guid>https://stackoverflow.com/questions/78461085/filenotfounderror-errno-2-no-such-file-or-directory-models-model-new-json</guid>
      <pubDate>Fri, 10 May 2024 15:19:30 GMT</pubDate>
    </item>
    <item>
      <title>我做了什么？ :) 迁移学习方法分类所需的帮助</title>
      <link>https://stackoverflow.com/questions/78460958/what-have-i-done-help-needed-in-classifying-a-transfer-learning-approach</link>
      <description><![CDATA[我想我有一些菜鸟问题，但是，我正在尝试对方法进行分类。
在这些方法的情况下，一组特征 A（源域？）通过数值方法转换为一组特征 B（目标域）。在具体情况下，这些特征是在荷载下具有预曲率的梁 (A) 和直梁 (B) 的中心线位置矢量。我有数值方法将预曲梁的中心线位置数据转换为直梁。转换后，接受过直梁训练的学习器正在估计输入数据的负载。
它是什么样的迁移学习？
我倾向于将其称为基于映射，但在文献中我发现了三个类别：

即时
基于功能
基于模型
基于关系

我假设在将数据提供给例如之前转换数据神经网络将是基于特征的。
或者我完全一无所知，这不被认为是迁移学习。
我很高兴得到你的帮助。
提前致谢并欢呼。]]></description>
      <guid>https://stackoverflow.com/questions/78460958/what-have-i-done-help-needed-in-classifying-a-transfer-learning-approach</guid>
      <pubDate>Fri, 10 May 2024 14:55:52 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：反序列化类“BatchNormalization”时出错</title>
      <link>https://stackoverflow.com/questions/78460953/typeerror-error-when-deserializing-class-batchnormalization</link>
      <description><![CDATA[TypeError：使用 config={&#39;name&#39;: &#39;bn_conv1&#39;, &#39;trainable&#39;: False, &#39;momentum&#39;: 0.99, &#39;epsilon&#39;: 1e-05, &#39;center&#39; 反序列化类 &#39;BatchNormalization&#39; 时出错: True, &#39;scale&#39;: True, &#39;beta_initializer&#39;: {&#39;class_name&#39;: &#39;Zeros&#39;, &#39;config&#39;: {}}, &#39;gamma_initializer&#39;: {&#39;class_name&#39;: &#39;Ones&#39;, &#39;config&#39;: {}} , &#39;moving_mean_initializer&#39;: {&#39;class_name&#39;: &#39;零&#39;, &#39;config&#39;: {}}, &#39;moving_variance_initializer&#39;: {&#39;class_name&#39;: &#39;Ones&#39;, &#39;config&#39;: {}}, &#39;beta_regularizer&#39;: 无, &#39; gamma_regularizer&#39;：无，&#39;beta_constraint&#39;：无，&#39;gamma_constraint&#39;：无，&#39;freeze&#39;：True}。

遇到异常：无法识别的关键字参数传递给 BatchNormalization：{&#39;freeze&#39;: True}

这是我在使用 ImageAI 对象检测时遇到的问题。
我真的不知道该怎么办，所以我会尝试你所说的一切。谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78460953/typeerror-error-when-deserializing-class-batchnormalization</guid>
      <pubDate>Fri, 10 May 2024 14:55:08 GMT</pubDate>
    </item>
    <item>
      <title>用最少层数训练绝对函数的神经网络</title>
      <link>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</link>
      <description><![CDATA[我正在尝试训练神经网络来学习 y = |x|功能。我们知道，绝对函数有两条不同的线在零点处相互连接。所以我尝试使用以下顺序模型：
隐藏层：
2 致密层（激活relu）
输出层：
1 致密层
训练模型后，它只拟合函数的一半边。大多数时候是右手边，有时是左手边。一旦我在隐藏层中再添加 1 层，那么我就用 3 层代替 2 层，它就完全符合该功能了。谁能解释为什么当绝对函数只有一次切割时需要额外的一层？
这是代码：
将 numpy 导入为 np


X = np.linspace(-1000,1000,400)
np.random.shuffle(X)
Y = np.abs(X)

# 重塑数据以适应模型输入
X = X.reshape(-1, 1)
Y = Y.重塑(-1, 1)

将张量流导入为 tf
将张量流导入为 tf
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

# 构建模型
模型 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(2, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(1)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;])
model.fit(X, Y, epochs=1000)
# 使用模型进行预测
Y_pred = model.predict(X)

# 绘制结果
plt.scatter(X, Y, color=&#39;blue&#39;, label=&#39;实际&#39;)
plt.scatter(X, Y_pred, color=&#39;red&#39;, label=&#39;预测&#39;)
plt.title(&#39;实际与预测&#39;)
plt.xlabel(&#39;X&#39;)
plt.ylabel(&#39;Y&#39;)
plt.图例()
plt.show()

2 个密集层的绘图：

3 个密集层的绘图：
]]></description>
      <guid>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</guid>
      <pubDate>Thu, 11 Apr 2024 15:34:01 GMT</pubDate>
    </item>
    <item>
      <title>Pycharm 调试不适用于 Tensorflow。我该如何解决？</title>
      <link>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</link>
      <description><![CDATA[我已成功安装以下内容：
tensorflow（最新版本2.16.1）
keras（最新版本3.1.1

我使用的是pycharm 2023.3.5（社区版）。我有一些导入的代码行，包括张量流：
&lt;前&gt;&lt;代码&gt;...
从tensorflow.keras导入后端为K
...

每当我调试代码时，都会收到如下错误：
回溯（最近一次调用最后一次）：
文件“C:\Program Files\JetBrains\PyCharm Community Edition 2023.3.5\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_xml.py”，第 177 行，在 _get_type 中
if isinstance(o, t[0]):
   ^^^^^^^^^^^^^^^^^^^^
文件“C:\Program Files\Python312\Lib\site-packages\tensorflow\python\platform\flags.py”，第 73 行，在 __getattribute__ 中
返回 self.__dict__[&#39;__wrapped&#39;].__getattribute__(name)
       ~~~~~~~~~~~~~^^^^^^^^^^^^^
关键错误：&#39;__wrapped&#39;

我想相信问题不是由张量流引起的，但我似乎无法弄清楚确切的问题。我已经上网但无济于事。我得到的最接近的解决方案是这个 问题，但是，它似乎我作为一个不同的问题。请这个崇高平台上的博学之士来帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</guid>
      <pubDate>Fri, 29 Mar 2024 03:17:26 GMT</pubDate>
    </item>
    <item>
      <title>作为开发人员如何利用 Apple Silicon/M1 处理器上的神经引擎？</title>
      <link>https://stackoverflow.com/questions/69983492/how-to-leverage-the-neural-engine-on-apple-silicon-m1-processors-as-a-developer</link>
      <description><![CDATA[我正在努力在 SO、Google 或 Apple 的开发者文档中找到这个问题的答案。
Apple 是否为任何语言提供 API，允许开发者在 macOS 上利用新型 M1 芯片的神经引擎？
搜索Apple的开发者文档，可以找到Metal Performance Shaders库中的很多函数，似乎使用了GPU加速。
使用标签搜索SO apple-m1 或 apple-silicon 和关键字“neural”没有提供任何有用的东西。
在 r/AppleDevelopers 中搜索“神经”结果什么也没发现。
我认为必须有一些关于如何使用神经核心进行开发的信息。这些内核仅适用于 Apple 开发者和商业合作伙伴吗？]]></description>
      <guid>https://stackoverflow.com/questions/69983492/how-to-leverage-the-neural-engine-on-apple-silicon-m1-processors-as-a-developer</guid>
      <pubDate>Tue, 16 Nov 2021 03:38:01 GMT</pubDate>
    </item>
    </channel>
</rss>