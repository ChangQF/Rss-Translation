<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 18:19:33 GMT</lastBuildDate>
    <item>
      <title>使用机器学习方法选择加权平均的权重集</title>
      <link>https://stackoverflow.com/questions/78551292/using-machine-learning-approach-to-select-weight-sets-for-weighted-average</link>
      <description><![CDATA[我有一个问题，我有多个风速预测，我试图为每个预测分配不同的权重，以获得最佳的“混合”预测，从而获得最佳的预测性能。假设每个风速预测在温度和湿度等外部条件下表现不同。
我知道这可以建模为优化问题，但我很好奇这是否可以通过机器学习来解决，因为 NN 基本上是在解决优化问题，并且由权重和偏差组成。
因此，给定预测，并且可能给定外部条件（例如温度），模型会返回最佳权重选择。
期待听到大家的想法。提前谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78551292/using-machine-learning-approach-to-select-weight-sets-for-weighted-average</guid>
      <pubDate>Wed, 29 May 2024 18:08:08 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中的 k 倍交叉验证机器学习模型中提取 SHAP 值？</title>
      <link>https://stackoverflow.com/questions/78551276/extract-shap-values-in-the-context-of-a-k-fold-cross-validated-machine-learning</link>
      <description><![CDATA[为了计算具有连续结果的随机森林模型的变量重要性，我想计算 k 倍交叉验证过程每一倍的训练集和测试集上的 SHAP 值并取平均值。Scheda 等人 已经完成了这项工作，似乎在 Python 中很容易完成。但是，在 R 中似乎没有简单的方法来实现这一点。下面是我正在尝试执行的操作的模式，基于 Scheda 和 al。

这是我的所在位置，带有一个可复制的示例：

用于 k 折交叉验证的常用 for 循环


library(iml)
library(caret)
library(tidyverse)

#upload car data
data(cars)

#create the folds
folds.samp = createFolds(cars$Price,k=4,list=F)

#创建 k 倍的 for 循环预测
rf_preds = list()#样本外预测的空列表
rf_models= list()#列出模型

#for 循环：这为我提供了经过训练和验证的模型（每个折叠一个），这些模型基于训练数据，并在未见数据上进行了测试
for(j in 1:4){
rf = caret::train(Price~.,cars[folds.samp!=j,],
method = &quot;rf&quot;,
trControl=trainControl(method=&quot;cv&quot;),
ntree=150)#ntrees 通常设置为 2000 以获得稳健变量重要性，但出于示例目的设置为 150
rf_models=c(rf_models,list(rf))
rf_preds[[j]]=predict(rf,cars[folds.samp==j,])
} 



我尝试在 k 折 for 循环中加入另一个 for 循环来提取每次折叠时每行的训练 SHAP 值，但这不起作用。我知道代码很乱，但除了使用 iml 包，我不知道还有其他方法可以做到这一点，即为给定模型创建预测器对象，然后循环遍历没有结果变量的数据集。

#在 k 倍上创建 for 循环预测
rf_preds = list()#用于样本外预测的空列表
rf_models= list()#带有模型的列表
shap_vals_matrix_list=list()
#for 循环：这为我提供了经过训练和验证的模型（每个折叠一个），这些模型在训练数据上进行训练，并在看不见的数据上进行测试
for(j in 1:5){
rf = caret::train(Price~.,cars[folds.samp!=j,],
method = &quot;rf&quot;,
trControl=trainControl(method=&quot;cv&quot;),
ntree=150)#ntrees 通常设置为 2000 用于稳健变量重要性，但为了便于示例，设置为 150
rf_models=c(rf_models,list(rf))
rf_preds[[j]]=predict(rf,cars[folds.samp==j,])
###循环的 Shapley 值部分###
mod = Predictor$new(rf_models[[j]]$finalModel, data = cars)#创建预测器对象
# 创建一个空矩阵来收集结果
shap_vals &lt;- matrix(NA,nrow(cars[folds.samp!=j,]),ncol(cars)-1)
# 预测器的训练数据
X &lt;- cars[folds.samp!=j, -which(names(cars) == &quot;Price&quot;)]
# 创建一个预测器对象
predictor &lt;- Predictor$new(model = rf_models[[j]]$finalModel, data = X, y = cars[folds.samp!=j,&quot;Price&quot;])
#创建一个内部循环来计算实际的 SHAP 值
for(i in 1:nrow(cars[folds.samp!=j,])){
shapley &lt;- Shapley$new(mod, x.interest = cars[i,-1])
shap_vals[i,] = abs(shapley$results$phi)[1:(ncol(cars)-1)]
mean_shap_values &lt;- colMeans(shap_vals, na.rm = TRUE)#每行的平均值
}
shap_vals_matrix_list=c(shap_vals_matrix_list,list(mean_shap_values))
}


我需要一些帮助，使代码正常工作或使其更简单！]]></description>
      <guid>https://stackoverflow.com/questions/78551276/extract-shap-values-in-the-context-of-a-k-fold-cross-validated-machine-learning</guid>
      <pubDate>Wed, 29 May 2024 18:04:24 GMT</pubDate>
    </item>
    <item>
      <title>Azure AI ML Studio - NLP 多标签提供 0 准确度、F1、精确度、召回率</title>
      <link>https://stackoverflow.com/questions/78551138/azure-ai-ml-studio-nlp-multilabel-giving-0-accuracy-f1-precision-recall</link>
      <description><![CDATA[我正在使用 Azure automl 进行 NLP，这是一种多标签分类，其中单个预测可能涉及多个值。就我而言，我正在预测汽车单元的维修代码。我将其压缩为两列，一列是纯文本文档，包含单元品牌、型号、使用的零件以及技术人员在维修期间记录的维修步骤。第二列是我想要预测的内容，它是相关维修代码的列表。我提供了 28,000 个训练样本和 4,000 个验证样本。
无论是默认值还是超参数调整，我在准确率、精确度、召回率以及 f1 上几乎总是得到 0。在每个实例中，对数损失都是 33 到 50。当我得到这些 0 指标时，我没有从模型部署端点获得任何结果。
知道我缺少什么来改进这个场景的预测指标吗？NLP 多标签方法完全是错误的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78551138/azure-ai-ml-studio-nlp-multilabel-giving-0-accuracy-f1-precision-recall</guid>
      <pubDate>Wed, 29 May 2024 17:32:39 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 CLI 创建 Azure 机器学习工作区</title>
      <link>https://stackoverflow.com/questions/78550892/unable-to-create-an-azure-machine-learning-workspace-using-the-cli</link>
      <description><![CDATA[下午好，开发人员，我目前正在尝试使用 CLI 创建一个 Azure 机器学习工作区。我使用的代码：
az ml working create --name &quot;rg-dp100-labs&quot; --resource-group &quot;rg-dp100-labs&quot;

我收到以下错误。仅创建了 KeyVault 和存储帐户。参考此Microsoft Learn 上的链接，我发现其他人也遇到了同样的问题。甚至谷歌搜索也给了我与上面写的代码相同的代码。lease，有人遇到过同样的问题并解决了吗？我认为这是最近出现的问题。
代码：ValidationError
消息：工作区 json 中缺少依赖资源
目标：工作区
异常详细信息：（无效）工作区 json 中缺少依赖资源
代码：无效
消息：工作区 json 中缺少依赖资源
目标：工作区
]]></description>
      <guid>https://stackoverflow.com/questions/78550892/unable-to-create-an-azure-machine-learning-workspace-using-the-cli</guid>
      <pubDate>Wed, 29 May 2024 16:44:20 GMT</pubDate>
    </item>
    <item>
      <title>如何追踪多标签MLP的损失？</title>
      <link>https://stackoverflow.com/questions/78550784/how-to-track-loss-of-multi-label-mlp</link>
      <description><![CDATA[我获得了维度为 5,000 的二进制数据点。我被要求执行机器学习，预测长度为 1k 的二进制向量，其中输出的每个位置都是一个类。这些类别不互斥。
我对类别分布的了解：

索引较小的位置更常见
一个样本可以属于多个类别
每个样本仅满足少数类别要求（即输出是“稀疏的”）

如何跟踪我的 ML 模型中的损失？我使用了多层感知器（pytorch）和交叉熵损失（CE 损失），但我发现很难解释结果。我假设当您有多个类别但一次只选择一个（多类分类）时使用 CE 损失。
此外，我的预测导致向量设置了大约一半的位，而我预计设置了 20 到 50 位，不会更多。
我很乐意得到关于阅读什么、做什么或任何其他帮助的建议。
# 一个“示例”数据点：
point = [1, 0, 0, 1, 0, 0, 1, 1, ...,1, 1, 0, 0, 1, 0, 1] # 长度 5000
label = [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...,0] # 长度 1000
# 标签仅设置了 20-50 位
]]></description>
      <guid>https://stackoverflow.com/questions/78550784/how-to-track-loss-of-multi-label-mlp</guid>
      <pubDate>Wed, 29 May 2024 16:17:36 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和深度学习在 5 年或 10 年后蓬勃发展，而人工智能无法做到或我们可以说它无法进入这个领域或行业 [关闭]</title>
      <link>https://stackoverflow.com/questions/78550741/the-way-ai-deep-learning-is-booming-after-5-or-10-years-later-what-ai-will-not</link>
      <description><![CDATA[人工智能正在迅速发展，但在某些领域，它不太可能在未来 5-10 年内完全取代人类。以下是人类能力可能仍占优势的一些领域：**
社会工作和治疗：这些领域严重依赖于理解复杂的情绪、建立信任和提供个性化指导。人工智能可以协助进行数据分析和初步评估，但人类治疗师擅长建立融洽关系和提供情感支持。
客户服务：虽然人工智能聊天机器人可以处理常规查询，但复杂问题或需要同理心的问题更适合人类代表。
高度创造性的领域：
艺术、音乐创作和写作：虽然人工智能可以生成创造性的文本格式或艺术风格，但它往往缺乏人类创作作品中的原创性和情感深度。人类的创造力是由人工智能目前难以复制的经历和情感所驱动的。
pen_spar
你的文字]]></description>
      <guid>https://stackoverflow.com/questions/78550741/the-way-ai-deep-learning-is-booming-after-5-or-10-years-later-what-ai-will-not</guid>
      <pubDate>Wed, 29 May 2024 16:05:51 GMT</pubDate>
    </item>
    <item>
      <title>针对多模态目标的大型 MSE 模型</title>
      <link>https://stackoverflow.com/questions/78550210/huge-mse-model-for-multimodal-targets</link>
      <description><![CDATA[我有四个输入参数，我想预测 500 个值（表示频率函数中的电场值），所以我的数据集大约有 50000 个数据，y=50000*500……这里的目标是根据 E 的峰值推断出共振频率
我尝试使用一个简单的 CNN（带有两个卷积层）：
class CNN(nn.Module):
def init(self):
super(CNN, self).init()
self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)
self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
self.fc = nn.Linear(32 * 1, 500)

def forward(self, x):
x = F.relu(self.conv1(x))
x = F.max_pool1d(x, kernel_size=2, stride=2)
x = F.relu(self.conv2(x))
x = F.max_pool1d(x, kernel_size=2, stride=2)
x = x.view(-1, 32 * 1)
x = self.fc(x)
return x

但我获得的 MSE 很大：
Epoch [1/6], Train Loss: 26878214.0000, Val Loss: 27697948.0000 
Epoch [2/6], Train Loss: 24366062.0000, Val Loss: 27761616.0000
Epoch [3/6]，训练损失：28823276.0000，Val 损失：27700362.0000 
Epoch [4/6]，训练损失：20534644.0000，Val 损失：27853372.0000 
Epoch [5/6]，训练损失：26829138.0000，Val 损失：29004308.0000 
Epoch [6/6]，训练损失：21424500.0000，Val 损失：28001668.0000 
测试集上的均方误差 (MSE)：29475708.0`

我可以做些什么来更好地解决我的问题？模型有什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78550210/huge-mse-model-for-multimodal-targets</guid>
      <pubDate>Wed, 29 May 2024 14:25:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 CSE-CIC-IDS2018 数据集的机器学习创建网络入侵检测系统 (NIDS)？</title>
      <link>https://stackoverflow.com/questions/78549360/how-to-create-a-network-intrusion-detection-system-nids-using-machine-learning</link>
      <description><![CDATA[我目前正在开展一个名为 NetGuardian 的项目，这是一个利用机器学习来检测入侵的网络入侵检测系统 (NIDS)。我计划使用 CSE-CIC-IDS2018 数据集来训练我的模型。但是，我面临挑战，希望得到以下方面的指导：

数据预处理：


我应该如何预处理 CSE-CIC-IDS2018 数据集以实现最佳训练？
是否有推荐的特定技术或库来处理此数据集？


特征选择：


在这种情况下，特征选择的最佳实践是什么？
我应该使用提供的所有特征还是选择一个子集更好？如果是，我该如何确定哪些特征最重要？


模型选择：


哪些机器学习算法对 NIDS 最有效？
是否有特定模型在 CSE-CIC-IDS2018 数据集上表现特别好？


训练和评估：


我应该如何拆分数据集进行训练和测试以确保可靠的性能评估？
我应该使用哪些指标来评估我的 NIDS 的性能？


实施：


是否有任何教程或资源可以指导我使用机器学习构建 NIDS？
在构建过程中我应该避免哪些常见陷阱实施？

如果您能提供任何建议、资源或代码片段来帮助我开始构建 NetGuardian，我将不胜感激。
我熟悉 Python 和常用库，例如​​ Pandas、Scikit-Learn 和 TensorFlow/PyTorch。
我的目标是创建一个强大而高效的 NIDS，可以准确检测各种类型的网络入侵。
提前感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78549360/how-to-create-a-network-intrusion-detection-system-nids-using-machine-learning</guid>
      <pubDate>Wed, 29 May 2024 11:55:47 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习的均匀分布数据</title>
      <link>https://stackoverflow.com/questions/78549325/uniformly-distibuted-data-for-machine-learning</link>
      <description><![CDATA[对于线性模型，我有均匀分布的变量，例如逻辑回归、线性 SVM、MLP 假设变量服从正态分布，变量服从多重共线，对吧？如果数据服从幂律、对数正态或偏态，我们可以应用 box-cox 变换将其转换为高斯分布，现在如果数据服从正态分布，我可以直接应用模型吗？当数据服从均匀分布时，它也能很好地工作吗？如果不是，如何将均匀分布转换为正态分布？
上面提到的相同问题]]></description>
      <guid>https://stackoverflow.com/questions/78549325/uniformly-distibuted-data-for-machine-learning</guid>
      <pubDate>Wed, 29 May 2024 11:49:49 GMT</pubDate>
    </item>
    <item>
      <title>在云中运行 ML 训练的经济有效方法有哪些？[关闭]</title>
      <link>https://stackoverflow.com/questions/78549284/what-are-cost-effective-ways-to-run-ml-training-in-the-cloud</link>
      <description><![CDATA[在研究机构工作时，在集群上训练机器学习模型通常是既定做法（例如通过提交 Slurm 作业）。但是，关于在商业云中训练 ML 模型的文献似乎并不多。在云上训练 ML 模型出于各种原因可能是可取的：靠近数据、快速扩展、无需配置自己的硬件等。
是否有任何已知的经济高效的云训练方法、任何技巧或最佳实践？
以下是我在 AWS 环境中确定的方法，但我对任何云提供商的方法都感兴趣：

使用 SageMaker

优点：托管、AWS 的一流支持、无服务器
缺点：笨拙、昂贵


使用 Lambda

优点：无服务器
缺点：冷启动


使用 EC2 实例

优点：接近您使用桌面的方式
缺点：如果使用率低并且您不启动/停止它，则成本高昂按需


使用 EC2 现货实例

优点：便宜
缺点：需要编写额外的代码来处理中断


]]></description>
      <guid>https://stackoverflow.com/questions/78549284/what-are-cost-effective-ways-to-run-ml-training-in-the-cloud</guid>
      <pubDate>Wed, 29 May 2024 11:40:39 GMT</pubDate>
    </item>
    <item>
      <title>Anylogic 和 ML 模型</title>
      <link>https://stackoverflow.com/questions/78549243/anylogic-and-ml-models</link>
      <description><![CDATA[我的目标是在我的 Anylogic 模型中包含一个随机森林模型，以预测我的代理变量的值。
我见过一个 Python 连接和 ML 模型使用示例，其中包含 pyCom 库，带有 AI 的简单医院，但我甚至无法运行它。
我已经导入了 pypeline 库。
但我遇到两个错误：
第一个在运行模型之前：

无法解析导入 com.google。位置：简单医院（AI 测试平台）/患者 - 代理类型

第二个在我运行它时：

无法运行 Python 代码；反馈：TypeError(&quot;&lt;class &#39;keras.src.initializers.random_initializers.GlorotUniform&#39;&gt; 无法正确反序列化。请确保 get_config() 返回的 Python 对象实例（层、模型等）的组件在模型的 from_config() 方法中明确反序列化。\n\nconfig={&#39;module&#39;: &#39;keras.initializers&#39;, &#39;class_name&#39;: &#39;GlorotUniform&#39;, &#39;config&#39;: {&#39;seed&#39;: None, &#39;dtype&#39;: &#39;float32&#39;}, &#39;registered_name&#39;: None}.\n\n遇到异常：GlorotUniform.init() 获得了意外的关键字参数 &#39;dtype&#39;&quot;)

我的电脑上有 python，包含所有库（numpy、pandas、tensorflow、 skit-learn...) 和 pyCommunicator 似乎可以工作，因为我测试了基本教程。问题可能是第二种情况下的 keras 版本？但哪个是正确的版本？
它们可能是很容易解决的问题，但我是自学编程的，我需要更详细的指导。]]></description>
      <guid>https://stackoverflow.com/questions/78549243/anylogic-and-ml-models</guid>
      <pubDate>Wed, 29 May 2024 11:33:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 SHAP 值来表示 EEG 生物标志物和特征重要性？</title>
      <link>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-eeg-biomarker-and-feature-importance</link>
      <description><![CDATA[我做什么：
我借助不同的机器学习算法和不同的预处理步骤等分析来自 EEG 数据的不同生物标志物。这为每种预处理步骤和算法的组合产生了多个模型。
每个模型都使用 StratifiedGroupKFold 进行训练，总共 6 个折叠。
每个折叠都保存为作业库，即 .joblib
生物标志物：
EEG 信号的每个波段都有许多生物标志物。这些生物标志物又由来自 EEG 所有电极的所有信号组成。因此，生物标志物由多个特征组成，这些特征不能分开（每个生物标志物必须包含所有电极数据）。
我想做什么：
在我的第一种方法中，我用所有生物标志物训练了每个模型。现在我想使用特征重要性来确定是否可以省略其中一些。
为此，我想研究每个预处理步骤和每个模型。
有人向我推荐 SHAP，但我的问题是我不知道如何总结每个生物标志物的折叠和通道。
这是我第一次尝试至少总结折叠（例如，我仅使用一个模型中的所有折叠）：
for i, (train_index, test_index) in enumerate(sgkf.split(X, y, groups)):
X_test, y_test = X.iloc[test_index], y.iloc[test_index]

# Modell
fold_file = fold_files[i]
clf = joblib.load(fold_file)

# SHAP-Explainer
explainer = shap.LinearExplainer(clf, X_test)
shap_values = explainer.shap_values(X_test)
sv = explainer(X_test)

all_shap_values.append(shap_values)

shap_values_stacked = np.vstack([sv[1] for sv in all_shap_values])
shap_values_mean = np.abs(shap_values_stacked).mean(0) 
importance_df = pd.DataFrame({
&quot;feature&quot;: columns,
&quot;shap_values&quot;: shap_values_mean
})

我首先通过 explainer.shap_values 尝试，因为这似乎是最简单的方法。但是我无法绘制它，我需要 sv = expaliner(X)。
我的问题分为两部分：

我如何总结折叠？（平均值？）
我如何对每个生物标志物的通道进行分组？我可以添加这些值吗？或者我会扭曲结果吗？

（生物标志物的命名方式使我可以轻松识别通道）
提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78547686/how-to-use-shap-values-for-eeg-biomarker-and-feature-importance</guid>
      <pubDate>Wed, 29 May 2024 06:28:02 GMT</pubDate>
    </item>
    <item>
      <title>我得到了 ValueError: np.nan 是一个无效文档，预期是字节或 unicode 字符串</title>
      <link>https://stackoverflow.com/questions/78545256/i-got-valueerror-np-nan-is-an-invalid-document-expected-byte-or-unicode-string</link>
      <description><![CDATA[import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 读取第一个包含业务代码和说明的 Excel 文件
df1 = pd.read_excel(&quot;E:/file1.xlsx&quot;)

# 读取第二个包含业务许可证的 Excel 文件
df2 = pd.read_excel(&quot;E:/file2.xlsx&quot;)

# 初始化 TF-IDF 向量化器
tfidf_vectorizer = TfidfVectorizer()

# 将业务说明和许可证合并为一个列表
combined_text = list(df1[&#39;Business descriptions&#39;]) + list(df2[&#39;Business licences&#39;])

# 在合并的文本上拟合并转换 TF-IDF 向量化器
tfidf_matrix = tfidf_vectorizer.fit_transform(combined_text)

# 计算 TF-IDF 向量之间的余弦相似度
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# 获取余弦相似度矩阵中业务描述和许可证的索引
desc_indices = range(len(df1))
lic_indices = range(len(df1), len(df1) + len(df2))

# 创建一个字典来存储业务描述和许可证之间的映射
mapping_dict = {}

# 遍历业务描述并根据余弦相似度找到最佳匹配的许可证
for desc_idx in desc_indices:
best_match_idx = max(lic_indices, key=lambda x: cosine_sim[desc_idx][x])
映射字典[df1.loc[desc_idx, &#39;Business codes&#39;]] = df2.loc[best_match_idx - len(df1), &#39;Business licences&#39;]

# 从映射字典创建新的数据框
mapped_df = pd.DataFrame(list(mapping_dict.items()), columns=[&#39;Business codes&#39;, &#39;Mapped Business licences&#39;])

# 将映射数据保存到新的 Excel 文件
mapped_df.to_excel(&#39;mapped_data.xlsx&#39;, index=False)


嗨，我有 2 个 excel 文件。其中一个有两列，分别是业务代码和业务描述。Excel 文件 2 有一列，即业务许可证。我想对业务描述和业务许可证之间的常用词进行语义文本映射。这是我从 chatgpt 获得的代码，我收到错误：ValueError：np.nan 是无效文档，预期为字节或 unicode 字符串。
感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78545256/i-got-valueerror-np-nan-is-an-invalid-document-expected-byte-or-unicode-string</guid>
      <pubDate>Tue, 28 May 2024 15:57:51 GMT</pubDate>
    </item>
    <item>
      <title>概率编程与概率机器学习有什么区别？</title>
      <link>https://stackoverflow.com/questions/57300913/what-is-the-difference-between-probabilistic-programming-vs-probabilistic-machi</link>
      <description><![CDATA[我试图理解概率编程的概念，但我读得越多，就越感到困惑。
我目前的理解是，概率编程类似于贝叶斯网络，只是翻译成编程语言来创建自动推理模型？
我有一些机器学习的背景，我记得一些机器学习模型也输出概率，然后我遇到了概率机器学习这个术语……
两者之间有区别吗？或者它们是类似的东西？
感谢任何能帮助澄清的人。]]></description>
      <guid>https://stackoverflow.com/questions/57300913/what-is-the-difference-between-probabilistic-programming-vs-probabilistic-machi</guid>
      <pubDate>Thu, 01 Aug 2019 01:57:10 GMT</pubDate>
    </item>
    <item>
      <title>“出了点问题；所有准确度指标值均缺失：”</title>
      <link>https://stackoverflow.com/questions/38945574/something-is-wrong-all-the-accuracy-metric-values-are-missing</link>
      <description><![CDATA[我从 Brett Lantz 的教科书《机器学习与 R》中取出了以下代码，但从教科书中将相同的代码复制到了控制台，
&gt; library(caret)
正在加载所需包：lattice
正在加载所需包：ggplot2
&gt; library(kernlab)

附加包：“kernlab”

以下对象从“package:ggplot2”中屏蔽：

alpha

&gt; set.seed(300)
&gt; ctrl &lt;- trainControl(method = “cv”, number = 10)
&gt; bagctrl &lt;- bagControl(fit = svmBag$fit, predict = svmBag$pred,aggregate = svmBag$aggregate)
&gt; setwd(&quot;~/2148OS_code/chapter 11&quot;)
&gt; credit &lt;- read.csv(&quot;credit.csv&quot;)
&gt; svmbag &lt;- train(default ~ ., data = credit, &quot;bag&quot;, trControl = ctrl, bagControl = bagctrl)

我收到此回复。哪里错了？
有些不对劲；所有准确度指标值都缺失：
准确度 Kappa 
最小值：NA 最小值: NA 
第 1 组：NA 第 1 组：NA 
中位数：NA 中位数：NA 
平均值：NaN 平均值：NaN 
第 3 组：NA 第 3 组：NA 
最大值：NA 最大值：NA 
NA ：1 NA ：1 
train.default(x, y, weights = w, ...) 中的错误：正在停止
此外：有 50 个或更多警告（使用 warnings() 查看前 50 个）

警告是
&gt; warnings()
警告消息：
1：在 data.row.names(row.names, rowsi, i) 中：
一些 row.names 重复： 3,6,10,13,17,19,23,24,26,27,30,32,34,36,38,41,42,45,49,54,59,60,61,64,66,69,71,72,77,80,81,90,95,102,103,106,112,114,117,118,122,125,127,132,133,137,139,141,143,146,148,151,152,155,158,161,174,176,178,181,185,187,188,189,191,194,203,208,210,21 2,215,216,218,219,221,223,225,229,230,235,236,239,245,246,262,266,269,271,272,276,279,282,283,285,286,287,288,296,299,305,308,309,313,314,315,317,318,319,322,323,327,328,330,332,333,335,336,338,339,343,347,349,350,352,354,358,360,361,363,366,3 67,368,369,371,377,379,387,389,392,394,396,397,399,400,410,412,413,414,421,425,428,437,438,441,443,445,446,448,451,453,461,467,469,471,479,481,482,484,486,487,489,491,493,503,504,506,508,511,512,514,517,519,521,522,524,529,530,532,534,537,538, 545,547,550,552,555,562,570,579,582,584,588,589,590,601,606,608,610,611,614,615,618,619,623,627,628,629,630,632,634,636,638,641,642,645,653,656,659,660,661,663,667,669,672,673,676,679,681,686,687,690,693,700,701,702,707,708,721,722,724,725,728, [... 截断]
2：在 data.row.names(row.names, rowsi, i) 中：
一些 row.names 重复：3,5,8,9,13,15,18,21,25,27,29,33,36,37,41,44,45,51,52,53,55,59,60,64,66,67,72,76,77,80,91,92,96,97,102,103,104,107,110,111,113,116,119,121,122,123,127,130,133,136,139, 140,143,145,147,148,149,154,158,160,164,166,168,169,171,174,176,177,178,180,182,185,187,195,199,203,205,216,218,220,223,226,231,234,236,237,238,242,245,2
]]></description>
      <guid>https://stackoverflow.com/questions/38945574/something-is-wrong-all-the-accuracy-metric-values-are-missing</guid>
      <pubDate>Sun, 14 Aug 2016 18:55:47 GMT</pubDate>
    </item>
    </channel>
</rss>