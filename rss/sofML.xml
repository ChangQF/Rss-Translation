<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 19 Jul 2024 06:21:51 GMT</lastBuildDate>
    <item>
      <title>使用 Python（Numpy、Pandas）在 1000x20 矩阵中查找哪些列是其他列的线性组合的平方</title>
      <link>https://stackoverflow.com/questions/78767733/find-in-a-1000x20-matrix-which-columns-are-squares-of-linear-combinations-of-oth</link>
      <description><![CDATA[我在 csv 文件中有一个形状为 (1000, 20) 的矩阵。使用此矩阵，我需要回答以下问题：

哪些列是其他列的线性组合的平方？
哪些列是其他列的线性组合的三角函数？
哪些列是其他几列之和的函数？

我尝试使用最小二乘法回答第一个问题，但没有成功，也许是因为该方法使用不正确。我想，我应该使用某种回归，但我真的不知道如何使其有效和正确。
据我所知，我们可以将列解释为维度为 1000 的向量。我们需要找到矩阵中的哪个向量可以表示为矩阵中其他向量的线性组合的平方。
column_i = (a_1 * column_1 + a_2 * column_2 + ... + a_{i-1} * column_{i-1} + a_{i+1} * column_{i+1} + ... + a_19 * column_19)^2 
我相信，我们需要为每个向量求解上述方程。
我使用 python 来执行此操作，但不知道哪个模块更适合用于此任务以及使用哪种回归模型。
是否需要机器学习那？
如果您能为我提供此问题的详细解决方案，我将不胜感激。
带有矩阵的 csv 文件如下所示：
1000x20 矩阵]]></description>
      <guid>https://stackoverflow.com/questions/78767733/find-in-a-1000x20-matrix-which-columns-are-squares-of-linear-combinations-of-oth</guid>
      <pubDate>Fri, 19 Jul 2024 05:59:55 GMT</pubDate>
    </item>
    <item>
      <title>如何减少 AWS SageMaker 上实时机器学习模型部署的延迟？</title>
      <link>https://stackoverflow.com/questions/78767578/how-to-reduce-latency-in-real-time-machine-learning-model-deployment-on-aws-sage</link>
      <description><![CDATA[我在 AWS SageMaker 上部署的实时 ML 模型中遇到了严重的延迟。我尝试了各种实例类型、简化的预处理和模型优化，但延迟仍然存在。
我优化了实例、简化了预处理并精简了模型。预计延迟会降低，但仍然很高。]]></description>
      <guid>https://stackoverflow.com/questions/78767578/how-to-reduce-latency-in-real-time-machine-learning-model-deployment-on-aws-sage</guid>
      <pubDate>Fri, 19 Jul 2024 04:56:43 GMT</pubDate>
    </item>
    <item>
      <title>尽管数据类型为数字且形状正确，KNNImputer 仍会删除列</title>
      <link>https://stackoverflow.com/questions/78767192/knnimputer-drops-columns-despite-of-numeric-datatypes-and-right-shape</link>
      <description><![CDATA[我正在使用 KNNImputer 在几个 pd.DataFrame 中估算 np.nan 值。我检查了每个数据框的所有数据类型都是数字。但是，KNNImputer 在某些数据框中删除了一些列：
&gt;&gt;&gt;input_df.shape 
(816, 216) 

&gt;&gt;&gt; input_df.dtypes.value_count()
float64 216
dtype: int64

&gt;&gt;output_df.shape 
(816, 27)

我使用了以下 KNNImputer 配置
imputer = KNNImputer(n_neighbors=1, 
weights=&quot;uniform&quot;,
add_indicator=False)

output_df = imputer.fit_transform(input_df)

我想知道为什么会发生这种情况，因为每个数据框都有 np.nan 值。顺便说一句，参数 n_neighbors=1 不应该对结果产生任何影响，因为我正在用最近邻居的值替换缺失值。
提前谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78767192/knnimputer-drops-columns-despite-of-numeric-datatypes-and-right-shape</guid>
      <pubDate>Fri, 19 Jul 2024 01:17:35 GMT</pubDate>
    </item>
    <item>
      <title>训练帮助混合模型，该模型集成了上下文和数值特征以解决分类问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78766812/training-help-hybrid-based-model-that-integrates-contextual-and-numerical-featur</link>
      <description><![CDATA[我想要一个关键的生产风险分析问题。因此，根据记录，我想将每条记录的风险等级从 0 到 5。训练集相当不平衡。
&gt; &quot;0.0 964 
&gt; 1.0 393 
&gt; 2.0 396
&gt; 3.0 286 
&gt; 4.0 109 
&gt; 5.0 44&quot;

现在，当前训练集如下所示：
 2 风险等级 float64
3 a_weights int64 
4 b_weights float64
5 c_weights float64
6 d_weights float64
7 e_weights float64
8 f_weights float64
9 g_weights float64
10 FinalDesc 对象 

FinalDesc 列包含一个字符串（工作单的描述）。
例如：
“HVAC 更换工具因恶劣环境而无法使用。请小心修理”
我在 Final Desc 中也有关键词的权重，这将有助于排名。
但是，现在的问题是，我的主管给了我工厂特定的背景信息，这可能有助于预测。例如：
&quot;
消防监视记录被认为风险较低，
高压灭菌器上的阀门 4/5 或由于库存水平较高而通常风险较低。
用于审查 PM 详细信息的 REL 记录不会带来直接风险。
&quot;
还有更多背景信息。进行这些排名的最佳方法是什么？我应该利用 LLM 的力量吗？请让我知道整合背景的最佳方法。
我目前的方法是：

矢量化描述并添加到数据框
使用随机 Forrest 分类器对工作订单进行排名（训练、预测）。同时使用数值和描述

它的准确率为 66%。我想添加更复杂的 AI/ML 功能来解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/78766812/training-help-hybrid-based-model-that-integrates-contextual-and-numerical-featur</guid>
      <pubDate>Thu, 18 Jul 2024 21:51:38 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：在 dim 1 处预期长度为 129 的序列（得到 46）</title>
      <link>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</guid>
      <pubDate>Thu, 18 Jul 2024 18:40:37 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音转文本和翻译（直播）</title>
      <link>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</link>
      <description><![CDATA[我有一个用例，我将在直播中录制一段演讲，并且我希望实时获得音频的文本转录，然​​后翻译该转录。
我是否需要使用 Google 的语音转文本 API，然后将生成的文本发送到翻译 API，还是可以在一行中完成？]]></description>
      <guid>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</guid>
      <pubDate>Thu, 18 Jul 2024 17:21:16 GMT</pubDate>
    </item>
    <item>
      <title>我需要在时间序列预测中“转移”我的新目标变量吗？</title>
      <link>https://stackoverflow.com/questions/78765782/do-i-need-to-shift-my-new-target-variable-in-time-series-prediction</link>
      <description><![CDATA[当我有时间序列数据但不想预测序列的值时。相反，我会创建一个新的目标变量，该变量为我提供方向（1 表示增加，0 表示减少）而不是值，从而将其转化为分类问题。
我需要“转移”我的新目标变量吗？
我试过了
def binary(dataframe):
dataframe[&#39;previous_day_close&#39;] = dataframe[&#39;Close&#39;].shift(1)
dataframe[&#39;direction&#39;] = 0
dataframe.loc[dataframe[&#39;Close&#39;] &gt; dataframe[&#39;previous_day_close&#39;], &#39;direction&#39;] = 1
dataframe.drop(columns=[&#39;previous_day_close&#39;], inplace=True)
return dataframe[&#39;direction&#39;].head()

binary(petr3)

days = 3

petr3[&#39;shift_direction&#39;] = petr3[[&#39;direction&#39;]].shift(-days )

petr3.dropna(inplace = True)

petr3[&#39;shift_direction&#39;] = petr3[&#39;shift_direction&#39;].astype(&#39;int64&#39;)

有了这个，我现在可以使用分类模型对转换后的时间序列进行预测了吗？这种转变是必要的技术吗？顺便说一下，我也需要转移我的变量吗？]]></description>
      <guid>https://stackoverflow.com/questions/78765782/do-i-need-to-shift-my-new-target-variable-in-time-series-prediction</guid>
      <pubDate>Thu, 18 Jul 2024 17:01:20 GMT</pubDate>
    </item>
    <item>
      <title>lmdb.InvalidParameterError：/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc.db：参数无效</title>
      <link>https://stackoverflow.com/questions/78763677/lmdb-invalidparametererror-data-project-hsi-foundation-hypersigma-imagedenoisi</link>
      <description><![CDATA[我正在下面的 hypersigma github 上工作。请参考下面的链接。顺便说一下，我遇到了一个问题。

HyperSIGMA github 链接：https://github.com/WHU-Sigma/HyperSIGMA

输入是从下面的网站下载的 dc.tif 文件，我使用 &#39;mat_data.py&#39; 的 create_WDC_dataset 函数创建了两个 mat 文件（train_0.mat、train_1.mat）。然后我们尝试将这两个 mat 文件（train_0.mat、train_1.mat）转换为 wdc.db 文件。
我尝试通过lmdb_data.py的createDCmall函数在wdc.db文件夹中创建data.mdb，lock.mdb，meta_info.txt文件，但是没有创建meta_info.txt文件，下面是相关错误。

https://engineering.purdue.edu/~biehl/MultiSpec/hyperspectral.html
华盛顿特区购物中心图片 (145MB) --------&gt; (dc.tif)

======================命令结果开始=========================
(venv) techwinjeo@gpusystem:~/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility$ python lmdb_data.py 

create wdc...
(1587, 191, 8, 8)
地图大小 (GB): 0.17344493865966795
/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc6.db
回溯（最近一次调用）：
文件&quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 95 行，位于 &lt;module&gt;
createDCmall()
文件 &quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 85 行，位于 createDCmall
create_lmdb_train(
文件 &quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 55 行，位于 create_lmdb_train
env = lmdb.open(name+&#39;.db&#39;, map_size=map_size, writemap=True)
lmdb.InvalidParameterError: /data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc.db: 参数无效

=======================命令结果结束=========================
任何帮助都非常感谢👍
谢谢你：D
我期待在下面的文件路径中创建以下三个文件。

路径：/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc

wdc.db
|
|----- data.mdb
|----- lock.mdb
└----- meta_info.txt
]]></description>
      <guid>https://stackoverflow.com/questions/78763677/lmdb-invalidparametererror-data-project-hsi-foundation-hypersigma-imagedenoisi</guid>
      <pubDate>Thu, 18 Jul 2024 09:58:58 GMT</pubDate>
    </item>
    <item>
      <title>在模型训练中，处理 Web 应用程序上的错误输入数据时遇到困难</title>
      <link>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</guid>
      <pubDate>Thu, 18 Jul 2024 09:48:16 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的分割</title>
      <link>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</link>
      <description><![CDATA[即使将单个特征输入模型，神经网络是否也能从细分中受益？
目前我的模型具有基于用户交互和时间的特征。
如果我们根据这些特征输入一些客户细分，我的模型是否会受益？]]></description>
      <guid>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</guid>
      <pubDate>Thu, 18 Jul 2024 04:04:29 GMT</pubDate>
    </item>
    <item>
      <title>自定义参数激活函数导致 NaN 损失和权重</title>
      <link>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</guid>
      <pubDate>Wed, 17 Jul 2024 20:02:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAN 进行欺诈检测</title>
      <link>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</link>
      <description><![CDATA[我正在使用 GAN 实现基于交易的欺诈检测模型，但我仍然想指定我的模型，即我想强调 RIB 和交易时间（尤其是发行时间）我想知道个人通过这些变量（时间和 RIB）的行为如何影响交易是否是欺诈性的。基本上，这个模型很好，但它仍然很肤浅，我们需要通过强调提到的变量来更深入地研究。
我的数据集的头部
就像我说的，我尝试了一个通用的 GAN 模型，但我想实现一个专注于 RIB 和发行时间的指定 GAN 模型]]></description>
      <guid>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</guid>
      <pubDate>Wed, 17 Jul 2024 19:15:59 GMT</pubDate>
    </item>
    <item>
      <title>karateclub MUSAE 嵌入产生奇怪的列数</title>
      <link>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</link>
      <description><![CDATA[我正在试验属性节点嵌入和结构嵌入，但 karateclub 实现返回的矩阵具有奇怪的列数。
MUSAE 给出 128 个“特征”，而不是请求的 32 个。当我请求 32 个时，GLEE 给出了 33 个。我遗漏了什么吗？
import random
import numpy as np
import networkx as nx
from scipy.sparse import coo_matrix

from karateclub.node_embedding.attributed import MUSAE
from karateclub.node_embedding.neighbourhood import GLEE

g = nx.newman_watts_strogatz_graph(50, 10, 0.2)

X = {i: random.sample(range(150),50) for i in range(50)}

row = np.array([k for k, v in X.items() for val in v])
col = np.array([val for k, v in X.items() for val in v])
data = np.ones(50*50)
shape = (50, 150)

X = coo_matrix((data, (row, col)), shape=shape)

model = MUSAE(dimensions=32)
model.fit(g, X)
emb = model.get_embedding()
print(emb.shape)

model = GLEE(dimensions=32)
model.fit(g)
emb = model.get_embedding()
print(emb.shape)

输出：
(50, 128)
(50, 33)
]]></description>
      <guid>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</guid>
      <pubDate>Fri, 14 Jun 2024 15:02:08 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试使用数据集包创建数据集时，出现“无法转换，因为列名不匹配”错误</title>
      <link>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</link>
      <description><![CDATA[DataFrame 结构
上图显示了我的数据的结构。
from sklearn.model_selection import train_test_split
from datasets import Features, ClassLabel, Value, Dataset, DatasetDict

df_train, df_tmp = train_test_split(
movie_df,stratify=movie_df[&quot;label&quot;], test_size=0.2)

df_val, df_test = train_test_split(
df_tmp,stratify=df_tmp[&quot;label&quot;], test_size=0.5)

ds_features = Features({&quot;text&quot;: Value(&quot;string&quot;), &quot;label&quot;: ClassLabel(names=labels)})

dataset = DatasetDict({
&quot;train&quot;: Dataset.from_pandas(df_train.reset_index(drop=True),features=ds_features),
&quot;valid&quot;: Dataset.from_pandas(df_val.reset_index(drop=True),features=ds_features),
&quot;test&quot;: Dataset.from_pandas(df_test.reset_index(drop=True),features=ds_features)})

dataset

此代码给我一个值错误，如下所示：
错误
错误
我期望得到类似的东西，但值不一样：
DatasetDict({
train: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 13267
})
valid: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1658
})
test: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1659
})
})

有人能告诉我我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</guid>
      <pubDate>Wed, 13 Mar 2024 04:00:13 GMT</pubDate>
    </item>
    <item>
      <title>在谷歌云平台中运行 jupyter lab 时出现错误 524</title>
      <link>https://stackoverflow.com/questions/68862621/getting-error-524-while-running-jupyter-lab-in-google-cloud-platform</link>
      <description><![CDATA[我无法访问在 Google Cloud 上创建的 jupyter lab

我使用 Google AI 平台创建了一个笔记本。我能够启动它并工作，但它突然停止了，我现在无法启动它。我尝试构建并重新启动 jupyterlab，但毫无用处。我也检查了我的磁盘使用情况，只有 12%。
我尝试了诊断工具，结果如下：

但没有修复。
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/68862621/getting-error-524-while-running-jupyter-lab-in-google-cloud-platform</guid>
      <pubDate>Fri, 20 Aug 2021 12:57:57 GMT</pubDate>
    </item>
    </channel>
</rss>