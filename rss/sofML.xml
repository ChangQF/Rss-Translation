<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 02 Jan 2024 09:14:18 GMT</lastBuildDate>
    <item>
      <title>数字预测的准确度为 0%</title>
      <link>https://stackoverflow.com/questions/77744924/digit-predication-give-0-accuracy</link>
      <description><![CDATA[我需要使用袖珍算法制作一个数字分类器进行二元分类。因为这是一个 10 位数字的问题，所以我需要使用一对一的方法。我已经实现了基本的学习算法来找到每个分类器的权重。除 2 之外的所有数字的准确度约为 90%（2 的准确度很低，不太清楚为什么）

现在，当我运行测试数据时，我得到 0% 的准确度，甚至没有 1 个正确的预测。我不太确定哪里出了问题，因为看起来每个数字的准确度有点高。如果有人能指出我的错误在哪里或者我做错了什么，那就太好了。
这是代码：
将 numpy 导入为 np
# 获取mnist数据
从 sklearn.datasets 导入 fetch_openml
从 sklearn.model_selection 导入 train_test_split

mnist = fetch_openml(&#39;mnist_784&#39;, 版本=1)
x, y = mnist[&#39;数据&#39;], mnist[&#39;目标&#39;]
x = x / 255.0 # 标准化数据


# 添加偏差的函数
def add_bias(x):
    偏差 = np.ones((x.shape[0], 1))
    返回 np.concatenate((偏差, x), 轴=1)


# 返回点积的符号。用作谓词
def 预测（权重，x）：
    返回 np.sign(np.dot(x, 权重))


def update_weights(权重, x, y):
    对于范围内的 i(len(x))：
        预测 = 预测（权重，x[i]）
        if y[i] * 预测 &lt;= 0: # 错误分类
            权重 = 权重 + y[i] * x[i]
        返回权重


# 确定权重准确性的函数
def calc_acc(权重, x, y):
    预测=预测（权重，x）
    正确 = sum(预测 == y)
    返回正确的/len(y)


def Predict_all_classifiers（分类器，样本）：
    # 将每个分类器应用于样本
    预测 = [np.dot(样本, 分类器[数字]) 对于范围(10) 中的数字]
    # 选择输出值最高的分类器
    返回 np.argmax(预测)


digital_classifier = {} # 字典来存储每个分类器的权重
y = y.astype(int) # 将数据转换为整数
对于范围 (10) 中的数字：
    # 准备数据：
    y_binary = (y == digital).astype(int) * 2 - 1 # 创建二进制目标数组
    # 将数据分割为 60K 用于训练，10K 用于测试
    X_train，X_test，y_train，y_test = train_test_split（x，y_binary，train_size = 60000，test_size = 10000，random_state = 42）
    X_train = X_train.值
    X_test = X_test.值
    y_train = y_train.值
    y_test = y_test.值

    # 初始化权重向量
    权重 = np.zeros(785) # 权重向量
    X_train_bias = add_bias(X_train) # 添加偏差值
    X_test_bias = add_bias(X_test) # 添加偏差值
    pocket_weights = np.copy(权重)

    # 使用袖珍算法训练分类器 1000 个时期
    历元 = 1000
    最佳_acc = 0.0

    对于范围内的纪元（纪元）：
        curr_weights = update_weights(np.copy(pocket_weights), X_train_bias, y_train)
        curr_acc = calc_acc(curr_weights, X_train_bias, y_train)
        如果 curr_acc &gt;最佳_ACC：
            最佳_acc = 当前_acc
            pocket_weights = np.copy(curr_weights)

    print(&quot;数字的最佳准确度：&quot; + str(digit) + &quot; 是：&quot; + str(best_acc))
    digital_classifier[digit] = pocket_weights # 将分类器添加到字典中

    # 根据测试数据进行预测和评估
    正确预测 = 0
    对于范围内的 i(len(X_test_bias))：
        # 预测数字
        Predicted_digit = Predict_all_classifiers(digit_classifier, X_test_bias[i])

        # 检查预测是否正确
        如果预测数字 == y_test[i]：
            正确预测 += 1

    # 计算准确率
    准确度 = Correct_predictions / len(X_test)
    print(f&quot;测试数据的准确度：{accuracy * 100}%&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/77744924/digit-predication-give-0-accuracy</guid>
      <pubDate>Tue, 02 Jan 2024 08:35:38 GMT</pubDate>
    </item>
    <item>
      <title>加载 pcapng 文件时出现“ValueError：文件未以正确的节标题开头”</title>
      <link>https://stackoverflow.com/questions/77744885/valueerror-file-not-starting-with-a-proper-section-header-while-loading-pcapn</link>
      <description><![CDATA[代码快照
我正在尝试从 5G-DAD 数据集加载 pcapng 文件。请帮我解决错误
数据集提供者的代码
数据集提供者的github上已经给出了数据准备的代码，但是代码显示错误“Not asupported capture file”
相同代码但有错误]]></description>
      <guid>https://stackoverflow.com/questions/77744885/valueerror-file-not-starting-with-a-proper-section-header-while-loading-pcapn</guid>
      <pubDate>Tue, 02 Jan 2024 08:28:03 GMT</pubDate>
    </item>
    <item>
      <title>将 Yolov8 模型转换为 Onnx 并在 OpenCV 中使用它 [IndexError：标量变量的索引无效]</title>
      <link>https://stackoverflow.com/questions/77744584/converting-yolov8-model-to-onnx-and-used-it-in-opencv-indexerror-invalid-index</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;导入cv2
将 numpy 导入为 np

# 加载 ONNX 模型
模型 = cv2.dnn.readNetFromONNX(“best.onnx”)

# 从数据集中加载图像
image = cv2.imread(“image3.jpg”)

# 根据YOLOv8的要求对图像进行预处理（调整大小、标准化等）
# 您可能需要根据您的YOLOv8模型的具体要求调整这些预处理步骤
调整大小的图像 = cv2.resize(图像, (640, 640))
调整大小的图像 = 调整大小的图像.astype(np.float32) / 255.0
调整大小的图像 = np.transpose(调整大小的图像, (2, 0, 1))
调整大小的图像 = np.expand_dims(调整大小的图像，轴=0)

# 将预处理后的图像设置为模型的输入
model.setInput(调整大小的图像)

# 进行推理
输出 = model.forward()

# YOLOv8 输出格式通常是检测列表，其中每个检测都有：
# - 类别概率（索引 5 到末尾）
# - 客观性得分（索引 4）
# - 边界框坐标（索引 0 到 3）

# 循环检测
用于输出[0, 0]中的检测：
    Scores = detector[5:] # 获取类别概率
    class_id = np.argmax(scores) # 获取概率最大的类
    置信度 = 分数[class_id]

    # 检查头盔类别（假设头盔的类别 ID 0）和置信度阈值
    如果 class_id == 0 且置信度 &gt; 0.5: # 根据需要调整置信度阈值
        x, y, w, h = (检测[0:4] * np.array([image.shape[1], image.shape[0], image.shape[1], image.shape[0]]) ).astype(int)

        # 绘制边界框
        cv2.矩形(图像, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(图像, &quot;头盔&quot;, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

# 显示或保存带有边界框的图像
cv2.imshow(“头盔检测”, 图片)
cv2.waitKey(0)
cv2.destroyAllWindows()

我正在使用我的头盔检测模型权重来使用 opencv 来预测图片周围的类标签和边界框，但它给了我一个错误：
回溯（最近一次调用最后一次）：
文件“/home/arhamriaz/Desktop/opencvmodel/main.py”，第 30 行，位于
Scores = detector[5:] # 获取类别概率
IndexError：标量变量的索引无效。]]></description>
      <guid>https://stackoverflow.com/questions/77744584/converting-yolov8-model-to-onnx-and-used-it-in-opencv-indexerror-invalid-index</guid>
      <pubDate>Tue, 02 Jan 2024 07:08:55 GMT</pubDate>
    </item>
    <item>
      <title>像耳语这样的语音转文本 API 有哪些？</title>
      <link>https://stackoverflow.com/questions/77744493/what-are-the-speech-to-text-apis-like-whisper</link>
      <description><![CDATA[所以我需要为我的项目提供语音转文本功能。它需要是多语言的（特别是印地语和英语）
我尝试过耳语 - openAI 和它的拥抱版本。基础版本和中等版本效果最好，因为我需要高精度和快速响应，但问题是，当我使用 ai 时，基础版本比我想要的更不准确英语以外的语言。另一方面，Medium 具有出色的准确性，但需要的时间太长。还有哪些其他 API 可以替代 Whisper ??]]></description>
      <guid>https://stackoverflow.com/questions/77744493/what-are-the-speech-to-text-apis-like-whisper</guid>
      <pubDate>Tue, 02 Jan 2024 06:42:29 GMT</pubDate>
    </item>
    <item>
      <title>Model.predict() 给出相同的值 [-2147483648]</title>
      <link>https://stackoverflow.com/questions/77743313/model-predict-give-same-value-2147483648</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77743313/model-predict-give-same-value-2147483648</guid>
      <pubDate>Mon, 01 Jan 2024 20:52:09 GMT</pubDate>
    </item>
    <item>
      <title>正确处理具有可选成员（可以没有）的模型？</title>
      <link>https://stackoverflow.com/questions/77743228/handling-models-with-optional-members-can-be-none-properly</link>
      <description><![CDATA[我有 torch.nn.Module 的子类，其初始化程序具有以下形式：
（A类）
def __init__(self,additional_layer=False):
    ...
    如果附加层：
        self.additional = nn.Sequential(nn.Linear(8,3)).to(self.device)
    别的：
        self.additional = 无
    ...
    ...

我使用additional_layer=True 进行训练，并使用torch.save 保存模型。我保存的对象是model.state_dict()。然后我加载模型进行推理。但后来我收到以下错误：
model.load_state_dict(best_model[“my_model”])

RuntimeError：加载 A 的 state_dict 时出错：
        state_dict 中出现意外的键：“additional.0.weight”

是否使用了不允许为 None 的可选字段？如何正确处理这个问题？ [还发布在此处]]]></description>
      <guid>https://stackoverflow.com/questions/77743228/handling-models-with-optional-members-can-be-none-properly</guid>
      <pubDate>Mon, 01 Jan 2024 20:21:44 GMT</pubDate>
    </item>
    <item>
      <title>输入类型不支持 ufunc“isnan”，并且根据转换规则“安全”，无法将输入安全地强制为任何受支持的类型</title>
      <link>https://stackoverflow.com/questions/77743214/ufunc-isnan-not-supported-for-the-input-types-and-the-inputs-could-not-be-safe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77743214/ufunc-isnan-not-supported-for-the-input-types-and-the-inputs-could-not-be-safe</guid>
      <pubDate>Mon, 01 Jan 2024 20:14:59 GMT</pubDate>
    </item>
    <item>
      <title>自动编码器重建效果更好，但 AUC 分数更差 [关闭]</title>
      <link>https://stackoverflow.com/questions/77742912/autoencoder-better-reconstruction-but-worse-auc-score</link>
      <description><![CDATA[我编写了两个用于 Jet 重建的自动编码器，一个 MLP 和一个 CNN。在一半数据集（标签 = 0）上训练网络并将测试样本传递给经过训练的网络后，CNN 在每个测试样本上的 MSE 比 MLP 网络低得多。然而，在测试 AUC 分数时，MLP 可以更好地区分样本。 AUC 分数约为。 MLP 的 AUC 分数约为 0.8，而 CNN 的 AUC 分数约为 0.8。 0.5。
我不太确定如何解释这一点。我将其解释为 CNN 擅长重建两个数据集，即使只接受了一种类型的训练，因此它是一个糟糕的分类器。另一方面，MLP 在未经训练的数据集上重建效果较差，因此它可以更好地区分两个数据集。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/77742912/autoencoder-better-reconstruction-but-worse-auc-score</guid>
      <pubDate>Mon, 01 Jan 2024 18:20:46 GMT</pubDate>
    </item>
    <item>
      <title>“DataFrame”对象没有属性“c”</title>
      <link>https://stackoverflow.com/questions/77741177/dataframe-object-has-no-attribute-c</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77741177/dataframe-object-has-no-attribute-c</guid>
      <pubDate>Mon, 01 Jan 2024 06:55:48 GMT</pubDate>
    </item>
    <item>
      <title>使用有限数量的直线重建图像的误差函数</title>
      <link>https://stackoverflow.com/questions/77740980/error-function-to-reconstruct-an-image-using-limited-number-of-straight-lines</link>
      <description><![CDATA[我目前正在从事一个项目，我想使用直线重建黑白图像。
图像经过充分预处理，因此没有大的黑色区域。图像大多是带有曲线的白色画布。您可以在边缘检测算法之后思考类似图像的情况。我的目的是仅使用 N 条直线重建图像。 N 将是一个很小的数字，比如说 100。所以基本上，这就像尝试将图像还原为可以用少量线条绘制的非常合成的版本。
我的主要挑战在于确定合适的方法或损失函数来准确比较原始图像与其重建图像。由于我使用直线来近似图像中存在的复杂形状和细节，均方误差 (MSE) 或平均绝对误差 (MAE) 等标准指标可能无法充分捕捉两种表示之间的相似性。
有人可以推荐一种更合适的损失函数或评估方法来衡量原始图像与其基于线的重建之间的保真度吗？我对解释用直线近似弯曲或复杂形状的性质的方法特别感兴趣。
此外，如果有人对通常用于使用线条进行图像近似的特定技术或算法有经验或知识，我将非常感谢任何相关资源的指示或参考。我找到了 这篇 codegolf 帖子，但方法不同。在那里，他们用颜色和线条重建了整个图像。
我想要使用的示例图像如下：

]]></description>
      <guid>https://stackoverflow.com/questions/77740980/error-function-to-reconstruct-an-image-using-limited-number-of-straight-lines</guid>
      <pubDate>Mon, 01 Jan 2024 04:39:57 GMT</pubDate>
    </item>
    <item>
      <title>我的张量流项目的测试集准确性较低，有人可以建议如何提高该项目的准确性吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77740755/accuracy-is-low-on-test-set-of-my-tensorflow-project-can-any-one-suggest-how-to</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77740755/accuracy-is-low-on-test-set-of-my-tensorflow-project-can-any-one-suggest-how-to</guid>
      <pubDate>Mon, 01 Jan 2024 01:32:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么“sklearn.svm.LinearSVC”的执行时间比“sklearn.svm.SVC”要长？ [复制]</title>
      <link>https://stackoverflow.com/questions/77731956/why-is-sklearn-svm-linearsvc-taking-longer-to-execute-than-sklearn-svm-svc</link>
      <description><![CDATA[我正在使用 scikit-learn 中的 LinearSVC 和 SVC 类执行超参数调整，尽管我使用  执行的搜索量增加了 10 倍SVC类比LinearSVC执行时间短很多，可能是什么原因呢？我认为 LinearSVC 更优化。
我正在使用 Olivetti 面孔数据集
这是我正在执行的两个搜索：
从 sklearn.svm 导入 LinearSVC
从 sklearn.svm 导入 SVC
从 sklearn.model_selection 导入 GridSearchCV

#LinearSVC超参数调优------------------------
参数网格 = [
    {&#39;svc__C&#39;: np.logspace(-3,3, num=10)}
]

full_pipeline = 管道([
    (“预处理”, StandardScaler(with_mean=False)),
    (“svc”,LinearSVC(random_state=0))
    ]）

svc_rnd_search = GridSearchCV(full_pipeline, param_grid=param_grid, cv=10,
                           评分=&#39;准确度&#39;,n_jobs=-1)

# 测量执行时间
开始时间 = 时间()

#运行搜索
svc_rnd_search.fit(X_train, y_train)

# 计算执行时间
结束时间 = 时间()
执行时间毫秒 = (结束时间 - 开始时间) * 1000
print(f&quot;执行时间: {execution_time_ms:.3f}ms&quot;)

#SVC超参数调优------------------------------------------------
参数网格 = [
    {&#39;svc__C&#39;: np.logspace(-2,3, num=10),
     &#39;svc__gamma&#39;: np.logspace(-5,1, num=10),
     &#39;svc__kernel&#39;: [&#39;rbf&#39;]}
]

full_pipeline = 管道([
    (“预处理”, StandardScaler(with_mean=False)),
    (“svc”,SVC())
    ]）

svc_rnd_search = GridSearchCV(full_pipeline, param_grid=param_grid, cv=10,
                           评分=&#39;准确度&#39;,n_jobs=-1)

# 测量执行时间
开始时间 = 时间()

#运行搜索
svc_rnd_search.fit(X_train, y_train)

# 计算执行时间
结束时间 = 时间()
执行时间毫秒 = (结束时间 - 开始时间) * 1000
print(f&quot;执行时间: {execution_time_ms:.3f}ms&quot;)

第一个代码块 (LinearSVC) 的执行时间为 1087635 毫秒，而 SVC 类的执行时间为 36961 毫秒。]]></description>
      <guid>https://stackoverflow.com/questions/77731956/why-is-sklearn-svm-linearsvc-taking-longer-to-execute-than-sklearn-svm-svc</guid>
      <pubDate>Fri, 29 Dec 2023 12:18:51 GMT</pubDate>
    </item>
    <item>
      <title>递归特征消除如何决定支持某个特征？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77731220/how-does-a-recursive-feature-elimination-decide-to-support-a-feature</link>
      <description><![CDATA[RFE 使用的基本算法是什么？RFE 如何决定支持哪些功能以及不支持哪些功能？]]></description>
      <guid>https://stackoverflow.com/questions/77731220/how-does-a-recursive-feature-elimination-decide-to-support-a-feature</guid>
      <pubDate>Fri, 29 Dec 2023 09:39:26 GMT</pubDate>
    </item>
    <item>
      <title>预测后如何取消数据缩放？</title>
      <link>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</link>
      <description><![CDATA[我有一个具有 2 个特征（价格和数量）的数据集1 个预测变量（价格），并使用 LTSM 模型根据前一组价格预测下一个价格。
首先我缩放数据集：
#缩放数据
缩放器 = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(数据集)

最后我想取消缩放：
#获取模型预测价格值
预测 = model.predict(x_test)
预测=scaler.inverse_transform(预测)

但这不起作用，我收到此错误：
ValueError：形状为 (400,1) 的不可广播输出操作数与广播形状 (400,2) 不匹配
]]></description>
      <guid>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</guid>
      <pubDate>Wed, 12 Aug 2020 16:20:50 GMT</pubDate>
    </item>
    <item>
      <title>sklearn LinearSVC 是 SVM 还是 SVC？</title>
      <link>https://stackoverflow.com/questions/61974843/is-sklearn-linearsvc-an-svm-or-svc</link>
      <description><![CDATA[我正在观看 YouTube 视频来了解支持向量机 (SVM)。
在视频中，他提到 SVM 会找到支持向量分类器 (SVC) 来划分数据，作为分类过程中的一个步骤。
我使用了LinearSVC&lt; /a&gt; 来自 scikit-learn 进行分类，但我很难理解 scikit-learn 中 LinearSVC 的实现是 SVM 还是 SVC，或者视频中的描述是否不正确。我发现不同网站上的描述相互矛盾。

此问题中接受的答案&lt; /a&gt; 表明 LinearSVC 不是 SVM，但也没有说它是 SVC。
在 LinearSVC 的描述页面上显示“线性支持向量分类”，但在“另请参阅”下显示了“线性支持向量分类”。在此页面它说 LinearSVC 是“使用 liblinear 实现的用于分类的可扩展线性支持向量机”。

据我所知，LinearSVC 和 SVC(kernel=&#39;linear&#39;) 并不相同，但这不是问题所在。]]></description>
      <guid>https://stackoverflow.com/questions/61974843/is-sklearn-linearsvc-an-svm-or-svc</guid>
      <pubDate>Sat, 23 May 2020 16:03:37 GMT</pubDate>
    </item>
    </channel>
</rss>