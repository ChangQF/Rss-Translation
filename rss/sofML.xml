<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 08 Mar 2024 18:18:33 GMT</lastBuildDate>
    <item>
      <title>使用 Tensorflow API 进行对象检测 - 没有名为“tensorflow.python.keras.layers.preprocessing”的模块</title>
      <link>https://stackoverflow.com/questions/78129120/object-detection-with-tensorflow-api-no-module-named-tensorflow-python-keras</link>
      <description><![CDATA[我遵循了教程Tensorflow 2 对象检测 API 教程  并收到以下错误：
找不到模块“official.legacy”
我执行了以下步骤：

打开 PowerShell
cd C:\Users\Administrator\Desktop\TestTensorflow
conda create -n tensorflow pip python=3.11
conda 激活张量流
pip install --ignore-installed --upgrade tensorflow
使用验证脚本：
python -c &quot;将张量流导入为 tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))&quot;

结果：成功

为了降低复杂性，第一步跳过了 GPU 支持

下载并安装 TensorFlow Model Garden 的对象检测 API https://github.com/tensorflow/模型（主分支）

将 .zip 文件夹解压到 C:\Users\Administrator\Desktop\TestTensorflow\Tensorflow
将生成的文件夹“model-master”重命名为“models”

cd C:\Users\Administrator\Desktop\TestTensorflow\Tensorflow\models\research

protoc object_detection/protos/*.proto --python_out=.

pip 安装 cython

pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI

cp object_detection/packages/tf2/setup.py 。
结果：成功安装pycocotools-2.0

python -m pip install .

使用python object_detection/builders/model_builder_tf2_test.py测试安装”
结果 = 错误（参见屏幕截图）

]]></description>
      <guid>https://stackoverflow.com/questions/78129120/object-detection-with-tensorflow-api-no-module-named-tensorflow-python-keras</guid>
      <pubDate>Fri, 08 Mar 2024 16:47:46 GMT</pubDate>
    </item>
    <item>
      <title>在谷歌驱动器中使用yolov8训练自定义数据集</title>
      <link>https://stackoverflow.com/questions/78129048/training-custom-dataset-using-yolov8-in-google-drive</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78129048/training-custom-dataset-using-yolov8-in-google-drive</guid>
      <pubDate>Fri, 08 Mar 2024 16:34:20 GMT</pubDate>
    </item>
    <item>
      <title>如何优化非线性损失函数？</title>
      <link>https://stackoverflow.com/questions/78129032/how-to-optimize-a-non-linear-loss-function</link>
      <description><![CDATA[当可训练参数显示为线性系数时，优化损失函数很容易，但如果可训练参数是指数形式怎么办？
导入tensorflow为tf
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
opt = tf.keras.optimizers.legacy.SGD(learning_rate=0.001)
e = 2.718281828459045

类测试：
    def __init__(自身, A):
        自我.A = A
    def 函数（自身）：
        返回 e**( 参数 * self.A )

定义损失（）：
    测试=测试（1。）
    x = (test.function()-148.4131591025766)**2
    print(&#39;损失：&#39; + str(x.numpy()))
    打印（）
    返回x

参数 = tf.Variable(1.001, 可训练=False, dtype=np.float32)
参数_t = []

对于范围 (10) 内的 ii：
    print(&#39;参数：&#39; + str(param.numpy()))
    opt.minimize(loss, var_list=[param])
    param_t.append(param.numpy())

Fig, ax = plt.subplots()
ax.plot(param_t)
plt.show()在这里输入

优化器将可训练参数param带到-无穷大，同时损失函数增加！但是，正确的答案应该是 param=1 和 loss=0。
如何修改我的代码？]]></description>
      <guid>https://stackoverflow.com/questions/78129032/how-to-optimize-a-non-linear-loss-function</guid>
      <pubDate>Fri, 08 Mar 2024 16:30:33 GMT</pubDate>
    </item>
    <item>
      <title>使用predict和predict_proba计算ROC AUC有什么区别？</title>
      <link>https://stackoverflow.com/questions/78128804/what-is-the-difference-between-using-predict-and-predict-proba-to-calculate-roc</link>
      <description><![CDATA[此代码使用 .predict_proba 并采用类别 1 的值：
# 导入sklearn.metrics包
从 sklearn.metrics 导入 roc_auc_score
# 使用 .predict_proba 计算 roc 准确度分数
pred=sktree.predict_proba(x_test)[:,1]
roc=roc_auc_score(y_test,pred)
print(&quot;决策树分类器的 roc 准确度得分为 {0:1.3f}&quot;.format(roc))
]]></description>
      <guid>https://stackoverflow.com/questions/78128804/what-is-the-difference-between-using-predict-and-predict-proba-to-calculate-roc</guid>
      <pubDate>Fri, 08 Mar 2024 15:43:05 GMT</pubDate>
    </item>
    <item>
      <title>经典机器学习方法对初始变量的敏感性[关闭]</title>
      <link>https://stackoverflow.com/questions/78128617/sensitivity-to-initial-variables-of-classical-ml-methods</link>
      <description><![CDATA[以下哪种机器学习算法对优化算法中使用的初始变量不敏感？
A.隐马尔可夫模型
B.人工神经网络
C.随机森林
D.支持向量机
E. k-最近邻
我认为 A 和 B 很敏感。至于 C，由于引导，随机森林对初始变量不那么敏感。 D 并不那么敏感，因为当我们训练模型时，无论初始变量如何，软边际都会收敛到适当的值。 E 很敏感，因为参数 k 很重要。]]></description>
      <guid>https://stackoverflow.com/questions/78128617/sensitivity-to-initial-variables-of-classical-ml-methods</guid>
      <pubDate>Fri, 08 Mar 2024 15:10:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 LSTM 进行时间序列预测的异常[关闭]</title>
      <link>https://stackoverflow.com/questions/78127888/anomaly-in-time-series-forecasting-using-lstm</link>
      <description><![CDATA[我正在使用 LSTM 进行时间序列预测，有些数据被视为异常值，但有这些值是正常的，我是否应该考虑删除或纠正这些值？它会影响我的 LSTM 模型吗？
我绘制了数据分布图，可以看出它不是正态分布的。
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78127888/anomaly-in-time-series-forecasting-using-lstm</guid>
      <pubDate>Fri, 08 Mar 2024 13:08:25 GMT</pubDate>
    </item>
    <item>
      <title>设置和训练模型以根据过去的注册预测事件注册的最佳方法[关闭]</title>
      <link>https://stackoverflow.com/questions/78127837/best-way-to-set-up-and-train-a-model-to-predict-event-registration-based-on-past</link>
      <description><![CDATA[我正在尝试找出根据之前的注册和其他人口统计因素（年龄、性别、收入等）来预测某人是否会注册参加活动的最佳方法
我有一个包含大约 4 万人的数据库可供使用。我的问题是，根据前几年的出勤率来训练/测试模型，然后使用相同的数据来预测明年的出勤率，这是一种不好的做法吗？我应该在这里采取什么方法？
我的利益相关者希望获得今年活动数据库中每个人的预测分数。所以我不能仅仅将某些人作为训练值而忽略。
我目前已经建立了一个逻辑回归模型，并根据去年的注册对其进行了训练]]></description>
      <guid>https://stackoverflow.com/questions/78127837/best-way-to-set-up-and-train-a-model-to-predict-event-registration-based-on-past</guid>
      <pubDate>Fri, 08 Mar 2024 12:59:14 GMT</pubDate>
    </item>
    <item>
      <title>无法进行网格搜索和训练模型</title>
      <link>https://stackoverflow.com/questions/78127612/not-able-to-do-grid-search-and-train-the-model</link>
      <description><![CDATA[我正在研究基本的文本分类问题，我想使用堆叠分类器以及对基本分类器的参数进行一些微调以获得高精度结果。
我的数据集有 8000 行和 2 列（文本和类）。下面的代码似乎被卡住了，我不熟悉该领域（初学者）来发现问题。
导入 pandas 作为 pd
从 sklearn.model_selection 导入 GridSearchCV，train_test_split
从 sklearn.ensemble 导入 StackingClassifier
从 sklearn.linear_model 导入 LogisticRegression
从 sklearn.svm 导入 NuSVC
从 sklearn.discriminant_analysis 导入 LinearDiscriminantAnalysis
从sklearn.metrics导入accuracy_score、log_loss、classification_report、confusion_matrix

# 定义分类器的参数网格
param_grid_nusvc = {
    “努”：[0.1，0.3，0.5，0.7，0.9]，
    &#39;内核&#39;：[&#39;线性&#39;，&#39;rbf&#39;]，
}

param_grid_logreg = {
    ‘C’: [0.1, 1, 10],
    &#39;惩罚&#39;: [&#39;l1&#39;, &#39;l2&#39;],
}

# 以更高的清晰度执行分类器的网格搜索
nusvc_grid_search = GridSearchCV(NuSVC(probability=True), param_grid_nusvc, cv=2, rating=&#39;accuracy&#39;) # 使用准确率评分
logreg_grid_search = GridSearchCV(LogisticRegression(), param_grid_logreg, cv=2, 评分=&#39;准确度&#39;)

nusvc_grid_search.fit(X_train, y_train)
logreg_grid_search.fit(X_train, y_train)

# 获取最佳参数
best_params_nusvc = nusvc_grid_search.best_params_
best_params_logreg = logreg_grid_search.best_params_

# 设置具有最佳参数的基分类器
best_nusvc = NuSVC(概率=True, **best_params_nusvc)
best_logreg = LogisticRegression(**best_params_logreg)

# 设置堆叠分类器
sc = 堆叠分类器(
    估计量=[
        (&#39;NuSVC&#39;, best_nusvc),
        （&#39;LDA&#39;，线性判别分析（））
    ],
    最终估计器=best_logreg
）

sc.fit(X_train, y_train)

# 评估组合分类器
print(&#39;****结果****&#39;)
train_predictions = sc.predict(X_test)
acc = 准确度_分数(y_test, train_predictions)
print(&quot;准确度: {:.4%}&quot;.format(acc))

train_predictions_proba = sc.predict_proba(X_test)
ll = log_loss(y_test, train_predictions_proba)
print(&quot;对数丢失: {}&quot;.format(ll))

# 打印分类报告（可选）
print(&#39;\n分类报告:&#39;)
打印（分类报告（y_test，train_predictions））

# 打印混淆矩阵（可选）
print(&#39;\n混淆矩阵:&#39;)
打印（confusion_matrix（y_test，train_predictions））

上面的一些更改是根据 chatGPT 的建议进行的，以指导我如何使用网格搜索进行微调。代码似乎卡住了（大约 20 分钟）。如果没有网格搜索，它似乎可以轻松地在 2-3 分钟内运行。]]></description>
      <guid>https://stackoverflow.com/questions/78127612/not-able-to-do-grid-search-and-train-the-model</guid>
      <pubDate>Fri, 08 Mar 2024 12:17:54 GMT</pubDate>
    </item>
    <item>
      <title>发生异常：ValueError 数据基数不明确：x 大小：1280 y 大小：32 确保所有数组包含相同数量的样本</title>
      <link>https://stackoverflow.com/questions/78127570/exception-has-occurred-valueerror-data-cardinality-is-ambiguous-x-sizes-1280</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78127570/exception-has-occurred-valueerror-data-cardinality-is-ambiguous-x-sizes-1280</guid>
      <pubDate>Fri, 08 Mar 2024 12:09:21 GMT</pubDate>
    </item>
    <item>
      <title>CreateML 模型添加到我的应用程序时无法按预期工作[关闭]</title>
      <link>https://stackoverflow.com/questions/78127234/createml-model-doesnt-work-as-expected-when-added-to-my-application</link>
      <description><![CDATA[我有一个训练有素的模型来识别深蹲（好的和坏的重复）。当我使用一些测试数据预览它时，它似乎在 CreateML 中完美运行，尽管将其添加到我的应用程序后，模型似乎不准确，并且大多数时候会混淆操作。有谁知道问题是否与代码相关，或者与模型本身及其如何分析实时数据有关？
下面我添加了“Good Squats”功能之一大多数时候甚至不会被调用（即使信心较低）。大多数时候，模型将所有事情都归为糟糕的深蹲，尽管事实显然并非如此。
问题可能是我的数据集没有足够的视频吗？
如果操作==“GoodForm” &amp;&amp;信心&gt; 0.80&amp;&amp; !squatDetected {
            打印（“好形式”）
            蹲检测=真
            
            DispatchQueue.main.asyncAfter(截止日期: .now() + 1.5) {
                self.squatDetected = false
            }
            DispatchQueue.main.async {
                self.showGoodFormAlert（带有：信心）
                音频服务PlayAlertSound（系统声音ID（1322））
            }
        }

我尝试过使用不同的 fps 设置和动作持续时间训练其他模型。目前我拥有的最好的设置是：120FPS 1.5s 动作持续时间。
更改了我的预测函数，使其仅分析每 10（以及每 20）帧而不是每帧。还是什么都没有]]></description>
      <guid>https://stackoverflow.com/questions/78127234/createml-model-doesnt-work-as-expected-when-added-to-my-application</guid>
      <pubDate>Fri, 08 Mar 2024 11:03:19 GMT</pubDate>
    </item>
    <item>
      <title>cnn 代码有问题，可能是班级讲师问题 [已关闭]</title>
      <link>https://stackoverflow.com/questions/78126559/problem-with-a-cnn-code-maybe-instructor-problem-of-the-class</link>
      <description><![CDATA[我建立了一个 CNN
将 numpy 导入为 np
进口火炬
将 torch.nn 导入为 nn

CNN 类（nn.Module）：
 def __init__(自身):
  超级（CNN，自我）.__init__()
    自我.n = 10
    内核大小 = 3
    填充 = (内核大小 - 1) / 2
    self.conv1 = nn.Conv2d(in_channels=3,out_channels=self.n,kernel_size=kernel_size,stride = (2,2),padding=padding)

    self.conv2 = nn.Conv2d(in_channels=self.n,out_channels=2*self.n,kernel_size=kernel_size,stride = (2,2),padding=padding)
        
    self.conv3 = nn.Conv2d(in_channels=2*self.n,out_channels=4*self.n,kernel_size=kernel_size,stride = (2,2),padding=padding)
    
    self.conv4 = nn.Conv2d(in_channels=4*self.n,out_channels=8*self.n,kernel_size=kernel_size,stride = (2,2),padding=padding)
    
    self.fc1 = nn.Linear(8 * self.n * 7 * 4, 100)
    self.fc2 = nn.Linear(100, 2)

 def 转发（自身，inp）：
   输出 = nn.function.relu(self.conv1(inp))
   输出 = nn.function.relu(self.conv2(out))
   输出 = nn.function.relu(self.conv3(out))
   输出 = nn.function.relu(self.conv4(out))

   出=出。视图(-1, 8 * self.n * 7 * 4)
   输出 = nn.function.relu(self.fc1(out))
   输出 = self.fc2(输出)
    
   返回

输入数据inp是形状为(N,3,448,224)的张量，输出形状为(N,2)。
问题是我收到错误：
TypeError: conv2d() 收到了无效的参数组合 - got (Tensor, Parameter, Parameter, tuple, tuple, tuple, int)，但需要以下之一：
 *（张量输入、张量权重、张量偏差、整数步幅元组、整数填充元组、整数膨胀元组、整数组）
      不匹配，因为某些参数的类型无效： (Tensor, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (float, float)!, !tuple of (int, int)!, int)
 *（张量输入、张量权重、张量偏差、整数步幅元组、str 填充、整数膨胀元组、整数组）
      不匹配，因为某些参数的类型无效： (Tensor, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (float, float)!, !tuple of (int, int)!, int)

有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78126559/problem-with-a-cnn-code-maybe-instructor-problem-of-the-class</guid>
      <pubDate>Fri, 08 Mar 2024 09:05:17 GMT</pubDate>
    </item>
    <item>
      <title>尽管张量是叶子，但神经网络中的损失却没有得到任何结果</title>
      <link>https://stackoverflow.com/questions/78126160/getting-none-from-loss-in-neural-network-despite-tensors-being-leaf</link>
      <description><![CDATA[我检查了所有的张量和输入参数，它们都是叶子，根据下面的代码，
def train_step(w1,b1):
    打印（“w=”，w1）
    可训练变量 = [w1,b1]
    优化器 = torch.optim.SGD(trainable_variables, lr=learning_rate)
    损失=变量（loss2_function（），requires_grad = True）
    打印(loss.backward())
    使用 torch.no_grad()：
        w1 -=(学习率 * w1.grad)
        b1 -= (学习率 * b1.grad)
        w1.grad.zero_()
        b1.grad.zero_()
    优化器.step()
    优化器.zero_grad()

我仍然没有得到任何结果，即使学习率、权重和偏差发生变化，网络仍然无法工作，请指导我。]]></description>
      <guid>https://stackoverflow.com/questions/78126160/getting-none-from-loss-in-neural-network-despite-tensors-being-leaf</guid>
      <pubDate>Fri, 08 Mar 2024 07:42:18 GMT</pubDate>
    </item>
    <item>
      <title>物体检测（Opencv）[关闭]</title>
      <link>https://stackoverflow.com/questions/78125895/object-detectionopencv</link>
      <description><![CDATA[我尝试过精简版的 SSD MobileNet 模型来检测对象，但我的主要动机是
应该检测未经训练的对象，如果该对象在我们的数据集中不可用，那么它应该被检测为未知对象。
我该怎么做？
我需要的解决方案是我的模型应该将对象检测为未知对象，而无需机器学习。
我不想认出这个物体。只是应该使用 python opencv 检测对象。]]></description>
      <guid>https://stackoverflow.com/questions/78125895/object-detectionopencv</guid>
      <pubDate>Fri, 08 Mar 2024 06:34:43 GMT</pubDate>
    </item>
    <item>
      <title>siann的解决方案有一个问题： ValueError: Variable <tf.Variable 'u/bias:0' shape=(1,) dtype=float64> has `None` forgradient</title>
      <link>https://stackoverflow.com/questions/78125337/there-is-a-problem-with-scianns-solution-valueerror-variable-tf-variable-u</link>
      <description><![CDATA[使用scinn求解偏微分方程时出现问题，结果显示：
&lt;块引用&gt;
ValueError：变量 渐变有“无”。请确保您的所有操作都定义了梯度（即可微分）。无梯度的常见操作：K.argmax、K.round、K.eval。

导入数学
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 siann 导入为 sn
从 siann.utils.math 导入 diff、sign、sin、cos、tan、exp、sqrt、pow


亩=0.20
罗 = 1000
xE = 21*1000000000
G = xE/(2*(1 + mu))
cp = math.sqrt(xE*(1 - mu)/(rho*(1 + mu)*(1 - 2*mu)))
r0 = 2.5
xdb = 100/1000
xdp = 2.5*100/1000
ρ0 = 1000
xD = 4000
SB = 4000/1000
r0 = 3.0
b = 2.0
阿尔法 = 2000

# 计算A0
定义 A0():
    term1 = xdb/(8*sb)*rho0*xD**2
    项 2 = (xdp/xdb)**2.2
    返回第 1 项/第 2 项

# 待解变量
r = sn.Variable(&#39;r&#39;, dtype=&#39;float64&#39;)
z = sn.Variable(&#39;z&#39;, dtype=&#39;float64&#39;)
t = sn.Variable(&#39;t&#39;, dtype=&#39;float64&#39;)
u = sn.Functional(&#39;u&#39;, [r, z, t], 4*[40], &#39;tanh&#39;)

# 偏微分方程
PDE1= diff(u,r,阶=2)+1/r*diff(u,r)+diff(u,z,阶=2)-1/cp*diff(u,t,阶=2)


＃边界条件
公差=0.0000001
BC1= (1-符号(t-TOL))*(1-符号(r-r0-TOL))*(diff(u,z))
BC2=(1+符号(z-TOL))*(1-符号(z-b-TOL))*(1-符号(r-r0-TOL))*(xE/(1+mu)*(mu/( 1-2*mu)*(diff(u,r,阶=2)+diff(u,r)/r+diff(u,z,阶=2))+diff(u,r,阶=2) )-A0()*exp(-1*alpha*t))

# 训练和验证模型
m = sn.SciModel([r,z,t], [PDE1, BC1,BC2])
r_data,z_data,t_data = np.meshgrid(
    np.linspace(r0, 10, 40),
    np.linspace(0, 5, 40),
    np.linspace(0, 0.001, 100)
）
 
# 这一步出错了
h = m.train([r_data,z_data,t_data], 3*[&#39;零&#39;],learning_rate=0.002, epochs=1000, verbose=0)

r_test,z_test ,t_test = np.meshgrid(
    np.linspace(0, 10, 40),
    np.linspace(0, 5, 40),
    np.linspace(0, 0.001, 80)
）
u_pred = u1.eval(m, [r_test,z_test ,t_test])

图 = plt.figure(figsize=(3, 4))
plt.pcolor(r_test, z_test, u_pred, cmap=&#39;地震&#39;)
plt.xlabel(&#39;r&#39;)
plt.ylabel(&#39;z&#39;)
plt.colorbar()

我试图解决它，然后在 h = m.train(...) 步骤出现了 ValueError。]]></description>
      <guid>https://stackoverflow.com/questions/78125337/there-is-a-problem-with-scianns-solution-valueerror-variable-tf-variable-u</guid>
      <pubDate>Fri, 08 Mar 2024 03:00:25 GMT</pubDate>
    </item>
    <item>
      <title>Hard Voting 如何在 scikit-learn 的 VotingClassifier 中选择偶数个分类器的结果？</title>
      <link>https://stackoverflow.com/questions/48991245/how-does-hard-voting-select-a-result-with-an-even-number-of-classifiers-in-a-vot</link>
      <description><![CDATA[我在投票分类器中有两个分类器，它们都用于预测实例是 0 类还是 1 类。结果是使用硬投票（使用多数投票）进行聚合的，但是我不确定 VotingClassifier 是如何进行聚合的使用偶数个分类器做出决策。]]></description>
      <guid>https://stackoverflow.com/questions/48991245/how-does-hard-voting-select-a-result-with-an-even-number-of-classifiers-in-a-vot</guid>
      <pubDate>Mon, 26 Feb 2018 14:54:46 GMT</pubDate>
    </item>
    </channel>
</rss>