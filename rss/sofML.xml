<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 06 Jan 2024 12:23:37 GMT</lastBuildDate>
    <item>
      <title>RandomizedSearchCV 独立于集成中的模型</title>
      <link>https://stackoverflow.com/questions/77769033/randomizedsearchcv-independently-on-models-in-an-ensemble</link>
      <description><![CDATA[假设我构建了两个估计器的集合，其中每个估计器运行自己的参数搜索：
导入和回归数据集：
从 sklearn.ensemble 导入 VotingRegressor、StackingRegressor、RandomForestRegressor
从 sklearn.tree 导入 DecisionTreeRegressor
从 sklearn.datasets 导入 make_regression

从 sklearn.model_selection 导入 RandomizedSearchCV

X, y = make_regression()

定义两个自调整估计器，并将它们组合起来：
rf_param_dist = dict(n_estimators=[1, 2, 3, 4, 5])
rf_searcher = RandomizedSearchCV(RandomForestRegressor(), rf_param_dist, n_iter=5, cv=3)

dt_param_dist = dict(max_深度=[4, 5, 6, 7, 8])
dt_searcher = RandomizedSearchCV(DecisionTreeRegressor(), dt_param_dist, n_iter=5, cv=3)

合奏 = StackingRegressor(
    [（&#39;rf&#39;，rf_searcher），（&#39;dt&#39;，dt_searcher）]
).fit(X, y)

我的问题是关于sklearn如何处理ensemble的拟合。
Q1）我们有两个并行的未拟合估计器，并且都需要在 ensemble.predict(...) 工作之前进行拟合。但是，如果没有首先从整体中获得预测，我们就无法拟合任何估计器。 sklearn 如何处理这种循环依赖？
Q2）由于我们有两个运行独立调整的估计器，每个估计器是否会错误地假设另一个估计器的参数是固定的？因此，我们最终遇到了一个定义不明确的优化问题。
&lt;小时/&gt;
作为参考，我认为联合优化集成模型的正确方法是定义一个联合搜索所有参数的 CV，如下所示。但我的问题是关于 sklearn 如何处理前面描述的特殊情况。
#联合优化
合奏 = VotingRegressor(
    [ (&#39;rf&#39;, RandomForestRegressor()), (&#39;dt&#39;, DecisionTreeRegressor()) ]
）

jointsearch_param_dist = 字典(
    rf__n_estimators=[1, 2, 3, 4, 5],
    dt__max_深度=[4,5,6,7,8]
）

ensemble_jointsearch = RandomizedSearchCV(ensemble, jointsearch_param_dist)
]]></description>
      <guid>https://stackoverflow.com/questions/77769033/randomizedsearchcv-independently-on-models-in-an-ensemble</guid>
      <pubDate>Sat, 06 Jan 2024 10:35:42 GMT</pubDate>
    </item>
    <item>
      <title>主动机器学习 - 在训练前预测模型的大部分信息数据</title>
      <link>https://stackoverflow.com/questions/77768656/active-machine-learning-predict-most-informative-data-for-the-model-before-tra</link>
      <description><![CDATA[我正在开展一个项目，我的目标是通过黑盒方法对电子电路进行建模（端到端建模，而不开发实际电路）。该电路接收四个输入，包括输入信号和范围在 0 到 5 之间的电位计（旋钮）值。
通过使用大量随机值，我的目标是开发一个能够将这些输入映射到输出的模型，并将电位计值用作模型的调节值。
然而，挑战是用最少的数据训练这个模型，因为数据收集非常耗时。我有兴趣找到一种方法，根据给定旋钮设置的过去和当前状态/损耗值，可以识别哪些旋钮值会产生最丰富的数据。这样，我可以将数据收集集中在这些特定值上，然后使用这些数据进行训练。
任何有关此主题的相关文献或资源的建议将不胜感激。
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/77768656/active-machine-learning-predict-most-informative-data-for-the-model-before-tra</guid>
      <pubDate>Sat, 06 Jan 2024 07:55:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在 aws sagemaker 无服务器推理上运行 Github 公共模型？</title>
      <link>https://stackoverflow.com/questions/77768620/how-to-run-github-public-models-on-aws-sagemaker-serverless-inference</link>
      <description><![CDATA[我想在 AWS Sagemaker 无服务器推理上运行来自 Github 的开源公共模型（例如  https://github.com/ai-forever/Kandinsky-3）。我希望它在 AWS Sagemaker 无服务器上运行，因为我希望在需要时使用 API，并且只需为推理付费。问题是我不知道从哪里开始。我问了 3 个不同的 AI，得到了 3 个不同的答案，但不知道哪一个是正确的。
有人可以帮我指出正确的方向吗？任何提示、教程、一般步骤列表等将不胜感激！谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77768620/how-to-run-github-public-models-on-aws-sagemaker-serverless-inference</guid>
      <pubDate>Sat, 06 Jan 2024 07:37:53 GMT</pubDate>
    </item>
    <item>
      <title>裂纹检测的预处理和算法</title>
      <link>https://stackoverflow.com/questions/77768422/pre-processing-and-algorithm-for-crack-detection</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77768422/pre-processing-and-algorithm-for-crack-detection</guid>
      <pubDate>Sat, 06 Jan 2024 06:11:59 GMT</pubDate>
    </item>
    <item>
      <title>最适合分类器算法的音频文件格式是什么？</title>
      <link>https://stackoverflow.com/questions/77767853/what-is-the-best-suited-audio-file-format-for-a-classifier-algorithm</link>
      <description><![CDATA[用于分类器算法的长录音（约 2 小时）的最佳文件格式是什么？
我的用例：
&lt;块引用&gt;
假设我想训练一个分类器，它可以计算出
房间里正在交谈的人数。
我想我想要一个包含数小时对话音频的数据集
记录下来，每个时间戳都标记有多少人在
给定时间的房间。
然后，我可以对录制的文件进行监督学习，并且
训练一个模型，它可以告诉我有多少人拥有
在任何给定时间进行对话。

我最初的想法是录制WAV，但是这些会不会变得很大，有没有更适合的文件格式？]]></description>
      <guid>https://stackoverflow.com/questions/77767853/what-is-the-best-suited-audio-file-format-for-a-classifier-algorithm</guid>
      <pubDate>Sat, 06 Jan 2024 00:37:11 GMT</pubDate>
    </item>
    <item>
      <title>单独更新 TensorFlow 中的指标</title>
      <link>https://stackoverflow.com/questions/77766703/updating-the-metrics-in-tensorflow-separately</link>
      <description><![CDATA[我编写了一个自定义指标：
类 ReidClassificationAccuracy(tf.keras.metrics.Metric)：
    def __init__(self, name=“accuracy_position_distance_thresholding”, with_visibility=False, with_occlusion=False,
                 参数={}, **kwargs):
        super(ReidClassificationAccuracy, self).__init__(name=name, **kwargs)
        self.accuracy = self.add_weight(name=“准确度”, 初始值设定项=“零”)
        self.num_samples = self.add_weight(name=“num_samples”, 初始值设定项=“零”)

    def update_state（自身，pids，cls_score_list，sample_weight =无）：
        总体评分 = 0
        对于 cls_score_list 中的 cls_score：
            总体 cls_score += cls_score
        self.accuracy = self.compute_accuracy(overall_cls_score, pids, [1])[0]
        返回自我准确度

    默认结果（自身）：
        返回 self.accuracy / self.num_samples

    def Reset_states(自身):
        self.accuracy.assign(0.)
        self.num_samples.分配(0.)

    defcompute_accuracy（自身，输出，目标，topk=[1]）：
        &quot;&quot;&quot;&quot;&quot;计算指定的 k 值的 precision@k&quot;&quot;&quot;&quot;
        最大k = 最大(topk)
        批量大小 = 目标大小(0)

        _, pred = 输出.topk(maxk, 1, True, True)
        pred = pred.t()
        正确 = pred.eq(target.view(1, -1).expand_as(pred))

        分辨率=[]
        对于 topk 中的 k：
            Correct_k = Correct[:k].view(-1).float().sum(0, keepdim=True)
            res.append( Correct_k )
        返回资源

现在，由于其输入与其他指标不同，并且不是 y_pred 和 y_trues，因此我想单独更新该指标的状态。目前，我使用以下方法更新指标：
model.compiled_metrics.update_state(y_trues, y_preds) # 更新指标

但是，我无法单独更新 Reid 指标。我尝试将其编写在 for 循环中，但 model.compiled_metrics 不可迭代。]]></description>
      <guid>https://stackoverflow.com/questions/77766703/updating-the-metrics-in-tensorflow-separately</guid>
      <pubDate>Fri, 05 Jan 2024 19:07:02 GMT</pubDate>
    </item>
    <item>
      <title>预测复数（绝对值和相位）的物理问题的线性回归</title>
      <link>https://stackoverflow.com/questions/77766687/linear-regression-for-physical-problem-predicting-complex-number-absolute-and-p</link>
      <description><![CDATA[我正在尝试进行线性回归，它进行一些物理测量，然后预测各种物理值。这些物理值之一是复数，因此我尝试将其分成两部分并分别预测幅度和相位。
我需要将幅度限制在 0 和 1 之间。在我的例子中，唯一可能的幅度值在 0 到 1 之间。允许网络预测超出此范围的值会解锁一系列退化解决方案，因此网络与真实预测相去甚远。
为了限制这一点，我对幅度输出应用了 sigmoid 激活函数。这有时有效。然而，幅度的真实值非常接近零（阶数 10^{-4}，这意味着它们接近 sigmoid 的尾部。这有时会导致损失和梯度在 100 个左右的 epoch 后变为 NaN。是否存在预测复数或限制回归问题输出的更好方法？
我尝试过降低学习率、增加批量大小并使用各种不同的架构，但没有成功。我还尝试在不使用 sigmoid 函数约束输出神经元的情况下解决问题，但这使得问题变得如此退化，以至于网络无法接近正确的解决方案。我还尝试过将幅度变换得更大（即接近 0.5），然后再将其变换回来。
就上下文而言，我的损失函数是
$$L = \frac{1}{n} \sum^n_i (f_{true} - f(a_{pred}, b_{pred}, |c_{pred}|, c_{pred}^{ \phi})^2$$
其中$f_{true})$是我们已知的东西，$a$和$b$是我们试图预测的东西，$c$是我们试图预测的复数。]]></description>
      <guid>https://stackoverflow.com/questions/77766687/linear-regression-for-physical-problem-predicting-complex-number-absolute-and-p</guid>
      <pubDate>Fri, 05 Jan 2024 19:03:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么 cartpole 奖励不收敛</title>
      <link>https://stackoverflow.com/questions/77766359/why-cartpole-reward-is-not-converge</link>
      <description><![CDATA[通过此图像，训练损失和期望值随着时间的推移而收敛，但每个情节的回报没有收敛，即使是伟大的情节。
这是我的训练循环代码：
对于范围内的剧集（500）：
    状态，信息 = env.reset()
    状态 = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)
    总奖励 = 0

    对于 count() 中的 t：
        env.render()
        状态 = torch.FloatTensor(状态).to(设备)
        动作 = agent.selectAction(状态,agent.learn_step_counter)
        观察、奖励、完成、_ = env.step(action.item())[:4]

        总奖励+=奖励
        奖励 = torch.tensor([奖励], 设备=设备)
        next_state = torch.tensor(观察, dtype=torch.float32, device=device).unsqueeze(0)
        
        replay_buffer.push（状态，动作，next_state，奖励）
        
        状态 = 下一个状态
        
        代理内存 = replay_buffer
        代理.learn()
        如果完成：
            休息

在此处输入图像描述
有什么方法可以帮助看到收敛吗？]]></description>
      <guid>https://stackoverflow.com/questions/77766359/why-cartpole-reward-is-not-converge</guid>
      <pubDate>Fri, 05 Jan 2024 17:51:33 GMT</pubDate>
    </item>
    <item>
      <title>ML 模型与 ReactNative 集成</title>
      <link>https://stackoverflow.com/questions/77764870/ml-model-integration-with-reactnative</link>
      <description><![CDATA[我正在尝试集成以检查 React Native 中的 ML 模型。我在 google colab 上制作了一个模型，并将训练后的模型保存为 Model.pkl 和 Model.joblib 现在我想将此模型集成到我的 React Native 应用程序中，但我不知道方法，请帮助我！
我一直在尝试在chatgpt的帮助下运行，但它对我不起作用]]></description>
      <guid>https://stackoverflow.com/questions/77764870/ml-model-integration-with-reactnative</guid>
      <pubDate>Fri, 05 Jan 2024 13:23:18 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 haar 级联找到使用网络摄像头的人的参与度？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades</link>
      <description><![CDATA[我正在建立一个网站，在编写考试时跟踪用户以了解他们的参与程度，并为此找到了这篇有趣的论文。
https://www.sciencedirect .com/science/article/pii/S0045790621002597?ref=cra_js_challenge&amp;fr=RR-1
我想使用 opencv 和 tensorflow 构建完全相同的模型。有人可以帮我完成模型吗？我是机器学习领域的新手。刚刚建立了一些回归和分类模型。任何帮助都会非常有帮助。我无法理解如何从上述论文中计算聚焦概率。我希望了解如何构建模型以及如何计算值的详细步骤。
数据集链接：
FER 2013：https://www.kaggle.com/datasets/msambare/fer2013&lt; /a&gt;
MES数据集：https://github.com/Harsh9524/MES-Dataset
我已经使用 haar 级联检测到人脸并且它正在工作。下一个问题是找出情绪，我也做到了！但问题在于寻找 MES 和焦点概率。请帮我解决一下。]]></description>
      <guid>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades</guid>
      <pubDate>Thu, 04 Jan 2024 20:42:19 GMT</pubDate>
    </item>
    <item>
      <title>DataFrame'对象没有属性'符号</title>
      <link>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</link>
      <description><![CDATA[我想使用机器学习创建股票价格预测，但出现“‘DataFrame’对象没有属性‘符号’”我的错误是什么以及如何修复它
将 numpy 导入为 np
将 pandas 导入为 pd
从sklearn导入预处理
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression

def prepare_data(df,forecast_col,forecast_out,test_size) :
    label = df[forecast_col].shift(-forecast_out) #创建名为 label 的新列，最后 5 行为 nan
    X = np.array(df [[forecast_col]]) #创建特征数组
    X = preprocessing.scale(X) #处理特征数组
    X_lately = X[-forecast_out:] #创建我想稍后在预测方法中使用的列
    X = X[:-forecast_out] # X 将包含训练和测试
    label.dropna(inplace=True) #删除na值
    y = np.array(label) # 分配 Y
    X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=test_size, random_state=0) #交叉验证

    响应 = [X_train,X_test,Y_train,Y_test,X_lately]
    返回响应

df = pd.read_csv(“GOOG.csv”)
df = df[df.symbol == &quot;GOOG&quot;]- &quot;错误信息出现的位置&quot;
Forecast_col = “关闭”
预测输出 = 5
   

测试大小 = 0,2

X_train、X_test、Y_train、Y_test、X_lately = 准备数据（df、forecast_col、forecast_out、test_size）
学习者 = 线性回归()
learner.fit (X_train,Y_train )
Score=learner.score(X_test,Y_test)#测试线性回归模型
Forecast= learner.predict(X_lately) #将包含预测数据的集合
响应={}#creting json 对象
响应[&#39;test_score&#39;]=分数
响应[&#39;forecast_set&#39;]=预测

打印（响应）
]]></description>
      <guid>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</guid>
      <pubDate>Thu, 04 Jan 2024 01:24:44 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17)</title>
      <link>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</link>
      <description><![CDATA[
第 1 步：创建管道
第2步：将管道转换为数据帧
第3步：我正在尝试将管道转换为数据帧，但出现异常。如何解决这个问题
第 4 步：如何解决 ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17) 在管道转换为数据帧之上，

from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
从 sklearn.impute 导入 SimpleImputer
从 sklearn.pipeline 导入管道
从 sklearn.compose 导入 ColumnTransformer

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split

print(&quot;步骤1：导入lib&quot;)
print(&quot;第2步：加载原始数据&quot;)
df = pd.read_csv(“online_shoppers_intention.csv”)

print(&quot;第三步：数据准备&quot;)
X = df.drop([&#39;收入&#39;], axis = 1)
y = df[&#39;收入&#39;]

print(&quot;第四步：数据分割&quot;)
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size = .3、random_state = 0)
名称 = X_train.columns.tolist()

numeric_transformer = SimpleImputer(策略 = &#39;常量&#39;)
categorical_transformer = OneHotEncoder(handle_unknown = &#39;忽略&#39;)

numeric_cols = X.select_dtypes(exclude = &quot;object&quot;).columns.values.tolist()
categorical_cols = X.select_dtypes(exclude = [&#39;int&#39;, &#39;float64&#39;, &#39;bool&#39;]).columns.values.tolist()
    
预处理器 = ColumnTransformer(
    变形金刚=[
    (&#39;num&#39;, numeric_transformer, numeric_cols)
    ,(&#39;猫&#39;, categorical_transformer, categorical_cols)
    ],
    余数 = &#39;直通&#39;)

pipeline_preprocessor = Pipeline(steps = [(“预处理器”, 预处理器), (“pandarizer”, FunctionTransformer(lambda x: pd.DataFrame(x, columns = 名称)))]).fit(X_train)
    
X_train_pipe = pipeline_preprocessor.transform(X_train)
X_test_pipe = pipeline_preprocessor.transform(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</guid>
      <pubDate>Wed, 03 Jan 2024 07:51:34 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：使用 URL 'http://127.0.0.1:8237' 初始化剩余存储时出错：模块 'jwt' 没有属性 'encode'</title>
      <link>https://stackoverflow.com/questions/77730757/runtimeerror-error-initializing-rest-store-with-url-http-127-0-0-18237-mo</link>
      <description><![CDATA[第一个命令python run_deployment.py --config deploy成功运行并建议我运行下一个命令 - zenml up
zenml up 生成以下错误。







我正在 YouTube 上关注 Ayush 的 MLOPs 课程。感谢您提前提供的帮助。
我试过了
&lt;前&gt;&lt;代码&gt;1。 pip 安装 jwt
2.pip安装PyJWT
3. pip卸载jwt
4. pip安装jwt==1.3.0
5. pip install --upgrade --force-reinstall PyJWT
6. pip install --upgrade --force-reinstall jwt
]]></description>
      <guid>https://stackoverflow.com/questions/77730757/runtimeerror-error-initializing-rest-store-with-url-http-127-0-0-18237-mo</guid>
      <pubDate>Fri, 29 Dec 2023 07:34:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 python 中的 AI 和 ML 库编写一个 python 程序来预测游戏的下一个结果（从两种颜色中选择一种颜色）</title>
      <link>https://stackoverflow.com/questions/76086477/how-to-make-a-python-program-to-predict-the-next-outcome-of-a-game-of-picking-a</link>
      <description><![CDATA[我想使用 LSTM 技术在 python 中编写一个程序，可以预测下一个结果，或者说从两种颜色中选择一种颜色的概率，该程序应该使用 AI 和 ML 库，来读取最后 40 个结果的模式从而预测下一个结果。
嗯，我为此制定了以下计划。
从 keras.models 导入顺序
从 keras.layers 导入 LSTM，密集
将 numpy 导入为 np


def Predict_next_color_lstm（结果）：
    如果 len(结果) &lt; 40：
        返回“错误：提供的结果数量小于 40。”

    # 将字符串输入转换为整数序列
    seq = [如果 x == &#39;r&#39; 则为 0，否则结果中的 x 为 1]

    # 创建 40 个结果的滚动窗口
    X = []
    y = []
    对于范围内的 i(len(seq) - 40)：
        X.append(seq[i:i + 40])
        y.append(seq[i + 40])
    X = np.array(X)
    y = np.array(y)

    # 重塑 X 以适应 LSTM 输入形状
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))

    # 创建LSTM模型
    模型=顺序（）
    model.add(LSTM(50, input_shape=(40, 1)))
    model.add（密集（1，激活=&#39;sigmoid&#39;））

    # 编译模型
    model.compile(loss=&#39;binary_crossentropy&#39;, 优化器=&#39;adam&#39;)

    # 训练模型
    model.fit(X, y, epochs=50, batch_size=32)

    # 预测下一个结果
    最后_40 = seq[-40:]
    pred = model.predict(np.array([last_40]))
    如果 pred &lt;，则返回 &#39;r&#39; 0.5 其他“g”


def get_input():
    # 要求用户输入长度为40的球颜色序列
    ball_seq = input(&quot;输入长度为 40 的球颜色序列（例如 rrggrrgrrgggrgrgrgrggggrgrgrrgrgggrrgggg）：&quot;)
    返回 ball_seq


＃ _主要的_
ball_seq = get_input()
print(“预测：”,predict_next_color_lstm(ball_seq))

但我在执行时不断收到以下错误：
C:\Users\Ashish\miniconda3\python.exe C:\Users\Ashish\Desktop\pyt_pract\test_prob1.py
输入长度为 40 的球颜色序列（例如 rrggrrgrrgggrgrgrggrrggggrgrgrrgrgggrrgggg）： rgggrrgrgrggrrgrgrgrggggrrrrggrrggrgrg
回溯（最近一次调用最后一次）：
文件“C:\Users\Ashish\Desktop\pyt_prac\test_prob1.py”，第 50 行，位于
print(“预测：”,predict_next_color_lstm(ball_seq))
文件“C:\Users\Ashish\Desktop\pyt_prac\test_prob1.py”，第 23 行，位于 Predict_next_color_lstm 中
X = np.reshape(X, (X.shape[0], X.shape[1], 1))
IndexError：元组索引超出范围]]></description>
      <guid>https://stackoverflow.com/questions/76086477/how-to-make-a-python-program-to-predict-the-next-outcome-of-a-game-of-picking-a</guid>
      <pubDate>Sun, 23 Apr 2023 18:08:18 GMT</pubDate>
    </item>
    <item>
      <title>用于分类特征的 LabelEncoder？</title>
      <link>https://stackoverflow.com/questions/61217713/labelencoder-for-categorical-features</link>
      <description><![CDATA[这可能是一个初学者问题，但我见过很多人使用 LabelEncoder() 用序数替换分类变量。很多人通过一次传递多个列来使用此功能，但是我对我的某些功能中的序数错误以及它将如何影响我的模型有些怀疑。这是一个例子：
输入
导入 pandas 作为 pd
将 numpy 导入为 np
从 sklearn.preprocessing 导入 LabelEncoder

a = pd.DataFrame([&#39;高&#39;,&#39;低&#39;,&#39;低&#39;,&#39;中&#39;])
le = 标签编码器()
le.fit_transform(a)

输出
数组([0, 1, 1, 2], dtype=int64)

如您所见，序数值未正确映射，因为我的 LabelEncoder 只关心列/数组中的顺序（应该是 High=1、Med=2、Low=3，反之亦然）。错误的映射会对模型产生多大的影响？除了 OrdinalEncoder() 之外，是否有一种简单的方法可以正确映射这些值？]]></description>
      <guid>https://stackoverflow.com/questions/61217713/labelencoder-for-categorical-features</guid>
      <pubDate>Tue, 14 Apr 2020 21:40:52 GMT</pubDate>
    </item>
    </channel>
</rss>