<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 15 Dec 2023 12:25:31 GMT</lastBuildDate>
    <item>
      <title>是否可以直接在张量流上运行使用 mediapipe 重新训练的对象检测模型，而不是使用 mediapipe？</title>
      <link>https://stackoverflow.com/questions/77666162/is-it-possible-to-run-object-detection-models-retrained-with-mediapipe-on-tensor</link>
      <description><![CDATA[我正在使用此 mediapipe 指南来重新训练对象检测模型，并将其导出到 tflite 模型。我想在反应原生中使用该模型。不幸的是，mediapipe 没有直接的 React-Native 实现，但我有一个可以在 RN 中运行任何 .tflite 模型的库。
起初我以为我只需要使用 mediapipe 来重新训练我的模型，但现在我在示例中意识到我还需要 mediapipe 用于检测部分。所以我想知道是否也可以直接在张量流中运行使用 mediapipe 创建的模型？
第一次测试后，我得到了以下形状的对象检测模型的“位置”输出：和“分数”：
&lt;前&gt;&lt;代码&gt;((1, 19125, 4), (1, 19125, 4))

位置的形状对我来说很有意义，但是我应该如何解释“分数”？数据？或者在没有媒体管道的情况下运行模型没有意义吗？非常感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/77666162/is-it-possible-to-run-object-detection-models-retrained-with-mediapipe-on-tensor</guid>
      <pubDate>Fri, 15 Dec 2023 12:08:03 GMT</pubDate>
    </item>
    <item>
      <title>OutOfMemoryError：LLM 中的 CUDA 内存不足</title>
      <link>https://stackoverflow.com/questions/77665954/outofmemoryerror-cuda-out-of-memory-in-llm</link>
      <description><![CDATA[我有一个文本列表，我需要将每个文本发送到大型语言模型（llama2-7b）。但是我遇到了 CUDA 内存不足错误。我在 Google Colab 上的 A100 上运行。这是我的尝试：
path = “meta-llama/Llama-2-7b-chat-hf”
tokenizer = LlamaTokenizer.from_pretrained(路径)
模型 = LlamaForCausalLM.from_pretrained(path).to(“cuda”)


def actuate_with_model(查询, input_text=&quot;&quot;):
    if pd.isna(input_text): return (“NaN”)
    别的：
        提示=查询+输入文本
        输入 = tokenizer(提示, return_tensors=“pt”, return_attention_mask=False).to(“cuda”)
        generate_ids = model.generate(**输入)
        输出 = tokenizer.batch_decode(outputs)[0]
        返回输出


def process_data(查询,批处理):
  回复 = []
  对于范围内的 i(len(batch))：
      响应 = interact_with_model(查询, 批次[i])
      响应.追加（响应）
  返回响应



query_1 = “总结以下文本”
响应_1 = []
对于范围内的 i(0,len(输入),50)：
    sub_inputs = 输入[i:i+50]
    response_1.append(process_data(query_1,batch=sub_inputs))

我尝试每次向模型发送 50 个样本的文本，但这也不起作用。问题出在哪里？]]></description>
      <guid>https://stackoverflow.com/questions/77665954/outofmemoryerror-cuda-out-of-memory-in-llm</guid>
      <pubDate>Fri, 15 Dec 2023 11:25:41 GMT</pubDate>
    </item>
    <item>
      <title>AutoTrain 高级 CLI：错误：无法识别的参数：--fp16 --use-int4</title>
      <link>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</link>
      <description><![CDATA[我目前在使用提供的自动训练工具在 Colab 笔记本中使用 LLM 模型微调数据时遇到问题。错误消息表明 autotrain 无法识别参数“--fp16”和“--use-int4”。我已经检查了文档和语法，但问题仍然存在。您能否提供解决此问题的指导或提供有关任何潜在解决方案的见解？谢谢。
&lt;前&gt;&lt;代码&gt;
/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13：UserWarning：无法加载图像Python扩展：&#39;/usr/local/lib/python3.10/dist-packages/ torchvision/image.so: 未定义符号: _ZN3c104cuda9SetDeviceEi&#39;如果您不打算使用 `torchvision.io` 中的图像功能，则可以忽略此警告。否则，您的环境可能有问题。在从源代码构建“torchvision”之前，您是否安装了“libjpeg”或“libpng”？ warn( 用法: autotrain  [] AutoTrain 高级 CLI: 错误: 无法识别的参数: --fp16 --use-int4

错误的屏幕截图
直到昨天，这段代码在这个 https://github.com/huggingface/autotrain-advanced 存储库中给出的 colab 笔记本上运行良好微调LLM，现在出现此错误。]]></description>
      <guid>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</guid>
      <pubDate>Fri, 15 Dec 2023 07:53:31 GMT</pubDate>
    </item>
    <item>
      <title>训练神经网络 - 米粒簇还是单个米粒？</title>
      <link>https://stackoverflow.com/questions/77664557/training-a-neural-network-cluster-of-rice-grains-or-individual-rice-grains</link>
      <description><![CDATA[训练神经网络 - 米粒簇还是单个米粒？
我正在尝试创建水稻品种分类。
关于训练数据，我可以做一簇米饭来填满整个图像
或者每张图片仅 1 粒米。
如果是单个米粒：
米粒的背景怎么样？我将使用什么？...或者数据增强是否足以使其减少对特定背景的依赖？
我尝试研究并发现了不同的论文。我们有多个答案，我试图在这里找到更多意见]]></description>
      <guid>https://stackoverflow.com/questions/77664557/training-a-neural-network-cluster-of-rice-grains-or-individual-rice-grains</guid>
      <pubDate>Fri, 15 Dec 2023 06:16:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将我的前端与 google colab 上的机器学习模型集成？</title>
      <link>https://stackoverflow.com/questions/77664369/how-to-integrate-my-front-end-with-a-machine-learning-model-on-google-colab</link>
      <description><![CDATA[我希望将我用于预测的机器学习模型与前端连接起来，这样我就可以拥有一个从用户收集数据的 UI，以便模型可以读取数据并根据其训练给出结果。
我尝试在 YouTube 上寻找答案，但找不到太多帮助]]></description>
      <guid>https://stackoverflow.com/questions/77664369/how-to-integrate-my-front-end-with-a-machine-learning-model-on-google-colab</guid>
      <pubDate>Fri, 15 Dec 2023 05:14:07 GMT</pubDate>
    </item>
    <item>
      <title>使用深度学习选择关键帧[关闭]</title>
      <link>https://stackoverflow.com/questions/77663856/keyframe-selection-using-deep-learning</link>
      <description><![CDATA[我想使用深度学习从视频片段中选择单个关键帧。我有一堆发生特定事件的视频片段。我想选择它发生的确切关键帧。
任何想法都会非常有帮助。
提前致谢。
我正在考虑在原始帧和光流帧上应用CNN，结合特征并应用lstm。类的数量就是帧的数量，它会在事件发生的帧上预测 1，在其他地方预测 0。]]></description>
      <guid>https://stackoverflow.com/questions/77663856/keyframe-selection-using-deep-learning</guid>
      <pubDate>Fri, 15 Dec 2023 01:32:55 GMT</pubDate>
    </item>
    <item>
      <title>Conv1D 输入形状</title>
      <link>https://stackoverflow.com/questions/77663705/conv1d-input-shape-for</link>
      <description><![CDATA[我正在针对分类问题训练 CNN。输入形状是一个 x_train.shape = (6352,) 的数字，我有 10 个类。
我构建了这个模型：
# 添加 Conv1D 层
输入形状=(6352,1)

模型 = keras.Sequential()

model.add(keras.layers.Conv1D(16，kernel_size=3，activation=&#39;relu&#39;，input_shape=input_shape))
model.add(keras.layers.MaxPooling1D(pool_size=3))

model.add(keras.layers.Conv1D(32,kernel_size=2,activation=&#39;relu&#39;))
model.add(keras.layers.MaxPooling1D(pool_size=3))

model.add(keras.layers.Flatten())
model.add（keras.layers.Dense（64，激活=&#39;relu&#39;））
model.add(keras.layers.Dropout(0.5))
model.add(keras.layers.Dense(10, 激活=&#39;softmax&#39;))

模型.summary()

但是当我尝试拟合模型时，我得到了这个：
警告：tensorflow：模型是使用输入 KerasTensor 的形状 (None, 6352, 1) 构建的(type_spec=TensorSpec(shape=(None, 6352, 1), dtype=tf.float32, name=&#39;conv1d_3_input &#39;), name=&#39;conv1d_3_input&#39;, description=“由层 &#39;conv1d_3_input&#39; 创建”)，但它是在形状不兼容的输入上调用的（无，）。

 ValueError：调用层“sequential_3”（类型 Sequential）时遇到异常。
    
    层“conv1d_3”的输入0与图层不兼容：预期 min_ndim=3，发现 ndim=1。收到完整形状：（无，）
    
    调用层“sequential_3”接收的参数（类型 Sequential）：
      输入=tf.Tensor（形状=（无，），dtype=float32）
      • 训练=真
      • 掩码=无

如何知道正确的输入形状以及如何通过层跟踪形状以便模型可以工作？
我尝试了几种输入形状，但没有任何效果]]></description>
      <guid>https://stackoverflow.com/questions/77663705/conv1d-input-shape-for</guid>
      <pubDate>Fri, 15 Dec 2023 00:22:56 GMT</pubDate>
    </item>
    <item>
      <title>Python ValueError：给定的列不是数据帧的列</title>
      <link>https://stackoverflow.com/questions/77663537/python-valueerror-a-given-column-is-not-a-column-of-the-dataframe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77663537/python-valueerror-a-given-column-is-not-a-column-of-the-dataframe</guid>
      <pubDate>Thu, 14 Dec 2023 23:15:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Marqo 进行矢量搜索的单个或多个键值对数据结构？</title>
      <link>https://stackoverflow.com/questions/77657071/single-or-multiple-key-value-pair-data-structure-for-vector-search-with-marqo</link>
      <description><![CDATA[我正在使用 Marqo Cloud 为工作项目实施矢量搜索。我的文档（产品）有一些数据，其结构可以如下：
单个键值对，例如：标签：红色、斑点、尼龙、休闲
或者每个标签标题包含多个键值对，例如：
红色
设计：斑点
材质: 尼龙
风格：休闲
在矢量搜索中，这些数据结构中的一种会比另一种表现得更好吗？或者差异可能可以忽略不计？]]></description>
      <guid>https://stackoverflow.com/questions/77657071/single-or-multiple-key-value-pair-data-structure-for-vector-search-with-marqo</guid>
      <pubDate>Wed, 13 Dec 2023 23:34:17 GMT</pubDate>
    </item>
    <item>
      <title>用转换层替换平均池层</title>
      <link>https://stackoverflow.com/questions/77652246/replacing-a-avg-pool-layer-with-a-conv-layer</link>
      <description><![CDATA[我有一个内核大小为 (4,3) 的平均池层，其步长为 (4,3) 和 0 填充。我想将其转换为等效的转换层，以便在我的神经网络中实现。
所以，在我的模型中，我替换了这个：
self.pool = nn.AvgPool2d((4, 3))

使用这一行（32 是输入通道数）：
self.pool = nn.Conv2d(32, 32, (4, 3), stride=(4, 3), 偏差=False)

对我来说，这两个层似乎应该是等效的，并且这两个层的输出大小都是 (1, 32, 32, 13) （它有 32 个通道）；对于大小为 (1, 32, 129, 40) 的输入（32 个通道，X 维度 129，Y 维度 40）。
我希望将平均池操作替换为转换层，以便两者产生相同的输出。这可以吗？]]></description>
      <guid>https://stackoverflow.com/questions/77652246/replacing-a-avg-pool-layer-with-a-conv-layer</guid>
      <pubDate>Wed, 13 Dec 2023 09:06:48 GMT</pubDate>
    </item>
    <item>
      <title>如何按照官方方式将 Hugging Face LLaMA v2 模型的权重重新初始化为原始模型？</title>
      <link>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</guid>
      <pubDate>Fri, 17 Nov 2023 03:15:56 GMT</pubDate>
    </item>
    <item>
      <title>模块“numpy”没有属性“MachAr”？</title>
      <link>https://stackoverflow.com/questions/75371176/module-numpy-has-no-attribute-machar</link>
      <description><![CDATA[我有一个问题。当我从“statsmodels.stats.outliers_influence”导入“variance_inflation_factor”时，出现“模块“numpy”没有属性“MachAr””错误，原因是什么？
我曾经在一个项目中执行过这段代码，它运行没有任何问题，但它在后续项目中给出了这个错误]]></description>
      <guid>https://stackoverflow.com/questions/75371176/module-numpy-has-no-attribute-machar</guid>
      <pubDate>Tue, 07 Feb 2023 09:17:47 GMT</pubDate>
    </item>
    <item>
      <title>惰性预测.监督.惰性分类器。 ImportError：无法从“sklearn.utils.deprecation”导入名称“_raise_dep_warning_if_not_pytest”</title>
      <link>https://stackoverflow.com/questions/67305004/lazypredict-supervised-lazyclassifier-importerror-cannot-import-name-raise-d</link>
      <description><![CDATA[我尝试过：
from lazypredict.Supervised import LazyClassifier

但得到以下回溯：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-1-f518cae57501&gt;在&lt;模块&gt;中
     10 从sklearn.linear_model导入LogisticRegression
     11 从 sklearn.ensemble 导入 RandomForestClassifier
---&gt; 12 从lazypredict.Supervised导入LazyClassifier
     13 从sklearn.model_selection导入GridSearchCV
     14 从sklearn.metrics导入accuracy_score

 中的 ~\AppData\Roaming\Python\Python38\site-packages\lazypredict\Supervised.py
     14 从sklearn.preprocessing导入StandardScaler、OneHotEncoder、OrdinalEncoder
     15 从 sklearn.compose 导入 ColumnTransformer
---&gt; 16 从 sklearn.utils.testing 导入 all_estimators
     17 从 sklearn.base 导入 RegressorMixin
     18 从sklearn.base导入ClassifierMixin

S:\anaconda\lib\site-packages\sklearn\utils\testing.py 在  中
      5 来自 . import _testing # 类型：忽略
      6 从 ..externals._pep562 导入 Pep562
----&gt; 7 从 ..utils.deprecation 导入 _raise_dep_warning_if_not_pytest
      8
      9 deprecated_pa​​th = &#39;sklearn.utils.testing&#39;

ImportError：无法从“sklearn.utils.deprecation”导入名称“_raise_dep_warning_if_not_pytest”（S：\ anaconda \ lib \ site-packages \ sklearn \ utils \ deprecation.py）

我当时在 Jupyter 笔记本中工作，并且也已经尝试升级 scikit-learn。]]></description>
      <guid>https://stackoverflow.com/questions/67305004/lazypredict-supervised-lazyclassifier-importerror-cannot-import-name-raise-d</guid>
      <pubDate>Wed, 28 Apr 2021 17:22:07 GMT</pubDate>
    </item>
    <item>
      <title>对于相同的损失函数和优化器，L1 或 L2 正则化是否给出最稀疏的权重？</title>
      <link>https://stackoverflow.com/questions/57967899/does-l1-or-l2-regularization-give-the-most-sparse-weights-for-the-same-loss-func</link>
      <description><![CDATA[如果我考虑一个数据集，对于相同的损失函数和相同的优化器，哪种正则化技术（L1 正则化或 L2 正则化）会输出最高的稀疏权重？]]></description>
      <guid>https://stackoverflow.com/questions/57967899/does-l1-or-l2-regularization-give-the-most-sparse-weights-for-the-same-loss-func</guid>
      <pubDate>Tue, 17 Sep 2019 05:35:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在远程服务器上运行 Tensorboard？</title>
      <link>https://stackoverflow.com/questions/37987839/how-can-i-run-tensorboard-on-a-remote-server</link>
      <description><![CDATA[我是 Tensorflow 新手，将从我正在做的事情的一些可视化中受益匪浅。我知道 Tensorboard 是一个有用的可视化工具，但如何在远程 Ubuntu 计算机上运行它？]]></description>
      <guid>https://stackoverflow.com/questions/37987839/how-can-i-run-tensorboard-on-a-remote-server</guid>
      <pubDate>Thu, 23 Jun 2016 09:40:01 GMT</pubDate>
    </item>
    </channel>
</rss>