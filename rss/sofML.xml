<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 13 Feb 2024 15:12:52 GMT</lastBuildDate>
    <item>
      <title>地理空间聚类 - 添加所有聚类都满足的条件</title>
      <link>https://stackoverflow.com/questions/77988569/geospacial-clustering-adding-a-condition-to-be-fulfilled-by-all-clusters</link>
      <description><![CDATA[我想创建基于距离的客户集群，总而言之，每个集群都会产生相同的收入潜力。
说明：

我正在查看分布在一个国家/地区的数千名客户
每个客户都标有邮政编码和收入潜力（我们将通过该客户赚多少钱？）
目标：
1.) 创建定义数量的集群，其中包含地理位置彼此接近的客户（基于 Zip）-&gt;直到这里都没问题
2.) 总之，每个集群应该产生大致相同的收入潜力 -&gt;我还没有找到包含这样一个条件的方法

有人知道这样做的方法吗？
到目前为止，我从未将这样的条件纳入我的聚类中。我现在已经对如何合并它进行了一些研究，但没有找到任何有用的结果。]]></description>
      <guid>https://stackoverflow.com/questions/77988569/geospacial-clustering-adding-a-condition-to-be-fulfilled-by-all-clusters</guid>
      <pubDate>Tue, 13 Feb 2024 14:10:16 GMT</pubDate>
    </item>
    <item>
      <title>ImageDatagenerator 中的自定义裁剪功能</title>
      <link>https://stackoverflow.com/questions/77987953/custom-cropping-function-in-imagedatagenerator</link>
      <description><![CDATA[我需要围绕中心点 (x,y) 裁剪一个正方形，并尝试在下面创建自定义函数。
从 PIL 导入图像

def Crop_Image(图像):
    裁剪尺寸 = 224
    裁剪长度 = 裁剪尺寸/2
    x = X中心
    y = Y中心
    image_crop = image.crop((x-裁剪长度，y-裁剪长度，x+裁剪长度，y+裁剪长度))
    返回图像_裁剪

然后将 Crop_Image 函数传递到 Imagedatagenerator。
datagen = ImageDataGenerator(rescale=1./255,
                             验证分割=0.2，
                             旋转范围=0.2，
                             宽度偏移范围=0.2，
                             height_shift_range=0.2，
                             剪切范围=0.2，
                             缩放范围=0.2，
                             水平翻转=真，
                             fill_mode=&#39;最近&#39;,
                             预处理函数=Crop_Image)

但是在训练过程中，我遇到了一些错误。
AttributeError：&#39;numpy.ndarray&#39;对象没有属性&#39;crop&#39;

如何解决这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/77987953/custom-cropping-function-in-imagedatagenerator</guid>
      <pubDate>Tue, 13 Feb 2024 12:35:00 GMT</pubDate>
    </item>
    <item>
      <title>在 ML 回归上下文中压缩测试和训练集中的数据以进行一种热编码？</title>
      <link>https://stackoverflow.com/questions/77987380/condensing-data-in-test-and-train-set-for-one-hot-encoding-in-ml-regression-cont</link>
      <description><![CDATA[我正在尝试理解特征工程的想法。我在网上看到了一些相互矛盾的信息（这可能是它取决于上下文的事实），所以也许如果我给出上下文，建议的方法可能会更清楚。
我们已经获得了一个训练集和一个测试集以及一个测试集。那么我假设我们想要对两者都进行任何数据预处理吗？ （也许是故意让事情变得更具挑战性）
所以目前我需要使用回归来预测 Spotify 上歌曲的流行度得分。我们被赋予了一堆特征——艺术家、响度、bpm 等。其中一个特征是流派和节奏。问题是：

这是分类数据
唯一值太多（100+）

所以我尝试为火车组和火车组执行此操作设法将流派特征的大小压缩到显着降低（大约 30 左右？）。不太确定我是否应该更改现有专栏或添加新的“广泛流派”功能。
但是，我在如何处理测试集方面遇到了困难。我也可以应用相同类型的特征工程，但在网上阅读一些内容后，似乎有人说我们不应该更改测试集（因为我们假设我们不知道测试集的存在）。
所以我只是有点不确定如何使用此功能，或者也许应该完全删除它。
所以我知道我需要使用一种技术（例如热编码）将分类数据转换为合理的回归格式。然而，由于流派数量众多，我知道的一种方法是特征工程。
我注意到其中许多类型：

重复但略有不同，即成人标准与成人标准
可以归为一个广泛的流派，即不同类型的摇滚乐

例如：
train_df.loc[train_df[&#39;顶级流派&#39;].str.contains(&#39;摇滚&#39;), [&#39;顶级流派&#39;]] = &#39;摇滚&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/77987380/condensing-data-in-test-and-train-set-for-one-hot-encoding-in-ml-regression-cont</guid>
      <pubDate>Tue, 13 Feb 2024 10:59:38 GMT</pubDate>
    </item>
    <item>
      <title>knn手动计算与R类包的比较</title>
      <link>https://stackoverflow.com/questions/77987372/knn-manual-calculation-vs-r-class-package</link>
      <description><![CDATA[为了更好地理解 kNN 方法，我想手动复制 R 使用 class 包的 knn 函数所做的事情。
首先，可以在此处获取数据https://github.com/NPejovicE/kNN。它是一个 csv 文件，包含 3 个类别的交通标志：pedestrian、speed 和 stop。为了解释数据集，假设标志被分为 16 块，每块中心的颜色用 r/g/b 颜色代码测量。因此，每个标志有 48 列 (16 x 3)。数据分为训练数据集和测试数据集。
signs %&gt;% filter(sample == &quot;train&quot;) -&gt; &gt;训练数据
标志%&gt;%过滤器(样本==“测试”)-&gt;测试数据

我想根据测试数据预测第 12 行。
test_data %&gt;% slice(12) %&gt;% select(4:ncol(test_data)) -&gt;我的测试

我将通过 R 中的“类包”进行 kNN 分类：
knn(train_data[4:ncol(train_data)], unlist(my_test), cl = train_data$sign_type)

行人
级别：行人限速

它说这是行人。
现在，我将尝试手动计算缩放值的欧几里德距离。我将仅使用训练和测试数据中所需的列，并从测试数据中提取第 12 行。
train_data[4:ncol(train_data)] -&gt;训练数据清理
test_data[4:ncol(test_data)] -&gt;测试数据清理

as.data.frame(scale(train_data_clean)) -&gt;;缩放训练
as.data.frame(scale(test_data_clean)) -&gt;;缩放测试

scaled_test %&gt;% 切片(12) -&gt;测试行

现在逐步计算距离：
scaled_train - unlist(test_row) -&gt;差异
# 平方差异：
diff^2 -&gt;差异2
# 行间求和：
rowSums(diff2) -&gt;;差异3
# 取平方根：
sqrt(diff3) -&gt;;差异4
# 查找具有最小值的行。
其中.min(diff4) -&gt; n

它说我的 train_data 第 72 行具有最小距离。
当我回顾原始列车数据时，它是：
 train_data %&gt;% slice(72) %&gt;% select(sign_type)

它是 stop 而不是类包中的 pedestrian。
我如何从类包中复制结果，我在这里做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/77987372/knn-manual-calculation-vs-r-class-package</guid>
      <pubDate>Tue, 13 Feb 2024 10:58:23 GMT</pubDate>
    </item>
    <item>
      <title>尝试在 GPU 上嵌入 CatBoostClassifier 时出现“CatBoostError：尝试在打包功能编写器上调用单个功能编写器”</title>
      <link>https://stackoverflow.com/questions/77987029/getting-catboosterror-attempt-to-call-single-feature-writer-on-packed-feature</link>
      <description><![CDATA[当我尝试使用带嵌入的 pandas 数据帧在 GPU 上安装 CatBoostClassifier 时，出现此错误：
CatBoostError：尝试在打包功能编写器上调用单个功能编写器

嵌入列中的数据类型是对象。 Catboost版本==1.2.2。
当我从训练中删除嵌入列时，一切正常，所以这肯定与嵌入有关。我尝试将它存储为列表、ndarray、张量。不会影响任何事情。
我规定了 embedding_features 参数。 
类不平衡或 eval_set 的存在也不会产生任何影响。
发现 task_type=&#39;GPU&#39; 导致了此错误。即使您尝试文档使用示例中的一些简单代码，但使用 task_type=&#39;GPU&#39;：
&lt;前&gt;&lt;代码&gt;cat_features = [3]
嵌入特征=[0, 1]
训练数据 = [
    [[0.1，0.12，0.33]，[1.0，0.7]，2，“男性”]，
    [[0.0,0.8,0.2],[1.1,0.2],1,“女性”],
    [[0.2，0.31，0.1]，[0.3，0.11]，2，“女性”]，
    [[0.01,0.2,0.9],[0.62,0.12],1,“男性”]
]
训练标签 = [1, 0, 0, 1]
评估数据 = [
    [[0.2，0.1，0.3]，[1.2，0.3]，1，“女性”]，
    [[0.33，0.22，0.4]，[0.98，0.5]，2，“女性”]，
    [[0.78，0.29，0.67]，[0.76，0.34]，2，“男性”]，
]

模型= CatBoostClassifier（迭代= 2，
                           学习率=1，
                           深度=2，
                           任务类型=&#39;GPU&#39;)

model.fit(train_data, train_labels, cat_features=cat_features, embedding_features=embedding_features)

preds_class = model.predict(eval_data)

在这种情况下，GPU 的使用至关重要。]]></description>
      <guid>https://stackoverflow.com/questions/77987029/getting-catboosterror-attempt-to-call-single-feature-writer-on-packed-feature</guid>
      <pubDate>Tue, 13 Feb 2024 10:00:09 GMT</pubDate>
    </item>
    <item>
      <title>删除 DCA 曲线中的“Treat All”和“Treat None”</title>
      <link>https://stackoverflow.com/questions/77986685/remove-treat-all-and-treat-none-in-dca-curve</link>
      <description><![CDATA[在此处输入图像描述
# 绘制 DCA 曲线
库（dcurves）
# dca(AS1min ~ knn + Boosting, data= data.set)
dcaoutput = dca(AS1min ~ knn + Boosting, data= data.set,
  阈值 = seq(0, 0.99, by = 0.01))

dca输出%&gt;%
  绘图（类型 = &#39;net_benefit&#39;，平滑 = TRUE，show_ggplot_code = FALSE）

我正在尝试在 R 中绘制 DCA 曲线，我的问题是如何删除“Treat All”和“不治疗”图中的变量？]]></description>
      <guid>https://stackoverflow.com/questions/77986685/remove-treat-all-and-treat-none-in-dca-curve</guid>
      <pubDate>Tue, 13 Feb 2024 09:06:37 GMT</pubDate>
    </item>
    <item>
      <title>Llama 索引核心嵌入</title>
      <link>https://stackoverflow.com/questions/77986616/llama-index-core-embbedings</link>
      <description><![CDATA[从 llama_index.core.embeddings 导入resolve_embed_model

错误：
ImportError：无法导入名称“resolve_embed_model”
 &#39;llama_index.core.embeddings&#39; (/usr/local/lib/python3.10/dist-packages/llama_index/core/embeddings/__init__.py)

安装 Llama 索引后，我收到上述错误。]]></description>
      <guid>https://stackoverflow.com/questions/77986616/llama-index-core-embbedings</guid>
      <pubDate>Tue, 13 Feb 2024 08:55:46 GMT</pubDate>
    </item>
    <item>
      <title>哪种机器学习模型可以处理多个输入和一个输出[关闭]</title>
      <link>https://stackoverflow.com/questions/77986009/which-ml-model-can-handle-multiple-input-and-one-output</link>
      <description><![CDATA[我有一个机器学习问题。我得到的数据如下

&lt;标题&gt;

前一天
潮湿
阴
风速
城市最近下雨
最近下雨的天数


&lt;正文&gt;

第一天
60
是
&lt; 50米/秒
城市A
3


第二天
20
没有
&gt; 50米/秒
B市
1



...可以有多行。
输出是 Z 市下雨
是的
不
也许
对于 Z 市的 N 天，我有时有 2 天前的数据。有时我有 3 天前的数据。有时是 10 天前的数据。
下面是示例
13/03/2023 - Z 市下雨 - 是

&lt;标题&gt;

前一天
潮湿
阴
风速
城市最近下雨
最近下雨的天数


&lt;正文&gt;

第一天
60
是
&lt; 50米/秒
城市A
3


第二天
20
没有
&gt; 50米/秒
B市
1



2023 年 9 月 19 日 - Z 市下雨 - 否

&lt;标题&gt;

前一天
潮湿
阴
风速
城市最近下雨
最近下雨的天数


&lt;正文&gt;

第一天
60
是
&lt; 50米/秒
城市A
3


第一天
20
没有
&gt; 50米/秒
C市
1


第四天
30
是
&gt; 20米/秒
D市
5


第六天
10
没有
&lt; 50米/秒
城市Q
3



对于当前 X 天，我可以有任意数量的行，并且我想预测是否可能下雨。我该如何做到这一点以及使用哪种模型
尝试阅读可以应用的不同机器学习模型，但无法理解一个可以接受许多输入行、自动决定权重并​​预测降雨的模型。
例如，几乎可以肯定，如果第一天 A 市下雨，Z 市也会下雨]]></description>
      <guid>https://stackoverflow.com/questions/77986009/which-ml-model-can-handle-multiple-input-and-one-output</guid>
      <pubDate>Tue, 13 Feb 2024 06:58:07 GMT</pubDate>
    </item>
    <item>
      <title>通过 3dskullstripping 无 Nifiti 生成 MRI [关闭]</title>
      <link>https://stackoverflow.com/questions/77985923/no-nifiti-generation-of-mri-via-3dskullstripping</link>
      <description><![CDATA[以下代码不会生成 nifiti 剥离头骨 MRI 图像。
目录看起来像这样 /4-Resample/LGG101/LGG102flair.nii.gz
“4-Resasmple”内有两个文件夹，文件夹内有一个 nifti 文件。
头骨条纹后，它会在“Skull_strpping_folder”中创建类似的文件夹和类似的nifiti文件。但以下代码没有创建任何内容。
导入操作系统
导入子流程
从 tqdm 导入 tqdm
导入时间

# 定义输入和输出文件夹的路径
input_folder =“D：/AID/1-Anum（预处理）/Dataset-20240202T042956Z-001/Dataset/Sumaiya/4-Resampled/”
头骨_stripped_folder =“D：/AID/1-Anum（预处理）/Dataset-20240202T042956Z-001/Dataset/Sumaiya/5-Skull_Stripped/brain/”
mask_folder =“D：/AID/1-Anum（预处理）/Dataset-20240202T042956Z-001/Dataset/Sumaiya/5-Skull_Stripped/brain_mask/”

# 处理子文件夹中的 NIfTI 文件的函数
def process_subfolders(子文件夹路径):
    对于 os.walk(subfolder_path) 中的 root、_、文件：
        对于 tqdm(files) 中的文件名：
            if filename.endswith(“.nii.gz”):
                input_file = os.path.join(root, 文件名).replace(&quot;\\&quot;,&quot;/&quot;)
                打印（输入文件）
                relative_path = os.path.relpath(input_file,input_folder).replace(&quot;\\&quot;,&quot;/&quot;)
                打印（相对路径）
                头骨_stripped_output = os.path.join(skull_stripped_folder, 相对路径)
                打印（头骨剥离输出）
                mask_output = os.path.join(mask_folder, 相对路径)
# 打印（掩码输出）
                # 如果输出文件夹不存在则创建子文件夹
                os.makedirs（os.path.dirname（skull_stripped_output），exist_ok = True）
                os.makedirs(os.path.dirname(mask_output),exist_ok=True)

                # 定义 3dSkullStrip 命令
                skullstrip_cmd = f“3dSkullStrip -input {input_file} -prefix {skull_stripped_output}”

                # 运行 3dSkullStrip 命令
                subprocess.run(skullstrip_cmd, shell=True)

                # 定义 3dcalc 命令来创建二进制掩码
                calc_cmd = f“3dcalc -a {skull_stripped_output} -expr &#39;step(a)&#39; -prefix {mask_output}”`

                # 运行 3dcalc 命令
                subprocess.run(calc_cmd, shell=True)


# 处理输入文件夹子文件夹中的 NIfTI 文件
对于 os.listdir(input_folder) 中的子文件夹：
    subfolder_path = os.path.join(input_folder, subfolder).replace(&quot;\\&quot;,&quot;/&quot;)
    如果 os.path.isdir(子文件夹路径):
        进程子文件夹（子文件夹路径）
        打印（子文件夹路径）

找出代码中的错误。]]></description>
      <guid>https://stackoverflow.com/questions/77985923/no-nifiti-generation-of-mri-via-3dskullstripping</guid>
      <pubDate>Tue, 13 Feb 2024 06:35:05 GMT</pubDate>
    </item>
    <item>
      <title>如何正确准备数据集，设置 EfficientNetV2B0 模型以使用 Tensorflow 对自定义数据集进行训练 [关闭]</title>
      <link>https://stackoverflow.com/questions/77985276/how-to-properly-prepare-dataset-setting-up-efficientnetv2b0-model-for-training</link>
      <description><![CDATA[我的代码中有什么问题，结果模型没有正确分类苹果叶病？我在 4 个类的 7k 图像数据集上进行了训练，每个类都有大约 1.8k 的图像。每个类的总图像不相等，这会影响训练结果吗？或者我下面的代码有问题吗？
从 google.colab 导入驱动器
驱动器.mount(&#39;/content/gdrive&#39;)


导入压缩文件
zip_ref = zipfile.ZipFile(&#39;/content/gdrive/MyDrive/dataset/data9k.zip&#39;, &#39;r&#39;)
zip_ref.extractall(“/内容/数据集”)
zip_ref.close()


将张量流导入为 tf
从tensorflow.keras.applications.imagenet_utils导入preprocess_input
将 matplotlib.pyplot 导入为 plt


train_dataset = tf.keras.utils.image_dataset_from_directory(
&#39;/内容/数据集/数据集/火车&#39;,
批量大小=10，
图像大小=(224, 224),
标签=&#39;推断&#39;,
label_mode=&#39;分类&#39;
）


validation_dataset = tf.keras.utils.image_dataset_from_directory(
&#39;/内容/数据集/数据集/测试&#39;,
批量大小=10，
图像大小=(224, 224),
标签=&#39;推断&#39;,
label_mode=&#39;分类&#39;
）


val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = valid_dataset.take(val_batches // 5)
validation_dataset =validation_dataset.skip(val_batches // 5)


自动调谐 = tf.data.AUTOTUNE
train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset =validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)


data_augmentation = tf.keras.Sequential(
[tf.keras.layers.RandomFlip(&#39;水平&#39;),
tf.keras.layers.RandomRotation(0.2)]
）


模型 = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(
include_top=假，
权重=无，
输入张量=无，
输入形状=(224, 224, 3),
池=&#39;平均&#39;，
include_preprocessing=True
）


#model.trainable=False


Prediction_layer = tf.keras.layers.Dense(4, 激活=&#39;softmax&#39;)


输入 = tf.keras.Input(形状=(224, 224, 3))
x = 数据增强（输入）
#x = 预处理输入(x)
x = 模型(x)
x = tf.keras.layers.Dropout(0.2)(x)
输出=预测层(x)
模型= tf.keras.Model（输入，输出）


模型.编译(
优化器=tf.keras.optimizers.Adam(learning_rate=1e-4),
损失=tf.keras.losses.CategoricalCrossentropy(),
指标=[&#39;准确性&#39;]
）


模型.拟合(
训练数据集，
验证数据=验证数据集，
纪元=10
）


将 numpy 导入为 np
从tensorflow.keras.preprocessing导入图像


img_path = &#39;gdrive/MyDrive/dataset/rust.jpg&#39;
img = image.load_img(img_path, target_size=(224, 224))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, 轴=0)


预测 = model.predict(img_array)


class_names = [&#39;apple_scab&#39;, &#39;black_rot&#39;, &#39;cedar_apple_rust&#39;, &#39;healthy&#39;]


Predicted_index = np.argmax(预测[0])
标签=类名[预测索引]
print(&quot;预测标签：&quot;, label)
]]></description>
      <guid>https://stackoverflow.com/questions/77985276/how-to-properly-prepare-dataset-setting-up-efficientnetv2b0-model-for-training</guid>
      <pubDate>Tue, 13 Feb 2024 02:23:46 GMT</pubDate>
    </item>
    <item>
      <title>尝试对象检测时出现 opencv 错误</title>
      <link>https://stackoverflow.com/questions/77982625/getting-opencv-errors-while-trying-object-detection</link>
      <description><![CDATA[这是我的代码：
&lt;前&gt;&lt;代码&gt;导入cv2
将 cvlib 导入为 cv

从 cvlib.object_detection 导入draw_bbox
将张量流导入为 tf
打印（tf.__版本__）
#从 gtts 导入 gTTS
#from Playsound 导入 Playsound

视频 = cv2.VideoCapture(0)

# 检查网络摄像头是否打开成功
如果不是 video.isOpened():
    print(“错误：无法打开网络摄像头。”)
    出口（）
别的：
    print(&quot;检测到相机&quot;)
而真实：
    ret, 帧 = video.read()
    打印（框架）
    bbox、标签、conf = cv.detect_common_objects(frame)
    输出图像=绘制_bbox（框架，bbox，标签，conf）

    cv2.imshow(“目标检测”,output_image)

    如果 cv2.waitKey(1) &amp; 0xFF == ord (“q”)：
        休息

我收到以下错误：cv2.error: OpenCV(4.9.0) D:\a\opencv-python\opencv-python\opencv\modules\dnn\src\darknet\darknet_io.cpp： 705：错误：（-215：断言失败）separator_index &lt;函数“cv::dnn::darknet::ReadDarknetFromCfgStream”中的 line.size()
我尝试导航到错误中指定的文件，但我的计算机上没有 D 驱动器，因此我不知道如何找到它。我尝试重新安装 OpenCV 但没有帮助。我在网上看到，导航到该文件并直接编辑它可以解决人们的问题，但我首先如何导航到它。]]></description>
      <guid>https://stackoverflow.com/questions/77982625/getting-opencv-errors-while-trying-object-detection</guid>
      <pubDate>Mon, 12 Feb 2024 15:44:27 GMT</pubDate>
    </item>
    <item>
      <title>如何包装 keras 模型以供 scikit-learn 堆叠集成使用</title>
      <link>https://stackoverflow.com/questions/77982056/how-to-wrap-keras-models-for-scikit-learn-stacking-ensemble-usages</link>
      <description><![CDATA[我有一个已经训练过的 keras 模型列表。我想在 scikit learn 中将它们与 StackingClassifier 一起使用。由于 keras 没有 Predict_proba 方法，我创建了一个包装器。
如果使用我的为 VotingClassifier 包装的模型以及软方法和硬方法，它就可以工作。
但是当我使用堆叠模型时，第一次运行后，它会显示此错误。我没有找到任何相关信息。
类 KerasWrapperWithEncoder(BaseEstimator, ClassifierMixin):
    def __init__(自身，keras_model，classes_)：
        self.keras_model = keras_model
        self.encoder = OneHotEncoder(sparse_output=False)
        # L&#39;encoder OneHotEncoder 已经过去了
        self.classes_ = classes_ # 定义可分配类

    def fit(自身, X, y):
        # 模型已安装，不再适合
        y_reshape = y.reshape(-1, 1)
        self.encoder.fit(y_reshape)
        返回自我

    def 预测（自身，X）：
        # 利用 les modèles entraînés pour faire des predictions
        预测 = self.keras_model.predict(X)
        np_argmax = np.argmax(预测，轴=1)
        打印（预测）
        打印（np_argmax）
        返回 np_argmax

    def Predict_proba(自身, X):
        # 返回分类模型的类别概率
        概率 = self.keras_model.predict(X)
        print(&quot;概率形状：&quot;, probabilities.shape) # 调试
        返回概率


keras_wrapped_models_with_encoder = [
    (name.replace(&#39; &#39;, &#39;_&#39;).replace(&#39;__&#39;, &#39;_&#39;), KerasWrapperWithEncoder(model, _target_classes_))
    对于 keras_models.items() 中的名称、模型
]

vote_clf = 投票分类器(
         估计器=all_估计器，
         投票=&#39;软&#39;，
         n_职位=3，
         详细=真）
vote_clf .fit(X_train, y_train) # 完美运行

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
keras_stacking_models_current_year = StackingClassifier(
    估计器=all_估计器，
    Final_estimator=LogisticRegression(),
    简历=简历，
    详细=3，
    # n_jobs=2
）


keras_stacking_models_current_year.fit(X_train, y_train) # 抛出错误


&lt;前&gt;&lt;代码&gt;========================================stacking_models_all_models===== =======================
12105/12105 [================================] - 25s 2ms/步
概率形状：(387348, 3)
训练折叠 (1) 中的类数与类总数 (3) 不匹配。结果可能不适合您的用例。要解决此问题，请使用交叉验证技术来产生正确分层的折叠
_enforce_prediction_order（类、预测、n_classes、方法）
   第1457章
   第1458章）
-&gt;第1459章
   第1460章 1460
   第1461章 回归预测

ValueError：形状不匹配：形状（387348,3）的值数组无法广播到形状（387348,1,3）的索引结果
]]></description>
      <guid>https://stackoverflow.com/questions/77982056/how-to-wrap-keras-models-for-scikit-learn-stacking-ensemble-usages</guid>
      <pubDate>Mon, 12 Feb 2024 14:12:27 GMT</pubDate>
    </item>
    <item>
      <title>如何从 GridSearchCV 输出可视化 XGBoost 树？</title>
      <link>https://stackoverflow.com/questions/62176516/how-to-visualize-an-xgboost-tree-from-gridsearchcv-output</link>
      <description><![CDATA[我正在使用XGBRegressor来使用gridsearchcv来拟合模型。我想将树木可视化。
这是我点击的链接（如果重复）如何绘制gridsearchcv 的决策树？
xgb = XGBRegressor(learning_rate=0.02, n_estimators=600,silent=True, nthread=1)
折叠 = 5
网格 = GridSearchCV(估计器=xgb, param_grid=params, 评分=&#39;neg_mean_squared_error&#39;, n_jobs=4, verbose=3 )
模型=grid.fit(X_train, y_train)

方法一：
 dot_data = tree.export_graphviz(model.best_estimator_, out_file=None,
        填充=真，舍入=真，feature_names=X_train.columns）
 点数据

 错误：NotFittedError：此 XGBRegressor 实例尚未安装。在使用此估计器之前，请使用适当的参数调用“fit”。

方法 2：
tree.export_graphviz(best_clf, out_file=&#39;tree.dot&#39;,feature_names=X_train.columns,leaves_parallel=True)
subprocess.call([&#39;dot&#39;, &#39;-Tpdf&#39;, &#39;tree.dot&#39;, &#39;-o&#39; &#39;tree.pdf&#39;])

同样的错误。]]></description>
      <guid>https://stackoverflow.com/questions/62176516/how-to-visualize-an-xgboost-tree-from-gridsearchcv-output</guid>
      <pubDate>Wed, 03 Jun 2020 15:20:02 GMT</pubDate>
    </item>
    <item>
      <title>FP-Growth 算法中的递归</title>
      <link>https://stackoverflow.com/questions/58385765/recursion-in-fp-growth-algorithm</link>
      <description><![CDATA[我正在尝试用Java实现FP-Growth（频繁模式挖掘）算法。我已经构建了树，但在条件 FP 树构建方面遇到困难；我不明白递归函数应该做什么。给定一个频繁项列表（按频率计数的递增顺序）- 一个标头和一棵树（Node 类实例列表），该函数应采取哪些步骤？

我很难理解上面的伪代码。 alpha 和 Betha 节点在树中吗？生成和构造函数的作用是什么？
我可以手动进行 FP-Growth，但发现实现非常混乱。如果这有帮助，我可以分享我的 FP-Tree 生成代码。]]></description>
      <guid>https://stackoverflow.com/questions/58385765/recursion-in-fp-growth-algorithm</guid>
      <pubDate>Tue, 15 Oct 2019 00:50:55 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法使用找到的顺序模式作为聚类算法的输入</title>
      <link>https://stackoverflow.com/questions/56025248/is-there-a-way-to-use-found-sequential-patterns-as-input-for-a-clustering-algori</link>
      <description><![CDATA[我正在做一个项目，根据用户在网站上的冲浪模式对用户进行分类。
为此，我需要找到数据中的模式，然后对它们进行聚类，但聚类是一个问题，因为我尝试的聚类算法（k-means、agglomerative 和 DBSCAN）不允许列表作为输入数据。&lt; /p&gt;
我有已访问页面的列表，按会话分隔。
示例：
&lt;前&gt;&lt;代码&gt;数据 = [[1, 2, 5],
        [2, 4],
        [2, 3],
        [1,2,4],
        [1, 3],
        [2, 3],
        [1, 3],
        [7,8,9],
        [9,8,7],
        [1,2,3,5],
        [1,2,3]]

每个列表代表一个包含已访问页面的会话。
每个数字代表 URL 的一部分。
示例：
&lt;前&gt;&lt;代码&gt;1 = &#39;/home&#39;
2 = &#39;/博客&#39;
3 = &#39;/关于我们&#39;
...

我将数据放入模式挖掘脚本中。
代码：
导入 pyfpgrowth # pip install pyfpgrowth

数据 = [[1, 2, 5],
        [2, 4],
        [2, 3],
        [1,2,4],
        [1, 3],
        [2, 3],
        [1, 3],
        [7,8,9],
        [9,8,7],
        [1,2,3,5],
        [1,2,3]]

模式= pyfpgrowth.find_frequent_patterns（数据，2）
打印（图案）

规则= pyfpgrowth.generate_association_rules（模式，0.7）
打印（规则）

结果：
# print(模式)

{（1，）：6，
 (1, 2): 4,
 (1,2,3): 2,
 (1,2,5): 2,
 (1, 3): 4,
 (1, 5): 2,
 （2，）：7，
 (2, 3): 4,
 (2, 4): 2,
 (2, 5): 2,
 （4，）：2，
 （5，）：2，
 （7，）：2，
 （8，）：2，
 (9,): 2}

# 打印（规则）

{(1, 5): ((2,), 1.0),
 (2, 5): ((1,), 1.0),
 (4,): ((2,), 1.0),
 (5,): ((1, 2), 1.0)}

根据论文我正在使用下一步是使用找到的模式作为聚类算法的输入（第118页第4.3章），但据我所知，聚类算法不接受列表（具有可变长度）作为输入。
我已经尝试过了，但没有成功。
代码：
从 sklearn.cluster 导入 KMeans

kmeans = KMeans(n_clusters=4, random_state=0).fit(模式)

测试 = [1, 8, 2]

打印（kmeans.预测（测试））

我应该怎么做才能让 k-means 算法能够预测冲浪模式所属的组，或者是否有其他更适合于此的算法？]]></description>
      <guid>https://stackoverflow.com/questions/56025248/is-there-a-way-to-use-found-sequential-patterns-as-input-for-a-clustering-algori</guid>
      <pubDate>Tue, 07 May 2019 14:48:33 GMT</pubDate>
    </item>
    </channel>
</rss>