<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 09 Sep 2024 01:13:46 GMT</lastBuildDate>
    <item>
      <title>结合语音、面部表情和文本数据进行实时心理健康监测的挑战</title>
      <link>https://stackoverflow.com/questions/78963600/challenges-in-combining-speech-facial-expression-and-text-data-for-real-time-m</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78963600/challenges-in-combining-speech-facial-expression-and-text-data-for-real-time-m</guid>
      <pubDate>Mon, 09 Sep 2024 01:01:00 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 的机器学习模型中处理具有数值的对象数据类型变量？[关闭]</title>
      <link>https://stackoverflow.com/questions/78963448/how-to-deal-with-object-data-type-variables-with-numeric-values-in-machine-learn</link>
      <description><![CDATA[我尝试在 Python 中构建机器学习模型，我有几个变量的数据类型为“object”，值如下：411,71 等。我的问题是：

我是否必须将这种具有 411,71 等值的对象变量更改为数字类型才能使用 xgboost 或随机森林等算法？

如何在我的数据集中找到适合将数据类型更改为数字的“object”类型的变量，即具有 411,71 等值的变量，以及在这种情况下是否也需要将“，”更改为“。”？你能给我展示一下 Python Pandas 中的示例代码来做到这一点吗？

]]></description>
      <guid>https://stackoverflow.com/questions/78963448/how-to-deal-with-object-data-type-variables-with-numeric-values-in-machine-learn</guid>
      <pubDate>Sun, 08 Sep 2024 22:50:51 GMT</pubDate>
    </item>
    <item>
      <title>如何在增加训练数据时调整 LightGBM 参数（如“min_child_samples”）？</title>
      <link>https://stackoverflow.com/questions/78963446/how-to-adjust-lightgbm-parameters-like-min-child-samples-when-increasing-train</link>
      <description><![CDATA[我正在训练 LightGBM 模型，目前面临着增加训练数据量时参数调整的困境。
最初，我将数据集分成 90% 用于训练，10% 用于测试。使用网格搜索，我找到了模型的最佳参数。现在，我想利用 100% 的数据来训练模型，使其尽可能强大。
我的问题是关于 min_child_samples 等参数，它与数据量有关。当我将数据从 90% 增加到 100% 时，我应该将 min_child_samples 保持为与 90% 数据训练期间找到的值相同吗？还是应该因为数据量增加了而进行调整？
有人可以提供如何处理此问题的指导，或者分享任何最佳实践吗？]]></description>
      <guid>https://stackoverflow.com/questions/78963446/how-to-adjust-lightgbm-parameters-like-min-child-samples-when-increasing-train</guid>
      <pubDate>Sun, 08 Sep 2024 22:50:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 Raspberry Pi 5 在 Edge TPU 上运行 YOLOv8 分割模型时出现 KeyError</title>
      <link>https://stackoverflow.com/questions/78963308/keyerror-when-running-yolov8-segmentation-model-on-edge-tpu-with-raspberry-pi-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78963308/keyerror-when-running-yolov8-segmentation-model-on-edge-tpu-with-raspberry-pi-5</guid>
      <pubDate>Sun, 08 Sep 2024 21:01:01 GMT</pubDate>
    </item>
    <item>
      <title>优化心理健康应用程序中的实时多模式数据集成和机器学习[关闭]</title>
      <link>https://stackoverflow.com/questions/78962995/optimizing-real-time-multimodal-data-integration-and-machine-learning-in-a-menta</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78962995/optimizing-real-time-multimodal-data-integration-and-machine-learning-in-a-menta</guid>
      <pubDate>Sun, 08 Sep 2024 17:57:14 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tensorflow 权重文件夹（包含.data、.index 和另一个未知文件名检查点）转换为.pb 格式和.tflite？</title>
      <link>https://stackoverflow.com/questions/78962022/how-to-convert-a-tensorflow-weights-folder-containing-data-index-and-another</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78962022/how-to-convert-a-tensorflow-weights-folder-containing-data-index-and-another</guid>
      <pubDate>Sun, 08 Sep 2024 09:39:58 GMT</pubDate>
    </item>
    <item>
      <title>如何根据多项评估对推荐路线与实际路线的相似度进行分类？[关闭]</title>
      <link>https://stackoverflow.com/questions/78962013/how-to-classify-the-similarity-between-a-recommended-and-an-actual-route-based-o</link>
      <description><![CDATA[我需要对应用程序推荐的路线和司机所走的路线是否相似进行分类。
我有一个包含以下变量的数据集：

id_viaje（行程 ID）
evaluador（评估者）——有 8 个不同的评估者
evaluacion（评估）——评估者的判断：相似、不相似或不确定
ruta_real（实际路线的点集）
ruta_estimada（估计路线的点集）

我已经做了一些探索性数据分析，以下是一些观察结果：

同一个评估者有时会对同一次行程进行两次评估，并给出相互矛盾的结果（一次说路线相似，另一次说不相似）。
在某些情况下在某些情况下，他们说他们不确定，但当我可视化路线时，它们实际上是相同的。
对于同一次旅行，不同的评估者会有相互矛盾的意见。

我对如何处理这个问题有些疑问：
对于评估者说“不确定”的情况，我计划为“相似”和“不相似”分配 0.5 的权重。 （或者，我可以忽略这些，或者先建立一个初始模型对这些情况进行分类，然后使用包含所有数据的最终模型。）
由于该任务似乎涉及对实际路线和拟议路线之间的相似性进行分类，而不是建立传统模型，因此似乎基于距离进行分类是最好的方法。
关于如何处理这些情况或计算路线相似性有什么建议吗？
我有这种数据
{&#39;journey_id&#39;: &#39;9cd6cd52-54c5-11ec-ae0a-0d030544d074&#39;,
&#39;annotator&#39;: 3,
&#39;annotation&#39;: &#39;两者相同&#39;,
&#39;estimated_route&#39;: [[-21.11149, -60.21455],
[-12.11145, -77.04671],
[-12.11139, -77.04664],
[-12.11134, -77.04659]
...],
&#39;real_route&#39;: 
[[-21.77149, -60.17455],
[-12.11139, -77.04659],
[-12.11139, -77.04671]]}

实际路线和估算路线并不总是具有相同长度的点]]></description>
      <guid>https://stackoverflow.com/questions/78962013/how-to-classify-the-similarity-between-a-recommended-and-an-actual-route-based-o</guid>
      <pubDate>Sun, 08 Sep 2024 09:35:49 GMT</pubDate>
    </item>
    <item>
      <title>什么是局部梯度错位？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78961861/what-is-local-gradient-misalignment</link>
      <description><![CDATA[我在阅读FedPRoto相关论文时，文章中提到了这个概念，但是我却无法理解它的具体定义。
但是我似乎无法从如此少的信息中找到明确的答案。]]></description>
      <guid>https://stackoverflow.com/questions/78961861/what-is-local-gradient-misalignment</guid>
      <pubDate>Sun, 08 Sep 2024 07:57:37 GMT</pubDate>
    </item>
    <item>
      <title>Python-NEAT算法的配置</title>
      <link>https://stackoverflow.com/questions/78961771/configuration-of-python-neat-algorithm</link>
      <description><![CDATA[我正在使用 NEAT 算法根据十字路口四个方向的队列长度等输入来优化交通信号时序。目标是生成最佳信号时序作为输出。但是，我在实现中遇到了激活函数的持续问题。
我使用 Python-NEAT 进行交通信号优化，其中：
输入：交叉路口四个方向的队列长度。
输出：每个方向的信号时序。

以下是我在使用不同激活函数时遇到的问题的描述：
ReLU：不断将输出值增加到非常大的数字，然后变得无法运行。
Sigmoid：虽然它给出的值从 0 到 1，但我通过将其乘以 10 来放大它，但问题是它对所有输出都卡在 1，无论输入如何，它都会不断给出 [1.0, 1.0, 1.0, 1.0]值。
tanh：与 sigmoid 有同样的问题。
sin：与 sigmoid 有同样的问题。
Softplus：对所有信号时序输出一个常数值 12。
我最初认为运行该算法多代可能会解决这个问题。所以，我让它用 Sigmoid 之类的函数运行了一整夜，结果醒来后发现适应度值已经暴跌到负数十亿。
我正在按如下方式评估我的适应度值：
ifqueue_length_north_avg &gt; 15:
fitness_N += 队列长度_北_avg + ((队列长度_北_avg - 15) ** 2)
else:
fitness_N += 队列长度_北_avg

然后将所有方向的适应度相加并从基因组中减去，如下所示：
 fitness = fitness_N + fitness_S + fitness_E + fitness_W / 4
基因组.fitness -= fitness

我的问题是，是什么原因导致我的 NEAT 实现中的激活函数出现这些问题，我如何配置算法以产生更稳定的输出，从而实现信号时序的有意义的优化？
是否可以为所有四个方向输入不同的适应度？这会有帮助吗？
我的配置文件如下：
*
[NEAT]
fitness_criterion = max
fitness_threshold = 1
pop_size = 30
reset_on_extinction = False

[DefaultGenome]
#compatibility_weight_coefficient = 1.0
activation_default = softplus
activation_mutate_rate = 0.0
activation_options = softplus

aggregation_default = sum
aggregation_mutate_rate = 0.0
aggregation_options = sum

bias_init_mean = 0.0
bias_init_stdev = 1.0
bias_max_value = 10.0
bias_min_value = 0.0
bias_mutate_power = 0.5
bias_mutate_rate = 0.4
bias_replace_rate = 0.1

compatibility_disjoint_coefficient = 1.0
compatibility_weight_coefficient = 1.0

conn_add_prob = 0.5
conn_delete_prob = 0.5

enabled_default = True
enabled_mutate_rate = 0.01

feed_forward = True
initial_connection = full_direct

node_add_prob = 0.2
node_delete_prob = 0.2

num_hidden = 4
num_inputs = 4
num_outputs = 4

response_init_mean = 1.0
response_init_stdev = 0.1
response_max_value = 10.0
response_min_value = 0.0
response_mutate_power = 0.1
response_mutate_rate = 0.1
response_replace_rate = 0.05

weight_init_mean = 0.0
weight_init_stdev = 0.5
weight_max_value = 10
weight_min_value = 0.0
weight_mutate_power = 0.5
weight_mutate_rate = 0.4
weight_replace_rate = 0.1

[DefaultSpeciesSet]
compatibility_threshold = 3.0

[DefaultStagnation]
species_fitness_func = max
max_stagnation = 20
species_elitism = 2

[DefaultReproduction]
elitism = 2
survival_threshold = 0.3*
]]></description>
      <guid>https://stackoverflow.com/questions/78961771/configuration-of-python-neat-algorithm</guid>
      <pubDate>Sun, 08 Sep 2024 06:48:43 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 中的 Autograd Trainstep 中的 Lightning</title>
      <link>https://stackoverflow.com/questions/78956646/autograd-in-pytorch-lightning-in-trainstep</link>
      <description><![CDATA[我想实现一个基于 Pytorch Lightning 的 ML 训练，其中我使用 autograd 功能进行训练损失计算：
def training_step(self, batch, batch_idx):
x, y = batch
y_hat = self(x)
loss = self.loss_function(y_hat, y)
return loss

X 的每个样本 x 都是一个二维向量 x = [v, a]。
在训练步骤中，我想计算 y_hat 相对于 的梯度。到 v。
损失进一步通过以下方式计算：
loss = mse(y,y_hat) + mse(gradient,gradient_hat)

其中给出了（真实）梯度。
到目前为止，尝试了 y_hat.backward() 的（典型）方法，但无法使其工作：
def training_step(self, batch, batch_idx):
x, y = batch
x.requires_grad_(True) # 确保我们跟踪 x 的梯度
y_hat = self(x)

# 计算 y_hat 相对于 v 的梯度（x[:, 0]）
v = x[:, 0]
grads = torch.autograd.grad(y_hat, v, grad_outputs=torch.ones_like(y_hat), create_graph=True)[0] # ...
]]></description>
      <guid>https://stackoverflow.com/questions/78956646/autograd-in-pytorch-lightning-in-trainstep</guid>
      <pubDate>Fri, 06 Sep 2024 10:08:53 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras 中使用 flow_from_directory 和多个目录实现多输出神经网络</title>
      <link>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</link>
      <description><![CDATA[我需要使用 Keras 中的 flow_from_directory 从多个目录加载图像。我的目录结构如下：
Images_folder/ 
═── Carpet_1/ 
│ ═── training/ 
│ │ ═── class_1/ 
│ │ ═── class_2/ 
│ ═── validation/ 
═── Carpet_2/ 
│ ═── training/ 
│ │ ═── class_1/ 
│ │ ═── class_2/ 
│ ═── validation/ 
...

每个“Carpet”目录（例如 Carpet_1、Carpet_2）包含相同的一组类（class_1、class_2 等）。我想使用来自所有这些目录的图像来训练 CNN。我的目标是构建一个多输出神经网络，其中一个输出预测“Carpet”数字（1、2、3、...），另一个输出预测该地毯内的类别。
鉴于这种结构，我如何使用 ImageDataGenerator 或 Keras 中的任何其他方法来加载和预处理这些图像？有没有办法将所有这些目录中的图像组合成一个生成器，同时仍然允许我区分不同的地毯？]]></description>
      <guid>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</guid>
      <pubDate>Thu, 05 Sep 2024 07:56:05 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用 Google Teachable 机器模型作为对象检测模型吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78951811/can-i-use-google-teachable-machine-model-as-object-detection-model</link>
      <description><![CDATA[我正在开发一款带有对象检测功能的移动自动收银应用程序。我面临的问题是，自定义项目的变体太多了（大约 250 个类别）。如果我要对以前的模型（如 MobileNet 或 YOLO）进行微调，这将花费太多时间，因为我仍然需要创建 POS、数据库和集成热敏打印机。
那么，我是否可以只使用 Google Teachable Machine 来处理我的对象检测数据集（假设背景相同），而不是对以前的模型进行微调？
应用程序的工作方式是，收银员将在白色背景上拍摄买家想要购买的商品的照片，然后应用程序将自动检测出哪些商品在画面中（使用 Google Teachable Machine .tflite 模型）。
Teachable Machine .tflite 模型是否可以替换下面代码中的 modelPath？
private fun runObjectDetection(bitmap: Bitmap) {
// 步骤 1：创建 TFLite 的 TensorImage 对象
val image = TensorImage.fromBitmap(bitmap)

// 步骤 2：初始化检测器对象
val options = ObjectDetector.ObjectDetectorOptions.builder()
.setMaxResults(5)
.setScoreThreshold(0.5f)
.build()
val detector = ObjectDetector.createFromFileAndOptions(
this, // 应用程序上下文
**&quot;model.tflite&quot;, **
options
)
// 步骤 3：将给定的图像输入模型并打印检测结果
val results = detector.detect(image)

// 步骤 4：解析检测结果并显示
debugPrint(results)

val resultToDisplay = results.map {
// 获取 top-1 类别并制作显示文本
val category = it.categories.first()
val text = &quot;${category.label}, ${category.score.times(100).toInt()}%&quot;

// 创建数据对象，用于显示检测结果
DetectionResult(it.boundingBox, text)
}

// 将检测结果绘制到位图上并显示。
val imgWithResult = drawDetectionResult(bitmap, resultToDisplay)
runOnUiThread {
inputImageView.setImageBitmap(imgWithResult)
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/78951811/can-i-use-google-teachable-machine-model-as-object-detection-model</guid>
      <pubDate>Thu, 05 Sep 2024 07:38:34 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络将输入分成几组[关闭]</title>
      <link>https://stackoverflow.com/questions/78950639/using-a-neural-network-to-separate-inputs-into-groups</link>
      <description><![CDATA[原始问题如下：
许多粒子撞击某些探测器，我们从这些事件中获得的信息是每次激活的坐标。探测器层层相继，我们可以为每个粒子绘制一些轨迹，只知道它经过的几个有探测器的坐标。
现在神经网络的问题是向它提供一段时间内发生的所有撞击坐标，并让它返回哪些撞击属于一个粒子，哪些属于另一个粒子
我对输出的唯一想法是给遵循相同轨迹的每个撞击系列编号，编号相同，最后得到一个向量“命名”每个输入坐标。我怀疑神经网络是否可以“即兴”这样的标签，因为理论上它应该迭代的每个数字不一定与任何可能的输入有联系，唯一的条件是当它们不属于同一个粒子时，它们彼此不同。
有没有更好的方法可以做到这一点？这是否可以作为解决问题的合理方法？]]></description>
      <guid>https://stackoverflow.com/questions/78950639/using-a-neural-network-to-separate-inputs-into-groups</guid>
      <pubDate>Wed, 04 Sep 2024 21:41:04 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 尽管进行了子采样并且没有设置种子，仍然表现确定性吗？</title>
      <link>https://stackoverflow.com/questions/76691875/xgboost-behaving-deterministically-despite-subsampling-and-not-setting-seed</link>
      <description><![CDATA[据我所知，XGBoost（版本 1.7.4）中的子采样是随机进行的，因此应该将随机行为引入 xgboost - 随机梯度下降也应如此。但是，当我在相同的数据分割上训练/测试 xgboost 时，尽管没有在任何地方设置随机状态，但我总是得到相同的结果，这是为什么？
在定义 XGBoostRegressor 时，我尝试在有和没有 seed=42 的情况下运行代码。我为精心挑选的数据执行了此操作，以便我知道随机行为只能源自 XGBoost 模型本身，而不是来自变量数据分割。]]></description>
      <guid>https://stackoverflow.com/questions/76691875/xgboost-behaving-deterministically-despite-subsampling-and-not-setting-seed</guid>
      <pubDate>Sat, 15 Jul 2023 01:24:32 GMT</pubDate>
    </item>
    <item>
      <title>机器学习：使用卷积神经网络将图像分为 3 类（狗、猫或非猫）</title>
      <link>https://stackoverflow.com/questions/40853349/machine-learning-image-classification-into-3-classes-dog-or-cat-or-neither-us</link>
      <description><![CDATA[如果您能帮我仔细思考一下，我将不胜感激。我有一个分类器，可以成功地将图像分类为狗或猫，并且准确度很高。我有一个很好的数据集来训练分类器。到目前为止没有问题。
我有大约 20,000 张狗和 20,000 张猫的图像。
但是，当我尝试呈现其他图像（如汽车、建筑物或老虎）时，这些图像中既没有狗也没有猫，我希望分类器的输出为“既不是”。现在，分类器显然试图将所有东西都分类为狗或猫，这是不正确的。
问题 1：
我该如何实现这一点？我是否需要有第三组不包含狗或猫的图像，并在这些额外的图像上训练分类器以将其他所有图像识别为“既不”？
大致来说，我需要多少张非狗/猫类别的图像才能获得良好的准确率？由于非狗/猫图像域非常大，大约 50,000 张图像就可以了？或者我是否需要更多图像？
问题 2：
我可以使用 Imagenet 训练的 VGG16 Keras 模型作为初始层，并在顶部添加 DOG/CAT/Neither 分类器作为全连接层，而不是使用自己的图像数据训练自己的分类器？
查看此示例以加载预先训练的 imagenet 模型
非常感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/40853349/machine-learning-image-classification-into-3-classes-dog-or-cat-or-neither-us</guid>
      <pubDate>Mon, 28 Nov 2016 20:58:33 GMT</pubDate>
    </item>
    </channel>
</rss>