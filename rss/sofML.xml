<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 18 Jan 2024 18:17:52 GMT</lastBuildDate>
    <item>
      <title>所有分类模型的性能都很糟糕[关闭]</title>
      <link>https://stackoverflow.com/questions/77841260/terrible-performance-for-all-classification-models</link>
      <description><![CDATA[在此处输入图像描述
因此，我正在创建分类模型来预测一个目标，该目标代表公司是否有很大可能实现其可持续发展目标。到目前为止，这些是我的模型（我知道它绝对是狗水，因为我之前构建过其他模型，没有什么可以与此相比）。有没有 ML/AI 专业人士可以推荐我可以做什么？
这里是数据集的链接：https://github.com/ Javen05/stackoverflow/blob/main/sustainability_data_set1.csv
可以补充来自任何来源的额外外部数据/数据集。

尝试过决策树、逻辑回归和神经网络。

这些基准模型的性能非常糟糕。

希望听到关于如何通过有用的特征工程、补充外部数据集或模型配置来提高性能的意见和技巧。

]]></description>
      <guid>https://stackoverflow.com/questions/77841260/terrible-performance-for-all-classification-models</guid>
      <pubDate>Thu, 18 Jan 2024 17:14:00 GMT</pubDate>
    </item>
    <item>
      <title>ML .NET 训练异常 [关闭]</title>
      <link>https://stackoverflow.com/questions/77840868/ml-net-exception-on-training</link>
      <description><![CDATA[我正在使用模型生成器 UI，选择 NLP 文本分类。
目标是尝试“清洁”数据丑陋，所以我制作了一个金融交易的样本数据集。这个想法是输入 Amazon Digit*8SDFS98 amzn.com/bill WA Am 应该输出：“Amazon Digital”。
但是我在训练后收到此错误。我认为数据有问题（除了它根本不是一个大数据集，但它都是模拟数据，只是为了学习这些东西）。
在此处输入图像描述
重现步骤。

使用此数据（或喜欢它）创建 csv。
打开 VS 并添加机器学习模型
选择“文本分类”如场景所示。
选择清理后的描述作为标签（目标）
选择“描述”作为数据
点击“下一步”去火车。
开始训练。
收到错误。

有没有办法从这个错误中找出实际问题是什么？
 位于 System.RuntimeMethodHandle.InvokeMethod（对象目标、对象[] 参数、签名 sig、布尔构造函数）
   在 System.Reflection.RuntimeMethodInfo.UnsafeInvokeInternal（对象 obj，对象 [] 参数，对象 [] 参数）
   在System.Reflection.RuntimeMethodInfo.Invoke（对象obj，BindingFlags invokeAttr，Binder活页夹，Object []参数，CultureInfo文化）
   在 Microsoft.ML.Runtime.ComponentCatalog.LoadableClassInfo.CreateInstanceCore(Object[] ctorArgs)
   在 Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes]（IHostEnvironment env，类型签名类型，TRes&amp;结果，字符串名称，字符串选项，Object[] 额外）
   在 Microsoft.ML.Runtime.ComponentCatalog.TryCreateInstance[TRes,TSig](IHostEnvironment env, TRes&amp; 结果，字符串名称，字符串选项，Object[] extra)
   在 Microsoft.ML.ModelLoadContext.TryLoadModelCore[TRes,TSig](IHostEnvironment env, TRes&amp; result, Object[] extra)
   在 Microsoft.ML.ModelLoadContext.TryLoadModel[TRes,TSig](IHostEnvironment env、TRes&amp; 结果、RepositoryReader 代表、Entry ent、String dir、Object[] extra)
   在 Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env、TRes&amp; 结果、RepositoryReader 代表、Entry ent、String dir、Object[] extra)
   在 Microsoft.ML.ModelLoadContext.LoadModelOrNull[TRes,TSig](IHostEnvironment env、TRes&amp; 结果、RepositoryReader 代表、String dir、Object[] extra)
   在 Microsoft.ML.ModelLoadContext.LoadModel[TRes,TSig](IHostEnvironment env、TRes&amp; 结果、RepositoryReader 代表、String dir、Object[] extra)
   在 Microsoft.ML.ModelOperationsCatalog.Load（流流、DataViewSchema&amp; inputSchema）
   在 Microsoft.ML.ModelOperationsCatalog.Load(String filePath, DataViewSchema&amp; inputSchema)
   在 /_/src/Microsoft.ML.ModelBuilder.AutoMLService/ServiceFactory/CodeGeneratorService 中的 Microsoft.ML.ModelBuilder.AutoMLService.ServiceFactory.CodeGeneratorService.SetTorchRunTimeFolderAndLoadModel（ITrainingConfiguration 配置、字符串 modelPath、MLContext 和上下文、ITransformer 和模型、DataViewSchema 和 inputSchema） .cs：第 139 行
   在 /_/src/Microsoft.ML.ModelBuilder 中的 Microsoft.ML.ModelBuilder.AutoMLService.ServiceFactory.CodeGeneratorService.GenerateConsumationAsync（ITrainingConfiguration 配置、字符串trainingConfigurationFolder、字符串nameSpace、字符串className、TargetType 目标、String[] 标签、CancellationToken ct）。 AutoMLService/ServiceFactory/CodeGeneratorService.cs：StreamJsonRpc.JsonRpc 处的第 155 行。d__151`1.MoveNext()
--- 从先前抛出异常的位置开始的堆栈跟踪结束 ---
   在 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()
   在 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification（任务任务）
   在 System.Runtime.CompilerServices.TaskAwaiter`1.GetResult()
   在 Microsoft.ML.ModelBuilder.ViewModels.TrainViewModel.d__100.MoveNext()

我尝试清理数据（没有重复值，两列中都没有空格）。]]></description>
      <guid>https://stackoverflow.com/questions/77840868/ml-net-exception-on-training</guid>
      <pubDate>Thu, 18 Jan 2024 16:14:56 GMT</pubDate>
    </item>
    <item>
      <title>CNN 模型训练循环中的批量大小不匹配</title>
      <link>https://stackoverflow.com/questions/77840815/batch-size-in-training-loop-of-a-cnn-model-is-not-matching</link>
      <description><![CDATA[这是我的 CNN 模型，适用于 400x400 的灰度图像：
导入火炬
将 torch.nn 导入为 nn

类 MModel(nn.Module):
    def __init__(自身):
        超级（MModel，自我）.__init__()
        
        # 定义卷积层
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        
        # 计算全连接层之前展平特征图的大小
        self.fc_input_size = 64 * 200 * 200
        
        # 定义全连接层
        self.fc1 = nn.Linear(self.fc_input_size, 128)
        self.fc2 = nn.Linear(128, 18) # 根据您的要求调整输出大小
        
    def 前向（自身，x）：
        # 应用卷积层和池化层
        x = self.pool(nn.function.relu(self.conv1(x)))
        x = self.pool(nn.function.relu(self.conv2(x)))
        
        # 展平特征图
        x = x.view(-1, self.fc_input_size)
        
        # 应用全连接层
        x = nn.function.relu(self.fc1(x))
        x = self.fc2(x)
        
        返回x

# 创建 CNN 模型的实例
模型 = MModel()

这是我的训练循环：
导入火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim
从 torch.utils.data 导入 DataLoader
导入 torchvision.transforms 作为变换

标准 = nn.CrossEntropyLoss()
优化器 = optim.Adam(model.parameters(), lr=0.001)

# 训练循环
纪元数 = 10

对于范围内的纪元（num_epochs）：
    运行损失 = 0.0

    对于 i，enumerate(train_DL, 0) 中的数据：
        输入，标签=数据

        # 将参数梯度归零
        优化器.zero_grad()

        # 前向传递
        输出 = 模型（输入）

        # 计算损失
        损失=标准（输出，标签）

        # 向后传递和优化
        loss.backward()
        优化器.step()

        # 打印统计数据
        running_loss += loss.item()

        if i % 10 == 9: # 每 10 个小批量打印一次
            print(f&quot;[{epoch + 1}, {i + 1}] 损失: {running_loss / 10:.3f}&quot;)
            运行损失 = 0.0

print(&quot;训练结束&quot;)

运行此代码时，我收到此错误，我的 DataLoader 的批处理大小为 32：
ValueError：预期输入batch_size (8) 与目标batch_size (32) 匹配。

我尝试将批量大小更改为 8，但这仍然给我带来了值错误。另外，在 StackOverflow 上找到的其他解决方案似乎也不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/77840815/batch-size-in-training-loop-of-a-cnn-model-is-not-matching</guid>
      <pubDate>Thu, 18 Jan 2024 16:05:59 GMT</pubDate>
    </item>
    <item>
      <title>安装适用于 Python 3.11 的 Neurolab</title>
      <link>https://stackoverflow.com/questions/77840804/install-neurolab-for-python-3-11</link>
      <description><![CDATA[我正在尝试将 neurolab 软件包安装到我的 Python 3.11 环境中。
我将 Anaconda 与 Python 版本 3.11 结合使用。在 Anaconda 页面上找到的 Neurolab 的可用版本如下：

但是这些版本都不适用于 Python 3.11 。我尝试通过 Anaconda Navigator 和 CMD（我使用 Windows 11）安装。
如何使用我的 Python 版本安装此软件包（或类似的可用版本）？]]></description>
      <guid>https://stackoverflow.com/questions/77840804/install-neurolab-for-python-3-11</guid>
      <pubDate>Thu, 18 Jan 2024 16:04:02 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 图执行错误：训练期间形状不兼容</title>
      <link>https://stackoverflow.com/questions/77840662/lstm-graph-execution-error-incompatible-shapes-during-training</link>
      <description><![CDATA[我对于使用深度网络还很陌生。我正在尝试使用 LSTM 来使用 keras 执行（我认为是）简单的二元分类。我的数据集由小说中的文本块组成，我使用这些文本进行处理：
def process_data(数据):
    文本 = data[&#39;text&#39;].tolist()
    标签 = data[&#39;label&#39;].tolist()

    tokenizer.fit_on_texts(文本)
    序列 = tokenizer.texts_to_sequences(texts)

    X_pated = pad_sequences(序列, maxlen=2000)
    X_sliding_window, y_sliding_window = create_sliding_window_data(
        X_填充，标签）

    y_train_reshape = np.expand_dims(y_sliding_window, axis=-1)

    返回 X_sliding_window, y_train_reshape

在将其输入 BiLSTM 之前：
def build_model（sequence_length，embedding_dim，batch_size）：
    输入层=输入（形状=（序列长度，
                        embedding_dim),batch_size=batch_size)
    lstm = 双向（
        LSTM(64, return_sequences=True, stateful=True))(input_layer)
    注意力=注意力（）（[lstm，lstm]）
    合并=连接（轴=-1）（[lstm，注意]）
    输出层=密集（1，激活=&#39;sigmoid&#39;）（合并）

    模型=模型（输入=输入层，输出=输出层）
    model.compile(优化器=&#39;亚当&#39;,
                  损失=&#39;binary_crossentropy&#39;，指标=[&#39;准确性&#39;]）

    返回模型

我一直在努力理解为什么会出现以下错误以及如何修复它：
图形执行错误：

在节点gradient_tape/binary_crossentropy/mul/Mul处检测到（最近一次调用最后）：

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py”，第 65 行，位于 error_handler 中

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py”，第 1807 行，适合

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py”，第 1401 行，在 train_function 中

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py”，第1384行，在step_function中

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py”，第 1373 行，在 run_step 中

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py”，第 1154 行，在 train_step 中

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py”，第 598 行，最小化

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py”，第 656 行，位于 _compute_gradients 中

  文件“/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/optimizers/legacy/optimizer_v2.py”，第 532 行，在 _get_gradients 中

不兼容的形状：[26,1] 与 [64,250]
         [[{{节点gradient_tape/binary_crossentropy/mul/Mul}}]] [操作：__inference_train_function_4934]

我使用的参数是：
&lt;前&gt;&lt;代码&gt;sequence_length = 250
embedding_dim = X_train.shape[2]
批量大小 = 64

我检查了训练形状，即 y_train.shape: (218, 1) X_train.shape: (218, 250, 2000) 对我来说似乎没问题......我不知道在哪里 [26 ,1] 会来自。有人可以帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/77840662/lstm-graph-execution-error-incompatible-shapes-during-training</guid>
      <pubDate>Thu, 18 Jan 2024 15:43:11 GMT</pubDate>
    </item>
    <item>
      <title>如何使用经过训练/测试的线性回归模态进行预测[关闭]</title>
      <link>https://stackoverflow.com/questions/77840461/how-to-make-prediction-with-linear-regression-modal-that-has-been-trained-tested</link>
      <description><![CDATA[我在我的数据集上制作了线性回归模态。但我不知道如何让模态进行预测。
我的数据集的格式为年份、旅程类型、VALUE作为列标题。我想预测数据集中未包含的年份的值（因为我没有此数据）。所以我想预测 2023-2027 年的值。
线性回归的变量是
X = &#39;年份&#39;
y = &#39;VALUE&#39;
我尝试了不同的方法，但似乎都不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/77840461/how-to-make-prediction-with-linear-regression-modal-that-has-been-trained-tested</guid>
      <pubDate>Thu, 18 Jan 2024 15:14:05 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 过度拟合 [关闭]</title>
      <link>https://stackoverflow.com/questions/77839964/xgboost-overfitting</link>
      <description><![CDATA[我一直在尝试使用 XGBoost（Last sem 迷你项目）构建流失预测模型。
但无论我做什么，模型都会过度拟合，我无法提前停止，因为我找不到最佳点。
该模型仅预测未见过的数据集中的一个值（在本例中为 1）。
是因为训练数据集（它是通过 minmaxscaler 进行平衡和缩放的）吗？
499998 行 × 11 列
有人遇到过这种情况吗？
我缩放并平衡了训练数据集
这些是我使用的参数：

测试大小 = 0.33
随机状态 = 7
子样本：0.5
reg_lambda: 5
reg_alpha：0.1
n_估计器：800
最小分割损失：0
最小儿童体重：0
最大深度：3
学习率：0.3
colsample_bytree：0.7
colsample_bynode：0.9
colsample_bylevel: 0.7


训练精度：0.9993223840142329
测试精度：0.9991333333333333
混淆矩阵：流失 0.0 1.0
行_0
0 82533 140
1 3 82324
]]></description>
      <guid>https://stackoverflow.com/questions/77839964/xgboost-overfitting</guid>
      <pubDate>Thu, 18 Jan 2024 14:00:32 GMT</pubDate>
    </item>
    <item>
      <title>模型遭受巨大损失[关闭]</title>
      <link>https://stackoverflow.com/questions/77839031/model-getting-huge-loss</link>
      <description><![CDATA[我正在尝试按标题制作文本生成器。文本最大长度为2500，词典大小为45,000字。这是我正在使用的模型。在训练过程中，损失增加，但准确率保持不变。
那么，我的模型出了什么问题？
&lt;前&gt;&lt;代码&gt;纪元 1/75
1311/1311 [================================] - 461s 347ms/步 - 损失：27230606.0000 - 准确度：0.0382
纪元 2/75
1311/1311 [================================] - 454s 346ms/步 - 损失：78650848.0000 - 准确度：0.0382


我在 anaconda 环境中使用 Tensorflow GPU 和 python 3.11。
模型 = keras.Sequential([
    嵌入（vocab_size，256，input_length = max_sequence_length），
    LSTM（单位= 256，kernel_regularizer = l2（0.01），return_sequences = True），
    LSTM（单位= 128，kernel_regularizer = l2（0.01）），
    密集（max_sequence_length，激活=&#39;softmax&#39;）
]）

亚当 = 亚当(lr=0.01)

model.compile(optimizer=adam,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
model.fit（标题_序列_填充，食谱_序列_填充，纪元= 75，详细= 1，
          回调=[ModelCheckpoint(filepath=Settings.new_model_path)])

我尝试增加单位数量、损失类型​​，但没有任何效果。]]></description>
      <guid>https://stackoverflow.com/questions/77839031/model-getting-huge-loss</guid>
      <pubDate>Thu, 18 Jan 2024 11:28:10 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的有损与无损音频格式</title>
      <link>https://stackoverflow.com/questions/77837837/lossy-vs-lossless-audio-format-in-machine-learning</link>
      <description><![CDATA[我们希望提供一种通过声音识别疾病的机器学习模型。特征提取基于专有算法。通常我们一直使用wav文件。我们一直在问自己是否也可以使用像 mp3 这样的东西？由于我们可能无法再次收集我们收集的数据，并且我们无法预见我们的专有算法的进一步开发在某个时候将需要什么样的信息，因此我们担心像 mp3 这样的东西会导致太多信息丢失。你觉得怎么样？
疾病示例：多动症、抑郁症、糖尿病、帕金森病、自杀。
算法生成特征的类别示例：旋律、节奏、停顿、语速、动态...
我对具体答案不太感兴趣，因为我知道由于某些细节的悬而未决的问题，不可能给出具体答案。更多的是分享经验和交流想法。例如，有人在机器学习领域有过这样的经验：MP3 中被切除的区域通常对 ML 算法影响很小或没有影响。这只是一个例子。我在互联网上还没有真正找到有关此主题的任何内容。
即使这与“非此即彼”没有太大关系。关于支持格式的决定，一个 &lt;a href=&quot;https://medium.com/voice-tech-podcast/improve-your-machine-learning-with-compressed-audio-3393a6c55aba&quot; rel=&quot;nofollow noreferrer例如，文章&lt;/a&gt;建议如下：“数据增强是机器学习领域众所周知的实践。我们可以简单地将音频数据的编码版本视为数据的增强，就像我们通过添加交通噪声或模拟干净语音的房间回声一样。例如，仅使用几个不同的 Opus 质量级别来增强训练数据将改善所有 Opus 测试样本的分类。” ...这非常有趣。]]></description>
      <guid>https://stackoverflow.com/questions/77837837/lossy-vs-lossless-audio-format-in-machine-learning</guid>
      <pubDate>Thu, 18 Jan 2024 08:13:51 GMT</pubDate>
    </item>
    <item>
      <title>召回分数！=使用confusion_matrix手动计算</title>
      <link>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</link>
      <description><![CDATA[我遇到了一个问题，即使用 recall_score(y, y_pred) 获得的召回分数与使用 confusion_matrix 手动计算的值不匹配。
不仅如此，召回率与特异性的值完全相同，我也在下面手动计算了该值。
这是我正在使用的相关代码：
recall = recall_score(y, y_pred) # &lt;-- 不同的分数

conf_matrix = fusion_matrix(y, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()
Manual_recall = tp / (tp + fn) # &lt;-- 达到这个分数
特异性 = tn / (tn + fp) # &lt;-- 与上面的分数相同

这是发生这种情况的终端中打印的混淆矩阵的示例：
&lt;前&gt;&lt;代码&gt;[[34 6]
 [20 20]]

科学套件召回：0.85
手动召回：0.5
或
&lt;前&gt;&lt;代码&gt;[[29 11]
 [9 31]]

科学套件召回：0.725
手动召回：0.775
问题：
scikit-learn 返回的召回和手动召回不会产生相同的值。
问题：
为什么recall_score和使用confusion_matrix的手动计算可能会产生不同的召回分数结果？
更多信息...

这是一个二元分类问题。

我正在使用 recall_score 的默认阈值。

我尝试确定混淆表是否准确（确实如此）。

]]></description>
      <guid>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</guid>
      <pubDate>Wed, 17 Jan 2024 18:08:23 GMT</pubDate>
    </item>
    <item>
      <title>事故报告统一分类：多类分类问题[关闭]</title>
      <link>https://stackoverflow.com/questions/77825594/accident-reports-to-unified-taxonomy-a-multi-class-classification-problem</link>
      <description><![CDATA[我来这里是为了集思广益，为我的标签问题寻找可能的解决方案。
核心数据
我有约 4500 份滑翔伞事故报告。报告是非结构化文本，有些在多个页面上对事件的不同方面进行了详细阐述，有些只有几行。
我的想法
从事故中提取语义相关信息，形成统一的分类，以便进一步分析事故原因等。
我的方法
我想使用主题建模为所有事故创建统一的分类法，其中几乎可以捕获每个事故的所有相关信息。然后，分类法 + 一次事故将形成一次 API 调用。在大约 4500 次 API 调用之后，我最终应该得到由统一分类法表示的所有事故。
示例
分类法有不同的类别，例如天气、飞行员经验、表面状况等。这些主要类别进一步细分，例如，天气 -&gt; 天气风-&gt;速度。
当前状态
目前，我的分类法尚未完成，但我估计在一次事故中大约需要注意 150 个参数。一年前我也研究过类似的问题，用 GPT 构建了一个语音助手。在那里，我使用 Davinci 将语音输入转换为具有预定义 JSON 操作的 JSON 格式。这对于大多数情况都适用，但我必须对输出进行后处理，因为格式并不总是正确的，等等。
目前，我的担忧和问题是：

与我的语音助手 (14) 相比，现在有更多的类别 (150) 和更大的文本输入（语音助手只有一句话，现在一整份事故报告多达 8 页），GPT 使用的类别与那些不同分类学中定义的，或幻觉不可预测的。
如何有效地从 GPT 获取结构化输出（此处以分类法的形式）？
我的解决方案能否按预期工作？
这是实现我的目标的明智方法吗？
有哪些替代方案？
]]></description>
      <guid>https://stackoverflow.com/questions/77825594/accident-reports-to-unified-taxonomy-a-multi-class-classification-problem</guid>
      <pubDate>Tue, 16 Jan 2024 11:59:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么支持向量机的 varImp() 出现错误？</title>
      <link>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</guid>
      <pubDate>Mon, 25 Dec 2023 17:08:22 GMT</pubDate>
    </item>
    <item>
      <title>即使使用 IQR 方法去除异常值。异常值仍然存在于数据中</title>
      <link>https://stackoverflow.com/questions/77662142/even-though-removing-the-outliers-using-the-iqr-method-the-outliers-are-still-p</link>
      <description><![CDATA[我使用箱线图方法找到了数据中的异常值。
在此处输入图像描述应用 IQR 方法之前的箱形图
&lt;前&gt;&lt;代码&gt;file1.shape
# (457, 11)

我已对数据应用了 IQR 方法。
q1, q2, q3 = file1[&#39;工资&#39;].quantile([0.25, 0.5, 0.75])
IQR = q3 - q1
f_data = file1[(file1[&#39;工资&#39;] &gt; lower_bound) &amp; (file1[&#39;工资&#39;] &lt; upper_bound)]

我删除了一些数据点。
&lt;前&gt;&lt;代码&gt;f_data.shape
# (420, 11)

但是，在使用箱线图查看过滤后的数据后，我仍然在数据中发现了一些异常值。
在此处输入图像描述应用 IQR 方法后的箱线图。
我现在应该做什么。
我是否必须对过滤后的数据再次执行 IQR 方法。
薪资数据是右偏数据。其偏差值约为 1.5
或者我应该减少倾斜值。就像使用 log、power 方法一样。]]></description>
      <guid>https://stackoverflow.com/questions/77662142/even-though-removing-the-outliers-using-the-iqr-method-the-outliers-are-still-p</guid>
      <pubDate>Thu, 14 Dec 2023 17:45:51 GMT</pubDate>
    </item>
    <item>
      <title>我无法从 C++ 安装用于姿势检测的 openpose 库</title>
      <link>https://stackoverflow.com/questions/76959397/i-could-not-installl-a-openpose-library-from-c-for-pose-detection</link>
      <description><![CDATA[我已经使用 C++ 为我的姿势检测项目安装了 OpenPose 库。但是，我在安装过程中遇到了困难，特别是在尝试按照  上提供的说明下载模型时https://sourceforge.net/projects/openpose.mirror/。
这些是他们提供的说明：
&lt;前&gt;&lt;代码&gt;1。双击“models/getBaseModels.bat”下载所需的身体、面部和手部模型。
    - 可选：双击“models/getCOCO_and_MPII_optional.bat”下载 COCO 和 MPII 模型（速度较慢且不太准确，只有在确实有理由这样做时才下载）。
2.检查所有信息：
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/tree/v1.7.0
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/
3. 特别是C++快速入门指南：
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/quick_start.md
4. 对于 Python，请检查 C++ 快速入门指南（相同标志）和 Python 测试文档：
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/quick_start.md
    - https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/v1.7.0/doc/modules/python_module.md#testing，但替换“cd build/examples/tutorial_api_python”通过“cd python/”。
        - 注意：其余的 python_module.md 指令是针对 GitHub 源代码库的，您可以在这里忽略它们。
    - Python 代码示例：

cd {OpenPose_root_path}
cd 蟒蛇/
python openpose_python.py

但是，当我尝试从下载的文件夹运行 models/getBaseModels.bat 脚本时，它不会下载或安装任何内容。相反，它不断尝试下载但没有成功。这是我在命令提示符中看到的输出片段：
------------------------ 身体、脚、脸和手模型 ---------- ----------------
----- 下载身体姿势（COCO 和 MPI）、面部和手部模型 -----

------------------------- 姿势（身体+脚）模型 ------------------ --------
身体 (BODY_25)
--2023-08-23 12:50:47-- http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel
正在解析posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)... 64:ff9b::8002:dc39, 128.2.220.57
连接到posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)|64:ff9b::8002:dc39|:80...失败：未知错误。
正在连接到posefs1.perception.cs.cmu.edu (posefs1.perception.cs.cmu.edu)|128.2.220.57|:80...


由于此问题，我无法进一步继续我的项目。您能否提供一个解决方案或建议一种用于姿势检测和获取关键坐标的替代方法]]></description>
      <guid>https://stackoverflow.com/questions/76959397/i-could-not-installl-a-openpose-library-from-c-for-pose-detection</guid>
      <pubDate>Wed, 23 Aug 2023 07:56:16 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型的扩展</title>
      <link>https://stackoverflow.com/questions/64739128/scaling-on-machine-learning-models</link>
      <description><![CDATA[我对机器学习模型中的缩放概念有点困惑。
在分类中，如果变量具有不同的尺度，我通常对自变量进行缩放，对目标变量进行标签编码，并对预测结果进行逆变换以获得实际标签
在回归中，如果我的变量不同，我知道我们必须缩放自变量，我是否也应该缩放我的目标变量？
如果我在上述情况下的理解是正确的，有人可以帮助我吗？我应该在回归模型中缩放我的目标变量吗？
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/64739128/scaling-on-machine-learning-models</guid>
      <pubDate>Sun, 08 Nov 2020 14:18:39 GMT</pubDate>
    </item>
    </channel>
</rss>