<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 26 Jan 2024 18:17:11 GMT</lastBuildDate>
    <item>
      <title>TF-TRT 警告：无法 dlopen 某些 TensorRT 库</title>
      <link>https://stackoverflow.com/questions/77888210/tf-trt-warning-cannot-dlopen-some-tensorrt-libraries</link>
      <description><![CDATA[我一直在尝试在HPC集群上搭建虚拟环境，但是每次涉及到使用GPU的tensorflow时都碰壁。
模块加载 python3.8/3.8 eval “$(conda shell.bash hook)” conda 激活 graphgan
之后我使用以下命令来设置环境
conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0
当我尝试将tensorflow导入为tf时，它显示以下错误
2024-01-26 23:06:17.968937: I tensorflow/core/platform/cpu_feature_guard.cc:193] 此 TensorFlow 二进制文件使用 oneAPI 深度神经网络库（在 eDNN 上）进行了优化，以使用以下 CPU性能关键操作中的指令：AVX2 AVX512F FMA 要在其他操作中启用它们，请使用适当的编译器标志重建 TensorFlow。 2024-01-26 23:06:18.289070: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] 无法注册 cuBLAS 工厂：在已注册插件 cu BLAS 的情况下尝试注册工厂 2024-01-26 23 ：06：20.132284：Wtensorflow/stream_executor/platform/default/dso_lo ader.cc:64]无法加载动态库“libnvinfer.so.7”； dlerror: libnvinfe r.so.7: 无法打开共享对象文件: 没有这样的文件或目录； LD_LIBRARY_PATH：/opt/ohpc/pub/apps/anaconda3/envs/py38/lib:/home/vanshg.phy21.iitbhu/.conda/envs/graphgan/lib/2024-01-26 23:06:20.132710:W tensorflow/stream_executor/platform/default/dso_lo ader.cc:64] 无法加载动态库“libnvinfer_plugin.so.7”； dlerror: li bnvinfer_plugin.so.7: 无法打开共享对象文件: 没有这样的文件或目录； LD_LIBRARY_PATH：/opt/ohpc/pub/apps/anaconda3/envs/py38/lib:/home/vanshg.phy21。 iitbhu/.conda/envs/graphgan/lib/ 2024-01-26 23:06:20.132755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc: 38] TF-TRT 警告：无法 dlopen 某些 TensorRT 库。如果您想将 Nvidia GPU 与 TensorRT 一起使用，请确保正确安装了上面提到的缺少的库。
我知道这将毫无问题地运行我的代码，但我想使用 GPU 加速。谁能告诉我我应该做什么来解决这个问题
我预计 GPU 会被检测到，就像我在教程中看到的那样。相反，它开始抛出错误。我还检查了它提到的目录，确实文件丢失了。为了使其工作，我必须安装哪些额外的库？]]></description>
      <guid>https://stackoverflow.com/questions/77888210/tf-trt-warning-cannot-dlopen-some-tensorrt-libraries</guid>
      <pubDate>Fri, 26 Jan 2024 18:02:56 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到 ml_utils.model GPS？我看过一些论文引用了这些依赖项，但找不到带有 gp 的 ml_utils 包</title>
      <link>https://stackoverflow.com/questions/77887931/where-can-i-find-ml-utils-model-gps-ive-seen-a-few-papers-reference-these-depe</link>
      <description><![CDATA[ml_utils 包是否仍然存在于 .models.gp 中？
我找不到它，但现在已经在 4 篇以上的论文中看到过它。
谢谢！
阿沃
找到了 pandas ml_utils 文档 (https://github .com/KIC/pandas_ml_utils/blob/master/pandas_ml_utils/model/models.py），但在模型下没有看到任何 GP。有人可以帮我弄清楚这些论文是用什么做的吗？他们都只是说“from ml_utils.model import gp”并在依赖项下列出 ml_utils。]]></description>
      <guid>https://stackoverflow.com/questions/77887931/where-can-i-find-ml-utils-model-gps-ive-seen-a-few-papers-reference-these-depe</guid>
      <pubDate>Fri, 26 Jan 2024 17:11:19 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Azure AI 文档智能下载客户训练的模型</title>
      <link>https://stackoverflow.com/questions/77887035/how-to-download-custome-trained-models-with-azure-ai-document-intelligence</link>
      <description><![CDATA[有没有办法下载我在 Azure AI Document Intelligence Studio 中训练的模型并在本地使用]]></description>
      <guid>https://stackoverflow.com/questions/77887035/how-to-download-custome-trained-models-with-azure-ai-document-intelligence</guid>
      <pubDate>Fri, 26 Jan 2024 14:46:05 GMT</pubDate>
    </item>
    <item>
      <title>客户流失的时间感知数据 - 帮助解决 ML 问题以了解方法是否正确以及模型建议 [关闭]</title>
      <link>https://stackoverflow.com/questions/77886825/time-aware-data-for-customer-churn-help-on-ml-problem-to-understand-if-the-app</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77886825/time-aware-data-for-customer-churn-help-on-ml-problem-to-understand-if-the-app</guid>
      <pubDate>Fri, 26 Jan 2024 14:09:29 GMT</pubDate>
    </item>
    <item>
      <title>电子邮件解析的电子邮件隔离[关闭]</title>
      <link>https://stackoverflow.com/questions/77886784/segregation-of-emails-for-email-parsing</link>
      <description><![CDATA[我正在研究电子邮件解析，并面临一个问题，我想将报价电子邮件与其他电子邮件分开并仅提取那些电子邮件（报价）。
现在我能够阅读所有未读电子邮件并转换和提取所有这些电子邮件，但无法找到仅提取报价电子邮件的方法。
如果您能提出任何方法来做到这一点，我将非常感激。]]></description>
      <guid>https://stackoverflow.com/questions/77886784/segregation-of-emails-for-email-parsing</guid>
      <pubDate>Fri, 26 Jan 2024 14:03:47 GMT</pubDate>
    </item>
    <item>
      <title>如何增加特征数量</title>
      <link>https://stackoverflow.com/questions/77886768/how-to-increase-numbers-of-features</link>
      <description><![CDATA[当我需要预测游戏价格时，我正在解决一项机器学习任务。
我有一个大约有 60 列的数据集：10 个数值和 50 个二进制值（True/False）。
我想提供更多功能来改进我的数据集。我怎样才能增加它们。是否可以使用一些数学函数？
我已将 Catboost 和 LGBM 回归器与 gridsearch 结合使用。所以我不知道如何改进模型。
我的数据集信息：
RequiredAge - 最低年龄限制

DemoCount - 演示数量

DeveloperCount - 开发人员数量

DLCOUNT - 附加组件的数量

Metacritic - Metacritic 评分

MovieCount - 电影数量

PackageCount - 游戏中数据集的数量

RecommendationCount - 推荐数量

PublisherCount - 发布者数量

Screenshot Count - 屏幕截图的数量

AchievementCount - 成就数

AchievementHighlightedCount - 特殊成就的数量

ControllerSupport - 如果有控制器支持则为 True

isFree - 如果免费则为 True

FreeVerAvail - 如果软件包组列表中 isfreelicense 为 True，则为 True

PurchaseAvail - 如果套餐组列表中的price_in_cents_with_discount 大于 0，则为 True

SubscriptionAvail - 如果 is_recurring_subscription 在包组中设置为 True，则为 True

如果 Platform.windows 为 True，则 PlatformWindows 为 True

如果platforms.linux 为 True，则 PlatformLinux 为 True

PlatformMac - 如果platforms.mac 为True，则为True

PCReqsHaveMin - 如果 pcrequirements.minimum 是非空字符串，则为 True

PCReqsHaveRec - 如果 pcrequirements.recommished 是非空字符串，则为 True

LinuxReqsHaveMin - 如果 linuxrequirements.minimum 是非空字符串，则为 True

LinuxReqsHaveRec - 如果 linuxrequirements.recommished 是非空字符串，则为 True

MacReqsHaveMin - 如果 macrequirements.minimum 是非空字符串，则为 True

MacReqsHaveRec - 如果 macrequirements.recommished 是非空字符串，则为 True

CategorySinglePlayer - 如果至少对于任何 i，categories[i].description 是“单人游戏”，则为 True

CategoryMultiplayer - 如果至少对于任何 i、categories[i].description 为以下值之一，则为 True：“跨平台多人游戏”、“本地多人游戏”、“多人游戏”、“在线多人游戏” ;, “共享/分屏”

如果至少对于任何i，categories[i].description是以下之一，则CategoryCoop为真：“co-op”、“本地co-op”、“在线co-op”或“co-op”。

CategoryMMO - 布尔 如果至少对于任何 i，categories[i].description 为“mmo”，则为 True

CategoryInAppPurchase - 如果至少对于任何 i，categories[i].description 是“应用内购买”，则为 True

CategoryIncludeSrcSDK - 如果至少对于任何 i，categories[i].description 为“包含源 sdk”，则为 True

CategoryIncludeLevelEditor - 如果至少对于任意 i，categories[i].description 为“包含关卡编辑器”，则为 True。

CategoryVRSupport - 如果至少对于任何 i，categories[i].description 是“vr 支持”，则为 True

GenreIsNonGame - 布尔 如果至少对于任何 i、genres[i].description 为以下值之一，则为 True：“实用程序”、“设计与游戏”插图”、“动画与动画” “建模”、“软件培训”、“教育”、“音频制作”、“视频制作”、“网络出版”、“照片编辑”、“会计”

GenreIsIndie - 如果至少对于任何 i，genres[i].description 是“独立”，则为 True

GenreIsAction - 如果至少对于任意 i，类型[i].description 是“动作”，则为 True

GenreIsAdventure - 如果至少对于任何 i，genres[i].description 是“冒险”，则为 True

GenreIsCasual - 如果至少对于任何 i，genres[i].description 是“休闲”，则为 True

GenreIsStrategy - 如果至少对于任何 i，genres[i].description 是“策略”，则为 True

GenreIsRPG - 如果至少对于任何 i，genres[i].description 为“rpg”，则为 True

GenreIsSimulation - 如果至少对于任何 i，genres[i].description 是“模拟”，则为 True

GenreIsEarlyAccess - 如果至少对于任何 i，genres[i].description 是“早期访问”，则为 True

GenreIsFreeToPlay - 如果至少对于任何 i，genres[i].description 是“免费玩”，则为 True

GenreIsSports - 如果至少对于任何 i，genres[i].description 为“sports”，则为 True

genreistracing - 如果至少对于任何 i，generators[i].description 为“racing”，则为 True

GenreIsMassivelyMultiplayer - 如果至少对于任何 i，genres[i].description 是“大型多人游戏”，则为 True

价格货币-price_overview.currency

PriceFinal - Price_overview.final，除以 h 100.0 将美分转换为货币
]]></description>
      <guid>https://stackoverflow.com/questions/77886768/how-to-increase-numbers-of-features</guid>
      <pubDate>Fri, 26 Jan 2024 14:00:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 Bag Of Words 的输出到其他数据集</title>
      <link>https://stackoverflow.com/questions/77885385/using-output-of-bag-of-words-to-other-dataset</link>
      <description><![CDATA[我正在尝试对数据集（包含句子）执行 BagOfwords 算法，并且词袋算法的输出（在清除所有不重要的单词之后）将进入第二个数据集（包含分割的数据我将把图片放在底部）但我的问题是如何附加第一个数据集的输出以便很好地进入第二个数据集训练。我想过做一个字典来转换和划分句子，以适合第二个数据集值，但这非常困难，我希望你有更好的主意。
我对他做的第一个数据集的样本 BagOf 单词
“过去几周，我的手臂、腿和躯干上一直出现皮疹。它呈红色、发痒，并覆盖着干燥的鳞片状斑块。”
来自第二个数据集的图片，我试图将第一个数据集连接到第二个数据集的神经网络：
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/77885385/using-output-of-bag-of-words-to-other-dataset</guid>
      <pubDate>Fri, 26 Jan 2024 09:55:11 GMT</pubDate>
    </item>
    <item>
      <title>梯度消失会导致“没有为任何变量提供梯度”</title>
      <link>https://stackoverflow.com/questions/77870522/can-vanishing-gradients-cause-no-gradients-provided-for-any-variable</link>
      <description><![CDATA[我一直在研究一个旨在输出微笑序列的 GAN 模型。在我的训练步骤中，我收到错误“值错误：没有为任何变量提供梯度”，我在生成器的可训练变量的 gan_model 中遇到了这个问题。我已经正确定义了损失和优化器以及鉴别器的梯度裁剪。
编辑
我已经使用 tf.op 函数（tf.reduce_mean）实现了我的损失函数，并检查了它是否可微。我仍然遇到没有为任何变量提供梯度的错误。我的生成器使用注意机制，并且我已经在我的级别检查了生成器中的任何函数是否不可微分或有任何不正确的输入。
wasserstein 损失函数返回合理的值并且输出形状似乎正确
这是我用来定义 gan_model、生成器和训练协议的相关代码。
损失函数
def wasserstein_loss(y_true, y_pred):
    损失 = tf.reduce_mean(y_true * y_pred)
    回波损耗


y_true = tf.constant([1.0, -1.0, 1.0], dtype=tf.float32)
y_pred = tf.constant([0.5, -0.5, 0.2], dtype=tf.float32)

使用 tf.GradientTape() 作为磁带：
    磁带.watch(y_pred)
    损失 = wasserstein_loss(y_true, y_pred)

梯度 = Tape.gradient(loss, y_pred)

print(&quot;损失：&quot;, loss.numpy())
print(&quot;渐变：&quot;,gradient.numpy())

发电机
重复器 = RepeatVector(max_ Protein_seq_length)
连接器=连接（轴=-1）
densor1 = 密集(10, 激活 = “tanh”)
densor2 = 密集（1，激活 =“relu”）

dotor = 点(轴 = 1)
post_activation_LSTM_cell = LSTM(max_smiles_length, return_sequences=True, return_state = True)
输出层=密集（num_smiles_tokens，激活=&#39;softmax&#39;）

def one_step_attention(a, s_prev):
    s_prev = 重复器(s_prev)
    concat = 连接器([a, s_prev])
    e = densor1(concat)
    能量 = densor2(e)
    alphas = tf.nn.softmax(能量，轴=1)
    上下文 = dotor([alphas, a])

    返回上下文

def softargmax(x, beta):
    x_range = tf.range(x.shape.as_list()[-1], dtype=x.dtype)
    返回 tf.reduce_sum(tf.nn.softmax(x*beta)*x_range, axis=-1)

如果有人可以帮助解决问题，我将不胜感激，如果需要，我愿意分享培训循环或其他相关部分。]]></description>
      <guid>https://stackoverflow.com/questions/77870522/can-vanishing-gradients-cause-no-gradients-provided-for-any-variable</guid>
      <pubDate>Wed, 24 Jan 2024 04:01:23 GMT</pubDate>
    </item>
    <item>
      <title>在本地部署 Azure autoML 模型</title>
      <link>https://stackoverflow.com/questions/77859735/deploying-azure-automl-model-locally</link>
      <description><![CDATA[我已经使用 Azure AutoML 成功训练了一些有前途的模型，现在我想将它们部署在本地。
我使用简单的 CSV 文件作为数据集（使用 Azure ML v1 API）来训练模型。之后，我下载了模型并使用 Microsoft 在 Conda 中提供的评分脚本插入它：


# ---------------------------- ----------------------------
# 版权所有 (c) Microsoft Corporation。版权所有。
#------------------------------------------------- --------
导入 json
导入日志记录
导入操作系统
进口泡菜
将 numpy 导入为 np
将 pandas 导入为 pd
导入作业库

导入 azureml.automl.core
从 azureml.automl.core.shared 导入logging_utilities、log_server
从 azureml.telemetry 导入 INSTRUMENTATION_KEY

从 inference_schema.schema_decorators 导入 input_schema、output_schema
从 inference_schema.parameter_types.numpy_parameter_type 导入 NumpyParameterType
从 inference_schema.parameter_types.pandas_parameter_type 导入 PandasParameterType
从 inference_schema.parameter_types.standard_py_parameter_type 导入 StandardPythonParameterType

data_sample = PandasParameterType(pd.DataFrame({&quot;SIO2&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;AL2O3&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;B2O3&quot; : pd.Series([0.0], dtype=&quot;float32&quot;), &quot;CAO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;K2O&quot;: pd.Series([0.0], dtype=&quot; float32&quot;), &quot;NA2O&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;PBO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;Li2O&quot;: pd.Series( [0.0], dtype=&quot;float32&quot;), &quot;MgO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;SRO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot; BAO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;ZNO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;P2O5&quot;: pd.Series([0.0], dtype =&quot;float32&quot;), &quot;ZRO2&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;TIO2&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;Bi2O3&quot;: pd.系列([0.0], dtype=&quot;float32&quot;)}))
input_sample = StandardPythonParameterType({&#39;data&#39;: data_sample})

result_sample = NumpyParameterType(np.array([0.0]))
输出样本 = StandardPythonParameterType({&#39;结果&#39;:result_sample})
Sample_global_parameters = StandardPythonParameterType(1.0)

尝试：
    log_server.enable_telemetry(INSTRUMENTATION_KEY)
    log_server.set_verbosity(&#39;INFO&#39;)
    logger =logging.getLogger(&#39;azureml.automl.core.scoring_script_v2&#39;)
除了：
    经过


定义初始化（）：
    全球模式
    # 这个名称是我们要部署的模型的 model.id 将模型文件反序列化回来
    # 进入sklearn模型
    model_path = os.path.join(os.getenv(&#39;AZUREML_MODEL_DIR&#39;), &#39;model.pkl&#39;)
    路径 = os.path.normpath(model_path)
    path_split = path.split(os.sep)
    log_server.update_custom_dimensions({&#39;model_name&#39;: path_split[-3], &#39;model_version&#39;: path_split[-2]})
    尝试：
        logger.info(“从路径加载模型。”)
        模型 = joblib.load(model_path)
        logger.info(&quot;加载成功。&quot;)
    除了异常 e：
        logging_utilities.log_traceback（e，记录器）
        增加

@input_schema(&#39;输入&#39;, input_sample)
@input_schema（&#39;GlobalParameters&#39;，sample_global_parameters，convert_to_provided_type = False）
@output_schema（输出样本）
def run（输入，全局参数=1.0）：
    数据=输入[&#39;数据&#39;]
    结果=模型.预测(数据)
    返回 {&#39;Results&#39;:result.tolist()}



环境是使用.yml文件设置的，但我总是收到错误消息：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ModuleNotFoundError Traceback（最近一次调用最后一次）
单元格 In[1]，第 12 行
      9 将 pandas 导入为 pd
     10 导入作业库
---&gt; 12 导入 azureml.automl.core
     13 从 azureml.automl.core.shared 导入logging_utilities、log_server
     14 从 azureml.telemetry 导入 INSTRUMENTATION_KEY

ModuleNotFoundError：没有名为“azureml”的模块

但是，我不认为它与软件包有关。当我尝试通过 Azure 中的实时端点部署模型并使用“测试”测试它们时，成功执行后，我收到以下错误消息：
有趣的是，我在 VS 中没有收到此错误消息。相反，当在那里执行 run 函数时，我只收到以下错误消息：


要解析的输入数据类型无效。预期：但得到了 ;
斯塔佩鲁贝尔瓦赫：
 &gt;文件“C:\Users\weightedfinalmodel\scoring_file_v_2_0_0.py”，第 59 行，在  中（当前帧）
 &gt;运行（数据样本）
“inference_schema.schema_decorators”geladen
“__main__”凝胶
“奔跑的”凝胶
Das 程序“python.exe”wurde mit Code 4294967295 (0xffffffff) wasdet。



看起来已经好多了，但我似乎忽略了一些东西。]]></description>
      <guid>https://stackoverflow.com/questions/77859735/deploying-azure-automl-model-locally</guid>
      <pubDate>Mon, 22 Jan 2024 12:07:02 GMT</pubDate>
    </item>
    <item>
      <title>将 XGBoost Shapely 值转换为 SHAP 的 Explanation 对象</title>
      <link>https://stackoverflow.com/questions/77800583/converting-xgboost-shapely-values-to-shaps-explanation-object</link>
      <description><![CDATA[我正在尝试将 XGBoost 形状值转换为 SHAP 解释器对象。将[此处][1]的示例与内置 SHAP 库一起使用需要几天的时间（即使在二次采样数据集上），而 XGBoost 库则需要几分钟。然而。我想输出一个与[此处][2]示例中显示的类似的蜂群图。
我的想法是，我可以使用 XGBoost 库来恢复形状值，然后使用 SHAP 库绘制它们，但蜂群图需要一个解释器对象。如何将我的 XGBoost 助推器对象转换为解释器对象？
这是我尝试过的：
导入形状
助推器 = model.get_booster()
d_test = xgboost.DMatrix(X_test[0:100], y_test[0:100])
shap_values = booster.predict(d_test, pred_contribs=True)
shap.plots.beeswarm(shap_values)

返回结果：
类型错误：蜂群图需要一个“Explanation”对象作为“shap_values”参数。

为了澄清，如果可能的话，我想用 xgboost 内置库生成的值创建解释器对象。避免 shap.explainer 或 shap.TreeExplainer 函数调用是一个优先事项，因为它们需要更长的时间（几天）而不是几分钟才能返回。
[1]: https: //shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Python%20Version%20of%20Tree%20SHAP.html
[2]:  https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/beeswarm.html#A-simple-beeswarm-summary-plot]]></description>
      <guid>https://stackoverflow.com/questions/77800583/converting-xgboost-shapely-values-to-shaps-explanation-object</guid>
      <pubDate>Thu, 11 Jan 2024 13:55:27 GMT</pubDate>
    </item>
    <item>
      <title>如何使用optuna试用版在sklearn MLPRegressor中设置hidden_​​layer_sizes</title>
      <link>https://stackoverflow.com/questions/69931757/how-to-set-hidden-layer-sizes-in-sklearn-mlpregressor-using-optuna-trial</link>
      <description><![CDATA[我想将 [OPTUNA][1] 与 sklearn [MLPRegressor][1] 模型结合使用。
对于几乎所有超参数，如何为其设置 OPTUNA 都非常简单。
例如，设置学习率：
learning_rate_init = Trial.suggest_float(&#39;learning_rate_init&#39;,0.0001, 0.1001, step=0.005)
我的问题是如何将其设置为hidden_​​layer_sizes，因为它是一个元组。假设我想要两个隐藏层，第一个隐藏层有 100 个神经元，第二个隐藏层有 50 个神经元。如果没有 OPTUNA，我会这样做：
MLPRegressor(hidden_​​layer_sizes =(100,50))
但是如果我希望 OPTUNA 在每一层尝试不同的神经元怎么办？例如，从100到500，我该如何设置？ MLPRegressor 需要一个元组]]></description>
      <guid>https://stackoverflow.com/questions/69931757/how-to-set-hidden-layer-sizes-in-sklearn-mlpregressor-using-optuna-trial</guid>
      <pubDate>Thu, 11 Nov 2021 16:30:48 GMT</pubDate>
    </item>
    <item>
      <title>下面的基本张量流模型可以学习吗？这是正确的方法吗？</title>
      <link>https://stackoverflow.com/questions/58324291/could-the-following-basic-tensorflow-model-learn-is-this-the-right-approach</link>
      <description><![CDATA[我开始像这样玩张量流：
我的训练数据由这样的数组组成（对于本例，len 是 3，但对于我的真实示例，len 是 100）：
&lt;前&gt;&lt;代码&gt;[1, 0, 0]
[0, 1, 0]
[0,0,1]

....
然后它会重复直到 1000
...

[1, 0, 0]
[0, 1, 0]
[0,0,1]

我的标签数据由一个数组列表组成，其中显示第 1 个位置：
[1, 2, 3, 1, 2, 3 .....] 直到 1000。

我使用以下模型配置，但精度似乎很低。所以我想这不是一个接近学习的事件。我是否错误地解释了张量流的工作原理？有人可以给我一个关于如何解决这个问题的提示吗？
model.add(layers.Dense(100,activation=&#39;relu&#39;))
model.add(layers.Dense(100, 激活=&#39;softmax&#39;))

model.compile(优化器=tf.compat.v1.train.AdamOptimizer(0.01),
    损失=&#39;分类交叉熵&#39;，
    指标=[&#39;准确性&#39;])

model.fit(数据、标签、epochs=50、batch_size=100)
]]></description>
      <guid>https://stackoverflow.com/questions/58324291/could-the-following-basic-tensorflow-model-learn-is-this-the-right-approach</guid>
      <pubDate>Thu, 10 Oct 2019 13:36:49 GMT</pubDate>
    </item>
    <item>
      <title>Seq2Seq 模型适合我的数据吗？有什么例子吗？</title>
      <link>https://stackoverflow.com/questions/51412473/is-seq2seq-the-right-model-for-my-data-any-examples</link>
      <description><![CDATA[我正在尝试训练一个模型来预测网页的设计模式。我正在使用给定一堆元素分组的边界矩形的坐标。模式如下所示：
 [[elementId, 宽度, 高度, x, y]]

所以我的目标将是给定[[elementId, width, height]]的[[x,y]]。
具体：
&lt;预&gt;&lt;代码&gt; [[5, 1.0, 1.0], [4, 1.0, 1.0], [2, 175.0, 65.0], [2, 1.0, 1.0], [4, 1.0, 1.0]]
 -&gt;
 [[0.0, 0.0], [0.0, 10.0], [3.0, 0.0], [0.0, 68.0], [0.0, 10.0]]


 [[2, 14.0, 14.0], [2, 14.0, 14.0], [2, 14.0, 14.0]]
 -&gt;
 [[0.0, 3.0], [0.0, 3.0], [0.0, 3.0]]

图案的大小各不相同，因此我用 [[0,0,0]] 填充它们。我目前拥有大约 15k，但可以获取更多。
我被告知带有注意力的 seq2seq 是这项工作的正确模型。我从 https://machinelearningmastery.com/ 开始开发-编码器-解码器-模型-序列-序列-预测-keras/并取得了可怕的结果。
我能找到的每个 seq2seq 示例（搜索 keras 或 pytorch）都用于分类翻译，我正在努力寻找一个基于回归的良好示例。
所以我的问题是：

对于我想要做的事情来说，这是正确的模型（编码器/解码器 LSTM）吗？

如果有的话有什么例子吗？

]]></description>
      <guid>https://stackoverflow.com/questions/51412473/is-seq2seq-the-right-model-for-my-data-any-examples</guid>
      <pubDate>Wed, 18 Jul 2018 23:55:30 GMT</pubDate>
    </item>
    <item>
      <title>将 sklearn 的 GridSearchCV 与管道一起使用，只需预处理一次</title>
      <link>https://stackoverflow.com/questions/43366561/use-sklearns-gridsearchcv-with-a-pipeline-preprocessing-just-once</link>
      <description><![CDATA[我正在使用 sckit-learn 来调整模型超参数。我正在使用管道将预处理与估计器链接起来。我的问题的一个简单版本如下所示：
将 numpy 导入为 np
从 sklearn.model_selection 导入 GridSearchCV
从 sklearn.pipeline 导入 make_pipeline
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.linear_model 导入 LogisticRegression


网格 = GridSearchCV(make_pipeline(StandardScaler(), LogisticRegression()),
                    param_grid={&#39;logisticregression__C&#39;: [0.1, 10.]},
                    简历=2，
                    改装=假）

_ = grid.fit(X=np.random.rand(10, 3),
             y=np.random.randint(2, 大小=(10,)))

就我而言，预处理（玩具示例中的 StandardScale()）非常耗时，而且我不会调整它的任何参数。
因此，当我执行该示例时，StandardScaler 被执行了 12 次。 2 个拟合/预测 * 2 个 cv * 3 个参数。但每次对参数 C 的不同值执行 StandardScaler 时，它都会返回相同的输出，因此计算一次，然后只运行管道的估计器部分会更高效。
我可以手动拆分预处理（未调整超参数）和估计器之间的管道。但要将预处理应用于数据，我应该只提供训练集。因此，我必须手动实现拆分，而根本不使用 GridSearchCV。
是否有一种简单/标准的方法可以避免在使用 GridSearchCV 时重复预处理？]]></description>
      <guid>https://stackoverflow.com/questions/43366561/use-sklearns-gridsearchcv-with-a-pipeline-preprocessing-just-once</guid>
      <pubDate>Wed, 12 Apr 2017 10:10:47 GMT</pubDate>
    </item>
    <item>
      <title>时间序列数据的模型参数选择</title>
      <link>https://stackoverflow.com/questions/40123102/model-parameter-selection-for-time-series-data</link>
      <description><![CDATA[对于模型参数选择，我们总是通过交叉验证进行网格搜索，以测试哪些参数比其他参数更好。
它适用于一般训练数据，例如这个，但是如果数据之间有时间关系，比如几天的销量或者几天的库存，直接做交叉验证有错吗？
由于交叉验证将使用 kFold 在训练数据中随机分割，这意味着对于时间序列数据，最近几天的信息将用于过去的训练。
如何对时间序列数据进行参数选择或交叉验证？]]></description>
      <guid>https://stackoverflow.com/questions/40123102/model-parameter-selection-for-time-series-data</guid>
      <pubDate>Wed, 19 Oct 2016 05:44:21 GMT</pubDate>
    </item>
    </channel>
</rss>