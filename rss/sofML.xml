<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 02 Apr 2024 03:17:00 GMT</lastBuildDate>
    <item>
      <title>将数据集从 LabelImg XML 转换为 YOLO txt 格式时出现问题：某些边界框的长度和宽度反转</title>
      <link>https://stackoverflow.com/questions/78258685/problem-with-converting-a-dataset-from-labelimg-xml-to-yolo-txt-format-inversio</link>
      <description><![CDATA[将数据集从 LabelImg XML (ImageNet) 格式转换为 YOLO txt 格式时，某些边界框的宽度和高度颠倒（即应该是宽度是高度，应该是高度是宽度）。
为了转换数据，我使用以下函数
def get_classes():
    &quot;&quot;&quot;&quot;从 txt 文件中读取类列表&quot;&quot;&quot;&quot;
    类=[]
    将 open(&#39;classes.txt&#39;) 作为 f：
        行= f.readlines()
        对于行中的 i：
            电流=我
            当前 = current.replace(&#39;\n&#39;, &#39;&#39;)
            类.append（当前）
    返回类

def 转换（大小，盒子）：
    “”““转换单个 robndbox”“”
    dw = 1./（大小[0]）
    dh = 1./（大小[1]）
    x = 框[0] * dw
    y = 框[1] * dh
    w = 框[2] * dw
    h = 框[3] * dh
    返回 x、y、w、h


def Convert_annotation(annotation_path):
    》》》》将XML标注文件转换为YOLO txt格式的函数》》》》
    in_file = open(annotation_path, 编码=&#39;UTF-8&#39;)
    out_file = open(&#39;./labels/&#39; + os.path.basename(annotation_path)[:-4] + &#39;.txt&#39;, &#39;w&#39;)
    树 = ET.parse(in_file)
    根 = 树.getroot()
    大小 = root.find(&#39;大小&#39;)
    类 = get_classes()
    w = int(size.find(&#39;宽度&#39;).text)
    h = int(size.find(&#39;高度&#39;).text)
    对于 root.iter(&#39;object&#39;) 中的 obj：
        困难 = obj.find(&#39;困难&#39;).text
        cls = obj.find(&#39;名称&#39;).text
        如果 cls 不在类中或 int(difficult) == 1：
            继续
        cls_id = 类.index(cls)
        xmlbox = obj.find(&#39;robndbox&#39;)
        b = (float(xmlbox.find(&#39;cx&#39;).text), float(xmlbox.find(&#39;cy&#39;).text), float(xmlbox.find(&#39;w&#39;).text),
             浮动（xmlbox.find（&#39;h&#39;）.text））
        theta = float(xmlbox.find(&#39;角度&#39;).text)
        θ -= 1.5
        b1、b2、b3、b4 = b
        如果b3＜ b4:
            b = (b1, b2, b4, b3)
            θ = int(((θ * 180 / math.pi) + 90) % 180)
        别的：
            θ = int(θ * 180 / math.pi)
        bb = 转换((w, h), b)
        #print(f“{theta} - {cls}”)
        out_file.write(str(cls_id) + &quot; &quot; + &quot; &quot;.join([str(a) for a in bb]) + &quot; &quot; + str(theta) + &#39;\n&#39;)


我期望得到的结果：
labelImg2 带注释的图像单选组件 xml
我实际上得到了什么
在此处输入图像描述
图中，terminal、transistor.bjt.pnp、resistor.adjustable 等元素和一些电阻器具有倒置的边界框。
例如，其中一些元素（晶体管和可调电阻）在 xml 中具有以下标记
&lt;前&gt;&lt;代码&gt;&lt;对象&gt;;
    &lt;名称&gt;transistor.bjt.pnp
    &lt;姿势&gt;未指定&lt;/姿势&gt;
    &lt;截断&gt;0
    &lt;困难&gt;0&lt;/困难&gt;
    &lt;Robndbox&gt;
        &lt;cx&gt;1299.0&lt;/cx&gt;
        &lt;cy&gt;375.5&lt;/cy&gt;
        &lt;w&gt;123.0&lt;/w&gt;
        &lt;h&gt;106.0&lt;/h&gt;
        &lt;角度&gt;1.570796
    &lt;/robndbox&gt;
    &lt;额外/&gt;
&lt;/对象&gt;
&lt;对象&gt;
    &lt;名称&gt;可调电阻
    &lt;姿势&gt;未指定&lt;/姿势&gt;
    &lt;截断&gt;0
    &lt;困难&gt;0&lt;/困难&gt;
    &lt;Robndbox&gt;
        &lt;cx&gt;658.0&lt;/cx&gt;
        &lt;cy&gt;479.0&lt;/cy&gt;
        &lt;w&gt;122.0&lt;/w&gt;
        &lt;h&gt;96.0&lt;/h&gt;
        &lt;角度&gt;1.55226
    &lt;/robndbox&gt;
    &lt;额外/&gt;
&lt;/对象&gt;

我该如何解决这个问题？预先感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78258685/problem-with-converting-a-dataset-from-labelimg-xml-to-yolo-txt-format-inversio</guid>
      <pubDate>Tue, 02 Apr 2024 02:37:25 GMT</pubDate>
    </item>
    <item>
      <title>令人惊讶但令人困惑的机器学习结果</title>
      <link>https://stackoverflow.com/questions/78258533/surprising-but-confusing-ml-results</link>
      <description><![CDATA[有人可以帮我理解以下问题吗？
我正在使用监督机器学习技术进行异常检测。我对结果感到惊讶和厌倦，对于一个数据集来说，它非常出色，而对于其他数据集来说，这些结果更糟。
问题是，“假阳性率为 100%，同时真阳性率为 99%。”据我所知，这种情况不应该发生，否则情况应该是这样，即如果 TPR 为 100%，则 FPR 应该为 0%。你怎么说？获得这样的结果的可能原因是什么？
为了更好地理解，请附上屏幕截图。
我尝试针对不同的数据集使用 0-4 范围内的不同值来调整我的模型。该模型在一种情况下显示出令人鼓舞的结果，但在另一种数据集上则显示出令人沮丧的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78258533/surprising-but-confusing-ml-results</guid>
      <pubDate>Tue, 02 Apr 2024 01:26:25 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么类型的机器学习模型？</title>
      <link>https://stackoverflow.com/questions/78258364/what-type-of-ml-model-should-i-use</link>
      <description><![CDATA[我一直在尝试制作一个代码片段预测模型来预测/完成下一组代码。文本框中有某种副驾驶的内容，但对于代码，我将使用它来将其部署在网站上。我应该使用什么型号。副驾驶文本框
我尝试了带有张量流分词器的基本 lstm 模型，但分词器无法对“”等符号进行分词。 , (“等。我尝试使用 gpt tokenizer，但它不适用于模型。我想先从一个简单的开始。我应该采取什么方法。]]></description>
      <guid>https://stackoverflow.com/questions/78258364/what-type-of-ml-model-should-i-use</guid>
      <pubDate>Tue, 02 Apr 2024 00:10:30 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 中的恒定预测值</title>
      <link>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</link>
      <description><![CDATA[我正在尝试使用 LightGBM 回归来预测变量 (Y)。然而我的预测值都是相同的（即常数）。有人可以帮忙检测问题吗？
data_x = [[2021,5,368.92],[2023,11,356.82],[2022,10,352.49],[2023,5,343.63],[2023,10,324.91],[2022,12,352.02],[2021,6,370.7 9] ,[2022,5,386.59],[2019,2,301.56],[2021,4,353.7],[2021,1,303.93],[2021,9,371.94],[2019,4,310.77],[2021,3,345.3],[2020,5,249。 63],[ 2022,4,381.16],[2023,4,363.14],[2019,7,304.19],[2020,7,258.43],[2022,2,412.47],[2022,8,353.43],[2019,6,302.34],[2020,1,319。 88]，[2022年， 7,361.66],[2020,9,265.39],[2022,3,408.72],[2022,1,417.47],[2022,6,351.92],[2022,9,344.06],[2022,11,373.75],[2019,9,314.97], [2019,11,324.14] ,[2023,2,377.23],[2021,11,380.83],[2021,12,403.12],[2023,7,368.73],[2023,1,379.76],[2019,5,295.02],[2023,9,343.78],[2020,4, 248.54],[ 2019,10,314.79],[2019,8,295.92],[2023,3,354.09],[2023,6,357.35],[2021,2,324.31],[2020,3,246.26],[2019,3,295.36],[2020,12,30 6.27]，[2021， 8,376.54],[2020,6,258.21],[2023,8,352.35],[2021,7,370.21],[2020,10,259.13],[2020,8,275.66],[2019,12,315.47],[2020,11,301.27 ],[2021,10,389.23] ,[2019,1,291.94],[2020,2,302.38]]

df_x = pd.DataFrame(data_x, columns=[&#39;年&#39;, &#39;月&#39;, &#39;关闭&#39;])

data_y = [[1479.42],[1654.53],[1537.76],[1621.22],[1567.62],[1528.39],[1444.63],[1562.17],[1356.81],[1463.48],[1558.9],[1463.96] ,[1362.03],[1432.7],[1502.46],[1524.71],[1592.68],[1342.74],[1467.48],[1553.66],[1609.19],[1349.1],[1379.39],[1496.12],[ 1448.08]、[1562.96]、[1525.25]、[1575.06]、[1591.15]、[1544.66]、[1319.9]、[1366.73]、[1482.72]、[1520.73]、[1557.03]、[1577.37]、[1624 .74] ,[1402.05],[1614.94],[1482.28],[1338.88],[1354.6],[1553.65],[1606.36],[1510.78],[1348.05],[1323.39],[1542.95],[1411.64],[ 1493.44],[1563.53],[1414.8],[1452.67],[1491.7],[1451.43],[1467.23],[1477.13],[1360.29],[1386.48]]

df_y = pd.DataFrame(data_y, columns=[&#39;值&#39;])

X_df_earn_ind_fin_train，X_df_earn_ind_fin_test，y_df_earn_ind_fin_train，y_df_earn_ind_fin_test = train_test_split（df_x，df_y，test_size = 0.3，random_state = 21）

hyper_params = {
    &#39;任务&#39;：&#39;训练&#39;，
    &#39;boosting_type&#39;：&#39;gbdt&#39;，
    &#39;目标&#39;：&#39;回归&#39;，
    &#39;公制&#39;：[&#39;mape&#39;，&#39;auc&#39;]，
    “学习率”：0.01，
    “特征分数”：0.9，
    &#39;bagging_fraction&#39;：0.7，
    &#39;bagging_freq&#39;：10，
    “详细”：0，
    &#39;详细评估&#39;：-1，
    “最大深度”：10，
    “叶子数”：96，
    “max_bin”：256，
    “迭代次数”：1000，
    “n_估计器”：250
}

gbm = lgm.LGBMRegressor(**hyper_params)
gbm.fit(X_df_earn_ind_fin_train, y_df_earn_ind_fin_train,
        eval_set=[(X_df_earn_ind_fin_test, y_df_earn_ind_fin_test)],
        eval_metric=&#39;mape&#39;)

y_pred_df_earn_ind_test = gbm.predict(X_df_earn_ind_fin_test)


但是我的输出只是一个常量值的数组
y_pred_df_earn_ind_test =
数组([1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863])


如何纠正这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</guid>
      <pubDate>Mon, 01 Apr 2024 21:17:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 pydotplus 可视化决策树</title>
      <link>https://stackoverflow.com/questions/78257646/visualization-a-decision-trees-with-pydotplus</link>
      <description><![CDATA[在决策树项目中
我写了这段代码，但是出现了具体的错误，我咨询了AI，问题没有解决，你可以看看问题出在哪里。
将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
从sklearn导入预处理
df = pd.read_csv(&#39;E:\mostafa文件夹\mashin学习\S5recommendersystems\Files\drug200.csv&#39;)
df.head()
df.describe()
df.列
x = df[[&#39;年龄&#39;, &#39;性别&#39;, &#39;血压&#39;, &#39;胆固醇&#39;, &#39;Na_to_K&#39;]].values
X
y = df[[&#39;药物&#39;]].值
y
从sklearn导入预处理
le_sex = 预处理.LabelEncoder()
le_sex.fit([&#39;F&#39;,&#39;M&#39;])
x[:,1] = le_sex.transform(x[:,1])


le_BP = 预处理.LabelEncoder()
le_BP.fit([ &#39;低&#39;, &#39;正常&#39;, &#39;高&#39;])
x[:,2] = le_BP.transform(x[:,2])


le_Chol = 预处理.LabelEncoder()
le_Chol.fit([ &#39;正常&#39;, &#39;高&#39;])
x[:,3] = le_Chol.transform(x[:,3])

x[0:4]
从 sklearn.model_selection 导入 train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=3)

print(&#39;火车形状：&#39;,x_train.shape,y_train.shape)
print(&#39;测试形状：&#39;,x_test.shape,y_test.shape)
从 sklearn.tree 导入 DecisionTreeClassifier

树= DecisionTreeClassifier（标准=“熵”，max_深度= 6）

树.fit(x_train,y_train)
pretree = tree.predict(x_test)

打印（前树[0:5]）
打印（y_测试[0:5]）
从 sklearn 导入指标
print(&quot;DecisionTrees 的准确率：&quot;,metrics.accuracy_score(y_test, pretree))
从 io 导入 StringIO
导入 pydotplus
将 matplotlib.image 导入为 mpimg
从 sklearn.tree 导入 DecisionTreeClassifier
从sklearn.tree导入export_graphviz
%matplotlib 内联
点数据 = StringIO()
特征名称 = df.columns
文件名 = &#39;mosi.png&#39;

out = export_graphviz(树,feature_names = featuresnames)
从sklearn.tree导入export_graphviz

点数据 = StringIO()
文件名 = &#39;ee.png&#39;
#featurenames = df.columns[0:5]

out = export_graphviz(tree, feature_names=df.columns[0:5], out_file=dot_data, class_names= np.unique(y_train),filled=True,special_characters=True,rotate=False)

图 = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png(文件名)
img = mpimg.imread(文件名)
plt.figure(figsize=(100, 200))
plt.imshow(img, 插值=&#39;最近&#39;)


这个问题取自这一行
out = export_graphviz(tree, feature_names=df.columns[0:5], out_file=dot_data, class_names= np.unique(y_train),filled=True,special_characters=True,rotate=False)
&lt;来自“C:\\Users\\PARDAZESHGARA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn”的模块“sklearn.tree” \\tree\\__init__.py&#39;&gt;不是估计器实例。

大家帮帮我！！！]]></description>
      <guid>https://stackoverflow.com/questions/78257646/visualization-a-decision-trees-with-pydotplus</guid>
      <pubDate>Mon, 01 Apr 2024 20:27:09 GMT</pubDate>
    </item>
    <item>
      <title>Tengo el错误“无法解析导入“keras.preprocessing.text”PylancereportMissingImports”[关闭]</title>
      <link>https://stackoverflow.com/questions/78257469/tengo-el-error-import-keras-preprocessing-text-could-not-be-resolvedpylancere</link>
      <description><![CDATA[附加的代码不允许我将文本库与 keras 一起使用，我收到以下错误
“导入“keras.preprocessing.text”” “无法解决PylancereportMissingImports”
导入json
将张量流导入为 tf
从张量流导入keras
from keras.preprocessing.text import Tokenizer #--&gt;;错误
从 keras.preprocessing.sequence 导入 pad_sequences


我希望能够使用该库或找到等效的库]]></description>
      <guid>https://stackoverflow.com/questions/78257469/tengo-el-error-import-keras-preprocessing-text-could-not-be-resolvedpylancere</guid>
      <pubDate>Mon, 01 Apr 2024 19:45:40 GMT</pubDate>
    </item>
    <item>
      <title>损失函数在梯度提升中的作用是什么？</title>
      <link>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</link>
      <description><![CDATA[在梯度提升中，可以使用不同的损失函数。例如，在 sklearn 的 GradientBoostingRegressor 中，可能的损失函数有：“squared_error”、“absolute_error”、“huber”和“quantile”损失函数。
我了解损失函数在梯度下降（而不是梯度提升）中的影响。例如，与绝对误差损失函数相比，平方误差损失函数对大误差的惩罚更大。我们可以在梯度提升的情况下说类似的话吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</guid>
      <pubDate>Mon, 01 Apr 2024 18:03:20 GMT</pubDate>
    </item>
    <item>
      <title>无法解释指标标识符 - scikeras.wrappers.KerasRegressor</title>
      <link>https://stackoverflow.com/questions/78257033/metric-identfier-cannot-be-interpreted-scikeras-wrappers-kerasregressor</link>
      <description><![CDATA[我正在尝试使用 scikeras.wrappers.KerasRegressor 调整超参数，但遇到了如下问题：
代码：
 # 定义一个函数来创建 lstm_model 的实例
def create_lstm_model():
    
    模型=顺序（[
            LSTM(5, input_shape = (Xtrain.shape[1], Xtrain.shape[2]), dropout = 0.1, 激活 = &#39;tanh&#39;, return_sequences = True),
            LSTM(10, dropout = 0.05, 激活 = &#39;tanh&#39;),
            密集（5，激活=&#39;relu&#39;），
            密集(1)
        ]）
    model.compile(优化器 = tf.keras.optimizers.Adam(), 损失 = tf.keras.losses.MeanSquaredError(), 指标 = [keras.metrics.MeanSquaredError()])
    
    返回模型

#为网络创建sklearn模型
模型 = KerasRegressor(build_fn = create_lstm_model, verbose = 1)

#参数网格
批次 = [16, 32]
历元 = [3, 4]

param_grid = dict(batch_size = 批次, epochs = epochs)

网格 = GridSearchCV(估计器 = 模型,
                    参数网格 = 参数网​​格,
                    简历 = 3)
grid.fit（Xtrain，ytrain，validation_data =（Xvalidation，yvalidation））

错误：
&lt;前&gt;&lt;代码&gt; fn_or_cls = keras_metric_get(公制)
  文件“/home/aaa/Desktop/aaa/aaa/2024-gold-price-prediction-with-lstm-model/.venv/lib/python3.10/site-packages/keras/src/metrics/__init__.py” ;，第 204 行，在 get 中
    raise ValueError(f“无法解释指标标识符：{identifier}”)
ValueError：无法解释指标标识符：损失

我从更复杂的代码开始，并在故障排除期间将其简化到最低限度。我什至试图从模型函数中删除指标。
您对我的代码有什么问题有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257033/metric-identfier-cannot-be-interpreted-scikeras-wrappers-kerasregressor</guid>
      <pubDate>Mon, 01 Apr 2024 18:02:32 GMT</pubDate>
    </item>
    <item>
      <title>带有注意力图执行错误的 LSTM 掩码</title>
      <link>https://stackoverflow.com/questions/78256963/lstm-masking-with-attention-graph-execution-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78256963/lstm-masking-with-attention-graph-execution-error</guid>
      <pubDate>Mon, 01 Apr 2024 17:43:41 GMT</pubDate>
    </item>
    <item>
      <title>为回归数值数据实现 ResNet Multi Output</title>
      <link>https://stackoverflow.com/questions/78255976/implementing-resnet-multi-output-for-numerical-data-for-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78255976/implementing-resnet-multi-output-for-numerical-data-for-regression</guid>
      <pubDate>Mon, 01 Apr 2024 14:15:11 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch如何生成掩模张量图像？</title>
      <link>https://stackoverflow.com/questions/78254779/pytorch-how-to-generate-mask-tensor-image</link>
      <description><![CDATA[Pytorch 从 png 生成数据集图像，将 alpha 转换为 0，将 rgb 转换为 1，或者如果有多个项目，则将它们转换为 1,2,3 ...将没有背景的标准 png 图像转换为 pytorch 张量进行训练
我正在学习pytorch示例这里，已经准备好使用数据集但是无法使用自己的数据集，我试图弄清楚如何创建这些数据集，但我在这个问题上停留了一个多月，请帮助
数据集的链接在这里，但是没有关于如何创建它们的描述。
示例图片：
还有掩模图像，其中包含格式为 0,1,2,3,4 的数据，但为二进制格式，尺寸较小“如何为 pytorch 图像识别创建这样的掩模图像&quot;: ]]></description>
      <guid>https://stackoverflow.com/questions/78254779/pytorch-how-to-generate-mask-tensor-image</guid>
      <pubDate>Mon, 01 Apr 2024 09:59:49 GMT</pubDate>
    </item>
    <item>
      <title>我只想在 python 中从该图像中提取图形部分，我该怎么做？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</link>
      <description><![CDATA[我想将右侧的两个图一起提取，也不能单独提取，两者都可以提取为一个（https://i.stack.imgur.com/RqwkB.jpg)
我不知道该尝试什么，我对此很陌生。我正在使用 python，我从图像中提取文本并将其保存在 csv 中
&lt;前&gt;&lt;代码&gt;导入cv2
将 numpy 导入为 np

# 加载图像
image_path = r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\1.jpg&#39;
图像 = cv2.imread(image_path)

# 将图像转换为灰度图
灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

# 应用高斯模糊来减少噪音
模糊 = cv2.GaussianBlur(灰色, (5, 5), 0)

# 应用 Canny 边缘检测
边缘 = cv2.Canny(模糊, 50, 150)

# 在边缘检测图像中查找轮廓
轮廓，_ = cv2.findContours（边缘，cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_SIMPLE）

# 根据面积过滤轮廓，找到最大的轮廓（假设图形是面积最大的）
轮廓=排序（轮廓，键= cv2.contourArea，反向= True）[：1]

# 创建一个掩码来提取图形区域
mask = np.zeros_like(灰色)
cv2.drawContours(蒙版, 轮廓, -1, (255, 255, 255), 厚度=cv2.FILLED)

# 将掩模应用于原始图像以提取图形
图= cv2.bitwise_and（图像，图像，掩码=掩码）

# 保存提取的图形图像
cv2.imwrite(r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\output\extracted_graph.jpg&#39;, graph)
]]></description>
      <guid>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</guid>
      <pubDate>Mon, 01 Apr 2024 08:33:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Textract 中获取 BLOCK 类型 LAYOUT_TITLE、LAYOUT_SECTION_HEADER 和 LAYOUT_xx 的内容</title>
      <link>https://stackoverflow.com/questions/78252584/how-to-get-content-of-block-types-layout-title-layout-section-header-and-layout</link>
      <description><![CDATA[我正在尝试使用 texttract 抓取多页 pdf。
需要根据其部分、子部分、表格来抓取 pdf 并格式化为 json。
在尝试使用布局和表格进行 UI 演示时，它完全能够显示布局标题、布局部分、布局文本、布局页脚、页码
在从 UI 演示下载的 csv 文件中可以观察到相同的信息：layout.csv 文件。
json 文件中也相同：analyzeDocResponse.json，但它包含所有内容（LINES、WORDS、LAYOUT_TITLE 和所有与布局相关的数据），我认为 textract 按顺序执行所有类型的块类型。
出于调试目的，我使用下面的代码来打印块的整个字典。
还有块类型及其相应的文本。
如果对 pdf 文件感兴趣：其 SmPC of Drugs：SmPC 文件
代码1：以json格式打印每个块。
&lt;前&gt;&lt;代码&gt;
def start_texttract_job（存储桶，文档）：
    响应 = texttract.start_document_analysis(
        文档位置={
            &#39;S3对象&#39;: {
                ‘桶’：桶，
                “名称”：文档
            }
        },
        FeatureTypes=[&quot;LAYOUT&quot;] # 您可以根据需要调整FeatureTypes
    ）
    返回响应[&#39;JobId&#39;]


def print_blocks(job_id):
    下一个令牌=无
    而真实：
        如果下一个令牌：
            响应 = texttract.get_document_analysis(JobId=job_id, NextToken=next_token)
        别的：
            响应 = texttract.get_document_analysis(JobId=job_id)

        for block in response.get(&#39;Blocks&#39;, []):
            打印（json.dumps（块，缩进= 4））

        next_token = response.get(&#39;NextToken&#39;, None)
        如果不是 next_token：
            休息

它正在按照 UI 演示打印类似信息，块类型为 LINES、WORDS、LAYOUT_
但是如果我尝试使用下面的代码打印每种块类型的文本，则无法打印 LAYOUT_ 相关的文本，不知道为什么，我是否遗漏了任何内容？
代码 2：打印块类型及其内容。
&lt;前&gt;&lt;代码&gt;
def start_texttract_job 与上面相同，LAYOUT。

def print_blocks(job_id):
    下一个令牌=无
    而真实：
        如果下一个令牌：
            响应 = texttract.get_document_analysis(JobId=job_id, NextToken=next_token)
        别的：
            响应 = texttract.get_document_analysis(JobId=job_id)

        for block in response.get(&#39;Blocks&#39;, []):
            print(f&quot;{block[&#39;BlockType&#39;]}: {block.get(&#39;Text&#39;, &#39;&#39;)}&quot;)

        next_token = response.get(&#39;NextToken&#39;, None)
        如果不是 next_token：
            休息

我可以看到块类型 LINES、WORDS 的值
但我认为，如下所示的布局为空，它是在块类型中进行识别，而不是其值。
布局标题：
布局图：
布局文本：
LAYOUT_SECTION_HEADER：
布局文本：
LAYOUT_SECTION_HEADER：
布局文本：
布局文本：
布局文本：
布局文本：
布局文本：
LAYOUT_PAGE_NUMBER：
LAYOUT_FOOTER：
任何帮助都受到高度赞赏，浏览了文档和其他一些 StackOverflow 问题，但找不到任何帮助。
Tetract 新手，对不起菜鸟 Q？，如果是的话:)]]></description>
      <guid>https://stackoverflow.com/questions/78252584/how-to-get-content-of-block-types-layout-title-layout-section-header-and-layout</guid>
      <pubDate>Sun, 31 Mar 2024 19:28:51 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机分类的增量学习[关闭]</title>
      <link>https://stackoverflow.com/questions/78248733/incremental-learning-for-support-vector-machines-classification</link>
      <description><![CDATA[我目前正在尝试为 Cawenbergs 和 Poggio 的增量和减量 SVM 算法找到一个好的实现。我找到了这个： Incremental-SVM-Learning-in- MATLAB，但我不太明白该算法在MatLab代码中是如何实现的。
我试图深入分析它并研究它，但仍然没有成功地理解它。我正在寻求一些帮助来理解代码，甚至寻求其他具有更清晰实现的解决方案。
非常欢迎任何帮助，你会给我一个很大的帮助！
这是我目前关注的算法：
Cawenbergs 和 Poggio 算法]]></description>
      <guid>https://stackoverflow.com/questions/78248733/incremental-learning-for-support-vector-machines-classification</guid>
      <pubDate>Sat, 30 Mar 2024 16:45:09 GMT</pubDate>
    </item>
    <item>
      <title>在运行时访问记录的值</title>
      <link>https://stackoverflow.com/questions/65392269/access-logged-values-during-runtime</link>
      <description><![CDATA[如何在运行完成之前从 wandb 检索记录的值？
导入操作系统
导入万数据库
wandb.init(项目=&#39;someproject&#39;)


def loss_a():
    # do_stuff 和日志：
    wandb.log({“loss_a”: 1.0})
    
def loss_b():
    # do_stuff 和日志：
    wandb.log({“loss_b”: 2.0})

对于范围（2）中的纪元：
    损失_a（）
    损失_b()
    
    # 以某种方式检索loss_a和loss_b并在此处打印它们：
    print(f&#39;loss_a={??}, loss_b={??}&#39;)


运行完成后，我可以使用 wandb.Api 找到它来获取 run.history。但似乎在 run 完成之前，访问 run.history 不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/65392269/access-logged-values-during-runtime</guid>
      <pubDate>Mon, 21 Dec 2020 11:51:10 GMT</pubDate>
    </item>
    </channel>
</rss>