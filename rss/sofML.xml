<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 06 Sep 2024 01:11:35 GMT</lastBuildDate>
    <item>
      <title>如何微调人脸识别预训练模型</title>
      <link>https://stackoverflow.com/questions/78954958/how-can-i-fine-tune-pre-trained-model-for-face-recognition</link>
      <description><![CDATA[我正在开发一个使用人脸识别的自动考勤系统，需要有关最佳方法的建议：
模型选择：哪种高级人脸识别模型（例如 FaceNet、DeepFace、ArcFace）最适合在自定义数据集上进行微调？
数据集管理：我应该如何构建和预处理我的数据集以实现最佳训练和验证？
上下文：
目标：使用人脸识别识别需要出勤的个人。
当前设置：使用 TensorFlow/Keras 和按单个文件夹组织的数据集。
任何指导或提示都将不胜感激！
谢谢！
我尝试制作一个人脸识别模型，我希望知道在自己的数据集中训练其他预训练模型的准确度。]]></description>
      <guid>https://stackoverflow.com/questions/78954958/how-can-i-fine-tune-pre-trained-model-for-face-recognition</guid>
      <pubDate>Thu, 05 Sep 2024 21:54:39 GMT</pubDate>
    </item>
    <item>
      <title>商品预测-时间序列建模</title>
      <link>https://stackoverflow.com/questions/78954699/commotdity-forecasting-time-series-modelling</link>
      <description><![CDATA[我正在与一位客户合作，他希望我按月进行商品价格预测。但他们只能为我们提供过去 5 年的月度数据。（60 个数据点）
我尝试过 Holt 的 Winter 模型、ARIMA、SARIMAX、LSTM、LR、Prophet。但准确度不达标。
进行月度预测所需的最低数据点数是多少？能否请您帮我找到正确的方法？]]></description>
      <guid>https://stackoverflow.com/questions/78954699/commotdity-forecasting-time-series-modelling</guid>
      <pubDate>Thu, 05 Sep 2024 20:17:53 GMT</pubDate>
    </item>
    <item>
      <title>Python 神经网络中的 DeprecationWarning</title>
      <link>https://stackoverflow.com/questions/78954495/deprecationwarning-in-neural-network-with-python</link>
      <description><![CDATA[我最近一直在学习神经网络实现，在 Dence、Sequential 和预测函数之后，当我想获得结果时，VS Code 会出现此错误
DeprecationWarning：将 ndim &gt; 0 的数组转换为标量已被弃用，将来会出现错误。确保在执行此操作之前从数组中提取单个元素。 （已弃用 NumPy 1.25。）
p[i,0] = my_sequence(X[i],W1,b1,W2,b2)
def my_dense(a_in,W,b): # 矩阵的大写 W
units = W.shape[1]
a_out = np.zeros(units)
for j in range(units):
w = W[:,j]
z = np.dot(w,a_in) + b[j]
a_out[j] = sigmoid(z)
return a_out
def my_sequence(a0,W1,b1,W2,b2): # a0 : x（输入）
a1 = my_dense(a0,W1,b1)
a2 = my_dense(a1,W2,b2)
return a2
def my_predict(X,W1,b1,W2,b2):
m = X.shape[0]
p = np.zeros((m,1))
for i in range(m):
p[i,0] = my_sequence(X[i],W1,b1,W2,b2)
return(p) # 预测矩阵中的 p
X = np.array([[210,17],
[190,20],
[240,19]])
W1 = np.array( [[-8.93, 0.29, 12.9 ],
[-0.1, -7.32, 10.81]] )
b1 = np.array( [-9.82, -9.28, 0.96] )
W2 = np.array( [[-31.18],
[-27.59],
[-32.56]] )
b2 = np.array( [15.41] )
norm_l.adapt(X)
X_n = norm_l(X)
predictions = my_predict(X_n,W1_tmp,b1_tmp,W2_tmp,b2_tmp)```
]]></description>
      <guid>https://stackoverflow.com/questions/78954495/deprecationwarning-in-neural-network-with-python</guid>
      <pubDate>Thu, 05 Sep 2024 19:03:34 GMT</pubDate>
    </item>
    <item>
      <title>如何训练人工智能完成任务？[关闭]</title>
      <link>https://stackoverflow.com/questions/78954394/how-can-an-ai-be-trained-to-do-a-task</link>
      <description><![CDATA[如何训练或指定 ai/ml 来学习某件事？
例如，当给定样本/数据时，如何让它学习我想要它做的事情？
（我不确定如何表述它，但希望有人明白我的意思）]]></description>
      <guid>https://stackoverflow.com/questions/78954394/how-can-an-ai-be-trained-to-do-a-task</guid>
      <pubDate>Thu, 05 Sep 2024 18:26:14 GMT</pubDate>
    </item>
    <item>
      <title>如何从中断的地方继续训练模型？</title>
      <link>https://stackoverflow.com/questions/78954139/how-to-continue-training-a-model-from-where-it-left-off</link>
      <description><![CDATA[我想知道在训练文本分类模型时如何保存检查点，以便我可以从中断的地方继续训练。
我遇到了麻烦，不知道如何配置我的代码以使用适当的文件保存检查点，以便我可以从之前结束的位置继续训练，例如“trainer_state.json”。
这是我的训练代码：
def executar_treinamento(self, base_treinada):
training_args = TrainingArguments(
output_dir=self.output_dir,
learning_rate=2e-5,
per_device_train_batch_size=8,
per_device_eval_batch_size=8,
num_train_epochs=8,
weight_decay=0.01,
evaluation_strategy=&quot;epoch&quot;,
        save_strategy=“epoch”, save_only_model=False, load_best_model_at_end=False ) self.trainer = Trainer( model=self.model, args=training_args,compute_metrics=self.calcular_metricas, train_dataset=base_treinada[&#39;train&#39;], eval_dataset=base_treinada[&#39;validation&#39;], tokenizer=self.tokenizar_textos ) self.trainer.train() def avaliar_modelo(self, base_treinada): self.trainer.evaluate(base_treinada[&#39;test&#39;]) def salvar_modelo(self, caminho): self.model.save_pretrained(caminho)
self.tokenizer.save_pretrained(caminho)

我尝试使用以下参数：
 save_strategy=&quot;steps&quot;, # 每 X 步保存检查点
save_steps=80, # 自定义保存频率（以步数为单位）

但是，即便如此，带有“trainer_state.json”等文件的检查点仍未保存。]]></description>
      <guid>https://stackoverflow.com/questions/78954139/how-to-continue-training-a-model-from-where-it-left-off</guid>
      <pubDate>Thu, 05 Sep 2024 17:01:57 GMT</pubDate>
    </item>
    <item>
      <title>PINN 中的物理损失是如何计算的？[关闭]</title>
      <link>https://stackoverflow.com/questions/78953649/how-is-physics-loss-calculated-in-pinns</link>
      <description><![CDATA[我正在研究物理信息神经网络 (PINN)，对物理损失的计算方式感到困惑。具体来说，在 1D 热方程示例中：
在此处输入图片说明
我知道该方程被平方以给出正输出，但不确定实际应用原始 1D 热方程如何计算成本。
假设输入是预测值，PINN 究竟如何知道“偏离多远”或预测是否在物理约束范围内？]]></description>
      <guid>https://stackoverflow.com/questions/78953649/how-is-physics-loss-calculated-in-pinns</guid>
      <pubDate>Thu, 05 Sep 2024 14:49:12 GMT</pubDate>
    </item>
    <item>
      <title>使用 Scikit Learn 在 Vertex 上导入模型</title>
      <link>https://stackoverflow.com/questions/78953273/importing-a-model-with-scikit-learn-on-vertex</link>
      <description><![CDATA[我尝试从本地导入模型，但每次我都会从 gcp 日志中收到相同的错误。框架是 scikit-learn
AttributeError: 无法从 &#39;/usr/app/model_server.py&#39;&gt; 获取 &lt;module &#39;model_server&#39; 上的属性 &#39;preprocess_text&#39; 
存在此问题的代码片段是
complaints_clf_pipeline = Pipeline(
[
(&quot;preprocess&quot;, text.TfidfVectorizer(preprocessor=utils.preprocess_text, ngram_range=(1, 2))),
(&quot;clf&quot;, naive_bayes.MultinomialNB(alpha=0.3)),
]
)

这个
preprocess_text 

来自上面的单元格，但我一直收到此问题，model_server 不存在于我的代码中。
有人可以帮忙吗？
我尝试重构代码但得到了同样的错误，尝试撤消此管道结构，但在尝试通过 API 查阅模型时又收到另一个错误。]]></description>
      <guid>https://stackoverflow.com/questions/78953273/importing-a-model-with-scikit-learn-on-vertex</guid>
      <pubDate>Thu, 05 Sep 2024 13:24:34 GMT</pubDate>
    </item>
    <item>
      <title>在 LSTM 神经网络中可以使用什么类似于 SHAP 值？[关闭]</title>
      <link>https://stackoverflow.com/questions/78952839/what-can-be-used-in-lstm-neural-network-similar-to-shap-values</link>
      <description><![CDATA[在使用长短期记忆 (LSTM) 神经网络执行顺序数据任务的情况下，了解不同输入特征的贡献或重要性对于模型的可解释性至关重要。虽然已经采用了特征重要性技术，但当前的挑战是探索其他指标或方法，以深入了解各个特征如何影响模型的预测。
解决这一挑战的一种潜在方法是应用 SHAP (SHapley Additive exPlanations) 值，这些值通常用于传统机器学习模型中的特征归因。SHAP 值通过将每个特征的贡献归因于预测来提供一种解释模型输出的一致方法。但是，由于 LSTM 网络涉及跨时间步骤的顺序依赖关系和复杂交互，因此实施 SHAP 或类似方法需要适应性或替代可解释性技术，这些技术适用于深度学习模型，尤其是处理时间序列的模型。
目标是识别和实施超越传统特征重要性的指标，重点关注可以解释输入数据的时间结构的方法，并提供更细致的见解，了解每个特征如何影响 LSTM 的预测。
尝试的内容：我们应用传统的特征重要性指标来了解不同的输入特征如何影响 LSTM 神经网络的预测。此外，我们考虑使用机器学习模型中常用的 SHAP 值，以更详细的方式归因特征重要性。
预期结果：我们预计 SHAP 值或类似的可解释性方法将有助于解释每个特征对 LSTM 预测的影响，从而清楚地了解时间特征如何随时间影响模型的输出。
实际结果：虽然特征重要性让我们大致了解哪些特征有影响，但由于 LSTM 网络的顺序性和时间依赖性，SHAP 值更难实现。我们发现为更简单的模型设计的 SHAP 方法没有完全捕捉到 LSTM 固有的时间依赖性的复杂性。因此，模型预测的可解释性仍然有限，需要替代方法。]]></description>
      <guid>https://stackoverflow.com/questions/78952839/what-can-be-used-in-lstm-neural-network-similar-to-shap-values</guid>
      <pubDate>Thu, 05 Sep 2024 11:41:07 GMT</pubDate>
    </item>
    <item>
      <title>无法让 XGBRegressor 输出 0 到 1 之间的值</title>
      <link>https://stackoverflow.com/questions/78952638/unable-to-get-xgbregressor-to-output-values-between-0-and-1</link>
      <description><![CDATA[我们创建了一个应用程序，在该应用程序中，我们为客户提供贷款优惠，客户可以根据其用例更改金额。现在，我正在尝试制作一个 XBGRegressor 模型，该模型可以预测客户的接受率金额，这将在下一个过程中进一步使用。
我使用的特征在某些列中具有空值，因此我制作了 XGBoost Regressor，因为它可以轻松处理空值。将平均值代入这些列是不可能的。我的训练数据的接受率在 0 到 1 的范围内，但我的模型预测的值仍然大于 1 甚至为负数。
我正在使用 Baysian Optimiser 来改进模型。 R 平方值不错（约为 0.75），有什么方法可以进一步改进吗？
这是我目前正在使用的代码。
def get_forecast(just_train_df, metric, data_df):
print(&#39;\nMetrics are:&#39;,metric)
data = just_train_df.copy()
X, y, X_train, y_train, X_test, y_test, X_forecast, y_original = data_preprocessing(data, metric, [])

pbounds = {
&#39;max_depth&#39;: (3, 10),
&#39;learning_rate&#39;: (0.01, 0.3),
&#39;gamma&#39;: (0, 0.5),
&#39;min_child_weight&#39;: (1, 10),
&#39;subsample&#39;: (0.5, 1.0),
&#39;colsample_bytree&#39;: (0.5, 1.0),
&#39;reg_alpha&#39;: (0, 1.0),
&#39;reg_lambda&#39;: (0, 1.0)
}

# 贝叶斯优化
def xgb_cv(max_depth, learning_rate, gamma, min_child_weight, subsample, colsample_bytree, reg_alpha, reg_lambda):

xgb_model = XGBRegressor(
objective=&#39;reg:squarederror&#39;,
eval_metric=&#39;rmse&#39;,
max_depth=int(max_depth),
learning_rate=learning_rate,
gamma=gamma,
min_child_weight=int(min_child_weight),
subsample=subsample,
colsample_bytree=colsample_bytree,
reg_alpha=reg_alpha,
reg_lambda=reg_lambda,
n_jobs=-1
)
r2_scorer = make_scorer(r2_score)
scores = cross_val_score(xgb_model, X_train, y_train,scoring=r2_scorer, cv=5, n_jobs=-1)
return scores.mean() # 返回负均方误差，因为 BayesianOptimization 最小化了目标函数

optimizer = BayesianOptimization(
f=xgb_cv,
pbounds=pbounds,
random_state=36,
verbose=2
)

print(&#39;Initiated Bayesian Optimizer...\n&#39;)
optimizer.maximize(init_points=5, n_iter=50)
print(&#39;\nCompleted Bayesian Optimizer\n&#39;)

print(&quot;Best hyperparameters: &quot;, optimizer.max[&#39;params&#39;], &#39;\n&#39;)

# 使用 Bayesian Optimizer 中的最佳参数训练模型
best_params = optimizer.max[&#39;params&#39;]
final_model = XGBRegressor(
objective=&#39;reg:squarederror&#39;,
eval_metric=&#39;rmse&#39;,
max_depth=int(best_params[&#39;max_depth&#39;]),
learning_rate=best_params[&#39;learning_rate&#39;],
gamma=best_params[&#39;gamma&#39;],
min_child_weight=int(best_params[&#39;min_child_weight&#39;]),
subsample=best_params[&#39;subsample&#39;],
colsample_bytree=best_params[&#39;colsample_bytree&#39;],
reg_alpha=best_params[&#39;reg_alpha&#39;],
reg_lambda=best_params[&#39;reg_lambda&#39;],
n_jobs=-1,
random_state=0
)

final_model.fit(X_train, y_train)

# 数据集上的预测
y_pred_test = final_model.predict(X_test)
y_pred_train = final_model.predict(X_train)
y_pred_val = final_model.predict(X_forecast)

# 在训练数据上评估 best_model
mae = mean_absolute_error(y_train, y_pred_train)
rmse = mean_squared_error(y_train, y_pred_train, squared=False)
r2_train = r2_score(y_train, y_pred_train)
print(f&quot;训练平均绝对误差：{mae}&quot;)
print(f&quot;训练 R 平方：{r2_train}\n&quot;)

# 在测试数据上评估模型
mae = mean_absolute_error(y_test, y_pred_test)
rmse = mean_squared_error(y_test, y_pred_test, squared=False)
r2_test = r2_score(y_test, y_pred_test)
print(f&quot;测试平均绝对误差：{mae}&quot;)
print(f&quot;测试 R 平方：{r2_test}\n&quot;)

目前我面临的一个主要问题是大约 65-70% 的数据采用比率为 1。我应该更改模型还是对现有模型进行更改？我应该在 XGBoost 中将输入特征标准化为 0 和 1 吗？]]></description>
      <guid>https://stackoverflow.com/questions/78952638/unable-to-get-xgbregressor-to-output-values-between-0-and-1</guid>
      <pubDate>Thu, 05 Sep 2024 10:48:03 GMT</pubDate>
    </item>
    <item>
      <title>分类模型仅预测单个类别[关闭]</title>
      <link>https://stackoverflow.com/questions/78952023/classification-model-only-predicts-single-class</link>
      <description><![CDATA[我有一个逻辑回归模型，我正在尝试在我的 NLP 项目中做出健康的预测。我做了一些事情，下面是我的分类报告：
 精确率 召回率 f1 分数 支持率

0 0.68 0.83 0.75 23
1 0.78 0.78 0.78 23
2 0.87 0.87 0.87 30
3 0.76 0.62 0.68 26

准确率 0.77 102
宏平均值 0.77 0.77 0.77 102
加权平均值 0.78 0.77 0.77 102

我认为它实际上没有看起来那么糟糕，但即使我以不同的方式设置参数，大多数时候它也会返回“3”，这是我的一个类。我的意思是，它看起来总是专注于一个单一的类别，即使我的分类报告不支持这种行为。
总之，我的模型看起来很平衡，但它的表现却不是那样。我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78952023/classification-model-only-predicts-single-class</guid>
      <pubDate>Thu, 05 Sep 2024 08:30:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras 中将 flow_from_directory 与多个目录结合使用，实现多输出神经网络</title>
      <link>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</link>
      <description><![CDATA[这是我在这里的第一个问题，所以如果有任何不清楚的地方，我深表歉意。
我正在做一个项目，需要使用 Keras 中的 flow_from_directory 从多个目录加载图像。我的目录结构如下：
Images_folder/
═── Carpet_1/
│ ═── training/
│ │ ═── class_1/
│ │ ═── class_2/
│ ═── validation/
═── Carpet_2/
│ ═── training/
│ │ ═── class_1/
│ │ ═── class_2/
│ ═── validation/
...
每个“Carpet”目录（例如 Carpet_1、Carpet_2）包含相同的类集（class_1、class_2 等）。我想使用来自所有这些目录的图像来训练 CNN。我的目标是构建一个多输出神经网络，其中一个输出预测“地毯”编号（1、2、3、...），另一个输出预测该地毯内的类别。
鉴于这种结构，我如何使用 ImageDataGenerator 或 Keras 中的任何其他方法来加载和预处理这些图像？有没有办法将来自所有这些目录的图像组合成一个生成器，同时仍然允许我区分不同的地毯？
任何关于如何解决这个问题的指导都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78951880/how-to-use-flow-from-directory-with-multiple-directories-for-multi-output-neural</guid>
      <pubDate>Thu, 05 Sep 2024 07:56:05 GMT</pubDate>
    </item>
    <item>
      <title>级联分段-通道设置是否正确？</title>
      <link>https://stackoverflow.com/questions/78951423/cascade-segmentation-are-the-channels-set-up-correctly</link>
      <description><![CDATA[我想训练一个机器学习模型，用于处理 2D DICOM 图像中的精细蒙版细节。我有 500 张图像准备进行标记/注释。我可以使用这种技术吗？还是我理解错了？
鱼 + 脊椎的注释

我用 1 个类别注释了 500 张图像：鱼。然后我训练一个 model1.pth，将鱼与背景区分开来。该模型有 2 个 out_channels：鱼和背景。

我再次注释了相同的 500 张图像，但现在有 2 个类别：鱼 + 脊椎。我加载 model1.pth，并创建一个具有 2 个输入通道 和 3 个输出通道 的模型：脊柱、鱼和背景，并将模型保存为 model2.pth

最后，我再次注释了 500 张图像，但现在我包括了变形。如果我有 3 种类型的变形，则每种变形都有自己的类别。我加载 model2.pth，创建一个具有 3 个输入通道 和 6 个输出通道 的模型：背景、鱼、脊柱、变形 1、变形 2、变形 3，并将模型保存为 model3.pth。

现在模型可以直接在新图像上使用。是这样吗？


背景和细节。我尝试过什么
目标是找到鱼脊椎的变形。到目前为止，我已尝试通过使用 MONAI 的 UNet 模型 来分割 3 个类别 + 背景。图像是转换为 NifTi 格式 (.dcm.nii.gz) 的 2D DICOM 图像，典型尺寸为 2000x900 像素。我使用 3Dslicer 进行注释。到目前为止的类别：

背景

鱼

脊椎

变形


到目前为止，我已经在（仅）12 张训练图像上进行了测试，只是为了让它运行，我得到了所有 3 个类别的结果，但我猜模型训练过度了。此外，我猜这种技术使得在训练结束后进行微小更改变得更加困难。例如，我想要多种不同类型的变形。 
我的结果：红线左侧：来自 tensorboard，红线右侧：在新图像上测试模型
在开始注释 500 张图像之前，我想验证我是否走在正确的道路上。我希望通过使用级联技术，我可以获得一个可以轻松分割鱼和脊椎的模型，并且我可以随后尝试不同的变形注释。]]></description>
      <guid>https://stackoverflow.com/questions/78951423/cascade-segmentation-are-the-channels-set-up-correctly</guid>
      <pubDate>Thu, 05 Sep 2024 05:34:37 GMT</pubDate>
    </item>
    <item>
      <title>具有共享权重的嵌套模块是否应为 nn.Module 对象参数？</title>
      <link>https://stackoverflow.com/questions/78950394/should-nested-modules-with-shared-weights-be-an-nn-module-object-parameter-or-no</link>
      <description><![CDATA[我希望两个 torch.nn.Module 类共享其部分架构和权重，如下例所示：
from torch import nn

class SharedBlock(nn.Module):
def __init__(self, *args, **kwargs):
super().__init__()

self.block = nn.Sequential(
# 在此处定义一些块架构...
)

def forward(self, x):
return self.block(x)

class MyNestedModule(nn.Module):
def __init__(self, shared_block: nn.Module, *args, **kwargs):
super().__init__()

self.linear = nn.Linear(...)
self.shared_block = shared_block

def forward(self, x):
return self.shared_block(self.linear(x))

class MyModule(nn.Module):
def __init__(self, *args, **kwargs):
super().__init__()

# 应该是：
shared_block = SharedBlock(*args, **kwargs)
# 或者：
self.shared_block = SharedBlock(*args, **kwargs) # 注意：self。
# ...如果有区别，区别是什么？

self.nested1 = MyNestedModule(shared_block, *args, **kwargs)
self.nested2 = MyNestedModule(shared_block, *args, **kwargs)

def forward(self, x):
x_1, x_2 = torch.split(x, x.shape[0] // 2, dim=0)
y_1 = self.nested1(x_1)
y_2 = self.nested2(y_2)
return y_1, y_2

我想知道 shared_block 是否应该是 MyModule 的对象参数。我认为不是，因为它在 MyNestedModule 类对象中都被设置为对象参数，所以它应该在 torch grad 中注册，但如果我确实在 MyModule 中将它创建为对象参数，会发生什么？]]></description>
      <guid>https://stackoverflow.com/questions/78950394/should-nested-modules-with-shared-weights-be-an-nn-module-object-parameter-or-no</guid>
      <pubDate>Wed, 04 Sep 2024 20:06:25 GMT</pubDate>
    </item>
    <item>
      <title>在 NumPy 中将索引数组转换为独热编码数组</title>
      <link>https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-one-hot-encoded-array-in-numpy</link>
      <description><![CDATA[给定一个 1D 索引数组：
a = array([1, 0, 3])

我想将其独热编码为 2D 数组：
b = array([[0,1,0,0], [1,0,0,0], [0,0,0,1]])
]]></description>
      <guid>https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-one-hot-encoded-array-in-numpy</guid>
      <pubDate>Thu, 23 Apr 2015 18:24:54 GMT</pubDate>
    </item>
    <item>
      <title>Akinator 游戏背后有什么样的算法？</title>
      <link>https://stackoverflow.com/questions/13649646/what-kind-of-algorithm-is-behind-the-akinator-game</link>
      <description><![CDATA[我一直很惊讶 Akinator 应用 只需问几个问题就能猜出一个字符。所以我想知道是什么样的算法或方法让它做到了这一点？这类算法有名字吗？我在哪里可以阅读更多关于它们的信息？]]></description>
      <guid>https://stackoverflow.com/questions/13649646/what-kind-of-algorithm-is-behind-the-akinator-game</guid>
      <pubDate>Fri, 30 Nov 2012 16:59:38 GMT</pubDate>
    </item>
    </channel>
</rss>