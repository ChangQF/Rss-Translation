<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 09 Aug 2024 09:17:45 GMT</lastBuildDate>
    <item>
      <title>我如何在 Tensorflow 中修剪这个神经网络？</title>
      <link>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-in-tensorflow</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network-in-tensorflow</guid>
      <pubDate>Fri, 09 Aug 2024 07:50:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的精度突然降到0.5？</title>
      <link>https://stackoverflow.com/questions/78850531/why-does-my-precision-suddenly-drop-to-0-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78850531/why-does-my-precision-suddenly-drop-to-0-5</guid>
      <pubDate>Thu, 08 Aug 2024 21:43:15 GMT</pubDate>
    </item>
    <item>
      <title>营销中的机器学习算法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78849579/ml-algorithms-in-marketing</link>
      <description><![CDATA[我接到一个任务，要将营销预算（假设为 100 万）按产品类别进行分配，从而实现收入最大化。
我熟悉机器学习的基本算法，但经验不足。
如果您能帮助我使用什么算法/提供一些想法，那就太好了？
我有一个想法，先运行回归，但我真的不明白该如何进行优化。]]></description>
      <guid>https://stackoverflow.com/questions/78849579/ml-algorithms-in-marketing</guid>
      <pubDate>Thu, 08 Aug 2024 16:49:51 GMT</pubDate>
    </item>
    <item>
      <title>如何在 sklearn 管道中实现反向序数编码并避免 NotFittedError？</title>
      <link>https://stackoverflow.com/questions/78848893/how-to-implement-reverse-ordinal-encoding-in-a-sklearn-pipeline-and-avoid-a-notf</link>
      <description><![CDATA[我正在尝试清理一个数据集，该数据集包含来自不同特征（包括数字和分类）的大量缺失值。我的想法如下：

使用 OrdinalEncoder 只保留数值并将缺失值保留为 NaN（不能使用 OneHotEncoder，因为它会创建新列，这些列为 NaN）
使用 KNNImputer 估算缺失值
反转编码，因为没有合理的理由在类别中绘制某种顺序

这是我目前的代码：
import pandas as pd
import numpy as np
from sklearn import set_config
set_config(transform_output=&quot;pandas&quot;)
from sklearn.preprocessing import OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute 导入 KNNImputer
从 sklearn.base 导入 BaseEstimator、TransformerMixin

class RoundingToIntegerTransformer(BaseEstimator、TransformerMixin):
def fit(self, X, y=None):
return self

def transform(self, X):
return np.round(X) 

class ReverseOrdinalEncoder(BaseEstimator、TransformerMixin):
def __init__(self,coder_name, categorical_columns):
self.encoder_name =coder_name
self.categorical_columns = categorical_columns

def fit(self, X, y=None):
return self

def transform(self, X, y=None):
X_ = X.copy()
coder = self.encoder_name
X_categorical = X_[categorical_columns] 
X_categorical =编码器.逆变换（X_categorical）
X_[categorical_columns] = X_categorical
返回 X_

数据 = pd.DataFrame({
&#39;类别 1&#39;：[&#39;a&#39;，&#39;b&#39;，&#39;a&#39;，np.nan，&#39;c&#39;，&#39;b&#39;]，
&#39;类别 2&#39;：[&#39;x&#39;，&#39;y&#39;，&#39;x&#39;，&#39;z&#39;，np.nan，&#39;y&#39;]，
&#39;数值 1&#39;：[1.1，np.nan，3.3，4.4，5.5，np.nan]，
&#39;数值 2&#39;：[np.nan，2.2，np.nan，4.4，5.5，6.6]
})

数值列 = data.select_dtypes(include=&#39;number&#39;).columns.tolist()
categorical_columns = data.select_dtypes(include=&#39;object&#39;).columns.tolist()

ordinal_encoder = OrdinalEncoder(encoded_missing_value=np.nan)

first_encoder = ColumnTransformer(transformers=[
(&#39;ordinal_cat&#39;, ordinal_encoder, categorical_columns)
],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False)

imputer = Pipeline([
(&#39;KNN_imputing&#39;, KNNImputer()),
(&#39;rounding&#39;, ColumnTransformer(transformers=[(&#39;round_cat&#39;, RoundingToIntegerTransformer() , categorical_columns)],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False))
])

reverse_encoder = ReverseOrdinalEncoder(
coder_name=first_encoder.transformers[0][1], 
categorical_columns=categorical_columns
)

preprocessor = Pipeline([
(&#39;encoding&#39;, first_encoder),
(&#39;imputing&#39;, imputer),
(&#39;decoding&#39;, reverse_encoder)
])

我尝试了一段时间，但从未成功，我总是收到以下错误：
&gt;NotFittedError：此 OrdinalEncoder 实例尚未安装。使用此估算器之前，请使用适当的参数调用“fit”。

我理解这个错误，但我认为由于序数编码器在管道中出现得早，因此在反向编码器中使用时它会被安装。有没有什么办法可以实现这个功能？]]></description>
      <guid>https://stackoverflow.com/questions/78848893/how-to-implement-reverse-ordinal-encoding-in-a-sklearn-pipeline-and-avoid-a-notf</guid>
      <pubDate>Thu, 08 Aug 2024 14:07:04 GMT</pubDate>
    </item>
    <item>
      <title>高效编码原则[关闭]</title>
      <link>https://stackoverflow.com/questions/78848312/principles-of-efficient-coding</link>
      <description><![CDATA[我是一名拥有 3 年以上经验的机器学习工程师。这 3 年中，我大部分时间都花在提出解决方案和为它们训练良好的模型（特别是 CV）上，仅此而已，我过去为我的团队提供模型，他们过去负责处理其余的事情。不过，最近我转向创建整个项目，包括它们的生产，现在我觉得自己对编码一无所知，因为我的代码通常很慢、很乱、效率很低。
为了解决这个问题，我开始学习一些东西，我学会了：

使用高效的数据类型
不要使用嵌套循环
学习了大 O 复杂度的概念
此外，我还在研究代码的可读性，如何使用记录器、异常、关注点分离、PEP8 标准、config.yaml、.env 文件等。

我的问题是，我似乎没有理解它的要点，效率和可读性对我来说并不自然。所以我的问题，特别是针对专业人士，当你开始任何项目时，你对代码的方法是什么，你是否有特殊的模式开始或编写和重构，你如何确保你的代码得到优化，你是否曾经想过你可能没有最好的方法。
此外，是否有一些你经常使用的库？例如，我刚刚了解了 PQDM 以及它如何并行化您的代码，那么您有什么可以帮助我的主要注意事项吗？我主要从事 ML 项目（如果这有帮助的话）。
欢迎任何想法或意见，我只是想自然地掌握它。
感谢大家的参与。
我观看了 YouTube 视频，联系了一些前辈，尝试阅读 OOP 概念和书籍，阅读数据结构等。]]></description>
      <guid>https://stackoverflow.com/questions/78848312/principles-of-efficient-coding</guid>
      <pubDate>Thu, 08 Aug 2024 12:04:57 GMT</pubDate>
    </item>
    <item>
      <title>无法在 AWS 或 Vercel 上部署 ML 项目</title>
      <link>https://stackoverflow.com/questions/78846779/unable-to-deploy-ml-project-on-aws-or-vercel</link>
      <description><![CDATA[我创建了一个简单的 ML 项目，根据性别、体重和身高预测一个人的 BMI，这是 GitHub 代码存储库的链接
https://github.com/sid111nov/BMIProject
我可以在本地机器上运行它，但无法将其部署到 AWS Bean Stack 或 Vercel。然后我认为我的项目可能存在一些问题，但构建似乎没问题。如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78846779/unable-to-deploy-ml-project-on-aws-or-vercel</guid>
      <pubDate>Thu, 08 Aug 2024 06:23:07 GMT</pubDate>
    </item>
    <item>
      <title>人工智能技术用于查找两个时间序列之间的相关性/模式/共同趋势[关闭]</title>
      <link>https://stackoverflow.com/questions/78846294/ai-techniques-to-find-correlation-pattern-common-trend-between-two-time-series</link>
      <description><![CDATA[我有一个想法，使用人工智能技术在两个连续的时间序列数据之间找到有用的信息。结果可以是相关值、共同模式或趋势等，输出结果如 TS1（时间序列 1）数据与 TS2 数据相关，反之亦然。
稍后我想特别指出这种关系究竟发生在哪里，以及它是什么类型的效果。
例如：

输入：过去 5 年的 TS1 和 TS2 数据。[浮点/双精度值]
过程：寻找相关性/模式/共同趋势。[这是我寻求指导的部分。]
输出：TS1 的变化每个月都会对 TS2 产生负面影响。 [输出文本可以由

过程部分的结果组成。]

加载数据、将其传递给模型/系统，并为非技术人员解释结果并不是一项艰巨的任务。对我来说，有趣的部分是如何找到某种关系。
到目前为止，我已经使用了 Person、Spearman 和 Kendall 相关性，并且根据我的要求，它运行得很好。但是，我想了解和使用多种技术，尤其是高级统计和机器学习模型。
哪些高级技术/模型（静态、机器学习等）适合查找两个连续时间序列数据之间的关系？]]></description>
      <guid>https://stackoverflow.com/questions/78846294/ai-techniques-to-find-correlation-pattern-common-trend-between-two-time-series</guid>
      <pubDate>Thu, 08 Aug 2024 02:13:43 GMT</pubDate>
    </item>
    <item>
      <title>face_recognition 模块以某种方式严重干扰了 Speech_recognition 模块 [关闭]</title>
      <link>https://stackoverflow.com/questions/78845929/face-recognition-module-somehow-badly-interfering-with-speech-recognition-module</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78845929/face-recognition-module-somehow-badly-interfering-with-speech-recognition-module</guid>
      <pubDate>Wed, 07 Aug 2024 22:40:22 GMT</pubDate>
    </item>
    <item>
      <title>在 RAG 中处理没有 LLMS 的问候类型问题</title>
      <link>https://stackoverflow.com/questions/78843382/handling-greet-type-of-questions-without-llm-in-rag</link>
      <description><![CDATA[我正在为一个聊天机器人实现一个检索增强生成 (RAG) 系统，该系统可以处理各种用户查询。虽然 RAG 的主要设计目的是通过检索相关文档并使用语言模型 (LLM) 生成响应来提供信息丰富的响应，但我想处理某些类型的查询，例如问候和礼貌交流，而无需借助 LLM 来提高效率和控制力。
具体来说，我想管理问候类型的问题，例如“你好”、“你好吗？”、 “早上好”等。这些问题通常是公式化的，不需要像更复杂的问题那样深入理解上下文。依靠 LLM 来处理这些问题可能会效率低下且过度。
是否有可能在没有 LLM 的情况下创建类似聊天机器人的问候交流系统？]]></description>
      <guid>https://stackoverflow.com/questions/78843382/handling-greet-type-of-questions-without-llm-in-rag</guid>
      <pubDate>Wed, 07 Aug 2024 11:17:51 GMT</pubDate>
    </item>
    <item>
      <title>如何继续创建视频描述模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</link>
      <description><![CDATA[我一直在尝试制作一个可以实时将视频转换为文本的应用程序。这意味着您可以将实时视频转换为文本。
首先，我尝试仅使用 gpt api，但当然速度很慢，而且远远达不到实时。然后我想到使用对象检测模型和 gpt 来生成视频描述，但问题是它非常不准确，因为只检测到了对象，但错过了背景或动作，我尝试过跟踪以及 yolo 的姿势模型，但这似乎也不起作用。那么，有什么建议可能有效吗？]]></description>
      <guid>https://stackoverflow.com/questions/78842373/how-to-go-on-about-creating-a-video-description-model</guid>
      <pubDate>Wed, 07 Aug 2024 07:34:13 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 和 Opacus 用于差异隐私</title>
      <link>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</link>
      <description><![CDATA[在使用 Jupyter Notebook（可从此处获取）测试来自 TensorFlow 网站的示例代码时，我遇到了错误。您可以在此处找到我关于该错误的 SO 问题。
因此，我决定使用 PyTorch、Opacus 和 PySyft 为相同功能编写等效实现。然而，不幸的是，我又遇到了另一个错误。
下面是实现与 TensorFlow 网站中的示例代码相同功能的代码，但使用 PyTorch 和 Opacus 和 PySyft，以及错误消息。
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from opacus import PrivacyEngine

# 定义一个简单的模型
class SimpleCNN(nn.Module):
def __init__(self):
super(SimpleCNN, self).__init__()
self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
self.fc1 = nn.Linear(32*26*26, 10)

def forward(self, x):
x = torch.relu(self.conv1(x))
x = x.view(-1, 32*26*26)
x = self.fc1(x)
return torch.log_softmax(x, dim=1)

# 数据加载器
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = datasets.MNIST(&#39;.&#39;, train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 初始化模型、优化器和损失函数
model = SimpleCNN()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.NLLLoss()

# 初始化 PrivacyEngine
privacy_engine = PrivacyEngine(
model,
batch_size=64,
sample_size=len(train_loader.dataset),
epochs=1,
max_grad_norm=1.0,
)

privacy_engine.attach(optimizer)

# 训练循环
model.train()
for epoch in range(1):
for data, target in train_loader:
optimizer.zero_grad()
output = model(data)
loss = criterion(output, target)
loss.backward()
optimizer.step()

# 打印隐私统计数据
epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(1e-5)
print(f&quot;Epsilon: {epsilon}, Delta: 1e-5&quot;)

错误：
-------------------------------------------------------------------------------
TypeError Traceback (最近一次调用最后一次)
Cell In[1]，第 32 行
29 criterion = nn.NLLLoss()
31 # 初始化 PrivacyEngine
---&gt; 32 privacy_engine = PrivacyEngine(
33 model,
34 batch_size=64,
35 sample_size=len(train_loader.dataset),
36 epochs=1,
37 max_grad_norm=1.0,
38 )
40 privacy_engine.attach(optimizer)
42 # 训练循环

TypeError: PrivacyEngine.__init__() 获得了意外的关键字参数“batch_size”
]]></description>
      <guid>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</guid>
      <pubDate>Tue, 06 Aug 2024 13:17:08 GMT</pubDate>
    </item>
    <item>
      <title>如果训练数据集中的正样本多于负样本，XGBoost 的 scale_pos_weight 是否可以正确平衡正样本？</title>
      <link>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我相信 scale_pos_weight 会是一种更好的方法。
是否可以安全地假设，由于比率小于 1，它仍将正确平衡类别？特异性在我的研究中很重要，但我们的主要目标集中在召回率、精确度和 F1 分数上。此设置是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>f1 分数低且损失函数分数也低</title>
      <link>https://stackoverflow.com/questions/76812516/low-f1-score-and-also-low-loss-function-score</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76812516/low-f1-score-and-also-low-loss-function-score</guid>
      <pubDate>Tue, 01 Aug 2023 14:10:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在微调过程中正确设置 pad token（而不是 eos）以避免模型无法预测 EOS？</title>
      <link>https://stackoverflow.com/questions/76633368/how-does-one-set-the-pad-token-correctly-not-to-eos-during-fine-tuning-to-avoi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76633368/how-does-one-set-the-pad-token-correctly-not-to-eos-during-fine-tuning-to-avoi</guid>
      <pubDate>Fri, 07 Jul 2023 01:11:24 GMT</pubDate>
    </item>
    <item>
      <title>如何处理预测标签比例很重要的多标签分类问题？</title>
      <link>https://stackoverflow.com/questions/62597159/how-to-approach-a-multilabel-classification-problem-where-the-proportions-of-the</link>
      <description><![CDATA[我最初的任务是根据基因表达模式对各种细胞类型（类别）进行分类，而这个问题只是涉及从多个类别中预测一个标签。这很容易做到，因为我可以分配一个独热编码向量并训练神经网络。
现在的新问题是样本中可能混合了各种细胞（因此是多标签问题）。新的挑战不仅是检测多个标签，还要检测每个标签的比例。例如，如果总共有 3 个 cell_types，并且样本包含 2 个 cell_type_1、1 个 cell_type_2 和 1 个 cell_type_3，则分类器的输出应为 [0.50, 0.25, 0.25]，而不是 [1, 1, 1]。
从我所做的简短研究来看，有多种方法可以进行二元分类，但比例分类的方法并不多。我读过关于不同准确度函数的文章，例如精确匹配率和汉明损失，这些函数似乎对这类问题很有希望。还了解到最后一层的激活函数应该是 S 型函数，而不是 Softmax，因为 Softmax 会分配一个概率，而这个属性会削弱其识别多个标签的能力。我想知道，由于比例很重要，这是否会对我有利？
我想首先了解一下这个问题是否可能（我习惯于做分类），针对这个问题推荐的损失/准确度函数类型，各种架构（如果以前已经做得很好），以及任何其他建议/资源。此外，如果这可能有助于提供更多背景信息，我正在使用 R 中的 Keras。]]></description>
      <guid>https://stackoverflow.com/questions/62597159/how-to-approach-a-multilabel-classification-problem-where-the-proportions-of-the</guid>
      <pubDate>Fri, 26 Jun 2020 14:40:54 GMT</pubDate>
    </item>
    </channel>
</rss>