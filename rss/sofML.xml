<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 19 Aug 2024 06:23:02 GMT</lastBuildDate>
    <item>
      <title>运行 Jenkins 管道时如何修复“脚本返回退出代码 15”</title>
      <link>https://stackoverflow.com/questions/78885552/how-to-fix-script-returned-exit-code-15-when-running-jenkins-pipeline</link>
      <description><![CDATA[我正在使用 Jenkins 定义管道。我正在开发一个文本摘要器项目，并使用 jenkins 进行 CICD。触发管道后，在 CD 阶段我收到以下错误：
ssh -o StrictHostKeyChecking=no -l ubuntu 3.226.221.21 &#39;cd /home/ubuntu/ &amp;&amp; wget https://raw.githubusercontent.com/mishraatharva/textsummarization/main/docker-compose.yml &amp;&amp; export IMAGE_NAME=${AWS_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/textsum:latest &amp;&amp; aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com &amp;&amp; docker compose up -d &#39;
Shell 脚本
1.6 秒
+ ssh -o StrictHostKeyChecking=no -l ubuntu 3.226.221.21 cd /home/ubuntu/ &amp;&amp; wget https://raw.githubusercontent.com/mishraatharva/textsummarization/main/docker-compose.yml &amp;&amp; export IMAGE_NAME=****:latest &amp;&amp; aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ****.dkr.ecr.us-east-1.amazonaws.com &amp;&amp; docker compose up -d 
--2024-08-18 19:19:08-- https://raw.githubusercontent.com/mishraatharva/textsummarization/main/docker-compose.yml
正在解析 raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...
正在连接到 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... 已连接。
HTTP 请求已发送，正在等待响应... 200 OK
长度：95 [text/plain]
保存至：‘docker-compose.yml.10’
0K 100% 3.77M=0s
2024-08-18 19:19:08 (3.77 MB/s) - ‘docker-compose.yml.10’ 已保存 [95/95]
警告！您的密码将以未加密形式存储在 /home/ubuntu/.docker/config.json 中。
配置凭据助手以删除此警告。请参阅
https://docs.docker.com/engine/reference/commandline/login/#credential-stores
登录成功
yaml：第 229 行：此上下文中不允许映射值
脚本返回退出代码 15
Jenkins 2.462.1

我不知道如何解决这个问题：
我正在共享包含 jenkins 文件的 github repo。
https://github.com/mishraatharva/textsummarization
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78885552/how-to-fix-script-returned-exit-code-15-when-running-jenkins-pipeline</guid>
      <pubDate>Sun, 18 Aug 2024 20:03:08 GMT</pubDate>
    </item>
    <item>
      <title>Val_accuracy 正在改变，有时它在补码之间交替（100％-val_acc）</title>
      <link>https://stackoverflow.com/questions/78885395/val-accuracy-inst-changing-and-sometimes-it-alternates-between-it-complement-10</link>
      <description><![CDATA[我被分配根据我读过的一篇论文来实现一个机器学习模型。
这篇论文实现了一个用于属性分类的多任务学习模型（带标签的图像是模型输入，带标签的意思是属性注释，每幅图像有 40 个）。
它是一个多任务学习模型，因为在模型输入层和 40 个属性分支之后有一个共享的密集层，每个分支都有自己的损失函数（所有分支的二元交叉熵）和自己的 S 型激活函数（在最后一层，用于预测 40 个属性中的每一个是否存在于图像中）。
经过大量艰苦的努力，它终于开始在所有分支上返回所有 S 型函数的概率，但只有 val_accuracy 的概率是错误的：val_loss 和损失（训练损失）越来越小，acc（训练准确度）也在正常的概率值范围内，除了 val_accuracy 总是相同的值或它的补码。
例如（仅举 5 个时期为例）：
40 个分支之一的一个属性预测的准确度：
5_o_Clock_Shadow_Accuracy
0 0.823665
1 0.891178
2 0.891178
3 0.891178

同一属性的损失：
 5_o_Clock_Shadow_loss
0 0.921046
1 0.701494
2 0.913597
3 0.765397
4 0.894950

val_loss：
val_5_o_Clock_Shadow_loss
0 730232.750000
1 300412.500000
2 376215.843750
3 0.747685
4 1.607191

最后是 val_Accuracy：
val_5_o_Clock_Shadow_Accuracy
0 0.882382
1 0.117618
2 0.882382
3   0.882382 4 0.882382  我的模型： def subnet(shared_layers_output, i): att_branch = Dense(512, name=&#39;dense_&#39;+str(i)+&#39;_1&#39;)(shared_layers_output) att_branch = ReLU()(att_branch) att_branch = BatchNormal ization()(att_branch) att_branch = Dropout(0.5)(att_branch) att_branch = Dense(512, name=&#39;dense_&#39;+str(i)+&#39;_2&#39;)(att_branch) att_branch = ReLU()(att_branch) att_branch = BatchNormalization()(att_branch) att_branch = Dropout(0.5)(att_branch)

branch_output = Dense(1, name=att_list[i],activation=&#39;sigmoid&#39;)(att_branch)

return branch_output

def multi_task_model():

#输入
input_layer = Input(shape=(512,), name=&#39;input_layer&#39;)

#共享网络（1 个网络）
shared_x = Dense(512, name=&#39;shared_dense_layer&#39;)(input_layer)
shared_x = ReLU()(shared_x)
shared_x = BatchNormalization()(shared_x)
shared_x = Dropout(0.5)(shared_x)

branch_outputs = list()
for i in range(40):
branch_outputs.append(subnet(shared_x, i))

model = Model(input_layer, branch_outputs, name=&#39;model&#39;)

返回模型


训练和测试输入形状：(n_samples, 512)
训练和测试标签输入形状：(40, n_samples)
学习率：1e-03
]]></description>
      <guid>https://stackoverflow.com/questions/78885395/val-accuracy-inst-changing-and-sometimes-it-alternates-between-it-complement-10</guid>
      <pubDate>Sun, 18 Aug 2024 18:38:14 GMT</pubDate>
    </item>
    <item>
      <title>使用自定义 yolov8 模型的图像无法在验证集中识别</title>
      <link>https://stackoverflow.com/questions/78885312/images-using-custom-yolov8-model-not-being-identified-in-validation-set</link>
      <description><![CDATA[我正在使用图像学习机器学习。我已经用总共三幅图像训练了一个新的 yolo v8 自定义模型。当我复制训练中使用的相同图像并运行时：
results = model.predict(source=&quot;/data/images/validate/*&quot;, device=device)

我得到以下输出
image 1/3 /data/images/validate/left1.jpg: 640x640 (无检测), 247.4ms
image 2/3 /data/images/validate/left2.jpg: 480x640 (无检测), 176.4ms
image 3/3 /data/images/validate/left3.jpg: 640x416 (无检测), 162.4ms

为什么检测失败？我该怎么做才能开始显示有助于理解为什么它无法检测到的指标？]]></description>
      <guid>https://stackoverflow.com/questions/78885312/images-using-custom-yolov8-model-not-being-identified-in-validation-set</guid>
      <pubDate>Sun, 18 Aug 2024 17:55:05 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用 PyTorch 运行自定义 SNN 模型时就地修改变量</title>
      <link>https://stackoverflow.com/questions/78885240/variable-modified-in-place-when-trying-to-run-a-custom-snn-model-with-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78885240/variable-modified-in-place-when-trying-to-run-a-custom-snn-model-with-pytorch</guid>
      <pubDate>Sun, 18 Aug 2024 17:16:29 GMT</pubDate>
    </item>
    <item>
      <title>理解 LSTM torch</title>
      <link>https://stackoverflow.com/questions/78884735/understanding-the-lstm-torch</link>
      <description><![CDATA[我在训练包含 LSTM 层的模型时遇到问题。
我怀疑错误可能是由于添加了数据加载器，因为当我使用完整数据集进行训练时，损失减少了。
配置：
num_epochs = 200
learning_rate = 1e-1
input_size = 599
hidden_​​size = 100
num_layers = 2
num_classes = 1
batch_size = 32

数据准备：
X_train_t = Variable(torch.Tensor(X_train.values))
y_train_t = Variable(torch.Tensor(y_train))

X_test_t = Variable(torch.Tensor(X_test.values))
y_test_t =变量（torch.Tensor（y_test））

X_train_t_final = torch.reshape（X_train_t，（X_train_t.shape[0]，1，X_train_t.shape[1]））

X_test_t_final = torch.reshape（X_test_t，（X_test_t.shape[0]，1，X_test_t.shape[1]））

print（“训练形状”，X​​_train_t_final.shape，y_train_t.shape）

print（“测试形状”，X​​_test_t_final.shape，y_test_t.shape）

train_dataset = TensorDataset（X_train_t_final，y_train_t）

test_dataset = TensorDataset（X_test_t_final，y_test_t）

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)

输出：
训练形状 torch.Size([8000, 1, 599]) torch.Size([8000, 1])
测试形状 torch.Size([998, 1, 599]) torch.Size([998, 1])

模型：
class LSTM1(nn.Module):
def __init__(self, num_classes, input_size, hidden_​​size, num_layers):
super(LSTM1，self).__init__()
self.num_classes = num_classes
self.num_layers = num_layers
self.input_size = input_size
self.hidden_​​size = hidden_​​size

self.lstm = nn.LSTM(input_size=input_size，hidden_​​size=hidden_​​size，num_layers=num_layers，batch_first=True)
self.fc_1 = nn.Linear(hidden_​​size，128)
self.fc = nn.Linear(128，num_classes)
self.relu = nn.ReLU()

def forward(self，x):
h_0 = torch.zeros(self.num_layers，x.shape[0]，self.hidden_​​size)
c_0 = torch.zeros(self.num_layers，x.shape[0]， self.hidden_​​size)
输出，(hn, cn) = self.lstm(x, (h_0, c_0))
hn = hn[-1]
out = self.relu(hn)
out = self.fc_1(out)
out = self.relu(out)
out = self.fc(out)
返回 out

训练：
lstm1 = LSTM1(num_classes, input_size, hidden_​​size, num_layers)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate) 
scheduler = optim.lr_scheduler.MultiStepLR(optimizer, miles=[30, 60, 90, 120, 150, 180]，gamma=0.2)

loss_train，loss_test = []，[]
mean_loss_train，mean_loss_test = 0，0

对于 tqdm 中的 epoch(range(num_epochs))：
对于 train_loader 中的 xb、yb：
optimizer.zero_grad()
outputs = lstm1.forward(xb)
loss = criterion(outputs，yb)
loss.backward()
optimizer.step()
mean_loss_train += loss.item()
loss_train.append(mean_loss_train / len(train_loader))
scheduler.step()

使用 torch.no_grad()：
对于 test_loader 中的 xb、yb：
outputs = lstm1.forward(xb)
loss = criterion(outputs，yb)
mean_loss_test += loss.item()
loss_test.append(mean_loss_test / len(test_loader))

if (epoch+1) % 20 == 0:
print(f&quot;Epoch: {epoch+1}, loss_train: {round(loss_train[-1], 5)}, loss_test: {round(loss_test[-1], 5)}, lr: {round(scheduler.get_last_lr()[0], 8)}&quot;) 
在此处输入代码

学习输出：
Epoch: 20, loss_train: 82.76209, loss_test: 15.35703, lr: 0.1
Epoch: 40, loss_train: 85.63364, loss_test: 18.2109, lr: 0.02
Epoch: 60，loss_train：85.87259，loss_test：18.30187，lr：0.004
Epoch：80，loss_train：85.95106，loss_test：18.39842，lr：0.004
Epoch：100，loss_train：86.0281，loss_test：18.49544，lr：0.0008
Epoch：120，loss_train：86.10304，loss_test：18.58921，lr：0.00016
Epoch：140，loss_train：86.21459，loss_test：18.65351，lr：0.00016
Epoch：160，loss_train： 86.32599，loss_test：18.80259，lr：3.2e-05
Epoch：180，loss_train：86.43954，loss_test：19.03469，lr：6.4e-06
Epoch：200，loss_train：86.58578，loss_test：19.16584，lr：6.4e-06

]]></description>
      <guid>https://stackoverflow.com/questions/78884735/understanding-the-lstm-torch</guid>
      <pubDate>Sun, 18 Aug 2024 13:32:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 ZED2 相机进行图像处理</title>
      <link>https://stackoverflow.com/questions/78884614/image-processing-with-zed2-camera</link>
      <description><![CDATA[在使用 zed2 相机处理图像时，我尝试通过 roboflow 训练图像，也使用 visual studio code 通过代码训练它们。我希望相机能够正确读取交通标志，我刚刚为特定区域拍摄了一张 3k 的照片。但远处的图像没有被 zed 检测到或误读。（大约 3-4 米）。我该如何改进图像处理。
是否需要拍摄更多照片？所以我已经训练了超过 10k。但结果并没有太大不同，它仍然没有按照我想要的方式读取。
这是一张远距离照片，但我希望它从更远的距离读取，而不是 767 值
这是我运行的 py 代码
from ultralytics import YOLO

model= YOLO(&quot;yolov8n.yaml&quot;)

predict = model.train(data=&quot;data.yaml&quot;, epochs=500)

我使用 ros bridge。我还试图通过 rviz2 可视化相机。]]></description>
      <guid>https://stackoverflow.com/questions/78884614/image-processing-with-zed2-camera</guid>
      <pubDate>Sun, 18 Aug 2024 12:43:18 GMT</pubDate>
    </item>
    <item>
      <title>在 gpu 上训练 tensorflow 模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78884301/train-tensorflow-model-on-gpu</link>
      <description><![CDATA[我的代码示例：
xTrain=[...]

yTrain=[...]

model.fit(xTrain,yTrain)

这花费了太多时间，因为模型很大，大约 3.4 GB，有 912,207,679 个可训练参数
将训练从 CPU 转移到 GPU 的最简单方法是什么？
我看到了许多其他问题和视频，但它们都很老了，而且 tf ha 最近发生了很大变化，所以请帮我做一下。]]></description>
      <guid>https://stackoverflow.com/questions/78884301/train-tensorflow-model-on-gpu</guid>
      <pubDate>Sun, 18 Aug 2024 10:13:35 GMT</pubDate>
    </item>
    <item>
      <title>回归决策树中用户定义的杂质</title>
      <link>https://stackoverflow.com/questions/78884108/user-defined-impurity-in-regression-decision-trees</link>
      <description><![CDATA[我正在从 R 迁移到 PySpark。我有一个创建回归树的过程，该树目前使用 R 的 rpart 算法构建。
在 PySpark 中配置时，我无法看到指定自定义
自定义杂质函数的选项。我有一个倾斜的数据集，我不想在公式中使用均值和方差/标准差作为节点杂质的标准，而是想使用更适合我的倾斜数据的指标。
如何在 PySpark 中定义自定义杂质函数？
我查看了决策树回归的文档，并且impurity 参数的文档仅提到对 variance 的支持

impurity = Param(parent=&#39;undefined&#39;, name=&#39;impurity&#39;, doc=&#39;用于信息增益计算的标准（不区分大小写）。支持的选项：方差&#39;)

是否有任何解决方法来定义自定义杂质函数？]]></description>
      <guid>https://stackoverflow.com/questions/78884108/user-defined-impurity-in-regression-decision-trees</guid>
      <pubDate>Sun, 18 Aug 2024 08:38:47 GMT</pubDate>
    </item>
    <item>
      <title>Cartpole 强化学习 Python</title>
      <link>https://stackoverflow.com/questions/78883565/cartpole-reinforcement-learning-python</link>
      <description><![CDATA[我已经为 cartpole 环境和强化学习编写了代码，但我不知道从哪里开始“保存”强化学习的进度，以便我可以重新运行该程序来继续训练它，以提高程序的性能。如何做到这一点？
我的程序：
import gym
import numpy as np
import time
env = gym.make(&quot;CartPole-v1&quot;, render_mode=&#39;human&#39;)
(state, _) = env.reset()
env.render()
env.step(0)
env.observation_space
env.observation_space.high
env.action_space
env.spec
env.spec.max_episode_steps
env.spec.reward_threshold
episodeNumber = 10000
timeSteps = 100
for episodeIndex in range(episodeNumber):
initial_state = env.reset
env.render()
appendedObservations = []
for timeIndex in range(timeSteps):
random_action = env.action_space.sample()
observation,奖励，终止，截断，信息 = env.step(random_action)
print(&quot;step&quot;, timeIndex, 观察，奖励，终止，信息)
appendedObservations. append(观察)
time.sleep(0.01)
if(终止)：
time.sleep(0.1)
break
env.close()
]]></description>
      <guid>https://stackoverflow.com/questions/78883565/cartpole-reinforcement-learning-python</guid>
      <pubDate>Sun, 18 Aug 2024 01:16:41 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn 的分类报告中的支持是否意味着原始数据集或输入模型的数据集中的出现？[重复]</title>
      <link>https://stackoverflow.com/questions/78883478/does-support-in-sklearns-classification-report-mean-occurences-within-original</link>
      <description><![CDATA[我实现了一个机器学习模型；为了获得有关模型性能的一些信息，我查看了来自 sklearn.metrics 的分类报告。
例如，这是我的分类报告：
分类报告图片
我有两个问题：

正类和负类旁边的支持值（56 和 3147）与底部宏和加权平均值旁边的支持值（3203 和 3203）有什么区别，我应该使用哪一个？
从这个 SO 问题，支持是每个类别中有多少个样本类。这是原始数据集中的样本，还是输入到机器学习模型中的样本？我之所以问这个问题，是因为我确实进行了重新采样，因为数据集是不平衡的。换句话说，正确的支持值是基于原始（不平衡）数据集还是输入到模型中的数据集（平衡）？

对于我的第一个问题，我相信“正确”的支持值是 3203 和 3203。这与我的第二个问题类似，因为我认为支持是基于输入到模型中的数据集，所以它应该是平衡的（因为模型如何“看到”原始数据集）？
顺便说一句，一切都在管道中，因此没有数据泄漏或模型“看到”测试数据，如果这可能相关的话。
我的问题与上面链接中的问题不是重复的，因为我问的是整个分类报告，而不仅仅是其中的一部分。]]></description>
      <guid>https://stackoverflow.com/questions/78883478/does-support-in-sklearns-classification-report-mean-occurences-within-original</guid>
      <pubDate>Sat, 17 Aug 2024 23:48:10 GMT</pubDate>
    </item>
    <item>
      <title>在sklearn的ClassificationReport中，科学“使用”的度量宏是平均值还是加权平均值？[关闭]</title>
      <link>https://stackoverflow.com/questions/78883328/in-sklearns-classificationreport-is-the-scientifically-used-metric-macro-ave</link>
      <description><![CDATA[在 Python 的 sklearn.metrics 中，我使用分类报告来帮助我解释不平衡数据集上的机器学习模型。例如，这是一个任意分类报告：
分类报告
在报告指标（例如精度）时，我们报告的是宏平均值（0.51）还是加权平均值（0.98）？我会假设是宏平均值，因为这会惩罚正类上较差的模型表现。我这样说对吗？
我不认为这是这个的重复问题，因为我基本上是在问使用宏还是加权平均值更有用（或在实践中使用更多）。]]></description>
      <guid>https://stackoverflow.com/questions/78883328/in-sklearns-classificationreport-is-the-scientifically-used-metric-macro-ave</guid>
      <pubDate>Sat, 17 Aug 2024 21:45:05 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下，torch.Tensor.backward() 函数如何工作？</title>
      <link>https://stackoverflow.com/questions/78872444/how-torch-tensor-backward-function-works-in-this-situation</link>
      <description><![CDATA[假设我将两个模型（例如 SAM 和 U-NET）的参数包含在名为“joint_parameters”的变量中，然后将优化器设置为
optimizer = torch.optim.Adam(joint_params, lr=1e-5)

假设“sam_loss”是从 SAM 模型的输出计算出来的损失。
当我执行时，U-NET 模型的参数会发生什么
sam_loss.backward()
optimizer.step() 

它对 U-NET 的参数有影响吗？还是什么都没有发生？
我认为 U-NET 的参数不会发生任何事情，但我只是想确定一下。]]></description>
      <guid>https://stackoverflow.com/questions/78872444/how-torch-tensor-backward-function-works-in-this-situation</guid>
      <pubDate>Wed, 14 Aug 2024 18:25:16 GMT</pubDate>
    </item>
    <item>
      <title>以矩阵为输入、以矩阵中位置为输出的神经网络 - 强化</title>
      <link>https://stackoverflow.com/questions/78862449/neural-network-for-matrix-as-input-and-position-in-matrix-as-output-reinforcem</link>
      <description><![CDATA[我在体育馆中设置了一个非常基本的环境，由一个 nxn 矩阵组成，由 0 和 1 填充。神经网络现在应该输出一个向量，指向矩阵的一个特定条目。
现在，这应该只是一个带有 0 的条目，然后将其更改为 1：本质上，人工智能通过强化学习用 1 填充矩阵。稍后，我希望它找到合适的位置将形状放入矩阵中（有点像俄罗斯方块游戏，只是方块不会掉落）。
无论如何，到目前为止，我一直使用 DQN 模型，但这似乎不太适合这里。有人能告诉我这种输入/输出设置的更好方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78862449/neural-network-for-matrix-as-input-and-position-in-matrix-as-output-reinforcem</guid>
      <pubDate>Mon, 12 Aug 2024 15:23:25 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：预期标量类型为 Long，但发现的是 Float（Pytorch）</title>
      <link>https://stackoverflow.com/questions/70279287/runtimeerror-expected-scalar-type-long-but-found-float-pytorch</link>
      <description><![CDATA[我尝试过多次来修复，也使用了 functional.py 中的示例代码，但仍然得到了相同的“loss”值。我该如何解决这个问题？
我的库：
导入 matplotlib.pyplot 作为 plt
导入 torch
导入 torch.nn 作为 nn
导入 numpy 作为 np
导入 matplotlib
导入 pandas 作为 pd
从 torch.autograd 导入变量
从 torch.utils.data 导入 DataLoader、TensorDataset
从 sklearn.model_selection 导入 train_test_split
导入警告
导入 os
导入 torchvision
导入 torchvision.datasets 作为 dsets
导入 torchvision.transforms 作为 transforms

train=pd.read_csv(&quot;train.csv&quot;,dtype=np.float32)

targets_numpy = train.label.values
features_numpy = train.loc[:,train.columns != &quot;label&quot;].values/255 # 标准化

features_train、features_test、targets_train、targets_test = train_test_split(features_numpy、targets_numpy、test_size = 0.2、random_state = 42)

featuresTrain=torch.from_numpy(features_train)
targetsTrain=torch.from_numpy(targets_train)

featuresTest=torch.from_numpy(features_test)
targetsTest=torch.from_numpy(targets_test) 

batch_size=100
n_iterations=10000
num_epochs=n_iterations/(len(features_train)/batch_size)
num_epochs=int(num_epochs)

train=torch.utils.data.TensorDataset(featuresTrain、targetsTrain)
test=torch.utils.data.TensorDataset(featuresTest,targetsTest)

print(type(train))

train_loader=DataLoader(train,batch_size=batch_size,shuffle=False)
test_loader=DataLoader(test,batch_size=batch_size,shuffle=False)
print(type(train_loader))

plt.imshow(features_numpy[226].reshape(28,28))
plt.axis(&quot;off&quot;)
plt.title(str(targets_numpy[226]))
plt.show()

class ANNModel(nn.Module):
def __init__(self,input_dim,hidden_​​dim,output_dim):
super(ANNModel,self).__init__()
self.fc1=nn.Linear(input_dim,hidden_​​dim)
self.relu1=nn.ReLU()
self.fc2=nn.Linear(hidden_​​dim,hidden_​​dim)
self.tanh2=nn.Tanh()
self.fc4=nn.Linear(hidden_​​dim,output_dim)

def forward (self,x): #forward 到上一层并返回 
out=self.fc1(x) 
out=self.relu1(out) 
out=self.fc2(out) 
out=self.tanh2(out)
out=self.fc4(out)
return out 

input_dim=28*28
hidden_​​dim=150 
output_dim=10

model=ANNModel(input_dim,hidden_​​dim,output_dim)

error=nn.CrossEntropyLoss()

learning_rate=0.02
optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)

count=0
loss_list=[]
iteration_list=[]
accuracy_list = []
for epoch in range(num_epochs):
for i,(images,labels) in enumerate(train_loader): 
train=Variable(images.view(-1,28*28))
labels=Variable(labels)
#print(labels)
#print(outputs) 
optimizer.zero_grad()

#forward propagation
output=model(train)

#outputs=torch.randn(784,10,requires_grad=True)
##labels=torch.randn(784,10).softmax(dim=1)
loss=error(outputs,labels)

loss.backward()

optimizer.step()

count+=1

if count % 50 == 0:
correct=0
total=0

for images,labels in test_loader:
test=Variable(images.view(-1,28*28)) 
output=model(test)

predict=torch.max(outputs.data,1)[1] #mantık???

total+= len(labels)

correct+=(predicted==labels).sum()

accuracy=100 *correct/float(total)

loss_list.append(loss.data)
iteration_list.append(count)
accuracy_list.append(accuracy)
if count % 500 == 0:
print(&#39;迭代：{} 损失：{} 准确度：{} %&#39;.format(count, loss.data, accuracy))

错误：
-------------------------------------------------------------------------------
RuntimeError Traceback（最近一次调用最后一次）
&lt;ipython-input-9-9e53988ad250&gt;在 &lt;module&gt;() 中
26 #outputs=torch.randn(784,10,requires_grad=True)
27 ##labels=torch.randn(784,10).softmax(dim=1)
---&gt; 28 loss=error(outputs,labels)
29 
30 

2 帧
/usr/local/lib/python3.7/dist-packages/torch/nn/ functional.py 在 cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing) 中
2844 如果 size_average 不为 None 或 reduce 不为 None:
2845 reduction = _Reduction.legacy_get_string(size_average, reduce)
-&gt; 2846 返回 torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
2847 
2848 

RuntimeError：预期标量类型为 Long，但发现为 Float

]]></description>
      <guid>https://stackoverflow.com/questions/70279287/runtimeerror-expected-scalar-type-long-but-found-float-pytorch</guid>
      <pubDate>Wed, 08 Dec 2021 17:29:11 GMT</pubDate>
    </item>
    <item>
      <title>错误识别某人[关闭]</title>
      <link>https://stackoverflow.com/questions/61835053/misidentifying-a-person</link>
      <description><![CDATA[我编写了一个代码，通过人脸图片识别我和其他人。然而，它把 3 张其他人的照片中的 1 张误认为是我。您如何解决这个问题？
我尝试了以下不同的方法，但仍然得到相同的结果。

2 个具有 relu 和 sigmoid 激活函数的密集层。
2 个具有 relu 和 softmax 激活函数的密集层。
3 个具有 relu 和 sigmoid 激活函数的层。
binary_crossentropy 和
categorical_crossentropy
10 个 epoch 和 15 个 epoch

以上所有操作均使用 3 层 Conv2D、3 层 MaxPooling2D 完成。
最后一个 epoch 训练：
Epoch 15/15
8/8 [===============================] - 2s 272ms/步 - 损耗：4.9323e-07 - 精度：1.0000 - val_loss：0.0326 - val_acc：1.0000
]]></description>
      <guid>https://stackoverflow.com/questions/61835053/misidentifying-a-person</guid>
      <pubDate>Sat, 16 May 2020 10:04:52 GMT</pubDate>
    </item>
    </channel>
</rss>