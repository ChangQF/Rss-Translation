<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 06 Jun 2024 12:27:55 GMT</lastBuildDate>
    <item>
      <title>为什么我的验证准确度比训练准确度差？</title>
      <link>https://stackoverflow.com/questions/78586275/why-is-my-validation-accuracy-worse-than-train-accuracy</link>
      <description><![CDATA[我正在 Chestxray 数据集上训练 ResNet50。我的训练数据大约有 15000 个样本，其中 1500 个用于验证，3000 个用于测试。这是一个多标签分类问题，我有 13 个标签，并且对其进行了独热编码。我在训练时遇到了一个问题。尽管观察到训练准确率在各个时期有所提高，但验证准确率似乎有所下降。我尝试了几次实验（操纵学习率、更改架构）和故障排除步骤，但都无法解决这个问题。我也使用了很多数据增强方法，但并没有收敛。我应该怎么做才能对其进行排序？
架构
learning_rate = 0.001
early_stopping = EarlyStopping(monitor=&#39;val_accuracy&#39;,patient=5,restore_best_weights=True)
adam_optimizer = Adam(learning_rate=learning_rate)

resnet50 = ResNet50(input_shape=(256, 256, 3),weights=&#39;imagenet&#39;,include_top=False)

for layer in resnet50.layers:
layer.trainable = False

x = Flatten()(resnet50.output)
prediction = Dense(13,activation=&#39;sigmoid&#39;)(x)

model = Model(inputs=resnet50.input,outputs=prediction)

model.compile(optimizer=adam_optimizer, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

history = model.fit(
train_dataset,
epochs=100,
validation_data=val_dataset,
callbacks=[early_stopping]

结果
Epoch 1/100
477/477 [================================] - 44s 83ms/step - loss: 1.2993 - accuracy: 0.1122 - val_loss: 1.0983 - val_accuracy: 0.1010

Epoch 2/100
477/477 [===============================] - 38s 80ms/step - 损失：1.0298 - 准确度：0.1843 - val_loss：1.3670 - val_accuracy：0.0976

Epoch 3/100
477/477 [===============================] - 39s 81ms/step - 损失：0.9871 - 准确度：0.2328 - val_loss：1.1190 - val_accuracy：0.1155

Epoch 4/100
477/477 [================================] - 39s 81ms/步 - 损失：0.9146 - 准确度：0.2757 - val_loss：1.2730 - val_accuracy：0.0797

Epoch 5/100
477/477 [==============================] - 38s 81ms/步 - 损失：0.9076 - 准确度：0.3011 - val_loss：1.4535 - val_accuracy：0.0708

Epoch 6/100
477/477 [================================] - 39s 82ms/步 - 损失：0.9280 - 准确度：0.3104 - val_loss：1.6235 - val_accuracy：0.0632

Epoch 7/100
477/477 [===============================] - 39s 81ms/step - 损失：0.8828 - 准确度：0.3356 - val_loss：1.3770 - val_accuracy：0.0777

Epoch 8/100
477/477 [===============================] - 39s 82ms/step - 损失：0.8223 - 准确度：0.3633 - val_loss：1.3722 - val_accuracy：0.1512

Epoch 9/100
477/477 [===============================] - 39s 81ms/步 - 损失：0.8407 - 准确度：0.3669 - val_loss：1.3479 - val_accuracy：0.1856

Epoch 10/100
477/477 [==============================] - 39s 81ms/步 - 损失：0.8931 - 准确度：0.3773 - val_loss：1.6562 - val_accuracy：0.0784

Epoch 11/100
477/477 [===============================] - 39s 81ms/step - 损失：0.9010 - 准确度：0.3832 - val_loss：1.9345 - val_accuracy：0.0804

Epoch 12/100
477/477 [===============================] - 39s 81ms/step - 损失：0.8932 - 准确度：0.3961 - val_loss：1.8141 - val_accuracy：0.0900

Epoch 13/100
477/477 [===============================] - 39s 81ms/step - 损失：0.8961 - 准确度：0.4017 - val_loss：2.1651 - val_accuracy：0.0598

Epoch 14/100
477/477 [===============================] - 39s 82ms/step - 损失：0.7799 - 准确度：0.4318 - val_loss：1.8136 - val_accuracy：0.0997
]]></description>
      <guid>https://stackoverflow.com/questions/78586275/why-is-my-validation-accuracy-worse-than-train-accuracy</guid>
      <pubDate>Thu, 06 Jun 2024 11:30:22 GMT</pubDate>
    </item>
    <item>
      <title>如何在支持物联网的自动售货机中实现实时库存跟踪？</title>
      <link>https://stackoverflow.com/questions/78586219/how-to-implement-real-time-inventory-tracking-in-iot-enabled-vending-machines</link>
      <description><![CDATA[该问题的主要目标是收集在自动售货机中实施基于物联网的实时库存跟踪的见解和解决方案。所概述的挑战涉及项目的关键方面，例如传感器选择、数据传输、系统集成、数据安全性和成本效益。通过提供详细的项目目标和具体挑战，该问题旨在让 Stack Overflow 社区提供实用建议、最佳实践和来自他们经验的示例
我尝试过的：

传感器选择：研究并入围了一些可以准确监控库存水平的传感器（例如，称重传感器、红外传感器）。
连接选项：考虑使用 Wi-Fi 和蜂窝网络进行数据传输。测试了初始设置，但面临间歇性连接问题。
数据处理：使用 AWS IoT Core 设置基本的云基础设施，以收集和处理来自传感器的数据。
原型：使用 Arduino 板和称重传感器构建了一个基本原型，以测量库存水平并将数据发送到 AWS IoT Core。原型可以工作，但准确性和可靠性需要改进。

我的期望：

关于最佳传感器类型的建议，以实现准确可靠的库存跟踪。
确保在连接性较差的地区稳定传输数据的解决方案。
自动售货机中 IoT 设备的电源管理技巧。
有关将新 IoT 组件与我们现有的后端系统集成的建议。
]]></description>
      <guid>https://stackoverflow.com/questions/78586219/how-to-implement-real-time-inventory-tracking-in-iot-enabled-vending-machines</guid>
      <pubDate>Thu, 06 Jun 2024 11:16:19 GMT</pubDate>
    </item>
    <item>
      <title>恶意软件特征提取困难，难以找到自动化工具</title>
      <link>https://stackoverflow.com/questions/78585761/stuck-at-the-malware-features-extraction-difficulty-at-finding-automated-tools</link>
      <description><![CDATA[我正在尝试构建一个机器学习恶意软件检测工具；我发现了多个数据集，包括微软恶意软件分类挑战（2015）和 CSV 数据集。问题是我卡在了特征提取上，特别是在 Windows 上自动执行静态和动态分析的工具。
我读过关于 PE（可移植可执行文件）工具（如 pestudio）、沙箱（如 cuckoo sandbox）的文章，但我卡在了需要自动执行分析的部分（即通过 python 代码调用工具）。
我已经使用 CSV 数据训练了多个模型（随机森林、SVM、梯度提升等），但现在我想在真正的恶意软件上尝试一下。
我曾尝试使用 IDA 反汇编程序将二进制文件转换为 .asm 和 .bytes，但似乎我需要专业版才能自动完成转换。
如果有人可以推荐一些工具，我可以用来自动执行 Windows 上的分析和特征提取，我将不胜感激，任何指向正确特征提取的指针也非常感谢 :)]]></description>
      <guid>https://stackoverflow.com/questions/78585761/stuck-at-the-malware-features-extraction-difficulty-at-finding-automated-tools</guid>
      <pubDate>Thu, 06 Jun 2024 09:43:08 GMT</pubDate>
    </item>
    <item>
      <title>在 Azure Databricks 中使用 pyspark ML 库函数时出现 Py4J 安全错误</title>
      <link>https://stackoverflow.com/questions/78585509/py4j-security-error-while-using-pyspark-ml-library-functions-in-azure-databricks</link>
      <description><![CDATA[我试图在我的 Azure Databricks 工作簿中运行以下代码
import pyspark.ml.feature
from pyspark.ml.feature import Tokenizer,StopWordsRemover
tokenizer = Tokenizer()

但是我遇到了这个错误：
Py4JError：调用 
None.org.apache.spark.ml.feature.Tokenizer 时发生错误。跟踪：
py4j.security.Py4JSecurityException：构造函数 public 
org.apache.spark.ml.feature.Tokenizer(java.lang.String) 未列入白名单。

StopWordsRemover 和 pyspark.ml.feature 中的其他一些函数也会出现类似的错误
有没有办法避免此错误，以便我可以使用相同的代码？]]></description>
      <guid>https://stackoverflow.com/questions/78585509/py4j-security-error-while-using-pyspark-ml-library-functions-in-azure-databricks</guid>
      <pubDate>Thu, 06 Jun 2024 08:56:01 GMT</pubDate>
    </item>
    <item>
      <title>Azure ML-如何从 Blob 容器注册模型？</title>
      <link>https://stackoverflow.com/questions/78584772/azure-ml-how-to-register-model-from-blob-container</link>
      <description><![CDATA[我有预定义的模型并存储在 blob 存储中。现在我想注册模型并部署它，并在 Azure ML 中启用端点。我使用了以下代码
from azureml.core import Model
from azureml.core import Workspace

subscription_id = &#39;mysub
resource_group = &#39;my_resource_group&#39;
workspace_name = &#39;my_ws_name&#39;

ws = Workspace(subscription_id, resource_group, working_name)

model_path = &#39;my_model.joblib&#39;

container = &#39;mycontainer&#39;

model_name = &#39;my_model_v1&#39;

model = Model.register(workspace=ws,
model_name=model_name,
model_path=model_path,
description=&quot;Test_Model&quot;,
tags={&#39;area&#39;: &quot;emotion detection&quot;},
model_framework=Model.Framework.SCIKITLEARN,
model_framework_version=&#39;0.24.1&#39;,
resource_configuration=None,
container_registry=None,
properties=None,
sample_input_dataset=None,
sample_output_dataset=None,
datasets=None,
model_url=f&#39;https://mystorage.blob.core.windows.net/{container}/{model_path}&#39;)
print(&quot;Ws object created&quot;)

但下面的代码返回错误
TypeError: register() 得到了一个意外的关键字参数 &#39;container_registry&#39;

有没有什么解决办法或者其他方法？]]></description>
      <guid>https://stackoverflow.com/questions/78584772/azure-ml-how-to-register-model-from-blob-container</guid>
      <pubDate>Thu, 06 Jun 2024 06:16:55 GMT</pubDate>
    </item>
    <item>
      <title>使用前向验证时，时间序列数据的 LSTM 性能急剧下降</title>
      <link>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78584759/lstm-performance-for-time-series-data-dramatically-drops-when-using-walking-forw</guid>
      <pubDate>Thu, 06 Jun 2024 06:12:10 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 detector2 中语义分割的每个类的像素总数</title>
      <link>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</link>
      <description><![CDATA[我想计算每个分割类的总像素数，我只需要每个一般对象的计数，例如每辆车一个类，每个人一个类等等。出于这个原因，我使用语义分割而不是实例分割（实例分割会分别考虑每个车辆或人员实例）。但detectron2中语义分割的输出没有二进制掩码。
我知道实例分割的输出是二进制掩码，可以使用以下代码获取像素数：
masks = output[&#39;instances&#39;].pred_masks 
results = torch.sum(torch.flatten(masks, start_dim=1),dim=1)

这给出了像素数，但分别考虑了每个车辆实例，这是我不想要的。
但是语义分割的输出是字段“sem_seg”，其中包含每个一般类的预测类概率而不是二元掩码，我怎样才能继续获取语义分割中每个类的像素数？]]></description>
      <guid>https://stackoverflow.com/questions/78583802/how-to-count-total-number-of-pixels-of-each-class-for-semantic-segmentation-in-d</guid>
      <pubDate>Wed, 05 Jun 2024 22:40:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 模型或其他实践在大型数据集中识别名字和姓氏的最佳实践是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</guid>
      <pubDate>Wed, 05 Jun 2024 20:00:15 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的残差</title>
      <link>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</link>
      <description><![CDATA[假设我们有一个线性模型，该模型适用于某些数据，其残差呈正态分布。我要问的问题是，我们能否在建模方面做得更好？有没有比这个线性模型更好的模型？
由于残差是 ND，因此没有模式可学习，因此线性模型是最好的。你对此有什么看法？
谢谢
我试图找到我的主张的严格证据，但找不到。]]></description>
      <guid>https://stackoverflow.com/questions/78581995/residuals-in-machine-learning</guid>
      <pubDate>Wed, 05 Jun 2024 15:14:26 GMT</pubDate>
    </item>
    <item>
      <title>将图像置于中心并在导出时添加背景</title>
      <link>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</link>
      <description><![CDATA[我想自动完成所有这些操作：

选择图像中的对象
在此对象上裁剪我的图像
裁剪为 1:1 的宽高比，在此对象周围留出一点空隙
以 800x800px 的 JPG 格式导出我的图像，我的对象位于图像中心，背景为白色。

我在 win11 64 位上
我做了什么：

安装 Python 并创建环境
安装opencv-python-headless、pillow、numpy、Pytorch以用于 CUDA 11.8
克隆存储库 segment-anything.git 并使用 PIP 安装它
下载sam_vit_b_01ec64.pth

像这样对 py 文件进行编码：
import os
import cv2
import numpy as np
from PIL import Image
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator

def load_image(image_path):
return cv2.imread(image_path)

def save_image(image, path):
cv2.imwrite(path + &#39;.jpg&#39;, image)

def select_object(image):
sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;sam_vit_b_01ec64.pth&quot;)
mask_generator = SamAutomaticMaskGenerator(sam)
mask = mask_generator.generate(image)
largest_mask = max(masks, key=lambda x: x[&#39;area&#39;])
返回 largest_mask[&#39;segmentation&#39;]

def crop_to_object(image, mask):
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
padding = 5
x = max(0, x - padding)
y = max(0, y - padding)
w = min(image.shape[1] - x, w + 2 * padding)
h = min(image.shape[0] - y, h + 2 * padding)

cropped_image = image[y:y+h, x:x+w]
返回 cropped_image

def resize_to_square(image, size=800):
h, w = image.shape[:2]
scale = size / max(h, w)
new_h, new_w = int(h * scale), int(w * scale)
resized_image = cv2.resize(image, (new_w, new_h), 插值=cv2.INTER_LANCZOS4)

new_image = np.ones((size, size, 3), dtype=np.uint8) * 255

top = (size - new_h) // 2
left = (size - new_w) // 2
bottom = top + new_h
right = left + new_w

new_image[top:top+new_h, left:left+new_w] = resized_image

return new_image

def process_image(image_path, output_path):

image = load_image(image_path)
mask = select_object(image)
cropped_image = crop_to_object(image, mask)
final_image = resize_to_square(cropped_image, 800)
save_image(final_image, output_path + &#39;.jpg&#39;)

def process_folder(input_folder, output_folder):

如果 os.path.exists(output_folder):
os.makedirs(output_folder)

对于 root, _, files in os.walk(input_folder):
对于 filename in files:
如果 filename.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;, &#39;.bmp&#39;, &#39;.tiff&#39;)):
input_path = os.path.join(root, filename)

relative_path = os.path.relpath(input_path, input_folder)
output_path = os.path.join(output_folder,relative_path)

output_dir = os.path.dirname(output_path)
如果 os.path.exists(output_dir):
os.makedirs(output_dir)

尝试:
process_image(input_path, output_path)
print(f&quot;已处理 {input_path}&quot;)
except Exception as e:
print(f&quot;无法处理 {input_path}：{e}&quot;)

if __name__ == &quot;__main__&quot;:
input_folder = &quot;&quot;
output_folder = &quot;&quot;
process_folder(input_folder, output_folder)

发生了什么：
我导入了基本图像，我想要预期结果，并且我获得了结果
我得到了一些不同的基本结果：

基本白色背景 -&gt; 结果
Base-nobg -&gt; &gt; 结果

有人能帮我理解我错过了什么吗？
提前谢谢，
Cyril]]></description>
      <guid>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</guid>
      <pubDate>Wed, 05 Jun 2024 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 logistf 包在 R 中计算 Firth 模型非收敛误差</title>
      <link>https://stackoverflow.com/questions/78579401/firths-model-non-converge-error-in-r-using-the-logistf-package</link>
      <description><![CDATA[这是示例数据的链接（示例数据不大 - 只有 23 kb，但可能是导致错误的原因）：

https://drive.google.com/file/d/1TWkFIKhq9VZkFnhUrt6LxYmab54ouODd/view?usp=sharing

这是我运行 firth 模型的代码。我在不同的运行中遇到了不同的错误（重新启动 r 或 r 会话），有时程序似乎卡住了（但是，活动监视器显示 CPU 使用率为 99%），其他时候我遇到了诸如不收敛之类的错误，并建议我增加迭代次数，但这并没有真正帮助。
library(caret)
library(logistf)
library(data.table)

# 定义训练控制
train_control &lt;- trainControl(method = &quot;repeatedcv&quot;, 
number = 3, repeats = 3,
savePredictions = TRUE,
classProbs = TRUE)

# 定义自定义模型函数
firth_model &lt;- list(
type = &quot;Classification&quot;,
library = &quot;logistf&quot;,
loop = NULL,
parameters = data.frame(parameter = c(&quot;none&quot;), class = c(&quot;character&quot;), label = c(&quot;none&quot;)),
grid = function(x, y, len = NULL, search = &quot;grid&quot;) {
data.frame(none = &quot;none&quot;)
},
fit = function(x, y, wts, param, lev, last, classProbs, ...) {
data &lt;- as.data.frame(x)
data$group &lt;- y
logistf(group ~ ., data = data, control = logistf.control(maxit = 100), ...)
},
predict = function(modelFit, newdata, submodels = NULL) {
as.factor(ifelse(predict(modelFit, newdata, type = &quot;response&quot;) &gt; 0.5, &quot;AD&quot;, &quot;control&quot;))
},
prob = function(modelFit, newdata, submodels = NULL) {
preds &lt;- predict(modelFit, newdata, type = &quot;response&quot;)
data.frame(control = 1 - preds, AD = preds)
}
)

train_proc &lt;- fread(&quot;train_proc.csv&quot;)

# 训练模型
set.seed(123)
firth.logist.model &lt;- train(train_proc[, .SD, .SDcols = !c(&quot;group&quot;)],
train_proc$group,
method = firth_model,
trControl = train_control)

print(firth.logist.model)


这是最新的错误
logistf(group ~ ., data = data, control = logistf.control(maxit = 100), 中出现警告：
未收敛的 PL 置信限度：变量的最大迭代次数：（截距）、x1、x2、x3、x4、x5、x6、x7、x8、x9、x10、x11、x12、x13、x14、x15、x16、x17、x18、x19、x20、x21、x22、x23、x24 超出。尝试通过将“logistpl.control(maxit=...)”传递给参数 plcontrol 来增加迭代次数

相同的代码似乎在某些数据集上运行，但在其他数据集上运行不起来。但这也可能是由于我的函数无法针对特定数据集进行自定义。我遇到了许多不同类型的错误，我开始怀疑 logistf 包本身是否不稳定。
为了提供更多信息，这是我的 r 版本：
R.version
_ 
platform aarch64-apple-darwin20 
arch aarch64 
os darwin20 
system aarch64, darwin20 
status 
major 4 
minor 3.2 
year 2023 
month 10 
day 31 
svn rev 85441 
language R 
version.string R version 4.3.2 (2023-10-31)
nickname Eye Holes 

这是我的包版本：
&gt; packageVersion(&quot;caret&quot;)
[1] ‘6.0.94’
&gt; packageVersion(&quot;logistf&quot;)
[1] ‘1.26.0’
&gt; packageVersion(&quot;data.table&quot;)
[1] ‘1.14.10’
]]></description>
      <guid>https://stackoverflow.com/questions/78579401/firths-model-non-converge-error-in-r-using-the-logistf-package</guid>
      <pubDate>Wed, 05 Jun 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>Julia MLJ Forest Load：错误：MethodError：没有与 BetaML.Bmlj.RandomForestRegressor() 匹配的方法</title>
      <link>https://stackoverflow.com/questions/78577415/julia-mlj-forest-loaderror-methoderror-no-method-matching-betaml-bmlj-randomf</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78577415/julia-mlj-forest-loaderror-methoderror-no-method-matching-betaml-bmlj-randomf</guid>
      <pubDate>Tue, 04 Jun 2024 19:40:11 GMT</pubDate>
    </item>
    <item>
      <title>SageMaker 处理作业权限被拒绝保存 /opt/ml/processing/<folder> 下的 csv 文件</title>
      <link>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</link>
      <description><![CDATA[我正在开展一个涉及 Step Functions 和 SageMaker 的项目。我有一个现有的 Step Function，需要将 SageMaker 集成到其中，我尝试添加处理、模型训练、注册模型和批量转换作业请求等步骤。我还在每个资源的末尾添加了 .sync，以便它等待一个资源完成后再开始下一个资源。
但是，我在 Step Function 的 SageMaker 处理作业中遇到了问题。处理作业运行但未完成，因为权限被拒绝从我处理的 pandas 数据框保存 CSV 文件。
# 依赖项导入
df = pd.read_csv(&quot;/opt/ml/processing/input/data/data.csv&quot;)
print(df.head())

# 对 df 进行一些处理

df.to_csv(&quot;/opt/ml/processing/output/result.csv&quot;, index=False)

以下是处理请求的状态机配置：
如果您需要查看我的配置的其他部分，请给我留言
{
&quot;AppSpecification&quot;: {
&quot;ContainerEntryPoint&quot;: [
&quot;python3&quot;,
&quot;/opt/ml/processing/input/code/processing.py&quot;
]
},
&quot;ProcessingInputs&quot;: [
{
&quot;InputName&quot;: &quot;Input-1&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/data&quot;
}
},
{
&quot;InputName&quot;: &quot;Input-2&quot;,
&quot;S3Input&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/processing.py&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/input/code&quot;
}
}
],
&quot;ProcessingOutputConfig&quot;: {
&quot;Outputs&quot;: [
{
&quot;OutputName&quot;: &quot;Output-1&quot;,
&quot;S3Output&quot;: {
&quot;S3U​​ri&quot;: &quot;s3://my-dataset/data.csv&quot;,
&quot;LocalPath&quot;: &quot;/opt/ml/processing/output/&quot;,
&quot;S3U​​ploadMode&quot;: &quot;EndOfJob&quot;
}
}
]
}
}

ProcessingInputs 配置按预期工作。我在日志中看到 df.head() 将 data.csv 内容正确打印在日志中。但是，当它到达最后一行代码时，我收到以下错误：
PermissionError: Permission Denied &#39;/opt/ml/processing/output/result.csv&#39;
我还尝试将其保存到其他文件夹，如我在网上找到的一些示例中所见，例如保存到 training、result 等文件夹，但到目前为止还没有成功。它给了我同样的权限错误。我使用了为此专门创建的 Lambda 函数，并向 SageMaker 处理作业发出请求，并得到了完全相同的权限被拒绝错误。
我还尝试将文件保存到 /opt/ml/processing/ 之外的完全不同的文件夹中，但 /result.csv
但它给了我不同的错误，因为 SageMaker 只允许我们将 csv 文件保存在 /opt/ml/processing/ 下......所以我不知道该怎么做。
目前，我正在使用 boto3 api 手动保存结果集，并等待处理作业通过我设置的 StoppingCondition.MaxRuntimeInSeconds 时间，最终它停止，我使用附加步骤来获取它。
但我不喜欢我解决问题的方式，我真的需要找到更好的方法来解决这个问题。
有人能告诉我我遗漏了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78551615/sagemaker-processing-job-permission-denied-to-save-csv-file-under-opt-ml-proces</guid>
      <pubDate>Wed, 29 May 2024 19:34:23 GMT</pubDate>
    </item>
    <item>
      <title>什么时候 dropout 对分割任务有用？</title>
      <link>https://stackoverflow.com/questions/44160030/when-dropout-is-useful-for-segmentation-task</link>
      <description><![CDATA[我正在从事分割任务。我的数据集很少。我的网络非常深（基于 Resnet）。我的问题是，dropout 在我的领域什么时候有用？我知道 dropout 通常用于处理过拟合问题。但对于分割，我没有看到很多使用 dropout 的论文。谢谢]]></description>
      <guid>https://stackoverflow.com/questions/44160030/when-dropout-is-useful-for-segmentation-task</guid>
      <pubDate>Wed, 24 May 2017 13:37:00 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn：如何获得真阳性、真阴性、假阳性和假阴性</title>
      <link>https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal</link>
      <description><![CDATA[我的问题：
我有一个数据集，它是一个大型 JSON 文件。我读取它并将其存储在 trainList 变量中。
接下来，我对其进行预处理 - 以便能够使用它。
完成后，我开始分类：

我使用 kfold 交叉验证方法来获得平均准确率并训练分类器。
我进行预测并获得该折叠的准确率和混淆矩阵。
在此之后，我想获得 真阳性 (TP)、真阴性 (TN)、假阳性 (FP) 和 假阴性 (FN) 值。我将使用这些参数来获得敏感性和特异性。 

最后，我将使用它将其放入 HTML 中，以便显示包含每个标签的 TP 的图表。
代码：
我目前拥有的变量：
trainList #这是一个包含我数据集的所有数据的 JSON 格式列表
labelList #这是一个包含我数据的所有标签的列表

该方法的大部分内容：
#我将数据从 JSON 格式转换为数字格式
X=vec.fit_transform(trainList)

#我缩放矩阵（不知道为什么，但没有它，就会出错）
X=preprocessing.scale(X.toarray())

#我生成一个 KFold 以进行交叉验证
kf = KFold(len(X), n_folds=10, indices=True, shuffle=True, random_state=1)

#我开始对 kf 中的 train_indices、test_indices 进行交叉验证

X_train=[X[ii] for ii in train_indices]
X_test=[X[ii] for ii in test_indices]
y_train=[listaLabels[ii] for ii in train_indices]
y_test=[listaLabels[ii] for ii in test_indices]

#我训练分类器
trained=qda.fit(X_train,y_train)

#我进行预测
predicted=qda.predict(X_test)

#我获得此折叠的准确率
ac=accuracy_score(predicted,y_test)

#我获得混淆矩阵
cm=confusion_matrix(y_test, predicted)

#我应该计算 TP、TN、FP 和 FN
#我不知道如何继续
]]></description>
      <guid>https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal</guid>
      <pubDate>Thu, 09 Jul 2015 17:19:02 GMT</pubDate>
    </item>
    </channel>
</rss>