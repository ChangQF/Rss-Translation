<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Apr 2024 12:24:36 GMT</lastBuildDate>
    <item>
      <title>迄今为止，哪种图像去雾模型最好？当对真实数据进行训练时，所有在线可用的模型都会给出丑陋的结果</title>
      <link>https://stackoverflow.com/questions/78310078/which-is-the-best-model-for-image-dehazing-till-now-when-train-on-real-data-all</link>
      <description><![CDATA[目前用于图像去雾的最佳模型或算法是什么？据我研究（从性能指标），我了解到 GMAN 架构具有最高的准确性。但我想提高模型的准确性。
我也尝试实现一些架构和 GAN，但到目前为止，我仅在 GMAN 中获得最高的准确度，但在真实数据图像上进行测试时，它没有给我正确的图像。
边缘的颜色正在扩散，模型也扰乱了天空（大气图像）]]></description>
      <guid>https://stackoverflow.com/questions/78310078/which-is-the-best-model-for-image-dehazing-till-now-when-train-on-real-data-all</guid>
      <pubDate>Thu, 11 Apr 2024 11:41:10 GMT</pubDate>
    </item>
    <item>
      <title>寻找最可分离的点云集</title>
      <link>https://stackoverflow.com/questions/78309433/finding-most-separable-set-of-point-clouds</link>
      <description><![CDATA[我有一组表示为多维空间中的数据点云的对象。在 40 个对象中，我需要选择 10 个来创建分离度最好的对象集。可分离性是使用所有可能的云对之间的 Bhattacharyya 距离来测量的。
我尝试过使用组合学和二项式系数的残酷力方法，通过创建所有可能的 10 组并计算每组的距离，然后进行比较。我也尝试过实现图算法，但这两种方法都需要大量计算且耗时。我正在寻找更优化的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78309433/finding-most-separable-set-of-point-clouds</guid>
      <pubDate>Thu, 11 Apr 2024 09:41:44 GMT</pubDate>
    </item>
    <item>
      <title>如何标准化输出数据</title>
      <link>https://stackoverflow.com/questions/78308791/how-can-i-normalize-the-output-data</link>
      <description><![CDATA[在他的 Flutter 项目中使用 TensorFlowLite 来查找脸上的点。输出如下所示：
模型输出
如何将这些数据转换为坐标？]]></description>
      <guid>https://stackoverflow.com/questions/78308791/how-can-i-normalize-the-output-data</guid>
      <pubDate>Thu, 11 Apr 2024 07:31:57 GMT</pubDate>
    </item>
    <item>
      <title>PyCaret Predict_model 数据集兼容性</title>
      <link>https://stackoverflow.com/questions/78308672/pycaret-predict-model-dataset-compatibility</link>
      <description><![CDATA[我正在尝试使用 pycaret 使用看不见的数据来预测分数。我确信我看不见的数据框具有模型中包含的所有功能，但我仍然收到此错误：
CatBoostError：catboost/libs/data/model_dataset_compatibility.cpp:81：位置 1 应该是名为 Customer_Acct 的功能（找到 Pay_Acct）

我在看不见的数据框中都有这两列。
当我使用 model.features_names_in_ 检查时，我发现这两个特征都在模型中，所以我不知道问题是什么。
我尝试交换两列的位置，但没有成功。我也尝试删除任一列，但随后遇到了不同的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78308672/pycaret-predict-model-dataset-compatibility</guid>
      <pubDate>Thu, 11 Apr 2024 07:07:14 GMT</pubDate>
    </item>
    <item>
      <title>Numpy reshape() 以编程方式以 3D 形式显示 2D 数组</title>
      <link>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</link>
      <description><![CDATA[示例数据
我有一系列经纬度的天气数据，其形状如下：(1038240,4)（有关示例数据，请参阅照片）
我想将其重塑为形状 (4,721,1440)，这将是 721 x 1440 地球图像上的四个天气变量（&amp; lat/lon）。
我已经尝试过：
newarr = t_new.reshape(4,721,1440)

这会将其置于正确的形状，但与前两个纬度/经度坐标与以下首选格式不匹配：
对于上图中的 (6,4) 示例数据，此操作看起来像下面的 (2,3,2) 数组：
所需输出示例
newarr = t_new.reshape(4,721,1440)
]]></description>
      <guid>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</guid>
      <pubDate>Thu, 11 Apr 2024 06:06:56 GMT</pubDate>
    </item>
    <item>
      <title>SQL 查询数据集包含查询和执行时间/内存</title>
      <link>https://stackoverflow.com/questions/78308154/sql-queries-dataset-containing-queries-and-execution-time-memory</link>
      <description><![CDATA[我正在致力于创建 ML 模型来预测 SQL 查询的执行速度或所需的内存量。是否有任何数据集可供我使用，同时具有 SQL 查询和执行时间/内存作为特征？]]></description>
      <guid>https://stackoverflow.com/questions/78308154/sql-queries-dataset-containing-queries-and-execution-time-memory</guid>
      <pubDate>Thu, 11 Apr 2024 04:08:54 GMT</pubDate>
    </item>
    <item>
      <title>如何解决使用 cnn 和 lstm 进行机器学习时出现的错误？</title>
      <link>https://stackoverflow.com/questions/78308090/how-can-i-resolve-an-error-that-appeared-in-machine-learning-using-cnn-and-lstm</link>
      <description><![CDATA[我想创建一个回归模型，其中包含 6 个时间序列图像作为解释变量和 3 个输出层。目前，有 125 对解释变量（6 个时间序列图像）和目标变量（3 个数值）。具有时间序列关系的 6 个图像被分组在一个文件夹中。我用以下代码创建了模型，执行环境是Google colab。
导入操作系统
将 pandas 导入为 pd
将 numpy 导入为 np
导入CV2
从 sklearn.model_selection 导入 train_test_split
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入ConvLSTM2D，BatchNormalization，密集
从tensorflow.keras.optimizers导入Adam
将 matplotlib.pyplot 导入为 plt

将张量流导入为 tf


# 三种类型的数值数据
df = pd.read_excel(r“/path/to/file/hoge.xlsx”)

# 图像数据加载和预处理
image_folder = r“/路径/到/文件夹”
图片 = []
标签=[]

img_set_cnt = 125
min_img_cnt = 6

对于范围内的 i(1, img_set_cnt + 1)：
    第一=[]
    对于范围内的 j（1，min_img_cnt + 1）：
        img_path = os.path.join(image_folder, str(i), f&quot;no{i}_BW_{j}.jpg&quot;)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img = np.array(img) / 255.0 # 标准化（例如在浮点表示系统中）
        lst.追加（img）
    图像.append(lst)
    labels.append(df.iloc[i-1][[“column1”, “column2”, “column3”]].values)

标签 = np.array(标签)

# 将数据分为训练和测试
train_x, val_x, train_y, val_y = train_test_split(图像, 标签, test_size=0.3, random_state=71, shuffle=True)

# 仅第一层需要输入规范
模型=顺序（[
    ConvLSTM2D(filters=16, kernel_size=(18,18), return_sequences=True, data_format=“channels_last”, input_shape=(min_img_cnt, 256, 256, 1)),
    批量归一化（动量=0.8），
    ConvLSTM2D(filters=8, kernel_size=(18,18), return_sequences=True, data_format=“channels_last”),
    批量归一化（动量=0.8），
    ConvLSTM2D(filters=3，kernel_size=(6,6)，return_sequences=False，data_format=“channels_last”，activation=&#39;relu&#39;),
    Dense(units=3,activation=&#39;linear&#39;) # 假设回归的恒等函数
]）


print(len(images)) # 图像集的数量
print(len(images[0])) # 第一个图像集中的图像数量
print(images[0][0].shape) # 第一个图像集中第一个图像的形状


# 模型编译
model.compile(loss=&#39;mean_squared_error&#39;, 优化器=Adam(), 指标=[&#39;mae&#39;])

# 模型学习
历史=模型.fit(
    np.array(train_x), np.array(train_y),
    批量大小=16，
    纪元=10，
    validation_data=(np.array(val_x), np.array(val_y)),
    随机播放=真）


############执行结果############
125
6
(256, 256)
纪元 1/10
&lt;小时/&gt;
InvalidArgumentError Traceback（最近一次调用最后一次）
 在&lt;细胞系：5&gt;()
历史 = model.fit(
    np.array(train_x), np.array(train_y),
    批量大小=16，

1 帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py 中的 fast_execute(op_name, num_outputs, inputs, attrs, ctx, name)
&lt;前&gt;&lt;代码&gt;尝试：
    ctx.ensure_initialized()
    张量 = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
                                      输入、属性、num_outputs）

除了 core._NotOkStatusException 作为 e:
InvalidArgumentError：图形执行错误
############################################
我不知道为什么在做机器学习的时候Graph这个词是错误的。请告诉我该怎么做。]]></description>
      <guid>https://stackoverflow.com/questions/78308090/how-can-i-resolve-an-error-that-appeared-in-machine-learning-using-cnn-and-lstm</guid>
      <pubDate>Thu, 11 Apr 2024 03:40:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 2 层神经网络进行 sin 近似</title>
      <link>https://stackoverflow.com/questions/78307766/sin-approximation-with-a-2-layer-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78307766/sin-approximation-with-a-2-layer-neural-network</guid>
      <pubDate>Thu, 11 Apr 2024 00:58:29 GMT</pubDate>
    </item>
    <item>
      <title>尝试寻找相关数据模式</title>
      <link>https://stackoverflow.com/questions/78307684/attempting-to-find-relative-data-patterns</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78307684/attempting-to-find-relative-data-patterns</guid>
      <pubDate>Thu, 11 Apr 2024 00:21:56 GMT</pubDate>
    </item>
    <item>
      <title>将手写数学方程解析为字符串/数值</title>
      <link>https://stackoverflow.com/questions/78307038/parse-handwritten-math-equation-to-string-numerical-value</link>
      <description><![CDATA[我有这个图像，我需要在Python中解决。它非常像手写数字，我需要将图像解析为字符串，甚至更好，对其求值并获取该表达式或与此类似的表达式的结果。
有什么方法可以至少半可靠地做到这一点吗？阅读它需要使用大量手写字符进行机器学习，但我无法理解它是如何工作的。我也希望它能够相当快地解析图像，但我不介意用数据训练我的模型，无论它在实际识别数字之前需要训练多长时间。
感谢任何帮助，提前致谢！
我尝试过超正方体，但它只能从该图像中检测到 4 和 5，因为我认为这些图像是不整洁和草率的，即使在将其转换为黑白并增强对比度等之后也是如此。]]></description>
      <guid>https://stackoverflow.com/questions/78307038/parse-handwritten-math-equation-to-string-numerical-value</guid>
      <pubDate>Wed, 10 Apr 2024 20:44:13 GMT</pubDate>
    </item>
    <item>
      <title>尽管已安装，脚本仍不断请求安装face_recognition_models</title>
      <link>https://stackoverflow.com/questions/78300706/script-continuously-requests-face-recognition-models-installation-despite-being</link>
      <description><![CDATA[我在使用 Face_recognition 库的 Python 脚本中遇到问题。尽管已经成功安装了face_recognition_models包，但当我尝试执行脚本时，脚本反复提示我安装它。这是我收到的命令和输出：

代码：
导入操作系统
导入人脸识别
导入人脸识别模型
导入CV2


image_path = “tes.png”;

# 检查图片文件是否存在
如果不是 os.path.isfile(image_path):
    print(&quot;图像文件不存在:&quot;, image_path)
    出口（）

# 获取网络摄像头 #0 的引用（默认摄像头）
video_capture = cv2.VideoCapture(0)

# 加载您的图像并学习如何识别它。
图像=face_recognition.load_image_file(image_path)
face_encoding =face_recognition.face_encodings(图像)[0]

# 创建已知面部编码及其名称的数组
已知人脸编码 = [
    面部编码，
]
已知面孔名称 = [
        “瓦利德”
]

而真实：
        # 抓取单帧视频
        ret, 帧 = video_capture.read()

        # 将图像从 BGR 颜色（OpenCV 使用）转换为 RGB 颜色（face_recognition 使用）
        rgb_frame = 帧[:, :, ::-1]

        # 查找当前帧视频中的所有人脸
        面部位置 = 面部识别.面部位置(rgb_frame)
        face_encodings =face_recognition.face_encodings（rgb_frame，face_locations）

        # 循环遍历该视频帧中的每张脸
        对于（上，右，下，左），zip中的face_encoding（face_locations，face_encodings）：
            # 查看该面孔是否与已知面孔匹配
            匹配=face_recognition.compare_faces（known_face_encodings，face_encoding）

            名称=“未知”

            如果匹配中为真：
                first_match_index = matches.index(True)
                名称 =known_face_names[first_match_index]

            # 在脸部周围画一个方框
            cv2.rectangle(frame, (左, 上), (右, 下), (0, 0, 255), 2)

            # 在脸部下方画一个带有名字的标签
            cv2.rectangle(frame, (左, 下 - 35), (右, 下), (0, 0, 255), cv2.FILLED)
            字体= cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(框架, 名称, (左 + 6, 下 - 6), 字体, 1.0, (255, 255, 255), 1)

        # 显示结果图像
        cv2.imshow(&#39;视频&#39;, 帧)

        # 按键盘上的“q”退出！
        如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
            休息

# 释放网络摄像头的句柄
video_capture.release()
cv2.destroyAllWindows()


我尝试利用face_recognition 库执行Python 脚本。尽管成功安装了face_recognition_models包，但该脚本在执行时不断提示我安装它。我希望脚本能够识别已安装的包并执行而不会出现错误，但它继续请求安装face_recognition_models。]]></description>
      <guid>https://stackoverflow.com/questions/78300706/script-continuously-requests-face-recognition-models-installation-despite-being</guid>
      <pubDate>Tue, 09 Apr 2024 19:29:09 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：“GraphModule”对象不可下标（Pytorch 中 .onnx ML 模型的访问权重）</title>
      <link>https://stackoverflow.com/questions/78289901/typeerror-graphmodule-object-is-not-subscriptable-access-weights-for-onnx-m</link>
      <description><![CDATA[我有一个流行的 .onnx ML 天气预报模型，我正在尝试将其转换为 PyTorch 进行微调。我使用以下代码来转换它：
导入操作系统
将 numpy 导入为 np
导入onnx
从 onnx 导入 numpy_helper
将 onnxruntime 导入为 ort
从 onnx2torch 导入 转换

model_24 = onnx.load(&#39;pangu_weather_24.onnx&#39;)
tm = Convert(model_24) #将onnx模型转换为torch

从这里，我想访问“tm”对象中模型的权重，但我似乎无法在网上找到任何相关资源。
尝试使用 tm[0] 对其进行下标会显示以下错误：
TypeError：“GraphModule”对象不可下标

通过“tm.dict”获取该对象的字典更加令人困惑（粘贴在图像中）。
在线访问 PyTorch 权重矩阵的常规方法也显示出图形模块不可下标的相同错误]]></description>
      <guid>https://stackoverflow.com/questions/78289901/typeerror-graphmodule-object-is-not-subscriptable-access-weights-for-onnx-m</guid>
      <pubDate>Mon, 08 Apr 2024 02:13:29 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“layoutlm”导入名称“LayoutlmConfig”</title>
      <link>https://stackoverflow.com/questions/72480985/importerror-cannot-import-name-layoutlmconfig-from-layoutlm</link>
      <description><![CDATA[我正在尝试保存 LayoutLM 模型的预测。
论文 - https://arxiv.org/abs/1912.13318
笔记本 - https://www.kaggle .com/code/iamarjunchandra/layoutlm-document-sequence-labeling-model/notebook
当我运行以下代码进行预测时出现问题
！ python unilm/layoutlm/examples/seq_labeling/run_seq_labeling.py
                               --do_predict
                               --data_dir 数据
                               --model_type布局lm
                               --模型名称或路径输出
                               --output_dir 输出
                               --标签数据/labels.txt \
                               --fp16

我收到以下错误。
回溯（最近一次调用最后一次）：
  文件“unilm\\layoutlm\\examples\\seq_labeling\\run_seq_labeling.py”，第53行，在&lt;module&gt;中。
    从layoutlm导入FunsdDataset、LayoutlmConfig、LayoutlmForTokenClassification
ImportError：无法从“layoutlm”导入名称“LayoutlmConfig”(c:\Users\jyoti\anaconda3\lib\site-packages\layoutlm\__init__.py)
]]></description>
      <guid>https://stackoverflow.com/questions/72480985/importerror-cannot-import-name-layoutlmconfig-from-layoutlm</guid>
      <pubDate>Thu, 02 Jun 2022 18:47:20 GMT</pubDate>
    </item>
    <item>
      <title>为什么 PCA 图像与原始图像完全不相似？</title>
      <link>https://stackoverflow.com/questions/58976380/why-the-pca-image-doesnt-resemble-the-original-image-at-all</link>
      <description><![CDATA[我正在尝试在没有任何图像降维库的情况下实现 PCA。我尝试了 O&#39;Reilly 计算机视觉书中的代码，并在示例 lenna 图片上实现了它：
 来自 PIL 导入图像
    从 numpy 导入 *

    def pca(X):
        num_data, 暗淡 = X.shape

        Mean_X = X.mean(轴=0)
        X = X - 平均值_X

        如果暗淡&gt;数据数量：
            # PCA 紧凑技巧
            M = np.dot(X, X.T) # 协方差矩阵
            e, U = np.linalg.eigh(M) # 计算特征值和特征向量
            tmp = np.dot(X.T, U).T
            V = tmp[::-1] # 反转，因为最后一个特征向量是我们想要的
            S = np.sqrt(e)[::-1] #reverse 因为最后一个特征值是按递增顺序排列的
            对于范围内的 i(V.shape[1])：
                V[:,i] /= S
        别的：
            #普通PCA、SVD方法
            U,S,V = np.linalg.svd(X)
            V = V[:num_data] # 仅返回第一个 num_data 才有意义
        返回 V、S、mean_X
img=color.rgb2gray(io.imread(&#39;D:\lenna.png&#39;))
x,y,z=pca(img)
plt.imshow(x)



但是 PCA 的图像图看起来根本不像原始图像。
据我所知，PCA 有点减少图像尺寸，但它仍然会在某种程度上类似于原始图像，但细节较低。代码有什么问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/58976380/why-the-pca-image-doesnt-resemble-the-original-image-at-all</guid>
      <pubDate>Thu, 21 Nov 2019 13:39:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sklearn 中的岭和套索回归需要 random_state？</title>
      <link>https://stackoverflow.com/questions/48909927/why-is-random-state-required-for-ridge-lasso-regression-in-sklearn</link>
      <description><![CDATA[在 scikit-learn 中，Lasso 和 Ridge 回归是两种具有 random_state 属性的回归方法。为什么这两个方法需要这个属性？
来自文档：
class sklearn.linear_model.Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001 ，warm_start = False，positive = False，random_state =无，selection =&#39;循环&#39;）


sklearn. Linear_model.Ridge 类（alpha=1.0，fit_intercept=True，normalize=False，copy_X=True，max_iter=None，tol=0.001，solver=&#39;auto&#39;，random_state=None）
]]></description>
      <guid>https://stackoverflow.com/questions/48909927/why-is-random-state-required-for-ridge-lasso-regression-in-sklearn</guid>
      <pubDate>Wed, 21 Feb 2018 15:43:31 GMT</pubDate>
    </item>
    </channel>
</rss>