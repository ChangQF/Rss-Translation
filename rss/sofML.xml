<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 17 Jan 2024 15:14:40 GMT</lastBuildDate>
    <item>
      <title>人脸图像检测CNN [关闭]</title>
      <link>https://stackoverflow.com/questions/77833016/face-image-detection-cnn</link>
      <description><![CDATA[我正在尝试训练一个简单的图像分类模型，用于根据面部图像对年龄进行分类。我收到这样的错误：“RuntimeError：权重张量应该为所有 64 个类定义，或者没有类，但得到形状的权重张量：[99]”。由于某种原因，我的自定义图像文件夹类将父文件夹 face_age 作为类别之一，我不确定为什么。我怀疑这可能与尺寸不兼容有关。
这是我的 Kaggle 笔记本：
https://www.kaggle.com/code/gustavo9898/face -年龄检测]]></description>
      <guid>https://stackoverflow.com/questions/77833016/face-image-detection-cnn</guid>
      <pubDate>Wed, 17 Jan 2024 13:58:48 GMT</pubDate>
    </item>
    <item>
      <title>整个数据集的概率估计[关闭]</title>
      <link>https://stackoverflow.com/questions/77832767/probability-estimates-on-whole-dataset</link>
      <description><![CDATA[对于数据集 X 上的二元分类问题，分为训练和集合测试（或训练、验证、测试（如果执行参数调整）），可以通过在训练集上拟合模型来获得概率估计，然后使用 &lt;测试集上的 code&gt;predict_proba 方法（如果可用）。通过这种方式，我们可以得到未见过的数据的概率估计。
但是，获得整个数据集概率估计的最佳方法是什么 - 如果这有意义，那么不涉及对整个数据集 X 进行训练？也许用多个保留集将数据集分成多个折叠？]]></description>
      <guid>https://stackoverflow.com/questions/77832767/probability-estimates-on-whole-dataset</guid>
      <pubDate>Wed, 17 Jan 2024 13:23:39 GMT</pubDate>
    </item>
    <item>
      <title>数字模式异常检测[关闭]</title>
      <link>https://stackoverflow.com/questions/77832445/number-pattern-anomaly-detection</link>
      <description><![CDATA[我正在尝试查找订单确认号中的异常模式。
例如
ABC 客户端具有以下模式：
&lt;前&gt;&lt;代码&gt;390142567
395142611
4001x
400
400142614
497142759
500142813
230123315

这是客户不断变化的模式，下面是异常情况
&lt;前&gt;&lt;代码&gt;4001x
400
230123315

不遵循模式
如何检测这些异常？]]></description>
      <guid>https://stackoverflow.com/questions/77832445/number-pattern-anomaly-detection</guid>
      <pubDate>Wed, 17 Jan 2024 12:28:05 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中的数据上应用分裂（自上而下）层次聚类？</title>
      <link>https://stackoverflow.com/questions/77831850/how-to-apply-divisive-top-downhierarchical-clustering-over-a-data-in-python</link>
      <description><![CDATA[我正在寻找一种（python）实现自上而下（又名）分层聚类的分裂方法。在文档中，人们到处都在谈论凝聚层次聚类，这是一种自下而上的方法。
有可用的内置 Python 函数吗？
我也愿意接受自定义 GitHub Python 存储库，甚至是其他编程语言的实现。]]></description>
      <guid>https://stackoverflow.com/questions/77831850/how-to-apply-divisive-top-downhierarchical-clustering-over-a-data-in-python</guid>
      <pubDate>Wed, 17 Jan 2024 10:51:48 GMT</pubDate>
    </item>
    <item>
      <title>如何训练一个接受十六进制代码的模型，并且它应该输出给定数量的对比或相似的十六进制代码</title>
      <link>https://stackoverflow.com/questions/77830997/how-do-i-train-a-model-that-takes-in-a-hex-code-and-it-should-output-a-given-num</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77830997/how-do-i-train-a-model-that-takes-in-a-hex-code-and-it-should-output-a-given-num</guid>
      <pubDate>Wed, 17 Jan 2024 08:40:22 GMT</pubDate>
    </item>
    <item>
      <title>查找输入列中的值的优化组合，以生成输出列中的值[关闭]</title>
      <link>https://stackoverflow.com/questions/77830783/find-optimized-combinations-of-values-in-input-columns-that-produces-the-values</link>
      <description><![CDATA[我有多个生成输出列的输入列。我想找到输入列中的值的优化组合，以生成输出列中的值。
例如：像这个表所以输出将是这样的：
抄送-&gt;输出4
AA，XX -&gt;输出1
等等。
我正在尝试使用关联规则学习来查找多个输入列和一个输出列（所有文本列）之间的规则或关系。我尝试过 pycaret.arules 但在 pycaret==2.3.10 之后它不可用，并且此版本或以下版本与 Python 3.10 不兼容。所以，我不能使用它。
有没有其他方法可以解决这个问题。我尝试过决策树，但我想要一些完全适合我的数据而无需任何额外节点的东西。
到目前为止，我已经研究了 apyori、efficient-apriori 等不同的 apriori 实现。它们都不完全符合我想要的。]]></description>
      <guid>https://stackoverflow.com/questions/77830783/find-optimized-combinations-of-values-in-input-columns-that-produces-the-values</guid>
      <pubDate>Wed, 17 Jan 2024 08:01:36 GMT</pubDate>
    </item>
    <item>
      <title>比较SQL形式的图数据库？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77830268/comparing-graph-database-in-sql-form</link>
      <description><![CDATA[我有几个 SQL 图形数据库。每个数据库都有不同的版本/更新，例如1.8-&gt; 1.9-&gt; 1.9.5等
每个数据库有6个表。

有没有办法比较他们的架构？哪种工具适合/推荐？

是否有资源可以让我学习如何比较图形数据库？例如。 YouTube、书籍

通常针对这些类型的工作进行静态分析？


蒂亚！
阅读Neoj4文档和KG书籍但不足以解决问题]]></description>
      <guid>https://stackoverflow.com/questions/77830268/comparing-graph-database-in-sql-form</guid>
      <pubDate>Wed, 17 Jan 2024 06:04:49 GMT</pubDate>
    </item>
    <item>
      <title>相关矩阵的累积 AOC 计算 [关闭]</title>
      <link>https://stackoverflow.com/questions/77830147/cumulative-aoc-calculation-for-a-correlation-matrix</link>
      <description><![CDATA[我正在使用一个非常简单的数据集（胎儿健康分类）进行练习，使用支持向量机、相关指标和典型模型指标（没什么特别的）进行一些练习。我必须写一个“for循环”执行以下操作：

采用（与目标）最相关的变量并计算 SVM 模型；然后保留 AUC 结果。
采用第二个最相关的变量（与目标）并使用第一个和第二个变量，计算 SVM 模型；然后保留 AUC 结果。
依此类推......直到到达最后一个变量

之后，我需要创建一个显示以下信息的图表：

X轴：累计变量数
Y 轴：模型中包含的每个变量数量对应的 AUC

我完全被困住了。我将不胜感激任何帮助...
我有相关矩阵并且我理解它。我无法制定一个策略来获取列表中的每个值，然后应用模型，以便最终我可以获得数据集：变量的累积数量和相应的 AUC。]]></description>
      <guid>https://stackoverflow.com/questions/77830147/cumulative-aoc-calculation-for-a-correlation-matrix</guid>
      <pubDate>Wed, 17 Jan 2024 05:28:50 GMT</pubDate>
    </item>
    <item>
      <title>随机获取.jpg文件的名称[关闭]</title>
      <link>https://stackoverflow.com/questions/77829674/randomly-get-the-names-of-the-jpg-files</link>
      <description><![CDATA[我想随机获取.jpg文件的名称并分为2个文件：tranning.txt和test.txt。我使用的数据集是Caltech256、python和ggcolab。
我想知道是否有任何工具或方法可以帮助我快速完成此操作。
感谢您的关注]]></description>
      <guid>https://stackoverflow.com/questions/77829674/randomly-get-the-names-of-the-jpg-files</guid>
      <pubDate>Wed, 17 Jan 2024 02:25:26 GMT</pubDate>
    </item>
    <item>
      <title>改进多类分类模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77829624/improving-multi-class-classification-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77829624/improving-multi-class-classification-model</guid>
      <pubDate>Wed, 17 Jan 2024 02:04:21 GMT</pubDate>
    </item>
    <item>
      <title>如何仅使用组件在 azure ml Designer 中训练和部署 ml 模型？</title>
      <link>https://stackoverflow.com/questions/77827691/how-to-train-and-deploy-ml-models-in-azure-ml-designer-just-using-components</link>
      <description><![CDATA[我在 azure ml Designer 中创建了一个训练管道。现在，我需要通过添加用于注册和部署的组件来部署此模型。我想我可以使用“执行 python 脚本”组件来执行此操作。但是我不知道如何将“训练的最佳模型”（“调整模型超参数”组件的输出）与“执行 python 脚本”组件连接起来。那么，知道如何完成这项任务吗？我将非常感谢您的帮助。
这是我的管道：
训练管道]]></description>
      <guid>https://stackoverflow.com/questions/77827691/how-to-train-and-deploy-ml-models-in-azure-ml-designer-just-using-components</guid>
      <pubDate>Tue, 16 Jan 2024 17:39:49 GMT</pubDate>
    </item>
    <item>
      <title>我在尝试使用 Tensorflow mnist 进行数字识别时遇到的问题</title>
      <link>https://stackoverflow.com/questions/77822681/problem-i-face-while-trying-number-recognition-using-tensorflow-mnist</link>
      <description><![CDATA[在我的 OpenCV 项目中，我的目标是读取数独表，将其划分为单独的单元格，并识别数字。剩下的大部分是数独解决。
我一直在识别数字部分。我决定使用 minst 数据集来训练模型。由于我无法弄清楚的原因，该程序总是识别错误的数字。我将用下面的代码进一步解释。
这是我的识别部分的代码：
(ds_train, ds_test), ds_info = tfds.load(
    &#39;姆尼斯特&#39;,
    split=[&#39;训练&#39;, &#39;测试&#39;],
    shuffle_files=真，
    as_supervised=真，
    with_info=真，
）


def Normalize_img(图像, 标签):
    &quot;&quot;&quot;标准化图像：`uint8` -&gt; `float32`。&quot;&quot;&quot;
    返回 tf.cast(image, tf.float32) / 255., 标签


ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
ds_train = ds_train.cache()
ds_train = ds_train.shuffle(ds_info.splits[&#39;train&#39;].num_examples)
ds_train = ds_train.batch(128)
ds_train = ds_train.prefetch(tf.data.AUTOTUNE)

ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
ds_test = ds_test.batch(128)
ds_test = ds_test.cache()
ds_test = ds_test.prefetch(tf.data.AUTOTUNE)

模型 = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),
    tf.keras.layers.Dense(128, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(10)
]）
模型.编译(
    优化器=tf.keras.optimizers.legacy.Adam(0.001),
    损失=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    指标=[tf.keras.metrics.SparseCategoricalAccuracy()],
）

模型.拟合(
    ds_火车，
    纪元=6，
    验证数据=ds_test，
）
样本 = cv.cvtColor(样本, cv.COLOR_BGR2GRAY)
样本 = cv.resize(样本, (28, 28))

视图图像（样本）
样本 = np.invert(np.array([样本]))

预测 = model.predict(样本)
打印（np.argmax（预测））

样本 = np.invert(np.array([样本])).reshape((28, 28, 1))
cv.imshow(“测试”, 样本)
CV.waitKey(0)

这是我处理之前和之后的图像。
我的图像的第一种形式：

重新缩放至 28x28 后的图像：

模型不断预测我的图像为 3。我不知道这背后的原因。
我尝试实现一个解决方案，其中我训练了尺寸为 300x300 的模型，并将图像转换为 300x300 而不是 28x28，但结果没有改变。
我不知道我是否实施了错误的解决方案，但我希望您能帮助我。
编辑
大小 = 300
(ds_train, ds_test), ds_info = tfds.load(
    &#39;姆尼斯特&#39;,
    split=[&#39;训练&#39;, &#39;测试&#39;],
    shuffle_files=真，
    as_supervised=真，
    with_info=真，
）


def resize_img(图像, 标签):
    返回 tf.image.resize(图像, (尺寸, 尺寸)), 标签


ds_train = ds_train.map(resize_img, num_parallel_calls=tf.data.AUTOTUNE)
ds_test = ds_test.map(resize_img, num_parallel_calls=tf.data.AUTOTUNE)


def Normalize_img(图像, 标签):
    &quot;&quot;&quot;标准化图像：`uint8` -&gt; `float32`。&quot;&quot;&quot;
    返回 tf.cast(image, tf.float32) / 255., 标签


ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
ds_train = ds_train.cache()
ds_train = ds_train.shuffle(ds_info.splits[&#39;train&#39;].num_examples)
ds_train = ds_train.batch(128)
ds_train = ds_train.prefetch(tf.data.AUTOTUNE)

ds_test = ds_test.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)
ds_test = ds_test.batch(128)
ds_test = ds_test.cache()
ds_test = ds_test.prefetch(tf.data.AUTOTUNE)

模型 = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(大小, 大小, 1)),
    tf.keras.layers.Dense(128, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(10)
]）
模型.编译(
    优化器=tf.keras.optimizers.legacy.Adam(0.001),
    损失=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    指标=[tf.keras.metrics.SparseCategoricalAccuracy()],
）

模型.拟合(
    ds_火车，
    纪元=6，
    验证数据=ds_test，
）
样本 = cv.cvtColor(样本, cv.COLOR_BGR2GRAY)
样本 = cv.resize(样本, (大小, 大小))

视图图像（样本）
样本 = np.invert(np.array([样本]))

预测 = model.predict(样本)
打印（np.argmax（预测））

对于 class_index，枚举中的概率（预测[0]）：
    print(f&#39;类 {class_index}: 概率 {prob}&#39;)

样本 = np.invert(np.array([样本])).reshape((大小, 大小, 1))
cv.imshow(“测试”, 样本)
CV.waitKey(0)

这是我编写的用于处理所有 300x300 格式图像的代码。当然，它比 28x28 慢，但我认为它会提高准确性。不幸的是，它没有改变任何东西。]]></description>
      <guid>https://stackoverflow.com/questions/77822681/problem-i-face-while-trying-number-recognition-using-tensorflow-mnist</guid>
      <pubDate>Mon, 15 Jan 2024 22:44:03 GMT</pubDate>
    </item>
    <item>
      <title>System.InvalidOperationException：异步操作尚未完成</title>
      <link>https://stackoverflow.com/questions/62976568/system-invalidoperationexception-the-asynchronous-operation-has-not-completed</link>
      <description><![CDATA[安装管道导致 Ml.net 出现异常。 Fit 不是可等待的，我很困惑为什么会发生这种情况。感谢任何帮助
var model = pipeline.Fit(dataView);
堆栈跟踪
&lt;块引用&gt;
在
System.Threading.Channels.AsyncOperation.ThrowIncompleteOperationException()
在 System.Threading.Channels.AsyncOperation1.GetResult(Int16 token) 在 Microsoft.ML.Transforms.RowShufflingTransformer.Cursor.MoveNextCore() 在 Microsoft.ML.Data.RootCursorBase.MoveNext() 在 Microsoft.ML.Trainers .TrainingCursorBase.MoveNext() 在 Microsoft.ML.Trainers.SdcaTrainerBase3.TrainCore(IChannel ch,
RoleMappedData 数据、LinearModelParameters 预测器、Int32
重量集计数）在
Microsoft.ML.Trainers.StochasticTrainerBase2.TrainModelCore(TrainContext context) 在 Microsoft.ML.Trainers.TrainerEstimatorBase2.TrainTransformer(IDataView
trainSet、IDataView 验证集、IPredictor initPredictor) at
Microsoft.ML.Trainers.TrainerEstimatorBase2.Fit（IDataView 输入）位于 Microsoft.ML.Data.EstimatorChain1.Fit（IDataView 输入）位于
ML.DetectFakeJobPosts.Analyzer.Train() 中
D:\Sources\code-everything\CodeItHere\ML.DetectFakeJobPosts\Program.cs:line
75 在 ML.DetectFakeJobPosts.Program.Main(String[] args) 中
D:\Sources\code-everything\CodeItHere\ML.DetectFakeJobPosts\Program.cs:line
13

管道
 var pipeline = _context.Transforms.Categorical.OneHotEncoding(“ec_title”, “title”)
        .Append(_context.Transforms.Categorical.OneHotEncoding(“ec_location”, “location”))
        .Append(_context.Transforms.Categorical.OneHotEncoding(“ec_department”, “部门”))
        .Append(_context.Transforms.Categorical.OneHotEncoding(“ec_salary_range”, “salary_range”))
        .Append(_context.Transforms.Text.FeaturizeText(“ec_company_profile”, “company_profile”))
        .Append(_context.Transforms.Text.FeaturizeText(“ec_description”, “描述”))
        .Append(_context.Transforms.Text.FeaturizeText(“ec_requirements”, “要求”))
        .Append(_context.Transforms.Text.FeaturizeText(“ec_benefits”, “好处”))
        .Append(_context.Transforms.Categorical.OneHotEncoding(“ec_employment_type”, “employment_type”))
        .Append(_context.Transforms.Categorical.OneHotEncoding(“ec_required_experience”, “required_experience”))
        .Append(_context.Transforms.Categorical.OneHotEncoding(“ec_required_education”, “required_education”))
        .Append(_context.Transforms.Categorical.OneHotEncoding(&quot;ec_industry&quot;, &quot;industry&quot;))
        .Append(_context.Transforms.Categorical.OneHotEncoding(&quot;ec_function&quot;, &quot;function&quot;))

        //从视图中删除不必要的列
        .Append(_context.Transforms.DropColumns(&quot;标题&quot;, &quot;位置&quot;, &quot;部门&quot;, &quot;工资范围&quot;, &quot;公司简介&quot;, &quot;描述&quot;, &quot;要求&quot;, &quot;福利&quot;, &quot; “就业类型”、“所需经验”、“所需教育”、“行业”、“职能”、“远程办公”、“has_company_logo”、“has_questions”))

        //连接特征
        .Append(_context.Transforms.Concatenate(&quot;功能&quot;, &quot;ec_title&quot;, &quot;ec_location&quot;, &quot;ec_department&quot;, &quot;ec_salary_range&quot;, &quot;ec_company_profile&quot;, &quot;ec_description&quot;, &quot;ec_requirements&quot;, &quot; “ec_benefits”、“ec_employment_type”、“ec_required_experience”、“ec_required_education”、“ec_industry”、“ec_function”))
        //设置标签/预测列
        .Append(_context.Transforms.Conversion.ConvertType(“标签”, “欺诈”, DataKind.Boolean))
        //选择一个训练者
        .Append(_context.BinaryClassification.Trainers.SdcaLogisticRegression());

点击此处获取数据集
版本
&lt;块引用&gt;
Ml.net：1.5.1
核心：3.1
]]></description>
      <guid>https://stackoverflow.com/questions/62976568/system-invalidoperationexception-the-asynchronous-operation-has-not-completed</guid>
      <pubDate>Sun, 19 Jul 2020 05:14:17 GMT</pubDate>
    </item>
    <item>
      <title>将复值图像输入神经网络</title>
      <link>https://stackoverflow.com/questions/40672094/feed-a-complex-valued-image-into-neural-network</link>
      <description><![CDATA[我正在努力“学习”一组大约 10 k 的复值输入图像（幅度/相位；实数/图像）与包含 48 个条目的实值输出向量之间的关系。该输出向量不是一组标签，而是一组数字，代表优化给定复值图像的视觉印象的最佳参数。这些参数是由算法生成的。数据中可能存在一些噪声（来自图像和生成参数向量的算法）
这些参数或多或少取决于输入图像的 FFT（快速傅里叶变换）。因此，我正在考虑用 FFT(complexImage) 的 1D 重塑版本为网络（5 个隐藏层，但架构现在不重要）提供数据 - 一些伪代码：
 // 离散化频谱
     obj_ft = fftshift(fft2(对象));
     
     obj_real_2d = 实数(obj_ft);
     obj_imag_2d = imag(obj_ft);
     
     // 将 2D 转换为 1D 行
     obj_real_1d = 重塑(obj_real_2d, 1, []);
     obj_imag_1d = 重塑(obj_imag_2d, 1, []);
     
     
     // 为 1d 对象创建复杂变量并连接
     obj_complx_1d(索引, :) = [obj_real_1d obj_imag_1d];
     
     opt_param_1D(索引, :) = get_opt_param(对象);
     

我想知道是否有更好的方法将复杂值图像输入深度网络。我想避免使用复杂的渐变，因为它并不是真的必要？！我“只是”尝试寻找“黑匣子”插入新图像后输出优化参数。
Tensorflow 获取输入：obj_complx_1d 和输出向量 opt_param_1D 进行训练。]]></description>
      <guid>https://stackoverflow.com/questions/40672094/feed-a-complex-valued-image-into-neural-network</guid>
      <pubDate>Fri, 18 Nov 2016 08:05:23 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 SVC 评分功能</title>
      <link>https://stackoverflow.com/questions/39735235/cant-get-svc-score-function-to-work</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/39735235/cant-get-svc-score-function-to-work</guid>
      <pubDate>Tue, 27 Sep 2016 22:22:08 GMT</pubDate>
    </item>
    </channel>
</rss>