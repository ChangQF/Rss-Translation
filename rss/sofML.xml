<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 08 May 2024 03:16:33 GMT</lastBuildDate>
    <item>
      <title>处理不平衡分类数据的模型</title>
      <link>https://stackoverflow.com/questions/78445468/model-to-handle-imbalanced-categorical-data</link>
      <description><![CDATA[我正在尝试创建出生缺陷数据的分类模型。目标是确定哪些父亲变量与前 5 种出生缺陷最相关。目标变量“缺陷”有 5 个缺陷类别：88、23、16、32、18，并且数据对于缺陷“88”高度不平衡。我的特征也是分类父亲变量，例如父亲的种族、教育程度、出生地、西班牙裔血统。
估计与出生缺陷患病率最相关的特征的最佳方法或模型是什么？
哪种机器学习算法最适合这种场景？]]></description>
      <guid>https://stackoverflow.com/questions/78445468/model-to-handle-imbalanced-categorical-data</guid>
      <pubDate>Tue, 07 May 2024 23:21:16 GMT</pubDate>
    </item>
    <item>
      <title>关于如何创建一种使用机器学习和 Matterbridge 将自杀 Reddit 用户连接到 Crisis Textline 的方法的建议？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78445413/advice-on-how-to-create-a-way-to-use-machine-learning-and-matterbridge-to-connec</link>
      <description><![CDATA[正如标题所示。
我正在寻找一种方法，将可能在精神上挣扎的 Reddit 用户直接连接到 Crisis Textline（他们甚至不必直接向 741741 发送 HOME 短信，这是联系他们的典型方式）。
只是为了提供一些背景信息，我对编程相当陌生（我使用 2D 数组和 P5JS 使用 JavaScript 制作了几个网页游戏，仅此而已）。因此，您认为可能有帮助的任何资源将不胜感激
基本上，我希望首先创建一个开源机器学习模型，该模型能够检测 r/suicidewatch 等子 Reddit 帖子中的自杀意念
（我想我找到了其中一个我可以使用的）：https： //github.com/zeinhasan/Suicidal-Detection-Sentiment-Analysis)
然后有一种方法可以自动向高风险用户发送消息，无论是在用户帖子的评论部分还是通过 DM 直接发送给用户（以效果最佳者为准），询问他们是否愿意直接连接到经过认证的用户员工（Crisis Textline 的人员）并允许他们通过 Reddit 进行对话。
模型检测到阳性 --&gt;消息系统会发出类似“嘿，我可以将您直接连接到训练有素的议员吗？您可以在评论部分[或“在您的 DM 收件箱中”]通过文本进行对话。如果您不想，请输入“否”；如果您愿意，请输入“是”。 （请注意这是一条自动消息）--&gt;如果是的话 --&gt; “谢谢，稍后就会连接到这里” --&gt; ...
我的理由是，如果体验更加无缝，这将增加他们获得所需帮助的可能性。
我正在寻找任何批评、提示、资源、更好的方法、reddit-api-doesn&#39;t-allow-this 或 WhatsApp-api-doesn&#39;t-allow-that 等建议。任何事情，因为此时此刻我正处于盲目状态。
我愿意为信息付费。]]></description>
      <guid>https://stackoverflow.com/questions/78445413/advice-on-how-to-create-a-way-to-use-machine-learning-and-matterbridge-to-connec</guid>
      <pubDate>Tue, 07 May 2024 22:55:26 GMT</pubDate>
    </item>
    <item>
      <title>反向传播中权重按什么顺序更新</title>
      <link>https://stackoverflow.com/questions/78445209/in-what-order-are-weights-updated-in-backpropagation</link>
      <description><![CDATA[假设我有一个像这样的神经网络：
3 个输入节点，
3个隐藏节点，
3个输出节点
我想用反向传播来训练它，假设我已经计算了所有权重的负梯度
但如果我更新 1 个权重，那么负梯度结果就会改变。
如果我先将输入节点 1 的权重更新到隐藏节点 1，会不会是错误的？或者顺序并不重要。
或者我是否必须先更新隐藏层到输出层的权重，然后更新输入层到隐藏层的权重，或者这并不重要
我搜索了这个问题很多次，但总是得到不同的答案。]]></description>
      <guid>https://stackoverflow.com/questions/78445209/in-what-order-are-weights-updated-in-backpropagation</guid>
      <pubDate>Tue, 07 May 2024 21:41:36 GMT</pubDate>
    </item>
    <item>
      <title>如何将 QLoRA 微调的 Llama-3-8B 模型保存在磁盘上并使用它，而无需再次下载基本模型</title>
      <link>https://stackoverflow.com/questions/78445069/how-to-save-qlora-fine-tuned-llama-3-8b-model-on-disk-and-use-it-without-the-nee</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78445069/how-to-save-qlora-fine-tuned-llama-3-8b-model-on-disk-and-use-it-without-the-nee</guid>
      <pubDate>Tue, 07 May 2024 21:08:50 GMT</pubDate>
    </item>
    <item>
      <title>训练网络不兼容的 Seq2Seq 问题</title>
      <link>https://stackoverflow.com/questions/78444834/seq2seq-issue-with-training-network-incompatibility</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78444834/seq2seq-issue-with-training-network-incompatibility</guid>
      <pubDate>Tue, 07 May 2024 20:06:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 AWS Neuron 设置 Poetry/Conda 虚拟环境</title>
      <link>https://stackoverflow.com/questions/78444450/how-to-set-up-poetry-conda-virtual-environment-with-aws-neuron</link>
      <description><![CDATA[有人能够在 AWS Trainium 实例上设置 Poetry 或 Conda 虚拟环境吗？我一直在尝试按照 适用于 Ubuntu 22 和 PyTorch 2.1.2 的 Neuron 安装说明，但我之前一直遇到不兼容版本错误安装neuronx-cc、torch-neuron 和torchvision。
我想我所需要的只是一个工作的project.toml 文件或conda 等效文件。]]></description>
      <guid>https://stackoverflow.com/questions/78444450/how-to-set-up-poetry-conda-virtual-environment-with-aws-neuron</guid>
      <pubDate>Tue, 07 May 2024 18:30:07 GMT</pubDate>
    </item>
    <item>
      <title>需要使用 Rand_forest 和 h2o 进行预测的指导</title>
      <link>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</link>
      <description><![CDATA[我有一个随机森林模型，我正在尝试更好地理解它。
为了举例，假设我们有一片蓝莓灌木丛。我们感兴趣的是预测特定灌木丛中腐烂蓝莓的产量以及各个灌木丛中所有蓝莓的收获量。
每个灌木都有一个识别名称：bush_name，例如&#39;bush001&#39;，我们希望根据每个单独的灌木进行预测。例如，我想知道 Bush025 是否在 2/2/22 生产了腐烂的浆果。
为了本示例，输入位于具有以下虚拟结构的 df 中：
train_data &lt;- data.frame(date = c(&quot;2022-01-01&quot;, &quot;2022-01-07&quot;, &quot;2022-02-09&quot;, &quot;2022-05&quot; -01”、“2022-11-01”、“2022-11-02”)、
                   Bush_name = c(“bush001”、“bush001”、“bush001”、“bush043”、“bush043”、“bush043”),
                   错误 = c(2, 0, 1, 0, 3, 1),
                   有腐烂的浆果 = c(1, 0, 0, 1, 1, 0),
                   浆果计数 = c(12, 1, 7, 100, 14, 4),
                   天气 = c(1, 0, 2, 0, 1, 1))

我已经建立了一个随机森林模型，并进行了以下高级设置：
库(agua)
图书馆（防风草）
图书馆（水）

h2o.init(n线程 = -1)

model_fit &lt;- rand_forest(mtry = 10, trees = 100) %&gt;%
  set_engine(“h2o”) %&gt;%
  set_mode(“分类”) %&gt;%
  适合（has_rotten_berry ~ .,
      数据 = train_data) %&gt;%
  step_dummy(灌木名称) %&gt;%
  step_zv(all_predictors()) %&gt;%
  step_normalize(all_predictors())

训练后我确实收到了这条消息：
警告消息：
在 .h2o.processResponseWarnings(res) 中：
  删除坏列和常量列：[bush_name]。

我想知道的是：
当我尝试预测训练模型中的新数据时，似乎我只能使用我已经训练过的灌木丛的 Bush_names 输入新的测试数据。 我假设该模型正在创建特定于灌木丛的预测是否正确？因此必须在训练中输入新的灌木丛信息才能输出这些新灌木丛的未来预测？
示例：我种植了一棵新灌木，bush700，它不存在于原始训练数据集中。如果我尝试使用新的灌木丛数据进行预测，但训练数据中不存在该数据，则会向我传达一条消息：数据中有新的级别。所以我假设因为这些预测似乎是特定于灌木丛的，并且我们无法为新添加的灌木丛获得任何新的灌木丛预测。
这个假设正确吗？
谢谢您，对于可能令人困惑的隐喻，我深表歉意。也欢迎您对该模型可能有的任何其他反馈。]]></description>
      <guid>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</guid>
      <pubDate>Tue, 07 May 2024 16:58:00 GMT</pubDate>
    </item>
    <item>
      <title>model.fit 对使用 tf.data.experimental.make_csv_dataset 创建的张量流数据集给出错误</title>
      <link>https://stackoverflow.com/questions/78443975/model-fit-gives-error-with-tensorflow-dataset-created-with-tf-data-experimental</link>
      <description><![CDATA[我是张量流新手。我正在尝试从 CSV 文件读取值并将其加载为张量流数据集。但是，当我尝试运行 model.fit 时，它给出以下错误 -
输入“input_39”缺少数据。您传递了一个带有键 [&#39;Age&#39;, &#39;Number&#39;, &#39;Start&#39;] 的数据字典。需要以下键：[&#39;input_39&#39;]
这是我的代码-
将 numpy 导入为 np
将 pandas 导入为 pd
将张量流导入为 tf

input_file=&#39;kyphosis.csv&#39;

all_dataset = tf.data.experimental.make_csv_dataset(input_file,batch_size=1,label_name=“Kyphosis”,num_epochs=1)

模型=tf.keras.models.Sequential()
model.add(tf.keras.layers.Input(3))
model.add(tf.keras.layers.Dense(10))
model.add(tf.keras.layers.Dense(1,activation=&#39;sigmoid&#39;))

model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,run_eagerly=True)

model.fit(all_dataset,epochs=10)

请让我知道我在这里做错了什么。 Tensorflow版本是2.11.0。
我尝试使用 tf.data.Dataset.from_tensor_slices 但遇到相同的错误-
df=pd.read_csv(&#39;kyphosis.csv&#39;)
X=df.drop(&#39;脊柱后凸&#39;,axis=1)
y=df[&#39;脊柱后凸&#39;]

all_dataset=tf.data.Dataset.from_tensor_slices((X.to_dict(orient=&#39;list&#39;),y))
all_dataset = all_dataset.batch(1)

模型=tf.keras.models.Sequential()
model.add(tf.keras.layers.Input(3))
model.add(tf.keras.layers.Dense(10))
model.add(tf.keras.layers.Dense(1,activation=&#39;sigmoid&#39;))

model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;)
model.fit(all_dataset,epochs=3)

错误-
ValueError：输入“input_41”缺少数据。您传递了一个带有键 [&#39;Age&#39;, &#39;Number&#39;, &#39;Start&#39;] 的数据字典。需要以下键：[&#39;input_41&#39;]]]></description>
      <guid>https://stackoverflow.com/questions/78443975/model-fit-gives-error-with-tensorflow-dataset-created-with-tf-data-experimental</guid>
      <pubDate>Tue, 07 May 2024 16:45:38 GMT</pubDate>
    </item>
    <item>
      <title>由于导入，在 python 程序中使用 bash 脚本运行 python 代码时出现高延迟</title>
      <link>https://stackoverflow.com/questions/78442377/high-latency-while-running-python-code-using-bash-script-in-a-python-program-due</link>
      <description><![CDATA[我有一个 python 应用程序，它使用子进程来运行 bash 脚本。 bash 脚本依次运行一个 python 文件，其中包含一些导入（视网膜面部、深层面部库）。该应用程序需要花费大量时间来运行，因为每次运行子进程时，都需要 20-30 秒来加载/导入视网膜/深脸模块。有没有办法可以加快速度？
注意：更改设置是不可能的，即我无法直接从原始 python 代码调用 python 代码。
我不确定如何解决这个问题，感谢任何帮助。谢谢。
我尝试使用系统模块的缓存版本，但这不起作用。虽然，我不确定如何正确使用它。]]></description>
      <guid>https://stackoverflow.com/questions/78442377/high-latency-while-running-python-code-using-bash-script-in-a-python-program-due</guid>
      <pubDate>Tue, 07 May 2024 12:09:10 GMT</pubDate>
    </item>
    <item>
      <title>模型预测的各种组合产生相似的地面事实</title>
      <link>https://stackoverflow.com/questions/78442079/various-combination-of-model-predictions-yields-to-similar-ground-truth</link>
      <description><![CDATA[我有一个模型（3DUnet，回归问题）可以预测值 PD 和 T1，其中 PD 和 T1 是基于输入的 qMRI 输出。根据这些预测，我使用以下公式计算 T1_Weighted_image：Weighted_images = PD (1 - exp(-1 / (T1 + epsilon)))*，其中 epsilon 很小值以防止被零除和 T1=&gt;0 。在训练期间，我用于损失计算的基本事实是 T1_Weighted_groundtruth，但我也有 PD 和 T1 的基本事实值，尽管它们不直接用于损失计算。它们用于确保 PD 和 T1 预测值的正确性。损失是使用 T1_Weighted_predict 和 T1_Weighted_groundtruth 之间的损失函数计算的。
但是，存在各种 PD 或 T1 组合，可以为 T1_Weighted 产生类似的结果。例如，我的模型可能预测 PD 的非常低的值（例如在 CSF 中作为一个明显的例子），而不是预测 T1 的高值（这是正确的答案）。有没有一种方法可以迫使我的模型预测正确的值，或者至少预测（任何）可能的组合？]]></description>
      <guid>https://stackoverflow.com/questions/78442079/various-combination-of-model-predictions-yields-to-similar-ground-truth</guid>
      <pubDate>Tue, 07 May 2024 11:19:19 GMT</pubDate>
    </item>
    <item>
      <title>“管道”对象没有属性“_check_fit_params”</title>
      <link>https://stackoverflow.com/questions/78440449/pipeline-object-has-no-attribute-check-fit-params</link>
      <description><![CDATA[来自 imblearn.over_sampling 导入 SMOTE
从 imblearn.under_sampling 导入 RandomUnderSampler
从 imblearn.pipeline 导入管道

# 定义特征和目标
X = df.drop(&#39;感染&#39;, axis=1)
y = df[&#39;感染&#39;]

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定义重采样策略
over = SMOTE(sampling_strategy=0.5) # 将少数类过采样到多数类的 50%
under = RandomUnderSampler(sampling_strategy=0.8) # 将多数类欠采样至其原始大小的 80%

管道 = 管道(步骤=[(&#39;o&#39;, 上), (&#39;u&#39;, 下)])

# 应用重采样
X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)

# 显示新的类分布
print(“重采样的类分布：”, pd.Series(y_resampled).value_counts())

这是我的代码
这是我遇到的错误
AttributeError Traceback（最近一次调用最后一次）
单元格 In[7]，第 19 行
     16 pipeline = Pipeline(steps=[(&#39;o&#39;, over), (&#39;u&#39;, under)])
     18 # 应用重采样
---&gt; 19 X_resampled, y_resampled = pipeline.fit_resample(X_train, y_train)
     21 # 显示新的班级分布
     22 print(&quot;重采样的类分布：&quot;, pd.Series(y_resampled).value_counts())

文件 ~\anaconda3\Lib\site-packages\imblearn\pipeline.py:372，在 Pipeline.fit_resample(self, X, y, **fit_params)
    第342章
    第343章
    第344章 一个接一个地安装所有变压器/采样器并且
   （...）
    第369章 变形的目标。
    第370章
    第371章
--&gt;第372章
    第373章
    第374章

AttributeError：“管道”对象没有属性“_check_fit_params”

我已经尝试了一切。我的所有包都已更新。我尝试使用的所有方法都在 sklearn 和 imblearn 这两个网站上查看。]]></description>
      <guid>https://stackoverflow.com/questions/78440449/pipeline-object-has-no-attribute-check-fit-params</guid>
      <pubDate>Tue, 07 May 2024 06:12:34 GMT</pubDate>
    </item>
    <item>
      <title>我的独立功能中的字母数字输入 - 错误：ValueError：无法将字符串转换为浮点数：'01232COM002-222'</title>
      <link>https://stackoverflow.com/questions/78436672/alphanumeric-inputs-in-my-independent-feature-error-valueerror-could-not-conv</link>
      <description><![CDATA[我有 2 列，一列是独立的，表示 PART_NO，另一列是相关的，表示数量。
我试图根据特定机器是什么机器来预测其数量。现在的问题是我的 PART_NO 有字母数字字符，例如 01232COM002-222、ABCD/235、GS.612.90-19、123456。
当我使用 RandomForestRegressor 拟合模型时，我得到
&lt;块引用&gt;
错误：无法将字符串转换为浮点型，

我无法用任何内容替换任何斜杠或逗号，因为 PART_NO 是唯一的。
导入 pandas 作为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 GradientBoostingRegressor
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.svm 导入 LinearSVR
从 sklearn. Linear_model 导入 LinearRegression
从sklearn.metrics导入confusion_matrix
从 sklearn.metrics 导入 precision_score
从 sklearn.metrics 导入 f1_score
从 sklearn.metrics 导入分类报告
从 sklearn.model_selection 导入 cross_val_score
从 sklearn.preprocessing 导入 LabelEncoder

文件 = &#39;testData.xlsx&#39;
df = pd.read_excel(文件)
df.head()

print(f&quot;行数 = {df.shape[0]}&quot;)
print(f&quot;列数 = {df.shape[1]}&quot;)

print(&quot;列的数据类型：\n&quot;, df.dtypes)

print(&quot;X 特征和 y 标签&quot;)
X = df[[&#39;PART_NO&#39;]]
y = df[&#39;数量&#39;]
print(&quot;X-特征\n&quot;)
打印（X.head（））
打印（“”）
print(“y 标签”)
打印（y.head（））


X_train、X_test、y_train、y_test = train_test_split(X、y、test_size = 0.3、random_state = 42)
print(&quot;训练大小 = &quot;, X_train.shape)
print(&quot;测试尺寸 = &quot;, X_test.shape)
模型 = RandomForestRegressor()
model.fit(X_train, y_train)

我尝试过LabelEncoding、OneHotEncoding，但不起作用，我尝试过字符串替换，但不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78436672/alphanumeric-inputs-in-my-independent-feature-error-valueerror-could-not-conv</guid>
      <pubDate>Mon, 06 May 2024 12:37:58 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 LSTM 模型预测具有多个特征的一个输出？</title>
      <link>https://stackoverflow.com/questions/72595250/how-to-forecast-one-output-with-multiple-features-by-lstm-model</link>
      <description><![CDATA[我正在处理一些股票时间序列数据，并尝试使用多变量特征预测趋势。下面是我拥有的示例数据集，其中包括不同的技术指标，包括每只股票的移动平均线、抛物线转向指标等。从不同的在线来源来看，他们中的大多数人都用一个特征（例如“平仓”）来预测一只股票。价格一次。我怎样才能利用所有股票的特征来预测一个输出，比如说S&amp;P 的收盘价。我知道这可能无助于提高预测准确性，但我不确定我现在正在训练什么，希望对 LSTM 模型有更多的了解。

基本上，我将整个数据集放入并进行缩放和训练。如何在一列上指定预测？
代码：
scaler = MinMaxScaler(feature_range = (0,1))
缩放特征数据 = 缩放器.fit_transform(特征数据)
X_train, y_train = 训练集[:, :-1], 训练集[:, -1]
X_test, y_test = 测试集[:, :-1], 测试集[:, -1]
X_train = X_train.reshape((X_train.shape[0],1,X_train.shape[1]))
X_test = X_test.reshape((X_test.shape[0],1,X_test.shape[1]))
model_lstm.add(LSTM(50, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))

型号：
model_lstm.add(LSTM(50, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))
model_lstm.add(Dropout(0.2))
model_lstm.add(LSTM(单位=50, return_sequences=True))
model_lstm.add(Dropout(0.2))
model_lstm.add(LSTM(单位=50, return_sequences=True))
model_lstm.add(Dropout(0.2))
model_lstm.add(LSTM(单位=50))
model_lstm.add(Dropout(0.2))
model_lstm.add(密集(单位=1,激活=&#39;relu&#39;))
]]></description>
      <guid>https://stackoverflow.com/questions/72595250/how-to-forecast-one-output-with-multiple-features-by-lstm-model</guid>
      <pubDate>Sun, 12 Jun 2022 19:24:42 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch，切片张量导致 RuntimeError:: 梯度计算所需的变量之一已被就地操作修改：</title>
      <link>https://stackoverflow.com/questions/60869124/pytorch-slicing-tensor-causes-runtimeerror-one-of-the-variables-needed-for-gr</link>
      <description><![CDATA[我用 Pycharm 编写了一个带有 LSTM 单元的 RNN。该网络的特殊性在于，RNN 的输出被输入到积分运算中，并使用 Runge-kutta 进行计算。
集成需要一些输入并提前一步及时传播。为此，我需要沿批量维度对特征张量 X 进行切片，并将其传递给 Runge-kutta。
类 MyLSTM(torch.nn.Module):
    def __init__(self, ni, no, 采样间隔, nh=10, nlayers=1):
        super(MyLSTM, self).__init__()

        self.device = torch.device(&quot;cpu&quot;)
        self.dtype = torch.float
        self.ni = ni
        self.no = 否
        自我.nh = nh
        self.nlayers = nlayers

        self.lstms = torch.nn.ModuleList(
            [torch.nn.LSTMCell(self.ni, self.nh)] + [torch.nn.LSTMCell(self.nh, self.nh) for i in range(nlayers - 1)])
        self.out = torch.nn.Linear(self.nh, self.no)
        self.do = torch.nn.Dropout(p=0.2)
        self.actfn = torch.nn.Sigmoid()
        self.采样间隔 = 采样间隔
        self.scaler_states = 无
        ＃ 选项

    # 整个块的描述
    defforward(self,x,h0,train=False,integrate_ode=True):
        x0 = x.clone().requires_grad_(True)
        hs = x # 启动隐藏状态

        如果 h0 为无：
            h = torch.zeros(hs.shape[0], self.nh, device=self.device)
            c = torch.zeros(hs.shape[0], self.nh, device=self.device)
        别的：
            (h,c) = h0

        # LSTM 单元
        对于范围内的 i(self.nlayers)：
            h, c = self.lstms[i](hs, (h, c))
            如果火车：
                hs = self.do(h)
            别的：
                hs = h

        # 输出层
        # y = self.actfn(self.out(hs))
        y = self.out(hs)

        如果集成代码：
            p = y
            y = self.integrate(x0, p)
        返回 y, (h, c)

    def 积分（自身，x0，p）：
        # 每个间隔 RK4 步
        中号=4
        DT = self.sampling_interval / M
        X = x0
        # X = self.scaler_features.inverse_transform(x0)

            对于范围内的 b(X.shape[0])：
                xx = X[b, :]
                对于范围 (M) 内的 j：
                    k1 = self.ode(xx, p[b, :])
                    k2 = self.ode(xx + DT / 2 * k1, p[b, :])
                    k3 = self.ode(xx + DT / 2 * k2, p[b, :])
                    k4 = self.ode(xx + DT * k3, p[b, :])
                    xx = xx + DT / 6 * (k1 + 2 * k2 + 2 * k3 + k4)
                X_all[b, :] = xx
        返回X_all

    def ode(自身, x0, y):
        # 这里我是一个动态模型


我收到此错误：
RuntimeError：梯度计算所需的变量之一已被就地操作修改：[torch.FloatTensor []]，它是 SelectBackward 的输出 0，版本为 64；预期版本为 63。提示：使用 torch.autograd.set_detect_anomaly(True) 启用异常检测以查找未能计算其梯度的操作。

问题出在操作 xx = X[b, :] 和 p[b,:] 中。我知道，因为我选择批量维度为 1，所以我可以用 xx=X 和 p 替换前面的两个方程，这样就可以了。如何在不丢失梯度的情况下分割张量？]]></description>
      <guid>https://stackoverflow.com/questions/60869124/pytorch-slicing-tensor-causes-runtimeerror-one-of-the-variables-needed-for-gr</guid>
      <pubDate>Thu, 26 Mar 2020 14:06:24 GMT</pubDate>
    </item>
    <item>
      <title>如何设计 Eurisko</title>
      <link>https://stackoverflow.com/questions/2524129/how-to-design-eurisko</link>
      <description><![CDATA[程序 Eurisko 由 Douglas Lenat 在 70 年代末和 80 年代开发。据称，它擅长学习一般模式和启发式方法，并能提高自身的性能。当然，Lenat 从未发布过源代码，并且几乎没有发布有关该程序确切内部工作原理的信息。那么，在没有官方解释的情况下，像 Eurisko 这样的程序将如何设计？当今有哪些开源技术可以使实现更加实用？]]></description>
      <guid>https://stackoverflow.com/questions/2524129/how-to-design-eurisko</guid>
      <pubDate>Fri, 26 Mar 2010 14:52:40 GMT</pubDate>
    </item>
    </channel>
</rss>