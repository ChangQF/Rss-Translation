<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 25 Jan 2024 21:12:09 GMT</lastBuildDate>
    <item>
      <title>在 Cloud Functions 中运行 MobileNetV2</title>
      <link>https://stackoverflow.com/questions/77882843/running-mobilenetv2-in-cloud-functions</link>
      <description><![CDATA[我正在尝试使用 Cloud Functions v2 和 Python 3.11 作为基础架构来获取给定图像的功能。 (张量流==2.15)
由于某种原因，模型在获取预测时没有返回，因此我的函数超时。
我一直在添加更多的 CPU，确切地说是 8 个以及 32GB 内存，但我仍然找不到返回任何结果的方法。
这是我正在执行的代码的一部分：
从 keras.applications 导入 MobileNetV2
从 keras.preprocessing 导入图像
从 keras.applications.mobilenet_v2 导入 preprocess_input

# include_top=False - 排除最终的分类层，专注于提取特征。
# pooling=&#39;avg&#39; - 添加全局平均池化层以将特征图压缩为单个向量（嵌入）。
#weights=&#39;imagenet&#39; - 使用在 ImageNet 上预先训练的权重以实现更好的特征提取。
模型 = MobileNetV2(权重=&#39;imagenet&#39;, include_top=False, pooling=&#39;avg&#39;)

def extract_embeddings(image_url):
  
    响应 = requests.get(image_url)
    响应.raise_for_status()

    img = image.load_img(BytesIO(响应.内容), target_size=(224, 224))

    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, 轴=0)
    img_array = 预处理_输入(img_array)

    嵌入 = model.predict(img_array)
    print(“预测的嵌入”)
    返回 embeddings.flatten()

我在这里有点迷失，所以希望有人能帮忙:)
谢谢
弗兰
我尝试扩展我的资源，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/77882843/running-mobilenetv2-in-cloud-functions</guid>
      <pubDate>Thu, 25 Jan 2024 20:45:38 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn 机器学习 ANN 模型在 Flask API 调用期间未加载 [关闭]</title>
      <link>https://stackoverflow.com/questions/77881808/sklearn-machine-learning-ann-model-not-loading-during-an-flask-api-call</link>
      <description><![CDATA[我有2个Python代码，1个是使用tensorflow和sklearn训练ANN模型。另一种是加载训练好的模型并进行预测。如果我在本地运行它们并将第二段代码作为函数调用，它可以完美地工作并且能够产生预测。
但是，当我尝试公开加载模型并使用 Flask 预测 API 调用的代码时，模型未加载，并且我不断收到有关反序列化的错误消息。
我将代码上传到我的 GitHub 中。如果有人能帮助我对此进行调试，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77881808/sklearn-machine-learning-ann-model-not-loading-during-an-flask-api-call</guid>
      <pubDate>Thu, 25 Jan 2024 17:16:42 GMT</pubDate>
    </item>
    <item>
      <title>将客户输入与词汇列表进行比较并分配正确的 ID [关闭]</title>
      <link>https://stackoverflow.com/questions/77881445/comparing-customer-input-to-a-vocabulary-list-and-assigning-the-right-id</link>
      <description><![CDATA[我正在使用张量流开发机器学习模型。
我有一个预设的词汇列表（即我们系统中的产品名称和描述），我正在尝试在其上训练我的模型
最终目标是从客户那里获取他们对正在列出的“小蓝色靴子”产品的描述的输入。例如，我们的模型能够正确地将输入分类为“鞋类”。
我已经构建了脚本来集成来自张量流的预训练语言模型，但在输入真实的客户数据进行测试之前，我一直坚持在词汇表上训练我的模型的最佳方法。
我想在词汇列表上对其进行训练，因为它非常详细地说明了哪些项目属于某些类别，并且我用于训练和验证的客户数据并未包含词汇列表所考虑的所有可能性。
想知道仅在词汇列表上预训练我的模型，然后将其作为预训练模型集成到新模型中是否最好？是否有人知道另一条最佳路线？]]></description>
      <guid>https://stackoverflow.com/questions/77881445/comparing-customer-input-to-a-vocabulary-list-and-assigning-the-right-id</guid>
      <pubDate>Thu, 25 Jan 2024 16:17:44 GMT</pubDate>
    </item>
    <item>
      <title>“PyTorch Conv2d 错误：预期有 3 个通道，但 [1, 128, 128, 3] 为 128。需要帮助！”</title>
      <link>https://stackoverflow.com/questions/77881247/pytorch-conv2d-error-expected-3-channels-got-128-for-1-128-128-3-help-n</link>
      <description><![CDATA[我在使用 PyTorch 卷积神经网络时遇到问题。我收到的错误消息是：
给定 groups=1，权重大小为 [8, 3, 5, 5]，预期输入 [1, 128, 128, 3] 有 3 个通道，但实际有 128 个通道
上下文：
模型架构：
导入 torch.nn 作为 nn
导入 torch.nn.function 作为 F

CNN 类（nn.Module）：
    def __init__(自身):
        超级（CNN，自我）.__init__()
        self.cnn_model = nn.Sequential(
        nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 5),
        nn.Tanh(),
        nn.AvgPool2d(kernel_size = 3, stride = 5),
        nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 5),
        nn.Tanh(),
        nn.AvgPool2d(kernel_size = 2, stride = 5))
        
        self.fc_model = nn.Sequential(
        nn.Linear（输入特征= 256，输出特征= 120），
        nn.Tanh(),
        nn.Linear(in_features = 120, out_features = 84),
        nn.Tanh(),
        nn.Linear(in_features = 84, out_features = 1))
        
    def 前向（自身，x）：
        x = self.cnn_model(x)
        x = x.view(x.size(0), -1)
        x = self.fc_model(x)
        x = F.sigmoid(x)
        
        返回x

数据加载：
类 MRI（数据集）：
    def __init__(自身):
        # 加载图像和标签
        肿瘤=[]
        path_tumor = &#39;/kaggle/input/brain-tumor/Dataset/Yes_Data/*.jpg&#39;
        对于 glob.iglob(path_tumor) 中的 f：
            img = cv2.imread(f)
            img = cv2.resize(img, (128, 128), 插值=cv2.INTER_AREA)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            肿瘤.append(img)

        健康=[]
        path_healthy = &#39;/kaggle/input/brain-tumor/Dataset/No_data/*.jpg&#39;
        对于 glob.iglob(path_healthy) 中的 f：
            img = cv2.imread(f)
            img = cv2.resize(img, (128, 128), 插值=cv2.INTER_AREA)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            健康的.append(img)

        # 将列表转换为 numpy 数组
        健康 = np.array(健康)
        肿瘤 = np.array(肿瘤)
        
        # 创建标签
        tumor_label = np.ones(tumor.shape[0], dtype=np.float32)
        health_label = np.zeros(healthy.shape[0], dtype=np.float32)

        # 连接图像和标签
        images = np.concatenate((肿瘤，健康)，轴=0)
        标签 = np.concatenate((tumor_label,healthy_label), axis=0)
        self.images = 图像
        self.labels = 标签

    def __getitem__(自身，索引)：
        样本 = {&#39;image&#39;: self.images[index], &#39;label&#39;: self.labels[index]}
        返回样品

    def __len__(自身):
        返回 self.images.shape[0]

    def 标准化（自身）：
        self.images = (self.images / 255.0).astype(np.float32)

错误上下文：
model.eval()
输出 = []
y_true = []

使用 torch.no_grad()：
    对于数据加载器中的示例：
        对于范围内的 i(sample[&#39;image&#39;].size(0))：
            图像 = 样本[&#39;图像&#39;][i].squeeze().to(device).float()
            标签 = 样本[&#39;标签&#39;][i].to(设备)

            y_hat = 模型（图像）
            输出.append(y_hat.cpu().detach().numpy())
            y_true.append(label.cpu().detach().numpy())


我已经尝试了所有调试方法，打印并检查形状]]></description>
      <guid>https://stackoverflow.com/questions/77881247/pytorch-conv2d-error-expected-3-channels-got-128-for-1-128-128-3-help-n</guid>
      <pubDate>Thu, 25 Jan 2024 15:46:44 GMT</pubDate>
    </item>
    <item>
      <title>在机器学习中使用日期时间</title>
      <link>https://stackoverflow.com/questions/77881238/using-datetime-in-machine-learning</link>
      <description><![CDATA[我有一个具有各种功能的 pandas 数据集，包括日期时间功能。
它看起来像这样：
&lt;前&gt;&lt;代码&gt; DD SSCL1 SEG_CLASS_CODE FCLCLD PASS_BK SA AU DTD DAY_OF_YEAR
0 2018-01-01 C C 1 0 0 18 -1 1
1 2018-01-01 C C 0 0 7 26 -1 1
2 2018-01-01 C C 0 0 9 18 -1 1
3 2018-01-01 C C 1 10 0 18 -1 1
4 2018-01-01 C C 0 9 1 18 -1 1

我需要使用DD列来训练模型。问题是如何对这一列进行编码？
我无法使用循环特征编码，如下所述：
如何处理机器学习数据预处理中的日期变量- 处理
因为在我教授模型的领域，2020 年与 2018 年不同，2022 年 2 月也不是 2023 年 2 月。因此，年、月和日有时会有所不同。
我的想法是以某种方式将日期时间转换为整数。例如，要获取总天数、小时数、分钟数或秒数，但我不知道起点（也许像往常一样是 1970 年 1 月 1 日）。
最简单的使用方法：dataset[&#39;DD&#39;]).apply(lambda x: x.value)，所以我会得到这样的结果：
&lt;前&gt;&lt;代码&gt;0 1514764800000000000
1 1514764800000000000
2 1514764800000000000
3 1514764800000000000
4 1514764800000000000
                  ...
1450583 1577577600000000000
1450584 1577664000000000000
1450585 1577664000000000000
1450586 1577145600000000000
1450587 1577232000000000000
名称：DD，长度：1450588，数据类型：int64

之后我想使用 MinMaxScaler 或 Standardscaler。
有没有办法根据我的要求对日期时间进行编码？]]></description>
      <guid>https://stackoverflow.com/questions/77881238/using-datetime-in-machine-learning</guid>
      <pubDate>Thu, 25 Jan 2024 15:45:18 GMT</pubDate>
    </item>
    <item>
      <title>在 Pytorch 中分析给定模型的所有层</title>
      <link>https://stackoverflow.com/questions/77880408/profile-all-layers-of-a-given-model-in-pytorch</link>
      <description><![CDATA[我正在学习使用 Pytorch profiler (https://pytorch.org/ Tutorials/recipes/recipes/profiler_recipe.html）来分析不同的模型。
它与示例配合得非常好。但是当我尝试不同的模型时，输出并不是我所期望的。
我想获取不同层（q_proj、k_proj、v_proj、softmax 等）所花费的时间。查看模型的代码（使用 https://github.com/kingoflolz/mesh -transformer-jax），这些层被定义为普通的pytorch层（nn.Linear（self.embed_dim，self.embed_dim，bias=False），nn.function.softmax等）。
在此类模型中如何使用 Pytorch 的正确方法？我需要修改模型吗？
例如，当使用 Pytorch profiler 与模型 GPT-J 时（来自 https:// Huggingface.co/docs/transformers/model_doc/gptj），我得到以下输出，其中没有显示任何层，但显示其他辅助功能：
&lt;前&gt;&lt;代码&gt;------------------------ ------------ ---------- -- ------------ ------------ ------------ ------------
                  名称 自身 CPU % 自身 CPU CPU 总计 % CPU 总 CPU 时间 平均调用次数
---------------------- ------------ ------------ ---- -------- ------------ ------------ ------------
               正向 90.29% 558.000us 94.34% 583.000us 583.000us 1
           aten::零 5.02% 31.000us 5.66% 35.000us 35.000us 1
          aten::解绑 1.62% 10.000us 2.43% 15.000us 15.000us 1
          aten::分离 0.49% 3.000us 1.29% 8.000us 8.000us 1
          aten::选择 0.65% 4.000us 0.81% 5.000us 5.000us 1
                分离 0.81% 5.000us 0.81% 5.000us 5.000us 1
           aten::空 0.65% 4.000us 0.65% 4.000us 2.000us 2
           aten::zero_ 0.16% 1.000us 0.16% 1.000us 1.000us 1
      aten::as_strided 0.16% 1.000us 0.16% 1.000us 1.000us 1
              aten::至 0.16% 1.000us 0.16% 1.000us 1.000us 1
    aten::resolve_conj 0.00% 0.000us 0.00% 0.000us 0.000us 1
     aten::resolve_neg 0.00% 0.000us 0.00% 0.000us 0.000us 1
---------------------- ------------ ------------ ---- -------- ------------ ------------ ------------
自CPU时间总计：618.000us

我使用的代码是：
导入火炬
导入 torchvision.models 作为模型
从 torch.profiler 导入配置文件、record_function、ProfilerActivity

从 Transformer 导入 AutoModelForCausalLM、AutoTokenizer

模型 = AutoModelForCausalLM.from_pretrained(“EleutherAI/gpt-j-6B”)
tokenizer = AutoTokenizer.from_pretrained(“EleutherAI/gpt-j-6B”)

Prompt = (“令人震惊的发现，科学家发现了一群生活在偏远地区的独角兽，”
           “安第斯山脉中以前未经探索的山谷。更令人惊讶的是“
           “研究人员发现独角兽能说一口流利的英语。”
        ）

input_ids = tokenizer(提示, return_tensors=“pt”).input_ids
gen_tokens = model.generate(input_ids,
                            do_sample=真，
                            温度=0.9，
                            最大长度=100)

将 profile(activities=[ProfilerActivity.CPU], record_shapes=True) 作为教授：
    使用 record_function(“forward”)：
       gen_text = tokenizer.batch_decode(gen_tokens)[0]


print(prof.key_averages().table(sort_by=“cpu_time_total”, row_limit=100))

print(&quot;-----按输入形状分组&quot;)
print(prof.key_averages(group_by_input_shape=True).table(sort_by=“cpu_time_total”, row_limit=10))

prof.export_chrome_trace(“trace.json”)
]]></description>
      <guid>https://stackoverflow.com/questions/77880408/profile-all-layers-of-a-given-model-in-pytorch</guid>
      <pubDate>Thu, 25 Jan 2024 13:38:21 GMT</pubDate>
    </item>
    <item>
      <title>我从头开始构建了我的神经网络，但它没有按预期学习</title>
      <link>https://stackoverflow.com/questions/77880094/i-built-my-nn-from-scratch-but-it-is-not-learning-as-expected</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77880094/i-built-my-nn-from-scratch-but-it-is-not-learning-as-expected</guid>
      <pubDate>Thu, 25 Jan 2024 12:46:29 GMT</pubDate>
    </item>
    <item>
      <title>SHAP特征选择[关闭]</title>
      <link>https://stackoverflow.com/questions/77879894/shap-feature-selection</link>
      <description><![CDATA[形状特征选择是通过计算形状值并将特征重要性最低的特征一一剔除来进行的。
先求特征重要性，去掉重要性最低的特征，然后再求特征重要性，一一去掉最低的特征，这样正确吗？
以ROC-AUC分数作为衡量指标，该值反复下降和上升。所以，我想知道根据最初获得的特征重要性（无需再次计算特征重要性）按照重要性最低的顺序将它们一一删除是否正确。
xgb.fit(X_train, y_train)
解释器_xgb = shap.TreeExplainer(xgb)
shap_values_xgb = 解释器_xgb(X_test)

df_shap_values_xgb = pd.DataFrame(data = shap_values_xgb.values, columns=X_test_xgb.columns)
df_feature_importance_xgb = pd.DataFrame(columns=[&#39;feature&#39;,&#39;importance&#39;])
对于 df_shap_values_xgb.columns 中的 col_xgb：
    important_xgb = df_shap_values_xgb[col_xgb].abs().mean()
    df_feature_importance_xgb.loc[len(df_feature_importance_xgb)] = [col_xgb,importance_xgb]
df_feature_importance_xgb = df_feature_importance_xgb11.sort_values(&#39;重要性&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/77879894/shap-feature-selection</guid>
      <pubDate>Thu, 25 Jan 2024 12:14:10 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用 FastAI 预测图像数据时出现断言错误</title>
      <link>https://stackoverflow.com/questions/77877552/assertionerror-when-trying-to-predict-image-data-with-fastai</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77877552/assertionerror-when-trying-to-predict-image-data-with-fastai</guid>
      <pubDate>Thu, 25 Jan 2024 04:31:05 GMT</pubDate>
    </item>
    <item>
      <title>梯度消失会导致“没有为任何变量提供梯度”</title>
      <link>https://stackoverflow.com/questions/77870522/can-vanishing-gradients-cause-no-gradients-provided-for-any-variable</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77870522/can-vanishing-gradients-cause-no-gradients-provided-for-any-variable</guid>
      <pubDate>Wed, 24 Jan 2024 04:01:23 GMT</pubDate>
    </item>
    <item>
      <title>多种产品的预测模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77857775/forecasting-model-for-multiple-products</link>
      <description><![CDATA[嗨，我是数据科学的一个相对较新的人，我有一个时间序列问题，我必须预测 100 多种产品的销售，并且所有产品都有不同的模式，而且新产品会不断添加，这很困难要单独建模它们，我还必须设置再训练流程，如何简化这个过程，有没有办法概括模型选择、验证和再训练，而不必每次都单独建模？
我的问题陈述是，当产品的销售数据上传时，我必须实时训练模型并给出预测，如何自动化此过程，而无需手动清理数据、处理缺失值和异常值、选择建模和调整超参数？]]></description>
      <guid>https://stackoverflow.com/questions/77857775/forecasting-model-for-multiple-products</guid>
      <pubDate>Mon, 22 Jan 2024 05:19:57 GMT</pubDate>
    </item>
    <item>
      <title>处理各种顺序数据[关闭]</title>
      <link>https://stackoverflow.com/questions/77776794/handling-varied-sequential-data</link>
      <description><![CDATA[我是数据科学新手，致力于根据文本、选项卡索引和选项卡位置预测文档中的选项卡位置。 “制表符索引”（例如，[2,15]）表示特定索引处的制表符，而“制表符位置”（例如，[(1.25, 0), (2.5, 1)]）表示它们的位置和类型。这意味着第二个索引上的第一个标签位于 1.25 厘米，类型 0 表示左（缩进）标签，第二个标签位于 2.5 厘米，类型表示右标签。段落中可能有多个或没有与选项卡索引相关的选项卡，并且它们本质上是连续的。

&lt;表类=“s-表”&gt;
&lt;标题&gt;

段落样式
字体名称
标签索引
段落文本
标签位置


&lt;正文&gt;

问题
Arial 窄体
NaN
银行的纳税风险率是多少
NaN


回答
Arial 窄体
NaN
给定\r
NaN


回答
Arial 窄体
[0, 10]
\t已付税款\t=卢比。 10 亿 = 卢比。 10 亿...
[(2.95, 0)]


回答
Arial 窄体
[0, 19]
\t税前收入\t=卢比。 40亿\r
[(2.95, 0)]


回答
Arial 窄体
[0, 1]
\t\t= = 0.25 或 25%\r
[(2.95, 0)]


问题
Arial 窄体
NaN
假设 ABC Bank Ltd. 借出卢比。 5亿...
NaN


回答
Arial 窄体
[0, 16]
\t利息收入\t=卢比。 5亿
[(3.4, 0)]


回答
Arial 窄体
[0, 17]
\t资本费用\t=卢比。 5亿
[(3.4, 0)]


回答
Arial 窄体
[0, 24]
\t利息收入税\t=（5215万卢比...
[(3.4, 0)]


回答
Arial 窄体
[0, 1]
\t\t= 卢比。 1414.5 万 \r [(3.4, 0)]
[(3.4, 0)]




我尝试使用 spacy 更改将文本预处理为 np.array 并将其输入网络，但困难在于呈现选项卡索引和选项卡位置，因为它们不一致（意味着某些段落中可能有多个选项卡，但没有在其他人中）并且它们彼此相关。
问题：
数据表示：如何构建数据（段落文本、选项卡索引、选项卡位置）以输入到预测模型？
模型选择：哪种模型架构或方法最适合预测这些连续且变化的数据中的选项卡位置？
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77776794/handling-varied-sequential-data</guid>
      <pubDate>Mon, 08 Jan 2024 05:43:35 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入张量流模型的 pyinstaller 转换为可执行文件，但预测和预测图像未显示</title>
      <link>https://stackoverflow.com/questions/76063824/converting-to-executable-using-pyinstaller-having-tensorflow-model-embeded-but-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76063824/converting-to-executable-using-pyinstaller-having-tensorflow-model-embeded-but-p</guid>
      <pubDate>Thu, 20 Apr 2023 12:01:37 GMT</pubDate>
    </item>
    <item>
      <title>如何给出整数列表作为 Tensorflow 数据集中的输入？</title>
      <link>https://stackoverflow.com/questions/65270127/how-to-give-a-list-of-integers-as-input-in-tensorflow-dataset</link>
      <description><![CDATA[我们正在尝试使用张量流微调/训练预训练的 RoBERTa 模型。为此，我们必须从数据帧创建一个 tf.data.Dataset。
数据框如下所示：

其中三个选项都是编码字符串，答案是一个整数，对应选项 A、B 或 C。
我们尝试使用以下方法创建 tf.dataset：
features= [&#39;选项A&#39;, &#39;选项B&#39;, &#39;选项C&#39;]

训练数据集 = (
    tf.data.Dataset.from_tensor_slices(
        （
            tf.cast(train_data[特征].values, tf.float32),
            tf.cast(train_data[&#39;答案&#39;].values, tf.int32)
        ）
    ）
）

但是这不起作用，因为我们收到以下错误：
ValueError：无法将 NumPy 数组转换为张量（不支持的对象类型列表）。

我读到我们不能将列表用作 tf.dtype，我们现在在其中放置了“float32”。但我们也无法将数据框中的列表转换为浮点数。
我们如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/65270127/how-to-give-a-list-of-integers-as-input-in-tensorflow-dataset</guid>
      <pubDate>Sat, 12 Dec 2020 21:44:39 GMT</pubDate>
    </item>
    <item>
      <title>什么是逻辑？ softmax 和 softmax_cross_entropy_with_logits 有什么区别？</title>
      <link>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</link>
      <description><![CDATA[在 tensorflow API 文档中，他们使用名为 logits 的关键字。它是什么？很多方法都是这样写的：
tf.nn.softmax(logits, name=None)

如果logits只是一个通用的Tensor输入，为什么它被命名为logits？
&lt;小时/&gt;
其次，下面两种方法有什么区别？
tf.nn.softmax(logits, name=None)
tf.nn.softmax_cross_entropy_with_logits（logits，标签，名称=无）

我知道 tf.nn.softmax 的作用，但不知道另一个。一个例子真的很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</guid>
      <pubDate>Sat, 12 Dec 2015 14:03:27 GMT</pubDate>
    </item>
    </channel>
</rss>