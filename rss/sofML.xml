<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 27 Apr 2024 15:13:23 GMT</lastBuildDate>
    <item>
      <title>如何访问和更新 LSTM 层的权重？</title>
      <link>https://stackoverflow.com/questions/78394601/how-to-access-and-update-the-weight-of-the-lstm-layer</link>
      <description><![CDATA[我使用 Tensorflow 2.17 版本构建了混合 CNN 和 LSTM 模型。我想向 LSTM 添加反向传播调整来修改 LSTM 层的权重。我尝试找到一种方法来访问权重进行计算并在 LSTM 训练期间更新权重。我做了一些研究，他们手动构建 LSTM，而不是应用 TensorFlow API。我只是好奇是否有一种方法可以获取权重，然后应用导数，最后在训练时进行更新。
这是我的模型：
 model_cnn = tf.keras.models.Sequential([
        tf.keras.layers.Conv1D(input_shape = input_data_shape,
                               过滤器=256，
                               内核大小=3，
                               激活=&#39;线性&#39;，
                               步幅=1，
                               填充=“因果”），
        tf.keras.layers.MaxPooling1D(pool_size=2),
        tf.keras.layers.Conv1D（过滤器=128，
                               内核大小=3，
                               激活=&#39;线性&#39;，
                               步幅=1，
                               填充=“因果”），
        tf.keras.layers.MaxPooling1D(pool_size=2),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.LSTM(16,return_sequences=True),
        tf.keras.layers.LSTM(8,return_sequences=True),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1)
    ]）
    返回 model_cnn


我的期望是在混合 CNN 和 LSTM 模型的训练期间访问权重并更新权重。]]></description>
      <guid>https://stackoverflow.com/questions/78394601/how-to-access-and-update-the-weight-of-the-lstm-layer</guid>
      <pubDate>Sat, 27 Apr 2024 10:01:25 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Python读取图像中的七段显示和徽标？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78393841/how-to-read-seven-segment-display-and-logos-in-images-using-python</link>
      <description><![CDATA[我有一堆能量计的照片。在每张照片中，仪表上都写有信息，还有一个七段显示屏，读数以千瓦时为单位。另外，还有仪表制造商的标志。我想提取电表序列号、电表制造商、电表读数（以 kWh 为单位）（7 段显示）等信息。
我使用 easyocr 模块来检测文本，并使用它来提取电表序列号，但对于 kWh 读数，easyocr 无法检测数字。
目前我有2个要求，一是从7段显示器中检测数字，二是从仪表中的徽标符号检测制造商。只有 2-3 个不同的制造商，所以我只需要根据 2-3 个徽标进行培训。但我不知道该怎么做。
任何有关步骤步骤的帮助或指导将不胜感激。
我尝试过谷歌搜索、YouTube 搜索，但没有得到任何相同的路线图。我尝试过其他 ocr 模块，例如 tesseract，但也失败了。]]></description>
      <guid>https://stackoverflow.com/questions/78393841/how-to-read-seven-segment-display-and-logos-in-images-using-python</guid>
      <pubDate>Sat, 27 Apr 2024 04:51:39 GMT</pubDate>
    </item>
    <item>
      <title>推理时得到奇怪的输出图像</title>
      <link>https://stackoverflow.com/questions/78393745/getting-weired-output-image-on-inference</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78393745/getting-weired-output-image-on-inference</guid>
      <pubDate>Sat, 27 Apr 2024 03:51:08 GMT</pubDate>
    </item>
    <item>
      <title>我想从 pdf 中提取图像及其标题，并将这些带有标题的图像保存在 blob 存储中[关闭]</title>
      <link>https://stackoverflow.com/questions/78392387/i-want-to-extract-the-images-and-its-caption-from-the-pdf-and-save-those-images</link>
      <description><![CDATA[如何从 pdf 中提取图像及其标题并将这些带有标题的图像保存在 blob 存储中？我正在考虑我在 pdf 列表中的 20-30 pdf 上训练的对象检测模型。将 pdf 每页的转换图像传递给模型并获取边界框。但不管这是否有效。
下面是我的 pdf 图像的示例屏幕截图，没有硬性规则要求所有图像都将位于特定页面上，它也可能会有所不同。

我还想提取图像中的标题并仅保存带有此标题的图像。
我订阅了顶点 AI，因此如果我可以从中使用任何优势，请告诉我。]]></description>
      <guid>https://stackoverflow.com/questions/78392387/i-want-to-extract-the-images-and-its-caption-from-the-pdf-and-save-those-images</guid>
      <pubDate>Fri, 26 Apr 2024 18:23:15 GMT</pubDate>
    </item>
    <item>
      <title>检查给定图像是否是另一个更大图像的裁剪</title>
      <link>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</link>
      <description><![CDATA[我有一些图片。其中一些图像是裁剪版本。
就像这里是原始图片大图
和裁剪后的图像小图像。
请注意，图像的形状（分辨率）不相同。
我有几双这样的。原始图像保存在一个文件夹中，裁剪后的图像保存在另一个文件夹中。
最终我想从这些图像中找到原始图像和裁剪图像对。
所以我想迭代这两个文件夹中的图像，并检查裁剪后的图像是否是更大图像的一部分。
但是我找不到任何算法可以用不同形状（分辨率）的图像给出这样的结果。
我已经尝试过cv2.matchTemplate和skimage.metrics.structural_similarity
但它们仅适用于形状（分辨率）相似的图像。]]></description>
      <guid>https://stackoverflow.com/questions/78389839/check-if-the-given-image-is-a-crop-of-another-bigger-image</guid>
      <pubDate>Fri, 26 Apr 2024 10:32:29 GMT</pubDate>
    </item>
    <item>
      <title>识别图像中红色粒子占据的像素</title>
      <link>https://stackoverflow.com/questions/78387055/identify-pixels-occupied-by-red-particles-in-image</link>
      <description><![CDATA[我有一些塑料颗粒和水波实验的图像。目标是自动识别塑料颗粒。它们有时会重叠，我不需要找到单个粒子，找到那些包含塑料的像素就足够了。
由于粒子是红色的，并且背景大多是白色或黑色，我想我可以进行简单的阈值处理，如果R &gt; &gt;，则说像素是塑料。 5*B 和 R&gt; 0.25，其中 R 和 B 是红色和蓝色通道。然而，不同实验之间的曝光差异很大，有时在实验中，当部分表面被水覆盖时，所以我的方法不能非常一致地工作，有时会错误地识别侧面的黑色裂缝。
我想知道还有什么其他选择。我对神经网络的经验有限，所以我不确定这是否可行（需要付出合理的努力）。特别是，我认为形状不会有太大帮助，因为粒子靠近在一起并且部分重叠，它们之间的对比度很差，但也许颜色就足够了？
示例图像：


]]></description>
      <guid>https://stackoverflow.com/questions/78387055/identify-pixels-occupied-by-red-particles-in-image</guid>
      <pubDate>Thu, 25 Apr 2024 20:14:01 GMT</pubDate>
    </item>
    <item>
      <title>使用注释数据进行图像分类</title>
      <link>https://stackoverflow.com/questions/78386605/image-classification-using-annotated-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78386605/image-classification-using-annotated-data</guid>
      <pubDate>Thu, 25 Apr 2024 18:31:50 GMT</pubDate>
    </item>
    <item>
      <title>在数据分割过程中保留数据的空间分布</title>
      <link>https://stackoverflow.com/questions/78383883/preserving-spatial-distribution-of-data-during-data-splitting</link>
      <description><![CDATA[我正在尝试使用随机森林模型来模拟德国巴伐利亚河流中的硝酸盐浓度。我使用 Python，主要使用 sklearn。我有 490 个水质站的数据。我遵循 LongzhuQ.Shen 等人论文中的方法，该论文可以在这里找到：https://www.nature.com/articles/s41597-020-0478-7
我想将数据集分成训练集和测试集，以便两个集中数据的空间分布相同。这个想法是，如果数据分割忽略空间分布，则训练集可能最终会集中来自人口稠密区域的点，而忽略稀疏区域。这可能会扭曲模型的学习过程，使其在整个感兴趣领域的准确性或概括性降低。 sklearn train_test_split只是将数据随机划分为训练集和测试集，并且不考虑数据中的空间模式。
我上面提到的论文遵循了这种方法：“我们将完整的数据集分为两个子数据集，分别是训练和测试。为了考虑监测站空间分布的异质性，我们在数据分割步骤中采用了空间密度估计技术，通过使用带宽为 50 km 的高斯核（使用 GRASS GIS33 中可用的 v.kernel）构建密度表面来计算每个物种和季节。所得密度表面的像素值用作权重因子，将数据分成具有相同空间分布的训练和测试子集。”
我想遵循相同的方法，但我不使用草地 GIS，而是自己用 Python 构建密度表面。我还提取了概率密度值和站点的权重。 （附图）
现在我面临的唯一问题是如何使用这些权重将数据分成训练集和测试集？我检查了sklearn train_test_split函数中没有可以考虑权重的关键字。我也与GPT 4聊天来回，但它也无法给我一个明确的答案。我在互联网上也没有找到任何关于此的具体信息。也许我错过了一些东西。
还有其他函数可以用来执行此操作吗？或者我必须编写自己的算法来进行分割？如果是后者，您能否建议我一种方法，以便我自己编写代码？
在附图中您可以看到站点的位置以及使用核密度估计方法（使用高斯核）生成的概率密度面。
还附上我的数据框的屏幕截图，让您了解数据结构。 （经度（‘lon’）列之后的所有列都用作特征。NO3 列用作目标变量。）
请查找附件图片以供参考。
使用高斯核的核密度估计方法生成的概率密度曲面。&lt; /p&gt;
我用来模拟硝酸盐浓度的数据集]]></description>
      <guid>https://stackoverflow.com/questions/78383883/preserving-spatial-distribution-of-data-during-data-splitting</guid>
      <pubDate>Thu, 25 Apr 2024 10:10:26 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：输入 X 包含 NaN。 SVR 不接受原生编码为 NaN 的缺失值</title>
      <link>https://stackoverflow.com/questions/78378560/valueerror-input-x-contains-nan-svr-does-not-accept-missing-values-encoded-as</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78378560/valueerror-input-x-contains-nan-svr-does-not-accept-missing-values-encoded-as</guid>
      <pubDate>Wed, 24 Apr 2024 12:44:18 GMT</pubDate>
    </item>
    <item>
      <title>训练 DL 模型时，本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束</title>
      <link>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</link>
      <description><![CDATA[我正在创建一个植物病害识别模型。我有一个包含 38 种疾病的数据集，每种疾病有大约 2000 张图像。但是在训练模型时，由于一些 OUT_OF_RANGE 错误，一些时期被跳过。有人可以帮我解决这个问题吗？
导入操作系统
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、展平、密集、输入

train_dir = &#39;数据集/火车&#39;
valid_dir = &#39;数据集/有效&#39;
批量大小 = 32

train_datagen = 图像数据生成器(
    重新缩放=1./255，
    旋转范围=40，
    width_shift_range=0.2，
    height_shift_range=0.2，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真，
    fill_mode=&#39;最近&#39;
）

valid_datagen = ImageDataGenerator(重新缩放=1./255)

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

valid_generator = valid_datagen.flow_from_directory(
    有效目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

模型=顺序（[
    输入(形状=(150, 150, 3)),
    Conv2D(32, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    展平（），
    密集（512，激活=&#39;relu&#39;），
    Dense(38,activation=&#39;softmax&#39;) # 根据疾病类别的数量调整输出单位
]）

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=10，
    验证数据=有效生成器，
    validation_steps=valid_generator.samples //batch_size
）

model.save(&#39;plant_disease_model.h5&#39;)

class_indices = train_generator.class_indices
疾病名称 = 列表(class_indices.keys())
print(“类索引到疾病名称的映射：”, class_indices)

终端：
找到属于 38 个类别的 70295 个图像。
找到属于 38 个类别的 17572 张图像。
2024-04-23 19：50：32.085744：我tensorflow / core / platform / cpu_feature_guard.cc：210]此TensorFlow二进制文件经过优化以使用可用的CPU仪器
性能关键操作中的操作。
要启用以下指令：AVX2 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
纪元 1/10
\.venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.p
y：120：用户警告：您的“PyDataset”类应在其构造函数中调用“super().__init__(**kwargs)”。 `**kwargs` 可以包括 `workers`、`use_m
ultiprocessing`、`max_queue_size`。不要将这些参数传递给“fit()”，因为它们将被忽略。
  self._warn_if_super_not_used()
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m905s←[0m 411ms/步]]准确度：0.4608 - 损失：1.8737 - val_accuracy：0.7432 - val_
损失：0.8556
纪元 2/10
←[1m 1/2196←[0m ←[37m–––––––––––––––––––←[0m ←[1m12:02←[0m 329ms/步 - 精度: 0.6875] -损失：0.78202024-04-23 20:05:37.996528：W张量
ow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束
         [[{{节点It​​eratorGetNext}}]]
C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py:155: UserWarning: 您的输入数据不足；中断训练。嘛
确保您的数据集或生成器至少可以生成“steps_per_epoch * epochs”批次。您可能需要使用`.repeat()`函数
构建您的数据集。
  self.gen.throw（类型，值，回溯）
2024-04-23 20:05:38.068817：W tensorflow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：结束
顺序
         [[{{节点It​​eratorGetNext}}]]
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m0s←[0m 49us/步]]准确度：0.6875 - 损失：0.7820 - val_accuracy：0.7500 - val_los
秒：0.2462

如上所示，epoch 1 已成功完成，但 epoch 2 由于某些错误而终止。同样，epoch 3、5、7、9 成功完成，但 epoch 4、6、8、10 出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</guid>
      <pubDate>Wed, 24 Apr 2024 06:27:20 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 的神经网络 NarX 模型</title>
      <link>https://stackoverflow.com/questions/78374854/neural-network-narx-model-with-python</link>
      <description><![CDATA[我正在尝试使用 Python 编写 NarX 模型代码。当我运行以下代码时，出现以下错误。我该如何解决这个错误？这个错误是什么意思？我相信问题出在我正在使用的数据集格式上，因为它适用于另一个数据集。我添加了来自 kaagle 数据集的示例。

这也是我的代码和错误消息：
inpt = all_data[[“category”,“cuisine”,“checkout_price”,“center_type”,“num_orders”,“city_code”]]
inpt = pd.get_dummies(inpt, columns=categorical_columns)
输出 = inpt[[“订单数量”]]
inpt = inpt.drop(columns=[“num_orders”])
sc = 标准缩放器()
in1 = sc.fit_transform(inpt[0:int(len_df * .8)]) #训练并拟合训练输入数据
in2 = sc.transform(inpt[int(len_df * .8)+1:len_df-1]) #测试变换
inp = np.concatenate([in1,in2]) #添加到末尾 df1 arr df2
inpt = pd.DataFrame(inp, columns=inpt.columns)
out1 = sc.fit_transform(output[0:int(len_df * .8)]) #训练并拟合训练出数据
out2 = sc.transform(output[int(len_df * .8)+1:len_df-1]) #测试变换
out = np.concatenate([out1,out2]) #添加到末尾 df1 arr df2
输出 = pd.DataFrame(out, columns=output.columns)
all_inputs = inpt.values
all_targets = 输出.值
对于 all_targets 中的 val：
    值=[值]
类型（所有目标）

&lt;前&gt;&lt;代码&gt;input_nodes = 6
隐藏节点 = 3
输出节点 = 1

输出顺序 = 9
来自输出的传入权重 = .6
输入顺序 = 2
来自输入的传入权重 = .4
网络 = 神经网络()

net.init_layers（输入节点，[隐藏节点]，输出节点，
    NARX循环（
        输出顺序，
        来自输出的传入权重，
        输入顺序，
        来自输入的传入权重））

net.randomize_network()

net.set_halt_on_extremes(True)
net.set_random_constraint(.5)
net.set_learnrate(.1)

net.set_all_inputs(all_inputs)
net.set_all_targets(all_targets)

长度 = len(所有输入)
学习结束点 = int(长度 * .8)

net.set_learn_range(0, learn_end_point)
net.set_test_range(learn_end_point + 1, 长度 - 1)

net.layers[1].set_activation_type(&#39;sigmoid&#39;)#sigmoid,线性 TF

net.learn(epochs= 30, show_epoch_results=True, random_testing=False)

ValueError：尝试将输入值加载到非输入节点
]]></description>
      <guid>https://stackoverflow.com/questions/78374854/neural-network-narx-model-with-python</guid>
      <pubDate>Tue, 23 Apr 2024 20:31:49 GMT</pubDate>
    </item>
    <item>
      <title>UnicodeEncodeError：“charmap”编解码器无法对位置 19-38 中的字符进行编码：字符映射到 <未定义></title>
      <link>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</link>
      <description><![CDATA[我正在开发一个基于 Flask 的 Web 应用程序，用户可以上传图像以使用机器学习模型进行预测。上传的图像存储在本地目录中，并使用预先训练的模型进行预测。然而，当我点击预测按钮时
是什么导致了这个 UnicodeEncodeError？
如何解决此问题以确保我的应用程序能够正确处理图像上传和预测？
是否有在 Flask 环境中处理字符编码的最佳实践，尤其是在 Windows 上？
==app.py====
@app.route(&#39;/uploadimage&#39;,methods=[&#39;GET&#39;, &#39;POST&#39;])
def upload_image():

        文件 = request.files[&#39;my_image&#39;]
        # 获取预测结果
        预测标签 = 预测标签(img_path)
        # 返回预测的标签和一条提示信息
        flash(f&quot;预测：{predicted_label}&quot;, &quot;成功&quot;)
        os.remove(img_path) # 处理后删除临时文件
    return render_template(&#39;uploadimage.html&#39;) # 对于 GET 请求，渲染表单


即使我设置了环境变量“UTF-8”，我仍然收到此错误
错误
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^次
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py”，第 19 行，编码
返回 codecs.charmap_encode(输入,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^
UnicodeEncodeError：“charmap”编解码器无法对位置 19-38 中的字符进行编码：字符映射为未定义。
============
即使我有一个最简单的代码来测试编码
标题是“要测试您的控制台是否可以处理 UTF-8，请尝试输出带有特殊字符或 Unicode 字符的文本：”
print(&quot;UTF-8 测试: àéîöü — 中文 — 阿拉伯语&quot;)


错误也相同
print(&quot;UTF-8 测试：����� � \u4e2d\u6587 � \u0627\u0644\u0639\u0631\u0628\u064a\u0629&quot;)
文件“C:\Users\Subha\AppData\Local\Programs\Python\Python311\Lib\encodings\cp1252.py”，第 19 行，编码
返回 codecs.charmap_encode(输入,self.errors,encoding_table)[0]
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^
UnicodeEncodeError：“charmap”编解码器无法对位置 20-21 中的字符进行编码：字符映射到 ]]></description>
      <guid>https://stackoverflow.com/questions/78367946/unicodeencodeerror-charmap-codec-cant-encode-characters-in-position-19-38-c</guid>
      <pubDate>Mon, 22 Apr 2024 17:25:20 GMT</pubDate>
    </item>
    <item>
      <title>多类问题的层次分类方法</title>
      <link>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</link>
      <description><![CDATA[有一个多类分类任务。我的目标是使用每父节点本地分类器 (LCPN) 方法来解决这个问题。
让我解释一下如何使用 MWE。
假设我有这个虚拟数据集：
将 numpy 导入为 np
从 sklearn.datasets 导入 make_classification
从 scipy.cluster 导入层次结构

X, y = make_classification(n_samples=1000, n_features=10, n_classes=5,
                             n_信息=4）

我想出了这些类之间的距离矩阵：
d = np.array(
[[ 0.、201.537、197.294、200.823、194.517]、
 [201.537, 0., 199.449, 202.941, 196.703],
 [197.294, 199.449, 0., 198.728, 192.354],
 [200.823, 202.941, 198.728, 0., 195.972],
[[194.517, 196.703, 192.354, 195.972, 0.]]
）

因此，我确定了类层次结构，如下所示：
hc = hierarchy.linkage(d, method=&#39;complete&#39;)

得到的树状图如下：
dendrogram = hierarchy.dendrogram(hc, labels=[&#39;A&#39;,&#39;B&#39;,&#39;C&#39;, &#39;D&#39;, &#39;F&#39;])
树状图


我使用hierarchy.to_tree()以树状结构进行说明：

我的问题：
如何按照 LCPN 方法在每个内部节点（包括根）处安装分类器，例如 DecisionTreeClassifier 或 SVM，以像在树中一样进行上图？]]></description>
      <guid>https://stackoverflow.com/questions/78358516/hierarchical-classification-approach-to-a-multiclass-problem</guid>
      <pubDate>Sat, 20 Apr 2024 14:08:05 GMT</pubDate>
    </item>
    <item>
      <title>ML 预测的 NER（命名实体识别）的 CUDA 问题</title>
      <link>https://stackoverflow.com/questions/77440001/cuda-issue-with-ner-named-entity-recognition-for-ml-predictions</link>
      <description><![CDATA[我正在尝试使用NamedEntityRecognition (NER)(https ://github.com/dotnet/machinelearning/issues/630）来预测大量文本中单词/短语的类别。
当前使用 3 个 Nuget 包来尝试实现此功能：
Microsoft.ML (3.0.0-preview.23511.1)
Microsoft.ML.TorchSharp (0.21.0-preview.23511.1)
Torchsharp-cpu (0.101.1)
在训练模型 [estimator.Fit(dataView)] 时，出现以下错误：
找不到字段：“TorchSharp.torch.CUDA”。
我可能在这里误解了一些东西，但我应该使用 Torchsharp-cpu 包中的 CPU 进行处理，并且我不确定 CUDA 参考来自哪里。这似乎也是一个包引用而不是一个字段？
使用 Microsoft.ML；
使用 Microsoft.ML.Data；
使用 Microsoft.ML.TorchSharp；
使用系统；
使用 System.Collections.Generic；
使用 System.Windows.Forms；

命名空间 NerTester
{
    公共部分类 Form1 ：表格
    {
        公共表格1()
        {
            初始化组件();
        }

    私有类 TestSingleSentenceData
    {
        公共字符串句子；
        公共字符串[]标签；
    }

    私人班级标签
    {
        公共字符串密钥{获取;放; }
    }

    私人无效startButton_Click（对象发送者，EventArgs e）
        {
        尝试
        {
                var context = new MLContext();
                context.FallbackToCpu = true;
                上下文.GpuDeviceId = null;

                var labels = context.Data.LoadFromEnumerable(
                新的[] {
                新标签{Key =“PERSON”; },
                新标签 { Key = &quot;CITY&quot;; },
                新标签 { Key = &quot;COUNTRY&quot;; }
                });

                var dataView = context.Data.LoadFromEnumerable(
                    新列表（新TestSingleSentenceData[] {
                    新的 TestSingleSentenceData()
                    { // 测试长度超过 512 个单词。
                        句子=“爱丽丝和鲍勃住在美国”，
                        Label = new string[]{&quot;人员&quot;, &quot;0&quot;, &quot;人员&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;国家&quot;}
                    },
                     新的 TestSingleSentenceData()
                     {
                        句子=“爱丽丝和鲍勃住在美国”，
                        Label = new string[]{&quot;人员&quot;, &quot;0&quot;, &quot;人员&quot;, &quot;0&quot;, &quot;0&quot;, &quot;0&quot;, &quot;国家&quot;}
                     },
                    }));
                var chain = new EstimatorChain();
                var estimator = chain.Append(context.Transforms.Conversion.MapValueToKey(“Label”, keyData: labels))
                   .Append(context.MulticlassClassification.Trainers.NameEntityRecognition(outputColumnName:“outputColumn”))
                   .Append(context.Transforms.Conversion.MapKeyToValue(“outputColumn”));

                var Transformer = estimator.Fit(dataView);
                Transformer.Dispose();
                
                MessageBox.Show(&quot;成功！&quot;);
            }
        catch（异常前）
            {
        MessageBox.Show($&quot;错误: {ex.Message}&quot;);
            }
    }
    }
}

应用程序在 x64 上运行，NER 的文档似乎有限。
任何帮助将不胜感激。
尝试更改我引用的 Nuget 软件包，包括使用 if libtorch 软件包。
尝试在 x86 和 x64 配置中运行应用程序。
添加了代码以尝试强制使用 CPU 而不是 GPU (CUDA)。]]></description>
      <guid>https://stackoverflow.com/questions/77440001/cuda-issue-with-ner-named-entity-recognition-for-ml-predictions</guid>
      <pubDate>Tue, 07 Nov 2023 16:42:42 GMT</pubDate>
    </item>
    <item>
      <title>Apriori 算法 - 没有在 python 中获取规则</title>
      <link>https://stackoverflow.com/questions/60989387/apriori-algorithm-not-getting-the-rules-in-python</link>
      <description><![CDATA[在此处输入图像描述
这是我的代码，我给出了我的数据集“Market_Basket_Optimization”的图像。我已经制作了列表交易列表以提供先验算法中的输入。但我没有得到规则。我是机器学习新手，无法找出错误。
# 导入库
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd

# 数据预处理
数据集 = pd.read_csv(&#39;Market_Basket_Optimization.csv&#39;, header = None)
交易 = []
对于范围 (0, 7501) 内的 i：
    transactions.append([str(dataset.values[i,j]) for j in range(0, 20)])

# 在数据集上训练 Apriori
从 apyori 导入 apriori
规则=先验（交易，min_support = 0.003，min_confidence = 0.2，min_lift = 3，min_length = 2）

# 可视化结果
结果=列表（规则）
]]></description>
      <guid>https://stackoverflow.com/questions/60989387/apriori-algorithm-not-getting-the-rules-in-python</guid>
      <pubDate>Thu, 02 Apr 2020 10:25:21 GMT</pubDate>
    </item>
    </channel>
</rss>