<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 07 Feb 2024 21:12:02 GMT</lastBuildDate>
    <item>
      <title>iCloud 到 Gmail 接口 [关闭]</title>
      <link>https://stackoverflow.com/questions/77957607/icloud-to-gmail-interface</link>
      <description><![CDATA[好吧，我知道我没有正确使用格式，但是请帮忙！！！
家庭暴力受害者的前任远程劫持或入侵了我在 iCloud 中 gmail 中的电话服务！！！警察不在乎，因为我很穷，而且说实话，我有过去！任何有关如何实现这一点的信息我都不太喜欢电子技术！！！！任何答案 pellom33@gmail.com！！！如果您的解决方案是更改密码，启动一个新帐户……谢谢，但知识不足以开始提供帮助！谢谢！！！！
我的手机虽然是我曾经拥有的同一部手机，但总是需要授予权限！ IP地址。似乎从来都不一样......手机中的设置本身会发生变化，例如......wifi通话，播放共享被打开......如果我听起来像个白痴，我只能给予和原谅，但是！蓝牙连接到汽车就是这一切的开始！我连接到室友的车。接下来我知道 Sirus xm 帐户和联系人正在更改，照片已从手机下载和删除！如果你能帮忙，如果需要的话我会解释更多！！！！只想找回我的生活！！！！由于这个请帮助，我正在服刑 4 年缓刑]]></description>
      <guid>https://stackoverflow.com/questions/77957607/icloud-to-gmail-interface</guid>
      <pubDate>Wed, 07 Feb 2024 20:01:12 GMT</pubDate>
    </item>
    <item>
      <title>错误：OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: 错误：(-215:断言失败) !_src.empty() 在函数“cvtColor”中</title>
      <link>https://stackoverflow.com/questions/77957561/error-opencv4-8-0-io-opencv-modules-imgproc-src-color-cpp182-error-215</link>
      <description><![CDATA[augmented_yes = &#39;/content/drive/MyDrive/脑肿瘤检测/augmented-images/yes&#39;
Augmented_no = &#39;/content/drive/MyDrive/脑肿瘤检测/augmented-images/no&#39;
IMG_WIDTH、IMG_HEIGHT = (240, 240)
X, y = load_data([augmented_yes,augmented_no], (IMG_WIDTH, IMG_HEIGHT))
我正在运行上面的代码，但它给了我错误：
错误回溯（最近一次调用最后一次）
 在&lt;细胞系：6&gt;()
4 IMG_宽度、IMG_高度 = (240, 240)
5
----&gt; 6 X, y = load_data([augmented_yes,augmented_no], (IMG_WIDTH, IMG_HEIGHT))
1 帧
 在crop_brain_contour（图像，绘图）中
6
7 # 将图像转为灰度图，并稍微模糊一下
----&gt; 8 灰度 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)
9 灰色 = cv2.GaussianBlur(灰色, (5, 5), 0)
10
错误：OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: 错误：(-215:断言失败) !_src.empty() 在函数“cvtColor”中
**这是 load_data() 函数：**
def load_data(dir_list, image_size):
”“”
读取图像，调整大小并标准化它们。
论据：
dir_list：表示文件目录的字符串列表。
返回：
X：形状 = (#_examples, image_width, image_height, #_channels) 的 numpy 数组
y：形状 = (#_examples, 1) 的 numpy 数组
”“”
# 加载目录中的所有图片
X = []
y = []
图像宽度、图像高度 = 图像大小

对于 dir_list 中的目录：
    对于 listdir（目录）中的文件名：
        # 加载图像
        image = cv2.imread(目录 + &#39;\\&#39; + 文件名)
        # 裁剪大脑并忽略图像中不必要的其余部分
        图像=crop_brain_contour（图像，情节=假）
        # 调整图像大小
        图像 = cv2.resize(图像, dsize=(image_width, image_height), 插值=cv2.INTER_CUBIC)
        # 标准化值
        图像=图像/255。
        # 将图像转换为 numpy 数组并将其附加到 X
        X.append(图像)
        # 如果图像为目标数组，则将值 1 附加到目标数组
        # 位于名为“yes”的文件夹中，否则附加 0。
        如果目录[-3:] == &#39;是&#39;:
            y.追加([1])
        别的：
            y.追加([0])

X = np.array(X)
y = np.array(y)

# 打乱数据
X, y = 随机播放(X, y)

print(f&#39;示例数量为：{len(X)}&#39;)
print(f&#39;X 形状是：{X.shape}&#39;)
print(f&#39;y 形状是: {y.shape}&#39;)

返回 X, y

**
这是crop_brain_contour()函数：**
defcrop_brain_contour（图像，plot=False）：
&lt;前&gt;&lt;代码&gt;#import imutils
#导入CV2
#从 matplotlib 导入 pyplot 作为 plt

# 将图像转为灰度图，并稍微模糊一下
灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

灰色 = cv2.GaussianBlur(灰色, (5, 5), 0)

# 对图像设置阈值，然后执行一系列腐蚀 +
# 膨胀以消除任何小噪声区域
阈值 = cv2.threshold(灰色, 45, 255, cv2.THRESH_BINARY)[1]
thresh = cv2.erode(thresh, 无, 迭代=2)
thresh = cv2.dilate(thresh, 无, 迭代=2)

# 在阈值图像中找到轮廓，然后抓取最大的轮廓
cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cnts = imutils.grab_contours(cnts)
c = max(cnts, key=cv2.contourArea)


# 找到极值点
extLeft = tuple(c[c[:, :, 0].argmin()][0])
extRight = tuple(c[c[:, :, 0].argmax()][0])
extTop = 元组(c[c[:, :, 1].argmin()][0])
extBot = tuple(c[c[:, :, 1].argmax()][0])

# 使用四个极值点（左、右、上、下）从原始图像中裁剪出新图像
new_image = 图像[extTop[1]:extBot[1], extLeft[0]:extRight[0]]

如果情节：
    plt.figure()

    plt. 子图(1, 2, 1)
    plt.imshow(图像)

    plt.tick_params(axis=&#39;两者&#39;,which=&#39;两者&#39;,
                    上=假，下=假，左=假，右=假，
                    labelbottom=False、labeltop=False、labelleft=False、labelright=False)

    plt.title(&#39;原图&#39;)

    plt. 子图(1, 2, 2)
    plt.imshow(new_image)

    plt.tick_params(axis=&#39;两者&#39;,which=&#39;两者&#39;,
                    上=假，下=假，左=假，右=假，
                    labelbottom=False、labeltop=False、labelleft=False、labelright=False)

    plt.title(&#39;裁剪后的图像&#39;)

    plt.show()

返回新图像

检查我正在进行的脑肿瘤检测项目的错误在哪里。/
我尝试了很多，但都失败了]]></description>
      <guid>https://stackoverflow.com/questions/77957561/error-opencv4-8-0-io-opencv-modules-imgproc-src-color-cpp182-error-215</guid>
      <pubDate>Wed, 07 Feb 2024 19:52:57 GMT</pubDate>
    </item>
    <item>
      <title>实施 Info NCE 损失时形状不匹配</title>
      <link>https://stackoverflow.com/questions/77957522/shape-mismatch-when-implementing-info-nce-loss</link>
      <description><![CDATA[我正在尝试用我自己的图像实现这篇论文的Info NCE丢失数据集。我正在遵循此 repo 的实现并使用以下代码：
def info_nce_loss(self, features):

        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)
        标签 = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()
        标签 = labels.to(self.args.device)

        特征 = F.normalize(特征, 暗淡=1)

        相似度矩阵 = torch.matmul(特征, 特征.T)
        # 断言相似度矩阵.shape == (
        # self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)
        # 断言相似度_matrix.shape == labels.shape

        # 丢弃标签和相似度矩阵中的主对角线
        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)
        标签 = labels[~mask].view(labels.shape[0], -1)
        相似度矩阵 = 相似度矩阵[~掩码].view(相似度矩阵.形状[0], -1)
        # 断言相似度_matrix.shape == labels.shape

        # 选择并组合多个正数
        正值=相似度矩阵[labels.bool()].view(labels.shape[0],-1)

        # 只选择底片 底片
        负数=相似度矩阵[~labels.bool()].view(similarity_matrix.shape[0],-1)

        logits = torch.cat([正数, 负数], dim=1)
        标签 = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)

        logits = logits / self.args.温度
        返回逻辑、标签

以自我监督的方式训练我的模型。我在代码中使用 batch_size 32 和上述损失函数，一切正常。但是，当我将 batch_size 更改为任何其他数字（例如 256）时，我收到以下错误：
索引 0 处的掩码 [512, 512] 的形状与索引 0 处的索引张量 [2, 2] 的形状不匹配。

错误源于此行：
labels = labels[~mask].view(labels.shape[0], -1)

我尝试调整图像大小，但这也没有帮助。知道这里可能出现什么问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77957522/shape-mismatch-when-implementing-info-nce-loss</guid>
      <pubDate>Wed, 07 Feb 2024 19:46:25 GMT</pubDate>
    </item>
    <item>
      <title>部署 scikit-learn 模型最便宜（或免费）的方法是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77956894/whats-the-cheapest-or-free-way-to-deply-scikit-learn-model</link>
      <description><![CDATA[我尝试使用 Vercel 函数，但安装 scikit-learn 模块导致超出 250MB 限制。这可能是由它的依赖关系引起的。
除了 AWS 或 gcloud 之外还有其他选择吗？我现在只想构建一个概念验证。]]></description>
      <guid>https://stackoverflow.com/questions/77956894/whats-the-cheapest-or-free-way-to-deply-scikit-learn-model</guid>
      <pubDate>Wed, 07 Feb 2024 17:42:58 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 模型在时间序列上的实现</title>
      <link>https://stackoverflow.com/questions/77955882/implementation-of-lstm-model-to-a-time-serie</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77955882/implementation-of-lstm-model-to-a-time-serie</guid>
      <pubDate>Wed, 07 Feb 2024 15:08:59 GMT</pubDate>
    </item>
    <item>
      <title>回归树中的主导特征使所有其他特征无关/0 [关闭]</title>
      <link>https://stackoverflow.com/questions/77954893/dominant-feature-in-regression-tree-makes-all-other-features-irrelevant-0</link>
      <description><![CDATA[我正在使用房地产数据集（高基数），因此我选择了 scikit-learn 回归树模型来尝试根据相关特征预测房屋的价格。我有这些功能 [&#39;Suburb&#39;,&#39;Address&#39;, &#39;Distance&#39;, &#39;Bedroom2&#39;, &#39;Bathroom&#39;, &#39;CouncilArea&#39;,&#39;Price&#39;]。
问题是，当我使用 Address it 时，它会使所有其他功能（“郊区”、“距离”、“卧室 2”、“浴室”、“议会区域”）基本上变得多余。地址是一个非常重要的功能，因此我正在尝试将其纳入其中。
我已经多次执行预处理和标准化步骤来尝试不同的结果。我将给出一个基本概述：
第一种方法最少预处理：

将原始 df 通过（这是基本的预处理，考虑 nan vals 并替换它们。）。
目标编码我的非 int （分类变量）并在整个 X （训练和测试）变量上使用标准标量。 （关于 Standardscaler，我也没有使用它，但有一个小的不明显的差异）

第二种方法标准化：

标准预处理（处理和替换 nan val）
评估数据偏差
我通过 Box Cox 运行了高度倾斜/非对称的值（用 IHS 进行了实验（有些值为负值（负值只是跳过了标准化，因为倾斜还不错），其他列一些数据点 == 0 所以我添加了小值（0.01）到 0 值以使它们为正）和 Log 变换）。 Box cox 标准化了所选值的最佳值，因此我使用了这个（请注意，我没有在所有适用的列上使用 Box Cox，仅在具有高偏差的列上使用 Box Cox，不确定这是否是标准流程）
将新结果和其余分类变量附加回 df
目标编码 X 分类变量（训练/测试）
使用标准标量
遍历回归树（使用 max_leaf，3-25 的差异非常小，因此其他特征变得明显，但它们包含 epsilon 值，所以不是真的）

第三种方法，省略地址：

重复第一种和第二种方法
结果还不错，但证明不使用“地址”让位于其他重要功能！

我还使用线性回归模型重复了这些过程，但它并不能很好地捕捉数据的复杂性质。我正在尝试使其适用于回归树。
我还使用线性回归模型重复了这个过程，但它没有很好地捕捉数据的复杂性质。]]></description>
      <guid>https://stackoverflow.com/questions/77954893/dominant-feature-in-regression-tree-makes-all-other-features-irrelevant-0</guid>
      <pubDate>Wed, 07 Feb 2024 12:52:43 GMT</pubDate>
    </item>
    <item>
      <title>了解变量选择和调整后的 randomForestSRC 行为 [关闭]</title>
      <link>https://stackoverflow.com/questions/77954827/understanding-randomforestsrc-behaviour-after-variable-selection-and-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77954827/understanding-randomforestsrc-behaviour-after-variable-selection-and-tuning</guid>
      <pubDate>Wed, 07 Feb 2024 12:43:24 GMT</pubDate>
    </item>
    <item>
      <title>在网络之间共享权重时联合或单独的优化器</title>
      <link>https://stackoverflow.com/questions/77954817/joint-or-seperate-optimizers-when-sharing-weights-between-networks</link>
      <description><![CDATA[我想知道，这两种情况有什么副作用。

netA 和 netB 共享权重，但各有一个优化器
netA 和 netB 共享权重，但使用单个优化器

结果非常相似，但不相等。
考虑这个例子
导入火炬
将 torch.nn 导入为 nn

火炬.manual_seed(0)

share_fc2 = 真
批量大小 = 4
通道 = 2

Training_data_A = torch.rand((batch_size, 通道))
Training_data_B = torch.rand((batch_size, 通道))


类 Net(torch.nn.Module):
    “”“最小网络”“”

    def __init__(self) -&gt;; __init__(self) -&gt;没有任何：
        超级().__init__()
        self.fc1 = nn.Linear(通道、通道、偏差=False)
        self.fc2 = nn.Linear(通道、通道、偏差=False)

    def 前向（自身，x）：
        返回 self.fc2(self.fc1(x))


netA = Net().requires_grad_()
netB = Net().requires_grad_()

如果共享_fc2：
    # 将 fc2 替换为 netA.fc2
    netB.fc2 = netA.fc2

lossA = netA(training_data_A).mean()
lossB = netA(training_data_A).mean()

lossA.backward()
lossB.backward()

选项 1
# 选项 1（独立运行，使用种子）
optA = torch.optim.Adam(params=netA.parameters()) # 包含共享的 fc2
optB = torch.optim.Adam(params=netB.parameters()) # 包含共享的 fc2
optA.step()
optB.step()

打印（列表（netA.parameters（）））
打印（列表（netB.parameters（）））

输出

选项 2
opt = torch.optim.Adam(
    参数=(
        list(netA.parameters()) # 包含 netA.fc1、netA/B.fc2
        + list(netB.parameters())[:1] # 包含 netA.fc1
    ）
）
opt.step()
打印（列表（netA.parameters（）））
打印（列表（netB.parameters（）））


输出

问题

是Adam内部参数调整造成的差异，可以忽略
差异是由于梯度计算和应用中的数学原因造成的吗？
一种选择比另一种更好吗？
]]></description>
      <guid>https://stackoverflow.com/questions/77954817/joint-or-seperate-optimizers-when-sharing-weights-between-networks</guid>
      <pubDate>Wed, 07 Feb 2024 12:42:07 GMT</pubDate>
    </item>
    <item>
      <title>我该如何进行模型预测？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77951971/how-can-i-do-model-predict</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77951971/how-can-i-do-model-predict</guid>
      <pubDate>Wed, 07 Feb 2024 02:51:25 GMT</pubDate>
    </item>
    <item>
      <title>如何获得更好的 AUC 分数？ （和累积提升）</title>
      <link>https://stackoverflow.com/questions/77948795/how-to-yield-a-better-auc-score-and-cumulative-lift</link>
      <description><![CDATA[我有一个包含 60 万条记录和 173 个专注于二元分类的特征的数据集。班级比例约为 98.7:1.3（1.3% 目标=1）。
目前，我正在尝试提高模型的性能，该模型的 AUC 为 73%。此外，我对前 2% 的累积提升是 10.41，对前 5% 的累积提升是 5.92。由于我只会针对正面预测分数的前 2-5%，因此我并不特别关心混淆矩阵阈值或改进矩阵值（FP、FN）。
我通过转换（交互，^2）和手动数学计算执行了特征工程。
尽管如此，在没有工程化特征的情况下训练模型后，AUC 分数大致相同，在没有工程化特征的模型中，累积提升略高。我使用了一个自动功能选择工具，该工具使用 RFE 和 XGBoost 来指示所选功能。
我应该注意到，我训练了模型，该模型具有 3 个周期的下采样数据集（3 个周期中每个周期 40k），分类比为 93.5:6.5（6.5% 目标=1），并使用常规的第 4 个周期验证数据集上的数据（原始 1.3% tareget=1 率）。我使用 H20 来训练我的模型（选择 XGBoost）。
如何提高模型得分和模型质量？我知道模型训练涉及插补，但我应该在预处理/清理阶段尝试使用 SimpleImputer、IterativeImputer 或/和 KNNImputer 吗？这会改善我的模型吗？
我尝试使用或不使用我的工程特征重新训练多个模型，并返回到第 1 步并创建更多变量（工程）以尝试帮助我的 AUC 和提升分数。]]></description>
      <guid>https://stackoverflow.com/questions/77948795/how-to-yield-a-better-auc-score-and-cumulative-lift</guid>
      <pubDate>Tue, 06 Feb 2024 15:11:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在 TensorFlow 中实现大数据集的交叉验证而不将整个数据集加载到内存中？</title>
      <link>https://stackoverflow.com/questions/77947993/how-to-implement-cross-validation-with-large-datasets-in-tensorflow-without-load</link>
      <description><![CDATA[我目前正在处理一个机器学习项目的大型数据集，并选择使用 TensorFlow 的 tf.data API 来高效管理数据加载和预处理，而无需将整个数据集加载到内存中。这种方法对于我的初始训练效果很好。
但是我很难实现交叉验证。据我了解，TensorFlow 本身并不支持直接通过 tf.data API 进行交叉验证，而与 Keras 集成进行交叉验证似乎需要先将数据加载到内存中。这对我的使用来说是有问题的，因为立即将整个数据集加载到内存中违背了使用 tf.data 的目的。
我正在寻找一种解决方法或方法来实现与 TensorFlow 的按需数据加载兼容的交叉验证。理想情况下，我希望保持 tf.data 的内存效率，同时对模型的评估进行交叉验证。
有没有办法使用 Keras 或任何其他库进行交叉验证，而不需要我将所有数据集加载到内存中？]]></description>
      <guid>https://stackoverflow.com/questions/77947993/how-to-implement-cross-validation-with-large-datasets-in-tensorflow-without-load</guid>
      <pubDate>Tue, 06 Feb 2024 13:16:55 GMT</pubDate>
    </item>
    <item>
      <title>keras.LSTM 如何将 3D 输入转换为 2D 输出？</title>
      <link>https://stackoverflow.com/questions/77946209/how-keras-lstm-converts-3d-input-to-2d-output</link>
      <description><![CDATA[根据 keras 的 LSTM 文档，输入应该是具有形状（批量、时间步长、特征）的 3D 张量
输出将为（批次，单位），其中单位是我们想要从 LSTM 单元获得的数字特征。
据我所知，lstm 的单个单元格将隐藏状态、单元格状态和单个数字作为时间戳 t 的输入，并将其输出以 c(t+1) 和 h(t+1) 的形式传递到下一个单元格。但从文档代码来看，它正在生成 2D 形式的输出？
输入 = np.random.random((32, 10, 8))
lstm = keras.layers.LSTM(4)
输出 = lstm(输入)
输出形状
(32, 4)

问题 1：向量表示如何传递给 LSTM？ （在每个时间戳处，它传递 8 个特征。如果有 8 个 lstm 单元并行运行，则输出大小也应为 8）
问题2：最终输出的大小如何为4。（如果我们忽略批量大小）]]></description>
      <guid>https://stackoverflow.com/questions/77946209/how-keras-lstm-converts-3d-input-to-2d-output</guid>
      <pubDate>Tue, 06 Feb 2024 08:25:41 GMT</pubDate>
    </item>
    <item>
      <title>时间序列分析：分类变量的预测</title>
      <link>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</link>
      <description><![CDATA[我有一台机器在 1 分钟时间间隔内的故障发生数据（以 0 和 1 表示）。 0 代表未发生故障，1 代表发生特定故障。因此，连续0 表示在一段时间内没有发生故障，连续1 表示在一段时间内连续发生故障。
我提供了如下的示例数据结构，现在我如何对下面提供的数据进行时间序列分析故障 A，并根据分析如何进行预测，例如“故障 A 将在未来时间戳中何时发生？” 
# 时间序列多元
将 pandas 导入为 pd
将 numpy 导入为 np

df = pd.DataFrame({&#39;timestamp&#39;:pd.date_range(&#39;2022-05-01 00:01:00&#39;, period=18, freq=&#39;T&#39;),
                   &#39;故障代码&#39;:[&#39;A&#39;]*4+[&#39;B&#39;]*3+[&#39;A&#39;]*2+[&#39;C&#39;]*5+[&#39;B&#39;]*2+[&#39;A&#39;]* 1+[&#39;D&#39;]*1
                  })
df[&#39;脉冲&#39;] = 1

df_ts = df.pivot(index=“时间戳”, columns=“故障代码”, value=“脉冲”)
df_ts = df_ts.fillna(0)
显示（df_ts）



         故障代码 A B C D
时间戳
2022-05-01 00:01:00 1 0 0 0
2022-05-01 00:02:00 1 0 0 0
2022-05-01 00:03:00 1 0 0 0
2022-05-01 00:04:00 1 0 0 0
2022-05-01 00:05:00 0 1 0 0
2022-05-01 00:06:00 0 1 0 0
2022-05-01 00:07:00 0 1 0 0
2022-05-01 00:08:00 1 0 0 0
2022-05-01 00:09:00 1 0 0 0
2022-05-01 00:10:00 0 0 1 0
2022-05-01 00:11:00 0 0 1 0
2022-05-01 00:12:00 0 0 1 0
2022-05-01 00:13:00 0 0 1 0
2022-05-01 00:14:00 0 0 1 0
2022-05-01 00:15:00 0 1 0 0
2022-05-01 00:16:00 0 1 0 0
2022-05-01 00:17:00 1 0 0 0
2022-05-01 00:18:00 0 0 0 1

# 时间序列图
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns

sns.set_theme(style=&quot;whitegrid&quot;) # darkgrid、whitegrid、dark、white 和ticks

故障=[&#39;A&#39;,
        &#39;B&#39;,
        &#39;C&#39;，
        &#39;D&#39;
       ]

plt.figure(figsize = (15,4))
sns.lineplot(数据=df_ts[故障])
plt.show()

上述数据的时间序列图
我要预测A的故障代码（0或1）
         
时间戳故障代码
2022-05-01 00:19:00 ?
2022-05-01 00:20:00 ?
2022-05-01 00:21:00 ？
2022-05-01 00:22:00 ？
2022-05-01 00:23:00 ？
2022-05-01 00:24:00 ？
2022-05-01 00:25:00 ？
]]></description>
      <guid>https://stackoverflow.com/questions/72488489/time-series-analysis-forecasting-of-categorical-variables</guid>
      <pubDate>Fri, 03 Jun 2022 10:48:17 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM错误：ValueError：为了提前停止，至少需要一个数据集和评估指标进行评估</title>
      <link>https://stackoverflow.com/questions/61694081/lightgbm-error-valueerror-for-early-stopping-at-least-one-dataset-and-eval-m</link>
      <description><![CDATA[我正在尝试使用 gridsearch 训练 LightGBM，当我尝试训练模型时出现以下错误。 
ValueError：为了提前停止，至少需要一个数据集和评估指标进行评估

我提供了验证数据集和评估指标。不知道为什么我仍然遇到这个问题。这是我的代码。
train_data = rtotal[rtotal[&#39;train_Y&#39;] == 1]
test_data = rtotal[rtotal[&#39;train_Y&#39;] == 0]

trainData，validData = train_test_split（train_data，test_size = 0.007，random_state = 123）

#训练数据准备
X_train = trainData.iloc[:,2:71]
y_train = trainData.loc[:,[&#39;a_class&#39;]]

#验证数据准备
X_valid = validData.iloc[:,2:71]
y_valid = validData.loc[:,[&#39;a_class&#39;]]

#X_测试
X_test = test_data.iloc[:,2:71]

将 lightgbm 导入为 lgb
从 sklearn.model_selection 导入 GridSearchCV

网格参数 = {
    &#39;学习率&#39;：[0.005]，
    “n_估计器”：[40]，
    &#39;num_leaves&#39;: [16,32, 64],
    &#39;目标&#39;：[&#39;多类&#39;]，
    “随机状态”：[501]，
    &#39;num_boost_round&#39;：[3000]，
    &#39;colsample_bytree&#39;：[0.65，0.66]，
    &#39;子样本&#39;：[0.7,0.75],
    &#39;reg_alpha&#39;: [1,1.2],
    &#39;reg_lambda&#39;：[1,1.2,1.4],
    }

lgb_estimator = lgb.LGBMClassifier(boosting_type = &#39;gbdt&#39;,
                                   n_估计器=500，
                                   目标=&#39;多类&#39;，
                                   学习率 = 0.05，叶子数 = 64，
                                   eval_metric = &#39;multi_logloss&#39;,
                                   详细评估=20，
                                   eval_set = [X_valid, y_valid],
                                   Early_stopping_rounds=100）

g_lgbm = GridSearchCV(估计器=lgb_estimator, param_grid=gridParams, n_jobs = 3, cv= 3)

lgb_model = g_lgbm.fit(X=X_train, y=y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/61694081/lightgbm-error-valueerror-for-early-stopping-at-least-one-dataset-and-eval-m</guid>
      <pubDate>Sat, 09 May 2020 08:50:22 GMT</pubDate>
    </item>
    <item>
      <title>RF：一个类别的 OOB 准确度较高，而另一个类别的准确度非常低，类别不平衡较大</title>
      <link>https://stackoverflow.com/questions/10306380/rf-high-oob-accuracy-by-one-class-and-very-low-accuracy-by-the-other-with-big</link>
      <description><![CDATA[我正在使用随机森林分类器对具有两个类别的数据集进行分类。

特征数量为 512 个。
数据比例为1:4。即，75% 的数据来自第一类，25% 来自第二类。
我使用了 500 棵树。

分类器产生 21.52% 的袋外错误。
第一类（由 75% 的训练数据表示）的每类误差为 0.0059。而第二类的分类误差非常高：0.965。
我正在寻找对此行为的解释，以及您是否有提高第二类准确性的建议。
我期待您的帮助。
谢谢
忘记说我正在使用 R 并且在上面的测试中使用了 1000 的节点大小。
这里我只用 10 棵树和节点大小 = 1 重复训练（只是为了给出一个想法），下面是 R 中的函数调用和混淆矩阵：

randomForest（公式 = Label ~ .，数据 = chData30PixG12，ntree = 10，重要性 = TRUE，节点大小 = 1，keep.forest = FALSE，do.trace = 50）

随机森林的类型：分类

树木数量：10

没有。每次分割尝试的变量数：22

OOB 错误率估计：24.46%

混淆矩阵：


 不相关、相关、class.error
 不相关 37954、4510、0.1062076
 相关8775、3068、0.7409440
]]></description>
      <guid>https://stackoverflow.com/questions/10306380/rf-high-oob-accuracy-by-one-class-and-very-low-accuracy-by-the-other-with-big</guid>
      <pubDate>Tue, 24 Apr 2012 21:37:50 GMT</pubDate>
    </item>
    </channel>
</rss>