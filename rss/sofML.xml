<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 06 May 2024 09:16:04 GMT</lastBuildDate>
    <item>
      <title>Imblearn 语法无效</title>
      <link>https://stackoverflow.com/questions/78435597/imblearn-invalid-syntax</link>
      <description><![CDATA[虽然我已经能够在 jupyter 笔记本中安装 Imblearn ，但在尝试通过下面的代码导入管道时出现错误。
代码
from imblearn.pipeline 导入管道

错误
文件“C:\Users\ibl165795\AppData\Roaming\Python\Python37\site-
packages\imblearn\utils\_metadata_requests.py”，第 1492 行
    def process_routing(_obj, _method, /, **kwargs):
语法错误：语法无效
]]></description>
      <guid>https://stackoverflow.com/questions/78435597/imblearn-invalid-syntax</guid>
      <pubDate>Mon, 06 May 2024 09:02:47 GMT</pubDate>
    </item>
    <item>
      <title>指导法学硕士 - 从文本中错误地提取数据继续</title>
      <link>https://stackoverflow.com/questions/78435586/instruct-llms-extract-data-from-text-wrongly-continues</link>
      <description><![CDATA[我正在尝试微调开源 LLM，现在让我们坚持使用 Mistral-7b-instruct 模型。
我的任务如下：我有电子邮件，代表客户发送的货物“价格请求”。
在电子邮件中，客户告诉我们取货地址、托运人、收货人等。
我最初的想法是使用 DORA 训练不同的适配器，每个适配器都经过训练以从电子邮件中提取不同的实体。
我的数据集创建如下：我有电子邮件和注释，注释为“根据电子邮件，我发现了这个 [ENTITY]：entity_here
我创建了一条系统消息和 chat_template，以 Mistral 可以接受的方式创建数据集，使用这个 chat_template：
&quot;{%- for message in messages %}&quot;
&quot;{%- if message[&#39;role&#39;] == &#39;system&#39; -%}&quot;
&quot;{{- &#39;&lt;s&gt;&#39; + message[&#39;content&#39;] -}}&quot;
&quot;{%- else -%}&quot;
&quot;{%- if message[&#39;role&#39;] == &#39;user&#39; -%}&quot;
&quot;{{-&#39;[INST] &#39; + message[&#39;content&#39;].rstrip() + &#39; [/INST]&#39;-}}&quot;
&quot;{%- else -%}&quot;
&quot;{{-&#39;&#39; + message[&#39;content&#39;] + &#39;&lt;/s&gt;&#39; -}}&quot;
&quot;{%- endif -%}&quot;
&quot;{%- endif -%}&quot;
&quot;{%- endfor -%}&quot;
&quot;{%- if add_generation_prompt -%}&quot;
&quot;{{-&#39;&#39;-}}&quot;
&quot;{%- endif -%}&quot;

现在来谈谈问题。该模型似乎学会了它需要提取的内容，它生成了不错的答案，格式与训练它的助手相同，问题是在它生成答案后，它继续生成与任务无关的有关电子邮件的其他文本，例如“请与我们联系...”。
当我针对同一任务微调 GPT3.5 时，该模型能够准确提取我需要的内容，这表明我做错了什么。
有人对我哪里做错了有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435586/instruct-llms-extract-data-from-text-wrongly-continues</guid>
      <pubDate>Mon, 06 May 2024 09:01:03 GMT</pubDate>
    </item>
    <item>
      <title>为我的 Npy 数据集定义 ML 模型时出现问题</title>
      <link>https://stackoverflow.com/questions/78435504/problem-in-defining-a-ml-model-for-my-npy-dataset</link>
      <description><![CDATA[我需要帮助为我的数据定义火炬模型。我尝试了各种方法，但似乎没有任何效果。与输入尺寸和形状相关的错误不断出现。我对此完全是初学者。非常感谢您的帮助。我渴望学得更好。
将 numpy 导入为 np
进口火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim
从 torch.utils.data 导入 DataLoader，TensorDataset
导入 torch.nn.function 作为 f

# 从 .npy 文件加载数据
data = np.load(“其他py文件/project_files/data/train/data.npy”)
print(&quot;数据形状：&quot;, data.shape) # (401, 701, 255)

数据大小 = 数据.形状[0] * 数据.形状[1] * 数据.形状[2]
print(“数据大小：”, data_size) # 71680755

# 从 .npy 文件加载标签数据
labels = np.load(“其他py文件/project_files/data/train/label.npy”)
print(&quot;标签数据形状:&quot;, labels.shape) # (401, 701, 255)

# 将 numpy 数组转换为 PyTorch 张量
data_tensor = torch.Tensor(数据)
labels_tensor = torch.Tensor(labels)


类 MyModel(nn.Module):
    def __init__(自身):
        超级（MyModel，自我）.__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.fc_input_size = data_size
        self.fc = nn.Linear(self.fc_input_size, 2)

    def 前向（自身，x）：
        x = self.pool(f.relu(self.conv1(x)))
        x = self.pool(f.relu(self.conv2(x)))
        x = x.view(-1, self.fc_input_size)
        x = self.fc(x)
        返回x

模型 = MyModel()
打印（模型）

标准 = nn.CrossEntropyLoss()
优化器 = optim.Adam(model.parameters(), lr=0.001)

数据集 = TensorDataset(data_tensor, labels_tensor)
dataloader = DataLoader(数据集,batch_size=32,shuffle=True)

纪元数 = 10
对于范围内的纪元（num_epochs）：
    运行损失 = 0.0
    对于 i，enumerate(dataloader, 0) 中的数据：
        输入，标签=数据
        优化器.zero_grad()
        outputs = model(inputs.unsqueeze(1)) # 通道维度
        损失=标准（输出，标签）
        loss.backward()
        优化器.step()

        running_loss += loss.item()
        如果我％100==99：
            print(f&quot;[{epoch + 1}, {i + 1}] 损失: {running_loss / 100}&quot;)
            运行损失 = 0.0


使用 torch.no_grad()：
    Predictions = model(data_tensor.unsqueeze(1)) # 通道维度


**控制台输出：
已连接到 pydev 调试器（内部版本 223.8836.43）
数据形状：(401, 701, 255)
数据大小：71680755
标签数据形状：(401, 701, 255)
我的模型（
(conv1): Conv2d(1, 32, kernel_size=(3, 3), 步幅=(1, 1), 填充=(1, 1))
（池）：MaxPool2d（kernel_size = 2，stride = 2，padding = 0，dilation = 1，ceil_mode = False）
(conv2): Conv2d(32, 64, kernel_size=(3, 3), 步幅=(1, 1), 填充=(1, 1))
（fc）：线性（in_features = 71680755，out_features = 2，偏差= True）
）
文件“C:\Users\PC1\PycharmProjects\Project1\newmodel2.py”，第 36 行，向前
x = x.view(-1, self.fc_input_size)
运行时错误：形状“[-1, 71680755]”对于大小 22579200 的输入无效
python-BaseException**]]></description>
      <guid>https://stackoverflow.com/questions/78435504/problem-in-defining-a-ml-model-for-my-npy-dataset</guid>
      <pubDate>Mon, 06 May 2024 08:45:53 GMT</pubDate>
    </item>
    <item>
      <title>如何保留机器学习课程中的数学概念？</title>
      <link>https://stackoverflow.com/questions/78435140/how-to-retain-mathematical-concepts-from-machine-learning-courses</link>
      <description><![CDATA[Stack Overflow 社区您好，
我最近完成了 Deeplearning.ai 在 Coursera 上提供的机器学习专业化以及 ML 和 DS 数学课程。虽然我设法完成了这些课程，但我在保留所教授的数学概念和公式方面面临着挑战。这些课程涵盖了广泛的主题，现在回想起来，我意识到我不记得大部分材料，尤其是详细的数学部分。
我正在寻找有效的策略或工具，以帮助更好地长期掌握和保留这些数学概念。我仍然觉得我还没有完全掌握这些材料。我将不胜感激任何有关学习技巧、资源或任何有助于巩固我对这些概念的理解的具体练习的建议。此外，如果社区有适合强化这些知识的后续课程或材料的建议，我将不胜感激。
感谢您的帮助！
我期待一个指导方针。]]></description>
      <guid>https://stackoverflow.com/questions/78435140/how-to-retain-mathematical-concepts-from-machine-learning-courses</guid>
      <pubDate>Mon, 06 May 2024 07:31:53 GMT</pubDate>
    </item>
    <item>
      <title>如何将FastAI分类器集成到sklearn VotingClassifier中？</title>
      <link>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</link>
      <description><![CDATA[我有一堆表格数据，我成功地训练了一个 RandomForestClassifier、一个 GradientBoostingClassifier 和一个深度学习模型（来自 fastai 的表格学习器代码&gt;) 与他们一起。我在结果中注意到，每个模型在特定标签上都比其他模型做得更好，每个模型都不同。我想知道是否可以将所有模型放入 VotingClassifier （来自 sklearn 的模型）。我对 RandomForestClassifier 和 GradientBoostingClassifier 没有任何问题，但我没有找到任何有关将表格学习器放入 VotingClassifier 中的信息。可以这样做吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</guid>
      <pubDate>Mon, 06 May 2024 07:21:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在tensorflow中读入csv文件</title>
      <link>https://stackoverflow.com/questions/78434695/how-to-read-into-a-csv-file-in-tensorflow</link>
      <description><![CDATA[我正在使用tensorflow在conda环境中进行机器学习。在我的代码中，当我尝试读入我的 train.csv 和 test.csv 时，出现问题，如下代码所示：
os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39;
将张量流导入为 tf
从张量流导入keras
从tensorflow.keras导入层，正则化器
从tensorflow.keras.datasets导入mnist
将 pandas 导入为 pd
从tensorflow.keras.optimizers.legacy导入Adam

#超级参数

批量大小 = 64
WEIGHT_DECAY = 0.001
学习率 = 0.001

train_df = pd.read_csv(“train.csv”)
test_df = pd.read_csv(“test.csv”)
train_images = os.getcwd() + “/train_images/” + train_df.iloc[:, 0].values
test_images = os.getcwd() + “/test_images/” + test_df.iloc[:, 0].values

train_labels = train_df.iloc[:, 1:].values
test_labels = test_df.iloc[:, 1:].values

def read_image(图像路径, 标签):
  图像 = tf.io.read_file(image_path)
  图像 = tf.image.decode_image(图像, 通道=1, dtype=tf.float32)

  图像.set_shape((64, 64, 1))
  标签[0].set_shape([])
  标签[1].set_shape([])

  标签 = {“first_num”：标签[0]，“second_num”：标签[1]}
  返回图像、标签

自动调谐 = tf.data.experimental.AUTOTUNE
train_dataset = tf.data.Dataset.from_tensor_slices(
  （火车图像，火车标签）
）
训练数据集 = (
  train_dataset.shuffle(buffer_size=len(train_labels))
  .map(读取图像)
  .batch(batch_size=BATCH_SIZE)
  .prefetch(buffer_size=AUTOTUNE)
）

test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))
测试数据集 = (
  test_dataset.map(read_image)
  .batch(batch_size=BATCH_SIZE)
  .prefetch(buffer_size=AUTOTUNE)
）

输入 = keras.Input(形状= (64, 64, 1))
x = 层.Conv2D(
  过滤器=32，
  内核大小=3，
  填充=&#39;相同&#39;，
  kernel_regularizer=regularizers.l2(WEIGHT_DECAY),
)(输入)
x = 层.BatchNormalization()(x)
x = keras.activations.relu(x)
x = 层.Conv2D(
  64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY),
）（X）
x = 层.BatchNormalization()(x)
x = keras.activations.relu(x)
x = 层数.MaxPooling2D()(x)
x = 层.Conv2D(
  64、
  3、
  激活=&#39;relu&#39;,
  kernel_regularizer=regularizers.l2(WEIGHT_DECAY),
）（X）

x= 层.Conv2D(128, 3, 激活=&#39;relu&#39;)(x)
x = 层数.MaxPooling2D()(x)
x = 层.Flatten()(x)
x = 层.Dense(128, 激活=&#39;relu&#39;)(x)
x = 层.Dropout(0.5)(x)
x = 层.Dense(64, 激活=&#39;relu&#39;)(x)
输出1 = 层.Dense(10, 激活=&#39;softmax&#39;, 名称=&#39;first_num&#39;)(x)
输出2 = 层.Dense(10, 激活=&#39;softmax&#39;, 名称=&#39;second_num&#39;)(x)
模型= keras.Model（输入=输入，输出=[输出1，输出2]）

打印（模型.摘要（））

模型.编译(
  损失=[keras.losses.SparseCategoricalCrossentropy(),
        keras.losses.SparseCategoricalCrossentropy(),
        ],
  指标=[“准确度”,“准确度”],
）

model.fit(train_dataset, epochs=5, verbose=2)
model.evaluate(train_dataset, verbose=2)

错误开始于...
&lt;前&gt;&lt;代码&gt;
2024-05-06 06:09:12.539105: E external/local_tsl/tsl/platform/windows/windows_file_system.cc:363] 错误：GetSymbolicLinkTarget 无法打开 \\?\C:\Users\USER\CODE\PycharmProjects\ 的文件pythonProject2Conda\train_images\129_97.png GetLastError：2


对于要读取的不同图像，以下错误类似，并以以下结尾：
回溯（最近一次调用最后一次）：
  文件“C:\Users\USER\CODE\PycharmProjects\pythonProject2Conda\main.py”，第 94 行，在  中
    model.fit(train_dataset, epochs=5, verbose=2)
  文件“C:\Users\USER\anaconda3\envs\tf_cpu\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 123 行，在 error_handler 中
    从 None 引发 e.with_traceback(filtered_tb)
  文件“C:\Users\USER\anaconda3\envs\tf_cpu\Lib\site-packages\tensorflow\python\eager\execute.py”，第 53 行，在 Quick_execute 中
    张量 = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tensorflow.python.framework.errors_impl.NotFoundError：图执行错误：

在定义于（最近一次调用最后）的节点 ReadFile 处检测到：
&lt;堆栈跟踪不可用&gt;
NewRandomAccessFile 无法创建/打开：C:\Users\USER\CODE\PycharmProjects\pythonProject2Conda/train_images/129_97.png ：系统找不到指定的文件。
;没有这样的文件或目录
     [[{{节点读取文件}}]]
     [[IteratorGetNext]] [操作：__inference_one_step_on_iterator_2745]


请问我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78434695/how-to-read-into-a-csv-file-in-tensorflow</guid>
      <pubDate>Mon, 06 May 2024 05:33:44 GMT</pubDate>
    </item>
    <item>
      <title>如何将训练好的模型移动到另一个 python 笔记本？</title>
      <link>https://stackoverflow.com/questions/78434627/how-can-i-move-my-trained-model-to-another-python-notebook</link>
      <description><![CDATA[我有一个Python笔记本，其中包含多个函数，例如pre_process，..并且它包含我训练的模型。现在我应该提交一个 python 笔记本，其中包含我训练过的模型以进行进一步测试。我怎样才能做到这一点？
我知道在运行单元格时，它会保存所有单元格使用的变量，我可以链接这两个文件并从那里调用模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/78434627/how-can-i-move-my-trained-model-to-another-python-notebook</guid>
      <pubDate>Mon, 06 May 2024 05:04:24 GMT</pubDate>
    </item>
    <item>
      <title>关于 onehotencoder 空间成本</title>
      <link>https://stackoverflow.com/questions/78434421/regarding-onehotencoder-space-cost</link>
      <description><![CDATA[为什么 onehotencoding 不使用基于位的编码？占用的内存不是少很多吗？我的意思是，当您对四个城市进行编码时，您可以像 onehotencoder 那样将一列扩展到 4 或在一列中这样进行：
 第一个城市 = 0(base10) = 00000000
    第二个城市 = 1(base10) = 00000001
    第三个城市 = 2(base10) = 00000010
    第四个城市 = 3(base10) = 00000011

。
就内存成本而言，这不是更有效吗？或者编码技术是否迫使它占用更多空间？]]></description>
      <guid>https://stackoverflow.com/questions/78434421/regarding-onehotencoder-space-cost</guid>
      <pubDate>Mon, 06 May 2024 03:24:38 GMT</pubDate>
    </item>
    <item>
      <title>如何在多个 GPU 上进行训练？</title>
      <link>https://stackoverflow.com/questions/78433502/how-do-i-train-on-multiple-gpus</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78433502/how-do-i-train-on-multiple-gpus</guid>
      <pubDate>Sun, 05 May 2024 19:27:19 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：无法同步创建数据集（名称已存在）</title>
      <link>https://stackoverflow.com/questions/78429387/valueerror-unable-to-synchronously-create-dataset-name-already-exists</link>
      <description><![CDATA[当我尝试将模型另存为 h5 时
caption_model.save(“/kaggle/working/mymodel.h5”)

我发现了这个错误
ValueError Traceback（最近一次调用最后一次）
[19] 中的单元格，第 1 行
----&gt; 1 title_model.save(“/kaggle/working/mymodel.h5”)

文件 /opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122，位于filter_traceback..error_handler(*args, **kwargs)
    第 119 章
    120 # 要获取完整的堆栈跟踪，请调用：
    121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
    123最后：
    124 删除filtered_tb

文件 /opt/conda/lib/python3.10/site-packages/h5py/_hl/group.py:183，在 Group.create_dataset(self, name, shape, dtype, data, **kwds)
    第180章 180
    [第 181 回]
--&gt;第183章
    184 dset = 数据集. 数据集（dsid）
    185 返回数据集

文件 /opt/conda/lib/python3.10/site-packages/h5py/_hl/dataset.py:163，在 make_new_dset(parent、shape、dtype、数据、名称、块、压缩、shuffle、fletcher32、maxshape、compression_opts 中、 fillvalue、scaleoffset、track_times、external、track_order、dcpl、dapl、efile_prefix、virtual_prefix、allow_unknown_filter、rdcc_nslots、rdcc_nbytes、rdcc_w0)
    160 其他：
    161 sid = h5s.create_simple（形状，maxshape）
--&gt;第163章
    165 if (data is not None) and (not isinstance(data, Empty)):
    166 dset_id.write（h5s.ALL，h5s.ALL，数据）

文件 h5py/_objects.pyx:54，在 h5py._objects.with_phil.wrapper() 中

文件 h5py/_objects.pyx:55，在 h5py._objects.with_phil.wrapper() 中

文件h5py/h5d.pyx:137，在h5py.h5d.create()中

ValueError：无法同步创建数据集（名称已存在）

你们以前遇到过这个问题或者知道如何解决吗？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78429387/valueerror-unable-to-synchronously-create-dataset-name-already-exists</guid>
      <pubDate>Sat, 04 May 2024 14:51:33 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch：不同的 DataLoader 批量大小会产生截然不同的损失</title>
      <link>https://stackoverflow.com/questions/78428584/pytorch-different-dataloader-batch-sizes-yield-very-different-losses</link>
      <description><![CDATA[我正在使用 此近似示例将正弦波作为学习近似的基础。我是 PyTorch 新手……为什么不同的 BATCH_SIZE 值会显着改变结果？
批量大小 512：

批量大小 10000（所有数据点）：

我发布了下面的代码，但首先我将解释我对原始代码所做的更改：

所有随机种子都是静态的，禁用洗牌：

学习率更改为 1e-4，X 大小更改为 10**4，MAX_EPOCH 更改为 20。

添加了一个绘图来绘制 X 范围内所有值的近似值，以显示差异


完整代码如下...
谢谢！
导入火炬
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

从火炬导入 nn，优化
从 torch.utils.data 导入 TensorDataset、DataLoader
从 sklearn.model_selection 导入 train_test_split

device = torch.device(“cuda”) if torch.cuda.is_available() else torch.device(“cpu”)
LR = 1e-4
最大纪元 = 20
BATCH_SIZE = 10**4

类 SineApproximator(nn.Module):
    def __init__(自身):
        超级（SineApproximator，自我）.__init__()
        self.regressor = nn.Sequential(nn.Linear(1, 1024),
                                       nn.ReLU(inplace=True),
                                       nn.线性(1024, 1024),
                                       nn.ReLU(inplace=True),
                                       nn.线性(1024, 1))
    def 前向（自身，x）：
        输出 = self.regressor(x)
        返回输出


火炬.manual_seed(41)
如果 torch.cuda.is_available():
    torch.cuda.manual_seed_all(41)
np.随机.种子(41)

X = np.random.rand(10**4) * 2 * np.pi
y = np.sin(X)

X_train, X_val, y_train, y_val = map(torch.tensor, train_test_split(X, y, test_size=0.2, shuffle=False, random_state=41))
train_dataloader = DataLoader(TensorDataset(X_train.unsqueeze(1), y_train.unsqueeze(1)), batch_size=BATCH_SIZE,
                              pin_memory=True, shuffle=True)
val_dataloader = DataLoader(TensorDataset(X_val.unsqueeze(1), y_val.unsqueeze(1)), batch_size=BATCH_SIZE,
                            pin_memory=True, shuffle=True)

模型 = SineApproximator().to(设备)
优化器 = optim.Adam(model.parameters(), lr=LR)
标准 = nn.MSELoss(reduction=&quot;mean&quot;)

train_loss_list = 列表()
val_loss_list = 列表()
对于范围内的纪元（MAX_EPOCH）：
    print(&quot;纪元 %d / %d&quot; % (纪元 + 1, MAX_EPOCH))
    模型.train()
    # 训练循环
    temp_loss_list = 列表()
    对于train_dataloader中的X_train、y_train：
        X_train = X_train.type(torch.float32).to(设备)
        y_train = y_train.type(torch.float32).to(设备)

        优化器.zero_grad()

        分数 = 模型(X_train)
        损失=标准（输入=分数，目标=y_train）
        loss.backward()

        优化器.step()

        temp_loss_list.append(loss.detach().cpu().numpy())

    temp_loss_list = 列表()
    对于train_dataloader中的X_train、y_train：
        X_train = X_train.type(torch.float32).to(设备)
        y_train = y_train.type(torch.float32).to(设备)

        分数 = 模型(X_train)
        损失=标准（输入=分数，目标=y_train）

        temp_loss_list.append(loss.detach().cpu().numpy())

    avg_loss = np.average（temp_loss_list）
    train_loss_list.append(avg_loss)
    print(&quot;\ttrain 损失: %.5f&quot; % train_loss_list[-1])

# 构建一个 np 数组，其中所有 X 值都在最小值和最大值之间，间隔为 0.01，每个值都在自己的数组中：
模型.eval()
X_all = torch.tensor(np.arange(X.min(), X.max(), 0.01)).type(torch.float32).unsqueeze(1).to(device)
y_预测 = 模型(X_all)
y_prediction = y_prediction.detach().cpu().numpy().flatten()
原始 = plt.scatter(X, y, s=1)
预测 = plt.scatter(X_all.detach().cpu().numpy(), y_prediction, s=1)
plt.legend((预测，原始), (“函数”, “样本”))
plt.waitforbuttonpress()

更新：根据 @karl 的建议，我通过增加纪元，将其从 20 更改为 20 * (10000/512) ~= 400 来补偿高批量大小中的少量更新步骤，这产生了类似的近似值（相同的LR）：
]]></description>
      <guid>https://stackoverflow.com/questions/78428584/pytorch-different-dataloader-batch-sizes-yield-very-different-losses</guid>
      <pubDate>Sat, 04 May 2024 10:10:58 GMT</pubDate>
    </item>
    <item>
      <title>从tensorflow.compat.v1导入估计器作为tf_estimator导入错误：无法从'tensorflow.compat.v1导入名称'估计器'</title>
      <link>https://stackoverflow.com/questions/78428547/from-tensorflow-compat-v1-import-estimator-as-tf-estimator-importerror-cannot-i</link>
      <description><![CDATA[我收到此错误
ImportError：无法从“tensorflow.compat.v1”（/root/.local/lib/python3.10/site-packages/tensorflow）导入名称“estimator” /_api/v2/compat/v1/__init__.py)

当我尝试运行此代码时
python Tensorflow\models\research\object_detection\model_main_tf2.py --model_dir=Tensorflow\workspace\models\my_ssd_mobnet --pipeline_config_path=Tensorflow\workspace\models\my_ssd_mobnet \pipeline.config --num_train_steps=10000
]]></description>
      <guid>https://stackoverflow.com/questions/78428547/from-tensorflow-compat-v1-import-estimator-as-tf-estimator-importerror-cannot-i</guid>
      <pubDate>Sat, 04 May 2024 09:58:47 GMT</pubDate>
    </item>
    <item>
      <title>COCO分段json格式的合并和减去注释</title>
      <link>https://stackoverflow.com/questions/78427741/merge-and-subtract-annotations-in-coco-segmentation-json-format</link>
      <description><![CDATA[我是 Python 和机器学习新手，遇到以下问题：我以 COCO .json 格式注释了数据。在这种情况下，水下照片上的珊瑚表面区域是活的，而珊瑚的部分区域是死的。有时，蒙版会重叠。
我想减去我注释为“死区”的区域来自我注释为“活着”的区域。在每张照片上，只有一个珊瑚被注释，有时我会分多个部分进行注释，因此我也想在减法之前合并每个类别的蒙版。注释类“死”了。仅出现在图像的子集中。
有人能指出我如何做到这一点的正确方向吗？
我添加了一张示例照片：黄色表示“活着”类别，绿色表示“死亡”类别。

非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78427741/merge-and-subtract-annotations-in-coco-segmentation-json-format</guid>
      <pubDate>Sat, 04 May 2024 04:11:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 GAN 模型训练在 90 次迭代时停止？</title>
      <link>https://stackoverflow.com/questions/78425198/why-does-my-gan-model-training-stop-at-90-iterations</link>
      <description><![CDATA[我正在训练一个cycleGAN模型，每个域40张图片。 epoch 应该为 50，batch_size=1，总迭代次数为 2000，batch_per_epoch 为 40，但是模型在迭代 90 次后停止训练，不存在甚至将 90 视为 true 且模型停止的条件.
def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, 数据集, epochs=1):
    # 定义训练运行的属性
    n_epochs, n_batch, = epochs, 1 #batch size固定为1，如论文中建议的
    # 确定鉴别器的输出正方形形状
    n_patch = d_model_A.output_shape[1]
    # 解压数据集
    trainA, trainB = 数据集
    # print(trainA.shape,trainB.shape)
    # 为假图像准备图像池
    池A，池B = 列表（），列表（）
    # 计算每个训练时期的批次数
    bat_per_epo = int(len(trainA) / n_batch)
    # 计算训练迭代次数
    n_steps = bat_per_epo * n_epochs
    
    打印（n_steps，bat_per_epo）
    # 手动枚举纪元
    对于范围内的 i（n_steps）：
        # 从每个域（A和B）中选择一批真实样本
        X_realA, y_realA =generate_real_samples(trainA, n_batch, n_patch)
        X_realB, y_realB =generate_real_samples(trainB, n_batch, n_patch)
        # 使用 B to A 和 A to B 生成器生成一批假样本。
        X_fakeA, y_fakeA =generate_fake_samples(g_model_BtoA, X_realB, n_patch)
        X_fakeB, y_fakeB =generate_fake_samples(g_model_AtoB, X_realA, n_patch)
        # 更新池中的假图像。请记住，论文建议使用 50 个图像的缓冲区
        X_fakeA = update_image_pool(poolA, X_fakeA)
        X_fakeB = update_image_pool(poolB, X_fakeB)
        # 通过复合模型更新生成器 B-&gt;A
        # print(类型(X_realA),类型(X_realB),类型(X_fakeA),类型(X_fakeB),类型(y_realA),类型(y_realB),类型(y_fakeA),类型(y_fakeB))
        
        g_loss2 = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])
        
        # 更新 A 的鉴别器 -&gt; [真/假]
        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)
        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)
        
        # 通过复合模型更新生成器 A-&gt;B
        g_loss1 = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])
        # 更新 B 的鉴别器 -&gt; [真/假]
        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)
        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)
        
        # 总结性能
        #由于我们的批量大小=1，迭代次数将与数据集的大小相同。
        #在一个纪元中，迭代次数等于图像数量。
        #如果你有 100 张图像，那么 1 epoch 就是 100 次迭代
        print(&#39;迭代&gt;%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]&#39; % (i+1, dA_loss1,dA_loss2, dB_loss1 ,dB_loss2, g_loss1,g_loss2))
        # 定期评估模型性能
        #如果批量大小（总图像）=100，则每 75 次迭代后将总结性能。
        如果 (i+1) % (bat_per_epo * 1) == 0:
            # 绘制 A-&gt;B 翻译
            总结性能（i，g_model_AtoB，trainA，&#39;AtoB&#39;）
            # 情节 B-&gt;A 翻译
            总结性能（i，g_model_BtoA，trainB，&#39;BtoA&#39;）
        如果 (i+1) % (bat_per_epo * 5) == 0:
            # 保存模型
            # #如果批量大小（总图像）=100，模型将在之后保存
            #每 75 次迭代 x 5 = 375 次迭代。
            save_models(i, g_model_AtoB, g_model_BtoA)

这是训练函数，历元传递为 50，最后一个条件：
如果 (i+1) % (bat_per_epo * 5) == 0:
    # 保存模型
    # #如果批量大小（总图像）=100，模型将在之后保存
    #每 75 次迭代 x 5 = 375 次迭代。
    save_models(i, g_model_AtoB, g_model_BtoA)

没有被执行。
随着生成器损失的减少，模型似乎正在训练和改进，生成的图像并没有那么糟糕，因为它只训练了 40 次迭代和 80 次迭代，在第 40 次和 80 次之后生成了图片并保存了模型迭代，然后停止。
这是我得到的结果：
40 次迭代后：

80次迭代后：
]]></description>
      <guid>https://stackoverflow.com/questions/78425198/why-does-my-gan-model-training-stop-at-90-iterations</guid>
      <pubDate>Fri, 03 May 2024 14:13:14 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制以下代码片段的ROC曲线？</title>
      <link>https://stackoverflow.com/questions/64962372/how-to-draw-roc-curve-for-the-following-code-snippet</link>
      <description><![CDATA[我是深度学习新手。我正在尝试为以下代码生成 ROC 曲线。我正在使用喀拉拉。
类大小为 10，图像为大小为 1001003 的 RGB 图像。
&lt;前&gt;&lt;代码&gt;target_size=(100,100,3)

train_generator = train_datagen.flow_from_directory(&#39;路径&#39;,
    目标大小=目标大小[:-1],
    批量大小=16，
    class_mode=&#39;分类&#39;,
    子集=&#39;训练&#39;,
    种子=随机种子）

有效生成器 = ...

测试生成器 = ...
n_classes = len(set(train_generator.classes))

打印（n_类）

input_layer = keras.layers.Input(shape=target_size)

conv2d_1 = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=1, padding=&#39;same&#39;,
激活=&#39;relu&#39;,
                           kernel_initializer=&#39;he_normal&#39;)(input_layer)

batchnorm_1 = keras.layers.BatchNormalization()(conv2d_1)
maxpool1=keras.layers.MaxPool2D(pool_size=(2,2))(batchnorm_1)


conv2d_2 = keras.layers.Conv2D(filters=32, kernel_size=(3,3), strides=1, padding=&#39;same&#39;,
激活=&#39;relu&#39;,
                           kernel_initializer=&#39;he_normal&#39;)(maxpool1)
batchnorm_2 = keras.layers.BatchNormalization()(conv2d_2)

maxpool2=keras.layers.MaxPool2D(pool_size=(2,2))(batchnorm_2)


展平 = keras.layers.Flatten()(maxpool2)
稠密_1 = keras.layers.Dense(256, 激活=&#39;relu&#39;)(展平)

稠密_2 = keras.layers.Dense(n_classes, 激活=&#39;softmax&#39;)(dense_1)



模型= keras.models.Model（input_layer，dense_3）

model.compile(优化器=keras.optimizers.Adam(0.001),
          损失=&#39;分类交叉熵&#39;，
          指标=[&#39;acc&#39;])
模型.summary()

model.fit_generator（生成器=train_generator，validation_data=valid_generator，
                纪元=200）
                
分数 = model.evaluate_generator(test_generator)

打印（分数）

我想看到曲线并生成 ROC 曲线。请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/64962372/how-to-draw-roc-curve-for-the-following-code-snippet</guid>
      <pubDate>Mon, 23 Nov 2020 03:58:45 GMT</pubDate>
    </item>
    </channel>
</rss>