<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 05 Jun 2024 21:15:40 GMT</lastBuildDate>
    <item>
      <title>使用 LLM 模型或其他实践在大型数据集中识别名字和姓氏的最佳实践是什么？</title>
      <link>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78583245/what-are-the-best-practices-to-identify-first-and-last-name-in-large-datasets-us</guid>
      <pubDate>Wed, 05 Jun 2024 20:00:15 GMT</pubDate>
    </item>
    <item>
      <title>EasyOCR TypeError：Reader.__init__() 得到了一个意外的关键字参数“detection”</title>
      <link>https://stackoverflow.com/questions/78582788/easyocr-typeerror-reader-init-got-an-unexpected-keyword-argument-detecti</link>
      <description><![CDATA[我尝试使用 easyocr 包，但出现以下错误
reader = easyocr.Reader([&#39;en&#39;], detection=&#39;DB&#39;, identification = &#39;Transformer&#39;)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Reader.init() 获得了意外的关键字参数“detection”
我刚开始使用 ocr 包。有谁能帮我解决这个问题
在官方仓库中，他们也包含了这些参数，但现在出现了错误
, ]]></description>
      <guid>https://stackoverflow.com/questions/78582788/easyocr-typeerror-reader-init-got-an-unexpected-keyword-argument-detecti</guid>
      <pubDate>Wed, 05 Jun 2024 18:02:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么卡方与orange3和python不同？</title>
      <link>https://stackoverflow.com/questions/78582697/why-chi-square-is-differ-from-orange3-and-python</link>
      <description><![CDATA[*我计算了平方的种类，但是我从orang3程序和python得到了不同的结果，有什么原因吗？
*这是我从 python 得到的数字
0个(毫升) 18.932143 0.755599
价格指数（克） 22.009615 0.519671
2毫克（毫克）84.000000 0.448668
3 件（克） 49.275000 0.382270
4年价格(克) 19.560714 0.848676
5 由 Google 数字化 13.391551 0.643942
*这是我通过orange3得到的号码
橙色3卡方数
*这是我使用的表的所有信息
仅供参考
*这是我使用的python代码
导入 pandas 作为 pd
导入 scipy.stats
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
从 matplotlib 导入 font_manager ， rc

font_path = “C:/Windows/Fonts/malgun.ttf” # Windows 的“Malgun Gothic”屏幕
字体 = font_manager.FontProperties(fname=font_path).get_name()
rc(&#39;字体&#39;, 系列=字体)

数据 = pd.read_csv(&#39;C:/Users/tlotr/OneDrive/Entertainment/BYDIET/Calorcateglrized_calorcateglrized.csv&#39;, 编码=&#39;euc-kr&#39;);
数据.info()

Variables = [&#39;浓度(ml)&#39;, &#39;含量浓度(g)&#39;, &#39;浓度浓度(mg)&#39;, &#39;浓度浓度(g)&#39;, &#39;浓度浓度(g)&#39; , &#39;雪花雪花(g)&#39; ]

chi2_结果 = []

对于变量中的 var：
contingency_table = pd.crosstab(data[&#39;languageC&#39;], data[var]);
chi2, p, _, _ = stats.chi2_contingency(contingency_table);
chi2_结果。追加（（var，chi2，p））

chi2_results_df = pd.DataFrame(chi2_results, columns=[&#39;变量&#39;, &#39;Chi2&#39;, &#39;p 值&#39;]);
打印（chi2_results_df）
plt. 图（图大小=(12, 8)）
sns.barplot(x=&#39;变量&#39;, y=&#39;Chi2&#39;, data=chi2_df_results);
plt.title(&#39;美国&#39;)
plt.xlabel(&#39;标签&#39;)
plt.ylabel(&#39;Chi2 값&#39;)
plt.xticks（旋转=45）
plt.tight_layout()
plt . 显示 ( )


*这是我用的Orange3
Orage3 GUI]]></description>
      <guid>https://stackoverflow.com/questions/78582697/why-chi-square-is-differ-from-orange3-and-python</guid>
      <pubDate>Wed, 05 Jun 2024 17:39:06 GMT</pubDate>
    </item>
    <item>
      <title>给定的梯度下降代码是按顺序还是同时更新参数？</title>
      <link>https://stackoverflow.com/questions/78582076/is-the-given-code-for-gradient-descent-updating-the-paraments-sequentially-or-si</link>
      <description><![CDATA[我是机器学习的新手，一直在学习梯度下降算法。我相信此代码使用同时更新，即使它看起来像是顺序更新。由于偏导数的值是在更新 w 或 b 之前计算的，即从原始 w 和 b 计算，因此应用于单个 w、b 的算法是从原始值应用的。我错了吗？

dj_dw=((w*x[i]+b-y[i])*x[i])/m
dj_db=(w*x[i]+b-y[i])/m
w=w-a*dj_dw
b=b-a*dj_db

语言是 python3。
x 和 y 是训练集。
w 和 b 是应用算法的参数。
我正在使用梯度下降算法进行线性回归。
dj_dw 是均方误差成本函数关于 w 的偏微分。 dj_db 也是如此。
如有错误，敬请原谅，我是新手。
我尝试使用 gemini 和 chatgpt 进行交叉检查，他们说这是连续的，因此才造成混淆]]></description>
      <guid>https://stackoverflow.com/questions/78582076/is-the-given-code-for-gradient-descent-updating-the-paraments-sequentially-or-si</guid>
      <pubDate>Wed, 05 Jun 2024 15:28:51 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用来自不同实验条件的数据来训练和测试 k-NN 分类器吗？</title>
      <link>https://stackoverflow.com/questions/78581759/can-i-train-and-test-a-k-nn-classifier-on-data-from-different-experimental-condi</link>
      <description><![CDATA[我有一些关于单个神经元群体的数据，我想看看在刺激前基线期间观察到的活动模式是否与刺激出现时观察到的活动模式具有相似的结构。基本上，当预期刺激（在基线）与显示的刺激相同时，我预计解码准确度只会略低，但当预期和实际刺激不匹配时，我预计它们之间的活动模式会有所不同，这将导致解码性能比预期和刺激匹配时更差（即前一种情况）。
我知道 k-最近邻分类器的工作原理，也知道如何实现它。我不知道这是否是一种常见/合理的方法。
我尝试使用这种方法寻找出版物，但我没有找到任何出版物，坦率地说，我不确定我是否使用了正确的搜索词...
任何帮助 - 以解释、链接、文献参考、搜索词的形式 - 都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78581759/can-i-train-and-test-a-k-nn-classifier-on-data-from-different-experimental-condi</guid>
      <pubDate>Wed, 05 Jun 2024 14:36:05 GMT</pubDate>
    </item>
    <item>
      <title>将图像置于中心并在导出时添加背景</title>
      <link>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</link>
      <description><![CDATA[我想自动完成所有这些操作：

选择图像中的对象
在此对象上裁剪我的图像
裁剪为 1:1 的宽高比，在此对象周围留出一点空隙
以 800x800px 的 JPG 格式导出我的图像，我的对象位于图像中心，背景为白色。

我在 win11 64 位上
我做了什么：

安装 Python 并创建环境
安装opencv-python-headless、pillow、numpy、Pytorch以用于 CUDA 11.8
克隆存储库 segment-anything.git 并使用 PIP 安装它
下载sam_vit_b_01ec64.pth

像这样对 py 文件进行编码：
import os
import cv2
import numpy as np
from PIL import Image
from fragment_anything import sam_model_registry, SamAutomaticMaskGenerator

def load_image(image_path):
return cv2.imread(image_path)

def save_image(image, path):
cv2.imwrite(path + &#39;.jpg&#39;, image)

def select_object(image):
sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;sam_vit_b_01ec64.pth&quot;)
mask_generator = SamAutomaticMaskGenerator(sam)
mask = mask_generator.generate(image)
largest_mask = max(masks, key=lambda x: x[&#39;area&#39;])
返回 largest_mask[&#39;segmentation&#39;]

def crop_to_object(image, mask):
x, y, w, h = cv2.boundingRect(mask.astype(np.uint8))
padding = 5
x = max(0, x - padding)
y = max(0, y - padding)
w = min(image.shape[1] - x, w + 2 * padding)
h = min(image.shape[0] - y, h + 2 * padding)

cropped_image = image[y:y+h, x:x+w]
返回 cropped_image

def resize_to_square(image, size=800):
h, w = image.shape[:2]
scale = size / max(h, w)
new_h, new_w = int(h * scale), int(w * scale)
resized_image = cv2.resize(image, (new_w, new_h), 插值=cv2.INTER_LANCZOS4)

new_image = np.ones((size, size, 3), dtype=np.uint8) * 255

top = (size - new_h) // 2
left = (size - new_w) // 2
bottom = top + new_h
right = left + new_w

new_image[top:top+new_h, left:left+new_w] = resized_image

return new_image

def process_image(image_path, output_path):

image = load_image(image_path)
mask = select_object(image)
cropped_image = crop_to_object(image, mask)
final_image = resize_to_square(cropped_image, 800)
save_image(final_image, output_path + &#39;.jpg&#39;)

def process_folder(input_folder, output_folder):

如果 os.path.exists(output_folder):
os.makedirs(output_folder)

对于 root、_、os.walk(input_folder) 中的文件：
对于 filename in files:
如果 filename.lower().endswith((&#39;.png&#39;, &#39;.jpg&#39;, &#39;.jpeg&#39;, &#39;.bmp&#39;, &#39;.tiff&#39;)):
input_path = os.path.join(root, filename)

relative_path = os.path.relpath(input_path, input_folder)
output_path = os.path.join(output_folder,relative_path)

output_dir = os.path.dirname(output_path)
如果 os.path.exists(output_dir):
os.makedirs(output_dir)

尝试：
process_image(input_path, output_path)
print(f&quot;已处理 {input_path}&quot;)
except Exception as e:
print(f&quot;无法处理 {input_path}: {e}&quot;)

if __name__ == &quot;__main__&quot;:
input_folder = &quot;&quot;
output_folder = &quot;&quot;
process_folder(input_folder, output_folder)

发生了什么：我有一张 800x800 像素的 jpg 图片。但背景是黑色的，根本不在中心。
有人能帮我理解我错过了什么吗？
提前谢谢，
Cyril]]></description>
      <guid>https://stackoverflow.com/questions/78581619/center-an-image-and-adding-a-background-at-export</guid>
      <pubDate>Wed, 05 Jun 2024 14:13:43 GMT</pubDate>
    </item>
    <item>
      <title>llama-index、uncharted 和 llama2:7b 在本地运行以生成索引</title>
      <link>https://stackoverflow.com/questions/78581041/llama-index-uncharted-and-llama27b-run-locally-to-generate-index</link>
      <description><![CDATA[我想在本地使用 llama-index 和 ollama 以及 llama3:8b 来索引 utf-8 json 文件。我没有 gpu。我使用 uncharted 将文档转换为 json。现在，如果没有 GPU 就无法在本地使用 llama-index，我想使用 hugging face 推理 API。但我不确定它是否免费。有人能建议一种方法吗？
这是我的 python 代码：


from llama_index.core import Document, SimpleDirectoryReader, VectorStoreIndex
from llama_index.llms.ollama import Ollama
import json
from llama_index.core import Settings

# 将 JSON 文档转换为 LlamaIndex Document 对象
with open(&#39;data/UBER_2019.json&#39;, &#39;r&#39;,encoding=&#39;utf-8&#39;) as f:
json_doc = json.load(f)
documents = [Document(text=str(doc)) for doc in json_doc]

# 使用本地 LLM 初始化 Ollama
ollama_llm = Ollama(model=&quot;llama3:8b&quot;)
Settings.llm = ollama_llm

# 使用本地 LLM 创建索引
index = VectorStoreIndex.from_documents(documents)#, llm=ollama_llm)


但我一直收到没有 OPENAI 密钥的错误。我想使用 llama2，这样就不需要 OPENAI 密钥了
有人能指出我做错了什么吗？我还可以免费使用 huggingfaceinference API 对本地 json 文件进行索引吗？]]></description>
      <guid>https://stackoverflow.com/questions/78581041/llama-index-uncharted-and-llama27b-run-locally-to-generate-index</guid>
      <pubDate>Wed, 05 Jun 2024 12:38:14 GMT</pubDate>
    </item>
    <item>
      <title>ViTHybrid 无法添加位置嵌入和嵌入</title>
      <link>https://stackoverflow.com/questions/78581025/vithybrid-cant-add-positional-embeddings-and-embeddings</link>
      <description><![CDATA[当我创建一个新模型并为其提供随机大小的数据作为输入 [1, 3, 224, 224] 时，我得到了 embeddings 和 positional_embeddings 维度错误
model = ViTHybridModel(ViTHybridConfig(backbone_config = {
&quot;depths&quot;: [3, 4, 16, 3],
&quot;hidden_​​sizes&quot;: [128, 256, 512, 1024],
&quot;layer_type&quot;: &quot;bottleneck&quot;
}, image_size=224)

torch.Size([1, 3, 224, 224])
Traceback（最近一次调用最后一次）：
文件 &quot;D:\sddif\itestingvit.py&quot;，第 17 行，位于&lt;module&gt;
输出 = 模型 (输入 [&quot;pixel_values&quot;])
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1532 行，位于 _wrapped_call_impl
返回 self._call_impl(*args, **kwargs)
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1541 行，位于 _call_impl
返回 forward_call(*args, **kwargs)
文件&quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\models\vit_hybrid\modeling_vit_hybrid.py&quot;，第 588 行，在 forward
embedding_output = self.embeddings(
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1532 行，在 _wrapped_call_impl
return self._call_impl(*args, **kwargs)
文件 &quot;C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py&quot;，第 1541 行，在 _call_impl
return forward_call(*args, **kwargs)
文件“C:\Users\ermak\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\models\vit_hybrid\modeling_vit_hybrid.py”，第 128 行，正向
embeddings = embeddings + self.position_embeddings
RuntimeError：张量 a (50) 的大小必须与非单例维度 1 上的张量 b (577) 的大小匹配

]]></description>
      <guid>https://stackoverflow.com/questions/78581025/vithybrid-cant-add-positional-embeddings-and-embeddings</guid>
      <pubDate>Wed, 05 Jun 2024 12:35:10 GMT</pubDate>
    </item>
    <item>
      <title>最新版本的 Mask-RCNN 和 TensorFlow 版本的错误</title>
      <link>https://stackoverflow.com/questions/78579595/newest-version-of-working-mask-rcnn-errors-on-tensorflow-version</link>
      <description><![CDATA[我一直在尝试在生物实验室的细胞图像上实现 Mask-RCNN。
我知道 matterport/Mask_RCNN 无法正常工作，因为它使用的是 TensorFlow 1，所以我尝试使用使用 TensorFlow 2 的 github repos。但我仍然觉得有些已经过时了，或者我的设置不匹配，它没有运行。我一直在使用这个：https://github.com/ahmedfgad/Mask-RCNN-TF2
是否有 2024 年或 2023 年的最新版本可以作为我的基础？我真的很想尝试在我的系统上实现，但是当我尝试从同一位置修复问题时，不断收到类似 ModuleNotFoundError: 没有名为“keras.engine”的模块 或 ERROR: 找不到满足要求 tensorflow==2.2.0 的版本的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78579595/newest-version-of-working-mask-rcnn-errors-on-tensorflow-version</guid>
      <pubDate>Wed, 05 Jun 2024 08:11:47 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Keras 创建小批量？</title>
      <link>https://stackoverflow.com/questions/78577993/how-to-create-minibatch-with-keras</link>
      <description><![CDATA[假设我有 20 个 5*5 张量。我该如何创建一个 batchsize = 20 的数据集？
在阅读了很多帖子后，我认为最有可能的解决方案是：
步骤 1.使用 tf.dataset.from_tensors 创建 20 个数据集，每个数据集包含一个 5*5 张量。
步骤 2.使用 tf.dataset.zips 将 20 个数据集压缩为一个大数据集。
步骤 3.不要在 model.fit 中声明 batch_size=20，因为从官方文档中可以看到，“如果您的数据是数据集、生成器或 keras.utils.PyDataset 实例的形式，请不要指定 batch_size（因为它们会生成批次）”
我看不出上面的步骤是如何生成批次的。是不是因为数据集的形状（20*5*5）意味着小批次大小应该是 20，这等于第一个参数？
如果以下陈述是正确的。假设我想将批次大小减少到 10。我需要做的就是在步骤 1 之后先将两个数据集压缩 10 次，然后将新的 10 个数据集压缩为最终数据集。这是正确的吗？
此外，我尝试使用 tf.dataset.batch(20) 在步骤 2 之后应用大数据集。在我 tf.print 之前和之后的这个批处理命令的最终数据集之后，我得到的输出是：
之前：压缩数据集 (array(shape(5*5), array(shape(5*5)), …)
之后：批处理数据集 (array(shape(none*5*5), array(shape(none*5*5)), …)
形状不同。输出值后，我注意到应用 tf.dataset.batch(20) 后的实际形状为每个数组变为 1*5*5。
这个命令 tf.dataset.batch(20) 在我的例子中是无用的还是我应该在步骤 2 之后使用它？
官方文档只使用了一个例子是无量纲数组。所以我不知道这个命令对高阶张量如何起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78577993/how-to-create-minibatch-with-keras</guid>
      <pubDate>Tue, 04 Jun 2024 22:21:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么会出现此错误？“TransformerMixin.fit_transform() 缺少 1 个必需的位置参数：'X'”-机器学习相关问题 [重复]</title>
      <link>https://stackoverflow.com/questions/78575884/why-is-this-error-coming-up-transformermixin-fit-transform-missing-1-require</link>
      <description><![CDATA[我有这行代码
cols_to_scale = [&#39;tenure&#39;,&#39;MonthlyCharges&#39;,&#39;TotalCharges&#39;]

来自 sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler

df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])

这会引发此错误，为什么？
TypeError Traceback (most recent call last)
Cell In[77], line 6
3 来自 sklearn.preprocessing import MinMaxScaler
4 scaler = MinMaxScaler
----&gt; 6 df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])

TypeError: TransformerMixin.fit_transform() 缺少 1 个必需的位置参数：“X”

不知道为什么会发生此错误。]]></description>
      <guid>https://stackoverflow.com/questions/78575884/why-is-this-error-coming-up-transformermixin-fit-transform-missing-1-require</guid>
      <pubDate>Tue, 04 Jun 2024 13:58:35 GMT</pubDate>
    </item>
    <item>
      <title>无论如何在 tensorflow 2.16 上使用 tensorflow 的 set_session</title>
      <link>https://stackoverflow.com/questions/78575816/anyway-to-use-tensorflows-set-session-on-tensorflow-2-16</link>
      <description><![CDATA[我完全不知道该如何为项目导入这个 set_session。我尝试过使用：
from tensorflow.compat.v1.keras.backend import set_session

and
from tensorflow.keras.backend import set_session`

（以及许多其他变体）
一切都没希望了吗？我使用的是 python 3.11.1、tensorflow 2.16.1（安装 keras 3.3.3）

我希望让这个程序尽可能容易运行，但似乎唯一的方法可能是安装旧版本的 tensorflow（使用 pip 无法做到这一点）
set_session 应该可以工作，我已经让它在旧版本的 tensorflow 上运行，我只是希望它能够友好地下载我的程序，而不需要经历这种挣扎。我也用过这个：
def get_session(gpu_fraction): #为 TensorFlow 设置 GPU 内存使用量
config = tf.compat.v1.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction
return tf.compat.v1.Session(config=config)
]]></description>
      <guid>https://stackoverflow.com/questions/78575816/anyway-to-use-tensorflows-set-session-on-tensorflow-2-16</guid>
      <pubDate>Tue, 04 Jun 2024 13:45:55 GMT</pubDate>
    </item>
    <item>
      <title>请问如何改进我的混合 1D CNN 和 Bi-LSTM 模型以实现高精度</title>
      <link>https://stackoverflow.com/questions/78575294/please-how-can-improve-my-hybrid-1d-cnn-and-bi-lstm-model-for-high-accuracy</link>
      <description><![CDATA[我正在构建一个混合 1D CNN 和 Bi-LSTM 模型，用于预测心脏病。然而，该模型的准确率是 0.73，但我想将其提高到 0.80 及以上。请就如何改进此模型提供任何帮助。谢谢。我期望准确率能稍微提高一点。
我的输入形状如下所示 (70000,13)
import tensorflow as tf 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling2D, MaxPooling1D, LSTM, Bidirectional, Dense, Flatten, Dropout, Input, BatchNormalization, Reshape
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from sklearn.utils.class_weight import compute_class_weight 

dataset = pd.read_csv(&#39;heart_disease.csv&#39;)
dataset.shape

#预处理数据集
X = dataset.drop(columns=[&#39;disease&#39;])
y = dataset[&#39;disease&#39;]

`#标准化特征
scaler = StandardScaler()
X = scaler.fit_transform(X)
# print(X)

#将数据分成训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

print(&quot;训练集大小：&quot;, X_train.shape)
print(&quot;测试集大小：&quot;, X_test.shape)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

#重塑数据1D CNN + Bi-LSTM 模型
X_train_dl = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))
X_test_dl = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))

#print(X_train_dl)
#print(X_test_dl)

# 构建混合模型

model = Sequential()
model.add(Input(shape=(X_train_dl.shape[1], X_train_dl.shape[2])))

model.add(Conv1D(filters=32, kernel_size=2,activation=&#39;relu&#39;))

model.add(MaxPooling1D(pool_size=2))
model.add(BatchNormalization(momentum=0.99))

model.add(Conv1D(filters=64, kernel_size=2,activation=&#39;relu&#39;))
model.add(MaxPooling1D(pool_size=2))
model.add(BatchNormalization(momentum=0.99))

model.add(Bidirectional(LSTM(50, return_sequences=True)))
model.add(Dropout(0.5))
model.add(Flatten())

`model.add(Dense(128,activation=&#39;relu&#39;, kernel_regularizer=tf.keras.regularizers.l2(0.01)))
model.add(Dropout(0.5))

model.add(Dense(1,activation=&#39;sigmoid&#39;))

#编译模型

model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate = 0.0001), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 提前停止回调
early_stopping = EarlyStopping(monitor=&#39;val_loss&#39;, waiting=20, restore_best_weights=True)

# 训练模型
history = model.fit(X_train_dl, y_train, epochs=10, batch_size=32, validation_data=(X_test_dl, y_test), callbacks=[early_stopping])

# 保存模型
model.save(&#39;my_model.keras&#39;)

# 评估模型
loss accuracy = model.evaluate(X_test_dl, y_test)
print(f &quot;混合模型 (1D CNN + Bi-LSTM) 准确率： {准确度：.2f}&quot;)

]]></description>
      <guid>https://stackoverflow.com/questions/78575294/please-how-can-improve-my-hybrid-1d-cnn-and-bi-lstm-model-for-high-accuracy</guid>
      <pubDate>Tue, 04 Jun 2024 12:04:25 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用 KL 散度损失进行知识蒸馏。损失太高了</title>
      <link>https://stackoverflow.com/questions/78452655/trying-to-perform-knowledge-distillation-using-kl-divergence-loss-the-loss-is</link>
      <description><![CDATA[KL 散度损失过高
我正在尝试进行知识提炼。对于我的学生损失，我使用了交叉熵损失，对于我的知识蒸馏损失，我尝试使用 KL 散度损失。
这是我用于 KL 散度损失的代码。
class KLDivLoss(nn.Module):
    def __init__(self,ignore_index=-1, reduction=&quot;batchmean&quot;, log_target=False):
        super(KLDivLoss, self).__init__()
        self.reduction = reduction
        self.log_target = log_target
        self.ignore_index = ignore_index

    def forward(self, preds_S, preds_T, T =1.0, alpha = 1.0):
        preds_T[0] = preds_T[0].detach()  # 分离教师预测
        pred_1 = torch.sigmoid(preds_T[0]/T) # 白色
        pred_0 = 1 - pred_1
        preds_teacher = torch.cat((pred_0, pred_1), dim=1)
        assert preds_S[0].shape == preds_teacher.shape, “输入和目标形状必须匹配 KLDivLoss”
       stu_prob = F.log_softmax(preds_S[0]/T, dim=1)
        kd_loss = F.kl_div(stu_prob, 
                           preds_teacher, 
                             reduction=&#39;batchmean&#39;,
                           ) * T * T
        return {&#39;loss&#39;: kd_loss}

我从中得到的值非常大。我只是添加了学生模型的知识蒸馏损失和交叉熵损失。由于我的 CE 损失非常小，这全都来自 KLdiv 损失。你能告诉我如何减少损失吗？或者如果我做错了什么。
在此处输入图片说明
我尝试使用 KL div 损失，其中温度 =1
我的老师模型以张量 [8,1,224,224] 的形式给出输出，因为它用于像素的二进制预测，而我的学生模型以 [8,2,224,224] 的形式给出输出，其中 0 属于黑色类，1 属于白色。
因此，为了将它们与 KL div 损失相匹配，我使用 sigmoid 函数来获取白色类的概率和 1 - 黑色的白色概率。然后将它们连接起来形成一个大小为 [8,2,224,224] 的张量，这与学生张量相似。
然后我尝试执行 KL 发散。我遭受的损失非常大]]></description>
      <guid>https://stackoverflow.com/questions/78452655/trying-to-perform-knowledge-distillation-using-kl-divergence-loss-the-loss-is</guid>
      <pubDate>Thu, 09 May 2024 06:27:53 GMT</pubDate>
    </item>
    <item>
      <title>Statsmodels - 使用经过训练的 arima 模型通过明确提供 endog 值来进行手动点预测</title>
      <link>https://stackoverflow.com/questions/56971901/statsmodels-use-trained-arima-model-to-do-manual-point-prediction-by-explicitl</link>
      <description><![CDATA[我正在使用 statsmodels 库来提供 ARIMAX 模型，用于预测时间序列。我有一个相当奇怪的问题 - 如何通过明确提供用于预测的 endog 和 exog 变量来强制训练模型执行完全手动点预测？
为了给你一个想法，我使用 2000-2017 年的年度数据训练我的模型，其中我根据前几年的劳动力和一堆 exog 变量预测公司未来的劳动力。它效果很好。问题是，2018 年和 2019 年，公司大幅扩大了员工数量，这是一次性的商业决策，我们也知道，从商业角度来看，我们在 2000-2017 年训练的模型是“正确的”。
我想要做的是使用我在 2000-2017 年训练的模型，并提供 2020 年的预测，同时明确提供 2018 年和 2019 年的“实际值”。这样，我们就可以确保模型不会试图适应这种一次性的跳跃，从而降低其质量。但我该怎么做呢？请注意，我使用 AR(2) 模型 - 因此我需要提供前 2 年的数据。
我见过一些 statsmodels 方法，它们允许您：
1) 选择经过训练的 ARIMAX 模型
2) 明确提供前 2 年的 exog 变量值
3) 明确提供前 2 年的 endog 值
4) 仅提供单点预测
predict 和 forecast 方法仅允许您指定要提供样本外预测的步数，但不允许明确提供用于预测的新内源值]]></description>
      <guid>https://stackoverflow.com/questions/56971901/statsmodels-use-trained-arima-model-to-do-manual-point-prediction-by-explicitl</guid>
      <pubDate>Wed, 10 Jul 2019 13:34:27 GMT</pubDate>
    </item>
    </channel>
</rss>