<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 18 Apr 2024 15:14:47 GMT</lastBuildDate>
    <item>
      <title>Keyence Lightning 模块需要紧急输入</title>
      <link>https://stackoverflow.com/questions/78348479/urgent-inputs-requried-on-keyence-lightning-module</link>
      <description><![CDATA[需要紧急输入。我正在用 baslar 相机做一个视觉项目。我的客户给了我 Keyence 多光谱环形灯作为照明系统。还提供CA-DC60E灯光模块和CV-X450A驱动模块。如何连接相机并连续打开环形灯？
如果我将环形灯连接到CA-DC60E并给雷电控制器提供24V电源，灯会持续亮起吗？
我尝试给 CV-X450A 驱动模块供电，因为 lightninig 模块已经连接到它，但灯没有打开。我也收到错误灯红色]]></description>
      <guid>https://stackoverflow.com/questions/78348479/urgent-inputs-requried-on-keyence-lightning-module</guid>
      <pubDate>Thu, 18 Apr 2024 14:59:06 GMT</pubDate>
    </item>
    <item>
      <title>重新创建研究论文的结果</title>
      <link>https://stackoverflow.com/questions/78348126/recreating-results-from-research-paper</link>
      <description><![CDATA[因此，我一直在尝试重现这篇论文（神经协同过滤）的结果。
我使用的数据集与这个非常相似。
我明白我应该将我的数据分成训练集和测试集。
我的问题是，我是否应该自己创建 test.negative 文件，或者它是否由代码中的负采样自动处理（它基本上包含基于数据缺失的负反馈）。
非常感谢您的反馈！提前致谢。
这是本文在github上的官方实现。]]></description>
      <guid>https://stackoverflow.com/questions/78348126/recreating-results-from-research-paper</guid>
      <pubDate>Thu, 18 Apr 2024 14:10:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 AdamW 算法的张量流模型中的 MeanAbsolutePercentageError() 错误</title>
      <link>https://stackoverflow.com/questions/78347984/error-with-meanabsolutepercentageerror-in-tensorflow-model-with-adamw-algorith</link>
      <description><![CDATA[我试图找到人工神经网络中 2 个隐藏层的最佳节点数。我想使用 MeanAbsolutePercentageError 来评估模型的准确性。这是有错误的代码小节：
这是我的代码：
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从tensorflow.keras.losses导入MeanAbsoluteError
从tensorflow.keras.utils导入set_random_seed
从tensorflow.keras.losses导入MeanAbsolutePercentageError
从tensorflow.keras.optimizers导入AdamW
设置随机种子（777）

结果 = []
对于范围 (1, 8) 内的 A：
  对于范围 (1, 8) 内的 B：

    设置随机种子（777）
    模型=顺序（层=[密集（单位=A，激活=“elu”，input_shape=[TRAIN_X.columns.size]），
                                        密集（单位=B，激活=“elu”），
                                        密集(单位=1)])
    MODEL.compile( 优化器=AdamW() ,
                  损失=MeanAbsolutePercentageError() )
    模型.fit( TRAIN_X/10 , TRAIN_Y/10 ,
                          validation_data=[ TEST_X / 10 , TEST_Y / 10 ] , epochs=300 )
    预测 = 模型.预测( TEST_X / 10 ) * 10
    C = MeanAbsolutePercentageError( 预测 , TEST_Y )
    结果.append([A, B, C])

我期望结果采用 [A,B,C] 格式的数组，这意味着 A = 第一个隐藏层中的 # 个节点，B = 第二个隐藏层中的 # 个节点，C = 平均绝对百分比误差。但是，我收到了这个错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-10-59489aa7b7de&gt;在&lt;细胞系：10&gt;()
     20 validation_data=[ TEST_X / 10 , TEST_Y / 10 ] , epochs=300 )
     21 预测 = 模型.预测( TEST_X / 10 ) * 10
---&gt; 22 C = MeanAbsolutePercentageError( 预测 , TEST_Y )
     23 结果.append([A,B,C])

3帧
/usr/local/lib/python3.10/dist-packages/keras/src/utils/losses_utils.py 中的 validate(cls, key)
     第85章
     86 def 验证（cls，密钥）：
---&gt; 87 如果 key 不在 cls.all() 中：
     88 引发值错误（
     89 f&#39;无效的还原键：{key}。预期的键为“{cls.all()}”

ValueError：具有多个元素的数组的真值不明确。使用 a.any() 或 a.all()
]]></description>
      <guid>https://stackoverflow.com/questions/78347984/error-with-meanabsolutepercentageerror-in-tensorflow-model-with-adamw-algorith</guid>
      <pubDate>Thu, 18 Apr 2024 13:53:29 GMT</pubDate>
    </item>
    <item>
      <title>如何利用RMS获取首次预测时间</title>
      <link>https://stackoverflow.com/questions/78347968/how-to-obtain-the-first-prediction-time-by-using-rms</link>
      <description><![CDATA[我正在尝试实现从论文中找到的这一点：
首先，选取轴承故障采样点中的前l个采样点，计算其均方根值的平均值μlRMS和标准差sigmaRMS，并建立3σ判据——
相应地基于判断区间[μlRMS − 3σlRMS, μlRMS +3σlRMS]。
2) 其次，计算第l+1个点FPTl+1的RMS指数，并与步骤1中的判定区间进行比较。如果其值不在该范围内，则使l=l+1后重新计算判定区间如果其值在此范围内，则触发一次判断。
3）最后，为了避免误触发，以连续3次触发作为最终FPT的识别依据，并使本次FPTl = FPT
论文标题：物理引导神经网络：滚动体剩余使用寿命预测
通过动态使用长短期记忆网络的轴承
降解过程的权重
我完全不明白他们是如何实现这一目标的。如果我计算 RMS，我只有一个值，那么如何从 RMS 获取平均值和标准差。另外，通过尝试我的代码，FPT 在轴承寿命开始时开始。
def find_fpt(数据):
    上= np.mean(数据，轴=1) + np.std(数据，轴=1)
    下= np.mean（数据，轴= 1） - np.std（数据，轴= 1）

    rms_values = np.sqrt(np.mean(样本 ** 2, 轴=1))
    间隔 = [下[0], 上[0]]
    触发 = 0
    对于范围内的 i(len(rms_values))：

        如果间隔[1]&gt;均方根值[i+1]&gt;间隔[0]：
            触发 += 1
            如果触发器== 3：
                返回我
        别的：
            间隔 = [下[i + 1], 上[i + 1]]

这是我尝试编写的代码，但没有成功实现 FPT]]></description>
      <guid>https://stackoverflow.com/questions/78347968/how-to-obtain-the-first-prediction-time-by-using-rms</guid>
      <pubDate>Thu, 18 Apr 2024 13:51:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 识别一维数据中的步长/扭结的卷积神经网络</title>
      <link>https://stackoverflow.com/questions/78347795/convolutional-neural-network-for-step-kink-identification-in-1d-data-using-keras</link>
      <description><![CDATA[我对机器学习还很陌生，并尝试尝试一些实际示例。
目前，我正在尝试实现一个能够检测一维数据中的步骤/扭结的卷积神经网络。
阶跃被定义为随时间变化然后变为恒定的信号，反之亦然。一个例子是机械测试中机器位移发生变化，然后保持恒定。
为了训练模型，我使用以下简单函数生成了一些合成数据：
将 numpy 导入为 np
从张量流导入keras
随机导入
导入数学

def createStepFunction(步骤: int, dy: float = 1.0, tHold: float = 3600.0, dt: float = 100.0):
    t = [0.0]
    y = [0.0]
    对于 _ 在范围内（0，步数）：
        保持时间 = round(tHold*random.random(),0)
        t1 = t[-1] + round(dt*random.random(),0)
        t2 = t1 + 保持时间
        t3 = t2 + round(dt*random.random(),0)
        t4 = t3 + 保持时间

        y1 = y[-1] + dy*random.random()
        y2 = y1
        y3 = y2 - dy*random.random()
        y4 = y3
        t.extend([t1,t2,t3,t4])
        y.extend([y1,y2,y3,y4])

    tInterp = np.arange(0.0,t[-1]+0.5,1.0)
    yInterp = np.interp(tInterp, t, y)
    flag = np.array([1 if (elem in t and elem != 0.0) else 0 for elem in tInterp])
    # flagBool = [True if elem == 1 else False for elem in flag]
    返回 tInterp、yInterp、标志

t、y、标志 = createStepFunction(200)
t = t/np.max(t)
gaussian_noise = np.random.normal(np.mean(y), 5e-4, len(t))
yn = y*高斯噪声
yn = (yn - np.min(yn))/(np.max(yn) - np.min(yn))

我还在数据中添加了一些高斯噪声。结果如下：
示例数据
我的特征是 one-hot 向量，除了台阶/扭结的位置之外，所有位置都为 0，它们在此处被分配了值 1。
我使用此函数创建批量数据：
def createBatches(windowSize: int, arr):
    位置 = 0
    批次 = []

    而 pos + windowSize &lt;长度（arr）：
        值 = arr[pos:pos+windowSize]
        批次.append(值)
        pos += 窗口大小
    
    返回 np.asarray(批次)

窗口大小 = 200
xBatch = createBatches(windowSize, yn)
yBatch = createBatches(窗口大小, 标志)
n_timesteps = xBatch.shape[1]
n_特征 = 1
n_outputs = yBatch.shape[1]

我的 Keras 模型如下所示：
模型 = keras.models.Sequential()
model.add(keras.layers.Conv1D(filters=24，kernel_size=2，activation=&#39;relu&#39;，input_shape=(n_timesteps，n_features)))
model.add(keras.layers.Conv1D(filters=24, kernel_size=2,activation=&#39;relu&#39;))
model.add(keras.layers.Conv1D(filters=24, kernel_size=2,activation=&#39;relu&#39;))
model.add(keras.layers.Conv1D(filters=24, kernel_size=2,activation=&#39;relu&#39;, strides=1))
model.add(keras.layers.MaxPooling1D(pool_size=2))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.Flatten())
model.add（keras.layers.Dense（200，激活=&#39;relu&#39;））
model.add(keras.layers.Dense(n_outputs, 激活=&#39;softmax&#39;))
model.compile（loss=&#39;mean_squared_error&#39;，optimizer=keras.optimizers.Adam（learning_rate=0.05），metrics=[&#39;accuracy&#39;]）
模型.summary()


# 拟合网络
历元 = 1000
批量大小 = 200
详细 = 1

历史= model.fit(xBatch, yBatch, epochs=epochs, batch_size=batch_size, verbose=verbose)

该架构类似于我在一本书中找到的示例。
然而，该模型似乎与所提供的数据不相符。损失并没有明显下降，而且准确率很差。我尝试了各种参数但没有成功。
我真的想知道我错过了什么？我生成的训练数据有问题吗？
是否有可能使用这种方法来达到我的目的？
我真的很感谢任何指导我的帮助。请原谅我可能犯的任何初学者错误。
提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78347795/convolutional-neural-network-for-step-kink-identification-in-1d-data-using-keras</guid>
      <pubDate>Thu, 18 Apr 2024 13:24:11 GMT</pubDate>
    </item>
    <item>
      <title>如何将采集函数应用于正在优化的参数子集？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78347081/how-to-apply-the-acquisition-function-to-a-subset-of-the-parameters-being-optimi</link>
      <description><![CDATA[想象一下您正在处理一个优化问题，并且它有 2 个您正在优化的参数。它还具有一个您无法控制的输出参数，但与系统如何选择前 2 个参数有一定的相关性。我想要做的是将所有三个参数（2 个输入和 1 个输出）参数添加到 GP 模型中，然后仅将采集函数（例如 EI）应用于 2 个输入参数（因为这是我唯一可以更改的 2 个参数）无论我指定的第三个参数的值是什么。这有道理吗？
有没有办法用 scikit-optimize 来做到这一点？或者有其他包支持这个吗？或者我需要手写这个吗？]]></description>
      <guid>https://stackoverflow.com/questions/78347081/how-to-apply-the-acquisition-function-to-a-subset-of-the-parameters-being-optimi</guid>
      <pubDate>Thu, 18 Apr 2024 11:31:48 GMT</pubDate>
    </item>
    <item>
      <title>如何在java中加载预训练模型或onnx模型并运行</title>
      <link>https://stackoverflow.com/questions/78347041/how-to-load-pretrained-model-or-onnx-model-in-java-and-run</link>
      <description><![CDATA[我有两种（普通和onnx）形式的拥抱脸预训练模型，我想在java中加载它并运行，

SamLowe/roberta-base-go_emotions
SamLowe/roberta-base-go_emotions-onnx

我尝试了不同的方法，但无法做到这一点]]></description>
      <guid>https://stackoverflow.com/questions/78347041/how-to-load-pretrained-model-or-onnx-model-in-java-and-run</guid>
      <pubDate>Thu, 18 Apr 2024 11:24:18 GMT</pubDate>
    </item>
    <item>
      <title>如何从 Neural Prophet 模型中提取线性回归系数？</title>
      <link>https://stackoverflow.com/questions/78346142/how-can-i-extract-linear-regression-coefficients-from-a-neural-prophet-model</link>
      <description><![CDATA[我正在使用 Neural Prophet (NP) 作为我正在构建的预测工具的一部分。
我真的希望能够访问我的额外回归量的线性回归系数估计值，以便在我正在整理的一些洞察工作中使用。
在 Prophet 中，我可以使用 regressor_coefficients() 函数来执行此操作，但是我在 NP 文档中找不到有关如何执行此操作的任何内容。
有任何帮助/建议或替代方法吗？
尝试过查看 NP 文档并使用 Prophet 的 regressor_coefficients() 函数，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78346142/how-can-i-extract-linear-regression-coefficients-from-a-neural-prophet-model</guid>
      <pubDate>Thu, 18 Apr 2024 08:57:53 GMT</pubDate>
    </item>
    <item>
      <title>当损失不减少时，我该怎么办？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78345591/when-loss-dont-decrease-what-should-i-do</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78345591/when-loss-dont-decrease-what-should-i-do</guid>
      <pubDate>Thu, 18 Apr 2024 07:24:37 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有类标签的情况下可视化实例预测？</title>
      <link>https://stackoverflow.com/questions/78345121/how-to-visualize-instance-predictions-but-without-class-labels</link>
      <description><![CDATA[导入 matplotlib.pyplot 作为 plt
Predicted_images_path = os.path.abspath(“/content/predicted”)
dataset_dicts_validation = DatasetCatalog.get(&#39;void-detection-2-valid&#39;)
对于 dataset_dicts_validation 中的 d：
    im = cv2.imread(d[“文件名”])
    输出 = 预测器(im)
    v = 展示台(im[:, :, ::-1],
                   元数据=元数据，
                   比例=0.5，
                   instance_mode=ColorMode.IMAGE_BW
    ）
    out = v.draw_instance_predictions(outputs[“instances”].to(“cpu”))
    图 = plt.figure(frameon=False, dpi=1)
    图.set_size_英寸(1024,1024)
    ax = plt.Axes(图, [0., 0., 1., 1.])
    ax.set_axis_off()
    图.add_axes(ax)
    ax.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB),spect=&#39;auto&#39;)
    Fig.savefig(f&quot;{predicted_images_path}/{d[&#39;file_name&#39;].split(&#39;/&#39;)[-1]}&quot;)

分割图像：

我使用 detectorron2 来训练模型并对检测到的空洞进行预测。如何仅标记分段而不使用文字的形状。
二值图像：
]]></description>
      <guid>https://stackoverflow.com/questions/78345121/how-to-visualize-instance-predictions-but-without-class-labels</guid>
      <pubDate>Thu, 18 Apr 2024 05:51:09 GMT</pubDate>
    </item>
    <item>
      <title>滴灌管的自动检测和测量</title>
      <link>https://stackoverflow.com/questions/78344991/automating-detection-and-measurement-of-drip-irrigation-pipes</link>
      <description><![CDATA[我正在使用无人机图像来自动从中提取一些数据。我想自动检测和测量田野中布置的灌溉线的长度，如下所示。我可以采取什么方法来实现这一目标？图像处理中是否有合适的基于规则的技术，例如颜色、边缘检测等？或者我应该使用一些对象检测技术？如果使用这些，注释和训练模型的最佳方法是什么？
该图像如下所示，下面显示了放大版本。

在此图像（上图的放大部分）中，您可以看到滴水线（其颜色始终为黑色，但有时在更复杂的背景和环境中，它们也可能并不总是直线，也可能是弯曲的）

期待听到社区的消息。
问候，
马卡兰德]]></description>
      <guid>https://stackoverflow.com/questions/78344991/automating-detection-and-measurement-of-drip-irrigation-pipes</guid>
      <pubDate>Thu, 18 Apr 2024 05:09:44 GMT</pubDate>
    </item>
    <item>
      <title>使用矩阵分解的复制 ML.NET 示例/教程电影推荐器</title>
      <link>https://stackoverflow.com/questions/78343327/duplication-ml-net-example-tutorial-movie-recommender-using-matrix-factorization</link>
      <description><![CDATA[我是机器学习新手，但我有 C# 经验，这就是为什么我想选择 Ml.net 来熟悉该主题。
当我掌握了这个概念后，我决定创建一个电影推荐模型，该模型将采用以前的评论并推荐具有与 Microsoft ML.NET 教程中提供的相同示例的电影。
我的问题是，当我在创建管道时在下面的函数中构建和训练模型时，我没有看到Recommendation() 的方法调用。顺便说一下，我使用的是VS2022和.NET 8.0。谁能告诉我为什么？
使用 Microsoft.ML；
使用 Microsoft.ML.Trainers；
使用 Microsoft.ML.Data；
使用 Microsoft.ML.Transforms；

ITransformer BuildAndTrainModel（MLContext mlContext，IDataView TrainingDataView）
{
    //第 3 步：通过对 userId 和 movieID 这两个特征进行编码来转换数据。这些编码特征将作为输入提供
    // 到我们的 MatrixFactorizationTrainer。
    var dataProcessingPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: &quot;userIdEncoded&quot;, inputColumnName: nameof(MovieRating.userId))
                   .Append(mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: &quot;movieIdEncoded&quot;, inputColumnName: nameof(MovieRating.movi​​eId)));

    //指定MatrixFactorization训练器的选项
    MatrixFactorizationTrainer.Options 选项 = new MatrixFactorizationTrainer.Options();
    options.MatrixColumnIndexColumnName = &quot;userIdEncoded&quot;;
    options.MatrixRowIndexColumnName = &quot;movieIdEncoded&quot;;
    options.LabelColumnName = &quot;标签&quot;;
    选项.NumberOfIterations = 20;
    选项.ApproximationRank = 100;

    //第4步：创建训练管道
    var TrainingPipeLine = dataProcessingPipeline.Append(mlContext.Recommendation().Transforms.MatrixFactorization(options));

   

    Console.WriteLine(“================训练模型==============”);
    ITransformer模型=trainingPipeLine.Fit(trainingDataView);

    返回模型；
}


我在 Github 代码中进行了一些搜索，但没有得到任何提示。]]></description>
      <guid>https://stackoverflow.com/questions/78343327/duplication-ml-net-example-tutorial-movie-recommender-using-matrix-factorization</guid>
      <pubDate>Wed, 17 Apr 2024 19:10:29 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型中分类数据平均二进制编码方法的澄清</title>
      <link>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</link>
      <description><![CDATA[有很多方法可以将分类数据转换为用于各种统计任务的数值数据。然而，大多数编码方法（例如 One-Hot 编码）会创建更多数据集列，从而产生高维数据。
因此，我引入了一种称为平均二进制编码的方法，该方法在训练模型中应用二进制数据表示。方法如下：

哪里|N|是分类数据X中二进制值的长度，B是分类数据X的二进制表示。
&lt;前&gt;&lt;代码&gt;|分类数据|应用于配方|编码数据|
| ---------------- | -------------------------------------------------- -------------------------------------------------- --| ------------------ |
|男 | (0+1+0+0+1+1+0+1+0+1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0 +1+1+0+0+1+0+1) ÷ 32 | 0.46875 | 0.46875
|女| (0+1+0+0+0+1+1+0+0+1+1+0+0+1+0+1+0+1+1+0+1+1+0+1+0 +1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0+1+1+0+0+1+0+1) ÷ 48 | 0.4791666666666667 |
|是的 | (0+1+0+1+1+0+0+1+0+1+1+0+0+1+0+1+0+1+1+1+0+0+1+1) ÷ 24 | 0.5416666666666666 |
|没有 | (0+1+0+0+1+1+1+0+0+1+1+0+1+1+1+1) ÷16 | 0.625 | 0.625
| 1 | (0+0+1+1+0+0+0+1) ÷ 8 | 0.375 | 0.375
| 0 | (0+0+1+1+0+0+0+0) ÷ 8 | 0.25 | 0.25

例如，
分类数据“男性”的二进制表示为 01001101011000010110110001100101。
该二进制数据的长度是 32。
因此，根据公式，编码值为0.46875。
我想进一步了解这种编码方法，看看它是否适用于统计模型。
对分类数据进行编码是否有任何具体注意事项或限制？]]></description>
      <guid>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</guid>
      <pubDate>Wed, 17 Apr 2024 09:09:55 GMT</pubDate>
    </item>
    <item>
      <title>以向量作为自变量而不是多个单值变量进行回归？</title>
      <link>https://stackoverflow.com/questions/78337383/regression-with-vector-as-independent-variable-instead-of-multiple-single-value</link>
      <description><![CDATA[我正在做一个项目，试图通过绘制书中句子的情绪来预测用户对书籍的评分（评论）。
给您一个想法的图表：
红色是得分最高的 25% 书籍的平均情绪图，
蓝色最差。
正如你所看到的，这些书的开头相当中等，在结尾之前就下降了，并且最后都具有很高的情绪。您还可以看到，最好得分 25%（红色）在最后达到最高点。
我想做的是使用回归来根据包含书中每个句子的情感分数的向量来预测一本书的分数。
我尝试了一些方法，但没有效果。
我的想法是将所有书籍分成 100 个部分，对每本书取这 100 个部分的平均值，并在此数据上训练支持向量回归模型（带有多边形内核）。然而，它的表现并不比每次都预测平均分数更好。
所以：
1 自变量 = [avg_sentiment1,avg_sentiment2,...avg_sentiment100]
1 因变量 = 分数（1 到 5 之间的数字，或更具体地说，在我们的数据集中，介于 ~3.200 和 ~4.700 之间）
因此，虽然使用此设置拟合 sklearn SVR 模型不会给出任何错误，但它似乎并没有学习（它的性能比始终预测平均值的虚拟预测器更差）。我尝试了几种具有不同参数的不同回归模型（Ridge、具有不同内核的 SVR、添加 SplineTransformer）。没有比随机做得更好的了。
我可以在网上找到的所有回归示例似乎都使用奇异值预测奇异值（因此自变量年龄 = 12，因变量身高 = 160 厘米，类似的东西），或者最多使用多个变量（添加更多奇异值）值，例如体重 = 67（公斤），作为自变量）。
我的回归是否将 100 个数字向量解释为 100 个不相关的变量？这有关系吗？
救命，我已经超出了我的能力范围。哪种技术最适用于此？最好是我可以在 SKLearn 上找到的东西，我不是专家（正如您可能知道的那样）]]></description>
      <guid>https://stackoverflow.com/questions/78337383/regression-with-vector-as-independent-variable-instead-of-multiple-single-value</guid>
      <pubDate>Tue, 16 Apr 2024 21:22:19 GMT</pubDate>
    </item>
    <item>
      <title>如何构建热图/效率图预测模型？</title>
      <link>https://stackoverflow.com/questions/77968069/how-can-i-build-a-heat-map-efficiency-map-prediction-model</link>
      <description><![CDATA[我有很多三维数据（x值、y值和给定的效率值z）。它们一起形成热图/效率图。这些地图几乎相似；他们只是在效率值上有微小的差异。
现在，我想使用此地图数据作为输出来训练模型。训练后，模型应该能够在给定几个输入向量（x、y、z）的情况下预测整个地图。
最好的模型是什么？我应该使用 CNN，还是生成任务？
我尝试使用GAN，但我无法调节它。]]></description>
      <guid>https://stackoverflow.com/questions/77968069/how-can-i-build-a-heat-map-efficiency-map-prediction-model</guid>
      <pubDate>Fri, 09 Feb 2024 12:14:31 GMT</pubDate>
    </item>
    </channel>
</rss>