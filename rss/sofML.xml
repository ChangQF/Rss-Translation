<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 14 Mar 2024 15:14:08 GMT</lastBuildDate>
    <item>
      <title>类型错误：“”SLiMPerformer 对象不可迭代</title>
      <link>https://stackoverflow.com/questions/78161397/typeerror-slimperformer-object-is-not-iterable</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78161397/typeerror-slimperformer-object-is-not-iterable</guid>
      <pubDate>Thu, 14 Mar 2024 14:49:35 GMT</pubDate>
    </item>
    <item>
      <title>3D 楼层平面重建</title>
      <link>https://stackoverflow.com/questions/78161086/3d-floor-plane-reconstruction</link>
      <description><![CDATA[我是一名开发人员，致力于开发用于跟踪房屋内数字孪生的 Unity 应用程序。
我希望能够仅根据楼层平面重建 3D 公寓，但我找不到任何可用的库来完成此任务。
我尝试了这个，它基于本文，但它并不完全符合我的需要，因为它返回图像的分段版本而不是有关布局的矢量信息。这不会是一个大问题，因为我可以从中提取矢量信息并统一使用它。然而，对于大多数图像来说，分段输出似乎非常嘈杂，使得它们无法用于生成 3D 几何。
我还尝试使用网络演示 给出的结果非常好。
但是，由于多种原因，我不知道如何在本地运行它（它同时使用 python 和 lua，它使用 Python 2.7，我不知道如何安装 pytorch）。即使我可以运行它，我仍然不喜欢将 python 2.7 与 Unity 应用程序结合起来。
我如何从地板图像中提取矢量数据以生成 3D 布局？您是否推荐任何擅长此方面的开源最新库？您将如何实施这个？
（我不想使用第三方 Web API，因为我正在制作的应用程序是用于研究论文，因此即使 API 不再存在，应用程序也需要正常运行）
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78161086/3d-floor-plane-reconstruction</guid>
      <pubDate>Thu, 14 Mar 2024 14:02:00 GMT</pubDate>
    </item>
    <item>
      <title>在 React Native 应用程序中访问 .bin 文件时出现问题</title>
      <link>https://stackoverflow.com/questions/78161067/issue-accessing-bin-files-in-react-native-app</link>
      <description><![CDATA[我在访问 React Native 应用程序中的 .bin 文件时遇到问题。我按照以下过程将 TensorFlow 模型保存为 .h5 格式，将其转换为 JSON 和二进制文件，然后将这些文件移动到应用程序目录。但是，虽然我可以访问 .json 文件，但无法访问 .bin 文件。
const { getDefaultConfig } = require(“metro-config”);

module.exports = async() =&gt;; {
  const defaultConfig = 等待 getDefaultConfig();
  const { assetExts } = defaultConfig.resolver;

  返回 {
    解析器：{
      资产扩展：[
        ...assetExts，
        &quot;json&quot;, // JSON 文件
        &quot;bin&quot;, // 二进制文件
      ],
    },
  };
};


附加说明：
我已确保 .bin 文件正确放置在我的项目中的 asset 目录中。
我还验证了 Metro.config.js 文件中没有语法错误或拼写错误。
尽管做出了这些努力，我仍然无法访问应用程序中的 .bin 文件。
任何有关解决此问题的见解或建议将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78161067/issue-accessing-bin-files-in-react-native-app</guid>
      <pubDate>Thu, 14 Mar 2024 13:59:11 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 hubbing-face Whisper 和 Gradio 加载 Tokenizer</title>
      <link>https://stackoverflow.com/questions/78161000/cant-load-tokenizer-using-hubbing-face-whisper-and-gradio</link>
      <description><![CDATA[引发环境错误(
OSError：无法加载“myusername/whisper-tiny-hi”的标记生成器。如果您尝试从“https://huggingface.co/models”加载它，请确保您没有同名的本地目录。否则，请确保“myusername/whisper-tiny-hi”是包含 WhisperTokenizerFast 分词器所有相关文件的目录的正确路径。
从变压器导入管道
将渐变导入为 gr
从 Transformer 导入 M2M100ForConditionalGeneration、M2M100Tokenizer
从转换器导入 AutoTokenizer、AutoModelForQuestionAnswering
从变压器进口管道

QAtokenizer = AutoTokenizer.from_pretrained(“SRDdev/QABERT-small”)
QAmodel = AutoModelForQuestionAnswering.from_pretrained(“SRDdev/QABERT-small”)

text = &#39;&#39;&#39;提取问答是从给定问题的文本中提取答案的任务。一个例子
问答数据集是 SQuAD 数据集，它完全基于该任务。如果你想微调
SQuAD 任务的模型，您可以利用 Examples/pytorch/question-answering/run_squad.py 脚本。&#39;&#39;&#39;
Question =“什么是提取式问答？”

def Question_answer（文本，问题）：
    Ask = pipeline(“问答”, model= QAmodel , tokenizer = QAtokenizer)
    结果=询问（问题=问题，上下文=文本）
    print(f&quot;答案: &#39;{结果[&#39;answer&#39;]}&#39;&quot;)
    返回结果[&#39;答案&#39;]

tmodel = M2M100ForConditionalGeneration.from_pretrained(“facebook/m2m100_418M”)
ttokenizer = M2M100Tokenizer.from_pretrained(“facebook/m2m100_418M”)

管道=管道（模型=“我的用户名/whisper-tiny-hi”）

def 翻译（文本）：
    # 将印地语翻译成英语
    ttokenizer.src_lang = “嗨”
    encoded_hi = ttokenizer(文本, return_tensors=“pt”)
    generated_tokens = tmodel.generate(**encoded_hi,forced_bos_token_id=ttokenizer.get_lang_id(“en”))
    返回 ttokenizer.batch_decode( generated_tokens,skip_special_tokens=True)
    
def 转录（音频）：
    打印（音频）
    文本 = 管道（音频）[“文本”]
    翻译文本 = 翻译（文本）
    返回翻译后的文本

def ques_ans(音频,问题):
    翻译文本 = 转录（音频）
    答案 = Question_answering(translated_text[0],问题)
    # 打印（翻译文本）
    返回答案


我也删除了hubbing-face的缓存文件后尝试了多次。请帮我解决一下]]></description>
      <guid>https://stackoverflow.com/questions/78161000/cant-load-tokenizer-using-hubbing-face-whisper-and-gradio</guid>
      <pubDate>Thu, 14 Mar 2024 13:47:40 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow Plot 中 GBT 的值表示什么？</title>
      <link>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</link>
      <description><![CDATA[我正在使用 tfdf.keras.GradientBoostedTreesModel 并在使用 tfdf.model_plotter.plot_model_in_colab 绘制它时显示分割条件下的值： 有值的节点
这个“价值”是什么？意思是？
我已经阅读了 gbt 模型和绘图仪的文档，但找不到有关此值的任何内容。
提前谢谢您。]]></description>
      <guid>https://stackoverflow.com/questions/78160878/what-does-the-value-of-a-gbt-in-tensorflow-plot-express</guid>
      <pubDate>Thu, 14 Mar 2024 13:26:35 GMT</pubDate>
    </item>
    <item>
      <title>根据历史数据预测用户最常问的 5 个问题</title>
      <link>https://stackoverflow.com/questions/78160731/predicting-top-5-frequently-asked-questions-by-users-based-on-historical-data</link>
      <description><![CDATA[问题陈述：
我有一个数据集，其中包含用户 ID 以及他们提出的问题。我的目标是根据每个用户的历史数据预测他们最有可能问的前 5 个问题。此任务涉及利用用户过去的问题历史记录来准确预测他们未来的查询。
要点：
数据集：数据集由两列组成：用户 ID 和每个用户提出的相应问题。
预测目标：目标是建立一个模型，可以分析每个用户的历史问题数据，并通过提供用户 ID 来预测他们将来最有可能问的前 5 个问题。
总体而言，我们的目标是开发一个有效的预测模型，该模型可以预测每个用户可能会问的前 5 个问题，从而根据用户的历史行为改善用户互动和满意度。
我尝试了各种聚类算法来根据用户的历史数据预测用户最有可能问的前 5 个问题。然而，这些方法的准确性并不令人满意。我正在寻找可以提高我的预测准确性的替代方法或方法。]]></description>
      <guid>https://stackoverflow.com/questions/78160731/predicting-top-5-frequently-asked-questions-by-users-based-on-historical-data</guid>
      <pubDate>Thu, 14 Mar 2024 13:04:26 GMT</pubDate>
    </item>
    <item>
      <title>哪些指标用于二元预测，哪些指标用于概率？</title>
      <link>https://stackoverflow.com/questions/78160698/which-metrics-are-used-for-binary-prediction-and-which-for-probability</link>
      <description><![CDATA[我正在构建一个 ML 模型（逻辑回归），该模型使用前一天的天气指标观测结果来预测天气状况。我已经获得了二进制预测以及predict_proba，现在我需要根据几个参数对其进行评估：

准确率得分，
杰卡德指数，
F1 分数，以及
对数丢失。

问题是，我对其中哪些使用predict_proba，对哪些使用预测？
感谢您的帮助！
我尝试了几种组合，但我不确定这些组合是否会输出正确的评估，并且我需要 100% 确定。]]></description>
      <guid>https://stackoverflow.com/questions/78160698/which-metrics-are-used-for-binary-prediction-and-which-for-probability</guid>
      <pubDate>Thu, 14 Mar 2024 12:59:25 GMT</pubDate>
    </item>
    <item>
      <title>无法使用此代码从文章中提取信息</title>
      <link>https://stackoverflow.com/questions/78160347/fail-to-extract-information-from-articles-using-this-code</link>
      <description><![CDATA[这段代码应该从不同的文章链接中提取标题和主要文本，但由于没有找到任何标题或文本，它只是跳过了网址
# 网页抓取和数据处理
对于范围内的 i(2, ws.max_row + 1)：
    link = ws.cell(row=i,column=2).hyperlink.target if ws.cell(row=i,column=2).hyperlink else ws.cell(row=i,column=2).value
    
    print(&quot;正在处理 URL:&quot;, link) # 打印正在处理的 URL
    
    headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0&#39;}
    响应 = requests.get(链接, headers=headers)
    汤 = BeautifulSoup(response.content, &#39;html.parser&#39;)

    如果不是 soup.find(&#39;h1&#39;) 或不是 soup.find(&#39;div&#39;, class_=&#39;td-post-content&#39;):
        print(“由于缺少‘h1’或‘div.td-post-content’而跳过 URL”)
        继续

    head = soup.find(&#39;h1&#39;).get_text()
    text = soup.find(&#39;div&#39;, class_=&#39;td-post-content&#39;).get_text()
]]></description>
      <guid>https://stackoverflow.com/questions/78160347/fail-to-extract-information-from-articles-using-this-code</guid>
      <pubDate>Thu, 14 Mar 2024 12:01:52 GMT</pubDate>
    </item>
    <item>
      <title>难以避开墙壁</title>
      <link>https://stackoverflow.com/questions/78160153/having-a-trouble-avoiding-the-wall</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78160153/having-a-trouble-avoiding-the-wall</guid>
      <pubDate>Thu, 14 Mar 2024 11:28:34 GMT</pubDate>
    </item>
    <item>
      <title>VAE 不是学习</title>
      <link>https://stackoverflow.com/questions/78159759/vae-is-not-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78159759/vae-is-not-learning</guid>
      <pubDate>Thu, 14 Mar 2024 10:25:17 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 sklearns 的 cross_validate 对样本进行加权仅用于评分？</title>
      <link>https://stackoverflow.com/questions/78155034/how-to-weight-samples-with-sklearnss-cross-validate-for-scoring-only</link>
      <description><![CDATA[我正在对由真实样本和增强样本组成的数据集运行回归任务。增强样本是通过抖动真实样本生成的。我想通过与 sklearn 进行交叉验证来选择性能最佳的模型。
为此我想：

在由真实样本和增强样本组成的集合上训练模型。我不希望拟合过程考虑样本的来源（即它应该相当于运行estimator.fit(..., sample_weights = [1,1,..., 1]).
根据模型仅在真实样本上的表现对模型进行评分。为此，我考虑将增强（或真实）样本的权重设置为 0（或 1）。

如何使用sklearn的cross_validate&lt;来实现这一点/代码&gt;？
我尝试了以下方法：
来自 sklearn 导入 model_selection
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 r2_score、mean_squared_error、make_scorer
将 numpy 导入为 np

n_smpl, n_feats = 100, 5
arr_source = np.random.random((n_smpl, n_feats))
arr_target = np.random.random((n_smpl, n_feats))
arr_weight = np.random.randint(0, 2, n_smpl) # 0 表示增强，1 表示真实

模型 = RandomForestRegressor()
kfold_splitter = model_selection.KFold(n_splits=5, random_state=7, shuffle=True)
我的得分者 = {
    “r2_weighted”：make_scorer（r2_score，sample_weight = arr_weight），
    “mse_weighted”：make_scorer（mean_squared_error，greater_is_better = False，sample_weight = arr_weight）
}

cv_results = model_selection.cross_validate（模型，arr_source，arr_target，评分= my_scorers，cv = kfold_splitter）

但这会返回ValueError：发现样本数量不一致的输入变量：[20, 20, 100]。我知道发生这种情况是因为 cross_validate 无法根据折叠分割样本权重。
有什么方法可以让它通过交叉验证吗？或者还有其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78155034/how-to-weight-samples-with-sklearnss-cross-validate-for-scoring-only</guid>
      <pubDate>Wed, 13 Mar 2024 15:36:03 GMT</pubDate>
    </item>
    <item>
      <title>训练随机森林分类器</title>
      <link>https://stackoverflow.com/questions/77970974/train-a-random-forest-classifier</link>
      <description><![CDATA[我正在尝试在一组图像上训练随机森林分类器，旨在对 10 种不同的颜色类别进行分类。我有一个带有子目录的 \dataset 目录，每个子目录都以一种颜色（黄色、红色、白色等）命名。我采用 HSV 直方图并将其用作我的特征（它比 RGB 更好吗？）
这是我的代码。我在代码中添加了 print(image_path) 进行调试。但运行时，它只打印第一个文件，不打印其他任何内容。
有什么问题吗？如何解决？
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.feature_extraction.image 导入 extract_patches_2d
从 sklearn.model_selection 导入 train_test_split
从 skimage.color 导入 rgb2hsv，rgb2gray
从 skimage.feature 导入graycomatrix，graycoprops
导入操作系统
将 numpy 导入为 np
从 PIL 导入图像
导入作业库


# 定义路径和参数
data_dir =“.\数据集” # 替换为你的实际目录路径
num_trees = 100 # 森林中树木的数量
patch_size = (32, 32) # 用于特征提取的图像块的大小

# 定义特征提取函数
def extract_color_histogram(图像):
    # 将 PIL 图像转换为 NumPy 数组
    img_array = np.array(图像)
    # 调整图像大小
    img_resized = Image.fromarray(img_array).resize((640, 640))
    # 转换为 HSV
    img_hsv = img_resized.convert(“HSV”)
    hist, _ = np.histogram(img_hsv, bins=(8, 8, 8), 范围=((0, 255), (0, 255), (0, 255)))
    hist = hist.flatten()
    返回历史记录

def extract_texture_features(图像):
    # 转换为灰度并提取纹理特征
    灰色 = rgb2gray(图像)
    gray_uint = (gray * 255).astype(np.uint8) # 将灰度转换为无符号整数
    glcm = Graycomatrix(gray_uint，距离=[5]，角度=[0]，级别=256，对称=True，normed=True)
    特征 = Graycoprops(glcm, &#39;对比度&#39;)[0]
    返回特征

# 加载数据并提取特征
X、y = []、[]
对于 os.listdir(data_dir) 中的颜色：
    对于 os.listdir(os.path.join(data_dir, color)) 中的 image_file：
        image_path = os.path.join(data_dir, 颜色, image_file)
        打印（图像路径）
        img = Image.open(图像路径)
        img_array = np.array(img)
        补丁 = extract_patches_2d(img_array, patch_size=patch_size)
        对于补丁中的补丁：
            # 从每个补丁中提取特征
            color_hist = extract_color_histogram(补丁)
            纹理特征=提取纹理特征（补丁）
            特征 = np.concatenate((color_hist,texture_features))
            X.append（功能）
            y.追加（颜色）

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 训练随机森林模型
print(&quot;现在训练...&quot;)
模型 = RandomForestClassifier(n_estimators=num_trees, random_state=42)
model.fit(X_train, y_train)

# 评估模型性能
准确度 = model.score(X_test, y_test)
print(f&quot;模型精度: {accuracy:.2f}&quot;)

# 保存模型以供将来使用
joblib.dump(模型,“color_model.pkl”)
]]></description>
      <guid>https://stackoverflow.com/questions/77970974/train-a-random-forest-classifier</guid>
      <pubDate>Fri, 09 Feb 2024 21:33:17 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 PyTorch 创建点的 2D 张量，每个维度从 0 到 1？</title>
      <link>https://stackoverflow.com/questions/77038120/how-to-create-a-2d-tensor-of-points-with-pytorch-each-dimension-going-from-0-to</link>
      <description><![CDATA[我正在尝试创建一个二维张量，其中每个维度的范围从 0 到 1。
对于一维张量，我可以使用：
torch.arange(0, 1, 0.2)

这给了我：
张量([0.0, 0.2, 0.4, 0.6, 0.8])

但是，我想将其扩展到 2D 点。我想要的输出是[形状为 (25, 2)]：
&lt;前&gt;&lt;代码&gt;张量([
    [0.0, 0.0], [0.0, 0.2], [0.0, 0.4], [0.0, 0.6], [0.0, 0.8],
    [0.2, 0.0], [0.2, 0.2], [0.2, 0.4], [0.2, 0.6], [0.2, 0.8],
    [0.4, 0.0], [0.4, 0.2], [0.4, 0.4], [0.4, 0.6], [0.4, 0.8],
    [0.6, 0.0], [0.6, 0.2], [0.6, 0.4], [0.6, 0.6], [0.6, 0.8],
    [0.8, 0.0], [0.8, 0.2], [0.8, 0.4], [0.8, 0.6], [0.8, 0.8]
]）

如何使用 PyTorch 实现此目的？]]></description>
      <guid>https://stackoverflow.com/questions/77038120/how-to-create-a-2d-tensor-of-points-with-pytorch-each-dimension-going-from-0-to</guid>
      <pubDate>Mon, 04 Sep 2023 13:25:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Sagemaker 端点上运行推理？</title>
      <link>https://stackoverflow.com/questions/76253353/how-do-i-run-inference-on-a-sagemaker-endpoint</link>
      <description><![CDATA[我正在使用 AWS Sagemaker 和 Python 部署机器学习模型的终端节点，特别是在一组图像芯片上运行推理。但是，当我执行脚本来执行推理时，我收到一条错误，指出模型容器标头超出了指定的字节数。下面是我用来测试脚本和捕获的输出消息的示例图像（数组）。
将 numpy 导入为 np
arr = np.ones([2,320,320,1], dtype=np.uint8)
      
从 sagemaker.predictor 导入预测器、numpy_deserializer、NumpySerializer、NumpyDeserializer
预测器 = 预测器(endpoint_name_serialzer=NumpySerializer(), 反序列化器=NumpyDeserizlier())
结果=预测器.预测(arr)
打印（结果.形状）

-&gt; /python3.8/site-packages/sagemaker/predictory.py 第 161 行出现错误
响应 = self.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**request_args)
  
ModelError：调用InvokeEndpoint操作时发生错误（modelError）：
从模型收到服务器错误 (O)，并显示消息“从模型容器收到响应”
具有长度大于 4096 字节的标头。减少容器的长度
响应标头并更新您的端点 请参阅 https://us-iso-east-
1.console.aws.amazon.com/cloudwatch/home?region=us-iso-east-
1#logEventViewer:group=/aws/sagemaker/Endpoints/ModelTest-mdl-1（账户 12345679012）”

尝试针对“result=predictor.predict(arr)”的端点使用预测函数时，出现错误。我试图以其他方式找到 Sagemaker 模型容器标头的示例，但我运气不佳。非常感谢任何帮助。]]></description>
      <guid>https://stackoverflow.com/questions/76253353/how-do-i-run-inference-on-a-sagemaker-endpoint</guid>
      <pubDate>Mon, 15 May 2023 10:53:22 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 是否为已经拟合的估计器提供 VotingClassifier？</title>
      <link>https://stackoverflow.com/questions/72262858/does-sklearn-provide-a-votingclassifier-for-already-fit-estimators</link>
      <description><![CDATA[我有 n 个二元分类器，我想看看通过组合它们的预测得到什么结果，就像 VotingClassifier 所做的那样，使用多数投票或单个 Predict_proba 的总和来确定最终的预测。
（在谷歌上我已经找到了这里一些人实现了我需要的东西以及代码似乎是正确的，我只是在寻找实现此目的的“sklearn 方法”）
我的问题是，sklearn.ensemble.VotingClassifier 是一个用于不适合估计器的软投票/多数规则分类器。
sklearn 是否为拟合估计器提供了一些东西？
通过查看sklearn.ensemble的文档 看起来似乎没有，但是这样一个完整的库中缺少这样的功能不是很奇怪吗？我错过了什么吗？我可以使用 sklearn 的功能来获得该功能还是必须自己实现它？]]></description>
      <guid>https://stackoverflow.com/questions/72262858/does-sklearn-provide-a-votingclassifier-for-already-fit-estimators</guid>
      <pubDate>Mon, 16 May 2022 16:53:26 GMT</pubDate>
    </item>
    </channel>
</rss>