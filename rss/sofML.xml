<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 27 Mar 2024 21:12:29 GMT</lastBuildDate>
    <item>
      <title>为什么删除 Chunksize 时会出现错误？</title>
      <link>https://stackoverflow.com/questions/78234289/why-do-i-get-an-error-when-i-remove-chunksize</link>
      <description><![CDATA[我在运行 Python 代码时遇到错误，需要帮助来解决该错误。以下是详细信息：
导入 pandas 作为 pd

df_列表 = []
file_path = &#39;houses.txt&#39;

for chunk in pd.read_csv(file_path, chunksize=1000000, names=[&#39;Size()sqft&#39;, &#39;卧室数量&#39;, &#39;楼层数量&#39;, &#39;房屋年龄&#39;, &#39;价格(1000美元)&#39;]) :
    df_list.append(块)

df = pd.concat(df_list)

打印（df_列表）


输出：
&lt;前&gt;&lt;代码&gt;0 952.0 2.0 1.0 65.0 271.5
1 1244.0 3.0 1.0 64.0 300.0
2 1947.0 3.0 2.0 17.0 509.8
3 1725.0 3.0 2.0 42.0 394.0
4 1959.0 3.0 2.0 15.0 540.0
……………………
95 1224.0 2.0 2.0 12.0 329.0
96 1432.0 2.0 1.0 43.0 388.0
97 1660.0 3.0 2.0 19.0 390.0
98 1212.0 3.0 1.0 20.0 356.0
99 1050.0 2.0 1.0 65.0 257.8

[100 行 x 5 列]]

删除“chunksize”后。我收到此错误：
类型错误：无法连接“”类型的对象；仅 Series 和 DataFrame 对象有效
请解释一下问题所在]]></description>
      <guid>https://stackoverflow.com/questions/78234289/why-do-i-get-an-error-when-i-remove-chunksize</guid>
      <pubDate>Wed, 27 Mar 2024 20:03:32 GMT</pubDate>
    </item>
    <item>
      <title>评估模型时出错：分类指标无法处理二进制目标和连续目标的混合</title>
      <link>https://stackoverflow.com/questions/78234279/error-when-evaluating-models-classification-metrics-cant-handle-a-mix-of-binar</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78234279/error-when-evaluating-models-classification-metrics-cant-handle-a-mix-of-binar</guid>
      <pubDate>Wed, 27 Mar 2024 20:00:54 GMT</pubDate>
    </item>
    <item>
      <title>正态贝叶斯分类</title>
      <link>https://stackoverflow.com/questions/78233586/normal-bayes-classification</link>
      <description><![CDATA[请帮助我。我是机器学习初学者。如何使用不同类型的协方差矩阵建议来训练普通贝叶斯分类器？
我有一个任务：训练普通贝叶斯分类器：

评估不同类的协方差矩阵，如果它们是 a) 相等、对角 b) 不同标量等
计算经过训练的贝叶斯分类器的分类点 a、b...
显示课程区域

我在 python 上做，但我不明白除了 GaussianNB() 之外我还能做什么。据我所知，这个函数在不检查任何类型的矩阵的情况下建立模型。请帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78233586/normal-bayes-classification</guid>
      <pubDate>Wed, 27 Mar 2024 17:33:47 GMT</pubDate>
    </item>
    <item>
      <title>VScode 抛出：ModuleNotFoundError：即使正确安装，也没有名为“keras.preprocessing.text”的模块？</title>
      <link>https://stackoverflow.com/questions/78233508/vscode-throwsmodulenotfounderror-no-module-named-keras-preprocessing-text-ev</link>
      <description><![CDATA[下面是我的完整代码。
https://github.com/mishraatharva/text_classification
每当我尝试运行我的代码时，我都会收到以下错误：
错误：
&lt;块引用&gt;
[nltk_data] 将包停用词下载到
[nltk_data] C:\Users\Naruto\AppData\Roaming\nltk_data...
[nltk_data] 包停用词已经是最新的！
2024-03-27 22:35:43.217542：我tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 TF_ENABLE_ONEDNN_OPTS=0。
2024-03-27 22:35:43.760781：​​我tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 TF_ENABLE_ONEDNN_OPTS=0。
回溯（最近一次调用最后一次）：
文件“C:\Users\Naruto\Desktop\generative_ai\PROJECTS\text_classification\app.py”，第 1 行，位于
从 hat.pipeline.train_pipeline 导入 TrainPipeline
文件“C:\Users\Naruto\Desktop\generative_ai\PROJECTS\text_classification\hate\pipeline\train_pipeline.py”，第 6 行，位于
从 hat.components.model_trainer 导入 ModelTrainer
文件“C:\Users\Naruto\Desktop\generative_ai\PROJECTS\text_classification\hate\components\model_trainer.py”，第 9 行，位于
从 keras.preprocessing.text 导入 Tokenizer
ModuleNotFoundError：没有名为“keras.preprocessing.text”的模块`

尽管我已经清楚地导入了所需的模块。

下面是我尝试使用 Tokenizer 的代码。
def 标记化（self，x_train）：
        尝试：
            logging.info(“对数据应用标记化”)
            分词器 = 分词器(num_words=self.model_trainer_config.MAX_WORDS)
            tokenizer.fit_on_texts(x_train)
            序列 = tokenizer.texts_to_sequences(x_train)
            logging.info(f“将文本转换为序列：{sequences}”)
            序列矩阵 = pad_sequences(序列,maxlen=self.model_trainer_config.MAX_LEN)
            logging.info(f&quot;序列矩阵为：{sequences_matrix}&quot;)
            返回sequence_matrix，分词器
        除了异常 e：
            从 e 引发 CustomException(e, sys)

我发现了下面的 stackoverflow 帖子，但没有帮助。
https://stackoverflow.com/questions/42725140/importerror-no-module-named-keras-preprocessing
提前致谢。
我希望尽快收到您的来信。]]></description>
      <guid>https://stackoverflow.com/questions/78233508/vscode-throwsmodulenotfounderror-no-module-named-keras-preprocessing-text-ev</guid>
      <pubDate>Wed, 27 Mar 2024 17:17:52 GMT</pubDate>
    </item>
    <item>
      <title>我的代码总是为每次迭代（甚至1次）给出收敛警告，请给出解决方案</title>
      <link>https://stackoverflow.com/questions/78233405/my-code-always-give-convergencewarning-for-every-iterationeven-1-please-give-a</link>
      <description><![CDATA[在此处输入图像说明在此处输入图像描述[在此处输入图像描述](https://i.stack. imgur.com/XwKBA.png)
我想检查四个内核函数的影响和稳定性
软件缺陷预测的SVM性能选择严格来讲，
我想检查非线性核函数与线性核函数的性能。我尝试使用管道解决这个问题，但是在解决这个问题时，即使 max_iter=1 也每次都会给出收敛警告。请给出一个在没有任何收敛警告的情况下运行代码的解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78233405/my-code-always-give-convergencewarning-for-every-iterationeven-1-please-give-a</guid>
      <pubDate>Wed, 27 Mar 2024 17:01:16 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 多步预测</title>
      <link>https://stackoverflow.com/questions/78233177/lstm-multistep-forecast</link>
      <description><![CDATA[有没有办法使用lstm模型对多个窗口进行多步预测？
例如，我训练模型输出 5 个步骤，有没有办法，如果我想预测 10 个步骤，我可以轻松做到？或者这是模型架构固有的，我没有办法做到这一点，以便我可以在预测中拥有更大的灵活性？
我搜索了诸如 seq2seq 编码器解码器之类的解决方案，但找不到答案。
谢谢
我尝试了简单的 lstm 模型，但只能有固定的输出......]]></description>
      <guid>https://stackoverflow.com/questions/78233177/lstm-multistep-forecast</guid>
      <pubDate>Wed, 27 Mar 2024 16:22:51 GMT</pubDate>
    </item>
    <item>
      <title>使用哪个模型来预测处理时间</title>
      <link>https://stackoverflow.com/questions/78233053/which-model-to-use-to-predict-processing-time</link>
      <description><![CDATA[您好，我正在尝试预测服务提供过程时间。
应用程序详细信息：它在设备上提供服务请求，这意味着用户在设备上推送一些配置。
以下是数据或 x 轴的架构。
RequestType：创建、修改、删除
服务类型：MPLS-L2、L3、ISP、...
涉及设备：Device-1、Device-2、Device-3
总处理时间。
Task-1 处理时间
任务2处理时间
当时正在进行的订单数量。

......
设备处理时间根据其使用情况而有所不同，我们没有使用信息。
我们不执行任务，我们将依赖其他系统来处理它。他们有一个队列机制，我们不知道处理它的实际时间是多少。
我们知道总体处理时间。
我们拥有数十万条此类记录。]]></description>
      <guid>https://stackoverflow.com/questions/78233053/which-model-to-use-to-predict-processing-time</guid>
      <pubDate>Wed, 27 Mar 2024 16:04:00 GMT</pubDate>
    </item>
    <item>
      <title>Yolo v9 保存每个纪元和损失</title>
      <link>https://stackoverflow.com/questions/78232885/yolo-v9-saving-each-epoch-and-loss</link>
      <description><![CDATA[你好，我有这段代码在自定义数据集上训练 yolov9 模型..但由于我只有 T4 GPU 并且我的数据集很大，它只训练了大约 3 个时期，然后就停止了..我想训练每个时期就其本身并保存它，它是损失..我该怎么做？？
这是我正在使用的代码
%cd /content/my_drive/MyDrive/yolov9/yolov9

!python train.py \
--batch 16 --epochs 25 --img 640 --min-items 0 --close-mosaic 15 \
--data /content/my_drive/MyDrive/yolov9/yolov9/data.yaml \
--weights /content/my_drive/MyDrive/yolov9/yolov9/gelan-c.pt \
--cfg 模型/检测/gelan-c.yaml \
--hyp hyp.scratch-high.yaml
]]></description>
      <guid>https://stackoverflow.com/questions/78232885/yolo-v9-saving-each-epoch-and-loss</guid>
      <pubDate>Wed, 27 Mar 2024 15:36:49 GMT</pubDate>
    </item>
    <item>
      <title>处理不平衡数据集分类的问题</title>
      <link>https://stackoverflow.com/questions/78232803/questions-of-handling-imbalance-dataset-classification</link>
      <description><![CDATA[我正在尝试预测将终止其会员资格的会员数量。整个数据集大约有 1200 万行数据，大约 40 列。会员状态可以是“继续”、“自愿终止”或“非自愿终止”。该数据集高度不平衡，98% 的会员选择“继续”，约 1% 的会员选择“自愿终止”和“非自愿终止”。为了降低维度，我进行了相关性分析，仅选择 15 个相关性最高的特征进行建模。
以下是我面临的问题：

我的同事使用多项回归。然而，他没有应用阈值将概率转换为类标签。相反，他总结了各个成员的所有概率，以估计预测将自愿终止或非自愿终止的成员数量。
我不确定这种方法，因为在求和个体概率而不是使用阈值后，我不太明白其含义。鉴于我们对总人数感兴趣，这种方法是否正确？另外，我们如何用这种方法衡量模型性能

我将这个问题视为分类问题。由于它是不平衡的数据集，并且我们对将停止使用的人感兴趣，因此我尝试了 SMOTE 和欠采样方法。然而，尝试使用逻辑回归、决策树和神经网络，它们对于“自愿中断”和“非自愿中断”类别的精度仍然很低。还有其他方法可以提高少数类的精度吗？

我尝试运行随机森林。但由于内存限制，未能运行。对于处理这种大型数据集有什么建议吗？

]]></description>
      <guid>https://stackoverflow.com/questions/78232803/questions-of-handling-imbalance-dataset-classification</guid>
      <pubDate>Wed, 27 Mar 2024 15:24:10 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tfidfvectorizer 的功能从英语修改为西班牙语</title>
      <link>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</link>
      <description><![CDATA[我有一个 tfidfvectorizer，它适合英语文本数据来预测英语通话的情绪。任务是将其转换为西班牙语。我想使用此 tfidfvectorizers 的权重，并希望将功能从英语转换为西班牙语，例如“谢谢”变成“gracias”并使用旧的权重。所以本质上我想使用相同的 tfidf 矢量器，但修改了特征名称。有人可以建议一些方法在 Python 中做到这一点吗？
编辑：我已经将功能从英语转换为西班牙语，并在英语文本上训练了 tfidf。我需要一种使用旧权重和新功能构建 tfidf 的方法，而不使用 fit 函数或将所有文本转换为西班牙语。
带有解决方案的代码。]]></description>
      <guid>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</guid>
      <pubDate>Wed, 27 Mar 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>使用隔离森林进行异常检测[关闭]</title>
      <link>https://stackoverflow.com/questions/78232159/anomaly-detection-with-isolation-forest</link>
      <description><![CDATA[我有车辆数据。该数据是在会议中测量的。我在数据框中有一列显示测量会话 ID。在“时间”列中，时间每 200 毫秒累加一次。测量的块具有不同的长度。有些是 600000 毫秒长，有些是 400000 毫秒长。如果 id 发生变化，时间列会再次从 0 开始计数。我现在的问题是，我如何向隔离森林教授这一点，或者我如何准备数据和列，以便隔离森林考虑到这一点？我真的需要尽快得到一个好的答案。非常感谢
我没有任何想法。 Time 列也只是 float64 的类型，它不是日期时间对象。]]></description>
      <guid>https://stackoverflow.com/questions/78232159/anomaly-detection-with-isolation-forest</guid>
      <pubDate>Wed, 27 Mar 2024 13:45:39 GMT</pubDate>
    </item>
    <item>
      <title>R 混淆矩阵 - 错误：“数据”和“参考”应该是具有相同级别的因素</title>
      <link>https://stackoverflow.com/questions/78205262/r-confussion-matrix-error-data-and-reference-should-be-factors-with-the-s</link>
      <description><![CDATA[尽管还有其他针对相同错误消息的报告，但没有一个对我的情况有帮助。
我已经准备了自己的数据，分割如下，但无法获得混淆矩阵。
test_index &lt;- createDataPartition(y =workingData$PM10, times = 1, p = 0.5, list = FALSE)
train_set &lt;-工作数据[-test_index,]
test_set &lt;-工作数据[test_index,]

train_knn &lt;- train(PM10 ~. , method= &quot;knn&quot; , data = train_set)

y_hatknn &lt;- 预测(train_knn, train_set, type = “raw”)

fusionMatrix(y_hatknn, test_set$PM10)

上面的最后一行给出了
错误：“data”和“reference”应该是具有相同级别的因素。

我想上传数据进行复制，但可以提供基本的：
&lt;前&gt;&lt;代码&gt;str（工作数据）
“数据帧”：3653 obs。 3 个变量：
&#39; $ 日期：数字 2e+07 2e+07 2e+07 2e+07 2e+07 ...
&#39; $ Rain_mm: 数字 0.1 6.7 0 1.4 0.8 1.8 15.3 0 2.6 3.8 ...
&#39; $ PM10 : 数字 -1 -1 -1 -1 -1 ...

PM10 是污染 PM10 水平。
如何解决？
添加更多信息：
在原始错误之后：
&lt;块引用&gt;
confusionMatrix(y_hatknn, test_set$PM10)
错误：data 和 reference 应该是具有相同水平的因素。

我尝试设置为因素...
&lt;块引用&gt;
confusionMatrix(y_hatknn, as.factor(test_set$PM10))
错误：data 和 reference 应该是具有相同水平的因素。

以预测为因素...
&lt;块引用&gt;
confusionMatrix(as.factor(y_hatknn), test_set$PM10)
错误：data 和 reference 应该是具有相同水平的因素。

以两个参数为因素...
&lt;块引用&gt;
confusionMatrix(as.factor(y_hatknn), as.factor(test_set$PM10))
fusionMatrix.default(as.factor(y_hatknn), as.factor(test_set$PM10)) 中的错误：
数据的级别不能多于参考

真正需要得到的已整理出来]]></description>
      <guid>https://stackoverflow.com/questions/78205262/r-confussion-matrix-error-data-and-reference-should-be-factors-with-the-s</guid>
      <pubDate>Fri, 22 Mar 2024 09:39:08 GMT</pubDate>
    </item>
    <item>
      <title>我可以将候选数据集转换为检索 topK 张量流模型的输入吗？</title>
      <link>https://stackoverflow.com/questions/78196301/can-i-turn-candidates-dataset-to-input-on-retrieval-topk-tensorflow-model</link>
      <description><![CDATA[我有一个检索张量流训练模型，并使用 tfrs.layers.factorized_top_k.BruteForce 来预测第一个 k 的附近候选者，如下实现：
index = tfrs.layers.factorized_top_k.BruteForce(final_model.query_model)

索引.index_from_dataset(
    tf.data.Dataset.zip((parsed_topK.batch(128).map(lambda x: x[&#39;id&#39;]), parsed_topK.batch(128).map(final_model.candidate_model)))
）

并获取前 5 个结果：
结果 = 索引(input_query, k=5)

我想知道是否可以将搜索数据库（在此代码中由 parsed_topK 表示）转换为模型的输入，例如：
索引(input_query, input_candidates, k=5)

在此示例中，其中input_candidates = parsed_topK
我尝试调用final_model.predict(input_query, input_candidates)，但我需要实现一个call()方法，并且我不知道这个方法需要做什么。]]></description>
      <guid>https://stackoverflow.com/questions/78196301/can-i-turn-candidates-dataset-to-input-on-retrieval-topk-tensorflow-model</guid>
      <pubDate>Wed, 20 Mar 2024 21:22:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 Conda + Poetry 有意义吗？</title>
      <link>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</link>
      <description><![CDATA[在机器学习项目中使用 Conda + Poetry 有意义吗？让我分享一下我（新手）的理解，请指正或赐教：
据我了解，Conda 和 Poetry 有不同的目的，但很大程度上是多余的：

Conda 主要是一个环境管理器（实际上不一定是 Python），但它也可以管理包和依赖项。
Poetry 主要是一个 Python 包管理器（例如，pip 的升级版），但它也可以创建和管理 Python 环境（例如，Pyenv 的升级版） .

我的想法是同时使用两者并划分它们的角色：让 Conda 担任环境管理器，让 Poetry 担任包管理器。我的推理是（听起来）Conda 最适合管理环境，可用于编译和安装非 python 包，尤其是 CUDA 驱动程序（用于 GPU 功能），而 Poetry 作为 Python 包管理器比 Conda 更强大。 
通过在 Conda 环境中使用 Poetry，我成功地相当轻松地完成了这项工作。诀窍是不使用 Poetry 来管理 Python 环境：我没有使用诸如 poetry shell 或 poetry run 这样的命令，只使用 poetry init 、poetry install 等（激活Conda环境后）。
为了充分披露，我的 environment.yml 文件（针对 Conda）如下所示：
&lt;前&gt;&lt;代码&gt;名称：N

渠道：
  - 默认值
  - 康达锻造

依赖项：
  - 蟒蛇=3.9
  -cuda工具包
  - 库德恩

我的poetry.toml文件看起来像这样：
&lt;前&gt;&lt;代码&gt;[工具.诗歌]
名称=“N”
作者 = [“B”]

[工具.诗歌.依赖项]
蟒蛇=“3.9”
火炬=“^1.10.1”

[构建系统]
需要= [“诗歌核心&gt;=1.0.0”]
构建后端=“poetry.core.masonry.api”

说实话，我这样做的原因之一是我在没有 Conda 的情况下很难安装 CUDA（用于 GPU 支持）。
您认为这个项目设计合理吗？]]></description>
      <guid>https://stackoverflow.com/questions/70851048/does-it-make-sense-to-use-conda-poetry</guid>
      <pubDate>Tue, 25 Jan 2022 15:09:43 GMT</pubDate>
    </item>
    <item>
      <title>如何计算线性回归中的正则化参数</title>
      <link>https://stackoverflow.com/questions/12182063/how-to-calculate-the-regularization-parameter-in-linear-regression</link>
      <description><![CDATA[当我们有一个高次线性多项式用于拟合线性回归设置中的一组点时，为了防止过度拟合，我们使用正则化，并在成本函数中包含 lambda 参数。然后使用该 lambda 更新梯度下降算法中的 theta 参数。
我的问题是我们如何计算这个 lambda 正则化参数？]]></description>
      <guid>https://stackoverflow.com/questions/12182063/how-to-calculate-the-regularization-parameter-in-linear-regression</guid>
      <pubDate>Wed, 29 Aug 2012 16:04:04 GMT</pubDate>
    </item>
    </channel>
</rss>