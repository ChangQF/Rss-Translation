<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 12 Jan 2024 09:14:47 GMT</lastBuildDate>
    <item>
      <title>标准化流程的转变</title>
      <link>https://stackoverflow.com/questions/77805312/transformation-in-normalizing-flow</link>
      <description><![CDATA[大家好，
我正在实现一个基于流程的模型。解码 (z-&gt;x) 步骤的仿射变换为： x_{i} = f(x_{i-1}) = x_{i-1}*exp(s) + t，编码步骤为： x_ {i-1} = f_1(x_{i}) = (x_{i} - t)/ exp(s)。
我的问题是，由于该函数是双射的，我可以使用 f_1 进行解码，使用 f 进行编码吗？我将从 z ~ N(0, 1) 到 x ~ N(mu, var) 的仿射变换视为重新参数化技巧： x_{i} = x_{i-1}*std + mu
感谢您的帮助
我尝试了 2 种情况，f_1 解码对于 z ~ N(0, I) 到 Halfmoon 给出了更好的结果。但不知道理论上是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/77805312/transformation-in-normalizing-flow</guid>
      <pubDate>Fri, 12 Jan 2024 08:42:56 GMT</pubDate>
    </item>
    <item>
      <title>谷歌colab笔记本，不工作“错误：页面不工作”无法提供安全连接”</title>
      <link>https://stackoverflow.com/questions/77805252/google-colab-notebook-not-working-error-the-page-not-working-cant-provide</link>
      <description><![CDATA[我的互联网连接良好，其他网站运行良好，但当我尝试打开 google Colab Notebook 时，页面无法运行”错误是：该网站无法提供安全连接？
任何人都可以回答并指导我解决此错误。谢谢
问题是这样的：]]></description>
      <guid>https://stackoverflow.com/questions/77805252/google-colab-notebook-not-working-error-the-page-not-working-cant-provide</guid>
      <pubDate>Fri, 12 Jan 2024 08:28:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 tSNE 后在 MNIST 数据集上应用 KMeans</title>
      <link>https://stackoverflow.com/questions/77805020/applying-kmeans-on-the-mnist-dataset-after-using-tsne</link>
      <description><![CDATA[我在 MNIST 数据集上使用 tSNE，并得到了非常好的结果（当我可视化该图时，所有 10 个标签都分离得很好）。
现在，我想对从 tSNE 建模获得的数据应用 KMeans，并再次将其可视化。
不幸的是，这次我得到了非常糟糕的结果 - 集群看起来非常错误。
我知道 t-SNE 空间中的点之间的距离和关系可能不一定保留原始高维空间中存在的结构，当将 KMeans 等聚类算法直接应用于 t 时，这可能会导致误导性的解释。 -SNE嵌入。
我想问 - 有什么我可以做得更好的吗？
非常感谢！
代码示例：
tsne = TSNE(n_components=2, perplexity=15,learning_rate=200, exaggeration=1)
x_train_tsne = tsne.fit(x_train)

kmeans = KMeans(n_clusters=10, n_init=1, init=&#39;kmeans++&#39;)
labels_kmeans = kmeans.fit_predict(x_train)

对于 np.unique(labels_kmeans) 中的数字：
   索引 = (labels_kmeans == 数字)
   plt.scatter(x_train_tsne[索引，0]，x_train_tsne[索引，1]，s=5，alpha=0.8，标签=str(数字))
]]></description>
      <guid>https://stackoverflow.com/questions/77805020/applying-kmeans-on-the-mnist-dataset-after-using-tsne</guid>
      <pubDate>Fri, 12 Jan 2024 07:35:51 GMT</pubDate>
    </item>
    <item>
      <title>我想通过上传图片来查找“车辆品牌和型号”</title>
      <link>https://stackoverflow.com/questions/77804868/i-want-to-find-vehicle-make-and-model-by-uploading-the-image</link>
      <description><![CDATA[我想创建一个Python模型来在上传车辆图像后识别车辆的品牌和型号。
导入deeplake
从张量流导入keras
从tensorflow.keras导入层

加载训练和测试子集
train_dataset = deeplake.load(“hub://activeloop/stanford-cars-train”)
test_dataset = deeplake.load(“hub://activeloop/stanford-cars-test”)

创建 TensorFlow 数据加载器
train_dataloader = train_dataset.tensorflow()
test_dataloader = test_dataset.tensorflow()

定义常量
image_height, image_width, num_channels = (224, 224, 3) # 根据您的数据集进行调整
num_classes = 196 # 数据集中的汽车类别数量

假设您的数据集有一个“images”键
input_layer=layers.Input(shape=(image_height, image_width, num_channels), name=&#39;images&#39;)
x = 层.Conv2D(32, (3, 3), 激活=&#39;relu&#39;)(input_layer)
x = 层数.MaxPooling2D((2, 2))(x)
x = 层.Conv2D(64, (3, 3), 激活=&#39;relu&#39;)(x)
x = 层数.MaxPooling2D((2, 2))(x)
x = 层.Conv2D(128, (3, 3), 激活=&#39;relu&#39;)(x)
x = 层.Flatten()(x)
x = 层.Dense(256, 激活=&#39;relu&#39;)(x)
输出层=层.Dense（num_classes，激活=&#39;softmax&#39;，名称=&#39;car_models&#39;）（x）

模型= keras.Model（输入=输入层，输出=输出层）

编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;sparse_categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

指定 epoch 数和其他训练参数
&lt;前&gt;&lt;代码&gt;num_epochs = 10

训练模型
model.fit（train_dataloader，epochs = num_epochs，validation_data = test_dataloader）

在测试集上评估模型
test_loss, test_accuracy = model.evaluate(test_dataloader)
print(f&#39;测试准确度: {test_accuracy * 100:.2f}%&#39;)

对新图像进行预测
假设您有一个新图像（将“your_image_path”替换为实际路径）
来自tensorflow.keras.preprocessing导入图像
将 numpy 导入为 np

new_image_path = &#39;/content/bmw2.jpg&#39;
img = image.load_img(new_image_path, target_size=(image_height, image_width))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) # 添加批量维度
img_array /= 255.0 # 标准化像素值

进行预测
预测 = model.predict(img_array)
Predicted_class = np.argmax(预测[0])

将预测的类别映射到实际的汽车品牌和型号（您可能需要从类别索引到品牌和型号的映射）
class_mapping = {} # 定义类映射
Predicted_make_model = class_mapping.get(predicted_class,“未知”)

print(f&#39;给定图像的预测品牌和型号为：{predicted_make_model}&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/77804868/i-want-to-find-vehicle-make-and-model-by-uploading-the-image</guid>
      <pubDate>Fri, 12 Jan 2024 06:57:25 GMT</pubDate>
    </item>
    <item>
      <title>UserWarning：X 没有有效的功能名称，但 KNeighborsClassifier 配备了功能名称 warnings.warn</title>
      <link>https://stackoverflow.com/questions/77804804/userwarning-x-does-not-have-valid-feature-names-but-kneighborsclassifier-was-f</link>
      <description><![CDATA[ID曾经_已婚毕业性别职业消费_分数细分家庭_大小年龄工作_经历
0 462809 0 0 1 5 2 3 3 4 1
1 462643 1 1 0 2 0 0 2 18 15
2 466315 1 1 0 2 2 1 0 44 1
3 461735 1 1 1 7 1 1 1 44 0
4 462669 1 1 0 3 1 0 5 20 15
……………………………………
8063 464018 0 0 1 9 2 3 6 4 0
8064 464685 0 0 1 4 2 3 3 15 3
8065 465406 0 1 0 5 2 3 0 14 1
8066 467299 0 1 0 5 2 1 3 8 1
8067 461879 1 1 1 4 0 1 2 17 0
8068行×10列
` data1=data.drop([&quot;ID&quot;,&quot;分割&quot;],axis=1)
from sklearn.model_selection import train_test_split
     x_train,x_test,y_train,y_test=train_test_split(data1,data.Segmentation,test_size=0.20,random_state=50)

 从 sklearn.neighbors 导入 KNeighborsClassifier
 knn=KNeighborsClassifier(n_neighbors=17)
 knn.fit(x_train,y_train)
 tahmin=knn.predict(x_test)

 knn.score(x_test,y_test)
 #0.4838909541511772
 knn.predict([[1,1,0,2,0,2,18,15]])

UserWarning：X 没有有效的功能名称，但 KNeighborsClassifier 已安装了功能名称
#warnings.warn(
#你的文本数组([1])`
当我做出预测时，我并没有预料到这个警告。]]></description>
      <guid>https://stackoverflow.com/questions/77804804/userwarning-x-does-not-have-valid-feature-names-but-kneighborsclassifier-was-f</guid>
      <pubDate>Fri, 12 Jan 2024 06:45:16 GMT</pubDate>
    </item>
    <item>
      <title>只能在 mycode 中将大小为 1 的数组转换为 Python 标量</title>
      <link>https://stackoverflow.com/questions/77804678/can-only-convert-an-array-of-size-1-to-a-python-scalar-in-mycode</link>
      <description><![CDATA[def time_lag(数据, 滞后):
    ”“”
    将数据集转换为网格信息的时间序列并吐出时间滞后的时间序列
    data - csv 文件的全名
    ”“”
    time_orig = pd.to_datetime(&#39;1900-01-01&#39;)

    df = pd.read_csv(数据)
    df.columns = [&#39;时间&#39;, &#39;wind_u10&#39;, &#39;wind_v10&#39;, &#39;slp&#39;, &#39;体重&#39;, &#39;浪涌&#39;]
    
    # 重新组织矩阵
    df_new = df.loc[df[&#39;权重&#39;] == df[&#39;权重&#39;].unique()[0]]
    df_new.drop([&#39;weight&#39;], axis = 1, inplace=True) #, &#39;surge&#39;
    
    对于范围 (1,10) 内的 i：
        df_sub = df.loc[df[&#39;weight&#39;] == df[&#39;weight&#39;].unique()[i]]
        df_sub.drop([&#39;weight&#39;, &#39;surge&#39;], axis = 1, inplace=True)
        df_new = pd.merge(df_new, df_sub, on=&#39;时间&#39;)
    
    
    # 滞后时间序列数据
    lagged_df = df_new.copy() # 防止修改原始矩阵
    对于范围内的 j（滞后）：
        #lagged.drop(j, 轴 = 0, 就地 = True)
        lagged_df[&#39;时间&#39;] = lagged_df[&#39;时间&#39;]+4
        
        # 删除最后一行，因为 df_new 中没有匹配的行
        lagged_df.drop（lagged_df.tail（1）.index.item（），轴= 0，就地= True）
        
        # 从 df_new 中删除最上面的行以匹配滞后
        df_new.drop（df_new.head（1）.index.item（），轴= 0，就地= True）
        
        # 将滞后数据与 df_new 合并
        df_new = pd.merge(df_new, lagged_df, on = &#39;时间&#39;, how = &#39;外部&#39;, \
                       后缀 = (&#39;_left&#39;, &#39;_right&#39;))
    df_new = df_new.T.reset_index(drop=True).T
    ind = df_new.loc[pd.isna(df_new[df_new.shape[1]-1]), :].index
    df_new.drop(ind, inplace=True)
    
    # 风暴潮时间序列数据
    Surge_ts = pd.DataFrame(df.loc[df[&#39;体重&#39;] == \
                                df[&#39;体重&#39;].unique()[0]][[&#39;时间&#39;, &#39;激增&#39;]])
    # 删除缺失值/NaN 值
    Surge_ts.reset_index(inplace=True) # 重置子集 isnans 的索引
    Surge_ts.drop([&#39;index&#39;], axis = 1, inplace=True)
    indx = Surge_ts.loc[pd.isna(surge_ts[“surge”]), :].index
    df_new.drop(indx, inplace=True)
    Surge_ts.drop(indx, inplace=True)
    
    # 根据 df_new 过滤浪涌
    lagged_time = 列表(df_new[0])
    time_df_new = [float(x) for x in df_new[0]]
    time_surge_ts = [float(x) for x in rush_ts[&#39;time&#39;]]
    时间_两者 = []
    对于 lagged_time 中的 k：
        if ((time_df_new 中的 k) &amp; (time_surge_ts 中的 k)):
            time_both.append(int(k))
            
    Surge_ts = Surge_ts[surge_ts[&#39;time&#39;].isin(time_both)]
    
    dt = pd.DataFrame(columns = [&#39;日期&#39;]);
    对于 Surge_ts.index 中的 i：
        dt.loc[i, &#39;日期&#39;] = time_orig + \
            datetime.timedelta(小时 = int(surge_ts.loc[i, &#39;时间&#39;]))
            
    Surge_ts[&#39;日期&#39;] = dt
    df_new = df_new[df_new[0].isin([x*1.0 for x in time_both])]
    df_new.drop(4, axis = 1, inplace = True) # 移除无滞后的浪涌数据
    返回 df_new、surge_ts

数据 = &#39;stormdata.csv&#39;
x, 浪涌 = time_lag(数据,3)
]]></description>
      <guid>https://stackoverflow.com/questions/77804678/can-only-convert-an-array-of-size-1-to-a-python-scalar-in-mycode</guid>
      <pubDate>Fri, 12 Jan 2024 06:15:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用人工智能识别文本和字典映射</title>
      <link>https://stackoverflow.com/questions/77804632/how-to-identify-text-and-dictionary-mapping-using-ai</link>
      <description><![CDATA[我正在从事一个医疗保健项目，我将收到一份包含有关患者疾病、药物等详细信息的文本。我有一个特定于领域的标准词典，其中包含疾病的标准术语和唯一的 ID。我需要创建一个人工智能模型来处理文本，然后识别字典中的正确映射。
示例：
在文字中 - 患者提到我从过去三天开始就胃痛，医生给我开了 xxx 药。
输出 - 腹痛 [1032713]（它产生了该症状的唯一 ID 和相应的标准术语）
有人可以指导我应该采取什么方法来解决这个问题吗？
我探索并发现我应该为文本和字典单词创建单词嵌入。但字典里可能有数百万个单词，这实际上是不可能的。]]></description>
      <guid>https://stackoverflow.com/questions/77804632/how-to-identify-text-and-dictionary-mapping-using-ai</guid>
      <pubDate>Fri, 12 Jan 2024 06:03:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 LOOCV 进行 K 最近邻的问题</title>
      <link>https://stackoverflow.com/questions/77804296/problem-conducting-k-nearest-neighbors-using-loocv</link>
      <description><![CDATA[我有一个示例表，我想对其进行 KKNN 分类。变量 V4 是响应，我希望分类器查看新数据点是否将分类为 0 或 1（实际数据有 12 列，第 12 列是响应，但我仍然会简化示例
库(kknn)

数据 &lt;- data.frame(
  V1=c(1.2,2.5,3.1,4.8,5.2),
  V2=c(0.7, 1.8, 2.3, 3.9, 4.1),
  V3=c(2.3, 3.7, 1.8, 4.2, 5.5),
  V4= c(0, 1, 0, 1, 0)
）

现在，我想使用 for 循环通过 LOOCV 构建 kknn 分类。假设 kknn=3
for (i in 1:nrow(data)) {
  train_data &lt;- 数据[-i, 1:3]
  train_data_response &lt;- data.frame(data[-i, 4])
  colnames(train_data_response) &lt;- “响应”
  test_set &lt;- 数据[i, 3]
  模型 &lt;- kknn(公式=train_data_response ~ ., data.frame(train_data),
                data.frame(test_set)，k=3，scale=TRUE)
}

现在我收到以下错误：
&lt;块引用&gt;
model.frame.default(公式，数据=训练)中的错误：
变量“train_data_response”的类型（列表）无效

有什么办法可以解决这个错误吗？我认为 kknn 接受矩阵或数据帧。我的训练和测试数据确实是数据框，那么什么给出了？
另外，我的 LOOCV 操作正确吗？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77804296/problem-conducting-k-nearest-neighbors-using-loocv</guid>
      <pubDate>Fri, 12 Jan 2024 04:15:37 GMT</pubDate>
    </item>
    <item>
      <title>构建聊天机器人以建议代码片段和 sharePoint 文件链接</title>
      <link>https://stackoverflow.com/questions/77804224/build-chatbot-to-suggest-code-snippets-and-sharepoint-file-links</link>
      <description><![CDATA[我正在尝试构建一个聊天机器人来训练我的数据并输出响应（代码片段、语法、网络链接、SharePoint 文件链接、文本响应等）。考虑到多种类型的输出响应，我不确定生成式 AI 和描述性 ML 模型中的哪一种适合我。有人可以让我了解从哪里开始吗？
我过去曾尝试过使用 TensorFlow 和 Keras 进行文本处理，但在这种情况下，我认为我不能使用它。]]></description>
      <guid>https://stackoverflow.com/questions/77804224/build-chatbot-to-suggest-code-snippets-and-sharepoint-file-links</guid>
      <pubDate>Fri, 12 Jan 2024 03:43:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在 kubernetes 中构建机器学习平台 [关闭]</title>
      <link>https://stackoverflow.com/questions/77804053/how-to-build-a-machine-learning-platform-in-kubernetes</link>
      <description><![CDATA[我需要在 Kubernetes 上构建一个自助机器学习平台。该平台适用于数据科学团队，无论他们的用例是机器学习、深度学习还是法学硕士。我想了解如何从 Kubernetes 设计转向 kubeflow、mlflow、spark、kafka 等组件，甚至 GPU/CPU 基线。任何有关此事的线索或阅读都将受到高度赞赏。 kubernetes 将是本地安装，而不是云托管服务。]]></description>
      <guid>https://stackoverflow.com/questions/77804053/how-to-build-a-machine-learning-platform-in-kubernetes</guid>
      <pubDate>Fri, 12 Jan 2024 02:30:35 GMT</pubDate>
    </item>
    <item>
      <title>初始化 VAE 权重</title>
      <link>https://stackoverflow.com/questions/77804014/initializing-vae-weights</link>
      <description><![CDATA[我正在训练遵循以下整体架构的 VAE：

变压器编码器
Mu/Logvar -&gt;重新参数化-&gt;潜在z
变压器解码器

根据典型的 VAE 设置，Mu 和 Logvar 只是两个前馈网络。然而，当我用标准值（例如权重为 0.5，偏差为 0）初始化它们时，我发现模型的初始 KL 损失巨大 - 例如5,000-20,000+。
当然，这个下降得相当快，但模型仍然花费数百个时期将 KL 损失从 300 降至 &lt;50。
一个“解决方法”我发现将权重初始化为低得多的值，并使用学习率预热。但初始化权重非常小：
def init_weights(self, initrange=0.0001) -&gt; &gt;没有任何：
        self.embedding_layer.weight.data.uniform_(-0.5, 0.5)
        
        nn.init.uniform_(self.fc_mu.weight, -initrange, initrange)
        nn.init.uniform_(self.fc_logvar.weight, -initrange, initrange)
        nn.init.zeros_(self.fc_mu.bias)
        nn.init.zeros_(self.fc_logvar.bias)

这样做的结果是一个更加稳定的 KL 损失（开始时约为 1.5），但我担心它会阻止我的解码器学习有意义的表示。实际的重建损失因此受到巨大影响。
所以我的问题是：这是 VAE 的已知问题吗？有什么我可以尝试的特定初始化技巧吗？或者也许我应该从正常值开始，让模型训练的时间明显更长？
提前非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77804014/initializing-vae-weights</guid>
      <pubDate>Fri, 12 Jan 2024 02:14:48 GMT</pubDate>
    </item>
    <item>
      <title>解释这个学习曲线[关闭]</title>
      <link>https://stackoverflow.com/questions/77803095/interpreting-this-learning-curve</link>
      <description><![CDATA[我一直在为我的简历开发一个基本的情感分析项目，并在这里为我的神经网络模型绘制了一条学习曲线。我是否正确绘制了学习曲线？这个具体的曲线告诉了我什么？
就上下文而言，我的训练准确度是 0.758
测试精度：.731
CV 准确度：.715

我无法判断这是否表明过度拟合，或者更多的训练数据将是有益的。]]></description>
      <guid>https://stackoverflow.com/questions/77803095/interpreting-this-learning-curve</guid>
      <pubDate>Thu, 11 Jan 2024 21:20:04 GMT</pubDate>
    </item>
    <item>
      <title>在 XGBoost 和 SHAP 中使用子采样数据的 SHAP 解释器错误</title>
      <link>https://stackoverflow.com/questions/77800921/shap-explainer-error-using-subsampled-data-in-xgboost-and-shap</link>
      <description><![CDATA[我正在尝试对数据子集进行随机采样，以从 XGBoost 模型创建 SHAP TreeExplainer 对象。我使用数据子集，因为从完整数据集（200K+）行创建 TreeExplainer 对象需要几天的时间才能运行。但是，当我运行代码时，我收到 TreeExplainer 错误。
我的代码：
&lt;前&gt;&lt;代码&gt;导入xgboost
将 numpy 导入为 np
将 pandas 导入为 pd
导入形状

数据= np.load（&#39;pandas_df.pkl&#39;，allow_pickle = True）
X = 数据[[&#39;feat_1&#39;, &#39;feat_2&#39;, ...., &#39;feat_n&#39;]]
y = 数据[[&#39;响应&#39;]]
X_train，X_test，y_train，y_test = train_test_split（X，y，test_size = 0.2，random_state = 0）

模型 = xgboost.XGBRFClassifier()
model.fit(X_train, y_train)

shap_sample_x_test = X_test.sample(n = 1000, random_state = 0)

解释器 = shap.Explainer(模型)
shap_values = 解释器(shap_sample_x_test)

shap.plots.beeswarm(shap_values)

这会导致此错误：
ExplainerError：TreeExplainer 中的可加性检查失败！请确保您传递给解释器的数据矩阵与模型训练时的形状相同。如果您的数据形状正确，请在 GitHub 上报告此情况。考虑使用 feature_perturbation=&#39;interventional&#39; 选项重试。此检查失败，因为其中一个样本的 SHAP 值总和为 -1.947115，而模型输出为 -1.936696。如果这种差异可以接受，您可以设置 check_additivity=False 来禁用此检查。
]]></description>
      <guid>https://stackoverflow.com/questions/77800921/shap-explainer-error-using-subsampled-data-in-xgboost-and-shap</guid>
      <pubDate>Thu, 11 Jan 2024 14:49:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 3.12.1 上安装 PyTorch</title>
      <link>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</link>
      <description><![CDATA[我正在安装 DARTS TimeSeries 库 (https: //github.com/unit8co/darts/blob/master/INSTALL.md#enabling-Optional-dependencies），但我遇到了依赖项安装问题。在 DARTS 安装指南中，它说如果我们遇到这个问题，我们必须参考 PyTorch 的官方安装指南，然后尝试再次安装 Darts。然后，当我尝试在 python 3.12.1 上安装 torch 时，我遇到了这个错误：
&lt;块引用&gt;
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版。

如何解决？
我使用 PyCharm 作为 Python 代码编辑器。
我尝试了pip install darts，但它没有安装所有软件包并遇到此错误错误：subprocess-exited-with-error
 用于安装构建依赖项的 pip 子进程未成功运行。
  │ 退出代码：1
  ╰─&gt; 【136行输出】
      正在收集setuptools&gt;=64.0
        从 https://files.pythonhosted.org/packages 获取 setuptools&gt;=64.0 的依赖信息

然后，我尝试使用 pip install torch 安装 torch 并遇到此错误
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版]]></description>
      <guid>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</guid>
      <pubDate>Wed, 10 Jan 2024 10:16:06 GMT</pubDate>
    </item>
    <item>
      <title>在 Sagemaker 中部署 dolly2 模型进行嵌入，但在调用端点时收到 400 错误</title>
      <link>https://stackoverflow.com/questions/76380739/deployed-dolly2-model-in-sagemaker-for-embeddings-but-receiving-a-400-error-whe</link>
      <description><![CDATA[我已经在 sagemaker 中部署了 dolly2 模型，并且正在尝试创建一些用于嵌入的向量，该代码对于文本生成来说效果很好，但是在更改 inference.py 来处理嵌入之后，我收到以下错误
otocore.errorfactory.ModelError：调用 InvokeEndpoint 操作时发生错误 (ModelError)：从主服务器收到客户端错误 (400)，消息为“{
  “代码”：400，
  “类型”：“InternalServerException”，
  &quot;message&quot;: &quot;(\&quot;您需要定义以下之一 [\u0027audio-classification\u0027, \u0027automatic-speech-recognition\u0027, \u0027feature-extraction\u0027, \u0027text-classification\u0027, \u0027标记分类\u0027、\u0027问答\u0027、\u0027表格问答\u0027、\u0027视觉问答\u0027、\u0027文档问答\u0027、\u0027填充掩码\u0027、\u0027摘要\u0027、\u0027翻译\u0027、\u0027text2文本生成\u0027、\u0027文本生成\u0027、\u0027零样本分类\u0027、\u0027零样本图像分类\u0027、\u0027会话\u0027、\u0027图像-分类\u0027、\u0027图像分割\u0027、\u0027图像到文本\u0027、\u0027对象检测\u0027、\u0027零镜头对象检测\u0027、\u0027深度估计\u0027、\u0027视频分类\ u0027] 作为环境 \u0027HF_TASK\u0027.\&quot;, 403)&quot;
}

下面您还可以看到我用于嵌入的代码
导入json
导入操作系统
导入boto3
从变压器进口管道


def invoke_sagemaker_endpoint():
    # 创建 SageMaker 客户端
    sagemaker_client = boto3.client(“sagemaker-runtime”)

    # 定义端点名称和负载
    endpoint_name = &#39;XXX&#39; # 替换为您的 SageMaker 端点名称
    Payload = {“inputs”：“这是一个大文档。”} # 按照模型的预期更新有效负载格式

    # 将请求发送到 SageMaker 端点
    响应= sagemaker_client.invoke_endpoint（
        端点名称=端点名称，
        ContentType =“应用程序/json”，
        正文=json.dumps(有效负载),
    ）

    # 解析响应并提取嵌入向量
    response_body = response[“Body”].read().decode(“utf-8”)
    response_json = json.loads(response_body)

    如果“嵌入”是在response_json中：
        嵌入 = response_json[“嵌入”]
        embeddings_vector = embeddings[0] # 嵌入作为列表返回
        返回嵌入向量
    别的：
        返回无


如果 __name__ == “__main__”：
    # 将嵌入的 HF_TASK 环境变量设置为“feature-extraction”
    os.environ[&quot;HF_TASK&quot;] = &quot;特征提取&quot;
    # 调用 SageMaker 端点
    embeddings_vector = invoke_sagemaker_endpoint()

    如果嵌入向量：
        打印（嵌入向量）
    别的：
        print(“响应中未发现嵌入。”)



和 inference.py
&lt;前&gt;&lt;代码&gt;
进口火炬
从变压器进口管道

def model_fn(model_dir):
    模型=管道（
        “文本生成”，
        模型=模型目录，
        torch_dtype=torch.bfloat16,
        trust_remote_code=真，
        device_map=“自动”，
        model_kwargs={“load_in_8bit”：True}，
    ）
    分词器=模型.分词器
    embeddings_model = 模型.model

    defgenerate_embeddings（输入）：
        输入 = tokenizer(输入、截断=True、填充=“最长”、return_tensors=“pt”)
        使用 torch.no_grad()：
            输出 = embeddings_model(**输入)
        嵌入=outputs.last_hidden_​​state.mean(dim=1).squeeze(0).tolist()
        返回嵌入

    defretrieve_qa（问题，上下文）：
        输入 = {“问题”：问题，“上下文”：上下文}
        qa_outputs = 模型（问题，上下文）
        返回 qa_outputs

    返回模型、generate_embeddings、retrieve_qa

更改了推理，将 HF 重新部署到 sagemaker，从 api 网关而不是 sagemaker 端点调用]]></description>
      <guid>https://stackoverflow.com/questions/76380739/deployed-dolly2-model-in-sagemaker-for-embeddings-but-receiving-a-400-error-whe</guid>
      <pubDate>Thu, 01 Jun 2023 09:59:24 GMT</pubDate>
    </item>
    </channel>
</rss>