<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 14 Oct 2024 01:17:27 GMT</lastBuildDate>
    <item>
      <title>Gymnasium 自定义环境“太多值无法解压”错误</title>
      <link>https://stackoverflow.com/questions/79084313/gymnasium-custom-environment-too-many-values-to-unpack-error</link>
      <description><![CDATA[我正在尝试使用具有体育馆和稳定基线的自定义群体群集环境。我有一个自定义策略和训练循环。
我的行动和观察空间如下：
min_action = np.array([-5, -5] * len(self.agents), dtype=np.float32)
max_action = np.array([5, 5] * len(self.agents), dtype=np.float32)

min_obs = np.array([-np.inf, -np.inf, -2.5, -2.5] * len(self.agents), dtype=np.float32)
max_obs = np.array([np.inf, np.inf, 2.5, 2.5] * len(self.agents), dtype=np.float32)

训练代码：
import numpy as np
import torch as th
from Parameters import *
from stable_baselines3 import PPO
from main import FlockingEnv, CustomMultiAgentPolicy
from Callbacks import TQDMProgressCallback, LossCallback
import os
from stable_baselines3.common.vec_env import DummyVecEnv

if os.path.exists(Results[&quot;Rewards&quot;]):
os.remove(Results[&quot;Rewards&quot;])
print(f&quot;File {Results[&#39;Rewards&#39;]} has been removed.&quot;)

if os.path.exists(&quot;training_rewards.json&quot;):
os.remove(&quot;training_rewards.json&quot;)
print(f&quot;文件 training_rewards 已被删除。&quot;) 

def seed_everything(seed):
np.random.seed(seed)
os.environ[&#39;PYTHONHASHSEED&#39;] = str(seed)
th.manual_seed(seed)
th.cuda.manual_seed(seed)
th.backends.cudnn.deterministic = True
env.seed(seed)
env.action_space.seed(seed)

loss_callback = LossCallback()
env = DummyVecEnv([lambda: FlockingEnv()])

seed_everything(SimulationVariables[&quot;Seed&quot;])

# # 模型训练
model = PPO(CustomMultiAgentPolicy, env, tensorboard_log=&quot;./ppo_Agents_tensorboard/&quot;, verbose=1)
model.set_random_seed(SimulationVariables[&quot;ModelSeed&quot;])
progress_callback = TQDMProgressCallback(total_timesteps=SimulationVariables[&quot;LearningTimeSteps&quot;])
# 训练模型
model.learn(total_timesteps=SimulationVariables[&quot;LearningTimeSteps&quot;], callback=[progress_callback, loss_callback])

错误：
使用 cuda 设备
回溯（最近一次调用最后一次）：
文件 &quot;D:\Thesis_\FlockingFinal\MultiAgentFlocking\Training.py&quot;，行45，在&lt;module&gt;中
model.learn(total_timesteps=SimulationVariables[&quot;LearningTimeSteps&quot;], callback=[progress_callback, loss_callback]) 
文件&quot;C:\Python312\Lib\site-packages\stable_baselines3\ppo\ppo.py&quot;，第 315 行，在 learn 中
return super().learn(
^^^^^^^^^^^^^^^
文件&quot;C:\Python312\Lib\site-packages\stable_baselines3\common\on_policy_algorithm.py&quot;，第 287 行，在 learn 中
total_timesteps, callback = self._setup_learn(
^^^^^^^^^^^^^^^^^^^
文件&quot;C:\Python312\Lib\site-packages\stable_baselines3\common\base_class.py&quot;，第 423 行，在 _setup_learn
self._last_obs = self.env.reset() # 类型：ignore[assignment]
^^^^^^^^^^^^^^^^^
文件 &quot;C:\Python312\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py&quot;，第 77 行，在 reset
obs 中，self.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError：太需要解压的值很多（预计为 2 个）

我也在 gym 中使用了类似的种子函数，但没有出现错误，我以为是它导致了错误，但即使我不使用它，错误也不会消失。]]></description>
      <guid>https://stackoverflow.com/questions/79084313/gymnasium-custom-environment-too-many-values-to-unpack-error</guid>
      <pubDate>Sun, 13 Oct 2024 22:45:48 GMT</pubDate>
    </item>
    <item>
      <title>DETR（检测变压器）模型不适用于我的数据集</title>
      <link>https://stackoverflow.com/questions/79084295/detr-detection-transformer-model-is-not-working-for-my-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79084295/detr-detection-transformer-model-is-not-working-for-my-dataset</guid>
      <pubDate>Sun, 13 Oct 2024 22:27:50 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该将遗忘集拆分为训练/验证/测试，以使用 CNN 和 Celeba 数据集进行反学习实验？[关闭]</title>
      <link>https://stackoverflow.com/questions/79084014/should-i-split-the-forget-set-into-train-validate-test-for-an-unlearning-experim</link>
      <description><![CDATA[我正在 CelebA 数据集上训练一个简单的 CNN，并尝试通过创建一个遗忘集（来自 CelebA 的随机部分图像）来进行反学习实验。
CNN 已在完整训练集上进行训练，并进行了单独的验证和测试拆分以进行评估。
我是否应该将遗忘集拆分为训练/测试/验证子集，如果是，为什么？（遗忘集约占训练集的 10% - 其余 90% 为保留集）
在我当前的反学习实验中，我只对遗忘集进行反学习，没有进行任何重新训练。因此，我在此过程中仅使用完整模型和遗忘集。
我尝试使用我相应拆分的遗忘集，但测试变得棘手，并且可能只有一个遗忘集感觉合乎逻辑（因为遗忘集中不是同一个人，它是一个混合包）
因此，拆分为测试和验证意味着它是不同面孔的不同包。]]></description>
      <guid>https://stackoverflow.com/questions/79084014/should-i-split-the-forget-set-into-train-validate-test-for-an-unlearning-experim</guid>
      <pubDate>Sun, 13 Oct 2024 19:44:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么尽管使用了 RLZoo3 的最佳超参数，我的 SB3 DQN 代理仍无法学习 CartPole-v1？</title>
      <link>https://stackoverflow.com/questions/79083972/why-is-my-sb3-dqn-agent-unable-to-learn-cartpole-v1-despite-using-optimal-hyperp</link>
      <description><![CDATA[我从 RLZoo3 获得了用于训练 CartPole-v1 的最佳超参数。我创建了一个最小示例来展示我的 CartPole 代理的性能。根据官方文档，代理应获得 500 分，才能成功完成一集。不幸的是，分数没有超过 300。
这是我的代码 -
import gymnasium as gym
import numpy as np
import torch
from stable_baselines3 import DQN
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import BaseCallback
from torch.utils.tensorboard import SummaryWriter
import os

def set_seed(seed):
np.random.seed(seed)
torch.manual_seed(seed)
torch.backends.cudnn.deterministic = True

class TensorBoardCallback(BaseCallback):
def __init__(self, log_dir):
super().__init__()
self.writer = SummaryWriter(log_dir=log_dir)
self.episode_rewards = []
self.current_episode_reward = 0

def _on_step(self):
self.current_episode_reward += self.locals[&#39;rewards&#39;][0]

如果 self.locals[&#39;dones&#39;][0]:
self.episode_rewards.append(self.current_episode_reward)
self.writer.add_scalar(&#39;train/episode_reward&#39;, self.current_episode_reward, self.num_timesteps)
self.current_episode_reward = 0

如果 len(self.episode_rewards) &gt;= 100:
avg_reward = sum(self.episode_rewards[-100:]) / 100
self.writer.add_scalar(&#39;train/average_reward&#39;, avg_reward, self.num_timesteps)

return True

def on_training_end(self):
self.writer.close()

# 设置日志目录
log_dir = &quot;tensorboard_logs&quot;
os.makedirs(log_dir, exist_ok=True)

# 设置可重复性的种子
seed = 42
set_seed(seed)

# 创建环境
env = gym.make(&quot;CartPole-v1&quot;)
env = DummyVecEnv([lambda: env])

# 使用来自 rlzoo3 的超参数创建模型
model = DQN(
policy=&quot;MlpPolicy&quot;,
env=env,
learning_rate=2.3e-3,
batch_size=64,
buffer_size=100000,
learning_starts=1000,
gamma=0.99,
target_update_interval=10,
train_freq=256,
gradient_steps=128,
exploration_fraction=0.16,
exploration_final_eps=0.04,
policy_kwargs=dict(net_arch=[256, 256]),
verbose=1,
tensorboard_log=log_dir,
seed=seed
)

# 创建回调
tb_callback = TensorBoardCallback(log_dir)

# 训练模型
total_timesteps = 50000
model.learn(total_timesteps=total_timesteps, callback=tb_callback)

print(&quot;训练完成。您可以使用 TensorBoard 查看结果。&quot;)
print(f&quot;在您的终端中运行以下命令：tensorboard --logdir {log_dir}&quot;)

env.close()

这是最终结果 -
]]></description>
      <guid>https://stackoverflow.com/questions/79083972/why-is-my-sb3-dqn-agent-unable-to-learn-cartpole-v1-despite-using-optimal-hyperp</guid>
      <pubDate>Sun, 13 Oct 2024 19:23:17 GMT</pubDate>
    </item>
    <item>
      <title>ML 梯度下降 [关闭]</title>
      <link>https://stackoverflow.com/questions/79082800/ml-gradient-descent</link>
      <description><![CDATA[梯度下降
梯度下降是机器学习中最广泛使用的优化算法之一。它通过迭代调整模型参数来帮助最小化成本函数（或损失函数）。
梯度下降中的导数：梯度（偏导数向量）显示损失函数最陡峭的增长方向。为了最小化损失，参数会沿梯度的反方向更新。从数学上来说，参数更新规则是：
𝜃
𝜃
−
𝛼
∇
𝜃
𝐽
(
𝜃
)
θ=θ−α∇
θ
​
J(θ)
其中
𝜃
θ 表示模型参数，
𝛼
α 表示学习率，
∇
𝜃
𝐽
(
𝜃
)
∇
θ
​
J(θ) 是成本函数相对于
𝜃
θ 的梯度。
2. 成本函数（损失函数）
成本函数是训练期间要最小化的目标函数。示例包括回归任务的均方误差 (MSE) 和分类任务的交叉熵。
微分学用于计算成本函数相对于模型参数的导数，以指导如何调整参数。]]></description>
      <guid>https://stackoverflow.com/questions/79082800/ml-gradient-descent</guid>
      <pubDate>Sun, 13 Oct 2024 09:18:27 GMT</pubDate>
    </item>
    <item>
      <title>Python 在分配 numpy 数组时抛出 MemoryError</title>
      <link>https://stackoverflow.com/questions/79082341/python-throws-memoryerror-while-allocating-a-numpy-array</link>
      <description><![CDATA[我正在以类似 sklearn 的方式拟合 QML 算法：
num_features = X_train.shape[1]

feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)
ansatz = RealAmplitudes(num_qubits=num_features, reps=3)
optimizer = COBYLA(maxiter=100)

vqc = VQC(
feature_map=feature_map,
ansatz=ansatz,
optimizer=optimizer
)

vqc.fit(X_train, y_train.to_numpy())

在执行 vqc.fit(X_train, y_train.to_numpy()) 行时，解释器抛出异常：
MemoryError：无法为形状为 (1048576,) 且数据类型为 &lt;U420  的数组分配 1.64 GiB
问题是，我正在使用的机器有 120 GB 的 RAM，我不明白它为什么不能为数组分配 1.64 GB。你能帮我解决这个问题吗？有什么方法可以突破这个 RAM 限制吗？
我不确定，但我想试试这个 https://stackoverflow.com/a/58686879。然而，我认为这行不通，也许你有更多的想法。]]></description>
      <guid>https://stackoverflow.com/questions/79082341/python-throws-memoryerror-while-allocating-a-numpy-array</guid>
      <pubDate>Sun, 13 Oct 2024 03:26:07 GMT</pubDate>
    </item>
    <item>
      <title>结合几种监督学习技术？[关闭]</title>
      <link>https://stackoverflow.com/questions/79081793/combining-several-supervised-learning-techniques</link>
      <description><![CDATA[我的数据集包含大量图像和制表数据（存储在 .csv 文件中）。我打算使用我拥有的所有数据（图像和制表数据）创建一个能够对案例 A 和案例 B 进行分类/识别的机器学习模型。
是否可以结合几种监督学习技术，例如使用 CNN 处理图像，使用随机森林分析制表数据？目标是创建一个对两种类型的数据进行训练的组合模型，该模型可以将案例 A 和案例 B 进行分类。
我的问题是这种方法在机器学习中是否可行。
是否有可能在训练过程中整合图像和制表数据？
对于这些类型的数据，通常推荐使用哪种机器学习算法？
我相信 CNN 是图像的不错选择，但我不确定制表数据的最佳方法是什么。
最适合用于此任务的 Python 包是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79081793/combining-several-supervised-learning-techniques</guid>
      <pubDate>Sat, 12 Oct 2024 19:52:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么飞机没有显示在 matplotlib 图中</title>
      <link>https://stackoverflow.com/questions/79081747/why-the-plane-doesnt-show-in-matplotlib-plot</link>
      <description><![CDATA[我正在对具有 13 个特征的波士顿房屋数据集实施 SLP。我为 X 选择“rm”和“zn”，为目标 Y 选择“medv”。我还从头实施了一个感知器类。在这个类中，我有一个名为 plot_losses 的函数，它在一个窗口中绘制预测线（2d）和损失，还绘制 3d 图的预测平面，这就是问题所在，即 3d 部分。
平面未显示在 3d 散点图上。
感知器类实现：
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter

感知器类：
def __init__(self, input_size, lr, epochs):
self.w = np.zeros(input_size)
self.b = 0
self.lr = lr
self.epochs = epochs
self.losses = []

def fit(self, X_train, Y_train):
for _ in range(self.epochs):
for x_i in range(X_train.shape[0]):
x = X_train[x_i]
y = Y_train[x_i]
y_pred = np.dot(x, self.w) + self.b
error = y - y_pred

self.w = self.w + (error * x * self.lr)
self.b = self.b + (error * self.lr)

loss = np.mean(np.abs(error))
self.losses.append(loss)

def predict(self, X_test):
return np.dot(X_test, self.w) + self.b

def plot_losses(self, X_train, Y_train, ax1_title, ax2_title, plot_3d=False, plot_3d_title=&#39;3D Plot&#39;):
for _ in range(self.epochs):
for x_i in range(X_train.shape[0]):
x = X_train[x_i]
y = Y_train[x_i]
Y_pred = np.dot(x, self.w) + self.b

if plot_3d:
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111,projection=&#39;3d&#39;)

X_feature1 = X_train[:, 0]
X_feature2 = X_train[:, 1]

ax.scatter(X_feature1, X_feature2, Y_train, color=&#39;blue&#39;, label=&#39;True Values&#39;)

X1_grid, X2_grid = np.meshgrid(
np.linspace(X_feature1.min(), X_feature1.max(), 20),
np.linspace(X_feature2.min(), X_feature2.max(), 20)
)

Z_pred = self.w[0] * X1_grid + self.w[1] * X2_grid + self.b

ax.plot_surface(X1_grid, X2_grid, Z_pred, color=&#39;red&#39;, alpha=0.5)
ax.set_xlabel(&quot;特征 &#39;rm&#39;&quot;)
ax.set_ylabel(&quot;特征 &#39;zn&#39;&quot;)
ax.set_zlabel(&quot;目标 &#39;medv​​&#39;&quot;)
ax.set_title(plot_3d_title)
ax.legend()
plt.show()
else:
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5))

ax1.scatter(X_train[:, 0], Y_train, color=&#39;blue&#39;, label=&#39;真值&#39;)
ax1.plot(X_train[:, 0], Y_pred, color=&#39;red&#39;, label=&#39;预测值Line&#39;)
ax1.set_title(ax1_title)
ax1.legend()

ax2.plot(self.losses)
ax2.set_title(ax2_title)
ax2.set_xlabel(&quot;Epochs&quot;)
ax2.set_ylabel(&quot;均方误差 (MSE)&quot;)

plt.tight_layout()
plt.show()

波士顿房屋数据集的线性回归：
%matplotlib qt
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
from perceptron import Perceptron
df_boston = pd.read_csv(&#39;input/BostonHousing.csv&#39;)
X = df_boston[[&#39;rm&#39;,&#39;zn&#39;]].values
Y = df_boston[&#39;medv​​&#39;].values
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=.2)

slp = Perceptron(2, .01, 100)
slp.fit(X_train, Y_train) 
slp.plot_losses(X_train,Y_train, &#39;员工工资和经验感知器&#39;, &#39;损失值&#39;, plot_3d=True, plot_3d_title=&#39;波士顿住房感知器&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/79081747/why-the-plane-doesnt-show-in-matplotlib-plot</guid>
      <pubDate>Sat, 12 Oct 2024 19:31:21 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 load_state_dict 加载我的模型：RuntimeError：为 UNetGenerator 加载 state_dict 时出错：state_dict 中出现意外键</title>
      <link>https://stackoverflow.com/questions/79081715/cant-load-my-model-using-load-state-dict-runtimeerror-errors-in-loading-sta</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79081715/cant-load-my-model-using-load-state-dict-runtimeerror-errors-in-loading-sta</guid>
      <pubDate>Sat, 12 Oct 2024 19:09:08 GMT</pubDate>
    </item>
    <item>
      <title>结合 CNN 和随机森林方法？[关闭]</title>
      <link>https://stackoverflow.com/questions/79081396/combining-cnn-and-random-forest-approach</link>
      <description><![CDATA[我的数据集包含大量图像和制表数据（存储在 .csv 文件中）。我打算使用我拥有的所有数据（图像和制表数据）创建一个能够对案例 A 和案例 B 进行分类/识别的机器学习模型。
是否可以结合几种监督学习技术，例如，使用 CNN 处理图像，使用随机森林分析制表数据？目标是创建一个对两种类型的数据进行训练的组合模型，该模型可以将案例 A 和案例 B 进行分类。
我的问题是这种方法在机器学习中是否可行。
是否可以在训练过程中集成图像和制表数据？
对于这些类型的数据，通常推荐使用哪种机器学习算法？
我认为 CNN 是图像的不错选择，但我不确定制表数据的最佳方法是什么。
最适合用于此任务的 Python 包是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79081396/combining-cnn-and-random-forest-approach</guid>
      <pubDate>Sat, 12 Oct 2024 16:08:46 GMT</pubDate>
    </item>
    <item>
      <title>用于增量学习的 Python 非线性回归器</title>
      <link>https://stackoverflow.com/questions/79063665/python-non-linear-regressor-for-incremental-learning</link>
      <description><![CDATA[我想知道 scikit-learn 中是否有一个非线性回归程序，允许增量学习，即通过 partial_fit 调用。我发现 SGDRegressor 和 PassiveAggressiveRegressor 都允许 partial_fit，但它们是线性的，而我的数据显然是非线性的，因此拟合效果并不理想。]]></description>
      <guid>https://stackoverflow.com/questions/79063665/python-non-linear-regressor-for-incremental-learning</guid>
      <pubDate>Mon, 07 Oct 2024 21:18:59 GMT</pubDate>
    </item>
    <item>
      <title>只有输入张量可以作为位置参数传递</title>
      <link>https://stackoverflow.com/questions/78360982/only-input-tensors-may-be-passed-as-positional-arguments</link>
      <description><![CDATA[从 PIL 导入图像
导入 matplotlib.pyplot 作为 plt
导入 argparse
导入 pickle
导入 numpy
作为 np
从 tensorflow 导入 keras
从 keras.applications.xception 导入 Xception
从 keras.preprocessing.sequence 导入 pad_sequences
从 tensorflow.keras.preprocessing.text 导入 Tokenizer
导入 tensorflow 作为 tf

# 使用 Lambda 定义自定义层（不带 name 参数）
class NotEqual(tf.keras.layers.Layer):
def __init__(self, name=None):
super(NotEqual, self).__init__(name=name)

def call(self, x, y): # 使用关键字参数“x”和“y”
return tf.math.not_equal(x, y)

# 定义用于提取特征、生成描述的函数，和其他必要的实用程序
def extract_features(filename, model):
try:
image = Image.open(filename)
except:
print(&quot;ERROR: 无法打开图片！请确保图片路径和扩展名正确&quot;)
image = image.resize((299, 299))
image = np.array(image)
if image.shape[2] == 4:
image = image[..., :3]
image = np.expand_dims(image, axis=0)
image = image / 127.5
image = image - 1.0
feature = model.predict(image)
return feature

def word_for_id(integer, tokenizer):
for word, index in tokenizer.word_index.items():
if index == integer:
return word
return None

def generate_desc(model, tokenizer, photo, max_length):
in_text = &#39;start&#39;
for i in range(max_length):
sequence = tokenizer.texts_to_sequences([in_text])[0]
sequence = pad_sequences([sequence], maxlen=max_length)
pred = model.predict({&#39;image_input&#39;: photo, &#39;text_input&#39;:sequence}) # 将输入作为字典传递
pred = np.argmax(pred)
word = word_for_id(pred, tokenizer)
if word is None:
break
in_text += &#39; &#39; + word
if word == &#39;end&#39;:
break
return in_text

# 解析参数
ap = argparse.ArgumentParser()
ap.add_argument(&#39;-i&#39;, &#39;--image&#39;, required=True, help=&quot;Image Path&quot;)
args = vars(ap.parse_args())
img_path = args[&#39;image&#39;]

# 加载tokenizer
tokenizer = pickle.load(open(&quot;tokenizer.p&quot;, &quot;rb&quot;))

# 定义模型的路径
model_path = &#39;models/model_9.h5&#39;
# 使用自定义对象（包括 NotEqual 层）加载模型
使用 keras.utils.custom_object_scope({&#39;NotEqual&#39;: NotEqual}):
model = tf.keras.models.load_model(model_path)

我尝试以各种方式运行此代码，但出现错误：
 model = tf.keras.models.load_model(model_path)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\saving\saving_api.py”，第 183 行，位于 load_model
return legacy_h5_format.load_model_from_hdf5(filepath)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 “C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\legacy\saving\legacy_h5_format.py”，第 133 行，位于 load_model_from_hdf5
model = saving_utils.model_from_config(
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\legacy\saving\saving_utils.py”，第 85 行，位于 model_from_config
return serialization.deserialize_keras_object(
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\legacy\saving\serialization.py”，第 495 行，位于 deserialize_keras_object
deserialized_obj = cls.from_config(
^^^^^^^^^^^^^^^^^
文件“C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\model.py”，第 528 行，位于 from_config 中
return functional_from_config(
^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\function.py”，第 528 行，位于 functional_from_config 中
process_node(layer, node_data)
文件&quot;C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\function.py&quot;，第 475 行，位于 process_node
layer(*args, **kwargs)
文件 &quot;C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\utils\traceback_utils.py&quot;，第 122 行，位于 error_handler
raise e.with_traceback(filtered_tb) from None
文件 &quot;C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\layers\layer.py&quot;，第 721 行，位于 __call__
raise ValueError(
ValueError: 只能将输入张量作为位置参数传递。以下参数值应作为关键字参数传递：0（类型为 &lt;class &#39;int&#39;&gt;）
]]></description>
      <guid>https://stackoverflow.com/questions/78360982/only-input-tensors-may-be-passed-as-positional-arguments</guid>
      <pubDate>Sun, 21 Apr 2024 09:15:40 GMT</pubDate>
    </item>
    <item>
      <title>错误：具有 ML Compute 加速功能的 TensorFlow 仅适用于 macOS 11.0 及更高版本</title>
      <link>https://stackoverflow.com/questions/74563984/error-tensorflow-with-ml-compute-acceleration-is-only-available-on-macos-11-0-a</link>
      <description><![CDATA[下载 Tensor Flow mac 发布包 (https://github.com/apple/tensorflow_macos/releases)，打开 tensorflow_macos-0.1alpha3.tar.gz 包，运行“install_venv.sh”脚本，出现以下错误 ERROR: 带有 ML Compute 加速的 TensorFlow 仅在 macOS 11.0 及更高版本上可用。
我在 conda 环境中使用 python 3.8 运行它（我尝试过 3.7-3.11，结果相同）。
我会在 apple github repo 上发布，但它已被公开存档，所以假设它不再可用？
我尝试过在 conda 环境中使用 python 3.8 运行它（我尝试过 3.7-3.11，结果相同）。
我预计安装会成功。我尝试安装 pip install tensorflow（即没有特定于 mac），pyCharm 看到了 lib tensorflow，但我得到
Apple M1：进程完成，退出代码为 132（被信号 4 中断：sigill，解决方案是从上面安装包：https://github.com/apple/tensorflow_macos/issues/270]]></description>
      <guid>https://stackoverflow.com/questions/74563984/error-tensorflow-with-ml-compute-acceleration-is-only-available-on-macos-11-0-a</guid>
      <pubDate>Thu, 24 Nov 2022 16:46:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么自然语言处理中的 Transformer 需要一堆编码器？</title>
      <link>https://stackoverflow.com/questions/59384146/why-do-transformers-in-natural-language-processing-need-a-stack-of-encoders</link>
      <description><![CDATA[我正在关注这篇关于 transformers 的博客
http://jalammar.github.io/illustrated-transformer/
我唯一不明白的是为什么需要一堆编码器或解码器。我知道多头注意力层捕获了问题的不同表示空间。我不明白为什么需要一堆编码器和解码器。一个编码器/解码器层不行吗？]]></description>
      <guid>https://stackoverflow.com/questions/59384146/why-do-transformers-in-natural-language-processing-need-a-stack-of-encoders</guid>
      <pubDate>Wed, 18 Dec 2019 00:57:26 GMT</pubDate>
    </item>
    <item>
      <title>线性回归爆炸的梯度下降</title>
      <link>https://stackoverflow.com/questions/50219054/gradient-descent-for-linear-regression-exploding</link>
      <description><![CDATA[我正在尝试使用此资源实现线性回归的梯度下降：https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/
我的问题是，我的权重正在爆炸式增长（呈指数增长），并且本质上与预期相反。
首先，我创建了一个数据集：
def y(x, a):
return 2*x + a*np.random.random_sample(len(x)) - a/2

x = np.arange(20)
y_true = y(x,10)

看起来像这样：

要优化的线性函数：
def y_predict(x, m, b):
return m*x + b

因此，对于一些随机选择的参数，结果如下：
m0 = 1
b0 = 1

a = y_predict(x, m0, b0)

plt.scatter(x, y_true)
plt.plot(x, a)
plt.show()


现在成本看起来是这样的：
cost = (1/2)* np.sum((y_true - a) ** 2)

成本相对于预测 (dc_da) 的偏导数：
dc_da = (a - y_true) # 仍然是一个向量

成本相对于斜率参数 (dc_dm) 的偏导数：
dc_dm = dc_da.dot(x) # 现在是一个常数

成本相对于 y 截距参数 (dc_db) 的偏导数：
dc_db = np.sum(dc_da) # 也是一个常数

最后是梯度下降的实现：
iterations = 10

m0 = 1

b0 = 1

learning_rate = 0.1

N = len(x)

for i in range(iterations):

a = y_predict(x, m0, b0)

cost = (1/2) * np.sum((y_true - a) ** 2)

dc_da = (a - y_true)

mgrad = dc_da.dot(x)
bgrad = np.sum(dc_da)

m0 -= learning_rate * (2 / N) * mgrad
b0 -= learning_rate * (2 / N) * bgrad

if (i % 2 == 0):
print(&quot;Iteration {}&quot;.format(i))
print(&quot;Cost: {}, m: {}, b: {}\n&quot;.format(cost, m0, b0))

结果为：
迭代 0
Cost: 1341.5241150881411, m: 26.02473879743261, b: 2.8683883457327797

迭代 2
Cost: 409781757.38124645, m: 13657.166910552878, b: 1053.5831308528543

迭代 4
Cost: 132510115599264.75，m：7765058.4350503925，b：598610.1166795876

迭代 6
成本：4.284947676217907e+19，m：4415631880.089208，b：340401694.5610262

迭代 8
成本：1.3856132043127762e+25，m：2510967578365.3584，b：193570850213.62192

我的实现有什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/50219054/gradient-descent-for-linear-regression-exploding</guid>
      <pubDate>Mon, 07 May 2018 16:54:52 GMT</pubDate>
    </item>
    </channel>
</rss>