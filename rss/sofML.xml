<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 01 May 2024 06:20:56 GMT</lastBuildDate>
    <item>
      <title>尝试使用 YOLOv8 训练后出现多处理错误</title>
      <link>https://stackoverflow.com/questions/78412108/multiprocessing-error-after-trying-to-train-with-yolov8</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78412108/multiprocessing-error-after-trying-to-train-with-yolov8</guid>
      <pubDate>Wed, 01 May 2024 05:10:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 conda 环境无法在 colab 或 kaggle 中运行</title>
      <link>https://stackoverflow.com/questions/78411886/why-my-conda-environment-is-not-working-in-colab-or-kaggle</link>
      <description><![CDATA[&lt;块引用&gt;
conda install --channel 默认 conda python=3.8 --yes
conda update --channel defaults --all --yes

一个月前，它运行良好。但现在显示错误。如何修复此无效语法和错误。
代码链接：- https://colab.research.google.com/github/SwayamInSync/clothes-virtual-try-on/blob/main/setup_gradio.ipynb#scrollTo=1k2dVj4vMhwA
我之前在 colab 上运行过这段代码，但现在不起作用。任何人都可以帮助我运行此代码或帮助我修复此错误]]></description>
      <guid>https://stackoverflow.com/questions/78411886/why-my-conda-environment-is-not-working-in-colab-or-kaggle</guid>
      <pubDate>Wed, 01 May 2024 03:24:43 GMT</pubDate>
    </item>
    <item>
      <title>寻找机器学习方面的指导[关闭]</title>
      <link>https://stackoverflow.com/questions/78411363/looking-for-mentorships-in-machine-learning</link>
      <description><![CDATA[我是机器学习的初学者，这个平台上是否有人愿意指导我完成机器学习专业版之旅？
我精通Python。寻找指导来帮助我进行机器学习]]></description>
      <guid>https://stackoverflow.com/questions/78411363/looking-for-mentorships-in-machine-learning</guid>
      <pubDate>Tue, 30 Apr 2024 22:58:58 GMT</pubDate>
    </item>
    <item>
      <title>学习曲线是否表明过度拟合或模型性能处于可接受的水平？</title>
      <link>https://stackoverflow.com/questions/78411015/does-the-learning-curve-suggest-overfitting-or-an-acceptable-level-of-model-perf</link>
      <description><![CDATA[
学习曲线是否表明模型性能过度拟合或处于可接受的水平？结果基于xgboost。我需要重新调整超参数吗？]]></description>
      <guid>https://stackoverflow.com/questions/78411015/does-the-learning-curve-suggest-overfitting-or-an-acceptable-level-of-model-perf</guid>
      <pubDate>Tue, 30 Apr 2024 21:03:33 GMT</pubDate>
    </item>
    <item>
      <title>这是一个 CNN 1d 模型，通过观察电流信号找出电压</title>
      <link>https://stackoverflow.com/questions/78409956/this-is-a-cnn-1d-model-to-find-out-the-voltages-by-observing-the-current-signal</link>
      <description><![CDATA[它说：
&lt;块引用&gt;
由于 conv1d_4 中的下采样，输出中的一个维度 &lt;= 0。考虑增加输入大小。接收到的输入形状 [None, 9600, 1, 1]，它将产生维度为零或负值的输出形状。

这是我到目前为止所做的：
dataset_url=“https://github.com/Kaustav-coder/cnn/blob/main/cnn.csv”

从 keras.models 导入顺序
从 keras.layers 导入密集、扁平化
从 keras.layers 导入 Conv1D、MaxPooling1D、Dropout
从 keras.layers 导入嵌入
来自 keras.preprocessing 导入序列
从 sklearn.model_selection 导入 train_test_split
将 pandas 导入为 pd
将 numpy 导入为 np
从sklearn导入预处理
从sklearn.metrics导入accuracy_score，confusion_matrix，classification_report

数据=pd.read_csv(&#39;cnn.csv&#39;)
y=数据[&#39;电压&#39;]
x=data.drop([&#39;电压&#39;],轴=1)

label_encoder = 预处理.LabelEncoder()
y_enc = label_encoder.fit_transform(y)
x_reshape = x.values.reshape(x.shape[0], x.shape[1],1)
x_train,x_test,y_train,y_test= train_test_split(x_reshape,y_enc,test_size=0.2,random_state=42)

模型=顺序（）
model.add(Conv1D(filters=64, kernel_size=10,activation=&#39;relu&#39;, input_shape=(9600,1,1)))
model.add(MaxPooling1D(pool_size=1))
model.add(Conv1D(filters=64，kernel_size=10，activation=&#39;relu&#39;))
model.add(MaxPooling1D(pool_size=1))
模型.add(压平())
model.add（密集（128，激活=&#39;relu&#39;））
模型.add(Dropout(0.25))
model.add（密集（128，激活=&#39;softmax&#39;））
]]></description>
      <guid>https://stackoverflow.com/questions/78409956/this-is-a-cnn-1d-model-to-find-out-the-voltages-by-observing-the-current-signal</guid>
      <pubDate>Tue, 30 Apr 2024 16:42:09 GMT</pubDate>
    </item>
    <item>
      <title>大尺寸的一种热编码[关闭]</title>
      <link>https://stackoverflow.com/questions/78409561/one-hot-encoding-with-large-dimensions</link>
      <description><![CDATA[我正在构建一个销售预测模型，其中包含“年”、“月”、“经济指标”、“Customer_Id”、“Product_Id”、“Quantity”、“Sales”、“ “保证金”。
清理后的数据集包含约 150 万行和上述 8 列，这是过去 6 年每个客户每种产品的每月销售额。我的最终目标是能够预测整个来年未来几个月的销售额，但更准确地说，预测将针对每个客户级别的产品，这是一个非常详细的级别。
但是，由于我的Customer_Id和Product_Id是TEXT，例如“A77BC”，并且有超过100000个唯一的product_id和6000个唯一的customer_id，如果我使用一种热编码来标记它们，那么维度对于我来说太高了设备来处理（例如，我的笔记本电脑有 16G 内存，但标签 customer_id 已经需要 24G 内存）并且我相信一定有更好的方法来处理这种情况，但我对机器学习非常陌生。]]></description>
      <guid>https://stackoverflow.com/questions/78409561/one-hot-encoding-with-large-dimensions</guid>
      <pubDate>Tue, 30 Apr 2024 15:23:06 GMT</pubDate>
    </item>
    <item>
      <title>model.fit 不起作用“运行时错误：‘tf.data.Dataset’仅支持急切模式下或 tf.function 内的 Python 样式迭代。”</title>
      <link>https://stackoverflow.com/questions/78409501/model-fit-is-not-working-runtimeerror-tf-data-dataset-only-supports-python-s</link>
      <description><![CDATA[我想在 JupyterLab 上编写一个简单的机器学习代码，但出现标题错误
我已经收集了数据，因为x是lamda，eps，c（数据的形状是102010行×3列），y是sen（数据的形状是102010行×1列），我想要我的机器学习模型来预测。这是我的简单模型代码。
导入tensorflow为tf
从 sklearn.model_selection 导入 train_test_split
将 pandas 导入为 pd

# 将数据拆分为特征 (X) 和目标 (y)
X_data = df_total_x_data.values.reshape(-1, 1) # 如果需要则重塑
y_data = df_sen_final.values

x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)
模型 = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)
model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))

如何修复此错误？
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
RuntimeError Traceback（最近一次调用最后一次）
单元格 In[60]，第 17 行
     15 模型 = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
     16 model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)
---&gt; 17 model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))

文件/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122，位于filter_traceback..error_handler(*args, **kwargs)
    第 119 章
    120 # 要获取完整的堆栈跟踪，请调用：
    121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
    123 最后：
    124 删除filtered_tb

文件 /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py:503，在 DatasetV2.__iter__(self) 中
    第501章
    第502章：
--&gt; 503 raise RuntimeError(“tf.data.Dataset`仅支持Python风格”
    [第 504 章]

RuntimeError: `tf.data.Dataset` 仅支持急切模式下或 tf.function 内的 Python 风格迭代。
]]></description>
      <guid>https://stackoverflow.com/questions/78409501/model-fit-is-not-working-runtimeerror-tf-data-dataset-only-supports-python-s</guid>
      <pubDate>Tue, 30 Apr 2024 15:12:43 GMT</pubDate>
    </item>
    <item>
      <title>RNN实现方程问题的简单BPTT</title>
      <link>https://stackoverflow.com/questions/78408682/simple-bptt-for-rnn-implementation-equation-question</link>
      <description><![CDATA[我正在尝试从头开始实现简单的 RNN，以了解每个实现背后的计算步骤。前向传播看起来很简单，但后向传播似乎很困难。尤其是尺寸不符……
def rnn_forward(self, e) ：
        对于范围内的 t(self.T_x - 1) ：
            # single (n_x, n_m) m 是时间上的训练集大小
            xt = self.cache[&#39;X&#39;][:, :, t]
            # 上一步的隐藏状态
            a_prev = self.cache[&#39;A&#39;][:, :, t]
            # 下一步的隐藏状态是通过以下权重和偏差计算的。
            a_next = tanh(np.dot(self.parameters[&#39;W_aa&#39;], a_prev) + np.dot(self.parameters[&#39;W_ax&#39;], xt) + self.parameters[&#39;b_a&#39;])
            # 使用softmax作为最终激活
            yt_pred = softmax(np.dot(self.parameters[&#39;W_ya&#39;], a_next) + self.parameters[&#39;b_y&#39;])
            self.cache[&#39;A&#39;][:, :, (t + 1)] = a_next
            self.cache[&#39;Y_pred&#39;][:, :, t] = yt_pred

def rnn_backward(self, e):
        # 成本函数导数
        self.cache[&#39;dY_pred&#39;] = - (self.cache[&#39;Y&#39;] / self.cache[&#39;Y_pred&#39;])
        # 初始化da
        da_next = np.zeros((self.n_a, self.m))
        对于反转中的 t(范围(self.T_x - 1)) ：
            # 维度似乎是 (n_y, n_m)
            print(self.cache[&#39;dY_pred&#39;][:, :, t].shape)
            # 维度似乎也是 (n_y, n_m)
            print(softmax_backward(np.dot(self.parameters[&#39;W_ya&#39;], self.cache[&#39;A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]).shape)
            # 下面的计算会有问题吗？ da_prev 预计有暗淡 (n_a, n_m)，但 (n_y, n_m) 和 (n_y, n_m) 的点不给我 (n_a, n_m)
            da_prev = np.dot(self.cache[&#39;dY_pred&#39;][:, :, t], np.dot(self.parameters[&#39;W_ya&#39;].T, softmax_backward(np.dot(self.parameters[&#39;W_ya&#39;) ], self.cache[&#39;A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]))) + da_next
            self.cache[&#39;dW_ya&#39;] += np.dot(self.cache[&#39;dY_pred&#39;][:, :, t], np.dot(softmax_backward(np.dot(self.parameters[&#39;W_ya&#39;], self) .cache[&#39;A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]), self.cache[&#39;A&#39;][:, :, t].T))
            self.cache[&#39;db_y&#39;] += np.dot(self.cache[&#39;dY_pred&#39;][:, :, t], softmax_backward(np.dot(self.parameters[&#39;Wya&#39;], self.cache[&#39; A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]))
            self.cache[&#39;dW_aa&#39;] += np.dot(da_prev, np.dot(tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, :, (t - 1)]) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;]), self.cache[ &#39;A&#39;][:, :, (t - 1)].T))
            self.cache[&#39;dW_ax&#39;] += np.dot(da_prev, np.dot(tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, :, (t - 1)]) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;]), self.cache[ &#39;X&#39;][:, :, t].T))
            self.cache[&#39;db_a&#39;] += np.dot(da_prev, tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, :, (t - 1)] ) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;]))
            da_next = np.dot(da_prev, np.dot(self.parameters[&#39;W_aa&#39;].T, tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, : , (t - 1)]) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;])))

正如代码中的注释，我似乎无法正确实现反向传播。 da_prev 的维数不正确，无法正确生成 (n_a, n_m)…我错过了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78408682/simple-bptt-for-rnn-implementation-equation-question</guid>
      <pubDate>Tue, 30 Apr 2024 12:58:33 GMT</pubDate>
    </item>
    <item>
      <title>转换深度学习 esrgan 模型时输入张量形状不匹配</title>
      <link>https://stackoverflow.com/questions/78407762/input-tensor-shape-mismatch-when-converting-deep-learning-esrgan-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78407762/input-tensor-shape-mismatch-when-converting-deep-learning-esrgan-model</guid>
      <pubDate>Tue, 30 Apr 2024 10:05:56 GMT</pubDate>
    </item>
    <item>
      <title>从 python 中的随机森林回归模型中查找最大值</title>
      <link>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</link>
      <description><![CDATA[当用户给出上限时，我一直在使用随机森林回归来计算广告支出回报率 (ROAS)。我的模型采用三个输入变量：电视、广播和报纸广告的成本。然而，为了找到最优值，我需要使用 for 循环来遍历每一美元，这非常耗时。有没有更快的方法来找到程序中的最高 y 值？
def ROASPrediction(Q、电视、广播、报纸)：
rec=“最佳销售推荐投资”
y_大=0
x_b=0
y_b=0
z_b=0
对于范围内的 x(TV//2,TV)：
  对于范围内的 y(Radio//2,Radio)：
    对于范围内的 z（报纸//2，报纸）：
      customer_features =np.array([x,y,z])
      customer_features1=customer_features.reshape(1, -1)
#customer_features1 =pd.DataFrame(customer_features)
      model_fit1 = joblib.load(&#39;/content/drive/MyDrive/ROAS.joblib&#39;)
      y_future_pred = model_fit1.predict(customer_features1)
      打印（“y_future_pred”，y_future_pred）
      if(y_future_pred[0]&gt;=y_big):
        y_big=y_future_pred[0]
        x_b=x
        y_b=y
        z_b=z
#y_future_pred1= str(y_future_pred[0]) + “M$”
#y_roas= y_future_pred[0]*1000000 / (电视+广播+报纸)
y_future_pred1= str(y_big) + “M$”
y_roas= y_big*1000000 / (电视+广播+报纸)
x_b1=str(x_b)
y_b1=str(y_b)
z_b1=str(z_b)
y_roas1=str(y_roas) + “%”
返回记录，x_b1，y_b1，z_b1，y_future_pred1，y_roas1

以下代码是我的随机森林模型。
df = pd.read_csv(&#39;/Advertising.csv&#39;)
df.head()
x = df[[&#39;电视&#39;,&#39;广播&#39;,&#39;报纸&#39;]]
y = df[[&#39;销售额&#39;]]
x_train, x_test, y_train, y_test = train_test_split (x, y, test_size=0.20 , random_state=41)
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)
rf_regressor.fit(x_train, y_train)
y_pred = rf_regressor.predict(x_test)

这是我正在使用的 csv 文件。 
有没有办法让 ROASPrediction 函数更加高效，这样就不需要 5 分钟来计算 30 美元的电视、广播和报纸？]]></description>
      <guid>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</guid>
      <pubDate>Tue, 30 Apr 2024 06:42:36 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    <item>
      <title>SVM 训练时间过长</title>
      <link>https://stackoverflow.com/questions/78400254/svm-training-taking-too-long</link>
      <description><![CDATA[我有一个包含 41 个特征的数据集，其中 4 个是文本特征。我得到了“词袋”这四个特征的 numpy 数组 (npz)，我将其与其他数值特征结合起来训练 SVM 模型。总共有 100000 条记录和 41 个特征，其中 4 个特征如前所述进行了矢量化。
该模型现已训练 45 分钟:)。有没有办法减少训练时间？我预处理数据集的方式（特别是结合 npz 和现有的数值特征）有什么问题吗？我还可以探索其他选择吗？
title_feature = load_npz(&#39;train_title_bow.npz&#39;)
Overview_feature = load_npz(&#39;train_overview_bow.npz&#39;)
tagline_feature = load_npz(&#39;train_tagline_bow.npz&#39;)
Production_companies_feature = load_npz(&#39;train_product_companies_bow.npz&#39;)

numeric_features = df_train[df_train.columns.difference([&#39;标题&#39;, &#39;概述&#39;, &#39;标语&#39;, &#39;生产公司&#39;, &#39;rate_category&#39;, &#39;average_rate&#39;, &#39;original_language&#39;])]
text_features = np.hstack([title_feature.toarray()、overview_feature.toarray()、tagline_feature.toarray()、生产_companies_feature.toarray()])
svm_X_train = np.hstack([数字特征, 文本特征])
svm_y_train = df_train[&#39;rate_category&#39;]

svm_classifier = SVC(kernel=&#39;linear&#39;) # 使用线性核，也可以选择其他核
svm_classifier.fit(svm_X_train, svm_y_train)
]]></description>
      <guid>https://stackoverflow.com/questions/78400254/svm-training-taking-too-long</guid>
      <pubDate>Mon, 29 Apr 2024 02:39:09 GMT</pubDate>
    </item>
    <item>
      <title>GKE 上的 GPU 时间共享</title>
      <link>https://stackoverflow.com/questions/78400223/gpu-time-sharing-on-gke</link>
      <description><![CDATA[我正在尝试使用 说明中的 GPU 时间共享此处，但是我的工作负载不会在启用分时的节点上运行。
我有一个具有 GPU 配置的节点池，启用了策略分时的 GPU 共享以及“每个 GPU 的最大共享客户端数”。如 48 所示。节点运行良好，但我无法使用记录的 nodeSelector 配置为我的工作负载运行工作负载，例如
节点选择器：
  cloud.google.com/gke-accelerator：“nvidia-tesla-t4”
  cloud.google.com/gke-max-shared-clients-per-gpu：“48”
  cloud.google.com/gke-gpu-sharing-strategy：分时

这样，我的 Pod 就会陷入挂起状态，并显示消息xnodes did not match Pod&#39;s nodeaffinity/selector。如果我删除 gke-max-shared-clients-per-gpu 和 gke-gpu-sharing-strategy 密钥对，pod 会正常调度并运行。
当我检查 GPU 分时节点池中节点上的 kubernetes 标签时，它们不包含这些标签，并且我无法手动添加它们，因为 GCP 阻止了它。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78400223/gpu-time-sharing-on-gke</guid>
      <pubDate>Mon, 29 Apr 2024 02:20:41 GMT</pubDate>
    </item>
    <item>
      <title>该系统应该能够使用手写技术解决涉及基本算术运算、线性和二次算术运算的表达式[关闭]</title>
      <link>https://stackoverflow.com/questions/78390987/the-system-should-be-capable-of-solving-expression-involving-arithmetic-operatio</link>
      <description><![CDATA[应用程序应该能够根据给定图像预测和求解手写数学方程。系统应能够求解涉及算术运算（加、减、乘、除）的表达式，并求解任意阶的方程（一次、二次、三次等）。
使用的关键人工智能概念包括 OCR（光学字符识别）和 CNN（卷积神经网络）。 OCR用于预处理图像和分割字符，CNN用于预测字符。
尝试了下面的代码，但不起作用
https://github.com/sabari205/Equation-Solver]]></description>
      <guid>https://stackoverflow.com/questions/78390987/the-system-should-be-capable-of-solving-expression-involving-arithmetic-operatio</guid>
      <pubDate>Fri, 26 Apr 2024 14:00:45 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地运行主宰模型</title>
      <link>https://stackoverflow.com/questions/78143186/how-to-run-juggernaut-model-in-local</link>
      <description><![CDATA[我想使用 python 在本地电脑上运行微调的稳定扩散模型。例如剑圣：https://huggingface.co/RunDiffusion/Juggernaut-XL-v9
这是我的代码（它适用于 stable-diffusion-xl-base-1.0）：
随机导入
从扩散器导入 DiffusionPipeline、StableDiffusionXLImg2ImgPipeline
进口火炬
导入GC
导入时间

# 用于清理内存
GC.collect()
torch.cuda.empty_cache()

开始时间 = 时间.time()

型号 =“RunDiffusion/Juggernaut-XL-v9”
管道 = DiffusionPipeline.from_pretrained(
    模型，
    torch_dtype=torch.float16,
）

管道.to(“cuda”)

提示=（“中世纪男性骑士肖像，阳刚的外观，背景中的战斗，清晰的焦点，高度详细，电影风格的灯光，阴影”）
种子 = random.randint(0, 2**32 - 1)

生成器 = torch.Generator(“cuda”).manual_seed(seed)
图像=管道（提示=提示，生成器=生成器，num_inference_steps=1）
图像=图像.图像[0]
image.save(f“output_images/{seed}.png”)

结束时间 = time.time()

总时间 = 结束时间 - 开始时间
分钟 = int(total_time // 60)
秒 = int(总时间 % 60)

print(f&quot;花费: {分钟} 分 {秒} 秒&quot;)
print(f&quot;保存到output_images/{seed}.png&quot;)


但我得到：
&lt;块引用&gt;
OSError：在目录中找不到名为 pytorch_model.bin、tf_model.h5、model.ckpt.index 或 flax_model.msgpack 的文件时出错

可能是因为python、cuda版本的原因。我正在删除我的库版本：
Python 3.9.0
PyTorch：2.2.0+cu118
CUDA：11.8
扩散器：0.26.3
变形金刚：4.38.1]]></description>
      <guid>https://stackoverflow.com/questions/78143186/how-to-run-juggernaut-model-in-local</guid>
      <pubDate>Mon, 11 Mar 2024 20:12:01 GMT</pubDate>
    </item>
    </channel>
</rss>