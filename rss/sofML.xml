<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 31 Oct 2024 03:26:10 GMT</lastBuildDate>
    <item>
      <title>寻找集群：DBSCAN 还是 Friends-of-Friends？</title>
      <link>https://stackoverflow.com/questions/79143343/finding-clusters-dbscan-or-friends-of-friends</link>
      <description><![CDATA[在我读本科的时候，我使用 Friends-of-Friends 算法在宇宙学模拟中搜索暗物质晕。
https://swift.dur.ac.uk/docs/FriendsOfFriends/algorithm_description.html
现在我是一名研究生，我使用 DBSCAN 算法在射电望远镜数据中搜索 HI 云。
https://en.wikipedia.org/wiki/DBSCAN
我发现这两种算法有一些相同之处，例如：

基于密度的聚类：DBSCAN 和从广义上讲，FoF 可以视为基于密度的方法。DBSCAN 根据数据点的密度明确定义聚类，而 FoF 还可以根据点之间的连接（即朋友）密度识别聚类。
聚类识别：两种算法都通过将某种意义上彼此接近的点分组在一起来识别聚类。在 DBSCAN 中，这基于指定半径内的点的密度，而在 FoF 中，这基于连通性或共享邻居的数量。
无需预定义聚类数量：两种算法都不需要提前指定聚类数量。DBSCAN 根据密度参数确定聚类，而 FoF 根据连通性结构查找聚类，而无需事先设置聚类数量。
处理噪声和异常值：两种方法都可以处理噪声或异常值，尽管它们处理的方式不同。DBSCAN 明确将不适合任何聚类的点归类为噪声。在 FoF 中，与其他点连接不够的点最终可能会被孤立或不属于任何重要聚类。
聚类形状灵活性：两种算法都能够识别任意形状的聚类。DBSCAN 以其基于密度的方法而闻名，能够找到各种形状和大小的聚类。FoF 还可以根据连接模式找到形状不规则的聚类。

我想知道它们之间是否存在一些重大差异，以便我可以更好地选择在聚类时使用哪个，谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79143343/finding-clusters-dbscan-or-friends-of-friends</guid>
      <pubDate>Thu, 31 Oct 2024 02:40:27 GMT</pubDate>
    </item>
    <item>
      <title>如何训练具有两个相互依赖的特征的分类（K 邻域）模型</title>
      <link>https://stackoverflow.com/questions/79142864/how-to-train-a-classification-k-neighbor-model-with-2-features-that-are-depend</link>
      <description><![CDATA[我有一组质谱图，并尝试用它们在 sklearn 上训练一个模型。因此，特征是“m/z”和“强度”，目标是“茶叶品种”。问题是，这两个特征是不可分割的，我想以某种方式将它们连接起来，如下所示：
&#39;spectrum id&#39; &#39;m/z-intensity&#39; &#39;tea variety&#39;
1 ; [[1,2],[2,3],...] ; var1
2 ; [[1,2],[2,3],...] ; var1
但是发生了一个错误，指出有一个列表需要浮点数，所以我只是连接了所有 m/z 和强度值，并在一个单元格中为每个值创建了一个数据框，虽然有效但完全不准确。有没有更好的方法来做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/79142864/how-to-train-a-classification-k-neighbor-model-with-2-features-that-are-depend</guid>
      <pubDate>Wed, 30 Oct 2024 21:34:24 GMT</pubDate>
    </item>
    <item>
      <title>验证准确率优于训练准确率问题</title>
      <link>https://stackoverflow.com/questions/79141961/validation-accuracy-better-than-train-accuracy-problem</link>
      <description><![CDATA[我有一个包含 21k 张图片的数据集。我建立了一个 CNN 模型，问题是 val 准确率比 train 准确率高很多，但 F1 Score 看起来相当不错（结果如下）。这样可以吗？如果没有，我该如何解决？：
def build_cnn_model(input_shape):
model = models.Sequential()

# 添加卷积层和最大池化层
model.add(layers.Conv2D(32, (3, 3),activation=&#39;relu&#39;, input_shape=input_shape))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.25)) 

model.add(layers.Conv2D(64, (3, 3),activation=&#39;relu&#39;, input_shape=input_shape, 
kernel_regularizer=regularizers.l2(0.001)))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.25)) 

model.add(layers.Conv2D(128, (3, 3),activation=&#39;relu&#39;))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Dropout(0.25)) 

# 向量
model.add(layers.Flatten())

# 添加全连接层
model.add(layers.Dense(128,activation=&#39;relu&#39;))
model.add(layers.Dropout(0.5)) # Dropout 以减少过拟合
model.add(layers.Dense(1,activation=&#39;sigmoid&#39;)) # 

返回模型

# 输入形状
input_shape = (128, 128, 3)

# 构建模型
cnn_model = build_cnn_model(input_shape)
adam = Adam(learning_rate=0.001)

cnn_model.compile(optimizer=adam,
loss=&#39;binary_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

我得到了这个准确率：
准确率图
F1 分数：
分类报告：
| 类别 | 精度 | 召回率 | F1 分数 | 支持率 |
|----------------|-----------|--------|-----------|---------|
| 非暴力 | 0.97 | 0.97 | 0.97 | 1186 |
| 暴力 | 0.96 | 0.96 | 0.96 | 953 |
| | | | | | |
| 准确度 | | | 0.97 | 2139 |
| 宏平均值 | 0.97 | 0.97 | 0.97 | 2139 |
| 加权平均值 | 0.97 | 0.97 | 0.97 | 2139 |

我尝试过增强数据。
我只是想知道我的模型是否正常。]]></description>
      <guid>https://stackoverflow.com/questions/79141961/validation-accuracy-better-than-train-accuracy-problem</guid>
      <pubDate>Wed, 30 Oct 2024 16:22:39 GMT</pubDate>
    </item>
    <item>
      <title>训练 IP-Adapter plus 模型后的推理错误</title>
      <link>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</link>
      <description><![CDATA[我从 https://github.com/tencent-ailab/IP-Adapter 下载了软件包
运行命令来训练 IP-Adapter plus 模型（输入：文本 + 图像，输出：图像）：
accelerate launch --num_processes 2 --multi_gpu --mixed_precision &quot;fp16&quot; \
tutorial_train_plus.py \
--pretrained_model_name_or_path=&quot;stable-diffusion-v1-5/&quot; \
--image_encoder_path=&quot;models/image_encoder/&quot; \
--data_json_file=&quot;assets/prompt_image.json&quot; \
--data_root_path=&quot;assets/train/&quot; \
--mixed_precision=&quot;fp16&quot; \
--resolution=512 \
--train_batch_size=2 \
--dataloader_num_workers=4 \
--learning_rate=1e-04 \
--weight_decay=0.01 \
--output_dir=&quot;out_model/&quot; \
--save_steps=3

训练过程中，出现提示，但训练可以继续：
已删除共享张量 {&#39;adapter_modules.27.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_v_ip.weight&#39;, &#39;adapter_modules.31.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_k_ip.weight&#39;, &#39;adapter_modules.31.to_v_ip.weight&#39;, &#39;adapter_modules.11.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_k_ip.weight&#39;, &#39;adapter_modules.25.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_k_ip.weight&#39;, &#39;adapter_modules.17.to_k_ip.weight&#39;, &#39;adapter_modules.19.to_v_ip.weight&#39;, &#39;adapter_modules.13.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_v_ip.weight&#39;, &#39;adapter_modules.7.to_k_ip.weight&#39;, &#39;adapter_modules.29.to_k_ip.weight&#39;, &#39;adapter_modules.3.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_v_ip.weight&#39;, &#39;adapter_modules.21.to_v_ip.weight&#39;, &#39;adapter_modules.5.to_k_ip.weight&#39;, &#39;adapter_modules.23.to_v_ip.weight&#39;, &#39;adapter_modules.25.to_k_ip.weight&#39;, &#39;adapter_modules.1.to_k_ip.weight&#39;, &#39;adapter_modules.9.to_v_ip.weight&#39;, &#39;adapter_modules.9.to_k_ip.weight&#39;, &#39;adapter_modules.15.to_v_ip.weight&#39;, &#39;adapter_modules.27.to_v_ip.weight&#39;, &#39;adapter_modules.29.to_v_ip.weight&#39;, &#39;adapter_modules.19.to_k_ip.weight&#39;, &#39;adapter_modules.11.to_v_ip.weight&#39;}。这应该没问题，但请检查重新加载时是否收到任何警告

训练完成后，转换权重以生成 ip_adapter.bin，然后使用此文件中的以下模型路径运行推理代码 ip_adapter-plus_demo.py：
base_model_path = &quot;SG161222/Realistic_Vision_V4.0_noVAE&quot;
vae_model_path = &quot;stabilityai/sd-vae-ft-mse&quot;
image_encoder_path = &quot;models/image_encoder&quot;
ip_ckpt = &quot;out_model/demo_plus_checkpoint/ip_adapter.bin&quot;

显示错误：
raise RuntimeError(&#39;Error(s) in loading state_dict for {}:\n\t{}&#39;.format(
RuntimeError: Error(s) in loading state_dict for ModuleList:
state_dict 中缺少键：&quot;1.to_k_ip.weight&quot;, &quot;1.to_v_ip.weight&quot;, &quot;3.to_k_ip.weight&quot;, &quot;3.to_v_ip.weight&quot;, &quot;5.to_k_ip.weight&quot;, &quot;5.to_v_ip.weight&quot;, &quot;7.to_k_ip.weight&quot;, &quot;7.to_v_ip.weight&quot;, &quot;9.to_k_ip.weight&quot;, &quot;9.to_v_ip.weight&quot;, “11.to_k_ip.weight”, “11.to_v_ip.weight”, “13.to_k_ip.weight”, “13.to_v_ip.weight”, “15.to_k_ip.weight”, “15.to_v_ip.weight”, “17.to_k_ip.weight”, “17.to_v_ip.weight”, “19.to_k_ip.weight”, “19.to_v_ip.weight”, “21.to_k_ip.weight”, “21.to_v_ip.weight”, “23.to_k_ip.weight”, “23.to_v_ip.weight”, &quot;25.to_k_ip.weight&quot;, &quot;25.to_v_ip.weight&quot;, &quot;27.to_k_ip.weight&quot;, &quot;27.to_v_ip.weight&quot;, &quot;29.to_k_ip.weight&quot;, &quot;29.to_v_ip.weight&quot;, &quot;31.to_k_ip.weight&quot;, &quot;31.to_v_ip.weight&quot;.

什么步骤出错导致此错误？]]></description>
      <guid>https://stackoverflow.com/questions/79140091/inference-error-after-training-an-ip-adapter-plus-model</guid>
      <pubDate>Wed, 30 Oct 2024 07:32:22 GMT</pubDate>
    </item>
    <item>
      <title>如何计算零膨胀泊松回归和零膨胀负二项回归的平均绝对误差（MAE）？</title>
      <link>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</link>
      <description><![CDATA[我尝试使用 Python 在进行零膨胀泊松回归和零膨胀负二项回归时计算平均绝对误差 (MAE)。
我将数据分为训练数据和测试数据。我使用下面的代码，但它不起作用：
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
import statsmodels.formula.api as smf
import tensorflow as tf
df = pd.read_excel(&#39;....&#39;, sheet_name=&#39;Sheet1&#39;)
print(df.head())
X = df[[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;]]
y = df[&#39;g&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from statsmodels.discrete.count_model import ZeroInflatedPoisson
y_zip = y_train.values

y_zip_test = y_test.values

X_count = X_train.values # 计数部分的预测器
X_zero = X_train.values # 零膨胀部分的预测器

X_count_test = X_test.values
X_zero_test = X_test.values

# 为截距添加一个常数
X_count = sm.add_constant(X_count)
X_zero = sm.add_constant(X_zero)

# 拟合 ZIP 模型
zip_model = ZeroInflatedPoisson(endog=y_zip, exog=X_count, exog_infl=X_zero, indication=&#39;logit&#39;)
zip_model_fit = zip_model.fit()
print(zip_model_fit.summary())

# 进行预测
y_pred = zip_model_fit.predict(X_count_test)

# 计算 MAE
mae = np.mean(np.abs(y_zip_test - y_pred))
print(f&#39;平均绝对误差：{mae}&#39;)

结果如下
-------------------------------------------------------------------------------
ValueError Traceback (most recent call last)
Cell In[3], line 33
29 print(zip_model_fit.summary())
32 # 进行预测
---&gt; 33 y_pred = zip_model_fit.predict(X_count_test)
35 # 计算 MAE 测试
36 mae = np.mean(np.abs(y_zip_test - y_pred))

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\base\model.py:1174，位于 Results.predict(self, exog, transform, *args, **kwargs)
1127 &quot;&quot;&quot;
1128 调用 self.model.predict 并以 self.params 作为第一个参数。
1129 
(...)
1169 返回预测。
1170 &quot;&quot;&quot;
1171 exog, exog_index = self._transform_predict_exog(exog,
1172 transform=transform)
-&gt; 1174 predict_results = self.model.predict(self.params, exog, *args,
1175 **kwargs)
1177 如果 exog_index 不为 None 且不 hasattr(predict_results,
1178 &#39;predicted_values&#39;):
1179 如果 predict_results.ndim == 1:

文件 ~\anaconda3\envs\tf\lib\site-packages\statsmodels\discrete\count_model.py:453，位于 GenericZeroInflated.predict(self, params, exog, exog_infl, Exposure, Offset, which, y_values)
449 params_main = params[self.k_inflate:]
451 prob_main = 1 - self.model_infl.predict(params_infl, exog_infl)
--&gt; 453 lin_pred = np.dot(exog, params_main[:self.exog.shape[1]]) + Exposure + Offset
455 # 重构：这很不靠谱，
456 # model_main 中应该有一个合适的预测方法
457 # 这只是 prob(y=0 | model_main)
458 tmp_exog = self.model_main.exog

ValueError：形状 (21,6) 和 (7,) 未对齐：6 (1 维) != 7 (0 维)

可以使用数据框解决错误。
y_train, X_train = dmatrices(expr, recreated_train_data, return_type=&#39;dataframe&#39;)
但是，我遇到了模型无法收敛的问题，信息如下：
C:\Users\Admin\anaconda3\envs\tf\lib\site-packages\scipy\optimize\_optimize.py:1291: OptimizeWarning: 已超出最大迭代次数。
res = _minimize_bfgs(f, x0, args, fprime, callback=callback, **opts)
C:\Users\Admin\anaconda3\envs\tf\lib\site-packages\statsmodels\base\model.py:607: ConvergenceWarning: 最大似然优化无法收敛。检查 mle_retvals
warnings.warn(&quot;最大似然优化失败&quot;

如何解决此错误？]]></description>
      <guid>https://stackoverflow.com/questions/79139968/how-can-we-calculate-mean-absolute-error-mae-for-zero-inflated-poisson-regress</guid>
      <pubDate>Wed, 30 Oct 2024 07:04:19 GMT</pubDate>
    </item>
    <item>
      <title>Kong AI 代理插件：在 Kong AI 网关上配置自托管 LLM 的正确参数</title>
      <link>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79139619/kong-ai-proxy-plugin-correct-parameters-for-configuring-a-self-hosted-llm-on-ko</guid>
      <pubDate>Wed, 30 Oct 2024 03:54:46 GMT</pubDate>
    </item>
    <item>
      <title>在这个简单的数据集中，模型性能滞后不到 50%</title>
      <link>https://stackoverflow.com/questions/78812358/model-performance-lagging-under-50-in-this-simple-dataset</link>
      <description><![CDATA[我正在按照此教程学习 keras
手动生成的数据集：

在临床试验中，对 13 至 100 岁的个体进行了实验性药物测试
该试验有 2100 名参与者。其中一半年龄在 65 岁以下 &amp;其余患者年龄在 65 岁或以上。
约 95% 的 65 岁或以上患者出现副作用。
约 95% 的 65 岁以下患者没有出现副作用。

for i in range (50):
# 约 5% 的年轻患者出现副作用
random_younger = randint(13,64)
train_samples.append(random_younger)
train_labels.append(1)

# 约 5% 的老年患者没有出现副作用
random_older = randint(65,100)
train_samples.append(random_older)
train_labels.append(0)

for i in range(1000):
# 约 95% 的年轻患者没有出现副作用
random_younger = randint(13,64)
train_samples.append(random_younger)
train_labels.append(0)

# 约 95% 的老年患者确实经历了副作用
random_older = randint(65,100)
train_samples.append(random_older)
train_labels.append(1)

然后使用 MinMaxScaler 缩放样本
然后使用一个简单的顺序模型：
model = Sequential([
Dense(units=16, input_shape=(1,),activation=&#39;relu&#39;),
Dense(units=32,activation=&#39;relu&#39;),
Dense(units=2,activation=&#39;softmax&#39;)
])

model.compile( 
optimizer=Adam(learning_rate=0.005), 
loss=&#39;sparse_categorical_crossentropy&#39;, 
metrics=[&#39;accuracy&#39;]
)

model.fit(
x=scaled_train_samples,
y=train_labels,
batch_size=10,
epochs=30, 
shuffle=True, 
verbose=2
)

但是，准确率徘徊在 50% 左右，损失在 70% 左右。我尝试在我的 PC 和Google colab。
Epoch 1/30
210/210 - 2s - 损失：0.7457 - 准确度：0.5029 - 2s/epoch - 7ms/step
Epoch 2/30
210/210 - 0s - 损失：0.7254 - 准确度：0.4957 - 413ms/epoch - 2ms/step
Epoch 3/30
210/210 - 0s - 损失：0.7142 - 准确度：0.5048 - 353ms/epoch - 2ms/step
Epoch 4/30
210/210 - 0s - 损失：0.6964 - 准确度：0.4914 - 386ms/epoch - 2ms/step
Epoch 5/30
210/210 - 0s - 损失：0.6971 - 准确度：0.5090 - 371ms/epoch - 2ms/step
Epoch 6/30
210/210 - 0s - 损失：0.6969 - 准确度：0.4938 - 351ms/epoch - 2ms/step
Epoch 7/30
210/210 - 0s - 损失：0.6958 - 准确度：0.4929 - 385ms/epoch - 2ms/step
...
...
Epoch 24/30
210/210 - 0s - 损失：0.6936 - 准确度：0.5000 - 367ms/epoch - 2ms/step
Epoch 25/30
210/210 - 0s - 损失：0.6935 - 准确度： 0.5010 - 367ms/epoch - 2ms/step
Epoch 26/30
210/210 - 0s - 损失：0.6940 - 准确度：0.4962 - 354ms/epoch - 2ms/step
Epoch 27/30
210/210 - 0s - 损失：0.6936 - 准确度：0.4819 - 472ms/epoch - 2ms/step
Epoch 28/30
210/210 - 0s - 损失：0.6937 - 准确度：0.4943 - 388ms/epoch - 2ms/step
Epoch 29/30
210/210 - 0s - 损失：0.6938 - 准确度：0.4905 - 406ms/epoch - 2ms/step
Epoch 30/30
210/210 - 0s - 损失：0.6935 - 准确率：0.4990 - 389ms/epoch - 2ms/step

我只是按照教程操作，但不明白我哪里犯了错误。
在手动生成的简单数据集上建立一个简单的顺序模型。
准确率预计会提高，但会滞后约 50%。]]></description>
      <guid>https://stackoverflow.com/questions/78812358/model-performance-lagging-under-50-in-this-simple-dataset</guid>
      <pubDate>Tue, 30 Jul 2024 14:37:43 GMT</pubDate>
    </item>
    <item>
      <title>如何将 FITS 文件转换为 Numpy 数组</title>
      <link>https://stackoverflow.com/questions/70578067/how-to-convert-a-fits-file-to-a-numpy-array</link>
      <description><![CDATA[我正在尝试训练一个 AI 算法来确定星系的光度红移，为此我有一个包含训练数据的 FITS 文件。我需要将此 FITS 文件转换为可在 Python 中轻松操作的格式，特别是 numpy 数组。我已经尝试使用 astropy 并按照以下 youtube 视频操作：
https://www.youtube.com/watch?v=goH9yXu4jWw
但是，当我尝试转换文件然后检查数据类型时，它仍然是一个 FITS 文件而不是 numpy 数组。如果有人能帮忙，我将不胜感激！
import astropy.io
from astropy.io import fits

truth_north = fits.open(&#39;dr9_pz_truth_north.fits&#39;)

data = truth_north[1].data 


当我打印数据类型时，它会给出 astropy.io.fits.fitsrec.FITS_rec
我被告知 FITS_rec 类的行为就像一个 numpy 数组，但是我必须将文件转换为一个 numpy 数组。
注意：我已经在 Physics Stack Exchange 上发布了这个问题，但是我的问题并没有得到真正的回答。
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/70578067/how-to-convert-a-fits-file-to-a-numpy-array</guid>
      <pubDate>Tue, 04 Jan 2022 11:26:32 GMT</pubDate>
    </item>
    <item>
      <title>孤立森林需要数据规范化吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/60877853/data-normalization-needed-for-isolation-forest</link>
      <description><![CDATA[我希望使用孤立森林对某些系统时间序列数据进行异常值检测。在我的案例中，特征的尺度变化很大。我的直觉告诉我应该对数据进行规范化，但我不记得原始 Iso Forest 论文中有此要求。任何指导都值得感激。]]></description>
      <guid>https://stackoverflow.com/questions/60877853/data-normalization-needed-for-isolation-forest</guid>
      <pubDate>Thu, 26 Mar 2020 23:39:45 GMT</pubDate>
    </item>
    <item>
      <title>Sigmoid 输出——可以解释为概率吗？</title>
      <link>https://stackoverflow.com/questions/59058867/sigmoid-output-can-it-be-interpreted-as-probability</link>
      <description><![CDATA[Sigmoid 函数输出一个介于 0 和 1 之间的数字。这是一个概率，还是仅仅是一个“是或否”，取决于它是高于还是低于 0.5？
最小示例：
猫与狗的二元分类。0 是猫，1 是狗。 
我可以对 S 型输出值进行以下解释吗：

0.9 - 它肯定是一只狗
0.52 - 它更可能是一只狗而不是一只猫，但仍然不确定
0.5 - 完全不确定，可能是一只猫或一只狗
0.48 - 它更可能是一只猫而不是一只狗，但仍然不确定
0.1 - 它肯定是一只猫

或者这是解释结果的正确方法：

0.9 - 它是一只狗
0.52 - 它是一只狗
0.5 - 完全不确定，可能是一只猫或一只狗
0.48 - 这是一只猫
0.1 - 这是一只猫

请注意，在第一种情况下，我们利用数值来表达概率，而在第二种情况下，我们完全忽略概率解释，将答案折叠为二进制。哪一个是正确的？你能解释一下为什么吗？

背景情况，请随意跳过：
我发现了许多来源，这些来源表明，是的，S 型函数输出可以解释为概率：

来源是 1 - (...) sigmoid(z) 将产生一个介于 0 和 1 之间的值（概率）。
来源是 2 - “输出”必须来自满足分布函数属性的函数，我们才能将其解释为概率。 (...) “S 型函数”满足这些属性。
来源 3 - tf.sigmoid(logits) 为您提供概率。

并且有许多来源表明相反，S 型输出不能解释为概率：

来源 1 - (...) 原始值不一定能解释为原始概率！
来源 2 - S 型(...) 不是概率分布函数
来源否（也是是）3 - 简短的回答是否定的，但是，根据您使用的损失，它可能比您想象的更接近事实。

（奖励问题，回答赢得汽车！）为什么有这么多相互矛盾的答案？这些答案有什么不同？我觉得不太可能只是很多人完全错了 - 我想他们只是在谈论不同的案例或一些不同的基本假设。我遗漏了什么区别？

我知道我可以使用 softmax。我还知道 sigmoid 可用于非排他性多类分类（来源多 1、来源多 2、来源多 3） - 尽管即便如此，仍不清楚这种多重 sigmoid 是否输出各种类别的概率，或者仅仅是“是或否”，但对于多个类别。但就我而言，我对专有的二分类（二进制）感兴趣，以及是否可以使用 S 型函数来确定其概率，或者是否应该使用二分类 Softmax。]]></description>
      <guid>https://stackoverflow.com/questions/59058867/sigmoid-output-can-it-be-interpreted-as-probability</guid>
      <pubDate>Tue, 26 Nov 2019 20:27:23 GMT</pubDate>
    </item>
    <item>
      <title>关于使用 R 进行 KNN 的 k 倍交叉验证的问题</title>
      <link>https://stackoverflow.com/questions/55328424/question-regarding-k-fold-cross-validation-for-knn-using-r</link>
      <description><![CDATA[我正在尝试对几个 k 值进行 5 倍交叉验证。我使用了 ISLR 包中的 OJ 数据集。
到目前为止我的代码如下，
library(ISLR)
library(class)
ks=c(1:5)
err.rate.test &lt;- numeric(length = 5)
folds &lt;- cut(seq(1,nrow(OJ)),breaks=5,labels=FALSE)

for (j in seq(along = ks)) {
set.seed(123)
cv.knn &lt;- sapply(1:5, FUN = function(i) {
testID &lt;- which(folds == i, arr.ind = TRUE)
test.X &lt;- OJ[testID, 3]
test.Y &lt;- OJ[testID, 1]
train.X &lt;- OJ[-testID, 3]
train.Y &lt;- OJ[-testID, 1]
knn.test &lt;- knn(data.frame(train.X), data.frame(test.X), train.Y, k = ks[j])
cv.test.est &lt;- mean(knn.test != test.Y)
return(cv.test.est)
})
err.rate.test[j] &lt;- mean(cv.knn)

}

err.rate.test
[1] 0.3757009 0.3757009 0.3757009 0.3757009 0.3757009

代码没有给出任何错误。但出于某种原因，我对每个 k 值的测试错误率都相同。这对我来说似乎很奇怪。所以我认为我的代码有问题。
有人能帮我解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/55328424/question-regarding-k-fold-cross-validation-for-knn-using-r</guid>
      <pubDate>Sun, 24 Mar 2019 20:48:12 GMT</pubDate>
    </item>
    <item>
      <title>如何为 k-NN 找到最佳的 k 值？</title>
      <link>https://stackoverflow.com/questions/46599534/how-to-find-the-best-value-of-k-for-the-k-nn</link>
      <description><![CDATA[我有 4 个不同的数据集，每个数据集包含属于以下两个类别之一的二维样本：1 或 2。每个样本的类别标签（1 或 2）位于最后一列。第一列和第二列包含代表样本的二维点的坐标。我的任务是：
对于 k-NN，找到 k 的最佳值，并使用 scikit-learn 将其与 1-NN 的值进行比较。
我是机器学习和 Python 的新手。请告诉我如何找到最佳 k，以及我们必须根据哪种度量来选择最佳 k。]]></description>
      <guid>https://stackoverflow.com/questions/46599534/how-to-find-the-best-value-of-k-for-the-k-nn</guid>
      <pubDate>Fri, 06 Oct 2017 06:26:22 GMT</pubDate>
    </item>
    <item>
      <title>Matlab 交叉验证和 K-NN</title>
      <link>https://stackoverflow.com/questions/35560228/matlab-cross-validation-and-k-nn</link>
      <description><![CDATA[我正在尝试在 Matlab 中构建一个带有交叉验证的 knn 分类器。由于我的 MATLAB 版本，我使用了 knnclassify() 来构建分类器 (classKNN = knnclassify (sample_test, sample_training, training_label))。
我无法使用 crossval()。]]></description>
      <guid>https://stackoverflow.com/questions/35560228/matlab-cross-validation-and-k-nn</guid>
      <pubDate>Mon, 22 Feb 2016 17:38:11 GMT</pubDate>
    </item>
    <item>
      <title>使用交叉验证的 KNN 分类器</title>
      <link>https://stackoverflow.com/questions/23174032/knn-classifier-using-cross-validation</link>
      <description><![CDATA[我正在尝试使用交叉验证方法实现 KNN 分类器，其中我有某个角色的不同图像用于训练（例如 5 张图像），另外两张用于测试。现在我明白了交叉验证的原理，只需在训练时选择误差值最小的 K，然后将其与测试数据一起使用，以查看结果的准确性。
如何在 matlab 中训练图像以获取 K 值？我是否应该比较它们并尝试找出不匹配项？！]]></description>
      <guid>https://stackoverflow.com/questions/23174032/knn-classifier-using-cross-validation</guid>
      <pubDate>Sat, 19 Apr 2014 18:46:58 GMT</pubDate>
    </item>
    <item>
      <title>k近邻算法中k的值</title>
      <link>https://stackoverflow.com/questions/11568897/value-of-k-in-k-nearest-neighbor-algorithm</link>
      <description><![CDATA[我有 7 个需要分类的类别，并且有 10 个特征。在这种情况下，我需要使用 k 的最优值吗？或者我必须对 1 到 10 之间的 k 值（大约 10）运行 KNN，然后借助算法本身确定最佳值？]]></description>
      <guid>https://stackoverflow.com/questions/11568897/value-of-k-in-k-nearest-neighbor-algorithm</guid>
      <pubDate>Thu, 19 Jul 2012 20:36:46 GMT</pubDate>
    </item>
    </channel>
</rss>