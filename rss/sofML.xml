<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 24 Mar 2024 18:18:21 GMT</lastBuildDate>
    <item>
      <title>Nevopy 用于两名或以上玩家的游戏</title>
      <link>https://stackoverflow.com/questions/78215459/nevopy-for-games-with-two-or-more-players</link>
      <description><![CDATA[我尝试过 nevopy 为四子棋制作一个好的 KI。在fitness_fuction中，我想让一个模型与随机选择的人口对手进行比赛，但我无法使用人口变量，尽管它是全局的。当一个模型的适应度依赖于其他模型时，是否有一种方法可以使用总体适应度函数？ nevopy 还应该如何用于多人游戏？
我想使用nevopy，因为它很简单，而且不像neat-python那么难理解。
我预计我可以在适应度函数中使用人口变量，但这不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78215459/nevopy-for-games-with-two-or-more-players</guid>
      <pubDate>Sun, 24 Mar 2024 17:24:29 GMT</pubDate>
    </item>
    <item>
      <title>使用量子电路实现强化学习模型的错误</title>
      <link>https://stackoverflow.com/questions/78215361/error-in-implementing-reinforcement-learning-model-using-quantum-circuit</link>
      <description><![CDATA[我已经完成了大部分部分，请参阅下面的代码
导入tensorflow为tf
从张量流导入keras
从tensorflow.keras导入层
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

类 HadamardLayer(layers.Layer):
  def __init__(self, **kwargs):
    super().__init__(**kwargs)

  def 构建（自身，input_shape）：
    super().build(input_shape)

  def 调用（自身，输入）：
    hadamard_gate = tf.constant([[1/np.sqrt(2), 1/np.sqrt(2)],
                                 [1/np.sqrt(2), -1/np.sqrt(2)]])
    返回 tf.linalg.matmul(hadamard_gate, 输入)

类 QuantumExplorationCircuit(keras.Model):
  def __init__(自身):
    超级().__init__()
    self.qubits = Layers.Input(shape=(1,)) # 假设 1 个量子位用于探索
    self.h = HadamardLayer() # 使用自定义 Hadamard 层

  def 调用（自身，输入）：
    super().call(输入)
    探索_prob = self.h（输入）
    返回探索概率

def run_episode_tensorflow（sess，env，action_prob，探索电路）：
  obs = env.reset()
  完成=假

  状态列表 = []
  动作列表 = []
  r_列表 = []
  虽然没有完成：
    cur_action_prob = sess.run(action_prob, feed_dict={observation_placeholder: obs.reshape(1, 4)})


#error 在这里 TypeError: Can not conversion a NoneType into a Tensor or Operations。
    Exploration_probs = sess.run(exploration_ Circuit, feed_dict={exploration_placeholder: np.zeros((1, 1))})

    组合概率 = (1 - epsilon) * cur_action_prob[0] + epsilon *探索_probs[0]
    动作 = np.random.choice([0, 1], p=combined_prob)

    state_list.append(obs)
    action_list.append(动作)
    obs, r, 完成, info = env.step(action)
    r_list.append(r)
  返回状态列表、动作列表、r_列表

epsilon = tf.constant(0.05, dtype=tf.float32)
Observation_placeholder = tf.compat.v1.placeholder(dtype=tf.float32, shape=(无, 4))
action_placeholder = tf.compat.v1.placeholder(dtype=tf.int32, shape=())
v = tf.compat.v1.placeholder(dtype=tf.float32, shape=())

model_params = tf.Variable(tf.compat.v1.random_uniform(shape=(4, 2), minval=0, maxval=1.0, dtype=tf.float32))
preds = tf.matmul(observation_placeholder, model_params)
action_prob = tf.nn.softmax(preds)

explore_placeholder = tf.compat.v1.placeholder(dtype=tf.float32, shape=(无, 1))
探索电路=量子探索电路（）

action_grad = tf.gradients(tf.compat.v1.log(action_prob[:, action_placeholder]), model_params)
update_step = model_params.assign(model_params + epsilon * tf.squeeze(action_grad) * v)

尝试列表 = []

对于范围内的剧集（100）：
  尝试次数 = 0
  当前_r = 0

  将 tf.compat.v1.Session() 用作 sess：
    sess.run(tf.compat.v1.global_variables_initializer())

    而 cur_r &lt; 200：
      state_list、action_list、r_list = run_episode_tensorflow(sess、env、action_prob、探索电路)
      cur_r = 总和(r_list)
      尝试次数 += 1
      对于 idx，枚举（zip（state_list，action_list））中的（状态，操作）：
        _ = sess.run(update_step, feed_dict={observation_placeholder: state.reshape(1, 4), action_placeholder: action, v:sum(r_list[idx:])})

    attempts_list.append(num_tries)

n，bins，补丁= plt.hist（tries_list，bins = max（tries_list），align =&#39;left&#39;）
plt.xlabel(&#39;解决环境之前的集数&#39;)
plt.ylabel(&#39;频率&#39;)
plt.title(&#39;蒙特卡罗策略梯度与量子探索的结果&#39;)
plt.网格（真）
plt.show()

错误是
类型错误：无法将 NoneType 转换为张量或操作。
文件的其余部分
这是我的 google colab 文件的可编辑链接，看看是否可以使其工作
https://colab.research.google.com/drive /1RYKXvMtDZqRD2T2b39N04VjNmolLC-QS#scrollTo=g1s1EnHJTLUy]]></description>
      <guid>https://stackoverflow.com/questions/78215361/error-in-implementing-reinforcement-learning-model-using-quantum-circuit</guid>
      <pubDate>Sun, 24 Mar 2024 16:59:17 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch EMNIST 数据集加载器返回文件未找到或损坏</title>
      <link>https://stackoverflow.com/questions/78215347/pytorch-emnist-dataset-loader-return-file-not-found-or-corrupted</link>
      <description><![CDATA[我正在处理 EMNIST 数据集，并希望从 PyTorch 加载它，但它返回一个奇怪的错误：
&lt;块引用&gt;
运行时错误：文件未找到或已损坏。

这是我尝试加载数据集的方法：
trainset = torchvision.datasets.EMNIST(root=“emnist”,
                                   split=“字母”，
                                   火车=真，
                                   下载=真，
                                   变换=transforms.ToTensor())

可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78215347/pytorch-emnist-dataset-loader-return-file-not-found-or-corrupted</guid>
      <pubDate>Sun, 24 Mar 2024 16:53:53 GMT</pubDate>
    </item>
    <item>
      <title>机器学习和创建简单的人工智能[关闭]</title>
      <link>https://stackoverflow.com/questions/78214831/machine-learning-and-creating-a-simple-ai</link>
      <description><![CDATA[我想创建一个可以和我一起玩简单游戏的人工智能。这个游戏有一些思维层次，所以我应该教人工智能如何在不同的独特情况下思考等。但我不知道从哪里开始。该游戏将在 iOS(swiftui) 上运行。我在考虑 createML，但我不想把精力花在错误的事情上，所以我需要你的帮助。基本上需要一个路线图。
我没有尝试太多。我知道 Apple 发布了 CoreML 和 CreateML，但不知道这些是否适合我。]]></description>
      <guid>https://stackoverflow.com/questions/78214831/machine-learning-and-creating-a-simple-ai</guid>
      <pubDate>Sun, 24 Mar 2024 14:12:48 GMT</pubDate>
    </item>
    <item>
      <title>用于多标签分类的堆叠集成学习</title>
      <link>https://stackoverflow.com/questions/78214688/stacking-ensamble-learning-for-multilabelclassification</link>
      <description><![CDATA[我有两个 BERT 模型来实现代码中漏洞检测的多标签分类。一名接受过源代码培训，另一名接受过编译代码培训。他们实现的任务是多标签分类，因此两个模型的单个输出都是一个包含 6 个元素的数组，每个元素可以是 0 或 1，指示漏洞是否存在。
我想在这两个模型之上构建一个经典的 ML 分类器（如 RandomForest、SVM 等），实现称为 Stacking 的集成技术。知道我正在处理多标签分类，我该如何实现这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78214688/stacking-ensamble-learning-for-multilabelclassification</guid>
      <pubDate>Sun, 24 Mar 2024 13:28:23 GMT</pubDate>
    </item>
    <item>
      <title>如果文件夹已存在 ChromaDB，则防止创建嵌入</title>
      <link>https://stackoverflow.com/questions/78214495/prevent-create-embeddings-if-folder-already-present-chromadb</link>
      <description><![CDATA[这是我第一次尝试RAG应用。我正在尝试使用法学硕士进行问答。我将在下面粘贴运行良好的代码。我的问题是每次运行 python 代码时都会运行生成嵌入的代码。有没有办法只运行一次或检查嵌入文件夹是否为空，然后运行该代码。
from langchain_community.document_loaders import WebBaseLoader
从 langchain_community.document_loaders 导入 TextLoader
从 langchain_community.vectorstores 导入 Chroma
从 langchain_community 导入嵌入
从 langchain_community.chat_models 导入 ChatOllama
从 langchain_core.runnables 导入 RunnablePassthrough
从 langchain_core.output_parsers 导入 StrOutputParser
从 langchain_core.prompts 导入 ChatPromptTemplate
从 langchain.output_parsers 导入 PydanticOutputParser
从 langchain.text_splitter 导入 CharacterTextSplitter
从 langchain_community.embeddings 导入 OllamaEmbeddings

model_local = ChatOllama(model=&quot;codellama:7b&quot;)

loader = TextLoader(“remedy.txt”)
raw_doc = loader.load()

# 将文本文件内容分割成块
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
splitted_docs = text_splitter.split_documents(raw_doc)

# 使用嵌入函数将它们存储在向量数据库中
ollamaEmbeddings = embeddings.ollama.OllamaEmbeddings(model=“nomic-embed-text”)


# 使用色度向量数据库来存储数据
矢量存储 = Chroma.from_documents(
    文档=splitted_docs，
    嵌入=ollamaEmbeddings，
    persist_directory=&quot;./vector/my_data&quot;,
）

# 这会将数据写入本地
检索器 = vectorstore.as_retriever()

# 4. RAG 之后
print(&quot;RAG 之后\n&quot;)
after_rag_template = “””
    仅根据以下上下文回答问题：
    {语境}
    问题{问题}？
”“”
after_rag_prompt = ChatPromptTemplate.from_template(after_rag_template)
after_rag_chain = (
    {“上下文”：检索器，“问题”：RunnablePassthrough()}
    | after_rag_prompt
    |模型本地
    | StrOutputParser()
）
print(after_rag_chain.invoke(“普通感冒的家庭疗法是什么？”))
]]></description>
      <guid>https://stackoverflow.com/questions/78214495/prevent-create-embeddings-if-folder-already-present-chromadb</guid>
      <pubDate>Sun, 24 Mar 2024 12:31:15 GMT</pubDate>
    </item>
    <item>
      <title>统一构建 APK [关闭]</title>
      <link>https://stackoverflow.com/questions/78212208/building-apk-in-unity</link>
      <description><![CDATA[我做了一个统一项目，它采用机器学习模型来预测图像的类别。它在统一中完美运行。但是当我构建 apk 文件并在我的手机中运行它时。没有什么是可见的。即预测是不可见的。为什么 ？我直接在unity中集成了keras模型，是不是因为我的手机没有安装python？
Android 手机上的结果Unity 上的结果
当我提取 apk 时，我没有在 apk 中看到我的模型或其他详细信息。怎么解决这个问题。如何在我的 apk 中添加 Unity 中使用的所有文件夹和文件]]></description>
      <guid>https://stackoverflow.com/questions/78212208/building-apk-in-unity</guid>
      <pubDate>Sat, 23 Mar 2024 19:38:12 GMT</pubDate>
    </item>
    <item>
      <title>无法从“jax”导入名称“linear_util”</title>
      <link>https://stackoverflow.com/questions/78210393/cannot-import-name-linear-util-from-jax</link>
      <description><![CDATA[我正在尝试重现S5模型的实验，https://github.com/lindermanlab/ S5，但是在解决环境的时候遇到了一些问题。当我运行 shell 脚本./run_lra_cifar.sh时，出现以下错误
回溯（最近一次调用最后一次）：
  文件“/Path/S5/run_train.py”，第3行，在&lt;module&gt;中。
    从 s5.train 导入火车
  文件“/Path/S5/s5/train.py”，第7行，在&lt;module&gt;中。
    从.train_helpers导入create_train_state，reduce_lr_on_plateau，\
  文件“/Path/train_helpers.py”，第 6 行，在  中。
    从 flax.training 导入 train_state
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/__init__.py”，第 19 行，在  中
    从 。导入核心
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/core/__init__.py”，第 15 行，在  中
    从 .axes_scan 导入广播
  文件“/Path/miniconda3/lib/python3.12/site-packages/flax/core/axes_scan.py”，第 22 行，在  中
    从 jax 导入 Linear_util 作为 lu
ImportError：无法从“jax”导入名称“linear_util”（/Path/miniconda3/lib/python3.12/site-packages/jax/__init__.py）

我在 RTX4090 上运行它，我的 CUDA 版本是 11.8。我的jax版本是0.4.25，jaxlib版本是0.4.25+cuda11.cudnn86
我首先尝试使用作者的安装依赖项
pip install -rrequirements_gpu.txt

但是，这似乎不适用于我的情况，因为我什至无法导入 jax。所以我根据 https://jax.readthedocs.io/en 上的说明安装了 jax /latest/installation.html
通过输入
pip install --upgrade pip
pip install --upgrade “jax[cuda11_pip]” -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

到目前为止我已经尝试过：

使用较旧的 GPU（3060 和 2070）
将 python 降级到 3.9

有谁知道可能出了什么问题吗？感谢任何帮助]]></description>
      <guid>https://stackoverflow.com/questions/78210393/cannot-import-name-linear-util-from-jax</guid>
      <pubDate>Sat, 23 Mar 2024 09:57:12 GMT</pubDate>
    </item>
    <item>
      <title>Python：运行保存的 SVM 模型时出错：ValueError：X 有 2943 个功能，但 SVC 期望 330320 个功能作为输入</title>
      <link>https://stackoverflow.com/questions/78207432/python-error-while-running-saved-svm-model-valueerror-x-has-2943-features-bu</link>
      <description><![CDATA[我使用 Sickit-learn 创建了一个 SVM 模型：
导入 pandas 作为 pd
df = pd.read_csv(r&quot;C:\Users\aaa\Documents\bbb\svm_.csv&quot;, 编码=&#39;latin1&#39;, sep=&#39;;&#39;)

从 imblearn.over_sampling 导入 RandomOverSampler
过采样器 = RandomOverSampler(sampling_strategy=&#39;auto&#39;, random_state=42)

X_resampled, y_resampled = oversampler.fit_resample(df.drop(columns=[&#39;alvo&#39;]), df[&#39;alvo&#39;])

df_resampled = pd.concat([X_resampled, pd.DataFrame({&#39;alvo&#39;: y_resampled})], axis=1)

打印（df_重采样）

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.svm 导入 SVC
从sklearn.metrics导入accuracy_score，classification_report
从 sklearn.preprocessing 导入 OneHotEncoder

X = df_resampled.drop(columns=[&#39;alvo&#39;])
y = df_resampled[&#39;alvo&#39;]

编码器 = OneHotEncoder()
X_encoded = 编码器.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=2)

svm_classifier = SVC(kernel=&#39;poly&#39;, random_state=42)

svm_classifier.fit(X_train, y_train)

y_pred = svm_classifier.predict(X_test)

准确度=准确度_得分(y_test, y_pred)
分类报告结果 = 分类报告(y_test, y_pred)

print(f&quot;准确度: {accuracy}&quot;)
print(&quot;分类报告：\n&quot;,classification_report_result)

进口泡菜

model_file_path = “C:\\Users\\aaa\\Documents\\bbb\\svm_modelo_sent_simnao2.pkl”

打开（model_file_path，&#39;wb&#39;）作为f：
    pickle.dump(svm_classifier, f)

print(&quot;模型保存成功！&quot;)


支持向量机的简单实现来预测分类变量是正确的，工作得很好。
但是，当加载模型并运行以下代码时：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 OneHotEncoder
导入作业库

model_file_path = &quot;C:\\Users\\AAA\\Documents\\BBB\\svm_modelo_sent_simnao.pkl&quot;
svm_classifier = joblib.load(model_file_path)

new_df = pd.read_csv(r&quot;C:\Users\AAA\Documents\BBB\svm_simnao_rodar.csv&quot;, 编码=&#39;latin1&#39;, sep=&#39;;&#39;)

X_new = new_df.drop(columns=[&#39;alvo&#39;, &#39;ID_ASSUNTO&#39;], axis=1) # 删除 &#39;alvo&#39; 和 &#39;ID_ASSUNTO&#39; 列

categorical_columns = [&#39;UF&#39;, &#39;TIPO_ACAO&#39;, &#39;AREA_JURIDICA&#39;, &#39;VARA_CAMARA&#39;, &#39;CLIENTE_NOME&#39;] # 分类列列表
编码器= OneHotEncoder（类别=&#39;自动&#39;，稀疏=假）
X_new_encoded = 编码器.fit_transform(X_new[categorical_columns])

X_new_processed = pd.concat([pd.DataFrame(X_new_encoded), X_new.drop(columns=categorical_columns)], axis=1)

y_pred_new = svm_classifier.predict(X_new_processed)

new_df[&#39;alvo&#39;] = y_pred_new

预测 = new_df[[&#39;ID_ASSUNTO&#39;, &#39;alvo&#39;]]

打印（预测）

什么会导致以下错误：
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-3-522717c33138&gt;在&lt;模块&gt;中
     22
     23 # 进行预测
---&gt; 24 y_pred_new = svm_classifier.predict(X_new_processed)
     25
     26 # 将预测（&#39;alvo&#39;）添加到新数据中

〜\ AppData \ Roaming \ Python \ Python39 \ site-packages \ sklearn \ svm \ _base.py 在预测（自我，X）
    第818章
    第819章：
--&gt;第820章
    第821章
    第822章

〜\ AppData \ Roaming \ Python \ Python39 \ site-packages \ sklearn \ svm \ _base.py 在预测（自我，X）
    第431章 预测值。
    第432章
--&gt;第433章
    第434章
    第435章 回归预测（X）

_validate_for_predict(self, X) 中的 ~\AppData\Roaming\Python\Python39\site-packages\sklearn\svm\_base.py
    611
...
--&gt;第389章
    [第 390 章]
    [391] f“期待{self.n_features_in_}特征作为输入。”

ValueError: X 有 2943 个特征，但 SVC 预计有 330320 个特征作为输入。

&lt;小时/&gt;
我在部署代码中用于预测 alvo 的数据与我训练模型的数据具有完全相同的结构，并且我在训练和部署代码中都使用 OneHotEncoding...所以我有点迷失在这个之中。
知道如何解决这个问题吗？
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78207432/python-error-while-running-saved-svm-model-valueerror-x-has-2943-features-bu</guid>
      <pubDate>Fri, 22 Mar 2024 15:57:18 GMT</pubDate>
    </item>
    <item>
      <title>libmagic 不可用，但有助于对类文件对象进行文件类型检测</title>
      <link>https://stackoverflow.com/questions/78186569/libmagic-is-unavailable-but-assists-in-filetype-detection-on-file-like-objects</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78186569/libmagic-is-unavailable-but-assists-in-filetype-detection-on-file-like-objects</guid>
      <pubDate>Tue, 19 Mar 2024 12:21:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 的 Google Colab Bert 实例化错误</title>
      <link>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</link>
      <description><![CDATA[我正在尝试在 Colab 上使用 Tensorflow 构建 Bert 模型。这段代码几周前就可以完美运行。现在，如果我尝试实例化模型，则会收到以下错误：
初始化 TF 2.0 模型 TFBertModel 时未使用 PyTorch 模型的某些权重：[&#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;, &#39;cls .predictions.transform.LayerNorm.weight&#39;、&#39;cls.predictions.bias&#39;、&#39;cls.seq_relationship.bias&#39;、&#39;cls.predictions.transform.dense.bias&#39;、&#39;cls.seq_relationship.weight&#39;]
- 如果您从在其他任务或其他架构上训练的 PyTorch 模型初始化 TFBertModel（例如，从 BertForPreTraining 模型初始化 TFBertForSequenceClassification 模型），这是预期的。
- 如果您从希望完全相同的 PyTorch 模型初始化 TFBertModel（例如，从 BertForSequenceClassification 模型初始化 TFBertForSequenceClassification 模型），则不会出现这种情况。
TFBertModel 的所有权重都是从 PyTorch 模型初始化的。
如果您的任务与检查点模型训练的任务类似，您就可以使用 TFBertModel 进行预测，而无需进一步训练。
-------------------------------------------------- ------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-14-b0e769ef7​​890&gt;在&lt;细胞系：7&gt;()
      5 SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
      6 SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
----&gt; 7 SC_pooler_output = SC_bert_model(SC_input_layer, Attention_mask=SC_mask_layer)[1] # 第二个输出，che è il pooler_output
      8
      9 # 辍学层的Aggiungi

36帧
/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py 在 type_spec_from_value(value) 中
   1002 3，“无法将 %r 转换为张量：%s” % (类型(值).__name__, e))
   1003
-&gt;第1004章
   第1005章 1005
   1006

TypeError：调用层“嵌入”时遇到异常（类型 TFBertEmbeddings）。

无法为名称构建 TypeSpec：“tf.debugging.assert_less_5/assert_less/Assert/Assert”
op：“断言”
输入：“tf.debugging.assert_less_5/assert_less/All”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_0”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_1”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_2”
输入：“占位符”
输入：“tf.debugging.assert_less_5/assert_less/Assert/Assert/data_4”
输入：“tf.debugging.assert_less_5/assert_less/y”
属性{
  键：“总结”
  价值 {
    我：3
  }
}
属性{
  键：“T”
  价值 {
    列表 {
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_STRING
      类型：DT_INT32
      类型：DT_STRING
      类型：DT_INT32
    }
  }
}
 不支持的类型。

调用层“embeddings”接收的参数（类型 TFBertEmbeddings）：
  • input_ids=
  •position_ids=无
  • token_type_ids=
  • input_embeds=无
  •过去的键值长度=0
  • 训练=False

模型的代码是：
SC_input_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“input_ids”)
SC_mask_layer = 输入(shape=(max_seq_length,), dtype=tf.int32, name=“attention_mask”)
SC_bert_model = TFBertModel.from_pretrained(“bert-base-uncased”)
SC_pooler_output = SC_bert_model（SC_input_layer，attention_mask = SC_mask_layer）[1]

# Dropout 层的Aggiungi
SC_dropout_layer = Dropout(dropout_rate)(SC_pooler_output)
SC_output_layer = 密集（6，激活=&#39;sigmoid&#39;）（SC_dropout_layer）
SC_model = 模型(输入=[SC_input_layer, SC_mask_layer], 输出=SC_output_layer)

我发现安装tensorflow 2.10.0可以工作，但是使用Google Colab时我的CUDA版本有问题，并且使用tensorflow 2.10它无法识别GPU。
该代码几周前就可以工作，有人有解决方案吗？
编辑：同样的错误出现在 Kaggle 上。]]></description>
      <guid>https://stackoverflow.com/questions/78176160/google-colab-bert-instantiation-error-using-tensorflow</guid>
      <pubDate>Sun, 17 Mar 2024 17:03:42 GMT</pubDate>
    </item>
    <item>
      <title>从二维输入预测多个输出的回归问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78170872/the-regression-problem-of-predicting-multiple-outputs-from-two-dimensional-input</link>
      <description><![CDATA[我有几个二维图表，每个图表都有七个独特的数字特征，可用于生成这些图表。我以大量 CSV 文件的形式获得了所有这些图表的 x 和 y 坐标及其数值特征。我想通过使用机器学习或深度学习模型来预测每个图的数值特征（通过使用图的图像或使用每个图的点的坐标）
例如，这是我的一张图表：

该图的独特数字特征是 [8.76e15, 8e-1, 5e-2, 5e-3, 5e-2, 9.65e-1, 2.1e-9] （我有该图所有点的坐标对 (x, y) 以两列 CSV 文件的形式存在，我也可以使用它们）。
到目前为止，我已经寻找了很多预训练的模型，并在 HuggingFace 等网站上搜索了此类模型，还在 GitHub 代码中搜索了很多。我还在 Papers with Code 网站上搜索了做过同样事情的文章，但不幸的是，我仍然没有找到任何东西！我曾多次尝试自己编写一个网络，但由于这样做的复杂性以及对于如何设置网络的超参数以达到预期结果的知识不够，我遇到了很多错误并且无法做到这一点！
例如，我编写了以下代码：
X = []
y = []
目录=“数据”；
对于 os.listdir（目录）中的 csv_file：
    data = pd.read_csv(f&quot;{目录}/{csv_file}&quot;)
    X.append(data.iloc[1:, :2].astype(float).values)
    y.append(data.iloc[0, 2:].astype(float).values)
X = np.array(X, dtype=np.float64) # X.shape: (50000, 253, 2)
y = np.array(y, dtype=np.float64) # y.shape: (50000, 7)

X_train = X[:40000,:,:]
X_val = X[40000:, :, :]
y_train = y[:40000,:]
y_val = y[40000:, :]

定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_val_scaled = 缩放器.fit_transform(X_val)

输入 = keras.layers.Input(shape=(X.shape[1], X.shape[2]))
lstm_out = keras.layers.LSTM(32)(输入)
输出 = keras.layers.Dense(7)(lstm_out)

模型= keras.Model（输入=输入，输出=输出）
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=“mse”)
模型.summary()

历史=模型.fit(
    x=X_train,
    y = y_train，
    纪元=10，
）

损失非常高，而且一点也不好。
我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/78170872/the-regression-problem-of-predicting-multiple-outputs-from-two-dimensional-input</guid>
      <pubDate>Sat, 16 Mar 2024 07:03:13 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.multiclass.OneVsRestClassifier 中的回调</title>
      <link>https://stackoverflow.com/questions/78119978/callbacks-in-sklearn-multiclass-onevsrestclassifier</link>
      <description><![CDATA[我想使用回调和 eval_set 等。
但我有一个问题：
from sklearn.multiclass import OneVsRestClassifier
导入lightgbm

&lt;前&gt;&lt;代码&gt;详细 = 100
参数 = {
    “目标”：“二元”，
    “n_估计器”：500，
    “详细”：0
}
适合参数= {
    “eval_set”：eval_数据集，
    “回调”：[CustomCallback（详细）]
}

clf = OneVsRestClassifier(lightgbm.LGBMClassifier(**params))
clf.fit(X_train, y_train, **fit_params)

我如何将 fit_params 交给我的估算器？我明白
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- --------------------------
---&gt; 13 clf.fit(X_train, y_train, **fit_params)

TypeError：OneVsRestClassifier.fit() 得到意外的关键字参数“eval_set”
]]></description>
      <guid>https://stackoverflow.com/questions/78119978/callbacks-in-sklearn-multiclass-onevsrestclassifier</guid>
      <pubDate>Thu, 07 Mar 2024 08:59:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tkinter 和 OpenCV 训练人脸识别模型的问题</title>
      <link>https://stackoverflow.com/questions/76396140/issue-with-training-a-face-recognition-model-using-tkinter-and-opencv</link>
      <description><![CDATA[描述：
我目前正在开发一个人脸识别项目，使用 Tkinter 作为 GUI，使用 OpenCV 在 Visual Studio 上进行图像处理。我的目标是使用图像数据集训练模型并显示一条弹出消息，指示训练完成。但是，我遇到了一个问题，当我单击“火车数据”按钮时没有任何反应。按钮。该窗口不会打开，也不会显示任何错误消息。
代码：
来自 tkinter 导入 *
从 tkinter 导入 ttk
从 PIL 导入图像、ImageTk
从 tkinter 导入消息框
导入 mysql.connector
导入CV2
导入操作系统
将 numpy 导入为 np

班次 火车：
    def __init__(自我，根)：
        self.root = 根
        self.root.geometry(“1530x790+0+0”)
        self.root.title(&quot;人脸识别系统&quot;)
        
        title_lbl= Label(self.root, text= &quot;列车数据集&quot;,font=(&quot;times new roman&quot;,35,&quot;粗体&quot;), bg=&quot;白色&quot;,fg=&quot;深绿色&quot;)
        title_lbl.place(x=0,y=0,宽度=1530,高度=45)
        
        img_top= Image.open(r&quot;C:\Users\The-Javeira\Desktop\test\images\b.jpg&quot;)
        img_top= img_top.resize((1530,325), Image.ANTIALIAS)
        self.photoimg_top= ImageTk.PhotoImage(img_top)
        
        f_lbl2= 标签(self.root,image=self.photoimg_top)
        f_lbl2.place(x=0,y=55,宽度=1530,高度=325)
        
         ＃按钮
        b1_1=Button(self.root ,text=“训练数据”,command=self.train_classifier,cursor=“hand2”,font=(“times new roman”,30,“bold”), bg=” ;红色”,fg=“白色”)
        b1_1.place(x=0,y=380,宽度=1530,高度=60)
        
        img_bottom= Image.open(r&quot;C:\Users\The-Javeira\Desktop\test\images\train2.JPEG&quot;)
        img_bottom= img_bottom.resize((1530,325), Image.ANTIALIAS)
        self.photoimg_bottom= ImageTk.PhotoImage(img_bottom)
        
        f_lbl2= 标签(self.root,image=self.photoimg_bottom)
        f_lbl2.place(x=0,y=440,宽度=1530,高度=325)
        
    def train_classifier(自身):
        data_dir=(“图像数据”)
        path=[os.path.join(data_dir,file) for file in os.listdir(data_dir)]
        
        面孔=[]
        id=[]
        
        对于路径中的图像：
            img=Image.open(image).convert(&#39;L&#39;) #灰度图像
            imageNp=np.array(img,&#39;uint8&#39;)
            id=int(os.path.split(image)[1].split(&#39;.&#39;)[1])
            
            faces.append(imageNp)
            ids.append(id)
            cv2.imshow(“训练数据”,imageNp)
            cv2.waitKey(1)==13
        
        ids=np.array(ids)
        
        #============训练分类器并保存===========
      
        clf=cv2.face.LBPHFaceRecognizer_create()
        clf.train(面孔,ids)
        clf.write(“Classifier.xml”)
        messagebox.showinfo(&quot;结果&quot;,&quot;训练数据集完成！！&quot;)
        cv2.destroyAllWindows()


如果 __name__ == “__main__”：
    根 = Tk()
    obj = 火车（根）
    root.mainloop()
        

        
        
        
            
            
        
             
     

预期行为：
当我点击“火车数据”时按钮，我希望打开一个窗口，显示训练进度并显示图像。
训练完成后，我预计会弹出一条消息“训练数据集已完成！”出现。
分类器应保存为“Classifier.xml”在指定目录中。
实际行为：
当我点击“火车数据”时按钮，什么也没有发生。该窗口不会打开，并且没有显示错误消息。
没有出现预期的指示训练完成的弹出消息。
没有“Classifier.xml”文件在指定目录下创建
其他信息
所有必需的依赖项均已安装。]]></description>
      <guid>https://stackoverflow.com/questions/76396140/issue-with-training-a-face-recognition-model-using-tkinter-and-opencv</guid>
      <pubDate>Sat, 03 Jun 2023 12:40:21 GMT</pubDate>
    </item>
    <item>
      <title>将自定义 ML 模型与 Service Now 预测智能结合使用</title>
      <link>https://stackoverflow.com/questions/75694868/using-custom-ml-model-with-service-now-predictive-intelligence</link>
      <description><![CDATA[我有一个自定义 ML 模型，希望将其与 ServiceNow 的预测智能集成。
我一直在阅读他们的文档，但只能找到一些 ML API 和类的用法，但没有看到是否有办法将其与自定义 ML 模型集成。
SNOW 提供了一个 ClassificationSolution 类来使用内置模型，但我无法继续了解如何在 Predictive Intelligence 中创建我们自己的自定义模型。
文档
ServiceNow 版本 - 圣地亚哥]]></description>
      <guid>https://stackoverflow.com/questions/75694868/using-custom-ml-model-with-service-now-predictive-intelligence</guid>
      <pubDate>Fri, 10 Mar 2023 10:20:26 GMT</pubDate>
    </item>
    </channel>
</rss>