<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 06 Jul 2024 09:16:58 GMT</lastBuildDate>
    <item>
      <title>此函数能找到 pytorch 张量中最后一个元素的内存地址吗？</title>
      <link>https://stackoverflow.com/questions/78713769/does-this-function-find-the-memory-address-of-the-last-element-in-a-pytorch-tens</link>
      <description><![CDATA[我想知道我编写的这个函数是否能找到 pytorch 张量中最后一个元素的内存地址。我运行它，它看起来不错，但有几次它返回了张量的“最后一个元素”，并且它显示它位于内存中比第一个元素更靠后的部分，我使用 .data_ptr() 函数获得第一个元素。张量是连续的，尺寸为 (3,1000,1000)。
我将张量作为参数，然后获取张量的最后一个索引，然后调用 data_ptr() 函数。以下是我的代码：
def get_last_mem(tensor):
last_element = tensor[-1,-1].data_ptr()
return last_element

这是我的输出
变换前的第一个元素内存地址：136496996679680，连续：True
变换前的最后一个元素内存地址：136497008675680]]></description>
      <guid>https://stackoverflow.com/questions/78713769/does-this-function-find-the-memory-address-of-the-last-element-in-a-pytorch-tens</guid>
      <pubDate>Sat, 06 Jul 2024 03:07:18 GMT</pubDate>
    </item>
    <item>
      <title>我加载一个 float32 Hugging Face 模型，将其转换为 float16，然后保存。我该如何将其加载为 float16？</title>
      <link>https://stackoverflow.com/questions/78713551/i-load-a-float32-hugging-face-model-cast-it-to-float16-and-save-it-how-can-i</link>
      <description><![CDATA[我加载一个 huggingface-transformers float32 模型，将其转换为 float16，然后保存。我如何将其加载为 float16？
示例：
# pip install tr​​ansformers
from transformers import AutoModelForTokenClassification, AutoTokenizer

# 加载模型
model_path = &#39;huawei-noah/TinyBERT_General_4L_312D&#39;
model = AutoModelForTokenClassification.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# 将模型转换为 FP16
model.half()

# 检查模型 dtype
def print_model_layer_dtype(model):
print(&#39;\nModel dtypes:&#39;)
for name, param in model.named_pa​​rameters():
print(f&quot;参数：{name}，数据类型：{param.dtype}&quot;)

print_model_layer_dtype(model)
save_directory = &#39;temp_model_SE&#39;
model.save_pretrained(save_directory)

model2 = AutoModelForTokenClassification.from_pretrained(save_directory, local_files_only=True)
print(&#39;\n\n##################&#39;)
print(model2)
print_model_layer_dtype(model2)

在此示例中，model2 加载为 float32 模型（如 print_model_layer_dtype(model2) 所示），即使 model2 已保存为 float16（如 config.json 中所示）。将其加载为 float16 的正确方法是什么？
在 Windows 10 上使用 transformers==4.36.2 和 Python 3.11.7 进行了测试。]]></description>
      <guid>https://stackoverflow.com/questions/78713551/i-load-a-float32-hugging-face-model-cast-it-to-float16-and-save-it-how-can-i</guid>
      <pubDate>Fri, 05 Jul 2024 23:58:06 GMT</pubDate>
    </item>
    <item>
      <title>AlexNet 的顶层和底层如何通信？</title>
      <link>https://stackoverflow.com/questions/78713337/how-do-the-top-and-bottom-layers-of-alexnet-communicate</link>
      <description><![CDATA[我正在尝试使用 PyTorch 重新实现 Krizhevsky et al. (2012)，并且我对 AlexNet 模型的第二和第三卷积层如何精确通信感到困惑（第五层到第六层以及第六层到第七层的输入也是如此，尽管我在这里的问题中省略了这一点）。
在下图中，有两个&quot;过滤器&quot;，它们将输出从上半部分传递到下一个上半部分，但也传递到下半部分。同样，下半部分也有两个&quot;过滤器&quot;将输出传递到下一个下半部分和上半部分。
我没有足够的声誉点来嵌入图像，所以这里是Krizhevsky et al. (2012) 的图 1 的部分屏幕截图。
第二层的输出如何传递到第三层？
我读了这篇论文，除非我错过了什么，否则作者似乎没有准确概述输出是如何从第二层传递到第三层的。我浏览了大量博客文章和 git 存储库，大多数描述都是高级的，大多数实现似乎没有将模型拆分到两个 GPU 之间。
我能找到的最相关的内容是来自 convnet2 readme 的以下句子：

这里，层 conv2a 和 conv2b 将 conv1a 和 conv1b 都作为输入。执行隐式复制操作，以便将 conv1a 的输出放入 conv2b 的输入中，以及将 conv1b 的输出放入 conv2a 的输入中。

我最好的猜测是第二层中的 out_channels 参数实际上应该是 64 而不是 128，然后顶层和底层的输出应该连接为 torch.cat([output_from_top_half, output_from_bottom_half], dim=1) 并传递给第三层的上半部分和下半部分。但我不确定我的理解是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/78713337/how-do-the-top-and-bottom-layers-of-alexnet-communicate</guid>
      <pubDate>Fri, 05 Jul 2024 21:44:17 GMT</pubDate>
    </item>
    <item>
      <title>XGBClassifier.fit() 得到了一个意外的关键字参数“early_stopping_rounds”</title>
      <link>https://stackoverflow.com/questions/78713048/xgbclassifier-fit-got-an-unexpected-keyword-argument-early-stopping-rounds</link>
      <description><![CDATA[我的代码如下：
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
import pandas as pd
RANDOM_STATE = 55 ## 您将把它传递给每个 sklearn 调用，以便我们确保可重复性
n = int(len(X_train)*0.8) ## 让我们使用 80% 进行训练，20% 进行评估
这将用独热编码的列替换列，并保持“列”参数之外的列不变。
df = pd.read_csv(&quot;doc/heart.csv&quot;)
cat_variables = [&#39;Sex&#39;,
&#39;ChestPainType&#39;,
&#39;RestingECG&#39;,
&#39;ExerciseAngina&#39;,
&#39;ST_Slope&#39;
]
df = pd.get_dummies(data = df,
prefix = cat_variables,
columns = cat_variables)
var = [x for x in df.columns if x not in &#39;HeartDisease&#39;] ## 删除我们的目标变量
X_train, X_test, y_train, y_test = train_test_split(df[var], df[&#39;HeartDisease&#39;], train_size = 0.8, random_state = RANDOM_STATE)
print(X_train.shape)
X_train_fit, X_train_eval, y_train_fit, y_train_eval = X_train[:n], X_train[n:], y_train[:n], y_train[n:]
import xgboost
print(xgboost.__version__) # 2.1.0
xgb_model = XGBClassifier(n_estimators = 500, learning_rate = 0.1,verbosity = 1, random_state = RANDOM_STATE)
xgb_model.fit(X_train_fit,y_train_fit, eval_set = [(X_train_eval,y_train_eval)],early_stopping_rounds = 10)

详细错误信息如下：
Traceback (most recent call last):
File &quot;C:\my_document\11_Python\exercise\main.py&quot;, line 153, in &lt;module&gt;
xgb_model.fit(X_train_fit,y_train_fit, eval_set = [(X_train_eval,y_train_eval)],early_stopping_rounds = 10)
文件 &quot;C:\Users\samc\AppData\Local\Programs\Python\Python312\Lib\site-packages\xgboost\core.py&quot;，第 726 行，在 inner_f
return func(**kwargs)
^^^^^^^^^^^^^^^
TypeError: XGBClassifier.fit() 获得意外的关键字参数“early_stopping_rounds”

我该如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78713048/xgbclassifier-fit-got-an-unexpected-keyword-argument-early-stopping-rounds</guid>
      <pubDate>Fri, 05 Jul 2024 19:33:28 GMT</pubDate>
    </item>
    <item>
      <title>需要提高我的卷积神经网络模型的准确性。我对数据或模型所做的任何更改都不会影响准确性 [关闭]</title>
      <link>https://stackoverflow.com/questions/78712868/need-to-increase-the-accuracy-of-my-convolution-neural-network-model-the-accura</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78712868/need-to-increase-the-accuracy-of-my-convolution-neural-network-model-the-accura</guid>
      <pubDate>Fri, 05 Jul 2024 18:23:27 GMT</pubDate>
    </item>
    <item>
      <title>关于 Hugging Face 的 Tokenizer</title>
      <link>https://stackoverflow.com/questions/78712655/regarding-tokenizer-of-hugging-face</link>
      <description><![CDATA[很难理解 tokenizer 的工作原理
from transformers import AutoModelForSequenceClassification,AutoTokenizer #hugging face libraries
tkz = AutoTokenizer.from_pretrained(model)

函数
def tkz_func(x): return tkz(x[&#39;input&#39;])

当我们将它应用于数据集时，它工作得很好，返回带有 input_ids、token_type_ids、attention_masks 的更新数据集
当我们将它应用于数据框 df.apply(tkz_func,axis=1) 时，它只返回所有行值的行名列表
[input_ids,token_type_ids,attention_masks]。
为什么？]]></description>
      <guid>https://stackoverflow.com/questions/78712655/regarding-tokenizer-of-hugging-face</guid>
      <pubDate>Fri, 05 Jul 2024 17:15:32 GMT</pubDate>
    </item>
    <item>
      <title>一旦使用测试集进行测试为什么不在训练加测试集上训练模型？</title>
      <link>https://stackoverflow.com/questions/78712450/once-using-the-test-set-for-testing-why-do-not-training-the-model-on-train-plus</link>
      <description><![CDATA[一旦我使用测试集来评估模型性能是否良好，为什么我不能从头开始在训练和测试集上重新训练模型？
以预测为例：我有一个长度为 L 的时间序列，我训练到 T（T &lt; L），然后从 T 到 L 进行测试。我获得了良好的表现，所以我知道模型很好。然后在推理时我必须预测 L+1 个元素，那么为什么我不能训练模型到 L，然后在 L+1 上进行推理？
我希望模型在更大的数据集（训练+测试）上训练后表现更好，那么我遗漏了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78712450/once-using-the-test-set-for-testing-why-do-not-training-the-model-on-train-plus</guid>
      <pubDate>Fri, 05 Jul 2024 16:18:01 GMT</pubDate>
    </item>
    <item>
      <title>寻找包含带有摘要分析注释的电子表格的数据集</title>
      <link>https://stackoverflow.com/questions/78712190/looking-for-dataset-containing-spreadsheets-with-summary-analytical-comments</link>
      <description><![CDATA[我正在开展一个机器学习项目，该项目需要一种独特类型的数据集。具体来说，我需要包含分析注释或描述的 CSV 或 XLSX 格式的电子表格。
我正在寻找这样的数据集：每个电子表格都有清晰的行和列标题，并在文件底部或注释部分包含注释，以像人类一样描述数据。这些注释应该解释数据、提供见解或描述数据所代表的内容，而不仅仅是元数据或文档。
例如，请参阅附件示例电子表格。此表显示了学生的每周时间表，下面有分析注释，根据下面注释中的数据描述了潜在问题和建议。
数据集可以来自任何领域，而不仅仅是学术领域。示例包括：

商业公司：公司的季度资产负债表，附有描述业绩和未来计划的评论。
政府报告：龙卷风发生统计数据，附有突出重要年份和因素的评论。
个人信息：财务数据，附有财富分配和促成因素的分析。

有谁知道这类电子表格的集合或我可以找到这类数据集的来源？或者，任何关于如何有效创建或注释这些数据集的建议都将不胜感激。
我也在考虑购买这类数据集。例如，Statista 提供带注释的数据，但我在付费之前不确定数据量。像这样的平台或其他可以让我与销售代表交谈的来源会很有帮助。
我正在考虑的另一种方法是下载长期上市公司的季度财务报告，并添加来自《华尔街日报》等稳定记者的评论。但是，找到预先存在的数据集会更有益。
我已经使用“带分析的电子表格”和“带注释的电子表格”等关键字在 Google 搜索、Statista、Kaggle、Google 数据集搜索和美国人口普查局等来源上搜索过，但仍然需要进一步的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78712190/looking-for-dataset-containing-spreadsheets-with-summary-analytical-comments</guid>
      <pubDate>Fri, 05 Jul 2024 15:16:23 GMT</pubDate>
    </item>
    <item>
      <title>对失败的测试进行分类，并提出解决方案 [关闭]</title>
      <link>https://stackoverflow.com/questions/78711965/classification-of-failed-tests-and-fix-them-with-solution-proposal</link>
      <description><![CDATA[我现在在一家运行测试台的组织工作，这些测试是用 C 和 C++ 开发的。
当执行结束时，我们通过了测试，并且测试失败了，每个失败的测试都会生成一个日志文件。
现在我们想使用 IA 对这些失败的测试进行分类（因为有些测试有相同的错误）。
我们想预测这些失败测试的解决方案。
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78711965/classification-of-failed-tests-and-fix-them-with-solution-proposal</guid>
      <pubDate>Fri, 05 Jul 2024 14:21:48 GMT</pubDate>
    </item>
    <item>
      <title>Darknet Yolov4-tiny（灰度输入）到 Tensorflow 权重，转换</title>
      <link>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</link>
      <description><![CDATA[TL;DR:
1 通道 TF 模型的行为与 3 通道模型不同。两者都成功从 Darknet -&gt; TF 转换，但 1 通道模型的表现不如转换前。
手头的任务和声明：
我有两个经过训练的 yolov4-tiny darknet 权重文件 (.weights)，一个有灰度输入（1 通道），另一个有颜色输入（3 通道）。我正在将两个权重文件转换为 Tensorflow 检查点格式，使用一个通用存储库（用于此任务），该存储库位于：
https://github.com/hunglc007/tensorflow-yolov4-tflite.git
两种模型的性能都已通过 c++ opencv LoadFromDarknet() 和 Python 等效项进行了测试。这两个模型本质上都是用灰度图像进行训练的，并且对灰度图像进行操作。3 通道模型的输入只是缩放到 3 通道的灰度图像。
Python 版本：3.10.11
TF 版本：2.10.1
问题陈述：
使用 tf.keras.Models.load_model(X) 加载时，带有颜色输入的权重文件转换良好，之后运行良好，但是当转换灰度输入权重文件时，使用 Tensorflow 加载时模型的性能急剧下降，我的意思是在最明显的情况下，带有颜色输入的模型运行完美，检测效果很差或不存在。值得注意的是，框不会错位，这意味着当发现检测结果时，它们大约在正确的位置，但例如宽度和高度可能会偏离。
我知道这个存储库的常见问题（硬编码内容等），并相应地更改了每次转换/模型加载的参数，并且在转换或模型加载期间不会发生任何错误。
我已经确认了输入层：

灰度：（无，640,640,1）
颜色：（无，640,640,3）

测试图像（用于性能测试）使用 opencv-python 加载，并且它们的有效性也已审查，即使将错误维度的数据插入到输入层也会出现错误。
除输入层之外的架构相同，已使用 model.summary() 确认。
我注意到，几年前我用不同的 TF 版本转换的 3 通道模型由 model.summary() 生成的架构有些不同。一些图块层似乎缺失了。此外，一些 tf 操作的名称也不同，但这可能只是 TF 版本不同。
旧颜色模型：
 tf_op_layer_Sigmoid (TensorFlo (None, 40, 40, 3, 2 0 [&#39;tf_op_layer_split_3[0][0]&#39;]
wOpLayer) )

tf_op_layer_Tile/multiples (Te (5,) 0 [&#39;tf_op_layer_strided_slice[0][0]
nsorFlowOpLayer) &#39;]

tf_op_layer_Sigmoid_3 (TensorF (None, 20, 20, 3, 2 0 [&#39;tf_op_layer_split_4[0][0]&#39;]
lowOpLayer) ) )

新灰度模型：
 tf.math.sigmoid (TFOpLambda) (无，40，40，3，2 0 [&#39;tf.split_3[0][0]&#39;]
)

---此处缺少图块层---

tf.math.sigmoid_3 (TFOpLambda) (无，20，20，3，2 0 [&#39;tf.split_4[0][0]&#39;]
)

我现在很困惑。有什么帮助吗？
一些反复试验：

使用 Yolov4-tiny Head 解码块 -&gt;即使在模型能够加载的情况下也没有变化（解码时错误的尺寸会引发错误）
之前提到的旧 3 通道模型（几年前已转换为 Darknet -&gt; TF），以与新模型相同的方式加载时可以完美运行
]]></description>
      <guid>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</guid>
      <pubDate>Fri, 05 Jul 2024 13:54:37 GMT</pubDate>
    </item>
    <item>
      <title>预测患者住院时间（机器学习分类）</title>
      <link>https://stackoverflow.com/questions/78710644/predict-the-the-length-of-stay-in-hospital-for-a-patient-ml-classification</link>
      <description><![CDATA[我有一个分类练习，我想预测住院时间（入院时进行预测）。我混合了数值和分类特征，数据集的大小为 318438x 17。
我应该使用哪种 ML 算法进行此练习？我应该对分类变量使用哪种编码技术？
以下是有关特征的详细信息：

病例 ID：医院就诊标识；
医院代码：医院的唯一代码（范围从 1 到 32）；
医院类型代码：医院类型的唯一代码（范围从 a 到 g）；
医院城市代码：医院城市代码（范围从 1 到 13）；
医院地区代码：医院地区代码（X、Y、Z）；
医院可用额外房间：医院可用额外房间数量（范围从 1 到 24）；
部门：病房所在的部门类型(妇科、麻醉、放疗、肺结核和胸腔疾病、外科);
病房类型：病房类型代码(P、Q、R、S、T、U);
病房设施代码：病房设施代码(A、B、C、D、E、F);
床位等级：病房床位状况(1、2、3、4);
患者 ID：唯一患者 ID;
患者城市代码：患者的城市代码(范围从 1 到 38);
入院类型：医院登记的入院类型(创伤、急诊、紧急);
疾病严重程度：记录的疾病严重程度入院时（中度、轻微、极度） ;
陪同患者的访客：陪同患者的访客人数（范围从 0 到 32）；
年龄：患者的年龄（0-10、11-20、21-30、...、91-100）;
入院押金：入院时的押金（范围从 1800 到 11 000）;
住院时间（目标变量 - 11 个类别）：患者的住院天数（0-10、11-20、...、91-100、超过 100 天）。

感谢您的帮助！
我已经尝试了带有独热编码的随机森林分类器和标签编码，但我只获得了 0.38 的准确度分数。]]></description>
      <guid>https://stackoverflow.com/questions/78710644/predict-the-the-length-of-stay-in-hospital-for-a-patient-ml-classification</guid>
      <pubDate>Fri, 05 Jul 2024 09:16:20 GMT</pubDate>
    </item>
    <item>
      <title>将最优模型应用于测试集</title>
      <link>https://stackoverflow.com/questions/78707916/to-apply-the-optimal-model-to-the-test-set</link>
      <description><![CDATA[我有一个数据集需要训练和测试，还有另一个数据集作为测试集。
我已经使用训练数据集获得了最佳模型，并希望将该模型应用于测试集进行预测，但遇到了此错误消息：
ValueError：特征名称应与拟合期间传递的特征名称匹配。
在拟合时看到但现在缺失的特征名称：
- 教育
- 婚姻

如何解决此错误？
示例数据集

# 加载和预处理训练数据
df = pd.read_csv(&#39;training.csv&#39;)
df.drop([&#39;USAGE(0)&#39;, &#39;CUSTOMERID&#39;], axis=1, inplace=True)

# 初始化编码器并拟合训练数据
encoder = OneHotEncoder(drop=&#39;first&#39;, sparse_output=False)
encoder.fit(df.select_dtypes(include=[&#39;object&#39;]))

# 在训练数据中编码字符串类型变量
for column in df.select_dtypes(include=[&#39;object&#39;]).columns:
coded_result =coder.transform(df[[column]])
coded_df = pd.DataFrame(encoded_result, columns=encoder.get_feature_names_out([column]))
df.drop(column, axis=1, inplace=True)
df = pd.concat([df,coded_df], axis=1)

# 分离特征和标签
label = &#39;PAYMENT(0)&#39;
excluded_columns = [label]
features = [feature for feature in df.columns if feature not in excluded_columns]
X = df[features]
y = df[label]

# 训练-测试分割
test_size = 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)

# 构建并训练初始决策树模型
model = DecisionTreeClassifier(criterion=&#39;gini&#39;, min_samples_leaf=3000)
model.fit(X_train, y_train)

# 使用网格搜索和交叉验证进行超参数调整
param_grid = {
&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;],
&#39;min_samples_leaf&#39;: [10, 20, 30, 40, 50, 60, 70, 80]
}
cv = KFold(n_splits=10, shuffle=True)
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv,scoring=&#39;accuracy&#39;)
grid_search.fit(X_train, y_train)

# 训练最优模型
optimal_model = grid_search.best_estimator_

# 可视化最优决策树
plt.figure(figsize=(100, 20))
plot_tree(optimal_model, filled=True, feature_names=features)
plt.show()

# 加载新测试数据
new_test_df = pd.read_csv(&#39;trial.csv&#39;)

# 保留提交文件的“ID”列
submission_ids = new_test_df[&#39;CUSTOMERID&#39;].copy()

new_test_df.drop(&#39;USAGE(0)&#39;, axis=1, inplace=True)

# 确保所有必需的列都存在
for column in df.select_dtypes(include=[&#39;object&#39;]).columns:
if column not in new_test_df.columns:
new_test_df[column] = 0

# 在新测试数据中编码字符串类型变量
for column in new_test_df.select_dtypes(include=[&#39;object&#39;]).columns:
coded_result =coder.transform(new_test_df[[column]]) # 使用拟合的编码器进行转换
coded_df = pd.DataFrame(encoded_result, columns=encoder.get_feature_names_out([column]))
new_test_df.drop(column, axis=1, inplace=True)
new_test_df = pd.concat([new_test_df,coded_df], axis=1)

# 确保新测试数据具有与训练数据相同的特征列
for feature在功能中：
如果功能不在 new_test_df.columns 中：
new_test_df[功能] = 0
X_new_test = new_test_df[功能]

# 将最佳模型应用于新测试数据
y_new_test_pred = optimal_model.predict(X_new_test)

# 将预测保存到名为“mapping.csv”的 CSV 文件中
submission = pd.DataFrame({
&#39;CUSTOMERID&#39;: submission_ids,
&#39;PAYMENT(0)&#39;: y_new_test_pred
})

submission.to_csv(&#39;mapping.csv&#39;, index=False)
]]></description>
      <guid>https://stackoverflow.com/questions/78707916/to-apply-the-optimal-model-to-the-test-set</guid>
      <pubDate>Thu, 04 Jul 2024 15:27:01 GMT</pubDate>
    </item>
    <item>
      <title>将基于 Bert 的 PyTorch 模型导出到 CoreML。如何让 CoreML 模型适用于任何输入？</title>
      <link>https://stackoverflow.com/questions/78704542/exporting-a-bert-based-pytorch-model-to-coreml-how-can-i-make-the-coreml-model</link>
      <description><![CDATA[我使用以下代码将基于 Bert 的 PyTorch 模型导出到 CoreML。
由于我使用
dummy_input = tokenizer(&quot;A French fan&quot;, return_tensors=&quot;pt&quot;)

在 macOS 上测试时，CoreML 模型仅适用于该输入。如何让 CoreML 模型适用于任何输入（即任何文本）？

导出脚本：
# -*- coding: utf-8 -*-
&quot;&quot;&quot;Core ML Export
pip install tr​​ansformers torch coremltools nltk
&quot;&quot;&quot;
导入 os
从 transformers 导入 AutoModelForTokenClassification、AutoTokenizer
导入 torch
导入 torch.nn 作为 nn
导入 nltk
导入 coremltools 作为 ct
nltk.download(&#39;punkt&#39;)
# 加载模型和 tokenizer
model_path = os.path.join(&#39;model&#39;)
model = AutoModelForTokenClassification.from_pretrained(model_path, local_files_only=True)
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
# 修改模型的 forward 方法以返回元组
class ModifiedModel(nn.Module):
def __init__(self, model):
super(ModifiedModel, self).__init__()
self.model = model
self.device = model.device # 添加设备属性

def forward(self, input_ids,tention_mask, token_type_ids=None):
outputs = self.model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)
returnoutputs.logits

modified_model = ModifiedModel(model)

# 导出到 Core ML
def convert_to_coreml(model, tokenizer):
# 定义用于跟踪的虚拟输入
dummy_input = tokenizer(&quot;A French fan&quot;, return_tensors=&quot;pt&quot;)
dummy_input = {k: v.to(model.device) for k, v in dummy_input.items()}

# 使用虚拟输入跟踪模型
traced_model = torch.jit.trace(model,(
dummy_input[&#39;input_ids&#39;],dummy_input[&#39;attention_mask&#39;], dummy_input.get(&#39;token_type_ids&#39;)))

# 转换为 Core ML
输入 = [
ct.TensorType(name=&quot;input_ids&quot;, shape=dummy_input[&#39;input_ids&#39;].shape),
ct.TensorType(name=&quot;attention_mask&quot;, shape=dummy_input[&#39;attention_mask&#39;].shape)
]
if &#39;token_type_ids&#39; in dummy_input:
输入.append(ct.TensorType(name=&quot;token_type_ids&quot;, shape=dummy_input[&#39;token_type_ids&#39;].shape))

mlmodel = ct.convert(traced_model, 输入=inputs)

# 保存 Core ML 模型
mlmodel.save(&quot;model.mlmodel&quot;)
print(&quot;模型导出到 Core ML成功&quot;)

convert_to_coreml(modified_model, tokenizer)

要使用导出的模型：
import os
from transformers import AutoModelForTokenClassification, AutoTokenizer
import torch
import torch.nn as nn
import nltk
import coremltools as ct
from coremltools.models import MLModel
import numpy as np
from transformers import AutoTokenizer
import nltk

nltk.download(&#39;punkt&#39;)

# 加载 Core ML 模型
model = MLModel(&#39;model.mlmodel&#39;)

# 加载 tokenizer
model_path = &#39;model&#39;
tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)

def prepare_input(text, tokenizer):
tokens = nltk.tokenize.word_tokenize(text)
tokenized_inputs = tokenizer(tokens, is_split_into_words=True, return_tensors=&quot;np&quot;)
input_ids = tokenized_inputs[&#39;input_ids&#39;].astype(np.int32)
tention_mask = tokenized_inputs[&#39;attention_mask&#39;].astype(np.int32)

input_data = {
&#39;input_ids&#39;: input_ids,
&#39;attention_mask&#39;:tention_mask
}

if &#39;token_type_ids&#39; in tokenized_inputs:
input_data[&#39;token_type_ids&#39;] = tokenized_inputs[&#39;token_type_ids&#39;].astype(np.int32)

return input_data, tokens

def predict(text):
# 准备输入
input_data, tokens = prepare_input(text, tokenizer)

# 进行预测
prediction = model.predict(input_data)

# 提取预测标签
logits = prediction[&#39;output&#39;] # 根据模型的输出调整此键
predicted_label = np.argmax(logits, axis=-1)[0]

# 显示结果
for word, label in zip(tokens, predicted_label):
print(f&quot;{word}: {model.model_description.outputDescriptions[0].dictionaryType.int64KeyType.stringDictionary[label]}&quot;)

# 用一个句子测试模型
predict(&quot;A French fan&quot;)

该脚本仅适用于示例“A French Fan”。当我尝试另一个示例 predict(&quot;A football fan is standing in the stadium.&quot;) 时，它会触发错误：
NSLocalizedDescription = &quot;MultiArray shape (1 x 12) does not match the shape (1 x 5) specified in the model description&quot;;


环境：

导出脚本：在 Ubuntu 20.04 上测试了 Python 3.10 和 torch 2.3.1（在 Windows 10 上不起作用）。
预测脚本：必须在 macOS 10.13+ 上运行，因为 CoreML 模型仅支持在 macOS 10.13+ 上进行预测。
]]></description>
      <guid>https://stackoverflow.com/questions/78704542/exporting-a-bert-based-pytorch-model-to-coreml-how-can-i-make-the-coreml-model</guid>
      <pubDate>Wed, 03 Jul 2024 23:39:36 GMT</pubDate>
    </item>
    <item>
      <title>Unity ML-Agents --num-envs 获取环境 ID</title>
      <link>https://stackoverflow.com/questions/78598596/unity-ml-agents-num-envs-get-env-id</link>
      <description><![CDATA[我想训练一款需要用户登录的游戏。目前，我对登录名进行了硬编码以使用训练帐户。每个玩家只能登录一次，因此使用 --num-envs=x 参数进行训练仍将导致只有一个环境实际进行训练。有没有办法访问当前环境的 ID，以便我可以为每个单独的环境使用不同的登录名？我希望能够说
playerName = $&quot;player{envId};

有没有办法做到这一点？
我研究了 Academy 和 Communicator 实现，但没有发现任何有用的东西。]]></description>
      <guid>https://stackoverflow.com/questions/78598596/unity-ml-agents-num-envs-get-env-id</guid>
      <pubDate>Sun, 09 Jun 2024 12:31:24 GMT</pubDate>
    </item>
    <item>
      <title>在具有标准化变量的模型中缩放样本外预测：恢复到原始比例</title>
      <link>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</link>
      <description><![CDATA[我正在使用一个模型进行预测，其中变量按 $ x_i = \frac{{x_i - \text{mean}(x_i)}}{{\text{sd}(x_i)}} $ 缩放，并且我保存了平均值和标准差。现在，对于样本外预测，假设目标变量 $ ( x_i )$，基于缩放模型，我该如何缩小预测值？
我是否应该使用样本内 $ \text{Mean}(x_i) $ 和 $ \text{sd}(x_i) $ 来缩小样本外预测值，以便：
$ \text{重新缩放的样本外预测} = \text{缩放的预测} \times \text{sd}(x_i) + \text{mean}(x_i) $
这里的适当程序是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</guid>
      <pubDate>Tue, 04 Jun 2024 15:17:14 GMT</pubDate>
    </item>
    </channel>
</rss>