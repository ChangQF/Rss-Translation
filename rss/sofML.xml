<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 07 Jun 2024 18:20:18 GMT</lastBuildDate>
    <item>
      <title>Tensorflow Lite 尺寸错误？同样的模型，如果不使用 tensorflow lite，模型可以完美运行。为什么？</title>
      <link>https://stackoverflow.com/questions/78592790/tensorflow-lite-dimmension-error-with-the-same-model-if-not-using-tensorflow</link>
      <description><![CDATA[请帮我解决我的问题
我将模型运行到 tflite 中。然后收到错误：
ValueError：无法设置张量：维度不匹配。得到 56 但输入 0 的维度 0 应为 1
我将使用的输入是一个名为 user_place_array 的数组
这是我的代码：
model = tf.lite.Interpreter(model_path=&quot;/content/recommender_model.tflite&quot;)

input_details = model.get_input_details()
output_details = model.get_output_details()
input_shape = input_details[0][&#39;shape&#39;]

print(f&quot;user_place_array shape = &quot;,user_place_array.shape)
print(f&quot;model input = &quot;,input_shape)


返回值为：
user_place_array shape = (56, 2)
model输入 = [1 2]

然后，我检查 user_place_array，输出为：
array([[253, 0],
[253, 1],
[253, 2],
[253, 3],
# 直到 56


然后我使用 tflite 运行模型：
model.set_tensor(input_details[0][&#39;index&#39;], user_place_array)
这就是问题所在。我在这里收到 tflite 错误
ValueError：无法设置张量：维度不匹配。得到 56，但输入 0 的维度 0 应为 1。
当我不使用 tflite 时，模型运行完美。我使用：
model.predict(user_place_array).flatten()
模型按预期提供建议。我不知道为什么它在 Tflite 上不起作用。
有人能帮我吗？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78592790/tensorflow-lite-dimmension-error-with-the-same-model-if-not-using-tensorflow</guid>
      <pubDate>Fri, 07 Jun 2024 15:22:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 提取多个实体 [关闭]</title>
      <link>https://stackoverflow.com/questions/78592545/extract-multiple-entities-with-llms</link>
      <description><![CDATA[我正在开展一个项目，该项目涉及从相同类型的 PDF 文档中提取实体（40-100 个），每个文档包含 8-20 页。这些文档包含表格、键值对和文本。我正在尝试寻找一种高效且经济的方法，以使用大型语言模型 (LLM) 实现高精度和高速度的实体提取。
我尝试过 RAG（检索增强生成），但它似乎很昂贵，因为它需要获取相关块并为每个实体生成 JSON 输出。因此，我正在寻找其他方法来完成此任务。
我考虑的一种方法是使用滑动窗口技术，其中我将连续的文档部分提供给 LLM 并采用提示工程来提取该特定部分中定义的实体。但是，这种方法引入了复杂性，例如处理某些实体的重复条目。
如果您能提供任何建议或最佳实践，以便以更高效、更经济的方式使用 LLM 从多页 PDF 中提取实体，我将不胜感激。
提前感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78592545/extract-multiple-entities-with-llms</guid>
      <pubDate>Fri, 07 Jun 2024 14:33:37 GMT</pubDate>
    </item>
    <item>
      <title>scikit 中的 gbrt_minimize 如何决定尝试多少个参数分割</title>
      <link>https://stackoverflow.com/questions/78592454/how-does-gbrt-minimize-from-scikit-decide-how-many-parameter-splits-to-try</link>
      <description><![CDATA[根据我对https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html和梯度提升决策树的理解，我假设对于 N 个参数，回归器会沿着每个参数选择一组分割，计算出应用此分割如何对数据进行分区，然后决定选择哪个分割以最大程度地减少损失（对于特定分位数）。
我的问题是，如果您的参数是实数，您如何决定在哪些参数值处进行分割？我原本希望找到某种参数来确定要进行多少次“等距”分割，但我只看到一个参数可以确定分割两侧所需的数据值数量以使其有效。这是否意味着它以某种方式反向运作？
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78592454/how-does-gbrt-minimize-from-scikit-decide-how-many-parameter-splits-to-try</guid>
      <pubDate>Fri, 07 Jun 2024 14:14:02 GMT</pubDate>
    </item>
    <item>
      <title>线性回归和时间序列分析预测完成一项工作的时间</title>
      <link>https://stackoverflow.com/questions/78592088/linear-regression-and-time-series-analysis-in-predict-the-time-to-complete-a-wor</link>
      <description><![CDATA[我对线性回归和时间序列分析等预测技术还不熟悉。我的问题如下。我的应用有点像待办事项应用。它有很多项目。一个项目有很多部分。一项任务有优先级和任务数量。假设工作没有限制。我想根据同一项目的历史数据预测完成一项工作的时间。对于线性回归，我有以下内容：

y：完成一项工作的时间
x1：一项工作的优先级（类别变量）
x2：一项工作中的任务数量。

虽然我知道这个模型不够准确，但我仍然想给出关于预期时间的建议，因为我无法收集足够的数据来影响 y。这样可以吗？我可以使用时间序列分析吗？]]></description>
      <guid>https://stackoverflow.com/questions/78592088/linear-regression-and-time-series-analysis-in-predict-the-time-to-complete-a-wor</guid>
      <pubDate>Fri, 07 Jun 2024 13:02:03 GMT</pubDate>
    </item>
    <item>
      <title>Python 中事件/事件关系的关联规则</title>
      <link>https://stackoverflow.com/questions/78591986/association-rule-on-incident-event-relations-in-python</link>
      <description><![CDATA[我有两组数据：一个事件列表和一个已解决事件列表，其中包含导致每个事件的事件。我如何训练模型来预测哪个事件导致新事件发生？
示例：触发事件后，模型预测哪个事件最有可能导致事件发生。]]></description>
      <guid>https://stackoverflow.com/questions/78591986/association-rule-on-incident-event-relations-in-python</guid>
      <pubDate>Fri, 07 Jun 2024 12:38:09 GMT</pubDate>
    </item>
    <item>
      <title>我可以训练一个逻辑回归模型来将 ML 模型组合起来形成一个集成模型吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78591369/can-i-train-a-logistic-regression-model-for-combining-ml-models-to-form-an-ensem</link>
      <description><![CDATA[我有 3 个经过训练的 ML 模型，用于对数据集进行分类。我想将它们组合成一个集成模型。我知道有多种方法可以做到这一点 - 投票分类器、堆叠、装袋、提升等。
但我想组合概率而不是类别，我认为这可以通过加权总和来实现。为了将权重分配给每个模型的概率，而不是尝试多种权重组合，我得到了一个建议，即使用逻辑回归，将概率值作为特征。这是一种从我的每个模型中获取概率值的权重或系数的可接受方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78591369/can-i-train-a-logistic-regression-model-for-combining-ml-models-to-form-an-ensem</guid>
      <pubDate>Fri, 07 Jun 2024 10:38:34 GMT</pubDate>
    </item>
    <item>
      <title>寻找快速大规模图像嵌入比较数据库结构</title>
      <link>https://stackoverflow.com/questions/78591334/looking-for-fast-large-scale-image-embeddings-comparison-database-structure</link>
      <description><![CDATA[我计划将 100-200 万个实体存储到数据库中。每个实体将链接到 10-100 个图像嵌入。目标是使用可能属于也可能不属于数据库的外部图像，并将其与每个存储的嵌入进行比较，以找到它可能属于的最相似的实体。
我想问一下，哪种数据库最适合这项任务，为什么？与 Milvus 或 FAISS 等更专业的数据库相比，带有 pgvector 的 PostgreSQL 会慢多少？]]></description>
      <guid>https://stackoverflow.com/questions/78591334/looking-for-fast-large-scale-image-embeddings-comparison-database-structure</guid>
      <pubDate>Fri, 07 Jun 2024 10:31:33 GMT</pubDate>
    </item>
    <item>
      <title>我的 UNet 图像重建模型无法学习</title>
      <link>https://stackoverflow.com/questions/78591272/my-unet-image-reconstruction-model-wont-learn</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78591272/my-unet-image-reconstruction-model-wont-learn</guid>
      <pubDate>Fri, 07 Jun 2024 10:13:54 GMT</pubDate>
    </item>
    <item>
      <title>Gradio 用于实时语音对话</title>
      <link>https://stackoverflow.com/questions/78591124/gradio-for-live-voice-conversation</link>
      <description><![CDATA[我正在努力为我的实时语音助手设置 gradio，用户和系统应该像 siri 一样持续地互相交谈，但我不知道输入和输出变量应该使用什么
`conversation_interface = gr.Interface(
fn=voice_assistant,
inputs=gr.inputs.Microphone(label=&quot;Speak Here&quot;),
outputs=gr.outputs.Textbox(label=&quot;Assistant&#39;s Response&quot;),
title=&quot;Bright Dentistry&quot;,
description=&quot;Welcome to Bright Dentistry here we do care of your dental!.&quot;,
allow_flagging=False,

)`
我试图摆脱变量，但似乎 gradio 需要它们]]></description>
      <guid>https://stackoverflow.com/questions/78591124/gradio-for-live-voice-conversation</guid>
      <pubDate>Fri, 07 Jun 2024 09:44:00 GMT</pubDate>
    </item>
    <item>
      <title>在训练过程中，我遇到了以下 Python 错误[关闭]</title>
      <link>https://stackoverflow.com/questions/78590831/while-training-i-ran-into-the-following-python-error</link>
      <description><![CDATA[Epoch 1/100 Traceback（最近一次调用最后一次）：
文件“C:\Users\noor_\Desktop\Code V1 and V2 Caps\code\Squash Code try it\Oral.py”，第 384 行，位于&lt;module&gt; 
train(model=model, data=((x_train, y_train), (x_test, y_test)), class_names=classNames, ar

这是我在运行代码时遇到的错误。有人能解决吗？]]></description>
      <guid>https://stackoverflow.com/questions/78590831/while-training-i-ran-into-the-following-python-error</guid>
      <pubDate>Fri, 07 Jun 2024 08:45:55 GMT</pubDate>
    </item>
    <item>
      <title>如果训练数据集中的正样本多于负样本，XGBoost 的 scale_pos_weight 是否可以正确平衡正样本？</title>
      <link>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我相信 scale_pos_weight 会是一种更好的方法。
是否可以安全地假设，由于比率小于 1，它仍将正确平衡类别？特异性在我的研究中很重要，但我们的主要目标集中在召回率、精确度和 F1 分数上。此设置是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 logistf 包时，Firth 的模型在 R 中卡住了（出现未收敛警告，CPU 使用率高达 99%）</title>
      <link>https://stackoverflow.com/questions/78579401/firths-model-stuck-with-non-converge-warning-and-cpu-usage-99-in-r-using-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78579401/firths-model-stuck-with-non-converge-warning-and-cpu-usage-99-in-r-using-the</guid>
      <pubDate>Wed, 05 Jun 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制多类别分类中所有类别的 SHAP 摘要图</title>
      <link>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</link>
      <description><![CDATA[我正在使用 XGBoost 和 SHAP 来分析多类分类问题中的特征重要性，并需要帮助同时绘制所有类的 SHAP 摘要图。目前，我一次只能生成一个类的图。
SHAP 版本：0.45.0
Python 版本：3.10.12

这是我的代码：
import xgboost as xgb
import shap
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# 生成合成数据
X, y = make_classification(n_samples=500, n_features=20, n_informative=4, n_classes=6, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# 训练 XGBoost 模型进行多类分类
model = xgb.XGBClassifier(objective=&quot;multi:softprob&quot;, random_state=42)
model.fit(X_train, y_train)

然后我尝试绘制形状值：
# 创建 SHAP TreeExplainer
explainer = shap.TreeExplainer(model)

# 计算测试集的 SHAP 值
shap_values = explainer.shap_values(X_test)

# 尝试绘制所有类的摘要
shap.summary_plot(shap_values, X_test, plot_type=&quot;bar&quot;)

我得到了这个交互图而是：

我在这篇文章的帮助下解决了这个问题：
shap.summary_plot(shap_values[:,:,0], X_test, plot_type=&quot;bar&quot;)

哪个给出类别 0 的正常条形图：

然后我可以对类别 1、2、3 等执行相同操作。
问题是，如何为所有类别制作摘要图？即，单个图显示特征对每个类别的贡献？]]></description>
      <guid>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</guid>
      <pubDate>Sat, 27 Apr 2024 19:02:16 GMT</pubDate>
    </item>
    <item>
      <title>加载 pickle NotFittedError：TfidfVectorizer - 词汇表不适合</title>
      <link>https://stackoverflow.com/questions/57213165/loading-pickle-notfittederror-tfidfvectorizer-vocabulary-wasnt-fitted</link>
      <description><![CDATA[多标签分类
我正在尝试使用 scikit-learn/pandas/OneVsRestClassifier/logistic 回归预测多标签分类。构建和评估模型有效，但尝试对新样本文本进行分类无效。
场景 1：
一旦我构建了一个模型，就使用名称 (sample.pkl) 保存该模型并重新启动我的内核，但是当我在对样本文本进行预测期间加载已保存的模型 (sample.pkl) 时，它给出了错误：
 NotFittedError：TfidfVectorizer - 词汇表不适合。

我构建了模型并评估了模型，然后我使用名称 sample.pkl 保存了该模型。我重启了内核，然后加载模型对样本文本进行预测 NotFittedError: TfidfVectorizer - 词汇表不适合
推理
import pickle,os
import collections
import numpy as np
import pandas as pd
import seaborn as sns
from tqdm import tqdm
import matplotlib.pyplot as plt
from collections import Counter
from nltk.corpus import stopwords
import json, nltk, re, csv, pickle
from sklearn.metrics import f1_score # 性能矩阵
from sklearn.multiclass import OneVsRestClassifier # 二元相关性
from sklearn.linear_model import LogisticRegression 
from sklearn.model_selection import train_test_split 
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.feature_extraction.text 导入 CountVectorizer
从 sklearn.preprocessing 导入 MultiLabelBinarizer
从 sklearn.model_selection 导入 train_test_split
从 sklearn.linear_model 导入 LogisticRegression
stop_words = set(stopwords.words(&#39;english&#39;))

def cleanHtml(sentence):
&#39;&#39;&#39;&#39; 删除标签 &#39;&#39;&#39;
cleanr = re.compile(&#39;&lt;.*?&gt;&#39;)
cleantext = re.sub(cleanr, &#39; &#39;, str(sentence))
return cleantext

def cleanPunc(sentence): 
&#39;&#39;&#39; 函数用于清除单词中的任何标点符号或特殊字符 &#39;&#39;&#39;
cleaned = re.sub(r&#39;[?|!|\&#39;|&quot;|#]&#39;,r&#39;&#39;,sentence)
cleaned = re.sub(r&#39;[.|,|)|(|\|/]&#39;,r&#39; &#39;,cleaned)
cleaned = cleaned.strip()
cleaned = cleaned.replace(&quot;\n&quot;,&quot; &quot;)
return cleaned

def keepAlpha(sentence):
&quot;&quot;&quot; 保留 alpha 句子 &quot;&quot;&quot;
alpha_sent = &quot;&quot;
for word in sentence.split():
alpha_word = re.sub(&#39;[^a-z A-Z]+&#39;, &#39; &#39;, word)
alpha_sent += alpha_word
alpha_sent += &quot; &quot;
alpha_sent = alpha_sent.strip()
return alpha_sent

def remove_stopwords(text):
&quot;&quot;&quot; 删除停用词 &quot;&quot;&quot;
no_stopword_text = [w for w in text.split() if not w in stop_words]
return &#39; &#39;.join(no_stopword_text)

test1 = pd.read_csv(&quot;C:\\Users\\abc\\Downloads\\test1.csv&quot;)
test1.columns

test1.head()
siNo plot movie_name gender_new
1 故事以 Hannah 开始... 唱歌 [戏剧,teen]
2 Debbie 最喜欢的乐队是 Dream... 最忠实的粉丝 [戏剧]
3 这个祖鲁家庭的故事是... 回来，非洲 [戏剧,纪录片]

获取错误
当我对示例文本进行推理时，我在这里获取错误
def infer_tags(q):
q = cleanHtml(q)
q = cleanPunc(q)
q = keepAlpha(q)
q = remove_stopwords(q)
multilabel_binarizer = MultiLabelBinarizer()
tfidf_vectorizer = TfidfVectorizer()
q_vec = tfidf_vectorizer.transform([q])
q_pred = clf.predict(q_vec)
return multilabel_binarizer.inverse_transform(q_pred)

for i in range(5):
print(i)
k = test1.sample(1).index[0] 
print(&quot;电影：&quot;, test1[&#39;movie_name&#39;][k], &quot;\n预测类型：&quot;, infer_tags(test1[&#39;plot&#39;][k])), print(&quot;实际类型：&quot;,test1[&#39;genre_new&#39;][k], &quot;\n&quot;)


已解决
我解决了将 tfidf 和 multibiniraze 保存到 pickle 模型中的问题
from sklearn.externals import joblib
pickle.dump(tfidf_vectorizer, open(&quot;tfidf_vectorizer.pickle&quot;, &quot;wb&quot;))
pickle.dump(multilabel_binarizer, open(&quot;multibinirizer_vectorizer.pickle&quot;, &quot;wb&quot;))
vectorizer = joblib.load(&#39;/abc/downloads/tfidf_vectorizer.pickle&#39;)
multilabel_binarizer = joblib.load(&#39;/abc/downloads/multibinirizer_vectorizer.pickle&#39;)

def infer_tags(q):
q = cleanHtml(q)
q = cleanPunc(q)
q = keepAlpha(q) 
q = remove_stopwords(q)
q_vec = vectorizer .transform([q])
q_pred = rf_model.predict(q_vec)
return multilabel_binarizer.inverse_transform(q_pred)

我通过以下链接找到了解决方案
,https://stackoverflow.com/questions/32764991/how-do-i-store-a-tfidfvectorizer-for-future-use-in-scikit-learn&gt;]]></description>
      <guid>https://stackoverflow.com/questions/57213165/loading-pickle-notfittederror-tfidfvectorizer-vocabulary-wasnt-fitted</guid>
      <pubDate>Fri, 26 Jul 2019 04:21:05 GMT</pubDate>
    </item>
    <item>
      <title>使用单类 SVM 计算异常检测的异常分数</title>
      <link>https://stackoverflow.com/questions/53956538/calculating-anomaly-score-for-anomaly-detection-using-one-class-svm</link>
      <description><![CDATA[我对使用单类 SVM 计算异常检测的异常分数有疑问。我的问题是：如何使用 decision_function(X) 计算它，就像我在隔离森林中计算异常分数一样？
非常感谢，]]></description>
      <guid>https://stackoverflow.com/questions/53956538/calculating-anomaly-score-for-anomaly-detection-using-one-class-svm</guid>
      <pubDate>Fri, 28 Dec 2018 09:50:20 GMT</pubDate>
    </item>
    </channel>
</rss>