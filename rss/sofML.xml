<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 13 Jun 2024 21:15:26 GMT</lastBuildDate>
    <item>
      <title>有没有更好的方法可以消除增强图像中的白色闪烁/点/小簇（噪音）</title>
      <link>https://stackoverflow.com/questions/78620185/is-there-a-better-way-to-get-rid-of-white-flickers-dots-small-clustersnoise-fr</link>
      <description><![CDATA[因此，我正在开展一个项目，需要我分割每个单独的细胞（图的左图）。通过获得一些帮助并使用自适应阈值和视网膜理论，我能够识别不同的组件，如图的右图所示。但是由于噪音，我的进一步分析变得很麻烦。我需要摆脱中间的小白色像素。因为我是图像分析的新手，所以我不确定哪种方法最好。有人可以帮我吗？我想我可以编写一个小代码，使其遍历每个连接的组件并查看组件实际上由多少个像素组成。如果少于 3，则将其删除。但这似乎不起作用。还有其他我不知道的方法吗？非常感谢。 
import cv2
import numpy as np

img = cv2.imread(&#39;/Users/yahya2/result1.png&#39;, 0) 

nb_components, output, stats, _ = cv2.connectedComponentsWithStats(img, connections=8)
sizes = stats[1:, -1] 
new_img = np.zeros_like(img)
for i in range(0, nb_components - 1):
if sizes[i] &gt;= 10: # 保留具有 3 个或更多像素的组件
new_img[output == i + 1] = 255 

cv2.imshow(&#39;去噪图像&#39;, new_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78620185/is-there-a-better-way-to-get-rid-of-white-flickers-dots-small-clustersnoise-fr</guid>
      <pubDate>Thu, 13 Jun 2024 21:07:18 GMT</pubDate>
    </item>
    <item>
      <title>我如何将所有 csv 文件数据绘制到一张图表中并以可解释的方式表示它？</title>
      <link>https://stackoverflow.com/questions/78620038/how-can-i-plot-all-csv-files-data-into-one-graph-and-represent-it-in-such-a-way</link>
      <description><![CDATA[我使用一些传感器收集了时间序列数据。数据集包含两个类别的 60 个样本，每个类别有 30 个样本。每个样本有 50 行和 11 列，标签以注释方式完成，即样本的文件名是样本数据的标签。现在，我想以一种应该表示与时间相关的数据的方式来可视化数据。 （例如 x 轴上的时间和 y 轴上的传感器值）。
这是来自数据集的样本图像（样本图像 1）（样本图像 2）
这是我的数据集的链接：https://drive.google.com/drive/folders/1aRIR5ei3Gr0RdS8QXM6hrqPQ2cJdRyEp
我还提供了代码，我曾尝试将其可视化，但帮助不大。
提供的代码未提供所需的输出。输出图像之一是：

此图是通过更改 go.Scatter() 中的 x=df.columns、y=df.iloc[0] 的值生成的
我想生成一个图表，其中 x 轴上有 50 个点（50 行）作为时间点，y 轴上绘制有 11 列数据。
任何帮助都将不胜感激！谢谢 &amp;问候
代码：
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import plotly.offline as pyo
import os

# 获取目录中的 csv 文件列表
PATH = &quot;E:\\Sankalp\\Practice_Stuff\\DummyData\\&quot;
fileNames = os.listdir(PATH)
fileNames = [file for file in fileNames if &#39;.csv&#39; in file]

# 创建图形
fig = go.Figure()
x_axis_values = list(range(50))

# 循环遍历每个 csv 文件并向图形添加轨迹
for file in fileNames:
if file.startswith(&#39;bye bye&#39;): 
df = pd.read_csv(os.path.join(PATH, file),header=None)
fig.add_trace(go.Scatter(x=x_axis_values, y=df.iloc[:,:], name=file, mode=&#39;lines+markers&#39;,line=dict(color=&quot;#2efd70&quot;)))
elif file.startswith(&#39;welcome&#39;):
df = pd.read_csv(os.path.join(PATH, file),header=None)
fig.add_trace(go.Scatter(x=x_axis_values, y=df.iloc[:,:], name=file, mode=&#39;lines+markers&#39;,line=dict(color=&quot;#ff0000&quot;)))

# 显示图表
fig.update_layout(title=&#39;\&#39;Welcome\&#39;&#39; 的趋势图, xaxis_title=&#39;Time&#39;, yaxis_title=&#39;Values&#39;)
fig.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78620038/how-can-i-plot-all-csv-files-data-into-one-graph-and-represent-it-in-such-a-way</guid>
      <pubDate>Thu, 13 Jun 2024 20:25:49 GMT</pubDate>
    </item>
    <item>
      <title>在不同的 Python 环境中训练的相同 XGBClassifier 模型得出的预测结果明显不同</title>
      <link>https://stackoverflow.com/questions/78619966/the-same-xgbclassifier-model-trained-in-different-python-environment-made-notice</link>
      <description><![CDATA[我尝试将在旧的 Python 环境中训练的 XGBClassifier 模型转移到新的环境中。
以下是新旧环境中关键软件包的版本信息。
旧环境

python=3.6.0
scikit-learn==0.22.2.post1
xgboost==0.90
pickleshare==0.7.5
numpy==1.18.1

新环境

python=3.11.9
scikit-learn==1.4.2
xgboost==2.0.3
pickleshare==0.7.5
numpy==1.26.4

在新旧环境中分别使用同一组超参数和相同的数据，预测的概率明显不同。
我还注意到，拟合管道对象的大小以及训练模型所需的时间发生了显着变化。
拟合管道对象的大小旧 vs. 新： 30 MB vs. 7 MB
训练时间旧 vs. 新： 4:38:46 vs. 0:06:40
对于我在旧环境中训练的模型和新环境中训练的模型之间的差异，您有什么看法吗？
提前谢谢您！我非常感谢您的帮助！
以下是我用来训练模型的关键 Python 代码。
def create_pipeline(model_params, cat_indices):
&quot;&quot;&quot;
创建管道
:param model_params：管道中 XGBoost 分类器的模型参数
:param cat_indices：X 中分类特征的索引
&quot;&quot;&quot;

cat_transformer = Pipeline(steps=[(&#39;imputer&#39;, SimpleImputer(strategy=&#39;constant&#39;, fill_value=&#39;missing&#39;)),
(&#39;one_hot_encoder&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))])

preprocessor = ColumnTransformer(
transformers=[(&#39;cat&#39;, cat_transformer, cat_indices)],
remainder=&#39;passthrough&#39;)

xgb = XGBClassifier(objective=&quot;binary:logistic&quot;, eval_metric=&quot;auc&quot;, missing=np.nan, use_label_encoder=False)
xgb.set_params(**model_params)

full_pipeline_model = Pipeline(steps=[(&#39;preprocessor&#39;, preprocessor),
(&#39;model&#39;, xgb)])
return full_pipeline_model

model_params = {
&#39;n_estimators&#39;: 500,
&#39;alpha&#39;: 9.73974803929248e-06,
&#39;gamma&#39;: 19,
&#39;lambda&#39;: 0.557185777864069,
&#39;learning_rate&#39;: 0.029438952461179668,
&#39;max_depth&#39;: 13,
&#39;scale_pos_weight&#39;: 5,
&#39;subsample&#39;: 0.687206238714661
}

cat_indices = [X.columns.get_loc(col) for col in cat_cols]

fitted_pipeline = create_pipeline(model_params, cat_indices).fit(X.values, y.values)
pickle.dump(fitted_pipeline, open(&quot;fitted_pipeline_final1.pkl&quot;, &quot;wb&quot;))


我预计从两个模型获得的预测概率非常相似，因为我使用了相同的超参数集和相同的数据。预测概率明显不同的原因可能是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78619966/the-same-xgbclassifier-model-trained-in-different-python-environment-made-notice</guid>
      <pubDate>Thu, 13 Jun 2024 20:07:18 GMT</pubDate>
    </item>
    <item>
      <title>分析 mediapipe 训练姿势的最佳方法是什么，以查看模型是否训练正确</title>
      <link>https://stackoverflow.com/questions/78619772/what-is-the-best-way-to-analyze-mediapipe-trained-poses-to-see-if-the-models-wer</link>
      <description><![CDATA[正如您从问题中读到的那样，我正在寻找分析训练过的鼻子模型的最佳方法。
比如，是否有某种方法可以查看训练过的模型的骨架模式，mediapipe 可以识别训练过的姿势
我尝试打印 npy 文件的值，但我只得到一个非常大的矩阵]]></description>
      <guid>https://stackoverflow.com/questions/78619772/what-is-the-best-way-to-analyze-mediapipe-trained-poses-to-see-if-the-models-wer</guid>
      <pubDate>Thu, 13 Jun 2024 19:14:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 S3 存储桶中的训练数据训练 YOLOv8？</title>
      <link>https://stackoverflow.com/questions/78619753/how-to-train-yolov8-with-traingin-data-in-s3-bucket</link>
      <description><![CDATA[似乎 model.train 需要 data.yml 文件的路径，并且该文件需要有训练和验证集的路径。s3 引用似乎不是实际路径，我看到人们使用数据生成器使用 S3 进行训练。有人知道如何使用 YOLOv8 做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/78619753/how-to-train-yolov8-with-traingin-data-in-s3-bucket</guid>
      <pubDate>Thu, 13 Jun 2024 19:08:12 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 datumaro 合并 comment.xml 和视频以获取仅具有标记图像的 yolo 数据集？</title>
      <link>https://stackoverflow.com/questions/78619747/how-can-i-use-datumaro-to-merge-the-annotations-xml-video-to-get-a-yolo-datase</link>
      <description><![CDATA[我是机器学习领域的新手，我刚刚发现这些
datum project import --format cvat -n cvat1 comments.xml
datum project import --format video_frames -n vid1 video.mp4

我发现https://github.com/cvat-ai/cvat/issues/1251这个
datum project export -e &#39;/item/annotation&#39; --filter-mode &#39;i+a&#39; -f --save-images &lt; your_target_format &gt; --

但我不知道如何实现这一点

https://openvinotoolkit.github.io/datumaro/latest/docs/data-formats/formats/yolo_ultralytics.html

为什么

cvat 在 docker 中运行，比主机 (macOS) 慢
cvat 导出帧很慢，每次导出图像都需要准备所有帧，即使是一点点标签更改
我希望我可以使用 annotations.xml+video/frames 来获得更快的导出
我希望我可以使用 jpg 而不是 png - MP4 视频，jpg 较好，png 很大。
]]></description>
      <guid>https://stackoverflow.com/questions/78619747/how-can-i-use-datumaro-to-merge-the-annotations-xml-video-to-get-a-yolo-datase</guid>
      <pubDate>Thu, 13 Jun 2024 19:07:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 detector2 区分灰度图像中的两种颜色并掩盖它们？</title>
      <link>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</link>
      <description><![CDATA[我刚开始使用detectron2，我计划将它用于一个项目。该项目包括使用该模型区分灰度图像中的对象。该图像由形状奇怪的灰色单元格组成，而其余空间为黑色。我的任务是使用该模型并描绘出灰色单元格的形状。
示例图像：
单元格的灰度图像
我曾尝试使用预先存在的模型来解决这个问题，但它们无法识别出物体的存在。解决这个问题的最佳方法是什么？
此外，我愿意使用不同的机器学习模型。我只是想找到一种区分灰色和黑色的方法。
提前非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78619402/how-would-you-use-detectron2-to-distinguish-between-two-colors-in-a-grayscale-im</guid>
      <pubDate>Thu, 13 Jun 2024 17:36:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习视觉模型以 95% 的准确率预测新数据相同的标签</title>
      <link>https://stackoverflow.com/questions/78619195/machine-learning-visual-model-with-95-accuracy-predicts-new-data-the-same-label</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78619195/machine-learning-visual-model-with-95-accuracy-predicts-new-data-the-same-label</guid>
      <pubDate>Thu, 13 Jun 2024 16:45:35 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：X 有 2 个特征，但 StandardScaler 需要 3 个特征作为输入</title>
      <link>https://stackoverflow.com/questions/78619143/valueerror-x-has-2-features-but-standardscaler-is-expecting-3-features-as-inpu</link>
      <description><![CDATA[我的代码中出现此错误“
ValueError：X 有 2 个特征，但 StandardScaler 需要 3 个特征作为输入。”
我正在使用神经网络训练我的模型以预测 RSC（雷达截面）的幅度。]]></description>
      <guid>https://stackoverflow.com/questions/78619143/valueerror-x-has-2-features-but-standardscaler-is-expecting-3-features-as-inpu</guid>
      <pubDate>Thu, 13 Jun 2024 16:31:11 GMT</pubDate>
    </item>
    <item>
      <title>不一致的否定 [关闭]</title>
      <link>https://stackoverflow.com/questions/78619130/inconsistent-nos</link>
      <description><![CDATA[`
#表示发现样本 [154,53] 的编号不一致
#这是来自 kaggle 的糖尿病预测模型
x_train,x_test,y_train_test=train_test_split(x, y, test_size=0.2`,random_state=42)在此处输入图片描述
我尝试更改随机状态值，但仍然出现相同的错误，如果有人知道如何解决它。请在 3 天内尽快完成。]]></description>
      <guid>https://stackoverflow.com/questions/78619130/inconsistent-nos</guid>
      <pubDate>Thu, 13 Jun 2024 16:28:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用多个 AMD GPU 运行 Ollama [关闭]</title>
      <link>https://stackoverflow.com/questions/78618964/how-to-run-ollama-with-multiple-amd-gpus</link>
      <description><![CDATA[问题：
我尝试在配备多个 AMD GPU 的系统上运行 Ollama，但在正确使用所有 GPU 时遇到了困难。
设置详细信息：

操作系统：RedHat
GPU：MI210 x 4
Ollama 版本：0.1.42
ROCm

面临的问题：

似乎只使用了一个 GPU，或者没有明显的性能改进。
[watch -n 0.1 /opt/rocm/bin/rocm-smi]
0 2 0x740f，30145 63.0°C 253.0W N/A，N/A，0 1700Mhz 1600Mhz 0% 自动 300.0W 60% 100%
1 3 0x740f，41677 28.0°C 41.0W N/A，N/A，0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%
2 4 0x740f，39309 31.0°C 40.0W N/A，N/A，0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%
3 5 0x740f, 50825 35.0°C 40.0W N/A, N/A, 0 800Mhz 1600Mhz 0% 自动 300.0W 0% 0%

问题：

我是否缺少在 Ollama 中启用多 GPU 支持的具体步骤？
Ollama 中是否需要任何其他配置设置才能进行多 GPU 设置？

如能提供任何指导或详细步骤以正确设置和验证 Ollama 是否使用多个 AMD GPU，我们将不胜感激！
提前致谢！
我尝试过 /set 参数 num_gpu 12，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/78618964/how-to-run-ollama-with-multiple-amd-gpus</guid>
      <pubDate>Thu, 13 Jun 2024 15:56:57 GMT</pubDate>
    </item>
    <item>
      <title>尝试将 Kaggle 笔记本提交到 GitHub 存储库时出错？如何解决此问题</title>
      <link>https://stackoverflow.com/questions/78618684/getting-error-while-trying-to-commit-a-kaggle-notebook-to-a-github-repository-h</link>
      <description><![CDATA[提交内核时发生错误：ConcurrencyViolation 序列号必须匹配草稿记录：KernelId=59714315、ExpectedSequence=43、ActualSequence=42、AuthorUserId=16388128（这是什么意思）
当我尝试将笔记本从 kaggle 提交到 github 时出现此错误。我该如何解决这个问题？
我原本以为它会直接提交到 github 而不会遇到任何问题]]></description>
      <guid>https://stackoverflow.com/questions/78618684/getting-error-while-trying-to-commit-a-kaggle-notebook-to-a-github-repository-h</guid>
      <pubDate>Thu, 13 Jun 2024 15:06:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Kotlin 上的移动应用程序中使用 imshow()？</title>
      <link>https://stackoverflow.com/questions/78617059/how-to-use-imshow-in-mobile-app-on-kotlin</link>
      <description><![CDATA[我决定创建一个检测物体的计算机视觉模型。它从相机获取实时图像并显示检测到的物体的矩形。但我不知道如何可视化 OpenCV imshow() 函数。
我的模型使用 Yolov8，我尝试将其转换为 tflite，但 Tensorflow 已更新，因此目前无法实现。因此，在移动应用上部署模型的一种方法是将结果发送到屏幕上。但我不知道 Kotlin，对我来说这太难了]]></description>
      <guid>https://stackoverflow.com/questions/78617059/how-to-use-imshow-in-mobile-app-on-kotlin</guid>
      <pubDate>Thu, 13 Jun 2024 09:38:51 GMT</pubDate>
    </item>
    <item>
      <title>搜索具有相似文本的文档</title>
      <link>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</link>
      <description><![CDATA[我有一个包含三个属性的文档：标签、位置和文本。
目前，我正在使用 LangChain/pgvector/embeddings 对它们全部进行索引。
我得到了满意的结果，但我想知道是否有更好的方法，因为我想查找一个或多个具有特定标签和位置的文档，但文本可能会有很大差异，但含义仍然相同。出于这个原因，我考虑使用嵌入/向量数据库。
这是否也是使用 RAG（检索增强生成）来“教”的一个例子LLM 不知道的一些常见缩写？
import pandas as pd

from langchain_core.documents import Document
from langchain_postgres import PGVector
from langchain_postgres.vectorstores import PGVector
from langchain_openai.embeddings import OpenAIEmbeddings

connection = &quot;postgresql+psycopg://langchain:langchain@localhost:5432/langchain&quot;
embeddings = OpenAIEmbeddings(model=&quot;text-embedding-3-small&quot;)
collection_name = &quot;notas_v0&quot;

vectorstore = PGVector(
embeddings=embeddings,
collection_name=collection_name,
connection=connection,
use_jsonb=True,
)

# 开始索引

# df = pd.read_csv(&quot;notes.csv&quot;)
# df = df.dropna() # .head(10000)
# df[&quot;tags&quot;] = df[&quot;tags&quot;].apply(
# lambda x: [tag.strip() for tag in x.split(&quot;,&quot;) if tag.strip()]
# )

# long_texts = df[&quot;Texto Longo&quot;].tolist()
# wc = df[&quot;Centro Trabalho Responsável&quot;].tolist()
# notes = df[&quot;Nota&quot;].tolist()
# tags = df[&quot;tags&quot;].tolist()

# documents = list(
# map(
# lambda x: Document(
# page_content=x[0], metadata={&quot;wc&quot;: x[1], &quot;note&quot;: x[2], &quot;tags&quot;: x[3]}
# ),
# zip(long_texts, wc, notes, tags),
# )
# )

# print(
# [
# vectorstore.add_documents(documents=documents[i : i + 100])
# for i in range(0, len(documents), 100)
# ]
# )
# print(&quot;Done.&quot;)

### END INDEX

### BEGIN QUERY

result = vectorstore.similarity_search_with_relevance_scores(
&quot;EVTD202301222707&quot;,
filter={&quot;note&quot;: {&quot;$in&quot;: [&quot;15310116&quot;]}, &quot;tags&quot;: {&quot;$in&quot;: [&quot;abcd&quot;, &quot;xyz&quot;]}},
k=10, # 结果限制
)

### END QUERY
]]></description>
      <guid>https://stackoverflow.com/questions/78599128/search-for-documents-with-similar-texts</guid>
      <pubDate>Sun, 09 Jun 2024 16:40:32 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 将特征重要性作为列表而不是绘图</title>
      <link>https://stackoverflow.com/questions/63060367/xgboost-get-feature-importance-as-a-list-of-columns-instead-of-plot</link>
      <description><![CDATA[我想知道是否可以将特征重要性作为列表而不是图表来获取。这就是我所拥有的
xg_reg = xgb.train(params=params, dtrain=data_dmatrix, num_boost_round=10)
import matplotlib.pyplot as plt

xgb.plot_importance(xg_reg)
plt.rcParams[&#39;figure.figsize&#39;] = [5,5]
plt.show()

这给了我这个图

我想只获取主要特征的列表，因为我有超过 800 个不同的特征。]]></description>
      <guid>https://stackoverflow.com/questions/63060367/xgboost-get-feature-importance-as-a-list-of-columns-instead-of-plot</guid>
      <pubDate>Thu, 23 Jul 2020 17:57:31 GMT</pubDate>
    </item>
    </channel>
</rss>