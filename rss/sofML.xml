<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 16 Jun 2024 09:16:47 GMT</lastBuildDate>
    <item>
      <title>向 TensorFlow 模型添加一个热门特征</title>
      <link>https://stackoverflow.com/questions/78628433/add-one-hot-feature-to-tensorflow-model</link>
      <description><![CDATA[我是深度学习的新手，我正在使用 init 函数逐步创建 MMOE 模型并添加功能。
class TIGMMOE(tfrs.Model):
def __init__(self, use_cross_layer, deep_layer_sizes, num_units, num_shared_experts, project_dim=None):
super().__init__()

self.embedding_dimension = 8

self._embeddings = {}

#categorical embedding（所有任务通用）
self._embeddings[&#39;category&#39;] = tf.keras.Sequential(
[tf.keras.layers.Embedding(num_total_pcats + 1, 32)
],name=&#39;cat_emb&#39;)

self._embeddings[&#39;ptype&#39;] = tf.keras.Sequential(
[tf.keras.layers.Embedding(num_total_ptypes + 1, 128)
],name=&#39;ptype_emb&#39;)

.
.
.
def call(self, feat_inputs):
features = feat_inputs
anchor_embeddings = []

for feat_name in _CONTEXT_FEATURE_KEYS:
anchor_embeddings.append(features[feat_name])

anchor_embeddings.append(self._embeddings[&#39;category&#39;](features[&#39;anc_pcat_map&#39;]))
anchor_embeddings.append(self._embeddings[&#39;ptype&#39;](features[&#39;anc_ptcode_map&#39;]))

anchor_embeddings = {}
anchor_embeddings[&#39;anc_feat_vec&#39;] = features[&#39;anc_feat_vec&#39;]
anchor_embeddings[&#39;anc_ptcode_map_emb&#39;] = self._embeddings[&#39;category&#39;](features[&#39;anc_pcat_map&#39;])
anchor_embeddings[&#39;anc_pcat_map_emb&#39;] = self._embeddings[&#39;ptype&#39;](features[&#39;anc_ptcode_map&#39;])


现在我想向模型添加另一个特征 x，该特征为 int 格式，我想将其添加为 one-hot-encode 特征。有人能告诉我如何将这个特征从 tfrecords 添加到我的模型中吗？]]></description>
      <guid>https://stackoverflow.com/questions/78628433/add-one-hot-feature-to-tensorflow-model</guid>
      <pubDate>Sun, 16 Jun 2024 06:33:12 GMT</pubDate>
    </item>
    <item>
      <title>在 AWS Sagemaker 中训练线性模型时出现 UnexpectedStatusException？</title>
      <link>https://stackoverflow.com/questions/78628328/getting-unexpectedstatusexception-while-training-linear-model-in-aws-sagemaker</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78628328/getting-unexpectedstatusexception-while-training-linear-model-in-aws-sagemaker</guid>
      <pubDate>Sun, 16 Jun 2024 05:27:48 GMT</pubDate>
    </item>
    <item>
      <title>潜在扩散 - Unet：除维度 1 外，张量的大小必须匹配</title>
      <link>https://stackoverflow.com/questions/78628262/latent-diffusion-unet-sizes-of-tensors-must-match-except-in-dimension-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78628262/latent-diffusion-unet-sizes-of-tensors-must-match-except-in-dimension-1</guid>
      <pubDate>Sun, 16 Jun 2024 04:27:29 GMT</pubDate>
    </item>
    <item>
      <title>如何对通过 HTTP 传递到/从远程 ONNX 模型的数据进行编码？</title>
      <link>https://stackoverflow.com/questions/78628055/how-to-encode-data-passed-to-from-remote-onnx-models-via-http</link>
      <description><![CDATA[假设我们有一个远程 ONNX ML 模型（在 onnxruntime 上运行），并且我们想通过 REST API 公开它以进行预测。
如何正确编码 HTTP 消息中传递的输入/输出？
由于 onnxruntime 具有不同的类型（主要使用张量、映射和序列），我想知道是否有统一的方法来实现。JSON？Protobuf？其他格式？我是否要为不同的 OrtValues 编写自己的编码器/解码器？
可能的情况：
输入：
N 张量
输出：
N 个预测标签的张量，以及每个标签的概率映射序列
问题与语言无关。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78628055/how-to-encode-data-passed-to-from-remote-onnx-models-via-http</guid>
      <pubDate>Sun, 16 Jun 2024 01:03:08 GMT</pubDate>
    </item>
    <item>
      <title>Chromadb EOFError：输入不足</title>
      <link>https://stackoverflow.com/questions/78627304/chromadb-eoferror-ran-out-of-input</link>
      <description><![CDATA[我正在使用 chromadb 来保存我的向量嵌入。
过去几个月，数据库更新得很好。我突然收到以下错误：
EOFError：输入不足

以下代码是导致问题的代码。
collection.add(
documents=docs,
metadatas=metadatas,
ids=ids,
)

我不确定从哪里开始调试和修复这个问题。
完整错误如下：
文件“/var/www/panoraapp.com/public_html/api/genius/search_embeddings.py”，第 237 行，在 save_to_chroma 中
collection.add(
文件“/usr/local/lib/python3.10/dist-packages/chromadb/api/models/Collection.py”，第 168 行，在 add 中
self._client._add(ids, self.id、嵌入、元数据、文档、uris)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/rate_limiting/__init__.py&quot;，第 45 行，在包装器中
return f(self, *args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/api/segment.py&quot;，第 372 行，在 _add 中
self._manager.hint_use_collection(collection_id, t.Operation.ADD)
文件&quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 230 行，在 hint_use_collection 中
instance = self.get_segment(collection_id, type)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件&quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 217 行，在 get_segment 中
instance = self._instance(segment)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 246 行，在 _instance 中
instance = cls(self._system,segment)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/vector/local_persistent_hnsw.py&quot;，第 107 行，在 __init__ 中
self._persist_data = PersistentData.load_from_file(
文件“/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/vector/local_persistent_hnsw.py”，第 70 行，位于 load_from_file
]]></description>
      <guid>https://stackoverflow.com/questions/78627304/chromadb-eoferror-ran-out-of-input</guid>
      <pubDate>Sat, 15 Jun 2024 17:25:34 GMT</pubDate>
    </item>
    <item>
      <title>Keras 的 one_hot 对不同的词产生相同的值</title>
      <link>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</link>
      <description><![CDATA[我使用 keras 的 one_hot 函数将单词转换为数字。但出于某种原因，它会为不同的单词生成相同的数字。在下面的代码中，您可以看到 48 用于“amazing”，但 48 也用于“too”。这是为什么？
from tensorflow.keras.preprocessing.text import one_hot

reviews = [&#39;nice food&#39;,
&#39;amazing restaurant&#39;,
&#39;too good&#39;,
&#39;just loved it!&#39;,
&#39;will go again&#39;,
&#39;horrible food&#39;,
&#39;never go there&#39;,
&#39;poor service&#39;,
&#39;poor quality&#39;,
&#39;needs Improvement&#39;]

# 转换为 ont hot 向量 
encoded_reviews = [one_hot(d, vocab_size) for d in reviews]

当我打印coded_reviews时，它显示：
[[13, 12],
[48, 44],
[48, 19],
[38, 28, 46],
[13, 29, 19],
[46, 12],
[19, 29, 4],
[18, 38],
[18, 35],
[42, 7]]
]]></description>
      <guid>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</guid>
      <pubDate>Sat, 15 Jun 2024 15:16:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“ValueError：找到具有 0 个样本的数组（shape=(0, 5)），而 LinearRegression 至少需要 1 个。”</title>
      <link>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</guid>
      <pubDate>Sat, 15 Jun 2024 10:53:01 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层 Sequenced_4 从未被调用，因此没有定义的输出</title>
      <link>https://stackoverflow.com/questions/78626027/valueerror-the-layer-sequential-4-has-never-been-called-and-thus-has-no-defined</link>
      <description><![CDATA[我尝试在 Grad cam 实现中使用它，但它显示这个错误。在下面我的 CNN 模型中-
import tensorflow as tf
from tensorflow.keras import layer

model = tf.keras.Sequential()

model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, input_shape=(128,128,3), name=&#39;conv1&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool1&#39;))

model.add(layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, name=&#39;conv2&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool2&#39;))

model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, name=&#39;conv3&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool3&#39;))

model.add(layers.Flatten(name=&#39;flatten&#39;))
model.add(layers.Dense(256,activation=&#39;relu&#39;, name=&#39;dense1&#39;))
model.add(layers.Dense(2,activation=tf.nn.sigmoid, name=&#39;dense2&#39;))

ValueError: 层 Sequenced_4 从未被调用，因此没有定义的输出。]]></description>
      <guid>https://stackoverflow.com/questions/78626027/valueerror-the-layer-sequential-4-has-never-been-called-and-thus-has-no-defined</guid>
      <pubDate>Sat, 15 Jun 2024 08:21:56 GMT</pubDate>
    </item>
    <item>
      <title>用于分割的视觉变换器[关闭]</title>
      <link>https://stackoverflow.com/questions/78625015/vision-transformer-for-segmentation</link>
      <description><![CDATA[我正在使用视觉转换器 (ViT) 进行图像分割，但我不确定要使用哪个分割头。
我知道我需要一个视觉转换器作为我的主干，以及一个分割头，以便根据给定输入图像的主干的学习表示生成图像分割。我可以将任何分割头与 ViT 主干一起使用吗，或者某些分割头是否适用于特定的 ViT 主干？
感谢任何可以提供一些见解的人！]]></description>
      <guid>https://stackoverflow.com/questions/78625015/vision-transformer-for-segmentation</guid>
      <pubDate>Fri, 14 Jun 2024 21:18:56 GMT</pubDate>
    </item>
    <item>
      <title>模型不适用于多类分割</title>
      <link>https://stackoverflow.com/questions/78624691/model-not-working-for-multiclass-segmentation</link>
      <description><![CDATA[我正在训练一个用于多类分割问题的模型。我有 3 个类，图像大小为 512x512 和 1 个通道。我的数据集中的类别不平衡。问题是该模型在多类分割方面表现不佳。
我尝试过交叉熵损失、Dice 损失、Jaccard 损失和损失组合（Jaccard + Focal）。
交叉熵工作正常，但结果并不令人满意。
我应该在其中进行哪些更改？
以下是模型的代码
class AxialDW(nn.Module):
def __init__(self, dim, mixer_kernel, dilation=1):
super().__init__()
h, w = mixer_kernel
self.dw_h = nn.Conv2d(dim, dim, kernel_size=(h, 1), padding=(max(h // 2, dilation), 0), groups=dim, dilation=dilation)
self.dw_w = nn.Conv2d(dim, dim, kernel_size=(1, w), padding=(0, max(w // 2, dilation)), groups=dim, dilation=dilation)

def forward(self, x):
x = x + self.dw_h(x) + self.dw_w(x)
返回 x

class EncoderBlock(nn.Module):
&quot;&quot;&quot;编码然后下采样&quot;&quot;&quot;

def __init__(self, in_c, out_c, mixer_kernel=(7, 7)):
super().__init__()
self.dw = AxialDW(in_c, mixer_kernel=(7, 7))
self.bn = nn.BatchNorm2d(in_c)
self.pw = nn.Conv2d(in_c, out_c, kernel_size=1)
self.down = nn.MaxPool2d((2, 2))
self.act = nn.GELU()

def forward(self, x):
skip = self.bn(self.dw(x))
x = self.act(self.down(self.pw(skip)))
return x, skip

class DecoderBlock(nn.Module):
&quot;&quot;&quot;上采样然后解码&quot;&quot;&quot;

def __init__(self, in_c, out_c, mixer_kernel=(7, 7)):
super().__init__()
self.up = nn.Upsample(scale_factor=2)
self.pw = nn.Conv2d(in_c + out_c, out_c, kernel_size=1)
self.bn = nn.BatchNorm2d(out_c)
self.dw = AxialDW(out_c, mixer_kernel=(7, 7))
self.act = nn.GELU()
self.pw2 = nn.Conv2d(out_c, out_c, kernel_size=1)

def forward(self, x, skip):
x = self.up(x)
x = torch.cat([x, skip], dim=1)
x = self.act(self.pw2(self.dw(self.bn(self.pw(x)))))
return x

class BottleNeckBlock(nn.Module):
&quot;&quot;&quot;轴向扩张 DW 卷积&quot;&quot;&quot;

def __init__(self, dim):
super().__init__()

gc = dim // 4
self.pw1 = nn.Conv2d(dim, gc, kernel_size=1)
self.dw1 = AxialDW(gc, mixer_kernel=(3, 3), dilation=1)
self.dw2 = AxialDW(gc, mixer_kernel=(3, 3), dilation=2)
self.dw3 = AxialDW(gc, mixer_kernel=(3, 3), dilation=3)

self.bn = nn.BatchNorm2d(4 * gc)
self.pw2 = nn.Conv2d(4 * gc, dim, kernel_size=1)
self.act = nn.GELU()

def forward(self, x):
x = self.pw1(x)
x = torch.cat([x, self.dw1(x), self.dw2(x), self.dw3(x)], 1)
x = self.act(self.pw2(self.bn(x)))
return x

class ULite(nn.Module):
def __init__(self, freeze_model, num_classes=3):
super().__init__()

&quot;&quot;&quot;Encoder&quot;&quot;&quot;
self.conv_in = nn.Conv2d(1, 16, kernel_size=7, padding=3)
self.e1 = EncoderBlock(16, 32)
self.e2 = EncoderBlock(32, 64)
self.e3 = EncoderBlock(64, 128)
self.e4 = EncoderBlock(128, 256)
self.e5 = EncoderBlock(256, 512)

“瓶颈”
self.b5 = BottleNeckBlock(512)

“解码器”
self.d5 = DecoderBlock(512, 256)
self.d4 = DecoderBlock(256, 128)
self.d3 = DecoderBlock(128, 64)
self.d2 = DecoderBlock(64, 32)
self.d1 = DecoderBlock(32, 16)
self.conv_out = nn.Conv2d(16, num_classes, kernel_size=1)

if freeze_model:
self.freeze_model()

def forward(self, x):
&quot;&quot;&quot;编码器&quot;&quot;&quot;
x = self.conv_in(x)
x, skip1 = self.e1(x)
x, skip2 = self.e2(x)
x, skip3 = self.e3(x)
x, skip4 = self.e4(x)
x, skip5 = self.e5(x)

“瓶颈” “” “”
x = self.b5(x) # (512, 8, 8)

“解码器” “” “”
x = self.d5(x, skip5)
x = self.d4(x, skip4)
x = self.d3(x, skip3)
x = self.d2(x, skip2)
x = self.d1(x, skip1)
x = self.conv_out(x)

# 应用 softmax 进行多类分类
x = F.softmax(x, dim=1)
return x

def freeze_model(self):
for name, param in self.named_pa​​rameters():
param.requires_grad = False

Jaccard + Focal Loss
Loss Image
Jaccard Loss
丢失图片]]></description>
      <guid>https://stackoverflow.com/questions/78624691/model-not-working-for-multiclass-segmentation</guid>
      <pubDate>Fri, 14 Jun 2024 19:30:25 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 中的 Essentia 模型无法预测</title>
      <link>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</link>
      <description><![CDATA[我正在尝试使用 Essentia discogs_track_embeddings-effnet-bs64 模型和 ML.NET 进行预测。我尝试过使用 tensorflow 和 onnx，但当我尝试预测任何东西时，我都遇到了问题
抛出异常：Microsoft.ML.Data.dll 中的“System.InvalidOperationException”
Microsoft.ML.Data.dll 中发生了未处理的“System.InvalidOperationException”类型的异常
Splitter/consolidator 工作程序在使用源数据时遇到异常

目前，我正在使用 onnx，因此其余部分将是该尝试的堆栈跟踪和代码。
完整调用堆栈：
 在 Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)
在 Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()
在 Microsoft.ML.Data.RootCursorBase.MoveNext()
在Microsoft.ML.Data.ColumnCursorExtensions.&lt;GetColumnArrayDirect&gt;d__4`1.MoveNext()
在 System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)
在 System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)
在 Program.&lt;Main&gt;$(String[] args) 中 Program.cs:line 122

在行上：var embeddingColumn = perceivedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
onnx 加载和预测代码：
Console.WriteLine($&quot;[+] Loading Model&quot;);
var mlContext = new MLContext();

// 将 melspectrogram 数据加载到管道中
var modelPath = &quot;discogs_track_embeddings-effnet-bs64-1.onnx&quot;;
var pipeline = mlContext.Transforms.ApplyOnnxModel(
modelFile: modelPath,
fallbackToCpu: true
);
IDataView mockData = mlContext.Data.LoadFromEnumerable(new List&lt;ModelInput&gt;() { new ModelInput() });
var model = pipeline.Fit(mockData);

var schema = model.Transform(mockData).Schema;
Console.WriteLine(&quot;[*] Model Schema:&quot;);
foreach (var column in schema)
{
Console.WriteLine($&quot;Column Name: {column.Name}, Column Type: {column.Type}&quot;);
}

List&lt;ModelOutput&gt; allPredictions = new List&lt;ModelOutput&gt;();

foreach (var fragment in melSpectrogram)
{
var seg = MelSpectrogramGenerator.ConvertToFloat(segment);

var data = new ModelInput
{
Melspectrogram = seg
};
IDataView dataView = mlContext.Data.LoadFromEnumerable(new [] { data });
var formedData = model.Transform(dataView);

// 检索嵌入
var embeddingColumn = formedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
foreach (var value in embeddingColumn.First())
{
Console.Write($&quot;{value} &quot;);
}
//allPredictions.Add(scoredData.);
Console.WriteLine(&quot;Wheee&quot;);
}

public class ModelInput
{
[VectorType(64, 128, 96)]
[ColumnName(&quot;melspectrogram&quot;)]
public float[,,] Melspectrogram { get; set; }
public ModelInput()
{
Melspectrogram = new float[64, 128, 96];
}
}

// 定义输出模式
public class ModelOutput
{
[VectorType(64, 512)]
[ColumnName(&quot;embeddings&quot;)]
public float[,] Embeddings { get; set; }
public ModelOutput()
{
Embeddings = new float[64, 512];
}
}

目前在 Microsoft.ML 3.0.1、Microsoft.ML.OnnxRuntime.Managed 1.18.0 上
我已检查，我的数据中没有 NaN，并且我的变量都不是 Null。我非常迷茫，不确定如何修复此问题，甚至不知道如何继续进行故障排除。]]></description>
      <guid>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</guid>
      <pubDate>Fri, 14 Jun 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>防止自定义 BiLSTM 模型中的过度拟合[关闭]</title>
      <link>https://stackoverflow.com/questions/78612882/prevent-overfitting-in-custom-bilstm-model</link>
      <description><![CDATA[我必须预测乌尔都语文本中的积极、中性和消极情绪。它有 30k 个样本
样本数据集
训练样本 = 24k，而验证样本 = 6k
我正在使用 bilstm 训练模型，但训练准确率正在提高，而验证却停滞不前。我尝试过更改 - 1. 批量大小从 (2 到 256)
2. 学习率从 0.1 到 1e-11
3. 优化器；我使用过 Adam、SGD、RMSProp 和 Adadelta。
4.使用 word2vec 进行可训练和不可训练的嵌入，
5. 将数据以不同的比例分为训练和验证。
6. 更改层数和单元数。
7.已实施正则化。
但未观察到任何改进。
import keras.backend as K
def get_f1(y_true, y_pred): #取自旧 keras 源代码
true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
precision = true_positives / (predicted_positives + K.epsilon())
recall = true_positives / (possible_positives + K.epsilon())
f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())
return f1_val

def bilstm(embedding_layer):
#定义神经网络
model = Sequential()
model.add(embedding_layer)
model.add(Bidirectional(LSTM(units=128, return_sequences = True)))
model.add(Bidirectional(LSTM(units=64)))
model.add(Dense(3,activation=&#39;softmax&#39;))
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[get_f1,&#39;accuracy&#39;])
return model

model = bilstm(embedding_layer)

learning_rate_reduction = ReduceLROnPlateau(monitor=&#39;val_accuracy&#39;,patience = 2,verbose=1,factor=0.5,min_lr=0.00001)
model.fit(train_seq,train_label, epochs=10, batch_size=8, validation_data=(val_seq, val_label))

Epoch 1
1511/1511 [==============================] - 601s 393ms/step - 损失：1.0787 - get_f1：0.0626 - 准确度：0.3957 - val_loss：1.0402 - val_get_f1：0.1804 - val_accuracy：0.4514
Epoch 2
1511/1511 [===============================] - 615s 407ms/step - 损失：0.7377 - get_f1：0.6348 - 准确度：0.6760 - val_loss：1.1938 - val_get_f1：0.3784 - val_accuracy：0.4509
Epoch 3
1511/1511 [==============================] - 608s 402ms/步 - 损失：0.3419 - get_f1：0.8503 - 准确度：0.8559 - val_loss：1.5797 - val_get_f1：0.4148 - val_accuracy：0.4448
Epoch 4
1511/1511 [===============================] - 612s 405ms/步- 损失：0.2141 - get_f1：0.9074 - 准确度：0.9084 - val_loss：2.2244 - val_get_f1：0.4319 - val_accuracy：0.4459
Epoch 5
1511/1511 [==============================] - 609s 403ms/step - 损失：0.1548 - get_f1：0.9357 - 准确度：0.9368 - val_loss：2.5604 - val_get_f1：0.4302 - val_accuracy：0.4391

]]></description>
      <guid>https://stackoverflow.com/questions/78612882/prevent-overfitting-in-custom-bilstm-model</guid>
      <pubDate>Wed, 12 Jun 2024 13:09:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 BARTDecoder 和 cached_property 的 Nougat OCR 中的 ImportError 和 TypeError 问题</title>
      <link>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</guid>
      <pubDate>Sat, 08 Jun 2024 05:43:48 GMT</pubDate>
    </item>
    <item>
      <title>如何将对象检测数据集转换为 Tensorflow 数据集</title>
      <link>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</link>
      <description><![CDATA[我正在尝试使用 keras 在 tensorflow 上创建一个对象检测模型，但一直遇到困难。我自动​​执行了查找训练图像的边界框的任务（训练数据集是游戏的），然后将所有内容转储到包含与其相关的所有数据的 .csv 文件中：对象出现的帧、边界框的坐标以及对象的类别。即使同一帧上出现多个边界框，每个边界框在数据集上都有不同的行。
我正在尝试使用此函数将我的数据集导入 Tensorflow：
def Data_Loader(annotation_file):
data=pd.read_csv(annotation_file)
data_groups=data.groupby(&#39;filename&#39;)

Dataset={&#39;images&#39;:[], &#39;bounding_boxes&#39;:[]}
ngroups=data_groups.ngroups

for image_name, group in data_groups:

BBoxes={&#39;classes&#39;: [], &#39;boxes&#39;:[]}
for _, row in group.iterrows():
BBoxes[&#39;boxes&#39;].append(Get_BBOX(row))
BBoxes[&#39;classes&#39;].append(class_ids.index(row[&#39;class&#39;]))

Dataset[&#39;bounding_boxes&#39;].append(tf.data.Dataset.from_tensor_slices(BBoxes))
image=load_img(image_name,(224, 224))
Dataset[&#39;images&#39;].append(tf.constant(image))

Dataset=tf.data.Dataset.from_tensor_slices(Dataset)

return(Dataset)


以下是边界框的加载方式：
def Get_BBOX(row):
xmin=int(row[&#39;xmin&#39;])
ymin=int(row[&#39;ymin&#39;])
xmax=int(row[&#39;xmax&#39;])
ymax=int(row[&#39;ymax&#39;])

bbox=np.array([xmin, ymin, xmax, ymax])

return bbox


图像加载如下：
def load_img(filename, target_size):
img = tf.keras.utils.load_img(filename, target_size=target_size) 
img = tf.keras.utils.img_to_array(img) 

return (img)


我正在使用 Keras 的本教程来指导自己
但是每当我到达教程中将地图应用于数据的部分时，我都会收到以下错误消息：
&#39;_VariantDataset&#39; 对象不可下标

有人知道我可能做错了什么吗？如何修复？
我尝试多次进行类型转换，从包含列表的字典更改为字典列表和所有其他类型的东西。但都没有任何结果。]]></description>
      <guid>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</guid>
      <pubDate>Sat, 27 Jan 2024 12:55:36 GMT</pubDate>
    </item>
    <item>
      <title>键错误：'acc' -> acc = history.history['acc']</title>
      <link>https://stackoverflow.com/questions/74016944/keyerror-acc-acc-history-historyacc</link>
      <description><![CDATA[代码链接：https://colab.research.google.com/drive/1_a4PLwDiFhF7qVlX_vvwKM4QM4Dxu0L0?usp=sharing
import matplotlib.pyplot as plt

acc = history.history[&#39;acc&#39;]
val_acc = history.history[&#39;val_accuracy&#39;]
loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]

epochs = range(1, len(acc) + 1)

# &quot;bo&quot; 代表 &quot;blue dot&quot;
plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;训练损失&#39;)
# b 代表“实蓝线”
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;验证损失&#39;)
plt.title(&#39;训练和验证损失&#39;)
plt.xlabel(&#39;Epochs&#39;)
plt.ylabel(&#39;损失&#39;)
plt.legend()

plt.show()

错误显示：
KeyError Traceback（最近一次调用最后一次）

&lt;ipython-input-31-12e4df2349dc&gt; in &lt;module&gt;
1 import matplotlib.pyplot as plt
2 
----&gt; 3 acc = history.history[&#39;acc&#39;]
4 val_acc = history.history[&#39;val_accuracy&#39;]
5 loss = history.history[&#39;loss&#39;]

KeyError: &#39;acc&#39;

嗨，我尝试了深度学习中的这个练习 3.5-classifying-movie-reviews.ipynb，使用 python -manning 并显示错误，有什么帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/74016944/keyerror-acc-acc-history-historyacc</guid>
      <pubDate>Mon, 10 Oct 2022 15:05:25 GMT</pubDate>
    </item>
    </channel>
</rss>