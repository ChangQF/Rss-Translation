<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 01 Dec 2024 01:40:37 GMT</lastBuildDate>
    <item>
      <title>我可以使用该数据集通过机器学习来预测公交车到达时间或延误时间吗？</title>
      <link>https://stackoverflow.com/questions/79239662/can-i-use-this-dataset-to-predict-bus-arrival-time-or-delay-using-machine-learni</link>
      <description><![CDATA[我正在开展一个机器学习项目来预测公交车到达时间。以下是我的数据集中可用字段的完整列表：
可用字段：
RecordedAtTime
DirectionRef
PublishedLineName
OriginName
OriginLat，OriginLong
DestinationName
DestinationLat，DestinationLong
VehicleRef
VehicleLocation.Latitude（当前位置）
VehicleLocation.Longitude（当前位置）
NextStopPointName
ArrivalProximityText
DistanceFromStop
ExpectedArrivalTime
ScheduledArrivalTime
我计划使用的功能：
RecordedAtTime
DirectionRef
PublishedLineName（为简单起见，选择 4-5 条短路线）
OriginLat，OriginLong
DestinationLat，DestinationLong
VehicleLocation.Latitude，VehicleLocation.Longitude（当前位置） location)
NextStopPointName
DistanceFromStop
目标：
我想预测 ExpectedArrivalTime 和 ScheduledArrivalTime 之间的差异。（因为数据集没有到达时间字段）
问题：
我没有明确记录行程的开始或结束时间。
但是，我有 RecordedAtTime（时间戳）和当前车辆位置，我相信可以用作参考。
目标：
预测公交车到达特定站点或沿途任何点的时间。
如果不可行，则预测延迟（ExpectedArrivalTime 和 ScheduledArrivalTime 之间的差异）。
方法：
我计划使用线性回归和随机森林作为该项目的主要模型。
此外：
为了提高预测准确性，我正在考虑将天气数据集成到此数据集中。为此：
我计划使用 VehicleLocation（当前）和 RecordedAtTime 获取相应位置和时间的天气数据（例如温度、降水量）。
我将专注于短途公交路线，以简化流程并确保数据一致性。
数据集：
我使用的数据来自 Kaggle 数据集：纽约市交通统计数据（https://www.kaggle.com/datasets/stoney71/new-york-city-transport-statistics）。

使用此数据集训练机器学习模型来预测到达时间或延误是否可行且有用？

RecordedAtTime 和当前位置是否可以替代明确记录的开始时间？

添加天气数据是否会显著提高模型在短途公交线路上的表现？

考虑到数据？

]]></description>
      <guid>https://stackoverflow.com/questions/79239662/can-i-use-this-dataset-to-predict-bus-arrival-time-or-delay-using-machine-learni</guid>
      <pubDate>Sat, 30 Nov 2024 13:38:13 GMT</pubDate>
    </item>
    <item>
      <title>当训练期间的序列长度与推理期间的序列长度不同时，TransformerEncoder 的性能会更差</title>
      <link>https://stackoverflow.com/questions/79239577/transformerencoder-give-worse-performance-when-the-sequence-length-during-traini</link>
      <description><![CDATA[给定（此 600 将用于推理）：

X_infer 张量，形状为 (num_window, window_len) -&gt; (1, 600)
y_infer 张量，形状为 (num_window, window_len) -&gt; （1, 600）

词汇大小：

X：128（振幅）
y：5（颜色标签）

从原点执行 sliding_window_view，返回（此 180 将在训练期间使用）：

X_train 张量，形状为 (num_window, window_len) -&gt; (471, 180)
y_train 张量，形状为 (num_window, window_len) -&gt; (471, 180)

训练：
model = instantiate_untrained_model(seq_len=180)
model.fit(X_train, y_train)

保存（仅权重）：
model.save_weights(&#39;trained.weights.h5&#39;)

使用差异 seq_len 进行推断：
# 600
model = instantiate_untrained_model(seq_len=600) # 整个数组
model.load_weights(&#39;trained.weights.h5&#39;) # 无错误
y_pred_600 = model.predict(X_infer)

# 180
model = instantiate_untrained_model(seq_len=180) # 窗口数组
model.load_weights(&#39;trained.weights.h5&#39;)
y_pred_180 = model.predict(X_train)

绘制预测 y_pred_180 及其基本事实：

绘制预测 y_pred_600 及其基本事实：

尽管是信号，但你可以把这个问题看作命名实体识别。
这是 keras 模型：
 SEQ_LEN=seq_len
VOCAB_SIZE=128
EMBEDD_DIM=128

coder_inputs = Input(shape=(SEQ_LEN,), name=&quot;encoder_inputs&quot;, dtype=np.uint8)
token_embeddings = Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDD_DIM)(encoder_inputs)
position_encodings = SinePositionEncoding()(token_embeddings)

# this行将嵌入相加并解决问题
embeddings = token_embeddings + position_encodings

coder_outputs = TransformerEncoder(intermediate_dim=EMBEDD_DIM*4, num_heads=2, dropout=0.05)(inputs=embeddings)

# 词汇量为 5 的输出层
output_predictions = Dense(units=5,activation=None)(encoder_outputs)

# 最终模型
model = Model(encoder_inputs, output_predictions, name=&quot;transformer_encoder&quot;)

我期望在推理过程中，Transformer 模型可以接受任意序列长度并获得良好的性能？
为什么会发生这种情况？是否与 SinePositionEncoding 或其他东西有关？该模型不够灵活，不够稳健，只有在序列长度为 180 时才有良好的表现，而不是任意长度？我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79239577/transformerencoder-give-worse-performance-when-the-sequence-length-during-traini</guid>
      <pubDate>Sat, 30 Nov 2024 12:51:56 GMT</pubDate>
    </item>
    <item>
      <title>软演员-评论家算法无法解决稍微复杂一点的任务</title>
      <link>https://stackoverflow.com/questions/79239534/soft-actor-critic-algorithm-does-not-manage-to-solve-slightly-more-complicated-t</link>
      <description><![CDATA[我刚开始学习强化学习不久，并尝试自己编写几种算法。我目前的项目是编写 Soft Actor-Critic 算法，然后将其用于 Carla 的自动驾驶。
我的代码设法解决了简单的任务，但当我在 Carla 上尝试时，我仍然表现不佳，尽管我的奖励基于硕士论文，这些论文表现更好。我的代码中是否存在编程错误或数学错误，它没有学习。如果有人能查看我的代码并提供反馈，那将非常感激。
我的代码在 Github 上，链接如下：Soft-Actor-Critic]]></description>
      <guid>https://stackoverflow.com/questions/79239534/soft-actor-critic-algorithm-does-not-manage-to-solve-slightly-more-complicated-t</guid>
      <pubDate>Sat, 30 Nov 2024 12:25:04 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中实现 Softmax，其中输入是有符号的 8 个整数</title>
      <link>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</link>
      <description><![CDATA[我正在尝试实现一个softmax 函数，该函数接受有符号的 int8 输入并返回有符号的 int8 输出数组。
我目前正在进行的实现是这样的，
 import numpy as np

def softmax_int8(inputs):
input = np.array(inputs, dtype=np.int8)

x = input.astype(np.int32)
x_max = np.max(x)
x_shifted = x - x_max
scale_factor = 2 ** 14
exp_limit = 16
exp_x = np.clip(x_shifted + exp_limit, 0, None)
exp_x = (1 &lt;&lt; exp_x)
sum_exp_x = np.sum(exp_x)

如果 sum_exp_x == 0:
sum_exp_x = 1

softmax_probs = (exp_x * scale_factor) // sum_exp_x
max_prob = np.max(softmax_probs)
min_prob = np.min(softmax_probs)
range_prob = max_prob - min_prob 如果 max_prob != min_prob 否则 1

scaled_probs = ((softmax_probs - min_prob) * 255) // range_prob - 128
output = scaled_probs.astype(np.int8)

返回输出

我使用此输入进行测试，Input = [101, 49, 6, -34, -75, -79, -38, 120, -55, 115]
但我得到此输出 array([-128, -128, -128, -128, -128, -128, -128, 127, -128, -121],dtype=int8)。
我的预期输出是 array([-57, -70, -79, -86, -92, -94, -88, -54, -91, -56], dtype=int8)。
我在这里做错了什么，我该如何修复？]]></description>
      <guid>https://stackoverflow.com/questions/79239232/how-to-implement-softmax-in-python-whereby-the-input-are-signed-8-integers</guid>
      <pubDate>Sat, 30 Nov 2024 09:37:57 GMT</pubDate>
    </item>
    <item>
      <title>使用“TensorFlowLiteSelectTfOps”、“~> 0.0.1-nightly”会导致应用程序体积过大</title>
      <link>https://stackoverflow.com/questions/79238982/large-app-size-for-using-tensorflowliteselecttfops-0-0-1-nightly</link>
      <description><![CDATA[我正在使用 -
&#39;TensorFlowLiteSwift&#39;
&#39;TensorFlowLiteSelectTfOps&#39;, &#39;~&gt; 0.0.1-nightly&#39;
使用 pod 在 iOS 应用中运行我的 Tflite 模型。但是，应用大小非常大，几乎有 202 MB。如果我删除 pod - &#39;TensorFlowLiteSelectTfOps&#39;, &#39;~&gt; 0.0.1-nightly&#39;，则应用程序大小减少到 32 MB。
所以现在我正在尝试构建框架 - TensorFlowLiteSelectTfOps.framework
使用 Python 脚本，我得到我的模型使用以下操作 -
{&#39;MUL&#39;, &#39;FlexRealDiv&#39;, &#39;FLOOR_DIV&#39;, &#39;FILL&#39;, &#39;SPLIT_V&#39;, &#39;DIV&#39;, &#39;TRANSPOSE&#39;, &#39;MAXIMUM&#39;, &#39;EXPAND_DIMS&#39;, &#39;FlexIRFFT&#39;, &#39;MIRROR_PAD&#39;, &#39;DEQUANTIZE&#39;, &#39;CONV_2D&#39;, &#39;SUB&#39;, &#39;FlexStridedSlice&#39;, &#39;TRANSPOSE_CONV&#39;, &#39;GATHER&#39;, &#39;PACK&#39;, &#39;ADD&#39;, &#39;SQRT&#39;, &#39;STRIDED_SLICE&#39;, &#39;CONCATENATION&#39;, &#39;IMAG&#39;, &#39;SPLIT&#39;, &#39;RFFT2D&#39;, &#39;RSQRT&#39;, &#39;BATCH_MATMUL&#39;, &#39;SQUARED_DIFFERENCE&#39;, &#39;SUM&#39;, &#39;SHAPE&#39;, &#39;DELEGATE&#39;, &#39;GELU&#39;, &#39;REAL&#39;, &#39;NEG&#39;, &#39;FULLY_CONNECTED&#39;, &#39;BATCH_TO_SPACE_ND&#39;, &#39;RANGE&#39;, &#39;FlexPad&#39;, &#39;FlexComplex&#39;, &#39;SQUEEZE&#39;, &#39;LOGISTIC&#39;, &#39;FlexTranspose&#39;, &#39;MEAN&#39;, &#39;SPACE_TO_BATCH_ND&#39;, &#39;PAD&#39;, &#39;RESHAPE&#39;, &#39;SOFTMAX&#39;}

我确实使用以下命令构建了框架，但大小没有减小-
bazel build -c opt --config=ios_arm64 \ 
--define=TF_LITE_STATIC_SELECT_TF_OPS=1 \
--define=tflite_with_xnnpack=false \
--copt=-DTF_LITE_STATIC_SELECT_OPS_LIST=&quot;MUL,FlexRealDiv,FLOOR_DIV,FILL,SPLIT_V,DIV,TRANSPOSE,MAXIMUM,EXPAND_DIMS,FlexIRFFT,MIRROR_PAD,DEQUANTIZE,CONV_2D,SUB,FlexStridedSlice,TRANSPOSE_CONV,GATHER,PACK,ADD,SQRT,STRIDED_SLICE,CONCA TENATION、IMAG、SPLIT、RFFT2D、RSQRT、BATCH_MATMUL、SQUARED_DIFFERENCE、SUM、SHAPE、DELEGATE、GELU、REAL、NEG、FULLY_CONNECTED、BATCH_TO_SPACE_ND、RANGE、FlexPad、FlexComplex、SQUEEZE、LOGISTIC、FlexTranspose、MEAN、SPACE_TO_BATCH_ND、PAD、RESHAPE、SOFTMAX&quot; \
//tensorflow/lite/ios:TensorFlowLiteSelectTfOps_framework
]]></description>
      <guid>https://stackoverflow.com/questions/79238982/large-app-size-for-using-tensorflowliteselecttfops-0-0-1-nightly</guid>
      <pubDate>Sat, 30 Nov 2024 07:07:35 GMT</pubDate>
    </item>
    <item>
      <title>回归 - 模型总体看起来不错，但 R2 意外地偏高</title>
      <link>https://stackoverflow.com/questions/79238923/regression-model-looks-good-overall-but-r2-unexpectedly-negatively-high</link>
      <description><![CDATA[我一直在构建一个包含大约 150 行数据的线性回归模型。我检查了参数与目标变量的相关性，并尝试仅保留它们，因为我的数据较少，并且想要一个简单的线性模型。
MAE 和 MAPE 确实足够不错：
训练 MAPE：3.3%，验证 MAPE：4.9%
训练数据和验证数据图看起来也足够不错：

但是，我的：
训练 R2：0.63，验证 R2：-0.37
我搜索了许多资源，询问了 Google Gemini ChatGPT，得到了类似的回复，但我仍然无法弄清楚找出为什么当其他一切看起来都不错时，我的 R2 会变得如此奇怪。我们可以使用此模型在现实世界中实现或推断吗？
请注意：我也尝试过随机森林、LightGBM、XGBoost 和许多其他线性和 bagging/boosting 模型，结果几乎相似。图表看起来不错，MAE、MAPE 看起来不错，但 R2 不在正常范围内。]]></description>
      <guid>https://stackoverflow.com/questions/79238923/regression-model-looks-good-overall-but-r2-unexpectedly-negatively-high</guid>
      <pubDate>Sat, 30 Nov 2024 06:19:51 GMT</pubDate>
    </item>
    <item>
      <title>正在访问非叶张量的张量的 .grad 属性</title>
      <link>https://stackoverflow.com/questions/79238710/grad-attribute-of-a-tensor-that-is-not-a-leaf-tensor-is-being-accessed</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79238710/grad-attribute-of-a-tensor-that-is-not-a-leaf-tensor-is-being-accessed</guid>
      <pubDate>Sat, 30 Nov 2024 02:10:20 GMT</pubDate>
    </item>
    <item>
      <title>如何在拆分后合并 tarin 和测试数据集但每行回到其原始位置或索引</title>
      <link>https://stackoverflow.com/questions/79238631/how-to-merge-tarin-and-test-dataset-after-splitting-but-each-row-back-to-its-ori</link>
      <description><![CDATA[import pandas as pd
import numpy as np
from sklearn.datasets import fetch_openml
# 加载糖尿病数据集 
diabetes = fetch_openml(&quot;diabetes&quot;, version=1, as_frame=True)
diabetes_df = diabetes.data
diabetes_df[&#39;target&#39;] = diabetes.target # 添加目标列

from sklearn.model_selection import train_test_split
# 拆分数据
train, test = train_test_split(diabetes_df, test_size=0.3, random_state=42)

我想合并训练和测试数据集，但与原始数据索引相同。
注意：但在出现一些失误后，我将数据集拆分为训练和测试数据集，并分别估算训练和测试数据集]]></description>
      <guid>https://stackoverflow.com/questions/79238631/how-to-merge-tarin-and-test-dataset-after-splitting-but-each-row-back-to-its-ori</guid>
      <pubDate>Sat, 30 Nov 2024 00:21:23 GMT</pubDate>
    </item>
    <item>
      <title>在 counterfactual-vulnerability-detection 存储库中运行数据预处理脚本时出错</title>
      <link>https://stackoverflow.com/questions/79238608/error-while-running-data-preprocessing-script-in-counterfactual-vulnerability-de</link>
      <description><![CDATA[我想在 CPU 上运行存储库 https://github.com/zahrazarezadeh1999/counterfactual-vulnerability-detection/tree/main 中的代码。
我正在运行一个名为 data_pre.py 的 Python 脚本作为项目的一部分，在处理数据时遇到了多个问题。最初，该脚本尝试访问位于 /home/user20/Desktop/counterfactual-vulnerability-detection-main/cfexplainer/storage/cache/minimal_datasets/minimal_bigvul.pq 的文件，但失败并出现“没有这样的文件或目录”错误。该文件似乎是该过程的关键部分，它的缺失阻止了脚本按预期继续运行。尽管出现了这个错误，但脚本仍继续运行一些操作，并显示数据处理的进度条，但很明显，丢失的文件导致了下游的重大问题。
后来，脚本又抛出了另一个错误，这次与 pandas 中的 DataFrame 操作有关。错误消息指出：ValueError：无法将没有列的 DataFrame 设置为列 mod_prop。似乎由于文件丢失或流程早期的其他问题，预计应该有数据的 DataFrame 要么没有正确加载，要么是空的。这个错误完全停止了脚本的执行，让我无法完成任务。
我使用 GPU 运行代码并遇到了同样的错误。这次，我尝试在 CPU 上运行它，但再次遇到了同样的错误。您建议如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79238608/error-while-running-data-preprocessing-script-in-counterfactual-vulnerability-de</guid>
      <pubDate>Fri, 29 Nov 2024 23:57:50 GMT</pubDate>
    </item>
    <item>
      <title>计算/计算 k 模式的 SSB（簇之间）[关闭]</title>
      <link>https://stackoverflow.com/questions/79238050/computing-calculating-ssb-between-clusters-for-k-modes</link>
      <description><![CDATA[我正在尝试计算用于验证/计算 K 模式性能的指标。我正在做我的论文，我需要根据二元变量（疾病）对患者进行分组
我最近读到 SSW 和 SSB 指标可能合适（https://math.stackexchange.com/questions/1009297/variances-for-k-means-clustering）。我只知道如何从 kmodes 函数中提取 SSW（此处回复了 K-Modes Cluster Validation），但我不知道如何计算 SSB（簇之间）...您能给出一个如何计算它的例子吗？
我试过计算指标，但我不知道如何计算组间方差]]></description>
      <guid>https://stackoverflow.com/questions/79238050/computing-calculating-ssb-between-clusters-for-k-modes</guid>
      <pubDate>Fri, 29 Nov 2024 18:24:49 GMT</pubDate>
    </item>
    <item>
      <title>如何比较不同年份的集群？</title>
      <link>https://stackoverflow.com/questions/79234461/how-to-compare-clusters-from-different-years</link>
      <description><![CDATA[我有多个数据集，所有数据集的组织方式都类似（相同的变量、值等）。我使用 KModes 独立分析了数据集，但是，我试图寻找多年来可能出现的趋势。我该如何比较不同年份的集群？]]></description>
      <guid>https://stackoverflow.com/questions/79234461/how-to-compare-clusters-from-different-years</guid>
      <pubDate>Thu, 28 Nov 2024 15:14:27 GMT</pubDate>
    </item>
    <item>
      <title>ML。如何让神经网络记住 UE/Unity 中的上下文和数据？[关闭]</title>
      <link>https://stackoverflow.com/questions/79233875/ml-how-to-make-a-neural-network-remember-the-context-and-data-in-ue-unity</link>
      <description><![CDATA[我希望神经网络能够记忆，但感知器只能在训练期间记住一些东西，但我希望神经网络能够适应新情况而无需重新训练，例如，如果我说我的名字是尼古拉，它就会记住，或者如果绿色蘑菇以前在游戏中很有用，但后来变得有毒，它就会停止食用，然后，如果它们恢复正常，它就会再次开始食用。我考虑过 LSTM，但这是一个循环神经网络，人们似乎正在放弃它们而选择 transformer？在 UE/Unity 中。]]></description>
      <guid>https://stackoverflow.com/questions/79233875/ml-how-to-make-a-neural-network-remember-the-context-and-data-in-ue-unity</guid>
      <pubDate>Thu, 28 Nov 2024 12:20:41 GMT</pubDate>
    </item>
    <item>
      <title>Python scorecardpy：UnboundLocalError：赋值前引用了局部变量“card_df”</title>
      <link>https://stackoverflow.com/questions/79219306/python-scorecardpy-unboundlocalerror-local-variable-card-df-referenced-befor</link>
      <description><![CDATA[我使用 scorecardpy 函数来获取模型：
import scorecardpy as ac
card=sc.scorecard(bins_adj, lr, X_train.columns)

然后我尝试使用以下代码保存此模型：
import numpy as np
np.save(&#39;card.npy&#39;,card)

之后我尝试重新加载此模型：
card=np.load(&#39;card.npy&#39;,allow_pickle=True)

然后我想使用该模型获取分数：
score=sc.scorecard_ply(data_train, card, print_step=0)

但它给出了错误：
UnboundLocalError Traceback（最近一次调用最后一次）
单元格在 [91]，第 1 行
score=sc.scorecard_ply(data_train, card, print_step=0)

文件 ~/.local/lib/python3.9/site-packages/scorecardpy/scorecard.py:330，在 scorecard_ply(dt, card, only_total_score, print_step, replace_blank_na, var_kp)
card_df=card.copy(deep=True)
# x 变量
xs=card_df.loc[card_df.variable != &#39;basepoints&#39;, &#39;variable&#39;].unique()
# x 变量的长度
xs_len=len(xs)

UnboundLocalError：局部变量“card_df”在赋值前被引用

如何解决此问题有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/79219306/python-scorecardpy-unboundlocalerror-local-variable-card-df-referenced-befor</guid>
      <pubDate>Sun, 24 Nov 2024 04:16:39 GMT</pubDate>
    </item>
    <item>
      <title>在 AdaBoostClassifier 中使用 scikit-learn 的 MLPClassifier</title>
      <link>https://stackoverflow.com/questions/55632010/using-scikit-learns-mlpclassifier-in-adaboostclassifier</link>
      <description><![CDATA[对于二元分类问题，我想使用 MLPClassifier 作为 AdaBoostClassifier 中的基本估计器。但是，这不起作用，因为 MLPClassifier 未实现 AdaBoostClassifier 所需的 sample_weight（请参阅 此处）。在此之前，我尝试在 AdaBoostClassifier 中使用 Keras 模型和 KerasClassifier，但这也不起作用，如 此处 所述。 
用户 V1nc3nt 提出的一种方法是在 TensorFlow 中构建自己的 MLPclassifier 并考虑 sample_weight。
用户 V1nc3nt 分享了他的大部分代码，但由于我对 Tensorflow 的经验有限，我无法填补缺失的部分。因此，我想知道是否有人找到了从 MLP 构建 Adaboost 集合的有效解决方案，或者可以帮助我完成 V1nc3nt 提出的解决方案。
提前非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/55632010/using-scikit-learns-mlpclassifier-in-adaboostclassifier</guid>
      <pubDate>Thu, 11 Apr 2019 12:00:49 GMT</pubDate>
    </item>
    <item>
      <title>grid.py 运行需要多长时间？</title>
      <link>https://stackoverflow.com/questions/2415557/how-much-time-does-grid-py-take-to-run</link>
      <description><![CDATA[我正在使用 libsvm 进行二分类。我想尝试 grid.py ，因为据说它可以改善结果。我在不同的终端中为五个文件运行了这个脚本，该脚本已经运行了 12 多个小时。
这是我的 5 个终端现在的状态：
[root@localhost tools]# python grid.py sarts_nonarts_feat.txt&gt;grid_arts.txt
警告：空 z 范围 [61.3997:61.3997]，正在调整到 [60.7857:62.0137]
第 2 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。
警告：z 范围为空 [61.3997:61.3997]，正在调整至 [60.7857:62.0137]
第 4 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。

[root@localhost tools]# python grid.py sgames_nongames_feat.txt&gt;grid_games.txt
警告：z 范围为空 [64.5867:64.5867]，正在调整至 [63.9408:65.2326]
第 2 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。
警告：z 范围为空 [64.5867:64.5867]，正在调整至 [63.9408:65.2326]
第 4 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。

[root@localhost tools]# python grid.py sref_nonref_feat.txt&gt;grid_ref.txt
警告：z 范围为空 [62.4602:62.4602]，正在调整至 [61.8356:63.0848]
第 2 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。
警告：z 范围为空 [62.4602:62.4602]，正在调整至 [61.8356:63.0848]
第 4 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。

[root@localhost tools]# python grid.py sbiz_nonbiz_feat.txt&gt;grid_biz.txt
警告：z 范围为空 [67.9762:67.9762]，正在调整至 [67.2964:68.656]
第 2 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。
警告：z 范围为空 [67.9762:67.9762]，正在调整至 [67.2964:68.656]
第 4 行：警告：无法勾勒非网格数据的轮廓。请使用“set dgrid3d”。

[root@localhost tools]# python grid.py snews_nonnews_feat.txt&gt;grid_news.txt
第 494 行输入格式错误
回溯（最近一次调用）：
文件“grid.py”，第 223 行，运行中
如果 rate 为 None：引发“get no rate”
TypeError：异常必须是类或实例，而不是 str

我已将输出重定向到文件，但这些文件现在不包含任何内容。此外，还创建了以下文件：

sbiz_nonbiz_feat.txt.out
sbiz_nonbiz_feat.txt.png
sarts_nonarts_feat.txt.out
sarts_nonarts_feat.txt.png
sgames_nongames_feat.txt.out
sgames_nongames_feat.txt.png
sref_nonref_feat.txt.out
sref_nonref_feat.txt.png
snews_nonnews_feat.txt.out（--&gt; 为空）

.out 文件中只有一行信息。“.png”文件是一些 GNU PLOTS。
但我不明白上述 GNUplots/警告传达了什么。我应该重新运行它们吗？
如果每个输入文件包含大约 144000 行，这个脚本可能需要多长时间？]]></description>
      <guid>https://stackoverflow.com/questions/2415557/how-much-time-does-grid-py-take-to-run</guid>
      <pubDate>Wed, 10 Mar 2010 08:59:52 GMT</pubDate>
    </item>
    </channel>
</rss>