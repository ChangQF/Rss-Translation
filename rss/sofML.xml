<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Wed, 05 Mar 2025 06:28:40 GMT</lastBuildDate>
    <item>
      <title>使用layoutlmv3获取文本和令牌</title>
      <link>https://stackoverflow.com/questions/79485430/getting-the-text-and-tokens-using-layoutlmv3</link>
      <description><![CDATA[嗨，我全力以赴使用图像培训模型，我培训了使用Label Studio创建标签数据集的Layoutlmv3模型。我能够使用以下代码测试模型的输出
  encoding =处理器（图像，单词，boxes = box，word_labels = word_labels，return_tensors =＆quort; pt;
对于k，v in encoding.items（）：
  打印（K，V.Shape）
 
并使用以下代码将盒子绘制在PDF上
 导入火炬

使用Torch.no_grad（）：
  输出=模型（**编码）
logits = outputs.logits
logits.shape
打印（输出）


预测= logits.argmax（-1）.squeeze（）。tolist（）
打印（预测）
标签= encoding.labels.squeeze（）。tolist（）
打印（标签）
def unormalize_box（bbox，宽度，高度）：
     返回 [
         宽度 *（bbox [0] / 1000），
         高度 *（bbox [1] / 1000），
         宽度 *（bbox [2] / 1000），
         高度 *（bbox [3] / 1000），
     这是给出的

token_boxes = encoding.bbox.squeeze（）.tolist（）
宽度，高度=图像尺寸

true_predictions = [model.config.id2label [pred] for pred，zip中的标签（预测，标签），如果标签！=  -  100]
true_labels = [model.config.id2label [label]用于预测，在zip中标记（预测，标签），如果标签！= -100]
true_boxes = [unnormalize_box（盒子，宽度，高度），标签在zip中（token_boxes，labels），如果标签！= -100]

打印（编码。值）

 
我要理解的是，该模型放弃的预测只是我必须在框上再次运行teserract以提取文本的边界框，或者将模型用相关标签吐出单词。。]]></description>
      <guid>https://stackoverflow.com/questions/79485430/getting-the-text-and-tokens-using-layoutlmv3</guid>
      <pubDate>Wed, 05 Mar 2025 04:04:14 GMT</pubDate>
    </item>
    <item>
      <title>小数据集的微型骆驼</title>
      <link>https://stackoverflow.com/questions/79485426/fine-tuning-llama-for-small-datasets</link>
      <description><![CDATA[我正在寻求微调美洲驼模型来回答某些问题。当前，必须回答问题的知识库很小，因此我可以作为上下文提供，并要求美洲驼基于上下文回答问题。但是，这个知识基础将继续增长，并且可能会有时间太大。
因此，我一直在寻找通过使用知识库作为数据集来微调Llama指示模型来回答问题。但是，当前数据集仅为25行。想知道目前仅针对25行进行微调是否还可以，还是我应该提供知识库作为上下文。如果是这样，如何适应未来知识基础的增长。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/79485426/fine-tuning-llama-for-small-datasets</guid>
      <pubDate>Wed, 05 Mar 2025 04:00:48 GMT</pubDate>
    </item>
    <item>
      <title>将Yolo分割模型导出到Coreml</title>
      <link>https://stackoverflow.com/questions/79484862/exporting-yolo-segmentation-model-to-coreml</link>
      <description><![CDATA[我要导出这样的模型：
 模型= Yolo（&#39;yolo11m-seg.pt&#39;）
Model.export（格式=; Coreml;）
 
，然后加载到Xcode中。效果很好。这是我进行推理和检查结果的方式：
 守卫让结果：yoloptoutput =尝试？ Model.prediction（图像：InputPixelBuffer）else {return}

/// var_1648为1×116×8400 3维浮标
让classPredictions：mlmultiarray = result.var_1648
让classpredictions形状：mlshapearray＆lt; float＆gt; =结果

让NumanchorBoxes = classPredictions.shape [2] .intvalue // 8400
令numValuesperbox = classpredictions.shape [1] .intvalue // 116
令classCount = 80

//假设前5个值是bbox（4） +对象（1），而接下来的80个是类概率
令class -probabilitiesstartindex = 5

var maxboxprob = -float.infinity
var maxboxindex：int = 0
var maxboxobjectness：float = 0
var BestClassIndex：int = 0

对于boxIndex in 0 ..＆lt; numanchorboxes {
    让ObjectnessLogit = classPredictions形状[0，4，BoxIndex] .scalar ?? 0
    让客观性= sigmoid（objectneslogit）
    
    Guard Absocnessprobability＆gt; 0.51 else {继续}
    
    var classLogits：[float] = []
    对于classIndex in 0 ..＆lt; classCount {
        LET valueIndex = classProbabiLitiessTartexex + classIndex
        令logit = classpredictions形状[0，valueindex，boxIndex] .scalar ?? 0
        classLogits.Append（logit）
    }
    
    Guard！classLogits.isempty else {继续}
    
    //计算SoftMax并获得最佳概率和类索引
    让（BestProb，BestClassix）= SoftMaxWithBestClass（classLogits）
    
    //检查此框是否到目前为止的概率最高
    如果Bestprob＆gt; maxboxprob {
        MaxBoxProb = BestProb
        MaxBoxIndex = BoxIndex
        maxBoxObjectness = objectnessprobability
        BestClassIndex = BestClassix
    }
}

print（$$ -MaxBoxIndex：\（MaxBoxIndex）-MaxBoxProb：\（MaxBoxProb）-BestClassIndex：\（BestClassIndex）-MaxBoxOjectness：\（MaxBoxObject）＆quot;）
 
这是我计算SoftMax和Sigmoid的方式：
  func softmaxwithBestClass（_ logits：[float]） - ＆gt; （Bestobability：float，bestClassIndex：int）{
    让eufferogits = logits.map {exp（$ 0）}
    令Expsum = Expeogits.Reduce（0， +）
    LET概率= Explogits.map {$ 0 / expsum}
    
    var Bestobyability：float = -float.infinity
    var BestClassIndex：int = 0
    
    for（索引，概率）概率。
        如果概率＆gt;最好的探针{
            BestRobibility =概率
            BestClassIndex =索引
        }
    }
    
    返回（Bestrobyability，BestClassIndex）
}

func sigmoid（_ x：float） - ＆gt;漂浮 {
    返回1 /（1 + EXP（-X））
}
 
我看到的是非常低的物质得分，主要是零，但最多〜0.53。而且非常低的概率，通常非常接近零。这是一个示例：
  $$ -MaxBoxIndex：7754 -MaxBoxProb：0.0128950095 -BestClassIndex：63 -MaxBoxOjectness：0.51033634
 
 63的类索引是正确的，或者合理地接近，但是为什么对象这么低呢？为什么班级概率如此之低？我担心我无法正确访问这些值。]]></description>
      <guid>https://stackoverflow.com/questions/79484862/exporting-yolo-segmentation-model-to-coreml</guid>
      <pubDate>Tue, 04 Mar 2025 21:03:23 GMT</pubDate>
    </item>
    <item>
      <title>如何将语义图作为输入？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79484796/how-to-formulate-semantic-map-as-input</link>
      <description><![CDATA[我有一个问题，需要通过UNET编码传递场景的语义图。我想知道如何塑造此地图的输入。
现在，我有一个单个通道映射，该图具有为场景中对象的每个像素的整数对象ID。我应该为场景中的每个对象使用二进制通道吗？]]></description>
      <guid>https://stackoverflow.com/questions/79484796/how-to-formulate-semantic-map-as-input</guid>
      <pubDate>Tue, 04 Mar 2025 20:32:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用重复的通道适应Shapley值计算的顺序归因模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79484542/how-to-adapt-shapley-value-calculation-for-sequential-attribution-models-with-re</link>
      <description><![CDATA[我正在根据Shapley价值开发一个归因模型，以分析营销旅程。在我的数据集中，一个单个频道（例如，“电子邮件”“电话”电话可以在同一旅程中多次出现，无论是连续或与其他渠道交织在一起。面临的挑战是要准确捕获每次发生的边际贡献，并考虑到其在序列中的位置以及重复通道时的潜在饱和或增强效应。
示例旅程：
考虑以下客户旅程：
“电子邮件”

“电子邮件”频道出现三遍。
与最终发生的情况相比，前两个事件是连续的，对转换的影响可能不同，后者遵循“电话”。

我正在考虑的解决方案：
将每次事件视为个体实例：
通过将频道的每个外观视为独特的“玩家”来计算莎普利的价值。计算每个实例的边际贡献后，按通道汇总结果以确定总体贡献。
合并顺序上下文：
修改特征函数，以使分配给每个通道子集的值不仅反映了通道的存在或不存在，还反映了其在旅程中的特定位置。我正在探索使用“订购Shapley Value”之类的变体的可能性。更好地捕获这些顺序效果。
重复发生的重量调整：
研究将不同权重与连续重复相比的潜力。例如，由于饱和而导致连续的发生可能会降低回报，而交错的发生可能会产生更明显的效果。
有人在适应Shapley值的顺序归因模型时面临类似的挑战，通道可以重复？您使用哪些策略或方法来说明特征功能中渠道的顺序和重复？任何可以帮助实施和验证此方法的代码示例或相关文献的引用？]]></description>
      <guid>https://stackoverflow.com/questions/79484542/how-to-adapt-shapley-value-calculation-for-sequential-attribution-models-with-re</guid>
      <pubDate>Tue, 04 Mar 2025 18:13:51 GMT</pubDate>
    </item>
    <item>
      <title>过度拟合模型：训练准确性和验证精度之间的差异很大[封闭]</title>
      <link>https://stackoverflow.com/questions/79484336/overfitting-model-difference-between-training-accuracy-and-validation-accuracy</link>
      <description><![CDATA[我正在建立一个地理空间模型，该模型可以预测未来几年的犯罪模式。我正在使用1999年至2023年的内核密度栅格数据训练模型。我从一个国家内的犯罪活动的点数据集创建了栅格。我的模型基于卷积神经网络和LSTM。运行该模型，由于训练准确性和测试精度之间的价值差异，我的模型往往会过高。我以以下方式将数据集分开：

培训数据：1999-2017 
验证数据：2018-2020 
测试数据：2021-2023 

我不明白为什么该模型是ove拟合的。有人可以帮助如何优化模型以正常工作吗？
创建标签
  加载栅格
  构建模型
    def load_kde_rasters（年，base_path =＆quot; quot;）：
    ““负载和重新示例” kde栅格文件，以确保“均匀形状”。
    kde_rasters = []
    ref_rows =无
    max_cols = 0
    丢失_years = []
    几年中的一年：
        raster_path = os.path.join（base_path，f＆quot; {年}/kd.tif&quot;）
        如果不是OS.PATH.EXISTS（RASTER_PATH）：
            打印（f＆quot;找不到文件：{raster_path}＆quot;）
            丢失_years.append（年）
            继续
        使用rasterio.open（raster_path）作为src：
            kde_raster = src.read（1）
            行，cols = kde_raster.shape
            print（for {Year}，形状：{kde_raster.shape}＆quort;）
            如果ref_rows是无：
                ref_rows =行
            max_cols = max（max_cols，cols）
            kde_rasters.append（（Kde_raster，src.transform，src.crs）））））
    如果丢失了：
        打印（f＆quot“多年缺少kde栅格文件：{novsed_years}＆quot”）
    如果不是kde_rasters：
        打印（“没有有效的kde rasters加载。退出功能。”）
        没有返回，没有
    标准化_rasters = []
    对于kde_raster，转换，kde_rasters中的CRS：
        standardized_raster = np.zeros（（ref_rows，max_cols），dtype = np.float32）
        rasterio.warp.reproject（
            source = kde_raster，
            目的地=标准化_raster，
            src_transform =变换，
            src_crs = crs，
            dst_transform =变换，
            dst_crs = crs，
            重采样=重新采样。
        ）
        standardized_rasters.append（标准化_raster）
    kde_stack = np.stack（standardized_rasters，axis = -1）
    打印（最终kde_stack形状：{kde_stack.shape}＆quot”）
    返回kde_stack
 
训练过程中终端上的详细消息
  我遇到的问题是，该模型不是在概括，而是在记住数据，以便当我尝试预测和开发使用最新数据的未来几年的光栅形象时，它将仅产生相同的图像而不是不同的图像。。
  def build_spatiotemporal_model（input_shape）：
    模型=模型。
        layers.unput（shape = input_shape），
        ＃通过空间辍学减少了卷积层
        层。
            16，（3，3），激活=&#39;relu&#39;，padding =&#39;same&#39;，kernel_regularizer =正元器.l2（0.002）），），），），），
        layers.timedistribated（layers.batchnormization（）），
        layers.timedistribated（layers.spatiallopout2d（0.2）），
        层。
            32，（3，3），激活=&#39;relu&#39;，padding =&#39;same&#39;，kernel_regularizer =正元器.l2（0.002）），），），），），
        layers.timedistribated（layers.batchnormization（）），
        layers.timedistribated（layers.spatiallopout2d（0.2）），
        ＃通过复发掉落减少Convlstm（并删除一层）
        layers.convlstm2d（64，（3，3），activation =&#39;relu&#39;，padding =&#39;same&#39;，return_sepences = true，true，
                          kernel_regularizer = rodorizers.l2（0.003），recurrent_dropout = 0.2），
        layers.dropout（0.4），
        ＃最终卷积层
        layers.timedistribed（layers.conv2d（1，（1，1），activation =&#39;sigmoid&#39;））
    ）））
    返回模型
 
如何改进模型，以便我可以获得一些准确性？]]></description>
      <guid>https://stackoverflow.com/questions/79484336/overfitting-model-difference-between-training-accuracy-and-validation-accuracy</guid>
      <pubDate>Tue, 04 Mar 2025 16:45:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用高度不平衡的交易数据应用FP-增长来推荐产品建议？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79484282/how-to-apply-fp-growth-for-product-recommendation-with-highly-imbalanced-transac</link>
      <description><![CDATA[我正在使用FP-GROWTH算法处理产品推荐系统。我的数据集包含700,000多个独特的交易，但是项目的分布高度不平衡：

有些产品出现在20,000多个订单中。
其他人仅在10个不同的订单中找到。
大约40％的产品出现在少于1,000个订单中。

这种差异在频繁的模式开采中造成了一个挑战，因为高流行的产品主导了模型，而频繁的产品通常被忽略。 
我的问题：

我如何处理产品频率的这种不平衡，以便FP增长可以产生有意义且平衡的建议？
我应该过滤掉低频产品还是调整最低支撑阈值以防止最受欢迎的物品遮盖其余的？
是否有补充技术可以提高这种不平衡数据集的建议质量？

我尝试设置不同的最低支持阈值，但是当阈值太高时，我会失去许多有趣的模式，当它太低时，频繁的模式将由最受欢迎的产品主导。
我还考虑过标准化产品频率或使用替代指标（例如，提升，信心），而不是仅仅支持，但是我不确定这是正确的方法。
我想找到一个平衡，允许推荐稀有产品，同时避免使用最常见的物品的模型。]]></description>
      <guid>https://stackoverflow.com/questions/79484282/how-to-apply-fp-growth-for-product-recommendation-with-highly-imbalanced-transac</guid>
      <pubDate>Tue, 04 Mar 2025 16:18:35 GMT</pubDate>
    </item>
    <item>
      <title>交替的时期将导致所有0个结果，损失和准确性所有零结果[关闭]</title>
      <link>https://stackoverflow.com/questions/79483879/alternating-epochs-are-resulting-into-all-0-results-loss-and-accuracy-all-zero</link>
      <description><![CDATA[当我运行训练循环时，我在一个时期获得了有效的准确性，但是在每个替代时期，我都会得到所有0的结果，我的损失和准确性所有结果均为0 
我试图在二进制数据集上训练我的模型，但是交替的时期正在构成所有零结果。我尝试了使用普通重新连接，从而给出了这种结果。
即使我在问题上评论问题时，我也必须使用班级权重方法来平衡我的班级权重。
我已经使用了数据增加，但我没有使用早期停止。
 ＃修复不正确的steps_per_epoch计算
step_per_epoch =（train_generator.samples // train_generator.batch_size） + int（train_generator.samples％train_generator.batch_size＆gt; 0）
验证_steps =（val_generator.samples // val_generator.batch_size） + int（val_generator.samples％val_generator.batch_size＆gt; 0）

＃编译模型（稳定性的较低初始LR）
final_model.compile（
    优化器= ADAM（Learning_rate = 1E-4），＃降低LR
    损失=&#39;binary_crossentropy&#39;，
    量表= [&#39;facer&#39;，tf.keras.metrics.auc（name =&#39;auc&#39;）]
）
＃训练模型
历史= final_model.fit（
    train_generator，
    step_per_epoch = step_per_epoch，
    验证_data = val_generator，
    验证_steps = validation_steps，
    时代= 10，
    ＃class_weight = class_weights_dict，  
    ＃callbacks =回调
）

＃ 评估
打印（“验证结果：”）
final_model.evaluate（val_generator）

＃从微调史上获得最终的培训准确性
train_accuracy = history.thistory [&#39;准确性&#39;] [ -  1]

＃评估测试集
test_loss，test_accuracy，test_auc = final_model.evaluate（test_generator）

＃打印结果
打印（最终训练精度：{train_accuracy：.4f}＆quot;）
打印（f＆quot“测试损失：{test_loss：.4f}＆quot”）
打印（f＆quot“测试精度：{test_accuracy：.4f}＆quort”）
打印（f＆quot test auc：{test_auc：.4f}＆quot;）

 ]]></description>
      <guid>https://stackoverflow.com/questions/79483879/alternating-epochs-are-resulting-into-all-0-results-loss-and-accuracy-all-zero</guid>
      <pubDate>Tue, 04 Mar 2025 13:44:14 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow实际上如何处理大/小logits [封闭]</title>
      <link>https://stackoverflow.com/questions/79483619/how-tensorflow-actually-treat-large-small-logits</link>
      <description><![CDATA[在最二进制的分类中，我们按以下计算横熵
损失= y*log（p） +（1-y）log（1-p）
其中 p = 1/（1+exp（-logit）） 
我们都知道何时p-＆gt; 1或p-＆gt; 0，损失实际爆炸，而梯度却被摧毁了训练过程。
但是，如何通常找到张力流的实际方法来解决此问题（只需使用 clip_by_value ？听起来像是我的一般解决方案）吗？我正在尝试编写自己的自定义损失，并想解决与TensorFlow相似的问题。
仅用于插图：
 ＃＃不起作用，并在瞬间开始
def bce_loss（y_true，y_pred）：
    损失=  - （y_true * tf.math.log（y_pred） +（1 -y_true） * tf.math.log（1 -y__pred））
    返回tf.Reduce_mean（损失）


＃按预期进行工作
tf.keras.losses.binarycrossentropy（from_logits = false），
 ]]></description>
      <guid>https://stackoverflow.com/questions/79483619/how-tensorflow-actually-treat-large-small-logits</guid>
      <pubDate>Tue, 04 Mar 2025 11:56:48 GMT</pubDate>
    </item>
    <item>
      <title>'numpy.ndarray'对象没有属性'groupby'</title>
      <link>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</link>
      <description><![CDATA[我正在尝试使用 category_encoders.targetencoder 在Python中应用目标编码。但是，我一直遇到以下错误：
  attributeError：&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39;
 
 来自category_encoder
来自sklearn.model_selection导入train_test_split

＃目标编码的功能
encoding_cols = [&#39;等级&#39;，&#39;sub_grade&#39;，&#39;home_ownhip&#39;，&#39;verification_status&#39;， 
                 “目的”，“ application_type”，“ zipcode”]

＃火车测试拆分
x_train_cv，x_test，y_train_cv，y_test = train_test_split（x，y，test_size = 0.25，andury_state = 1）
x_train，x_test_cv，y_train，y_test_cv = train_test_split（x_train_cv，y_train_cv，test_size = 0.25，andury_state = 1）

＃初始化目标编码器
encoder = targetencoder（）

＃应用目标编码
因为我在encoding_cols中：
    x_train [i] = encoder.fit_transform（x_train [i]，y_train）＃**错误在这里发生**
    x_test_cv [i] = encoder.transform（x_test_cv [i]）
    x_test [i] = encoder.transform（x_test [i]）
 
想要成功地将目标编码应用于分类列，而不会遇到&#39;numpy.ndarray&#39;对象没有属性&#39;groupby&#39; error。]]></description>
      <guid>https://stackoverflow.com/questions/79483002/numpy-ndarray-object-has-no-attribute-groupby</guid>
      <pubDate>Tue, 04 Mar 2025 08:00:57 GMT</pubDate>
    </item>
    <item>
      <title>安装Llava</title>
      <link>https://stackoverflow.com/questions/79474039/installing-llava</link>
      <description><![CDATA[ LLAVA的安装的正确依赖性和顺序是什么？我已经尝试了多个选项，但是在尝试采购模型时继续遇到以下错误：
代码：
 
错误：
 无法从&#39;llava.model&#39;导入名称&#39;llavallamaforcausallm&#39;
 
我遵循了正式文档中的每一个指示，但到目前为止没有运气。如何解决它？]]></description>
      <guid>https://stackoverflow.com/questions/79474039/installing-llava</guid>
      <pubDate>Thu, 27 Feb 2025 22:07:50 GMT</pubDate>
    </item>
    <item>
      <title>在Mac上安装PGVECTOR扩展</title>
      <link>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</link>
      <description><![CDATA[我正在尝试在Mac上安装Postgres矢量扩展名，但是正在获得
 错误：扩展名为“向量”没有安装脚本也没有版本的“ 0.4.0”。
 
这是我所做的：

遵循 
但是当我运行创建扩展向量; 有一个错误：
 错误：无法打开扩展控制文件;/applications/postgres.app/contents/versions/13/share/postgresql/extension/extension/extension/vector.control&quot;&quot;：没有这样的文件或目录
 

 我将pgvector的含量复制到posgresql/扩展名中：
 sudo cp -r〜/downloads/pgvector/*/applications/postgres.app/contents/versions/13/share/postgresql/extension/extension/


尝试运行创建扩展向量; 现在错误是：
 错误：扩展名为“向量”没有安装脚本也没有版本的“ 0.4.0”。
 
这里有人看到了这个问题吗？
顺便说一句，使用 postgresql 13.10  ]]></description>
      <guid>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</guid>
      <pubDate>Tue, 07 Mar 2023 15:32:42 GMT</pubDate>
    </item>
    <item>
      <title>Shap的功能贡献是如何计算出具有单词嵌入式作为输出的模型的？</title>
      <link>https://stackoverflow.com/questions/70988481/how-are-shaps-feature-contributions-calculated-for-models-with-word-embeddings</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/70988481/how-are-shaps-feature-contributions-calculated-for-models-with-word-embeddings</guid>
      <pubDate>Fri, 04 Feb 2022 14:59:08 GMT</pubDate>
    </item>
    <item>
      <title>如何了解自动编码器型号的形状值？</title>
      <link>https://stackoverflow.com/questions/64742811/how-to-understand-shap-value-for-an-autoencoder-model</link>
      <description><![CDATA[“功能重要性”对自动编码器（AE）模型意味着什么？
假设我有一个训练有素的AE模型。如果我运行之类的代码
  e = shap.kernelexplainer（autoencoder.predict，x_train.values）
shap_values = e.shap_values（x_train.values）
shap.summary_plot（shap_values，x_train）
 
所以我想知道结果意味着什么？由于它是一个自动编码器神经网络。 “特征重要性”是否意味着哪个功能对此模型更重要？另外，我应该用x_test替换x_train吗？自动编码器以其异常检测能力而闻名。如果我将一些异常样本放入中
  shap_values = e.shap_values（abnormal_sample.values）
 
那是什么意思？
另外，我发现SHAP模型不需要任何训练目标值（任何神经网络模型的Y值）。那么它如何定义“特征重要性”？]]></description>
      <guid>https://stackoverflow.com/questions/64742811/how-to-understand-shap-value-for-an-autoencoder-model</guid>
      <pubDate>Sun, 08 Nov 2020 20:38:21 GMT</pubDate>
    </item>
    <item>
      <title>如何处理预测价值的变化</title>
      <link>https://stackoverflow.com/questions/52252442/how-to-handle-shift-in-forecasted-value</link>
      <description><![CDATA[我在KERAS中使用LSTM实现了一个预测模型。该数据集分为15敏，我预计将来有12个步骤。 
该模型对问题的表现有益。但是预测的问题很小。它显示出很小的转移效果。要获得更清晰的图片，请参见下面的图形。
  如何处理这个问题。必须如何转换数据以处理此类问题。？
我使用的模型在下面给出
  init_lstm = Randomuniform（MinVal =  - 。05，MaxVal = .05）
init_dense_1 =随机分辨（MinVal =  - 。03，MaxVal = .06）

型号=顺序（）

model.ADD（LSTM（15，input_shape =（X.Shape [1]，X.Shape [2]），kernel_initializer = init_lstm，recurrent_dropout = 0.33））

model.Add（密集（1，kernel_initializer = init_dense_1，activation =&#39;linear&#39;））））

model.compile（loss =&#39;mae&#39;，优化器= adam（lr = 1e-4））

历史= model.fit（x，y，epochs = 1000，batch_size = 16，验证_data =（x_valid，y_valid），冗长= 1，shuffle = false）
 
我做了这样的预测
  my_forecasts = model.predict（x_valid，batch_size = 16）
 
时间序列数据被转换为监督以使用此功能来喂养LSTM

 ＃将时间序列转换为监督学习问题
def series_to_to_supervising（data，n_in = 1，n_out = 1，dropnan = true）：
    n_vars = 1如果类型（数据）列表else data.shape [1]
    DF = DataFrame（数据）
    cols，names = list（），list（）
    ＃输入序列（T-N，... T-1）
    对于我的范围（n_in，0，-1）：
        cols.append（df.shift（i））
        名称 += [（&#39;var％d（t-％d）&#39;％（j +1，i））在范围内（n_vars）]
    ＃预测序列（t，t+1，... t+n）
    对于我在范围内（0，n_out）：
        cols.append(df.shift(-i))
        if i == 0:
            名称 += [（&#39;var％d（t）&#39;％（j +1）的J范围（n_vars）]
        别的：
            名称+= [（&#39;var％d（t+％d）&#39;％（j+1，i））在范围内（n_vars）]
    ＃将所有内容放在一起
    agg = concat（cols，轴= 1）
    agg.columns =名称
    ＃带有NAN值的掉落行
    如果Dropnan：
        agg.dropna（intplace = true）
    返回agg

super_data = series_to_to_superpising（数据，12，1）
 
我的时间表是多变量的。  var2 是我需要预测的。我放弃了未来的 var1 喜欢
  del super_data [&#39;var1（t）&#39;]
 
分开的火车和有效的像这样
 功能= super_data [fart_names]
值= super_data [val_name]

ntest = 3444

train_feats，test_feats =功能[0：-n_test]，功能[-n_test：]
train_vals，test_vals =值[0：-n_test]，值[-n_test：]

x，y = train_feats.values，train_vals.values
X = X.Reshape（X.Shape [0]，1，X.Shape [1]）

x_valid，y_valid = test_feats .values，test_vals .Values
x_valid = x_valid.reshape（x_valid.shape [0]，1，x_valid.shape [1]）
 
我尚未对此预测进行数据固定。我还尝试采取不同的方式并尽我所能使模型保持固定，但问题仍然相同。
我还尝试了Min-Max缩放器的不同缩放范围，希望它可以帮助模型。但是预测正在恶化。
 我尝试过的其他事情

=＆gt;尝试了其他优化器
=＆gt;尝试了MSE损失和自定义的对数损失功能
=＆gt;尝试了变化的batch_size
=＆gt;尝试添加更多过去的时间段
=＆gt;尝试使用滑动窗口和timeseriessplit培训
 
I understand that the model is replicating the last known value to it, thereby minimizing the loss as good as it can
在培训过程中，验证和培训损失保持足够低。这使我想到我是否需要为此目的提出新的损失功能。
这是必要的吗？如果是这样，我应该去做什么损失功能。？
我尝试了我偶然发现的所有方法。我找不到任何资源指向这种问题。这是数据问题吗？这是因为LSTM很难学习问题。？]]></description>
      <guid>https://stackoverflow.com/questions/52252442/how-to-handle-shift-in-forecasted-value</guid>
      <pubDate>Mon, 10 Sep 2018 06:48:48 GMT</pubDate>
    </item>
    </channel>
</rss>