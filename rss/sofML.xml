<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 14 Dec 2023 12:25:59 GMT</lastBuildDate>
    <item>
      <title>根据当前活动预测用户的下一次点击</title>
      <link>https://stackoverflow.com/questions/77660056/next-click-prediction-of-user-based-on-present-activity</link>
      <description><![CDATA[在此处输入图像描述
我有 44,000 个数据，其中包含 81 个用户和 80 个服务，其中包含方法作为子类别（唯一方法总数为 300）。
我想根据用户的第一次服务和方法选择来预测用户的下一次点击。这里我相信用户和时间戳，第一次选择，方法选择被认为是特征选择。我需要帮助，我想知道我是否可以使用 LSTM、隐马尔可夫方法或 RNN 模型问题，哪个模型更好？我想知道即使时间戳不均匀，我是否可以使用 RNN 和 LSTM？我是否需要对标签（即服务和方法）使用热编码？任何建议对我也有帮助。是否可以通过多类预测 2 个输出？]]></description>
      <guid>https://stackoverflow.com/questions/77660056/next-click-prediction-of-user-based-on-present-activity</guid>
      <pubDate>Thu, 14 Dec 2023 12:11:37 GMT</pubDate>
    </item>
    <item>
      <title>当使用人工智能模型预测某些东西时，是否可以使用用户输入的特征值进行预测？</title>
      <link>https://stackoverflow.com/questions/77659839/when-predict-something-using-ai-model-is-it-possible-to-predict-with-user-input</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.ensemble 导入 RandomForestRegressor

# 读取Excel文件
data = pd.read_excel(“input.xlsx”)

# 房屋特征数据
X_train = data.iloc[1:57, 0:6].values # 第 2 行到第 57 行第 1 到第 6 列的特征数据
y_train = data.iloc[1:57, 6].values # 第 7 列第 2 行到第 57 行的因变量

# 创建随机森林回归模型
模型 = RandomForestRegressor()

# 训练模型
model.fit(X_train, y_train)

# 获取用户输入的外壳规格
sd = float(input(&quot;请输入到地铁的距离：&quot;))
Fp = float(input(&quot;请输入高楼层的溢价：&quot;))
Aa = float(input(&quot;请输入专属区域：&quot;))
Ba = float(input(&quot;请输入土地面积：&quot;))
Rp = float(input(&quot;请输入实际成交价格：&quot;))
O = float(input(&quot;请输入房屋年龄：&quot;))

# 预测房屋的合理价格
X_new = [[Ba, Aa, Sd, Rp, O, Fp]]
预测价格 = model.predict(X_new)

# 显示预测的合理价格
print(&quot;房屋的预测合理价格：&quot;,predicted_price)


这是 input.xlsx 文件的示例。
通常，在使用 AI 模型时，众所周知，会将数据分为训练集和测试集，利用训练数据来预测测试数据的值。
但是，我希望用户直接输入特征值，以便 AI 模型可以预测目标值。这可能吗？
而且，如果只输入六个特征中的三个，会起作用吗？
因为当有人输入他想要的特征值时，他通常不太了解土地面积、高层溢价等信息，...
预处理是否必要？]]></description>
      <guid>https://stackoverflow.com/questions/77659839/when-predict-something-using-ai-model-is-it-possible-to-predict-with-user-input</guid>
      <pubDate>Thu, 14 Dec 2023 11:33:45 GMT</pubDate>
    </item>
    <item>
      <title>使用回归分析图像的相似度百分比</title>
      <link>https://stackoverflow.com/questions/77658841/similarity-percentage-on-images-using-regression</link>
      <description><![CDATA[我正在开发一个项目，该项目对包含两种花卉的数据集使用分类和回归：雏菊和向日葵。我已经成功地应用随机森林分类来找到每个测试图像的类别，但我的问题是如何使用回归来显示图像与每个类别共享的相似度百分比？（例如雏菊图片为 87%雏菊和 13% 向日葵）。我知道回归不是最好的方法，但我将其作为一项作业来做，所以我必须这样做。
我尝试过随机森林回归器和 scikit-learn predict_proba 东西，但我的程序完全冻结了，所以我猜我做错了什么。
这是与我的问题相关的代码片段：
# 将列表转换为 numpy 数组
test_images = np.array(test_images)
test_labels = np.array(test_labels)
test_probabilities = classifier.predict_proba(test_images)

# 为测试集创建交互式图像查看器
图像查看器类：
    def __init__(自身、图像、真实标签、预测概率):
        self.images = 图像
        self.true_labels = true_labels
        自我预测概率 = 预测概率
        自我索引 = 0

        self.fig, self.ax = plt.subplots()
        self.display_image()

        self.next_button = 按钮(plt.axes([0.7, 0.02, 0.1, 0.05]), &#39;下一个&#39;)
        self.next_button.on_clicked(self.next_image)

        plt.show()

    def 显示图像（自身）：
        img = self.images[self.index].reshape(256, 256, 3)
        true_class = self.true_labels[self.index]
        预测概率=自我.预测概率[自我.索引]

        self.ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        self.ax.set_title(f&quot;真: {true_class}\n预测概率: {predicted_probs}&quot;)
        self.ax.axis(&#39;关闭&#39;)

    def next_image(自身, 事件):
        self.index = (self.index + 1) % len(self.images)
        self.display_image()
        plt.draw()

# 初始化测试集的图像查看器
test_image_viewer = ImageViewer（测试图像，测试标签，测试概率）

这段代码不显示任何内容，正如我所说，我也在同一个程序中使用分类，但它工作正常，直到我添加回归。另外，我显示图像的方式有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77658841/similarity-percentage-on-images-using-regression</guid>
      <pubDate>Thu, 14 Dec 2023 08:55:16 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow_federated.python.simulation”没有属性“from_clients_and_fn”</title>
      <link>https://stackoverflow.com/questions/77657875/attributeerror-module-tensorflow-federated-python-simulation-has-no-attribute</link>
      <description><![CDATA[&lt;块引用&gt;
将 pandas 导入为 pd
将tensorflow_federated导入为tff
df = pd.DataFrame({
&#39;用户 ID&#39;: [1, 1, 2, 3],
&#39;产品 ID&#39;: [2, 3, 1, 2],
&#39;购买&#39;: [1, 0, 1, 0],
&#39;浏览&#39;: [0, 1, 0, 1]
})
数据 = {}
对于 df.groupby(“user_id”) 中的 user_id、user_data：
购买 = user_data[user_data[“购买”] == 1][“product_id”].tolist()
browsers = user_data[user_data[“browse”] == 1][“product_id”].tolist()
data[user_id] =（购买、浏览）
client_data = [数据[user_id] for data中的user_id]
client_ids = [str(i) for i in range(len(client_data))]
tff_data = tff.simulation.datasets.TestClientData(client_data, client_ids)
数据集 = tff_data.create_tf_dataset_for_client(tff_data.client_ids[0])
我在最后一步中遇到问题，AttributeError：模块“tensorflow_federated.python.simulation”没有属性“from_clients_and_fn”
]]></description>
      <guid>https://stackoverflow.com/questions/77657875/attributeerror-module-tensorflow-federated-python-simulation-has-no-attribute</guid>
      <pubDate>Thu, 14 Dec 2023 05:05:24 GMT</pubDate>
    </item>
    <item>
      <title>根据提示对 NLP 任务进行分类？</title>
      <link>https://stackoverflow.com/questions/77657539/classifying-nlp-tasks-based-on-prompts</link>
      <description><![CDATA[我正在致力于创建一个聊天机器人。我被分配的任务是“根据提示对 NLP 任务进行分类”。例如确定用户请求是总结文本还是翻译段落。
我在 Google 上搜索过，但没有找到明确的答案。您能否建议如何完成这项任务或分享任何相关的研究资源？]]></description>
      <guid>https://stackoverflow.com/questions/77657539/classifying-nlp-tasks-based-on-prompts</guid>
      <pubDate>Thu, 14 Dec 2023 02:48:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 Marqo 进行矢量搜索的单个或多个键值对数据结构？</title>
      <link>https://stackoverflow.com/questions/77657071/single-or-multiple-key-value-pair-data-structure-for-vector-search-with-marqo</link>
      <description><![CDATA[我正在使用 Marqo Cloud 为工作项目实施矢量搜索。我的文档（产品）有一些数据，其结构可以如下：
单个键值对，例如：标签：红色、斑点、尼龙、休闲
或者每个标签标题包含多个键值对，例如：
红色
设计：斑点
材质: 尼龙
风格：休闲
在矢量搜索中，这些数据结构中的一种会比另一种表现得更好吗？或者差异可能可以忽略不计？]]></description>
      <guid>https://stackoverflow.com/questions/77657071/single-or-multiple-key-value-pair-data-structure-for-vector-search-with-marqo</guid>
      <pubDate>Wed, 13 Dec 2023 23:34:17 GMT</pubDate>
    </item>
    <item>
      <title>8 位量化是否应该使 GPU 上的耳语推理速度更快？</title>
      <link>https://stackoverflow.com/questions/77656929/should-8bit-quantization-make-whisper-inference-faster-on-gpu</link>
      <description><![CDATA[我正在对拥抱脸变压器进行耳语推理。
load_in_8bit 量化由 bitsandbytes 提供。
如果在 NVIDIA T4 GPU 上以 8 位模式加载 Whisper-large-v3，则对示例文件的推理需要更长的时间 (5 倍)。 nvidia-smi 中的 GPU 利用率为 33%。
量化不应该提高 GPU 上的推理速度吗？
https://pytorch.org/docs/stable/quantization.html
类似问题：

https://discuss .huggingface.co/t/enabling-load-in-8bit-makes-inference-much-slower/38596

&lt;代码&gt;
进口火炬

从转换器导入 WhisperFeatureExtractor、WhisperTokenizerFast
从 Transformers.pipelines.audio_classification 导入 ffmpeg_read

MODEL_NAME =“openai/whisper-large-v3”

tokenizer = WhisperTokenizerFast.from_pretrained(MODEL_NAME)
feature_extractor = WhisperFeatureExtractor.from_pretrained(MODEL_NAME)

model_8bit = AutoModelForSpeechSeq2Seq.from_pretrained(
     “openai/whisper-large-v3”，
    device_map=&#39;自动&#39;,
    load_in_8bit=真）

样本=“样本.mp3”；第27章 长

使用 torch.inference_mode()：
    将 open(sample, &quot;rb&quot;) 作为 f：
        输入 = f.read()
        输入= ffmpeg_read（输入，feature_extractor.sampling_rate）

        input_features = feature_extractor（输入，sampling_rate = feature_extractor.sampling_rate，return_tensors =&#39;pt&#39;）[&#39;input_features&#39;]

        input_features = torch.tensor(input_features, dtype=torch.float16, device=&#39;cuda&#39;)

        forced_decoder_ids_output = model_8bit.generate(input_features=input_features, return_timestamps=False)

        out = tokenizer.decode(forced_decoder_ids_output.squeeze())
        打印出）
]]></description>
      <guid>https://stackoverflow.com/questions/77656929/should-8bit-quantization-make-whisper-inference-faster-on-gpu</guid>
      <pubDate>Wed, 13 Dec 2023 22:43:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么我在文本分类中得到一长串零？</title>
      <link>https://stackoverflow.com/questions/77656547/why-do-i-get-a-long-list-of-zeros-in-classification-of-text</link>
      <description><![CDATA[我有 500 条来自 YouTube 的俄语评论。我使用 youtokentome 库对它们进行标记。
df[&#39;textOriginal&#39;].to_csv(&#39;text.txt&#39;, index=False, header=False)

model_path = &#39;tokenizer.model&#39;
yttm.BPE.train(data=&#39;text.txt&#39;, model=model_path, vocab_size=5000)

tokenizer = yttm.BPE(模型=模型路径)

df[&#39;tokens&#39;] = df[&#39;textOriginal&#39;].apply(lambda x: tokenizer.encode(x, output_type=yttm.OutputType.ID))

文本标记示例
接下来，我给出张量中的标记列表。
tokens_tensor = df[&#39;tokens&#39;].apply(lambda x: torch.tensor(x)).tolist()
tokens_tensor = torch.nn.utils.rnn.pad_sequence（tokens_tensor，batch_first=True）

接下来，我想将文本分为 3 类。为此，我使用 nn.Embedding+nn.LIST+ nn.Linear。
但是模型的返回值我不清楚。我得到一长串零。
如何获得对象的分类？
我的模型代码：
&lt;前&gt;&lt;代码&gt;embedding_dim = 300
词汇大小 = 5000
隐藏大小 = 512
输出暗度 = 3

导入 torch.nn.function 作为 F

类 MyModel(nn.Module):
    def __init__(自身、vocab_size、embedding_dim、hidden_​​size、output_dim、dropout_rate=0.5):
        超级（MyModel，自我）.__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_​​size=hidden_​​size,batch_first=True)
        self.线性 = nn.Linear(hidden_​​size, output_dim)


    defforward(self, input_seq):
        嵌入 = self.embedding(input_seq)
        lstm_out, _ = self.lstm(嵌入)
        lstm_out = lstm_out[:, -1, :]
        x = self.线性(lstm_out)
        返回 F.log_softmax(x, 暗淡=1)
]]></description>
      <guid>https://stackoverflow.com/questions/77656547/why-do-i-get-a-long-list-of-zeros-in-classification-of-text</guid>
      <pubDate>Wed, 13 Dec 2023 21:08:49 GMT</pubDate>
    </item>
    <item>
      <title>最后一行的结果没有像我想象的那样出现[关闭]</title>
      <link>https://stackoverflow.com/questions/77654857/result-of-the-last-line-doesnt-appear-as-i-thought-it-would-be</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77654857/result-of-the-last-line-doesnt-appear-as-i-thought-it-would-be</guid>
      <pubDate>Wed, 13 Dec 2023 15:46:40 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类器演示期间用户输入的问题</title>
      <link>https://stackoverflow.com/questions/77653884/a-problem-with-the-user-input-during-the-random-forest-classifier-demonstration</link>
      <description><![CDATA[我使用随机森林分类器获得了超过 90% 的准确率，但我担心其余算法给出的结果要低得多：
包含结果的表格
但这不是主要问题。问题是，当我使用用户输入时，预测是 100% 错误的。用户输入的列的顺序对应于训练数据集列的位置。
模型 = RandomForestClassifier()
model.fit(X_train, y_train)
预测 = model.predict(X_test)
acc = precision_score(y_test, 预测) # 输出：0.91

X_test_user = df_user_compounds_1.to_numpy()
user_input_predictions_1 = model.predict(X_test_user) #
user_input_predictions_1 # 输出： array([0, 0, 0, 0, 0], dtype=int64)，但应该是： array([1, 1, 1, 1, 1],dtype=int64)

有人知道为什么会发生这种情况吗？
数据集经过预处理 - 没有缺失值，没有重复，使用 RandomOverSampler 进行平衡，使用 MinMaxScaler 进行缩放，没有负值，并且包含 11 个特征/7K 行。]]></description>
      <guid>https://stackoverflow.com/questions/77653884/a-problem-with-the-user-input-during-the-random-forest-classifier-demonstration</guid>
      <pubDate>Wed, 13 Dec 2023 13:17:28 GMT</pubDate>
    </item>
    <item>
      <title>执行与自然语言处理相关的代码时出错[关闭]</title>
      <link>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</link>
      <description><![CDATA[此代码显示了图像中给出的错误。我无法理解其中的原因。
导入系统
断言 sys.version_info[0]==3
断言 sys.version_info[1] &gt;= 5

从平台导入 python_version
assert int(python_version().split(&quot;.&quot;)[1]) &gt;= 5, &quot;请按照\中的说明升级您的Python版本
    在与此笔记本相同的目录中找到 README.txt 文件。您的 Python 版本是“ + python_版本()

从 gensim.models 导入 KeyedVectors
从 gensim.test.utils 导入数据路径
导入打印件
将 matplotlib.pyplot 导入为 plt
plt.rcParams[&#39;figure.figsize&#39;] = [10, 5]

导入nltk
nltk.download(&#39;reuters&#39;) #指定下载位置，可选添加参数：download_dir=&#39;/specify/desired/path/&#39;
从 nltk.corpus 导入路透社

将 numpy 导入为 np
随机导入
将 scipy 导入为 sp
从 sklearn.decomposition 导入 TruncatedSVD
从 sklearn.decomposition 导入 PCA

START_TOKEN = &#39;&#39;
END_TOKEN = &#39;&#39;

np.随机.种子(0)
随机种子(0)

错误消息：
&lt;块引用&gt;
[nltk data] 加载路透社时出错：

我不知道如何在Python中使用导入命令。我尝试了所有可能的方法进行检查，包括删除带有其他新闻门户名称的“路透社”，但没有任何效果。现在，如果有人帮助我正确编写代码的“导入”部分，那就更好了。我认为其他部分没问题，因为没有显示其他消息。]]></description>
      <guid>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</guid>
      <pubDate>Wed, 13 Dec 2023 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>SEEM 模型在向其传递图像及其推理时面临的问题</title>
      <link>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</link>
      <description><![CDATA[我正在研究 SEEM 模型，这是一个可推广的交互式模型，用于一次性分割图像中任何地方的所有内容。由于资源有限，我在将图像传递给它及其推理时面临问题。我已经安装了所有依赖项并单独加载了 SEEM 模型。有谁对此有任何想法并相应地指导我。
我期待有人可以根据他们的知识指导我，我可以解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</guid>
      <pubDate>Wed, 13 Dec 2023 04:53:29 GMT</pubDate>
    </item>
    <item>
      <title>具有不同输入形状的 3D 深度学习输入 [关闭]</title>
      <link>https://stackoverflow.com/questions/77602918/3d-deep-learning-input-with-varying-input-shapes</link>
      <description><![CDATA[如何将可变维度的数据集输入到深度学习模型中。
我正在使用可变切片进行 3D 医学成像，我使用了 PCA 和其他切片选择技术以及填充以使模型具有相同的形状
但我想知道是否有任何用于深度学习模型的可变输入形状的技术。
下面是代码：
来自tensorflow.keras导入层

#输入形状 = (200, 200, 60, 1)
输入形状=像素数组[1:]
输入 = keras.Input(shape=(pixel_arrays.shape[1:]))
x=layers.Conv3D(filters=16,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(输入)
x=layers.Conv3D(filters=32,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(x)
x=layers.Conv3D(filters=64,kernel_size=3,activation=&#39;relu&#39;,padding=&#39;same&#39;)(x)
#x = 层.Conv3D(filters=32, kernel_size=3, 激活=&#39;relu&#39;, padding=&#39;same&#39;)(x)
]]></description>
      <guid>https://stackoverflow.com/questions/77602918/3d-deep-learning-input-with-varying-input-shapes</guid>
      <pubDate>Mon, 04 Dec 2023 22:33:53 GMT</pubDate>
    </item>
    <item>
      <title>如果我的模型在最后一层使用 sigmoid 和二元交叉熵进行训练，我可以输出类的概率而不是 0/1 吗？</title>
      <link>https://stackoverflow.com/questions/70159955/if-my-model-is-trained-using-sigmoid-at-the-final-layer-and-binary-crossentropy</link>
      <description><![CDATA[我使用 sigmoid 函数训练了一个最后带有密集层的 CNN 模型：
model.add(layers.Dense(1,activation=&#39;sigmoid&#39;))

我还使用二进制交叉熵进行了编译：
model.compile(loss=&#39;binary_crossentropy&#39;,
              优化器 = &#39;亚当&#39;,
              指标=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),&#39;准确性&#39;])

二值图像分类的 f1 分数较低，我的模型预测一个类别优于另一个类别。所以我决定根据我的 sigmoid 函数在最后一层的输出概率添加一个阈值：
c = load_img(&#39;/home/kenan/Desktop/COV19D/validation/covid/ct_scan_19/120.jpg&#39;,
             color_mode=&#39;灰度&#39;,
             目标大小 = (512,512))
c=img_to_array(c)
c= np.expand_dims(c, 轴=0)
pred = model.predict_proba(c)
预测
y_classes = ((model.predict(c)&gt; 0.99)+0).ravel()
y_类

我想在代码中使用“pred”作为该类的概率，但它始终为 0 或 1，如下所示：
Out[113]: array([[1.]], dtype=float32)

为什么它不给出预测 [0,1] 之间类别的概率而不是 1？有没有办法获得我的情况下的类概率而不是 0 或 1？]]></description>
      <guid>https://stackoverflow.com/questions/70159955/if-my-model-is-trained-using-sigmoid-at-the-final-layer-and-binary-crossentropy</guid>
      <pubDate>Mon, 29 Nov 2021 18:56:08 GMT</pubDate>
    </item>
    <item>
      <title>设置分类器参数，无需拟合即可使用</title>
      <link>https://stackoverflow.com/questions/48252006/set-parameters-for-classifier-and-use-it-without-fitting</link>
      <description><![CDATA[我正在使用 python 和 scikit-learn 进行一些分类。
是否可以重用分类器学习到的参数？
例如：
从 sklearn.svm 导入 SVC

cl = SVC(...) # 使用一些超参数创建 svm 分类器
cl.fit(X_train, y_train)
参数 = cl.get_params()

让我们将这个 params 作为字符串字典存储在某处，甚至写入 json 文件。假设，我们稍后想要使用这个经过训练的分类器对某些数据进行一些预测。尝试恢复它：
params = ... # 检索以字典形式存储在某处的这些参数
data = ... # 我们要预测的数据
cl = SVC(...)
cl.set_params(**参数)
预测 = cl.predict(数据)

如果我这样做，我会得到 NonFittedError 和以下堆栈跟踪：
文件“C:\Users\viacheslav\Python\Python36-32\lib\site-packages\sklearn\svm\base.py”，第 548 行，在预测中
    y = super(BaseSVC, self).predict(X)
  文件“C:\Users\viacheslav\Python\Python36-32\lib\site-packages\sklearn\svm\base.py”，第 308 行，在预测中
    X = self._validate_for_predict(X)
  文件“C:\Users\viacheslav\Python\Python36-32\lib\site-packages\sklearn\svm\base.py”，第 437 行，在 _validate_for_predict 中
    check_is_fitted(自我,&#39;support_&#39;)
  文件“C:\Users\viacheslav\Python\Python36-32\lib\site-packages\sklearn\utils\validation.py”，第 768 行，在 check_is_fitted 中
    引发 NotFittedError(msg % {&#39;name&#39;: type(estimator).__name__})
sklearn.exceptions.NotFittedError：此 SVC 实例尚未安装。在使用此方法之前，请使用适当的参数调用“fit”。

是否可以为分类器设置参数并在不拟合的情况下进行预测？我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/48252006/set-parameters-for-classifier-and-use-it-without-fitting</guid>
      <pubDate>Sun, 14 Jan 2018 17:04:03 GMT</pubDate>
    </item>
    </channel>
</rss>