<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 17 May 2024 15:15:29 GMT</lastBuildDate>
    <item>
      <title>选择测试数据来衡量现成分类模型的性能并提高精度</title>
      <link>https://stackoverflow.com/questions/78495909/choosing-test-data-to-measure-performance-of-an-off-the-shelf-classification-mod</link>
      <description><![CDATA[我使用分类模型（German-BERT-uncased Transformer 模型），该模型已针对二分分类任务对大约 44,000 个手动标记的社交媒体帖子进行了微调。我将该模型应用于一个新的数据集（大约 10,000 个帖子），该数据集不是原始训练数据的一部分，它为我提供了每个帖子的标签及其各自的置信水平。我现在想做两件事：

通过计算精度、召回率和 F1 分数来衡量分类器在新数据集上的性能
基于此，我想选择置信水平的截止值，以提高两个预测类别之一的精度

为了解决 1)，我想手动标记 10,000 个帖子中的 500 个。但是，我现在不确定如何选择这些职位。当然，您通常会进行随机选择以避免偏差。但很有可能，在 500 个职位中，这两个类别之一的代表性严重不足。
鉴于我有模型提供的 10,000 个帖子的标签和置信度，我想知道是否应该进行混合选择，例如：手动标记的 500 个帖子中随机选择 20%，40 % 是分类器以高于 0.5 的置信度预测类别 1 的情况，另外 40% 是分类器以高于 0.5 的置信度预测类别 2 的情况。
我已经尝试查找对此提出建议的文献，但不幸的是，除了一篇或多或少相关的论文之外，没有找到任何内容，该论文对于类似但略有不同的问题使用 20%/80% 分割 (doi.org/10.1017/潘.2022.15）。
关于2），我阅读了不同的建议，例如考虑成本错误预测的。由于我的情况没有实际成本，因此这个选项似乎不适合我。不过，我也听说您可以使用 Youden&#39;s J 来选择截止置信水平，可提高二分分类任务中某一类的精度（参见示例 8.9）。我的最终目标是尽量减少误报。
如果您根据自己对这两个问题中的任何一个的经验有任何建​​议，或者您对此有一些不错的读物，请告诉我:)也愿意提供更多信息，这是我在这里的第一篇文章，我是不确定需要多少详细信息。]]></description>
      <guid>https://stackoverflow.com/questions/78495909/choosing-test-data-to-measure-performance-of-an-off-the-shelf-classification-mod</guid>
      <pubDate>Fri, 17 May 2024 13:13:29 GMT</pubDate>
    </item>
    <item>
      <title>如何将机器学习模型与snort/suricata集成</title>
      <link>https://stackoverflow.com/questions/78495663/how-to-integrate-machine-learning-model-with-snort-suricata</link>
      <description><![CDATA[我创建了一个机器学习模型，现在我想将其与 snort 或 suricata 等 ids 集成，如果有人可以提供帮助或拥有与此主题相关的任何资源，我将不胜感激。
我考虑过创建 Snort 插件，但找不到太多关于如何做到这一点的信息。]]></description>
      <guid>https://stackoverflow.com/questions/78495663/how-to-integrate-machine-learning-model-with-snort-suricata</guid>
      <pubDate>Fri, 17 May 2024 12:27:54 GMT</pubDate>
    </item>
    <item>
      <title>nlp 中的无监督情感分析</title>
      <link>https://stackoverflow.com/questions/78495476/unsupervised-sentiment-analysis-in-nlp</link>
      <description><![CDATA[如何对未标记的数据进行情感分析，我查遍了互联网（给出了聚类算法），但效果不佳。如何对未标记的数据从头开始进行情感分析，例如使用深度学习。我的意思是大公司如何使用他们的数据进行情感分析之类的任务，他们是否标记了数百万数据
我尝试过一些聚类算法，如LDA、Kmeans，但效果不佳。
怎么做。
或者也许可以向我指出学习此内容的资源
我必须从头开始，而不是使用一些预训练的模型]]></description>
      <guid>https://stackoverflow.com/questions/78495476/unsupervised-sentiment-analysis-in-nlp</guid>
      <pubDate>Fri, 17 May 2024 11:51:53 GMT</pubDate>
    </item>
    <item>
      <title>多元模型“abess”包中的变化系数</title>
      <link>https://stackoverflow.com/questions/78495306/change-coefficient-in-multivariate-model-abess-package</link>
      <description><![CDATA[我正在尝试更改训练模型的系数，如下所示
set.seed(1)
y &lt;- cumsum(rnorm(100))
x &lt;- 1:长度(y)

LR &lt;- lm(y~x)
pr &lt;- 预测(LR, cbind.data.frame(x))

绘图（x，y，t =“l”）
行（pr，col = 4）


更改一些模型系数，仅作为示例
LR$系数 &lt;- LR$系数 + 0.05
new_pr &lt;- 预测(LR, cbind.data.frame(x))
行（new_pr，col = 2，lty = 2）


现在我想对具有许多响应函数的 abess 包中的模型执行相同的操作
y &lt;- 矩阵(rnorm(200), ncol = 4) ; colnames(y) &lt;-paste0(“y”, 1:ncol(y))
x &lt;- 矩阵(rnorm(200), ncol = 4) ; colnames(x) &lt;-paste0(“x”, 1:ncol(x))
图书馆（阿贝斯）
################ 多元高斯模型 ################
abess_fit &lt;- abess(x, y, family = “mgaussian”)

但问题是，当我尝试获取模型的系数时，我得到了几组系数，在本例中有 5 个，但数量取决于数据。
abess_fit[[“beta”]]

$`0`
“ddiMatrix”类的 4 x 4 对角矩阵
   y1 y2 y3 y4
x1 0 。 。 。
x2 . 0 . 。
x3 . 。 0 .
x4。 。 。 0

$`1`
类“dgCMatrix”的 4 x 4 稀疏矩阵
           y1 y2 y3 y4
x1 。 。 。 。
x2 -0.1015219 0.02199386 0.1122985 -0.250586
x3 . 。 。 。
x4。 。 。 。

$`2`
类“dgCMatrix”的 4 x 4 稀疏矩阵
            y1 y2 y3 y4
x1 。 。 。 。
x2 -0.09682036 0.03178114 0.11441030 -0.24966314
x3 . 。 。 。
x4 -0.11844742 -0.24657644 -0.05320414 -0.02324879

$`3` .. $`4` .. $`5`

和
abess_fit[[“截距”]]

[[1]]
[1] 0.10044828 0.11732645 -0.15248544 0.07686929

[[2]]
[1] 0.1096521 0.1153325 -0.1626663 0.0995871

[[3]] .. [[4]] .. [[5]]

我不明白为什么有几组以及我需要哪组系数来更改模型。]]></description>
      <guid>https://stackoverflow.com/questions/78495306/change-coefficient-in-multivariate-model-abess-package</guid>
      <pubDate>Fri, 17 May 2024 11:21:53 GMT</pubDate>
    </item>
    <item>
      <title>通过机器学习预测季后赛</title>
      <link>https://stackoverflow.com/questions/78495190/predicting-playoff-with-machine-learning</link>
      <description><![CDATA[我正在研究 WNBA 球队和球员从第 1 季到第 10 季的数据，目的是预测一支球队是否会在第 11 季获得季后赛资格。指令是用第 1 季的统计数据填充第 2 季，用第 2 季的统计数据填充第 3 季，依此类推。我现在的问题是，在预测第 11 季的季后赛列时，我该如何用第 10 季的最新条目填充它，同时仅用年份列来指示是哪个赛季，就能预测它。
我尝试过以某种方式调整赛季，这样现在我在一个组合数据框中就有了第 2 季到第 11 季的数据。既然这个数据框已经有季后赛列，那么在测试我预测的每支球队的季后赛结果时，我是否会将其用作实际情况？]]></description>
      <guid>https://stackoverflow.com/questions/78495190/predicting-playoff-with-machine-learning</guid>
      <pubDate>Fri, 17 May 2024 10:59:02 GMT</pubDate>
    </item>
    <item>
      <title>在 amazon sagemaker jupyter Lab 上传大文件</title>
      <link>https://stackoverflow.com/questions/78495028/uploading-big-files-at-amazon-sagemaker-jupyter-lab</link>
      <description><![CDATA[我需要在亚马逊 sagemaker 上上传大型预训练 pytorch 模型文件，该文件可通过 Huggingface 链接获取，文件大小约为 14GB。我已在 MacBook 本地下载了文件，但是当我在 sagemaker jupyter lab 上上传文件时，需要花费很多时间并且上传速度很慢。有没有任何命令可以使用 jupyter lab 终端轻松上传这个大文件？
文件链接如下：
https://huggingface.co/csuhan/ OneLLM-7B/resolve/main/consolidated.00-of-01.pth]]></description>
      <guid>https://stackoverflow.com/questions/78495028/uploading-big-files-at-amazon-sagemaker-jupyter-lab</guid>
      <pubDate>Fri, 17 May 2024 10:24:22 GMT</pubDate>
    </item>
    <item>
      <title>如何从青光眼检测报告中读取数据[关闭]</title>
      <link>https://stackoverflow.com/questions/78495015/how-to-read-a-data-from-a-glaucoma-detection-report</link>
      <description><![CDATA[我想读取数据并将其转换为矩阵。
我尝试读取数据并将其转换为矩阵形式。
无法理解和读取数据，以便将其转换为矩阵形式。
它实际上是阈值测试的青光眼检测报告]]></description>
      <guid>https://stackoverflow.com/questions/78495015/how-to-read-a-data-from-a-glaucoma-detection-report</guid>
      <pubDate>Fri, 17 May 2024 10:22:15 GMT</pubDate>
    </item>
    <item>
      <title>cnn 模型的纪元大小</title>
      <link>https://stackoverflow.com/questions/78494862/epoch-size-for-cnn-model</link>
      <description><![CDATA[如果我有一个包含大约 200 个样本的数据集，并且我正在应用 CNN，那么我的 epoch 大小应该是多少？
我尝试了 epoch 大小为 50，但结果非常差。
但是当我将 epoch = 5 时，它给出了明显更好的结果，但我不确定正确的 epoch 大小应该是多少。]]></description>
      <guid>https://stackoverflow.com/questions/78494862/epoch-size-for-cnn-model</guid>
      <pubDate>Fri, 17 May 2024 09:52:20 GMT</pubDate>
    </item>
    <item>
      <title>神经网络回归的 Numpy 实现仅学习数据集的第一个样本</title>
      <link>https://stackoverflow.com/questions/78494357/numpy-implementation-of-neural-network-regression-learns-only-first-sample-of-th</link>
      <description><![CDATA[实现一个具有 16（特征）+1（偏差）输入和 1 个输出的回归任务的神经网络，我只使用 numpy 和向量化，当我在训练集上训练它时，输入的第一个样本是只有一个人学得很好，其他人都学了一点，但一点也不好。
我在反向传播操作中做错了什么吗？
通过在训练样本中添加值为 1 的特征，在第一层中实现偏差。
我尝试了不同的学习率和网络维度，但没有任何变化。这是我得到的输出，其中 l 是标签，y 是预测值，前 5 行是损失级数：
&lt;前&gt;&lt;代码&gt;损失：[8702.85226111]
损失：[6.46234854e-27]
损失：[1.61558713e-27]
损失：[4.03896783e-28]
损失：[0。]


左：131.042274 右：[131.042274]
左：64.0 右：[103.78313187]
l：89.429199 y：[30.54333083]
l：111.856492 y：[108.32052489]
左：69.3899 右：[57.11792288]

这是我用于此任务的 Colab 笔记本：
https://colab.research.google.com/drive/1SNEjgZQkmQW9LV8PSxE_Lx4VIQSjf1rP?usp=分享
向后传递：
def向后(l,y,输入,alpha=0.00001):
  l_out.d=o_d(l,y)
  l3.d=h_d(l_out.w,l3.z,l_out.d)
  l2.d=h_d(l3.w,l2.z,l3.d)
  l1.d=h_d(l2.w,l1.z,l2.d)
  #不确定
  l_out.dadw=da_dw(l_out.z,l3.a)
  l3.dadw=da_dw(l3.z,l2.a)
  l2.dadw=da_dw(l2.z,l1.a)
  l1.dadw=da_dw(l1.z,输入.T)

  l_out.e=w_e(l_out.dadw,l_out.d)
  l3.e=w_e(l3.dadw,l3.d)
  l2.e=w_e(l2.dadw,l2.d)
  l1.e=w_e(l1.dadw,l1.d)

  l_out.w=l_out.w-alpha*l_out.e
  l3.w=l3.w-alpha*l3.e
  l2.w=l2.w-alpha*l2.e
  l1.w=l1.w-alpha*l1.e

我正在对每个样本进行向后传递，首先计算输出层的增量，即
&lt;前&gt;&lt;代码&gt;#out 增量
def o_d(l,y):
  返回-(l-y)

然后对隐藏层执行相同的操作
#隐藏的增量
def h_d(w, z, d):
  temp=np.matmul(d.T,w)
  温度=relu_der(z)*温度
  返回温度

现在激活函数相对于每层权重的导数
def da_dw(z,a):
返回 np.outer(relu_der(z), a)

然后我通过执行计算每个权重的误差
def w_e(dadw,d):
  返回 badw * d[:, np.newaxis]

最后我更新了权重]]></description>
      <guid>https://stackoverflow.com/questions/78494357/numpy-implementation-of-neural-network-regression-learns-only-first-sample-of-th</guid>
      <pubDate>Fri, 17 May 2024 08:18:24 GMT</pubDate>
    </item>
    <item>
      <title>具有 n 维卫星图像的多类 UNet</title>
      <link>https://stackoverflow.com/questions/78491587/multiclass-unet-with-n-dimensional-satellite-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78491587/multiclass-unet-with-n-dimensional-satellite-images</guid>
      <pubDate>Thu, 16 May 2024 17:28:46 GMT</pubDate>
    </item>
    <item>
      <title>eval(predvars, data, env) 中的错误：未找到对象“适配器”</title>
      <link>https://stackoverflow.com/questions/78466280/error-in-evalpredvars-data-env-object-adapter-not-found</link>
      <description><![CDATA[我正在尝试在 tf-idf 矩阵上训练随机森林分类器，其中的列是评论中的单词。
获得一个想法：
标签...1实际上是适配器
1 0 0.01495934 0.02880089
2 0 0.00000000 0.00000000
3 0 0.00000000 0.00000000

我使用 train_data 训练了模型，其中标签为 [0] 表示负数，[1] 表示正数。
这是代码：
set.seed(123)
random_forest_model &lt;- 训练（标签...1 ~ .,
               数据=训练数据，
               方法=“rf”，
               trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 10),
               调整网格 = 展开.网格(mtry = 100),
               n树= 500，
               重要性=真）

我想使用经过训练的模型来预测另一个矩阵的评论是正面还是负面。
使用此代码：
# 对测试集进行预测
y_pred &lt;- 预测（random_forest_model，newdata = test_data）

问题是我收到此错误：
eval(predvars, data, env) 中的错误：未找到对象“适配器”

因为并非train_data中存在的所有单词（列）也存在于test_data中。对test_data的评价不同。
该模型的想法是在这种情况下预测评论是正面还是负面。不可能找到总是具有相同单词的矩阵。
我尝试输入 RF 模型数据框而不是矩阵，因为我读到它更好，但它没有解决问题。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78466280/error-in-evalpredvars-data-env-object-adapter-not-found</guid>
      <pubDate>Sat, 11 May 2024 22:55:59 GMT</pubDate>
    </item>
    <item>
      <title>(tflite_flutter) tflite 模型（文本分类）给出相同的结果</title>
      <link>https://stackoverflow.com/questions/76880529/tflite-flutter-tflite-model-text-classification-giving-the-same-result</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76880529/tflite-flutter-tflite-model-text-classification-giving-the-same-result</guid>
      <pubDate>Fri, 11 Aug 2023 03:35:43 GMT</pubDate>
    </item>
    <item>
      <title>错误消息 R - PrettyNum(.Internal(format(x,rim,digits,nsmall,width,3L,：‘digits’参数的值 0 无效”</title>
      <link>https://stackoverflow.com/questions/75961903/error-message-r-prettynum-internalformatx-trim-digits-nsmall-width-3l</link>
      <description><![CDATA[我想知道是否有人可以帮助我识别和解决使用 LCAvarsel 时遇到的错误术语。
就上下文而言，该库旨在用于潜在类别分析中的变量选择。
install.packages(&quot;LCAvarsel&quot;)
install.packages(&quot;poLCA&quot;)
library(LCAvarsel)
library(poLCA)

data(carcinoma)
sel1 &lt;- LCAvarsel(carcinoma) 

返回以下错误：
prettyNum(.Internal(format(x, trim, digits, nsmall, width, 3L, :
&#39;digits&#39; 参数的值 0 无效
https://www.rdocumentation.org/packages/LCAvarsel/versions/1.1/topics/LCAvarsel]]></description>
      <guid>https://stackoverflow.com/questions/75961903/error-message-r-prettynum-internalformatx-trim-digits-nsmall-width-3l</guid>
      <pubDate>Fri, 07 Apr 2023 20:59:28 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 PyTorch 从本地目录导入 MNIST 数据集</title>
      <link>https://stackoverflow.com/questions/64080130/how-to-import-the-mnist-dataset-from-local-directory-using-pytorch</link>
      <description><![CDATA[我正在 PyTorch 中编写一个众所周知的问题 MNIST 手写数字数据库 的代码。我下载了训练和测试数据集（从主网站），包括标记的数据集。数据集格式为t10k-images-idx3-ubyte.gz，提取后为t10k-images-idx3-ubyte。我的数据集文件夹看起来像
&lt;前&gt;&lt;代码&gt;MINST
 数据
  火车图像-idx3-ubyte.gz
  火车标签-idx1-ubyte.gz
  t10k-images-idx3-ubyte.gz
  t10k-labels-idx1-ubyte.gz

现在，我编写了一个代码来加载数据，如下所示
def load_dataset():
    data_path =“/home/MNIST/Data/”
    xy_trainPT = torchvision.datasets.ImageFolder(
        root=data_path，transform=torchvision.transforms.ToTensor()
    ）
    train_loader = torch.utils.data.DataLoader(
        xy_trainPT，batch_size = 64，num_workers = 0，shuffle = True
    ）
    返回train_loader

我的代码显示支持的扩展名是：.jpg、.jpeg、.png、.ppm、.bmp、.pgm、.tif、.tiff、.webp
如何解决这个问题，并且我还想检查我的图像是否已从数据集中加载（仅一个图形包含前 5 个图像）？]]></description>
      <guid>https://stackoverflow.com/questions/64080130/how-to-import-the-mnist-dataset-from-local-directory-using-pytorch</guid>
      <pubDate>Sat, 26 Sep 2020 16:38:11 GMT</pubDate>
    </item>
    <item>
      <title>如何根据信用记录计算信用评分</title>
      <link>https://stackoverflow.com/questions/37712731/how-to-calculate-credit-score-on-the-basis-of-credit-history</link>
      <description><![CDATA[我有一个特定人群的信用历史数据集，我需要计算每个人的信用评分。
我计划是根据信用历史变量计算概率，然后尝试将该概率转换为分数。这种方法行得通吗？或者我应该遵循什么技术或方法？ ]]></description>
      <guid>https://stackoverflow.com/questions/37712731/how-to-calculate-credit-score-on-the-basis-of-credit-history</guid>
      <pubDate>Wed, 08 Jun 2016 20:54:30 GMT</pubDate>
    </item>
    </channel>
</rss>