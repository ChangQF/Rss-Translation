<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 04 Feb 2024 21:11:00 GMT</lastBuildDate>
    <item>
      <title>PyTorch ArrayRef 线性神经网络的无效索引问题</title>
      <link>https://stackoverflow.com/questions/77937339/pytorch-arrayref-invalid-index-problem-with-linear-nn</link>
      <description><![CDATA[我头疼，下面的代码让我晚上睡不着觉：
1 导入火炬
  2 导入torch.nn为nn
  3 导入torch.optim作为optim
  4 将numpy导入为np
  6 个样本 = torch.linspace(0, 100,100) # 生成集合
  7 train_split = int(len(样本)*0.8)
  8 x_train, x_test = 样本[:train_split], 样本[train_split:]
  9 y_labels = 2*samples-4 # 定义函数
 10 y_labels += torch.tensor(np.random.normal(0, 5, len(samples))) # 添加噪声
 13类神经网络（nn.Module）：
 14 def __init__(自我):
 15 超级().__init__()
 16 self.fc1 = nn.Linear(1, 1)
 17 def 向前（自身，x）：
 18 返回 self.fc1(x)
 19 模型 = NeuralNetwork()
 20 loss_func = nn.MSELoss()
 21 优化器 = optim.Adam(model.parameters(), lr=0.001)
 22 num_epochs = 50
 23 代表纪元范围（num_epochs）：
 24 用于输入，zip(x_train, y_labels[:train_split]) 中的标签：
 25
 26 y_pred = model(inputs) # 文件“.../torch/nn/modules/linear.py”，第 116 行，向前
    返回 F.线性(输入, self.weight, self.bias)
运行时错误：ArrayRef：无效索引索引= 18446744073709551615；长度 = 0
 27 损失 = loss_func(y_pred, 标签)
 28 优化器.zero_grad()
 29 损失.backward()
 30 优化器.step()
 31 print(&quot;纪元 %d - 损失: %.4f%&quot; % (纪元, 损失))



这是一个简单的单层事情，而且我做得很直观，所以没有必要称我为傻瓜。
我在几台机器上运行它，没有区别......
附注任何有关进一步改进这些野兽的编写过程的建议将不胜感激！！！]]></description>
      <guid>https://stackoverflow.com/questions/77937339/pytorch-arrayref-invalid-index-problem-with-linear-nn</guid>
      <pubDate>Sun, 04 Feb 2024 19:40:19 GMT</pubDate>
    </item>
    <item>
      <title>不知道如何在此 ML 程序中进行用户输入</title>
      <link>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 r2_score、mean_squared_error

# 加载数据集
dp = pd.read_csv(&#39;https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv&#39;)

# 分离特征（x）和目标变量（y）
y = dp[&#39;logS&#39;]
x = dp.drop(&#39;logS&#39;, 轴=1)

# 分割数据
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)

# 线性回归模型
lr = 线性回归()
lr.fit(x_train, y_train)
y_train_pred_lr = lr.predict(x_train)
y_test_pred_lr = lr.predict(x_test)

# 随机森林回归模型
k1 = RandomForestRegressor（最大深度=2，随机状态=100）
k1.fit(x_train, y_train)
y_train_pred_rf = k1.predict(x_train)
y_test_pred_rf = k1.predict(x_test)

# 评估线性回归模型
y_train_mse_lr =mean_squared_error(y_train, y_train_pred_lr)
y_train_r2_lr = r2_score(y_train, y_train_pred_lr)
y_test_mse_lr = 均方误差(y_test, y_test_pred_lr)
y_test_r2_lr = r2_score(y_test, y_test_pred_lr)

# 评估随机森林回归模型
y_train_mse_rf =mean_squared_error(y_train, y_train_pred_rf)
y_train_r2_rf = r2_score(y_train, y_train_pred_rf)
y_test_mse_rf =mean_squared_error(y_test, y_test_pred_rf)
y_test_r2_rf = r2_score(y_test, y_test_pred_rf)

# 创建数据框
rs_lr = pd.DataFrame({“方法”: [“线性回归”],
                      “训练MSE”：[y_train_mse_lr]，
                      “训练R2”：[y_train_r2_lr]，
                      “测试 MSE”：[y_test_mse_lr]，
                      “测试 R2”：[y_test_r2_lr]})

rs_rf = pd.DataFrame({“方法”: [“随机森林回归器”],
                      “训练MSE”：[y_train_mse_rf]，
                      “训练R2”：[y_train_r2_rf]，
                      “测试 MSE”：[y_test_mse_rf]，
                      “测试 R2”：[y_test_r2_rf]})

# 连接数据帧
结局 = pd.concat([rs_lr, rs_rf],ignore_index=True)
打印（结局）

加载数据集：它使用 Pandas 从 URL 加载数据集。该数据集与分子溶解度相关，包含各种分子描述符。
数据准备：它将特征（x）和目标变量（y）从数据集中分离出来。本例中的目标变量是溶解度的对数 (logS)。
数据拆分：它使用 scikit-learn 中的 train_test_split 函数将数据集拆分为训练集和测试集。训练集用于训练模型，测试集用于评估模型的性能。
模型训练：它使用训练数据训练两个回归模型 - 线性回归模型 (lr) 和随机森林回归模型 (k1)。
预测：它使用经过训练的模型对训练集和测试集进行预测。
模型评估：它使用均方误差 (MSE) 和 R 平方 (R2) 分数评估两个模型的性能。这些指标可以深入了解模型对数据的拟合程度。
创建 DataFrame：它创建两个单独的 DataFrame（rs_lr 和 rs_rf）来存储每个模型的评估指标。
串联：它将两个 DataFrame 连接成一个最终的 DataFrame（结局）。此 DataFrame 总结了两种模型的训练和测试性能。
打印结果：最后，它打印串联的 DataFrame（结局），其中包括线性回归和随机森林回归模型的方法名称、训练 MSE、训练 R2、测试 MSE 和测试 R2。
该程序的目标是比较线性回归和随机森林回归模型在根据描述符预测分子溶解度方面的性能。
我希望用户输入值。那么我该如何修改代码呢？]]></description>
      <guid>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</guid>
      <pubDate>Sun, 04 Feb 2024 18:32:58 GMT</pubDate>
    </item>
    <item>
      <title>在每个点上绘制指向图中线条的箭头</title>
      <link>https://stackoverflow.com/questions/77936741/plot-arrow-on-each-point-towards-the-line-in-graph</link>
      <description><![CDATA[我正在尝试使用 matplotlib 绘制从每个数据点到图表中的线的箭头。

我希望箭头代表每个点和线之间的距离。我怎样才能做到这一点？
这是我的代码：
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np

# 创建一条直线（45度角）
x_line = np.linspace(0, 10, 100)
y_线 = x_线

# 在线周围添加一些随机点
点数 = 20
x_points = np.linspace(2, 8, num_points) # 根据需要调整范围
y_points = x_points + np.random.normal(0, 0.5, num_points) # 添加一些随机性

# 绘制直线
plt.plot(x_line, y_line, label=&#39;Line&#39;, color=&#39;blue&#39;)

# 绘制点
plt.scatter(x_points, y_points, label=&#39;点&#39;, color=&#39;红色&#39;)

# 设置标签和标题
plt.xlabel(&#39;X轴&#39;)
plt.ylabel(&#39;Y轴&#39;)
plt.title(&#39;围绕一条线的散点图&#39;)

# 显示图例
plt.图例()

# 显示绘图
plt.show()

我自己尝试这样做但失败了：

代码：
导入 matplotlib.pyplot 作为 plt
将 numpy 导入为 np

# 创建一条直线（45度角）
x_line = np.linspace(0, 10, 100)
y_线 = x_线

# 在线周围添加一些随机点
点数 = 20
x_points = np.linspace(2, 8, num_points) # 根据需要调整范围
y_points = x_points + np.random.normal(0, 0.5, num_points) # 添加一些随机性

# 绘制直线
plt.plot(x_line, y_line, label=&#39;Line&#39;, color=&#39;blue&#39;)

# 绘制点
plt.scatter(x_points, y_points, label=&#39;点&#39;, color=&#39;红色&#39;)

# 添加从每个点到直线的箭头
对于 zip(x_points, y_points) 中的 x, y：
    plt.arrow(x, y, 0, y - x, color=&#39;black&#39;, linestyle=&#39;dashed&#39;, linewidth=0.5, head_width=0.2)

# 设置标签和标题
plt.xlabel(&#39;X轴&#39;)
plt.ylabel(&#39;Y轴&#39;)
plt.title(&#39;围绕一条线的散点图&#39;)

# 显示图例
plt.图例()

# 显示绘图
plt.show()

正如您所看到的，数据点发生了移动，箭头指向外侧，而不是向内或指向直线。]]></description>
      <guid>https://stackoverflow.com/questions/77936741/plot-arrow-on-each-point-towards-the-line-in-graph</guid>
      <pubDate>Sun, 04 Feb 2024 17:00:07 GMT</pubDate>
    </item>
    <item>
      <title>探索模型加载、推理和内存管理的基本概念，以实现 OpenVINO 中与设备无关的高效处理</title>
      <link>https://stackoverflow.com/questions/77936078/exploring-fundamental-concepts-in-model-loading-inference-and-memory-managemen</link>
      <description><![CDATA[在之前的开发工作中，该人还发起了 OpenVINO CSharp API 项目。基本实现是调用OpenVINO提供的C API接口并封装在上层。
但是，OpenVINO 当前的 C API 仅实现了大部分接口，部分功能尚未实现。因此，开发者无法在 C# 和 C 语言中充分体验 OpenVINO 的所有功能。
该人表达了与其他开发人员合作增强未实现的 C API 接口的愿望。作为说明，当前发布的C API包括用于设置“比例”的接口。和“平均”。然而，它目前仅支持将所有通道设置为相同的参数，缺乏对每个通道参数进行不同设置的能力。具体问题和建议的改进可以在以下 GitHub 链接中找到：[OpenVINO GitHub Issue #22001](https://github.com/openvinotoolkit/openvino/issues/22001）。
到目前为止，我已经深入研究了以下基本概念：
1.加载和管理模型。
2.进行推理。
3.实施与设备无关的解决方案。
4.了解同步和异步推理。
5.有效管理内存。
6.实施预处理和后处理技术。]]></description>
      <guid>https://stackoverflow.com/questions/77936078/exploring-fundamental-concepts-in-model-loading-inference-and-memory-managemen</guid>
      <pubDate>Sun, 04 Feb 2024 14:03:19 GMT</pubDate>
    </item>
    <item>
      <title>无效路径、路径未指向有效文件、注释图像</title>
      <link>https://stackoverflow.com/questions/77935509/invalid-path-path-not-pointing-to-a-valid-file-annotating-images</link>
      <description><![CDATA[我正在尝试为我想要创建的机器学习模型注释图像，但出现以下错误：
&lt;块引用&gt;
注释 C:\mypath\Post_Event_Images_In_JPEG\tile_12_26.jpg 并保存到 C:\mypath\AnnotatedImages\annotated_after_tile_12_26.jpg
注释 C:\mypath\Post_Event_Images_In_JPEG\tile_12_26.jpg 时出错：无效路径，路径未指向有效文件。

代码如下：
导入操作系统
将 numpy 导入为 np
从 PIL 导入图像
从 tifffile 导入 imread、imwrite
导入光栅
从 rasterio.transform 导入 from_origin
进口舒蒂尔
导入子流程

将张量流导入为 tf
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D，MaxPooling2D，UpSampling2D，BatchNormalization，激活
从tensorflow.keras.optimizers导入Adam
从 sklearn.model_selection 导入 train_test_split
从 imageai.Detection 导入 ObjectDetection

defpair_images(文件夹前、文件夹后、图像数):
    before_images = os.listdir(before_folder)[:num_images]
    after_images = os.listdir(after_folder)[:num_images]

    图像对 = {}

    对于 before_images 中的 before_image：
        common_part = os.path.splitext(before_image)[0]
        after_image = f“{common_part}.jpg”

        如果 after_image 在 after_images 中：
            image_pairs[common_part] = (os.path.join(before_folder, before_image), os.path.join(after_folder, after_image))
        别的：
            print(f“警告：未找到 {before_image} 的后图像”)

    返回图像对


def annotate_image(图像路径, 输出路径):
    检测器 = 对象检测()
    detector.setModelTypeAsRetinaNet()
    detector.setModelPath(“path/to/resnet50_coco_best_v2.1.0.h5”) # 从 https://github.com/OlafenwaMoses/ImageAI/releases/tag/essential-v4 下载此文件
    detector.loadModel()

    print(f“检测{image_path}中的对象”)
    检测= detector. detectorObjectsFromImage(
        输入图像=图像路径，
        输出图像路径=输出路径，
        最小百分比概率=30
    ）

    print(“检测到的对象：”)
    用于检测中的检测：
        print(f&quot;{检测[&#39;名称&#39;]} - {检测[&#39;百分比概率&#39;]}&quot;)

    print(f“{image_path} 的注释已完成”)

def main():
    # 指定“之前”的路径和“之后”图像文件夹
    before_folder = r“C:\Users\Erevos\Desktop\EYContest\Pre_Event_Images_In_JPEG”
    after_folder = r“C:\Users\Erevos\Desktop\EYContest\Post_Event_Images_In_JPEG”
    output_folder = r“C:\Users\Erevos\Desktop\EYContest\AnnotatedImages”

    # 获取图像对
    要注释的图像数量 = 500
    image_pairs =pair_images(before_folder, after_folder, num_images_to_annotate)

    # 使用 ImageAI 注释前 500 张图像
    os.makedirs（输出文件夹，exist_ok = True）
    
    对于 image_pairs.items() 中的 common_part，(before_image, after_image)：
        annotated_before_path = os.path.join(output_folder, f&quot;annotated_before_{common_part}.jpg&quot;)
        annotated_after_path = os.path.join(output_folder, f&quot;annotated_after_{common_part}.jpg&quot;)

        print(f“注释 {before_image} 并保存到 {annotated_before_path}”)
        尝试：
            注释_图像（之前_图像，注释_之前_路径）
        除了异常 e：
            print(f&quot;注释 {before_image} 时出错：{e}&quot;)

        print(f“注释 {after_image} 并保存到 {annotated_after_path}”)
        尝试：
            注释图像（后图像，注释后路径）
        除了异常 e：
            print(f&quot;注释 {after_image} 时出错：{e}&quot;)

    print(&quot;注释并保存完成。&quot;)

如果 __name__ == “__main__”：
    主要的（）

请注意，我已手动创建文件夹来检查是否是这种情况，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/77935509/invalid-path-path-not-pointing-to-a-valid-file-annotating-images</guid>
      <pubDate>Sun, 04 Feb 2024 11:06:05 GMT</pubDate>
    </item>
    <item>
      <title>ImageNet 的多标签分类映射到 16 个类别</title>
      <link>https://stackoverflow.com/questions/77935339/multi-label-classification-of-imagenet-mapped-to-16-classes</link>
      <description><![CDATA[我想在三个数据集上训练一个模型 - 标准 ImageNet (IN)、ImagetNet-a (IN-a) 和 Stylized-ImageNet (SIN)。 SIN 将 1000 个 IN 类别映射到仅 16 个类别，例如“airplane”代表 IN 标签 404，“bear”代表 IN 标签 294、295、296、297。为了在此数据集上训练模型，我对 16 个 SIN 类 [0,...,0,1,0,...] 进行了 One-hot 编码。为了测试，我做了同样的事情，但我制作了 SIN 数据集的副本及其原始类标签（0-15，通过 ImageFolder 导入）。
SIN 的作者提供了一种建立（单标签）测试函数的简单方法，如其 GitHub 上所示 存储库。
作为此多标签任务的另一种测试方法，我使用 Pytorch 实现了以下功能：
def multi_l_eval（模型，test_loader）：
  模型.eval()
  正确 = 0
  总计 = 0
  灵敏度=0.5
  使用 torch.no_grad()：
      对于图像，test_loader 中的标签：
          图像、标签 = images.to(设备)、标签.to(设备)
          输出=模型（图像）
          输出 = torch.sigmoid(输出)

          输出[输出&gt;=灵敏度] = 1
          输出[输出&lt;灵敏度] = 0

          正确+=（输出==标签）.sum()

          总计 += labels.size(0)*labels.size(1)
  返回（正确/总计）*100

ImageNet-a
此外，我想在 IN-a 上训练模型（IN adversarial示例数据集）和 SIN，我也是通过对 IN-a 数据集进行 one-hot 编码来实现的。在 IN-a 数据集（多标签）上训练模型后，与 IN-a git 存储库中所示的（单标签）测试方法相比，我的函数产生了更高的测试准确性。
问题
现在，当比较单标签测试方法和我的函数的结果时，我的函数输出完全不同、更高的准确率百分比。我实现的函数是分析多标签性能的正确方法吗？
我发现一些信息，在多标签分类中需要平衡类。我将如何平衡 SIN 的类别标签以及不同数量的正确标签，正如“飞机”和“熊”的示例中已经提到的那样？此外，如何针对多个不同的数据集实现这种平衡？
训练方法
def std_train_model (模型,train_loader, opt, num_epochs):
  model.train() # 将模型设置为训练模式
  crit = nn.BCEWithLogitsLoss()
  对于范围内的纪元（num_epochs）：
      运行损失 = 0.0
      对于输入，train_loader 中的标签：
          输入，标签=输入.to（设备），标签.to（设备）
          opt.zero_grad()
          输出 = 模型（输入）
          损失=暴击（输出，标签）
          loss.backward()
          opt.step()

          running_loss += loss.item()

      print(f&#39;Epoch {epoch + 1}/{num_epochs}，损失：{running_loss / len(train_loader)}&#39;)

  print(&quot;训练完成&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/77935339/multi-label-classification-of-imagenet-mapped-to-16-classes</guid>
      <pubDate>Sun, 04 Feb 2024 10:11:25 GMT</pubDate>
    </item>
    <item>
      <title>更改房间图像中的地板纹理[关闭]</title>
      <link>https://stackoverflow.com/questions/77935330/change-the-floor-texture-in-a-room-image</link>
      <description><![CDATA[我正在尝试创建一个房间可视化工具，用户可以在其中上传他们的房间图像，并可以将不同的纹理应用到地板上。我成功地使用 roboflow 中的地板分割模型提取图像中的地板坐标，并将纹理图像应用到坐标上，现在的问题是纹理在某些图像上看起来很好，但在某些图像上看起来更糟。我知道我做错了什么，任何人都可以建议一种方法来处理分段蒙版上的纹理应用程序。我正在附加我得到的输出图像  
这是我现在实际做的事情的逻辑
 来自 PIL 导入图像
    将 numpy 导入为 np
    将 matplotlib.pyplot 导入为 plt
    从 io 导入 BytesIO
    导入base64
    从 roboflow 导入 Roboflow
    
    rf = Roboflow(api_key=&quot;key&quot;)
    项目 = rf.workspace().project(“名称”)
    模型 = 项目.版本(1).模型
    
    # 推断本地图像
    # print(model.predict(“room3.jpg”).json())
    
    # 加载房间和纹理图像
    room_image_path = &#39;newwww.jpg&#39;
    纹理图像路径 = &#39;tex3.jpg&#39;
    房间图像 = Image.open(房间图像路径)
    纹理图像 = Image.open(纹理图像路径)
    
    # 显示房间图像
    # plt.imshow(房间图像)
    # plt.title(&#39;房间图片&#39;)
    # plt.axis(&#39;关闭&#39;)
    # plt.show()
    
    # 显示纹理图像
    # plt.imshow(纹理图像)
    # plt.title(&#39;纹理图像&#39;)
    # plt.axis(&#39;关闭&#39;)
    # plt.show()
    
    # JSON 数据
    json_data = model.predict(“newwww.jpg”).json()
    
    # 提取楼层坐标
    Floor_data = json_data[&#39;预测&#39;][0]
    Floor_points = Floor_data[&#39;点&#39;]
    
    # 创建点的元组列表
    Floor_coordinates = [(point[&#39;x&#39;], point[&#39;y&#39;]) for Floor_points 中的点]
    
    # 打印提取的楼层坐标
    print(&#39;提取的楼层坐标：&#39;)
    打印（地板坐标）
    
    
    # 根据地板坐标创建遮罩的函数
    从 matplotlib.path 导入路径
    
    def create_mask_from_points(image_size, 点):
        # 创建点网格
        y, x = np.mgrid[:image_size[1], :image_size[0]]
        点 = np.array(点)
        路径=路径（点）
        mask = path.contains_points(np.vstack((x.ravel(), y.ravel())).T)
        mask = mask.reshape((image_size[1], image_size[0]))
        返回掩码
    
    # 为地板创建遮罩
    mask = create_mask_from_points(room_image.size, 地板坐标)
    
    # 将纹理叠加在房间图像上
    # 为简单起见，调整纹理大小以匹配房间图像大小
    调整大小的纹理=纹理图像.调整大小（房间图像.大小）
    
    # 使用遮罩来组合图像
    room_with_texture = np.array(room_image)
    room_with_texture[掩码] = np.array(resized_texture)[掩码]
    
    # 转换回图像
    room_with_texture_image = Image.fromarray(room_with_texture)
    
    # 保存结果
    输出图像路径 = &#39;final2.jpg&#39;
    room_with_texture_image.save（输出图像路径）
    
    # 显示结果
    plt.imshow(room_with_texture_image)
    plt.title(&#39;带有纹理叠加的房间&#39;)
    plt.axis(&#39;关闭&#39;)
    plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/77935330/change-the-floor-texture-in-a-room-image</guid>
      <pubDate>Sun, 04 Feb 2024 10:08:55 GMT</pubDate>
    </item>
    <item>
      <title>法学硕士中的温度：它如何影响随机性[关闭]</title>
      <link>https://stackoverflow.com/questions/77935310/temperature-in-llms-how-it-impacts-randomness</link>
      <description><![CDATA[在研究 openapi 和其他 LLM 的代码示例时，我发现了非常常用的参数“温度”。
我无法理解其背后的想法。
在线消息来源称，它告诉 llm 可以在多大程度上随机。
我的问题是，如果法学硕士甚至不确定其生成的内容中是否存在随机性（这就是为什么我们将温度值传递给它，不是），那么它如何找出生成的内容的哪一部分是随机的过滤它。]]></description>
      <guid>https://stackoverflow.com/questions/77935310/temperature-in-llms-how-it-impacts-randomness</guid>
      <pubDate>Sun, 04 Feb 2024 10:03:40 GMT</pubDate>
    </item>
    <item>
      <title>拟合和评估模型需要多少时间？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77907135/how-much-time-is-required-to-fit-and-evaluate-a-model</link>
      <description><![CDATA[我想计算每个模型的时间复杂度（LR，DS，k-NN，SVM 和 ANN）找出与时间相比精度最高的最佳模型。为此，我实现了代码。
start_time = perf_counter()
logModel = LogisticRegression()
logModel.fit(X_train, Y_train)

# 训练数据的准确性
x_train_prediction = logModel.predict(X_train)
训练数据准确度 = 准确度得分（x_train_预测，Y_train）
print(&#39;训练数据的准确性:,&#39;,training_data_accuracy)

# 测试数据的准确性
x_test_prediction = logModel.predict(X_test)
test_data_accuracy = precision_score(x_test_prediction, Y_test)
print(&#39;测试数据的准确率得分：&#39;, test_data_accuracy)
生成_模型_报告（Y_测试，x_测试_预测）
结束时间 = perf_counter()
经过时间 = 结束时间 - 开始时间

print(&quot;经过时间：&quot;, elapsed_time)

在此代码中，我在这里使用elapsed_time来计算所需的时间逻辑回归模型。我的代码可以计算时间吗？]]></description>
      <guid>https://stackoverflow.com/questions/77907135/how-much-time-is-required-to-fit-and-evaluate-a-model</guid>
      <pubDate>Tue, 30 Jan 2024 14:33:04 GMT</pubDate>
    </item>
    <item>
      <title>无法在python中安装lap==0.4.0库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类算法的训练类型与测试误差（评估方差）</title>
      <link>https://stackoverflow.com/questions/70836956/types-of-training-vs-test-error-for-random-forest-classification-algorithm-asse</link>
      <description><![CDATA[如果可能的话，我想确定两个问题（问题以粗体显示）：
我最近了解了（我希望）随机森林分类算法，并尝试使用 Python 上的 sklearn 将其应用于从卫星图像派生的相当大的像素数据集（其特征是不同的波段，并且标签是我自己概述的特定特征，即植被、云等）。然后我想了解模型是否遇到方差问题，因此我想到的第一个想法是比较训练数据和测试数据。
现在这就是我感到困惑的地方 - 我知道有很多不同的帖子：

与袋外 (OOB) 错误相比，应该/不应该使用 CV 错误
按照设计，随机森林分类器的训练误差几乎总是~0（即，将我的模型拟合到训练数据上并使用它来预测同一组训练数据） - 无论如何，情况似乎都是如此树的深度

关于第 2 点，我似乎永远无法比较我的训练误差和测试误差，因为前者总是很低，因此我决定使用 OOB 误差作为整个模型的“代表性”训练误差。然后我意识到 OOB 错误可能是伪测试错误，因为它本质上是在树没有专门学习的点上测试树（在引导树的情况下），因此我默认将 CV 错误作为我的新“代表性”训练错误对于整个模型。
回顾 CV 误差的用法，我最初将其用于超参数调整（例如，最大树深度、树数量、标准类型等），因此我再次怀疑自己是否应该将其用作我的将官方训练错误与我的测试错误进行比较。
更糟糕的是，我很难根据网络上的帖子来验证我认为正确的内容，因为每个答案只回答了一小部分，并且可能相互矛盾，因此任何人都可以帮助我困境在于使用什么作为我的官方训练错误来与我的测试错误进行比较？
我的第二个问题围绕 OOB 错误如何可能是基于引导期间未选择的数据点的伪测试错误。如果这是真的，如果禁用引导，可以公平地说这不成立吗（该算法在技术上仍然是随机森林，因为特征仍然对每棵树进行随机子采样，只是相关性树之间可能更高）？]]></description>
      <guid>https://stackoverflow.com/questions/70836956/types-of-training-vs-test-error-for-random-forest-classification-algorithm-asse</guid>
      <pubDate>Mon, 24 Jan 2022 16:14:46 GMT</pubDate>
    </item>
    <item>
      <title>Keras：如果我用标准化数据训练模型，model.predict() 是否需要标准化数据？</title>
      <link>https://stackoverflow.com/questions/68119256/keras-does-model-predict-require-normalized-data-if-i-train-the-model-with-no</link>
      <description><![CDATA[使用 Keras 完成模型训练后，我尝试使用 Keras 的 model.predict() 来测试新颖输入的模型。
训练模型时，我使用 Scikit Learn 的 MinMaxScaler() 对训练数据进行标准化。
使用 model.predict() 时是否还需要标准化数据？如果是这样，我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/68119256/keras-does-model-predict-require-normalized-data-if-i-train-the-model-with-no</guid>
      <pubDate>Thu, 24 Jun 2021 16:10:03 GMT</pubDate>
    </item>
    <item>
      <title>随机森林算法中的置信度与概率</title>
      <link>https://stackoverflow.com/questions/45810720/confidence-vs-probability-in-random-forest-algorithm</link>
      <description><![CDATA[我一直在尝试使用 scikit-learn 运行随机森林分类器。我想了解概率和置信度之间的区别。假设我们有 5 个类别 A、B、C、D、E 。现在，如果我运行 predict_proba() 并获得 A 类的匹配项，返回的概率是否是 5 个类中 A 类的概率？这意味着如果 A 类的概率为 0.95，那么剩余的 0.05 会为其余类共享？如果是这样的话，我想了解是否有办法获得预测的置信度，这意味着分类器以 0.95 的概率预测 A 类的置信度有多大？有这样的机制吗？
我想了解这一点的原因是因为假设我输入的分类数据不属于这 5 个类别中的任何一个，我想抛出它不属于这 5 个类别中的任何一个类。我觉得分类器目前会尝试将其放入 5 个类别之一，并且可能会返回很高的概率？即使它对此没有信心？]]></description>
      <guid>https://stackoverflow.com/questions/45810720/confidence-vs-probability-in-random-forest-algorithm</guid>
      <pubDate>Tue, 22 Aug 2017 06:50:28 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 pred_proba 输出四舍五入值</title>
      <link>https://stackoverflow.com/questions/31141133/random-forest-pred-proba-outputs-rounded-off-values</link>
      <description><![CDATA[我在 scikit learn 中使用随机森林进行分类并获取类概率，我使用了 pred_proba 函数。但它输出的概率四舍五入到小数点后第一位
我尝试使用示例虹膜数据集
iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df[&#39;is_train&#39;] = np.random.uniform(0, 1, len(df)) &lt;= .75
df[&#39;物种&#39;] = pd.Categorical(iris.target, iris.target_names)
df.head()

训练，测试 = df[df[&#39;is_train&#39;]==True]，df[df[&#39;is_train&#39;]==False]

特征 = df.columns[:4]
clf = 随机森林分类器(n_jobs=2)
y, _ = pd.factorize(train[&#39;物种&#39;])
clf.fit(训练[特征], y)
clf.predict_proba(训练[特征])

输出概率

&lt;前&gt;&lt;代码&gt; [ 1. , 0. , 0. ],
   [ 1. , 0. , 0. ],
   [ 1. , 0. , 0. ],
   [ 1. , 0. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 0.8, 0.2],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],
   [ 0. , 1. , 0. ],

这是默认输出吗？可以增加小数位数吗？
注意：
找到了解决方案。
默认编号增加树数后，树数=10。树数达到百时，概率的精度提高了。 ]]></description>
      <guid>https://stackoverflow.com/questions/31141133/random-forest-pred-proba-outputs-rounded-off-values</guid>
      <pubDate>Tue, 30 Jun 2015 14:30:47 GMT</pubDate>
    </item>
    <item>
      <title>随机森林：%IncMSE 和 %NodePurity 之间不匹配</title>
      <link>https://stackoverflow.com/questions/16465109/random-forest-mismatch-between-incmse-and-nodepurity</link>
      <description><![CDATA[我在一个相当小的数据集（即 11 个变量的 28 个观测值）上对 100,000 个分类树进行了随机森林分析。
然后我绘制了变量重要性的图
在结果图中，至少有一个重要变量的 %IncMSE 和 IncNodePurity 之间存在严重不匹配。事实上，该变量的重要性在前者中排名第七（即 %IncMSE&lt;0），但在后者中排名第三。
我应该如何解释这种不匹配？
所讨论的变量与在两张图中始终排在第二位的另一个变量显着相关。这可能是一个线索吗？]]></description>
      <guid>https://stackoverflow.com/questions/16465109/random-forest-mismatch-between-incmse-and-nodepurity</guid>
      <pubDate>Thu, 09 May 2013 15:10:33 GMT</pubDate>
    </item>
    </channel>
</rss>