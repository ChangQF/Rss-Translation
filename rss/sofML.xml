<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 22 Jul 2024 15:17:25 GMT</lastBuildDate>
    <item>
      <title>PyBullet 的 Walker2D 的关节角度</title>
      <link>https://stackoverflow.com/questions/78778576/joint-angles-of-pybullets-walker2d</link>
      <description><![CDATA[我正在使用 pybullet_envs 中的 Walker2D 环境，并尝试获取 6 个关节角度，以便将它们用于由 Arduino 控制的实际双足机器人。
我尝试过但未能找到文档，例如 gym 中的文档，其中指定了 6 个关节角度的索引，并且它们的值由 rad 测量。我发现有人指出，在 pybullet_envs GitHub 文档中，有评论说关节位置是观察空间的偶数元素。我认为这从 Walker2D 环境的每个列的数组索引 8 开始是正确的。我的问题是我不知道这些值的单位，我不确定它们是否正确。有没有更简单的方法可以通过物理客户端 ID 和机器人 ID 通过环境访问实际值（rad 或 deg）？]]></description>
      <guid>https://stackoverflow.com/questions/78778576/joint-angles-of-pybullets-walker2d</guid>
      <pubDate>Mon, 22 Jul 2024 12:02:18 GMT</pubDate>
    </item>
    <item>
      <title>如何在 RGB 图像中找到已知尺寸的立方体的角？</title>
      <link>https://stackoverflow.com/questions/78778435/how-can-i-find-the-corners-of-a-cube-with-known-dimensions-in-an-rgb-image</link>
      <description><![CDATA[如何在 RGB 图像中实时找到已知尺寸（每边 30 厘米）立方体的角？立方体将是单色（一种颜色），但颜色信息未知。
我搜索了 2d 关键点检测器，但不确定使用哪一个以及如何使用]]></description>
      <guid>https://stackoverflow.com/questions/78778435/how-can-i-find-the-corners-of-a-cube-with-known-dimensions-in-an-rgb-image</guid>
      <pubDate>Mon, 22 Jul 2024 11:29:29 GMT</pubDate>
    </item>
    <item>
      <title>多个数据集的集成方法</title>
      <link>https://stackoverflow.com/questions/78777745/ensemble-methods-for-multiple-datasets</link>
      <description><![CDATA[我有 5 个数据集，我想用它们来预测一个特征。我想将 5 个数据集的预测组合起来，做出一个最终预测。考虑到不同数据集的性质，将数据集组合成一个数据集似乎不是一个可行的选择。据我所知，大多数现有的集成方法都需要使用相同的数据集来组合预测，有没有办法用多个数据集来做到这一点？
我尝试过对结果取平均值，并尝试使用 5 组预测作为输入来制作元模型，但我觉得应该有更好的方法来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78777745/ensemble-methods-for-multiple-datasets</guid>
      <pubDate>Mon, 22 Jul 2024 08:50:13 GMT</pubDate>
    </item>
    <item>
      <title>多类别分类选择机器学习模型</title>
      <link>https://stackoverflow.com/questions/78777697/multi-class-classification-selecting-machine-learning-model</link>
      <description><![CDATA[在多类分类问题中，使用神经网络通常比使用 svm 模型更好吗？
这是我用数据制作的图。
计算 PCA 并使用 SVM 进行线性分类对我来说会更好吗？scatterplot3d
pca visuslization
那么当我得到这个准确度指标时。我保留代码可以吗？准确度]]></description>
      <guid>https://stackoverflow.com/questions/78777697/multi-class-classification-selecting-machine-learning-model</guid>
      <pubDate>Mon, 22 Jul 2024 08:40:05 GMT</pubDate>
    </item>
    <item>
      <title>GPy 回归中的输出 Gram 矩阵</title>
      <link>https://stackoverflow.com/questions/78776963/output-gram-matrix-in-gpy-regression</link>
      <description><![CDATA[因为我需要在大量点上训练我的高斯过程 (GP)，所以我不仅想保存优化的超参数
ker = GPy.kern.Matern32(nc, ARD=True) 
m = GPy.models.GPRegression(xTrain, np.reshape(yTrain, (-1, 1)), ker, noise_var=1e-8)
m.Mat32.lengthscale.constrain_bounded(0.01, 5e0)
m.Mat32.variance.constrain_bounded(1e-4, 1e+10)
m.Gaussian_noise.variance.constrain_fixed(1e-8)

m.optimize_restarts(messages=True, num_restarts=1, max_f_eval=10000)
np.save(f, m.param_array)

yPrd, yVar = m.predict_noiseless(xTest)
yStd = np.sqrt(yVar)
yPred = np.squeeze(yPrd)

但也要保存 Gram 矩阵与观察到的 值 K(s,s)^{-1} f 的乘积
后验的平均值 = K(s^*,s)K(s,s)^{-1} f
因此加载 块 K(s,s)^{-1} f 并仅与相应的测试 点 K(s^*,s) 执行一次乘法。我如何访问/输出这些矩阵/保存它们？]]></description>
      <guid>https://stackoverflow.com/questions/78776963/output-gram-matrix-in-gpy-regression</guid>
      <pubDate>Mon, 22 Jul 2024 04:33:20 GMT</pubDate>
    </item>
    <item>
      <title>无法重现 ViTImageProcessor 变压器库的预处理</title>
      <link>https://stackoverflow.com/questions/78776752/cannot-reproduction-vitimageprocessor-preprocessing-of-transformers-library</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78776752/cannot-reproduction-vitimageprocessor-preprocessing-of-transformers-library</guid>
      <pubDate>Mon, 22 Jul 2024 02:25:58 GMT</pubDate>
    </item>
    <item>
      <title>使用python图像去噪没有得到想要的重建图像</title>
      <link>https://stackoverflow.com/questions/78776540/not-getting-desired-reconstructed-image-with-python-image-denoising</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78776540/not-getting-desired-reconstructed-image-with-python-image-denoising</guid>
      <pubDate>Sun, 21 Jul 2024 23:19:13 GMT</pubDate>
    </item>
    <item>
      <title>更改 YoloV8 分割颜色</title>
      <link>https://stackoverflow.com/questions/78776522/change-yolov8-segmentation-color</link>
      <description><![CDATA[我是 YoloV8 训练任务的新手，想了解如何更改模型执行的分割颜色。
如能提供任何帮助和指导，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78776522/change-yolov8-segmentation-color</guid>
      <pubDate>Sun, 21 Jul 2024 23:11:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Yolo 3D 中获取边界框标签及其格式</title>
      <link>https://stackoverflow.com/questions/78776364/how-to-get-bounding-box-labels-and-its-format-in-yolo-3d</link>
      <description><![CDATA[我已经在工作区中实现了 Yolo 3D 模型，并且运行良好。我得到了一个图像作为输出。所以我想知道在哪里可以得到我的 3D 边界框的标签。我甚至想知道标签的存储格式是什么。
x,y,x,y... 格式或 x,y,z,x,y,z... 格式。
(编辑)
我已经实现了 Yolo 3D 模型：
https://github.com/ruhyadi/YOLO3D
我下载了预训练的权重，并使用以下命令运行推理：
python inference.py \
--weights yolov5s.pt \
--source eval/image_2 \
--reg_weights weights/resnet18.pkl \
--model_select resnet18 \
--output_path runs/ \
--show_result --save_result

现在在运行文件夹中，我仅获得 PNG 图像作为输出。我的输出是：

现在我甚至想获取此图像中 3D 边界框的点，我甚至想知道这些点的存储格式是 x,y,x,y.. 格式还是 x,y,z,x,y,z.. 格式？]]></description>
      <guid>https://stackoverflow.com/questions/78776364/how-to-get-bounding-box-labels-and-its-format-in-yolo-3d</guid>
      <pubDate>Sun, 21 Jul 2024 21:16:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Flux.jl 中的 RNN 层？</title>
      <link>https://stackoverflow.com/questions/78776287/how-to-use-the-rnn-layer-in-flux-jl</link>
      <description><![CDATA[我对这个 Flux.jl NN 做错了什么？
我的 batch_size=5 和 num_features = 1200
如果我想输入 (num_timesteps, num_features)，RNN 层如何工作？
Flux.Chain(
Flux.RNN(num_features, 32, tanh, init=Flux.glorot_normal), 
Flux.Dropout(0.2),
Flux.flatten,
Flux.Dense(32*batch_size, output_size,identity;bias = false)
)

错误：
DimensionMismatch：层 Dense(160 =&gt; 1;bias=false) 期望 size(input, 1) == 160，但得到的是 32×5矩阵{Float32}
]]></description>
      <guid>https://stackoverflow.com/questions/78776287/how-to-use-the-rnn-layer-in-flux-jl</guid>
      <pubDate>Sun, 21 Jul 2024 20:22:24 GMT</pubDate>
    </item>
    <item>
      <title>计算计算机断层扫描的内轮廓</title>
      <link>https://stackoverflow.com/questions/78775537/calculate-the-inner-contour-of-a-computed-tomography</link>
      <description><![CDATA[我正在做一个计算胸部畸形程度的项目。
为此，我需要从断层扫描中找到胸部的内轮廓；但是，我不知道如何选择内轮廓。
首先，我将图像转换为二进制并应用阈值。
import cv2
import numpy as np
from PIL import Image

import matplotlib.pyplot as plt

def process_and_plot(image_path):
def process(image_path):
image = cv2.imread(image_path)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
blur_image = cv2.GaussianBlur(gray_image, (5, 5), 0)
_, binary_image = cv2.threshold(blurred_image, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
return binary_image

fig, axis = plt.subplots(1, 2，figsize=(10，5))

img = Image.open(image_path)
axes[0].imshow(img，cmap=&#39;gray&#39;)
axes[0].set_title(&#39;Original Image&#39;)

processed_image = process(image_path)
axes[1].imshow(processed_image，cmap=&#39;gray&#39;) 
axes[1].set_title(&#39;Processed Image&#39;)

plt.show()

process_and_plot(&#39;test.jpeg&#39;)



我期望得到红色轮廓。
]]></description>
      <guid>https://stackoverflow.com/questions/78775537/calculate-the-inner-contour-of-a-computed-tomography</guid>
      <pubDate>Sun, 21 Jul 2024 15:02:37 GMT</pubDate>
    </item>
    <item>
      <title>将不规则 Excel 布局自动转换为结构化数据集的技术 [关闭]</title>
      <link>https://stackoverflow.com/questions/78768436/techniques-to-automate-transformation-of-irregular-excel-layouts-to-structured-d</link>
      <description><![CDATA[我面临的挑战是将不规则的 Excel 布局自动转换为结构化数据集。这些 Excel 文件通常包含：
合并单元格
分层列
注释和说明……如下所示：在此处输入图像描述
目标：
我想将这些复杂的 Excel 布局转换为计算机可以理解的结构化数据集，从而实现无缝的数据可视化和解释。
可以使用哪些技术或工具来自动化此转换过程？是否有任何机器学习模型、数据预处理技术或软件工具可以帮助标准化和结构化这些不同的 Excel 文件？]]></description>
      <guid>https://stackoverflow.com/questions/78768436/techniques-to-automate-transformation-of-irregular-excel-layouts-to-structured-d</guid>
      <pubDate>Fri, 19 Jul 2024 08:53:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAN 进行欺诈检测</title>
      <link>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</link>
      <description><![CDATA[我正在使用 GAN 实现基于交易的欺诈检测模型，但我仍然想指定我的模型，即我想强调 RIB 和交易时间（尤其是发行时间）我想知道个人通过这些变量（时间和 RIB）的行为如何影响交易是否是欺诈性的。基本上，这个模型很好，但它仍然很肤浅，我们需要通过强调提到的变量来更深入地研究。
我的数据集的头部
就像我说的，我尝试了一个通用的 GAN 模型，但我想实现一个专注于 RIB 和发行时间的指定 GAN 模型]]></description>
      <guid>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</guid>
      <pubDate>Wed, 17 Jul 2024 19:15:59 GMT</pubDate>
    </item>
    <item>
      <title>TypeError: 无法将函数返回值转换为 Python 类型！签名为 () -> handle anaconda spyder</title>
      <link>https://stackoverflow.com/questions/72179285/typeerror-unable-to-convert-function-return-value-to-a-python-type-the-signatu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/72179285/typeerror-unable-to-convert-function-return-value-to-a-python-type-the-signatu</guid>
      <pubDate>Mon, 09 May 2022 23:48:41 GMT</pubDate>
    </item>
    <item>
      <title>在 MultiLabelBinarizer 中获取计数</title>
      <link>https://stackoverflow.com/questions/56372324/getting-counts-in-multilabelbinarizer</link>
      <description><![CDATA[如何获取 MultiLabelBinarizer 中的项目数？
import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
mlb = MultiLabelBinarizer()

pd.DataFrame(mlb.fit_transform([(1,1,2), (3,3,2,5)]),columns=mlb.classes_)

Out[0]: 
1 2 3 5
0 1 1 0 0
1 0 1 1 1

与此相反，我想要获取
Out[0]: 
1 2 3 5
0 2 1 0 0
1 0 1 2 1

因为 1 在第 1 行重复 2 次，而 3 在第 1 行重复 2 次]]></description>
      <guid>https://stackoverflow.com/questions/56372324/getting-counts-in-multilabelbinarizer</guid>
      <pubDate>Thu, 30 May 2019 05:47:14 GMT</pubDate>
    </item>
    </channel>
</rss>