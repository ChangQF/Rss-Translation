<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 31 Mar 2024 18:15:33 GMT</lastBuildDate>
    <item>
      <title>如何在机器学习模型中根据目标参数预测输入参数？</title>
      <link>https://stackoverflow.com/questions/78252231/how-to-predict-input-parameters-from-target-parameter-in-a-machine-learning-mode</link>
      <description><![CDATA[例如，如果像 T=300 C、时间= 60 分钟、催化剂= A 型这样的实验输入数据给出 70% 的生物柴油产量，我希望 ANN 模型能够预测什么输入参数可以实现 90% 甚至 95% 的生物柴油产量？
我还没有找到解决的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78252231/how-to-predict-input-parameters-from-target-parameter-in-a-machine-learning-mode</guid>
      <pubDate>Sun, 31 Mar 2024 17:28:41 GMT</pubDate>
    </item>
    <item>
      <title>训练精度和验证精度曲线几乎彼此平行。模型是否过度拟合？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78251744/the-training-accuracy-and-the-validation-accuracy-curves-are-almost-parallel-to</link>
      <description><![CDATA[训练和验证精度如下：
Epoch 1/5，训练精度：0.9442，验证精度：0.7626，时间：27.09 秒
Epoch 2/5，训练精度：0.9631，验证精度：0.7518，时间：28.14 秒
Epoch 3/5，训练精度：0.9757，验证精度：0.7914，时间：27.54 秒
Epoch 4/5，训练精度：0.9730，验证精度：0.7698，时间：27.30 秒
Epoch 5/5，训练精度：0.9865，验证精度：0.7482，时间：27.74 秒
它是一个基于文本的英语和印地语新闻标题数据集。
大小为 1680+ 条记录。
使用的模型是带有 Adam 优化器的多语言 BERT。
图表快照
模型是否过度拟合？如果是这样，我们如何改进模型？
我们预计训练精度会急剧上升，验证精度曲线会接近它，但不确定该图是否最优。]]></description>
      <guid>https://stackoverflow.com/questions/78251744/the-training-accuracy-and-the-validation-accuracy-curves-are-almost-parallel-to</guid>
      <pubDate>Sun, 31 Mar 2024 14:52:10 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“llama_index.llms”（未知位置）导入名称“HuggingFaceInferenceAPI”</title>
      <link>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</link>
      <description><![CDATA[想要导入 HuggingFaceInferenceAPI。
从 llama_index.llms 导入 HugggingFaceInferenceAPI

llama_index.llms 文档没有 HuggingFaceInferenceAPI 模块。有人有这方面的更新吗？]]></description>
      <guid>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</guid>
      <pubDate>Sun, 31 Mar 2024 14:21:19 GMT</pubDate>
    </item>
    <item>
      <title>哪个库可以替代机器学习编程中的 causal_conv1d？</title>
      <link>https://stackoverflow.com/questions/78251511/which-library-can-replace-causal-conv1d-in-machine-learning-programming</link>
      <description><![CDATA[最近，我一直在使用 causal_conv1d 库进行机器学习编程，而 causal_conv1d 是 mamba_ssm 库的一部分。但是，我只能在 NVIDIA GPU 上运行这些库。我使用的是带有M系列芯片（M2 PRO）的MAC机器。如何在我的 MAC 计算机上使用 causal_conv1d 库或者是否有任何可用的替代库？
我尝试使用 MPS 版本安装 PyTorch，但 causal_conv1d 库似乎直接需要对 nvcc 和 CUDA 的支持。]]></description>
      <guid>https://stackoverflow.com/questions/78251511/which-library-can-replace-causal-conv1d-in-machine-learning-programming</guid>
      <pubDate>Sun, 31 Mar 2024 13:38:26 GMT</pubDate>
    </item>
    <item>
      <title>在包含文本和图像的 PDF 上微调大型语言模型</title>
      <link>https://stackoverflow.com/questions/78251401/fine-tuning-large-language-model-on-pdfs-containing-text-and-images</link>
      <description><![CDATA[我需要在包含从 PDF 中提取的文本和图像的自定义数据集上微调法学硕士。
对于文本部分，我已成功提取整个文本数据并使用 OpenAI API 生成 JSON/CSV 格式的问题和答案。这种方法对于基于文本的微调非常有效。
但是，我不确定如何处理图像。谁能建议一种方法或库来帮助我处理图像并将其合并到微调过程中？
然后，使用 QnA 的微调模型。此外，我对使用哪个模型来完成此任务感到困惑。
任何指导、资源或见解将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78251401/fine-tuning-large-language-model-on-pdfs-containing-text-and-images</guid>
      <pubDate>Sun, 31 Mar 2024 13:04:38 GMT</pubDate>
    </item>
    <item>
      <title>草图引导文本到图像生成</title>
      <link>https://stackoverflow.com/questions/78251364/sketch-guided-text-to-image-generation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78251364/sketch-guided-text-to-image-generation</guid>
      <pubDate>Sun, 31 Mar 2024 12:53:19 GMT</pubDate>
    </item>
    <item>
      <title>我的 ICNN 似乎不适用于任何 n_hidden</title>
      <link>https://stackoverflow.com/questions/78251346/my-icnn-doesnt-seem-to-work-for-any-n-hidden</link>
      <description><![CDATA[`
类凸线性（nn.Module）：
    def __init__(自身, size_in, size_out):
        超级().__init__()
        self.size_in, self.size_out = size_in, size_out
        权重 = torch.Tensor(size_out, size_in)
        self.weights = nn.Parameter(权重)
        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5))

    def 前向（自身，x）：
        w_times_x= torch.mm(x, F.softplus(self.weights.t()))
        返回 w_times_x

类 ICNN(nn.Module):
    def __init__(自身, n_input, n_hidden, n_output):
        超级（ICNN，自我）.__init__()
        self.layers = nn.ModuleDict()
        self.深度 = len(n_hidden)
        self.layers[str(0)] = nn.Linear(n_input, n_hidden[0]).float()
        nn.init.xavier_uniform_(self.layers[str(0)].weight)
        # 创建NN，以n_hidden中的元素数量作为深度
        对于范围内的 i(1, self.deep):
            self.layers[str(i)] =凸线性(n_hidden[i-1], n_hidden[i]).float()

        self.layers[str(self.深度)] =凸线性(n_hidden[self.深度-1], n_output).float()
        
    def 前向（自身，x）：
        # 第一层
        x = x.view(-1, 3, 3)
        det = 火炬.det(x)
        det = det.view(-1, 1)
        x_t = x.转置(1, 2)
        mult = torch.bmm(x_t, x)
        跟踪 = torch.diagonal(mult, dim1=1, dim2=2).sum(1)
        跟踪 = 跟踪.view(-1, 1)
        x = torch.cat((trace, det), 1)
        z = x.clone()
        z = self.layers[str(0)](z)

        对于范围（1，self.深度）中的图层：
            z = self.layers[str(层)](z)
            z = F.softplus(z)
            z = 火炬.square(z)
        y = self.layers[str(self.深度)](z)
        返回y

&lt;前&gt;&lt;代码&gt;n_input = 2
n_输出 = 1
n_隐藏 = [64, 64]
icnn = ICNN(n_输入, n_隐藏, n_输出)

x 是一个 600, 9 数据集，在 defforward 中转换为 600, 2 集：
输出应该是 600, 1
但是对于 n_hidden 的任何其他组合，代码都会给出非常糟糕的结果。
如果有任何疑问 - 我需要一个凸的、非递减的激活函数，线性层的权重为非负]]></description>
      <guid>https://stackoverflow.com/questions/78251346/my-icnn-doesnt-seem-to-work-for-any-n-hidden</guid>
      <pubDate>Sun, 31 Mar 2024 12:46:57 GMT</pubDate>
    </item>
    <item>
      <title>Optuna Hyperband 算法不遵循预期的模型训练方案</title>
      <link>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</link>
      <description><![CDATA[我在 Optuna 中使用 Hyperband 算法时发现了一个问题。根据 Hyperband 算法，当 min_resources = 5、ma​​x_resources = 20 且 reduction_factor = 2 时，搜索应以 支架 1 的初始空间为 4 个模型，每个模型在第一轮中接收 5 epoch。随后，每轮模型的数量减少 2 倍，下一个括号的搜索空间也应减少 2 倍，即括号 2 将进行初始搜索2 个模型的空间，并且剩余模型的 epoch 数量在后续的每一轮中加倍。因此预计模型总数应为 11，但它正在训练很多模型。
文章链接：- https://arxiv.org/pdf/1603.06560.pdf
导入 optuna
将 numpy 导入为 np

# 玩具数据集生成
defgenerate_toy_dataset():
    np.随机.种子(0)
    X_train = np.random.rand(100, 10)
    y_train = np.random.randint(0, 2, 大小=(100,))
    X_val = np.random.rand(20, 10)
    y_val = np.random.randint(0, 2, 大小=(20,))
    返回 X_train、y_train、X_val、y_val

X_train、y_train、X_val、y_val =generate_toy_dataset（）

# 模型构建函数
def build_model（试用）：
    模型=顺序（）
    model.add(Dense(units=Trial.suggest_int(&#39;unit_input&#39;, 20, 30),
                    激活=&#39;selu&#39;,
                    input_shape=(X_train.shape[1],)))

    num_layers = Trial.suggest_int(&#39;num_layers&#39;, 2, 3)
    对于范围内的 i（num_layers）：
        单位 = Trial.suggest_int(f&#39;num_layer_{i}&#39;, 20, 30)
        激活 = Trial.suggest_categorical(f&#39;activation_layer_{i}&#39;, [&#39;relu&#39;, &#39;selu&#39;, &#39;tanh&#39;])
        model.add（密集（单位=单位，激活=激活））
        if Trial.suggest_categorical(f&#39;dropout_layer_{i}&#39;, [True, False]):
            model.add(Dropout(rate=0.5))

    model.add（密集（1，激活=&#39;sigmoid&#39;））

    Optimizer_name = Trial.suggest_categorical(&#39;optimizer&#39;, [&#39;adam&#39;, &#39;rmsprop&#39;])
    如果优化器名称==&#39;亚当&#39;：
        优化器 = tf.keras.optimizers.Adam()
    别的：
        优化器 = tf.keras.optimizers.RMSprop()

    model.compile(optimizer=optimizer,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;,tf.keras.metrics.AUC(name=&#39;val_auc&#39;)])

    返回模型

定义目标（试用）：
    模型 = build_model(试用)
    # 假设你已经准备好数据
    # 修改拟合方法以包含 AUC 指标
    历史= model.fit（X_train_splitted，y_train_splitted，validation_data =（X_val，y_val），详细= 1）
    
    # 检查&#39;val_auc&#39;是否被记录
    auc_key = 无
    对于history.history.keys()中的键：
        if key.startswith(&#39;val_auc&#39;):
            auc_key = 密钥
            print(f&quot;auc_key 是 {auc_key}&quot;)
            休息
    
    如果 auc_key 为 None：
        raise ValueError(“历史记录中未找到 AUC 指标。确保在训练期间记录它。”)
    
    # 报告每个模型的验证 AUC
    
    如果 auc_key ==“val_auc”：
        步长=0
    别的：
        步骤 = int(auc_key.split(&#39;_&#39;)[-1])
    
    auc_value=history.history[auc_key][0]
    试验.报告（auc_value，步骤=步骤）
    print(f&quot;是否修剪:-{Trial.should_prune()}&quot;)
    如果审判.should_prune():
        引发 optuna.TrialPruned()

    返回历史记录.history[auc_key]

# Optuna 研究创建
研究 = optuna.create_study(
    方向=&#39;最大化&#39;,
    修剪器=optuna.pruners.HyperbandPruner(
        最小资源=5，
        最大资源=20,
        减少因子=2
    ）
）

# 开始优化
研究.优化（目标）

]]></description>
      <guid>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</guid>
      <pubDate>Sun, 31 Mar 2024 12:38:07 GMT</pubDate>
    </item>
    <item>
      <title>如何解决这个错误并在深度学习中顺利工作？</title>
      <link>https://stackoverflow.com/questions/78251029/how-can-i-resolve-this-error-and-work-smoothly-in-deep-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78251029/how-can-i-resolve-this-error-and-work-smoothly-in-deep-learning</guid>
      <pubDate>Sun, 31 Mar 2024 10:36:24 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“llama_index.node_parser”的模块</title>
      <link>https://stackoverflow.com/questions/78250613/modulenotfounderror-no-module-named-llama-index-node-parser</link>
      <description><![CDATA[我想从 llama_index.node 解析器导入 SimpleNodeParser。
from llama_index.node_parser import SimpleNodeParser

但是当我运行这个时，我收到一个错误：
ModuleNotFoundError：没有名为“llama_index.node_parser”的模块

帮我解决这个问题。
我想从 llama_index.node 解析器导入 SimpleNodeParser。]]></description>
      <guid>https://stackoverflow.com/questions/78250613/modulenotfounderror-no-module-named-llama-index-node-parser</guid>
      <pubDate>Sun, 31 Mar 2024 07:53:47 GMT</pubDate>
    </item>
    <item>
      <title>model.evaluate 和metrics.accuracy_score 之间的区别</title>
      <link>https://stackoverflow.com/questions/78250436/difference-between-model-evaluate-and-metrics-accuracy-score</link>
      <description><![CDATA[我尝试使用两种不同的方法评估 CNN 模型：
1.
model.evaluate(test_data)

在这种情况下，我得到 79% 的准确度分数：[1.2163524627685547, 0.7924528121948242]
2.
我想获取实际的预测值并使用 scikit-learn 指标来获取准确度分数：
test_prediction=model.predict(test_data)
test_prediction = np.argmax（test_prediction，轴= 1）

y_test = np.concatenate([y_batch for X_batch, y_batch in test_data])

指标.accuracy_score(test_prediction,y_test)

本例中的准确度得分为 21%。
为什么会有差异，哪种方式更可靠？]]></description>
      <guid>https://stackoverflow.com/questions/78250436/difference-between-model-evaluate-and-metrics-accuracy-score</guid>
      <pubDate>Sun, 31 Mar 2024 06:05:04 GMT</pubDate>
    </item>
    <item>
      <title>此代码不适用于tensorflow 2.16.0+版本</title>
      <link>https://stackoverflow.com/questions/78223936/this-code-is-not-working-on-tensorflow-2-16-0-version</link>
      <description><![CDATA[检查点 = ModelCheckpoint(
    &#39;./base.model&#39;,
    监视器=&#39;val_accuracy&#39;,
    详细=1，
    save_best_only=真，
    模式=&#39;最大&#39;,
    save_weights_only=假,
    保存频率=1
）
提前停止=提前停止(
    监视器=&#39;val_loss&#39;,
    最小增量=0.001，
    耐心=30，
    详细=1，
    模式=&#39;自动&#39;
）

opt1 = tf.keras.optimizers.Adam()

回调= [检查点，提前停止]

这不适用于tensorflow 2.16.1
但是，正在 google colab 上开发 2.15.0
如何修复我的代码或如何安装tensorflow 2.15.0？
我尝试了pip install tensorflow=2.15.0
但是，它显示错误]]></description>
      <guid>https://stackoverflow.com/questions/78223936/this-code-is-not-working-on-tensorflow-2-16-0-version</guid>
      <pubDate>Tue, 26 Mar 2024 08:41:28 GMT</pubDate>
    </item>
    <item>
      <title>中途Discord图片上传问题</title>
      <link>https://stackoverflow.com/questions/75265882/midjourney-discord-image-uploading-problem</link>
      <description><![CDATA[无法仅在单个图像提示中使用 --version 4。
请添加另一个图像提示或文本提示。
/想象 https://media.disc/
尝试在旅途中遇到问题时通过链接上传图像]]></description>
      <guid>https://stackoverflow.com/questions/75265882/midjourney-discord-image-uploading-problem</guid>
      <pubDate>Sat, 28 Jan 2023 06:45:19 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 与 Tensorflow CUDA 版本</title>
      <link>https://stackoverflow.com/questions/75227372/pytorch-vs-tensorflow-cuda-versions</link>
      <description><![CDATA[我目前安装了 Pytorch（版本 1.13.1+cu116）。它检测 GPU 并与 CUDA 版本 11.6 配合良好。以下是我运行 nvidia-smi 的输出：

我现在正在尝试设置具有 GPU 支持的张量流。但是，它不适用于 CUDA 版本 11.6（使用 tf.config.list_physical_devices 时无法检测到我的 GPU），并且经过进一步检查最新版本的 tensorflow 仅支持 CUDA 11.2。
如果我尝试安装 CUDA 版本 11.2，安装程序会退出并提示“您已经安装了较新版本的 NVIDIA Frameview SDK”，考虑到我为 pytorch 安装了 CUDA 11.6，这是可以理解的。我的问题是，如果我卸载 CUDA 11.6 并为tensorflow 安装 CUDA 11.2，这会破坏我的 pytorch GPU 支持吗？或者 pytorch 向后兼容以前的 CUDA 版本吗？让 TensorFlow 和 pytorch 与我的 GPU 一起工作的最佳方法是什么，因为它们都支持不同的 CUDA 版本？
非常感谢任何帮助。]]></description>
      <guid>https://stackoverflow.com/questions/75227372/pytorch-vs-tensorflow-cuda-versions</guid>
      <pubDate>Tue, 24 Jan 2023 21:15:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 MNIST 分类器代码中使用 X[0] 会出现错误？</title>
      <link>https://stackoverflow.com/questions/65506131/why-does-using-x0-in-mnist-classifier-code-give-me-an-error</link>
      <description><![CDATA[我正在学习使用 MNIST 数据集进行分类。我遇到了一个我无法弄清楚的错误，我已经做了很多谷歌搜索，但我无能为力，也许你是专家并且可以帮助我。这是代码--
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt;从 sklearn.datasets 导入 fetch_openml
&gt;&gt;&gt;&gt;&gt; mnist = fetch_openml(&#39;mnist_784&#39;, 版本=1)
&gt;&gt;&gt;&gt;&gt; mnist.keys()

输出：
dict_keys([&#39;数据&#39;, &#39;目标&#39;, &#39;框架&#39;, &#39;类别&#39;, &#39;feature_names&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;详细信息&#39;, &#39;url&#39;])
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt; X, y = mnist[“数据”], mnist[“目标”]
&gt;&gt;&gt;&gt;&gt; X形

输出：(70000, 784)
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt; y 形状

输出：(70000)
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt; X[0]

输出：KeyError Traceback（最近一次调用）
get_loc 中的 c:\users\khush\appdata\local\programs\python\python39\lib\site-packages\pandas\core\indexes\base.py(self、key、method、tolerance)
   第2897章 试试：
-&gt;第2898章
   第2899章

pandas\_libs\index.pyx 在 pandas._libs.index.IndexEngine.get_loc()

pandas\_libs\index.pyx 在 pandas._libs.index.IndexEngine.get_loc()

pandas\_libs\hashtable_class_helper.pxi 在 pandas._libs.hashtable.PyObjectHashTable.get_item()

pandas\_libs\hashtable_class_helper.pxi 在 pandas._libs.hashtable.PyObjectHashTable.get_item()

密钥错误：0

上述异常是导致以下异常的直接原因：

KeyError Traceback（最近一次调用最后一次）
&lt;ipython-input-10-19c40ecbd036&gt;在&lt;模块&gt;中
----&gt; 1 个[0]

c:\users\khush\appdata\local\programs\python\python39\lib\site-packages\pandas\core\frame.py 在 __getitem__(self, key)
   第2904章1：
   第2905章
-&gt;第2906章
   第2907章
   第2908章

get_loc 中的 c:\users\khush\appdata\local\programs\python\python39\lib\site-packages\pandas\core\indexes\base.py(self、key、method、tolerance)
   第2898章
   第2899章
-&gt;第2900章 2900
   2901
   第2902章

密钥错误：0
]]></description>
      <guid>https://stackoverflow.com/questions/65506131/why-does-using-x0-in-mnist-classifier-code-give-me-an-error</guid>
      <pubDate>Wed, 30 Dec 2020 11:19:43 GMT</pubDate>
    </item>
    </channel>
</rss>