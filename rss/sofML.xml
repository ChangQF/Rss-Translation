<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 31 Dec 2023 06:16:36 GMT</lastBuildDate>
    <item>
      <title>为什么我的目标列上出现键错误，并且出现值错误：给定列不是数据帧的列</title>
      <link>https://stackoverflow.com/questions/77738345/why-am-i-having-a-key-error-on-my-target-column-and-a-value-error-that-says-a-g</link>
      <description><![CDATA[首先，我分割了我的数据
target = &#39;member_casual&#39; X_train = train.drop(target, axis=1) y_train = train[target]
然后，转换我的数字列和分类列
cat_trans = Pipeline([(“imputer”, SimpleImputer(strategy=“most_frequent”)),(&#39;encoder&#39;,OneHotEncoder(handle_unknown=“ignore”, drop=“first”,稀疏=假））]）
num_trans = Pipeline([(“imputer”, SimpleImputer(strategy=“mean”)),(“scaler”, MinMaxScaler())]) 
预处理器 = ColumnTransformer(transformers=[(&#39;num&#39;, num_trans, num),(&#39;cat&#39;, cat_trans, cat)])
pipeline = Pipeline([(&#39;预处理器&#39;, 预处理器)]) 
然后接下来的代码给了我错误
pipe_fit = pipeline.fit(x_train)
键错误和值错误：给定列不是数据帧的列]]></description>
      <guid>https://stackoverflow.com/questions/77738345/why-am-i-having-a-key-error-on-my-target-column-and-a-value-error-that-says-a-g</guid>
      <pubDate>Sun, 31 Dec 2023 06:05:14 GMT</pubDate>
    </item>
    <item>
      <title>我正在为机器学习预测模型编写一个快速 api 服务器，但收到此错误：</title>
      <link>https://stackoverflow.com/questions/77738256/i-ma-writing-a-fast-api-server-for-a-ml-prediction-model-and-i-am-getting-this-e</link>
      <description><![CDATA[from fastapi import FastAPI,文件,UploadFile
进口uvicorn
将 numpy 导入为 np
从 io 导入 BytesIO
从 PIL 导入图像
将张量流导入为 tf


应用程序 = FastAPI()
MODEL=tf.keras.models.load_model(&#39;./bone_fracture_detection_model.h5&#39;)
CLASS_NAMES = [“破裂”,“未破裂”]

@app.get(“/ping”)
异步 def ping():
    返回“你好，我还活着”

def read_file_as_image(data)-&gt;; np.ndarray：
    图像 = np.array(BytesIO(数据))
    返回图像

@app.post(“/预测”)
异步 def 预测（
    文件：上传文件=文件(...)
）：
    图像 = read_file_as_image(等待 file.read())
    image_batch = np.expand_dims(图像,0)
    预测= MODEL.预测（图像）
    Predicted_class = CLASS_NAMES[np.argmax(预测[0])]
    置信度 = np.max(预测[0])
    返回{
        &#39;类&#39;：预测类，
        &#39;信心&#39;：浮动（信心）
    }


如果 __name__ == “__main__”：
    uvicorn.run（应用程序，主机=&#39;localhost&#39;，端口=8000）

这是我遇到的错误
文件“C:\Users\Chetan\Documents\localprograms\api.venv\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 70 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件“C:\Users\Chetan\Documents\localprograms\api.venv\Lib\site-packages\tensorflow\python\framework\constant_op.py”，第103行，在convert_to_eager_tensor中
返回 ops.EagerTensor(值, ctx.device_name, dtype)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError：无法将 NumPy 数组转换为张量（不支持的对象类型 _io.BytesIO）。
在邮递员上，我尝试传递图像并收到内部服务器错误
https://colab.research.google.com/drive /1DNnIVtXZek2BZD9wDaugj-wuI9XEqZrV#scrollTo=iGSVvHFCHlLh
这就是我在 kaggel 上编写骨折模型的方法
我尝试传递从 kaggel 笔记本获得的整个模型输出，但我面临另一个错误，即加载模型无法读取它。我是新手，请用简单的话解释我哪里出错了。]]></description>
      <guid>https://stackoverflow.com/questions/77738256/i-ma-writing-a-fast-api-server-for-a-ml-prediction-model-and-i-am-getting-this-e</guid>
      <pubDate>Sun, 31 Dec 2023 05:06:07 GMT</pubDate>
    </item>
    <item>
      <title>漫画的匹配版本 - 最好的方法是什么？</title>
      <link>https://stackoverflow.com/questions/77737789/matching-edition-of-comics-what-is-the-best-approach</link>
      <description><![CDATA[我是一名程序员，但我刚刚开始学习机器学习。
我想根据漫画的图片编写一个与漫画版本相匹配的程序。
我一直在寻找正确的方法来做到这一点，但我正在努力使用网络上的所有可用资源，而且我不知道从哪里开始。
例如，我应该通过 Yolov8 + 图像匹配算法与我自己训练的数据集使用图像分割吗？
在这里回答可能太长了，所以如果有人有有用的链接可以帮助我确定实现我的目标所需/适当的工具，我将非常感激。
谢谢您的宝贵时间，
最好的
我试图在互联网上找到足够的工具，但我不知道从哪里开始。]]></description>
      <guid>https://stackoverflow.com/questions/77737789/matching-edition-of-comics-what-is-the-best-approach</guid>
      <pubDate>Sat, 30 Dec 2023 23:59:01 GMT</pubDate>
    </item>
    <item>
      <title>创建多语言聊天机器人</title>
      <link>https://stackoverflow.com/questions/77737679/create-a-multilingual-chatbot</link>
      <description><![CDATA[我使用 PyTorch 创建了一个聊天机器人，我想让它支持法语。请注意，我想训练聊天机器人，以便它能够回答技术问题。
我想到的一件事是使用翻译 API，但由于聊天机器人需要回答技术问题，翻译 API 可能会提供不准确的信息]]></description>
      <guid>https://stackoverflow.com/questions/77737679/create-a-multilingual-chatbot</guid>
      <pubDate>Sat, 30 Dec 2023 23:05:27 GMT</pubDate>
    </item>
    <item>
      <title>我无法解决数据科学案例研究[关闭]</title>
      <link>https://stackoverflow.com/questions/77737223/i-cant-solve-data-science-case-study</link>
      <description><![CDATA[我正在尝试自学数据科学，我必须解决一个案例研究。有一个数据库，其中包含酒店的名称、评论、负面和正面评论、评级等。我必须为该数据库创建咨询工具。有人可以告诉我应该使用哪种 ML 和 NLP 方法吗？为什么？ https://drive.google.com/file/d/1wYW_pLEEFluEejgkg_I2emxLjy9YZ5GG/view ?usp=
数据集链接。
(https://i.stack.imgur.com/KPU3e.png)( https://i.stack.imgur.com/yuOoB.png)
我尝试使用负面和正面评论来管理它，但我还必须添加用户的评分。所以我不知道是否可以添加其他信息]]></description>
      <guid>https://stackoverflow.com/questions/77737223/i-cant-solve-data-science-case-study</guid>
      <pubDate>Sat, 30 Dec 2023 19:51:43 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的决策树只有一个节点？</title>
      <link>https://stackoverflow.com/questions/77737156/why-does-my-decision-tree-just-have-one-node</link>
      <description><![CDATA[我必须使用 R 创建决策树。
您可以在这里找到我正在使用的数据集 - https:/ /www.kaggle.com/datasets/iamsouravbanerjee/customer-shopping-trends-dataset
清理数据集后，这些是我在项目中使用的变量。这个新数据集被称为“GroupAgrePref”。 （附图）。（https://i.stack.imgur.com/eSt13.png&lt; /a&gt;)
变量“颜色”创建它的目的是为了替换以前仅 3 个类别“暖色”、“中性”、“冷色”中存在的所有不同颜色。
变量“AgeGroup”也是如此。我创建了将所有年龄段分为“青少年”、“成人”、“老年人”3 个类别的方法。使用以下公式：
subdata$Group.Age &lt;- cut(subdata$Age, Breaks = c(17,30,50,71),labels = c(“青少年”,“成人”,“老年人” ;))

所有变量都是因素。
下一步是创建训练数据集：
train &lt;- GroupAgePref[sample(1:nrow(GroupAgePref),3120),]

然后是决策树：
Tree_1 &lt;- rpart(公式 = 类别 ~ ., 数据 = 训练)

但是当我想用 rpart.plot 以图形方式查看它时，就会发生这种情况：
rpart.plot(arbol_1, box.palette = “红色”)

(https://i.stack.imgur.com/Rs7jl.png)
为什么会发生这种情况？
我正在尝试预测“类别”根据性别、季节、年龄组和颜色购买的衣服。]]></description>
      <guid>https://stackoverflow.com/questions/77737156/why-does-my-decision-tree-just-have-one-node</guid>
      <pubDate>Sat, 30 Dec 2023 19:24:21 GMT</pubDate>
    </item>
    <item>
      <title>如何定义仅部分可训练的 PyTorch 张量</title>
      <link>https://stackoverflow.com/questions/77737016/how-to-define-pytorch-tensor-that-is-only-partially-trainable</link>
      <description><![CDATA[我正在尝试构建一个自定义模型来在 PyTorch 中进行训练，长话短说，我需要构建一个张量，将除矩形下对角线块之外的所有元素设置为零，至关重要的是，优化过程应该只涉及该子对角线块的元素，保持所有零不变。为此，我定义了一个自定义 pytorch 网络，并使用 nn.Parameter 定义了我的矩形块
类 My_Network(nn.Module):
    def __init__(自身, 垂直尺寸, 水平尺寸):
        超级().__init__()
        self.total_dim = 垂直_dim + 水平_dim
        self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , Horizo​​ntal_dim))


这样，如果我错了，请纠正我，PyTorch应该用随机值初始化这个张量的值，并且应该将它们注册为训练期间要优化的模型的参数。但现在我陷入了困境，我想告诉 PyTorch 构建一个方阵张量，其维度等于 self.total_dim ，除了次对角线块之外都是零，正如我所说在我将在前向方法中定义的计算中，pytorch 应该只训练次对角线块。
我可以根据需要添加零张量，而无需将其设置为模型参数，如下所示（如果我没有记错的话）：
类 My_Network(nn.Module):
    def __init__(自身, 垂直尺寸, 水平尺寸):
        超级().__init__()
        self.total_dim = 垂直_dim + 水平_dim
        self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , Horizo​​ntal_dim))
        self.total_zero_tensor = torch.zeros(self.total_dim, self.total_dim)


但是现在我如何告诉 PyTorch 将我的次对角线块插入这个零矩阵的左下角？我需要为我的计算定义这个矩阵（我需要执行矩阵乘法），但这比仅将小下对角块视为一组要训练的参数更重要。]]></description>
      <guid>https://stackoverflow.com/questions/77737016/how-to-define-pytorch-tensor-that-is-only-partially-trainable</guid>
      <pubDate>Sat, 30 Dec 2023 18:32:49 GMT</pubDate>
    </item>
    <item>
      <title>可教机器出口降低精度</title>
      <link>https://stackoverflow.com/questions/77736961/teachable-machine-export-decreasing-accuracy</link>
      <description><![CDATA[我试图用可教学机器制作图像识别模型，但为了测试该模型，我想将其导出到笔记本上，以便我可以快速运行它通过许多图像。然而，当我将模型导出到 Kaggle 时，导出版本的精度低于 Teachable machine 中的原始模型。我决定在两个模型上测试一张图像，在可教学机器上测试一张图像给了我正确的分类，但在 Kaggle 上我得到了错误的分类。如果我为每个人使用相同的模型，这是怎么发生的？
以下是我用于创建模型的步骤：
登录可示教机器
每类输入900张图像（6类）
在可示教机器中训练模型（400 epoch）
将模型从可示教机器导出到 TensorFlow Keras
将模型上传到 Kaggle 笔记本上
在Kaggle中，使用模型对一张图像进行分类（得到错误的分类）
在可教机器中使用模型（与导出到 Kaggle 的模型相同）对同一图像进行分类（获得正确的分类）
我怀疑 Teachable 机器可能是用 TensorFlow JS 制作的，但当它导出为 Keras 模型时，它会失去一些准确性，但我在这方面的经验很少，所以我可能是错的。
当我导出模型时，是否有办法保持可示教机器的准确性？
我尝试使用 jupyter 笔记本和 google collab 而不是 Kaggle，但我无法弄清楚如何将文件导入其中。]]></description>
      <guid>https://stackoverflow.com/questions/77736961/teachable-machine-export-decreasing-accuracy</guid>
      <pubDate>Sat, 30 Dec 2023 18:13:38 GMT</pubDate>
    </item>
    <item>
      <title>pytorch CTC 损失在我的测试数据上表现得很奇怪</title>
      <link>https://stackoverflow.com/questions/77735398/pytorch-ctc-loss-works-strange-on-my-test-data</link>
      <description><![CDATA[我试图了解 CTC 损失是如何工作的并生成一些“输入数据”和“地面真实数据”，将它们发送到 CTC 损失函数并得到奇怪的结果。
例如：
&lt;前&gt;&lt;代码&gt;*“|” - 是词汇[4] - 空白字符*

尝试#1“出色的猜测”：
2个词：“acb” “acc”
2 个猜测：“a|ccc|b” “aaa|ccc|cccc”

损失：张量([16.9247, 18.9556])

尝试#2“优秀匹配，无空白”
单词：“b” “b”
猜测：“b” “b”

损失张量([22.0504, 22.0504])

尝试#3“绝对错过”：
2个字：“bba” “bbb”
2 个猜测：“a|ccc|b” “aaa|ccc|cccc”

损失张量([17.4538, 18.9426])

所有 3 次尝试的损失似乎几乎相同。
我预计前两次尝试会损失很小，第三次尝试会损失很大。
我做错了什么？
代码在这里
https://colab.research。 google.com/drive/1KXgTuNqg-uO-oDvdwDDc-3UbnO7BvWUI?usp=sharing#scrollTo=yFzLIj663DQr
这里：
vocab_test = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39; &#39;, &#39;|&#39;]
vocab_dict_test = {&#39;a&#39;:1,&#39;b&#39;:2,&#39;c&#39;:3,&#39;&#39;:4,&#39;|&#39;:5}

词汇长度 = 5
批量大小 = 2
标签长度 = 7
输入长度 = 15

def loss_check（单词1，单词2，猜测1，猜测2）：

    # 将单词转换为所需大小的数字火炬
    input_word1 = word1.ljust(label_len)
    猜测的词1 = 猜测1.ljust(input_len)

    input_word_numbers1 = get_numbers(vocab_dict_test, input_word1)
    猜测的单词数字1 = get_numbers(vocab_dict_test, 猜测的单词1)

    input_word2 = word2.ljust(label_len)
    猜测的词2 = 猜测2.ljust(input_len)

    input_word_numbers2 = get_numbers(vocab_dict_test, input_word2)
    猜测的单词数字2 = get_numbers(vocab_dict_test, 猜测的单词2)

    print(&#39;单词:&#39;, &#39;&quot;&#39; + word1 + &#39;&quot; / &quot;&#39; + word2 + &#39;&quot;&#39;, &#39;转换后:&#39;, input_word_numbers1, input_word_numbers2)
    print(&#39;猜测：&#39;, &#39;&quot;&#39; + 猜测 1 + &#39;&#39; / &#39;&#39; + 猜测 2 + &#39;&#39;&#39;, &#39;转换后:&#39;, 猜测的单词数字 1, 猜测的单词数字 2)

    # 用于损失函数的特殊火炬
    input_len_size = torch.IntTensor([input_len] * batch_size).to(device)
    label_len_size = torch.IntTensor([label_len] * batch_size).to(device)

    真相 = torch.from_numpy(np.array([input_word_numbers1,input_word_numbers2])).float()
    #打印（真相）
    #print(truth.size())

    logits = [torch.from_numpy(np.array(guessed_word_numbers1)),torch.from_numpy(np.array(guessed_word_numbers2))]
    logits_converted = [[[1 if (logits[j][h] == i+1) else 0 for i in range(vocab_length)] for h in range(input_len)] for j in range(batch_size)]
    logits_converted = torch.from_numpy(np.array(logits_converted)).float()
    #print(logits_converted)
    Softmax = nn.LogSoftmax(dim=2)
    logits_log = Softmax(logits_converted)
    #print(logits_log)

    logits_log_formatted = logits_log.transpose(1,0)
    #print(logits_log_formatted)
    #print(logits_log_formatted.size())
    loss_fn = nn.CTCLoss(blank=4,zero_infinity=True,reduction=&#39;none&#39;).to(device)

    #log_probs、目标、input_lengths、target_lengths、self.blank、
    损失 = loss_fn(logits_log_formatted, 真值, input_len_size, label_len_size)

    回波损耗


打印（loss_check（&#39;acb&#39;，&#39;acc&#39;，&#39;a | ccc | b&#39;，&#39;aaa | ccc | cccc&#39;））
打印（loss_check（&#39;bba&#39;，&#39;bbb&#39;，&#39;a | ccc | b&#39;，&#39;aaa | ccc | cccc&#39;））
打印（loss_check（&#39;b&#39;，&#39;b&#39;，&#39;b&#39;，&#39;b&#39;））
]]></description>
      <guid>https://stackoverflow.com/questions/77735398/pytorch-ctc-loss-works-strange-on-my-test-data</guid>
      <pubDate>Sat, 30 Dec 2023 09:08:09 GMT</pubDate>
    </item>
    <item>
      <title>运行时错误：张量的大小必须匹配（维度 1 除外）。预期大小为 18，但列表中张量 1 的大小为 17</title>
      <link>https://stackoverflow.com/questions/77723713/runtimeerror-sizes-of-tensors-must-match-except-in-dimension-1-expected-size-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77723713/runtimeerror-sizes-of-tensors-must-match-except-in-dimension-1-expected-size-1</guid>
      <pubDate>Wed, 27 Dec 2023 19:38:15 GMT</pubDate>
    </item>
    <item>
      <title>尝试从 inceptionv3 架构中提取特征时出现图形断开连接错误</title>
      <link>https://stackoverflow.com/questions/77713548/graph-disconnected-error-when-trying-to-extract-features-from-inceptionv3-archit</link>
      <description><![CDATA[我正在尝试从架构中间提取一些特征并将其用于另一个模型。
base_model = InceptionV3(weights=&#39;imagenet&#39;, include_top=False)
input_tensor = Input(shape=(299, 299, 3)) # InceptionV3 的输入形状
InceptionA_feature_extractor = models.Model(inputs=input_tensor,outputs=base_model.get_layer(&#39;mixed2&#39;).output)

在尝试执行此操作时，我收到以下错误，可能的原因是什么？
ValueError：图形已断开连接：无法获取张量 KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name=&#39;input_6&#39;), name=&#39; 的值input_6&#39;，描述=“由层&#39;input_6&#39;创建”）在层“conv2d_376”。访问以下先前层没有问题：[]
]]></description>
      <guid>https://stackoverflow.com/questions/77713548/graph-disconnected-error-when-trying-to-extract-features-from-inceptionv3-archit</guid>
      <pubDate>Mon, 25 Dec 2023 11:49:34 GMT</pubDate>
    </item>
    <item>
      <title>存储使用 Torchvision 变换时应用的精确变换</title>
      <link>https://stackoverflow.com/questions/77711542/storing-the-exact-transformation-applied-when-using-torchvision-transforms</link>
      <description><![CDATA[当我们使用 torchvision 或 albumentations 的变换时，我们可以使用随机裁剪和随机亮度对比度等功能来生成增强图像。有没有可能的方法来存储应用于图像的精确变换以获得相应的图像？]]></description>
      <guid>https://stackoverflow.com/questions/77711542/storing-the-exact-transformation-applied-when-using-torchvision-transforms</guid>
      <pubDate>Sun, 24 Dec 2023 18:31:34 GMT</pubDate>
    </item>
    <item>
      <title>输入数据耗尽，中断张量流训练</title>
      <link>https://stackoverflow.com/questions/77705086/input-ran-out-of-data-interrupting-training-in-tensorflow</link>
      <description><![CDATA[我正在从事肿瘤分割工作，图像是 nifti 格式的 3D（MRI 图像）。我创建了一个数据生成器，因为如果我将完整数据集上传到 RAM，它会因 3D 图像而崩溃。该数据集由 611 张图像组成，尺寸为（240,240,160），计算时的 patch 数量为 61000 和 11375
这是我的数据管道：
def load_nifti_image(文件路径, patch_size=(48, 48, 32), step_size=(48, 48, 32)):
    nifti = nib.load(文件路径)
    体积 = nifti.get_fdata()

    # 从卷创建补丁
    补丁 = patchify(体积, patch_size, 步骤=step_size)

    # 重塑 patch 相乘 (5, 5, 5) 并添加通道维度（1 表示灰度）
    补丁 = patchs.reshape(-1, *patches.shape[-3:])
    补丁= np.expand_dims（补丁，轴=-1）

    返回补丁

＃  -  -  -  -  -  -  -  -  -  -  - -火车 -  -  -  -  -  -  -  -  -  -  - -
nifti_files = [os.path.join(“/content/drive/MyDrive/Interpolated/train/images”, f) for f in os.listdir(“/content/drive/MyDrive/Interpolated/train/images”) if f.endswith(&#39;.nii.gz&#39;)]
mask_files = [os.path.join(“/content/drive/MyDrive/Interpolated/train/masks”, f) for f in os.listdir(“/content/drive/MyDrive/Interpolated/train/masks”) if f.endswith(&#39;.nii.gz&#39;)]

 ＃  -  -  -  -  -  -  -  -  -  -  - -验证 -  -  -  -  -  -  -  -  -  -  - -
nifti_files_val = [os.path.join(&quot;/content/drive/MyDrive/Interpolated/validation/images&quot;, f) for f in os.listdir(&quot;/content/drive/MyDrive/Interpolated/validation/images&quot;) if f.endswith(&#39;.nii.gz&#39;)]
mask_files_val = [os.path.join(“/content/drive/MyDrive/Interpolated/validation/masks”, f) for f in os.listdir(“/content/drive/MyDrive/Interpolated/validation/masks”) if f.endswith(&#39;.nii.gz&#39;)]

defcalculate_patches(文件路径, patch_size=(48, 48, 32), step_size=(48, 48, 32)):
    nifti = nib.load(文件路径)
    体积 = nifti.get_fdata()

    # 计算补丁数量
    patch_shape = [((i - p) // s) + 1 for i, p, s in zip(volume.shape, patch_size, step_size)]
    num_patches = np.prod(patches_shape)

    返回 num_patches

num_train_patches = sum(calculate_patches(f) for i, f in enumerate(nifti_files) if print(f“处理文件 {i}...”) 为 None)
num_val_patches = sum(calculate_patches(f) for i, f in enumerate(nifti_files_val) if print(f“处理文件 {i}...”) 为 None)

def data_generator(image_files, mask_files):
    对于 zip(image_files, mask_files) 中的 img_file、mask_file：
        image_patches = load_nifti_image(img_file)
        mask_patches = load_nifti_image(mask_file)

        对于 zip(image_patches, mask_patches) 中的 img_patch、mask_patch：
            产量 img_patch, mask_patch

train_generator = data_generator(nifti_files, mask_files)
val_generator = data_generator(nifti_files_val, mask_files_val)

输出签名 = (
    tf.TensorSpec(形状=(48, 48, 32, 1), dtype=tf.float64),
    tf.TensorSpec(形状=(48, 48, 32, 1), dtype=tf.float64)
）

数据集= tf.data.Dataset.from_generator（lambda：train_generator，output_signature=output_signature）.repeat（）
dataset_val = tf.data.Dataset.from_generator(lambda: val_generator, output_signature=output_signature).repeat()

数据集=数据集.batch(32)
dataset_val = dataset_val.batch(32)

test_model.fit（数据集，validation_data=dataset_val，epochs=100，steps_per_epoch=num_train_patches//32，validation_steps=num_val_patches//32）

我添加了 .repeat() 希望它能有所帮助，但事实并非如此。
我还尝试计算补丁的数量并手动插入它们，但它也不起作用。
这是完整的回溯：
纪元 1/100
1906/1906 [================================] - 1963s 1s/步 - 损失：0.6447 - dice_coefficient：0.3553 - val_loss ：0.9113 - val_dice_系数：0.0887
纪元 2/100
   1/1906 [................................] - 预计到达时间：10:17 - 损失：1.0000 - dice_coefficient：1.7961e -05

警告：tensorflow：您的输入数据不足；中断训练。确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次（在本例中为 190600 个批次）。构建数据集时，您可能需要使用 Repeat() 函数。
警告：tensorflow：您的输入数据不足；中断训练。确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次（在本例中为 355 个批次）。构建数据集时，您可能需要使用 Repeat() 函数。

1906/1906 [================================] - 0s 31us/步 - 损失：1.0000 - dice_coefficient：1.7961e- 05


]]></description>
      <guid>https://stackoverflow.com/questions/77705086/input-ran-out-of-data-interrupting-training-in-tensorflow</guid>
      <pubDate>Fri, 22 Dec 2023 17:43:32 GMT</pubDate>
    </item>
    <item>
      <title>python 中非常大的浮点数</title>
      <link>https://stackoverflow.com/questions/53797370/very-large-float-in-python</link>
      <description><![CDATA[我正在尝试为 Mnist 数据库构建一个神经网络。计算 softmax 函数时，我收到与“您无法存储该大小的浮点数”相同的错误
代码如下：
def softmax(vector): # 需要一维 numpy 数组
    调整值 = [0] * len(向量)
    总Exp = np.exp(向量)
    print(&quot;总Exp等于&quot;)
    打印（总Exp）
    总和=totalExp.sum()
    对于范围内的 i(len(向量))：
        调整值[i] = (np.exp(向量[i])) / 总和
    return adjustmentVals # 这有时会抛出错误？！？！

经过检查，最推荐使用decimal模块。但是，当我弄乱了此模块的命令行中使用的值时，即：
从十进制导入十进制
导入数学
测试 = 小数(math.exp(720))

对于 math.exp(&gt;709) 的任何值，我都会收到类似的错误。
OverflowError: (34, &#39;数值结果超出范围&#39;)

我的结论是，即使是十进制也无法处理这个数字。有谁知道我可以用来表示这些非常大的浮点数的另一种方法。]]></description>
      <guid>https://stackoverflow.com/questions/53797370/very-large-float-in-python</guid>
      <pubDate>Sat, 15 Dec 2018 21:21:43 GMT</pubDate>
    </item>
    <item>
      <title>从混淆矩阵计算灵敏度和特异性</title>
      <link>https://stackoverflow.com/questions/51513311/calculation-of-sensitivity-and-specificity-from-confusion-matrix</link>
      <description><![CDATA[考虑这样的情况，标记数据的数量为 0 = 1400，标记为 1 = 100。标记为0的数据表示正常运行情况，标记为1的数据表示异常。仅针对异常事件触发警报。
假设二元分类获得以下混淆矩阵
cmMatrix =

                    预测 0 预测 1
           真相 0 1100 (TN) 300 (FP)
           真相 1 30 (FN) 70 (TP)


cmMatrix = [1100,300;30,70];
acc_0 = 100*(cmMatrix(1,1))/sum(cmMatrix(1,:));
acc_1 = 100*(cmMatrix(2,2))/sum(cmMatrix(2,:));

将给出 acc_0 = 78.5714 和 acc_1 = 70
混淆矩阵被读取为 1400 个正常事件，1100 个被正确识别为正常，300 个被错误识别为异常。
那么，在 100 个异常事件中，有 70 个被正确检测为异常，而 30 个被错误检测为异常。
我想计算 1 类的敏感性和特异性，因为这是异常事件检测的主要兴趣。我就是这样做的
灵敏度 = TP/(TP+FN) = 70/(70+30 ) = 0.70
特异性 = TN/(TN+FP) = 1100/(1100+300) = 0.78


灵敏度是指测试正确检测异常事件的能力。为什么灵敏度如此之低，并且与如此高 (70%) 的准确度 acc_1 不同。 
此计算是否正确？各个类别的准确度和灵敏度之间有什么区别？

我的计算有错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/51513311/calculation-of-sensitivity-and-specificity-from-confusion-matrix</guid>
      <pubDate>Wed, 25 Jul 2018 07:35:29 GMT</pubDate>
    </item>
    </channel>
</rss>