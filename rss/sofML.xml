<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 29 Jan 2024 15:13:04 GMT</lastBuildDate>
    <item>
      <title>如何通过 AI/ML 分析日志</title>
      <link>https://stackoverflow.com/questions/77900640/how-to-analyze-logs-via-ai-ml</link>
      <description><![CDATA[我正在做一个小项目，尝试分析日志并在出现错误时提供根本原因和解决问题的建议。
我有一个 Databricks 作业不断运行以提供日志。我想实时分析这些日志，如果发现异常，实时提供建议。
由于这些日志是非结构化数据，我在想是否可以使用 NLP 来解决这个问题。基本了解日志的上下文并提供建议。
我曾使用机器学习模型对结构化数据进行异常检测，但这是我第一次使用非结构化数据。
我需要以下方面的帮助

如何/在哪里存储可训练的日志？我遇到了矢量数据库，但不确定它是否有帮助。
如何在 llama、gpt 模型之上训练这些基于服务的日志？由于这些模型已经拥有“世俗知识”，因此它们应该能够提供 70% 的建议。但 Databricks 作业给出了一些特定于我的服务的日志，我认为这些日志需要培训。
鉴于有现成的训练模型，如何向模型提供实时日志以使其理解上下文？

由于我是人工智能工作的新手，任何建议/程序/文档/博客/包/Azure 服务都会有很大帮助！！]]></description>
      <guid>https://stackoverflow.com/questions/77900640/how-to-analyze-logs-via-ai-ml</guid>
      <pubDate>Mon, 29 Jan 2024 15:02:18 GMT</pubDate>
    </item>
    <item>
      <title>部署在 Streamlit Coumminity Cloud 上的机器学习模型给出了错误的预测</title>
      <link>https://stackoverflow.com/questions/77899985/machine-learning-model-after-deployed-on-streamlit-coumminity-cloud-is-giving-wr</link>
      <description><![CDATA[我创建了一个垃圾邮件预测机器学习模型，为了创建一个界面，我去了 pycharm 并编写了 app.py 代码，还有另外两个文件 &lt; app.py 文件中使用了 code&gt;vectorizer.pkl 和 model.pkl，在终端上我编写了 streamlit run app.py，它把我带到了本地主机 8501 浏览器，现在一切都很顺利，做出了正确的预测。我想公开这个应用程序以在 GitHub 上分享链接。我在 streamlit 社区云上创建了一个帐户，将其与我的 GitHub 链接起来，并部署了该应用程序。 GitHub 存储库包含所有必要的文件，包括带有整个 ml 模型、app.py、model.pkl,requirements.txt 的笔记本， 向量化器.pkl。现在的问题是，使用公共链接部署的应用程序对于完全相同的输入给出了不同的预测（即说“不是垃圾邮件”而不是“垃圾邮件”）。我将输出附在此处，请告诉我该怎么做。
单击这些链接可查看附加的图像：


当我第一次在 streamlit.io 上部署该应用程序时，它运行良好。几周前，但由于不活动，链接不起作用，所以我删除了该应用程序，并重新开始将其部署为新应用程序，我不明白下一步应该做什么来解决此问题？
我第一次尝试使用渲染将其部署在那里，并且遇到了同样的问题，请帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77899985/machine-learning-model-after-deployed-on-streamlit-coumminity-cloud-is-giving-wr</guid>
      <pubDate>Mon, 29 Jan 2024 13:14:02 GMT</pubDate>
    </item>
    <item>
      <title>通过 Docker 镜像使用时将 Faiss 索引写入文件的问题</title>
      <link>https://stackoverflow.com/questions/77899677/issue-on-writing-faiss-index-to-a-file-when-using-through-docker-image</link>
      <description><![CDATA[我有一个 FastAPI Docker 映像，在启动部分中，我从 Redis 获取 FAISS 索引的二进制版本，使用 pickle.loads 解封它，然后使用
file_path = os.path.join(folder_path, &#39;index.faiss&#39;)
faiss.write_index(faissModelFromRedis,file_path)
将其写入文件。这在本地有效，但是当使用 Docker 部署到 Azure Web App 时，它会抛出异常
文件“/app/main.py”，第 38 行，位于 loadModelAndSetRetriever 2024-01-27T14:03:27.547507225Z faiss.write_index(faiss_model,file_path) 2024-01-27T14:03:27.547510425Z 文件“ /usr/local/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py”，第 10200 行，在 write_index 2024-01-27T14:03:27.547513825Z 返回 _swigfaiss_avx2.write_index(*args) 2024-01-27T14 ：03：27.547517125Z TypeError：重载函数“write_index”的参数数量或类型错误。 2024-01-27T14:03:27.547520225Z 可能的 C/C++ 原型是： 2024-01-27T14:03:27.547523325Z faiss::write_index(faiss::Index const *,char const *) 2024-01-27T14:03 :27.547526526Z faiss::write_index(faiss::Index const *,FILE *) 2024-01-27T14:03:27.547529526Z faiss::write_index(faiss::Index const *,faiss::IOWriter *) 
我们如何解决这个问题？
我尝试使用 pickle.dumps，但使用 Faiss，它无法读取已保存文件的索引。
还尝试在 Dockerfile 中添加 chmod 777 或新用户添加命令，认为这是 faiss 的写入访问问题。]]></description>
      <guid>https://stackoverflow.com/questions/77899677/issue-on-writing-faiss-index-to-a-file-when-using-through-docker-image</guid>
      <pubDate>Mon, 29 Jan 2024 12:19:42 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的语音识别</title>
      <link>https://stackoverflow.com/questions/77899035/speech-recognition-in-machine-learning</link>
      <description><![CDATA[我举办了一场关于机器学习中语音识别的研讨会，在这次研讨会中我们提供了演示、算法和演示文稿
任何人都可以帮助我进行 ML 语音识别
用于 ML 模型中的语音识别
、演示和演示]]></description>
      <guid>https://stackoverflow.com/questions/77899035/speech-recognition-in-machine-learning</guid>
      <pubDate>Mon, 29 Jan 2024 10:30:40 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层“conv3d”的输入 0 与该层不兼容 - Keras 3DConv 模型</title>
      <link>https://stackoverflow.com/questions/77898943/valueerror-input-0-of-layer-conv3d-is-incompatible-with-the-layer-keras-3dc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77898943/valueerror-input-0-of-layer-conv3d-is-incompatible-with-the-layer-keras-3dc</guid>
      <pubDate>Mon, 29 Jan 2024 10:16:50 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI Gym 步骤功能不起作用错误需要 5 个变量才能解压</title>
      <link>https://stackoverflow.com/questions/77898872/openai-gym-step-function-doesnt-work-error-needs-5-variables-to-unpack</link>
      <description><![CDATA[导入健身房
从 nes_py.wrappers 导入 JoypadSpace
从 Contra.actions 导入 SIMPLE_MOVMENT、COMPLEX_MOVMENT、RIGHT_ONLY
SIMPLE_MOVMENT #简化环境

环境=gym.make（&#39;Contra-v0&#39;）
envi = JoypadSpace(envi, SIMPLE_MOVMENT)

重新启动=真

对于范围（1000）内的帧：
    如果重新启动：
        状态 = envi.reset()
    action = envi.action_space.sample() # 生成随机动作
    state,reward,restart,truncated,inf=envi.step(action)#采取随机生成的动作
    envi.render() # 只显示游戏
环境.close()

运行代码后，出现以下错误：
&lt;前&gt;&lt;代码&gt;---&gt; 50 观察、奖励、终止、截断、info = self.env.step(action)
     51 self._elapsed_steps += 1
     53 如果 self._elapsed_steps &gt;= self._max_episode_steps：

ValueError：没有足够的值来解压（预期为 5，实际为 4）

)
我一直在努力解决这个问题，但我不知道如何解决它。我尝试使用较旧的健身房版本，但仍然不起作用
其他人就堆栈溢出提出了同样的问题，但有一个不清楚的答案。]]></description>
      <guid>https://stackoverflow.com/questions/77898872/openai-gym-step-function-doesnt-work-error-needs-5-variables-to-unpack</guid>
      <pubDate>Mon, 29 Jan 2024 10:06:00 GMT</pubDate>
    </item>
    <item>
      <title>在colab中运行excel文件</title>
      <link>https://stackoverflow.com/questions/77898474/running-excel-file-in-colab</link>
      <description><![CDATA[尝试在 Google colab 中加载 Excel 工作表时收到错误消息。 Excel 包含 5000 多行。
我尝试过：data=pd.read_excel(&#39;/content/data_ml.xlsx&#39;)
获得错误：:---------------------------------------- -----------------------------------
BadZipFile Traceback（最近一次调用最后一次）
&lt;ipython-input-3-0935045ece15&gt;在&lt;细胞系：1&gt;()
----&gt; 1 data=pd.read_excel(&#39;/content/data_ml.xlsx&#39;)

6帧
_RealGetContents(self) 中的 /usr/lib/python3.10/zipfile.py
   第1334章
   第1335章
-&gt;第1336章
   第1337章1：
   第1338章

BadZipFile：文件不是 zip 文件
]]></description>
      <guid>https://stackoverflow.com/questions/77898474/running-excel-file-in-colab</guid>
      <pubDate>Mon, 29 Jan 2024 09:04:56 GMT</pubDate>
    </item>
    <item>
      <title>keras多类分类欠拟合</title>
      <link>https://stackoverflow.com/questions/77897827/keras-multiclass-classification-underfitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77897827/keras-multiclass-classification-underfitting</guid>
      <pubDate>Mon, 29 Jan 2024 06:41:23 GMT</pubDate>
    </item>
    <item>
      <title>在 Colab 上访问 TensorFlow Open Image open_images_v4/200k 时出现问题；继续下载原始数据集</title>
      <link>https://stackoverflow.com/questions/77896924/trouble-access-to-tensorflow-open-image-open-images-v4-200k-on-colab-keep-downl</link>
      <description><![CDATA[所以我尝试在 Google Colab 上导入 open_images_v4/200k 数据集，但它不断下载超过 500 GiB 的原始文件，我没有足够的存储空间，也不需要使用那么大的数据集.
我尝试过使用 ds, info = tfds.load(&#39;open_images_v4/200k&#39;, with_info=True) 进行基本导入
然后开始下载，预计大小为 565.11 GiB。第二次我得到了明显的错误，我没有足够的存储空间。
我只想使用 60.70 GiB v4/200k。
请帮忙！]]></description>
      <guid>https://stackoverflow.com/questions/77896924/trouble-access-to-tensorflow-open-image-open-images-v4-200k-on-colab-keep-downl</guid>
      <pubDate>Mon, 29 Jan 2024 00:35:37 GMT</pubDate>
    </item>
    <item>
      <title>将图像移动到目录后数字不同</title>
      <link>https://stackoverflow.com/questions/77895090/different-numbers-after-moving-images-into-a-directory</link>
      <description><![CDATA[我试图将一些图像移动到包含 3 个类（石头、布和剪刀）的目录中，以分割基本目录。
我尝试过这段代码：
train_dir = os.path.join(base_dir, &#39;train&#39;)
val_dir = os.path.join(base_dir, &#39;验证&#39;)
test_dir = os.path.join(base_dir, &#39;测试&#39;)

# 创建子目录
对于 [train_dir, val_dir, test_dir] 中的目录：
    os.makedirs（目录，exist_ok=True）

# 类别列表（石头、剪刀、布）
类名 = os.listdir(base_dir)

# 迭代每个类
对于 class_names 中的 class_name：
    class_path = os.path.join(base_dir, class_name)

    如果 os.path.isdir(class_path):
        # 列出类中的所有图像
        images = [img for img in os.listdir(class_path) if img.endswith(&#39;.jpg&#39;) or img.endswith(&#39;.png&#39;) or img.endswith(&#39;.jpeg&#39;) and img != &#39;README_rpc-简历-images.txt&#39;]

        # 将图像分为训练集、验证集和测试集
        训练图像，测试图像，训练标签，测试标签=训练测试分割（
            所有图像、所有标签、test_size=0.2、random_state=42）

        train_images，val_images，train_labels，val_labels = train_test_split（
            训练图像、训练标签、测试大小=0.25、随机状态=42）
        
        对于 [os.path.join(train_dir, class_name), os.path.join(val_dir, class_name), os.path.join(test_dir, class_name)] 中的目录：
            os.makedirs（目录，exist_ok=True）

        # 将图片移动到对应的子目录
        对于 train_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))
        对于 val_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(val_dir, class_name, img))
        对于 test_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(test_dir, class_name, img))

但是在我使用此代码仔细检查了 train_images 和 train_dir 中的图像数量后：
print(f“train_images 中的图像数量: {len(train_images)}”)
print(f&quot;train_dir 中的图像数量: {len(train_dir)}&quot;)

结果是：
train_images 中的图像数量：1312 和
train_dir 中的图像数量：28
我一直在寻找导致这种数字差异的代码出了什么问题。
将train_images中的图像移动到train_dir的目的是train_dir将在生成器中使用：
train_generator = train_datagen.flow_from_directory()

这需要一个目录才能执行此操作。
关于如何解决这个问题有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77895090/different-numbers-after-moving-images-into-a-directory</guid>
      <pubDate>Sun, 28 Jan 2024 14:15:59 GMT</pubDate>
    </item>
    <item>
      <title>如何阻塞 OCDNet 管道并仅在 OCRNet 上获取结果？ （NVIDIA 光学字符检测和识别解决方案/OCDR）</title>
      <link>https://stackoverflow.com/questions/77892097/how-to-block-the-ocdnet-pipeline-and-get-the-result-only-on-ocrnet-nvidia-opti</link>
      <description><![CDATA[我正在 Jetson 上本地运行 NVIDIA 光学字符检测和识别解决方案。我想阻止 OCDNet 的管道，只使用 OCRNet 进行推断。我注释掉了所有与 OCDNet 相关的代码。结果是空洞的推论。]]></description>
      <guid>https://stackoverflow.com/questions/77892097/how-to-block-the-ocdnet-pipeline-and-get-the-result-only-on-ocrnet-nvidia-opti</guid>
      <pubDate>Sat, 27 Jan 2024 17:22:01 GMT</pubDate>
    </item>
    <item>
      <title>将从 keras YOLOV8Detector 获取的模型更新到 Apple MLPackage/CoreML</title>
      <link>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</link>
      <description><![CDATA[我按照 KerasCV 上的教程使用 YOLOV8 和 KerasCV 进行高效目标检测，并在 不同的数据集
一段时间后，我能够获得预测并将其可视化，如教程中所述：
&lt; /p&gt;
我想在苹果 iOS 应用程序中使用这个模型，所以我使用了 coremltools 包来转换它。然而，“输出”似乎是这样的。 kerascv 制作的产品并不完全是苹果界所期望的。
模型训练完成后，我可以要求进行预测：
 图像，y_true = next(iter(dataset.take(1)))
 y_pred = model.predict(images) // y_pred 是一个字典

y_pred 是包含这些键的字典 [&#39;boxes&#39;, &#39;confidence&#39;, &#39;classes&#39;, &#39;num_detections&#39;]
使用Netron，我可以看看苹果世界所期待的模型的形状

如何修改/重塑从 kerascv 生成的模型，这样我就可以拥有一个将置信度和坐标答案作为两个单独输出输出的模型，而不是输出字典？
我在此链接上找到了一些元素 MobileNetv2 和 SSD 但我我不确定在这种情况下如何应用这些元素]]></description>
      <guid>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</guid>
      <pubDate>Fri, 26 Jan 2024 13:00:22 GMT</pubDate>
    </item>
    <item>
      <title>让谢尔曼-莫里森更新更加高效</title>
      <link>https://stackoverflow.com/questions/77884077/make-sherman-morrison-update-more-efficient</link>
      <description><![CDATA[我需要计算 CIFAR10 数据集子集的点上的参数梯度的协方差矩阵。为此，我有以下代码：
from torch.func import function_call, vmap, grad

model1 = LogisticModel().to(设备)

def loss_fn（预测，目标）：
  损失 = nn.CrossEntropyLoss()
  回波损耗（预测、目标）

defcompute_loss（参数，缓冲区，样本，目标）：
  批次=样本.unsqueeze(0)
  目标 = target.unsqueeze(0)

  预测 = function_call(model1, (params, buffers), (batch,))
  损失= loss_fn（预测，目标）
  回波损耗

ft_compute_grad = grad(compute_loss)
ft_compute_sample_grad = vmap(ft_compute_grad, in_dims=(无, 无, 0, 0))

def sherman_morrison_update(A, u, v):
  vT = v.T
  金=A@u

  α = 1/(1 + vT@Au)
  A = A - alpha*torch.outer(Au, vT@A)
  返回A

testloader1 = DataLoader（test_dataset，batch_size = 512）
params = {k: v.detach() for k, v in model1.named_pa​​rameters()}
buffers = {k: v.detach() for k, v in model1.named_buffers()}
w = 0

p_covs = {p:torch.eye(q.flatten().shape[0]).to(device) for p,q in param_grads.items()}
param_grad_mean = {p:torch.zeros(q​​.flatten().shape[0]).to(device) for p,q in param_grads.items()}

对于 tqdm(testloader1) 中的 x,y：
  param_grads = ft_compute_sample_grad(参数、缓冲区、x.to(设备)、y.to(设备))
  对于 p，q，zip 中的平均值（param_grads.values（），p_covs，param_grad_mean）：
    对于 p 中的 p_grad：
      w += 1
      diff = p_grad.flatten() - param_grad_mean[平均值]
      param_grad_mean[平均值] += diff / w
      p_covs[q] = sherman_morrison_update(A=p_covs[q], u=diff, v= diff)

现在，这是非常低效的，并且在每次迭代中执行此操作都非常耗时。
此外，我们无法真正同时获取所有点的参数梯度，因为这会导致内存问题（因此我转向 Sherman-Morrison）。
有没有办法提高效率？谢尔曼-莫里森的更好实施？还有什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/77884077/make-sherman-morrison-update-more-efficient</guid>
      <pubDate>Fri, 26 Jan 2024 03:37:37 GMT</pubDate>
    </item>
    <item>
      <title>识别 SMOTE 生成的合成样本</title>
      <link>https://stackoverflow.com/questions/77870847/identify-the-synthetic-samples-generated-by-smote</link>
      <description><![CDATA[我有一个带标签的数据集，X 形状为 7000 x 2400，y 形状为 7000。数据严重不平衡，因此我尝试使用 SMOTE 生成合成样本。不过，我想确定 SMOTE 实际生成的合成样本。
作为示例，下面是一个代码片段：
将 pandas 导入为 pd
将 numpy 导入为 np
从 sklearn.datasets 导入 load_iris
从 imblearn.over_sampling 导入 SMOTE

虹膜 = load_iris()

X = 虹膜[&#39;数据&#39;]
y = 虹膜[&#39;目标&#39;]

#数据是平衡的，所以我故意去掉了一些样本
X = X[:125,::]
y = y[:125]

过采样 = SMOTE()
X_smt, y_smt = oversample.fit_resample(X, y)

数组 X_smt 和 y_smt 既有原始样本又有合成样本。是否有一种简单的方法可以通过索引或其他机制来识别合成样本？]]></description>
      <guid>https://stackoverflow.com/questions/77870847/identify-the-synthetic-samples-generated-by-smote</guid>
      <pubDate>Wed, 24 Jan 2024 06:04:18 GMT</pubDate>
    </item>
    <item>
      <title>手动实施多元线性回归的 AIC 分数</title>
      <link>https://stackoverflow.com/questions/58965317/implementing-aic-score-for-multiple-linear-regression-manually</link>
      <description><![CDATA[我已经手动实现了一个多元线性回归类，现在我正在研究度量方法。我尝试手动计算AIC和BIC分数，但结果不正确。原因是我没有使用 Log Likelihood 函数，而是使用了 SSE 方法。您能否建议我如何更改实现来计算完整的 AIC 和 BIC 分数？
这是我的方法现在的样子：
 def AIC_BIC(self, 实际 = None, pred = None):
    如果实际为 None：
      实际 = 自我响应
    如果 pred 为 None：
      pred = self.response_pred

    n = len（实际）
    k = self.num_features

    残差 = np.subtract(pred, 实际)
    RSS = np.sum(np.power(残差, 2))

    AIC = n * np.log(RSS / n) + 2 * k
    BIC = n * np.log(RSS / n) + k * np.log(n)

    退货（AIC、BIC）

请尝试为我提供手动方法，而不是图书馆调用。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/58965317/implementing-aic-score-for-multiple-linear-regression-manually</guid>
      <pubDate>Thu, 21 Nov 2019 00:11:59 GMT</pubDate>
    </item>
    </channel>
</rss>