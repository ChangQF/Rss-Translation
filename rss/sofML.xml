<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 13 May 2024 21:15:26 GMT</lastBuildDate>
    <item>
      <title>Keras 卷积回归模型，始终预测相同的值</title>
      <link>https://stackoverflow.com/questions/78474230/keras-convolutional-regression-model-predicting-always-the-same-value</link>
      <description><![CDATA[目标是计算图像中较大圆圈与较小圆圈的比例。所以我希望模型返回一个浮点数。
数据集包括：

16K 图像，每张图像都包含 2 个比另一个大的圆圈。

具有更大圆圈数据的 CSV，在本例中为文件名和
比例。


问题：
该模型始终预测相同的值。
我尝试过：

标准化 0 和 1 之间的比例。
使用其他方法加载数据集。
不同的优化器和学习率

代码：
train_dir = &#39;../train/circles/&#39;
test_dir = &#39;../test/circles/&#39;

IMG_SIZE = 250
批次大小 = 32

data_df = pd.read_csv(&#39;../data/circles_big.csv&#39;)
train_df = data_df[data_df[&#39;变体&#39;] == &#39;火车&#39;]
test_df = data_df[data_df[&#39;变体&#39;] == &#39;测试&#39;]

train_df = train_df[[&#39;比例&#39;, &#39;文件名&#39;]]
test_df = test_df[[&#39;比例&#39;, &#39;文件名&#39;]]

gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_generator = gen.flow_from_dataframe(
    数据框=train_df，
    目录=train_dir，
    x_col=&#39;文件名&#39;,
    y_col=&#39;比例&#39;,
    目标大小=（IMG_SIZE，IMG_SIZE），
    class_mode=&#39;原始&#39;,
    批量大小=批量大小，
    随机播放=真
）

test_generator = gen.flow_from_dataframe(
    数据框=test_df，
    目录=test_dir，
    x_col=&#39;文件名&#39;,
    y_col=&#39;比例&#39;,
    目标大小=（IMG_SIZE，IMG_SIZE），
    class_mode=&#39;原始&#39;,
    批量大小=批量大小，
    随机播放=真
）

输入= keras.Input（形状=（IMG_SIZE，IMG_SIZE，3））
x = groups.Conv2D(filters=32, kernel_size=3,activation=“relu”)(输入)
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 64，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 128，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 128，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Flatten()(x)
x = 层.Dense(512, 激活=“relu”)(x)
输出=层.Dense(1)(x)

模型= keras.Model（输入=输入，输出=输出）

model.compile（损失=“mse”，优化器=“adam”，指标=[“mae”]）

历史= model.fit（train_generator，epochs = 10，batch_size = 32，verbose = 1）

训练输出（我已经训练了 50 个 epoch，但没有摆脱 72.000 损失）：
344/344 [================================] - 63s 161ms/步 - 损耗：73.8999 - 前：3.7510
纪元 2/10
344/344 [================================] - 54s 156ms/步 - 损耗：72.5437 - mae：3.7838
纪元 3/10
344/344 [================================] - 53s 153ms/步 - 损耗：72.3242 - mae：3.7979
纪元 4/10
344/344 [================================] - 53s 153ms/步 - 损耗：72.3054 - mae：3.7828
纪元 5/10
344/344 [================================] - 54s 158ms/步 - 损耗：72.2541 - mae：3.7986
纪元 6/10
344/344 [================================] - 54s 157ms/步 - 损耗：72.3650 - mae：3.7947
纪元 7/10
344/344 [================================] - 53s 155ms/步 - 损耗：72.2549 - mae：3.7982
纪元 8/10
344/344 [================================] - 55s 159ms/步 - 损耗：72.2433 - mae：3.7906
纪元 9/10
344/344 [==============================] - 54s 158ms/步 - 损耗：72.2253 - 平均：3.8048
纪元 10/10
344/344 [================================] - 53s 154ms/步 - 损耗：72.2451 - mae：3.7841

现在我的问题是为什么预测总是相同的？即使模型没有经过足够的训练，它不应该给出不同的预测值吗？
test_data = next(test_generator)
预测 = model.predict(test_data[0])
真实值 = 测试数据[1]

对于范围内的 i(len(预测))：
    print(f&quot;预测: {predictions[i][0]:}, 真实值: {true_value[i]:}&quot;)

输出：
1/1 [================================] - 0s 33ms/步
预测：3.8054518699645996，真实值：1.448
预测：3.8054518699645996，真实值：1.063
预测：3.8054518699645996，真实值：6.06
预测：3.8054518699645996，真实值：1.058
预测：3.8054518699645996，真实值：2.826
预测：3.8054518699645996，真实值：3.188
预测：3.8054518699645996，真实值：4.437
预测：3.8054518699645996，真实值：1.983
预测：3.8054518699645996，真实值：2.213
...
]]></description>
      <guid>https://stackoverflow.com/questions/78474230/keras-convolutional-regression-model-predicting-always-the-same-value</guid>
      <pubDate>Mon, 13 May 2024 18:47:00 GMT</pubDate>
    </item>
    <item>
      <title>正类是大多数类，因此很难解释结果</title>
      <link>https://stackoverflow.com/questions/78474226/positive-class-is-the-majority-class-made-it-hard-to-interpret-result</link>
      <description><![CDATA[我正在做一个流失预测任务，其中 1 类（流失）是大多数类别。
两个类的结果
我的问题是：这个结果是类设置的结果吗（通常正类是负类）。我该如何解释上面的结果？就F1分数而言，0类和1类之间是否存在权衡？
结果中，默认的 F1 在不平衡数据集上得分更高，而我预计重采样方法会改善 F1。他们实际上为少数群体改进了 F1，但没有为多数群体改进。]]></description>
      <guid>https://stackoverflow.com/questions/78474226/positive-class-is-the-majority-class-made-it-hard-to-interpret-result</guid>
      <pubDate>Mon, 13 May 2024 18:45:18 GMT</pubDate>
    </item>
    <item>
      <title>机器学习：从哪里开始实践？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78474129/machine-learning-where-to-start-the-practice</link>
      <description><![CDATA[我正在学习机器学习和大数据的大学课程，即将完成（今年年底），但我们很少进行练习，并且很多理论。
我想要一些关于我可以遵循哪些来源在机器学习领域进行实践的建议。
谢谢大家。]]></description>
      <guid>https://stackoverflow.com/questions/78474129/machine-learning-where-to-start-the-practice</guid>
      <pubDate>Mon, 13 May 2024 18:18:29 GMT</pubDate>
    </item>
    <item>
      <title>如何将 LinkedIn 或类似网站上的原始文本格式职位发布处理为键值格式？</title>
      <link>https://stackoverflow.com/questions/78473771/how-can-i-process-raw-text-format-job-posts-from-linkedin-or-similar-sites-into</link>
      <description><![CDATA[出于研究目的，我从链接中收集了一些职位信息。我想从这些职位帖子中获取特定数据并将其保存在我的 SQL 数据库中。那么我如何处理职位发布 txt 文件并获取特定字段，如标题、描述、技能、要求列表、注释（如果有）、角色、地点、福利等。而且每个职位发布都有自己的格式。我想我需要使用一些 NLP 技术，比如 NER，但我不知道如何实际解决这个问题。我不是机器学习专家，所以一些建议、参考资料会很好。]]></description>
      <guid>https://stackoverflow.com/questions/78473771/how-can-i-process-raw-text-format-job-posts-from-linkedin-or-similar-sites-into</guid>
      <pubDate>Mon, 13 May 2024 17:02:32 GMT</pubDate>
    </item>
    <item>
      <title>有人设法在 colab 上运行 alphageometry 吗？</title>
      <link>https://stackoverflow.com/questions/78473546/has-anyone-manage-to-run-alphageometry-on-colab</link>
      <description><![CDATA[我正在尝试在 colab 上运行 alphageometry 但不断遇到问题：
https://colab.research.google.com/drive/1RrTfa3O80QOFL68rXdtAyn1KHt0NCCB3 ?usp=共享
下面的堆栈跟踪不包括 JAX 内部框架。
前面是发生的原始异常，未修改。
上述异常是导致以下异常的直接原因：
回溯（最近一次调用最后一次）：
  文件“/usr/lib/python3.10/runpy.py”，第 196 行，在 _run_module_as_main 中
    返回_run_code（代码，main_globals，无，
  文件“/usr/lib/python3.10/runpy.py”，第 86 行，在 _run_code 中
    执行（代码，run_globals）
  文件“/content/alphageometry/alphageometry.py”，第651行，在&lt;module&gt;中。
    应用程序.运行（主要）
  文件“/usr/local/lib/python3.10/dist-packages/absl/app.py”，第308行，运行中
    _run_main（主要，参数）
  文件“/usr/local/lib/python3.10/dist-packages/absl/app.py”，第 254 行，在 _run_main 中
    sys.exit(主(argv))
  文件“/content/alphageometry/alphageometry.py”，第 637 行，在 main 中
    模型 = get_lm(_CKPT_PATH.value, _VOCAB_PATH.value)
  文件“/content/alphageometry/alphageometry.py”，第 203 行，get_lm
    返回 lm.LanguageModelInference(vocab_path, ckpt_init, mode=&#39;beam_search&#39;)
  文件“/content/alphageometry/lm_inference.py”，第 62 行，位于 __init__ 中
    (tstate, _, imodel, prngs) = trainer.initialize_model()
  文件“/content/alphageometry/meliad_lib/meliad/training_loop.py”，第 367 行，initialize_model
    变量 = model_init_fn(init_rngs, imodel.get_fake_input())
  文件“/content/alphageometry/models.py”，第 68 行，在 __call__ 中
    自解码器（
  文件“/content/alphageometry/meliad_lib/meliad/transformer/decoder_stack.py”，第 273 行，在 __call__ 中
    嵌入 = embeddings.astype(self.dtype)
  文件“/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py”，第 4952 行，在 _astype 中
    dtypes.check_user_dtype_supported(dtype, “astype”)
类型错误：JAX 仅支持数字和布尔数据类型，在 astype` 中获取数据类型 bfloat16

这就是它停止的地方：
!python -m alphageometry \
--alsologtostderr \
--problems_file=$(pwd)/examples.txt \
--problem_name=正交中心 \
--mode=alpha几何 \
--defs_file=$(pwd)/defs.txt \
--rules_file=$(pwd)/rules.txt \
--ckpt_path=$数据\
  --vocab_path=$DATA/geometry.757.model \
  --gin_search_paths=$MELIAD_PATH/transformer/configs,$(pwd) \
  --gin_file=base_htrans.gin \
  --gin_file=大小/medium_150M.gin \
  --gin_file=选项/positions_t5.gin \
  --gin_file=选项/lr_cosine_decay.gin \
  --gin_file=选项/seq_1024_nocache.gin \
  --gin_file=geometry_150M_generate.gin \
  --gin_param=DecoderOnlyLanguageModelGenerate.output_token_losses=True \
  --gin_param=TransformerTaskConfig.batch_size=$BATCH_SIZE \
  --gin_param=TransformerTaskConfig.sequence_length=128 \
  --gin_param=Trainer.restore_state_variables=False \
  --beam_size=$BEAM_SIZE \
  --search_深度=$深度\

到目前为止，有人设法让它在 Colab 中运行吗？我在网上没有找到任何相关内容。
我按照 git 上提供的教程进行操作，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/78473546/has-anyone-manage-to-run-alphageometry-on-colab</guid>
      <pubDate>Mon, 13 May 2024 16:12:04 GMT</pubDate>
    </item>
    <item>
      <title>在深度训练/验证循环期间使用分层 k 折叠时出现越界错误</title>
      <link>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</guid>
      <pubDate>Mon, 13 May 2024 14:43:39 GMT</pubDate>
    </item>
    <item>
      <title>高 MSE 和负 R 平方值的原因 [已迁移]</title>
      <link>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</guid>
      <pubDate>Mon, 13 May 2024 14:10:35 GMT</pubDate>
    </item>
    <item>
      <title>预测社交媒体参与率的最佳机器学习模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</link>
      <description><![CDATA[根据你们的意见，哪个模型是预测社交媒体（例如 Facebook）中参与度帖子的最佳模型。
如果你们中有人遇到过同样的情况，请分享一下您的经验
谢谢
我尝试了这两个：

线性回归（11% 准确度）

LightGBM 回归器（准确度 79%）

]]></description>
      <guid>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</guid>
      <pubDate>Mon, 13 May 2024 13:59:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么二元分类中非 sigmoid 变换输出比 sigmoid 变换输出更匹配目标矩阵？</title>
      <link>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</link>
      <description><![CDATA[我正在使用神经网络进行二元分类任务，其中模型输出 logits，然后通过 sigmoid 函数将其映射到概率。目标矩阵是一个 17x17 网格，其中距中心曼哈顿距离 &lt;=2 内的单元格标记为 1（正类），所有其他单元格标记为 0（负类）：
目标矩阵
这是损失的代码。我使用 binary_cross_entropy_with_logits 作为我的损失函数。 sigmoid函数在pytorch提供的上述函数中实现：
 defforward(自身，输入，目标)：
        pos_mask =（目标== 1）
        neg_mask =（目标== 0）
        pos_num = pos_mask.sum().float()
        neg_num = neg_mask.sum().float()
        重量 = target.new_zeros(target.size())
        权重[pos_mask] = 1 / pos_num
        权重[neg_mask] = 1 / neg_num * self.neg_weight
        重量 /= 重量.sum()
        返回 F.binary_cross_entropy_with_logits(
            输入，目标，权重，减少=&#39;总和&#39;）

然后我可视化训练模型的输出，并注意到一个意想不到的现象。可视化显示了两张图像：一张是模型直接输出的 logits（左），另一张是通过对这些 logits 应用 sigmoid 函数获得的概率（右）。令人惊讶的是，与 sigmoid 变换输出（概率）相比，非 sigmoid 变换输出（logits）似乎更好地匹配目标矩阵的模式。
可视化
这个结果令人费解，因为在训练期间，损失函数对 sigmoid 变换后的概率进行运算。因此，人们会期望 sigmoid 变换的输出更接近目标矩阵。
这种行为背后是否存在解释或常见原因，即原始逻辑在视觉上比从其派生的概率更准确地匹配目标结构？我可能缺少任何可能影响此外观的可视化或缩放因素吗？
我在网上搜索过，但似乎没有与我类似的问题。我仔细检查了 binary_cross_entropy_with_logits 中是否存在 sigmoid 函数：
labels = self._create_labels(responses.size())
loss = self.criterion(responses, labels) # 标准：binary_cross_entropy_with_logits

_responses = torch.sigmoid(responses)
_loss = self._criterion(_responses, labels) # 标准：binary_cross_entropy

但是，在我的实验中，loss 等于 _loss，这意味着虽然是 sigmoided 响应尝试拟合目标矩阵，但非 sigmoided 响应却拟合目标矩阵目标矩阵更好。
&lt;小时/&gt;
如果您想了解有关该项目的更多详细信息，请参阅以下描述。我正在使用 SiamFC 重现一个对象跟踪项目，可视化 siamfc 中第 171 行的响应图-pytorch/siamfc/siamfc.py，作为反应图，反映第一帧中的groundtruth目标与后续帧中的搜索区域之间的相似性。您可以在项目中下载预训练的模型，插入一些代码进行可视化并运行代码查看结果。]]></description>
      <guid>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</guid>
      <pubDate>Mon, 13 May 2024 13:45:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOv5 标记对象的正确方法</title>
      <link>https://stackoverflow.com/questions/78471070/correct-way-to-tag-objects-with-yolov5</link>
      <description><![CDATA[我需要标记一系列图像以用于织物上的缝纫检测。我使用 YOLOv5 算法。
我遇到的问题是，我不清楚标记这些缝纫的最佳方式应该是什么。
下图显示了织物中的缝线。

正如您在图片中看到的，缝线总是会占据布料的整个宽度。最初，我曾想过对缝纫的几个部分/部分进行标记（检测到的缝纫数量并不重要，对我来说真正重要的是它检测到至少有一个缝纫）。下图展示了这个想法：

但是，我不清楚这是否是正确的方法（而是最佳方法），或者应该创建一个完全包围缝纫的单个标签。
另一方面，根据文档中给出的标签提示，标签应该恰好包围要检测的对象，在对象和标签的边界框之间留出尽可能小的空间。
&lt;块引用&gt;
标签准确性。标签必须紧密包围每个对象。没有空间
应该存在于对象与其边界框之间。没有物体
应该缺少标签。

获得最佳训练结果的提示
在这种特殊情况下，考虑到缝线总是以非常相似的方式出现（它们总是具有水平方向），这些标签将非常薄（高度很小），因此不清楚我认为该算法将能够检测到它们。以我的拙见，我认为稍微增加标签的高度将使算法更有效地检测缝纫，因为通过这些缝纫连接的织物可能具有相同的颜色。 （第二张图片显示了我正在谈论的想法）。
如果您能帮助我并告诉我进行此标记的最佳方法，我将不胜感激。
提前非常感谢您。]]></description>
      <guid>https://stackoverflow.com/questions/78471070/correct-way-to-tag-objects-with-yolov5</guid>
      <pubDate>Mon, 13 May 2024 08:48:35 GMT</pubDate>
    </item>
    <item>
      <title>在 Streamlit.io 上部署 Python 应用程序时出错：“sklearn”的 ModuleNotFoundError</title>
      <link>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</link>
      <description><![CDATA[我在 Streamlit.io 上部署 Python 应用程序时遇到错误。尽管在我的 requests.txt 文件中列出了“scikit-learn”，但我在部署过程中遇到了 ModuleNotFoundError。
]]></description>
      <guid>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</guid>
      <pubDate>Sun, 12 May 2024 23:18:51 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 可以在 Python 中获取输入序列吗？</title>
      <link>https://stackoverflow.com/questions/78027259/can-arima-take-input-sequence-in-python</link>
      <description><![CDATA[在Python中，当你训练LSTM模型时，你可以在部分数据上训练模型。然后在推理时，您可以为其提供任何您喜欢的输入，例如不属于训练集的 10 个最近时间步长。它将产生输出。现在 ARIMA 可以以同样的方式运行吗？我们可以给它输入序列吗？或者它是否使用训练数据来预测下一步？
下面是我的代码：
导入 pandas 作为 pd
从 statsmodels.tsa.arima.model 导入 ARIMA
进口火炬
导入系统
导入数学

# 从CSV文件中读取数据集
df = pd.read_csv(&#39;sm_data.csv&#39;, header=None)

# 将前102行作为训练数据，其余作为测试数据
train_data = df.iloc[:102, :]
test_data = df.iloc[102:, :]


# 迭代每个趋势
预测结果 = {}
对于 df.columns 中的列：
    # 在训练数据上拟合 ARIMA 模型
    模型 = ARIMA(train_data[列], 顺序=(10,1,0))
    model_fit = model.fit()

    # 预测未来 36 个月
    预测 = model_fit.forecast(步数=36)

    # 存储预测结果
    Forecast_results[列] = 预测

# 将预测结果转换为DataFrame
Forecast_df = pd.DataFrame(forecast_results)

# 将预测结果保存到 CSV
Forecast_df.to_csv(&#39;forecast_results.csv&#39;, index=False)
]]></description>
      <guid>https://stackoverflow.com/questions/78027259/can-arima-take-input-sequence-in-python</guid>
      <pubDate>Tue, 20 Feb 2024 12:16:51 GMT</pubDate>
    </item>
    <item>
      <title>从 nltk 停用词中排除负面词</title>
      <link>https://stackoverflow.com/questions/76924321/exclude-negative-words-from-nltk-stopwords</link>
      <description><![CDATA[我想从我的句子中删除 nltk 停用词，除了那些具有负面含义的停用词，例如：不，不，不能等。换句话说，我想从停用词列表中排除负面词。我怎样才能做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/76924321/exclude-negative-words-from-nltk-stopwords</guid>
      <pubDate>Thu, 17 Aug 2023 18:45:59 GMT</pubDate>
    </item>
    <item>
      <title>仅具有一个数字特征的逻辑回归</title>
      <link>https://stackoverflow.com/questions/43010225/logistic-regression-with-just-one-numeric-feature</link>
      <description><![CDATA[当您只有一个数值特征时，使用 scikit-learn 的 LogisticRegression 求解器的正确方法是什么？
我运行了一个我发现很难解释的简单示例。谁能解释一下我在这里做错了什么？
导入pandas
将 numpy 导入为 np
从 sklearn.linear_model 导入 LogisticRegression

X = [1, 2, 3, 10, 11, 12]
X = np.reshape(X, (6, 1))
Y = [0, 0, 0, 1, 1, 1]
Y = np.reshape(Y, (6, 1))

lr = 逻辑回归()

lr.fit(X, Y)
print(&quot;2 --&gt; {0}&quot;.format(lr.predict(2)))
print(&quot;4 --&gt; {0}&quot;.format(lr.predict(4)))

这是脚本运行完毕后得到的输出。 4 的预测不应该是 0 因为根据高斯分布 4 更接近根据测试集分类为 0 的分布吗？

&lt;前&gt;&lt;代码&gt;2 --&gt; [0]
4 --&gt; [1]

当只有一列包含数值数据时，逻辑回归采用什么方法？ ]]></description>
      <guid>https://stackoverflow.com/questions/43010225/logistic-regression-with-just-one-numeric-feature</guid>
      <pubDate>Fri, 24 Mar 2017 22:36:12 GMT</pubDate>
    </item>
    <item>
      <title>控制 Scikit Learn 中逻辑回归的阈值</title>
      <link>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</link>
      <description><![CDATA[我在高度不平衡的数据集上使用 scikit-learn 中的 LogisticRegression() 方法。我什至将 class_weight 功能设置为 auto。
我知道在逻辑回归中应该可以知道特定类对的阈值是多少。 
是否可以知道 LogisticRegression() 方法设计的每个一对一类的阈值是多少？
我在文档页面中没有找到任何内容。
默认情况下，无论参数值如何，它是否都会应用 0.5 值作为所有类的阈值？]]></description>
      <guid>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</guid>
      <pubDate>Wed, 25 Feb 2015 10:11:33 GMT</pubDate>
    </item>
    </channel>
</rss>