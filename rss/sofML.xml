<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 13 Mar 2024 15:14:25 GMT</lastBuildDate>
    <item>
      <title>使用 SentenceTransformers 编码后嵌入校验和不同？</title>
      <link>https://stackoverflow.com/questions/78154849/different-embedding-checksums-after-encoding-with-sentencetransformers</link>
      <description><![CDATA[我正在使用 SentenceTransformers 库计算一些嵌入。然而，在对句子进行编码并在检查其值的总和时计算其嵌入时，我得到了不同的结果。例如：
在：
&lt;前&gt;&lt;代码&gt;
随机种子 = 42
np.random.seed(RANDOM_SEED)
随机种子（RANDOM_SEED）
tf.random.set_seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)


句子 = df[&#39;内容&#39;].tolist()
标签 = df[&#39;标签&#39;].tolist()


对于tqdm中的transformer_model（transformer_models，desc =“变压器模型”）：
    tqdm.write(f&quot;使用 Transformer 模型处理：{transformer_model}&quot;)
    模型 = SentenceTransformer(transformer_model)
    嵌入 = model.encode(句子)
    print(f“{transformer_model} 的嵌入校验和：”, np.sum(embeddings))
    

输出：
M-CLIP/M-BERT-Distil-40 的嵌入校验和：1105.9185

或者
M-CLIP/M-BERT-Distil-40 的嵌入校验和：1113.5422

我注意到当我重新启动并清除 jupyter 笔记本的输出，然后重新运行完整笔记本时会发生这种情况。知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78154849/different-embedding-checksums-after-encoding-with-sentencetransformers</guid>
      <pubDate>Wed, 13 Mar 2024 15:07:56 GMT</pubDate>
    </item>
    <item>
      <title>我们可以结合 RL 和 ML/DL 来进行复杂的二元分类吗？</title>
      <link>https://stackoverflow.com/questions/78154666/can-we-conbine-rl-and-ml-dl-to-do-a-complex-binary-classfication</link>
      <description><![CDATA[事情是这样的：
有一个金融数据集（Freddie Mac Single-Family Loan-Level Dataset），其中包含：客户的地址、交易流向以及许多其他特征（大约20个）。
有一个特征可以判断客户是否存在延期还款的情况，即判断他是否是诈骗者。
我想通过 RL 和 ML/DL 组合来学习所有其他功能。然后只有通过在模型中输入其他特征来判断该客户是否会进行欺诈。
我目前的想法是：从随机分类开始，然后利用RL和ML/DL结合模型不断调整分类方法（调整特征权重、模型中的内部指标等）以获得最佳分类方法并获得最高的分类精度。
但是我不知道如何开始，因为我对强化学习不是很熟悉。 （我对深度学习和机器学习比较熟悉）
我找不到任何相关参考资料。
有人可以给我一个想法或教程吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78154666/can-we-conbine-rl-and-ml-dl-to-do-a-complex-binary-classfication</guid>
      <pubDate>Wed, 13 Mar 2024 14:42:00 GMT</pubDate>
    </item>
    <item>
      <title>如何对困难数据进行多项式回归？</title>
      <link>https://stackoverflow.com/questions/78154421/how-do-i-do-polynomial-regression-right-on-difficult-data</link>
      <description><![CDATA[我的多项式回归遇到问题。由于某种原因，我的线画错了。我查看了堆栈上的其他类似问题，但找不到适合我的解决方案。我正在处理价格 (y) 和评论数量 (X)。
有人遇到过类似的事情或对相似的数据成功完成多项式回归吗？
这是我的代码：
# 定义自变量和因变量
X = cph_listings_df[[&#39;reviews_per_month&#39;]].values.reshape(-1, 1)
y = cph_listings_df[&#39;价格&#39;].values.reshape(-1, 1)

# 分为测试和训练
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# 尺度特征
定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)

# 对数据集进行线性回归拟合
lin_reg = 线性回归()
lin_reg.fit(X, y)

# 将多项式回归拟合到数据集
poly_model = 多项式特征（度=2）
X_poly = poly_model.fit_transform(X) # 将 X 变换为多边形特征
pol_reg = LinearRegression() # 线性回归实例
pol_reg.fit(X_poly, y) # 训练模型
y_predict = pol_reg.predict(X_poly) # 对训练模型进行预测
plt.scatter(X, y, color=&#39;red&#39;) # red = 实际数据点
    plt.plot(X, y_predict, color=&#39;blue&#39;)
    plt.title(&#39;多项式回归)&#39;)
    plt.xlabel(&#39;评论数量&#39;)
    plt.ylabel(&#39;价格&#39;)
    plt.show()

这是图表：

这是我的老师告诉我我需要得到的（我自己画的线）：

我尝试在运行代码之前对 X 值进行排序，但对我来说没有任何改变。]]></description>
      <guid>https://stackoverflow.com/questions/78154421/how-do-i-do-polynomial-regression-right-on-difficult-data</guid>
      <pubDate>Wed, 13 Mar 2024 14:06:54 GMT</pubDate>
    </item>
    <item>
      <title>在python中创建线性回归模型的问题</title>
      <link>https://stackoverflow.com/questions/78152862/problem-with-creating-a-linear-regression-model-in-python</link>
      <description><![CDATA[我有一个数据库，其中包含一个城市的多个属性：
该数据库中保存了各种属性（约 19,000 个）。每个房产都有一些特征，例如：销售价格、房产面积、浴室数量、建造年份、上市天数......
我是机器学习算法编程的新手，希望首先编写一个简单的线性回归模型，该模型可以根据其他数据预测该房产的上市天数。
数据保存在Excel中。
这就是我所做的：
&lt;前&gt;&lt;代码&gt;
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.metrics 导入mean_squared_error, r2_score
从 sklearn.model_selection 导入 train_test_split
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd
导入请求


模型=线性回归()
data=pd.read_excel(r“C:\Users....”)

X=np.array(data.drop([“daysOnMarket”], axis=1))
Y=np.array(数据[“daysOnMarket”])
x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)
model.fit(x_train, y_train)
y_pred=模型.预测(x_test)
print(model.score(x_test, y_test))
打印（均方误差（y_test，y_pred））


现在让我觉得我做错了的是，我得到的分数是 0.9999852324248868，均方误差是 0.07659752059595726
现在我不明白这是一个过度拟合问题还是我只是在编程中做错了什么。
谁能帮我找出问题出在哪里吗？
这是我的数据示例：
]]></description>
      <guid>https://stackoverflow.com/questions/78152862/problem-with-creating-a-linear-regression-model-in-python</guid>
      <pubDate>Wed, 13 Mar 2024 10:06:17 GMT</pubDate>
    </item>
    <item>
      <title>我们可以使用不同的 yaml 文件来微调新数据集的模型，但与之前的数据集具有相同的类吗？</title>
      <link>https://stackoverflow.com/questions/78152669/can-we-use-different-yaml-file-for-fine-tuning-a-model-with-newdataset-but-has-s</link>
      <description><![CDATA[我使用我的自定义数据集训练了 YOLOv8 模型，其中使用了 ultralytics 和 pytorch。我具有与第一个数据集相同的数据集，但图像中对象的位置在新数据集中发生了更改。现在，如果我在不从第一个数据集 YAML 文件中获取任何引用的情况下进行注释，它会起作用吗？
第一个经过训练的 YAML 文件如下：
训练：/home/user/Code/newdata/YOLODataset/images/train/
val：/home/user/Code/newdata/YOLODataset/images/val/
测试：/home/user/Code/newdata/YOLODataset/images/test/
数控：8
名称：[“货架”、“托盘”、“条形码”、“box-botte”、“mbox”、“cobj”、“糖浆”、“半”]

微调 yaml 文件：
训练：/home/user/Code/newdata/YOLODataset/images/train/
val：/home/user/Code/newdata/YOLODataset/images/val/
测试：/home/user/Code/newdata/YOLODataset/images/test/
数控：7
名称：[“货架”、“托盘”、“条形码”、“盒子瓶”、“mbox”、“糖浆”、“半个”]

第二个 YAML 文件适合微调自定义预训练模型吗？我第一次使用 520 张图像和 25 个 epoch 进行训练。现在我应该微调模型多少张图像和纪元？
提前致谢
我使用 Pytorch 和 Ultralytics。我可以按照上面的YAML文件进行微调吗？]]></description>
      <guid>https://stackoverflow.com/questions/78152669/can-we-use-different-yaml-file-for-fine-tuning-a-model-with-newdataset-but-has-s</guid>
      <pubDate>Wed, 13 Mar 2024 09:41:41 GMT</pubDate>
    </item>
    <item>
      <title>验证错误：无法实例化 GPT4AllEmbeddings 模型</title>
      <link>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</link>
      <description><![CDATA[我在尝试创建 GPT4AllEmbeddings 实例时遇到问题。但是我不断收到以下错误
[15] 中的单元格，第 1 行
----&gt; 1 vectorstore = Chroma.from_documents(文档 = 分割, 嵌入 = GPT4AllEmbeddings())
2 检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
3retrieve_docs =retrieve.get_relevant_documents(“你是什么？”)
文件 ~\anaconda3\Lib\site-packages\pydantic\main.py:341，位于 pydantic.main.BaseModel.init()
ValidationError：GPT4AllEmbeddings 出现 1 个验证错误
根
无法实例化模型（type=value_error）
这是相关的代码片段
vectorstore = Chroma.from_documents(documents = splits, embeddings = GPT4AllEmbeddings())
检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
retrieved_docs =retrieve.get_relevant_documents(“什么是Young Decade？”)
打印（len（检索文档））
打印（retrieve_docs[0].page_content）

有人可以提供有关如何解决此错误的指导吗？]]></description>
      <guid>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</guid>
      <pubDate>Wed, 13 Mar 2024 09:36:07 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试通过训练迭代计算余弦相似度时，如何选择模型权重</title>
      <link>https://stackoverflow.com/questions/78152246/how-do-i-select-model-weights-when-i-try-to-calculate-cosine-similarity-though-t</link>
      <description><![CDATA[我正在尝试计算“t”步骤的权重值和“t-1”步骤的权重值之间的余弦相似度。
我正在使用 LSTM 网络 &amp; 2FC层。
我想检查训练期间的体重差异。
但是如果我想检查这些事情，我想知道我是只选择 LSTM 层的权重还是全部（LSTM，2FC 权重）或最终层的权重（FC_2 权重）
谢谢。
请帮助我。我不知道如何细化余弦相似条件下选择图层的最佳解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78152246/how-do-i-select-model-weights-when-i-try-to-calculate-cosine-similarity-though-t</guid>
      <pubDate>Wed, 13 Mar 2024 08:34:22 GMT</pubDate>
    </item>
    <item>
      <title>为什么 e 在神经网络中使用得如此之多？</title>
      <link>https://stackoverflow.com/questions/78152237/why-is-e-used-so-much-in-the-nn</link>
      <description><![CDATA[我不明白为什么我们在神经网络中如此频繁地使用“e”，可能是 sigmoid 函数或 softmax 函数。
在 sigmoid 函数中，我们本质上是将值 y=mx+b 压缩到 0-1 范围内，那么为什么我们专门使用“e”。如果我们凭直觉，使用“2”而不是“e”是有意义的，我的意思是我们要进行二元分类，这样才有意义，对吗？
另外，在softmax函数中，我们采用e^x / sum(e^x)，为​​什么我们需要这样做，我的意思是我们试图获得x属于哪个类的概率，所以为什么不能我们只是知道像这样 x/sum(abs(x)) 吗？]]></description>
      <guid>https://stackoverflow.com/questions/78152237/why-is-e-used-so-much-in-the-nn</guid>
      <pubDate>Wed, 13 Mar 2024 08:31:52 GMT</pubDate>
    </item>
    <item>
      <title>如何检测图片是否上下颠倒？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78151191/how-to-detect-if-a-picture-is-upside-down</link>
      <description><![CDATA[我的团队正在开发一项在 AWS 上运行并从 S3 存储桶中提取图片的服务。这些图片是来自监控摄像头视频流的帧，导致它们没有 Exif 元数据，而且大多数时候，图片中不会有任何人。
该服务需要“读取”这些图片并区分其中是否有颠倒的情况，以便我们确定这些相机是否正常工作。最初我以为可以使用AWS Rekognition，但是看了文档，似乎无法满足要求。
所以，我想知道是否有任何 AWS 服务或库可以完成此任务并部署在 Lambda 或 ECS 中？]]></description>
      <guid>https://stackoverflow.com/questions/78151191/how-to-detect-if-a-picture-is-upside-down</guid>
      <pubDate>Wed, 13 Mar 2024 04:08:00 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试使用数据集包创建数据集时，出现“无法转换，因为列名称不匹配”错误</title>
      <link>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</link>
      <description><![CDATA[DataFrame 结构
上图显示了我的数据结构。
from sklearn.model_selection import train_test_split
从数据集中导入特征、ClassLabel、值、数据集、DatasetDict

df_train, df_tmp = train_test_split(
        movie_df,stratify=movie_df[“标签”], test_size=0.2)

df_val, df_test = train_test_split(
        df_tmp,stratify=df_tmp[“标签”], test_size=0.5)

ds_features = Features({“text”: Value(“string”), “label”: ClassLabel(names=labels)})

数据集 = DatasetDict({
    “火车”：Dataset.from_pandas(df_train.reset_index(drop=True),features=ds_features),
    “有效”：Dataset.from_pandas(df_val.reset_index(drop=True),features=ds_features),
    “测试”：Dataset.from_pandas(df_test.reset_index(drop=True),features=ds_features)})

数据集

这段代码给了我一个值错误，如下所示：
错误
错误
我期待类似的东西，但不具有相同的值：
DatasetDict({
    火车：数据集（{
        特征：[&#39;文本&#39;，&#39;标签&#39;]，
        行数：13267
    })
    有效：数据集（{
        特征：[&#39;文本&#39;，&#39;标签&#39;]，
        行数：1658
    })
    测试：数据集（{
        特征：[&#39;文本&#39;，&#39;标签&#39;]，
        行数：1659
    })
})

谁能告诉我我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</guid>
      <pubDate>Wed, 13 Mar 2024 04:00:13 GMT</pubDate>
    </item>
    <item>
      <title>预测分位数与梯度增强回归相交</title>
      <link>https://stackoverflow.com/questions/78140825/prediction-quantiles-intersect-from-gradient-boosted-regression</link>
      <description><![CDATA[我正在尝试构建一个回归模型，该模型接收各种类型的产品和市场信息，对数据进行转换，并在一天中定期预测产品的价格。我希望能够预测分位数置信带，以帮助我的团队根据模型的预测做出决策。我遵循了 scikit-learn 文档中的示例&lt; /code&gt;，但我发现这些回归器产生的预测有时会相交，例如有时P50预测大于P75预测或小于P25预测。
查看此处突出显示的图表中的错误。
即使使用更宽的频段（包括 P95 和 P05），这个问题仍然存在。尽管数据集比我正在使用的数据集简单得多，但我已经能够毫无问题地重现链接的示例。
下面的代码代表了该问题的可重现示例，并带有生成的数据集：
# 导入和定义
将 numpy 导入为 np
从 sklearn.ensemble 导入 HistGradientBoostingRegressor
从 sklearn.model_selection 导入 train_test_split
从 sklearn.datasets 导入 make_regression

X,y = make_regression(
    n_样本 = 14000,
    n_特征 = 39,
    n_目标 = 1
）

# 进行测试/训练分割和模型字典
X_train, X_test, y_train, y_test = train_test_split(
    X、Y、测试大小=0.1
）
型号={}

for alpha in [0.25, 0.5, 0.75]: # HistGradientBoostingRegressor model - Early_stopping = False 有助于解决问题，但不能解决问题
    hgbr = HistGradientBoostingRegressor(
        max_iter=100, # 通常在1000左右，例如减少
        损失=“分位数”，
        分位数 = 阿尔法，
    ）

    # 将最佳模型添加到字典中
    models[f&quot;P{alpha*100:02.0f}&quot;] = hgbr.fit(X_train, y_train.ravel())


任何帮助或建议将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78140825/prediction-quantiles-intersect-from-gradient-boosted-regression</guid>
      <pubDate>Mon, 11 Mar 2024 13:05:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 Huggingface MT5 模型中执行批量编码时会得到不同的嵌入？</title>
      <link>https://stackoverflow.com/questions/78139855/why-do-i-get-different-embeddings-when-i-perform-batch-encoding-in-huggingface-m</link>
      <description><![CDATA[我正在尝试使用 HuggingFace 的 mt5-base 模型对一些文本进行编码。我使用的模型如下所示
从转换器导入 MT5EncoderModel、AutoTokenizer

模型 = MT5EncoderModel.from_pretrained(“google/mt5-base”)
tokenizer = AutoTokenizer.from_pretrained(“google/mt5-base”)

def get_t5_embeddings(文本):
    last_hidden_​​state = model(input_ids=tokenizer(texts, return_tensors=“pt”, padding=True).input_ids).last_hidden_​​state
    pooled_sentence = torch.max(last_hidden_​​state, 暗淡=1)
    返回 pooled_sentence[0].detach().numpy()

当我注意到相同的文本与其自身的余弦相似度分数较低时，我正在做一些实验。我做了一些挖掘，意识到如果我批量进行编码，模型会返回非常不同的嵌入。为了验证这一点，我运行了一个小实验，逐步生成 Hello 的嵌入和 10 个 Hello 的列表。并检查列表中 Hello 和第一个 Hello 的嵌入（两者应该相同）。
对于范围 (1, 10) 内的 i：
    print(i, (get_t5_embeddings([“你好”])[0] == get_t5_embeddings([“你好”]*i)[0]).sum())

这将返回嵌入中相互匹配的值的数量。
结果是这样的：
&lt;前&gt;&lt;代码&gt;1 768
2 768
3 768
4 768
5 768
6 768
7 768
8 27
9 27

每次运行它时，如果批量大小超过 768，就会出现不匹配情况。
为什么我会得到不同的嵌入以及如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78139855/why-do-i-get-different-embeddings-when-i-perform-batch-encoding-in-huggingface-m</guid>
      <pubDate>Mon, 11 Mar 2024 10:14:53 GMT</pubDate>
    </item>
    <item>
      <title>为多标签 ViTForImageClassification 准备数据集</title>
      <link>https://stackoverflow.com/questions/77967230/prepare-a-dataset-for-multilabel-vitforimageclassification</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77967230/prepare-a-dataset-for-multilabel-vitforimageclassification</guid>
      <pubDate>Fri, 09 Feb 2024 09:52:59 GMT</pubDate>
    </item>
    <item>
      <title>xgboost 错误：dtypes 必须是 int、float 或 bool，但它们是</title>
      <link>https://stackoverflow.com/questions/67977854/xgboost-error-dtypes-must-be-int-float-or-bool-but-they-are</link>
      <description><![CDATA[我有一个经过预处理的房地产相关DataFrame，具有以下数据类型：
&lt;前&gt;&lt;代码&gt;&gt;&gt; df.dtype

OHE_Cat__x0_单户住宅 Int64
OHE_Cat__x0_联排别墅 Int64
OHE_Cat__x1_1 Int64
OHE_Cat__x1_2 Int64
邮政编码 Int64
价格 Int64
床位 Int64
浴室 Float64
平方英尺 Int64
批量大小 Int64
建造年份 Int64
纬度 Float64
经度 Float64
年龄 Int64
时间 VAR UNIX Int64
is_Pandemic 布尔值
is_CY 布尔值
数据类型：对象

但是，当尝试拟合我的 XGBRegressor 时，我收到以下错误：
ValueError：数据的 DataFrame.dtypes 必须是 int、float 或 bool。
            没想到字段 OHE_Cat__x0_Single Family Residential、OHE_Cat__x0_Townhouse、OHE_Cat__x1_1、OHE_Cat__x1_2、ZIP OR POSTAL CODE、BEDS、BATHS、SQUARE FEET、LOT SIZE、YEAR BUILT、LATITUDE、LONGITUDE、Age、TIME VAR UNIX、is_Pandemic、is_CY 中的数据类型

奇怪的是，当我使用pd.get_dummmies时，这个错误并不存在，但在切换到sklearn.preprocessing.OneHotEncoder后，我开始收到它，所以我在想我的下面的代码有错误吗？
oneHotE = OneHotEncoder(drop=&#39;first&#39;)
变压器 = ColumnTransformer([(&#39;OHE_Cat&#39;, oneHotE, 分类)], 剩余 = &#39;直通&#39;)
    
df = pd.DataFrame(transformer.fit_transform(df), columns=transformer.get_feature_names()).convert_dtypes()

在train_test_split之前，我已尝试对数据集进行以下更改：
df = df.apply(pd.to_numeric, axis=1)
df = df.apply(pd.to_numeric, axis=0)
df = df.convert_dtypes()
df = df.dropna()
df = df._get_numeric_data()

编辑：

RandomForestRegressor 运行正常，没有错误，但出现以下警告：

&lt;块引用&gt;
futurewarning：字节/字符串数组正在转换为十进制
如果 dtype=&#39;numeric&#39; 则为数字。此行为在 0.24 中已弃用，并且
将在 1.1 中删除（0.26 重命名）。请将您的数据转换为
明确地改为数值。


CatBoostRegressor 出现以下错误：无法将 FloatingArray 转换为 numpy.ndarray
]]></description>
      <guid>https://stackoverflow.com/questions/67977854/xgboost-error-dtypes-must-be-int-float-or-bool-but-they-are</guid>
      <pubDate>Mon, 14 Jun 2021 22:20:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在sklearn中计算.fit()训练模型的实际大小？</title>
      <link>https://stackoverflow.com/questions/45601897/how-to-calculate-the-actual-size-of-a-fit-trained-model-in-sklearn</link>
      <description><![CDATA[是否可以在 scikit-learn 中计算模型（假设是随机森林分类器）的大小？ 
例如：

&lt;块引用&gt;
 from sklearn.ensemble import RandomForestClassifier
  clf = RandomForestClassifier(n_jobs=-1, n_estimators=10000, min_samples_leaf=50)
  clf.fit(self.X_train, self.y_train)


我可以确定clf的大小吗？]]></description>
      <guid>https://stackoverflow.com/questions/45601897/how-to-calculate-the-actual-size-of-a-fit-trained-model-in-sklearn</guid>
      <pubDate>Wed, 09 Aug 2017 23:00:07 GMT</pubDate>
    </item>
    </channel>
</rss>