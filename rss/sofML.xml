<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 13 Apr 2024 12:19:44 GMT</lastBuildDate>
    <item>
      <title>使用 Huggingface Trainer API 在视频数据集上微调“google/vit-base-patch16-224-in21k”时出现 Pytorch 错误</title>
      <link>https://stackoverflow.com/questions/78320351/pytorch-error-when-fine-tuning-google-vit-base-patch16-224-in21k-on-video-data</link>
      <description><![CDATA[我正在尝试读取 csv 文件中带有标签的自定义视频数据集，并使用 Huggingface Trainer 和 google/vit-base-patch16-224-in21k 模型对它们进行传输训练。
这是我到目前为止所实现的，但遇到了 Key 42 错误代码。
导入火炬
导入 torchvision.transforms 作为变换
将 torchvision.io.video 导入为视频
从 torch.utils.data 导入数据集，DataLoader
从 Transformers 导入 ViTFeatureExtractor、ViTForImageClassification、TrainingArguments、Trainer
从 sklearn.model_selection 导入 train_test_split
将 pandas 导入为 pd
导入全局
导入影音
从 tqdm 导入 tqdm

# 定义类
类 = [&#39;class_0&#39;, &#39;class_1&#39;]

# 为视频帧定义自定义数据集
类视频数据集（数据集）：
    def __init__(自我，视频路径，标签，变换=无)：
        self.video_paths = video_paths
        self.labels = 标签
        self.transform = 变换

    def __len__(自身):
        返回 len(self.video_paths)

    def __getitem__(self, idx):
        帧, _, _ = video.read_video(self.video_paths[idx], pts_unit=&#39;sec&#39;)
        样本 = {&#39;frames&#39;: 框架, &#39;标签&#39;: self.labels[idx]}

        如果自我变换：
            样本[&#39;frames&#39;] = [self.transform(frame) 用于样本[&#39;frames&#39;]中的帧]

        返回样品

# 定义预处理帧的转换
变换 = 变换.Compose([
    变换.调整大小((224, 224)),
    变换.ToTensor(),
]）

# 预处理每一帧的函数
def preprocess_frame(帧):
    帧 = 变换.ToPILImage()(帧)
    帧 = 变换（帧）
    返回帧

# 数据集预处理函数
def preprocess_dataset（数据集）：
    返回数据集

# 定义训练参数
训练参数 = 训练参数（
    输出目录=“./训练”，
    per_device_train_batch_size=4,
    num_train_epochs=3,
    logging_dir=&#39;./logs&#39;,
    记录步骤=100，
）

# 加载ViT模型和特征提取器
模型 = ViTForImageClassification.from_pretrained(“google/vit-base-patch16-224-in21k”)
feature_extractor = ViTFeatureExtractor.from_pretrained(“google/vit-base-patch16-224-in21k”)

#加载训练视频
train_videos = glob.glob(“./dataset100/train/all/*.mp4”)

#加载标签
train_df = pd.read_csv(&#39;./train100.csv&#39;,names=header_list)
标签 = train_df[&#39;标签&#39;]

#将数据集拆分为训练集和验证集
train_paths，val_paths，train_labels，val_labels = train_test_split（train_videos，标签，test_size = 0.2，random_state = 42）

# 创建数据集并对其进行预处理
train_dataset = VideoDataset(train_paths, train_labels, 变换=变换)
val_dataset = VideoDataset(val_paths, val_labels, 变换=变换)
train_dataset = preprocess_dataset(train_dataset)
val_dataset = preprocess_dataset(val_dataset)

print(&quot;训练视频数量:&quot;, len(train_paths))
print(&quot;验证视频数量:&quot;, len(val_paths))
print(&quot;训练标签数量：&quot;, len(train_labels))
print(&quot;验证标签数量：&quot;, len(val_labels))

print(“训练视频：”, train_videos[:5])
print(&quot;训练标签：&quot;, train_labels[:5])

# 定义函数来计算精度
def 计算精度(pred):
    标签 = pred.label_ids
    preds = pred.predictions.argmax(-1)
    return {“准确度”: (preds == labels).mean()}

# 定义训练器
教练=教练（
    型号=型号，
    参数=训练参数，
    训练数据集=训练数据集，
    eval_dataset = val_dataset，
    compute_metrics=compute_accuracy,`你的文本`
）

# 训练模型
训练师.train()

这是我收到的错误消息，我非常感谢您的帮助。
------------------------------------------------ ----------------------------------------------------
KeyError Traceback（最近一次调用最后一次）
文件 c:\Users\Code\venv\Lib\site-packages\pandas\core\indexes\base.py:3791，在 Index.get_loc(self, key) 中
   第3790章
-&gt;第3791章
   第3792章

文件index.pyx:152，在pandas._libs.index.IndexEngine.get_loc()中

文件index.pyx:181，在pandas._libs.index.IndexEngine.get_loc()中

文件 pandas\_libs\hashtable_class_helper.pxi:2606，位于 pandas._libs.hashtable.Int64HashTable.get_item()

文件 pandas\_libs\hashtable_class_helper.pxi:2630，位于 pandas._libs.hashtable.Int64HashTable.get_item()

密钥错误：42

上述异常是导致以下异常的直接原因：

KeyError Traceback（最近一次调用最后一次）
单元格 In[31]，第 121 行
    第112章 训练师=训练师（
    113 型号=型号，
    第114章
   （...）
...
   第3801章否则我们会失败并重新加注
   第3802章
   第3803章

密钥错误：42
]]></description>
      <guid>https://stackoverflow.com/questions/78320351/pytorch-error-when-fine-tuning-google-vit-base-patch16-224-in21k-on-video-data</guid>
      <pubDate>Sat, 13 Apr 2024 11:00:26 GMT</pubDate>
    </item>
    <item>
      <title>在打印 OLS Summery 或打印任何内容时，它在 google collab 中未以正确的布局打印</title>
      <link>https://stackoverflow.com/questions/78320334/while-printing-ols-summery-or-while-printing-anything-it-is-not-printing-in-prop</link>
      <description><![CDATA[“我想以正确的格式打印 OLS 摘要，但我无法这样做。我已经尝试了所有可能的解决方案，但它无法正常工作。即使打印 pd.info() 时，它的格式也不正确。”
您可以在此处查看布局]]></description>
      <guid>https://stackoverflow.com/questions/78320334/while-printing-ols-summery-or-while-printing-anything-it-is-not-printing-in-prop</guid>
      <pubDate>Sat, 13 Apr 2024 10:51:51 GMT</pubDate>
    </item>
    <item>
      <title>如何将参数（标签）传递给映射函数map_func，可从Python中的tf.data.Dataset.map()调用</title>
      <link>https://stackoverflow.com/questions/78320298/how-to-pass-argumentslabels-to-map-function-map-func-callable-from-tf-data-da</link>
      <description><![CDATA[有已知的方法来创建数据集：
代码片段借自： https://www.tensorflow.org/tutorials/audio/simple_audio&lt; /a&gt;
#从文件中收集数据
&#39;&#39;&#39;
.....一些代码我认为不需要粘贴，请参阅上面的链接以获取完整代码......
&#39;&#39;&#39;
#创建地图函数

def get_label(文件路径):
  零件 = tf.strings.split(
      输入=文件路径，
      sep=os.path.sep)
  # 注意：您将在此处使用索引而不是元组解包来启用此功能
  # 在 TensorFlow 图中工作。
  返回零件[-2]

#地图功能!!!!!
def get_waveform_and_label(文件路径):
  标签 = get_label(文件路径)
  audio_binary = tf.io.read_file(文件路径)
  波形 = 解码音频（音频二进制）
  返回波形、标签

自动调谐 = tf.data.AUTOTUNE

#创建数据集
files_ds = tf.data.Dataset.from_tensor_slices(train_files)


#标记数据集中每个数据的最常见方法是使用 tf.data.Dataset.map():
波形_ds = 文件_ds.map(
    map_func=get_waveform_and_label,
    num_parallel_calls=自动调谐）

对于waveform_ds中的元素：
  打印（元素）

打印执行后，任何元素都会显示此类数据（我随机选取了数据集行“waveform_ds”）：
(, )
(, )

两个问题：
1.如果没有参数传递给“get_waveform_and_label”，tf.data.Dataset.map() 函数如何确定我要传递什么样的标签？在....Dataset.map()？
2. 如果我想使用自己的标签（在列表、元组或字典中定义，而不是像上面的许多教程和代码片段那样来自文件路径文件夹），我必须做什么？例如：
my_labels = [&#39;放松&#39;, &#39;抓握&#39;, &#39;放松&#39;]

那么除了将 my_labels 作为地图函数“get_waveform_and_label”中的常量值之外，还有其他方法吗？
下面的代码不是主要的，那是“我试图解决问题”、“maplabel”部分的代码。写得不好，“标签”接收“my_labels”之一item，RaggedTensor &#39;timeframes&#39; 实际上是一个数组，存储简单的张量，例如：
tf.Tensor(
[[0.5369535 0.2724565 0.073154 ... 0.0074817 0.2035824 0.0882927]
 [0.5376732 0.2733304 0.0730333 ... 0.0017834 0.1970369 0.0859187]
 [0.5307747 0.2692053 0.0720603 ... 0.0029357 0.1989727 0.0866213]
 ...
 [0.5395046 0.2826822 0.0747677 ... 0.0085316 0.1982029 0.0849934]
 [0.5299433 0.2774992 0.073246 ... 0.0083179 0.1994617 0.085429 ]
 [0.5329857 0.278462 0.0736021 ... 0.0070133 0.2008929 0.0860079]]，形状=（117, 128），dtype=float64）

tf.张量(
[[0.5278226 0.27012 0.0709168 ... 0.0110207 0.1954106 0.0877619]
 [0.5296971 0.2716435 0.0712691 ... 0.005279 0.1967631 0.0881876]
 [0.5316442 0.2725459 0.0716114 ... 0.0044511 0.1991368 0.089243 ]
 ...
 [0.5419291 0.2776711 0.0726136 ... 0.0114332 0.1941741 0.0884957]
 [0.5319294 0.2723156 0.071426 ... 0.010159 0.1962118 0.0891404]
 [0.5338816 0.2737131 0.0718814 ... 0.0103788 0.1974683 0.0897296]]，形状=（118, 128），dtype=float64）

&lt;前&gt;&lt;代码&gt;
_def maplabel（数据集，tensored_label）：
    返回数据集，tensored_label

def get_timeFrames_with_label(时间帧:tf.RaggedTensor, \
                              标签：str）：

    样本计数 = 时间范围.shape[0]
    dataset_lines = [无] * 样本数
    str_tensors = [无] * 样本数

    
    对于范围内的 i（samplesCount）：
        dataset_lines[i] = tf.data.Dataset.from_tensors(timeframes[i])
        str_tensors[i] = tf.constant(标签, dtype=tf.string)
    
    com1tframes_ds = tf.data.Dataset.choose_from_datasets(dataset_lines,\ tf.data.Dataset.range(samplesCount))
    #command_ds = tf.data.Dataset.from_tensor_slices(str_tensors)
    #...Dataset.zip(com1tframes_ds, command_ds) 给出错误“command_ds 没有功能”
    #string.isidentifier”
    
    com1tframes_ds.map(map_func=maplabel(com1tframes_ds, 标签), \
                       num_parallel_calls=tf.data.AUTOTUNE)_
]]></description>
      <guid>https://stackoverflow.com/questions/78320298/how-to-pass-argumentslabels-to-map-function-map-func-callable-from-tf-data-da</guid>
      <pubDate>Sat, 13 Apr 2024 10:35:58 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 图像分类模型在第二个 epoch 后达到峰值，并在其余训练中保持相同的准确性</title>
      <link>https://stackoverflow.com/questions/78320148/tensorflow-image-classification-model-peaks-after-second-epoch-and-keeps-the-sam</link>
      <description><![CDATA[我有一个简单的分类模型，有 4 个不同的类别：停止、前进、右、左交通手势信号。在第二个纪元之后，我在其余纪元中获得了相同的准确性。我也尝试过使用不同的数据集，并认为这是一个数据问题。
def fit_cnn_model(X_train, Y_train, X_test, Y_test, savedir, num_layers=2,
                  num_filters=64，kernel_size=3，pool_size=2，dropout_rate=0.3，learning_rate=0.0001，
                  n_epochs=10，batch_size=64，详细=2）：

    模型=顺序（）
    date_time = datetime.now().strftime(&quot;%Y-%m-%d %H:%M:%S&quot;)

    对于 _ 在范围内（num_layers）：
        model.add(Conv2D(filters=num_filters, kernel_size=kernel_size,activation=&#39;relu&#39;, padding=&#39;same&#39;, kernel_initializer=&#39;he_uniform&#39;))
        model.add(BatchNormalization())
        model.add(MaxPooling2D(pool_size=pool_size))
        model.add(Dropout(dropout_rate))

    模型.add(压平())
    model.add（密集（128，激活=&#39;relu&#39;））
    model.add（密集（4，激活=&#39;softmax&#39;））

    选择=亚当（学习率=学习率）
    model.compile(optimizer=opt,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

    历史 = model.fit(X_train, Y_train,
                        纪元=n_纪元，
                        批量大小=批量大小，
                        验证数据=（X_测试，Y_测试），
                        详细=详细）

    模型.summary()

    分数 = model.evaluate(X_test, Y_test, verbose=0)
    print(&quot;损失: {:.2f}&quot;.format(scores[0]))
    print(&quot;准确率: {:.2f}%&quot;.format(scores[1] * 100))

    model_path = os.path.join(savedir, &#39;saved_model_&#39; + date_time + &#39;.h5&#39;)
    模型.保存（模型路径）
    print(f&quot;模型已保存到 {model_path}&quot;)

    返回模型

def load_data(image_folder, label_folder, target_size=(224, 224)):
    # 加载数据集并排序
    image_files = os.listdir(image_folder)
    label_files = os.listdir(label_folder)
    image_files.sort()
    label_files.sort()

    图片 = []
    标签=[]

    # 加载图像和标签
    对于 image_files 中的 img_file：
        img_path = os.path.join(image_folder, img_file)

        label_file = img_file.replace(&quot;.jpg&quot;, &quot;.txt&quot;).replace(&quot;.jpeg&quot;, &quot;.txt&quot;)
        label_path = os.path.join(label_folder, label_file)

        img = Image.open(img_path).resize(target_size)
        img_array = np.array(img) / 255.0
        图像.append(img_array)

        将 open(label_path, &#39;r&#39;) 作为 f：
            label_str = f.readline().strip()
            label_dict = {&#39;停止&#39;: 0, &#39;继续&#39;: 1, &#39;左&#39;: 2, &#39;右&#39;: 3}
            标签 = label_dict.get(label_str, -1)
            如果标签==-1：
                raise ValueError(“未知标签：{}”.format(label_str))

        labels.append(标签)

    图像 = np.array(图像)
    标签 = np.array(标签)
    标签 = to_categorical(标签, 4)


    X_train, X_test, Y_train, Y_test = train_test_split(图像, 标签, test_size=0.2)

    返回X_train，Y_train，X_test，Y_test


我尝试稍微调整学习率、dropout、层和过滤器。还使用了不同的经过验证的数据集。]]></description>
      <guid>https://stackoverflow.com/questions/78320148/tensorflow-image-classification-model-peaks-after-second-epoch-and-keeps-the-sam</guid>
      <pubDate>Sat, 13 Apr 2024 09:30:48 GMT</pubDate>
    </item>
    <item>
      <title>错误：尝试量化模型时，“tf.TensorListSetItem”操作既不是自定义操作也不是弹性操作</title>
      <link>https://stackoverflow.com/questions/78319798/error-tf-tensorlistsetitem-op-is-neither-a-custom-op-nor-a-flex-op-while-tryi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78319798/error-tf-tensorlistsetitem-op-is-neither-a-custom-op-nor-a-flex-op-while-tryi</guid>
      <pubDate>Sat, 13 Apr 2024 07:02:24 GMT</pubDate>
    </item>
    <item>
      <title>为什么训练 nn 的准确率没有提高并且损失值如此之高？</title>
      <link>https://stackoverflow.com/questions/78319532/why-when-train-nn-accuracy-doesnt-improve-and-loss-value-is-so-high</link>
      <description><![CDATA[我正在尝试根据 Kaggle 的数据集使用 TensorFlow 创建一个简单的神经网络来查找债务余额；然而，我尝试的每种方法都会导致相同的结果 = 疯狂的损失（有时甚至是负数）和固定的低准确度。
# 将日期分配给 X 和 y
X = pd.read_csv(&#39;Train_Features.csv&#39;)
y = pd.read_csv(&#39;Train_Output.csv&#39;)

# 删除索引
X = X.drop(&#39;索引&#39;, 轴= 1)
y = y.drop(&#39;索引&#39;, 轴= 1)

# 将 Yes 和 No 转换为整数的时间

# 带有“是”/“否”的列列表
columns_to_convert = [&#39;自己的&#39;、&#39;学生&#39;、&#39;已婚&#39;]

# 转换“是”和“否”
X[columns_to_convert] = X[columns_to_convert].map(lambda x: 1 if x == &#39;Yes&#39; else 0)

features_num = [&#39;收入&#39;, &#39;限额&#39;, &#39;评级&#39;, &#39;卡&#39;, &#39;年龄&#39;, &#39;教育&#39;, &#39;拥有&#39;, &#39;学生&#39;, &#39;已婚&#39;]
features_cat = [&#39;区域&#39;]

# 特征的预处理器设置
预处理器 = make_column_transformer(
    (MinMaxScaler(), features_num), # 最小-最大缩放到数字特征
    （OneHotEncoder（），features_cat），
）

# 分割数据
X_train, X_valid, y_train, y_valid = train_test_split(X, y,random_state=42)

# 处理特征
X_train = 预处理器.fit_transform(X_train)
X_valid = 预处理器.transform(X_valid)

# 使用最小-最大缩放来缩放 y(Balance)
y_scaler = MinMaxScaler()
y_train = y_scaler.fit_transform(y_train)
y_valid = y_scaler.transform(y_valid)

输入 = [X_train.shape[1]]

# 构建模型架构
模型 = keras.Sequential([
    层.BatchNormalization(input_shape=input),
    层.Dense(256, 激活=&#39;relu&#39;),
    层.BatchNormalization(),
    层.Dense(256, 激活=&#39;relu&#39;),
    层.BatchNormalization(),
    层.密集(1),
]）

# 编译模型
模型.编译(
    优化器=&#39;亚当&#39;,
    损失=&#39;mse&#39;,
    指标=[&#39;准确性&#39;],
）

# 提前停止以防止过度拟合
Early_stopping = keras.callbacks.EarlyStopping(
    耐心=8，
    最小增量=0.001，
    Restore_best_weights=真，
）

# 训练模型
历史=模型.fit(
    X_列车，y_列车，
    验证数据=（X_有效，y_有效），
    批量大小=512，
    纪元=100，
    回调=[early_stopping],
）

# 将历史记录转换为 DataFrame 以进行绘图
History_df = pd.DataFrame(history.history)
History_df.loc[:, [&#39;loss&#39;, &#39;val_loss&#39;]].plot(title=“交叉熵”)
History_df.loc[:, [&#39;准确度&#39;, &#39;val_accuracy&#39;]].plot(title=&quot;准确度&quot;)

编辑：我找出了导致高损失值的原因。事实证明，这是由于一些诸如“平衡”之类的价值观造成的。太高了，并且模型不是使用归一化集，而是使用梯度，这不好。然而，准确性问题仍然存在
数据展望




]]></description>
      <guid>https://stackoverflow.com/questions/78319532/why-when-train-nn-accuracy-doesnt-improve-and-loss-value-is-so-high</guid>
      <pubDate>Sat, 13 Apr 2024 04:33:34 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在随机森林的核心中使用 adaBoosting 而不是 bootstrap？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</link>
      <description><![CDATA[随机森林使用 Bagging（Bootstrapping）为其每棵树选择样本，对吗？是否可以使用 adaBoosting 代替？有什么优点和优点？缺点？为什么我没看到这个？
我看到 Sci-kit learn 中的 RandomForestClassifier 允许启用/禁用引导程序，否则没有选项可以用 boosting 替换它。]]></description>
      <guid>https://stackoverflow.com/questions/78319519/is-it-possible-to-use-adaboosting-in-the-core-of-random-forest-instead-of-bootst</guid>
      <pubDate>Sat, 13 Apr 2024 04:19:58 GMT</pubDate>
    </item>
    <item>
      <title>拟合投票回归器中权重的估计器预测[关闭]</title>
      <link>https://stackoverflow.com/questions/78318639/fitting-estimator-predictions-for-weights-in-the-voting-regressor</link>
      <description><![CDATA[投票回归器所做的似乎就是取平均值，除非您手动输入一些权重，但这看起来并不有效。对 x 和 y 中的所有预测进行线性拟合是否有意义以及它会是什么样子。我假设有一些限制的一阶线性拟合。
我尝试为其编写一些代码，这不是一项艰巨的任务，但我更好奇第二次拟合的统计实现，因为它感觉不“真实”。]]></description>
      <guid>https://stackoverflow.com/questions/78318639/fitting-estimator-predictions-for-weights-in-the-voting-regressor</guid>
      <pubDate>Fri, 12 Apr 2024 20:45:00 GMT</pubDate>
    </item>
    <item>
      <title>在用于大数据分析的 PySpark 中，面临使用哈希转换字符串特征的问题。有什么解决办法吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78317805/in-pyspark-for-big-data-analytics-facing-issues-converting-string-features-usin</link>
      <description><![CDATA[我是大数据分析新手，目前正在使用 PySpark 处理大数据机器学习任务，特别是信用卡欺诈检测。然而，我遇到了障碍。在我的数据集中，我有两个字符串特征，需要在构建模型之前将其转换为数值。我尝试过各种方法，例如one-hot编码和散列，但没有成功。下面，我提供我最近遇到的错误。您能否建议如何解决这个问题，或者是否有更好的方法来解决这个问题？如果需要，请随时询问任何其他信息，例如代码片段或其他信息。


大多数时候我都会面临这个错误和缓冲区溢出！

如果有人可以帮助我解决这种情况，请告诉我。几天来我尝试了不同的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78317805/in-pyspark-for-big-data-analytics-facing-issues-converting-string-features-usin</guid>
      <pubDate>Fri, 12 Apr 2024 17:09:42 GMT</pubDate>
    </item>
    <item>
      <title>如何修改我的代码，以便它可以使用网络摄像头正确预测</title>
      <link>https://stackoverflow.com/questions/78317359/how-to-modify-my-code-so-it-can-correctly-predict-using-the-webcam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78317359/how-to-modify-my-code-so-it-can-correctly-predict-using-the-webcam</guid>
      <pubDate>Fri, 12 Apr 2024 15:39:17 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：操作数无法与形状一起广播 (10,1024) (1024,1) [关闭]</title>
      <link>https://stackoverflow.com/questions/78316002/valueerror-operands-could-not-be-broadcast-together-with-shapes-10-1024-1024</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78316002/valueerror-operands-could-not-be-broadcast-together-with-shapes-10-1024-1024</guid>
      <pubDate>Fri, 12 Apr 2024 11:33:12 GMT</pubDate>
    </item>
    <item>
      <title>Numpy reshape() 以编程方式以 3D 方式显示 2D 数组</title>
      <link>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</link>
      <description><![CDATA[示例数据
我有一系列经纬度的天气数据，其形状如下：(1038240,4)（有关示例数据，请参阅照片）
我想将其重塑为形状 (4,721,1440)，这将是 721 x 1440 地球图像上的四个天气变量（&amp; lat/lon）。
我已经尝试过：
newarr = t_new.reshape(4,721,1440)

这会将其置于正确的形状，但与前两个纬度/经度坐标与以下首选格式不匹配：
对于上图中的 (6,4) 示例数据，此操作看起来像下面的 (2,3,2) 数组：
所需输出示例
newarr = t_new.reshape(4,721,1440)
]]></description>
      <guid>https://stackoverflow.com/questions/78308446/numpy-reshape-to-display-2d-array-in-3d-programmatically</guid>
      <pubDate>Thu, 11 Apr 2024 06:06:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tfidfvectorizer 的功能从英语修改为西班牙语</title>
      <link>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</link>
      <description><![CDATA[我有一个 TfidfVectorizer 模型，该模型经过英语文本数据的训练来预测英语通话中的情绪。我想针对西班牙语文本调整此 TfidfVectorizer，以便我可以将其与使用原始英语 TfidfVectorizer 训练的现有 XGBoost 模型一起使用。我的目标是在将功能从英语转换为西班牙语的同时保留现有的权重，例如将“谢谢”翻译为西班牙语。致“谢谢”，并重复使用旧的权重。本质上，我想应用相同的 TfidfVectorizer，但修改了功能名称。
这些功能已从英语翻译为西班牙语，并且 TfidfVectorizer 已针对英语文本进行了训练。我需要一种方法来构建一个新的 TfidfVectorizer，它融合了旧的权重和新的西班牙语特征，而无需重新拟合模型或将整个文本语料库翻译成西班牙语。你能推荐一种Python方法来实现这一点吗？请添加相关的Python代码。]]></description>
      <guid>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</guid>
      <pubDate>Wed, 27 Mar 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow federated 中工作时遇到“学习属性”错误</title>
      <link>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78158329/facing-error-in-learning-attribute-while-working-in-tensorflow-federated</guid>
      <pubDate>Thu, 14 Mar 2024 05:35:24 GMT</pubDate>
    </item>
    <item>
      <title>如何使用变分推理来拟合分布</title>
      <link>https://stackoverflow.com/questions/59276428/how-to-use-variational-inference-to-fit-a-distribution</link>
      <description><![CDATA[假设我有 gamma=10 的泊松分布。我想拟合一个高斯分布，它可以最小化泊松分布的 KL 散度。这可以通过变分推理来实现。我如何使用 Stan 进行此优化？
参考手册有一个关于 VI 的章节，但仅提供了有关如何在内部实现的一些高级信息，而不是如何使用它。
用户指南在章节中提到了 VI 22.2，但仅对其效率进行了一些一般性评论。
关于 SO 的相关问题可能是：PyStan API 中的变分推理？ 
但这只是询问 advi 是否已在 PyStan 中实现（它已经实现）。没有其他信息。]]></description>
      <guid>https://stackoverflow.com/questions/59276428/how-to-use-variational-inference-to-fit-a-distribution</guid>
      <pubDate>Tue, 10 Dec 2019 22:43:29 GMT</pubDate>
    </item>
    </channel>
</rss>