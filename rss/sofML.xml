<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 12 Mar 2024 06:18:19 GMT</lastBuildDate>
    <item>
      <title>python darts 中的 RNN 训练指标</title>
      <link>https://stackoverflow.com/questions/78144820/rnn-training-metrics-in-python-darts</link>
      <description><![CDATA[我目前正在使用 python darts 训练 RNNModel。为了比较不同的训练模型，我想从 fit 方法中提取 train_loss 和 val_loss 。我该怎么做？我读过一些有关指标集合的内容，但不知道如何使用它。
这是我当前的代码
train = # 训练数据为 TimeSeries
模型 = RNNModel(模型 =“LSTM”, input_chunk_length=self.past_samples)
模型.fit(火车)

训练过程中损失会显示在控制台中，但我不知道如何访问它。
到目前为止，我已尝试在线查找任何文档，并向 bing chat 和 ChatGPT 寻求帮助。然而他们告诉我使用不存在的model.history.history[“loss”]]]></description>
      <guid>https://stackoverflow.com/questions/78144820/rnn-training-metrics-in-python-darts</guid>
      <pubDate>Tue, 12 Mar 2024 05:29:49 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：环境类型为 <class '__main__.StockTradingEnvironment'>，而不是 Gymnasium 环境</title>
      <link>https://stackoverflow.com/questions/78144599/valueerror-the-environment-is-of-type-class-main-stocktradingenvironment</link>
      <description><![CDATA[运行代码时
env = DummyVecEnv([lambda: StockTradingEnvironment(stock_data)])，它提供
ValueError：环境类型为 ，而不是 Gymnasium 环境。在本例中，我们期望安装 OpenAI Gym 并且环境是 OpenAI Gym 环境。
我已经导入了必要的库，如下所示。
导入 yfinance 作为 yf
将 numpy 导入为 np
将 pandas 导入为 pd
从 stable_baselines3 导入 DQN
从 stable_baselines3.common.vec_env 导入 DummyVecEnv
从健身房进口空间

请帮助解决该错误。]]></description>
      <guid>https://stackoverflow.com/questions/78144599/valueerror-the-environment-is-of-type-class-main-stocktradingenvironment</guid>
      <pubDate>Tue, 12 Mar 2024 04:03:13 GMT</pubDate>
    </item>
    <item>
      <title>在 TensorFlow 推荐模型中初始化 FactorizedTopK 时出现 ValueError</title>
      <link>https://stackoverflow.com/questions/78144515/valueerror-when-initializing-factorizedtopk-in-tensorflow-recommenders-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78144515/valueerror-when-initializing-factorizedtopk-in-tensorflow-recommenders-model</guid>
      <pubDate>Tue, 12 Mar 2024 03:28:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使神经网络的输出满足约束条件？</title>
      <link>https://stackoverflow.com/questions/78144484/how-to-make-the-output-of-the-neural-network-satisfy-the-constraint-condition</link>
      <description><![CDATA[假设我的神经网络有两个输出y1_pred和y2_pred，损失函数使用MSE。现在假设真实的y1和y2满足y1=y2**2这样的条件，在理想情况下，网络经过足够的训练后自然会满足这个约束，但在现实中，由于网络和约束的复杂性条件下，网络输出不能很好地满足约束，有什么解决办法吗？
事实上，真正的约束是一个经过训练的 REGRESSION 模型，其中 y2 = REGRESSION(y1)，
所以我让loss=MSE(y1_pred,y2_pred,y1_true,y2_true) +0.5*(y2-REGRESSION(y1))，但这没有效果。]]></description>
      <guid>https://stackoverflow.com/questions/78144484/how-to-make-the-output-of-the-neural-network-satisfy-the-constraint-condition</guid>
      <pubDate>Tue, 12 Mar 2024 03:15:52 GMT</pubDate>
    </item>
    <item>
      <title>改进多模态检测模型指标[关闭]</title>
      <link>https://stackoverflow.com/questions/78143946/improving-multimodal-detection-model-metrics</link>
      <description><![CDATA[我正在尝试建立一个多模态模型来检测言语中的抑郁症。我使用 opensmile 从语音文件中提取了音频特征（这是必需的），并在文本文件上使用了 bert 嵌入。然后我将它们都输入到 LSTM-CNN 模型中
def create_fused_model(audio_input_shape, text_input_shape, dropout_rate=0.3, l2_reg= 0.01):
        # 音频输入和 LSTM 处理
    音频输入=输入（形状=（音频输入形状，1），名称=&#39;音频输入&#39;）
    lstm_audio = LSTM(32, return_sequences=True, kernel_regularizer=l2(l2_reg))(audio_input)
    lstm_audio2 = LSTM(16, return_sequences=True, kernel_regularizer=l2(l2_reg))(lstm_audio)
    lstm_audio2 = 辍学（dropout_rate）（lstm_audio2）
    lstm_audio_pooled = GlobalAveragePooling1D()(lstm_audio2)
    
    # 文本输入和CNN处理
    文本输入=输入（形状=（文本输入形状，1），名称=&#39;文本输入&#39;）
    conv_text = Conv1D(filters=32，kernel_size=3，activation=&#39;relu&#39;，strides=1，padding=&#39;same&#39;，kernel_regularizer=l2(l2_reg))(text_input)
    conv_text2 = Conv1D(filters=16，kernel_size=3，activation=&#39;relu&#39;，strides=1，padding=&#39;same&#39;，kernel_regularizer=l2(l2_reg))(conv_text)
    conv_text2 = Dropout(dropout_rate)(conv_text2)
    conv_text_pooled = GlobalAveragePooling1D()(conv_text2)
    
    # Fusion - 门控机制
    ated_layer = Multiply()([lstm_audio_pooled, conv_text_pooled])
    
    # 用于分类的密集层
    密集层=密集（64，激活=&#39;relu&#39;，kernel_regularizer=l2（l2_reg））（gate_layer）
    dropout_layer = Dropout(dropout_rate)(dense_layer)
    输出层=密集（1，激活=&#39;sigmoid&#39;，名称=&#39;输出&#39;）（dropout_layer）
    
    # 模型编译
    模型=模型（输入=[音频输入，文本输入]，输出=输出层）
    model.compile(优化器=Adam(learning_rate=0.001),loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
    
    返回模型

我无法获得超过 67% 的准确率。我尝试过更改所使用的模型、超参数调整以及对 txt 文件使用不同的特征提取技术。]]></description>
      <guid>https://stackoverflow.com/questions/78143946/improving-multimodal-detection-model-metrics</guid>
      <pubDate>Mon, 11 Mar 2024 23:45:24 GMT</pubDate>
    </item>
    <item>
      <title>scikit-optimize 的 BayesSearchCV 的作者是谁？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78143727/who-is-the-author-of-bayessearchcv-from-scikit-optimize</link>
      <description><![CDATA[我在我的手稿中使用了 scikit-optimize 的 BayesSearchCV。我在网上搜索过，但没有找到合适的引用。]]></description>
      <guid>https://stackoverflow.com/questions/78143727/who-is-the-author-of-bayessearchcv-from-scikit-optimize</guid>
      <pubDate>Mon, 11 Mar 2024 22:33:09 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助理解 SHAP 瀑布图 [关闭]</title>
      <link>https://stackoverflow.com/questions/78143713/need-help-in-understanding-shap-waterfall-chart</link>
      <description><![CDATA[我正在使用一个包含大约 72 个特征的数据集。我试图预测客户是否会流失，因此我的目标变量有 2 个类别：0 - 客户和 1 - 前客户（流失）
我使用此代码生成了 SHAP 瀑布图，并注意到 f(x) = 0.1
但是，当我将 sv[:,:,1], sv.base_values[:,1] 中的 1 替换为 0 时，我得到 f(x) = 0.9
为什么该特定指数的概率会发生变化？我假设概率越高，流失的可能性就越大，但现在我很困惑。
解释器 = 解释器(rf)
sv = 解释器(Train_X)

exp = 解释(sv[:,:,1], sv.base_values[:,1],Train_X, feature_names=None)

idx = 16 # 解释的数据点
瀑布图（exp[idx]，max_display=10）

这是我的瀑布图：
]]></description>
      <guid>https://stackoverflow.com/questions/78143713/need-help-in-understanding-shap-waterfall-chart</guid>
      <pubDate>Mon, 11 Mar 2024 22:30:19 GMT</pubDate>
    </item>
    <item>
      <title>图神经网络节点迭代更新中输入和输出维度的一致性[关闭]</title>
      <link>https://stackoverflow.com/questions/78143339/graph-neural-network-nodes-input-and-output-dimension-consistency-amid-iterativ</link>
      <description><![CDATA[我试图弄清楚使用图神经网络学习嵌入后节点的输入维度（n）和输出维度（m）是否可以不同，我想是的。但是，我正在努力弄清楚这是如何实现的，如下所示：
一般在迭代步骤中：
h_u^(k+1) = update(h_u^(k) + 聚合({h_v^(k) | u 的 v 邻居})
现在，h_u(0) 的维度是输入维度，因此在生成 h_u(1) 时，聚合函数和更新函数的输入是 n 的向量，这里的输出具有维度 m（主要是矩阵乘法和完成了加权求和类型的聚合，并将维度调整为 m)，那么从下一次迭代开始，如何通过相同的函数或矩阵来处理维度 m（而不是 n）的向量进行更新？]]></description>
      <guid>https://stackoverflow.com/questions/78143339/graph-neural-network-nodes-input-and-output-dimension-consistency-amid-iterativ</guid>
      <pubDate>Mon, 11 Mar 2024 20:47:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地运行主宰模型</title>
      <link>https://stackoverflow.com/questions/78143186/how-to-run-juggernaut-model-in-local</link>
      <description><![CDATA[我想使用 python 在本地电脑上运行微调的稳定扩散模型。例如剑圣：https://huggingface.co/RunDiffusion/Juggernaut-XL-v9
这是我的代码（它适用于 stable-diffusion-xl-base-1.0）：
随机导入
从扩散器导入 DiffusionPipeline、StableDiffusionXLImg2ImgPipeline
进口火炬
导入气相色谱
导入时间

# 用于清理内存
GC.collect()
torch.cuda.empty_cache()

开始时间 = 时间.time()

型号 =“RunDiffusion/Juggernaut-XL-v9”
管道 = DiffusionPipeline.from_pretrained(
    模型，
    torch_dtype=torch.float16,
）

管道.to(“cuda”)

提示=（“中世纪男性骑士肖像，阳刚的外观，背景中的战斗，清晰的焦点，高度详细，电影风格的灯光，阴影”）
种子 = random.randint(0, 2**32 - 1)

生成器 = torch.Generator(“cuda”).manual_seed(seed)
图像=管道（提示=提示，生成器=生成器，num_inference_steps=1）
图像=图像.图像[0]
image.save(f&quot;output_images/{seed}.png&quot;)

结束时间 = time.time()

总时间 = 结束时间 - 开始时间
分钟 = int(total_time // 60)
秒 = int(总时间 % 60)

print(f&quot;花费: {分钟} 分 {秒} 秒&quot;)
print(f&quot;保存到output_images/{seed}.png&quot;)


但我得到：
&lt;块引用&gt;
OSError：在目录中找不到名为 pytorch_model.bin、tf_model.h5、model.ckpt.index 或 flax_model.msgpack 的文件时出错

可能是因为python、cuda版本的原因。我正在删除我的库版本：
Python 3.9.0
PyTorch：2.2.0+cu118
CUDA：11.8
扩散器：0.26.3
变形金刚：4.38.1]]></description>
      <guid>https://stackoverflow.com/questions/78143186/how-to-run-juggernaut-model-in-local</guid>
      <pubDate>Mon, 11 Mar 2024 20:12:01 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 python 中的 Brian2 模拟器实现液体状态机用于分类任务？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78141953/how-to-implement-liquid-state-machine-for-a-classification-task-using-brian2-sim</link>
      <description><![CDATA[我是一名正在攻读本科生的学生，目前正在研究用于分类相关任务的液态机。但是，即使花了几天时间研究 LSM，我也无法找到如何实现它们进行分类的良好开端。
如果没有适当的资源，学习概念也非常困难。那么，有人可以帮助我进行研究吗？]]></description>
      <guid>https://stackoverflow.com/questions/78141953/how-to-implement-liquid-state-machine-for-a-classification-task-using-brian2-sim</guid>
      <pubDate>Mon, 11 Mar 2024 15:53:53 GMT</pubDate>
    </item>
    <item>
      <title>将 Android ML-Kit 鸟类分类器与 Python 结合使用</title>
      <link>https://stackoverflow.com/questions/78139883/using-android-ml-kit-bird-classifier-with-python</link>
      <description><![CDATA[我测试了 ML Kit 中的 Android Vision 快速入门应用程序。正如您在图片中看到的，这里可以进行对象跟踪。现在我正在使用 Python 尝试相同的模型 (bird_classifier.tflite)。这非常有效，但是我如何在这里获取边界框呢？无论我做什么，反馈都是：该模型仅包含一个张量。但为什么它可以在 Android 应用程序中运行呢？
有人可以给我看一个代码示例吗？
测试图片
image = Image.fromarray(screenshot)
image_pred = image.resize((宽度,高度), Image.ANTIALIAS)
结果=classify_image(interpreter, image_pred)
# TrackingID = results[i0][0]
# 分数 = 结果[i0][1]
# Boxes = ?]]></description>
      <guid>https://stackoverflow.com/questions/78139883/using-android-ml-kit-bird-classifier-with-python</guid>
      <pubDate>Mon, 11 Mar 2024 10:19:20 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法直接在windows下使用Nvidia Rapids？</title>
      <link>https://stackoverflow.com/questions/78136820/a-way-to-use-nvidia-rapids-in-windows-directly</link>
      <description><![CDATA[我想知道有没有办法直接在 Windows 11 中安装 Nvidia Rapids 并使用它，而不是与 wsl2 或 docker 一起使用？或者有没有办法将 jupyter lab 主机连接到 dataspell？
我尝试通过 github 将 cuMl 直接安装到 Windows，但每次都失败。我想在 jetbrains dataspell 中使用 cuml，这就是寻求帮助的原因。]]></description>
      <guid>https://stackoverflow.com/questions/78136820/a-way-to-use-nvidia-rapids-in-windows-directly</guid>
      <pubDate>Sun, 10 Mar 2024 17:30:40 GMT</pubDate>
    </item>
    <item>
      <title>如何以高精度（+ 90%）对面部特征嵌入进行分类。我可以在 svm 模型中进行哪些调整来对 20 多个类别进行分类</title>
      <link>https://stackoverflow.com/questions/78133540/how-to-classify-facials-features-embedding-with-high-accuracy-90-what-adjus</link>
      <description><![CDATA[我使用facenet提取特征并使用svm进行分类。效果很好，但 20 堂课后，准确率下降到 75%。如何在利用 GPU 的同时优化 svm。
我使用了这个 svm 类模型
scikit learn 的 svm 模型不使用 GPU，所以我使用了这个
类 SVM(nn.Module):
    def __init__(自身):
        超级（SVM，自我）.__init__()
        self.fc = nn.Linear(X.shape[1], len(ClassList))

    def 前向（自身，x）：
        返回 self.fc(x)

但是对于 20 多个类别来说，这个准确率非常低
我也尝试过使用这个：
类 SoftmaxUsed(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.layers = nn.Sequential(nn.Linear(512, 1024),
                                 ReLU(),
                                 nn.Dropout(0.2),
                                 nn.线性(1024, 1024),
                                 ReLU(),
                                 nn.Dropout(0.2),
                                 nn.Linear(1024, len(ClassList)),
                                 nn.LogSoftmax(dim=1))
    def 前向（自身，x）：
        返回 self.layers(x)

但准确率最高仍为 86%]]></description>
      <guid>https://stackoverflow.com/questions/78133540/how-to-classify-facials-features-embedding-with-high-accuracy-90-what-adjus</guid>
      <pubDate>Sat, 09 Mar 2024 18:56:09 GMT</pubDate>
    </item>
    <item>
      <title>持久化模型如何提高准确性？</title>
      <link>https://stackoverflow.com/questions/78127879/how-does-persisting-the-model-increase-accuracy</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入 precision_score, f1_score

Whitewine_data = pd.read_csv(&#39;winequality-white.csv&#39;,
分隔符=&#39;;&#39;)

变量= [&#39;alcohol_cat&#39;, &#39;酒精&#39;, &#39;硫酸盐&#39;, &#39;密度&#39;,
“总二氧化硫”、“柠檬酸”、“挥发性酸度”、
‘氯化物’]

X = Whitewine_data[变量]
y = Whitewine_data[&#39;质量&#39;]
X_train, X_test, y_train, y_test = train_test_split(X, y,
测试大小=0.2）

模型 = DecisionTreeClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
准确度=准确度_分数（y_test，y_pred）
f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)

预测 = model.predict([[0.27, 0.36, 0.045, 170, 1.001,
0.45, 8.9, 0]])
print(f&#39;预测输出：{预测}&#39;)
print(f&#39;准确率: {准确率 * 100}%&#39;)
print(f&#39;F1 分数: {f1 * 100}% &#39;)

这个初始模型的准确度得分为 57%
================================================== ===============
whitewine_data = pd.read_csv(&#39;winequality-white.csv&#39;,
分隔符=&#39;;&#39;)

# 要从数据集中删除的变量 - 不是输入
变量
变量 = [&#39;固定酸度&#39;,&#39;残留糖&#39;,&#39;游离硫
二氧化硫&#39;, &#39;pH&#39;, &#39;质量&#39;, &#39;isSweet&#39;]

X = Whitewine_data.drop(变量，轴=1)
y = Whitewine_data[&#39;质量&#39;]

X_train, X_test, y_train, y_test = train_test_split(X, y,
测试大小=0.2）

模型 = DecisionTreeClassifier()
model.fit(X_train, y_train)

joblib.dump(模型, &#39;WhiteWine_Quality_Predictor.joblib&#39;)

创建保存的模型
================================================== ===============
whitewine_data = pd.read_csv(&#39;winequality-white.csv&#39;,
分隔符=&#39;;&#39;)

变量 = [&#39;挥发酸度&#39;, &#39;柠檬酸&#39;, &#39;氯化物&#39;,
&#39;二氧化硫总量&#39;、&#39;密度&#39;、&#39;硫酸盐&#39;、&#39;酒精&#39;、
&#39;酒精_猫&#39;]

X_test = Whitewine_data[变量]
y_test = Whitewine_data[&#39;质量&#39;]

模型 = joblib.load(&#39;WhiteWine_Quality_Predictor.joblib&#39;)

y_pred = model.predict(X_test)

f1 = f1_score(y_test, y_pred, 平均值=&#39;加权&#39;)
准确度=准确度_分数（y_test，y_pred）
预测 = model.predict([[0.27, 0.36, 0.045, 170, 1.001,
0.45, 10.9, 3]])

print(f&#39;F1分数: {f1 * 100}%&#39;)
print(f&#39;模型精度: {accuracy * 100}%&#39;)
print(f&#39;预测输出：{预测}&#39;)

调用保存的模型现在的准确率达到 92%
问题：调用已保存的模型如何导致增加
我看到的准确性]]></description>
      <guid>https://stackoverflow.com/questions/78127879/how-does-persisting-the-model-increase-accuracy</guid>
      <pubDate>Fri, 08 Mar 2024 13:07:01 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 numpy python 读取多个 3D 图像并将它们存储在 4D 数组中？</title>
      <link>https://stackoverflow.com/questions/72667735/how-to-read-multiple-3d-images-and-store-them-in-4d-array-using-numpy-python</link>
      <description><![CDATA[我使用下面的代码为 3 个图像创建了一个形状为 (2, 3, 365, 256, 256) (2, 365, 256, 256) 的数组，但是我需要我的形状为 (2,365, 256, 256, 3) (2, 365, 256, 256) 让我的模型运行，有什么提示吗？
def Load_function(路径):
  f_img= nib.load(路径)
  img_data= f_img.get_fdata()
返回img_data


 def __load__(self, id_name):

    image_path = os.path.join(self.path, id_name)
    ## 读取图像
    图像 = np.empty((0,365, 256, 256))

    对于 [“image2B.nii.gz”、“image1to2_nlB.nii.gz”、“diffFSL.nii.gz”] 中的 imname：
        img = Load_function(os.path.join(image_path,imname))

        img = 调整大小_数据(img)
        
        ## 标准化
        img = img/np.percentile(img,99.5)
        #images.append(img)
        #images.append(img)
    ## 存储到您在上面创建的 4D 数组中（这将保存您想要的一个主题的所有图像）
        image = np.append(img[np.newaxis, ...],image, axis=0) # 为每个图像添加一个新轴并将其附加到结果中
          
    ## 阅读面具
    mask = Load_function(os.path.join(image_path, “ground_truth.nii.gz”))
    掩码 = resize_data(掩码)
    
    返回图像，掩码
]]></description>
      <guid>https://stackoverflow.com/questions/72667735/how-to-read-multiple-3d-images-and-store-them-in-4d-array-using-numpy-python</guid>
      <pubDate>Sat, 18 Jun 2022 08:12:16 GMT</pubDate>
    </item>
    </channel>
</rss>