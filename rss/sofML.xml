<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 09 Jan 2024 18:14:33 GMT</lastBuildDate>
    <item>
      <title>我正在尝试在视觉变压器中使用矩形图像数据集。我设置 image_size= (128, 256) 但是批处理大小batch_size=(16, 32) 可能是多少</title>
      <link>https://stackoverflow.com/questions/77788451/i-am-trying-to-use-rectangular-image-dataset-in-vision-transformers-i-set-image</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77788451/i-am-trying-to-use-rectangular-image-dataset-in-vision-transformers-i-set-image</guid>
      <pubDate>Tue, 09 Jan 2024 16:55:52 GMT</pubDate>
    </item>
    <item>
      <title>scikit 的 RFECV 类如何计算 cv_results_？</title>
      <link>https://stackoverflow.com/questions/77788410/how-does-scikits-rfecv-class-compute-cv-results</link>
      <description><![CDATA[根据我对 sklearn.feature_selection.RFECV（递归特征消除交叉验证）的理解，您提供了一种在整个数据集上进行训练的算法，并使用属性 coef_ 创建特征重要性排名 或 feature_importances_。现在包含了所有功能，该算法通过交叉验证进行评估。然后，删除排名底部的特征，并在数据集上重新训练模型并创建新的排名，再次通过交叉验证进行评估。这一过程将持续下去，直到只剩下一个特征（或由 min_features_to_select 指定），并且最终选择的特征数量取决于产生最高 CV 分数的特征。 （来源)
每个特征数量的 CV 分数存储在 rfecv.cv_results_[“mean_test_score”] 中，并且在不使用 scikit 内置方法的情况下尝试复制这些分数时遇到了麻烦。 
这是我试图获得 n-1 个特征的分数，其中 n 是特征总数。
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn.model_selection 导入 StratifiedKFold
从 sklearn.model_selection 导入 cross_validate
从 sklearn.feature_selection 导入 RFECV

alg = DecisionTreeClassifier(random_state = 0)
cv_split = 分层KFold(5)
# train 是 pandas 数据框，x_var 和 y_var 都是包含变量字符串的列表
X = 火车[x_var]
y = np.ravel(train[y_var])

alg.fit(X, y)
最低排名特征 = np.argmin(alg.feature_importances_)
x_var.pop(最低排名特征)

one_removed_feature = 火车[x_var]
alg.fit(one_removed_feature, y)
cv_score = cross_validate(alg, one_removed_feature, y, cv=cv_split, 评分=“准确度”)
np.mean(cv_score[“test_score”])

这是提供不同分数的内置方法：
&lt;前&gt;&lt;代码&gt;rfecv = RFECV(
    估计量=alg,
    步骤=1，
    CV=CV_分裂，
    评分=“准确度”，
）

rfecv.fit(X, y)
rfecv.cv_results_[“mean_test_score”][-2]

如何获得内置方法中计算出的准确分数？
我还想提一下，我确实首先尝试了所有 n 个功能，并且我的方法与
rfecv.cv_results_[“mean_test_score”][-1]。]]></description>
      <guid>https://stackoverflow.com/questions/77788410/how-does-scikits-rfecv-class-compute-cv-results</guid>
      <pubDate>Tue, 09 Jan 2024 16:47:46 GMT</pubDate>
    </item>
    <item>
      <title>这段执行无监督分割的代码有什么问题？</title>
      <link>https://stackoverflow.com/questions/77787381/what-is-wrong-with-this-code-performing-unsupervised-segmentation</link>
      <description><![CDATA[这是在获取音频输入文件后执行 MFCC 的代码块。在mfcc之后，找到边界段，使用函数calculate_duration_features()计算每个段的段持续时间，存储在列表duration_feats中，然后与相应的mfcc连接。
导入librosa
将 numpy 导入为 np

sr = 16000 # 采样率
n_mfcc = 20 # MFCC系数的数量
n_fft_值 = [128, 256, 512]
跳长度值 = [32, 64, 128]
zcr_阈值 = [0.05, 0.08, 0.10, 0.12]

类FeatureExtractorSegmenter：
    def __init__(self, sr, n_mfcc):
        self.sr = sr
        self.n_mfcc = n_mfcc

    def extract_features(self,audio_file):
        y, _ = librosa.load(audio_file, sr=self.sr)

        对于 n_fft_values 中的 n_fft：
            对于 hop_length_values 中的 hop_length：
                对于 zcr_thresholds 中的 zcr_threshold：
                    # 使用 ZCR 进行粗分割
                    zcr = librosa.feature.zero_crossing_rate(y=y)
                    rough_segments = np.where(zcr &gt; zcr_threshold)[0]

                    # 通过光谱变化分析细化边界（如果粗片段可用）
                    精炼段 = []
                    如果coarse_segments.any()：
                        开始，结束于 zip(coarse_segments[:-1], rough_segments[1:])：
                            段 = y[开始:结束]
                            onset_frames = librosa.onset.onset_detect(y=段, sr=self.sr, 单位=“帧”)
                            onset_frames += start # 将起始位置调整为全局索引
                            Fine_segments.extend(segment[i:j] for i, j in zip(onset_frames[:-1], onset_frames[1:]))

                    # 从精细细分中提取 MFCC（如果有）
                    mfcc = []
                    持续时间特征 = []
                    如果精炼_段：
                        对于refine_segments中的段：
                            segment_mfccs = librosa.feature.mfcc(y=段, sr=self.sr, n_mfcc=self.n_mfcc,
                                                              n_fft=n_fft, hop_length=hop_length)
                            period_feats = self.calculate_duration_features(segment)
                            mfccs.append(segment_mfccs)
                            持续时间特征.append(duration_feats)
                    print(f&quot;MFCC for n_fft={n_fft}, hop_length={hop_length}, zcr_threshold={zcr_threshold}:&quot;)
                    打印（mfcc）
                    print(f&quot;n_fft={n_fft}, hop_length={hop_length}, zcr_threshold={zcr_threshold} 的持续时间特征:&quot;)
                    打印（持续时间特征）


    def计算持续时间特征（自身，段）：
        num_frames = len(段)
        Total_duration = num_frames * 0.025 # 假设帧持续时间为 25ms
        返回[帧数，总持续时间]

audio_file =“/content/speech.wav”
提取器 = FeatureExtractorSegmenter(sr, n_mfcc)
extractor.extract_features（音频文件）

这是我正在使用的音频文件的链接： http://www.fit.vutbr.cz/~motlicek/sympatex/f2bjrop1.0.wav
我期待一个包含功能持续时间和 MFCC 的列表，但每次运行代码时，它都会给出空的 mfcc 和uration_feature。有人可以告诉我代码有什么问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77787381/what-is-wrong-with-this-code-performing-unsupervised-segmentation</guid>
      <pubDate>Tue, 09 Jan 2024 14:12:19 GMT</pubDate>
    </item>
    <item>
      <title>pycaret.arules 的替代品 [关闭]</title>
      <link>https://stackoverflow.com/questions/77787203/alternative-to-pycaret-arules</link>
      <description><![CDATA[我正在尝试使用关联规则学习来查找多个输入列和一个输出列（所有文本列）之间的规则或关系。 pycaret.arules 似乎是一个不错的选择，但在 pycaret==2.3.10 之后不可用，并且此版本或以下版本与 Python 3.10 不兼容。
是否有任何替代库或技术可以帮助我解决这个问题？
到目前为止，我已经研究了 apyori、efficient-apriori 等不同的 apriori 实现。它们都不完全符合我想要的。
我的问题陈述是：
我有多个产生输出列的输入列。我想找到输入列中的值的优化组合，以生成输出列中的值。]]></description>
      <guid>https://stackoverflow.com/questions/77787203/alternative-to-pycaret-arules</guid>
      <pubDate>Tue, 09 Jan 2024 13:42:03 GMT</pubDate>
    </item>
    <item>
      <title>寻求在 MLOps 领域开始的指导 [已关闭]</title>
      <link>https://stackoverflow.com/questions/77785935/seeking-guidance-to-start-in-mlops-field</link>
      <description><![CDATA[我是一名预科学生，渴望开始我在 MLOps 领域的旅程。虽然我目前没有具体的问题或项目，但我正在寻求有关如何开始学习并为 MLOps 职业生涯做好准备的指导。
以下是我希望获得帮助的一些具体要点：

推荐学习资源：为 MLOps 概念和实践打下坚实基础的最佳资源、在线课程或书籍是什么？

关键技能和技术：作为初学者，我应该关注哪些基本技能和技术来为 MLOps 打下坚实的基础？

实践练习：是否有任何推荐的实践练习或项目可供我进行，以应用理论知识并获得 MLOps 的实践经验？

社区参与：是否有特定的社区、论坛或交流机会，让像我这样的初学者可以与 MLOps 领域经验丰富的专业人士互动？


我知道 MLOps 是一个广阔的领域，任何有关如何构建我的学习路径的指导或建议都将非常有价值。
作为一名渴望深入 MLOps 领域的预科学生，我已采取以下步骤来启动我的学习之旅：

研究学习资源：我已经开始研究与 MLOps 概念和实践相关的在线学习平台、课程和书籍。我正在确定最推荐的资源，以确保奠定坚实的基础。

确定关键技能：我一直在探索 MLOps 所需的基本技能和技术。最初，我专注于了解机器学习、云计算和版本控制系统的基础知识。

计划实践练习：虽然我还没有具体的实践项目，但我计划在获得基本了解后进行实践练习和项目。我愿意接受对初学者有益的具体练习建议。

探索社区：我已开始研究 MLOps 社区、论坛和交流机会。我正在积极寻找初学者可以与经验丰富的专业人士交流以寻求建议和指导的地方。


虽然我现阶段没有具体的问题可以分享，但我热衷于收到关于这些初始步骤是否符合 MLOps 初学者的最佳实践的建议。]]></description>
      <guid>https://stackoverflow.com/questions/77785935/seeking-guidance-to-start-in-mlops-field</guid>
      <pubDate>Tue, 09 Jan 2024 10:14:01 GMT</pubDate>
    </item>
    <item>
      <title>过多的 padding 导致 NN 模型精度下降</title>
      <link>https://stackoverflow.com/questions/77785503/excessive-padding-causes-accuracy-decrease-to-nn-model</link>
      <description><![CDATA[我训练了一个简单的神经网络模型来进行二元分类，并能够区分真假新闻
#创建模型的类
类 FakeNewsDetectionModelV0(nn.Module):
     def __init__(自身, input_size):
        超级().__init__()
        
        self.layer_1=nn.Linear(in_features=input_size, out_features=8)
        self.layer_2=nn.Linear(in_features=8, out_features=1) #从前一层获取5个特征并输出单个特征

     #定义一个forward()用于前向传播
     def 前向（自身，x，掩码）：
        
        # 应用掩码来忽略某些值
        如果掩码不是 None：
            x = x * 掩码

        x = self.layer_1(x)
        x = self.layer_2(x)
        返回x




我使用 CountVectorizer 将文本转换为列表，然后转换为张量
从 sklearn.feature_extraction.text 导入 CountVectorizer

矢量化器 = CountVectorizer(min_df=0, 小写=False)
矢量化器.fit(df[&#39;文本&#39;])

X=vectorizer.fit_transform(df[&#39;text&#39;]).toarray()

问题在于，由于数据集有超过 9000 个条目，因此训练模型的输入大小非常大（大约 120000 个）。因此，当我尝试对单个句子进行预测时，由于大小明显较小，我需要过度填充句子以使其适合模型的输入，这极大地影响了模型的准确性。
from io 导入 StringIO
来自 torch.nn.function 导入垫
导入字符串
进口重新
从 nltk.tokenize 导入 word_tokenize
从 nltk.corpus 导入停用词
导入nltk
从 keras.preprocessing.text 导入 Tokenizer
从 keras.preprocessing.sequence 导入 pad_sequences


尝试：
    #nltk.download(&#39;停用词&#39;)
    nltk.download(&#39;punkt&#39;)
除了：
    print(&quot;下载停用词时出错&quot;)

def normalise_text (文本):

  text = text.lower() # 小写
  text = text.replace(r&quot;\#&quot;,&quot;&quot;) # 替换主题标签
  text = text.replace(r&quot;http\S+&quot;,&quot;URL&quot;) # 删除 URL 地址
  text = text.replace(r&quot;@&quot;,&quot;&quot;)
  text = text.replace(r&quot;[^A-Za-z0-9()!?\&#39;\`\&quot;]&quot;, &quot; &quot;)
  text = text.replace(&quot;\s{2,}&quot;, &quot;&quot;)
  文本 = re.sub(r&#39;[^\w\s]&#39;, &#39;&#39;, 文本)
  返回文本

def fake_news_detection(df, model, model_input_size):
    预测=[]
    最大字数 = 10000
    最大长度 = 模型输入大小

    模型.eval()

    对于 df[&#39;text&#39;][:4000] 中的预测数据：
        预测数据=标准化文本（预测数据）

        #print([预测数据])



        # 使用CountVectorizer将文本数据转换为数组
        矢量化器 = CountVectorizer(min_df=0, 小写=False)
        Prediction_data_array = Vectorizer.fit_transform([prediction_data]).toarray()

        #tokenizer = Tokenizer(num_words=max_words)
        #tokenizer.fit_on_texts([预测数据])
        #sequences = tokenizer.texts_to_sequences([预测数据])


        #prediction_data_array = pad_sequences(序列, maxlen=max_length,value=-1.0)

        #print(预测数据数组.形状)

        # 检查转换后数据的形状
        当前输入大小=预测数据数组.形状[1]


        Prediction_data_tensor = torch.tensor(prediction_data_array, dtype=torch.float32)


        # 如果形状不匹配，则调整其大小
        如果当前输入大小！=模型输入大小：

            打印（当前输入大小）
            填充 = 模型输入大小 - 当前输入大小
            Prediction_data_tensor = pad(prediction_data_tensor, (0, 填充), &#39;常量&#39;, 值 = 0)
            mask_tensor = torch.ones_like(prediction_data_tensor)
            mask_tensor[:, -padding:] = 0 # 将填充区域中的值设置为 0
            #print(torch.unique(mask_tensor, return_counts=True))

            # 应用掩码来忽略某些值
            #预测数据张量 = 预测数据张量 * 掩码张量



        # 假设你的模型将 input_data 作为输入
        使用 torch.inference_mode()：
            预测 = torch.round(torch.sigmoid(model(prediction_data_tensor, mask_tensor))).squeeze()

        预测.append(round(预测.item()))

    print(f“我们的数据张量形状是 {prediction_data_tensor.shape}”)

    Predictions_tensor = torch.FloatTensor(预测)

    返回预测张量

有谁知道有什么解决方法可以让我将数据适合我的模型而不降低其准确性分数吗？
尝试：在对小尺寸数据进行预测时填充向量
预期：准确的预测类似于我在训练/评估过程中得到的结果
得到：预测不准确，准确度非常低（大约 43%）]]></description>
      <guid>https://stackoverflow.com/questions/77785503/excessive-padding-causes-accuracy-decrease-to-nn-model</guid>
      <pubDate>Tue, 09 Jan 2024 09:03:52 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中 NxM 密集层和 M 独立 Nx1 密集层之间的梯度和优化差异 [关闭]</title>
      <link>https://stackoverflow.com/questions/77785480/gradient-and-optimization-differences-between-a-nxm-dense-layer-and-m-separate-n</link>
      <description><![CDATA[我很好奇这两种设计选择如何影响训练过程中的梯度计算和优化过程。
反向传播过程中每个结构的梯度计算会受到怎样的影响？梯度流回网络的方式有什么不同吗？这些不同的网络结构是否需要或受益于不同的优化算法或学习率？
我的目标是从梯度计算和优化的角度了解每种模型结构选择的潜在好处和可能的缺点。
我以为“渐变”是一样的，但结果是不同的。]]></description>
      <guid>https://stackoverflow.com/questions/77785480/gradient-and-optimization-differences-between-a-nxm-dense-layer-and-m-separate-n</guid>
      <pubDate>Tue, 09 Jan 2024 08:59:37 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 解释器获取错误的数据类型[关闭]</title>
      <link>https://stackoverflow.com/questions/77785286/shap-explainer-getting-wrong-datatype</link>
      <description><![CDATA[这是我的代码。我正在尝试获取 X 射线图像的 SHAP 值。
导入火炬
将 numpy 导入为 np
将 torch.nn 导入为 nn
导入 torchvision.transforms 作为变换
从 torchvision.models 导入 alexnet
导入形状
从 PIL 导入图像
进口泡菜
导入 matplotlib
%matplotlib 内联

model_path = &#39;alexnet_lion_model.pkl&#39;
将 open(model_path, &#39;rb&#39;) 作为 f：
    模型 = pickle.load(f)

模型.eval()

＃ 转型
def preprocess_image(image_path):
    图像 = Image.open(image_path).convert(&#39;RGB&#39;)
    变换 = 变换.Compose([
        变换.调整大小((224, 224)),
        变换.ToTensor(),
        变换.Normalize(平均值=[0.485,0.456,0.406],std=[0.229,0.224,0.225]),])
    input_image = 变换（图像）.unsqueeze（0）
    返回输入图像

image_path = &#39;C.jpg&#39;
输入图像 = 预处理图像（图像路径）

masker = shap.maskers.Image(“inpaint_telea”, input_image.size())

解释器= shap.Explainer（模型，掩码器，output_names = [“A”，“B”，“C”]）

shap_values = 解释器(input_image)

shap.image_plot(shap_values, input_image.numpy())

当我运行此命令时，解释器获取错误的数据类型，并且出现此错误：
 *（张量输入、张量权重、张量偏差、整数步幅元组、整数填充元组、整数膨胀元组、整数组）
      不匹配，因为某些参数具有无效类型： (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple (int, int)!, int)
 *（张量输入、张量权重、张量偏差、整数步幅元组、str 填充、整数膨胀元组、整数组）
      不匹配，因为某些参数具有无效类型： (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple (int, int)!, int)

上线：
shap_values = 解释器(input_image)

我想获取图像 C.jpg 的 SHAP 值]]></description>
      <guid>https://stackoverflow.com/questions/77785286/shap-explainer-getting-wrong-datatype</guid>
      <pubDate>Tue, 09 Jan 2024 08:26:58 GMT</pubDate>
    </item>
    <item>
      <title>哪种评估指标最适合不平衡的多标签分类，确保准确的模型评估？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77785250/which-evaluation-metric-suits-imbalanced-multi-label-classification-best-ensuri</link>
      <description><![CDATA[如何处理？
在处理多标签分类中的平均指标时，应优先考虑采用微观平均、宏观平均、加权平均或样本平均等平均技术来综合评估模型的性能]]></description>
      <guid>https://stackoverflow.com/questions/77785250/which-evaluation-metric-suits-imbalanced-multi-label-classification-best-ensuri</guid>
      <pubDate>Tue, 09 Jan 2024 08:20:55 GMT</pubDate>
    </item>
    <item>
      <title>带有我自己的预训练模型的 Sagemaker 批处理变压器</title>
      <link>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:54:18 GMT</pubDate>
    </item>
    <item>
      <title>如何构建多输出回归模型的目标变量？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</link>
      <description><![CDATA[我想使用 XGBoost 构建一个多输出模型，其中输出是联系客户时预测的销售情况，例如：

output1 是联系后的预测销售额
output2 是未联系情况下的预测销售额。

我的数据如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

区域
销售类别
在线客户
已联系
促销


&lt;正文&gt;

北
3
1
1
1000


北
2
0
0
600


东
2
0
1
500




我打算将“Contacted”和“Sales”合并在一起，形成两个目标列，如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

区域
销售类别
在线客户
Contacted_Sale
NonContacted_Sale


&lt;正文&gt;

北
3
1
1000
0


北
2
0
0
600


东
2
0
500
0




这是正确的方法吗？零会扰乱模型训练并降低模型的准确性吗？将模型与一个预测联系销售和一个预测非接触销售分开的更好方法是吗？]]></description>
      <guid>https://stackoverflow.com/questions/77781440/how-to-structure-the-target-variables-for-a-multi-output-regression-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:05:39 GMT</pubDate>
    </item>
    <item>
      <title>mlr3 (R) 管道 |泰坦尼克号宇宙飞船 Kaggle [关闭]</title>
      <link>https://stackoverflow.com/questions/77779659/mlr3-r-pipelines-spaceship-titanic-kaggle</link>
      <description><![CDATA[我正在尝试在 R 中复制此 python 代码：
从 sklearn.pipeline 导入管道
从 sklearn.impute 导入 SimpleImputer
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.compose 导入 ColumnTransformer
从 sklearn.preprocessing 导入 OrdinalEncoder
从 sklearn.preprocessing 导入 OneHotEncoder

num_pipeline = 管道([
    (&#39;imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)),
    (&#39;std_scaler&#39;, StandardScaler())
]）

cat_pipeline = 管道([
    (&#39;oh_encoder&#39;, OneHotEncoder())
]）

full_pipeline = ColumnTransformer([
    (&#39;num&#39;, num_pipeline, num_attribs),
    （&#39;猫&#39;，cat_pipeline，cat_attribs）
]）

# 未选择的列，例如“PassengerId”和“Cabin”将被
# 通过列变压器后掉落
X_train_copy_transformed = df_transform(X_train_copy)
打印（X_train_copy_transformed.columns）
X_train_copy_prepared = full_pipeline.fit_transform(X_train_copy_transformed)
打印（X_train_copy_prepared[0]）

这是我到目前为止所做的事情：
库(mlr3)
库（mlr3pipelines）

num_pipeline &lt;- po(“imputemedian”) %&gt;&gt;% po(“scale”，center = TRUE，scale = TRUE)
cat_pipeline &lt;- po(“编码”, method = “one-hot”)

完整管道 &lt;-

X_train_copy_transformed &lt;- df_transform(X_train_copy)
打印（列名（X_train_copy_transformed））
X_train_copy_prepared &lt;- full_pipeline$train(列表(数据 = 列表(x = X_train_copy_transformed)))$预测(列表(x = X_train_copy_transformed))
打印（X_train_copy_prepared[1，]）

我不知道如何解决这个问题。这是整个笔记本供您使用数据：
https://www.kaggle.com/code/paulitos/保罗斯号泰坦尼克号宇宙飞船
我已阅读文档，但不太明白。任何帮助将不胜感激。我什至不知道 X_train_copy_transformed 的定义是否做得好。
这里是Python中的原始笔记本，我正在尝试在R中进行操作：https://www.kaggle.com/code/oscardata963/spaceship-titanic-notebook
我已经在上一个单元格中说过了。我正在使用 mlr3，并且尝试使用 recipes 和 caret 执行此操作，但没有成功。我认为 mlr3 是一个与 R 中的 scikit-learn 更相似的库。我已经阅读了文档并尝试了 “select”和其他人但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77779659/mlr3-r-pipelines-spaceship-titanic-kaggle</guid>
      <pubDate>Mon, 08 Jan 2024 11:44:44 GMT</pubDate>
    </item>
    <item>
      <title>跨多个模型的交叉验证的一致性</title>
      <link>https://stackoverflow.com/questions/77778800/consistency-in-cross-validation-folds-across-multiple-models</link>
      <description><![CDATA[我目前正在做一个机器学习项目，其中使用三种不同的模型：随机森林、AdaBoost 和梯度提升。对于每个模型，我将它们应用于一组训练和测试数据。此外，我计划将五重交叉验证纳入我的实验中。
我的问题涉及这些模型之间交叉验证的实施。具体来说，我是否应该对所有三个模型（RF、ADA 和 GB）使用相同的五倍，以确保每个模型训练和测试的数据的一致性？或者，为每个模型生成不同的折叠集，从而独立地对 RF、ADA 和 GB 进行交叉验证过程是否更合适？
我有兴趣了解哪种方法更有利于实验的完整性，以及在这种情况下是否有任何标准实践或建议。
如果您能分享任何见解或经验，我们将不胜感激。谢谢！
我在网上发现了相互矛盾的信息。]]></description>
      <guid>https://stackoverflow.com/questions/77778800/consistency-in-cross-validation-folds-across-multiple-models</guid>
      <pubDate>Mon, 08 Jan 2024 10:17:44 GMT</pubDate>
    </item>
    <item>
      <title>将大型语料库中的 n 元模型加载到集合中时如何避免内存问题</title>
      <link>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</link>
      <description><![CDATA[我一直在尝试实现一种无监督学习算法，该算法根据从语料库中提取的特定特征来匹配相似性。一个用例是作者识别。该算法的工作方式是从训练语料库中提取不同类型的 n-gram，然后每个作者都会获得一个“指纹”。基于文章中出现的 n 元语法。
为此，我首先需要收集训练语料库中存在的所有 n 元语法。这就是我遇到内存问题的地方，我一直在使用 Yelp 评论数据，并且在某些时候我的程序由于内存限制而崩溃。我尝试过存储中间结果，然后将 n-gram 加载到最终集合中，以避免我的稀疏计算中出现任何潜在的内存泄漏问题，但这也失败了，看来该集合太大了。
如何解决这个问题？
根据反馈，我希望这能提供一些见解，不确定如果我通过 800 多行代码会有多大帮助，我希望我能够提取要点：
假设我有以下文本片段：
&#39;Zahlreiche Konzertabsagen aufgrund von Impf-Nebenwirkungen。 Teil XI – 11 Direkt zum 视频：Politiker und hochrangige Beamte leiden unter Nebenwirkungen und sterben nach der Impfung。 Teil XIV Direkt zum 视频：Frontstadt Charkow – Putins verlorene Schlacht 乌克兰 – Der Kontext，der in den Medien fehlt |历史学家 Prashad Freitod 教授 nach „Impfschaden“ – Ein Weckruf Corona [...]&#39;
在本文中，我仅使用如下内容保留功能词：
 def filter_function_words(doc, lta_table,phrase_matcher):
    匹配的单词= []
    masked_matched_words = [&#39;#&#39;] * len(doc)
    短语匹配 = 短语匹配器（文档）
    对于在 doc.sents 中发送：
        # 过滤属于当前句子的匹配项
        短语匹配_发送 = [
            匹配phrase_matches中的匹配项
            如果已发送.start &lt;= match[1] &lt;已发送结束]

        如果没有phrase_matches_sent：
            继续
            
        对于 match_id、开始、结束于phrase_matches_sent：
            跨度 = doc[开始:结束]
            masked_matched_words[开始:结束] = span.text.split()
        matched_words = [x for x in masked_matched_words if x != &#39;#&#39;]
    返回 masked_matched_words、matched_words

[&#39;aufgrund&#39;, &#39;von&#39;, &#39;direkt&#39;, &#39;zum&#39;, &#39;und&#39;, &#39;unter&#39;, &#39;und&#39;, &#39;nach&#39;, &#39;der&#39;, &#39;direkt&#39;, &#39;zum&#39;, &#39;der &#39;, &#39;der&#39;, &#39;in&#39;, &#39;den&#39;, &#39;nach&#39;, &#39;ein&#39;]
现在我构造多个 n-gram，即 (1,2,3,4)，这里是 3 的示例：
[(&#39;aufgrund&#39;, &#39;von&#39;, &#39;direkt&#39;),
(&#39;von&#39;, &#39;direkt&#39;, &#39;zum&#39;),
(&#39;direct&#39;, &#39;zum&#39;, &#39;und&#39;),
(&#39;zum&#39;, &#39;und&#39;, &#39;unter&#39;),
(&#39;和&#39;, &#39;下&#39;, &#39;和&#39;),
(&#39;unter&#39;, &#39;und&#39;, &#39;nach&#39;),
(&#39;und&#39;, &#39;nach&#39;, &#39;der&#39;),
(&#39;nach&#39;, &#39;der&#39;, &#39;direkt&#39;),
(&#39;der&#39;, &#39;direkt&#39;, &#39;zum&#39;),
(&#39;direct&#39;, &#39;zum&#39;, &#39;der&#39;),
(&#39;zum&#39;, &#39;der&#39;, &#39;der&#39;),
(&#39;der&#39;, &#39;der&#39;, &#39;in&#39;),
(&#39;der&#39;, &#39;in&#39;, &#39;den&#39;),
(&#39;在&#39;, &#39;书房&#39;, &#39;nach&#39;),
(&#39;den&#39;, &#39;nach&#39;, &#39;ein&#39;)]
我对整个语料库执行此操作，收集一组 n 元语法。
对于 self.n_grams_token 中的 n：
        self.token_n_grams_set[n].update(ngrams(matched_words, n))

现在我有了整个语料库中出现的所有 n 元语法，然后我用这样的东西构建特征向量
 def _get_feature_vector(self,
                            元素：列表[str]，
                            壮举名称，
                            n=无）-&gt;火炬.张量：
        计数器 = 计数器（元素）
        counter_set = OrderedSet(计数器)
        # 更改为 torch.Tensor
        如果 n 不是 None：
            feat_set = self.feature_name_set_dict[feat_name][n]
        别的：
            feat_set = self.feature_name_set_dict[feat_name]
        available_terms = feat_set.intersection(counter_set)
        索引 = feat_set.index(available_terms)
        值 = np.fromiter(counter.values(),
                             dtype=int)[counter_set.index(available_terms)]
        #feature_vector = torch.zeros(len(feat_set), dtype=torch.int)
        #feature_vector[indexes] = torch.tensor(values, dtype=torch.int)
        idxs = torch.tensor([索引], dtype=torch.long)
        vals = torch.tensor(values, dtype=torch.float)
        大小 = torch.Size([len(feat_set)])
        feature_vector = torch.sparse_coo_tensor(idxs, vals, 大小)
        返回特征向量

我的数据存储在数据框中，它的大小为 5854272 行，我得到以下内存使用情况输出：
df.memory_usage()
索引 128
作者 46834176
文章 46834176
数据类型：int64

基本上，我正在计算每篇文章的 n 元语法，将它们添加到一个集合中，然后将它们存储到字典中。]]></description>
      <guid>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</guid>
      <pubDate>Thu, 04 Jan 2024 12:00:51 GMT</pubDate>
    </item>
    <item>
      <title>如何计算最佳批量大小？</title>
      <link>https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size</link>
      <description><![CDATA[有时我会遇到一个问题：
分配具有形状的张量时发生 OOM

例如
分配形状为 (1024, 100, 160) 的张量时出现 OOM

其中 1024 是我的批量大小，我不知道其余的是什么。如果我减少批量大小或模型中神经元的数量，它就可以正常运行。
是否有一种通用方法可以根据模型和 GPU 内存计算最佳批量大小，以便程序不会崩溃？
简而言之：我希望模型的批量大小尽可能大，这样可以适合我的 GPU 内存，并且不会使程序崩溃。]]></description>
      <guid>https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size</guid>
      <pubDate>Mon, 09 Oct 2017 20:25:09 GMT</pubDate>
    </item>
    </channel>
</rss>