<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 05 Jul 2024 18:19:37 GMT</lastBuildDate>
    <item>
      <title>关于 Hugging Face 的 Tokenizer</title>
      <link>https://stackoverflow.com/questions/78712655/regarding-tokenizer-of-hugging-face</link>
      <description><![CDATA[很难理解 tokenizer 的工作原理
from transformers import AutoModelForSequenceClassification,AutoTokenizer #hugging face libraries
tkz = AutoTokenizer.from_pretrained(model)
函数：
def tkz_func(x): return tkz(x[&#39;input&#39;])
当我们将其应用于数据集时，它可以完美运行，返回包含 input_ids、token_type_ids、attention_masks 的更新数据集
当我们将其应用于数据框 df.apply(tkz_func,axis=1) 时，它只会返回所有行值的行名列表
[input_ids,token_type_ids,attention_masks]
为什么？]]></description>
      <guid>https://stackoverflow.com/questions/78712655/regarding-tokenizer-of-hugging-face</guid>
      <pubDate>Fri, 05 Jul 2024 17:15:32 GMT</pubDate>
    </item>
    <item>
      <title>一旦使用测试集进行测试为什么不在训练加测试集上训练模型？</title>
      <link>https://stackoverflow.com/questions/78712450/once-using-the-test-set-for-testing-why-do-not-training-the-model-on-train-plus</link>
      <description><![CDATA[一旦我使用测试集来评估模型性能是否良好，为什么我不能从头开始在训练和测试集上重新训练模型？
以预测为例：我有一个长度为 L 的时间序列，我训练到 T（T &lt; L），然后从 T 到 L 进行测试。我获得了良好的表现，所以我知道模型很好。然后在推理时我必须预测 L+1 个元素，那么为什么我不能训练模型到 L，然后在 L+1 上进行推理？
我希望模型在更大的数据集（训练+测试）上训练后表现更好，那么我遗漏了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78712450/once-using-the-test-set-for-testing-why-do-not-training-the-model-on-train-plus</guid>
      <pubDate>Fri, 05 Jul 2024 16:18:01 GMT</pubDate>
    </item>
    <item>
      <title>寻找包含带有摘要分析注释的电子表格的数据集</title>
      <link>https://stackoverflow.com/questions/78712190/looking-for-dataset-containing-spreadsheets-with-summary-analytical-comments</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78712190/looking-for-dataset-containing-spreadsheets-with-summary-analytical-comments</guid>
      <pubDate>Fri, 05 Jul 2024 15:16:23 GMT</pubDate>
    </item>
    <item>
      <title>对失败的测试进行分类，并提出解决方案</title>
      <link>https://stackoverflow.com/questions/78711965/classification-of-failed-tests-and-fix-them-with-solution-proposal</link>
      <description><![CDATA[我现在在一家公司工作，负责运行一系列测试，这些测试都是用 C 和 C++ 开发的。
当执行结束时，我们通过了测试，也失败了，每个失败的测试都会生成一个日志文件。
现在我们想使用 IA 对这些失败的测试进行分类（因为有些测试有相同的错误）。
我们想预测这些失败测试的解决方案。
有什么想法吗？！！
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78711965/classification-of-failed-tests-and-fix-them-with-solution-proposal</guid>
      <pubDate>Fri, 05 Jul 2024 14:21:48 GMT</pubDate>
    </item>
    <item>
      <title>Darknet Yolov4-tiny（灰度输入）到 Tensorflow 权重，转换</title>
      <link>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</link>
      <description><![CDATA[--
长话短说，TLDR：
1 通道 TF 模型的行为与 3 通道模型不同。两者都成功从 Darknet -&gt; TF 转换，但 1 通道模型的表现不如转换前。
手头的任务和声明：
我有两个经过训练的 yolov4-tiny darknet 权重文件 (.weights)，一个有灰度输入（1 通道），另一个有彩色输入（3 通道）。我正在使用一个通用存储库（用于此任务）将两个权重文件转换为 Tensorflow 检查点格式，该存储库位于：
https://github.com/hunglc007/tensorflow-yolov4-tflite.git
两种模型的性能都已通过 c++ opencv LoadFromDarknet() 和 Python 等效程序进行了测试。这两种模型本质上都是用灰度图像进行训练并对灰度图像进行操作的。3 通道模型的输入只是缩放到 3 通道的灰度图像。
Python 版本：3.10.11
TF 版本：2.10.1
问题描述：
使用 tf.keras.Models.load_model(X) 加载时，带有颜色输入的权重文件转换良好，之后运行良好，但是当转换灰度输入权重文件时，使用 Tensorflow 加载模型的性能急剧下降，我的意思是在最明显的情况下，带有颜色输入的模型运行完美，但检测结果很差或不存在。值得注意的是，框不会错位，这意味着当发现检测结果时，它们大致处于正确的位置，但例如宽度和高度可能会偏离。
我知道这个存储库的常见问题（硬编码内容等），并相应地更改了每次转换/模型加载的参数，并且在转换或模型加载期间不会发生任何错误。
我已经确认输入层：
灰度：（无，640,640,1）
颜色：（无，640,640,3）
测试图像（用于性能测试）使用 opencv-python 加载，并且它们的有效性也已审查，即使将错误维度的数据插入输入层也会出现错误。
除输入层之外的架构相同，已使用 model.summary() 确认。
我注意到，几年前我用不同的 TF 版本转换的 3 通道模型由 model.summary() 生成的架构有些不同。一些图块层似乎缺失了。此外，一些 tf 操作的名称也不同，但这可能只是 TF 版本不同。
旧颜色模型：
tf_op_layer_Sigmoid (TensorFlo (None, 40, 40, 3, 2 0 [&#39;tf_op_layer_split_3[0][0]&#39;]
wOpLayer) )
tf_op_layer_Tile/multiples (Te (5,) 0 [&#39;tf_op_layer_strided_slice[0][0]
nsorFlowOpLayer) &#39;]
tf_op_layer_Sigmoid_3 (TensorF (None, 20, 20, 3, 2 0 [&#39;tf_op_layer_split_4[0][0]&#39;]
lowOpLayer) ) )
新灰度模型：
tf.math.sigmoid (TFOpLambda) (无，40，40，3，2 0 [&#39;tf.split_3[0][0]&#39;]
)
---此处缺少图块层---
tf.math.sigmoid_3 (TFOpLambda) (无，20，20，3，2 0 [&#39;tf.split_4[0][0]&#39;]
)
我目前陷入困境，非常感激任何帮助。如果需要任何其他信息，我很乐意尽快提供。
一些反复试验：
-使用 Yolov4-tiny Head 解码块 -&gt;即使在模型能够加载的情况下也没有变化（解码时错误的尺寸会引发错误）
- 之前提到的旧 3 通道模型（几年前已转换为 Darknet -&gt; TF），当以与新模型相同的方式加载时，可以完美运行]]></description>
      <guid>https://stackoverflow.com/questions/78711847/darknet-yolov4-tiny-grayscale-input-to-tensorflow-weights-conversion</guid>
      <pubDate>Fri, 05 Jul 2024 13:54:37 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的上游与下游是什么？</title>
      <link>https://stackoverflow.com/questions/78711787/what-is-upstream-vs-downstream-in-machine-learning</link>
      <description><![CDATA[目前有很多深度学习模型库，这些模型被上传到那里用于下游任务。但是，我相信有目的地保存用于训练这些模型的代码，例如 GitHub。在这种情况下，我们可以将深度学习库称为下游，将代码库称为上游吗？]]></description>
      <guid>https://stackoverflow.com/questions/78711787/what-is-upstream-vs-downstream-in-machine-learning</guid>
      <pubDate>Fri, 05 Jul 2024 13:40:14 GMT</pubDate>
    </item>
    <item>
      <title>如果损失没有进一步减少，如何停止训练？</title>
      <link>https://stackoverflow.com/questions/78711202/how-to-stop-training-if-loss-doesnt-decrease-further</link>
      <description><![CDATA[我正在使用以下 .cfg 训练 Yolo Tiny Net 模型：
[Common]
image_size：448
batch_size：16
num_classes：21
max_objects_per_image：21
[DataSet]
name：yolo.dataset.text_dataset.TextDataSet
path：VOC_Dataset/pascal_voc.txt
thread_num：5
[Net]
name：yolo.net.yolo_tiny_net.YoloTinyNet
weight_decay：0.0005
cell_size：7
boxes_per_cell：2
object_scale：1
noobject_scale：0.5
class_scale：1
coord_scale：5
[Solver]
name：yolo.solver.yolo_solver.YoloSolver
learning_rate： 0.000001
moment: 0.9
max_iterators: 1000000
pretrain_model_path: lenet_model_to_use.ckpt
train_dir: models/train

此处 lenet_model_to_use.ckpt 是之前使用的训练模型，其标签比实际训练模型少一个（我为其添加了标签和图像，以便新模型能够识别该新图像）
我注意到，使用当前的 le​​arning_rate，模型训练会继续执行，而损失不会减少。我的问题是，如果经过两个连续步骤后损失没有进一步减少，我想停止训练。
要添加的参数名称是什么，在 .cfg 文件中的哪个部分下设置哪个值？]]></description>
      <guid>https://stackoverflow.com/questions/78711202/how-to-stop-training-if-loss-doesnt-decrease-further</guid>
      <pubDate>Fri, 05 Jul 2024 11:29:31 GMT</pubDate>
    </item>
    <item>
      <title>核密度估计：所有数据点与带宽内结果不同</title>
      <link>https://stackoverflow.com/questions/78711117/kernel-density-estimation-different-results-for-all-data-points-vs-within-band</link>
      <description><![CDATA[我正在使用 Python 对道路事故数据进行核密度估计 (KDE)，但这里我将使用 1d 数据仅用于说明。在拟合 KDE 模型时，我注意到考虑所有数据点与限制带宽内的数据点时会得到不同的结果。具体来说，当仅使用带宽内的点时，我在点数较少的区域和点数较多的区域得到的密度值几乎相同，这对我来说似乎是违反直觉的。我不知道该如何解释这一点，或者这是否是代码问题。
def KDE(x_list,radius):
return (1/(len(x_list)*radius))*np.sum([K(x/radius) for x in x_list])

def kde_val(x,dati):
return K((x-xi))

dataset = np.array([10,11,10,55,56,57,58,59])

x_range = np.linspace(dataset.min()-0.3, dataset.max()+0.3, num=600)

# 实验的带宽值
H = [30, 40, 50,30, 40, 50]
n_samples = dataset.size

# 不同带宽值的线属性
color_list = [&quot;棕色&quot;,&quot;黑色&quot;,&quot;黄色&quot;,&quot;蓝色&quot;,&quot;红色&quot;,&quot;绿色&quot;]
alpha_list = [0.8, 1, 0.8,0.8, 1, 0.8]
width_list = [1.7,2.5,1.7,1.7,2.5,1.7]

plt.figure(figsize=(10,4))
# 迭代带宽值
i=0
for h, color, alpha, width in zip(H, color_list, alpha_list, width_list):
i+=1

# 迭代数据点
y_range=[]
for x in x_range:
a=x-dataset
b=a[abs(a) &lt;= h] #仅考虑带宽 h 内的数据点
if i&gt;3: #当i&gt;3 我考虑所有数据点
b=x-dataset
y_range.append(KDE(b,h))
y_range=np.array(y_range)

plt.plot(x_range, y_range, 
color=color, alpha=alpha, linewidth=width, 
label=f&#39;{h}&#39;)

plt.plot(dataset, np.zeros_like(dataset) , &#39;s&#39;, 
markersize=8, color=&#39;black&#39;)


KDE
我找不到任何忽略带宽之外的数据点的库来比较结果。]]></description>
      <guid>https://stackoverflow.com/questions/78711117/kernel-density-estimation-different-results-for-all-data-points-vs-within-band</guid>
      <pubDate>Fri, 05 Jul 2024 11:10:51 GMT</pubDate>
    </item>
    <item>
      <title>在生物学项目中使用人体细胞实例分割</title>
      <link>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</link>
      <description><![CDATA[我对深度学习和 fastai 完全陌生，这可能是一个非常简单的问题，但我在为与生物学相关的项目进行实例分割时遇到了困难。
关于问题：我有一些人类细胞的图片（每张图片大约有 5 个细胞），我想要实现的是创建一个模型，可以拍摄这样的照片并识别细胞。我面临的问题是：我可以让模型识别细胞，但无法区分不同的细胞。（这意味着作为输出，我得到一个 .png 图片，其中 0 表示背景，1 表示细胞；所以我没有得到关于它们分离的信息）。例如，如果我想计算图片上有多少个单元格，那么这将是一个问题。
澄清一下：我手头有：单元格图片（RGB，.jpg）并且我有 2 种类型的蒙版：第一种是灰度（背景为 0，单元格全部为 1，.png）并且我还有一个 RGB 图片，其中所有单元格都有不同的 RGB 值（如果图片上有 4 个单元格，则存在 4 个不同的 RGB 值；背景始终为 0）。也是 .png。
使用 fastai，我的 DataBlock 如下所示：
 dblock = DataBlock(blocks = (ImageBlock, MaskBlock(codes)),
get_items = get_image_files,
splitter = RandomSplitter(),
get_y = get_label,
item_tfms = Resize(224))

dls = dblock.dataloaders(path, bs=5)

问题：我知道此代码无法工作，因为模型输入的灰度图像只有 0 和 1。但我不知道如何合并其他类型的掩码，该掩码实际上包含有关不同细胞分离的信息。（所有细胞都是同一类型）。
非常感谢您的帮助，
Andrej
上面已经提到了：)]]></description>
      <guid>https://stackoverflow.com/questions/78710926/using-instance-segmentation-on-human-cells-for-biology-project</guid>
      <pubDate>Fri, 05 Jul 2024 10:24:16 GMT</pubDate>
    </item>
    <item>
      <title>当它们都使用同一个类时，我该如何抓取整个表？到目前为止，我只能得到名称</title>
      <link>https://stackoverflow.com/questions/78710808/how-do-i-scrape-a-whole-table-when-they-all-use-the-same-class-i-can-so-far-ge</link>
      <description><![CDATA[我试图获取标有“关键利率”的表中的数据。但是，我只能提取名称，因为它们具有独特的样式（）。
我想要表中的数据并使用 Pandas 将其排列成表。
请帮忙
代码：
URL = &quot;https://www.centralbank.go.ke/&quot;
page = request.get(url)
soup = BeautifulSoup(page.content, &#39;html.parser&#39;)

job_elems = soup.find_all(&#39;td&#39;, class_=&quot;tg-4eph&quot;) 
for job_elem in job_elems: 
title_elem = job_elem.find(&#39;small&#39;) 
if title_elem: 
print(title_elem.text.strip())
]]></description>
      <guid>https://stackoverflow.com/questions/78710808/how-do-i-scrape-a-whole-table-when-they-all-use-the-same-class-i-can-so-far-ge</guid>
      <pubDate>Fri, 05 Jul 2024 09:55:49 GMT</pubDate>
    </item>
    <item>
      <title>如何将中国公司归类为 NAC 代码 [关闭]</title>
      <link>https://stackoverflow.com/questions/78709423/how-to-class-chinese-company-to-naics-code</link>
      <description><![CDATA[我想将一家中国上市公司或任何一家上市公司映射到NAICS代码。我有这些公司的业务范围和主营业务描述（中文，每年）和NAICS手册（英文，2012 2017 2022年更改）。使用什么技术进行分类会更好？
我想知道我应该使用什么样的软件，什么样的方法，我需要掌握哪些技术，这需要什么设备。我想尽快得到最终结果。非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78709423/how-to-class-chinese-company-to-naics-code</guid>
      <pubDate>Fri, 05 Jul 2024 02:04:54 GMT</pubDate>
    </item>
    <item>
      <title>cnnhistory=model.fit(x_traincnn, y_train, batch_size=20, epochs=500, validation_data=(x_testcnn, y_test)) 无值不支持错误</title>
      <link>https://stackoverflow.com/questions/78709319/cnnhistory-model-fitx-traincnn-y-train-batch-size-20-epochs-500-validation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78709319/cnnhistory-model-fitx-traincnn-y-train-batch-size-20-epochs-500-validation</guid>
      <pubDate>Fri, 05 Jul 2024 00:58:54 GMT</pubDate>
    </item>
    <item>
      <title>将最优模型应用于测试集</title>
      <link>https://stackoverflow.com/questions/78707916/to-apply-the-optimal-model-to-the-test-set</link>
      <description><![CDATA[我有一个数据集需要训练和测试，还有另一个数据集作为测试集。
我已经使用训练数据集获得了最佳模型，并希望将该模型应用于测试集进行预测，但遇到了此错误消息：
ValueError：特征名称应与拟合期间传递的特征名称匹配。
在拟合时看到的特征名称，但现在缺失：

教育
婚姻

如何解决此错误？
示例数据集
[![data][1]][1]
df = pd.read_csv(&#39;training.csv&#39;)
df.drop([&#39;USAGE(0)&#39;, &#39;CUSTOMERID&#39;], axis=1, inplace=True)

# 初始化编码器并拟合训练数据
encoder = OneHotEncoder(drop=&#39;first&#39;, sparse_output=False)
encoder.fit(df.select_dtypes(include=[&#39;object&#39;]))

# 在训练数据中编码字符串类型变量
for column in df.select_dtypes(include=[&#39;object&#39;]).columns:
coded_result =coder.transform(df[[column]])
coded_df = pd.DataFrame(encoded_result, columns=encoder.get_feature_names_out([column]))
df.drop(column, axis=1, inplace=True)
df = pd.concat([df,coded_df], axis=1)

# 分离特征和标签
label = &#39;PAYMENT(0)&#39;
excluded_columns = [label]
features = [feature for feature in df.columns if feature not in excluded_columns]
X = df[features]
y = df[label]

# 训练-测试分割
test_size = 0.2
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)

#构建并训练初始决策树模型
model = DecisionTreeClassifier(criterion=&#39;gini&#39;, min_samples_leaf=3000)
model.fit(X_train, y_train)

# 使用网格搜索和交叉验证进行超参数调整
param_grid = {
&#39;criterion&#39;: [&#39;gini&#39;, &#39;entropy&#39;],
&#39;min_samples_leaf&#39;: [10, 20, 30, 40, 50, 60, 70, 80]
}
cv = KFold(n_splits=10, shuffle=True)
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv,scoring=&#39;accuracy&#39;)
grid_search.fit(X_train, y_train)

# 训练最优模型
optimal_model = grid_search.best_estimator_

# 可视化最佳决策树
plt.figure(figsize=(100, 20))
plot_tree(optimal_model, filled=True, feature_names=features)
plt.show()

# 加载新测试数据
new_test_df = pd.read_csv(&#39;trial.csv&#39;)

# 保留提交文件的“ID”列
submission_ids = new_test_df[&#39;CUSTOMERID&#39;].copy()

new_test_df.drop(&#39;USAGE(0)&#39;, axis=1, inplace=True)

# 确保所有必要的列都存在
for column in df.select_dtypes(include=[&#39;object&#39;]).columns:
if column not in new_test_df.columns:
new_test_df[column] = 0

# 在新测试中编码字符串类型变量数据
for column in new_test_df.select_dtypes(include=[&#39;object&#39;]).columns:
coded_result =coder.transform(new_test_df[[column]]) # 使用拟合的编码器进行转换
coded_df = pd.DataFrame(encoded_result, columns=encoder.get_feature_names_out([column]))
new_test_df.drop(column, axis=1, inplace=True)
new_test_df = pd.concat([new_test_df,coded_df], axis=1)

# 确保新测试数据与训练数据具有相同的特征列
for feature in features:
if feature not in new_test_df.columns:
new_test_df[feature] = 0
X_new_test = new_test_df[features]

# 将最优模型应用于新测试数据
y_new_test_pred = optimal_model.predict(X_new_test)

# 将预测保存到名为“mapping.csv”的 CSV 文件中
submission = pd.DataFrame({
&#39;CUSTOMERID&#39;: submission_ids,
&#39;PAYMENT(0)&#39;: y_new_test_pred
})

submission.to_csv(&#39;mapping.csv&#39;, index=False)

[1]: https://i.sstatic.net/fz90exd6.png
]]></description>
      <guid>https://stackoverflow.com/questions/78707916/to-apply-the-optimal-model-to-the-test-set</guid>
      <pubDate>Thu, 04 Jul 2024 15:27:01 GMT</pubDate>
    </item>
    <item>
      <title>鉴于我的数据集不大且大多数模型都无法生成正确的响应，我该如何训练我的聊天机器人</title>
      <link>https://stackoverflow.com/questions/78705520/how-do-i-train-my-chatbot-given-that-my-dataset-is-not-vast-large-and-most-mode</link>
      <description><![CDATA[我从 llama 开始，因为我被告知要使用 meta-llama（hugging face 上的任何一种），但由于我的笔记本电脑规格有限，meta-llama 从未进入训练阶段。甚至尝试了 meta 中的 10 亿参数模型，仍然不好。
我有一个包含原始数据的 .txt 文件（未按问题：答案对排列），所以我编写了一个脚本，首先创建一个 json 文件，在该文件中，数据按问题：答案对排列，现在我的目标是使用特定模型对其进行微调和训练。我的数据不是庞大/大，最多是小或中等。所以，我尝试了很多模型。Gpt2 等给了我糟糕的回应，所以我尝试了一些其他模型，如 Albert、tiny-bert、roberta-large，但问题是，有些问题确实得到了机器人的正确回答，但其中很大一部分都失败了。有些问题的答案只是重复的、不完整的。
我尝试了几种方法来提高效率（SBERT/TF-IDF 等），甚至尝试修改微调文件，但都无济于事。我对这一切都很陌生，所以我想知道如何继续。T
尝试了几种模型来训练我的聊天机器人，但几乎都失败了。
希望我的聊天机器人能够使用包含问题：答案对的 json 文件进行适当的训练，但是数据可能不会太大。
笔记本电脑也有一些限制（规格，例如低内存 -&gt; 8GB）]]></description>
      <guid>https://stackoverflow.com/questions/78705520/how-do-i-train-my-chatbot-given-that-my-dataset-is-not-vast-large-and-most-mode</guid>
      <pubDate>Thu, 04 Jul 2024 07:06:35 GMT</pubDate>
    </item>
    <item>
      <title>如何在 AWS DeepRacer 学生联赛中提高我的汽车速度？[关闭]</title>
      <link>https://stackoverflow.com/questions/78703745/how-to-increase-speed-of-my-car-in-aws-deepracer-student-league</link>
      <description><![CDATA[如何在此处访问速度的输入参数？
# 读取输入参数
track_width = params[&#39;track_width&#39;]
distance_from_center = params[&#39;distance_from_center&#39;]

我曾尝试使用此方法访问速度参数
speed = params[&#39;speed&#39;]

但这导致了错误并且无法运行模型]]></description>
      <guid>https://stackoverflow.com/questions/78703745/how-to-increase-speed-of-my-car-in-aws-deepracer-student-league</guid>
      <pubDate>Wed, 03 Jul 2024 18:36:28 GMT</pubDate>
    </item>
    </channel>
</rss>