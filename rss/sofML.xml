<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 15 May 2024 21:15:16 GMT</lastBuildDate>
    <item>
      <title>为什么 JAX 编译时间随着 vmap 批处理大小的增加而增长？</title>
      <link>https://stackoverflow.com/questions/78486071/why-does-jax-compilation-time-grow-with-vmap-batch-size</link>
      <description><![CDATA[我正在使用 JAX 来评估批量损失梯度，其中涉及一些复杂的线性代数（包括 Cholesky 分解和解决方案等）。我的梯度损失的示意图形式是
jax.jit( jax.value_and_grad( jax.vmap(loss)(...).mean() ) )

我发现编译/首次评估时间在给定 vmap 的特定批量大小之前是恒定的（正如我通常所期望的那样），然后开始超线性增长。在 A100 上，nbatch &lt;= 64 需要 6 分钟，nbatch=128 需要 13 分钟，nbatch=256 需要 1 小时，这变得很笨拙。
这里可能发生什么？如果内存或计算单元不足，jax.vmap 是否会尝试展开批处理？]]></description>
      <guid>https://stackoverflow.com/questions/78486071/why-does-jax-compilation-time-grow-with-vmap-batch-size</guid>
      <pubDate>Wed, 15 May 2024 19:17:27 GMT</pubDate>
    </item>
    <item>
      <title>我应该在 GitHub 上分享我的自我项目吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78484980/should-i-share-my-self-projects-on-github</link>
      <description><![CDATA[我一直在考虑是否应该在 GitHub 上分享我自己的项目。这些项目主要涉及机器学习，重点关注回归和分类任务。虽然我已经付出了努力，但我不确定是否值得清理代码并上传它。展示这些小项目实际上是否有益，或者最终只是浪费时间？]]></description>
      <guid>https://stackoverflow.com/questions/78484980/should-i-share-my-self-projects-on-github</guid>
      <pubDate>Wed, 15 May 2024 15:26:31 GMT</pubDate>
    </item>
    <item>
      <title>使用 Flask 时的机器学习问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</link>
      <description><![CDATA[我有一个用于房屋预测的数据库。在这个数据集中，我有很多分类变量，因此我使用了一个热编码器，现在我有大约 40 列数据。我正在尝试为我的模型构建一个 API，尽管我无法正确传递数据来进行预测。有什么办法可以实现这一点吗？
我尝试使用每个变量并获取请求表单，然后将它们放入数组中，尽管我遇到了错误。是否可以为我编写关于如何在烧瓶中插入大数据集以便邮递员发送请求的代码？]]></description>
      <guid>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</guid>
      <pubDate>Wed, 15 May 2024 14:32:08 GMT</pubDate>
    </item>
    <item>
      <title>有什么办法可以找到音频和视频之间的同步分数吗？</title>
      <link>https://stackoverflow.com/questions/78484136/is-there-any-way-to-find-synchronization-score-between-audio-and-video</link>
      <description><![CDATA[假设我们有一个扩展名为 .mp4 的静音视频文件和一个扩展名为 .wav 的音频文件。有什么办法可以找到音频和视频之间的同步分数。预先感谢您回答问题。
我使用深度学习模型进行视频特征提取，使用另一种模型进行音频特征提取。现在我已经使用欧几里德距离和相关性来检查音频和视频特征之间的相似性，但它不起作用。我希望如果两个特征相似或同步，那么输出应该接近 1，否则接近 0。]]></description>
      <guid>https://stackoverflow.com/questions/78484136/is-there-any-way-to-find-synchronization-score-between-audio-and-video</guid>
      <pubDate>Wed, 15 May 2024 13:00:05 GMT</pubDate>
    </item>
    <item>
      <title>无法在 Windows 机器中安装 Rasa</title>
      <link>https://stackoverflow.com/questions/78483192/unable-to-install-rasa-in-windows-machine</link>
      <description><![CDATA[我尝试在 Windows 10 笔记本电脑中使用命令 pip install rasa 安装 Rasa。
我安装了Python 3.11版本。
但我收到以下错误：
获取构建轮的要求未成功运行。
  │ 退出代码：1
  ╰─&gt; [20行输出]
      回溯（最近一次调用最后一次）：
        文件“C:\python311\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，行
     353，在&lt;模块&gt;中
          主要的（）
    文件“C:\python311\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 335 行，
    在主要
          json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

我错过了什么？之前，我尝试安装chatterbot模块，但也遇到了类似的错误。
此外，我也尝试使用 pip install chatterbot ，但仍然出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78483192/unable-to-install-rasa-in-windows-machine</guid>
      <pubDate>Wed, 15 May 2024 10:10:42 GMT</pubDate>
    </item>
    <item>
      <title>随机森林和交叉验证</title>
      <link>https://stackoverflow.com/questions/78483176/random-forest-and-cross-validation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78483176/random-forest-and-cross-validation</guid>
      <pubDate>Wed, 15 May 2024 10:08:38 GMT</pubDate>
    </item>
    <item>
      <title>从 CLIP 功能恢复图像的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/78482968/what-is-the-best-way-to-recover-image-from-its-clip-features</link>
      <description><![CDATA[假设我们有一个大小为 torch.Size([1, 3, 336, 336]) 的图像，并使用大小为 torch.Size([1, 577, 1024]），如何用这个潜在特征图恢复原始图像？
我尝试使用StabilityAI/stable-diffusion-2-1-unclip，它是从 sd2 中进行微调以接受图像嵌入的。但是，我发现它只需要 cls 令牌并忽略其他令牌。有什么办法可以充分利用整个嵌入吗？还是需要sd2进行微调？]]></description>
      <guid>https://stackoverflow.com/questions/78482968/what-is-the-best-way-to-recover-image-from-its-clip-features</guid>
      <pubDate>Wed, 15 May 2024 09:32:19 GMT</pubDate>
    </item>
    <item>
      <title>UNet Segmentor 仅“识别”背景类</title>
      <link>https://stackoverflow.com/questions/78482896/unet-segmentor-only-identifies-background-class</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78482896/unet-segmentor-only-identifies-background-class</guid>
      <pubDate>Wed, 15 May 2024 09:21:07 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 TensorFlow 提高多类分类的准确性？</title>
      <link>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</link>
      <description><![CDATA[我正在使用 TensorFlow 解决多类分类问题，并在实现令人满意的准确性方面遇到了挑战。我有7节课。文件夹中的每个类包含 2000 个 .csv 文件（每个文件有两列）。当我使用二元分类方法训练模型并用另一个类测试一个类时，准确性和 val_accuracy 会很高，0.85 到 0.95，但是当我使用多类进行测试时，精度最高可达0.47。下面是包含数据抛光和模型多类的代码。
#文件夹中的 csv 类
文件夹路径 = [
    &#39;/content/drive/MyDrive/medical_chem/Aa&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ab&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ac&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ba&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Bb&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Cc&#39;,
    &#39;/内容/驱动器/MyDrive/medical_chem/DD&#39;
]


数据 = []
标签=[]

#加载文件夹并将文件csv存档在数据框中
对于 enumerate(folder_paths) 中的 class_index、folder_path：
    对于 os.listdir(folder_path) 中的文件：
        file_path = os.path.join(文件夹路径, 文件)
        df = pd.read_csv(文件路径)
        数据.append(df)
        labels.append(class_index)

X = 数据
y = 标签

# 找到数据框中的最小值
min_length = min(len(df) for df in X)
# 设置数据帧长度相同
truncated_dfs = [df.head(min_length) for df in X]
# 数据帧到 numpy 数组
X = np.array([df.truncated_dfs 中 df 的值])


# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 标准化数据
X_train = 归一化(X_train, 轴=1)
X_test = 归一化(X_test, 轴=1)
y_train = to_categorical(y_train, num_classes=7)
y_test = to_categorical(y_test, num_classes=7)


X_train.shape、y_train.shape、X_test.shape、y_test.shape
# 输出 ((8943, 2906, 2), (8943, 7), (2236, 2906, 2), (2236, 7))

模型 = tf.keras.Sequential([
    tf.keras.layers.Dense(128, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(64, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(32, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(7,activation=&#39;softmax&#39;) # 7个类的输出层
]）

# 训练模型的检查点
checkpoint_path = “training_checkpoint/cp.ckpt”
checkpoint_dir = os.path.dirname(checkpoint_path)
checkpoint_callback = ModelCheckpoint(文件路径=checkpoint_path,
                                      save_weights_only=真，
                                      save_best_only=真，
                                      监视器=&#39;val_loss&#39;,
                                      详细=1)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;分类交叉熵&#39;，
              指标=[&#39;准确性&#39;])

#model.load_weights(检查点路径)

历史 = model.fit(X_train, y_train,
                    纪元=100，
                    验证数据=（X_测试，y_测试），
                    回调=[检查点回调])


我尝试过调整神经网络的架构，尝试不同的激活函数，并优化学习率和批量大小等超参数。但是，我仍然没有达到预期的准确性。
我确信我出错的地方是在预处理数据或模型中，因为二进制训练有很好的结果。
与二进制训练相比，准确度为 0.85 至 0.95
**多类别的预期准确率：高于 0.90
**
数据集： https://drive .google.com/drive/folders/1UAt50dPH7ABeoLu16nfa19g4oVccPeFO?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</guid>
      <pubDate>Wed, 15 May 2024 00:27:22 GMT</pubDate>
    </item>
    <item>
      <title>调查 TensorFlow 和 PyTorch 性能的差异</title>
      <link>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</guid>
      <pubDate>Tue, 14 May 2024 13:54:26 GMT</pubDate>
    </item>
    <item>
      <title>尝试强制新预测器中的观察结果以在医疗补助支出数据集中执行逻辑函数</title>
      <link>https://stackoverflow.com/questions/78456621/attempting-to-coerce-observations-in-a-new-predictor-to-perform-logistic-functio</link>
      <description><![CDATA[我正在分析按药物数据划分的医疗补助支出数据字典数据集。具体来说，我想执行逻辑回归，其中 y 应该是 CAGR_Avg_Spnd_Per_Dsg_Unt_18_22。
不幸的是，根据我的代码，类和模式仍然是字符。
我对“Up”的灵感来自于和“向下”方法来自以下内容：
# 该库来自《统计学习简介：R 中的应用》

图书馆（ISLR）
附加(Smarket)
总结(Smarket)
# 期望的输出：
glm.fit=glm(方向~Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + 音量,
            家庭=二项式，数据=Smarket）
对比（方向）

通过使用 glm.fit，我可以执行预测、创建混淆矩阵等等。
但是，在检查时
摘要(drug.spending)

我的“向上”和“向下”是角色，而 ISLR 的“Up”的作者是角色。和“向下”看来是按数字算的。作者从未提供使用数据框的“Up”来执行此操作的代码。和“向下”观察！
这是我的代码：
库(dplyr)
图书馆（tidyr）
图书馆（心理学）
图书馆（跳跃）
设置.种子(1)

支出 &lt;- read.csv(“medicaid_spending_by_drug_data_dictionary.csv”)
药品支出 &lt;- 支出 %&gt;%
  na.omit(支出) %&gt;%
  filter(Mftr_Name == “总体”) %&gt;%
  安排(desc(Tot_Mftr)) %&gt;%
  过滤器（重复（Gnrc_Name））
drug.spending &lt;- drug.spending[!duplicate(drug.spending$Gnrc_Name),]
附加（药物.支出）



药物支出 &lt;- 药物支出 %&gt;%
  mutate(CAGR_Direction = ifelse(CAGR_Avg_Spnd_Per_Dsg_Unt_18_22 &gt; 0, &#39;向上&#39;, &#39;向下&#39;))
drug.spending$CAGR_Direction &lt;- factor(drug.spending$CAGR_Direction,levels = c(&#39;Down&#39;, &#39;Up&#39;)) # 更新#1

摘要（药品.支出）
对比（CAGR_Direction）#给出错误

我使用了不同的强制转换，例如 as.numeric() 和 as.integer()。我不太确定我哪里出错了......]]></description>
      <guid>https://stackoverflow.com/questions/78456621/attempting-to-coerce-observations-in-a-new-predictor-to-perform-logistic-functio</guid>
      <pubDate>Thu, 09 May 2024 19:27:54 GMT</pubDate>
    </item>
    <item>
      <title>将分类加权损失函数集成到我的代码中后，准确性下降了[关闭]</title>
      <link>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</link>
      <description><![CDATA[我想提高准确性，并且我有不平衡数据集：akiec：229，bcc：360，bkl：769，df：81，mel：779，vasc：99。为了解决这个问题，我选择将分类加权损失机制集成到模型中。然而，尽管进行了这样的调整，我还是注意到准确性随后下降了。这个意想不到的结果让我怀疑实施过程中出现了错误。您能否帮助我识别和解决任何潜在的错误以优化模型的性能？
# 定义目录
train_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Train&#39;
test_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Test&#39;
validation_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Validation&#39;

# 确定类的数量
numClasses = len(os.listdir(train_dir))

# 定义超参数网格
参数网格 = {
    &#39;学习率&#39;：[0.001]，
    &#39;批量大小&#39;：[16]，
}

最佳准确度 = 0
最佳参数=无

# 执行网格搜索
对于 ParameterGrid(param_grid) 中的参数：
    # 为每次网格搜索迭代加载预训练的 VGG19 模型
    base_model = VGG19(权重=&#39;imagenet&#39;, include_top=False, input_shape=(224, 224, 3))
    对于 base_model.layers 中的图层：
        可训练层 = False

    # 定义函数从最后一个卷积层提取特征
    def extract_features（生成器，模型）：
        特征 = model.predict(生成器)
        返回 features.reshape((len(generator.filenames), -1))

    # 创建数据生成器
    train_datagen = 图像数据生成器(
        重新缩放=1./255，
        旋转范围=20，
        width_shift_range=0.2，
        height_shift_range=0.2，
        剪切范围=0.2，
        缩放范围=0.2，
        水平翻转=真，
        fill_mode=&#39;最近&#39;)

    validation_datagen = ImageDataGenerator（重新缩放=1./255）

    train_generator = train_datagen.flow_from_directory(
        火车目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）

    validation_generator =validation_datagen.flow_from_directory(
        验证目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）
&#39;&#39;&#39;

可能这里有一个错误

&#39;&#39;&#39;

    # 定义类索引
    类索引 = {
        &#39;基亚克&#39;: 0,
        “密件抄送”：1，
        “bkl”：2，
        “df”：3，
        “梅尔”：4，
        “血管”：5
    }

    ## 计算班级人数
    类计数 = {}
    对于 os.listdir(train_dir) 中的 class_name：
        class_counts[class_name] = len(os.listdir(os.path.join(train_dir, class_name)))

    # 计算类别权重
    类权重 = {}
    Total_samples = sum(class_counts.values())
    对于 class_name、class_count 在 class_counts.items() 中：
        class_weights[class_indices[class_name]] = 总样本数 / (class_count * len(class_counts))



    # 定义模型架构以接受提取的特征作为输入
    输入=输入(形状=(combined_data_train.shape[1],))
    x = 密集（256，激活=&#39;relu&#39;）（输入）
    预测=密集（numClasses，激活=&#39;softmax&#39;）（x）
    模型=模型（输入=输入，输出=预测）

    # 使用当前的超参数和类权重编译模型
    model.compile（优化器=SGD（learning_rate=params[&#39;learning_rate&#39;]），loss=&#39;sparse_categorical_crossentropy&#39;，metrics=[&#39;accuracy&#39;]，sample_weight_mode=&#39;temporal&#39;）

    # 定义提前停止
    Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

    # 通过提前停止来训练模型
    num_epochs = 50 # 您可以在此处调整纪元数
    历史=模型.fit(
        x=组合数据训练，
        y=train_generator.labels,
        纪元=num_epochs，
        批量大小=参数[&#39;批量大小&#39;],
        validation_data=(combined_data_validation,validation_generator.labels),
        回调=[early_stopping],
        类权重=类权重，
        详细=1
    ）

    model.save(&#39;best_vgg19_model_with_age.h5&#39;)

    # 根据验证数据评估模型
    _，val_accuracy = model.evaluate（combined_data_validation，validation_generator.labels，详细= 0）

    # 如有必要，更新最佳精度和最佳参数
    如果 val_accuracy &gt;最佳准确度：
        最佳准确度 = 有效准确度
        最佳参数 = 参数

# 打印最佳参数和准确度
print(&#39;最佳参数：&#39;, best_params)
print(&#39;最佳验证准确度：&#39;, best_accuracy)


# 加载最佳模型
best_model = load_model(&#39;best_vgg19_model_with_age.h5&#39;)

]]></description>
      <guid>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</guid>
      <pubDate>Thu, 09 May 2024 14:52:54 GMT</pubDate>
    </item>
    <item>
      <title>训练 BigGan 模型时的运行时错误和其他错误</title>
      <link>https://stackoverflow.com/questions/78437895/runtime-error-and-other-errors-while-training-biggan-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78437895/runtime-error-and-other-errors-while-training-biggan-model</guid>
      <pubDate>Mon, 06 May 2024 16:18:20 GMT</pubDate>
    </item>
    <item>
      <title>线性回归的正规方程</title>
      <link>https://stackoverflow.com/questions/49347878/normal-equation-for-linear-regression</link>
      <description><![CDATA[我有以下 X 和 y 矩阵：

为此，我想使用正规方程方法计算线性回归方程的最佳 θ 值：
theta = inv(X^T * X) * X^T * y
theta 的结果应该是：[188.400,0.3866,-56.128,-92.967,-3.737]
我通过以下方式实现这些步骤：
X=np.matrix([[1,1,1,1],[2104,1416,1534,852],[5,3,3,2],[1,2,2, 1],[45,41,30,36]])
y=np.matrix([460,232,315,178])

XT=np.转置(X)

XTX=XT.点(X)

inv=np.linalg.inv(XTX)

inv_XT=inv.dot(XT)

θ=inv_XT.dot(y)

打印（θ）

但我没有得到想要的结果。相反，它会抛出错误：

&lt;块引用&gt;
  回溯（最近一次调用最后一次）：文件“C:/”，第 19 行，位于
      theta=inv_XT.dot(y) ValueError：形状 (4,5) 和 (1,4) 未对齐：5 (dim 1) != 1 (dim 0)

我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/49347878/normal-equation-for-linear-regression</guid>
      <pubDate>Sun, 18 Mar 2018 12:28:38 GMT</pubDate>
    </item>
    <item>
      <title>do_one(nmeth) 中的错误：外部函数调用中的 NA/NaN/Inf (arg 1)</title>
      <link>https://stackoverflow.com/questions/36469671/error-in-do-onenmeth-na-nan-inf-in-foreign-function-call-arg-1</link>
      <description><![CDATA[我有一个数据表（“范数”），其中包含数字（至少就我所见），其标准化值如下：

当我执行时
k &lt;- kmeans(norm,center=3)

我收到以下错误：
do_one(nmeth) 中的错误：外部函数调用中的 NA/NaN/Inf (arg 1)

你能帮我吗？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/36469671/error-in-do-onenmeth-na-nan-inf-in-foreign-function-call-arg-1</guid>
      <pubDate>Thu, 07 Apr 2016 07:40:01 GMT</pubDate>
    </item>
    </channel>
</rss>