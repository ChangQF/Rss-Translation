<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 24 Apr 2024 12:29:58 GMT</lastBuildDate>
    <item>
      <title>为什么在用平均值或中位数替换数据集中的 NaN 值后会得到“inf”值？</title>
      <link>https://stackoverflow.com/questions/78378193/why-do-i-get-inf-values-after-replacing-nan-values-in-my-dataset-with-the-mean</link>
      <description><![CDATA[我正在使用 Python，并且有一个包含 NaN 值的数据集。为了清理这些数据，我使用 pandas 的 fillna() 函数将 NaN 值替换为每列的平均值或中位数。然而，在此操作之后，我的数据集中的一些值变成了“inf”。我不明白为什么会发生这种情况以及如何解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78378193/why-do-i-get-inf-values-after-replacing-nan-values-in-my-dataset-with-the-mean</guid>
      <pubDate>Wed, 24 Apr 2024 11:45:41 GMT</pubDate>
    </item>
    <item>
      <title>无法使用数据数组 1*10201 编写机器学习模型</title>
      <link>https://stackoverflow.com/questions/78377490/can-t-coding-machine-learning-model-with-data-array-110201</link>
      <description><![CDATA[我已经编写了拓扑优化代码，并希望使用从拓扑优化循环收集的数据作为数据帧来添加机器学习，如图所示，J_old 每列都有一个值，但 lamda 和灵敏度值​​是 1*10201 数组，灵敏度是我希望该模型预测的输出目标
我用如图所示的数据编码机器学习模型
数据
而且，我希望 x_data 成为“J_old”和“lamda”列中的数据，我该怎么做？？
x_data = df[&#39;J_old&#39;]
y_data = df[&#39;灵敏度&#39;]

x_train, x_test, y_train, y_test = train_test_split(x_data1, y_data1, test_size=0.2, random_state=42)

模型=顺序（）

input_data = tf.placeholder(tf.float32, (None, 40, 40, 2), name=&#39;input_data&#39;) #输入大小=40
model_dens = model.add(Dense(units=64,activation=&#39;softmax&#39;)) #dense 中的单位 = 64, softmax = 输出为数组
output_true = tf.placeholder(tf.float32, (None, 40, 40, 1), name=&#39;output_true&#39;) #输入大小=40
学习率 = tf.placeholder(tf.float32, [], name=&#39;learning_rate&#39;)

model.compile（优化器=&#39;adam&#39;，损失=&#39;mean_squared_error&#39;，指标=[&#39;mae&#39;]）
#model.fit(x=trainX, y=trainY,validation_data=(testX, testY),epochs=200)
#model.fit(x_train, y_train, epochs=5)
model.fit(x_train, y_train, epochs=5,validation_data=(x_test, y_test))
# 打印模型摘要
模型.summary()

&lt;前&gt;&lt;代码&gt;
-------------------------------------------------- ------------------------
TypeError Traceback（最近一次调用最后一次）
[160] 中的单元格，第 19 行
     16 model.compile（优化器=&#39;adam&#39;，损失=&#39;mean_squared_error&#39;，指标=[&#39;mae&#39;]）
     17 #model.fit(x=trainX, y=trainY,validation_data=(testX, testY),epochs=200)
     18 #model.fit(x_train, y_train, epochs=5)
---&gt; 19 model.fit(x_train, y_train, epochs=5,validation_data=(x_test, y_test))
     20 # 打印模型摘要
     21 模型.summary()

文件/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122，位于filter_traceback..error_handler(*args, **kwargs)
    第119章
    120 # 要获取完整的堆栈跟踪，请调用：
    121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
    123 最后：
    124 删除filtered_tb

文件/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/compat.py:81，在as_bytes（bytes_or_text，编码）中
     79 返回字节或文本
     80 其他：
---&gt; 81 raise TypeError(&#39;需要二进制或unicode字符串，得到%r&#39; %
     82（字节或文本，））

类型错误：需要二进制或 unicode 字符串，得到数组([-0.24753326+0.j, -0.24753326+0.j, -0.2500359 +0.j, ...,
       -0.34861478+0.j,-0.34856497+0.j,-0.34856497+0.j])

我该如何修复这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/78377490/can-t-coding-machine-learning-model-with-data-array-110201</guid>
      <pubDate>Wed, 24 Apr 2024 09:52:12 GMT</pubDate>
    </item>
    <item>
      <title>顺序最小优化器的训练损失曲线上的峰值</title>
      <link>https://stackoverflow.com/questions/78377148/spikes-on-training-loss-curve-of-sequential-minimal-optimizer</link>
      <description><![CDATA[我正在尝试实现一个具有硬边距的 SMO 优化器来解决大边距分类器，但是，我注意到训练损失曲线上有奇怪的尖峰（我正在使用铰链损失），我做了什么吗错了？
我的代码
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
导入时间

np.随机.种子(0)


def SMO_impl(no_of_points):
#数据点生成
    区域_abc = []
    区域_bcd = []

    while(len(region_abc) &lt; no_of_points 或 len(region_bcd) &lt; no_of_points):
        new_point = np.random.uniform(0,1,(2,))
        if(new_point[1]&gt;new_point[0] 且 len(region_bcd) &lt; no_of_points):
            Region_bcd.append(new_point)
        elif(new_point[1] 容差且 alphas[i] &gt; 0)):
                j = pick_j(i,len(数据点))
                error_j = sum([alphas[k]*y[k]*np.dot(data_points[j],data_points[k]) for k in range(len(data_points))]) + b - y[j]

                old_alpha_i, old_alpha_j = alphas[i], alphas[j]

                L = max(0, alphas[j] - alphas[i]) 如果 y[i] != y[j] 否则 max(0, alphas[i] + alphas[j] - C)
                H = min(C, C + alphas[j] - alphas[i]) 如果 y[i] != y[j] else min(C, alphas[i] + alphas[j])

                如果 L == H：
                    继续

                eta = 2* np.dot(data_points[i], data_points[j]) - np.dot(data_points[i], data_points[i]) - np.dot(data_points[j], data_points[j])
                如果（eta &gt;= 0）：
                    继续
                new_alpha_j = alphas[j] - y[j] * (error_i - error_j) / eta
                new_alpha_j = np.clip(new_alpha_j, L, H)

                阿尔法[j] = new_alpha_j
                if(np.abs(alphas[j]-old_alpha_j)&lt;0.00001):
                    继续
                alphas[i] = alphas[i] + y[i]*y[j]*(old_alpha_j-alphas[j])

                b1 = b - error_i - y[i]*(old_alpha_i-alphas[i])*np.dot(data_points[i],data_points[i])- y[j]*(old_alpha_j-alphas[j])*np .dot(数据点[i],数据点[j])
                b2 = b - error_j - y[i]*(old_alpha_i-alphas[i])*np.dot(data_points[i],data_points[j]) - y[j]*(old_alpha_j-alphas[j])*np .dot(数据点[j],数据点[j])

                if(alphas[i]&gt;0):
                    b = b1
                elif(alphas[j]&gt;0):
                    b = b2
                别的：
                    b = (b1+b2)/2
                改变的阿尔法 += 1
        总损失 = sum([hinge_loss(alphas, y, data_points,i,b) for i in range(len(data_points))]) / len(data_points)
                         
        损失.append(total_loss)
        迭代 = 迭代 + 1 if(changed_alphas==0) else 0

    #训练损失曲线

    plt.plot(losses, label = f&#39;每组有 {no_of_points} 点的训练损失曲线&#39;)
    plt.title(f&#39;每组有 {no_of_points} 点的训练损失曲线&#39;)

 
SMO_impl(20)

曲线
在此处输入图片描述
忽略以下内容
（看起来我的帖子主要是代码；添加更多细节。看起来我的帖子主要是代码；添加更多细节。）]]></description>
      <guid>https://stackoverflow.com/questions/78377148/spikes-on-training-loss-curve-of-sequential-minimal-optimizer</guid>
      <pubDate>Wed, 24 Apr 2024 08:59:54 GMT</pubDate>
    </item>
    <item>
      <title>尽管 GPU 可用，但 CUDA 设置失败</title>
      <link>https://stackoverflow.com/questions/78376600/cuda-setup-failed-despite-gpu-being-available</link>
      <description><![CDATA[我需要使用bitsandbytes包来运行使用Falcon7B模型的代码。我已经安装了 CUDA，并且我的系统具有 NVIDIA RTX A6000 GPU。我的系统有 Windows 11 操作系统。
这是代码，它只是导入部分：
导入火炬
从数据集导入load_dataset
从变压器导入 AutoModelForCausalLM、AutoTokenizer、BitsAndBytesConfig、TrainingArguments、GenerationConfig
从peft导入LoraConfig，get_peft_model，PeftConfig，PeftModel，prepare_model_for_kbit_training
从 trl 导入 SFTTrainer
进口警告
warnings.filterwarnings(“忽略”)

这是错误：
运行时错误：
        尽管 GPU 可用，但 CUDA 安装失败。请运行以下命令来获取更多信息：

        python -m 位和字节

        检查命令的输出并查看是否可以找到 CUDA 库。您可能需要添加它们
        到您的 LD_LIBRARY_PATH。如果您怀疑存在错误，请从 python -m bitsandbytes 获取信息
        并在以下位置提出问题：https://github.com/TimDettmers/bitsandbytes/issues



RuntimeError：由于以下错误而无法导入transformers.training_args（查找其回溯）：

        尽管 GPU 可用，但 CUDA 安装失败。请运行以下命令来获取更多信息：

        python -m 位和字节

        检查命令的输出并查看是否可以找到 CUDA 库。您可能需要添加它们
        到您的 LD_LIBRARY_PATH。如果您怀疑存在错误，请从 python -m bitsandbytes 获取信息
        并在以下位置提出问题：https://github.com/TimDettmers/bitsandbytes/issues

有时不会出现此错误，并且代码可以正常工作。但大多数时候我都会遇到此错误，并且无法找到准确的修复方法。
当系统中未安装 CUDA 时，首次出现此错误。安装后没有报错，但是第二天再次运行时，又出现了同样的错误。
接下来我尝试将 python 版本降级到 3.11.1 以下，之后代码再次运行。但今天我再次面临同样的错误。
这是我的 CUDA 版本：
&lt;前&gt;&lt;代码&gt;nvcc --版本
nvcc：NVIDIA (R) Cuda 编译器驱动程序
版权所有 (c) 2005-2023 NVIDIA 公司
建于 Wed_Feb__8_05:53:42_Cooperative_Universal_Time_2023
Cuda 编译工具，版本 12.1，V12.1.66
构建cuda_12.1.r12.1/compiler.32415258_0
]]></description>
      <guid>https://stackoverflow.com/questions/78376600/cuda-setup-failed-despite-gpu-being-available</guid>
      <pubDate>Wed, 24 Apr 2024 07:18:58 GMT</pubDate>
    </item>
    <item>
      <title>合并两个不同的人工智能模型</title>
      <link>https://stackoverflow.com/questions/78376582/merging-two-different-ai-models</link>
      <description><![CDATA[我已经训练了两个模型，一个用于模糊检测，另一个用于两个不同数据集的曝光分类，现在我想合并这两个模型以获得执行这两项任务的单个组合模型
我希望组合模型通过将单个图像作为输入来预测模糊和曝光]]></description>
      <guid>https://stackoverflow.com/questions/78376582/merging-two-different-ai-models</guid>
      <pubDate>Wed, 24 Apr 2024 07:14:39 GMT</pubDate>
    </item>
    <item>
      <title>训练 DL 模型时，本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束</title>
      <link>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</link>
      <description><![CDATA[我正在创建一个植物病害识别模型。我有一个包含 38 种疾病的数据集，每种疾病有大约 2000 张图像。但是在训练模型时，由于一些 OUT_OF_RANGE 错误，一些时期被跳过。有人可以帮我解决这个问题吗？
导入操作系统
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、展平、密集、输入

train_dir = &#39;数据集/火车&#39;
valid_dir = &#39;数据集/有效&#39;
批量大小 = 32

train_datagen = 图像数据生成器(
    重新缩放=1./255，
    旋转范围=40，
    宽度偏移范围=0.2，
    height_shift_range=0.2，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真，
    fill_mode=&#39;最近&#39;
）

valid_datagen = ImageDataGenerator(重新缩放=1./255)

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

valid_generator = valid_datagen.flow_from_directory(
    有效目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

模型=顺序（[
    输入(形状=(150, 150, 3)),
    Conv2D(32, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    展平（），
    密集（512，激活=&#39;relu&#39;），
    Dense(38,activation=&#39;softmax&#39;) # 根据疾病类别的数量调整输出单位
]）

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=10，
    验证数据=有效生成器，
    valid_steps=valid_generator.samples // 批量大小
）

model.save(&#39;plant_disease_model.h5&#39;)

class_indices = train_generator.class_indices
疾病名称 = 列表(class_indices.keys())
print(“类索引到疾病名称的映射：”, class_indices)

终端：
找到属于 38 个类别的 70295 个图像。
找到属于 38 个类别的 17572 张图像。
2024-04-23 19：50：32.085744：我tensorflow / core / platform / cpu_feature_guard.cc：210]此TensorFlow二进制文件经过优化以使用可用的CPU仪器
性能关键操作中的操作。
要启用以下指令：AVX2 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
纪元 1/10
\.venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.p
y：120：用户警告：您的“PyDataset”类应在其构造函数中调用“super().__init__(**kwargs)”。 `**kwargs` 可以包括 `workers`、`use_m
ultiprocessing`、`max_queue_size`。不要将这些参数传递给“fit()”，因为它们将被忽略。
  self._warn_if_super_not_used()
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m905s←[0m 411ms/步]]准确度：0.4608 - 损失：1.8737 - val_accuracy：0.7432 - val_
损失：0.8556
纪元 2/10
←[1m 1/2196←[0m ←[37m–––––––––––––––––––←[0m ←[1m12:02←[0m 329ms/步 - 精度: 0.6875] -损失：0.78202024-04-23 20:05:37.996528：W张量
ow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束
         [[{{节点It​​eratorGetNext}}]]
C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py:155: UserWarning: 您的输入数据不足；中断训练。嘛
确保您的数据集或生成器至少可以生成“steps_per_epoch * epochs”批次。您可能需要使用`.repeat()`函数
构建您的数据集。
  self.gen.throw（类型，值，回溯）
2024-04-23 20:05:38.068817：W tensorflow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：结束
顺序
         [[{{节点It​​eratorGetNext}}]]
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m0s←[0m 49us/步]]准确度：0.6875 - 损失：0.7820 - val_accuracy：0.7500 - val_los
秒：0.2462

如上所示，epoch 1 已成功完成，但 epoch 2 由于某些错误而终止。同样，epoch 3、5、7、9 成功完成，但 epoch 4、6、8、10 出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</guid>
      <pubDate>Wed, 24 Apr 2024 06:27:20 GMT</pubDate>
    </item>
    <item>
      <title>优化问题的软件方法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78376279/software-approach-for-optimization-problem</link>
      <description><![CDATA[我陷入了优化问题，不知道从哪里着手。这些是问题的条件和整体背景：
我们有一组类型的产品，每种类型都有在生产线上执行的几个步骤。
生产线由7台机器组成
例如，产品可以通过步骤（或机器）编号 1、5 和 7
产品用货车运送到不同的机器上，总共有3辆货车。我根据一些推理确定了货车是这样划分的：货车 1 机器 1 到 5 都包括在内，货车 2 机器 2 到 4 都包括在内，货车 3 机器 5 到 7 都包括在内。货车不能碰撞，每台机器一次只能加工一种产品。机器 1 用于入口，只能通过货车 1 进入，机器 7（出口机器）只能通过货车 3 进入
我们的目标是优化生产，以便一年至少生产 70,000 件。我必须找到不同类型产品进入生产线的顺序（例如：A、D、E、K、 C ....) 使单位总数最大化
产品列表及其必须执行的顺序如下所示：

A 3 7 10
B 3 7 9 10
C 3 7 10
D 3 6 7 10
E 3 6 7 8 9 10
F 3 4 6 7 10
G 3 4 6 7 8 9 10
H 3 4 9 6 9 7 10
我3 4 6 7 10
J 3 4 6 7 8 9 10
K 3 4 6 7 8 9 10
L 3 5 9 6 7 4 5 9 6 9 7 10
中号3 5 9 6 7 4 5 9 6 9 7 10

我们有在每台机器上花费的时间。
我正在考虑是否使用某种优化，例如杰克逊定律，与优化相关的东西，或者遗传算法，甚至强化学习。你有什么看法？
我正在考虑是否使用某种优化，例如杰克逊定律，与优化相关的东西，或者遗传算法，甚至强化学习。你有什么看法？]]></description>
      <guid>https://stackoverflow.com/questions/78376279/software-approach-for-optimization-problem</guid>
      <pubDate>Wed, 24 Apr 2024 06:08:01 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 的 DDP 在扩散模型训练中的运行时错误</title>
      <link>https://stackoverflow.com/questions/78376085/runtime-error-with-pytorchs-ddp-in-the-diffusion-model-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78376085/runtime-error-with-pytorchs-ddp-in-the-diffusion-model-training</guid>
      <pubDate>Wed, 24 Apr 2024 05:05:11 GMT</pubDate>
    </item>
    <item>
      <title>无法过度拟合多项式回归？</title>
      <link>https://stackoverflow.com/questions/78374435/failing-to-overfit-polynomial-regression</link>
      <description><![CDATA[我正在尝试将多项式回归过拟合到正弦曲线。据我所知，当有 N 数据样本和多项式次数 N-1 时，曲线应该穿过所有数据点，但是，在我的例如这不会发生。
我的代码如下：
from sklearn. Linear_model 导入 LinearRegression
从 sklearn.preprocessing 导入多项式特征

数 = 50
度 = 49

X = X = np.linspace(0, 2 * np.pi, N).reshape(-1, 1)
X = np.sort(X, 轴=0)
y = np.sin(X) + np.random.randn(N, 1) * 0.2

poly_features = 多项式特征（度=deg，include_bias=False）

X_poly = poly_features.fit_transform(X)

reg = 线性回归()
reg.fit(X_poly, y)

y_vals = reg.predict(X_poly)

plt.scatter(X, y)
plt.plot(X, y_vals, color=&#39;r&#39;)
plt.show()


你能解释一下我在这里的误解吗？]]></description>
      <guid>https://stackoverflow.com/questions/78374435/failing-to-overfit-polynomial-regression</guid>
      <pubDate>Tue, 23 Apr 2024 18:44:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中制作人工智能驱动的自学习聊天机器人 [关闭]</title>
      <link>https://stackoverflow.com/questions/78370101/how-to-make-ai-powered-self-learning-chatbot-in-python</link>
      <description><![CDATA[我一直在尝试用 Python 制作一个自学习聊天机器人，并尝试了不同的库，如 NLTK、TensorFlow、ChatBot 和 PyTorch，但所有这些库都在处理预定义的训练数据。我找不到任何选项来根据给定的输入自行训练模型并尝试不同类型的数据集。
在Python中有什么方法可以实现这一点吗？
我可以看到我们可以使用已经训练好的模型并对其进行微调，或者使用 DialogFlow 和 Rasa 来建立对话模型。然而，我正在寻找一种方法，可以用我们自己的数据来训练它，并且它可以从给定的数据中自我学习。]]></description>
      <guid>https://stackoverflow.com/questions/78370101/how-to-make-ai-powered-self-learning-chatbot-in-python</guid>
      <pubDate>Tue, 23 Apr 2024 05:44:52 GMT</pubDate>
    </item>
    <item>
      <title>valueerror: 层“model_2”的输入 0 与该层不兼容：预期形状=(none, 128, 128, 3)，发现形状=(1, 224, 224, 3)</title>
      <link>https://stackoverflow.com/questions/78361052/valueerror-input-0-of-layer-model-2-is-incompatible-with-the-layer-expected</link>
      <description><![CDATA[我正在尝试使用 cnn 模型和 Streamlit UI 进行疟疾检测。但它显示“valueerror：层“model_2”的输入0”的错误与层不兼容：预期形状=(无, 128, 128, 3)，发现形状=(1, 224, 224, 3)”用于预测。
错误消息：
ValueError：层“model_2”的输入 0与图层不兼容：预期形状=(无, 128, 128, 3)，发现形状=(1, 224, 224, 3)

回溯：
文件“C:\Users\HP\.conda\envs\DiseasePredictionSystem\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py”，第 584 行，位于 _run_script
    exec（代码，模块.__dict__）
文件“C:\Users\HP\Desktop\多种疾病预测系统\多种疾病pred.py”，第361行，在&lt;模块&gt;中。
    结果 = malaria_model.predict(final_image)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\HP\.conda\envs\DiseasePredictionSystem\Lib\site-packages\keras\src\utils\traceback_utils.py”，第 122 行，位于 error_handler 中
    从 None 引发 e.with_traceback(filtered_tb)
文件“C:\Users\HP\.conda\envs\DiseasePredictionSystem\Lib\site-packages\keras\src\layers\input_spec.py”，第 245 行，位于assert_input_compatibility 中
    引发值错误（

这是我与 CNN 模型交互的 UI：

这是我用于该项目的 UI 文件。
malaria_model = tf.keras.models.load_model(r&#39;C:\Users\HP\Desktop\多种疾病预测系统\保存的模型\malaria.h5&#39;)
#疟疾预测页面
如果选择==“疟疾疾病预测”：

     ＃页面标题
     st.title(&#39;使用机器学习预测疟疾&#39;)
     
     IMG_大小 = 224
     def resize_rescale(图像):
          返回 tf.image.resize(图像, (IMG_SIZE, IMG_SIZE))/255.0

     uploaded_image = st.file_uploader(&quot;上传图片&quot;, type=[&quot;jpg&quot;, &quot;png&quot;, &quot;jpeg&quot;])

     如果 uploaded_image 不是 None：
    # 显示上传的图片
         st.image（uploaded_image，caption =“上传的图像”，use_column_width = False）
         图像 = Image.open(上传的图像)
    
    # 处理图像（例如，执行图像分析）

     if st.button(“PREDICT”)：
         image_array = tf.keras.preprocessing.image.img_to_array(图像)

    # 将 NumPy 数组转换为 TensorFlow 张量
         张量图像 = tf.convert_to_tensor(image_array)
         张量图像 = tf.expand_dims(张量图像，轴=0)
    
         最终图像=调整大小重新缩放（张量图像）

         结果 = malaria_model.predict(final_image)

         如果结果[0][0] &lt; 0.5：
            st.header(“寄生虫”)
         别的：
            st.header(“未感染”)

这是我用于该项目的参考代码文件：https://github.com/kanchitank/Medibuddy-Smart-Disease-Predictor/blob/main/notebooks/malaria.ipynb]]></description>
      <guid>https://stackoverflow.com/questions/78361052/valueerror-input-0-of-layer-model-2-is-incompatible-with-the-layer-expected</guid>
      <pubDate>Sun, 21 Apr 2024 09:40:42 GMT</pubDate>
    </item>
    <item>
      <title>通过 Keras 训练同时检查不同类型的数据</title>
      <link>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</link>
      <description><![CDATA[在回归任务中，我得到以下数据：

具有已知标签的输入向量。 MSE损失应该用在预测和标签之间。
没有标签的输入向量对，已知模型应给出相似的结果。应在两个预测之间使用 MSE 损失。

同时将这两种数据拟合 Keras 模型的正确方法是什么？
理想情况下，我希望火车循环以交错的方式迭代这两种类型 - 一个有监督的（1）批次，然后是一个自我监督的（2）批次，然后再次监督，等等。
如果重要的话，我正在使用 Jax 后端。 Keras 版本 3.2.1。]]></description>
      <guid>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</guid>
      <pubDate>Thu, 18 Apr 2024 16:05:11 GMT</pubDate>
    </item>
    <item>
      <title>用于多标签分类的 CLIP</title>
      <link>https://stackoverflow.com/questions/74927358/clip-for-multi-label-classification</link>
      <description><![CDATA[我正在使用 CLIP 来确定单词和图像之间的相似性。
现在我正在使用这个 repo 和以下代码，对于分类它给出了很好的结果。我需要它来进行多标签分类，其中我需要使用 sigmoid 而不是 softmax。
导入火炬
从 PIL 导入图像
导入 open_clip

模型, _, 预处理 = open_clip.create_model_and_transforms(&#39;ViT-B-32-quickgelu&#39;, pretrained=&#39;laion400m_e32&#39;)
tokenizer = open_clip.get_tokenizer(&#39;ViT-B-32-quickgelu&#39;)

图像 = 预处理(Image.open(&quot;CLIP.png&quot;)).unsqueeze(0)
text = tokenizer([“图表”, “一只狗”, “一只猫”])

与 torch.no_grad(), torch.cuda.amp.autocast():
    image_features = model.encode_image(图像)
    text_features = model.encode_text(text)
    image_features /= image_features.norm(dim=-1, keepdim=True)
    text_features /= text_features.norm(dim=-1, keepdim=True)

    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)

print(“标签概率：”, text_probs) # 打印：[[1., 0., 0.]]

现在我想将它用于多类别。例如，如果我们有图像狗和猫，我希望两者都有很高的概率，所以我需要用 sigmoid 运行它。但这给我的结果都是 0.55 左右，正确的类别是 0.56，错误的类别是 0.54，所以像这样的 [0.54, 0.555, 0.56]。我希望在使用 sigmoid 后得到类似 [0.01, 0.98, 0.99] 的结果。
我在那里做错了什么？我怎样才能得到我想要的结果？]]></description>
      <guid>https://stackoverflow.com/questions/74927358/clip-for-multi-label-classification</guid>
      <pubDate>Tue, 27 Dec 2022 08:56:22 GMT</pubDate>
    </item>
    <item>
      <title>迭代重新加权最小二乘法</title>
      <link>https://stackoverflow.com/questions/62116804/iterative-reweighted-least-squares</link>
      <description><![CDATA[我正在尝试手动实现irls逻辑回归（Bishop - 模式识别和机器学习）。 
为了更新权重，我使用 
然而，我没有得到令人满意的结果，而且我的权重在每次迭代中都无限增长。
到目前为止我已经编写了这段代码：
def y(X, w):
    返回 sigmoid(X.dot(w))

定义 R(y)：
    R = np.identity(y.size)
    R = R*(y*(1-y))
    返回R

def irls(X, t):
    w = np.ones(X.shape[1])
    w = w.reshape(w.size, 1)
    t = np.array(list(map(lambda x: 1 if x else 0, t)))
    t = t.reshape(t.size, 1)

    #3次迭代后矩阵是奇异的
    对于范围 (3) 内的 i：
        y_ = y(X,w)
        w = w - np.linalg.inv(X.T.dot(R(y_)).dot(X)).dot((X.T).dot(y_-t))
    返回w

其中 X 是我的设计矩阵（64 个特征和 74 个样本），t 是由布尔值组成的目标向量（数据来自 https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression)。
感谢任何帮助指出我出错的地方。]]></description>
      <guid>https://stackoverflow.com/questions/62116804/iterative-reweighted-least-squares</guid>
      <pubDate>Sun, 31 May 2020 13:15:36 GMT</pubDate>
    </item>
    <item>
      <title>最大似然估计伪代码</title>
      <link>https://stackoverflow.com/questions/7718034/maximum-likelihood-estimate-pseudocode</link>
      <description><![CDATA[我需要编写一个最大似然估计器来估计一些玩具数据的均值和方差。我有一个包含 100 个样本的向量，是使用 numpy.random.randn(100) 创建的。数据应具有零均值和单位方差高斯分布。
我检查了维基百科和一些额外的资源，但我有点困惑，因为我没有统计背景。
是否有最大似然估计器的伪代码？我得到了 MLE 的直觉，但我不知道从哪里开始编码。
Wiki 表示采用对数似然的 argmax。我的理解是：我需要使用不同的参数来计算对数似然，然后我将采用给出最大概率的参数。我不明白的是：我首先在哪里可以找到参数？如果我随机尝试不同的平均值 &amp;方差以获得高概率，我什么时候应该停止尝试？]]></description>
      <guid>https://stackoverflow.com/questions/7718034/maximum-likelihood-estimate-pseudocode</guid>
      <pubDate>Mon, 10 Oct 2011 20:05:45 GMT</pubDate>
    </item>
    </channel>
</rss>