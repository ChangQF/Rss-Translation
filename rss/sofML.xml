<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Fri, 14 Feb 2025 03:22:59 GMT</lastBuildDate>
    <item>
      <title>TensorFlow的性能问题</title>
      <link>https://stackoverflow.com/questions/79437180/tensorflow-perfomance-issue</link>
      <description><![CDATA[我正在尝试在TensorFlow上进行非常原始的增强学习模型。尽管它相对较小，但单个迭代需要约6-7秒。
  def build_model（）：
    模型= keras。
        层。输入（shape =（400，）），
        layers.dense（128，激活=; relu; quot;），，
        layers.dense（128，激活=; relu; quot;），，
        层。密度（3）
    ）））
    model.compile（优化器= keras.optimizers.adam（Learning_rate = 0.001），Loss =＆quot; quot;
    返回模型

dqnagent类：
    def __init __（自我）：
        self.model = build_model（）
        self.target_model = build_model（）
        self.target_model.set_weights（self.model.get_weights（））

        self.memory = Deque（Maxlen = 1000）
        self.epsilon = 1.0
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.gamma = 0.95
        self.batch_size = 32

    def select_action（self，state）：
        如果np.random.rand（）＆lt; self.epsilon：
            返回随机选择（[0，1，2]）
        q_values = self.model.model.predict（np.array（[state]），详细= 0）
        返回np.argmax（q_values [0]）

    def记住（自我，状态，行动，奖励，next_state，完成）：
        self.memory.append（（（状态，行动，奖励，next_state，Done完成）））

    def火车（自我）：
        如果Len（self.memory）＆lt; self.batch_size：
            返回
        batch =随机。样本（self.memory，self.batch_size）
        状态，目标= []，[]

        对于状态，行动，奖励，next_state，在批处理中完成：
            目标=奖励
            如果没有完成：
                target += self.gamma * np.max（self.target_model.predict（np.array（[[next_state]）），verbose = 0））

            q_values = self.model.model.predict（np.array（[state]），详细= 0）
            q_values [0] [action] =目标

            states.append（状态）
            targets.append（q_values [0]）

        self.model.fit（np.Array（states），np.Array（targets），Epochs = 1，冗长= 0）

        如果self.epsilon＆gt; self.epsilon_min：
            self.epsilon *= self.epsilon_decay

    def Update_target_model（self）：
        self.target_model.set_weights（self.model.get_weights（））
 
分析了所有给定代码后，我看到 model.predict（）花费了很多时间来完成：
 profiler result   
最初，我以为我只需要在GPU上计算，但是两天后尝试这样做，没有真正改变。
真的花了很多时间，还是我在代码中搞砸了？
  gpu：geforce 2060，
CPU：Intel Core i7， 
Windows 11，
Python：3.10
TensorFlow：2.10
 ]]></description>
      <guid>https://stackoverflow.com/questions/79437180/tensorflow-perfomance-issue</guid>
      <pubDate>Thu, 13 Feb 2025 17:07:09 GMT</pubDate>
    </item>
    <item>
      <title>Tweedie回归：功率> = 2'“ Y的某些值超出了损失的有效范围”，但Y值不是</title>
      <link>https://stackoverflow.com/questions/79437039/tweedie-regression-power-2-some-values-of-y-are-out-of-the-valid-range-o</link>
      <description><![CDATA[我正在运行Tweedie回归，对于Powers＆gt; = 2，我遇到了一个错误，告诉我我的y值超出了半weedeieloss的范围。我了解Y损失的有效范围为0。  我所有的y值都是＆gt; 0 and＆lt; 1，但我仍然会遇到这个错误。我不知道为什么。
 Sklearn版本1.3.0 
 i消除了所有行，并用y＆lt; = 0的值和double检查了一个描述。我期望回归器合适，并给我一个更好的理由，尤其是因为我的y值都大于0。我知道伽玛不是我的数据的出色分配，但我希望尝试尝试power = 3（逆高斯），这也是不可能的。
 power = 0和1都可以正常工作（正常和泊松）。
这是我培训y数据的描述（ cv_y ）：
 计数|   616420.000000  
平均|        0.955883  
std |        0.021402  
最小|        0.700465  
25％|        0.937018  
50％|        0.954769  
75％|        0.975716  
最大|        0.990000  
 
这是我的代码的重要元素
  glr = tweedieregressor（）＃广义线性回归模型
x_pipeline = pipeline（[（（＆quot; preprocessor&#39;&#39;，x_transformer），（&#39;Model; quode; glr）]）
esteNator = transformedTargetRegressor（recressor = x_pipeline，变压器= y_transformer）
家庭=“ Tweedie”
链接=“自动”
n_splits = 5
tscv = timeseriessplit（gap = 20，n_splits = n_splits）

param_grid = {
        &#39;recressor__preprocessor__x_pca__whiten&#39;：[true，false]，
        “回归器__model__power”：[0,1,2]，，
        &#39;Recressor__model__alpha&#39;：[0.5]，，，
        &#39;recressor__model__fit_intercept&#39;：[true]，
        “回归器__model__link”：[link]，，，
        &#39;Recressor__model__solver&#39;：[&#39;Newton-Cholesky&#39;]，
        &#39;Recressor__model__max_iter&#39;：[5,10]，，
        &#39;Recressor__model__tol&#39;：[1E-5]，，
        “回归器__model__verbose”：[1]
}

GS = GridSearchCV（
            估算器=估算器，
            param_grid = param_grid，
            得分=得分，
            n_jobs = -1，
            refit = refit_strategy，
            CV = TSCV，
            详细= 3，
            pre_dispatch = 10，
            ERROR_SCORE =&#39;RAIND&#39;
）

型号= gs.fit（cv_x，cv_y）



 ]]></description>
      <guid>https://stackoverflow.com/questions/79437039/tweedie-regression-power-2-some-values-of-y-are-out-of-the-valid-range-o</guid>
      <pubDate>Thu, 13 Feb 2025 16:29:26 GMT</pubDate>
    </item>
    <item>
      <title>保存到磁盘中的磁盘时会遇到Unicode错误</title>
      <link>https://stackoverflow.com/questions/79436672/getting-unicode-error-while-saving-to-disk-in-distiset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79436672/getting-unicode-error-while-saving-to-disk-in-distiset</guid>
      <pubDate>Thu, 13 Feb 2025 15:04:10 GMT</pubDate>
    </item>
    <item>
      <title>Yolov9e-Seg在6 A100-80G上进行培训，并试图尽可能优化，但是在验证阶段之后，CUDA出现了失误错误</title>
      <link>https://stackoverflow.com/questions/79436107/yolov9e-seg-training-on-6-a100-80g-and-tried-to-optimize-as-much-as-i-could-but</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79436107/yolov9e-seg-training-on-6-a100-80g-and-tried-to-optimize-as-much-as-i-could-but</guid>
      <pubDate>Thu, 13 Feb 2025 12:12:17 GMT</pubDate>
    </item>
    <item>
      <title>ValueRror：X具有7个功能，但ColumnTransFormer期望13个功能</title>
      <link>https://stackoverflow.com/questions/79434756/valueerror-x-has-7-features-but-columntransformer-expects-13-features</link>
      <description><![CDATA[我有以下代码，我尝试预测使用泊松回归的工具价格。
 ＃---加载并准备数据---
y =火车[&#39;priceToday&#39;]
x = train.drop（columns = [&#39;pricetoday&#39;]）

＃定义非标准类型
non_standard_types = [&#39;nar;

＃为非标准创建标志功能
x [&#39;non_standard_flag;]

＃确定数值和分类列
num_features = [&#39;age&#39;&#39;&#39;
cat_features = [&#39;country; country; quot&#39;final_trans;]

＃定义预处理管道
预处理器= columntransformer（
    变形金刚= [
        （&#39;num&#39;，StandardScaler（），num_features），
        （&#39;cat&#39;，onehotencoder（handle_unknown =&#39;ignore&#39;），cat_features）
    ]，剩余=; drop; quot;
）

＃---火车/测试拆分---
＃创建一个重量列
train [sample_weight; quight&#39;&#39;] = train [type; type_ls; quot;]。应用（lambda x：1如果x == x ==;

火车[stratify_group&#39;&#39;]
x_train，x_val，y_train，y_val，train_weights，val_weights = train_test_split（
    x，y，train [sample_weight&#39;]，test_size = 0.2，andural_state = 42，stratefify = train [＆quot; stratify_group＆quort＆quort;
）
＃将预处理器安装在培训数据上一次
x_train_preprocessed = preprocessor.fit_transform（x_train）
x_val_preprocessed = preprocessor.transform（x_val）

＃定义模型
模型= {
    ＆quot“ poisson”：poissonRegressor（alpha = 0.01）
}

＃火车和评估模型
model_results = {}

对于model_name，model.items（）中的型号：
    model.fit（x_train_preprocessed，y_train，sample_weight = train_weights）

    ＃预测
    预测= model.predict（x_val_preprocessed）
    ＃计算指标
    r2 = r2_score（y_val，预测）

    model_results [model_name] = {
        “型号”：模型，
        ＆quot“ R2”：R2
    }
 
我有一个测试数据，我想将其价格与模型的预测价格进行比较。
我的测试数据是这样的：
 ＃确保新数据具有正确的格式
new_data = pd.dataframe（{{
    ＆quot;：：[12，24，36，48，60，72，84，12，24，36，48，60，60，72，84]，
    ＆quot”小时：[500，1000，1500，2000，2500，3000，3500，3500，500，1000，1500，2000，2500，2500，3000，3500]，
    ＆quot“ brand;
    ＆quot&#39;power＆quot; [150] * 7 + [80] * 7，
    ＆quot“ final_trans＆quot”：[＆quot; cv; quot&#39;] * 14，，
    ＆quot“ country”：[deu＆quot;] * 14，，
    &#39;type_ls＆quot;：[NAR，NAR，NAR，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST，ST] 
    ＆quot&#39;current_pred＆quot;：[105614，96681，88504，81018，74165，67892，62150，42608，39728，37043，37043，34540，32206，32206，30029，28000]
}））
 
我的代码是：
  new_df = pd.dataframe（new_data）
＃创建&#39;non_standard_flag&#39;
new_df [&#39;non_standard_flag;] = new_df [type; type_ls; quot;]。isin（non_standard_types）.astype（int）

＃选择预处理器所需的列
x_new = new_df [[&#39;age&#39;，&#39;power&#39;，&#39;小时&#39;，&#39;non_standard_flag&#39;，&#39;brand&#39;，&#39;country&#39;，&#39;final_trans&#39;]]]

x_new_preprocessed = preprocessor.transform（x_new） 

＃从培训数据中进行单次编码后获取列名
ohe = preprocessor.named_transformers _ [&#39;cat&#39;]
encoded_cat_columns = ohe.get_feature_names_out（cat_features）

＃创建数字功能的列名称
num_columns = num_features

＃组合列名称
all_columns = num_columns + list（encoded_cat_columns）

＃从预处理数据中创建数据框
x_new_preprocessed_df = pd.dataframe（x_new_preprocessed，columns = all_columns）

＃---用泊松模型预测---
poisson_model = model_results [＆quot; poisson; quot; quote; quode;]＃访问训练有素的泊松模型
predicted_prices = poisson_model.predict（x_new_preprocessed_df）

＃比较和存储结果---
new_df [&#39;prediction_price&#39;] = predicted_prices

＃计算预测和当前价格之间的差异
new_df [&#39;Price_difference&#39;] = new_df [&#39;Predicted_price&#39;]  -  new_df [&#39;current_pred&#39;]
 
但是，在这样做之后，我会出现错误：
  X具有7个功能，但是ColumnTransFormer期望13个功能
 
我有相同数量的列，所以我不明白为什么我有这个错误。]]></description>
      <guid>https://stackoverflow.com/questions/79434756/valueerror-x-has-7-features-but-columntransformer-expects-13-features</guid>
      <pubDate>Wed, 12 Feb 2025 23:51:03 GMT</pubDate>
    </item>
    <item>
      <title>如何使用嵌入式和余弦相似性改善Excel文件中的列标题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79433790/how-to-improve-column-header-matching-in-excel-files-using-embeddings-and-cosine</link>
      <description><![CDATA[我正在构建一个工具，该工具处理用户上传的Excel文件。这些文件可以具有各种列标题，我的目标是将这些标题映射到预定义的输出列集。例如：
输出列是固定的：名字，姓氏，年龄，性别，城市，地址等
输入Excel标头可能会有所不同。例如，输出中的名字可以表示为员工名字，f_name或输入文件中的名字。
如果该工具找不到列的匹配（例如，不存在名称等效的匹配），则应使用null填充输出列。
尝试的方法
我使用了一种基于嵌入的方法：

  i使用模型（例如，来自OpenAI或其他NLP模型的Text-Embedding-ADA-002）为输入列标题生成嵌入式。

  i计算这些嵌入之间的余弦相似性和预定义的输出列名称的嵌入。

 我根据相似性得分确定匹配。


问题面临
虽然这在某种程度上有效，但余弦的相似性得分通常是不可靠的：

对于名称（输出列）：

与员工的相似性= 0.90（预期）。
与依赖的名字= 0.92（意外且不正确）的相似性。

对于名字和无关列：

与年龄的相似性= 0.70，对于无关术语而言太高。
这个问题使得很难区分相关和无关的匹配。例如：
年龄和名字不应被认为相似，但相似性仍然很高。
员工的名字和依赖的名字应该具有不同的分数以偏爱正确的匹配。
要求
我需要一个解决方案，以确保列的准确映射，考虑到这些点：

 相似的列名称（例如，名字和员工名字）应具有很高的相似性分数。

 无关的列名称（例如，名称和年龄）的相似度得分低。

 该解决方案应处理列名称的变化，例如同义词（性别↔性）或缩写（DOB↔出生日期）。


问题

 为什么无关列对的余弦相似性得分如此之高（例如，名字↔年龄）？

 在这种情况下如何提高列匹配的准确性？


尝试的潜在解决方案

 手动创建一个用于常见变体的映射字典，但这是不可扩展的。

 实验余弦相似性的阈值值，但仍然不一致。


我要寻找的东西

 替代方法（例如，对嵌入模型进行微调或使用域特异性模型）。

 任何专门为匹配列名称设计的预训练模型或库。

 建议将基于规则的方法与嵌入以提高准确性的建议。

]]></description>
      <guid>https://stackoverflow.com/questions/79433790/how-to-improve-column-header-matching-in-excel-files-using-embeddings-and-cosine</guid>
      <pubDate>Wed, 12 Feb 2025 16:28:05 GMT</pubDate>
    </item>
    <item>
      <title>如何使用DART提取MFCC功能[封闭]</title>
      <link>https://stackoverflow.com/questions/79433652/how-to-extract-mfcc-features-using-dart</link>
      <description><![CDATA[我正在研究一个试图识别使用机器学习模型的说话者的颤音应用程序，该应用程序将在离线上使用，输入是5秒钟的MFCC功能的数组，并且输出是名称扬声器的大小和数组的大小为13，是否有任何方法可以使用DART提取这些功能。]]></description>
      <guid>https://stackoverflow.com/questions/79433652/how-to-extract-mfcc-features-using-dart</guid>
      <pubDate>Wed, 12 Feb 2025 15:40:32 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM力量变量要分裂</title>
      <link>https://stackoverflow.com/questions/79433458/lightgbm-force-variables-to-be-in-splits</link>
      <description><![CDATA[我试图找到一种训练LightGBM模型的方法，强迫将某些功能分为分割，即：＆quot“处于重要性重要性”，那么这些变量的预测都会受到这些变量的影响。 
这是一个恒定变量的建模代码的示例，但其想法是，从业务角度来看可能存在一个重要的变量，而不是在功能中
 来自LightGBM Import LGBMRegressor
导入大熊猫作为pd
导入numpy作为NP
从sklearn.datasets导入make_regression
来自sklearn.model_selection导入train_test_split
来自sklearn.metrics导入均值_squared_error

＃通用联合国数据集DeRegresiónAleatorio
x，y = make_regression（n_samples = 1000，n_features = 10，噪声= 0.9，Random_State = 42）
feature_names = [f＆quot; feature_ {i}＆quot;对于我的范围（X.Shape [1]）]

＃constir a dataframe para市长legibilidad
x = pd.dataframe（x，columns = feature_names）

＃cysgarcaracterísticasInútiles
x [＆quot; useless_feature_1&#39;] = 1

＃dividir los datos en conjuntos de intrenamiento y prueba
x_train，x_test，y_train，y_test = train_test_split（x，y，test_size = 0.2，andural_state = 42）

＃Definir El Modelo LGBMregressor
型号= lgbMregressor（
    客观=“回归”
    公制=“ rmse”
    Random_State = 1，
    n_estimators = 100
）

＃Entrenar El Modelo
model.fit（x_train，y_train，eval_set = [（x_test，y_test）]）

＃predicciones y评估
y_pred = model.predict（x_test）
rmse = np.sqrt（mean_squared_error（y_test，y_pred））
打印（f＆quot test rmse：{rmse：.4f}＆quot;）

＃umputancia decaracterísticas
重要性= pd.dataframe（{{
    “特征”：X.Columns，
    “重要＆quot”：model.feature_importances_
}）。sort_values（by =&#39;

打印（“ \ nfeature重要性：”）
打印（重要）
 
预期的解决方案：应该有一些工具设备，但是最有趣的是在拟合或回归方法中使用一些参数的解决方案。。]]></description>
      <guid>https://stackoverflow.com/questions/79433458/lightgbm-force-variables-to-be-in-splits</guid>
      <pubDate>Wed, 12 Feb 2025 14:36:26 GMT</pubDate>
    </item>
    <item>
      <title>来自视频的实时对象跟踪模型[关闭]</title>
      <link>https://stackoverflow.com/questions/79433270/real-time-object-tracking-model-from-videos</link>
      <description><![CDATA[我需要开发一个可以实时准确跟踪对象的机器学习模型。这是我的想法：

数据收集：我计划在网上摘录大约10个视频，这些视频清楚地显示了从一个地方移动到另一个地方的对象。
目的：使用这些视频，我的目标是构建和训练一个可以实时遵循这些对象并准确指出其位置的模型

我正在寻找以下建议：

如何最好地选择和预处理此类视频进行培训。
您发现哪种算法或框架对实时对象跟踪有效？
有关处理潜在挑战等潜在挑战（例如闭塞或不同对象速度）的任何技巧。
]]></description>
      <guid>https://stackoverflow.com/questions/79433270/real-time-object-tracking-model-from-videos</guid>
      <pubDate>Wed, 12 Feb 2025 13:38:28 GMT</pubDate>
    </item>
    <item>
      <title>从简历中的R平方比XGBoost中的CV高[关闭]</title>
      <link>https://stackoverflow.com/questions/79320673/r-squared-from-cv-is-way-higher-than-without-cv-in-xgboost</link>
      <description><![CDATA[我有XGBoost模型的此代码：
  temp_dataset_pos = dataset_vehicle_pos.copy（）
＃temp_dataset_pos = temp_dataset_pos.drop（[&#39;sum_passenger&#39;]，axis = 1）
＃temp_dataset_pos = temp_dataset_pos [[&#39;湿度&#39;，&#39;温度&#39;，&#39;warter_avg_speed_pos&#39;]]]

x_pos = temp_dataset_pos.drop（&#39;warter_avg_speed_pos&#39;，axis = 1）
y_pos = temp_dataset_pos [&#39;warter_avg_speed_pos&#39;]

＃将数据分为火车和测试集
x_train，x_test，y_train，y_test = train_test_split（x_pos，y_pos，test_size = 0.20，andury_state = 42）

＃创建XGBoost模型
xgboost_model = xgb.xgbregressor（objective =&#39;reg：squaredError&#39;，andury_state = 42）＃您可以调整HyperParameters

＃适合模型
xgboost_model.fit（x_train，y_train）
＃确保预测的数据与测试集对齐
x_test [&#39;warter_count_pos&#39;] = prediction_vehicle_count_pos [&#39;predicted_vehicle_count_pos&#39;]

＃对测试集进行预测
y_pred_xgboost = xgboost_model.predict（x_test）

＃将预测的值舍入整数
y_pred_rounded = y_pred_xgboost.Round（）。astype（int）

＃评估模型
mse_xgboost = mean_squared_error（y_test，y_pred_rounded）
打印（f&#39;mean Squared错误（XGBOOST）：{MSE_XGBOOST}&#39;）
r2_xgboost = r2_score（y_test，y_pred_rounded）
打印（&#39;r平方值：&#39;，r2_xgboost）
重要性= xgboost_model.feature_importances_


＃创建XGBoost模型
xgboost_model = xgb.xgbregressor（objective =&#39;reg：squaredError&#39;，andury_state = 42）＃您可以调整HyperParameters

＃定义k折的交叉验证器
kf = kfold（n_splits = 5，shuffle = true，andury_state = 42）

＃根据平方误差定义得分手
mse_scorer = make_scorer（mean_squared_error，greate_is_better = false）

＃执行交叉验证并计算MSE
mse_scores = cross_val_score（xgboost_model，x_pos，y_pos，评分= mse_scorer，cv = kf）

＃将MSE分数转换为正； cross_val_score返回&#39;greate_is_better = false的负值&#39;
MSE_SCORES = -MSE_SCORES

＃计算MSE的平均值和标准偏差
MANE_MSE = np.Mean（MSE_SCORES）
std_mse = NP.STD（MSE_SCORES）

print（f&#39;mean MSE来自CV：{mean_mse}&#39;）
print（cv：{std_mse} \ n&#39;）

＃如果您还想在结果摘要中包含R平方
r2_scorer =&#39;r2&#39;
r2_scores = cross_val_score（xgboost_model，x_pos，y_pos，评分= r2_scorer，cv = kf）

平均_r2 = np.mean（r2_scores）
std_r2 = np.std（r2_scores）

print（f&#39;mean r平方从CV：{mean_r2}&#39;）
print（f&#39;std r平方从cv：{std_r2}&#39;）
打印（&#39;\ n&#39;）
 
我得到了这些结果：
平均误差（XGBoost）：395.3362869635255 
 R平方值：0.37072522417952525  
 CV的平均MSE：6.902625450153782 
CV的STD MSE：0.8885273860917627 
平均R平方从CV：0.990070278719086 &lt; /strong&gt; 
CV的STD R平方：0.000623638887270274 
 R平方如何在有或没有简历的情况下如此不同？
我是否缺少代码中的东西？]]></description>
      <guid>https://stackoverflow.com/questions/79320673/r-squared-from-cv-is-way-higher-than-without-cv-in-xgboost</guid>
      <pubDate>Tue, 31 Dec 2024 19:21:35 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost/ LightGBM中多级分类中的自定义标签</title>
      <link>https://stackoverflow.com/questions/79309001/custom-labelling-in-multi-class-classification-in-xgboost-lightgbm</link>
      <description><![CDATA[我有以下数据框1,2,3,4在不同类别（ class_id ），我想使用这些功能来预测谁将毕业他们的同类顶部（ top ）&lt; /p&gt;
  class_id iq_1 IQ_2 IQ_3 IQ_3 IQ_4小时_1小时_2小时_3小时_4 score_1 score_2 score_3 score_4 pot_4
1 101 99 130 100 10 19 3 12 98 80 95 88 3     
2 93 103 112 200 5 9 12 10 50 88 99 100 1
3 100 102 101 102 12 13 17 9 84 88 89 98 4
 
为此，我使用XGBoost库中的多类分类（其中类是 1,2,3,4 ）。但是，由于该人最终在课堂上排名第二，但是在训练中，他/她无论如何都会获得0，因此更好的训练计划是奖励最高得分的顶级人士，而第二个人则是得分像底部的人一样给它0。因此，我想在XGBoost中问，无论如何是否可以进行自定义标签，例如：
  class_id iq_1 IQ_2 IQ_3 IQ_3 IQ_4小时_1小时_2小时_3小时_4 score_1 score_2 score_2 score_3 scust_4 Student_1 Student_2 Student_3 Student_3 Student_4
1 101 99 130 100 10 19 3 12 98 80 95 88 0 0.3 0.7 0 0
2 93 103 112 200 5 9 12 10 50 88 99 100 0.7 0 0.3 0
3 100 102 101 102 12 13 17 9 84 88 89 98 0 0.3 0 0.7
 
即。我们奖励班级0.7的顶部和第0.3类（ [0，0.3，0.7，0] 的第二类，而不是 [0,0,1， 0] 在原始标签中？）
如果Xgboost没有这种自定义标签，我们可以在类似的包装中这样做吗？？]]></description>
      <guid>https://stackoverflow.com/questions/79309001/custom-labelling-in-multi-class-classification-in-xgboost-lightgbm</guid>
      <pubDate>Thu, 26 Dec 2024 08:18:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用ML模型和FastAPI处理多次用户的请求？</title>
      <link>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</link>
      <description><![CDATA[我正在研究通过Fastapi分发人工智能模块的过程。
我创建了一个FastApi应用，该应用使用预学的机器学习模型回答问题。
在这种情况下，使用它不是问题，但是当多个用户同时使用它时，响应可能太慢了。
因此，当多个用户输入问题时，是否有任何方法复制模型并立即加载？
  class senterbert_ai（）：
    def __init __（self） - ＆gt;没有任何：
        super（）.__ init __（）

 def ask_query（self，Query，topn）：
        startt = time.time（）

        ask_result = []
        得分= []
        result_value = []  
        嵌入式= torch.load（model_path）
        colpus_embeddings = embedder.encode（colpus，convert_to_tensor = true）
        query_embedding = embedder.encode（query，convert_to_tensor = true）
        cos_scores = util.pytorch_cos_sim（query_embedding，colpus_embeddings）[0]＃torch.size（[121]）121개의개의대한유사도。
        cos_scores = cos_scores.cpu（）

        top_results = np.argpartition（-cos_scores，range（topn））[0：topn]

        对于top_results [0：topn]中的IDX：        
            ask_result.append（colpusid [idx] .Item（））
            ＃.Item（）으로이유는tensor（5）에서에서접근하기위한방식이다。
            Score.Append（round（cos_scores [idx] .Item（），3））

        ＃서버에json阵列형태로형태로내보내기위한위한
        对于我，e在zip中（ask_result，得分）：
            result_value.append（{{;
        endd = time.time（）
        print（&#39;시간체크&#39;，端启动）
        返回结果_VALUE
        。



class item_inference（basemodel）：
    文字：str
    TOPN：可选[int] = 1

@app.post（“/reterieval＆quot”，tags = [＆quot;知识建议＆quot;]）
异步def知识_recommendation（item：item_inference）：
  
    ＃db.append（item.dict（））
    item.dict（）
    结果= _ai.ask_query（item.Text，item.topn）

    返回结果


如果__name__ ==＆quot __ Main __＆quot;：
    Parser = argparse.argumentparser（）
    parser.add_argument（＆quot;  -  port; default =&#39;9003&#39;，type = int）
    ＃parser.add_argument（;＆quot; mode＆quot＆quort＆quort＆quort =&#39;cpu&#39;，type = str，help，help =&#39;cpu for CPU模式，GPU for GPU模式&#39;）
    args = parser.parse_args（）

    _ai = stonebert_ai（）
    uvicorn.run（app，host =; 0.0.0.0＆quort; port = args.port，工人= 4）
 
更正版本
 @app.post（;＆quort;/aaa;;;;;;;;;;;;;;&#39;&#39;your_endpoint（请求：请求：request，item：item_inference）：start = time.time.time.time（）型号= request。 app.state.model item.dict（）＃커널커널_ai = stonbert_ai（）结果= _ai.ask_query（item.text，item.topn，model）end end = time.time.time.time.time（time（end-end oft）结果````&#39;&#39; 
 ]]></description>
      <guid>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</guid>
      <pubDate>Fri, 25 Mar 2022 07:13:32 GMT</pubDate>
    </item>
    <item>
      <title>pytorch runtimeerror：cuda不记忆，有大量的自由记忆</title>
      <link>https://stackoverflow.com/questions/71498324/pytorch-runtimeerror-cuda-out-of-memory-with-a-huge-amount-of-free-memory</link>
      <description><![CDATA[在训练模型时，我遇到了以下问题：
  RuntimeError：CUDA不记忆。试图分配304.00 MIB（GPU 0; 8.00 GIB总容量； 142.76 MIB已分配； 6.32 Gib;如果保留存储器为GT;＆GT;＆gt;＆gt;分配的内存尝试设置max_split_size_mb以避免碎片。  请参阅存储器管理文档，Pytorch_cuda_alloc_conf  
正如我们所看到的，试图分配304个MIB内存时发生错误，而6.32 GIB是免费的！问题是什么？如我所见，建议的选项是设置 max_split_size_mb 避免碎片。它会有所帮助以及如何正确执行吗？
这是我的Pytorch版本：
  TORCH == 1.10.2+CU113     
Torchvision == 0.11.3+CU113     
Torchaudio === 0.10.2+CU113
 ]]></description>
      <guid>https://stackoverflow.com/questions/71498324/pytorch-runtimeerror-cuda-out-of-memory-with-a-huge-amount-of-free-memory</guid>
      <pubDate>Wed, 16 Mar 2022 13:53:45 GMT</pubDate>
    </item>
    <item>
      <title>Adam Optimizer with pytorch上的热身</title>
      <link>https://stackoverflow.com/questions/65343377/adam-optimizer-with-warmup-on-pytorch</link>
      <description><![CDATA[在论文中
    
我们如何在pytorch中使用 adam  ？最好没有其他软件包。]]></description>
      <guid>https://stackoverflow.com/questions/65343377/adam-optimizer-with-warmup-on-pytorch</guid>
      <pubDate>Thu, 17 Dec 2020 15:12:56 GMT</pubDate>
    </item>
    <item>
      <title>XGBOOST不足</title>
      <link>https://stackoverflow.com/questions/57978541/xgboost-underfitting</link>
      <description><![CDATA[我训练了以下XGBoost分类器：
  xgb.xgb.xgbclassifier（tree_method =&#39;hist&#39;，grow_policy =&#39;lossguide&#39;，gamma = 1.0，max_depth = 0，max_leaves = 255，min_child_weight = 100，n_estimators = 100，n_estimators = 500，= 500，= 500，，
                    n_jobs = -1，
                    Learning_rate = 0.1，
                    子样本= 0.7，
                    colsample_bytree = 0.7，
                   ）
 
我绘制了训练集和验证集的学习曲线（对数损失与时期）。
 学习曲线我得到的在培训和培训中完全相同验证集：开始在开始时从0.6降低到0.3，然后在100个时期后平稳
我相信这是拟合不足的情况？给我很高的偏见。
在这种情况下如何使模型复杂化？
任何帮助都非常感谢
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/57978541/xgboost-underfitting</guid>
      <pubDate>Tue, 17 Sep 2019 16:36:03 GMT</pubDate>
    </item>
    </channel>
</rss>