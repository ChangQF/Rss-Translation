<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 06 Jan 2024 06:16:53 GMT</lastBuildDate>
    <item>
      <title>裂纹检测的预处理和算法</title>
      <link>https://stackoverflow.com/questions/77768422/pre-processing-and-algorithm-for-crack-detection</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77768422/pre-processing-and-algorithm-for-crack-detection</guid>
      <pubDate>Sat, 06 Jan 2024 06:11:59 GMT</pubDate>
    </item>
    <item>
      <title>最适合分类器算法的音频文件格式是什么？</title>
      <link>https://stackoverflow.com/questions/77767853/what-is-the-best-suited-audio-file-format-for-a-classifier-algorithm</link>
      <description><![CDATA[用于分类器算法的长录音（约 2 小时）的最佳文件格式是什么？
我的用例：
&lt;块引用&gt;
假设我想训练一个分类器，它可以计算出
房间里正在交谈的人数。
我想我想要一个包含数小时对话音频的数据集
记录下来，每个时间戳都标记有多少人在
给定时间的房间。
然后，我可以对录制的文件进行监督学习，并且
训练一个模型，它可以告诉我有多少人拥有
在任何给定时间进行对话。

我最初的想法是录制WAV，但是这些会不会变得很大，有没有更适合的文件格式？]]></description>
      <guid>https://stackoverflow.com/questions/77767853/what-is-the-best-suited-audio-file-format-for-a-classifier-algorithm</guid>
      <pubDate>Sat, 06 Jan 2024 00:37:11 GMT</pubDate>
    </item>
    <item>
      <title>单独更新 TensorFlow 中的指标</title>
      <link>https://stackoverflow.com/questions/77766703/updating-the-metrics-in-tensorflow-separately</link>
      <description><![CDATA[我编写了一个自定义指标：
类 ReidClassificationAccuracy(tf.keras.metrics.Metric)：
    def __init__(self, name=“accuracy_position_distance_thresholding”, with_visibility=False, with_occlusion=False,
                 参数={}, **kwargs):
        super(ReidClassificationAccuracy, self).__init__(name=name, **kwargs)
        self.accuracy = self.add_weight(name=“准确度”, 初始值设定项=“零”)
        self.num_samples = self.add_weight(name=“num_samples”, 初始值设定项=“零”)

    def update_state（自身，pids，cls_score_list，sample_weight =无）：
        总体评分 = 0
        对于 cls_score_list 中的 cls_score：
            总体 cls_score += cls_score
        self.accuracy = self.compute_accuracy(overall_cls_score, pids, [1])[0]
        返回自我准确度

    默认结果（自身）：
        返回 self.accuracy / self.num_samples

    def Reset_states(自身):
        self.accuracy.assign(0.)
        self.num_samples.分配(0.)

    defcompute_accuracy（自身，输出，目标，topk=[1]）：
        &quot;&quot;&quot;&quot;&quot;计算指定的 k 值的 precision@k&quot;&quot;&quot;&quot;
        最大k = 最大(topk)
        批量大小 = 目标大小(0)

        _, pred = 输出.topk(maxk, 1, True, True)
        pred = pred.t()
        正确 = pred.eq(target.view(1, -1).expand_as(pred))

        分辨率=[]
        对于 topk 中的 k：
            Correct_k = Correct[:k].view(-1).float().sum(0, keepdim=True)
            res.append( Correct_k )
        返回资源

现在，由于其输入与其他指标不同，并且不是 y_pred 和 y_trues，因此我想单独更新该指标的状态。目前，我使用以下方法更新指标：
model.compiled_metrics.update_state(y_trues, y_preds) # 更新指标

但是，我无法单独更新 Reid 指标。我尝试将其编写在 for 循环中，但 model.compiled_metrics 不可迭代。]]></description>
      <guid>https://stackoverflow.com/questions/77766703/updating-the-metrics-in-tensorflow-separately</guid>
      <pubDate>Fri, 05 Jan 2024 19:07:02 GMT</pubDate>
    </item>
    <item>
      <title>预测复数（绝对值和相位）的物理问题的线性回归</title>
      <link>https://stackoverflow.com/questions/77766687/linear-regression-for-physical-problem-predicting-complex-number-absolute-and-p</link>
      <description><![CDATA[我正在尝试进行线性回归，它进行一些物理测量，然后预测各种物理值。这些物理值之一是复数，因此我尝试将其分成两部分并分别预测幅度和相位。
我需要将幅度限制在 0 和 1 之间。在我的例子中，唯一可能的幅度值在 0 到 1 之间。允许网络预测超出此范围的值会解锁一系列退化解决方案，因此网络与真实预测相去甚远。
为了限制这一点，我对幅度输出应用了 sigmoid 激活函数。这有时有效。然而，幅度的真实值非常接近零（阶数 10^{-4}，这意味着它们接近 sigmoid 的尾部。这有时会导致损失和梯度在 100 个左右的 epoch 后变为 NaN。是否存在预测复数或限制回归问题输出的更好方法？
我尝试过降低学习率、增加批量大小并使用各种不同的架构，但没有成功。我还尝试在不使用 sigmoid 函数约束输出神经元的情况下解决问题，但这使得问题变得如此退化，以至于网络无法接近正确的解决方案。我还尝试过将幅度变换得更大（即接近 0.5），然后再将其变换回来。
就上下文而言，我的损失函数是
$$L = \frac{1}{n} \sum^n_i (f_{true} - f(a_{pred}, b_{pred}, |c_{pred}|, c_{pred}^{ \phi})^2$$
其中$f_{true})$是我们已知的东西，$a$和$b$是我们试图预测的东西，$c$是我们试图预测的复数。]]></description>
      <guid>https://stackoverflow.com/questions/77766687/linear-regression-for-physical-problem-predicting-complex-number-absolute-and-p</guid>
      <pubDate>Fri, 05 Jan 2024 19:03:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么 cartpole 奖励不收敛</title>
      <link>https://stackoverflow.com/questions/77766359/why-cartpole-reward-is-not-converge</link>
      <description><![CDATA[通过此图像，训练损失和期望值随着时间的推移而收敛，但每个情节的回报没有收敛，即使是伟大的情节。
这是我的训练循环代码：
对于范围内的剧集（500）：
    状态，信息 = env.reset()
    状态 = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)
    总奖励 = 0

    对于 count() 中的 t：
        env.render()
        状态 = torch.FloatTensor(状态).to(设备)
        动作 = agent.selectAction(状态,agent.learn_step_counter)
        观察、奖励、完成、_ = env.step(action.item())[:4]

        总奖励+=奖励
        奖励 = torch.tensor([奖励], 设备=设备)
        next_state = torch.tensor(观察, dtype=torch.float32, device=device).unsqueeze(0)
        
        replay_buffer.push（状态，动作，next_state，奖励）
        
        状态 = 下一个状态
        
        代理内存 = replay_buffer
        代理.learn()
        如果完成：
            休息

在此处输入图像描述
有什么方法可以帮助看到收敛吗？]]></description>
      <guid>https://stackoverflow.com/questions/77766359/why-cartpole-reward-is-not-converge</guid>
      <pubDate>Fri, 05 Jan 2024 17:51:33 GMT</pubDate>
    </item>
    <item>
      <title>Python 中级，有志于 ML。朋友建议使用 Java/C++ 进行内存管理，并使用 Web 开发来获得更好的初学者机会。寻求建议[已关闭]</title>
      <link>https://stackoverflow.com/questions/77766281/intermediate-in-python-aspiring-for-ml-friend-suggests-java-c-for-memory-man</link>
      <description><![CDATA[我的 Python 水平处于中级，希望在机器学习 (ML) 领域发展职业生涯。然而，我的一位精通 Web 开发的朋友建议我不要坚持使用 Python。相反，他们建议学习其他语言，如 Java 或 C++，因为它们可以提供对内存管理的更深入的理解。此外，他们建议我考虑转向网络开发，并为初学者提供了更多的范围和机会。对于此事的任何指导或见解，我将不胜感激。
我探索了这两个领域的机会，但发现自己对 ML 比 Web 开发更感兴趣。]]></description>
      <guid>https://stackoverflow.com/questions/77766281/intermediate-in-python-aspiring-for-ml-friend-suggests-java-c-for-memory-man</guid>
      <pubDate>Fri, 05 Jan 2024 17:33:45 GMT</pubDate>
    </item>
    <item>
      <title>AWS ElasticBean CodePipeline 部署一次又一次失败。我缺少什么？</title>
      <link>https://stackoverflow.com/questions/77766259/aws-elasticbean-codepipeline-deployment-failed-again-and-again-what-am-i-missi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77766259/aws-elasticbean-codepipeline-deployment-failed-again-and-again-what-am-i-missi</guid>
      <pubDate>Fri, 05 Jan 2024 17:28:46 GMT</pubDate>
    </item>
    <item>
      <title>我应该在代码中添加什么或者代码有什么问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77764698/what-should-i-add-to-the-code-or-what-is-wrong-with-the-code</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;

    导入操作系统


os.environ[&#39;LOKY_MAX_CPU_COUNT&#39;] = &#39;6&#39;
导入 pandas**强文本** 作为

从 sklearn.preprocessing 导入 StandardScaler


从 sklearn.neighbors 导入 KNeighborsClassifier


从 sklearn.metrics 导入 precision_score


从 sklearn.impute 导入 SimpleImputer
从 sklearn.metrics 导入分类报告


egitim_data = pd.read_excel(r&#39;C:\Users\memo3\OneDrive\Masaüstü\ZSCOREEGITIMDATA.xlsx&#39;)
test_data = pd.read_excel(r&#39;C:\Users\memo3\OneDrive\Masaüstü\ZSCORETESTDATA.xlsx&#39;)


print(&quot;训练数据中的 NaN 值：&quot;)
打印（egitim_data.isnull（）。sum（））


print(&quot;\n测试数据中的 NaN 值：&quot;)
打印（test_data.isnull（）。sum（））


X_train = egitim_data.drop(&#39;标签&#39;, axis=1)
y_train = egitim_data[&#39;标签&#39;]

X_test = test_data.drop(&#39;标签&#39;, axis=1)
y_test = test_data[&#39;标签&#39;]


imputer = SimpleImputer(策略=&#39;均值&#39;)

X_train_scaled = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)


X_test_scaled = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)


定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train_scaled)
X_test_scaled = 缩放器.transform(X_test_scaled)


knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled, y_train)


y_pred_test = knn_model.predict(X_test_scaled)


准确度测试 = 准确度分数(y_test, y_pred_test)
print(“测试数据的模型准确度：”, precision_test)



分类代表=分类报告（y_test，y_pred_test，zero_division = 1）
print(&quot;分类报告：\n&quot;,classification_rep)


我这样编辑了代码。首先，我有7200条数据，我将它们分为90％的训练数据和10％的测试数据，并创建了两个excel文件。我在 Excel 中使用 Z 分数标准化编辑了这两个数据文件。后来，当我编辑代码时，它给出了以下输出。不过，不应该是46%，而且仍然有错误或缺失，但我找不到它。
&lt;前&gt;&lt;代码&gt;
训练数据中的 NaN 值：
流动持续时间 0
转发 IAT 分钟 0
Bwd IAT 最小值 0
转发 IAT 混合 0
Bwd IAT 最大 0
转发 IAT 平均值 0
Bwd IAT 平均值 0
流量包/秒 0
流字节/秒 0
流量 IAT 最小值 0
流量 IAT 最大 0
流量 IAT 平均值 0
流量 IAT 标准 0
活跃分钟 0
主动平均值 0
活跃最大 0
主动标准 0
空闲分钟 0
空闲平均值 0
空闲最大 0
空闲标准 0
标签0
数据类型：int64

测试数据中的 NaN 值：
流动持续时间 0
转发 IAT 分钟 0
Bwd IAT 最小值 0
转发 IAT 混合 0
Bwd IAT 最大 0
转发 IAT 平均值 0
Bwd IAT 平均值 0
流量包/秒 0
流字节/秒 0
流量 IAT 最小值 0
流量 IAT 最大 0
流量 IAT 平均值 0
流量 IAT 标准 0
活跃分钟 0
主动平均值 0
活跃最大 0
主动标准 0
空闲分钟 0
空闲平均值 0
空闲最大 0
空闲标准 0
标签0
数据类型：int64
测试数据上的模型精度：0.46111111111111114
分类报告：
                  精确召回率 f1-score 支持

音频流 0.61 0.42 0.50 90
       浏览 0.31 0.32 0.31 90
           聊天 0.28 0.34 0.31 90
  文件传输 0.60 0.71 0.65 90
           邮寄 0.55 0.39 0.45 90
            P2P 0.36 0.06 0.10 90
视频流 0.28 0.59 0.38 90
           网络电话 0.96 0.86 0.91 90

       准确度 0.46720
      宏观平均 0.49 0.46 0.45 720
   加权平均 0.49 0.46 0.45 720


进程已完成，退出代码为 0












]]></description>
      <guid>https://stackoverflow.com/questions/77764698/what-should-i-add-to-the-code-or-what-is-wrong-with-the-code</guid>
      <pubDate>Fri, 05 Jan 2024 12:46:17 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 正则化 Alpha - 权重还是叶子？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77763321/lightgbm-regularization-alpha-weights-or-leaves</link>
      <description><![CDATA[我已经阅读了有关 XGBoost 和 LightGBM 的论文以及它们的大部分文档，但无法找到明确的声明表明除了 GOSS &amp; EFB用于更快的学习，基本算法与XGBoost相同。
具体来说，XGBoost 目标函数中唯一的 L1 式正则化是 gamma*T，其中 gamma 是超参数，T 是叶子数量。 LightGBM 有 reg_alpha 参数，根据他们的文档，该参数应用 L1 正则化，该参数是否会惩罚叶子的数量，或者，在更传统的意义上，惩罚每个叶子的贡献的绝对值？
附注参考回归案例，我从未使用过该模型进行分类，因此不知道哪些部分仍然有效。]]></description>
      <guid>https://stackoverflow.com/questions/77763321/lightgbm-regularization-alpha-weights-or-leaves</guid>
      <pubDate>Fri, 05 Jan 2024 08:25:18 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 haar 级联找到使用网络摄像头的人的参与度？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades</link>
      <description><![CDATA[我正在建立一个网站，在编写考试时跟踪用户以了解他们的参与程度，并为此找到了这篇有趣的论文。
https://www.sciencedirect .com/science/article/pii/S0045790621002597?ref=cra_js_challenge&amp;fr=RR-1
我想使用 opencv 和 tensorflow 构建完全相同的模型。有人可以帮我完成模型吗？我是机器学习领域的新手。刚刚建立了一些回归和分类模型。任何帮助都会非常有帮助。我无法理解如何从上述论文中计算聚焦概率。我希望了解如何构建模型以及如何计算值的详细步骤。
数据集链接：
FER 2013：https://www.kaggle.com/datasets/msambare/fer2013&lt; /a&gt;
MES数据集：https://github.com/Harsh9524/MES-Dataset
我已经使用 haar 级联检测到人脸并且它正在工作。下一个问题是找出情绪，我也做到了！但问题在于寻找 MES 和焦点概率。请帮我解决一下。]]></description>
      <guid>https://stackoverflow.com/questions/77761102/how-to-find-the-engagement-level-of-a-person-using-webcam-with-haar-cascades</guid>
      <pubDate>Thu, 04 Jan 2024 20:42:19 GMT</pubDate>
    </item>
    <item>
      <title>DataFrame'对象没有属性'符号</title>
      <link>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</link>
      <description><![CDATA[我想使用机器学习创建股票价格预测，但出现“‘DataFrame’对象没有属性‘符号’”我的错误是什么以及如何修复它
将 numpy 导入为 np
将 pandas 导入为 pd
从sklearn导入预处理
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression

def prepare_data(df,forecast_col,forecast_out,test_size) :
    label = df[forecast_col].shift(-forecast_out) #创建名为 label 的新列，最后 5 行为 nan
    X = np.array(df [[forecast_col]]) #创建特征数组
    X = preprocessing.scale(X) #处理特征数组
    X_lately = X[-forecast_out:] #创建我想稍后在预测方法中使用的列
    X = X[:-forecast_out] # X 将包含训练和测试
    label.dropna(inplace=True) #删除na值
    y = np.array(label) # 分配 Y
    X_train,X_test,Y_train,Y_test = train_test_split(X, y, test_size=test_size, random_state=0) #交叉验证

    响应 = [X_train,X_test,Y_train,Y_test,X_lately]
    返回响应

df = pd.read_csv(“GOOG.csv”)
df = df[df.symbol == &quot;GOOG&quot;]- &quot;错误信息出现的位置&quot;
Forecast_col = “关闭”
预测输出 = 5
   

测试大小 = 0,2

X_train、X_test、Y_train、Y_test、X_lately = 准备数据（df、forecast_col、forecast_out、test_size）
学习者 = 线性回归()
learner.fit (X_train,Y_train )
Score=learner.score(X_test,Y_test)#测试线性回归模型
Forecast= learner.predict(X_lately) #将包含预测数据的集合
响应={}#creting json 对象
响应[&#39;test_score&#39;]=分数
响应[&#39;forecast_set&#39;]=预测

打印（响应）
]]></description>
      <guid>https://stackoverflow.com/questions/77755413/dataframe-object-has-no-attribute-symbol</guid>
      <pubDate>Thu, 04 Jan 2024 01:24:44 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17)</title>
      <link>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</link>
      <description><![CDATA[
第 1 步：创建管道
第2步：将管道转换为数据帧
第3步：我正在尝试将管道转换为数据帧，但出现异常。如何解决这个问题
第 4 步：如何解决 ValueError：传递值的形状为 (8631, 28)，索引意味着 (8631, 17) 在管道转换为数据帧之上，

from sklearn.preprocessing import FunctionTransformer, OneHotEncoder
从 sklearn.impute 导入 SimpleImputer
从 sklearn.pipeline 导入管道
从 sklearn.compose 导入 ColumnTransformer

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split

print(&quot;步骤1：导入lib&quot;)
print(&quot;第2步：加载原始数据&quot;)
df = pd.read_csv(“online_shoppers_intention.csv”)

print(&quot;第三步：数据准备&quot;)
X = df.drop([&#39;收入&#39;], axis = 1)
y = df[&#39;收入&#39;]

print(&quot;第四步：数据分割&quot;)
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size = .3、random_state = 0)
名称 = X_train.columns.tolist()

numeric_transformer = SimpleImputer(策略 = &#39;常量&#39;)
categorical_transformer = OneHotEncoder(handle_unknown = &#39;忽略&#39;)

numeric_cols = X.select_dtypes(exclude = &quot;object&quot;).columns.values.tolist()
categorical_cols = X.select_dtypes(exclude = [&#39;int&#39;, &#39;float64&#39;, &#39;bool&#39;]).columns.values.tolist()
    
预处理器 = ColumnTransformer(
    变形金刚=[
    (&#39;num&#39;, numeric_transformer, numeric_cols)
    ,(&#39;猫&#39;, categorical_transformer, categorical_cols)
    ],
    余数 = &#39;直通&#39;)

pipeline_preprocessor = Pipeline(steps = [(“预处理器”, 预处理器), (“pandarizer”, FunctionTransformer(lambda x: pd.DataFrame(x, columns = 名称)))]).fit(X_train)
    
X_train_pipe = pipeline_preprocessor.transform(X_train)
X_test_pipe = pipeline_preprocessor.transform(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/77750389/valueerror-shape-of-passed-values-is-8631-28-indices-imply-8631-17</guid>
      <pubDate>Wed, 03 Jan 2024 07:51:34 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：使用 URL 'http://127.0.0.1:8237' 初始化剩余存储时出错：模块 'jwt' 没有属性 'encode'</title>
      <link>https://stackoverflow.com/questions/77730757/runtimeerror-error-initializing-rest-store-with-url-http-127-0-0-18237-mo</link>
      <description><![CDATA[第一个命令python run_deployment.py --config deploy成功运行并建议我运行下一个命令 - zenml up
zenml up 生成以下错误。







我正在 YouTube 上关注 Ayush 的 MLOPs 课程。感谢您提前提供的帮助。
我试过了
&lt;前&gt;&lt;代码&gt;1。 pip 安装 jwt
2.pip安装PyJWT
3. pip卸载jwt
4. pip安装jwt==1.3.0
5. pip install --upgrade --force-reinstall PyJWT
6. pip install --upgrade --force-reinstall jwt
]]></description>
      <guid>https://stackoverflow.com/questions/77730757/runtimeerror-error-initializing-rest-store-with-url-http-127-0-0-18237-mo</guid>
      <pubDate>Fri, 29 Dec 2023 07:34:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 python 中的 AI 和 ML 库编写一个 python 程序来预测游戏的下一个结果（从两种颜色中选择一种颜色）</title>
      <link>https://stackoverflow.com/questions/76086477/how-to-make-a-python-program-to-predict-the-next-outcome-of-a-game-of-picking-a</link>
      <description><![CDATA[我想使用 LSTM 技术在 python 中编写一个程序，可以预测下一个结果，或者说从两种颜色中选择一种颜色的概率，该程序应该使用 AI 和 ML 库，来读取最后 40 个结果的模式从而预测下一个结果。
嗯，我为此制定了以下计划。
从 keras.models 导入顺序
从 keras.layers 导入 LSTM，密集
将 numpy 导入为 np


def Predict_next_color_lstm（结果）：
    如果 len(结果) &lt; 40：
        返回“错误：提供的结果数量小于 40。”

    # 将字符串输入转换为整数序列
    seq = [如果 x == &#39;r&#39; 则为 0，否则结果中的 x 为 1]

    # 创建 40 个结果的滚动窗口
    X = []
    y = []
    对于范围内的 i(len(seq) - 40)：
        X.append(seq[i:i + 40])
        y.append(seq[i + 40])
    X = np.array(X)
    y = np.array(y)

    # 重塑 X 以适应 LSTM 输入形状
    X = np.reshape(X, (X.shape[0], X.shape[1], 1))

    # 创建LSTM模型
    模型=顺序（）
    model.add(LSTM(50, input_shape=(40, 1)))
    model.add（密集（1，激活=&#39;sigmoid&#39;））

    # 编译模型
    model.compile(loss=&#39;binary_crossentropy&#39;, 优化器=&#39;adam&#39;)

    # 训练模型
    model.fit(X, y, epochs=50, batch_size=32)

    # 预测下一个结果
    最后_40 = seq[-40:]
    pred = model.predict(np.array([last_40]))
    如果 pred &lt;，则返回 &#39;r&#39; 0.5 其他“g”


def get_input():
    # 要求用户输入长度为40的球颜色序列
    ball_seq = input(&quot;输入长度为 40 的球颜色序列（例如 rrggrrgrrgggrgrgrgrggggrgrgrrgrgggrrgggg）：&quot;)
    返回 ball_seq


＃ _主要的_
ball_seq = get_input()
print(“预测：”,predict_next_color_lstm(ball_seq))

但我在执行时不断收到以下错误：
C:\Users\Ashish\miniconda3\python.exe C:\Users\Ashish\Desktop\pyt_pract\test_prob1.py
输入长度为 40 的球颜色序列（例如 rrggrrgrrgggrgrgrggrrggggrgrgrrgrgggrrgggg）： rgggrrgrgrggrrgrgrgrggggrrrrggrrggrgrg
回溯（最近一次调用最后一次）：
文件“C:\Users\Ashish\Desktop\pyt_prac\test_prob1.py”，第 50 行，位于
print(“预测：”,predict_next_color_lstm(ball_seq))
文件“C:\Users\Ashish\Desktop\pyt_prac\test_prob1.py”，第 23 行，位于 Predict_next_color_lstm 中
X = np.reshape(X, (X.shape[0], X.shape[1], 1))
IndexError：元组索引超出范围]]></description>
      <guid>https://stackoverflow.com/questions/76086477/how-to-make-a-python-program-to-predict-the-next-outcome-of-a-game-of-picking-a</guid>
      <pubDate>Sun, 23 Apr 2023 18:08:18 GMT</pubDate>
    </item>
    <item>
      <title>用于机器学习算法的 csv 流</title>
      <link>https://stackoverflow.com/questions/44240145/csv-stream-for-machine-learning-algorithms</link>
      <description><![CDATA[我有一个很大的 CSV 文件（大约 5GB）。
我试图逐行读取整个文件，并尝试应用最典型的算法（SVM、朴素贝叶斯、线性回归等）。
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd
导入 csv

i_f = open(&#39;top2Mmm.csv&#39;, &#39;r&#39; )
reader = csv.reader( i_f, 分隔符 = &#39;;&#39; )
对于读卡器中的行：
print(“斐乐 -&gt;”, 行)

我刚刚成功阅读了 CSV，但我不知道如何获取每一行并构建模型。
我从一个较小的文件开始以加快该过程，但我不知道如何使该过程正常工作。
有什么线索或提示吗？]]></description>
      <guid>https://stackoverflow.com/questions/44240145/csv-stream-for-machine-learning-algorithms</guid>
      <pubDate>Mon, 29 May 2017 10:23:16 GMT</pubDate>
    </item>
    </channel>
</rss>