<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 26 Mar 2024 06:18:31 GMT</lastBuildDate>
    <item>
      <title>我们如何创建或者什么类型的机器学习或深度学习模型可用于创建用于安排比赛的模型</title>
      <link>https://stackoverflow.com/questions/78223241/how-can-we-create-or-what-type-of-machine-learning-or-deeplearning-models-be-use</link>
      <description><![CDATA[想要创建一个网球锦标赛时间表
我还没有尝试过，但想了解启动和训练模型的基本知识。我有一组过去的比赛数据，其中有各种限制，所以我想创建一个可以进行预测的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78223241/how-can-we-create-or-what-type-of-machine-learning-or-deeplearning-models-be-use</guid>
      <pubDate>Tue, 26 Mar 2024 06:01:20 GMT</pubDate>
    </item>
    <item>
      <title>如何有效利用机器学习专业课程可选实验室（吴恩达先生）？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78223041/how-to-effectively-use-optional-labs-in-machine-learning-specialization-course</link>
      <description><![CDATA[我应该复制实验室中给出的代码并在本地运行吗？另外，您如何使用可选实验室，请详细说明（提供分步路径）。
目前，我正在阅读代码并了解实验室中使用的库。
但我相信这不是理想的方式。我没有充分发挥实验室的优势。]]></description>
      <guid>https://stackoverflow.com/questions/78223041/how-to-effectively-use-optional-labs-in-machine-learning-specialization-course</guid>
      <pubDate>Tue, 26 Mar 2024 04:47:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Flower 和 Tensorflow 来结束联邦学习中服务器的额外参数？</title>
      <link>https://stackoverflow.com/questions/78221905/how-to-end-extra-parameters-to-server-in-federated-learning-with-flower-and-tens</link>
      <description><![CDATA[我想将带有模型更新的额外参数发送到服务器，然后将服务器中的这些额外参数用于其他目的。我在这个项目中使用 Flower 和 Tensorflow。在发送额外参数之前，我的模型运行良好。目前我有这些代码客户端模型 server.py。
如何在服务器中成功发送额外参数或值并接收它？
感谢您的帮助。
我尝试在 get_parameter 方法中发送附加参数，并使用 FedAvg 策略接收它。但我一次又一次地遇到这个错误。 错误]]></description>
      <guid>https://stackoverflow.com/questions/78221905/how-to-end-extra-parameters-to-server-in-federated-learning-with-flower-and-tens</guid>
      <pubDate>Mon, 25 Mar 2024 21:38:40 GMT</pubDate>
    </item>
    <item>
      <title>这段代码应该做什么？它持续执行并且不会停止</title>
      <link>https://stackoverflow.com/questions/78221744/what-does-this-code-is-supposed-to-do-it-keeps-executing-and-does-not-stop</link>
      <description><![CDATA[我正在使用 Google Colab 上的 CelebA 数据集开发生成模型。一切都运行良好，但它要执行这个单元，它会继续执行。我应该在执行时做一些事情吗？为什么一直执行3、4个小时？
这是代码：
导入时间
迭代次数 = 15000
批量大小 = 16

RES_DIR = &#39;res2&#39;
FILE_PATH = &#39;%s/生成_%d.png&#39;
如果不是 os.path.isdir(RES_DIR):
    os.mkdir(RES_DIR)

CONTROL_SIZE_SQRT = 6
control_vectors = np.random.normal(size=(CONTROL_SIZE_SQRT**2, LATENT_DIM)) / 2

开始=0
d_损失= []
a_损失= []
图片已保存 = 0
对于范围内的步长（iters）：
    开始时间 = 时间.time()
    Latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))
    生成=生成器.预测（潜在向量）

    真实=图像[开始：开始+批量大小]
    组合图像 = np.concatenate([生成, 真实])

    标签 = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))])
    标签 += .05 * np.random.random(labels.shape)

    d_loss = discriminator.train_on_batch(combined_images, labels)
    d_losses.append(d_loss)

    Latent_vectors = np.random.normal(size=(batch_size, LATENT_DIM))
    误导目标 = np.zeros((batch_size, 1))

    a_loss = gan.train_on_batch（潜在向量，误导目标）
    a_losses.append(a_loss)

    开始+=批量大小
    如果开始&gt; images.shape[0] - 批量大小：
        开始=0

    如果步骤 % 50 == 49：
        gan.save_weights(&#39;/gan.h5&#39;)

        print(&#39;%d/%d: d_loss: %.4f, a_loss: %.4f.(%.1f sec)&#39; % (step + 1, iters, d_loss, a_loss, time.time() - start_time))

        control_image = np.zeros((宽度 * CONTROL_SIZE_SQRT, 高度 * CONTROL_SIZE_SQRT, 通道))
        control_generate = 生成器.predict(control_vectors)

        对于范围内的 i（CONTROL_SIZE_SQRT ** 2）：
            x_off = i % CONTROL_SIZE_SQRT
            y_off = i // CONTROL_SIZE_SQRT
            control_image[x_off * 宽度:(x_off + 1) * 宽度, y_off * 高度:(y_off + 1) * 高度, :] = control_ generated[i, :, :, :]
        im = Img.fromarray(np.uint8(control_image * 255))#.save(StringIO(), &#39;jpeg&#39;)
        im.save(FILE_PATH % (RES_DIR, images_saved))
        图片已保存 += 1

什么时候执行完成？]]></description>
      <guid>https://stackoverflow.com/questions/78221744/what-does-this-code-is-supposed-to-do-it-keeps-executing-and-does-not-stop</guid>
      <pubDate>Mon, 25 Mar 2024 20:58:02 GMT</pubDate>
    </item>
    <item>
      <title>如何微调任何生成模型？自动列车</title>
      <link>https://stackoverflow.com/questions/78221298/how-can-i-fine-tune-the-any-generative-model-autotrain</link>
      <description><![CDATA[如何微调 Realistic_Vision_V6.0_B1_noVAE 模型并生成自己的图像？这是huggingface 链接。
我在稳定的扩散基础 xl 模型上使用了 autotrain。但在现实视觉模型上使用它似乎不太正确。模型生成不良图像。
&lt;块引用&gt;
自动训练 Dreambooth --型号 SG161222/Realistic_Vision_V6.0_B1_noVAE
--image-path input_images/ --prompt “摩诃人的照片” --分辨率 1024 --批量大小 1 --步数 500 --混合精度 fp16 --梯度累积 4 --lr 1e-4 --项目名称
现实愿景

这给了我 pytorch_lora_weights.safetensors 文件，我用它来生成我自己的图像。
pipeline.load_lora_weights（“模型/”，weight_name =“pytorch_lora_weights.safetensors”）
这种微调 Realistic_Vision_V6.0_B1_noVAE 模型的技术是否正确？或者任何类似稳定扩散的模型？]]></description>
      <guid>https://stackoverflow.com/questions/78221298/how-can-i-fine-tune-the-any-generative-model-autotrain</guid>
      <pubDate>Mon, 25 Mar 2024 19:17:08 GMT</pubDate>
    </item>
    <item>
      <title>从 9 年的 Java 经验转向 AI/ML 职业道路是一个明智的决定吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78220858/is-it-good-decision-to-move-to-ai-ml-career-path-from-9-years-of-java-experience</link>
      <description><![CDATA[您好，我作为软件开发人员和 API 开发人员拥有 9 年的 Java 经验。
现在，在这个不断变化的技术时代，每个人都在谈论人工智能。
那么，将职业道路转向与 AI/ML 相关的方向是个好决定吗？
搜索了很多youtybe]]></description>
      <guid>https://stackoverflow.com/questions/78220858/is-it-good-decision-to-move-to-ai-ml-career-path-from-9-years-of-java-experience</guid>
      <pubDate>Mon, 25 Mar 2024 17:42:06 GMT</pubDate>
    </item>
    <item>
      <title>使用变压器模型改进列车准点预测：模型设置和性能问题</title>
      <link>https://stackoverflow.com/questions/78220853/improving-train-punctuality-prediction-using-a-transformer-model-model-setup-an</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78220853/improving-train-punctuality-prediction-using-a-transformer-model-model-setup-an</guid>
      <pubDate>Mon, 25 Mar 2024 17:41:18 GMT</pubDate>
    </item>
    <item>
      <title>波士顿房价数据集的 ANN 损失并未减少</title>
      <link>https://stackoverflow.com/questions/78220834/ann-loss-not-reducing-for-boston-house-price-data-set</link>
      <description><![CDATA[from sklearn.datasets import load_boston

波士顿 = load_boston()
boston_data = pd.DataFrame(boston.data)
boston_data.columns=boston.feature_names

boston_data[&#39;PRICE&#39;]=boston.target # 因变量，要预测的值

# 对于当前数据集，进行对数转换以减少异常值，然后对数据集进行归一化

boston_data_log=np.log1p(boston_data)
boston_data_log=(boston_data_log-boston_data_log.min())/(boston_data_log.max()-boston_data_log.min())
boston_data_log[&#39;价格&#39;]=boston_data[&#39;价格&#39;]

## 构建人工神经网络

# Log_transformed 和标准化数据集

从 sklearn.model_selection 导入 train_test_split
x_train,x_test,y_train,y_test=train_test_split(boston_data_log.drop(columns=[&#39;PRICE&#39;]).values,boston_data_log[&#39;PRICE&#39;].values,test_size=0.2)


x_train=torch.FloatTensor(x_train)
x_test=torch.FloatTensor(x_test)

y_train=torch.FloatTensor(y_train)
y_test=torch.FloatTensor(y_test)

进口火炬
将 torch.nn 导入为 nn
导入 torch.nn.function 作为 F

ANN 类（nn.Module）：
    def __init__(自身,输入层,隐藏层_1,隐藏层_2,隐藏层_3,隐藏层_4,隐藏层_5,输出层):
        超级().__init__()
        self.full_connected_1=nn.Linear(input_layer,hidden_​​layer_1)
        self.full_connected_2=nn.Linear(hidden_​​layer_1,hidden_​​layer_2)
        self.full_connected_3=nn.Linear(hidden_​​layer_2,hidden_​​layer_3)
        self.full_connected_4=nn.Linear(hidden_​​layer_3,hidden_​​layer_4)
        self.full_connected_5=nn.Linear(hidden_​​layer_4,hidden_​​layer_5)
        self.output_layer=nn.Linear(hidden_​​layer_5,output_layer)
    defforward_prop（自身，x）：
        x=F.relu(self.complete_connected_1(x))
        x=F.relu(self.complete_connected_2(x))
        x=F.relu(self.complete_connected_3(x))
        x=F.relu(self.complete_connected_4(x))
        x=F.relu(self.complete_connected_5(x))
        x=self.output_layer(x)
        返回x
        

火炬.manual_seed(20)
模型=ANN(x_train.shape[1],200,200,200,200,200,1)

loss_function=nn.MSELoss()
优化器=torch.optim.Adam(model.parameters(),lr=0.01)

纪元=500
loss_cumul_list=[]
循环列表=[]
对于范围内的 i（纪元）：
    y_pred=model.forward_prop(x_train)
    损失=loss_function(y_pred,y_train)
    loss_cumul_list.append(loss.item())
    循环列表.append(i+1)
    优化器.zero_grad()
    loss.backward()
    优化器.step()

损失累积列表

预测=[]
使用 torch.no_grad()：
    对于 i，枚举（x_test）中的数据：
        y_pred=model.forward_prop(数据)
        预测.append(y_pred.item())

从 sklearn.metrics 导入 r2_score,mean_squared_error,mean_absolute_error
error_r2=r2_score(y_test,预测)
error_mse=mean_squared_error(y_test,预测)
error_mae=mean_absolute_error(y_test,预测)

我一直试图使用 Pytorch 在波士顿房价数据集上应用 ANN，但在 50 个 epoch 后，损失并没有进一步减少太多。在网上看到过一些使用张量流的类似笔记本，但模型在那里工作得很好。无法理解这里的问题。
我一直试图使用 Pytorch 在波士顿房价数据集上应用 ANN，但在 50 个 epoch 后，损失并没有进一步减少太多。在网上看到过一些使用张量流的类似笔记本，但模型在那里工作得很好。无法理解这里的问题。]]></description>
      <guid>https://stackoverflow.com/questions/78220834/ann-loss-not-reducing-for-boston-house-price-data-set</guid>
      <pubDate>Mon, 25 Mar 2024 17:39:02 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中将管道重新编写为类时出错</title>
      <link>https://stackoverflow.com/questions/78219825/error-when-rewiriting-a-pipeline-as-a-class-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78219825/error-when-rewiriting-a-pipeline-as-a-class-in-python</guid>
      <pubDate>Mon, 25 Mar 2024 14:32:03 GMT</pubDate>
    </item>
    <item>
      <title>用于多标签分类的堆叠集成学习</title>
      <link>https://stackoverflow.com/questions/78214688/stacking-ensamble-learning-for-multilabelclassification</link>
      <description><![CDATA[我有两个 BERT 模型来实现代码中漏洞检测的多标签分类。一名接受过源代码培训，另一名接受过编译代码培训。他们实现的任务是多标签分类，因此两个模型的单个输出都是一个包含 6 个元素的数组，每个元素可以是 0 或 1，指示漏洞是否存在。
我想在这两个模型之上构建一个经典的 ML 分类器（如随机森林、SVM 或逻辑回归等），实现称为 Stacking 的集成技术。知道我正在处理多标签分类，我该如何实现这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78214688/stacking-ensamble-learning-for-multilabelclassification</guid>
      <pubDate>Sun, 24 Mar 2024 13:28:23 GMT</pubDate>
    </item>
    <item>
      <title>我做了什么来纠正属性错误。请帮助我[关闭]</title>
      <link>https://stackoverflow.com/questions/78210052/what-did-i-do-to-correct-the-attribute-error-please-help-me</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;batch_size = 100
对于范围 (25) 内的 i：
    num_batches = int(mnist.train.num_examples/batch_size)
    总成本 = 0
    对于范围内的 j（num_batches）：
        batch_x,batch_y = mnist.train.next_batch(batch_size)
        c, _ = sess.run([成本,优化], feed_dict={x:batch_x, y:batch_y, keep_prob:0.8})
        总成本 += c
    打印（总成本）

属性错误
                            回溯（最近一次调用最后一次）
单元格 In[65]，第 3 行
      1 批量大小 = 100
      2 对于范围 (25) 内的 i：
----&gt; 3 num_batches = int(mnist.train.num_examples/batch_size)
      4 总成本 = 0
      5 对于 j 在范围内（num_batches）：

AttributeError：模块“keras.datasets.mnist”没有属性“train”
]]></description>
      <guid>https://stackoverflow.com/questions/78210052/what-did-i-do-to-correct-the-attribute-error-please-help-me</guid>
      <pubDate>Sat, 23 Mar 2024 07:25:50 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 矩阵乘法形状错误：“RuntimeError：mat1 和 mat2 形状无法相乘”</title>
      <link>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</link>
      <description><![CDATA[我是 PyTorch 的新手，正在创建一个多输出线性回归模型，根据字母为单词着色。 （这将帮助有字素颜色联觉的人更轻松地阅读。）它接收单词并输出 RGB 值。每个单词都表示为 45 个浮点数 [0,1] 的向量，其中 (0, 1] 代表字母，0 代表该位置不存在字母。每个样本的输出应该是一个向量 [r-value, g -值，b-值]。
我懂了
&lt;块引用&gt;
运行时错误：mat1 和 mat2 形状无法相乘（90x1 和 45x3）

当我尝试在训练循环中运行我的模型时。
查看现有的 Stack Overflow 帖子，我认为这意味着我需要重塑我的数据，但我不知道如何/在哪里以解决此问题的方式进行此操作。特别是考虑到我不知道那个 90x1 矩阵来自哪里。
我的模型
我一开始很简单；在我可以让单个层发挥作用之后，可以出现多个层。
类 ColorPredictor(torch.nn.Module):
    #构造函数
    def __init__(自身):
        super(ColorPredictor, self).__init__()
        self.linear = torch.nn.Linear(45, 3, device= device) #编码词向量的长度 &amp; r,g,b 向量的大小
        
    ＃ 预言
    defforward(self, x: torch.Tensor) -&gt;;火炬.张量：
        y_pred = self.线性(x)
        返回 y_pred

我如何加载数据
# 数据集类
数据类（数据集）：
    # 构造函数
    def __init__(自身，输入，输出)：
        self.x = input # 编码词向量列表
        self.y = 输出 # 将 r、g、b 值转换为火炬张量的 Pandas 数据帧
        self.len = len(输入)
    
    # 吸气剂
    def __getitem__(自身，索引)：
        返回 self.x[索引], self.y[索引]
    
    # 获取样本数
    def __len__(自身):
        返回 self.len

# 创建训练/测试分割
train_size = int(0.8 * len(数据))
train_data = 数据(输入[:train_size], 输出[:train_size])
test_data = 数据(输入[train_size:], 输出[train_size:])

# 为训练和测试集创建 DataLoaders
train_loader = DataLoader（数据集= train_data，batch_size = 2）
test_loader = DataLoader（数据集= test_data，batch_size = 2）

发生错误的测试循环
对于范围内的纪元（纪元）：
    ＃ 火车
    model.train() #训练模式
    对于 train_loader 中的 x,y：
        y_pred = model(x) #此处错误
        损失=标准(y_pred, y)
        优化器.zero_grad()
        loss.backward()
        优化器.step()
      

错误回溯


新尝试：
将 45x1 输入张量更改为 2x45 输入张量，第二列全为零。这适用于第一次运行 train_loader 循环，但在第二次运行 train_loader 循环期间，我得到另一个矩阵乘法错误，这次是大小为 90x2 和 45x3 的矩阵。]]></description>
      <guid>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</guid>
      <pubDate>Thu, 21 Mar 2024 01:00:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 OneClassSVM 绘制 SHAP 绘图需要很长时间</title>
      <link>https://stackoverflow.com/questions/73279201/shap-plots-taking-ages-with-oneclasssvm</link>
      <description><![CDATA[我正在尝试解释我的 OneClassSVM 模型，但计算时间非常长。我使用了 36 次折叠的交叉验证，因此希望将所有折叠的结果合并到一个 SHAP 图上，以便我可以充分解释哪些特征对模型贡献最大。
到目前为止，我认为对我想要解释的数据进行采样会加快处理速度（确实减少了时间），但折叠一次仍然需要大约 8 小时，并且有 36 次折叠。
请注意，我的训练集约为 2400 个，测试集约为 1400 个，每个集有 88 个特征。
导入形状
从 sklearn.svm 导入 OneClassSVM
将 numpy 导入为 np

# 这些是二维数组，其中每个元素都是用于训练/测试折叠的所选数据的 DataFrame
shap_train = np.load(&#39;shap_train.npy&#39;,allow_pickle=True)
shap_test = np.load(&#39;shap_test.npy&#39;,allow_pickle=True)

clf = OneClassSVM(nu=0.35)

折叠 = len(shap_train)
形状值 = []
shap_data_test = []

对于范围内的折叠（折叠）：
        解释器 = shap.Explainer(clf.fit_predict, shap_train[fold])
        # 采样1/3的数据
        数据 = shap_test[fold].sample(frac=(1/3))
        shap_values.append(解释器(数据))
        shap_data_test.append（数据）

# 存储稍后绘图的 SHAP 值
np.save(&#39;shap_data.npy&#39;, np.array(shap_values))
np.save(&#39;shap_data_test.npy&#39;, np.array(shap_data_test))


我对需要为所有折叠生成形状值的方法提出了质疑，但我知道某些折叠的性能比其他折叠更好，因此希望全面了解哪些功能贡献最大。
我将此脚本部署在具有 Intel(R) Xeon(R) CPU E5-2667 v4 @ 3.20GHz 和 64GB RAM 的 Debian 服务器上。]]></description>
      <guid>https://stackoverflow.com/questions/73279201/shap-plots-taking-ages-with-oneclasssvm</guid>
      <pubDate>Mon, 08 Aug 2022 14:06:46 GMT</pubDate>
    </item>
    <item>
      <title>从“y”的唯一值推断出的类无效。预期：[0 1 2 3 4 5]，得到[1 2 3 4 5 6]</title>
      <link>https://stackoverflow.com/questions/71996617/invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2-3-4-5-got</link>
      <description><![CDATA[我已经使用 XGB 分类器训练了数据集，但在本地出现了此错误。它在 Colab 上有效，而且我的朋友对相同的代码也没有任何问题。
我不知道这个错误意味着什么......
从 y 的唯一值推断出的类无效。预期：[0 1 2 3 4 5]，得到[1 2 3 4 5 6]
这是我的代码，但我想这不是原因。
start_time = time.time()
xgb = XGBClassifier（n_估计器 = 400，学习率 = 0.1，最大深度 = 3）
xgb.fit(X_train.values, y_train)
print(&#39;适合时间：&#39;, time.time() - start_time)
]]></description>
      <guid>https://stackoverflow.com/questions/71996617/invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2-3-4-5-got</guid>
      <pubDate>Mon, 25 Apr 2022 08:32:38 GMT</pubDate>
    </item>
    <item>
      <title>在 XGBoost 的 GridSearchCV 中评分</title>
      <link>https://stackoverflow.com/questions/50296817/scoring-in-gridsearchcv-for-xgboost</link>
      <description><![CDATA[我目前正在尝试使用 XGBoost 第一次分析数据。我想使用 GridsearchCV 找到最佳参数。我想最小化均方根误差，为此，我使用“rmse”作为 eval_metric。然而，网格搜索中的评分没有这样的指标。我在这个网站上发现“neg_mean_squared_error”的作用相同，但我发现这给出了与 RMSE 不同的结果。当我计算“neg_mean_squared_error”的绝对值的根时，我得到的值约为 8.9，而另一个函数给出的 RMSE 约为 4.4。
我不知道出了什么问题，也不知道如何让这两个函数达成一致/给出相同的值？
由于这个问题，我得到了错误的“best_params_”值，这给了我比我最初开始调整的一些值更高的 RMSE。
谁能解释一下如何在网格搜索中获得 RMSE 分数或者为什么我的代码给出不同的值？ 
提前致谢。
def modelfit（alg、trainx、trainy、useTrainCV=True、cv_folds=10、early_stopping_rounds=50）：
    如果使用TrainCV：
        xgb_param = alg.get_xgb_params()
        xgtrain = xgb.DMatrix(trainx, label=trainy)
        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()[&#39;n_estimators&#39;], nfold=cv_folds,
                          指标=&#39;rmse&#39;，early_stopping_rounds=early_stopping_rounds）
        alg.set_params(n_estimators=cvresult.shape[0])

    # 将算法拟合到数据上
    alg.fit(trainx, trainy, eval_metric=&#39;rmse&#39;)

    # 预测训练集：
    dtrain_predictions = alg.predict(trainx)
    # dtrain_predprob = alg.predict_proba(trainy)[:, 1]
    打印（dtrain_预测）
    打印（np.sqrt（mean_squared_error（trainy，dtrain_predictions）））

    # 打印模型报告：
    print(&quot;\n模型报告&quot;)
    print(&quot;RMSE : %.4g&quot; % np.sqrt(metrics.mean_squared_error(trainy, dtrain_predictions)))

 参数_test2 = {
 &#39;最大深度&#39;:[6,7,8],
 &#39;min_child_weight&#39;:[2,3,4]
}

grid2 = GridSearchCV(估计器 = xgb.XGBRegressor( 学习率 =0.1, n_estimators=2000, max_深度=5,
 min_child_weight=2，gamma=0，子样本=0.8，colsample_bytree=0.8，
 目标=&#39;reg：线性&#39;，nthread=4，scale_pos_weight=1，random_state=4），
 param_grid = param_test2，评分=&#39;neg_mean_squared_error&#39;，n_jobs=4，iid=False，cv=10，详细=20）
grid2.fit(X_train,y_train)
# best_estimator 的平均交叉验证分数
打印（grid2.best_params_，np.sqrt（np.abs（grid2.best_score_））），打印（np.sqrt（np.abs（grid2.score（X_train，y_train））））
modelfit(grid2.best_estimator_, X_train, y_train)
打印（np.sqrt（np.abs（grid2.score（X_train，y_train））））
]]></description>
      <guid>https://stackoverflow.com/questions/50296817/scoring-in-gridsearchcv-for-xgboost</guid>
      <pubDate>Fri, 11 May 2018 16:46:16 GMT</pubDate>
    </item>
    </channel>
</rss>