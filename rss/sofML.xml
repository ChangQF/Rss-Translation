<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 20 Dec 2023 03:12:24 GMT</lastBuildDate>
    <item>
      <title>如何制作一个单神经元的神经网络？</title>
      <link>https://stackoverflow.com/questions/77688349/how-can-i-make-a-one-neuron-neural-network</link>
      <description><![CDATA[我想制作一个像 w1x1+w2x2+w3*x3+b1 这样的单神经元函数
我的训练输入是
&lt;前&gt;&lt;代码&gt; [1, 0, 0],
                    [0, 1, 0],
                    [0,0,1],
                    [1, 1, 0],
                    [0,1,1],
                    [1,1,1],
                    [2, 0, 0]

训练输出是：
&lt;前&gt;&lt;代码&gt;[1,2,0,1,0,2,3]

我尝试使用一种热编码来编写代码，但失败了。我是 AI 编码新手，不想使用任何 AI 库，例如 Pytorch 和 Tensorflow 或 scikitlearn。这个问题困扰了我两周，我也尝试了不同的代码，但没有成功。这是一个示例代码，我知道它是错误的，但它可能会给您带来见解。
&lt;前&gt;&lt;代码&gt;
将 numpy 导入为 np
将 pandas 导入为 pd

定义 sigmoid(x):
    返回 1 /(1+np.exp(-x))

def sigmoid_derivative(x):
    返回 x*(1-x)

训练输入 = np.array([
                    [1,0,0],
                    [0, 1, 0],
                    [0,0,1],
                    [1, 1, 0],
                    [0,1,1],
                    [1,1,1],
                    [2, 0, 0]
                ]）

Training_outputs = np.array([[1,2,0,1,0,2,3]]).T

np.随机.种子(1)

synaptic_weights = 2 * np.random.random((3,1))-1
print(&#39;随机起始突触权重：&#39;)
打印（突触权重）

对于范围（2000）内的迭代：

    输入层=训练输入

    输出 = sigmoid(np.dot(input_layer, synaptic_weights))

    错误 = 训练输出 - 输出

    调整 = 误差 * sigmoid_derivative(输出)

    synaptic_weights += np.dot(input_layer.T,调整)

print(&#39;训练后的突触权重：&#39;)
打印（突触权重）

print(&#39;训练后的输出：&#39;)
打印（输出）


我希望它输出像 [0,1,0,0] 这样的结果，意思是 1 作为一个热编码。我不知道该怎么做。]]></description>
      <guid>https://stackoverflow.com/questions/77688349/how-can-i-make-a-one-neuron-neural-network</guid>
      <pubDate>Tue, 19 Dec 2023 22:33:45 GMT</pubDate>
    </item>
    <item>
      <title>我正在寻求建议来解决我创建的问题，我基本上是在优化花园的布局，但需要考虑许多因素[关闭]</title>
      <link>https://stackoverflow.com/questions/77688112/im-looking-for-advice-to-solve-a-problem-i-created-where-i-am-basically-optimiz</link>
      <description><![CDATA[假设我有一堆灌木丛，我为具有以下列名称的灌木丛创建一个数据集。
布什类型（或名称），
布什需要阳光，
需要灌木丛土壤，
布什高度，
衬套宽度（衬套直径），
布什值得注意的营养需求，
布什著名的营养提供（土壤），
布什昆虫吸引，
布什昆虫分散注意力，
ETC....
好吧，我想将这些灌木丛放在我使用 x、y、z 坐标创建的 3-D 地图上（我可以在其中给出湿度和土壤类型等坐标值），但我希望优化灌木丛的位置（基本上我正在尝试优化我的花园的布局）。
我的意思是，假设我住在北半球，所以我想要南方最短的灌木丛和北方最高的灌木丛，并且我想充分利用我的空间，所以如果有一个灌木丛很小并且不不需要太多阳光，那么我希望程序将其放置在另一个更高的灌木丛的叶子下，如果一个灌木丛吸引蚜虫，另一个灌木吸引瓢虫（瓢虫吃蚜虫），我想把它们放在彼此附近，并且相同根据营养需求，如果一棵灌木向土壤中添加了大量氮，那么我希望该程序将这些植物放置在一起。问题是程序需要考虑很多因素，我不知道如何让计算机进行这种优化，因为虽然一件事可能对两种植物昆虫有益，但它可能与土壤方面相反。我会想出一个每个列重要性的排名系统吗？我需要考虑的另一件事是，我可能只有一株这种类型的灌木，但我也可以拥有 12 株这种其他类型的灌木。这是我想知道的关于这个问题的信息：
这是什么类型的问题（比如我可以查找什么来了解人们如何处理类似的问题）以及我应该查看哪些资源来学习如何解决这样的问题？
我想做研究以了解如何最好地编码，所以任何建议都会非常有帮助！我是一名初学者编码员，只有一点点制作不同计算器的经验，并完成了基本的机器学习课程，只是为了让你们知道我在哪里。感谢您为我提供的任何帮助！
我尝试对优化思维主题进行研究，这将提供一些类似的场景，但它比这更深入，因此比我预期的更深。接下来我尝试思考，由于我对优化不太了解，我该如何解决这个问题，并且我决定考虑如何将我学到的机器学习知识应用到这个问题上，但这似乎并不可行就像无监督或监督机器学习的最佳应用一样。因此，我试图找到类似的问题，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77688112/im-looking-for-advice-to-solve-a-problem-i-created-where-i-am-basically-optimiz</guid>
      <pubDate>Tue, 19 Dec 2023 21:32:55 GMT</pubDate>
    </item>
    <item>
      <title>AWS Sagemaker/ML 操作</title>
      <link>https://stackoverflow.com/questions/77687831/aws-sagemaker-ml-ops</link>
      <description><![CDATA[我在尝试使用 AWS Sagemaker 端点进行推理时遇到 AWS 实例问题。我需要的图像 ml.g5.12xlargem 不在我的配额范围内。我需要这个，或者我的模型尺寸太大。当我开票时，他们只是告诉我使用当前的配额，但我没有现金可以浪费。
现在我在 Colab Notebook 中微调了 Llama-2-7b-chat，并手动将其上传到 s3 存储桶中。
有什么办法可以适当增加配额吗？致电 AWS Support 对您有用吗？我的s3存储桶包含model.tar.gz，可能格式不正确，因此太大。
解决方案可能是按照 Sagemaker Studio 中的说明进行部署：
https://aws.amazon.com/blogs/machine-learning/llama-2-foundation-models-from-meta-are-now-available-in-amazon-sagemaker-jumpstart/
但如果我不在 Sagemaker Studio 中进行训练，这是否可能：
https： //github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/llama-2-finetuning.ipynb
这可能有效，但重新训练需要时间。我仍然会遇到同样的问题，因为该实例不在我的配额内。
或者我应该使用不同的文本生成模型，称为 Phi-2。它的性能比 llama 2 稍好一些，是 2.7B 参数，比 7B Llama 模型少很多。它可能能够运行成本低得多且可用的计算。它需要迁移到 Azure AI Studio，并对功能进行完整的重新培训，以及学习曲线。

增加配额或减小模型大小的某种方法
在 Sagemaker studio 中以略有不同的方式训练和运行推理
使用不同的文本生成模型 (Phi-2)，并在 Azure AI Studio 中执行此操作（我计划在将来执行此操作，只有在必要时我才会立即执行此操作）
]]></description>
      <guid>https://stackoverflow.com/questions/77687831/aws-sagemaker-ml-ops</guid>
      <pubDate>Tue, 19 Dec 2023 20:26:02 GMT</pubDate>
    </item>
    <item>
      <title>新的 ML 模型具有较低的历元损失，但平均 RMSE 较高。如何/为什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77687730/new-ml-model-with-lower-epoch-loss-but-higher-average-rmse-how-why</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77687730/new-ml-model-with-lower-epoch-loss-but-higher-average-rmse-how-why</guid>
      <pubDate>Tue, 19 Dec 2023 20:04:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么 MLNet 没有得出合理的结论</title>
      <link>https://stackoverflow.com/questions/77687481/why-is-mlnet-not-coming-to-reasonable-conclusions</link>
      <description><![CDATA[我有一个模型，它目前基于合理的推理，然后对其进行测试来支持它。问题是预测多人游戏中的获胜者。
所以我希望使用一些机器学习来改进它。第一次尝试是做大小玩家的游戏，数据如下col0[标签],col1-col10[玩家一数据],col11-20[玩家二数据]...
数据是平衡的，因此每个类别的可能性与其他类别的可能性相同。
当样本用完时，这能够以 24% 的准确率进行预测，但问题是我知道，如果你只按每个玩家的第一个列排序，你会在样本中获得 27% 的准确率（并且你需要向你的老板为什么会这样）。我还知道所有其他数据都具有预测能力，可以解释原因并通过回归证明这一点，并且它们都在现实世界中发挥了与测试相同的准确性。
我尝试简化 MLNet 的问题，将其变成二元分类问题，并让它预测两个玩家的相对成功，数据再次平衡。这与第一列的执行方式几乎相同，但我可以看到它使用其他参数，如果我使用它们，我会得到比这产生的更好的结果。
经过几个小时的训练，我终于有了一个 6 人游戏的模型，它与第一个排序排序达到了同等水平，但我觉得我不能相信它，因为它无意中接触到了样本外的数据适者生存，淘汰在样本外表现不佳的模型。
我使用“Microsoft.ML”在本地运行了这个但我尝试过不同的自动化机器学习提供商 azure、amazon、google，但它们都未能产生更好的结果。当人们不断告诉我 ML 很棒，你可以向其扔数据，但就这个问题而言，它只是不如人类洞察力时，我是否遗漏了一些东西。
请注意，六人游戏有 1,000,000 条记录，我将其分解为两人游戏的 10,000,000 条记录。
关于提高性能有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77687481/why-is-mlnet-not-coming-to-reasonable-conclusions</guid>
      <pubDate>Tue, 19 Dec 2023 19:11:11 GMT</pubDate>
    </item>
    <item>
      <title>用于优化的多变量梯度上升问题</title>
      <link>https://stackoverflow.com/questions/77687410/problem-with-multivariable-gradient-ascent-for-optimization</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77687410/problem-with-multivariable-gradient-ascent-for-optimization</guid>
      <pubDate>Tue, 19 Dec 2023 18:56:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 LightGBM.LGBMRanker 执行交叉验证，同时将组保持在一起？</title>
      <link>https://stackoverflow.com/questions/77687360/how-to-perform-cross-validation-with-lightgbm-lgbmranker-while-keeping-groups-t</link>
      <description><![CDATA[我遇到了搜索问题，我有一个查询和网址数据集。对于给定的查询，每对（查询、网址）都有一个相关性（目标），即一个应保留网址顺序的浮点数。
我想对我的 lightgbm.LGBMRanker 模型进行交叉验证，目标为 ndcg。
我浏览了文档，发现将实例保留在同一个组中非常重要，因为实例实际上是一个包含所有关联 URL 的查询。
然而，我对此有一个问题，因为我收到以下错误：
ValueError: 计算 NDCG 仅当存在超过 1 个文档时才有意义。反而得到了1。

我使用了调试器，虽然我的数据集中没有任何大小小于 2 的组，但在 _feval 函数中我有较小的组，这意味着 cv() 函数实际上并未将组保持在一起。
在 lightgbm.cv 我看到没有 LGBMRanker。
但我可以看到函数 lightbm.cv 精确地指出通过参数传递的值优先于通过参数提供的值。我的理解是这个值被传递给cv函数的底层模型。
这是我到目前为止的代码：
def eval_model(
    自己，
    模型：lightgbm.LGBMRanker，
    k_fold: int = 3,
    种子：int = 42，
）：
    “”“”用 NDCG 进行评估“”“”

    def _feval(y_pred: np.ndarray, lgb_dataset: lightgbm.basic.Dataset):
        y_true = lgb_dataset.get_label()
        serp_sizes = lgb_dataset.get_group()

        ndcg_值 = []
        开始=0
        对于 serp_sizes 中的大小：
            结束=开始+大小
            y_true_serp, y_pred_serp = y_true[开始:结束], y_pred[开始:结束]
            ndcg_serp = sklearn.metrics.ndcg_score(
                [y_true_serp]，[y_pred_serp]，k=10
            ）
            ndcg_values.append(ndcg_serp)
            开始=结束

        eval_name =“my-ndcg”；
        eval_result = np.mean(ndcg_values)
        更大更好=真
        返回 eval_name、eval_result、greater_is_better

    lgb_dataset = lightgbm.Dataset(data=self.X, label=self.y, group=self.serp_sizes)
    cv_结果 = lightgbm.cv(
        params={**model.get_params(), &quot;group&quot;: self.serp_sizes},
        train_set=lgb_dataset,
        num_boost_round=1_000,
        nfold=k_fold,
        分层=假，
        种子=种子，
        费瓦尔=_费瓦尔,
    ）
    ndcg = np.mean(cv_results[“my-ndcg”])

    返回 NDCG

我的错误/误解在哪里？
是否有一个简单的解决方法可以使用 lightgbm.LGBMRanker 执行交叉验证，并将组保持在一起？]]></description>
      <guid>https://stackoverflow.com/questions/77687360/how-to-perform-cross-validation-with-lightgbm-lgbmranker-while-keeping-groups-t</guid>
      <pubDate>Tue, 19 Dec 2023 18:47:13 GMT</pubDate>
    </item>
    <item>
      <title>python中的矩阵乘法以获得成本函数[关闭]</title>
      <link>https://stackoverflow.com/questions/77686666/matrix-multiplication-in-python-to-get-cost-function</link>
      <description><![CDATA[谁能告诉我为什么我的代码给出了错误的输出？
评论的是我的。
# 分级函数：cofi_cost_func
#UNQ_C1

def cofi_cost_func(X, W, b, Y, R, lambda_):
    ”“”
    返回基于内容的过滤的成本
    参数：
      X (ndarray (num_movies,num_features))：项目特征矩阵
      W (ndarray (num_users,num_features)) ：用户参数矩阵
      b (ndarray (1, num_users) ：用户参数向量
      Y (ndarray (num_movies,num_users) ：电影用户评分矩阵
      R (ndarray (num_movies,num_users) ：矩阵，其中 R(i, j) = 1 如果第 i 个电影由第 j 个用户评分
      lambda_ (float): 正则化参数
    返回：
      J（浮点数）：成本
    ”“”
    nm, nu = Y.shape
    J = 0
    ### 从这里开始代码 ###
    
# J+= np.sum(np.square((R*(X@(W.T)+b)-Y)))/2
# J+= (lambda_/2)*np.sum(np.square(W))
# J+= (lambda_/2)*np.sum(np.square(X))
        
    对于 j 在范围内（nu）：
        w = W[j,:]
        b_j = b[0,j]
        对于范围内的 i（nm）：
            x = X[i,:]
            y = Y[i,j]
            r = R[i,j]
            J += np.square(r * (np.dot(w,x) + b_j - y ) )
    J = J/2
    J += (lambda_/2) * (np.sum(np.square(W)) + np.sum(np.square(X)))
            
            
            
    
    
    ### 在此结束代码 ###

    返回J

我不知道为什么使用我的成本函数代码测试会失败，我只是尝试在不使用循环的情况下做同样的事情。
 J+= np.sum(np.square((R*(X@(W.T)+b)-Y)))/2
    J+= (lambda_/2)*np.sum(np.square(W))
    J+= (lambda_/2)*np.sum(np.square(X))
]]></description>
      <guid>https://stackoverflow.com/questions/77686666/matrix-multiplication-in-python-to-get-cost-function</guid>
      <pubDate>Tue, 19 Dec 2023 16:34:22 GMT</pubDate>
    </item>
    <item>
      <title>机器学习后指标结果相同的问题</title>
      <link>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</guid>
      <pubDate>Tue, 19 Dec 2023 15:36:36 GMT</pubDate>
    </item>
    <item>
      <title>有什么想法可以让 scikit 学得更快吗？它不断使内核崩溃</title>
      <link>https://stackoverflow.com/questions/77686255/any-ideas-how-to-make-scikit-learn-faster-it-keeps-crashing-the-kernel</link>
      <description><![CDATA[我的内核在这个单元格中不断死亡：
hyper_params = {&#39;outlier_neighbors&#39;:3, &#39;base_lambda&#39;:1e9, &#39;base_p&#39;:0.0005, &#39;smoothing_window&#39;:2,&#39;smoothing_order&#39;:1,
                &#39;diff_ma_window&#39;：2，&#39;diff_rhl_window&#39;：2，&#39;eps&#39;：0.001，&#39;ms&#39;：2，&#39;regress_portion&#39;：（0,1）}
#parameters 我建议采样频率为 1 分钟的数据

outlier_neighbors = hyper_params[&#39;outlier_neighbors&#39;]
base_lambda = hyper_params[&#39;base_lambda&#39;]
base_p = hyper_params[&#39;base_p&#39;]
smoothing_window = hyper_params[&#39;smoothing_window&#39;]
smoothing_order = hyper_params[&#39;smoothing_order&#39;]
diff_ma_window = hyper_params[&#39;diff_ma_window&#39;]
diff_rhl_window = hyper_params[&#39;diff_rhl_window&#39;]

污染物 = &#39;CO2&#39; #此处指定浓度时间序列的列名称
date_time = &#39;日期/时间&#39; #and 用于您的时间戳列

有没有办法让 scikit learn 库运行得更快或更有效，这样就不会杀死内核？]]></description>
      <guid>https://stackoverflow.com/questions/77686255/any-ideas-how-to-make-scikit-learn-faster-it-keeps-crashing-the-kernel</guid>
      <pubDate>Tue, 19 Dec 2023 15:22:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Matlab 中从线性 SVM 导出权重和偏移量 [关闭]</title>
      <link>https://stackoverflow.com/questions/77685684/how-to-derive-weights-and-offsets-from-linear-svm-in-matlab</link>
      <description><![CDATA[Matlab训练的线性SVM模型如下：
阿尔法
测试版
偏差
穆
西格玛
支持向量
支持向量标签
请问如何使用上述参数来计算超平面的权重和偏移？
超平面：f(x) = 符号((w,x) + b)]]></description>
      <guid>https://stackoverflow.com/questions/77685684/how-to-derive-weights-and-offsets-from-linear-svm-in-matlab</guid>
      <pubDate>Tue, 19 Dec 2023 13:52:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Hubert 模型获得音频嵌入</title>
      <link>https://stackoverflow.com/questions/77685045/how-to-get-audio-embeddings-using-hubert-model</link>
      <description><![CDATA[示例代码
进口火炬
从变压器导入 Wav2Vec2Processor、HubertForCTC
从数据集导入load_dataset

处理器 = Wav2Vec2Processor.from_pretrained(“facebook/hubert-large-ls960-ft”)
模型 = HubertForCTC.from_pretrained(“facebook/hubert-large-ls960-ft”)
input_values = 处理器(&#39;来自音频文件的数组。, return_tensors=“pt”).input_values


之后如何获得嵌入？模型中没有最后一个隐藏状态。
尝试了我提到的代码块，此外，尝试创建没有最后一层的模型，然后将其提供给输入。我的另一个问题是，假设我有不同时间维度的剪辑，那么如何创建固定嵌入。是沿着时间轴平均还是需要不同的方法。]]></description>
      <guid>https://stackoverflow.com/questions/77685045/how-to-get-audio-embeddings-using-hubert-model</guid>
      <pubDate>Tue, 19 Dec 2023 12:04:19 GMT</pubDate>
    </item>
    <item>
      <title>如何为此笔记本创建 Sagemaker 端点？</title>
      <link>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-notebook</link>
      <description><![CDATA[我创建了一个 VectorDB (FAISS) 并将 PDF 输入到其中。然后我使用 AWS Bedrock 的 Langchain 包装器来调用它。我知道现在存在 Kowledge Base，但至少在 SageMaker 笔记本中，我有更多的控制权。该模型在 SageMaker Notebook 中完美运行，当我提出问题时，它会返回答案。
我想做的是创建一个小网页（并通过 HTTP/REST API），只需在文本字段中提交问题并在文本字段中接收答案。我猜如果链中某个地方没有 Lambda 函数，这很难做到，或者也许不是？
当我查看 Sagemaker 控制台的推理选项卡下时，没有模型或没有端点，或者没有&lt; /strong&gt; 端点配置（因为我没有从 Sagemaker 选择模型，所以我只是在 Python 笔记本中使用 langchain LLM 和 Bedrock，如下所示）。
&lt;前&gt;&lt;代码&gt;导入boto3
导入 json

bedrock = boto3.client(service_name=&quot;bedrock&quot;)
bedrock_runtime = boto3.client(service_name=“bedrock-runtime”)



从 langchain.llms.bedrock 导入 Bedrock
从 langchain.chains 导入 RetrievalQA
从 langchain.prompts 导入 PromptTemplate

嵌入 = BedrockEmbeddings(model_id=“amazon.titan-embed-text-v1”,
                               客户端=bedrock_runtime）

最终我将文档嵌入到 FAISS Vector 数据库中，我查询的就是这个数据库
db = FAISS.from_documents（文档，嵌入）


模型泰坦 = {
    “最大令牌计数”：512，
    “停止序列”：[]，
    “温度”：0.0，
    “顶部P”：0.5
}

# 亚马逊泰坦模型
llm = 基岩(
    model_id=&quot;amazon.titan-text-express-v1&quot;,
    客户端=bedrock_runtime，
    model_kwargs=model_titan,
）

然后定义一个提示......
提示 = 提示模板(
    template=prompt_template, input_variables=[“上下文”, “问题”]
）

并查询数据库：
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type=“东西”，
    检索器=db.as_retriever(
        search_type=“相似度”，
    ),
    return_source_documents=真，
    chain_type_kwargs={“提示”: 提示},
）



query =“未来的技术是什么样的？”

结果 = qa({“查询”: 查询})

print(f&#39;查询: {结果[“查询”]}\n&#39;)
print(f&#39;结果: {结果[“结果”]}\n&#39;)
print(f&#39;上下文文档：&#39;)
对于结果 [“source_documents”] 中的 srcdoc：
      打印（f&#39;{srcdoc}\n&#39;）

这恰好返回了我在 Sagemaker 中需要的内容，我只需要从外部查询数据库即可。
我不想让 lambda 函数每次都重建链。我考虑的是效率，我需要的只是在 lambda 函数中传递查询并返回结果。]]></description>
      <guid>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-notebook</guid>
      <pubDate>Thu, 14 Dec 2023 14:49:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使用分类变量运行聚类</title>
      <link>https://stackoverflow.com/questions/52401225/how-to-run-clustering-with-categorical-variables</link>
      <description><![CDATA[我尝试仅使用分类变量运行聚类。由于 Kmeans 仅适用于数值数据，是否有可用的聚类技术？
我有 30 个变量，如邮政编码、年龄组、爱好、首选频道、婚姻状况、信用风险（低、中、高）、教育状况等。如果我将每个变量转换为虚拟变量并运行 kmeans，我将有 90 列（30*3 - 假设每个变量有 4 个因子）。这是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/52401225/how-to-run-clustering-with-categorical-variables</guid>
      <pubDate>Wed, 19 Sep 2018 08:16:04 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中参数、特征和类之间的区别</title>
      <link>https://stackoverflow.com/questions/35819869/difference-between-parameters-features-and-class-in-machine-learning</link>
      <description><![CDATA[我是机器学习和自然语言处理方面的新手。
我总是对这三个术语感到困惑？
据我了解：
class：我们的模型输出的各种类别。给出一个人的名字，确定他/她是男性还是女性？
假设我正在使用朴素贝叶斯分类器。
我的功能和参数是什么？
此外，上述单词的一些可互换使用的别名是什么？]]></description>
      <guid>https://stackoverflow.com/questions/35819869/difference-between-parameters-features-and-class-in-machine-learning</guid>
      <pubDate>Sat, 05 Mar 2016 21:02:05 GMT</pubDate>
    </item>
    </channel>
</rss>