<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 11 May 2024 21:13:15 GMT</lastBuildDate>
    <item>
      <title>是否可以根据熟练程度/复杂性对文本进行有效分类？</title>
      <link>https://stackoverflow.com/questions/78465977/is-it-possible-to-efficiently-classify-text-based-on-proficiency-complexity</link>
      <description><![CDATA[我目前正在开发一个项目，该项目需要一个包含大量文本的数据集，这些文本带有标记的文本复杂性/熟练程度、5/6 不同的复杂性级别。我尝试了多种方法，例如 API、可读性公式、搜索现有数据集等。但似乎没有任何效果。
我正在寻找基本文本，例如“她参观动物园”。她看到了很多动物。”，到精通的文本，例如：“他对行为经济学的深入研究细致地研究了影响消费者行为的认知偏差的复杂动态，提出了先进的预测模型来提高预测消费者购买模式的准确性。”&lt; /p&gt;
有人熟悉标记大量文本（50,000-100,000）吗？
如前所述，我尝试使用 API、可读性公式和现有数据集。但似乎没有任何作用。我无法使用任何模型，因为我没有数据集，这就是问题所在。]]></description>
      <guid>https://stackoverflow.com/questions/78465977/is-it-possible-to-efficiently-classify-text-based-on-proficiency-complexity</guid>
      <pubDate>Sat, 11 May 2024 20:11:08 GMT</pubDate>
    </item>
    <item>
      <title>构建分类模型后，如何在数据集中不指定对象定位的情况下执行对象/异常定位？</title>
      <link>https://stackoverflow.com/questions/78465357/how-to-perform-object-anomaly-localization-after-building-a-classification-model</link>
      <description><![CDATA[我已经使用 EfficientNetB4 成功构建了一个分类模型，该模型可以高精度地将医学图像分类为各种类别。现在，我想本地化并提取这些图像中的感兴趣区域（异常），而无需在数据集中添加明确的本地化注释。
我接触过 Grad-CAM、CAM 和引导反向传播等多种技术，但在正确实施它们时遇到了困难。以下是我的设置的简要概述：
模型架构：EfficientNetB4 具有用于分类的附加密集层。
分类准确度：非常高，因此模型区分类别的能力不是问题。
目标：可视化并提取模型用于预测的区域（异常）。
**
我的问题：**
在这种情况下，异常定位的最佳技术是什么？有没有特别适合医学图像的方法？
如何在 TensorFlow/Keras 中实现这些技术？任何示例代码或详细步骤将不胜感激。
在尝试使用这些技术可视化和提取异常时，我应该注意哪些常见陷阱？
**我尝试过的：
**实施 Grad-CAM，但在与我的 EfficientNetB4 模型集成时面临形状不匹配问题。
尝试展平图层并调整输入形状，但仍然遇到错误。]]></description>
      <guid>https://stackoverflow.com/questions/78465357/how-to-perform-object-anomaly-localization-after-building-a-classification-model</guid>
      <pubDate>Sat, 11 May 2024 16:35:06 GMT</pubDate>
    </item>
    <item>
      <title>CreateML 超参数</title>
      <link>https://stackoverflow.com/questions/78465196/createml-hyperparameters</link>
      <description><![CDATA[我尝试为 S&amp;P500 指数中的每只股票创建一些机器学习模型。使用 sklearn（提升树模型）创建模型时，我尝试通过使用 GridSearchCV 执行超参数来使其更成功。创建一种模型需要很长时间，因此我不想考虑创建所有股票模型。我尝试使用 CreateML 和 swift，但看起来它比 python 上的 sklearn 运行时间更长。我的问题是如何使该过程更快？ swift 上的 CreateML 上是否有任何超参数（我在文档中找不到它）以及如何在我的 GPU 上运行此代码？ （应该快得多）。
我对任何想法持开放态度，在 GPU 上运行整个 python，只运行 hyperopt params 部分，或者在 CreateML 中快速创建模型。
我有 MacBook Pro M2]]></description>
      <guid>https://stackoverflow.com/questions/78465196/createml-hyperparameters</guid>
      <pubDate>Sat, 11 May 2024 15:36:45 GMT</pubDate>
    </item>
    <item>
      <title>计算伯杰方程函数时出现错误</title>
      <link>https://stackoverflow.com/questions/78464990/error-in-calculating-the-function-of-bergers-equations</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;#burger
defsolve_burgers(X, t, nu):
  定义 f(y):
    返回 torch.exp(-torch.cos(np.pi * y) / (2 * np.pi * nu))
  定义 g(y):
    返回 np.exp(-(y**2) / (4 * nu * t))
  定义乐趣（eta）：
    return torch.sin(np.pi * (x - eta)) * f(x - eta) * g(eta)
  def fun1(eta):
    返回 f(x - eta) * g(eta)
  U = np.zeros_like(X)
  对于范围内的 i(len(X))：
    x = X[[[i]]]
    如果 np.abs(x) != 1:
      uxt = -quad(fun, -np.inf, np.inf)[0] # 使用quad进行积分
      U[i] = uxt /quad(fun1, -np.inf, np.inf)[0]
     # print(&quot;uxt= &quot;,uxt)
  返回U

伯杰方程是根据以下文章求解的。我实现了这个解决方案，但我认为答案是错误的，例如，在t=0 25的时刻，答案总是从0开始，并且有增加的趋势，这不符合逻辑。我不知道为什么计算是正确完成
我需要你提前帮忙。非常感谢。
论文：C. BASDEVANT、M. DEVILLE、P. HALDENWANG、J. M. LACROIX、J. OUAZZANI、R. PEYRET、P. ORLANDI、
A. T. PATERA，“伯格斯方程的光谱和有限差分解”，]]></description>
      <guid>https://stackoverflow.com/questions/78464990/error-in-calculating-the-function-of-bergers-equations</guid>
      <pubDate>Sat, 11 May 2024 14:33:14 GMT</pubDate>
    </item>
    <item>
      <title>预测保证金永远不会给出负值</title>
      <link>https://stackoverflow.com/questions/78464909/predictive-margin-never-gives-negative-values</link>
      <description><![CDATA[我正在使用 Jupyter Notebook 来做随机森林分类模型。模型完成后，我希望它计算并打印预测裕度，它确实做到了，但没有实例的预测裕度为负。
我使用了以下行：
margins_new_data = np.max(proba_values, axis=1) - np.partition(proba_values, -2, axis=1)[:, -2]
从概念上讲，我将预测裕度理解为 1 到 -1 之间的数字，有助于确定模型在预测特定实例时的信心程度（1 表示完全有信心，-1 表示完全没有信心）。
我是否使用了错误的线条或者我误解了这个概念？]]></description>
      <guid>https://stackoverflow.com/questions/78464909/predictive-margin-never-gives-negative-values</guid>
      <pubDate>Sat, 11 May 2024 14:06:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 python spacy 模块的词向量显示错误</title>
      <link>https://stackoverflow.com/questions/78464557/word-vectors-using-spacy-module-of-python-showing-error</link>
      <description><![CDATA[我正在尝试使用 python 的 spacy 模块获取词向量，并使用 en_core_web_lg 创建词向量。
从 sklearn.feature_extraction.text 导入 CountVectorizer
从 sklearn.feature_extraction.text 导入 TfidfVectorizer

tfidf=TfidfVectorizer(小写=False)

df1[&#39;问题1&#39;]=df1[&#39;问题1&#39;].apply(lambda x : str(x))
df1[&#39;问题2&#39;]=df1[&#39;问题2&#39;].apply(lambda x : str(x))

tot_ques=列表(df1[&#39;问题1&#39;]) + 列表(df1[&#39;问题2&#39;])

tfidf.fit(tot_ques)

idfscore=dict(zip(tfidf.get_feature_names_out(),tfidf.idf_))
打印（idf分数）

从 tqdm 导入 tqdm
导入spacy
nlp=spacy.load(&#39;en_core_web_lg&#39;)

向量1 = []
# 迭代每个问题1
对于 tqdm(list(df1[&#39;question1&#39;])) 中的 qu1：
doc1 = nlp（qu1）

# 初始化向量总和以及 IDF 总得分
sum_vec = np.zeros(len(doc1[0].vector)) # 第一个单词的向量维度
Total_idf = 0.0 # 初始化IDF总分

# 遍历句子中的每个单词
对于 doc1 中的单词：
    vec = 词.向量
    
    # 计算单词的IDF分数
    尝试：
        idf = idfscore(str(单词))
    除了：
        idf = 0.0
    
    # 累加词向量的加权和
    sum_vec += vec * idf
    
    # 累计IDF总分
    总计 idf += idf

# 如果 IDF 总得分不为零，则计算均值向量
如果total_idf！= 0：
    平均向量 = 向量总和 / 总 idf
别的：
    mean_vec = sum_vec # 如果总 IDF 为零，则回退到 sum_vec

# 将均值向量附加到 vec1
vec1.append(mean_vec)

# 将计算出的向量分配给数据框中的新列“q1”
df1[&#39;q1&#39;] = vec1`

但是当我查看 q1 列的值时，每行都显示 0。]]></description>
      <guid>https://stackoverflow.com/questions/78464557/word-vectors-using-spacy-module-of-python-showing-error</guid>
      <pubDate>Sat, 11 May 2024 12:13:25 GMT</pubDate>
    </item>
    <item>
      <title>Inception 在 isic 数据集中给出的准确度非常低</title>
      <link>https://stackoverflow.com/questions/78464120/inception-gives-verylow-accuracy-in-isic-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78464120/inception-gives-verylow-accuracy-in-isic-dataset</guid>
      <pubDate>Sat, 11 May 2024 09:44:43 GMT</pubDate>
    </item>
    <item>
      <title>有序 Logit 回归的预测如何工作？</title>
      <link>https://stackoverflow.com/questions/78461070/how-does-prediction-for-ordered-logit-regression-work</link>
      <description><![CDATA[我正在学习有序 logit 回归，我想知道预测在数学上是如何工作的以及我如何自己在 python 中完成它。我知道在 python 中我可以简单地使用预测，但我想知道如何仅使用 model.summary() 中的 coef 进行预测。
导入 pandas 作为 pd
从 statsmodels.miscmodels.ordinal_model 导入 OrderedModel


数据 = pd.DataFrame({
    ‘分数’: [3.2, 4.5, 5.6, 6.7, 7.8, 8.9, 9.1],
    “评级”：[1,2,3,4,5,6,6]
})

X = 数据[[&#39;分数&#39;]]
y = 数据[&#39;评级&#39;]


ordinal_model = OrderedModel(y, X, distr=&#39;logit&#39;)


ordinal_results = ordinal_model.fit(method=&#39;bfgs&#39;)


打印（ordinal_results.summary（））


结果是：
时间：17:05:52
观察次数：7
Df 残差：1
DF型号：1
=================================================== ===========================
                 coef std err z P&gt;|z| [0.025 0.975]
-------------------------------------------------- ----------------------------
得分 66.3902 5669.125 0.012 0.991 -1.1e+04 1.12e+04
1/2 285.5835 2.56e+04 0.011 0.991 -4.98e+04 5.04e+04
2/3 4.2698 88.656 0.048 0.962 -169.493 178.032
3/4 4.1879 155.834 0.027 0.979 -301.241 309.617
4/5 4.3867 136.765 0.032 0.974 -263.668 272.442
5/6 3.4706 220.734 0.016 0.987 -429.161 436.102
=================================================== ===========================

使用 coef 向量如何获得与中相同的输出
ordinal_results.model.predict(ordinal_results.params, exog = (4.3))

&lt;预&gt;&lt;代码&gt;[[0.5264086 0.4735914 0.0.0.0.]]


我认为我应该对 coef 和新数据的线性和使用 softmax，但这不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78461070/how-does-prediction-for-ordered-logit-regression-work</guid>
      <pubDate>Fri, 10 May 2024 15:16:52 GMT</pubDate>
    </item>
    <item>
      <title>我做了什么？ :) 迁移学习方法分类所需的帮助</title>
      <link>https://stackoverflow.com/questions/78460958/what-have-i-done-help-needed-in-classifying-a-transfer-learning-approach</link>
      <description><![CDATA[我想我有一些菜鸟问题，但是，我正在尝试对方法进行分类。
在这些方法的情况下，一组特征 A（源域？）通过数值方法转换为一组特征 B（目标域）。在具体情况下，这些特征是在荷载下具有预曲率的梁 (A) 和直梁 (B) 的中心线位置矢量。我有数值方法将预曲梁的中心线位置数据转换为直梁。转换后，接受过直梁训练的学习器正在估计输入数据的负载。
它是什么样的迁移学习？
我倾向于将其称为基于映射，但在文献中我发现了三个类别：

即时
基于功能
基于模型
基于关系

我假设在将数据提供给例如之前转换数据神经网络将是基于特征的。
或者我完全一无所知，这不被认为是迁移学习。
我很高兴得到你的帮助。
提前致谢并欢呼。]]></description>
      <guid>https://stackoverflow.com/questions/78460958/what-have-i-done-help-needed-in-classifying-a-transfer-learning-approach</guid>
      <pubDate>Fri, 10 May 2024 14:55:52 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：反序列化类“BatchNormalization”时出错</title>
      <link>https://stackoverflow.com/questions/78460953/typeerror-error-when-deserializing-class-batchnormalization</link>
      <description><![CDATA[TypeError：使用 config={&#39;name&#39;: &#39;bn_conv1&#39;, &#39;trainable&#39;: False, &#39;momentum&#39;: 0.99, &#39;epsilon&#39;: 1e-05, &#39;center&#39; 反序列化类 &#39;BatchNormalization&#39; 时出错: True, &#39;scale&#39;: True, &#39;beta_initializer&#39;: {&#39;class_name&#39;: &#39;Zeros&#39;, &#39;config&#39;: {}}, &#39;gamma_initializer&#39;: {&#39;class_name&#39;: &#39;Ones&#39;, &#39;config&#39;: {}} , &#39;moving_mean_initializer&#39;: {&#39;class_name&#39;: &#39;零&#39;, &#39;config&#39;: {}}, &#39;moving_variance_initializer&#39;: {&#39;class_name&#39;: &#39;Ones&#39;, &#39;config&#39;: {}}, &#39;beta_regularizer&#39;: 无, &#39; gamma_regularizer&#39;：无，&#39;beta_constraint&#39;：无，&#39;gamma_constraint&#39;：无，&#39;freeze&#39;：True}。

遇到异常：无法识别的关键字参数传递给 BatchNormalization：{&#39;freeze&#39;: True}

这是我在使用 ImageAI 对象检测时遇到的问题。
我真的不知道该怎么办，所以我会尝试你所说的一切。谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78460953/typeerror-error-when-deserializing-class-batchnormalization</guid>
      <pubDate>Fri, 10 May 2024 14:55:08 GMT</pubDate>
    </item>
    <item>
      <title>损失值不断波动，MLP模型的一般问题</title>
      <link>https://stackoverflow.com/questions/78458260/the-value-of-loss-is-keeping-fluctuating-questions-about-mlp-model-in-general</link>
      <description><![CDATA[我正在为 ML 内容构建 MLP 模型，我对模型输出有一个基本问题。
这是我的源代码和结果
纪元 = 50
对于范围内的纪元（纪元）：
    对于输入，train_loader 中的标签：
        输出 = 模型（输入）
        损失=标准（输出，标签）

        优化器.zero_grad()
        loss.backward()
        优化器.step()

    loss_values.append(loss.item())
    print(f&#39;Epoch {epoch + 1}/{epochs}, 损失: {loss.item()}&#39;)

纪元 1/50，损失：0.2941759526729584
纪元 2/50，损失：0.2274172008037567
纪元 3/50，损失：0.1548108160495758
纪元 4/50，损失：0.09923569858074188
纪元 5/50，损失：0.07782179117202759
纪元 6/50，损失：0.08670808374881744
纪元 7/50，损失：0.1000475212931633
纪元 8/50，损失：0.08599527180194855
纪元 9/50，损失：0.06509505957365036
纪元 10/50，损失：0.0660080686211586
纪元 11/50，损失：0.07633966952562332
纪元 12/50，损失：0.06544400751590729
纪元 13/50，损失：0.07453220337629318
纪元 14/50，损失：0.0681438073515892
纪元 15/50，损失：0.07069016247987747
纪元 16/50，损失：0.05649592727422714
纪元 17/50，损失：0.05515648424625397
纪元 18/50，损失：0.05455780029296875
纪元 19/50，损失：0.06591354310512543
20/50 纪元，损失：0.06227065622806549
纪元 21/50，损失：0.050895411521196365
纪元 22/50，损失：0.05813339725136757
纪元 23/50，损失：0.05856814980506897
纪元 24/50，损失：0.056620728224515915
纪元 25/50，损失：0.05406007170677185
纪元 26/50，损失：0.05851085111498833
纪元 27/50，损失：0.04691702872514725
纪元 28/50，损失：0.036375436931848526
纪元 29/50，损失：0.043669767677783966
纪元 30/50，损失：0.047907356172800064
纪元 31/50，损失：0.04583781585097313
纪元 32/50，损失：0.044408515095710754
纪元 33/50，损失：0.04572493955492973
纪元 34/50，损失：0.0413966178894043
纪元 35/50，损失：0.047711536288261414
纪元 36/50，损失：0.046094246208667755
纪元 37/50，损失：0.03935185819864273
纪元 38/50，损失：0.036376748234033585
纪元 39/50，损失：0.04275327920913696
纪元 40/50，损失：0.04050033539533615
纪元 41/50，损失：0.03928723931312561
纪元 42/50，损失：0.038021307438611984
纪元 43/50，损失：0.039322346448898315
纪元 44/50，损失：0.03544142469763756
纪元 45/50，损失：0.03906610235571861
纪元 46/50，损失：0.03384337201714516
纪元 47/50，损失：0.040965259075164795
纪元 48/50，损失：0.038688428699970245
纪元 49/50，损失：0.041332412511110306
纪元 50/50，损失：0.03592131659388542

在此处输入图片描述
正如您所看到的，损失值总体上持续下降，但在某些点上仍然存在波动。这是我第一次构建 MLP 模型，因此我没有任何可以比较的经验。是正常现象吗？应该是在没有波动的情况下减少，还是波动很小很正常？
这是正常现象吗？应该是在没有波动的情况下减少，还是波动很小很正常？]]></description>
      <guid>https://stackoverflow.com/questions/78458260/the-value-of-loss-is-keeping-fluctuating-questions-about-mlp-model-in-general</guid>
      <pubDate>Fri, 10 May 2024 05:54:58 GMT</pubDate>
    </item>
    <item>
      <title>用最少层数训练绝对函数的神经网络</title>
      <link>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</link>
      <description><![CDATA[我正在尝试训练神经网络来学习 y = |x|功能。我们知道，绝对函数有两条不同的线在零点处相互连接。所以我尝试使用以下顺序模型：
隐藏层：
2 致密层（激活relu）
输出层：
1 致密层
训练模型后，它只拟合函数的一半边。大多数时候是右手边，有时是左手边。一旦我在隐藏层中再添加 1 层，那么我就用 3 层代替 2 层，它就完全符合该功能了。谁能解释为什么当绝对函数只有一次切割时需要额外的一层？
这是代码：
将 numpy 导入为 np


X = np.linspace(-1000,1000,400)
np.random.shuffle(X)
Y = np.abs(X)

# 重塑数据以适应模型输入
X = X.reshape(-1, 1)
Y = Y.重塑(-1, 1)

将张量流导入为 tf
将张量流导入为 tf
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt

# 构建模型
模型 = tf.keras.models.Sequential([
    tf.keras.layers.Dense(2, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(1)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;])
model.fit(X, Y, epochs=1000)
# 使用模型进行预测
Y_pred = model.predict(X)

# 绘制结果
plt.scatter(X, Y, color=&#39;blue&#39;, label=&#39;实际&#39;)
plt.scatter(X, Y_pred, color=&#39;red&#39;, label=&#39;预测&#39;)
plt.title(&#39;实际与预测&#39;)
plt.xlabel(&#39;X&#39;)
plt.ylabel(&#39;Y&#39;)
plt.图例()
plt.show()

2 个密集层的绘图：

3 个密集层的绘图：
]]></description>
      <guid>https://stackoverflow.com/questions/78311513/train-neural-network-for-absolute-function-with-minimum-layers</guid>
      <pubDate>Thu, 11 Apr 2024 15:34:01 GMT</pubDate>
    </item>
    <item>
      <title>Pycharm 调试不适用于 Tensorflow。我该如何解决？</title>
      <link>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</link>
      <description><![CDATA[我已成功安装以下内容：
tensorflow（最新版本2.16.1）
keras（最新版本3.1.1

我使用的是pycharm 2023.3.5（社区版）。我有一些导入的代码行，包括张量流：
&lt;前&gt;&lt;代码&gt;...
从tensorflow.keras导入后端为K
...

每当我调试代码时，都会收到如下错误：
回溯（最近一次调用最后一次）：
文件“C:\Program Files\JetBrains\PyCharm Community Edition 2023.3.5\plugins\python-ce\helpers\pydev\_pydevd_bundle\pydevd_xml.py”，第 177 行，在 _get_type 中
if isinstance(o, t[0]):
   ^^^^^^^^^^^^^^^^^^^^
文件“C:\Program Files\Python312\Lib\site-packages\tensorflow\python\platform\flags.py”，第 73 行，在 __getattribute__ 中
返回 self.__dict__[&#39;__wrapped&#39;].__getattribute__(name)
       ~~~~~~~~~~~~~^^^^^^^^^^^^^
关键错误：&#39;__wrapped&#39;

我想相信问题不是由张量流引起的，但我似乎无法弄清楚确切的问题。我已经上网但无济于事。我得到的最接近的解决方案是这个 问题，但是，它似乎我作为一个不同的问题。请这个崇高平台上的博学之士来帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</guid>
      <pubDate>Fri, 29 Mar 2024 03:17:26 GMT</pubDate>
    </item>
    <item>
      <title>作为开发人员如何利用 Apple Silicon/M1 处理器上的神经引擎？</title>
      <link>https://stackoverflow.com/questions/69983492/how-to-leverage-the-neural-engine-on-apple-silicon-m1-processors-as-a-developer</link>
      <description><![CDATA[我正在努力在 SO、Google 或 Apple 的开发者文档中找到这个问题的答案。
Apple 是否为任何语言提供 API，允许开发者在 macOS 上利用新型 M1 芯片的神经引擎？
搜索Apple的开发者文档，可以找到Metal Performance Shaders库中的很多函数，似乎使用了GPU加速。
使用标签搜索SO apple-m1 或 apple-silicon 和关键字“neural”没有提供任何有用的东西。
在 r/AppleDevelopers 中搜索“神经”结果什么也没发现。
我认为必须有一些关于如何使用神经核心进行开发的信息。这些内核仅适用于 Apple 开发者和商业合作伙伴吗？]]></description>
      <guid>https://stackoverflow.com/questions/69983492/how-to-leverage-the-neural-engine-on-apple-silicon-m1-processors-as-a-developer</guid>
      <pubDate>Tue, 16 Nov 2021 03:38:01 GMT</pubDate>
    </item>
    <item>
      <title>混淆矩阵错误：错误：“数据”和“参考”应该是具有相同级别的因素</title>
      <link>https://stackoverflow.com/questions/56995048/confusion-matrix-error-error-data-and-reference-should-be-factors-with-the</link>
      <description><![CDATA[我目前正在尝试构建一个神经网络来预测人们在数据中的排名。 
等级系统为：A、B、C、D、E
一切都运行得非常顺利，直到我到达我的混淆矩阵。我收到错误“错误：data 和 reference 应该是具有相同级别的因素。”。我在其他帖子中尝试了许多不同的方法，但似乎都不起作用。
NNPredictions 和 test$Rank 中的级别相同。我用 table() 检查了它们。
库（readxl）
库（插入符号）
图书馆（神经网络）
库（预测）
图书馆（tidyverse）
库（ggplot2）



间接 &lt;-read_excel(&quot;C:/Users/Abdulazizs/Desktop/Projects/Indirect/FIltered Indirect.xlsx&quot;,
    n_最大 = 500)

间接$Direct_or_Indirect &lt;- NULL


间接$parentaccount &lt;- NULL


sum(is.na(间接))


计数 &lt;- 表（间接$排名）



条形图（计数）

总结（计数）



第 2 部分 &lt;- createDataPartition(Indirect$Rank, ti​​mes = 1, p = .8, list = FALSE, groups = min(5, length(Indirect$Rank)))

火车 &lt;- 间接[part2, ]
测试 &lt;- 间接[-part2, ]

设置.种子(1234)

TrainingParameters &lt;- trainControl(方法 = &quot;repeatedcv&quot;, 数量 = 10, 重复 = 10)

as.data.frame(火车)
as.data.frame(测试)

NNModel &lt;- 训练(训练[,-7], 训练$Rank,
                  方法=“nnet”，
                  trControl= 训练参数，
                  预处理=c(&quot;尺度&quot;,&quot;中心&quot;),
                  na.action = na.omit
）

NNPredictions &lt;-预测（NNModel，测试，类型=“原始”）



摘要（NN预测）





fusionMatrix(NNPredictions, 测试$Rank)

长度（NN预测）
长度（测试$排名）

&lt;块引用&gt;
  长度（NN预测）
  [1] 98
  长度（测试$排名）
  [1]98

表（NNPredictions，测试$Rank，useNA =“ifany”）
NN预测 A B C D E
            1 0 0 0 0
            乙 0 6 0 0 0
            0 0 11 0 0
            d 0 0 0 18 0
            E 0 0 0 0 62]]></description>
      <guid>https://stackoverflow.com/questions/56995048/confusion-matrix-error-error-data-and-reference-should-be-factors-with-the</guid>
      <pubDate>Thu, 11 Jul 2019 18:05:03 GMT</pubDate>
    </item>
    </channel>
</rss>