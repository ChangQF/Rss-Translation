<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 22 Apr 2024 03:15:05 GMT</lastBuildDate>
    <item>
      <title>使用 ONNX 模型进行量化。推理步骤</title>
      <link>https://stackoverflow.com/questions/78363618/quantization-using-onnx-model-inference-step</link>
      <description><![CDATA[我在 ONNX 量化方面遇到一些问题。
我将 ResNet18 转换为 ONNX 量化模型，并尝试实现一些专用硬件来复制操作。在量化步骤中，ONNX 参考文献中解释了量化的公式为：
y = 饱和 ((x / y_scale) + y_zero_point)。
对于去量化，公式为：
y = (x - x_zero_point) * x_scale
我使用对称量化（zero_point=0），所以它变成：
量化：
y = 饱和 (x / y_scale) 。
去量化：
y = x * x_scale
您可以在此处找到相关信息
https://onnxruntime.ai/docs/performance/model-optimizations/quantization。 html
问题是，如果我查看 ONNX 训练后在校准步骤中计算的缩放因子，缩放因子均小于 1。例如，它们的值介于 0 和 1 之间。如附图所示（使用 Netron 生成）。
用于量化的 ONNX 比例因子示例 
如果我的缩放因子小于一，那么量化和反量化操作就不再有意义。因为假设我想以 int8 进行量化，并且从 fp32 数字开始，我想要这样的东西：
xq = x_fp /s
这样我就可以减少用 int8 表示的 x_fp 的动态范围。但如果我的缩放因子小于 1，我实际上正在扩大范围！
因此，对于量化，我得到的范围更大而不是更小，而对于去量化，我得到的范围更小，而不是更大。
我在想我可能必须将缩放因子乘以我想要的量化位宽度，例如 uint8 的 2^8=256。
由于缩放因子的计算方式为 s= (2^N-1) / fp_range，因此他们可能只提供以下部分：
s_onnx = 1/fp_range
并让您精确地乘以所需的位。
有人可以帮我解决这个问题吗？
谢谢！
考虑到缩放因子在 0 和 1 之间，那么我期望这样的公式：
量化
x_q = x_fp * 比例
去量化
x_fp = x_q / 比例
而不是相反。]]></description>
      <guid>https://stackoverflow.com/questions/78363618/quantization-using-onnx-model-inference-step</guid>
      <pubDate>Mon, 22 Apr 2024 01:31:14 GMT</pubDate>
    </item>
    <item>
      <title>在 keras 调谐器中使用 F1 分数作为指标时遇到问题</title>
      <link>https://stackoverflow.com/questions/78363511/having-trouble-using-the-f1-score-as-a-metric-in-keras-tuner</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78363511/having-trouble-using-the-f1-score-as-a-metric-in-keras-tuner</guid>
      <pubDate>Mon, 22 Apr 2024 00:18:59 GMT</pubDate>
    </item>
    <item>
      <title>用于近似四象限图上 x,y 坐标的机器学习模型</title>
      <link>https://stackoverflow.com/questions/78363501/machine-learning-model-for-approximating-x-y-coordinates-on-four-quadrant-graph</link>
      <description><![CDATA[该项目适用于大学课程。我从 政治指南针 收集了数据，我想用它来近似 x 坐标和 y 坐标值使用 Twitter 数据的政治指南针。这只是一个片段：

&lt;标题&gt;

键
twitter_user_id
politician_name
twitter_handle
x_坐标
y_坐标
政党
选举年
国家
twitter_active_during_election


&lt;正文&gt;

8132862008
813286
巴拉克·奥巴马
巴拉克奥巴马
3
2
民主
2008
美国
正确


9390912008
939091
乔·拜登
乔拜登
3
3
民主
2008
美国
正确


150226332008
15022633
丹尼斯·库西尼奇
丹尼斯_库西尼奇
-2
-2
民主
2008
美国
正确


314286852008
31428685
比尔·理查森
理查森政府
4
4
民主
2008
美国
错误


154165052008
15416505
迈克·赫卡比
GovMikeHuckabee
6
6
共和党
2008
美国
正确



我的教授告诉我使用两种逻辑回归模型 - 一种用于近似 x 值，另一种用于近似 y。我想确保这是一个可行的方法。根据我在网上阅读的内容，逻辑回归似乎是一个二元模型。我找不到提供除 yes/no 或 1/0 之外的输出的示例。
逻辑回归可以近似这些值吗？如果不是，什么模型是该项目的正确方法？]]></description>
      <guid>https://stackoverflow.com/questions/78363501/machine-learning-model-for-approximating-x-y-coordinates-on-four-quadrant-graph</guid>
      <pubDate>Mon, 22 Apr 2024 00:13:56 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络的多类别分类问题</title>
      <link>https://stackoverflow.com/questions/78363467/classification-problem-with-multi-categories-using-neural-networks</link>
      <description><![CDATA[在我的设置中，我遇到一个问题，其中每个实体（假设用户）都有一组分类属性。为了简单起见，我们可以将它们表示为数字，例如：

u1, [1,2,3]
u2 [0, 4]
u3 [0,1,2,3,4]

假设我们有多个类别MAX_CATEGORIES。因此，在我的玩具设置中，生成了标签：
def likes_movies(row):
    如果 (MAX_CATEGORY - 1) 在行中则返回 1，否则返回 0

我尝试了一个模型，其中每个类别都表示为嵌入，然后聚合它们：
类 SimpleMultiCategoricalClassifier(torch.nn.Module):
    def __init__(self, num_embeddings, embedding_dim):
        超级().__init__()

        self.embeddings = nn.EmbeddingBag(
                num_embeddings=num_embeddings,
                embedding_dim=embedding_dim, mode=“平均值”）

        self.net = nn.Sequential(
            nn.Linear(embedding_dim, 2),
            ReLU()
        ）
        
    def 前向（自身，输入，偏移量）：
        x = self.embeddings(输入, 偏移量)
        返回 self.net(x)

但是我连最简单的函数都学不会。我的分类器损失只是在一个固定点上振荡，基本上没有学到任何东西。我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78363467/classification-problem-with-multi-categories-using-neural-networks</guid>
      <pubDate>Sun, 21 Apr 2024 23:45:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在多项式回归中找到未处理的输入数据的多项式方程？</title>
      <link>https://stackoverflow.com/questions/78363183/how-to-find-the-polynomial-equation-for-unprocessed-input-data-in-polynomial-reg</link>
      <description><![CDATA[这里我的 .csv 文件包含大小和时间。大小（唯一的自变量）是指程序的大小，时间（目标/预测）是指完成程序所需的时间。请告诉我找到从程序中获取方程的方法，以便我可以直接从原始的未处理的输入大小预测时间，而不需要进一步处理。
导入 pandas 作为 pd
将 numpy 导入为 np
df = pd.read_csv(“/content/drive/MyDrive/Project/combined2.csv”)
X = df[[&#39;尺寸&#39;]]
打印（X）
y = df[&#39;时间&#39;]
从 sklearn.model_selection 导入 train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)
从 sklearn.preprocessing 导入 StandardScaler
定标器=标准定标器()
打印（X_train）
X_train_scaler = 缩放器.fit_transform(X_train)
X_test_scaler = 缩放器.transform(X_test)
从 sklearn. Linear_model 导入 LinearRegression
lin = 线性回归()
def 答案(arr,x):
  总和=0
  j=0
  对于我在arr：
    打印（j）
    总和=总和+(pow(x,j))*i
    j=j+1
  返回总和

我=1
从 sklearn.preprocessing 导入多项式特征
从 sklearn.metrics 导入mean_squared_error
当 i&lt;=50 时：
  poly = 多项式特征(度=i)
  X_poly_train = poly.fit_transform(X_train_scaler)
  X_test_poly = poly.transform(X_test_scaler)
  poly.fit(X_poly_train, y_train)
  lin.fit(X_poly_train, y_train)
  y_pred = lin.predict(X_test_poly)
  均方误差（y_test，y_pred）
  y_pred_train = lin.predict(X_poly_train)
  均方误差（y_train，y_pred_train）
  如果我==1：
    mnum=abs(均方误差(y_test, y_pred)-均方误差(y_train, y_pred_train))
  别的：
    如果 mnum&gt;abs(mean_squared_error(y_test, y_pred)-mean_squared_error(y_train, y_pred_train))：
      达达=我
      mnum=abs(均方误差(y_test, y_pred)-均方误差(y_train, y_pred_train))
  我=我+1
print(&#39;mse(testpred)-mse(trainpredtrain)=&#39;+str(mnum))
print(&#39;度=&#39;+str(达达))
打印（均方误差）
poly = 多项式特征(度=daada)
X_poly_train = poly.fit_transform(X_train_scaler)
X_test_poly = poly.transform(X_test_scaler)
poly.fit(X_poly_train, y_train)
lin.fit(X_poly_train, y_train)
y_pred = lin.predict(X_test_poly)
倾角=mean_squared_error(y_test, y_pred)
print(&#39;均方误差(test&amp;pred)=&#39;+str(dip))
y_pred_train = lin.predict(X_poly_train)
罗伊=mean_squared_error(y_train, y_pred_train)
print(&#39;均方误差(train,predtrain)=&#39;+str(roy))
print(&#39;mse(testpred)-mse(trainpredtrain)=&#39;+str(abs(dip-roy)))
print(&#39;截距=&#39;+str(lin.intercept_))
print(&#39;系数=&#39;)
打印（lin.coef_）
打印（缩放器.scale_）
&quot;&quot;&quot;&quot;coefficients_unscaled = lin.coef_ / scaler.scale_ # 除以缩放因子
Intercept_unscaled = lin.intercept_ - np.sum(coefficients_unscaled * scaler.mean_) # 调整均值缩放
print(&quot;coefficients_unscaled=&quot;)
打印（系数_未缩放）
打印（拦截_未缩放）
新大小 = 5128192
print(int(answer(coefficients_unscaled,new_size)-intercept_unscaled))“”“”
Coefficients_unscaled = lin.coef_ / scaler.scale_ # 除以缩放因子
Intercept_unscaled = lin.intercept_ - np.sum(coefficients_unscaled * scaler.mean_) # 调整均值缩放

打印（“coefficients_unscaled=”，coefficients_unscaled）
打印（“intercept_unscaled =”，intercept_unscaled）

# 计算多项式的函数
def 答案(arr, x):
    返回 sum(arr[i] * (x ** i) for i in range(len(arr)))

# x 的值
新大小 = 5128192

# 计算 new_size 处多项式的值
结果=答案（coefficients_unscaled，new_size）-拦截_unscaled
print(&quot;大小 5128192 的预测时间：&quot;, result)

即将到来的结果太大了。请帮我修复它。
我的问题是我无法获得原始输入的方程，它可以直接给出预测的输出。我尝试对其进行缩放，但得到的答案比预期值太大。]]></description>
      <guid>https://stackoverflow.com/questions/78363183/how-to-find-the-polynomial-equation-for-unprocessed-input-data-in-polynomial-reg</guid>
      <pubDate>Sun, 21 Apr 2024 21:20:09 GMT</pubDate>
    </item>
    <item>
      <title>如何正确标记停车位编号并据此监控停车位盒？</title>
      <link>https://stackoverflow.com/questions/78363064/how-can-i-properly-label-the-parking-slots-number-and-monitor-the-slot-boxes-acc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78363064/how-can-i-properly-label-the-parking-slots-number-and-monitor-the-slot-boxes-acc</guid>
      <pubDate>Sun, 21 Apr 2024 20:21:06 GMT</pubDate>
    </item>
    <item>
      <title>我收到错误 - ValueError: 在使用模型 ss3 进行投票分类器时，估计器 SS3 应该是分类器</title>
      <link>https://stackoverflow.com/questions/78362782/i-am-getting-an-error-valueerror-the-estimator-ss3-should-be-a-classifier-whi</link>
      <description><![CDATA[我正在研究一个使用投票的集成模型，用于 ss3 模型、svm 模型和 RoBERTa 模型，但我遇到了很多错误。
我尝试包含拟合函数、预测函数，并尝试在 ss3 类的 init 中添加 _estimator_type = &#39;classifier&#39; 行，但随后出现错误，表明这是不必要的。请帮助我消除这个错误并指导我如何制作集成模型。
这是我面临最多问题的代码部分：
SS3 级：
def __init__(self):
    _estimator_type = &#39;分类器&#39;
    # self.train_df = 无
    self.cf = 无
    self. precision = 无，
    自我回忆=无，
    self.f1_score = 无，
    self.accuracy = 无，
    self.local_values = 无

def get_params(self, deep=True):
    返回 {
        &#39;_estimator_type&#39;: self._estimator_type,
    }

这是错误：
C:\Users\hp\PycharmProjects\EnsembleModelVoting\.venv\Scripts\python.exe C:\Users\hp\PycharmProjects\EnsembleModelVoting\Base.py
&lt;类&#39;pandas.core.frame.DataFrame&#39;&gt;
索引：20 个条目，4119 至 1902
数据列（共2列）：
 # 列非空计数 Dtype
--- ------ -------------- -----
 0 文本 20 非空对象
 1 标签 20 非空 int32
数据类型：int32(1)、对象(1)
内存使用：400.0+字节
                                                   文字标签
第4119章.....鸡皮疙瘩的梦想0
第3477章
第4322章 我感到兴奋。天哪，有点颤抖 0
第3349章(∣´à¸´´´)... 0
第469章 就让这焦急安息吧。请这个1
第538章 第一次紧张，凌龙……1
6636 rabi o rapapa 但等我毕业... 0
5820 为什么使用限制事件？ 0
第1047章 占有权，还怕不行老大？ 0
第1219章 博伊101 0
6542 [BOT] 范妮在这里！那儿是谁&#39;3&#39;）/ 0
6580 黎明后真的随机梦 0
5110 欢呼比埃尔姐姐！！ 0
第1783章 我不明白这个世界..旧T恤... 0
960 改掉7年的习惯……0
分段阅读_第 4810 章
4539 已经感觉最接近了。尽管有... 0
6929 快到开斋节了，一定要打扫卫生... 0
第1858章 卖礼篮的人肯定很幸福……0
1902 他的父亲再次恐吓..BUTTEREADY ON BBMAS!!!..... 0
SS3 呼叫
RobertaForSequenceClassification 的一些权重未从 roberta-base 的模型检查点初始化，而是新初始化的：[&#39;classifier.dense.bias&#39;、&#39;classifier.dense.weight&#39;、&#39;classifier.out_proj.bias&#39;、&#39;classifier.out_proj。重量&#39;]
您可能应该在下游任务上训练该模型，以便能够将其用于预测和推理。
罗伯塔打电话
支持向量机调用
回溯（最近一次调用最后一次）：
  文件“C:\Users\hp\PycharmProjects\EnsembleModelVoting\Base.py”，第 166 行，在  中
    vote_classifier.fit(X_train, y_train) # 直接传递DataFrame对象X_train和y_train
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\hp\PycharmProjects\EnsembleModelVoting\.venv\Lib\site-packages\sklearn\base.py”，第 1474 行，包装器中
    返回 fit_method(估计器, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\hp\PycharmProjects\EnsembleModelVoting\.venv\Lib\site-packages\sklearn\ensemble\_voting.py”，第 366 行，适合
    返回 super().fit(X,transformed_y,sample_weight)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\hp\PycharmProjects\EnsembleModelVoting\.venv\Lib\site-packages\sklearn\ensemble\_voting.py”，第 81 行，适合
    名称，clfs = self._validate_estimators()
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\hp\PycharmProjects\EnsembleModelVoting\.venv\Lib\site-packages\sklearn\ensemble\_base.py”，第 236 行，位于 _validate_estimators 中
    引发值错误（
ValueError：估计器 SS3 应该是一个分类器。

进程已完成，退出代码为 1
]]></description>
      <guid>https://stackoverflow.com/questions/78362782/i-am-getting-an-error-valueerror-the-estimator-ss3-should-be-a-classifier-whi</guid>
      <pubDate>Sun, 21 Apr 2024 18:48:18 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：形状（无，1）和（无，13）不兼容</title>
      <link>https://stackoverflow.com/questions/78362771/valueerror-shapes-none-1-and-none-13-are-incompatible</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78362771/valueerror-shapes-none-1-and-none-13-are-incompatible</guid>
      <pubDate>Sun, 21 Apr 2024 18:45:10 GMT</pubDate>
    </item>
    <item>
      <title>基于机器学习的面部识别的伦理影响是什么以及如何降低隐私风险？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78362554/cu%c3%a1les-son-las-implicaciones-%c3%a9ticas-del-reconocimiento-facial-basado-en-aprendi</link>
      <description><![CDATA[在拉丁美洲的城市环境中实施基于机器学习的面部识别系统会产生哪些伦理影响？如何减轻隐私风险？
这个问题与我最近的经历有关。假设他们对我进行了欺诈，或者某些公司的员工做出了不良行为，他们给了我发票或费用，而我不知道他们何时这样做，因为我拒绝了产品并且没有签署任何东西。查看评论后，我意识到许多客户都这样做了。
我在说什么，想象一下如果现在很容易进行欺诈，现在有了面部识别......]]></description>
      <guid>https://stackoverflow.com/questions/78362554/cu%c3%a1les-son-las-implicaciones-%c3%a9ticas-del-reconocimiento-facial-basado-en-aprendi</guid>
      <pubDate>Sun, 21 Apr 2024 17:35:50 GMT</pubDate>
    </item>
    <item>
      <title>在时间序列预测中提前多天进行预测时出现问题</title>
      <link>https://stackoverflow.com/questions/78361646/problem-forecasting-multiple-days-ahead-in-time-series-forecasting</link>
      <description><![CDATA[我正在尝试使用各种机器学习和深度学习模型来预测股票价格。目标变量是股票每天到第二天收盘价的百分比变化。该数据集由 23 个变量组成，包括宏观经济指标（gdp、通货膨胀...）、一些技术指标（RSI、EMAF、EMAS...）、其他股票从前一天到当前一天的走势以及一些公司基本面数据（每季度收益）。我总共有 23 行，不包括目标列，所有行都在 -1 和 1 之间缩放。
对于单步预测，模型的表现大致符合我的预期，其中随机森林和 lstm 表现最好，在股票走势方向上达到了 80% 左右的准确度。然而，我遇到的问题是在尝试比较模型预测未来 5 天的能力时。我预计模型预测的天数越多，其预测精度就会越来越低，但实际上精度保持不变，甚至由于某种原因而增加。这让我相信存在某种数据泄漏问题，或者我错误地分割了数据。
到目前为止，我尝试解决此问题的方法是为我尝试训练的每一天训练一个新模型，每个模型都针对移动的 y 列。这意味着如果我想用随机森林预测 5 天，我将训练 5 个随机森林，1 个针对明天，1 个针对后天，依此类推（全部来自同一个 x 数据集）。其代码如下：
def precision_trend(list1, list2):
  计数器 = 0
  对于范围内的 x(len(list1)-1)：
    if (list1[x] &gt; 0) == (list2[x] &gt; 0):
      计数器 = 计数器 + 1
  返回计数器 / (len(list1) - 1)

def spliter(路径, days_ahead):
  数据 = pd.read_csv(路径)
  data.drop([&#39;公司&#39;], axis=1, inplace=True)
  x = np.array(data.iloc[:-days_ahead, :-1])
  y = [np.array(data.iloc[i:-(days_ahead-i) if days_ahead-i &gt; 0 else
  无，-1]) 对于范围内的 i(days_ahead)]
  返回 x、y

train_x, train_ys = 分离器(train_path, 5)
test_x, test_ys = 分割器(test_path, 5)

train_ys = np.array(train_ys)

模型 = [RandomForestRegressor(n_estimators=100, random_state=4) for _ in range(5)]
预测=[]

对于 zip(models, train_ys, test_ys) 中的模型、train_y、test_y：
  model.fit(train_x, train_y)
  pred = model.predict(test_x)
  预测.append(pred)
  acc = 准确度趋势(test_y, pred) * 100
  print(f&quot;天 {len(预测)} 准确度：{acc}%&quot;)
  rmse =mean_absolute_error(test_y, pred)
  print(f&quot;Day {len(预测)} MAE: {rmse}&quot;)

输出如下：
第 1 天准确率：73.85272145144077%
第 1 天 MAE：0.01674374965706874
第 2 天准确率：74.49306296691569%
第 2 天 MAE：0.016746951626310427
第 3 天准确度：75.02668089647813%
第 3 天 MAE：0.016743799915880105
第 4 天准确度：76.09391675560299%
第 4 天 MAE：0.016736960931285863
第 5 天准确度：75.02668089647813%
第 5 天 MAE：0.016843232056633316

由于我使用最小-最大缩放测试数据集的方式，存在少量数据泄漏，但我不相信这会解释这个问题，并且目标变量未缩放。
我知道就这个问题提供建议相当困难，但我相当有信心这一定是我没有看到的编码问题。任何建议将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78361646/problem-forecasting-multiple-days-ahead-in-time-series-forecasting</guid>
      <pubDate>Sun, 21 Apr 2024 13:05:28 GMT</pubDate>
    </item>
    <item>
      <title>Baseline3 TD3，reset() 方法值太多，无法解包错误</title>
      <link>https://stackoverflow.com/questions/78361630/baseline3-td3-reset-method-too-many-values-to-unpack-error</link>
      <description><![CDATA[环境是python 3.10，stable-baseline3 2.3.0，我正在尝试TD3算法。
无论我做什么，我都会遇到同样的错误。
据我所知，重置方法的返回值与定义的观察空间相同
我制作的环境有如下重置方法
def重置（自身，种子=0）：
    self.current_index = 0
    self.current_cash = self.start_cash
    self.done = False
    self.当前时间 = self.开始时间

    # 초기 관찰 상태 계산
    初始状态 = self.get_state() # 字典
    返回初始状态

它从来都不复杂，定义环境，模型也很好
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
从 stable_baselines3 导入 TD3

类 CustomFeatureExtractor(BaseFeaturesExtractor):
    def __init__(自我，观察空间，features_dim = 5)：
        super(CustomFeatureExtractor, self).__init__(observation_space, features_dim)
        self.model_alpha = ModelAlpha()
    
    defforward（自我，观察）：
        价格 = 观察结果[&#39;价格&#39;]
        位置 = 观测值[&#39;位置&#39;]
        数量 = 观测值[&#39;数量&#39;]
        pnr = 观测值[&#39;pnr&#39;]
        
        return self.model_alpha(价格, torch.cat([位置, 数量, pnr]))
        
        
# 환경과 모델 설정
env = MarketEnvironment(蜡烛, &#39;2020-07-01 00:00:00&#39;, &#39;2023-12-31 23:59:00&#39;) # 여러분의 환경 설정
策略_kwargs = 字典（
    features_extractor_class=自定义特征提取器，
    features_extractor_kwargs=dict（features_dim=5）
）

模型 = TD3(“MultiInputPolicy”，env，policy_kwargs=policy_kwargs，batch_size=128，verbose=1)

Jupyter 提示符显示
使用CPU设备
使用 Monitor 包装器包装环境
将环境包装在 DummyVecEnv 中。
它运行良好，直到
model.learn（total_timesteps=1，log_interval=10，progress_bar=True）

这段代码。
无论我做了什么，它都会一遍又一遍地这么说
文件 ~\.conda\envs\mlbase-py3.10\lib\site-packages\stable_baselines3\common\off_policy_algorithm.py:297，在 OffPolicyAlgorithm._setup_learn(self、total_timesteps、callback、reset_num_timesteps、tb_log_name ， 进度条）
    第290章
    第291章
    292 和 self.env.num_envs &gt; 1
    293 而不是 isinstance(self.action_noise, VectorizedActionNoise)
    第294章）：
    第295章
--&gt; [第 297 章]
    298 总时间步数，
    299回调，
    300 重置_num_timesteps，
    第301章
    第302章
    第303章）

文件~\.conda\envs\mlbase-py3.10\lib\site-packages\stable_baselines3\common\base_class.py:425，在BaseAlgorithm._setup_learn(self,total_timesteps,callback,reset_num_timesteps,tb_log_name,progress_bar)中
    第423章
    第424章 断言self.env不是None
--&gt;第425章
    第426章
    第427章

文件 ~\.conda\envs\mlbase-py3.10\lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py:77，在 DummyVecEnv.reset(self) 中
     范围内的 env_idx 为 75(self.num_envs)：
     76 Maybe_options = {“选项”: self._options[env_idx]} if self._options[env_idx] else {}
---&gt; 77 obs, self.reset_infos[env_idx] = self.envs[env_idx].reset(seed=self._seeds[env_idx], **maybe_options)
     78 self._save_obs（env_idx，obs）
     79 # 种子和选项仅使用一次

ValueError：需要解包的值太多（预期为 2）

我知道这个错误的reset()方法是在一个名为VecEnv的抽象类中
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78361630/baseline3-td3-reset-method-too-many-values-to-unpack-error</guid>
      <pubDate>Sun, 21 Apr 2024 12:58:27 GMT</pubDate>
    </item>
    <item>
      <title>KNN 类型错误和数据标准化</title>
      <link>https://stackoverflow.com/questions/78360476/knn-typeerror-and-data-normalization</link>
      <description><![CDATA[即使完成教程指示的所有操作，我也无法使预测正常工作。
从 sklearn.neighbors 导入 KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=3, metric=&#39;euclidean&#39;)
knn_model.fit(train_val_process, merge_labels.label)
y_pred_knn = knn.predict(test_data_process)

错误如下：
TypeError：KNeighborsClassifier.predict() 缺少 1 个必需的位置参数：
&#39;X&#39;

我应该将数据均值标准化为 1 std 0。这样好吗？
from sklearn.preprocessing import StandardScaler
定标器=标准定标器()
缩放器.fit(pd.concat([train_data, val_data]))
train_data_process = pd.DataFrame(scaler.transform(train_data), columns=train_data.columns)
val_data_process = pd.DataFrame(scaler.transform(val_data), columns=val_data.columns)
train_val_process = pd.concat([train_data, val_data])
test_data_process = pd.DataFrame(scaler.transform(test_data), columns=test_data.columns)
y_test = test_labels.label
]]></description>
      <guid>https://stackoverflow.com/questions/78360476/knn-typeerror-and-data-normalization</guid>
      <pubDate>Sun, 21 Apr 2024 05:13:50 GMT</pubDate>
    </item>
    <item>
      <title>快速衡量某个值与许多其他值相比的新颖性</title>
      <link>https://stackoverflow.com/questions/78359547/fast-measuring-the-novelty-of-a-value-compared-to-many-others</link>
      <description><![CDATA[我正在训练一个 ki 模型在迷宫中移动。每个模型都会选择随后获得奖励的行动。最后，这会产生一个数值列表，我想将其与其他数值进行比较。
目的是衡量列表的相似程度。但不仅仅是与其中之一进行比较，而是与所有这些进行比较。
但是，必须确保距离在总计算中不会相互抵消。如果一个动作列表位于另外两个动作列表之间，那么这两个动作列表可能会相互抵消并且距离为零。这绝不能发生。另外，计算的数值应该与下一个列表有 2 的位置处的列表中是否有 0 或 1 无关。因此，Levensthein 距离不起作用。
或者Python中有一个库可以完成此类任务吗？
第二件事是速度；有人能给我看一段代码片段，可以在 python 中有效地进行这种新颖的测量吗？
顺便说一句，对于我来说，是否为一系列操作列表计算排名列表并将其与已执行的操作进行比较，或者是否为每个操作列表计算单独的值，对我来说并不重要。]]></description>
      <guid>https://stackoverflow.com/questions/78359547/fast-measuring-the-novelty-of-a-value-compared-to-many-others</guid>
      <pubDate>Sat, 20 Apr 2024 19:53:17 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 mRMRe 包找到最佳特征数？</title>
      <link>https://stackoverflow.com/questions/71996789/how-to-find-the-optimal-feature-count-by-mrmre-package</link>
      <description><![CDATA[我正在尝试使用 R 中的 mRMRe 包对基因表达数据集进行特征选择。我有包含超过 10K 个基因的 RNA seq 数据，我想找到适合分类模型的最佳特征。我想知道如何找到最佳特征数。这是我的代码，
mrEnsemble &lt;- mRMR.ensemble(data = Xdata, target_indices = c(1) ,feature_count = 100 ,solution_count = 1)
mrEnsemble_genes &lt;- as.data.frame(apply(solutions(mrEnsemble)[[1]], 2, function(x, y) { return(y[x]) }, y=featureNames(Xdata)))
查看（mrEnsemble_genes）

我刚刚设置了feature_count = 100，但我想知道如何在不设置数量的情况下找到分类的最佳特征数量。
提取 mrEnsemble_genes 后的结果将是基因列表，例如，
&lt;前&gt;&lt;代码&gt;gene05
基因08
基因45
基因67

他们的排名是根据相互信息计算出的分数吗？我的意思是排名第一的基因获得最高的 MI，它可能是对样本类别（即癌症和正常）进行分类的良好基因，对吗？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/71996789/how-to-find-the-optimal-feature-count-by-mrmre-package</guid>
      <pubDate>Mon, 25 Apr 2022 08:50:24 GMT</pubDate>
    </item>
    <item>
      <title>如何从 Scikit-learn 中获取多类分类的特异性和阴性预测值？</title>
      <link>https://stackoverflow.com/questions/63526955/how-to-obtain-specificity-and-negative-predictive-value-from-scikit-learn-for-mu</link>
      <description><![CDATA[目前，scikit-learn 的默认分类报告 (sklearn.metrics.classification_report - 链接）不包括特异性和阴性预测值 (NPV)。
因此，我制作了自己的分类报告功能：
def custom_classification_report(y_true, y_pred):
    tp, fn, fp, tn = fusion_matrix(y_true, y_pred).ravel()
    acc = (tp+tn)/(tp+tn+fp+fn)
    森 = (tp)/(tp+fn)
    sp = (tn)/(tn+fp)
    ppv = (tp)/(tp+fp)
    净现值 = (tn)/(tn+fn)
    f1 = 2*(sen*ppv)/(sen+ppv)
    fpr = (fp)/(fp+tn)
    tpr = (tp)/(tp+fn)
    return ( &#39;2X2 混淆矩阵:&#39;, [&#39;TP&#39;, tp, &#39;FP&#39;, fp, &#39;FN&#39;, fn, &#39;TN&#39;, tn],
                &#39;准确度：&#39;, round(acc, 3),
                &#39;灵敏度/召回率：&#39;, round(sen, 3),
                &#39;特异性：&#39;，round(sp, 3),
                &#39;PPV/精度：&#39;, round(ppv, 3),
                &#39;净现值：&#39;，圆形（净现值，3），
                &#39;F1-分数：&#39;, round(f1, 3),
                &#39;误报率：&#39;, round(fpr, 3),
                &#39;真阳性率：&#39;, round(tpr, 3),
            ）

def auc_roc(y_true, y_pred_score):
    return (&#39;AUC-ROC:&#39;, round(roc_auc_score(y_true, y_pred_score), 3))

def avg_ precision(y_true, y_pred_score, target_name):
    return (&#39;平均精度:&#39;, round(average_ precision_score(y_true, y_pred_score, pos_label=target_name), 3))
    tpr = (tp)/(tp+fn)
    return ( &#39;2X2 混淆矩阵:&#39;, [&#39;TP&#39;, tp, &#39;FP&#39;, fp, &#39;FN&#39;, fn, &#39;TN&#39;, tn],
                &#39;准确度：&#39;, round(acc, 3),
                &#39;灵敏度/召回率：&#39;, round(sen, 3),
                &#39;特异性：&#39;，round(sp, 3),
                &#39;PPV/精度：&#39;, round(ppv, 3),
                &#39;净现值：&#39;，圆形（净现值，3），
                &#39;F1-分数：&#39;, round(f1, 3),
                &#39;误报率：&#39;, round(fpr, 3),
                &#39;真阳性率：&#39;, round(tpr, 3),
            ）

def auc_roc(self, y_true, y_pred_score):
    return (&#39;AUC-ROC:&#39;, round(roc_auc_score(y_true, y_pred_score), 3))

def avg_ precision(self, y_true, y_pred_score, target_name):
    return (&#39;平均精度:&#39;, round(average_ precision_score(y_true, y_pred_score, pos_label=target_name), 3))

当我使用它进行二元类分类时，它工作得很好 -
print(&#39;&gt;&gt; 自定义分类报告:\n&#39;, custom_classification_report(y_test, Predicted_labels), &#39;\n&#39;)

当我使用同一行代码 print(&#39;&gt;&gt;&gt; 自定义分类报告:\n&#39;, custom_classification_report(y_test, Predicted_labels), &#39;\n&#39;) 进行多类分类时，它给出错误 ValueError: 需要解压的值太多（预期为 4）。这是为什么，如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/63526955/how-to-obtain-specificity-and-negative-predictive-value-from-scikit-learn-for-mu</guid>
      <pubDate>Fri, 21 Aug 2020 16:48:48 GMT</pubDate>
    </item>
    </channel>
</rss>