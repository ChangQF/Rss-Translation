<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 03 Apr 2024 15:13:42 GMT</lastBuildDate>
    <item>
      <title>pd.concat 正在创建一个我不需要的新列</title>
      <link>https://stackoverflow.com/questions/78268518/pd-concat-is-creating-a-new-column-i-dont-need</link>
      <description><![CDATA[所以我有 5 个数据集，其中包含有关 SQL 注入攻击的数据。我正在尝试合并它们，以便训练 ML 模型来检测 SQLi 攻击。所有5个数据集的特征都是相同的。
但是，当我使用 pd.concat 函数合并这些数据集时，会在原始查询索引本身中创建一个额外的特征“查询”列。
我认为是 df4 导致了问题，但我似乎无法解决该问题。请帮助我。
为了更好地理解以下代码：
]]></description>
      <guid>https://stackoverflow.com/questions/78268518/pd-concat-is-creating-a-new-column-i-dont-need</guid>
      <pubDate>Wed, 03 Apr 2024 14:49:11 GMT</pubDate>
    </item>
    <item>
      <title>如何将 sklearn-crf 套件与文档而不是句子一起使用？</title>
      <link>https://stackoverflow.com/questions/78268442/how-can-i-use-sklearn-crf-suite-with-documents-and-not-sentences</link>
      <description><![CDATA[我想在文档上训练我的 crf 模型，而不是在句子上训练，如文档 https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html）。
在本例中，我具有以下结构：
&lt;前&gt;&lt;代码&gt;[
    [ # 文档 1
        [(&#39;word1&#39;, {&#39;feature1&#39;: &#39;value1&#39;, &#39;feature2&#39;: &#39;value2&#39;, ...}), (&#39;word2&#39;, {&#39;feature1&#39;: &#39;value3&#39;, &#39;feature2&#39;: &#39;value4&#39; , ...}), ...], # 短语 1
        [(&#39;word3&#39;, {&#39;feature1&#39;: &#39;value5&#39;, &#39;feature2&#39;: &#39;value6&#39;, ...}), (&#39;word4&#39;, {&#39;feature1&#39;: &#39;value7&#39;, &#39;feature2&#39;: &#39;value8&#39; , ...}), ...], # 短语 2
        ...
    ],
    [ # 文档 2
        ...
    ],
    ...
]



不幸的是，我收到以下消息：
 trainer.append(xseq, yseq)
  文件“pycrfsuite/_pycrfsuite.pyx”，第 312 行，位于 pycrfsuite._pycrfsuite.BaseTrainer.append 中
  文件“”，第 48 行，位于 vector.from_py.__pyx_convert_vector_from_py_std_3a__3a_string 中
  文件“”，第 15 行，位于 string.from_py.__pyx_convert_string_from_py_std__in_string
类型错误：预期字节，找到列表

我的印象是crf不接受这样的格式。这种情况我该怎么办？
感谢您的想法:)]]></description>
      <guid>https://stackoverflow.com/questions/78268442/how-can-i-use-sklearn-crf-suite-with-documents-and-not-sentences</guid>
      <pubDate>Wed, 03 Apr 2024 14:35:07 GMT</pubDate>
    </item>
    <item>
      <title>创建用于 html 理解和数据提取的 AI 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/78268338/create-a-ai-model-for-html-understanding-and-extraction-of-data</link>
      <description><![CDATA[我正在开发一个项目，要求是我应该制作一个脚本，可以从给定的链接获取包含特定数据的表。因为有很多网站的结构不同，有些有table标签，有些使用div，有些使用其他标签。
现在，我对机器学习之类的东西非常陌生。如果有人可以指导我如何实现这一目标或给我一个正确的路线图。我应该学习什么，什么对我这个项目有帮助。不过，我精通 python 和数据抓取。
数据非常相似，我认为这是可能的。我将向专家展示一些例子。
https://www.rockauto.com/en/moreinfo.php?pk=101750&amp;cc=0&amp;pt=1000587&amp;jsn=788&amp;optionchoice=0-0-8-1


像这样的表格和交换号码（如果有）
另一个例子是
https://www.aimsinduscial。 com.au/gates-9770-13a1955-green-stripe-belt-heavy-duty-en
]]></description>
      <guid>https://stackoverflow.com/questions/78268338/create-a-ai-model-for-html-understanding-and-extraction-of-data</guid>
      <pubDate>Wed, 03 Apr 2024 14:20:16 GMT</pubDate>
    </item>
    <item>
      <title>Liu 等人 [2022] 中将多时相卫星数据输入 Informer 模型的格式是什么？</title>
      <link>https://stackoverflow.com/questions/78268294/what-is-the-format-in-which-the-multitemporal-satellite-data-was-fed-to-the-info</link>
      <description><![CDATA[Liu et al [2022]，标题为基于水稻产量预测和模型解释在
使用 Transformer 方法的卫星和气候指标，使用 Informer 模型（Zhou 等人发表） al) 使用 MODIS 数据（特别是 MOD13A2）进行水稻产量预测，可在 NASA 网站 上获取气候变量（可在此网站和（此网站）[https: //data.chc.ucsb.edu/products/CHIRPS-2.0/]) 作为功能，以及 各地区农作物产量统计数据作为地面实况数据的值。 Zhou等人发表的论文中提到的原始Informer模型的代码可以在（GitHub）上找到[https://github.com/zhouhaoyi/Informer2020]。
浏览完代码后，代码似乎将 csv 文件作为输入，其中指定列作为特征，其他指定列作为目标。为了调整多时相卫星数据以适合 csv 文件，Liu 等人说：
“八个连续变量（即 NDVI、EVI、NIRV、SIF、Tmax、Tmin、Srad 和 Pr）在空间上聚合到区级别。最后，总共应用了 96 个特征来构建模型，其中包含 8 个连续变量，每个变量有 12 个时间间隔。”
我的问题是，“聚合”到底是什么意思？也许他们的意思是这些值是所有像素的平均值？或者是某种其他形式的“聚合”？
我尝试过的：
我一直在寻找将卫星数据输入变压器模型的可能方法，视觉变压器（ViT）似乎经常用于处理卫星数据。然而，这仅适用于单个时间步数据。对于多时相数据（即具有多个时间步长的数据），出现了其他更复杂的方法，但 Liu 等人没有提到这些方法。由于我的目标是复制 Liu 等人的结果，因此使用如此复杂的方法是不可取的。]]></description>
      <guid>https://stackoverflow.com/questions/78268294/what-is-the-format-in-which-the-multitemporal-satellite-data-was-fed-to-the-info</guid>
      <pubDate>Wed, 03 Apr 2024 14:12:45 GMT</pubDate>
    </item>
    <item>
      <title>文本转换：训练模型从输入文件生成输出文件</title>
      <link>https://stackoverflow.com/questions/78268215/text-transformation-train-a-model-to-generate-output-files-from-input-files</link>
      <description><![CDATA[我目前正在进行一个项目，其中包括“翻译”文件从一种格式转换为另一种格式，我使用了带有映射的编程方法，该映射将输入文件中的每个模式与输出中方便的模式链接起来，编写映射和执行转换的类非常困难，此外，我每次我想要一种新的格式或调整时，都应该写一个新的，所以我决定用一个可以用数千个输入文件及其各自的输出进行尝试的模型来替换整个东西，这里有一个小例子可以给你一个想法:
输入文件中的块：
暗淡+1.800:0.400:500:CT+12
在输出中转换为 XML 标记：
 &lt;高度&gt;1.800&lt;\高度&gt;
    &lt;长度&gt;0.400&lt;\长度&gt;
    &lt;宽度&gt;500&lt;\宽度&gt;


所以基本上，第一行就是我们所说的“段”，它以 3 个字母的缩写开头，如您所见，它代表此处的尺寸，它转换高度、长度和宽度，如图所示，输入文件是一系列像维度、日期、地址之类的段，输出可能是 XML 或其他东西，但我想模型的逻辑不会有很大不同，我可以将其调整为其他格式，这就是我现在所需要的是XML，这怎么办？？？谢谢
我对机器学习非常陌生，但我作为开发人员已经有足够的时间了，所以我尝试了一种严格的方法]]></description>
      <guid>https://stackoverflow.com/questions/78268215/text-transformation-train-a-model-to-generate-output-files-from-input-files</guid>
      <pubDate>Wed, 03 Apr 2024 14:01:01 GMT</pubDate>
    </item>
    <item>
      <title>write_deltalake 错误 - > OSError 通用 Deltalocal 对象存储错误：不支持操作（操作系统错误 95）[关闭]</title>
      <link>https://stackoverflow.com/questions/78268024/write-deltalake-error-oserror-generic-deltalocal-objectstore-error-operatio</link>
      <description><![CDATA[尝试将 pandas 数据帧转换为 delta 表，标题中出现错误。生成一个表，但 delta_log 为空，无法读取数据。
点击此处查看我正在尝试的内容
尝试创建增量表，通过数据集使用 MLS 上传到 blob。]]></description>
      <guid>https://stackoverflow.com/questions/78268024/write-deltalake-error-oserror-generic-deltalocal-objectstore-error-operatio</guid>
      <pubDate>Wed, 03 Apr 2024 13:29:07 GMT</pubDate>
    </item>
    <item>
      <title>在图像上使用小波变换训练 SRGAN 时结果不正确</title>
      <link>https://stackoverflow.com/questions/78267811/incorrect-results-when-training-a-srgan-using-wavelet-transform-on-the-images</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78267811/incorrect-results-when-training-a-srgan-using-wavelet-transform-on-the-images</guid>
      <pubDate>Wed, 03 Apr 2024 12:55:10 GMT</pubDate>
    </item>
    <item>
      <title>合并多个数据集时协调标签注释 (ML)</title>
      <link>https://stackoverflow.com/questions/78267741/harmonize-label-annotation-when-merging-multiple-datasets-ml</link>
      <description><![CDATA[我想构建一个用于假新闻检测的机器学习模型。有多个数据集使用不同的标签方案。例如，LIAR 数据集允许 6 种分类（真、假、半真、大部分真等），而 FakeNewsNet 数据集仅提供 2 个标签（真/假）。
尽管我知道有些方法不涉及“合并”数据集（例如迁移学习、多任务学习），我的目标是找到一种方法将两个（或更多）数据集合并为一个数据集，以便最终可以在所有数据上训练单个模型。
因此，我正在寻找一种方法来协调多个数据集 (ds) 的标签方案。
假设，ds A 有 3 个标签（真/假和仇恨言论），ds B 有 4 个标签（真/半真/假和讽刺）。在 A 和 B 中，“讽刺”和“仇恨言论”并不排除实例的其他标签。任务是创建一个由 A 和 B 中所有实例的统一组成的 ds C。C 的每个实例都有一个标签，用于编码真/半真/假/讽刺/仇恨言论的类成员资格。

匹配 A 和 B 中假新闻的不同粒度。这意味着，允许 A 的实例是半真而不是真/假。

通过不一定链接到 A（和 B）中其他标签的标签来扩展 A（和 B）的标签方案。也就是说，允许 A (B) 的实例不仅是真/假/半真，而且同时是讽刺（仇恨言论）。


我正在寻找将 A 和 B 组合成一个 d 的方法。欢迎引用科学论文！
谢谢:)
到目前为止我收集的想法：
-引导特征方法[Jiang 2019]：在ds B上训练模型B。然后使用模型B对A进行分类（从而对其进行标记）。
-软标签元学习 [Vyas 2020]：标签成为可训练的实值参数（这可以帮助克服“不同粒度”问题。]]></description>
      <guid>https://stackoverflow.com/questions/78267741/harmonize-label-annotation-when-merging-multiple-datasets-ml</guid>
      <pubDate>Wed, 03 Apr 2024 12:44:41 GMT</pubDate>
    </item>
    <item>
      <title>寻求建议：使用 LRCN 改进可疑活动检测模型</title>
      <link>https://stackoverflow.com/questions/78267648/seeking-advice-improving-suspicious-activity-detection-model-using-lrcn</link>
      <description><![CDATA[我目前正在使用 LRCN 开发可疑活动检测模型，该模型有四个类别：跑步、步行、打斗和不打斗。然而，我在准确区分步行和跑步方面遇到了困难，导致准确率较低。
我正在考虑两种可能的解决方案，非常感谢您的见解：

数据增强：添加更多数据或旋转视频是否有助于提高分类准确性？

模型增强：我在两个选项之间左右为难：

集成情绪分析来分析活动的背景。这是否可行且有益，还是会使模型过于复杂？

实时视频分类：使用边界框实现实时视频分类系统来识别活动。此外，我有兴趣针对持枪等活动建立警报系统。我应该如何为此添加更多数据集和类？




我还在寻求有关任何预训练模型或资源的建议，以帮助提高我的模型的准确性和功能。
提前谢谢您！！
到目前为止准确率为 76%]]></description>
      <guid>https://stackoverflow.com/questions/78267648/seeking-advice-improving-suspicious-activity-detection-model-using-lrcn</guid>
      <pubDate>Wed, 03 Apr 2024 12:29:18 GMT</pubDate>
    </item>
    <item>
      <title>线性回归的 cros_val_score 问题</title>
      <link>https://stackoverflow.com/questions/78267134/problem-with-cros-val-score-with-linear-regression</link>
      <description><![CDATA[我有这段代码，当我计算 cross_val_score 时，我不明白错误在哪里。
您可以在最后找到代码。
当我将 X 和 Y 插入 cross_val_score 时，我得到这个输出=
&lt;预&gt;&lt;代码&gt;[-1.04310278e+25 -9.02663688e-01 -5.58849445e-01 -4.67666181e-01
  -5.31695826e-01 -5.38521348e-01 -4.88145909e-01 -9.43066823e-01
  -8.05226210e-01 -1.08907648e+00]

如果我插入 x_train 和 y_train （即使在将它们分割为 test_size=0.01 后，因此与 X 和 Y 非常相似），我得到的 cross_val_score 的结果为：
&lt;前&gt;&lt;代码&gt;[-0.71077296 -0.55292557 -0.61305045 -0.56387715 -0.69411482 -0.6876596
 -0.58946027 -0.65684074 -0.70967388 -0.887881]

它们的结果截然不同，我不明白问题出在哪里。
X 的形状为 (18994, 12)
Y (18994, 2)，如果 x_train 的测试大小为 0.2，则我们有 (15195, 12) 和 y_train (15195, 2)。
谁能帮我理解我哪里出了问题？
导入请求
将 pandas 导入为 pd
导入 csv
导入地理数据
将plotly.express导入为px
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
将seaborn导入为sns
从 sklearn.model_selection 导入 train_test_split
将日期时间导入为 dt
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.metrics 导入mean_squared_error, r2_score
从 sklearn.multioutput 导入 MultiOutputRegressor
从 sklearn.model_selection 导入 cross_val_score、cross_val_predict
模型=线性回归()
mulregressor = MultiOutputRegressor（模型）
data=pd.read_excel(r&quot;C:\Users\...\file.xlsx&quot;)
def 使用标准化（数据）：
    尺度标准=标准缩放器()
    数据=scaleStandard.fit_transform（数据）
    data=pd.DataFrame(data, columns=[“卧室”,“浴室”,“平方英尺”,“建造年份”,“价格”,
                                “listedDate”、“removedDate”、“daysOnMarket”、“latitude”、
                               “经度”、“公寓”、“多户住宅”、“单户住宅”、“联排别墅”、“浴室比率”])
    返回数据

datastand=使用标准化（数据）
X=datastand.drop([“daysOnMarket”], axis=1)
X=X.drop([&quot;removedDate&quot;], axis=1)
X=X.drop([“价格”], axis=1).values
Y=datastand[[&quot;daysOnMarket&quot;,&quot;price&quot;]].values

x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)
k_fold_acc= cross_val_score(mulregressor, x_train,y_train,cv=10,scoring=“neg_mean_squared_error”)
打印（k_fold_acc）
]]></description>
      <guid>https://stackoverflow.com/questions/78267134/problem-with-cros-val-score-with-linear-regression</guid>
      <pubDate>Wed, 03 Apr 2024 10:53:41 GMT</pubDate>
    </item>
    <item>
      <title>Torchserve 工作流程因超过 14 个 python 异步请求而卡住</title>
      <link>https://stackoverflow.com/questions/78266554/torchserve-workflow-is-stuck-for-more-than-14-python-async-requests</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78266554/torchserve-workflow-is-stuck-for-more-than-14-python-async-requests</guid>
      <pubDate>Wed, 03 Apr 2024 09:12:56 GMT</pubDate>
    </item>
    <item>
      <title>使用非序列数据时，LSTM 给出更概括的结果，准确率为 89%，而使用序列数据时准确率为 64%</title>
      <link>https://stackoverflow.com/questions/78265338/lstm-giving-more-generalize-result-with-accuracy-of-89-when-using-non-sequentia</link>
      <description><![CDATA[我正在研究时间序列分类。我使用了下面给出的两个预处理步骤

时间序列数据集 --&gt;切片时间序列 ---&gt;训练-验证-测试-分割 --&gt;模型训练
准确度——90%

时间序列数据集 --&gt;训练-验证-测试-分割 --&gt;独立切片训练/测试/验证 --&gt;模型训练
准确度 -- 64%


我目前正在努力为我的项目获取顺序概率分布，并已进入第二步。但是，我得到的准确度结果低于预期，甚至低于第一步。我已经调整了超参数并解决了类别不平衡的问题以消除偏差，但准确率没有提高到超过 64%。谁能提供一些关于为什么会发生这种情况的见解？
对于训练验证测试拆分，我使用 sklearn
x_main, x_test, y_main, y_test = train_test_split(x, y, test_size=0.2, random_state=42,stratify=y,shuffle=True)
x_train, x_val, y_train, y_val = train_test_split(x_main, y_main, test_size= 0.1, random_state=42,stratify=y_main,shuffle=True)
至少我预计第二步的结果接近 80-85%]]></description>
      <guid>https://stackoverflow.com/questions/78265338/lstm-giving-more-generalize-result-with-accuracy-of-89-when-using-non-sequentia</guid>
      <pubDate>Wed, 03 Apr 2024 05:05:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 openai 和 langchain 将已创建的 chromadb 集合与法学硕士一起使用？</title>
      <link>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</link>
      <description><![CDATA[我已经使用其文档和元数据创建了 chromadb 集合。
问题是当我想使用 langchain 创建 llm 并传递此 chromadb 集合以用作知识库时。
langchain_chroma = 色度(
客户端=持久客户端，
集合名称=集合.名称,
embedding_function = openai_ef，
）

llm_model =“gtp35turbo-最新”

llm = AzureChatOpenAI(
   api_key=openai_api_key,
   api_version=openai_api_version,
   azure_endpoint=openai_api_base,
   型号=llm_model）

qa_chain = RetrievalQA.from_chain_type(
   嗯，
   检索器=langchain_chroma.as_retriever(),
   chain_type=&quot;精炼&quot;
）

当我想跑步时：
qa_chain.run(“对象检测问题需要多少数据科学家”)

我收到此错误：
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-81-3cdb65aeb43e&gt;在&lt;细胞系：1&gt;()
----&gt; 1 qa.run(“对象检测问题需要多少数据科学家”)

9帧
/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py 中相似性_search_with_score(self, query, k, filter, where_document, **kwargs)
    第430章）
    第431章：
--&gt;第432章
    第433章
    第434章

AttributeError：“OpenAIEmbeddingFunction”对象没有属性“embed_query”

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</guid>
      <pubDate>Mon, 11 Dec 2023 21:17:23 GMT</pubDate>
    </item>
    <item>
      <title>神经网络的反向传播（形状误差）</title>
      <link>https://stackoverflow.com/questions/47472833/back-propagation-for-neural-network-error-in-shapes</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/47472833/back-propagation-for-neural-network-error-in-shapes</guid>
      <pubDate>Fri, 24 Nov 2017 11:57:35 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在 scikit learn 中将装袋技术与两种不同的算法结合使用？</title>
      <link>https://stackoverflow.com/questions/26283045/is-it-possible-to-use-the-bagging-technique-with-two-different-algorithms-in-sci</link>
      <description><![CDATA[我想知道是否可以将装袋技术与两种不同的算法（例如逻辑回归和随机森林）或（几乎）任何其他算法一起使用？
我需要一些能够返回平均概率或组合概率和预测的东西。
这将用于分类任务。
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/26283045/is-it-possible-to-use-the-bagging-technique-with-two-different-algorithms-in-sci</guid>
      <pubDate>Thu, 09 Oct 2014 16:06:55 GMT</pubDate>
    </item>
    </channel>
</rss>