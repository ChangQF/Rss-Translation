<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 May 2024 09:17:01 GMT</lastBuildDate>
    <item>
      <title>如何让 LangChain 代理可以访问 DataFrame？</title>
      <link>https://stackoverflow.com/questions/78547953/how-to-make-dataframe-accessible-to-langchain-agent</link>
      <description><![CDATA[我目前正在开发一个 LangChain 代理，需要一些帮助来使 DataFrame (df) 可供代理访问。以下是我想要实现的目标的简要概述：
代理可以访问多个功能工具。
这些工具需要 DataFrame (df) 作为参数。
代理的任务是调用这些工具，传递存储在 df 变量中的数据。
我的问题：
有没有办法确保代理可以访问 df 变量，以便它可以成功地将数据传递给功能工具？
任何指导或示例都将不胜感激！
提前致谢！
我尝试在提示模板中传递数据，但需要 30 多秒。在此部分中，代理重新格式化数据然后才传递。但我希望代理传递变量。
我也厌倦了创建一个工具函数，该函数使用查询从数据库中提取数据并将其存储在变量中。但是 llm 使用的代理仍然会转换为 json 格式然后传递它。
我希望 llm 接受变量并在不进行任何格式化的情况下传递它（以节省时间）。]]></description>
      <guid>https://stackoverflow.com/questions/78547953/how-to-make-dataframe-accessible-to-langchain-agent</guid>
      <pubDate>Wed, 29 May 2024 07:28:30 GMT</pubDate>
    </item>
    <item>
      <title>寻找预测因频繁接触社交网络而引起的心身疾病的数据集</title>
      <link>https://stackoverflow.com/questions/78547748/looking-for-dataset-on-predicting-psychosomatic-disorders-arising-from-intensive</link>
      <description><![CDATA[我正在研究如何预测因频繁接触社交网络而导致的心身疾病。我需要一个数据集来分析和模拟这种现象。您能否推荐一些特定的来源或数据库，让我可以找到包含社交媒体使用模式、心理指标和潜在心身症状相关数据的数据集？理想情况下，数据集应包括诸如在社交媒体平台上花费的时间、互动类型、自我报告的心理健康指标以及任何已诊断的心身疾病等变量。如果您能帮助我找到这样的数据集，我将不胜感激
我正在寻找用于训练的数据集]]></description>
      <guid>https://stackoverflow.com/questions/78547748/looking-for-dataset-on-predicting-psychosomatic-disorders-arising-from-intensive</guid>
      <pubDate>Wed, 29 May 2024 06:41:51 GMT</pubDate>
    </item>
    <item>
      <title>KITTI 数据集中的标签文件</title>
      <link>https://stackoverflow.com/questions/78547630/label-file-in-kitti-dataset</link>
      <description><![CDATA[我正在研究 3d 对象检测，并遇到了 PointPillars。PointPillars 使用 KITTI 数据集。
现在我想使用自己的数据集，但首先我应该像 KITTI 一样格式化我的数据集，因为我想知道 KITTI 数据集的标签文件中的那些值是什么。有人可以解释一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/78547630/label-file-in-kitti-dataset</guid>
      <pubDate>Wed, 29 May 2024 06:15:31 GMT</pubDate>
    </item>
    <item>
      <title>YoloV8 结果中没有 'box'、'max' 属性</title>
      <link>https://stackoverflow.com/questions/78547320/yolov8-results-have-no-box-max-properties-in-it</link>
      <description><![CDATA[我已经训练了一个 YOLOV8 模型来识别十字路口的物体（即汽车、道路等）。
它工作正常，我可以将输出作为带有感兴趣分割对象的图像。
但是，我需要做的是捕获原始几何图形（多边形），以便稍后将它们保存在 txt 文件中。
我尝试了在文档中找到的内容（https://docs.ultralytics.com/modes/predict/#key-features-of-predict-mode）但返回的对象与文档所述不同。
实际上，结果是 TensorFlow 数字列表：

这是我的代码：
import argparse
import cv2
import numpy as np
from pathlib import Path
from ultralytics.yolo.engine.model import YOLO 

# 解析命令行参数
parser = argparse.ArgumentParser()
parser.add_argument(&#39;--source&#39;, type=str, required=True, help=&#39;源图像目录或文件&#39;)
parser.add_argument(&#39;--output&#39;, type=str, default=&#39;output&#39;, help=&#39;输出目录&#39;)
args = parser.parse_args()

# 如果不存在则创建输出目录
Path(args.output).mkdir(parents=True, exist_ok=True)

# 模型路径
model_path = r&#39;C:\\_Projects\\best_100img.pt&#39;

# 直接加载模型
model = YOLO(model_path)
model.fuse()

# 加载图像
if Path(args.source).is_dir():
image_paths = list(Path(args.source).rglob(&#39;*.tiff&#39;))
else:
image_paths = [args.source]

# 处理每幅图像
for image_path in image_paths:
img = cv2.imread(str(image_path))
if img is None:
continue

# 执行推理
predictions = model.predict(image_path, save=True, save_txt=True)

print(&quot;处理完成。&quot;)

问题在于：返回对象（预测变量）没有框、掩码、关键点和等等。
我想我的问题是：

为什么结果与文档如此不同？
是否有转换步骤？
]]></description>
      <guid>https://stackoverflow.com/questions/78547320/yolov8-results-have-no-box-max-properties-in-it</guid>
      <pubDate>Wed, 29 May 2024 04:32:01 GMT</pubDate>
    </item>
    <item>
      <title>机器学习项目：PCB 的光学检测 [关闭]</title>
      <link>https://stackoverflow.com/questions/78547175/machine-learning-project-optical-inspection-of-pcbs</link>
      <description><![CDATA[我有一个项目要创建一个机器学习模型，其中有一个印刷电路板 (PCB) 被分成 16 个部分的图像，我们以正确的印刷电路板组件为基础，然后在相机的帮助下放大印刷电路板 (PCB) 组件以检查它是否与正确的印刷电路板 (PCB) 组件匹配。
我完全不知道该如何处理这个问题，因为我对图像处理的机器学习知识很少，所以请有人帮助我。]]></description>
      <guid>https://stackoverflow.com/questions/78547175/machine-learning-project-optical-inspection-of-pcbs</guid>
      <pubDate>Wed, 29 May 2024 03:18:48 GMT</pubDate>
    </item>
    <item>
      <title>当使用大规模数据进行训练时，数据是如何处理？[关闭]</title>
      <link>https://stackoverflow.com/questions/78547001/when-training-with-large-scale-data-how-is-the-data-processed</link>
      <description><![CDATA[我面临着使用大规模数据进行训练的挑战，具体来说是大约 19 TB 的视频数据。创建模型并不困难，但我不知道在哪里存储如此大量的数据以及如何使用它。由于我们没有高性能计算机，似乎我们可能需要租用一些。我很好奇处理大规模数据的 AI 开发人员通常如何处理这种情况。
此外，我发现可以使用 AWS，但我想知道是否真的采用了这种方法，或者是否有更好的替代方案。]]></description>
      <guid>https://stackoverflow.com/questions/78547001/when-training-with-large-scale-data-how-is-the-data-processed</guid>
      <pubDate>Wed, 29 May 2024 01:50:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么加载 AutoTokenizer 会占用这么多的 RAM？</title>
      <link>https://stackoverflow.com/questions/78546693/why-loading-autotokenizer-takes-so-much-ram</link>
      <description><![CDATA[我测量了脚本使用的 RAM，惊讶地发现它占用了大约 300Mb 的 RAM，而 tokenizer 文件本身大约只有 9MB。这是为什么？
我试过：
from transformers import AutoTokenizer
from memory_profiler import profile

@profile
def load_tokenizer():
path = &quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot; 
tokenizer = AutoTokenizer.from_pretrained(path)

return tokenizer

load_tokenizer()

输出：
行 # 内存使用量 增量 发生次数 行内容
==================================================================
4 377.4 MiB 377.4 MiB 1 @profile
5 def load_tokenizer():
6 377.4 MiB 0.0 MiB 1 path = &quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot; 
7 676.6 MiB 299.2 MiB 1 tokenizer = AutoTokenizer.from_pretrained(path)
8 
9 
10 676.6 MiB 0.0 MiB 1 返回 tokenizer
]]></description>
      <guid>https://stackoverflow.com/questions/78546693/why-loading-autotokenizer-takes-so-much-ram</guid>
      <pubDate>Tue, 28 May 2024 22:44:10 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么机器学习方法来找到最佳卷积？</title>
      <link>https://stackoverflow.com/questions/78546274/what-machine-learning-approach-should-i-use-to-find-optimal-convolutions</link>
      <description><![CDATA[因此，我想寻找最适合某个物理实验的熵编码波形的最佳卷积运算。您可以想象，搜索空间非常大，我需要一种机器学习方法来找到一个好的最小值。我有大量数据和一台超级计算机可供使用。
我曾考虑使用与 AlphaTensor 类似的方法（有没有开源替代方案？），但我对 ML 算法不太熟悉，因此任何建议都将不胜感激。
我搜索过非 ML 方法，但认为其中一种方法效果最好。]]></description>
      <guid>https://stackoverflow.com/questions/78546274/what-machine-learning-approach-should-i-use-to-find-optimal-convolutions</guid>
      <pubDate>Tue, 28 May 2024 20:16:15 GMT</pubDate>
    </item>
    <item>
      <title>使用并行神经网络实现动态权重分配，提升 CNN 性能</title>
      <link>https://stackoverflow.com/questions/78545298/improving-cnn-performance-with-a-parallel-neural-network-for-dynamic-weight-assi</link>
      <description><![CDATA[我试图通过为所有数据点分配 0-1 之间的权重来改进我的回归模型，即卷积神经网络，这反过来又告诉我特定数据点在进行预测时有多好。关键是有些数据点很嘈杂并且会做出更糟糕的预测，我希望这些数据点具有较低的权重，以便在最后和训练期间忽略它们。
我所做的：尝试实现一个并行神经网络 (nn)，输出 0 到 1 之间的权重，并将此权重分配给相关的数据点/图像。
两个网络都接收相同的数据点作为输入，nn 输出权重，而回归 cnn 输出值 Y_i。然后将结果连接起来并传递给两个网络的相互自定义损失函数，该函数将预测值和目标值之间的平方差与并行 nn 中的给定权重相乘：sum((Y(:,i)-T(:,i))^2)*W(i)。
问题是模型似乎向较小的权重 W(i) 收敛，因为这将最大限度地减少损失，我该如何解决这个问题？
我尝试添加与权重大小成比例的正则化项来惩罚较小的权重。它有所帮助，但结果仍然不如没有并行 nn 时那么好。
# functional api
inputs = Input(shape=(16,150,1) )

x2 = Conv2D(64, 3, 1,activation=&#39;relu&#39;,data_format=&quot;channels_last&quot;,name=&#39;Conv1&#39;)(inputs)

x2 = MaxPooling2D()(x2)
x2 = BatchNormalization()(x2)

x2 = Conv2D(74, 2,activation=&#39;relu&#39;)(x2)
x2 = MaxPooling2D()(x2)
x2 = BatchNormalization()(x2)

x2 = Conv2D(128, 2,activation=&#39;relu&#39;)(x2)
x2 = Flatten()(x2)

x2 = Dense(256,activation=&#39;relu&#39;, name=&quot;FC1&quot;)(x2)
x2 = Dense(256,activation=&#39;relu&#39;,name=&#39;FC2&#39;)(x2)
regression_output = Dense(1,name=&#39;Output&#39;)(x2)

# 权重 NN 
x1 = Flatten()(inputs) # 与上面的 CNN 相同的输入
x1 = Dense(64,activation=&#39;relu&#39;,kernel_regularizer=tf.keras.regularizers.l2(0.01))(x1)
x1 = Dense(64,activation=&#39;relu&#39;,kernel_regularizer=tf.keras.regularizers.l2(0.01))(x1)
x1 = Dense(64,activation=&#39;relu&#39;)(x1)

weight_output = Dense(1,activation=&#39;sigmoid&#39;,name=&#39;weight_output&#39;)(x1) # 权重作为输出
weight_output = tf.maximum(weight_output, 0.1) # 确保权重至少为 0.1
combined_output = Concatenate()([regression_output, weight_output])
model = Model(inputs=inputs, output=combined_output)

def custom_loss(y_true, y_pred):
regression = y_pred[:, 0]
weight = y_pred[:, 1]
# 与之前一样对权重进行 L2 惩罚
#weight_penalty = tf.reduce_mean(tf.square(weight))
#l1_penalty = tf.reduce_sum(tf.abs(weight)) # L1 惩罚
#lambda_l1 = 0.10 # L1 的正则化强度
return tf.reduce_mean(weight * tf.square(y_true - return))
model.compile(optimizer=&#39;adam&#39;, loss=custom_loss, metrics = [&#39;mae&#39;])
]]></description>
      <guid>https://stackoverflow.com/questions/78545298/improving-cnn-performance-with-a-parallel-neural-network-for-dynamic-weight-assi</guid>
      <pubDate>Tue, 28 May 2024 16:06:38 GMT</pubDate>
    </item>
    <item>
      <title>随机梯度下降算法无法正常工作（Python）</title>
      <link>https://stackoverflow.com/questions/78537136/stochastic-gradient-descent-algorithm-does-not-work-properly-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78537136/stochastic-gradient-descent-algorithm-does-not-work-properly-python</guid>
      <pubDate>Mon, 27 May 2024 04:02:36 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 保存模型有效，但加载模型无效</title>
      <link>https://stackoverflow.com/questions/78535919/tensorflow-saving-model-works-but-loading-it-doesnt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78535919/tensorflow-saving-model-works-but-loading-it-doesnt</guid>
      <pubDate>Sun, 26 May 2024 16:58:03 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：预期标量类型为 Long，但发现为 Int</title>
      <link>https://stackoverflow.com/questions/78535309/runtimeerror-expected-scalar-type-long-but-found-int</link>
      <description><![CDATA[我正在我的电脑上运行这个笔记本
这个笔记本使用 wav2vec2 基础模型处理音频分类
https://www.kaggle.com/code/dima806/music-genre-classification-wav2vec2-base-960h
并在步骤 trainer.evaluate() 上收到此错误
RuntimeError：预期标量类型为 Long，但发现 Int
请帮忙！！
希望运行时没有错误]]></description>
      <guid>https://stackoverflow.com/questions/78535309/runtimeerror-expected-scalar-type-long-but-found-int</guid>
      <pubDate>Sun, 26 May 2024 12:50:55 GMT</pubDate>
    </item>
    <item>
      <title>基于 Python 的模型学习，使用 TF、Keras 和 NLTK 进行标记</title>
      <link>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</link>
      <description><![CDATA[我已经使用 tensorflow、keras 和 nltk 在 Python 中开发了一个聊天机器人模型，用于标记化。当我在 vs 终端中运行它时，它会显示时间戳和模型提供答案所需的时间，但我试图在使用 React 设计的网站中显示它。如何从输出中删除日志。我尝试了所有方法，包括隐藏日志（除非它们至关重要），但我仍然无法删除它们。
我试过用这个，但没有用，它仍然显示它们。我知道日志不是警告，所以它们可能不会被删除。
import os os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;3&#39;]]></description>
      <guid>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</guid>
      <pubDate>Sat, 25 May 2024 08:01:27 GMT</pubDate>
    </item>
    <item>
      <title>在 PyCharm 虚拟环境中训练后模型未保存</title>
      <link>https://stackoverflow.com/questions/78531747/model-not-saving-after-training-in-pycharm-virtual-environment</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78531747/model-not-saving-after-training-in-pycharm-virtual-environment</guid>
      <pubDate>Sat, 25 May 2024 07:44:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 StandardScaler 正确扩展训练、验证和测试集？</title>
      <link>https://stackoverflow.com/questions/58823264/how-to-scale-train-validation-and-test-sets-properly-using-standardscaler</link>
      <description><![CDATA[有些文章说，在只有训练集和测试集的情况下，首先，我们需要使用 fit_transform() 来缩放训练集，然后只对测试集使用 transform()，以防止数据泄漏。
就我而言，我还有验证集。
我认为下面这些代码之一可以使用，但我不能完全依赖它们。任何形式的帮助都将不胜感激，谢谢！
1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 2/7)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

2)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 2/7)
X_test = scaler.transform(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/58823264/how-to-scale-train-validation-and-test-sets-properly-using-standardscaler</guid>
      <pubDate>Tue, 12 Nov 2019 16:54:52 GMT</pubDate>
    </item>
    </channel>
</rss>