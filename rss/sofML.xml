<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 30 Jul 2024 15:16:27 GMT</lastBuildDate>
    <item>
      <title>我写了一个代码，运行时间太长</title>
      <link>https://stackoverflow.com/questions/78812154/i-wrote-a-code-and-the-running-time-is-too-long</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78812154/i-wrote-a-code-and-the-running-time-is-too-long</guid>
      <pubDate>Tue, 30 Jul 2024 13:59:27 GMT</pubDate>
    </item>
    <item>
      <title>从采访脚本中提取问题和答案</title>
      <link>https://stackoverflow.com/questions/78812091/extracting-question-and-answer-from-the-interview-script</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78812091/extracting-question-and-answer-from-the-interview-script</guid>
      <pubDate>Tue, 30 Jul 2024 13:46:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么 bentoml serve 命令执行时间很长，而 localhost:3000 仍然没有响应</title>
      <link>https://stackoverflow.com/questions/78812002/why-does-the-bentoml-serve-command-take-a-lot-of-time-to-execute-and-still-local</link>
      <description><![CDATA[我在本地模型存储中保存了一个假新闻分类器，使用方法如下：
saved_model = bentoml.sklearn.save_model(&quot;FakeNewsClassifier&quot;,model)

当我使用 bentoml serve service:service 运行 service.py 时，执行需要很长时间，即使在此之后 localhost:3000 仍未加载。另外，我尝试使用 bentofile.yaml 执行，然后使用 bento build，但同样失败了。
service.py :
class Input(BaseModel):
text: str 

model_runner = bentoml.sklearn.get(&quot;fakenewsclassifier:latest&quot;).to_runner()

service = bentoml.Service(&quot;classifier&quot;,runners=[model_runner]) 

&#39;&#39;&#39;
问题 1：
像这样定义服务会导致错误，即资源不是属性
@bentoml.Service(name=&quot;News_Classifier&quot;, 
runners=[model_runner],
resources={&quot;cpu&quot;: &quot;200m&quot;, &quot;memory&quot;: &quot;512Mi&quot;}
)

问题2：
要指定资源，我们可以使用以下内容：

model_runner = bentoml.sklearn.get(&quot;fakenewsclassifier:latest&quot;).to_runner()
@bentoml.service(
resources={&quot;cpu&quot;: &quot;2&quot;},
Traffic={&quot;timeout&quot;: 10},
runners=[model_runner],
name=&quot;News-Classifier&quot;
)
@bentoml.api
def predict(input: Input):
#预测逻辑

这里的问题是 api 的输入和输出格式无法精确化。
问题 3：
即使在提到 train_model.py 作为一个包之后，为了防止不必要的导入，在条件 if __name__ == &quot;__main__&quot; 中保留除函数内部存在之外的语句，它们也会被执行。

问题 4：
另一个问题是，如果 
service = bentoml.Service(&quot;classifier&quot;,runners=[model_runner]) 
中指定的名称为大写，则会进行多个调用（此处为 16 个），如下所示，而不是 1 个：
2024-07-30T18:12:50+0530 [警告] [api_server:16] 将 News-Classifier 转换为 
小写：news-classifier。
问题 5：
所有这些结合在一起导致 vscode 和 windows 崩溃，删除它们并执行 bentoml serve service:service 后，执行开始，不会导致 VS Code 崩溃，但也不会加载 url http://localhost:3000
&#39;&#39;&#39;

@service.api(input=JSON(),output=JSON())
def predict(input: str):
try:
df = pd.DataFrame([input])
#processed_text = preprocess_data(df)

#X_test = model_runner.artifacts[&quot;tfidf_vectorizer&quot;].transform(processed_text[&#39;content&#39;])
#prediction = model_runner.artifacts[&quot;model&quot;].predict(X_test)

#prediction = [&#39;real&#39; if pred == 1 else &#39;fake&#39; for pred in prediction]
return {&quot;prediction&quot;: 1}

except BentoMLException as e:
return {&quot;error&quot;: str(e)}

最初我只是尝试使用 bentoml serve service:service 运行 bentoml 服务，但它给出了许多错误]]></description>
      <guid>https://stackoverflow.com/questions/78812002/why-does-the-bentoml-serve-command-take-a-lot-of-time-to-execute-and-still-local</guid>
      <pubDate>Tue, 30 Jul 2024 13:28:14 GMT</pubDate>
    </item>
    <item>
      <title>将字符串值映射到数据集中变量的数值时遇到错误（使用的语言是 python）</title>
      <link>https://stackoverflow.com/questions/78811760/encountering-error-while-mapping-string-values-to-numerical-values-of-variables</link>
      <description><![CDATA[X[&#39;Waterfront View&#39;] = X[&#39;Waterfront View&#39;].map({&#39;Yes&#39;:1, &#39;No&#39;:0})
X[&#39;Ever Renovated&#39;] = X[&#39;Ever Renovated&#39;].map({&#39;Yes&#39;:1, &#39;No&#39;:0})
X[&#39;Condition of the House&#39;] = X[&#39;Condition of the House&#39;].map({&#39;Excellent&#39;:5, &#39;Good&#39;:4, &#39;Okay&#39;:3, &#39;Fair&#39;:2, &#39;Bad&#39;:1})
X.head()
以下是代码，运行时，变量“Condition of the house”的值已正确更新，但“ever renovated”和“waterfront view”的值已更新为 NaN，这使得在进行线性回归拟合时出现问题，因为它不接受字符串或 NaN 值
我尝试删除代码段，导入数据集再次对这 3 个变量应用相应的映射。但这一次，这 3 个变量都没有正确更新。现在，所有 3 个变量“海滨景观”、“房屋状况”和“曾经翻新”都在各自的列中显示 NaN。因此，我无法对数据集应用线性回归。
缺失值已处理。]]></description>
      <guid>https://stackoverflow.com/questions/78811760/encountering-error-while-mapping-string-values-to-numerical-values-of-variables</guid>
      <pubDate>Tue, 30 Jul 2024 12:35:28 GMT</pubDate>
    </item>
    <item>
      <title>如何判断汽车配置的相似性？</title>
      <link>https://stackoverflow.com/questions/78811479/how-to-determine-the-similarity-of-a-cars-configuration</link>
      <description><![CDATA[大家好！
这里有一个车辆配置的数据集：

ID
品牌
型号
代数
发动机类型
发动机排量
气缸数
车身类型
变速箱类型
发动机代码
制造年份

任务：
需要确定一个配置与另一个配置的相似程度。
我假设将数据集中的每个条目表示为一个向量，并计算向量之间的余弦相似度。
但是对于如何以数值形式表示值存在误解，例如，车身类型：轿车、跨界车、轿跑车，等等。
感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/78811479/how-to-determine-the-similarity-of-a-cars-configuration</guid>
      <pubDate>Tue, 30 Jul 2024 11:38:50 GMT</pubDate>
    </item>
    <item>
      <title>DPR 模型微调无法在自定义数据集上收敛</title>
      <link>https://stackoverflow.com/questions/78810906/dpr-model-finetuning-does-not-converge-on-custom-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78810906/dpr-model-finetuning-does-not-converge-on-custom-dataset</guid>
      <pubDate>Tue, 30 Jul 2024 09:32:16 GMT</pubDate>
    </item>
    <item>
      <title>使用 Azure Vision AI 的预训练模型分析货架图像，同时检测货架中的物体和间隙</title>
      <link>https://stackoverflow.com/questions/78802566/detect-objects-gaps-in-a-shelf-while-analyzing-shelf-images-using-pretrained-m</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78802566/detect-objects-gaps-in-a-shelf-while-analyzing-shelf-images-using-pretrained-m</guid>
      <pubDate>Sat, 27 Jul 2024 22:14:06 GMT</pubDate>
    </item>
    <item>
      <title>语义分割中的数据增强[关闭]</title>
      <link>https://stackoverflow.com/questions/78798068/data-augmentation-in-semantic-segmentation</link>
      <description><![CDATA[我尝试对数据集执行数据增强，但得到的却是空白的白色图像，在蒙版上工作正常，但图像存在问题。
如何解决这个问题？
这是原始图像+蒙版
增强图像+蒙版
增强代码：
seed = 24
batch_size = 8

img_datagen_args = dict(rescale = 1/255,
rotation_range = 5,
zoom_range = 0.1,
Horizo​​ntal_flip = True,
Vertical_flip = True,
Fill_mode = &#39;nearest&#39;)

mask_datagen_args = dict(rescale = 1/255,
Rotation_range = 5,
Zoom_range = 0.1,
Horizo​​ntal_flip = True,
Vertical_flip = True,
Fill_mode = &#39;nearest&#39;,
Preprocessing_function = lambda x: np.where(x&gt;0, 1, 0).astype(x.dtype))

img_datagen = ImageDataGenerator(**img_datagen_args)
img_generator = img_datagen.flow_from_directory(&#39;/content/split_dataset/train/images/&#39;,
Seed = Seed,
Batch_size = Batch_size,
Class_mode = None)

mask_datagen = ImageDataGenerator(**mask_datagen_args)
mask_generator = mask_datagen.flow_from_directory(&#39;/content/split_dataset/train/masks/&#39;,
seed = seed,
batch_size = batch_size,
color_mode = &#39;grayscale&#39;,
class_mode = None)

valid_img_generator = img_datagen.flow_from_directory(&#39;/content/split_dataset/test/images/&#39;,
seed = seed,
batch_size = batch_size,
class_mode = None)

valid_mask_generator = mask_datagen.flow_from_directory(&quot;/content/split_dataset/test/masks/&quot;,
seed = seed,
batch_size = batch_size,
color_mode = &#39;grayscale&#39;,
class_mode = None)

train_generator = zip(img_generator, mask_generator)
valid_generator = zip(valid_img_generator, valid_mask_generator)

可视化代码：
import matplotlib.pyplot as plt

# 获取一批图像和掩码
img_batch, mask_batch = next(zip(img_generator, mask_generator))

# 绘制一些增强图像
fig, ax = plt.subplots(1, 4, figsize=(20, 5))
for i in range(4):
ax[i].imshow(img_batch[i]) # 对灰度图像使用 cmap=&#39;gray&#39;
ax[i].set_title(f&quot;Augmented Image {i+1}&quot;)
ax[i].axis(&#39;off&#39;)
plt.show()

# 绘制相应的掩码
fig, ax = plt.subplots(1, 4, figsize=(20, 5))
for i in range(4):
ax[i].imshow(mask_batch[i]) # 如果是灰度，则挤压以删除通道维度
ax[i].set_title(f&quot;增强蒙版 {i+1}&quot;)
ax[i].axis(&#39;off&#39;)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/78798068/data-augmentation-in-semantic-segmentation</guid>
      <pubDate>Fri, 26 Jul 2024 12:32:26 GMT</pubDate>
    </item>
    <item>
      <title>如何追踪之前图像的轮廓？</title>
      <link>https://stackoverflow.com/questions/78790401/how-do-i-track-a-contour-from-my-previous-image</link>
      <description><![CDATA[我有一个细菌细胞移动的视频，我将其转换为帧。现在我想找到每个细菌细胞的瞬时速度。为此，我感兴趣的是找出细菌细胞移动了多少，但我不知道如何告诉我的程序准确识别这种特定的细菌移动了。例如，假设我只有两张图像。对于每张图像，我都有每种细菌的 COM 坐标。现在我如何关联这些数据。我如何让我的程序准确识别这种特定细菌的 COM 变化量。我已将两张图片附上以供参考。


我想到的一个方法是给每个轮廓一个唯一的 id，并将该轮廓的特征与该唯一 id 关联起来。例如它的长轴和短轴长度。这样我就可以关联轮廓的初始和最终 COM。但是这个想法假设所有细菌细胞都是独一无二的，并且我的代码可以准确而精确地识别每个细菌细胞的轮廓，但事实并非如此。如果您感兴趣，我还附上了查找每个细菌细胞轮廓的代码。有人可以提出一些更好的想法吗？非常感谢。
import cv2 as cv
import numpy as np
from numpy.typing import NDArray
import math

def gaussian_filter_multiscale_retinex(image: NDArray, sigmas: list[float], weights: list[float]) -&gt;; NDArray:
img32 = image.astype(&#39;float32&#39;) / 255

img32_log = cv.log(img32 + 1)

msr = np.zeros(image.shape, np.float32)
对于 zip(sigmas, weights) 中的 sigma、weight:

blur = cv.GaussianBlur(img32, ksize=(0, 0), sigmaX=sigma)
blur_log = cv.log(blur + 1)
ssr = cv.subtract(img32_log, blur_log)
ssr = cv.multiply(ssr, weight)

msr = cv.add(msr, ssr)

msr = cv.divide(msr, sum(weights))

msr = cv.normalize(msr, None, 0, 255, cv.NORM_MINMAX, cv.CV_8U)
返回 msr
def calculate_ellipse_area(椭圆):

(cx, cy), (a, b), 角度 = 椭圆
半长轴 = a / 2
半短轴 = b / 2
面积 = math.pi * 半长轴 * 半短轴
返回面积，角度

def process_image(img, size_threshold):
gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
rtnx = gaussian_filter_multiscale_retinex(gray, sigmas=[15, 55, 185], weights=[10, 5, 1])
阈值 = cv.adaptiveThreshold(rtnx, 255,自适应方法 = cv.ADAPTIVE_THRESH_GAUSSIAN_C，
阈值类型 = cv.THRESH_BINARY，blockSize = 7，C = -7)
nb_components，输出，统计，_ = cv.connectedComponentsWithStats（阈值，连通性 = 8）
大小 = 统计 [1：，-1]
new_img = np.zeros_like（阈值）
对于 i 在范围内（0，nb_components - 1）：
如果sizes [i]＆gt; = size_threshold：
new_img [输出 == i + 1] = 255
connected_components = cv.connectedComponentsWithStats（new_img）
（numLabels，标签，统计，质心）=connected_components

result_image = np.ones_like（img）* 255
对于 i 在范围内（1， numLabels):
componentMask = (labels == i).astype(&#39;uint8&#39;)
contours, _ = cv.findContours(componentMask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)
if len(contours) &gt; 0:
cnt = contours[0]
if len(cnt) &gt;= 5:
ellipse = cv.fitEllipse(cnt)
area, angle = calculate_ellipse_area(ellipse)
if area &lt; 250:
cv.ellipse(result_image, ellipse, (0, 0, 0), 1) # 在白色背景上绘制黑色轮廓
return result_image
img1path = &quot;/Users/yahya2/Desktop/1.png&quot;
img = cv.imread(img1path)
size_threshold = 16
result_image = process_image(img, size_threshold)

cv.imshow(&#39;轮廓&#39;, result_image)
cv.waitKey(0)
cv.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78790401/how-do-i-track-a-contour-from-my-previous-image</guid>
      <pubDate>Wed, 24 Jul 2024 20:14:25 GMT</pubDate>
    </item>
    <item>
      <title>运行预先训练的 ONNX 模型 - 图像识别</title>
      <link>https://stackoverflow.com/questions/75360420/running-a-pre-trained-onnx-model-image-recognition</link>
      <description><![CDATA[我正在尝试运行一个预先训练的 ONNX 模型（在第三方标签工具上训练）来进行图像识别。该模型通过工具中的一些预定义标签进行训练。现在的下一个目标是能够在工具之外运行此模型。为此，我正在获取示例图像并尝试通过模型运行该模型以获取已识别的标签作为输出。在此过程中，我遇到了有关如何调整输入的障碍。该模型需要输入如下：

如何在以下代码中调整输入？
import cv2
import numpy as np
import onnxruntime
import pytesseract
import PyPDF2

# 加载图像
image = cv2.imread(&quot;example.jpg&quot;)

# 检查图像是否已成功加载
if image is None:
raise ValueError(&quot;Failed to load the image&quot;)

# 获取图像的形状
height, width = image.shape[:2]

# 确保高度和宽度为正数
if height &lt;= 0 or width &lt;= 0:
raise ValueError(&quot;无效图像大小&quot;)

# 设置调整大小后图像的所需大小
dsize = (640, 640)

# 使用 cv2.resize 调整图像大小
resized_image = cv2.resize(image, dsize)

# 显示调整大小后的图像
cv2.imshow(&quot;调整大小后的图像&quot;, resized_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

# 加载 ONNX 模型
session = onnxruntime.InferenceSession(&quot;ic/model.onnx&quot;)

# 检查模型是否已成功加载
if session is None:
raise ValueError(&quot;加载模型失败&quot;)

# 获取模型的输入名称和形状
inputs = session.get_inputs()
for i, input_info in enumerate(inputs):
print(f&quot;Input {i}: name = {input_info.name}, shape = {input_info.shape}&quot;)

# 运行 ONNX 模型
input_name = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name
prediction = session.run([output_name], {input_name: image})[0]

# 对预测进行后处理以获取标签
labels = postprocess(prediction)

# 使用 PyTesseract 从图像中提取文本
text = pytesseract.image_to_string(image)

# 打印标签和文本
print(&quot;Labels:&quot;, labels)
print(&quot;Text:&quot;, text)

因为代码抛出了以下错误：
ValueError: Model 需要 4 个输入。输入 Feed 包含 1]]></description>
      <guid>https://stackoverflow.com/questions/75360420/running-a-pre-trained-onnx-model-image-recognition</guid>
      <pubDate>Mon, 06 Feb 2023 10:58:44 GMT</pubDate>
    </item>
    <item>
      <title>理解 sklearn 的 KNNImputer</title>
      <link>https://stackoverflow.com/questions/61752284/understanding-sklearns-knnimputer</link>
      <description><![CDATA[我浏览了它的文档，上面写着

每个样本的缺失值都是使用在训练集中找到的
n_neighbors 最近邻居的平均值来估算的。如果两个样本都没有缺失的特征接近，则这两个样本接近。

现在，使用一个玩具数据集，即
&gt;&gt;&gt;X = [[1, 2, nan], [3, 4, 3], [nan, 6, 5], [8, 8, 7]]
&gt;&gt;&gt;X

[[ 1., 2., nan],
[ 3., 4., 3.],
[nan, 6., 5.],
[ 8., 8., 7.]]

我们制作一个 KNNImputer，如下所示：
imputer = KNNImputer(n_neighbors=2)

问题是，它如何填充nan，而其中两列中有 nan？例如，如果要在第一行第三列中填充 nan，由于其中一行在第一列中也有 nan，它将如何选择最接近的特征？当我执行 imputer.fit_transform(X) 时，它给了我
array([[1. , 2. , 4. ],
[3. , 4. , 3. ],
[5.5, 6. , 5. ],
[8. , 8. , 7. ]])

这意味着要在第一行中填充 nan，最近的邻居是第二行和第三行。第一行和第三行之间的欧氏距离是如何计算的？]]></description>
      <guid>https://stackoverflow.com/questions/61752284/understanding-sklearns-knnimputer</guid>
      <pubDate>Tue, 12 May 2020 12:54:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras、Tensorflow 中导入 LSTM</title>
      <link>https://stackoverflow.com/questions/45296656/how-to-import-lstm-in-keras-tensorflow</link>
      <description><![CDATA[尝试导入 LSTM 层时，我遇到以下错误：
from keras.layers.recurrent import LSTM


没有名为“LSTM”的模块

因此，我尝试从网站下载此模块，另一个问题是文件类型是 .tar，我不知道如何安装它。 ]]></description>
      <guid>https://stackoverflow.com/questions/45296656/how-to-import-lstm-in-keras-tensorflow</guid>
      <pubDate>Tue, 25 Jul 2017 07:29:36 GMT</pubDate>
    </item>
    <item>
      <title>为 LeNet 创建数据集？</title>
      <link>https://stackoverflow.com/questions/36509340/create-dataset-for-lenet</link>
      <description><![CDATA[我正在做一个项目，我想创建一个绘制人脸的数据集（概念上类似于 CUFS 数据集）。除了手绘人脸之外，我该如何从“我已将这些图像文件上传到我的计算机并确保它们都具有相同的尺寸”到拥有一个随时可用的数据集？（我想用这个数据集训练/测试 LeNet。）我以前从未创建过自己的数据集，所以不太确定如何开始。
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/36509340/create-dataset-for-lenet</guid>
      <pubDate>Fri, 08 Apr 2016 21:05:15 GMT</pubDate>
    </item>
    <item>
      <title>mAP 指标是什么以及如何计算？[关闭]</title>
      <link>https://stackoverflow.com/questions/36274638/what-is-the-map-metric-and-how-is-it-calculated</link>
      <description><![CDATA[在计算机视觉和物体检测中，一种常见的评估方法是mAP。
它是什么以及如何计算？]]></description>
      <guid>https://stackoverflow.com/questions/36274638/what-is-the-map-metric-and-how-is-it-calculated</guid>
      <pubDate>Tue, 29 Mar 2016 03:03:12 GMT</pubDate>
    </item>
    <item>
      <title>我如何检测实心圆圈的网格？</title>
      <link>https://stackoverflow.com/questions/35320416/how-can-i-detect-a-grid-of-filled-circles</link>
      <description><![CDATA[给定一个四子棋盘的图像，我想要识别并输出棋盘的状态（一个 6×7 的矩阵）。我尝试的第一种方法是基于找到圆，然后在它们的质心处寻找网格图案。
这是我使用的 open-cv 函数：
circles = cv2.HoughCircles(bw_im,
cv2.cv.CV_HOUGH_GRADIENT,
dp=DP,
minDist=MIN_DIST,
minRadius=MIN_RADIUS,
maxRadius=MAX_RADIUS)

我添加了非最大抑制，但结果并不好。
有没有比直接处理霍夫圆更好的方法，也许有某种我不知道的填充圆形形态学操作。
这是一个示例输入图像：

您可以假设输入图片已被裁剪，并且具有与上图类似的边距（我有另一段代码可以处理这个问题）。]]></description>
      <guid>https://stackoverflow.com/questions/35320416/how-can-i-detect-a-grid-of-filled-circles</guid>
      <pubDate>Wed, 10 Feb 2016 16:18:37 GMT</pubDate>
    </item>
    </channel>
</rss>