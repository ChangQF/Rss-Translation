<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 28 Nov 2024 21:16:14 GMT</lastBuildDate>
    <item>
      <title>如何使用 Arm CMSIS-NN Softmax 函数进行嵌入式机器学习</title>
      <link>https://stackoverflow.com/questions/79235253/how-to-use-arm-cmsis-nn-softmax-function-for-embedded-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79235253/how-to-use-arm-cmsis-nn-softmax-function-for-embedded-ml</guid>
      <pubDate>Thu, 28 Nov 2024 20:33:38 GMT</pubDate>
    </item>
    <item>
      <title>如何比较不同年份的集群？</title>
      <link>https://stackoverflow.com/questions/79234461/how-to-compare-clusters-from-different-years</link>
      <description><![CDATA[我有多个数据集，所有数据集的组织方式都类似（相同的变量、值等）。我使用 KModes 独立分析了数据集，但是，我试图寻找多年来可能出现的趋势。我该如何比较不同年份的集群？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79234461/how-to-compare-clusters-from-different-years</guid>
      <pubDate>Thu, 28 Nov 2024 15:14:27 GMT</pubDate>
    </item>
    <item>
      <title>无法从 xgboost 导入名称 XGBRegressor（未知位置）</title>
      <link>https://stackoverflow.com/questions/79234191/cannot-import-name-xgbregressor-from-xgboost-unknown-location</link>
      <description><![CDATA[xgboost 错误
无法导入 XGBRegressor
我在 vscode 上创建了一个环境，用于为机器学习项目实现端到端管道。我的大部分代码都保存在 github 中。我使用 requirements.txt 文件安装了所有 python 包。除了 xgboost 之外，其他所有包都可以使用]]></description>
      <guid>https://stackoverflow.com/questions/79234191/cannot-import-name-xgbregressor-from-xgboost-unknown-location</guid>
      <pubDate>Thu, 28 Nov 2024 13:56:19 GMT</pubDate>
    </item>
    <item>
      <title>利用贝叶斯优化进行黑箱优化</title>
      <link>https://stackoverflow.com/questions/79233932/blackbox-opimization-with-bayesian-optimization</link>
      <description><![CDATA[我想使用贝叶斯优化来识别物理实验中新的有趣参数。
更具体地说，我想用已知的有界实验参数初始化算法，并使用贝叶斯优化进行黑盒优化。我目前正在使用一个名为“bayes_op”的库在 Python 上工作，但是，我发现的所有示例都使用了数学定义的函数。
我想首先给出函数在某些实验点上的得分，以开始算法，然后获得下一个有趣的实验参数的建议。
到目前为止，我已经成功地从随机参数开始优化已知函数。但是，我想知道是否有可能在不提供显式函数的情况下使用此算法，同时利用已有的实验数据。我想补充一点，我没有数据集来训练任何东西。]]></description>
      <guid>https://stackoverflow.com/questions/79233932/blackbox-opimization-with-bayesian-optimization</guid>
      <pubDate>Thu, 28 Nov 2024 12:40:07 GMT</pubDate>
    </item>
    <item>
      <title>ML。如何让神经网络记住上下文和数据？</title>
      <link>https://stackoverflow.com/questions/79233875/ml-how-to-make-a-neural-network-remember-the-context-and-data</link>
      <description><![CDATA[我希望神经网络能够记忆，但感知器只能在训练期间记住一些东西，但我希望神经网络能够适应新情况而无需重新训练，例如，如果我说我的名字是尼古拉，它就会记住，或者如果绿色蘑菇以前在游戏中有用，但后来变得有毒，它就会停止食用，然后，如果它们恢复正常，它就会再次开始食用。我考虑过 LSTM，但这是一个循环神经网络，人们似乎正在放弃它们而选择 transformer？]]></description>
      <guid>https://stackoverflow.com/questions/79233875/ml-how-to-make-a-neural-network-remember-the-context-and-data</guid>
      <pubDate>Thu, 28 Nov 2024 12:20:41 GMT</pubDate>
    </item>
    <item>
      <title>运行贝叶斯寻找最佳超参数时出错</title>
      <link>https://stackoverflow.com/questions/79233155/error-while-running-bayesian-for-finding-best-hyperparameter</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79233155/error-while-running-bayesian-for-finding-best-hyperparameter</guid>
      <pubDate>Thu, 28 Nov 2024 08:53:05 GMT</pubDate>
    </item>
    <item>
      <title>从 PHP 脚本调用时，Flask API 始终预测相同的类</title>
      <link>https://stackoverflow.com/questions/79232596/flask-api-always-predicts-the-same-class-when-called-from-php-script</link>
      <description><![CDATA[我使用 Flask 开发了一个 API，用于集成一个在胸部 X 光片图像上训练的深度学习模型，用于肺炎检测。为了测试 PHP 和 Flask API 之间的连接，我成功使用了 Fashion MNIST 模型（用于服装分类），并且该模型可以正确预测类别。
但是，当我尝试使用我的自定义训练模型进行肺炎检测（在评估期间表现非常好）时，我注意到即使图像处于“正常”状态，该模型也始终预测类别“肺炎”类。
模型性能（在测试集上）：
测试损失：11.41%
测试准确率：97.10%
测试精度：97.46%
测试召回率：98.60%
测试AUC：98.33%
采取的步骤：
训练：我使用 ResNet50 层和附加自定义层训练模型。
测试：我在包含正常和肺炎图像的测试集上测试了模型，它表现良好。
通过 Flask API 进行测试：我尝试通过 PHP 将图像发送到 Flask API，但模型始终预测“肺炎”。
Flask API 代码：
从 flask 导入 Flask、请求、jsonify
从 tensorflow 导入keras
import numpy as np
from PIL import Image

app = Flask(__name__)

# 加载模型
model = keras.models.load_model(&#39;path_to_your_model&#39;)

# 类名
class_names = [&#39;NORMAL&#39;, &#39;PNEUMONIA&#39;]

@app.route(&#39;/predict&#39;, methods=[&#39;POST&#39;])
def predict():
if &#39;image&#39; not in request.files:
return jsonify({&#39;error&#39;: &#39;No image file provided&#39;}), 400

image = request.files[&#39;image&#39;]

try:
# 将图像转换为 RGB 并调整其大小
img = Image.open(image).convert(&#39;RGB&#39;)
img = img.resize((224, 224))

# 将图像转换为数组并扩展维度以匹配模型输入
img_array = np.array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0) # 添加批次维度

# 进行预测
prediction = model.predict(img_array)

# 获取预测类别
predict_class = class_names[int(prediction[0] &gt; 0.5)]

return jsonify({
&#39;prediction&#39;: predict_class,
&#39;probability&#39;: float(prediction[0])
})
except Exception as e:
return jsonify({&#39;error&#39;: f&quot;An error occurred: {str(e)}&quot;}), 500

if __name__ == &#39;__main__&#39;:
app.run(debug=True)


将图像发送到 Flask API 的 PHP 代码：
&lt;?php
if (isset($_POST[&#39;submit&#39;])) {
if (isset($_FILES[&#39;img&#39;]) &amp;&amp; $_FILES[&#39;img&#39;][&#39;error&#39;] == 0) {
$image = $_FILES[&#39;img&#39;][&#39;name&#39;];
$image_tmp_name = $_FILES[&#39;img&#39;][&#39;tmp_name&#39;];
$folder = &#39;uploaded_img/&#39;;
$image_folder = $folder . $image;

if (!is_dir($folder)) {
mkdir($folder, 0777, true);
}

if (move_uploaded_file($image_tmp_name, $image_folder)) {
$url = &#39;http://localhost:5000/predict&#39;;
$cfile = new CURLFile($image_folder, &#39;image/jpeg&#39;, $image);
$data = array(&#39;image&#39; =&gt; $cfile);

$ch = curl_init();
curl_setopt($ch, CURLOPT_URL, $url);
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, $data);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($ch);
curl_close($ch);

if ($response === false) {
echo &quot;预测错误！&quot;;
} else {
$result = json_decode($response, true);
echo &quot;预测：&quot; . $result[&#39;prediction&#39;];
}
}
}
}
?&gt;


问题：尽管该模型在本地测试时运行良好，并且在 NORMAL 和 PNEUMONIA 图像上具有良好的性能指标，但当我通过 Flask API（通过 PHP）对其进行测试时，该模型始终预测 &quot;PNEUMONIA&quot;，即使图像来自 &quot;NORMAL&quot;类。
我发送图像的方式或 Flask API 处理图像的方式是否存在问题？]]></description>
      <guid>https://stackoverflow.com/questions/79232596/flask-api-always-predicts-the-same-class-when-called-from-php-script</guid>
      <pubDate>Thu, 28 Nov 2024 04:30:21 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中的 GaussianProcessRegressor 估计器可以在多核上并行化吗？</title>
      <link>https://stackoverflow.com/questions/79232519/is-the-gaussianprocessregressor-estimator-in-scikit-learn-able-to-be-parallelize</link>
      <description><![CDATA[在具有 8 个内核（16 个线程）的机器上使用 GaussianProcessRegressor 时，我没有注意到任何性能改进，尽管我只使用物理内核。所以我想知道，sklearn.gaussian_process 中的 GaussianProcessRegressor 类是否能够利用多个处理器/内核/线程？
#当前场景
4 个内核情况下的时间：0.57
8 个内核情况下的时间：0.56
加速不明显。这次只是将 fit_transform 作用于数据块。因此没有计时开销。]]></description>
      <guid>https://stackoverflow.com/questions/79232519/is-the-gaussianprocessregressor-estimator-in-scikit-learn-able-to-be-parallelize</guid>
      <pubDate>Thu, 28 Nov 2024 03:36:56 GMT</pubDate>
    </item>
    <item>
      <title>通过建模进行需求预测[关闭]</title>
      <link>https://stackoverflow.com/questions/79232517/demand-prediction-through-modeling</link>
      <description><![CDATA[在此处输入图片说明我的公司正在开展一个按客户预测需求的项目。客户分为 6 个行业组，我们有按客户划分的过去需求数据。当我按行业组检查模式时，结果如下，由于确定了特定模式，我对数据进行了预处理（时间序列分解），似乎可以看到特定的趋势和周期。由于残差不是随机的，我认为我需要添加解释变量，但即使我添加变量，我也不认为我可以使其完全随机。因为它是时间序列数据，并且需求模式的特征因行业组而异，所以我想按行业组进行拆分并应用每个模型。我正在考虑将 SARIMAX 作为候选模型，
问题是：

为什么 LSTM 不适合这种情况
我应该如何预处理和建模？
我还应该考虑哪些其他因素？

2 年的需求模式和时间序列分解（趋势、季节性）
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/79232517/demand-prediction-through-modeling</guid>
      <pubDate>Thu, 28 Nov 2024 03:35:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么某些模型架构使用加法运算符而不是减法，反之亦然？[关闭]</title>
      <link>https://stackoverflow.com/questions/79232424/why-do-some-model-architectures-use-the-addition-operator-instead-of-subtraction</link>
      <description><![CDATA[为什么有些模型架构使用加法运算符而不是减法运算符，反之亦然？例如，在 ResNet 中，更改运算符是否会影响模型（F(x) + x -&gt; F(x) - x）？模型是否只需通过翻转符号就可以轻松学习？]]></description>
      <guid>https://stackoverflow.com/questions/79232424/why-do-some-model-architectures-use-the-addition-operator-instead-of-subtraction</guid>
      <pubDate>Thu, 28 Nov 2024 02:39:18 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Hugging Face Trainer 或 SFT Trainer 中记录第零步的训练损失？</title>
      <link>https://stackoverflow.com/questions/79232257/how-to-log-training-loss-at-step-zero-in-hugging-face-trainer-or-sft-trainer</link>
      <description><![CDATA[我正在使用 Hugging Face Trainer（或 SFTTrainer）进行微调，我想在步骤 0（在执行任何训练步骤之前）记录训练损失。我知道有一个用于评估的 eval_on_start 选项，但我找不到在训练开始时记录训练损失的直接等效方法。
是否有办法使用 Trainer 或 SFTTrainer 在步骤 0（在任何更新之前）记录初始训练损失？理想情况下，我希望使用类似于 eval_on_start 的方法。
以下是我迄今为止尝试过的方法：
解决方案 1：自定义回调
我实现了自定义回调，以在训练开始时记录训练损失：
from transformers import TrainerCallback

class TrainOnStartCallback(TrainerCallback):
def on_train_begin(self, args, state, control, logs=None, **kwargs):
# 在步骤 0 记录训练损失
logs = logs or {}
logs[&quot;train/loss&quot;] = None # 如果可用，用初始值替换 None
logs[&quot;train/global_step&quot;] = 0
self.log(logs)

def log(self, logs):
print(f&quot;Logging at start: {logs}&quot;)
wandb.log(logs)

# 将回调添加到 Trainer
trainer = SFTTrainer(
model=model,
tokenizer=tokenizer,
train_dataset=train_dataset,
eval_dataset=eval_dataset,
args=training_args,
optimizers=(optimizer, scheduler),
callbacks=[TrainOnStartCallback()],
)

这有效，但感觉有点过头了。它会在训练开始时记录任何步骤之前的指标。
解决方案 2：手动记录
或者，我在开始训练之前手动记录训练损失：
wandb.log({&quot;train/loss&quot;: None, &quot;train/global_step&quot;: 0})
trainer.train()

问题：
Trainer 或 SFTTrainer 中是否有任何内置功能可以在第 0 步记录训练损失？或者自定义回调或手动记录是这里的最佳解决方案吗？如果是这样，是否有更好的方法来实现此功能？与 eval_on_start 类似，但 train_on_start？
交叉：https://discuss.huggingface.co/t/how-to-log-training-loss-at-step-zero-in-hugging-face-trainer-or-sft-trainer/128188]]></description>
      <guid>https://stackoverflow.com/questions/79232257/how-to-log-training-loss-at-step-zero-in-hugging-face-trainer-or-sft-trainer</guid>
      <pubDate>Thu, 28 Nov 2024 00:23:35 GMT</pubDate>
    </item>
    <item>
      <title>如何解决矢量化器不匹配问题</title>
      <link>https://stackoverflow.com/questions/79231510/how-do-i-resolve-vectorizer-mismatch</link>
      <description><![CDATA[我正在使用 TfidfVectorizer 作为文本矢量化器，但当我尝试获取 cosine_similarity 时，我遇到了维度不匹配的问题。
我的情况如下：
首先，
def clean_text(text):
return re.sub(r&#39;[^a-zA-Z0-9 ]&#39;, &quot;&quot;, text)

movies[&#39;title&#39;] = movies[&#39;title&#39;].apply(clean_text)

vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words =&#39;english&#39;)

title_vec = vectorizer.fit_transform(movies[&#39;title&#39;])

title = &quot;Toy Story&quot;

title = clean_text(title)

word_vec = vectorizer.transform([title])

similarity = cosine_similarity(word_vec, title_vec)

这会导致错误消息：
ValueError: X 和 Y 矩阵的维度不兼容：X.shape[1] == 172412 而 Y.shape[1] == 156967

PS：我检查了 word_vec 和 title_vec 的 len，它们显示的长度不同。
我在 vectorizer 中设置了 ngram_range=(1,1)，但没有得到肯定的结果。
我使用了 countvectorizer()，但问题仍然存在
我没有其他选择，而 chatGPT 提供的解决方案也无法解决问题：
from scipy.sparse import hstack

用零填充较小的矩阵
if word_vec.shape[1] &gt; title_vec.shape[1]:
diff = word_vec.shape[1] - title_vec.shape[1]
title_vec = hstack([title_vec, np.zeros((title_vec.shape[0], diff))])
elif title_vec.shape[1] &gt; word_vec.shape[1]:
diff = title_vec.shape[1] - word_vec.shape[1]
word_vec = hstack([word_vec, np.zeros((word_vec.shape[0], diff))])

所以我不能使用上面的代码，但我把它放在这里以显示这个问题的严重程度。]]></description>
      <guid>https://stackoverflow.com/questions/79231510/how-do-i-resolve-vectorizer-mismatch</guid>
      <pubDate>Wed, 27 Nov 2024 18:38:44 GMT</pubDate>
    </item>
    <item>
      <title>如何摆脱 Unity ML 中找不到类型或命名空间名称“Keypoint”的错误</title>
      <link>https://stackoverflow.com/questions/79231502/how-to-get-rid-of-the-type-or-namespace-name-keypoint-could-not-be-found-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79231502/how-to-get-rid-of-the-type-or-namespace-name-keypoint-could-not-be-found-error</guid>
      <pubDate>Wed, 27 Nov 2024 18:36:11 GMT</pubDate>
    </item>
    <item>
      <title>如何从本地向量数据库中删除特定的问答对？</title>
      <link>https://stackoverflow.com/questions/79226011/how-to-delete-a-specific-question-response-pair-from-a-local-vector-database</link>
      <description><![CDATA[我已经实现了一个基于反馈的聊天机器人，它将问题-响应对存储在本地向量数据库中。我使用以下设置来访问向量数据库：
import os

VECTOR_DB_PATH = os.path.join(os.getcwd(), &quot;vectordb&quot;)

向量数据库用于存储嵌入和响应，以实现高效的相似性搜索。现在，我想从向量数据库中删除特定的问题-响应对。我知道我想删除的对（例如，问题：“你好吗？”，回答：“我很好，谢谢！”），但我不确定如何以编程方式从数据库中删除它。
以下是有关我的设置的一些详细信息：
我使用的向量数据库库是 FAISS。
问题的嵌入存储在数据库中以供检索。
我可以成功访问和查询向量数据库。
我正在使用的库是
import json
import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import boto3
import botocore
from langchain.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

从向量数据库中查找和删除特定对的最佳方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/79226011/how-to-delete-a-specific-question-response-pair-from-a-local-vector-database</guid>
      <pubDate>Tue, 26 Nov 2024 09:12:37 GMT</pubDate>
    </item>
    <item>
      <title>何时使用 mlflow.set_tag() 与 mlflow.log_params()？</title>
      <link>https://stackoverflow.com/questions/72473826/when-to-use-mlflow-set-tag-vs-mlflow-log-params</link>
      <description><![CDATA[我对 mlflow.set_tag() 与 mlflow.log_params() 的用例感到困惑，因为两者都采用键和值对。目前，我使用 mlflow.set_tag() 来设置数据版本、代码版本等的标签，使用 mlflow.log_params() 来设置模型训练参数，如损失、准确率、优化器等。]]></description>
      <guid>https://stackoverflow.com/questions/72473826/when-to-use-mlflow-set-tag-vs-mlflow-log-params</guid>
      <pubDate>Thu, 02 Jun 2022 09:23:32 GMT</pubDate>
    </item>
    </channel>
</rss>