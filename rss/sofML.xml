<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 01 Apr 2024 09:15:13 GMT</lastBuildDate>
    <item>
      <title>我只想在 python 中从该图像中提取图形部分，我该怎么做？</title>
      <link>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</link>
      <description><![CDATA[我想将右侧的两个图一起提取，也不能单独提取，两者都可以提取为一个（https://i.stack.imgur.com/RqwkB.jpg)
我不知道该尝试什么，我对此很陌生。我正在使用 python，我从图像中提取文本并将其保存在 csv 中
&lt;前&gt;&lt;代码&gt;导入cv2
            将 numpy 导入为 np

            # 加载图像
            image_path = r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\1.jpg&#39;
            图像 = cv2.imread(image_path)

            # 将图像转换为灰度图
            灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

            # 应用高斯模糊来减少噪音
            模糊 = cv2.GaussianBlur(灰色, (5, 5), 0)

            # 应用 Canny 边缘检测
            边缘 = cv2.Canny(模糊, 50, 150)

            # 在边缘检测图像中查找轮廓
            轮廓，_ = cv2.findContours（边缘，cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_SIMPLE）

            # 根据面积过滤轮廓，找到最大的轮廓（假设图形是面积最大的）
            轮廓=排序（轮廓，键= cv2.contourArea，反向= True）[：1]

            # 创建一个掩码来提取图形区域
            mask = np.zeros_like(灰色)
            cv2.drawContours(蒙版, 轮廓, -1, (255, 255, 255), 厚度=cv2.FILLED)

            # 将掩模应用于原始图像以提取图形
            图= cv2.bitwise_and（图像，图像，掩码=掩码）

            # 保存提取的图形图像
            cv2.imwrite(r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\output\extracted_graph.jpg&#39;, graph)
]]></description>
      <guid>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</guid>
      <pubDate>Mon, 01 Apr 2024 08:33:52 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：使用 `bitsandbytes` 8 位量化需要 Accelerate：`pip install Accelerate` 和最新版本的 Bitsandbytes：`pip install</title>
      <link>https://stackoverflow.com/questions/78254344/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78254344/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate-pip-i</guid>
      <pubDate>Mon, 01 Apr 2024 08:15:53 GMT</pubDate>
    </item>
    <item>
      <title>视觉 Transformer 模型的回归</title>
      <link>https://stackoverflow.com/questions/78253997/regression-on-the-vision-transformers-model</link>
      <description><![CDATA[我正在尝试对视觉变换器模型进行回归，但无法用回归层替换最后一层分类
当我尝试初始化模型时收到此错误
&lt;前&gt;&lt;代码&gt;
类 RegressionViT(nn.Module):
    def __init__(self, in_features=224 * 224 * 3, num_classes=1, pretrained=True):
        super(RegressionViT, self).__init__()
        self.vit_b_16 = vit_b_16(pretrained=pretrained) # 加载预训练权重

        # 用回归头替换最终的分类层
        self.regressor = nn.Linear(self.vit_b_16.heads.in_features, num_classes)

    def 前向（自身，x）：
        x = self.vit_b_16(x)
        x = self.regressor(x)
        返回x
]]></description>
      <guid>https://stackoverflow.com/questions/78253997/regression-on-the-vision-transformers-model</guid>
      <pubDate>Mon, 01 Apr 2024 06:33:32 GMT</pubDate>
    </item>
    <item>
      <title>NLP 中的序列分类/标记</title>
      <link>https://stackoverflow.com/questions/78253915/sequence-classification-labelling-in-nlp</link>
      <description><![CDATA[我正在尝试 nlp 的序列分类/标记。我有一些逻辑问题需要专家的回答。
这些问题与下面链接中给出的数据集相关。
数据集：https://huggingface.co/datasets /surrey-nlp/PLOD-CW/viewer/default/train

预处理：我正在删除停用词、标点符号和词形还原。这是正确的方法吗？

在“tokens”列的预处理过程中，我是否需要相应地更新 pos_tags 和 ner_tags 列，还是保持其余列相同？

接下来，我是否需要仅对预处理数据进行矢量化和构建模型？ （新的“tokens”、“pos_tags”、“ner_tags”列）


我做了什么：
我只预处理了“tokens”列，并保持其他列与原始数据集中相同。
我所期望的：
我在可视化数据时意识到其余列也应该更新]]></description>
      <guid>https://stackoverflow.com/questions/78253915/sequence-classification-labelling-in-nlp</guid>
      <pubDate>Mon, 01 Apr 2024 06:05:32 GMT</pubDate>
    </item>
    <item>
      <title>我的 PyTorch 回归机器学习程序没有学习</title>
      <link>https://stackoverflow.com/questions/78253278/my-pytorch-machine-learning-program-for-regression-is-not-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78253278/my-pytorch-machine-learning-program-for-regression-is-not-learning</guid>
      <pubDate>Mon, 01 Apr 2024 01:08:49 GMT</pubDate>
    </item>
    <item>
      <title>使用相机模块训练的 ML 模型未给出预测</title>
      <link>https://stackoverflow.com/questions/78252865/trained-ml-model-with-the-camera-module-is-not-giving-predictions</link>
      <description><![CDATA[我已经训练了 CNN 模型并将其保存为 .h5 格式，但是当我在相机的帮助下使用它进行预测时，我无法预测，相机打开但没有预测和其他内容
这是我的代码，我实际上正在学习 ML，所以你能解决这个问题吗？
这是我的代码，我实际上正在学习 ML，所以你能解决这个问题吗？
当我向笔记本电脑摄像头显示图像时，我希望预测图像类别
将 numpy 导入为 np
导入CV2
从 keras.models 导入 load_model

# 加载模型
模型 = load_model(&#39;C:/Users/Win/Downloads/traffic_classifier.h5&#39;)

＃ 参数
帧宽度 = 640 # 相机分辨率
框架高度 = 480
亮度=180
阈值 = 0.5 # 概率阈值
字体= cv2.FONT_HERSHEY_SIMPLEX

# 设置摄像机
上限 = cv2.VideoCapture(0)
cap.set(3, 框架宽度)
cap.set(4, 框架高度)
cap.set(10, 亮度)

def 预处理(img):
    # 将图像转换为RGB格式
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # 将图像大小调整为 30x30
    img = cv2. 调整大小(img, (30, 30))
    # 标准化像素值
    图片 = 图片 / 255.0
    # 添加批次维度
    img = np.expand_dims(img, 轴=0)
    返回图片

def getClassName(类号):
    类={
        0: &#39;限速 20 公里/小时&#39;,
        1：“限速 30 公里/小时”，
        2：“限速 50 公里/小时”，
        3：“限速 60 公里/小时”，
        4：“限速 70 公里/小时”，
        5：“限速 80 公里/小时”，
        6：“限速 80 公里/小时结束”，
        7: &#39;限速 100 公里/小时&#39;,
        8：“限速 120 公里/小时”，
        9：“禁止通过”，
        10：“3.5吨以上车辆禁止通行”，
        11：“下一个路口的通行权”，
        12：“优先道路”，
        13：“产量”，
        14：“停止”，
        15：“没有车辆”，
        16：“禁止超过 3.5 吨的车辆”，
        17：“禁止进入”，
        18：“一般警告”，
        19：“向左危险曲线”，
        20：“向右危险曲线”，
        21：“双曲线”，
        22：“崎岖不平的道路”，
        23：“路滑”
        24：“道路右侧变窄”，
        25：“道路施工”
        26：“交通信号”，
        27：“行人”，
        28：“儿童穿越”，
        29：“自行车过路处”，
        30：“小心冰/雪”
        31：“野生动物穿越”
        32：“所有速度和超车限制结束”，
        33：“向前右转”
        34：“向前左转”，
        35：“仅向前”，
        36：“直走或右转”
        37：“直走或向左走”，
        38：“靠右行驶”
        39：“靠左行驶”
        40：“强制回旋处”，
        41：“禁止通过的结束”，
        42：“禁止3.5吨以上车辆通行”
    }
    返回类[classNo]

而真实：
    成功，imgOriginal = cap.read()

    # 预处理图像
    img = 预处理(imgOriginal)

    # 预测
    预测 = model.predict(img)
    classIndex = np.argmax(预测，轴=1)
    概率值 = np.amax(预测)

    # 如果概率高于阈值则显示结果
    如果概率值&gt;临界点：
        类名 = getClassName(类索引)
        cv2.putText(imgOriginal, &quot;类: &quot; + 类名, (20, 35), 字体, 0.75, (0, 0, 255), 2, cv2.LINE_AA)
        cv2.putText(imgOriginal, &quot;概率:&quot; + str(round(probabilityValue * 100, 2)) + &quot;%&quot;, (20, 75), 字体, 0.75, (0, 0, 255), 2 ，cv2.LINE_AA)
        cv2.imshow(“结果”, imgOriginal)
    别的：
        cv2.imshow(“处理后的图像”, imgOriginal)

    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;): # 检查是否按下&#39;q&#39;键退出
        休息

cap.release()
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/78252865/trained-ml-model-with-the-camera-module-is-not-giving-predictions</guid>
      <pubDate>Sun, 31 Mar 2024 21:19:14 GMT</pubDate>
    </item>
    <item>
      <title>Keras相似度计算。枚举两个张量之间的距离，以列表形式表示</title>
      <link>https://stackoverflow.com/questions/78252612/keras-similarity-calculation-enumerating-distance-between-two-tensors-which-in</link>
      <description><![CDATA[我遵循 Nicholas Renotte 教程“构建深度面部识别应用程序”(Python)。但在第 4 部分我遇到了一个问题，代码如下：
连体 L1 距离等级
类L1Dist（图层）：

    # Init方法-继承
    def __init__(self, **kwargs):
        超级().__init__()

    # 魔法发生在这里 - 相似度计算
    def 调用（自身，input_embedding，validation_embedding）：
        返回 tf.math.abs（输入嵌入 - 验证嵌入）

类型错误：不支持的操作数类型 -：“列表”和“列表”
在视频中一切都很好，但在我的例子中，函数无法进行减法（input_embedding - valid_embedding）
L1Dist.call() 收到的参数：
args=([&#39;&#39;]，[&#39;&#39;])

尝试修改：
def 调用（自身、input_embedding、validation_embedding）：
        input_embedding = tf.convert_to_tensor(input_embedding)
        validation_embedding = tf.convert_to_tensor(validation_embedding)
        input_embedding = tf.squeeze(input_embedding, axis=0) # 删除潜在的第一维
        validation_embedding = tf.squeeze(validation_embedding, axis=0)
        返回 tf.math.abs（输入嵌入 - 验证嵌入）

但是失败了
第108行，在convert_to_eager_tensor中
    返回 ops.EagerTensor(值, ctx.device_name, dtype)
ValueError：TypeError：“KerasTensor”类型的对象没有 len()

尝试过 tf.keras.layers.Subtract()([input_embedding,validation_embedding])
但是 AttributeError: 调用 Subtract.call() 时遇到异常。
“列表”对象没有属性“形状”
使用 keras.ops.subtract（input_embedding，validation_embedding）
面临：ValueError(f“无效的 dtype：{dtype}”)
ValueError：无效的数据类型：列表]]></description>
      <guid>https://stackoverflow.com/questions/78252612/keras-similarity-calculation-enumerating-distance-between-two-tensors-which-in</guid>
      <pubDate>Sun, 31 Mar 2024 19:39:46 GMT</pubDate>
    </item>
    <item>
      <title>如何在机器学习模型中根据目标参数预测输入参数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78252231/how-to-predict-input-parameters-from-target-parameter-in-a-machine-learning-mode</link>
      <description><![CDATA[例如，如果像 T=300 C、时间= 60 分钟、催化剂= A 型这样的实验输入数据给出 70% 的生物柴油产量，我希望 ANN 模型能够预测什么输入参数可以实现 90% 甚至 95% 的生物柴油产量？
我还没有找到解决的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78252231/how-to-predict-input-parameters-from-target-parameter-in-a-machine-learning-mode</guid>
      <pubDate>Sun, 31 Mar 2024 17:28:41 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“llama_index.llms”（未知位置）导入名称“HuggingFaceInferenceAPI”</title>
      <link>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</link>
      <description><![CDATA[想要导入 HuggingFaceInferenceAPI。
从 llama_index.llms 导入 HugggingFaceInferenceAPI

llama_index.llms 文档没有 HuggingFaceInferenceAPI 模块。有人有这方面的更新吗？]]></description>
      <guid>https://stackoverflow.com/questions/78251629/importerror-cannot-import-name-huggingfaceinferenceapi-from-llama-index-llms</guid>
      <pubDate>Sun, 31 Mar 2024 14:21:19 GMT</pubDate>
    </item>
    <item>
      <title>哪个库可以替代机器学习编程中的 causal_conv1d？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78251511/which-library-can-replace-causal-conv1d-in-machine-learning-programming</link>
      <description><![CDATA[最近，我一直在使用 causal_conv1d 库进行机器学习编程，而 causal_conv1d 是 mamba_ssm 库的一部分。但是，我只能在 NVIDIA GPU 上运行这些库。我使用的是带有M系列芯片（M2 PRO）的MAC机器。如何在我的 MAC 计算机上使用 causal_conv1d 库或者是否有任何可用的替代库？
我尝试使用 MPS 版本安装 PyTorch，但 causal_conv1d 库似乎直接需要对 nvcc 和 CUDA 的支持。]]></description>
      <guid>https://stackoverflow.com/questions/78251511/which-library-can-replace-causal-conv1d-in-machine-learning-programming</guid>
      <pubDate>Sun, 31 Mar 2024 13:38:26 GMT</pubDate>
    </item>
    <item>
      <title>Optuna Hyperband 算法不遵循预期的模型训练方案</title>
      <link>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</link>
      <description><![CDATA[我在 Optuna 中使用 Hyperband 算法时发现了一个问题。根据 Hyperband 算法，当 min_resources = 5、ma​​x_resources = 20 且 reduction_factor = 2 时，搜索应以 支架 1 的初始空间为 4 个模型，每个模型在第一轮中接收 5 epoch。随后，每轮模型的数量减少 2 倍，下一个括号的搜索空间也应减少 2 倍，即括号 2 将进行初始搜索2 个模型的空间，并且剩余模型的 epoch 数量在后续的每一轮中加倍。因此预计模型总数应为 11，但它正在训练很多模型。
文章链接：- https://arxiv.org/pdf/1603.06560.pdf
导入 optuna
将 numpy 导入为 np
将 pandas 导入为 pd
从tensorflow.keras.layers导入密集，扁平化，丢弃
将张量流导入为 tf
从tensorflow.keras.models导入顺序


# 玩具数据集生成
defgenerate_toy_dataset():
    np.随机.种子(0)
    X_train = np.random.rand(100, 10)
    y_train = np.random.randint(0, 2, 大小=(100,))
    X_val = np.random.rand(20, 10)
    y_val = np.random.randint(0, 2, 大小=(20,))
    返回 X_train、y_train、X_val、y_val

X_train、y_train、X_val、y_val =generate_toy_dataset（）

# 模型构建函数
def build_model（试用）：
    模型=顺序（）
    model.add(Dense(units=Trial.suggest_int(&#39;unit_input&#39;, 20, 30),
                    激活=&#39;selu&#39;,
                    input_shape=(X_train.shape[1],)))

    num_layers = Trial.suggest_int(&#39;num_layers&#39;, 2, 3)
    对于范围内的 i（num_layers）：
        单位 = Trial.suggest_int(f&#39;num_layer_{i}&#39;, 20, 30)
        激活 = Trial.suggest_categorical(f&#39;activation_layer_{i}&#39;, [&#39;relu&#39;, &#39;selu&#39;, &#39;tanh&#39;])
        model.add（密集（单位=单位，激活=激活））
        if Trial.suggest_categorical(f&#39;dropout_layer_{i}&#39;, [True, False]):
            model.add(Dropout(rate=0.5))

    model.add（密集（1，激活=&#39;sigmoid&#39;））

    Optimizer_name = Trial.suggest_categorical(&#39;optimizer&#39;, [&#39;adam&#39;, &#39;rmsprop&#39;])
    如果优化器名称==&#39;亚当&#39;：
        优化器 = tf.keras.optimizers.Adam()
    别的：
        优化器 = tf.keras.optimizers.RMSprop()

    model.compile(optimizer=optimizer,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;,tf.keras.metrics.AUC(name=&#39;val_auc&#39;)])

    返回模型

定义目标（试用）：
    模型 = build_model(试用)
    # 假设你已经准备好数据
    # 修改拟合方法以包含 AUC 指标
    历史= model.fit（X_train，y_train，validation_data =（X_val，y_val），详细= 1）
    
    # 检查&#39;val_auc&#39;是否被记录
    auc_key = 无
    对于history.history.keys()中的键：
        if key.startswith(&#39;val_auc&#39;):
            auc_key = 密钥
            print(f&quot;auc_key 是 {auc_key}&quot;)
            休息
    
    如果 auc_key 为 None：
        raise ValueError(“历史记录中未找到 AUC 指标。确保在训练期间记录它。”)
    
    # 报告每个模型的验证 AUC
    
    如果 auc_key ==“val_auc”：
        步长=0
    别的：
        步骤 = int(auc_key.split(&#39;_&#39;)[-1])
    
    auc_value=history.history[auc_key][0]
    试验.报告（auc_value，步骤=步骤）
    print(f&quot;是否修剪:-{Trial.should_prune()}&quot;)
    如果审判.should_prune():
        引发 optuna.TrialPruned()

    返回历史记录.history[auc_key]

# Optuna 研究创建
研究 = optuna.create_study(
    方向=&#39;最大化&#39;,
    修剪器=optuna.pruners.HyperbandPruner(
        最小资源=5，
        最大资源=20,
        减少因子=2
    ）
）

# 开始优化
研究.优化（目标）

]]></description>
      <guid>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</guid>
      <pubDate>Sun, 31 Mar 2024 12:38:07 GMT</pubDate>
    </item>
    <item>
      <title>在数字分类混合数据帧上应用 RandomForestRegressor 来预测两列标签集时得分较低</title>
      <link>https://stackoverflow.com/questions/78242202/low-score-when-applying-randomforestregressor-on-a-numeric-categorical-mixed-dat</link>
      <description><![CDATA[我在 Kaggle 上使用这个保险数据集 insurance数据集尝试构建一个简单的回归器来预测最后两列 [&#39;coverage_level&#39;,&#39;charges&#39;]，同时使用所有其他 10 列作为特征输入到回归器模型中。
我知道用作特征的 10 列既是数字类型又是分类类型，因此我使用 LabelEncoder 进行了一些转换：
df2 = df.copy()
# 姜
le = 标签编码器()
le.fit(df2.gender.drop_duplicates())
df2.gender = le.transform(df2.gender)
...其余分类列如“吸烟者”、“地区”等。

然后我在转换后的数据帧上应用了最小最大缩放器：
inputs = df2[[“年龄”、“性别”、“bmi”、“儿童”、“吸烟者”、“地区”、“医疗历史”、
         “家庭医疗史”、“运动频率”、“职业”]]
目标 = df2[[“coverage_level”, “charges”]]

缩放器 = MinMaxScaler()
scaledInputs = np.array(scaler.fit_transform(输入))

X_train，X_test，y_train，y_test = train_test_split（scaledInputs，目标，test_size = 0.20，random_state = 42）

最后是训练和测试部分：
rf_model = RandomForestRegressor(n_estimators=10, random_state=42)

# 拟合训练集
rf_model.fit(X_train, y_train)
rf_outputs = rf_model.predict(X_test)

rf_mse =mean_squared_error(y_test, rf_outputs)
rf_score = rf_model.score(X_test, y_test)

但是性能非常低，得分为0.27，mse接近2615601。
我尝试了一些修复。第一个不是仅缩放输入，而是在馈送之前缩放了两个目标列 [&#39;coverage_level&#39;,&#39;charges&#39;]，但是，它根本没有帮助。第二个修复是使用one-hot编码代替标签编码，但仍然没有增益。
我该如何调查这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78242202/low-score-when-applying-randomforestregressor-on-a-numeric-categorical-mixed-dat</guid>
      <pubDate>Fri, 29 Mar 2024 05:50:10 GMT</pubDate>
    </item>
    <item>
      <title>使用词嵌入在没有上下文的情况下预测印度人名的最佳方法[关闭]</title>
      <link>https://stackoverflow.com/questions/76387839/best-approach-for-predicting-indian-human-names-without-context-using-word-embed</link>
      <description><![CDATA[我探索了 GloVe 和 FastText 等词嵌入来预测搜索查询，特别是印度人名。然而，在这种情况下，我们缺乏数据的上下文。预测印度人名的最佳方法是什么，特别是使用前缀序列级嵌入来识别人名？任何见解或替代方法将不胜感激。谢谢！”]]></description>
      <guid>https://stackoverflow.com/questions/76387839/best-approach-for-predicting-indian-human-names-without-context-using-word-embed</guid>
      <pubDate>Fri, 02 Jun 2023 06:59:36 GMT</pubDate>
    </item>
    <item>
      <title>在运行时访问记录的值</title>
      <link>https://stackoverflow.com/questions/65392269/access-logged-values-during-runtime</link>
      <description><![CDATA[如何在运行完成之前从 wandb 检索记录的值？
导入操作系统
导入万数据库
wandb.init(项目=&#39;someproject&#39;)


def loss_a():
    # do_stuff 和日志：
    wandb.log({“loss_a”: 1.0})
    
def loss_b():
    # do_stuff 和日志：
    wandb.log({“loss_b”: 2.0})

对于范围（2）中的纪元：
    损失_a（）
    损失_b()
    
    # 以某种方式检索loss_a和loss_b并在此处打印它们：
    print(f&#39;loss_a={??}, loss_b={??}&#39;)


运行完成后，我可以使用 wandb.Api 找到它来获取 run.history。但似乎在 run 完成之前，访问 run.history 不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/65392269/access-logged-values-during-runtime</guid>
      <pubDate>Mon, 21 Dec 2020 11:51:10 GMT</pubDate>
    </item>
    <item>
      <title>如何选择合适的机器学习分类器</title>
      <link>https://stackoverflow.com/questions/3902137/how-to-choose-the-right-machine-learning-classifer</link>
      <description><![CDATA[我在为数据挖掘任务选择正确的分类器时遇到问题。
我使用统计方法来标记网页，并使用 1-4 等级来标记它们，1 是最差的，4 是最好的。
之前，我使用 SVM 来训练系统，因为当时我使用的是二进制 (1,0) 标签。但现在自从我切换到这个4类标签后，我需要更改分类器，因为我认为SVM分类器只能用于二类分类（如果我错了，请纠正我）。
哪种分类器最适合我的分类目的？]]></description>
      <guid>https://stackoverflow.com/questions/3902137/how-to-choose-the-right-machine-learning-classifer</guid>
      <pubDate>Sun, 10 Oct 2010 20:48:51 GMT</pubDate>
    </item>
    </channel>
</rss>