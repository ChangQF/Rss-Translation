<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sat, 22 Mar 2025 21:15:20 GMT</lastBuildDate>
    <item>
      <title>T5雇用员工男高音</title>
      <link>https://stackoverflow.com/questions/79528017/t5-fastai-empty-tensors</link>
      <description><![CDATA[为什么我的张量为空，我正在使用T5令牌，在调试时，一切看起来都不错，但是DLS.Train_ds有16个空张量（我的数据集的80％）？
在
    def __init __（self，tokenizer）：
        self.tokenizer = tokenizer

    def编码（self，x）：
        返回self.tokenizer（
            x，
            padding =; max_length＆quot;
            截断= true，
            max_length = 128，
            return_tensors =＆quot; pt; quot;
        ）.input_ids.squeeze（）


dls = datablock（
    blocks =（（
        TextBlock（TransformerStonizer（Tokenizer）），
        TextBlock（TransformerStonizer（Tokenizer）），
    ），
    get_x = colreader（＆quot; input_text; quot;），
    get_y = colreader（&#39;output_xml＆quort;），
）.dataloaders（DF，BS = 2）

＃dsets.train [0]，dsets.valid [0]
＃dls.show_batch（）

（＃16）[（tensortext（[0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0]），TensorText（[0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0、0，0，0，0
        0，0，0，0，0，0，0，0，0，0，0，0，0，0，0，0]）），
 ]]></description>
      <guid>https://stackoverflow.com/questions/79528017/t5-fastai-empty-tensors</guid>
      <pubDate>Sat, 22 Mar 2025 19:38:47 GMT</pubDate>
    </item>
    <item>
      <title>涉及GAT和GRU层的高级DNN体系结构培训培训中的虚拟二进制分类器问题[封闭]</title>
      <link>https://stackoverflow.com/questions/79527850/dummy-binary-classifier-issue-in-training-of-advanced-dnn-architecture-involving</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79527850/dummy-binary-classifier-issue-in-training-of-advanced-dnn-architecture-involving</guid>
      <pubDate>Sat, 22 Mar 2025 17:43:17 GMT</pubDate>
    </item>
    <item>
      <title>处理回归器神经网络的目标值的正确方法是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79527427/whats-the-right-way-in-handling-target-values-for-a-regressor-neural-network</link>
      <description><![CDATA[我目前正在处理特定数据集：
 品牌模型年egine_size fuel_type传输里程门所有者 
起亚里约2020 4.2柴油手册289944 3 5 8501 
雪佛兰Malibu 2012 2.0混合动力自动5356 2 3 12092 
梅赛德斯GLA 2020 4.2柴油自动231440 4 2 11171 
奥迪Q5 2023 2.0电动手册160971 2 1 11780 
大众高尔夫2003 2.6混合半自动286618 3 3 2867 
Toyota Camry 2007 2.7汽油自动157889 4 4 7242
...

 
我的目标是创建一个神经网络，该网络将根据功能执行回归。
根据我以前阅读的内容，您通常不需要扩展目标功能。
但是当我尝试一下时，我的rmse很高：
 时代631/1000
25/25━━━━━━━━━━━━━━━━━━━━0S3ms/step 
损失：4282125.0000  
MSE：4282125.0000  
root_mean_squared_error：2069.2246  
val_loss：4227971.5000  
val_mse：4227971.5000 
val_root_mean_squared_error：2056.2031

 
然后，我在这里阅读了一些论坛帖子，这表明执行目标缩放可能是有益的，这产生了有希望的结果：
 时代100/100
25/25━━━━━━━━━━━━━━━━━━━━0S3ms/step  
损失：0.0141  
MSE：0.0141  
root_mean_squared_error：0.1186  
val_loss：0.0170  
val_mse：0.0170  
val_root_mean_squared_error：0.1305

 
但是，在应用 inverse_transform 并再次计算RMSE之后，结果仍然很糟糕：
  mscale = minmaxscaler（）###我在笔记本中将数据安装到了这个scaleer中。
                        ###我只是在这里添加它以显示我使用的缩放器。

pred = model_neur.predict（x_train_complete）
pred_inv_scale = mscale.inverse_transform（pred）
y_test_split_inv = mscale.inverse_transform（y_train_final）
print（np.sqrt（mean_squared_error（y_test_split_inv，pred_inv_scale）））））））

250/250━━━━━━━━━━━━━━━━━━━━0S466us/step
1988.584022180217

 
对我来说，结果是有意义的，通过以这种方式扩展目标，我会影响预测价值与真实价值之间的距离。在[0,1]的规模上，我知道看到RMSE真的很小。
我知道，RMSE的解释高度取决于数据，但是我的目标的最小价值是2000，最大的价值为18,000，我觉得2000年的RMSE大约是很糟糕的。。
是否有适当的方法可以实际执行大型目标功能进行回归？您甚至应该完全缩放它们吗？]]></description>
      <guid>https://stackoverflow.com/questions/79527427/whats-the-right-way-in-handling-target-values-for-a-regressor-neural-network</guid>
      <pubDate>Sat, 22 Mar 2025 12:16:06 GMT</pubDate>
    </item>
    <item>
      <title>需要有关KAN模型的帮助[关闭]</title>
      <link>https://stackoverflow.com/questions/79527265/need-help-about-kan-model</link>
      <description><![CDATA[获取此错误。我需要更改代码还是火炬版本的问题？
 描述：0％|          | 0/500 [00：00＆lt;？，？it/s]
----------------------------------------------------------------------------------------------------------------------------
Runtimeerr Trackback（最近的最新电话）
＆lt; ipython-Input-10-2da0ffaf5447＆gt;在＆lt;单元线：0＆gt;（）
----＆gt; 1火车（）

7帧
/USR/local/lib/python3.11/dist-packages/torch/functional.py in Einsum（*args）
    405＃收缩0或1次的路径已经优化
    406＃或使用opt_einsum禁用了用户
 - ＆gt; 407返回_vf.einsum（方程式，操作数）＃类型：忽略[attr-defined]
    408 
    409路径=无

RuntimeError：预期标量型双键，但发现了浮动
 
这是火车代码
  def train（）：
优化器= lbfgs（model.parameters（），lr = 1，max_iter = 50，history_size = 10，tolerance_grad = 1e-32，tolerance_change = 1e-32，tolerance_ys = 1e-32）

pBar = tqdm（range（step），desc =&#39;description&#39;）

对于_在PBAR中：
    def closure（）：
        全局PDE_LOSS，BC_LOSS
        优化器.zero_grad（）
        ＃内部损失
        sol = sol_fun（x_i）
        sol_d1_fun = lambda x：batch_jacobian（型号，x，create_graph = true）[：，0，：]
        sol_d1 = sol_d1_fun（x_i）
        sol_d2 = batch_jacobian（sol_d1_fun，x_i，create_graph = true）[：， ：，：]
        lap = torch.sum（torch.diagonal（sol_d2，dim1 = 1，dim2 = 2），dim = 1，keepdim = true）
        source = source_fun（x_i）
        pde_loss = torch.mean（（lap- source）** 2）

        ＃边界损失
        ＃bc_true = sol_fun（x_b）
        bc_true = y_b
        BC_PRED =模型（x_b）
        bc_loss = torch.mean（（BC_PRED-BC_TRUE）** 2）

        损失= alpha * pde_loss + bc_loss
        loss.backward（）
        回报损失

    如果_％5 == 0和_＆lt; 50：
        model.update_grid_from_samples（x_i）

    优化器。
    sol = sol_fun（x_i）
    损失= alpha * pde_loss + bc_loss
    pde_losss [_] = pde_loss
    BC_LOSSS [_] = BC_LOSS
    ＃l2 = torch.mean（（型号（x_i） -  sol）** 2）


    如果_％log == 0：
        pbar.set_description（; pde损失：％.2e | bc损失：％.2e;％（pde_loss.cpu（）。
 ]]></description>
      <guid>https://stackoverflow.com/questions/79527265/need-help-about-kan-model</guid>
      <pubDate>Sat, 22 Mar 2025 10:15:44 GMT</pubDate>
    </item>
    <item>
      <title>当训练模型使用KAFKA和RDL索引4096训练模型时的错误是否超出了尺寸4096的轴0</title>
      <link>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</guid>
      <pubDate>Sat, 22 Mar 2025 05:30:38 GMT</pubDate>
    </item>
    <item>
      <title>如何构建反馈系统以奖励自定义的Yolo模型？ [迁移]</title>
      <link>https://stackoverflow.com/questions/79526652/how-to-build-a-feedback-system-to-reward-a-custom-yolo-model</link>
      <description><![CDATA[我已经在自定义的食品数据集上培训了定制的Yolo型号（版本：Yolov11-Obb）。目的是检测图像是否包含同一类别的N产品。
示例检测代码：
  model = yolo（model_path）
＃class = [&#39;product_a&#39;，&#39;product_b&#39;，...]
结果= model.predict（source = cv2_img，class = [0]）
model_predictions，ventity = process_results（结果）
 
这是发生的事情： &lt; /p&gt;

结果包含模型中的原始预测。
 process_results（结果）处理预测和返回：

 model_predictions：检测到的对象的边界框。
数量：检测到的对象的数量。



我需要根据模型的检测准确性来为我的模型实施奖励系统。具体而言，如果模型正确检测图像中的所有对象，则应将其奖励。但是，如果它错过任何对象，它应该会收到具有正确预测的反馈。
例如：

如果该模型检测到3个对象中的2个，则应告知检测不正确，并以真实的注释作为反馈。
目的是使用此基于奖励的反馈来提高模型的表现。

如何有效地实施此奖励机制？]]></description>
      <guid>https://stackoverflow.com/questions/79526652/how-to-build-a-feedback-system-to-reward-a-custom-yolo-model</guid>
      <pubDate>Fri, 21 Mar 2025 22:12:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Codebert嵌入识别类似的代码零件？</title>
      <link>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</link>
      <description><![CDATA[我正在使用Codebert比较两个代码的相似性。例如：
 ＃代码1
def calculate_area（半径）：
返回3.14 *半径 *半径
 
 ＃代码2
def Compute_circle_area（R）：
返回3.14159 * r * r
 
 Codebert创建“嵌入”就像对代码的详细描述为数字。然后，我比较这些数值描述，以查看代码的相似之处。这对于告诉我多少代码是相似的。
但是，我无法分辨Codebert认为哪些部分相似。因为“嵌入”很复杂，我无法轻易看到Codebert的重点。比较逐字代码在这里不起作用。
我的问题是：我如何找出两个代码段的哪些特定部分Codebert认为相似，而不仅仅是获得一般相似性得分？
我尝试了简单的DIFF方法，但这违反了纯粹使用Codebert的目的。
我想知道是否可以单独使用Codebert。]]></description>
      <guid>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</guid>
      <pubDate>Thu, 20 Mar 2025 14:30:35 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow模型训练，列表到Numpy阵列转换不均会改变数据形状</title>
      <link>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</link>
      <description><![CDATA[我正在尝试从MRI图像中预测LSDC。对于每个 study_id 都有多个图像。每个 study_id 代表每个患者。我想在5个级别上预测5个条件下的3级严重程度。
我正在尝试使用 sequence 类创建数据集。
这是我的 datagenerator 类：
 类CustomDatagenerator（序列）：
    def __init __（self，image_dict，num_img，labels_dict = none，batch_size = 8，image_size =（224，224），shuffle = true）：
       self.image_dict = image_dict
       self.labels_dict = labels_dict
       self.batch_size = batch_size
       self.image_size = image_size
       self.shuffle =洗牌
       self.ids = list（image_dict.keys（））
       self.num_img = num_img
       self.on_epoch_end（）

    def __len __（自我）：
       返回int（np.floor（len（self.ids） / self.batch_size））

    def __getItem __（自我，索引）：
       start = index * self.batch_size
       end = min（（索引 + 1） * self.batch_size，len（self.ids））
       batch_ids = self.ids [start：end]
       batch_images = []
       batch_labels = []

       对于batch_ids中的ID_：
           图像= []

           对于self.image_dict.get（id_，[]）中的image_path：
               dicomdata = pydicom.dcmread（image_path）
               图像= dicomdata.pixel_array
               图像= cv2.resize（图像，self.image_size）
               image = np.expand_dims（图像，axis = -1）
               image = image.astype（&#39;float32&#39;） / np.max（图像）
               图像= np.Repeat（图像，3，轴= -1）
               images.append（图像）

           图像= np.Array（图像）

           如果Len（Images）＆lt; self.num_img：
               pad_amount = self.num_img- len（图像）
               padding = [（0，pad_amount）] + [（0，0）] *（len（images.shape） -  1）
               图像= np.pad（图像，填充，模式=&#39;常数&#39;）

           batch_images.append（图像）

           如果self.labels_dict：
               label = np.array（self.labels_dict.get（id_），dtype = np.float32）
               batch_labels.append（标签）

       batch_images = np.stack（batch_images）
       如果self.labels_dict：
           batch_labels = np.array（batch_labels，dtype = np.float32）
           返回batch_images，batch_labels

       返回batch_images

    def on_epoch_end（self）：
       如果self.shuffle：
           np.random.shuffle（self.ids）
 
我的标签字典如下：
  i，sid在枚举中（train_df [&#39;study_id&#39;]）：
        labels_dict [str（sid）] = []
        对于条件下的骗局：
            如果train_df.loc [i，con] ==&#39;normal_mild&#39;：
                labels_dict [str（sid）]。附加（[1，0，0]）
            elif train_df.loc [i，con] ==&#39;严重&#39;：
                labels_dict [str（sid）]。附加（[0，0，1]）
            别的：
                labels_dict [str（sid）]。附加（[0，1，0]）

       labels_dict [str（sid）] = np.array（labels_dict [str（sid）]，dtype = np.float32）
 
我尝试了多种方法将 labels_dict 转换为numpy数组。但是要么在训练时显示形状不匹配错误。或试图查看数据时显示错误。
这是它显示的错误：
  -----＆gt; 1 Model.Fit（train_generator，epochs = 2）＃，step_per_epoch = len（train_generator）// 8）

/USR/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py in Error_handler（*args，** kwargs）
    120＃要获取完整的堆栈跟踪，请致电：
    121＃`keras.config.disable_traceback_filtering（）`
 - ＆gt; 122从无
    123最后：
    124 del filtered_tb

＆lt; ipython-Input-12-Cf42609bddda＆gt;在__getItem __（自我，索引）中
     47 batch_images = np.stack（batch_images）
     48如果self.labels_dict：
---＆gt; 49 batch_labels = np.array（batch_labels，dtype = np.float32）
     50返回batch_images，batch_labels
     51 

ValueError：设置具有序列的数组元素。 1个维度后，请求的阵列具有不均匀的形状。检测到的形状为（8，） +不均匀部分。
 
我尝试使用 np.stack 或 batch_labels = batch_labels.reshape（（（batch_labels.shape.shape [0]，len（presente），3），3））），但显示出不同的错误。我的数据没有任何 nan ，所有 labels_dict 均为Shape （batch_size，num_of_condition，severity_class）。即使我尝试从发电机打印数据。生成器数据形状来自 data_x，data_y = next（iter（train_generator））显示模型输入和输出的数据形状。我无法弄清楚这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/79455291/tensorflow-model-training-list-to-numpy-array-conversion-unevenly-changes-the-s</guid>
      <pubDate>Thu, 20 Feb 2025 17:02:54 GMT</pubDate>
    </item>
    <item>
      <title>训练数据和标签在掩盖应付填充后没有相同的形状</title>
      <link>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</guid>
      <pubDate>Sun, 10 Nov 2024 19:56:09 GMT</pubDate>
    </item>
    <item>
      <title>分类神经网络不学习</title>
      <link>https://stackoverflow.com/questions/60393573/classification-neural-network-does-not-learn</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/60393573/classification-neural-network-does-not-learn</guid>
      <pubDate>Tue, 25 Feb 2020 11:28:15 GMT</pubDate>
    </item>
    <item>
      <title>神经网络回归</title>
      <link>https://stackoverflow.com/questions/51938859/neural-network-regression</link>
      <description><![CDATA[对于给定的数据集X，带有两个类{0,1}。如果我分别为每个0和1训练两个单独的神经网络NN0和NN1。 NN0可以从1类中预测数据集中的点，即使在类0？上训练了该点？]]></description>
      <guid>https://stackoverflow.com/questions/51938859/neural-network-regression</guid>
      <pubDate>Mon, 20 Aug 2018 21:40:39 GMT</pubDate>
    </item>
    <item>
      <title>用Pytorch实施自定义数据集</title>
      <link>https://stackoverflow.com/questions/51545026/implementing-a-custom-dataset-with-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/51545026/implementing-a-custom-dataset-with-pytorch</guid>
      <pubDate>Thu, 26 Jul 2018 18:04:14 GMT</pubDate>
    </item>
    <item>
      <title>使用keras简单的线性回归</title>
      <link>https://stackoverflow.com/questions/51181393/simple-linear-regression-using-keras</link>
      <description><![CDATA[我一直在尝试使用Keras中的神经网络实现一个简单的线性回归模型，以了解我们如何在Keras库中工作。不幸的是，我最终获得了一个非常糟糕的模型。这是实现：
 来自Pylab Import *
来自keras.models导入顺序
来自keras.layers导入密集

#Generate虚拟数据
data = data = linspace（1,2,100）.RESHAPE（-1,1）
y =数据*5

＃定义模型
def baseline_model（）：
   型号=顺序（）
   model.Add（密集（1，激活=&#39;Linear&#39;，input_dim = 1））
   model.compile（优化器=&#39;rmsprop&#39;，loss =&#39;mean_squared_error&#39;，量表= [&#39;cocucy&#39;]）
   返回模型


＃使用模型
regr = baseline_model（）
regr.fit（数据，y，epochs = 200，batch_size = 32）
绘图（Data，regr.predict（data），&#39;b&#39;，data，y，&#39;k。&#39;）
 
生成的图如下：
  有人可以指出上述模型定义中的缺陷（这可以确保更好地拟合）？]]></description>
      <guid>https://stackoverflow.com/questions/51181393/simple-linear-regression-using-keras</guid>
      <pubDate>Wed, 04 Jul 2018 22:27:31 GMT</pubDate>
    </item>
    <item>
      <title>撤离激活的辍学</title>
      <link>https://stackoverflow.com/questions/45504710/dropout-with-relu-activations</link>
      <description><![CDATA[我正在尝试在TensorFlow中使用辍学的神经网络。
  tf.layers.dropout（输入，费率，培训）
 
来自文档：

辍学包括在培训时间期间每个更新时将输入单元的分数随机设置为0，这有助于防止过度拟合。保留的单元按1 /（1-速率）缩放，以使其总和在训练时间和推理时间保持不变。&lt; / p&gt;

现在，我知道这种行为如果在严格高于零高于零的乙状结激活的顶部应用。如果将一半的输入单元零零，则所有输出的总和也将减半，因此将其比例缩放为2是有意义的，以便在下一层之前恢复某种一致性。
现在，如果一个人使用以零为中心的tanh激活该怎么办？上面的推理不再是正确的，所以将辍学的输出扩展到上述因素是否仍然有效？有没有办法防止张量流液位缩放输出？]]></description>
      <guid>https://stackoverflow.com/questions/45504710/dropout-with-relu-activations</guid>
      <pubDate>Fri, 04 Aug 2017 10:41:25 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习识别名称[封闭]</title>
      <link>https://stackoverflow.com/questions/37876401/recognize-names-using-machine-learning</link>
      <description><![CDATA[我正在处理一个问题，我不确定机器学习是否会成为理想的候选人。
我有一个沿着别名的列表位置。这是我计划使用来训练模型的监督数据集。使用此，我想在从大型文本语料库中提取的列表中识别它们。挑战是这些位置是外国名称，因此它们以各种方式拼写。
 培训数据 

名称：澳大利亚（AUS，Australea，Down）
名称：维也纳（VNA，欧洲珠宝）

 语料库数据 
 奥地利 
南部的国家 
Oustralea 
欧洲珠宝
 ]]></description>
      <guid>https://stackoverflow.com/questions/37876401/recognize-names-using-machine-learning</guid>
      <pubDate>Fri, 17 Jun 2016 08:11:53 GMT</pubDate>
    </item>
    </channel>
</rss>