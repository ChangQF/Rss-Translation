<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 25 Dec 2023 18:16:21 GMT</lastBuildDate>
    <item>
      <title>为什么支持向量机的 varImp() 出现错误？</title>
      <link>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77714417/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</guid>
      <pubDate>Mon, 25 Dec 2023 17:08:22 GMT</pubDate>
    </item>
    <item>
      <title>无法在 F# 中将内存数据传递到 AutoML。不明白为什么它不能编译</title>
      <link>https://stackoverflow.com/questions/77714343/cant-pass-in-memory-data-to-automl-in-f-not-understanding-why-it-doesnt-com</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77714343/cant-pass-in-memory-data-to-automl-in-f-not-understanding-why-it-doesnt-com</guid>
      <pubDate>Mon, 25 Dec 2023 16:43:24 GMT</pubDate>
    </item>
    <item>
      <title>Mediapipe-model-maker安装问题</title>
      <link>https://stackoverflow.com/questions/77713844/mediapipe-model-maker-installation-issue</link>
      <description><![CDATA[希望你们一切都好。我正在研究图像分类模型，为此，我正在安装 mediapipe-model-marker，但遇到以下错误。
这是我的 python 和 pip 版本
在此处输入图像描述
这是我用来安装此软件包的 pip 命令。
pip install mediapipe-model-maker 
这是错误
在此处输入图像描述
我尝试在我的 venv 中下载 medipipe-model-marker 包来使用图像分类模型。
我希望下载这个包。]]></description>
      <guid>https://stackoverflow.com/questions/77713844/mediapipe-model-maker-installation-issue</guid>
      <pubDate>Mon, 25 Dec 2023 13:36:29 GMT</pubDate>
    </item>
    <item>
      <title>SARIMAX 错误：ValueWarning：已提供日期索引，但它没有关联的频率信息，因此在例如预测</title>
      <link>https://stackoverflow.com/questions/77713776/sarimax-errorvaluewarninga-date-index-has-been-provided-but-it-has-no-associat</link>
      <description><![CDATA[我有这样的数据

&lt;表类=“s-表”&gt;
&lt;标题&gt;

时间
湿度_(%)


&lt;正文&gt;

15:21:02
31.03


15:23:05
30.98




当我运行代码时出现此错误：
ValueWarning：已提供日期索引，但它没有关联的频率信息，因此在例如预测。
有熟悉这方面的人可以帮助我吗？
不知道是什么原因
我写了这段代码：
导入 pandas 作为 pd
将 statsmodels.api 导入为 sm


data.set_index(&#39;时间&#39;, inplace=True)


# 将数据分为训练集和测试集
train_data = data.iloc[:-17000] # 使用除最后 8 个样本之外的所有样本进行训练
test_data = data.iloc[-17000:] # 使用最后8个样本进行测试

# 将 SARIMAX 模型拟合到训练数据
模型 = sm.tsa.SARIMAX(train_data[&#39;湿度_(%)&#39;], order=(1, 0, 0))
model_fit = model.fit()
]]></description>
      <guid>https://stackoverflow.com/questions/77713776/sarimax-errorvaluewarninga-date-index-has-been-provided-but-it-has-no-associat</guid>
      <pubDate>Mon, 25 Dec 2023 13:13:17 GMT</pubDate>
    </item>
    <item>
      <title>尝试从 inceptionv3 架构中提取特征时出现图形断开连接错误</title>
      <link>https://stackoverflow.com/questions/77713548/graph-disconnected-error-when-trying-to-extract-features-from-inceptionv3-archit</link>
      <description><![CDATA[我正在尝试从架构中间提取一些特征并将其用于另一个模型。
base_model = InceptionV3(weights=&#39;imagenet&#39;, include_top=False)
input_tensor = Input(shape=(299, 299, 3)) # InceptionV3 的输入形状
InceptionA_feature_extractor = models.Model(inputs=input_tensor,outputs=base_model.get_layer(&#39;mixed2&#39;).output)

在尝试执行此操作时，我收到以下错误，可能的原因是什么？
ValueError：图形已断开连接：无法获取张量 KerasTensor 的值（type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name=&#39;input_6&#39;), name=&#39; input_6&#39;，描述=“由层&#39;input_6&#39;创建”）在层“conv2d_376”。访问以下先前层没有问题：[]
]]></description>
      <guid>https://stackoverflow.com/questions/77713548/graph-disconnected-error-when-trying-to-extract-features-from-inceptionv3-archit</guid>
      <pubDate>Mon, 25 Dec 2023 11:49:34 GMT</pubDate>
    </item>
    <item>
      <title>从 Adaboost 的错误中学习</title>
      <link>https://stackoverflow.com/questions/77712597/learning-from-errors-in-adaboost</link>
      <description><![CDATA[我对 adaboost 算法的工作原理有深入的了解：
1.初始化：每个样本初始分配相等的权重，使得所有样本在第一轮中同等重要。

训练弱学习器：在数据集上训练弱学习器（例如，深度有限的决策树）。弱学习器关注整个数据集，但更重视前几轮错误分类的样本。

计算误差：计算弱学习器的训练误差。该误差本质上是错误分类的加权和，其中权重是样本权重。

更新样本权重：增加误分类样本的权重，减少正确分类样本的权重。这个想法是让下一个弱学习者更多地关注之前错误分类的样本。

计算弱学习器权重：弱学习器本身的权重是根据其在训练过程中的准确性来计算的。

合并弱学习器：将弱学习器添加到集成中，并使用反映其准确性的权重。弱学习器的准确率越高，对最终预测的影响就越大。


重复：重复步骤2-6指定的轮次（迭代），将一系列弱学习器组合成一个强模型。
通过在每次迭代中为错误分类的样本赋予更高的权重，AdaBoost 确保后续的弱学习器更加关注之前难以正确分类的样本。这种自适应过程使 AdaBoost 能够专注于“困难”问题。示例，提高整体模型的性能。最终模型是所有弱学习器的加权组合，权重由它们在训练过程中的个体准确率决定。
这是我从互联网上得到的理解。但我仍然不清楚“后续的弱学习器更多地关注以前难以正确分类的样本”是什么意思。这是否意味着：

在后续的学习器中，我们用分类错误的样本填充训练数据集？
我试图了解幕后发生的事情。
]]></description>
      <guid>https://stackoverflow.com/questions/77712597/learning-from-errors-in-adaboost</guid>
      <pubDate>Mon, 25 Dec 2023 05:47:38 GMT</pubDate>
    </item>
    <item>
      <title>NLP TFBertForSequenceClassification 文本分类非常慢</title>
      <link>https://stackoverflow.com/questions/77712257/nlp-tfbertforsequenceclassification-text-classification-being-very-slow</link>
      <description><![CDATA[我一直在尝试训练TFBERtForSequenceClassification来解决文本分类问题；但是，当我尝试执行模型时，它非常慢，有时甚至会崩溃。
我的数据集分为训练、验证、测试。它也相当大。
训练样本大小：315057。
验证样本大小：39382。
测试样本大小：39383
from Transformers import TFBertForSequenceClassification, BertConfig

伯特 = TFBertForSequenceClassification.from_pretrained(
    &#39;bert-base-uncased&#39;,
    num_labels = 6 # 标签数量
）

模型=顺序（[
        输入（形状=（无，），dtype=tf.int32），
        伯特,
        密集（64，激活=&#39;relu&#39;），
        辍学率（0.3），
        密集（6，激活=&#39;softmax&#39;）
    ]）

模型.编译(
        损失=&#39;sparse_categorical_crossentropy&#39;,
        优化器=keras.optimizers.Adam(learning_rate = 0.001)
        指标=[&#39;准确性&#39;]
）

模型.summary()

h_bert = bert_model.fit(
    训练输入_tf，
    训练标签_tf，
    验证数据=（val_inputs_tf，val_labels_tf），
    纪元=2，
    批量大小=128，
    回调=[
        EarlyStopping（监视器=&#39;val_accuracy&#39;，耐心=2）
    ]
）


有什么办法可以提高性能吗？我的模型配置有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77712257/nlp-tfbertforsequenceclassification-text-classification-being-very-slow</guid>
      <pubDate>Mon, 25 Dec 2023 01:48:31 GMT</pubDate>
    </item>
    <item>
      <title>假新闻检测数据集。 （CSV 格式）[关闭]</title>
      <link>https://stackoverflow.com/questions/77712037/dataset-for-fake-news-detections-csv-format</link>
      <description><![CDATA[我想实现一个专门针对某个地区的假新闻检测的机器学习模型，我需要一个针对该主题的大型数据集，我的主要想法是在一个网站中实现它，其中将给出 URL 链接用户可以选择输入主题的 URL 或标题。但是，我在为此寻找数据集时遇到困难。
有什么见解、建议或资源可以帮助我推进这个项目吗？]]></description>
      <guid>https://stackoverflow.com/questions/77712037/dataset-for-fake-news-detections-csv-format</guid>
      <pubDate>Sun, 24 Dec 2023 22:37:35 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在树莓派零中运行离线语音识别，或者有没有更便宜的替代方案？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77711684/is-there-a-way-to-run-offline-speech-recognition-in-raspberry-pi-zero-or-is-ther</link>
      <description><![CDATA[我正在尝试制作一款可以运行实时离线语音识别的产品，现在我知道可以使用 google api 在线执行此操作，但我不想依赖在线服务。那么有没有一种方法可以像ALEXA一样将Live语音转换为文本呢？由于 Alexa 可以以非常小的延迟进行离线实时语音识别，现在我知道有像 VOSK 这样的库可以进行离线语音识别，但问题是它们对于树莓派零来说太大了，或者太不可靠
我尝试过使用 VOSK 但不方便。我已经尝试过 google api，但从长远来看它很昂贵，而且如果离线，你就无法与产品交互，我知道在低端设备中可以这样做，因为手机也可以离线执行相同的操作，但我不知道不知道该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/77711684/is-there-a-way-to-run-offline-speech-recognition-in-raspberry-pi-zero-or-is-ther</guid>
      <pubDate>Sun, 24 Dec 2023 19:29:52 GMT</pubDate>
    </item>
    <item>
      <title>随机森林与回归模型：为什么随机森林的 R 平方为负，而回归模型的 R 平方为正 [关闭]</title>
      <link>https://stackoverflow.com/questions/77711645/random-forest-vs-regression-model-why-r-squared-for-random-forest-is-negative-w</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77711645/random-forest-vs-regression-model-why-r-squared-for-random-forest-is-negative-w</guid>
      <pubDate>Sun, 24 Dec 2023 19:14:27 GMT</pubDate>
    </item>
    <item>
      <title>自定义梯度提升分类器实现。训练无进展</title>
      <link>https://stackoverflow.com/questions/77710582/custom-gradient-boosting-classifier-implementation-no-training-progress</link>
      <description><![CDATA[我正在尝试实现一个GradientBoostingClassifier
我从 StatQuest 视频中获取了该算法（梯度提升第 4 部分（共 4 部分）：分类详细信息）并尝试使用 numpy + sklearn.DecisionTreeRegressor 作为基本模型来实现它。
这是我的代码：
从 sklearn.tree 导入 DecisionTreeRegressor

定义 sigmoid(x):
  如果x&gt; 0:
    z = np.exp(-x)
    返回 1/(1+z)
  别的：
    z = np.exp(x)
    返回 z/(1+z)

类 GradientBoostingClassifier()：
  def __init__(self, n_estimators=20, lr=0.1):
    self.n_estimators = n_estimators
    self.lr = lr
    self.training_history = {
        “log_loss”：[]，“roc_auc”：[]，“pr_auc”：[]
    }
    self.base_learners = []

  def fit(自身, X, y):
    数据 = X.copy()
    特征=数据.列
    # 1. 使用常量值初始化模型：
    p = y.sum() / len(y)
    赔率 = p / (1-p)
    log_odds = np.log(赔率)
    数据[&#39;cur_log_odds&#39;] = log_odds
    数据[&#39;预测&#39;] = 数据[&#39;cur_log_odds&#39;].apply(sigmoid)

    self.training_history[&#39;log_loss&#39;].append( log_loss(y, data[&#39;prediction&#39;]) )
    self.training_history[&#39;roc_auc&#39;].append( roc_auc_score(y, data[&#39;预测&#39;]) )
    self.training_history[&#39;pr_auc&#39;].append(average_ precision_score(y, data[&#39;prediction&#39;]) )

    # 2. 对于 m = 1 到 M：
    for _ in tqdm(range(self.n_estimators)):
      # 2.1 计算所谓的伪残差：
      数据[&#39;残差&#39;] = (数据[&#39;预测&#39;] - y)

      # 2.2 拟合基学习器回归器来预测伪残差：
      base_learner = DecisionTreeRegressor（max_深度 = 3，min_samples_split = 2，random_state = 42）
      base_learner.fit(数据[特征],数据[&#39;残差&#39;])
      self.base_learners.append(base_learner)

      # 2.3 对于每个叶子计算其输出对数几率
      # 从回归树中获取叶子数
      数据[&#39;叶子&#39;] = base_learner.apply(数据[特征])

      # 将输出对数奇数计算为 sum(residuals) / sum(old_prediction * (1 - old_prediction))
      leafs_output = data.groupby(&#39;leaf&#39;, as_index=False).apply(
          lambda d: d[&#39;残差&#39;].sum() / (0.00001+(d[&#39;预测&#39;] * (1-d[&#39;预测&#39;]) ).sum())
      ).rename(columns={无: &#39;lambda_odds&#39;})

      数据 = data.merge(leafs_output, on=&#39;leaf&#39;)
      # 2.4 更新 current_log_odds = current_log_odds + lr*predicted_log_odds
      数据[&#39;cur_log_odds&#39;] += self.lr*data[&#39;lambda_odds&#39;]
      数据 = data.drop(&#39;lambda_odds&#39;, axis=1)

      数据[&#39;预测&#39;] = 数据[&#39;cur_log_odds&#39;].apply(sigmoid)

      self.training_history[&#39;log_loss&#39;].append( log_loss(y, data[&#39;prediction&#39;]) )
      self.training_history[&#39;roc_auc&#39;].append( roc_auc_score(y, data[&#39;预测&#39;]) )
      self.training_history[&#39;pr_auc&#39;].append(average_ precision_score(y, data[&#39;prediction&#39;]) )

    返回数据

  def Predict_proba(自身, X):
    经过

问题是，即使经过 1000 次迭代 (n_estimators = 1000)，我的 roc_auc 和 pr_auc 分数也接近随机模型给出的分数（roc_auc=0.5，pr_auc=0.29，这是正类的比例）。
我做错了什么？
即使在 n_estimators = 10 的情况下，sklearn GradientBoostingClassifier 实现在同一数据集上也能给出更高的分数]]></description>
      <guid>https://stackoverflow.com/questions/77710582/custom-gradient-boosting-classifier-implementation-no-training-progress</guid>
      <pubDate>Sun, 24 Dec 2023 12:11:08 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习将地址文本拆分为多个组件</title>
      <link>https://stackoverflow.com/questions/77710080/split-address-text-into-components-using-machine-learning</link>
      <description><![CDATA[我有一个 CSV 文件，每一行代表地址的不同组成部分，例如城市、街道、门牌号等，然后一列在一行中包含组合地址，具有预定义的格式，例如街道房屋号码、邮政编码、城市。
我想要的是判断用户输入的地址文本的不同组成部分，例如我想知道用户是否输入了所有组件，或者只是输入了街道名称和城市等，以及这些组件的值是什么。
我可以通过机器学习技术来实现这一目标，以便我使用 CSV 文件来教导模型，这就是地址文本被分割成不同组件的方式，然后期望它根据该训练为我提供不同的组件？
添加更多信息，因为我正在 .NET 中实现这一点，因此基于 ML.NET 的解决方案或可以轻松与 .NET 集成的解决方案将是更好的选择。
此外，我们可以不管地址解析上下文如何来看待这个问题。难道我们不应该能够教导一个模型，让其知道文本句子在任何给定上下文中是如何由不同部分组成的吗？然后期望模型建议给定的新文本句子中的各个部分？]]></description>
      <guid>https://stackoverflow.com/questions/77710080/split-address-text-into-components-using-machine-learning</guid>
      <pubDate>Sun, 24 Dec 2023 08:47:00 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：从“y”的唯一值推断出无效的类。预期：[0 1 2 ... 1387 1388 1389]，得到[0 1 2 ... 18609 24127 41850]</title>
      <link>https://stackoverflow.com/questions/72452872/valueerror-invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2</link>
      <description><![CDATA[情况：我正在尝试使用 XGBoost 分类器，但是向我弹出此错误：
“ValueError：从 y 的唯一值推断出的类无效。预期：[0 1 2 ... 1387 1388 1389]，得到[0 1 2 ... 18609 24127 41850]”。。
与这个已解决的问题不同：从“y”的唯一值推断出的类无效。预期：[0 1 2 3 4 5]，得到[1 2 3 4 5 6]，看来我有一个不同的场景，不是从0开始。
代码：
&lt;前&gt;&lt;代码&gt;X = data_concat
y = data_concat[[&#39;forward_count&#39;,&#39;comment_count&#39;,&#39;like_count&#39;]]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=72)

#训练，测试分割
print (&#39;训练集:&#39;, X_train.shape, y_train.shape) #查看分割后的大小
print (&#39;测试集：&#39;, X_test.shape, y_test.shape)

xgb = XGBClassifier()
clf = xgb.fit(X_train, y_train, eval_metric=&#39;auc&#39;) #这里是哪里得到错误

Datafrme 和框架信息如下：
DataFrame
数据帧信息
我采用了不同的 y，这意味着当 y 具有更少或更多列时，列表“[0 1 2 ... 1387 1388 1389]”将同时缩小或扩大。
如果您需要更多信息，请告诉我。感谢您的帮助:)]]></description>
      <guid>https://stackoverflow.com/questions/72452872/valueerror-invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2</guid>
      <pubDate>Tue, 31 May 2022 18:55:55 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中回归的局限性？</title>
      <link>https://stackoverflow.com/questions/61731738/limitations-of-regression-in-machine-learning</link>
      <description><![CDATA[我最近一直在学习 ML 的一些核心概念，并使用 Sklearn 库编写代码。经过一些基本练习后，我尝试了来自 kaggle 的 AirBnb NYC 数据集（大约有 40000 个样本） - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data#New_York_City_.png
我尝试建立一个模型，可以根据数据集的各种特征来预测房间/公寓的价格。我意识到这是一个回归问题，并使用这个 sklearn 备忘单，我开始尝试各种回归模型。 

我使用 sklearn.linear_model.Ridge 作为基准，在进行一些基本数据清理之后，我在测试集上得到了糟糕的 R^2 分数 0.12。然后我想，也许线性模型太简单了，所以我尝试了适用于回归的“内核技巧”方法（sklearn.kernel_ridge.Kernel_Ridge），但它们需要太多时间来适应（&gt;1小时）！为了解决这个问题，我使用 sklearn.kernel_approximation.Nystroem 函数来近似内核图，在训练之前将变换应用于特征，然后使用简单的线性回归模型。然而，如果我增加 n_components 参数，即使这样也需要花费大量时间来转换和拟合，我必须获得任何有意义的准确性提高。 
所以我现在在想，当你想对一个巨大的数据集进行回归时会发生什么？核技巧的计算量非常大，而线性回归模型则过于简单，因为实际数据很少是线性的。那么神经网络是唯一的答案还是我缺少一些聪明的解决方案？
附注我刚刚开始使用溢出，所以请让我知道我可以做些什么来改善我的问题！]]></description>
      <guid>https://stackoverflow.com/questions/61731738/limitations-of-regression-in-machine-learning</guid>
      <pubDate>Mon, 11 May 2020 14:11:10 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中对相似但完全相同的单词及其缩写进行分组</title>
      <link>https://stackoverflow.com/questions/51648330/group-similar-but-exact-words-and-their-abbreviation-in-python</link>
      <description><![CDATA[我有一个关于将相似单词及其缩写分组到一组的问题，例如我有下面给出的单词列表：

人工智能
人工智能
人工智能
机器学习
机器学习
数据分析
数据与分析

我想将这些词分组为[人工智能、机器学习、数据分析]
我使用了 difflib.get_close_matches() 但这并没有给我想要的结果例如这就是 difflib group: Information Technology&#39;: [&#39;Information Technology&#39;,&#39;Mobile Technology&#39;, &#39;newtechnology&#39;]
我还使用了 fuzz.token_set_ratio() 但这也没有为我提供所需的结果。 Levenshtein 也没有。
如果有任何机器学习算法或任何Python库，请告诉我。]]></description>
      <guid>https://stackoverflow.com/questions/51648330/group-similar-but-exact-words-and-their-abbreviation-in-python</guid>
      <pubDate>Thu, 02 Aug 2018 07:52:04 GMT</pubDate>
    </item>
    </channel>
</rss>