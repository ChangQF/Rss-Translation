<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 16 Jun 2024 12:26:28 GMT</lastBuildDate>
    <item>
      <title>向 TensorFlow 模型添加一个热门特征</title>
      <link>https://stackoverflow.com/questions/78628433/add-one-hot-feature-to-tensorflow-model</link>
      <description><![CDATA[我是深度学习的新手，我正在使用 init 函数逐步创建 MMOE 模型并添加功能。
class TIGMMOE(tfrs.Model):
def __init__(self, use_cross_layer, deep_layer_sizes, num_units, num_shared_experts, project_dim=None):
super().__init__()

self.embedding_dimension = 8

self._embeddings = {}

#categorical embedding（所有任务通用）
self._embeddings[&#39;category&#39;] = tf.keras.Sequential(
[tf.keras.layers.Embedding(num_total_pcats + 1, 32)
],name=&#39;cat_emb&#39;)

self._embeddings[&#39;ptype&#39;] = tf.keras.Sequential(
[tf.keras.layers.Embedding(num_total_ptypes + 1, 128)
],name=&#39;ptype_emb&#39;)

.
.
.
def call(self, feat_inputs):
features = feat_inputs
anchor_embeddings = []

for feat_name in _CONTEXT_FEATURE_KEYS:
anchor_embeddings.append(features[feat_name])

anchor_embeddings.append(self._embeddings[&#39;category&#39;](features[&#39;anc_pcat_map&#39;]))
anchor_embeddings.append(self._embeddings[&#39;ptype&#39;](features[&#39;anc_ptcode_map&#39;]))

anchor_embeddings = {}
anchor_embeddings[&#39;anc_feat_vec&#39;] = features[&#39;anc_feat_vec&#39;]
anchor_embeddings[&#39;anc_ptcode_map_emb&#39;] = self._embeddings[&#39;category&#39;](features[&#39;anc_pcat_map&#39;])
anchor_embeddings[&#39;anc_pcat_map_emb&#39;] = self._embeddings[&#39;ptype&#39;](features[&#39;anc_ptcode_map&#39;])


现在我想向模型添加另一个特征 x，该特征为 int 格式，我想将其添加为 one-hot-encode 特征。有人能告诉我如何将这个特征从 tfrecords 添加到我的模型中吗？]]></description>
      <guid>https://stackoverflow.com/questions/78628433/add-one-hot-feature-to-tensorflow-model</guid>
      <pubDate>Sun, 16 Jun 2024 06:33:12 GMT</pubDate>
    </item>
    <item>
      <title>在 AWS Sagemaker 中训练线性模型时出现 UnexpectedStatusException？</title>
      <link>https://stackoverflow.com/questions/78628328/getting-unexpectedstatusexception-while-training-linear-model-in-aws-sagemaker</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78628328/getting-unexpectedstatusexception-while-training-linear-model-in-aws-sagemaker</guid>
      <pubDate>Sun, 16 Jun 2024 05:27:48 GMT</pubDate>
    </item>
    <item>
      <title>潜在扩散 - Unet：除维度 1 外，张量的大小必须匹配</title>
      <link>https://stackoverflow.com/questions/78628262/latent-diffusion-unet-sizes-of-tensors-must-match-except-in-dimension-1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78628262/latent-diffusion-unet-sizes-of-tensors-must-match-except-in-dimension-1</guid>
      <pubDate>Sun, 16 Jun 2024 04:27:29 GMT</pubDate>
    </item>
    <item>
      <title>如何对通过 HTTP 传递到/从远程 ONNX 模型的数据进行编码？</title>
      <link>https://stackoverflow.com/questions/78628055/how-to-encode-data-passed-to-from-remote-onnx-models-via-http</link>
      <description><![CDATA[假设我们有一个远程 ONNX ML 模型（在 onnxruntime 上运行），并且我们想通过 REST API 公开它以进行预测。
如何正确编码 HTTP 消息中传递的输入/输出？
由于 onnxruntime 具有不同的类型（主要使用张量、映射和序列），我想知道是否有统一的方法来实现。JSON？Protobuf？其他格式？我是否要为不同的 OrtValues 编写自己的编码器/解码器？
可能的情况：
输入：
N 张量
输出：
N 个预测标签的张量，以及每个标签的概率映射序列
问题与语言无关。
谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78628055/how-to-encode-data-passed-to-from-remote-onnx-models-via-http</guid>
      <pubDate>Sun, 16 Jun 2024 01:03:08 GMT</pubDate>
    </item>
    <item>
      <title>Chromadb EOFError：输入不足</title>
      <link>https://stackoverflow.com/questions/78627304/chromadb-eoferror-ran-out-of-input</link>
      <description><![CDATA[我正在使用 chromadb 来保存我的向量嵌入。
过去几个月，数据库更新得很好。我突然收到以下错误：
EOFError：输入不足

以下代码是导致问题的代码。
collection.add(
documents=docs,
metadatas=metadatas,
ids=ids,
)

我不确定从哪里开始调试和修复这个问题。
完整错误如下：
文件“/var/www/panoraapp.com/public_html/api/genius/search_embeddings.py”，第 237 行，在 save_to_chroma 中
collection.add(
文件“/usr/local/lib/python3.10/dist-packages/chromadb/api/models/Collection.py”，第 168 行，在 add 中
self._client._add(ids, self.id、嵌入、元数据、文档、uris)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/rate_limiting/__init__.py&quot;，第 45 行，在包装器中
return f(self, *args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/api/segment.py&quot;，第 372 行，在 _add 中
self._manager.hint_use_collection(collection_id, t.Operation.ADD)
文件&quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 230 行，在 hint_use_collection 中
instance = self.get_segment(collection_id, type)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/telemetry/opentelemetry/__init__.py&quot;，第 143 行，在包装器中
return f(*args, **kwargs)
文件&quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 217 行，在 get_segment 中
instance = self._instance(segment)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/manager/local.py&quot;，第 246 行，在 _instance 中
instance = cls(self._system,segment)
文件 &quot;/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/vector/local_persistent_hnsw.py&quot;，第 107 行，在 __init__ 中
self._persist_data = PersistentData.load_from_file(
文件“/usr/local/lib/python3.10/dist-packages/chromadb/segment/impl/vector/local_persistent_hnsw.py”，第 70 行，位于 load_from_file
]]></description>
      <guid>https://stackoverflow.com/questions/78627304/chromadb-eoferror-ran-out-of-input</guid>
      <pubDate>Sat, 15 Jun 2024 17:25:34 GMT</pubDate>
    </item>
    <item>
      <title>Keras 的 one_hot 对不同的词产生相同的值</title>
      <link>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</link>
      <description><![CDATA[我使用 keras 的 one_hot 函数将单词转换为数字。但出于某种原因，它会为不同的单词生成相同的数字。在下面的代码中，您可以看到 48 用于“amazing”，但 48 也用于“too”。这是为什么？
from tensorflow.keras.preprocessing.text import one_hot

reviews = [&#39;nice food&#39;,
&#39;amazing restaurant&#39;,
&#39;too good&#39;,
&#39;just loved it!&#39;,
&#39;will go again&#39;,
&#39;horrible food&#39;,
&#39;never go there&#39;,
&#39;poor service&#39;,
&#39;poor quality&#39;,
&#39;needs Improvement&#39;]

# 转换为 ont hot 向量 
encoded_reviews = [one_hot(d, vocab_size) for d in reviews]

当我打印coded_reviews 时，它显示：
[[13, 12],
[48, 44],
[48, 19],
[38, 28, 46],
[13, 29, 19],
[46, 12],
[19, 29, 4],
[18, 38],
[18, 35],
[42, 7]]
]]></description>
      <guid>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</guid>
      <pubDate>Sat, 15 Jun 2024 15:16:01 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“ValueError：找到具有 0 个样本的数组（shape=(0, 5)），而 LinearRegression 至少需要 1 个。”</title>
      <link>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78626396/how-i-solve-valueerror-found-array-with-0-samples-shape-0-5-while-a-min</guid>
      <pubDate>Sat, 15 Jun 2024 10:53:01 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：层 Sequenced_4 从未被调用，因此没有定义的输出</title>
      <link>https://stackoverflow.com/questions/78626027/valueerror-the-layer-sequential-4-has-never-been-called-and-thus-has-no-defined</link>
      <description><![CDATA[我尝试在 Grad cam 实现中使用它，但它显示这个错误。在下面我的 CNN 模型中-
import tensorflow as tf
from tensorflow.keras import layer

model = tf.keras.Sequential()

model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, input_shape=(128,128,3), name=&#39;conv1&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool1&#39;))

model.add(layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, name=&#39;conv2&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool2&#39;))

model.add(layers.Conv2D(filters=16, kernel_size=(3,3), strides=(1,1),activation=tf.nn.relu, name=&#39;conv3&#39;))
model.add(layers.MaxPool2D(name=&#39;maxpool3&#39;))

model.add(layers.Flatten(name=&#39;flatten&#39;))
model.add(layers.Dense(256,activation=&#39;relu&#39;, name=&#39;dense1&#39;))
model.add(layers.Dense(2,activation=tf.nn.sigmoid, name=&#39;dense2&#39;))

ValueError: 层 Sequenced_4 从未被调用，因此没有定义的输出。]]></description>
      <guid>https://stackoverflow.com/questions/78626027/valueerror-the-layer-sequential-4-has-never-been-called-and-thus-has-no-defined</guid>
      <pubDate>Sat, 15 Jun 2024 08:21:56 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 中的 Essentia 模型无法预测</title>
      <link>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</link>
      <description><![CDATA[我正在尝试使用 Essentia discogs_track_embeddings-effnet-bs64 模型和 ML.NET 进行预测。我尝试过使用 tensorflow 和 onnx，但当我尝试预测任何东西时，我都遇到了问题
抛出异常：Microsoft.ML.Data.dll 中的“System.InvalidOperationException”
Microsoft.ML.Data.dll 中发生了未处理的“System.InvalidOperationException”类型的异常
Splitter/consolidator 工作程序在使用源数据时遇到异常

目前，我正在使用 onnx，因此其余部分将是该尝试的堆栈跟踪和代码。
完整调用堆栈：
 在 Microsoft.ML.Data.DataViewUtils.Splitter.Batch.SetAll(OutPipe[] pipes)
在 Microsoft.ML.Data.DataViewUtils.Splitter.Cursor.MoveNextCore()
在 Microsoft.ML.Data.RootCursorBase.MoveNext()
在Microsoft.ML.Data.ColumnCursorExtensions.&lt;GetColumnArrayDirect&gt;d__4`1.MoveNext()
在 System.Collections.Generic.List`1..ctor(IEnumerable`1 collection)
在 System.Linq.Enumerable.ToList[TSource](IEnumerable`1 source)
在 Program.&lt;Main&gt;$(String[] args) 中的 Program.cs:line 122

在行上：var embeddingColumn = perceivedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
onnx 加载和预测代码：
Console.WriteLine($&quot;[+] Loading Model&quot;);
var mlContext = new MLContext();

// 将 melspectrogram 数据加载到管道中
var modelPath = &quot;discogs_track_embeddings-effnet-bs64-1.onnx&quot;;
var pipeline = mlContext.Transforms.ApplyOnnxModel(
modelFile: modelPath,
fallbackToCpu: true
);
IDataView mockData = mlContext.Data.LoadFromEnumerable(new List&lt;ModelInput&gt;() { new ModelInput() });
var model = pipeline.Fit(mockData);

var schema = model.Transform(mockData).Schema;
Console.WriteLine(&quot;[*] Model Schema:&quot;);
foreach (var column in schema)
{
Console.WriteLine($&quot;Column Name: {column.Name}, Column Type: {column.Type}&quot;);
}

List&lt;ModelOutput&gt; allPredictions = new List&lt;ModelOutput&gt;();

foreach (var fragment in melSpectrogram)
{
var seg = MelSpectrogramGenerator.ConvertToFloat(segment);

var data = new ModelInput
{
Melspectrogram = seg
};
IDataView dataView = mlContext.Data.LoadFromEnumerable(new [] { data });
var formedData = model.Transform(dataView);

// 检索嵌入
var embeddingColumn = formedData.GetColumn&lt;float[]&gt;(&quot;embeddings&quot;).ToList();
foreach (var value in embeddingColumn.First())
{
Console.Write($&quot;{value} &quot;);
}
//allPredictions.Add(scoredData.);
Console.WriteLine(&quot;Wheee&quot;);
}

public class ModelInput
{
[VectorType(64, 128, 96)]
[ColumnName(&quot;melspectrogram&quot;)]
public float[,,] Melspectrogram { get; set; }
public ModelInput()
{
Melspectrogram = new float[64, 128, 96];
}
}

// 定义输出模式
public class ModelOutput
{
[VectorType(64, 512)]
[ColumnName(&quot;embeddings&quot;)]
public float[,] Embeddings { get; set; }
public ModelOutput()
{
Embeddings = new float[64, 512];
}
}

目前在 Microsoft.ML 3.0.1、Microsoft.ML.OnnxRuntime.Managed 1.18.0 上
我已检查，我的数据中没有 NaN，并且我的变量都不是 Null。我非常迷茫，不确定如何修复此问题，甚至不知道如何继续进行故障排除。]]></description>
      <guid>https://stackoverflow.com/questions/78622030/essentia-models-in-ml-net-fail-to-predict</guid>
      <pubDate>Fri, 14 Jun 2024 09:11:02 GMT</pubDate>
    </item>
    <item>
      <title>防止自定义 BiLSTM 模型中的过度拟合[关闭]</title>
      <link>https://stackoverflow.com/questions/78612882/prevent-overfitting-in-custom-bilstm-model</link>
      <description><![CDATA[我必须预测乌尔都语文本中的积极、中性和消极情绪。它有 30k 个样本
样本数据集
训练样本 = 24k，而验证样本 = 6k
我正在使用 bilstm 训练模型，但训练准确率正在提高，而验证却停滞不前。我尝试过更改 - 1. 批量大小从 (2 到 256)
2. 学习率从 0.1 到 1e-11
3. 优化器；我使用过 Adam、SGD、RMSProp 和 Adadelta。
4.使用 word2vec 进行可训练和不可训练的嵌入，
5. 将数据以不同的比例分为训练和验证。
6. 更改层数和单元数。
7.已实施正则化。
但未观察到任何改进。
import keras.backend as K
def get_f1(y_true, y_pred): #取自旧 keras 源代码
true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
precision = true_positives / (predicted_positives + K.epsilon())
recall = true_positives / (possible_positives + K.epsilon())
f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())
return f1_val

def bilstm(embedding_layer):
#定义神经网络
model = Sequential()
model.add(embedding_layer)
model.add(Bidirectional(LSTM(units=128, return_sequences = True)))
model.add(Bidirectional(LSTM(units=64)))
model.add(Dense(3,activation=&#39;softmax&#39;))
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[get_f1,&#39;accuracy&#39;])
return model

model = bilstm(embedding_layer)

learning_rate_reduction = ReduceLROnPlateau(monitor=&#39;val_accuracy&#39;,patience = 2,verbose=1,factor=0.5,min_lr=0.00001)
model.fit(train_seq,train_label, epochs=10, batch_size=8, validation_data=(val_seq, val_label))

Epoch 1
1511/1511 [==============================] - 601s 393ms/step - 损失：1.0787 - get_f1：0.0626 - 准确度：0.3957 - val_loss：1.0402 - val_get_f1：0.1804 - val_accuracy：0.4514
Epoch 2
1511/1511 [===============================] - 615s 407ms/step - 损失：0.7377 - get_f1：0.6348 - 准确度：0.6760 - val_loss：1.1938 - val_get_f1：0.3784 - val_accuracy：0.4509
Epoch 3
1511/1511 [==============================] - 608s 402ms/步 - 损失：0.3419 - get_f1：0.8503 - 准确度：0.8559 - val_loss：1.5797 - val_get_f1：0.4148 - val_accuracy：0.4448
Epoch 4
1511/1511 [===============================] - 612s 405ms/步- 损失：0.2141 - get_f1：0.9074 - 准确度：0.9084 - val_loss：2.2244 - val_get_f1：0.4319 - val_accuracy：0.4459
Epoch 5
1511/1511 [==============================] - 609s 403ms/step - 损失：0.1548 - get_f1：0.9357 - 准确度：0.9368 - val_loss：2.5604 - val_get_f1：0.4302 - val_accuracy：0.4391

]]></description>
      <guid>https://stackoverflow.com/questions/78612882/prevent-overfitting-in-custom-bilstm-model</guid>
      <pubDate>Wed, 12 Jun 2024 13:09:39 GMT</pubDate>
    </item>
    <item>
      <title>使用 BARTDecoder 和 cached_property 的 Nougat OCR 中的 ImportError 和 TypeError 问题</title>
      <link>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</guid>
      <pubDate>Sat, 08 Jun 2024 05:43:48 GMT</pubDate>
    </item>
    <item>
      <title>如何将对象检测数据集转换为 Tensorflow 数据集</title>
      <link>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</link>
      <description><![CDATA[我正在尝试使用 keras 在 tensorflow 上创建一个对象检测模型，但一直遇到困难。我自动​​执行了查找训练图像的边界框的任务（训练数据集是一个游戏），然后将所有内容转储到包含与其相关的所有数据的 .csv 文件中：对象出现的帧、边界框的坐标以及对象的类别。即使同一帧上出现多个边界框，每个边界框在数据集上都有不同的行。
我正在尝试使用此函数将我的数据集导入 Tensorflow：
def Data_Loader(annotation_file):
data=pd.read_csv(annotation_file)
data_groups=data.groupby(&#39;filename&#39;)

Dataset={&#39;images&#39;:[], &#39;bounding_boxes&#39;:[]}
ngroups=data_groups.ngroups

for image_name, group in data_groups:

BBoxes={&#39;classes&#39;: [], &#39;boxes&#39;:[]}
for _, row in group.iterrows():
BBoxes[&#39;boxes&#39;].append(Get_BBOX(row))
BBoxes[&#39;classes&#39;].append(class_ids.index(row[&#39;class&#39;]))

Dataset[&#39;bounding_boxes&#39;].append(tf.data.Dataset.from_tensor_slices(BBoxes))
image=load_img(image_name,(224, 224))
Dataset[&#39;images&#39;].append(tf.constant(image))

Dataset=tf.data.Dataset.from_tensor_slices(Dataset)

return(Dataset)


以下是边界框的加载方式：
def Get_BBOX(row):
xmin=int(row[&#39;xmin&#39;])
ymin=int(row[&#39;ymin&#39;])
xmax=int(row[&#39;xmax&#39;])
ymax=int(row[&#39;ymax&#39;])

bbox=np.array([xmin, ymin, xmax, ymax])

return bbox


图像加载如下：
def load_img(filename, target_size):
img = tf.keras.utils.load_img(filename, target_size=target_size) 
img = tf.keras.utils.img_to_array(img) 

return (img)


我正在使用 Keras 的本教程来指导自己
但是每当我到达教程中将地图应用于数据的部分时，我都会收到以下错误消息：
&#39;_VariantDataset&#39; 对象不可下标

有人知道我可能做错了什么吗？如何修复？
我尝试多次进行类型转换，从包含列表的字典更改为字典列表和所有其他类型的东西。但都没有任何结果。]]></description>
      <guid>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</guid>
      <pubDate>Sat, 27 Jan 2024 12:55:36 GMT</pubDate>
    </item>
    <item>
      <title>键错误：'acc' -> acc = history.history['acc']</title>
      <link>https://stackoverflow.com/questions/74016944/keyerror-acc-acc-history-historyacc</link>
      <description><![CDATA[代码链接：https://colab.research.google.com/drive/1_a4PLwDiFhF7qVlX_vvwKM4QM4Dxu0L0?usp=sharing
import matplotlib.pyplot as plt

acc = history.history[&#39;acc&#39;]
val_acc = history.history[&#39;val_accuracy&#39;]
loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]

epochs = range(1, len(acc) + 1)

# &quot;bo&quot; 代表 &quot;blue dot&quot;
plt.plot(epochs, loss, &#39;bo&#39;, label=&#39;训练损失&#39;)
# b 代表“实蓝线”
plt.plot(epochs, val_loss, &#39;b&#39;, label=&#39;验证损失&#39;)
plt.title(&#39;训练和验证损失&#39;)
plt.xlabel(&#39;Epochs&#39;)
plt.ylabel(&#39;损失&#39;)
plt.legend()

plt.show()

错误显示：
KeyError Traceback（最近一次调用最后一次）

&lt;ipython-input-31-12e4df2349dc&gt; in &lt;module&gt;
1 import matplotlib.pyplot as plt
2 
----&gt; 3 acc = history.history[&#39;acc&#39;]
4 val_acc = history.history[&#39;val_accuracy&#39;]
5 loss = history.history[&#39;loss&#39;]

KeyError: &#39;acc&#39;

嗨，我尝试了深度学习中的这个练习 3.5-classifying-movie-reviews.ipynb，使用 python -manning 并显示错误，有什么帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/74016944/keyerror-acc-acc-history-historyacc</guid>
      <pubDate>Mon, 10 Oct 2022 15:05:25 GMT</pubDate>
    </item>
    <item>
      <title>如何使用带有灰度图像的预训练神经网络？</title>
      <link>https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images</link>
      <description><![CDATA[我有一个包含灰度图像的数据集，我想在这些图像上训练最先进的 CNN。我非常想微调一个预先训练好的模型（比如这里的模型）。
问题是，我能找到权重的几乎所有模型都是在包含 RGB 图像的 ImageNet 数据集上训练的。
我无法使用其中一个模型，因为它们的输入层需要一批形状为 (batch_size, height, width, 3) 或 (64, 224, 224, 3) 的模型，但我的图像批次是 (64, 224, 224)。
我有什么办法可以使用其中一个模型吗？我曾考虑在加载权重后删除输入层并添加自己的权重（就像我们对顶层所做的那样）。这种方法正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/51995977/how-can-i-use-a-pre-trained-neural-network-with-grayscale-images</guid>
      <pubDate>Fri, 24 Aug 2018 00:33:04 GMT</pubDate>
    </item>
    <item>
      <title>准确度得分值错误：无法处理二进制和连续目标的混合</title>
      <link>https://stackoverflow.com/questions/38015181/accuracy-score-valueerror-cant-handle-mix-of-binary-and-continuous-target</link>
      <description><![CDATA[我使用 scikit-learn 中的 linear_model.LinearRegression 作为预测模型。它很有效，而且很完美。我在使用 accuracy_score 指标评估预测结果时遇到问题。
这是我的真实数据：
array([1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0])

我的预测数据：
array([ 0.07094605, 0.1994941 , 0.19270157, 0.13379635, 0.04654469,
0.09212494, 0.19952108, 0.12884365, 0.15685076, -0.01274453,
0.32167554, 0.32167554, -0.10023553, 0.09819648, -0.06755516,
0.25390082, 0.17248324])

我的代码：
accuracy_score(y_true, y_pred, normalize=False)

错误消息：
ValueError：无法处理二进制和连续目标的混合
]]></description>
      <guid>https://stackoverflow.com/questions/38015181/accuracy-score-valueerror-cant-handle-mix-of-binary-and-continuous-target</guid>
      <pubDate>Fri, 24 Jun 2016 13:57:17 GMT</pubDate>
    </item>
    </channel>
</rss>