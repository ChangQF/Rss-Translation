<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 24 Oct 2024 21:17:23 GMT</lastBuildDate>
    <item>
      <title>时间序列预测：如何使用截至 t-1 计算的特征预测未来值而不会发生数据泄漏？</title>
      <link>https://stackoverflow.com/questions/79123110/time-series-forecasting-how-to-predict-future-values-using-features-calculated</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79123110/time-series-forecasting-how-to-predict-future-values-using-features-calculated</guid>
      <pubDate>Thu, 24 Oct 2024 17:39:23 GMT</pubDate>
    </item>
    <item>
      <title>将 Python 模型集成到 Power Bi</title>
      <link>https://stackoverflow.com/questions/79122864/integrate-python-model-to-power-bi</link>
      <description><![CDATA[在 power BI 中，我必须创建一个基于 NLP 的聊天机器人，就像我们在 power bi 中有 QnA visual 一样，它可以回答自然语言处理中提出的问题，但由于它的一些限制，我无法使用它。
我想使用 python 训练我的数据集并创建一个可以回答任何自然语言问题的模型。
然而问题是我无法将 python 脚本运行到 Power bi 中，因为它没有网关连接，所以它不会刷新，我不需要在我的本地系统中执行此操作，只需将其发送给最终用户即可。任何我加载到 power bi 中的东西最终都会看起来像一张表格，我必须创建它的视觉效果。
我想知道以何种方式可以使用用 python 编写的 QnA 模型将 python 模型灌输到 power bi 中，以便用户可以用自然语言搜索他们想要问的问题。
有没有办法使用 python 让最终用户可以像聊天机器人一样输入他们的问题并得到他们的答案？]]></description>
      <guid>https://stackoverflow.com/questions/79122864/integrate-python-model-to-power-bi</guid>
      <pubDate>Thu, 24 Oct 2024 16:24:05 GMT</pubDate>
    </item>
    <item>
      <title>如何在 ML.NET 中使用 CenterFace？模型预期形状为 (10, 3, 32, 32)</title>
      <link>https://stackoverflow.com/questions/79122749/how-to-use-centerface-in-ml-net-model-expects-shape-10-3-32-32</link>
      <description><![CDATA[我尝试在 ML.NET 中使用 CenterFace ONNX，但一直出现各种错误，主要是关于输入大小的错误。
CenterFace 元数据指出，它应该有一个 10, 3, 32, 32 的输入，这对于图像检测来说已经毫无意义了 - 为算法提供 10 个批次（每个批次 32x32 像素）有什么意义？
这是我的主要代码：
 string modelPath = &quot;centerface.onnx&quot;;
var mlContext = new MLContext();

string imagePath = &quot;photo1.jpg&quot;;

var img = Image.FromFile(imagePath);
var DH = (int)(Math.Ceiling((float)img.Height / 32) * 32);
var DW = (int)(Math.Ceiling((float)img.Width / 32) * 32);

var inputData = new[] { new ModelInput { ImagePath = imagePath } };
IDataView imageData = mlContext.Data.LoadFromEnumerable(inputData);

var pipeline = mlContext.Transforms.LoadImages(outputColumnName: &quot;input.1&quot;, imageFolder: &quot;&quot;, inputColumnName: nameof(ModelInput.ImagePath))
.Append(mlContext.Transforms.ResizeImages(outputColumnName: &quot;input.1&quot;, imageWidth: DW, imageHeight: DH))
.Append(mlContext.Transforms.ExtractPixels(outputColumnName: &quot;input.1&quot;))
.Append(mlContext.Transforms.ApplyOnnxModel(
outputColumnNames: [&quot;537&quot;, &quot;538&quot;, &quot;539&quot;, &quot;540&quot;],
inputColumnNames: [&quot;input.1&quot;],
modelFile: modelPath
));

var model = pipeline.Fit(imageData);
var predictionEngine = mlContext.Model.CreatePredictionEngine&lt;ModelInput, ModelOutput&gt;(mo​​del);
var prediction = predictionEngine.Predict(new ModelInput { ImagePath = imagePath });

使用我的 2 个模型类：
 public class ModelInput
{
public string ImagePath { get; set; }
}

public class ModelOutput
{
[ColumnName(&quot;537&quot;)] 
public float[] HeatMap { get; set; }

[ColumnName(&quot;538&quot;)]
public float[] Scale { get; set; }

[ColumnName(&quot;539&quot;)]
public float[] Offset { get; set; }

[ColumnName(&quot;540&quot;)]
public float[] Landmarks { get; set; }
}

但我确实一直收到有关输入大小的错误：

System.ArgumentException：“内存长度（3686400）必须与尺寸乘积（30720）匹配。”

30720 显然是 10x3x32x32。但同样，这有什么意义呢？
我认为我的 ONNX 坏了，但我确实有一个使用 OpenCVSharp 的工作实现：
// 这是计算机 DW 和 DH，与 ML.NET 示例中的方式相同
CenterFaceParams p = new(image, resizedSize.Width, resizedSize.Height, scoreThreshold, nmsThreshold);
Size size = new(p.DW, p.DH);

使用 Mat input = new();
Cv2.Resize(image, input, size);

使用 Mat blobInput = CvDnn.BlobFromImage(input, 1.0, size, new Scalar(0, 0, 0), true, false);
_net.SetInput(blobInput, &quot;input.1&quot;);

使用 (Mat heatMap = new())
使用 (Mat scale = new())
使用 (Mat offset = new())
使用 (Mat skylines = new())
{
_net.Forward([heatMap, scale, offset, skylines], [&quot;537&quot;, &quot;538&quot;, &quot;539&quot;, &quot;540&quot;]);

CenterFaceDecodercoder = new(heatMap, scale, offset, skylines, p);
returncoder.GetOutput();
}

这个实现给了我所有 4 个层，建模后我得到了我想要的值。]]></description>
      <guid>https://stackoverflow.com/questions/79122749/how-to-use-centerface-in-ml-net-model-expects-shape-10-3-32-32</guid>
      <pubDate>Thu, 24 Oct 2024 15:52:45 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 的 mask r-cnn 推理 ONNX 模型从不起作用</title>
      <link>https://stackoverflow.com/questions/79122467/inferencing-onnx-model-of-pytorchs-mask-r-cnn-never-works</link>
      <description><![CDATA[问题：推理 onnx 模型给出空结果或形状奇怪的结果
我正在尝试：pytorch 预训练 mask-rcnn -&gt; 在数据集上微调 -&gt; 另存为 onnx -&gt; 在 onnx 上推理 -&gt; 绘制结果
我目前拥有的一切都在推理之前有效。
我的 main.py 文件：https://pastebin.com/3jNfZdBi
获取有关我保存的 onnx 模型的信息
模型输入信息：
名称：输入
形状：[&#39;batch_size&#39;, 3, &#39;height&#39;, &#39;width&#39;]
类型：张量（浮点）

模型输出信息：
名称：boxes
形状：[&#39;Concatboxes_dim_0&#39;, 4]
类型：张量（浮点）
名称：labels
形状：[&#39;Gatherlabels_dim_0&#39;]
类型：张量（int64）
名称：分数
形状：[&#39;Gatherlabels_dim_0&#39;]
类型：张量（浮点）
名称：掩码
形状：[&#39;Unsqueezemasks_dim_0&#39;, &#39;Unsqueezemasks_dim_1&#39;, &#39;Unsqueezemasks_dim_2&#39;, &#39;Unsqueezemasks_dim_3&#39;]
类型：张量（浮点）

我的推理代码：https://pastebin.com/wxvp649G
我怀疑我要么：错误地将内容保存到 onnx，要么没有正确地预处理我的数据，要么我的推理代码是错误的（或其他我不知道的东西）
保存到 onnx 的代码
def save_model_onnx(models_file_path, model, torch_input):
#传统的导出方法。还有一种实验性的 dynamo_export 方法
torch.onnx.export(
model.cpu(),
torch_input.cpu(),
models_file_path, # 模型的完整路径，包括模型本身，即 ./models/model.onnx
export_params = True,
opset_version=15, # 选择支持的 ONNX opset 版本
do_constant_folding=True, # 折叠常量节点以进行优化
input_names = [&#39;input&#39;],
output_names = [&#39;boxes&#39;, &#39;labels&#39;, &#39;scores&#39;, &#39;masks&#39;],
dynamic_axes={
&quot;input&quot;: {0: &quot;batch_size&quot;, 2: &quot;height&quot;, 3: &quot;width&quot;}, 
}
)
logstash.info(f&quot;模型保存在{models_file_path}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/79122467/inferencing-onnx-model-of-pytorchs-mask-r-cnn-never-works</guid>
      <pubDate>Thu, 24 Oct 2024 14:41:59 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的部署问题[关闭]</title>
      <link>https://stackoverflow.com/questions/79121685/deployment-issues-on-machine-learning</link>
      <description><![CDATA[如何在没有 html 文件的情况下将 ML 模型部署到 github 操作中，我使用了 streamlit 应用程序？
我曾尝试找到一些使用 github 操作部署机器学习的源代码，但经常失败。
我有这个问题，该如何解决它。]]></description>
      <guid>https://stackoverflow.com/questions/79121685/deployment-issues-on-machine-learning</guid>
      <pubDate>Thu, 24 Oct 2024 11:31:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Python 中实现贝叶斯逻辑回归和 SVM 进行分类</title>
      <link>https://stackoverflow.com/questions/79098217/how-to-implement-bayesian-logistic-regression-and-svm-for-classification-in-pyth</link>
      <description><![CDATA[我想在单个 Python 代码中实现贝叶斯逻辑回归和 SVM 进行分类，但我无法做到，请任何人告诉我。
我尝试使用 pymc3，但它不起作用。我也尝试过 theano tensor，但都没有用，有人能帮我解决这些吗]]></description>
      <guid>https://stackoverflow.com/questions/79098217/how-to-implement-bayesian-logistic-regression-and-svm-for-classification-in-pyth</guid>
      <pubDate>Thu, 17 Oct 2024 13:04:09 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV 与 OpenVINO 后端：动态批次大小问题</title>
      <link>https://stackoverflow.com/questions/79097169/opencv-with-openvino-backend-problem-whit-dynamic-batch-size</link>
      <description><![CDATA[我正在使用 OpenCV（版本 4.10.0）和 OpenVINO（2023.0.1）后端编译来加载和处理深度学习模型。我已使用 ovc 和 omz_downloader 成功将模型从 Open Model Zoo 转换为 OpenVINO IR 格式。转换工作正常，但在将模型导入 OpenCV 进行推理时遇到了问题。
问题：
模型使用动态批处理大小（[-1, 3, 112, 112]）进行转换。当我尝试使用 cv::dnn::readNetFromModelOptimizer() 函数在 OpenCV 中加载此模型时，我在 OpenCV 源代码的这一部分中收到异常：
NetImplOpenVINO::createNetworkFromModelOptimizer(std::shared_ptr&lt;ov::Model&gt;&amp; ieNet) 函数
{
....
for (auto&amp; it : ieNet-&gt;get_parameters())
{
inputNames.push_back(it-&gt;get_friendly_name());
std::vector&lt;size_t&gt; dims = it-&gt;get_shape(); // 此处发生异常
inp_shapes.push_back(std::vector&lt;int&gt;(dims.begin(), dims.end()));
}
.....
}

在 OpenCV 代码中调用 it-&gt;get_shape() 时发生异常，可能是因为模型具有动态形状。
问题：
使用 OpenVINO 后端时，如何在 OpenCV 的 DNN 模块中处理具有动态批处理大小的模型？
是否有在 OpenCV 中加载具有动态输入形状的模型的解决方法，还是应该直接使用 OpenVINO 的推理引擎管理动态批处理？
环境：
OpenCV 4.10.0
OpenVINO 2023.1
Windows 11
环境 c++

静态批处理大小：我使用静态批处理大小 ([1, 3, 112, 112]) 转换了模型，并且它运行良好。但是，我需要为我的应用程序处理动态批次大小。
后端设置：我正在使用以下方法将后端设置为 OpenVINO：

`net.setPreferableBackend(cv::dnn::DNN_BACKEND_INFERENCE_ENGINE);
net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);`

任何有关使用 OpenVINO 处理 OpenCV 中的动态批次大小的帮助或见解都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/79097169/opencv-with-openvino-backend-problem-whit-dynamic-batch-size</guid>
      <pubDate>Thu, 17 Oct 2024 08:22:34 GMT</pubDate>
    </item>
    <item>
      <title>通过索引为张量赋值后，值不匹配</title>
      <link>https://stackoverflow.com/questions/78949501/mismatch-of-values-after-assigning-values-to-a-tensor-by-index</link>
      <description><![CDATA[我正在编写一个 PyTorch 训练代码，它构建了一个算法类。其中有一个步骤需要为内部张量分配一些值。但是，即使代码只有两行，也有一个错误。我发现分配的张量的值与分配的值不同。
这是该类的代码：
class PRODEN(Algorithm):
&quot;&quot;&quot;
PRODEN
参考：部分标签学习的真实标签的渐进式识别，ICML 2020。
&quot;&quot;&quot;

def __init__(self, input_shape, train_givenY, hparams):
super(PRODEN, self).__init__(input_shape, train_givenY, hparams)
self.featurizer = networks.Featurizer(input_shape, self.hparams)
self.classifier = networks.Classifier(
self.featurizer.n_outputs,
self.num_classes)

self.network = nn.Sequential(self.featurizer, self.classifier)
self.optimizer = torch.optim.Adam(
self.network.parameters(),
lr=self.hparams[&quot;lr&quot;],
weight_decay=self.hparams[&#39;weight_decay&#39;]
)
train_givenY = torch.from_numpy(train_givenY)
tempY = train_givenY.sum(dim=1).unsqueeze(1).repeat(1, train_givenY.shape[1])
label_confidence = train_givenY.float()/tempY
self.label_confidence = label_confidence

def update(self, minibatches):
_, x, strong_x, partial_y, _, index = minibatches
loss = self.rc_loss(self.predict(x), index)
self.optimizer.zero_grad()
loss.backward()
self.optimizer.step()
self.confidence_update(x, partial_y, index)
return {&#39;loss&#39;: loss.item()}

def rc_loss(self, output, index):
device = &quot;cuda&quot; if index.is_cuda else &quot;cpu&quot;
self.label_confidence = self.label_confidence.to(device)
logsm_outputs = F.log_softmax(outputs, dim=1)
#print(self.label_confidence.is_cuda)
final_outputs = logsm_outputs * self.label_confidence[index, :]
average_loss = - ((final_outputs).sum(dim=1)).mean()
return average_loss

def predict(self, x):
return self.network(x)

def confidence_update(self, batchX, batchY, batch_index):
with torch.no_grad():
batch_outputs = self.predict(batchX)
temp_un_conf = F.softmax(batch_outputs, dim=1)
&#39;&#39;&#39;有问题的代码开始了&#39;&#39;&#39;
self.label_confidence[batch_index, :] = temp_un_conf * batchY # un_confidence 存储每个示例的权重
&#39;&#39;&#39;问题代码结束&#39;&#39;&#39;
base_value = self.label_confidence.sum(dim=1).unsqueeze(1).repeat(1, self.label_confidence.shape[1])
self.label_confidence = self.label_confidence / base_value

问题出在 confidence_update 上。我发现
self.label_confidence[batch_index, :]

的值与
temp_un_conf * batchY

在此分配之后
self.label_confidence[batch_index, :] = temp_un_conf * batchY

仅适用于少数示例，但适用于大多数示例。例如，对于 1024 的批次大小，第一次迭代时大约有 4 个示例，之后会变得更大。我对这个问题非常沮丧，尝试了很多方法：

这个问题只存在于 CIFAR10，但其他数据集不存在。

所有张量的数据类型都是 Float32。

所有张量都在 gpu 上。


我的代码有什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78949501/mismatch-of-values-after-assigning-values-to-a-tensor-by-index</guid>
      <pubDate>Wed, 04 Sep 2024 15:41:44 GMT</pubDate>
    </item>
    <item>
      <title>Keras 的 one_hot 对不同的词产生相同的值</title>
      <link>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</link>
      <description><![CDATA[我使用 keras 的 one_hot 函数将单词转换为数字。但出于某种原因，它会为不同的单词生成相同的数字。在下面的代码中，您可以看到 48 用于“amazing”，但 48 也用于“too”。这是为什么？
from tensorflow.keras.preprocessing.text import one_hot

reviews = [&#39;nice food&#39;,
&#39;amazing restaurant&#39;,
&#39;too good&#39;,
&#39;just loved it!&#39;,
&#39;will go again&#39;,
&#39;horrible food&#39;,
&#39;never go there&#39;,
&#39;poor service&#39;,
&#39;poor quality&#39;,
&#39;needs Improvement&#39;]

# 转换为 ont hot 向量 
encoded_reviews = [one_hot(d, vocab_size) for d in reviews]

当我打印coded_reviews 时，它显示：
[[13, 12],
[48, 44],
[48, 19],
[38, 28, 46],
[13, 29, 19],
[46, 12],
[19, 29, 4],
[18, 38],
[18, 35],
[42, 7]]
]]></description>
      <guid>https://stackoverflow.com/questions/78626998/one-hot-from-keras-producing-the-same-value-for-different-words</guid>
      <pubDate>Sat, 15 Jun 2024 15:16:01 GMT</pubDate>
    </item>
    <item>
      <title>在 PyCharm 中运行 Teachable Machines 对象识别器</title>
      <link>https://stackoverflow.com/questions/78596363/running-teachable-machines-object-recognizer-in-pycharm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78596363/running-teachable-machines-object-recognizer-in-pycharm</guid>
      <pubDate>Sat, 08 Jun 2024 16:51:36 GMT</pubDate>
    </item>
    <item>
      <title>内核形状必须与输入具有相同的长度，但接收形状为 A 的内核和形状为 B 的输入</title>
      <link>https://stackoverflow.com/questions/78287794/kernel-shape-must-have-the-same-length-as-input-but-received-kernel-of-shape-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78287794/kernel-shape-must-have-the-same-length-as-input-but-received-kernel-of-shape-a</guid>
      <pubDate>Sun, 07 Apr 2024 12:27:31 GMT</pubDate>
    </item>
    <item>
      <title>将卫星图像与地图匹配</title>
      <link>https://stackoverflow.com/questions/74901142/matching-satellite-images-to-map</link>
      <description><![CDATA[我目前有点被一个问题难住了，听起来比实际容易（至少对我来说）：
假设你有从低地球轨道（LEO）拍摄的卫星图像，显示大约 1000 公里宽的区域（相机的图像轴或多或少垂直于地面）。图像中没有存储其他位置数据，因此无法直接提取拍摄图像的位置）。
我想要做的是编写一个程序（用 Python），可以通过将其与地球地图进行匹配来找到拍摄图像的位置。这应该自动完成（或多或少是实时的），以便计算拍摄图像的卫星的轨道。
一旦我有位置数据（即使非常嘈杂），使用基于扩展卡尔曼滤波器的技术，我可以毫无问题地计算轨道。
另一方面，仅使用图像数据将卫星图像与地球地图相匹配......老实说，我甚至不知道从哪里开始。
我知道这是一个非常不具体的问题，与特定问题无关，但也许有人可以给我指出正确的方向......
编辑：
只是为了让你了解未经处理的低地球轨道图像是什么样子，我附上了一些在地球轨道上拍摄的相当不错的图像。




图片是用 NIR 相机拍摄的。我所包含图片的分辨率只有 640x480（错误！），但图片分辨率应该在 4k 左右。
这些图片有一些瑕疵，因为它们是通过国际空间站的厚玻璃窗拍摄的 - 所以那里有一些反射……]]></description>
      <guid>https://stackoverflow.com/questions/74901142/matching-satellite-images-to-map</guid>
      <pubDate>Fri, 23 Dec 2022 15:08:14 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit learn 训练机器学习模型进行时间序列预测</title>
      <link>https://stackoverflow.com/questions/59843700/train-machine-learning-model-with-scikit-learn-for-time-series-prediction</link>
      <description><![CDATA[我需要使用 scikit-learn 训练一个模型来预测房间中人数较少的可能时间。
我的数据集如下所示：
时间 人数 数量
---------------------------------------------------------
2019-12-29 12:40:10 50
2019-12-29 12:42:10 30
2019-12-29 12:44:10 10
2019-12-29 12:46:10 10
2019-12-29 12:48:10 80
等等...

这些数据将保留 30 天。
模型训练完成后，我将查询模型以获取上午 10 点至下午 12 点之间房间中人数较少的可能时间晚上 8 点。我希望机器学习模型能够以 30 分钟的准确度做出响应，即“下午 3 点到 3 点 30 分”
我可以使用什么算法来解决这个问题，我该如何实现目标？或者除了 SciKit-Learn 之外，还有其他 Python 库可以用于此目的吗？]]></description>
      <guid>https://stackoverflow.com/questions/59843700/train-machine-learning-model-with-scikit-learn-for-time-series-prediction</guid>
      <pubDate>Tue, 21 Jan 2020 14:52:49 GMT</pubDate>
    </item>
    <item>
      <title>关于如何预测未来时间序列数据的建议</title>
      <link>https://stackoverflow.com/questions/37556600/advice-on-how-to-predict-future-time-series-data</link>
      <description><![CDATA[我有不同国家和因素的时间序列数据，例如“阿富汗”从 1972 年到 2007 年的出生率（来源）。
目标：
预测 2008 年和 2012 年的出生率
我熟悉线性回归，但需要一些关于如何处理时间序列数据和预测未来值的帮助。
您能给我举些例子或分享一些代码片段吗？]]></description>
      <guid>https://stackoverflow.com/questions/37556600/advice-on-how-to-predict-future-time-series-data</guid>
      <pubDate>Tue, 31 May 2016 22:22:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit-learn 中预测时间序列？</title>
      <link>https://stackoverflow.com/questions/20841167/how-to-predict-time-series-in-scikit-learn</link>
      <description><![CDATA[Scikit-learn 采用基于 fit 和 predict 方法的非常方便的方法。我有适合 fit 和 predict 格式的时间序列数据。
例如，我有以下 Xs：
[[1.0, 2.3, 4.5], [6.7, 2.7, 1.2], ..., [3.2, 4.7, 1.1]]

以及相应的 ys：
[[1.0], [2.3], ..., [7.7]]

这些数据具有以下含义。存储在 ys 中的值形成时间序列。 Xs 中的值是相应的时间相关“因素”，已知这些因素会对 ys 中的值产生一定影响（例如：温度、湿度和大气压力）。
现在，当然，我可以使用 fit(Xs,ys)。但是，我得到了一个模型，其中 ys 中的未来值仅取决于因素，而不依赖于先前的 Y 值（至少直接不依赖于），这是该模型的一个限制。我希望有一个模型，其中 Y_n 还依赖于 Y_{n-1 和 Y_{n-2 等等。例如，我可能想使用指数移动平均线作为模型。在 scikit-learn 中，最优雅的实现方式是什么？

已添加
正如评论中提到的，我可以通过添加 ys 来扩展 Xs。但这种方式有一些限制。例如，如果我将 y 的最后 5 个值作为 5 个新列添加到 X，则有关 ys 的时间顺序的信息将丢失。例如，X 中没有迹象表明第 5 列中的值遵循第 4 列中的值，依此类推。作为模型，我可能希望对最后五个 ys 进行线性拟合，并使用找到的线性函数进行预测。但是如果我有 5 个值，分 5 列，那么就没那么简单了。
添加 2
为了让我的问题更加清晰，我想举一个具体的例子。我想要一个“线性”模型，其中 y_n = c + k1*x1 + k2*x2 + k3*x3 + k4*EMOV_n，其中 EMOV_n 只是一个指数移动平均数。我如何在 scikit-learn 中实现这个简单的模型？]]></description>
      <guid>https://stackoverflow.com/questions/20841167/how-to-predict-time-series-in-scikit-learn</guid>
      <pubDate>Mon, 30 Dec 2013 14:06:33 GMT</pubDate>
    </item>
    </channel>
</rss>