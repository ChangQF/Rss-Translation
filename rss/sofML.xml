<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 13 Jan 2025 12:34:54 GMT</lastBuildDate>
    <item>
      <title>AttributeError：'RasterIOSource'对象没有属性'urlpath'[关闭]</title>
      <link>https://stackoverflow.com/questions/79352075/attributeerror-rasteriosource-object-has-no-attribute-urlpath</link>
      <description><![CDATA[我正在运行一个使用detectron2和zenodo库检测树冠的代码。
print(cat_tc[&#39;sepilok_rgb&#39;]) # 打印目录条目详细信息
print(&quot;URL Path:&quot;, cat_tc[&#39;sepilok_rgb&#39;].urlpath) # 打印urlpath

# 使用rioxarray直接从urlpath打开数据集
tc_rgb = rioxarray.open_rasterio(cat_tc[&#39;sepilok_rgb&#39;].urlpath)

print(&#39;dims =&#39;, tc_rgb.dims, &#39;, number of bands =&#39;, len(tc_rgb.data_vars), &#39;, crs =&#39;, tc_rgb.rio.crs)

我想打印url路径，但我收到属性错误]]></description>
      <guid>https://stackoverflow.com/questions/79352075/attributeerror-rasteriosource-object-has-no-attribute-urlpath</guid>
      <pubDate>Mon, 13 Jan 2025 11:46:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 FLOPS 和 FLOP 计算 GPU 执行时间</title>
      <link>https://stackoverflow.com/questions/79351271/calculate-gpu-excution-time-with-flops-and-flops</link>
      <description><![CDATA[我正在对深度学习模型进行性能分析，并希望验证以下计算执行时间的公式：
公式：时间（秒）= 模型 FLOP/GPU FLOP 每秒
上下文：
我有一个总共 24,029,362,176 FLOP 的模型。
我正在两个不同的 GPU 上对其进行测试：

NVIDIA A100 (80 GB)，峰值性能为 312 TFLOP（FP32）。
NVIDIA Tesla T4（Colab GPU），峰值性能为 8.1 TFLOP（FP32）。

使用该公式，我计算了这些 GPU 的执行时间。但是，我想确认一下这个公式对于比较 2 个 GPU 的执行时间估算是否有效。
这个公式对于估算执行时间模型是否准确？
]]></description>
      <guid>https://stackoverflow.com/questions/79351271/calculate-gpu-excution-time-with-flops-and-flops</guid>
      <pubDate>Mon, 13 Jan 2025 05:53:50 GMT</pubDate>
    </item>
    <item>
      <title>使用矩阵在 PyTorch 上计算公式</title>
      <link>https://stackoverflow.com/questions/79350403/calculate-formulas-on-pytorch-using-matrix</link>
      <description><![CDATA[我有方程式：
$e_{ij} = \frac{X_i W^Q (X_j W^K + A^K_{ij}) }{\sqrt{D_z}}$
$\alpha_{ij} = softmax(e_{ij})$
$z_{i} = \sum_j \alpha_{ij} (X_j W^V + A^V_{ij})$

其中大小：
X：[B，S，H，D]
每个 W：[H，D，D]
每个 A：[S，S，H，D]

我如何通过矩阵运算计算它？
我有一个部分解决方案
import torch
import torch.nn. functional as F

B, S, H, D = X.shape
d_z = D # 为简单起见，假设 d_z 等于 D

W_Q = torch.randn(H, D, D)
W_K = torch.randn(H, D, D)
W_V = torch.randn(H, D, D)

a_K = torch.randn(S, S, H, D)
a_V = torch.randn(S, S, H, D)
}
XW_Q = torch.einsum(&#39;bshd,hde-&gt;bshe&#39;, X, W_Q) # [B, S, H, D] @ [H, D, D] -&gt; [B，S，H，D]
XW_K = torch.einsum(&#39;bshd,hde-&gt;bshe&#39;, X, W_K) # [B，S，H，D] @ [H，D，D] -&gt; [B，S，H，D]

e_ij_numerator = XW_Q.unsqueeze(2) @ (XW_K.unsqueeze(1) + a_K).transpose(-1, -2) # [B，S，1，H，D] @ [B，1，S，H，D] -&gt; [B，S，S，H，D]
e_ij = e_ij_numerator / torch.sqrt(torch.tensor(d_z, dtype=torch.float32)) # [B，S，S，H，D]

XW_V = torch.einsum(&#39;bshd,hde-&gt;bshe&#39;, X, W_V) # [B，S，H，D] @ [H，D，D] -&gt; [B，S，H，D]
alpha = F.softmax(e_ij, dim=2) # [B，S，S，H，D]

z_i = torch.einsum(&#39;bshij,bshjd-&gt;bshid&#39;, alpha, XW_V.unsqueeze(1) + a_V) # [B，S，S，H，D] @ [B，1，S，H，D] -&gt; [B, S, S, H, D]

但 z 应该是 [B, S, H,D]]]></description>
      <guid>https://stackoverflow.com/questions/79350403/calculate-formulas-on-pytorch-using-matrix</guid>
      <pubDate>Sun, 12 Jan 2025 17:48:23 GMT</pubDate>
    </item>
    <item>
      <title>Xavier 初始化在经过第一个隐藏层后不保持方差</title>
      <link>https://stackoverflow.com/questions/79348329/xavier-initialization-doesnt-maintain-variance-after-pass-through-first-hidden</link>
      <description><![CDATA[一直在尝试初始化不同的权重。目前使用 MNIST 数据集，其中有 1 个隐藏层，每个层有 256 个神经元，并使用 tanh 激活。输入为零均值和单位方差。
因此，我假设在第一层之后的第一次传递之后，方差将大致相同或乘以我们提供的增益。
因此，如果输入方差为 1，则 fc1 之后的方差应为 1*5/3 或接近 1。但我得到的方差是 489。有人能更好地启发我吗？我感觉我直觉上缺少了一些东西。我尝试了
init.xavier_normal_(self.fc1.weight,gain=nn.init.calculate_gain(&#39;tanh&#39;)) 和
init.xavier_normal_(self.fc1.weight)
import torch
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.optim as optim
import torch.nn. functional as F
import random
import torch.nn.init as init

random.seed(42)
torch.manual_seed(42)

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
# 下载并加载训练和测试集
trainset = datasets.MNIST(root=&#39;./data&#39;, train=True, download=True, transform=transform)
testset = datasets.MNIST(root=&#39;./data&#39;, train=False, download=True, transform=transform)

# 创建 DataLoader 来分批处理数据
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)
testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)
class SimpleNN(nn.Module):
def __init__(self):
super(SimpleNN, self).__init__()
self.flatten = nn.Flatten()
self.fc1 = nn.Linear(28 * 28, 256)
self.fc2 = nn.Tanh() 
self.fc3 = nn.Linear(256, 10)
init.xavier_normal_(self.fc1.weight,gain=nn.init.calculate_gain(&#39;tanh&#39;))
init.xavier_normal_(self.fc3.weight)

def forward(self, x):
self.activations = {} 

x = self.flatten(x)
self.activations[&#39;input&#39;] = x

x = self.fc1(x)
self.activations[&#39;fc1&#39;] = x

x = self.fc2(x)
self.activations[&#39;fc2&#39;] = x

x = self.fc3(x)
self.activations[&#39;fc3&#39;] = x

return x
def analyze_layer_statistics(model):

stats = {}
for layer_name,activations in model.activations.items():
stats[layer_name] = {
&#39;mean&#39;: torch.mean(activations).item(),
&#39;var&#39;: torch.var(activations).item(),
&#39;min&#39;: torch.min(activations).item(),
&#39;max&#39;: torch.max(activations).item()
}

返回统计信息
model = SimpleNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(),lr=0.01)
epochs = 20
losses = []
stats = []
for epoch in range(epochs):
model.train()
total = 0
correct = 0
running_loss = 0.0
for images, labels in trainloader:
optimizer.zero_grad() 
output = model(images)
loss = criterion(output, labels)
loss.backward()
optimizer.step()
running_loss += loss
total += images.shape[0]
correct += (torch.argmax(output,dim=1)==labels).sum()
print(f&#39;Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(trainloader):.4f}&#39;)
print(f&#39;Accuracy = {(correct/total)*100}&#39;)
loss.append(running_loss/len(trainloader)) 
stats.append(analyze_layer_statistics(model))
break

输出：
stats 输出为

[{&#39;input&#39;: {&#39;mean&#39;: 0.023540694266557693,
&#39;var&#39;: 1.056724190711975,
&#39;min&#39;: -0.4242129623889923,
&#39;max&#39;: 2.821486711502075},
&#39;fc1&#39;: {&#39;平均值&#39;: 0.15851731598377228,
&#39;变量&#39;: 489.0372009277344,
&#39;最小值&#39;: -79.83320617675781,
&#39;最大值&#39;: 87.52055358886719},
&#39;fc2&#39;: {&#39;平均值&#39;: -0.0067255799658596516,
&#39;变量&#39;: 0.9763329029083252,
&#39;最小值&#39;: -1.0,
&#39;最大值&#39;: 1.0},
&#39;fc3&#39;: {&#39;平均值&#39;: -0.31016167998313904,
&#39;var&#39;: 17.94700050354004,
&#39;min&#39;: -11.344281196594238,
&#39;max&#39;: 13.964859962463379}}]

当我一次性传递整个数据集时，即一次性将全部 60000 个条目传递到第一层 - 第一次传递后的方差为 4
[{&#39;input&#39;: {&#39;mean&#39;: -0.00012828917533624917,
&#39;var&#39;: 1.0000507831573486,
&#39;min&#39;: -0.4242129623889923,
   “最大”：2.821486711502075}，
  &#39;fc1&#39;：{&#39;平均值&#39;：-0.04259666055440903，
   “变量”：3.9302892684936523，
   “分钟”：-13.193024635314941，
   “最大”：11.443111419677734}，
  &#39;fc2&#39;：{&#39;平均值&#39;：-0.012426979839801788，
   “变量”：0.6235496401786804，
   “分钟”：-1.0，
   “最大”：1.0}，
&#39;fc3&#39;: {&#39;mean&#39;: -0.197908416390419,
&#39;var&#39;: 1.3438835144042969,
&#39;min&#39;: -4.865184783935547,
&#39;max&#39;: 5.251534938812256}}]

我觉得我在初始化权重时缺少方差逻辑背后的一些直觉。]]></description>
      <guid>https://stackoverflow.com/questions/79348329/xavier-initialization-doesnt-maintain-variance-after-pass-through-first-hidden</guid>
      <pubDate>Sat, 11 Jan 2025 14:56:26 GMT</pubDate>
    </item>
    <item>
      <title>验证准确率很低但训练准确率很高</title>
      <link>https://stackoverflow.com/questions/73410090/very-low-validation-accuracy-but-high-training-accuracy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/73410090/very-low-validation-accuracy-but-high-training-accuracy</guid>
      <pubDate>Thu, 18 Aug 2022 22:32:25 GMT</pubDate>
    </item>
    <item>
      <title>Azure 数据集 .to_pandas_dataframe() 错误</title>
      <link>https://stackoverflow.com/questions/71939604/azure-dataset-to-pandas-dataframe-error</link>
      <description><![CDATA[我正在 udemy 上学习 azure ml 课程，但无法解决以下错误：
Dataset(id=&#39;id&#39;, name=&#39;Loan Applications Using SDK&#39;, version=1, error_code=None, exception_type=PandasImportError) 的操作“to_pandas_dataframe”执行失败
以下是提交脚本的代码：
from azureml.core import Workspace, Experiment, ScriptRunConfig, 
Environment

ws = Workspace.from_config(path=&quot;./config&quot;)

new_experiment = Experiment(workspace=ws,
name=&quot;Loan_Script&quot;)

script_config = ScriptRunConfig(source_directory=&quot;.&quot;,
script=&quot;180 - Script to Run.py”）

script_config.framework = “python”
script_config.environment = Environment(&quot;conda_env&quot;)

new_run = new_experiment.submit(config=script_config)

这是正在运行的脚本：
from azureml.core import Workspace, Datastore, Dataset, 
Experiment

from azureml.core import Run

ws = Workspace.from_config(path=&quot;./config&quot;)
az_store = Datastore.get(ws, &quot;bencouser_sdk_blob01&quot;)
az_dataset = Dataset.get_by_name(ws, name=&#39;Loan Applications Using SDK&#39;)
az_default_store = ws.get_default_datastore()

#%%----------------------------------------------------
# 获取运行的上下文
#------------------------------------------------------

new_run = Run.get_context()

#%%----------------------------------------------------
# 将记录的内容
#------------------------------------------------------

df = az_dataset.to_pandas_dataframe()

total_observations = len(df)

nulldf = df.isnull().sum()

#%%----------------------------------------------------
# 完成实验
#---------------------------------------------------

new_run.log(&quot;Total Observations:&quot;, total_observations)

for columns in df.columns:
new_run.log(columns, nulldf[columns])

new_run.complete()

我在实验之外运行了 .to_pandas_dataframe() 部分，并且没有出现错误。我还尝试了以下操作（驱动程序日志中推荐的操作）：
InnerException 无法导入 pandas。通过运行以下命令确保安装了兼容版本：pip install azureml-dataprep[pandas]
我之前见过有人遇到过这种情况，但我找不到解决方案，任何帮助都值得感激。]]></description>
      <guid>https://stackoverflow.com/questions/71939604/azure-dataset-to-pandas-dataframe-error</guid>
      <pubDate>Wed, 20 Apr 2022 12:24:54 GMT</pubDate>
    </item>
    <item>
      <title>使用支持向量回归进行预测</title>
      <link>https://stackoverflow.com/questions/51350585/predictions-using-support-vector-regression</link>
      <description><![CDATA[我的问题中有四个特征 (X)；a、b、c、d 和两个从属项 (Y)；e、f。我手头有一个数据集，其中包含所有这些变量的一组值。当给出新的 a,b,c,d 值时，如何使用 scikit-learn 通过支持向量回归预测 e,f 变量的值？
我发现很难遵循 scikit-learn 文档中的 SVR。
这是我在 sklearn 文档中的示例的帮助下到目前为止所做的。
train = pd.read_csv(&#39;/Desktop/test.csv&#39;)
X = train.iloc[:, 4]
y = train.iloc[:, 4:5]

svr_rbf = SVR(kernel=&#39;rbf&#39;, C=1e3, gamma=0.1)
y_rbf = svr_rbf.fit(X, y).predict(X)

lw = 2
plt.scatter(X, y, color=&#39;darkorange&#39;, label=&#39;data&#39;)
plt.plot(X, y_rbf, color=&#39;navy&#39;, lw=lw, label=&#39;RBF model&#39;)
plt.xlabel(&#39;data&#39;)
plt.ylabel(&#39;target&#39;)
plt.title(&#39;Support Vector Regression&#39;)
plt.legend()
plt.show()

这会出现错误，
ValueError: 预期为 2D 数组，但得到的却是 1D 数组：
:
如果您的数据只有一个特征，则使用 array.reshape(-1, 1) 重塑数据，如果数据包含单个样本，则使用 array.reshape(1, -1)。
 ]]></description>
      <guid>https://stackoverflow.com/questions/51350585/predictions-using-support-vector-regression</guid>
      <pubDate>Sun, 15 Jul 2018 17:31:02 GMT</pubDate>
    </item>
    <item>
      <title>在 sklearn 中预测训练数据</title>
      <link>https://stackoverflow.com/questions/43210970/predict-training-data-in-sklearn</link>
      <description><![CDATA[我这样使用 scikit-learn 的 SVM：
clf = svm.SVC()
clf.fit(td_X, td_y) 

当我使用分类器预测训练集成员的类别时，即使在 scikit-learn 实现中，分类器也会出错吗（例如 clf.predict(td_X[a])==td_Y[a]）？]]></description>
      <guid>https://stackoverflow.com/questions/43210970/predict-training-data-in-sklearn</guid>
      <pubDate>Tue, 04 Apr 2017 15:04:36 GMT</pubDate>
    </item>
    <item>
      <title>weka 对旋转森林方法中的分类属性做了什么？</title>
      <link>https://stackoverflow.com/questions/29838606/what-does-weka-do-for-categorical-attributes-in-rotation-forest-method</link>
      <description><![CDATA[我有一个包含数值和分类属性的数据集。我正在 Weka 中通过旋转森林进行分类。我知道旋转森林只适用于数值属性，因为它计算 PCA 和其他东西。
我的期望是 Weka 忽略分类属性，但当我使用整个数据集进行分类时和从数据集中删除分类属性时，性能结果不同。
Weka 在旋转森林方法中对分类属性做了什么？]]></description>
      <guid>https://stackoverflow.com/questions/29838606/what-does-weka-do-for-categorical-attributes-in-rotation-forest-method</guid>
      <pubDate>Fri, 24 Apr 2015 04:16:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Weka 中应用特征减少方法？</title>
      <link>https://stackoverflow.com/questions/20880365/how-can-i-apply-feature-reduction-methods-in-weka</link>
      <description><![CDATA[
如何在 weka 中应用 LSI 等特征缩减方法进行文本分类？

LSI 等特征缩减方法能否提高分类的准确性？

]]></description>
      <guid>https://stackoverflow.com/questions/20880365/how-can-i-apply-feature-reduction-methods-in-weka</guid>
      <pubDate>Thu, 02 Jan 2014 10:00:30 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类 weka</title>
      <link>https://stackoverflow.com/questions/18854599/randomforest-classification-weka</link>
      <description><![CDATA[csv 文件中的属性被保存在 11 列中。如果列的顺序发生变化，Randomforest 和 RandomTree 每次给出的准确率是否不同？]]></description>
      <guid>https://stackoverflow.com/questions/18854599/randomforest-classification-weka</guid>
      <pubDate>Tue, 17 Sep 2013 16:03:37 GMT</pubDate>
    </item>
    <item>
      <title>分类器 weka 的组合</title>
      <link>https://stackoverflow.com/questions/18854042/combination-of-classifiers-weka</link>
      <description><![CDATA[我已基于每个阶段的 107 个实例、11 个特征和 2 个类别构建了三个分类器。Weka 用作机器学习工具。

第一个分类器预测类别 0 和类别 1-2-3。（所有 107 个实例均用于交叉验证方法中的训练和测试）
第二个分类器预测类别 1 和类别 2-3。（移除类别 0 的实例以进行训练和测试）
第三个分类器预测类别 2 和类别 3。（移除类别 1 的实例以进行训练和测试）

每个分类器均应用了 Randoforest。有人知道我该如何组合这三个分类器吗？]]></description>
      <guid>https://stackoverflow.com/questions/18854042/combination-of-classifiers-weka</guid>
      <pubDate>Tue, 17 Sep 2013 15:34:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 weka 进行文本分类</title>
      <link>https://stackoverflow.com/questions/9639707/text-classification-with-weka</link>
      <description><![CDATA[我正在使用 Weka 库在 Java 中构建一个文本分类器。
首先我删除停用词，然后使用词干提取器（例如将 cars 转换为 car）。
现在我有 6 个预定义类别。我针对每个类别在
5 个文档上训练分类器。文档的长度相似。
当要分类的文本很短时，结果还不错。但是当文本长度超过 100 个字时，结果会变得越来越奇怪。
我返回每个类别的概率如下：
概率：
[0.0015560238056109177, 0.1808919321002592, 0.6657404531908249, 0.004793498469427115, 
0.13253647895234325, 0.014481613481534815] 

这是一个相当可靠的分类。
但是当我使用长度超过 100 个字的文本时，我得到的结果如下：
概率： [1.2863123678314889E-5, 4.3728547754744305E-5, 0.9964710903856974, 
5.539960514402068E-5, 0.002993481218084141, 4.234371196414616E-4]

哪个好。
现在我使用朴素贝叶斯多项式对文档进行分类。我读过
关于它的内容，发现我在处理较长的文本时会表现得很奇怪。这可能是我现在的问题吗？
为什么会这样？]]></description>
      <guid>https://stackoverflow.com/questions/9639707/text-classification-with-weka</guid>
      <pubDate>Fri, 09 Mar 2012 19:16:21 GMT</pubDate>
    </item>
    <item>
      <title>如何在weka中表示文本以进行分类？</title>
      <link>https://stackoverflow.com/questions/8313426/how-to-represent-text-for-classification-in-weka</link>
      <description><![CDATA[如何在 weka 中表示文本分类的属性或类别？使用什么属性可以进行分类，词频还是仅单词？ARFF 格式的可能结构是什么？您能给我几行该结构的示例吗？]]></description>
      <guid>https://stackoverflow.com/questions/8313426/how-to-represent-text-for-classification-in-weka</guid>
      <pubDate>Tue, 29 Nov 2011 15:32:02 GMT</pubDate>
    </item>
    <item>
      <title>weka java api stringtovector 异常</title>
      <link>https://stackoverflow.com/questions/6644191/weka-java-api-stringtovector-exception</link>
      <description><![CDATA[所以我有这个使用 Weka 的 Java API 的代码：
 String html = &quot;blaaah&quot;;
Attribute input = new Attribute(&quot;html&quot;,(FastVector) null);

FastVector inputVec = new FastVector();
inputVec.addElement(input);

Instances htmlInst = new Instances(&quot;html&quot;,inputVec,1);
htmlInst.add(new Instance(1)); 
htmlInst.instance(0).setValue(0, html);

System.out.println(htmlInst);

StringToWordVector filter = new StringToWordVector();
filter.setInputFormat(htmlInst);
Instances dataFiltered = Filter.useFilter(htmlInst, filter);

但是在 filter.setInputFormat(htmlInst) 行上，Java 抱怨该函数抛出了未处理的异常...
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/6644191/weka-java-api-stringtovector-exception</guid>
      <pubDate>Sun, 10 Jul 2011 22:35:28 GMT</pubDate>
    </item>
    </channel>
</rss>