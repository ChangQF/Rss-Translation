<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 29 Jan 2025 12:32:15 GMT</lastBuildDate>
    <item>
      <title>使用 ML/DL 算法并进行参数调整的最佳房价预测模型</title>
      <link>https://stackoverflow.com/questions/79396627/best-model-for-home-price-prediction-using-ml-dl-algorithms-with-parameter-tunin</link>
      <description><![CDATA[我使用以下代码根据其他特征进行价格估算：
#超参数调整代码
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from kerastuner.tuners import RandomSearch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

#加载数据集
#假设df是您的数据框
X = df.drop([&#39;Price&#39;, &#39;Log_Price&#39;], axis=1) #特征
y_price = df[&#39;Price&#39;]#目标变量
y_log_price = df[&#39;Log_Price&#39;]
y=y_price 
#将数据拆分为训练和测试集合
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定义 Keras Tuner 的模型构建函数
def build_model(hp):
model = Sequential()
# 调整层数
for i in range(hp.Int(&#39;num_layers&#39;, 1, 6)):
model.add(Dense(
unit=hp.Int(f&#39;units_{i}&#39;, min_value=32, max_value=256, step=32),
activation=&#39;relu&#39;
))
model.add(Dense(1)) # 输出层
# 调整学习率
learning_rate = hp.Choice(&#39;learning_rate&#39;, values=[1e-2, 1e-3, 1e-4])
model.compile(
optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
loss=&#39;mse&#39;,
metrics=[&#39;mae&#39;]
)
return model

# 初始化调谐器
tuner = RandomSearch(
build_model,
objective=&#39;val_loss&#39;,
max_trials=20, # 要尝试的超参数组合数
executives_per_trial=2, # 每次试验要训练的模型数
directory=&#39;tuner_results&#39;,
project_name=&#39;house_price_prediction&#39;
)

# 执行超参数搜索
tuner.search(
X_train, y_train,
epochs=100,
batch_size=32,
validation_split=0.2,
verbose=1
)

# 获取最佳模型
best_model = tuner.get_best_models(num_models=1)[0]

# 评估最佳模型
y_pred = best_model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f&quot;最佳模型 MAE: {mae}, MSE: {mse}&quot;)

# 打印最佳超参数
best_hyperparameters = tuner.get_best_hyperparameters()[0]
print(&quot;最佳超参数:&quot;, best_hyperparameters.values)


在这里，在试验中，一个可能是最好的，并将 mae 减少为 3000000；
如果下一次试验从这个终点开始，它可以提供更好的结果并减少更多的 mae；
但在下一次试验中，我再次得到 mae 的起点为 10000000 这样的值；
我该如何处理？
值得一提的是，我不喜欢 StandardScaler，因为它无法确保数据集的完整性！
如果有任何想法，当然会很高兴。
数据特征及其相关性如下：
价格 1.000000
大小 0.591717
房间数 0.462939
楼层 0.330746
建筑年龄 -0.113272
街区 -0.160568
地区 -0.363924

当我搜索时，有一些解决方案如下：

使用更高级的调谐器，如贝叶斯优化（BayesianOptimization 调谐器）或 Hyperband（Hyperband 调谐器）
从以前的试验中进行热启动
使用较小的搜索空间

但我仍然无法减少 mae blow 500在我的情况下可以接受吗？
基于 ML/DL 方法的特征进行房价估算]]></description>
      <guid>https://stackoverflow.com/questions/79396627/best-model-for-home-price-prediction-using-ml-dl-algorithms-with-parameter-tunin</guid>
      <pubDate>Wed, 29 Jan 2025 11:48:18 GMT</pubDate>
    </item>
    <item>
      <title>使用输入层作为第二个输入层的权重</title>
      <link>https://stackoverflow.com/questions/79396213/using-an-input-layer-as-a-weight-to-a-second-input-layer</link>
      <description><![CDATA[我有两个输入结构，其中第二个输入中的每个特征都使用输入 1 的值来计算每个特征。然后，第二个输入层连接到隐藏层，最后连接到单个输出层。因此，假设我在第一个输入中有 A、B、C，在第二个输入中有 G M N O，其中例如 G 被计算为总和（A 到 C），并且 G M N O 连接到隐藏层。如何使用 tensorflow keras 实现这一点？ G M N O 是连接到隐藏层的输入层。
input_elements = Input(shape=(4,), name=&quot;Elemental_Composition&quot;)
input_descriptors = Input(shape=(7,), name=&quot;Descriptors&quot;)

combined = concatenate([input_elements, input_descriptors])
hidden = Dense(64,activation=&quot;relu&quot;)
output = Dense(1,activation=&quot;linear&quot;)(hidden)
]]></description>
      <guid>https://stackoverflow.com/questions/79396213/using-an-input-layer-as-a-weight-to-a-second-input-layer</guid>
      <pubDate>Wed, 29 Jan 2025 09:17:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用“tf.data.Dataset.save”将数据集保存在多个分片中</title>
      <link>https://stackoverflow.com/questions/79395477/how-to-save-a-dataset-in-multiple-shards-using-tf-data-dataset-save</link>
      <description><![CDATA[如何使用 tf.data.Dataset.save() 将 tf.data.Dataset 保存到多个分片中？我正在使用 tf.data.experimental.make_csv_dataset 从 CSV 读取我的数据集。
此处的 TF 文档 不是很有用。有一个 shard_func 参数，但给出的示例没有帮助，并且不清楚如何以确定性方式映射到 int。使用随机 int 似乎也不起作用。
类似问题 此处 中的解决方案为我生成了一个错误
TypeError：不支持 % 的操作数类型：&#39;collections.OrderedDict&#39; 和 &#39;int&#39;
单分片（有效）
以下成功保存到单个分片。
import pandas as pd
import numpy as np
import tensorflow as tf

# gen data
n=10000
pd.DataFrame(
{&#39;label&#39;: np.random.randint(low=0, high=2, size=n),
&#39;f1&#39;: np.random.random(n),
&#39;f2&#39;: np.random.random(n),
&#39;f3&#39;: np.random.random(n),
&#39;c1&#39;: np.random.randint(n),
&#39;c2&#39;: np.random.randint(n)}
).to_csv(&#39;tmp.csv&#39;)
# 将数据加载到 tf.data.Dataset
data_ts = tf.data.experimental.make_csv_dataset(
&#39;tmp.csv&#39;, 1, label_name=&#39;label&#39;, num_epochs=1)
data_ts.save(&#39;tmp.data&#39;) # 单个分片，有效！

使用 randint 的多个分片（保存单个分片）
尝试使用随机数保存到多个分片，仍然只保存到单个分片，尽管文件名中有一个随机整数。
# 尝试使用随机数进行分片。
def random_shard_function(features, label):
return np.int64(np.random.randint(10))
data_ts.save(&#39;tmp2.data&#39;, shard_func=random_shard_function)



Modulo shard（错误）
尝试这个解决方案问题。
def modulo_shard_function(features, label):
return x &amp; 10
data_ts.save(&#39;tmp2.data&#39;, shard_func=modulo_shard_function)

TypeError: &amp; 不支持的操作数类型：&#39;collections.OrderedDict&#39; 和 &#39;int&#39;
调试 - 不知道 shard_fun 如何工作。
如果我打印出输入，似乎分片函数只运行一次，张量是 SymbolicTensors
def debug_shard_function(features, label):
for val in features.items():
print(f&#39;{val=}&#39;)
print(f&#39;{label=}&#39;)
print(f&#39;{type(val[1])}&#39;)
return np.int64(10)
data_ts.save(&#39;tmp2.data&#39;, shard_func=debug_shard_function)

输出：
仍然保存到单个分片
val=(&#39;&#39;, &lt;tf.Tensor &#39;args_0:0&#39; shape=(None,) dtype=int32&gt;)
val=(&#39;f1&#39;, &lt;tf.Tensor &#39;args_3:0&#39; shape=(None,) dtype=float32&gt;)
val=(&#39;f2&#39;, &lt;tf.Tensor &#39;args_4:0&#39; shape=(None,) dtype=float32&gt;)
val=(&#39;f3&#39;, &lt;tf.Tensor &#39;args_5:0&#39; shape=(None,) dtype=float32&gt;)
val=(&#39;c1&#39;, &lt;tf.Tensor &#39;args_1:0&#39; shape=(None,) dtype=int32&gt;)
val=(&#39;c2&#39;, &lt;tf.Tensor &#39;args_2:0&#39; shape=(None,) dtype=int32&gt;)
label=&lt;tf.Tensor &#39;args_6:0&#39; shape=(None,) dtype=int32&gt;
&lt;class &#39;tensorflow.python.framework.ops.SymbolicTensor&#39;&gt;
]]></description>
      <guid>https://stackoverflow.com/questions/79395477/how-to-save-a-dataset-in-multiple-shards-using-tf-data-dataset-save</guid>
      <pubDate>Wed, 29 Jan 2025 00:08:54 GMT</pubDate>
    </item>
    <item>
      <title>NumPy Stride 技巧：是否可以将窗口重新添加回原始数组大小的同一位置而无需 for 循环？</title>
      <link>https://stackoverflow.com/questions/79395423/numpy-stride-tricks-is-it-possible-to-add-the-windows-back-into-the-original-ar</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79395423/numpy-stride-tricks-is-it-possible-to-add-the-windows-back-into-the-original-ar</guid>
      <pubDate>Tue, 28 Jan 2025 23:28:50 GMT</pubDate>
    </item>
    <item>
      <title>LSTM AE 预测恒定输出</title>
      <link>https://stackoverflow.com/questions/79395028/lstm-ae-predicts-constant-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79395028/lstm-ae-predicts-constant-output</guid>
      <pubDate>Tue, 28 Jan 2025 19:57:18 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型从物理应用题中提取向量[关闭]</title>
      <link>https://stackoverflow.com/questions/79394932/machine-learning-model-to-extract-vectors-from-physics-word-problems</link>
      <description><![CDATA[我正在开展一个小项目，从物理应用题中提取向量及其属性，例如量级、方向和类型，以便进一步处理它们。这个项目将通过实施机器学习模型来取代我目前在 spaCy 中使用的基于规则的方法。例如，给定文本：
“Joe 向北走 2 米，然后向东走 3 米，”

我的目标是提取相应的向量属性：量级、方向和类型。在这种情况下，正确的输出将是：
2m，北，位移
3m，东，位移

但是，提取 3N，北，位移和 2m，东，位移是不正确的，因为 3m 与东方向相关，反之亦然。虽然我们目前的方法适用于更简单的句子（例如上面给出的句子），但句子结构的多变性带来了重大挑战，我相信机器学习可以更好地解决这些挑战。
我在网上看到这个模型可以通过简单的前馈结构和二元分类来完成。但我对训练数据和方法应该如何做感到非常困惑。ChatGPT 建议使用以下结构作为潜在的训练数据。这个结构合法吗？我也不确定如何使用 Keras 访问它。
这是 chatgpt 生成的 json 文件
[

{
&quot;context&quot;: [
&quot;一辆车以 50 公里的速度向北行驶，而另一辆车向东行驶 30 公里。&quot;
],
&quot;pairs&quot;: [
{&quot;magnitude&quot;: &quot;50 km&quot;, &quot;direction&quot;: &quot;north&quot;, &quot;label&quot;: 1},
{&quot;magnitude&quot;: &quot;30 km&quot;, &quot;direction&quot;: &quot;east&quot;, &quot;label&quot;: 1},
{&quot;magnitude&quot;: &quot;50 km&quot;, &quot;direction&quot;: &quot;east&quot;, &quot;label&quot;: 0},
{&quot;magnitude&quot;: &quot;30 km&quot;, &quot;direction&quot;: &quot;north&quot;, &quot;label&quot;: 0}
]
},
{
&quot;context&quot;: [
&quot;一辆汽车向南行进 40 公里。随后，它向东移动 20 公里。”
],
&quot;pairs&quot;: [
{&quot;magnitude&quot;: &quot;40 km&quot;, &quot;direction&quot;: &quot;south&quot;, &quot;label&quot;: 1},
{&quot;magnitude&quot;: &quot;20 km&quot;, &quot;direction&quot;: &quot;east&quot;, &quot;label&quot;: 1},
{&quot;magnitude&quot;: &quot;40 km&quot;, &quot;direction&quot;: &quot;east&quot;, &quot;label&quot;: 0},
{&quot;magnitude&quot;: &quot;20 km&quot;, &quot;direction&quot;: &quot;south&quot;, &quot;label&quot;: 0}
]
},
{
&quot;context&quot;: [
“一架飞机以 5 米/秒^2 的速度向上加速，然后以 3 米/秒^2 的速度向西减速。”
],
&quot;pairs&quot;: [
{&quot;magnitude&quot;: &quot;5 m/s^2&quot;, &quot;direction&quot;: &quot;upwards&quot;, &quot;label&quot;: 1},
{&quot;magnitude&quot;: &quot;3 m/s^2&quot;, &quot;direction&quot;: &quot;westward&quot;, &quot;label&quot;: 1},
{&quot;magnitude&quot;: &quot;5 m/s^2&quot;, &quot;direction&quot;: &quot;westward&quot;, &quot;label&quot;: 0},
{&quot;magnitude&quot;: &quot;3 m/s^2&quot;, &quot;direction&quot;: &quot;upwards&quot;, &quot;label&quot;: 0}
]
}
]

如何提取这些向量属性并相应地关联它们？]]></description>
      <guid>https://stackoverflow.com/questions/79394932/machine-learning-model-to-extract-vectors-from-physics-word-problems</guid>
      <pubDate>Tue, 28 Jan 2025 19:04:32 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ollama-python 包有效地对本地 Llama 3.1 模型进行并发调用？</title>
      <link>https://stackoverflow.com/questions/79394817/how-to-efficiently-make-concurrent-calls-to-a-local-llama-3-1-model-using-the-ol</link>
      <description><![CDATA[我正在使用本地 Llama 3.1:7b 模型。我正在使用 Python 和 ollama-python 包与模型交互。
我需要对模型进行 20,000 多次调用，但我目前是按顺序调用的，效率很低。我正在寻找提高效率的方法。具体来说，我试图找出是否有办法：

批量输入以一次发送多个请求。
使用线程、多处理或任何形式的并发处理来同时处理多个调用，而不是按顺序进行。
提高大量查询的整体速度和响应时间。

是否有人有使用 ollama-python 包实现此目的的建议或代码示例，或者在 Python 中处理并发 API 调用的一般技术？即使解决方案不专门涉及 ollama，我也愿意听取其他方法。
到目前为止，我已经尝试按顺序运行模型，目前正在尝试对调用进行线程化。]]></description>
      <guid>https://stackoverflow.com/questions/79394817/how-to-efficiently-make-concurrent-calls-to-a-local-llama-3-1-model-using-the-ol</guid>
      <pubDate>Tue, 28 Jan 2025 18:12:08 GMT</pubDate>
    </item>
    <item>
      <title>自定义字母表的文本识别</title>
      <link>https://stackoverflow.com/questions/79394460/text-recogniton-for-custom-alphabet</link>
      <description><![CDATA[我有一个虚构的字母表，由大约 20 种形状和字母组成，它们与希腊字母和西里尔字母相似。
它们是作为资产生成的，我为它们每个都制作了 30 x 30 的图像。我想创建一个特殊的图像处理工具来实时翻译它们。
它们总是打印在黑色多边形上。
所以我尝试使用通用 opencv2 方法使用黑色多边形进行检测，并且成功了。
为了扫描和检测字母，我尝试了 ORB 特征提取和匹配，但没有成功。由于相似的符文形状，它在整个字母中都发现了特征。
我曾尝试使用 Yolo11 训练物体检测模型，但由于数据量少（我没有已打印的示例，我尝试生成具有不同角度的模拟图像），它成本高且表现不佳。
我没有足够的数据来训练 HOG。
是否有一个简单的 Python 模式匹配算法，可以考虑现实生活中相机的小倾斜平移和滚动，因此仍然可以检测字母？]]></description>
      <guid>https://stackoverflow.com/questions/79394460/text-recogniton-for-custom-alphabet</guid>
      <pubDate>Tue, 28 Jan 2025 16:02:10 GMT</pubDate>
    </item>
    <item>
      <title>Keras 训练问题：“您的输入数据不足”警告和 0 损失/准确度</title>
      <link>https://stackoverflow.com/questions/79394023/keras-training-issue-your-input-ran-out-of-data-warning-and-0-loss-accuracy</link>
      <description><![CDATA[我正在使用 ImageDataGenerator 训练 CNN 模型，数据集包含 1500 张训练图像和 32 个批次大小。我计算每个时期的步数为
⌈1500/32⌉=47，最后一个批次不完整，我正在使用 flow_from_directory() 加载图像。但是，在第一个时期之后，模型显示某些时期的损失为 0，准确率为 0，并且训练中断并显示警告：

UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 steps_per_epoch * epochs 个批次。在构建数据集时，您可能需要使用 .repeat() 函数。
self.gen.throw(typ, value, traceback)

train_datagen = ImageDataGenerator(rescale=1./255)
valid_datagen = ImageDataGenerator(rescale=1./255)

# 从目录导入数据并将其转换为批次
train_data = train_datagen.flow_from_directory(train_path,
batch_size=32,
target_size=(224, 224),
class_mode=&quot;binary&quot;)

valid_data = valid_datagen.flow_from_directory(test_path,
batch_size=32,
target_size=(224, 224),
class_mode=&quot;binary&quot;)

tf.random.set_seed(42)

model_1 = tf.keras.models.Sequential([
输入（形状=（224, 224, 3）），
Conv2D（过滤器=10，
kernel_size=3，
strides=1，
padding=&#39;valid&#39;，
激活=&#39;relu&#39;），
Conv2D（10，3，激活=&#39;relu&#39;），
Conv2D（10，3，激活=&#39;relu&#39;），
Flatten（），
Dense（1，激活=&#39;sigmoid&#39;）
]）

model_1.compile（loss=“binary_crossentropy”，
optimizer=tf.keras.optimizers.Adam（），
metrics=[“accuracy”]）

history_1 = model_1.fit（train_data，
epochs=5，
steps_per_epoch=len（train_data），
validation_data=valid_data，
validation_steps=len(valid_data))

输出日志：
Epoch 1/5
/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122：UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()

47/47 ━━━━━━━━━━━━━━━━━━━━━ 767s 14s/step - 准确度：0.6488 - 损失：0.6197 - val_accuracy：0.7620 - val_loss：0.4793

Epoch 2/5
47/47 ━━━━━━━━━━━━━━━━━━━━━━ 0s 426us/step - 准确度：0.0000e+00 - 损失： 0.0000e+00

Epoch 3/5
/usr/lib/python3.11/contextlib.py:158: UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 `steps_per_epoch * epochs` 批次。您可能需要在构建数据集时使用 `.repeat()` 函数。
self.gen.throw(typ, value, traceback)

47/47 ━━━━━━━━━━━━━━━━━━━━━ 48s 224ms/step - 准确度：0.8120 - 损失：0.4131 - val_accuracy：0.8600 - val_loss：0.3441

Epoch 4/5
47/47 ━━━━━━━━━━━━━━━━━━━━━━━ 3s 54ms/step - 准确度：0.0000e+00 - 损失： 0.0000e+00

纪元 5/5
47/47 ━━━━━━━━━━━━━━━━━━━━━━ 11 秒 219 毫秒/步 - 准确度：0.8336 - 损失：0.3814 - val_accuracy：0.8880 - val_loss：0.3042
]]></description>
      <guid>https://stackoverflow.com/questions/79394023/keras-training-issue-your-input-ran-out-of-data-warning-and-0-loss-accuracy</guid>
      <pubDate>Tue, 28 Jan 2025 13:39:12 GMT</pubDate>
    </item>
    <item>
      <title>如何从接地恐龙的预测函数中提取边界框坐标？</title>
      <link>https://stackoverflow.com/questions/79393871/how-to-extract-bounding-box-coordinates-from-grounding-dinos-predict-function</link>
      <description><![CDATA[预测函数返回的框似乎不是规范化的形式，即使与图像宽度和高度相乘后，我也无法获得边界框的坐标。
import torch
from groundingdino.util.inference import load_model, load_image, predict, annotate
import cv2

# 加载模型
model = load_model(&quot;../GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py&quot;,
&quot;../GroundingDINO/weights/groundingdino_swint_ogc.pth&quot;)
IMAGE_PATH = &quot;.asset/cat_dog.jpeg&quot;
TEXT_PROMPT = &quot;person . animal . bird . object&quot;
BOX_THRESHOLD = 0.35
TEXT_THRESHOLD = 0.25

# 加载图像
image_source, image = load_image(IMAGE_PATH)

# 执行预测
boxes, logits, phrases = predict(
model=model,
image=image,
caption=TEXT_PROMPT,
box_threshold=BOX_THRESHOLD,
text_threshold=TEXT_THRESHOLD
)

# 获取图像尺寸
ht, wd = image_source.shape[:2]
print(ht, wd, image_source.shape[:2])

# 将边界框转换为绝对坐标
abs_box = boxes * torch.tensor([wd, ht, wd, ht])
abs_box = [abs_bo.numpy().astype(&quot;int&quot;) for abs_bo in abs_box]

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

for abs_bo in abs_box:
cv2.rectangle(annotated_frame, (abs_bo[0], abs_bo[1]),[![enter image description here][1]][1] (abs_bo[2], abs_bo[3]), (255, 0, 0), 2)

cv2.imwrite(&quot;annotated_image.jpg&quot;, annotated_frame)



蓝色框由“绝对”坐标，任何关于如何操作返回的数据以获得绝对坐标的见解都将非常有帮助，谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/79393871/how-to-extract-bounding-box-coordinates-from-grounding-dinos-predict-function</guid>
      <pubDate>Tue, 28 Jan 2025 12:45:28 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 分类器中获取属性错误</title>
      <link>https://stackoverflow.com/questions/79374019/getting-attribute-error-in-keras-classifier</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79374019/getting-attribute-error-in-keras-classifier</guid>
      <pubDate>Tue, 21 Jan 2025 10:21:29 GMT</pubDate>
    </item>
    <item>
      <title>无法访问自由变量“fig”，因为它与封闭范围内的值没有关联</title>
      <link>https://stackoverflow.com/questions/79270292/cannot-access-free-variable-fig-where-it-is-not-associated-with-a-value-in-enc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79270292/cannot-access-free-variable-fig-where-it-is-not-associated-with-a-value-in-enc</guid>
      <pubDate>Wed, 11 Dec 2024 02:04:10 GMT</pubDate>
    </item>
    <item>
      <title>Hugging Face 的 Transformers 库中 Trainer 使用的损失函数是什么？</title>
      <link>https://stackoverflow.com/questions/71581197/what-is-the-loss-function-used-in-trainer-from-the-transformers-library-of-huggi</link>
      <description><![CDATA[Hugging Face 的 Transformers 库中的 Trainer 中使用的损失函数是什么？
我正在尝试使用 Hugging Face 的 Transformers 库中的 Trainer 类 来微调 BERT 模型。
在他们的文档中，他们提到可以通过覆盖类中的 compute_loss 方法来指定自定义损失函数。但是，如果我不执行方法覆盖并使用 Trainer 直接微调 BERT 模型进行情绪分类，那么默认使用的损失函数是什么？是分类交叉熵吗？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/71581197/what-is-the-loss-function-used-in-trainer-from-the-transformers-library-of-huggi</guid>
      <pubDate>Wed, 23 Mar 2022 02:35:51 GMT</pubDate>
    </item>
    <item>
      <title>为什么在 sotfmax_cross_entropy_with_logits 中将 logit 解释为“未缩放对数概率”？</title>
      <link>https://stackoverflow.com/questions/48483980/why-explain-logit-as-unscaled-log-probabililty-in-sotfmax-cross-entropy-with-l</link>
      <description><![CDATA[在 tensorflow 文档 (softmax_cross_entropy_with_logits) 中，他们说“logits：未缩放的对数概率”。什么是“对数概率”？
首先，我理解 &#39;logits&#39; 是 &#39;归一化之前的输出&#39; 或 &#39;类别的分数&#39;。
logits = tf.matmul(X,W) + b
hypothesis = tf.nn.softmax(logits)

如果我通过 tf.matmul(X,W) + b 得到 [1.5, 2.4, 0,7]，那么 [1.5, 2.4, 0,7] 就是 logits(score)，并且这是未缩放的。我能理解到这个阶段。但是，我不明白为什么 [1.5, 2.4, 0.7] 是 &#39;对数概率&#39;。]]></description>
      <guid>https://stackoverflow.com/questions/48483980/why-explain-logit-as-unscaled-log-probabililty-in-sotfmax-cross-entropy-with-l</guid>
      <pubDate>Sun, 28 Jan 2018 07:00:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么我实现的深度神经网络在经过几次迭代后成本就会增加？</title>
      <link>https://stackoverflow.com/questions/47952812/why-does-the-cost-in-my-implementation-of-a-deep-neural-network-increase-after-a</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/47952812/why-does-the-cost-in-my-implementation-of-a-deep-neural-network-increase-after-a</guid>
      <pubDate>Sat, 23 Dec 2017 13:14:53 GMT</pubDate>
    </item>
    </channel>
</rss>