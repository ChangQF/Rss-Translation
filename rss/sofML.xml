<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 22 May 2024 12:27:52 GMT</lastBuildDate>
    <item>
      <title>使用 SHAP 解释学习到的潜在空间位置</title>
      <link>https://stackoverflow.com/questions/78517488/using-shap-to-explain-learned-latent-space-position</link>
      <description><![CDATA[我在 MNIST 数据集上的 pytorch 中实现了一个监督自动编码器。
我在潜在空间（大小 8）上使用分类层对其进行监督。在训练期间，我优化了 MSE 重建损失和分类损失 (BCE)。我在潜在空间中有单个实例，这些实例很有趣，我想找到它们不同位置的解释。
所以我的问题是，在潜在维度上使用 SHAP 值是否是一种有效的方法（它有效，我得到了值，但我不确定这是否有意义）。
更具体地说：我想比较例如实例 A 和实例 B。假设在潜在空间中它们相距很远，例如在潜在维度 3 of 8 中。现在我想找到输入中可以解释这种现象的像素。因此，我计算实例 A 和 B 的潜在表示的 SHAP 值，并比较两者的维度 3 的 SHAP 值。这是有效的吗？我认为它与解释多输出回归没有太大不同，对吧？但我还没有看到任何 SHAP 的应用来解释潜在位置
非常感谢您的任何评论！]]></description>
      <guid>https://stackoverflow.com/questions/78517488/using-shap-to-explain-learned-latent-space-position</guid>
      <pubDate>Wed, 22 May 2024 12:17:33 GMT</pubDate>
    </item>
    <item>
      <title>限制中途使用上传的图像来创建新图像</title>
      <link>https://stackoverflow.com/questions/78517370/restrict-mid-journey-to-use-the-uploaded-image-for-creating-new-image</link>
      <description><![CDATA[在中途有没有一种方法可以限制它使用我们自己上传的图像来创建新图像？例如，我有一个帽子的图像，并希望在旅途中创建一个戴着相同帽子的男孩的新图像。
如果不在旅途中，是否有任何图像生成工具可以执行相同的操作。]]></description>
      <guid>https://stackoverflow.com/questions/78517370/restrict-mid-journey-to-use-the-uploaded-image-for-creating-new-image</guid>
      <pubDate>Wed, 22 May 2024 11:55:32 GMT</pubDate>
    </item>
    <item>
      <title>ONNX 中的拆分模型</title>
      <link>https://stackoverflow.com/questions/78517213/splitting-models-in-onnx</link>
      <description><![CDATA[我想评估模型的性能。但我想为此进行分层评估，我需要将深度学习模型拆分为层/子图。你们有什么建议或资源吗？我知道 ONNX 允许您创建模型子图，但这并不是特定于每一层的。如果我想根据层而不是节点来拆分模型怎么办？
这有点超前，但 resnet 有 515 个节点。是否可以创建 10 个子图并通过一些分析来评估它们的每个性能？
目前我正在尝试探索创建给定模型（resnet.onnx）的子图。评估特定层/子图的推理性能的方法有哪些]]></description>
      <guid>https://stackoverflow.com/questions/78517213/splitting-models-in-onnx</guid>
      <pubDate>Wed, 22 May 2024 11:28:15 GMT</pubDate>
    </item>
    <item>
      <title>DQN 显示损失有所改善，但缺乏奖励改善</title>
      <link>https://stackoverflow.com/questions/78516916/dqn-showing-loss-improvements-but-lacking-reward-improvements</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78516916/dqn-showing-loss-improvements-but-lacking-reward-improvements</guid>
      <pubDate>Wed, 22 May 2024 10:32:11 GMT</pubDate>
    </item>
    <item>
      <title>阻止进程时内核崩溃</title>
      <link>https://stackoverflow.com/questions/78516548/kernel-crashed-while-stemming-process</link>
      <description><![CDATA[我使用这个函数来进行句子词干分析
从 nltk.stem 导入 WordNetLemmatizer、PorterStemmer
从 nltk.tokenize 导入 word_tokenize
导入字符串
从 nltk.corpus 导入停用词

标点符号 = set(字符串.标点符号)
english_stopwords = set(stopwords.words(&#39;english&#39;))
porter_stemmer = PorterStemmer()
def clean_text(文本):
    文本 = 文本.lower()
    标记 = word_tokenize(文本)
    clean_tokens = []
    clean_tokens = [如果令牌不在 english_stopwords 中则为令牌中的令牌的令牌]
    clean_tokens = [如果标记不在标点符号中，则标记为标记中的标记]
    clean_tokens = [token 中的 token if token.isalnum()]
    clean_tokens = [porter_stemmer.stem(token) for token in clean_tokens if len(token) &gt;; 0]

    返回 &#39;​​ &#39;.join(cleaned_tokens)


我只是在我的 csv 上运行它
导入 pandas 作为 pd
currData = pd.read_csv(f&#39;../Steam dataset/clean_steam_database(english)_133.csv&#39;)
currData[&#39;review&#39;] = [clean_text(word) for word in currData[&#39;review&#39;]]

但它说：
“在当前单元或前一个单元中执行代码时内核崩溃。
请检查单元格中的代码以确定失败的可能原因。
点击这里查看更多信息。
查看 Jupyter 日志以获取更多详细信息。”
和
给出这个错误：
＆quot;16：23：09.679 [错误]将会话处置为内核进程死亡 ExitCode：3221225725，原因：
16:23:09.706 [info] Cell 2 在 -1716369788.31 秒内完成（开始：1716369788310，结束：未定义）”
它可能是什么？
我实际上是从以下位置获取这个数据集的：
https://www.kaggle.com/datasets/najzeko/ steam-reviews-2021?resource=download
我在已分成 1000 个部分的数据集上运行此代码。
每次执行该函数时，我都会打印以查看哪个索引有问题，但是，当我直接在该索引处运行该函数时，它没有问题。
当我在 google colab 上运行这段代码时，它说
“RecursionError：比较中超出了最大递归深度”
Stem命令有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78516548/kernel-crashed-while-stemming-process</guid>
      <pubDate>Wed, 22 May 2024 09:32:06 GMT</pubDate>
    </item>
    <item>
      <title>每个时期 Retinanet 模型内的数据流</title>
      <link>https://stackoverflow.com/questions/78516393/flow-of-data-inside-the-retinanet-model-in-each-epoch</link>
      <description><![CDATA[需要通过提供batch_size、epochs和每个epoch的步骤来澄清向retinanet model_network提供了多少数据。
到目前为止，我认为步长的计算如下：
step_size = (total_number_of_data/batch_size)*epochs

而在keras-retinanet中，它以batch_size、epochs和steps_per_epoch作为参数，这与上述情况不同。我有疑问如何进行计算？提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/78516393/flow-of-data-inside-the-retinanet-model-in-each-epoch</guid>
      <pubDate>Wed, 22 May 2024 09:04:14 GMT</pubDate>
    </item>
    <item>
      <title>名为“视障援助”项目的功能[关闭]</title>
      <link>https://stackoverflow.com/questions/78515845/features-for-a-project-titled-assistance-for-visually-impaired</link>
      <description><![CDATA[我正在开展一个名为“为视障人士提供援助”的项目。我已经添加了一些功能，并且正在尝试添加更多功能。
任何人都可以向我建议一个可以添加以使其完美的功能列表吗？]]></description>
      <guid>https://stackoverflow.com/questions/78515845/features-for-a-project-titled-assistance-for-visually-impaired</guid>
      <pubDate>Wed, 22 May 2024 07:11:59 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“utils.feature_extractor”的模块[关闭]</title>
      <link>https://stackoverflow.com/questions/78515681/modulenotfounderror-no-module-named-utils-feature-extractor</link>
      <description><![CDATA[
嗨，为什么我有这个错误，我的文件上已经有这个函数，但它仍然错误？
我正在创建一个网络钓鱼链接检测，需要在执行结果之前扫描所需的功能。
我已经添加了该功能，我检查了拼写，但什么也没发生。]]></description>
      <guid>https://stackoverflow.com/questions/78515681/modulenotfounderror-no-module-named-utils-feature-extractor</guid>
      <pubDate>Wed, 22 May 2024 06:36:46 GMT</pubDate>
    </item>
    <item>
      <title>哪个库适合基于人脸检测的考勤系统，需要在没有GPU系统的低硬件设备上运行[关闭]</title>
      <link>https://stackoverflow.com/questions/78515586/which-is-the-suitable-library-for-face-detection-based-attendance-system-which</link>
      <description><![CDATA[需要在 Raspberry pi 中快速且准确地运行人脸检测代码。如果没有 GPU，输出非常慢，而且我无法使用 GPU，因此如果有人可以帮助或指导我，我将非常感激
任何用于人脸识别的库建议或代码]]></description>
      <guid>https://stackoverflow.com/questions/78515586/which-is-the-suitable-library-for-face-detection-based-attendance-system-which</guid>
      <pubDate>Wed, 22 May 2024 06:09:35 GMT</pubDate>
    </item>
    <item>
      <title>确定可最小化预测误差的最佳聚合级别</title>
      <link>https://stackoverflow.com/questions/78514089/determining-an-optimal-level-of-aggregation-that-would-minimize-prediction-error</link>
      <description><![CDATA[我正在寻找以最大化类别数量同时最小化分类错误的方式聚合预测结果的想法。
作为一个激励示例，假设我正在执行一项预测任务，以按流派对歌曲进行分类，并且有 6 种流派（来自下面的目标列）：

&lt;标题&gt;

类型（广泛）
类型（目标）


&lt;正文&gt;

流行音乐
独立流行音乐


流行音乐
超级流行


流行音乐
韩国流行音乐


摇滚
另类摇滚


摇滚
经典摇滚


摇滚
硬摇滚



该模型在识别前 4 个类别（独立流行、超级流行、韩国流行、另类摇滚）方面具有 100% 的准确率，但将大约 50% 的硬摇滚歌曲错误地分类为经典摇滚，将大约 20% 的经典摇滚歌曲错误地分类为硬摇滚摇滚。
基于此，我们可以想象通过几种方式聚合目标类型，从而减少分类错误。例如

2 个类别：流行、摇滚
4 个类别：独立流行音乐、超级流行音乐、韩国流行音乐、摇滚
5 个类别：独立流行音乐、超级流行音乐、韩国流行音乐、另类摇滚、其他摇滚

在本例中，我希望将目标类型聚合到这 5 个类别，保留尽可能多的类别，同时保持 100% 的准确性。
为了找到理想的聚合结构，我可以排列所有可能的聚合并计算 MSE。然而，考虑到我正在使用的类的数量，这在计算上是不可行的。所以，我想知道是否有一些相关文献可以阅读，以更好地理解如何解决这个问题，或者是否有人有想法。]]></description>
      <guid>https://stackoverflow.com/questions/78514089/determining-an-optimal-level-of-aggregation-that-would-minimize-prediction-error</guid>
      <pubDate>Tue, 21 May 2024 19:51:46 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow PPO 模型未给出模型输出</title>
      <link>https://stackoverflow.com/questions/78510077/tensorflow-ppo-model-not-giving-model-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78510077/tensorflow-ppo-model-not-giving-model-output</guid>
      <pubDate>Tue, 21 May 2024 06:49:17 GMT</pubDate>
    </item>
    <item>
      <title>如果该层没有任何权重，则如何在 NN 中计算梯度下降</title>
      <link>https://stackoverflow.com/questions/78509864/how-gradient-descent-is-calculated-in-nn-if-the-layer-is-not-having-any-weights</link>
      <description><![CDATA[考虑具有三层的简单神经网络。第二层是我的自定义层，我没有任何权重或偏差，我只是转发输入乘以某个常数值。我了解前向传播流程，但我不了解反向传播如何与自定义层一起使用。我期望梯度下降为零，因为常数的导数为零，但它计算了某个值的梯度下降，我不确定梯度下降是如何计算的。
导入火炬作为t
将 torch.nn 导入为 nn

类自定义层（nn.Module）：
 def __init__(自身):
     超级（自定义层，自我）.__init__()
 def 前向（自身，x）：
     返回 x.mul(0.001)

def hookFunc(模块, gradInput, gradOutput):
   打印（模块）
   打印（等级输入）
   打印（梯度输出）

random_input = t.randn(2,2)

随机输出 = t.randn(1,1)
print(&#39;随机输入是&#39;, random_input)
标准 = nn.MSELoss()
＃ 模型
l1 = nn.Linear(2, 3, 偏差=False)
l2 = 自定义层()
l3 = nn.Linear(3, 1, 偏差=False)


l1.register_backward_hook(hookFunc)
l2.register_backward_hook(hookFunc)
l3.register_backward_hook(hookFunc)

中间1 = l1(随机输入)
中间2 = l2(中间1)
输出= l3(中间2)

损失=标准（输出，随机输出）
loss.backward()

打印（l1.重量）

打印（&#39; -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - &#39;）
打印（l1.体重.grad）
打印（l3.权重.grad）

打印（&#39; -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  - - &#39;) ```
]]></description>
      <guid>https://stackoverflow.com/questions/78509864/how-gradient-descent-is-calculated-in-nn-if-the-layer-is-not-having-any-weights</guid>
      <pubDate>Tue, 21 May 2024 05:55:09 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：用户偏好向量和餐厅特征向量必须具有相同的维数</title>
      <link>https://stackoverflow.com/questions/78475573/valueerror-user-preference-vector-and-restaurant-feature-vectors-must-have-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78475573/valueerror-user-preference-vector-and-restaurant-feature-vectors-must-have-the</guid>
      <pubDate>Tue, 14 May 2024 03:27:58 GMT</pubDate>
    </item>
    <item>
      <title>MLFlow 配方：缺少临时文件</title>
      <link>https://stackoverflow.com/questions/77096670/mlflow-recipes-missing-temporary-file</link>
      <description><![CDATA[首次在 Azure Databricks 环境中尝试 MLFlow Recipes。直到昨天，从摄取到预测一切都很顺利。然而今天，我遇到了一个错误，提示 MLFlow 在训练我的模型时找不到在我看来像是临时文件的内容。我真的没有在所有这些步骤中做任何花哨的事情，而是想使用 LGBMClassifier 进行训练。 MLFlow版本是2.7.0，但它似乎不适用于我尝试过的任何其他版本。
experiment_name = “experiment_name”

如果不是 mlflow.get_experiment_by_name(experiment_name)：
    mlflow.create_experiment(name=experiment_name )
别的：
    mlflow.set_experiment(实验名称)
实验 = mlflow.get_experiment_by_name(experiment_name)

r = 配方(profile=&quot;databricks&quot;)
r.clean()
r.inspect()
r.run(“摄取”)
r.run(“分割”)
r.run(“变换”)
r.run(“火车”)

这是我的估计器函数在 train.py 中的样子。 estimator_params 在recipe.yaml 中定义。
def estimator_fn(estimator_params: Dict[str, Any] = None):
    从 lightgbm 导入 LGBMClassifier

    如果 estimator_params 为 None：
        estimator_params = {}
        
    返回 LGBMClassifier(**estimator_params)

正如我所说，昨天相同的代码对我来说工作得很好，但今天我遇到了这个错误：
运行 MLFlow 配方步骤：训练
2023/09/13 11:09:36 INFO mlflow.recipes.step：跑步步骤火车...
2023/09/13 11:09:38 INFO mlflow.recipes.steps.train：类别不平衡 0.50 优于 0.3，无需重新平衡
回溯（最近一次调用最后一次）：
  文件“”，第 1 行，位于  中。
  文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/recipes/step.py”，第132行，运行中
    self.step_card = self._run(output_directory=output_directory)
  文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/recipes/steps/train.py”，第373行，在_run中
    logging_estimator = self._log_estimator_to_mlflow(fitted_estimator, X_train)
  文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/recipes/steps/train.py”，第1270行，在_log_estimator_to_mlflow中
    返回 mlflow.sklearn.log_model(
  文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/sklearn/__init__.py”，第408行，在log_model中
    返回模型.log(
  文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/models/model.py”，第 568 行，日志中
    将 TempDir() 作为 tmp：
  文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/utils/file_utils.py”，第383行，在__enter__中
    self._path = os.path.abspath(create_tmp_dir())
  文件“/local_disk0/.ephemeral_nfs/envs/pythonEnv-f235e133-8940-41eb-b389-d9cf570c187a/lib/python3.10/site-packages/mlflow/utils/file_utils.py”，第 830 行，位于 create_tmp_dir
    返回 tempfile.mkdtemp(dir=repl_local_tmp_dir)
  文件“/usr/lib/python3.10/tempfile.py”，第 507 行，在 mkdtemp 中
    _os.mkdir(文件, 0o700)
FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;/tmp/repl_tmp_data/ReplId-68395-9c373-e0490-3/tmpuyeyu8co&#39;
make: *** [Makefile:40: 步骤/训练/输出/模型] 错误 1

我真的不知道该怎么办，因为堆栈跟踪似乎表明存在一些 MLFlow 内部错误。]]></description>
      <guid>https://stackoverflow.com/questions/77096670/mlflow-recipes-missing-temporary-file</guid>
      <pubDate>Wed, 13 Sep 2023 11:30:27 GMT</pubDate>
    </item>
    <item>
      <title>关于 pytorch 在多 GPU 上的再现性</title>
      <link>https://stackoverflow.com/questions/70178014/something-about-the-reproducibility-of-pytorch-on-multi-gpu</link>
      <description><![CDATA[我设置了随机种子以使我的模型可重现，并且当我使用单个 GPU 来训练我的模型时它可以工作。
但当我尝试使用 nn.DataParallel() 在两个 GPU 上训练我的模型时，它似乎不起作用。每次的结果都不一样。
那么问题出在哪里呢？
设置种子的函数是这样的：
def set_seed(种子):
    随机种子（种子）
    np.随机.种子（种子）
    torch.manual_seed(种子)
    torch.cuda.manual_seed（种子）
    torch.cuda.manual_seed_all(种子)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.确定性 = True
]]></description>
      <guid>https://stackoverflow.com/questions/70178014/something-about-the-reproducibility-of-pytorch-on-multi-gpu</guid>
      <pubDate>Wed, 01 Dec 2021 01:15:54 GMT</pubDate>
    </item>
    </channel>
</rss>