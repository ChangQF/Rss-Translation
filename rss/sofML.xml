<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 25 Jun 2024 09:15:52 GMT</lastBuildDate>
    <item>
      <title>如何检测重叠图片中的不同符号</title>
      <link>https://stackoverflow.com/questions/78666370/how-to-detect-different-symbols-in-a-picture-with-overlapping</link>
      <description><![CDATA[我有一张包含每个项目里程碑信息的图片。每个里程碑都用独特的符号在图表中标记。在图片中，我们有不同的三角形或正方形，颜色也不同。
我需要从图例中的符号中提取有关日期的信息。这意味着我需要知道每个符号及其图例的位置。然后在 x 轴和 y 轴上搜索临近日期。
里程碑图片
我尝试过使用 cv2 进行颜色识别。首先，我提取了 x-y 轴上的日期并保存了它们的位置。我对黄色菱形使用 cv2，效果很好。但是当涉及到红色或灰色时，因为有不同的符号，但都是红色。我无法仅使用 cv2 来区分它们。
cv2 中的传统计算机视觉方法无法处理重叠。例如有两种类型的红色三角形，一种指向左侧。面对所有这些问题，我无法找到一种好的方法来识别图例中的每个符号。你有什么建议吗？
也许训练 ML 是一个潜在的解决方案。我有大约 1000 张这样的图片。我不知道训练模型是否足够。但工作量也会很大。]]></description>
      <guid>https://stackoverflow.com/questions/78666370/how-to-detect-different-symbols-in-a-picture-with-overlapping</guid>
      <pubDate>Tue, 25 Jun 2024 09:04:21 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark MLlib 自定义 Transformer 类 -AttributeError:'DummyMod' 对象没有属性 'MyTransformer'</title>
      <link>https://stackoverflow.com/questions/78665992/pyspark-mllib-custom-transformer-class-attributeerror-dummymod-object-has-no</link>
      <description><![CDATA[我正在尝试创建一个自定义转换器作为管道中的一个阶段。一些转换我通过 SparkNLP 进行，接下来的几个转换使用 MLlib。要将某个阶段的 SparkNLP 转换结果传递给下一个 MLlib 转换，我需要提取 spark_nlp_col.result 列并传递它，为此我使用了自定义转换阶段。
在我安装好管道后，我可以将其持久化，但当我再次加载它时，我收到错误：
AttributeError：&#39;DummyMod&#39; 对象没有属性 &#39;MyTransformer&#39;
这是我的课程：
从 pyspark.ml 导入 Transformer
从 pyspark.ml.param.shared 导入 Param、Params、TypeConverters

class MyTransformer(Transformer、DefaultParamsWritable、DefaultParamsReadable):
inputCol = Param(Params._dummy(), &quot;inputCol&quot;, &quot;&quot;,TypeConverters.toString)
outputCol = Param(Params._dummy(), &quot;outputCol&quot;, &quot;&quot;,TypeConverters.toString)

def __init__(self,inputCol=None,outputCol=None):
super(MyTransformer, self).__init__()
self._setDefault(inputCol=None)
self._set(inputCol = inputCol)
self._setDefault(outputCol=None)
self._set(outputCol = outputCol)

def getInputCol(self):
return self.getOrDefault(self.inputCol)

def setInputCol(self, inputCol):
self._set(inputCol=inputCol)

def getOutputCol(self):
return self.getOrDefault(self.outputCol)

def setOutputCol(self, outputCol):
self._set(outputCol=outputCol)

def _transform(self, dataset):
in_col = self.getInputCol()
out_col = self.getOutputCol()

final_in_col = in_col+&quot;.result&quot;
result = dataset.withColumn(out_col, dataset[final_in_col])
返回结果

我已在其上创建了一个简单的包装函数以进行标准化，然后使用它来创建管道、拟合并保存它：
def extract_col(cols, in_suffix, out_suffix):
return [MyTransformer(inputCol=col+in_suff, outputCol=col+out_suffix) for col in cols]

自定义转换器之前的阶段数

extractors = extract_col(cols, &quot;_in&quot;, &quot;_out&quot;)

自定义转换器之后的阶段数

stages = s1 + s2 + .. + extractors + .. + snlast + sn
pipeline = Pipeline(stages = periods)
fit_pipeline = pipeline.fit(data)
fit_pipeline.write().overwrite().save(&quot;path_to_store_at&quot;)

我如何读回它：
saved_pipeline = PipelineModel.load(&quot;path_where_stored&quot;)

然后我遇到了错误。
我尝试了多种编写自定义类的方法，使用 HasInputCol、HasOutputCol 等，但到目前为止都没有效果。
有什么想法可以解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/78665992/pyspark-mllib-custom-transformer-class-attributeerror-dummymod-object-has-no</guid>
      <pubDate>Tue, 25 Jun 2024 07:42:56 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试读取 .wav 文件，但只能转换 20 秒的对话。请提出建议</title>
      <link>https://stackoverflow.com/questions/78665946/i-am-trying-to-read-a-wav-file-but-was-able-to-convert-only-20s-conversation-p</link>
      <description><![CDATA[我尝试读取 .wav 文件，但只能将 20 秒的对话转换为文本。请提出建议。
 # 读取 .wav 文件的代码 
import Speech_recognition as sr
r = sr.Recognizer()
audio = r&quot;D:\Fraud_Call_Detection\audio1.wav&quot;
with sr.AudioFile(audio) as source:
audio = r.record(source)
print (&#39;Done!&#39;)

try:

text = (r.recognize_google(audio, language=&quot;en-HK&quot;))
print (text)

except Exception as e:
print (e)

输出：]]></description>
      <guid>https://stackoverflow.com/questions/78665946/i-am-trying-to-read-a-wav-file-but-was-able-to-convert-only-20s-conversation-p</guid>
      <pubDate>Tue, 25 Jun 2024 07:33:04 GMT</pubDate>
    </item>
    <item>
      <title>在 C# 应用程序中使用我的模型时出现形状不兼容错误</title>
      <link>https://stackoverflow.com/questions/78665873/incompatible-shapes-error-while-using-my-model-in-a-c-sharp-app</link>
      <description><![CDATA[我在使用 Python 开发的图像分类器模型时遇到了问题，我想将其用于 C# 工业应用中。
这是模型结构：
model = Sequential([
Conv2D(32, (3, 3),activation=&#39;relu&#39;, input_shape=(img_height, img_width, 3)),
MaxPooling2D((2, 2)),
Conv2D(64, (3, 3),activation=&#39;relu&#39;),
MaxPooling2D((2, 2)),
Conv2D(128, (3, 3),activation=&#39;relu&#39;),
MaxPooling2D((2, 2)),
Flatten(),
Dense(512,activation=&#39;relu&#39;),
Dropout(0.5),
Dense(len(class_names),激活=&#39;softmax&#39;)
])

这是我在 C# 中使用的代码：
var modelfile = &quot;D:\\Soft\\Soft\\C#\\LastVersion\\frozen_model.pb&quot;;
var labels = new[] { &quot;ORANGE&quot;, &quot;BANANA&quot;, &quot;APPLE&quot;, &quot;MIX&quot; };

var graph = new Graph().as_default();
graph.Import(File.ReadAllBytes(modelfile));

using (var session = tf.Session(graph))
{
var tensor = ImageToTensor(RutaImagen);

var input_op = graph.OperationByName(&quot;sequence_1/conv2d_1/convolution&quot;); 
var output_op = graph.OperationByName(&quot;sequence_1/dense_1_2/Softmax&quot;); 

// 下一行给我一个运行时错误
var result = session.run(output_op.outputs[0], (input_op.outputs[0], tensor));

var results = result.ToArray&lt;float&gt;();
float totalConfidence = results.Sum();

int[] quantized = Quantized(results);

label1.Text = &quot;Resultados cuantizados:\n&quot;;
for (int i = 0; i &lt; results.Length; i++)
{
label1.Text += $&quot;{labels[i]}:\n&quot; +
$&quot; Valor original: {results[i]:0.000}\n&quot; +
$&quot;概率：{results[i] * 100:0.00}%\n&quot; +
$&quot; 归一化：{(results[i] / totalConfidence) * 100:0.00}%\n&quot; +
$&quot; 概率：{(results[i] &gt;= 0.5 ? &quot;可能&quot; : &quot;不可能&quot;)}\n&quot;;
}

我调用 ImageToTensor 函数的代码来预处理图像：
 private static NDArray ImageToTensor(string file)
{
Bitmap bitmap = new Bitmap(file);
Bitmap resizedBitmap = new Bitmap(bitmap, new Size(imgWidth, imgHeight));

// 将图像转换为张量
float[,,,] input = new float[1, imgHeight, imgWidth, 3];
for (int y = 0; y &lt; imgHeight; y++)
{
for (int x = 0; x &lt; imgWidth; x++)
{
Color pixel = resizedBitmap.GetPixel(x, y);
input[0, y, x, 0] = pixel.R / 255.0f;
input[0, y, x, 1] = pixel.G / 255.0f;
input[0, y, x, 2] = pixel.B / 255.0f;
}
}
//return new DenseTensor&lt;float&gt;(input);
return np.array(input);
}

最后是运行时错误：
执行时
var result = session.run(output_op.outputs[0], (input_op.outputs[0], tensor));
Tensorflow.InvalidArgumentError
HResult=0x80131500
Message=不兼容的形状：[1,1,1,32] vs. [1,200,150,3]
[[{{node chronological_1/conv2d_1/add}}]]
Source=Tensorflow.Binding
StackTrace:
at Tensorflow.Status.Check(Boolean throwException)
at Tensorflow.BaseSession._call_tf_sessionrun(KeyValuePair`2[] feed_dict, TF_Output[] fetch_list, List`1 target_list)
at Tensorflow.BaseSession._do_run(List`1 target_list, List`1 fetch_list, Dictionary`2 feed_dict)
在 Tensorflow.BaseSession._run(Object fetches, FeedItem[] feed_dict)
在 Tensorflow.BaseSession.run(Tensor fetche, FeedItem[] feed_dict)
在 Test2.Form1.EvaluarImagen(String RutaImagen) 在 D:\Soft\Soft\C#\LastVersion\Test2\Form1.cs:line 103
在 Test2.Form1.button1_Click(Object sender, EventArgs e) 在 D:\Soft\Soft\C#\LastVersion\Test2\Form1.cs:line 26
在 System.Windows.Forms.Button.OnClick(EventArgs e)
在 System.Windows.Forms.Button.OnMouseUp(MouseEventArgs mevent)
在 System.Windows.Forms.Control.WmMouseUp(Message&amp; m，MouseButtons 按钮，Int32 点击）
在 System.Windows.Forms.Control.WndProc(Message&amp; m)
在 System.Windows.Forms.ButtonBase.WndProc(Message&amp; m)
在 System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message&amp; m)
在 System.Windows.Forms.NativeWindow.Callback(HWND hWnd, MessageId msg, WPARAM wparam, LPARAM lparam)


有人能帮我一下吗？我很绝望
谢谢大家]]></description>
      <guid>https://stackoverflow.com/questions/78665873/incompatible-shapes-error-while-using-my-model-in-a-c-sharp-app</guid>
      <pubDate>Tue, 25 Jun 2024 07:17:05 GMT</pubDate>
    </item>
    <item>
      <title>如何自动从工程图中提取外部尺寸？[关闭]</title>
      <link>https://stackoverflow.com/questions/78665748/how-do-i-extract-the-outer-dimensions-from-an-engineering-drawing-automatically</link>
      <description><![CDATA[我最近一直在研究从工程图中提取信息，因为公司经常会收到很多图纸，而编制清单需要标题、说明、重量、图纸编号和外部尺寸等特征。
我看到了 Werk24 的这个工具 - https://werk24.io/blog/why-extracting-external-dimensions-from-technical-drawings-is-compliated。
他们声称他们将图纸转换为 3D 图纸，然后从 3D 模型中可靠地提取外部尺寸。但我不明白如何自动将 PDF 工程图转换为 3D 格式
我能够准确地提取标题、说明、重量和图纸编号，但无法提取外部尺寸。我尝试使用 ChatGPT 4o，但它只是在编造一些数字。尽管修改了提示并解释了它们的工作原理，但输出没有任何改进。]]></description>
      <guid>https://stackoverflow.com/questions/78665748/how-do-i-extract-the-outer-dimensions-from-an-engineering-drawing-automatically</guid>
      <pubDate>Tue, 25 Jun 2024 06:45:03 GMT</pubDate>
    </item>
    <item>
      <title>在语义分割模型上对脑肿瘤患者进行分割时，keras 中的 nan 损失 2021 年任务 1</title>
      <link>https://stackoverflow.com/questions/78665443/nan-loss-in-keras-when-working-on-a-semantic-segmentation-model-to-segment-brain</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78665443/nan-loss-in-keras-when-working-on-a-semantic-segmentation-model-to-segment-brain</guid>
      <pubDate>Tue, 25 Jun 2024 04:49:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用 colsample_bytree 超参数时始终保留 XGBoost 中的某个特征</title>
      <link>https://stackoverflow.com/questions/78665326/how-to-always-keep-a-feature-in-xgboost-while-using-colsample-bytree-hyperparame</link>
      <description><![CDATA[我使用 XGBoost 训练 ML 模型。如果我使用 colsample_bytree 超参数，XGBoost 会平等对待所有特征。我需要始终包含一个二进制特征，因为该特征决定了观察结果属于哪个子样本。其他特征应在训练期间随机包含，由 colsample_bytree 超参数决定。如何做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/78665326/how-to-always-keep-a-feature-in-xgboost-while-using-colsample-bytree-hyperparame</guid>
      <pubDate>Tue, 25 Jun 2024 03:52:51 GMT</pubDate>
    </item>
    <item>
      <title>我如何根据 1 分钟间隔内初始 5 个等距变化率来建模预测衰减趋势？</title>
      <link>https://stackoverflow.com/questions/78665223/how-can-i-model-to-predict-decay-trend-based-on-intial-5-equally-spaced-rate-of</link>
      <description><![CDATA[我有 30 条衰减轨迹。每条轨迹的变化率略有不同。我想基于每 1 分钟后的 5 个初始变化率进行建模（经典或 RNN）。因此，前 5 分钟我有 R1、R2、R3、R4、R5，然后想预测衰减轨迹的其余部分。对于训练，我们可以使用整个轨迹，在推理时输入将是 5 个速率。有哪些可能的方法可以对此进行建模？]]></description>
      <guid>https://stackoverflow.com/questions/78665223/how-can-i-model-to-predict-decay-trend-based-on-intial-5-equally-spaced-rate-of</guid>
      <pubDate>Tue, 25 Jun 2024 02:59:47 GMT</pubDate>
    </item>
    <item>
      <title>我想通过机器学习预测未来 60 天的股票价格</title>
      <link>https://stackoverflow.com/questions/78665213/i-want-to-predict-stock-price-in-next-60-days-by-machine-learning</link>
      <description><![CDATA[我想预测未来60天的股价，但是写完代码后，预测结果却向后。有人能指点我吗？我该怎么做？我修改了代码，但是不起作用。
我的代码是
import math
from mplfinance.original_flavor import candlestick_ohlc
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping
from sklearn.metrics import mean_squared_error

Tencent2.head()
#定义特征和目标
##features = [&#39;Open&#39;, &#39;Vol.&#39;]
##target = &#39;Price&#39;

#绘制折线图
Tencent2[&#39;Date&#39;] = pd.to_datetime(Tencent2[&#39;日期&#39;])
plt.figure(figsize=(15,6))
plt.plot(Tencent2[&#39;日期&#39;], Tennis2[&#39;收盘价&#39;], marker=&#39;.&#39;)
plt.title(&#39;按月收盘价&#39;, fontsize=15)
plt.xlabel(&#39;日期&#39;, fontsize=13)
plt.ylabel(&#39;收盘价&#39;, fontsize=13)
plt.xticks(rotation=45)
plt.show()

#绘制蜡烛图
matplotlib_date = mdates.date2num(Tencent2[&#39;日期&#39;])
ohlc = np.vstack((matplotlib_date,Tencent2[&#39;Open&#39;],Tencent2[&#39;High&#39;],Tencent2[&#39;Low&#39;],Tencent2[&#39;Close&#39;])).T
plt.figure(figsize=(15,6))
ax = plt.subplot()
candlestick_ohlc(ax,ohlc,width=0.8,colorup=&#39;g&#39;,colordown=&#39;r&#39;)
ax.xaxis_date()
plt.title(&#39;收盘价变动&#39;)
plt.xlabel(&#39;日期&#39;)
plt.ylabel(&#39;收盘价&#39;)
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

#重置索引
Tencent2.set_index(&#39;Date&#39;, inplace=True)

#创建一个只有“Close”列的新数据框
data =腾讯2.filter([&#39;Close&#39;])

#将数据框转换为numpy数组
dataset = data.values
#获取训练模型的行数
training_data = math.ceil( len(dataset) * 0.7 )

#缩放数据
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)

#创建训练数据集
#创建缩放后的训练数据集
train_data = scaled_data[0:training_data, :]
#将数据拆分为x_train和y_train数据集
x_train = []
y_train = []
#我们创建一个循环
for i in range(60, len(train_data)):
x_train.append(train_data[i-60:i, 0]) 
y_train.append(train_data[i, 0]) 
if i &lt;= 60:
print(x_train)
print(y_train)
print()

#将 x_train 和 y_train 转换为 numpy 数组
x_train, y_train = np.array(x_train), np.array(y_train)

#重塑数据
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
x_train.shape

#构建 LSTM 模型
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(25))
model.add(Dense(1))

#编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

#训练模型
model.fit(x_train, y_train, batch_size=1, epochs=1)

#创建测试数据集
#创建一个包含从索引 1738 到 2247 的缩放值的新数组
test_data = scaled_data[training_data - 60:]
#创建数据集 X_test 和 y_test
X_test = []
y_test = dataset[training_data:, :]
for i in range(60, len(test_data)):
X_test.append(test_data[i-60:i, 0])

#将数据转换为 numpy 数组
X_test = np.array(X_test)

#重塑数据
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

#获取模型对 X_test 数据集的预测价格值
predictions = model.predict(X_test)
predictions = scaler.inverse_transform(predictions)

#评估模型（获取均方根误差 (RMSE)）
rmse = np.sqrt( np.mean( predictions - y_test )**2 )

#绘制数据
train = data[:training_data]
valid = data[training_data:]
valid[&#39;Predictions&#39;] = predictions
#可视化数据
plt.figure(figsize=(16,8))
plt.title(&#39;Model&#39;)
plt.xlabel(&#39;Date&#39;, fontsize=18)
plt.ylabel(&#39;Close Price&#39;, fontsize=18)
plt.plot(train[&#39;Close&#39;])
plt.plot(valid[[&#39;Close&#39;, &#39;Predictions&#39;]])
plt.legend([&#39;Train&#39;, &#39;Validation&#39;, &#39;Predictions&#39;], loc=&#39;lower right&#39;)
plt.show()


我想预测未来 60 天的价格，但价格是过去预测的。我该如何预测 2024-06 之后的价格？
感谢您的帮助。
我的示例数据是
]]></description>
      <guid>https://stackoverflow.com/questions/78665213/i-want-to-predict-stock-price-in-next-60-days-by-machine-learning</guid>
      <pubDate>Tue, 25 Jun 2024 02:51:50 GMT</pubDate>
    </item>
    <item>
      <title>对包含姓名、电子邮件、地址、出生日期、电话号码和一些二进制标志的数据库进行重复数据删除的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/78664960/best-way-to-deduplicate-a-database-which-has-name-email-address-dob-phone-nu</link>
      <description><![CDATA[我有一个数据库，其中有重复的记录（同一个客户创建了多个帐户）。它们的唯一标识符列值对于每个 NameID 都不同，但其他信息可能相同。
例如，有一个名叫 Mark 的人。他创建了两个来宾用户：
来宾用户 1：
姓名 ID= 12345
姓名 = Mark Thomas
IsOnlineshopper = 1
Isinstoreshopper = 0
出生日期 = 01/12/1998
电子邮件 = mark.thomas@hotmail.com
地址 = # 12 Bailey Street, New Jersey, USA
电话 =03248923423

来宾用户 2：
姓名 ID= 56789
姓名 = Mark Thomas
IsOnlineshopper = 0
Isinstoreshopper = 1
出生日期 = 01/12/1998
电子邮件 = mark.thomas@hotmail.com
地址 = # 12 Bailey Street, New Jersey, USA
电话 =03248923423

现在，这是其中一个场景&#39;IsOnlineshopper&#39; 和 &#39;Isinstoreshopper&#39; 不同，但其他所有参数都相同。可能会出现用户输入错误的电话号码而其他所有参数都相同的情况。有很多种情况，但我想从最简单的一种开始，即所有字段都匹配。
我的目标是实现：
NameID 100% 匹配，并根据以下算法将它们列为重复项（通过公共 ID 将所有匹配项链接在一起）：

如果名称匹配，则 100% 进入下一步，否则不匹配。
如果电子邮件匹配，则 100% 进入下一步，否则不匹配。
如果电话号码匹配，则 100% 进入下一步，否则不匹配。
如果地址匹配，则 100% 进入下一步，否则不匹配。
如果地址出生日期匹配，则 100% 进入下一步，否则不匹配。
根据以下优先级标记为主要和重复项



NameID 具有IsOnlineshopper 应标记为主要。
具有 Isinstoreshopper 的 NameID 应标记为重复。


在匹配和合并这些名称一次（清除系统）后，我想自动化该过程，但每天运行该过程，将所有传入的记录（重复）与主要名称合并。
我在 Azure SQL 中有数据，我可以选择使用 Databricks（考虑到数据量巨大，可能需要更多的计算能力）。我已经创建了主数据集的一个子集进行测试。但我不确定应该使用什么方法进行重复数据删除。
我做了一些研究，看起来机器学习可以用于这种情况。我也在考虑在 pyspark 中对此进行硬编码。但正如我提到的，我不确定哪种方法最好。
请分享您的想法。谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78664960/best-way-to-deduplicate-a-database-which-has-name-email-address-dob-phone-nu</guid>
      <pubDate>Tue, 25 Jun 2024 00:17:16 GMT</pubDate>
    </item>
    <item>
      <title>使用不同的总 epoch 数，对同一 epoch 得出不同的结果</title>
      <link>https://stackoverflow.com/questions/78664794/different-results-for-the-same-epoch-using-different-number-of-total-epochs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78664794/different-results-for-the-same-epoch-using-different-number-of-total-epochs</guid>
      <pubDate>Mon, 24 Jun 2024 22:35:04 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 中的自定义评分功能无法按预期工作？</title>
      <link>https://stackoverflow.com/questions/78664597/custom-scoring-function-in-sklearn-does-not-work-as-intended</link>
      <description><![CDATA[大家好，我目前正在使用来自 kaggle 的葡萄酒质量数据集深入研究机器学习领域。
我查看了我的数据，识别并限制了异常值，缩放了数据，对其使用了 smote（因为有 100 种好葡萄酒和 900 种坏葡萄酒）
我发现 f2_score 最适合对我的模型的质量进行分类。
这些是我的 f2_score 函数和打印结果：
from sklearn.metrics import classes_report, confusion_matrix,precision_score, recall_score

def f2_score(y, y_pred, pos_label=1):
precision = precision_score(y, y_pred, pos_label=1)
recall = recall_score(y, y_pred, pos_label=1)
f2 = (5 * precision * recall) / (4 * 精度 + 召回率)
return f2

def print_results(y, y_pred):
print(&#39;__________________________________________________________________________________&#39;)
print(&#39;&#39;)
# 创建和导出分类报告
report = 分类报告(y, y_pred, zero_division=1)
print(&quot;分类报告:&quot;)
print(&#39;F2_Score:&#39;,f2_score(y,y_pred))
print(&#39;__________________________________________________________________________________&#39;)
print(report)

# 发现混淆矩阵
conf_matrix = 混淆矩阵(y, y_pred)

# 创建和导出图表
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix,
annot=True,
fmt=&#39;d&#39;,
cmap=&#39;Blues&#39;,
xticklabels=[&#39;Schlecht&#39;, &#39;Gut&#39;],
yticklabels=[&#39;Schlecht&#39;, &#39;Gut&#39;]
)

plt.xlabel(&#39;Vorhergesagte Labels&#39;)
plt.ylabel(&#39;Wahre Labels&#39;)
plt.title(&#39;Konfusionsmatrix&#39;)
plt.show()
print(conf_matrix)
print(&#39;__________________________________________________________________________________&#39;)

def print_best_score_and_params(model):
print(&#39;Best score: &#39; + str(model.best_score_))
print(&#39;Best params: &#39; + str(model.best_params_))

使用 SVC 的标准参数时，我已经获得了良好的结果：
来自 sklearn.svm导入 SVC
从 sklearn.metrics 导入 accuracy_score、f1_score、recall_score

svc = SVC(random_state=11, C = 1, gamma = &#39;scale&#39;) # C = 190 下一个更准确的结果 // 标准参数：C=1，gamma=&#39;scale&#39;

svc.fit(X_smote, y_smote)

y_pred = svc.predict(X_test)

print_and_write_results(0, y_test, y_pred)


--&gt; F2_Score：0.7196969696969696
但是，如果我现在尝试使用 RandomizedSearchCV 或 GridSearchCV，我总是会得到更差的分数，并且它不会搜索具有最高 f2_score 的选项。
甚至在调试几个小时后，我也不知道为什么。
来自 sklearn.metrics 导入 make_scorer，recall_score
来自 sklearn.model_selection 导入 KFold
来自 sklearn.model_selection 导入 RandomizedSearchCV

search_distribution = {&#39;C&#39;：[1,2,5,10,15,20]
}

scorer = make_scorer(f2_score, pos_label=1) # 创建一个基于召回率指标的 1 级评分器优化

kfold = KFold(n_splits=3, random_state=42, shuffle=True)

svc_search = RandomizedSearchCV(svc, search_distribution, random_state = 11, n_iter = 6,scoring = scorer, cv=kfold)

svc_search.fit(X_smote, y_smote)

print_best_score_and_params(svc_search)

print(&#39;最佳得分：&#39;, svc_search.best_score_)

y_pred = svc_search.predict(X_test)

print_and_write_results(0, y_test, y_pred)

使用仅具有不同 C 参数的随机搜索
我总是得到这样的结果：
最佳得分： 0.9587991499630526
最佳参数：{&#39;C&#39;: 20}
最佳得分：0.9587991499630526

分类报告：
F2_Score：0.6995884773662552
RandomizedSearchCV 使用的得分与我给出的 f2 得分无关，因此我无法使用 random_search 或 grid_search 来查找最佳参数？
您知道为什么得分与 f2 得分如此不同吗？
我尝试使用 f2_score 作为最佳拟合参数的指标。我认为 best_score 和 f2 得分相同？
我真的不知道这个超过 0.95 的值在哪里来自？]]></description>
      <guid>https://stackoverflow.com/questions/78664597/custom-scoring-function-in-sklearn-does-not-work-as-intended</guid>
      <pubDate>Mon, 24 Jun 2024 21:10:54 GMT</pubDate>
    </item>
    <item>
      <title>担任数据科学家需要具备哪些必备技能或知识？哪些技能或知识能让应届毕业生更有价值？[关闭]</title>
      <link>https://stackoverflow.com/questions/78664514/what-are-all-the-mandatory-skills-or-knowledge-one-should-have-for-data-scientis</link>
      <description><![CDATA[我最近刚获得电子与通信工程 (ECE) 硕士学位，我渴望转型从事数据科学职业。我的背景包括数学概念、编程（主要是 Python）方面的坚实基础。我对利用数据来获得有意义的见解和解决复杂问题有着浓厚的兴趣。
鉴于我的技术背景，我渴望了解数据科学家角色所必需的基本技能和知识。根据您的经验，雇主在数据科学家身上寻找的关键能力是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78664514/what-are-all-the-mandatory-skills-or-knowledge-one-should-have-for-data-scientis</guid>
      <pubDate>Mon, 24 Jun 2024 20:36:16 GMT</pubDate>
    </item>
    <item>
      <title>单头 Transformer 模型，输出和目标张量大小不匹配</title>
      <link>https://stackoverflow.com/questions/78663722/single-headed-transformer-model-output-and-target-tensor-sizes-dont-match</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78663722/single-headed-transformer-model-output-and-target-tensor-sizes-dont-match</guid>
      <pubDate>Mon, 24 Jun 2024 16:50:02 GMT</pubDate>
    </item>
    <item>
      <title>U-Net 无法过度拟合单个训练示例 - 损失平台</title>
      <link>https://stackoverflow.com/questions/78642145/u-net-unable-to-overfit-single-training-example-loss-plateaus</link>
      <description><![CDATA[我正在通过在由单个训练示例（图像到图像）组成的“数据集”上训练 U-Net 架构来测试它。输入图像是输出图像的噪声版本。最初，输出图像开始看起来更像所需的输出，但损失曲线开始趋于稳定，模型停止改进。
我的问题是：

U-Net（或任何没有完全连接层的 CNN）是否应该能够在给定单个示例的情况下在恒定图像上过度拟合？
如果它不能完成这个简单的任务，会犯什么常见错误或需要注意什么？

我通过将深度降低到几乎双卷积层（没有任何编码器/解码器层）来简化架构，并调整了学习率，但它仍然不会过度拟合。我期望模型在单个训练示例上完美地过度拟合，但事实并非如此。我已经调整了学习率，但模型仍然无法在这个简单的任务上实现完美的过度拟合。
输入图像：

地面实况：

达到平台期后的模型输出：


以下是我的实验的具体内容：
架构（深度 1）：
UNet(
（编码器）： ModuleList(
(0): Sequential(
(0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU(inplace=True)
(2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(3): ReLU(inplace=True)
)
)
(解码器): ModuleList(
(0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))
(1): Sequential(
(0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
(1): ReLU（就位=True）
（2）：Conv2d（64，64，kernel_size=（3，3），stride=（1，1），padding=（1，1））
（3）：ReLU（就位=True）
）
）
（池）：MaxPool2d（kernel_size=2，stride=2，padding=0，dilation=1，ceil_mode=False）
（瓶颈）：Sequential（
（0）：Conv2d（64，128，kernel_size=（3，3），stride=（1，1），padding=（1，1））
（1）：ReLU（就位=True）
（2）：Conv2d（128，128，kernel_size=（3，3），stride=（1，1），padding=（1，1））
（3）：ReLU（就位=True）
)
(out_conv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
)

初始化：凯明法线
 def _initialize_weights(self) -&gt; None:
for m in self.modules():
if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):
nn.init.kaiming_normal_(m.weight, mode=&#39;fan_in&#39;, nonlinearity=&#39;relu&#39;)
if m.bias is not None:
nn.init.constant_(m.bias, 0)

上采样方法：裁剪和连接
 def crop_and_concat(self, upsampled: torch.Tensor,
passive: torch.Tensor) -&gt; torch.Tensor:
diffY =pass.size()[2] - upsampled.size()[2]
diffX =pass.size()[3] - upsampled.size()[3]
upsampled = F.pad(upsampled, (diffX // 2, diffX - diffX // 2,
diffY // 2, diffY - diffY // 2))
return torch.cat((upsampled,bypass), dim=1)

损失：MSELoss
优化器：Adam，学习率从 1e-3 到 1e-4（上面的一切都在振荡，下面的也达到了稳定状态并且收敛速度较慢）]]></description>
      <guid>https://stackoverflow.com/questions/78642145/u-net-unable-to-overfit-single-training-example-loss-plateaus</guid>
      <pubDate>Wed, 19 Jun 2024 11:09:33 GMT</pubDate>
    </item>
    </channel>
</rss>