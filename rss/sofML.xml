<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 17 Dec 2024 21:15:09 GMT</lastBuildDate>
    <item>
      <title>如果原始训练数据是离散的，是否可以将数据添加到连续的 keras 模型？</title>
      <link>https://stackoverflow.com/questions/79289159/is-it-possible-to-add-data-to-a-keras-model-that-is-continous-if-the-original-tr</link>
      <description><![CDATA[我有一个模型 keras 模型，该模型是在离散数据（基于生物体中基因的存在而得出的是/否数据）上进行训练的，这可以预测离散响应（生物体是否执行某种功能而得出的是/否）。
我们想要添加连续的新数据（生物体中蛋白质的丰度），现在我们想要预测连续响应（某种功能的活动水平）。
这有可能做到吗？我已按照此链接中的步骤进行操作，但似乎假设您使用的是相同类型的数据。我该如何添加不同类型的数据？]]></description>
      <guid>https://stackoverflow.com/questions/79289159/is-it-possible-to-add-data-to-a-keras-model-that-is-continous-if-the-original-tr</guid>
      <pubDate>Tue, 17 Dec 2024 19:32:07 GMT</pubDate>
    </item>
    <item>
      <title>图像预处理步骤[关闭]</title>
      <link>https://stackoverflow.com/questions/79288818/image-preprocessing-steps</link>
      <description><![CDATA[我想知道 Keras 图像数据加载是否对图像数据集进行了完整的预处理，例如应用过滤器、规范化、标准化等，之后该模块不需要进行更详细的预处理还是怎样？
代码如下。
malimg=tf.keras.utils.image_dataset_from_directory(
r&quot;C:\Users\PMYLS\Desktop\Malware Pycharm Project\malimg_paper_dataset_imgs&quot;,
labels=&quot;inferred&quot;,
label_mode=&quot;int&quot;,
class_names=None,
color_mode=&quot;rgb&quot;,
batch_size=64,
image_size=(256, 256),
shuffle=True,
seed=None,
validation_split=None,
subset=None,
interpolation=&quot;bilinear&quot;,
follow_links=False,
crop_to_aspect_ratio=False,
pad_to_aspect_ratio=False,
data_format=None,
verbose=True,
)
class_names = malimg.class_names # 获取类名
print(&quot;Classes:&quot;, class_names)
]]></description>
      <guid>https://stackoverflow.com/questions/79288818/image-preprocessing-steps</guid>
      <pubDate>Tue, 17 Dec 2024 17:17:21 GMT</pubDate>
    </item>
    <item>
      <title>在 Google Cloud Functions 中部署 Keras 模型进行预测</title>
      <link>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</link>
      <description><![CDATA[我一直在尝试将一个非常简单的 Keras 玩具模型部署到 Cloud Functions，该模型可以预测图像的类别，但由于未知原因，当执行到 predict 方法时，它会卡住，不会抛出任何错误，最终会超时。
import functions_framework
import io
import numpy as np
import tensorflow as tf

from tensorflow.keras.models import load_model
from PIL import Image

model = load_model(&quot;gs://&lt;my-bucket&gt;/cifar10_model.keras&quot;)

class_names = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]

def preprocess_image(image_file):
img = Image.open(io.BytesIO(image_file.read()))
img = img.resize((32, 32))
img = np.array(img)
img = img / 255.0
img = img.reshape(1, 32, 32, 3)
return img

@functions_framework.http
def predict(request):
image = preprocess_image(request.files[&#39;image_file&#39;])
print(image.shape) # 这会打印 OK
prediction = model.predict(image)
print(prediction) # 永远不会打印
predict_class = class_names[np.argmax(prediction)]
return f&quot;Predicted class: {predicted_class}&quot;

本地调试运行良好，预测速度如预期一样快（模型权重文件为 2MB）。我还在此过程中添加了几个打印（从上面的代码片段中删除），执行工作正常，直到 predict 方法。
即使最小计算配置应该可以工作，我还是尝试保留更多内存和 CPU，但没有任何效果。该模型托管在存储中，我尝试先下载它，但也没有用。我也尝试在 tf.device(&#39;/cpu:0&#39;) 上下文中进行预测，传递 step=1 参数并首先将图像数组转换为 Keras 数据集，如 ChatGPT 所建议的那样，结果相同。实际上，调用 predict 根本没有打印任何内容。调用 call 而不是 predict 没有任何效果。
我错过了什么？]]></description>
      <guid>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</guid>
      <pubDate>Tue, 17 Dec 2024 13:51:16 GMT</pubDate>
    </item>
    <item>
      <title>Databricks MLFlow 和 MetaFlow 集成</title>
      <link>https://stackoverflow.com/questions/79287981/databricks-mlflow-and-metaflow-integration</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79287981/databricks-mlflow-and-metaflow-integration</guid>
      <pubDate>Tue, 17 Dec 2024 13:02:01 GMT</pubDate>
    </item>
    <item>
      <title>对于非常随机的文本语料库，哪些是最有效的主题建模算法？[关闭]</title>
      <link>https://stackoverflow.com/questions/79287858/which-are-the-most-effective-topic-modelling-algorithm-for-a-very-random-text-co</link>
      <description><![CDATA[没有关于语料库长度的信息。
没有关于任何主题层次结构的信息。
我遇到了 BERTopic，但它有 9 种不同的建模类型，哪一种应该适合？我不能使用监督或半监督，因为我没有关于数据的信息，我只知道它与 RFP（提案请求）相关。我可以预测一些主题，因此可以使用种子建模，但也会有随机主题。
我也对 LDA 等仅是句法的方法持开放态度，因为它给出了良好的结果。
我知道概括是不可能的，但想知道你的经验。
最初我尝试了 LDA，它没有给出好的结果，因为像数据长度和数据中的主题数量这样的超参数很难对如此大的完全非结构化随机数据集进行微调。]]></description>
      <guid>https://stackoverflow.com/questions/79287858/which-are-the-most-effective-topic-modelling-algorithm-for-a-very-random-text-co</guid>
      <pubDate>Tue, 17 Dec 2024 12:25:44 GMT</pubDate>
    </item>
    <item>
      <title>如何使用python的spaCy正确识别标记的实体类型？</title>
      <link>https://stackoverflow.com/questions/79287799/how-to-correctly-identify-entity-types-for-tokens-using-spacy-using-python</link>
      <description><![CDATA[我正在使用 spaCy 从文本描述中提取和识别实体类型（如 ORG、GPE、DATE 等）。但是，我注意到一些不正确的结果，我不确定如何修复它。
这是我使用的代码：
import spacy

nlp = spacy.load(&quot;en_core_web_sm&quot;)

def getPayeeName(description):
description = description.replace(&quot;-&quot;, &quot; &quot;).replace(&quot;/&quot;, &quot; &quot;).strip()
doc = nlp(description)

for token in doc:
print(f&quot;Token: {token.text}, Entity: {token.ent_type_ if token.ent_type_ else &#39;None&#39;}&quot;)

# 示例输入
description = &quot;UPI DR 400874707203 BENGALORE 08 JAN 2024 14:38:56 医疗有限公司 HDFC 50200&quot;
getPayeeName（说明）

令牌：UPI，实体：ORG
令牌：DR，实体：ORG
令牌：400874707203，实体：无
令牌：BENGALORE，实体：无
令牌：08，实体：DATE
令牌：JAN，实体：DATE
令牌：2024，实体：DATE
令牌：14:38:56，实体：无
令牌：MEDICAL，实体：ORG
令牌：LTD，实体：ORG
令牌：HDFC，实体：ORG
令牌：50200，实体： ORG

50200 被识别为 ORG，但它只是一个数字。

BENGALORE 是一个城市，但它未被识别为 GPE 或位置
（返回 None）。

UPI 和 DR 是首字母缩略词/缩写，但它们被错误地
识别为 ORG。


我希望实体识别更加准确和可靠。
我该如何解决这些问题？是否有其他 spaCy 配置、自定义规则或预训练模型可用于改进实体识别？
注意：我也尝试了 ChatGPT，但这个问题仍然没有解决。]]></description>
      <guid>https://stackoverflow.com/questions/79287799/how-to-correctly-identify-entity-types-for-tokens-using-spacy-using-python</guid>
      <pubDate>Tue, 17 Dec 2024 12:09:49 GMT</pubDate>
    </item>
    <item>
      <title>如何确保 RStudio 使用我的一半内存？</title>
      <link>https://stackoverflow.com/questions/79287098/how-to-make-sure-that-rstudio-uses-half-of-my-memory</link>
      <description><![CDATA[我正在尝试使用 tidymodels 在 RStudio 上调整机器学习模型。
我有 Macbook Pro 2019

2.3 GHz 8 核 Intel Core i9，
32 GB 2667 MHz DDR4

对于调整 KNN 回归，它花费了 10 多个小时，我不明白为什么。以下是代码：
knn_model &lt;-
nearest_neighbor(neighbors = tune(), weight_func = tune(), dist_power = tune()) %&gt;%
set_engine(&#39;kknn&#39;) %&gt;%
set_mode(&#39;regression&#39;)

knn_grid &lt;-
grid_regular(
neighbours(),
weight_func(),
dist_power(),
levels = c(20, 5, 5)
)

knn_wf &lt;-
working() %&gt;%
add_model(knn_model) %&gt;%
add_formula(demande_energetique_projectee ~ .)

knn_res &lt;-
knn_wf %&gt;%
tune_grid(
resamples = folds,
grid = knn_grid,
metrics = metric_set(rmse)
)
knn_res

我检查了分配给 rstudio 的内存；它不超过 1.2Gb。但为什么呢？
为什么它没有使用所有内存来加快我的超参数调整速度？
经过一番研究，我在主文件夹中创建了 .Renviron 文件并将其放入
R_MAX_VSIZE=16Gb

并重新启动了 RStudio，但问题并未解决。
以下是有关会话的信息
R 版本 4.3.3 (2024-02-29)
平台：x86_64-apple-darwin20 (64 位)
运行于：macOS 15.1.1

问题：

如何加快超参数调整速度？
我们如何确保 RStudio 使用一半的内存而不是仍然阻塞最大 1.2Gb？
]]></description>
      <guid>https://stackoverflow.com/questions/79287098/how-to-make-sure-that-rstudio-uses-half-of-my-memory</guid>
      <pubDate>Tue, 17 Dec 2024 08:11:39 GMT</pubDate>
    </item>
    <item>
      <title>如何修复使用 Prompt Flow 时出现的“错误：pip 的依赖解析器当前未考虑已安装的所有软件包。”</title>
      <link>https://stackoverflow.com/questions/79286932/how-to-fix-error-pips-dependency-resolver-does-not-currently-take-into-accoun</link>
      <description><![CDATA[我制作了一个自定义映像，以在 Azure Ai Foundry 的 Prompt Flow（早期的 Ai Studio）上使用 python 的 3.10.1 版本。忽略错误，Flow 成功运行。

错误：pip 的依赖解析器当前未考虑已安装的所有软件包。此行为是以下依赖冲突的根源。mlflow 2.13.0 需要 protobuf&lt;5,&gt;=3.12.0，但您有不兼容的 protobuf 5.29.1。mlflow-skinny 2.13.0 需要 protobuf&lt;5,&gt;=3.12.0，但您有不兼容的 protobuf 5.29.1。

但是，我认为这会在最终的生产部署中造成麻烦。此外，我还检查了我的自定义图像上的 protobuf 版本，但版本号是 4.25.5，在这种情况下应该可以正常工作。下面是错误和 docker 容器的屏幕截图。

我在执行 find 部署时遇到的错误如下：

根据用于故障排除此错误的文档，错误为 ResourceNotReady。其中提到了 score.py 文件。我想知道什么是 score.py 文件，这个文件在部署时会自动生成吗？还是需要在自定义镜像时单独创建这个文件？最后我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79286932/how-to-fix-error-pips-dependency-resolver-does-not-currently-take-into-accoun</guid>
      <pubDate>Tue, 17 Dec 2024 07:12:40 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 停留在图像生成上</title>
      <link>https://stackoverflow.com/questions/79283140/lstm-stuck-on-image-generation</link>
      <description><![CDATA[我创建了一个 LSTM 来生成序列中的下一张图像（我知道 CNN 是用于图像生成的，但我需要整个图像，而不仅仅是提供给序列下一次迭代的过滤器）。所以我有一个数据集，它包含图像（电影中的帧），我创建了它的序列，就像 1 个场景包含例如。 n 个图像，我有 s 个序列长度，那么输入将是 image_1 到 image_s，输出是 image_s+1，下一个输入是 image_2 到 image_s+1，输出是 image_s+2，依此类推。
模型如下：
class LSTM(nn.Module):
def __init__(self, input_len, hidden_​​size, num_layers):
super(LSTM, self).__init__()
self.hidden_​​size = hidden_​​size
self.num_layers = num_layers
self.lstm = nn.LSTM(input_len, hidden_​​size, num_layers, batch_first=True)
self.output_layer = nn.Linear(hidden_​​size, input_len)
self.dropout = nn.Dropout(.2)

def forward(self, X):
hidden_​​states = torch.zeros(self.num_layers, X.size(0), self.hidden_​​size, device=device)
cell_states = torch.zeros(self.num_layers, X.size(0), self.hidden_​​size, device=device)
out, _ = self.lstm(X, (hidden_​​states, cell_states))
out = self.dropout(out)
out = self.output_layer(out[:, -1, :])
return out

训练是：
def train(num_epochs, model, loss_func, optimizer):
total_steps = loader.getSizeWithBatch()

for epoch in range(num_epochs):
loader.reset()
for item in range(total_steps-1):
element = loader.next()[0]
x_images,y_image = element
x_images = x_images.reshape(-1,sequence_len,input_len)
output = model(x_images)
y_image = y_image.reshape(-1,input_len)
loss = loss_func(output, y_image)

optimizer.zero_grad()
loss.backward()
optimizer.step()

if (item + 1) % 1 == 0:
print(f&#39;Epoch: {epoch + 1};批次：{item + 1} / {total_steps};损失：{loss.item():&gt;4f}&#39;)

if (epoch + 1) % int(config[&#39;SAVE&#39;][&#39;model_save_interval&#39;]) == 0:
if (epoch + 1) % int(config[&#39;SAVE&#39;][&#39;clean_save_interval&#39;]) == 0:
torch.save(model.state_dict(), os.path.join(config[&#39;PATH&#39;][&#39;model_path&#39;], config[&#39;PATH&#39;][&#39;model_name&#39;] + str(epoch+1)))
else:
torch.save(model.state_dict(), os.path.join(config[&#39;PATH&#39;][&#39;model_path&#39;], config[&#39;PATH&#39;][&#39;model_name&#39;]))

Loader 以张量的形式引导图像由于内存使用，从文件中预先排序。
我使用 MSE 损失和 Adam 作为优化器。
问题是，当我训练它时，错误达到 0.003，这是目标，因为我通过将它们除以 255 来规范化值，但是当我预测时，它会产生一种模糊的场景图像，并且无论输入如何，预测图像始终相同，即使输入来自其他场景，它也会创建相同的图像，当我减去不同输出图像的颜色值时，该值为 0，因此每个输出图像都完全相同。
最终结果看起来就像我将数据集中的每个图像都作为层放在一起一样
我尝试添加 Droput，增加隐藏大小的神经元（现在是 128），尝试增加层数，不同的时期会创建相同的图像，只是模糊程度略低一些，但效果是一样的，我将学习率从 .001 降低到 .0001，效果都是一样的]]></description>
      <guid>https://stackoverflow.com/questions/79283140/lstm-stuck-on-image-generation</guid>
      <pubDate>Sun, 15 Dec 2024 20:28:51 GMT</pubDate>
    </item>
    <item>
      <title>获取“TypeError：ufunc‘isnan’不支持输入类型”</title>
      <link>https://stackoverflow.com/questions/79281350/getting-typeerror-ufunc-isnan-not-supported-for-the-input-types</link>
      <description><![CDATA[我正在做一个机器学习项目，在 Jupyter Notebook 上预测电动汽车的价格。
我运行这些单元：
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
cols = [&#39;County&#39;, &#39;City&#39;, &#39;State&#39;, &#39;ZIP Code&#39;, &#39;Model Year&#39;, &#39;Make&#39;, &#39;Model&#39;, &#39;Electric Vehicle Type&#39;, &#39;Clean Alternative Fuel Vehicle (CAFV) Eligibility&#39;]
for col in cols:
le.fit(t[col])
x[col] = le.transform(x[col]) 
print(le.classes_)

from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.5，random_state = 0)

r2_score(y_test，lm.predict(x_test))

从 sklearn.tree 导入 DecisionTreeRegressor 
regressor = DecisionTreeRegressor(random_state = 0) 
regressor.fit(x_train，y_train)
r2_score(y_test，regressor.predict(x_test))

r2_score(y_train，regressor.predict(x_train))

uv = np.nanpercentile(df2[&#39;Base MSRP&#39;]，[99])[0]*2

df2[&#39;Base MSRP&#39;][(df2[&#39;Base MSRP&#39;]&gt;uv)] = uv

df2 = df2[df2[&#39;Model Year&#39;] != &#39;N/&#39;] # 过滤掉包含 &#39;Model Year&#39; 的行&#39;N/&#39;

for col in cols:
df2[col] = df2[col].replace(&#39;N/&#39;, -1)
le.fit(df2[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

le = preprocessing.LabelEncoder()

cols = [&#39;County&#39;, &#39;City&#39;, &#39;State&#39;, &#39;ZIP Code&#39;, &#39;Model Year&#39;, &#39;Make&#39;, &#39;Model&#39;, &#39;Electric Vehicle Type&#39;, &#39;Clean Alternative Fuel Vehicle (CAFV) Eligibility&#39;]

for col in cols:
le.fit(t[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

我收到此错误：
TypeError回溯（最近一次调用最后一次）
~\AppData\Local\Temp\ipykernel_16424\1094749331.py in &lt;module&gt;
1 for col in cols:
2 le.fit(t[col])
----&gt; 3 df2[col] = le.transform(df2[col])
4 print(le.classes_)

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\preprocessing\_label.py in transform(self, y)
136 return np.array([])
137 
--&gt; 138 返回 _encode(y, uniques=self.classes_)
139 
140 def inverse_transform(self, y):

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\_encode.py in _encode(values, uniques, check_unknown)
185 else:
186 if check_unknown:
--&gt; 187 diff = _check_unknown(values, uniques)
188 if diff:
189 raise ValueError(f&quot;y 包含之前未见过的标签：{str(diff)}&quot;)

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\_encode.py in _check_unknown(values, known_values, return_mask)
259 
260 # 检查 known_values 中的 nans
--&gt; 261 if np.isnan(known_values).any():
262 diff_is_nan = np.isnan(diff)
263 if diff_is_nan.any():

TypeError: ufunc &#39;isnan&#39; 不支持输入类型，并且根据转换规则 &#39;&#39;safe&#39;&#39;，无法将输入安全地强制转换为任何受支持的类型

我尝试了什么？
我尝试使用以下代码：
le = preprocessing.LabelEncoder()
cols = [&#39;County&#39;, &#39;City&#39;, &#39;State&#39;, &#39;ZIP Code&#39;, &#39;Model Year&#39;, &#39;Make&#39;, &#39;Model&#39;, &#39;Electric Vehicle Type&#39;, &#39;Clean Alternative Fuel Vehicle (CAFV) Eligibility&#39;]
for col in cols:
le.fit(t[col])
df2[col] = le.transform(df2[col]) 
print(le.classes_)

代码给出了具体的错误。
为了解决这个问题，我尝试使用以下代码来插入缺失值（“N/”）而不是删除它：
for col in cols:
le.fit(t[col].fillna(&#39;Missing&#39;)) # 使用“Missing”插入缺失值
df2[col] = le.transform(df2[col].fillna(&#39;Missing&#39;))
print(le.classes_)

但我仍然收到相同的错误。
这是我的笔记本的链接：https://github.com/SteveAustin583/electric-vehicle-price-prediction-revengers/blob/main/revengers.ipynb
以下是数据集的链接：
https://www.kaggle.com/datasets/rithurajnambiar/electric-vehicle-data
如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79281350/getting-typeerror-ufunc-isnan-not-supported-for-the-input-types</guid>
      <pubDate>Sat, 14 Dec 2024 20:23:19 GMT</pubDate>
    </item>
    <item>
      <title>如何使用具有动态尺寸输入的 Dense 层？</title>
      <link>https://stackoverflow.com/questions/79280552/how-to-use-a-dense-layer-with-an-input-that-has-a-dynamically-sized-dimension</link>
      <description><![CDATA[我有一个模型，其输入（具有形状（高度、宽度、时间）的图像批次）具有动态大小的维度（时间），该维度仅在运行时确定。但是，Dense 层需要完全定义的空间维度。代码片段示例：
import tensorflow as tf
from tensorflow.keras.layers import Dense, Flatten, Input

# 定义具有未定义维度的输入（无）
input_tensor = Input(shape=(None, 256, 256, None, 13))

# 应用密集层（需要完全定义的形状）
x = Flatten()(input_tensor)
x = Dense(10)(x)

# 构建模型
model = tf.keras.models.Model(inputs=input_tensor, output=x)

model.summary()

这会引发错误：
ValueError：密集层输入的最后一个维度应已定义。未找到。

如何使用 Flatten 而不是 GlobalAveragePooling3D 等替代方案使其工作？本质上，我正在寻找一种方法来创建一个具有原始像素值的 1D 数组，但与 Dense 层兼容。]]></description>
      <guid>https://stackoverflow.com/questions/79280552/how-to-use-a-dense-layer-with-an-input-that-has-a-dynamically-sized-dimension</guid>
      <pubDate>Sat, 14 Dec 2024 11:31:35 GMT</pubDate>
    </item>
    <item>
      <title>处理 Llama 3.2：3b-Instruct 模型中的令牌限制问题（最多 2048 个令牌）[关闭]</title>
      <link>https://stackoverflow.com/questions/79267003/handling-token-limit-issues-in-llama-3-23b-instruct-model-2048-tokens-max</link>
      <description><![CDATA[我正在使用 Llama 3.2:3b-instruct 模型并遇到以下错误：
此模型的最大上下文长度为 2048 个令牌。但是，您请求了 
2049 个令牌（消息中 1681 个，完成中 368 个）。

我理解这是由于超出令牌限制造成的，但我想知道：

是否有任何最佳实践或技术可以减少令牌使用量，而不会丢失消息或完成中的关键上下文？
]]></description>
      <guid>https://stackoverflow.com/questions/79267003/handling-token-limit-issues-in-llama-3-23b-instruct-model-2048-tokens-max</guid>
      <pubDate>Tue, 10 Dec 2024 04:19:17 GMT</pubDate>
    </item>
    <item>
      <title>时间序列运动捕捉数据的 PCA 图聚类问题</title>
      <link>https://stackoverflow.com/questions/79263104/pca-plot-clustering-issue-with-time-series-motion-capture-data</link>
      <description><![CDATA[我正在使用 PCA 对手部动作捕捉数据的时间序列数据集进行降维，并遇到了意外的聚类行为。以下是我的过程和我面临的问题的详细信息。

上下文：
我有一个使用智能手套捕捉的手部动作记录数据集，每个手指上有 4 个传感器。每个传感器提供：

位置值：X、Y、Z
旋转值：X、Y、Z、W

数据记录在单独的文件中，每个文件包含 10 次手势重复。这些重复随后被分割成单独的文件（每个文件 1 个重复），贴上标签，并合并成一个大型数据集。
在对数据进行标签编码和缩放后，我使用以下代码应用 PCA 进行降维：
# PCA 用于降维
pca_components = 3
pca = PCA(n_components=pca_components)
x_train_pca = pca.fit_transform(x_train_scaled)

为了可视化结果，我创建了一个 PCA 摘要图，其中每个数据段都表示为一个点。目标是查看每个手势的 10 个点的聚类。以下是总结 PCA 结果的代码：
# 将 PCA 结果转换为 DataFrame 以关联标签
x_train_pca_df = pd.DataFrame(x_train_pca, columns=[&#39;PC1&#39;, &#39;PC2&#39;, &#39;PC3&#39;])
x_train_pca_df[&#39;label&#39;] = y_train_data
x_train_pca_df[&#39;segment&#39;] = train_data[&#39;segment&#39;].values.ravel()

# 计算每个数据集的 PC1 和 PC2 的平均值（将每个数据集总结为一个点）
summary_train_points = x_train_pca_df.groupby([&#39;label&#39;, &#39;segment&#39;]).mean().reset_index()

以下是我用来绘制总结 PCA 的方法数据：
def plot_3d_pca_matplotlib(summary_points, title=&#39;3D PCA Plot&#39;):
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111,projection=&#39;3d&#39;)

# 对于每个唯一数据集（标签），分散点并分配图例条目
unique_labels = summary_points[&#39;label&#39;].unique()

for label in unique_labels:
# 过滤当前标签的数据
filtered_data = summary_points[summary_points[&#39;label&#39;] == label]

# 当前标签点的散点图
ax.scatter(filtered_data[&#39;PC1&#39;],
filtered_data[&#39;PC2&#39;],
filtered_data[&#39;PC3&#39;],
label=label)

ax.set_xlabel(&#39;PCA 组件 1&#39;)
ax.set_ylabel(&#39;PCA 组件 2&#39;)
ax.set_zlabel(&#39;PCA 组件 3&#39;)
ax.set_title(title)
ax.legend(title=&quot;Labels&quot;, loc=&quot;center left&quot;, bbox_to_anchor=(1.05, 0.7))

plt.subplots_adjust(left=0.05, right=0.75)
plt.show()


问题：
当我为相同手势记录一组新数据并绘制 PCA 结果时，我希望看到每个手势有 20 个点（10 个来自原始数据的点 + 10 个来自新数据的点）的聚类。
相反，PCA 图显示每个手势有两个独立的 10 点簇。这表明，即使手势相同，新数据也未与 PCA 空间中的原始数据对齐。

问题：
什么原因导致相同手势被分离为不同的簇？
可能与以下情​​况有关：

缩放过程？
传感器校准不一致？
在应用 PCA 之前是否需要对齐或对数据进行额外的预处理？
]]></description>
      <guid>https://stackoverflow.com/questions/79263104/pca-plot-clustering-issue-with-time-series-motion-capture-data</guid>
      <pubDate>Sun, 08 Dec 2024 18:31:23 GMT</pubDate>
    </item>
    <item>
      <title>如何在 nltk 中下载 punkt tokenizer？</title>
      <link>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</link>
      <description><![CDATA[我使用 pip install nltk 安装了 NLTK 库
pip install nltk

在使用库时
from nltk.tokenize import sent_tokenize 
sent_tokenize(text)

我收到此错误
LookupError: 
**************************************************************************
未找到资源 punkt。
请使用 NLTK 下载器获取资源：

&gt;&gt;&gt; import nltk
&gt;&gt;&gt; nltk.download(&#39;punkt&#39;)

有关更多信息，请参阅：https://www.nltk.org/data.html

尝试加载 tokenizers/punkt/english.pickle

搜索位置：
- &#39;C:\\Users\\adars/nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\share\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Roaming\\nltk_data&#39;
- &#39;C:\\nltk_data&#39;
- &#39;D:\\nltk_data&#39;
- &#39;E:\\nltk_data&#39;
- &#39;&#39;

因此，为了解决此错误，我尝试了
import nltk
nltk.download(&#39;punkt&#39;)

但是我无法下载此包，因为每次运行此包时都会出现错误，提示
[nltk_data] 加载 punkt 时出错：&lt;urlopen 错误 [WinError 10060] A
[nltk_data] 连接尝试失败，因为连接方
[nltk_data] 在一段时间后未正确响应，或者
[nltk_data] 建立连接失败，因为连接的主机
[nltk_data] 未响应&gt;

请帮帮我]]></description>
      <guid>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</guid>
      <pubDate>Tue, 19 Sep 2023 04:36:59 GMT</pubDate>
    </item>
    <item>
      <title>分析客户支持单，了解产品缺陷/特点</title>
      <link>https://stackoverflow.com/questions/66428112/analyze-customer-support-tickets-to-understand-product-gaps-features</link>
      <description><![CDATA[我希望分析客户支持单，以了解产品差距/功能或我可以对产品进行哪些改进以解决客户痛点/问题。
但您知道，客户支持单中有很多文本/注释，这些文本/注释是由我们的支持代理通过电子邮件或电话收集的，并且从人的角度来说，不可能浏览所有单据并了解全局。
我正在从 Stack Overflow 上的开发人员那里寻求有关如何处理分析客户支持单以了解产品差距/功能或客户痛点的问题的想法。
您能给我指明正确的方向吗？我们可以使用 NLP 或任何其他 ML 概念来解决问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/66428112/analyze-customer-support-tickets-to-understand-product-gaps-features</guid>
      <pubDate>Mon, 01 Mar 2021 19:04:28 GMT</pubDate>
    </item>
    </channel>
</rss>