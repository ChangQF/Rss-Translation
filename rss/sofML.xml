<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 19 Apr 2024 15:14:25 GMT</lastBuildDate>
    <item>
      <title>使用 CNN 进行音频分类总是预测错误</title>
      <link>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</guid>
      <pubDate>Fri, 19 Apr 2024 13:39:10 GMT</pubDate>
    </item>
    <item>
      <title>尝试将自定义模型部署到 OpenSearch 中会引发 RuntimeError: KeyError: token_type_ids</title>
      <link>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</guid>
      <pubDate>Fri, 19 Apr 2024 13:36:18 GMT</pubDate>
    </item>
    <item>
      <title>获取边界框问题</title>
      <link>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</guid>
      <pubDate>Fri, 19 Apr 2024 12:40:40 GMT</pubDate>
    </item>
    <item>
      <title>梅尔频谱图的卷积自动编码器。不起作用</title>
      <link>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</link>
      <description><![CDATA[# 将列表转换为 numpy 数组
data_array = np.array(data_list, dtype=&#39;float32&#39;)
data_array = np.array(data_array, dtype=&#39;float32&#39;) / 255.0 # 所以我的数据是从0到1
导入操作系统
导入keras
将 numpy 导入为 np
将张量流导入为 tf
从张量流导入keras
从 keras.layers 导入输入、Conv2D、BatchNormalization、MaxPooling2D、UpSampling2D、Flatten、Dense、Reshape、Dropout
从 keras.models 导入模型
从 sklearn.model_selection 导入 train_test_split
#从keras.preprocessing.image导入img_to_array，load_img
从 sklearn.model_selection 导入 train_test_split
#from keras.callbacks 导入 LearningRateScheduler
从 sklearn.model_selection 导入 train_test_split
从 keras.callbacks 导入 TensorBoard
导入时间
从 keras 导入正则化器

train_images, test_images = train_test_split(data_array, test_size=0.1) # 10% 用于测试
train_images, val_images = train_test_split(train_images, test_size=0.1) # 其余的 10% 用于验证

print(f&#39;训练集大小：{train_images.shape}&#39;)
print(f&#39;验证集大小：{val_images.shape}&#39;)
print(f&#39;测试集大小：{test_images.shape}&#39;)

# 超参数正确或接近正确？参数以纸质为准。
H、W、C = 256, 256, 1 # 1 排列 np 黑白
学习率 = 1e-3
批量大小 = 16
纪元 = 50 #Random 纪元
Latent_dim = 128 # 理解

l2_reg = 正则化器.l2(1e-4)

输入=输入（形状=（H，W，C））
x = Conv2D(32, (5, 5), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(输入)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), padding=&#39;same&#39;)(x) #固定池化
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), 填充=&#39;相同&#39;)(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), 填充=&#39;相同&#39;)(x)

# X 是我最后一层的输出

# 关于 X\ 的瓶颈操作
瓶颈=展平()(x)
瓶颈=密集（latent_dim，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（bottleneck）#潜在空间（LS）
瓶颈 = Dropout(0.3)(bottleneck) # 应用 dropout 进行正则化
                                       #输出是瓶颈
#解码器
x = 密集（8* 8* 128，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（瓶颈）
x = 重塑((8, 8, 128))(x)
x = 上采样2D((2, 2))(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(32, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
#填充？
#x = ZeroPadding2D(padding=((2, 2), (14, 14)))(x) # 大小要求？
# 最终重建
outputs = Conv2D(1, (5, 5), activate=&#39;sigmoid&#39;, padding=&#39;same&#39;, kernel_regularizer=l2_reg)(x) # 修改 1 因为之前有一个 3 : 没有意义，为什么是 sigmoid
#Sigmoid = 0 到 1 之间的值
#或Relu


# 完整的自动编码器模型
自动编码器=模型（输入，输出）
autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;]) # 或 mse
 


# 模型架构
自动编码器.summary()
打印（train_images.shape，test_images.shape）

从 keras.callbacks 导入 EarlyStopping

#early_stopping = EarlyStopping（monitor=&#39;val_loss&#39;，耐心=5，restore_best_weights=True）
# train_images、val_images 在 CAE 开始时预加载

历史=自动编码器.fit(
    train_images, train_images, # 输入和目标
    纪元=纪元，
    批量大小=批量大小，
    洗牌=真，#真
    回调=[张量板],
    验证数据=（val_images，val_images），#validation_data=（val_images，val_images）
）
# 生成重建
rec_images = autoencoder.predict(val_images)[[在此处输入图像描述](https://i.stack.imgur.com/4g01e.png)](https://i.stack.imgur.com/trl9d.png)

我有 2550 个 2 秒的音频文件，我应用了 Mel 扫描图，仅使用 np 数组数据，我为我的 CAE 提供了这些尺寸 2562561。我已经应用了早期停止、主动学习和调节 L2 来提高我的 NN 学习，但我不知道为什么它不起作用。我对 NN 没有太多的经验，我想了解我在 NN 上做错了什么。我将在此处附上代码和结果。如果您想分享您的类似经验和这些问题的解决方案，请提前致谢。 在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</guid>
      <pubDate>Fri, 19 Apr 2024 12:38:40 GMT</pubDate>
    </item>
    <item>
      <title>MLFlow UI 未加载 - 缺少静态内容</title>
      <link>https://stackoverflow.com/questions/78353335/mlflow-ui-not-loading-missing-static-content</link>
      <description><![CDATA[我已经使用 mlflow server ... 部署了 MLFlow 服务器。当访问其部署的 URL https://some.url 时，我会看到一个空白页面并且无法加载。奇怪的是，这在本地主机上不是本地问题。
调查浏览器的控制台，我发现静态 (.../mlflow/build) 文件出现一堆错误，给出 404。
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78353335/mlflow-ui-not-loading-missing-static-content</guid>
      <pubDate>Fri, 19 Apr 2024 11:28:16 GMT</pubDate>
    </item>
    <item>
      <title>如何从 LbfgsLogisticRegression 训练的模型中检索原始模型参数？</title>
      <link>https://stackoverflow.com/questions/78352598/how-can-i-retrieve-original-model-parameters-from-a-lbfgslogisticregression-trai</link>
      <description><![CDATA[我选择使用 LbfgsLogisticRegression，因为它是可重新训练的（可以在不丢失现有模型的情况下对更多数据进行训练）。 （链接)
我的第一批数据通过通常的 Fit 调用训练得很好：
var estimator = mlContext.Transforms.Concatenate(“Features”, nameof(SampleDataEntry.Features))
.Append(mlContext.BinaryClassification.Trainers.LbfgsLogisticRegression(labelColumnName: &quot;name_match&quot;, featureColumnName: nameof(SampleDataEntry.Features)));

但是，当涉及到重新训练时，我显然应该调用 Fit(IDataView, LinearModelParameters)。我有 IDataView，但正在努力获取 LinearModelParameters。 Microsoft 的文档提供了以下不同算法的代码示例：
//提取训练好的模型参数
线性回归模型参数 原始模型参数 =
    ((ISingleFeaturePredictionTransformer)trainedModel).Model 作为 LinearRegressionModelParameters;

但是，当我尝试调整它以检索我自己的模型参数时，我遇到了一系列转换失败。在监视模式下调查 model 对象，我发现它甚至没有代码示例中暗示的 Model 属性。它有一个 .LastTransformer 属性，该属性又包含 .Model。
.LastTransformer 具有类型
Microsoft.ML.Data.BinaryPredictionTransformer&gt;
.LastTransformer.Model 具有类型
Microsoft.ML.Calibrators.ParameterMishingCalibrateModelParameters
打开该模型，我们找到一个 .SubModel 属性，其类型为
Microsoft.ML.Trainers.LinearBinaryModelParameters
但是，如果我检索该组参数，它们不包含 label 字段等基本信息，因此重新训练失败。
任何人都可以向我指出代码示例/教程，或者解释我可以在哪里查找这些原始参数吗？
这是最后一段不起作用的代码：
LinearBinaryModelParameters 原始模型参数 = ((TransformerChain&gt;&gt;)model).LastTransformer.Model.SubModel as LinearBinaryModelParameters;
返回mlContext.BinaryClassification.Trainers.LbfgsLogisticRegression().Fit(splitTrainSet,originalModelParameters);
]]></description>
      <guid>https://stackoverflow.com/questions/78352598/how-can-i-retrieve-original-model-parameters-from-a-lbfgslogisticregression-trai</guid>
      <pubDate>Fri, 19 Apr 2024 09:12:03 GMT</pubDate>
    </item>
    <item>
      <title>自学pdf到数据转换器</title>
      <link>https://stackoverflow.com/questions/78352394/self-learning-pdf-to-data-converter</link>
      <description><![CDATA[以下是问题陈述 -
创建尖端、自学的智能 PDF 到数据转换器
目标：

生成式 AI 集成：利用生成式 AI 技术智能地解释和提取多页 PDF 文档中的数据（包括文本、表格和图形），并将其转换为结构化且可用的数据格式。&lt; /里&gt;
自学习能力：整合机器学习模型，使系统能够通过学习每个处理的文档来不断提高转换准确性。这包括理解各种文档布局并根据反馈纠正错误。
处理复杂文档：确保解决方案有效处理布局复杂的文档（例如科学论文、财务报告和法律文档），准确提取数据，同时保持上下文和结构。
效率和可扩展性：开发一种解决方案，不仅准确，而且处理时间高效，能够处理大量文档，并且可扩展以满足个人用户和大型组织的需求。&lt; /里&gt;
用户界面和体验：设计一个用户友好的界面，允许用户上传 PDF 文档、监控转换过程以及轻松编辑或纠正提取数据中的任何不准确之处。

可交付成果：

智能 PDF 到数据转换器的工作原型，展示了生成式 AI 和机器学习在数据提取方面的集成。
原型应有效处理不同类型的文档，例如商业文档（例如采购订单、提单、空运单、装箱单）、财务文档（例如各种布局的发票、付款通知书）和合规文档（例如，运输单、报关单）。
概述解决方案架构、所使用的生成式 AI 和机器学习模型以及用户说明的文档。
重点介绍原型的功能、所解决的挑战以及对数据提取过程的潜在影响的演示。

目前是否有任何模型/变压器或任何工作可以用来解决这个问题以及如何解决这个问题陈述。还有我可以使用的这个问题陈述的任何数据集吗？]]></description>
      <guid>https://stackoverflow.com/questions/78352394/self-learning-pdf-to-data-converter</guid>
      <pubDate>Fri, 19 Apr 2024 08:39:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 Raspberry Pi 4 时 Python 中的多线程崩溃</title>
      <link>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</link>
      <description><![CDATA[我在尝试使用 Raspberry Pi 4B 完成大学项目时遇到问题。
该项目使用 Python 编写，由 5 个线程组成，其中 2 个线程运行机器学习预测，第 3 个线程按顺序运行一系列计算，以达到与机器学习模型预测的输出相同的输出（这样我可以对比输出是否是合理的值）。另外两个线程是：一个等待 10 秒并激活一个标志（开始处理所需的标志），另一个在终端上打印值（都是从 ML 模型和计算中预测的）。
我的问题是，当我尝试同时运行所有线程时，ML 模型运行正确，但我的计算线程不执行任何操作。相反，如果我不启动 ML 线程，计算线程就会正常工作。
我认为Raspberry没有足够的计算能力，因此计算线程崩溃了。
没有必要所有 3 个线程同时运行（我希望能够选择是否要查看终端上打印的 ML 预测或计算输出），因此我尝试禁用线程当我不使用它们时（使用 thread.join() ）并在我决定希望该线程再次开始运行时再次启动它们（thread.start() ）但它无法正常工作。
我还尝试过使用运行预测或计算函数所需的两个标志（ML_flag 和calculations_flag），但也不起作用。
关于我可以使用的其他技术的任何想法，以便 ML 预测和计算单独运行并且不会崩溃？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</guid>
      <pubDate>Fri, 19 Apr 2024 08:31:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用已经制作的嵌入来制作索引</title>
      <link>https://stackoverflow.com/questions/78351643/how-to-make-indexes-using-already-made-embeddings</link>
      <description><![CDATA[我是机器学习新手。我想使用 llama_index。我有嵌入。如何使用这些嵌入创建索引？我正在使用huggingface微调法学硕士。如果我理解有误，请纠正我。]]></description>
      <guid>https://stackoverflow.com/questions/78351643/how-to-make-indexes-using-already-made-embeddings</guid>
      <pubDate>Fri, 19 Apr 2024 06:14:32 GMT</pubDate>
    </item>
    <item>
      <title>python - ImportError：无法从“dill._dill”导入名称“_is_imported_module”</title>
      <link>https://stackoverflow.com/questions/78351307/python-importerror-cannot-import-name-is-imported-module-from-dill-dill</link>
      <description><![CDATA[已安装的数据集打包到Python虚拟环境中。当我尝试导入它并运行时，
from datasets import load_dataset，我收到此错误，“ImportError：无法从 &#39;dill._dill&#39; 导入名称 &#39;_is_imported_module&#39;”，然后出现此错误，当我向下滚动时，“AttributeError：模块“dill”没有属性“_dill””。
完整的错误消息：
”\[自动重新加载 dill.session 失败：回溯（最近一次调用）：
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\IPython\\extensions\\autoreload.py”，第276行，检查
superreload(m, 重新加载, self.old_objects)
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\IPython\\extensions\\autoreload.py”，第 475 行，在超级重载中
模块=重新加载（模块）
^^^^^^^^^^^^^^^
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\importlib\__init_\_.py”，第 131 行，重新加载
\_bootstrap.\_exec(规范，模块)
文件“\”，第 866 行，位于 \_exec
文件“\”，第 995 行，位于 exec_module
文件“\”，第 488 行，位于 \_call_with_frames_removed
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\dill\\session.py”，第 24 行，位于 \ 中
从 .\_dill 导入 (
ImportError：无法从“dill.\_dill”导入名称“\_is_imported_module”（C：\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\dill_dill.py）
\]
\[自动重新加载 dill.\_shims 失败：回溯（最近一次调用最后一次）：
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\IPython\\extensions\\autoreload.py”，第276行，检查
superreload(m, 重新加载, self.old_objects)
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\IPython\\extensions\\autoreload.py”，第 500 行，在超级重载中
update_generic（旧的_obj，新的_obj）
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\IPython\\extensions\\autoreload.py”，第 397 行，位于 update_generic
更新（a，b）
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\IPython\\extensions\\autoreload.py”，第 365 行，在 update_class 中
update_instances（旧的，新的）
文件“C:\\Users\\joshu\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\IPython\\extensions\\autoreload.py”，第 323 行，位于 update_instances 中
对象.__setattr__（参考，“__class__”，新）
TypeError: __class__ 赋值: &#39;\_CallableReduce&#39; 对象布局与 &#39;\_CallableReduce&#39; 不同
\]
回溯（最近一次调用最后一次）：

compat_exec 中的文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\spyder_kernels\\py3compat.py:356
exec（代码、全局变量、局部变量）

文件 c:\\users\\joshu.spyder-py3\\temp.py:14
从数据集导入load_dataset

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\__init_\_.py:18
从 .arrow_dataset 导入数据集

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\arrow_dataset.py:68
从 .arrow_writer 导入 ArrowWriter，OptimizedTypedSequence

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\arrow_writer.py:29
从 .features 导入特征、图像、值

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\features\__init__\_.py:17
从.audio导入音频

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\features\\audio.py:11
从 ..download.streaming_download_manager 导入 xopen、xsplitext

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\download\__init__\_.py:9
从 .download_manager 导入 DownloadManager、DownloadMode

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\download\\download_manager.py:43
从 ..utils.py_utils 导入 NestedDataStructure、map_nested、size_str

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\utils\\py_utils.py:44
from .\_dill import ( # noqa: F401 # 为向后兼容而导入。 TODO: 在 3.0.0 中删除

文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\utils_dill.py:27
Pickler 类（莳萝.Pickler）：

Pickler 中的文件 \~\\anaconda3\\envs\\sentence_similarity\\Lib\\site-packages\\datasets\\utils_dill.py:28
调度 = dill.\_dill.MetaCatchingDict(dill.Pickler.dispatch.copy())

AttributeError: 模块“dill”没有属性“\_dill””

尝试重新安装并安装早期版本的 dill。那不起作用。此外，我有一个运行相同版本数据集的 jupyter 笔记本，并且我和 dill 没有遇到任何问题。]]></description>
      <guid>https://stackoverflow.com/questions/78351307/python-importerror-cannot-import-name-is-imported-module-from-dill-dill</guid>
      <pubDate>Fri, 19 Apr 2024 04:11:25 GMT</pubDate>
    </item>
    <item>
      <title>请为我的毕业设计解决机器学习中牙齿分割模型的Valueerror</title>
      <link>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</link>
      <description><![CDATA[这是牙齿分割模型的 GitHub 链接：https://github.com/Arnold0210/TEETH-RECOGNITION-WITH-MACHINE-LEARNING
大家好，我在 GitHub [HTTPs://github.com/] 上获取的模型中的 classification.py 中的代码遇到了一些问题。 com/Arnold0210/牙齿识别与机器学习]。如果有人有兴趣深入研究我的问题，该程序应该执行以下操作：
该程序应为用户提供两种选择：

从图像中读取并提取特征：此选项使用 FeatureExtraction 模块从图像中提取 9 个特征（包括图像名称）。
读取预先存在的数据集：此选项读取包含 labels.csv、features.csv 和图像文件的数据集。然后它会询问用户：

执行程序的次数（假设为 5）。
使用 K 折交叉验证分割数据所需的折叠数（假设为 5 折叠，即 k=5）。
测试数据集的大小（假设为 20%）。



模型然后将这些参数传递给classification模块中的分类函数。这就是问题出现的地方：

代码将整个数据集传递给 onlyfiles，其中包含 973 个条目。
然后，它会从 labels.csv（有 778 个条目）中识别 images_name 和 label_color。这代表训练数据集，因为我们之前指定了 20% 的测试集（778 = 973 的 80%）。
以下 for 循环迭代由 k_folds.split(images_name) 生成的分割。此时，我们仍在处理训练数据集，并且当 k=5 时，应该有：

train_index 中有 662 个索引（用于训练数据）。
test_index 中有 156 个索引（用于在训练集中进行验证）。



这是下一个 for 循环中发生错误的位置：
对于 train_index 中的 i：
    current_filename = onlyfiles[i].split(&#39;.&#39;)[0].strip()
    如果 current_filename 在训练数据集中：
        # ...（其余代码）
    别的：
        print(f“警告：在 images_name 中找不到‘{current_filename}’，因为它的索引是 {i}.train。”)


第一行根据 train_index 中的索引 i 检索文件名 (current_filename)。假设 i 为 324，train_index 包含从 156 到 777 的索引（而 test_index 范围从 0 到 155）。
出现此错误的原因是，有时循环会尝试在 images_name 中查找 current_filename，但该文件并不存在。这是因为 images_name 只有 778 个条目（训练数据），其余 195 个条目（测试数据）不包括在内。因此，current_filename 实际上可能属于测试数据集，从而导致错误“101_0032.JPG 不在列表中”。

我尝试对列表进行排序并删除随机播放（在 k_folds.split 中设置 shuffle=False），但错误仍然存​​在。我非常感谢您为解决此问题提供一些帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</guid>
      <pubDate>Thu, 18 Apr 2024 23:03:02 GMT</pubDate>
    </item>
    <item>
      <title>无论输入值如何，序数编码都会显示相同的值，从而使预测结果相同</title>
      <link>https://stackoverflow.com/questions/78343238/ordinal-encoding-keeps-showing-the-same-value-no-matter-the-input-value-thus-ma</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78343238/ordinal-encoding-keeps-showing-the-same-value-no-matter-the-input-value-thus-ma</guid>
      <pubDate>Wed, 17 Apr 2024 18:50:08 GMT</pubDate>
    </item>
    <item>
      <title>对于表格数据模型中的过度拟合我该怎么办</title>
      <link>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</link>
      <description><![CDATA[我建立了一个预测模型，用于根据所提供数据中的某些特征来预测结果。
该模型是一个利用 fastai 的表格学习器。
该数据集包含约 300 条记录，分为训练集、验证集和测试集。
我已经实现了解决过度拟合的技术，例如提前停止和权重衰减，但在对未见过的数据进行评估时，模型仍然似乎过度拟合。
此外，我还尝试调整学习率和批量大小等超参数，但没有改善。我怀疑我的模型架构或预处理管道的某些方面可能会导致该问题，但我不确定从哪里开始调查。
鉴于该项目的敏感性，我无法提供有关数据集或预测任务的具体细节，但我可以分享当前模型的预处理和结构。
这是训练的输出：

&lt;标题&gt;

纪元
train_loss
valid_loss
准确度
时间


&lt;正文&gt;

0
0.752707
0.579501
0.776119
00:00


1
0.699270
0.833771
0.776119
00:00


2
0.652438
0.598243
0.791045
00:00


3
0.621083
3.889398
0.776119
00:00


4
0.591348
0.632366
0.791045
00:00


5
0.580582
6.670314
0.791045
00:00



&lt;块引用&gt;
自 epoch 2 以来没有任何改进：提前停止

这是预处理的代码（在我构建了我不能透露的功能之后）。
features 列表定义每个特征，包括有效值范围和权重（feature、range_ 和 weight 如下面的标准化函数中所使用的那样）。
def custom_normalize(df, 特征, range_, 权重):
    df[特征] = 归一化(df[特征], range_)
    df[特征] = df[特征] * 权重
    返回df

分割 = RandomSplitter(valid_pct=0.2)(range_of(df))

procs = [分类，填充缺失]

对于功能，features.items() 中的信息：
    # 确定训练时选择值的范围。
    procs.append(partial(custom_normalize, feature=feature, range_=info[&#39;range&#39;],weight=info[&#39;weight&#39;]))

据我所知，构建模型和训练是非常标准的：
to = TabularPandas(df, procs=procs,
                   cat_names = cat_vars,
                   连续名称=连续变量，
                   y_names=dep_var,
                   分裂=分裂）

dls = to.dataloaders(bs=64)

Early_stop = EarlyStoppingCallback(监视器=&#39;准确度&#39;, min_delta=0.01, 耐心=3)

学习 = tabular_learner(dls, 指标=准确度, wd=0.1)
学习.lr_find()

# 绘制学习率。
learn.recorder.plot_lr_find()

# 根据情节选择学习率。
lr = learn.recorder.lrs[np.argmin(learn.recorder.losses)]

learn.fit_one_cycle(15, lr, cbs=early_stop)
学习.show_results()

# 如果模型不存在则只保存模型
# TODO 将保存包装在条件中，以防止模型存在时保存。
如果不是 os.path.exists(model_fname):
    学习.保存(model_fname)
]]></description>
      <guid>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</guid>
      <pubDate>Tue, 16 Apr 2024 08:38:01 GMT</pubDate>
    </item>
    <item>
      <title>如何将Yolo片段注释转换为coco格式？</title>
      <link>https://stackoverflow.com/questions/77364462/how-to-convert-yolo-segment-annotations-to-coco-format</link>
      <description><![CDATA[我正在尝试将 yolo 段数据集转换为 coco 格式。最初我使用 ultralytics 的 JsonToYolo 从 Coco 转换为 Yolo。现在我想做反之亦然。
我尝试过一些 yolo 到 coco 转换器，例如 YOLO2COCO 和使用五十一转换器。这些只会将 bbox（边界框）值转换为 coco 格式，而不是分段值。分段值为空([])。
可可格式：
“注释”：[
        {
            “id”：1，
            “图像ID”：1，
            “类别 ID”：1，
            “分段”：[
                [
                    5131.4,
                    1099.1,
                    5014.3,
                    1079.0,
                    4918.16,
                    1093.03,
                    4878.82,
                    1161.22,
                    4881.44,
                    1205.81,
                    4898.05,
                    1264.38,
                    4934.77,
                    1283.62,
                    4904.17,
                    1302.85,
                    4982.85,
                    1323.83,
                    4988.97,
                    1338.69,
                    5090.38,
                    1307.22,
                    5135.84,
                    1288.86,
                    5183.05,
                    1283.62,
                    5168.19,
                    1227.67,
                    5179.55,
                    1217.18,
                    5184.8,
                    1199.69,
                    5214.5,
                    1157.7
                ]
            ],
            “区域”：62712.0，
            “bbox”：[
                4878.82,
                1079.0,
                335.68,
                259.69
            ],
            “拥挤”：0，
            “属性”：{
                “用户名”：“”，
                “被遮挡”：假
            }
        },

Yolo 格式：
  0 0.21875 0.380208 0.215625 0.390625 0.215625 0.395833 0.214062 0.401042 0.214062 0.4062 0.40625 0.40625 0.2125 0.2125 0.411458 0.2125 0.2125 0.4270938 0.4210938 0.4210938 0.4210938 0.4210938 0.4210938 0.4210938 0.4210938.4210938.4210938.4210938 375 0.453125 0.209375 0.458333 0.207813 0.463542 0.207813 0.46875 0.20625 0.20625 0.473958 0.20625 0.479167 201562 0.520833 0.201562 0.5625 0.2 0.567708 0.2 0.59375 0.201562 0.598958 0.201562 0.651042 0.203125 0.65625 0.204688 0.651042 0.204688 0.6451042 375 0.619792 0.209375 0.614583 0.210938 0.609375 0.210938 0.604167 0.2125 0.598958 0.598958 0.2125 0.59375 0.2145 0.214062 708 0.217187 0.5625 0.217187 0.552083 0.21875 0.546875 0.21875 0.21875 0.536458 0.220313 0.53125 0.220313 0.520833 0.221875 0.515625 0.221875 0.505208 0.223438 0.5 0.223438 0.489583 0.225 0.484375 0.225 0.46875 0 .226562 0.463542 0.226562 0.432292 0.228125 0.427083 0.228125 0.380208

另一种方法是使用 Roboflow，其中数据以 yolo 格式上传并以 coco 格式导出。但我需要一个将 yolo 注释转换为 coco 格式的脚本。
有线索吗？]]></description>
      <guid>https://stackoverflow.com/questions/77364462/how-to-convert-yolo-segment-annotations-to-coco-format</guid>
      <pubDate>Thu, 26 Oct 2023 06:03:51 GMT</pubDate>
    </item>
    <item>
      <title>生成算法和判别算法有什么区别？ [关闭]</title>
      <link>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</link>
      <description><![CDATA[生成式和生成式有什么区别
判别算法？]]></description>
      <guid>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</guid>
      <pubDate>Mon, 18 May 2009 19:44:45 GMT</pubDate>
    </item>
    </channel>
</rss>