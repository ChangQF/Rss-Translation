<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 03 Sep 2024 15:17:19 GMT</lastBuildDate>
    <item>
      <title>要求法学硕士取一个值并从可接受的值列表中选择最适用的标签。我该如何预防幻觉？</title>
      <link>https://stackoverflow.com/questions/78944999/asking-an-llm-to-take-a-value-and-choose-the-most-applicable-tag-from-an-accepte</link>
      <description><![CDATA[目前，我有一个工作流，其中有大约 17,000 个值，这些值代表给定公司的行业价值（例如金融科技、医疗保健等）。其中许多被认为过于具体，因此我构建了一个提示，要求它从 250 个已批准的行业标签列表中获取每个值并选择最合适的值。我的问题是，尽管提示中明确说明，但 LLM 仍然以相当高的频率产生幻觉（900 个不同的值）。这是我的提示：
您将获得两个列表，一个包含公司所在行业的已批准值（行业价值），另一个包含广泛的不同行业（行业标签）。您的任务是将第二个列表中的每个行业标签与第一个列表中最合适的行业值进行匹配。风险投资公司将使用这些标签来识别他们可能投资的公司，因此需要从这个角度对其进行评估。只返回一个值至关重要。不要返回不在批准的行业值列表中的值。如果没有相关匹配，则返回“无匹配”。

仅返回每个行业标签的批准列表中匹配的行业值，

格式为 YAML，不包含任何超出此格式的附加文本、说明或内容。不返回任何额外文本至关重要。
在输入和输出之间保留行业顺序也极其重要，仅反映基于所提供信息的必要分类。请不要返回 YAML 输出之外的任何其他文本。输出格式与提供的示例输出相同至关重要。

每个行业标签应具有以下列表中的一个行业值：

3D 打印
配件
...

示例输入：
- 行业标签：农业加工
- 行业标签：金融科技
- 行业标签：胡言乱语
...

Yaml 输出：
- 行业标签：
农业加工：
行业价值：农业

- 行业标签：
金融科技：
行业价值：金融科技

- 行业标签：
胡言乱语：
行业价值：不匹配
...

以下是行业价值：
- 行业标签：多元化材料
- 行业标签：政府和公共服务
- 行业标签：医疗管理咨询
...

此处使用省略号缩短提示显示。尽管我已要求它不要生成批准列表之外的值，但它仍然会生成，我需要一些关于如何解决此问题的提示。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78944999/asking-an-llm-to-take-a-value-and-choose-the-most-applicable-tag-from-an-accepte</guid>
      <pubDate>Tue, 03 Sep 2024 15:11:06 GMT</pubDate>
    </item>
    <item>
      <title>如何从雪花阶段注册模型？</title>
      <link>https://stackoverflow.com/questions/78944290/how-to-register-a-model-from-a-snowflake-stage</link>
      <description><![CDATA[我在 Snowflake 阶段存储了模型，该模型可以预测给定数据集的收入。
现在我想将 Snowflake 中的模型注册为端点函数，该函数可以接受输入数据并返回预测值？
我查看了
snowflake.snowpark.functions.sproc

但它没有明确说明将模型注册为函数/存储过程端点？
那么在 Snowflake 中从现有阶段注册模型的最佳方法是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78944290/how-to-register-a-model-from-a-snowflake-stage</guid>
      <pubDate>Tue, 03 Sep 2024 12:14:31 GMT</pubDate>
    </item>
    <item>
      <title>如何理解 NN 输入和输出</title>
      <link>https://stackoverflow.com/questions/78944213/how-to-understand-nn-input-and-output</link>
      <description><![CDATA[我有一个项目想要对图像进行特征提取。我有这个 CNN 层：
model = keras.Sequential(
[
layers.Input((2*imsize,imsize,3)), 
layers.Reshape((2,imsize,imsize,3)), # 将图像拆分为 2 个 3 维图像 
layers.LayerNormalization(axis=[-1,-2,-3]), 

# CNN 层 
layers.SeparableConv2D(32, (3, 3),activation=&#39;relu&#39;),
layers.MaxPooling2D(pool_size=(2, 2)),
layers.SeparableConv2D(32, (3, 3),activation=&#39;relu&#39;),
layers.MaxPooling2D(pool_size=(2, 2)),
layers.SeparableConv2D(64, (3, 3),activation=&#39;relu&#39;),
layer.MaxPooling2D(pool_size=(2, 2)),

layer.Flatten(), 
layer.Dropout(rate=0.7), 
layer.Dense(16,activation=&#39;relu&#39;), 
layer.Dense(2,activation=&#39;softmax&#39;) 
])

虽然我得到了这个错误
内核形状必须与输入具有相同的长度，但接收到的内核形状为 (3, 3, 3, 32)，输入形状为 (None, 2, 64, 64, 3)。 SeparableConv2D.call() 接收的参数：
• args=(&#39;&lt;KerasTensor shape=(None, 2, 64, 64, 3), dtype=float32, sparse=False, 
name=keras_tensor_141&gt;&#39;,)
• kwargs=&lt;class &#39;inspect._empty&#39;&gt;

我无法理解如何将 LayerNormalization 层放入 SeparableConv2D 中。有人能帮我解决我做错的地方吗？]]></description>
      <guid>https://stackoverflow.com/questions/78944213/how-to-understand-nn-input-and-output</guid>
      <pubDate>Tue, 03 Sep 2024 11:55:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 Python 上的 OpenCV 运行海康威视摄像机时，FPS 较低且延迟较大</title>
      <link>https://stackoverflow.com/questions/78943962/low-fps-and-lot-of-delay-with-my-hikvision-cam-with-opencv-on-python</link>
      <description><![CDATA[我有一个任务，使用 OpenCV 处理来自 Hikvision IP 摄像机的流媒体视频。最初，视频的 FPS 约为 20-25，延迟为 2-3 秒。然而，随着代码运行时间的延长，FPS 迅速下降，延迟增加。最终，FPS 下降到 2-3，视频冻结。
 class VideoLoader:
@staticmethod
def load_video(video_path):
cap = cv2.VideoCapture(video_path)
cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc(&#39;M&#39;, &#39;J&#39;, &#39;P&#39;, &#39;G&#39;))
cap.set(cv2.CAP_PROP_FPS, 25)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) 
assert cap.isOpened(), &quot;Video dosyası okunurken hata oluştu&quot;
return cap


我尝试过使用 GPU、采用多线程和降低分辨率等方法，但这些方法都不太有效。您认为问题是什么，我该如何解决它
 def frame_reader(cap, frame_queue):
while cap.isOpened():
success, frame = cap.read()
if not success:
break
if not frame_queue.full(): # 检查队列是否有空间
frame_queue.put(frame)
cap.release()
frame_queue.put(None) # 流结束信号

def video_processor(frame_queue, output_queue, model, class_names, playing_sounds):
Threshold = 0.5 # 测试结果
device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model.to(device)

while True:
frame = frame_queue.get()
if frame is None: # 流结束信号
break
start_time = time.time()
img = cv2.resize(frame, (640, 480))
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
img_tensor = torch.from_numpy(img_rgb).permute(2, 0, 1).float().unsqueeze(0).to(device)
img_tensor /= 255.0 # 标准化

 def video_detection(video_source):
cap = VideoLoader.load_video(video_source)
model = YOLO(&quot;YOLO-Weights/ppe.pt&quot;)
class_names = [&#39;safety-glasses&#39;, &#39;gloves&#39;, &#39;orange-vest&#39;, &#39;yellow-vest&#39;,]
playing_sounds = set()

frame_queue = 队列（maxsize=5）
output_queue = 队列（maxsize=5）

reader_thread = threading.Thread（target=frame_reader，args=（cap，frame_queue），daemon=True）
processing_thread = threading.Thread（target=video_processor，args=（frame_queue，output_queue，model，class_names，played_sounds），daemon=True）

reader_thread.start()
processing_thread.start()


]]></description>
      <guid>https://stackoverflow.com/questions/78943962/low-fps-and-lot-of-delay-with-my-hikvision-cam-with-opencv-on-python</guid>
      <pubDate>Tue, 03 Sep 2024 10:50:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML 和深度学习对发票进行 OCR，不同供应商的发票格式各异。我需要提取详细信息并将其存储在 excel 中 [关闭]</title>
      <link>https://stackoverflow.com/questions/78943747/ocr-for-invoice-using-ml-and-deep-learning-invoice-is-of-varied-format-from-dif</link>
      <description><![CDATA[我正在尝试制作用于发票扫描的 OCR。我有来自不同供应商的许多不同格式的发票。我想扫描该发票并提取一些详细信息，例如发票号、供应商名称、交货条款等，我有 5 到 6 个详细信息，所有这些都在不同的地方，甚至其名称也发生了变化，例如有些有发票号，而有些账单有买家的订单号。
我想提取数据并将其存储在 excel 表中。
我曾考虑过使用 LayoutLMV3、Pytorch 和 OpenCv 等
我应该如何处理这个问题陈述。]]></description>
      <guid>https://stackoverflow.com/questions/78943747/ocr-for-invoice-using-ml-and-deep-learning-invoice-is-of-varied-format-from-dif</guid>
      <pubDate>Tue, 03 Sep 2024 10:00:07 GMT</pubDate>
    </item>
    <item>
      <title>如何实现自适应负荷和光伏预测模型的强化学习？[关闭]</title>
      <link>https://stackoverflow.com/questions/78942987/how-to-implement-reinforcement-learning-for-adaptive-load-and-pv-forecasting-mod</link>
      <description><![CDATA[我正在开展一个项目，使用时间序列数据构建负载和光伏 (PV) 预测模型。目前，我已经使用随机森林和 LSTM 实现了模型，虽然它们表现相当不错，但由于趋势多变，我遇到了挑战。
我面临的问题是，负载和 PV 输出由于外部因素而高度可变。例如，负载因不同的消费模式而变化，PV 输出因气候变化而波动。我需要一个可以动态适应这些变化的模型。
我正在考虑使用强化学习 (RL) 来开发一个可以实时适应这些环境变化的模型。我的目标是实施一种在线学习方法，让模型不断学习并根据新数据进行自我更新。但是，我发现重新训练随机森林和 LSTM 等模型在计算上非常昂贵。
我的问题是：
如何有效地实施强化学习以实现这种自适应预测？
是否有特定的 RL 算法或技术非常适合动态变化环境中的时间序列预测？
在在线学习场景中，我可以使用哪些策略来平衡模型性能和计算成本之间的权衡？
任何指导或资源都将不胜感激！
我已经实施了随机森林和 LSTM 模型来进行负载和 PV 预测。这些模型对于初始预测效果很好，但很难适应数据随时间变化的趋势。我探索了在线学习方法，希望它们能提供实时适应的解决方案。但是，我发现不断重新训练这些模型在计算上非常昂贵，并且不适合我的用例。
我希望开发一种可以实时适应负载和 PV 趋势变化的模型，而无需不断重新训练。我的目标是找到一种可以动态高效地处理数据变化的方法。
到目前为止，我尝试过的模型要么需要频繁重新训练，这很昂贵，要么它们无法足够快地适应数据的变化。这导致预测准确性随着时间的推移而下降。]]></description>
      <guid>https://stackoverflow.com/questions/78942987/how-to-implement-reinforcement-learning-for-adaptive-load-and-pv-forecasting-mod</guid>
      <pubDate>Tue, 03 Sep 2024 06:46:11 GMT</pubDate>
    </item>
    <item>
      <title>SAM 模型中无法检测图像 - TypeError：无法处理此数据类型</title>
      <link>https://stackoverflow.com/questions/78942834/image-not-detecting-in-sam-model-typeerror-cannot-handle-this-data-type</link>
      <description><![CDATA[以下是我的代码。每当我上传任何类型的图像时，都会出现相同的错误。它是否只处理高质量图像（或任何特定类型的图像）或我的代码中存在任何错误？
我尝试了不同的图像，上面的代码是 chatgpt 经过一些修改后给出的。仍然没有运气。
错误
TypeError：无法处理此数据类型：（1, 1, 640, 3），|u1
code
import torch
import numpy as np
from PIL import Image
fromsegment_anything import sam_model_registry, SamPredictor
from google.colab import files

# 加载 SAM 模型

sam = sam_model_registry[&quot;vit_b&quot;](checkpoint=&quot;/content/sam_vit_b_01ec64.pth&quot;)
predictor = SamPredictor(sam)

uploaded = files.upload()
image_name = list(uploaded.keys())[0]

image = Image.open(image_name).convert(&quot;RGB&quot;)
image_np = np.array(image)

# 检查图像形状

print(f&quot;原始图像形状：{image_np.shape}&quot;)

# 如果存在额外维度，则删除它们

if len(image_np.shape) == 4 and image_np.shape[0] == 1:
image_np = image_np.squeeze(0) # 如果第一个维度的大小为 1，则删除它

# 确保图像的格式和类型正确

image_np = image_np.astype(np.uint8)

print(f&quot;处理后的图像形状：{image_np.shape}&quot;)

# 将图像设置为 SAM 预测器

predictor.set_image(image_np)

# 预测图像的蒙版

masks = predictor.predict()

# 确保您有蒙版并使用它们

如果蒙版不为 None 且 len(masks) &gt; 0:
mask = mask[0] # 假设第一个蒙版是您需要的

# 将蒙版应用于图像
masked_image = np.where(mask[..., None], image_np, 0) # 将蒙版应用于图像

# 将蒙版图像转换回 PIL 图像
masked_image = Image.fromarray(masked_image)

# 显示蒙版图像
masked_image.show()

否则：
print(&quot;未找到给定图像的蒙版。&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78942834/image-not-detecting-in-sam-model-typeerror-cannot-handle-this-data-type</guid>
      <pubDate>Tue, 03 Sep 2024 05:49:49 GMT</pubDate>
    </item>
    <item>
      <title>RL：梯度赌博机代理</title>
      <link>https://stackoverflow.com/questions/78942595/rl-gradient-bandit-agent</link>
      <description><![CDATA[我正在阅读 Sutton&amp;Barto 的《强化学习：导论》。尝试测试梯度强盗代理（第 2.7 章）。但性能极低。我试过：

使用基线 = 平均奖励，不使用基线；
alpha = 0.1、0.2、0.3、0.4；
初始偏好 H = 0、1、10、100。

没有任何帮助。
这是我的 Python 代码，用于代理的 生命步骤 = 动作选择 + 参数更新 (self = agent)：
# 用于概率计算：
pref_exps = np.exp(self.params[&quot;preferences&quot;])
pref_exps_sum = sum(pref_exps)

# 选择强盗：
choice_dice = np.random.uniform() * pref_exps_sum
accum_pref_exp = 0
for i, pref_exp in enumerate(pref_exps):
accum_pref_exp += pref_exp
if accum_pref_exp &gt;= choice_dice:
self.chosen_bandit_i = i
break

# self.reward 在此处填充：
self.perform_bandit(self.chosen_bandit_i)

# 更新基线：
self.params[&quot;lifetime&quot;] += 1
self.params[&quot;average_reward&quot;] += 1 / self.params[&quot;lifetime&quot;] * (self.reward - self.params[&quot;average_reward&quot;])

# 更新偏好：
for i, pref_exp in enumerate(pref_exps):
probability = pref_exp / pref_exps_sum
if i == self.chosen_bandit_i:
self.params[&quot;preferences&quot;][i] += self.params[&quot;alpha&quot;] * (self.reward - self.params[&quot;average_reward&quot;]) * (1 - probability)
else:
self.params[&quot;preferences&quot;][i] -= self.params[&quot;alpha&quot;] * (self.reward - self.params[&quot;average_reward&quot;]) * probability

此代码导致性能极差（100 个代理，每个代理访问自己的 10 个 1-armed-bandits，测试超过 2000 步），我们可以从下图中看到：

我看过这篇帖子，修复错误后，它的代码似乎与我的代码相同，这也是我写这篇帖子的原因。但与我的代码不同，那篇帖子的代码在纠正后可以正常工作！
我不知道自己在哪里犯了错误。你们能帮我正确使用Gradient-bandit agent的全部功能吗？]]></description>
      <guid>https://stackoverflow.com/questions/78942595/rl-gradient-bandit-agent</guid>
      <pubDate>Tue, 03 Sep 2024 03:40:50 GMT</pubDate>
    </item>
    <item>
      <title>我应该做什么 Web 开发或 Ai/ML [关闭]</title>
      <link>https://stackoverflow.com/questions/78942412/what-should-i-do-web-development-or-ai-ml</link>
      <description><![CDATA[我是计算机科学专业的学生。我的第三年才刚刚开始，我已经学过 html、CSS 和 JavaScript。但我不确定我应该做 Ai/ML 还是 Web 开发。
我尝试过 Web 开发，但我不确定是否应该继续。]]></description>
      <guid>https://stackoverflow.com/questions/78942412/what-should-i-do-web-development-or-ai-ml</guid>
      <pubDate>Tue, 03 Sep 2024 01:40:05 GMT</pubDate>
    </item>
    <item>
      <title>RandomForest 模型未按预期工作</title>
      <link>https://stackoverflow.com/questions/78941615/randomforest-model-not-working-as-expected</link>
      <description><![CDATA[我想尝试预测股票价格。我知道股市基本上是一个随机过程，因此我不期望任何正回报。我编写了一个小脚本，使用随机森林回归器，该回归器已根据过去 20 年左右的 AAPL 股票数据（过去 100 天除外）进行训练。我使用过去 100 天作为验证。
根据开盘价/收盘价/最高价/最低价和交易量，我在数据框中创建了另外两列：收盘价的涨跌百分比和 days_since_start_column，因为如果我的判断正确，模型无法根据日期时间进行学习。
无论如何，这是代码的其余部分：
df = pd.read_csv(&#39;stock_data.csv&#39;)
df = df[::-1].reset_index()
df[&#39;timestamp&#39;] = pd.to_datetime(df[&#39;timestamp&#39;])
df[&#39;% Difference&#39;] = df[&#39;close&#39;].pct_change()

splits = [
{&#39;date&#39;: &#39;2020-08-31&#39;, &#39;ratio&#39;: 4},
{&#39;date&#39;: &#39;2014-06-09&#39;, &#39;ratio&#39;: 7},
{&#39;date&#39;: &#39;2005-02-28&#39;, &#39;ratio&#39;: 2},
{&#39;date&#39;: &#39;2000-06-21&#39;, &#39;ratio&#39;: 2}
]

用于 split 中的 split:
split[&#39;date&#39;] = pd.to_datetime(split[&#39;date&#39;])
split_date = split[&#39;date&#39;]
ratio = split[&#39;ratio&#39;]
df.loc[df[&#39;timestamp&#39;] &lt; split_date, &#39;close&#39;] /= 比率

df[&#39;days_since_start&#39;] = (df[&#39;timestamp&#39;] - df[&#39;timestamp&#39;].min()).dt.days
#data = r.json()
target = df.close
features = [&#39;days_since_start&#39;,&#39;open&#39;,&#39;high&#39;,&#39;low&#39;,&#39;volume&#39;]

X_train = (df[features][:-100])
X_validation = df[features][-100:]

y_train = df[&#39;close&#39;][:-100]
y_validation = df[&#39;close&#39;][-100:]

#X_train,X_validation,y_train,y_validation = train_test_split(df[features][:-100],target[:-100],random_state=0)

model = RandomForestRegressor()
model.fit(X_train,y_train)
predictions = model.predict(X_validation)

predictions_df = pd.DataFrame(columns=[&#39;days_since_start&#39;,&#39;close&#39;])
predictions_df[&#39;close&#39;] = predictions
predictions_df[&#39;days_since_start&#39;] = df[&#39;timestamp&#39;][-100:].values
plt.xlabel(&#39;日期&#39;)
#plt.scatter(df.loc[X_validation.index, &#39;timestamp&#39;], predictions, color=&#39;red&#39;, label=&#39;预测收盘价&#39;, alpha=0.6)
plt.plot(df.timestamp[:-100],df.close[:-100],color=&#39;black&#39;)
plt.plot(df.timestamp[-100:],df.close[-100:],color=&#39;green&#39;)
plt.plot(predictions_df.days_since_start,predictions_df.close,color=&#39;red&#39;)
plt.show()

我用黑色绘制了过去几年截至最近 100 天的收盘价，用绿色绘制了最近 100 天的收盘价，用红色绘制了最近 100 天的预测收盘价。这是结果（过去 100 天）：

为什么价格大幅上涨后模型保持平稳？我在训练过程中做错了什么吗？我的验证数据集太小了吗？还是这只是超参数调整的问题？]]></description>
      <guid>https://stackoverflow.com/questions/78941615/randomforest-model-not-working-as-expected</guid>
      <pubDate>Mon, 02 Sep 2024 17:53:54 GMT</pubDate>
    </item>
    <item>
      <title>subprocess.CalledProcessError [关闭]</title>
      <link>https://stackoverflow.com/questions/78940345/subprocess-calledprocesserror</link>
      <description><![CDATA[我正在使用 Unsloth 库来加载我的微调模型，我能够成功加载我的模型，但是当我想要生成推理时，我收到此错误：
subprocess.CalledProcessError：命令&#39;[&#39;/usr/bin/gcc&#39;, &#39;/tmp/tmpepjvuftj/main.c&#39;, &#39;-O3&#39;, &#39;-shared&#39;, &#39;-fPIC&#39;, &#39;-o&#39;, &#39;/tmp/tmpepjvuftj/cuda_utils.cpython-311-x86_64-linux-gnu.so&#39;, &#39;-lcuda&#39;, &#39;-L/usr/local/lib/python3.11/dist-packages/triton/backends/nvidia/lib&#39;, &#39;-L/lib/x86_64-linux-gnu&#39;, &#39;-I/usr/local/lib/python3.11/dist-packages/triton/backends/nvidia/include&#39;, &#39;-I/tmp/tmpepjvuftj&#39;, &#39;-I/usr/include/python3.11&#39;]&#39; 返回非零退出状态 1。
这是我的代码：
def load_model()：
max_seq_length = 2048 # 选择任意！我们自动内部支持 RoPE 缩放！
dtype = None # 自动检测为 None。Float16 适用于 Tesla T4、V100，Bfloat16 适用于 Ampere+
load_in_4bit = True # 使用 4 位量化来减少内存使用量。可以为 False。
如果为 True:
model, tokenizer = FastLanguageModel.from_pretrained(
model_name = &quot;/root/natural-matchmaking-ai/models/text_to_nosql&quot;, # 您用于训练的模型
max_seq_length = max_seq_length,
dtype = dtype,
load_in_4bit = load_in_4bit,
)
FastLanguageModel.for_inference(model) 
print(&quot; 模型已成功加载&quot;)
return model,tokenizer

def generate_response(message_content,tokenizer,model):
try:
messages = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message_content}]
 # 从模板生成输入 ID
input_ids = tokenizer.apply_chat_template(
messages,
add_generation_prompt=True,
return_tensors=&quot;pt&quot;
).to(device)
print(&quot;输入 ID 设备：&quot;, input_ids.device)
print(&quot;模型设备：&quot;, next(model.parameters()).device)
# 初始化文本流器
text_streamer = TextStreamer(tokenizer, skip_prompt=True)
print(&quot;从文本流器继续&quot;)
# 生成响应
generated_outputs = model.generate(
input_ids,
streamer=text_streamer,
max_new_tokens=128,
pad_token_id=tokenizer.eos_token_id
)

# 解码生成的文本
generated_text = tokenizer.decode(generated_outputs[0], skip_special_tokens=True)

# 按行拆分响应并获取最后一行
lines = generated_text.strip().split(&#39;\n&#39;)
if not lines:
return {&quot;error&quot;: &quot;Response is empty or isn&#39;t be split into lines&quot;}

last_line = lines[-1].strip()

# 调试：打印最后一行
print(&quot;Last Line:&quot;, last_line)

return last_line
except Exception as error:
print(&quot;Error duringgeneration:&quot;,error)
traceback.print_exc()

model,tokenizer=load_model()
res=generate_response(&quot;latest products&quot;,tokenizer,model)]]></description>
      <guid>https://stackoverflow.com/questions/78940345/subprocess-calledprocesserror</guid>
      <pubDate>Mon, 02 Sep 2024 11:58:30 GMT</pubDate>
    </item>
    <item>
      <title>无需深度学习或 Tesseract 的文本图像二元分类器</title>
      <link>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</link>
      <description><![CDATA[我有 20k 张小标签图像，每张图像都有单词“Back”或“Front”。
图像分辨率为全部 (200px, 25px)

我可以使用 tesseract_OCR 对这些图像进行 100% 准确率的分类。
 txt = pytesseract.image_to_string(img, lang=&#39;eng&#39;)
if &quot;Front&quot; in txt:
return &quot;Front&quot;
if &quot;Back&quot; in txt:
return &quot;Back&quot;

问题是，它太慢了（20k 张图像需要 1 小时）并且需要安装 OCR 包。
我知道即使是 3 层的简单 CNN 也能很好地运行，但我认为这个问题似乎可以用简单的算法解决，而不需要复杂的技术。
你能给我推荐一种新方法吗？
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</guid>
      <pubDate>Wed, 07 Aug 2024 06:46:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Core ML 中的 MLMultiArray 中设置正确的步幅？步幅的值是什么意思？</title>
      <link>https://stackoverflow.com/questions/72166348/how-to-set-right-strides-in-mlmultiarray-in-core-ml-whats-the-strides-values</link>
      <description><![CDATA[如何在 Core ML 中的 MLMultiArray 中设置正确的 strides？每个 strides 的值的含义是什么？
例如，假设 Core ML 模型输入 shape 为 (1, 3, 1280, 720)，那么在使用 initWithDataPointer:shape:dataType:strides:deallocator:error: 创建 MLMultiArray 对象时如何设置 strides？
我从一些网站将 strides 设置为 (720 * 1280, 720 * 1280, 720, 1)，但我不知道为什么这样设置，或者是否正确。 shape 和 strides 之间有什么联系。Apple 开发者网站上没有更多相关文档。]]></description>
      <guid>https://stackoverflow.com/questions/72166348/how-to-set-right-strides-in-mlmultiarray-in-core-ml-whats-the-strides-values</guid>
      <pubDate>Mon, 09 May 2022 02:07:53 GMT</pubDate>
    </item>
    <item>
      <title>如何将两个不同的训练过的 ML 模型合二为一？</title>
      <link>https://stackoverflow.com/questions/64801479/how-to-combine-two-different-trained-ml-models-as-one</link>
      <description><![CDATA[我根据两个不同的数据集训练了两个 ml 模型。然后我将它们保存为 model1.pkl 和 model2.pkl 。有两个用户输入（不是模型的输入数据），如 x=0 和 x=1，如果 x=0，我必须使用 model1.pkl 进行预测，否则我必须使用 model2.pkl 进行预测。我可以使用 if 条件来执行它们，但我的问题是我必须知道是否有可能将其保存回 model.pkl 包括此条件语句。如果我将它们组合并保存为模型，它将很容易在其他 IDE 中加载。]]></description>
      <guid>https://stackoverflow.com/questions/64801479/how-to-combine-two-different-trained-ml-models-as-one</guid>
      <pubDate>Thu, 12 Nov 2020 09:44:27 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET：输入列“AnswerFeaturized_CharExtractor”的架构不匹配：预期为单个或已知大小的单个向量，得到向量 <Single></title>
      <link>https://stackoverflow.com/questions/57309814/ml-net-schema-mismatch-for-input-column-answerfeaturized-charextractor-expec</link>
      <description><![CDATA[我试图在 ML.NET 中创建一个机器学习模型，该模型根据用户输入的答案预测成绩。
以下是代码：
 private static string _appPath =&gt; Path.GetDirectoryName(Environment.GetCommandLineArgs()[0]);
private static string _trainDataPath =&gt; Path.Combine(_appPath, &quot;..&quot;, &quot;..&quot;, &quot;..&quot;, &quot;Data&quot;, &quot;GradeTrain.csv&quot;);

static void Main(string[] args)
{
_mlContext = new MLContext(seed: 0);
_trainingDataView = _mlContext.Data.LoadFromTextFile&lt;InputData&gt;(_trainDataPath, hasHeader: true); 
var pipeline = ProcessData();
var trainingPipeline = BuildAndTrainModel(_trainingDataView, pipeline); 
评估（_trainingDataView.Schema）； 
}

public static IEstimator&lt;ITransformer&gt; ProcessData()
{
var pipeline = _mlContext.Transforms.Conversion.MapValueToKey（inputColumnName：“成绩”，outputColumnName：“标签”）。追加（_mlContext.Transforms.Text.FeaturizeText（inputColumnName：“问题ID”，outputColumnName：“问题IDFeaturized”））。追加（_mlContext.Transforms.Text.FeaturizeText（inputColumnName：“答案”，outputColumnName：“答案Featurized”））。追加（_mlContext.Transforms.Concatenate（“特征”，“问题IDFeaturized”，“答案Featurized”））。追加CacheCheckpoint（_mlContext）；
return pipeline;
}
public static IEstimator&lt;ITransformer&gt; BuildAndTrainModel(IDataView trainingDataView, IEstimator&lt;ITransformer&gt; 管道)
{
var trainingPipeline = pipeline.Append(_mlContext.MulticlassClassification.Trainers.SdcaMaximumEntropy(&quot;Label&quot;, &quot;Features&quot;)) .Append(_mlContext.Transforms.Conversion.MapKeyToValue(&quot;PredictedLabel&quot;)); 
_trainedModel = trainingPipeline.Fit(trainingDataView);
_predEngine = _mlContext.Model.CreatePredictionEngine&lt;InputData, answerGradePrediction&gt;(_trainedModel);
InputData issue = new InputData()
{
QuestionID = &quot;HOUSES&quot;,
Answer = &quot;上议院称为 Rajya sabha，下议院称为 Lok sabha&quot;
};
var prediction = _predEngine.Predict(issue); 
返回 trainingPipeline;
}

输入类的代码
public class InputData
{
[LoadColumn(0)]
public string QuestionID { get; set; }
[LoadColumn(1)]
public string Answer { get; set; }
[LoadColumn(2)]
public string Grade { get; set; }
}

这在 Fit 函数中产生以下错误：
System.ArgumentOutOfRangeException：&#39;输入列 &#39;AnswerFeaturized_CharExtractor&#39; 的架构不匹配：预期为 Single 或已知大小的 Single 向量，得到 Vector&lt;Single&gt;
参数名称：inputSchema&#39;

有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/57309814/ml-net-schema-mismatch-for-input-column-answerfeaturized-charextractor-expec</guid>
      <pubDate>Thu, 01 Aug 2019 13:11:37 GMT</pubDate>
    </item>
    </channel>
</rss>