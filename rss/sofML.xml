<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 12:34:15 GMT</lastBuildDate>
    <item>
      <title>将注意力机制增强至 O(log N)：基于树的 Transformer 模型优化方法</title>
      <link>https://stackoverflow.com/questions/79133220/enhancing-attention-mechanism-to-olog-n-a-tree-based-approach-for-optimizing</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79133220/enhancing-attention-mechanism-to-olog-n-a-tree-based-approach-for-optimizing</guid>
      <pubDate>Mon, 28 Oct 2024 11:42:20 GMT</pubDate>
    </item>
    <item>
      <title>如何提高 CNN 模型的准确率并减少损失？</title>
      <link>https://stackoverflow.com/questions/79133215/how-to-increase-accuracy-and-decrease-loss-in-cnn-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79133215/how-to-increase-accuracy-and-decrease-loss-in-cnn-model</guid>
      <pubDate>Mon, 28 Oct 2024 11:41:21 GMT</pubDate>
    </item>
    <item>
      <title>调用 BroadcastTo.call() 时遇到异常</title>
      <link>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</guid>
      <pubDate>Sun, 27 Oct 2024 19:29:36 GMT</pubDate>
    </item>
    <item>
      <title>绝对、相对、旋转和学习位置编码之间的区别[关闭]</title>
      <link>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</link>
      <description><![CDATA[位置编码（绝对、相对、旋转）和学习到的位置编码之间有什么区别？
我了解绝对、相对和旋转编码之间的区别，但我无法识别这些编码和学习到的位置编码之间的任何区别。]]></description>
      <guid>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</guid>
      <pubDate>Sun, 27 Oct 2024 16:39:04 GMT</pubDate>
    </item>
    <item>
      <title>删除所有人口后，Python NEAT 给出错误</title>
      <link>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</guid>
      <pubDate>Sun, 27 Oct 2024 16:27:23 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的负损失没有减少</title>
      <link>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</guid>
      <pubDate>Sun, 27 Oct 2024 16:07:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么卷积层的输出形状不能跨通道相乘？</title>
      <link>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</link>
      <description><![CDATA[# 第一个卷积层：输入通道 = 1，输出通道 = 32，内核大小 = 5x5，填充 = 2（相同）
self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)
# 第一个池化层：最大池化，内核大小 = 2x2，步长 = 2
self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

# 第二个卷积层：输入通道 = 32，输出通道 = 64，内核大小 = 5x5，填充 = 2（相同）
self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
# 第二个池化层：最大池化，内核大小 = 2x2， stride = 2
self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

为什么第二个卷积层后的输出不是
14 * 14 * 32 * 64？对于32通道的输入，每个卷积核只作用于一个通道，因此会产生64种不同的结果。难道不应该将32个通道相乘吗？
我得到的答案是：对于输入的每个14 * 14位置，5532核与5532输入区域进行点积将产生14*14的单通道输出。核大小不是5 * 5吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</guid>
      <pubDate>Sun, 27 Oct 2024 14:14:47 GMT</pubDate>
    </item>
    <item>
      <title>输入图像与 TensorFlow 模型输入形状不兼容</title>
      <link>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</link>
      <description><![CDATA[我正在构建一个模型，我想测试它的性能，因此我导入了一个本地文件并加载它，并尝试使用以下代码预测它的标签：
from tensorflow.preprocessing import image
# tensorlfow 等的其他导入。

#...

# 示例图像
img_path = &quot;./Model/data/brain/train/Glioma/images/gg (2).jpg&quot;
img = image.load_img(img_path,target_size=(256,256))
arr = image.img_to_array(img)
t_img = tf.convert_to_tensor(arr)
print(t_img.shape) # 返回 (256,256,3)
# 客户端测试
client = Client(&quot;brain&quot;) # 自定义类。包含模型：顺序（已编译和训练）
client.predict(img=t_img) # 调用 self.model.predict(t_img)

但是我收到以下错误：
输入 Tensor(&quot;data:0&quot;, shape=(32, 256, 3), dtype=float32) 的输入形状无效。预期形状 (None, 256, 256, 3)，但输入具有不兼容的形状 (32, 256, 3)

我在训练模型中有一个输入层，其 input_shape=[256,256,3]（来自图像宽度、高度和 rgb 值）
您能帮助我理解问题并解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</guid>
      <pubDate>Sun, 27 Oct 2024 11:57:01 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的 Tensorflow predict() 时间序列对齐</title>
      <link>https://stackoverflow.com/questions/79106002/tensorflow-predict-timeseries-alignment-in-python</link>
      <description><![CDATA[假设我在 Tensorflow 中创建一个顺序输入 LSTM，如下所示：
def Sequential_Input_LSTM(df, input_sequence):
df_np = df.to_numpy()
X = []
y = []

for i in range(len(df_np) - input_sequence):
row = [a for a in df_np[i:i + input_sequence]]
X.append(row)
label = df_np[i + input_sequence]
y.append(label)

return np.array(X), np.array(y)

X, y = Sequential_Input_LSTM(df_data , 10) # pandas DataFrame df_data 包含我们的数据

在此示例中，我将数据切片X（输入向量）和 y（标签），例如前 10 个值（序列长度）用作 X，第 11 个值用作第一个 y。然后，将 10 个值的窗口向右移动一步（再移动一个时间步），我们再次为 X 取 10 个值，并将第二行之后的值作为下一个 y，依此类推。
然后假设我将 X 的一部分作为我的 X_test，并使用 LSTM model 进行时间序列预测，例如 predictions = model.predict(X_test)。
当我实际尝试此操作并绘制 predict(X_test) 的结果时，它看起来像 y 数组，并且预测结果是同步的，无需进一步调整。我预计在将预测数组与标签一起绘制时，我必须手动将预测数组向右移动 10 个时间步，因为我无法解释预测的前 10 个时间戳来自哪里。
由于模型尚未收到 10 个输入序列值，X_test 的前 10 个时间步的预测来自哪里？Tensorflow 是否使用 X_test 中的最后几个时间步来创建前 10 个值的预测，还是一开始的预测只是纯粹的猜测？]]></description>
      <guid>https://stackoverflow.com/questions/79106002/tensorflow-predict-timeseries-alignment-in-python</guid>
      <pubDate>Sat, 19 Oct 2024 21:37:05 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习预训练模型</title>
      <link>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</link>
      <description><![CDATA[我在 Google Colab 上拟合迁移学习模型。但是，我在代码中遇到了一条警告消息
Epoch 1/30
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: 
UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。
请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()

在第一个 epoch 之后，我收到以下错误：
----------------------------------------------------------------------------------------
KeyboardInterrupt Traceback（最近一次调用最后一次）
&lt;ipython-input-23-962a870d4412&gt; in &lt;cell line: 16&gt;()
14 # 拟合模型
15 # 运行单元。执行需要一些时间
---&gt; 16 training_history = model_efficientnet.fit(
17 training_set,
18 validation_data=validate_set,

我已经成功地拟合了其他六个迁移学习模型，没有任何问题，它们的准确率令人满意。
如何解决这个问题？
我想获得训练准确率和验证准确率]]></description>
      <guid>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</guid>
      <pubDate>Thu, 15 Aug 2024 14:49:45 GMT</pubDate>
    </item>
    <item>
      <title>Tensor Flow TFX 管道中的图像处理</title>
      <link>https://stackoverflow.com/questions/72166920/image-processing-in-tensor-flow-tfx-pipelines</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/72166920/image-processing-in-tensor-flow-tfx-pipelines</guid>
      <pubDate>Mon, 09 May 2022 04:10:29 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 scikit 的 Surprise 进行预测？</title>
      <link>https://stackoverflow.com/questions/65282827/how-to-make-predictions-with-scikits-surprise</link>
      <description><![CDATA[我在理解 Surprise 工作流程时遇到了一些困难。我有一个用于训练的文件（我想将其分为训练和验证）和一个用于测试数据的文件。我很难理解 Surprise Dataset 和 Trainset 之间的区别
# 导入数据
data_dir = &#39;DIRECTORY_NAME&#39;
reader = Reader(rating_scale=(1, 5))

# 创建 pandas 数据框
train_valid_df = pd.read_csv(os.path.join(data_dir, &#39;TRAINING_FILENAME.csv&#39;))
train_df, valid_df = train_test_split(train_valid_df, test_size=0.2)
test_df = pd.read_csv(os.path.join(data_dir, &#39;TEST_FILENAME.csv&#39;))

# 创建 Surprise Dataset 对象
train_valid_Dataset = Dataset.load_from_df(train_valid_df[[&#39;user_id&#39;, &#39;item_id&#39;, &#39;rating&#39;]], reader)
train_Dataset = Dataset.load_from_df(train_df[[&#39;user_id&#39;, &#39;item_id&#39;, &#39;rating&#39;]], reader)
valid_Dataset = Dataset.load_from_df(valid_df[[&#39;user_id&#39;, &#39;item_id&#39;, &#39;rating&#39;]], reader)
test_Dataset = Dataset.load_from_df(test_df[[&#39;user_id&#39;, &#39;item_id&#39;, &#39;rating&#39;]], reader)

# 创建惊喜训练集对象（和测试集对象？）
train_Trainset = train_data.build_full_trainset()
valid_Testset = trainset.build_anti_testset()

然后，我创建我的预测器：
algo = KNNBaseline(k=60, min_k=2, sim_options={&#39;name&#39;: &#39;msd&#39;, &#39;user_based&#39;: True})

现在，如果我想进行交叉验证，我会这样做
cross_v = cross_validate(algo, all_data, measures=[&#39;mae&#39;], cv=10, verbose=True)

哪个训练模型（？），但如果我想使用我的固定验证集，我该怎么做？这个：？
algo.fit(train_Trainset)

完成此操作后，我尝试获得一些预测：
predictions = algo.test(valid_Testset)
print(predictions[0])

结果如下

但是当我尝试使用商品和用户 ID 号进行预测时，它说这样的预测是不可能的：
print(algo.predict(&#39;13&#39;, &#39;194&#39;))
print(algo.predict(&#39;260&#39;, &#39;338&#39;))
print(algo.predict(&#39;924&#39;, &#39;559&#39;))

结果：

第一个用户/项目对来自训练反集，第二个来自验证集，第三个来自训练集。我不知道为什么会出现这种情况，而且我发现文档有时令人困惑。同样，网上的许多教程似乎都在对 pandas 数据框进行训练，而我却因此而遇到错误。有人能解释一下 surprise 的工作流程到底是什么样的吗？我如何训练然后在测试集上进行预测？]]></description>
      <guid>https://stackoverflow.com/questions/65282827/how-to-make-predictions-with-scikits-surprise</guid>
      <pubDate>Mon, 14 Dec 2020 02:19:44 GMT</pubDate>
    </item>
    <item>
      <title>深度强化学习 - 如何处理动作空间中的边界[关闭]</title>
      <link>https://stackoverflow.com/questions/51127979/deep-reinforcement-learning-how-to-deal-with-boundaries-in-action-space</link>
      <description><![CDATA[我构建了一个自定义强化学习环境和代理，它类似于迷宫游戏。
在迷宫中有 5 种可能的动作：上、下、左、右和停留。如果被阻挡，例如代理无法上去，那么人们如何设计环境和代理来模拟这种情况？
具体来说，代理处于当前状态s0，根据定义，采取下、左、右动作将使状态更改为其他值并立即获得奖励（如果在出口则为&gt;0）。一种可能的方法是，当采取上动作时，状态将保持在s0，奖励将是一个很大的负数。理想情况下，代理将学习这一点，并且永远不会再在这个状态下上。 
但是，我的代理似乎没有学到这一点。相反，它仍然向上。另一种方法是对代理和环境进行硬编码，使代理在s0时无法执行操作向上，我能想到的是：

当某些状态下不允许向上时，我们查看不同操作的Q值
选择除向上之外具有最大Q值的操作
因此，代理永远不会执行无效操作

我想问的是上述方法是否可行？会不会有什么与此相关的问题？或者有没有更好的设计来处理边界和无效操作？]]></description>
      <guid>https://stackoverflow.com/questions/51127979/deep-reinforcement-learning-how-to-deal-with-boundaries-in-action-space</guid>
      <pubDate>Mon, 02 Jul 2018 00:35:49 GMT</pubDate>
    </item>
    <item>
      <title>sklearn：获取点到最近聚类的距离</title>
      <link>https://stackoverflow.com/questions/44041347/sklearn-get-distance-from-point-to-nearest-cluster</link>
      <description><![CDATA[我正在使用 DBSCAN 之类的聚类算法。
它返回一个名为 -1 的“聚类”，这些点不属于任何聚类。对于这些点，我想确定它与最近聚类之间的距离，以获得类似于该点异常程度的指标。这可能吗？或者这种指标还有其他选择吗？]]></description>
      <guid>https://stackoverflow.com/questions/44041347/sklearn-get-distance-from-point-to-nearest-cluster</guid>
      <pubDate>Thu, 18 May 2017 07:31:36 GMT</pubDate>
    </item>
    <item>
      <title>QLearning 和永无止境的剧集</title>
      <link>https://stackoverflow.com/questions/1836731/qlearning-and-never-ending-episodes</link>
      <description><![CDATA[假设我们有一个 (x,y) 平面，机器人可以在其中移动。现在我们将世界的中心定义为目标状态，这意味着一旦机器人达到该状态，我们将给予它 100 的奖励。
现在，假设有 4 个状态（我将其称为 A、B、C、D）可以导致目标状态。
第一次处于 A 并进入目标状态时，我们将按如下方式更新 QValues 表：
Q(state = A, action = going to goal state) = 100 + 0

可能会发生以下两种情况之一。我可以在这里结束这一集，然后开始另一个集，让机器人再次找到目标状态，或者我可以继续探索世界，即使我找到了目标状态。如果我尝试这样做，我会看到一个问题。如果我处于目标状态并返回到状态 A，它的 Qvalue 将如下所示：
Q(state = goalState, action = going to A) = 0 + gamma * 100

现在，如果我尝试再次从 A 转到目标状态：
Q(state = A, action = going to goal state) = 100 + gamma * (gamma * 100)

这意味着如果我继续这样做，因为 0 &lt;= gamma &lt;= 0，两个 qValues 都会永远上升。
这是 QLearning 的预期行为吗？我做错了什么吗？如果这是预期行为，这不会导致问题吗？我知道从概率上讲，所有 4 个状态（A、B、C 和 D）都会以相同的速率增长，但即便如此，让它们永远增长也让我有点烦。
允许代理在找到目标后继续探索的想法与代理距离目标状态越近，就越有可能处于可以立即更新的状态有关。]]></description>
      <guid>https://stackoverflow.com/questions/1836731/qlearning-and-never-ending-episodes</guid>
      <pubDate>Wed, 02 Dec 2009 23:53:13 GMT</pubDate>
    </item>
    </channel>
</rss>