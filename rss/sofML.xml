<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 01 Apr 2024 21:13:04 GMT</lastBuildDate>
    <item>
      <title>使用 pydotplus 可视化决策树</title>
      <link>https://stackoverflow.com/questions/78257646/visualization-a-decision-trees-with-pydotplus</link>
      <description><![CDATA[在决策树项目中
我写了这段代码，但是出现了具体的错误，我咨询了AI，问题没有解决，你可以看看问题出在哪里。
将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
从sklearn导入预处理
df = pd.read_csv(&#39;E:\mostafa文件夹\mashin学习\S5recommendersystems\Files\drug200.csv&#39;)
df.head()
df.describe()
df.列
x = df[[&#39;年龄&#39;, &#39;性别&#39;, &#39;血压&#39;, &#39;胆固醇&#39;, &#39;Na_to_K&#39;]].values
X
y = df[[&#39;药物&#39;]].值
y
从sklearn导入预处理
le_sex = 预处理.LabelEncoder()
le_sex.fit([&#39;F&#39;,&#39;M&#39;])
x[:,1] = le_sex.transform(x[:,1])


le_BP = 预处理.LabelEncoder()
le_BP.fit([ &#39;低&#39;, &#39;正常&#39;, &#39;高&#39;])
x[:,2] = le_BP.transform(x[:,2])


le_Chol = 预处理.LabelEncoder()
le_Chol.fit([ &#39;正常&#39;, &#39;高&#39;])
x[:,3] = le_Chol.transform(x[:,3])

x[0:4]
从 sklearn.model_selection 导入 train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=3)

print(&#39;火车形状：&#39;,x_train.shape,y_train.shape)
print(&#39;测试形状：&#39;,x_test.shape,y_test.shape)
从 sklearn.tree 导入 DecisionTreeClassifier

树= DecisionTreeClassifier（标准=“熵”，max_深度= 6）

树.fit(x_train,y_train)
pretree = tree.predict(x_test)

打印（前树[0:5]）
打印（y_测试[0:5]）
从 sklearn 导入指标
print(&quot;DecisionTrees 的准确率：&quot;,metrics.accuracy_score(y_test, pretree))
从 io 导入 StringIO
导入 pydotplus
将 matplotlib.image 导入为 mpimg
从 sklearn.tree 导入 DecisionTreeClassifier
从sklearn.tree导入export_graphviz
%matplotlib 内联
点数据 = StringIO()
特征名称 = df.columns
文件名 = &#39;mosi.png&#39;

out = export_graphviz(树,feature_names = featuresnames)
从sklearn.tree导入export_graphviz

点数据 = StringIO()
文件名 = &#39;ee.png&#39;
#featurenames = df.columns[0:5]

out = export_graphviz(tree, feature_names=df.columns[0:5], out_file=dot_data, class_names= np.unique(y_train),filled=True,special_characters=True,rotate=False)

图 = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png(文件名)
img = mpimg.imread(文件名)
plt.figure(figsize=(100, 200))
plt.imshow(img, 插值=&#39;最近&#39;)


这个问题取自这一行
out = export_graphviz(tree, feature_names=df.columns[0:5], out_file=dot_data, class_names= np.unique(y_train),filled=True,special_characters=True,rotate=False)
&lt;来自“C:\Users\PARDAZESHGARA\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\tree\init.py”的模块“sklearn.tree” &#39;&gt;不是估计器实例。
大家帮帮我！！！]]></description>
      <guid>https://stackoverflow.com/questions/78257646/visualization-a-decision-trees-with-pydotplus</guid>
      <pubDate>Mon, 01 Apr 2024 20:27:09 GMT</pubDate>
    </item>
    <item>
      <title>Tengo el错误“无法解析导入“keras.preprocessing.text”PylancereportMissingImports”[关闭]</title>
      <link>https://stackoverflow.com/questions/78257469/tengo-el-error-import-keras-preprocessing-text-could-not-be-resolvedpylancere</link>
      <description><![CDATA[附加的代码不允许我将文本库与 keras 一起使用，我收到以下错误
“导入“keras.preprocessing.text”” “无法解决PylancereportMissingImports”
导入json
将张量流导入为 tf
从张量流导入keras
from keras.preprocessing.text import Tokenizer #--&gt;;错误
从 keras.preprocessing.sequence 导入 pad_sequences


我希望能够使用该库或找到等效的库]]></description>
      <guid>https://stackoverflow.com/questions/78257469/tengo-el-error-import-keras-preprocessing-text-could-not-be-resolvedpylancere</guid>
      <pubDate>Mon, 01 Apr 2024 19:45:40 GMT</pubDate>
    </item>
    <item>
      <title>损失函数在梯度提升中的作用是什么？</title>
      <link>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</link>
      <description><![CDATA[在梯度提升中，可以使用不同的损失函数。例如，在 sklearn 的 GradientBoostingRegressor 中，可能的损失函数有：“squared_error”、“absolute_error”、“huber”和“quantile”损失函数。
我了解损失函数在梯度下降（而不是梯度提升）中的影响。例如，与绝对误差损失函数相比，平方误差损失函数对大误差的惩罚更大。我们可以在梯度提升的情况下说类似的话吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</guid>
      <pubDate>Mon, 01 Apr 2024 18:03:20 GMT</pubDate>
    </item>
    <item>
      <title>无法解释指标标识符 - scikeras.wrappers.KerasRegressor</title>
      <link>https://stackoverflow.com/questions/78257033/metric-identfier-cannot-be-interpreted-scikeras-wrappers-kerasregressor</link>
      <description><![CDATA[我正在尝试使用 scikeras.wrappers.KerasRegressor 调整超参数，但遇到了如下问题：
代码：
 # 定义一个函数来创建 lstm_model 的实例
def create_lstm_model():
    
    模型=顺序（[
            LSTM(5, input_shape = (Xtrain.shape[1], Xtrain.shape[2]), dropout = 0.1, 激活 = &#39;tanh&#39;, return_sequences = True),
            LSTM(10, dropout = 0.05, 激活 = &#39;tanh&#39;),
            密集（5，激活=&#39;relu&#39;），
            密集(1)
        ]）
    model.compile(优化器 = tf.keras.optimizers.Adam(), 损失 = tf.keras.losses.MeanSquaredError(), 指标 = [keras.metrics.MeanSquaredError()])
    
    返回模型

#为网络创建sklearn模型
模型 = KerasRegressor(build_fn = create_lstm_model, verbose = 1)

#参数网格
批次 = [16, 32]
历元 = [3, 4]

param_grid = dict(batch_size = 批次, epochs = epochs)

网格 = GridSearchCV(估计器 = 模型,
                    参数网格 = 参数网​​格,
                    简历 = 3)
grid.fit（Xtrain，ytrain，validation_data =（Xvalidation，yvalidation））

错误：
&lt;前&gt;&lt;代码&gt; fn_or_cls = keras_metric_get(公制)
  文件“/home/aaa/Desktop/aaa/aaa/2024-gold-price-prediction-with-lstm-model/.venv/lib/python3.10/site-packages/keras/src/metrics/__init__.py” ;，第 204 行，在 get 中
    raise ValueError(f“无法解释指标标识符：{identifier}”)
ValueError：无法解释指标标识符：损失

我从更复杂的代码开始，并在故障排除期间将其简化到最低限度。我什至试图从模型函数中删除指标。
您对我的代码有什么问题有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257033/metric-identfier-cannot-be-interpreted-scikeras-wrappers-kerasregressor</guid>
      <pubDate>Mon, 01 Apr 2024 18:02:32 GMT</pubDate>
    </item>
    <item>
      <title>带有注意力图执行错误的 LSTM 掩码</title>
      <link>https://stackoverflow.com/questions/78256963/lstm-masking-with-attention-graph-execution-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78256963/lstm-masking-with-attention-graph-execution-error</guid>
      <pubDate>Mon, 01 Apr 2024 17:43:41 GMT</pubDate>
    </item>
    <item>
      <title>为回归数值数据实现 ResNet Multi Output</title>
      <link>https://stackoverflow.com/questions/78255976/implementing-resnet-multi-output-for-numerical-data-for-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78255976/implementing-resnet-multi-output-for-numerical-data-for-regression</guid>
      <pubDate>Mon, 01 Apr 2024 14:15:11 GMT</pubDate>
    </item>
    <item>
      <title>ONNX 模型池层转换器不支持称为扩张的属性</title>
      <link>https://stackoverflow.com/questions/78255741/onnx-model-pooling-layer-converter-does-not-support-attribute-called-dilations</link>
      <description><![CDATA[我在尝试使用 SnapChat 提供的多对象笔记本中的 ML 模型时遇到错误，当我导入 ML 模型时出现错误：
“D:/Downloads/best (6).onnx 的资源导入失败：‘/model.8/m/MaxPool’层出现异常：ONNX 模型池层转换器不支持名为 dilations 的属性”,
我不确定如何修复它以及问题是什么，因为它之前工作得很好。谢谢！
错误
我尝试使用其他笔记本转换为 .onnx 模型，但似乎没有效果]]></description>
      <guid>https://stackoverflow.com/questions/78255741/onnx-model-pooling-layer-converter-does-not-support-attribute-called-dilations</guid>
      <pubDate>Mon, 01 Apr 2024 13:25:09 GMT</pubDate>
    </item>
    <item>
      <title>解决神经网络训练期间的错误</title>
      <link>https://stackoverflow.com/questions/78255508/solving-error-during-neural-network-training</link>
      <description><![CDATA[这是我的代码，它给出了这样的错误，我需要帮助来解决这个问题。
train_loader = DataLoader(train_data,batch_size=32)
test_loader = DataLoader(test_data,batch_size=32,shuffle=False)
device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
网络类（nn.Module）：
    def __init__(自身):
        超级（网络，自我）.__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, 填充=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        self.batchnorm1 = nn.BatchNorm2d(32)
        self.batchnorm2 = nn.BatchNorm2d(64)
        self.batchnorm3 = nn.BatchNorm2d(128)
        self.batchnorm4 = nn.BatchNorm2d(256)
        self.fc1 = nn.Linear(256 * 4 * 4, 512)
        self.fc2 = nn.Linear(512, 256)
        self.fc3 = nn.Linear(256, 100) # Cifar100 的 100 个类

    def 前向（自身，x）：
        x = self.pool(F.relu(self.batchnorm1(self.conv1(x))))
        x = self.pool(F.relu(self.batchnorm2(self.conv2(x))))
        x = self.pool(F.relu(self.batchnorm3(self.conv3(x))))
        x = self.pool(F.relu(self.batchnorm4(self.conv4(x))))
        x = x.view(-1, 256 * 4 * 4)
        x = self.dropout(x)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        返回x

网络 = Network().to(设备)

opt = Adam(network.parameters(),lr=1e-4)
loss_function = nn.CrossEntropyLoss()
对于范围（20）内的纪元：
    总损失= 0
    对于我，批量枚举（train_loader）：
        输入=批量[0].to(设备)
        目标 = 批处理[1].to(设备)
        y = 网络（输入）
        损失值 = 损失函数(y,目标)
        loss_value.backward()
        opt.step()
        总损失 += loss_value.item()
        print(f&quot;{total_loss / (i + 1)} ------ &gt; {i}&quot;)

我的错误是：“ValueError：预期输入batch_size (8) 与目标batch_size (32) 匹配。”
我还有第二个问题：我目前正在使用卷积网络在 CIFAR100 数据集上训练模型，但是从我尝试的各种模型获得的准确率非常低（损失约为 5，准确度约为 1%）。我不知道该怎么做才能选择更好的模型。我尝试了很多不同的模型，但我不想使用预先训练的模型；我想建立自己的。
请通过修改代码解决批量问题，并介绍为 CIFAR100 数据集构建合适模型的解决方案。
最美好的祝愿]]></description>
      <guid>https://stackoverflow.com/questions/78255508/solving-error-during-neural-network-training</guid>
      <pubDate>Mon, 01 Apr 2024 12:36:57 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 GAN 制作一个关于 DR 检测的项目，并尝试运行“models_from_json”，但它不起作用</title>
      <link>https://stackoverflow.com/questions/78255418/i-am-making-a-project-on-dr-detection-using-gan-and-trying-to-run-models-from-j</link>
      <description><![CDATA[所以在我的代码中，我尝试基本上从 json 中获取现有模型，但它不起作用
从 keras.models 导入顺序
从 keras.layers 导入 Convolution2D
从 keras.layers 导入 MaxPooling2D
从 keras.layers 导入扁平化
从 keras.layers 导入密集、激活、BatchNormalization
**从 keras.models 导入 model_from_json**


with open(&#39;model/train.json&#39;, &quot;r&quot;) 作为 json_file:
    load_model_json = json_file.read()
    加载模型 = model_from_json(加载模型_json)

loaded_model.load_weights(“模型/train.h5”)
loaded_model._make_predict_function()
打印（loaded_model.summary（））

我收到此错误：-
 with open(&#39;model/train.json&#39;, &quot;r&quot;) 作为 json_file：
FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;model/train.json&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/78255418/i-am-making-a-project-on-dr-detection-using-gan-and-trying-to-run-models-from-j</guid>
      <pubDate>Mon, 01 Apr 2024 12:16:19 GMT</pubDate>
    </item>
    <item>
      <title>随机森林项目</title>
      <link>https://stackoverflow.com/questions/78255277/randomforest-project</link>
      <description><![CDATA[我对机器学习非常陌生，这是我作为大学课程的一部分正在从事的第一个项目。我选择了英国足球比赛。我选择使用随机森林。
使用不同的来源，我成功地获得了 20 年的上述比赛数据，清理了数据并构建了我的模型。
但是，我被困住了。我如何真正让模型对未来的比赛进行预测？
谢谢
我尝试加载模型，然后使用仅填充“日期”、“Home_Team”和“Away_Team”列的 CSV 文件，将其他列留空，以便模型预测这些值 - 这是执行此操作的正确方法吗？ 
更新：
谢谢 - 请参阅用于构建模型的代码；
从 sklearn.ensemble 导入 RandomForestClassifier
train = matches[matches[“日期”] &lt; &#39;2012-06-01&#39;]
测试=匹配[匹配[“日期”]&gt; &#39;2012-06-01&#39;]
预测器 = [&#39;Home_Team&#39;、&#39;Away_Team&#39;、&#39;HT_Winner&#39;、&#39;FT_Winner&#39;、&#39;match_result&#39;、&#39;ht_match_result&#39;、&#39;HomeShots&#39;、&#39;AwayShots&#39;、&#39;HomeCorners&#39;、&#39;AwayCorners&#39;]
rf.fit(train[预测变量], train[“FT_Winner”])
preds = rf.predict(测试[预测变量])

用于未来预测的新 CSV：
导入 pandas 作为 pd

new_data_df = pd.read_csv(..)
预测 = model.predict(new_data_df)

更新后的 CSV 包含所有相同的列（仅填充了日期、Home_Team 和 Away_Team 列，因为这是当前唯一可用的信息以及希望模型进行预测的其他列。但是当尝试获取新的预测时CSV，我得到以下内容；
“特征名称的顺序必须与拟合时的顺序相同。\n”
值错误（消息）
ValueError：特征名称应与拟合期间传递的特征名称相匹配。
]]></description>
      <guid>https://stackoverflow.com/questions/78255277/randomforest-project</guid>
      <pubDate>Mon, 01 Apr 2024 11:46:02 GMT</pubDate>
    </item>
    <item>
      <title>C++ 如何创建带有游戏训练的神经网络？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78255012/c-how-to-create-a-neural-network-with-game-training</link>
      <description><![CDATA[互联网上关于如何用 C++ 创建神经网络的信息很少。我对 C++ 基础非常熟悉。我的目标是用 C++ 创建神经网络，以便它们可以玩特定的游戏。例如，您可以从使用井字游戏开始，然后是战舰、国际象棋，以及使用更复杂的游戏，如大富翁和其他游戏。
我使用了来自互联网、YouTube 来源观看视频的更多信息。我了解了不同类型的神经网络，其中一些对某些动作以分数形式给予奖励。
我了解 CNN 模型、RNN、GAN 等架构。我知道LSTM、GRU是用来存储上下文的，充当内存。权重在神经元中用于某种目的，各种激活函数有 ReLu、sigmoid、tanh。
我还想为需要 2 名以上玩家的游戏创建竞争性神经网络，例如大富翁和其他游戏。将代码从 Python 翻译为 C++ 并不是最好的解决方案。
更新：
我需要有关如何制作能够玩游戏以及制作竞争性神经网络的神经网络的信息。问题是如何在 C++ 中实现这一点。我刚刚用 JavaScript 编写了一个更简单的神经网络。
更新：
我问 OpenAI 的 ChatGPT 如何完成这个任务，他回答说：
要为井字游戏创建这样的神经网络，您需要编写 291 个“if else”块来记住游戏所有动作的模式。

实现国际象棋神经网络不可能做到这一点，因为国际象棋有超过 20 万个对手和你的走法模板。

我用 C++ 编写了一些代码。
#include ;
#include &lt;向量&gt;
#include &lt;字符串&gt;
#include &lt;功能&gt;

枚举类型激活{
    正弦，
    雷鲁，
    乙状结肠
};

类实用程序{
    模板&lt;类型名称 T&gt;
    bool static every(const std::vector&gt;&amp;mtx, const std::function cb) {
        for (const auto&amp; row : mtx) {
            for (const auto&amp; i : row) {
               if (cb(i) == 0) 返回 false；
            }
        }
        
       返回真；
    }
};

类代理{
民众：
    代理（）=默认；
 
私人的：
    浮重；
    类型激活激活；
    浮动平均值； // 消除？
};

类游戏{
民众：
    游戏（）=默认；
    〜游戏（）{}；
    
    bool walk(int x, int y, std::string 值) {
        if (x &gt;= 1 &amp;&amp; x &lt;= 3) {
            if (_mtx[x][y] == &quot; &quot;) {
                _mtx[x][y] = 值；
                返回真；
            }
        }
        
        返回假；
    }
    
    布尔 isEmpty() {
        auto = utils::every(_mtx, [](const std::string&amp; str) {
            返回 str == ” ”;
        });
        
        返回的是；
    }
    
私人的：
    std::vector&gt;&gt; _mtx = {
        {” ”、“ ”、“ ”},
        {” ”、“ ”、“ ”},
        {” ”、“ ”、“ ”}
    };
};

int main() {
    游戏游戏；
    代理代理；
    
    
    返回0；
}
]]></description>
      <guid>https://stackoverflow.com/questions/78255012/c-how-to-create-a-neural-network-with-game-training</guid>
      <pubDate>Mon, 01 Apr 2024 10:47:09 GMT</pubDate>
    </item>
    <item>
      <title>我只想在 python 中从该图像中提取图形部分，我该怎么做？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</link>
      <description><![CDATA[我想将右侧的两个图一起提取，也不能单独提取，两者都可以提取为一个（https://i.stack.imgur.com/RqwkB.jpg)
我不知道该尝试什么，我对此很陌生。我正在使用 python，我从图像中提取文本并将其保存在 csv 中
&lt;前&gt;&lt;代码&gt;导入cv2
将 numpy 导入为 np

# 加载图像
image_path = r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\1.jpg&#39;
图像 = cv2.imread(image_path)

# 将图像转换为灰度图
灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

# 应用高斯模糊来减少噪音
模糊 = cv2.GaussianBlur(灰色, (5, 5), 0)

# 应用 Canny 边缘检测
边缘 = cv2.Canny(模糊, 50, 150)

# 在边缘检测图像中查找轮廓
轮廓，_ = cv2.findContours（边缘，cv2.RETR_EXTERNAL，cv2.CHAIN_APPROX_SIMPLE）

# 根据面积过滤轮廓，找到最大的轮廓（假设图形是面积最大的）
轮廓=排序（轮廓，键= cv2.contourArea，反向= True）[：1]

# 创建一个掩码来提取图形区域
mask = np.zeros_like(灰色)
cv2.drawContours(蒙版, 轮廓, -1, (255, 255, 255), 厚度=cv2.FILLED)

# 将掩模应用于原始图像以提取图形
图= cv2.bitwise_and（图像，图像，掩码=掩码）

# 保存提取的图形图像
cv2.imwrite(r&#39;C:\Prarthana\PROJECTS\GitHub\MajorProject\Images\output\extracted_graph.jpg&#39;, graph)
]]></description>
      <guid>https://stackoverflow.com/questions/78254412/i-want-to-extract-only-the-graph-parts-from-this-image-in-python-how-do-i-go-abo</guid>
      <pubDate>Mon, 01 Apr 2024 08:33:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Textract 中获取 BLOCK 类型 LAYOUT_TITLE、LAYOUT_SECTION_HEADER 和 LAYOUT_xx 的内容</title>
      <link>https://stackoverflow.com/questions/78252584/how-to-get-content-of-block-types-layout-title-layout-section-header-and-layout</link>
      <description><![CDATA[我正在尝试使用 texttract 抓取多页 pdf。
需要根据其部分、子部分、表格来抓取 pdf 并格式化为 json。
在尝试使用布局和表格进行 UI 演示时，它完全能够显示布局标题、布局部分、布局文本、布局页脚、页码
在从 UI 演示下载的 csv 文件中可以观察到相同的信息：layout.csv 文件。
json 文件中也相同：analyzeDocResponse.json，但它包含所有内容（LINES、WORDS、LAYOUT_TITLE 和所有与布局相关的数据），我认为 textract 按顺序执行所有类型的块类型。
出于调试目的，我使用下面的代码来打印块的整个字典。
还有块类型及其相应的文本。
如果对 pdf 文件感兴趣：其 SmPC of Drugs：SmPC 文件
代码1：以json格式打印每个块。
&lt;前&gt;&lt;代码&gt;
def start_texttract_job（存储桶，文档）：
    响应 = texttract.start_document_analysis(
        文档位置={
            &#39;S3对象&#39;: {
                ‘桶’：桶，
                “名称”：文档
            }
        },
        FeatureTypes=[&quot;LAYOUT&quot;] # 您可以根据需要调整FeatureTypes
    ）
    返回响应[&#39;JobId&#39;]


def print_blocks(job_id):
    下一个令牌=无
    而真实：
        如果下一个令牌：
            响应 = texttract.get_document_analysis(JobId=job_id, NextToken=next_token)
        别的：
            响应 = texttract.get_document_analysis(JobId=job_id)

        for block in response.get(&#39;Blocks&#39;, []):
            打印（json.dumps（块，缩进= 4））

        next_token = response.get(&#39;NextToken&#39;, None)
        如果不是 next_token：
            休息

它正在按照 UI 演示打印类似信息，块类型为 LINES、WORDS、LAYOUT_
但是如果我尝试使用下面的代码打印每种块类型的文本，则无法打印 LAYOUT_ 相关的文本，不知道为什么，我是否遗漏了任何内容？
代码 2：打印块类型及其内容。
&lt;前&gt;&lt;代码&gt;
def start_texttract_job 与上面相同，LAYOUT。

def print_blocks(job_id):
    下一个令牌=无
    而真实：
        如果下一个令牌：
            响应 = texttract.get_document_analysis(JobId=job_id, NextToken=next_token)
        别的：
            响应 = texttract.get_document_analysis(JobId=job_id)

        for block in response.get(&#39;Blocks&#39;, []):
            print(f&quot;{block[&#39;BlockType&#39;]}: {block.get(&#39;Text&#39;, &#39;&#39;)}&quot;)

        next_token = response.get(&#39;NextToken&#39;, None)
        如果不是 next_token：
            休息

我可以看到块类型 LINES、WORDS 的值
但我认为，如下所示的布局为空，它是在块类型中进行识别，而不是其值。
布局标题：
布局图：
布局文本：
LAYOUT_SECTION_HEADER：
布局文本：
LAYOUT_SECTION_HEADER：
布局文本：
布局文本：
布局文本：
布局文本：
布局文本：
LAYOUT_PAGE_NUMBER：
LAYOUT_FOOTER：
任何帮助都受到高度赞赏，浏览了文档和其他一些 StackOverflow 问题，但找不到任何帮助。
Tetract 新手，对不起菜鸟 Q？，如果是的话:)]]></description>
      <guid>https://stackoverflow.com/questions/78252584/how-to-get-content-of-block-types-layout-title-layout-section-header-and-layout</guid>
      <pubDate>Sun, 31 Mar 2024 19:28:51 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机分类的增量学习[关闭]</title>
      <link>https://stackoverflow.com/questions/78248733/incremental-learning-for-support-vector-machines-classification</link>
      <description><![CDATA[我目前正在尝试为 Cawenbergs 和 Poggio 的增量和减量 SVM 算法找到一个好的实现。我找到了这个： Incremental-SVM-Learning-in- MATLAB，但我不太明白该算法在MatLab代码中是如何实现的。
我试图深入分析它并研究它，但仍然没有成功地理解它。我正在寻求一些帮助来理解代码，甚至寻求其他具有更清晰实现的解决方案。
非常欢迎任何帮助，你会给我一个很大的帮助！
这是我目前关注的算法：
Cawenbergs 和 Poggio 算法]]></description>
      <guid>https://stackoverflow.com/questions/78248733/incremental-learning-for-support-vector-machines-classification</guid>
      <pubDate>Sat, 30 Mar 2024 16:45:09 GMT</pubDate>
    </item>
    <item>
      <title>如何将预训练的拥抱脸模型转换为.pt并在本地完全运行？</title>
      <link>https://stackoverflow.com/questions/78210297/how-to-convert-pretrained-hugging-face-model-to-pt-and-run-it-fully-locally</link>
      <description><![CDATA[我正在尝试将此模型转换为.pt格式。它对我来说工作得很好，所以我不想对其进行微调。如何将其导出为.pt并运行界面？
我尝试使用它转换为 .pt：
从变压器导入 AutoConfig、AutoProcessor、AutoModelForCTC、AutoTokenizer、Wav2Vec2Processor
导入库
进口火炬



# 定义模型名称
model_name = “UrukHan/wav2vec2-俄罗斯”

# 加载模型和分词器
config = AutoConfig.from_pretrained(model_name)
模型 = AutoModelForCTC.from_pretrained(model_name, config=config)
处理器 = Wav2Vec2Processor.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

# 将模型保存为.pt 文件
torch.save(model.state_dict(), &quot;model.pt&quot;)

# 如果需要的话也保存分词器
tokenizer.save_pretrained(“模型标记器”)

但不幸的是它没有运行界面：
model = AutoModelForCTC.from_pretrained(“model.pt”)
处理器 = AutoProcessor.from_pretrained(“model.pt”)


# 使用模型进行推理
FILE = &#39;这里是 wav.wav&#39;
音频，_ = librosa.load（文件，sr = 16000）
音频=列表（音频）
def map_to_result(batch):
  使用 torch.no_grad()：
    input_values = torch.tensor(batch, device=“cpu”).unsqueeze(0) #, device=“cuda”
    logits = 模型(input_values).logits
  pred_ids = torch.argmax(logits, dim=-1)
  批处理=处理器.batch_decode(pred_ids)[0]
  退货批次
映射到结果（音频）
打印（映射到结果（音频））


模型.eval()

并遇到错误：
`model.pt 不是本地文件夹，也不是“https://huggingface.co/models”上列出的有效模型标识符
`]]></description>
      <guid>https://stackoverflow.com/questions/78210297/how-to-convert-pretrained-hugging-face-model-to-pt-and-run-it-fully-locally</guid>
      <pubDate>Sat, 23 Mar 2024 09:18:49 GMT</pubDate>
    </item>
    </channel>
</rss>