<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 02 Jul 2024 06:22:51 GMT</lastBuildDate>
    <item>
      <title>使用 Flask 进行 ML 项目时出现 500 内部服务器错误[关闭]</title>
      <link>https://stackoverflow.com/questions/78695216/500-internal-server-error-while-using-flask-for-ml-project</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78695216/500-internal-server-error-while-using-flask-for-ml-project</guid>
      <pubDate>Tue, 02 Jul 2024 05:46:46 GMT</pubDate>
    </item>
    <item>
      <title>一维数组 - 自动编码器</title>
      <link>https://stackoverflow.com/questions/78695139/1d-array-autoencoder</link>
      <description><![CDATA[机器学习相当新，致力于降低数据的复杂性。基本上，数据具有太阳能电池板的电流-电压曲线，即 100pts 电流和 100pts 电压。
我正在尝试减少数据并转换为 7 或 10 个特征，稍后我将使用这些特征对各种故障进行分类。
我使用自动编码器执行此操作，但结果非常糟糕？我遗漏了什么吗？
自动编码器是 1D 数组的好技术吗？ [
encoder_input = keras.Input(shape=(200,),name=&quot;curve_data&quot;)
x = keras.layers.Flatten()(encoder_input)
encoder_output = keras.layers.Dense(10,activation=&quot;relu&quot;)(x)

encoder = keras.Model(encoder_input,encoder_output, name=&quot;encoder&quot;)

decoder_input = keras.layers.Dense(200,activation=&quot;relu&quot;)(encoder_output)
decoder_output = keras.layers.Reshape((200,))(decoder_input)

opt = keras.optimizers.Adam(learning_rate=0.001)
autoencoder = keras.Model(encoder_input,decoder_output, name=&quot;autoencoder&quot;)
autoencoder.summary()
autoencoder.compile(opt,loss=&quot;mse&quot;)
autoencoder.fit(x_train,x_train,epochs=10, batch_size=16, validation_split=0.1)

]]></description>
      <guid>https://stackoverflow.com/questions/78695139/1d-array-autoencoder</guid>
      <pubDate>Tue, 02 Jul 2024 05:17:45 GMT</pubDate>
    </item>
    <item>
      <title>stackoverflow 如何检测重复的问题</title>
      <link>https://stackoverflow.com/questions/78695052/how-stackoverflow-detect-duplicate-questions</link>
      <description><![CDATA[我在网上搜索过，但搞不懂用于判断两个问题是否相似的特征是什么？所以请帮我解释一下用于检测两个问题是否重复的特征工程？另外，对于一个新问题，请告诉我我们如何检测一组彼此相似的问题？]]></description>
      <guid>https://stackoverflow.com/questions/78695052/how-stackoverflow-detect-duplicate-questions</guid>
      <pubDate>Tue, 02 Jul 2024 04:40:07 GMT</pubDate>
    </item>
    <item>
      <title>精确而强大的角点检测（噪声图像、脏污物体）</title>
      <link>https://stackoverflow.com/questions/78694749/precise-and-robust-corner-detection-noisy-image-dirty-object</link>
      <description><![CDATA[鉴于一定的质量控制要求，我们实施了一个自动化系统来测量钢板生产线的某些尺寸。问题是，有时系统不够强大，系统选择的像素不能反映我们人类推理认为的真实角落。该图像大约为 17 MPixels-
此简化的代码片段应代表我们的测量过程：
defcontrast_stretch(image, multiplier=1.0):
min_val = np.min(image)
max_val = np.max(image)
stretched = (image - min_val) * (255 / (max_val - min_val) * multiplier)
stretched = np.clip(stretched, 0, 255).astype(np.uint8)
returnstretched

def distance(pt1, pt2):
return math.sqrt((pt2[0] - pt1[0]) ** 2 + (pt2[1] - pt1[1]) ** 2)

defmeasure_diagonals(image, contours, px_to_mm):
refined_corners = []
for cnt in轮廓：
rect = cv2.minAreaRect(cnt)
box = cv2.boxPoints(rect)
box = np.int0(box)
corners = cv2.cornerSubPix(image, np.float32(box), (5, 5), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))
refined_corners.append(corners)
如果 len(refined_corners) &gt;= 2:
d1 = distance(refined_corners[0][0], refined_corners[0][2])
d2 = distance(refined_corners[1][0], refined_corners[1][2])
m1 = d1 * px_to_mm
m2 = d2 * px_to_mm
diff = abs(m2 - m1)
返回 m1, m2, diff
返回 None, None, None

# 加载校准数据
calibration_data = load_calibration_data(calibration_data_path)
mtx = calibration_data[&quot;mtx&quot;]
dist = calibration_data[&quot;dist&quot;]

# 加载图像
frame = cv2.imread(img_path)

# 不失真图像
frame_undistorted = cv2.undistort(frame, mtx, dist, None, mtx)

# 转换为灰度
gray = cv2.cvtColor(frame_undistorted, cv2.COLOR_BGR2GRAY)

# 应用双边滤波器
filtered_image = cv2.bilateralFilter(gray, 9, 125, 25)

# 增强对比度
enhanced_image =对比度拉伸（过滤图像）

# 检测轮廓
_, edge = cv2.threshold(enhanced_image, 140, 255, cv2.THRESH_BINARY)
contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 测量对角线
px_to_mm = 0.1 # 示例转换因子
m1, m2, diff = measure_diagonals(enhanced_image, contours, px_to_mm)

这是正确选择角的示例：
ROI 生成阈值（白点），然后是圆角子像素（黑色点）
这是一个错误选择角落的例子：
红色部分是我们知道的真正角落
我知道我们应该改善照明。我们正在测量一个大面积（&gt;4 米），并且要有一个能够生成明亮、均匀图像的照明系统极具挑战性，因此我们应用了大量软件校正，例如双边滤波器、增益和对比度增强器。]]></description>
      <guid>https://stackoverflow.com/questions/78694749/precise-and-robust-corner-detection-noisy-image-dirty-object</guid>
      <pubDate>Tue, 02 Jul 2024 01:35:14 GMT</pubDate>
    </item>
    <item>
      <title>HTML 文件输出未生成</title>
      <link>https://stackoverflow.com/questions/78694578/html-file-output-not-generating</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78694578/html-file-output-not-generating</guid>
      <pubDate>Mon, 01 Jul 2024 23:43:32 GMT</pubDate>
    </item>
    <item>
      <title>我尝试使用 hugginsface 中的 convert_graph_to_onnx.py，但出现此错误：“转换模型时出错：未安装模块 onnx！”</title>
      <link>https://stackoverflow.com/questions/78694557/i-tried-to-use-convert-graph-to-onnx-py-from-hugginsface-but-i-got-the-this-err</link>
      <description><![CDATA[我尝试使用此 [page][1] 中的示例使用导出模型功能
python convert_graph_to_onnx.py --framework pt --model bert-base-cased bert-base-cased.onnx

我收到一个错误，我需要使用 ONNX opset 版本 14，因此我使用了这个：
python convert_graph_to_onnx.py --framework pt --opset 14 --model bert-base-cased bert-base-cased.onnx

我收到此错误：

====== 将模型转换为 ONNX ====== convert_graph_to_onnx.py:361: FutureWarning: &#39;transformers.convert_graph_to_onnx` 包已弃用并将在 Transformers 版本 5 中删除
warnings.warn( ONNX opset 版本设置为：14 加载管道（模型：bert-base-cased，tokenizer：bert-base-cased）使用框架 PyTorch：2.3.1+cpu 发现输入 input_ids 形状：{0：&#39;batch&#39;，1：&#39;sequence&#39;} 发现输入 token_type_ids 形状：{0：&#39;batch&#39;，1：
&#39;sequence&#39;} 发现输入tention_mask 形状：{0：&#39;batch&#39;，1：
&#39;sequence&#39;} 发现输出 output_0 形状：{0：&#39;batch&#39;，1：
&#39;sequence&#39;} 发现输出 output_1 形状：{0：&#39;batch&#39;} 确保输入的顺序正确 position_ids 不存在于生成的输入列表中。生成的输入顺序：[&#39;input_ids&#39;,
&#39;attention_mask&#39;, &#39;token_type_ids&#39;] 转换模型时出错：
未安装模块 onnx！

我安装了 onnx==1.16.1
有人能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/78694557/i-tried-to-use-convert-graph-to-onnx-py-from-hugginsface-but-i-got-the-this-err</guid>
      <pubDate>Mon, 01 Jul 2024 23:34:48 GMT</pubDate>
    </item>
    <item>
      <title>在 cross_val_score 中获取 mac-avg f1-score</title>
      <link>https://stackoverflow.com/questions/78694297/get-mac-avg-f1-score-in-cross-val-score</link>
      <description><![CDATA[我有一个简单的二元分类实验。我正在尝试执行。
这是代码：
从 sklearn.linear_model 导入 LogisticRegression
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.svm 导入 LinearSVC
从 sklearn.model_selection 导入 cross_val_score
导入 xgboost 作为 xgb
models = [
RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0),
LinearSVC(),
MultinomialNB(),
LogisticRegression(random_state=0),
xgb.XGBClassifier(max_depth=3, 
objective=&#39;binary:logistic&#39;, 
n_estimators=100, 
num_classes=2, 
n_jobs = -1)
]
CV = 5
cv_df = pd.DataFrame(index=range(CV * len(models)))
entries = []
for model in models:
model_name = model.__class__.__name__
f1_score = cross_val_score(model, X_prep, labels,scoring = make_scorer(f1_score, average=&#39;weighted&#39;, labels=[2]), cv=CV)
for fold_idx, f1score in enumerate(f1_score):
entrys.append((model_name, fold_idx, f1score))

我收到以下错误消息：
-------------------------------------------------------------------------------
InvalidParameterError Traceback (most recent call last)
Cell In[34], line 22
20 for model in models:
21 model_name = model.__class__.__name__
---&gt; 22 f1_score = cross_val_score(model, X_prep, labels,scoring = make_scorer(f1_score, average=&#39;weighted&#39;, labels=[2]), cv=CV)
23 for fold_idx, f1score in enumerate(f1_score):
24 entities.append((model_name, fold_idx, f1score))

文件 ~/anaconda3/envs/gpt-ds/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:203，在validate_params.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)
200 to_ignore += [&quot;self&quot;, &quot;cls&quot;]
201 params = {k: v for k, v 在 params.arguments.items() 中，如果 k 不在 to_ignore 中}
--&gt; 203 验证参数约束 (
204 参数约束，参数，调用者名称 = 函数。__qualname__
205 )
207 尝试：
208 使用 config_context (
209 跳过参数验证 = (
210 首选跳过嵌套验证或全局跳过验证
211 )
212 ):

文件 ~/anaconda3/envs/gpt-ds/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:95，在验证参数约束 (参数约束，参数，调用者名称) 中
89 其他：
90 约束字符串 = (
91 f&quot;{&#39;, &#39;.join([str(c) for c in约束[:-1]])} 或&quot;
92 f&quot; {约束[-1]}&quot;
93 )
---&gt; 95 引发 InvalidParameterError(
96 f&quot;{caller_name} 的 {param_name!r} 参数必须是&quot;
97 f&quot; {约束_str}。得到的是 {param_val!r}。&quot;
98 )

InvalidParameterError: make_scorer 的 &#39;score_func&#39; 参数必须是可调用的。得到的是数组([0., 0., 0., 0., 0.])。

如何获取 cross_val_score 的 mac_avg f1 分数？]]></description>
      <guid>https://stackoverflow.com/questions/78694297/get-mac-avg-f1-score-in-cross-val-score</guid>
      <pubDate>Mon, 01 Jul 2024 21:32:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在 macOS 10.12 上运行 Core ML 模型？</title>
      <link>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</link>
      <description><![CDATA[https://developer.apple.com/documentation/coreml 提到 macOS 10.13+：

如何在 macOS 10.12 上运行 Core ML 模型？

在 Ubuntu 20.04 上创建的 Core ML 模型示例（使用 Python 3.10 和 torch 2.3.1 测试）：
git clone https://github.com/huggingface/exporters.git
cd exporters
pip install -e .
python -m exporters.coreml --model=distilbert-base-uncasederated/ --quantize=float32 
]]></description>
      <guid>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</guid>
      <pubDate>Mon, 01 Jul 2024 20:13:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 Detectron2 进行多任务问题分割和关键点检测</title>
      <link>https://stackoverflow.com/questions/78692534/multitask-issue-segmentation-keypoint-detection-with-detectron2</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78692534/multitask-issue-segmentation-keypoint-detection-with-detectron2</guid>
      <pubDate>Mon, 01 Jul 2024 13:32:45 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 Pytorch 提取视觉转换器的倒数第二层输出</title>
      <link>https://stackoverflow.com/questions/78691616/cannot-extract-the-penultimate-layer-output-of-a-vision-transformer-with-a-pytor</link>
      <description><![CDATA[我有以下模型，该模型使用我自己的 DataParallel 训练的数据集进行了调整：
model = timm.create_model(&#39;vit_base_patch16_224&#39;, pretrained=False)
model.head = nn.Sequential(nn.Linear(768, 512),nn.ReLU(),nn.BatchNorm1d(512),nn.Dropout(p=0.2),nn.Linear(512, 141))
checkpoint = torch.load(&#39;vit_b_16v3.pth&#39;)
checkpoint = {k.partition(&#39;module.&#39;)[2]: v for k, v in checkpoint.items()}
# 加载参数
model.load_state_dict(checkpoint)

但是，我不知道如何获取这种视觉转换器的倒数第二层输出。我尝试了本教程，但不起作用。我只想输入一张图片，并有一个 512 维向量来描述它。使用 Tensorflow 做这件事很容易，但在 Pytorch 中我却很挣扎。
我最后的几层如下：
(norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
(fc_norm): Identity()
(head_drop): Dropout(p=0.0, inplace=False)
(head): Sequential(
(0): Linear(in_features=768, out_features=512, bias=True)
(1): ReLU()
(2): BatchNorm1d(512, eps=1e-05, motivation=0.1, affine=True, track_running_stats=True)
(3): Dropout(p=0.2, inplace=False)
(4): Linear(in_features=512, out_features=141, bias=True)
)
)
]]></description>
      <guid>https://stackoverflow.com/questions/78691616/cannot-extract-the-penultimate-layer-output-of-a-vision-transformer-with-a-pytor</guid>
      <pubDate>Mon, 01 Jul 2024 10:16:39 GMT</pubDate>
    </item>
    <item>
      <title>Roboflow Vs. Darknet 用于生成权重文件和创建模型</title>
      <link>https://stackoverflow.com/questions/78691574/roboflow-vs-darknet-for-generating-weight-file-and-creating-the-model</link>
      <description><![CDATA[我有一个 YoloV8 数据文件格式，它是手动完成的数据（图像）注释。
生成模型并因此产生权重文件的最有效和最直接的方法是什么？是通过以下命令使用 darknet 吗：
darknet.exe detector train data/obj.data yolo-obj.cfg backup\yolo-obj_2000.weights

然后使用类似下面的命令生成关联模型：
python tools/model_converter/convert.py cfg/yolov3.cfg weights/yolov3.weights weights/yolov3.h5

或者通过以下命令使用 Roboflow：
version.deploy(model_type=&quot;yolov8&quot;, model_path=f”{HOME}/runs/detect/train/&quot;)

在我看来，darknet 更难安装。]]></description>
      <guid>https://stackoverflow.com/questions/78691574/roboflow-vs-darknet-for-generating-weight-file-and-creating-the-model</guid>
      <pubDate>Mon, 01 Jul 2024 10:07:36 GMT</pubDate>
    </item>
    <item>
      <title>学习 Python 的最佳书籍 [关闭]</title>
      <link>https://stackoverflow.com/questions/78690958/best-book-to-learn-python</link>
      <description><![CDATA[寻求具有最新更新的最佳 Python 书籍推荐
我渴望从头开始学习 Python，并及时了解该语言的最新发展。随着 Python 的快速发展，我想确保自己学习的是最新的功能、最佳实践和行业标准。
您能否推荐一本全面且适合初学者的书，涵盖 Python 3.x（最好是最新版本 Python 3.10 或 3.11），并包含以下主题：

核心 Python 概念：变量、数据类型、控制结构、函数、面向对象编程等
数据分析和可视化：NumPy、Pandas、Matplotlib 和 Seaborn
Web 开发：Flask 或 Django、HTML、CSS 和 JavaScript 基础知识
机器学习和人工智能：scikit-learn、TensorFlow 和 Keras
最佳实践和编码标准：代码组织、调试和测试
]]></description>
      <guid>https://stackoverflow.com/questions/78690958/best-book-to-learn-python</guid>
      <pubDate>Mon, 01 Jul 2024 07:35:55 GMT</pubDate>
    </item>
    <item>
      <title>在 shap.Explainer() 中，我应该输入 classifier 还是 classifier.predict？那么，如何获取 shap 值？[关闭]</title>
      <link>https://stackoverflow.com/questions/78690391/in-shap-explainer-should-i-input-classifier-or-classifier-predict-then-how</link>
      <description><![CDATA[我正在使用 SHAP（Shapley Additive Explanations）。我理解工作流程必须是：将我的数据拆分为训练和测试，训练我的模型，运行 SHAP 解释器，获取 SHAP 值。
当然，我见过使用不同方法做同样事情的代码（有点像 Perl 哲学，但很好）。我搞不懂它们之间的区别。我已阅读 SHAP 文档，但未能理解正确的方法。
我已看到两者：

explainer = shap.Explainer(clf)
explainer = shap.Explainer (clf.predict, X train)

后来，为了获取 shap 值，我看到了：

explainer(X)
explainer(X_test)
explainer.shap_values(X_test) - 这是我唯一理解差异的。它返回一个 numpy 数组，而不是 shap 解释对象。

下面，我复制了一些我见过的例子。
在Towards Data Science中：
X_train, X_test, y_train, y_test = train_test_split(X, y)
clf.fit(X_train, y_train)

explainer = shap.Explainer(clf.predict, X_test)
shap_values = explainer(X_test)

在 SHAP 官方GitHub 页面（不是他们的文档）
explainer = shap.Explainer(clf)
shap_values = explainer(X)

在geeks for geeks和datacamp
X_train, X_test, y_train, y_test = train_test_split(X, y)
clf.fit(X_train, y_train)

解释器 = shap.Explainer(clf)
shap_values = explainer(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/78690391/in-shap-explainer-should-i-input-classifier-or-classifier-predict-then-how</guid>
      <pubDate>Mon, 01 Jul 2024 03:49:45 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret 设置独热编码</title>
      <link>https://stackoverflow.com/questions/74001472/pycaret-setup-for-one-hot-encoding</link>
      <description><![CDATA[我陷入了 Pycaret 中分类变量独热编码的问题。问题是，即使设置了我的分类变量，管道也会对分类变量应用规范化，我不知道我做错了什么。
首先，使用下面的代码一切正常：
from pycaret.classification import *
from pycaret.datasets import get_data
import pandas as pd
import numpy as np
import seaborn as sns
dataset = get_data(&#39;income&#39;)
dataset.dtypes

直到我开始设置和
exp_clf01 = setup( data = dataset
, target = &#39;income &gt;50K&#39;
, session_id = 123
, numeric_features = [&#39;age&#39;,&#39;education-num&#39;,&#39;capital-gain&#39;,&#39;capital-loss&#39;,&#39;hours-per-week&#39;]
, categorical_features = [&#39;workclass&#39;,&#39;education&#39;,&#39;marital-status&#39;,&#39;occupation&#39;,&#39;relationship&#39;,&#39;race&#39;,&#39;sex&#39;,&#39;native-country&#39;]
)
df_transformed = get_config(&quot;X_train&quot;)
df_transformed.head()

尝试查看数据框的头部后，它仅将独热编码应用于列 race，并将其他分类输入标准化，我不明白为什么。




age
workclass
education
education-num
marital-status
occupation
other列




46.0
0.303273
0.271186
11.0
0.101942
0.484643
...


27. 0
0.218620
0.412939
13.0
0.044165
0.484643
...


33.0
0.218557
0.568315
 14.0
0.448894
0.455449
...


60.0
0.218557
0.412673
13.0
0.448894
0.484286
&lt; td&gt;...


25.0
0.218620
0.063798
6.0
0.044165
0.229692
...




我该如何防止这种行为？]]></description>
      <guid>https://stackoverflow.com/questions/74001472/pycaret-setup-for-one-hot-encoding</guid>
      <pubDate>Sun, 09 Oct 2022 00:59:48 GMT</pubDate>
    </item>
    <item>
      <title>当setCar设置为true时，如何显示前提和后果？</title>
      <link>https://stackoverflow.com/questions/39066421/how-to-display-the-premise-and-consequence-when-the-setcar-is-set-to-true</link>
      <description><![CDATA[我想在 Weka 3.8.0 中运行 apriori 算法后，获取生成规则的每一行的前提和后果。
 apriori.setNumRules(NUMBER_OF_RULES);
apriori.setMinMetric(MINIMUM_CONFIDENCE);
apriori.setLowerBoundMinSupport(MINIMUM_SUPPORT);

apriori.setCar(true);

apriori.buildAssociations(instances);

我尝试使用下面的代码来获取规则，但它给出了一个异常
（weka.associations.ItemSet 无法转换为 weka.associations.AprioriItemSet）：
 AssociationRules arules = apriori.getAssociationRules();

此外，我尝试使用 getAllTheRules() 方法，但它给出了不同的结果。
 ArrayList&lt;Object&gt;[] arules = apriori.getAllTheRules();
System.out.println(((ItemSet)arules[0].get(1)).getRevision()); //12014
System.out.println(((ItemSet)arules[0].get(2)).getRevision()); //12014
System.out.println(((ItemSet)arules[0].get(5)).getRevision()); //12014
]]></description>
      <guid>https://stackoverflow.com/questions/39066421/how-to-display-the-premise-and-consequence-when-the-setcar-is-set-to-true</guid>
      <pubDate>Sun, 21 Aug 2016 16:30:51 GMT</pubDate>
    </item>
    </channel>
</rss>