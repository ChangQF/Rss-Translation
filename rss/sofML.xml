<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 26 Sep 2024 06:24:32 GMT</lastBuildDate>
    <item>
      <title>如何对高度相关的特征进行特征工程</title>
      <link>https://stackoverflow.com/questions/79025609/how-to-feature-engineer-a-highly-correlated-feature</link>
      <description><![CDATA[我正在创建一个分类模型，用于预测患者的急诊就诊次数。目标变量是患者是否去过急诊室，如果没有去过，则为 0，如果他们至少去过一次，则为 1。其中一个特征是患者过去去过急诊室的次数。该特征与目标高度相关，因为非零值对应目标中的 1，而 0 对应目标中的 0，因此我不得不将其删除。
但是，这可能是非常有用的信息，因为患者去过急诊室的次数越多，他们再次就诊的可能性就越高。我尝试了许多方法来设计该特征，例如将其转换为分类变量、对其进行分类，但即便如此，相关性仍然很高。
有没有办法设计这个特征以便也可以使用它？]]></description>
      <guid>https://stackoverflow.com/questions/79025609/how-to-feature-engineer-a-highly-correlated-feature</guid>
      <pubDate>Thu, 26 Sep 2024 05:18:24 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法的时间复杂度和空间复杂度度量</title>
      <link>https://stackoverflow.com/questions/79025437/machine-learning-algrorithms-time-complexity-and-space-complextiy-measurement</link>
      <description><![CDATA[我已经训练了几个模型来预测/检测数据集中的分类值。
现在我想看看在这两种情况下哪种模型表现最好：

时间复杂度（预测/检测的时间）
空间复杂度（模型预测/检测所需的空间（GPU/CPU））
我使用的一些模型如下
RF、CNN、MLP、RNN、LGBM、LSTM、KNN、GRU

由此我可以找到在检测/预测特定情况时可以使用更少时间和更少空间的最佳模型。
你能解释一下这个 python 代码/sudo 代码吗？]]></description>
      <guid>https://stackoverflow.com/questions/79025437/machine-learning-algrorithms-time-complexity-and-space-complextiy-measurement</guid>
      <pubDate>Thu, 26 Sep 2024 03:50:39 GMT</pubDate>
    </item>
    <item>
      <title>模型推理时出错：RangeError（长度）：无效值：唯一有效值为 0：1</title>
      <link>https://stackoverflow.com/questions/79025367/error-during-model-inference-rangeerror-length-invalid-value-only-valid-val</link>
      <description><![CDATA[我在运行 Flutter 应用相机、mlkit 姿势检测和自定义 tflite 模型（通过身体动作检测情绪）时总是遇到此错误，这两者都应连接起来运行并给出准确的值
我试图寻找导致该错误的原因，但找不到它]]></description>
      <guid>https://stackoverflow.com/questions/79025367/error-during-model-inference-rangeerror-length-invalid-value-only-valid-val</guid>
      <pubDate>Thu, 26 Sep 2024 03:11:17 GMT</pubDate>
    </item>
    <item>
      <title>SiteGPT 如何工作？他们使用微调、RAG 还是其他什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/79024774/how-does-sitegpt-work-do-they-use-fine-tuning-rag-or-something-else</link>
      <description><![CDATA[我最近遇到了 SiteGPT，它允许您根据您的网站或特定文档创建自定义聊天机器人。我很好奇它背后的底层技术。有人知道 SiteGPT 的底层工作原理吗？具体来说：

他们是否使用语言模型的微调？

是否使用检索增强生成 (RAG) 直接从提供的站点或文档中提取信息？

是否还有其他技巧或技术可以使聊天机器人根据站点的内容准确响应？

]]></description>
      <guid>https://stackoverflow.com/questions/79024774/how-does-sitegpt-work-do-they-use-fine-tuning-rag-or-something-else</guid>
      <pubDate>Wed, 25 Sep 2024 21:11:36 GMT</pubDate>
    </item>
    <item>
      <title>EfficientNet 中的迁移学习在二元分类任务中停留在 50%</title>
      <link>https://stackoverflow.com/questions/79024541/transfer-learning-in-efficientnet-for-binary-classification-task-stuck-at-50</link>
      <description><![CDATA[我一直在尝试在二元分类任务中使用 EfficientNet 进行迁移学习。
我的目录结构如下所示：
training
│── label0
└── label1

validation
│── label0
└── label1

我使用它来创建图像数据生成器：
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
rescale=1./255,
rotation_range=30, 
width_shift_range=0.0, 
height_shift_range=0.0,
sher_range=0.0, 
zoom_range=0.0, 
Horizo​​ntal_flip=True,
fill_mode=&#39;nearest&#39;
)
未应用任何增强
validation_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
&#39;training&#39;,
target_size=(240, 240), 
batch_size=128, 
class_mode=&#39;binary&#39;, # 二元分类
shuffle=True
)

validation_generator = validation_datagen.flow_from_directory(
&#39;validation&#39;, 
target_size=(240, 240),
batch_size=128,
class_mode=&#39;binary&#39;,
shuffle=True
)

输出为：
找到属于 2 个类别的 19747 张图像。
找到属于 2 个类别的 4938 张图像。

这是构建模型的代码：
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.applications import EfficientNetB1
from tensorflow.keras.models import Model
from tensorflow.keras import layer

NUM_CLASSES = 2
IMG_SIZE = 240
size = (IMG_SIZE, IMG_SIZE)

def build_model():
inputs = layer.Input(shape=(IMG_SIZE, IMG_SIZE, 3))

model = EfficientNetB1(include_top=False, input_tensor=inputs, weights=&quot;imagenet&quot;)

model.trainable = False

x = layer.GlobalAveragePooling2D(name=&quot;avg_pool&quot;)(model.output)
x = layer.BatchNormalization()(x)
# x = layer.Dense(128, 激活=&quot;relu&quot;)(x)
# top_dropout_rate = 0.2
# x = layer.Dropout(top_dropout_rate, 名称=&quot;dropout&quot;)(x)
# 输出 = layer.Dense(1, 激活=&quot;sigmoid&quot;, 名称=&quot;pred&quot;)(x)
输出 = layer.Dense(1, 激活=&quot;sigmoid&quot;, 名称=&quot;pred&quot;)(x)

模型 = tf.keras.Model(输入、输出、名称=&quot;EfficientNet&quot;)
优化器 = tf.keras.optimizers.Adam(learning_rate=1e-4)
model.compile(
optimizer=optimizer,
loss=&quot;binary_crossentropy&quot;,
metrics=[&quot;accuracy&quot;]
)

return model

你可以看到我尝试了很多方法只是为了让某些东西起作用但都无济于事。我将model.trainable设置为False，因为我正在遵循这个关于迁移学习的实现。我还没有完成第一步。我原本计划在达到 60-70% 后继续解冻，但我甚至无法达到 52%。
以下是我开始训练的方式：
model = build_model()
epochs = 50
hist = model.fit(train_generator, 
epochs=epochs, 
steps_per_epoch=len(train_generator), 
validation_data=validation_generator,
validation_steps=len(validation_generator))

并且在前十个时期，准确率和 val_accuracy 始终接近 50%，这只不过是随机猜测。
我尝试降低或增加学习率（1e-1 到 1e-6）、批量大小（32 - 256）、添加 dropouts（0.1 - 0.5），添加 relu 层（32 - 128），并确保图像属于正确的类别。我能做些什么来让模型真正学习？]]></description>
      <guid>https://stackoverflow.com/questions/79024541/transfer-learning-in-efficientnet-for-binary-classification-task-stuck-at-50</guid>
      <pubDate>Wed, 25 Sep 2024 19:42:31 GMT</pubDate>
    </item>
    <item>
      <title>尽管 np.where(np.isnan(X)) 没有返回任何内容，sklearn 仍会引发错误“输入 X 包含 NaN”[关闭]</title>
      <link>https://stackoverflow.com/questions/79024134/sklearn-raises-error-input-x-contains-nan-despite-np-wherenp-isnanx-return</link>
      <description><![CDATA[我正在尝试为著名的泰坦尼克号数据集制作一个简单的 Knearestneighbor 算法。尽管我的数据框似乎没有任何 NaN 值，但我还是不断收到标题中的错误。如何解决这个问题？
y = train_data[&quot;Survived&quot;]
features = [&quot;Fare&quot;, &quot;Sex&quot;]

X = train_data[features]
X.loc[:, &#39;Sex&#39;] = X.loc[:, &#39;Sex&#39;].apply(weigh_sex)
X = ct.fit_transform(X)

X_test = test_data[features]
X_test.loc[:, &quot;Sex&quot;] = X_test.loc[:, &quot;Sex&quot;].apply(weigh_sex)
X_test = ct.fit_transform(X_test)

print(np.where(np.isnan(X))) #即使放在 clf.fit() 之后，也不会返回任何内容

clf.fit(X, y)

predictions = clf.predict(X_test) #此行引发错误

完整回溯：
回溯（最近一次调用）：
文件“C:\pystuff\StatsSandbox\Titanic.py”，第 65 行，位于&lt;module&gt;
predictions = clf.predict(X_test) #此行引发错误
文件“C:\pystuff\learn\StatsSandbox\lib\site-packages\sklearn\neighbors\_classification.py”，第 266 行，在 predict 中
neigh_ind = self.kneighbors(X, return_distance=False)
文件“C:\pystuff\learn\StatsSandbox\lib\site-packages\sklearn\neighbors\_base.py”，第 804 行，在 kneighbors 中
X = self._validate_data(X, accept_sparse=&quot;csr&quot;, reset=False, order=&quot;C&quot;)
文件“C:\pystuff\learn\StatsSandbox\lib\site-packages\sklearn\base.py”，第 605 行，在 _validate_data 中
out = check_array(X，input_name=&quot;X&quot;，**check_params)
文件 &quot;C:\pystuff\learn\StatsSandbox\lib\site-packages\sklearn\utils\validation.py&quot;，第 957 行，在 check_array 中
_assert_all_finite(
文件 &quot;C:\pystuff\learn\StatsSandbox\lib\site-packages\sklearn\utils\validation.py&quot;，第 122 行，在 _assert_all_finite
_assert_all_finite_element_wise(
文件 &quot;C:\pystuff\learn\StatsSandbox\lib\site-packages\sklearn\utils\validation.py&quot;，第 171 行，在 _assert_all_finite_element_wise
raise ValueError(msg_err)
ValueError：输入 X 包含 NaN。
 ]]></description>
      <guid>https://stackoverflow.com/questions/79024134/sklearn-raises-error-input-x-contains-nan-despite-np-wherenp-isnanx-return</guid>
      <pubDate>Wed, 25 Sep 2024 17:26:01 GMT</pubDate>
    </item>
    <item>
      <title>鉴于训练和测试集完全不相交，可以使用哪些 ML/DL 模型来玩 Hangman 游戏？[关闭]</title>
      <link>https://stackoverflow.com/questions/79023327/what-ml-dl-models-can-be-used-to-play-the-game-hangman-given-the-training-and-t</link>
      <description><![CDATA[Hangman 是一款猜字游戏，玩家需要逐个字母猜出隐藏的单词。每次猜对都会显示单词中该字母的所有实例，而猜错则会减少玩家剩余的尝试次数。目标是在尝试次数用完之前猜出单词。隐藏单词的长度是可变的，最大尝试次数为 5 次。
我必须想出一个模型/算法来猜测隐藏字符串的字母（例如，如果隐藏单词是“mathematics”，输入是 _ a t h e _ a t i _ s，则模型理想情况下应该猜测“m”或“c”）。测试将通过模拟从完全隐藏的单词（仅下划线）开始的绞刑游戏来完成。
训练数据是来自英语的单词列表，测试数据将不包含任何这些给定的单词。
机器学习方法是首选，但不是强制性的。
我尝试在通过随机删除给定单词中的字母实例生成的数据上训练 BiLSTM 模型，然后为输入字符串中的每个位置（包括已经显示的单词）输出 27 个类别的 softmax（每个字母 1 个，填充字符 1 个）。由于训练集中的最大单词数为 32，因此我将输入字符串填充为 32 个字符。这并没有给出令人满意的结果。
还尝试了字节对编码 (BPE) 来提取训练词汇表中的相关子词，然后尝试从测试集中猜测单词是 BPE 词汇表中三个单词的组合。
我还能尝试什么？这会属于哪种问题？我在哪里可以阅读有关此类问题的更多信息？]]></description>
      <guid>https://stackoverflow.com/questions/79023327/what-ml-dl-models-can-be-used-to-play-the-game-hangman-given-the-training-and-t</guid>
      <pubDate>Wed, 25 Sep 2024 14:03:42 GMT</pubDate>
    </item>
    <item>
      <title>Jupyter Notebook 和 Python 脚本返回不同的 YOLOV8 实例分割掩码[关闭]</title>
      <link>https://stackoverflow.com/questions/79023273/jupyter-notebook-and-python-script-return-different-yolov8-instance-segmentation</link>
      <description><![CDATA[我一直在运行预先训练的 YOLOV8 模型来进行实例分割。为了进行测试和开发，我一直在使用 Anaconda Jupyter Notebook，在部署之前我将其转换为 Python 脚本。
这是来自 Jupyter Notebook 的（正确）掩码：

这是来自 Python 脚本的结果：

您可以看到 Python 结果在边缘处有奇怪的块我的头和手机。

两个版本的代码完全相同
Python 虚拟环境直接从 Jupyter 环境导出创建（我仔细检查了：Python 版本相同，所有库的版本也相同）
CUDA 版本相同
硬件相同（两个示例都在同一台机器上执行）

有人知道为什么会发生这种情况或我该如何修复它吗？]]></description>
      <guid>https://stackoverflow.com/questions/79023273/jupyter-notebook-and-python-script-return-different-yolov8-instance-segmentation</guid>
      <pubDate>Wed, 25 Sep 2024 13:53:07 GMT</pubDate>
    </item>
    <item>
      <title>将双线性采样特征映射回体素</title>
      <link>https://stackoverflow.com/questions/79022319/map-bilinear-sampled-features-to-voxel-back</link>
      <description><![CDATA[我正在开发一个专门用于双线性采样的类。我的目标是将从双线性采样过程中提取的特征映射到创建的体素网格中的适当位置。
实施步骤：
B = 批次

C = 通道

S = 视图数

D = 深度

H = 高度

W = 宽度

3 = x,y,z

2 = x,y

我创建了一个具有此形状 [B,D,H,W,3] 的体素
并且我有 360 个图像视图样本，尺寸为 [B,S,C,H,W]
第一步，我使用外部和内部将体素点（点云）投影到每个图像。然后我过滤了图像之外的点。
结果我得到了 valid_points = [B,S,H,W,2]
我从 valid_points 中对我的点进行了归一化，并创建了大小为 [B,S,H,W,2] 的网格，请注意，W 是有效点的数量，H = 1
然后我所做的是应用双线性采样，如代码所示：
valid_points = cur_coords[:, on_img[1]]

######### 将有效点归一化在 [-1, 1] 之间 ########
normalized_points = torch.zeros_like(valid_points)
normalized_points[:,:, 0] = 2.0 * (valid_points[:, :, 0] / (H_img - 1)) - 1.0 # 归一化y 坐标
normalized_points[:,:, 1] = 2.0 * (valid_points[:, :, 1] / (W_img - 1)) - 1.0 # [N, M&#39;,2]

grid = normalized_points.unsqueeze(1).cuda() # 形状 [S, H_out, W_out, 2]
sampled_features_with_location_list = []
for i in range(0,N):
img_s =camera_view_tensor[i].unsqueeze(0).permute(0, 3, 1, 2) #[B, C, H_in, W_in]
grid_s = grid[i].unsqueeze(0)
sampled_points = F.grid_sample(img_s, grid_s,mode=&#39;bilinear&#39;,
align_corners=None) # (B,N,C,H_out,W_out)
sampled_features_list.append(sampled_pointson)
sampled_points = torch.stack(sampled_features_list, dim=1) #[B = 1,S = 6,C= 3,H= 1,W =22965]

现在我想应用逆映射来提取 bev 特征。怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/79022319/map-bilinear-sampled-features-to-voxel-back</guid>
      <pubDate>Wed, 25 Sep 2024 10:14:39 GMT</pubDate>
    </item>
    <item>
      <title>SBERT 微调总是在完成所有 epoch 之前停止</title>
      <link>https://stackoverflow.com/questions/79021064/sbert-fine-tuning-always-stops-before-finish-all-epochs</link>
      <description><![CDATA[我正在使用 SBERT 预训练模型（特别是 MiniLM）进行一个包含 995 个分类的文本分类项目。我大部分时间都在按照此处列出的步骤进行操作，一切似乎都运行正常。
我的问题出现在实际训练模型时。无论我在训练参数中设置什么值，训练似乎总是提前结束，并且永远不会完成所有批次。例如，我设置了 num_train_epochs=1，但它最多只能达到 0.49 个 epoch。如果 num_train_epochs=4，它总是在 3.49 个 epoch 处结束。
这是我的代码：
from datasets import load_dataset
from sentence_transformers import (
SentenceTransformer,
SentenceTransformerTrainer,
SentenceTransformerTrainingArguments,
SentenceTransformerModelCardData,
)
from sentence_transformers.losses import BatchAllTripletLoss
from sentence_transformers.training_args import BatchSamplers
from sentence_transformers.evaluation import TripletEvaluator

model = SentenceTransformer(
&quot;nreimers/MiniLM-L6-H384-uncased&quot;,
model_card_data=SentenceTransformerModelCardData(
language=&quot;en&quot;,
license=&quot;apache-2.0&quot;,
model_name=&quot;all-MiniLM-L6-v2&quot;,
)
)

loss = BatchAllTripletLoss(model)
# 损失概述：https://www.sbert.net/docs/sentence_transformer/loss_overview.html
# 此特定损失方法：https://www.sbert.net/docs/package_reference/sentence_transformer/losses.html#batchalltripletloss

# 训练参数：https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments
args = SentenceTransformerTrainingArguments(
# 必需参数：
output_dir=&quot;finetune/model20240924&quot;,
# 可选训练参数：
num_train_epochs=1,
max_steps = -1,
per_device_train_batch_size=8,
per_device_eval_batch_size=8,
learning_rate=1e-5,
warmup_ratio=0.1,
fp16=True, # 如果您收到 GPU 无法在 FP16 上运行的错误，请设置为 False
bf16=False, # 如果您拥有支持 BF16 的 GPU，请设置为 True
batch_sampler=BatchSamplers.GROUP_BY_LABEL, # 
# 可选的跟踪/调试参数：
eval_strategy=&quot;no&quot;,
eval_steps=100,
save_strategy=&quot;epoch&quot;,
# save_steps=100,
save_total_limit=2,
logs_steps=100,
run_name=&quot;miniLm-triplet&quot;, # 如果在 W&amp;B 中使用`wandb` 已安装
)

trainer = SentenceTransformerTrainer(
model=model,
args=args,
train_dataset=trainDataset,
eval_dataset=devDataset,
loss=loss,
#evaluator=dev_evaluator,
)
trainer.train()

请注意，我没有使用评估器，因为我们正在创建模型，并在事后使用专用的测试值集对其进行测试。我的数据集结构如下：
Dataset({
features: [&#39;Title&#39;, &#39;Body&#39;, &#39;label&#39;],
num_rows: 23961
})

与 dev 数据集具有相同的结构，只是行数较少。这将提供以下输出：
 [1473/2996 57:06 &lt; 59:07，0.43 it/s，Epoch 0/1]
步骤训练损失
100 1.265600
200 0.702700
300 0.633900
400 0.505200
500 0.481900
600 0.306800
700 0.535600
800 0.369800
900 0.265400
1000 0.345300
1100 0.516700
1200 0.372600
1300 0.392300
1400 0.421900

TrainOutput(global_step=1473, training_loss=0.5003972503496366, metrics={&#39;train_runtime&#39;: 3427.9198, &#39;train_samples_per_second&#39;: 6.99, &#39;train_steps_per_second&#39;: 0.874, &#39;total_flos&#39;: 0.0, &#39;train_loss&#39;: 0.5003972503496366, &#39;epoch&#39;: 0.4916555407209613})

无论我如何调整值，我都无法让它完成所有批次。如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/79021064/sbert-fine-tuning-always-stops-before-finish-all-epochs</guid>
      <pubDate>Wed, 25 Sep 2024 03:55:44 GMT</pubDate>
    </item>
    <item>
      <title>ImportError: 导入 o​​nnx_cpp2py_export 时 DLL 加载失败：动态链接库 (DLL) 初始化例程失败</title>
      <link>https://stackoverflow.com/questions/78996950/importerror-dll-load-failed-while-importing-onnx-cpp2py-export-a-dynamic-link</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78996950/importerror-dll-load-failed-while-importing-onnx-cpp2py-export-a-dynamic-link</guid>
      <pubDate>Wed, 18 Sep 2024 07:08:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在 AWS 免费套餐上分配 GPU？</title>
      <link>https://stackoverflow.com/questions/60668849/how-to-allocate-gpus-on-aws-free-tier</link>
      <description><![CDATA[是否可以在 AWS 免费套餐上分配 GPU？如果可以，有人可以解释一下步骤吗？我尝试在 Amazon EC2 上分配 GPU。]]></description>
      <guid>https://stackoverflow.com/questions/60668849/how-to-allocate-gpus-on-aws-free-tier</guid>
      <pubDate>Fri, 13 Mar 2020 10:33:16 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“无法将类强制转换为data.frame？</title>
      <link>https://stackoverflow.com/questions/58870663/how-to-solve-cannot-coerce-class-to-data-frame</link>
      <description><![CDATA[问题出现在第 20 行：x3 &lt;- lm(Salary ~ ...

as.data.frame.default(data) 中的错误：无法将类‘c(&quot;train&quot;, &quot;train.formula&quot;)’强制转换为 data.frame

如何解决？
attach(Hitters)
Hitters

library(caret)
set.seed(123)
# 定义训练控制
set.seed(123) 
train.control &lt;- trainControl(method = &quot;cv&quot;, number = 10)
# 训练模型
x2 &lt;- train(Salary ~., data = x, method = &quot;lm&quot;,
trControl = train.control)
# 总结结果
print(x)
x3 &lt;- lm(Salary ~ poly(AtBat,3) + poly(Hits,3) + poly(Walks,3) + poly(CRuns,3) + poly(CWalks,3) + poly(PutOuts,3), data = x2)
summary(x3)
MSE = mean(x3$residuals^2)
print(&quot;均方误差：&quot;)
print(MSE)
]]></description>
      <guid>https://stackoverflow.com/questions/58870663/how-to-solve-cannot-coerce-class-to-data-frame</guid>
      <pubDate>Fri, 15 Nov 2019 05:09:08 GMT</pubDate>
    </item>
    <item>
      <title>努力理解 R 中完整的预测模型流程</title>
      <link>https://stackoverflow.com/questions/40127296/struggling-to-understand-complete-predictive-model-process-in-r</link>
      <description><![CDATA[我正在尝试使用现有客户和已流失客户的数据库来预测客户流失。到目前为止，我已经

获取现有客户和已流失客户的完整客户数据库以及客户服务变量等，用于预测。
将数据集随机分为 70/30 的训练和测试
使用 R，我训练了一个随机森林模型来预测，然后使用混淆矩阵将其与实际状态进行比较。
我已经使用测试数据运行该模型来检查识别流失者的准确性

我现在想做的是获取我们所有的现有客户并预测哪些客户会流失。我是否完全做错了，因为我需要预测是否会流失的很多现有客户已经被模型看到，因为他们出现在训练集中？
我是否应该使用不属于我需要进行预测的数据集的训练和测试集？]]></description>
      <guid>https://stackoverflow.com/questions/40127296/struggling-to-understand-complete-predictive-model-process-in-r</guid>
      <pubDate>Wed, 19 Oct 2016 09:24:33 GMT</pubDate>
    </item>
    <item>
      <title>开源神经网络库 [关闭]</title>
      <link>https://stackoverflow.com/questions/11477145/open-source-neural-network-library</link>
      <description><![CDATA[我正在寻找一个开源神经网络库。到目前为止，我已经研究过 FANN、WEKA 和 OpenNN。我还应该看看其他的吗？当然，标准是文档、示例和易用性。]]></description>
      <guid>https://stackoverflow.com/questions/11477145/open-source-neural-network-library</guid>
      <pubDate>Fri, 13 Jul 2012 19:32:11 GMT</pubDate>
    </item>
    </channel>
</rss>