<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 05 Dec 2023 15:15:31 GMT</lastBuildDate>
    <item>
      <title>缺陷的时间演变：预测剩余缺陷</title>
      <link>https://stackoverflow.com/questions/77607265/temporal-evolution-of-defects-predicting-remaining-defect</link>
      <description><![CDATA[我在一家公司的人工智能论文是预测 10 分钟后纸张上剩余的缺陷
-墨水被打印在金属片上
- 打印后直接出现一些缺陷（打印步骤后1秒拍照）
-但一段时间后，一些缺陷消失了，一些缺陷仍然存在
-Xtime之后我们再拍一张照片看看
我的目标是在打印一张新纸张并拍照后使用机器/深度学习预测 10 分钟或 Xtime 后剩余的缺陷
说明（涂上墨水后涂抹更多并覆盖疤痕等缺陷）
我需要帮助，任何想法都会被采纳
我有多种资源，如相机、机器等
我愿意接受任何想法]]></description>
      <guid>https://stackoverflow.com/questions/77607265/temporal-evolution-of-defects-predicting-remaining-defect</guid>
      <pubDate>Tue, 05 Dec 2023 15:12:18 GMT</pubDate>
    </item>
    <item>
      <title>我如何开始学习数据科学和机器学习请建议一条明确的路径？</title>
      <link>https://stackoverflow.com/questions/77607227/how-can-i-start-learning-data-science-and-machine-learning-please-suggest-a-well</link>
      <description><![CDATA[我希望以机器学习工程师的身份从事数据科学和机器学习的职业，但是我找不到一条有明确指导和布局良好的道路，这个领域似乎是多样化的，我只是感到困惑。
人们只是告诉要学习Python和像numpy、pandas、用于可视化的matplot等库，这很模糊，我已经知道Python了，我找不到合适的资源来从基础理论开始学习数据科学和机器学习基础知识，并在实践中通过建议提供帮助参考资料、书籍、讲座、课程我才刚刚开始。]]></description>
      <guid>https://stackoverflow.com/questions/77607227/how-can-i-start-learning-data-science-and-machine-learning-please-suggest-a-well</guid>
      <pubDate>Tue, 05 Dec 2023 15:04:53 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助...Apple ML 给出奇怪的结果</title>
      <link>https://stackoverflow.com/questions/77607078/need-help-apple-ml-giving-out-weird-results</link>
      <description><![CDATA[只是我想要创建的一些背景：
我的目标是使用 WLASL 数据集创建一个将手语转换为文本的模型。现在，从一开始就从kaggle下载这个模型，虽然数据集看起来相当全面，但每个类别的视频数量从5到13个不等，这显然需要训练的内容相当少。我决定尝试 Apple Create ML，而不是像 Tensorflow 或更复杂的深度学习框架，因为这样会简单得多。由于数据集在每个类别的视频方面非常有限，因此我在“手部动作分类器”中使用了所有 6 个数据增强。 （水平翻转、旋转、平移、缩放、插帧、丢帧）。虽然我知道这无法保存模型，但它肯定会大大提高准确性。请注意，我没有使用数据集中的所有 2000 个类（单词），而是仅使用了 300 个类的子集。我获得了 16% 的验证准确率，以及 90% 的所有增强训练准确率，因此我的模型显然过度拟合。所以我对 25 个类进行了同样的尝试，这次我获得了 42% 的验证准确率，以及 100% 的训练准确率。再次，过度拟合。我进入实时预览，几乎我尝试的每个迹象都被预测为错误。
现在，我决定使用“模型源”在侧边栏中。我不太确定它们的用途，但这是我尝试过的：
我将数据子集分成 2 个单独的模型源（16 个类，但数量仍然很高），分别获得了 83% 的验证准确率和 90% 的验证准确率。这两个模型源都使用所有数据增强。我的模型显然过度拟合，在两个来源中都有 100% 的训练准确度，但将其分成两个模型显然提高了我的准确度，当我在“实时预览”中测试这一点时，我自己做的每个 ASL 标志都能够以超过 90% 的置信度准确猜出每个单词。
所以我的问题是，即使我的数据有限（虽然增强确实增加了很多，但显然性能差异不应该这么大），我的模型如何表现得这么好？此外，将一个模型拆分为单独的模型源是否可行？我不确定“模型来源”有什么用？甚至是，所以我尝试了这个，不知怎的，我得到了更好的结果。如果可行，我如何将它们实现到一个快速应用程序中。我现在有点困惑，所以希望有人能告诉我发生了什么事。如果这不是一个可行的解决方案，有人可以提供另一个解决方案来说明我如何使用这个数据集吗？事先了解它会非常有帮助，但即使你不知道，你能帮助我吗？
非常感谢大家:)
PS：这是它的链接-：
Kaggle链接：https://www.kaggle.com/datasets/risangbaskoro/ wlasl 处理
原始论文github页面：https://github.com/dxli94/WLASL
抱歉这么长的消息。如果您需要任何图像来获得更多见解或更好的知识以提供更好的帮助，我很乐意提供它们。
再次感谢您]]></description>
      <guid>https://stackoverflow.com/questions/77607078/need-help-apple-ml-giving-out-weird-results</guid>
      <pubDate>Tue, 05 Dec 2023 14:43:09 GMT</pubDate>
    </item>
    <item>
      <title>运行“docker build -t file-name”时构建 docker 映像会导致错误。</title>
      <link>https://stackoverflow.com/questions/77606730/building-the-docker-image-results-in-error-while-running-docker-build-t-file-n</link>
      <description><![CDATA[我正在开发一个机器学习模型，我正在尝试使用 Docker 将其容器化，
运行命令时
docker build -t &lt;文件名&gt; &lt;位置&gt;
下面是docker文件。
&lt;前&gt;&lt;代码&gt;来自 python:3.11-alpine
复制 。 /应用程序
工作目录/应用程序
运行 pip install -rrequirements.txt
CMD Streamlit 运行 viz_app.python

下面是我收到的错误。
22.34 注意：此错误源自子进程，并且可能不是 pip 的问题。
22.34 错误：子进程退出并出现错误
22.34
22.34 × 用于安装构建依赖项的 pip 子进程未成功运行。
22.34 │ 退出代码：1
22.34 ╰─&gt;输出见上文。
22.34
22.34 注意：此错误源自子进程，并且可能不是 pip 的问题。
22.36
22.36 [通知] pip 新版本发布：23.0.1 -&gt; 23.3.1
22.36 [注意] 要更新，请运行： pip install --upgrade pip
------
Dockerfile:4
--------------------
   2 |复制 。 /应用程序
   3 |工作目录/应用程序
   4 | &gt;&gt;&gt;&gt;&gt;运行 pip install -rrequirements.txt
   5 | CMD Streamlit 运行 viz_app.python
--------------------
错误：无法解决：进程“/bin/sh -c pip install -rrequirements.txt”未成功完成：退出代码：1

我尝试使用以下方法解决特定问题。

我尝试通过提及“RUN pip install --upgrade pip”来升级 pip
还尝试安装需求文件的不同版本的软件包。

为了进一步参考，我添加了下面的requirement.txt 文件的包。
&lt;前&gt;&lt;代码&gt;numpy
熊猫
流光溢彩
scikit学习
绘图库
OpenCV-Python
张量流
分割模型
]]></description>
      <guid>https://stackoverflow.com/questions/77606730/building-the-docker-image-results-in-error-while-running-docker-build-t-file-n</guid>
      <pubDate>Tue, 05 Dec 2023 13:51:20 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow.js 散点图显示预测维护与实际维护相差甚远，我不明白为什么</title>
      <link>https://stackoverflow.com/questions/77606726/tensorflow-js-scatterplot-showing-predicted-vs-actual-maintenance-very-far-apart</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77606726/tensorflow-js-scatterplot-showing-predicted-vs-actual-maintenance-very-far-apart</guid>
      <pubDate>Tue, 05 Dec 2023 13:50:52 GMT</pubDate>
    </item>
    <item>
      <title>端到端 ML 项目上的模型训练器问题 - TypeError：__init__() 获得意外的关键字参数“trained_model_file_path”</title>
      <link>https://stackoverflow.com/questions/77606532/model-trainer-issue-on-end-to-end-ml-project-typeerror-init-got-an-unex</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77606532/model-trainer-issue-on-end-to-end-ml-project-typeerror-init-got-an-unex</guid>
      <pubDate>Tue, 05 Dec 2023 13:22:19 GMT</pubDate>
    </item>
    <item>
      <title>使用新数据集重新训练机器学习模型。我怎样才能执行它？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77605213/retraining-of-a-machine-learning-model-with-new-dataset-how-i-can-preform-it</link>
      <description><![CDATA[我使用 SVM 分类器模型创建了一个文本分类模型，该模型使用批量学习对具有 12 个类别的 20000 行数据的数据集进行学习，现在，我在该类别上获得了 10000 行新数据集，我想在旧数据集上重新训练新数据集，因为我有旧模型 pickle 文件，并且我不想从头开始重新训练模型。但是，我希望保留旧模型数据，而无需通过将由新数据集构建的新模型再次提供旧数据集。我如何执行此任务或存在哪些可能的方法。
我尝试过增量学习、传统学习。但是，没有人保留我的旧数据，因为它已被新数据取代。]]></description>
      <guid>https://stackoverflow.com/questions/77605213/retraining-of-a-machine-learning-model-with-new-dataset-how-i-can-preform-it</guid>
      <pubDate>Tue, 05 Dec 2023 09:48:47 GMT</pubDate>
    </item>
    <item>
      <title>搜索癌症相关医疗数据集进行 AI 模型训练</title>
      <link>https://stackoverflow.com/questions/77604720/searching-for-cancer-related-healthcare-datasets-for-ai-model-training</link>
      <description><![CDATA[我正在开发一个专注于医疗保健的人工智能 (AI) 模型，特别是癌症诊断、治疗和患者结果。我正在寻找能够深入了解各种类型的癌症、患者人口统计数据、治疗计划、生存率和其他相关临床数据的数据集。
详细信息：

所需数据类型：患者案例研究、临床试验数据、癌症成像数据集、遗传信息、治疗反应和纵向研究数据。
预期用途：训练 AI 模型，以协助肿瘤学的早期检测、个性化治疗计划和预后评估。
所需的特异性：涵盖多种癌症类型、阶段和治疗方式的数据。

我尝试过的：
在国家癌症研究所 (NCI) 和癌症影像档案库等存储库中搜索医学数据集。
审查了通过医疗保健提供者和研究网络（例如监测、流行病学和最终结果 (SEER) 计划）提供的数据集。
探索与癌症研究相关的数据集的学术出版物。
在哪里可以找到其他与癌症相关的医疗保健数据集？对公共和专有数据集（经过必要的道德批准才能使用）的建议将非常有价值。]]></description>
      <guid>https://stackoverflow.com/questions/77604720/searching-for-cancer-related-healthcare-datasets-for-ai-model-training</guid>
      <pubDate>Tue, 05 Dec 2023 08:23:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 1D 贝叶斯 CNN（通过使用工作 CNN 的 Convolution1DFlipout 和 DenseFlipout 替换卷积层和密集层而制成）无法训练？</title>
      <link>https://stackoverflow.com/questions/77602609/why-does-my-1d-bayesian-cnn-made-by-replacing-the-convolution-and-dense-layers</link>
      <description><![CDATA[我有一个 CNN 模型，它将波形（形状为 (601,3)，其中 601 是时间步数，3 是通道数）分类为噪声或信号。如下：
# 导入
将 numpy 导入为 np
从 sklearn.model_selection 导入 train_test_split
从 sklearn.preprocessing 导入 StandardScaler
将张量流导入为 tf
从张量流导入keras
从tensorflow.keras导入层

随机种子 = 42

tf.random.set_seed(random_seed)

模型 = keras.Sequential([
    Layers.Input(shape=(601, 3)), # 一维数据的输入形状
    层.Conv1D（32，kernel_size = 16，激活=&#39;relu&#39;），
    层.Conv1D（64，kernel_size = 16，激活=&#39;relu&#39;），
    层.Conv1D（128，kernel_size = 16，激活=&#39;relu&#39;），
    层.Flatten(),
    层.Dense(80, 激活=&#39;relu&#39;),
    层.Dense(80, 激活=&#39;relu&#39;),
    层.Dense(2, 激活=&#39;softmax&#39;)
]）

优化器 = keras.optimizers.Adam(learning_rate=0.001)
model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=优化器, 指标=[&#39;准确性&#39;])

纪元数 = 40
批量大小 = 48

历史= model.fit(X_train, y_train_encoded, epochs=num_epochs, batch_size=batch_size,
                    validation_data=(X_test, y_test_encoded), 详细=2)

# X_train 形状: (num_train_samples,601,3)
# X_test 形状: (num_test_samples,601,3)
# y_train_encoded 形状：(num_train_samples,2)
# y_test_encoded 形状：(num_test_samples,2)

上述模型在第 12 个 epoch 时运行良好，在所有 epoch 训练后准确率超过 99%。
当我尝试通过分别用 Convolution1DFlipout 和 DenseFlipout 层替换 Conv1D 和 Dense 层来将上述 CNN 转换为贝叶斯 CNN 时，问题就出现了。
# 导入
将tensorflow_probability导入为tfp

tfd = tfp.分布
tfpl = tfp.层

随机种子 = 42

tf.random.set_seed(random_seed)

num_training_samples = X_train.shape[0]
kl_divergence_fn = lambda q, p, _: tfd.kl_divergence(q, p) / num_training_samples

模型 = keras.Sequential([
    层.输入(形状=(601, 3)),
    tfpl.Convolution1DFlipout(
        32、kernel_size=16、activation=tf.nn.relu、kernel_divergence_fn=kl_divergence_fn、bias_divergence_fn=kl_divergence_fn)、
    tfpl.Convolution1DFlipout(
        64、kernel_size=16、activation=tf.nn.relu、kernel_divergence_fn=kl_divergence_fn、bias_divergence_fn=kl_divergence_fn)、
    tfpl.Convolution1DFlipout(
        128、kernel_size=16、activation=tf.nn.relu、kernel_divergence_fn=kl_divergence_fn、bias_divergence_fn=kl_divergence_fn)、
    层数.MaxPooling1D(pool_size=2),
    层.Flatten(),
    tfpl.DenseFlipout(80，激活=tf.nn.relu，kernel_divergence_fn=kl_divergence_fn，bias_divergence_fn=kl_divergence_fn),
    tfpl.DenseFlipout(80，激活=tf.nn.relu，kernel_divergence_fn=kl_divergence_fn，bias_divergence_fn=kl_divergence_fn),
    tfpl.DenseFlipout(2，激活=tf.nn.softmax，kernel_divergence_fn=kl_divergence_fn，bias_divergence_fn=kl_divergence_fn)
]）

优化器 = keras.optimizers.Adam(learning_rate=0.001)
model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=优化器, 指标=[&#39;准确性&#39;])

# 训练模型（与之前相同）
纪元数 = 40
批量大小 = 48

历史= model.fit(X_train, y_train_encoded, epochs=num_epochs, batch_size=batch_size,
                    validation_data=(X_test, y_test_encoded), 详细=2)

这个模型似乎没有收敛。有人可以帮我解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77602609/why-does-my-1d-bayesian-cnn-made-by-replacing-the-convolution-and-dense-layers</guid>
      <pubDate>Mon, 04 Dec 2023 21:17:27 GMT</pubDate>
    </item>
    <item>
      <title>从 .BIN 文件加载嵌入模型</title>
      <link>https://stackoverflow.com/questions/77600726/load-a-embeddings-model-from-a-bin-file</link>
      <description><![CDATA[我在从 .BIN 文件加载嵌入模型时遇到问题，当我尝试读取模型时，收到此消息错误：
UnicodeDecodeError：“utf-8”编解码器无法解码位置 6 中的字节 0xd6：无效的连续字节
这是我正在使用的脚本：
将 numpy 导入为 np
导入gensim
从 tqdm 导入 tqdm

## .TXT 文件中的字典：nlp.stanford.edu/projects/glove&gt;&gt;手套.6B.zip&gt;&gt;手套.6B.50d.txt
word_to_embeddings = dict()

open(&#39;glove.6B/glove.6B.50d.txt&#39;) 作为 f：
    对于 f 中的行：
        字 = line.split()[0]
        嵌入 = np.asarray(line.split()[1:], dtype=&#39;float32&#39;)
        word_to_embeddings[词] = 嵌入

w = 词到嵌入


## 在.BIN文件中写入字典
def save_word2vec_format（fname，词汇，向量大小，二进制= True）：
    “”“”以与原始使用的相同格式存储输入隐藏权重矩阵
    C word2vec-tool，用于兼容性。

    参数
    ----------
    文件名称：str
        用于保存矢量的文件路径。
    词汇：字典
        单词的词汇。
    矢量大小：整数
        词向量的维数。
    二进制：布尔值，可选
        如果为 True，则数据将以二进制 word2vec 格式保存，否则将以纯文本格式保存。
    ”“”
    
    Total_vec = len(词汇)
    将 gensim.utils.open(fname, &#39;wb&#39;) 用作 fout：
        fout.write(gensim.utils.to_utf8(“%s %s\n” % (total_vec, vector_size)))
        对于单词，tqdm(vocab.items()) 中的行：
            如果是二进制：
                行 = row.astype(np.float32)
                fout.write(gensim.utils.to_utf8(word) + b&quot; &quot; + row.tobytes())
            别的：
                fout.write(gensim.utils.to_utf8(“%s %s\n” % (word, &#39; &#39;.join(repr(val) for val in row))))

save_word2vec_format(binary=True, fname=&#39;ppl6B50d.bin&#39;, vocab=w,vector_size=50)

## 读取Word2Vec模型
new_model = gensim.models.keyedvectors.load_word2vec_format(&#39;ppl6B50d.bin&#39;,binary=True)
打印（新模型）

当我尝试加载嵌入模型时，收到此消息错误：UnicodeDecodeError: &#39;utf-8&#39; 编解码器无法解码位置 6 中的字节 0xd6: 无效的连续字节
我不明白出了什么问题，.BIN 文件创建时没有错误，但我无法加载它。任何人都可以帮我解决这个问题吗？？
非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77600726/load-a-embeddings-model-from-a-bin-file</guid>
      <pubDate>Mon, 04 Dec 2023 15:39:42 GMT</pubDate>
    </item>
    <item>
      <title>后端的大.pkl数据没有推送到github中</title>
      <link>https://stackoverflow.com/questions/77600252/large-pkl-data-for-backend-is-not-pushed-in-github</link>
      <description><![CDATA[我正在学习机器学习。最近，我从 tmdb 数据集制作了电影推荐模型，我使用 .pkl （二进制）文件中的模型处理数据。使用该数据制作后端，但是数据太大，无法推送到 github，我无法托管网站。
我正在尝试将已处理的数据推送到后端，但无法部署，因为它超出了文件大小的限制]]></description>
      <guid>https://stackoverflow.com/questions/77600252/large-pkl-data-for-backend-is-not-pushed-in-github</guid>
      <pubDate>Mon, 04 Dec 2023 14:33:48 GMT</pubDate>
    </item>
    <item>
      <title>为机器学习采购特定领域数据集的策略[关闭]</title>
      <link>https://stackoverflow.com/questions/77583636/strategies-for-sourcing-domain-specific-datasets-for-machine-learning</link>
      <description><![CDATA[我正在研究一个需要特定领域数据集的机器学习模型，特别是那些富含特定领域术语和工作流程的数据集。我有兴趣讨论识别和利用此类数据集的有效策略。这是我到目前为止所做的：
搜索开源平台（GitHub、Kaggle、Google 数据集搜索）。
探索研究论文和数据集的学术数据库。
考虑与行业合作伙伴签订数据共享协议。
问题：
有人可以分享他们有效采购和利用特定领域数据集的经验或策略吗？对挑战、数据预处理或机器学习模型集成（尤其是那些处理专门内容的模型）的见解将非常有价值。]]></description>
      <guid>https://stackoverflow.com/questions/77583636/strategies-for-sourcing-domain-specific-datasets-for-machine-learning</guid>
      <pubDate>Fri, 01 Dec 2023 07:31:33 GMT</pubDate>
    </item>
    <item>
      <title>在 LightGBM 中使用不同 boosting 类型的数据采样方法</title>
      <link>https://stackoverflow.com/questions/77578111/use-of-data-sample-methods-with-different-boosting-types-in-lightgbm</link>
      <description><![CDATA[我的问题
我不太清楚所有参数的用法以及它们如何相互交互（或应该使用）。
我所知道的
据我了解，LightGBM中有3种算法：

GBDT，默认的，使用 boosting
DART 是一种带有 dropout 的 boosting 算法
随机森林，不使用增强（确实如此，但仅在一次迭代中）

并且有两种数据采样策略：

Bagging，默认设置，用于集成学习
GOSS 选择更多对误差梯度贡献最大的数据（我们的想法是，我们需要对远离基线的数据进行更多训练），而对“弱”数据进行更少的训练。数据点（对误差梯度贡献较小的数据点）。

问题
所以我的问题如下：

Bagging 和 GOSS 似乎能够协同工作，但 data_sample_method 参数阻止我们这样做，因为它是一个字符串参数。这是有意为之的行为吗？
选择 GOSS 数据样本方法时，如果我们提供 bagging_fraction 和 bagging_freq 参数，会发生什么情况？文档没有提到这两个需要 badding 示例方法。
LightGBM的主要创新似乎是GOSS，但它并不是默认选择，这样选择的动机是什么？
最后，我们能够将 boosting_type=goss 作为参数传递。当我们这样做时会发生什么？算法会是GBDT，而数据样本策略是goss吗？

非常感谢您抽出时间。
祝你有美好的一天。]]></description>
      <guid>https://stackoverflow.com/questions/77578111/use-of-data-sample-methods-with-different-boosting-types-in-lightgbm</guid>
      <pubDate>Thu, 30 Nov 2023 11:34:21 GMT</pubDate>
    </item>
    <item>
      <title>是否可以从图像运行资产？</title>
      <link>https://stackoverflow.com/questions/77175532/is-it-possible-to-run-an-asset-from-an-image</link>
      <description><![CDATA[我正在尝试了解我能用 Dagster 真正做什么。
我有一些 Python 代码已经容器化并推送到容器注册表。
我想知道在 Dagster&#39;op 或资产中我是否可以读取这些图像并在我的 Kubernetes 集群上运行最终的管道。
例如，我可能有一个在 GCR 上执行一些乘法的图像。 Dagster 是否提供任何工具来提取此图像，然后允许我执行以下操作：
&lt;前&gt;&lt;代码&gt;@asset(PULL_IMAGE)
def my_asset():
    从 MY_IMAGE_CODE 导入函数_1、函数_2
    函数_1()

然后，我想使用 Dagster-kubernetes 在 Kubernetes 上运行这个管道。
我试图从 Dagster 文档中获取想法，但我找不到任何东西。
我查看了各种 GitHub 存储库，但其中许多都使用旧版本的 Dagster。
我跳进 https://docs.dagster.io/_apidocs/libraries/dagster-k8s  和 https://dagster.io/integrations/dagster-docker 但我我不太明白如何链接它们。]]></description>
      <guid>https://stackoverflow.com/questions/77175532/is-it-possible-to-run-an-asset-from-an-image</guid>
      <pubDate>Mon, 25 Sep 2023 20:28:10 GMT</pubDate>
    </item>
    <item>
      <title>如何在多个 GPU 上使用 Huggingface Trainer？</title>
      <link>https://stackoverflow.com/questions/75814047/how-to-use-huggingface-trainer-with-multiple-gpus</link>
      <description><![CDATA[假设我有以下模型（来自此脚本）：
从变压器导入 AutoTokenizer、GPT2LMHeadModel、AutoConfig

配置 = AutoConfig.from_pretrained(
    “gpt2”，
    vocab_size=len(分词器),
    n_ctx=上下文长度，
    bos_token_id=tokenizer.bos_token_id,
    eos_token_id=tokenizer.eos_token_id,
）
模型 = GPT2LMHeadModel(配置)

我目前正在为 Trainer 使用此训练参数：
从 Transformers 导入 Trainer、TrainingArguments

args = 训练参数(
    output_dir=“codeparrot-ds”，
    per_device_train_batch_size=32，
    per_device_eval_batch_size=32，
    评价_策略=“步骤”，
    评估步骤=5_000，
    记录步骤=5_000，
    梯度累积步数=8，
    num_train_epochs=1,
    权重衰减=0.1，
    热身步骤=1_000,
    lr_scheduler_type=“余弦”,
    学习率=5e-4,
    保存步骤=5_000，
    fp16=正确，
    Push_to_hub=真，
）

教练=教练（
    型号=型号，
    分词器=分词器，
    参数=参数，
    data_collat​​or = data_collat​​or，
    train_dataset=tokenized_datasets[“火车”],
    eval_dataset=tokenized_datasets[“有效”],
）
训练师.train()

我如何对此进行调整，以便训练器将使用多个 GPU（例如 8 个）？
我发现这个所以问题，但他们没有使用培训师，刚刚使用了 PyTorch 的 DataParallel
model = torch.nn.DataParallel(model, device_ids=[0,1])

Huggingface 有关使用多个 GPU 进行训练的文档对我来说并不是很清楚，也不明白没有使用 Trainer 的示例。相反，我发现这里他们添加了参数他们的 python 文件带有 nproc_per_node，但这对于他们的脚本来说似乎过于具体，并且不清楚一般如何使用。这与他们论坛上的这个讨论相反“Trainer 类自动处理多 GPU 训练，您无需执行任何特殊操作。”。所以这很令人困惑，因为一方面他们提到在多个 GPU 上进行训练需要做一些事情，并且还说训练器会自动处理它。所以我不知道该怎么办。]]></description>
      <guid>https://stackoverflow.com/questions/75814047/how-to-use-huggingface-trainer-with-multiple-gpus</guid>
      <pubDate>Wed, 22 Mar 2023 15:10:23 GMT</pubDate>
    </item>
    </channel>
</rss>