<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 08 May 2024 18:19:12 GMT</lastBuildDate>
    <item>
      <title>在训练用于分类文本数据的 ML 模型时，是否有方法可以优先考虑或提高特征重要性？</title>
      <link>https://stackoverflow.com/questions/78450312/is-there-a-way-to-prioritize-or-increase-feature-importance-while-training-a-ml</link>
      <description><![CDATA[我有一个文本数据集，其中包含产品描述。我需要将这些描述分类到不同的产品中。我正在使用 TFIDF 向量化将标记向量化为用于训练的特征。对于任何目标标签，是否有办法优先考虑或增加或减少某些特征或单词的重要性？
根据产品描述，我确定了某些关键字并对它们进行矢量化以训练机器学习模型。在某些描述中，可能存在与多个目标标签相关的多个关键字。在这种情况下，如果我可以给出某些关键字，其重要性高于其他关键字，那么它将帮助模型识别正确的标签或产品。有没有办法为这些特征分配权重？]]></description>
      <guid>https://stackoverflow.com/questions/78450312/is-there-a-way-to-prioritize-or-increase-feature-importance-while-training-a-ml</guid>
      <pubDate>Wed, 08 May 2024 17:33:10 GMT</pubDate>
    </item>
    <item>
      <title>如何强制模型使用变量</title>
      <link>https://stackoverflow.com/questions/78450279/how-to-force-a-model-to-use-a-variable</link>
      <description><![CDATA[我有用于训练二元分类模型的数据。
set.seed(1)
n &lt;- 20
dat &lt;- cbind.data.frame(target=as.factor(sample(0:1,n,T)),
                        价格=圆(rnorm(n)+1000,2),
                        var1=样本(1:n),
                        var2=round(rnorm(n),2),
                        var3=round(rnorm(n),2))

.
 目标价格 var1 var2 var3
1 1 1001.03 5 -0.95 1.16
2 0 1000.21 13 -0.02 -0.45
3 0 999.49 11 1.20 1.95
4 0 1000.95 7 0.71 0.86
5 1 1001.49 20 -0.44 1.07
6 0 999.45 10 0.78 -1.76
7 1 998.78 12 -1.64 -0.77
8 1 998.23 8 0.67 0.12

我想强制我的模型考虑我在做出的每个决策中指定的变量 price。
我将用一个例子来解释我的意思。
假设我正在使用由规则组成的随机森林模型，在这种情况下，我希望每个规则都有一个 price 变量。
这些都是很好的规则，因为每个规则都有一个变量价格
 价格&lt;=1001.49 &amp;变量1&gt;0.105
 var2&lt;=0.12&amp;价格&gt;1001.03 &amp;变量3&gt;-0.025
 价格≤998.23&amp;价格&gt;=997.23

这些都是不好的规则，我希望模型中没有这样的规则
var3&lt;=0.57 &amp; var3&gt;0.105
var2&lt;=0.12&amp; var2&gt;-1.005 &amp;变量3&gt;-0.025
变量1&lt;=6.5

我知道我无法影响模型本身，但也许我可以以某种方式更改数据集中的变量，最终迫使模型在每个决策中强制使用 price 变量。
作为测试，您可以使用此代码从经过训练的随机森林模型中提取规则。
库（inTrees）
库（随机森林）
规则 &lt;- randomForest(target~., dat, ntree=20) |&gt;
          RF2List（）|&gt;
          提取规则（数据）|&gt;
          唯一（）|&gt;
          getRuleMetric(dat[,-1], dat$target) |&gt;;
          pruneRule(dat[,-1], dat$target) |&gt;;
          buildLearner(dat[,-1], dat$target)

.
presentRules(规则, colnames(dat[,-1]))

    长度 频率 错误 条件 预测
[1，]“2” “0.35” “0” &quot;var1&lt;=15.5 &amp; var2&lt;=-0.05” “1”
[2，]“3” “0.2” “0” &quot;var1&lt;=13.5&amp; var2&gt;-0.05 &amp; var3&lt;=-0.315” “0”
[3，]“1” “0.1” “0” “var2&gt;1.255” “1”
[4，]“2” “0.1” “0” &quot;var1&gt;17 &amp; var2&gt;-1.55” “1”
[5，]“1” “0.1” “0” “var3≤-0.16” “0”
[6，]“2” “0.1” “0” &quot;var2&gt;-0.05 &amp; var3＞0.49” “0”
[7，]“1” “0.05” “0” “其他” “1”

正如您在此阶段所看到的，模型拒绝在其规则中使用变量 price。但我的任务的具体情况意味着我不需要不使用价格的规则。
总而言之，我的问题是这样的：
如何更改数据集以强制模型在每个规则中使用 price？]]></description>
      <guid>https://stackoverflow.com/questions/78450279/how-to-force-a-model-to-use-a-variable</guid>
      <pubDate>Wed, 08 May 2024 17:26:29 GMT</pubDate>
    </item>
    <item>
      <title>训练级联 R-CNN 时损失图中的随机峰值</title>
      <link>https://stackoverflow.com/questions/78449913/random-spikes-in-loss-graph-when-training-cascade-r-cnn</link>
      <description><![CDATA[我目前正在使用 MMDetection 训练 Cascade R-CNN 模型，并且我注意到训练期间损失图中出现随机峰值。我的配置如下：

纪元：100
学习率：0.0002
批量大小：4
优化器：带有梯度裁剪的 Adam
调度程序：我使用 LinearLR 和 CosineAnnealingLR 的预热策略

尽管使用一致的训练设置，这些峰值在整个训练过程中还是偶尔出现。如图所示
损失图
什么可能导致这些随机损失峰值，以及如何减轻它们？对于调试或稳定训练过程有什么具体建议吗？
我尝试过的：

验证数据集是否存在损坏或标签错误的图像。
将初始学习率降低至 0.0001，但没有看到显着改善。
调整了梯度裁剪范数，但尖峰仍然存在。
]]></description>
      <guid>https://stackoverflow.com/questions/78449913/random-spikes-in-loss-graph-when-training-cascade-r-cnn</guid>
      <pubDate>Wed, 08 May 2024 16:18:45 GMT</pubDate>
    </item>
    <item>
      <title>深度学习中的孪生网络和卷积网络有什么区别？</title>
      <link>https://stackoverflow.com/questions/78449190/what-are-the-differences-between-siamese-network-and-convolution-network-in-deep</link>
      <description><![CDATA[我对这个领域很陌生，我目前正在学习神经网络，并且接触过 CNN（卷积神经网络），但我看到有些人使用 Siamese 网络来处理图像数据
它们之间有什么区别，我应该使用哪个来进行图像分类/识别/相似性？]]></description>
      <guid>https://stackoverflow.com/questions/78449190/what-are-the-differences-between-siamese-network-and-convolution-network-in-deep</guid>
      <pubDate>Wed, 08 May 2024 14:14:35 GMT</pubDate>
    </item>
    <item>
      <title>生成随机字符串的预训练模型</title>
      <link>https://stackoverflow.com/questions/78448547/pretrained-models-generating-a-random-strings</link>
      <description><![CDATA[我是机器学习新手，知识不够。在过去的两周里，我尝试使用 ollama 包装器来玩一些现成的模型，实际上效果很好。但是，当我尝试解码它们的输出时，我使用的拥抱脸部模型中很少有它是一些随机的混乱字母串，对我来说没有任何意义。现在我只想知道我是否错过了进一步调整模型之类的东西，或者我可能以错误的方式进行了操作。

我尝试过 HuggingFace 上提供的一些预训练医学模型，例如 https://huggingface.co /UFNLP/gatortron-base 还有一些其他生物 llms。 *
]]></description>
      <guid>https://stackoverflow.com/questions/78448547/pretrained-models-generating-a-random-strings</guid>
      <pubDate>Wed, 08 May 2024 12:33:28 GMT</pubDate>
    </item>
    <item>
      <title>如何使用神经网络进行PCB差异检测（黄金样本与实际样本）？</title>
      <link>https://stackoverflow.com/questions/78448316/how-to-use-neural-networks-for-pcb-difference-detection-golden-sample-vs-actua</link>
      <description><![CDATA[我正在开展一个项目，需要检测两个印刷电路板 (PCB) 之间的差异：黄金样本（参考）和实际样本。我想利用神经网络来完成这项任务，但需要有关具体技术和使用方法的指导。
以下是我的项目的详细信息：

我有黄金样品和实际样品的图像或扫描件
多氯联苯。目标是自动识别并突出显示差异
在这两个 PCB 之间。

具体来说，我正在寻求以下方面的建议：

什么类型的神经网络架构适合于此
图像比较任务？
我应该如何构建数据集来训练神经网络？
我应该使用成对的图像（黄金样本，实际样本）
标记差异？
准备 PCB 图像时建议采取哪些预处理步骤
在将它们输入神经网络之前？任何其他考虑因素
或者有效实施此类系统的最佳实践？

我对神经网络和图像处理相对较新，因此任何见解、教程或代码示例将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78448316/how-to-use-neural-networks-for-pcb-difference-detection-golden-sample-vs-actua</guid>
      <pubDate>Wed, 08 May 2024 11:53:48 GMT</pubDate>
    </item>
    <item>
      <title>RAG 系统的格式化数据</title>
      <link>https://stackoverflow.com/questions/78447942/formatting-data-for-rag-system</link>
      <description><![CDATA[我在从 RAG 系统的图像中提取数据时遇到了问题。问题在于提取的文本，如下所示：
“Shiek Muhammed bin Khursid Mr Shiekh Omar Abdulla 董事总经理 CEO 电子邮件：mkk22@gmail.com 电子邮件：soabdulla786@gmail,com 联系方式：553151 联系方式：556523”
这种格式使得 LLM 难以提供有效的信息。
有什么改进建议吗？
我使用非结构化方法来提取文本。我想以我的 RAG 系统中的 LLM 可以轻松理解的格式提取文本。]]></description>
      <guid>https://stackoverflow.com/questions/78447942/formatting-data-for-rag-system</guid>
      <pubDate>Wed, 08 May 2024 10:52:14 GMT</pubDate>
    </item>
    <item>
      <title>用于图像识别和数据增强的机器学习参数</title>
      <link>https://stackoverflow.com/questions/78447630/machine-learning-parameters-for-image-recognition-and-data-augmentation</link>
      <description><![CDATA[我正在使用两篇不同论文中已经建立的机器学习方法，这些方法建立在 CNN 和图像识别的基础上。然而，这些方法是使用高质量数据创建的，我试图看看这些方法是否可以适应现实世界的低质量图像。我通过增强图像并降低原始模型训练所用的同一数据集的质量来做到这一点。
在执行此操作时，我使用论文中的原始模型作为基线模型来评估我自己的模型并进行比较。
这让我想知道我是否应该使用与论文中的原始模型相同的模型参数，例如批量大小损失函数、学习率等，以便我可以更好地进行比较，或者应该优化参数以降低 -质量数据？
这样做的优点和缺点是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78447630/machine-learning-parameters-for-image-recognition-and-data-augmentation</guid>
      <pubDate>Wed, 08 May 2024 09:58:33 GMT</pubDate>
    </item>
    <item>
      <title>对每个经过训练的 k-1 倍的测试集进行预测</title>
      <link>https://stackoverflow.com/questions/78446923/predictions-on-testing-set-for-every-trained-k-1-fold</link>
      <description><![CDATA[我有一个数据集，它被分成训练集和测试集。首先，我使用 K 折交叉验证来调整我的模型。之后，我想使用每个经过训练的 (K-1) 折来预测我的整个测试数据集（而不是在 cv 期间分割的验证集）。例如，如果我使用 5 折 cv，对于 4 折的每种拟合组合，我都希望我的预测在测试集上，所以最后我想要一个 5 列的测试集预测数据框。
# 迭代每个折
for train_index, _ in cv.split(x_train, y_train):
# 将分类器拟合到此折的训练数据上
svm_model.fit(x_train[train_index], y_train[train_index])
# 预测测试数据的概率
y_pred_proba_fold = svm_model.predict_proba(x_test)
# 汇总每个折的预测
y_pred_test += y_pred_proba_fold
# # 折的平均预测
y_pred_test /= cv.get_n_splits()

我在 AI 工具的帮助下尝试了这段代码，但它没有正常工作。]]></description>
      <guid>https://stackoverflow.com/questions/78446923/predictions-on-testing-set-for-every-trained-k-1-fold</guid>
      <pubDate>Wed, 08 May 2024 08:00:40 GMT</pubDate>
    </item>
    <item>
      <title>多标签分类得分</title>
      <link>https://stackoverflow.com/questions/78446615/multi-label-classification-score</link>
      <description><![CDATA[我目前正在开展一个多标签分类项目，其中包含诸如“团队的惊人支持”之类的短语。被分为诸如“支持”等类别。和“团队”。我已经为此任务训练了一个模型。
我正在寻求有关使用 Langsmith 评估模型性能的最佳方法的建议。具体来说，我想实现一个评分系统：
部分匹配（例如，识别“支持”而不是“团队”）得分一定的值，
完美匹配(例如，识别“支持”和“团队”)得分1，
不相关或不正确的分类会获得不同的指定值。
Langsmith 是否提供可以处理此类评分的内置评估器？如果没有，建议采用什么方法来定制我们的评估指标以适应这些标准？
感谢您的见解！
我尝试了 cot_qa 评估器，但它没有给出部分匹配所需的分数。]]></description>
      <guid>https://stackoverflow.com/questions/78446615/multi-label-classification-score</guid>
      <pubDate>Wed, 08 May 2024 07:03:04 GMT</pubDate>
    </item>
    <item>
      <title>我使用 Ultralytics AI 的代码缓慢且滞后</title>
      <link>https://stackoverflow.com/questions/78446384/my-code-using-ultralytics-ai-is-slow-and-laggy</link>
      <description><![CDATA[我是一名高中生，试图做一些有趣的项目并将其放到我的网站上。目前，我正在使用 OpenCV 开发石头、剪刀、布游戏，但是当我在网络摄像头上本地尝试时，加载时间大约需要 2 分钟，当我看到网络摄像头时，速度非常慢且滞后。我想知道如何解决这个问题。我计划使用 React.js 前端和 Django 或 Flask 后端。我在脚本中做错了什么，或者在添加前端和后端时是否必须更改架构。或者是否有地方可以托管前端和后端以更快地计算并解决问题？或者我应该使用什么工具来代替 OpenCV？
从 ultralytics 导入 YOLO
导入CV2
随机导入
导入时间
从 ultralytics.utils.plotting 导入注释器

# 初始化YOLO模型
模型 = YOLO(&#39;runs\\detect\\train6\\weights\\best.pt&#39;)

# 初始化网络摄像头
上限 = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # 设置帧宽度
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # 设置框架高度
cap.set(cv2.CAP_PROP_FPS, 15) # 限制每秒帧数以减少处理负载

玩家得分 = 0
cpu_分数 = 0

def确定_获胜者（玩家，CPU）：
    全局玩家分数、cpu_分数
    如果玩家==CPU：
        返回“平局！”
    elif (player == &#39;rock&#39; and cpu == &#39;scissors&#39;) 或 \
         (player == &#39;剪刀&#39; and cpu == &#39;布&#39;) 或 \
         （玩家 == &#39;纸&#39; 和 cpu == &#39;石头&#39;）：
        玩家得分 += 1
        返回“玩家获胜！”
    别的：
        cpu_score += 1
        返回“CPU 获胜！”

options = [&#39;石头&#39;, &#39;布&#39;, &#39;剪刀&#39;]

而真实：
    ret, img = cap.read()
    如果不转：
        break # 如果没有捕获到帧则退出循环

    # 使用模型进行预测
    结果 = model.predict(img)
    注释器 = 注释器(img, line_width=2, example_text=&#39;&#39;)

    # 显示倒计时
    [“Rock”、“Paper”、“Shoot!”] 中的倒计时：
        cv2.putText(img, 倒计时, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow(&#39;YOLO V8 检测&#39;, img)
        cv2.waitKey(1000) # 每个倒计时步骤等待 1 秒

    cpu_choice = random.choice(选择)
    玩家选择=无

    如果结果：
        对于结果中的 r：
            盒子 = r.盒子
            对于盒中盒：
                b = 盒子.xyxy[0]
                c = 盒子.cls
                玩家选择 = model.names[int(c)]
                annotator.box_label(b, f&quot;{player_choice} vs CPU: {cpu_choice}&quot;)

    如果玩家选择：
        游戏结果=确定获胜者（玩家选择，CPU选择）
        cv2.putText(img, game_result, (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(img, f&quot;玩家: {player_score} CPU: {cpu_score}&quot;, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

    # 显示带有注释的最终帧
    img = 注释器.result()
    cv2.imshow(&#39;YOLO V8 检测&#39;, img)
    cv2.waitKey(5000) # 显示结果后等待5秒

    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39; &#39;):
        休息

cap.release()
cv2.destroyAllWindows()


我尝试了多线程处理并试图提高循环效率，但没有效果。]]></description>
      <guid>https://stackoverflow.com/questions/78446384/my-code-using-ultralytics-ai-is-slow-and-laggy</guid>
      <pubDate>Wed, 08 May 2024 06:11:12 GMT</pubDate>
    </item>
    <item>
      <title>需要使用 Rand_forest 和 h2o 进行预测的指导</title>
      <link>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</link>
      <description><![CDATA[我有一个随机森林模型，我正在尝试更好地理解它。
为了举例，假设我们有一片蓝莓灌木丛。我们感兴趣的是预测特定灌木丛中腐烂蓝莓的产量以及各个灌木丛中所有蓝莓的收获量。
每个灌木都有一个识别名称：bush_name，例如&#39;bush001&#39;，我们希望根据每个单独的灌木进行预测。例如，我想知道 Bush025 是否在 2/2/22 生产了腐烂的浆果。
为了本示例，输入位于具有以下虚拟结构的 df 中：
train_data &lt;- data.frame(date = c(&quot;2022-01-01&quot;, &quot;2022-01-07&quot;, &quot;2022-02-09&quot;, &quot;2022-05&quot; -01”、“2022-11-01”、“2022-11-02”)、
                   Bush_name = c(“bush001”、“bush001”、“bush001”、“bush043”、“bush043”、“bush043”),
                   错误 = c(2, 0, 1, 0, 3, 1),
                   有腐烂的浆果 = c(1, 0, 0, 1, 1, 0),
                   浆果计数 = c(12, 1, 7, 100, 14, 4),
                   天气 = c(1, 0, 2, 0, 1, 1))

我已经建立了一个随机森林模型，并进行了以下高级设置：
库(agua)
图书馆（防风草）
图书馆（水）

h2o.init(n线程 = -1)

model_fit &lt;- rand_forest(mtry = 10, trees = 100) %&gt;%
  set_engine(“h2o”) %&gt;%
  set_mode(“分类”) %&gt;%
  适合（has_rotten_berry ~ .,
      数据 = train_data) %&gt;%
  step_dummy(灌木名称) %&gt;%
  step_zv(all_predictors()) %&gt;%
  step_normalize(all_predictors())

训练后我确实收到了这条消息：
警告消息：
在 .h2o.processResponseWarnings(res) 中：
  删除坏列和常量列：[bush_name]。

我想知道的是：
当我尝试预测训练模型中的新数据时，似乎我只能使用我已经训练过的灌木丛的 Bush_names 输入新的测试数据。 我假设该模型正在创建特定于灌木丛的预测是否正确？因此必须在训练中输入新的灌木丛信息才能输出这些新灌木丛的未来预测？
示例：我种植了一棵新灌木，bush700，它不存在于原始训练数据集中。如果我尝试使用新的灌木丛数据进行预测，但训练数据中不存在该数据，则会向我传达一条消息：数据中有新的级别。所以我假设因为这些预测似乎是特定于灌木丛的，并且我们无法为新添加的灌木丛获得任何新的灌木丛预测。
这个假设正确吗？
谢谢您，对于可能令人困惑的隐喻，我深表歉意。也欢迎您对该模型可能有的任何其他反馈。]]></description>
      <guid>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</guid>
      <pubDate>Tue, 07 May 2024 16:58:00 GMT</pubDate>
    </item>
    <item>
      <title>model.fit 对使用 tf.data.experimental.make_csv_dataset 创建的张量流数据集给出错误</title>
      <link>https://stackoverflow.com/questions/78443975/model-fit-gives-error-with-tensorflow-dataset-created-with-tf-data-experimental</link>
      <description><![CDATA[我是张量流新手。我正在尝试从 CSV 文件读取值并将其加载为张量流数据集。但是，当我尝试运行 model.fit 时，它给出以下错误 -
输入“input_39”缺少数据。您传递了一个带有键 [&#39;Age&#39;, &#39;Number&#39;, &#39;Start&#39;] 的数据字典。需要以下键：[&#39;input_39&#39;]
这是我的代码-
将 numpy 导入为 np
将 pandas 导入为 pd
将张量流导入为 tf

input_file=&#39;kyphosis.csv&#39;

all_dataset = tf.data.experimental.make_csv_dataset(input_file,batch_size=1,label_name=“Kyphosis”,num_epochs=1)

模型=tf.keras.models.Sequential()
model.add(tf.keras.layers.Input(3))
model.add(tf.keras.layers.Dense(10))
model.add(tf.keras.layers.Dense(1,activation=&#39;sigmoid&#39;))

model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,run_eagerly=True)

model.fit(all_dataset,epochs=10)

请让我知道我在这里做错了什么。 Tensorflow版本是2.11.0。
我尝试使用 tf.data.Dataset.from_tensor_slices 但遇到相同的错误-
df=pd.read_csv(&#39;kyphosis.csv&#39;)
X=df.drop(&#39;脊柱后凸&#39;,axis=1)
y=df[&#39;脊柱后凸&#39;]

all_dataset=tf.data.Dataset.from_tensor_slices((X.to_dict(orient=&#39;list&#39;),y))
all_dataset = all_dataset.batch(1)

模型=tf.keras.models.Sequential()
model.add(tf.keras.layers.Input(3))
model.add(tf.keras.layers.Dense(10))
model.add(tf.keras.layers.Dense(1,activation=&#39;sigmoid&#39;))

model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;)
model.fit(all_dataset,epochs=3)

错误-
ValueError：输入“input_41”缺少数据。您传递了一个带有键 [&#39;Age&#39;, &#39;Number&#39;, &#39;Start&#39;] 的数据字典。需要以下键：[&#39;input_41&#39;]]]></description>
      <guid>https://stackoverflow.com/questions/78443975/model-fit-gives-error-with-tensorflow-dataset-created-with-tf-data-experimental</guid>
      <pubDate>Tue, 07 May 2024 16:45:38 GMT</pubDate>
    </item>
    <item>
      <title>如何以编程方式设置 W&B 运行失败警报？</title>
      <link>https://stackoverflow.com/questions/78439701/how-to-programmatically-set-alerts-for-failure-in-a-wb-run</link>
      <description><![CDATA[如何以编程方式设置 W&amp;B 运行失败警报？
我正在尝试在 W&amp;B（权重和偏差）项目中设置警报，以便在运行失败时通知我。我一直在测试一些我认为根据我的研究可以工作的功能，但似乎没有一个在 W&amp;B API 中实现。这是我尝试设置这些通知的代码片段：
导入 wandb

模式 = &#39;空运行&#39;
运行名称 = &#39;我的运行&#39;
批次数量 = 50
路径=&#39;/数据&#39;
名称 = &#39;实验1&#39;
今天 = &#39;2023-08-01&#39;
概率 = [0.1, 0.9]
批量大小 = 32
data_mixture_name = &#39;mix1&#39;

调试 = 模式 == &#39;dryrun&#39;
run = wandb.init(mode=mode,project=“超越规模”,name=run_name,save_code=True)
万db.config.更新（{
    “num_batches”：num_batches，
    “路径”：路径，
    “姓名”：姓名，
    “今天”：今天，
    “概率”：概率，
    &#39;batch_size&#39;：batch_size，
    “调试”：调试，
    &#39;data_mixture_name&#39;：data_mixture_name
})

# 尝试设置通知
run.notify_on_failure()
run.notify_on_crash()
run.notify_on_exit()
run.notify_on_heartbeat()
run.notify_on_abort()

每次尝试都会导致 AttributeError，表明“Run”对象没有此类属性。例如：
AttributeError：“Run”对象没有属性“notify_on_failure”

在 W&amp;B 中是否有正确的方法来设置故障或其他警报？如果是这样，我应该如何修改我的方法？
参考：https://community.wandb.ai/t/how-do-i-set-the-wandb-alert-programatically-for-my-current-run/4891]]></description>
      <guid>https://stackoverflow.com/questions/78439701/how-to-programmatically-set-alerts-for-failure-in-a-wb-run</guid>
      <pubDate>Tue, 07 May 2024 01:17:24 GMT</pubDate>
    </item>
    <item>
      <title>SKlearn 中嵌套交叉验证的分类报告（平均值/个体值）</title>
      <link>https://stackoverflow.com/questions/42562146/classification-report-with-nested-cross-validation-in-sklearn-average-individua</link>
      <description><![CDATA[是否可以通过一些解决方法从 cross_val_score 获取分类报告？我正在使用嵌套交叉验证，我可以在这里获得模型的各种分数，但是，我想查看外循环的分类报告。有什么建议吗？ 
# 为内循环和外循环选择交叉验证技术，
# 独立于数据集。
# 例如“LabelKFold”、“LeaveOneOut”、“LeaveOneLabelOut”等。
inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)
external_cv = KFold(n_splits=4, shuffle=True, random_state=i)

# 非嵌套参数搜索和评分
clf = GridSearchCV(估计器=svr, param_grid=p_grid, cv=inner_cv)

# 带有参数优化的嵌套 CV
嵌套分数 = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv)

我想在此处查看分类报告以及分数值。
http://scikit-learn.org/stable/modules/ generated /sklearn.metrics.classification_report.html]]></description>
      <guid>https://stackoverflow.com/questions/42562146/classification-report-with-nested-cross-validation-in-sklearn-average-individua</guid>
      <pubDate>Thu, 02 Mar 2017 17:33:42 GMT</pubDate>
    </item>
    </channel>
</rss>