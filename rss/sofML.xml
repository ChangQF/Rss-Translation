<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 13 Dec 2023 06:18:07 GMT</lastBuildDate>
    <item>
      <title>SEEM 模型在向其传递图像及其推理时面临的问题</title>
      <link>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</link>
      <description><![CDATA[我正在研究 SEEM 模型，这是一个可推广的交互式模型，用于一次性分割图像中任何地方的所有内容。由于资源有限，我在将图像传递给它及其推理时面临问题。我已经安装了所有依赖项并单独加载了 SEEM 模型。有谁对此有任何想法并相应地指导我。
我期待有人能够根据他们的知识指导我，我可以尽快解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/77651185/facing-issues-with-seem-model-in-passing-images-to-it-and-its-inferencing</guid>
      <pubDate>Wed, 13 Dec 2023 04:53:29 GMT</pubDate>
    </item>
    <item>
      <title>如何安装集群； AssertionError：错误：无法打开“optimum/version.py”，因为[Errno 2]没有这样的文件或目录：“optimum/version.py”</title>
      <link>https://stackoverflow.com/questions/77649233/how-to-install-swarms-assertionerror-error-could-not-open-optimum-version-py</link>
      <description><![CDATA[我正在尝试安装 swarms，但无法安装并收到此错误：
pip install swarms

收集蜂群
  使用缓存的 swarms-2.7.7-py3-none-any.whl.metadata (15 kB)
收集枕头（从蜂群中）
  使用缓存的 Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)
收集 PyPDF2（从群中）
  使用缓存的 pypdf2-3.0.1-py3-none-any.whl (232 kB)
收集加速（来自蜂群）
  使用缓存的 Accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)
收集 asyncio（从群中）
...
使用缓存的optimum-0.1.1.tar.gz (17 kB)
  安装构建依赖项...完成
  获取制造轮子的要求...完成
  准备元数据 (pyproject.toml) ...完成
  使用缓存的optimum-0.1.0.tar.gz (16 kB)
  安装构建依赖项...完成
  获取构建轮子的要求...错误
  错误：子进程退出并出现错误
  
  × 获取构建 Wheel 的需求未成功运行。
  │ 退出代码：1
  ╰─&gt; [24行输出]
      回溯（最近一次调用最后一次）：
        文件“”，第 7 行，位于  中。
      FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;optimum/version.py&#39;
      
      在处理上述异常的过程中，又出现了一个异常：
      
      回溯（最近一次调用最后一次）：
        文件“/home/ubuntu/miniconda/envs/tree_of_thoughts/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py”，第 353 行，在  中
          主要的（）
        文件“/home/ubuntu/miniconda/envs/tree_of_thoughts/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py”，第 335 行，在 main 中
          json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
        文件“/home/ubuntu/miniconda/envs/tree_of_thoughts/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py”，第 118 行，在 get_requires_for_build_wheel 中
          返回钩子（config_settings）
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 325 行，在 get_requires_for_build_wheel 中
          返回 self._get_build_requires(config_settings, requests=[&#39;wheel&#39;])
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 295 行，位于 _get_build_requires 中
          self.run_setup()
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 480 行，在 run_setup 中
          超级（_BuildMetaLegacyBackend，自我）.run_setup（setup_script = setup_script）
        文件“/tmp/pip-build-env-rn01vqif/overlay/lib/python3.10/site-packages/setuptools/build_meta.py”，第 311 行，在 run_setup 中
          执行（代码，局部变量（））
        文件“”，第 10 行，位于  中。
      AssertionError：错误：无法打开“optimum/version.py”，因为[Errno 2]没有这样的文件或目录：“optimum/version.py”
      
      [输出结束]
  
  注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：子进程退出并出现错误

× 获取构建 Wheel 的需求未成功运行。
│ 退出代码：1
╰─&gt;请参阅上面的输出。

注意：此错误源自子进程，并且可能不是 pip 的问题。

如何解决这个问题？
交叉： ]]></description>
      <guid>https://stackoverflow.com/questions/77649233/how-to-install-swarms-assertionerror-error-could-not-open-optimum-version-py</guid>
      <pubDate>Tue, 12 Dec 2023 21:58:14 GMT</pubDate>
    </item>
    <item>
      <title>Labeled Cluster ：根据训练数据将点云分为几类</title>
      <link>https://stackoverflow.com/questions/77648966/labeled-cluster-divide-a-point-cloud-into-categories-based-on-the-training-dat</link>
      <description><![CDATA[输入：
N 点（X，Y）（A 点是屏幕中红色形状的中心）。
输出 =（屏幕中的青色矩形）
将这些点聚类到 K 组（K &lt;= N）。屏幕中的青色矩形是我们期望的输出。
我们有数千个标记数据（如屏幕中的数据）。
如何使用标记数据（我们已经手动完成）来训练可以对新数据进行聚类的算法。
在此处输入图片描述
我尝试了 sklearn.cluster 但这是针对未标记的数据...]]></description>
      <guid>https://stackoverflow.com/questions/77648966/labeled-cluster-divide-a-point-cloud-into-categories-based-on-the-training-dat</guid>
      <pubDate>Tue, 12 Dec 2023 20:46:27 GMT</pubDate>
    </item>
    <item>
      <title>神经网络在时间序列中查找子序列？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77648688/neural-network-to-find-subsequence-in-time-series</link>
      <description><![CDATA[

蓝线代表时间序列
红色矩形子序列

是否可以通过机器学习方法找到这些子序列？
PS：这是合成数据，在真实数据中经典算法会失败]]></description>
      <guid>https://stackoverflow.com/questions/77648688/neural-network-to-find-subsequence-in-time-series</guid>
      <pubDate>Tue, 12 Dec 2023 19:48:08 GMT</pubDate>
    </item>
    <item>
      <title>数学图数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/77648552/math-graph-dataset</link>
      <description><![CDATA[我正在寻找包含通过某些方程获得的可能图形的任何数据集，因为我想制作和训练一个人工智能模型，当给定图像时，它将获取图像的轮廓，并返回一系列数学方程，当例如在 Desmos 图形计算器 中绘制的，给出图像的轮廓。
我尝试拍摄照片并单独标记每张照片，但这需要很长时间！我希望我能找到一个至少包含一些基本图表的数据集，我可以从那里继续。]]></description>
      <guid>https://stackoverflow.com/questions/77648552/math-graph-dataset</guid>
      <pubDate>Tue, 12 Dec 2023 19:20:44 GMT</pubDate>
    </item>
    <item>
      <title>FFNN 帮助进行超频带调整</title>
      <link>https://stackoverflow.com/questions/77648526/ffnn-help-on-hyperband-tuning</link>
      <description><![CDATA[我正在开发一个时间序列玩具问题来学习前馈神经网络。在本例中，我想根据一些输入来预测 Nova Dehli 的温度。
我开发了模型，但现在我尝试使用超频带调整来调整参数。
问题是我觉得它消耗的时间很奇怪。运行整个代码总是需要 21 秒。无论我将 hyperband_iterations 从 1 增加到 100000000000 还是将因子从 3 更改为 3000。总是 21 秒。我认为这就是运行所谓的“最佳模型”的 250 个周期所需的时间。
# 定义回归模型
def model_builder（马力）：
    模型 = keras.Sequential()

    hp_units1 = hp.Int(&#39;单位1&#39;, min_value=1, max_value=500, 步骤=1)
    model.add(keras.layers.Dense(units=hp_units1,activation=&#39;relu&#39;,input_shape=(Xtrain_np.shape[1],)))

    hp_units2 = hp.Int(&#39;units2&#39;, min_value=1, max_value=500, 步骤=1)
    model.add(keras.layers.Dense(units=hp_units2,activation=&#39;relu&#39;))

    model.add(keras.layers.Dense(1))

    # 调整优化器的学习率
    hp_learning_rate = hp.Choice(&#39;learning_rate&#39;, 值=[1e0, 1e-1, 1e-2, 1e-3, 1e-4 ])

    # 使用“mean_squared_error”进行回归任务
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
                  损失=&#39;均方误差&#39;,
                  metrics=[&#39;mae&#39;]) # 平均绝对误差是回归的常用指标

    返回模型

**#调整**
调谐器 = kt.Hyperband(hypermodel = model_builder,
                     目标=&#39;val_loss&#39;，
                     最大纪元=500，
                     系数=30，
                     hyperband_iterations=1,
                     种子=无，
                     超参数=True,
                     tune_new_entries=真，
                     允许新条目=真，
                     每次试验的最大重试次数=5，
                     最大连续失败试验=5）

stop_early = tf.keras.callbacks.EarlyStopping(monitor=&#39;val_loss&#39;, 耐心=400)

# 寻找最佳参数
tuner.search（Xtrain_np，ytrain_np，epochs = 400，validation_data =（Xval_np，yval_np），回调= [stop_early]）

我尝试更改调整中的所有参数，例如 hyperband_iterations、factor 和 max_epochs。所花费的时间没有任何改变。]]></description>
      <guid>https://stackoverflow.com/questions/77648526/ffnn-help-on-hyperband-tuning</guid>
      <pubDate>Tue, 12 Dec 2023 19:13:24 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：调用层“查询”（类型 EinsumDense）时遇到异常。形状必须为 3 级，但为 1 级</title>
      <link>https://stackoverflow.com/questions/77648267/valueerror-exception-encountered-when-calling-layer-query-type-einsumdense</link>
      <description><![CDATA[我正在做关于 NLP 的项目，我在 Transformer 模型上遇到了这个问题。
问题说：
形状必须为 3 级，但为 1 级

关于我的数据集，它看起来像这样：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

API 序列
标签


&lt;正文&gt;

调用API
0


呼叫病毒
1




这是我的代码：
类变压器：
    def __init__(自身，数据，名称=“”，batch_size=16)：
        向量 = np.stack(data.iloc[:, 0].values)
        标签 = data.iloc[:, 1].values

        …………

        # 输入
        向量 = 向量.reshape(-1, 1)

        输入=输入（形状=（向量.形状[0]，向量.形状[1]））

        # 变压器块 1
        attn_output_1 = MultiHeadAttention（num_heads = 8，key_dim = 32）（输入，输入）
        attn_output_1 = LayerNormalization()(attn_output_1)
        ff_output_1 = 密集（单位=32，激活=&#39;relu&#39;）（attn_output_1）
        ff_output_1 = 密集（单位=50）（ff_output_1）
        残差_输出_1 = LayerNormalization()(输入 + ff_output_1)

我尝试了很多方法，比如.reshape()，但不起作用]]></description>
      <guid>https://stackoverflow.com/questions/77648267/valueerror-exception-encountered-when-calling-layer-query-type-einsumdense</guid>
      <pubDate>Tue, 12 Dec 2023 18:16:18 GMT</pubDate>
    </item>
    <item>
      <title>组合 2 个或更多具有不同响应时间的 ML 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/77648139/combine-out-of-2-or-more-ml-models-with-different-response-times</link>
      <description><![CDATA[我有几个模型，它们对提示的响应时间不同。我想将它们的输出和供应结合到不同的机器学习模型中。这些模型具有不同的运行时，因此更多的是异步方式。
我怎样才能实现这个目标？]]></description>
      <guid>https://stackoverflow.com/questions/77648139/combine-out-of-2-or-more-ml-models-with-different-response-times</guid>
      <pubDate>Tue, 12 Dec 2023 17:53:10 GMT</pubDate>
    </item>
    <item>
      <title>MNIST 的 CLIP 零样本准确率为 30%？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77647994/zero-shot-accuracy-of-clip-for-mnist-is-30</link>
      <description><![CDATA[《Learning Transferable Visual Models From Natural Language Supervision》论文指出，CLIP 在 MNIST 上的准确率约为 88%。我从这里从 CLIP 下载了他们的实现： https://github.com/openai/CLIP
我在 MNIST 上对其进行了测试，仅获得 30% 左右的准确率。有谁知道我做错了什么？
导入火炬
导入剪辑
从 PIL 导入图像
进口火炬视觉
导入 torchvision.transforms 作为变换
将 numpy 导入为 np
设备=“cuda”； if torch.cuda.is_available() else “cpu”
模型，预处理=clip.load(“ViT-B/32”，device=device)

Training_set = torchvision.datasets.MNIST(&#39;./data&#39;,train=True,transform=preprocess,download=True)
validation_set = torchvision.datasets.MNIST(&#39;./data&#39;,train=False,transform=preprocess,download=True)

trainloader = torch.utils.data.DataLoader(training_set,batch_size=32,
                                          洗牌=真，num_workers=0）
testloader = torch.utils.data.DataLoader(validation_set,batch_size=32,
                                         洗牌=假，num_workers=0）
类 = [&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;,
    &#39;5&#39;、&#39;6&#39;、&#39;7&#39;、&#39;8&#39;、&#39;9&#39;]

正确 = 0
总计 = 0
对于测试加载器中的 i、j：
    文本 = Clip.tokenize(classes).to(device)
    标签 = [j 中 x 的类 [x]]
    使用 torch.no_grad()：
        logits_per_image, logits_per_text = 模型(i, 文本)
        probs = logits_per_image.softmax(dim=-1).cpu().numpy()
    结果 = [np.argmax(probs, axis=1) 中 x 的类[x]]
    对于 zip 中的 i、j（结果、标签）：
        如果我==j：
            正确+=1
打印（正确/len（testloader.dataset））
]]></description>
      <guid>https://stackoverflow.com/questions/77647994/zero-shot-accuracy-of-clip-for-mnist-is-30</guid>
      <pubDate>Tue, 12 Dec 2023 17:28:36 GMT</pubDate>
    </item>
    <item>
      <title>使用部分地面实况信息的图像恢复[关闭]</title>
      <link>https://stackoverflow.com/questions/77647934/image-restoration-using-partial-ground-truth-information</link>
      <description><![CDATA[我正在开展一个图像恢复项目，其中有四张图像，每张图像都揭示了真实情况的不同部分，而其余部分则被遮挡。我还有真实图像来计算损失。
我熟悉 GAN 等较旧的架构，但尚未探索 Vision Transformers 或扩散模型。我渴望了解类似的方法或论文来解决像我这样的挑战。您能推荐一些相关的想法、技术或论文吗？
我记得读过有关 GAN 模型的文章，这些模型可以解决与此类似的任务，但我想尝试一些现代方法。]]></description>
      <guid>https://stackoverflow.com/questions/77647934/image-restoration-using-partial-ground-truth-information</guid>
      <pubDate>Tue, 12 Dec 2023 17:16:50 GMT</pubDate>
    </item>
    <item>
      <title>Python：fillna()函数输出单词“None”[重复]</title>
      <link>https://stackoverflow.com/questions/77647622/python-fillna-function-is-outputting-the-word-none</link>
      <description><![CDATA[我正在尝试为一堂课进行练习，其中我必须使用 fillna() 函数将列的缺失值替换为数据的中位数。在被称为“housing”的数据框中，有一列标题为“Mas Vnr Area”。其中有几行具有“NA”。价值观。为了填写和验证这些更改，在阅读必要的 .csv 文件后，我一直使用以下代码行（使用 PyCharm IDE）：
median_val = housing[&quot;Mas Vnr Area&quot;].median()

print(housing[&quot;Mas Vnr Area&quot;].fillna(median_val,inplace = True))

但是，每次我运行该程序时，这部分代码都只输出单词“None”。我已经多次核实“住房”是真的。里面有必要的信息，但我每次都会得到这个输出。有谁知道可能是什么原因造成的？]]></description>
      <guid>https://stackoverflow.com/questions/77647622/python-fillna-function-is-outputting-the-word-none</guid>
      <pubDate>Tue, 12 Dec 2023 16:25:12 GMT</pubDate>
    </item>
    <item>
      <title>对包含 nan 元素的 xarray 数据执行 sklearn.linearmodel 岭回归</title>
      <link>https://stackoverflow.com/questions/77640756/performing-sklearn-linearmodel-ridge-regression-on-xarray-data-which-contains-na</link>
      <description><![CDATA[我正在尝试执行带有岭校正的多元线性回归，以确定 xarray 数据框中某些空间变量之间的关系。因为这些是观察到的数据，所以数据中偶尔会有 NaN 值，这是 sklearn 本身无法处理的。我尝试使用 data.interpolate_na(fill_value=&#39;extrapolate&#39;)，但这无法替换所有 NaN 值。一个可行的解决方案是使用 data.fillna(0) ，但这可能会出现问题，因为当插值或屏蔽之类的方法会更好时，我不希望从整个布料中“发明”数据。我的代码如下：
从 sklearn.linear_model 导入 Ridge
将 xarray 导入为 xr
将 pandas 导入为 pd
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 cartopy.crs 导入为 ccrs

def detrend_dim(da, dim, deg=1): # 从数据中删除（时间）趋势
    # 沿单一维度去趋势
    p = da.polyfit(dim=dim, deg=deg)
    fit = xr.polyval(da[dim], p.polyfit_coefficients)
    返回 da - 适合

#加载和预处理数据
data = xr.open_dataset(&#39;reanalysisdata.nc&#39;)
data2 = xr.open_dataset(&#39;satellitedata.nc&#39;)
土地 = xr.open_dataset(&#39;twopt Fivedeglandmask.nc&#39;)
data2.coords[&#39;mask&#39;] = ((&#39;lat&#39;, &#39;lon&#39;), land.FRLAND.mean(dim=&#39;time&#39;).data)
数据2 = 数据2.where(数据2.掩码== 0)
data.coords[&#39;mask&#39;] = ((&#39;lat&#39;, &#39;lon&#39;), land.FRLAND.mean(dim=&#39;time&#39;).data)
数据 = 数据.where(数据.掩码 == 0)

#尝试处理 NaN 值
数据 = data.fillna(0)
数据2 = 数据2.fillna(0)

#删除时间趋势
数据[&#39;x1&#39;] = detrend_dim(data.x1, &#39;时间&#39;)
数据[&#39;x2&#39;] = detrend_dim(data.x2, &#39;时间&#39;)
数据[&#39;x3&#39;] = detrend_dim(data.x3, &#39;时间&#39;)
data2[&#39;y&#39;] = detrend_dim(data2.y, &#39;时间&#39;)

#去除季节周期
dataM = data.groupby(&#39;时间.月份&#39;)
数据U = 数据M - 数据M.mean()
data2M = data2.groupby(&#39;时间.月份&#39;)
data2U = data2M - data2M.mean()

#执行回归
a = np.zeros((72,144,3))
对于范围内的 i(len(data.lat))：
    对于范围内的 j(len(data.lon))：
        a[i,j,:] = (Ridge().fit(np.array((dataU.isel(lev=2).x1.values[:,i,j].reshape(-1,1),
                    dataU.isel(lev=2).x2.values[:,i,j].reshape(-1,1),
                    dataU.isel(lev=2).x3.values[:,i,j].reshape(-1,1))).reshape(108,3),
                    data2U.y.values[:,i,j].reshape(108)).coef_)
dataU = data.assign_coords(varname=[&#39;x1&#39;,&#39;x2&#39;,&#39;x3&#39;])
dataU[&#39;multiple_reg_coeff&#39;] = ((&#39;lat&#39;,&#39;lon&#39;,&#39;varname&#39;), a)

我需要迭代检查每个变量的 NaN 吗？ sklearn.linear_model 中有一些回归本身可以处理 NaN，但我对它们背后的数学的理解不如岭回归。]]></description>
      <guid>https://stackoverflow.com/questions/77640756/performing-sklearn-linearmodel-ridge-regression-on-xarray-data-which-contains-na</guid>
      <pubDate>Mon, 11 Dec 2023 15:48:54 GMT</pubDate>
    </item>
    <item>
      <title>重新排列 LGBMClassifier Predict_proba 输出列</title>
      <link>https://stackoverflow.com/questions/77639975/rearranging-lgbmclassifier-predict-proba-outputs-columns</link>
      <description><![CDATA[我正在训练一个 LGBMClassifier，以便使用其 predict_proba 方法。目标有 3 个类别：a、b 和 c。我想确保模型 predict_proba 按 b、a、c 的顺序输出列的概率。
有没有办法确保 LGBMClassifier predict_proba 的输出具有上述顺序？
导入 pandas 作为 pd
从 lightgbm 导入 LGBMClassifier
将 numpy 导入为 np

＃数据
特征 = [&#39;feat_1&#39;]
目标=&#39;目标&#39;
df = pd.DataFrame({
    &#39;feat_1&#39;：np.random.uniform（大小= 100），
    &#39;目标&#39;:np.random.choice(a=[&#39;b&#39;,&#39;c&#39;,&#39;a&#39;], size=100)
})

＃训练
模型 = LGBMClassifier()
model.fit(df[特征], df[目标])
打印（模型.classes_）

&lt;块引用&gt;
[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]

我尝试过的事情

只需重新排列 .classes_ 属性即可。
model.classes_ = [&#39;b&#39;,&#39;a&#39;,&#39;c&#39;]

&lt;块引用&gt;
AttributeError：无法设置属性“classes_”


根据 .classes_ 属性手动重新排列列。

desired_order = [&#39;b&#39;,&#39;a&#39;,&#39;c&#39;]
Correct_idx = [list(model._classes).index(val) for val indesired_order]
model.predict_proba(测试[特征])[:, Correct_idx]

#2 有效，但我不必在每次 predict_proba 调用时重新排列列顺序。]]></description>
      <guid>https://stackoverflow.com/questions/77639975/rearranging-lgbmclassifier-predict-proba-outputs-columns</guid>
      <pubDate>Mon, 11 Dec 2023 13:35:28 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试从 Transformer 导入 Trainer 时，DLL 失败</title>
      <link>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</link>
      <description><![CDATA[我想在本地计算机上微调基于 Transformer 的模型，因此当我尝试导入训练器时
从 Transformers 导入 Trainer

出现此错误
导入错误：导入 lib 时 DLL 加载失败：找不到指定的过程。
运行时错误：由于以下错误，无法导入transformers.trainer（查找其回溯）：
导入 lib 时 DLL 加载失败：找不到指定的过程。
如何解决此错误？
环境
蟒蛇
库达12.3
Python 3.9.18
火炬2.1.0+cu118
火炬音频2.1.0+cu118
火炬视觉 0.16.0+cu118
变形金刚 4.35.2

我尝试升级CUDA，升级和降级transformers库，torch及其子库，但没有帮助]]></description>
      <guid>https://stackoverflow.com/questions/77633777/dll-failed-when-i-tried-to-import-trainer-from-transformers</guid>
      <pubDate>Sun, 10 Dec 2023 05:33:49 GMT</pubDate>
    </item>
    <item>
      <title>如何修复我的感知器来识别数字？</title>
      <link>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77594625/how-can-i-fix-my-perceptron-to-recognize-numbers</guid>
      <pubDate>Sun, 03 Dec 2023 14:03:49 GMT</pubDate>
    </item>
    </channel>
</rss>