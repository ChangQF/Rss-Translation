<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 07 Sep 2024 15:16:25 GMT</lastBuildDate>
    <item>
      <title>使用来自 transformers 的 GPT-2 开发生成式 AI 聊天机器人</title>
      <link>https://stackoverflow.com/questions/78960411/developing-a-generative-ai-chatbot-using-gpt-2-from-transformers</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78960411/developing-a-generative-ai-chatbot-using-gpt-2-from-transformers</guid>
      <pubDate>Sat, 07 Sep 2024 14:42:14 GMT</pubDate>
    </item>
    <item>
      <title>拟合过程中功能模型出现错误[重复]</title>
      <link>https://stackoverflow.com/questions/78960201/getting-error-in-functional-model-during-fitting</link>
      <description><![CDATA[错误 - output_signature 必须包含 tf.TypeSpec 子类的对象，但发现 &lt;class &#39;list&#39;&gt;事实并非如此。
我是深度学习的新手，正在制作一个功能模型来预测人物图像的年龄和性别
数据集链接 - https://www.kaggle.com/datasets/jangedoo/utkface-new
age = []
gender = []
img_path = []
for file in os.listdir(file_path):
age.append(int(file.split(&#39;_&#39;)[0]))
gender.append(int(file.split(&#39;_&#39;)[1]))
img_path.append(file)

df = pd.DataFrame({&#39;age&#39;:age , &#39;gender&#39;:gender , &#39;img_path&#39;:img_path})

train_df = df.sample(frac = 1 , random_state = 0).iloc[:20000]
test_df = df.sample(frac = 1, random_state=0).iloc[20000:]

# generator

train_datagen = ImageDataGenerator(rescale= 1./255,
rotation_range = 30,
width_shift_range = 0.2,
height_shift_range = 0.2,
sher_range = 0.2,
zoom_range = 0.2,
Horizo​​ntal_flip = True)
test_datagen = ImageDataGenerator(rescale = 1./255)

train_generator = train_datagen.flow_from_dataframe(
dataframe=train_df,
directory=file_path,
x_col=&#39;img_path&#39;,
y_col=[&#39;age&#39;, &#39;gender&#39;], # 仍然指定列以供参考
target_size=(200, 200),
class_mode= &#39;multi_output&#39;,
batch_size=32
)

test_generator = test_datagen.flow_from_dataframe(
dataframe=test_df,
directory=file_path,
x_col=&#39;img_path&#39;,
y_col=[&#39;age&#39;, &#39;gender&#39;],
target_size=(200, 200),
class_mode=&#39;multi_output&#39;, # 此处相同
batch_size=32
)


vggnet = VGG16(include_top = False , input_shape = (200 , 200 , 3))

vggnet = VGG16(include_top = False , input_shape = (200 , 200 , 3))

vggnet.trainable = False
output = vggnet.layers[-1].output

flatten = Flatten()(output)

dense1 = Dense(512 , 激活 = &#39;relu&#39;)(flatten)
dense2 = Dense(512 , 激活 = &#39;relu&#39;)(flatten)

dense3 = Dense(512 , 激活 = &#39;relu&#39;)(dense1)
dense4 = Dense(512 , 激活 = &#39;relu&#39;)(dense2)

output1 = Dense(1 , 激活 = &#39;linear&#39; , name = &#39;age&#39;)(dense3)
output2 = Dense(1 , 激活= &#39;sigmoid&#39; , name = &#39;gender&#39;)(dense4)


model = Model(inputs = vggnet.input , output = [output1,output2])

model.compile(optimizer = &#39;adam&#39; , loss = {&#39;age&#39;:&#39;mae&#39; , &#39;gender&#39;:&#39;binary_crossentropy&#39;} , metrics = {&#39;age&#39;:&#39;mae&#39; , &#39;gender&#39;:&#39;accuracy&#39;},loss_weights = {&#39;age&#39;:1 , &#39;gender&#39;:99})

model.fit(train_generator, batch_size=32, epochs=10, validation_data=test_generator)


错误 - output_signature 必须包含属于tf.TypeSpec 但发现 &lt;class &#39;list&#39;&gt; 不是。]]></description>
      <guid>https://stackoverflow.com/questions/78960201/getting-error-in-functional-model-during-fitting</guid>
      <pubDate>Sat, 07 Sep 2024 13:10:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 imageDataGenerator 对象执行 Keras model.fit 时出错</title>
      <link>https://stackoverflow.com/questions/78960164/error-while-executing-keras-model-fit-with-imagedatagenerator-object</link>
      <description><![CDATA[在使用 Cats &amp; 时执行以下代码行时出现错误狗数据集。
EPOCHS = 100
history = model.fit(
train_data_gen,
steps_per_epoch=int(np.ceil(2000 / float(BATCH_SIZE))),
epochs=EPOCHS,
validation_data=val_data_gen,
validation_steps=int(np.ceil(1000 / float(BATCH_SIZE)))
)

错误
Epoch 1/100
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: 您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。 `**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。不要将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()
20/20 ━━━━━━━━━━━━━━━━━━━━━━━ 17s 311ms/step - 准确度：0.4858 - 损失：0.7865 - val_accuracy：0.5000 - val_loss：0.6925
Epoch 2/100
/usr/lib/python3.10/contextlib.py:153：UserWarning：您的输入数据不足；中断训练。确保您的数据集或生成器至少可以生成 `steps_per_epoch * epochs` 批次。构建数据集时，您可能需要使用 `.repeat()` 函数。
self.gen.throw(typ, value, traceback)
---------------------------------------------------------------------------
AttributeError Traceback (most recent call last)
&lt;ipython-input-22-f495897bdf8d&gt; in &lt;cell line: 2&gt;()
1 EPOCHS = 100
----&gt; 2 history = model.fit(
3 train_data_gen,
4 steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),
5 epochs=EPOCHS,

1 帧
/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)
352 )
353 val_logs = {
--&gt; 354 &quot;val_&quot; + name: val for name, val in val_logs.items()
355 }
356 epoch_logs.update(val_logs)

AttributeError: &#39;NoneType&#39; 对象没有属性 &#39;items&#39;

错误提到输入用尽数据，但步骤大小对于训练和验证数据集都是正确的。
我找到了一些使用 fit_generator 的示例，但该方法在 tensorflow 2.1.0 中已弃用。
有什么解决该问题的建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78960164/error-while-executing-keras-model-fit-with-imagedatagenerator-object</guid>
      <pubDate>Sat, 07 Sep 2024 12:52:02 GMT</pubDate>
    </item>
    <item>
      <title>使用分类数据和现有标签进行聚类</title>
      <link>https://stackoverflow.com/questions/78959485/clustering-with-categorical-data-and-existing-labels</link>
      <description><![CDATA[假设我有一个电子商务数据库，其中每一行代表一个产品视图以及它是否导致转化（购买/未购买）
我的目标是根据除价格之外的所有特征（所有分类）合理地将“群组”分配给用户视图，同时考虑数据中的价格和标签。这样当有新视图出现时，我就知道该视图属于哪个集群。
是否存在可以做到这一点的算法？最好是现有的 Python 库可以帮助解决这个问题。
数据的示例列：currencyCode、country、pageType、isMobile、browser、hourOfDay、productPrice、converted
我知道存在处理分类数据的 kprototypes / kmodes，但汉明距离作为相异性似乎并不适用于我们这里的情况，而且它没有考虑数据的标签。]]></description>
      <guid>https://stackoverflow.com/questions/78959485/clustering-with-categorical-data-and-existing-labels</guid>
      <pubDate>Sat, 07 Sep 2024 06:11:33 GMT</pubDate>
    </item>
    <item>
      <title>高效的 PyTorch 带矩阵到密集矩阵乘法</title>
      <link>https://stackoverflow.com/questions/78959447/efficient-pytorch-band-matrix-to-dense-matrix-multiplication</link>
      <description><![CDATA[问题：在我的某个程序中，我需要计算矩阵乘法 A @ B，其中两个矩阵的大小均为 N x N，但 N 相当大。我推测使用 band_matrix(A, width) @ B 来近似该乘积即可满足需求，其中 band_matrix(A, width) 表示 A 的带状矩阵部分，宽度为 width。例如，width = 0 给出对角矩阵，对角线元素取自 A，而 width = 1 给出以类似方式获取的三对角矩阵。
我的尝试：我尝试提取三对角矩阵，例如，以以下方式：
# 步骤 1：提取主对角线
main_diag = torch.diagonal(A, dim1=-2, dim2=-1) # 形状：[d1, d2, N]

# 步骤 2：提取上对角线（偏移量=1）
upper_diag = torch.diagonal(A, offset=1, dim1=-2, dim2=-1) # 形状：[d1, d2, N-1]

# 步骤 3：提取下对角线(offset=-1)
lower_diag = torch.diagonal(A, offset=-1, dim1=-2, dim2=-1) # 形状：[d1, d2, N-1]

# 步骤 4：重建三对角矩阵
# 主对角线
tridiag = torch.diag_embed(main_diag) # 形状：[d1, d2, N, N]

# 上对角线（移动值以创建第一个上对角线）
tridiag += torch.diag_embed(upper_diag, offset=1)

# 下对角线（移动值以创建第一个下对角线）
tridiag += torch.diag_embed(lower_diag, offset=-1)

但我不确定 tridiag @ B 是否比原始 A 更有效率@ B 或者只是相同的复杂性，因为 Torch 可能不知道 tridiag 的具体结构。理论上，使用三对角矩阵的计算应该快 N 倍。

任何有助于理解 PyTorch 在这种情况下的行为或实施一些替代的 GPU 优化方法的帮助都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78959447/efficient-pytorch-band-matrix-to-dense-matrix-multiplication</guid>
      <pubDate>Sat, 07 Sep 2024 05:46:17 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Flutter 中实现 flex 委托</title>
      <link>https://stackoverflow.com/questions/78959407/how-to-implement-flex-delegate-in-flutter</link>
      <description><![CDATA[当我尝试使用 python 将模型保存在 .tflite 文件中时，我使用 tf_ops，它以将模型保存在 .tflite 文件中的方式实现 flex 委托。
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# 仅使用受支持的 TensorFlow Lite 操作和 Flex 委托

converter.target_spec.supported_ops = \[tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS\]

当我使用 tflite_flutter 包在 Flutter 中加载模型时，它会抛出错误：无法加载模型
import &#39;package:flutter/services.dart&#39;;
import &#39;package:tflite_flutter/tflite_flutter.dart&#39;;
import &#39;dart:convert&#39;;

class TFLiteService {
late Interpreter \_interpreter;
\_interpreter = await Interpreter.fromAsset(&#39;assets/ml_simple_rnn.tflite&#39;);
print(&#39;TFLite 模型已成功加载&#39;);
}

我尝试了 tflite_flutter_helper 包，但没有得到预期的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78959407/how-to-implement-flex-delegate-in-flutter</guid>
      <pubDate>Sat, 07 Sep 2024 05:27:57 GMT</pubDate>
    </item>
    <item>
      <title>在函数中创建 VLLM 对象时会导致内存错误，即使明确清除 GPU 缓存也是如此，只有共享引用才能使代码不会崩溃</title>
      <link>https://stackoverflow.com/questions/78959131/vllm-objects-cause-memory-errors-when-created-in-a-function-even-when-explicitly</link>
      <description><![CDATA[我在 Python 中使用 VLLM 库时遇到了问题。具体来说，当我在函数内部创建 VLLM 模型对象时，我遇到了内存问题，并且无法有效清除 GPU 内存，即使在删除对象并使用 torch.cuda.empty_cache() 之后也是如此。
当我尝试在函数内部实例化 LLM 对象时会出现问题，但如果我在父进程或全局范围内实例化该对象，则不会发生这种情况。这表明 VLLM 在函数中创建和管理对象时存在问题，从而导致内存保留和 GPU 耗尽。
示例代码
以下是代码的简化版本：
import torch
import gc
from vllm import LLM

def run_vllm_eval(model_name, samples_params, path_2_eval_dataset):
# 在函数中实例化 LLM
llm = LLM(model=model_name, dtype=torch.float16, trust_remote_code=True)

# 在此处运行一些 VLLM 推理或评估（简化）
result = llm.generate([path_2_eval_dataset], samples_params)

# 推理后清理
del llm
gc.collect()
torch.cuda.empty_cache()

# 在此之后，GPU 内存未正确清除并导致 OOM 错误
run_vllm_eval()
run_vllm_eval()
run_vllm_eval()

但是
llm = run_vllm_eval2()
llm = run_vllm_eval2(llm)
llm = run_vllm_eval2(llm)

有效。
即使明确删除 LLM 对象并清除缓存后，GPU 内存仍未正确释放，导致在尝试加载或运行同一脚本中的另一个模型时出现内存不足 (OOM) 错误。
我尝试过的方法
使用 del 删除 LLM 对象。
运行 gc.collect() 以触发 Python 的垃圾收集。
使用 torch.cuda.empty_cache() 清除 CUDA 内存。
确保父进程中没有实例化 VLLM 对象。
当在函数内创建 LLM 对象时，这些似乎都无法解决问题。
问题
有人在函数内创建 VLLM 对象时遇到过类似的内存问题吗？
是否有推荐的方法来管理或清除函数中的 VLLM 对象以防止 GPU 内存保留？
在这种情况下，是否存在与标准 Hugging Face 或 PyTorch 模型不同的特定 VLLM 处理技术？]]></description>
      <guid>https://stackoverflow.com/questions/78959131/vllm-objects-cause-memory-errors-when-created-in-a-function-even-when-explicitly</guid>
      <pubDate>Sat, 07 Sep 2024 00:58:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用外部库（例如 OpenCV）和反向传播梯度处理 PyTorch 中的自定义固定操作？</title>
      <link>https://stackoverflow.com/questions/78959071/how-to-handle-custom-fixed-operations-in-pytorch-with-external-libraries-e-g</link>
      <description><![CDATA[我正在开发一个 PyTorch 项目，我需要训练一个使用第三方库（特别是 OpenCV）中的自定义 FIXED 操作的神经网络。此操作会修改输入数据，然后使用其输出来计算相对于目标数据的损失。
问题是 OpenCV 仅适用于 NumPy 数组，这意味着我需要将我的 PyTorch 张量转换为 NumPy（强制将计算转移到 CPU 上）。这样做会破坏 PyTorch 的计算图，从而无法使用 loss.backward() 自动计算梯度。
此外，我正在努力弄清楚如何使用适当的反向传递来实现自定义 autograd 函数来解释这种情况。我查阅了相关文献，没有找到明确的解决方案来以可重复使用的方式处理此问题。
我的问题是：

在使用第三方库（如 OpenCV）时，如何保持梯度流？这些库需要将张量转换为 NumPy（因此会破坏计算图）？
如果我需要实现自定义自动求导函数，当自定义操作不可微分或使用固定变换时，如何正确计算反向传递？
是否有任何现有的最佳实践或通用解决方案可以解决此问题？

这是方案：
]]></description>
      <guid>https://stackoverflow.com/questions/78959071/how-to-handle-custom-fixed-operations-in-pytorch-with-external-libraries-e-g</guid>
      <pubDate>Sat, 07 Sep 2024 00:06:41 GMT</pubDate>
    </item>
    <item>
      <title>向量近似程序故障</title>
      <link>https://stackoverflow.com/questions/78958485/vector-approximation-program-malfunction</link>
      <description><![CDATA[我和一个朋友创建了一个程序，该程序应该近似一个向量，输入数据是该向量中的一些点。我的朋友写了一行我无法理解的代码，它出现故障：
model = make_pipeline(PolynomialFeatures(degree), RidgeCV(alphas=ridge_alpha,normalize=True,cv=5))

我尝试执行这行代码，但结果出错了：
C:\Users\USER\OneDrive\Desktop\programming\python\vector approximation&gt; &amp; &quot;c:/Users/USER/OneDrive/Desktop/programming/python/vector approximation/.venv/Scripts/python.exe&quot; &quot;c:/Users/USER/OneDrive/Desktop/programming/python/vector approximation/file.py&quot;
50
回溯（最近一次调用）：
文件“c:\Users\USER\OneDrive\Desktop\programming\python\vector approximation\file.py”，第 78 行，位于&lt;module&gt;
model = make_pipeline(PolynomialFeatures(degree), RidgeCV(alphas=ridge_alpha,normalize=True,cv=5))
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError：_BaseRidgeCV.__init__() 获得了意外的关键字参数“normalize”

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78958485/vector-approximation-program-malfunction</guid>
      <pubDate>Fri, 06 Sep 2024 19:17:51 GMT</pubDate>
    </item>
    <item>
      <title>是否可以使用 `sklearn` 管道中的 `ravel()` 或 `to_numpy()` 转换目标变量？</title>
      <link>https://stackoverflow.com/questions/78958361/is-it-possible-to-transform-a-target-variable-using-ravel-or-to-numpy-in</link>
      <description><![CDATA[我在 R markdown 文档中使用 RStudio 和 tidymodels。我想整合一些来自 scikit-learn 的模型。将数据从 R 代码块传输到 Python 代码块效果很好，但是当我使用以下代码训练和测试模型时：
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

log_reg_pipe = Pipeline([
(&#39;Logistic Regression&#39;, LogisticRegression())
])

log_reg_pipe.fit(X_train, y_train).score(X_val, y_val)

我收到错误
DataConversionWarning：当预期为 1d 数组时，传递了列向量 y。
请将 y 的形状更改为 (n_samples, )，例如使用 ravel()。

我可以通过使用 y_train[&#39;clinical_course&#39;].to_numpy() 训练数据来解决这个问题，但我希望这直接在管道中完成。这可能吗？
请注意，上面的代码只是一个简单的示例来展示我的问题。在这种情况下，X_train 有四列，y_train 有一列。
如上所述，我尝试使用 .to_numpy()，但我想要一个在管道内完成所有转换的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78958361/is-it-possible-to-transform-a-target-variable-using-ravel-or-to-numpy-in</guid>
      <pubDate>Fri, 06 Sep 2024 18:31:45 GMT</pubDate>
    </item>
    <item>
      <title>Python 神经网络中的 DeprecationWarning</title>
      <link>https://stackoverflow.com/questions/78954495/deprecationwarning-in-neural-network-with-python</link>
      <description><![CDATA[我最近一直在学习神经网络实现，在 Dence、Sequential 和预测函数之后，当我想获得结果时，VS Code 会给出此警告：
DeprecationWarning：将带有 ndim \&gt; 0 的数组转换为标量已被弃用，
并且将来会出错。在执行此操作之前，请确保从数组中提取单个元素。 （已弃用 NumPy 1.25。）

p[i,0] = my_sequence(X[i],W1,b1,W2,b2)

def my_dense(a_in,W,b): # 矩阵的大写 W
units = W.shape[1]
a_out = np.zeros(units)
for j in range(units):
w = W[:,j]
z = np.dot(w,a_in) + b[j]
a_out[j] = sigmoid(z)
return a_out
def my_sequence(a0,W1,b1,W2,b2): # a0 : x（输入）
a1 = my_dense(a0,W1,b1)
a2 = my_dense(a1,W2,b2)
return a2
def my_predict(X,W1,b1,W2,b2):
m = X.shape[0]
p = np.zeros((m,1))
for i in range(m):
p[i,0] = my_sequence(X[i],W1,b1,W2,b2)
return(p) # 预测矩阵中的 p
X = np.array([[210,17],
[190,20],
[240,19]])
W1 = np.array( [[-8.93, 0.29, 12.9 ],
[-0.1, -7.32, 10.81]] )
b1 = np.array( [-9.82, -9.28, 0.96] )
W2 = np.array( [[-31.18],
[-27.59],
[-32.56]] )
b2 = np.array( [15.41] )
norm_l.adapt(X)
X_n = norm_l(X)
predictions = my_predict(X_n,W1_tmp,b1_tmp,W2_tmp,b2_tmp)
]]></description>
      <guid>https://stackoverflow.com/questions/78954495/deprecationwarning-in-neural-network-with-python</guid>
      <pubDate>Thu, 05 Sep 2024 19:03:34 GMT</pubDate>
    </item>
    <item>
      <title>运行 Jenkins 管道时如何修复“脚本返回退出代码 15”</title>
      <link>https://stackoverflow.com/questions/78885552/how-to-fix-script-returned-exit-code-15-when-running-jenkins-pipeline</link>
      <description><![CDATA[我正在使用 Jenkins 定义管道。我正在开发一个文本摘要器项目，并使用 jenkins 进行 CICD。触发管道后，在 CD 阶段我收到以下错误：
ssh -o StrictHostKeyChecking=no -l ubuntu 3.226.221.21 &#39;cd /home/ubuntu/ &amp;&amp; wget https://raw.githubusercontent.com/mishraatharva/textsummarization/main/docker-compose.yml &amp;&amp; export IMAGE_NAME=${AWS_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com/textsum:latest &amp;&amp; aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ${AWS_ACCOUNT_ID}.dkr.ecr.us-east-1.amazonaws.com &amp;&amp; docker compose up -d &#39;
Shell 脚本
1.6 秒
+ ssh -o StrictHostKeyChecking=no -l ubuntu 3.226.221.21 cd /home/ubuntu/ &amp;&amp; wget https://raw.githubusercontent.com/mishraatharva/textsummarization/main/docker-compose.yml &amp;&amp; export IMAGE_NAME=****:latest &amp;&amp; aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin ****.dkr.ecr.us-east-1.amazonaws.com &amp;&amp; docker compose up -d 
--2024-08-18 19:19:08-- https://raw.githubusercontent.com/mishraatharva/textsummarization/main/docker-compose.yml
正在解析 raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...
正在连接到 raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... 已连接。
HTTP 请求已发送，正在等待响应... 200 OK
长度：95 [text/plain]
保存至：‘docker-compose.yml.10’
0K 100% 3.77M=0s
2024-08-18 19:19:08 (3.77 MB/s) - ‘docker-compose.yml.10’ 已保存 [95/95]
警告！您的密码将以未加密形式存储在 /home/ubuntu/.docker/config.json 中。
配置凭据助手以删除此警告。请参阅
https://docs.docker.com/engine/reference/commandline/login/#credential-stores
登录成功
yaml：第 229 行：此上下文中不允许映射值
脚本返回退出代码 15
Jenkins 2.462.1

我不知道如何解决这个问题：
我正在共享包含 jenkins 文件的 github repo。
https://github.com/mishraatharva/textsummarization
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78885552/how-to-fix-script-returned-exit-code-15-when-running-jenkins-pipeline</guid>
      <pubDate>Sun, 18 Aug 2024 20:03:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在 nltk 中下载 punkt tokenizer？</title>
      <link>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</link>
      <description><![CDATA[我使用 安装了 NLTK 库
pip install nltk

在使用库时
from nltk.tokenize import sent_tokenize 
sent_tokenize(text)

我收到此错误
LookupError: 
**************************************************************************
未找到资源 punkt。
请使用 NLTK 下载器获取资源：

&gt;&gt;&gt; import nltk
&gt;&gt;&gt; nltk.download(&#39;punkt&#39;)

有关更多信息，请参阅：https://www.nltk.org/data.html

尝试加载 tokenizers/punkt/english.pickle

搜索位置：
- &#39;C:\\Users\\adars/nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\share\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\nltk_data&#39;
- &#39;C:\\Users\\adars\\AppData\\Roaming\\nltk_data&#39;
- &#39;C:\\nltk_data&#39;
- &#39;D:\\nltk_data&#39;
- &#39;E:\\nltk_data&#39;
- &#39;&#39;

因此，为了解决此错误，我尝试了
import nltk
nltk.download(&#39;punkt&#39;)

但是我无法下载此包，因为每次运行此包时都会出现错误，提示
[nltk_data] 加载 punkt 时出错：&lt;urlopen 错误 [WinError 10060] A
[nltk_data] 连接尝试失败，因为连接方
[nltk_data] 在一段时间后未正确响应，或者
[nltk_data] 建立连接失败，因为连接的主机
[nltk_data] 未响应&gt;

请帮帮我]]></description>
      <guid>https://stackoverflow.com/questions/77131746/how-to-download-punkt-tokenizer-in-nltk</guid>
      <pubDate>Tue, 19 Sep 2023 04:36:59 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch“在 DataLoader 工作进程 0 中捕获 IndexError”、“IndexError：数组索引太多”</title>
      <link>https://stackoverflow.com/questions/61900138/pytorch-caught-indexerror-in-dataloader-worker-process-0-indexerror-too-man</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/61900138/pytorch-caught-indexerror-in-dataloader-worker-process-0-indexerror-too-man</guid>
      <pubDate>Tue, 19 May 2020 20:25:06 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 中的“unsqueeze”起什么作用？</title>
      <link>https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch</link>
      <description><![CDATA[PyTorch 文档中写道：

返回一个在指定位置插入维度为 1 的新张量。[...]
&gt;&gt;&gt; x = torch.tensor([1, 2, 3, 4])
&gt;&gt;&gt; torch.unsqueeze(x, 0)
tensor([[ 1, 2, 3, 4]])
&gt;&gt;&gt; torch.unsqueeze(x, 1)
tensor([[ 1],
[ 2],
[ 3],
[ 4]])

]]></description>
      <guid>https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch</guid>
      <pubDate>Sun, 28 Jul 2019 01:43:43 GMT</pubDate>
    </item>
    </channel>
</rss>