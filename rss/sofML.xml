<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 25 Dec 2023 03:15:50 GMT</lastBuildDate>
    <item>
      <title>NLP TFBertForSequenceClassification 文本分类非常慢</title>
      <link>https://stackoverflow.com/questions/77712257/nlp-tfbertforsequenceclassification-text-classification-being-very-slow</link>
      <description><![CDATA[我一直在尝试训练TFBERtForSequenceClassification来解决文本分类问题；但是，当我尝试执行模型时，它非常慢，有时甚至会崩溃。
我的数据集分为训练、验证、测试。它也相当大。
训练样本大小：315057。
验证样本大小：39382。
测试样本大小：39383
from Transformers import TFBertForSequenceClassification, BertConfig

伯特 = TFBertForSequenceClassification.from_pretrained(
    &#39;bert-base-uncased&#39;,
    num_labels = 6 # 标签数量
）

模型=顺序（[
        输入（形状=（无，），dtype=tf.int32），
        伯特,
        密集（64，激活=&#39;relu&#39;），
        辍学率（0.3），
        密集（6，激活=&#39;softmax&#39;）
    ]）

模型.编译(
        损失=&#39;sparse_categorical_crossentropy&#39;,
        优化器=keras.optimizers.Adam(learning_rate = 0.001)
        指标=[&#39;准确性&#39;]
）

模型.summary()

h_bert = bert_model.fit(
    训练输入_tf，
    训练标签_tf，
    验证数据=（val_inputs_tf，val_labels_tf），
    纪元=2，
    批量大小=128，
    回调=[
        EarlyStopping（监视器=&#39;val_accuracy&#39;，耐心=2）
    ]
）


有什么办法可以提高性能吗？我的模型配置有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77712257/nlp-tfbertforsequenceclassification-text-classification-being-very-slow</guid>
      <pubDate>Mon, 25 Dec 2023 01:48:31 GMT</pubDate>
    </item>
    <item>
      <title>零参数向量在张量流中如何工作？</title>
      <link>https://stackoverflow.com/questions/77712255/how-the-parameter-vector-of-zeroes-works-in-tensorflow</link>
      <description><![CDATA[所以，我正在关注 Chris Mattman 写的关于 Tensorflow 的书。它有很多错误并且已经过时，但我仍在尝试用它进入机器学习（书中还有一些有趣的概念）
这是代码：
导入tensorflow为tf
tf.disable_v1_behavior()
#...
#...
#...
定义模型（X，w）：
    条款 = []
    对于范围内的 i(num_coeffs)：#num_coeffs = 6
        项 = tf.multiply(w[i], tf.pow(X, i))
        条款.append(term)
    返回 tf.add_n(术语)

w = tf.Variable([0.]*num_coeffs, name=&quot;参数&quot;)
y_model = model(X, w) #X = tf.placeholder(tf.float32)


我的问题：我们如何将 0. 乘以变量中的某个值并得到与 0 不同的值？
编辑：我忘了提，它是多项式回归模型 =)]]></description>
      <guid>https://stackoverflow.com/questions/77712255/how-the-parameter-vector-of-zeroes-works-in-tensorflow</guid>
      <pubDate>Mon, 25 Dec 2023 01:47:43 GMT</pubDate>
    </item>
    <item>
      <title>假新闻检测数据集。 （CSV 格式）[关闭]</title>
      <link>https://stackoverflow.com/questions/77712037/dataset-for-fake-news-detections-csv-format</link>
      <description><![CDATA[我想实现一个专门针对某个地区的假新闻检测的机器学习模型，我需要一个针对该主题的大型数据集，我的主要想法是在一个网站中实现它，其中将给出 URL 链接用户可以选择输入主题的 URL 或标题。但是，我在为此寻找数据集时遇到困难。
有什么见解、建议或资源可以帮助我推进这个项目吗？]]></description>
      <guid>https://stackoverflow.com/questions/77712037/dataset-for-fake-news-detections-csv-format</guid>
      <pubDate>Sun, 24 Dec 2023 22:37:35 GMT</pubDate>
    </item>
    <item>
      <title>为什么支持向量机的 varImp() 出现错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77711844/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</link>
      <description><![CDATA[我尝试在 R 中输出支持向量机二元分类模型的变量重要性，但它不断产生错误。
我在 Iris 数据集上尝试了相同的代码，它按预期工作。但是，当我尝试使用自己的数据集修改模型的代码时，会产生错误。模型创建效果很好；但是，当我尝试输出变量重要性时，会出现错误。
我正在使用此处链接的以下数据集，在我的工作目录中保存为“titanic.csv”：https://www.kaggle.com/datasets/shubhamgupta012/titanic-dataset/data
这是我尝试过的代码：
泰坦尼克号 &lt;- read_csv(&#39;titanic.csv&#39;)

trctrl &lt;- trainControl(方法 = &quot;cv&quot;, 数字 = 10, savePredictions=TRUE)

svm &lt;- train(as.factor(Survived)~., data = titanic, method =“svmLinear”, trControl=trctrl)

varImp（支持向量机）

分配 svm 的行工作正常，但 varImp(svm) 行会产生以下错误消息：
regMod$residuals 中的错误：$ 运算符对于原子向量无效
另外：警告消息：
在mean.default(y, rm.na = TRUE)中：
  参数不是数字或逻辑：返回 NA

如何解决此问题并输出泰坦尼克号数据集的变量重要性表？]]></description>
      <guid>https://stackoverflow.com/questions/77711844/why-am-i-getting-an-error-with-varimp-for-support-vector-machine</guid>
      <pubDate>Sun, 24 Dec 2023 20:42:56 GMT</pubDate>
    </item>
    <item>
      <title>在人工智能快速发展的背景下探索职业道路[关闭]</title>
      <link>https://stackoverflow.com/questions/77711721/navigating-career-paths-amidst-rapid-ai-advancements</link>
      <description><![CDATA[随着人工智能继续快速发展，我正在考虑职业选择并寻求对当前和未来前景的见解。考虑到人工智能的动态本质，我对网络开发、应用程序开发、数据科学、数据结构和算法、机器学习和人工智能等各个领域的机会感到好奇。

网页开发和应用程序开发：

鉴于人工智能的激增，网络和应用开发领域的专业人士是否仍有足够的发展空间？


数据科学：

人工智能的发展如何影响数据科学领域的机遇？这个领域是否值得投入时间和精力？


数据结构和算法：

随着人工智能变得越来越普遍，数据结构和算法仍然是基础吗？它们在当代开发角色中有多重要？


机器学习和人工智能：

在人工智能快速发展的背景下，机器学习和人工智能领域的职业前景如何？



考虑到人工智能的当前趋势和快速发展，我渴望就技能发展和职业选择做出明智的决定。来自经验丰富的专业人士的任何建议或见解将受到高度赞赏。在人工智能革命中，您如何规划自己的职业道路？对于那些进入或转型科技行业的人，您有何建议？
我问了一个问题，当前人工智能的趋势会发生什么，快速增长，就业机会是否有任何范围，如果是的话，在什么领域以及应该考虑学习什么几乎人工智能，能够编写顶级玩家的课程]]></description>
      <guid>https://stackoverflow.com/questions/77711721/navigating-career-paths-amidst-rapid-ai-advancements</guid>
      <pubDate>Sun, 24 Dec 2023 19:45:45 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在树莓派零中运行离线语音识别，或者有没有更便宜的替代方案？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77711684/is-there-a-way-to-run-offline-speech-recognition-in-raspberry-pi-zero-or-is-ther</link>
      <description><![CDATA[我正在尝试制作一款可以运行实时离线语音识别的产品，现在我知道可以使用 google api 在线执行此操作，但我不想依赖在线服务。那么有没有一种方法可以像ALEXA一样将Live语音转换为文本呢？由于 Alexa 可以以非常小的延迟进行离线实时语音识别，现在我知道有像 VOSK 这样的库可以进行离线语音识别，但问题是它们对于树莓派零来说太大了，或者太不可靠
我尝试过使用 VOSK 但不方便。我已经尝试过 google api，但从长远来看它很昂贵，而且如果离线，你就无法与产品交互，我知道在低端设备中可以这样做，因为手机也可以离线执行相同的操作，但我不知道不知道该怎么做]]></description>
      <guid>https://stackoverflow.com/questions/77711684/is-there-a-way-to-run-offline-speech-recognition-in-raspberry-pi-zero-or-is-ther</guid>
      <pubDate>Sun, 24 Dec 2023 19:29:52 GMT</pubDate>
    </item>
    <item>
      <title>随机森林与回归模型：为什么随机森林的 R 平方为负，而回归模型的 R 平方为正 [关闭]</title>
      <link>https://stackoverflow.com/questions/77711645/random-forest-vs-regression-model-why-r-squared-for-random-forest-is-negative-w</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77711645/random-forest-vs-regression-model-why-r-squared-for-random-forest-is-negative-w</guid>
      <pubDate>Sun, 24 Dec 2023 19:14:27 GMT</pubDate>
    </item>
    <item>
      <title>存储使用 Torchvision 变换时应用的精确变换</title>
      <link>https://stackoverflow.com/questions/77711542/storing-the-exact-transformation-applied-when-using-torchvision-transforms</link>
      <description><![CDATA[当我们使用 torchvision 或 albumentations 的变换时，我们可以使用随机裁剪和随机亮度对比度等功能来生成增强图像。有没有可能的方法来存储应用于图像的精确变换以获得相应的图像？]]></description>
      <guid>https://stackoverflow.com/questions/77711542/storing-the-exact-transformation-applied-when-using-torchvision-transforms</guid>
      <pubDate>Sun, 24 Dec 2023 18:31:34 GMT</pubDate>
    </item>
    <item>
      <title>人工智能数字预测[关闭]</title>
      <link>https://stackoverflow.com/questions/77711067/artificial-intelligence-number-prediction</link>
      <description><![CDATA[尽管它没有给出任何错误，但它会将我从外部上传的照片估计为 2。我的模型具有很高的准确率。有什么问题吗？
它在测试数据上运行良好。但是，当我从外部上传图像时，它无法正常工作。
请帮帮我
这是代码
将 numpy 导入为 np
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.decomposition 导入 PCA
从 sklearn.datasets 导入 fetch_openml
从 sklearn.linear_model 导入 LogisticRegression
从 sklearn.model_selection 导入 train_test_split
将 tkinter 导入为 tk
从 tkinter 导入 ttk, filedialog
从 PIL 导入图像、ImageTk

# 加载 MNIST 数据集
mnist = fetch_openml(&#39;mnist_784&#39;, 版本=1, 缓存=True)

# 将数据集分为训练集和测试集
train_img, test_img, train_lbl, test_lbl = train_test_split(mnist.data, mnist.target, test_size=1/7.0, random_state=0)

# 标准化数据
定标器=标准定标器()
缩放器.fit(train_img)
train_img = 缩放器.transform(train_img)
test_img = 缩放器.transform(test_img)

# 使用 PCA 降低维度（保留 95% 的方差）
期望方差 = 0.95
pca = PCA(n_components=desired_variance)
pca.fit(train_img)
train_img = pca.transform(train_img)
test_img = pca.transform(test_img)

# 训练逻辑回归模型
LogisticRegr = LogisticRegression(求解器=&#39;lbfgs&#39;, max_iter=10000)
LogisticsRegr.fit(train_img, train_lbl)

def 准备图像（图像路径）：
    尝试：
        # 打开图像
        img = Image.open(图像路径)
        
        # 将图像大小调整为 28x28
        img = img.resize((28, 28), Image.LANCZOS)
        
        # 将图像转换为灰度图
        img = img.convert(&#39;L&#39;)
        
        # 将图像转换为numpy数组
        img_array = np.array(img)
        
        # 压平图像
        img_array_flat = img_array.flatten()
        
        # 标准化图像
        img_array_flat_normalized = img_array_flat / 255.0

        返回 img_array_flat_normalized.reshape(1, -1)
    除了异常 e：
        print(f&quot;错误: {e}&quot;)
        返回无

def get_prediction(img_pca):
    尝试：
        返回logisticRegr.predict(img_pca)
    除了异常 e：
        print(f&quot;错误: {e}&quot;)
        返回无

def get_accuracy(test_img, test_lbl):
    尝试：
        返回logisticRegr.score(test_img, test_lbl)
    除了异常 e：
        print(f&quot;错误: {e}&quot;)
        返回无

def update_gui(图像路径):
    img_scaled = 准备图像（图像路径）
    
    如果 img_scaled 不是 None：
        img_pca = pca.transform(img_scaled)
        预测 = get_prediction(img_pca)
        准确度 = get_accuracy(test_img, test_lbl)

        print(f&quot;预测：{预测[0]}&quot;)
        print(f&quot;模型精度: {accuracy:.4f}&quot;)

        img = Image.open(图像路径)
        img = img.resize((28, 28), Image.LANCZOS)
        img = img.convert(&#39;L&#39;)
        img_tk = ImageTk.PhotoImage(img)
        img_label.config（图像=img_tk）
        img_label.image = img_tk

        Prediction_label.config(text=f&quot;预测：{预测[0]}&quot;)
        precision_label.config(text=f&quot;模型精度：{accuracy:.4f}&quot;)

# 图形用户界面
窗口 = tk.Tk()
window.title(&quot;数字识别界面&quot;)

img_label = ttk.Label(窗口)
img_label.grid（行=0，列=0，列跨度=2）

Prediction_label = ttk.Label(window, text=&quot;预测：&quot;)
Prediction_label.grid（行=1，列=0，列跨度=2）

precision_label = ttk.Label(window, text=&quot;模型准确度：&quot;)
precision_label.grid(行=2，列=0，列跨度=2)

def select_image():
    file_path = filedialog.askopenfilename()
    image_entry.delete(0, tk.END)
    image_entry.insert(0, 文件路径)

image_button = ttk.Button(window, text=“选择图像”, command=choose_image)
image_button.grid(行=3，列=0，pady=10)

image_entry = ttk.Entry(窗口)
image_entry.grid(行=3，列=1，pady=10)

Predict_button = ttk.Button(window, text=“预测”, command=lambda: update_gui(image_entry.get()))
Predict_button.grid(行=4，列=0，列跨度=2，pady=10)

窗口.mainloop()


让他猜对我从外面上传的照片中的数字。我找不到问题。]]></description>
      <guid>https://stackoverflow.com/questions/77711067/artificial-intelligence-number-prediction</guid>
      <pubDate>Sun, 24 Dec 2023 15:27:20 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习将地址文本拆分为多个组件</title>
      <link>https://stackoverflow.com/questions/77710080/split-address-text-into-components-using-machine-learning</link>
      <description><![CDATA[我有一个 CSV 文件，每一行代表地址的不同组成部分，例如城市、街道、门牌号等，然后一列在一行中包含组合地址，具有预定义的格式，例如街道房屋号码、邮政编码、城市。
我想要的是判断用户输入的地址文本的不同组成部分，例如我想知道用户是否输入了所有组件，或者只是输入了街道名称和城市等，以及这些组件的值是什么。
我可以通过机器学习技术来实现这一目标，以便我使用 CSV 文件来教导模型，这就是地址文本被分割成不同组件的方式，然后期望它根据该训练为我提供不同的组件？]]></description>
      <guid>https://stackoverflow.com/questions/77710080/split-address-text-into-components-using-machine-learning</guid>
      <pubDate>Sun, 24 Dec 2023 08:47:00 GMT</pubDate>
    </item>
    <item>
      <title>从口腔内扫描中检测点[关闭]</title>
      <link>https://stackoverflow.com/questions/77708692/detect-points-from-an-intraoral-scan</link>
      <description><![CDATA[我们需要从口腔内扫描中检测点，但我们不知道如何开始或如何注释图像以训练模型来检测看不见的图像上的点。有人可以指导我们吗？
数据由 VTP (3D) 和 PNG (2D) 文件组成（分段牙齿上下部分的扫描）。我们需要有关如何进行界标检测（描述每颗牙齿的解剖结构的点）的帮助。 在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/77708692/detect-points-from-an-intraoral-scan</guid>
      <pubDate>Sat, 23 Dec 2023 18:49:39 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：从“y”的唯一值推断出无效的类。预期：[0 1 2 ... 1387 1388 1389]，得到[0 1 2 ... 18609 24127 41850]</title>
      <link>https://stackoverflow.com/questions/72452872/valueerror-invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2</link>
      <description><![CDATA[情况：我正在尝试使用 XGBoost 分类器，但是向我弹出此错误：
“ValueError：从 y 的唯一值推断出的类无效。预期：[0 1 2 ... 1387 1388 1389]，得到[0 1 2 ... 18609 24127 41850]”。。
与这个已解决的问题不同：从“y”的唯一值推断出的类无效。预期：[0 1 2 3 4 5]，得到[1 2 3 4 5 6]，看来我有一个不同的场景，不是从0开始。
代码：
&lt;前&gt;&lt;代码&gt;X = data_concat
y = data_concat[[&#39;forward_count&#39;,&#39;comment_count&#39;,&#39;like_count&#39;]]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=72)

#训练，测试分割
print (&#39;训练集:&#39;, X_train.shape, y_train.shape) #查看分割后的大小
print (&#39;测试集：&#39;, X_test.shape, y_test.shape)

xgb = XGBClassifier()
clf = xgb.fit(X_train, y_train, eval_metric=&#39;auc&#39;) #这里是哪里得到错误

Datafrme 和框架信息如下：
DataFrame
数据帧信息
我采用了不同的 y，这意味着当 y 具有更少或更多列时，列表“[0 1 2 ... 1387 1388 1389]”将同时缩小或扩大。
如果您需要更多信息，请告诉我。感谢您的帮助:)]]></description>
      <guid>https://stackoverflow.com/questions/72452872/valueerror-invalid-classes-inferred-from-unique-values-of-y-expected-0-1-2</guid>
      <pubDate>Tue, 31 May 2022 18:55:55 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中回归的局限性？</title>
      <link>https://stackoverflow.com/questions/61731738/limitations-of-regression-in-machine-learning</link>
      <description><![CDATA[我最近一直在学习 ML 的一些核心概念，并使用 Sklearn 库编写代码。经过一些基本练习后，我尝试了来自 kaggle 的 AirBnb NYC 数据集（大约有 40000 个样本） - https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data#New_York_City_.png
我尝试建立一个模型，可以根据数据集的各种特征来预测房间/公寓的价格。我意识到这是一个回归问题，并使用这个 sklearn 备忘单，我开始尝试各种回归模型。 

我使用 sklearn.linear_model.Ridge 作为基准，在进行一些基本数据清理之后，我在测试集上得到了糟糕的 R^2 分数 0.12。然后我想，也许线性模型太简单了，所以我尝试了适用于回归的“内核技巧”方法（sklearn.kernel_ridge.Kernel_Ridge），但它们需要太多时间来适应（&gt;1小时）！为了解决这个问题，我使用 sklearn.kernel_approximation.Nystroem 函数来近似内核图，在训练之前将变换应用于特征，然后使用简单的线性回归模型。然而，如果我增加 n_components 参数，即使这样也需要花费大量时间来转换和拟合，我必须获得任何有意义的准确性提高。 
所以我现在在想，当你想对一个巨大的数据集进行回归时会发生什么？核技巧的计算量非常大，而线性回归模型则过于简单，因为实际数据很少是线性的。那么神经网络是唯一的答案还是我缺少一些聪明的解决方案？
附注我刚刚开始使用溢出，所以请让我知道我可以做些什么来改善我的问题！]]></description>
      <guid>https://stackoverflow.com/questions/61731738/limitations-of-regression-in-machine-learning</guid>
      <pubDate>Mon, 11 May 2020 14:11:10 GMT</pubDate>
    </item>
    <item>
      <title>我们如何在 CNN 中选择内核？ （卷积神经网络）</title>
      <link>https://stackoverflow.com/questions/55193099/how-do-we-select-kernels-in-cnn-convolutional-neural-networks</link>
      <description><![CDATA[在输入到神经网络之前，需要将内核应用于图像以进行特征提取。但是，我们如何理解特定的内核将有助于提取神经网络所需的特征。]]></description>
      <guid>https://stackoverflow.com/questions/55193099/how-do-we-select-kernels-in-cnn-convolutional-neural-networks</guid>
      <pubDate>Sat, 16 Mar 2019 03:16:37 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中对相似但完全相同的单词及其缩写进行分组</title>
      <link>https://stackoverflow.com/questions/51648330/group-similar-but-exact-words-and-their-abbreviation-in-python</link>
      <description><![CDATA[我有一个关于将相似单词及其缩写分组到一组的问题，例如我有下面给出的单词列表：

人工智能
人工智能
人工智能
机器学习
机器学习
数据分析
数据与分析

我想将这些词归入[人工智能、机器学习、数据分析]
我使用了 difflib.get_close_matches() 但这并没有给我想要的结果例如这就是 difflib group: Information Technology&#39;: [&#39;Information Technology&#39;,&#39;Mobile Technology&#39;, &#39;newtechnology&#39;]
我还使用了 fuzz.token_set_ratio() 但这也没有为我提供所需的结果。 Levenshtein 也没有。
如果有任何机器学习算法或任何Python库，请告诉我。]]></description>
      <guid>https://stackoverflow.com/questions/51648330/group-similar-but-exact-words-and-their-abbreviation-in-python</guid>
      <pubDate>Thu, 02 Aug 2018 07:52:04 GMT</pubDate>
    </item>
    </channel>
</rss>