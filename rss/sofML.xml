<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 30 Apr 2024 09:15:25 GMT</lastBuildDate>
    <item>
      <title>尝试对简短的调查答案进行聚类（1 到 10 个单词）。我走在正确的轨道上吗？</title>
      <link>https://stackoverflow.com/questions/78407025/trying-to-cluster-short-survey-answers-1-to-10-words-am-i-on-the-right-track</link>
      <description><![CDATA[这是我想要完全制作的内容的解释（这是学校的一个项目）。

用户只需将调查中提出的任何问题的答案放入一个文件即可。

2.机器找到相似的答案，并将它们分组到一个未命名的标签或簇下（考虑使用 MeanShift、GMM、KMeans）

如果可能的话，我还希望它为集群生成标签。

4.将聚类和标记的答案写回到文件中以供检查并用于任何目的。
关于数据的一些上下文：很多简短的答案（有一些长的，超过 10 个单词）答案，例如“我不知道”、“??”、“有帮助”、“红色”等，以及每个都有 200 到 2000 个答案。答案是荷兰语或法语，是否建议我将它们翻译成英语以获得更好的性能？通常有大约 7 到 20 个（数量较多的情况很少见）簇。我还有正确的答案标签，这样我就可以检查算法是否正确聚类。
我尝试过研究它，我需要首先对我的文本进行矢量化，为此我尝试了 scikit 中的 TF-IDF 和 Count 矢量化器。我还找到了他们的备忘单，它建议我使用 MeanShift。
我还没有尝试寻找最佳参数，但性能似乎很差（接近随机）。我使用调整兰德指数、归一化互信息和轮廓分数来评估。
我走在正确的道路上还是有更好的东西？矢量化方法、嵌入、聚类算法？]]></description>
      <guid>https://stackoverflow.com/questions/78407025/trying-to-cluster-short-survey-answers-1-to-10-words-am-i-on-the-right-track</guid>
      <pubDate>Tue, 30 Apr 2024 07:50:57 GMT</pubDate>
    </item>
    <item>
      <title>从 python 中的随机森林回归模型中查找最大值</title>
      <link>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</link>
      <description><![CDATA[当用户给出上限时，我一直在使用随机森林回归来计算广告支出回报率 (ROAS)。我的模型采用三个输入变量：电视、广播和报纸广告的成本。然而，为了找到最优值，我需要使用 for 循环来遍历每一美元，这非常耗时。有没有更快的方法来找到程序中的最高 y 值？
def ROASPrediction(Q、电视、广播、报纸)：
rec=“最佳销售推荐投资”
y_大=0
x_b=0
y_b=0
z_b=0
对于范围内的 x(TV//2,TV)：
  对于范围内的 y(Radio//2,Radio)：
    对于范围内的 z（报纸//2，报纸）：
      customer_features =np.array([x,y,z])
      customer_features1=customer_features.reshape(1, -1)
#customer_features1 =pd.DataFrame(customer_features)
      model_fit1 = joblib.load(&#39;/content/drive/MyDrive/LUV BARNWAL/ROAS.joblib&#39;)
      y_future_pred = model_fit1.predict(customer_features1)
      打印（“y_future_pred”，y_future_pred）
      if(y_future_pred[0]&gt;=y_big):
        y_big=y_future_pred[0]
        x_b=x
        y_b=y
        z_b=z
#y_future_pred1= str(y_future_pred[0]) + “M$”
#y_roas= y_future_pred[0]*1000000 / (电视+广播+报纸)
y_future_pred1= str(y_big) + “M$”
y_roas= y_big*1000000 / (电视+广播+报纸)
x_b1=str(x_b)
y_b1=str(y_b)
z_b1=str(z_b)
y_roas1=str(y_roas) + “%”
返回记录，x_b1，y_b1，z_b1，y_future_pred1，y_roas1

以下代码是我的随机森林模型。
df = pd.read_csv(&#39;/Advertising.csv&#39;)
df.head()
x = df[[&#39;电视&#39;,&#39;广播&#39;,&#39;报纸&#39;]]
y = df[[&#39;销售额&#39;]]
x_train, x_test, y_train, y_test = train_test_split (x, y, test_size=0.20 , random_state=41)
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)
rf_regressor.fit(x_train, y_train)
y_pred = rf_regressor.predict(x_test)

这是我正在使用的 csv 文件。 
有没有办法让 ROASPrediction 函数更加高效，这样就不需要 5 分钟来计算 30 美元的电视、广播和报纸？]]></description>
      <guid>https://stackoverflow.com/questions/78406689/finding-the-maximum-value-from-a-random-forest-regression-model-in-python</guid>
      <pubDate>Tue, 30 Apr 2024 06:42:36 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音输入指令如何工作？</title>
      <link>https://stackoverflow.com/questions/78406393/how-does-google-voice-typing-instructions-works</link>
      <description><![CDATA[我正在研究一些听写应用程序，例如 Nuance Dragon 等，它允许您用语音进行听写和编辑文本。为了弄清楚这个工作原理，我偶然发现了文档中的谷歌语音输入功能，我对系统的速度和准确性感到震惊。
谷歌语音输入：https://support.google.com/docs/回答/4492226?sjid=14897244542593477678-AP
细微龙：https://www.nuance.com/dragon.html&lt; /p&gt;
所以，这不仅仅是一个简单的 STT 模型来提供转录 - 它允许您转到特定单词、突出显示、应用格式等。我参与了很多后期处理（我认为）
我是一名初级机器学习工程师，所以我了解 STT 模型及其工作原理，但这个语音输入和编辑系统看起来更复杂。
我想知道这样的系统是如何工作的。任何见解将不胜感激。
我试图了解这样的系统的底层架构，但找不到任何具体的东西。我希望了解该系统的人可以帮助我理解它。]]></description>
      <guid>https://stackoverflow.com/questions/78406393/how-does-google-voice-typing-instructions-works</guid>
      <pubDate>Tue, 30 Apr 2024 05:25:06 GMT</pubDate>
    </item>
    <item>
      <title>当时间序列元数据变化时如何构建多元时间序列</title>
      <link>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</link>
      <description><![CDATA[我根据多元、地理、时间序列数据进行预测。
我的数据包括每种产品的历史价格和生产数量，不同的地方生产和销售不同的产品组。例如：

&lt;标题&gt;

旧金山
第 1 个月
第 2 个月
第 3 个月


&lt;正文&gt;

小麦





美元价格
3
4
3


生产数量T
200
100
150


苹果





美元价格
1
2
0.8


生产数量T
20
10
50




&lt;标题&gt;

布里斯班
第 1 个月
第 2 个月
第 3 个月


&lt;正文&gt;

米饭





美元价格
3
4
3


生产数量T
200
100
150


香蕉





美元价格
5
4
3


生产数量T
200
300
450



每个地点的产品列表都不同。我正在寻找异常情况并预测消费类别（我有这方面的专家历史）。我应该如何构建它来进行训练和预测？
&lt;小时/&gt;
我的猜测（您可能可以停止阅读这里，因为这是新手的猜测，但建议包括迄今为止完成的工作）：
我可以使用的一种方法是将所有价格标准化并平均。 （收集每个区域最重要产品的价格。）但这会消除很多细节。我可以根据种植的数量来猜测每种产品的重要性，但这通常会产生误导。价格和产量之间的关系和紧张关系很重要。
我猜想，暴力方法是在每个示例中包含每个产品，并为未在某个区域交易的任何产品的时间序列使用一个空令牌。但这将是一个非常稀疏且庞大的数据集。
我可以说product1=“大米w2v嵌入”，product2=“香蕉w2v嵌入”，price_timeseries1=[大米价格]，price_timeseries2=[香蕉价格]（加上产量，以及在另一个例子中，小麦和苹果也是如此）？有任何模型能够解释这一点吗？
我最好的猜测是将产品分类，例如，将大米和小麦分类为“碳水化合物”，然后标准化，然后对每个类别的产品进行平均。 （我确实有一个层次结构，但是有没有办法可以导出或学习分类？）这在统计上有效吗？
源地理数据以行政单位（城镇边界多边形）为单位。我正在考虑选择（a）将所有内容转换为 100km2 网格，或（b）cos（lat）.cos（lon），cos（lat）.sin（lon），sin（lat） 形状质心 lon/lat，获取 3D 中的（缩放）坐标，加上面积。选项（b）更容易，除了管理单位随着时间的推移而变化，所以我必须将旧的数字重新分配到最新的边界。
（我还将添加位置元数据，例如国家/地区、人口、季节时间序列等）
有什么建议/预感吗？
我（也许天真地）正在考虑 ARIMA、XGBoost、LSTM、timeseries变压器，也许Mamba，如果相关的话。鉴于我完全缺乏经验，我怀疑 XGBoost 可能是复杂性/功能和新手超参数调整技能的最佳点，尽管我会尝试更复杂的架构，因为我知道树会错过生产和价格之间的相互作用，这在这里很重要。&lt; /p&gt;
非常感谢您提供任何提示。]]></description>
      <guid>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</guid>
      <pubDate>Tue, 30 Apr 2024 05:08:43 GMT</pubDate>
    </item>
    <item>
      <title>选择准确率相似但变量数不同的模型</title>
      <link>https://stackoverflow.com/questions/78406265/choosing-model-with-similar-accuracy-but-different-numbers-of-variables</link>
      <description><![CDATA[我使用不同的变量集开发了机器学习模型 (XGBClassifier)，两组变量的准确率都达到了 80% 左右。但是，一个模型使用了 17 个变量，而另一个模型使用了 18 个变量。我不确定要选择哪个模型进行部署。以下是我正在考虑的一些因素：

可解释性：我理解，为了便于解释，通常首选变量较少的简单模型。这是否意味着我应该选择具有 17 个变量的模型？

过度拟合：即使使用两个变量集具有相似的准确度得分，具有 18 个变量的模型是否由于其更高的复杂性而更容易过度拟合？

计算效率：变量较少（17 个）的模型在训练和预测时间方面是否具有更高的计算效率？

特征重要性：如何评估具有 18 个变量的模型中附加变量的重要性？有没有办法确定它是否提供了有意义的见解或提高了性能？

数据质量：在做出此决定时，我是否应该考虑数据集的质量和维度？添加额外变量是否存在任何风险，例如增加对噪声或过度拟合的敏感性？

信息：更多变量是否会为模型提供更多信息，从而做出更好的决策？

考虑：我参加的是 Kaggle 私人竞赛，因此评估更为重要。


考虑到这些因素，我应该如何做出选择，在准确率相似但变量数量不同的两组之间做出选择？在这种情况下，我应该遵循哪些最佳实践或指南？
任何见解或建议都将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78406265/choosing-model-with-similar-accuracy-but-different-numbers-of-variables</guid>
      <pubDate>Tue, 30 Apr 2024 04:35:46 GMT</pubDate>
    </item>
    <item>
      <title>从 Kaggle 保存的模型无法在本地环境中正确预测</title>
      <link>https://stackoverflow.com/questions/78406107/model-saved-from-kaggle-does-not-predict-properly-in-a-local-a-environment</link>
      <description><![CDATA[我有一个在 Kaggle 笔记本中训练的 GAN 架构模型，我想保存它并在本地环境中使用它。该模型是使用 GPU P100 训练的，但我的本地计算机不支持 GUP。
以下代码用于使用火炬保存模型。
torch.save(modelG.state_dict(), &#39;modelG_appl_v1.pt&#39;)

此代码用于加载模型。
类生成器（nn.Module）：
  def __init__(自身, input_size):
    超级().__init__()

    # 3 个 GRU 层，input_size = features
    self.gru_1 = nn.GRU（input_size，1024，batch_first = True）
    self.gru_2 = nn.GRU(1024、 512、batch_first = True)
    self.gru_3 = nn.GRU(512, 256, batch_first = True)
    self.gru_4 = nn.GRU(256, 128, batch_first = True)
    # 3 致密层
    self.线性_1 = nn.线性(256, 128)
    self.linear_2 = nn.Linear(128, 64)
    self.linear_3 = nn.Linear(64, 5)

    self.dropout = nn.Dropout(0.2)


  def 前向（自身，x）：
    使用_cuda = 1
    device = torch.device(“cuda” if (torch.cuda.is_available() &amp; use_cuda) else “cpu”)
    h0 = torch.zeros(1, x.size(0), 1024).to(device) # 第一个 GRU 层的初始隐藏状态 - （GRU 中的层数、批量大小、GRU 中的隐藏单元数）
    out_gru_1, _ = self.gru_1(x, h0)
    out_gru_1 = self.dropout(out_gru_1)

    h1 = torch.zeros(1, x.size(0), 512).to(设备)
    out_gru_2, _ = self.gru_2(out_gru_1, h1)
    out_gru_2 = self.dropout(out_gru_2)

    h2 = torch.zeros(1, x.size(0), 256).to(设备)
    out_gru_3, _ = self.gru_3(out_gru_2, h2)
    out_gru_3 = self.dropout(out_gru_3)

    h3 = torch.zeros(1, x.size(0), 128).to(设备)
    out_gru_4, _ = self.gru_4(out_gru_3, h3)
    out_gru_4 = self.dropout(out_gru_4)


    out_dense_1 = self.linear_1(out_gru_3[:, -1, :])
    out_dense_2 = self.线性_2(out_dense_1)
    out_dense_3 = self.线性_3(out_dense_2)

    返回out_dense_3,out_gru_3

# 加载模型
Prediction_model = Generator(62).to(&#39;cpu&#39;)
Prediction_model.load_state_dict(torch.load(&#39;../models/modelG_appl_v1.pt&#39;, map_location=torch.device(&#39;cpu&#39;)))


获取预测
#获取预测
使用 torch.no_grad()：
  预测模型.eval()
  预测，gru_layer=预测_模型（特征）

该模型加载时没有任何错误，但给出了错误的预测。我已在同一个 Kaggle 笔记本中加载相同的模型并进行预测，它给出了正确的结果。我也尝试过 pickle 和 joblib。
我想知道这个过程中是否有任何错误或建议更好的方法来保存和加载模型。我还有另一个 XGB 模型需要保存。也建议一个方法。]]></description>
      <guid>https://stackoverflow.com/questions/78406107/model-saved-from-kaggle-does-not-predict-properly-in-a-local-a-environment</guid>
      <pubDate>Tue, 30 Apr 2024 03:27:46 GMT</pubDate>
    </item>
    <item>
      <title>神经网络可以有损失函数吗？</title>
      <link>https://stackoverflow.com/questions/78405886/neural-network-can-have-loss-functions</link>
      <description><![CDATA[我自学了神经网络，因为我认为它可以解决我的问题。一般来说，我对机器学习或人工智能一无所知。
我的问题很复杂，但可以很容易地转化为：我需要两个输出，其中一个是坏的，一个是无用的，一个是好的。
示例：一款真人快打风格的游戏，我需要选择：我是否应该攻击，如果我攻击了，我是赢了还是输了。所以：

output_1：我应该攻击吗（布尔值：是/否）
output_2：如果我攻击，我造成或受到伤害（bool：造成/受到伤害）

很明显，在这种情况下，如果我一直选择不攻击，那是没有用的，所以我不能选择理想的输出。
所以我需要攻击，但前提是我的输入告诉我这是一个好主意（例如：距离合适并且对手没有攻击）。
有没有办法只用神经网络来做到这一点？我错过了什么吗？
我问“那个”著名的人工智能引擎如何做到这一点，它告诉我在神经网络中使用损失函数，但我找不到神经网络中损失函数的任何示例，只能在机器学习中找到。
那么如果我想解决这个问题，我是否需要从 NN 更改为任何其他 ML 算法？请问是哪一个？]]></description>
      <guid>https://stackoverflow.com/questions/78405886/neural-network-can-have-loss-functions</guid>
      <pubDate>Tue, 30 Apr 2024 01:52:36 GMT</pubDate>
    </item>
    <item>
      <title>RFE 与 GBM 集成，用于特征选择和超参数调整</title>
      <link>https://stackoverflow.com/questions/78405164/integration-of-rfe-with-gbm-for-feature-selection-and-hyperparameter-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78405164/integration-of-rfe-with-gbm-for-feature-selection-and-hyperparameter-tuning</guid>
      <pubDate>Mon, 29 Apr 2024 21:00:14 GMT</pubDate>
    </item>
    <item>
      <title>如何提高汽车价格估算中的 RMSE？</title>
      <link>https://stackoverflow.com/questions/78405026/how-can-i-improve-the-rmse-in-my-car-price-estimate</link>
      <description><![CDATA[如何提高汽车价格估算中的 RMSE？

首先，我将根据行驶公里数估算缺失的条件值。

&lt;前&gt;&lt;代码&gt;`
new_condition_df = df[df[&#39;condition&#39;].map(condition_mapping) == 2]
top_1000_highest_mileage = new_condition_df.nlargest(1000, &#39;里程&#39;)[&#39;里程&#39;]
average_top_1000_highest_mileage = top_1000_highest_mileage.mean()

# 过滤 DataFrame 中条件为 null 或未指定的行
null_condition_df = df[df[&#39;条件&#39;].isnull() | (df[&#39;条件&#39;] == &#39;&#39;)]

# 根据里程条件更新“条件”
null_condition_df.loc[null_condition_df[&#39;mileage&#39;] &gt;=average_top_1000_highest_mileage, &#39;condition&#39;] = &#39;CONDITION_USED&#39;
null_condition_df.loc[null_condition_df[&#39;里程&#39;] &lt; average_top_1000_highest_mileage, &#39;条件&#39;] = &#39;CONDITION_NEW&#39;

# 使用修改后的行更新原始 DataFrame
df.update(null_condition_df)
`


删除一些空行

columns_with_null = [&#39;color&#39;, &#39;vat_reclaimable&#39;, &#39;cubic_capacity&#39;, &#39;seller_country&#39;, &#39;feature&#39;]
df.dropna（子集=columns_with_null，inplace=True）

df[&#39;air_conditioning&#39;].fillna(&#39;AIRCONDITIONING_NONE&#39;, inplace=True)
df[&#39;parking_camera&#39;].fillna(&#39;PARKINGCAMERA_NONE&#39;, inplace=True)
df[&#39;parking_sensors&#39;].fillna(&#39;PARKINGSENZOR_NONE&#39;, inplace=True)


这里我试图估计drive列的缺失值，其中包含汽车是4x4还是4x2的信息，drive包含大量空值，这就是为什么我用如此复杂的方式估计它方式

features = [&#39;里程&#39;, &#39;立方容量&#39;, &#39;功率&#39;, &#39;年份&#39;] + list(df.columns[df.columns.str.startswith(&#39;car_style_&#39;)]) + list(df .columns[df.columns.str.startswith(&#39;transmission_&#39;)]) + list(df.columns[df.columns.str.startswith(&#39;fuel_type_&#39;)])

train_data = df.dropna(subset=[&#39;drive&#39;]) # Odstranění řádků s chybějícími hodnotami sloupce &#39;drive&#39;
X_train, X_test, y_train, y_test = train_test_split(train_data[features], pd.get_dummies(train_data[&#39;drive&#39;]), test_size=0.2, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

Missing_data = df[df[&#39;drive&#39;].isnull()]
X_missing = Missing_data[特征]
预测值 = model.predict(X_missing)


df_imput = df.copy()
Predicted_df = pd.DataFrame(predicted_values, columns=y_train.columns, index=missing_data.index)
df_impulated.loc[df_impulated[&#39;drive&#39;].isnull(), y_train.columns] = Predicted_df.values

Predicted_df_encoded = pd.DataFrame(predicted_values, columns=y_train.columns, index=missing_data.index)
Predicted_df_encoded = (predicted_df_encoded &gt; 0.5).astype(int)

对于 Predicted_df_encoded.columns 中的列：
    df_impulated[column] = 0 # Přidání sloupce se všemi hodnotami 0
    df_impulated.loc[predicted_df_encoded.index, 列] = Predicted_df_encoded[列].values

unique_values_impulated_encoded = df_impulated[&#39;drive&#39;].unique()
df = df_估算
df.drop(列=[&#39;drive&#39;], inplace=True)


这里我对特征字段进行编码

from sklearn.preprocessing import MultiLabelBinarizer

mlb = MultiLabelBinarizer()
df = df.join(pd.DataFrame(mlb.fit_transform(df[&#39;feature&#39;]),columns=mlb.classes_))
df.fillna(0,就地=True)

df = df.drop(列=[&#39;特征&#39;])


培训本身

df_encoded = pd.get_dummies(df)

X_train, X_test, y_train, y_test = train_test_split(df_encoded.drop(columns=[&#39;price_with_vat_czk&#39;]), df_encoded[&#39;price_with_vat_czk&#39;], test_size=0.25, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)


所有程序：https://onecompiler.com/python/42brp9a4r
数据集https://filetransfer.io/data-package/a0mFEfg4#link
我的 RMSE 约为 64k]]></description>
      <guid>https://stackoverflow.com/questions/78405026/how-can-i-improve-the-rmse-in-my-car-price-estimate</guid>
      <pubDate>Mon, 29 Apr 2024 20:23:39 GMT</pubDate>
    </item>
    <item>
      <title>如何可视化 yolo best.pt 模型架构</title>
      <link>https://stackoverflow.com/questions/78404883/how-to-visualize-yolo-best-pt-model-architecture</link>
      <description><![CDATA[我想以图形方式可视化 yolo v9 模型的架构
我尝试将其转换为 keras 但不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78404883/how-to-visualize-yolo-best-pt-model-architecture</guid>
      <pubDate>Mon, 29 Apr 2024 19:49:00 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 - 针对 AUC 或 F1 分数进行优化</title>
      <link>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</link>
      <description><![CDATA[我在 sklearn 中使用随机森林，并且我的数据集相当不平衡（20% 为正类，80% 为其他类）。有没有办法让它针对一些考虑到这一点的指标进行训练（优化），比如 AUC 分数或 F1 分数？我可以使用什么技巧来推动它朝这个方向发展吗？
到目前为止，我想到/尝试过的唯一方法是使用不同的类别权重。
或者，是否有其他实现（或其他模型，例如 xgboost）允许我使用这样的自定义指标？]]></description>
      <guid>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</guid>
      <pubDate>Mon, 29 Apr 2024 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：基数为 10 的 int() 的文字无效：Q-learning 中的“”</title>
      <link>https://stackoverflow.com/questions/78399063/valueerror-invalid-literal-for-int-with-base-10-in-q-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78399063/valueerror-invalid-literal-for-int-with-base-10-in-q-learning</guid>
      <pubDate>Sun, 28 Apr 2024 17:29:11 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法评估模型是否能够识别有影响的变量（使用 make_classification 生成的变量）？</title>
      <link>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</link>
      <description><![CDATA[我有一个关于 scikit-learn 的 make_classification 的问题。我使用 make_classification（二元分类任务）创建了一个数据集，目的是测试不同模型区分重要特征和不太重要特征的能力。
如何设置一个实验来评估模型是否能够识别有影响的变量？
我查看了 make_classification 的文档，但不幸的是我没有进一步了解。
我设置了以下内容：
X,y = make_classification(n_samples=50000, n_features=10, n_informative=5,
                    n_redundant=2、n_repeated=0、n_classes=2、n_clusters_per_class=2、
                          类间隔=1，
                   Flip_y=0.01，权重=[0.9,0.1]，shuffle=True，random_state=42）

谢谢您，我们非常感谢任何想法或建议。]]></description>
      <guid>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</guid>
      <pubDate>Sun, 28 Apr 2024 11:37:08 GMT</pubDate>
    </item>
    <item>
      <title>在 lightgbm 中，当数据集构建中已经存在时，为什么 train 和 cv API 接受 categorical_feature 参数</title>
      <link>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</link>
      <description><![CDATA[以下是.cv lightgbm的API
&lt;块引用&gt;
lightgbm.cv（params，train_set，num_boost_round = 100，folds = None，nfold = 5，stratified = True，shuffle = True，metrics = None，feval = None，init_model = None，feature_name =&#39;auto&#39;，categorical_feature =&#39;auto&#39;，fpreproc=None，seed=0，callbacks=None，eval_train_metric=False，return_cvbooster=False）

有一个参数cateogrical_feature
&lt;块引用&gt;
分类特征。如果是 int 列表，则解释为索引。如果是 str 列表，则解释为功能名称（还需要指定 feature_name）。

现在是 .train API 
&lt;块引用&gt;
lightgbm.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, keep_training_booster=False, 回调=None ）

这里还有一个categorical_feature参数。这方面的文档与上面相同
现在，您注意到这两个 API 都使用 lightgbm 数据集 本身带有一个categorical_feature 参数。文档完全一样
问题：

如果两者都指定，哪一个优先？
建议在哪一个位置指定 categorical_feature？
这两种选择在 lightgbm 管道的工作内部是否有任何不同？
]]></description>
      <guid>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</guid>
      <pubDate>Thu, 25 Apr 2024 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>调用 OnActionReceived 或 RequestDecision 让 Unity ML-Agent 轮流执行，观察次数较少 (0)</title>
      <link>https://stackoverflow.com/questions/78138694/call-onactionreceived-or-requestdecision-to-make-unity-ml-agents-do-their-turn</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78138694/call-onactionreceived-or-requestdecision-to-make-unity-ml-agents-do-their-turn</guid>
      <pubDate>Mon, 11 Mar 2024 06:13:00 GMT</pubDate>
    </item>
    </channel>
</rss>