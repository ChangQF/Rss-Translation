<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 07 Feb 2024 06:17:55 GMT</lastBuildDate>
    <item>
      <title>我正在做一个flutter项目基于情感的电影和歌曲推荐系统我已经完成了模型和ui，但我不知道如何将两者结合起来</title>
      <link>https://stackoverflow.com/questions/77952576/im-doing-a-flutter-project-emotion-based-movie-and-song-recommendation-system-i</link>
      <description><![CDATA[Flutter 应用程序已准备就绪，识别情绪的模型也已准备就绪，但这里唯一的问题是模型的部署，即我应该如何在 Flutter 应用程序中使用我的模型。
我尝试使用 Flask 创建 API，但似乎不起作用]]></description>
      <guid>https://stackoverflow.com/questions/77952576/im-doing-a-flutter-project-emotion-based-movie-and-song-recommendation-system-i</guid>
      <pubDate>Wed, 07 Feb 2024 06:13:54 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：值的长度（####）与索引的长度（####）不匹配[重复]</title>
      <link>https://stackoverflow.com/questions/77952546/valueerror-length-of-values-does-not-match-length-of-index</link>
      <description><![CDATA[我必须添加一列，其中包含特定行的特定值。所以我将 df 分成 3 并尝试添加值。
当添加到第二个 split df 时，我想出了
&lt;块引用&gt;
ValueError：值的长度 (4744) 与索引的长度 (1897) 不匹配

即使在 .reset_index(drop=True) 之后，它仍然显示相同的错误。
random_values = np.random.randint(10,25, size=len1)
# 将随机值分配给特定列
列名 = &#39;公交车站距离&#39;
split1[列名] = 随机值

random_values = np.random.randint(5,15, size=len2)
# 将随机值分配给特定列
split2.reset_index(drop=True)
列名 = &#39;公交车站距离&#39;
split2[列名] = 随机值

random_values = np.random.randint(0,6, size=len3)
# 将随机值分配给特定列
列名 = &#39;公交车站距离&#39;
split2[列名] = 随机值

我希望它添加与第一个拆分 (split1) 类似的值。即使删除索引后，它也是一样的。]]></description>
      <guid>https://stackoverflow.com/questions/77952546/valueerror-length-of-values-does-not-match-length-of-index</guid>
      <pubDate>Wed, 07 Feb 2024 06:08:38 GMT</pubDate>
    </item>
    <item>
      <title>当我的特征变量大部分为零时我该怎么办？</title>
      <link>https://stackoverflow.com/questions/77952098/what-should-i-do-when-my-feature-variables-are-mostly-zero</link>
      <description><![CDATA[我有一组商店销售数据，我想使用外部 POI 特征及其人口统计因素来预测其他商店的销售情况。然而，我的特征变量几乎 80% 为零，其余 20% 有不同的范围。导致所有特征都高度倾斜。
我得到了一个较低的 r 平方值，我已经尝试过随机森林、XGBOOST 以及 cat boost 回归。]]></description>
      <guid>https://stackoverflow.com/questions/77952098/what-should-i-do-when-my-feature-variables-are-mostly-zero</guid>
      <pubDate>Wed, 07 Feb 2024 03:42:49 GMT</pubDate>
    </item>
    <item>
      <title>我如何为 edx Data Science R Capstone 项目做好准备？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77952089/how-can-i-prepare-myserlf-for-edx-data-science-r-capstone-project</link>
      <description><![CDATA[我如何为 edx Data Science R Capstone 项目做好准备？
我已经完成了HarvardX 的机器学习系列课程，我想要一些建议来为这个项目做好准备。
我需要为此预留多少小时？ （我做八点到五点的生意，我有家人）
以及其他人可以给我的建议。
课程网址如下：
https://learning.edx.org/course/课程-v1：HarvardX+PH125.8x+1T2023/home]]></description>
      <guid>https://stackoverflow.com/questions/77952089/how-can-i-prepare-myserlf-for-edx-data-science-r-capstone-project</guid>
      <pubDate>Wed, 07 Feb 2024 03:39:58 GMT</pubDate>
    </item>
    <item>
      <title>推理后如何向 PyTorch 转换器添加编码器/解码器层？</title>
      <link>https://stackoverflow.com/questions/77952028/how-to-add-encoder-decoder-layers-to-pytorch-transformers-after-inference</link>
      <description><![CDATA[我有一个 PyTorch 编码解码器转换器：我想保存模型，然后加载权重，除非在放大模型中。例如，我想在 3 个编码器层和 3 个解码器层上训练模型，保存参数。然后，我想加载所有参数，但在最后添加另一个随机编码器和解码器层。然后，我想在推理过程中冻结除新层之外的所有参数。这些本质上是适配器层，但我想将它们作为块来实现。
类代码：
类 Seq2SeqTransformer(nn.Module):

  def __init__(自我,
              num_encoder_layers: int,
              num_decoder_layers: int,
              嵌入大小：整数，
              nhead：整数，
              src_vocab_size：整数，
              tgt_vocab_size：整数，
              暗淡前馈：int = 512，
              辍学：浮动= 0.1）：
    超级(Seq2SeqTransformer, self).__init__()
    self.transformer = 变压器(d_model=emb_size,
                                    n头=n头，
                                    num_encoder_layers=num_encoder_layers,
                                    num_decoder_layers=num_decoder_layers,
                                    暗淡前馈=暗淡前馈，
                                    辍学=辍学）
    self.generator = nn.Linear(emb_size, tgt_vocab_size)
    self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)
    self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)
    self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)

  def 向前（自身，
              src：张量，
              trg：张量，
              src_mask：张量，
              tgt_mask：张量，
              src_padding_mask：张量，
              tgt_padding_mask：张量，
              memory_key_padding_mask：张量）：
      src_emb = self.positional_encoding(self.src_tok_emb(src))
      tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))
      outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, 无,
                              src_padding_mask、tgt_padding_mask、内存_key_padding_mask）
      返回 self.generator(outs)

  def 编码（自身，src：张量，src_mask：张量）：
      返回 self.transformer.encoder(self.positional_encoding(
                          self.src_tok_emb(src)), src_mask)

  def解码（自身，tgt：张量，内存：张量，tgt_mask：张量）：
      返回 self.transformer.decoder(self.positional_encoding(
                        self.tgt_tok_emb(tgt))，内存，
                        tgt_掩码）

]]></description>
      <guid>https://stackoverflow.com/questions/77952028/how-to-add-encoder-decoder-layers-to-pytorch-transformers-after-inference</guid>
      <pubDate>Wed, 07 Feb 2024 03:17:33 GMT</pubDate>
    </item>
    <item>
      <title>我该如何进行模型预测？</title>
      <link>https://stackoverflow.com/questions/77951971/how-can-i-do-model-predict</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77951971/how-can-i-do-model-predict</guid>
      <pubDate>Wed, 07 Feb 2024 02:51:25 GMT</pubDate>
    </item>
    <item>
      <title>在非线性回归模型中测量 r2_score</title>
      <link>https://stackoverflow.com/questions/77951236/measuring-the-r2-score-in-a-non-linear-regression-model</link>
      <description><![CDATA[我想测量 kaggle 中可用的 kc_house_data 数据中的 r2_score，但我不明白为什么它给我一个负面结果。你能解释一下吗？
df[“组合”] = 卧室_norm + 浴室_norm + sqftliving_norm + sqftabove_norm + long_norm + lat_norm + sqftliving15_norm +yrbuilt_norm + Grade_norm + Floors_norm + sqftbasement_norm+condition_norm
cdf = df[[“组合”,“价格”]]

def log(a, Beta_1, Beta_2, Beta_3):
    y = (Beta_1 * (np.power(Beta_2, a)) + Beta_3)
    返回y
beta_3 = 0.10
贝塔_2 = 1.5
贝塔_1 = 1
x_data, y_data = (df[“组合”].值, df[“价格”].值)
x_data_norm = x_data / 最大值(x_data)
y_data_norm = y_data / max(y_data)
y_pred = log(x_data_norm, beta_1, beta_2, beta_3)
从 scipy.optimize 导入 curve_fit
popt, pcov = curve_fit(log, x_data_norm, y_data_norm)
x = np.linspace(4, 12, 21613)
x = x / 最大值(x)
plt.figure(figsize=(8,5))
y = log(x, *popt)
plt.plot(x_data_norm, y_data_norm, &#39;ro&#39;, label=&#39;data&#39;)
plt.plot(x, y, 线宽=3.0, 标签=&#39;适合&#39;)
plt.legend(loc=&#39;最佳&#39;)
plt.ylabel(&#39;价格&#39;)
plt.xlabel(&#39;组合&#39;)
plt.show()

从 sklearn.metrics 导入 r2_score
print(&quot;R2-score: %.2f&quot; % r2_score(y_data_norm , y))


我尝试在 sklearn.metrics 中使用 r2_score，我期望得到一个 0 到 1 之间的数字，但我不明白为什么它计算出负数
from sklearn.metrics import r2_score
print(&quot;R2-score: %.2f&quot; % r2_score(y_data_norm , y))
R2 分数：-59.51
]]></description>
      <guid>https://stackoverflow.com/questions/77951236/measuring-the-r2-score-in-a-non-linear-regression-model</guid>
      <pubDate>Tue, 06 Feb 2024 22:40:53 GMT</pubDate>
    </item>
    <item>
      <title>在 Rust 的“ort”包中使用 ONNX CLIP ViT-B-32，收到有关无效输入维度的错误</title>
      <link>https://stackoverflow.com/questions/77950750/using-onnx-clip-vit-b-32-in-rusts-ort-crate-getting-errors-about-invalid-inp</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77950750/using-onnx-clip-vit-b-32-in-rusts-ort-crate-getting-errors-about-invalid-inp</guid>
      <pubDate>Tue, 06 Feb 2024 20:43:57 GMT</pubDate>
    </item>
    <item>
      <title>图像的梯度批处理</title>
      <link>https://stackoverflow.com/questions/77950584/gradio-batch-processing-of-images</link>
      <description><![CDATA[我正在尝试使用 gradio.File() 处理 gradio 中的图像，但它需要一个 Zip 文件，然后我必须解压缩它并复制路径，然后打开图像。我的算法适用于 gr.image() 打开的图像，但是当我尝试对多个图像执行相同操作时，它无法正常工作。我试图找出答案，但没有成功。我想批量打开图像，它应该与 gr.Image() 相同，但多个图像。
我尝试了选择 zip 文件的方法，但它无法正确处理图像。但对于像 gr.Image() 这样的单个图像，它工作得很好。]]></description>
      <guid>https://stackoverflow.com/questions/77950584/gradio-batch-processing-of-images</guid>
      <pubDate>Tue, 06 Feb 2024 20:09:38 GMT</pubDate>
    </item>
    <item>
      <title>从头开始反向传播方法出错</title>
      <link>https://stackoverflow.com/questions/77949922/error-in-backpropagation-method-from-scratch</link>
      <description><![CDATA[我正在尝试制作一个预测加密货币价格的人工智能，现在我在反向传播方法中遇到了这个持续性错误（特别是关于 np.dot 语句中用于计算新权重的数组规模） ），我认为这可能是由于某个功能造成的，但我不知道如何纠正它。
类 Layer_Dense：
    def __init__(self, n_neurons, 权重, 偏差):
        self.n_neurons = np.array(n_neurons)
        self.weights = np.array(权重)
        self.biases = np.array(偏差)
    def 前向（自身，输入）：
        self.inputs = np.array(输入)
        self.output = np.dot(self.weights, 输入) + self.biases
    def 反向传播（自身，梯度，学习率 = 0.01）：
        梯度 = np.array(梯度)
        # 计算相对于权重和偏差的梯度
        weights_gradient = np.dot(梯度, self.inputs.T) / len(self.inputs)
        biases_gradient = np.sum(梯度) / len(self.inputs)

        # 使用一些优化算法（例如梯度下降）更新权重和偏差
        self.weights -= 学习率 * 权重梯度
        self.biases -= 学习率 *biases_gradient
        
        self.weights = np.array(self.weights)

        # 返回相对于下一层输入的梯度
        返回 np.dot(self.weights.T, 梯度)



[...]



神经网络层 = [
    Layer_Dense（neural_network_layers_and_its_neurons[1]，weights_list_of_matrises_for_continuation[0]，biases_matrix_continuation[0]），
    Layer_Dense（neural_network_layers_and_its_neurons[2]，weights_list_of_matrises_for_continuation[1]，biases_matrix_continuation[1]），
    Layer_Dense（neural_network_layers_and_its_neurons[3]，weights_list_of_matrises_for_continuation[2]，biases_matrix_continuation[2]），
    Layer_Dense（neural_network_layers_and_its_neurons[4]，weights_list_of_matrises_for_continuation[3]，biases_matrix_continuation[3]），
    Layer_Dense(neural_network_layers_and_its_neurons[5]、weights_list_of_matrises_for_continuation[4]、biases_matrix_continuation[4])
    ]




[...]




对于范围内的 i（0，Batch_size）：

        真实输出 = []

        对于 X 中的 i：
            
            当前输入=我

            # 前向传递各层
            对于 enumerate(neural_network_layers) 中的 a 层：
                层.forward（当前输入）
                如果 a != (len(neural_network_layers)-1):
                    当前输入 = 向前（层.输出）
                如果 a == (len(neural_network_layers)-1):
                    当前输入 = 层.输出
                    当前输入 = 当前输入[0]

            real_outputs.append（当前输入）

        loss_a、accuracy_a = F.accuracy_and_or_loss_in_one_output_NN(expected_outputs, real_outputs, 0)

        准确度.append(accuracy_a)
        loss.append(loss_a)
        
#这是我之前讨论过的函数

        loss_gradient = F.gradient_of_loss(expected_outputs, real_outputs)
        
        如果 a12 == 1：
            损失_b = 损失_a + 1e10
        
        当前梯度 = 损失梯度
        对于反向层（neural_network_layers）：
            current_gradient = layer.backpropagation(current_gradient,learning_rate)


def梯度损失（真实值，预测值）：
    true_values = np.array(true_values_)
    预测值 = np.array(预测值_)


    # 计算真实值和预测值之间的差异
    梯度 = 预测值 - 真实值

    返回梯度

我尝试过重塑数组，我尝试过转置它们，我已经改变了损失函数的梯度大约10次，我已经观看了3个关于偏导数的数学youtube视频，但没有任何效果]]></description>
      <guid>https://stackoverflow.com/questions/77949922/error-in-backpropagation-method-from-scratch</guid>
      <pubDate>Tue, 06 Feb 2024 18:02:18 GMT</pubDate>
    </item>
    <item>
      <title>Faiss GPU索引传递给拥抱面部训练器时无法序列化</title>
      <link>https://stackoverflow.com/questions/77949462/faiss-gpu-index-cannot-be-serialised-when-passed-to-hugging-face-trainer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77949462/faiss-gpu-index-cannot-be-serialised-when-passed-to-hugging-face-trainer</guid>
      <pubDate>Tue, 06 Feb 2024 16:45:32 GMT</pubDate>
    </item>
    <item>
      <title>如何获得更好的 AUC 分数？ （和累积提升）</title>
      <link>https://stackoverflow.com/questions/77948795/how-to-yield-a-better-auc-score-and-cumulative-lift</link>
      <description><![CDATA[我有一个包含 60 万条记录和 173 个专注于二元分类的特征的数据集。班级比例约为 98.7:1.3（1.3% 目标=1）。
目前，我正在尝试提高模型的性能，该模型的 AUC 为 73%。此外，我对前 2% 的累积提升是 10.41，对前 5% 的累积提升是 5.92。由于我只会针对正面预测分数的前 2-5%，因此我并不特别关心混淆矩阵阈值或改进矩阵值（FP、FN）。
我通过转换（交互，^2）和手动数学计算执行了特征工程。
尽管如此，在没有工程化特征的情况下训练模型后，AUC 分数大致相同，在没有工程化特征的模型中，累积提升略高。我使用了一个自动功能选择工具，该工具使用 RFE 和 XGBoost 来指示所选功能。
我应该注意到，我训练了模型，该模型具有 3 个周期的下采样数据集（3 个周期中每个周期 40k），分类比为 93.5:6.5（6.5% 目标=1），并使用常规的第 4 个周期验证数据集上的数据（原始 1.3% tareget=1 率）。我使用 H20 来训练我的模型（选择 XGBoost）。
如何提高模型得分和模型质量？我知道模型训练涉及插补，但我应该在预处理/清理阶段尝试使用 SimpleImputer、IterativeImputer 或/和 KNNImputer 吗？这会改善我的模型吗？
我尝试使用或不使用我的工程特征重新训练多个模型，并返回到第 1 步并创建更多变量（工程）以尝试帮助我的 AUC 和提升分数。]]></description>
      <guid>https://stackoverflow.com/questions/77948795/how-to-yield-a-better-auc-score-and-cumulative-lift</guid>
      <pubDate>Tue, 06 Feb 2024 15:11:26 GMT</pubDate>
    </item>
    <item>
      <title>预处理新数据以从 PyCaret 中的现有模型进行预测[关闭]</title>
      <link>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</guid>
      <pubDate>Mon, 05 Feb 2024 03:32:23 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Roberta 计算最后 4 个隐藏层的加权和？</title>
      <link>https://stackoverflow.com/questions/77933640/how-to-calculate-the-weighted-sum-of-last-4-hidden-layers-using-roberta</link>
      <description><![CDATA[这篇论文中的表格解释了获得嵌入的各种方法，我认为这些方法也适用于 Roberta：

我正在尝试使用 Roberta 计算最后 4 个隐藏层的加权和来获得令牌嵌入，但我不知道这是否是正确的方法，这是我尝试过的代码：
从变压器导入 RobertaTokenizer, RobertaModel
进口火炬

tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;)
模型 = RobertaModel.from_pretrained(&#39;roberta-base&#39;)
Caption = [&#39;这是一只黄色的鸟&#39;, &#39;示例标题&#39;]

tokens = tokenizer(标题, return_tensors=&#39;pt&#39;, padding=True)

input_ids = 标记[&#39;input_ids&#39;]
注意掩码 = 标记[&#39;注意掩码&#39;]

输出=模型（input_ids，attention_mask，output_hidden_​​states = True）

状态 = 输出.hidden_​​states
token_emb = torch.stack([states[i] for i in [-4, -3, -2, -1]]).sum(0).squeeze()
]]></description>
      <guid>https://stackoverflow.com/questions/77933640/how-to-calculate-the-weighted-sum-of-last-4-hidden-layers-using-roberta</guid>
      <pubDate>Sat, 03 Feb 2024 20:34:36 GMT</pubDate>
    </item>
    <item>
      <title>导入bertopic时导入UMAP的问题</title>
      <link>https://stackoverflow.com/questions/75158273/problem-in-importing-umap-while-importing-bertopic</link>
      <description><![CDATA[所以我的代码一切正常，然后突然 hdbscan 不再工作了，然后我重新安装了所有软件包，现在我遇到了 umap 问题。
我按照此处和其他论坛中的建议进行了操作，卸载并重新安装了 umap-learn 和 bertopic 。我可以将 umap 导入为 import umap 或 import umap.umap_ as UMAP ，问题是当我导入 bertopic 时。我尝试过：
导入bertopic

和
导入 umap.umap_ 作为 UMAP
导入bertopic

和
导入umap
导入bertopic

和
导入umap
从 bertopic 导入 BERTopic

最后：
导入 umap.umap_ 作为 UMAP
从 bertopic 导入 BERTopic

在所有情况下，当我导入 bertopic 时都会出现问题： ImportError: Cannot import name &#39;UMAP&#39; from &#39;umap&#39; (unknown location) 。我也重新启动机器几次。我不认为这个问题与环境有关，因为我之前在相同的代码运行时一直使用相同的环境： Python 3.10.7 和 Visual Code Studio 1.74.3 。 bertopic版本为0.13.0，umap-learn版本为0.5.3]]></description>
      <guid>https://stackoverflow.com/questions/75158273/problem-in-importing-umap-while-importing-bertopic</guid>
      <pubDate>Wed, 18 Jan 2023 11:06:19 GMT</pubDate>
    </item>
    </channel>
</rss>