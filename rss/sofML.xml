<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 17 Oct 2024 12:32:52 GMT</lastBuildDate>
    <item>
      <title>如何在客户端之间部署我的联邦学习模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/79097780/how-to-deploy-my-federated-learning-model-across-clients</link>
      <description><![CDATA[我有要部署的模型，但我不知道如何跨客户端部署。我已经使用 tensorflow 创建了 adaboost 模型，但我不知道如何跨客户端部署该模型。
请提出一些方法来解决我的问题。]]></description>
      <guid>https://stackoverflow.com/questions/79097780/how-to-deploy-my-federated-learning-model-across-clients</guid>
      <pubDate>Thu, 17 Oct 2024 11:07:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么我针对二元分类的多元二维卷积 LSTM 模型的超参数调整是错误的？</title>
      <link>https://stackoverflow.com/questions/79097667/why-is-my-hyperparameter-tuning-for-a-multivariate-2d-convolutional-lstm-model-f</link>
      <description><![CDATA[我尝试编写一个 2D 卷积 LSTM 模型。
我有 7514 个样本。
每个样本包含 180 分钟的数据。
有 5 个特征。
样本由连续的 120 分钟周期组成，其中每分钟的目标值为 0，然后是 60 分钟周期，每分钟的目标值为 1。
120 分钟周期表示正常活动，而 60 分钟周期表示异常活动。
序列是 Conv2D - Batch Normalization - Activation - LSTM - Fully Connected。
我不完全理解时间序列的 Conv2D 参数。
import pandas as pd
import io
import tensorflow as tf
import keras
from keras.optimizers import Adam
from keras.models import Sequential
from keras.layers import LSTM, Dense, BatchNormalization, Flatten, Conv2D, Reshape, TimeDistributed
import numpy as np
from sklearn.preprocessing import LabelEncoder

colnames=(&#39;Bx&#39;, &#39;By&#39;, &#39;Bz&#39;, &#39;Vx&#39;, &#39;Density&#39;, &#39;Labels&#39;, &#39;ID&#39;)
df = pd.read_csv(&#39;200304periodnanreplacedwithID&#39;, sep=&#39;\s+&#39;, names=colnames)
dfc=df.drop([&#39;Labels&#39;, &#39;ID&#39;], axis=1)
rmv=dfc[dfc.apply(sum, axis = 1) == 0].index
df1=df.drop(rmv)
counts = df1[&#39;ID&#39;].value_counts()
df1=df1[df1[&#39;ID&#39;].isin(counts.index[counts == 180])]
df1=df1.drop([&#39;ID&#39;], axis=1)

Xcols=[x for x in df1.columns if x!= &#39;Labels&#39;]
features=len(Xcols)
model= Sequential()
X=df1[Xcols]
X=np.resize(X, (X.shape[0], 1, X.shape[1]))
y=df1[&#39;Labels&#39;]

def basic_conv2D(n_filters=7514, fsize=5, window_size=180, n_features=5):
new_model = keras.Sequential()
new_model.add(tf.keras.layers.Conv2D(180, (3, fsize), padding=&#39;same&#39;, input_shape=(window_size, n_features, 1)))
new_model.add(BatchNormalization())
new_model.add(tf.keras.layers.Activation(&#39;relu&#39;))
new_model.add(TimeDistributed(Flatten()))
new_model.add(tf.keras.layers.LSTM(120, return_sequences=True))
new_model.add(tf.keras.layers.Dense(1))
adm = keras.optimizers.Adam(learning_rate=0.01)
new_model.compile(optimizer=adm, loss=&#39;binary_crossentropy&#39;, metrics=[keras.metrics.Recall(), keras.metrics.Precision()])
返回 new_model

m2 = basic_conv2D(n_filters=7514, fsize=5, window_size=1, n_features=5)
m2.summary()

m2_hist = m2.fit(X, y, batch_size=180, shuffle=False, validation_split=0.3, epochs=5)
]]></description>
      <guid>https://stackoverflow.com/questions/79097667/why-is-my-hyperparameter-tuning-for-a-multivariate-2d-convolutional-lstm-model-f</guid>
      <pubDate>Thu, 17 Oct 2024 10:32:43 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV 与 OpenVINO 后端：动态批次大小问题</title>
      <link>https://stackoverflow.com/questions/79097169/opencv-with-openvino-backend-problem-whit-dynamic-batch-size</link>
      <description><![CDATA[我正在使用 OpenCV（版本 4.10.0）和 OpenVINO（2023.0.1）后端编译来加载和处理深度学习模型。我已使用 ovc 和 omz_downloader 成功将模型从 Open Model Zoo 转换为 OpenVINO IR 格式。转换工作正常，但在将模型导入 OpenCV 进行推理时遇到了问题。
问题：
模型使用动态批处理大小（[-1, 3, 112, 112]）进行转换。当我尝试使用 cv::dnn::readNetFromModelOptimizer() 函数在 OpenCV 中加载此模型时，我在 OpenCV 源代码的这一部分中收到异常：
NetImplOpenVINO::createNetworkFromModelOptimizer(std::shared_ptr&lt;ov::Model&gt;&amp; ieNet) 函数
{
....
for (auto&amp; it : ieNet-&gt;get_parameters())
{
inputNames.push_back(it-&gt;get_friendly_name());
std::vector&lt;size_t&gt; dims = it-&gt;get_shape(); // 此处发生异常
inp_shapes.push_back(std::vector&lt;int&gt;(dims.begin(), dims.end()));
}
.....
}

在 OpenCV 代码中调用 it-&gt;get_shape() 时发生异常，可能是因为模型具有动态形状。
问题：
使用 OpenVINO 后端时，如何在 OpenCV 的 DNN 模块中处理具有动态批处理大小的模型？
是否有在 OpenCV 中加载具有动态输入形状的模型的解决方法，还是应该直接使用 OpenVINO 的推理引擎管理动态批处理？
环境：
OpenCV 4.10.0
OpenVINO 2023.1
Windows 11
环境 c++

静态批处理大小：我使用静态批处理大小 ([1, 3, 112, 112]) 转换了模型，并且它运行良好。但是，我需要为我的应用程序处理动态批次大小。
后端设置：我正在使用以下方法将后端设置为 OpenVINO：

`net.setPreferableBackend(cv::dnn::DNN_BACKEND_INFERENCE_ENGINE);
net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);`

任何有关使用 OpenVINO 处理 OpenCV 中的动态批次大小的帮助或见解都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/79097169/opencv-with-openvino-backend-problem-whit-dynamic-batch-size</guid>
      <pubDate>Thu, 17 Oct 2024 08:22:34 GMT</pubDate>
    </item>
    <item>
      <title>微调细分任何模型[关闭]</title>
      <link>https://stackoverflow.com/questions/79097002/fine-tuning-segment-anything-model</link>
      <description><![CDATA[我一直在尝试微调 SAM 模型，但我发现大多数教程都要求我们在微调后提供提示。 难道不能微调模型，以便它可以在不提供提示的情况下处理该特定数据集吗？
我尝试按照教程操作，但没有输出任何相关结果。我会将笔记本附在这里。]]></description>
      <guid>https://stackoverflow.com/questions/79097002/fine-tuning-segment-anything-model</guid>
      <pubDate>Thu, 17 Oct 2024 07:29:00 GMT</pubDate>
    </item>
    <item>
      <title>基于 Noise2Self 的 AI 降噪器无法正确训练</title>
      <link>https://stackoverflow.com/questions/79095888/noise2self-based-ai-denoiser-failing-to-train-properly</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79095888/noise2self-based-ai-denoiser-failing-to-train-properly</guid>
      <pubDate>Wed, 16 Oct 2024 21:30:55 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：将输入绑定到 tf.function 失败，无法将 input_tensor TensorSpec 转换为 TensorSpec</title>
      <link>https://stackoverflow.com/questions/79094829/typeerror-binding-inputs-to-tf-function-failed-can-not-cast-input-tensor-tenso</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79094829/typeerror-binding-inputs-to-tf-function-failed-can-not-cast-input-tensor-tenso</guid>
      <pubDate>Wed, 16 Oct 2024 15:43:54 GMT</pubDate>
    </item>
    <item>
      <title>需要 NeuralProphet 的帮助</title>
      <link>https://stackoverflow.com/questions/78905115/need-help-in-neuralprophet</link>
      <description><![CDATA[我想对到 2024 年底的 neuroprophet 支出进行一个简单的预测。
我以前从未编程过。有人向我推荐了 neuroprophet，因为它应该很容易使用。但我不明白 :-(
我有从 1.1.19 到 30.6.24 的支出数据，其中有些天输入的是“0”，因为那些天没有支出。所以我考虑按周汇总数据。以下是数据示例：
Datum Ausgaben
0 2019-01-07 0.00
1 2019-01-14 4921.54
2 2019-01-21 4566.80
3 2019-01-28 1946.64
4 2019-02-04 112201.45

我收到警告：
尝试从不明确的集合中推断“batch_size”。
我们发现是 15。
为了避免任何计算错误，请使用 `self.log(..., batch_size=batch_size)`。

你有什么建议，我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/78905115/need-help-in-neuralprophet</guid>
      <pubDate>Fri, 23 Aug 2024 09:02:58 GMT</pubDate>
    </item>
    <item>
      <title>如何配置 Prophet 以使用每周交易数据进行准确的每日预测？</title>
      <link>https://stackoverflow.com/questions/78839538/how-to-configure-prophet-for-accurate-daily-forecasts-with-weekly-transaction-da</link>
      <description><![CDATA[我们正在使用 Facebook Prophet 库根据从 Plaid API 获得的交易数据预测 13 周的现金流。我们的目标是生成每日预测。但是，我们在模型预测一周中每一天的交易时遇到了问题，而不仅仅是预测交易通常发生的日子（例如，每周两次交易）。
问题描述：

输入数据：我们的输入包括历史交易数据，其中包括每周几笔交易，但不包括每日交易。
当前配置：我们正在使用 Prophet 的每日季节性功能来生成每日预测。
问题：Prophet 输出包含所有日期交易的每日预测，没有反映每周只有几次交易的实际模式。

我们尝试过的方法：

零填充：为没有交易的日子添加零值，以帮助 Prophet 了解非交易日。
聚合：每周聚合交易数据，但这仍然会导致每日预测不正确预测。
模型配置：尝试使用 daily_seasonality=False，但

结果并不令人满意。
虚拟数据测试：创建具有已知模式的虚拟数据来测试

模型行为，但在实际数据中遇到类似问题。

问题：

配置建议：考虑到我们的交易通常每周发生几次，我们应该如何配置 Prophet 以更好地处理我们的数据并提供准确的每日预测？

处理零交易：我们如何确保模型在没有历史活动的日子预测零交易？

模型调整：是否有特定的参数或方法来微调 Prophet 以适应这种零星交易模式？

]]></description>
      <guid>https://stackoverflow.com/questions/78839538/how-to-configure-prophet-for-accurate-daily-forecasts-with-weekly-transaction-da</guid>
      <pubDate>Tue, 06 Aug 2024 14:14:53 GMT</pubDate>
    </item>
    <item>
      <title>处理时间序列预测的较大差距（TFT模型）[关闭]</title>
      <link>https://stackoverflow.com/questions/76229254/handling-large-gaps-for-time-series-forecasting-tft-model</link>
      <description><![CDATA[我有一个每小时时间序列数据，其中包含短和大的缺失间隙。对于小间隙，我可以使用线性插值技术来填补缺失点，但我想了解填补大间隙的最佳实践是什么？我的目标是准备数据来训练 TFT（时间融合变压器）模型，据我所知，我无法简单地消除间隙，因为数据不再连续，这会导致问题。]]></description>
      <guid>https://stackoverflow.com/questions/76229254/handling-large-gaps-for-time-series-forecasting-tft-model</guid>
      <pubDate>Thu, 11 May 2023 15:23:23 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 中的分类返回相同的分类值</title>
      <link>https://stackoverflow.com/questions/68315278/classification-in-lstm-returns-same-value-for-classification</link>
      <description><![CDATA[我有 10000 个数据，每个数据都有 0 和 1 的标签。我想使用 LSTM 进行分类，因为这是时间序列数据。
input_dim = 1
hidden_​​dim = 32
num_layers = 2
output_dim = 1

# 在这里我们将模型定义为一个类
class LSTM(nn.Module):
def __init__(self, input_dim, hidden_​​dim, num_layers, output_dim):
super(LSTM, self).__init__()
self.hidden_​​dim = hidden_​​dim
self.num_layers = num_layers
self.lstm = nn.LSTM(input_dim, hidden_​​dim, num_layers, batch_first=True)
self.fc = nn.Linear(hidden_​​dim, output_dim)

def forward(self, x):
#初始化隐藏层和单元状态
h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​dim).requires_grad_()
c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_​​dim).requires_grad_()

#我们需要分离，因为我们正在进行截断时间反向传播 (BPTT)
#如果不这样做，我们将一直反向传播到起点，即使经过另一个批次
out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))

#索引上一个时间步骤的隐藏状态
# out.size() --&gt; 100, 32, 100
# out[:, -1, :] --&gt; 100, 100 --&gt;只想要最后一步隐藏状态！
out = self.fc(out[:, -1, :])

# 用于二项分类
m = torch.sigmoid(out)

return m

model = LSTM(input_dim=input_dim, hidden_​​dim=hidden_​​dim, output_dim=output_dim, num_layers=num_layers)
loss = nn.BCELoss()

optimiser = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.00006)

num_epochs = 100

# 要展开的步骤数
seq_dim =look_back-1 

for t in range(num_epochs):
y_train_class = model(x_train)

output = loss(y_train_class, y_train)

# 将梯度归零，否则它们将在梯度之间累积epochs
optimiser.zero_grad(set_to_none=True)

# 反向传播
output.backward()

# 更新参数
optimiser.step()


这是结果的示例
此代码最初来自 kaggle，我对其进行了编辑以进行分类。请告诉我我做错了什么？
编辑 1：
添加数据加载器
从 torch.utils.data 导入 DataLoader
从 torch.utils.data 导入 TensorDataset
x_train = torch.from_numpy(x_train).type(torch.Tensor)
y_train = torch.from_numpy(y_train).type(torch.Tensor)
x_test = torch.from_numpy(x_test).type(torch.Tensor)
y_test = torch.from_numpy(y_test).type(torch.Tensor)

train_dataloader = DataLoader(TensorDataset(x_train, y_train), batch_size=128, shuffle=True)
test_dataloader = DataLoader(TensorDataset(x_test, y_test), batch_size=128, shuffle=True)

我意识到在检查结果之前我忘记了反转转换。当我这样做时，我从分类中得到了不同的值，但是所有值都在 0.001-0.009 的范围内，所以当我对它们进行四舍五入时，结果是相同的。所有分类都标记为 0。]]></description>
      <guid>https://stackoverflow.com/questions/68315278/classification-in-lstm-returns-same-value-for-classification</guid>
      <pubDate>Fri, 09 Jul 2021 10:29:00 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对 Xgboost 进行超参数调整以进行二元分类</title>
      <link>https://stackoverflow.com/questions/60538664/xgboost-hyperparameter-tuning-in-r-for-binary-classification</link>
      <description><![CDATA[我正在尝试对 xgboost-二元分类进行超参数调整，但是我得到了错误：
as.matrix(cv.res)[, 3] 中的错误：下标超出范围
此外：警告消息：&#39;early.stop.round&#39; 已弃用。
改用 &#39;early_stopping_rounds&#39;。
请参阅帮助（“弃用”）和帮助（“xgboost-deprecated”）。

如何解决？
请参阅下面的代码片段`
X_Train &lt;- as(X_train, &quot;dgCMatrix&quot;)

GS_LogLoss = data.frame(&quot;Rounds&quot; = numeric(), 
&quot;Depth&quot; = numeric(),
&quot;r_sample&quot; = numeric(),
&quot;c_sample&quot; = numeric(), 
&quot;minLogLoss&quot; = numeric(),
&quot;best_round&quot; = numeric())

for (rounds in seq(50,100, 25)) {

for (depth in c(4, 6, 8, 10)) {

for (r_sample in c(0.5, 0.75, 1)) {

for (c_sample in c(0.4, 0.6, 0.8, 1)) {

for (imb_scale_pos_weight in c(5, 10, 15, 20, 25)) {

for (wt_gamma in c(5, 7, 10)) {

for (wt_max_delta_step in c(5,7,10)) {

for (wt_min_child_weight in c(5,7,10,15)) {

set.seed(1024)
eta_val = 2 / rounds
cv.res = xgb.cv(data = X_Train, nfold = 2, label = y_train, 
nrounds = rounds, 
eta = eta_val, 
max_depth =depth,
subsample = r_sample, 
colsample_bytree = c_sample,
early.stop.round = 0.5*rounds,
scale_pos_weight= imb_scale_pos_weight,
max_delta_step = wt_max_delta_step,
gamma = wt_gamma,
objective=&#39;binary:logistic&#39;, 
eval_metric = &#39;auc&#39;,
verbose = FALSE)

print(paste(rounds,depth,r_sample,c_sample,min(as.matrix(cv.res)[,3])))
GS_LogLoss[nrow(GS_LogLoss)+1,] = c(rounds, 
depth, 
r_sample, 
c_sample, 
min(as.matrix(cv.res)[,3]), 
which.min(as.matrix(cv.res)[,3]))

}
}
}
}
}
}
}
}

`]]></description>
      <guid>https://stackoverflow.com/questions/60538664/xgboost-hyperparameter-tuning-in-r-for-binary-classification</guid>
      <pubDate>Thu, 05 Mar 2020 05:24:56 GMT</pubDate>
    </item>
    <item>
      <title>使用 LSTM 构建二元分类模型</title>
      <link>https://stackoverflow.com/questions/58285521/build-a-binary-classification-model-with-lstm</link>
      <description><![CDATA[我有一个 csv 格式的数据集，其中包含 49 列，其中一些是字符串，一些是整数。
我添加了一个新列用作标签，名为“input”，其相应标签为 0 和 1。
以下是数据集的示例：

要求考虑所有这些特征列进行模型训练。
我有哪些选项可以训练这个模型？
我应该遵循哪些步骤？]]></description>
      <guid>https://stackoverflow.com/questions/58285521/build-a-binary-classification-model-with-lstm</guid>
      <pubDate>Tue, 08 Oct 2019 11:31:16 GMT</pubDate>
    </item>
    <item>
      <title>填充大量时间序列数据</title>
      <link>https://stackoverflow.com/questions/57419021/filling-huge-large-chunks-of-time-series-data</link>
      <description><![CDATA[什么是填补时间序列数据中缺失值的最佳方法。数据在工作时间内变化很大。大量数据缺失。
我尝试过反向填充、正向填充和均值技术来填充数据。我也尝试过使用 pandas 包进行插值（线性、最近和多项式）。但得到的结果不是很有用。在此处输入图片说明
第一张图显示了 4 月 6 日至 9 日左右的缺失数据。第二张图是在使用线性插值填充缺失值后绘制的。
什么是填补此类数据的最佳方法？我担心线性插值最终会污染数据。
我读过一些关于卡尔曼滤波器的文章。不确定如何使用它。]]></description>
      <guid>https://stackoverflow.com/questions/57419021/filling-huge-large-chunks-of-time-series-data</guid>
      <pubDate>Thu, 08 Aug 2019 18:52:38 GMT</pubDate>
    </item>
    <item>
      <title>需要一些帮助来调试这个 java</title>
      <link>https://stackoverflow.com/questions/53719504/need-some-help-debugging-this-java</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/53719504/need-some-help-debugging-this-java</guid>
      <pubDate>Tue, 11 Dec 2018 07:44:58 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 scikit 线性回归找到系数的特征名称？</title>
      <link>https://stackoverflow.com/questions/34649969/how-to-find-the-features-names-of-the-coefficients-using-scikit-linear-regressio</link>
      <description><![CDATA[我使用 scikit 线性回归，如果我更改特征的顺序，系数仍会按相同顺序打印，因此我想知道特征与系数的映射。
#训练模型
model_1_features = [&#39;sqft_living&#39;, &#39;bathrooms&#39;, &#39;bedrooms&#39;, &#39;lat&#39;, &#39;long&#39;]
model_2_features = model_1_features + [&#39;bed_bath_rooms&#39;]
model_3_features = model_2_features + [&#39;bedrooms_squared&#39;, &#39;log_sqft_living&#39;, &#39;lat_plus_long&#39;]

model_1 = linear_model.LinearRegression()
model_1.fit(train_data[model_1_features], train_data[&#39;price&#39;])

model_2 = linear_model.LinearRegression()
model_2.fit(train_data[model_2_features], train_data[&#39;price&#39;])

model_3 = linear_model.LinearRegression()
model_3.fit(train_data[model_3_features], train_data[&#39;price&#39;])

# 提取系数
print model_1.coef_
print model_2.coef_
print model_3.coef_
]]></description>
      <guid>https://stackoverflow.com/questions/34649969/how-to-find-the-features-names-of-the-coefficients-using-scikit-linear-regressio</guid>
      <pubDate>Thu, 07 Jan 2016 07:58:04 GMT</pubDate>
    </item>
    </channel>
</rss>