<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 21 Jan 2024 15:13:36 GMT</lastBuildDate>
    <item>
      <title>Flower - 联邦学习的每一轮模型精度都是相同的</title>
      <link>https://stackoverflow.com/questions/77855250/model-accuracy-is-the-same-after-every-round-with-flower-federated-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77855250/model-accuracy-is-the-same-after-every-round-with-flower-federated-learning</guid>
      <pubDate>Sun, 21 Jan 2024 14:33:27 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 输入、输出和隐藏状态混淆</title>
      <link>https://stackoverflow.com/questions/77855145/lstm-input-output-and-hidden-state-confusion</link>
      <description><![CDATA[我对如何准备用于训练 LSTM 的数据感到困惑。它们有一个隐藏状态（至少在 Keras 中也是输出）和一个单元状态，它们都用于下一个时间步。我看到很多人也使用一个时间步的输出作为下一时间步的输入，但根据我的理解，信息应该已经被隐藏和/或单元状态覆盖。
有时人们想要预测时间序列的下一个时间步长并使用之前的时间步长作为输入，这对我来说很有意义。但就我而言，我有多个时间序列作为输入，多个不同时间序列作为输出，我知道这些时间序列取决于输入。
在这种情况下，您是否也会使用输出作为下一个时间步的输入？
LSTM 是解决此类问题的正确选择吗？]]></description>
      <guid>https://stackoverflow.com/questions/77855145/lstm-input-output-and-hidden-state-confusion</guid>
      <pubDate>Sun, 21 Jan 2024 14:09:41 GMT</pubDate>
    </item>
    <item>
      <title>警告：ctransformers：令牌数量（6462）超过最大上下文长度（2048）[关闭]</title>
      <link>https://stackoverflow.com/questions/77854655/warningctransformersnumber-of-tokens-6462-exceeded-maximum-context-length-2</link>
      <description><![CDATA[我正在尝试对我的 json 数据使用 Mistra 7B 指令，当我使用 Ctransformer 加载我的模型时，我收到此错误。谁能帮我解决我的问题吗？
到目前为止，我尝试了不同的方法来加载模型，但它们都不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/77854655/warningctransformersnumber-of-tokens-6462-exceeded-maximum-context-length-2</guid>
      <pubDate>Sun, 21 Jan 2024 11:46:28 GMT</pubDate>
    </item>
    <item>
      <title>“Atari 基于模型的强化学习”论文中代理的输入是什么？为什么世界模型在推理时运行？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77854230/what-is-the-input-to-the-agent-in-the-paper-model-based-reinforcement-learning</link>
      <description><![CDATA[我目前正在阅读论文“Atari 基于模型的强化学习” （链接：https://arxiv.org/abs/1903.00374）。但是，他们没有指定具体使用什么作为代理的输入。
我相信它是观察空间 - 意思是堆叠的框架。在训练期间，这些将由世界模型提供，而在推理时，真实环境将提供它们 - 对吗？然而，他们还在第 4 节“随机模型”下指定了模型。这个随机模型 - 据我所知，在某种意义上是世界模型的一部分 - 在推理时运行。但只有当我们在那段时间使用世界模型的任何输出时，这才有意义，但据我所知，我们并不这样做。也许有人能为我澄清这一点。]]></description>
      <guid>https://stackoverflow.com/questions/77854230/what-is-the-input-to-the-agent-in-the-paper-model-based-reinforcement-learning</guid>
      <pubDate>Sun, 21 Jan 2024 09:16:43 GMT</pubDate>
    </item>
    <item>
      <title>导入tensorflow.compat.v2包时出现问题[关闭]</title>
      <link>https://stackoverflow.com/questions/77853942/there-was-a-problem-when-importing-the-tensorflow-compat-v2-package</link>
      <description><![CDATA[在此处输入图像描述
我在检查 TensorFlow 版本时遇到问题。如何解决导入tensorflow.compat.v2包的问题？
在此处输入图片描述
我正在尝试查看此问题是否是由于 TensorFlow 版本造成的。]]></description>
      <guid>https://stackoverflow.com/questions/77853942/there-was-a-problem-when-importing-the-tensorflow-compat-v2-package</guid>
      <pubDate>Sun, 21 Jan 2024 07:35:37 GMT</pubDate>
    </item>
    <item>
      <title>检测图像中的地板并更改其颜色[关闭]</title>
      <link>https://stackoverflow.com/questions/77853519/detecting-the-floor-in-an-image-and-change-its-color</link>
      <description><![CDATA[我的目标是更改给定图像中的地板颜色。有没有我可以使用的工具、库、产品等？流程将非常简单：

选择照片
为地板选择新颜色
使用地板的新颜色更新图像
]]></description>
      <guid>https://stackoverflow.com/questions/77853519/detecting-the-floor-in-an-image-and-change-its-color</guid>
      <pubDate>Sun, 21 Jan 2024 03:26:35 GMT</pubDate>
    </item>
    <item>
      <title>如何预测带有字符串的结构化数据输入中的数字？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77853308/how-to-predict-a-number-in-a-structured-data-input-with-strings</link>
      <description><![CDATA[我在尝试使用字符串作为输入来预测数字时遇到了一些麻烦。为了具体化，我的输入程序是一组考虑建筑物地址以及与该建筑物关联的 ID 的列。我的数据如下所示：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

building_id
标题
简短描述
构造类型
地址
地区 - 州 - 城市
纬度 - 经度
首席信息官


&lt;正文&gt;

1836
Obra nueva destinada a galpón de 2 pisos de altura con superficie总量de 2.037 m2
加尔彭
工业
Subdivisión de la Finca Denominada Violeta S/N
阿里卡和帕里纳科塔-阿里卡地区
-19.423411,-11.371551
183653




所以，基本上我想预测的是 CIO。这是与整个项目关联的唯一编号，输入数据如下：

building_id - 整数
标题 - 字符串
建筑物外观的简短描述 - 字符串
一种构造类型，表示如何使用该构造 - 字符串
字符串形式的地址 - 字符串
建筑物所在的州和城市 - 字符串
纬度和经度 - 字符串

如何制作一个仅使用输入数据即可预测 CIO 编号（有点像 ID）的项目？我不知道如何使用字符串，所以我想了解如何正确地执行此操作并获得良好的准确性！]]></description>
      <guid>https://stackoverflow.com/questions/77853308/how-to-predict-a-number-in-a-structured-data-input-with-strings</guid>
      <pubDate>Sun, 21 Jan 2024 01:11:48 GMT</pubDate>
    </item>
    <item>
      <title>当数据超过设备/核心数量时，jax 中的并行化</title>
      <link>https://stackoverflow.com/questions/77853268/parallelization-in-jax-when-the-data-are-more-than-the-number-of-devices-cores</link>
      <description><![CDATA[我正在尝试在jax中进行并行计算。然而，就我而言，我有 100 个数据，但只有 8 个核心/设备。看起来 jax.pmap() 不支持这种情况。
我只想知道当我的数据多于 jax 并行化中的设备时，最简单的方法是什么。例如，我希望如果核心/设备完成一项工作，然后它可以计算下一项工作。
导入操作系统
os.environ[“XLA_FLAGS”] = &#39;--xla_force_host_platform_device_count=8&#39;
导入贾克斯


密钥 = jax.random.PRNGKey(0)
N = 100
x = jax.random.normal(key, (N,))


jax.pmap(jax.numpy.square)(x)

当然会报错：
编译计算需要 100 个逻辑设备，但只有 8 个 XLA 设备可用 (num_replicas=100)。
当我有100个数据但jax中只有8个设备时，有什么办法可以并行计算吗？]]></description>
      <guid>https://stackoverflow.com/questions/77853268/parallelization-in-jax-when-the-data-are-more-than-the-number-of-devices-cores</guid>
      <pubDate>Sun, 21 Jan 2024 00:47:19 GMT</pubDate>
    </item>
    <item>
      <title>将分割图像放入分类模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77853232/putting-segmented-images-into-classification-model</link>
      <description><![CDATA[我正在制作皮肤病变分类的模型。我想知道是否有办法将分割模型与分类相结合来改善结果？
我的意思是获取分割的图像并将其放入分类层中。
到目前为止，我已经创建了一个准确率约为 90% 的分割模型。我还有一个单独的分类模型，准确率约为 85%，但我想提高其准确率。]]></description>
      <guid>https://stackoverflow.com/questions/77853232/putting-segmented-images-into-classification-model</guid>
      <pubDate>Sun, 21 Jan 2024 00:29:35 GMT</pubDate>
    </item>
    <item>
      <title>多类多输出分类平台[关闭]</title>
      <link>https://stackoverflow.com/questions/77853082/multiclass-multioutput-classification-platform</link>
      <description><![CDATA[我一直在使用 Microsoft Azure 环境及其现成的模型训练、测试和部署环境。
我已经成功找到了预测模型的选项和算法：多个特征作为输入，单个变量作为输出。
例如，给定一个人的：(a) 工作范围、(b) 年龄、(c) 体重，我构建的系统能够预测（真/假）该人是否应该执行练习“E1”。 
现在，从技术上讲，人们可以训练 20 个与此类似的模型，并使用有关练习“E2”、“E3”等的“SINGLE”二进制输出。
但是，我觉得必须有一种更简单的方法。
这样，为了训练模型，我会为其提供一个 CSV 文件，每个场景/人一行：
第一人：“数据录入员”，24 岁，100 磅 ==&gt; E1 是，E2 否，E3 是
第二个人：“按摩师”，45岁，168磅==&gt; E1 是，E2 是，E3 否
等等...
什么算法/环境最适合此类任务？ （也许 Microsoft Azure 不是最好的？）
我希望无需任何编码即可执行上述设置、培训、测试和部署。
我不介意未来所有这些的编码版本；但目前我喜欢学习在无代码环境中执行此操作。
我通过使用自动化 ML 来训练我的预测模型，尝试使用 Azure ML。但是，我找不到任何功能表明 Azure 可以训练多输出模型。]]></description>
      <guid>https://stackoverflow.com/questions/77853082/multiclass-multioutput-classification-platform</guid>
      <pubDate>Sat, 20 Jan 2024 23:17:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 TreeExplainer 绘制瀑布图</title>
      <link>https://stackoverflow.com/questions/77851097/waterfall-plot-with-treeexplainer</link>
      <description><![CDATA[在 SHAP 中使用 TreeExplainer，我无法绘制瀑布图。
错误消息：
&lt;前&gt;&lt;代码&gt;---&gt; 17 shap.plots.waterfall(shap_values[0], max_display=14)
类型错误：瀑布图需要一个“Explanation”对象作为
`shap_values` 参数。

由于我的模型是基于树的，因此我使用 TreeExplainer（因为使用 xgb.XGBClassifier）。
如果我使用 Explainer 而不是 TreeExplainer，我可以绘制瀑布图。
我的代码如下：
导入 pandas 作为 pd

数据 = {
    &#39;a&#39;: [1, 2, 3, 3, 2, 1, 4, 5, 6, 7, 8, 1, 2, 3, 3, 2, 1, 4, 5, 6, 7, 8],
    &#39;b&#39;: [2, 1, 2, 3, 4, 6, 5, 8, 7, 9, 10, 2, 1, 2, 3, 4, 6, 5, 8, 7, 9, 10],
    &#39;c&#39;: [1, 5, 2, 4, 3, 9, 6, 8, 7, 10, 1, 1, 5, 2, 4, 3, 9, 6, 8, 7, 10, 1],
    &#39;d&#39;: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1],
    &#39;e&#39;: [1, 2, 3, 4, 3, 2, 1, 5, 4, 2, 1, 1, 2, 3, 4, 3, 2, 1, 5, 4, 2, 1],
    &#39;f&#39;: [1, 1, 2, 1, 2, 2, 3, 3, 3, 2, 1, 1, 1, 2, 1, 2, 2, 3, 3, 3, 2, 1],
    &#39;g&#39;: [3, 3, 2, 1, 3, 2, 1, 1, 1, 2, 2, 3, 3, 2, 1, 3, 2, 1, 1, 1, 2, 2],
    &#39;h&#39;: [1, 2, 1, 2, 3, 4, 5, 3, 4, 5, 5, 1, 2, 1, 2, 3, 4, 5, 3, 4, 5, 5],
    &#39;我&#39;: [1, 2, 1, 2, 3, 4, 5, 6, 5, 4, 6, 1, 2, 1, 2, 3, 4, 5, 6, 5, 4, 6],
    &#39;j&#39;: [5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 6],
    &#39;k&#39;: [3, 3, 2, 1, 4, 3, 2, 2, 2, 1, 1, 3, 3, 2, 1, 4, 3, 2, 2, 2, 1, 1],
    &#39;r&#39;: [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1]
}

df = pd.DataFrame(数据)

X = df.iloc[:,[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]
y = df.iloc[:,11]

从 sklearn.model_selection 导入 train_test_split，GridSearchCV
X_train、X_test、y_train、y_test = train_test_split(X、y、test_size = 0.30、random_state = 42)

将 xgboost 导入为 xgb
从sklearn.metrics导入accuracy_score，confusion_matrix，classification_report
从 sklearn.model_selection 导入 GridSearchCV

参数网格 = {
    &#39;最大深度&#39;：[6]，
    “n_估计器”：[500]，
    “学习率”：[0.3]
}


grid_search_xgboost = GridSearchCV(
    估计器 = xgb.XGBClassifier(),
    参数网格=参数网格，
    CV = 3,
    详细 = 2,
    职位数 = -1
）

grid_search_xgboost.fit(X_train, y_train)

print(&quot;最佳参数：&quot;, grid_search_xgboost.best_params_)
best_model_xgboost = grid_search_xgboost.best_estimator_

导入形状

解释器 = shap.TreeExplainer(best_model_xgboost)
shap_values = 解释器.shap_values(X_train)

shap.summary_plot（shap_values，X_train，plot_type =“条”）

shap.summary_plot(shap_values, X_train)

对于 X_train.columns 中的名称：
    shap.dependence_plot(名称, shap_values, X_train)

shap.force_plot(explainer.expected_value, shap_values[0], X_train.iloc[0], matplotlib=True)

shap.decision_plot(explainer.expected_value, shap_values[:10], X_train.iloc[:10])

shap.plots.waterfall(shap_values[0], max_display=14)

问题出在哪里？]]></description>
      <guid>https://stackoverflow.com/questions/77851097/waterfall-plot-with-treeexplainer</guid>
      <pubDate>Sat, 20 Jan 2024 12:55:45 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 中具有多个层的简单 RNN，用于顺序预测</title>
      <link>https://stackoverflow.com/questions/77848436/simple-rnn-with-more-than-one-layer-in-pytorch-for-squential-prediction</link>
      <description><![CDATA[我得到了连续的时间序列数据。在每个时间戳，只有一个变量可供观察（如果我的理解是正确的，这意味着特征数量 = 1）。我想训练一个具有多个层的简单 RNN 来预测下一个观察结果。
我使用滑动窗口创建了训练数据，窗口大小设置为8。为了给出具体的想法，下面是我的原始数据、训练数据和目标。
示例数据
0.40 0.82 0.14 0.01 0.98 0.53 2.5 0.49 0.53 3.37 0.49
训练数据
&lt;前&gt;&lt;代码&gt;X =
    0.40 0.82 0.14 0.01 0.98 0.53 2.5 0.49
    0.82 0.14 0.01 0.98 0.53 2.5 0.49 0.53
    0.14 0.01 0.98 0.53 2.5 0.49 0.53 3.37


对应的目标是
&lt;前&gt;&lt;代码&gt;Y =
     0.53
     3.37
     0.49

我将批量大小设置为 3。但它给了我一个错误
运行时错误：input.size(-1) 必须等于 input_size。期望 8，得到 1
导入火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim
导入 torch.utils.data 作为数据
将 numpy 导入为 np

X = np.array( [ [0.40, 0.82, 0.14, 0.01, 0.98, 0.53, 2.5, 0.49], [0.82, 0.14, 0.01, 0.98, 0.53, 2.5, 0.49, 0.53], [0.14, 0.01, 0.98, 0.53, 2.5, 0.49, 0.53, 3.37] ], dtype=np.float32)

Y = np.array([[0.53], [3.37], [0.49]], dtype=np.float32)

类 RNNModel(nn.Module):
    def __init__(self, input_sz, n_layers):
        超级（RNNModel，自我）.__init__()
        self.hidden_​​dim = 3*input_sz
        self.n_layers = n_layers
        输出大小 = 1
        self.rnn = nn.RNN（input_sz，self.hidden_​​dim，num_layers = n_layers，batch_first = True）
        self.线性 = nn.Linear(self.hidden_​​dim, output_sz)

    def 前向（自身，x）：
        batch_sz = x.size(0)
        hide = torch.zeros(self.n_layers, batch_sz, self.hidden_​​dim) #初始化n_layer*batch_sz维度的隐藏状态数hidden_​​dim)
        out, 隐藏 = self.rnn(x, 隐藏)
        out = out.contigious().view(-1, self.hidden_​​dim)
        返回，隐藏

device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
模型 = RNNModel(8,2)
X = torch.tensor(X[:,:,np.newaxis])
Y = torch.tensor(Y[:,:,np.newaxis])
X = X.to(设备)
Y = Y.to(设备)
模型 = model.to(设备)
优化器 = optim.Adam(model.parameters())
loss_fn = nn.MSELoss()

加载器= data.DataLoader（data.TensorDataset（X，Y），shuffle=False，batch_size=3）

n_epoch = 10
对于范围内的历元（n_epoch）：
    模型.train()
    对于加载器中的 X_batch、Y_batch：
        Y_pred = 模型(X_batch)
        损失 = loss_fn(Y_pred,Y_batch)
        优化器.zero_grad()
        loss.backward()
        优化器.step()

    如果纪元 % 10 != 0:
        继续
        模型.eval()
        使用 torch.no_grad()：
            Y_pred = 模型(X)
            train_rmse = np.sqrt(loss_fn(Y_pred,Y))
        print(“纪元 %d: 训练 RMSE %.4f” % (纪元, train_rmse))


我做错了什么？谁能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/77848436/simple-rnn-with-more-than-one-layer-in-pytorch-for-squential-prediction</guid>
      <pubDate>Fri, 19 Jan 2024 19:36:58 GMT</pubDate>
    </item>
    <item>
      <title>感知器算法未收敛于线性可分离数据</title>
      <link>https://stackoverflow.com/questions/77836071/perceptron-algorithm-not-converging-on-linearly-separable-data</link>
      <description><![CDATA[我正在研究感知器问题，我制作了一些假数据，当数据线性可分时，感知器算法不会收敛。
这是线性可分的假数据。
np.random.seed(42)
Linear_df = pd.DataFrame({
    &#39;X1&#39;：np.round（np.concatenate（[np.random.uniform（低= 0，高= 5，大小= 4），np.random.uniform（低= 8，高= 12，大小= 4） ]), 1),
    &#39;X2&#39;：np.round（np.concatenate（[np.random.uniform（低= 0，高= 5，大小= 4），np.random.uniform（低= 8，高= 12，大小= 4） ]),1),
    &#39;Y&#39;: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]
})

然后我在上面运行感知器
clf = 感知器（详细=1，max_iter=1000）
X = Linear_df[[&#39;X1&#39;, &#39;X2&#39;]]
y = 线性_df[&#39;Y&#39;]
clf.fit(X, y)
线性系数 = clf.coef_
线性偏差 = clf.intercept_[0]
打印（clf.coef_）
打印（clf.intercept_）
打印（clf.score（X，y））

8 个 epoch 后的收敛时间为 0.00 秒
[[ 2.3 -2.6]]
[17.]
0.5
但它说它在 8 个 Epoch 后收敛，并且没有产生正确的输出。]
情节如下：

有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77836071/perceptron-algorithm-not-converging-on-linearly-separable-data</guid>
      <pubDate>Wed, 17 Jan 2024 23:19:38 GMT</pubDate>
    </item>
    <item>
      <title>我无法从“typing_extensions”导入名称“TypeAliasType”</title>
      <link>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</link>
      <description><![CDATA[我是 Python 新手，发现了以下类似错误。我非常感谢您的评论。谢谢
我尝试将 Gradio 库导入为 gr
我已经尝试了一些现有的建议，但结果都是徒劳的。我不知道该怎么办]]></description>
      <guid>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</guid>
      <pubDate>Thu, 09 Nov 2023 03:38:10 GMT</pubDate>
    </item>
    <item>
      <title>在微调期间如何正确设置 pad token（不是 eos）以避免模型无法预测 EOS？</title>
      <link>https://stackoverflow.com/questions/76633368/how-does-one-set-the-pad-token-correctly-not-to-eos-during-fine-tuning-to-avoi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76633368/how-does-one-set-the-pad-token-correctly-not-to-eos-during-fine-tuning-to-avoi</guid>
      <pubDate>Fri, 07 Jul 2023 01:11:24 GMT</pubDate>
    </item>
    </channel>
</rss>