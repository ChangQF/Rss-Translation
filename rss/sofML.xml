<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Wed, 25 Sep 2024 12:33:22 GMT</lastBuildDate>
    <item>
      <title>æˆ‘æ­£åœ¨å®ç° qwen_2-vl +byaldiï¼Œç”¨äºåŸºäºè§†è§‰çš„ ocrï¼Œå¹¶å°†å…¶æ‰˜ç®¡ä¸ºåŸºäº stremlit çš„ Web åº”ç”¨ç¨‹åºï¼Œä½†å®ƒæ— æ³•æ­£å¸¸å·¥ä½œï¼Œä¸€ç›´å´©æºƒ</title>
      <link>https://stackoverflow.com/questions/79022489/i-am-doing-an-implementation-of-qwen-2-vl-byaldi-for-vision-based-ocr-and-hosti</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ª Streamlit åº”ç”¨ç¨‹åºï¼Œè¯¥åº”ç”¨ç¨‹åºåˆ©ç”¨å¤šæ¨¡æ€æ¨¡å‹è¿›è¡Œå›¾åƒæœç´¢å’Œæ–‡æœ¬æå–ã€‚ç„¶è€Œï¼Œåœ¨å°è¯•ä¸‹è½½æå–çš„æ–‡æœ¬æ—¶ï¼Œè¯¥åº”ç”¨ç¨‹åºç»å¸¸åœ¨æ–‡æœ¬æå–è¿‡ç¨‹ä¸­å´©æºƒã€‚ä»¥ä¸‹æ˜¯ç›¸å…³ä»£ç ï¼Œä»¥åŠé‡ç°é—®é¢˜çš„æ­¥éª¤ã€‚
requirement.txt
pdf2image

git+https://github.com/huggingface/transformers.git

qwen-vl-utils

#flash-attn

byaldi

qwen_vl_utils

transformers

é‡ç°æ­¥éª¤

ä½¿ç”¨æä¾›çš„ä»£ç è¿è¡Œ Streamlit åº”ç”¨ç¨‹åºã€‚
ä¸Šä¼ æœ‰æ•ˆçš„å›¾åƒæ–‡ä»¶ï¼ˆJPGã€JPEGã€PNGï¼‰ã€‚
åœ¨æä¾›çš„è¾“å…¥æ¡†ä¸­è¾“å…¥æ–‡æœ¬æŸ¥è¯¢ã€‚
å•å‡»â€œæœç´¢å¹¶æå–æ–‡æœ¬â€æŒ‰é’®ã€‚

import streamlit as st
import base64
from huggingface_hub import notebook_login
from byaldi import RAGMultiModalModel
from transformers import Qwen2VLForConditionalGenerationã€AutoTokenizerã€AutoProcessor
ä» PIL å¯¼å…¥å›¾åƒ
ä» io å¯¼å…¥ BytesIO
å¯¼å…¥ torch
å¯¼å…¥ re

@st.cache_resource
def load_models():
RAG = RAGMultiModalModel.from_pretrained(&quot;vidore/colpali&quot;, verbose=10)
model = Qwen2VLForConditionalGeneration.from_pretrained(
&quot;Qwen/Qwen2-VL-2B-Instruct&quot;,
torch_dtype=torch.float16,
device_map=&quot;auto&quot;,
)
processor = AutoProcessor.from_pretrained(&quot;Qwen/Qwen2-VL-2B-Instruct&quot;)
return RAGã€modelã€processor

RAGã€modelã€processor = load_models()

st.title(&quot;å¤šæ¨¡æ€å›¾åƒæœç´¢å’Œæ–‡æœ¬æå–Appâ€)

uploaded_file = st.file_uploader(â€œé€‰æ‹©å›¾ç‰‡â€ï¼Œtype=[â€œjpgâ€ï¼Œâ€œjpegâ€ï¼Œâ€œpngâ€])

å¦‚æœ uploaded_file ä¸ä¸º None:
image = Image.open(uploaded_file)
st.image(image, caption=&#39;Uploaded Image&#39;, use_column_width=True)

temp_image_path = â€œuploaded_image.jpegâ€
image.save(temp_image_path)

@st.cache_data
def create_rag_index(image_path):
RAG.index(
input_path=image_path,
index_name=&quot;image_index&quot;,
store_collection_with_index=True,
overwrite=True,
)

create_rag_index(temp_image_path)

text_query = st.text_input(&quot;è¾“å…¥æ‚¨çš„æ–‡æœ¬æŸ¥è¯¢&quot;)

if st.button(&quot;æœç´¢å¹¶æå–æ–‡æœ¬&quot;):
if text_query:
results = RAG.search(text_query, k=1, return_base64_results=True)

image_data = base64.b64decode(results[0].base64)
image = Image.open(BytesIO(image_data))
st.image(image, caption=&quot;ç»“æœå›¾åƒ&quot;, use_column_width=True)

messages = [
{
&quot;role&quot;: &quot;user&quot;,
&quot;content&quot;: [
{&quot;type&quot;: &quot;image&quot;},
{&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;extract text&quot;}
]
}
]

text_prompt = processing.apply_chat_template(messages, add_generation_prompt=True)

input = processing(
text=[text_prompt],
images=[image],
padding=True,
return_tensors=&quot;pt&quot;
)

è¾“å…¥ = è¾“å…¥.to(model.device)

ä½¿ç”¨ torch.no_grad():
è¾“å‡º_ids = æ¨¡å‹.generate(**è¾“å…¥, max_new_tokens=1024)

ç”Ÿæˆ_ids = è¾“å‡º_ids[:, è¾“å…¥.è¾“å…¥_ids.shape[1]:]

è¾“å‡º_text = å¤„ç†å™¨.batch_decode(
ç”Ÿæˆ_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True
)[0]

# çªå‡ºæ˜¾ç¤ºæŸ¥è¯¢çš„æ–‡æœ¬
def çªå‡ºæ˜¾ç¤º_text(text, æŸ¥è¯¢):
çªå‡ºæ˜¾ç¤º_text = æ–‡æœ¬
for word in query.split():
pattern = re.compile(re.escape(word), re.IGNORECASE)
çªå‡ºæ˜¾ç¤º_text = æ¨¡å¼.sub(lambda m: f&#39;&lt;span style=&quot;background-color: yellow;&quot;&gt;{m.group()}&lt;/span&gt;&#39;, highlight_text)
return highlight_text

highlight_output = highlight_text(output_text, text_query)

st.subheader(&quot;æå–çš„æ–‡æœ¬ï¼ˆæŸ¥è¯¢çªå‡ºæ˜¾ç¤ºï¼‰ï¼š&quot;)
st.markdown(highlighted_output, unsafe_allow_html=True)
else:
st.warning(&quot;è¯·è¾“å…¥æŸ¥è¯¢ã€‚&quot;)
else:
st.info(&quot;ä¸Šä¼ å›¾ç‰‡ä»¥å¼€å§‹ã€‚&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/79022489/i-am-doing-an-implementation-of-qwen-2-vl-byaldi-for-vision-based-ocr-and-hosti</guid>
      <pubDate>Wed, 25 Sep 2024 10:56:35 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨ AI / OCR æ£€æµ‹å’ŒéªŒè¯æ–‡æ¡£ä¸­çš„å¤é€‰æ¡†[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79022347/how-to-detect-and-validate-checkboxes-in-documents-using-ai-ocr</link>
      <description><![CDATA[æˆ‘éœ€è¦å¼€å‘å¯ä»¥è‡ªåŠ¨éªŒè¯ç§°ä¸ºâ€œW åˆåŒâ€çš„æ–‡æ¡£çš„è½¯ä»¶ã€‚è¿™äº›åˆåŒåŒ…å«è®¸å¤šéœ€è¦å¡«å†™çš„å¤é€‰æ¡†å’Œå­—æ®µï¼Œæˆ‘çš„ç›®æ ‡æ˜¯å‡†ç¡®è¯†åˆ«å“ªäº›æ¡†è¢«é€‰ä¸­å¹¶æ ¹æ®ç‰¹å®šè§„åˆ™å’Œå‚æ•°éªŒè¯å€¼ã€‚
æˆ‘æ›¾å°è¯•ä½¿ç”¨ OpenAI çš„ API æ¥æ£€æµ‹è¿™äº›å…ƒç´ ï¼Œä½†æˆ‘å‘ç°å®ƒåœ¨å¤„ç†æ–‡æ¡£ä¸­çš„å¤§é‡å¤é€‰æ¡†å’Œé€‰é¡¹æ—¶é‡åˆ°äº†å›°éš¾ã€‚å®ƒç»å¸¸ä¼šé”™è¯¯è¯†åˆ«ç»“æ„æˆ–æ— æ³•æ­£ç¡®è¯†åˆ«å¤é€‰æ¡†ã€‚
æˆ‘æ­£åœ¨å¯»æ‰¾å¯ä»¥å¸®åŠ©æˆ‘æ›´å‡†ç¡®åœ°æ‰§è¡Œæ­¤ä»»åŠ¡çš„æŠ€æœ¯ã€åº“æˆ– API çš„å»ºè®®ï¼Œæœ€å¥½ä½¿ç”¨ OCR å’Œè®¡ç®—æœºè§†è§‰ã€‚ç†æƒ³çš„è§£å†³æ–¹æ¡ˆåº”è¯¥èƒ½å¤Ÿï¼š
æ£€æµ‹ PDF æˆ–å›¾åƒæ–‡æ¡£ä¸­çš„å¤é€‰æ¡†å’Œè¾“å…¥å­—æ®µã€‚
å‡†ç¡®ç¡®å®šå¤é€‰æ¡†æ˜¯å¦è¢«é€‰ä¸­ã€‚
è¯»å–å­—æ®µå¹¶æ ¹æ®æŸäº›è§„åˆ™éªŒè¯æ•°æ®ã€‚
ä»»ä½•å…³äºå¯ä»¥ä¿ƒè¿›è¿™é¡¹ä»»åŠ¡çš„å·¥å…·æˆ–æ–¹æ³•çš„å»ºè®®éƒ½å°†ä¸èƒœæ„Ÿæ¿€ã€‚æˆ‘å¯¹åŸºäº AI çš„è§£å†³æ–¹æ¡ˆæŒå¼€æ”¾æ€åº¦ï¼Œä½†ä¹Ÿå¯¹ä¼ ç»Ÿçš„ OCR æ–¹æ³•æ„Ÿå…´è¶£ã€‚
]]></description>
      <guid>https://stackoverflow.com/questions/79022347/how-to-detect-and-validate-checkboxes-in-documents-using-ai-ocr</guid>
      <pubDate>Wed, 25 Sep 2024 10:22:52 GMT</pubDate>
    </item>
    <item>
      <title>å°†åŒçº¿æ€§é‡‡æ ·ç‰¹å¾æ˜ å°„å›ä½“ç´ </title>
      <link>https://stackoverflow.com/questions/79022319/map-bilinear-sampled-features-to-voxel-back</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªä¸“é—¨ç”¨äºåŒçº¿æ€§é‡‡æ ·çš„ç±»ã€‚æˆ‘çš„ç›®æ ‡æ˜¯å°†ä»åŒçº¿æ€§é‡‡æ ·è¿‡ç¨‹ä¸­æå–çš„ç‰¹å¾æ˜ å°„åˆ°åˆ›å»ºçš„ä½“ç´ ç½‘æ ¼ä¸­çš„é€‚å½“ä½ç½®ã€‚
å®æ–½æ­¥éª¤ï¼š
B = æ‰¹æ¬¡

C = é€šé“

S = è§†å›¾æ•°

D = æ·±åº¦

H = é«˜åº¦

W = å®½åº¦

3 = x,y,z

2 = x,y

æˆ‘åˆ›å»ºäº†ä¸€ä¸ªå…·æœ‰æ­¤å½¢çŠ¶ [B,D,H,W,3] çš„ä½“ç´ 
å¹¶ä¸”æˆ‘æœ‰ 360 ä¸ªå›¾åƒè§†å›¾æ ·æœ¬ï¼Œå°ºå¯¸ä¸º [B,S,C,H,W]
ç¬¬ä¸€æ­¥ï¼Œæˆ‘ä½¿ç”¨å¤–éƒ¨å’Œå†…éƒ¨å°†ä½“ç´ ç‚¹ï¼ˆç‚¹äº‘ï¼‰æŠ•å½±åˆ°æ¯ä¸ªå›¾åƒã€‚ç„¶åæˆ‘è¿‡æ»¤äº†å›¾åƒä¹‹å¤–çš„ç‚¹ã€‚
ç»“æœæˆ‘å¾—åˆ°äº† valid_points = [B,S,H,W,2]
æˆ‘ä» valid_points ä¸­å¯¹æˆ‘çš„ç‚¹è¿›è¡Œäº†å½’ä¸€åŒ–ï¼Œå¹¶åˆ›å»ºäº†å¤§å°ä¸º [B,S,H,W,2] çš„ç½‘æ ¼ï¼Œè¯·æ³¨æ„ï¼ŒW æ˜¯æœ‰æ•ˆç‚¹çš„æ•°é‡ï¼ŒH = 1
ç„¶åæˆ‘æ‰€åšçš„æ˜¯åº”ç”¨åŒçº¿æ€§é‡‡æ ·ï¼Œå¦‚ä»£ç æ‰€ç¤ºï¼š
valid_points = cur_coords[:, on_img[1]]

######### å°†æœ‰æ•ˆç‚¹å½’ä¸€åŒ–åœ¨ [-1, 1] ä¹‹é—´ ########
normalized_points = torch.zeros_like(valid_points)
normalized_points[:,:, 0] = 2.0 * (valid_points[:, :, 0] / (H_img - 1)) - 1.0 # å½’ä¸€åŒ–y åæ ‡
normalized_points[:,:, 1] = 2.0 * (valid_points[:, :, 1] / (W_img - 1)) - 1.0 # [N, M&#39;,2]

grid = normalized_points.unsqueeze(1).cuda() # å½¢çŠ¶ [S, H_out, W_out, 2]
sampled_features_with_location_list = []
for i in range(0,N):
img_s =camera_view_tensor[i].unsqueeze(0).permute(0, 3, 1, 2) #[B, C, H_in, W_in]
grid_s = grid[i].unsqueeze(0)
sampled_points = F.grid_sample(img_s, grid_s,mode=&#39;bilinear&#39;,
align_corners=None) # (B,N,C,H_out,W_out)
sampled_features_list.append(sampled_pointson)
sampled_points = torch.stack(sampled_features_list, dim=1) #[B = 1,S = 6,C= 3,H= 1,W =22965]

ç°åœ¨æˆ‘æƒ³åº”ç”¨é€†æ˜ å°„æ¥æå– bev ç‰¹å¾ã€‚æ€ä¹ˆåšï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79022319/map-bilinear-sampled-features-to-voxel-back</guid>
      <pubDate>Wed, 25 Sep 2024 10:14:39 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨ä¸æ–­æ¼”å˜çš„ç‰¹å¾ç©ºé—´ä¸­é‡‡ç”¨åé¦ˆè¿›è¡Œè‡ªé€‚åº”é¢„æµ‹çš„æŠ€æœ¯</title>
      <link>https://stackoverflow.com/questions/79022083/techniques-for-adaptive-prediction-with-feedback-in-an-evolving-feature-space</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ç ”ç©¶ä¸€ä¸ªé¢„æµ‹é—®é¢˜ï¼Œå…¶ä¸­ç›®æ ‡å˜é‡ ğ‘¦ æ¥è‡ªæ­£æ€åˆ†å¸ƒï¼Œè¿ç»­ç‰¹å¾ç©ºé—´ ğ‘‹ å’Œ ğ‘¦ ä¹‹é—´çš„å…³ç³»éšæ—¶é—´ä¿æŒç¨³å®šã€‚ä½†æ˜¯ï¼Œç›®æ ‡å€¼ï¼ˆä¾‹å¦‚å¹³å‡å€¼å’Œæ ‡å‡†å·®ï¼‰ä¼šéšç€ç³»ç»Ÿçš„å˜åŒ–è€Œéšæ—¶é—´å˜åŒ–ã€‚æˆ‘äº‹å…ˆå¹¶ä¸äº†è§£çœŸæ­£çš„ç›®æ ‡å€¼ï¼Œå› æ­¤æˆ‘åˆ©ç”¨åœ¨çº¿å›å½’å’Œå¼ºåŒ–å­¦ä¹  (RL) ç­‰æŠ€æœ¯æ ¹æ®åé¦ˆè¿­ä»£è°ƒæ•´æˆ‘çš„é¢„æµ‹ã€‚
åé¦ˆæœºåˆ¶ä»…æŒ‡ç¤ºæˆ‘çš„é¢„æµ‹æ˜¯é«˜ä¼°è¿˜æ˜¯ä½ä¼°ï¼Œå¹¶ä¸”æ­¤åé¦ˆæ˜¯åœ¨å»¶è¿Ÿåæä¾›çš„ã€‚è¯¯å·®å¤§å°æœªçŸ¥ï¼Œå¹¶ä¸”ä»…æä¾›æ–¹å‘æ€§åé¦ˆï¼ˆé«˜ä¼°/ä½ä¼°ï¼‰ã€‚æˆ‘ç›®å‰æ­£åœ¨ä½¿ç”¨å¢é‡æ–¹æ³•ï¼Œæ ¹æ®åé¦ˆå‘ä¸Šæˆ–å‘ä¸‹è°ƒæ•´é¢„æµ‹ä»¥æ›´æ–°é¢„æµ‹ã€‚
å…³äºæ”¹è¿›æ­¤æ–¹æ³•ï¼Œæˆ‘æœ‰ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼š
(1) æ”¹è¿›è‡ªé€‚åº”è°ƒæ•´æŠ€æœ¯ï¼š

æˆ‘ç›®å‰æ­£åœ¨ä½¿ç”¨åœ¨çº¿å›å½’å’Œ RLï¼Œåé¦ˆä¼šå‘Šè¯‰æˆ‘æ˜¯å¦å¢åŠ æˆ–å‡å°‘å…ˆå‰çš„é¢„æµ‹ã€‚é™¤äº†ç®€å•çš„å¢é‡/å‡é‡ä¹‹å¤–ï¼Œæˆ‘æ˜¯å¦åº”è¯¥æ¢ç´¢æ›´å…ˆè¿›çš„æŠ€æœ¯æ¥è¿›è¡Œæ›´æ™ºèƒ½çš„è°ƒæ•´ï¼Ÿå…·ä½“æ¥è¯´ï¼Œå½“åé¦ˆä»…é™äºè¿‡åº¦/ä¸è¶³æŒ‡ç¤ºæ—¶ï¼Œæ˜¯å¦æœ‰æ–¹æ³•å¯ä»¥è¿›è¡Œæ›´ç»†å¾®çš„è°ƒæ•´ï¼Œå¹¶ä¸”éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¿™å¯èƒ½å¯¼è‡´æ›´å¿«çš„æ”¶æ•›æˆ–æ›´å¥½çš„é¢„æµ‹ï¼Ÿ

(2) è‡ªé€‚åº”æ›´æ–°å€¼çš„æœ‰æ•ˆç®¡ç†ï¼š

ä¸ºäº†å¢å¼ºæˆ‘ç›®å‰çš„æ–¹æ³•ï¼Œæˆ‘è€ƒè™‘ä¿æŒé¢„æµ‹çš„åŠ¨æ€ä¸Šé™å’Œä¸‹é™ï¼Œå¹¶æ ¹æ®åé¦ˆè°ƒæ•´è¿™äº›ç•Œé™ï¼ˆå³ç¼©å°è¿‡åº¦/ä¸è¶³ä¼°è®¡ä¹‹é—´çš„èŒƒå›´ï¼‰ã€‚æˆ‘æ¢ç´¢çš„å¦ä¸€ç§ç­–ç•¥æ˜¯ä½¿ç”¨å…ˆå‰è°ƒæ•´çš„æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡çº¿ (EWMA)ï¼Œå…¶ä¸­åå¤çš„ä½ä¼°ä¼šå¯¼è‡´é€æ¸å¢å¤§çš„æ ¡æ­£ã€‚ä½†æ˜¯ï¼Œåœ¨å¤§å‹ç‰¹å¾ç©ºé—´ä¸­ç®¡ç†è¿™äº›è°ƒæ•´åœ¨è®¡ç®—ä¸Šæ˜¯æ˜‚è´µçš„ã€‚
æˆ‘æœ€åˆä½¿ç”¨å­—å…¸å°†ç‰¹å¾ ğ‘‹ æ˜ å°„åˆ°è¿™äº›æ›´æ–°å€¼ï¼ˆä¾‹å¦‚ç•Œé™æˆ– EWMA è°ƒæ•´ï¼‰çš„æ–¹æ³•éšç€ç‰¹å¾ç©ºé—´çš„å¢é•¿å˜å¾—ä¸åˆ‡å®é™…ã€‚æˆ‘ä¹Ÿå°è¯•å°†è¿™äº›å€¼æ˜ å°„åˆ°å›å½’æ¨¡å‹ï¼Œä½†æ•ˆæœä¸ä½³ï¼Œå¯èƒ½æ˜¯ç”±äºæ›´æ–°çš„éå¹³ç¨³æ€§è´¨ã€‚
é‰´äºè¿™äº›è°ƒæ•´å€¼ä¸æ˜¯é™æ€ç›®æ ‡ï¼Œè€Œæ˜¯åŸºäºåé¦ˆåŠ¨æ€å˜åŒ–çš„ï¼Œåœ¨é«˜ç»´ç‰¹å¾ç©ºé—´ä¸­æœ‰æ•ˆç®¡ç†æˆ–å»ºæ¨¡å®ƒä»¬çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿåœ¨è¿™æ ·çš„è®¾ç½®ä¸­ï¼Œæ˜¯å¦æœ‰æ›´åˆé€‚çš„è‡ªé€‚åº”æ›´æ–°ç­–ç•¥ï¼Œå¯èƒ½æ¶‰åŠå‡½æ•°é€¼è¿‘æŠ€æœ¯æˆ–å†…å­˜é«˜æ•ˆçš„æ•°æ®ç»“æ„ï¼Ÿ
]]></description>
      <guid>https://stackoverflow.com/questions/79022083/techniques-for-adaptive-prediction-with-feedback-in-an-evolving-feature-space</guid>
      <pubDate>Wed, 25 Sep 2024 09:24:03 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨ opencv æ¸…ç†ï¼ˆå»å™ªï¼‰å›¾åƒï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79021532/how-to-clean-denoise-an-image-using-opencv</link>
      <description><![CDATA[æˆ‘è¯•å›¾åªæ£€æµ‹è¾ƒå¤§çš„å­—æ¯å¹¶å°è¯•å°†å®ƒä»¬ä¿å­˜åœ¨ä¸€ä¸ªå¹³é¢ä¸­ï¼ˆæƒ³è±¡å®ƒæ˜¯ä¸€å—é»‘æ¿ï¼Œæˆ‘è¯•å›¾åœ¨å…¶ä¸­æ‰“å°è¾ƒå¤§çš„å­—æ¯ï¼‰ã€‚
æˆ‘åˆ°ç›®å‰ä¸ºæ­¢æ‰§è¡Œçš„æ­¥éª¤

å°†å›¾åƒè½¬æ¢ä¸º hsvã€‚

ä½¿ç”¨ inRange åŠŸèƒ½æˆ‘åˆ›å»ºäº†ä¸€ä¸ªè’™ç‰ˆã€‚

æ·»åŠ äº†å½¢æ€å­¦å…³é—­ï¼Œä»¥ä¾¿æˆ‘æ¶ˆé™¤è¾ƒå°çš„å™ªéŸ³ã€‚

ç»ˆäºå¼€å§‹ç»˜åˆ¶å¤§å­—æ¯ä¾›æˆ‘å‚è€ƒï¼ˆå¦‚ä¸‹æ‰€è¿°ï¼Œä¸€äº›å­—æ¯æœªè¢«æ£€æµ‹åˆ°ï¼‰ã€‚

å½“æˆ‘æ‰“å°é»‘æ¿æ—¶ï¼Œä¼šçœç•¥ä¸€ä¸ªæˆ–ä¸¤ä¸ªå­—æ¯ã€‚


æˆ‘æœ‰ä¸‹é¢çš„ä»£ç 
#include &lt;iostream&gt;
#include &lt;fstream&gt;

#include &lt;opencv2/imgproc.hpp&gt;
#include &lt;opencv2/highgui.hpp&gt;
#include &lt;opencv2/dnn.hpp&gt;

using namespace cv;
using namespace cv::dnn;
using namespace std;

int main()
{
// åŠ è½½å›¾åƒ
cv::Mat image = cv::imread(&quot;/run/media/cams/B4267D4B267D0F9A/Downloads/2.png&quot;);
// cv::Mat image = cv::imread(&quot;/run/media/cams/B4267D4B267D0F9A/Downloads/np7.jpg&quot;);
// cv::Mat image = cv::imread(&quot;/run/media/cams/B4267D4B267D0F9A/Downloads/license-plate.png&quot;);

if (image.empty()) {
std::cerr &lt;&lt; &quot;é”™è¯¯ï¼šæ— æ³•åŠ è½½å›¾åƒã€‚&quot; &lt;&lt; std::endl;
return -1;
}

cv::Mat resizedImage;
cv::Size newSize(513, 134);

cv::resize(image,resizedImage,newSize);

int rows = resizedImage.rows;
int cols = resizedImage.cols;

cv::Mat result(rows, cols ,resizedImage.type(), cv::Scalar(0, 0, 0));

// è½¬æ¢ä¸ºç°åº¦
cv::Mat gray;
cv::cvtColor(resizedImage, gray, cv::COLOR_BGR2GRAY);
imshow(&quot;Gray-img&quot;, gray);

// è½¬æ¢ä¸º hsv
cv::Mat hsv;
cv::cvtColor(resizedImage, hsv, cv::COLOR_BGR2HSV);
imshow(&quot;HSV&quot;, hsv);

cv:: Mat others;
cv::cvtColor(resizedImage, others, cv::COLOR_BGR2HSV_FULL);
imshow(&quot;HSV_FULL&quot;, others);

cv::Mat mask;
cv::Scalar lower(0, 0, 0); // ä¸‹é™
cv::Scalar upper(179, 100, 130); // ä¸Šç•Œ

cv::inRange (others, lower, upper, mask);
imshow(&quot;Mask&quot;, mask);

// åˆ›å»ºä¸€ä¸ªçŸ©å½¢ç»“æ„å…ƒç´ 
cv::Mat kernel = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(3, 3));

// æ‰§è¡Œå½¢æ€å­¦é—­è¿ç®—
cv::Mat close;
cv::morphologyEx(mask, close, cv::MORPH_CLOSE, kernel, cv::Point(-1, -1), 1);

// å°†å•é€šé“é—­å›¾åƒåˆå¹¶ä¸º 3 é€šé“å›¾åƒ
cv::Mat extract;
std::vector&lt;cv::Mat&gt; channels(3, close); // åˆ›å»ºä¸€ä¸ªåŒ…å«ä¸‰ä¸ªâ€œcloseâ€å‰¯æœ¬çš„å‘é‡
cv::merge(channels, extract); // å°†å®ƒä»¬åˆå¹¶ä¸ºå•ä¸ª 3 é€šé“å›¾åƒ

cv::imshow(&quot;Closed Mask&quot;, close);
// cv::imshow(&quot;Merged Image&quot;, extract);

// æŸ¥æ‰¾è½®å»“
std::vector&lt;std::vector&lt;cv::Point&gt;&gt; contours;
// std::vector&lt;cv::Vec4i&gt; å±‚æ¬¡ç»“æ„;
cv::findContours(close, contours, cv::RETR_TREE, cv::CHAIN_APPROX_SIMPLE);

for (const auto&amp; c : contours) {
// è·å–è¾¹ç•ŒçŸ©å½¢
cv::Rect boundingBox = cv::boundingRect(c);
int area = boundingBox.width * boundingBox.height;

// æ ¹æ®é¢ç§¯è¿›è¡Œè¿‡æ»¤
if ( area&gt;2500 &amp;&amp; area&lt;5000) {
// åœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶çŸ©å½¢
cv::rectangle(resizedImage, boundingBox, cv::Scalar(36, 255, 12), 3);

// ä» &#39;extract&#39; ä¸­æå–åŒºåŸŸå¹¶å°†å…¶å¤åˆ¶åˆ° &#39;result&#39;
cv::imshow(&quot;contourssss&quot;, resizedImage);
waitKey(0);

// ä» &#39;extract&#39; ä¸­æå–åŒºåŸŸå¹¶å°†å…¶å¤åˆ¶åˆ° &#39;result&#39;
cv::Mat roi = extract(boundingBox); // ä» extract ä¸­æå–æ„Ÿå…´è¶£çš„åŒºåŸŸ
roi.copyTo(result(boundingBox)); // å¤åˆ¶åˆ° result ä¸­çš„ç›¸åº”åŒºåŸŸ
}
}

// æ˜¾ç¤ºç»“æœ
cv::imshow(&quot;Contours&quot;, result);
cv::waitKey(0);
cv::destroyAllWindows();

return 0;

}

è¾“å‡º]]></description>
      <guid>https://stackoverflow.com/questions/79021532/how-to-clean-denoise-an-image-using-opencv</guid>
      <pubDate>Wed, 25 Sep 2024 07:12:25 GMT</pubDate>
    </item>
    <item>
      <title>SBERT å¾®è°ƒæ€»æ˜¯åœ¨å®Œæˆæ‰€æœ‰ epoch ä¹‹å‰åœæ­¢</title>
      <link>https://stackoverflow.com/questions/79021064/sbert-fine-tuning-always-stops-before-finish-all-epochs</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ SBERT é¢„è®­ç»ƒæ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯ MiniLMï¼‰è¿›è¡Œä¸€ä¸ªåŒ…å« 995 ä¸ªåˆ†ç±»çš„æ–‡æœ¬åˆ†ç±»é¡¹ç›®ã€‚æˆ‘å¤§éƒ¨åˆ†æ—¶é—´éƒ½åœ¨æŒ‰ç…§æ­¤å¤„åˆ—å‡ºçš„æ­¥éª¤è¿›è¡Œæ“ä½œï¼Œä¸€åˆ‡ä¼¼ä¹éƒ½è¿è¡Œæ­£å¸¸ã€‚
æˆ‘çš„é—®é¢˜å‡ºç°åœ¨å®é™…è®­ç»ƒæ¨¡å‹æ—¶ã€‚æ— è®ºæˆ‘åœ¨è®­ç»ƒå‚æ•°ä¸­è®¾ç½®ä»€ä¹ˆå€¼ï¼Œè®­ç»ƒä¼¼ä¹æ€»æ˜¯æå‰ç»“æŸï¼Œå¹¶ä¸”æ°¸è¿œä¸ä¼šå®Œæˆæ‰€æœ‰æ‰¹æ¬¡ã€‚ä¾‹å¦‚ï¼Œæˆ‘è®¾ç½®äº† num_train_epochs=1ï¼Œä½†å®ƒæœ€å¤šåªèƒ½è¾¾åˆ° 0.49 ä¸ª epochã€‚å¦‚æœ num_train_epochs=4ï¼Œå®ƒæ€»æ˜¯åœ¨ 3.49 ä¸ª epoch å¤„ç»“æŸã€‚
è¿™æ˜¯æˆ‘çš„ä»£ç ï¼š
from datasets import load_dataset
from sentence_transformers import (
SentenceTransformer,
SentenceTransformerTrainer,
SentenceTransformerTrainingArguments,
SentenceTransformerModelCardData,
)
from sentence_transformers.losses import BatchAllTripletLoss
from sentence_transformers.training_args import BatchSamplers
from sentence_transformers.evaluation import TripletEvaluator

model = SentenceTransformer(
&quot;nreimers/MiniLM-L6-H384-uncased&quot;,
model_card_data=SentenceTransformerModelCardData(
language=&quot;en&quot;,
license=&quot;apache-2.0&quot;,
model_name=&quot;all-MiniLM-L6-v2&quot;,
)
)

loss = BatchAllTripletLoss(model)
# æŸå¤±æ¦‚è¿°ï¼šhttps://www.sbert.net/docs/sentence_transformer/loss_overview.html
# æ­¤ç‰¹å®šæŸå¤±æ–¹æ³•ï¼šhttps://www.sbert.net/docs/package_reference/sentence_transformer/losses.html#batchalltripletloss

# è®­ç»ƒå‚æ•°ï¼šhttps://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments
args = SentenceTransformerTrainingArguments(
# å¿…éœ€å‚æ•°ï¼š
output_dir=&quot;finetune/model20240924&quot;,
# å¯é€‰è®­ç»ƒå‚æ•°ï¼š
num_train_epochs=1,
max_steps = -1,
per_device_train_batch_size=8,
per_device_eval_batch_size=8,
learning_rate=1e-5,
warmup_ratio=0.1,
fp16=True, # å¦‚æœæ‚¨æ”¶åˆ° GPU æ— æ³•åœ¨ FP16 ä¸Šè¿è¡Œçš„é”™è¯¯ï¼Œè¯·è®¾ç½®ä¸º False
bf16=False, # å¦‚æœæ‚¨æ‹¥æœ‰æ”¯æŒ BF16 çš„ GPUï¼Œè¯·è®¾ç½®ä¸º True
batch_sampler=BatchSamplers.GROUP_BY_LABEL, # 
# å¯é€‰çš„è·Ÿè¸ª/è°ƒè¯•å‚æ•°ï¼š
eval_strategy=&quot;no&quot;,
eval_steps=100,
save_strategy=&quot;epoch&quot;,
# save_steps=100,
save_total_limit=2,
logs_steps=100,
run_name=&quot;miniLm-triplet&quot;, # å¦‚æœåœ¨ W&amp;B ä¸­ä½¿ç”¨`wandb` å·²å®‰è£…
)

trainer = SentenceTransformerTrainer(
model=model,
args=args,
train_dataset=trainDataset,
eval_dataset=devDataset,
loss=loss,
#evaluator=dev_evaluator,
)
trainer.train()

è¯·æ³¨æ„ï¼Œæˆ‘æ²¡æœ‰ä½¿ç”¨è¯„ä¼°å™¨ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨åˆ›å»ºæ¨¡å‹ï¼Œå¹¶åœ¨äº‹åä½¿ç”¨ä¸“ç”¨çš„æµ‹è¯•å€¼é›†å¯¹å…¶è¿›è¡Œæµ‹è¯•ã€‚æˆ‘çš„æ•°æ®é›†ç»“æ„å¦‚ä¸‹ï¼š
Dataset({
features: [&#39;Title&#39;, &#39;Body&#39;, &#39;label&#39;],
num_rows: 23961
})

ä¸ dev æ•°æ®é›†å…·æœ‰ç›¸åŒçš„ç»“æ„ï¼Œåªæ˜¯è¡Œæ•°è¾ƒå°‘ã€‚è¿™å°†æä¾›ä»¥ä¸‹è¾“å‡ºï¼š
 [1473/2996 57:06 &lt; 59:07ï¼Œ0.43 it/sï¼ŒEpoch 0/1]
æ­¥éª¤è®­ç»ƒæŸå¤±
100 1.265600
200 0.702700
300 0.633900
400 0.505200
500 0.481900
600 0.306800
700 0.535600
800 0.369800
900 0.265400
1000 0.345300
1100 0.516700
1200 0.372600
1300 0.392300
1400 0.421900

TrainOutput(global_step=1473, training_loss=0.5003972503496366, metrics={&#39;train_runtime&#39;: 3427.9198, &#39;train_samples_per_second&#39;: 6.99, &#39;train_steps_per_second&#39;: 0.874, &#39;total_flos&#39;: 0.0, &#39;train_loss&#39;: 0.5003972503496366, &#39;epoch&#39;: 0.4916555407209613})

æ— è®ºæˆ‘å¦‚ä½•è°ƒæ•´å€¼ï¼Œæˆ‘éƒ½æ— æ³•è®©å®ƒå®Œæˆæ‰€æœ‰æ‰¹æ¬¡ã€‚å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79021064/sbert-fine-tuning-always-stops-before-finish-all-epochs</guid>
      <pubDate>Wed, 25 Sep 2024 03:55:44 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å°† CIFAR10 æ¨¡å‹çš„å‡†ç¡®ç‡æé«˜åˆ° 80% ä»¥ä¸Šï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79020893/how-to-increase-accurracy-for-cifar10-model-above-80-accuracy</link>
      <description><![CDATA[æœ‰äººèƒ½å¸®åŠ©æˆ‘å—ï¼Ÿæˆ‘ä½¿ç”¨æ¥è‡ª tensorflow æ•°æ®é›†çš„ CIFAR10 æ•°æ®é›†è®­ç»ƒæˆ‘çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä½†æˆ‘æ— æ³•å°†æ¨¡å‹å‡†ç¡®ç‡æé«˜åˆ° 80% ä»¥ä¸Š...
æœ‰äººèƒ½ç»™æˆ‘ä¸€ä¸ªå»ºè®®å—ï¼Ÿ
import tensorflow as tf
import time
import tensorflow_datasets as tfds
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

def normalize(train_images, test_images):
normalized_train_dataset = tf.cast(train_images, tf.float32) / 255.0
normalized_test_dataset = tf.cast(test_images, tf.float32) / 255.0
è¿”å› normalized_train_dataset, normalized_test_dataset

# Normalisasi Dataset
train_dataset, test_dataset = normalize(train_images, test_images)

def visual(image, image_sample=2):
for i in range (image_sample):

print(f&quot;å¼¯æ›²å›¾åƒï¼š{np.shape(image)}&quot;)
print(f&quot;å¼¯æ›²æ•°æ®ï¼š{image[i].dtype}&quot;)
print(f&quot;Nilai æœ€å¤§å›¾åƒï¼š{np.max(image[i])}&quot;)
print(f&quot;Nilai æœ€å°å›¾åƒï¼š{np.min(image[i])}&quot;)

plt.figure(figsize=(6,6))
plt.imshow(image[i])
plt.axis(&#39;off&#39;)
plt.colorbar()
plt.title(&quot;Gambar CIFAR-10&quot;)
plt.grid(False)
plt.show()

visualization(train_dataset)

train_labels = np.squeeze(train_labels)
test_labels = np.squeeze(test_labels)

print(f&quot;Shape Of Train Label : {train_labels.shape}&quot;)

print(f&quot;Shape Of Test_Label : {test_labels.shape}&quot;)

train_labels= to_categorical(train_labels, num_classes=10)
test_labels = to_categorical(test_labels, num_classes=10)

ä» tensorflow.keras.preprocessing.image å¯¼å…¥ ImageDataGenerator

datagen = ImageDataGenerator(
rotation_range=20,
width_shift_range=0.2,
height_shift_range=0.2,
sheath_range=0.2,
zoom_range=0.2,
Horizoâ€‹â€‹ntal_flip=True,
fill_mode=&#39;nearest&#39;
)

model = tf.keras.models.Sequential([
tf.keras.layers.Conv2D(32, (3,3), padding=&#39;same&#39;,activation=tf.nn.relu, input_shape=(32, 32, 3)),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(64, (3,3), padding=&#39;same&#39;,activation=tf.nn.relu),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(128, (3,3), padding=&#39;same&#39;, æ¿€æ´»=tf.nn.relu),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(128, (3,3), padding=&#39;same&#39;, æ¿€æ´»=tf.nn.relu),
tf.keras.layers.BatchNormalization(),
tf.keras.layers.MaxPool2D((2,2), strides=2),

tf.keras.layers.Conv2D(512, (3,3)ï¼Œpadding=&#39;same&#39;ï¼Œactivation=tf.nn.reluï¼Œkernel_regularizer=tf.keras.regularizers.l2(0.01))ï¼Œ
tf.keras.layers.BatchNormalization()ï¼Œ
tf.keras.layers.MaxPool2D((2,2)ï¼Œstrides=2)ï¼Œ

tf.keras.layers.Flatten()ï¼Œ
tf.keras.layers.Dense(512ï¼Œactivation=tf.nn.relu)ï¼Œ
tf.keras.layers.Dropout(0.3)ï¼Œ

tf.keras.layers.Dense(128ï¼Œactivation=tf.nn.relu)ï¼Œ
tf.keras.layers.Dropout(0.5)ï¼Œ

tf.keras.layers.Dense(10ï¼Œæ¿€æ´»=tf.nn.softmax)
])

model.summary()

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
loss=&#39;categorical_crossentropy&#39;,
metrics=[&#39;accuracy&#39;])

early_stopping = tf.keras.callbacks.EarlyStopping(
monitor=&#39;val_loss&#39;,
patience=5,
restore_best_weights=True
)

reducer_lr = tf.keras.callbacks.ReduceLROnPlateau(
monitor=&#39;val_loss&#39;,
factor=0.2,
patience=3,
verbose=1,
min_lr=0.00001
)

callbacks = [early_stopping, reducer_lr]

start_time = time.time()

history = model.fit(datagen.flow(
train_dataset,
train_labels,
batch_size=64),
epochs=30,
validation_data=(test_dataset, test_labels),
callbacks=callbacks,
verbose=1
)

end_time = time.time()
training_time = end_time - start_time
print(f&quot;è®­ç»ƒæ—¶é—´ï¼š{training_time/60:.2f} åˆ†é’Ÿ&quot;)

model.save(&#39;hand_gesture_detect.keras&#39;)

# è¯„ä¼°æ¨¡å‹
loss_val, accuracy_val = model.evaluate(test_dataset, test_labels)
print(f&quot;æŸå¤±ï¼š{loss_val}&quot;)
print(f&quot;å‡†ç¡®ç‡ï¼š{accuracy_val}&quot;)

æ¥è‡ª tensorflow.keras.applications å¯¼å…¥ ResNet50

base_model = ResNet50(weights=&#39;ImageNet&#39;, include_top=False, input_tensor=(32, 32, 3))

æˆ‘å·²ç»ä½¿æˆ‘çš„æ¨¡å‹å¤æ‚åŒ–ï¼Œä½†å‡†ç¡®ç‡ä»ç„¶åªæœ‰ 77-80%ï¼Œæˆ‘ä¸çŸ¥é“å¦‚ä½•æé«˜æˆ‘çš„æ¨¡å‹å‡†ç¡®ç‡]]></description>
      <guid>https://stackoverflow.com/questions/79020893/how-to-increase-accurracy-for-cifar10-model-above-80-accuracy</guid>
      <pubDate>Wed, 25 Sep 2024 01:55:02 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨ GPU ä¸Šè¿è¡Œ gridSearchCV æˆ– randonizedSerchCV</title>
      <link>https://stackoverflow.com/questions/79020888/how-to-run-gridsearchcv-or-randonizedserchcv-on-gpu</link>
      <description><![CDATA[æˆ‘æƒ³è¿è¡Œ gridSearchCV æˆ– randonizedSerchCV æ¥ä½¿ç”¨ GPU åœ¨ Colab ç¯å¢ƒä¸­è°ƒæ•´è¶…å‚æ•°ã€‚
ä½†æˆ‘æ‰¾ä¸åˆ°è¿™äº›å‡½æ•°ä¸ GPU å…¼å®¹çš„å®ç°ã€‚
åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘è¯¥å¦‚ä½•è°ƒæ•´è¶…å‚æ•°ï¼Ÿ
å› æ­¤ï¼Œç”±äºæˆ‘æ‰¾ä¸åˆ°åœ¨ GPU ä¸Šè°ƒæ•´è¶…å‚æ•°çš„å‡½æ•°ï¼Œæˆ‘å°è¯•å®ç° randonizedSerchCVã€‚ä½†æˆ‘è®¤ä¸ºä¸€å®šæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œè€Œæ— éœ€æ‰‹åŠ¨å®ç°è¯¥å‡½æ•°ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79020888/how-to-run-gridsearchcv-or-randonizedserchcv-on-gpu</guid>
      <pubDate>Wed, 25 Sep 2024 01:53:20 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨ PyTorch ä¸­è®­ç»ƒçœ¼ç›éªŒè¯ï¼ˆè€Œéè¯†åˆ«ï¼‰æ¨¡å‹ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79019854/how-to-train-an-eye-verification-not-recognition-model-in-pytorch</link>
      <description><![CDATA[æˆ‘æƒ³çŸ¥é“æˆ‘ä»¬å¦‚ä½•è®­ç»ƒä¸€å¯¹ä¸€å›¾åƒéªŒè¯æ¨¡å‹ã€‚æ¨¡å‹ä¼šæ‹æ‘„ä¸¤å¼ å›¾åƒå¹¶éªŒè¯å®ƒä»¬æ˜¯å¦ç›¸åŒã€‚
æˆ‘åœ¨ç½‘ä¸Šæœç´¢è¿‡ï¼Œä½†åªèƒ½æ‰¾åˆ°æœ‰å…³è¯†åˆ«ï¼ˆä¸€å¯¹å¤šï¼‰çš„ç­”æ¡ˆã€‚
å¦‚ä½•åœ¨æ–‡æœ¬æˆ–ä»£ç ä¸­åˆ›å»ºè¿™æ ·çš„æ¨¡å‹ï¼Ÿ
ä¸ºäº†æ¾„æ¸…èµ·è§ï¼Œæˆ‘è¯´çš„ç›¸åŒæ˜¯æŒ‡çœ¼ç›ç›¸åŒï¼Œå³å®ƒä»¬å±äºåŒä¸€ä¸ªäººã€‚è¿™æ˜¯ä¸€ä¸ªéªŒè¯æ¨¡å‹ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79019854/how-to-train-an-eye-verification-not-recognition-model-in-pytorch</guid>
      <pubDate>Tue, 24 Sep 2024 18:10:07 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä¸ºæ’åæ¨¡å‹ç”Ÿæˆæ•°æ®é›†ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79019494/how-generate-dataset-for-ranking-model</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•åˆ›å»ºä¸¤é˜¶æ®µæ¨èç³»ç»Ÿï¼šä½¿ç”¨çŸ©é˜µåˆ†è§£ç”Ÿæˆå€™é€‰å¯¹è±¡ï¼Œå¹¶ä½¿ç”¨ Lambdarank æ’åæ¨¡å‹å¯¹å…¶è¿›è¡Œæ’åã€‚æˆ‘æœ‰ä¸¤ä¸ªé€‰é¡¹æ¥ç”Ÿæˆæ•°æ®é›†ï¼š

å– 128 ä¸ªé¡¹ç›®
ï¼ˆç›¸å…³é¡¹ç›® + éšæœºé¡¹ç›®å¡«å……ï¼‰ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ¨¡å‹å¯¹å…¶è¿›è¡Œè¯„åˆ†å’Œæ’åºï¼Œç„¶åä½¿ç”¨æ­¤åºåˆ—è®­ç»ƒç¬¬äºŒä¸ªæ¨¡å‹ï¼ˆå› æ­¤æˆ‘ä»¬å§‹ç»ˆå…·æœ‰ç›¸å¯¹å€¼ã€‚
å¯¹æ‰€æœ‰é¡¹ç›®è¿›è¡Œè¯„åˆ†ï¼Œæ’åºå¹¶å–å‰ 128 ä¸ªé¡¹ç›®ï¼Œç„¶åè¿›è¡Œè®­ç»ƒï¼ˆæˆ‘ä»¬å¯èƒ½æ²¡æœ‰ç›¸å…³é¡¹ç›®ï¼Œä½†æˆ‘è®¤ä¸ºè¿™æ›´è‡ªç„¶ï¼Œå› ä¸ºåœ¨ç”Ÿäº§ä¸­æˆ‘ä»¬å°†ä»¥è¿™ç§æ–¹å¼è¿›è¡Œé¢„æµ‹ï¼‰ã€‚

é‚£ä¹ˆï¼Œå“ªä¸ªæ›´å¥½ï¼Ÿæ­¤å¤–ï¼Œåœ¨è®­ç»ƒä¸­ä½¿ç”¨å°æƒé‡ï¼ˆç±»ä¼¼äºéšå¼ ALSï¼‰å¡«å……é¡¹ç›®æ˜¯å¦æœ‰æ„ä¹‰ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79019494/how-generate-dataset-for-ranking-model</guid>
      <pubDate>Tue, 24 Sep 2024 16:14:00 GMT</pubDate>
    </item>
    <item>
      <title>ç±»å‹é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°ç±»â€œSequentialâ€</title>
      <link>https://stackoverflow.com/questions/79019296/typeerror-could-not-locate-class-sequential</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79019296/typeerror-could-not-locate-class-sequential</guid>
      <pubDate>Tue, 24 Sep 2024 15:17:10 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å°†é¢„æµ‹å€¼åˆå¹¶å›æ•°æ®é›†ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79018990/how-to-merge-predicted-value-back-to-the-data-set</link>
      <description><![CDATA[æˆ‘å·²ç»åœ¨ Python ä¸­è®­ç»ƒäº†ä¸€ä¸ª XGboost æ¨¡å‹ï¼Œå¹¶å°†æ¦‚ç‡åˆ—è¡¨ä½œä¸ºè¾“å‡ºã€‚æˆ‘å¦‚ä½•å°†è¿™äº›æ¦‚ç‡å¸¦åˆ°åŸå§‹æ•°æ®é›†ï¼Œä»¥ä¾¿åœ¨ä¸€ä¸ª DF ä¸­æ‹¥æœ‰æ•°æ® + é¢„æµ‹å€¼ï¼Ÿå‡è®¾æˆ‘çš„åŸå§‹åŸå§‹æµ‹è¯• df ç§°ä¸º df_rawã€‚
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)
model = XGBClassifier(n_estimators=1500, max_depth=5, n_jobs=-1, min_child_weight=2, 
early_stopping_rounds=25)
model.fit(X_train, y_train, eval_set=[(X_test, y_test)])
test_outputs = model.predict_proba(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/79018990/how-to-merge-predicted-value-back-to-the-data-set</guid>
      <pubDate>Tue, 24 Sep 2024 14:08:01 GMT</pubDate>
    </item>
    <item>
      <title>æå–å“ªäº›ç‰¹å¾æ¥èšç±»æ–‡æœ¬ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/78974474/what-features-to-extract-to-cluster-text</link>
      <description><![CDATA[æˆ‘æƒ³ä¸ºæ–‡æœ¬åˆ¶ä½œä¸€ä¸ªåˆ†ç±»å™¨ï¼Œè¿›ä¸€æ­¥ç”¨äºä¸ºç»™å®šçš„æ–‡æœ¬æ¨èæœ€ç›¸ä¼¼çš„æ–‡æœ¬ã€‚
åº”ç”¨ç¨‹åºçš„æµç¨‹å¦‚ä¸‹ï¼š

ä½¿ç”¨ llm ä»æ–‡æœ¬ä¸­æå– 10 ä¸ªä¸»è¦ä¸»é¢˜ï¼ˆå®ƒå¯ä»¥ä» 150 ä¸ªè¯æ± ä¸­é€‰æ‹©ï¼‰
æˆ‘å°†è¯å‘é‡è®¾ä¸ºäºŒè¿›åˆ¶å‘é‡ï¼ŒåŸºæœ¬ä¸Šåœ¨ 150 ç»´ç©ºé—´ä¸­å·¥ä½œï¼Œå…¶ä¸­æ¯ä¸ªæ–‡æœ¬éƒ½æœ‰ä¸€ä¸ªåæ ‡ï¼Œä¾‹å¦‚ [1, 0, 1, ..., 0]
ç„¶åæˆ‘ä½¿ç”¨ cosine è·ç¦»æ‰¾åˆ°æœ€è¿‘çš„é‚»å±…ï¼ˆæˆ‘æƒ³æ‰©å±•åˆ° 3-5ï¼Œä½†ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å‡è®¾åªæœ‰ä¸€ä¸ªï¼‰
æˆ‘æ”¶åˆ°äº†æœ€æ¥è¿‘çš„æ–‡æœ¬

é—®é¢˜æ˜¯æ–‡æœ¬éå¸¸ä¸åŒï¼Œå¹¶ä¸” llm å¯ä»¥å¾ˆå¥½åœ°æä¾›ä¸»é¢˜ï¼Œä½†æ˜¯å»ºè®®çš„æ–‡æœ¬å¹¶ä¸å®Œå…¨ç¬¦åˆæˆ‘çš„é¢„æœŸã€‚æˆ‘å°è¯•æ ¹æ®é‡è¦æ€§å¯¹ä¸»é¢˜è¿›è¡Œæ’åºï¼Œå¹¶ä½¿å‘é‡éäºŒè¿›åˆ¶ï¼ˆ[10, 0, 0, 9, ..., 1]ï¼‰ï¼Œä½†è¿™ä¼¼ä¹æ²¡æœ‰å¤ªå¤§å¸®åŠ©ã€‚
æˆ‘æƒ³çŸ¥é“è¿™ç§æ–¹æ³•æ˜¯å¦ä¸é€‚åˆæˆ‘çš„é—®é¢˜ï¼Œæˆ–è€…æˆ‘æ˜¯å¦åº”è¯¥ä½¿ç”¨å…¶ä»–å‚æ•°æˆ–å…¶ä»–ä»»ä½•ä¸œè¥¿æ¥å¯¹æˆ‘çš„æ–‡æœ¬è¿›è¡Œåˆ†ç»„ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/78974474/what-features-to-extract-to-cluster-text</guid>
      <pubDate>Wed, 11 Sep 2024 14:56:49 GMT</pubDate>
    </item>
    <item>
      <title>ä»€ä¹ˆæ˜¯ Killed:9 ä»¥åŠå¦‚ä½•åœ¨ macOS ç»ˆç«¯ä¸­ä¿®å¤ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/51833310/what-is-killed9-and-how-to-fix-in-macos-terminal</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€æ®µç”¨äºæœºå™¨å­¦ä¹ é¡¹ç›®çš„ç®€å• Python ä»£ç ã€‚æˆ‘æœ‰ä¸€ä¸ªç›¸å¯¹è¾ƒå¤§çš„è‡ªå‘è¯­éŸ³æ•°æ®åº“ã€‚æˆ‘å¼€å§‹è®­ç»ƒæˆ‘çš„è¯­éŸ³æ¨¡å‹ã€‚ç”±äºè¿™æ˜¯ä¸€ä¸ªåºå¤§çš„æ•°æ®åº“ï¼Œæˆ‘è®©å®ƒè¿å¤œå·¥ä½œã€‚æ—©ä¸Šæˆ‘é†’æ¥æ—¶çœ‹åˆ°ç»ˆç«¯ä¸­å‡ºç°ä¸€ä¸ªç¥ç§˜çš„
Killed: 9
è¡Œã€‚æ²¡æœ‰å…¶ä»–å†…å®¹ã€‚æ²¡æœ‰å…¶ä»–é”™è¯¯æ¶ˆæ¯æˆ–éœ€è¦å¤„ç†çš„å†…å®¹ã€‚ä»£ç è¿è¡Œè‰¯å¥½çº¦ 6 å°æ—¶ï¼Œå æ•´ä¸ªè¿‡ç¨‹çš„ 75%ï¼Œæ‰€ä»¥æˆ‘çœŸçš„ä¸æ˜ç™½å“ªé‡Œå‡ºäº†é—®é¢˜ã€‚
ä»€ä¹ˆæ˜¯ Killed:9 ä»¥åŠå¦‚ä½•ä¿®å¤å®ƒï¼Ÿæµªè´¹æ•°å°æ—¶çš„è®¡ç®—æ—¶é—´éå¸¸ä»¤äººæ²®ä¸§â€¦â€¦
å¦‚æœè¿™å¾ˆé‡è¦ï¼Œæˆ‘æ­£åœ¨ä½¿ç”¨ macOS Mojave æµ‹è¯•ç‰ˆã€‚æå‰è°¢è°¢æ‚¨ï¼]]></description>
      <guid>https://stackoverflow.com/questions/51833310/what-is-killed9-and-how-to-fix-in-macos-terminal</guid>
      <pubDate>Tue, 14 Aug 2018 03:28:58 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ FeatureUnion è¿”å› Dataframe</title>
      <link>https://stackoverflow.com/questions/36652196/how-to-make-featureunion-return-dataframe</link>
      <description><![CDATA[æ‰€ä»¥æˆ‘ç›®å‰æœ‰ä¸€ä¸ªåŒ…å«å¤§é‡å®¢æˆ·è½¬æ¢å™¨çš„ç®¡é“ï¼š
p = Pipeline([
(&quot;GetTimeFromDate&quot;,TimeTransformer(&quot;Date&quot;)), #æ·»åŠ  [&quot;time&quot;] åˆ—çš„è‡ªå®šä¹‰è½¬æ¢å™¨
(&quot;GetZipFromAddress&quot;,ZipTransformer(&quot;Address&quot;)), #æ·»åŠ  [&quot;zip&quot;] åˆ—çš„è‡ªå®šä¹‰è½¬æ¢å™¨
(&quot;GroupByTimeandZip&quot;,GroupByTransformer([&quot;time&quot;,&quot;zip&quot;]) #æ·»åŠ  onehot åˆ—çš„è‡ªå®šä¹‰è½¬æ¢å™¨
])

æ¯ä¸ªè½¬æ¢å™¨éƒ½æ¥æ”¶ä¸€ä¸ª pandas æ•°æ®æ¡†å¹¶è¿”å›åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªæ–°åˆ—çš„ç›¸åŒæ•°æ®æ¡†ã€‚å®ƒå®é™…ä¸Šè¿è¡Œå¾—å¾ˆå¥½ï¼Œä½†æˆ‘å¦‚ä½•å¹¶è¡Œè¿è¡Œâ€œGetTimeFromDateâ€å’Œâ€œGetZipFromAddressâ€æ­¥éª¤ï¼Ÿ
æˆ‘æƒ³ä½¿ç”¨ FeatureUnionï¼š
f = FeatureUnion([
(&quot;GetTimeFromDate&quot;,TimeTransformer(&quot;Date&quot;)), #æ·»åŠ  [&quot;time&quot;] åˆ—çš„è‡ªå®šä¹‰è½¬æ¢å™¨
(&quot;GetZipFromAddress&quot;,ZipTransformer(&quot;Address&quot;)), #æ·»åŠ  [&quot;zip&quot;] åˆ—çš„è‡ªå®šä¹‰è½¬æ¢å™¨])
])

p = Pipeline([
(&quot;FeatureUnionStep&quot;,f),
(&quot;GroupByTimeandZip&quot;,GroupByTransformer([&quot;time&quot;,&quot;zip&quot;]) #æ·»åŠ  onehot åˆ—çš„è‡ªå®šä¹‰è½¬æ¢å™¨
])

ä½†é—®é¢˜æ˜¯ FeatureUnion è¿”å›çš„æ˜¯ numpy.ndarrayï¼Œè€Œâ€œGroupByTimeandZipâ€æ­¥éª¤éœ€è¦ä¸€ä¸ªæ•°æ®æ¡†ã€‚
æœ‰æ²¡æœ‰åŠæ³•è®© FeatureUnion è¿”å› pandas æ•°æ®æ¡†ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/36652196/how-to-make-featureunion-return-dataframe</guid>
      <pubDate>Fri, 15 Apr 2016 16:18:14 GMT</pubDate>
    </item>
    </channel>
</rss>