<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 14 May 2024 15:16:57 GMT</lastBuildDate>
    <item>
      <title>调查 TensorFlow 和 PyTorch 性能的差异</title>
      <link>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</guid>
      <pubDate>Tue, 14 May 2024 13:54:26 GMT</pubDate>
    </item>
    <item>
      <title>LinearRegression：即使在管道中有 Simple Imputer 后也会出现 NaN 错误</title>
      <link>https://stackoverflow.com/questions/78478326/linearregression-nan-error-even-after-having-simple-imputer-in-the-pipeline</link>
      <description><![CDATA[我在经典的加州住房数据集上尝试预测房屋价值中位数。因此，数据集包含卧室总数的 NaN 值。我使用 Simple Imputer 将它们替换为中值，但当我继续训练模型时，我仍然得到 NaN 值。现在，输入器使用的策略是中值，因此传统的恒定策略方法不起作用。我检查了数据框，经过预处理后没有任何数据框。但是，当我尝试通过管道预处理并一起运行模型时，我不知道出了什么问题。我复制了一些与 Jupyter 笔记本相关的代码与其余代码的链接，以供参考。任何帮助将不胜感激。谢谢！
https://colab.research.google.com/drive/1gpaI2xJE2tY0gxEAD1oFGUGsBgRIal5q?usp=分享
从 sklearn.cluster 导入 KMeans
从 sklearn.base 导入 TransformerMixin、BaseEstimator
从 sklearn.metrics.pairwise 导入 rbf_kernel
类 ClusterSimilarity(BaseEstimator, TransformerMixin):
  def __init__(self, n_clusters=10, gamma=1.0,random_state=None):
    self.n_clusters=n_clusters
    self.gamma=gamma
    self.random_state=随机状态
  def fit(self, X,y=无,sample_weight=无):
    self.kmeans_=KMeans(self.n_clusters,random_state=self.random_state,n_init=10)
    self.kmeans_.fit(X,样本权重=样本权重)
    返回自我
  def 变换（自身，X）：
    返回 rbf_kernel(X, self.kmeans_.cluster_centers_,gamma=self.gamma)
  def get_feature_names_out(self,names=None):
    return [f“聚类{i}相似度”对于范围内的 i(self.n_clusters)]

def column_ratio(X):
  返回 X[:,[0]]/X[:,[1]]
defratio_name(function_transformer,feature_names_in):
  返回[&#39;比例&#39;]
defratio_pipeline():
  返回 make_pipeline(SimpleImputer(strategy=&#39;median&#39;,missing_values=pd.NA),FunctionTransformer(column_ratio,feature_names_out=ratio_name),StandardScaler())
log_pipeline=make_pipeline(SimpleImputer(strategy=&#39;median&#39;,missing_values=pd.NA),FunctionTransformer(np.log,feature_names_out=&#39;一对一&#39;),StandardScaler())
cluster_simil=簇相似度(n_clusters=10,gamma=1.,random_state=69)
default_num_pipeline=make_pipeline(SimpleImputer(strategy=&#39;median&#39;,missing_values=pd.NA),StandardScaler())
预处理=ColumnTransformer([(&quot;bedrooms_per_room&quot;,ratio_pipeline(),[&quot;total_bedrooms&quot;,&quot;total_rooms&quot;]),(&quot;rooms_per_house&quot;,ratio_pipeline(),
 [“total_rooms”,“households”]),(“people_per_house”,ratio_pipeline(),[“population”,“households”]),
  (“log”,log_pipeline,[“total_bedrooms”,“total_rooms”,“人口”,“家庭”,“median_venue”]),(“coordinates_ adjustmentments”,cluster_simil,[“纬度”, “经度”]），
   (“cat”,cat_pipeline,make_column_selector(dtype_include=object))],remainder=default_num_pipeline)

从 sklearn.linear_model 导入 LinearRegression
lin_reg=make_pipeline(预处理, LinearRegression())
lin_reg.fit_transform（外壳，外壳标签）

我尝试在管道中使用 SimpleImputer 来删除 NaN 值，但即使在那之后我也收到 NaN 错误。我手动检查了管道并测试了 NaN 值，但数据为空，这意味着不存在 NaN 值，但当我尝试将其用于线性回归模型时，出现 NaN 错误。除了“None”之外，我还将 Missing_values 用作 pd.NA 和 np.none，并且全部不执行任何操作。]]></description>
      <guid>https://stackoverflow.com/questions/78478326/linearregression-nan-error-even-after-having-simple-imputer-in-the-pipeline</guid>
      <pubDate>Tue, 14 May 2024 13:09:36 GMT</pubDate>
    </item>
    <item>
      <title>Azure 助理 API 文件搜索和响应时间问题</title>
      <link>https://stackoverflow.com/questions/78477560/issues-with-azure-assistant-api-file-search-and-response-times</link>
      <description><![CDATA[我目前正在使用 Azure Assistant API，并面临一些挑战。具体来说，当我尝试添加文件并使用函数调用时，文件搜索功能无法按预期工作。尽管提供了正确的说明，API 经常会回复“我没有该信息”。即使文件中提供了必要的数据。
我已使用 GPT-3.5 Turbo、GPT-4 和 GPT-4 Turbo 对此进行了测试，但该问题在所有型号上仍然存在。此外，与标准 OpenAI Assistant API 相比，响应时间明显更长，在文件搜索、函数调用和响应时间方面表现良好。
我需要有关此问题的进一步支持。]]></description>
      <guid>https://stackoverflow.com/questions/78477560/issues-with-azure-assistant-api-file-search-and-response-times</guid>
      <pubDate>Tue, 14 May 2024 10:52:10 GMT</pubDate>
    </item>
    <item>
      <title>如何编写具有多个输入的神经网络[关闭]</title>
      <link>https://stackoverflow.com/questions/78477416/how-to-write-a-neural-network-with-multiple-inputs</link>
      <description><![CDATA[这里我想问一下如何编写具有多个输入的神经网络。您的方法、现代解决方案和建议。
我认为制作一个只能获得一个输入并且可以多次使用它的模型是一个很好的决定。
&lt;前&gt;&lt;代码&gt;# 输入1，输入2，输入3 = ...，...，...
模型=顺序（）

输出1 = 模型(输入1)
输出2 = 模型(输入2)
输出3 = 模型(输入3)`

您认为一致性如何？这样做真的很重要吗？或者你可以这样做：
输出1 = 模型(输入3) 输出2 = 模型(输入1) 输出3 = 模型(输入2)
也许你的做法不同，所以你可以在这里告诉...
我只是尝试这样做，所以听到更多信息很有趣]]></description>
      <guid>https://stackoverflow.com/questions/78477416/how-to-write-a-neural-network-with-multiple-inputs</guid>
      <pubDate>Tue, 14 May 2024 10:24:18 GMT</pubDate>
    </item>
    <item>
      <title>亮度增强破坏了图像</title>
      <link>https://stackoverflow.com/questions/78477344/albumentations-intensity-augmentations-disrupt-the-image</link>
      <description><![CDATA[我使用经过预处理的 z 分数标准化列表作为数据集的来源。
这是一张由专辑增强的图像拼贴画：
在此处输入图片描述
这是我的撰写：
增强 = A.Compose([
    A.Horizo​​ntalFlip(),
    A.RandomBrightnessContrast（brightness_limit=（-0.0001，0.0001），contrast_limit=（-0.01，0.01）），
    A.CoarseDropout(8, 0.1, 0.1),
    A.旋转(限制=15),
    A.Affine(剪切=(-2, 2), 尺度=(0.95, 1.05)),
&gt;！ ToTensorV2()
]）

在 50% 的图像上，即使参数非常小，也应用了 RandBrightnessContrast，图像的整个分布被压缩为 [0, 1]（如 z 分数归一化图像所预期的那样，从 ~-2,~2 ）。
有办法解决这个问题吗？
也许我应该在这些之后执行 z 分数标准化，但我最初的意图是将所有确定性步骤（调整大小、标准化等）与增强步骤分开以提高效率。]]></description>
      <guid>https://stackoverflow.com/questions/78477344/albumentations-intensity-augmentations-disrupt-the-image</guid>
      <pubDate>Tue, 14 May 2024 10:11:54 GMT</pubDate>
    </item>
    <item>
      <title>为什么应用 Standard Scaler 时我的行数会减少？</title>
      <link>https://stackoverflow.com/questions/78477264/why-is-my-number-of-rows-getting-reduced-when-applying-standard-scaler</link>
      <description><![CDATA[我正在应用 StandardScaler() 来标准化我的数据集。但生成的标准化数据集的行数比原始数据集少。为什么会发生这种情况？我想在标准化后保留原始行数。
应用 StandardScaler() 函数后，我希望获得与标准化值相同的行数。]]></description>
      <guid>https://stackoverflow.com/questions/78477264/why-is-my-number-of-rows-getting-reduced-when-applying-standard-scaler</guid>
      <pubDate>Tue, 14 May 2024 09:57:32 GMT</pubDate>
    </item>
    <item>
      <title>掩模注释的质量保证</title>
      <link>https://stackoverflow.com/questions/78477050/quality-assurance-for-annotation-of-masks</link>
      <description><![CDATA[我将多个人的注释作为相同图像的掩模。
如何组合这些蒙版以获得更“真实”的效果？注解？有某种标准吗？
我还考虑过使用 Cohen&#39;s kappa、Krippendorf&#39;s alpha、F1 等，但我刚刚意识到我不能使用它们来保证质量，因为它们更多的是用于标记而不是分割中的注释。
你知道我也可以用什么来保证质量吗？]]></description>
      <guid>https://stackoverflow.com/questions/78477050/quality-assurance-for-annotation-of-masks</guid>
      <pubDate>Tue, 14 May 2024 09:22:21 GMT</pubDate>
    </item>
    <item>
      <title>OSError：[model] 似乎没有名为 config.json 的文件</title>
      <link>https://stackoverflow.com/questions/78474448/oserror-model-does-not-appear-to-have-a-file-named-config-json</link>
      <description><![CDATA[我想加载一个拥抱脸模型。 我要加载的模型大约有 15 万次下载所以我不认为模型本身有什么问题。
使用下面的两个加载代码我得到相同的错误：
从变压器导入 AutoModel
AutoModel.from_pretrained(“laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup”)

还有
从 Transformers 导入 CLIPProcessor、CLIPModel
model_id =“laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup”
处理器 = CLIPProcessor.from_pretrained(model_id)
模型 = CLIPModel.from_pretrained(model_id)

两者我都得到：
OSError：laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup 似乎没有名为 preprocessor_config.json 的文件。查看“https://huggingface.co/laion/CLIP-convnext_large_d_320.laion2B-s29B-b131K-ft-soup/main”以获取可用文件。

任何加载模型的帮助将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78474448/oserror-model-does-not-appear-to-have-a-file-named-config-json</guid>
      <pubDate>Mon, 13 May 2024 19:38:47 GMT</pubDate>
    </item>
    <item>
      <title>在深度训练/验证循环期间使用分层 k 折叠时出现越界错误</title>
      <link>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</guid>
      <pubDate>Mon, 13 May 2024 14:43:39 GMT</pubDate>
    </item>
    <item>
      <title>如何实现每层有多个类的多标签层次分类？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78468216/how-to-implement-multi-label-hierarchical-classification-with-multiple-classes-a</link>
      <description><![CDATA[我正在开发一个需要多标签层次分类的项目，其中层次结构的每个级别都有多个要预测的类。具体来说，我正在处理一个场景，其中标签遵循​​层次结构，并且在层次结构的每个级别上都有多个可能的类。
我的项目旨在根据 Instagram 用户的兴趣对他们进行分类。目标是将用户分类为分层兴趣组，其中每个用户可能属于层次结构不同级别的多个类别。
例如，考虑克里斯蒂亚诺·罗纳尔多作为示例用户，他的主要兴趣可能是“体育”和“家人和朋友”作为顶级品类，进一步细化“体育”类分类为“足球”和“手球” （假设）作为同一级别的子类别。
我已经探索了一些现有的分层分类方法，但它们似乎专注于单标签分类或假设每个级别都有一个类别。任何人都可以建议一种方法或为我提供资源来实现每个级别有多个类的多标签层次分类吗？
任何见解、算法或代码示例将不胜感激。
预先感谢您的帮助！
我一直在尝试使用多标签层次分类来根据 Instagram 用户的兴趣对他们进行分类。但是，我的方法遇到了限制：它似乎只在层次结构的每一级别对一个类进行分类，这不适合我的用例。]]></description>
      <guid>https://stackoverflow.com/questions/78468216/how-to-implement-multi-label-hierarchical-classification-with-multiple-classes-a</guid>
      <pubDate>Sun, 12 May 2024 14:35:02 GMT</pubDate>
    </item>
    <item>
      <title>不平衡学习管道的哪些部分应用于测试集？</title>
      <link>https://stackoverflow.com/questions/78462616/which-parts-of-the-imbalanced-learn-pipeline-are-applied-to-the-test-set</link>
      <description><![CDATA[我创建了一个由 RobustScaler、SMOTE-NC、 组成的 imbalanced-learn Pipeline随机欠采样和随机森林分类器。
RandomSearchCV 用于选择最佳的超参数。
我想在我的测试集上测试最佳估计器。
cv = RepeatedStratifiedKFold(n_splits=5,
                             n_重复=10，
                             随机状态=42
）

缩放器 = RobustScaler(quantile_range=(25.0, 75.0))

smote = SMOTENC（
    分类特征=分类特征，
    采样策略=0.35，
    随机状态=42
）
rus = RandomUnderSampler(sampling_strategy=0.35, random_state=42)

分类器 = RandomForestClassifier(random_state=42)

管道=不平衡_make_pipeline（缩放器，smote，rus，分类器）

random_search = RandomizedSearchCV(
    管道，
    param_distributions=参数，
    评分=scoring_metric，
    简历=简历，
    n_iter=10,
    随机状态=42，
    n_工作=-1，
）

best_model = random_search.fit(X_train, y_train).best_estimator_

y_pred = best_model.predict(X_test)

据我了解，只有缩放（通过X_train获得的设置）和分类器应该应用于测试集。 SMOTE 和 RandomUndersampling 不应应用于 X_test。
这是由 imbalanced-learn 管道保证的还是我必须考虑其他事情？]]></description>
      <guid>https://stackoverflow.com/questions/78462616/which-parts-of-the-imbalanced-learn-pipeline-are-applied-to-the-test-set</guid>
      <pubDate>Fri, 10 May 2024 21:28:24 GMT</pubDate>
    </item>
    <item>
      <title>ValueError: matmul: 输入操作数 1 的核心维度 0 不匹配，gufunc 签名为 (n?,k),(k,m?)->(n?,m?)（大小 5 与 3 不同）</title>
      <link>https://stackoverflow.com/questions/78460776/valueerror-matmul-input-operand-1-has-a-mismatch-in-its-core-dimension-0-with</link>
      <description><![CDATA[将 numpy 导入为 np
从 numpy.linalg 导入 inv
从 scipy.linalg 导入 pinv

# 定义必要的函数
def create_laplacian_from_adjacency(adj_matrix):
    Degree_matrix = np.diag(adj_matrix.sum(axis=1))

    laplacian_matrix = Degree_matrix - adj_matrix
    
    返回拉普拉斯矩阵

def dirichlet_energy(L, X):
    “”““用于平滑度量化的狄利克雷能量。”“””
    返回 np.trace(X.T @ L @ X)

def update_C(X, X_tilde, L, C, gamma, alpha, lam, J):
    “”“”使用具有主函数近似的梯度下降来更新C。
    p, k = C.shape
    C_old = np.copy(C)
    
    梯度_f = (-2 * gamma * L @ C_old @ inv(C_old.T @ L @ C_old + J) +
                  alpha * (C_old @ X_tilde - X) @ X_tilde.T +
                  2 * L @ C_old @ X_tilde @ X_tilde.T + lam * C_old @ np.ones((k, k)))
    
    # 主要函数优化步骤（简化方法）
    t = 0.01 # 学习率，需要根据实际应用进行调整
    C_new = pinv(C_old - t * 梯度_f)
    C_new = np.maximum(C_new, 0) # 强制非负性
    返回C_new

def update_X(X, L, C, alpha):
    “”“”基于更新的C来更新X(tilda)。“”“”
    inv_matrix = inv((2/alpha) * (C.T @ L @ C)) + (C.T @ C)
    X_tilde_new = inv_matrix @ C.T @ X
    返回 X_tilde_new

def fgc_algorithm(X, L, alpha, gamma, lam, iterations=5):
    “”“”执行特征图粗化算法。“”“”
    p, n = X.形状
    k = 3 # 假设粗化的降维为 3
    C = np.random.rand(p, k)*0.1
    J = np.full((k, k), 1/k)
    X_代字号 = pinv(C)@X

    对于范围内的 i（迭代）：
        C = update_C(X, X_tilde, L, C, gamma, alpha, lam, J)
        X_tilde = update_X(X, L, C, alpha)
        当前能量 = dirichlet_energy(L, X_tilde)
        print(f&quot;迭代 {i}: 狄利克雷能量 = {current_energy}&quot;)

    L_c=C.T@L@C
    返回 C、L_c、X_tilde

＃ 例子：
X = np.random.rand(5, 7) # 10 个节点的随机特征
adj_matrix = np.array([
    [0, 1, 0, 0, 0],
    [1, 0, 1, 1, 1],
    [0, 1, 0, 1, 0],
    [0, 1, 1, 0, 1],
    [1, 1, 0, 1, 0]
]）
L = create_laplacian_from_adjacency(adj_matrix) # 创建样本拉普拉斯矩阵
alpha, gamma, lam = 0.1, 1, 0.5 # 正则化参数

C、L_c、X_tilde = fgc_algorithm(X、L、alpha、gamma、lam)
print(&quot;更新的 C 矩阵：\n&quot;, C)
print(&quot;L_C 矩阵:\n&quot;, L_c)
print(&quot;更新后的特征矩阵 X(tilda):\n&quot;, X_tilde)


我正在尝试实现特色粗化图算法，但每次代码到达第 34 行时：inv_matrix = inv((2/alpha) * (C.T @ L @ C)) + (C.T @ C),
出现了上述错误。
我已经尝试检查所有内容，但根据我的说法，矩阵的尺寸是正确的，所以我不太明白为什么会出现这个问题？
如果您碰巧明白这一点，请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78460776/valueerror-matmul-input-operand-1-has-a-mismatch-in-its-core-dimension-0-with</guid>
      <pubDate>Fri, 10 May 2024 14:28:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在短时间内建立准确的数据集？</title>
      <link>https://stackoverflow.com/questions/78418098/how-can-i-build-an-accurate-dataset-in-a-short-span-of-time</link>
      <description><![CDATA[我们正在开发一款 iOS 应用，让用户可以发送可定制的数字卡片。用户可以从各种卡片模板中进行选择，输入自己的文本，并根据自己的喜好对卡片进行编辑。我们还有一项功能，用户可以提供短信，例如“妈妈生日快乐”，并收到文本的扩展版本，例如“祝我特别的母亲生日快乐！”我爱你，希望你度过愉快的一天。”
我正在研究如何实现这一目标，并计划使用自然语言处理 (NLP) 和 CoreML 创建一个模型。但是，我在为该特定任务寻找合适的数据集时遇到了问题。因此，我有兴趣构建专门为此目的而定制的准确数据集。但是，我不确定从哪里可以获得必要的数据，或者是否有其他数据源可供快速使用。
如果您有任何见解或替代方法来实现此功能，请分享。]]></description>
      <guid>https://stackoverflow.com/questions/78418098/how-can-i-build-an-accurate-dataset-in-a-short-span-of-time</guid>
      <pubDate>Thu, 02 May 2024 09:18:54 GMT</pubDate>
    </item>
    <item>
      <title>如何提高 cv2.dnn.readNetFromCaffe() 的 net.forward() 性能，net.forward 需要更多时间（7 到 10 秒/帧）才能给出结果</title>
      <link>https://stackoverflow.com/questions/54488986/how-to-improve-performance-net-forward-of-cv2-dnn-readnetfromcaffe-net-for</link>
      <description><![CDATA[我使用了net = cv2.dnn.readNetFromCaffe(protoFile, WeightsFile)，然后循环播放实时视频帧以使用net.forward()&lt;来获取每个帧的输出&lt; /代码&gt;.
但是 net.forward() 每帧需要 7 到 10 秒才能给出结果。请帮助我如何提高性能（减少 net.forward() 中的处理时间）。
意思是：从Step1到Step2每帧需要7到10秒。
（下面的代码中提到了Step1和Step2）。

&lt;前&gt;&lt;代码&gt;导入cv2
导入时间
将 numpy 导入为 np

protoFile =“部署.prototxt”
权重文件=“iter_10.caffemodel”

宽度 = 300
高度 = 300

＃ 网络摄像头
上限 = cv2.VideoCapture(0)
hasFrame,frame = cap.read()

net = cv2.dnn.readNetFromCaffe(protoFile,weightsFile)
k = 0
而1：
    k+=1
    t = 时间.time()
    print(&quot;开始时间 = {}&quot;.format(t))
    hasFrame,frame = cap.read()

    如果没有hasFrame：
        cv2.waitKey()
        print(&quot;请稍等====&gt;&quot;)
        休息

    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),
                              (0, 0, 0)，swapRB=False，crop=False)


    net.setInput(inpBlob)

    ＃ 步骤1
    print(&quot;前向 = {}&quot;.format(time.time() - t))

    输出 = net.forward()

    ＃ 第2步
    #每帧花费近 7 到 10 秒
    print(&quot;forward = {}&quot;.format(time.time() - t))
]]></description>
      <guid>https://stackoverflow.com/questions/54488986/how-to-improve-performance-net-forward-of-cv2-dnn-readnetfromcaffe-net-for</guid>
      <pubDate>Sat, 02 Feb 2019 00:56:04 GMT</pubDate>
    </item>
    <item>
      <title>文本分类。 TFIDF 和朴素贝叶斯？ [关闭]</title>
      <link>https://stackoverflow.com/questions/43163959/text-classification-tfidf-and-naive-bayes</link>
      <description><![CDATA[我正在尝试执行文本分类任务，其中有大约 500 条餐厅评论的训练数据，这些评论被标记为 12 个类别。我花了比我应该花的时间来实现 TF.IDF 和余弦相似度来对测试数据进行分类，但只得到了一些非常差的结果（0.4 F-measure）。由于现在时间不在我这边，我需要实施一些更有效且没有陡峭学习曲线的东西。我正在考虑将 TF.IDF 值与朴素贝叶斯结合使用。这听起来合理吗？我知道如果我能够以正确的格式获取数据，我可以使用 Scikit learn 来做到这一点。您还有其他建议我考虑吗？]]></description>
      <guid>https://stackoverflow.com/questions/43163959/text-classification-tfidf-and-naive-bayes</guid>
      <pubDate>Sun, 02 Apr 2017 02:21:23 GMT</pubDate>
    </item>
    </channel>
</rss>