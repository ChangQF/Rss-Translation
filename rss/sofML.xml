<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 04 May 2024 00:59:34 GMT</lastBuildDate>
    <item>
      <title>如何将自定义训练代码上传到 Sagemaker Estimator Python</title>
      <link>https://stackoverflow.com/questions/78427298/how-to-upload-custom-training-code-to-sagemaker-estimator-python</link>
      <description><![CDATA[我正在尝试使用 Sagemaker 的 Estimator 类来训练模型。我的目录结构如下：
&lt;前&gt;&lt;代码&gt;- 温度
   - 训练步骤
      - 火车.py
      - 要求.txt
   - 温度.py

train.py：
from sklearn.datasets import load_iris
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestClassifier
从 sklearn.metrics 导入 precision_score

########################################版本测试######## #################################################### ####
导入日志记录
导入系统
导入pkg_resources
导入 json

def get_python_and_package_versions():
    # 获取Python版本
    python_version = 系统版本

    # 获取已安装的包版本
    install_packages = {pkg.key: pkg_resources.working_set 中 pkg 的 pkg.version}

    # 将Python版本和已安装的包版本合并到字典中
    版本数据 = {
        “python_版本”：python_版本，
        “已安装的包”：已安装的包
    }
    
    # 初始化记录器
    记录器=logging.getLogger(__name__)
    logger.setLevel(logging.INFO)
    
    # 检查默认记录器是否已经存在
    如果不是 logger.hasHandlers():
        # 如果不存在默认记录器，则创建一个新记录器
        处理程序=logging.StreamHandler(sys.stdout)
        formatter =logging.Formatter(&#39;%(asctime)s - %(levelname)s - %(message)s&#39;)
        handler.setFormatter(格式化程序)
        logger.addHandler(处理程序)
    
    # 记录版本数据
    logger.info(“Python版本和安装的包版本：”)
    logger.info(json.dumps(version_data, indent=4))

# 用法示例：
get_python_and_package_versions()


########################################版本测试######## #################################################### ####


# 加载鸢尾花数据集
虹膜 = load_iris()
X = 虹膜数据
y = 虹膜.目标

# 将数据集分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 初始化并训练随机森林分类器
分类器 = RandomForestClassifier(n_estimators=100, random_state=42)
分类器.fit(X_train, y_train)

# 对测试集进行预测
预测 = classifier.predict(X_test)

# 计算准确率
准确度=准确度_分数（y_测试，预测）
print(“准确度：”, 准确度)

临时.py：
导入 sagemaker
从 sagemaker.estimator 导入估算器
从 sagemaker.image_uris 导入 get_base_python_image_uri
从 sagemaker.local 导入 LocalSession
导入boto3

# 创建 boto 会话
boto_session = boto3.Session()

local_session = LocalSession(boto_session = boto_session, default_bucket = pipeline_bucket_name) #存储桶名称

输入 = {
        “训练”：sagemaker.inputs.TrainingInput(
            s3_data=processor_output #数据存在的S3 URI
        ）

    }

估计器 = 估计器(
            image_uri=get_base_python_image_uri(
                “us-east-1”，py_version=str(38)
            ),
            role=role, #添加执行角色
            实例计数=1，
            instance_type =“本地”，
            output_path=artifact_location, #s3-bucket-location
            base_job_name=training_base_job_name, # 训练作业的名称
            sagemaker_session=local_session,
            source_dir=&quot;./train_step&quot;,
            code_location=training_code_location, #s3-bucket-location
            入口点=“train.py”，
            container_entry_point=[&quot;find&quot;, &quot;.&quot;, &quot;-type&quot;, &quot;f&quot;, &quot;(&quot; , &quot;-name&quot;, &quot;train.py&quot;, &quot;-o&quot;, “-name”、“train.csv”、“)” ]
        ）
train_args = 估计器.fit(
    输入=输入
）

似乎未添加 source_dir 中指定的目录。当我尝试查找 train.py 和 train.csv 时，我可以找到 train.csv 的路径，但  中没有任何文件&gt;train_step 目录。
train.csv - ./opt/ml/input/data/train/train.csv。
注意：train.py 是一个虚拟代码，只是为了使其可以在没有数据集的情况下重现。
在检查 code_location 中指定的 s3 位置时，我可以看到上传到那里的 source_code。]]></description>
      <guid>https://stackoverflow.com/questions/78427298/how-to-upload-custom-training-code-to-sagemaker-estimator-python</guid>
      <pubDate>Fri, 03 May 2024 23:14:44 GMT</pubDate>
    </item>
    <item>
      <title>“寻求 Python 中高效 EDA 和大型数据集可视化的先进技术”</title>
      <link>https://stackoverflow.com/questions/78427059/seeking-advanced-techniques-for-efficient-eda-and-visualization-of-large-datase</link>
      <description><![CDATA[在提高数据分析和可视化技能的过程中，我一直在探索各种技术和工具来更有效地处理大型数据集。我一直使用 Python、Pandas 和 Matplotlib 作为我的主要工具，但我目前正在社区寻求建议和最佳实践，以进一步增强我在该领域的工作流程和熟练程度。我希望从像你们这样经验丰富的专业人士那里获得宝贵的见解、技术和建议，这将帮助我更好地处理涉及海量数据集的现实生活场景
我试图解释我的学习目标，但我最初的反应很不专业。我期望清楚地了解我的意图，但实际结果却是混乱。我现在提供更合适的回应]]></description>
      <guid>https://stackoverflow.com/questions/78427059/seeking-advanced-techniques-for-efficient-eda-and-visualization-of-large-datase</guid>
      <pubDate>Fri, 03 May 2024 21:42:03 GMT</pubDate>
    </item>
    <item>
      <title>神经网络倾向于对训练中的所有输入值返回相同的预测</title>
      <link>https://stackoverflow.com/questions/78426999/neural-net-tending-towards-returning-the-same-predictions-for-all-input-values-i</link>
      <description><![CDATA[我正在尝试在 numpy 中创建一个神经网络来对 iris 数据集进行预测。我很确定我做的一切都是正确的，但在训练中，模型的预测概率总是倾向于每个类别几乎相同，并且记录与记录之间完全相同。
我尝试过调整学习率、复杂性（添加更多节点）和缩放输入值，似乎没有什么可以阻止模型倾向于对每一行做出相同的预测。
我不会复制并粘贴所有代码，而是直接链接笔记本，因为我不确定这是否是代码的问题，或者在代码中的何处会发现问题：
https://github.com/ mocboch/Neural-Net/blob/master/Neural%20Network%20for%20Iris%20Classification.ipynb]]></description>
      <guid>https://stackoverflow.com/questions/78426999/neural-net-tending-towards-returning-the-same-predictions-for-all-input-values-i</guid>
      <pubDate>Fri, 03 May 2024 21:21:04 GMT</pubDate>
    </item>
    <item>
      <title>如何解释基于情感分析数据训练的朴素贝叶斯模型？</title>
      <link>https://stackoverflow.com/questions/78426520/how-to-explain-a-naive-bayes-model-trained-on-data-for-sentiment-analysis</link>
      <description><![CDATA[我正在编写此代码来训练朴素贝叶斯模型：
# 加载必要的库
库（readxl）
库（插入符号）
图书馆(e1071)

# 加载预处理后的TF-IDF矩阵
tfidf_df &lt;- read_excel(&#39;~/Downloads/tfidf_r.xlsx&#39;)

# 加载带有标签的原始DataFrame
df &lt;- read_excel(&#39;~/Downloads/all-review_label.xlsx&#39;)

# 将 TF-IDF 矩阵与标签 DataFrame 合并
merged_df &lt;- 合并(tfidf_df, df, by=&#39;review_id&#39;)

# 将数据分为训练集和测试集
  设置.种子(42)
  train_indices &lt;- createDataPartition(merged_df$review_id, p = 0.8, list = FALSE)
  train_data &lt;- merged_df[train_indices, ]
  test_data &lt;- merged_df[-train_indices, ]
  
  # 初始化并训练朴素贝叶斯分类器
  naive_bayes_model &lt;- naiveBayes(标签 ~ ., data = train_data)
  
  # 对测试集进行预测
  y_pred &lt;- 预测（naive_bayes_model，newdata = test_data）
  打印（y_pred）
  
  # 将预测值和实际值转换为相同水平的因子
  级别 &lt;- 唯一（c（级别（y_pred），级别（test_data$review）））
  y_pred &lt;- 因子(y_pred, 级别 = 级别)
  test_data$label&lt;- 因子(test_data$label, 级别 = 级别)

我想解释一下使用 SHAP 的模型获得的结果，我使用了以下代码：
库（kernelshap）
图书馆（shapviz）

xvars &lt;- setdiff(colnames(merged_df), “标签”)

shap_values &lt;- permshap(naive_bayes_model, X = merged_df,
                        bg_X = 合并_df,
                        功能名称 = xvars)

shap_values &lt;- shapviz(shap_values)
sv_importance(shap_values, kind = “蜜蜂”)

但我收到此错误：
permshap.default 中的错误（naive_bayes_model，X = merged_df，bg_X = merged_df，：
  排列 SHAP 仅支持最多 14 个特征

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78426520/how-to-explain-a-naive-bayes-model-trained-on-data-for-sentiment-analysis</guid>
      <pubDate>Fri, 03 May 2024 18:57:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么最终模型中的树木数量不是我指定的数量？</title>
      <link>https://stackoverflow.com/questions/78426497/why-is-the-number-of-trees-in-the-final-model-not-the-number-that-i-specified</link>
      <description><![CDATA[我使用 quantregForest 进行分位数回归森林模型，代码如下：
opt_mdl &lt;- quantregForest(x = train[, features],
                          y = 训练[，目标]，
                          节点大小 = 5,
                          尝试= 14，
                          n树= 500，
                          nthreads = 并行::DetectCores() - 1)

这里我指定ntree为500。但是在opt_mdl中，值ntree (opt_mdl$ntree) 是 34。为什么会发生这种情况以及如何修复它？]]></description>
      <guid>https://stackoverflow.com/questions/78426497/why-is-the-number-of-trees-in-the-final-model-not-the-number-that-i-specified</guid>
      <pubDate>Fri, 03 May 2024 18:51:19 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 高估非零类</title>
      <link>https://stackoverflow.com/questions/78426439/lightgbm-overestimating-non-zero-classes</link>
      <description><![CDATA[我有 3 个类别的分类问题。信噪比相当低，非零类大约占所有数据的 3-4%。因此，我决定按频率反比地衡量样本的权重：
对于 [-1, 0, 1] 中的标签：
    freq = (df[&#39;y&#39;]==label).sum() / len(df)
    df[&#39;weight&#39;] = np.where(df[&#39;y&#39;]==label, 1./freq, df[&#39;weight&#39;])

0 类的权重略高于 1，其他 2 类的权重在 40 左右。
当我进行推理时：
df[&#39;y_hat&#39;] = clf.predict(df[特征])

我得到的非零样本比真实 y 列中的实际样本多大约 4 倍。这种情况在样本内和样本外都会发生。所以，这在训练和测试中都是一个问题。
如果我想要获得类似数量的非零样本，我该怎么办，是否是我的称重方案过于极端，或者可能的解决方案是什么？我是否应该考虑使用 predict_proba() 并在训练集上计算自己的阈值？]]></description>
      <guid>https://stackoverflow.com/questions/78426439/lightgbm-overestimating-non-zero-classes</guid>
      <pubDate>Fri, 03 May 2024 18:38:49 GMT</pubDate>
    </item>
    <item>
      <title>正确理解 LSTM 的 Keras 实现：单元如何工作？</title>
      <link>https://stackoverflow.com/questions/78425666/proper-understanding-of-keras-implementation-of-lstm-how-do-the-units-work</link>
      <description><![CDATA[N_u 单位的 LSTM 如何处理 N_x 长度的数据？我知道以前有很多类似的问题被问过，但答案却充满矛盾和困惑。因此，我试图通过提出具体问题来消除我的疑虑。我在这里关注简单的博客：
https://colah.github.io/posts/2015-08-Understanding -LSTM/
Q0) keras 实现与上面博客一致吗？
请考虑以下代码。
导入tensorflow为tf
N_u,N_x=1,1
模型 = tf.keras.Sequential([
    tf.keras.layers.LSTM(N_u, stateful=True, batch_input_shape=(32, 1, N_x))
]）
模型.summary()

为了简单起见，我在这里的输入数据只是一个标量，并且我有一个时间步长来使事情简单。输出形状为(32,1)。参数个数为12。
Q1) 我有一个 LSTM 单元或单元，对吗？下面代表一个单元格，对吗？

我从图片中了解到会有12个参数：忘记gate=2个权重+1个偏差； input_gate=2*(2个权重+1个偏置);输出门=（2个权重+1个偏置）。所以到目前为止一切都很好。
Q2) 现在让我们设置N_u,N_x=1,2。我希望相同的单元格将应用于 x 的两个元素。但是我发现现在参数总数是16个！为什么？是因为我得到了 4 个额外的权重参数，对应于 x_2 和 LSTM 单元之间的 LSTM 连接吗？
Q3) 现在让我们设置N_u,N_x=2,1。我现在有两个 LSTM 单元。我的理解是两个单元将并行操作相同的数据（在本例中为标量）。这两个单位是完全独立的还是相互影响的？我预计参数数量为 2*12=24，但实际上我得到了 32 个。为什么是 32？
Q4）如果我设置N_u,N_x=2,2，参数数量是40。我想如果我理解了以上两点就可以得到它。
Q5）最后，是否有 keras 实现所基于的文档/论文？]]></description>
      <guid>https://stackoverflow.com/questions/78425666/proper-understanding-of-keras-implementation-of-lstm-how-do-the-units-work</guid>
      <pubDate>Fri, 03 May 2024 15:46:19 GMT</pubDate>
    </item>
    <item>
      <title>如何提高决策树的准确性？</title>
      <link>https://stackoverflow.com/questions/78425640/how-can-i-improve-the-accuracy-of-my-decision-tree</link>
      <description><![CDATA[我的决策树的准确率是 5%。如何改进？我已经尝试过一些事情，但没有运气。我的目标变量是 Daily_Max，它是每日臭氧水平读数。
&lt;前&gt;&lt;代码&gt;库(mlbench)
#data(包=“mlbench”)
数据（“臭氧”，包=“mlbench”）
臭氧名称
colnames(Ozone) = c(“月”、“日”、“周”、“Daily_Max”、“Pressure_Height”、“Wind_Speed”、“湿度”、“Sandburg_Temp”、“ElMonte_Temp” ;、“Inversion_Height”、“Pressure_Gradient”、“Inversion_Temp”、“Visibility”）

#（来源）Leo Breiman，加州大学伯克利分校统计系。 Leo Breiman 和 Jerome H. Friedman (1985)，《估计多元回归和相关性的最佳变换》中使用的数据，JASA，80，第 580-598 页。
#（资源）https://rdrr.io/cran/mlbench/man/Ozone.html


＃打扫  -  -  -  -  -  -  -  -  - 
sum(is.na(臭氧))

df_Ozone = na.omit(臭氧)
总和（is.na（df_Ozone））


#我的数据需要平衡吗？ ----------------
#班级分布
class_counts = 表(df_Ozone$Daily_Max)
打印（类计数）

# 绘制类别分布
barplot(class_counts, main = “类别分布”)

# 训练模型的示例（替换为您的实际模型）
w_model &lt;- rpart(Daily_Max ~ ., data = df_Ozone)

＃ 作出预测
w_predictions &lt;- 预测(w_model, newdata = df_Ozone)

# 计算混淆矩阵
fusion_matrix &lt;- 表(w_predictions, df_Ozone$Daily_Max)
打印（混淆矩阵）

#分箱
#低 0 - 12 ppb
#中 12 - 25 ppb
#高 26 - 38 ppb
休息时间 = c(1, 12, 25, 38)
df_Ozone$bin = cut(df_Ozone$Daily_Max, Breaks = Breaks, labels = c(“低”, “中”, “高”), include.lowest = TRUE)
打印（df_臭氧）


＃决策树  -  -  -  - -
设置.种子(123)

# 将数据分为训练集和测试集
train_indices = Sample(1:nrow(df_Ozone), 0.7 * nrow(df_Ozone)) # 70% 用于训练
dt_train = df_Ozone[train_indices, ]
dt_test = df_Ozone[-train_indices, ]

库（r部分）
库（rpart.plot）
dt_model = rpart(Daily_Max ~ ., 数据 = dt_train)

# 可视化决策树
rpart.plot(dt_model)

# 对测试集进行预测
dt_predictions = 预测(dt_model, dt_test)
dt_预测

dt_table = 表(dt_test$Daily_Max, dt_predictions)
数据表


# 计算准确率
dt_accuracy = sum(diag(dt_table)) / sum(dt_table)
dt_准确度

dt_准确度 = dt_准确度 * 100
dt_accuracy #accuracy 为 4.92%，表现不佳

# 决策树总结
摘要（dt_model）

我尝试删除“周”从数据中提取特征，它实际上使准确性变得更差！我不知道从这里该去哪里。]]></description>
      <guid>https://stackoverflow.com/questions/78425640/how-can-i-improve-the-accuracy-of-my-decision-tree</guid>
      <pubDate>Fri, 03 May 2024 15:39:50 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的多线程无法在 Raspberry Pi 上正常工作</title>
      <link>https://stackoverflow.com/questions/78424618/multithreading-in-python-not-working-correctly-with-raspberry-pi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78424618/multithreading-in-python-not-working-correctly-with-raspberry-pi</guid>
      <pubDate>Fri, 03 May 2024 12:10:47 GMT</pubDate>
    </item>
    <item>
      <title>从核矩阵中删除特征</title>
      <link>https://stackoverflow.com/questions/78424564/remove-feature-from-kernel-matrix</link>
      <description><![CDATA[我正在尝试使用带有预先计算内核的 SVM 和 sklearn 来执行二元分类任务。
我创建了我的火车内核，但我包含了一个我不打算包含的功能，并且测试数据中没有该功能。我对内核除了“距离”之外到底是什么没有非常透彻的了解。数据点之间，但是否可以从训练内核中删除此功能而不必生成新的功能？]]></description>
      <guid>https://stackoverflow.com/questions/78424564/remove-feature-from-kernel-matrix</guid>
      <pubDate>Fri, 03 May 2024 11:59:00 GMT</pubDate>
    </item>
    <item>
      <title>通过组合许多不同的 ML 模型的输出来构建强化学习模型</title>
      <link>https://stackoverflow.com/questions/78424449/building-a-reinforcement-learning-model-by-combining-outputs-of-many-different-m</link>
      <description><![CDATA[与许多人相比，我对编码来说是一个业余爱好者，我需要一些指导。
在仔细编写和调整构建股票价格预测器（希望之后是交易机器人）后，我构建了 3 个不同的 ML 模型：CNN+LSTM、带有 LSTM 的堆叠自动编码器和液体时间常数模型，以使用 LNN。我保存了他们的模型文件、缩放器和模型权重（用于 LNN）。使用它们获得了不错的 MSE、MAE、RMSE 和 Theil&#39;s U (U1) 结果。
现在我想将他们的输出整合到一个强化学习模型中，这将受益于目标和奖励函数。我可以想象我即将踏上人生旅程中最艰难的一段路。我的第一个选择是编写一个 Qlearning 类来在 Tensorflow (python) 上运行。然后我转而使用 Tensorflow 代理来组合和堆叠不同的模型文件。这里很黑。有人指导一下吗？
目前我正在尝试这个：
# 为股市数据定义自定义环境
StockMarketEnv 类（suite_gym.GymEnv）：
    “”“我们的股票市场预测器的自定义环境。”“”
    def __init__(自身，数据)：
        super().__init__(数据, max_episode_steps=1000)
        self._data = data # 这应该是预处理的市场数据

    def观察规范（自我）：
        “”“”返回观察规范。“”“”
        return self._data.shape[1] # 特征数量

    def action_spec(自身):
        “”“返回动作规范。”“”
        return 3 # 例如：买入、持有、卖出

我的第二个选择是使用 OpenAI Gym 或其他一些库。请帮助选择最佳方法以及如何开始实施它。
提前非常感谢
我尝试用 Tensorflow 构建一个类，但这只是初步的努力。不过，我确实有以前模型的模型输出和缩放器+权重，可以用作我即将推出的 RL 模型的输入。]]></description>
      <guid>https://stackoverflow.com/questions/78424449/building-a-reinforcement-learning-model-by-combining-outputs-of-many-different-m</guid>
      <pubDate>Fri, 03 May 2024 11:33:54 GMT</pubDate>
    </item>
    <item>
      <title>Unsloth 未检测到 CUDA 和“str2optimizer32bit”</title>
      <link>https://stackoverflow.com/questions/78420830/unsloth-not-detecting-cuda-and-str2optimizer32bit</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78420830/unsloth-not-detecting-cuda-and-str2optimizer32bit</guid>
      <pubDate>Thu, 02 May 2024 17:30:58 GMT</pubDate>
    </item>
    <item>
      <title>如何解决在 Python 中导入 TensorFlow 时出现“不可哈希类型”错误？</title>
      <link>https://stackoverflow.com/questions/78185218/how-can-i-solve-the-unhashable-type-error-when-importing-tensorflow-in-python</link>
      <description><![CDATA[我在 Virtual Studio Code 中导入 TensorFlow 时遇到问题。我尝试执行我的代码，该代码从导入不同的模块开始。其中一行正在导入 Tensorflow：
将tensorflow导入为tf
这给了我错误：
不可散列的类型：“列表”
文件“链接”，第 10 行，位于
导入tensorflow as tf TypeError：不可散列类型：&#39;list&#39;
首先，我在另一台计算机上使用 Jupyter Notebook 编写了此代码，我可以毫无问题地执行它。在我想要执行它的计算机上遇到此错误后，我尝试重现该错误。我在第一台计算机上安装了 Virtual Studio Code，安装了所有模块并成功执行。好像是设置什么的问题。
为了测试我只执行了这个，这给了我错误：
导入tensorflow为tf
我在两台计算机上都安装了 Python 3.9.0 和 Tensorflow 2.16.1。经过多次尝试（例如卸载并安装tensorflow，或重置Virtual Studio Code），我决定在这里询问。也许这里有人更了解这个问题:)]]></description>
      <guid>https://stackoverflow.com/questions/78185218/how-can-i-solve-the-unhashable-type-error-when-importing-tensorflow-in-python</guid>
      <pubDate>Tue, 19 Mar 2024 08:44:21 GMT</pubDate>
    </item>
    <item>
      <title>分类特征与连续目标特征之间的关系</title>
      <link>https://stackoverflow.com/questions/77166237/relationship-between-categorical-feature-and-continuous-target-feature</link>
      <description><![CDATA[我正在研究与 Kaggle 上的竞争相对应的房价模型。
https://www.kaggle.com/competitions/house-prices-高级回归技术。
我发现分类数据中有很多缺失值。其中一些失踪率超过 60%，另一些则失踪 47%。
我读到，在删除它们之前，我需要查看它们与目标特征之间的关系（连续）。但是，我无法测量分类特征和连续数值目标特征之间的关系。
我删除的特征缺失值超过 60%。
即将上线，但缺失了 47%。我很困惑是否要放弃它。并知道是否丢弃它取决于我不知道如何计算的目标之间的关系。
我搜索了很多。并且找不到仅“备件人等级”而且计算之前必须是完整的数据，所以我用KNN估算它然后计算。给我 0.1，所以我放弃了它。
我不知道我应该做什么，我所做的是否正确，请帮忙

我的问题：如何计算关系以做出是否放弃分类特征的决策
]]></description>
      <guid>https://stackoverflow.com/questions/77166237/relationship-between-categorical-feature-and-continuous-target-feature</guid>
      <pubDate>Sun, 24 Sep 2023 08:11:39 GMT</pubDate>
    </item>
    <item>
      <title>在 Tensorflow C++ API 中为占位符张量提供值</title>
      <link>https://stackoverflow.com/questions/45054737/feeding-a-value-for-placeholder-tensor-in-tensorflow-c-api</link>
      <description><![CDATA[我使用（Tensorflow）Python API重新训练了Inception-v3模型，并通过修改tensorflow/tensorflow/examples/image_retraining/retrain.py在.pb中保存了独立的图形，并进行了以下修改以在分类之前添加退出层层：
def nn_layer（input_tensor，input_dim，output_dim，layer_name，activation_name =&#39;activation&#39;，act = tf.nn.softmax）：
# 添加名称范围可确保对图中各层进行逻辑分组。
与 tf.name_scope(layer_name):
# 该变量将保存该层权重的状态
与 tf.name_scope(&#39;权重&#39;):
权重=weight_variable([input_dim,output_dim])
变量摘要（权重，图层名称+&#39;/权重&#39;）
与 tf.name_scope(&#39;dropout&#39;):
keep_prob = tf.placeholder(tf.float32)
tf.scalar_summary(&#39;dropout_keep_probability&#39;, keep_prob)
drop = tf.nn.dropout(input_tensor, keep_prob)
变量摘要(drop, 图层名称 + &#39;/dropout&#39;)
与 tf.name_scope(&#39;偏差&#39;):
偏差 =bias_variable([output_dim])
变量摘要（偏差，层名称 + &#39;/偏差&#39;）
preactivate = tf.matmul(drop, 权重) + 偏差
tf.histogram_summary(layer_name + &#39;/pre_activations&#39;, 预激活)
与 tf.name_scope(activation_name):
激活 = 行动（预激活）
tf.histogram_summary(layer_name + &#39;/activations&#39;, 激活)
返回预激活、激活、keep_prob

在Python中生成预测的代码如下：
softmax_tensor = sess.graph.get_tensor_by_name(&#39;final_layer/final_result/Softmax:0&#39;)
预测 = sess.run(softmax_tensor, { &#39;DecodeJpeg/contents:0&#39;:image_data, &#39;final_layer/dropout/Placeholder:0&#39;: 1.})

Python 代码的 C++ 对应部分如下：
字符串 input_layer = &quot;Mul&quot;;
字符串output_layer =“final_layer/dropout/Placeholder:0”;
状态 run_status = session-&gt;Run({{input_layer, resized_tensor}}, {output_layer}, {}, &amp;outputs);

C++ 代码最终出现以下错误消息：
运行模型失败：参数无效：您必须为占位符张量“final_layer/dropout/Placeholder”提供一个值

我应该在上面的 C++ 代码中更改什么来消除此错误？换句话说，如何像在 python 代码中一样更改 C++ 代码中的占位符值。我已经被这个问题困扰很多天了。任何帮助将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/45054737/feeding-a-value-for-placeholder-tensor-in-tensorflow-c-api</guid>
      <pubDate>Wed, 12 Jul 2017 10:10:13 GMT</pubDate>
    </item>
    </channel>
</rss>