<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 07 May 2024 03:16:59 GMT</lastBuildDate>
    <item>
      <title>Datacamp实践中的Pandas代码是错误的</title>
      <link>https://stackoverflow.com/questions/78439826/pandas-code-is-wrong-in-datacamp-practical</link>
      <description><![CDATA[实践考试：房屋销售
Real Agents 是一家专注于销售房屋的房地产公司。
Real Agents 在一个大都市区销售多种类型的房屋。
有些房屋销售缓慢，有时需要降低价格才能找到买家。
为了保持竞争力，Real Agents 希望优化其试图出售的房屋的挂牌价格。
他们希望通过根据房屋的特征预测其售价来实现这一目标。
如果他们能够提前预测销售价格，就可以缩短销售时间。
数据
数据集包含该地区以前出售的房屋的记录。

&lt;标题&gt;

列
姓名
标准


&lt;正文&gt;

house_id
标称。
房屋的唯一标识符。不可能缺少值。


城市
标称。
房屋所在的城市。 “Silvertown”、“Riverford”、“Teasdale”和“Poppleton”之一。将缺失值替换为“未知”。


促销价
离散。
房屋的售价（以美元计）。值可以是任何大于或等于零的正数。删除缺失的条目。


促销日期
离散。
最后一次出售房屋的日期。将缺失值替换为 2023-01-01。


列出的月份
连续。
房屋在最后一次销售之前在市场上挂牌的月数，四舍五入到小数点后一位。将缺失值替换为列出的平均月数，精确到小数点后一位。


卧室
离散。
房子里的卧室数量。任何大于或等于零的正值。将缺失值替换为平均卧室数，四舍五入到最接近的整数。


房屋类型
序数。
“梯田”之一（两堵共用墙）、“半独立式” （一堵共用墙），或“独立”。 （无共用墙）。用最常见的房屋类型替换缺失值。


区域
连续。
房屋面积，以平方米为单位，四舍五入到小数点后一位。将缺失值替换为平均值，精确到小数点后一位。



任务1
Real Agents 的团队知道房产所在的城市会对售价产生影响。
不幸的是，他们认为这并不总是记录在数据中。
计算城市缺失值的数量。
您应该使用文件“house_sales.csv”中的数据。
您的输出应该是一个对象missing_city，其中包含此列中缺失值的数量。
所有必需的数据都应该已创建，并具有所需的列，并识别和替换缺失的值。
将 pandas 导入为 pd

# 从 CSV 文件加载数据集
数据 = pd.read_csv(“house_sales.csv”)

# 检查“city”中是否有缺失值柱子
missing_city = data[“city”].isnull().sum()

# 替换“城市”中缺失的值带有“未知”的列
data[“城市”].fillna(“未知”, inplace=True)

在这段代码中发现错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78439826/pandas-code-is-wrong-in-datacamp-practical</guid>
      <pubDate>Tue, 07 May 2024 02:23:03 GMT</pubDate>
    </item>
    <item>
      <title>将任意深度转换为 CoreML</title>
      <link>https://stackoverflow.com/questions/78439767/converting-depth-anything-to-coreml</link>
      <description><![CDATA[我正在尝试将现有的 depth-anything PyTorch 模型转换为 CoreML 格式。我决定使用 Google Colab 并采用以下注释来推断depth-anything模型。然而，我在尝试将其导入 iOS 端时遇到了一些异常。以下是我用于转换的代码片段：
# 安装所有需要的扩展
!pip install coremltools
# ...

import coremltools as ct
import torch

# 将 PyTorch 模型转换为 TorchScript
traced_model = torch.jit.trace(depth_anything, torch.rand(1, 3, 518, 518))

# 将 TorchScript 模型转换为 CoreML
model_coreml = ct.convert(
traced_model,
输入=[ct.ImageType(name=&quot;input_1&quot;, shape=(1, 3, 518, 518), scale=1/255.0)]
)

输出 = model_coreml._spec.description.output[0]
output.type.imageType.colorSpace = ct.proto.FeatureTypes_pb2.ImageFeatureType.ColorSpace.Value(&#39;RGB&#39;)
output.type.imageType.width = 518
output.type.imageType.height = 518

# 保存修改后的 CoreML 模型
print(model_coreml)
model_coreml.save(&#39;/content/drive/MyDrive/trained_models/depth9.mlpackage&#39;)

我尝试直接指定输入参数，就像我为输出参数所做的那样：
# 为输入模式创建字典
input_schema = {&#39;input_name&#39;: &#39;input&#39;, &#39;input_type&#39;: ct.TensorType(shape=(1, 3, 518, 518))}

# 将输入模式添加到模型的元数据
model_coreml.user_defined_metadata[&#39;inputSchema&#39;] = str(input_schema)

或者使用 convert_to 选项设置 neuralnetwork，如下所示：
model_coreml = ct.convert(
traced_model,
输入=[ct.ImageType(name=&quot;input_1&quot;, shape=(1, 3, 518, 518), scale=1/255.0)],
convert_to=&#39;neuralnetwork&#39;
)

或者使用 BGR/GRAYSCALE 设置 ct.proto.FeatureTypes_pb2.ImageFeatureType.ColorSpace.Value(&#39;RGB&#39;)&gt;
没有任何帮助。
如果我尝试使用 neuralnetwork 后端导入模型，我只会收到无限加载。如果我尝试使用 mlprogram 后端导入模型（默认，如果未指定），我会收到以下信息：

我期待任何建议和帮助，因为我需要的只是将现有的 depth-anything 模型转换为 CoreML 格式，而无需进行任何调整或更改。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78439767/converting-depth-anything-to-coreml</guid>
      <pubDate>Tue, 07 May 2024 01:53:36 GMT</pubDate>
    </item>
    <item>
      <title>如何以编程方式设置 W&B 运行失败警报？</title>
      <link>https://stackoverflow.com/questions/78439701/how-to-programmatically-set-alerts-for-failure-in-a-wb-run</link>
      <description><![CDATA[如何以编程方式设置 W&amp;B 运行失败警报？
我正在尝试在 W&amp;B（权重和偏差）项目中设置警报，以便在运行失败时通知我。我一直在测试几个我认为根据我的研究可以工作的函数，但似乎没有一个在 W&amp;B API 中实现。这是我尝试设置这些通知的代码片段：
导入 wandb

模式 = &#39;空运行&#39;
运行名称 = &#39;我的运行&#39;
批次数量 = 50
路径=&#39;/数据&#39;
名称 = &#39;实验1&#39;
今天 = &#39;2023-08-01&#39;
概率 = [0.1, 0.9]
批量大小 = 32
data_mixture_name = &#39;mix1&#39;

调试 = 模式 == &#39;dryrun&#39;
run = wandb.init(mode=mode,project=“超越规模”,name=run_name,save_code=True)
wandb.config.更新（{
    “num_batches”：num_batches，
    “路径”：路径，
    “姓名”：姓名，
    “今天”：今天，
    “概率”：概率，
    &#39;batch_size&#39;：batch_size，
    “调试”：调试，
    &#39;data_mixture_name&#39;：data_mixture_name
})

# 尝试设置通知
run.notify_on_failure()
run.notify_on_crash()
run.notify_on_exit()
run.notify_on_heartbeat()
run.notify_on_abort()

每次尝试都会导致 AttributeError，表明“Run”对象没有此类属性。例如：
AttributeError：“Run”对象没有属性“notify_on_failure”

在 W&amp;B 中是否有正确的方法来设置故障或其他警报？如果是这样，我应该如何修改我的方法？
参考：https://community.wandb.ai/t/how-do-i-set-the-wandb-alert-programatically-for-my-current-run/4891]]></description>
      <guid>https://stackoverflow.com/questions/78439701/how-to-programmatically-set-alerts-for-failure-in-a-wb-run</guid>
      <pubDate>Tue, 07 May 2024 01:17:24 GMT</pubDate>
    </item>
    <item>
      <title>为 Windows 11 和 AMD GPU 安装 Pytorch</title>
      <link>https://stackoverflow.com/questions/78439640/installing-pytorch-for-windows-11-and-amd-gpu</link>
      <description><![CDATA[有人可以帮我安装 Pytorch 吗？我的设备当前使用 Windows 操作系统和 AMD GPU。但是，Pytorch 安装不支持与 ROCm 组合的 Windows 操作系统。只有选择Linux操作系统时，ROCm选项才可用。
我可以使用 CUDA 工具包来替代 ROCm 吗？或者我是否可以将我的操作系统更改为Linux？有没有办法绕过所有这些并且仍然能够使用 Pytorch？
任何建议将不胜感激！
我尝试在 youtube 上寻找安装教程，但他们没有与我相同的操作系统和 GPU 组合。 （即Windows操作系统和AMD GPU）]]></description>
      <guid>https://stackoverflow.com/questions/78439640/installing-pytorch-for-windows-11-and-amd-gpu</guid>
      <pubDate>Tue, 07 May 2024 00:46:02 GMT</pubDate>
    </item>
    <item>
      <title>关于 ML + 计算机视觉项目的建议</title>
      <link>https://stackoverflow.com/questions/78439584/advice-regarding-a-ml-computer-vision-project</link>
      <description><![CDATA[我正在研究制作考勤系统的方法，教授点击几张照片（2到3张）
并上传到应用程序，大约 80 名学生会自动出勤。我的训练数据有限，这是我们需要应对的最大缺点和主要问题。我制作了一个用于训练和标记出勤率的基本模型。
我需要帮助来改进它和所有步骤，例如 -
CNN 在这方面有何帮助？
我如何训练它像奖励惩罚系统一样工作，我可以手动告诉它它无法识别的人是谁，以便它在途中学习。
任何帮助、意见或建议。
这是我的第一个研究项目，请详细回答所有内容，我仍在学习中。 0_0]]></description>
      <guid>https://stackoverflow.com/questions/78439584/advice-regarding-a-ml-computer-vision-project</guid>
      <pubDate>Tue, 07 May 2024 00:12:44 GMT</pubDate>
    </item>
    <item>
      <title>R 中的 PCA 时间序列索引：分数图与预期索引不匹配</title>
      <link>https://stackoverflow.com/questions/78439533/pca-time-series-index-in-r-score-plot-doesnt-match-expected-index</link>
      <description><![CDATA[我正在致力于在 R 中创建 PCA 索引以了解它的工作原理。为此，我使用了“弥补”数据。然而，当我绘制第一个组件的分数时，结果并不符合预期。具体来说，分数图显示该指数在第一年表现不佳，然后随着时间的推移迅速提高，这与我的预期相反。
pca &lt;- prcomp（数据，比例= TRUE，中心= TRUE）
分数 &lt;- 比例（数据）%*% pca$rotation[, 1]
情节（分数）

我试图找出我可能做错了什么，或者如何更好地解释结果。任何见解或建议将不胜感激。

数据在这里]]></description>
      <guid>https://stackoverflow.com/questions/78439533/pca-time-series-index-in-r-score-plot-doesnt-match-expected-index</guid>
      <pubDate>Mon, 06 May 2024 23:48:12 GMT</pubDate>
    </item>
    <item>
      <title>当 num_workers>0 时发生 OOM</title>
      <link>https://stackoverflow.com/questions/78439442/oom-when-num-workers0</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78439442/oom-when-num-workers0</guid>
      <pubDate>Mon, 06 May 2024 22:58:51 GMT</pubDate>
    </item>
    <item>
      <title>将 NumPy 函数转换为 TensorFlow 操作时的图形执行问题</title>
      <link>https://stackoverflow.com/questions/78439375/graph-execution-issue-with-converting-numpy-function-to-tensorflow-ops</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78439375/graph-execution-issue-with-converting-numpy-function-to-tensorflow-ops</guid>
      <pubDate>Mon, 06 May 2024 22:24:20 GMT</pubDate>
    </item>
    <item>
      <title>Transformers.js 扩展在关闭扩展选项卡后一次又一次地重新下载模型</title>
      <link>https://stackoverflow.com/questions/78439242/transformers-js-extension-is-redownloading-the-model-again-and-again-after-closi</link>
      <description><![CDATA[我正在尝试使用 Transformers.js 库构建一个 Chrome 扩展，以测试其限制并查看 onDevice ML 在某些情况下是否可以作为选择。
根据他们的官方仓库中提供的示例，我添加新功能。
当我添加翻译管道时，我看到了一些奇怪的事情，即每次打开和关闭浏览器后模型都会一次又一次下载。
class MyTranslationPipeline {
静态任务=“翻译”；
静态模型＝“Xenova/nllb-200-distilled-600M”；
静态实例= null；

静态异步 getInstance(progress_callback = null) {
    if (this.instance === null) {
        console.log(“正在加载翻译管道...”);
        this.instance = pipeline(this.task, this.model, {progress_callback});
    }

    返回这个实例；
 }
}

原始示例展示了 env.allowLocalModels = false; 但我将其设置回 true，但它不起作用，我希望当我重新打开浏览器时，将从中加载模型缓存它已经在的地方。
缓存条目]]></description>
      <guid>https://stackoverflow.com/questions/78439242/transformers-js-extension-is-redownloading-the-model-again-and-again-after-closi</guid>
      <pubDate>Mon, 06 May 2024 21:40:33 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中 2D 输入的集成梯度实现</title>
      <link>https://stackoverflow.com/questions/78438413/integrated-gradients-implementation-for-2d-input-in-pytorch</link>
      <description><![CDATA[我正在尝试为 GNN 实现积分梯度计算（在文章中描述）我正在与.具体来说，我使用论文中的Eq3
我的网络输入是一个 NxM 矩阵，表示 N 个顶点的图，每个顶点都有一个 M 维的特征向量。
考虑到他们是针对 N 维输入推导出该方法，并且在我的情况下，我想为每个节点获得一个分数，如何扩展论文中的方法？
在我当前的实现中，我获得了一个 NxM 矩阵，通过执行 torch.sum(dim=1) 来折叠该矩阵，但这感觉并不那么干净
这是我当前在 PyTorch 中的实现
graph_copy = input_graph.detach().clone()
# 公式中的k/m
k_m = torch.linspace(0, 1, n_steps)
# 存储样本的数组
input_features = [baseline.clone()] # 第一个样本是基线
# x-x&#39;
diff = 原始输入特征 - 基线

# 填充样本数组
对于范围内的 i(1, k_m.shape[0])：
    temp = 基线 + k_m[i] * diff
    input_features_path.append（临时）

梯度= []
对于范围内的 i(k_m.shape[0])：
    ### 将每个输入的向量梯度归零
    input_features[i].requires_grad = True
    model.zero_grad()
    任务.zero_grad()
    
    temp_model_out = 模型（图 = graph_copy，输入 = input_features[i]）[&#39;graph_feature&#39;][0]
    temp_mlp_output = 任务.mlp(temp_model_out)
    temp_prob = Softmax(temp_mlp_output, 暗淡 = 0)

    temp_gradient = grad(输出 = temp_prob[true_label_id], 输入 = input_features_path[i])
    梯度.append(temp_gradient[0])

    input_features_path[i].requires_grad = False

使用 torch.no_grad()：
    ig_scores = original_input_feature * torch.stack(梯度, 暗淡 = 2). 平均值(暗淡 = 2)
    Final_ig_scores = ig_scores.sum(dim = 1)
    排序，索引= torch.sort（final_ig_scores，降序= True）

]]></description>
      <guid>https://stackoverflow.com/questions/78438413/integrated-gradients-implementation-for-2d-input-in-pytorch</guid>
      <pubDate>Mon, 06 May 2024 18:08:43 GMT</pubDate>
    </item>
    <item>
      <title>关于用于食谱成分提取的 spaCy NER 模型注释的反馈</title>
      <link>https://stackoverflow.com/questions/78437443/feedback-on-spacy-ner-model-annotations-for-recipe-ingredient-extraction</link>
      <description><![CDATA[我正在训练一个 spaCy NER 模型，专门识别和分类食谱中的配料。目标是从各种食谱中准确提取配料及其数量、单位和准备说明。以下是我如何注释数据的概述：
跨标签

数量：与单位相关的数字（例如，“2”、“3/4”）
成分：实际成分名称（例如，“糖”、“牛奶”）
测量单位：测量单位（例如，“杯”、“汤匙”）
说明：准备说明（例如，“切成小块”、“分开”）

关系标签

quantity_of：将跨度标签数量与成分相关联
action_to：将跨度标签说明与成分相关联
unit_of：将跨度标签测量单位与数量相关联

我提供了两个示例：一个简单的成分行和一个复杂的成分行。
简单行
复杂行
我正在寻求有关以下几点的反馈：

注释过度：是否存在类别太多或注释过于详细，不利于有效学习和实际应用？是否应该合并或省略某些类别？
训练数据量：在这种类型的 NER 任务中，通常建议使用多少注释数据来实现稳健的模型？我想确保模型在各种食谱格式中都是可靠的。

我尝试过的方法：
我使用类似的标签设置训练了一个模型，减去关系标签和“测量单位”跨度标签。我使用来自随机食谱的大约 700 个样本训练了该模型。结果不尽如人意；该模型很难识别某些方面，特别是在数量及其单位不相邻的情况下（例如 3 瓣大蒜）]]></description>
      <guid>https://stackoverflow.com/questions/78437443/feedback-on-spacy-ner-model-annotations-for-recipe-ingredient-extraction</guid>
      <pubDate>Mon, 06 May 2024 14:52:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么这个模型在某些目标上表现良好，但在某些目标上却表现不佳？</title>
      <link>https://stackoverflow.com/questions/78435762/why-is-this-model-peforming-on-some-targets-well-but-on-some-not</link>
      <description><![CDATA[我正在开发一个监督机器学习项目。我将 horse_data(size,weight,peformance,...) 作为输入，并将配方的成分作为输出。我想预测给定马数据的成分。
这是我的 horse_data 的摘要：HorseData
这是我的目标（秘诀）的摘要：
FirstPartTargets
第二部分目标
第三方目标
我想用这些数据训练一个机器学习模型。在本例中是随机森林回归器，因为输入有许多分类变量（保留、表现、工作类型、种族和种族类型）。
resDf = pd.DataFrame(columns=[&#39;训练 R^2 分数&#39;,&#39;测试 R^2 分数&#39;,&#39;训练 MSE&#39;,&#39;测试 MSE&#39;,&#39;训练 RMSE&#39;,&#39;测试 RMSE&#39; ,&#39;训练 MSAE&#39;,&#39;测试 MSAE&#39;])

参数网格 = {
    &#39;n_estimators&#39;: [100,200,1000],
    &#39;最大深度&#39;: [10,20,30],
    &#39;min_samples_split&#39;:[2,5,10],
    &#39;min_samples_leaf&#39;:[1,2,4]
}
对于 Y.columns 中的 ing：
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y[ing], test_size=0.2, random_state=52)

    gridModel = make_pipeline(GridSearchCV(估计器=RandomForestRegressor(),cv=10,param_grid=param_grid,n_jobs=-1,scoring=&#39;neg_mean_squared_error&#39;,verbose=True))
    gridModel.fit(X_train,Y_train)
    y_pred_train = gridModel.predict(X_train)
    
    train_mse_error =mean_squared_error(y_pred=y_pred_train,y_true=Y_train)
    train_mse_absoulte_error = Mean_absolute_error(y_pred=y_pred_train,y_true=Y_train)
    train_r2_score = r2_score(y_pred=y_pred_train,y_true=Y_train)
    train_rmse = train_mse_error ** (0.5)
    
    y_pred = gridModel.predict(X_test)
    test_mse_error =mean_squared_error(y_pred=y_pred,y_true=Y_test)
    test_mse_absoulte_error = Mean_absolute_error(y_pred=y_pred,y_true=Y_test)
    test_r2_score = r2_score(y_pred=y_pred,y_true=Y_test)
    test_rmse = test_mse_error ** (0.5)
    resDf.loc[ing] = [train_r2_score,test_r2_score,train_mse_error,test_mse_error,train_rmse,test_rmse,train_mse_absoulte_error,test_mse_absoulte_error]

结果如下：
FirstPartResult
第二部分结果
问题是有时我不明白结果。我的理解是我的模型过度拟合，因为在每一行中，测试集上的分数和错误都高于训练集上的分数和错误。但有些行我不明白。 VitaminA 在训练集上有很好的 r2 分数，但在测试集上很差（对我来说，这是过度拟合）。
但是训练集和测试集的 RMSE 都非常高。
同样令人困惑的是“schwefel”。它在训练集上的 r2score 很差，在测试集上的得分也很糟糕。但我在系统中看不到为什么会得到这些结果。
问题是特征还是目标有时范围很大？]]></description>
      <guid>https://stackoverflow.com/questions/78435762/why-is-this-model-peforming-on-some-targets-well-but-on-some-not</guid>
      <pubDate>Mon, 06 May 2024 09:34:58 GMT</pubDate>
    </item>
    <item>
      <title>指导法学硕士 - 从文本中错误地提取数据继续</title>
      <link>https://stackoverflow.com/questions/78435586/instruct-llms-extract-data-from-text-wrongly-continues</link>
      <description><![CDATA[我正在尝试微调开源 LLM，现在让我们继续使用 Mistral-7b-instruct 模型。
我的任务如下：我有代表“价格请求”的电子邮件对于我们的客户发送的货物。
客户在邮件中告诉我们取货地址、发货人、收货人等信息。
我最初的想法是使用 DORA 训练不同的适配器，每个适配器都接受从电子邮件中提取不同实体的训练。
我的数据集创建如下：我有电子邮件和注释“基于电子邮件，我找到了这个[ENTITY]：entity_here”
我已经创建了一条系统消息，并使用 chat_template 以 Mistral 接受的方式创建数据集，使用此 chat_template：
“{%- for messages in messages %}”
  “{%- if message[&#39;角色&#39;] == &#39;系统&#39;-%}”
      ”{{- &#39;&#39; + 消息[&#39;内容&#39;] -}}”
  “{%-else-%}”
      “{%- if message[&#39;角色&#39;] == &#39;用户&#39;-%}”
          “{{-&#39;[INST]&#39; + message[&#39;content&#39;].rstrip() + &#39;[/INST]&#39;-}}”
      “{%-else-%}”
          ”{{-&#39;&#39; + 消息[&#39;内容&#39;] + &#39;&#39; -}}”
      “{%-endif-%}”
  “{%-endif-%}”
“{%-endfor-%}”
“{%- if add_ Generation_prompt -%}”
    “{{-&#39;&#39;-}}”
“{%-endif-%}”

现在解决问题了。该模型似乎了解了需要提取的内容，它生成了不错的答案，其格式与训练它的助手相同，问题是在生成答案后，它不断生成与电子邮件无关的附加文本到任务，E.G. “请联系我们......”
例如，当我针对同一任务微调 GPT3.5 时，模型能够准确提取我需要的内容，这表明我做错了什么。
有人对我哪里出错有建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435586/instruct-llms-extract-data-from-text-wrongly-continues</guid>
      <pubDate>Mon, 06 May 2024 09:01:03 GMT</pubDate>
    </item>
    <item>
      <title>向 Python Streamlit 饮食推荐应用程序添加饮食偏好按钮 [关闭]</title>
      <link>https://stackoverflow.com/questions/78433479/adding-dietary-preference-button-to-python-streamlit-diet-recommendation-app</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78433479/adding-dietary-preference-button-to-python-streamlit-diet-recommendation-app</guid>
      <pubDate>Sun, 05 May 2024 19:19:19 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    </channel>
</rss>