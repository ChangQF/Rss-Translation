<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 23 May 2024 21:13:50 GMT</lastBuildDate>
    <item>
      <title>时间序列相关回归中的数据泄漏</title>
      <link>https://stackoverflow.com/questions/78525482/data-leakage-in-time-series-related-regression</link>
      <description><![CDATA[我有一个包含解释变量值和目标变量的数据集。它们都是不同的历史日常值。 X 是不同的经济指标，Y 是债券收益率的前瞻性变化。因此，对于第 N 天，X 是当前失业率和通货膨胀率，Y 是 (yield_n+3 / Yield_n) - 1，这是 3 天的变化。
我的问题是，如果我稍后使用 sklearn 中的 train_test_split，我可以打开 shuffle = True 吗？
我知道对于典型的时间序列回归，这将导致数据泄漏，但在这里我不使用 Y 的过去值，也不使用任何滞后。
理论上，我想对数据进行洗牌，因为从我所看到的来看，X 和 Y 之间的关系会随着时间的推移而变化，所以如果我仅根据较早和较晚的日期分割数据，我担心我会训练模型稍微过时的值。
顺便说一句，我使用梯度提升作为我的模型
那么，我可以在我的情况下使用 shuffle = True 吗？如果是，哪些附加功能可能导致泄漏：滞后、季节性影响或其他因素？]]></description>
      <guid>https://stackoverflow.com/questions/78525482/data-leakage-in-time-series-related-regression</guid>
      <pubDate>Thu, 23 May 2024 20:43:46 GMT</pubDate>
    </item>
    <item>
      <title>Mediapipe 培训数据</title>
      <link>https://stackoverflow.com/questions/78525263/data-for-mediapipe-training</link>
      <description><![CDATA[嘿，大家好，我希望这里有人参与过 mediapipe 框架的图像/视频培训。
我正在尝试向媒体管道框架提供尽可能多的图片，但我发现从各个角度制作人物图片以从人们那里获取数据非常累人。
我还没有尝试媒体管道的视频训练，因为我讨厌它剪切视频。
举个例子，我想训练演习小队，所以我需要三个州来组建一个小队

站立
小队下线
小分队

对于每一个状态，我都需要大量的训练数据来喂养人工智能，否则它不会计算我的运动。
所以我向你们提出的问题如下。
从动作中获取尽可能多的图片而不浪费太多时间的最佳方法是什么。
拍摄曼努埃尔的照片，但我意识到这会花费多少时间]]></description>
      <guid>https://stackoverflow.com/questions/78525263/data-for-mediapipe-training</guid>
      <pubDate>Thu, 23 May 2024 19:45:15 GMT</pubDate>
    </item>
    <item>
      <title>Logistic reg 预测同一类</title>
      <link>https://stackoverflow.com/questions/78524770/logistic-reg-predicting-the-same-class</link>
      <description><![CDATA[所以我从头开始创建了一个逻辑回归模型，它工作得很好，但问题是它每次都会预测同一个类，有时它会预测其他类，但这种情况非常罕见
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt


逻辑回归类：
    def __init__(self, *, lr=0.01, n_epochs=1000, verbose=False):
        self.lr = lr
        self.n_epochs = n_epochs
        self.verbose = 详细

    def 初始化（自身，形状，n_class）：
        _, 列 = 形状
        w = np.random.randn(n_class, 列数 + 1) * 0.01
        返回w

    def _inverse_mapper（自身，y_mapped）：
        inverse_mapper = {v: k for k, v in self.mapper.items()}
        返回 np.vectorize(inverse_mapper.get)(y_mapped)

    def _mapper（自身，y）：
        矢量化映射 = np.vectorize(self.mapper.get)
        返回向量化映射（y）

    def _get_mapper（自我，y）：
        self.unique = np.unique(y)
        self._range = np.arange(len(self.unique))
        返回 dict(zip(self.unique, self._range))

    def _one_hot(自我, y):
        n_rows = y.shape[0]
        n_class = len(np.unique(y))
        one_hot = np.zeros((n_rows, n_class))
        one_hot[np.arange(len(y)), y.ravel()] = 1
        返回 one_hot

    def _vec_o​​h(自身，y)：
        self.mapper = self._get_mapper(y)
        y_mapped = self._mapper(y)
        y_oh = self._one_hot(y_mapped)
        返回 y_oh, y_mapped

    def softmax(自身, X):
        z = np.dot(X, self.w.T)
        pk = np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)
        返回PK

    def Predict_proba(自身, X):
        X_added_ones = self.addOnes(X)
        返回 self.softmax(X_added_ones)

    def addOnes(self, X):
        行，_ = X.shape
        个= np.ones((行, 1))
        返回 np.hstack((ones, X))

    def _cost(自身, y, preds):
        返回-np.mean(np.sum(y * np.log(preds + 1e-9), axis=1))

    def _init_data(自身, X, y):
        n_class = len(np.unique(y))
        self.w = self.initialize(X.shape, n_class)
        y_oh, _ = self._vec_o​​h(y)
        返回 y_oh

    def grad_desc(自身, X, y):
        m = X.shape[0]
        y_oh = self._init_data(X, y)

        对于范围内的纪元（self.n_epochs）：
            X_added_ones = self.addOnes(X)
            pk = self.softmax(X_added_ones)
            误差 = pk - y_oh
            w_gradient = np.dot(X_added_ones.T, 错误) / m
            self.w -= self.lr * w_gradient

            如果 self.verbose 和 epoch % 100 == 0:
                损失 = self._cost(y_oh, pk)
                print(f&quot;纪元 {epoch}: 损失 = {损失}&quot;)

    def fit(自身, X, y):
        X = np.array(X)
        y = np.array(y)
        self.grad_desc(X, y)

    def 预测（自身，X）：
        概率 = self.predict_proba(X)
        Predictions_encoded = np.argmax（概率，轴= 1）
        预测 = self._inverse_mapper(predictions_encoded)
        返回预测

我尝试更改公式，但这似乎不起作用我尝试更改渐变似乎根本不起作用我根本不知道问题是什么]]></description>
      <guid>https://stackoverflow.com/questions/78524770/logistic-reg-predicting-the-same-class</guid>
      <pubDate>Thu, 23 May 2024 17:44:42 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[当我尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我认为问题不在于我的代码，而在于库冲突，但我不确定。
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler #actually scikit-learn
from imblearn.over_sampling import RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
X = dataframe[dataframe.columns[:-1]].values
Y = dataframe[dataframe.columns[-1]].values

scaler = StandardScaler() 
X = scaler.fit_transform(X) 

if oversample:
ros = RandomOverSampler()
X, Y = ros.fit_resample(X,Y) 
data = np.hstack((X, np.reshape(Y, (-1, 1))))
返回数据，X，Y

print(len(train[train[&quot;class&quot;]==1]))
print(len(train[train[&quot;class&quot;]==0]))

train, X_train, Y_train = scale_dataset(train, True)

我尝试完全导入 sklearn，卸载并重新安装 scipi 和 sklearn（作为 scikit-learn），安装 Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>文本分类最新模型</title>
      <link>https://stackoverflow.com/questions/78524470/text-classification-latest-models</link>
      <description><![CDATA[我正在寻找构建一个文本多标签分类器，并且需要一些有关最佳模型的帮助或建议。您能为这项任务推荐一些有效的模型吗？我对大型语言模型 (LLM) 和传统模型都感兴趣。
预先感谢您的建议！]]></description>
      <guid>https://stackoverflow.com/questions/78524470/text-classification-latest-models</guid>
      <pubDate>Thu, 23 May 2024 16:28:40 GMT</pubDate>
    </item>
    <item>
      <title>使用 VS Code 上的 computervision + yolov8 应用程序进行实时网络摄像头数据分类</title>
      <link>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</guid>
      <pubDate>Thu, 23 May 2024 15:57:14 GMT</pubDate>
    </item>
    <item>
      <title>图像分类中的融合特征向量？</title>
      <link>https://stackoverflow.com/questions/78523862/fuse-feature-vector-in-image-classification</link>
      <description><![CDATA[目前，我正在处理一个关于面部情感分类的图像分类问题。我使用 2 种提取方法：HOG 和面部地标。我的想法是使用 HOG 来查找图像的梯度大小和方向，并使用面部标志来查找面部关键点。我想我可以融合两种方法来制作更好的功能。但新特征比 HOG 差，比面部特征点好（评估相同模型）。我有一个问题：

我想知道如何融合这两种方法，其中 HOG 归一化之前和面部标志返回 68x2 对点整数。

如果可以，我应该在熔断之前进行正常化或其他操作吗？我可以尝试哪种方法来融合它们（连接、加法、乘法……）？

有没有办法衡量我的方法会更好或评估它？我也尝试融合 HOG 和 SIFT（视觉词袋）。


我曾尝试融合 HOG 和 Facial Landmark 功能，但在同一模型中，它比 HOG 更差，但比 Facial Landmark 更好。我还融合了（SIFT）视觉词袋和 HOG，但它仍然比 HOG 差，但比视觉词袋好。这是我使用的代码：
x_hogp_train = pca.transform(x_hog_train)[:,:382]
x_hogp_valid = pca.transform(x_hog_valid)[:,:382]
x_hogp_test = pca.transform(x_hog_test)[:,:382]

scaler = StandardScaler() # 缩放 bovw 特征
缩放器.fit(x_bovw_train)
x_scale_bovw_train = 缩放器.transform(x_bovw_train)
x_scale_bovw_valid = 缩放器.transform(x_bovw_valid)
x_scale_bovw_test = 缩放器.transform(x_bovw_test)

# 使用 concat 融合它们
x_fused_train = np.concatenate((x_hogp_train, x_scale_bovw_train), axis=1)
x_fused_valid = np.concatenate((x_hogp_valid, x_scale_bovw_valid), axis=1)
x_fused_test = np.concatenate((x_hogp_test, x_scale_bovw_test), axis=1)

]]></description>
      <guid>https://stackoverflow.com/questions/78523862/fuse-feature-vector-in-image-classification</guid>
      <pubDate>Thu, 23 May 2024 14:35:09 GMT</pubDate>
    </item>
    <item>
      <title>我使用 K 均值对图像中的颜色进行聚类。当使用 matplotlib 中的 imshow() 进行重建时，绘图为空白</title>
      <link>https://stackoverflow.com/questions/78522757/i-used-k-means-to-cluster-the-colors-in-my-image-when-use-imshow-from-matplot</link>
      <description><![CDATA[我在kaggle上运行以下代码
img = imread(“/kaggle/input/image-segmentation/ladybug.png”)
x = img.reshape(-1, 3)
kmeans = KMeans(n_clusters=8, random_state=42).fit(x)
segmented_img = kmeans.cluster_centers_[kmeans.labels_]
Segmented_img = Segmented_img.reshape(img.shape)
图 = plt.figure()
ax = Fig.add_subplot(1,2,1)
斧头.imshow(img)

ax = Fig.add_subplot(1,2,2)
ax.imshow(segmented_img)

我得到这个输出。请告诉我为什么我没有获得分割图像。
]]></description>
      <guid>https://stackoverflow.com/questions/78522757/i-used-k-means-to-cluster-the-colors-in-my-image-when-use-imshow-from-matplot</guid>
      <pubDate>Thu, 23 May 2024 11:19:11 GMT</pubDate>
    </item>
    <item>
      <title>如何确定FastText模型在文本分类中的准确性？</title>
      <link>https://stackoverflow.com/questions/78518695/how-to-find-accuracy-of-fasttext-model-in-text-classification</link>
      <description><![CDATA[在机器学习中，所有模型都有准确度方程，而在 FastText 模型中，我们没有请支持。]]></description>
      <guid>https://stackoverflow.com/questions/78518695/how-to-find-accuracy-of-fasttext-model-in-text-classification</guid>
      <pubDate>Wed, 22 May 2024 15:50:57 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型的小批量实现的奇怪绘图模式</title>
      <link>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</guid>
      <pubDate>Sun, 19 May 2024 19:05:35 GMT</pubDate>
    </item>
    <item>
      <title>我无法从“typing_extensions”导入名称“TypeAliasType”</title>
      <link>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</link>
      <description><![CDATA[我是 Python 新手，发现了以下类似错误。我非常感谢您的评论。谢谢
我尝试将 Gradio 库导入为 gr
我已经尝试了一些现有的建议，但结果都是徒劳的。我不知道该怎么办]]></description>
      <guid>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</guid>
      <pubDate>Thu, 09 Nov 2023 03:38:10 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未知层：“CustomScaleLayer”。请确保您使用的是`keras.utils.custom_object_scope`</title>
      <link>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</guid>
      <pubDate>Fri, 16 Jun 2023 09:13:29 GMT</pubDate>
    </item>
    <item>
      <title>如何安装 model_evaluation_utils</title>
      <link>https://stackoverflow.com/questions/58693134/how-to-install-model-evaluation-utils</link>
      <description><![CDATA[我正在尝试通过模型评估我们深度学习模型的性能。下面是我的代码。不过，我还是明白

&lt;块引用&gt;
  没有名为“model_evaluation_utils”的模块

是否有任何 pip 安装或 conda 可以解决此问题？
from keras.preprocessing.image import load_img, img_to_array, array_to_img
从 keras.models 导入 load_model
import model_evaluation_utils as meu # 抛出错误
]]></description>
      <guid>https://stackoverflow.com/questions/58693134/how-to-install-model-evaluation-utils</guid>
      <pubDate>Mon, 04 Nov 2019 12:05:28 GMT</pubDate>
    </item>
    <item>
      <title>SVC 分类器花费太多时间进行训练</title>
      <link>https://stackoverflow.com/questions/53940258/svc-classifier-taking-too-much-time-for-training</link>
      <description><![CDATA[我正在使用带有线性核的 SVC 分类器来训练我的模型。
训练数据：42000 条记录
 model = SVC(probability=True)
model.fit(self.features_train, self.labels_train)
y_pred = model.predict(self.features_test)
train_accuracy = model.score(self.features_train,self.labels_train)
test_accuracy = model.score(self.features_test, self.labels_test)

训练我的模型需要 2 个多小时。
我做错了什么吗？
此外，可以做些什么来缩短时间
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/53940258/svc-classifier-taking-too-much-time-for-training</guid>
      <pubDate>Thu, 27 Dec 2018 05:43:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在多元/三维中实现核密度估计</title>
      <link>https://stackoverflow.com/questions/30696741/how-to-implement-kernel-density-estimation-in-multivariate-3d</link>
      <description><![CDATA[我有类似以下 fromat 的数据集，我试图找出具有最佳带宽的内核密度估计。 
data = np.array([[1, 4, 3], [2, .6, 1.2], [2, 1, 1.2],
         [2, 0.5, 1.4], [5, .5, 0], [0, 0, 0],
         [1, 4, 3], [5, .5, 0], [2, .5, 1.2]])

但我不知道如何处理它。以及如何找到Σ矩阵。 
更新
我尝试使用 scikit-learn 工具包中的 KDE 函数来找出单变量（1D）kde，
# kde 函数
def kde_sklearn(x, x_grid, 带宽):
    kde = KernelDensity(kernel=&#39;高斯&#39;, 带宽=带宽).fit(x)
    log_pdf = kde.score_samples(x_grid[:, np.newaxis])
    返回 np.exp(log_pdf)

# 最优带宽选择
从 sklearn.grid_search 导入 GridSearchCV
grid = GridSearchCV(KernelDensity(), {&#39;带宽&#39;: np.linspace(.1, 1.0, 30)}, cv=20)
网格.fit(x)
bw = grid.best_params_

# 使用 kde 生成 pdf
pdf = kde_sklearn(x, x_grid, bw)
ax.plot(x_grid, pdf, label=&#39;bw={}&#39;.format(bw))
ax.legend(loc=&#39;最佳&#39;)
plt.show()

任何人都可以帮助我将其扩展到多元/在本例中为 3D 数据吗？]]></description>
      <guid>https://stackoverflow.com/questions/30696741/how-to-implement-kernel-density-estimation-in-multivariate-3d</guid>
      <pubDate>Sun, 07 Jun 2015 18:00:35 GMT</pubDate>
    </item>
    </channel>
</rss>