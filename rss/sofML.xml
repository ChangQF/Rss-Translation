<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 21 Sep 2024 15:17:45 GMT</lastBuildDate>
    <item>
      <title>X 有 8 个特征，但 RandomForestRegressor 需要 2924 个特征作为输入</title>
      <link>https://stackoverflow.com/questions/79009698/x-has-8-features-but-randomforestregressor-is-expecting-2924-features-as-input</link>
      <description><![CDATA[这看起来可能真的微不足道，但我就是不明白这个问题。所以基本上，我正在使用 Kaggle 数据集和 RandomForestRegressor 为我的城市构建一个餐厅推荐器。
我建立了模型，现在想让模型在给定 4 个参数时推荐一家好餐厅：位置、大概费用、餐厅类型和投票数。但是，它返回了一个值错误：X 有 8 个特征，但 RandomForestRegressor 需要 2924 个特征作为输入。
这是我尝试运行的：
import joblib
import numpy as np
from sklearn.preprocessing import StandardScaler

model = joblib.load(&#39;my_model.pkl&#39;)
scaler = joblib.load(&#39;scaler.pkl&#39;)

def preprocess_input(location, type_, cost, votes):
one_hot_location = [1 if loc == location else 0 for loc in [&#39;Whitefield&#39;, &#39;Koramangala&#39;, &#39;Indiranagar&#39;]]
one_hot_type = [1 if t == type_ else 0 for t in [&#39;Casual Dining&#39;, &#39;Quick Bites&#39;, &#39;Cafe&#39;]]

scaled_features = scaler.transform([[cost, votes]])

return np.array(one_hot_location + one_hot_type + list(scaled_features[0])).reshape(1, -1)

input_data = preprocess_input(&#39;Whitefield&#39;, &#39;Casual Dining&#39;, 1000, 500)

prediction = model.predict(input_data)

print(f&quot;预测的餐厅：{prediction}&quot;)


训练数据的形状：
X_train.shape = (41373, 2924)
y_train.shape = (41373,)
这是我的数据集的样子
我是这方面的新手，请帮帮我！]]></description>
      <guid>https://stackoverflow.com/questions/79009698/x-has-8-features-but-randomforestregressor-is-expecting-2924-features-as-input</guid>
      <pubDate>Sat, 21 Sep 2024 13:43:40 GMT</pubDate>
    </item>
    <item>
      <title>我的非序列 keras 模型的一个输入出现了难以理解的形状错误</title>
      <link>https://stackoverflow.com/questions/79009687/incomprehensible-shape-error-with-one-of-the-inputs-of-my-non-sequential-keras-m</link>
      <description><![CDATA[我编写了以下 keras 模型
input_A = 输入(shape=[5], name=&quot;wide_input&quot;)
hidden_​​layer_1 = Dense(10,activation=&quot;relu&quot;, name=&#39;h_wide_layer&#39;)(input_A)
input_B = 输入(shape=[6], name=&quot;deep_input&quot;)
hidden_​​layer_2 = Dense(30,activation=&quot;relu&quot;, name=&#39;h_deep_layer_1&#39;)(input_B)
hidden_​​layer_3 = Dense(30,activation=&quot;relu&quot;, name=&#39;h_deep_layer_2&#39;)(hidden_​​layer_2)
concat = Concatenate()([hidden_​​layer_1, hidden_​​layer_3])
output = Dense(1, name=&quot;output&quot;)(concat)
complex_model_2_1 = keras.Model(inputs=[input_A, input_B], output=[output])

#编译第二个复杂模型
complex_model_2_1.compile(loss=&quot;mean_squared_error&quot;, optimizer=&quot;sgd&quot;)

#训练
X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]
X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]
X_test_A, X_test_B = X_test_full[:, :5], X_test_full[:, 2:]
X_new_A, X_new_B = X_new[:, :5], X_new[:, 2:]
print(f&quot;X_train_A 的形状：{X_train_A.shape}&quot;)
print(f&quot;X_train_B 的形状：{X_train_B.shape}&quot;)
history = complex_model_2_1.fit({&quot;wide_input&quot;: X_train_A, &quot;deep_input&quot;: X_train_B},
y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))

# 评估模型
mse_test_complex_2_1 = complex_model_2_1.evaluate((X_test_A, X_test_B), y_test_full)

# 预测前三套房子价格
y_pred_complex_2_1 = complex_model_2_1.predict((X_new_A, X_new_B))

X_train 有 8 个特征，因此 X_train_A 和 X_train_B 实际上分别有 5 个和 6 个特征。但是，我不明白为什么我会得到下面的 hidden_​​layer_2 不兼容形状错误：
ValueError Traceback (most recent call last)
&lt;ipython-input-42-86b1419058f7&gt; in &lt;cell line: 11&gt;()
9 print(f&quot;Shape of X_train_A: {X_train_A.shape}&quot;)
10 print(f&quot;Shape of X_train_B: {X_train_B.shape}&quot;)
---&gt; 11 history = complex_model_2_1.fit({&quot;wide_input&quot;: X_train_A, &quot;deep_input&quot;: X_train_B},
12 y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))
13 

1 帧
/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py in assert_input_compatibility(input_spec, input, layer_name)
225 无,
226 }:
--&gt; 227 raise ValueError(
228 f&#39;层“{layer_name}”的输入 {input_index} 是 &#39;
229 f“与层不兼容：预期轴 {axis}”

ValueError：调用 Functional.call() 时遇到异常。

层“h_deep_layer_1”的输入 0 与层不兼容：预期输入形状的轴 -1 具有值 6，但收到的输入形状为 (None, 5)

Functional.call() 收到的参数：
• 输入={&#39;wide_input&#39;: &#39;tf.Tensor(shape=(None, 5), dtype=float32)&#39;, &#39;deep_input&#39;: &#39;tf.Tensor(shape=(None, 6), dtype=float32)&#39;}
• 训练=True
• 掩码={&#39;wide_input&#39;: &#39;None&#39;, &#39;deep_input&#39;: &#39;None&#39;}

有人能帮我修复它吗？
PS：Google colab 中的 Gemini 无法解释该问题，并向我提出了 X_train_B = X_train[:, 5:]，这是不正确的（形状为 (_, 3)]]></description>
      <guid>https://stackoverflow.com/questions/79009687/incomprehensible-shape-error-with-one-of-the-inputs-of-my-non-sequential-keras-m</guid>
      <pubDate>Sat, 21 Sep 2024 13:38:38 GMT</pubDate>
    </item>
    <item>
      <title>对 GPT 架构感到失望 [关闭]</title>
      <link>https://stackoverflow.com/questions/79009482/disappoint-at-gpt-architecture</link>
      <description><![CDATA[我是NLP的新手，读过一些该领域的经典论文。读完GPT-2后，我感到很失望，因为它只是将Decoder堆叠了多层，并使用大量数据进行训练。
说实话，Transformer架构给我留下了深刻的印象。GPT-2释放了一个信号，它只需要在更大的模型上训练更多的数据，就可以获得良好的性能。
我还没有读过关于最近模型的论文，你们能给我一些提示吗，现在的LLM是否只是一场由资源控制的游戏？有什么有趣的论文可以阅读吗？
我会阅读更多关于这个主题的论文并有一个整体的了解。]]></description>
      <guid>https://stackoverflow.com/questions/79009482/disappoint-at-gpt-architecture</guid>
      <pubDate>Sat, 21 Sep 2024 11:45:47 GMT</pubDate>
    </item>
    <item>
      <title>为问题和答案生成上下文</title>
      <link>https://stackoverflow.com/questions/79009231/generating-context-for-questions-and-answers</link>
      <description><![CDATA[一般问题概述：
我需要微调问答模型，以便从约 5 页的文档中提取问题的答案，但我只有问题和答案的对，没有上下文。
这些文档是非结构化的文本，每个文档包含约 20 个问题的答案 + 一些不重要的文本。所有文档都有非常相似的主题（它们都是数据管理计划）。问题和答案通常至少有一句话长。
问题和答案示例：

问：项目将生成/收集哪些类型和格式的数据？


答：因此，生成的数据类型和格式列表很长，包括但不限于：格式化/未格式化的文本 Mov MP4 二进制 HDF5 Xlsx Jpg VTK PDB PSF PRMTOP XTC PDF PNG EPS DICOM C3D VTK



问：数据的来源是什么？


答：数据来自许多不同的来源。非模拟数据通常用于构建模型，可以源自临床数据管理系统或 DICOM 图像存储。&quot;


查看更多问题此处（不仅仅是这些问题，但都与此类似）。
可用数据
我的数据集由问题和答案组成（大约 1 万对），我需要生成上下文来微调问答模型。
我还有大约 1000 份未标记的文档，每个文档都有自由文本，每个文本包含大约 20 个问题的答案。我的目标是训练模型，以便从此类文档中提取答案（我有一些带标签的文档，将用于评估，但不足以进行训练）。
问题：
如何通过将我的答案作为输入并用类似于我的目标文档的文本围绕它来生成上下文，同时仍然知道答案在哪里。]]></description>
      <guid>https://stackoverflow.com/questions/79009231/generating-context-for-questions-and-answers</guid>
      <pubDate>Sat, 21 Sep 2024 09:31:00 GMT</pubDate>
    </item>
    <item>
      <title>是否有一种 ML 数据处理参数 getter 和 setter 方法来包装常见的 ML 预处理转换器/块/层？[关闭]</title>
      <link>https://stackoverflow.com/questions/79008906/is-there-a-ml-data-processing-parameter-getter-and-setter-approach-to-wrap-commo</link>
      <description><![CDATA[在机器学习数据预处理管道中，管道步骤通常被序列化或保存为 pickle 或模型中的层，以便稍后可以再次加载它们以进行服务或预测，从而保留从原始训练数据中得出的每个步骤的变换/拟合参数。
为什么没有高级 Python 包装器，而是允许将处理步骤的参数或属性值作为数据返回，从而能够将其保存在数据库中而无需保存整个对象？
这将允许在预测时新创建用于服务/预测的处理步骤，并使用从数据库加载的已保存参数和属性值进行配置。
我找不到任何 Python 库或现有库的包装器（例如 TensorFlow、scikit-learn、PyTorch 等）提供用于管道步骤参数保存和设置的高级 API。
为什么它们不存在？
在我看来，它会很有用为了可移植性和从实现库中抽象出来，以及为了检查和调试处理步骤。
我研究过 sklearn get_attrs 和 set_attrs，但它们变得非常复杂，特别是在使用嵌套转换并需要进行树遍历的情况下。
我是否遗漏了基本概念或其他东西？]]></description>
      <guid>https://stackoverflow.com/questions/79008906/is-there-a-ml-data-processing-parameter-getter-and-setter-approach-to-wrap-commo</guid>
      <pubDate>Sat, 21 Sep 2024 06:31:58 GMT</pubDate>
    </item>
    <item>
      <title>使用 Scikit-learn、XGBoost 和 Prophet 时，保存训练模型的最佳文件格式是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/79008634/what-is-the-best-file-format-to-save-trained-model-when-using-scikit-learn-xgbo</link>
      <description><![CDATA[问题
我正在使用 Scikit-learn 开展 ML 项目。根据我的研究，人们建议使用 .joblib 保存经过训练的 Scikit-learn 模型。
这就是我将模型保存到 .joblib 的方式
import os
from joblib import dump

model_path = os.path.join(script_dir, &quot;../models/trained_model.joblib&quot;)
dump(model, model_path)
print(f&quot;Model saved at {model_path}&quot;)

我还想使用 XGBoost 和 Prophet 测试此模型，只是为了尝试不同的库。

什么是实现此目标的最佳文件格式？我在搜索过程中多次看到 ONNX，但似乎它与 Prophet 不兼容。

有没有办法同时将我的模型保存为 joblib 和 onnx，或者我是否需要将 jobllib 转换为 onnx 文件？


任何最佳实践或建议都会有所帮助！]]></description>
      <guid>https://stackoverflow.com/questions/79008634/what-is-the-best-file-format-to-save-trained-model-when-using-scikit-learn-xgbo</guid>
      <pubDate>Sat, 21 Sep 2024 01:49:12 GMT</pubDate>
    </item>
    <item>
      <title>与其他架构相比，LSTM 为 Apple 的语言识别提供了哪些优势？[关闭]</title>
      <link>https://stackoverflow.com/questions/79008154/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</link>
      <description><![CDATA[既然 LSTM 的强大功能来自其长程依赖性记忆，那么为什么我们要使用 LSTM 而不是其他架构来从短文本字符串中进行基于字符的语言识别 (LID)？
例如，Apple 发布了一篇行业博客文章，指出他们使用 biLSTM 进行语言识别：https://machinelearning.apple.com/research/language-identification-from-very-short-strings
然后这篇论文试图复制它：https://aclanthology.org/2021.eacl-srw.6/
我在阅读 Karpathy 关于 RNN 的著名文章时，尝试训练一个小型语言识别模型进行练习。我首先尝试了一种简单、直观（对我来说）的方法：使用 tf-idf，使用在训练数据中的双或三元计数上训练的朴素贝叶斯分类器。我的数据集包含不同语系的 13 种语言。虽然我的简单分类器确实表现良好，但在查看类似语言时会出错。例如，西班牙语通常被归类为葡萄牙语。
我研究了神经网络架构，发现 LSTM 经常用于语言识别任务。在阅读了有关 RNN 和 LSTM 的内容后，我无法完全理解为什么 LSTM 更适合用于 LID，尤其是短文本字符串。这不是违反直觉的吗，因为 LSTM 擅长记住长距离依赖关系，而 RNN 则不然？对于短文本字符串，我建议使用 vanilla RNN....
Apple 博客确实说过，

在本文中，我们探讨了如何通过将其视为字符级别的序列标记问题，并使用在短字符序列上训练的双向长短期记忆 (bi-LSTM) 神经网络来提高 LID 准确性。

我觉得我没有理解这里的一些基本知识。
那么，他们的 LSTM 的学习目标是否是正确分类给定的字符 n-gram？这就是他们所说的“序列标记”问题吗？序列标记任务的根本难道不就是分类任务吗（“用 N 个预定义标签中的 1 个标记来自测试集的给定输入”）？
当您使用已知可以处理长序列的架构时，在短字符序列上训练 LSTM 有什么意义？]]></description>
      <guid>https://stackoverflow.com/questions/79008154/what-advantage-do-lstms-provide-for-apples-language-identification-over-other-a</guid>
      <pubDate>Fri, 20 Sep 2024 20:18:48 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 Imagecaption 模型虽然没有过度拟合且损失很低，但性能却很差？[关闭]</title>
      <link>https://stackoverflow.com/questions/79006661/why-does-my-imagecaption-model-perform-poorly-even-though-it-is-not-overfitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79006661/why-does-my-imagecaption-model-perform-poorly-even-though-it-is-not-overfitting</guid>
      <pubDate>Fri, 20 Sep 2024 12:03:50 GMT</pubDate>
    </item>
    <item>
      <title>从 Colab 获取不相关的响应</title>
      <link>https://stackoverflow.com/questions/79006597/getting-irrelevant-responses-from-the-colab</link>
      <description><![CDATA[我正在使用“Bringing-Old-Photos-Back-to-Life”存储库 colab。
但它运行整个存储库，并且没有在划痕图像上显示实际生成的图像。
GitHub Repo
示例图像附在下面：
左图为原始图像，右图由模型生成
我期待有人指导如何改进它。]]></description>
      <guid>https://stackoverflow.com/questions/79006597/getting-irrelevant-responses-from-the-colab</guid>
      <pubDate>Fri, 20 Sep 2024 11:44:27 GMT</pubDate>
    </item>
    <item>
      <title>网页抓取问题：从网站提取干净数据 [关闭]</title>
      <link>https://stackoverflow.com/questions/79005517/issues-with-web-scraping-extracting-clean-data-from-websites</link>
      <description><![CDATA[问题：
我正在开展一个网页抓取项目，旨在从网站中提取干净、结构化的数据，以进一步丰富检索增强生成 (RAG) 模型。虽然我已经成功抓取并处理了 YouTube 转录本，但在抓取网站数据时我仍面临挑战。
我的方法：

使用的技术：

用于动态内容呈现的 Selenium
用于解析和提取 HTML 内容的 BeautifulSoup
用于过滤不需要的模式和噪音的 Regex 和 NLTK


我已采取的步骤：

删除了 &lt;script&gt;、&lt;style&gt; 等不属于主要内容的 HTML 元素。
使用正则表达式模式过滤掉不相关的数据，例如日期、电子邮件地址和 URL。
应用了 NLTK停用词来进一步清理文本。


代码片段：
这是我的 BeautifulSoup 抓取工具的一个示例：
from bs4 import BeautifulSoup
import request
import re
from nltk.corpus import stopwords

stop_words = set(stopwords.words(&#39;english&#39;))

class BeautifulSoupScraper:
@staticmethod
def extract_text_from_url(url):
response = request.get(url)
soup = BeautifulSoup(response.text, &#39;html.parser&#39;)

# 删除不需要的元素
for unwanted in soup([&#39;script&#39;, &#39;style&#39;, &#39;header&#39;, &#39;footer&#39;, &#39;nav&#39;, &#39;aside&#39;, &#39;form&#39;]):
unwanted.decompose()

段落 = soup.find_all(&#39;p&#39;)
文本 = &quot;\n&quot;.join([para.get_text() for para in 段落])
返回文本

@staticmethod
def filter_text(text):
# 删除不需要的模式（例如 URL、日期等）
unwanted_pa​​tterns = [r&#39;http[s]?://\S+&#39;, r&#39;\b\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\b&#39;]
for pattern in unwanted_pa​​tterns:
文本 = re.sub(pattern, &#39;&#39;, text)
返回 &#39; &#39;.join([word for word in text.split() if word.lower() not in stop_words])

我还使用 Selenium 动态收集搜索结果：
from selenium import webdriver
来自 selenium.webdriver.common.by import By

class GoogleSearch:
@staticmethod
def search(keyword, num_results=5):
driver = webdriver.Chrome()
driver.get(f&quot;https://www.google.com/search?q={keyword}&quot;)
elements = driver.find_elements(By.CLASS_NAME, &quot;MjjYud&quot;)[:num_results]
links = [element.find_element(By.TAG_NAME, &#39;a&#39;).get_attribute(&#39;href&#39;) for element in elements]
driver.quit()
return links



问题：
尽管使用 BeautifulSoup 和正则表达式过滤掉不需要的数据，但提取的内容中仍然有很多噪音，尤其是来自评论部分、广告和其他不相关的内容网页的部分。我的目标是干净地提取有意义的文本（例如，博客内容、文章文本），而不产生这些噪音。
我尝试过的方法：

使用正则表达式删除日期、URL 和电子邮件地址等常见模式。
使用 NLTK 删除停用词。
按关键字过滤（例如，“订阅”、“评论”），但这仍然会留下不需要的网页部分。

我需要的方法：

改进过滤过程的最佳实践或建议，尤其是删除网页中不相关的部分。
除了正则表达式和基本停用词过滤之外，还有更有效的清理抓取数据的方法的建议。
在处理不同类型的网站时，有没有关于如何使提取过程更准确、无噪音的建议结构。
]]></description>
      <guid>https://stackoverflow.com/questions/79005517/issues-with-web-scraping-extracting-clean-data-from-websites</guid>
      <pubDate>Fri, 20 Sep 2024 06:34:55 GMT</pubDate>
    </item>
    <item>
      <title>无法从 Pytorch Dataset 的 __get_item__ 返回布尔变量</title>
      <link>https://stackoverflow.com/questions/79000230/unable-to-return-a-boolean-variable-from-pytorch-datasets-get-item</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79000230/unable-to-return-a-boolean-variable-from-pytorch-datasets-get-item</guid>
      <pubDate>Wed, 18 Sep 2024 21:33:47 GMT</pubDate>
    </item>
    <item>
      <title>Optuna Hyperband 算法不遵循预期的模型训练方案</title>
      <link>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</link>
      <description><![CDATA[我在 Optuna 中使用 Hyperband 算法时发现了一个问题。根据 Hyperband 算法，当 min_resources = 5、ma​​x_resources = 20 和 reduction_factor = 2 时，搜索应从 1 组别的 4 个模型的初始空间开始，每个模型在第一轮中接收 5 个 epoch。随后，模型数量在每一轮中减少 2 倍，搜索空间也应在下一组的 2 倍减少，即组别 2 的初始搜索空间为 2 个模型，其余模型的 epoch 数量在随后的每一轮中加倍。因此预计总模型数应为 11，但需要训练大量模型。
文章链接：- https://arxiv.org/pdf/1603.06560.pdf
import optuna
import numpy as np
import pandas as pd 
from tensorflow.keras.layers import Dense,Flatten,Dropout
import tensorflow as tf
from tensorflow.keras.models import Sequential

# 玩具数据集生成
def generate_toy_dataset():
np.random.seed(0)
X_train = np.random.rand(100, 10)
y_train = np.random.randint(0, 2, size=(100,))
X_val = np.random.rand(20, 10)
y_val = np.random.randint(0, 2, size=(20,))
return X_train, y_train, X_val, y_val

X_train, y_train, X_val, y_val = generate_toy_dataset()

# 模型构建函数
def build_model(trial):
model = Sequential()
model.add(Dense(units=trial.suggest_int(&#39;unit_input&#39;, 20, 30),
activation=&#39;selu&#39;,
input_shape=(X_train.shape[1],)))

num_layers = trial.suggest_int(&#39;num_layers&#39;, 2, 3)
for i in range(num_layers):
units = trial.suggest_int(f&#39;num_layer_{i}&#39;, 20, 30)
activation = trial.suggest_categorical(f&#39;activation_layer_{i}&#39;, [&#39;relu&#39;, &#39;selu&#39;, &#39;tanh&#39;])
model.add(Dense(units=units,activation=activation))
如果 trial.suggest_categorical(f&#39;dropout_layer_{i}&#39;, [True, False]):
model.add(Dropout(rate=0.5))

model.add(Dense(1,activation=&#39;sigmoid&#39;))

optimizer_name = trial.suggest_categorical(&#39;optimizer&#39;, [&#39;adam&#39;, &#39;rmsprop&#39;])
如果 optimizer_name == &#39;adam&#39;:
optimizer = tf.keras.optimizers.Adam()
否则:
optimizer = tf.keras.optimizers.RMSprop()

model.compile(optimizer=optimizer, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;, tf.keras.metrics.AUC(name=&#39;val_auc&#39;)])

return model

def objective(trial):
model = build_model(trial)
# 假设您已准备好数据
# 修改拟合方法以包含 AUC 指标
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), verbose=1)

# 检查是否记录了“val_auc”
auc_key = None
for key in history.history.keys():
if key.startswith(&#39;val_auc&#39;):
auc_key = key
print(f&quot;auc_key is {auc_key}&quot;)
break

if auc_key is None:
raise ValueError(&quot;历史记录中未找到AUC指标。确保在训练期间记录它。&quot;)

# 报告每个模型的验证 AUC

if auc_key ==&quot;val_auc&quot;:
step=0
else:
step = int(auc_key.split(&#39;_&#39;)[-1])

auc_value=history.history[auc_key][0]
trial.report(auc_value, step=step)
print(f&quot;prune or not:-{trial.should_prune()}&quot;)
if trial.should_prune():
raise optuna.TrialPruned()

return history.history[auc_key]

# Optuna 研究创建
study = optuna.create_study(
direction=&#39;maximize&#39;,
pruner=optuna.pruners.HyperbandPruner(
min_resource=5,
max_resource=20,
reduction_factor=2
)
)

# 开始优化
study.optimize(objective)

]]></description>
      <guid>https://stackoverflow.com/questions/78251318/optuna-hyperband-algorithm-not-following-expected-model-training-scheme</guid>
      <pubDate>Sun, 31 Mar 2024 12:38:07 GMT</pubDate>
    </item>
    <item>
      <title>Python：GridSearchCV 需要很长时间才能完成运行</title>
      <link>https://stackoverflow.com/questions/72101295/python-gridsearchcv-taking-too-long-to-finish-running</link>
      <description><![CDATA[我尝试使用网格搜索来优化我的模型，但执行时间太长了。我的总数据集只有大约 15,000 个观测值，大约有 30-40 个变量。我成功地通过网格搜索运行了一个随机森林，大约花了一个半小时，但现在我已经切换到 SVC，它已经运行了 9 个多小时，但仍然没有完成。下面是我用于交叉验证的代码示例：
from sklearn.model_selection import GridSearchCV
from sklearn import svm
from sklearn.svm import SVC

SVM_Classifier= SVC(random_state=7)

param_grid = {&#39;C&#39;: [0.1, 1, 10, 100],
&#39;gamma&#39;: [1,0.1,0.01,0.001],
&#39;kernel&#39;: [&#39;linear&#39;, &#39;poly&#39;, &#39;rbf&#39;, &#39;sigmoid&#39;],
&#39;degree&#39; : [0, 1, 2, 3, 4, 5, 6]}

grid_obj = GridSearchCV(SVM_Classifier,

return_train_score=True,
param_grid=param_grid,
评分=&#39;roc_auc&#39;,
cv=3,
n_jobs = -1)

grid_fit = grid_obj.fit(X_train, y_train)
SVMC_opt = grid_fit.best_estimator_

print(&#39;=&#39;*20)
print(&quot;best params: &quot; + str(grid_obj.best_estimator_))
print(&quot;best params: &quot; + str(grid_obj.best_params_))
print(&#39;best score:&#39;, grid_obj.best_score_)
print(&#39;=&#39;*20)


我已经将交叉验证从 10 减少到 3，并且我使用 n_jobs=-1，因此我使用了所有核心。我还有什么遗漏的，可以在这里做些事情来加快进程吗？]]></description>
      <guid>https://stackoverflow.com/questions/72101295/python-gridsearchcv-taking-too-long-to-finish-running</guid>
      <pubDate>Tue, 03 May 2022 14:51:20 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ML 模型和 FastAPI 处理来自多个用户的请求？</title>
      <link>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</link>
      <description><![CDATA[我正在研究通过FastAPI分发人工智能模块的过程。
我创建了一个FastAPI应用，使用预先学习的机器学习模型来回答问题。
这种情况下，一个用户使用是没有问题的，但是多个用户同时使用的时候，响应可能会太慢。
那么，当多个用户输入一个问题的时候，有没有办法一次性复制模型并加载进去？
class sentencebert_ai():
def __init__(self) -&gt;无：
super().__init__()

def ask_query(self,query, topN):
startt = time.time()

ask_result = []
score = []
result_value = [] 
embedder = torch.load(model_path)
corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)
query_embedding = embedder.encode(query, convert_to_tensor=True)
cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0] #torch.Size([121])121 表示该数据集为 10 ... cos_scores = cos_scores.cpu() top_results = np.argpartition(-cos_scores, range(topN))[0:topN] for idx in top_results[0:topN]: Ask_result.append(corpusid[idx].item()) #.item()으로 접근하는 Been张量( 5）에서해당숫자에접근하기위한방식다。
            score.append(round(cos_scores[idx].item(),3))

# 生成 json 数组并返回结果
for i,e in zip(ask_result,score):
result_value.append({&quot;pred_id&quot;:i,&quot;pred_weight&quot;:e})
endd = time.time()
print(&#39;结果集&#39;,endd-startt)
return result_value
# return &#39;,&#39;.join(str(e) for e in ask_result),&#39;,&#39;.join(str(e) for e in score)

class Item_inference(BaseModel):
text : str
topN : Optional[int] = 1

@app.post(&quot;/retrieval&quot;, tags=[&quot;knowledge referral&quot;])
async def Knowledge_recommendation(item: Item_inference):

# db.append(item.dict())
item.dict()
results = _ai.ask_query(item.text, item.topN)

return results

if __name__ == &quot;__main__&quot;:
parser = argparse.ArgumentParser()
parser.add_argument(&quot;--port&quot;, default=&#39;9003&#39;, type=int)
# parser.add_argument(&quot;--mode&quot;, default=&#39;cpu&#39;, type=str, help=&#39;cpu for CPU mode, gpu for GPU mode&#39;)
args = parser.parse_args()

_ai = sentencebert_ai()
uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=args.port,workers=4)

更正版本
@app.post(&quot;/aaa&quot;) def your_endpoint(request: Request, item:Item_inference): start = time.time() model = request.app.state.model item.dict() # 测试结果 _ai = sentencebert_ai() results = _ai.ask_query(item.text, item.topN,model) end = time.time() print(end-start) return results ``` 
]]></description>
      <guid>https://stackoverflow.com/questions/71613305/how-to-process-requests-from-multiiple-users-using-ml-model-and-fastapi</guid>
      <pubDate>Fri, 25 Mar 2022 07:13:32 GMT</pubDate>
    </item>
    <item>
      <title>onnxruntime 推理比 GPU 上的 pytorch 慢得多</title>
      <link>https://stackoverflow.com/questions/70740287/onnxruntime-inference-is-way-slower-than-pytorch-on-gpu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/70740287/onnxruntime-inference-is-way-slower-than-pytorch-on-gpu</guid>
      <pubDate>Mon, 17 Jan 2022 11:03:53 GMT</pubDate>
    </item>
    </channel>
</rss>