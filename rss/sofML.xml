<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 17 Dec 2023 06:16:21 GMT</lastBuildDate>
    <item>
      <title>为什么使用 dataloader 来存储训练数据会改变模型的训练？</title>
      <link>https://stackoverflow.com/questions/77673297/why-does-the-usage-of-dataloader-for-train-data-change-the-training-of-the-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673297/why-does-the-usage-of-dataloader-for-train-data-change-the-training-of-the-model</guid>
      <pubDate>Sun, 17 Dec 2023 04:17:54 GMT</pubDate>
    </item>
    <item>
      <title>端到端 ML 项目的模型训练器问题 - TypeError：initiate_model_training() 缺少 4 个必需的位置参数</title>
      <link>https://stackoverflow.com/questions/77673255/model-trainer-issue-on-end-to-end-ml-project-typeerror-initiate-model-trainin</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673255/model-trainer-issue-on-end-to-end-ml-project-typeerror-initiate-model-trainin</guid>
      <pubDate>Sun, 17 Dec 2023 03:50:40 GMT</pubDate>
    </item>
    <item>
      <title>使用神经网络训练数据集时出错</title>
      <link>https://stackoverflow.com/questions/77673218/error-while-training-with-datasets-using-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673218/error-while-training-with-datasets-using-neural-network</guid>
      <pubDate>Sun, 17 Dec 2023 03:24:35 GMT</pubDate>
    </item>
    <item>
      <title>keras.models.load_model("") 在 h5f.open() 上给出错误[关闭]</title>
      <link>https://stackoverflow.com/questions/77673041/keras-models-load-model-gives-error-on-h5f-open</link>
      <description><![CDATA[当使用keras.models.load时，它会在h5f.open(name, flags, fapl=fapl)上抛出错误，并显示OSError: Unable to打开文件（未找到文件签名）。
DNN模型文件代码
随机导入
将 numpy 导入为 np
将张量流导入为 tf
从 keras.layers 导入密集、Dropout
从 keras.models 导入顺序
从 keras.regularizers 导入 l1, l2
从 keras.optimizers 导入 Adam

def set_seeds(种子 = 100):
    随机种子（种子）
    np.随机.种子（种子）
    tf.random.set_seed(种子)
    
def CW(df):
    c0, c1 = np.bincount(df[“dir”])
    w0 = (1/c0) * (len(df)) / 2
    w1 = (1/c1) * (len(df)) / 2
    返回 {0:w0, 1:w1}

优化器 = Adam(lr = 0.0001)

def create_model(hl = 2, hu = 100, dropout = False, 速率 = 0.3, 正则化 = False,
                 reg = l1(0.0005)，优化器 = 优化器，input_dim = 无）：
    如果不正则化：
        reg = 无
    模型=顺序（）
    model.add（密集（hu，input_dim = input_dim，activity_regularizer = reg，activation =“relu”））
    如果辍学：
        model.add(Dropout(速率, 种子 = 100))
    对于范围（hl）内的图层：
        model.add（密集（hu，激活=“relu”，activity_regularizer = reg））
        如果辍学：
            model.add(Dropout(速率, 种子 = 100))
    model.add(Dense(1, 激活 = “sigmoid”))
    model.compile（损失=“binary_crossentropy”，优化器=优化器，指标=[“准确性”]）
    返回模型


加载模型和参数
# 加载模型
导入keras
model = keras.models.load_model(“C:/Users/Hussein Ali/Desktop/d/DNNModel.py”)

错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
OSError Traceback（最近一次调用最后一次）
第 3 行 [1] 中的单元格
      1 # 加载模型
      2导入keras
----&gt; 3 模型 = keras.models.load_model(“C:/Users/Hussein Ali/Desktop/d/DNNModel.py”)

文件 C:\anaconda\lib\site-packages\keras\utils\traceback_utils.py:70，位于filter_traceback..error_handler(*args, **kwargs)
     67、filtered_tb = _process_traceback_frames（e.__traceback__）
     68 # 要获取完整的堆栈跟踪，请调用：
     69 # `tf.debugging.disable_traceback_filtering()`
---&gt; 70 从 None 引发 e.with_traceback(filtered_tb)
     71 最后：
     72 删除filtered_tb

文件 C:\anaconda\lib\site-packages\h5py\_hl\files.py:533，在 File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy 、fs_persist、fs_threshold、fs_page_size、page_buf_size、min_meta_keep、min_raw_keep、锁定、alignment_threshold、alignment_interval、**kwds）
    第525章
    526锁定，page_buf_size，min_meta_keep，min_raw_keep，
    [第 527 章]
    [第 528 章]
    第529章
    第530章
    [第 531 章]
    第532章
--&gt;第533章
    第535章
    第536章

文件 C:\anaconda\lib\site-packages\h5py\_hl\files.py:226，在 make_fid（名称、模式、userblock_size、fapl、fcpl、swmr）中
    224 如果 swmr 和 swmr_support:
    225 个标志 |= h5f.ACC_SWMR_READ
--&gt; 226 fid = h5f.open（名称，标志，fapl = fapl）
    227 elif 模式 == &#39;r+&#39;:
    [第 228 章]

文件 h5py\_objects.pyx:54，在 h5py._objects.with_phil.wrapper() 中

文件 h5py\_objects.pyx:55，在 h5py._objects.with_phil.wrapper() 中

文件 h5py\h5f.pyx:106，在 h5py.h5f.open() 中

OSError：无法打开文件（未找到文件签名）
]]></description>
      <guid>https://stackoverflow.com/questions/77673041/keras-models-load-model-gives-error-on-h5f-open</guid>
      <pubDate>Sun, 17 Dec 2023 01:20:24 GMT</pubDate>
    </item>
    <item>
      <title>无法微调 CLIP 模型</title>
      <link>https://stackoverflow.com/questions/77673015/fail-to-finetune-clip-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673015/fail-to-finetune-clip-model</guid>
      <pubDate>Sun, 17 Dec 2023 01:01:53 GMT</pubDate>
    </item>
    <item>
      <title>你能帮我理解 logit 函数吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77672810/can-you-help-me-to-understand-the-logit-function</link>
      <description><![CDATA[你能帮我理解第二行吗？我不明白对数是如何在第二行消失的。我知道 exp=2.7 但我无法理解转换。请帮忙
在此处输入图片描述
logit 解释。无法理解。]]></description>
      <guid>https://stackoverflow.com/questions/77672810/can-you-help-me-to-understand-the-logit-function</guid>
      <pubDate>Sat, 16 Dec 2023 23:05:27 GMT</pubDate>
    </item>
    <item>
      <title>如何处理我的 RNAseq 数据以便应用机器学习方法进行基因选择？</title>
      <link>https://stackoverflow.com/questions/77672716/how-can-i-process-my-rnaseq-data-in-order-to-apply-machine-learning-methods-for</link>
      <description><![CDATA[我正在处理来自 RNAseq 的数据，其中包含约 3000 个基因的表达值，包括来自患病患者和对照患者的测量值。
我的目标是训练机器学习模型、套索和随机森林，以便选择哪些基因子集能够执行更好的疾病预测。我依赖于平衡的准确性和 P 值 [Acc &gt; NIR]以选择最佳模型。
有人知道可以让我提高性能的技术吗？
我应用了一系列数据处理来改进获得的结果，其中包括：

删除高度相关的预测变量。
消除方差接近于零的预测变量。
我使用 DESeq 和 edgeR 选择差异表达基因。

使用其中的一种或多种后，我仍然没有得到好的结果，我一直在 RNAseq 生物信息学论文中寻找信息，但没有发现任何与我已经应用的内容有很大不同的内容。]]></description>
      <guid>https://stackoverflow.com/questions/77672716/how-can-i-process-my-rnaseq-data-in-order-to-apply-machine-learning-methods-for</guid>
      <pubDate>Sat, 16 Dec 2023 22:23:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么我使用随机森林回归器得到负 R2 分数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77672303/why-im-getting-a-negative-r2-score-with-random-forest-regressor</link>
      <description><![CDATA[我试图使用 Phyton 中的随机森林模型来预测 MOF 的一些变量（来自一篇科学论文），但 R2 的值为负值（与论文不同，论文为正值）。我实际上不知道问题是否出在我的数据集（涉及将数值分配给字符串）或我的代码中。原始数据集是文学数据集，我的版本是“Dados editados 3”
数据集链接：https://docs.google.com/spreadsheets/d/17r-hxcuuzEFdfsqcAdHe_9iIp1d51IvL/edit?usp=sharing&amp;ouid=111702212107777597741&amp;rtpof=true&amp;sd=true
我尝试多次检查代码，但我不知道我做错了什么，因为 RF 模型是一个非常强大的模型。此外，我还使用检测和删除异常值的函数删除数据集的所有 Nan 值。
代码：
导入 pandas 作为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.model_selection 导入 GridSearchCV
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.ensemble 导入 RandomForestRegressor
从sklearn导入预处理
从 sklearn 导入指标
将 numpy 导入为 np

df = pd.read_excel(r&#39;/content/drive/My Drive/Projeto ML/Dados ML.xlsx&#39;,sheet_name =“Dados editados 3”)

df = df.drop(columns = [&#39;酶负载&#39;, &#39;固定率&#39;, &#39;活性保留&#39;] )

df.replace(&#39;-&#39;, np.NaN, inplace = True)

df = df.dropna()

#修改后的函数

def get_outliers(l):
    #如果保留 0.1 和 0.75，那么几乎不会过滤任何异常值
    #q1 是 0.25 分位数，q3 是 0.75 分位数
    q1 = l.分位数(0.25)
    q3 = l.分位数(0.75)
    iqr = q3-q1
    栅栏低 = q1 - 1.5 * iqr
    栅栏高 = q3 + 1.5 * iqr
    返回 [~(i&gt;=fenceLow 且 i&lt;=fenceHigh) for i in l]

离群值 = df.apply(get_outliers)

df = df[~离群值.apply(lambda x:any(x), axis=1)]


X = df.iloc[:, :-1]

Y = df.iloc[:,-1]

x_train，x_test，y_train，y_test = train_test_split（X，Y，test_size = 0.25，random_state = 42）

缩放器 = 预处理.MinMaxScaler(feature_range = (0.1, 0.9))
x_train = 缩放器.fit_transform(x_train)
x_test= 缩放器.fit_transform(x_test)

从 sklearn.model_selection 导入 KFold
从 sklearn.model_selection 导入 cross_val_score
从 sklearn.metrics 导入 r2_score

rf = RandomForestRegressor()

rf.fit(x_train, y_train)

y_pred = rf.predict(x_test)

k_folds = KFold(n_splits = 6)

分数 = cross_val_score(rf, x_train, y_train, cv = k_folds, 评分 = “r2”)

print(&quot;简历分数：&quot;, 分数)
print(&quot;平均简历分数：&quot;, Scores.mean())
print(&quot;平均值中使用的 CV 分数数量：&quot;, len(scores))

在此处输入图像描述
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77672303/why-im-getting-a-negative-r2-score-with-random-forest-regressor</guid>
      <pubDate>Sat, 16 Dec 2023 19:55:00 GMT</pubDate>
    </item>
    <item>
      <title>我应该应用什么预处理来对雕刻文本执行 OCR？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77671624/what-preproccessing-should-i-apply-to-perform-an-ocr-on-an-engraved-text</link>
      <description><![CDATA[我正在尝试对下面有一些其他文本的雕刻数字执行 OCR（参见下图），我正在尝试读取数字并忽略黑色文本。

我尝试过 Google ML 套件文本识别，但它不起作用，我尝试过应用许多过滤器，例如灰度和颜色反转，但它也不起作用。我有一些关于使用 python 和 pytesseract 进行深度学习的线索，但我几乎可以肯定这也行不通。
我想知道，这里的方法是什么？我应该对图像应用任何特定的处理，还是这是一个机器学习问题？这还能解决吗？]]></description>
      <guid>https://stackoverflow.com/questions/77671624/what-preproccessing-should-i-apply-to-perform-an-ocr-on-an-engraved-text</guid>
      <pubDate>Sat, 16 Dec 2023 16:10:46 GMT</pubDate>
    </item>
    <item>
      <title>尽管进行了标准化和交叉验证，模型性能仍面临挑战：使用 Automobile.tn 数据进行的案例研究（1766 条条目）"</title>
      <link>https://stackoverflow.com/questions/77669285/challenges-in-model-performance-despite-standardization-and-cross-validation-a</link>
      <description><![CDATA[从 sklearn.model_selection 导入 cross_val_score
从 sklearn. Linear_model 导入 LinearRegression

# 创建线性回归模型的实例

线性模型 = 线性回归()

# 应用 5 倍交叉验证

cross_val_scores = cross_val_score(线性模型, 缩放数据, y, cv=5, 评分=&#39;neg_mean_squared_error&#39;)

# 分数通常为负数，因为 scikit-learn 为了方便起见颠倒了符号

# 将分数转换为正值

mse_scores = -cross_val_scores

# 显示结果

print(&quot;R_squared:&quot;,r_squared)
打印（“RMSE：”，rmse）

输出：
&lt;前&gt;&lt;代码&gt;R_squared：0.34315292365076344
均方根误差：50511.93582816874
]]></description>
      <guid>https://stackoverflow.com/questions/77669285/challenges-in-model-performance-despite-standardization-and-cross-validation-a</guid>
      <pubDate>Fri, 15 Dec 2023 23:34:17 GMT</pubDate>
    </item>
    <item>
      <title>哪些分类器可以在这个简单的数据集上实现零训练误差？</title>
      <link>https://stackoverflow.com/questions/77668739/which-classifiers-can-achieve-zero-training-error-on-this-simple-data-set</link>
      <description><![CDATA[数据集
i) 我知道为什么逻辑回归在这个数据集上不能实现 0 错误，因为它不能画一条直线来划分类。
其他人呢？
我曾尝试询问法学硕士，但得到的答复令人困惑。]]></description>
      <guid>https://stackoverflow.com/questions/77668739/which-classifiers-can-achieve-zero-training-error-on-this-simple-data-set</guid>
      <pubDate>Fri, 15 Dec 2023 20:44:10 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Iris 数据集加载到数据框中？</title>
      <link>https://stackoverflow.com/questions/77667785/how-to-load-iris-dataset-into-a-data-frame</link>
      <description><![CDATA[我需要将 Iris 数据集加载到数据框中。查看并打印该数据集的信息。然后使用 .describe() 方法，检查数据的描述性统计。
我不太确定我所做的是否正确。
from sklearn.datasets import load_iris
将 pandas 导入为 pd

虹膜 = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
打印（df.info（））
打印（df.描述（））

]]></description>
      <guid>https://stackoverflow.com/questions/77667785/how-to-load-iris-dataset-into-a-data-frame</guid>
      <pubDate>Fri, 15 Dec 2023 17:07:15 GMT</pubDate>
    </item>
    <item>
      <title>如何为此模型创建 Sagemaker 端点？</title>
      <link>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-model</link>
      <description><![CDATA[我创建了一个 VectorDB (FAISS) 并将 PDF 输入到其中。然后我使用 AWS Bedrock 的 Langchain 包装器来调用它。我知道现在存在 Kowledge Base，但至少在 SageMaker 笔记本中，我有更多的控制权。该模型在 SageMaker Notebook 中完美运行，当我提出问题时，它会返回答案。
我想做的是创建一个小网页（并通过 HTTP/REST API），只需在文本字段中提交问题并在文本字段中接收答案。我猜如果链中某个地方没有 Lambda 函数，这很难做到，或者也许不是？
当我查看 Sagemaker 控制台的推理选项卡下时，没有模型或没有端点，或者没有&lt; /strong&gt; 端点配置（因为我没有从 Sagemaker 选择模型，所以我只是在 Python 笔记本中使用 langchain LLM 和 Bedrock，如下所示）。
&lt;前&gt;&lt;代码&gt;导入boto3
导入 json

bedrock = boto3.client(service_name=&quot;bedrock&quot;)
bedrock_runtime = boto3.client(service_name=“bedrock-runtime”)



从 langchain.llms.bedrock 导入 Bedrock
从 langchain.chains 导入 RetrievalQA
从 langchain.prompts 导入 PromptTemplate

嵌入 = BedrockEmbeddings(model_id=“amazon.titan-embed-text-v1”,
                               客户端=bedrock_runtime）

最终我将文档嵌入到 FAISS Vector 数据库中，我查询的就是这个数据库
db = FAISS.from_documents（文档，嵌入）


模型泰坦 = {
    “最大令牌计数”：512，
    “停止序列”：[]，
    “温度”：0.0，
    “顶部P”：0.5
}

# 亚马逊泰坦模型
llm = 基岩(
    model_id=&quot;amazon.titan-text-express-v1&quot;,
    客户端=bedrock_runtime，
    model_kwargs=model_titan,
）

然后定义一个提示......
提示 = 提示模板(
    template=prompt_template, input_variables=[“上下文”, “问题”]
）

并查询数据库：
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type=“东西”，
    检索器=db.as_retriever(
        search_type=“相似度”，
    ),
    return_source_documents=真，
    chain_type_kwargs={“提示”: 提示},
）



query =“未来的技术是什么样的？”

结果 = qa({“查询”: 查询})

print(f&#39;查询: {结果[“查询”]}\n&#39;)
print(f&#39;结果: {结果[“结果”]}\n&#39;)
print(f&#39;上下文文档：&#39;)
对于结果 [“source_documents”] 中的 srcdoc：
      打印（f&#39;{srcdoc}\n&#39;）

这恰好返回了我在 Sagemaker 中需要的内容，我只需要从外部查询数据库即可。
我不想让 lambda 函数每次都重建链。我考虑的是效率，我需要的只是在 lambda 函数中传递查询并返回结果。]]></description>
      <guid>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-model</guid>
      <pubDate>Thu, 14 Dec 2023 14:49:20 GMT</pubDate>
    </item>
    <item>
      <title>与自然语言处理相关的代码执行错误</title>
      <link>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</link>
      <description><![CDATA[此代码显示了图像中给出的错误。我无法理解其中的原因。
导入系统
断言 sys.version_info[0]==3
断言 sys.version_info[1] &gt;= 5

从平台导入 python_version
assert int(python_version().split(&quot;.&quot;)[1]) &gt;= 5, &quot;请按照\中的说明升级您的Python版本
    在与此笔记本相同的目录中找到 README.txt 文件。您的 Python 版本是“ + python_版本()

从 gensim.models 导入 KeyedVectors
从 gensim.test.utils 导入数据路径
导入打印件
将 matplotlib.pyplot 导入为 plt
plt.rcParams[&#39;figure.figsize&#39;] = [10, 5]

导入nltk
nltk.download(&#39;reuters&#39;) #指定下载位置，可选添加参数：download_dir=&#39;/specify/desired/path/&#39;
从 nltk.corpus 导入路透社

将 numpy 导入为 np
随机导入
将 scipy 导入为 sp
从 sklearn.decomposition 导入 TruncatedSVD
从 sklearn.decomposition 导入 PCA

START_TOKEN = &#39;&#39;
END_TOKEN = &#39;&#39;

np.随机.种子(0)
随机种子(0)

错误消息：
&lt;块引用&gt;
[nltk data]加载路透社时出错：

我不知道如何在Python中使用导入命令。我尝试了所有可能的方法进行检查，包括删除带有其他新闻门户名称的“路透社”，但没有任何效果。现在，如果有人帮助我正确编写代码的“导入”部分，那就更好了。我认为其他部分没问题，因为没有显示其他消息。]]></description>
      <guid>https://stackoverflow.com/questions/77653463/error-in-execution-of-code-related-to-natural-language-processing</guid>
      <pubDate>Wed, 13 Dec 2023 12:07:23 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn Ridge 分类器：提取类概率</title>
      <link>https://stackoverflow.com/questions/22538080/scikit-learn-ridge-classifier-extracting-class-probabilities</link>
      <description><![CDATA[我目前正在使用 sklearn 的 Ridge 分类器，并且希望将此分类器与 sklearn 和其他库中的分类器集成。为了做到这一点，理想的做法是提取给定输入属于类列表中每个类的概率。目前，我正在使用 model.decision_function(x) 的输出来压缩类，但这返回的是距超平面的距离，而不是直接的概率。
这些距离值从 -1 到 1 左右变化。
distances = dict(zip(clf.classes_, clf.decision_function(x)[0]))

如何将这些距离转换为一组更具体的概率（一系列总和为 1 的正值）？我正在寻找类似 clf.predict_proba() 的东西，它是为 sklearn 中的 SVC 实现的。]]></description>
      <guid>https://stackoverflow.com/questions/22538080/scikit-learn-ridge-classifier-extracting-class-probabilities</guid>
      <pubDate>Thu, 20 Mar 2014 15:43:10 GMT</pubDate>
    </item>
    </channel>
</rss>