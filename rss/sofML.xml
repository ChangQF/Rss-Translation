<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 20 Jan 2024 06:17:09 GMT</lastBuildDate>
    <item>
      <title>对于特征工程师来说，有哪些好主意可以为分类模型创建与目标特征的更多相关性？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77848799/what-are-good-ideas-to-feature-engineer-features-to-create-more-correlation-with</link>
      <description><![CDATA[我正在开发一个分类模型，可以对客户进行分类，判断他们是否会成功付款或未能付款。
我尝试了 Scikit Learn 分类模型，但它的准确率略高于 50%。然后，我研究了 TensorFlow 分类模型，并获得了 67% 的准确率分数。
我正在努力提高准确率，希望模型的准确率能够达到 90% 以上。
我注意到的主要问题是没有一个特征与目标特征具有高相关性得分。
这是我尝试过的：
&lt;前&gt;&lt;代码&gt;df5.corr()

结果是

我尝试了多个 TensorFlow 模型，最高准确度得分为 67%
tf.random.set_seed(42)

log_model_8 = tf.keras.Sequential([
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(50, 激活 = &#39;relu&#39;),
    tf.keras.layers.Dense(1)
]）

log_model_8.compile(loss = tf.keras.losses.BinaryCrossentropy(),
                   优化器= tf.keras.optimizers.Adam(),
                   指标 = [&#39;准确性&#39;])

log_model_8.fit(X,y, epochs = 100, verbose = 1)

log_model_8.evaluate(X,y)


在这种情况下有什么好主意，如何才能提高模型准确率达到 90% 以上？]]></description>
      <guid>https://stackoverflow.com/questions/77848799/what-are-good-ideas-to-feature-engineer-features-to-create-more-correlation-with</guid>
      <pubDate>Fri, 19 Jan 2024 21:03:11 GMT</pubDate>
    </item>
    <item>
      <title>如何将字符串转换为浮点数，dtype='numeric' 与字节/字符串数组不兼容。将数据显式转换为数值</title>
      <link>https://stackoverflow.com/questions/77848723/how-to-convert-string-to-float-dtype-numeric-is-not-compatible-with-arrays-of</link>
      <description><![CDATA[将 pandas 导入为 pd
从 sklearn.tree 导入 DecisionTreeClassifier
从sklearn导入预处理

cols = [&#39;国家&#39;, &#39;人口&#39;, &#39;中位数年龄&#39;]
col_types = {&#39;国家&#39;：str，&#39;人口&#39;：int，&#39;median_age&#39;：int}
数据库 = pd.read_csv(&#39;dataset.csv&#39;, dtype=col_types)

le = 预处理.LabelEncoder()
数据库[&#39;国家&#39;] = le.fit_transform(数据库[&#39;国家&#39;])

X = (数据库[[&#39;国家&#39;]])
y = database.drop(列=[&#39;国家&#39;])

模型 = DecisionTreeClassifier()
model.fit(X.值, y.值)
prevision = model.predict([[&#39;意大利&#39;]])
打印（预览）
``py


我正在尝试使用机器学习编写一个程序，该程序以一个国家的名称作为唯一输入，返回中位年龄以及该国家有多少居民。问题是拟合和预测函数需要浮点数，但我的输入是字符串，所以我尝试使用标签编码器转换它，但收到此错误：

dtype=&#39;numeric&#39; 与字节/字符串数组不兼容。
而是将数据显式转换为数值
&lt;前&gt;&lt;代码&gt;
如何解决这个问题？
]]></description>
      <guid>https://stackoverflow.com/questions/77848723/how-to-convert-string-to-float-dtype-numeric-is-not-compatible-with-arrays-of</guid>
      <pubDate>Fri, 19 Jan 2024 20:44:26 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 中具有多个层的简单 RNN，用于顺序预测</title>
      <link>https://stackoverflow.com/questions/77848436/simple-rnn-with-more-than-one-layer-in-pytorch-for-squential-prediction</link>
      <description><![CDATA[我得到了连续的时间序列数据。在每个时间戳，只有一个变量可供观察（如果我的理解是正确的，这意味着特征数量 = 1）。我想训练一个具有多个层的简单 RNN 来预测下一个观察结果。
我使用滑动窗口创建了训练数据，窗口大小设置为8。为了给出具体的想法，下面是我的原始数据、训练数据和目标。
示例数据
0.40 0.82 0.14 0.01 0.98 0.53 2.5 0.49 0.53 3.37 0.49
训练数据
&lt;前&gt;&lt;代码&gt;X =
    0.40 0.82 0.14 0.01 0.98 0.53 2.5 0.49
    0.82 0.14 0.01 0.98 0.53 2.5 0.49 0.53
    0.14 0.01 0.98 0.53 2.5 0.49 0.53 3.37


对应的目标是
&lt;前&gt;&lt;代码&gt;Y =
     0.53
     3.37
     0.49

我将批量大小设置为 3。但它给了我一个错误
运行时错误：input.size(-1) 必须等于 input_size。期望 8，得到 1
导入火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim
导入 torch.utils.data 作为数据
将 numpy 导入为 np

X = np.array( [ [0.40, 0.82, 0.14, 0.01, 0.98, 0.53, 2.5, 0.49], [0.82, 0.14, 0.01, 0.98, 0.53, 2.5, 0.49, 0.53], [0.14, 0.01, 0.98, 0.53, 2.5, 0.49, 0.53, 3.37] ], dtype=np.float32)

Y = np.array([[0.53], [3.37], [0.49]], dtype=np.float32)

类 RNNModel(nn.Module):
    def __init__(self, input_sz, n_layers):
        超级（RNNModel，自我）.__init__()
        self.hidden_​​dim = 3*input_sz
        self.n_layers = n_layers
        输出大小 = 1
        self.rnn = nn.RNN（input_sz，self.hidden_​​dim，num_layers = n_layers，batch_first = True）
        self.线性 = nn.Linear(self.hidden_​​dim, output_sz)

    def 前向（自身，x）：
        batch_sz = x.size(0)
        hide = torch.zeros(self.n_layers, batch_sz, self.hidden_​​dim) #初始化n_layer*batch_sz维度的隐藏状态数hidden_​​dim)
        out, 隐藏 = self.rnn(x, 隐藏)
        out = out.contigious().view(-1, self.hidden_​​dim)
        返回，隐藏

device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
模型 = RNNModel(8,2)
X = torch.tensor(X[:,:,np.newaxis])
Y = torch.tensor(Y[:,:,np.newaxis])
X = X.to(设备)
Y = Y.to(设备)
模型 = model.to(设备)
优化器 = optim.Adam(model.parameters())
loss_fn = nn.MSELoss()

加载器= data.DataLoader（data.TensorDataset（X，Y），shuffle=False，batch_size=3）

n_epoch = 10
对于范围内的历元（n_epoch）：
    模型.train()
    对于加载器中的 X_batch、Y_batch：
        Y_pred = 模型(X_batch)
        损失 = loss_fn(Y_pred,Y_batch)
        优化器.zero_grad()
        loss.backward()
        优化器.step()

    如果纪元 % 10 != 0:
        继续
        模型.eval()
        使用 torch.no_grad()：
            Y_pred = 模型(X)
            train_rmse = np.sqrt(loss_fn(Y_pred,Y))
        print(“纪元 %d: 训练 RMSE %.4f” % (纪元, train_rmse))


我做错了什么？谁能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/77848436/simple-rnn-with-more-than-one-layer-in-pytorch-for-squential-prediction</guid>
      <pubDate>Fri, 19 Jan 2024 19:36:58 GMT</pubDate>
    </item>
    <item>
      <title>基于多重线性回归模型输出和蒙特卡罗模拟的先验 BPN</title>
      <link>https://stackoverflow.com/questions/77848365/prior-bpn-based-on-multi-linear-regression-model-output-and-monte-carlo-simulati</link>
      <description><![CDATA[在道路事故预测：贝叶斯分层方法中的第286页&lt; /a&gt; 纸。
本文描述了贝叶斯置信网络 (BPN) 的构建和参数学习，特别关注创建先验 BPN 并将其更新为后验 BPN 所涉及的步骤：

之前的 BPN 构建：
先前的 BPN 最初是使用回归分析的结果构建的。
应用Genie 2.0的推理引擎构建网络并计算边际概率分布函数。
利用回归系数的估计分布和误差项的协方差矩阵进行蒙特卡罗模拟，建立响应变量Y的预测概率密度函数，将其离散为48个状态，然后填充条件概率表之前的 BPN。
模拟还用于将结果推断到没有观察到的区域。

后 BPN 更新：
EM算法将先验BPN更新为后验BPN。
使用开发数据集中的信息将风险指示变量和响应变量的观察结果记录在列联表中。
参数学习使用贝叶斯推理和 EM 算法，其经验因素几乎不赋予先验信息任何权重。
仅更新开发数据集中具有可用信息的先前 BPN 的域。


&lt;小时/&gt;
我的问题：
我们最初是否使用蒙特卡洛模拟来填充“概率”？在条件概率表 (CPT) 中并建立先验 BPN（即，在生成的 Y 响应变量的分布下查找 X 值的所有组合的频率通过蒙特卡洛模拟），然后使用数据集作为证据来更新和学习进一步的参数和概率，从而得到后验 BPN？
或者
我们是否从头开始使用数据集来用概率填充 CPT，并通过从蒙特卡罗模拟生成的 Y 分布下从头开始查找数据集中出现的频率来学习参数和概率（即，找到X值组合的频率，从而找到模拟Y下的条件概率，以填充初始CPT“概率”和单元格）？
非常感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/77848365/prior-bpn-based-on-multi-linear-regression-model-output-and-monte-carlo-simulati</guid>
      <pubDate>Fri, 19 Jan 2024 19:20:59 GMT</pubDate>
    </item>
    <item>
      <title>如果新的交叉验证迭代出现，是否需要重新创建神经网络层？</title>
      <link>https://stackoverflow.com/questions/77847336/whether-should-be-the-neuron-network-layers-recreated-if-the-new-iteration-of-cr</link>
      <description><![CDATA[我有一个关于交叉验证的问题。
k=5，
将有 4/5 训练数据集和 1/5 验证数据集
 data = np.concatenate([self.training_data1, self.training_data2], axis=1)
        
        kf = KFold(n_splits=k, shuffle=True) # k 折叠交叉验证
        kf.get_n_splits(data) # 返回交叉验证器中的分割迭代次数
     
        损失CV = 0
        val_loss_cv = 0
    
        对于 kf.split(data) 中的 train_index、val_index：
            
            logging.info(f“train_index:{train_index.shape}”)
            logging.info(f&quot;val_index:{val_index.shape}&quot;)

            self.is_train = tf.Variable(initial_value=True, trainable=False, dtype=tf.bool, name=“is_train”)
   
            loss_cv, val_loss_cv = self.train(train_index, val_index)
            loss_cv += loss_cv
            val_loss_cv += val_loss_cv

loss_cv = loss_cv / k
val_loss_cv = val_loss_cv / k

每次迭代都有新的train_index、val_index。（例如在train_index0、val_index0之后，下一次迭代将从train_index1、val_index1开始）
这些数据集将被加载到函数 self.train(train_index, val_index) 中。
在 train() 函数中，有一个使用神经元网络层创建的自动编码器层。
当新的交叉验证索引（train_index1，val_index1）在新的迭代中出现时，是否应该使用新的初始权重和偏差重新创建新的神经元网络层？
如果我在神经元网络层中使用继承的权重和偏差，而不是创建新的神经元网络层，结果是否会导致过拟合？]]></description>
      <guid>https://stackoverflow.com/questions/77847336/whether-should-be-the-neuron-network-layers-recreated-if-the-new-iteration-of-cr</guid>
      <pubDate>Fri, 19 Jan 2024 15:56:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 spaCy 模型对文本中的实体进行分类但不定位实体</title>
      <link>https://stackoverflow.com/questions/77847222/classifying-but-not-locating-entities-within-a-text-with-spacy-model</link>
      <description><![CDATA[有没有办法“强制”经过训练的 spaCy 模型对文本中的给定字符串进行分类，而不是定位？
就我而言，我想构建一个 NER 模型，将文本中的地名分类为特定类别，例如“城市”或“国家”。所以模型不需要定位地名。对于每个文本文件，它需要处理其中的地名列表、字典等作为参数，然后根据周围的文本为该地名分配最可能的类。
此外，是否有一个选项可以让 spaCy“忽略”地名的各个字符，而仅通过查看周围的文本来训练模型？
如果我尝试在不指定标签的情况下设置实体，则 print(doc.ents) 返回一个空集。
doc = nlp(“德国距离日本比莫斯科更远”)

doc.set_ents([跨度(doc, 0, 1), 跨度(doc, 4, 5), 跨度(doc, 6, 7)])

打印（文档）
对于 doc.ents 中的 ent：
    打印（ent.text，ent.label_）
]]></description>
      <guid>https://stackoverflow.com/questions/77847222/classifying-but-not-locating-entities-within-a-text-with-spacy-model</guid>
      <pubDate>Fri, 19 Jan 2024 15:36:34 GMT</pubDate>
    </item>
    <item>
      <title>是否有一个值可以表达多种因素对结果的影响？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77846958/is-there-an-value-that-expresses-the-effect-of-multiple-factors-to-the-outcome</link>
      <description><![CDATA[我有多个变量，例如 X_1、X_2、...、X_n，它们不一定是独立的，但预计会影响 Y。
是否有一个值可以指示 X_1、X_2、...、X_n 对 Y 总共有多大影响？
例如，如果还有其他变量 Z_1、Z_2、..._、Z_m 也影响 Y，但与 X_1 ~X_n 无关，我们进行线性回归并得到 Y=w_1X_1 +w_2X_2+ ...+w_nX_n+ w_n +1 Z_1 +...+w_n+m Z_m ，“w_1X_1 +...+w_nX_n”可能是一个指标。]]></description>
      <guid>https://stackoverflow.com/questions/77846958/is-there-an-value-that-expresses-the-effect-of-multiple-factors-to-the-outcome</guid>
      <pubDate>Fri, 19 Jan 2024 14:53:49 GMT</pubDate>
    </item>
    <item>
      <title>如何知道 VGGish 正确运行并查询音频分类的嵌入</title>
      <link>https://stackoverflow.com/questions/77846542/how-to-know-vggish-runs-correctly-and-queries-about-embeddings-for-audio-classif</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77846542/how-to-know-vggish-runs-correctly-and-queries-about-embeddings-for-audio-classif</guid>
      <pubDate>Fri, 19 Jan 2024 13:45:06 GMT</pubDate>
    </item>
    <item>
      <title>从头开始的 DQN 给出错误形状的输出</title>
      <link>https://stackoverflow.com/questions/77846372/dqn-from-scratch-giving-wrong-shaped-output</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77846372/dqn-from-scratch-giving-wrong-shaped-output</guid>
      <pubDate>Fri, 19 Jan 2024 13:21:14 GMT</pubDate>
    </item>
    <item>
      <title>Xgboost算法问题文件为空</title>
      <link>https://stackoverflow.com/questions/77843515/xgboost-algorithm-issue-file-empty</link>
      <description><![CDATA[我尝试使用 1.7-1 版本的 Xgboost 算法训练数据集。调用 Xgboost 函数时，它会抛出如下错误。
2024-01-19:02:57:27:INFO] 导入框架 sagemaker_xgboost_container.training
[2024-01-19:02:57:27:INFO] 未检测到 GPU（如果未安装 GPU，则正常）
[2024-01-19:02:57:27:INFO] 调用用户培训脚本。
[2024-01-19:02:57:27:错误] 报告培训失败
[2024-01-19:02:57:27:ERROR] 框架错误：
回溯（最近一次调用最后一次）：
  文件“/miniconda3/lib/python3.8/tarfile.py”，第 2318 行，下一个
    tarinfo = self.tarinfo.fromtarfile(self)
  文件“/miniconda3/lib/python3.8/tarfile.py”，第 1105 行，fromtarfile
    obj = cls.frombuf(buf, tarfile.encoding, tarfile.errors)
  文件“/miniconda3/lib/python3.8/tarfile.py”，第 1041 行，frombuf 中
    raise EmptyHeaderError(“空标题”)
tarfile.EmptyHeaderError：空标头
在处理上述异常的过程中，又出现了一个异常：
回溯（最近一次调用最后一次）：
  文件“/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_trainer.py”，第 84 行，列车中
    入口点（）
  文件“/miniconda3/lib/python3.8/site-packages/sagemaker_xgboost_container/training.py”，第 102 行，在 main 中
    火车（框架.training_env（））
  文件“/miniconda3/lib/python3.8/site-packages/sagemaker_xgboost_container/training.py”，第 87 行，训练中
    框架.模块.run_module(
  文件“/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_modules.py”，第 290 行，在 run_module 中
    _files.download_and_extract(uri, _env.code_dir)
  文件“/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_files.py”，第 131 行，位于 download_and_extract 中
    使用 tarfile.open(name=dst, mode=“r:gz”) 作为 t：
  文件“/miniconda3/lib/python3.8/tarfile.py”，第 1621 行，打开
    返回 func(名称、文件模式、fileobj、**kwargs)
  gzopen 中的文件“/miniconda3/lib/python3.8/tarfile.py”，第 1674 行
    t = cls.taropen(名称、模式、fileobj、**kwargs)
  taropen 中的文件“/miniconda3/lib/python3.8/tarfile.py”，第 1651 行
    返回 cls(名称、模式、fileobj、**kwargs)
  文件“/miniconda3/lib/python3.8/tarfile.py”，第 1514 行，位于 __init__ 中
    self.firstmember = self.next()
  文件“/miniconda3/lib/python3.8/tarfile.py”，第 2333 行，在下一个
    引发 ReadError(“空文件”)
tarfile.ReadError：空文件
空的文件

我有两个具有相同结构且扩展名为 .csv 的源文件。
我不知道为什么它抱怨 tar 文件为空]]></description>
      <guid>https://stackoverflow.com/questions/77843515/xgboost-algorithm-issue-file-empty</guid>
      <pubDate>Fri, 19 Jan 2024 03:10:14 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：给定 groups=1，权重大小为 [128, 64, 4, 4]，预期输入 [1, 128, 65, 65] 有 64 个通道，但得到了 128 个通道</title>
      <link>https://stackoverflow.com/questions/77843263/runtimeerror-given-groups-1-weight-of-size-128-64-4-4-expected-input1</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77843263/runtimeerror-given-groups-1-weight-of-size-128-64-4-4-expected-input1</guid>
      <pubDate>Fri, 19 Jan 2024 01:31:36 GMT</pubDate>
    </item>
    <item>
      <title>在小型训练数据集上训练的文本转语音模型</title>
      <link>https://stackoverflow.com/questions/77406851/text-to-speech-model-that-trains-on-small-training-dataset</link>
      <description><![CDATA[我需要一个模型，可以使用包含转录本和最多 20 个句子的 wav 文件的数据集进行训练。
我尝试在这样的情况下训练 https://github.com/coqui-ai/TTS数据集，它根本没有训练得很好。这个推论只是噪音而不是文字。
我正在研究 https ://github.com/microsoft/SpeechT5/tree/main/SpeechLM#pre-trained-and-fine-tuned-models 但他们使用的微调数据集似乎也有超过 100 小时的音频内容。
解决这个问题的最佳研究模型是什么？]]></description>
      <guid>https://stackoverflow.com/questions/77406851/text-to-speech-model-that-trains-on-small-training-dataset</guid>
      <pubDate>Thu, 02 Nov 2023 04:00:19 GMT</pubDate>
    </item>
    <item>
      <title>面对强化学习的问题</title>
      <link>https://stackoverflow.com/questions/76695094/facing-a-problem-with-reinforcement-learning</link>
      <description><![CDATA[导入健身房
从 stable_baselines3 导入 A2C

env =gym.make(&#39;LunarLander-v2&#39;, render_mode=&quot;人类&quot;)
env.reset()

模型 = A2C(“MlpPolicy”, env, verbose=1)
model.learn(total_timesteps=1000)

集数 = 10

对于范围内的 ep（剧集）：
    obs = env.reset()
    完成=假
    虽然没有完成：
        动作、_states、_episode、_determ = model.predict(obs)
        obs、奖励、完成、info = env.step(action)
        env.render()

env.close()

我上面的代码产生以下输出：
DeprecationWarning：“np.bool8”是“np.bool_”的已弃用别名。 （已弃用 NumPy 1.24）
  如果不是 isinstance(终止, (bool, np.bool8)):
------------------------------------------------
|推出/ | |
| ep_len_mean | 89.2 | 89.2
| ep_rew_mean | -227 | -227
|时间/| |
|帧率 | 43 | 43
|迭代| 100 | 100
|已用时间 | 11 | 11
|总时间步数 | 500 | 500
|火车/ | |
|熵损失 | -1.29 | -1.29
|解释方差 | -0.0216 | -0.0216
|学习率 | 0.0007 | 0.0007
| n_更新 | 99 | 99
|政策损失 | 2.79 | 2.79
|价值损失 | 12.3 | 12.3
------------------------------------------------
------------------------------------------------
|推出/ | |
| ep_len_mean | 107 | 107
| ep_rew_mean | -209 | -209
|时间/| |
|帧率 | 45 | 45
|迭代| 200 | 200
|已用时间 | 21 | 21
|总时间步数 | 1000 | 1000
|火车/ | |
|熵损失 | -0.864 |
|解释方差 | -0.00161 | -0.00161
|学习率 | 0.0007 | 0.0007
| n_更新 | 199 | 199
|政策损失 | -16.6 | -16.6
|价值损失 | 228 | 228

随后出现此错误：
&lt;前&gt;&lt;代码&gt;------------------------------------
回溯（最近一次调用最后一次）：
  文件“c:\Appu\Courses\Fun items\Reinforcement Learning\c1.py”，第 17 行，位于  中。
    动作、_states、_episode、_determ = model.predict(obs)
                                         ^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\sarav\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\base_class.py”，第 555 行，在预测中
    返回 self.policy.predict（观察、状态、episode_start、确定性）
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\sarav\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\policies.py”，第 346 行，在预测中
    观察，vectorized_env = self.obs_to_tensor(观察)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\sarav\AppData\Local\Programs\Python\Python311\Lib\site-packages\stable_baselines3\common\policies.py”，第 260 行，位于 obs_to_tensor 中
    观察 = np.array(观察)
                  ^^^^^^^^^^^^^^^^^^^^^^^
ValueError：使用序列设置数组元素。请求的数组在 1 维之后具有不均匀的形状。检测到的形状为(2,)+不均匀部分。

当我运行代码时，它会运行几个时间步，然后退出并出现上述错误。有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/76695094/facing-a-problem-with-reinforcement-learning</guid>
      <pubDate>Sat, 15 Jul 2023 17:51:40 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost：如何使用带有 scikit-learn 接口 .fit 的 DMatrix</title>
      <link>https://stackoverflow.com/questions/76502318/xgboost-how-to-use-a-dmatrix-with-scikit-learn-interface-fit</link>
      <description><![CDATA[我目前在我的项目中使用 XGBoost 的 scikit-learn 接口。但是，我有一个非常大的数据集，每次调用 .fit 时，数据都会转换为 DMatrix，这非常耗时，尤其是在使用训练相对较快的 GPU 时。我使用本机接口对每次拟合使用单个 DMatrix 进行基准测试，结果显示出显着差异（每次拟合 14 秒与每次拟合 0.9 秒）。问题是，我需要一个 scikit-learn 模型，以便它可以与我的程序的其余部分配合使用。
有没有办法在 XGBoost 中将 DMatrix 与 scikit-learn 接口结合使用，或者有任何解决方法来避免重复转换为 DMatrix，同时仍保持与 scikit-learn 的兼容性？
请参阅下面的代码以获取导致此问题的可重现方法。
from sklearn.datasets import make_classification
从 xgboost 导入 XGBClassifier
将 xgboost 导入为 xgb

# 大型综合数据集
X, y = make_classification(n_samples=500_0000, n_features=20,
                           n_informative=10，n_redundant=10，random_state=42）

# scikit 学习
t = 时间.time()
模型 = XGBClassifier(tree_method=“gpu_hist”, gpu_id=0,
                      预测器=“gpu_predictor”，max_bin=256）
模型.fit(X, y)
print(&quot;scikit-learn 接口：&quot;, time.time() - t)

# 再次进行 scikit-learn
t = 时间.time()
模型.fit(X, y)
print(&quot;scikit-learn (2nd) 接口：&quot;, time.time() - t)

打印（）

#DMatrix
dtrain = xgb.DMatrix(数据=X,标签=y)
t = 时间.time()
model = xgb.train({“tree_method”: “gpu_hist”, “gpu_id”: 0,
                  “预测器”：“gpu_predictor”}，dtrain）
print(&quot;本机接口：&quot;, time.time() - t)

#再次DMatrix
t = 时间.time()
model = xgb.train({“tree_method”: “gpu_hist”, “gpu_id”: 0,
                  “预测器”：“gpu_predictor”}，dtrain）
print(“本机（第二）接口::”, time.time() - t)

输出：
scikit-learn 接口：14.393212795257568
scikit-learn（第二）接口：14.048950433731079

本机接口：3.9494242668151855
本机（第二）接口:: 0.9888997077941895

如您所见，scikit-learn 和 Native 之间存在很大的时间差异。]]></description>
      <guid>https://stackoverflow.com/questions/76502318/xgboost-how-to-use-a-dmatrix-with-scikit-learn-interface-fit</guid>
      <pubDate>Sun, 18 Jun 2023 19:56:25 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 中处理 nan/null 的分类器</title>
      <link>https://stackoverflow.com/questions/30317119/classifiers-in-scikit-learn-that-handle-nan-null</link>
      <description><![CDATA[我想知道 scikit-learn 中是否有处理 nan/null 值的分类器。我认为随机森林回归器可以处理这个问题，但当我调用 predict 时出现错误。
X_train = np.array([[1, np.nan, 3],[np.nan, 5, 6]])
y_train = np.array([1, 2])
clf = RandomForestRegressor(X_train, y_train)
X_test = np.array([7, 8, np.nan])
y_pred = clf.predict(X_test) # 失败！

我不能使用任何带有缺失值的 scikit-learn 算法来调用预测吗？
编辑。
现在我想起来，这是有道理的。这在训练期间不是问题，但是当您预测变量为空时如何分支时？也许你可以将两种方式分开并平均结果？看来只要距离函数忽略空值，k-NN 就应该可以正常工作。
编辑 2（我年纪更大、更聪明）
一些 gbm 库（例如 xgboost）使用三叉树而不是二叉树正是为了这个目的：2 个子节点用于是/否决策，1 个子节点用于缺失决策。 sklearn 使用二叉树&lt; /a&gt;]]></description>
      <guid>https://stackoverflow.com/questions/30317119/classifiers-in-scikit-learn-that-handle-nan-null</guid>
      <pubDate>Tue, 19 May 2015 05:02:35 GMT</pubDate>
    </item>
    </channel>
</rss>