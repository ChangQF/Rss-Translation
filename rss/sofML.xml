<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 29 Apr 2024 15:15:22 GMT</lastBuildDate>
    <item>
      <title>有没有办法在 Designer 中使用在 Azure AutoML 中创建的 ML 模型？</title>
      <link>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</link>
      <description><![CDATA[我知道我可以在 Azure Designer 中创建自定义代码模块，但是有没有办法连接我在 AutoML 中本机创建的 ML 模型？
AutoML 模型正在使用 XGBoost，这似乎不是 Designer 的 ML 组件功能下的选项。我的目标是创建一个低代码解决方案，因此我不想使用自定义 Python 代码组件。
有什么想法吗？
使用 AutoML 构建模型，需要连接到 Designer 中的现有数据管道]]></description>
      <guid>https://stackoverflow.com/questions/78403537/is-there-a-way-to-use-a-ml-model-created-in-azure-automl-within-designer</guid>
      <pubDate>Mon, 29 Apr 2024 14:52:21 GMT</pubDate>
    </item>
    <item>
      <title>为什么在机器学习中使用管道？</title>
      <link>https://stackoverflow.com/questions/78403533/why-use-pipelines-in-machine-learning</link>
      <description><![CDATA[我们都知道，在机器学习中，我们通常不会对整个数据集及其所有列执行数据处理和特征工程步骤。
例如，在处理缺失值的步骤中，我们假设我们将使用平均值处理某些列，而使用中位数或众数处理其他列。但是，如果我们使用管道，则无法指定要用平均值或中位数替换缺失值的列。这可能会导致不同的结果，那么为什么要使用管道呢？]]></description>
      <guid>https://stackoverflow.com/questions/78403533/why-use-pipelines-in-machine-learning</guid>
      <pubDate>Mon, 29 Apr 2024 14:51:51 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 - 针对 AUC 或 F1 分数进行优化</title>
      <link>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</link>
      <description><![CDATA[我在 sklearn 中使用随机森林，并且我的数据集相当不平衡（20% 为正类，80% 为其他类）。有没有办法让它针对一些考虑到这一点的指标进行训练（优化），比如 AUC 分数或 F1 分数？我可以使用什么技巧来推动它朝这个方向发展吗？
到目前为止，我想到/尝试过的唯一方法是使用不同的类别权重。
或者，是否有其他实现（或其他模型，例如 xgboost）允许我使用这样的自定义指标？]]></description>
      <guid>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</guid>
      <pubDate>Mon, 29 Apr 2024 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>使用人工智能寻找好的视频质量增强器</title>
      <link>https://stackoverflow.com/questions/78402402/searching-for-a-good-video-quality-enhancer-using-ai</link>
      <description><![CDATA[我有一些 15 年前制作的旧视频。质量很差，它确实被压缩了，而且我有一些小故障，因为此时视频导入非常有问题。
我想尝试一些能够使用人工智能增强这些视频的程序。
如果只有可用的模型，我什至可以编写此代码。
我搜索 MacOS 或 Linux 工具。我更喜欢它是开源的。
你知道我在哪里可以找到一个好的工具吗？我尝试了一些，但质量不太好。
如果没有程序可以做到这一点，我该如何继续训练我的模型？我不知道这是否是一个好方法，因为它需要大量视频来完成......
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78402402/searching-for-a-good-video-quality-enhancer-using-ai</guid>
      <pubDate>Mon, 29 Apr 2024 11:32:19 GMT</pubDate>
    </item>
    <item>
      <title>关于机器学习中预测时间序列的分析和模型的建议[关闭]</title>
      <link>https://stackoverflow.com/questions/78402245/suggestion-about-analysis-and-model-for-forecasting-time-series-in-ml</link>
      <description><![CDATA[我必须根据 csv 数据对给定日期的网络单元格进行流量预测，其中包含 5 列：区域、站点、单元格、日期、流量
例如：
&lt;上一页&gt;&lt;代码&gt;AAN,AAN001,AAN001A,2021-01-01,2.56

AAN,AAN001,AAN001B,2021-01-01,5.6

ANM,ANM448,ANM448B,2021-04-19,1.2

ANM,ANM448,ANM448C,2021-04-19,3.6

有人可以帮助我一点，我仍然是机器和深度学习的初学者
我已经尝试过 randomforst 但没有成功。
我做了一些研究，结果被告知我们可以使用 LSTM 模型？]]></description>
      <guid>https://stackoverflow.com/questions/78402245/suggestion-about-analysis-and-model-for-forecasting-time-series-in-ml</guid>
      <pubDate>Mon, 29 Apr 2024 11:01:17 GMT</pubDate>
    </item>
    <item>
      <title>Python SkLearn 线性回归的准确度分数给出了无意义的结果</title>
      <link>https://stackoverflow.com/questions/78402227/python-sklearn-accuracy-scores-for-linear-regression-give-nonsensical-results</link>
      <description><![CDATA[我正在参加 Kaggle 房价 竞赛练习我的机器学习技能。我对数据进行预处理，然后使用交叉验证来测试几个不同的模型，看看哪个模型表现最好。不幸的是，尽管我收到了大多数模型的正常结果，但我得到的线性回归结果毫无意义。我发布了我的代码和结果图片，您可以在 Kaggle 竞赛的链接中找到数据文件。您能否向我解释一下为什么我会收到这些结果以及我可以采取哪些措施来解决这些问题？
准确率得分结果
train = pd.read_csv(&#39;train.csv&#39;)

train.dropna（轴= 1，阈值= 1200，就地= True）
train[&#39;SalePrice&#39;] = np.log(train[&#39;SalePrice&#39;])

num_data = list(train.select_dtypes(include=[&#39;float64&#39;, &#39;int64&#39;]).drop([&#39;Id&#39;, &#39;SalePrice&#39;], axis=1))
cat_data = list(train.select_dtypes(include=&#39;object&#39;))

cat_pipeline = Pipeline([(&#39;cat_imputer&#39;, SimpleImputer(strategy=&#39;most_frequent&#39;)), (&#39;编码器&#39;, OneHotEncoder())])
num_pipeline = Pipeline([(&#39;num_imputer&#39;, SimpleImputer(strategy=&#39;median&#39;)), (&#39;scaler&#39;, StandardScaler())])
                         
col_transformer = ColumnTransformer([(&#39;cat_pipeline&#39;, cat_pipeline, cat_data),
                                     (&#39;num_pipeline&#39;, num_pipeline, num_data)], 余数=&#39;drop&#39;)

y = 火车[&#39;销售价格&#39;]
X = train.drop(columns=[&#39;Id&#39;, &#39;SalePrice&#39;])
X = col_transformer.fit_transform(X).toarray()

X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=42)

lin_reg = 线性回归()
sgd = SGDRegressor()
贝叶斯 = BayesianRidge()
树 = DecisionTreeRegressor()
森林 = RandomForestRegressor()
xgb = XGBRegressor()

结果={}
对于 [lin_reg、sgd、bayes、tree、forest、xgb] 中的模型：
    分数 = cross_validate(模型, X_train, y_train, 评分=[&#39;neg_mean_squared_error&#39;, &#39;neg_mean_absolute_error&#39;,
                                                              &#39;explained_variance&#39;, &#39;r2&#39;], cv=10)
    结果[str(model).split(&#39;(&#39;)[0]] = [分数[&#39;test_neg_mean_squared_error&#39;].mean(), 分数[&#39;test_neg_mean_absolute_error&#39;].mean(),
                           分数[&#39;test_explained_variance&#39;].mean(), 分数[&#39;test_r2&#39;].mean()]

pd.options.display.float_format = &#39;{:,.4f}&#39;.format
results_df = pd.DataFrame(数据=结果,
                          index=[&#39;负均方误差&#39;, &#39;负平均绝对误差&#39;, &#39;解释方差得分&#39;, &#39;R2 得分&#39;])
结果_df


我上网查了一下，但没有找到遇到同样问题的人。]]></description>
      <guid>https://stackoverflow.com/questions/78402227/python-sklearn-accuracy-scores-for-linear-regression-give-nonsensical-results</guid>
      <pubDate>Mon, 29 Apr 2024 10:55:30 GMT</pubDate>
    </item>
    <item>
      <title>使用Python从工程图PDF中提取表格[关闭]</title>
      <link>https://stackoverflow.com/questions/78401923/extract-table-from-engineering-drawing-pdf-with-python</link>
      <description><![CDATA[在此处输入图片描述
输入的是pdf文件
我想从中提取表，其中包含 FOOTING SCHEDULE 和项目标题
无论这些信息位于设计中什么
如何做到这一点
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78401923/extract-table-from-engineering-drawing-pdf-with-python</guid>
      <pubDate>Mon, 29 Apr 2024 10:04:06 GMT</pubDate>
    </item>
    <item>
      <title>我们可以将 MobileNet v2 用于 fashinon minst 数据集吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78401789/can-we-mobilenet-v2-for-fashinon-minst-dataset</link>
      <description><![CDATA[我想使用预定义的模型及其基于迁移学习的项目（电子商务）。
我需要知道的是我可以将 mobilenet v2 模型用于时尚 Minst 数据集吗？如果不是，哪种预定义模型更适合迁移学习中的该数据集
谢谢
我尝试了不同的迁移学习教程，但在使用预定义模型时仍然感到困惑]]></description>
      <guid>https://stackoverflow.com/questions/78401789/can-we-mobilenet-v2-for-fashinon-minst-dataset</guid>
      <pubDate>Mon, 29 Apr 2024 09:40:37 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 进行图像分类的迁移学习</title>
      <link>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</link>
      <description><![CDATA[我正在尝试使用已经训练好的模型将学习转移到我将创建并仅修改最后几层的模型。这样做的目标是使用已经训练的模型（已经在数百万张图像上训练）来帮助我的模型对食品识别进行分类。我对 Keras 还很陌生，我面临着一个问题，我现在开始理解它，但不知道如何解决
# 从 TensorFlow Hub 加载模型
model_url =“https://www.kaggle.com/models/tensorflow/resnet-50/TensorFlow2/classification/1”
hub_layer = hub.KerasLayer(model_url, input_shape=(224, 224, 3))

# 创建一个序列模型
模型 = tf.keras.Sequential()

# 将 TensorFlow Hub 层添加到 Sequential 模型中
模型.add(hub_layer)

# 构建顺序模型
模型.build((无, 224, 224, 3))

# 模型总结
模型.summary()

错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValueError Traceback（最近一次调用最后一次）
[56] 中的单元格，第 9 行
      6 模型 = tf.keras.Sequential()
      8 # 将 TensorFlow Hub 层添加到 Sequential 模型中
----&gt; 9 模型.add(hub_layer)
     11 # 构建顺序模型
     12 模型.build((无, 224, 224, 3))

文件c:\Users\Karim\AppData\Local\Programs\Python\Python312\Lib\site-packages\keras\src\models\sequential.py:95，在Sequential.add(self，layer，rebuild)中
     93层=origin_layer
     94 如果不是 isinstance(layer, Layer):
---&gt; 95 引发值错误（
     96、“只有‘keras.Layer’的实例可以是”
     97 f”添加到顺序模型中。收到：{层}”
     98 f“(类型{type(层)})”
     99）
    100 如果不是 self._is_layer_name_unique(layer):
    101 引发值错误（
    102“添加到顺序模型的所有层”
    103 f”应该有唯一的名称。名称“{layer.name}”已经是“”
    104“该模型中层的名称。更新“name”参数“
    105“传递唯一的名称。”
    106）

ValueError：只能将“keras.Layer”的实例添加到顺序模型中。收到： （类型）
]]></description>
      <guid>https://stackoverflow.com/questions/78401636/transfer-learning-using-keras-for-image-classification</guid>
      <pubDate>Mon, 29 Apr 2024 09:15:19 GMT</pubDate>
    </item>
    <item>
      <title>卡在 AWS SageMaker 笔记本实例的 1 个训练单元中</title>
      <link>https://stackoverflow.com/questions/78401011/stuck-at-1-training-cell-in-notebook-instance-in-aws-sagemaker</link>
      <description><![CDATA[我已开始运行命令，使用 Ultralytics YOLOv8.2.4 训练模型。
大多数先决条件应该已经安装。但是，每当我运行单元时，它都会卡在以下位置：
开始训练 100 个 epoch...

Epoch GPU_mem box_loss cls_loss dfl_loss Instances Size
0%| | 0/143 [00:00&lt;?, ?it/s]

之后它会卡在那里几个小时而没有任何变化，并且单元停止运行。
有一次我停止了笔记本并尝试重新启动，我收到以下错误消息：
IOStream.flush 超时

有人知道问题是什么吗？
我当前的 Jupyter Notebook 实例正在 ml.t3.medium 上运行
我尝试过重启笔记本实例，但似乎没有开始训练。我也尝试过在 google colab 上操作，效果很好。]]></description>
      <guid>https://stackoverflow.com/questions/78401011/stuck-at-1-training-cell-in-notebook-instance-in-aws-sagemaker</guid>
      <pubDate>Mon, 29 Apr 2024 07:07:23 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：在 LSTM 时间序列预测中发现输入变量样本数量不一致</title>
      <link>https://stackoverflow.com/questions/78400794/valueerror-found-input-variables-with-inconsistent-numbers-of-samples-in-lstm-t</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78400794/valueerror-found-input-variables-with-inconsistent-numbers-of-samples-in-lstm-t</guid>
      <pubDate>Mon, 29 Apr 2024 06:16:48 GMT</pubDate>
    </item>
    <item>
      <title>Keras TextVectorization 似乎区分大小写，即使词汇量没有反映这一点？</title>
      <link>https://stackoverflow.com/questions/78400462/keras-textvectorization-seems-to-be-case-sensitive-even-though-vocabulary-doesn</link>
      <description><![CDATA[我有以下代码
导入 keras

v = {
    “甲板”：[&#39;a&#39;，&#39;B&#39;，&#39;C&#39;，&#39;D&#39;，&#39;E&#39;，&#39;F&#39;，&#39;G&#39;，&#39;H&#39;，&#39;I&#39;，&#39;J&#39;，&#39;K&#39;， &#39;L&#39;]
}

打印（len（v[“甲板”]））

l = keras.layers.TextVectorization(
    max_tokens=len(v[“甲板”])+2,
    词汇=v[“甲板”],
    输出模式=&#39;计数&#39;,
    名称=“甲板”）

打印（l.vocabulary_size（））
打印（l.get_vocabulary（））

print(l(&#39;a A b B&#39;))

输出是：
&lt;前&gt;&lt;代码&gt;12
13
[&#39;[UNK]&#39;、&#39;a&#39;、&#39;B&#39;、&#39;C&#39;、&#39;D&#39;、&#39;E&#39;、&#39;F&#39;、&#39;G&#39;、&#39;H&#39;、&#39;I&#39;、&#39;J&#39;、&#39;K&#39; ，&#39;L&#39;]
tf.Tensor([2.2.0.0.0.0.0.0.0.0.0.0.0.],形状=(13,),dtype=float32)

我希望至少有一个 b 能够被计算在内。
如果我使用l.adapt(v[“deck”])，事情似乎会相应地工作，但词汇都是小写的。
像这样：
导入 keras

v = {
    “甲板”：[&#39;a&#39;，&#39;B&#39;，&#39;C&#39;，&#39;D&#39;，&#39;E&#39;，&#39;F&#39;，&#39;G&#39;，&#39;H&#39;，&#39;I&#39;，&#39;J&#39;，&#39;K&#39;， &#39;L&#39;]
}

打印（len（v[“甲板”]））

l = keras.layers.TextVectorization(
    max_tokens=len(v[“甲板”])+2,
    # 词汇=v[“甲板”],
    输出模式=&#39;计数&#39;,
    名称=“甲板”）

l.adapt(v[&#39;甲板&#39;])

打印（l.vocabulary_size（））
打印（l.get_vocabulary（））

print(l(&#39;a A b B&#39;))

和输出：
&lt;前&gt;&lt;代码&gt;12
13
[&#39;[UNK]&#39;、&#39;l&#39;、&#39;k&#39;、&#39;j&#39;、&#39;i&#39;、&#39;h&#39;、&#39;g&#39;、&#39;f&#39;、&#39;e&#39;、&#39;d&#39;、&#39;c&#39;、&#39;b&#39; ， &#39;A&#39;]
tf.Tensor([0.0.0.0.0.0.0.0.0.0.0.2.2.]，形状=(13,)，dtype=float32)

如何正确使用词汇参数？]]></description>
      <guid>https://stackoverflow.com/questions/78400462/keras-textvectorization-seems-to-be-case-sensitive-even-though-vocabulary-doesn</guid>
      <pubDate>Mon, 29 Apr 2024 04:20:18 GMT</pubDate>
    </item>
    <item>
      <title>GKE 上的 GPU 时间共享</title>
      <link>https://stackoverflow.com/questions/78400223/gpu-time-sharing-on-gke</link>
      <description><![CDATA[我正在尝试使用 说明中的 GPU 时间共享此处，但是我的工作负载不会在启用分时的节点上运行。
我有一个具有 GPU 配置的节点池，启用了策略分时的 GPU 共享以及“每个 GPU 的最大共享客户端数”。如 48 所示。节点运行良好，但我无法使用记录的 nodeSelector 配置为我的工作负载运行工作负载，例如
节点选择器：
  cloud.google.com/gke-accelerator：“nvidia-tesla-t4”
  cloud.google.com/gke-max-shared-clients-per-gpu：“48”
  cloud.google.com/gke-gpu-sharing-strategy：分时

这样，我的 Pod 就会陷入挂起状态，并显示消息xnodes did not match Pod&#39;s nodeaffinity/selector。如果我删除 gke-max-shared-clients-per-gpu 和 gke-gpu-sharing-strategy 密钥对，pod 会正常调度并运行。
当我检查 GPU 分时节点池中节点上的 kubernetes 标签时，它们不包含这些标签，并且我无法手动添加它们，因为 GCP 阻止了它。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78400223/gpu-time-sharing-on-gke</guid>
      <pubDate>Mon, 29 Apr 2024 02:20:41 GMT</pubDate>
    </item>
    <item>
      <title>用于无人机基地垃圾检测的城市固体废物数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/78390012/msw-data-set-for-drone-base-garbage-detection</link>
      <description><![CDATA[我的项目需要一个根据 MSW 进行标记和分类的城市固体废物数据集，该项目是使用 Raspberry Pi 进行无人机基础垃圾检测。
我检查了 Kaggle &amp; Roboflow，但没有为我的项目获得任何有用的数据集。]]></description>
      <guid>https://stackoverflow.com/questions/78390012/msw-data-set-for-drone-base-garbage-detection</guid>
      <pubDate>Fri, 26 Apr 2024 11:08:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 Raspberry Pi 4 在 Python 中崩溃的多线程 [关闭]</title>
      <link>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</link>
      <description><![CDATA[我在尝试使用 Raspberry Pi 4B 完成大学项目时遇到问题。
该项目使用 Python 编写，由 5 个线程组成，其中 2 个线程运行机器学习预测，第 3 个线程按顺序运行一系列计算，以达到与机器学习模型预测的输出相同的输出（这样我可以对比输出是否是合理的值）。另外两个线程是：一个等待 10 秒并激活一个标志（开始处理所需的标志），另一个在终端上打印值（都是从 ML 模型和计算中预测的）。
我的问题是，当我尝试同时运行所有线程时，ML 模型运行正确，但我的计算线程不执行任何操作。相反，如果我不启动 ML 线程，计算线程就会正常工作。
我认为Raspberry没有足够的计算能力，因此计算线程崩溃了。
没有必要所有 3 个线程同时运行（我希望能够选择是否要查看终端上打印的 ML 预测或计算输出），因此我尝试禁用线程当我不使用它们时（使用 thread.join() ）并在我决定希望该线程再次开始运行时再次启动它们（thread.start() ）但它无法正常工作。
我还尝试过使用运行预测或计算函数所需的两个标志（ML_flag 和calculations_flag），但也不起作用。
关于我可以使用的其他技术的任何想法，以便 ML 预测和计算单独运行并且不会崩溃？
谢谢！
下图显示了命令htop：
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</guid>
      <pubDate>Fri, 19 Apr 2024 08:31:18 GMT</pubDate>
    </item>
    </channel>
</rss>