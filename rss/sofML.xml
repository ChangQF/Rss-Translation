<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 05 Oct 2024 12:30:57 GMT</lastBuildDate>
    <item>
      <title>如果两个基因组没有匹配的连接，如何获得 NEAT 算法中兼容性距离的平均权重差异[关闭]</title>
      <link>https://stackoverflow.com/questions/79055601/how-do-i-get-the-average-weight-difference-for-the-compatibility-distance-in-a-n</link>
      <description><![CDATA[由于计算两个基因组的兼容性距离的公式包括平均权重差异，如果它们没有一个匹配的连接，就会出现问题。通常，你会通过将总权重差异除以共享权重的总量来计算平均权重差异。但由于你不能用 0 除以某个数，所以这是一个问题。
我可以将平均权重差异设置为无穷大或一个非常大的数字吗？或者有更好的解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/79055601/how-do-i-get-the-average-weight-difference-for-the-compatibility-distance-in-a-n</guid>
      <pubDate>Fri, 04 Oct 2024 19:28:30 GMT</pubDate>
    </item>
    <item>
      <title>我的梯度下降实现有什么问题（带铰链损失的 SVM 分类器）</title>
      <link>https://stackoverflow.com/questions/79055573/what-is-wrong-with-my-gradient-descent-implementation-svm-classifier-with-hinge</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79055573/what-is-wrong-with-my-gradient-descent-implementation-svm-classifier-with-hinge</guid>
      <pubDate>Fri, 04 Oct 2024 19:19:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Google Cloud Services 设计实时产品建议管道？[关闭]</title>
      <link>https://stackoverflow.com/questions/79055177/how-to-design-a-real-time-product-suggesting-pipeline-using-google-cloud-service</link>
      <description><![CDATA[我正在考虑一个用例，我需要使用谷歌云功能进行设计。
案例是：
假设用户正在点击一个产品。
该产品 ID 将被发送到实时流式数据流管道，
它将选择与该产品相关的更多项目并
将该产品 ID 发送回该特定用户。
然后该 ID 将用于获取产品信息，并将在页面上的某个位置呈现，例如 -&gt; 您可能喜欢的部分。
信息将存储在 Bigtable 中，这样我们就可以非常快速地获取我们的产品 ID，因为 Bigtable 具有非常高的吞吐量。
现在的问题是，如何将 ID 发送回同一个用户，以便该产品在该特定用户窗口中呈现，而不是其他用户？
如果有人有更好的方法，他们也可以提到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/79055177/how-to-design-a-real-time-product-suggesting-pipeline-using-google-cloud-service</guid>
      <pubDate>Fri, 04 Oct 2024 16:39:19 GMT</pubDate>
    </item>
    <item>
      <title>分类器的数据集极度不平衡[关闭]</title>
      <link>https://stackoverflow.com/questions/79055091/extremely-imbalanced-dataset-for-a-classifier</link>
      <description><![CDATA[我正在研究一种二分类器。我面临的挑战是我的数据集是多么的不平衡。只有 2% 的行属于 A 类（正）。剩下的 98% 属于 B 类（负）。
在这种情况下，获得很高的准确率并不意味着什么。你可以想象我追求的是真正的阳性。
我曾尝试在 Azure 机器学习设计器上使用 SMOTE，但得到的结果很差。为了防止发生任何数据泄露，我在拆分数据后应用了 SMOTE。
我曾尝试过自动化机器学习，希望它能以某种方式处理不平衡的数据集，但事实并非如此。它只是向我发送了一条关于 Imalabace 类的警告消息。结果也很糟糕。
我想知道我是否也可以应用 SMOTE 和可能的 Tomek Links，但仅限于 Auto ML 的训练数据集。
我想我需要去笔记本，复制排名最高的自动化模型的代码，并对其进行调整，以便我可以将这些转换仅应用于训练部分（如果可能的话）。此外，通过这样做，我不会使用自动化 ML 的功能，但我只使用自动化 ml 生成的模型之一。
有什么想法和指导吗？
在 Azure ML Designer 上应用了 SMOTE，希望更平衡的训练数据集能够帮助模型学习。但是我得到的结果并不好。
我尝试使用 AutomatedML，因为我读到它有一些内置功能可以帮助解决不平衡的数据集。但是，我没有看到任何进展。
在这两种情况下，我选择的指标都是精度。我也尝试了 Designer AUC 加权，但没有任何改善。]]></description>
      <guid>https://stackoverflow.com/questions/79055091/extremely-imbalanced-dataset-for-a-classifier</guid>
      <pubDate>Fri, 04 Oct 2024 16:10:32 GMT</pubDate>
    </item>
    <item>
      <title>nnUNetv2_plan_and_preprocess：未找到命令</title>
      <link>https://stackoverflow.com/questions/79054923/nnunetv2-plan-and-preprocess-command-not-found</link>
      <description><![CDATA[在程序中，U-Mamba，
当我运行
nnUNetv2_plan_and_preprocess -d 701 --verify_dataset_integrity

它显示
nnUNetv2_plan_and_preprocess：未找到命令

我的运行环境：
Ubuntu 20.04.6 LTS (GNU/Linux 5.15.0-101-generic x86_64)
RTX 2080ti，RTX 3090
这些事情已经完成：

conda activate env-...
torch with cuda
causal-conv1d
mamba-ssm
umamba pip install -e .
nnunetv2 pip install -e .
nnU-Net 数据集格式
导出 nnUNet_raw、nnUNet_preprocessed、nnUNet_results
]]></description>
      <guid>https://stackoverflow.com/questions/79054923/nnunetv2-plan-and-preprocess-command-not-found</guid>
      <pubDate>Fri, 04 Oct 2024 15:22:50 GMT</pubDate>
    </item>
    <item>
      <title>多模态命名实体识别</title>
      <link>https://stackoverflow.com/questions/79054866/multimodal-named-entity-recognition</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79054866/multimodal-named-entity-recognition</guid>
      <pubDate>Fri, 04 Oct 2024 15:08:57 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Pytorch 中将 DistributedSampler 与类权重结合使用？</title>
      <link>https://stackoverflow.com/questions/79052969/how-to-use-class-weights-with-distributedsampler-in-pytorch</link>
      <description><![CDATA[我有一个高度不平衡的数据集，需要在多 GPU 设置上进行训练。在单个 GPU 上，类不平衡可以通过 WeightedRandomSampler 来处理。然后我会将采样器对象传递给 DataLoader。但在多 GPU 设置中，由于我使用 DistributedSampler 作为采样器，因此我无法以相同的方式传递 WeightedRandomSampler。如何在我的 DataLoader 中同时使用两者？
这是我使用 DistributedSampler 的代码：
train_dataset = SampleDataset(data_root=data_root, transform=train_transforms, num_classes=num_classes)
train_sampler = DistributedSampler(train_dataset, num_replicas=world_size)
train_loader = DataLoader(train_dataset,
batch_size=batch_size,
pin_memory=True,
sampler=train_sampler,
num_workers=0)

]]></description>
      <guid>https://stackoverflow.com/questions/79052969/how-to-use-class-weights-with-distributedsampler-in-pytorch</guid>
      <pubDate>Fri, 04 Oct 2024 05:51:45 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：如果没有传递“decoder_input_ids”或“decoder_inputs_embeds”，则“input_ids”不能为“None”</title>
      <link>https://stackoverflow.com/questions/79052681/valueerror-if-no-decoder-input-ids-or-decoder-inputs-embeds-are-passed-in</link>
      <description><![CDATA[我正在尝试获取佛罗伦萨 2 模型的解码器隐藏状态。我按照这个 https://huggingface.co/microsoft/Florence-2-large/blob/main/modeling_florence2.py 来了解前向方法中的参数。我尝试了类似这样的方法
# 使用 output_hidden_​​states=True 将输入传递给模型以获取隐藏状态
with torch.no_grad():
outputs = model(
input_ids=inputs[&quot;input_ids&quot;],
pixel_values=inputs[&quot;pixel_values&quot;],
tention_mask=inputs[&quot;attention_mask&quot;],
output_hidden_​​states=True, # 请求隐藏状态
)

但是执行此操作时出现此错误：
ValueError：如果未传递 decoder_input_ids 或 decoder_inputs_embeds，则 input_ids 不能为 None。请传递 input_ids 或 decoder_input_ids 或 decoder_inputs_embeds。
我无法完全理解错误，因为它说“input_ids 不能为 None”但我的 input_ids 不是 None。它类似于：
tensor([[ 0, 2264, 473, 5, 2274, 6192, 116, 2]], device=&#39;cuda:1&#39;)
此外，我仅使用此模型进行推理，decoder_input_ids 是什么意思，我可以在哪里找到它以在前向方法中传递。]]></description>
      <guid>https://stackoverflow.com/questions/79052681/valueerror-if-no-decoder-input-ids-or-decoder-inputs-embeds-are-passed-in</guid>
      <pubDate>Fri, 04 Oct 2024 02:40:48 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：从“视频息肉分割：深度学习视角”复制代码时编译扩展对象时出错</title>
      <link>https://stackoverflow.com/questions/79049069/runtimeerror-error-compiling-objects-for-extension-when-copying-code-from-vide</link>
      <description><![CDATA[当我尝试从一篇名为“视频息肉分割：深度学习视角”的论文中复制代码并按照步骤“python setup.py build evolve”时，它总是提到“RuntimeError：编译扩展对象时出错”。还有很多错误：
回溯（最近一次调用最后一次）：
文件“/home/jinghong/VPS/lib/module/PNS/setup.py”，第 17 行，位于&lt;module&gt;
setup(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/__init__.py&quot;, 第 117 行, 在 setup 中
return distutils.core.setup(**attrs)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/core.py&quot;, 第 183 行, 在 setup 中
return run_commands(dist)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/core.py&quot;, 第 199 行, 在 run_commands 中
dist.run_commands()
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/dist.py&quot;, 第 954 行, 在 run_commands 中
self.run_command(cmd)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/dist.py&quot;, 第 950 行, 在 run_command 中
super().run_command(command)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/dist.py&quot;, 第 973 行, 在 run_command 中
cmd_obj.run()
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build.py&quot;，第 135 行，在 run_command 中
self.run_command(cmd_name)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/cmd.py&quot;，第 316 行，在 run_command 中
self.distribution.run_command(command)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/dist.py&quot;，第 950 行，在 run_command 中
super().run_command(command)
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/dist.py&quot;，第 973 行，在 run_command 中
cmd_obj.run()
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/command/build_ext.py&quot;，第 98 行，在 run 中
_build_ext.run(self)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;，第 359 行，在 run 中
self.build_extensions()
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;，第 709 行，位于 build_extensions
build_ext.build_extensions(self)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;，第 476 行，位于 build_extensions
self._build_extensions_serial()
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;，第 502 行，位于 _build_extensions_serial
self.build_extension(ext)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/command/build_ext.py&quot;, 第 263 行, 在 build_extension
_build_ext.build_extension(self, ext)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;, 第 557 行, 在 build_extension
objects = self.compiler.compile(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;, 第 530 行, 在unix_wrap_ninja_compile
_write_ninja_file_and_compile_objects(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;, 行 1355, 位于 _write_ninja_file_and_compile_objects
_run_ninja_build(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;, 行 1682, 位于 _run_ninja_build
raise RuntimeError(message) from e
RuntimeError: 编译扩展对象时出错

我不知道如何解决这个问题，有人能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/79049069/runtimeerror-error-compiling-objects-for-extension-when-copying-code-from-vide</guid>
      <pubDate>Thu, 03 Oct 2024 03:55:10 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 torchmeta 冲突</title>
      <link>https://stackoverflow.com/questions/79034188/how-to-fix-torchmeta-conflicts</link>
      <description><![CDATA[尝试使用 google colab 安装“torchmeta”。但显示以下错误：
错误：无法安装 torchmeta==1.1.0、torchmeta==1.1.1、torchmeta==1.2.0、torchmeta==1.2.1、torchmeta==1.2.2、torchmeta==1.3.0、torchmeta==1.3.1、torchmeta==1.3.2、torchmeta==1.3.3、torchmeta==1.3.4、torchmeta==1.4.0、torchmeta==1.4.1、torchmeta==1.4.2、torchmeta==1.4.3、torchmeta==1.4.4、torchmeta==1.4.5、torchmeta==1.4.6， torchmeta==1.5.0、torchmeta==1.5.1、torchmeta==1.5.2、torchmeta==1.5.3、torchmeta==1.6.0、torchmeta==1.6.1、torchmeta==1.7.0 和 torchmeta==1.8.0，因为这些软件包版本存在依赖冲突。

冲突的原因是：
torchmeta 1.8.0 依赖于 torch&lt;1.10.0 和 &gt;=1.4.0
torchmeta 1.7.0 依赖于 torch&lt;1.9.0 和 &gt;=1.4.0
torchmeta 1.6.1 依赖于 torch&lt;1.8.0 和 &gt;=1.4.0
要解决此问题，您可以尝试：
1. 放宽您指定的软件包版本范围
2. 删除软件包版本以允许 pip 尝试解决依赖项冲突

我需要有人帮助我解决这个问题，我也尝试安装较低版本的 pytorch，但我不能，有什么方法可以安装 torchmeta，请等待详细答复。我使用的是 windows (google colab) Pytorch-geometric 2.3.1]]></description>
      <guid>https://stackoverflow.com/questions/79034188/how-to-fix-torchmeta-conflicts</guid>
      <pubDate>Sat, 28 Sep 2024 12:32:30 GMT</pubDate>
    </item>
    <item>
      <title>BigQuery Arima Plus 预测高于预期</title>
      <link>https://stackoverflow.com/questions/79032297/bigquery-arima-plus-forecasts-are-higher-than-expected</link>
      <description><![CDATA[我试图以 15 分钟的分辨率预测来自许多不同设备（1000 个，出于性能原因在几百个设备上进行测试）的值。所有设备都记录：名称和值。我尝试过不同的时间范围进行训练，但到目前为止还没有成功。
问题的一些示例：
设备始终记录 40 -&gt; Arima 从第一次预测（30 天训练）开始预测 20-80 的范围
设备记录 60-64 -&gt; Arima 预测 65-120 个峰值，然后在 102 时趋于平稳（1 天训练）。我正在努力理解 Arima plus 如何得出比训练数据集中的所有值都高出数量级的值。
这是 arima plus 模型创建和预测的伪代码：
我使用摘要表作为数据源，数据分辨率为 15 分钟
训练：
CREATE OR REPLACE MODEL predictioning.model
OPTIONS(
MODEL_TYPE=&#39;ARIMA_PLUS&#39;
,TIME_SERIES_TIMESTAMP_COL=&#39;timestamp&#39;
,TIME_SERIES_DATA_COL=&#39;value&#39;
,TIME_SERIES_ID_COL=&#39;id&#39;
-- ,auto_arima = TRUE
,clean_spikes_and_dips = FALSE
,adjust_step_changes = FALSE
-- ,data_frequency = &#39;AUTO_FREQUENCY&#39;
-- ,auto_arima_max_order = 2 -- 默认值为 5
-- ,max_time_series_length = 96 -- 1 d?
) AS
(
SELECT timestamp
,id
,SUM(value) as value

FROM `forecasting.summary`
WHERE CAST(TIMESTAMP_TRUNC(timestamp, DAY) AS DATE) &lt; _CUTOFF_DATE
AND CAST(TIMESTAMP_TRUNC(timestamp, DAY) AS DATE) &gt;= DATE_ADD(CURRENT_DATE(), INTERVAL _PERIOD DAY)
GROUP BY 1,2

);

虽然我确实使用了 SUM(value)，但很确定它只有 1 行的总和。从其他尝试中得出。
SELECT 
id
,forecast_timestamp as timestamp
,forecast_value as value
,standard_error 
,confidence_level 
,prediction_interval_lower_bound 
,prediction_interval_upper_bound
FROM 
ML.FORECAST(MODEL `forecasting.forecast`
,STRUCT(672 as horizo​​n -- 192 is 2d; 672 is 7d 
,0.95 as confidence_level
)
)
;

过去对我有用的一种方法是将每 15m 预测为其自己的时间序列。问题是，在这种情况下，它会导致数万或数十万个时间序列。虽然 ArimaPlus 声称能够处理数百万个数据，但如果我进行 30 天训练并且不限制最大 pdq，它的训练性能就已经很慢了。
我在预测表现出每日和每周季节性的数据时也遇到了类似的问题。在当前设备数据的情况下，可能存在与气候和天气条件相关的每日和年度季节性。
我怎样才能让 Arima 发挥作用？如果不行，你会推荐什么方法？]]></description>
      <guid>https://stackoverflow.com/questions/79032297/bigquery-arima-plus-forecasts-are-higher-than-expected</guid>
      <pubDate>Fri, 27 Sep 2024 16:57:25 GMT</pubDate>
    </item>
    <item>
      <title>总参数：0，执行 model.summary() keras</title>
      <link>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</link>
      <description><![CDATA[model = Sequential()
model.add(Embedding(283, 100, input_length=56))
model.add(LSTM(150))
model.add(LSTM(150))
model.add(Dense(283,activation=&#39;softmax&#39;))

model.compile(loss=&#39;categorical_crossentropy&#39;,optimizer=&#39;adam&#39;,metrics=[&#39;accuracy&#39;])

model.summary()

Tensorflow 版本：2.16.1，
Keras 版本：3.3.3，
设备 - M3 pro macbook
我尝试使用虚拟数据集（有 282 个唯一单词，使用 tokenizer 检查）构建用于文本生成的 LSTM 模型，预期参数为非零，但输出每个层都有 0 个参数。]]></description>
      <guid>https://stackoverflow.com/questions/78462277/total-params-0-on-doing-model-summary-keras</guid>
      <pubDate>Fri, 10 May 2024 19:49:53 GMT</pubDate>
    </item>
    <item>
      <title>如何定义仅部分可训练的 PyTorch 张量</title>
      <link>https://stackoverflow.com/questions/77737016/how-to-define-pytorch-tensor-that-is-only-partially-trainable</link>
      <description><![CDATA[我正在尝试构建一个自定义模型来在 PyTorch 中训练，长话短说，我需要构建一个张量，其中除矩形次对角线块之外的所有元素都设置为零，至关重要的是，优化过程应该只触及这个次对角线块的元素，而所有零保持不变。为此，我定义了一个自定义 pytorch 网络，并使用 nn.Parameter 定义了我的矩形块
class My_Network(nn.Module):
def __init__(self , vertical_dim , Horizo​​ntal_dim):
super().__init__()
self.total_dim = vertical_dim + Horizo​​ntal_dim
self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , Horizo​​ntal_dim))


这样，如果我错了，请纠正我，PyTorch 应该用随机值初始化这个张量的值，并将它们注册为训练期间要优化的模型的参数。但是现在我陷入了困境，我想告诉 PyTorch 构建一个方阵张量，其维度等于 self.total_dim，除了次对角线块之外，其余均为零，正如我在计算中所说，我将在前向方法中定义 pytorch 应该只训练次对角线块。
我可以根据需要添加零张量，而无需将其设置为模型参数，如下所示（如果我没记错的话）：
class My_Network(nn.Module):
def __init__(self , vertical_dim , Horizo​​ntal_dim):
super().__init__()
self.total_dim = vertical_dim + Horizo​​ntal_dim
self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , Horizo​​ntal_dim))
self.total_zero_tensor = torch.zeros(self.total_dim, self.total_dim)


但是现在我该如何告诉 PyTorch 将我的下对角线块插入这个零矩阵的左下角？我需要定义这个矩阵以便进行计算（我需要执行矩阵乘法），但至关重要的是，只有小的下对角线块才被视为一组要训练的参数。]]></description>
      <guid>https://stackoverflow.com/questions/77737016/how-to-define-pytorch-tensor-that-is-only-partially-trainable</guid>
      <pubDate>Sat, 30 Dec 2023 18:32:49 GMT</pubDate>
    </item>
    <item>
      <title>文件名中的键值对是否有标准的文件命名约定？[关闭]</title>
      <link>https://stackoverflow.com/questions/10087079/is-there-a-standard-file-naming-convention-for-key-value-pairs-in-filename</link>
      <description><![CDATA[我有多个以它们所包含的内容命名的数据文件。例如
machine-testM_pid-1234_key1-value1.log

键和值由 - 和 _ 分隔。有没有更好的语法？有没有自动读取这些文件/文件名的解析器？
这里的想法是文件名是人类和机器可读的。]]></description>
      <guid>https://stackoverflow.com/questions/10087079/is-there-a-standard-file-naming-convention-for-key-value-pairs-in-filename</guid>
      <pubDate>Tue, 10 Apr 2012 10:32:32 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的学习曲线是什么？</title>
      <link>https://stackoverflow.com/questions/4617365/what-is-a-learning-curve-in-machine-learning</link>
      <description><![CDATA[我想知道机器学习中的学习曲线是什么。绘制它的标准方法是什么？我的意思是我的图的 x 轴和 y 轴应该是什么？]]></description>
      <guid>https://stackoverflow.com/questions/4617365/what-is-a-learning-curve-in-machine-learning</guid>
      <pubDate>Thu, 06 Jan 2011 16:48:44 GMT</pubDate>
    </item>
    </channel>
</rss>