<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 28 Dec 2023 09:13:52 GMT</lastBuildDate>
    <item>
      <title>有没有办法解决在创建 kfp 管道时使用 @pipeline() 时给出的类型错误？</title>
      <link>https://stackoverflow.com/questions/77725948/is-there-a-way-to-sole-the-type-error-given-while-using-pipeline-while-creati</link>
      <description><![CDATA[在 Kfp 管道中使用 pipleine() 装饰器时，它会给出管道类型错误。
@pipeline(name=&quot;basic-pipeline&quot;,
         pipeline_root = PIPELINE_ROOT + “基本管道”)
def basic_pipeline(a:str = &quot;stres&quot;, b:str = &quot;sed&quot;): #pipeline 有 2 个参数
    concat_task = concat(a,b) # 上面定义的 2 个组件
    verse_task = reverse(concat_task.output) # pipeline 的参数是第一个组件的输入。
                                               
]]></description>
      <guid>https://stackoverflow.com/questions/77725948/is-there-a-way-to-sole-the-type-error-given-while-using-pipeline-while-creati</guid>
      <pubDate>Thu, 28 Dec 2023 09:11:23 GMT</pubDate>
    </item>
    <item>
      <title>脑肿瘤生存模型的预测结果是二元的——如何解释？</title>
      <link>https://stackoverflow.com/questions/77725853/predicted-results-from-brain-tumor-survival-model-are-binary-how-to-interpret</link>
      <description><![CDATA[我正在使用 BraTS20 数据集进行“脑肿瘤总体生存预测”。
模型的输出是一个二进制数组，但是如何预测患者的生存时间？
为什么预测结果是二进制的？
如何在脑肿瘤生存时间的背景下解释这些二元结果？
我需要对模型或后处理步骤进行任何具体调整吗？
这里是数据转换成数组的地方
def getListAgeDays(id_list): # 仅创建年龄：类别数据

    x_val = [] # 初始化一个空列表来存储特征数据
    y_val = [] # 初始化一个空列表来存储类别标签
    对于 id_list 中的 i：
        if (i not in age_dict): # 检查 &#39;i&#39; 是否存在于 &#39;age_dict&#39; 字典中
            继续
        mask = getMaskSizesForVolume(nib.load(TRAIN_DATASET_PATH + f&#39;\\BraTS20_Training_{i[-3:]}/BraTS20_Training_{i[-3:]}_seg.nii&#39;).get_fdata())
        # 加载分割掩码并提取其大小信息
        Brain_vol = getBrainSizeForVolume(nib.load(TRAIN_DATASET_PATH + f&#39;\\BraTS20_Training_{i[-3:]}/BraTS20_Training_{i[-3:]}_t1.nii&#39;).get_fdata())
        # 加载大脑体积图像并提取其大小信息
        mask[1] = mask[1]/brain_vol # 标准化 mask 的大小
        掩码[2] = 掩码[2]/brain_vol
        掩码[3] = 掩码[3]/brain_vol
        合并 = [age_dict[i]、掩码[1]、掩码[2]、掩码[3]]
        # 通过将“age_dict[i]”与掩码大小值相结合来创建特征向量
        radiomics_values = df_radiomics.loc[df_radiomics[&#39;目标&#39;] == str(i)]
        # 查询 DataFrame &#39;df_radiomics&#39; 中与 &#39;i&#39; 相关的放射组学值
        如果 radiomics_values.empty：
            continue # 如果没有放射组学值则跳过本次迭代
        merged.extend(radiomics_values.values.tolist()[0][:-1])
        # 将放射组学值添加到“合并”特征向量（不包括最后一个值）
        x_val.append(merged) # 将特征向量附加到 &#39;x_val&#39;
        如果（days_dict[i] &lt; 250）：
            y_val.append([1, 0, 0]) # 根据 &#39;days_dict&#39; 条件附加类别标签
        elif (days_dict[i] &gt;= 250 且 days_dict[i] &lt; 450):
            y_val.append([0, 1, 0])
        别的：
            y_val.append([0, 0, 1])
    return np.array(x_val), np.array(y_val) # 以 NumPy 数组形式返回特征数据和类别标签

X_all, y_all = getListAgeDays(brats_ids) # 使用 &#39;train_and_test_ids&#39; 调用该函数
print(f&#39;X_test: {X_all.shape}&#39;) # 打印特征数据的形状

将模型保存到Joblib中
joblib.dump(model, &#39;model_joblib&#39;)
mj = joblib.load(&#39;model_joblib&#39;)
包含您获得的预测结果的示例
mj.predict(X_test) 输出为： array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0])]]></description>
      <guid>https://stackoverflow.com/questions/77725853/predicted-results-from-brain-tumor-survival-model-are-binary-how-to-interpret</guid>
      <pubDate>Thu, 28 Dec 2023 08:51:33 GMT</pubDate>
    </item>
    <item>
      <title>Llama 2 上的 PEFT QLoRA 培训</title>
      <link>https://stackoverflow.com/questions/77725437/peft-qlora-training-on-llama-2</link>
      <description><![CDATA[这是一个更具概念性的问题。我正在尝试在 Llama 2 上执行 PEFT QLoRA，特别是在 imdb 电影评论数据集上。我仅使用 650 个样本进行训练，使用 650 个样本进行测试。我使用了“meta-llama/Llama-2-7b-chat-hf”模型作为我的基本 llama 2 模型。使用 SFTTrainer 训练后，我将模型保存到目录中。如果我没有记错的话，只有适配器权重会保存到目录中，而不是整个模型权重。完成此操作后，我知道这些适配器权重可以与原始模型权重一起加载。
模型 = PeftModel.from_pretrained(
    模型，
    “./my_dir”，
）

完成此操作后，我们应该将这些适配器权重合并到原始模型
merged_model = model.merge_and_unload()

但是，当我使用此 merged_model 进行推理时，我注意到性能非常差，因为仅对 PEFT 加载的模型进行推理，即来自
模型 = PeftModel.from_pretrained(
    模型，
    “./my_dir”，
）

是理想的。这种行为是预期的吗？我正在这样进行推理
tokenizer = AutoTokenizer.from_pretrained(“meta-llama/Llama-2-7b-chat-hf”)
管道=变压器.管道(
    “文本生成”，
    型号=型号，
    分词器=分词器，
    torch_dtype=torch.float16,
    device_map=“自动”，
）

序列=管道（
    迅速的，
    do_sample=真，
    顶部_k=10,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
    最大长度=500，
）
对于序列中的 seq：
    print(f&quot;结果：{seq[&#39;生成的文本&#39;]}&quot;)

还有什么我可以做得更好的吗？]]></description>
      <guid>https://stackoverflow.com/questions/77725437/peft-qlora-training-on-llama-2</guid>
      <pubDate>Thu, 28 Dec 2023 07:01:41 GMT</pubDate>
    </item>
    <item>
      <title>在训练神经网络模型时，如何在 matlab 中编写 Garson 算法来查找参数的相对重要性？</title>
      <link>https://stackoverflow.com/questions/77725247/how-do-you-code-garsons-algorithm-in-matlab-to-find-the-relative-importance-of</link>
      <description><![CDATA[我正在进行一项预测分析研究，并遇到了加森算法，但我在为其编写公式时遇到了麻烦。这是我的代码：
&lt;前&gt;&lt;代码&gt;
%%% 数据输入
输入=数据(:, 1:4)&#39;;
目标=数据(:, 5)&#39;;

%%% 创建前馈神经网络
净 = 前馈网络([10, 15, 20]);

%%%% 设置每个隐藏层的神经元数量
net.layers{1}.size = 10;
net.layers{2}.size = 15;
net.layers{3}.size = 20;

%%%% 更改激活函数（例如，将输出层的“tansig”更改为“purelin”）
net.layers{1}.transferFcn = &#39;tansig&#39;; % 第一个隐藏层的激活函数
net.layers{2}.transferFcn = &#39;tansig&#39;; % 第二隐藏层的激活函数
net.layers{3}.transferFcn = &#39;tansig&#39;; % 第三隐藏层的激活函数
net.layers{4}.transferFcn = &#39;purelin&#39;; % 输出层的激活函数

%%%% 划分数据进行训练、验证和测试
net.divideParam.trainRatio = 0.7;
net.divideParam.valRatio = 0.15;
net.divideParam.testRatio = 0.15;

%%%% 训练神经网络
[net, tr] = train(net, 输入, 目标);

%%%%计算Garson的重要性
重要性= garsonsAlgorithm(net);

%%%% 显示特征重要性
disp(&#39;特征重要性（Garson 算法）:&#39;);
对于 i = 1：长度（重要性）
    disp([&#39;x 的重要性&#39; num2str(i) &#39;: &#39; num2str(importance(i))]);
结尾

&lt;前&gt;&lt;代码&gt;
这是我写的garson算法函数：

函数重要性 = garsonsAlgorithm(net)
    %%% 从神经网络中提取连接权重
    权重 = cell2mat(net.IW);
    
    % 检查权重是否存在偏差
    如果 isfield(net, &#39;b&#39;)
        bias_weights = cell2mat(net.b);
        权重 = [权重;偏差权重]；
    结尾
    
    %%%计算权重的绝对值
    绝对权重=abs(权重);
    
    %%%计算每个输入特征的重要性
    重要性 = sum(absolute_weights, 1);
    
    %%% 标准化重要性值
    重要性=重要性/总和（重要性）；
结尾





我想知道这是否正确，因为我是编程新手。另外，当改变加森算法中的输入数量时，输出会出现任何变化（相对重要性）吗？
我附上了Garson算法的公式供参考：
Garson 算法公式]]></description>
      <guid>https://stackoverflow.com/questions/77725247/how-do-you-code-garsons-algorithm-in-matlab-to-find-the-relative-importance-of</guid>
      <pubDate>Thu, 28 Dec 2023 06:04:03 GMT</pubDate>
    </item>
    <item>
      <title>gpt 3.5微调后如何给出提示</title>
      <link>https://stackoverflow.com/questions/77725206/how-to-give-prompt-to-gpt-3-5-after-its-fine-tuning</link>
      <description><![CDATA[我有一个关于模型微调的问题。如果我微调模型并且我的微调数据训练数据如下所示：
“用户：请判断以下是否反对“我对买车不感兴趣”
店员：是的，是顾客买车时提出的异议”
现在我很困惑，微调后我是否必须给出“确定以下内容是否反对”的确切提示“我对买车不感兴趣”
如果我通过以下方式给出提示，微调模型会起作用吗：
总结下面给出的文字。还要确定以下内容是否是反对意见。
“我对买车没兴趣”
给出的文字：不客气！如果你有任何
如有其他问题或需要更多信息，请随时与我们联系。我们
期待帮助您找到完美的汽车。
此对话是一个基本示例，可以根据情况进行调整
根据具体情况、客户偏好和卖家的方法。它是
重要的是要专心，满足客户的需求，并引导他们完成整个过程
采购流程。
我想知道是否可行]]></description>
      <guid>https://stackoverflow.com/questions/77725206/how-to-give-prompt-to-gpt-3-5-after-its-fine-tuning</guid>
      <pubDate>Thu, 28 Dec 2023 05:46:59 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 ANN 预测两个高度相关的变量</title>
      <link>https://stackoverflow.com/questions/77725008/how-to-predict-two-variables-that-are-highly-correlated-using-ann</link>
      <description><![CDATA[我正在尝试从 ANN 模型预测两个变量。设这两个变量为A和B。现在根据我掌握的数据，在所有其他特征中，变量B与变量A的相关性最高。我的模型非常准确地预测了变量 A。但是变量 B 的预测不正确。所以我在想我可以使用变量 A 的预测数据来训练另一个模型来预测变量 B，因为 B 与 A 的相关性最高（0.91）。第二高的相关性仅为 0.52。
有人可以告诉我这种方法是否有效吗？]]></description>
      <guid>https://stackoverflow.com/questions/77725008/how-to-predict-two-variables-that-are-highly-correlated-using-ann</guid>
      <pubDate>Thu, 28 Dec 2023 04:23:54 GMT</pubDate>
    </item>
    <item>
      <title>将道馆环境与 Pokemon Essentials 游戏连接起来</title>
      <link>https://stackoverflow.com/questions/77725007/connecting-gymnasium-environment-with-pokemon-essentials-game</link>
      <description><![CDATA[我正在研究一个基于 RPG Maker XP 和 RGSS 制作的 Pokemon Essentials 游戏的强化学习模型，我想做的第一步是为gymnasium 创建一个与游戏交互的环境。然而，由于游戏是用 RGSS 编码的，我很难弄清楚如何使环境与游戏连接起来。有什么办法可以做到这一点吗？
我的第一个解决方案是尝试将 RPG 游戏制作成类似终端的格式，其中仅打印战斗统计数据，并且模型将根据这些统计数据进行工作，但是我也不知道如何做到这一点.]]></description>
      <guid>https://stackoverflow.com/questions/77725007/connecting-gymnasium-environment-with-pokemon-essentials-game</guid>
      <pubDate>Thu, 28 Dec 2023 04:23:49 GMT</pubDate>
    </item>
    <item>
      <title>如何找到大小为“N”的训练数据向量与大小为“Z”的响应变量之间的相关性？</title>
      <link>https://stackoverflow.com/questions/77724016/how-to-find-correlation-between-vector-of-training-data-of-size-n-and-response</link>
      <description><![CDATA[我正在学习时间序列 ML 课程，使用随机森林来预测大小为 (1, 12) 的多尺寸输出目标。训练变量的大小为(1, 6)。本质上，该模型使用过去 6 个月的滞后来预测未来 12 个月。
但是，我不确定如何知道两个向量是否存在相关性，因为您需要成对输入来计算相关性。因此，我不知道 6 个滞后是否比 10 个或 12 个滞后更好。
有什么好方法可以了解一定数量的滞后与不同形状的响应变量之间是否存在相关性？
示例数据：
将 numpy 导入为 np
x = np.random.random((21,6))
y = np.random.random((21,12))

上面在我正在使用的维度中开发了两个数据集。]]></description>
      <guid>https://stackoverflow.com/questions/77724016/how-to-find-correlation-between-vector-of-training-data-of-size-n-and-response</guid>
      <pubDate>Wed, 27 Dec 2023 21:07:02 GMT</pubDate>
    </item>
    <item>
      <title>知道如何提高预测准确性吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77723854/any-idea-how-to-improve-prediction-accuracy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77723854/any-idea-how-to-improve-prediction-accuracy</guid>
      <pubDate>Wed, 27 Dec 2023 20:18:51 GMT</pubDate>
    </item>
    <item>
      <title>从拥抱的脸上加载耳语基础模型？</title>
      <link>https://stackoverflow.com/questions/77723275/loading-whisper-base-model-from-hugging-face</link>
      <description><![CDATA[我正在尝试加载耳语的基本模型，但我很难这样做。
貌似没有直接的方法可以直接从抱脸网站下载模型，而且使用变压器也不行。我知道我做错了什么，因为我知道我加载了模型两次，但我不能这样做。
目前，这是我尝试过的：
导入耳语
进口火炬
从变压器导入 AutoProcessor、AutoModelForSpeechSeq2Seq
print(&quot;正在下载模型...&quot;)
直接=“型号/”
model_1 = AutoModelForSpeechSeq2Seq.from_pretrained(&#39;openai/whisper-base&#39;,cache_dir=direct)
处理器= AutoProcessor.from_pretrained(&#39;openai/whisper-base&#39;,cache_dir=direct)

模型 = 耳语.load_model(model_1)
print(“模型已加载。正在转录测试音频...”)
结果 = model.transcribe(“audio_test.mp3”)
打印（结果[“文本”]）

我需要使用变压器吗？我应该有其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77723275/loading-whisper-base-model-from-hugging-face</guid>
      <pubDate>Wed, 27 Dec 2023 17:33:49 GMT</pubDate>
    </item>
    <item>
      <title>朱莉娅维度不匹配[关闭]</title>
      <link>https://stackoverflow.com/questions/77719712/julia-dimension-mismatch</link>
      <description><![CDATA[我无法理解如何在 julia 的 nn 模型中实现转换层。每次我尝试实现它时都会收到此错误
DimensionMismatch：x 和 w 的等级必须匹配！ （2 对 3）

下面是我试图实现 Conv 层的 julia 模型，它应该位于倒数第二个 Dense 层之前，但每次我把它放在那里时，它都会抛出上述错误。
&lt;前&gt;&lt;代码&gt;开始
    路径 =normpath(joinpath(@__DIR__, “..”, “ass-6/datasets”, “amazon_reviews_multi”, “en”, “1.0.0”))
    文件名=“火车.箭头”；
    to_device = cpu # GPU 或 CPU
    
    文件路径 = joinpath(路径, 文件名)
    
    df = DataFrame(箭头.Table(文件路径))
    显示（第一个（df，20））
    println(“”)
    
    超参数 = 字典(
        “种子” =&gt; 314159,
        “标记器” =&gt; “none”, # 选项：无 bpe 词缀
        “n标签” =&gt; 5、
        “pdrop” =&gt; 0.3,
        “暗淡嵌入” =&gt; 36
    ）
    nlabels = 超参数[“nlabels”]
    n_epochs = 10
结尾;
开始
    dim_embedding = 超参数[“dim_embedding”]
    pdrop = 超参数[“pdrop”]
    
    模型=链(
                TransformersLite.TransformerClassifier(
        嵌入（dim_embedding，长度（索引器）），
        位置编码（dim_embedding），
        辍学（pdrop），
        TransformerEncoderBlock[
            TransformerEncoderBlock(6, dim_embedding, dim_embedding * 6; pdrop=pdrop),
        ],
           密集（dim_embedding，16，relu），
           压平图层(),
           密集（800，dim_embedding，relu），
        ),
        BatchNorm(dim_embedding),
        LayerNorm(dim_embedding),
        Conv((1, 1), dim_embedding =&gt; 36, relu, pad=(1, 0)),
        密集（dim_embedding，50，relu），
        辍学（pdrop），
        密集（50，nlabels，relu），
        软最大
    
        
    ）
        
    显示（型号）
    println(“”)
    模型 = to_device(模型)
    
    hyperparameters[“model”] = “$(typeof(model).name.wrapper)”
    hyperparameters[“可训练参数”] = sum(length, Flux.params(model));
    
    如果 nlabels == 1
        损失（x，y）= Flux.logitbinarycrossentropy（x，y）
        精度(ŷ, y) = 平均值((Flux.sigmoid.(ŷ) .&gt; 0.5) .== y)
    别的
        损失（x，y）= Flux.logitcrossentropy（x，y）
        准确度(ŷ, y) = 平均值(Flux.onecold(ŷ) .== Flux.onecold(y))
    结尾
结尾;

我尝试了很多不同的值和方法，但它仍然不起作用，有人可以解释一下如何实现这个转换层。输入是一个 32x50 矩阵，批量大小为 32，因此是 32x50x32 矩阵。]]></description>
      <guid>https://stackoverflow.com/questions/77719712/julia-dimension-mismatch</guid>
      <pubDate>Wed, 27 Dec 2023 01:36:36 GMT</pubDate>
    </item>
    <item>
      <title>如何对不同性能指标的结果进行排名，其中一些指标是非线性的[关闭]</title>
      <link>https://stackoverflow.com/questions/77706319/how-to-rank-results-from-disparate-performance-metrics-some-of-which-are-non-li</link>
      <description><![CDATA[我想根据一组图像对不同二值化算法的性能进行排名。
根据以下详细信息，实现此目的的最佳方法是什么？
我使用了许多指标：准确度、F 测量、PSNR、MCC、距离倒数失真测量等。
其中一些是线性的，并且非常容易量化，例如准确性。
其他的是非线性的，这些是我关心的。
例如，PSNR 可以在 0?和 Infinity（实际上是 55 岁左右？）。
PSNR 只是一个例子，但不知何故，我觉得这些测量结果是盲目的。
数字越高可能意味着越好，但我无法真正判断好多少。
如果我用两种算法处理三张图像，我可以得到这样的东西（完全化妆）：

&lt;表类=“s-表”&gt;
&lt;标题&gt;


Img1
Img2
Img3


&lt;正文&gt;

算法 1
准确率：99.97%，PSNR：46.82
准确率：81.32%，PSNR：10.98
准确率：75.92%，峰值信噪比：11.28


算法 2
准确率：98.96%，PSNR：36.95
准确率：85.75%，PSNR：14.21
准确率：76.32%，PSNR：11.20




PSNR 为 12.0 的东西并不比 PSNR 为 6.0 的东西好 2 倍。
我看到两个选项：
选项 1 - 执行他们在 DIBCO 中所做的操作，对每个图像的每个算法进行排名，然后汇总排名计数以获得最终分数。很简单，但是当您试图找出哪种算法真正更好时，它有点没有抓住重点。
选项 2 - 以某种方式找出如何将每个测量值归一化为线性标度。我觉得这可能很困难、耗时，但也许是一个解决的问题？
还有其他选择吗？或者其他更好的方式来问这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77706319/how-to-rank-results-from-disparate-performance-metrics-some-of-which-are-non-li</guid>
      <pubDate>Sat, 23 Dec 2023 00:46:46 GMT</pubDate>
    </item>
    <item>
      <title>收到“ValueError：X 有 6 个特征，但 LinearRegression 期望 7 个特征作为输入。”可能是由于列转换（管道）步骤</title>
      <link>https://stackoverflow.com/questions/77702656/getting-valueerror-x-has-6-features-but-linearregression-is-expecting-7-featu</link>
      <description><![CDATA[泰坦尼克号 = pd.read_csv(“train.csv”)
titanic_test = pd.read_csv(“test.csv”)
titanic_train_labels = 泰坦尼克号[&#39;幸存&#39;].copy()
泰坦尼克号 = 泰坦尼克号.drop(columns = &#39;幸存&#39;)

# 管道

titanic_num = [&#39;年龄&#39;, &#39;票价&#39;]
titanic_cat = [&#39;性别&#39;, &#39;登船&#39;]

num_pipeline = 管道([
        (“imputer”, SimpleImputer(strategy=&#39;median&#39;)),
        （“std_scaler”，StandardScaler（）），
    ]）

cat_pipeline = 管道([
        (“enc”, OneHotEncoder(drop=&#39;if_binary&#39;))
    ]）

def full_pipeline(num_attribs, cat_attribs):
    返回列转换器（[
        (“num”, num_pipeline, num_attribs),
        （“猫”，cat_pipeline，cat_attribs）
    ]）

titanic_prepared = full_pipeline(titanic_num, titanic_cat)
泰坦尼克号清洁 = 泰坦尼克号准备.fit_transform(泰坦尼克号)

# 在这里，我通过相同的管道准备测试数据

泰坦尼克号测试编号 = 泰坦尼克号测试编号
泰坦尼克号测试猫 = 泰坦尼克号猫
titanic_test_prepared = full_pipeline(titanic_test_num, titanic_test_cat)
泰坦尼克号测试清洁 = 泰坦尼克号测试准备.fit_transform(泰坦尼克号测试)
Final_model.fit(titanic_clean, titanic_train_labels)

标题上出现错误的代码：
final_model.predict(titanic_test_clean)

&lt;小时/&gt;
打印可能提示问题的有用信息：
titanic_clean[0] -&gt; &gt;数组([-0.56573646,-0.50244517,1.,0.,0.,
        1., 0.]) # 7 项
titanic_test_clean[0] -&gt; 泰坦尼克号测试清洁[0] -&gt;数组([ 0.38623105, -0.49741333, 1., 0., 1.,
        0.]) # 6 项

从上面的信息来看，我认为问题在于 onecodeencoder 的数量不匹配。我怀疑训练集和测试集的分类值数量不同。但他们确实是。
数据集的链接 -&gt; https://github.com/minsuk-heo/ kaggle-titanic/blob/master/input/test.csv]]></description>
      <guid>https://stackoverflow.com/questions/77702656/getting-valueerror-x-has-6-features-but-linearregression-is-expecting-7-featu</guid>
      <pubDate>Fri, 22 Dec 2023 09:05:39 GMT</pubDate>
    </item>
    <item>
      <title>处理 CNN 二元分类的分布外样本和异常 [关闭]</title>
      <link>https://stackoverflow.com/questions/77679785/handling-out-of-distribution-samples-and-anomalies-for-cnn-binary-classification</link>
      <description><![CDATA[我的经理要求我开发一种机器学习模型，能够在攻击性图像发送到服务器之前识别它们。这些图像可以分为不同的类别，例如武器或成人内容。
问题
但是，我在模型检测异常或分布外样本的能力方面遇到了问题。
我尝试过的
我尝试了不同的方法，利用&#39;binary_crossentropy&#39;作为我的损失函数，但遇到了同样的问题。我还构建了一个包含两个类的模型：

12,278 与武器相关的图片 class_name = 武器
3,000 张食物 商品图片 class_name = 其他

但是，我不确定 “其他” 类别中应包含哪些内容。使用 MobileNet 作为基础模型构建模型后，它成功地准确预测了武器，并提供了 0.4 到 0.6 范围内的食品预测，这似乎是可以接受的。然而，当我引入大象或汽车的图像时，模型倾向于将它们预测为武器，显示的置信度接近 1。
我不知道如何解决这个问题。我尝试研究这个问题，并发现了一些关于分布外检测的线索以及与异常或离群值相关的概念。当模型的输入包含不属于训练数据的图像时，如何获得不确定性值？
有任何指导、建议，甚至参考视频或资源可以有效解决此问题吗？
数据加载：
train_ds, test_ds = keras.utils.image_dataset_from_directory(
    目录=“/内容/武器”，
    标签=“推断”，
    label_mode =“二进制”，
    批量大小=32，
    子集=“两者”，
    图像大小=(224,224),
    验证分割=0.2，
    随机播放=真，
    种子=1337
）

现在标准化输入图像数据：
def process（图像，标签）：
  图像=tf.cast(图像/255, tf.float32)
  返回图像、标签
train_ds = train_ds.map(进程)
test_ds = test_ds.map(进程)

创建 CNN 模型：
input_shape = (224,224,3)
mobilenet = MobileNet(input_shape,weights=&#39;imagenet&#39;,include_top=False)
模型=顺序（）
 
model.add（移动网络）
模型.add(压平())
model.add（密集（256，激活=&#39;relu&#39;））
模型.add(Dropout(0.5))
model.add（密集（1，激活=&#39;sigmoid&#39;））
模型.summary()



sgd = SGD(学习率=0.0001，动量=0.9，nesterov=True)
model.compile（损失=&#39;binary_crossentropy&#39;，优化器=sgd，指标=[&#39;准确性&#39;]）
历史= model.fit（train_ds，validation_data = test_ds，batch_size = 4，epochs = 6）


纪元 6/6
382/382 [==============================] - 58s 150ms/步 - 损失：0.0042 - 精度：0.9984 - val_loss ：0.0063 - val_accuracy：0.997
]]></description>
      <guid>https://stackoverflow.com/questions/77679785/handling-out-of-distribution-samples-and-anomalies-for-cnn-binary-classification</guid>
      <pubDate>Mon, 18 Dec 2023 14:34:38 GMT</pubDate>
    </item>
    <item>
      <title>以 PMML 格式转储的 LightGBM 模型给出了与原始模型不同的预测</title>
      <link>https://stackoverflow.com/questions/77664935/lightgbm-model-dumped-in-pmml-format-gives-different-predictions-from-the-origin</link>
      <description><![CDATA[我训练了一个 lightGBM 模型，它给出了倾向问题的概率。
然后将此模型转换为 PMML 格式，如下所示：
从 sklearn2pmml 导入 sklearn2pmml
sklearn2pmml(trained_model, &#39;prod_trained_model.pmml&#39;)

然后我像这样读取 PMML 模型：
从 pypmml_spark 导入 ScoreModel
model_pipeline = ScoreModel.fromFile(&#39;prod_trained_model.pmml&#39;)

然后我做出这样的预测：
predictions_df = model_pipeline.transform(features_df)

现在的问题是模型预测与原始模型的预测不匹配。预测概率有 5% 到 10% 的变化。
此外，对于输入数据帧中大约 5% 的行，PMML 模型的输出概率为 NaN。而对于完全相同的行，原始模型预测得很好。]]></description>
      <guid>https://stackoverflow.com/questions/77664935/lightgbm-model-dumped-in-pmml-format-gives-different-predictions-from-the-origin</guid>
      <pubDate>Fri, 15 Dec 2023 07:56:51 GMT</pubDate>
    </item>
    </channel>
</rss>