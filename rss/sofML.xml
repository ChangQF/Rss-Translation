<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 25 Oct 2024 09:18:47 GMT</lastBuildDate>
    <item>
      <title>我是否需要使用具有混合值的 kprototype 聚类来缩放数据？</title>
      <link>https://stackoverflow.com/questions/79124536/do-i-need-to-scale-the-data-with-kprototype-clustering-with-mixed-value</link>
      <description><![CDATA[我想使用 kmodes.kprototypes 中的 kprototype 对一些混合数据进行聚类。因此，有些是数值数据，有些是分类数据。我需要缩放数据吗？如果是，我是否只需要缩放数值数据？
我不熟悉 kprototype 的实现，我想对一些混合数据进行聚类。缩放能给我带来更好的结果吗？]]></description>
      <guid>https://stackoverflow.com/questions/79124536/do-i-need-to-scale-the-data-with-kprototype-clustering-with-mixed-value</guid>
      <pubDate>Fri, 25 Oct 2024 06:48:32 GMT</pubDate>
    </item>
    <item>
      <title>如何计算嵌套张量的均值和方差？</title>
      <link>https://stackoverflow.com/questions/79124074/how-to-compute-nested-tensors-s-mean-and-var</link>
      <description><![CDATA[对于 torch.Tesnor，计算均值和方差很容易，但我找不到计算嵌套张量的均值和方差的方法。嵌套张量支持 layer_norm 操作，其中包括均值和方差操作。
感谢您的帮助！
 x = torch.randn(1, 192)
y = torch.randn(10, 192)
nested = torch.nested.nested_tensor([x, y])
nested.mean(dim=-1)#不支持
layer_norm(nested)#支持

有没有办法计算嵌套张量的均值？]]></description>
      <guid>https://stackoverflow.com/questions/79124074/how-to-compute-nested-tensors-s-mean-and-var</guid>
      <pubDate>Fri, 25 Oct 2024 02:17:33 GMT</pubDate>
    </item>
    <item>
      <title>尽管 Keras 模型在训练中具有很高的准确率，但它对所有输入都给出完全相同的预测值</title>
      <link>https://stackoverflow.com/questions/79123575/keras-model-gives-exact-same-prediction-value-for-all-inputs-even-though-it-has</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79123575/keras-model-gives-exact-same-prediction-value-for-all-inputs-even-though-it-has</guid>
      <pubDate>Thu, 24 Oct 2024 20:49:05 GMT</pubDate>
    </item>
    <item>
      <title>以 32 位数字为例，FLUX.1-* 和 StableDiffusion 在制​​作图像时执行的典型计算有多大？[关闭]</title>
      <link>https://stackoverflow.com/questions/79123548/how-big-in-terms-of-say-32bit-numbers-are-the-typical-calculations-performed-b</link>
      <description><![CDATA[我没有 GPU，我只依赖我的 CPU，即 2x XEONS（没有 AVX、AVX2、AVX-512、F16C）和大量 RAM，所以我很好奇；

*实际平均矩阵有多大，我假设不是所有 60GB 的 .safetensors，它在图像处理和噪声生成过程中真正处理？

我假设它的根源是 GEMM 计算，但它抖动的真实矩阵有多大，以及它会在任何 AVX* 指令中抛出的每行和每列的长度是多少来乘以和/或加法？


顺便说一句，即使使用我的过时系统，我也会得到一个每 10 分钟左右处理一次 1024x512。
我也不使用 GUI，因此我也节省了大量资源。
仅供参考，所有内容都在 CLI 上的 Python 脚本上运行，我通过笔记本电脑使用 SSH 使用 PUtty 进行操作。
在我看来，GUI 和 GPU 被高估了。
大多数计算是否仅基于图像大小，比如我用作系统基准的 1024x512？
因此，某种方法，任何方法，快速处理 1024x512 矩阵，比如大约 524288 个 32 位浮点数的几个颜色层（RGB）都会很方便，对吧？]]></description>
      <guid>https://stackoverflow.com/questions/79123548/how-big-in-terms-of-say-32bit-numbers-are-the-typical-calculations-performed-b</guid>
      <pubDate>Thu, 24 Oct 2024 20:38:01 GMT</pubDate>
    </item>
    <item>
      <title>训练 AI 模型以纠正多边形坐标错误的最佳方法（Django REST Framework GIS）</title>
      <link>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</link>
      <description><![CDATA[我需要选择一个最适合训练的 AI 模型和一个 Python 库。我有来自 djangorestframework-gis 库的以 Multipolygon 字段表示的坐标，它们在不同范围内存在小误差 - 大约 0.75 到 1 米。此外，我有相同地块的正确坐标。该模型需要学习找到正确数据和错误数据之间的差异，并在此基础上找到一种算法来确定错误，以便将来纠正错误坐标。]]></description>
      <guid>https://stackoverflow.com/questions/79123372/optimal-approach-for-training-an-ai-model-to-correct-errors-in-multipolygon-coor</guid>
      <pubDate>Thu, 24 Oct 2024 19:14:14 GMT</pubDate>
    </item>
    <item>
      <title>时间序列预测：如何使用截至 t-1 计算的特征预测未来值而不会发生数据泄漏？</title>
      <link>https://stackoverflow.com/questions/79123110/time-series-forecasting-how-to-predict-future-values-using-features-calculated</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79123110/time-series-forecasting-how-to-predict-future-values-using-features-calculated</guid>
      <pubDate>Thu, 24 Oct 2024 17:39:23 GMT</pubDate>
    </item>
    <item>
      <title>将 Python 模型集成到 Power Bi</title>
      <link>https://stackoverflow.com/questions/79122864/integrate-python-model-to-power-bi</link>
      <description><![CDATA[在 power BI 中，我必须创建一个基于 NLP 的聊天机器人，就像我们在 power bi 中有 QnA visual 一样，它可以回答自然语言处理中提出的问题，但由于它的一些限制，我无法使用它。
我想使用 python 训练我的数据集并创建一个可以回答任何自然语言问题的模型。
然而问题是我无法将 python 脚本运行到 Power bi 中，因为它没有网关连接，所以它不会刷新，我不需要在我的本地系统中执行此操作，只需将其发送给最终用户即可。任何我加载到 power bi 中的东西最终都会看起来像一张表格，我必须创建它的视觉效果。
我想知道以何种方式可以使用用 python 编写的 QnA 模型将 python 模型灌输到 power bi 中，以便用户可以用自然语言搜索他们想要问的问题。
有没有办法使用 python 让最终用户可以像聊天机器人一样输入他们的问题并得到他们的答案？]]></description>
      <guid>https://stackoverflow.com/questions/79122864/integrate-python-model-to-power-bi</guid>
      <pubDate>Thu, 24 Oct 2024 16:24:05 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 的 mask r-cnn 推理 ONNX 模型从不起作用</title>
      <link>https://stackoverflow.com/questions/79122467/inferencing-onnx-model-of-pytorchs-mask-r-cnn-never-works</link>
      <description><![CDATA[问题：推理 onnx 模型给出空结果或形状奇怪的结果
我正在尝试：pytorch 预训练 mask-rcnn -&gt; 在数据集上微调 -&gt; 另存为 onnx -&gt; 在 onnx 上推理 -&gt; 绘制结果
我目前拥有的一切都在推理之前有效。
我的 main.py 文件：https://pastebin.com/3jNfZdBi
获取有关我保存的 onnx 模型的信息
模型输入信息：
名称：输入
形状：[&#39;batch_size&#39;, 3, &#39;height&#39;, &#39;width&#39;]
类型：张量（浮点）

模型输出信息：
名称：boxes
形状：[&#39;Concatboxes_dim_0&#39;, 4]
类型：张量（浮点）
名称：labels
形状：[&#39;Gatherlabels_dim_0&#39;]
类型：张量（int64）
名称：分数
形状：[&#39;Gatherlabels_dim_0&#39;]
类型：张量（浮点）
名称：掩码
形状：[&#39;Unsqueezemasks_dim_0&#39;, &#39;Unsqueezemasks_dim_1&#39;, &#39;Unsqueezemasks_dim_2&#39;, &#39;Unsqueezemasks_dim_3&#39;]
类型：张量（浮点）

我的推理代码：https://pastebin.com/wxvp649G
我怀疑我要么：错误地将内容保存到 onnx，要么没有正确地预处理我的数据，要么我的推理代码是错误的（或其他我不知道的东西）
保存到 onnx 的代码
def save_model_onnx(models_file_path, model, torch_input):
#传统的导出方法。还有一种实验性的 dynamo_export 方法
torch.onnx.export(
model.cpu(),
torch_input.cpu(),
models_file_path, # 模型的完整路径，包括模型本身，即 ./models/model.onnx
export_params = True,
opset_version=15, # 选择支持的 ONNX opset 版本
do_constant_folding=True, # 折叠常量节点以进行优化
input_names = [&#39;input&#39;],
output_names = [&#39;boxes&#39;, &#39;labels&#39;, &#39;scores&#39;, &#39;masks&#39;],
dynamic_axes={
&quot;input&quot;: {0: &quot;batch_size&quot;, 2: &quot;height&quot;, 3: &quot;width&quot;}, 
}
)
logstash.info(f&quot;模型保存在{models_file_path}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/79122467/inferencing-onnx-model-of-pytorchs-mask-r-cnn-never-works</guid>
      <pubDate>Thu, 24 Oct 2024 14:41:59 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 混合预测和预测</title>
      <link>https://stackoverflow.com/questions/79122079/ml-net-mix-forecast-and-predict</link>
      <description><![CDATA[我正在制作一个简单的应用程序来检测 .NET 中的网络异常
应用程序正在收集原始数据包，然后对其进行分析并确定是否发生了潜在攻击（使用静态算法）。目前，我已经实现了基于 TCP 数据包中的 SYN 和 ACK 标志来检测 TCP 洪水攻击的算法。除了分析之外，应用程序还在指定模式中将数据保存在文件中：
SOURCE_IP | DESTINATION_IP | TIMESTAMP (TIMEVAL) | SYN | ACK
10.0.0.5 | 10.0.0.10 | 1726332243,275925 | 1 | 1

我想实现 ML 模型（使用 ML.NET），根据当前“会话”中已经收集的数据预测是否发生攻击。
我尝试添加另一列“IsAttack”，这是我的标签。之后，我模拟了 tcp 洪水攻击，并通过完成最后一列来准备训练数据。但 ml 模型还包括当前会话中所有为“0”的先前标签，因此它无法正常工作。另一方面，当我尝试预测场景时，ML 仅从单行获取数据。有什么想法可以混合预测和预测吗？或者任何其他解决方案？
生成的 ML 模型：
public partial class TCPFloodMLDetector
{
/// &lt;summary&gt;
/// TCPFloodMLDetector 的模型输入类。
/// &lt;/summary&gt;
#region 模型输入类
public class ModelInput
{
[LoadColumn(0)]
public string SourceAddress { get; set; }

[LoadColumn(1)]
public string DestinationAddress { get; set; }

[LoadColumn(2)]
public double Timeval { get; set; }

[LoadColumn(3)]
public bool SYN { get; set; }

[LoadColumn(4)]
public bool ACK { get; set; }

[LoadColumn(5)]
[ColumnName(@&quot;col5&quot;)]
public Single IsAttack { get; set; }
}

#endregion

/// &lt;summary&gt;
/// TCPFloodMLDetector 的模型输出类。
/// &lt;/summary&gt;
#region 模型输出类
public class ModelOutput
{
[ColumnName(@&quot;col5&quot;)]
public float[] Col5 { get; set; }

[ColumnName(@&quot;col5_LB&quot;)]
public float[] Col5_LB { get; set; }

[ColumnName(@&quot;col5_UB&quot;)]
public float[] Col5_UB { get; set; }

}

#endregion

private static string MLNetModelPath = Path.GetFullPath(@&quot;D:\Projects\NetworkAnalyzer\\Models\TCPFloodMLDetector.mlnet&quot;);

public static readonly Lazy&lt;TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt;&gt; PredictEngine = new Lazy&lt;TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt;&gt;(() =&gt; CreatePredictEngine(), true);

/// &lt;summary&gt;
/// 使用此方法对 &lt;see cref=&quot;ModelInput&quot;/&gt; 进行预测。
/// &lt;/summary&gt;
/// &lt;param name=&quot;input&quot;&gt;model input。&lt;/param&gt;
/// &lt;returns&gt;&lt;seealso cref=&quot; ModelOutput&quot;/&gt;&lt;/returns&gt;
public static ModelOutput Predict(ModelInput? input = null, int? horizo​​n = null)
{
var predEngine = PredictEngine.Value;
return predEngine.Predict(input, horizo​​n);
}

private static TimeSeriesPredictionEngine&lt;ModelInput, ModelOutput&gt; CreatePredictEngine()
{
var mlContext = new MLContext();
ITransformer mlModel = mlContext.Model.Load(MLNetModelPath, out var schema);
return mlModel.CreateTimeSeriesEngine&lt;ModelInput, ModelOutput&gt;(mlContext);
}
}

我在每秒运行的 Detect 函数中使用它：
public async Task Detect()
{
try
{
var context = new MLContext();
var data = context.Data.LoadFromTextFile&lt;TCPFloodInputModel&gt;(&quot;tcpflood.txt&quot;,
hasHeader: false, SeparatorChar: &#39;|&#39;);

TCPFloodMLDetector.LoadIDataViewFromFile(context, &quot;tcpflood.txt&quot;,
&#39;|&#39;, false, true);

// 使用默认选项进行预测。
var modelOutput = TCPFloodMLDetector.Predict();
Console.WriteLine(string.Join(&quot;,&quot;, modelOutput.Col5));

// 预测接下来的 5 个周期
modelOutput = TCPFloodMLDetector.Predict(horizo​​n: 5);
Console.WriteLine(string.Join(&quot;,&quot;, modelOutput.Col5));
}
catch (Exception ex)
{

}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79122079/ml-net-mix-forecast-and-predict</guid>
      <pubDate>Thu, 24 Oct 2024 13:12:42 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV 与 OpenVINO 后端：动态批次大小问题</title>
      <link>https://stackoverflow.com/questions/79097169/opencv-with-openvino-backend-problem-whit-dynamic-batch-size</link>
      <description><![CDATA[我正在使用 OpenCV（版本 4.10.0）和 OpenVINO（2023.0.1）后端编译来加载和处理深度学习模型。我已使用 ovc 和 omz_downloader 成功将模型从 Open Model Zoo 转换为 OpenVINO IR 格式。转换工作正常，但在将模型导入 OpenCV 进行推理时遇到了问题。
问题：
模型使用动态批处理大小（[-1, 3, 112, 112]）进行转换。当我尝试使用 cv::dnn::readNetFromModelOptimizer() 函数在 OpenCV 中加载此模型时，我在 OpenCV 源代码的这一部分中收到异常：
NetImplOpenVINO::createNetworkFromModelOptimizer(std::shared_ptr&lt;ov::Model&gt;&amp; ieNet) 函数
{
....
for (auto&amp; it : ieNet-&gt;get_parameters())
{
inputNames.push_back(it-&gt;get_friendly_name());
std::vector&lt;size_t&gt; dims = it-&gt;get_shape(); // 此处发生异常
inp_shapes.push_back(std::vector&lt;int&gt;(dims.begin(), dims.end()));
}
.....
}

在 OpenCV 代码中调用 it-&gt;get_shape() 时发生异常，可能是因为模型具有动态形状。
问题：
使用 OpenVINO 后端时，如何在 OpenCV 的 DNN 模块中处理具有动态批处理大小的模型？
是否有在 OpenCV 中加载具有动态输入形状的模型的解决方法，还是应该直接使用 OpenVINO 的推理引擎管理动态批处理？
环境：
OpenCV 4.10.0
OpenVINO 2023.1
Windows 11
环境 c++

静态批处理大小：我使用静态批处理大小 ([1, 3, 112, 112]) 转换了模型，并且它运行良好。但是，我需要为我的应用程序处理动态批次大小。
后端设置：我正在使用以下方法将后端设置为 OpenVINO：

`net.setPreferableBackend(cv::dnn::DNN_BACKEND_INFERENCE_ENGINE);
net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);`

任何有关使用 OpenVINO 处理 OpenCV 中的动态批次大小的帮助或见解都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/79097169/opencv-with-openvino-backend-problem-whit-dynamic-batch-size</guid>
      <pubDate>Thu, 17 Oct 2024 08:22:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 scikit learn 训练机器学习模型进行时间序列预测</title>
      <link>https://stackoverflow.com/questions/59843700/train-machine-learning-model-with-scikit-learn-for-time-series-prediction</link>
      <description><![CDATA[我需要使用 scikit-learn 训练一个模型来预测房间中人数较少的可能时间。
我的数据集如下所示：
时间 人数 数量
---------------------------------------------------------
2019-12-29 12:40:10 50
2019-12-29 12:42:10 30
2019-12-29 12:44:10 10
2019-12-29 12:46:10 10
2019-12-29 12:48:10 80
等等...

这些数据将保留 30 天。
模型训练完成后，我将查询模型以获取上午 10 点至下午 12 点之间房间中人数较少的可能时间晚上 8 点。我希望机器学习模型能够以 30 分钟的准确度做出响应，即“下午 3 点到 3 点 30 分”
我可以使用什么算法来解决这个问题，我该如何实现目标？或者除了 SciKit-Learn 之外，还有其他 Python 库可以用于此目的吗？]]></description>
      <guid>https://stackoverflow.com/questions/59843700/train-machine-learning-model-with-scikit-learn-for-time-series-prediction</guid>
      <pubDate>Tue, 21 Jan 2020 14:52:49 GMT</pubDate>
    </item>
    <item>
      <title>ALS 算法 Spark MLlib - 如何获得我自己的“个人推荐”（我尚未排名的电影排名）</title>
      <link>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</link>
      <description><![CDATA[我在 Azure Databricks 中使用 PySpark。我使用 Sparks MLlib 库 ALS 算法来预测电影评分，效果很好。但是，我尝试添加一个数据框，其中包含我对 10 部随机选择的电影的评分。当我这样做时，我只能获得我已经排名的电影的预测排名。 
我希望能够使用该模型根据他们的排名获得推荐。
我有执行以下任务的 Spark 代码：

导入数据（RatingsSmall、MoviesSmall、RatingsLarge、Movies Large）
将 Ratings small 与 Movies Small 合并，将 Ratings Large 与 Movies Large 合并
将两个新数据集附加在一起
删除不相关的列 Timestamp 和 Genre

我现在有一个干净的表，其中包含 MovieID、Title（电影名称）、UserID 和 Ranking。我将从此处展示代码。如果您想要之前的代码，我也可以提交。

将数据拆分为训练集和测试集 (0.80, 0.20)
ALS 算法
显示预测。

希望以上内容能帮助您完成我所附的代码。
我只获得已提交排名的预测。
我尝试将我的排名加入训练集。从这里，我希望获得数据集中其他电影的推荐或预测。
我的尝试：
导入了具有我自己排名的 DF。
将其 (UnionAll) 附加到训练集。
获得预测（但仅限于我已经排名的电影）
code:
#拆分数据集

training, test = All_Movies.randomSplit([0.8, 0.2])
from pyspark.ml.recommendation import ALS

from pyspark.ml.evaluation import RegressionEvaluator

#设置模型

ALS = ALS(maxIter=10, regParam=0.01, userCol = &quot;userId&quot;,itemCol=&quot;movieId&quot;, ratingsCol=&quot;rating&quot;, coldStartStrategy=&quot;drop&quot;)

#将模型拟合到训练集并附加个人推荐

model = ALS.fit(training.unionAll(PersonalDF)) #PersonalDF 是我的排名

#获取测试集的预测
predictions = model.transform(test).dropna()

#直到一切都很好这里。

#尝试获取我的电影的预测排名
mySampledMovies = model.transform(PersonalDF) 
mySampledMovies.registerTempTable(&quot;mySampledMovies&quot;)

display(sqlContext.sql(&quot;select userId, movieId, ratings,title, prediction from mySampledMovies&quot;))

我期望一个 DataFrame 表示我的用户 ID、电影 ID、排名、预测。对于我没见过的电影，排名为 N/A 或 Null，预测有值。
非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/54592009/als-algorithm-spark-mllib-how-do-i-get-my-own-personal-recomendations-rank</guid>
      <pubDate>Fri, 08 Feb 2019 12:00:58 GMT</pubDate>
    </item>
    <item>
      <title>如何从一系列图像中预测下一张图像？</title>
      <link>https://stackoverflow.com/questions/49714969/how-can-i-predict-the-next-image-from-a-series-of-images</link>
      <description><![CDATA[我计划从图像序列中预测下一张图像。我在互联网上（Google/YouTube）搜索过教程和类似的工作。但我找不到任何内容。
我想知道是否有可能找到模式并预测下一张图像，我能否找到一些相关教程。]]></description>
      <guid>https://stackoverflow.com/questions/49714969/how-can-i-predict-the-next-image-from-a-series-of-images</guid>
      <pubDate>Sun, 08 Apr 2018 06:07:06 GMT</pubDate>
    </item>
    <item>
      <title>关于如何预测未来时间序列数据的建议</title>
      <link>https://stackoverflow.com/questions/37556600/advice-on-how-to-predict-future-time-series-data</link>
      <description><![CDATA[我有不同国家和因素的时间序列数据，例如“阿富汗”从 1972 年到 2007 年的出生率（来源）。
目标：
预测 2008 年和 2012 年的出生率
我熟悉线性回归，但需要一些关于如何处理时间序列数据和预测未来值的帮助。
您能给我举些例子或分享一些代码片段吗？]]></description>
      <guid>https://stackoverflow.com/questions/37556600/advice-on-how-to-predict-future-time-series-data</guid>
      <pubDate>Tue, 31 May 2016 22:22:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit-learn 中预测时间序列？</title>
      <link>https://stackoverflow.com/questions/20841167/how-to-predict-time-series-in-scikit-learn</link>
      <description><![CDATA[Scikit-learn 采用基于 fit 和 predict 方法的非常方便的方法。我有适合 fit 和 predict 格式的时间序列数据。
例如，我有以下 Xs：
[[1.0, 2.3, 4.5], [6.7, 2.7, 1.2], ..., [3.2, 4.7, 1.1]]

以及相应的 ys：
[[1.0], [2.3], ..., [7.7]]

这些数据具有以下含义。存储在 ys 中的值形成时间序列。 Xs 中的值是相应的时间相关“因素”，已知这些因素会对 ys 中的值产生一定影响（例如：温度、湿度和大气压力）。
现在，当然，我可以使用 fit(Xs,ys)。但是，我得到了一个模型，其中 ys 中的未来值仅取决于因素，而不依赖于先前的 Y 值（至少直接不依赖于），这是该模型的一个限制。我希望有一个模型，其中 Y_n 还依赖于 Y_{n-1 和 Y_{n-2 等等。例如，我可能想使用指数移动平均线作为模型。在 scikit-learn 中，最优雅的实现方式是什么？

已添加
正如评论中提到的，我可以通过添加 ys 来扩展 Xs。但这种方式有一些限制。例如，如果我将 y 的最后 5 个值作为 5 个新列添加到 X，则有关 ys 的时间顺序的信息将丢失。例如，X 中没有迹象表明第 5 列中的值遵循第 4 列中的值，依此类推。作为模型，我可能希望对最后五个 ys 进行线性拟合，并使用找到的线性函数进行预测。但是如果我有 5 个值，分 5 列，那么就没那么简单了。
添加 2
为了让我的问题更加清晰，我想举一个具体的例子。我想要一个“线性”模型，其中 y_n = c + k1*x1 + k2*x2 + k3*x3 + k4*EMOV_n，其中 EMOV_n 只是一个指数移动平均数。我如何在 scikit-learn 中实现这个简单的模型？]]></description>
      <guid>https://stackoverflow.com/questions/20841167/how-to-predict-time-series-in-scikit-learn</guid>
      <pubDate>Mon, 30 Dec 2013 14:06:33 GMT</pubDate>
    </item>
    </channel>
</rss>