<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Jan 2024 09:14:33 GMT</lastBuildDate>
    <item>
      <title>联邦学习全局聚合后准确率下降</title>
      <link>https://stackoverflow.com/questions/77798059/the-accuacy-decreased-after-global-aggregation-in-federated-learning</link>
      <description><![CDATA[我正在开展一个联合学习项目。我编写了一段代码来刺激联邦学习的过程。然而，每次迭代进行全局聚合后，全局模型的测试精度会下降很多，并且在接下来的迭代中保持不变。我使用的聚合算法是FedAvg。我尝试将我的代码分成不同的单元来找出问题所在。
对于本地训练，所选客户训练 3 轮。在这个实验中，将选择所有五个客户端进行训练和聚合，我用于本地的模型是从 torchvision 分叉的 vgg16，数据集是 MNIST，并以 i.i.d 方式分割每个客户端： 
for id, net_id in enumerate(selected):
    logging.info(“训练所选设备 %s。” % (str(net_id)))
    结果 = Userlists[net_id].train(hparams[&#39;n_local_epochs&#39;])
    logging.info(&#39;&gt;&gt; 局部模型 %d: 局部精度: %f in round %d\n&#39; % (id, result[&#39;local_test_acc&#39;], step+1))

在本地模型聚合之前，我使用全局服务器的测试数据来测试本地模型的准确性，
tesc，conf = Misc.compute_accuracy(Userlists[2].model，test_dl_global，get_confusion_matrix=True，device=hparams[&#39;device&#39;])
打印（测试）
&gt; 0.2478966346153846
tesc，conf = Misc.compute_accuracy（Userlists [3] .model，test_dl_global，get_confusion_matrix = True，device = hparams [&#39;device&#39;]）
打印（测试）
&gt; 0.14413060897435898
tesc,conf=misc.compute_accuracy(Userlists[4].model,test_dl_global,get_confusion_matrix=True,device=hparams[&#39;device&#39;])
打印（测试）
&gt; 0.17387820512820512

我使用下面的聚合代码来聚合所选客户端的权重：
&lt;前&gt;&lt;代码&gt;total_sum = 0.0
对于选定的 client_idx：
    Total_sum += 用户列表[client_idx].data_len
    
    
global_para = global_model.state_dict()
client_weights = [torch.tensor( Userlists[client_idx].data_len/total_sum, device=hparams[&#39;device&#39;]) for client_idx in selected]

使用 torch.no_grad()：
    对于顺序，枚举中的 idx（选定）：
        logging.info(f“对于客户端 {idx}”)
        net_para = Userlists[idx].model.state_dict()
        
        如果订单 == 0：
            对于 net_para.keys() 中的键：
                global_para[key] = net_para[key] * client_weights[订单]
        别的：
            对于 net_para.keys() 中的键：
                global_para[key] += net_para[key] * client_weights[订单]


global_model.load_state_dict(global_para)
tesc,conf=misc.compute_accuracy(global_model,train_dl_global,get_confusion_matrix=True,device=hparams[&#39;device&#39;])

全局测试精度下降并保持不变
&lt;前&gt;&lt;代码&gt;&gt; 0.11236666666666667

虽然我尝试增加本地训练的纪元，局部准确率提高到 40%，但全局准确率仍然落入与之前相同的值。我的聚合代码中是否有错误的地方？
测试精度应与本地精度保持在同一水平。]]></description>
      <guid>https://stackoverflow.com/questions/77798059/the-accuacy-decreased-after-global-aggregation-in-federated-learning</guid>
      <pubDate>Thu, 11 Jan 2024 06:30:41 GMT</pubDate>
    </item>
    <item>
      <title>数据帧和多变量标签的嵌套目录上的多视图谱聚类</title>
      <link>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</guid>
      <pubDate>Thu, 11 Jan 2024 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到<类'NoneType'></title>
      <link>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</link>
      <description><![CDATA[我正在尝试对我的数据运行深度学习代码；但是，由于输入数据中缺少数据集，我遇到了问题。作为一个新人，我不知道如何解决这个问题。我正在努力解决下面给出的这个错误，下面还提供了输入链接。
python3 Validation2co.py
BP_benchmarkSet_2.csv
BP seqmodel 启动
序列模块（
  (seq_CNN): 顺序(
    (0): Conv1d(100, 64, kernel_size=(16,), stride=(1,), padding=(8,))
    (1): ReLU(原地=True)
    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv1d(64, 32, kernel_size=(16,), stride=(1,), padding=(8,))
    (4): ReLU(inplace=True)
    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv1d(32, 16, kernel_size=(16,), stride=(1,), padding=(8,))
    (7): ReLU(原地=True)
    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  ）
  （seq_FClayer）：线性（in_features = 3008，out_features = 1024，偏差= True）
  （seq_outlayer）：线性（in_features = 1024，out_features = 491，偏差= True）
）
batch_size_32，learning_rate_0.0001，epoch_time_30
selected_208964_ Protein_score.csv
selected_208964_ Protein_score.csv
警告：iprID Q9HTQ2 数据丢失。跳过...
警告：iprID Q9I559 数据丢失。跳过...
警告：iprID Q9HT21 数据丢失。跳过...
警告：iprID Q9I0Q1 数据丢失。跳过...
警告：iprID Q9HVI7 数据丢失。跳过...
警告：iprID Q9I422 数据丢失。跳过...
警告：iprID Q9I2V9 数据丢失。跳过...
警告：iprID Q9HWB6 数据丢失。跳过...
警告：iprID Q9HVT7 数据丢失。跳过...
警告：iprID Q9I3I5 数据丢失。跳过...
警告：iprID Q9I4C1 数据丢失。跳过...
警告：iprID Q9I5K0 数据丢失。跳过...
警告：iprID P26995 数据丢失。跳过...
警告：iprID Q9I1Y7 数据丢失。跳过...
警告：iprID Q9I316 数据丢失。跳过...
警告：iprID Q9I299 数据丢失。跳过...
警告：iprID Q9I2Q4 数据丢失。跳过...
警告：iprID Q9HT20 数据丢失。跳过...
警告：iprID Q9HV34 数据丢失。跳过...
警告：iprID Q9HX99 数据丢失。跳过...
警告：iprID Q9HZK1 数据丢失。跳过...
警告：iprID Q9HXG5 数据丢失。跳过...
警告：iprID Q9I3F5 数据丢失。跳过...
警告：iprID Q9HV44 数据丢失。跳过...
警告：iprID Q9HY92 数据丢失。跳过...
警告：iprID Q9HVX9 数据丢失。跳过...
警告：iprID Q9I6Z3 数据丢失。跳过...
警告：iprID Q9HU16 数据丢失。跳过...
警告：iprID Q9HYL8 数据丢失。跳过...
警告：iprID Q9HI37 数据丢失。跳过...
警告：iprID Q9I1Y4 数据丢失。跳过...
警告：iprID Q9HW04 数据丢失。跳过...
回溯（最近一次调用最后一次）：
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 990 行，在  中。
    验证（条款[0], 5）
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 972 行，验证中
    每个_fold_scores = Main(train_set, test_set, func=func)
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 831 行，位于 Main 中
    seq_train_out, seq_test_out, seq_t = Seq_train(0.0001, 16, train_benchmark, test_benchmark, 30, func) # 15
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 408 行，Seq_train
    对于batch_idx，枚举（train_data_loader）中的（seqMatrix，domainStence，ppiVect，GO_annotiations）：
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 681 行，位于 __next__
    数据 = self._next_data()
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 721 行，位于 _next_data
    data = self._dataset_fetcher.fetch(index) # 可能会引发 StopIteration
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py​​”，第 52 行，在 fetch 中
    返回 self.collat​​e_fn(数据)
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/collat​​e.py”，第 183 行，在 default_collat​​e 中
    引发 TypeError(default_collat​​e_err_msg_format.format(elem_type))
**类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到**
]]></description>
      <guid>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</guid>
      <pubDate>Thu, 11 Jan 2024 04:55:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 AWS Sagemaker 向 50 名学生教授数据科学和机器学习？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77797651/how-to-use-aws-sagemaker-for-teaching-data-science-and-machine-learning-to-50-st</link>
      <description><![CDATA[我想为 50 名学生提供数据科学和机器学习方面的培训。我的客户不被允许使用任何 Google 产品，例如 Kaggle 或 Google Colab。因此，我计划使用 AWS，学生可以在 amazon sagemaker ipynb 中运行代码。
有没有什么方法可以让每个学生独立运行他们的笔记本并在 AWS 中进行他们想要的实验，并且我可以监控他们？
我有一个 AWS 组织账户。
我怎样才能做到这一点？
我尝试创建具有 50 个子用户的 IAM 用户，但在笔记本中进行更改后，它会自动反映在另一个子帐户中]]></description>
      <guid>https://stackoverflow.com/questions/77797651/how-to-use-aws-sagemaker-for-teaching-data-science-and-machine-learning-to-50-st</guid>
      <pubDate>Thu, 11 Jan 2024 04:17:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用离群数据来训练随机森林回归以用于填充其他缺失数据</title>
      <link>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</link>
      <description><![CDATA[dataAgeNull = data[data[“年龄”].isnull()]
dataAgeNotNull = data[data[“年龄”].notnull()]
remove_outlier = dataAgeNotNull[(np.abs(dataAgeNotNull[“票价”]-dataAgeNotNull[“票价”].mean())&gt;(4*dataAgeNotNull[“票价”].std()))|
                      (np.abs(dataAgeNotNull[“Family_Size”]-dataAgeNotNull[“Family_Size”].mean())&gt;(4*dataAgeNotNull[“Family_Size”].std()))
                     ]
rfModel_age = RandomForestRegressor(n_estimators=2000,random_state=42)
ageColumns = [&#39;出发&#39;, &#39;票价&#39;, &#39;舱位等级&#39;, &#39;性别&#39;, &#39;家庭人数&#39;, &#39;标题1&#39;, &#39;标题2&#39;,&#39;客舱&#39;,&#39;机票信息&#39;]
rfModel_age.fit(remove_outlier[ageColumns], remove_outlier[“年龄”])

ageNullValues = rfModel_age.predict(X= dataAgeNull[ageColumns])
dataAgeNull.loc[:,&quot;年龄&quot;] = AgeNullValues
数据 = dataAgeNull.append(dataAgeNotNull)
data.reset_index(inplace=True, drop=True)

为什么我们使用“票价”的离群数据和“family_size”训练 RandomForestRegressor 来填充“年龄”的缺失数据？
我试图理解这段代码，但仍然无法弄清楚
4]]></description>
      <guid>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</guid>
      <pubDate>Thu, 11 Jan 2024 03:58:16 GMT</pubDate>
    </item>
    <item>
      <title>回归任务中日志转换后的指标解释问题</title>
      <link>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</link>
      <description><![CDATA[我目前正在研究房价预测任务，由于目标变量（价格）的非正态分布，我对它进行了对数转换。我使用 RMSE、MAE 和 MAPE 等指标，并且对于模型训练，我使用了 cross_val_score。
获得预测后，我采用 MAE 和 MAPE 指标的指数将其恢复到原始规模。然而，我遇到了意想不到的小值；两个指标都等于 1。我怀疑这些值不正确。
kf = KFold(n_splits=5, random_state=42, shuffle=True)

def rmse_cv（模型）：
    mse_scorer = make_scorer(mean_squared_error)
    rmse = np.sqrt(cross_val_score(模型, 训练, y_train, 评分=mse_scorer, cv=kf))
    返回均方根误差

def mae_cv（模型）：
    mae_scorer = make_scorer(mean_absolute_error)
    mae = cross_val_score(模型, 训练, y_train, 评分=mae_scorer, cv=kf)
    返回梅

def mape_cv（模型）：
    mape_scorer = make_scorer(mean_absolute_percentage_error)
    mape = cross_val_score(模型, 训练, y_train, 评分=mape_scorer, cv=kf)
    返回马普

lightgbm = LGBMRegressor(num_leaves=6, max_depth=7, random_state=42, n_estimators=500, Objective=&#39;回归&#39;)

rmse = rmse_cv(lightgbm)
mae = mae_cv(lightgbm)
映射 = 映射_cv(lightgbm)
print(&#39;Lightgbm rmse %.4f&#39; % (rmse.mean()))
print(&#39;Lightgbm mae %.4f&#39; % (mae.mean()))
print(&#39;Lightgbm mape %.4f&#39; % (mape.mean()))

Lightgbm rmse 0.1331
Lightgbm mae 0.0874
Lightgbm 映射 0.0073

我希望获得合理且可解释的值，以反映模型在原始规模上的性能。然而，这两个指标都得出了意想不到的小值 1，这似乎不准确。我期望在原始价格范围内能够更有意义地表示模型误差。]]></description>
      <guid>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</guid>
      <pubDate>Thu, 11 Jan 2024 03:13:07 GMT</pubDate>
    </item>
    <item>
      <title>是否可以找到特定日期股票的平均值（Mathematica）？</title>
      <link>https://stackoverflow.com/questions/77797312/is-is-possible-to-find-the-average-value-of-a-stock-on-a-specific-date-mathemat</link>
      <description><![CDATA[我正在尝试使用 Mathematica 的机器学习工具创建一个模型，该模型使用股票的不同特征（包括 6 个月的价值变化）进行半准确的股市预测。我需要特定日期的值来计算 6 个月期间的百分比差异。
我尝试使用财务数据并将开始和结束设置为同一天，但它返回一个错误，指出它们不能相同。检查了文档，找不到其他方法来查找给定时间间隔内股票价值的变化。
如果 Mathematica 无法做到这一点，它是否可以与 R 或 MatLab 等替代编程语言一起使用？我偏爱 Mathematica，但总体来说我很灵活。]]></description>
      <guid>https://stackoverflow.com/questions/77797312/is-is-possible-to-find-the-average-value-of-a-stock-on-a-specific-date-mathemat</guid>
      <pubDate>Thu, 11 Jan 2024 02:10:59 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和语言处理[关闭]</title>
      <link>https://stackoverflow.com/questions/77796617/ai-and-language-processing</link>
      <description><![CDATA[在开发人工智能应用程序来分析和减轻社交媒体声明中的声誉风险的背景下，检测潜在攻击性或文化不敏感内容的最有效的自然语言处理技术是什么？
我在 Huggingface 等网站上研究过法学硕士。然而，这种方法似乎有点碰运气，大多数法学硕士都需要进一步的培训。]]></description>
      <guid>https://stackoverflow.com/questions/77796617/ai-and-language-processing</guid>
      <pubDate>Wed, 10 Jan 2024 22:00:34 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型是否有可能通过将其概率指定为“两者都不”来预测新数据不适合用于训练的任何类别？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77796241/is-it-possible-for-an-ml-model-to-predict-that-new-data-doesnt-fit-any-of-the-c</link>
      <description><![CDATA[我正在 python 中使用 sklearn.ensemble 中的 RandomForestClassifier 来训练 ML 模型。我有 2 个类/模型（比如 A 和 B）可以生成曲线。在输入中，每行代表一条曲线，每列给出不同 x 值的 y 值。这些值是从 .txt 文件中读取的。
我想训练 ML 模型，以便当我向它提供新曲线时，它可以预测新曲线属于模型 A、模型 B 或两者都不属于的概率。例如如果我提供一条假曲线（不属于任何模型），我希望将其标记为“两者都不是”或类似的内容。
我面临的问题是，使用 Predict.proba() 的两个类（A 和 B）的概率总和为 1，即随机森林将每条新曲线分配给模型，而我无法得到新曲线不属于任何一个的情况。在上述情况下有没有办法执行此操作？或者是否可以使用随机森林以外的其他东西？
下面是代码的工作示例：
导入 pandas 作为 pd
将 numpy 导入为 np
从 sklearn.ensemble 导入 RandomForestClassifier


X_train = pd.read_csv(‘training_dataset.txt’)
X_test = pd.read_csv(&#39;test_dataset.txt&#39;)
y_train = pd.read_csv(&#39;training_dataset_label.txt&#39;)
y_test = pd.read_csv(&#39;test_dataset_label.txt&#39;)

X_train1 = X_train.值
X_test1 = X_test.值

y_train1 = y_train.值
y_test1 = y_test.值

模型 = RandomForestClassifier()
model.fit(X_train1, y_train1.ravel())
预测 = model.predict(X_test1)
概率 = model.predict_proba(X_test1)

这是我得到的输出，其中每一行给出新曲线属于 A 或 B 的概率

&lt;表类=“s-表”&gt;
&lt;标题&gt;

一个
B


&lt;正文&gt;

0.94
0.06


0.14
0.86


1.00
-


0.41
0.59


0.15
0.85


0.83
0.17


0.77
0.23


0.65
0.35


0.99
0.01




如果新曲线不属于任何一个，我预计 A 和 B 的输出（预测概率）均为 0。]]></description>
      <guid>https://stackoverflow.com/questions/77796241/is-it-possible-for-an-ml-model-to-predict-that-new-data-doesnt-fit-any-of-the-c</guid>
      <pubDate>Wed, 10 Jan 2024 20:38:53 GMT</pubDate>
    </item>
    <item>
      <title>是什么导致 keras.model.evaluate 出现错误？不兼容的形状：[32] 与 [32,3]，并且“输出”必须具有等级 (ndim)“target.ndim - 1”</title>
      <link>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</guid>
      <pubDate>Wed, 10 Jan 2024 16:47:49 GMT</pubDate>
    </item>
    <item>
      <title>SHAP KernelExplainer 不接受 DMatrix 也不接受 numpy 数组</title>
      <link>https://stackoverflow.com/questions/77794688/shap-kernelexplainer-not-accepting-a-dmatrix-nor-a-numpy-array</link>
      <description><![CDATA[我正在尝试绘制我训练的 XGBoost 模型的 SHAP 分析图。类似于这个.
但是，我使用了 Dart booster，所以 shap.TreeExplainer 不起作用。然后，我尝试使用应该对我有用的 shap.KernelExplainer 。但是，它不接受任何常见类型的输入。
我的代码是这样的：
第一次尝试
# 要预测的数据
full_data = xgb.DMatrix(full_X, label=full_y, feature_names=feature_names)

# 使用 DART booster 预训练的 XGB 模型
loaded_model.set_param({“device”:“cuda”})


xgb_predict = lambda x:loaded_model.predict(x)
解释器 = shap.KernelExplainer(xgb_predict, full_data)

我得到：
TypeError：作为数据对象传递的未知类型：

第二次尝试
我还尝试提供一个 numpy 数组：
X_np = np.array(full_X)

解释器 = shap.KernelExplainer(xgb_predict, X_np)

但它也会返回一个错误：
TypeError: (&#39;期望数据是 DMatrix 对象，得到：&#39;, )

我使用的是 shap 0.44.0 和 xgboost 2.0.2
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77794688/shap-kernelexplainer-not-accepting-a-dmatrix-nor-a-numpy-array</guid>
      <pubDate>Wed, 10 Jan 2024 15:55:55 GMT</pubDate>
    </item>
    <item>
      <title>使用 1 或 3 通道灰度图像的 CNN 基准</title>
      <link>https://stackoverflow.com/questions/77793280/cnn-benchmark-on-using-grayscale-images-with-1-or-3-channels</link>
      <description><![CDATA[我目前使用的 cnn（MANet、带有 imagenet 权重的 effectivenet b-3）不是由我开发的，是在彩色 Bing 卫星图像上进行训练的，因此第一个模型配置引用了 3 通道图像，但是还有第二个模型配置使用 2 个图像和 6 个通道（一张卫星图像、当前的 Bing 地图和一张来自 Corona 数据集的 60 年代至 70 年代）。
我对它的使用纯粹局限于特定的地理区域，因此我的任务是微调来自不同地理区域的 300-400 张图像（其中我可以获取当前的 Bing 图像和来自 Corona 数据集的灰度图像）并分析结果。
第一个问题是关于通道数量的；由于第二张图像 Corona 是灰度图像，那么输入通道总数不应该是 4 吗？
然而，模型的架构对微调施加了限制，正因为如此，我的想法是，可能选择 6 作为输入通道的数量，以便将灰度图像视为 RGB，并且在用法，这可能吗？
在线搜索，我发现这个非常好的指南灰度图像上的迁移学习 最后提出了一种灰度图像的各种用途和微调类型之间的比较研究，你知道是否有有什么学术层面的内容吗（论文、谷歌学术链接）？
最后一件事，在上面链接的指南中，使用 3 个通道的性能下降没有量化，让我更好地解释一下，因为我必须首先从头开始训练模型，然后进行微调，训练过程是在5000 张 2k 图像，在没有任何特殊安排的情况下，我将 Colab 上提供的 15gb RAM 饱和，假设使用 4 个通道而不是 6 个通道，我能够在空间和时间方面获得多少收益？
非常感谢您的回答，希望我的回答尽可能清楚。]]></description>
      <guid>https://stackoverflow.com/questions/77793280/cnn-benchmark-on-using-grayscale-images-with-1-or-3-channels</guid>
      <pubDate>Wed, 10 Jan 2024 12:14:35 GMT</pubDate>
    </item>
    <item>
      <title>如何在 python 3.12.1 上安装 PyTorch</title>
      <link>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</link>
      <description><![CDATA[我正在安装 DARTS TimeSeries 库 (https: //github.com/unit8co/darts/blob/master/INSTALL.md#enabling-Optional-dependencies），但我遇到了依赖项安装问题。在 DARTS 安装指南中，它说如果我们遇到这个问题，我们必须参考 PyTorch 的官方安装指南，然后尝试再次安装 Darts。然后，当我尝试在 python 3.12.1 上安装 torch 时，我遇到了这个错误：
&lt;块引用&gt;
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版。

如何解决？
我使用 PyCharm 作为 Python 代码编辑器。
我尝试了pip install darts，但它没有安装所有软件包并遇到此错误错误：subprocess-exited-with-error
 用于安装构建依赖项的 pip 子进程未成功运行。
  │ 退出代码：1
  ╰─&gt; 【136行输出】
      正在收集setuptools&gt;=64.0
        从 https://files.pythonhosted.org/packages 获取 setuptools&gt;=64.0 的依赖信息

然后，我尝试使用 pip install torch 安装 torch 并遇到此错误
错误：找不到满足火炬要求的版本（来自版本：无）
错误：找不到火炬的匹配发行版]]></description>
      <guid>https://stackoverflow.com/questions/77792551/how-to-install-pytorch-on-python-3-12-1</guid>
      <pubDate>Wed, 10 Jan 2024 10:16:06 GMT</pubDate>
    </item>
    <item>
      <title>我在视觉变压器中有矩形图像数据集。我设置 image_size= (128, 256) 但补丁大小可能是多少？</title>
      <link>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</guid>
      <pubDate>Tue, 09 Jan 2024 16:55:52 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归和决策树之间的区别</title>
      <link>https://stackoverflow.com/questions/76161673/difference-between-logistic-regression-and-decision-trees</link>
      <description><![CDATA[我正在研究决策树，并了解到它通常用于分类问题。
但逻辑回归也仅用于分类问题。
于是我在网上到处搜索，但没有得到满意的结果。我真的很困惑我们什么时候应该使用什么，或者给我一些用例，其中任何一个都可以更好地工作]]></description>
      <guid>https://stackoverflow.com/questions/76161673/difference-between-logistic-regression-and-decision-trees</guid>
      <pubDate>Wed, 03 May 2023 08:04:30 GMT</pubDate>
    </item>
    </channel>
</rss>