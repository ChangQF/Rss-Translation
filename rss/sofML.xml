<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 26 Dec 2023 18:16:30 GMT</lastBuildDate>
    <item>
      <title>定义类实例时出现属性错误</title>
      <link>https://stackoverflow.com/questions/77718541/getting-attribute-error-while-defining-instance-of-class</link>
      <description><![CDATA[作为菜鸟似乎无法完成这项工作。“data”是实际的 pandas 数据框。
类 MyStocksEnv(TradingEnv):

    def _process_data（自身）：

        价格 = self.data[&#39;收盘价&#39;].values

        signal_features = self.data[[&#39;收盘&#39;, &#39;开盘&#39;, &#39;最高&#39;, &#39;最低&#39;]].values

        返回价格，信号特征`



# env_name = &#39;stocks-v0&#39; # 或 &#39;forex-v0&#39;

# env =gym.make(env_name)

# 创建一个函数来制作环境

# def make_env(env_id, 种子):

    #def _init():

        #env = 健身房.make(env_id)

        #env.seed(种子)

        #返回环境

    #返回_init

# -----------

# my_env = MyStocksEnv(df=数据，window_size=10，frame_bound=(10，len(数据)))

# my_env = MyStocksEnv(df=数据, window_size=10)

my_env = MyStocksEnv(data, window_size=10) # 假设 window_size 是必需参数

价格，signal_features = my_env._process_data(df=data)

# 并行环境数量

环境数 = 3

# 选择 DummyVecEnv（单进程）或 SubprocVecEnv（多进程）

# envs = DummyVecEnv([make_env() for _ in range(num_envs)])

envs = SubprocVecEnv([lambda: my_env(&#39;stocks-v0&#39;, Seed) for Seed in range(num_envs)])

# 使用 VecCheckNan 检查观察和奖励中的 NaN 值

vec_env = VecCheckNan(envs, raise_exception=Tre)`

在 Google Colab 中收到此错误：
&lt;小时/&gt;
AttributeError Traceback（最近一次调用最后一次）
 在&lt;细胞系：18&gt;()
16 # my_env = MyStocksEnv(df=数据, window_size=10)
17 号
---&gt; 18 my_env = MyStocksEnv(data, window_size=10) # 假设 window_size 是必需参数
19 个价格，signal_features = my_env._process_data(df=data)
20
1 帧
 在_process_data（自身）中
1 类 MyStocksEnv(TradingEnv)：
2 def _process_data(自身):
----&gt; 3 价格 = self.data[&#39;Close&#39;].values
4 signal_features = self.data[[&#39;收盘&#39;, &#39;开盘&#39;, &#39;高&#39;, &#39;低&#39;]].values
5 个返回价格，signal_features
AttributeError：“MyStocksEnv”对象没有属性“data”
我实在无法理解这个问题。编码方面完全是新手。]]></description>
      <guid>https://stackoverflow.com/questions/77718541/getting-attribute-error-while-defining-instance-of-class</guid>
      <pubDate>Tue, 26 Dec 2023 18:02:57 GMT</pubDate>
    </item>
    <item>
      <title>在 R 的插入符中定义一个uneGrid会自动触发GridSearch吗？</title>
      <link>https://stackoverflow.com/questions/77718109/does-defining-a-tunegrid-in-rs-caret-automatically-trigger-a-gridsearch</link>
      <description><![CDATA[我正在做一个多类分类项目，目前处于超参数优化阶段。运行网格搜索很好，使用 R 和插入符号，定义网格并将其传递给 train 中的 trainGrid 参数。运行大约需要 1.5 天，但考虑到我使用的硬件和网格的大小，这并不奇怪。
现在我正在尝试其他选项，特别是随机搜索，目前我的代码如下所示：
paramGrid &lt;- Expand.grid(
  n 轮 = c(100, 200, 300, 400, 500, 600, 700, 800),
  最大深度 = c(4, 6, 8, 10),
  eta = seq(0.05, 0.25, length.out = 5),
  伽玛 = seq(0, 0.1, length.out = 3),
  colsample_bytree = seq(0.6, 1, length.out = 3),
  最小儿童体重 = c(1, 3, 5),
  子样本 = seq(0.6, 1, length.out = 3)
）

trainControlMethod &lt;- trainControl(
  方法=“repeatedcv”，
  数量 = 10,
  重复次数 = 1,
  搜索=“随机”，
  verboseIter = TRUE,
  类概率 = TRUE,
  允许并行 = TRUE
）

randomSearchModel &lt;- 训练（
  x = X,
  y = y，
  方法=“xgbTree”，
  trControl = 训练控制方法，
  #tuneGrid = paramGrid,
  曲调长度 = 60,
  度量=“准确度”
）

上述代码的目的是使用 10 倍分层 CV 尝试 60 个调整参数（随机）。
如果我将 tuneGrid 行注释掉，它的行为就像我期望的 RandomSearch 的行为一样。如果我取消注释 tuneGrid，它的运行时间会突然从 1-2.5 小时变为 2.5 天，这让我认为它会触发网格搜索，尽管 search = “random”已定义。
据我所知，文档，tuneGrid 是
&lt;块引用&gt;
具有可能的调整值的数据框。列的命名与调整参数相同

但没有提及将行为转换为网格搜索。
我发现的所有教程都没有定义任何可供随机搜索操作的网格，因此如果没有网格，随机搜索如何知道要尝试的参数的上限和下限？
在 R 插入符号的 train 函数中定义 tuneGrid 是否会自动触发网格搜索（尽管定义了随机搜索）？]]></description>
      <guid>https://stackoverflow.com/questions/77718109/does-defining-a-tunegrid-in-rs-caret-automatically-trigger-a-gridsearch</guid>
      <pubDate>Tue, 26 Dec 2023 16:06:00 GMT</pubDate>
    </item>
    <item>
      <title>机器学习的并行计算使用相同的随机种子产生不同的结果</title>
      <link>https://stackoverflow.com/questions/77717258/parallel-computing-with-machine-learning-produces-different-results-with-the-sam</link>
      <description><![CDATA[使用sklearn.model_selection.RandomizedSearchCV函数。参数列表是在使用np.random.seed(42)后获取的，应该修复。并且每一步都添加了random_state=42。 ShuffleSplit 用于函数分区；
部分代码片段如下：
&lt;前&gt;&lt;代码&gt;my_seed = 42
RandomizedSearchCV(估计器=模型，param_distributions=param_distributions，n_iter=Random_search_n_iter_list\[i\],
cv=ShuffleSplit(test_size=0.3, train_size=0.7, n_splits=10,random_state=my_seed),random_state=my_seed,scoring=“准确度”)

所以我猜这是因为并行计算导致机器学习在采用相同的随机种子后会产生不同的结果。我们该如何解决这个问题呢？或者我在随机过程本身中犯了一个错误？]]></description>
      <guid>https://stackoverflow.com/questions/77717258/parallel-computing-with-machine-learning-produces-different-results-with-the-sam</guid>
      <pubDate>Tue, 26 Dec 2023 12:34:26 GMT</pubDate>
    </item>
    <item>
      <title>我对机器学习中的分类数据编码有两个疑问。建议我如何更好地编码，这将非常有帮助</title>
      <link>https://stackoverflow.com/questions/77717254/i-have-two-doubts-related-to-encoding-categorical-data-in-machine-learning-advi</link>
      <description><![CDATA[
假设我想在 pd.iloc[] 中添加两个不同范围的列和所有行，该怎么做？
我知道您可以通过 pd.iloc[:, [0,2,3] 添加多列。但如果我们想添加两个范围，例如 0:2 和 7:9，那么我们应该怎么做呢？

下面的代码显示了错误 - ValueError: y 应该是一个一维数组，而是得到了一个 shape () 数组。


&lt;小时/&gt;
# 导入必要的库
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd
从 sklearn.impute 导入 SimpleImputer
从 sklearn.compose 导入 ColumnTransformer
从 sklearn.preprocessing 导入 OneHotEncoder
从 sklearn.preprocessing 导入 LabelEncoder

# 加载数据集
df = pd.read_csv(&#39;泰坦尼克号.csv&#39;)
X = df.drop(“幸存”, axis=1)
y = df[“幸存”]

# 识别分类数据
categorical_data = [&#39;Pclass&#39;, &#39;性别&#39;, &#39;登船&#39;]

# 实现 ColumnTransformer 类的实例
ct = ColumnTransformer(transformers = [(&#39;编码器&#39;, OneHotEncoder, categorical_data)], 余数 = &#39;passthrough&#39;)

# 对 ColumnTransformer 实例应用 fit_transform 方法
X = ct.fit_transform(X)

# 将输出转换为 NumPy 数组
X = np.array(X)

# 使用 LabelEncoder 对二进制分类数据进行编码
le = 标签编码器()
y = le.fit_transform(&#39;幸存&#39;)

# 打印更新后的特征矩阵和因变量向量
打印（X）
打印（y）

这段代码有什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77717254/i-have-two-doubts-related-to-encoding-categorical-data-in-machine-learning-advi</guid>
      <pubDate>Tue, 26 Dec 2023 12:33:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Synthesia 风格的视频转换为 Midi 文件？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77717140/how-can-i-convert-a-synthesia-style-video-to-a-midi-file</link>
      <description><![CDATA[我正在尝试找出一些方法来使用 Python 将一些合成风格的视频转换为 midi 文件。视频如下所示： 
我在研究将提取的数据转换为 Midi 的方法时没有遇到问题，因为有大量的资源，但我找不到从视频中提取数据的有效方法。
基本的运动检测不起作用，因为手和粒子也被标记为移动物体（显然）。
有什么方法可以做到这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/77717140/how-can-i-convert-a-synthesia-style-video-to-a-midi-file</guid>
      <pubDate>Tue, 26 Dec 2023 12:04:15 GMT</pubDate>
    </item>
    <item>
      <title>我的模型在训练后预测完全相反的值。 （即将圆的内部值预测为外部值，将外部值预测为内部值）</title>
      <link>https://stackoverflow.com/questions/77716617/my-model-is-predicting-completely-opposite-values-after-training-i-e-predicti</link>
      <description><![CDATA[制作数据集
from sklearn.datasets import make_circles
n_样本=1000
x, y = make_circles(n_samples, 噪声=0.03, random_state=42)
X = torch.from_numpy(x).type(torch.float)
Y = torch.from_numpy(y).type(torch.float)
从 sklearn.model_selection 导入 train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.2, random_state=42)

模型（预测圆）（我们知道圆的方程 s (x**2 + y**2 = r**2)
类 cp(nn.Module):
    def __init__(自身):
        超级().__init__()
        self.r = nn.Parameter(torch.randn(1, require_grad = True, dtype=torch.float))
    def 前向（自身，x）：
        返回 x[:, 0]**2 + x[:, 1]**2 - self.r**2
火炬.manual_seed(42)
米 = cp()
loss_fn = nn.BCEWithLogitsLoss()
opt = torch.optim.SGD(params = m.parameters(), lr=0.1)

训练循环
&lt;前&gt;&lt;代码&gt;e = 1000
对于范围 (e+1) 内的 i：
    m.train()
    p = m(xtrain).squeeze()
    f = torch.round(torch.sigmoid(p))
    l = loss_fn(p, ytrain)
    acc = precision_fn(f, ytrain)
    opt.zero_grad()
    l.backward()
    opt.step()
    如果（i%10==0）：
        使用 torch.inference_mode()：
            tp = m(xtest).squeeze()
            tf= 火炬.round(火炬.sigmoid(tp))
            tl = loss_fn(tp, ytest)
            tacc = precision_fn(tf, ytest)
            print(f&quot;epoch: {i} | 训练损失: {l:.4f} | 训练 acc: {acc} | 测试损失: {tl:.4f} | 测试 acc: {tacc}&quot;)
            if(i%100==0): 打印(m.state_dict())

如果我按照上述方式训练模型，它会预测 1 为 0，O 为 1。
IE。 ytrain[:10] = 张量([1., 0., 0., 0., 1., 0., 1., 1., 0., 0.])。预测值为： torch.round(torch.sigmoid(m(xtrain[:10]))) = tensor([0., 1., 1., 1., 0., 1., 0., 0., 1., 1.])
但是，当我绘制圆时，它的预测正确（圆的半径预测正确）
预测圆
我试图预测一个圆。里面都是0，外面都是1。但训练后，它以相反的顺序进行预测（即外部 0 和内部 1）。请检查一次。我已经提供了完整的代码。]]></description>
      <guid>https://stackoverflow.com/questions/77716617/my-model-is-predicting-completely-opposite-values-after-training-i-e-predicti</guid>
      <pubDate>Tue, 26 Dec 2023 09:49:49 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>在本地计算机中设置 UDpipe 服务器</title>
      <link>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77715913/setting-up-udpipe-server-in-local-machine</guid>
      <pubDate>Tue, 26 Dec 2023 06:18:57 GMT</pubDate>
    </item>
    <item>
      <title>无法在 F# 中将内存数据传递到 AutoML。不明白为什么它不能编译</title>
      <link>https://stackoverflow.com/questions/77714343/cant-pass-in-memory-data-to-automl-in-f-not-understanding-why-it-doesnt-com</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77714343/cant-pass-in-memory-data-to-automl-in-f-not-understanding-why-it-doesnt-com</guid>
      <pubDate>Mon, 25 Dec 2023 16:43:24 GMT</pubDate>
    </item>
    <item>
      <title>Mediapipe-model-maker安装问题</title>
      <link>https://stackoverflow.com/questions/77713844/mediapipe-model-maker-installation-issue</link>
      <description><![CDATA[我正在安装 mediapipe-model-marker，但遇到以下错误。
这是我的 python 和 pip 版本
在此处输入图像描述
这是我用来安装此软件包的 pip 命令。
pip install mediapipe-model-maker 
这是错误
在此处输入图像描述
我尝试在我的 venv 中下载 medipipe-model-marker 包来使用图像分类模型。]]></description>
      <guid>https://stackoverflow.com/questions/77713844/mediapipe-model-maker-installation-issue</guid>
      <pubDate>Mon, 25 Dec 2023 13:36:29 GMT</pubDate>
    </item>
    <item>
      <title>我有带有标签和模式的 json 意图文件，我需要为我的 FYP 创建聊天机器人</title>
      <link>https://stackoverflow.com/questions/77712864/i-have-json-intent-file-with-tags-and-patterns-and-i-need-to-create-chatbot-from</link>
      <description><![CDATA[我正在创建心理健康聊天机器人，并且我有带有标签和模式的 json 数据意图文件。这是我的五年计划，我不知道从哪里开始为聊天机器人创建模型，我需要一些好的建议和简单的步骤来创建我自己的聊天机器人模型]]></description>
      <guid>https://stackoverflow.com/questions/77712864/i-have-json-intent-file-with-tags-and-patterns-and-i-need-to-create-chatbot-from</guid>
      <pubDate>Mon, 25 Dec 2023 07:42:43 GMT</pubDate>
    </item>
    <item>
      <title>增加 Amazon Sagemaker 培训和评估作业的数量</title>
      <link>https://stackoverflow.com/questions/77710916/increase-the-volume-of-amazon-sagemaker-training-and-evaluation-jobs</link>
      <description><![CDATA[我正在运行带有自定义容器的 Sagemaker 管道以进行培训和评估。训练容器将通过从S3存储桶下载数据来训练模型，并将模型存储到S3存储桶中，评估容器将获取该模型，从S3存储桶下载测试数据并准备评估结果。目前，训练数据下载到容器本身中。该代码工作正常，但对于大量数据，我收到以下错误：OSError：[Errno 28]设备上没有剩余空间。我正在考虑附加一个 EBS 卷，以便可以在 EBS 卷中下载训练数据，这样我们就可以避免错误。
有人实施过类似的解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/77710916/increase-the-volume-of-amazon-sagemaker-training-and-evaluation-jobs</guid>
      <pubDate>Sun, 24 Dec 2023 14:26:05 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”</title>
      <link>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</link>
      <description><![CDATA[我正在尝试使用最新的可用资源来开发一些时间序列序列预测。为此，我确实检查了 TensorFlow 时间序列中的示例代码，但收到此错误：
AttributeError：模块“tensorflow.python.pywrap_tensorflow”没有属性“TFE_Py_RegisterExceptionClass”

我正在使用 Anaconda。当前环境是Python 3.5和TensorFlow 1.2.1。也尝试过 TensorFlow 1.3，但没有任何改变。
这是我的代码尝试运行。我在谷歌上没有找到与该问题相关的任何有用信息。有什么解决办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/46010571/attributeerror-module-tensorflow-python-pywrap-tensorflow-has-no-attribute-t</guid>
      <pubDate>Sat, 02 Sep 2017 04:48:51 GMT</pubDate>
    </item>
    <item>
      <title>张量流，我想改变输入图像大小</title>
      <link>https://stackoverflow.com/questions/41703944/tensorflow-i-want-to-change-input-image-size</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/41703944/tensorflow-i-want-to-change-input-image-size</guid>
      <pubDate>Tue, 17 Jan 2017 17:59:58 GMT</pubDate>
    </item>
    <item>
      <title>绘制具有多个标签的混淆矩阵 sklearn</title>
      <link>https://stackoverflow.com/questions/39033880/plot-confusion-matrix-sklearn-with-multiple-labels</link>
      <description><![CDATA[我正在为多个标记数据绘制混淆矩阵，其中标签如下所示：

&lt;块引用&gt;
  标签1: 1, 0, 0, 0
标签2：0, 1, 0, 0
标签3：0, 0, 1, 0
标签4：0, 0, 0, 1

我能够使用以下代码成功分类。 我只需要一些帮助来绘制混淆矩阵。
 对于范围 (4) 中的 i：
        y_train= y[:,i]
        print(&#39;训练科目 %d, 班级 %s&#39; % (subject, cols[i]))
        lr.fit(X_train[::样本,:],y_train[::样本])
        pred[:,i] = lr.predict_proba(X_test)[:,1]

我使用下面的代码来打印混淆矩阵，但它总是返回一个 2X2 矩阵
预测 = lr.predict(X_train)

打印（confusion_matrix（y_train，预测））
]]></description>
      <guid>https://stackoverflow.com/questions/39033880/plot-confusion-matrix-sklearn-with-multiple-labels</guid>
      <pubDate>Fri, 19 Aug 2016 07:56:40 GMT</pubDate>
    </item>
    </channel>
</rss>