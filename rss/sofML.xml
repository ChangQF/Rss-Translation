<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 28 Nov 2023 05:50:16 GMT</lastBuildDate>
    <item>
      <title>如何使用tensorflow训练用于面部比较的ML模型并在java中使用它？</title>
      <link>https://stackoverflow.com/questions/77561597/how-to-train-a-ml-model-for-face-comparison-using-tensorflow-and-use-it-in-java</link>
      <description><![CDATA[我想比较两张脸，无论它们是否是同一个人。为此，我使用预训练模型 (FaceNet) 来获取面部嵌入并比较两个面部。
为了使用 FaceNet 模型，我使用了这个 github 链接。但我无法这样做，因为它是 5 年前的代码，并且给我带来了折旧错误。
我有 LFW 数据集（成对的图像），我想自己训练一个模型，并想用它在 java 中比较人脸（使用人脸嵌入）。
指导我如何使用tensorflow训练模型并在java中使用它进行面部比较？]]></description>
      <guid>https://stackoverflow.com/questions/77561597/how-to-train-a-ml-model-for-face-comparison-using-tensorflow-and-use-it-in-java</guid>
      <pubDate>Tue, 28 Nov 2023 05:46:10 GMT</pubDate>
    </item>
    <item>
      <title>用于线性回归的随机梯度下降算法的意外输出</title>
      <link>https://stackoverflow.com/questions/77560377/unexpected-output-with-stochastic-gradient-descent-algorithm-for-linear-regressi</link>
      <description><![CDATA[在为我的 ML 作业实现 SGD 算法时，我得到了意外的输出。
这是我的训练数据的一部分，通常有 320 行：

我首先做了一些数据预处理：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 StandardScaler
将 numpy 导入为 np

train_data = pd.read_csv(&#39;carseats_train.csv&#39;)
train_data.replace({&#39;是&#39;: 1, &#39;否&#39;: 0}, inplace=True)
onehot_tr = pd.get_dummies(test_data[&#39;ShelveLoc&#39;], dtype=int, prefix_sep=&#39;_&#39;, prefix=&#39;ShelveLoc&#39;)
train_data = train_data.drop(&#39;ShelveLoc&#39;, axis=1)
train_data = train_data.join(onehot_tr)


train_data_Y = train_data.iloc[:, 0]
train_data_X = train_data.drop(&#39;销售额&#39;, axis=1)


然后实现这样的算法：
&lt;前&gt;&lt;代码&gt;学习率 = 0.01
epoch_num = 50
初始w = 0.1
截距 = 0.1
w_matrix = np.ones((12, 1)) * 初始w

对于范围内的 e（epoch_num）：
    对于范围内的 i(len(train_data_X))：

        x_i = train_data_X.iloc[i].to_numpy()
        y_i = train_data_Y.iloc[i]
        
        y_估计 = np.dot(x_i, w_matrix) + 截距
        
        grad_w = x_i.reshape(-1, 1) * (y_i - y_估计)
    
        grad_intercept = (y_i - y_估计)
        
       
        w_matrix = w_matrix - 2 * 学习率 * grad_w
        截距 = 截距 - 2 * 学习率 * 梯度截距
        
        

print(&quot;最终权重：\n&quot;, w_matrix)
print(&quot;最终拦截：&quot;,拦截)

但是输出是
最终权重：
 [[南]
 [南]
 [南]
 [南]
 [南]
 [南]
 [南]
 [南]
 [南]
 [南]
 [南]
 [楠]]
最终截距：[nan]

我以不同的学习率运行它，我也尝试了收敛阈值，但仍然得到相同的结果..我无法找出为什么我的代码给我nans..
有人能看到这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77560377/unexpected-output-with-stochastic-gradient-descent-algorithm-for-linear-regressi</guid>
      <pubDate>Mon, 27 Nov 2023 22:46:46 GMT</pubDate>
    </item>
    <item>
      <title>如何提取给定文档集的顶级分类器特征</title>
      <link>https://stackoverflow.com/questions/77560320/how-to-extract-top-classifier-features-for-a-given-set-of-documents</link>
      <description><![CDATA[我有一个经过二元分类任务训练的逻辑回归分类器。我想提取 X 中给定文档集的顶级分类器特征（信息最丰富的系数）。这些文档的索引存储在名为 idx_list 的列表中。
我尝试使用以下代码提取 X 中所有文档的主要特征：
 def most_informative_feature_for_binary_classification（分类器，向量化器，n=20）：
        类标签 = 分类器.classes_
        feature_names = vectorizer.get_feature_names_out()
        topn_class1 = 排序(zip(classifier.coef_[0], feature_names))[:n]
        topn_class2 = 排序(zip(classifier.coef_[0], feature_names))[-n:]
        print(&#39;0 类主要功能： ----------------------&#39;)
        class0_feat =[]
        对于 coef，topn_class1 中的壮举：
            #print (class_labels[0], coef, feat)
            打印（壮举）
            class0_feat.append(feat )
    
        class0_feat = [str(x) for x in class0_feat]
        使用 open(&#39;../../classification/result/class0_top_features_top_&#39;+str(top_features_nb)+&#39;_&#39;+network+&#39;.txt&#39;,&#39;w&#39;) 作为 f：
            f.write(&#39;\n&#39;.join(class0_feat))
        
        print(&#39;1 类主要功能： ----------------------&#39;)
        class1_feat = []
        对于 coef，相反的壮举（topn_class2）：
            #print (class_labels[1], coef, feat)
            打印（壮举）
            class1_feat.append(壮举)

此代码适用于提取 X 中所有文档的主要特征，但我想提取 idx_list 定义的一组特定文档的主要特征。
使用 Sklearn 对文本文档进行分类：
向量化器 = TfidfVectorizer(input=&#39;文件名&#39;, min_df=mindf, max_df = maxdf)
        X = 矢量化器.fit_transform(friend_files)
        
        print(&quot;X 形状：&quot;,X.shape)

        y = list(username_labels.values()) # 0 或 1

        clf = 逻辑回归()

        clf.fit(X, y)
        most_informative_feature_for_binary_classification3（clf，矢量化器，n=10）

如何修改代码以提取 idx_list 指定文档的顶级特征？]]></description>
      <guid>https://stackoverflow.com/questions/77560320/how-to-extract-top-classifier-features-for-a-given-set-of-documents</guid>
      <pubDate>Mon, 27 Nov 2023 22:32:30 GMT</pubDate>
    </item>
    <item>
      <title>神经网络意外预测</title>
      <link>https://stackoverflow.com/questions/77560144/neuralnet-unexpected-prediction</link>
      <description><![CDATA[我试图了解神经网络包是如何工作的。
我使用的是 mnist 数据集，其中包含对应于不同图片的 60.000 行和代表图片每个像素的 785 列（除了第一个像素）
与图片标签对应的列）。
initial_data &lt;- read.csv(file = &#39;train.csv&#39;, header = TRUE)

数据如下所示：
 标签 Pixel1 Pixel2 Pixel3 Pixel4 Pixel5 Pixel6 ...
1 5 0 0 3 0 1 0 ...
2 3 0 0 0 7 0 0 ...
ETC

首先，我删除方差等于 0 的像素。因为它们无法提供评估图片中写入的数字的信息。
filtered_data &lt;-initial_data %&gt;%
  select_if(函数(列) var(列) != 0)

# 显示新过滤数据的维度
暗淡（过滤数据）

然后我对数据进行标准化，以确保每个功能的贡献相同
到模型中，算法不受较大尺度特征的影响。
filtered_data &lt;- as.data.frame(scale(filtered_data[-1]))

现在我进行数据分区（80% 训练和 20% 测试）。
filtered_data$label &lt;-initial_data$label
filtered_data &lt;-filtered_data %&gt;% select(标签, everything())
索引 &lt;- createDataPartition(filtered_data$label, p = 0.8, list = FALSE)

# 创建训练集和验证集
训练数据&lt;-过滤数据[索引，]
validation_data &lt;-filtered_data[-index, ]

# 通过预测变量和标签分隔
训练数据X &lt;- 训练数据[-1]
训练数据Y &lt;- 训练数据[1]
validation_data_X &lt;-validation_data[-1]
validation_data_Y &lt;-validation_data[1]

现在我生成一个非常简单的神经网络并进行预测
input_variables &lt;- 粘贴（名称（training_data_X），collapse =＆quot; +＆quot;）
输出变量 &lt;- 名称(training_data_Y)[1]
content_formula &lt;- 粘贴（输出变量，“~”，输入变量）

simple_nn_model &lt;- 神经网络（内容公式，数据 = 训练数据，隐藏 = 1，
                             act.fct =“逻辑”，线性输出= FALSE）

Predictions_simple_model &lt;- 预测（simple_nn_model，newdata =validation_data_X）

问题：我希望对象predictions_simple_model包含10列（每列代表0到9之间的一个数字），并且它们的值范围应该从0到1（取决于预测者所做的预测）模型）。但是，相反，我获得了一列，并且它们的所有值都等于 1。
&lt;前&gt;&lt;代码&gt;&gt;预测简单模型
           [,1]
137 1.0000000
171 1.0000000
213 1.0000000
225 1.0000000
236 1.0000000
420 1.0000000
第576章 1.0000000
615 1.0000000
899 1.0000000
ETC

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77560144/neuralnet-unexpected-prediction</guid>
      <pubDate>Mon, 27 Nov 2023 21:52:43 GMT</pubDate>
    </item>
    <item>
      <title>将 pyspark 数据帧保存为 RecordIO protobuf</title>
      <link>https://stackoverflow.com/questions/77559860/save-pyspark-dataframe-as-recordio-protobuf</link>
      <description><![CDATA[我想以 RecordIO protobuf 格式保存我的 pyspark 数据帧。我正在使用 Amazon EMR 运行我的 pyspark 脚本，并且我想使用 AWS SageMaker 来训练机器学习模型。
SageMaker 管道模式仅接受 RecordIO protobuf 作为输入，因此我的问题
我尝试将我的 pyspark 数据帧保存为 recordio protobuf，如下所示：
output_path = f“s3://my_path/output_processed”
df_transformed.write.format(“sagemaker”).mode(“覆盖”).save(output_path)

但是当我运行 sagemaker 模型时，即使我的数据帧没有缺失值，我也会收到缺失值的错误。可能是什么问题以及如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77559860/save-pyspark-dataframe-as-recordio-protobuf</guid>
      <pubDate>Mon, 27 Nov 2023 20:49:10 GMT</pubDate>
    </item>
    <item>
      <title>如何将文本描述映射到类别？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77559226/how-do-i-map-text-descriptions-to-categories</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77559226/how-do-i-map-text-descriptions-to-categories</guid>
      <pubDate>Mon, 27 Nov 2023 18:39:59 GMT</pubDate>
    </item>
    <item>
      <title>展开数据表，无法获得正确的代码！ ：/ [关闭]</title>
      <link>https://stackoverflow.com/questions/77558724/expanding-the-datasheet-cant-get-the-code-right</link>
      <description><![CDATA[问题一：红酒数据集来源的文章还提供了来自 vhino verde 地区白葡萄酒的数据。假设白葡萄酒和红酒有一些共享属性，让我们看看是否可以通过将白葡萄酒数据添加到训练集中来提高模型的性能。
白葡萄酒数据总共包含 4898 个观测值。然而，其中五个观测值来自第 9 类。由于红酒数据集中没有第 9 类葡萄酒，因此我们丢弃这些观测值。
下面的代码加载白葡萄酒数据集并将其与您的训练数据合并。填写代码中缺失的行，以使用额外数据训练模型并在验证数据集上对其进行评估。
(https://foundations-of-ml.ida. liu.se/content/section7/practical_example)
帮助我已经尝试了大约 10 个小时，我对此很糟糕，但很接近：/]]></description>
      <guid>https://stackoverflow.com/questions/77558724/expanding-the-datasheet-cant-get-the-code-right</guid>
      <pubDate>Mon, 27 Nov 2023 17:08:30 GMT</pubDate>
    </item>
    <item>
      <title>随机森林分类器抛出错误“DataFrame”对象没有属性“_validate_params”[关闭]</title>
      <link>https://stackoverflow.com/questions/77556738/random-forest-classifier-throws-an-error-dataframe-object-has-no-attribute-v</link>
      <description><![CDATA[这是我使用的数据集和一些代码。
我一直在从事一个 ML 项目，当我尝试使用随机森林分类进行训练时，它抛出了此“DataFrame”对象没有属性“_validate_params”错误。有人能帮我解决这个问题吗？输出错误在此处。
我的列名称中有空格，之前显示过类似的错误。现在我已经用下划线替换了空格，现在就抛出了这个错误。
rf = RandomForestClassifier
rf.fit(X_train, y_train)

使用上面数据的代码抛出错误。
 AttributeError Traceback（最近一次调用最后一次）
/var/folders/94/3rhbwt5n0s5fbvc_2gk50dwm0000gn/T/ipykernel_62767/1137608719.py 在？（）
      3 青光眼DF.head()
      4 # 训练随机森林分类器模型。
      5
      6 rf = 随机森林分类器
----&gt; 7 rf.fit(X_train, y_train)

~/Desktop/projects/medical_webapp/medical_env/lib/python3.11/site-packages/sklearn/base.py 中？（估计器，*args，**kwargs）
   第1141章和 _is_fitted（估计器）
   第1142章）
   第1143章
   攀上漂亮女局长之后1144
-&gt;第1145章
   1146
   第1147章
   第1148章

〜/ Desktop/projects/medical_webapp/medical_env/lib/python3.11/site-packages/pandas/core/generic.py 在？（自我，名称）
   6200 和名称不在 self._accessors 中
   第6201章
   6202）：
   第6203章
-&gt;第6204章

AttributeError：“DataFrame”对象没有属性“_validate_params”
]]></description>
      <guid>https://stackoverflow.com/questions/77556738/random-forest-classifier-throws-an-error-dataframe-object-has-no-attribute-v</guid>
      <pubDate>Mon, 27 Nov 2023 12:01:07 GMT</pubDate>
    </item>
    <item>
      <title>我们可以在一个 Colab（或 Jupyter Notebook）中使用“train_test_split”两次吗？</title>
      <link>https://stackoverflow.com/questions/77555330/can-we-use-train-test-split-in-one-single-colabor-jupyter-notebook-twice</link>
      <description><![CDATA[我必须使用决策树机器学习算法执行分类和回归。现在我已经完成了代码的回归部分。如果我继续对此进行分类任务，我应该对预处理的数据集执行train_test_split。 在代码中我必须定义 X 和 y 变量，然后执行 X_train、X_test、y_train 和 y_test 部分。回归和分类中都会重复相同的变量。通过从分类中获取相同的变量，它会考虑回归中首先给出的先前值还是会采用新给定的值？
我想清楚地知道我们是否可以在单个 colab 或 jupyter 笔记本中多次使用 train_test_split 函数。]]></description>
      <guid>https://stackoverflow.com/questions/77555330/can-we-use-train-test-split-in-one-single-colabor-jupyter-notebook-twice</guid>
      <pubDate>Mon, 27 Nov 2023 08:05:19 GMT</pubDate>
    </item>
    <item>
      <title>使用 H2O 随机森林进行递归特征消除</title>
      <link>https://stackoverflow.com/questions/77549868/recursive-feature-elimination-with-h2o-random-forest</link>
      <description><![CDATA[我正在 python 中使用 h2o 包来构建一个相当复杂的模型。
它有大约 1500 个特征，但我知道其中大多数并不重要，我想提取给定大小（假设为 100）的子集，以最大化模型的 R 平方。
是否有一些方法已经在 python 中为 h2o 实现了这个？
否则我需要自己编码，但这也意味着多次运行模型，而且我不确定我是否会以正确的方式编码。
一种可能的编码方法是：

保存模型的 R2，然后删除 k 个不太重要的特征
创建第二个模型，但不删除已删除的特征
计算新模型的 R2 并与之前的 R2 进行比较。使用指标来决定是保留新模型还是坚持旧模型。
迭代这些步骤，直到上一步选择旧模型作为最佳模型
我很确定这不会给我功能的“最佳子集”，但我真的希望它足够了。

我想到的第二种方法如下：

设置新模型中所需的特征数 N 和迭代次数 K
保存原始模型 R2 作为参考
从原始模型中随机提取 N 个特征，使用它们的相对重要性作为被提取的概率（更重要的特征更有可能被提取）
保存每个型号的功能列表和新 R2
迭代 K 次后停止算法并比较 R2
选择 R2 最接近原始特征的一组特征
]]></description>
      <guid>https://stackoverflow.com/questions/77549868/recursive-feature-elimination-with-h2o-random-forest</guid>
      <pubDate>Sat, 25 Nov 2023 23:03:26 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中绘制 LSTM 模型的 SHAP 值</title>
      <link>https://stackoverflow.com/questions/77536125/plot-the-shap-values-for-lstm-model-in-python</link>
      <description><![CDATA[我有以下正在运行的代码。
将 numpy 导入为 np
导入形状
从张量流导入keras

X = np.array([[(1,2,3,3,1),(3,2,1,3,2),(3,2,2,3,3),(2,2,1 ,1,2),(2,1,1,1,1)],
              [(4,5,6,4,4),(5,6,4,3,2),(5,5,6,1,3),(3,3,3,2,2),( 2,3,3,2,1)],
              [(7,8,9,4,7),(7,7,6,7,8),(5,8,7,8,8),(6,7,6,7,8),( 5,7,6,6,6)],
              [(7,8,9,8,6),(6,6,7,8,6),(8,7,8,8,8),(8,6,7,8,7),( 8,6,7,8,8)],
              [(4,5,6,5,5),(5,5,5,6,4),(6,5,5,5,6),(4,4,3,3,3),( 5,5,4,4,5)],
              [(4,5,6,5,5),(5,5,5,6,4),(6,5,5,5,6),(4,4,3,3,3),( 5,5,4,4,5)],
              [(1,2,3,3,1),(3,2,1,3,2),(3,2,2,3,3),(2,2,1,1,2),( 2,1,1,1,1)]])
y = np.array([0, 1, 2, 2, 1, 1, 0])

# 使用正确的输入形状更新模型
模型 = keras.Sequential([
    keras.layers.LSTM(128, return_sequences=True, input_shape=(5, 5)), # 带有返回序列的 LSTM 层
    keras.layers.LSTM(128, return_sequences=False), # 另一个 LSTM 层
    keras.layers.Flatten(),
    keras.layers.Dense(128, 激活=&#39;relu&#39;),
    keras.layers.Dense(3,activation=&#39;softmax&#39;) # 3个输出类
]）
model.compile(optimizer=&#39;adam&#39;,loss=&#39;sparse_categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

# 训练模型
model.fit(X, y, epochs=10)

# 将 GradientExplainer 与模型本身一起使用
解释器 = shap.GradientExplainer(模型, X)
shap_values = 解释器.shap_values(X)
打印（形状值）

我想显示一个漂亮的 SHAP 值图。
我尝试了以下代码行
shap.summary_plot(shap_values, X, feature_names=[&#39;特征 1&#39;, &#39;特征 2&#39;, &#39;特征 3&#39;, &#39;特征 4&#39;, &#39;特征 5&#39;]) 
但不工作]]></description>
      <guid>https://stackoverflow.com/questions/77536125/plot-the-shap-values-for-lstm-model-in-python</guid>
      <pubDate>Thu, 23 Nov 2023 10:27:08 GMT</pubDate>
    </item>
    <item>
      <title>如何按照官方方式将 Hugging Face LLaMA v2 模型的权重重新初始化为原始模型？</title>
      <link>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77499162/how-does-one-reinitialize-the-weights-of-a-hugging-face-llama-v2-model-the-offic</guid>
      <pubDate>Fri, 17 Nov 2023 03:15:56 GMT</pubDate>
    </item>
    <item>
      <title>如何在 argparse 中为 AzureML 中的管道添加元组？</title>
      <link>https://stackoverflow.com/questions/77459218/how-to-add-tuple-in-argparse-for-the-pipeline-in-azureml</link>
      <description><![CDATA[我想对我在管道中执行的函数进行argparse元组。为了简单起见，我将跳过读取数据和其他与主题不太相关的步骤。看起来像这样：
def model_train_sales(X_train, order: tuple,seasonal_order: tuple):

    模型 = sm.tsa.SARIMAX(X_train[&#39;sales&#39;], order=order,seasonal_order=seasonal_order)
    结果 = model.fit()

    返回模型、结果

def main():

    解析器 = argparse.ArgumentParser()

    parser.add_argument(&quot;--order&quot;, type=tuple)
    parser.add_argument(&quot;--seasonal_order&quot;, type=tuple)

    args = parser.parse_args()

    模型，结果 = model_train_sales(X_train[&#39;sales&#39;], order=args.order,
    seasonal_order=args.seasonal_order)

此时一切都很好，但是当您开始构建管道时，解析变量的类型不同。
来自 azure.ai.ml 导入命令
从 azure.ai.ml 导入输入、输出

演示模型训练组件 = 命令（
    name=&#39;我的萨里玛管道&#39;,
    display_name=&#39;我的描述&#39;,
    description=&#39;长描述。&#39;,
    输入={
        “订单”：输入（类型=&#39;&lt;类型&gt;&#39;），
        “seasonal_order”：输入（type=&#39;&#39;），
    },
    输出=字典（
        df = 输出（类型=“uri_folder”，模式=“rw_mount”）
    ),
    代码 = feature_creation_src_dir,
    命令=“”“python sarima_model.py \
              --order ${{inputs.order}} --seasonal_order ${{inputs.seasonal_order}} \
              --df ${{输出.df}}
              ”“”，
    环境= f“{pipeline_job_env.name}”{pipeline_job_env.version}”，
）

在这里，我在处签名了我不确定应该是哪种类型的地方。我知道类型是有限的，可以是 string、integer、number 或 bool。
有什么方法可以解析其中的元组吗？或者唯一的方法是分别解析 p, d, q 和 P, D, Q, S 并将它们组合成主函数中的元组？]]></description>
      <guid>https://stackoverflow.com/questions/77459218/how-to-add-tuple-in-argparse-for-the-pipeline-in-azureml</guid>
      <pubDate>Fri, 10 Nov 2023 10:17:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用张量流在每个纪元创建一个新数组</title>
      <link>https://stackoverflow.com/questions/77440102/how-can-i-create-a-new-array-with-each-epoch-using-tensorflow</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77440102/how-can-i-create-a-new-array-with-each-epoch-using-tensorflow</guid>
      <pubDate>Tue, 07 Nov 2023 16:57:35 GMT</pubDate>
    </item>
    <item>
      <title>重新启动运行时后模型加载得到不同的结果</title>
      <link>https://stackoverflow.com/questions/68116676/model-load-get-different-result-after-restart-runtime</link>
      <description><![CDATA[你好，我是神经网络新手，我在训练模型后使用谷歌colab编写了一个模型CNN架构Resnet50，然后保存模型，然后加载模型而不重新启动运行时得到相同的结果，但为什么当重新启动运行时谷歌colab并运行xtrain，ytest时,x_val,y_val 然后再次加载模型得到不同的结果
这是我设置参数的代码
#超参数和回调
批量大小 = 128
纪元数 = 120
输入形状 = (48, 48, 1)
类数 = 7

#编译模型。
从 keras.optimizers 导入 Adam，SGD
模型 = ResNet50(input_shape = (48, 48, 1)，类 = 7)
优化器 = SGD(learning_rate=0.0005)
model.compile(optimizer=optimizer,loss=&#39;sparse_categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

模型.summary()
历史=模型.fit(
    data_generator.flow(xtrain, ytrain,),
    步骤_per_epoch = len（xtrain）/批量大小，
    纪元=num_epochs，
    详细=1，
    验证数据=（x_val，y_val））

将 matplotlib.pyplot 导入为 plt
model.save(&#39;Fix_Model_resnet50editSGD5st.h5&#39;)

#plot 图表
准确度=历史记录.历史[&#39;准确度&#39;]
val_accuracy = 历史.history[&#39;val_accuracy&#39;]
损失=历史.历史[‘损失’]
val_loss = 历史.history[&#39;val_loss&#39;]
num_epochs = 范围(len(准确度))
plt.plot(num_epochs, 准确度, &#39;r&#39;, label=&#39;训练 acc&#39;)
plt.plot(num_epochs, val_accuracy, &#39;b&#39;, label=&#39;验证 acc&#39;)
plt.title(&#39;训练和验证准确性&#39;)
plt.ylabel(&#39;准确度&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.图例()
plt.figure()
plt.plot(num_epochs, loss, &#39;r&#39;, label=&#39;训练损失&#39;)
plt.plot(num_epochs, val_loss, &#39;b&#39;, label=&#39;验证损失&#39;)
plt.title(&#39;训练和验证损失&#39;)
plt.ylabel(&#39;损失&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.图例()
plt.show()

#加载模型
从 keras.models 导入 load_model
model_load = load_model(&#39;Fix_Model_resnet50editSGD5st.h5&#39;)

model_load.summary()


testdatamodel = model_load.evaluate(xtest, ytest)
print(&quot;测试损失&quot; + str(testdatamodel[0]))
print(&quot;测试 Acc:&quot; + str(testdatamodel[1]))

traindata = model_load.evaluate(xtrain, ytrain)
print(&quot;测试损失&quot; + str(traindata[0]))
print(&quot;测试准确率：&quot; + str(traindata[1]))

valdata = model_load.evaluate(x_val, y_val)
print(&quot;测试损失&quot; + str(valdata[0]))
print(&quot;测试记录：&quot; + str(valdata[1]))

-训练并保存模型后，然后运行加载模型，无需重新启动运行时 google colab ：
如你所见
测试得到损失：0.9411 - 准确度：0.6514
训练损失：0.7796 - 准确度：0.7091
ModelEvaluateTest &amp;火车
重启运行时colab后再次运行加载模型：
测试损失：0.7928 - 准确度：0.6999
训练损失：0.8189 - 准确度：0.6965
重新启动运行时评估测试和训练]]></description>
      <guid>https://stackoverflow.com/questions/68116676/model-load-get-different-result-after-restart-runtime</guid>
      <pubDate>Thu, 24 Jun 2021 13:25:12 GMT</pubDate>
    </item>
    </channel>
</rss>