<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 ä¸ª</description>
    <lastBuildDate>Mon, 18 Dec 2023 21:11:57 GMT</lastBuildDate>
    <item>
      <title>KeyErrorï¼šâ€œ[Index(['names_of_categorical_columns'], dtype='object', name='name_of_index_column')] éƒ½ä¸åœ¨ [index] ä¸­â€</title>
      <link>https://stackoverflow.com/questions/77681457/keyerror-none-of-indexnames-of-categorical-columns-dtype-object-name</link>
      <description><![CDATA[æˆ‘ç¼–å†™è¿™æ®µä»£ç æ˜¯ä¸ºäº†è·å–ä¸€ä¸ªå˜é‡ä¸­çš„æ‰€æœ‰åˆ†ç±»åˆ—ï¼Œå¹¶ä½¿ç”¨ OrdinalEncoder() å¯¹å®ƒä»¬è¿›è¡Œç¼–ç ã€‚
æˆ‘çš„ä»£ç ï¼š
s = (X_train.dtypes == &#39;å¯¹è±¡&#39;)
object_cols = åˆ—è¡¨(s[s].index)

ordinal_encoder = OrdinalEncoder(handle_unknown = &#39;use_encoded_value&#39;,unknown_value = 999)

# è¿›è¡Œå¤åˆ¶ä»¥é¿å…æ›´æ”¹åŸå§‹æ•°æ®
label_X_train = X_train.copy()
label_X_valid = X_valid.copy()

# å°†åºæ•°ç¼–ç å™¨åº”ç”¨äºå…·æœ‰åˆ†ç±»æ•°æ®çš„æ¯ä¸€åˆ—
label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])
label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])

æˆ‘æ”¶åˆ°æ­¤é”™è¯¯ï¼ˆåœ¨é—®é¢˜æ ‡é¢˜ä¸­ï¼‰å¹¶ä¸”æ— æ³•å¤„ç†å®ƒã€‚æ‚¨èƒ½å‘Šè¯‰æˆ‘å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿ
æˆ‘å°è¯•ä½¿ç”¨ OrdinalEncoder() å¯¹åˆ†ç±»æ•°æ®è¿›è¡Œç¼–ç ï¼Œç„¶åå†ä½¿ç”¨å®ƒæ¥è®­ç»ƒ XGBRegressor() æ¨¡å‹ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/77681457/keyerror-none-of-indexnames-of-categorical-columns-dtype-object-name</guid>
      <pubDate>Mon, 18 Dec 2023 19:59:08 GMT</pubDate>
    </item>
    <item>
      <title>precisionAtRecall ä» 0 å¼€å§‹</title>
      <link>https://stackoverflow.com/questions/77681250/precisionatrecall-starts-with-0</link>
      <description><![CDATA[åœ¨ä½¿ç”¨å¼ é‡æµè¿›è¡Œæ¨¡å‹è®­ç»ƒæœŸé—´ï¼Œæˆ‘ç›®ç¹äº†ä»¥ä¸‹æŒ‡æ ‡æ›´æ–°ï¼š
åœ¨æ­¤å¤„è¾“å…¥å›¾åƒæè¿°
ä¸¤ä¸ª precisionAtRecall å€¼åˆ†åˆ«å¯¹åº”å¬å›å€¼ 0.8 å’Œ 0.7ã€‚æˆ‘ä¸æ˜ç™½ä¸ºä»€ä¹ˆ 1) precisionAtRecall_0.8 = 0 è€Œ precisionAtRecall_0.7 &gt; 0ï¼Ÿ 2) ä¸ºä»€ä¹ˆ precisionAtRecall_0.8 = 0 åœ¨ 0 å’Œçœ‹ä¼¼åˆç†çš„æ•°å­—ä¹‹é—´æŒ¯è¡ï¼Ÿ
æˆ‘æœŸæœ› precisionAtRecall_0.8 &lt; precisionAtRecall_0.7 ä½†å¦‚æœ precisionAtRecall_0.7 &gt; éé›¶0]]></description>
      <guid>https://stackoverflow.com/questions/77681250/precisionatrecall-starts-with-0</guid>
      <pubDate>Mon, 18 Dec 2023 19:09:02 GMT</pubDate>
    </item>
    <item>
      <title>å¾®è°ƒæœ´ç´ è´å¶æ–¯æ¨¡å‹ä»¥è¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼ˆå¤šç±»åˆ«ç»“æœï¼‰</title>
      <link>https://stackoverflow.com/questions/77681240/fine-tuning-naive-bayesian-model-for-text-classification-multi-categorical-outc</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªåŒ…å«æ•°åƒä¸ªæœ‰å…³ç¾å›½ç»æµé—®é¢˜çš„ Reddit å¸–å­çš„æ•°æ®é›†ã€‚
æˆ‘ä»¬éšæœºæŠ½å–äº†æ€»å¸–å­æ•° 40% çš„æ ·æœ¬ï¼Œå…¶ä¸­æ¯ä¸ªå¸–å­éƒ½åŒ…å«â€œè´£å¤‡â€å†…å®¹ã€‚å…·æœ‰ä¸‰ä¸ªå¯èƒ½å€¼â€œå…±å’Œå…šâ€ã€â€œæ°‘ä¸»å…šâ€çš„æŒ‡ç¤ºç¬¦ã€‚æˆ–â€œç¾è”å‚¨â€å®ƒæ•è·äº†ç»™å®šå¸–å­ä¸­æ¯ä¸ªäº‹ä»¶ä¸­è°å—åˆ°æŒ‡è´£ã€‚
æˆ‘çš„ç›®æ ‡æ˜¯ä½¿ç”¨ 40% çš„äººå·¥æ³¨é‡Šå¸–å­æ¥é¢„æµ‹â€œè´£å¤‡â€çš„ä»·å€¼ã€‚æˆ‘çš„æ•°æ®é›†ä¸­å‰©ä½™ 60% çš„å¸–å­ä¸­å­˜åœ¨å˜é‡ã€‚æˆ‘çœ‹è¿‡ä¸€äº›ç ”ç©¶è®ºæ–‡ä½¿ç”¨æœ´ç´ è´å¶æ–¯æ¨¡å‹æ¥é¢„æµ‹åˆ†ç±»å˜é‡ï¼Œä½†æˆ‘çš„æ¡ˆä¾‹çš„ç»“æœå¹¶ä¸ä»¤äººå°è±¡æ·±åˆ»ã€‚å› æ­¤ï¼Œæˆ‘æƒ³çŸ¥é“è¿™é‡Œä½¿ç”¨çš„ BERT æ¨¡å‹æ˜¯å¦æ›´åˆé€‚ï¼Œæˆ–è€…æˆ‘æ˜¯å¦é”™è¯¯åœ°è¿è¡Œäº†è´å¶æ–¯æ¨¡å‹ã€‚
è¿™æ˜¯æˆ‘çš„ä»£ç ï¼š
#åŠ è½½åŒ…
å›¾ä¹¦é¦†ï¼ˆtidyverseï¼‰
éœ€è¦ï¼ˆè¯»xlï¼‰
éœ€è¦ï¼ˆwritexlï¼‰
å›¾ä¹¦é¦†ï¼ˆé‡å­ï¼‰
åº“ï¼ˆquanteda.textmodelsï¼‰
åº“ï¼ˆæ’å…¥ç¬¦å·ï¼‰

#æ•°æ®ç¤ºä¾‹ï¼š
dput(reddit_corpus[1:5,c(1,2,3,4,8)])


è¾“å‡ºï¼š
ç»“æ„(åˆ—è¡¨(id = c(1933, 7161, 4661, 2885, 5102), ç”¨æˆ·å = c(â€œthe_dogâ€,
&quot;Empyrean Cobalt&quot;ã€&quot;Engineer&quot;ã€&quot;AuraKUPO&quot;ã€&quot;kyo_465&quot;), post = c(&quot;è®¤ä¸º jhk AT Pinoy ç­‰éƒ½åº”è¯¥æ„Ÿè°¢ cecas ä¸ºä»–ä»¬å‡è½»äº†å‹åŠ›&quot;,
â€œScamDetectorè¯´æˆ‘å¸Œæœ›ä½ ä»¬éƒ½æ„è¯†åˆ°UOBå®é™…ä¸Šæ²¡æœ‰å›ç­”Clementçš„é—®é¢˜ç‚¹å‡»å±•å¼€UOBåªæ˜¯ä½¿ç”¨ç›¸åŒçš„æ¨¡æ¿åƒæœºå™¨äººæ¨¡å¼ä¸€æ ·å›å¤â€ï¼Œ
â€œnetzach è¯´è¿™ä¸ª Daniels çš„å®¶ä¼™ç‚¹å‡»å±•å¼€æˆ‘è®¤ä¸ºäººä»¬å¹¶æ²¡æœ‰å®Œå…¨ç†è§£ WP å’Œ Daniel Gohâ€ï¼Œ
â€œTSä»ç„¶æ˜¯å­¦ç”Ÿï¼Œå…¬å¸å¿…é¡»ä»¥ç°é‡‘æ”¯ä»˜FT CPFï¼Œåªæœ‰sinkieséœ€è¦ä»å·¥èµ„ä¸­æ”¯ä»˜ä¸€éƒ¨åˆ†CPFâ€ï¼Œ
â€œponpokku è¯´è‡³å°‘ä»–ä»¬ä¸ä¼šåƒ CECA é‚£æ ·é™çº§ï¼Œå¯¹å½“åœ°äººä¸ä¼šæ„æˆå¨èƒ CECA ish ä½ å¿…é¡»åŠ å€å·¥ä½œæ‰èƒ½ kio ä»–ä»¬çš„ sai å•å‡»å±•å¼€æˆ‘ä¸æƒ³é›‡ç”¨é‚£äº›å‘Šè¯‰æˆ‘æœ‰æ¯”ä»–ä»¬æ›´ç³Ÿç³•çš„äººâ€
), date = c(&quot;2021-07-13 00:00:00 UTC&quot;, &quot;2020-09-22 00:00:00 UTC&quot;,
â€œ2021-08-07 00:00:00 UTCâ€ã€â€œ2021-04-07 00:00:00 UTCâ€ã€â€œ2021-07-23 00:00:00 UTCâ€
), Collective_action = c(0, 0, 0, 0, 0)), row.names = c(NA, -5L
), class = c(&quot;tbl_df&quot;, &quot;tbl&quot;, &quot;data.frame&quot;))

æ„å»ºæ¨¡å‹ï¼šreddit_corpus
#ç”Ÿæˆ 1109 ä¸ªæ•°å­—ï¼ˆ2913 çš„ 38%ï¼‰ï¼Œæ— éœ€æ›¿æ¢
è®¾ç½®ç§å­(300)
id_train &lt;- æ ·æœ¬(1:2913, 1109, æ›¿æ¢ = FALSE)
å¤´ï¼ˆid_trainï¼Œ10ï¼‰

#è·å–è®­ç»ƒé›†
dfmat_training &lt;- dfm_subset(dfmt_sing, id_numeric %in% id_train)

#è·å–æµ‹è¯•é›†ï¼ˆid_trainä¸­æ²¡æœ‰çš„æ–‡æ¡£ï¼‰
dfmat_test &lt;- dfm_subset(dfmt_sing, !id_numeric %in% id_train)

#ä½¿ç”¨textmodel_nb()è®­ç»ƒæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
tmod_nb &lt;- textmodel_nb(dfmat_training, dfmat_training$responsibility_attribution)
æ‘˜è¦(tmod_nb)

dfmat_matched &lt;- dfm_match(dfmat_test, features = featnames(dfmat_training))

ç»“æœï¼š
#æ£€æŸ¥åˆ†ç±»å™¨çš„å·¥ä½œæƒ…å†µ
å®é™…ç±» &lt;- dfmat_matched$responsibility_attribution
Predicted_class &lt;- é¢„æµ‹(tmod_nb, newdata = dfmat_matched)
tab_class &lt;- è¡¨ï¼ˆå®é™…ç±»ï¼Œé¢„æµ‹ç±»ï¼‰
é€‰é¡¹å¡ç±»

è¾“å‡ºï¼š
 é¢„æµ‹ç±»
å®é™…ç±» 1 2 3 4
           1 240 6 5 45
           2 67 2 1 7
           3 79 0 10 15
           4 128 6 5 75

æ··æ·†çŸ©é˜µ
#æˆ‘ä»¬å¯ä»¥ä½¿ç”¨caretåŒ…ä¸­çš„å‡½æ•°confusionMatrix()æ¥è¯„ä¼°åˆ†ç±»çš„æ€§èƒ½
fusionMatrix(tab_class, mode = â€œä¸€åˆ‡â€, Positive = â€œposâ€)

æ€»ä½“ç»Ÿè®¡
                                          
               å‡†ç¡®åº¦ï¼š0.4732
                 95% ç½®ä¿¡åŒºé—´ï¼š(0.4355, 0.5112)

                     ç±»åˆ«ï¼š1 ç±»åˆ«ï¼š2 ç±»åˆ«ï¼š3 ç±»åˆ«ï¼š4
çµæ•åº¦ 0.4669 0.142857 0.47619 0.5282
ç‰¹å¼‚æ€§ 0.6836 0.889217 0.85970 0.7468
é¢„æµ‹å€¼ 0.8108 0.025974 0.09615 0.3505
è´Ÿé¢„æµ‹å€¼ 0.3063 0.980456 0.98126 0.8595
ç²¾åº¦ 0.8108 0.025974 0.09615 0.3505
å¬å›ç‡ 0.4669 0.142857 0.47619 0.5282
F1 0.5926 0.043956 0.16000 0.4213
æ‚£ç—…ç‡ 0.7438 0.020260 0.03039 0.2055
æ£€å‡ºç‡ 0.3473 0.002894 0.01447 0.1085
æ£€æµ‹ç‡ 0.4284 0.111433 0.15051 0.3097
å¹³è¡¡ç²¾åº¦ 0.5753 0.516037 0.66795 0.6375
]]></description>
      <guid>https://stackoverflow.com/questions/77681240/fine-tuning-naive-bayesian-model-for-text-classification-multi-categorical-outc</guid>
      <pubDate>Mon, 18 Dec 2023 19:07:27 GMT</pubDate>
    </item>
    <item>
      <title>è§£é‡Š AutoGluon è¡¨æ ¼åˆ†ç±»å™¨çš„æ–‡æœ¬ç‰¹å¾ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/77680786/explaining-text-features-of-autogluon-tabular-classifier</link>
      <description><![CDATA[æˆ‘æ­£åœ¨è®­ç»ƒ AutoGluon è¡¨æ ¼åˆ†ç±»å™¨ã€‚
æˆ‘çš„æ‰€æœ‰æ•°æ®éƒ½æ˜¯è¡¨æ ¼æ ¼å¼ï¼Œå¹¶ä¸”å¤§å¤šæ•°ç‰¹å¾éƒ½æ˜¯æ•°å­—ã€‚ç„¶è€Œï¼Œè®­ç»ƒä¸­ä½¿ç”¨çš„ä¸€äº›ç‰¹å¾æ˜¯æ–‡æœ¬ç‰¹å¾ã€‚æ˜¯å¦å¯ä»¥è§£é‡Šæ–‡æœ¬ç‰¹å¾å¦‚ä½•å½±å“é¢„æµ‹ï¼Ÿä¾‹å¦‚ï¼Œæˆ‘æ„Ÿå…´è¶£çš„æ˜¯æ˜¯å¦æœ‰ä»»ä½•ç‰¹å®šçš„å•è¯ä¼šå¯¼è‡´é¢„æµ‹å‘ç”Ÿè¿™æ ·æˆ–é‚£æ ·çš„å˜åŒ–ã€‚æˆ‘å°è¯•ä½¿ç”¨ SHAP çš„ KernelExplainerï¼Œä½†æˆ‘ä¸ç¡®å®šè¿™æ˜¯å¦æ˜¯æ­£ç¡®çš„æ–¹æ³•æˆ–å¦‚ä½•åœ¨è¿™ç§æƒ…å†µä¸‹ä½¿ç”¨å®ƒã€‚
æˆ‘æœ€åˆä½¿ç”¨ AutoGluon çš„ TabularPredictor.feature_importanceï¼Œä½†è¿™åªèƒ½å‘Šè¯‰æˆ‘å“ªäº›ç‰¹å¾åœ¨æœ€ç»ˆé¢„æµ‹ä¸­æƒé‡æœ€å¤§ã€‚ç„¶è€Œï¼Œæƒé‡æœ€é«˜çš„ç‰¹å¾æ˜¯æ–‡æœ¬ç‰¹å¾ã€‚æˆ‘æ— æ³•æ‰¾å‡º AutoGluon åœ¨è¯¥åŠŸèƒ½ä¸­å…·ä½“æŸ¥çœ‹ä»€ä¹ˆå†…å®¹æ¥è¿›è¡Œé¢„æµ‹ï¼Œæ— è®ºæ˜¯ç‰¹å®šå•è¯è¿˜æ˜¯å…¶ä»–å•è¯ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/77680786/explaining-text-features-of-autogluon-tabular-classifier</guid>
      <pubDate>Mon, 18 Dec 2023 17:28:53 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†æ ¼å¼è®­ç»ƒè‡ªå®šä¹‰ Transformer æ¨¡å‹</title>
      <link>https://stackoverflow.com/questions/77680618/how-to-train-a-customized-transformer-model-with-custom-dataset-formatting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77680618/how-to-train-a-customized-transformer-model-with-custom-dataset-formatting</guid>
      <pubDate>Mon, 18 Dec 2023 16:56:58 GMT</pubDate>
    </item>
    <item>
      <title>åŠ æƒæœºå™¨å­¦ä¹ é›†æˆç»™å‡ºçš„ç»“æœå¾ˆå·®[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/77680479/weighted-machine-learning-ensemble-giving-poor-results</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä¸ºåŸºäºæ–‡æœ¬çš„ csv æ–‡ä»¶æƒ…æ„Ÿåˆ†æå®æ–½åŠ æƒé›†æˆæ¨¡å¼ã€‚æˆ‘å°è¯•è¿‡æ ¹æ®å‡†ç¡®åº¦ã€ç²¾ç¡®åº¦ã€å¬å›ç‡è¿›è¡Œæƒé‡åˆ†é…ï¼Œä½†å®ƒç»™æˆ‘çš„ç»“æœä¸å•ä¸ª ML æˆ–æ·±åº¦å­¦ä¹ æ¨¡å‹ç›¸ä¼¼æˆ–æ›´å·® ğŸ¤”
æˆ‘å·²ç»åˆ¶ä½œäº†å¤§çº¦ 23 ä¸ªå…·æœ‰ä¸åŒç»„åˆçš„æ¨¡å‹
ã€‚
Python
è¾“å…¥æ˜¯åŸºäºæ–‡æœ¬çš„æ¨æ–‡
è¾“å‡ºä¸º3ç±»åˆ†ç±»
è¯åµŒå…¥æ˜¯tfidf
æˆ‘æ€æ ·æ‰èƒ½æé«˜æ€§èƒ½ä»¥åŠæˆ‘åº”è¯¥ä½¿ç”¨ä»€ä¹ˆæƒé‡æŒ‡æ ‡ï¼Ÿé‡é‡åº¦é‡çš„æ–¹ç¨‹åº”è¯¥æ˜¯..]]></description>
      <guid>https://stackoverflow.com/questions/77680479/weighted-machine-learning-ensemble-giving-poor-results</guid>
      <pubDate>Mon, 18 Dec 2023 16:33:10 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•å°† OHLCV äº¤æ˜“æ•°æ®åŠ è½½åˆ° TensorflowJS å·ç§¯å±‚ä¸­ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/77680420/how-to-load-ohlcv-trading-data-into-tensorflowjs-convolution-layer</link>
      <description><![CDATA[æˆ‘çš„ç›®æ ‡
è·å–æœ¬å‘¨å‰ 5 ä¸ªè‚¡ç¥¨äº¤æ˜“æ—¥çš„é«˜ä½æ•°æ®ï¼Œçœ‹çœ‹æˆ‘æ˜¯å¦å¯ä»¥é¢„æµ‹å‘¨æœ«ä»·æ ¼ä¸Šæ¶¨æˆ–ä¸‹è·Œã€‚
æ•°æ®
åœ¨äº¤æ˜“ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ OHLCV æ•°æ®æ¥æè¿°äº¤æ˜“æ—¥çš„æƒ…å†µï¼š
ï¼ˆO=å½“æ—¥å¼€ç›˜ä»·ï¼ŒH=å½“æ—¥æœ€é«˜ä»·ï¼ŒL=å½“æ—¥æœ€ä½ä»·ï¼ŒC=å½“æ—¥æ”¶ç›˜ä»·ï¼ŒV=å½“æ—¥æˆäº¤é‡ï¼‰ã€‚
//1å¤©çš„æ•°æ®
[oã€hã€lã€cã€v]

// ä¾‹å¦‚
[10ã€12ã€9ã€11ã€100]

å› æ­¤ 5 å¤©çš„æ•°æ®å¦‚ä¸‹ï¼š
//5å¤©çš„æ•°æ®
[[oã€hã€lã€cã€v]ã€[oã€hã€lã€cã€v]ã€[oã€hã€lã€cã€v]ã€[oã€hã€lã€cã€v]ã€[ oã€hã€lã€cã€v]]

// ä¾‹å¦‚
[[10, 12, 9, 11, 100], [11, 13, 11, 12, 200], [12, 12, 11, 11, 150], [11, 14, 11, 14, 300], [ 14, 14, 11, 12, 200]]

æˆ‘è¯»åˆ°ï¼Œå¤„ç†è¿™äº›æ•°æ®çš„æœ€ä½³æ–¹æ³•æ˜¯ä½¿ç”¨å·ç§¯å±‚ï¼Œç‰¹åˆ«æ˜¯ Tensorflow ä¸­çš„ conv2d å±‚ã€‚æ®æˆ‘äº†è§£ï¼Œè¯¥å±‚éœ€è¦ 4dTensor ä½œä¸ºè¾“å…¥ã€‚å› æ­¤ï¼Œæˆ‘ä½¿ç”¨tensor4d()ä»åŒ…å«4å‘¨è®­ç»ƒæ•°æ®ï¼ˆ4å€5å¤©æ•°æ®ï¼‰çš„æ•°æ®æ•°ç»„åˆ›å»ºè¿™æ ·çš„å¼ é‡
// 4 æ¬¡ 5 å¤©çš„ javascript æ•°ç»„
å¸¸é‡æ•°æ® = [10, 12, 9, 11, 100, 11, 13, 11, 12, 200, 12, 12, 11, 11, 150, 11, 14, 11, 14, 300, 14, 14, 11, 12, 200, 10, 12, 9, 11, 100, 11, 13, 11, 12, 200, 12, 12, 11, 11, 150, 11, 14, 11, 14, 300, 14, 14, 11, 12, 200, 10, 12, 9, 11, 100, 11, 13, 11, 12, 200, 12, 12, 11, 11, 150, 11, 14, 11, 14, 300, 14, 14, 11, 12, 200, 10, 12, 9, 11, 100, 11, 13, 11, 12, 200, 12, 12, 11, 11, 150, 11, 14, 11, 14, 300, 14, 14, 11, 12, 200]

// è½¬æ¢ä¸º 4d å¼ é‡
const input_tensor = tf.tensor4d(data, [data.length / (5 * 5), 5, 5, 1]);

ç›®æ ‡ç”±æ¯å‘¨ 1 ä¸ªç»“æœç»„æˆï¼ˆå‘¨æœ«äº¤æ˜“çš„ç»“æœï¼‰ã€‚
const target = [-1, 2, -3, 1] // % ç›ˆåˆ©æˆ–äºæŸ

// è½¬æ¢ä¸ºä¸€ç»´å¼ é‡
const target_tensor = tf.tensor1d(ç›®æ ‡);

æ¨¡å‹
æˆ‘çš„æ¨¡å‹çœ‹èµ·æ¥åƒè¿™æ ·ï¼Œæ˜¯æ ¹æ®æ­¤å¤„æ‰¾åˆ°çš„ç¤ºä¾‹æ„å»ºçš„ï¼šhttps:// blog.quantinsti.com/å·ç§¯ç¥ç»ç½‘ç»œ/
const model = tf.sequential();
model.add(tf.layers.conv2d({

    æ¿€æ´»ï¼š&#39;relu&#39;ï¼Œ
    è¿‡æ»¤å™¨ï¼š32ï¼Œ
    inputShape: [5, 5, 1], // 5 ä¸ª ohlcvï¼Œå…± 5 ä¸ªå€¼ï¼Œæ¯ä¸ªå€¼ 1
    å†…æ ¸å¤§å°ï¼š1ï¼Œ
}));
model.add(tf.layers.maxPooling2d([2, 2]));
model.add(tf.layers.conv2d({

    æ¿€æ´»ï¼š&#39;relu&#39;ï¼Œ
    è¿‡æ»¤å™¨ï¼š64ï¼Œ
    å†…æ ¸å¤§å°ï¼š1ï¼Œ
}));
model.add(tf.layers.maxPooling2d([2, 2]));
model.add(tf.layers.flatten());
model.add(tf.layers.dense({

    æ¿€æ´»ï¼š&#39;relu&#39;ï¼Œ
    å•ä½ï¼š64ï¼Œ
}));
model.add(tf.layers.dense({

    å•ä½ï¼š1ï¼Œ
    æ¿€æ´»ï¼š&#39;relu&#39;ï¼Œ
}));

æˆ‘ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„å¼ é‡è®­ç»ƒæ¨¡å‹
//è®­ç»ƒæ¨¡å‹
ç­‰å¾… model.fit(input_tensor, target_tensor, {
                    
    æ‰¹é‡å¤§å°ï¼š32ï¼Œ
    çºªå…ƒï¼š50ï¼Œ
    éšæœºæ’­æ”¾ï¼šæ­£ç¡®ï¼Œ
});

é”™è¯¯
åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæˆ‘æ”¶åˆ°ä»¥ä¸‹é”™è¯¯
unhandledRejection: TypeError: æ— æ³•å°† undefined æˆ– null è½¬æ¢ä¸ºå¯¹è±¡

æœ€åä¸€æ­¥
model.predict([10, 12, 9, 11, 100], [5, 1])

é—®é¢˜

æˆ‘ä½¿ç”¨å·ç§¯å±‚æ˜¯å› ä¸ºæˆ‘æƒ³ä¿ç•™ 1 å¤©çš„ OHLCV æ•°æ®ä¹‹é—´çš„å…³ç³»ï¼Œæˆ‘çš„æ¨¡å‹æ˜¯å¦å±äºè¿™ç§æƒ…å†µï¼Ÿæœ‰å¿…è¦å—ï¼Ÿ
æˆ‘æ­£ç¡®åˆ›å»ºäº† 4d å’Œ 1d å¼ é‡å—ï¼Ÿ
å†…æ ¸å¤§å°ä¸º [1, 1] çš„å·ç§¯å±‚æ˜¯å¦æœ‰æ„ä¹‰ï¼Ÿä¼¼ä¹è¿èƒŒäº†å·ç§¯å±‚çš„ç›®çš„ï¼Ÿ
å¦‚ä½•ä¿®å¤è¯¥é”™è¯¯ï¼Ÿ
æˆ‘æ˜¯èµ°åœ¨æ­£ç¡®çš„é“è·¯ä¸Šè¿˜æ˜¯å®Œå…¨çœ‹é”™äº†æ–¹å‘ï¼Ÿåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨èƒ½å¦ä¸ºæˆ‘æŒ‡æ˜å¦‚ä½•æ„å»ºæ¨¡å‹çš„æ­£ç¡®æ–¹å‘ï¼Ÿ
]]></description>
      <guid>https://stackoverflow.com/questions/77680420/how-to-load-ohlcv-trading-data-into-tensorflowjs-convolution-layer</guid>
      <pubDate>Mon, 18 Dec 2023 16:22:48 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨æ‰‹åŠ¨äº¤å‰éªŒè¯å’Œ cross_val_score ä¹‹é—´è·å–ä¸åŒçš„åˆ†æ•°å€¼</title>
      <link>https://stackoverflow.com/questions/77680320/getting-different-score-values-between-manual-cross-validation-and-cross-val-sco</link>
      <description><![CDATA[æˆ‘åˆ›å»ºäº†ä¸€ä¸ª python for å¾ªç¯ï¼Œå°†è®­ç»ƒæ•°æ®é›†åˆ†å‰²æˆåˆ†å±‚çš„ KFoldï¼Œå¹¶åœ¨å¾ªç¯å†…ä½¿ç”¨åˆ†ç±»å™¨æ¥è®­ç»ƒå®ƒã€‚ç„¶åä½¿ç”¨ç»è¿‡è®­ç»ƒçš„æ¨¡å‹é€šè¿‡éªŒè¯æ•°æ®è¿›è¡Œé¢„æµ‹ã€‚ä½¿ç”¨æ­¤è¿‡ç¨‹å®ç°çš„æŒ‡æ ‡ä¸ä½¿ç”¨ cross_val_score å‡½æ•°å®ç°çš„æŒ‡æ ‡å®Œå…¨ä¸åŒã€‚æˆ‘æœŸæœ›ä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•å¾—åˆ°ç›¸åŒçš„ç»“æœã€‚
æ­¤ä»£ç ç”¨äºæ–‡æœ¬åˆ†ç±»ï¼Œæˆ‘ä½¿ç”¨ TF-IDF å¯¹æ–‡æœ¬è¿›è¡ŒçŸ¢é‡åŒ–
è¿™æ˜¯ä»£ç ï¼š
æ‰‹åŠ¨å®ç°äº¤å‰éªŒè¯çš„ä»£ç ï¼š
#å¯¼å…¥æŒ‡æ ‡å‡½æ•°æ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½
ä» sklearn.metrics å¯¼å…¥ f1_scoreã€accuracy_scoreã€ precision_scoreã€recall_score
ä» sklearn.model_selection å¯¼å…¥ StratifiedKFold
data_validation = [] # ç”¨äºå­˜å‚¨ä½¿ç”¨äº¤å‰éªŒè¯çš„æ¨¡å‹éªŒè¯ç»“æœçš„åˆ—è¡¨
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
å‡†ç¡®åº¦å€¼ = []
f1_val = []

# ä½¿ç”¨ravelå‡½æ•°å°†å¤šç»´æ•°ç»„å±•å¹³ä¸ºä¸€ç»´
å¯¹äº (skf.split(X_train, y_train)) ä¸­çš„ train_indexã€val_indexï¼š
    X_tr, X_val = X_train.ravel()[train_index], X_train.ravel()[val_index]
    y_tr, y_val = y_train.ravel()[train_index] , y_train.ravel()[val_index]
    tfidf=TfidfVectorizer()
    X_tr_vec_tfidf = tfidf.fit_transform(X_tr) # å¯¹è®­ç»ƒæŠ˜å è¿›è¡Œå‘é‡åŒ–
    X_val_vec_tfidf = tfidf.transform(X_val) # å¯¹éªŒè¯æŠ˜å è¿›è¡Œå‘é‡åŒ–
    #å®ä¾‹åŒ–æ¨¡å‹
    æ¨¡å‹= MultinomialNB(alpha=0.5, fit_prior=False)
    #ç”¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†è®­ç»ƒç©ºæ¨¡å‹
    model.fit(X_tr_vec_tfidf, y_tr)
    Predictions_val = model.predict(X_val_vec_tfidf) # ä½¿ç”¨éªŒè¯æ•°æ®é›†è¿›è¡Œé¢„æµ‹
    acc_val = å‡†ç¡®åº¦_åˆ†æ•°ï¼ˆy_valï¼Œé¢„æµ‹_valï¼‰
    Accuracy_val.append(acc_val)
    f_val = f1_scoreï¼ˆy_valï¼Œé¢„æµ‹å€¼ï¼‰
    f1_val.append(f_val)

avg_accuracy_val = np.mean(accuracy_val)
avg_f1_val = np.mean(f1_val)

# å­˜å‚¨æŒ‡æ ‡çš„ä¸´æ—¶åˆ—è¡¨
temp = [&#39;NaiveBayes&#39;]
temp.append(avg_accuracy_val) #éªŒè¯å‡†ç¡®ç‡åˆ†æ•°
temp.append(avg_f1_val) #éªŒè¯f1åˆ†æ•°
data_validation.append(ä¸´æ—¶)
#ä½¿ç”¨æ•°æ®å¸§åˆ›å»ºä¸€ä¸ªè¡¨ï¼Œå…¶ä¸­åŒ…å«æ‰€æœ‰ç»è¿‡è®­ç»ƒå’Œæµ‹è¯•çš„ ML æ¨¡å‹çš„æŒ‡æ ‡
result = pd.DataFrame(data_validation, columns = [&#39;ç®—æ³•&#39;,&#39;å‡†ç¡®åº¦åˆ†æ•°ï¼šéªŒè¯&#39;,&#39;F1-åˆ†æ•°ï¼šéªŒè¯&#39;])
result.reset_index(drop=True, inplace=True)
ç»“æœ

è¾“å‡ºï¼š
 ç®—æ³•å‡†ç¡®åº¦åˆ†æ•°ï¼šéªŒè¯ F1-Scoreï¼šéªŒè¯
0 å¤©çœŸçš„è´å¶æ–¯ 0.77012 0.733994

ç°åœ¨ä½¿ç”¨ cross_val_score å‡½æ•°çš„ä»£ç ï¼š
ä» sklearn.model_selection å¯¼å…¥ cross_val_score
ä» sklearn.feature_extraction.text å¯¼å…¥ CountVectorizerã€TfidfVectorizer
åˆ†æ•° = [&#39;å‡†ç¡®åº¦&#39;, &#39;f1&#39;]
#ä½¿ç”¨NLPæŠ€æœ¯TF-IDFå¯¹è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–
tfidf=TfidfVectorizer()
X_tr_vec_tfidf = tfidf.fit_transform(X_train)
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
nb=å¤šé¡¹å¼NB(alpha=0.5, fit_prior=False)
å¯¹äº [â€œaccuracyâ€, â€œf1â€] ä¸­çš„åˆ†æ•°ï¼š
    print (f&#39;{score}: {cross_val_score(nb,X_tr_vec_tfidf,y_train,cv=skf,scoring=score).mean()} &#39;)

è¾“å‡ºï¼š
å‡†ç¡®åº¦ï¼š0.7341283583255231
f1ï¼š0.7062017090972422

å¯ä»¥çœ‹å‡ºï¼Œä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•çš„å‡†ç¡®æ€§å’Œ f1 æŒ‡æ ‡æœ‰å¾ˆå¤§ä¸åŒã€‚å½“æˆ‘ä½¿ç”¨ KNeighborsClassfier æ—¶ï¼ŒæŒ‡æ ‡çš„å·®å¼‚æ›´åŠ ä¸¥é‡ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/77680320/getting-different-score-values-between-manual-cross-validation-and-cross-val-sco</guid>
      <pubDate>Mon, 18 Dec 2023 16:05:36 GMT</pubDate>
    </item>
    <item>
      <title>å¤„ç† CNN äºŒå…ƒåˆ†ç±»çš„åˆ†å¸ƒå¤–æ ·æœ¬å’Œå¼‚å¸¸</title>
      <link>https://stackoverflow.com/questions/77679785/handling-out-of-distribution-samples-and-anomalies-for-cnn-binary-classification</link>
      <description><![CDATA[æˆ‘å¯¹æœºå™¨å­¦ä¹ é¢†åŸŸæ¯”è¾ƒé™Œç”Ÿï¼Œå¹¶ä¸”å¯¹åˆ›å»ºåŸºæœ¬è‡ªå®šä¹‰æ¨¡å‹æœ‰åŸºæœ¬çš„äº†è§£ã€‚
åˆ†é…ç»™æˆ‘çš„ä»»åŠ¡
æˆ‘çš„ç»ç†è¦æ±‚æˆ‘å¼€å‘ä¸€ç§æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨æ”»å‡»æ€§å›¾åƒå‘é€åˆ°æœåŠ¡å™¨ä¹‹å‰è¯†åˆ«å®ƒä»¬ã€‚è¿™äº›å›¾åƒå¯ä»¥åˆ†ä¸ºä¸åŒçš„ç±»åˆ«ï¼Œä¾‹å¦‚æ­¦å™¨æˆ–æˆäººå†…å®¹ã€‚
é—®é¢˜
ä½†æ˜¯ï¼Œæˆ‘åœ¨æ¨¡å‹æ£€æµ‹å¼‚å¸¸æˆ–åˆ†å¸ƒå¤–æ ·æœ¬çš„èƒ½åŠ›æ–¹é¢é‡åˆ°äº†é—®é¢˜ã€‚
æˆ‘å°è¯•è¿‡çš„
æˆ‘å°è¯•äº†ä¸åŒçš„æ–¹æ³•ï¼Œåˆ©ç”¨&#39;binary_crossentropy&#39;ä½œä¸ºæˆ‘çš„æŸå¤±å‡½æ•°ï¼Œä½†é‡åˆ°äº†åŒæ ·çš„é—®é¢˜ã€‚æˆ‘è¿˜æ„å»ºäº†ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªç±»çš„æ¨¡å‹ï¼š

12,278 ä¸æ­¦å™¨ç›¸å…³çš„å›¾ç‰‡ class_name = æ­¦å™¨
3,000 å¼ é£Ÿç‰© å•†å“å›¾ç‰‡ class_name = å…¶ä»–

ä½†æ˜¯ï¼Œæˆ‘ä¸ç¡®å®š â€œå…¶ä»–â€ ç±»åˆ«ä¸­åº”åŒ…å«å“ªäº›å†…å®¹ã€‚ä½¿ç”¨ MobileNet ä½œä¸ºåŸºç¡€æ¨¡å‹æ„å»ºæ¨¡å‹åï¼Œå®ƒæˆåŠŸåœ°å‡†ç¡®é¢„æµ‹äº†æ­¦å™¨ï¼Œå¹¶æä¾›äº† 0.4 åˆ° 0.6 èŒƒå›´å†…çš„é£Ÿå“é¢„æµ‹ï¼Œè¿™ä¼¼ä¹æ˜¯å¯ä»¥æ¥å—çš„ã€‚ç„¶è€Œï¼Œå½“æˆ‘å¼•å…¥å¤§è±¡æˆ–æ±½è½¦çš„å›¾åƒæ—¶ï¼Œæ¨¡å‹å€¾å‘äºå°†å®ƒä»¬é¢„æµ‹ä¸ºæ­¦å™¨ï¼Œæ˜¾ç¤ºçš„ç½®ä¿¡åº¦æ¥è¿‘ 1ã€‚
æˆ‘ä¸çŸ¥é“å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚æˆ‘å°è¯•ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œå¹¶å‘ç°äº†ä¸€äº›å…³äºåˆ†å¸ƒå¤–æ£€æµ‹çš„çº¿ç´¢ä»¥åŠä¸å¼‚å¸¸æˆ–ç¦»ç¾¤å€¼ç›¸å…³çš„æ¦‚å¿µã€‚å½“æ¨¡å‹çš„è¾“å…¥åŒ…å«ä¸å±äºè®­ç»ƒæ•°æ®çš„å›¾åƒæ—¶ï¼Œå¦‚ä½•è·å¾—ä¸ç¡®å®šæ€§å€¼ï¼Ÿ
å¦‚æœæ‚¨èƒ½æä¾›ä»»ä½•æŒ‡å¯¼ã€å»ºè®®ï¼Œç”šè‡³å‚è€ƒèƒ½å¤Ÿæœ‰æ•ˆè§£å†³æ­¤é—®é¢˜çš„è§†é¢‘æˆ–èµ„æºï¼Œæˆ‘å°†ä¸èƒœæ„Ÿæ¿€ã€‚æ„Ÿè°¢æ‚¨çš„å¸®åŠ©ã€‚
æ•°æ®åŠ è½½ï¼š
train_ds, test_ds = keras.utils.image_dataset_from_directory(
    ç›®å½•=â€œ/å†…å®¹/æ­¦å™¨â€ï¼Œ
    æ ‡ç­¾=â€œæ¨æ–­â€ï¼Œ
    label_mode =â€œäºŒè¿›åˆ¶â€ï¼Œ
    æ‰¹é‡å¤§å°=32ï¼Œ
    å­é›†=â€œä¸¤è€…â€ï¼Œ
    å›¾åƒå¤§å°=(224,224),
    éªŒè¯åˆ†å‰²=0.2ï¼Œ
    éšæœºæ’­æ”¾=çœŸï¼Œ
    ç§å­=1337
ï¼‰

ç°åœ¨æ ‡å‡†åŒ–è¾“å…¥å›¾åƒæ•°æ®ï¼š
def processï¼ˆå›¾åƒï¼Œæ ‡ç­¾ï¼‰ï¼š
  å›¾åƒ=tf.cast(å›¾åƒ/255, tf.float32)
  è¿”å›å›¾åƒã€æ ‡ç­¾
train_ds = train_ds.map(è¿›ç¨‹)
test_ds = test_ds.map(è¿›ç¨‹)

åˆ›å»º CNN æ¨¡å‹ï¼š
input_shape = (224,224,3)
mobilenet = MobileNet(input_shape,weights=&#39;imagenet&#39;,include_top=False)
æ¨¡å‹=é¡ºåºï¼ˆï¼‰
 
model.addï¼ˆç§»åŠ¨ç½‘ç»œï¼‰
æ¨¡å‹.add(å‹å¹³())
model.addï¼ˆå¯†é›†ï¼ˆ256ï¼Œæ¿€æ´»=&#39;relu&#39;ï¼‰ï¼‰
æ¨¡å‹.add(Dropout(0.5))
model.addï¼ˆå¯†é›†ï¼ˆ1ï¼Œæ¿€æ´»=&#39;sigmoid&#39;ï¼‰ï¼‰
æ¨¡å‹.summary()



sgd = SGD(å­¦ä¹ ç‡=0.0001ï¼ŒåŠ¨é‡=0.9ï¼Œnesterov=True)
model.compileï¼ˆæŸå¤±=&#39;binary_crossentropy&#39;ï¼Œä¼˜åŒ–å™¨=sgdï¼ŒæŒ‡æ ‡=[&#39;å‡†ç¡®æ€§&#39;]ï¼‰
å†å²= model.fitï¼ˆtrain_dsï¼Œvalidation_data = test_dsï¼Œbatch_size = 4ï¼Œepochs = 6ï¼‰


çºªå…ƒ 6/6
382/382 [==============================] - 58s 150ms/æ­¥ - æŸå¤±ï¼š0.0042 - ç²¾åº¦ï¼š0.9984 - val_loss ï¼š0.0063 - val_accuracyï¼š0.997
]]></description>
      <guid>https://stackoverflow.com/questions/77679785/handling-out-of-distribution-samples-and-anomalies-for-cnn-binary-classification</guid>
      <pubDate>Mon, 18 Dec 2023 14:34:38 GMT</pubDate>
    </item>
    <item>
      <title>è¿è¡Œ fmri æ·±åº¦å­¦ä¹ æ¨¡å‹æ—¶å‡ºç°é”™è¯¯</title>
      <link>https://stackoverflow.com/questions/77677389/getting-error-while-running-fmri-deep-learning-model</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¤„ç† fmri æ•°æ®ï¼Œæˆ‘æœ‰ä¸¤ç»„æ•°æ®é›†ç–¾ç—…å’Œæ­£å¸¸æ•°æ®çš„å½¢çŠ¶æ˜¯æ­£å¸¸æ•°æ®å½¢çŠ¶ï¼š(91, 109, 91, 1200)
ç–¾ç—…æ•°æ®å½¢çŠ¶ï¼š(91, 109, 91, 210)
æˆ‘å†™äº†pythonè„šæœ¬
å°† numpy å¯¼å…¥ä¸º np
å°† nibabel å¯¼å…¥ä¸º nib
ä» sklearn.model_selection å¯¼å…¥ train_test_split


# å®šä¹‰æ­£å¸¸å’Œç–¾ç—…æ•°æ®æ–‡ä»¶å¤¹çš„è·¯å¾„
ç–¾ç—…æ•°æ®è·¯å¾„ = glob(&#39;/media/aish/Backup Plus1/ABIDE/scan_data001/**/**/**/**/**/**/**/**/swa*&#39;)
Normal_data_path = glob(&#39;/media/aish/rs2/hcp/s*&#39;)

# åŠ è½½æ­£å¸¸å’Œç–¾ç—…æ•°æ®
æ­£å¸¸æ•°æ® = []
ç–¾ç—…æ•°æ® = []
å¯¹äºnormal_data_path[0:400]ä¸­çš„æ–‡ä»¶ï¼š
    Normal_data.append(nib.load(file).get_data())
å¯¹äºç–¾ç—…æ•°æ®è·¯å¾„ä¸­çš„æ–‡ä»¶ï¼š
    ç–¾ç—…æ•°æ®.append(nib.load(æ–‡ä»¶).get_data())

print(â€œæ­£å¸¸æ•°æ®å½¢çŠ¶ï¼šâ€, normal_data[1].shape)
print(â€œç–¾ç—…æ•°æ®å½¢çŠ¶ï¼šâ€,ç–¾ç—…æ•°æ®[1].shape)

# åˆ›å»ºæ ‡ç­¾
æ ‡ç­¾ = np.concatenate((np.zeros(len(normal_data)), np.ones(len(disease_data))))

# å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_trainï¼ŒX_testï¼Œy_trainï¼Œy_test = train_test_splitï¼ˆnp.arrayï¼ˆæ­£å¸¸æ•°æ®+ç–¾ç—…æ•°æ®ï¼‰ï¼Œæ ‡ç­¾ï¼Œtest_size = 0.2ï¼Œrandom_state = 42ï¼‰

ä½†æ˜¯æˆ‘æ”¶åˆ°é”™è¯¯
å®Œæ•´é”™è¯¯æ˜¯
ValueError Tracebackï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰
[7]ï¼Œç¬¬ 32 è¡Œä¸­çš„å•å…ƒæ ¼
     29 ä¸ªæ ‡ç­¾ = np.concatenate((np.zeros(len(normal_data)), np.ones(len(disease_data))))
     31 # å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
---&gt; 32 X_trainï¼ŒX_testï¼Œy_trainï¼Œy_test = train_test_splitï¼ˆnp.arrayï¼ˆæ­£å¸¸æ•°æ®+ç–¾ç—…æ•°æ®ï¼‰ï¼Œæ ‡ç­¾ï¼Œtest_size = 0.2ï¼Œrandom_state = 42ï¼‰
     34 # å®šä¹‰CNNæ¨¡å‹
     35 æ¨¡å‹ = é¡ºåº()

ValueErrorï¼šæ— æ³•å°†è¾“å…¥æ•°ç»„ä»å½¢çŠ¶ (91,109,91,1200) å¹¿æ’­åˆ°å½¢çŠ¶ (91,109,91)

æˆ‘æ— æ³•è§£å†³æ­¤é”™è¯¯]]></description>
      <guid>https://stackoverflow.com/questions/77677389/getting-error-while-running-fmri-deep-learning-model</guid>
      <pubDate>Mon, 18 Dec 2023 06:53:58 GMT</pubDate>
    </item>
    <item>
      <title>LLMæ¨¡å‹éå¸¸æ…¢</title>
      <link>https://stackoverflow.com/questions/77199972/llm-model-is-very-slow</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ nvidia g5 ä¸Šè¿è¡Œ 34b LLM æ¨¡å‹ã€‚ 8xlarge å®ä¾‹ï¼ˆ1 ä¸ª Nvidia A10G GPUã€24GB GPU RAMã€32 ä¸ª vCPUã€128GB RAMï¼‰
è¿™æ˜¯æ¨ç†ä»£ç 
ä»å˜å‹å™¨å¯¼å…¥ AutoTokenizer,LlamaForCausalLM, AutoConfig, AutoModelForCausalLM
ä»åŠ é€Ÿå¯¼å…¥ infer_auto_device_map, init_empty_weights
è¿›å£ç«ç‚¬

model_path = â€œPhind/Phind-CodeLlama-34B-v2â€

model = LlamaForCausalLM.from_pretrained(model_path, device_map=â€œè‡ªåŠ¨â€, offload_folder=â€œå¸è½½â€, torch_dtype=torch.float16, offload_state_dict = True)
tokenizer = AutoTokenizer.from_pretrained(model_path)

defgenerate_one_completionï¼ˆæç¤ºï¼šstrï¼‰ï¼š
    tokenizer.pad_token = tokenizer.eos_token
    è¾“å…¥=åˆ†è¯å™¨ï¼ˆæç¤ºï¼Œreturn_tensors =â€œptâ€ï¼Œæˆªæ–­= Trueï¼Œmax_length = 4096ï¼‰

    ï¼ƒ äº§ç”Ÿ
    generate_ids = model.generate(inputs.input_ids.to(â€œcudaâ€), max_new_tokens=384, do_sample=True, top_p=0â€‹â€‹.75, top_k=10, æ¸©åº¦=0.1)
    å®Œæˆ= tokenizer.batch_decodeï¼ˆgenerate_idsï¼Œskip_special_tokens = Trueï¼Œclean_up_tokenization_spaces = Falseï¼‰[0]
    å®Œæˆ = å®Œæˆ.replace(prompt, &quot;&quot;).split(&quot;\n\n\n&quot;)[0]

    è¿”å›å®Œæˆ

text = â€œä½ å¥½ï¼Œè¯·é—®æ˜¯ä½ å—ï¼Ÿâ€
æ‰“å°ï¼ˆç”Ÿæˆ_ä¸€ä¸ª_å®Œæˆï¼ˆæ–‡æœ¬ï¼‰ï¼‰


åŠ è½½æ£€æŸ¥ç‚¹åˆ†ç‰‡ - è¿™éœ€è¦ 4 åˆ†é’Ÿã€‚å¦‚ä½•æ‰èƒ½åŠ å¿«é€Ÿåº¦ï¼Ÿ
å³ä½¿æ˜¯ç®€å•çš„æ¨ç†ä¹Ÿéœ€è¦ 60 ç§’ä»¥ä¸Šã€‚ä»£ç å¡«å†™/æç¤ºéœ€è¦ 10 å¤šåˆ†é’Ÿã€‚å¯ä»¥åœ¨æ­¤ ec2 å®ä¾‹ä¸ŠåŠ é€Ÿå—ï¼Ÿ
]]></description>
      <guid>https://stackoverflow.com/questions/77199972/llm-model-is-very-slow</guid>
      <pubDate>Fri, 29 Sep 2023 06:54:14 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨GANç”Ÿæˆæ‹‰æ›¼å…‰è°±çš„åˆæˆæ•°æ®æ ·æœ¬ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/76906588/how-to-generate-synthetic-data-samples-of-raman-spectroscopy-by-using-gan</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76906588/how-to-generate-synthetic-data-samples-of-raman-spectroscopy-by-using-gan</guid>
      <pubDate>Tue, 15 Aug 2023 14:05:29 GMT</pubDate>
    </item>
    <item>
      <title>æ— æ³•åœ¨pythonä¸­å®‰è£…lap==0.4.0åº“</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>ValueErrorï¼šX æœ‰ 1 ä¸ªç‰¹å¾ï¼Œä½† LinearRegression æœŸæœ›æœ‰ 2 ä¸ªç‰¹å¾ä½œä¸ºè¾“å…¥</title>
      <link>https://stackoverflow.com/questions/73132252/valueerror-x-has-1-features-but-linearregression-is-expecting-2-features-as-in</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ pywebio ä¸ºæˆ‘çš„æœºå™¨å­¦ä¹ ç¨‹åºåˆ›å»ºä¸€ä¸ªå°å‹è„šæœ¬è¿è¡Œç”¨æˆ·ç•Œé¢ã€‚å½“ä¸ä½¿ç”¨å°å‹ UI æ—¶ï¼Œè¿è¡Œçº¿æ€§å›å½’ predict() å‡½æ•°æ—¶ä¸ä¼šå‡ºç°ä»»ä½•é”™è¯¯ã€‚
UI æ­£åœ¨ä»ç”¨æˆ·å¤„æ£€ç´¢ä¸¤ä¸ªæ•°å­—ï¼š&#39;age&#39; å’Œ &#39;salary&#39;ã€‚è¿™ä¸¤ä¸ªæ•°å­—è¢«è¾“å…¥åˆ°ä¸€ä¸ª numpy æ•°ç»„ä¸­ï¼Œå¹¶ä¸”å½“æˆ‘æ”¶åˆ°æœ‰å…³ numpy æ•°ç»„å½¢çŠ¶çš„é”™è¯¯æ—¶ï¼Œè¯¥ numpy æ•°ç»„å·²ä»ä¸€ç»´æ•°ç»„é‡æ–°è°ƒæ•´ä¸ºäºŒç»´æ•°ç»„ã€‚
ç°åœ¨ï¼Œå½“ sklearn æ–‡æ¡£æŒ‡å‡ºçº¿æ€§å›å½’ predict() æ—¶ï¼Œæˆ‘æ”¶åˆ°ä¸€æ¡æœ‰å…³ predict() æ–¹æ³•ä»…æ¥æ”¶ 1 ä¸ªç‰¹å¾è€Œä¸æ˜¯ 2 ä¸ªç‰¹å¾çš„é”™è¯¯æ¶ˆæ¯&gt; æ–¹æ³•æ€»æ˜¯è·å–â€œselfâ€å’Œå¦ä¸€ä¸ªç‰¹å¾ã€‚æˆ‘è¯¥å¦‚ä½•ä¿®å¤è¿™ä¸ªé”™è¯¯ï¼Ÿ
è¿™æ˜¯æˆ‘çš„ç”¨æˆ·ç•Œé¢ä»£ç ï¼š
age = int(input(â€œè¯·è¾“å…¥æ‚¨çš„å¹´é¾„ï¼šâ€, type=NUMBER))
å·¥èµ„ = int(input(&quot;è¯·è¾“å…¥æ‚¨çš„å·¥èµ„ï¼š&quot;, type=NUMBER))

æ¡ç›® = np.array([å¹´é¾„, è–ªæ°´])
reshape_entry = Entry.reshape(-1, 1)

ä¼°è®¡ = regr.predict(reshape_entry)

è¿™æ˜¯é”™è¯¯æ¶ˆæ¯ï¼š
ValueError Tracebackï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰
è¾“å…¥ In [21], in ()

è¾“å…¥[21]ï¼Œåœ¨retirement_ui()ä¸­

æ–‡ä»¶ ~\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:362ï¼Œåœ¨ LinearModel.predict(self, X) ä¸­
    348 def é¢„æµ‹ï¼ˆè‡ªèº«ï¼ŒXï¼‰ï¼š
    ç¬¬349ç« 
    350 ä½¿ç”¨çº¿æ€§æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚
    ç¬¬351ç« 
   ï¼ˆ...ï¼‰
    360 è¿”å›é¢„æµ‹å€¼ã€‚
    ç¬¬361ç« 
--&gt;ç¬¬362ç« 

æ–‡ä»¶ã€œ\ anaconda3 \ lib \ site-packages \ sklearn \ Linear_model \ _base.pyï¼š345ï¼Œåœ¨LinearModel._decision_functionï¼ˆselfï¼ŒXï¼‰ä¸­
    ç¬¬342ç« 
    ç¬¬343ç« 
--&gt; [ç¬¬ 345 ç« ]
    [ç¬¬ 346 ç« ]

æ–‡ä»¶ ~\anaconda3\lib\site-packages\sklearn\base.py:585ï¼Œåœ¨ BaseEstimator._validate_data(self, X, y, Reset, validate_separately, **check_params)
    ç¬¬582ç« 
    ç¬¬584ç« 
--&gt;ç¬¬585ç« 
    ç¬¬587ç«  å›æ¥

æ–‡ä»¶ ~\anaconda3\lib\site-packages\sklearn\base.py:400ï¼Œåœ¨ BaseEstimator._check_n_features(self, X, Reset) ä¸­
    ç¬¬397ç«  å›å½’
    ç¬¬399ç« 
--&gt;æ­£æ–‡ æ­£æ–‡_ç¬¬400ç« 
    [401] ç¬¬401è¯
    [402] fâ€œæœŸå¾…{self.n_features_in_}ç‰¹å¾ä½œä¸ºè¾“å…¥ã€‚â€
    ç¬¬403ç« ï¼‰

ValueErrorï¼šX æœ‰ 1 ä¸ªç‰¹å¾ï¼Œä½† LinearRegression æœŸæœ›æœ‰ 2 ä¸ªç‰¹å¾ä½œä¸ºè¾“å…¥ã€‚
]]></description>
      <guid>https://stackoverflow.com/questions/73132252/valueerror-x-has-1-features-but-linearregression-is-expecting-2-features-as-in</guid>
      <pubDate>Wed, 27 Jul 2022 04:29:07 GMT</pubDate>
    </item>
    <item>
      <title>æ˜¯å¦æœ‰ä»»ä½•æœ€ä½³å®è·µæ¥ä¸ºåŸºäºæ–‡æœ¬çš„åˆ†ç±»å‡†å¤‡ç‰¹å¾ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/22087407/is-there-any-best-practice-to-prepare-features-for-text-based-classification</link>
      <description><![CDATA[æˆ‘ä»¬æ”¶åˆ°äº†è®¸å¤šæ¥è‡ªå®¢æˆ·çš„åé¦ˆå’Œé—®é¢˜æŠ¥å‘Šã€‚å®ƒä»¬æ˜¯çº¯æ–‡æœ¬ã€‚æˆ‘ä»¬æ­£åœ¨å°è¯•ä¸ºè¿™äº›æ–‡æ¡£æ„å»ºä¸€ä¸ªè‡ªåŠ¨åˆ†ç±»å™¨ï¼Œä»¥ä¾¿æœªæ¥åé¦ˆ/é—®é¢˜å¯ä»¥è‡ªåŠ¨è·¯ç”±åˆ°æ­£ç¡®çš„æ”¯æŒå›¢é˜Ÿã€‚é™¤äº†æ–‡æœ¬æœ¬èº«ä¹‹å¤–ï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬åº”è¯¥å°†å®¢æˆ·èµ„æ–™ã€æ¡ˆä¾‹æäº¤åŒºåŸŸç­‰å†…å®¹çº³å…¥åˆ†ç±»å™¨ä¸­ã€‚æˆ‘è®¤ä¸ºè¿™å¯ä»¥ä¸ºåˆ†ç±»å™¨åšå‡ºæ›´å¥½çš„é¢„æµ‹æä¾›æ›´å¤šçº¿ç´¢ã€‚
ç›®å‰ï¼Œæ‰€æœ‰é€‰æ‹©ç”¨äºè®­ç»ƒçš„ç‰¹å¾éƒ½æ˜¯åŸºäºæ–‡æœ¬å†…å®¹çš„ã€‚å¦‚ä½•åŒ…å«ä¸Šè¿°å…ƒç‰¹å¾ï¼Ÿ
æ·»åŠ 1
æˆ‘ç›®å‰çš„åšæ³•æ˜¯é¦–å…ˆå¯¹åŸå§‹æ–‡æœ¬ï¼ˆåŒ…æ‹¬æ ‡é¢˜å’Œæ­£æ–‡ï¼‰è¿›è¡Œä¸€äº›å…¸å‹çš„é¢„å¤„ç†ï¼Œä¾‹å¦‚åˆ é™¤åœç”¨è¯ã€è¯æ€§æ ‡è®°å’Œæå–é‡è¦è¯ã€‚ç„¶åï¼Œæˆ‘å°†æ ‡é¢˜å’Œæ­£æ–‡è½¬æ¢ä¸ºå•è¯åˆ—è¡¨ï¼Œå¹¶ä»¥æŸç§ç¨€ç–æ ¼å¼å­˜å‚¨å®ƒä»¬ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
&lt;å—å¼•ç”¨&gt;
å®ä¾‹ 1ï¼šå•è¯ 1ï¼šå•è¯ 1 è®¡æ•°ï¼Œå•è¯ 2ï¼šå•è¯ 2 è®¡æ•°ï¼Œ...
å®ä¾‹ 2ï¼šwordX:word1 è®¡æ•°ï¼ŒwordY:word2 è®¡æ•°ï¼Œ...

å¯¹äºå…¶ä»–éæ–‡æœ¬åŠŸèƒ½ï¼Œæˆ‘è®¡åˆ’å°†å®ƒä»¬æ·»åŠ ä¸ºå•è¯â€œcolumnsâ€ä¹‹åçš„æ–°åˆ—ã€‚æ‰€ä»¥æœ€ç»ˆçš„å®ä¾‹å°†å¦‚ä¸‹æ‰€ç¤ºï¼š
&lt;å—å¼•ç”¨&gt;
å®ä¾‹ 1ï¼šword1:word1 è®¡æ•°ï¼Œ...ï¼Œç‰¹å¾ X:å€¼ï¼Œç‰¹å¾ Y:å€¼
]]></description>
      <guid>https://stackoverflow.com/questions/22087407/is-there-any-best-practice-to-prepare-features-for-text-based-classification</guid>
      <pubDate>Fri, 28 Feb 2014 05:57:21 GMT</pubDate>
    </item>
    </channel>
</rss>