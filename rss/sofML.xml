<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 30 Apr 2024 18:19:52 GMT</lastBuildDate>
    <item>
      <title>用于 ML 、keras tensorflow 或 scikit learn 的更好的库应该是什么[关闭]</title>
      <link>https://stackoverflow.com/questions/78410129/what-should-be-the-better-library-to-use-for-ml-keras-tensorflow-or-scikit-lea</link>
      <description><![CDATA[只是困惑我应该使用哪个库进行机器学习，两者的优点和缺点是什么。
我尝试了这两个库，我想对它们进行比较，也想知道哪个更好。]]></description>
      <guid>https://stackoverflow.com/questions/78410129/what-should-be-the-better-library-to-use-for-ml-keras-tensorflow-or-scikit-lea</guid>
      <pubDate>Tue, 30 Apr 2024 17:13:17 GMT</pubDate>
    </item>
    <item>
      <title>这是一个 CNN 1d 模型，通过观察电流信号找出电压</title>
      <link>https://stackoverflow.com/questions/78409956/this-is-a-cnn-1d-model-to-find-out-the-voltages-by-observing-the-current-signal</link>
      <description><![CDATA[它说：
&lt;块引用&gt;
由于 conv1d_4 中的下采样，输出中的一个维度 &lt;= 0。考虑增加输入大小。接收到的输入形状 [None, 9600, 1, 1]，它将产生维度为零或负值的输出形状。

这是我到目前为止所做的：
dataset_url=“https://github.com/Kaustav-coder/cnn/blob/main/cnn.csv”

从 keras.models 导入顺序
从 keras.layers 导入密集、扁平化
从 keras.layers 导入 Conv1D、MaxPooling1D、Dropout
从 keras.layers 导入嵌入
来自 keras.preprocessing 导入序列
从 sklearn.model_selection 导入 train_test_split
将 pandas 导入为 pd
将 numpy 导入为 np
从sklearn导入预处理
从sklearn.metrics导入accuracy_score，confusion_matrix，classification_report

数据=pd.read_csv(&#39;cnn.csv&#39;)
y=数据[&#39;电压&#39;]
x=data.drop([&#39;电压&#39;],轴=1)

label_encoder = 预处理.LabelEncoder()
y_enc = label_encoder.fit_transform(y)
x_reshape = x.values.reshape(x.shape[0], x.shape[1],1)
x_train,x_test,y_train,y_test= train_test_split(x_reshape,y_enc,test_size=0.2,random_state=42)

模型=顺序（）
model.add(Conv1D(filters=64, kernel_size=10,activation=&#39;relu&#39;, input_shape=(9600,1,1)))
model.add(MaxPooling1D(pool_size=1))
model.add(Conv1D(filters=64，kernel_size=10，activation=&#39;relu&#39;))
model.add(MaxPooling1D(pool_size=1))
模型.add(压平())
model.add（密集（128，激活=&#39;relu&#39;））
模型.add(Dropout(0.25))
model.add（密集（128，激活=&#39;softmax&#39;））
]]></description>
      <guid>https://stackoverflow.com/questions/78409956/this-is-a-cnn-1d-model-to-find-out-the-voltages-by-observing-the-current-signal</guid>
      <pubDate>Tue, 30 Apr 2024 16:42:09 GMT</pubDate>
    </item>
    <item>
      <title>Google Ads 数据的数据科学/机器学习分析 [关闭]</title>
      <link>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</link>
      <description><![CDATA[我们希望对 Google Ads 数据进行一些机器学习分析，以微调我们的营销效果。有人对方法有什么建议吗？
是否有严肃的 DS/ML 从业者的现有资源正在使用来自 Google Ads 的数据，或许还可以通过其他来源（YouTube 等）进行增强，以生成预测分析以最大化转化价值。
我们正在考虑：
识别并调整不同的关键字值
识别每个营销活动或广告中可能解释效果的不同特征
通过识别“趋势”主题、主题标签等而不是被动方法来探索“套利”关键字值的可能性
生成因果发现/因果推理分析来解释事件之间关系的强度
我们理想地寻找可以向我们展示该领域现有思维的最佳实践/权威分析师/资源。任何提供分析方法的 GitHub 存储库的建议将不胜感激。
我们从“Google Ads”的角度在 google 上搜索了这个问题，并查看了 Reddit，但存在很多噪音和“黑匣子”解决方案，因此我们决定从认真的 DS 从业者的角度来解决这个问题...希望您能帮助。
我们已经通过 PyCaret ML 回归分析对 Google Ads 广告系列、广告和关键字数据进行了分析，并获得了一些基础结果，但我们现在正在寻求有关如何推进这一工作的指导。]]></description>
      <guid>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</guid>
      <pubDate>Tue, 30 Apr 2024 16:38:08 GMT</pubDate>
    </item>
    <item>
      <title>伙计们，我需要帮助。这里有什么错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78409929/guys-please-i-need-help-what-is-the-error-here</link>
      <description><![CDATA[在此处输入图片说明
我从其他地方复制了此代码...我遇到了很多错误，并能够纠正这些错误。这是最后一步，我被困住了。]]></description>
      <guid>https://stackoverflow.com/questions/78409929/guys-please-i-need-help-what-is-the-error-here</guid>
      <pubDate>Tue, 30 Apr 2024 16:35:28 GMT</pubDate>
    </item>
    <item>
      <title>使用Python深度学习进行时间序列分析</title>
      <link>https://stackoverflow.com/questions/78409576/time-series-analysis-with-python-deep-learning</link>
      <description><![CDATA[我正在使用 python 进行时间序列数据分析。但有一个问题。
导入操作系统
从 omegaconf 导入 OmegaConf

将 pandas 导入为 pd
进口火炬
将数据集导入为 module_data
将模型导入为 module_arch
将指标导入为 module_metric
从 utils 导入 MetricTracker，get_data_path


END_DATE = &#39;2024-03-22&#39;

    
def get_test_dollar_price(开始日期, 结束日期):
    ”“”
    不要修复这个功能
    ”“”
    df = pd.read_csv(get_data_path(&#39;比特币&#39;), index_col=“日期”, parse_dates=True, na_values=[&#39;nan&#39;])
    df.sort_index(inplace=True)
    价格 = df.loc[开始日期:结束日期, [&#39;价格&#39;]][-10:].values
    退货价格


def 主要（配置）：
    
    test_dataset = getattr(module_data, config.dataset.type)(end_date=END_DATE,
                                                             is_training=假,
                                                             **配置.数据集.args)
    test_dataloader = getattr(torch.utils.data, config.dataloader.type)(test_dataset,
                                                                        批量大小=1，
                                                                        随机播放=假，
                                                                        num_workers=0,)

    #################################################### #################################################### ##############
    # 检查测试数据
    if abs(test_dataset.y.numpy() - get_test_dollar_price(&#39;2024-03-12&#39;, END_DATE)).sum() &gt; 1e-3：
        raise ValueError(&#39;你的测试数据是错误的！&#39;)
    #################################################### #################################################### ##############

    
    model = getattr(module_arch, config.model.type)(input_size=test_dataset.__getitem__(0)[0].size(0), **config.model.args)
    model.load_state_dict(torch.load(config.test.load_path))
    模型.eval()

    # GPU
    设备 = torch.device(&#39;mps&#39;)

  
    模型 = model.to(设备)

    
    指标 = [getattr(module_metric, met) for met in config.test.metrics]
    metric_tracker_test = MetricTracker(*config.test.metrics)

    
    对于枚举（test_dataloader）中的 i，（x，y）：
        x, y = x.to(设备), y.to(设备)
        pred_y = 模型(x)
        print(f&#39;[DAY {i+1:02d}] 预测：{pred_y[0].item():.1f} | 目标：{y[0].item():.1f}&#39;)
        对于满足指标：
            metric_tracker_test.update(met.__name__, met(pred_y, y))
        
    print(&#39;\nTEST &#39; + &#39;, &#39;.join([f&#39;{k.upper()}: {v:.2f}&#39; for k, v in metric_tracker_test.result().items()]))


这是我的 test.py 代码，如果我运行此代码，则会引发值错误。在 #inspect 测试数据部分中，start_data 是 2022-01-25。我想知道为什么会出现值错误（您的测试数据是错误的）。帮助我
我多次更改日期。但结果是一样的]]></description>
      <guid>https://stackoverflow.com/questions/78409576/time-series-analysis-with-python-deep-learning</guid>
      <pubDate>Tue, 30 Apr 2024 15:26:09 GMT</pubDate>
    </item>
    <item>
      <title>大尺寸的 One Hot 编码</title>
      <link>https://stackoverflow.com/questions/78409561/one-hot-encoding-with-large-dimensions</link>
      <description><![CDATA[我正在构建一个销售预测模型，其中包含“年”、“月”、“经济指标”、“Customer_Id”、“Product_Id”、“Quantity”、“Sales”、“ “保证金”。
清理后的数据集包含约 150 万行和上述 8 列，这是过去 6 年每个客户每个产品的每月销售额。我的最终目标是能够预测整个来年未来几个月的销售额，但更准确地说，预测将针对每个客户级别的产品，这是一个非常详细的级别。
但是，由于我的Customer_Id和Product_Id是TEXT，例如“A77BC”，并且有超过100000个唯一的product_id和6000个唯一的customer_id，如果我使用一种热编码来标记它们，那么维度对于我来说太高了设备来处理（例如，我的笔记本电脑有 16G 内存，但标签 customer_id 已经需要 24G 内存）并且我相信一定有更好的方法来处理这种情况，但我对机器学习非常陌生。]]></description>
      <guid>https://stackoverflow.com/questions/78409561/one-hot-encoding-with-large-dimensions</guid>
      <pubDate>Tue, 30 Apr 2024 15:23:06 GMT</pubDate>
    </item>
    <item>
      <title>model.fit 不起作用“运行时错误：‘tf.data.Dataset’仅支持急切模式下或 tf.function 内的 Python 样式迭代。”</title>
      <link>https://stackoverflow.com/questions/78409501/model-fit-is-not-working-runtimeerror-tf-data-dataset-only-supports-python-s</link>
      <description><![CDATA[我想在 JupyterLab 上编写一个简单的机器学习代码，但出现标题错误
我已经收集了数据，因为x是lamda，eps，c（数据的形状是102010行×3列），y是sen（数据的形状是102010行×1列），我想要我的机器学习模型来预测。这是我的简单模型代码。
导入tensorflow为tf
从 sklearn.model_selection 导入 train_test_split
将 pandas 导入为 pd

# 将数据拆分为特征 (X) 和目标 (y)
X_data = df_total_x_data.values.reshape(-1, 1) # 如果需要则重塑
y_data = df_sen_final.values

x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)
模型 = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)
model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))

如何修复此错误？
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
RuntimeError Traceback（最近一次调用最后一次）
[60] 中的单元格，第 17 行
     15 模型 = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
     16 model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)
---&gt; 17 model.fit(x_train, y_train, epochs=10,validation_data=(x_test, y_test))

文件/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:122，位于filter_traceback..error_handler(*args, **kwargs)
    第119章
    120 # 要获取完整的堆栈跟踪，请调用：
    121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 引发 e.with_traceback(filtered_tb)
    123最后：
    124 删除filtered_tb

文件 /usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py:503，在 DatasetV2.__iter__(self) 中
    第501章
    第502章：
--&gt; 503 raise RuntimeError(“tf.data.Dataset`仅支持Python风格”
    [第 504 章]

RuntimeError: `tf.data.Dataset` 仅支持急切模式下或 tf.function 内的 Python 风格迭代。
]]></description>
      <guid>https://stackoverflow.com/questions/78409501/model-fit-is-not-working-runtimeerror-tf-data-dataset-only-supports-python-s</guid>
      <pubDate>Tue, 30 Apr 2024 15:12:43 GMT</pubDate>
    </item>
    <item>
      <title>如何应用神经网络的总势能原理来解决结构力学问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78409373/how-implement-a-total-potential-energy-principle-for-a-neural-network-to-solve-s</link>
      <description><![CDATA[我需要创建一个神经网络来解决负载下板的弹性问题，并且我想实现一个基于物理的神经网络，该网络通过最小化基于总势能原理的损失函数来解决该问题。
我使用总势能原理作为损失函数，该原理指出结构的平衡配置是使系统总能量最小化的配置。所以我强加了损失函数=最小势能，我进行了积分，然后，为了最小化它，我强加了总势能本身相对于我想要恢复的变量的导数等于0。获得 A*x=b 类型的方程，其中 x 是神经网络的权重，但它不起作用。可能是积分过程或损失函数构造有问题。]]></description>
      <guid>https://stackoverflow.com/questions/78409373/how-implement-a-total-potential-energy-principle-for-a-neural-network-to-solve-s</guid>
      <pubDate>Tue, 30 Apr 2024 14:50:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么学习率需要这么低？[关闭]</title>
      <link>https://stackoverflow.com/questions/78409111/why-does-learning-rate-need-to-be-so-low</link>
      <description><![CDATA[我是机器学习新手，所以我尝试在多元线性回归中使梯度下降。函数很简单，就是z = x + y。但由于某种原因，学习率需要为 1e-16 才能发挥作用。有什么想法吗？
这是代码
将 numpy 导入为 np

case_x = np.array([[1,1], [2,3], [5,6], [1,5], [2,2], [100,100], [101,102], [500,500], [ 1000,1000],[100000000,100000000]])
case_y = np.array([2,5,11,6,4,200,203,1000,2000,200000000])


cur_w = np.array([0,0])
当前_b = 0
def f(x,w,b)：
    返回 np.dot(w,x) + b
    
定义 J(w,b)：
    总和_ = 0
    对于范围 (0,10) 内的 i：
        sum_ += pow(f(cases_x[i], w,b) - Cases_y[i],2)
    总和_ /= 20
    返回总和_
    

def derivitive_w(w):
    d = np.array([])
    对于范围 (0,2) 内的 i：
        电流_d = 0
        对于范围 (0,10) 内的 j：
            cur_d += (f(cases_x[j], cur_w, cur_b) - Cases_y[j]) * Cases_x[j][i]
            
        cur_d /= 10
        #print(cur_d)
        d = np.append(d,cur_d)
    #打印（d）
    返回d
def derivitive_b(b):
    tmp_b = 0
    对于范围 (0,10) 内的 i：
        tmp_b += f(cases_x[i], cur_w, cur_b) - Cases_y[i]
    tmp_b /= 10
    返回tmp_b
对于范围 (0,100) 内的 i：
    tmp_w = derivitive_w(cur_w)
    tmp_b = derivitive_b(cur_b)
    
    cur_b = cur_b - (0.0000000000000001 * tmp_b)
    cur_w = cur_w - (0.0000000000000001 * tmp_w)
inpt = 列表(map(int,input().split()))
arr = np.array([inpt[0],inpt[1]])
打印（int（f（arr，cur_w，cur_b）））
]]></description>
      <guid>https://stackoverflow.com/questions/78409111/why-does-learning-rate-need-to-be-so-low</guid>
      <pubDate>Tue, 30 Apr 2024 14:11:05 GMT</pubDate>
    </item>
    <item>
      <title>RNN实现方程问题的简单BPTT</title>
      <link>https://stackoverflow.com/questions/78408682/simple-bptt-for-rnn-implementation-equation-question</link>
      <description><![CDATA[我正在尝试从头开始实现简单的 RNN，以了解每个实现背后的计算步骤。前向传播看起来很简单，但后向传播似乎很困难。尤其是尺寸不符……
def rnn_forward(self, e) ：
        对于范围内的 t(self.T_x - 1) ：
            # single (n_x, n_m) m 是时间上的训练集大小
            xt = self.cache[&#39;X&#39;][:, :, t]
            # 上一步的隐藏状态
            a_prev = self.cache[&#39;A&#39;][:, :, t]
            # 下一步的隐藏状态是通过以下权重和偏差计算的。
            a_next = tanh(np.dot(self.parameters[&#39;W_aa&#39;], a_prev) + np.dot(self.parameters[&#39;W_ax&#39;], xt) + self.parameters[&#39;b_a&#39;])
            # 使用softmax作为最终激活
            yt_pred = softmax(np.dot(self.parameters[&#39;W_ya&#39;], a_next) + self.parameters[&#39;b_y&#39;])
            self.cache[&#39;A&#39;][:, :, (t + 1)] = a_next
            self.cache[&#39;Y_pred&#39;][:, :, t] = yt_pred

def rnn_backward(self, e):
        # 成本函数导数
        self.cache[&#39;dY_pred&#39;] = - (self.cache[&#39;Y&#39;] / self.cache[&#39;Y_pred&#39;])
        # 初始化da
        da_next = np.zeros((self.n_a, self.m))
        对于反转中的 t(范围(self.T_x - 1)) ：
            # 维度似乎是 (n_y, n_m)
            print(self.cache[&#39;dY_pred&#39;][:, :, t].shape)
            # 维度似乎也是 (n_y, n_m)
            print(softmax_backward(np.dot(self.parameters[&#39;W_ya&#39;], self.cache[&#39;A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]).shape)
            # 下面的计算会有问题吗？ da_prev 预计有暗淡 (n_a, n_m)，但 (n_y, n_m) 和 (n_y, n_m) 的点不给我 (n_a, n_m)
            da_prev = np.dot(self.cache[&#39;dY_pred&#39;][:, :, t], np.dot(self.parameters[&#39;W_ya&#39;].T, softmax_backward(np.dot(self.parameters[&#39;W_ya&#39;) ], self.cache[&#39;A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]))) + da_next
            self.cache[&#39;dW_ya&#39;] += np.dot(self.cache[&#39;dY_pred&#39;][:, :, t], np.dot(softmax_backward(np.dot(self.parameters[&#39;W_ya&#39;], self) .cache[&#39;A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]), self.cache[&#39;A&#39;][:, :, t].T))
            self.cache[&#39;db_y&#39;] += np.dot(self.cache[&#39;dY_pred&#39;][:, :, t], softmax_backward(np.dot(self.parameters[&#39;Wya&#39;], self.cache[&#39; A&#39;][:, :, t]) + self.parameters[&#39;b_y&#39;]))
            self.cache[&#39;dW_aa&#39;] += np.dot(da_prev, np.dot(tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, :, (t - 1)]) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;]), self.cache[ &#39;A&#39;][:, :, (t - 1)].T))
            self.cache[&#39;dW_ax&#39;] += np.dot(da_prev, np.dot(tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, :, (t - 1)]) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;]), self.cache[ &#39;X&#39;][:, :, t].T))
            self.cache[&#39;db_a&#39;] += np.dot(da_prev, tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, :, (t - 1)] ) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;]))
            da_next = np.dot(da_prev, np.dot(self.parameters[&#39;W_aa&#39;].T, tanh_backward(np.dot(self.parameters[&#39;W_aa&#39;], self.cache[&#39;A&#39;][:, : , (t - 1)]) + np.dot(self.parameters[&#39;W_ax&#39;], self.cache[&#39;X&#39;][:, :, t]) + self.parameters[&#39;b_a&#39;])))

正如代码中的注释，我似乎无法正确实现反向传播。 da_prev 的维度没有正确组合在一起，导致 (n_a, n_m)…我错过了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78408682/simple-bptt-for-rnn-implementation-equation-question</guid>
      <pubDate>Tue, 30 Apr 2024 12:58:33 GMT</pubDate>
    </item>
    <item>
      <title>转换深度学习 esrgan 模型时输入张量形状不匹配</title>
      <link>https://stackoverflow.com/questions/78407762/input-tensor-shape-mismatch-when-converting-deep-learning-esrgan-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78407762/input-tensor-shape-mismatch-when-converting-deep-learning-esrgan-model</guid>
      <pubDate>Tue, 30 Apr 2024 10:05:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使 XGBoost 在分层分类器中工作</title>
      <link>https://stackoverflow.com/questions/78407603/how-to-make-xgboost-work-in-a-hierarchical-classifier</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78407603/how-to-make-xgboost-work-in-a-hierarchical-classifier</guid>
      <pubDate>Tue, 30 Apr 2024 09:37:37 GMT</pubDate>
    </item>
    <item>
      <title>尝试对简短的调查答案进行聚类（1 到 10 个单词）。我走在正确的轨道上吗？</title>
      <link>https://stackoverflow.com/questions/78407025/trying-to-cluster-short-survey-answers-1-to-10-words-am-i-on-the-right-track</link>
      <description><![CDATA[这是我想要完全制作的内容的解释（这是学校的一个项目）。

用户只需将调查中提出的任何问题的答案放入一个文件即可。

2.机器找到相似的答案，并将它们分组到一个未命名的标签或簇下（考虑使用 MeanShift、GMM、KMeans）

如果可能的话，我还希望它为集群生成标签。

4.将聚类和标记的答案写回到文件中以供检查并用于任何目的。
关于数据的一些上下文：很多简短的答案（有一些长的，超过 10 个单词）答案，例如“我不知道”、“??”、“有帮助”、“红色”等，以及每个都有 200 到 2000 个答案。答案是荷兰语或法语，是否建议我将它们翻译成英语以获得更好的性能？通常有大约 7 到 20 个（数量较多的情况很少见）簇。我还有正确的答案标签，这样我就可以检查算法是否正确聚类。
我尝试过研究它，我需要首先对我的文本进行矢量化，为此我尝试了 scikit 中的 TF-IDF 和 Count 矢量化器。我还找到了他们的备忘单，它建议我使用 MeanShift。
我还没有尝试寻找最佳参数，但性能似乎很差（接近随机）。我使用调整兰德指数、归一化互信息和轮廓分数来评估。
我走在正确的道路上还是有更好的东西？矢量化方法、嵌入、聚类算法？
编辑：我刚刚意识到一些可能会推翻算法的事情。在每项调查中都有一个名为“其他”的类别。这是一个与实际答案无关的类别。
我认为可行的解决方法：该类别“很小”，大约为 8%。我的聚类算法总是产生太多的类，但我可以尝试在将 1 或 2 个答案的类组合到“其他”中之间找到平衡。]]></description>
      <guid>https://stackoverflow.com/questions/78407025/trying-to-cluster-short-survey-answers-1-to-10-words-am-i-on-the-right-track</guid>
      <pubDate>Tue, 30 Apr 2024 07:50:57 GMT</pubDate>
    </item>
    <item>
      <title>NefTune 在 Transformers 上获得 0 训练损失</title>
      <link>https://stackoverflow.com/questions/78404768/neftune-receiving-0-training-loss-on-transformers</link>
      <description><![CDATA[我基本上是在尝试使用 Neftune 微调我的模型。模型基于土耳其语言。但在那里我的训练损失为零。我尝试过另一种模型，例如 Turkish-GPT2 没有问题一切都好。我认为模型可能有问题。我不知道如何处理这个问题。
加载模型：
从变压器导入 AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(“asafaya/kanarya-750m”)
模型 = AutoModelForCausalLM.from_pretrained(“asafaya/kanarya-750m”)

v3_prompt =“”“Aşağıda，daha fazla bağlam sağlayan bir girdiyle eşleştirilmiş，bir görevi açıklayan bir talimat bulunmaktadır。请注意，请确保您的设备正常工作。

＃＃＃ 输入：
{}

＃＃＃ 指示：
{}

＃＃＃ 回复：
{}
”“”

更改格式提示：
EOS_TOKEN = tokenizer.eos_token # 必须添加EOS_TOKEN
defformatting_prompts_func（示例）：
    输入=示例[“输入”]
    说明 = 示例[&#39;说明&#39;]
    输出=示例[“响应”]
    文本=[]
    对于 zip 中的输入、指令、输出（输入、指令、输出）：
        # 必须添加EOS_TOKEN，否则你的一代将永远延续下去！
        text = v3_prompt.format(输入、指令、输出) + EOS_TOKEN
        文本.append(文本)
    返回 {“文本”； ：文本，}
经过

从数据集导入数据集

数据集 = Dataset.from_pandas(数据[:40000])
数据集= dataset.map(formatting_prompts_func,batched=True)

Neftune：
from trl import SFTTrainer
从 Transformers 导入 TrainingArguments

trainer_2 = SFTTrainer(
    型号=型号，
    train_dataset=数据集，
    dataset_text_field=&quot;文本&quot;,
    最大序列长度=512，
    neftune_noise_alpha=5,
    包装=假，
    args = 训练参数(
        per_device_train_batch_size = 1, # 批量大小
        gradient_accumulation_steps = 2, # 梯度累积步数
        热身步骤 = 5,
        最大步数 = 80,
        学习率 = 2e-4,
        fp16 = 假，
        bf16 = torch.cuda.is_bf16_supported(),
        日志记录步骤 = 1,
        优化=“adamw_8bit”，
        权重衰减 = 0.01,
        lr_scheduler_type =“线性”，
        种子=3407，
        输出目录=“输出”，
    ),
）
trainer_2.train()

输出：
&lt;前&gt;&lt;代码&gt; [80/80 00:25，纪元 0/1]
步数训练损失
1 0.000000
2 0.000000
3 0.000000
4 0.000000
5 0.000000
6 0.000000
7 0.000000
8 0.000000
9 0.000000
10 0.000000
11 0.000000
12 0.000000
13 0.000000
14 0.000000
15 0.000000
16 0.000000
17 0.000000
18 0.000000
19 0.000000
20 0.000000
21 0.000000
22 0.000000
23 0.000000
24 0.000000
25 0.000000
26 0.000000
27 0.000000
28 0.000000
29 0.000000
30 0.000000
31 0.000000
32 0.000000
33 0.000000
34 0.000000
35 0.000000
36 0.000000
37 0.000000
38 0.000000
39 0.000000
40 0.000000
41 0.000000
42 0.000000
43 0.000000
44 0.000000
45 0.000000
46 0.000000
47 0.000000
48 0.000000
49 0.000000
50 0.000000
51 0.000000
52 0.000000
53 0.000000
54 0.000000
55 0.000000
56 0.000000
57 0.000000
58 0.000000
59 0.000000
60 0.000000
61 0.000000
62 0.000000
63 0.000000
64 0.000000
65 0.000000
66 0.000000
67 0.000000
68 0.000000
69 0.000000
70 0.000000
71 0.000000
72 0.000000
73 0.000000
74 0.000000
75 0.000000
76 0.000000
77 0.000000
78 0.000000
79 0.000000
80 0.000000
TrainOutput（global_step = 80，training_loss = 0.0，metrics = {&#39;train_runtime&#39;：25.3789，&#39;train_samples_per_second&#39;：6.304，&#39;train_steps_per_second&#39;：3.152，&#39;total_flos&#39;：117937578909696.0，&#39;train_loss&#39;：0.0，&#39;epoch&#39;： 0.004})
]]></description>
      <guid>https://stackoverflow.com/questions/78404768/neftune-receiving-0-training-loss-on-transformers</guid>
      <pubDate>Mon, 29 Apr 2024 19:23:04 GMT</pubDate>
    </item>
    <item>
      <title>通过 Keras 训练同时检查不同类型的数据</title>
      <link>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</link>
      <description><![CDATA[在回归任务中，我得到了以下数据：

具有已知标签的输入向量。预测和标签之间应使用 MSE 损失。
没有标签的输入向量对，已知模型应该给出相似的结果。两个预测之间应使用 MSE 损失。

同时使用这两种数据拟合 Keras 模型的正确方法是什么？
理想情况下，我希望训练循环以交错的方式迭代这两种数据 - 一个监督（1）批次，然后是一个自监督（2）批次，然后再次进行监督等。
如果重要的话，我正在使用 Jax 后端。Keras 版本 3.2.1。]]></description>
      <guid>https://stackoverflow.com/questions/78348894/simultaneously-going-over-different-kinds-of-data-with-keras-training</guid>
      <pubDate>Thu, 18 Apr 2024 16:05:11 GMT</pubDate>
    </item>
    </channel>
</rss>