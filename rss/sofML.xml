<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 13 May 2024 18:17:06 GMT</lastBuildDate>
    <item>
      <title>如何将 LinkedIn 或类似网站上的原始文本格式职位发布处理为键值格式？</title>
      <link>https://stackoverflow.com/questions/78473771/how-can-i-process-raw-text-format-job-posts-from-linkedin-or-similar-sites-into</link>
      <description><![CDATA[出于研究目的，我从链接中收集了一些职位信息。我想从这些职位帖子中获取特定数据并将其保存在我的 SQL 数据库中。那么我如何处理职位发布 txt 文件并获取特定字段，如标题、描述、技能、要求列表、注释（如果有）、角色、地点、福利等。而且每个职位发布都有自己的格式。我想我需要使用一些 NLP 技术，比如 NER，但我不知道如何实际解决这个问题。我不是机器学习专家，所以一些建议、参考资料会很好。]]></description>
      <guid>https://stackoverflow.com/questions/78473771/how-can-i-process-raw-text-format-job-posts-from-linkedin-or-similar-sites-into</guid>
      <pubDate>Mon, 13 May 2024 17:02:32 GMT</pubDate>
    </item>
    <item>
      <title>有人设法在 colab 上运行 alphageometry 吗？</title>
      <link>https://stackoverflow.com/questions/78473546/has-anyone-manage-to-run-alphageometry-on-colab</link>
      <description><![CDATA[我正在尝试在 colab 上运行 alphageometry 但不断遇到问题：
https://colab.research.google.com/drive/1RrTfa3O80QOFL68rXdtAyn1KHt0NCCB3 ?usp=共享
下面的堆栈跟踪不包括 JAX 内部框架。
前面是发生的原始异常，未修改。
上述异常是导致以下异常的直接原因：
回溯（最近一次调用最后一次）：
  文件“/usr/lib/python3.10/runpy.py”，第 196 行，在 _run_module_as_main 中
    返回_run_code（代码，main_globals，无，
  文件“/usr/lib/python3.10/runpy.py”，第 86 行，在 _run_code 中
    执行（代码，run_globals）
  文件“/content/alphageometry/alphageometry.py”，第651行，在&lt;module&gt;中。
    应用程序.运行（主要）
  文件“/usr/local/lib/python3.10/dist-packages/absl/app.py”，第308行，运行中
    _run_main（主要，参数）
  文件“/usr/local/lib/python3.10/dist-packages/absl/app.py”，第 254 行，在 _run_main 中
    sys.exit(主(argv))
  文件“/content/alphageometry/alphageometry.py”，第 637 行，在 main 中
    模型 = get_lm(_CKPT_PATH.value, _VOCAB_PATH.value)
  文件“/content/alphageometry/alphageometry.py”，第 203 行，get_lm
    返回 lm.LanguageModelInference(vocab_path, ckpt_init, mode=&#39;beam_search&#39;)
  文件“/content/alphageometry/lm_inference.py”，第 62 行，位于 __init__ 中
    (tstate, _, imodel, prngs) = trainer.initialize_model()
  文件“/content/alphageometry/meliad_lib/meliad/training_loop.py”，第 367 行，initialize_model
    变量 = model_init_fn(init_rngs, imodel.get_fake_input())
  文件“/content/alphageometry/models.py”，第 68 行，在 __call__ 中
    自解码器（
  文件“/content/alphageometry/meliad_lib/meliad/transformer/decoder_stack.py”，第 273 行，在 __call__ 中
    嵌入 = embeddings.astype(self.dtype)
  文件“/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py”，第 4952 行，在 _astype 中
    dtypes.check_user_dtype_supported(dtype, “astype”)
类型错误：JAX 仅支持数字和布尔数据类型，在 astype` 中获取数据类型 bfloat16

这就是它停止的地方：
!python -m alphageometry \
--alsologtostderr \
--problems_file=$(pwd)/examples.txt \
--problem_name=正交中心 \
--mode=alpha几何 \
--defs_file=$(pwd)/defs.txt \
--rules_file=$(pwd)/rules.txt \
--ckpt_path=$数据\
  --vocab_path=$DATA/geometry.757.model \
  --gin_search_paths=$MELIAD_PATH/transformer/configs,$(pwd) \
  --gin_file=base_htrans.gin \
  --gin_file=大小/medium_150M.gin \
  --gin_file=选项/positions_t5.gin \
  --gin_file=选项/lr_cosine_decay.gin \
  --gin_file=选项/seq_1024_nocache.gin \
  --gin_file=geometry_150M_generate.gin \
  --gin_param=DecoderOnlyLanguageModelGenerate.output_token_losses=True \
  --gin_param=TransformerTaskConfig.batch_size=$BATCH_SIZE \
  --gin_param=TransformerTaskConfig.sequence_length=128 \
  --gin_param=Trainer.restore_state_variables=False \
  --beam_size=$BEAM_SIZE \
  --search_深度=$深度\

到目前为止，有人设法让它在 Colab 中运行吗？我在网上没有找到任何相关内容。
我按照 git 上提供的教程进行操作，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/78473546/has-anyone-manage-to-run-alphageometry-on-colab</guid>
      <pubDate>Mon, 13 May 2024 16:12:04 GMT</pubDate>
    </item>
    <item>
      <title>在深度训练/验证循环期间使用分层 k 折叠时出现越界错误</title>
      <link>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78473057/out-of-bounds-error-when-using-stratified-k-fold-during-deep-train-validation-lo</guid>
      <pubDate>Mon, 13 May 2024 14:43:39 GMT</pubDate>
    </item>
    <item>
      <title>MSE 高且 R 方值为负的原因</title>
      <link>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</guid>
      <pubDate>Mon, 13 May 2024 14:10:35 GMT</pubDate>
    </item>
    <item>
      <title>预测社交媒体参与率的最佳机器学习模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</link>
      <description><![CDATA[根据你们的意见，哪个模型是预测社交媒体（例如 Facebook）中参与度帖子的最佳模型。
如果你们中有人遇到过同样的情况，请分享一下您的经验
谢谢
我尝试了这两个：

线性回归（11% 准确度）

LightGBM 回归器（准确度 79%）

]]></description>
      <guid>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</guid>
      <pubDate>Mon, 13 May 2024 13:59:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么二元分类中非 sigmoid 变换输出比 sigmoid 变换输出更匹配目标矩阵？</title>
      <link>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</link>
      <description><![CDATA[我正在使用神经网络进行二元分类任务，其中模型输出 logits，然后通过 sigmoid 函数将其映射到概率。目标矩阵是一个 17x17 网格，其中距中心曼哈顿距离 &lt;=2 内的单元格标记为 1（正类），所有其他单元格标记为 0（负类）：
目标矩阵
这是损失的代码。我使用 binary_cross_entropy_with_logits 作为我的损失函数。 sigmoid函数在pytorch提供的上述函数中实现：
 defforward(自身，输入，目标)：
        pos_mask =（目标== 1）
        neg_mask =（目标== 0）
        pos_num = pos_mask.sum().float()
        neg_num = neg_mask.sum().float()
        重量 = target.new_zeros(target.size())
        权重[pos_mask] = 1 / pos_num
        权重[neg_mask] = 1 / neg_num * self.neg_weight
        重量 /= 重量.sum()
        返回 F.binary_cross_entropy_with_logits(
            输入，目标，权重，减少=&#39;总和&#39;）

然后我可视化训练模型的输出，并注意到一个意想不到的现象。可视化显示了两张图像：一张是模型直接输出的 logits（左），另一张是通过对这些 logits 应用 sigmoid 函数获得的概率（右）。令人惊讶的是，与 sigmoid 变换输出（概率）相比，非 sigmoid 变换输出（logits）似乎更好地匹配目标矩阵的模式。
可视化
这个结果令人费解，因为在训练期间，损失函数对 sigmoid 变换后的概率进行运算。因此，人们会期望 sigmoid 变换的输出更接近目标矩阵。
这种行为背后是否存在解释或常见原因，即原始逻辑在视觉上比从其派生的概率更准确地匹配目标结构？我可能缺少任何可能影响此外观的可视化或缩放因素吗？
我在网上搜索过，但似乎没有与我类似的问题。我仔细检查了 binary_cross_entropy_with_logits 中是否存在 sigmoid 函数：
labels = self._create_labels(responses.size())
loss = self.criterion(responses, labels) # 标准：binary_cross_entropy_with_logits

_responses = torch.sigmoid(responses)
_loss = self._criterion(_responses, labels) # 标准：binary_cross_entropy

但是，在我的实验中，loss 等于 _loss，这意味着虽然是 sigmoided 响应尝试拟合目标矩阵，但非 sigmoided 响应却拟合目标矩阵目标矩阵更好。
&lt;小时/&gt;
如果您想了解有关该项目的更多详细信息，请参阅以下描述。我正在使用 SiamFC 重现一个对象跟踪项目，可视化 siamfc 中第 171 行的响应图-pytorch/siamfc/siamfc.py，作为反应图，反映第一帧中的groundtruth目标与后续帧中的搜索区域之间的相似性。您可以在项目中下载预训练的模型，插入一些代码进行可视化并运行代码查看结果。]]></description>
      <guid>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</guid>
      <pubDate>Mon, 13 May 2024 13:45:05 GMT</pubDate>
    </item>
    <item>
      <title>如何创建我自己的自定义输入器以在 pyspark.ml 管道中无缝输入常量值</title>
      <link>https://stackoverflow.com/questions/78472581/how-to-create-my-own-custom-imputter-to-input-constant-values-seamlessly-in-pysp</link>
      <description><![CDATA[我想通过 CV 搜索来优化数据集上缺失值的插补。这在我熟悉的 sklearn 中是微不足道的——但是，我是第一次使用集群分布式 Spark 数据帧，并且必须使用 pyspark.ml 模块。
据我所知， pyspark.ml.feature.Imputer 类无法估算（选择）常量值，这是我想测试的一件事。
您建议我如何执行此操作？我研究了编写一个自定义转换器，这在 sklearn API 中也很容易，但我还没有在 pyspark.ml 中找到明确的方法来做到这一点。
非常感谢任何见解。]]></description>
      <guid>https://stackoverflow.com/questions/78472581/how-to-create-my-own-custom-imputter-to-input-constant-values-seamlessly-in-pysp</guid>
      <pubDate>Mon, 13 May 2024 13:26:04 GMT</pubDate>
    </item>
    <item>
      <title>易于计算机器学习算法的决策边界[关闭]</title>
      <link>https://stackoverflow.com/questions/78471748/easy-to-compute-decision-boundaries-of-a-machine-learning-algorithm</link>
      <description><![CDATA[可用于精确计算数值数据的 2D 或 ND 分类的决策边界的最佳机器学习算法是什么。我对分类的性能不感兴趣，而是对决策边界的简单性和计算时间感兴趣。我已经将 SVM 与 sk-learn 一起使用，但它只返回每条线的方程，而不返回界定 2D 类的多边形。我感兴趣的是提取每个类别的最终分类的多边形或确切形状。
非常感谢。
我尝试了 SVM，但库没有提供解决方案。我期待一种有监督的机器学习算法，具有易于提取决策边界的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78471748/easy-to-compute-decision-boundaries-of-a-machine-learning-algorithm</guid>
      <pubDate>Mon, 13 May 2024 10:49:18 GMT</pubDate>
    </item>
    <item>
      <title>我需要 ph2 数据集用于分类项目</title>
      <link>https://stackoverflow.com/questions/78471681/i-need-ph2-data-set-for-classification-project</link>
      <description><![CDATA[我在大学有一个关于人工智能的项目“ ph2数据集中的分类和深度学习但是我无法找到适合这个项目的数据，因为Kaggle中的数据只是图片，不包含样本是否患病的信息。谁有合适的数据？
我意识到除了有人已经在使用这个数据集之外没有其他解决方案，因为我没有时间在大学展示该项目]]></description>
      <guid>https://stackoverflow.com/questions/78471681/i-need-ph2-data-set-for-classification-project</guid>
      <pubDate>Mon, 13 May 2024 10:38:48 GMT</pubDate>
    </item>
    <item>
      <title>在 Streamlit.io 上部署 Python 应用程序时出错：“sklearn”的 ModuleNotFoundError</title>
      <link>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</link>
      <description><![CDATA[我在 Streamlit.io 上部署 Python 应用程序时遇到错误。尽管在我的 requests.txt 文件中列出了“scikit-learn”，但我在部署过程中遇到了 ModuleNotFoundError。
]]></description>
      <guid>https://stackoverflow.com/questions/78469534/error-deploying-python-app-on-streamlit-io-modulenotfounderror-for-sklearn</guid>
      <pubDate>Sun, 12 May 2024 23:18:51 GMT</pubDate>
    </item>
    <item>
      <title>训练 DL 模型时，本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束</title>
      <link>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</link>
      <description><![CDATA[我正在创建一个植物病害识别模型。我有一个包含 38 种疾病的数据集，每种疾病有大约 2000 张图像。但是在训练模型时，由于一些 OUT_OF_RANGE 错误，一些时期被跳过。有人可以帮我解决这个问题吗？
导入操作系统
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Conv2D、MaxPooling2D、展平、密集、输入

train_dir = &#39;数据集/火车&#39;
valid_dir = &#39;数据集/有效&#39;
批量大小 = 32

train_datagen = 图像数据生成器(
    重新缩放=1./255，
    旋转范围=40，
    width_shift_range=0.2，
    height_shift_range=0.2，
    剪切范围=0.2，
    缩放范围=0.2，
    水平翻转=真，
    fill_mode=&#39;最近&#39;
）

valid_datagen = ImageDataGenerator(重新缩放=1./255)

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

valid_generator = valid_datagen.flow_from_directory(
    有效目录，
    目标大小=(150, 150),
    批量大小=批量大小，
    class_mode=&#39;分类&#39;
）

模型=顺序（[
    输入(形状=(150, 150, 3)),
    Conv2D(32, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(64, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    Conv2D(128, (3, 3), 激活=&#39;relu&#39;),
    最大池化2D(2, 2),
    展平（），
    密集（512，激活=&#39;relu&#39;），
    Dense(38,activation=&#39;softmax&#39;) # 根据疾病类别的数量调整输出单位
]）

model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=10，
    验证数据=有效生成器，
    valid_steps=valid_generator.samples // 批量大小
）

model.save(&#39;plant_disease_model.h5&#39;)

class_indices = train_generator.class_indices
疾病名称 = 列表(class_indices.keys())
print(“类索引到疾病名称的映射：”, class_indices)

终端：
找到属于 38 个类别的 70295 个图像。
找到属于 38 个类别的 17572 张图像。
2024-04-23 19：50：32.085744：我tensorflow / core / platform / cpu_feature_guard.cc：210]此TensorFlow二进制文件经过优化以使用可用的CPU仪器
性能关键操作中的操作。
要启用以下指令：AVX2 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
纪元 1/10
\.venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.p
y：120：用户警告：您的“PyDataset”类应在其构造函数中调用“super().__init__(**kwargs)”。 `**kwargs` 可以包括 `workers`、`use_m
ultiprocessing`、`max_queue_size`。不要将这些参数传递给“fit()”，因为它们将被忽略。
  self._warn_if_super_not_used()
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m905s←[0m 411ms/步]]准确度：0.4608 - 损失：1.8737 - val_accuracy：0.7432 - val_
损失：0.8556
纪元 2/10
←[1m 1/2196←[0m ←[37m–––––––––––––––––––←[0m ←[1m12:02←[0m 329ms/步 - 精度: 0.6875] -损失：0.78202024-04-23 20:05:37.996528：W张量
ow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：序列结束
         [[{{节点It​​eratorGetNext}}]]
C:\Users\Admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py:155: UserWarning: 您的输入数据不足；中断训练。嘛
确保您的数据集或生成器可以生成至少“steps_per_epoch * epochs”批次。您可能需要使用`.repeat()`函数
构建您的数据集。
  self.gen.throw（类型，值，回溯）
2024-04-23 20:05:38.068817：W tensorflow/core/framework/local_rendezvous.cc:404] 本地集合点正在中止，状态为：OUT_OF_RANGE：结束
顺序
         [[{{节点It​​eratorGetNext}}]]
←[1m2196/2196←[0m ←[32m–––––––––––––––––––←[0m←[37m←[0m ←[1m0s←[0m 49us/步]]准确度：0.6875 - 损失：0.7820 - val_accuracy：0.7500 - val_los
秒：0.2462

如上所示，epoch 1 已成功完成，但 epoch 2 由于某些错误而终止。同样，epoch 3、5、7、9 成功完成，但 epoch 4、6、8、10 出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78376338/while-training-dl-model-local-rendezvous-is-aborting-with-status-out-of-range</guid>
      <pubDate>Wed, 24 Apr 2024 06:27:20 GMT</pubDate>
    </item>
    <item>
      <title>scikit 学习 1.1.3。 import 无法在 python 中导入名称“METRIC_MAPPING64”</title>
      <link>https://stackoverflow.com/questions/78327535/scikit-learn-1-1-3-import-cannot-import-name-metric-mapping64-in-python</link>
      <description><![CDATA[我试图将 scikit-learn 中的线性模型导入到 vscode 中的 python 代码中，但收到意外的错误消息。
导入sklearn
从sklearn导入线性模型

错误：
无法从“sklearn.metrics._dist_metrics”导入名称“METRIC_MAPPING64”

我不想导入这些指标，如何解决这个问题？
使用的scikit-learn版本是1.1.3。]]></description>
      <guid>https://stackoverflow.com/questions/78327535/scikit-learn-1-1-3-import-cannot-import-name-metric-mapping64-in-python</guid>
      <pubDate>Mon, 15 Apr 2024 09:54:33 GMT</pubDate>
    </item>
    <item>
      <title>从 nltk 停用词中排除负面词</title>
      <link>https://stackoverflow.com/questions/76924321/exclude-negative-words-from-nltk-stopwords</link>
      <description><![CDATA[我想从我的句子中删除 nltk 停用词，除了那些具有负面含义的停用词，例如：不，不，不能等。换句话说，我想从停用词列表中排除负面词。我怎样才能做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/76924321/exclude-negative-words-from-nltk-stopwords</guid>
      <pubDate>Thu, 17 Aug 2023 18:45:59 GMT</pubDate>
    </item>
    <item>
      <title>仅具有一个数字特征的逻辑回归</title>
      <link>https://stackoverflow.com/questions/43010225/logistic-regression-with-just-one-numeric-feature</link>
      <description><![CDATA[当您只有一个数值特征时，使用 scikit-learn 的 LogisticRegression 求解器的正确方法是什么？
我运行了一个我发现很难解释的简单示例。谁能解释一下我在这里做错了什么？
导入pandas
将 numpy 导入为 np
从 sklearn.linear_model 导入 LogisticRegression

X = [1, 2, 3, 10, 11, 12]
X = np.reshape(X, (6, 1))
Y = [0, 0, 0, 1, 1, 1]
Y = np.reshape(Y, (6, 1))

lr = 逻辑回归()

lr.fit(X, Y)
print(&quot;2 --&gt; {0}&quot;.format(lr.predict(2)))
print(&quot;4 --&gt; {0}&quot;.format(lr.predict(4)))

这是脚本运行完毕后得到的输出。 4 的预测不应该是 0 因为根据高斯分布 4 更接近根据测试集分类为 0 的分布吗？

&lt;前&gt;&lt;代码&gt;2 --&gt; [0]
4 --&gt; [1]

当只有一列包含数值数据时，逻辑回归采用什么方法？ ]]></description>
      <guid>https://stackoverflow.com/questions/43010225/logistic-regression-with-just-one-numeric-feature</guid>
      <pubDate>Fri, 24 Mar 2017 22:36:12 GMT</pubDate>
    </item>
    <item>
      <title>控制 Scikit Learn 中逻辑回归的阈值</title>
      <link>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</link>
      <description><![CDATA[我在高度不平衡的数据集上使用 scikit-learn 中的 LogisticRegression() 方法。我什至将 class_weight 功能设置为 auto。
我知道在逻辑回归中应该可以知道特定类对的阈值是多少。 
是否可以知道 LogisticRegression() 方法设计的每个一对一类的阈值是多少？
我在文档页面中没有找到任何内容。
默认情况下，无论参数值如何，它是否都会应用 0.5 值作为所有类的阈值？]]></description>
      <guid>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</guid>
      <pubDate>Wed, 25 Feb 2015 10:11:33 GMT</pubDate>
    </item>
    </channel>
</rss>