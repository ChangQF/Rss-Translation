<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 16 May 2024 12:27:13 GMT</lastBuildDate>
    <item>
      <title>如何评估 SVM 模型的变量重要性？</title>
      <link>https://stackoverflow.com/questions/78488619/how-do-i-asses-variable-importance-of-a-svm-model</link>
      <description><![CDATA[我正在开发一个机器学习项目。我的目标变量是二进制的，我用插入符构建了一个 SVM 径向模型：
ctrl_SVM &lt;- trainControl(method=“cv”，number=10，search=“grid”，summaryFunction = TwoClassSummary，classProbs = TRUE)
param_grid_SVM_radial &lt;- Expand.grid(C = c(0.01, 0.1, 1, 10, 100), sigma = c(0.01, 0.1, 1, 10))
SVM_radial &lt;- train(Target~., data=under_svm, method = &quot;svmRadial&quot;, trControl = ctrl_SVM,tuneGrid = param_grid_SVM_radial,
                    指标=“ROC”，预处理=NULL）

如何评估变量的重要性？正确的代码是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78488619/how-do-i-asses-variable-importance-of-a-svm-model</guid>
      <pubDate>Thu, 16 May 2024 08:44:20 GMT</pubDate>
    </item>
    <item>
      <title>有谁可以询问有关使用 NER 和 XLM-RoBERTa 进行信息提取的问题吗？</title>
      <link>https://stackoverflow.com/questions/78488394/is-there-anyone-can-i-ask-about-information-extraction-using-ner-with-xlm-robert</link>
      <description><![CDATA[大家好我想问一下关于从PDF文档中提取信息的问题。因此，我将使用 XLM-RoBERTa 和 NER 来执行信息提取，并使用来自以下来源的代码进行微调：https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a。从这个来源来看，它确实使用了 BERT，并且在我尝试之后，结果发现来自单词的预测实体与真实值不同。我很困惑是否需要从代码中更改某些内容，或者数据集是否有问题，因为我使用的数据集是自制的数据集。有什么可以问的吗？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78488394/is-there-anyone-can-i-ask-about-information-extraction-using-ner-with-xlm-robert</guid>
      <pubDate>Thu, 16 May 2024 08:03:25 GMT</pubDate>
    </item>
    <item>
      <title>识别和提取特定语句</title>
      <link>https://stackoverflow.com/questions/78487711/identifying-and-extracting-particular-statements</link>
      <description><![CDATA[鉴于一份包含排除声明的文件，例如“提供的所有文件都证明没有涉及印度尼西亚船只”。我想从文件中识别此类声明，然后使用机器学习模型提取国家/地区。我
正在考虑我们可以使用 lstm 和 NER 或 smtng...请给我更好的管道]]></description>
      <guid>https://stackoverflow.com/questions/78487711/identifying-and-extracting-particular-statements</guid>
      <pubDate>Thu, 16 May 2024 05:26:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 DeepSeekMath 7b 模型在 vllm 中进行无说明的断言，为什么，如何修复？</title>
      <link>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model-why-how-to-fix</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model-why-how-to-fix</guid>
      <pubDate>Thu, 16 May 2024 02:49:09 GMT</pubDate>
    </item>
    <item>
      <title>如何避免保存pytorch中register_forward_hook跳过的参数？</title>
      <link>https://stackoverflow.com/questions/78487193/how-to-avoid-saving-params-skipped-by-register-forward-hook-in-pytorch</link>
      <description><![CDATA[代码如下。
我可以跳过 register_forward_hook 跳过的保存权重吗？
def get_activation(mem, 名称):
    def get_output_hook（模块，输入，输出）：
        mem[名称] = 输出

    返回 get_output_hook

def add_hook（网络，mem，mapping_layers）：
    对于 net.named_modules() 中的 n、m：
        如果mapping_layers中有n：
            m.register_forward_hook(get_activation(mem, n))

行为_stu = {}
mapping_layers_stu = [&#39;块1&#39;,&#39;块2&#39;]
add_hook（网络，acts_stu，mapping_layers_stu）

]]></description>
      <guid>https://stackoverflow.com/questions/78487193/how-to-avoid-saving-params-skipped-by-register-forward-hook-in-pytorch</guid>
      <pubDate>Thu, 16 May 2024 01:44:44 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker SDK 无法使用自定义算法运行训练</title>
      <link>https://stackoverflow.com/questions/78486992/unable-to-sagemaker-sdk-to-run-training-using-a-custom-algorithm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78486992/unable-to-sagemaker-sdk-to-run-training-using-a-custom-algorithm</guid>
      <pubDate>Wed, 15 May 2024 23:54:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Flask 时的机器学习问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</guid>
      <pubDate>Wed, 15 May 2024 14:32:08 GMT</pubDate>
    </item>
    <item>
      <title>特征工程是一种新近特征[关闭]</title>
      <link>https://stackoverflow.com/questions/78481149/feature-engineering-a-recency-feature</link>
      <description><![CDATA[我有一个客户评分问题，我正在专门研究预测转化并得出转化的概率分数（使用 xgboost 分类器 atm）。我想介绍一个功能，但我很难明确该功能的定义。
具体来说，我知道当事件 A 最近发生时（例如，客户给我们的办公室打电话），这表明客户对我们的产品感兴趣并且可能会转化。为此，我创建了一个新近度功能，基本上是：（今天 - 事件日期）以天为单位。
问题在于，这没有捕捉到旧客户记录的影响。例如，客户可能在一年前给我们打电话（事件 A 触发），并在不久后进行转换，并且使用该公式，新近度特征将相对较大。我希望模型知道低新近度值会转化为更高的概率。
有没有什么好的方法来设计功能来捕捉这种关系？]]></description>
      <guid>https://stackoverflow.com/questions/78481149/feature-engineering-a-recency-feature</guid>
      <pubDate>Wed, 15 May 2024 00:26:20 GMT</pubDate>
    </item>
    <item>
      <title>调查 TensorFlow 和 PyTorch 性能的差异</title>
      <link>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78478574/investigating-discrepancies-in-tensorflow-and-pytorch-performance</guid>
      <pubDate>Tue, 14 May 2024 13:54:26 GMT</pubDate>
    </item>
    <item>
      <title>如何构建交易分类的分类引擎？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78468435/how-to-build-a-classification-engine-for-transaction-categorization</link>
      <description><![CDATA[我目前正在开发这个个人项目，以便让我的生活更轻松地预算支出，并且我正在尝试添加一种方法，允许用户训练模型来对其交易进行分类（或更详细地说是分类）。
问题是，除了本大学课程中的一些术语和小型项目之外，我没有深厚的数据科学背景，我需要一些帮助来理解如何执行此操作以及我需要学习/重新学习哪些内容。从来没有做过这样的事情。
基本上，我的想法是：
允许用户上传其交易的 CSV 数据文件（带有我预定义的校准类别变量，例如交易名称、金额、日期等）。
我知道分类模型必须经过训练才能有效，因此我希望用户分类数据量的阈值是 x，然后用户才能使用模型来预测类别（正确我，如果我不需要这个...）。
一旦超过阈值，模型将被解锁，供用户用来预测其数据的类别。
使用模型时，它将返回包含预测类别的数据集，然后用户可以根据需要编辑类别。编辑后的数据集将反馈给模型以提高准确性。
我的方向正确吗？我该如何执行此操作以及我应该学习/重新学习哪些内容？我可以在 SQL 数据库中执行此操作还是应该使用 Python 脚本（我的理解是我可以将数据存储在 SQL 服务器中，然后在 Python 中执行预处理和 ML 任务）？]]></description>
      <guid>https://stackoverflow.com/questions/78468435/how-to-build-a-classification-engine-for-transaction-categorization</guid>
      <pubDate>Sun, 12 May 2024 15:41:45 GMT</pubDate>
    </item>
    <item>
      <title>将 PyG 数据对象列表转换为 PyG 数据集？</title>
      <link>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</link>
      <description><![CDATA[我有一个 torch_geometric.data.Data 对象的 python 列表（每个对象代表一个图形）。我没有简单的方法来访问这些数据的原始文件：我只有列表。我需要将此数据对象列表转换为 torch_geometric.data.InMemoryDataset 或 torch_geometric.data.Dataset 对象，以便将其与我没有编写的更大的代码库集成。我该怎么做？
需要明确的是，我知道可以使用一系列数据对象来创建 torch_geometric.data.DataLoader 对象。但是，我特别需要一个 Dataset 对象，而不是 DataLoader 对象，因为较大的代码库在将 Dataset 对象转换为加载器之前会对它们执行一些额外的处理步骤。
我不明白为什么 PyG 让这变得如此困难。难道没有一种非常简单的方法可以做到这一点吗？
我尝试使用一个简单的 CustomDataset 类
类 CustomDataset(InMemoryDataset):
    def __init__(自身，数据)：
        超级().__init__()
        self.data = 数据
    
    def __len__(自身):
        返回 len(self.data)
    
    def __getitem__(self, idx):
        样本 = self.data[idx]
        返回样品

当我尝试获取索引 0 处的 Data 对象时，它给了我一个 KeyIndex 错误。我还尝试了上述代码的一个版本，其中超类是 Dataset 而不是 InMemoryDataset，但我不知道如何制作整理方法有效。]]></description>
      <guid>https://stackoverflow.com/questions/78433332/turning-a-list-of-pyg-data-objects-into-a-pyg-dataset</guid>
      <pubDate>Sun, 05 May 2024 18:30:03 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制多类分类中所有类的 SHAP 摘要图</title>
      <link>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</link>
      <description><![CDATA[我正在使用 XGBoost 和 SHAP 来分析多类分类问题中的特征重要性，并且需要帮助一次性绘制所有类的 SHAP 摘要图。目前，我一次只能生成一个类的绘图。
SHAP 版本：0.45.0
Python版本：3.10.12

这是我的代码：
将 xgboost 导入为 xgb
导入形状
将 numpy 导入为 np
将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.datasets 导入 make_classification
从 sklearn.metrics 导入 precision_score

# 生成合成数据
X，y = make_classification（n_samples = 500，n_features = 20，n_informative = 4，n_classes = 6，random_state = 42）
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# 训练用于多类分类的 XGBoost 模型
模型 = xgb.XGBClassifier(objective=“multi:softprob”, random_state=42)
model.fit(X_train, y_train)

然后我尝试绘制形状值：
# 创建一个 SHAP TreeExplainer
解释器 = shap.TreeExplainer(模型)

# 计算测试集的SHAP值
shap_values = 解释器.shap_values(X_test)

# 尝试绘制所有类的摘要
shap.summary_plot（shap_values，X_test，plot_type =“酒吧”）

我得到了这个交互图：

我在 此帖子：
shap.summary_plot(shap_values[:,:,0], X_test,plot_type=&quot;bar&quot;)

它给出了 0 类的正常条形图：

然后我可以对类 1、2、3 等执行相同的操作。
问题是，如何为所有类别制作汇总图？即，显示某个特征对每个类的贡献的单个图？]]></description>
      <guid>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</guid>
      <pubDate>Sat, 27 Apr 2024 19:02:16 GMT</pubDate>
    </item>
    <item>
      <title>在一个巨大的向量上执行余弦相似度时出现内存错误</title>
      <link>https://stackoverflow.com/questions/73629817/got-memory-error-while-performing-cosine-similarity-on-a-huge-vector</link>
      <description><![CDATA[我试图使用词袋模型构建一个基于内容的推荐系统。我接下来的教程使用 sklearn 库中大小为 (4000,5000) 的向量的余弦相似度，其中 4000 是数据集中的行数，5000 是特征数。
从 sklearn.feature_extraction.text 导入 CountVectorizer
cv = CountVectorizer(max_features=5000, stop_words=&#39;english&#39;)
向量 = cv.fit_transform(new_df[&#39;tags&#39;]).toarray()
// 这里 new_df 是数据帧，new_df[tags] 包含将执行推荐的所有标签（例如：位置、流派）

但是当我尝试在另一个具有 94955 行的数据集上实现余弦相似度（这会产生大小为 (94955, 5000) 的向量时，我收到以下错误
MemoryError：无法为形状为 (94955, 94955) 和数据类型 float64 的数组分配 67.2 GiB

上线了
相似度= cosine_similarity（向量，dense_output=False）
有没有办法实现余弦相似度的批处理，以便我可以克服这个问题，或者我应该更改算法吗？]]></description>
      <guid>https://stackoverflow.com/questions/73629817/got-memory-error-while-performing-cosine-similarity-on-a-huge-vector</guid>
      <pubDate>Wed, 07 Sep 2022 03:33:45 GMT</pubDate>
    </item>
    <item>
      <title>从训练集或测试集计算残差值</title>
      <link>https://stackoverflow.com/questions/56552458/calculate-residual-values-from-trainfset-or-test-set</link>
      <description><![CDATA[我想执行残差分析，并且我知道残差等于观测值减去预测值。但我不知道应该计算训练集还是测试集的残差？
我应该使用这个：
导入 statsmodels.api 作为 sm
# 进行预测
lm = sm.OLS(y_train,X_train).fit()

y_pred = lm.predict(X_train)
残差 = y_train - y_pred.to_frame(&#39;价格&#39;)

或者这个：
导入 statsmodels.api 作为 sm
# 进行预测
lm = sm.OLS(y_train,X_train).fit()

y_pred = lm.predict(X_test)
resid = y_test- y_pred.to_frame(&#39;价格&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/56552458/calculate-residual-values-from-trainfset-or-test-set</guid>
      <pubDate>Tue, 11 Jun 2019 22:33:05 GMT</pubDate>
    </item>
    <item>
      <title>比 tf/idf 和余弦相似度更好的文本文档聚类？</title>
      <link>https://stackoverflow.com/questions/17537722/better-text-documents-clustering-than-tf-idf-and-cosine-similarity</link>
      <description><![CDATA[我正在尝试对 Twitter 流进行聚类。我想将每条推文放入讨论同一主题的集群中。我尝试使用具有 tf/idf 和余弦相似度的在线聚类算法对流进行聚类，但我发现结果非常糟糕。
使用 tf/idf 的主要缺点是它会聚集关键字相似的文档，因此只能识别几乎相同的文档。例如，考虑以下句子：
1- Stackoverflow 网站是一个不错的地方。
2- Stackoverflow 是一个网站。
前面的两个句子可能会以合理的阈值聚集在一起，因为它们共享很多关键字。但现在考虑以下两句话：
1- Stackoverflow 网站是一个不错的地方。
2- 我定期访问 Stackoverflow。
现在，通过使用 tf/idf，聚类算法将严重失败，因为即使它们谈论同一主题，它们也只共享一个关键字。
我的问题：是否有更好的技术来聚类文档？]]></description>
      <guid>https://stackoverflow.com/questions/17537722/better-text-documents-clustering-than-tf-idf-and-cosine-similarity</guid>
      <pubDate>Mon, 08 Jul 2013 23:40:57 GMT</pubDate>
    </item>
    </channel>
</rss>