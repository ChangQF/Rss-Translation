<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 17 Sep 2024 15:17:55 GMT</lastBuildDate>
    <item>
      <title>多输出分类 - 输出彼此之间没有相关性[关闭]</title>
      <link>https://stackoverflow.com/questions/78993861/multi-output-classification-outputs-not-making-sense-relative-to-one-another</link>
      <description><![CDATA[假设我有一个多输出二元分类问题，但类别是相关的。
即，如果一个类别 = 1，则另一个类别必须 = 1。
标准是具有 2 个输出层，每个输出层有 1 个输出单元，并使用 S 型激活函数。
例如，假设我试图预测在马拉松比赛中我是否会跨越 10 公里和 15 公里的标记。
我如何确保网络知道，如果我越过了 15 公里的标记，那么我也越过了 10 公里的标记？我如何使概率保持一致？ P(跨越 10 公里) &gt;= P(跨越 15 公里)。
网络是否应该自然地从数据集中学习（即，如果未跨越 10 公里，就不可能跨越 15 公里标记）？]]></description>
      <guid>https://stackoverflow.com/questions/78993861/multi-output-classification-outputs-not-making-sense-relative-to-one-another</guid>
      <pubDate>Tue, 17 Sep 2024 11:35:03 GMT</pubDate>
    </item>
    <item>
      <title>如何让我的 GPU 在笔记本电脑上充分发挥其潜力？[关闭]</title>
      <link>https://stackoverflow.com/questions/78993633/how-to-make-my-gpu-work-at-full-potential-on-a-laptop</link>
      <description><![CDATA[在此处输入图片描述
我有一台配备两个 GPU 的笔记本电脑
英特尔和英伟达
我从 github 下载了一个 AI 模型的存储库来创建图像
当我运行它时，我注意到我的 GPU 几乎不工作
然后我意识到它几乎发生在所有事情上，所有负载都落在 CPU 上
我寻找的让 GPU 工作的几乎所有方法都没有奏效
我尝试将计算机性能更改为高
也尝试更改英伟达控制面板设置]]></description>
      <guid>https://stackoverflow.com/questions/78993633/how-to-make-my-gpu-work-at-full-potential-on-a-laptop</guid>
      <pubDate>Tue, 17 Sep 2024 10:28:11 GMT</pubDate>
    </item>
    <item>
      <title>PINN 没有学习 [关闭]</title>
      <link>https://stackoverflow.com/questions/78993577/pinn-is-not-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78993577/pinn-is-not-learning</guid>
      <pubDate>Tue, 17 Sep 2024 10:11:13 GMT</pubDate>
    </item>
    <item>
      <title>混淆矩阵中的空列</title>
      <link>https://stackoverflow.com/questions/78993181/empty-columns-in-confusion-matrix</link>
      <description><![CDATA[我正在对预处理的 APTOS 2019 数据集进行疾病分级训练，我的混淆矩阵的最后两列每次都恒定为零。数据分布如下：

类别 0：1805 幅图像
类别 1：370 幅图像
类别 3：999 幅图像
类别 4：193 幅图像
类别 5：295 幅图像

以下是 70 个时期的结果：
测试准确率=77%

混淆矩阵：
[[258 3 1 0 0]
[ 6 38 16 0 0]
[ 13 13 130 0 0]
[ 0 7 22 0 0]
[ 4 9 30 0 0]]

测试集的类别准确率模型：
[98.47328244 63.33333333 83.33333333 0. 0.]

每个类别的敏感度（召回率）：
[0.98473282 0.63333333 0.83333333 0. 0.]

每个类别的特异性：
[0.98513011 0.95416667 0.92592593 0.94727273 0.92181818]

我尝试应用类别权重、分层 k 倍交叉验证，但没有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78993181/empty-columns-in-confusion-matrix</guid>
      <pubDate>Tue, 17 Sep 2024 08:31:41 GMT</pubDate>
    </item>
    <item>
      <title>Nougat OCR 对页面进行部分检测时出现问题</title>
      <link>https://stackoverflow.com/questions/78992893/issue-with-partial-detection-of-pages-by-nougat-ocr</link>
      <description><![CDATA[我正在使用 Nougat OCR 模型将数学方程式转换为 latex 格式。我遇到的问题是，有些页面无法被 Nougat OCR 模型完全检测到。在许多情况下，页面上只有一半的内容被检测到，而其余部分则被跳过。但是，对于其他页面，检测工作完全正常。
重现步骤：

将 PDF 转换为图像（每页一张图像）。
使用 Nougat OCR 模型单独处理每张图像。
观察到某些页面被部分检测到，而其他页面则被正确处理。

（这是我用于推理的笔记本）
示例结果：
第一页
## 答案 (LC2020 HL, P2):

1.\(0\); \(A\)、\(B\) 和 \(C\) 共线 [0, 4, 7, 11, 15]
2. \(33\cdot 435^{\circ}\)[0, 4, 7, 11, 15]
3. \(9\)[0, 4, 7, 11, 15]
4. \(x^{2}+y^{2}+4x-21=0\)、\(x^{2}+y^{2}-8x-9=0\)[0, 4, 7, 11, 15]
5. \(6\cdot 44\) m [0, 4, 7, 11, 15]
6. \(k=9\)[0, 4, 7, 11, 15]
7. \(\frac{5\pi}{3}\), \(

第二页

## 答案 (LC 2019 HL, P2):

1. (i) \(\frac{48}{95}\) [**0, 4, 7, 10**], (ii) \(\frac{88}{969}\) [**0, 4, 5, 8, 10**]
2. 1400 [**0, 4, 7, 10**]
3. 显示 [**0, 4, 7, 10**]
4. (i) \(mx-y-6m=0\) [**0, 2, 5**], (ii) \(P\bigg{(}\frac{18m+25}{3m+4}\), \(\frac{m}{3m+4}\bigg{)}\) [**0, 4, 7, 11, 15**]

1. \(k=-4\), 10 [**0, 4, 7, 10**]
2. \(s\): \(x^{2}+y^{2}-2x-2y+1=0\) [**0, 5, 10, 15, 20**]
3. 显示 [**0, 2, 3, 5**]
4. \(\frac{1}{3}\) [**0, 5, 10, 15, 20**]
5. 构造 [**0, 4, 7, 11, 15**]
6. \(30^{\circ

预期行为：OCR 模型应一致地检测每个页面的所有部分，而不是仅检测部分内容。
问题：是否需要进行任何预处理以确保完整的页面检测？或者在 Nougat OCR 中是否有特定参数需要调整以改善结果？]]></description>
      <guid>https://stackoverflow.com/questions/78992893/issue-with-partial-detection-of-pages-by-nougat-ocr</guid>
      <pubDate>Tue, 17 Sep 2024 07:12:30 GMT</pubDate>
    </item>
    <item>
      <title>从手绘图像中检测线条</title>
      <link>https://stackoverflow.com/questions/78992773/detecting-lines-from-hand-drawn-images</link>
      <description><![CDATA[单击此处查看图片
我正在开展一个图像处理项目，需要从测量图中检测线条。如果能帮助我完成这项任务，我将不胜感激。
关于图片
该图片是 75-80 年前绘制的村庄手绘测量图。仔细观察后，您会注意到一些手写文字以另一种语言表示 F 线的测量值。图片中有三种不同类型的线：

F 线：勾勒出地块轮廓的场线。

B 线：基线，图片中最重要的线。这些线始终是直的，没有弯曲。

G 线：垂直于基线（B 线）的投影线。


问题陈述
我的目标是检测这些线并将其分别标记为 F、B 和 G 线。作为参考，我手动标记了一个示例图像以便更好地理解。我有 100-150 张未标记的图像需要以编程方式进行标记和分类。（我计划使用这些标记图像来训练用于线检测的深度学习模型。）我面临的一个重大挑战是线条之间的间隙，这导致程序错误地将单条线识别为多条线。
我迄今为止尝试过的方法

霍夫线：我使用了霍夫线，但结果不一致。虽然它对某些图像效果很好，但在更复杂的图像上表现不佳，检测到不存在的线条。我尝试调整 rho、theta、阈值和最大线间隙等参数，但结果仍然不令人满意。

Pillow： 我还尝试使用 Pillow 跟踪线条，它可以跟踪图像中的所有内容，包括文本和形状。这导致我偏离了目标，因为它检测到间隙并将一条线视为多条线。

]]></description>
      <guid>https://stackoverflow.com/questions/78992773/detecting-lines-from-hand-drawn-images</guid>
      <pubDate>Tue, 17 Sep 2024 06:29:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 MobileNetV2 模型来处理灰度图像</title>
      <link>https://stackoverflow.com/questions/78992679/how-do-i-use-mobilenetv2-model-to-use-gray-scale-images</link>
      <description><![CDATA[我使用 MobileNetV2 模型作为基础模型，但我添加了 5 个新的可训练层，并在两个新类别上重新训练它：猴痘阳性和猴痘阴性。猴痘阴性图像文件夹包含不同的皮肤感染，这些感染看起来与猴痘相似，但感染方式与水痘类似。我有一个包含彩色图像的数据集，但我将它们转换为灰度（下面的代码）。
当我尝试运行模型时，我遇到了以下问题：
层“Conv1”的输入 0 与层不兼容：预期输入形状的轴 -1 具有值 3，但收到的输入形状为（None、200、200、1）

我知道我必须欺骗模型，让其认为 1 的值是 3，但我不确定如何做。我正在使用 imagenet 作为权重。
从 tensorflow.keras.preprocessing 导入图像作为 IMAGE
导入 numpy 作为 np
导入 cv2
导入 os
os.environ[&quot;CUDA DEVICE ORDER&quot;]=&quot;PCI BUS ID&quot;
os.environ[&quot;CUDA VISIBLE DEVICES&quot;]=&quot;0&quot;

从 tensorflow.keras 导入模型
从 tensorflow.keras.applications.mobilenet_v2 导入 MobileNetV2、preprocess_input
从 tensorflow.keras.preprocessing.image 导入 ImageDataGenerator
从 tensorflow.keras.layers 导入 Dense、GlobalAveragePooling2D
从 tensorflow.keras.optimizers 导入 Adam
从 tensorflow.keras.preprocessing 导入图像
导入 matplotlib.pyplot 作为 plt

导入 tensorflow 作为 tf
从 PIL 导入图像
从 google.colab.patches 导入 cv2_imshow

!pip3 安装 tensorflowjs

导入 tensorflowjs 作为 tfjs

train = ImageDataGenerator(rescale = 1/255)
test = ImageDataGenerator（重新缩放 = 1/255）
val = ImageDataGenerator（重新缩放 = 1/255）

training_set = train.flow_from_directory（&quot;/content/drive/MyDrive/mpox_data/Train&quot;,
target_size=(200,200),
batch_size = 15,
class_mode = &quot;categorical&quot;,
color_mode=&#39;rgb&#39;
)

testing_set = test.flow_from_directory（&quot;/content/drive/MyDrive/mpox_data/Test&quot;,
target_size=(200,200),
batch_size = 15,
class_mode = &quot;categorical&quot;,
color_mode=&#39;rgb&#39;
)
validation_set = val.flow_from_directory(&quot;/content/drive/MyDrive/mpox_data/Val&quot;,
target_size=(200,200),
batch_size=15,
class_mode = &quot;categorical&quot;,
color_mode=&#39;rgb&#39;
)

x, y = training_set[0]
a, b = testing_set[0]
d, c = validation_set[0]

base_model = MobileNetV2(weights = &quot;imagenet&quot;, include_top = False)

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(42,activation=&quot;relu&quot;)(x)
x = Dense(64,activation = &quot;relu&quot;)(x)
x = Dense(32,激活=&quot;relu&quot;)(x)
preds = Dense(2, 激活 = &quot;sigmoid&quot;)(x)

模型 = 模型(输入 = base_model.input, 输出 = preds)

epochs = 5
优化器 = Adam(learning_rate = 0.0003)
模型.编译(损失 = &quot;binary_crossentropy&quot;, 优化器 = 优化器, 指标 = [&quot;Accuracy&quot;])
模型.fit(training_set, 验证数据 = 验证集, epochs = epochs, shuffle=True)

我尝试在模型中使用灰度图像，希望它能成功运行，但它给了我上面提到的错误。
为什么我的程序无法运行，我该如何修复它，让模型继续在灰度上进行自我训练图像？]]></description>
      <guid>https://stackoverflow.com/questions/78992679/how-do-i-use-mobilenetv2-model-to-use-gray-scale-images</guid>
      <pubDate>Tue, 17 Sep 2024 05:48:26 GMT</pubDate>
    </item>
    <item>
      <title>对多个相互交织的目标使用反向预测[关闭]</title>
      <link>https://stackoverflow.com/questions/78992262/using-reverse-prediction-for-multiple-intertwined-targets</link>
      <description><![CDATA[我有一个人生阶段预测模型，它根据一组规则为每个潜在的人生阶段分配点数，总点数最高的人生阶段被视为赢家。这种无监督模型在识别样本客户是青少年、单身、夫妻还是有年幼的孩子等方面效果很好。
在每次模型运行结束时，我都会总结结果，以获得每个人生阶段内的客户比例。该模型每三个月运行一次，如果不进行补救，每次的最终比例都会与目标比例相差太大。目前，我使用反复试验来重新平衡比例，通过在每个人生阶段增加或减去少量点数，将边缘客户转移到另一个人生阶段类别。
我想要的是一种自动化方法，可以指定重新校准最终比例所需的点数，以比我的手动方法更轻松（更少的迭代次数）地匹配目标比例。本质上，协调点 (recon_pts) 是模型的输入，预测每个客户的生命阶段是关键输出，同时还有相应的比例 (model_pn)。我希望模型比例最终与目标比例 (target_pn) 相匹配。
一个例子肯定有助于说明我所追求的。请注意，以下是实际观察到的结果，但我不想要使用或输出这些精确数字的工具，而是使用机器学习来更有效地重现我的反复试验方法。
假设起始位置为：

提供者：
life_stage=c(&#39;CHD&#39;, &#39;TNG&#39;, &#39;TWS&#39;, &#39;SGL&#39;, &#39;CPL&#39;, &#39;YGF&#39;, &#39;PTF&#39;, &#39;OLF&#39;, &#39;ENR&#39;),
recon_pts=c(0.215, -0.143, -0.086, 0.024, -0.049, -0.079, -0.14, -0.162, 0.083),
model_pn=c(0.012, 0.087, 0.091, 0.065, 0.113, 0.115, 0.123, 0.122, 0.273),
target_pn=c(0.014, 0.091, 0.095, 0.065, 0.114, 0.114, 0.107, 0.122, 0.277))

CHD 生命阶段比例过低 (1.2%)，低于目标 (1.4%)。在另一个极端，PTF 太高 (12.3%)，因为它高于目标 (10.7%)。
在我的手动方法下，我选择将 CHD 的 recon_pts 从 0.215 增加到 0.22，这样我就能在这个生命阶段获得更多客户。同时，我还将 PTF 的分数从 -0.14 减少到 -0.17，这样分配到这里的客户就会减少。
然后我得到了这些结果，所有比例都经过了调整。 CHD 比例更接近目标但仍然太低，PTF 现在太低，因为比例已低于目标，其他所有方面也都需要注意：

因此，在下一次迭代中，我可能会选择增加 CHD 的 recon_pts，增加 PTF 的点数并减少 YFG 的点数。然后它就以一种痛苦而缓慢的方式继续下去了！
对我来说，这看起来像是机器学习的理想候选者，其中过程可以学习如何调整 recon_pts，以便 model_pn 最终匹配每个生命阶段的 target_pn。
请问如何在 R 中有效地编码？]]></description>
      <guid>https://stackoverflow.com/questions/78992262/using-reverse-prediction-for-multiple-intertwined-targets</guid>
      <pubDate>Tue, 17 Sep 2024 01:29:30 GMT</pubDate>
    </item>
    <item>
      <title>将成分/特征分成标有“0”或“1”的单独列</title>
      <link>https://stackoverflow.com/questions/78991472/separate-a-ingredients-feature-into-separate-columns-that-is-marked-with-0-or</link>
      <description><![CDATA[我正在查看一些食物浪费数据，其中包括食物成分等大量数据。我正在尝试对数据进行一些机器学习，但在准备过程中遇到了一些麻烦。
示例
我能够将所有单个成分分离到各自的列中，但当该成分在成分列表/列中时，我很难将其标记为 1。
示例 2
我一直在尝试逐行查看列名是否在成分列中，然后将其更改为 1。我根本没有接近目标，但这是我目前尝试的灾难。还尝试了 get_dummies 和其他一些方法。
有没有更简单的方法？
def xs_os(df, Ingredients_Column):
df2 = df.drop(&quot;Ingredients&quot;, axis = 0) 
for z in df:
for x in list(df2.columns.values):
if x in str(Ingredients_Column):
df.at[z, df[x]] = 1
xs_os(df, df[&#39;Ingredients&#39;])
df.head()
]]></description>
      <guid>https://stackoverflow.com/questions/78991472/separate-a-ingredients-feature-into-separate-columns-that-is-marked-with-0-or</guid>
      <pubDate>Mon, 16 Sep 2024 19:07:49 GMT</pubDate>
    </item>
    <item>
      <title>Keras-rl2 错误与 Tensorflow 的兼容性</title>
      <link>https://stackoverflow.com/questions/78340927/keras-rl2-error-compability-with-tensorflow</link>
      <description><![CDATA[我目前在使用 keras-rl2 和 tensorflow 时遇到了一个问题，我不知道为什么，我只是在互联网上搜索了 keras-rl2、tensorflow 和 keras 文档，但没有找到解决方案。
目前，我想将 keras-rl2 与最新版本的 tensorflow 2.16.1 和 keras 3 一起使用，使用时出现了这样的错误
from rl.agents import DKQAgent

ModuleNotFoundError Traceback（最近一次调用最后一次）
Cell In[37]，第 1 行
----&gt; 1 导入 rl.agents
3 print(&quot;RL 代理库版本：&quot;, rl.agents.__version__)

文件 D:\Anaconda\Lib\site-packages\rl\agents\__init__.py:2
1 来自 .dqn 导入 DQNAgent、NAFAgent、ContinuousDQNAgent
----&gt; 2 来自 .ddpg 导入 DDPGAgent
3 来自 .cem 导入 CEMAgent
4 来自 .sarsa 导入 SarsaAgent、SARSAAgent

文件 D:\Anaconda\Lib\site-packages\rl\agents\dqn.py:8
5 来自 tensorflow.keras.layers 导入 Lambda、Input、Layer、Dense
7 来自 rl.core 导入 Agent
----&gt; 8 从 rl.policy 导入 EpsGreedyQPolicy、GreedyQPolicy
9 从 rl.util 导入 *
12 def mean_q(y_true, y_pred):

文件 D:\Anaconda\Lib\site-packages\rl\core.py:8
4 导入 numpy 作为 np
5 从 tensorflow.keras.callbacks 导入 History
7 从 rl.callbacks 导入 (
----&gt; 8 CallbackList,
9 TestLogger,
10 TrainEpisodeLogger,
11 TrainIntervalLogger,
12 Visualizer
13 )
16 类 Agent:
17 &quot;&quot;&quot;所有已实现代理的抽象基类。
18 
19 每个代理通过首先观察
(...)
37 处理器（“Processor”实例）与环境进行交互：有关详细信息，请参阅 [Processor](#processor)。
38 &quot;&quot;&quot;

文件 D:\Anaconda\Lib\site-packages\rl\callbacks.py:12
9 from tensorflow.python.keras.callbacks import Callback as KerasCallback, CallbackList as KerasCallbackList
10 from tensorflow.python.keras.utils.generic_utils import Progbar
---&gt; 12 class Callback(KerasCallback):
13 def _set_env(self, env):
14 self.env = env

ModuleNotFoundError: 没有名为“keras.utils.generic_utils”的模块

当我以为我只需要将其降级到某个版本（如 2.13.0 和 keras 2.13.0）时，它仍然会出错
-------------------------------------------------------------------------------------------
ImportError Traceback（最近一次调用最后一次）
Cell In[18]，第 1 行
----&gt; 1 from rl.agents.dqn import DQNAgent

File D:\Anaconda\envs\AI\Lib\site-packages\rl\agents\__init__.py:1
----&gt; 1 从 .dqn 导入 DQNAgent、NAFAgent、ContinuousDQNAgent
2 从 .ddpg 导入 DDPGAgent
3 从 .cem 导入 CEMAgent

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\agents\dqn.py:7
4 从 tensorflow.keras.models 导入 Model
5 从 tensorflow.keras.layers 导入 Lambda、Input、Layer、Dense
----&gt; 7 从 rl.core 导入 Agent
8 从 rl.policy 导入 EpsGreedyQPolicy、GreedyQPolicy
9 从 rl.util 导入 *

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\core.py:7
4 将 numpy 导入为 np
5 从 tensorflow.keras.callbacks 导入 History
----&gt; 7 from rl.callbacks import (
8 CallbackList,
9 TestLogger,
10 TrainEpisodeLogger,
11 TrainIntervalLogger,
12 Visualizer
13 )
16 class Agent:
17 &quot;&quot;&quot;所有已实现代理的抽象基类。
18 
19 每个代理通过首先观察
(...) 来与环境（由 `Env` 类定义）交互
37 处理器（`Processor` 实例）：有关详细信息，请参阅 [Processor](#processor)。
38 &quot;&quot;&quot;

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\callbacks.py:8
6 import numpy as np
7 import tensorflow as tf
----&gt; 8 从 tensorflow.keras 导入 __version__ 作为 KERAS_VERSION
9 从 tensorflow.python.keras.callbacks 导入 Callback 作为 KerasCallback，CallbackList 作为 KerasCallbackList
10 从 tensorflow.python.keras.utils.generic_utils 导入 Progbar

ImportError：无法从“tensorflow.keras”导入名称“__version__”（D:\Anaconda\envs\AI\Lib\site-packages\keras\api\_v2\keras\__init__.py）

有人能给我解释或解决方案为什么它总是错误吗？
感谢您的关心]]></description>
      <guid>https://stackoverflow.com/questions/78340927/keras-rl2-error-compability-with-tensorflow</guid>
      <pubDate>Wed, 17 Apr 2024 12:20:33 GMT</pubDate>
    </item>
    <item>
      <title>我正在使用 MNIST 数据集和 jupyter notebook 做一个机器学习项目[关闭]</title>
      <link>https://stackoverflow.com/questions/68442936/im-doing-a-machine-learning-project-using-mnist-data-set-with-jupyter-notebook</link>
      <description><![CDATA[我对机器学习还很陌生，我正在 Jupyter 笔记本中编写 Python 代码，用于对 MNIST 数据集执行手写识别。但是当我尝试运行笔记本时，出现以下错误。有人能帮我找出原因吗？x_train 数组是一个 (70000,784) 数组。
~\AppData\Local\Temp/ipykernel_6700/1983129579.py in &lt;module&gt;
1 shuffle_index = np.random.permutation(6000)
----&gt; 2 x_train, y_train = x_train[shuffle_index], y_train[shuffle_index]

c:\users\hp\appdata\local\programs\python\python39\lib\site-packages\pandas\core\frame.py 在 __getitem__(self, key) 中
3459 if is_iterator(key):
3460 key = list(key)
-&gt; 3461 indexer = self.loc._get_listlike_indexer(key, axis=1)[1]
3462 
3463 # take() 不接受布尔索引器

c:\users\hp\appdata\local\programs\python\python39\lib\site-packages\pandas\core\indexing.py in _get_listlike_indexer(self, key, axis)
1312 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr)
1313 
-&gt; 1314 self._validate_read_indexer(keyarr, indexer, axis)
1315 
1316 if needs_i8_conversion(ax.dtype) or isinstance(

c:\users\hp\appdata\local\programs\python\python39\lib\site-packages\pandas\core\indexing.py in _validate_read_indexer(self, key, indexer, axis)
1372 if use_interval_msg:
1373 key = list(key)
-&gt; 1374 raise KeyError(f&quot;[{key}] 中没有一个在 [{axis_name}] 中&quot;)
1375 
1376 not_found = list(ensure_index(key)[missing_mask.nonzero()[0]].unique())

KeyError: &quot;没有一个[Int64Index([4112, 3293, 403, 2579, 942, 987, 3778, 3831, 3053, 3412,\n ...\n 642, 2789, 3410, 3946, 5883, 3439, 2029, 2776, 4626, 497],\n dtype=&#39;int64&#39;, length=6000)] 位于 [columns]&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/68442936/im-doing-a-machine-learning-project-using-mnist-data-set-with-jupyter-notebook</guid>
      <pubDate>Mon, 19 Jul 2021 15:14:58 GMT</pubDate>
    </item>
    <item>
      <title>如果我使用网格搜索简历，是否需要做简历？</title>
      <link>https://stackoverflow.com/questions/66061499/is-it-required-to-do-cv-if-i-use-grid-search-cv</link>
      <description><![CDATA[我在 ML 中使用网格搜索来超调我的算法。我有一个疑问，如果我使用网格搜索 cv，是否必须稍后使用交叉验证？
因为网格搜索也进行交叉验证，所以我认为使用网格搜索 cv 就足够了。我是否正确，否则请纠正我]]></description>
      <guid>https://stackoverflow.com/questions/66061499/is-it-required-to-do-cv-if-i-use-grid-search-cv</guid>
      <pubDate>Fri, 05 Feb 2021 10:22:42 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：分类指标无法处理多类别和多标签指标目标的混合</title>
      <link>https://stackoverflow.com/questions/56496708/valueerror-classification-metrics-cant-handle-a-mix-of-multiclass-and-multilab</link>
      <description><![CDATA[我有一个多类标记文本分类问题，有 2000 个不同的标签。使用带有 Glove Embedding 的 LSTM 进行分类。

目标变量的标签编码器
带有 Embedd 层的 LSTM 层
错误度量是 F2 分数

LabelEncoded 目标变量：
le = LabelEncoder() 
le.fit(y)
train_y = le.transform(y_train)
test_y = le.transform(y_test)

带有 Glove Embeddings 的 LSTM 网络如下所示
np.random.seed(seed)
K.clear_session()
model = Sequential()
model.add(Embedding(max_features, embed_dim, input_length = X_train.shape[1],
weights=[embedding_matrix]))#,trainable=False
model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(num_classes,activation=&#39;softmax&#39;))
model.compile(optimizer=&#39;rmsprop&#39;,loss=&#39;sparse_categorical_crossentropy&#39;)
print(model.summary())

我的错误指标是 F1 分数。我为错误度量构建了以下函数
class Metrics(Callback):
def on_train_begin(self, logs={}):
self.val_f1s = []
self.val_recalls = []
self.val_precisions = []

def on_epoch_end(self, epoch, logs={}):
val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()
val_targ = self.validation_data[1]
_val_f1 = f1_score(val_targ, val_predict)
_val_recall = recall_score(val_targ, val_predict)
_val_precision = precision_score(val_targ, val_predict)
self.val_f1s.append(_val_f1)
self.val_recalls.append(_val_recall)
self.val_precisions.append(_val_precision)
print(&quot;— val_f1: %f — val_precision: %f — val_recall %f&quot; % (_val_f1, _val_precision, _val_recall))
return

metrics = Metrics()

##模型拟合是
model.fit(X_train, train_y, validation_data=(X_test, test_y),epochs=10, batch_size=64, callbacks=[metrics])

第一个 epoch 后出现以下错误：
ValueError：分类指标无法处理多类和连续多输出目标的混合

在哪里我的代码有错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/56496708/valueerror-classification-metrics-cant-handle-a-mix-of-multiclass-and-multilab</guid>
      <pubDate>Fri, 07 Jun 2019 14:55:37 GMT</pubDate>
    </item>
    <item>
      <title>图像颜色和纹理的均匀性</title>
      <link>https://stackoverflow.com/questions/54166908/uniformity-of-color-and-texture-in-image</link>
      <description><![CDATA[我是深度学习领域的新手，在确定两幅图像是否具有均匀的颜色和纹理方面遇到了问题。例如，我有一个 
主图像 -

现在，对于这张图片，我需要确定以下图片是否具有均匀的纹理和颜色分布 -
图像 1 -
 
图像 2 -

图片 3 - 

我需要开发一种算法，用主图像评估这 3 张图像。该算法应该批准图像 1，并拒绝图像 2（因为它的颜色），拒绝图像 3（因为它的颜色和纹理均匀性）。
我解决这个问题的方法是直接分析图像以进行纹理检测。我发现局部二元模式方法在所有纹理识别方法中表现不错（但我不确定）。我在 python 中使用 opencv 实现了它的 skimage 并发现该方法有效。 
from skimage import feature
import numpy as np
import cv2
import matplotlib.pyplot as plt

class LocalBinaryPatterns:
def __init__(self, numPoints, radius):
# 存储点数和半径
self.numPoints = numPoints
self.radius = radius

def describe(self, image, eps=1e-7):
# 计算图像的局部二元模式表示
# 然后使用 LBP 表示
# 构建模式直方图
lbp = feature.local_binary_pattern(image, self.numPoints,
self.radius, method=&quot;uniform&quot;)
(hist, _) = np.histogram(lbp.ravel(),
bins=np.arange(0, self.numPoints + 3),
range=(0, self.numPoints + 2))

# 标准化直方图
hist = hist.astype(&quot;float&quot;)
hist /= (hist.sum() + eps)

# 返回局部二值模式的直方图
return hist

desc = LocalBinaryPatterns(24, 8)

image = cv2.imread(&quot;main.png&quot;)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
hist = desc.describe(gray)

plt.plot(hist,&#39;b-&#39;)
plt.ylabel(&#39;Feature Vectors&#39;)
plt.show()

它检测了特征并制作了特征向量的直方图。我使用 matplotlib 绘制了直方图，清楚地发现图像 1 和图像 2 的纹理特征与主图像几乎相似。并且图像 3 的纹理特征不匹配。
然后我开始分析图像的颜色。我使用 opencv 绘制了颜色直方图 - 
import cv2
from matplotlib import pyplot as plt

def draw_image_histogram(image, channels, color=&#39;k&#39;):
hist = cv2.calcHist([image], channels, None, [256], [0, 256])
plt.plot(hist, color=color)
plt.xlim([0, 256])

def show_color_histogram(image):
for i, col in enumerate([&#39;b&#39;, &#39;g&#39;, &#39;r&#39;]):
draw_image_histogram(image, [i], color=col)
plt.show()

show_color_histogram(cv2.imread(&quot;test1.jpg&quot;))

我发现图像 1 的颜色直方图与主图像匹配。图像 2 和 3 的颜色直方图不匹配。这样我就能发现图像 1 匹配，而图像 2 和 3 不匹配。
但是，这是一种非常简单的方法，我不知道它会匹配多少假阳性。此外，我不知道这个问题的解决方法是否是最好的。
我也希望通过像 CNN 这样的单一而强大的算法来完成此操作（但计算成本不应太高）。但我没有使用 CNN 的经验。那么我应该用主图像训练 CNN 吗？请为我指明正确的方向。我也遇到了 LBCNN，它们能解决这个问题吗？还有其他更好的方法吗？
非常感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/54166908/uniformity-of-color-and-texture-in-image</guid>
      <pubDate>Sun, 13 Jan 2019 07:30:49 GMT</pubDate>
    </item>
    <item>
      <title>如何有条件地为张量赋值[损失函数的掩蔽]？</title>
      <link>https://stackoverflow.com/questions/48510741/how-to-conditionally-assign-values-to-tensor-masking-for-loss-function</link>
      <description><![CDATA[我想创建一个 L2 损失函数，忽略标签值为 0 的值（=&gt; 像素）。张量 batch[1] 包含标签，而 output 是净输出的张量，两者的形状均为 (None,300,300,1)。
labels_mask = tf.identity(batch[1])
labels_mask[labels_mask &gt; 0] = 1
loss = tf.reduce_sum(tf.square((output-batch[1])*labels_mask))/tf.reduce_sum(labels_mask)

我当前的代码产生 TypeError: &#39;Tensor&#39; object does not support item assignment（在第二行）。 tensorflow 中如何实现这个？我还尝试使用 tf.reduce_sum(labels_mask) 来标准化损失，希望它能像这样工作。]]></description>
      <guid>https://stackoverflow.com/questions/48510741/how-to-conditionally-assign-values-to-tensor-masking-for-loss-function</guid>
      <pubDate>Mon, 29 Jan 2018 22:03:51 GMT</pubDate>
    </item>
    </channel>
</rss>