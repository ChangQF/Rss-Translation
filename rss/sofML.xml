<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Thu, 20 Mar 2025 12:34:03 GMT</lastBuildDate>
    <item>
      <title>torch_mlir.com当前是官方Pytorch还是Torch-Mlir API的一部分？</title>
      <link>https://stackoverflow.com/questions/79522928/is-torch-mlir-compile-currently-part-of-the-official-pytorch-or-torch-mlir-api</link>
      <description><![CDATA[我已经看到了 torch_mlir.compile 来自几种AI工具的引用，尤其是来自chatgpt，deepseek等的引用。我还根据方案附加了示例代码。
 导入火炬
导入TORCH_MLIR

＃定义一个简单的pytorch模型
类SimpleModel（Torch.nn.Module）：
    def __init __（自我）：
        超级（SimpleModel，self）.__ Init __（）
        self.linear = torch.nn.linear（3，2）

    def向前（self，x）：
        返回self.linear（x）

＃创建模型的实例
model = SimpleModel（）
model.eval（）＃将模型设置为评估模式

＃创建示例输入张量
example_input = torch.randn（1，3）

＃使用火炬 - 摩尔编译模型
mlir_module = torch_mlir.compile（型号，（example_input，），output_type =; torch; quot;）

＃打印MLIR输出
打印（mlir_module）
 
是  torch_mlir.compile 在Pytorch或Torch-Mlir的最新版本中的正式支持功能，还是过时或更名？
我感谢基于API的当前状态的明确答案。]]></description>
      <guid>https://stackoverflow.com/questions/79522928/is-torch-mlir-compile-currently-part-of-the-official-pytorch-or-torch-mlir-api</guid>
      <pubDate>Thu, 20 Mar 2025 12:25:00 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow联合（TFF）中聚合的客户端选择</title>
      <link>https://stackoverflow.com/questions/79522886/client-selection-for-aggregation-in-tensorflow-federated-tff</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79522886/client-selection-for-aggregation-in-tensorflow-federated-tff</guid>
      <pubDate>Thu, 20 Mar 2025 12:12:07 GMT</pubDate>
    </item>
    <item>
      <title>深XDE模型拟合</title>
      <link>https://stackoverflow.com/questions/79522731/deep-xde-model-fit</link>
      <description><![CDATA[我正在尝试使用DEEPXDE在合成数据上训练物理信息的神经网络（PINN）。我的目标是使用简单的葡萄糖模型生成数据，然后在此数据上训练PINN，看看它是否可以恢复模型中使用的参数。
但是，当我训练模型时，拟合很糟糕。这些预测与数据不太匹配，并且损失不如预期。
这是我到目前为止尝试的：

我使用已知的参数生成了合成数据。
我在deepxde中定义了管理方程。
我同时使用了数据丢失和物理损失来训练Pinn。

在使用deepxde为Pinns时是否有人遇到过类似的问题？是否有特定的超参数或培训策略可以有助于改善合适？
 导入DeepXde为DDE
导入numpy作为NP
导入matplotlib.pyplot作为PLT
来自Scipy.Comtegrate Import Odeint
来自Sklearn.metrics导入R2_Score

def单元格（y，t，p）：
    dn = p [0]  -  p [1] *（1 +（y [1] / p [2]）** p [3]） * y [0]
    dc = p [1] *（1 +（y [1] / p [2]）** p [3]） * y [0] -p [4] * y [1]
    返回[DN，DC]

＃仿真参数
times = np.Arange（0，15，0.01）
V，K1，K，N，K2 = 14，1，2，3，4

＃生成合成数据
y = odeint（cell，t = times，y0 = [0，0]，args =（（v，k1，k，n，k2），rtol = 1e-8）

def glycolysy_ode（x，y）：
    y1，y2 = y [：，0：1]，y [：，1：]
    dy1_t = dde.grad.jacobian（y，x，i = 0）
    dy2_t = dde.grad.jacobian（y，x，i = 1）
    
    dn = v -k1 *（1 +（y2 / k）** n） * y1
    dc = k1 *（1 +（y2 / k）** n） * y1 -k2 * y2
    
    返回[DY1_T -DN，DY2_T -DC]

def边界（_，on_initial）：
    返回on_initial

def true_solution（x）：
    idx = np.searchsorted（times，x.flatten（））
    idx = np.clip（idx，0，len（times）-1）＃确保指数保持在范围内
    返回np.hstack（（y [idx，0：1]，y [idx，1：]））

＃直接使用综合数据而无需噪声
noisy_y = y＃没有噪音

geom = dde.Deometry.timedomain（0，15）
ic1 = dde.icbc.ic（Geom，Lambda X：0，边界，组件= 0）
IC2 = dde.icbc.ic（Geom，Lambda X：0，边界，组件= 1）
data = dde.data.pde（Geom，Glycolysis_ode，[IC1，IC2]，35，2，solution = true_solution，num_test = 1500）

layer_size = [1] + [50] * 3 + [2]
激活=“ tanh”
initializer =; glorot制服
net = dde.nn.fnn（layer_size，activation，initializer）

型号= dde.model（数据，网络）
model.compile（&#39;adam＆quort＆quort＆lr = 0.001，量表= [l2相对错误＆quot;]）
损失史，train_state = model.train（迭代= 20000）

＃计算模型的R²得分没有噪音
y_pred = model.predict（times.reshape（-1，1））
r2_y1 = r2_score（noisy_y [：，0]，y_pred [：，0]）
r2_y2 = r2_score（noisy_y [：，1]，y_pred [：，1]）

打印（f6p的f＆quot&#39;r²得分：{r2_y1：.4f}＆quot;）
打印（f16bp的f＆quot&#39;r²得分：{r2_y2：.4f}＆quot;）

＃绘制F6P和F16BP的预测与真实数据
plt.figure（无花果=（10，6））
plt.plot（times，noisy_y [：，0]，&#39;r&#39;，label =&#39;观察到$ f6p（t）$&#39;，lineWidth = 4.0）
plt.plot（times，y_pred [：，0]，&#39;k-&#39;，label =&#39;pinn型号$ f6p（t）$&#39;）
plt.plot（times，noisy_y [：，1]，&#39;b&#39;，label =&#39;观察到$ f16bp（t）$&#39;，lineWidth = 4.0）
plt.plot（times，y_pred [：，1]，&#39;k-&#39;，label =&#39;pinn型号$ f16bp（t）$&#39;）
plt.xlabel（“时间”）
plt.ylabel（“集中度”）
plt.legend（）
plt.show（）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79522731/deep-xde-model-fit</guid>
      <pubDate>Thu, 20 Mar 2025 11:07:49 GMT</pubDate>
    </item>
    <item>
      <title>图像分类器的培训CNN模型[闭合]</title>
      <link>https://stackoverflow.com/questions/79522416/training-cnn-model-for-image-classifier</link>
      <description><![CDATA[我在创建一个模型，可以将艺术分为三类，无论是绘画，数字艺术，雕塑。
我有一个带有2k图像的数据集，现在我被卡住了如何构建好模型
任何人都可以告诉我怎么了，我做错了什么。
我检查了诸如精确度和召回之类的指标，它们超过90％，但准确性滞后（仅24％）。
可能的原因是什么？

我的数据很干净
我有两个目录（培训和验证）
两者都有进一步的子目录（对应 DigitalArt ，绘画和 sculpture 带有等量的样本）

  model = keras。 
    layers.conv2d（32，（3，3），激活=&#39;relu&#39;，input_shape =（256，256，3）），＃这是第一个卷积层具有32个过滤器，使用relu引入非线性性
                             ＃我们以后在所有图层上在第一层中定义所有这些东西，都会自动继承这些道具 
    layers.maxpooling2d（），＃这会降低尺寸，例如图像hieght和width
    layers.conv2d（64，（3，3），激活=&#39;relu&#39;），＃第二层
    layers.maxpooling2d（），
    layers.conv2d（128，（3，3），激活=&#39;relu&#39;），＃第三
    layers.maxpooling2d（），
    layers.flatten（），＃将2D特征地图转换为一个1D，向男性完全连接的层
                             
    layers.dense（128，激活=&#39;relu&#39;），＃完全连接的层 
    层。密度（3，激活=&#39;softmax&#39;）＃3类：绘画，雕塑，数字艺术三神经元作为三个输出 
）））

＃编译模型
model.compile（优化器=&#39;adam&#39;，
              损失=&#39;Sparse_categorical_crossentropy&#39;，
              指标= [&#39;准确性&#39;]）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79522416/training-cnn-model-for-image-classifier</guid>
      <pubDate>Thu, 20 Mar 2025 09:14:52 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法显示训练管道中ML.NET FIT（）功能的训练日志输出？</title>
      <link>https://stackoverflow.com/questions/79521737/is-there-a-way-to-show-the-training-log-output-from-the-ml-net-fit-function-in</link>
      <description><![CDATA[我正在使用Microsoft.ml库中的3.0.1版，我的C＃Winforms对象检测程序。
当我将机器学习模型添加到我的Visual Studio项目中时，在MLModel1.MBConfig页面上训练它。
但是，当我创建培训管道并在程序中调用FIT（）功能时，我希望能够在窗口中看到训练日志，因为培训可能很耗时，我希望能够在进步时看到结果。在进行培训时，如何访问此输出日志？]]></description>
      <guid>https://stackoverflow.com/questions/79521737/is-there-a-way-to-show-the-training-log-output-from-the-ml-net-fit-function-in</guid>
      <pubDate>Thu, 20 Mar 2025 02:07:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么tf.keras不让我通过多个样本权重的字典？</title>
      <link>https://stackoverflow.com/questions/79521352/why-wont-tf-keras-let-me-pass-a-dictionary-of-multiple-sample-weights</link>
      <description><![CDATA[我正在尝试通过单个np。示例的阵列对我的keras模型的两个输出进行了示例阵列，其中一个是对二进制值的置信度度量，其中一个是连续的输出。但是，根据Trackback，我会收到 keyError：0 作为TF.Keras试图使用 Object = Object = Object = Object [_Path] 读取它。代码段中提供了导入，以确保
  def train_model（型号，x_ts_train，x_item_train，y_train_conf，y_train_pct，epochs = 50，batch_size = 32）：
    导入numpy作为NP
    来自sklearn.utils.class_weight导入compute_class_weight

    ＃----确保y_train_conf是整数（0或1）----＃
    y_train_conf = np.asarray（y_train_conf）.astype（int）

    ＃----计算二进制分类的每类权重----＃
    unique_classes = np.unique（y_train_conf.ravel（））
    class_weight_dict = {0：1.0，1：1.0}＃默认权重
    如果len（unique_classes）== 2：＃确保存在0和1
        class_weights = compute_class_weight（class_weight =&#39;balanced&#39;，class = unique_classes，y = y__train_conf.ravel（））
        class_weight_dict = {int（unique_classes [i]）：class_weights [i] for in range（len（simolor_classes））}}

    ＃----将类权重转换为按样本权重（匹配y_train_conf形状）----＃
   sample_weights_conf = np.array（[class_weight_dict [label] for y_train_conf.ravel（））
   sample_weights_conf = sample_weights_conf.reshape（y_train_conf.shape）＃现在形状为（84，5）

   ＃----计算连续尖峰百分比的按样本重量----＃
   y_train_pct = np.Asarray（y_train_pct）
   sample_weights_pct = np.ones_like（y_train_pct）＃默认权重= 1

   nonzero_mask = y_train_pct＆gt; 0
   如果np.any（nonzero_mask）：
       scaling_factor = np.sum（nonzero_mask） / y_train_pct.size
       sample_weights_pct [nonzero_mask] = 1 / max（scaling_factor，1e-6）
   print（sample_weights_conf.shape，sample_weights_pct.shape，y_train_conf.shape，y_train_pct.shape.shape，flush = true）

   ＃sample_weights_binary = np.mean（sample_weights_conf，axis = 1）
   ＃sample_weights_continous = np.mean（sample_weights_pct，axis = 1）

   ＃print（sample_weights_continous.shape，sample_weights_binary.shape，flush = true）
   ＃----火车模型----＃
   历史= model.fit（
       {ts_input＆quot＆quot; x_ts_train，＆quot; item_input＆quot＆quot; x_item_train}，
       {&#39;output_binary＆quot;：y_train_conf，＆quort&#39;output_continouul＆quot;：y_train_pct}，
       时代= epochs，
       batch_size = batch_size，
       验证_split = 0.1，
       详细= 2，
       sample_weight = {&#39;output_binary&#39;：sample_weights_conf，&#39;output_continuul&#39;：sample_weights_pct}＃单独通过
   ）

   返回历史
 
我希望该模型可以毫无问题地将样品权重采用，并试图将它们作为列表传递，将它们作为一个阵列，这是两者的平均值，并试图给出y_train，x_train和sample_weaights作为阵列，所有这些阵列都给了我多种错误，但仍然没有给出一个错误的结果。我的模型的输出定义如下：
  output_binary = dense（num_binary_targets，activation =&#39;sigmoid&#39;，name =＆quort; output_binary＆quot;）（dense_out）     
output_continouul = dense（num_continuun_targets，activation =&#39;linear&#39;，name =＆quot; output_continuul＆quort;）（dense_out）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79521352/why-wont-tf-keras-let-me-pass-a-dictionary-of-multiple-sample-weights</guid>
      <pubDate>Wed, 19 Mar 2025 20:47:01 GMT</pubDate>
    </item>
    <item>
      <title>需要在流失预测模型上帮助[封闭]</title>
      <link>https://stackoverflow.com/questions/79521346/need-help-on-churn-prediction-model</link>
      <description><![CDATA[我是一个小组，为公司做一个ML项目。我们正在进行的项目是服务的流失预测模型，现在该公司将其定义为Churn，整个数据集中只有大约2％的流失。 200万行。这些是我们迄今为止最佳模型的结果：
分类报告 
我们尝试了所有常规的监督学习算法和pytorch神经网络算法，并且我们一直在使用Smote Overplating和Smotetomek，但是对于流失案例，我们的结果不足。截至目前，使用梯度提升，我们在上传图片中看到的分数获得了最佳效果。有什么建议吗？另外，如果我们要通过每行计算搅动或进行窗户的ChurnF.X。如果我们要以3个月的基础计算终止服务的数量，并且如果他们删除了证书百分比，那么它将被视为流失，或者我们是否应该对独特的客户进行分组并将数据集转换为每个客户的一行，而不是出现48个不同时间？数据集中有30列以上的列是捕获太多噪声的模型吗？
任何建议都会有所帮助！
我们尝试了所有常规监督的学习算法和pytorch神经网络。]]></description>
      <guid>https://stackoverflow.com/questions/79521346/need-help-on-churn-prediction-model</guid>
      <pubDate>Wed, 19 Mar 2025 20:42:11 GMT</pubDate>
    </item>
    <item>
      <title>数据加载器 -  CPU和MPS之间的Pytorch不一致 - 苹果硅</title>
      <link>https://stackoverflow.com/questions/76991341/dataloader-pytorch-inconsistency-between-cpu-and-mps-apple-silicon</link>
      <description><![CDATA[我在Mac Apple Silicone上与Pytorch的Dataloader陷入了这种不一致之处。
如果我使用cpu  y ，请正确解释。但是，如果我使用MPS，它总是以正确的长度返回向量，但是仅基于第一个元素 y [0] 。
 导入火炬
来自torch.utils.data导入tensordataset，Random_split，dataLoader


设备= TORCH.DEVICE（MPS;） 
x = torch.tensor（[[[[[0.5,0.4]，[0,0]]，[[0.3,0.2]，[0,0]]，[[0.5,0.2]，[0,0,0]，[0,0.0.2]，[[0.2,0.2]，[0,0,0]，[0,0,0]，[0,0,0]
Y = TORCH.TENSOR（[1,0,0,0]，dtype = Type = Torch.float32）TO（设备）

打印（X.Shape）
打印（y.形）
打印（y）
dataset = tensordataset（x，y）
train_size = int（0.5 * len（数据集））
test_size = len（数据集） -  train_size
train_dataset，test_dataset = Random_split（数据集，[train_size，test_size]）
train_loader = dataloader（train_dataset，batch_size = 10，shuffle = true）

对于i（batch_data，batch_labels）枚举（train_loader）：
    打印（batch_data）
    打印（batch_labels）
    休息
 
对于 batch_labels  on  mps 我总是在 y  中根据第一个值获得张量。
  torch.size（[4，2，2]）
TORCH.Size（[4]）
张量（[1.，0.，1。1。，0。]，设备=&#39;MPS：0&#39;）
张量（[[[[0.5000，0.2000]，
         [0.0000，0.0000]]，

        [[0.5000，0.4000]，
         [0.0000，0.0000]]]，设备=&#39;MPS：0&#39;）
张量（[1。，1。]，设备=&#39;MPS：0&#39;）
 
也许它与一般MPS OP覆盖范围跟踪问题＃777764 ]]></description>
      <guid>https://stackoverflow.com/questions/76991341/dataloader-pytorch-inconsistency-between-cpu-and-mps-apple-silicon</guid>
      <pubDate>Mon, 28 Aug 2023 08:55:44 GMT</pubDate>
    </item>
    <item>
      <title>Intel Mac上的Torch MPS：获取设备的名称？</title>
      <link>https://stackoverflow.com/questions/76954976/torch-mps-on-intel-mac-get-name-of-device</link>
      <description><![CDATA[在Python中，在具有NVIDIA GPU的机器上，可以使用以下方式确认GPU的MPS设备名称：
  torch.cuda.get_device_name（） 
根据文档： https://pytorch.org/docs/stable/generated/torch.cuda.get_device_name.html#torch.cuda.get_device_name  
如何确认具有AMD GPU的Intel Mac的MPS设备名称？我在文档中没有任何提及。]]></description>
      <guid>https://stackoverflow.com/questions/76954976/torch-mps-on-intel-mac-get-name-of-device</guid>
      <pubDate>Tue, 22 Aug 2023 15:48:25 GMT</pubDate>
    </item>
    <item>
      <title>稳定的扩散模型的运行模型提示从MPOS上拥抱脸部的稳定扩散模型</title>
      <link>https://stackoverflow.com/questions/76939164/running-model-prompt-on-stable-diffusion-model-from-hugging-face-on-mps-macos</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76939164/running-model-prompt-on-stable-diffusion-model-from-hugging-face-on-mps-macos</guid>
      <pubDate>Sun, 20 Aug 2023 11:27:44 GMT</pubDate>
    </item>
    <item>
      <title>反馈循环：预期发电机的“ CPU”设备类型，但找到了“ MPS”</title>
      <link>https://stackoverflow.com/questions/76817578/feedback-loop-expected-a-cpu-device-type-for-generator-but-found-mps</link>
      <description><![CDATA[我试图在MacOS M2上捕获拥抱面模型。但是，MPS尚不存在火炬操作员“ Aten :: Random_”。因此，我用运行了该程序
  pytorch_enable_mps_fallback = 1 
 
然后，我收到了以下消息，“预期“ CPU”发电机设备类型，但找到了“ MPS”。我试图通过指定 generator = torch.generator（device =&#39;mps&#39;）在数据载加载程序中解决此问题。然而，这扭曲了信息，并产生“预期A MPS：0”生成器设备，但发现了“ MPS”。因此，看来我陷入了循环。
这是我正在使用的完整代码
 从数据集导入load_dataset
从变形金刚导入自动源
导入火炬
来自torch.utils.data导入数据加载程序

dataset = load_dataset（&#39;yelp_review_flull&#39;）
tokenizer = autotokenizer.from_pretaining（“ bert-base cased;）
def tokenize_function（示例）：
    返回tokenizer（示例[&#39;text;]，padding =; max_length＆quort＆quot; truncation = true）

tokenize_datasets = dataset.map（tokenize_function，batched = true）

tokenized_datasets = tokenized_datasets.remove_columns（[text;]）
tokenized_datasets = tokenized_datasets.rename_column（“ label; quot”;
tokenized_datasets.set_format（“ Torch”）
small_train_dataset = tokenized_datasets [&#39;train;]。shuffle（seed = 42）。选择（range（1000））
small_eval_dataset = tokenized_datasets [&#39;test&#39;]。shuffle（seed = 42）。选择（range（range（1000）））


train_dataloader = dataloader（small_train_dataset，shuffle = true，batch_size = 8，generator = torch.generator（device =&#39;cpu&#39;）
eval_dataloader = dataloader（small_eval_dataset，batch_size = 8，generator = torch.generator（device =&#39;cpu&#39;））
对于train_dataloader中的批次：
    打印（批次）
    ＃当然，我想在这里做其他事情，但是打开循环已经产生错误。 
 
我正在使用火炬2.0.1，数据集2.14.0与变压器4.31.0 一起使用]]></description>
      <guid>https://stackoverflow.com/questions/76817578/feedback-loop-expected-a-cpu-device-type-for-generator-but-found-mps</guid>
      <pubDate>Wed, 02 Aug 2023 07:34:31 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch MPS：“ MPS.Scatter_nd” OP无效输入张量形状</title>
      <link>https://stackoverflow.com/questions/76196734/pytorch-mps-mps-scatter-nd-op-invalid-input-tensor-shape</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76196734/pytorch-mps-mps-scatter-nd-op-invalid-input-tensor-shape</guid>
      <pubDate>Sun, 07 May 2023 23:44:53 GMT</pubDate>
    </item>
    <item>
      <title>M2 Mac上的Pytorch（2022）：RuntimeError：占位符存储尚未在MPS设备上分配</title>
      <link>https://stackoverflow.com/questions/75842303/pytorch-on-m2-mac2022-runtimeerror-placeholder-storage-has-not-been-allocate</link>
      <description><![CDATA[I&#39;m training a model in PyTorch 2.0.0.I built a model Bert+Liner Model below. I have set device=torch.device(&quot;mps&quot;).Error occurs where input_ids,attention_mask,token_type_ids,labels. Thanks for your help~~
i expect that model could run on mps, while i figure it out on cpu, with much time to spend.I want to run the model on mps with less time.Thanks
model = bert+Linear
class Model(torch.nn.Module):
def init(self):
super().init()
# 定义一个全连接层
# 输入768维：bert-base-chinese的输出维度，输出2维：情感倾向的种类数
self.fc = torch.nn.Linear(768, 2)
# 前向传播函数
def forward(self, input_ids, attention_mask, token_type_ids):
    with torch.no_grad():  
        out = pretrained(input_ids=input_ids,
                         attention_mask=attention_mask,
                         token_type_ids=token_type_ids)  # 基于bert模型，直接获得输出768维的结果

    # 取0个词的特征作为全连接层的输入
    out = self.fc(out.last_hidden_state[:, 0])
    out = out.softmax(dim=1)  # 取出概率最大的一维作为结果
    return out

predict sentiment of text
for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(bar_predict):
print(&#39;当前批次:&#39;, i)
    # 将变量转移到MPS上
    input_ids = input_ids.to(torch.long).to(config.device)
    attention_mask = attention_mask.to(torch.long).to(config.device)
    token_type_ids = token_type_ids.to(torch.long).to(config.device)
    labels = labels.to(torch.long).to(config.device)

    with torch.no_grad():  # 预测过程不计算梯度，
        out = sentimodel(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
        out = out.argmax(dim=1)  # 取列维度最大的值所对应的位置索引
]]></description>
      <guid>https://stackoverflow.com/questions/75842303/pytorch-on-m2-mac2022-runtimeerror-placeholder-storage-has-not-been-allocate</guid>
      <pubDate>Sat, 25 Mar 2023 14:20:30 GMT</pubDate>
    </item>
    <item>
      <title>如何解决M1 Mac上的“ MPS Framework不支持Float64”</title>
      <link>https://stackoverflow.com/questions/75173055/how-to-resolve-mps-framework-doesnt-support-float64-on-m1-mac</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75173055/how-to-resolve-mps-framework-doesnt-support-float64-on-m1-mac</guid>
      <pubDate>Thu, 19 Jan 2023 13:34:42 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机。精度和/或准确性？</title>
      <link>https://stackoverflow.com/questions/36846795/support-vector-machine-precision-and-or-accuracy</link>
      <description><![CDATA[我正在尝试弄清我使用的代码是计算精度还是准确性或两者兼而有之。由于我只有少量的统计背景（用另一种语言），所以我真的不理解 wikipedia&#39;&gt; wikipedia文章涵盖该主题。
具体地我使用以下python代码：
 来自Sklearn Import SVM，Cross_validation
clf = svm.svc（内核=内核，c = c）
scores = cross_validation.cross_val_score（clf，featurematrix，np.squeeze（labelmatrix），cv = d_inds）
 
  scikit-learn 函数可以在此处找到：

     sklearn.svc.svm.svc.svc.svc       
 ]]></description>
      <guid>https://stackoverflow.com/questions/36846795/support-vector-machine-precision-and-or-accuracy</guid>
      <pubDate>Mon, 25 Apr 2016 17:03:37 GMT</pubDate>
    </item>
    </channel>
</rss>