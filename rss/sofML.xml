<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 23 Jan 2024 15:15:08 GMT</lastBuildDate>
    <item>
      <title>如何更改微调技能中的学习率</title>
      <link>https://stackoverflow.com/questions/77867150/how-to-change-the-learn-rate-in-the-fine-tune-skill</link>
      <description><![CDATA[查询：

在特定层将学习率提高十倍的目的：我想了解实现选择背后的基本原理，如果param_group为 True 时，全连接层 (net .fc）设置为默认学习率（learning_rate * 10）的十倍。这种方法有哪些好处和潜在影响？

在此处输入图像描述

动态学习率调整的可行性：是否可以动态调整学习率，例如，通过使用正弦函数在一定范围（例如，从 0 到pi/2）？如何在这段代码的上下文中实现这一点，特别是对于不同的层，例如全连接层（接近 pi/2）和卷积层（接近 0） ？
]]></description>
      <guid>https://stackoverflow.com/questions/77867150/how-to-change-the-learn-rate-in-the-fine-tune-skill</guid>
      <pubDate>Tue, 23 Jan 2024 14:48:15 GMT</pubDate>
    </item>
    <item>
      <title>此 MinMaxScaler 实例尚未安装。在使用此估计器之前，使用适当的参数调用“fit”。NotFittedError</title>
      <link>https://stackoverflow.com/questions/77866770/this-minmaxscaler-instance-is-not-fitted-yet-call-fit-with-appropriate-argume</link>
      <description><![CDATA[xgb = XGBRegressor(n_estimators=1000，learning_rate=0.01)
xgb.fit(X_train3,y_train1,eval_set=[(X_train3,y_train1),(X_valid3,y_valid1)],early_stopping_rounds=100,verbose=True)
Predicted_results_v = xgb.predict(X_train3)
Predicted_results_t = xgb.predict(X_train3)
Predicted_results_v = Predicted_results_v.reshape(-1,1)
Predicted_results_t = Predicted_results_t.reshape(-1,1)
Predicted_reults_v = scaler1.inverse_transform(predicted_results_v)
Predicted_results_t = 缩放器.inverse_transform(predicted_results_t)

我正在使用 xgboost 库作为股票交易的机器学习模型。为了缩放数据，使用了 MinMaxScaler，但它无法适应数据，因为它引发了错误
NotFittedError：此 MinMaxScaler 实例尚未安装。
在使用此估计器之前，请使用适当的参数调用“fit”。
]]></description>
      <guid>https://stackoverflow.com/questions/77866770/this-minmaxscaler-instance-is-not-fitted-yet-call-fit-with-appropriate-argume</guid>
      <pubDate>Tue, 23 Jan 2024 13:45:59 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试在 vsc 上使用 pip 安装tensorflow，但即使安装后，在运行代码时它也会显示“没有名为‘tensorflow’的模块”[关闭]</title>
      <link>https://stackoverflow.com/questions/77866135/im-trying-to-install-tensorflow-using-pip-on-vsc-but-even-after-installing-o</link>
      <description><![CDATA[所以，我在这里尝试在 vsc 上使用 pip 安装tensorflow，但出现错误，没有名为tensorflow的模块。我尝试重新安装，但显示相同的错误。目前tensorflow所需的python版本是3.8-3.11，我正在使用3.10.10和最新版本的pip。我该如何让它发挥作用？
我想在本地运行它，不想使用虚拟环境，我正在使用 vsc
安装了tensorflow-cpu，但在导入时抛出错误，“没有名为“tensorflow”的模块”。]]></description>
      <guid>https://stackoverflow.com/questions/77866135/im-trying-to-install-tensorflow-using-pip-on-vsc-but-even-after-installing-o</guid>
      <pubDate>Tue, 23 Jan 2024 12:01:38 GMT</pubDate>
    </item>
    <item>
      <title>如何清理存在拼写错误的数据以进行文本分类？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77866039/how-to-clean-my-data-which-has-spelling-errors-for-text-classification</link>
      <description><![CDATA[我的文本数据包含金融句子，其中有很多拼写错误和无意义的单词。我已经做了很多清理工作，但仍然留下一些文字。有什么方法可以帮助纠正我的数据的这种不稳定现象吗？
我已经尝试了所有的清理方法和缩写的处理。但这些就像手动输入]]></description>
      <guid>https://stackoverflow.com/questions/77866039/how-to-clean-my-data-which-has-spelling-errors-for-text-classification</guid>
      <pubDate>Tue, 23 Jan 2024 11:44:15 GMT</pubDate>
    </item>
    <item>
      <title>该模型不断预测同一类[关闭]</title>
      <link>https://stackoverflow.com/questions/77865558/this-model-keeps-predicting-the-same-class</link>
      <description><![CDATA[我编写了一个用于预测药用植物的代码，但它一直预测相同类型的植物（印楝）
即使我的输入不同。
https://colab.research.google.com/drive/1dDmFyach90W7wjWu8mOW1xbOvctRLB3Y ?usp=共享
这是我的代码的链接。
我的数据集
请尽快完成，我有一个项目要到期。
我尝试最小化数据集，就像我在堆栈溢出时看到的那样。
但它一直给出相同的输出。
我希望它能够正确预测叶子的类型。]]></description>
      <guid>https://stackoverflow.com/questions/77865558/this-model-keeps-predicting-the-same-class</guid>
      <pubDate>Tue, 23 Jan 2024 10:25:14 GMT</pubDate>
    </item>
    <item>
      <title>IndexError：数组索引太多：数组是一维的，但在使用多列 y 输入时对 2 个进行了索引</title>
      <link>https://stackoverflow.com/questions/77864377/indexerror-too-many-indices-for-array-array-is-1-dimensional-but-2-were-index</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77864377/indexerror-too-many-indices-for-array-array-is-1-dimensional-but-2-were-index</guid>
      <pubDate>Tue, 23 Jan 2024 06:33:21 GMT</pubDate>
    </item>
    <item>
      <title>AssertionError LLama-cpp-python 模型加载失败</title>
      <link>https://stackoverflow.com/questions/77864368/assertionerror-llama-cpp-python-model-failed-to-load</link>
      <description><![CDATA[即使我使用 GGUF 格式，Llama-cpp-python 也会出现断言错误。
我正在尝试使用 llama-cpp-python 0.1.85 在 python 3.7.2 中运行 AI 模型，每次运行我的代码时都会收到此错误：
加载模型时出错：MapViewOfFile 失败：没有足够的内存资源来处理此命令。

llama_load_model_from_file：加载模型失败
回溯（最近一次调用最后一次）：
  文件“server.py”，第 26 行，在  中。
    n_ctx=N_CTX,
  文件“D:\AI 2\Venv\lib\site-packages\llama_cpp\llama.py”，第 323 行，位于 __init__ 中
    断言 self.model 不是 None
断言错误

我使用的是 GGUF 格式，所以我不知道问题是什么，它在第二台计算机上运行良好，但在我的主机上运行不佳，有什么帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/77864368/assertionerror-llama-cpp-python-model-failed-to-load</guid>
      <pubDate>Tue, 23 Jan 2024 06:30:48 GMT</pubDate>
    </item>
    <item>
      <title>在成人收入数据集上对梯度增强分类器模型应用动物园攻击时，无法生成对抗性示例</title>
      <link>https://stackoverflow.com/questions/77864310/not-able-to-generate-adversarial-examples-when-applying-zoo-attack-on-gradient-b</link>
      <description><![CDATA[当对用例应用动物园攻击以使用梯度提升分类器模型预测成人收入数据集时，它无法生成任何对抗性示例。相反，只有当我使用 minmaxscaler 标准化数据集时，它才能生成对抗性示例。
from art.estimators.classification import SklearnClassifier

X,y = shap.datasets.adult()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)

art_classifier = SklearnClassifier(模型=model_gb)

动物园 = ZooAttack(分类器=art_classifier,置信度=0.0,learning_rate=1e-1, max_iter=20,
                    binary_search_steps=10、use_resize=False、use_importance=False、nb_parallel=1、batch_size=1、variable_h=0.2）

对手=zoo.generate(np.array(X_test))

我期望算法至少生成一些对抗性示例

操作系统 - Windows 11
Python 版本 - Python 3.10.9
ART 版本或提交号 -1.14.1
]]></description>
      <guid>https://stackoverflow.com/questions/77864310/not-able-to-generate-adversarial-examples-when-applying-zoo-attack-on-gradient-b</guid>
      <pubDate>Tue, 23 Jan 2024 06:14:37 GMT</pubDate>
    </item>
    <item>
      <title>我使用 Diffusers 来训练 LoRA。训练图像是我的照片，但结果图像不像我</title>
      <link>https://stackoverflow.com/questions/77864227/i-use-diffusers-to-train-lora-training-images-are-my-photos-but-the-result-ima</link>
      <description><![CDATA[这是我的训练代码。
from Accelerate.utils import write_basic_config
write_basic_config()

导入操作系统

os.environ[“MODEL_NAME”] = “runwayml/stable-diffusion-v1-5”
os.environ[“INSTANCE_DIR”] =“/notebooks/me_photos”
os.environ[“OUTPUT_DIR”] =“/notebooks/me_model_1_22”
script_path =“/notebooks/diffusers/examples/dreambooth/train_dreambooth_lora.py”

!加速启动{script_path} \
  --pretrained_model_name_or_path={os.environ[“MODEL_NAME”]} \
  --instance_data_dir={os.environ[“INSTANCE_DIR”]} \
  --output_dir={os.environ[“OUTPUT_DIR”]} \
  --instance_prompt=&quot;Ryan 的照片&quot; \
  --分辨率=512 \
  --train_batch_size=1 \
  --learning_rate=2e-6 \
  --max_train_steps=2400 \
  --gradient_checkpointing \
  --use_8bit_adam \
  --with_prior_preservation \
  --prior_loss_weight=1.0 \
  --class_data_dir=“/notebooks/faces_prior_preservation” \
  --class_prompt=“人脸照片”

这是生成图像的代码。
从扩散器导入 DiffusionPipeline
进口火炬

# 初始化日志记录
导入日志记录
日志记录.basicConfig（级别=日志记录.INFO）
记录器=logging.getLogger()


管道 = DiffusionPipeline.from_pretrained(“runwayml/stable-diffusion-v1-5”,
                                         torch_dtype=torch.float16,
                                         use_safetensors=真，
                                         变体=“fp16”）
管道.to(“cuda”)


pipeline.load_lora_weights（“/notebooks/me_model_1_22”，weight_name =“pytorch_lora_weights.safetensors”，adapter_name =“me”）

active_adapters = pipeline.get_active_adapters()
活动适配器

logger.info(f“LoRA {active_adapters} 加载成功。”)


# 生成图像
提示=“瑞安的照片”
洛拉规模= 1
图像=管道（
    提示，num_inference_steps=30，cross_attention_kwargs={“scale”：lora_scale}
).图片[0]

# 保存图像
输出路径=“/notebooks/image_of_me2.png”
图像.保存（输出路径）
logger.info(f“图像保存在 {output_path}”)

＃ 清理
删除图像
torch.cuda.empty_cache()


]]></description>
      <guid>https://stackoverflow.com/questions/77864227/i-use-diffusers-to-train-lora-training-images-are-my-photos-but-the-result-ima</guid>
      <pubDate>Tue, 23 Jan 2024 05:52:20 GMT</pubDate>
    </item>
    <item>
      <title>部署时ValueError：无法确定Excel文件格式[关闭]</title>
      <link>https://stackoverflow.com/questions/77863886/when-deploy-valueerror-excel-file-format-cannot-be-determined</link>
      <description><![CDATA[我的本​​地计算机上有一个 Excel 工作表，它正在为我的 Streamlit 应用程序提供数据。该应用程序和每个组件在我的本地系统上运行良好。但我在部署时解决了这个问题
ValueError：无法确定 Excel 文件格式，您必须手动指定引擎。

我添加了引擎openpyxl
df = pd.read_excel(f, engine=“openpyxl”).reindex(columns = customer_id).dropna(how=&#39;all&#39;, axis=1)

现在我得到了一个不同的错误：
BadZipFile：文件不是 zip 文件
]]></description>
      <guid>https://stackoverflow.com/questions/77863886/when-deploy-valueerror-excel-file-format-cannot-be-determined</guid>
      <pubDate>Tue, 23 Jan 2024 03:45:05 GMT</pubDate>
    </item>
    <item>
      <title>使用多维训练集通过 RNN 进行预测</title>
      <link>https://stackoverflow.com/questions/77863462/make-predictions-with-an-rnn-using-a-multi-dimensional-training-set</link>
      <description><![CDATA[我有一个训练数据的二维矩阵TD，它是N个非线性信号的集合，这些信号是时间的函数（因此训练的规范设置在这篇文章的标题中）。让M表示每个信号的时间步数。每个信号共享相同的M。因此，TD 是一个 MxN 矩阵。我想在整个训练集上训练我的神经网络，以计算我的输出权重矩阵 Wout。 然后我想对单独的非线性信号 yTest 进行预测code&gt;，这不是使用训练后的 Wout 的 TD 中已有的 N 信号之一。然后，我想将尺寸为 1xM 的预测输出 yNN 与尺寸为 1xM 的 yTest 进行比较&gt; 查看预测的准确度。
我的问题是我当前的 yTest 和 yNN 的尺寸均为 NxM 而不是 1xM。我的目标是在所有 N 训练集信号上训练神经网络，并使用考虑所有 Wout 进行单一 1xM 预测&gt;N 非线性信号。附带说明一下，Wout 的维度为 DxN，其中 D 是我的神经网络中的节点数。
我不确定我所问的是否可能。 MATLAB 中有没有办法在计算 WoutTD 从 MxN 矩阵展平或重塑为 Mx1 矩阵&gt;？这样，Wout 将是一个 Dx1 矩阵，预测输出 yNN 将是一个 1xM 矩阵，就像我想要的那样成为？]]></description>
      <guid>https://stackoverflow.com/questions/77863462/make-predictions-with-an-rnn-using-a-multi-dimensional-training-set</guid>
      <pubDate>Tue, 23 Jan 2024 00:25:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用变压器的管道处理大文件</title>
      <link>https://stackoverflow.com/questions/77862602/how-to-process-large-file-using-pipeline-from-transformers</link>
      <description><![CDATA[我使用管道从 Hugging Face 加载模型：
设备 =“cuda:0” if torch.cuda.is_available() else “cpu”
torch_dtype = torch.float16 如果 torch.cuda.is_available() else torch.float32

model_id =“openai/whisper-large-v3”；

模型 = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id、torch_dtype=torch_dtype、low_cpu_mem_usage=True、use_safetensors=True
）
模型.to（设备）

处理器 = AutoProcessor.from_pretrained(model_id)

管道 = 管道（
    “自动语音识别”，
    型号=型号，
    tokenizer=处理器.tokenizer,
    feature_extractor=处理器.feature_extractor,
    最大新令牌=128，
    块长度_s = 20，
    批量大小=16，
    return_timestamps=真，
    torch_dtype=torch_dtype,
    设备=设备，
）

我想处理大音频文件
结果=管道(“文件名3.mp3”)

但是谷歌协作说我的内存不足。是否可以将输出通过管道传输到文件而不是变量？]]></description>
      <guid>https://stackoverflow.com/questions/77862602/how-to-process-large-file-using-pipeline-from-transformers</guid>
      <pubDate>Mon, 22 Jan 2024 20:35:09 GMT</pubDate>
    </item>
    <item>
      <title>添加 2 个模型作为另一个模型的输入（图表已断开连接）</title>
      <link>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</link>
      <description><![CDATA[我有两个模型：model_A 和 model_B。
我想对这两个模型进行元素明智加法，并将结果用作 model_C 的输入。
所以，我有这个代码：
从tensorflow.keras.layers导入Conv2D，BatchNormalization，\
    激活、输入、添加
从tensorflow.keras.models导入模型
将 numpy 导入为 np
将张量流导入为 tf

def model_A（输入）：
    x1 = Conv2D(32, 3, padding=&#39;相同&#39;)(输入)
    x1 = BatchNormalization()(x1)
    x1 = 激活(&#39;relu&#39;)(x1)
    
    x2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(x1)
    模型=模型（输入=输入，输出=x​​2，名称=&#39;model_A&#39;）
    返回模型
    

def model_B（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(f1)

    模型=模型（输入=输入，输出=f2，名称=&#39;model_B&#39;）
    返回模型

def model_C（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(16, 3, 填充=&#39;相同&#39;)(f1)
    f2 = BatchNormalization()(f2)
    f2 = 激活(&#39;relu&#39;)(f2)

    f3 = Conv2D(1, 3, 填充=&#39;相同&#39;)(f2)

    模型=模型（输入=输入，输出=f3，名称=&#39;model_C&#39;）
    返回模型
    
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    modelC = model_C（加法）
    
    返回模型（输入，modelC.输出）
    
a = np.random.uniform(0, 1, (100, 32, 32, 3))
b = np.random.uniform(0, 1, (100, 32, 32, 3))
c = np.random.uniform(0, 1, (100, 32, 32, 3))
    
模型 = model_final(32, 32, 3)

优化器 = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(优化器=优化器,
              损失=&#39;mae&#39;,
              指标=[&#39;mae&#39;])
    

如果我运行代码，我会在 Model(inputs=inputs,outputs=f3, name=&#39;model_C&#39;) 处收到 Graph Disconnected。
所以，为了解决这个问题，我正在做：
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    input_C = 输入((高度,宽度,32))
    modelC = model_C(输入_C)
    modelC = modelC(加法)
    
    模型=模型（输入，模型C）
    返回模型

编译得很好。
但是，我不确定这是否正确。如果这样做的逻辑是正确的！]]></description>
      <guid>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</guid>
      <pubDate>Mon, 22 Jan 2024 12:34:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么感知器没有按预期进行训练？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77858926/why-is-the-perceptron-not-training-as-expected</link>
      <description><![CDATA[我试图学习神经网络，并从感知器开始。
我看了一些教程并完全按照它们进行操作，但它对我不起作用。


var canvas = document.querySelector(&#39;canvas&#39;)
画布宽度=内部宽度；
画布高度=内部高度；
var c = canvas.getContext(&#39;2d&#39;)



函数符号（val）{
  如果（值&gt;= 0）{
    返回1
  } 别的 {
    返回-1
  }
}

类感知器{
  构造函数（数字）{
    this.权重 = []
    这个.lr = 0.1

    for (var i = 0; i &lt; num; i++) {
      this.weights.push(Math.random() * 2 - 1)
    }
  }

  猜测（输入）{
    变量总和 = 0
    for (var i = 0; i &lt; this.weights.length; i++) {
      sum += this.weights[i] * 输入[i]
    }
    var 输出 = 符号（总和）
    返回输出
  }

  训练（输入，目标）{
    var 猜测 = this.guess(输入)
    var 错误 = 目标 - 猜测

    for (var i = 0; i &lt; this.weights.length; i++) {
      this.weights[i] += 错误 * 输入[i] * this.lr
    }
  }
}

var Brain = 新感知器(2)

变量点 = []


类点{
  构造函数（x，y）{
    这个.x = x
    这个.y = y
    这个.标签 = 0

    c.线宽=2

    if (this.y &lt; canvas.height / 2) {
      这个.标签 = 1
    } else if (this.y &gt; canvas.height / 2) {
      这个.标签 = -1
    }
  }
  画（） {
    c.beginPath()
    c.arc(this.x, this.y, 10, 0, Math.PI * 2, false)
    c.fill()
    if (this.label == 1) {
      c.中风()
    }
  }
  更新（） {



    this.draw()
  }
}

for (var i = 0; i &lt; 100; i++) {
  point.push(new Point(Math.random() * canvas.width, Math.random() * canvas.height))
}


函数动画（）{
  请求动画帧（动画）
  c.clearRect(0, 0, canvas.width, canvas.height)
  点.forEach(点=&gt;{


    Brain.train([point.x, point.y], point.label)
    var猜测 = Brain.guess([point.x, point.y])
    if (猜测==点.标签) {
      c.fillStyle = &quot;绿色&quot;
    } 别的 {
      c.fillStyle = &quot;红色&quot;
    }
    点.update()
  })
}

动画（）
&lt;代码&gt;* {
  保证金：0；
  填充：0；
}

帆布 {
  位置：绝对；
}




这是我的代码
谁能告诉我这是怎么回事吗？
我的目标是让感知器对点进行分类，其中屏幕一半以上的点应具有 1 的值，而屏幕一半以下的点应具有 -1 的值
它正确预期的点应该用绿色着色，其他点应该用红色着色，但有些球没有变成绿色。
请注意，我在动画函数中使用了训练函数，以便每帧训练网络。]]></description>
      <guid>https://stackoverflow.com/questions/77858926/why-is-the-perceptron-not-training-as-expected</guid>
      <pubDate>Mon, 22 Jan 2024 09:48:47 GMT</pubDate>
    </item>
    <item>
      <title>多种产品的预测模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77857775/forecasting-model-for-multiple-products</link>
      <description><![CDATA[嗨，我是数据科学的一个相对较新的人，我有一个时间序列问题，我必须预测 100 多种产品的销售，并且所有产品都有不同的模式，而且新产品会不断添加，这很困难要单独建模它们，我还必须设置再训练流程，如何简化这个过程，有没有什么方法可以概括模型选择、验证和再训练，而不必每次都单独建模？
我的问题陈述是，当产品的销售数据上传时，我必须实时训练模型并给出预测，如何自动化此过程，而无需手动清理数据、处理缺失值和异常值、选择建模和调整超参数？]]></description>
      <guid>https://stackoverflow.com/questions/77857775/forecasting-model-for-multiple-products</guid>
      <pubDate>Mon, 22 Jan 2024 05:19:57 GMT</pubDate>
    </item>
    </channel>
</rss>