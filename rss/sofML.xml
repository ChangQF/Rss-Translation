<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 29 Aug 2024 12:31:09 GMT</lastBuildDate>
    <item>
      <title>Google COLAB：我编写任何代码，然后在 colab 编辑器中单击该代码，它的行为很奇怪，并且一次又一次地重复出现单词</title>
      <link>https://stackoverflow.com/questions/78927737/google-colab-i-write-any-code-and-then-clicking-on-that-code-in-colab-editor-i</link>
      <description><![CDATA[[在此处输入图片描述](https://i.sstatic.net/1vRZC63L.png)
如何解决此问题：Google COLAB：我编写了任何代码，然后在 colab 编辑器中单击该代码，它表现得很奇怪，并且一次又一次地重复单词。它会从点击处随机复制任何内容，然后粘贴到我单击的下一个位置。]]></description>
      <guid>https://stackoverflow.com/questions/78927737/google-colab-i-write-any-code-and-then-clicking-on-that-code-in-colab-editor-i</guid>
      <pubDate>Thu, 29 Aug 2024 12:15:56 GMT</pubDate>
    </item>
    <item>
      <title>如何构建一个具有稳定扩散功能的简单 ML 文本转图像应用程序？</title>
      <link>https://stackoverflow.com/questions/78927463/how-can-i-build-a-simple-ml-text-to-image-app-with-stable-diffusion</link>
      <description><![CDATA[我看了下面的 yt 视频，我想尝试自己制作，但我不知道 vs 代码的设置，我只是得到了它的代码，我该怎么办？
我的目标是制作与 yt 视频完全相同的，然后对其进行修改以添加更多功能，但第一步我已经完成了。
如何使用提供的代码做到这一点？
https://www.youtube.com/watch?v=7xc0Fs3fpCg]]></description>
      <guid>https://stackoverflow.com/questions/78927463/how-can-i-build-a-simple-ml-text-to-image-app-with-stable-diffusion</guid>
      <pubDate>Thu, 29 Aug 2024 11:04:04 GMT</pubDate>
    </item>
    <item>
      <title>两个相似形状的潜在向量距离是否比不相似形状的潜在向量距离更近。如果是同一个物体</title>
      <link>https://stackoverflow.com/questions/78927177/is-distance-of-latent-vector-from-two-similar-shape-closer-than-which-is-not-sim</link>
      <description><![CDATA[问题是，‘两个相似形状的潜在向量距离是否比不相似形状的潜在向量更近’，raymarch（在 nerf 中）可以在特定空间中保证（这不是问题，跳过此问题），但如果它们是来自 MLP（多层感知器）或 FCN（全连接网络）的潜在向量，则在同一对象中获取相似场景。相似场景的距离比非相似场景更近。
请看图片。

如果这个物体完全是堆叠的（这可能不是确切的表达）纸张。
角度 B 和 C 看起来像这样
 
这两个场景非常相似，因为两张纸的纹理相似。
但是，场景 A 是这样的

假设通过训练有素的 MLP 或 FCN 提取向量，场景 B 到场景 C 的每个距离（距离 1）可能大于场景 A 到场景 B 的距离（距离 2）。
我认为距离 1 总是小于距离 2。
但是，另一种观点是永远无法决定哪一个更大。
我想引用另一种观点。]]></description>
      <guid>https://stackoverflow.com/questions/78927177/is-distance-of-latent-vector-from-two-similar-shape-closer-than-which-is-not-sim</guid>
      <pubDate>Thu, 29 Aug 2024 09:54:46 GMT</pubDate>
    </item>
    <item>
      <title>如何用 pytorch 处理文本和数字特征？</title>
      <link>https://stackoverflow.com/questions/78926855/how-to-handle-text-and-number-features-with-pytorch</link>
      <description><![CDATA[我是 ML 新手，所以这个问题可能很愚蠢。
我的数据集包含一些数字列和一个文本列。文本是一个句子。
我想使用 pytorch 将此数据集用于分类。但不知道如何处理文本列。
之前我使用 Catboost 和 text_features 选项，它运行良好。我还尝试将文本转换为嵌入，并像 Catboost 中的任何其他数字特征一样使用它，它也能正常工作。这是我所做的：
model = AutoModel.from_pretrained(&quot;DeepPavlov/rubert-base-cased&quot;, num_labels = 3, output_attentions = False, output_hidden_​​states = False)

def getEmbedding(text):

coded_input = tokenizer(text, return_tensors=&#39;pt&#39;, truncation=True,
max_length=max_len, add_special_tokens=True)

with torch.no_grad():

output = model(**encoded_input)
output = output[1].detach().cpu().numpy()[0]
torch.cuda.empty_cache()

return output

data[&#39;embedding&#39;] = data[&#39;text&#39;].apply(lambda x: getEmbedding(x))
data= pd.concat([data, data[&#39;embedding&#39;].apply(pd.Series)], axis=1)

但是现在我很好奇我使用带有 Bert 层的 pytorch 模型来处理文本，然后将结果与数字特征连接起来并将其传递到 Linear 层。类似于：
class BaselineNN(nn.Module):
def __init__(self, input_size, hidden1, out_size, drop1):
super(BaselineNN, self).__init__()
self.l1 = BertModel.from_pretrained(&#39;bert-base-uncased&#39;) # 用于文本特征的 bert 层
self.fc2 = nn.Linear(input_size, hidden1) # 用于数字特征的线性层
self.fc3 = nn.Linear(???, out_size) # 输出层

def forward(self, input1, input2, mask, token_type_ids):
_, output_1= self.l1(input1,tention_mask = mask, token_type_ids = token_type_ids)
output_2 = self.fc2(input2)
combined = torch.cat((output_1.view(output_1.size(0), -1),
output_2.view(output_2.size(0), -1)), dim=1)
out= self.fc2(combined)
return out

def init_weights(self, m):
if isinstance(m, nn.Linear):
torch.nn.init.kaiming_uniformal_(m.weight, mode=&#39;fan_in&#39;, nonlinearity=&#39;relu&#39;)
m.bias.data.fill_(0.01)

我的第一个问题 - 这值得吗？我的意思是我可以将文本转换为嵌入，将嵌入转换为数字并在模型中使用它。
如果值得 - 我如何正确连接 Bert 输出和线性层输出以将其传递到下一层？]]></description>
      <guid>https://stackoverflow.com/questions/78926855/how-to-handle-text-and-number-features-with-pytorch</guid>
      <pubDate>Thu, 29 Aug 2024 08:35:02 GMT</pubDate>
    </item>
    <item>
      <title>如何将 CLIP 向量转换为 LLM 文本标记嵌入？</title>
      <link>https://stackoverflow.com/questions/78926828/how-to-convert-clip-vectors-to-an-llm-text-token-embeddings</link>
      <description><![CDATA[我希望将多种模态嵌入到您传统的基于文本的 LLM 中。为此，我需要将任何模态转换为 CLIP 向量（我已经完成了），现在我需要将此向量转换为 LLM 文本标记嵌入。有人能帮我完成这个转换吗？
仍在研究这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78926828/how-to-convert-clip-vectors-to-an-llm-text-token-embeddings</guid>
      <pubDate>Thu, 29 Aug 2024 08:27:14 GMT</pubDate>
    </item>
    <item>
      <title>YOLO 的数据训练标记策略</title>
      <link>https://stackoverflow.com/questions/78926680/data-training-labeling-policy-for-yolo</link>
      <description><![CDATA[我正在训练我的 YOLO 来检测飞机和无人机。在一些图片中，无法检测到物体确实是飞机，它甚至看起来像无人机（图片是从很远的地方拍摄的），但我从上下文中知道它确实是。我还应该把它标记为飞机吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78926680/data-training-labeling-policy-for-yolo</guid>
      <pubDate>Thu, 29 Aug 2024 07:45:18 GMT</pubDate>
    </item>
    <item>
      <title>qiskit.optimization、qiskit.aqua、quiskit.aglorithms 无法识别</title>
      <link>https://stackoverflow.com/questions/78926571/qiskit-optimization-qiskit-aqua-quiskit-aglorithms-not-recognised</link>
      <description><![CDATA[因此，我一直在尝试编写/获取基于与心脏病变分量子分类器相关的项目的量子分类器代码，并在 GitHub 链接中的代码中（致谢：Rodneysodo）我尝试在我的解释器中编译它，但找不到 quiskit 包。
https://github.com/rodneyosodo/variational-quantum-classifier-on-heartattack/tree/main
我尝试将此代码用于我的数据集，并从 quiskit.aqua.components.optimizers 导入（或尝试导入）COBYLA、ADAM、SPSA，但尽管我的 qiskit 版本是最新的并且软件包已安装，但几天后“没有模块名称尽管卸载并重新安装了 qiskit 和其他模块，但仍发现了“qiskit_optimizer”]]></description>
      <guid>https://stackoverflow.com/questions/78926571/qiskit-optimization-qiskit-aqua-quiskit-aglorithms-not-recognised</guid>
      <pubDate>Thu, 29 Aug 2024 07:16:26 GMT</pubDate>
    </item>
    <item>
      <title>Azure ML 查询 - 后续端点生成期间未生成任何 Web 服务输入，且输入数据架构无效</title>
      <link>https://stackoverflow.com/questions/78925914/azure-ml-query-no-web-service-input-generated-and-void-input-data-schema-during</link>
      <description><![CDATA[我正尝试在 Azure ml 中创建实时推理管道，并遵循所有简单的步骤，但无法生成 Web 服务输入。仅生成 Web 服务输出。
此外，如果我手动添加 Web 服务输入或手动添加数据，在接下来的步骤中，即部署以创建端点，我无法在端点的“使用”部分中获取填充的数据模式，因此我无法使用输入数据运行我的预测。 （如果我有输入的数据模式，我会创建一个笔记本并在那里运行输入以获得我的预测）。

我使用了各种计算，包括容器实例、akscompute，彻底检查了我的数据集。
我迫切需要任何解决方案，我非常激动，因为我已经尝试了所有可能的解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78925914/azure-ml-query-no-web-service-input-generated-and-void-input-data-schema-during</guid>
      <pubDate>Thu, 29 Aug 2024 02:33:02 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种类型的分析和 ml 方法来预测 python 中具有分类独立变量的连续数据[关闭]</title>
      <link>https://stackoverflow.com/questions/78925814/what-type-of-analysis-and-ml-methodology-should-i-use-to-predict-continuous-data</link>
      <description><![CDATA[我有一个已经清理过的数据集，下面附上了示例数据。（实际数据集实际上有 140 个因变量，这里我只添加了 X1~X7）
Y 列是我想要预测的属性
而 X1 ~ X7 列是我用来预测 Y 结果的变量。
X1 ~ X7 列的 1 表示真，0 表示假。
在此处输入图片说明

最好的分析方法是什么，以查看这些 X 变量与我的结果变量 Y 之间是否存在相关性？我可以使用那些 X 变量的不同组合来查看某些组合是否能更好地预测结果吗？ （我不知道该怎么做）

我应该使用什么样的机器学习方法来训练这个数据集来预测 Y 值。


我查过独热编码和随机森林。我仍然不完全理解，也没有看到任何似乎准确代表我的数据集的示例。]]></description>
      <guid>https://stackoverflow.com/questions/78925814/what-type-of-analysis-and-ml-methodology-should-i-use-to-predict-continuous-data</guid>
      <pubDate>Thu, 29 Aug 2024 01:40:54 GMT</pubDate>
    </item>
    <item>
      <title>序列到序列 LSTM 用于分类</title>
      <link>https://stackoverflow.com/questions/78925733/sequence-to-sequence-lstm-for-classification</link>
      <description><![CDATA[我有一个包含两列的数据集：
past_events，future_events。
past_events 是 53 个数字代码的序列，如下所示
&#39;198&#39;、&#39;2000&#39;、&#39;197&#39;、&#39;85903&#39;，...
而 future_events 是 52 个数字代码的序列，如下所示
&#39;345&#39;、&#39;200&#39;、&#39;8904&#39;、&#39;23765&#39;，...
每个代码代表一个事件（代码按时间顺序排列）。
这个数据集中有近 3000 行。
我想构建一个 LSTM，它采用以下序列输入为 past_events，输出为 52 个事件的序列，这些事件是 future_events 的预测。
由于每个代码代表一个事件，在 future_events 中可能会出现 past_events 中不存在的代码，并且某些代码可能只出现在几行中，因此只出现在几个序列中。
这是我第一次做这种问题。如果是序列到值，我可以做到，但是对于这种分类的序列到序列，我不知道如何构建这个模型。
如果您能给我一些例子或一些解释此类问题的网站，我将不胜感激。
这是我构建 LSTM 的尝试，但没有成功
 input_1 = Input(shape=sequence_length)

lstm_out = LSTM(128, return_sequences=True)(input_1)
lstm_out = Dropout(0.2)(lstm_out)
lstm_out = LSTM(64, return_sequences=True)(lstm_out)
lstm_out = Dropout(0.2)(lstm_out)
lstm_out = LSTM(64, return_sequences=True)(lstm_out)
lstm_out = Dropout(0.2)(lstm_out)

lstm_out = Lambda(lambda x: x[:, :52, :])(lstm_out)

# 注意机制
tention = Attention()([lstm_out, lstm_out])

density_out = TimeDistributed(Dense(128,activation=&#39;relu&#39;))(attention)
density_out = Dropout(0.2)(dense_out)

output_layer = TimeDistributed(Dense(num_classes,activation=&#39;softmax&#39;))(dense_out)

我能得到的最好结果是，预测都是相同的数字代码，例如 52 &#39;367&#39;]]></description>
      <guid>https://stackoverflow.com/questions/78925733/sequence-to-sequence-lstm-for-classification</guid>
      <pubDate>Thu, 29 Aug 2024 00:33:59 GMT</pubDate>
    </item>
    <item>
      <title>如何利用机器学习来追踪公司员工的个人资料？</title>
      <link>https://stackoverflow.com/questions/78925616/how-to-use-machine-learning-to-trace-the-profile-of-employees-in-a-company</link>
      <description><![CDATA[我正在开展一个项目，该项目旨在使用一个包含已离职人员历史记录的数据库，并根据离职人员的个人资料计算在职员工离职的风险。
已离职人员的数据库 df_hist 包含有关自愿辞职的个人的信息，例如工作、种族、性别、薪水等。它的结构类似于以下示例：
日期 行动 姓名 薪水 职位
&#39;05/10/2023&#39; &#39;自我辞职&#39; &#39;Ana&#39; &#39;10,000&#39; &#39;IT&#39;
&#39;05/12/2024&#39; &#39;自我辞职&#39; &#39;John&#39; &#39;9,000&#39; &#39;空白&#39;
&#39;03/01/2023&#39; &#39;自我辞职&#39; &#39;Niel&#39; &#39;空白&#39; &#39;数据Scients&#39;
&#39;03/01/2023&#39; &#39;Self-resignation&#39; &#39;Isa&#39; &#39;10,000&#39; &#39;IT&#39;

数据库全部采用 object 格式，可能包含一些指定为“空白”的 NaN 值。
此外，我有一个数据库 df_active，其中包含活跃员工的历史记录。它包括参考日期和活跃个人的特征。这个数据库可能有同一个人的多个条目，因为他们可能已经更换了职位、获得了加薪或其他变化，所有这些都记录在相应的日期（并且他们的风险可能会随着修改而改变）。它的结构类似于下面的示例：
日期操作名称薪资职位
&#39;05/10/2023&#39; &#39;自我辞职&#39; &#39;Harry&#39; &#39;8,000&#39; &#39;数据科学家&#39;
&#39;10/10/2023&#39; &#39;自我辞职&#39; &#39;Harry&#39; &#39;10,000&#39; &#39;数据科学家&#39; # 薪资变化
&#39;05/13/2024&#39; &#39;自我辞职&#39; &#39;Emma&#39; &#39;7,000&#39; &#39;空白&#39;
&#39;08/01/2024&#39; &#39;自我辞职&#39; &#39;Diana&#39; &#39;13,000&#39; &#39;数据科学家&#39;
&#39;10/01/2024&#39; &#39;自我辞职&#39; &#39;Diana&#39; &#39;13,000&#39; &#39;IT&#39; # 职位更改

我的目标是计算在职员工的流失风险。我想到了两种方法：

根据已辞职员工的数据库创建 100 个档案，按风险从高到低（100%）进行排序，然后确定与每个在职员工最接近的档案。在职员工的风险评分将基于所创建的 100 个档案的排名。

生成一个代表员工历史中最突出特征的档案，并计算此高风险档案与在职员工档案之间的相似度。


我已经开始构建代码，但我不确定要使用哪个变量作为目标，以及解决这个问题的最佳方法是什么。
from sklearn.tree import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

columns = [&#39;Action&#39;, &#39;Name&#39;, &#39;Salary&#39;, &#39;Position&#39;]

# 转换：分类为数字
le = LabelEncoder()
for column in columns:
df_hist[coluna] = le.fit_transform(df_hist[coluna])

# 训练测试拆分
X = df_hist.drop(&#39;Action&#39;, axis=1)
y = df_hist[&#39;Action&#39;]

我该如何进行第一步来追踪流失风险最高的人的个人资料？]]></description>
      <guid>https://stackoverflow.com/questions/78925616/how-to-use-machine-learning-to-trace-the-profile-of-employees-in-a-company</guid>
      <pubDate>Wed, 28 Aug 2024 23:20:15 GMT</pubDate>
    </item>
    <item>
      <title>应用模型预测时出现属性错误[关闭]</title>
      <link>https://stackoverflow.com/questions/78921545/attribut-error-during-applying-predicition-for-the-model</link>
      <description><![CDATA[代码
arr=[[90,42,43,20.879744,82.002744,6.502985,202.935536]]
y_predict=app.predict(arr)

第二行代码错误
AttributeError: &#39;tuple&#39; 对象没有属性 &#39;predict&#39;

第二行错误是什么]]></description>
      <guid>https://stackoverflow.com/questions/78921545/attribut-error-during-applying-predicition-for-the-model</guid>
      <pubDate>Wed, 28 Aug 2024 04:31:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么ReLU是非线性激活函数？</title>
      <link>https://stackoverflow.com/questions/52446789/why-is-relu-a-non-linear-activation-function</link>
      <description><![CDATA[据我了解，在深度神经网络中，我们在应用权重 (w) 和偏差 (b) (z := w * X + b | a := g(z)) 后使用激活函数 (g)。因此，存在 (g o z) 的复合函数，激活函数使得我们的模型可以学习除线性函数之外的函数。我看到 Sigmoid 和 Tanh 激活函数使我们的模型变得非线性，但我很难看出 ReLu（从 0 和 z 中取最大值）可以使模型变得非线性...
假设每个 Z 始终为正，那么就好像没有激活函数一样...
那么为什么 ReLu 会使神经网络模型变得非线性？]]></description>
      <guid>https://stackoverflow.com/questions/52446789/why-is-relu-a-non-linear-activation-function</guid>
      <pubDate>Fri, 21 Sep 2018 15:20:20 GMT</pubDate>
    </item>
    <item>
      <title>ReLU 何时会杀死神经元？</title>
      <link>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</link>
      <description><![CDATA[我对 ReLU 死亡问题感到困惑。ReLU 只会在前向传递期间杀死神经元吗？还是在后向传递期间也会杀死神经元？]]></description>
      <guid>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</guid>
      <pubDate>Tue, 15 May 2018 11:35:06 GMT</pubDate>
    </item>
    <item>
      <title>通过机器学习从网页中提取信息</title>
      <link>https://stackoverflow.com/questions/13336576/extracting-an-information-from-web-page-by-machine-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/13336576/extracting-an-information-from-web-page-by-machine-learning</guid>
      <pubDate>Sun, 11 Nov 2012 23:27:23 GMT</pubDate>
    </item>
    </channel>
</rss>