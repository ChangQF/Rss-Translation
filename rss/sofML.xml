<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 14 May 2024 03:16:50 GMT</lastBuildDate>
    <item>
      <title>我该如何解决这个类型错误？</title>
      <link>https://stackoverflow.com/questions/78475048/how-can-i-solve-this-typeerror</link>
      <description><![CDATA[我正在研究我的第一个完整机器学习，我现在正在尝试处理原始数据，将其转换为监督学习。
在其中一个步骤中，为了重新编码数据：我使用了重新编码，然后使用了 apply 方法并通过采样字典指定不同列的聚合函数。
如下：
导入 pandas 作为 pd
从全局导入全局

#------------------------------------------------- -------------
# 转成函数
#------------------------------------------------- -------------

文件 = glob(“../../data/raw/MetaMotion/MetaMotion/*.csv”)
data_path =“../../data/raw/MetaMotion/MetaMotion”

def read_data_from_files(文件):
    
    acc_df = pd.DataFrame()
    gyr_df = pd.DataFrame()
    
    acc_set = 1
    陀螺仪设置 = 1
    
    对于文件中的 f：
        参与者 = (f.split(&quot;-&quot;)[0].replace(data_path, &quot;&quot;))[-1]
        标签 = f.split(&quot;-&quot;)[1]
        类别 = f.split(“-”)[2].rstrip(“123”).rstrip(“_MetaWear_2019”)

        df = pd.read_csv(f)
        
        df[“参与者”] = 参与者
        df[“标签”] = 标签
        df[“类别”] = 类别

        如果“加速度计”是在 f 中：
            df[“设置”] = acc_set
            acc_set =+ 1
            acc_df = pd.concat([acc_df, df])
            
        如果“陀螺仪”在 f 中：
            df[“设置”] = gyr_set
            gyr_set =+ 1
            gyr_df = pd.concat([gyr_df, df])

        
    acc_df.index = pd.to_datetime(acc_df[“纪元 (毫秒)”], 单位=“毫秒”)
    gyr_df.index = pd.to_datetime(gyr_df[“纪元 (毫秒)”], 单位=“毫秒”)
    
    del acc_df[“纪元（毫秒）”]
    del acc_df[“时间 (01:00)”]
    del acc_df[“经过时间”]

    del gyr_df[“纪元（毫秒）”]
    del gyr_df[“时间 (01:00)”]
    del gyr_df[“经过时间”]

    返回 acc_df、gyr_df


acc_df, gyr_df = read_data_from_files(文件)

#------------------------------------------------- -------------
# 合并数据集
#------------------------------------------------- -------------


data_merged = pd.concat([acc_df.iloc[:,:3], gyr_df], axis=1)
data_merged.dropna()
data_merged.info()


#重命名列
data_merged.columns = {
    “acc_x”，
    “acc_y”，
    “acc_z”，
    “gyr_x”，
    “gyr_y”，
    “gyr_z”，
    “标签”，
    “类别”，
    “参与者”，
    “设定”，
}


#------------------------------------------------- -------------
# 重新采样数据（变频）
#------------------------------------------------- -------------

# 加速度计：12.500HZ
# 陀螺仪：25.000Hz
 
采样={
    “acc_x”：“平均值”，
    “acc_y”：“平均值”，
    “acc_z”：“平均值”，
    “gyr_x”：“平均值”，
    “gyr_y”：“平均值”，
    “gyr_z”：“平均值”，
    “标签”：“最后”，
    “类别”：“最后”，
    “参与者”：“最后”，
    “设置”：“最后”，
}

(data_merged[:1000].resample(rule=“200ms”)).apply(采样)
resampled_data = data_merged[:1000].resample(rule=&quot;200ms&quot;).agg(采样, numeric_only=False)

]]></description>
      <guid>https://stackoverflow.com/questions/78475048/how-can-i-solve-this-typeerror</guid>
      <pubDate>Mon, 13 May 2024 22:37:37 GMT</pubDate>
    </item>
    <item>
      <title>Keras 卷积回归模型，始终预测相同的值</title>
      <link>https://stackoverflow.com/questions/78474230/keras-convolutional-regression-model-predicting-always-the-same-value</link>
      <description><![CDATA[目标是计算图像中较大圆圈与较小圆圈的比例。所以我希望模型返回一个浮点数。
数据集包括：

16K 图像，每张图像都包含 2 个比另一个大的圆圈。

具有更大圆圈数据的 CSV，在本例中为文件名和
比例。


问题：
该模型始终预测相同的值。
我尝试过：

标准化 0 和 1 之间的比例。
使用其他方法加载数据集。
不同的优化器和学习率

代码：
train_dir = &#39;../train/circles/&#39;
test_dir = &#39;../测试/圆圈/&#39;

IMG_SIZE = 250
批次大小 = 32

data_df = pd.read_csv(&#39;../data/circles_big.csv&#39;)
train_df = data_df[data_df[&#39;变体&#39;] == &#39;火车&#39;]
test_df = data_df[data_df[&#39;变体&#39;] == &#39;测试&#39;]

train_df = train_df[[&#39;比例&#39;, &#39;文件名&#39;]]
test_df = test_df[[&#39;比例&#39;, &#39;文件名&#39;]]

gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_generator = gen.flow_from_dataframe(
    数据框=train_df，
    目录=train_dir，
    x_col=&#39;文件名&#39;,
    y_col=&#39;比例&#39;,
    目标大小=（IMG_SIZE，IMG_SIZE），
    class_mode=&#39;原始&#39;,
    批量大小=批量大小，
    随机播放=真
）

test_generator = gen.flow_from_dataframe(
    数据框=test_df，
    目录=test_dir，
    x_col=&#39;文件名&#39;,
    y_col=&#39;比例&#39;,
    目标大小=（IMG_SIZE，IMG_SIZE），
    class_mode=&#39;原始&#39;,
    批量大小=批量大小，
    随机播放=真
）

输入 = keras.Input(形状=(IMG_SIZE, IMG_SIZE, 3))
x = groups.Conv2D(filters=32, kernel_size=3,activation=“relu”)(输入)
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 64，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 128，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 128，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Flatten()(x)
x = 层.Dense(512, 激活=“relu”)(x)
输出=层.Dense(1)(x)

模型= keras.Model（输入=输入，输出=输出）

model.compile（损失=“mse”，优化器=“adam”，指标=[“mae”]）

历史= model.fit（train_generator，epochs = 10，batch_size = 32，verbose = 1）

训练输出（我已经训练了 50 个 epoch，但没有摆脱 72.000 损失）：
344/344 [================================] - 63s 161ms/步 - 损耗：73.8999 - 前：3.7510
纪元 2/10
344/344 [==============================] - 54s 156ms/步 - 损失：72.5437 - 平均：3.7838
纪元 3/10
344/344 [================================] - 53s 153ms/步 - 损耗：72.3242 - mae：3.7979
纪元 4/10
344/344 [================================] - 53s 153ms/步 - 损耗：72.3054 - mae：3.7828
纪元 5/10
344/344 [================================] - 54s 158ms/步 - 损耗：72.2541 - mae：3.7986
纪元 6/10
344/344 [================================] - 54s 157ms/步 - 损耗：72.3650 - mae：3.7947
纪元 7/10
344/344 [================================] - 53s 155ms/步 - 损耗：72.2549 - mae：3.7982
纪元 8/10
344/344 [================================] - 55s 159ms/步 - 损耗：72.2433 - mae：3.7906
纪元 9/10
344/344 [================================] - 54s 158ms/步 - 损耗：72.2253 - mae：3.8048
纪元 10/10
344/344 [==============================] - 53s 154ms/步 - 损耗：72.2451 - mae：3.7841

现在我的问题是为什么预测总是相同的？即使模型没有经过足够的训练，它是否应该给出不同的预测值？
test_data = next(test_generator)
预测 = model.predict(test_data[0])
真实值 = 测试数据[1]

对于范围内的 i(len(预测))：
    print(f&quot;预测: {predictions[i][0]:}, 真实值: {true_value[i]:}&quot;)

输出：
1/1 [================================] - 0s 33ms/步
预测：3.8054518699645996，真实值：1.448
预测：3.8054518699645996，真实值：1.063
预测：3.8054518699645996，真实值：6.06
预测：3.8054518699645996，真实值：1.058
预测值：3.8054518699645996，真实值：2.826
预测：3.8054518699645996，真实值：3.188
预测值：3.8054518699645996，真实值：4.437
预测：3.8054518699645996，真实值：1.983
预测：3.8054518699645996，真实值：2.213
...
]]></description>
      <guid>https://stackoverflow.com/questions/78474230/keras-convolutional-regression-model-predicting-always-the-same-value</guid>
      <pubDate>Mon, 13 May 2024 18:47:00 GMT</pubDate>
    </item>
    <item>
      <title>正类是大多数类，因此很难解释结果[关闭]</title>
      <link>https://stackoverflow.com/questions/78474226/positive-class-is-the-majority-class-made-it-hard-to-interpret-result</link>
      <description><![CDATA[我正在做一个流失预测任务，其中 1 类（流失）是大多数类别。
两个类的结果
我的问题是：这个结果是类设置的结果吗（通常正类是负类）。我该如何解释上面的结果？就F1分数而言，0类和1类之间是否存在权衡？
结果中，默认的 F1 在不平衡数据集上得分更高，而我预计重采样方法会改善 F1。他们实际上为少数群体改进了 F1，但没有为多数群体改进。]]></description>
      <guid>https://stackoverflow.com/questions/78474226/positive-class-is-the-majority-class-made-it-hard-to-interpret-result</guid>
      <pubDate>Mon, 13 May 2024 18:45:18 GMT</pubDate>
    </item>
    <item>
      <title>机器学习：从哪里开始实践？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78474129/machine-learning-where-to-start-the-practice</link>
      <description><![CDATA[我正在学习机器学习和大数据方面的大学课程，即将完成（今年年底），但我们的实践很少，理论较多。
我想要一些关于我可以遵循哪些来源在机器学习领域进行实践的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78474129/machine-learning-where-to-start-the-practice</guid>
      <pubDate>Mon, 13 May 2024 18:18:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Colab 上运行 alphageometry？</title>
      <link>https://stackoverflow.com/questions/78473546/how-to-run-alphageometry-on-colab</link>
      <description><![CDATA[我正在尝试在 colab 上运行 alphageometry 但不断遇到问题：
https://colab.research.google.com/drive/1RrTfa3O80QOFL68rXdtAyn1KHt0NCCB3 ?usp=共享
下面的堆栈跟踪不包括 JAX 内部帧。
前面是发生的原始异常，未修改。
上述异常是导致以下异常的直接原因：
回溯（最近一次调用最后一次）：
  文件“/usr/lib/python3.10/runpy.py”，第 196 行，在 _run_module_as_main 中
    返回_run_code（代码，main_globals，无，
  文件“/usr/lib/python3.10/runpy.py”，第 86 行，在 _run_code 中
    执行（代码，run_globals）
  文件“/content/alphageometry/alphageometry.py”，第651行，在&lt;module&gt;中。
    应用程序.运行（主要）
  文件“/usr/local/lib/python3.10/dist-packages/absl/app.py”，第308行，运行中
    _run_main（主要，参数）
  文件“/usr/local/lib/python3.10/dist-packages/absl/app.py”，第 254 行，在 _run_main 中
    sys.exit(主(argv))
  文件“/content/alphageometry/alphageometry.py”，第 637 行，在 main 中
    模型 = get_lm(_CKPT_PATH.value, _VOCAB_PATH.value)
  文件“/content/alphageometry/alphageometry.py”，第 203 行，get_lm
    返回 lm.LanguageModelInference(vocab_path, ckpt_init, mode=&#39;beam_search&#39;)
  文件“/content/alphageometry/lm_inference.py”，第 62 行，位于 __init__ 中
    (tstate, _, imodel, prngs) = trainer.initialize_model()
  文件“/content/alphageometry/meliad_lib/meliad/training_loop.py”，第 367 行，initialize_model
    变量 = model_init_fn(init_rngs, imodel.get_fake_input())
  文件“/content/alphageometry/models.py”，第 68 行，在 __call__ 中
    自解码器（
  文件“/content/alphageometry/meliad_lib/meliad/transformer/decoder_stack.py”，第 273 行，在 __call__ 中
    嵌入 = embeddings.astype(self.dtype)
  文件“/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/lax_numpy.py”，第 4952 行，在 _astype 中
    dtypes.check_user_dtype_supported(dtype, “astype”)
类型错误：JAX 仅支持数字和布尔数据类型，在 astype` 中获取数据类型 bfloat16

这就是它停止的地方：
!python -m alphageometry \
--alsologtostderr \
--problems_file=$(pwd)/examples.txt \
--problem_name=正交中心 \
--mode=alpha几何 \
--defs_file=$(pwd)/defs.txt \
--rules_file=$(pwd)/rules.txt \
--ckpt_path=$数据\
  --vocab_path=$DATA/geometry.757.model \
  --gin_search_paths=$MELIAD_PATH/transformer/configs,$(pwd) \
  --gin_file=base_htrans.gin \
  --gin_file=大小/medium_150M.gin \
  --gin_file=选项/positions_t5.gin \
  --gin_file=选项/lr_cosine_decay.gin \
  --gin_file=选项/seq_1024_nocache.gin \
  --gin_file=geometry_150M_generate.gin \
  --gin_param=DecoderOnlyLanguageModelGenerate.output_token_losses=True \
  --gin_param=TransformerTaskConfig.batch_size=$BATCH_SIZE \
  --gin_param=TransformerTaskConfig.sequence_length=128 \
  --gin_param=Trainer.restore_state_variables=False \
  --beam_size=$BEAM_SIZE \
  --search_深度=$深度\

到目前为止，有人设法让它在 Colab 中运行吗？我在网上没有找到任何相关内容。
我按照 git 上提供的教程进行操作，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/78473546/how-to-run-alphageometry-on-colab</guid>
      <pubDate>Mon, 13 May 2024 16:12:04 GMT</pubDate>
    </item>
    <item>
      <title>高 MSE 和负 R 平方值的原因 [已迁移]</title>
      <link>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78472866/reason-for-high-mse-and-negative-r-square-value</guid>
      <pubDate>Mon, 13 May 2024 14:10:35 GMT</pubDate>
    </item>
    <item>
      <title>预测社交媒体参与率的最佳机器学习模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</link>
      <description><![CDATA[根据你们的意见，哪个模型是预测社交媒体（例如 Facebook）中参与度帖子的最佳模型。
如果你们中有人遇到过同样的情况，请分享一下您的经验
谢谢
我尝试了这两个：

线性回归（11% 准确度）

LightGBM 回归器（准确度 79%）

]]></description>
      <guid>https://stackoverflow.com/questions/78472788/best-machine-learning-model-to-predict-engagement-rate-on-social-media</guid>
      <pubDate>Mon, 13 May 2024 13:59:37 GMT</pubDate>
    </item>
    <item>
      <title>为什么二元分类中非 sigmoid 变换输出比 sigmoid 变换输出更匹配目标矩阵？</title>
      <link>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</link>
      <description><![CDATA[我正在使用神经网络进行二元分类任务，其中模型输出 logits，然后通过 sigmoid 函数将其映射到概率。目标矩阵是一个 17x17 网格，其中距中心曼哈顿距离 &lt;=2 内的单元格标记为 1（正类），所有其他单元格标记为 0（负类）：
目标矩阵
这是损失的代码。我使用 binary_cross_entropy_with_logits 作为我的损失函数。 sigmoid函数在pytorch提供的上述函数中实现：
defforward（自身，输入，目标）：
    pos_mask =（目标== 1）
    neg_mask =（目标== 0）
    pos_num = pos_mask.sum().float()
    neg_num = neg_mask.sum().float()
    重量 = target.new_zeros(target.size())
    权重[pos_mask] = 1 / pos_num
    权重[neg_mask] = 1 / neg_num * self.neg_weight
    重量 /= 重量.sum()
    返回 F.binary_cross_entropy_with_logits(
        输入，目标，权重，减少=&#39;总和&#39;）

然后我可视化训练模型的输出，并注意到一个意想不到的现象。可视化显示了两张图像：一张是模型直接输出的 logits（左），另一张是通过对这些 logits 应用 sigmoid 函数获得的概率（右）。令人惊讶的是，与 sigmoid 变换输出（概率）相比，非 sigmoid 变换输出（logits）似乎更好地匹配目标矩阵的模式。
可视化
这个结果令人费解，因为在训练过程中，损失函数对 sigmoid 变换后的概率进行运算。因此，人们会期望 sigmoid 变换的输出更接近目标矩阵。
这种行为背后是否存在解释或常见原因，即原始逻辑在视觉上比从其派生的概率更准确地匹配目标结构？我可能缺少任何可能影响此外观的可视化或缩放因素吗？
我在网上搜索过，但似乎没有与我类似的问题。我仔细检查了 binary_cross_entropy_with_logits 中是否存在 sigmoid 函数：
labels = self._create_labels(responses.size())
loss = self.criterion(responses, labels) # 标准：binary_cross_entropy_with_logits

_responses = torch.sigmoid(responses)
_loss = self._criterion(_responses, labels) # 标准：binary_cross_entropy

但是，在我的实验中，loss 等于 _loss，这意味着虽然是 sigmoided 响应尝试拟合目标矩阵，但非 sigmoided 响应却拟合目标矩阵目标矩阵更好。
&lt;小时/&gt;
如果您想了解有关该项目的更多详细信息，请参阅以下描述。我正在使用 SiamFC 重现一个对象跟踪项目，可视化 siamfc 中第 171 行的响应图-pytorch/siamfc/siamfc.py，作为反应图，反映第一帧中的groundtruth目标与后续帧中的搜索区域之间的相似性。您可以在项目中下载预训练的模型，插入一些代码进行可视化并运行代码查看结果。]]></description>
      <guid>https://stackoverflow.com/questions/78472692/why-does-the-non-sigmoid-transformed-output-match-the-target-matrix-more-closely</guid>
      <pubDate>Mon, 13 May 2024 13:45:05 GMT</pubDate>
    </item>
    <item>
      <title>如何创建我自己的自定义输入器以在 pyspark.ml 管道中无缝输入常量值</title>
      <link>https://stackoverflow.com/questions/78472581/how-to-create-my-own-custom-imputter-to-input-constant-values-seamlessly-in-pysp</link>
      <description><![CDATA[我想通过 CV 搜索来优化数据集上缺失值的插补。这在我熟悉的 sklearn 中是微不足道的——但是，我是第一次使用集群分布式 Spark 数据帧，并且必须使用 pyspark.ml 模块。
据我所知， pyspark.ml.feature.Imputer 类无法估算（选择）常量值，这是我想测试的一件事。
您建议我如何执行此操作？我研究了编写一个自定义转换器，这在 sklearn API 中也很容易，但我还没有在 pyspark.ml 中找到明确的方法来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78472581/how-to-create-my-own-custom-imputter-to-input-constant-values-seamlessly-in-pysp</guid>
      <pubDate>Mon, 13 May 2024 13:26:04 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林模型的多目标预测</title>
      <link>https://stackoverflow.com/questions/78471569/multi-objective-prediction-using-random-forest-model</link>
      <description><![CDATA[以下是实际流程

原始混凝土配合比的实验数据为1000块，采用的算法模型为随机森林回归模型。

以下代码用于创建模型、训练模型、预测目标值和优化 Optuna。


通过多重预测多个输出项时如何优化参数，使RMSE拟合值接近0输入项目？ 
RMSE的拟合指数为27.781625571862275。]]></description>
      <guid>https://stackoverflow.com/questions/78471569/multi-objective-prediction-using-random-forest-model</guid>
      <pubDate>Mon, 13 May 2024 10:17:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 YOLOv5 标记对象的正确方法</title>
      <link>https://stackoverflow.com/questions/78471070/correct-way-to-tag-objects-with-yolov5</link>
      <description><![CDATA[我需要标记一系列图像以用于织物上的缝纫检测。我使用 YOLOv5 算法。
我遇到的问题是，我不清楚标记这些缝纫的最佳方式应该是什么。
下图显示了织物中的缝线。

正如您在图片中看到的，缝线总是会占据布料的整个宽度。最初，我曾想过对缝纫的几个部分/部分进行标记（检测到的缝纫数量并不重要，对我来说真正重要的是它检测到至少有一个缝纫）。下图展示了这个想法：

但是，我不清楚这是否是正确的方法（而是最佳方法），或者应该创建一个完全包围缝纫的单个标签。
另一方面，根据文档中给出的标签提示，标签应该恰好包围要检测的对象，在对象和标签的边界框之间留出尽可能小的空间。
&lt;块引用&gt;
标签准确性。标签必须紧密包围每个对象。没有空间
应该存在于对象与其边界框之间。没有物体
应该缺少标签。

获得最佳训练结果的提示
在这种特殊情况下，考虑到缝线总是以非常相似的方式出现（它们总是具有水平方向），这些标签将非常薄（高度很小），因此不清楚我认为该算法将能够检测到它们。以我的拙见，我认为稍微增加标签的高度将使算法更有效地检测缝纫，因为通过这些缝纫连接的织物可能具有相同的颜色。 （第二张图片显示了我正在谈论的想法）。
如果您能帮助我并告诉我进行此标记的最佳方法，我将不胜感激。
提前非常感谢您。]]></description>
      <guid>https://stackoverflow.com/questions/78471070/correct-way-to-tag-objects-with-yolov5</guid>
      <pubDate>Mon, 13 May 2024 08:48:35 GMT</pubDate>
    </item>
    <item>
      <title>MLPerf Docker 容器</title>
      <link>https://stackoverflow.com/questions/78419544/mlperf-docker-container</link>
      <description><![CDATA[我正在尝试复制 MLPerf 任务，但无法弄清楚他们想要哪个 Docker 容器。我对 Docker 的经验很少；我错过了什么？
情况是这样的：MLPerf 是一组机器学习基准。我对图像分类训练任务感兴趣。他们所有训练任务的参考实现可在 https://github.com/mlcommons/training/ 获取tree/master，特别是 install_cuda_docker。 sh 脚本。
但是，我找不到任何对我应该获取的 docker 容器的引用。 MLCommons（生产 MLPerf 的组织）拥有一系列 docker 容器，但没有一个描述似乎合适。 （最接近的是图像分割 docker 图像，但是（1）这是一个不同的问题，（2）它是为 PyTorch 构建的，但我知道参考图像分类代码使用 TensorFlow。我还偶然发现了对 inference&lt; 的引用/em&gt; 容器，但想必这些也不适合训练。）
顺便说一句，其他一些训练任务目录（例如rnn_speech_recognition或graph_neural_network）包含Dockerfile，但图像分类目录中没有Dockerfile。]]></description>
      <guid>https://stackoverflow.com/questions/78419544/mlperf-docker-container</guid>
      <pubDate>Thu, 02 May 2024 13:37:09 GMT</pubDate>
    </item>
    <item>
      <title>学习曲线是否表明过度拟合或模型性能处于可接受的水平？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78411015/does-the-learning-curve-suggest-overfitting-or-an-acceptable-level-of-model-perf</link>
      <description><![CDATA[
学习曲线是否表明模型性能过度拟合或处于可接受的水平？结果基于xgboost。我需要重新调整超参数吗？如果是的话，如何调整超参数？目前，我使用 scikit-optimize 中的 BayesSearchCV 来自动调整超参数。我的搜索空间是
from skopt.space import Real, Integer
search_spaces = {&#39;learning_rate&#39;: Real(0.0001, 0.04, &#39;统一&#39;),
                 &#39;最大深度&#39;: 整数(2, 20),
                 &#39;子样本&#39;: Real(0.1, 1.0, &#39;均匀&#39;),
                 &#39;colsample_bytree&#39;: Real(0.1, 1.0, &#39;uniform&#39;), # 按树的列子样本比例
                 &#39;reg_lambda&#39;: Real(1e-9, 100., &#39;uniform&#39;), # L2 正则化, 默认 = 0
                 &#39;reg_alpha&#39;: Real(1e-9, 100., &#39;uniform&#39;), # L1 正则化, 默认 = 0
                 &#39;n_estimators&#39;: Integer(100, 3000), # boosting 轮数或决策树数
                 &#39;min_child_weight&#39;: Real(2, 8, &#39;统一&#39;),
                 &#39;伽玛&#39;：真实（0.1，0.9，&#39;均匀&#39;）
}
]]></description>
      <guid>https://stackoverflow.com/questions/78411015/does-the-learning-curve-suggest-overfitting-or-an-acceptable-level-of-model-perf</guid>
      <pubDate>Tue, 30 Apr 2024 21:03:33 GMT</pubDate>
    </item>
    <item>
      <title>ARIMA 可以在 Python 中获取输入序列吗？</title>
      <link>https://stackoverflow.com/questions/78027259/can-arima-take-input-sequence-in-python</link>
      <description><![CDATA[在Python中，当你训练LSTM模型时，你可以在部分数据上训练模型。然后在推理时，您可以为其提供任何您喜欢的输入，例如不属于训练集的 10 个最近时间步长。它将产生输出。现在 ARIMA 可以以同样的方式运行吗？我们可以给它输入序列吗？或者它是否使用训练数据来预测下一步？
下面是我的代码：
导入 pandas 作为 pd
从 statsmodels.tsa.arima.model 导入 ARIMA
进口火炬
导入系统
导入数学

# 从CSV文件中读取数据集
df = pd.read_csv(&#39;sm_data.csv&#39;, header=None)

# 将前102行作为训练数据，其余作为测试数据
train_data = df.iloc[:102,:]
test_data = df.iloc[102:, :]


# 迭代每个趋势
预测结果 = {}
对于 df.columns 中的列：
    # 在训练数据上拟合 ARIMA 模型
    模型 = ARIMA(train_data[列], 顺序=(10,1,0))
    model_fit = model.fit()

    # 预测未来 36 个月
    预测 = model_fit.forecast(步数=36)

    # 存储预测结果
    Forecast_results[列] = 预测

# 将预测结果转换为DataFrame
Forecast_df = pd.DataFrame(forecast_results)

# 将预测结果保存到 CSV
Forecast_df.to_csv(&#39;forecast_results.csv&#39;, index=False)
]]></description>
      <guid>https://stackoverflow.com/questions/78027259/can-arima-take-input-sequence-in-python</guid>
      <pubDate>Tue, 20 Feb 2024 12:16:51 GMT</pubDate>
    </item>
    <item>
      <title>控制 Scikit Learn 中逻辑回归的阈值</title>
      <link>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</link>
      <description><![CDATA[我在高度不平衡的数据集上使用 scikit-learn 中的 LogisticRegression() 方法。我什至将 class_weight 功能设置为 auto。
我知道在逻辑回归中应该可以知道特定类对的阈值是多少。 
是否可以知道 LogisticRegression() 方法设计的每个一对一类的阈值是多少？
我在文档页面中没有找到任何内容。
默认情况下，无论参数值如何，它是否都会应用 0.5 值作为所有类的阈值？]]></description>
      <guid>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</guid>
      <pubDate>Wed, 25 Feb 2015 10:11:33 GMT</pubDate>
    </item>
    </channel>
</rss>