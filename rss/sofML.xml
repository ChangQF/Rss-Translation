<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 27 Jan 2024 21:11:26 GMT</lastBuildDate>
    <item>
      <title>将拥抱脸部音频分类器转换为 TFLite 格式</title>
      <link>https://stackoverflow.com/questions/77892732/convert-hugging-face-audio-classifier-to-tflite-format</link>
      <description><![CDATA[我正在制作一个在 Android 手机上运行的模型，它将能够识别一组特定的音频命令。有 6 个命令，所以我需要一个包含 7 个类的分类器，每个命令一个，加上一个用于任何无法识别的类。
为此，我首先使用 facebook/wav2vec2-base，并在每个命令类包含 1000 个示例的数据集上对其进行训练，另外还有 2000 个包含“无法识别”单词的示例。分类器表现出色。
TFLite 似乎是将模型移植到 Android 上的最佳方式，因此使用 optimization 将其导出为 TFLite 格式（optimum-cli export tflite --task audio-classification ...）。这并不容易，因为一开始它失败并出现错误 KeyError: “tflite 后端尚不支持 wav2vec2 (tf_wav2_vec2_for_sequence_classification)。仅支持 [&#39;onnx&#39;]。如果您想支持 tflite，请提出 PR 或提出问题。”。
最终我将其导出到 onnx，然后导出到 tf，最后导出到 TFLite。该模型太大，约 500MB，因此我使用动态量化将其缩小到约 100MB。整数量化确实弄乱了模型，所以我将其保留为动态量化。
我想将该模型与更简单的模型进行比较，但是 wav2vec2 没有任何“小”或“微小”变体。相反，我使用了 Whisper，它旨在用于 ASR（而非分类），使用 openai/whisper-tiny 变体。使用 transformers.WhisperForAudioClassification 加载它，因为分类是我的目标，并在同一数据集上对其进行了微调。尽管体积小得多（30MB），但它的性能优于第一个模型 - 太棒了。
尝试将此模型（用于分类的微调 Whisper 模型）导出到 TFLite 时出现问题：

直接导出到 TFLite（optimum-cli export tflite --task audio-classification ...）不起作用，因为任务 audio-classification 只能识别 Wav2Vec2。因此，将它用于 Whisper 模型会引发 ValueError: Unrecognized configuration class 对于这种 AutoModel：TFAutoModelForAudioClassification。模型类型应为 Wav2Vec2Config 之一。推测的解释：Whisper 本质上是 ASR，而不是分类器。
导出到 ONNX（optimum-cli export onnx --task audio-classification ...）不起作用，因为 ValueError：要求导出任务音频的耳语模型 -分类，但 Optimum ONNX 导出器仅支持特征提取、过去特征提取、自动语音识别、耳语自动语音识别等任务。请使用支持的任务。如果您希望 ONNX 导出耳语支持任务音频分类，请在 https://github.com/huggingface/optimum/issues 上提出问题。

对于如何让这个模型在 Android 上运行有什么建议吗？我是 Android 机器学习新手，所以也许我遗漏了一些明显的东西。我试图解释一些背景和迄今为止我所尝试的内容，并提供详细信息，以防有人提出实现我的目标的更好方法的建议。任何想法都非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/77892732/convert-hugging-face-audio-classifier-to-tflite-format</guid>
      <pubDate>Sat, 27 Jan 2024 20:36:25 GMT</pubDate>
    </item>
    <item>
      <title>机器学习平台[关闭]</title>
      <link>https://stackoverflow.com/questions/77892428/machine-learning-platforms</link>
      <description><![CDATA[我是 ML 世界的新手，但我一直在使用 Microsoft Azure 环境及其现成的模型训练、测试和部署环境。
我已经成功找到了预测模型的选项和算法：多个特征作为输入，单个变量作为输出。
例如，给定一个人的：(a) 工作范围、(b) 年龄、(c) 体重，我构建的系统能够预测（正确/错误）该人是否应该执行练习“E1”。 
现在，从技术上讲，人们可以训练 20 个与此类似的模型，并使用有关练习“E2”、“E3”等的“SINGLE”二进制输出。
但是，我觉得必须有一种更简单的方法。
这样，为了训练模型，我会为其提供一个 CSV 文件，每个场景/人一行：
第一人：“数据录入员”，24 岁，100 磅 ==&gt; E1 是，E2 否，E3 是
第二个人：“按摩师”，45岁，168磅==&gt; E1 是，E2 是，E3 否
等等...
我向亲爱的社区成员提出的问题是：
什么算法/环境最适合此类任务？ （也许 Microsoft Azure 不是最好的？）
请注意，我希望无需任何编码即可执行上述设置、培训、测试和部署。
我不介意未来所有这些的编码版本；但目前我喜欢学习在无代码环境中执行此操作。
提前非常感谢，
我第一次尝试 AzureMl，但无法通过使用 Azure ML 中的自动化 Ml 功能获得多输出预测模型。我最终部署了一个仅能够预测分类模型的目标值之一的模型。]]></description>
      <guid>https://stackoverflow.com/questions/77892428/machine-learning-platforms</guid>
      <pubDate>Sat, 27 Jan 2024 19:02:14 GMT</pubDate>
    </item>
    <item>
      <title>线性回归均方根误差</title>
      <link>https://stackoverflow.com/questions/77892345/linear-regression-rmse</link>
      <description><![CDATA[尝试比较不同多项式次数的均方根误差，但最终得到相同的 RMSE。
train_rmse_errors=[]
test_rmse_errors=[]
对于范围（1,20）内的 d：
poly_converter = PolynomialFeatures（度= d，include_bias = False）
poly_fearures = poly_converter.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.33, random_state=42)
模型=线性回归()
model.fit(X_train,y_train)

train_pred = model.predict(X_train)
test_pred = model.predict(X_test)

train_rmse = np.sqrt(mean_squared_error(y_train,train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test,test_pred))

train_rmse_errors.append(train_rmse)
test_rmse_errors.append(test_rmse)
]]></description>
      <guid>https://stackoverflow.com/questions/77892345/linear-regression-rmse</guid>
      <pubDate>Sat, 27 Jan 2024 18:38:33 GMT</pubDate>
    </item>
    <item>
      <title>在 Flask 框架中集成 ML 模型时似乎无法解决此错误</title>
      <link>https://stackoverflow.com/questions/77892140/cant-seem-to-solve-this-error-while-integrating-a-ml-model-in-a-flask-framework</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77892140/cant-seem-to-solve-this-error-while-integrating-a-ml-model-in-a-flask-framework</guid>
      <pubDate>Sat, 27 Jan 2024 17:33:27 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：使用高斯贝叶斯和高斯朴素贝叶斯对点进行分类时，操作数无法与形状 (1,13) (14,) 一起广播</title>
      <link>https://stackoverflow.com/questions/77892117/valueerror-operands-could-not-be-broadcast-together-with-shapes-1-13-14-wh</link>
      <description><![CDATA[我正在尝试对此数据集中的数据点进行分类：https: //sharon.srworkspace.com/ml/datasets/hw1/wine.data.csv。我几乎从头开始在 Python 中使用高斯贝叶斯和高斯朴素贝叶斯分类器。因此，在模型的训练测试拆分之后，我实现了这些函数来对数据点进行分类：
将 numpy 导入为 np
从 scipy.stats 导入 multivariate_normal

def Classify_point_gaussian_bayes(x):
    类 = np.unique(y)
    可能性= []
    
    对于类中的 c：
        类数据 = 数据[y == c]
        先验 = len(class_data) / len(数据)
        平均值 = np.mean(class_data, axis=0)
        cov = np.cov(class_data.T)
                
        可能性= multivariate_normal.pdf(x_reshape,mean=mean,cov=cov,allow_singular=True)
        likelihoods.append(先验 * 可能性)
    
    返回类别[np.argmax(可能性)]

def Classify_point_gaussian_naive_bayes(x):
    类 = np.unique(y)
    可能性= []
    
    对于类中的 c：
        类数据 = 数据[y == c]
        先验 = len(class_data) / len(数据)
        平均值 = np.mean(class_data, axis=0)
        var = np.var(class_data, 轴=0)
                
        可能性= multivariate_normal.pdf(x_reshape,mean=mean,cov=np.diag(var),allow_singular=True)
        likelihoods.append(先验 * 可能性)
    
    返回类别[np.argmax(可能性)]

然后我必须查看这两种方法的测试精度，我以这种形式进行：
&lt;前&gt;&lt;代码&gt;res = []
对于 idx，枚举中的 test_point(X_test.values)：
    res.append(classify_point_gaussian_bayes(test_point) == y_test[idx])
print(f&#39;高斯贝叶斯的测试精度为 {res.count(True)/len(res)}&#39;)

分辨率=[]
对于 idx，枚举中的 test_point(X_test.values)：
    res.append(classify_point_gaussian_naive_bayes(test_point) == y_test[idx])
print(f&#39;高斯朴素贝叶斯的测试精度为 {res.count(True)/len(res)}&#39;)

但我仍然遇到同样的错误：ValueError：操作数无法与形状 (1,13) (14,) 一起广播。
&lt;小时/&gt;
更具体地说：
ValueError Traceback（最近一次调用最后一次）
单元格 In[42]，第 3 行
      1 资源 = []
      2 对于 idx，enumerate(X_test.values) 中的 test_point：
----&gt; 3 res.append(classify_point_gaussian_bayes(test_point) == y_test[idx])
      4 print(f&#39;高斯贝叶斯的测试精度为 {res.count(True)/len(res)}&#39;)
      6 资源 = []

单元格 In[41]，第 21 行
     18 # 重塑 x 使其具有与平均值相同数量的特征
     19 x_reshape = x.reshape(1, -1)
---&gt; 21 可能性 = multivariate_normal.pdf(x_reshape,mean=mean,cov=cov,allow_singular=True)
     22likelihoods.append(先验*可能性)
     24 个返回类别[np.argmax(likelihoods)]

文件c：\ Users \ User \ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ scipy \ stats \ _multivariate.py：583，在multivariate_normal_gen.pdf中（self，x，mean，cov，allow_singular）
    第581章
    第582章
--&gt;第583章
    第584章
    第585章

文件c：\ Users \ User \ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ scipy \ stats \ _multivariate.py：526，在multivariate_normal_gen._logpdf（self，x，mean，cov_object）中
    507“”“”多元正态概率密度函数的对数。
    508
    第509章 参数
   （...）
    第523章
    第524章
    第525章
--&gt; 526 dev = x - 平均值
    第527章1：
    第528章

ValueError：操作数无法与形状 (1,13) (14,) 一起广播

由于这是一个关于维度的问题，我尝试在两个函数中使用此行调整函数作为参数的 x 数据点的大小：x_reshape = x.reshape(1, -1)甚至：x_reshape = x.reshape(-1)。
但它不起作用，仍然给我带来与上面相同的错误。]]></description>
      <guid>https://stackoverflow.com/questions/77892117/valueerror-operands-could-not-be-broadcast-together-with-shapes-1-13-14-wh</guid>
      <pubDate>Sat, 27 Jan 2024 17:26:09 GMT</pubDate>
    </item>
    <item>
      <title>如何阻塞 OCDNet 管道并仅在 OCRNet 上获取结果？ （NVIDIA 光学字符检测和识别解决方案/OCDR）</title>
      <link>https://stackoverflow.com/questions/77892097/how-to-block-the-ocdnet-pipeline-and-get-the-result-only-on-ocrnet-nvidia-opti</link>
      <description><![CDATA[我正在 Jetson 上本地运行 NVIDIA 光学字符检测和识别解决方案。我想阻止 OCDNet 的管道，只使用 OCRNet 进行推断。我注释掉了所有与 OCDNet 相关的代码。结果是空洞的推论。]]></description>
      <guid>https://stackoverflow.com/questions/77892097/how-to-block-the-ocdnet-pipeline-and-get-the-result-only-on-ocrnet-nvidia-opti</guid>
      <pubDate>Sat, 27 Jan 2024 17:22:01 GMT</pubDate>
    </item>
    <item>
      <title>我无法运行二元期权机器人</title>
      <link>https://stackoverflow.com/questions/77892067/i-can-not-run-a-binary-option-bot</link>
      <description><![CDATA[我正在使用这个 git hub 存储库
https://github.com/ItamarRocha/binary-bot
当我运行 pip install -rrequirements.txt 时
我收到此错误
&lt;前&gt;&lt;代码&gt;

E:\binary-bot&gt;pip install -r requests.txt
收集 iqoptionapi@ git+git://github.com/Lu-Yi-Hsun/iqoptionapi.git@e96ba2c5
b905a139a4765167b08c5df48cf57773 来自 git+git://github.com/Lu-Yi-Hsun/iqoptionap
i.git@e96ba2c5b905a139a4765167b08c5df48cf57773（来自 -rrequirements.txt（第 1 行
））
  克隆 git://github.com/Lu-Yi-Hsun/iqoptionapi.git （修订版 e96ba2c5b905a
139a4765167b08c5df48cf57773) 到 c:\users\pars\appdata\local\temp\pip-install-fq4
i3vho\iqoptionapi
  运行命令 git clone -q git://github.com/Lu-Yi-Hsun/iqoptionapi.git &#39;C:\U
sers\pars\AppData\Local\Temp\pip-install-fq4i3vho\iqoptionapi&#39;
  致命：无法从远程存储库读取。

  请确保您拥有正确的访问权限
  并且存储库存在。
错误：命令出错，退出状态为 128：git clone -q git://github.com/L
u-Yi-Hsun/iqoptionapi.git &#39;C:\Users\pars\AppData\Local\Temp\pip-install-fq4i3vho
\iqoptionapi&#39; 检查日志以获取完整的命令输出。
警告：您正在使用 pip 版本 19.2.3，但版本 23.3.2 可用。
您应该考虑通过“python -m pip install --upgrade pip”通讯进行升级
和。

E:\binary-bot&gt;

如果您能帮助我，那就太好了。
我尝试使用 pip install -rrequirements.txt 安装该要求
但它给出了错误]]></description>
      <guid>https://stackoverflow.com/questions/77892067/i-can-not-run-a-binary-option-bot</guid>
      <pubDate>Sat, 27 Jan 2024 17:11:34 GMT</pubDate>
    </item>
    <item>
      <title>使用 Torchio 对两个图像应用完全相同的变换</title>
      <link>https://stackoverflow.com/questions/77892019/apply-the-exact-same-transformation-to-two-images-using-torchio</link>
      <description><![CDATA[我想使用 torchio 对两个图像（图像和分割数据）应用完全相同的转换。这两个图像都存储在名为 image_data 和 segmentation_data 的 numpy 数组中。
到目前为止，我添加了一些增强功能：
self.augmentations = tio.Compose([
            仿射变换，
            弹性变换，
            翻转变换，
            交换变换
        ]）

例如， elastic_transform = tio.RandomElasticDeformation 并尝试通过以下方式将它们应用到图像：
 subject_image = tio.Subject(image=tio.ScalarImage(tensor=image_data))
        subject_segmentation = tio.Subject(
            图像=tio.ScalarImage(张量=segmentation_data))
        数据集 = tio.SubjectsDataset([subject_image, subject_segmentation])
        数据集 = self.augmentations(数据集)
        image_data = 数据集[0][&#39;image&#39;].data
        分段数据 = 数据集[1][&#39;图像&#39;].data

不幸的是，这是不正确的（因为 Compose 无法与主题数据集一起使用），但我找不到任何有关如何正确执行此操作的信息。有人可以帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/77892019/apply-the-exact-same-transformation-to-two-images-using-torchio</guid>
      <pubDate>Sat, 27 Jan 2024 16:57:43 GMT</pubDate>
    </item>
    <item>
      <title>Java 使用 weka 库使用 Weka API 对一些 arff 文件运行随机森林分类</title>
      <link>https://stackoverflow.com/questions/77891962/java-using-the-weka-library-to-run-random-forest-classification-on-some-arff-fil</link>
      <description><![CDATA[我编写了一些代码来执行 10 倍交叉验证，然后最终通过 weka 运行随机森林算法。然而，我有很多文件需要通过 Weka 运行，因此一直在尝试使用 Weka API 并遵循其文档。
我正在努力遵循/创造一些按照我想要的方式工作的东西。
这是我到目前为止所做的代码：
for(int i = 0; i &lt; 阈值.length; i++)
{
    //学习集和有效集的副本
    ArrayList&gt; learnSetCopy = new ArrayList&lt;&gt;(learnSet);
    ArrayList&gt; validSetCopy = new ArrayList&lt;&gt;(validSet);
                
    //二值化化学蛋白质相互作用值
    binarizeCpiAttributes(learnSetCopy, 阈值[i]);
    //生成要通过Weka运行的Arff文件
    generateARFF(文件名 + “LearningThreshold” + 阈值[i] + “Fold” + j + “.arff”, attributeNames, learnSetCopy);

    binarizeCpiAttributes(validSetCopy, 阈值[i]);
    generateARFF(文件名 + “ValidThreshold” + 阈值[i] + “Fold” + j + “.arff”, attributeNames, validSetCopy);
                
    //创建学习和有效arff文件的实例
    实例learningInstances = DataSource.read(fileName + &quot;LearningThreshold&quot; + Threshold[i] + &quot;Fold&quot; + j + &quot;.arff&quot;);
    实例 validInstances = DataSource.read(fileName + &quot;ValidThreshold&quot; + Threshold[i] + &quot;Fold&quot; + j + &quot;.arff&quot;);
                
    //设置学习和有效集的类标签
    if(learningInstances.classIndex() == -1)
    {
        LearningInstances.setClassIndex(learningInstances.numAttributes()-1);
    }

    if(validInstances.classIndex() == -1)
    {
        validInstances.setClassIndex(validInstances.numAttributes()-1);
    }
                
    //初始化随机森林分类器
    RandomForest cls = new RandomForest();
    cls.buildClassifier(learningInstances);

    评估 eval = 新评估(learningInstances);
    eval.evaluateModel(cls​​, validInstances);


    System.out.println(“处理阈值：”+threshold[i]);
}

我想做的是：

在某个折叠上以某个阈值初始化两个arff文件，即学习的arff文件和有效的arff文件

将类标签设置为 arff 文件中的最后一个属性

通过 Weka 对学习 arff 文件运行随机森林分类，然后将该模型应用于有效的 arff 文件

输出生成的 ROC 面积值。


这里还有一张图片，展示了如果我通过 GUI 进行操作的话我会做什么（如果有帮助的话）：
Weka GUI 示例
我尝试通读下载 Weka API 的 jar 文件时提供的文档，以将其实现为 java 代码。]]></description>
      <guid>https://stackoverflow.com/questions/77891962/java-using-the-weka-library-to-run-random-forest-classification-on-some-arff-fil</guid>
      <pubDate>Sat, 27 Jan 2024 16:40:59 GMT</pubDate>
    </item>
    <item>
      <title>我有我的自定义训练模型（best.pt），它检测人和车头灯两件事。现在我想要根据这些条件输出</title>
      <link>https://stackoverflow.com/questions/77891961/i-have-my-custom-trained-model-best-pt-it-detects-two-things-person-and-headl</link>
      <description><![CDATA[你能帮我一下吗......
我有我的自定义训练模型（best.pt），它检测人和车头灯两件事。现在我想要根据以下条件输出： 1. 如果模型仅检测到车头灯返回 0, 2. 如果模型仅检测到人返回 1, 3. 如果模型检测到车头灯和人都返回 0。
&lt;前&gt;&lt;代码&gt;导入cv2
从 ultralytics 导入 YOLO

video_path = &#39;数据/video1.mp4&#39;
video_out_path = &#39;输出.mp4&#39;

cap = cv2.VideoCapture(video_path)

# 检查视频文件是否打开成功
如果不是 cap.isOpened():
    print(“错误：无法打开视频文件。”)
    出口（）

ret, 框架 = cap.read()

# 检查第一帧是否读取成功
如果不转：
    print(“错误：无法读取视频的第一帧。”)
    出口（）

cap_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*&#39;MP4V&#39;), cap.get(cv2.CAP_PROP_FPS),
                          (int(cap.get(3)), int(cap.get(4)))) # 使用 cap.get(3) 和 cap.get(4) 获取宽度和高度

模型 = YOLO(“bestall5.pt”)

检测阈值 = 0.5
休息时：
    结果列表=模型（框架）

    检测到头灯=假
    检测到的人=假

    # 遍历结果列表
    对于 results_list 中的结果：
        # 检查当前结果是否具有必要的属性
        if hasattr(结果, &#39;xyxy&#39;):
            对于 results.xyxy 中的结果：
                x1, y1, x2, y2, 分数, class_id = result.tolist()
                x1, x2, y1, y2 = int(x1), int(x2), int(y1), int(y2)

                # 假设class_id是模型类列表中类的索引
                类名=模型.名称[类id]

                if class_name == “车头灯”且分数&gt;检测阈值：
                    检测到头灯=真
                elif class_name == &quot;人&quot;;且分数&gt;检测阈值：
                    检测到的人 = True

    # 根据指定条件输出
    如果检测到头灯和检测到人：
        输出=0
    elif headlight_Detected：
        输出=0
    elif person_Detected：
        输出=1
    别的：
        输出 = -1 # 未检测到人或前灯

    print(“输出：”, 输出)

    cap_out.write(帧)

    cv2.imshow(&#39;物体检测&#39;,frame)
    
    # 如果按下“q”键则中断循环
    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
        休息

    ret, 框架 = cap.read()

cap.release()
cap_out.release()
cv2.destroyAllWindows()

我尝试了这个，但只得到 -1 作为输出，但我的视频既有车头灯又有人物]]></description>
      <guid>https://stackoverflow.com/questions/77891961/i-have-my-custom-trained-model-best-pt-it-detects-two-things-person-and-headl</guid>
      <pubDate>Sat, 27 Jan 2024 16:40:44 GMT</pubDate>
    </item>
    <item>
      <title>机器学习和人工智能[关闭]</title>
      <link>https://stackoverflow.com/questions/77891866/machine-learning-and-artificial-intelligence</link>
      <description><![CDATA[1.机器学习和人工智能，这两个概念是互补的吗？
2.上述概念我们将走向何方？
3.为什么机器学习被视为神经科学？
4.是否有任何算法可用于处理能够缓解太阳放射性射线导致的全球变暖危机的机器？
我正在进行一项研究，以寻找上述问题的解决方案]]></description>
      <guid>https://stackoverflow.com/questions/77891866/machine-learning-and-artificial-intelligence</guid>
      <pubDate>Sat, 27 Jan 2024 16:09:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么随机森林无法预测模型中的高值（稀有值）？</title>
      <link>https://stackoverflow.com/questions/77891522/why-the-random-forest-can-not-predict-the-high-values-rare-values-in-my-model</link>
      <description><![CDATA[我最近开始使用随机森林，并且遇到了一个问题：模型无法预测大部分数据的值。相反，尽管模型没有表现出过度拟合的迹象，但预测值似乎保持不变。任何见解或建议将不胜感激。

我希望模型也能够预测稀有数据？]]></description>
      <guid>https://stackoverflow.com/questions/77891522/why-the-random-forest-can-not-predict-the-high-values-rare-values-in-my-model</guid>
      <pubDate>Sat, 27 Jan 2024 14:24:26 GMT</pubDate>
    </item>
    <item>
      <title>使用 sympy 时消除格式字符串冲突</title>
      <link>https://stackoverflow.com/questions/77891386/get-rid-of-format-string-conflict-when-using-sympy</link>
      <description><![CDATA[我正在学习用于机器学习的 Python 编码。当我尝试使用 sympy 求损失函数的导数时，它会与格式字符串发生冲突。
将 numpy 导入为 np
将 sympy 导入为 sp

def 预测（X，w，b）：
    返回 np.dot(X, w) + b

def 损失(X, w, b, Y):
    返回 np.mean((预测(X, w, b) - Y) ** 2)

X, Y = np.loadtxt(“code/02_first/pizza.txt”，unpack=True，skiprows=1)

# 将 X 和 Y 转换为 sympy 符号
X, w, b, Y = sp.symbols(“X w b Y”)

def 梯度(X, w, b, Y):
    loss_expr = 损失(X, w, b, Y)
    dw_dX = sp.diff(loss_expr, w)
    db_dX = sp.diff(loss_expr, b)
    返回 dw_dX, db_dX

def train(X, Y, 迭代, lr):
    w = sp.symbols(&#39;w&#39;)
    b = sp.symbols(&#39;b&#39;)
    
    对于范围内的 i（迭代）：
        损失值 = 损失(X, w, b, Y)
        print(f&quot;迭代: {i:4d}, 损失: {loss_value:.10f}&quot;)
        dw_dX, db_dX = 梯度(X, w, b, Y)
        w -= dw_dX * lr
        b -= db_dX * lr
    返回w,b

w, b = 训练(X, Y, 迭代=20000, lr=0.001)

print(f&quot;\nw = {w:.10f}, b = {b:.10f}&quot;)
print(f&quot;预测: x = 20 ==&gt; y = {predict(20, w, b):.2f}&quot;)

类型错误：传递给 Pow.__format__ 的格式字符串不受支持

数据以 txt 形式存在（或通过链接此处&lt; /a&gt;):
预订披萨
13 33
2 16
14 32
23 51
13 27
1 16
18 34
10 17
26 29
3 15
3 15
21 32
7月22日
22 37
2 13
27 44
6 16
10 21
18 37
15 30
9 26
26 34
8月23日
15 39
10 27
21 37
5 17
6 18
13 25
13 23

我可以只使用numpy，但这样做我需要自己计算损失函数，这不是有效的（并且很容易用括号引发错误）。
如果您能解释该错误以及为什么 sympy 与格式字符串不兼容，我们将不胜感激。另外，如何使用 sympy 生成正确的脚本？
提前非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77891386/get-rid-of-format-string-conflict-when-using-sympy</guid>
      <pubDate>Sat, 27 Jan 2024 13:35:43 GMT</pubDate>
    </item>
    <item>
      <title>如何将对象检测数据集转换为 Tensorflow 数据集</title>
      <link>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</link>
      <description><![CDATA[我正在尝试使用 keras 在张量流上建立一个对象检测模型，但我一直遇到困难。我自动执行了查找训练图像的边界框的任务（训练数据集是游戏的），然后将所有内容转储到包含与其相关的所有数据的 .csv 文件中：对象出现的帧、边界框的坐标、和对象的类。即使同一帧上出现多个边界框，每个边界框在数据集上都有不同的行。
我正在尝试使用此函数将我的数据集导入 Tensorflow：
def Data_Loader(annotation_file):
    数据=pd.read_csv（注释文件）
    data_groups=data.groupby(&#39;文件名&#39;)

    数据集={&#39;images&#39;:[],&#39;bounding_boxes&#39;:[]}
    ngroups=data_groups.ngroups

    对于 image_name，data_groups 中的组：

        BBoxes={&#39;类&#39;:[],&#39;盒子&#39;:[]}
        对于 _，group.iterrows() 中的行：
            BBoxes[&#39;boxes&#39;].append(Get_BBOX(行))
            BBoxes[&#39;classes&#39;].append(class_ids.index(row[&#39;class&#39;]))

       
        数据集[&#39;bounding_boxes&#39;].append(tf.data.Dataset.from_tensor_slices(BBoxes))
        图像=load_img(图像名称,(224, 224))
        数据集[&#39;images&#39;].append(tf.constant(image))
 

    数据集=tf.data.Dataset.from_tensor_slices(数据集)

    返回（数据集）


以下是边界框的加载方式：
def Get_BBOX(行):
    xmin=int(行[&#39;xmin&#39;])
    ymin=int(行[&#39;ymin&#39;])
    xmax=int(行[&#39;xmax&#39;])
    ymax=int(行[&#39;ymax&#39;])

    bbox=np.array([xmin, ymin, xmax, ymax])

    返回bbox


图像加载如下：
def load_img(文件名, target_size):
    img = tf.keras.utils.load_img(文件名, target_size=target_size)
    img = tf.keras.utils.img_to_array(img)

    返回（图片）


我正在使用 Keras 的本教程来指导自己
但是每当我到达教程中将地图应用于数据的部分时，我都会收到以下错误消息：
“_VariantDataset”对象不可下标

有人知道我可能做错了什么以及如何解决它吗？
我多次尝试进行多次类型转换，从包含列表的字典更改为字典列表和所有其他类型的内容。这些都没有产生任何结果。]]></description>
      <guid>https://stackoverflow.com/questions/77891268/how-to-convert-object-detection-dataset-into-tensorflow-dataset</guid>
      <pubDate>Sat, 27 Jan 2024 12:55:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么在小数据集上微调 MLP 模型，仍然保持与预训练权重相同的测试精度？</title>
      <link>https://stackoverflow.com/questions/77885918/why-finetuning-mlp-model-on-a-small-dataset-still-keeps-the-test-accuracy-same</link>
      <description><![CDATA[我设计了一个简单的 MLP 模型，在 6k 数据样本上进行训练。
类 MLP(nn.Module)：
    def __init__(自身,input_dim=92,hidden_​​dim=150,num_classes=2):
        超级().__init__()
        self.input_dim = input_dim
        self.num_classes = num_classes
        self.hidden_​​dim = 隐藏_dim
        #self.softmax = nn.Softmax(dim=1)

        self.layers = nn.Sequential(
            nn.Linear(self.input_dim, self.hidden_​​dim),
            ReLU(),
            nn.Linear(self.hidden_​​dim, self.hidden_​​dim),
            ReLU(),
            nn.Linear(self.hidden_​​dim, self.hidden_​​dim),
            ReLU(),
            nn.Linear(self.hidden_​​dim, self.num_classes),

        ）

    def 前向（自身，x）：
        x = self.layers(x)
        返回x

并且模型已实例化
model = MLP(input_dim=input_dim,hidden_​​dim=hidden_​​dim,num_classes=num_classes).to(设备)

优化器= Optimizer.Adam(model.parameters(),lr=learning_rate,weight_decay=1e-4)
标准 = nn.CrossEntropyLoss()

和超参数：
num_epoch = 300 # 200e3//len(train_loader)
学习率 = 1e-3
批量大小 = 64
设备 = torch.device(“cuda”)
种子 = 42
火炬.manual_seed(42)

我的实现主要遵循这个问题。我将模型保存为预训练权重 model_weights.pth。
测试数据集上模型的准确率为96.80%。
然后，我还有另外 50 个样本（在 finetune_loader 中），我正在尝试在这 50 个样本上微调模型：
model_finetune = MLP()
model_finetune.load_state_dict(torch.load(&#39;model_weights.pth&#39;))
model_finetune.to（设备）
model_finetune.train()
# 训练网络
对于 t in tqdm(范围(num_epoch))：
  对于 i，enumerate(finetune_loader, 0) 中的数据：
    #def 闭包():
      # 获取并准备输入
      输入、目标 = 数据
      输入，目标=输入.float(), 目标.long()
      输入，目标 = 输入.to(设备), 目标.to(设备)
      
      # 将梯度归零
      优化器.zero_grad()
      # 执行前向传递
      输出 = model_finetune(输入)
      # 计算损失
      损失=标准（输出，目标）
      # 执行向后传递
      loss.backward()
      #回波损耗
      优化器.step() # a

model_finetune.eval()
使用 torch.no_grad()：
    输出2 = model_finetune(测试数据)
    #predicted_labels =outputs.squeeze().tolist()

    _, preds = torch.max(输出2, 1)
    Prediction_test = np.array(preds.cpu())
    准确度测试微调 = 准确度得分（y_测试，预测测试）
    精度测试微调
    
    输出：0.9680851063829787

我检查过，精度与将模型微调到 50 个样本之前保持不变，并且输出概率也相同。
可能是什么原因？我在微调代码中是否犯了一些错误？]]></description>
      <guid>https://stackoverflow.com/questions/77885918/why-finetuning-mlp-model-on-a-small-dataset-still-keeps-the-test-accuracy-same</guid>
      <pubDate>Fri, 26 Jan 2024 11:32:05 GMT</pubDate>
    </item>
    </channel>
</rss>