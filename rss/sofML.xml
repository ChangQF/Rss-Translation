<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 30 Dec 2024 21:15:25 GMT</lastBuildDate>
    <item>
      <title>SVM 调优过程：由 `vectbl_recycle_rhs_rows()` 中的错误引起：</title>
      <link>https://stackoverflow.com/questions/79318610/svm-tuning-process-caused-by-error-in-vectbl-recycle-rhs-rows</link>
      <description><![CDATA[我是 tidymodels 的新用户。
我来这里是因为我不理解 SVM 模型调优过程的输出。
这是我的代码。
basic_recipe &lt;-
recipe(target ~ 
loan_type + New_versus_Repeat + 
Total_Amount + Total_Amount_to_Repay +
disbursement_date + due_date + duration +
Amount_Funded_By_Lender + Lender_portion_Funded + Lender_portion_to_be_repaid, 
data = train) |&gt;
step_string2factor(loan_type, levels = all_loan_type) |&gt;
step_string2factor(New_versus_Repeat, levels = all_new_versus_repeat) |&gt;
step_other(贷款类型，阈值 = 0.1 / 100) |&gt;
step_date(all_date()) |&gt;
step_log(持续时间，总金额，总还款金额，贷款人资助金额，贷款人待偿还部分，基数 = 10，偏移量 = 0.001) |&gt;
step_normalize(总金额，总还款金额，贷款人资助金额，贷款人待偿还部分，贷款人待偿还部分，na_rm = TRUE) |&gt;
step_cut(持续时间，中断 = ggplot_build(p)$data[[1]]$x) |&gt;
step_dummy(loan_type, New_versus_Repeat, duration, one_hot = TRUE)

svm_model &lt;-
svm_rbf(mode = &quot;classification&quot;, cost = tune(), rbf_sigma = tune()) |&gt;
set_engine(&quot;kernlab&quot;)

control_gd &lt;- control_grid(
verbose = TRUE,
save_pred = FALSE,
parallel_over = &quot;everything&quot;
)

set.seed(1)

svm_wf &lt;-
working() |&gt;
add_model(svm_model) |&gt;
add_recipe(basic_recipe)

svm_grid &lt;-
grid_regular(
cost(),
rbf_sigma(),
levels = c(3, 3)
)

svm_tune &lt;- 
svm_wf |&gt;
tune_grid(
resamples = folds,
grid = svm_grid,
metrics = metrics,
control = control_gd
)

这是第一次重新采样的输出 Resample01
Resample01：预处理器 1/1
✓ Resample01：预处理器 1/1
i Resample01：预处理器 1/1，模型 1/9
! Resample01：预处理器 1/1，模型 1/9：变量 `&#39; 常量。无法缩放数据。
✓ Resample01：预处理器 1/1，模型 1/9
i Resample01：预处理器 1/1，模型 1/9（提取）
i Resample01：预处理器 1/1，模型 1/9（预测）
x Resample01：预处理器 1/1，模型 1/9（预测）：
`$&lt;-` 中出现错误：
！分配的数据 `orig_rows` 必须与现有数据兼容。
✖ 现有数据有 6456 行。
✖ 分配的数据有 6492 行。
ℹ 仅回收大小为 1 的向量。
由 `vectbl_recycle_rhs_rows()` 中的错误导致：
！无法将大小为 6492 的输入回收到大小为 6456 的输入。
i Resample01：预处理器 1/1
✓ Resample01：预处理器 1/1
i Resample01：预处理器 1/1，模型 2/9
! Resample01：预处理器 1/1，模型 2/9：变量 `&#39; 常量。无法缩放数据。
✓ Resample01：预处理器 1/1，模型 2/9
i Resample01：预处理器 1/1，模型 2/9（提取）
i Resample01：预处理器 1/1，模型 2/9（预测）
x Resample01：预处理器 1/1，模型 2/9（预测）：
`$&lt;-` 中出现错误：
! 分配的数据 `orig_rows` 必须与现有数据兼容。
✖ 现有数据有 6456 行。
✖ 分配的数据有 6492 行。
ℹ 仅回收大小为 1 的向量。
由 `vectbl_recycle_rhs_rows()` 中的错误引起：
！无法将大小为 6492 的输入回收为大小为 6456。


我不明白这些错误。
有人能帮我理解吗？我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/79318610/svm-tuning-process-caused-by-error-in-vectbl-recycle-rhs-rows</guid>
      <pubDate>Mon, 30 Dec 2024 20:59:42 GMT</pubDate>
    </item>
    <item>
      <title>如何在基础数据集上提高机器学习的能力？</title>
      <link>https://stackoverflow.com/questions/79318363/how-to-improve-machine-learning-on-basic-data-set</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79318363/how-to-improve-machine-learning-on-basic-data-set</guid>
      <pubDate>Mon, 30 Dec 2024 18:46:42 GMT</pubDate>
    </item>
    <item>
      <title>测试图像是否符合指南[关闭]</title>
      <link>https://stackoverflow.com/questions/79317677/test-if-image-is-compliant-to-guideline</link>
      <description><![CDATA[我正在尝试建立一个模型来确定产品图像是否合规（例如，图像应该有背景，图像不应放置在图像的边缘）。指南相当长，图像不合规的原因可能太多，因此不可能逐一解决不合规的原因。我正在寻找某种整体解决方案。
鉴于图像和文本的进步，我想有一些现成的工具可以进行微调。如果有人能在这里提供一些见解，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/79317677/test-if-image-is-compliant-to-guideline</guid>
      <pubDate>Mon, 30 Dec 2024 13:02:30 GMT</pubDate>
    </item>
    <item>
      <title>带有 JPA 和 vectorscale 的 Java：SQL 错误 [42704]：错误：类型“vectorscale”不存在</title>
      <link>https://stackoverflow.com/questions/79317642/java-with-jpa-and-vectorscale-sql-error-42704-error-type-vectorscale-does</link>
      <description><![CDATA[我正在使用基于 Postgres 的扩展 vectorscale 构建原型 ML 系统。操作如下：
我使用 docker 镜像 timescale/timescaledb-ha:pg17

我创建了一个用于嵌入的表：
CREATE TABLE IF NOT EXISTS products.products_embedding (
embedding_id int8 NOT NULL PRIMARY KEY,
&quot;text&quot; varchar(255),
embedding vector(3072),
metadata json
);

我安装了 vectorscale 扩展：
CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;


一切运行正常，我可以看到创建的扩展：
SELECT * 
FROM pg_extension; - 列出了我的 `vectorscale` 和 `vector` 扩展

现在，当我尝试使用 Java JPA 存储库查询数据库时，如下所示：
@Query(nativeQuery = true, value = &quot;SELECT * FROM products.products_embedding ORDER BY embedding &lt;=&gt; cast(&#39;[:embedding]&#39; as vectorscale) LIMIT :limit&quot;)
List&lt;ProductsEmbedding&gt; findByEmbedding(List&lt;Float&gt; embedding, int limit);

，以下错误让我大吃一惊：
SQL 错误 [42704]：错误：类型 &quot;vectorscale&quot;不存在
如果我在 Postgres 中进行简单查询，我会得到相同的结果：
SELECT *
FROM products.argos_products_embedding
ORDER BY embedding &lt;=&gt; cast (&#39;[0.002165521029382944,..(truncated for brievety)..]&#39; as vectorscale)
LIMIT 10;

为什么找不到扩展？
顺便说一句，如果我尝试，它会起作用
SELECT *
FROM products.argos_products_embedding
ORDER BY embedding &lt;=&gt; cast (&#39;[0.002165521029382944,..(truncated for brievety)..]&#39; as vector)
LIMIT 10;

我之前在同一个容器上安装了“vector扩展，我相信 vectorscale 是建立在vector 之上的”，所以它在 Postgres 中可以工作。
但它在 Java 中仍然不起作用：
@Query(nativeQuery = true, value = &quot;SELECT * FROM products.products_embedding ORDER BY embedding &lt;=&gt; cast(&#39;[:embedding]&#39; as vector) LIMIT :limit&quot;)
List&lt;ProductsEmbedding&gt; findByEmbedding(List&lt;Float&gt; embedding, int limit);

仍然中断并抱怨 ERROR: type \&quot;vector\&quot;不存在\n 位置：95
请问您知道为什么只有一半的时间可以找到扩展吗？]]></description>
      <guid>https://stackoverflow.com/questions/79317642/java-with-jpa-and-vectorscale-sql-error-42704-error-type-vectorscale-does</guid>
      <pubDate>Mon, 30 Dec 2024 12:46:58 GMT</pubDate>
    </item>
    <item>
      <title>如何解决我的欺诈检测模型在随机森林中 100% 准确率的问题？[关闭]</title>
      <link>https://stackoverflow.com/questions/79317583/how-do-i-resolve-100-accuracy-on-random-forest-for-my-fraud-detection-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79317583/how-do-i-resolve-100-accuracy-on-random-forest-for-my-fraud-detection-model</guid>
      <pubDate>Mon, 30 Dec 2024 12:28:47 GMT</pubDate>
    </item>
    <item>
      <title>PGVectorscale：无法创建索引 SQL 错误 [XX000]：错误：断言失败：meta_page.get_num_dimensions_to_index() > 0 && <= 2000</title>
      <link>https://stackoverflow.com/questions/79317581/pgvectorscale-failure-to-create-index-sql-error-xx000-error-assertion-faile</link>
      <description><![CDATA[我正在使用基于 Postgres 的扩展 vectorscale 构建原型 ML 系统。操作如下：
我使用 docker 镜像 timescale/timescaledb-ha:pg17

我创建了一个用于嵌入的表：
CREATE TABLE IF NOT EXISTS products.products_embedding (
embedding_id int8 NOT NULL PRIMARY KEY,
&quot;text&quot; varchar(255),
embedding vector(3072),
metadata json
);

我安装了 vectorscale 扩展：
CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;


一切运行正常，我可以看到创建的扩展：
SELECT * 
FROM pg_extension; - 列出了我的 `vectorscale` 扩展

现在，根据文档，当我尝试创建索引时，如下所示：
CREATE INDEX argos_products_embedding_idx ON products.products_embedding 
USING diskann (embedding) WITH(num_neighbors=20);

，以下错误让我大吃一惊：
SQL 错误 [XX000]：错误：断言失败：meta_page.get_num_dimensions_to_index() &gt; 0 &amp;&amp; meta_page.get_num_dimensions_to_index() &lt;= 2000
我尝试了 10 到 100 之间的所有 num_neighbours 值，但仍然出现相同的错误。
有什么帮助吗？
更大的问题是：PgVector 上的向量搜索速度很慢，因此我尝试使用索引来加快速度。除了使用我正在做的方法之外，还有什么更好的方法可以实现这一目标吗？]]></description>
      <guid>https://stackoverflow.com/questions/79317581/pgvectorscale-failure-to-create-index-sql-error-xx000-error-assertion-faile</guid>
      <pubDate>Mon, 30 Dec 2024 12:26:56 GMT</pubDate>
    </item>
    <item>
      <title>SGDRegressor 图与 LinearRegressor 有很大不同</title>
      <link>https://stackoverflow.com/questions/79317350/sgdregressor-graph-looking-so-different-from-linearregression</link>
      <description><![CDATA[使用 ggplot2 的“经济学”数据集研究线性回归。
为什么我的 SGDRegression 图表看起来像这样？
x = df.loc[:,&#39;pce&#39;].values.reshape(-1,1)
y = df.loc[:,&#39;psavert&#39;].values.reshape(-1,1)
来自 sklearn.model_selection 导入 train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2)
来自 sklearn.linear_model 导入 SGDRegressor
sr = SGDRegressor(eta0 = 0.001, verbose = 1)
sr.fit(x_train,y_train.flatten())
plt.scatter(x_train,y_train, s = 5, alpha = 0.3, c = &#39;blue&#39;)
plt.plot(x_train,sr.predict(x_train), c = &#39;green&#39;)
plt.xlabel(&#39;pce(billions)&#39;)
plt.ylabel(&#39;saving rate&#39;)
plt.show()

SGD 图表
线性回归图表
尝试调整 eta0 或 max_iter，但不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/79317350/sgdregressor-graph-looking-so-different-from-linearregression</guid>
      <pubDate>Mon, 30 Dec 2024 10:35:23 GMT</pubDate>
    </item>
    <item>
      <title>mlagents-learn --help 出现错误（python=3.11、3.10、3.9、3.8）</title>
      <link>https://stackoverflow.com/questions/79316958/mlagents-learn-help-is-giving-errors-python-3-11-3-10-3-9-3-8</link>
      <description><![CDATA[我正在尝试安装 mlagents。我进入了 python 部分，但在使用 pyenv 创建虚拟环境并将本地版本设置为 3.10、3.9 和 3.8 后，它们都不起作用。我升级了 pip，安装了 mlagents，然后安装了 torch、torchvision 和 torchaudio。然后我测试了 mlagents-learn --help，然后因为错误安装了 protobuf 3.20.3。然后我再次测试，得到以下错误
(venv) D:\Unity\AI Ecosystem&gt;mlagents-learn --help
回溯（最近一次调用）：
文件“&lt;frozen runpy&gt;”，第 198 行，在 _run_module_as_main
文件“&lt;frozen runpy&gt;”，第 88 行，在 _run_code
文件“D:\Unity\AI Ecosystem\venv\Scripts\mlagents-learn.exe\__main__.py”，第 4 行，在 &lt;module&gt;
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\trainers\learn.py”，第 2 行，在 &lt;module&gt;
从 mlagents 导入 torch_utils
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\torch_utils\__init__.py”，第 1 行，位于 &lt;module&gt;
从 mlagents.torch_utils.torch 导入 torch 作为 torch # noqa
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\torch_utils\torch.py​​”，第 6 行，位于 &lt;module&gt;
从 mlagents.trainers.settings 导入 TorchSettings
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\trainers\settings.py”，第 644 行，位于 &lt;module&gt;
class TrainerSettings(ExportableSettings):
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\trainers\settings.py”，第 667 行，位于 TrainerSettings
cattr.register_structure_hook(
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\cattr\converters.py”，第 207 行，位于 register_structure_hook
self._structure_func.register_cls_list([(cl, func)])
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\cattr\dispatch.py​​”，第 55 行，位于 register_cls_list
self._single_dispatch.register(cls, handler)
文件&quot;C:\Users\Ebrah\AppData\Local\Programs\Python\Python311\Lib\functools.py&quot;，第 864 行，在寄存器中
raise TypeError(
TypeError: `register()` 的第一个参数无效。 typing.Dict[mlagents.trainers.settings.RewardSignalType, mlagents.trainers.settings.RewardSignalSettings] 不是类或联合类型。

我尝试安装 cattrs 1.5.0，但错误仍然存​​在。正如我之前所说，我也尝试了 3.11、3.10、3.9 和 3.8，但在所有这些版本中都出现了相同的错误。我的 unity 版本是 2022.3.5f1，但我看不出这会有什么不同。我的 pyenv 版本是 3.1.1。我在 Windows 11 上并且正在使用 pyenv-win。]]></description>
      <guid>https://stackoverflow.com/questions/79316958/mlagents-learn-help-is-giving-errors-python-3-11-3-10-3-9-3-8</guid>
      <pubDate>Mon, 30 Dec 2024 06:36:09 GMT</pubDate>
    </item>
    <item>
      <title>由于模拟程度高，蒙特卡洛树搜索在 1 步内失误</title>
      <link>https://stackoverflow.com/questions/79316664/monte-carlo-tree-search-blundering-mate-in-1-due-to-high-simulations</link>
      <description><![CDATA[我很难理解在 MCTS 中选择终端节点时会发生什么。我看到这里、这里和这里有几篇标题类似的帖子，但它们似乎没有解释我的难点。
假设是白棋先走，W 步虽然在下一步 B 步时失误失利，但仍被扩展，并恰好在出局时获胜。经过反向传播后，W 得分较高，因此选择一个子节点进行扩展，即 B。B 是终端节点，因此我们反向传播黑棋获胜。现在 B 得分较高。现在我看到两种可能性：

允许再次选择 B（尽管它没有子节点），在这种情况下，B 会不断积累越来越多的得分，因为它每次都赢得黑棋并继续被选中。然后 W 将成为根节点模拟程度最高的子节点，因此尽管犯了错误，但仍被选中进行游戏（我根据维基百科文章选择模拟程度最高的节点）。

我不允许再次选择 B。但我认为这会带来另一个问题。如果当前状态是在 W 步之后，并且是黑棋先行，那么黑棋只会选择 B 一次，尽管 B 赢得了比赛，但黑棋不会获胜，因为 B 的模拟次数会比其他步少。


这似乎是算法的一个非常基本的部分，所以我确信我只是错过了一些关于它如何工作的显而易见的东西。]]></description>
      <guid>https://stackoverflow.com/questions/79316664/monte-carlo-tree-search-blundering-mate-in-1-due-to-high-simulations</guid>
      <pubDate>Mon, 30 Dec 2024 02:07:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中为 Nvidia GeForce RTX 3050 Ti 启用 CUDA？</title>
      <link>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</link>
      <description><![CDATA[我想在我的显卡（Nvidia GeForce RTX 3050 Ti）上运行 PyTorch 库（我在 PyCharm 的虚拟环境中运行该库）。但是，它在 CPU 上运行，每当我使用命令 import torch 和 print(&quot;cuda is available:&quot;, torch.cuda.is_available()) 时，它总是返回 False。
我安装了 CUDA 版本 12.6。我还安装了 PyTorch for CUDA 版本 12.4，因为它是 PyTorch 网站上可用的最新版本。考虑到我的显卡类型，我应该安装什么？]]></description>
      <guid>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</guid>
      <pubDate>Thu, 07 Nov 2024 04:30:29 GMT</pubDate>
    </item>
    <item>
      <title>需要一些帮助来调试这个 java</title>
      <link>https://stackoverflow.com/questions/53719504/need-some-help-debugging-this-java</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/53719504/need-some-help-debugging-this-java</guid>
      <pubDate>Tue, 11 Dec 2018 07:44:58 GMT</pubDate>
    </item>
    <item>
      <title>如何提高随机森林多类分类模型的性能？[关闭]</title>
      <link>https://stackoverflow.com/questions/53634808/how-to-improve-performance-of-random-forest-multiclass-classification-model</link>
      <description><![CDATA[我正在研究多类别分类，根据客户的购买行为和人口统计特征将客户分为 3 个不同的类别。我无法完全披露数据集，但一般来说它包含大约 300 个特征和 50000 行。我尝试了以下方法，但无法达到 50% 以上的准确率：

调整超参数（我在执行 GridSearchCV 后使用调整后的超参数）
规范化数据集，然后运行我的模型
尝试了不同的分类方法：OneVsRestClassifier、RandomForestClassification、SVM、KNN 和 LDA
我还删除了不相关的特征并尝试运行我的模型
我的类别不平衡，所以我还尝试使用 class_weight =balanced、使用 SMOTE 进行过采样、下采样和重采样。

我还可以尝试其他方法来提高性能（f 分数、精度和召回率）吗？]]></description>
      <guid>https://stackoverflow.com/questions/53634808/how-to-improve-performance-of-random-forest-multiclass-classification-model</guid>
      <pubDate>Wed, 05 Dec 2018 14:43:07 GMT</pubDate>
    </item>
    <item>
      <title>随机森林多分类不会提高准确性</title>
      <link>https://stackoverflow.com/questions/52703577/random-forest-multi-class-does-not-improve-accuracy</link>
      <description><![CDATA[我正在制作一个随机森林多分类器模型。基本上有数百个家庭具有 200 多个特征，并且基于这些特征我必须将它们归类到其中一个类别 {1,2,3,4,5,6}。
我面临的问题是无论我怎么努力都无法提高模型的准确性。我使用过 RandomSearchCV 和 GridSearchCV，但我只能达到 68% 左右的准确率。
一些注意事项

样本点不平衡。这是按降序排列的类别顺序 {1,4,2,7,6,3}。我使用了 class_weight = &quot;balanced&quot;但它确实提高了准确度。
我尝试了 50-450 个估算器
我还计算了 f1 分数，而不仅仅是通过准确度来比较模型

你们还建议如何提高准确度/f1 分数？]]></description>
      <guid>https://stackoverflow.com/questions/52703577/random-forest-multi-class-does-not-improve-accuracy</guid>
      <pubDate>Mon, 08 Oct 2018 13:37:56 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机糟糕的结果-Python</title>
      <link>https://stackoverflow.com/questions/38685875/support-vector-machine-bad-results-python</link>
      <description><![CDATA[我正在研究 SVM 并实现了此代码，它太基础、太原始并且花费太多时间，但我只是想看看它实际上是如何工作的。不幸的是，它给了我糟糕的结果。我错过了什么？一些编码错误或数学错误？如果您想查看数据集，请在此处链接。我从 UCI 机器学习存储库中获取了它。感谢您的支持。
def hypo(x,q):
return 1/(1+np.exp(-x.dot(q)))

data=np.loadtxt(&#39;LSVTVoice&#39;,delimiter=&#39;\t&#39;);

x=np.ones(data.shape)
x[:,1:]=data[:,0:data.shape[1]-1]
y=data[:,data.shape[1]-1]

q=np.zeros(data.shape[1])
C=0.002

##均值归一化
for i in range(q.size-1):
x[:,i+1]=(x[:,i+1]-x[:,i+1].mean())/(x[:,i+1].max()-x[:,i+1].min());

对于范围（2000）内的 i：
h=x.dot(q)
对于范围（q.size）内的 j：
q[j]=q[j]-(C*np.sum( -y*np.log(hypo(x,q))-(1-y)*np.log(1-hypo(x,q))) ) + (0.5*np.sum(q**2))

对于范围（y.size）内的 i：
如果 h[i]&gt;=0：
打印 y[i],&#39;1&#39; 
否则：
打印 y[i],&#39;0&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/38685875/support-vector-machine-bad-results-python</guid>
      <pubDate>Sun, 31 Jul 2016 16:04:48 GMT</pubDate>
    </item>
    <item>
      <title>什么是logits？softmax和softmax_cross_entropy_with_logits有什么区别？</title>
      <link>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</link>
      <description><![CDATA[在 tensorflow API 文档 中，他们使用一个名为 logits 的关键字。它是什么？很多方法都是这样写的：
tf.nn.softmax(logits, name=None)

如果logits只是一个通用的Tensor输入，为什么它被命名为logits？

其次，以下两种方法有什么区别？
tf.nn.softmax(logits, name=None)
tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)

我知道tf.nn.softmax的作用，但不知道另一个。举个例子会很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</guid>
      <pubDate>Sat, 12 Dec 2015 14:03:27 GMT</pubDate>
    </item>
    </channel>
</rss>