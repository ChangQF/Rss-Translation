<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 15 May 2024 15:13:40 GMT</lastBuildDate>
    <item>
      <title>使用 Flask 时的机器学习问题</title>
      <link>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</link>
      <description><![CDATA[我有一个用于房屋预测的数据库。在这个数据集中，我有很多分类变量，因此我使用了一个热编码器，现在我有大约 40 列数据。我正在尝试为我的模型构建一个 API，尽管我无法正确传递数据来进行预测。有什么办法可以实现这一点吗？
我尝试使用每个变量并获取请求表单，然后将它们放入数组中，尽管我遇到了错误。是否可以为我编写关于如何在烧瓶中插入大数据集以便邮递员发送请求的代码？]]></description>
      <guid>https://stackoverflow.com/questions/78484656/machine-learning-issue-while-using-flask</guid>
      <pubDate>Wed, 15 May 2024 14:32:08 GMT</pubDate>
    </item>
    <item>
      <title>有什么办法可以找到音频和视频之间的同步分数。预先感谢您回答问题</title>
      <link>https://stackoverflow.com/questions/78484136/is-there-any-way-to-find-synchronization-score-between-audio-and-video-thanks-i</link>
      <description><![CDATA[假设我们有一个扩展名为 .mp4 的静音视频文件和一个扩展名为 .wav 的音频文件。有什么办法可以找到音频和视频之间的同步分数。预先感谢您回答问题。
我使用深度学习模型进行视频特征提取，并使用另一种模型进行音频特征提取。现在我已经使用欧几里德距离和相关性来检查音频和视频特征之间的相似性，但它不起作用。我希望如果两个功能相似或同步，那么输出应该接近 1，否则接近 0。]]></description>
      <guid>https://stackoverflow.com/questions/78484136/is-there-any-way-to-find-synchronization-score-between-audio-and-video-thanks-i</guid>
      <pubDate>Wed, 15 May 2024 13:00:05 GMT</pubDate>
    </item>
    <item>
      <title>如何将扩展名为 .GRD 的二进制文件转换为 r 中的 NeCDF</title>
      <link>https://stackoverflow.com/questions/78483567/how-do-i-convert-a-binary-file-with-extension-grd-to-necdf-in-r</link>
      <description><![CDATA[我有一个温度的二进制文件，扩展名为.GRD。我从 IMD 网格温度数据下载了它，分辨率为 1 度 x 1 度。 [IMD 高分辨率 1.0 × 1.0 度网格化每日温度数据（1951-2018）*。该数据排列在 31x31 网格点中。纬度 7.5N、8.5N ... 36.5、37.5（31 个值）。长 67.5E、68.5E ... 96.5、97.5（31 个值）。对于闰年，包括 366 天的数据。]
文件名示例：Maxtemp_MaxT_1955.GRD
我想先将其（二进制文件）转换为 NetCDF，然后再转换为光栅砖。由于是日数据，所以有365个栅格；我将其转换为砖块，然后每年对其进行求和，然后通过进行区域统计来获取特征多边形中的平均值。在提取数据之前，我想将栅格的分辨率从1度×1度更改为0.5度×0度。

如何在r中读取扩展名为.GRD的二进制文件并将其转换为r中的NetCDF（补充：.GRD文件是单个文件。它没有任何补充信息文件。
如何对栅格进行重新采样，使其分辨率为 r 中的 0.5 度到 0.5 度？

我尝试在 r 中读取二进制文件并将其转换为 NetCDF。但我没有取得进展。如果有人知道流程，请尽快回复。这将是一个很大的帮助。提前谢谢您。]]></description>
      <guid>https://stackoverflow.com/questions/78483567/how-do-i-convert-a-binary-file-with-extension-grd-to-necdf-in-r</guid>
      <pubDate>Wed, 15 May 2024 11:22:28 GMT</pubDate>
    </item>
    <item>
      <title>无法在 Windows 机器中安装 Python Rasa 库</title>
      <link>https://stackoverflow.com/questions/78483192/unable-to-install-python-rasa-library-in-windows-machine</link>
      <description><![CDATA[作为我使用 Python 开发聊天机器人 UI 的一部分，我尝试在 Windows 10 笔记本电脑中使用命令 pip install rasa 安装 Rasa 库模块。
我安装了 Python 版本 3.11。
但我收到以下错误：
获取构建轮的要求未成功运行。
  │ 退出代码：1
  ╰─&gt; [20行输出]
      回溯（最近一次调用最后一次）：
        文件“C:\python311\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，行
     353，在&lt;模块&gt;中
          主要的（）
    文件“C:\python311\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py”，第 335 行，
    在主要
          json_out[&#39;return_val&#39;] = hook(**hook_input[&#39;kwargs&#39;])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

想知道这个安装中缺少什么。之前，我尝试安装chatterbot模块，但也遇到了类似的错误。
我尝试过的：
尝试在 Python 中安装 Rasa 模块时，出现错误。我无法继续。
我尝试使用 pip install Rasa
另外，我也尝试使用 pip install chatterbot，但仍然出现错误。]]></description>
      <guid>https://stackoverflow.com/questions/78483192/unable-to-install-python-rasa-library-in-windows-machine</guid>
      <pubDate>Wed, 15 May 2024 10:10:42 GMT</pubDate>
    </item>
    <item>
      <title>随机森林和交叉验证</title>
      <link>https://stackoverflow.com/questions/78483176/random-forest-and-cross-validation</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78483176/random-forest-and-cross-validation</guid>
      <pubDate>Wed, 15 May 2024 10:08:38 GMT</pubDate>
    </item>
    <item>
      <title>从 CLIP 功能恢复图像的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/78482968/what-is-the-best-way-to-recover-image-from-its-clip-features</link>
      <description><![CDATA[假设我们有一个大小为 torch.Size([1, 3, 336, 336]) 的图像，并使用大小为 torch.Size([1, 577, 1024]），如何用这个潜在特征图恢复原始图像？
我尝试使用StabilityAI/stable-diffusion-2-1-unclip，它是从 sd2 中进行微调以接受图像嵌入的。但是，我发现它只需要 cls 令牌并忽略其他令牌。有什么办法可以充分利用整个嵌入吗？还是需要sd2进行微调？]]></description>
      <guid>https://stackoverflow.com/questions/78482968/what-is-the-best-way-to-recover-image-from-its-clip-features</guid>
      <pubDate>Wed, 15 May 2024 09:32:19 GMT</pubDate>
    </item>
    <item>
      <title>UNet Segmentor 仅“识别”背景类</title>
      <link>https://stackoverflow.com/questions/78482896/unet-segmentor-only-identifies-background-class</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78482896/unet-segmentor-only-identifies-background-class</guid>
      <pubDate>Wed, 15 May 2024 09:21:07 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 TensorFlow 提高多类分类的准确性？</title>
      <link>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</link>
      <description><![CDATA[我正在使用 TensorFlow 解决多类分类问题，并在实现令人满意的准确性方面遇到了挑战。我有7节课。文件夹中的每个类包含 2000 个 .csv 文件（每个文件有两列）。当我使用二元分类方法训练模型并用另一个类测试一个类时，准确性和 val_accuracy 会很高，0.85 到 0.95，但是当我使用多类进行测试时，精度最高可达0.47。下面是包含数据抛光和模型多类的代码。
#文件夹中的 csv 类
文件夹路径 = [
    &#39;/content/drive/MyDrive/medical_chem/Aa&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ab&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ac&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Ba&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Bb&#39;,
    &#39;/content/drive/MyDrive/medical_chem/Cc&#39;,
    &#39;/内容/驱动器/MyDrive/medical_chem/DD&#39;
]


数据 = []
标签=[]

#加载文件夹并将文件csv存档在数据框中
对于 enumerate(folder_paths) 中的 class_index、folder_path：
    对于 os.listdir(folder_path) 中的文件：
        file_path = os.path.join(文件夹路径, 文件)
        df = pd.read_csv(文件路径)
        数据.append(df)
        标签.append(class_index)

X = 数据
y = 标签

# 找到数据框中的最小值
min_length = min(len(df) for df in X)
# 设置数据帧长度相同
truncated_dfs = [df.head(min_length) for df in X]
# 数据帧到 numpy 数组
X = np.array([df.truncated_dfs 中 df 的值])


# 分割数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 标准化数据
X_train = 归一化(X_train, 轴=1)
X_test = 归一化(X_test, 轴=1)
y_train = to_categorical(y_train, num_classes=7)
y_test = to_categorical(y_test, num_classes=7)


X_train.shape、y_train.shape、X_test.shape、y_test.shape
# 输出 ((8943, 2906, 2), (8943, 7), (2236, 2906, 2), (2236, 7))

模型 = tf.keras.Sequential([
    tf.keras.layers.Dense(128, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(64, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(32, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(7,activation=&#39;softmax&#39;) # 7个类的输出层
]）

# 训练模型的检查点
checkpoint_path = “training_checkpoint/cp.ckpt”
checkpoint_dir = os.path.dirname(checkpoint_path)
checkpoint_callback = ModelCheckpoint(文件路径=checkpoint_path,
                                      save_weights_only=真，
                                      save_best_only=真，
                                      监视器=&#39;val_loss&#39;,
                                      详细=1)

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;分类交叉熵&#39;，
              指标=[&#39;准确性&#39;])

#model.load_weights(检查点路径)

历史 = model.fit(X_train, y_train,
                    纪元=100，
                    验证数据=（X_测试，y_测试），
                    回调=[检查点回调])


我尝试过调整神经网络的架构，尝试不同的激活函数，并优化学习率和批量大小等超参数。但是，我仍然没有达到预期的准确性。
我确信我出错的地方是在预处理数据或模型中，因为二进制训练有很好的结果。
与二进制训练相比，准确度为 0.85 至 0.95
**多类别的预期准确率：高于 0.90
**
数据集： https://drive .google.com/drive/folders/1UAt50dPH7ABeoLu16nfa19g4oVccPeFO?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78481152/how-to-enhance-accuracy-in-multi-class-classification-with-tensorflow</guid>
      <pubDate>Wed, 15 May 2024 00:27:22 GMT</pubDate>
    </item>
    <item>
      <title>Keras 卷积回归模型，始终预测相同的值</title>
      <link>https://stackoverflow.com/questions/78474230/keras-convolutional-regression-model-predicting-always-the-same-value</link>
      <description><![CDATA[目标是计算图像中较大圆圈与较小圆圈的比例。所以我希望模型返回一个浮点数。
数据集包括：

16K 图像，每张图像都包含 2 个圆圈，一个比另一个大。

具有更大圆圈数据的 CSV，在本例中为文件名和
比例。


问题：
该模型始终预测相同的值。
我尝试过的：

标准化 0 和 1 之间的比例。
使用其他方法加载数据集。
不同的优化器和学习率

代码：
train_dir = &#39;../train/circles/&#39;
test_dir = &#39;../测试/圆圈/&#39;

IMG_SIZE = 250
批次大小 = 32

data_df = pd.read_csv(&#39;../data/circles_big.csv&#39;)
train_df = data_df[data_df[&#39;变体&#39;] == &#39;火车&#39;]
test_df = data_df[data_df[&#39;变体&#39;] == &#39;测试&#39;]

train_df = train_df[[&#39;比例&#39;, &#39;文件名&#39;]]
test_df = test_df[[&#39;比例&#39;, &#39;文件名&#39;]]

gen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

train_generator = gen.flow_from_dataframe(
    数据框=train_df，
    目录=train_dir，
    x_col=&#39;文件名&#39;,
    y_col=&#39;比例&#39;,
    目标大小=（IMG_SIZE，IMG_SIZE），
    class_mode=&#39;原始&#39;,
    批量大小=批量大小，
    随机播放=真
）

test_generator = gen.flow_from_dataframe(
    数据框=test_df，
    目录=test_dir，
    x_col=&#39;文件名&#39;,
    y_col=&#39;比例&#39;,
    目标大小=（IMG_SIZE，IMG_SIZE），
    class_mode=&#39;原始&#39;,
    批量大小=批量大小，
    随机播放=真
）

输入= keras.Input（形状=（IMG_SIZE，IMG_SIZE，3））
x = groups.Conv2D(filters=32, kernel_size=3,activation=“relu”)(输入)
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 64，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 128，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Conv2D（过滤器= 128，kernel_size = 3，激活=“relu”）（x）
x = 层数.MaxPooling2D(pool_size=2)(x)
x = 层.Flatten()(x)
x = 层.Dense(512, 激活=“relu”)(x)
输出=层.Dense(1)(x)

模型= keras.Model（输入=输入，输出=输出）

model.compile（损失=“mse”，优化器=“adam”，指标=[“mae”]）

历史= model.fit（train_generator，epochs = 10，batch_size = 32，verbose = 1）

训练输出（我已经训练了 50 个 epoch，但没有摆脱 72.000 损失）：
344/344 [================================] - 63s 161ms/步 - 损耗：73.8999 - 前：3.7510
纪元 2/10
344/344 [================================] - 54s 156ms/步 - 损耗：72.5437 - mae：3.7838
纪元 3/10
344/344 [================================] - 53s 153ms/步 - 损耗：72.3242 - mae：3.7979
纪元 4/10
344/344 [================================] - 53s 153ms/步 - 损耗：72.3054 - mae：3.7828
纪元 5/10
344/344 [================================] - 54s 158ms/步 - 损耗：72.2541 - mae：3.7986
纪元 6/10
344/344 [================================] - 54s 157ms/步 - 损耗：72.3650 - mae：3.7947
纪元 7/10
344/344 [================================] - 53s 155ms/步 - 损耗：72.2549 - mae：3.7982
纪元 8/10
344/344 [================================] - 55s 159ms/步 - 损耗：72.2433 - mae：3.7906
纪元 9/10
344/344 [==============================] - 54s 158ms/步 - 损耗：72.2253 - 平均：3.8048
纪元 10/10
344/344 [==============================] - 53s 154ms/步 - 损耗：72.2451 - mae：3.7841

现在我的问题是为什么预测总是相同的？即使模型没有经过足够的训练，它是否应该给出不同的预测值？
test_data = next(test_generator)
预测 = model.predict(test_data[0])
真实值 = 测试数据[1]

对于范围内的 i(len(预测))：
    print(f&quot;预测: {predictions[i][0]:}, 真实值: {true_value[i]:}&quot;)

输出：
1/1 [================================] - 0s 33ms/步
预测：3.8054518699645996，真实值：1.448
预测：3.8054518699645996，真实值：1.063
预测：3.8054518699645996，真实值：6.06
预测：3.8054518699645996，真实值：1.058
预测：3.8054518699645996，真实值：2.826
预测：3.8054518699645996，真实值：3.188
预测：3.8054518699645996，真实值：4.437
预测：3.8054518699645996，真实值：1.983
预测：3.8054518699645996，真实值：2.213
...
]]></description>
      <guid>https://stackoverflow.com/questions/78474230/keras-convolutional-regression-model-predicting-always-the-same-value</guid>
      <pubDate>Mon, 13 May 2024 18:47:00 GMT</pubDate>
    </item>
    <item>
      <title>将分类加权损失函数集成到我的代码中后，准确性下降了[关闭]</title>
      <link>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</link>
      <description><![CDATA[我想提高准确性，并且我有不平衡数据集：akiec：229，bcc：360，bkl：769，df：81，mel：779，vasc：99。为了解决这个问题，我选择将分类加权损失机制集成到模型中。然而，尽管进行了这样的调整，我还是注意到准确性随后下降了。这个意想不到的结果让我怀疑实施过程中出现了错误。您能否帮助我识别和解决任何潜在的错误以优化模型的性能？
# 定义目录
train_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Train&#39;
test_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Test&#39;
validation_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Validation&#39;

# 确定类的数量
numClasses = len(os.listdir(train_dir))

# 定义超参数网格
参数网格 = {
    &#39;学习率&#39;：[0.001]，
    &#39;批量大小&#39;：[16]，
}

最佳准确度 = 0
最佳参数=无

# 执行网格搜索
对于 ParameterGrid(param_grid) 中的参数：
    # 为每次网格搜索迭代加载预训练的 VGG19 模型
    base_model = VGG19(权重=&#39;imagenet&#39;, include_top=False, input_shape=(224, 224, 3))
    对于 base_model.layers 中的图层：
        可训练层 = False

    # 定义函数从最后一个卷积层提取特征
    def extract_features（生成器，模型）：
        特征 = model.predict(生成器)
        返回 features.reshape((len(generator.filenames), -1))

    # 创建数据生成器
    train_datagen = 图像数据生成器(
        重新缩放=1./255，
        旋转范围=20，
        width_shift_range=0.2，
        height_shift_range=0.2，
        剪切范围=0.2，
        缩放范围=0.2，
        水平翻转=真，
        fill_mode=&#39;最近&#39;)

    validation_datagen = ImageDataGenerator（重新缩放=1./255）

    train_generator = train_datagen.flow_from_directory(
        火车目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）

    validation_generator =validation_datagen.flow_from_directory(
        验证目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）
&#39;&#39;&#39;

可能这里有一个错误

&#39;&#39;&#39;

    # 定义类索引
    类索引 = {
        &#39;基亚克&#39;: 0,
        “密件抄送”：1，
        &#39;bkl&#39;：2，
        “df”：3，
        “梅尔”：4，
        “血管”：5
    }

    ## 计算班级人数
    类计数 = {}
    对于 os.listdir(train_dir) 中的 class_name：
        class_counts[class_name] = len(os.listdir(os.path.join(train_dir, class_name)))

    # 计算类别权重
    类权重 = {}
    Total_samples = sum(class_counts.values())
    对于 class_name、class_count 在 class_counts.items() 中：
        class_weights[class_indices[class_name]] = 总样本数 / (class_count * len(class_counts))



    # 定义模型架构以接受提取的特征作为输入
    输入=输入(形状=(combined_data_train.shape[1],))
    x = 密集（256，激活=&#39;relu&#39;）（输入）
    预测=密集（numClasses，激活=&#39;softmax&#39;）（x）
    模型=模型（输入=输入，输出=预测）

    # 使用当前的超参数和类权重编译模型
    model.compile（优化器=SGD（learning_rate=params[&#39;learning_rate&#39;]），loss=&#39;sparse_categorical_crossentropy&#39;，metrics=[&#39;accuracy&#39;]，sample_weight_mode=&#39;temporal&#39;）

    # 定义提前停止
    Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

    # 通过提前停止来训练模型
    num_epochs = 50 # 您可以在此处调整纪元数
    历史=模型.fit(
        x=组合数据训练，
        y=train_generator.labels,
        纪元=num_epochs，
        批量大小=参数[&#39;批量大小&#39;],
        validation_data=(combined_data_validation,validation_generator.labels),
        回调=[early_stopping],
        类权重=类权重，
        详细=1
    ）

    model.save(&#39;best_vgg19_model_with_age.h5&#39;)

    # 根据验证数据评估模型
    _，val_accuracy = model.evaluate（combined_data_validation，validation_generator.labels，详细= 0）

    # 如有必要，更新最佳精度和最佳参数
    如果 val_accuracy &gt;最佳准确度：
        最佳准确度 = 有效准确度
        最佳参数 = 参数

# 打印最佳参数和准确度
print(&#39;最佳参数：&#39;, best_params)
print(&#39;最佳验证准确度：&#39;, best_accuracy)


# 加载最佳模型
best_model = load_model(&#39;best_vgg19_model_with_age.h5&#39;)

]]></description>
      <guid>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</guid>
      <pubDate>Thu, 09 May 2024 14:52:54 GMT</pubDate>
    </item>
    <item>
      <title>如何训练我的图像识别模型，使其像奖励惩罚系统一样工作，让我可以分辨出它无法识别的人是谁？</title>
      <link>https://stackoverflow.com/questions/78441996/how-do-i-train-my-image-recognition-model-to-work-like-a-reward-punishment-syste</link>
      <description><![CDATA[我正在研究制作考勤系统的方法，教授点击几张照片（2到3张）
并上传到应用程序，大约 80 名学生会自动出勤。我的训练数据有限，这是我们需要应对的最大缺点和主要问题。我制作了一个用于训练和标记出勤率的基本模型。
我如何训练它像奖励惩罚系统一样工作，我可以手动告诉它它无法识别的人是谁，以便它在途中学习。]]></description>
      <guid>https://stackoverflow.com/questions/78441996/how-do-i-train-my-image-recognition-model-to-work-like-a-reward-punishment-syste</guid>
      <pubDate>Tue, 07 May 2024 11:03:00 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：调用层“gan_model”时遇到异常</title>
      <link>https://stackoverflow.com/questions/78439895/valueerror-exception-encountered-when-calling-layer-gan-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78439895/valueerror-exception-encountered-when-calling-layer-gan-model</guid>
      <pubDate>Tue, 07 May 2024 02:56:21 GMT</pubDate>
    </item>
    <item>
      <title>为 Windows 11 和 AMD GPU 安装 Pytorch</title>
      <link>https://stackoverflow.com/questions/78439640/installing-pytorch-for-windows-11-and-amd-gpu</link>
      <description><![CDATA[有人可以帮我安装 Pytorch 吗？我的设备当前使用 Windows 操作系统和 AMD GPU。但是，Pytorch 安装不支持与 ROCm 组合的 Windows 操作系统。只有选择Linux操作系统时，ROCm选项才可用。
我可以使用 CUDA 工具包来替代 ROCm 吗？或者我是否可以将我的操作系统更改为Linux？有没有办法绕过所有这些并且仍然能够使用 Pytorch？
任何建议将不胜感激！
我尝试在 youtube 上寻找安装教程，但他们没有与我相同的操作系统和 GPU 组合。 （即Windows操作系统和AMD GPU）]]></description>
      <guid>https://stackoverflow.com/questions/78439640/installing-pytorch-for-windows-11-and-amd-gpu</guid>
      <pubDate>Tue, 07 May 2024 00:46:02 GMT</pubDate>
    </item>
    <item>
      <title>训练 BigGan 模型时的运行时错误和其他错误</title>
      <link>https://stackoverflow.com/questions/78437895/runtime-error-and-other-errors-while-training-biggan-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78437895/runtime-error-and-other-errors-while-training-biggan-model</guid>
      <pubDate>Mon, 06 May 2024 16:18:20 GMT</pubDate>
    </item>
    <item>
      <title>线性回归的正规方程</title>
      <link>https://stackoverflow.com/questions/49347878/normal-equation-for-linear-regression</link>
      <description><![CDATA[我有以下 X 和 y 矩阵：

为此，我想使用正规方程方法计算线性回归方程的最佳 θ 值：
theta = inv(X^T * X) * X^T * y
theta 的结果应该是：[188.400,0.3866,-56.128,-92.967,-3.737]
我通过以下方式实现这些步骤：
X=np.matrix([[1,1,1,1],[2104,1416,1534,852],[5,3,3,2],[1,2,2, 1],[45,41,30,36]])
y=np.matrix([460,232,315,178])

XT=np.转置(X)

XTX=XT.点(X)

inv=np.linalg.inv(XTX)

inv_XT=inv.dot(XT)

θ=inv_XT.dot(y)

打印（θ）

但我没有得到想要的结果。相反，它会抛出错误：

&lt;块引用&gt;
  回溯（最近一次调用最后一次）：文件“C:/”，第 19 行，位于
      theta=inv_XT.dot(y) ValueError：形状 (4,5) 和 (1,4) 未对齐：5 (dim 1) != 1 (dim 0)

我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/49347878/normal-equation-for-linear-regression</guid>
      <pubDate>Sun, 18 Mar 2018 12:28:38 GMT</pubDate>
    </item>
    </channel>
</rss>