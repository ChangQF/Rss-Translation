<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Mon, 24 Mar 2025 01:22:48 GMT</lastBuildDate>
    <item>
      <title>SoftMax功能衍生物与其Python实现有何关系？</title>
      <link>https://stackoverflow.com/questions/79529962/how-does-the-softmax-function-derivative-related-to-its-python-implementation</link>
      <description><![CDATA[ SoftMax函数的导数等于：
s_ij * delta_jk -s_ij * s_ik
其中s是SoftMax函数，i是0轴索引，j是第一个轴索引，k是校正的标签。
但是这甚至与Python代码有关？
 导入numpy作为np

softmax_output = np.array（[0.7，0.1，0.2]）。重塑（-1，1）
jacobian_matrix = np.diagflat（softmax_output）
right = np.dot（softmax_output，softmax_output.t）
结果= jacobian_matrix-对
 
 AI完全困惑，根本无法回答。
是否有人知道数学函数与这些python函数如何相关]]></description>
      <guid>https://stackoverflow.com/questions/79529962/how-does-the-softmax-function-derivative-related-to-its-python-implementation</guid>
      <pubDate>Mon, 24 Mar 2025 01:02:19 GMT</pubDate>
    </item>
    <item>
      <title>TABPFN功能选择提高了keyError（f“ [{key}]中的一个都不在[{axis_name}]中</title>
      <link>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79529836/tabpfn-feature-selection-raises-keyerrorfnone-of-key-are-in-the-axis-nam</guid>
      <pubDate>Sun, 23 Mar 2025 22:59:22 GMT</pubDate>
    </item>
    <item>
      <title>DUAT息肉细分模型未开箱即用[关闭]</title>
      <link>https://stackoverflow.com/questions/79529461/duat-polyp-segmentation-model-not-working-out-of-the-box</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79529461/duat-polyp-segmentation-model-not-working-out-of-the-box</guid>
      <pubDate>Sun, 23 Mar 2025 18:24:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么SeceentialFeaturesElector最多返回“ N_features_in_ -1”预测变量？</title>
      <link>https://stackoverflow.com/questions/79528929/why-does-sequentialfeatureselector-return-at-most-n-features-in-1-predictor</link>
      <description><![CDATA[我有一个具有六个功能的培训数据集，我正在使用 sequentialFeaturesElector 查找“最佳”线性回归模型的特征子集。以下代码返回三个功能，我将调用 x1，x2，x3 。
  sfs = sequentialFeaturesElector（linearregression（），n_features_to_select =&#39;auto&#39;， 
                                tol = 0.05，方向=&#39;正向&#39;， 
                                评分=&#39;neg_root_mean_squared_error&#39;，cv = 8）
sfs.fit_transform（x_train，y_train）
 
要检查结果，我决定使用功能的子集 x1，x2，x3 而不是 x_train 来运行相同的代码。我期望看到功能 x1，x2，x3 再次返回，但仅是功能 x1，x2 。同样，在同一代码中再次使用这两个功能仅返回 x1 。看来 sfs 的行为总是要返回输入功能的适当子集，最多使用 n_features_in_-1 列，但是我似乎无法在 scikit-learn docs 。这是正确的吗？如果是这样，不允许的理由是什么
 sfs 返回完整的功能？
我还检查了使用向后选择是否会返回完整功能集。
  sfs = sequentialFeaturesElector（linearregression（），n_features_to_select =&#39;auto&#39;， 
                                tol = 1000，方向=&#39;向后&#39;， 
                                评分=&#39;neg_root_mean_squared_error&#39;，cv = 8）
sfs.fit_transform（x_train，y_train）
 
我将阈值设置为是一个很大的值，希望从 x_train 的完整功能中没有令人满意的改进。但是，它没有返回六个原始功能，而是返回了五个。文档只是说明

如果10分在两个连续的特征添加或删除之间至少会增加分数，请停止添加或删除。

因此，在交叉验证期间似乎没有考虑完整的功能集，并且在远期选择的末尾或在向后选择的开始时， sfs 的行为是不同的。如果完整的功能超过了功能的任何适当子集，那么我们不希望 sfs 返回这种可能性吗？是否有标准方法可以比较选定的特征的适当子集以及使用交叉验证的完整功能？]]></description>
      <guid>https://stackoverflow.com/questions/79528929/why-does-sequentialfeatureselector-return-at-most-n-features-in-1-predictor</guid>
      <pubDate>Sun, 23 Mar 2025 12:16:03 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-Learn PCA与自定义PCA实现之间的符号差异[迁移]</title>
      <link>https://stackoverflow.com/questions/79528591/discrepancy-in-signs-between-scikit-learn-pca-and-custom-pca-implementation</link>
      <description><![CDATA[我正在实现自己的PCA版本，并将其与Scikit-Learn的PCA进行比较。但是，我注意到主要组件的迹象的差异。
 使用scikit-learn  
  sualer =标准尺度（）
scaled_data = scaler.fit_transform（数据）

pca_scaled = pca（n_components = 2）
PCA_SCALED.FIT（scaled_data）

principal_components = pca_scaled.components_
 
输出：
  [[0.70710678 0.70710678]
 [-0.70710678 0.70710678]]
 
 自定义PCA  
  def custom_pca（数据，num_components）：
    平均值= np.mean（数据，轴= 0）
    std = np.std（数据，轴= 0）  
    X_Standardized =（数据 - 平均） / STD

    cov_matrix = np.cov（x_standardized，rowvar = false）

    特征值，eigenVectors = np.linalg.eig（cov_matrix）

    返回特征向量
 
输出：
  [[0.70710678 -0.70710678]
 [0.70710678 0.70710678]]
 
为什么符号被翻转？
  scikit-learn：
[[0.70710678 0.70710678]
 [-0.70710678 0.70710678]]

自定义PCA：
[[0.70710678 -0.70710678]
 [0.70710678 0.70710678]]
 ]]></description>
      <guid>https://stackoverflow.com/questions/79528591/discrepancy-in-signs-between-scikit-learn-pca-and-custom-pca-implementation</guid>
      <pubDate>Sun, 23 Mar 2025 07:25:07 GMT</pubDate>
    </item>
    <item>
      <title>验证准确性和AUC不增加[关闭]</title>
      <link>https://stackoverflow.com/questions/79527674/validation-accuracy-and-auc-not-increasing</link>
      <description><![CDATA[这是我的体系结构代码：
 ＃加载预训练的InceptionResnetv2
base_model = inceptionResnetv2（weights =&#39;imagenet&#39;，include_top = false，input_shape =（300，300，3））

＃最初冻结所有层
对于base_model.layers中的图层：
    layer.trainable = false  

＃---添加具有多头注意的自定义分类头---
x = base_model.output
x = globalaveragepooling2d（）（x）
x = batchnormatorization（）（x）
x =辍学（0.3）（x）

＃---实施多头注意机制---
＃重塑以准备关注功能
x_reshaped = reshape（（1，x. shape [-1]））（x）

＃实现多头注意（3个主人）
num_heads = 3
head_outputs = []

对于我的范围（num_heads）：
 ＃每个关注头
    注意=密集（64，activation =&#39;relu&#39;，name = f&#39;attention_proctive_ {i}&#39;）（x_reshape）
    注意=密集（1，activation =&#39;tanh&#39;，name = f&#39;attention_score_ {i}&#39;）（注意）
    注意= Flatten（）（注意）
    注意_weights =激活（&#39;softmax&#39;）（注意）
    activation_weights = repotevector（x. shape [-1]）（activation_weights）
    注意_weights = permute（[2，1]）（注意_weights）
    
    ＃施加注意力
    head_output = pulty（）（[x_reshaped，coadivation_weights]）
    head_output = lambda（lambda x：k.sum（x，axis = 1））（head_output）
    head_outputs.append（head_output）

＃结合注意力头
如果num_heads＆gt; 1：
    context_vector = concatenate（）（head_outputs）
    ＃项目回到原始维度
    context_vector =致密（x. shape [-1]，activation =&#39;relu&#39;）（context_vector）
别的：
    context_vector = head_outputs [0]

＃---跳过连接---
＃添加从Globalaverate Pooling After Globalageerpooling到After Pastion之后的Skip Connection
context_vector = add（）（[context_vector，x]）

＃---带有增强正规化的最终层---
X = Gaussiannoise（0.02）（Context_Vector）
x =密集（256，activation =&#39;relu&#39;，kernel_regularizer = tf.keras.regularizers.l2（0.005））（x）
x = batchnormatorization（）（x）
x =辍学（0.3）（x）
x =密集（128，activation =&#39;relu&#39;，kernel_regularizer = tf.keras.regularizers.l2（0.005））（x）
x = batchnormatorization（）（x）
x =辍学（0.3）（x）

＃---输出层---
输出=密集（1，激活=&#39;Sigmoid&#39;）（x）

＃---创建模型---
model =模型（inputs = base_model.input，outputs =输出）

＃---编译模型---
＃添加梯度剪辑以防止爆炸梯度

优化器= ADAM（Learning_rate = 0.0001，clipnorm = 1.0）
model.compile（优化器=优化器，  
              损失=&#39;binary_crossentropy&#39;，  
              量表= [&#39;准确性&#39;，&#39;auc&#39;，&#39;precision&#39;，&#39;回忆&#39;]）

＃＃打印模型摘要
＃print（model.summary（））

＃---增强回调---
lr_scheduler = reducelronplateau（monitor =&#39;val_loss&#39;，因子= 0.5，耐心= 5，冗长= 1）
早期_STOP =早期踩踏（Monitor =&#39;Val_loss&#39;，Patience = 10，Restore_best_weights = true，verbose = 1）
checkpoint = modelCheckpoint（&#39;best_model.h5&#39;，monitor =&#39;val_auc&#39;，mode =&#39;max&#39;， 
                             save_best_only = true，详细= 1）
callbacks_list = [LR_SCHEDULER，早期_STOP，检查点]

＃---训练模型---
历史= model.fit（
    x_train，y_train， 
    时代= 70，  
    验证_data =（x_test，y_test）， 
    batch_size = 16，  
    详细= 1， 
    回调= callbacks_list
）
 
这是我的模型体系结构
数据集概述：1260个彩色图像（铁路轨道缺陷数据集），标记的数据，清洁数据集具有等量的类别（即50％有缺陷和50％的非缺陷）
图像像素已经已归一化（即在进出数据集之前[0,1]。
我尝试的是：

  lr_scheduler 余弦衰减，不工作
数据增强略微降低了性能
调整辍学，学习率和高斯噪声的值，但仍无法正常工作
微调基本模型中的后来层

验证精度在0.91-0.92之间固定，而验证AUC的验证精度并未从0.9624提高。
如何提高其性能？]]></description>
      <guid>https://stackoverflow.com/questions/79527674/validation-accuracy-and-auc-not-increasing</guid>
      <pubDate>Sat, 22 Mar 2025 15:39:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Codebert嵌入识别类似的代码零件？</title>
      <link>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</link>
      <description><![CDATA[我正在使用Codebert比较两个代码的相似性。例如：
 ＃代码1
def calculate_area（半径）：
返回3.14 *半径 *半径
 
 ＃代码2
def Compute_circle_area（R）：
返回3.14159 * r * r
 
 Codebert创建“嵌入”就像对代码的详细描述为数字。然后，我比较这些数值描述，以查看代码的相似之处。这对于告诉我多少代码是相似的。
但是，我无法分辨Codebert认为哪些部分相似。因为“嵌入”很复杂，我无法轻易看到Codebert的重点。比较逐字代码在这里不起作用。
我的问题是：我如何找出两个代码段的哪些特定部分Codebert认为相似，而不仅仅是获得一般相似性得分？
我尝试了简单的DIFF方法，但这违反了纯粹使用Codebert的目的。
我想知道是否可以单独使用Codebert。]]></description>
      <guid>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</guid>
      <pubDate>Thu, 20 Mar 2025 14:30:35 GMT</pubDate>
    </item>
    <item>
      <title>面对ModulenotFoundError：没有名为“ ragas.metrics.critique”的模块</title>
      <link>https://stackoverflow.com/questions/79512981/facing-modulenotfounderror-no-module-named-ragas-metrics-critique</link>
      <description><![CDATA[在AWS Sagemaker Jupyterlab笔记本中运行代码段时，我的错误低于错误：

 modulenotfounderror：没有名为&#39;ragas.metrics.critique&#39;的模块

 导入警告
警告。FilterWarnings（“忽略”）＃忽略与Pydantic V1到V2迁移有关的警告

来自拉加斯进口评估
从ragas.metrics导入（
    忠诚，
    答案_relevancy，
    context_recall，
    context_precision，
    context_entity_recall，
    答案_象征性，
    答案_校正
）

来自ragas.metrics.Critique Import（
有害， 
恶意， 
连贯性， 
正确性， 
简明
）

＃在此处指定指标
指标= [
        忠诚，
        答案_relevancy，
        context_precision，
        context_recall，
        context_entity_recall，
        答案_象征性，
        wonse_correctness，
        有害， 
        恶意， 
        连贯性， 
        正确性， 
        简明
    这是给出的

结果=评估（
    数据集=数据集， 
    指标=指标，
    llm = llm_for_evaluation，
    嵌入= bedrock_embeddings，
）

df = result.to_pandas（）
 
我试图通过使用命令“ PIP install ragas”来重新安装拉加斯。并且仍然面临同一问题。
当我检查ragas时，它似乎已经正确安装了。
 pip显示ragas 
 名称：ragas
版本：0.2.14
概括： 
主页： 
作者： 
作者 - 邮件： 
执照： 
位置：/opt/conda/lib/python3.11/site-packages
要求：AppDirs，数据集，Diskcache，Langchain，Langchain-Community，Langchain-core，Langchain_openai，Nest-Asyncio，Numpy，Numpy，Openai，Openai，Pydantic，Tiktoken，Tiktoken
要求： 
注意：您可能需要重新启动内核才能使用更新的软件包。
 
如何解决这个问题？
 更新----  
我能够通过安装0.1.16版本的Ragas的以下步骤来解决上述问题，但是当我运行上述代码部分时，我会收到一个新问题（如下所述）。。
％pip安装ragas == 0.1.16 

  Importerror Trackback（最近的最新通话）
[27]中的细胞17
4来自拉加斯进口评估
5来自ragas.metrics进口（
6忠诚，
7 wonse_relevancy，
（...）
12个答案_校正
13）
---＆gt; 17来自ragas.metrics.Critique Importique（
18有害，
19恶意，
20连贯性，
21正确性，
22简洁
23）
25＃在这里指定指标
26指标= [
27忠诚，
28答案_relevancy，
（...）
38简洁
39]

file/opt/conda/lib/python3.11/site-packages/ragas/metrics/critique.py:13
11来自ragas.llms.output_parser导入ragasoutputparser，get_json_format_instructions
12来自ragas.llms.prompt进口提示
---＆gt; 13摘自ragas.metrics.base Import EvaluationMode，metricwithllm
15如果t.type_checking：
16来自langchain_core.callbacks.base导入回调

Importerror：无法从&#39;ragas.metrics.base&#39;（/opt/conda/lib/python3.11/site-packages/ragas/ragas/metrics/base.py）导入名称&#39;evaluationMode&#39;
 ]]></description>
      <guid>https://stackoverflow.com/questions/79512981/facing-modulenotfounderror-no-module-named-ragas-metrics-critique</guid>
      <pubDate>Sun, 16 Mar 2025 17:49:25 GMT</pubDate>
    </item>
    <item>
      <title>如何将KERAS（H5）文件转换为TFLITE文件？</title>
      <link>https://stackoverflow.com/questions/53256877/how-to-convert-kerash5-file-to-a-tflite-file</link>
      <description><![CDATA[我有一个keras（H5）文件。我需要将其转换为tflite？
我研究了，首先我需要通过H5-&gt; pb-&gt; tflite去
（因为H5 -Tflite有时会导致某些问题）]]></description>
      <guid>https://stackoverflow.com/questions/53256877/how-to-convert-kerash5-file-to-a-tflite-file</guid>
      <pubDate>Mon, 12 Nov 2018 06:25:31 GMT</pubDate>
    </item>
    <item>
      <title>训练模型以识别句子中出现的名称</title>
      <link>https://stackoverflow.com/questions/51476682/training-a-model-to-identify-names-appearing-in-a-sentence</link>
      <description><![CDATA[我有一个数据集，其中包含大约238583人的名称。名称可以包含多个单词：例如：
  Willie Enriquez，James J Johnson，D.J。 khaled 。
 我的问题是在句子中出现这些名称时识别这些名称。我正在尝试创建一个机器学习模型，该模型可以识别输入是否为名称。我的麻烦是找出该模型的输入和输出。由于我有一堆名称，因此我可以训练一个模型，该模型可以识别输入是一个名称时的名称，但是该句子中的其他单词又如何。该模型还应该能够识别不是名称的单词。假设句子中有任何其他单词，那么为此目的的理想数据集是什么？在随机的单词上训练模型并将其标记为非名称是有意义的吗？
（名称出现的整个句子不可用。用户可以绝对键入他/她想要的任何内容）
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/51476682/training-a-model-to-identify-names-appearing-in-a-sentence</guid>
      <pubDate>Mon, 23 Jul 2018 10:30:30 GMT</pubDate>
    </item>
    <item>
      <title>比较MSE损失和跨凝结损失</title>
      <link>https://stackoverflow.com/questions/49322197/comparing-mse-loss-and-cross-entropy-loss-in-terms-of-convergence</link>
      <description><![CDATA[对于一个非常简单的分类问题，我有一个目标向量[0,0,0，.... 0]，而预测向量[0,0.1,0.2，.... 1]是否会更好/更快地收敛或MSE损失？
当我绘制它们时，在我看来，MSE损失的错误差距较低。为什么会这？
 或例如，当我将目标作为[1,1,1,1 .... 1]时，我会得到以下内容：
  ]]></description>
      <guid>https://stackoverflow.com/questions/49322197/comparing-mse-loss-and-cross-entropy-loss-in-terms-of-convergence</guid>
      <pubDate>Fri, 16 Mar 2018 13:41:01 GMT</pubDate>
    </item>
    <item>
      <title>神经网络收敛到零输出</title>
      <link>https://stackoverflow.com/questions/44213659/neural-network-converging-to-zero-output</link>
      <description><![CDATA[我正在尝试训练这个神经网络以对某些数据进行预测。
我在一个小数据集（大约100个记录）上尝试了它，它像魅力一样工作。然后，我插入了新数据集，发现NN收敛到0输出，并且错误收敛于正面示例数量和示例总数之间的比率。
我的数据集由是/否特征（1.0/0.0）组成的，地面真相是/否。
我的假设：
1）有一个本地最小值，输出0（但是我尝试了许多学习率和初始权重的值，它似乎总是在那里收敛）
2）我的体重更新是错误的（但对我来说看起来不错）
3）这只是一个输出缩放问题。我试图扩展输出（即输出/最大（输出）和输出/平均值（输出）），但是结果不如下面提供的代码中看到。我应该以不同的方式扩展它吗？ Softmax？ 
这是代码：
 将大熊猫作为pd导入
导入numpy作为NP
进口泡菜
导入随机
从集合导入违约

alpha = 0.1
n_layers = 10
n_iter = 10
#N_Features = 8
init_scale = 1.0

train = pd.read_csv（“ ./ data/data/prediction.csv”）

y = train [&#39;y_true&#39;]。as_matrix（）
y = np.vstack（y）.astype（float）
ytest = y [18000：]
y = y [：18000]

x = train.drop（[&#39;y_true&#39;]，axis = 1）.as_matrix（）
xtest = x [18000：]。astype（float）
x = x [：18000]

def tanh（x，deriv = false）：
    如果（deriv == true）：
        返回（1 -np.tanh（x）** 2）*alpha
    别的：
        返回np.tanh（x）

def sigmoid（x，deriv = false）：
    如果（deriv == true）：
        返回x*（1-x）
    别的：
        返回1/（1+NP.EXP（-X））

def relu（x，deriv = false）：
    如果（deriv == true）：
        返回0.01 + 0.99*（x＆gt; 0）
    别的：
        返回0.01*x + 0.99*x*（x＆gt; 0）

np.random.seed（）

syn = defaultdict（np.array）

对于我的范围（n_layers-1）：
    syn [i] = init_scale * np.random.random（（len（x [0]），len（x [0]））） -  init_scale/2
syn [n_layers -1] = init_scale * np.random.random（（len（x [0]），1）） -  init_scale/2

l = defaultdict（np.array）
delta = defaultdict（np.array）

对于Xrange（n_iter）中的j
    l [0] = x
    对于我的范围（1，n_layers+1）：
        l [i] = relu（np.dot（l [i-1]，syn [i-1]）））

    错误=（y -l [n_layers]）

    e = np.mean（np.abs（error））
    如果（J％1）== 0：
        打印“ \ niteration” + str（j） +“” + str（n_iter）
        打印“错误：” + str（e）

    delta [n_layers] = error * relu（l [n_layers]，deriv = true） * alpha
    对于我的范围（n_layers-1,0，-1）：
        错误= delta [i+1] .dot（syn [i] .t）
        delta [i] = error * relu（l [i]，deriv = true） * alpha

    对于我的范围（n_layers）：
        syn [i] += l [i] .t.dot（delta [i +1]）



pickle.dump（syn，open（&#39;neural_weights.pkl&#39;，&#39;wb&#39;））

＃用F1量测试
＃回忆= true积极 /（真正的阳性 +虚假负面）
＃precision = true阳性 /（true积极 +误报）

l [0] = xtest
对于我的范围（1，n_layers+1）：
    l [i] = relu（np.dot（l [i-1]，syn [i-1]）））

out = l [n_layers]/max（l [n_layers]）

tp = float（0）
fp = float（0）
fn = float（0）
tn = float（0）

对于l [n_layers] [：50]：
    打印i

对于我的范围（len（ytest））：
    如果出去[i]＆gt; 0.5和ytest [i] == 1：
        TP += 1
    如果输出[i]＆lt; = 0.5和ytest [i] == 1：
        fn += 1
    如果出去[i]＆gt; 0.5和ytest [i] == 0：
        FP += 1
    如果输出[i]＆lt; = 0.5和ytest [i] == 0：
        TN += 1

打印“ TP：” + Str（TP）
打印“ fp：” + str（fp）
打印“ TN：” + Str（TN）
打印“ fn：” + str（fn）

打印“ \ nprecision：” + str（tp/（tp + fp））
打印“回忆：” + str（tp/（tp + fn））

f1 = 2 * tp /（2 * tp + fn + fp）
打印“ \ nf1-measure：” + str（f1）
 
这是输出：
 迭代10 of 10
错误：0.222500767998

迭代1 of 10
错误：0.222500771157

迭代2共10
错误：0.222500774321

迭代3 of 10
错误：0.22250077749

迭代4，共10个
错误：0.222500780663

迭代5 of 10
错误：0.222500783841

迭代6 of 10
错误：0.222500787024

迭代7 of 10
错误：0.222500790212

迭代第8次
错误：0.222500793405

迭代9 of 10
错误：0.222500796602


[0.]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[0.]
[0.]
[4.62182626E-06]
[0.]
[0.]
[0.]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[0.]
[4.62182626E-06]
[0.]
[0.]
[5.04501079E-10]
[5.58610895E-06]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[0.]
[5.04501079E-10]
[0.]
[0.]
[4.62182626E-06]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[5.58610895E-06]
[0.]
[0.]
[0.]
[5.58610895E-06]
[0.]
[1.31432294E-05]

TP：28.0
FP：119.0
TN：5537.0
FN：1550.0

精度：0.190476190476
召回：0.0177439797212

F1量表：0.0324637681159
 ]]></description>
      <guid>https://stackoverflow.com/questions/44213659/neural-network-converging-to-zero-output</guid>
      <pubDate>Sat, 27 May 2017 06:21:36 GMT</pubDate>
    </item>
    <item>
      <title>训练后如何用分布的时间来替换嵌入层？</title>
      <link>https://stackoverflow.com/questions/39532572/how-to-replace-an-embedding-layer-with-a-time-distributed-dense-after-training</link>
      <description><![CDATA[我有以下问题：

 我想使用LSTM网络进行文本分类。为了加快训练的速度并使代码更加清楚，我想沿沿 keras.tokenizer 嵌入层以训练我的模型。 
 一旦我训练了我的模型 - 我想计算输出W.R.T.的显着性图。输入。为此，我决定将嵌入层替换为 timeDistributedDense 。 

您知道什么是最好的方法。对于一个简单的模型，我可以简单地使用已知权重的模型来重建模型 - 但我想使其尽可能通用 - 例如替换模型结构的未来并使我的框架尽可能不可知。]]></description>
      <guid>https://stackoverflow.com/questions/39532572/how-to-replace-an-embedding-layer-with-a-time-distributed-dense-after-training</guid>
      <pubDate>Fri, 16 Sep 2016 13:21:25 GMT</pubDate>
    </item>
    <item>
      <title>使用Python分类信号图像</title>
      <link>https://stackoverflow.com/questions/23053365/classify-signal-images-using-python</link>
      <description><![CDATA[我有以下信号图像，我想根据形状进行分类。哪种算法适合这样做？我已经附上了每个班级的2-2张图像。 





 ]]></description>
      <guid>https://stackoverflow.com/questions/23053365/classify-signal-images-using-python</guid>
      <pubDate>Mon, 14 Apr 2014 06:30:28 GMT</pubDate>
    </item>
    <item>
      <title>确定这两个类是可分开的（在2D中算法）</title>
      <link>https://stackoverflow.com/questions/9779179/determine-whether-the-two-classes-are-linearly-separable-algorithmically-in-2d</link>
      <description><![CDATA[有两个类，我们称其为X和O。属于这些类别的许多元素都在XY平面中分布。这是一个示例，其中两个类不可分离。不可能绘制一条直线，完美地将XS和操作系统分开。 
  
 通常如何确定两个类别是否线性分离？。我对一种算法感兴趣，该算法没有对元素数量或它们的分布做出任何假设。 最低计算复杂性的算法当然是首选的。]]></description>
      <guid>https://stackoverflow.com/questions/9779179/determine-whether-the-two-classes-are-linearly-separable-algorithmically-in-2d</guid>
      <pubDate>Mon, 19 Mar 2012 22:58:01 GMT</pubDate>
    </item>
    </channel>
</rss>