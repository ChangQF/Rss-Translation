<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 15 Jan 2024 15:15:03 GMT</lastBuildDate>
    <item>
      <title>有效计算不同目标的输入梯度</title>
      <link>https://stackoverflow.com/questions/77820641/computing-input-gradients-for-different-targets-efficiently</link>
      <description><![CDATA[我目前正在研究一个类似于对抗性例子的问题。在我的设置中，我想根据不同类的梯度计算输入样本的梯度掩码。更具体地说，我有一个输入图像 x，并且想要计算给定目标类别为 0、1、2、... 的各个像素损失梯度。
我当前的解决方案类似于这个玩具示例：
net = torch.nn.Sequential(torch.nn.Linear(10, 10), torch.nn.ReLU(), torch.nn.Linear(10, 5))
x = 火炬.randn(1, 10)
x.requires_grad = True

y = 净值(x)
损失 = torch.nn.function.mse_loss(y, torch.tensor([0., 1., 2., 3., 4.]), 减少=&#39;无&#39;)[0]
梯度= []
对于损失中的损失：
    loss.backward(retain_graph=True)
    渐变.append(x.grad.clone().detach())
    x.grad.zero_()

由于损失目前是针对每个目标值顺序反向传播的，因此运行时间并不是很好。有没有更有效的方法来在一次向后传递中计算不同类的梯度？由于我的内存也有些有限，因此简单地复制输入示例并并行运行多次是行不通的。
我很感谢这里的任何见解和想法:)
我已经尝试复制输入以并行运行向后传递。不幸的是，我的 GPU 内存在此设置中受到限制。]]></description>
      <guid>https://stackoverflow.com/questions/77820641/computing-input-gradients-for-different-targets-efficiently</guid>
      <pubDate>Mon, 15 Jan 2024 15:00:00 GMT</pubDate>
    </item>
    <item>
      <title>直接从x_t获取x_0和用它按照t-1,t-2,...的顺序获取x_0有什么区别？ 。 。和 DDPM 中的 0？</title>
      <link>https://stackoverflow.com/questions/77820598/what-is-the-difference-between-getting-x-0-directly-from-x-t-and-using-it-to-get</link>
      <description><![CDATA[抱歉我的英语不好..
根据DDPM，我们可以通过重新参数化技巧直接从x_t获取x_0。
利用这个 x_t, x_0 我们可以得到 x_(t-1)，对吗？
重复此操作，我们可以得到x_0。
那么，这些x_0有什么区别呢？为什么我们不直接获取x_0？]]></description>
      <guid>https://stackoverflow.com/questions/77820598/what-is-the-difference-between-getting-x-0-directly-from-x-t-and-using-it-to-get</guid>
      <pubDate>Mon, 15 Jan 2024 14:50:47 GMT</pubDate>
    </item>
    <item>
      <title>过采样产生奇怪的结果[关闭]</title>
      <link>https://stackoverflow.com/questions/77820366/oversampling-with-strange-results</link>
      <description><![CDATA[为了通过机器学习来学习不平衡数据，
使用train_test_split分离训练集和测试集
在此处输入图像描述
然后，偶然的机会，如下所示，X 和 y 首先以我创建的集合的形式进行了过采样。
我使用过采样训练集 X_train_sm 和 y_train_sm 通过 LGBMClassifier 学习了一个模型，然后使用非过采样测试集 X_test 和 y_test 评估了性能，并获得了改进的性能值。
我很好奇为什么结果是这样，以及使用这种方法是否可以。
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/77820366/oversampling-with-strange-results</guid>
      <pubDate>Mon, 15 Jan 2024 14:10:58 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的线性回归模型返回负 R2 分数？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77820300/why-is-my-linearregression-model-returning-negative-r2-score</link>
      <description><![CDATA[我正在尝试训练一个模型来预测客户的总购买金额。这次我尝试了不同的算法，线性回归。
我的数据如下所示：https://i.stack.imgur.com/JbM9J .png
以下是进一步的步骤：
# 预处理

def preprocess_input(df):
  df = df.copy()

  #删除不必要的列
  df = df.drop(“购买日期”, axis=1)
  df = df.drop(“客户名称”, axis=1)
  df = df.drop(“客户ID”, axis=1)
# df = df.drop(“数量”, axis=1)

  #二进制编码
  df[“性别”] = df[“性别”].replace({“女”:0, “男”:1})

  #One 热门编码
  ohe = OneHotEncoder(sparse_output=False, handle_unknown=“忽略”).set_output(transform=“pandas”)
  x_cat = df.select_dtypes(include=&#39;object&#39;)
  x_encoded = ohe.fit_transform(x_cat)

  df = df.drop(“产品类别”, axis=1)
  df = pd.concat([df, x_encoded], 轴=1)

  #将 df 分割为 x 和 y
  y = df[“总购买金额”]
  X = df.drop([“总购买金额”], axis=1)

  #训练-测试分割
  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

  #缩放x
  定标器=标准定标器()
  缩放器.fit(x_train)
  x_train = pd.DataFrame(scaler.transform(x_train),index=x_train.index,columns=x_train.columns)
  x_test = pd.DataFrame(scaler.transform(x_test),index=x_test.index,columns=x_test.columns)

  返回x_train、x_test、y_train、y_test

x_train, x_test, y_train, y_test = preprocess_input(数据)

# 训练/结果

从sklearn导入线性模型
从 sklearn.metrics 导入mean_squared_error, r2_score

模型 = Linear_model.LinearRegression()
model.fit(x_train, y_train)

y_lr_train_pred = model.predict(x_train)
y_lr_test_pred = model.predict(x_test)

lr_train_mse =mean_squared_error(y_train, y_lr_train_pred)
lr_train_r2 = r2_score(y_train, y_lr_train_pred)

lr_test_mse =mean_squared_error(y_test, y_lr_test_pred)
lr_test_r2 = r2_score(y_test, y_lr_test_pred)

lr_results = pd.DataFrame([“线性回归”, lr_train_mse, lr_train_r2, lr_test_mse, lr_test_r2]).transpose()
lr_results.columns = [“方法”、“训练 MSE”、“训练 R2”、“测试 MSE”、“测试 R2”]

打印（lr_结果）

y_pred = model.predict(x_test)

_preds_df = pd.DataFrame(dict(观察=y_test, 预测=y_pred))
_preds_df.head()

但是结果是


训练 MSE：1981065.009898
训练 R2：0.015117
测试MSE：2036338.881142
测试R2：-0.021321




&lt;表类=“s-表”&gt;
&lt;标题&gt;

观察
预测


&lt;正文&gt;

5010
2575.423427


1420
2891.011360


2174
2865.481353


3470
2449.776070


3274
2748.318404




准确性和结果似乎不对，这里可能出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77820300/why-is-my-linearregression-model-returning-negative-r2-score</guid>
      <pubDate>Mon, 15 Jan 2024 13:59:14 GMT</pubDate>
    </item>
    <item>
      <title>哪种方法可以用于多时间序列机器学习问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77820208/which-approach-can-be-used-for-multi-time-series-machine-learning-problem</link>
      <description><![CDATA[我正在尝试结合有限元模拟来实现机器学习问题。
我有一组模拟（~5000），每个模拟都有多个时间步长（~20），对于每个时间步长，我想预测~50个节点的坐标。我使用每个节点作为观察，因此这将是一个多输出回归问题，其目标是预测每个节点的 x、y 和 z 坐标。我按节点组织数据集，因此每个节点都属于特定的时间步和特定的模拟。
在这种情况下使用的最佳模型/方法是什么？
我考虑过使用 LSTM 和多时间序列，但由于我正在处理彼此不相关的小型时间序列模拟，所以我不太确定如何实现它。这不是一个常见的预测问题，因为我只有 t=0 的信息，并且希望基于该信息构建整个时间序列。
我也研究过图神经网络，但它们主要用于分类问题，并且每个模拟的每个时间步长我都会有一个小图（约 50 个节点之间的连接）。]]></description>
      <guid>https://stackoverflow.com/questions/77820208/which-approach-can-be-used-for-multi-time-series-machine-learning-problem</guid>
      <pubDate>Mon, 15 Jan 2024 13:42:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 PositionalEmbedding 和 BARTForConditionalGeneration 生成摘要时，获得与输入相同的结果</title>
      <link>https://stackoverflow.com/questions/77820052/while-generating-summary-using-positionalembedding-with-bartforconditionalgenera</link>
      <description><![CDATA[我正在尝试使用（下面的代码）位置嵌入+令牌嵌入作为inputs_embeds并使用BARTForConditionalGeneration来生成摘要。它返回与输入相同的 1-2 行 (max_len =120)（要么完全相同的 1-2 行，要么这 1-2 行更改了 1-2 个单词）。
tok = BartTokenizer.from_pretrained(“facebook/bart-base”)
example_english_phrase = CNN/DM 测试用例的第一篇文章
input_ids = tok(example_english_phrase, padding=&#39;max_length&#39;,max_length = 512 ,truncation= True,return_tensors=“pt”).to(device)

生成嵌入（令牌嵌入+位置嵌入）。此步骤使自定义嵌入也可以工作。
embed_pos = model.model.encoder.embed_positions(input_ids.input_ids) * model.model.encoder.embed_scale # 默认比例为 1.0
input_embeds = model.model.encoder.embed_tokens(input_ids.input_ids)
隐藏状态 = 嵌入位置 + 输入嵌入

使用上面生成的嵌入进行摘要过程
 generated_summaries = []
最大长度 = 120
光束数 = 10
无重复 = 3
长度p = 2.0
多样性=0.8

摘要_ids = bart_for_cond.generate(
        输入嵌入=隐藏状态，
        最大长度=最大长度，
        num_beams = num_beams,
        Early_stopping=真，
        no_repeat_ngram_size = no_repeat,
        长度惩罚=长度p，
        多样性惩罚=多样性，
        num_beam_groups = num_beam,
        num_return_sequences = num_beam
    ）
    


generated_summaries.append（[tokenizer.decode（summary_id，skip_special_tokens = True）对于summary_ids中的summary_id]）
]]></description>
      <guid>https://stackoverflow.com/questions/77820052/while-generating-summary-using-positionalembedding-with-bartforconditionalgenera</guid>
      <pubDate>Mon, 15 Jan 2024 13:17:49 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 模型数组抛出错误：“AttributeError: '_UserObject' 对象没有属性 'fit'”</title>
      <link>https://stackoverflow.com/questions/77819900/an-array-of-tensorflow-models-throws-error-attributeerror-userobject-objec</link>
      <description><![CDATA[我已经为 5 个不同类别的图像训练了 5 个单独的模型，我的代码使用它们根据需要进一步分类的类别进行推理。因此，我将它们保存为数组，如下面的代码所示，并在尝试使用 model() 通常具有的任何方法时开始出现此错误。
&lt;前&gt;&lt;代码&gt;型号 = [无] * 5
模型[0] = tf.saved_model.load(r&#39;/content/gdrive/MyDrive/model_category1&#39;)
模型[1] = tf.saved_model.load(r&#39;/content/gdrive/MyDrive/model_category2&#39;)
模型[2] = tf.saved_model.load(r&#39;/content/gdrive/MyDrive/model_category3&#39;)
模型[3] = tf.saved_model.load(r&#39;/content/gdrive/MyDrive/model_category4&#39;)
模型[4] = tf.saved_model.load(r&#39;/content/gdrive/MyDrive/model_category5&#39;)

并尝试使用模型方法：
预测 = model[cat_no]()

或
model[cat_no].fit(数据集，validation_data=val_dataset，epochs=epoch_len，verbose=1)

错误：“AttributeError：&#39;_UserObject&#39;对象没有属性&#39;fit&#39;”
（模型之前使用 tf.saved_model.save 保存。）
我以什么方式使用这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/77819900/an-array-of-tensorflow-models-throws-error-attributeerror-userobject-objec</guid>
      <pubDate>Mon, 15 Jan 2024 12:50:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用电子鼻检测特定气体[关闭]</title>
      <link>https://stackoverflow.com/questions/77819695/how-can-specific-gases-be-detected-using-an-e-nose</link>
      <description><![CDATA[我正在尝试使用啤酒的风味特征创建啤酒特征，但在检测特定气体时遇到困难。
我发现的大多数传感器都会输出 VOC 的浓度，但不是每种 VOC 的浓度。
有人知道如何只检测乙酸乙酯吗？
我发现许多传感器可以输出所有存在的 VOC 的总浓度，但我希望能够区分每种气体。]]></description>
      <guid>https://stackoverflow.com/questions/77819695/how-can-specific-gases-be-detected-using-an-e-nose</guid>
      <pubDate>Mon, 15 Jan 2024 12:11:17 GMT</pubDate>
    </item>
    <item>
      <title>在使用pywinauto生成的多个系统中使用Wrapper_objects</title>
      <link>https://stackoverflow.com/questions/77819573/using-wrapper-objects-in-multiple-systems-generated-using-pywinauto</link>
      <description><![CDATA[我正在使用 pywinauto 为元素创建wrapper_obejcts，以便使用元素所在的坐标来控制它们。我想使用这个包装对象来进行一系列录音，其中多个元素被单击、选择或键入。我希望创建的这些包装器对象可以在不同的系统/PC 中使用，以便我可以自动执行相同的操作
我正在使用它创建包装对象：
from ctypes.wintypes import tagPOINT
导入 pywinauto
导入时间
时间.睡眠(2)
def get_ElementFromPoint(x,y):
     elem = pywinauto.uia_defines.IUIA().iuia.ElementFromPoint(tagPOINT(x, y))
     元素 = pywinauto.uia_element_info.UIAElementInfo(elem)
     包装器 = pywinauto.controls.uiawrapper.UIAWrapper(元素)
     返回包装器

创建的对象示例如下：


如何在不同的系统中使用此包装器来自动执行我的任务？]]></description>
      <guid>https://stackoverflow.com/questions/77819573/using-wrapper-objects-in-multiple-systems-generated-using-pywinauto</guid>
      <pubDate>Mon, 15 Jan 2024 11:49:34 GMT</pubDate>
    </item>
    <item>
      <title>通过机器学习协调变量名称和类别</title>
      <link>https://stackoverflow.com/questions/77818821/harmonizing-variable-names-and-categories-through-machine-learning</link>
      <description><![CDATA[我正在寻找资源和工具来协调从 1985 年到 2020 年的数据集。该数据集涉及名称、类别和标签随时间变化的变量。我的目标是使用机器学习根据三个关键标识符来识别变量之间的相似性：1) 变量类别，2) 变量命名模式，以及 3) 变量标签。
这是我的数据集的简化版本：
# 小标题：12 × 5
   变量名称 变量标签 变量目录号 变量目录文本 年份
   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; 
 1 Degree_father 父亲学位 1 学士学位 1986
 2 Degree_father 父亲学位 2 硕士学位 1986
 3 Degree_father 父亲学位 3 博士 1986
 4 FADEGREE 个人父亲的学位 1 1990 年学士学位
 5 FADEGREE 个人父亲的学位 2 硕士 1990
 6 FADEGREE 个人父亲的学位 3 1990 年获得博士学位
 7 Age_Ind 受访者年龄 1 0 至 30 岁之间 1986 年
 8 Age_Ind 受访者年龄 2 31 岁至 60 岁之间 1986 年
 9 Age_Ind 受访者年龄 3 61 岁或以上 1986 年
10 RESP_AGE 受访者的年龄 1 0-40 1992
11 RESP_AGE 受访者的年龄 2 41-70 1992
12 RESP_AGE 受访者的年龄 3 70 岁或以上 1992 年

我正在寻找有关使用机器学习来检测 Degree_father (1986) 和 FADEGREE (1990) 代表相同信息的指导，就像 Age_Ind (1986) 和 RESP_AGE (1992) 一样，尽管变量标签、名称、和类别。我熟悉 R，但乐于学习新方法。有什么建议或提示吗？我听说过语言模型，但我不知道它们的目的是否符合我的目的。]]></description>
      <guid>https://stackoverflow.com/questions/77818821/harmonizing-variable-names-and-categories-through-machine-learning</guid>
      <pubDate>Mon, 15 Jan 2024 09:33:13 GMT</pubDate>
    </item>
    <item>
      <title>如何在输入列中找到在输出列中生成结果的优化值组合[关闭]</title>
      <link>https://stackoverflow.com/questions/77787203/how-to-find-optimized-combinations-of-values-in-input-columns-that-produces-the</link>
      <description><![CDATA[我有多个生成输出列的输入列。我想找到输入列中的值的优化组合，以生成输出列中的值。
例如：
点赞此表
所以输出会是这样的：
抄送-&gt;输出4
AA，XX -&gt;输出1
等等。
我正在尝试使用关联规则学习来查找多个输入列和一个输出列（所有文本列）之间的规则或关系。我尝试过 pycaret.arules 但在 pycaret==2.3.10 之后它不可用，并且此版本或以下版本与 Python 3.10 不兼容。所以，我不能使用它。
有没有其他方法可以解决这个问题。我尝试过决策树，但我想要一些完全适合我的数据而无需任何额外节点的东西。
到目前为止，我已经研究了 apyori、efficient-apriori 等不同的 apriori 实现。它们都不完全符合我想要的。]]></description>
      <guid>https://stackoverflow.com/questions/77787203/how-to-find-optimized-combinations-of-values-in-input-columns-that-produces-the</guid>
      <pubDate>Tue, 09 Jan 2024 13:42:03 GMT</pubDate>
    </item>
    <item>
      <title>带有我自己的预训练模型的 Sagemaker 批处理变压器</title>
      <link>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77781734/sagemaker-batch-transformer-with-my-own-pre-trained-model</guid>
      <pubDate>Mon, 08 Jan 2024 15:54:18 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost 错误 - 提供分类类型时，DMatrix 参数“enable_categorical”必须设置为“True”</title>
      <link>https://stackoverflow.com/questions/67080149/xgboost-error-when-categorical-type-is-supplied-dmatrix-parameter-enable-cat</link>
      <description><![CDATA[我有四个类别特征和第五个数字特征 (Var5)。当我尝试以下代码时：
cat_attribs = [&#39;var1&#39;,&#39;var2&#39;,&#39;var3&#39;,&#39;var4&#39;]

full_pipeline = ColumnTransformer([(&#39;cat&#39;, OneHotEncoder(handle_unknown = &#39;ignore&#39;), cat_attribs)], 剩余 = &#39;passthrough&#39;)
X_train = full_pipeline.fit_transform(X_train)

模型= XGBRegressor（n_estimators = 10，max_深度= 20，详细程度= 2）
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

当模型尝试进行预测时，我收到以下错误消息：
&lt;块引用&gt;
ValueError：数据的 DataFrame.dtypes 必须是 int、float、bool 或 categorical。什么时候
提供分类类型，DMatrix 参数
enable_categorical 必须设置为 True。Var1、Var2、Var3、Var4

有人知道这里出了什么问题吗？
如果有帮助的话，这里是 X_train 数据和 y_train 数据的一个小样本：
&lt;预置&gt;&lt;代码&gt; Var1 Var2 Var3 Var4 Var5
1507856 日本 2009 6581 OME 325.787218
839624 法国 2018 5783 I_S 11.956326
1395729 2015 年 6719 OME 42.888565
1971169 DK 2011 3506 RPP 70.094146
1140120 AT 2019 5474 NMM 270.082738

和：
&lt;前&gt;&lt;代码&gt; Ind_Var
1507856 8.013558
839624 4.105559
1395729 7.830077
1971169 83.000000
1140120 51.710526
]]></description>
      <guid>https://stackoverflow.com/questions/67080149/xgboost-error-when-categorical-type-is-supplied-dmatrix-parameter-enable-cat</guid>
      <pubDate>Tue, 13 Apr 2021 18:03:12 GMT</pubDate>
    </item>
    <item>
      <title>Scikit 机器学习模型 - 数据库存储</title>
      <link>https://stackoverflow.com/questions/33542592/scikit-machine-learning-models-database-storage</link>
      <description><![CDATA[有没有办法将 Scikit 机器学习模型存储在数据库中？ 
我知道我可以将模型存储在磁盘上的 .pkl 文件中。但我想将它直接作为 blob 存储在我的数据库中。
joblib.dump(模型, &#39;../dump_file.pkl&#39;)

我想从 dump_file.pkl 中读取所有内容作为字节并直接写入数据库，但问题是也生成了很多支持文件。

现在，如何将我的模型存储到数据库？]]></description>
      <guid>https://stackoverflow.com/questions/33542592/scikit-machine-learning-models-database-storage</guid>
      <pubDate>Thu, 05 Nov 2015 10:46:29 GMT</pubDate>
    </item>
    <item>
      <title>通过机器学习提取重叠类别</title>
      <link>https://stackoverflow.com/questions/26226178/extracting-overlapping-categories-through-machine-learning</link>
      <description><![CDATA[我正在尝试获取可能重叠的产品属性。&lt;​​/p&gt;
根据标题、制造商、描述，我需要知道该产品是牛仔裤还是其他类型的牛仔裤，甚至是紧身牛仔裤还是其他类型的牛仔裤。通过 scikit-learn 练习，我似乎一次只能预测一个类别，这不适用于我的情况。关于如何解决这个问题有什么建议吗？
我现在想到的是为每个类别提供训练数据，例如：
Jeans = [&#39;牛仔裤 1 的描述&#39;, &#39;牛仔裤 2 的描述&#39;]
紧身牛仔裤 [&#39;紧身牛仔裤 1 的描述&#39;, &#39;紧身牛仔裤 2 的描述&#39;]

利用这些训练数据，我会询问给定未知产品的概率，并期望以匹配百分比的形式得到此类答案：
Unknown_Product_1 = {
    “牛仔裤”：93，
    “紧身牛仔裤”：80，
    “T 恤”：5
}

我离基地太远了吗？如果这是一条正确的道路，如果是的话，我该如何实现它？]]></description>
      <guid>https://stackoverflow.com/questions/26226178/extracting-overlapping-categories-through-machine-learning</guid>
      <pubDate>Mon, 06 Oct 2014 23:03:15 GMT</pubDate>
    </item>
    </channel>
</rss>