<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 09 May 2024 21:15:01 GMT</lastBuildDate>
    <item>
      <title>用于确定点平面象限的 Kohonen 神经网络</title>
      <link>https://stackoverflow.com/questions/78456978/kohonen-neural-network-for-determining-the-quadrant-of-a-point-plane</link>
      <description><![CDATA[我需要实现 Kohonen 神经网络（没有老师）来确定点的平面（从 1 到 8）的象限。坐标 [x, y, z] 的向量被馈送到神经网络的输入。在输出中，我们得到一个向量，通过该向量可以确定该点属于哪个象限。
这是我训练神经网络的代码：
def 火车(
        数据集：list[tuple[npt.NDArray[npt.NDArray[float]], npt.NDArray[npt.NDArray[float]]]],
        学习率：浮动，
        纪元：int
）-&gt; npt.NDArray[npt.NDArray[浮点]]：

    W = np.random.randn(3, 8)

    对于范围（1，纪元 + 1）中的纪元：
        random_indexes = np.random.choice(len(数据集)，size=len(数据集)，replace=False)
        对于 random_indexes 中的索引：
            x = 数据集[索引][0] # [[x, y, z]]
            y = 数据集[索引][1]

            x_normalized = x / np.sqrt(np.sum(x ** 2))

            z = np.dot(x_归一化，W)

            W[0][z.argmax()] += 学习率 * (x[0][0] - W[0][z.argmax()])
            W[1][z.argmax()] += 学习率 * (x[0][1] - W[1][z.argmax()])
            W[2][z.argmax()] += 学习率 * (x[0][2] - W[2][z.argmax()])

        学习率 = 学习率 / 时期

    返回W

def calc_accuracy(
        数据集：list[tuple[npt.NDArray[npt.NDArray[float]], npt.NDArray[npt.NDArray[float]]]],
        W: npt.NDArray[npt.NDArray[float]]) -&gt;漂浮：
    正确 = 0
    对于数据集中的 x、y：
        z = np.dot(x, W)
        如果 z.argmax() == y.argmax():
            正确+=1
    返回（正确/len（数据集））* 100


def draw_accuracy_epoch_plots(
        数据集：list[list[tuple[npt.NDArray[npt.NDArray[float]], npt.NDArray[npt.NDArray[float]]]]],
        epoch_number：int
）-&gt;没有任何：
    对于索引，枚举中的数据集（数据集）：
        准确度列表 = []
        准确度列表_2 = []
        对于范围（1，epoch_number + 1）中的纪元：
            W = 训练（数据集，learning_rate=0.7，epochs=epochs）
            precision_list.append(calc_accuracy(数据集，W))
            precision_list_2.append(calc_accuracy(generate_dataset(15), W))

        plt.subplot(3, 2, (2 * 索引) + 1)
        plt.plot(accuracy_list)

        plt.subplot(3, 2, (2 * 索引) + 2)
        plt.plot(accuracy_list_2)


draw_accuracy_epoch_plots([generate_dataset(25),generate_dataset(50),generate_dataset(100)],100)

在代码中，我计算了不同时期神经网络预测的准确性。结果，我得到的准确度为 0 到 45%，这不适合我。同时，神经网络经常产生 0% 的匹配。
如果更改学习率和历元没有帮助，我该如何解决这个问题？我可以添加图层吗（我还没有找到这个问题的答案）？或者也许我错误地构建了学习算法？]]></description>
      <guid>https://stackoverflow.com/questions/78456978/kohonen-neural-network-for-determining-the-quadrant-of-a-point-plane</guid>
      <pubDate>Thu, 09 May 2024 21:05:03 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用 R（编程语言）在新的预测器中强制观察以在医疗补助支出数据集中执行逻辑函数</title>
      <link>https://stackoverflow.com/questions/78456621/attempting-to-coerce-observations-in-a-new-predictor-to-perform-logistic-functio</link>
      <description><![CDATA[我正在对 医疗补助支出进行一些数据分析药物数据字典数据集。具体来说，我想执行逻辑回归，其中 y 应该是 CAGR_Avg_Spnd_Per_Dsg_Unt_18_22。
不幸的是，根据我的代码，类和模式仍然是字符。
我对“Up”的灵感来自于和“向下”方法来自以下内容：
# 该库来自统计学习简介：R 中的应用

图书馆（ISLR）
附加(Smarket)
总结(Smarket)
# 期望的输出：
glm.fit=glm(方向~Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + 音量,
            家庭=二项式，数据=Smarket）
对比（方向）

通过使用 glm.fit，我可以执行预测、创建混淆矩阵等等。
但是，在检查时
摘要（药物.支出）

我的“向上”和“向下”是角色，而 ISLR 的“Up”的作者是角色。和“向下”看来是按数字算的。作者从未提供使用数据框的“向上”来执行此操作的代码。和“向下”观察！
这是我的代码：
库(dplyr)
图书馆（tidyr）
图书馆（心理学）
图书馆（跳跃）
设置.种子(1)

支出 &lt;- read.csv(“medicaid_spending_by_drug_data_dictionary.csv”)
drug.spending &lt;- 支出 %&gt;%
  na.omit(支出) %&gt;%
  filter(Mftr_Name == “总体”) %&gt;%
  安排(desc(Tot_Mftr)) %&gt;%
  过滤器（重复（Gnrc_Name））
drug.spending &lt;- drug.spending[!duplicate(drug.spending$Gnrc_Name),]
附加（药物.支出）



药物支出 &lt;- 药物支出 %&gt;%
  mutate(CAGR_Direction = ifelse(CAGR_Avg_Spnd_Per_Dsg_Unt_18_22 &gt; 0, &#39;向上&#39;, &#39;向下&#39;))

摘要（药品.支出）
对比（CAGR_Direction）#给出错误

我使用了不同的强制转换，例如 as.numeric() 和 as.integer()。我不太确定我哪里出错了......
请联系我们寻求澄清。]]></description>
      <guid>https://stackoverflow.com/questions/78456621/attempting-to-coerce-observations-in-a-new-predictor-to-perform-logistic-functio</guid>
      <pubDate>Thu, 09 May 2024 19:27:54 GMT</pubDate>
    </item>
    <item>
      <title>“适合训练数据的最短程序是最好的概括”这个定理是什么？</title>
      <link>https://stackoverflow.com/questions/78456286/shortest-program-that-fits-training-data-is-the-best-possible-generalisation-w</link>
      <description><![CDATA[在麻省理工学院的课堂上，一位演说家说“适合的最短程序”训练数据是最好的概括”这不仅仅是哲学 (https://en.wikipedia.org/wiki/Occam&#39;s_razor ），但实际上是一个由形式（简单）证明支持的数学事实。
该数学定理的名称是什么？这是“最小描述长度”吗？这就是当我问 ChatGPT 问题时它告诉我的，但对我来说，它看起来不像是一个经过证明的数学定理，而是类似的东西，尽管比奥卡姆剃刀稍微更正式。]]></description>
      <guid>https://stackoverflow.com/questions/78456286/shortest-program-that-fits-training-data-is-the-best-possible-generalisation-w</guid>
      <pubDate>Thu, 09 May 2024 18:19:17 GMT</pubDate>
    </item>
    <item>
      <title>图书柜台|我需要一个模型来计算图像/视频中的书籍数量</title>
      <link>https://stackoverflow.com/questions/78456209/book-counter-i-need-a-model-which-will-count-numbers-of-book-from-image-video</link>
      <description><![CDATA[我需要一个模型来计算图像/视频中的书籍数量。
原型机将能够拍摄图像/视频并继续计数书籍，就像我们在路灯上的车辆计数器一样。]]></description>
      <guid>https://stackoverflow.com/questions/78456209/book-counter-i-need-a-model-which-will-count-numbers-of-book-from-image-video</guid>
      <pubDate>Thu, 09 May 2024 18:01:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么无论使用什么数据集和模型，我的准确性都没有变化？</title>
      <link>https://stackoverflow.com/questions/78456058/why-doesnt-my-accuracy-vary-no-matter-the-dataset-and-the-model-used</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78456058/why-doesnt-my-accuracy-vary-no-matter-the-dataset-and-the-model-used</guid>
      <pubDate>Thu, 09 May 2024 17:26:57 GMT</pubDate>
    </item>
    <item>
      <title>test=model.predict([text]) 整个项目连续运行六次</title>
      <link>https://stackoverflow.com/questions/78455825/test-model-predicttext-entire-project-runs-six-times-consecutively</link>
      <description><![CDATA[似乎当执行 test=model.predict([text]) 行时，您的整个项目连续运行六次，并且当您关闭打开的窗口时，它会进行预测。
您可以看到下面的代码片段。
[主文件]
print(“test1”)
def 分类():
    打印（“测试2”）
    raw_text = str(entry.get(“1.0”, tk.END))
    tahmin_sonucu = 主要（raw_text）
    categories_label.config(text=“分类器：”+ tahmin_sonucu)

[主要功能]
from simpletransformers.classification import ClassificationModel

labels = [“Bilim Kurgu”、“经济”、“伊斯兰”、“Polisiye”、“浪漫”、“Sağlık”、“体育”]
模型 = ClassificationModel(&#39;bert&#39;, &#39;bert_model&#39;, num_labels=7, use_cuda=False,
                                    args={&#39;reprocess_input_data&#39;：True，&#39;overwrite_output_dir&#39;：True，&#39;num_train_epochs&#39;：3，
                                        “train_batch_size”：16，“fp16”：False，“output_dir”：“bert_model”})
打印（“测试11”）
def main(metin):
    塔明=无
    打印（“tes12”）
    tahmin=model.predict([metin])

    打印（标签[tahmin[0][0]]）
    
    返回标签[tahmin[0][0]]


输出]]></description>
      <guid>https://stackoverflow.com/questions/78455825/test-model-predicttext-entire-project-runs-six-times-consecutively</guid>
      <pubDate>Thu, 09 May 2024 16:31:34 GMT</pubDate>
    </item>
    <item>
      <title>在数据框中，我想以行数加倍的方式组合 2 列[重复]</title>
      <link>https://stackoverflow.com/questions/78455730/in-a-dataframe-i-want-to-combine-2-columns-in-such-way-that-the-no-of-rows-gets</link>
      <description><![CDATA[我有一个熊猫数据框（df）说
&lt;前&gt;&lt;代码&gt; Col1 Col2 Col3
1 条 AAA CCC 垃圾邮件
2 bbb ddd 火腿
……

我想将 Col1 和 Col2 与 Col3 一起合并到一个新的数据帧中，例如“test_df”
我想要这个
&lt;前&gt;&lt;代码&gt; Col_new Col3
1 条 AAA 垃圾邮件
2个bbb火腿
3 抄送垃圾邮件
4 dd 火腿

是否有任何简单的代码行？]]></description>
      <guid>https://stackoverflow.com/questions/78455730/in-a-dataframe-i-want-to-combine-2-columns-in-such-way-that-the-no-of-rows-gets</guid>
      <pubDate>Thu, 09 May 2024 16:13:58 GMT</pubDate>
    </item>
    <item>
      <title>将分类加权损失函数集成到我的代码后，准确率下降了</title>
      <link>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</link>
      <description><![CDATA[我想提高准确性，并且我有不平衡数据集：akiec：229，bcc：360，bkl：769，df：81，mel：779，vasc：99。为了解决这个问题，我选择将分类加权损失机制集成到模型中。然而，尽管进行了这样的调整，我还是注意到准确性随后下降了。这个意想不到的结果让我怀疑实施过程中出现了错误。您能否帮助我识别和解决任何潜在的错误以优化模型的性能？
# 定义目录
train_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Train&#39;
test_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Test&#39;
validation_dir = &#39;/content/drive/MyDrive/ikinciasamadataset/Validation&#39;

# 确定类的数量
numClasses = len(os.listdir(train_dir))

# 定义超参数网格
参数网格 = {
    &#39;学习率&#39;：[0.001]，
    &#39;批量大小&#39;：[16]，
}

最佳准确度 = 0
最佳参数 = 无

# 执行网格搜索
对于 ParameterGrid(param_grid) 中的参数：
    # 为每次网格搜索迭代加载预训练的 VGG19 模型
    base_model = VGG19(权重=&#39;imagenet&#39;, include_top=False, input_shape=(224, 224, 3))
    对于 base_model.layers 中的图层：
        可训练层 = False

    # 定义函数从最后一个卷积层提取特征
    def extract_features（生成器，模型）：
        特征 = model.predict(生成器)
        返回 features.reshape((len(generator.filenames), -1))

    # 创建数据生成器
    train_datagen = 图像数据生成器(
        重新缩放=1./255，
        旋转范围=20，
        宽度偏移范围=0.2，
        height_shift_range=0.2，
        剪切范围=0.2，
        缩放范围=0.2，
        水平翻转=真，
        fill_mode=&#39;最近&#39;)

    validation_datagen = ImageDataGenerator（重新缩放=1./255）

    train_generator = train_datagen.flow_from_directory(
        火车目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）

    validation_generator =validation_datagen.flow_from_directory(
        验证目录，
        目标大小=(224, 224),
        批量大小=参数[&#39;批量大小&#39;],
        class_mode=&#39;分类&#39;
    ）
&#39;&#39;&#39;

可能这里有一个错误

&#39;&#39;&#39;

    # 定义类索引
    类索引 = {
        &#39;基亚克&#39;: 0,
        “密件抄送”：1，
        &#39;bkl&#39;：2，
        “df”：3，
        “梅尔”：4，
        “血管”：5
    }

    ## 计算班级人数
    类计数 = {}
    对于 os.listdir(train_dir) 中的 class_name：
        class_counts[class_name] = len(os.listdir(os.path.join(train_dir, class_name)))

    # 计算类别权重
    类权重 = {}
    Total_samples = sum(class_counts.values())
    对于 class_name、class_count 在 class_counts.items() 中：
        class_weights[class_indices[class_name]] = 总样本数 / (class_count * len(class_counts))



    # 定义模型架构以接受提取的特征作为输入
    输入=输入(形状=(combined_data_train.shape[1],))
    x = 密集（256，激活=&#39;relu&#39;）（输入）
    预测=密集（numClasses，激活=&#39;softmax&#39;）（x）
    模型=模型（输入=输入，输出=预测）

    # 使用当前的超参数和类权重编译模型
    model.compile（优化器=SGD（learning_rate=params[&#39;learning_rate&#39;]），loss=&#39;sparse_categorical_crossentropy&#39;，metrics=[&#39;accuracy&#39;]，sample_weight_mode=&#39;temporal&#39;）

    # 定义提前停止
    Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

    # 通过提前停止来训练模型
    num_epochs = 50 # 您可以在此处调整纪元数
    历史=模型.fit(
        x=组合数据训练，
        y=train_generator.labels,
        纪元=num_epochs，
        批量大小=参数[&#39;批量大小&#39;],
        validation_data=(combined_data_validation,validation_generator.labels),
        回调=[early_stopping],
        类权重=类权重，
        详细=1
    ）

    model.save(&#39;best_vgg19_model_with_age.h5&#39;)

    # 根据验证数据评估模型
    _，val_accuracy = model.evaluate（combined_data_validation，validation_generator.labels，详细= 0）

    # 如有必要，更新最佳精度和最佳参数
    如果 val_accuracy &gt;最佳准确度：
        最佳准确度 = 验证准确度
        最佳参数 = 参数

# 打印最佳参数和准确度
print(&#39;最佳参数：&#39;, best_params)
print(&#39;最佳验证准确度：&#39;, best_accuracy)


# 加载最佳模型
best_model = load_model(&#39;best_vgg19_model_with_age.h5&#39;)

]]></description>
      <guid>https://stackoverflow.com/questions/78455283/the-accuracy-decreased-after-integrating-categorical-weighted-loss-function-to-m</guid>
      <pubDate>Thu, 09 May 2024 14:52:54 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么工具来注释机器学习项目的图像，以便我可以将数据添加到每个边界框</title>
      <link>https://stackoverflow.com/questions/78455181/what-tool-should-i-use-to-annotate-images-for-a-machine-learning-project-so-that</link>
      <description><![CDATA[我和我的团队有大量的水果图像需要注释来训练 YOLO 模型。注释过程需要包括每个水果周围的边界框和其他数据，例如重量。
根据 YOLO 文档，可以通过将补充信息直接附加到通常包含边界框数据的文件中来包含补充信息。我在 GitHub 上看到了一个建议这种方法的回复（链接至回复），但我还没有找到支持在定义边界框的同时添加额外数据的注释工具（如 Roboflow 或 CVAT）。
虽然可以在创建边界框后手动将数据添加到文本文件中，但这将是一项艰巨的任务。我正在寻找一种更自动化的解决方案，可以注释每幅图像，同时方便地添加其他信息。
是否有任何工具或网站支持此功能？]]></description>
      <guid>https://stackoverflow.com/questions/78455181/what-tool-should-i-use-to-annotate-images-for-a-machine-learning-project-so-that</guid>
      <pubDate>Thu, 09 May 2024 14:36:09 GMT</pubDate>
    </item>
    <item>
      <title>我需要一些有关如何正确注释数据集的说明</title>
      <link>https://stackoverflow.com/questions/78454868/i-need-some-clarification-on-how-to-annotate-a-dataset-correctly</link>
      <description><![CDATA[我正在做一个项目，我想做的是检测器和分类器。具体来说，我有两个类（袋子、纸板），我想使用像 YOLOv8 这样的检测器，然后使用分类器来提高它们的性能。我正在创建我的数据集，所以我正在拍摄视频，在某些地方扔掉这种浪费（别担心，我不会把它留在那里 xD），然后我注释这些视频中的帧。我想要这个数据集，这样我就可以对 YOLOv8 模型和分类器进行训练，训练它们识别这种浪费。我只有一个疑问。
当垃圾在地面上静止约 10 秒（30 fps 时为 300 帧）时，我应该用相同的边界框注释每个帧吗？或者对网络有危险吗？]]></description>
      <guid>https://stackoverflow.com/questions/78454868/i-need-some-clarification-on-how-to-annotate-a-dataset-correctly</guid>
      <pubDate>Thu, 09 May 2024 13:46:42 GMT</pubDate>
    </item>
    <item>
      <title>如何纠正 r 中光栅堆栈的方向</title>
      <link>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</link>
      <description><![CDATA[我有一个每日数据的 NetCDF 文件。我将其转换为光栅堆栈，但其方向不正确（我已附上图像）。我该如何纠正它。我还将我的代码附在本文中。 [raster_stack 图像和 r 代码](https://i.sstatic.net/UmI4kSNE.png)
另外，请告诉是否有人知道，我如何从这些栅格文件中提取年度数据到 Excel 格式（在 arcGIS 或 r 中）。我有 1955 年到 2023 年的栅格文件，其中包含每日降雨量数据，我想根据我拥有的管理形状文件提取年降雨量数据。
我在 r 中运行了代码，但没有取得任何进展。]]></description>
      <guid>https://stackoverflow.com/questions/78454706/how-do-i-correct-the-orientation-of-a-raster-stack-in-r</guid>
      <pubDate>Thu, 09 May 2024 13:18:03 GMT</pubDate>
    </item>
    <item>
      <title>如何为大型语言模型有效构建提示？</title>
      <link>https://stackoverflow.com/questions/78454565/how-to-structure-prompts-effectively-for-large-language-models</link>
      <description><![CDATA[我目前正在使用大型语言模型 (LLM)，在构建提示以获得最准确和最相关的响应方面面临挑战。我对提示工程有基本的了解，但正在寻找有关如何改进提示的最佳实践和建议。
以下是我的具体问题：

LLM 结构良好的提示的关键组成部分是什么？
提示的复杂性或简单性如何影响 LLM 的响应？
设计提示时是否有常见的陷阱或错误需要避免？

我对确保模型理解并遵守提示中提供的上下文的技术特别感兴趣。任何可以指导我的例子或资源都将不胜感激。
我希望指导法学硕士做什么和不做什么，包括与此相关的流程和链条，正如我所期望的那样
我尝试的示例提示：
“作为您的专属助理，我在这里解决与我们公司产品和服务相关的任何询问。请注意，我的专业知识仅限于内部主题，我没有能力处理外部查询或执行数学计算。”“
在某些情况下，此提示有效，但在其他情况下，它无效。]]></description>
      <guid>https://stackoverflow.com/questions/78454565/how-to-structure-prompts-effectively-for-large-language-models</guid>
      <pubDate>Thu, 09 May 2024 12:52:49 GMT</pubDate>
    </item>
    <item>
      <title>feature_weights 参数没有影响 Xgboost</title>
      <link>https://stackoverflow.com/questions/78454026/the-feature-weights-parameter-has-no-effect-xgboost</link>
      <description><![CDATA[xgboost 有一个 parameter feature_weights 应该影响模型选择特征的概率，也就是说，我们可以给每个特征更多或更少的权重，但似乎该参数不起作用还是我做错了什么？
X &lt;- as.matrix(iris[,-5])
Y &lt;- ifelse(iris$Species==&quot;setosa&quot;, 1, 0)

库（xgboost）
dm1 &lt;- xgb.DMatrix(X, 标签 = Y)
#我为每个特征设置不同的概率
dm2 &lt;- xgb.DMatrix(X, 标签 = Y, feature_weights = c(1, 0, 0, 0.01))
params &lt;- list(objective = “binary:logistic”, eval_metric = “logloss”)

设置.种子(1)



xgb1 &lt;- xgboost（数据 = dm1，参数 = 参数，nrounds = 10，print_every_n = 5）

[1] 火车对数损失：0.448305
[6] 火车对数损失：0.090220
[10]训练对数损失：0.033148



xgb2 &lt;- xgboost（数据 = dm2，参数 = 参数，nrounds = 10，print_every_n = 5）

[1] 火车对数损失：0.448305
[6] 火车对数损失：0.090220
[10]训练对数损失：0.033148

但是模型的行为完全相同，似乎参数feature_weights被简单地忽略了]]></description>
      <guid>https://stackoverflow.com/questions/78454026/the-feature-weights-parameter-has-no-effect-xgboost</guid>
      <pubDate>Thu, 09 May 2024 11:10:59 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError: 默认进程组尚未初始化，请确保调用 init_process_group</title>
      <link>https://stackoverflow.com/questions/78376085/runtimeerror-default-process-group-has-not-been-initialized-please-make-sure-t</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78376085/runtimeerror-default-process-group-has-not-been-initialized-please-make-sure-t</guid>
      <pubDate>Wed, 24 Apr 2024 05:05:11 GMT</pubDate>
    </item>
    <item>
      <title>NLTK 与距离度量的一致性</title>
      <link>https://stackoverflow.com/questions/32733510/nltk-agreement-with-distance-metric</link>
      <description><![CDATA[我的任务是计算 注释者间协议 “https://en.wikipedia.org/wiki/Multi-label_classification” rel=&quot;nofollow noreferrer&quot;&gt;多标签分类，其中每个示例可以分配多个标签。我发现 NLTK 可以根据距离度量来衡量一致性。
我正在寻找使用 MASI 距离计算 krippendorff alpha 的示例。
这就是我所拥有的。
&lt;前&gt;&lt;代码&gt;导入nltk
从 nltk.metrics 导入 masi_distance


玩具数据 = [[&#39;1&#39;, 5723, [1,2]],[&#39;2&#39;, 5723, [2,3]]]

任务= nltk.metrics.agreement.AnnotationTask（数据= toy_data，距离= masi_distance）
打印任务.alpha()

此代码失败并显示
类型错误：不可散列的类型：“列表”

以下方法也不起作用：
toy_data = [[&#39;1&#39;, 5723, set([1,2])],[&#39;2&#39;, 5723, set([2,3])]]

你有一个可行的例子吗？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/32733510/nltk-agreement-with-distance-metric</guid>
      <pubDate>Wed, 23 Sep 2015 07:28:09 GMT</pubDate>
    </item>
    </channel>
</rss>