<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Tue, 18 Feb 2025 15:20:29 GMT</lastBuildDate>
    <item>
      <title>OPENCV：从图像分割/提取打印机标签</title>
      <link>https://stackoverflow.com/questions/79448585/opencv-segmenting-extracting-printer-labels-from-image</link>
      <description><![CDATA[我有来自打印机的标签的镜头。 这是录像中的框架。
我想从框架中提取单个标签（即检测每个单独标签的边界）。
我最初尝试与一些形态学操作一起尝试轮廓检测，但是标签内的印刷内容（矩形和数字）正在干扰边缘检测，因此很难仅隔离标签边框。 
有人解决了类似问题吗？哪些预处理技术或替代方法最适合仅可靠地分割标签边缘？]]></description>
      <guid>https://stackoverflow.com/questions/79448585/opencv-segmenting-extracting-printer-labels-from-image</guid>
      <pubDate>Tue, 18 Feb 2025 14:26:06 GMT</pubDate>
    </item>
    <item>
      <title>这两个实现洛拉（低级适应）之间有什么区别吗？</title>
      <link>https://stackoverflow.com/questions/79447495/is-there-any-difference-between-these-two-implementations-of-lora-low-rank-adap</link>
      <description><![CDATA[我们都知道洛拉是一种低级适应方法，可以表达如下：x = w_0 * x +（a @ b） * x。我有两个不同的代码实现。它们之间有什么区别吗？
代码1：
  def向前（self，x）：
    x = x @ self.lora_a
    x = x @ self.lora_b
    x = self.scaling * x
    返回x
 
代码2：
  def向前（self，x）：
    x = x @（self.lora_a @ self.lora_b）
    x = self.scaling * x
    返回x
 
从数学角度来看，两者均似乎是等效的。但是，当我在玩具数据集上运行两个实现时，我观察到它们的性能有很小的差异 - 编码2的性能稍好。
为什么会发生这种轻微的差异？是否有基本的计算或优化细微差别可以解释这一点？
我不完全确定两个实现是否正确。我经常在GitHub存储库中看到代码1，但是我注意到代码2的性能稍好一些。为什么可能是这种情况？]]></description>
      <guid>https://stackoverflow.com/questions/79447495/is-there-any-difference-between-these-two-implementations-of-lora-low-rank-adap</guid>
      <pubDate>Tue, 18 Feb 2025 07:56:56 GMT</pubDate>
    </item>
    <item>
      <title>寻求2到3D超声重建的开源数据集[封闭]</title>
      <link>https://stackoverflow.com/questions/79446055/seeking-open-source-datasets-for-2d-to-3d-ultrasound-reconstruction</link>
      <description><![CDATA[我目前正在研究一个专注于将2D超声图像转换为3D型号的项目。要培训我的AI模型，我正在寻找专门为2到3D超声重建设计的开源数据集。
您知道可用于此目的的任何公开可用数据集吗？如果没有，我将非常感谢有关工具，资源或方法的任何建议，这些建议可以帮助我为此任务创建自己的数据集。
I checked out this ResearchGate link, but I couldn&#39;t find a way下载数据集。]]></description>
      <guid>https://stackoverflow.com/questions/79446055/seeking-open-source-datasets-for-2d-to-3d-ultrasound-reconstruction</guid>
      <pubDate>Mon, 17 Feb 2025 16:37:20 GMT</pubDate>
    </item>
    <item>
      <title>转换型号。</title>
      <link>https://stackoverflow.com/questions/79446020/convert-model-safetensors-in-onnx</link>
      <description><![CDATA[我已经从v1-5-pruned-emeonly.safetensors模型中创建了一个使用kohya的自定义模型，现在想将此模型导入C＃应用程序。我读到我可以使用ONNX来执行此操作，但我被卡在加载型号的权重。代码如下
 从扩散器导入StablediffusionPipeline
导入火炬
从SafetEnsors进口Safe_open

model_path =＆quot&#39;runwayml/stable-diffusion-v1-5＆quot;
pipe = stablediffusionpipeline.from_pretrataining（model_path，torch_dtype = torch.float16）

lora_path =＆quot; p718_long_crack_v1.safetensors;

pipe.unet.load_attn_procs（lora_path）

pipe.to（“ cuda”

unet = pipe.unet
 
产生以下错误
 加载管道组件...：100％|██████████| 7/7 [00：01＆lt; 00：00，4.75it/s]
d：\ onnx \ venv \ lib \ site-packages \ diffusers \ loaders \ loaders \ unet.py：212：future warnning：`load_attn_procs`被弃用，将在版本0.40.0中删除。使用`load_attn_procs（）`方法已被弃用，并将在将来的版本中删除。请使用`load_lora_adapter（）`。
  dobecate（&#39;load_attn_procs; quot；＆quot＆quot; quot; quot;
Trackback（最近的最新电话）：
  file＆quort＆quot d：\ onnx \ converter.py”，第11行，in＆lt; module＆gt;
    pipe.unet.load_attn_procs（lora_path）
  file＆quot＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ huggingface_hub \ utils \ _validators.py＆quort＆quort＆quort＆quort＆quort＆quort＆quort in _inner_fn in _inner_fn
    返回fn（*args，** kwargs）
  file＆quot＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ diffusers \ loaders \ loaders \ unet.py;
    is_model_cpu_offload，is_sequential_cpu_offload = self._process_lora（
  file＆quort＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ diffusers \ loaders \ loaders \ unet.py;
    lora_config_kwargs = get_peft_kwargs（rank，network_alphas，state_dict，is_unet = true）
  file＆quot＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ diffusers \ utils \ peft_utils.py＆quot＆quort＆quort＆quort＆quort＆quort 153，在get_peft_kwargs中
    r = lora_alpha = list（rank_dict.values（））[0]
indexError：列表索引以外
 
我正在接受错误的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79446020/convert-model-safetensors-in-onnx</guid>
      <pubDate>Mon, 17 Feb 2025 16:23:26 GMT</pubDate>
    </item>
    <item>
      <title>如何对混合VAR-LSTM模型执行样本外预测？</title>
      <link>https://stackoverflow.com/questions/79445942/how-to-perform-out-of-sample-forecast-for-a-hybrid-var-lstm-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79445942/how-to-perform-out-of-sample-forecast-for-a-hybrid-var-lstm-model</guid>
      <pubDate>Mon, 17 Feb 2025 15:56:31 GMT</pubDate>
    </item>
    <item>
      <title>如何从音频中删除背景人声？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79445833/how-to-remove-background-vocals-from-audio</link>
      <description><![CDATA[我目前正在研究语音情感识别（SER）项目，需要干净的声音音频而没有任何背景干扰。我使用Google Colab中的Demucs从数据集中删除背景音乐。尽管它成功地删除了乐器背景音乐，但仍然保留了一些背景唱歌（人声BGM）。
到目前为止，我尝试的是：
✅用示威者分开人声和乐器。
✅验证了乐器音乐已被删除。
❌背景人声仍然存在。
我的问题：
在保留主扬声器的声音时，我该如何完全删除背景唱歌？是否有更好的深度学习声音分离技术有效地有效？
🔧工具我正在使用：
 Google Colab（因此，欢迎基于GPU的解决方案！）
源分离的拆除
Kuet Bangla情感语音数据集
如果您解决了类似的问题，请分享您的经验！ 🙌
用示威者分开人声和乐器。]]></description>
      <guid>https://stackoverflow.com/questions/79445833/how-to-remove-background-vocals-from-audio</guid>
      <pubDate>Mon, 17 Feb 2025 15:14:35 GMT</pubDate>
    </item>
    <item>
      <title>如何准确匹配公司名称和地址以识别重复的公司？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79445057/how-to-accurately-match-company-names-and-addresses-to-identify-duplicate-compan</link>
      <description><![CDATA[我正在从事一个项目，我需要确定两个公司记录是否代表同一公司。我为每个公司拥有的数据包括：
公司名称（可能具有较小的变化或拼写差异）
地址详细信息：
区域
建筑物编号
城市
状态
Pincode
电话号码（在某些情况下可用，但并非总是如此）
挑战：
公司名称不一致：
示例：“ ABC Pvt Ltd” vs.“ ABC Private Limited”或“ XYZ Corp.” vs.“ X.Y.Z Corporation”
拼写错误和缩写也很常见。
地址变化：可以多种方式编写相同的地址。例如：
＆quot” 123，Mg Road＆quot＆quot＆quot vs.＆quot 123 mg rd&#39;
＆quot“第5号建筑物” vs.“ bldg 5”
＆quot“ sector-15” vs.＆quot＆quot&#39;
部分数据：在某些情况下，电话号码丢失或不完整。
多个匹配字段：
我应该比其他领域更重要的重量（例如平台和建筑物号）吗？
目标：
我想准确匹配这些记录以识别重复项，同时最大程度地减少误报（不正确的匹配）和误报（错过重复）。
我尝试的是：

确切的匹配：由于名称和地址的不一致而效果不佳。
模糊匹配：有助于解决较小的拼写差异，但会产生误报。
串联地址字段：尝试将所有地址字段串联到一个字符串中，但是较小的变化仍然会导致不匹配。

我需要帮助：

最佳方法或算法：我应该使用模糊匹配，语义相似性或机器学习模型吗？
预处理技术：如何处理缩写，拼写错误和地址格式的变化？
匹配策略：我是否应该优先考虑某些字段（例如，pincode和建筑号码）？
库或工具：任何推荐的Python/R库或第三方API可以有效地处理此问题？
]]></description>
      <guid>https://stackoverflow.com/questions/79445057/how-to-accurately-match-company-names-and-addresses-to-identify-duplicate-compan</guid>
      <pubDate>Mon, 17 Feb 2025 10:07:35 GMT</pubDate>
    </item>
    <item>
      <title>使用诸如大气气体浓度，地面变形，历史喷发记录等属性的火山喷发预测[封闭]</title>
      <link>https://stackoverflow.com/questions/79444356/volcano-eruption-prediction-using-attributes-such-as-atmospheric-gases-concentra</link>
      <description><![CDATA[我需要该项目的结构指导，我正在使用机器学习，数据源以及标题中提到的一些属性。。
我还需要选择机器学习模型的指导
我尝试使用自定义数据集（.csv）进行示例预测，但现在正在增强我的项目以实时预测。]]></description>
      <guid>https://stackoverflow.com/questions/79444356/volcano-eruption-prediction-using-attributes-such-as-atmospheric-gases-concentra</guid>
      <pubDate>Mon, 17 Feb 2025 03:46:32 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch多类分类网络的异常损失和低精度[封闭]</title>
      <link>https://stackoverflow.com/questions/79443990/abnormal-loss-and-low-accuracy-of-pytorch-multi-class-classification-network</link>
      <description><![CDATA[我的数据集来自 https://www.kaggle.com /数据集/yasserh/wine-emagility-dataset/data 。 （该功能标签应该是0-10，但只有7个独特的类，3至9，因此我只是设置[&#39;Quality&#39;] -3，因此所有内容均为0至6）。当我运行训练模型时，我看到损失异常高（整个时间为1.8至1.9）；我正在同时评估测试集上的模型，但准确性始终较低，大约为.2 -.3。当我在训练数据本身上测试HTE模型时，这是相同的精度（〜 -.24 -.25）。
我尝试重塑y_train和y_test集，将学习率更改为0.1至0.001，更改批次大小，在2-5个隐藏层之间进行测试，Min-Max归一化，不正常化，并标记了编码功能列的标签。但是，训练损失和测试准确性始终保持在相同的异常范围内。我不知道我在哪里做错了什么。
我的代码在：
。
供参考，这是我的训练循环：
  lose_fn = nn.crossentropyloss（）
优化器= Optim.Adam（model.parameters（），lr = 0.01）#lr可选，但通常更好地指定

DEF MULTICLASSNN_TRAIN（）：
        n_epochs = 100
        batch_size = 10
    
        对于范围（n_epochs）的时期：
            model.train（）
            total_loss = 0
            对于我的范围（0，len（x_train），batch_size）：
                xbatch = x_train [i：i+batch_size]
                ybatch = y_train [i：i+batch_size] .type（torch.long）
            
                优化器.zero_grad（）
                输出=模型（xbatch）
                损失= lose_fn（输出，ybatch）
                loss.backward（）
                优化器.step（）
            
                total_loss += lose.item（）
            
            avg_loss = total_loss /（len（x_train）// batch_size）
            打印（f&#39;epoch {epoch+1}，平均损失：{avg_loss：.4f}&#39;）
        
            ＃在每个时期之后对测试集进行评估
            model.eval（）
            使用Torch.no_grad（）：
                test_outputs =模型（x_test）
                test_loss = loss_fn（test_outputs，
                 y_test.type（torch.long））
                预测= torch.argmax（test_outputs，dim = 1）
                精度=（预测== y_test）.float（）。平均（）
                打印（f&#39;test损失：{test_loss：.4f}，准确性：                 
                {准确性：.4f}&#39;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79443990/abnormal-loss-and-low-accuracy-of-pytorch-multi-class-classification-network</guid>
      <pubDate>Sun, 16 Feb 2025 21:44:28 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同的数据范围内训练Sklearn模型？</title>
      <link>https://stackoverflow.com/questions/79439462/how-to-train-sklearn-model-in-different-dataframes</link>
      <description><![CDATA[我有一个用“ knn”制作的ML模型在Scikit-Learn中，注意到我的数据越多，我的模型就会越准确地说服它的预测。问题是，我有很多数据框架显示了我想预测的同一系统的不同情况。是否可以在那些不同的数据范围内训练模型？因为如果我致电.fit（），则将重置它是以前的培训。
  x_cleaned = x.dropna（）
y_cleaned = y [x_cleaned.index]
x_training，x_test，y_training，y_test = train_test_split（x_cleaned，y__cleaned，test_size = 0.15，Random_State = 0）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79439462/how-to-train-sklearn-model-in-different-dataframes</guid>
      <pubDate>Fri, 14 Feb 2025 13:01:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么2048年游戏训练对我来说不正常？</title>
      <link>https://stackoverflow.com/questions/79411336/why-is-training-for-the-game-2048-not-working-well-for-me</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79411336/why-is-training-for-the-game-2048-not-working-well-for-me</guid>
      <pubDate>Tue, 04 Feb 2025 10:28:14 GMT</pubDate>
    </item>
    <item>
      <title>培训LLM在图数据库中用于查询生成的LLM</title>
      <link>https://stackoverflow.com/questions/77613507/training-llm-for-query-generation-in-a-graph-database</link>
      <description><![CDATA[如果我已经开发了一个具有自己的查询语言的图形数据库。我必须找到一种方法来馈送图形，然后LLM应该能够生成我们数据库的查询。
我在Langchain中发现了类似的东西，我们可以将其喂入RDF文件，然后将生成Sparql查询。
所以我对此有很多疑问，因为我非常陌生：
是否可以像我们的数据库那样培训LLM上的全新技术。如果可能的话，那么如何。
我知道我们必须向LLM提供培训数据。因此，在这种情况下，将是我们数据库查询的数据集。如果是，那么我们必须在数据集中提供多少查询。
对不起，如果没有详细详细介绍，这只是我第二次在这里问。]]></description>
      <guid>https://stackoverflow.com/questions/77613507/training-llm-for-query-generation-in-a-graph-database</guid>
      <pubDate>Wed, 06 Dec 2023 13:34:06 GMT</pubDate>
    </item>
    <item>
      <title>预测后解开数据麻烦</title>
      <link>https://stackoverflow.com/questions/76020437/trouble-unscaling-data-after-predictions</link>
      <description><![CDATA[我正在研究一个项目，我正在尝试预测1970年至2022年的MLB播放器统计数据。我有2个数据集，一个用于击球手，我预测5个具有20个功能的统计数据，另一个用于投手，我可以预测。 6个具有25个功能的统计数据。我目前正在研究决策树模型，但也计划使用线性回归和LSTM模型。
在最初缩放数据集之前，我删除了我使用的字符串列，年度和列来比较结果。
  remove_bat_cols = [&#39;name&#39;，&#39;tm&#39;，&#39;年&#39;，&#39;nxt_ba&#39;，&#39;nxt_rbi&#39;，&#39;nxt_hr&#39;，&#39;nxt_bb&#39;，&#39;nxt_bb&#39;，&#39;nxt_so&#39;]
remove_pitch_cols = [&#39;name&#39;，&#39;tm&#39;，&#39;年&#39;，&#39;nxt_era&#39;，&#39;nxt_so&#39;，&#39;nxt_whip&#39;，&#39;nxt_bb&#39;，&#39;nxt_w&#39;，&#39;nxt_w&#39;，&#39;nxt_sv&#39;]

BAT_COLS =击球。
pitch_cols =俯仰。
 
我然后缩放了我的数据
  sualer = minmaxscaler（）
thatting.loc [：，bat_cols] = scaler.fit_transform（击球[BAT_COLS]）
pitching.loc [：,, pitch_cols] = scaler.fit_transform（pitching [pitch_cols]）
 
我最初试图将步骤扭转为解开
  thatting.loc [：，bat_cols] = scaler.inverse_transform（击球[bat_cols]）
pitching.loc [：,, pitch_cols] = scaleer.inverse_transform（pitching [pitch_cols]）
 
但我收到以下错误：
  valueerror：操作数无法与形状一起播放（26768,29）（31，）（26768,29） 
 
我还尝试添加预测的列，甚至仅尝试过预测的列并接收相同的列。]]></description>
      <guid>https://stackoverflow.com/questions/76020437/trouble-unscaling-data-after-predictions</guid>
      <pubDate>Sat, 15 Apr 2023 05:00:54 GMT</pubDate>
    </item>
    <item>
      <title>Azure机器学习</title>
      <link>https://stackoverflow.com/questions/70853882/azure-machine-learning</link>
      <description><![CDATA[我可以在Azure中创建机器学习工作区，因为我不能选择一个区域。
你能帮我吗？
 错误  ]]></description>
      <guid>https://stackoverflow.com/questions/70853882/azure-machine-learning</guid>
      <pubDate>Tue, 25 Jan 2022 18:32:29 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow.js的最佳模型类型用于颜色预测？</title>
      <link>https://stackoverflow.com/questions/53416245/best-model-type-in-tensorflow-js-for-color-prediction</link>
      <description><![CDATA[我意识到出现问题时，我正在创建一个颜色预测因子。我让模型成功地工作，但是预测总是在约2.5至5.5的同一中值范围内。该模型应该输出与每种颜色相对应的0到达8，并且每种颜色的数据点均匀量。是否可以使用更好的模型，以便它可以预测某些内容为0或7？我认为不会，因为它认为他们是某种异常值。
这是我的模型
  const Model = tf.sequenenty（）;

const hidden = tf.layers.dense（{{
  单位：3，
  INPUTSHAPE：[3] //每个输入具有3个值R，G和B
}）;
const output = tf.layers.dense（{{
  单位：1 //只有一个输出（与RGB值相对应的颜色
    }）;
model.Add（隐藏）;
model.Add（输出）;

model.compile（{
  激活：“ Sigmoid”，
  损失：“ MeansquaredError”，
  优化器：tf.train.sgd（0.005）
}）;
 
这是我问题的好模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/53416245/best-model-type-in-tensorflow-js-for-color-prediction</guid>
      <pubDate>Wed, 21 Nov 2018 16:14:03 GMT</pubDate>
    </item>
    </channel>
</rss>