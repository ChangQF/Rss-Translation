<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 18 Jul 2024 21:14:26 GMT</lastBuildDate>
    <item>
      <title>ValueError：在 dim 1 处预期长度为 129 的序列（得到 46）</title>
      <link>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</guid>
      <pubDate>Thu, 18 Jul 2024 18:40:37 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音转文本和翻译（直播）</title>
      <link>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</link>
      <description><![CDATA[我有一个用例，我将在直播中录制一段演讲，并且我希望实时获得音频的文本转录，然​​后翻译该转录。
我是否需要使用 Google 的语音转文本 API，然后将生成的文本发送到翻译 API，还是可以在一行中完成？]]></description>
      <guid>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</guid>
      <pubDate>Thu, 18 Jul 2024 17:21:16 GMT</pubDate>
    </item>
    <item>
      <title>我需要在时间序列预测中“转移”我的新目标变量吗？</title>
      <link>https://stackoverflow.com/questions/78765782/do-i-need-to-shift-my-new-target-variable-in-time-series-prediction</link>
      <description><![CDATA[当我有时间序列数据但不想预测序列的值时。相反，我会创建一个新的目标变量，该变量为我提供方向（1 表示增加，0 表示减少）而不是值，从而将其转化为分类问题。
我需要“转移”我的新目标变量吗？
我试过了
def binary(dataframe):
dataframe[&#39;previous_day_close&#39;] = dataframe[&#39;Close&#39;].shift(1)
dataframe[&#39;direction&#39;] = 0
dataframe.loc[dataframe[&#39;Close&#39;] &gt; dataframe[&#39;previous_day_close&#39;], &#39;direction&#39;] = 1
dataframe.drop(columns=[&#39;previous_day_close&#39;], inplace=True)
return dataframe[&#39;direction&#39;].head()

binary(petr3)

days = 3

petr3[&#39;shift_direction&#39;] = petr3[[&#39;direction&#39;]].shift(-days )

petr3.dropna(inplace = True)

petr3[&#39;shift_direction&#39;] = petr3[&#39;shift_direction&#39;].astype(&#39;int64&#39;)

有了这个，我现在可以使用分类模型对转换后的时间序列进行预测了吗？这种转变是必要的技术吗？顺便说一下，我也需要转移我的变量吗？]]></description>
      <guid>https://stackoverflow.com/questions/78765782/do-i-need-to-shift-my-new-target-variable-in-time-series-prediction</guid>
      <pubDate>Thu, 18 Jul 2024 17:01:20 GMT</pubDate>
    </item>
    <item>
      <title>安装 open-pose 时出现问题</title>
      <link>https://stackoverflow.com/questions/78763910/issue-installing-open-pose</link>
      <description><![CDATA[我一直按照官方页面 (https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation/0_index.md) 上针对 ubuntu (22.04) 的安装步骤进行操作，似乎已经安装完毕。但是，在测试部分，我正在运行：
*# Ubuntu 和 Mac
./build/examples/openpose/openpose.bin --video examples/media/video.avi*

但是它不起作用，这是我得到的
upo@upo-Stealth-15M-A11SEK:~/openpose$ ./build/examples/openpose/openpose.bin --video examples/media/video.avi
正在启动 OpenPose 演示...
正在配置 OpenPose...
正在启动线程...
正在自动检测所有可用的 GPU...检测到 1 个 GPU，使用其中 1 个，从 GPU 0 开始。
F0718 11:32:00.771245 104120 syncedmem.cpp:71] 检查失败：错误 == cudaSuccess（2 vs. 0）内存不足
***检查失败堆栈跟踪：***
@ 0x7271ad411b03 google::LogMessage::Fail()
@ 0x7271ad4199d1 google::LogMessage::SendToLog()
@ 0x7271ad4117c2 google::LogMessage::Flush()
@ 0x7271ad41378f google::LogMessageFatal::~LogMessageFatal()
@ 0x7271ac2af1ba caffe::SyncedMemory::mutable_gpu_data()
@ 0x7271ac2e461c caffe::CuDNNConvolutionLayer&lt;&gt;::Forward_gpu()
@ 0x7271ac2700c2 caffe::Net&lt;&gt;::ForwardFromTo()
@ 0x7271ad01fac7 op::NetCaffe::forwardPass()
@ 0x7271ad03b132 op::PoseExtractorCaffe::forwardPass()
@ 0x7271ad035a1c op::PoseExtractor::forwardPass()
@ 0x7271ad033690 op::WPoseExtractor&lt;&gt;::work()
@ 0x7271ad065e6f op::Worker&lt;&gt;::checkAndWork()
@ 0x7271ad066033 op::SubThread&lt;&gt;::workTWorkers()
@ 0x7271ad0732cd op::SubThreadQueueInOut&lt;&gt;::work()
@ 0x7271ad069cb1 op::Thread&lt;&gt;::threadFunction()
@ 0x7271acadc253 (未知)
@ 0x7271ac694ac3 (未知)
@ 0x7271ac726850 (未知)
@ (nil) (未知)
已中止 (核心转储)

我认为，我应该能够运行该示例，因为我有一台 6GB 的 RTX 2060，但它说我的内存不足……所以我不知道如何解决这个问题。
我只想获取 open pose 可以提供的 json 文件，以便我可以将其用于 NN。如果没有解决方案，是否可以使用其他工具获取与 openpose 格式相同的 json 文件？ （作为 mediapipe 或 yolo-pose）我尝试过 yolo（它工作正常）但格式不一样，并且网络经过训练以获取 openpose 格式。
pd：我已经安装了 CUDA 12.4 和 CUDNN 8.9，并且它们应该可以正常工作，因为它们被 tensorflow 识别]]></description>
      <guid>https://stackoverflow.com/questions/78763910/issue-installing-open-pose</guid>
      <pubDate>Thu, 18 Jul 2024 10:46:03 GMT</pubDate>
    </item>
    <item>
      <title>lmdb.InvalidParameterError：/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc.db：参数无效</title>
      <link>https://stackoverflow.com/questions/78763677/lmdb-invalidparametererror-data-project-hsi-foundation-hypersigma-imagedenoisi</link>
      <description><![CDATA[我正在下面的 hypersigma github 上工作。请参考下面的链接。顺便说一下，我遇到了一个问题。

HyperSIGMA github 链接：https://github.com/WHU-Sigma/HyperSIGMA

输入是从下面的网站下载的 dc.tif 文件，我使用 &#39;mat_data.py&#39; 的 create_WDC_dataset 函数创建了两个 mat 文件（train_0.mat、train_1.mat）。然后我们尝试将这两个 mat 文件（train_0.mat、train_1.mat）转换为 wdc.db 文件。
我尝试通过lmdb_data.py的createDCmall函数在wdc.db文件夹中创建data.mdb，lock.mdb，meta_info.txt文件，但是没有创建meta_info.txt文件，下面是相关错误。

https://engineering.purdue.edu/~biehl/MultiSpec/hyperspectral.html
华盛顿特区购物中心图片 (145MB) --------&gt; (dc.tif)

======================命令结果开始=========================
(venv) techwinjeo@gpusystem:~/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility$ python lmdb_data.py 

create wdc...
(1587, 191, 8, 8)
地图大小 (GB): 0.17344493865966795
/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc6.db
回溯（最近一次调用）：
文件&quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 95 行，位于 &lt;module&gt;
createDCmall()
文件 &quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 85 行，位于 createDCmall
create_lmdb_train(
文件 &quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 55 行，位于 create_lmdb_train
env = lmdb.open(name+&#39;.db&#39;, map_size=map_size, writemap=True)
lmdb.InvalidParameterError: /data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc.db: 参数无效

=======================命令结果结束=========================
任何帮助都非常感谢👍
谢谢你：D
我期待在下面的文件路径中创建以下三个文件。

路径：/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc

wdc.db
|
|----- data.mdb
|----- lock.mdb
└----- meta_info.txt
]]></description>
      <guid>https://stackoverflow.com/questions/78763677/lmdb-invalidparametererror-data-project-hsi-foundation-hypersigma-imagedenoisi</guid>
      <pubDate>Thu, 18 Jul 2024 09:58:58 GMT</pubDate>
    </item>
    <item>
      <title>在模型训练中，处理 Web 应用程序上的错误输入数据时遇到困难</title>
      <link>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</guid>
      <pubDate>Thu, 18 Jul 2024 09:48:16 GMT</pubDate>
    </item>
    <item>
      <title>PipeOp classif.avg (mlr3) 错误：对“prob”的断言失败：包含缺失值（元素 1）</title>
      <link>https://stackoverflow.com/questions/78763091/error-with-pipeop-classif-avg-mlr3-assertion-on-prob-failed-contains-missi</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78763091/error-with-pipeop-classif-avg-mlr3-assertion-on-prob-failed-contains-missi</guid>
      <pubDate>Thu, 18 Jul 2024 07:56:11 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的分割</title>
      <link>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</link>
      <description><![CDATA[即使将单个特征输入模型，神经网络是否也能从细分中受益？
目前我的模型具有基于用户交互和时间的特征。
如果我们根据这些特征输入一些客户细分，我的模型是否会受益？]]></description>
      <guid>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</guid>
      <pubDate>Thu, 18 Jul 2024 04:04:29 GMT</pubDate>
    </item>
    <item>
      <title>自定义参数激活函数导致 NaN 损失和权重</title>
      <link>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</guid>
      <pubDate>Wed, 17 Jul 2024 20:02:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAN 进行欺诈检测</title>
      <link>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</link>
      <description><![CDATA[我正在使用 GAN 实现基于交易的欺诈检测模型，但我仍然想指定我的模型，即我想强调 RIB 和交易时间（尤其是发行时间）我想知道个人通过这些变量（时间和 RIB）的行为如何影响交易是否是欺诈性的。基本上，这个模型很好，但它仍然很肤浅，我们需要通过强调提到的变量来更深入地研究。
我的数据集的头部
就像我说的，我尝试了一个通用的 GAN 模型，但我想实现一个专注于 RIB 和发行时间的指定 GAN 模型]]></description>
      <guid>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</guid>
      <pubDate>Wed, 17 Jul 2024 19:15:59 GMT</pubDate>
    </item>
    <item>
      <title>使用单个标记和二元标记进行语料库预处理的最佳方法？</title>
      <link>https://stackoverflow.com/questions/78758590/best-approach-corpus-pre-processing-with-single-tokens-and-bigram-tokens</link>
      <description><![CDATA[我想知道是否有关于如何以最聪明的方式解决这个问题的一般建议。
我正在使用 word2vec 来确定特定单词之间的相似度分数（这是我感兴趣的最终输出） - 其中一些是单个标记，但其他应该是二元词组。更复杂的是，我正在使用 tensorflow（为了学习如何使用 tensorflow）。
我想保留在单独列表中找到的二元语法：
Bigram_list = [&quot;northern lights&quot;, &quot;cloud cover&quot;, &quot;table leg&quot;,...]

目前，该过程应如下所示：

识别语料库中的二元语法（使用 nltk 搭配）
创建 identified_bigrams_list = [&quot;northern lights&quot;, &quot;cloud cover&quot;, &quot;banana peel&quot;,...]
在 identified_bigrams_list 中搜索匹配项Bigram_list
问题：用“_”替换语料库中的匹配项，例如“northern_light”、“cloud_cover”。我尝试使用 Bigram_list 的字典（例如 “northern lights”：“northern_lights”）。所以我试图将其放回语料库中，这样它将被视为单个标记并作为单个嵌入进行处理

即使我可以让它工作，但这似乎在计算上效率低下，尤其是当我转向更大的语料库进行实际训练时（目前使用一个很小的语料库来让它工作）。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78758590/best-approach-corpus-pre-processing-with-single-tokens-and-bigram-tokens</guid>
      <pubDate>Wed, 17 Jul 2024 09:02:44 GMT</pubDate>
    </item>
    <item>
      <title>设置具有序列的数组元素请求数组在 1 维之后具有不均匀形状</title>
      <link>https://stackoverflow.com/questions/78749448/setting-an-array-element-with-a-sequence-requested-array-has-an-inhomogeneous-sh</link>
      <description><![CDATA[当我拟合各种人工神经网络时，TLNN 的代码显示为不正确，尤其是包含重塑函数的那一行。这有什么问题吗？
def Forecast_TLNN(model, time_lagged_points, last_sequence, Future_steps):
Forecasted_values = []
max_lag = max(time_lagged_points)
for i in range(future_steps):
input_sequence = [last_sequence[max_lag - p] for p in time_lagged_points]
Forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
Forecasted_values.append(forecasted_value[0][0])
last_sequence = last_sequence[1:] + [forecasted_value[0][0]]
return Forecasted_values

错误显示在以下行：forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
我似乎无法在互联网上找到有关此代码的任何更正。
---------------------------------------------------------------------------
ValueError Traceback (most recent call last)

Cell In[223]，第 6 行，在 Forecast_TLNN(model, time_lagged_points, last_sequence, Future_steps) 中
4 for i in range(future_steps):
5 input_sequence = [last_sequence[max_lag - p] for p in time_lagged_points]
----&gt; 6 Forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
7 Forecasted_values.append(forecasted_value[0][0])
8 last_sequence = last_sequence[1:] + [forecasted_value[0][0]]

文件 ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:285，在 reshape(a, newshape, order) 中
200 @array_function_dispatch(_reshape_dispatcher)
201 def reshape(a, newshape, order=&#39;C&#39;):
202 &quot;&quot;&quot;
203 为数组赋予新形状而不更改其数据。
204 
(...)
283 [5, 6]])
284 &quot;&quot;&quot;
--&gt; 285 返回 _wrapfunc(a, &#39;reshape&#39;, newshape, order=order)

文件 ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:56，位于 _wrapfunc(obj, method, *args, **kwds)
54 bound = getattr(obj, method, None)
55 如果 bound 为 None:
---&gt; 56 return _wrapit(obj, method, *args, **kwds)
58 try:
59 return bound(*args, **kwds)

File ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:45, in _wrapit(obj, method, *args, **kwds)
43 except AttributeError:
44 wrap = None
---&gt; 45 result = getattr(asarray(obj), method)(*args, **kwds)
46 if wrap:
47 if not isinstance(result, mu.ndarray):

ValueError: 设置带有序列的数组元素。请求的数组在 1 维之后具有非均匀形状。检测到的形状为 (5,) + 非均匀部分。
]]></description>
      <guid>https://stackoverflow.com/questions/78749448/setting-an-array-element-with-a-sequence-requested-array-has-an-inhomogeneous-sh</guid>
      <pubDate>Mon, 15 Jul 2024 10:54:58 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试使用数据集包创建数据集时，出现“无法转换，因为列名不匹配”错误</title>
      <link>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</link>
      <description><![CDATA[DataFrame 结构
上图显示了我的数据的结构。
from sklearn.model_selection import train_test_split
from datasets import Features, ClassLabel, Value, Dataset, DatasetDict

df_train, df_tmp = train_test_split(
movie_df,stratify=movie_df[&quot;label&quot;], test_size=0.2)

df_val, df_test = train_test_split(
df_tmp,stratify=df_tmp[&quot;label&quot;], test_size=0.5)

ds_features = Features({&quot;text&quot;: Value(&quot;string&quot;), &quot;label&quot;: ClassLabel(names=labels)})

dataset = DatasetDict({
&quot;train&quot;: Dataset.from_pandas(df_train.reset_index(drop=True),features=ds_features),
&quot;valid&quot;: Dataset.from_pandas(df_val.reset_index(drop=True),features=ds_features),
&quot;test&quot;: Dataset.from_pandas(df_test.reset_index(drop=True),features=ds_features)})

dataset

此代码给我一个值错误，如下所示：
错误
错误
我期望得到类似的东西，但值不一样：
DatasetDict({
train: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 13267
})
valid: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1658
})
test: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1659
})
})

有人能告诉我我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</guid>
      <pubDate>Wed, 13 Mar 2024 04:00:13 GMT</pubDate>
    </item>
    <item>
      <title>SKlearn 分类器的 predict_proba 总和不为 1</title>
      <link>https://stackoverflow.com/questions/76626629/sklearn-classifiers-predict-proba-doesnt-sum-to-1</link>
      <description><![CDATA[我有一个分类器（在本例中为 sklearn.MLPClassifier），我试图用它对 18 个类别中的其中一个进行分类。
因此，该类别是多类别，而不是多标签。我试图仅预测单个类别。
我有训练数据：X X.shape = (103393, 300) 和 Y Y.shape = (103393, 18)，其中目标 Y 是一个独热编码向量，表示目标类别。

编辑以回应@Dr. Snoopy：我不提供任何标签 - 我只是传递 18 维向量，其正确类别的索引对应于向量中的 1，其他所有向量均为 0（独热编码向量）。
为了证明向量正确地进行了 1-hot 编码，我可以运行

import pandas as pd
pd.DataFrame(Y.sum(axis=1)).value_counts()


这将返回 103393 个计数 1。即使经过检查，向量也正确地进行了 1-hot 编码。

当我拟合模型并返回所有类的类概率时，概率向量的总和不为 1。为什么会这样？
以下是我运行拟合的示例：
from sklearn.neural_network import MLPClassifier

X_train, Y_train, X_test, Y_test = get_data()

model = MLPClassifier(max_iter=10000)
model.fit(X_train,Y_train)
probability_vector = model.predict_proba(X_test[0, :].respahe(1,-1))

有时，输出非常接近 1。我怀疑错误可能是由于四舍五入造成的。
在其他情况下，输出总和约为 0.5 或更小。示例输出：
probability_vector = list(model.predict_proba(X_test[301,:].reshape(1,-1))[0])
print(probability_vector)
&gt;&gt;&gt; [1.7591416e-06、3.148203e-05、3.9732524e-05、0.3810972、0.059248358、0.00032832936、8.5996935e-06、9.0914684e-05、 -07, 0.0007674346, 1.5543707e-06, 0.0008467222, 0.009655427, 2.5728454e-05, 1.07812774e-07, 0.00022920035,
0.00050288404,
0.013878004]

len(probability_vecto)

&gt;&gt;&gt; 18

sum(probability_vector)
&gt;&gt;&gt; 0.46675437349917814


为什么会发生这种情况？我的模型初始化不正确吗？

注意：错误可能有几个原因以及我的评论：

类别不平衡：数据集中的类别确实不平衡。但是，非 1 求和问题也发生在代表性良好的类别中，而不仅仅是代表性不足的类别。这可能是模型表达能力不够的结果吗？

模型不确定性：“模型可能对每个输入的预测没有很高的信心。”就是这样吗？


]]></description>
      <guid>https://stackoverflow.com/questions/76626629/sklearn-classifiers-predict-proba-doesnt-sum-to-1</guid>
      <pubDate>Thu, 06 Jul 2023 07:51:28 GMT</pubDate>
    </item>
    <item>
      <title>带有 gpu 的 Lightgbm 分类器</title>
      <link>https://stackoverflow.com/questions/60360750/lightgbm-classifier-with-gpu</link>
      <description><![CDATA[model = lgbm.LGBMClassifier(
n_estimators=1250,
num_leaves=128,
learning_rate=0.009,
verbose=1
)

使用 LGBM 分类器，
现在有没有办法将其与 GPU 一起使用？]]></description>
      <guid>https://stackoverflow.com/questions/60360750/lightgbm-classifier-with-gpu</guid>
      <pubDate>Sun, 23 Feb 2020 09:20:03 GMT</pubDate>
    </item>
    </channel>
</rss>