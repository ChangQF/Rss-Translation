<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 05 Apr 2024 00:58:39 GMT</lastBuildDate>
    <item>
      <title>如何找到不同公司竞争对手产品矩阵与特定品牌数据集的相关性？有机器学习来预测适合度吗？</title>
      <link>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</link>
      <description><![CDATA[我非常感谢有关此挑战的任何建议，我正在尝试找到数据集（矩阵）的相关性，该数据集（矩阵）包含行上的客户和他们按列拥有的竞争对手产品（拥有=&#39;是&#39;，不拥有= “否”）以及拥有我们品牌的客户的另一个数据集（拥有=1，不拥有=0）。我可以使用任何机器学习模型或算法来根据客户拥有的产品来预测客户的适合度吗？请记住，我们品牌数据集中的所有零值都是潜在客户。
我尝试了随机森林，但我们对拥有我们品牌的客户的所有价值观都是积极的，我如何根据所有积极的价值观来预测适合度？]]></description>
      <guid>https://stackoverflow.com/questions/78277282/how-can-i-find-the-correlation-of-a-matrix-of-competitor-products-of-different-c</guid>
      <pubDate>Fri, 05 Apr 2024 00:53:35 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“tensorflow”没有属性“Summary”</title>
      <link>https://stackoverflow.com/questions/78277279/attributeerror-module-tensorflow-has-no-attribute-summary</link>
      <description><![CDATA[运行此代码时：
def scalar_summary(自身、标签、值、步骤)：
“”“记录标量变量。”“”
摘要 = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])
self.writer.add_summary(摘要，步骤)
我收到错误消息：
AttributeError：模块“tensorflow”没有属性“Summary”。您指的是：“摘要”吗？
我正在尝试运行 https:/ 中的代码Google colabs 上的 /github.com/InhwanBae/ENet-SAD_Pytorch/blob/master/utils/tensorboard.py。我正在尝试使用 CULane 数据集训练 ENet-SAD 模型。]]></description>
      <guid>https://stackoverflow.com/questions/78277279/attributeerror-module-tensorflow-has-no-attribute-summary</guid>
      <pubDate>Fri, 05 Apr 2024 00:51:51 GMT</pubDate>
    </item>
    <item>
      <title>Keras 3 与 Pytorch 后端 - 自定义 test_step</title>
      <link>https://stackoverflow.com/questions/78277162/keras-3-with-pytorch-backend-custom-test-step</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78277162/keras-3-with-pytorch-backend-custom-test-step</guid>
      <pubDate>Fri, 05 Apr 2024 00:00:45 GMT</pubDate>
    </item>
    <item>
      <title>线性回归调整问题：学习率与方程精度 (Python)</title>
      <link>https://stackoverflow.com/questions/78276066/linear-regression-adjustment-issue-learning-rate-vs-equation-accuracy-python</link>
      <description><![CDATA[我正在尝试以 0.01 的学习率调整线性回归。但是，我遇到了一个问题，线路似乎无法正确调整。该线似乎没有遵循学习率规定的预期路径，而是随机移动到不同的位置，而没有正确对齐。我确信这不是因为学习率，而是因为方程。
这是我尝试过的
from sklearn.datasets import make_regression, make_classification, make_blobs
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
将随机导入为 rd

# 1.make_regression
x, y = make_regression(
  n_样本=100，
  n_特征=1，
  噪音=30
）

# 2.make_classification
train_x = x[:-20]
test_x = x[-20:]

train_y = y[:-20]
test_y = y[-20:]

# 3.make_blob
def graph_linear_regression():
  # 绘制数据
  plt.scatter(train_x, train_y, color=&#39;blue&#39;, label=&#39;Data&#39;)

  # 绘制线性回归线
  plt.plot(train_x, train_x, color=&#39;red&#39;, label=&#39;线性回归&#39;)

  # 添加标签和标题
  plt.xlabel(&#39;x&#39;)
  plt.ylabel(&#39;y&#39;)
  plt.title(&#39;线性回归&#39;)

  # 显示绘图
  plt.图例()
  plt.show()

# 4.计算误差
defcalculate_update_error():
  全球米
  全球b
  学习率 = 0.01
  # 计算误差
  # M = 1/n * 总和(f(x) - y)
  # B = 1/n * 总和(f(x) - y) * x

  M = 1 / n * np.sum(f(train_x) - train_y)
  B = 1 / n * np.sum(np.sum(f(train_x) - train_y) * train_x)

  m = m - 学习率 * M
  b = b - 学习率 * B

# 计算线性回归
# 步骤 1 - 初始化

m = rd.randint(1, 100)
b = rd.randint(1, 100)
n = len(train_x)
学习率 = 0.01

打印（f“n：{n}”）
打印（f“m：{m}”）
打印（f“b：{b}”）
print(f“学习率：{学习率}”)

定义 f(x)：
  返回 m * x + b

＃ 问题？
对于范围 (n) 内的 i：
  计算更新错误()
  打印（）

graph_linear_regression()

这就是我得到的
在此处输入图像描述
现在，这就是我想要获得的，这是使用最小平方
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78276066/linear-regression-adjustment-issue-learning-rate-vs-equation-accuracy-python</guid>
      <pubDate>Thu, 04 Apr 2024 18:58:26 GMT</pubDate>
    </item>
    <item>
      <title>为什么在启用 from_logits 的情况下使用 BinaryCrossEntropy 生成器损失？</title>
      <link>https://stackoverflow.com/questions/78275777/why-generator-loss-using-binarycrossentropy-with-from-logits-enabled</link>
      <description><![CDATA[从简单的普通 GAN 代码中，我查看  GitHub
我看到这个生成器模型具有激活sigmoid：
&lt;前&gt;&lt;代码&gt;# 生成器
G = tf.keras.models.Sequential([
  tf.keras.layers.Dense(28*28 // 2, input_shape = (z_dim,), 激活=&#39;relu&#39;),
  tf.keras.layers.Dense(28*28, 激活=&#39;sigmoid&#39;),
  tf.keras.layers.Reshape((28, 28))])

在启用 from_logits 的情况下，G 的损失定义如下：
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)
def G_loss(D, x_fake):
  返回 cross_entropy(tf.ones_like(D(x_fake)), D(x_fake))

据我所知，from_logits=True旨在使损失函数接受范围在-infinity到&lt;之间的y_pred值代码&gt;无穷大。与 from_logits=False 相反，损失函数假设值的范围在 0 到 1 之间。
如您所见，G 模型的输出层已经具有 sigmoid 激活，其范围在 0 到 1.
但是，为什么作者仍然使用 from_logits=True？]]></description>
      <guid>https://stackoverflow.com/questions/78275777/why-generator-loss-using-binarycrossentropy-with-from-logits-enabled</guid>
      <pubDate>Thu, 04 Apr 2024 18:03:32 GMT</pubDate>
    </item>
    <item>
      <title>如何得到Adam训练时的平均学习率？</title>
      <link>https://stackoverflow.com/questions/78275586/how-to-get-the-average-learning-rate-for-adam-during-training</link>
      <description><![CDATA[Adam 优化器的每个参数都有一个自适应学习率，该学习率在训练期间会发生变化。我试图获得所有参数的平均学习率。我发现这个SO问题有一个相关的问题，并且建议使用答案之一（没有接受此问题的答案）
def get_current_lr（优化器，group_idx，parameter_idx）：
    # Adam 对每个参数都有不同的学习率。所以我们需要选择
    # 首先是组和参数。
    组=optimizer.param_groups[group_idx]
    p = 组[&#39;params&#39;][parameter_idx]

    beta1, _ = 组[&#39;betas&#39;]
    状态 = 优化器.状态[p]

    bias_ Correction1 = 1 - beta1 ** 状态[&#39;step&#39;]
    current_lr = group[&#39;lr&#39;] /bias_ Correction1 / torch.sqrt(state[&#39;exp_avg_sq&#39;] + 1e-8)
    返回当前_lr

我尝试根据我的情况调整它以获得平均值，但结果没有多大意义，因为学习率似乎高得离谱（有时超过 15）。所以我想知道这是否是正确的方法，或者我是否遗漏了一些东西。
导入火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim

火炬.manual_seed(42)

def get_current_lr(优化器):
    # Adam 对每个参数都有不同的学习率。所以我们需要选择
    # 首先是组和参数。
    劳斯莱斯 = []
    对于范围内的 group_idx(len(optimizer.param_groups))：
        组=optimizer.param_groups[group_idx]
        对于范围内的parameter_idx(len(opt.param_groups[group_idx][&#39;params&#39;]))：
            p = 组[&#39;params&#39;][parameter_idx]

            beta1, _ = 组[&#39;betas&#39;]
            状态 = 优化器.状态[p]

            bias_ Correction1 = 1 - beta1 ** 状态[&#39;step&#39;]
            current_lr = group[&#39;lr&#39;] /bias_ Correction1 / torch.sqrt(state[&#39;exp_avg_sq&#39;] + 1e-8)
            # 打印(current_lr.mean())
            lrs.append(current_lr.mean().item())

    返回总和(lrs)/len(lrs)

类模型（nn.Module）：
    def __init__(自身):
        超级（模型，自我）.__init__()
        self.fc1 = nn.Linear(10, 100)
        self.fc2 = nn.Linear(100, 1)

    def 前向（自身，x）：
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        返回x

净=模型（）
# opt = optim.SGD(net.parameters(), lr=1e-2)
opt = optim.Adam(net.parameters())

特征 = torch.rand((100,10))
x_goal = torch.tensor(100)

对于范围（100）内的纪元：
    x = 净值（特征）
    损失 = torch.square(x_goal - x).mean()
    opt.zero_grad()
    loss.backward()
    opt.step()
    如果纪元 % 5 == 0 ：
        打印（获取当前lr（选择））
&gt;&gt;&gt;&gt;&gt;
16.065366545983125
3.296213309022278
2.23316600310136
1.8703228593794847
1.7041209160006474
1.6200325103309297
1.5739126955249958
1.5481085549622549
1.5332565682870154
1.5246047580963022
1.5195341832059057
1.5165529197865908
1.5148021120267003
1.5137746352747854
1.5131711492076647
1.512817604085285
1.5126127881085267
1.5124981075282449
1.5124379168978521
1.5124109954704181
]]></description>
      <guid>https://stackoverflow.com/questions/78275586/how-to-get-the-average-learning-rate-for-adam-during-training</guid>
      <pubDate>Thu, 04 Apr 2024 17:26:49 GMT</pubDate>
    </item>
    <item>
      <title>验证集和测试集之间的性能差距（ResNet-18、k-Fold CV）</title>
      <link>https://stackoverflow.com/questions/78275584/performance-gap-between-validation-and-test-sets-resnet-18-k-fold-cv</link>
      <description><![CDATA[我正在使用 k 折交叉验证开发二值图像分类器 (ResNet-18)。训练过程中，模型的最高验证准确率达到99%。然而，在单独的测试集上，准确率下降至 92%。我还观察到损失函数有类似的趋势，其中验证损失比测试集损失更低。训练数据和测试数据中的标签分布是平衡的。
为什么验证集和测试集之间的性能存在如此显着的差异？]]></description>
      <guid>https://stackoverflow.com/questions/78275584/performance-gap-between-validation-and-test-sets-resnet-18-k-fold-cv</guid>
      <pubDate>Thu, 04 Apr 2024 17:26:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 Snowflake Cortex 函数作为外部阶段</title>
      <link>https://stackoverflow.com/questions/78275339/use-snowflake-cortex-functions-for-external-stage</link>
      <description><![CDATA[我正在尝试将 Snowflake Cortex 函数用于外部阶段（Azure）。函数对于普通表运行良好，但我不知道如何在外部阶段运行它。
下面的示例适用于普通表：
选择 SNOWFLAKE.CORTEX.COMPLETE(&#39;llama2-70b-chat&#39;,concat(&#39;&#39; , &#39;- ddl: &#39;, get_ddl(&#39;table &#39;,&#39;&lt;数据库&gt;.&lt;架构&gt;.&lt;表&gt;&#39;)))

这就是我从外部阶段选择数据的方式，它工作正常：
从 @azure_stage t 中选择 $1、$2；

我不知道如何将 LLAMA2 用于外部舞台。
有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78275339/use-snowflake-cortex-functions-for-external-stage</guid>
      <pubDate>Thu, 04 Apr 2024 16:40:04 GMT</pubDate>
    </item>
    <item>
      <title>可能是什么引发了错误：ValueError：X 有 23 个特征，但 SVR 期望 24 个特征作为输入？</title>
      <link>https://stackoverflow.com/questions/78275238/what-may-be-raising-the-error-valueerror-x-has-23-features-but-svr-is-expecti</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78275238/what-may-be-raising-the-error-valueerror-x-has-23-features-but-svr-is-expecti</guid>
      <pubDate>Thu, 04 Apr 2024 16:21:48 GMT</pubDate>
    </item>
    <item>
      <title>在yolov5s中，我添加了一个带有 [-1, 1, CA, [1024, 1]] 的 CA 层，当我运行 train.py 时，我遇到了这个问题，如何解决这个问题</title>
      <link>https://stackoverflow.com/questions/78275133/in-yolov5s-i-added-a-layer-ca-with-1-1-ca-1024-1-when-i-run-train-py</link>
      <description><![CDATA[运行时错误：给定组=1，权重大小为[32, 1024, 1, 1]，预期输入[1, 512, 16, 1]有1024个通道，但得到了512个通道
在此处输入图片描述
预期输入[1, 512, 16, 1]有1024个通道，但实际有512个通道]]></description>
      <guid>https://stackoverflow.com/questions/78275133/in-yolov5s-i-added-a-layer-ca-with-1-1-ca-1024-1-when-i-run-train-py</guid>
      <pubDate>Thu, 04 Apr 2024 16:03:19 GMT</pubDate>
    </item>
    <item>
      <title>多元线性回归房价r2得分问题</title>
      <link>https://stackoverflow.com/questions/78275121/multiple-linear-regression-house-price-r2-score-problem</link>
      <description><![CDATA[我有样本房价数据和简单代码：
导入 pandas 作为 pd
从 sklearn.preprocessing 导入 LabelEncoder、StandardScaler
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.metrics 导入 r2_score

数据 = pd.read_csv(&#39;house_price_4.csv&#39;)
df = pd.DataFrame(数据)
df[&#39;区域&#39;] = df[&#39;区域&#39;].str.replace(&#39;,&#39;, &#39;&#39;)
df = df.dropna()

# 对分类特征“地址”进行编码
df[&#39;地址&#39;] = df[&#39;地址&#39;].astype(&#39;类别&#39;).cat.codes
df[&#39;停车&#39;] = df[&#39;停车&#39;].replace({True: 1, False: 0})
df[&#39;仓库&#39;] = df[&#39;仓库&#39;].replace({True: 1, False: 0})
df[&#39;电梯&#39;] = df[&#39;电梯&#39;].replace({True: 1, False: 0})

X = df.drop(columns=[&#39;价格(美元)&#39;,&#39;价格&#39;])
y = df[&#39;价格&#39;]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

r_squared = r2_score(y_test, y_pred)
print(f&#39;R^2 得分: {r_squared:.4f}&#39;)

                                                                  

我的 R2 分数非常低：0.34
如何获得更高的 R2 分数？
这是我的示例数据：https://drive.google .com/file/d/14Se90XbGJivftq3_VrtgRSalkCplduVX/view?usp=sharing]]></description>
      <guid>https://stackoverflow.com/questions/78275121/multiple-linear-regression-house-price-r2-score-problem</guid>
      <pubDate>Thu, 04 Apr 2024 16:01:38 GMT</pubDate>
    </item>
    <item>
      <title>ML ColumnTransformer OneHotEncoder</title>
      <link>https://stackoverflow.com/questions/78274904/ml-columntransformer-onehotencoder</link>
      <description><![CDATA[当在数据帧的第一列中转换分类数据时，我发现 ColumnTransformer 与 OneHotEncoder 出现奇怪的行为。当我向 csv 文件添加一行时，就会发生此行为。
初始数据为：
标题、每日总收入、影院、DayInYear
AC汀巴黎,307,5,257
给莫莫的一封信，307,5,257
生命的另一天,307,5,257
批准收养，307,5,257
四月与非凡的世界, 307,5,257
美女,307,5,257
鸟男孩被遗忘的孩子，307,5,257
奇科丽塔,307,5,257

运行代码时
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将 pandas 导入为 pd

数据集 = pd.read_csv(&#39;../data/GKIDS_DayNum_test_names.csv&#39;)
数据集[&#39;标题&#39;].str.strip()
X = dataset.iloc[:, :-1].values
y = dataset.iloc[:, -1].values

从 sklearn.compose 导入 ColumnTransformer
从 sklearn.preprocessing 导入 OneHotEncoder

title_column_index = dataset.columns.get_loc(&#39;标题&#39;)
print(&#39;标题索引：&#39;, title_column_index)
ct = ColumnTransformer(transformers=[(&#39;编码器&#39;, OneHotEncoder(), [title_column_index])], 剩余=&#39;passthrough&#39;)
X_Encoded = np.array(ct.fit_transform(X))
打印（X_编码）

结果是正确的：
&lt;前&gt;&lt;代码&gt;[[1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 307 5]
 [0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 307 5]]

但是，当我添加附加行时：BlueGiant,307,5,257
到文件并重新运行代码我得到奇怪的输出：
&lt;前&gt;&lt;代码&gt; (0, 0) 1.0
  (0, 9) 307.0
  (0, 10) 5.0
  (1, 1) 1.0
  (1, 9) 307.0
  (1, 10) 5.0
  (2, 2) 1.0
  (2, 9) 307.0
  (2, 10) 5.0
  (3, 3) 1.0
  (3, 9) 307.0
  (3, 10) 5.0
  (4, 4) 1.0
  (4, 9) 307.0
  (4, 10) 5.0
  (5, 5) 1.0
  (5, 9) 307.0
  (5, 10) 5.0
  (6, 6) 1.0
  (6, 9) 307.0
  (6, 10) 5.0
  (7, 8) 1.0
  (7, 9) 307.0
  (7, 10) 5.0
  (8, 7) 1.0
  (8, 9) 307.0
  (8, 10) 5.0

我不明白为什么会这样。
请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78274904/ml-columntransformer-onehotencoder</guid>
      <pubDate>Thu, 04 Apr 2024 15:25:57 GMT</pubDate>
    </item>
    <item>
      <title>我在测试模型时遇到未知层错误</title>
      <link>https://stackoverflow.com/questions/78268793/i-am-getting-unknown-layer-error-while-testing-a-model</link>
      <description><![CDATA[错误是这样的：
我tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 TF_ENABLE_ONEDNN_OPTS=0。
2024-04-03 20:51:40.389067：我tensorflow/core/util/port.cc:113] oneDNN 自定义操作已开启。由于不同计算顺序的浮点舍入误差，您可能会看到略有不同的数值结果。要关闭它们，请设置环境变量 TF_ENABLE_ONEDNN_OPTS=0。
警告：tensorflow：来自 C:\Users\DELL\AppData\Local\Programs\Python\Python312\Lib\site-packages\tf_keras\src\losses.py:2976：名称 tf.losses.sparse_softmax_cross_entropy 已弃用。请改用 tf.compat.v1.losses.sparse_softmax_cross_entropy。
2024-04-03 20:51:47.709342: I tensorflow/core/platform/cpu_feature_guard.cc:210] 此 TensorFlow 二进制文件经过优化，可以在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：AVX2 AVX512F AVX512_VNNI FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
回溯（最近一次调用最后一次）：
文件“D:\image title\testing_caption_generator.py”，第 68 行，位于
模型 = 加载模型（
ValueError：未知层：“NotEqual”。请确保您使用的是 keras.utils.custom_object_scope 并且该对象包含在范围内。请参阅https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object 详细信息。
这是我的代码：
从 PIL 导入图像
将 matplotlib.pyplot 导入为 plt
导入argparse
进口泡菜
从 keras.models 导入 load_model
从 keras.layers 导入 Lambda
从 keras.applications.xception 导入 Xception
从 keras.preprocessing.sequence 导入 pad_sequences
从tensorflow.keras.preprocessing.text导入Tokenizer
from pickle import load # 从 pickle 模块导入 load 函数
导入tensorflow_hub作为集线器

# 定义自定义层
def NotEqual(x, y):
    将张量流导入为 tf
    返回 tf.math.not_equal(x, y)

# 定义用于提取特征、生成描述和其他必要实用程序的函数
def extract_features(文件名, 模型):
    尝试：
        图像 = Image.open(文件名)
    除了：
        print(&quot;错误：无法打开图像！请确保图像路径和扩展名正确&quot;)
    图像 = image.resize((299,299))
    图像 = np.array(图像)
    如果图像.shape[2] == 4:
        图像 = 图像[...,:3]
    图像 = np.expand_dims(图像, 轴=0)
    图像=图像/127.5
    图像 = 图像 - 1.0
    特征 = model.predict(图像)
    返回功能

def word_for_id(整数, 分词器):
    对于单词，在 tokenizer.word_index.items() 中索引：
        如果索引==整数：
            返回词
    返回无

defgenerate_desc（模型，分词器，照片，max_length）：
    in_text = &#39;开始&#39;
    对于范围内的 i（最大长度）：
        序列 = tokenizer.texts_to_sequences([in_text])[0]
        序列 = pad_sequences([序列], maxlen=max_length)
        pred = model.predict([照片, 序列], verbose=0)
        pred = np.argmax(pred)
        word = word_for_id(pred, 分词器)
        如果单词为“无”：
            休息
        in_text += &#39; &#39; + 单词
        如果单词==&#39;结束&#39;：
            休息
    返回 in_text

ap = argparse.ArgumentParser()
ap.add_argument(&#39;-i&#39;, &#39;--image&#39;, required=True, help=“图像路径”)
args = vars(ap.parse_args())
img_path = args[&#39;图像&#39;]




#path = &#39;Flicker8k_Dataset/111537222_07e56d5a30.jpg&#39;
最大长度 = 32
tokenizer = pickle.load(open(&quot;tokenizer.p&quot;,&quot;rb&quot;))
路径=&#39;模型/model_9.h5&#39;
模型 = 加载模型（
       （小路），
       custom_objects={&#39;KerasLayer&#39;:hub.KerasLayer}
）
xception_model = Xception(include_top=False, pooling=“avg”)

照片 = extract_features(img_path, xception_model)
img = Image.open(img_path)

描述 =generate_desc(模型、分词器、照片、max_length)
打印(“\n\n”)
打印（描述）
plt.imshow(img)```
]]></description>
      <guid>https://stackoverflow.com/questions/78268793/i-am-getting-unknown-layer-error-while-testing-a-model</guid>
      <pubDate>Wed, 03 Apr 2024 15:32:23 GMT</pubDate>
    </item>
    <item>
      <title>在 Azure Auto ML 上运行模型时遇到奇怪的错误</title>
      <link>https://stackoverflow.com/questions/78237575/strange-error-encountered-when-running-a-model-on-azure-auto-ml</link>
      <description><![CDATA[我已经在 Azure Auto ML 上研究分类器几天了，当我尝试禁用一些不需要的变量时，遇到了以下错误。
我以前从未遇到过此类错误。即使在仅使用我感兴趣的变量创建新数据集之后，错误仍然存​​在。我需要帮助来解决这个问题。谢谢
您在 Auto ML 上的数据集上使用的唯一 SQL 代码是 SELECT * FROM my_table，它可以工作，因为我可以在 Azure ML studio 上看到数据。另外我昨天才开始出现这个错误，我不知道为什么。
获取数据时遇到错误。
错误代码：ScriptExecution.Database.Unexpected
本机错误：数据流访问错误：ExecutionError(DatabaseError(Unknown(&quot;SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \&quot;解析错误位于行：1，列：22：不正确&#39;stmt&#39; 附近的语法。\&quot;，服务器：\&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 }))&quot;, Some( SQLError(Server(TokenError { 代码：103010，状态：1，类：16，消息：“行：1，列：22 处的解析错误：&#39;stmt&#39; 附近的语法不正确。”，服务器：“数据平台-sql-data-warehouse-server”，过程：“”，行：1 }))))))
    VisitError(ExecutionError(DatabaseError(Unknown(&quot;SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \&quot;第 1 行解析错误，第 22 列：“stmt”附近语法不正确) .\&quot;，服务器：\&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 }))&quot;，Some(SQLError(Server(TokenError) { 代码：103010，状态：1，类：16，消息：“第 1 行解析错误，第 22 列：&#39;stmt&#39; 附近的语法不正确。”，服务器：“data-platform-sql-data-仓库服务器”，过程：“”，行：1 })))))))
=&gt;失败并执行错误：执行数据库查询时发生错误。
    ExecutionError(DatabaseError(Unknown(&quot;SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \&quot;行解析错误：1，列：22：&#39;stmt&#39;附近的语法不正确。\ ”，服务器：\“data-platform-sql-data-warehouse-server\”，过程：\“\”，行：1 }))”，Some(SQLError(Server(TokenError { code ：103010，状态：1，类：16，消息：“行：1，列：22处解析错误：‘stmt’附近的语法不正确。”，服务器：“data-platform-sql-data-warehouse-服务器”，过程：“”，行：1 }))))))
错误消息：数据库执行失败，并显示“SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \”解析错误位于行：1，列：22：“stmt”附近的语法不正确。 \&quot;，服务器：\&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 }))&quot;。 “Ok(SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \”解析错误位于行：1，列：22：“stmt”附近的语法不正确。\”，server : \&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 })))&quot;| session_id=af8ac40c-2ffe-410f-8ecb-70e45405ef78

谢谢
我刚刚关闭了模型不需要的一些变量。因此，我只需创建该数据集的新版本，其中变量较少，我可以将其用于新版本的模型，这是我过去几周一直在做的事情。
我创建了一个新数据集，仅包含我需要的变量，但出现了相同的错误。现在，无论我做什么，我似乎总是遇到同样的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78237575/strange-error-encountered-when-running-a-model-on-azure-auto-ml</guid>
      <pubDate>Thu, 28 Mar 2024 10:44:51 GMT</pubDate>
    </item>
    <item>
      <title>使不同大小的火炬张量相等</title>
      <link>https://stackoverflow.com/questions/61943896/pad-torch-tensors-of-different-sizes-to-be-equal</link>
      <description><![CDATA[我正在寻找一种方法来获取图像/目标批次进行分割并返回图像尺寸已更改为与整个批次相同的批次。我已经使用下面的代码尝试过：
def collat​​e_fn_padd(批处理):
    &#39;&#39;&#39;
    可变长度的衬垫批次

    注意：自从 ToTensor 变换以来，它在这里手动将事物转换为 ToTensor
    假设它接受图像而不是任意张量。
    &#39;&#39;&#39;
    # 分离图像和蒙版
    image_batch,mask_batch = zip(*batch)

    # 填充图像和蒙版
    image_batch = torch.nn.utils.rnn.pad_sequence（image_batch，batch_first = True）
    mask_batch = torch.nn.utils.rnn.pad_sequence（mask_batch，batch_first = True）

    # 重新压缩批处理
    批次=列表（zip（image_batch，mask_batch））

    退货批次

但是，我收到此错误：
运行时错误：张量的扩展大小 (650) 必须与非单一维度 2 处的现有大小 (439) 匹配。目标大小：[3, 650, 650]。张量大小：[3, 406, 439]

如何有效地将张量填充为相等尺寸并避免此问题？]]></description>
      <guid>https://stackoverflow.com/questions/61943896/pad-torch-tensors-of-different-sizes-to-be-equal</guid>
      <pubDate>Thu, 21 May 2020 21:11:02 GMT</pubDate>
    </item>
    </channel>
</rss>