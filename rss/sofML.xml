<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 19 Apr 2024 21:12:41 GMT</lastBuildDate>
    <item>
      <title>在SVM中，当超参数C增大时，margin会变大吗？</title>
      <link>https://stackoverflow.com/questions/78356095/in-svm-when-hyper-parameter-c-increases-the-margin-will-be-larger</link>
      <description><![CDATA[我目前正在研究SVM，发现关于超参数C和margin之间的关系有两种相反的解释。我知道在支持向量分类器中，C 限制 epsilon 的总和不能大于 C。问题是，我发布的第一张图片说当 C 增加时，边距会更大，但我发布的第二张图片和我发现的其他一些信息说边距会变窄。我很困惑。
在此处输入图像描述
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78356095/in-svm-when-hyper-parameter-c-increases-the-margin-will-be-larger</guid>
      <pubDate>Fri, 19 Apr 2024 20:43:04 GMT</pubDate>
    </item>
    <item>
      <title>使用邮递员使用临时凭证调用 Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/78356002/calling-sagemaker-endpoint-using-postman-using-temporary-credentials</link>
      <description><![CDATA[我已将 AWS CLI 配置为通过 SSO 使用配置文件。我已引用此文档 AWS 文档
我想使用邮递员调用 Sagemaker 端点。有没有办法做到。我尝试在邮递员中提供我的凭据，但它返回 404 错误。
一些额外的细节 -
Sagemaker 端点使用 VPC。]]></description>
      <guid>https://stackoverflow.com/questions/78356002/calling-sagemaker-endpoint-using-postman-using-temporary-credentials</guid>
      <pubDate>Fri, 19 Apr 2024 20:13:01 GMT</pubDate>
    </item>
    <item>
      <title>Llama2-7b 根据提示生成文本的运行时间较长</title>
      <link>https://stackoverflow.com/questions/78355789/llama2-7b-long-runtime-to-generate-text-from-a-prompt</link>
      <description><![CDATA[我已将 HuggingFace 中的 Llama2-7b 模型加载到我的计算机上，以根据简单的提示生成文本。该模型加载速度非常快（大约 2 分钟），但当我想从简单的提示中生成非常简单的响应时，例如“什么是 LLM？”该模型需要两个多小时才能生成响应。我需要它运行得更快，但不知道让它运行得更快有什么问题。有什么建议吗？
这是我的代码：
类 LlamaInference():
    “”“使用 Llama 70b 参数 LLM 的文本生成类。生成数据集。“”“
    def __init__(self, 输出文件路径):
        ”“”初始化 LlamaInference 类和所有变量
        关键字参数：
        output_file_path -- 数据集生成后输出文件的位置
        ”“”
        self.output_file_path = 输出文件路径
        self.pipeline = 无
        self.output_list = []
        self.output_list_condensed = []

    def __set_up(自我):
        ”“”使用特定模型和修订版设置 Huggingface 管道
        ”“”
        #model =“meta-llama/Llama-2-70b-chat-hf”
        #revision =“e6152b720bd3cd67afc66e36d06893a0e1f84b48”
        模型=“meta-llama/Llama-2-7b-chat-hf”
        修订版=“08751db2aca9bf2f7f80d2e516117a53d7450235”


    
        self.tokenizer = AutoTokenizer.from_pretrained(模型, padding_side=“左”)

        self.pipeline = 变压器.pipeline(
            “文本生成”，
            型号=型号，
            分词器=self.分词器，
            torch_dtype=torch.float16,
            device_map=“自动”，
            修订=修订，
            do_sample=真，
            return_full_text=False
        ）
        self.pipeline.tokenizer.pad_token_id = self.tokenizer.eos_token_id


    def gen_text(自我，提示，**kwargs)：
        ”“”根据提示生成文本

        关键字参数：
        提示——我们向法学硕士提出的问题
        **kwargs——传递给 self.pipeline 的参数
        ”“”
        尝试：
            如果 self.pipeline 为 None：
                self.__set_up()
            如果“batch_size”是不在 kwargs 中：
                kwargs[“batch_size”] = 1
            
            如果“max_new_tokens”是不在 kwargs 中：
                kwargs[“max_new_tokens”] = 2048

            kwargs.update(
                {
                    “pad_token_id”：self.pipeline.tokenizer.eos_token_id，
                    “eos_token_id”：self.pipeline.tokenizer.eos_token_id，
                }
            ）
            显示（&#39;启动管道&#39;）
            token_outputs = self.tokenizer(提示)
            显示（令牌输出）
            输出= self.pipeline（提示，**kwargs）
            显示(&#39;结束管道&#39;)
            返回输出
        除了异常作为错误：
            显示（f&#39;__gen_text错误：{错误}&#39;）

推理 = LlamaInference(&#39;test.json&#39;)
结果 = inference.gen_text(“你好”，max_new_tokens=2048，batch_size=1，温度=0.5)
]]></description>
      <guid>https://stackoverflow.com/questions/78355789/llama2-7b-long-runtime-to-generate-text-from-a-prompt</guid>
      <pubDate>Fri, 19 Apr 2024 19:18:13 GMT</pubDate>
    </item>
    <item>
      <title>从 torchensemble 中的基本模型获取嵌入</title>
      <link>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</link>
      <description><![CDATA[我一直在学习Torchensemble，我想知道你可以如何在最终分类层之前提取嵌入。
这是我的整体模型：
VotingClassifier(
 （基本估计器_）：CCT（
  （分词器）：分词器（
   (conv_layers): 顺序(
    (0): 顺序(
     (0): Conv2d(3, 64, kernel_size=(7, 7), 步幅=(2, 2), 填充=(3, 3), 偏差=False)
     (1)：ReLU()
     (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    ）
    (1): 顺序(
     (0): Conv2d(64, 256, kernel_size=(7, 7), 步长=(2, 2), 填充=(3, 3), 偏差=False)
     (1)：ReLU()
     (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    ）
   ）
   （展平器）：展平（start_dim=2，end_dim=3）
  ）
  （分类器）：TransformerClassifier（
   （注意力池）：线性（in_features=256，out_features=1，偏差=True）
   (dropout): Dropout(p=0.0, inplace=False)
   （块）：模块列表（
    (0): TransformerEncoderLayer(
     (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     (self_attn): 注意(
      （qkv）：线性（in_features = 256，out_features = 768，偏差= False）
      (attn_drop): Dropout(p=0.1, inplace=False)
      （项目）：线性（in_features = 256，out_features = 256，偏差= True）
      (proj_drop): Dropout(p=0.0, inplace=False)
     ）
     （线性1）：线性（in_features = 256，out_features = 512，偏差= True）
     (dropout1): Dropout(p=0.0, inplace=False)
     (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     （线性2）：线性（in_features = 512，out_features = 256，偏差= True）
     (dropout2): Dropout(p=0.0, inplace=False)
     (drop_path): 身份()
    ）
    (1-6): 6 x TransformerEncoderLayer(
     (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     (self_attn): 注意(
      （qkv）：线性（in_features = 256，out_features = 768，偏差= False）
      (attn_drop): Dropout(p=0.1, inplace=False)
      （项目）：线性（in_features = 256，out_features = 256，偏差= True）
      (proj_drop): Dropout(p=0.0, inplace=False)
     ）
     （线性1）：线性（in_features = 256，out_features = 512，偏差= True）
     (dropout1): Dropout(p=0.0, inplace=False)
     (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     （线性2）：线性（in_features = 512，out_features = 256，偏差= True）
     (dropout2): Dropout(p=0.0, inplace=False)
     (drop_path): DropPath()
    ）
   ）
   (范数): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
   （fc）：线性（in_features = 256，out_features = 5013，偏差= True）
  ）
 ）
 (估计器_): ModuleList()
 (_criterion): CrossEntropyLoss()
）

你看，基础模型的最后有一个全连接层（fc）。我想删除它或用 Identity 替换它。怎么做？看起来删除基本估计器中的层没有做任何事情。]]></description>
      <guid>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</guid>
      <pubDate>Fri, 19 Apr 2024 18:25:20 GMT</pubDate>
    </item>
    <item>
      <title>带有产品推荐系统的电子商务网络应用程序</title>
      <link>https://stackoverflow.com/questions/78355434/e-commerce-webapp-with-product-recommandation-system</link>
      <description><![CDATA[您好，我有一个带有推荐系统的电子商务 Web 应用程序的 fyp，您能告诉我如何集成制作一个可以在 React JS 中工作的推荐系统，或者如何将其与 React JS 集成
我已经完成了我的 Mern Stack Web 电子商务应用程序，现在我想创建推荐系统并将其与我的 Web 应用程序连接]]></description>
      <guid>https://stackoverflow.com/questions/78355434/e-commerce-webapp-with-product-recommandation-system</guid>
      <pubDate>Fri, 19 Apr 2024 17:50:13 GMT</pubDate>
    </item>
    <item>
      <title>在序列模型中使用归一化层时，adapt() 会出错吗？</title>
      <link>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</link>
      <description><![CDATA[在顺序模型中使用归一化层时，在调整（）时，我收到未绑定错误：
这是错误
我做了以下事情：
标准化器 = 标准化()
标准化器.adapt(X_train)

但是这给了
未绑定错误：赋值之前引用了局部变量“input_shape”。

为什么我会收到此错误？]]></description>
      <guid>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</guid>
      <pubDate>Fri, 19 Apr 2024 17:04:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 进行音频分类总是预测错误</title>
      <link>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</guid>
      <pubDate>Fri, 19 Apr 2024 13:39:10 GMT</pubDate>
    </item>
    <item>
      <title>尝试将自定义模型部署到 OpenSearch 中会引发 RuntimeError: KeyError: token_type_ids</title>
      <link>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</guid>
      <pubDate>Fri, 19 Apr 2024 13:36:18 GMT</pubDate>
    </item>
    <item>
      <title>获取边界框问题</title>
      <link>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</guid>
      <pubDate>Fri, 19 Apr 2024 12:40:40 GMT</pubDate>
    </item>
    <item>
      <title>梅尔频谱图的卷积自动编码器。不起作用</title>
      <link>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</link>
      <description><![CDATA[# 将列表转换为 numpy 数组
data_array = np.array(data_list, dtype=&#39;float32&#39;)
data_array = np.array(data_array, dtype=&#39;float32&#39;) / 255.0 # 所以我的数据是从0到1
导入操作系统
导入keras
将 numpy 导入为 np
将张量流导入为 tf
从张量流导入keras
从 keras.layers 导入输入、Conv2D、BatchNormalization、MaxPooling2D、UpSampling2D、Flatten、Dense、Reshape、Dropout
从 keras.models 导入模型
从 sklearn.model_selection 导入 train_test_split
#从keras.preprocessing.image导入img_to_array，load_img
从 sklearn.model_selection 导入 train_test_split
#from keras.callbacks 导入 LearningRateScheduler
从 sklearn.model_selection 导入 train_test_split
从 keras.callbacks 导入 TensorBoard
导入时间
从 keras 导入正则化器

train_images, test_images = train_test_split(data_array, test_size=0.1) # 10% 用于测试
train_images, val_images = train_test_split(train_images, test_size=0.1) # 其余的 10% 用于验证

print(f&#39;训练集大小：{train_images.shape}&#39;)
print(f&#39;验证集大小：{val_images.shape}&#39;)
print(f&#39;测试集大小：{test_images.shape}&#39;)

# 超参数正确或接近正确？参数以纸质为准。
H、W、C = 256, 256, 1 # 1 排列 np 黑白
学习率 = 1e-3
批量大小 = 16
纪元 = 50 #Random 纪元
Latent_dim = 128 # 理解

l2_reg = 正则化器.l2(1e-4)

输入=输入（形状=（H，W，C））
x = Conv2D(32, (5, 5), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(输入)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), padding=&#39;same&#39;)(x) #固定池化
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), 填充=&#39;相同&#39;)(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), 填充=&#39;相同&#39;)(x)

# X 是我最后一层的输出

# 关于 X\ 的瓶颈操作
瓶颈=展平()(x)
瓶颈=密集（latent_dim，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（bottleneck）#潜在空间（LS）
瓶颈 = Dropout(0.3)(bottleneck) # 应用 dropout 进行正则化
                                       #输出是瓶颈
#解码器
x = 密集（8* 8* 128，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（瓶颈）
x = 重塑((8, 8, 128))(x)
x = 上采样2D((2, 2))(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(32, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
#填充？
#x = ZeroPadding2D(padding=((2, 2), (14, 14)))(x) # 大小要求？
# 最终重建
outputs = Conv2D(1, (5, 5), activate=&#39;sigmoid&#39;, padding=&#39;same&#39;, kernel_regularizer=l2_reg)(x) # 修改 1 因为之前有一个 3 : 没有意义，为什么是 sigmoid
#Sigmoid = 0 到 1 之间的值
#或Relu


# 完整的自动编码器模型
自动编码器=模型（输入，输出）
autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;]) # 或 mse
 


# 模型架构
自动编码器.summary()
打印（train_images.shape，test_images.shape）

从 keras.callbacks 导入 EarlyStopping

#early_stopping = EarlyStopping（monitor=&#39;val_loss&#39;，耐心=5，restore_best_weights=True）
# train_images、val_images 在 CAE 开始时预加载

历史=自动编码器.fit(
    train_images, train_images, # 输入和目标
    纪元=纪元，
    批量大小=批量大小，
    洗牌=真，#真
    回调=[张量板],
    验证数据=（val_images，val_images），#validation_data=（val_images，val_images）
）
# 生成重建
rec_images = autoencoder.predict(val_images)[[在此处输入图像描述](https://i.stack.imgur.com/4g01e.png)](https://i.stack.imgur.com/trl9d.png)

我有 2550 个 2 秒的音频文件，我应用了 Mel 扫描图，仅使用 np 数组数据，我为我的 CAE 提供了这些尺寸 2562561。我已经应用了早期停止、主动学习和调节 L2 来提高我的 NN 学习，但我不知道为什么它不起作用。我对 NN 没有太多的经验，我想了解我在 NN 上做错了什么。我将在此处附上代码和结果。如果您想分享您的类似经验和这些问题的解决方案，请提前致谢。 在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</guid>
      <pubDate>Fri, 19 Apr 2024 12:38:40 GMT</pubDate>
    </item>
    <item>
      <title>请为我的毕业设计解决机器学习中牙齿分割模型的Valueerror</title>
      <link>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</link>
      <description><![CDATA[大家好，我从 此处。
该程序应为用户提供两种选择：

从图像中读取并提取特征：此选项使用 FeatureExtraction 模块从图像中提取 9 个特征（包括图像名称）。
读取预先存在的数据集：此选项读取包含 labels.csv、features.csv 和图像文件的数据集。然后它会询问用户：

执行程序的次数（假设为 5）。
使用 K 折交叉验证分割数据所需的折叠数（假设为 5 折叠，即 k=5）。
测试数据集的大小（假设为 20%）。



模型然后将这些参数传递给classification模块中的分类函数。这就是问题出现的地方：

代码将整个数据集传递给 onlyfiles，其中包含 973 个条目。
然后，它会从 labels.csv（有 778 个条目）中识别 images_name 和 label_color。这代表训练数据集，因为我们之前指定了 20% 的测试集（778 = 973 的 80%）。
以下 for 循环迭代由 k_folds.split(images_name) 生成的分割。此时，我们仍在处理训练数据集，并且当 k=5 时，应该有：

train_index 中有 662 个索引（用于训练数据）。
test_index 中有 156 个索引（用于在训练集中进行验证）。



这是下一个 for 循环中发生错误的位置：
对于 train_index 中的 i：
    current_filename = onlyfiles[i].split(&#39;.&#39;)[0].strip()
    如果 current_filename 在训练数据集中：
        # ...（其余代码）
    别的：
        print(f“警告：在 images_name 中找不到‘{current_filename}’，因为它的索引是 {i}.train。”)


第一行根据 train_index 中的索引 i 检索文件名 (current_filename)。假设 i 为 324，train_index 包含从 156 到 777 的索引（而 test_index 范围从 0 到 155）。
出现此错误的原因是，有时循环会尝试在 images_name 中查找 current_filename，但该文件并不存在。这是因为 images_name 只有 778 个条目（训练数据），其余 195 个条目（测试数据）不包括在内。因此，current_filename 实际上可能属于测试数据集，从而导致错误“101_0032.JPG 不在列表中”。

我尝试对列表进行排序并删除随机播放（在 k_folds.split 中设置 shuffle=False），但错误仍然存​​在。我非常感谢您为解决此问题提供一些帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</guid>
      <pubDate>Thu, 18 Apr 2024 23:03:02 GMT</pubDate>
    </item>
    <item>
      <title>LMST模型敏感性——初学者抗运气</title>
      <link>https://stackoverflow.com/questions/78349854/lmst-model-sensitivity-beginners-anti-luck</link>
      <description><![CDATA[我一直在尝试使用艾伯塔省电力市场的一些非常基本的数据，并尝试使用时间序列数据的 LMST 模型来尝试预测价格。我确实得到“可能”这是我的模型的结果，而且它似乎确实出现了我们可以预期的一些波动（仅根据我自己的市场经验）。
但是，我正在寻求更好地理解我遇到的一些陷阱。
从 keras.models 导入顺序
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dropout
从 keras.layers 导入密集
将 pandas 导入为 pd
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入mean_absolute_error,mean_squared_error
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
导入作业库

# 加载数据
# 加载数据

# 加载数据
csv_file_path = &#39;Frankenstein.csv&#39; # 使用您的实际文件路径更新
df = pd.read_csv(csv_file_path)

# 将“日期/时间”转换为日期时间并提取数据集中存在的组件
如果 df.columns 中的“日期/时间”：
    df[&#39;日期&#39;] = pd.to_datetime(df[&#39;日期/时间&#39;])
    df[&#39;年份&#39;] = df[&#39;日期&#39;].dt.year
    df[&#39;月份&#39;] = df[&#39;日期&#39;].dt.月份
    df[&#39;日期&#39;] = df[&#39;日期&#39;].dt.day
    df[&#39;小时&#39;] = df[&#39;日期&#39;].dt.小时
    df.drop([&#39;日期/时间&#39;, &#39;日期&#39;], axis=1, inplace=True)

# 假设“价格”是目标变量
features = df.drop([&#39;价格&#39;], axis=1)
目标 = df[&#39;价格&#39;]

# 标准化特征和目标
缩放器特征 = MinMaxScaler()
features_scaled = scaler_features.fit_transform(features)
缩放器目标 = MinMaxScaler()
target_scaled = scaler_target.fit_transform(target.values.reshape(-1, 1))

# 创建序列函数
def create_sequences（特征，目标，time_steps = 100）：
    X、y = []、[]
    对于范围内的 i(len(features) - time_steps)：
        X.append(特征[i:(i + time_steps)])
        y.append(目标[i + time_steps])
    返回 np.array(X), np.array(y)

# 使用整个数据集创建序列
X, y = create_sequences(features_scaled, target_scaled.flatten())

# 模型配置
input_shape = (X.shape[1], X.shape[2]) # (time_steps, num_features)

# 定义LSTM模型
模型=顺序（[
    LSTM（单位=100，return_sequences=True，input_shape=input_shape），
    辍学（0.1），
    LSTM（单位=100），
    辍学（0.1），
    密集（单位=100，激活=&#39;elu&#39;），
    Dense(1) # 预测单个值
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

# 在整个数据集上训练模型
历史= model.fit（X，y，纪元= 150，batch_size = 20，validation_split = 0.1）

# 情节训练&amp;验证损失值
plt.figure(figsize=(10, 6))
plt.plot(history.history[&#39;loss&#39;], label=&#39;火车&#39;)
plt.plot(history.history[&#39;val_loss&#39;], label=&#39;验证&#39;)
plt.title(&#39;模型损失&#39;)
plt.ylabel(&#39;损失&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.legend(loc=&#39;右上&#39;)
plt.show()

# 保存LSTM模型
model_save_path = &#39;trained_lstm_model.h5&#39;
model.save(model_save_path)
print(f&quot;模型已保存到 {model_save_path}&quot;)
joblib.dump(scaler_features, &#39;scaler_features.pkl&#39;)
joblib.dump(scaler_target, &#39;scaler_target.pkl&#39;)

有人可以给绝对的初学者一些建议吗？主要是为了更好地理解我应该如何设置它。我有一个每小时的数据集，是过去三年的历史生成和交换。我正在寻找方法让我的模型对供应与价格的变化更具反应性。]]></description>
      <guid>https://stackoverflow.com/questions/78349854/lmst-model-sensitivity-beginners-anti-luck</guid>
      <pubDate>Thu, 18 Apr 2024 19:18:18 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Vertex AI 中部署自定义容器作为端点</title>
      <link>https://stackoverflow.com/questions/77266349/how-to-deploy-custom-container-in-vertex-ai-as-endpoint</link>
      <description><![CDATA[我正在尝试在 vertex ai 中部署自定义容器作为端点（REST URL 或 API），我能够成功构建 docker 映像，但无法将模型部署为端点，从日志中我也无法了解错误是什么。
下面是我的 Predict.py 、 dockerfile 和部署脚本
将 numpy 导入为 np

def 预测（数据）：
  # 预测函数示例
  打印（数据）
  #result = np.sum(data, axis=1) # 示例：沿轴 1 求和
  结果 = [3,4,5,6]
  results_array = np.array(结果)
  print ({“预测”: results_array.tolist()})
  return ({“预测”: results_array.tolist()})
  预测([3,4,6])

docker 文件
&lt;前&gt;&lt;代码&gt;来自 python:3.10
工作目录/代码

复制 要求.txt 要求.txt
复制模型.pkl 模型.pkl
运行 pip install --升级 pip
运行 pip --版本
运行 pip install -rrequirements.txt
复制 。 。
CMD [“python3”，“predict.py”]

部署脚本
导入操作系统
将 google.cloud.aiplatform 导入为 aiplatform

# 设置您的 GCP 项目 ID、位置和模型名称
项目=“项目ID”
位置=“us-central1”
model_name =“testing_3”；

# 初始化API客户端
aiplatform.init（项目=项目，位置=位置）

# 定义容器镜像URI
container_image_uri = “图像 URI”

# 创建自定义容器预测模型
模型 = aiplatform.Model.upload(
显示名称=模型名称，
serving_container_image_uri=container_image_uri，
 ）

print (“现在部署模型”)
尝试：
  # 部署模型
  端点 = model.deploy(machine_type=&quot;n1-standard-4&quot;)
  打印（端点）
除了异常 e：
  print(f“部署模型时出错：{e}”)

我还尝试运行已部署的 docker 映像，并且其运行没有任何错误，只是我无法部署端点
有人可以帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/77266349/how-to-deploy-custom-container-in-vertex-ai-as-endpoint</guid>
      <pubDate>Tue, 10 Oct 2023 13:43:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 OpenCV 和 Mediapipe 实现逼真的唇色变化？</title>
      <link>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</guid>
      <pubDate>Mon, 20 Mar 2023 17:50:46 GMT</pubDate>
    </item>
    <item>
      <title>生成算法和判别算法有什么区别？ [关闭]</title>
      <link>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</link>
      <description><![CDATA[生成式和生成式有什么区别
判别算法？]]></description>
      <guid>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</guid>
      <pubDate>Mon, 18 May 2009 19:44:45 GMT</pubDate>
    </item>
    </channel>
</rss>