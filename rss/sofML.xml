<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 19 Jul 2024 03:20:36 GMT</lastBuildDate>
    <item>
      <title>尽管数据类型为数字且形状正确，KNNImputer 仍会删除列</title>
      <link>https://stackoverflow.com/questions/78767192/knnimputer-drops-columns-despite-of-numeric-datatypes-and-right-shape</link>
      <description><![CDATA[我正在使用 KNNImputer 在几个 pd.DataFrame 中估算 np.nan 值。我检查了每个数据框的所有数据类型都是数字。但是，KNNImputer 在某些数据框中删除了一些列：
&gt;&gt;&gt;input_df.shape 
(816, 216) 

&gt;&gt;&gt; input_df.dtypes.value_count()
float64 216
dtype: int64

&gt;&gt;output_df.shape 
(816, 27)

我使用了以下 KNNImputer 配置
imputer = KNNImputer(n_neighbors=1, 
weights=&quot;uniform&quot;,
add_indicator=False)

output_df = imputer.fit_transform(input_df)

我想知道为什么会发生这种情况，因为每个数据框都有 np.nan 值。顺便说一句，参数 n_neighbors=1 不应该对结果产生任何影响，因为我正在用最近邻居的值替换缺失值。
提前谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78767192/knnimputer-drops-columns-despite-of-numeric-datatypes-and-right-shape</guid>
      <pubDate>Fri, 19 Jul 2024 01:17:35 GMT</pubDate>
    </item>
    <item>
      <title>训练帮助混合模型，该模型集成了上下文和数值特征以解决分类问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78766812/training-help-hybrid-based-model-that-integrates-contextual-and-numerical-featur</link>
      <description><![CDATA[我想要一个关键的生产风险分析问题。因此，根据记录，我想将每条记录的风险等级从 0 到 5。训练集相当不平衡。
&gt; &quot;0.0 964 
&gt; 1.0 393 
&gt; 2.0 396
&gt; 3.0 286 
&gt; 4.0 109 
&gt; 5.0 44&quot;

现在，当前训练集如下所示：
 2 风险等级 float64
3 a_weights int64 
4 b_weights float64
5 c_weights float64
6 d_weights float64
7 e_weights float64
8 f_weights float64
9 g_weights float64
10 FinalDesc 对象 

FinalDesc 列包含一个字符串（工作单的描述）。
例如：
“HVAC 更换工具因恶劣环境而无法使用。请小心修理”
我在 Final Desc 中也有关键词的权重，这将有助于排名。
但是，现在的问题是，我的主管给了我工厂特定的背景信息，这可能有助于预测。例如：
&quot;
消防监视记录被认为风险较低，
高压灭菌器上的阀门 4/5 或由于库存水平较高而通常风险较低。
用于审查 PM 详细信息的 REL 记录不会带来直接风险。
&quot;
还有更多背景信息。进行这些排名的最佳方法是什么？我应该利用 LLM 的力量吗？请让我知道整合背景的最佳方法。
我目前的方法是：

矢量化描述并添加到数据框
使用随机 Forrest 分类器对工作订单进行排名（训练、预测）。同时使用数值和描述

它的准确率为 66%。我想添加更复杂的 AI/ML 功能来解决这个问题]]></description>
      <guid>https://stackoverflow.com/questions/78766812/training-help-hybrid-based-model-that-integrates-contextual-and-numerical-featur</guid>
      <pubDate>Thu, 18 Jul 2024 21:51:38 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：在 dim 1 处预期长度为 129 的序列（得到 46）</title>
      <link>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78766178/valueerror-expected-sequence-of-length-129-at-dim-1-got-46</guid>
      <pubDate>Thu, 18 Jul 2024 18:40:37 GMT</pubDate>
    </item>
    <item>
      <title>Google 语音转文本和翻译（直播）</title>
      <link>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</link>
      <description><![CDATA[我有一个用例，我将在直播中录制一段演讲，并且我希望实时获得音频的文本转录，然​​后翻译该转录。
我是否需要使用 Google 的语音转文本 API，然后将生成的文本发送到翻译 API，还是可以在一行中完成？]]></description>
      <guid>https://stackoverflow.com/questions/78765868/google-speech-to-text-and-translation-live-stream</guid>
      <pubDate>Thu, 18 Jul 2024 17:21:16 GMT</pubDate>
    </item>
    <item>
      <title>我需要在时间序列预测中“转移”我的新目标变量吗？</title>
      <link>https://stackoverflow.com/questions/78765782/do-i-need-to-shift-my-new-target-variable-in-time-series-prediction</link>
      <description><![CDATA[当我有时间序列数据但不想预测序列的值时。相反，我会创建一个新的目标变量，该变量为我提供方向（1 表示增加，0 表示减少）而不是值，从而将其转化为分类问题。
我需要“转移”我的新目标变量吗？
我试过了
def binary(dataframe):
dataframe[&#39;previous_day_close&#39;] = dataframe[&#39;Close&#39;].shift(1)
dataframe[&#39;direction&#39;] = 0
dataframe.loc[dataframe[&#39;Close&#39;] &gt; dataframe[&#39;previous_day_close&#39;], &#39;direction&#39;] = 1
dataframe.drop(columns=[&#39;previous_day_close&#39;], inplace=True)
return dataframe[&#39;direction&#39;].head()

binary(petr3)

days = 3

petr3[&#39;shift_direction&#39;] = petr3[[&#39;direction&#39;]].shift(-days )

petr3.dropna(inplace = True)

petr3[&#39;shift_direction&#39;] = petr3[&#39;shift_direction&#39;].astype(&#39;int64&#39;)

有了这个，我现在可以使用分类模型对转换后的时间序列进行预测了吗？这种转变是必要的技术吗？顺便说一下，我也需要转移我的变量吗？]]></description>
      <guid>https://stackoverflow.com/questions/78765782/do-i-need-to-shift-my-new-target-variable-in-time-series-prediction</guid>
      <pubDate>Thu, 18 Jul 2024 17:01:20 GMT</pubDate>
    </item>
    <item>
      <title>lmdb.InvalidParameterError：/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc.db：参数无效</title>
      <link>https://stackoverflow.com/questions/78763677/lmdb-invalidparametererror-data-project-hsi-foundation-hypersigma-imagedenoisi</link>
      <description><![CDATA[我正在下面的 hypersigma github 上工作。请参考下面的链接。顺便说一下，我遇到了一个问题。

HyperSIGMA github 链接：https://github.com/WHU-Sigma/HyperSIGMA

输入是从下面的网站下载的 dc.tif 文件，我使用 &#39;mat_data.py&#39; 的 create_WDC_dataset 函数创建了两个 mat 文件（train_0.mat、train_1.mat）。然后我们尝试将这两个 mat 文件（train_0.mat、train_1.mat）转换为 wdc.db 文件。
我尝试通过lmdb_data.py的createDCmall函数在wdc.db文件夹中创建data.mdb，lock.mdb，meta_info.txt文件，但是没有创建meta_info.txt文件，下面是相关错误。

https://engineering.purdue.edu/~biehl/MultiSpec/hyperspectral.html
华盛顿特区购物中心图片 (145MB) --------&gt; (dc.tif)

======================命令结果开始=========================
(venv) techwinjeo@gpusystem:~/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility$ python lmdb_data.py 

create wdc...
(1587, 191, 8, 8)
地图大小 (GB): 0.17344493865966795
/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc6.db
回溯（最近一次调用）：
文件&quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 95 行，位于 &lt;module&gt;
createDCmall()
文件 &quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 85 行，位于 createDCmall
create_lmdb_train(
文件 &quot;/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/lmdb_data.py&quot;，第 55 行，位于 create_lmdb_train
env = lmdb.open(name+&#39;.db&#39;, map_size=map_size, writemap=True)
lmdb.InvalidParameterError: /data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc.db: 参数无效

=======================命令结果结束=========================
任何帮助都非常感谢👍
谢谢你：D
我期待在下面的文件路径中创建以下三个文件。

路径：/data/project/hsi_foundation/HyperSIGMA/ImageDenoising/utility/WDC/wdc

wdc.db
|
|----- data.mdb
|----- lock.mdb
└----- meta_info.txt
]]></description>
      <guid>https://stackoverflow.com/questions/78763677/lmdb-invalidparametererror-data-project-hsi-foundation-hypersigma-imagedenoisi</guid>
      <pubDate>Thu, 18 Jul 2024 09:58:58 GMT</pubDate>
    </item>
    <item>
      <title>在模型训练中，处理 Web 应用程序上的错误输入数据时遇到困难</title>
      <link>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78763624/stuck-in-handling-incorrect-input-data-on-web-app-for-model-training</guid>
      <pubDate>Thu, 18 Jul 2024 09:48:16 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的分割</title>
      <link>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</link>
      <description><![CDATA[即使将单个特征输入模型，神经网络是否也能从细分中受益？
目前我的模型具有基于用户交互和时间的特征。
如果我们根据这些特征输入一些客户细分，我的模型是否会受益？]]></description>
      <guid>https://stackoverflow.com/questions/78762363/segmentation-in-neural-netowrk</guid>
      <pubDate>Thu, 18 Jul 2024 04:04:29 GMT</pubDate>
    </item>
    <item>
      <title>自定义参数激活函数导致 NaN 损失和权重</title>
      <link>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78761422/custom-parametric-activation-function-leading-to-nan-loss-and-weights</guid>
      <pubDate>Wed, 17 Jul 2024 20:02:35 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAN 进行欺诈检测</title>
      <link>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</link>
      <description><![CDATA[我正在使用 GAN 实现基于交易的欺诈检测模型，但我仍然想指定我的模型，即我想强调 RIB 和交易时间（尤其是发行时间）我想知道个人通过这些变量（时间和 RIB）的行为如何影响交易是否是欺诈性的。基本上，这个模型很好，但它仍然很肤浅，我们需要通过强调提到的变量来更深入地研究。
我的数据集的头部
就像我说的，我尝试了一个通用的 GAN 模型，但我想实现一个专注于 RIB 和发行时间的指定 GAN 模型]]></description>
      <guid>https://stackoverflow.com/questions/78761254/fraud-detection-using-gan</guid>
      <pubDate>Wed, 17 Jul 2024 19:15:59 GMT</pubDate>
    </item>
    <item>
      <title>设置具有序列的数组元素请求数组在 1 维之后具有不均匀形状</title>
      <link>https://stackoverflow.com/questions/78749448/setting-an-array-element-with-a-sequence-requested-array-has-an-inhomogeneous-sh</link>
      <description><![CDATA[当我拟合各种人工神经网络时，TLNN 的代码显示为不正确，尤其是包含重塑函数的行。这有什么问题吗？
def Forecast_TLNN(model, time_lagged_points, last_sequence, Future_steps):
Forecasted_values = []
max_lag = max(time_lagged_points)
for i in range(future_steps):
input_sequence = [last_sequence[max_lag - p] for p in time_lagged_points]
Forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
Forecasted_values.append(forecasted_value[0][0])
last_sequence = last_sequence[1:] + [forecasted_value[0][0]]
return Forecasted_values

错误显示在以下行：forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
我似乎无法在互联网上找到有关此代码的任何更正。
---------------------------------------------------------------------------
ValueError Traceback (most recent call last)

Cell In[223]，第 6 行，在 Forecast_TLNN(model, time_lagged_points, last_sequence, Future_steps) 中
4 for i in range(future_steps):
5 input_sequence = [last_sequence[max_lag - p] for p in time_lagged_points]
----&gt; 6 Forecasted_value = model.predict(np.reshape(input_sequence, (1, len(input_sequence))))
7 Forecasted_values.append(forecasted_value[0][0])
8 last_sequence = last_sequence[1:] + [forecasted_value[0][0]]

文件 ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:285，在 reshape(a, newshape, order) 中
200 @array_function_dispatch(_reshape_dispatcher)
201 def reshape(a, newshape, order=&#39;C&#39;):
202 &quot;&quot;&quot;
203 为数组赋予新形状而不更改其数据。
204 
(...)
283 [5, 6]])
284 &quot;&quot;&quot;
--&gt; 285 返回 _wrapfunc(a, &#39;reshape&#39;, newshape, order=order)

文件 ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:56，位于 _wrapfunc(obj, method, *args, **kwds)
54 bound = getattr(obj, method, None)
55 如果 bound 为 None:
---&gt; 56 return _wrapit(obj, method, *args, **kwds)
58 try:
59 return bound(*args, **kwds)

File ~\anaconda3\Lib\site-packages\numpy\core\fromnumeric.py:45, in _wrapit(obj, method, *args, **kwds)
43 except AttributeError:
44 wrap = None
---&gt; 45 result = getattr(asarray(obj), method)(*args, **kwds)
46 if wrap:
47 if not isinstance(result, mu.ndarray):

ValueError: 设置带有序列的数组元素。请求的数组在 1 维之后具有非均匀形状。检测到的形状为 (5,) + 非均匀部分。
]]></description>
      <guid>https://stackoverflow.com/questions/78749448/setting-an-array-element-with-a-sequence-requested-array-has-an-inhomogeneous-sh</guid>
      <pubDate>Mon, 15 Jul 2024 10:54:58 GMT</pubDate>
    </item>
    <item>
      <title>karateclub MUSAE 嵌入产生奇怪的列数</title>
      <link>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</link>
      <description><![CDATA[我正在试验属性节点嵌入和结构嵌入，但 karateclub 实现返回的矩阵具有奇怪的列数。
MUSAE 给出 128 个“特征”，而不是请求的 32 个。当我请求 32 个时，GLEE 给出了 33 个。我遗漏了什么吗？
import random
import numpy as np
import networkx as nx
from scipy.sparse import coo_matrix

from karateclub.node_embedding.attributed import MUSAE
from karateclub.node_embedding.neighbourhood import GLEE

g = nx.newman_watts_strogatz_graph(50, 10, 0.2)

X = {i: random.sample(range(150),50) for i in range(50)}

row = np.array([k for k, v in X.items() for val in v])
col = np.array([val for k, v in X.items() for val in v])
data = np.ones(50*50)
shape = (50, 150)

X = coo_matrix((data, (row, col)), shape=shape)

model = MUSAE(dimensions=32)
model.fit(g, X)
emb = model.get_embedding()
print(emb.shape)

model = GLEE(dimensions=32)
model.fit(g)
emb = model.get_embedding()
print(emb.shape)

输出：
(50, 128)
(50, 33)
]]></description>
      <guid>https://stackoverflow.com/questions/78623717/karateclub-musae-embedding-produces-strange-number-of-columns</guid>
      <pubDate>Fri, 14 Jun 2024 15:02:08 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试使用数据集包创建数据集时，出现“无法转换，因为列名不匹配”错误</title>
      <link>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</link>
      <description><![CDATA[DataFrame 结构
上图显示了我的数据的结构。
from sklearn.model_selection import train_test_split
from datasets import Features, ClassLabel, Value, Dataset, DatasetDict

df_train, df_tmp = train_test_split(
movie_df,stratify=movie_df[&quot;label&quot;], test_size=0.2)

df_val, df_test = train_test_split(
df_tmp,stratify=df_tmp[&quot;label&quot;], test_size=0.5)

ds_features = Features({&quot;text&quot;: Value(&quot;string&quot;), &quot;label&quot;: ClassLabel(names=labels)})

dataset = DatasetDict({
&quot;train&quot;: Dataset.from_pandas(df_train.reset_index(drop=True),features=ds_features),
&quot;valid&quot;: Dataset.from_pandas(df_val.reset_index(drop=True),features=ds_features),
&quot;test&quot;: Dataset.from_pandas(df_test.reset_index(drop=True),features=ds_features)})

dataset

此代码给我一个值错误，如下所示：
错误
错误
我期望得到类似的东西，但值不一样：
DatasetDict({
train: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 13267
})
valid: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1658
})
test: Dataset({
features: [&#39;text&#39;, &#39;label&#39;],
num_rows: 1659
})
})

有人能告诉我我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78151170/im-getting-couldnt-cast-because-column-names-dont-match-error-while-i-was-t</guid>
      <pubDate>Wed, 13 Mar 2024 04:00:13 GMT</pubDate>
    </item>
    <item>
      <title>在谷歌云平台中运行 jupyter lab 时出现错误 524</title>
      <link>https://stackoverflow.com/questions/68862621/getting-error-524-while-running-jupyter-lab-in-google-cloud-platform</link>
      <description><![CDATA[我无法访问在 Google Cloud 上创建的 jupyter lab

我使用 Google AI 平台创建了一个笔记本。我能够启动它并工作，但它突然停止了，我现在无法启动它。我尝试构建并重新启动 jupyterlab，但毫无用处。我也检查了我的磁盘使用情况，只有 12%。
我尝试了诊断工具，结果如下：

但没有修复。
提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/68862621/getting-error-524-while-running-jupyter-lab-in-google-cloud-platform</guid>
      <pubDate>Fri, 20 Aug 2021 12:57:57 GMT</pubDate>
    </item>
    <item>
      <title>带有 gpu 的 Lightgbm 分类器</title>
      <link>https://stackoverflow.com/questions/60360750/lightgbm-classifier-with-gpu</link>
      <description><![CDATA[model = lgbm.LGBMClassifier(
n_estimators=1250,
num_leaves=128,
learning_rate=0.009,
verbose=1
)

使用 LGBM 分类器，
现在有没有办法将其与 GPU 一起使用？]]></description>
      <guid>https://stackoverflow.com/questions/60360750/lightgbm-classifier-with-gpu</guid>
      <pubDate>Sun, 23 Feb 2020 09:20:03 GMT</pubDate>
    </item>
    </channel>
</rss>