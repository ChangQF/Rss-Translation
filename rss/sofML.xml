<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Mon, 23 Dec 2024 12:33:09 GMT</lastBuildDate>
    <item>
      <title>è®­ç»ƒ transformer æ¨¡å‹æ—¶å‡ºç° OOM é”™è¯¯</title>
      <link>https://stackoverflow.com/questions/79302713/oom-error-when-training-transformer-model</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ç ”ç©¶ HMERï¼ˆæ‰‹å†™æ•°å­¦è¡¨è¾¾å¼è¯†åˆ«ï¼‰é—®é¢˜ï¼Œå¹¶å°è¯•ä½¿ç”¨ CNN-Transformer æ¶æ„ã€‚ä½†æ˜¯ï¼Œå½“æˆ‘å°è¯•è®­ç»ƒæˆ‘çš„æ¨¡å‹æ—¶ï¼Œæˆ‘é‡åˆ°äº†æ­¤é”™è¯¯ï¼š
DefaultCPUAllocatorï¼šå†…å­˜ä¸è¶³ï¼šæ‚¨å°è¯•åˆ†é… 69271363584 å­—èŠ‚ã€‚
æˆ‘è®¤ä¸ºæˆ‘çš„ä½ç½®ç¼–ç å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä½†æˆ‘çœŸçš„ä¸çŸ¥é“å¦‚ä½•è°ƒè¯•å®ƒæˆ–è¿™é‡ŒçœŸæ­£çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼ˆæˆ‘åœ¨è¿™æ–¹é¢è¿˜åªæ˜¯åˆå­¦è€…ï¼‰
æˆ‘å½“å‰çš„æ¨¡å‹å¦‚ä¸‹æ‰€ç¤º
class PositionalEncoding(nn.Module):
def __init__(self, d_model, max_len=5000):
super(PositionalEncoding, self).__init__()
self.encoding = torch.zeros(max_len, d_model)
position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
self.encoding[:, 0::2] = torch.sin(position * div_term)
self.encoding[:, 1::2] = torch.cos(position * div_term)
self.encoding = self.encoding.unsqueeze(0) # æ·»åŠ æ‰¹æ¬¡ç»´åº¦

def forward(self, x):
seq_len = x.size(1)
return x + self.encoding[:, :seq_len, :].to(x.device)

class TransformerDecoder(nn.Module):
def __init__(self, vocab_size, d_model, num_heads, num_layers, max_seq_length):
super(TransformerDecoder, self).__init__()
self.embedding = nn.Embedding(vocab_size, d_model)
self.positional_encoding = PositionalEncoding(d_model, max_seq_length)
decrypt_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=num_heads)
self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)
self.fc_out = nn.Linear(d_model, vocab_size)

def forward(self, target_seqs, memory, target_mask):
# åµŒå…¥ç›®æ ‡åºåˆ—
embedded = self.embedding(target_seqs) # (batch, seq_len, d_model)
embedded = checkpoint(self.positional_encoding, embedded) # æ·»åŠ ä½ç½®ç¼–ç 
# è½¬ç½®ä»¥å…¼å®¹ nn.TransformerDecoder (seq_len, batch, d_model)
embedded = embedded.permute(1, 0, 2)
memory = memory.permute(1, 0, 2)
# è§£ç 
coded = checkpoint(self.transformer_decoder, embedded, memory, target_mask) # (seq_len, batch, d_model)
# è½¬ç½®å› (batch, seq_len, d_model)
coded = decrypted.permute(1, 0, 2)
# æœ€ç»ˆè¾“å‡ºå±‚
logits = checkpoint(self.fc_out,coded) # (batch, seq_len, vocab_size)
return logits


æˆ‘çš„ä»£ç æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿå¦‚æœæ²¡æœ‰ï¼Œæ˜¯ä»€ä¹ˆåŸå› å¯¼è‡´æˆ‘é‡åˆ°è¿™ä¸ªé—®é¢˜çš„]]></description>
      <guid>https://stackoverflow.com/questions/79302713/oom-error-when-training-transformer-model</guid>
      <pubDate>Mon, 23 Dec 2024 09:44:33 GMT</pubDate>
    </item>
    <item>
      <title>å¹¶é›†å’Œäº¤é›†çš„ VC ç»´æ•°çš„ä¸Šé™[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79302585/upper-bound-on-vc-dimension-of-union-and-intersection</link>
      <description><![CDATA[é—®é¢˜ï¼šç±» C çš„ VC ç»´åº¦ä¸º dã€‚ç±» Câ€™ åŒ…æ‹¬ç”± C ä¸­ s ä¸ªå¯¹è±¡çš„äº¤é›†å’Œå¹¶é›†ï¼ˆä»¥ä»»ä½•é¡ºåºï¼‰å½¢æˆçš„æ‰€æœ‰å¯¹è±¡ã€‚ç»™å‡º Câ€™ çš„ VC ç»´åº¦çš„ä¸Šé™ã€‚
å°è¯•
æˆ‘çŸ¥é“ï¼Œå¦‚æœ H æ˜¯å¤§å°ä¸º s ä¸” VC ç»´åº¦ä¸º d çš„å‡è®¾ç±»ã€‚ä»¥ä¸‹ä¸ºçœŸï¼š
å¦‚æœ H&#39; æ˜¯ç”±æ¥è‡ª H çš„ s ä¸ªå‡è®¾çš„æ‰€æœ‰å¹¶é›†å½¢æˆçš„ç±»ï¼Œå¹¶ä¸” s â‰¥ 1ã€‚åˆ™ VC ç»´åº¦ (ğ»&#39;) â‰¤ $2ğ‘‘ğ‘ log{_2}â¡(3ğ‘ )$ã€‚
å¦‚æœ H&#39; æ˜¯ç”±æ‰€æœ‰äº¤é›†å½¢æˆçš„ç±»ï¼Œåˆ™åŒæ ·ä¸ºçœŸã€‚
ä»è¿™é‡Œå¼€å§‹æ˜¯æˆ‘çš„å°è¯•ï¼š
ä¸ºäº†å½¢æˆ Câ€™ï¼Œæˆ‘ä»¬å…è®¸äº¤é›†å’Œå¹¶é›†çš„åµŒå¥—ç»„åˆã€‚è¿™æ„å‘³ç€ $â‹ƒ{{i=1}}â‹‚{{j=1}}c{_{ij}}$ï¼Œå…¶ä¸­ câˆˆCã€‚
å¦‚æœ ğ¶${_â‹ƒ}$ å’Œ ğ¶${_â‹‚}$ æ˜¯ä¸¤ä¸ªå‡è®¾ç±»ï¼Œåˆ™å®ƒä»¬åœ¨å¹¶é›†æˆ–äº¤é›†ä¸­çš„ç»„åˆç±»çš„ VC ç»´æ•°æœ€å¤šæ˜¯å®ƒä»¬çš„ VC ç»´æ•°ä¹‹å’Œã€‚
æ¯ä¸ªé¢å¤–çš„å¹¶é›†æˆ–äº¤é›†å±‚æœ€å¤šå¯¹å­é›†çš„ç»„åˆå¢é•¿è´¡çŒ® $log{_2}â¡(3ğ‘ )$ã€‚å› æ­¤ï¼ŒCâ€™ çš„ VC ç»´æ•°å—ä»¥ä¸‹é™åˆ¶ï¼šVC(Câ€™) â‰¤ $4ğ‘‘ğ‘ log{_2}â¡(3ğ‘ )$ã€‚
æˆ‘å¾ˆæƒ³å¬å¬ä½ å¯¹è¿™æ˜¯å¦æ­£ç¡®çš„çœ‹æ³•ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79302585/upper-bound-on-vc-dimension-of-union-and-intersection</guid>
      <pubDate>Mon, 23 Dec 2024 08:40:39 GMT</pubDate>
    </item>
    <item>
      <title>äºŒè¿›åˆ¶äº¤å‰ç†µçš„å®ç°ç»™å‡ºä¸æ­£å¸¸çš„ç»“æœ</title>
      <link>https://stackoverflow.com/questions/79302179/implementation-of-binary-cross-entropy-gives-not-normal-result</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•æ„å»ºä¸€ä¸ª NNï¼Œä½†åœ¨è®­ç»ƒé˜¶æ®µï¼Œæˆ‘å¾—åˆ°çš„æŸå¤±å‡½æ•°å€¼å°±å¼‚å¸¸äº†ã€‚è¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ
å“¦ï¼Œæˆ‘åªèƒ½ä½¿ç”¨ NumPyã€‚
è¿™å°±æ˜¯æ•°æ®çœ‹èµ·æ¥ç›¸ä¼¼çš„æ–¹å¼ï¼š
print(X_train.shape) #(784,800)
print(X_test.shape) #(784,200)
print(Y_train.shape) #(800,1)
print(Y_test.shape) #(200,1)

æŸå¤±å‡½æ•° - BCE
def log_loss(y_hat, y):
m = y.shape[0]
epsilon = 1e-15 
y_hat = np.clip(y_hat, epsilon, 1 - epsilon) 

# loss = -1/m * (y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))
æŸå¤± = -1/m * (np.dot(y.T,np.log(y_hat)) + np.dot((1-y).T, np.log(1-y_hat)))
å›æŠ¥æŸå¤±

è®­ç»ƒé˜¶æ®µ - å‰å‘ä¼ æ’­ + åå‘ä¼ æ’­
input_layer = X_train.shape[0]
hidden_â€‹â€‹layer = 128
learning_rate = 0.01
epochs = 10

W1 = np.random.randn(hidden_â€‹â€‹layer, input_layer)
b1 = np.zeros((hidden_â€‹â€‹layer, 1))
W2 = np.random.randn(1, hidden_â€‹â€‹layer)
b2 = np.zeros((1, 1))

X = X_train
Y = Y_train
loss_list = []
epoch_list = []
num_of_examples = X.shape[1]

for i in range(epochs):
avg_epoch_loss = 0
for j in range(num_of_examples):

Z1 = np.matmul(W1,X[:,j].reshape(-1,1)) + b1 # ä¸è¦å¿˜è®°æ·»åŠ åå·®
A1 = sigmoid(Z1)
Z2 = np.matmul(W2,A1) + b2
A2 = sigmoid(Z2)
Yout = Y[j]

loss = log_loss( A2, Yout)
avg_epoch_loss = avg_epoch_loss + loss

dZ2 = (A2-Yout)
dW2 = np.matmul(dZ2,A1.T)
db2 = dZ2

dA1 = np.matmul(W2.T,dZ2)
dZ1 = dA1 * A1 * (1 - A1)
dW1 = np.matmul(dZ1,X[:,j].reshape(-1,1).T)
db1 = dZ1

W2 = W2 - å­¦ä¹ ç‡ * dW2
b2 = b2 - å­¦ä¹ ç‡ * db2
W1 = W1 - å­¦ä¹ ç‡ * dW1
b1 = b1 - å­¦ä¹ ç‡ * db1

avg_epoch_loss = avg_epoch_loss/num_of_examples
loss_list.append(avg_epoch_loss)
epoch_list.append(i)
print(&quot;Epoch&quot;, i,&quot;æŸå¤±ï¼š&quot;ï¼Œavg_epoch_loss)

è¿™äº›æ˜¯ä¸æ­£å¸¸çš„å€¼ - å½“ç„¶æ˜¯å¯»æ‰¾ 0-1 ä¹‹é—´çš„å€¼ï¼š
Epoch 0 æŸå¤±ï¼š[-18.37821485]
Epoch 1 æŸå¤±ï¼š[-18.82406892]
Epoch 2 æŸå¤±ï¼š[-18.82406892]
Epoch 3 æŸå¤±ï¼š[-19.99316345]
Epoch 4 æŸå¤±ï¼š[-29.91647793]
Epoch 5 æŸå¤±ï¼š[-32.32075724]
Epoch 6 æŸå¤±ï¼š[-32.89639034]
Epoch 7 æŸå¤±ï¼š[-32.34691639]
Epoch 8 æŸå¤±ï¼š [-32.749394]
ç¬¬ 9 é˜¶æ®µæŸå¤±ï¼š[-33.61631871]
]]></description>
      <guid>https://stackoverflow.com/questions/79302179/implementation-of-binary-cross-entropy-gives-not-normal-result</guid>
      <pubDate>Mon, 23 Dec 2024 05:00:53 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ ONNXRuntime C++ ä¼˜åŒ– Florence-2 æ¨¡å‹æ¨ç† - ç”Ÿæˆå¾ªç¯çš„æ€§èƒ½ä¼˜åŒ– [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79302122/optimizing-florence-2-model-inference-with-onnxruntime-c-performance-optimiz</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79302122/optimizing-florence-2-model-inference-with-onnxruntime-c-performance-optimiz</guid>
      <pubDate>Mon, 23 Dec 2024 04:15:57 GMT</pubDate>
    </item>
    <item>
      <title>æ¨¡å‹æ— æ³•æ­£å¸¸å­¦ä¹ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79301299/model-cant-learn-normally</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79301299/model-cant-learn-normally</guid>
      <pubDate>Sun, 22 Dec 2024 16:24:38 GMT</pubDate>
    </item>
    <item>
      <title>å•ä¸ªå·ç§¯æ»¤æ³¢å™¨æ˜¯å¦å¯ä»¥ç»„åˆæ¥è‡ªè¾“å…¥å¤šä¸ªé€šé“çš„å€¼[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79301125/can-single-convolutional-filter-combine-values-from-input-multiple-channels</link>
      <description><![CDATA[å…³äºå·ç§¯ç¥ç»ç½‘ç»œçš„é—®é¢˜ã€‚
ç¬¬ 1 éƒ¨åˆ†ï¼šå‡è®¾è¾“å…¥æ˜¯ RGB å›¾åƒï¼Œæˆ‘ä»¬å°†å…¶æ”¾å…¥å·ç§¯å±‚ã€‚äººä»¬æ˜¯å¦æ›¾ç»ä½¿ç”¨åŒæ—¶å¯¹è¾“å…¥çš„å¤šä¸ªé€šé“ï¼ˆä¾‹å¦‚ R å’Œ Gï¼‰è¿›è¡Œæ“ä½œçš„è¿‡æ»¤å™¨ï¼Œå¹¶åœ¨è®¡ç®—ä¸­ç»“åˆä¸¤ä¸ªé€šé“çš„å€¼ï¼Ÿæ¢å¥è¯è¯´ï¼Œè¿‡æ»¤å™¨çŸ©é˜µæ˜¯ 3Dï¼ˆæˆ–æ›´å¤šï¼‰è¿˜æ˜¯ 2Dï¼Ÿ
ç¬¬ 2 éƒ¨åˆ†ï¼šå¦‚æœæˆ‘é”™äº†ï¼Œè¯·çº æ­£æˆ‘ï¼Œä½†æœ‰æ—¶åœ¨åŒä¸€å±‚ä¸­å¯ä»¥æœ‰å¤šä¸ªè¿‡æ»¤å™¨ã€‚æˆ‘çš„æ„æ€æ˜¯ï¼Œä¹Ÿè®¸è¾“å…¥å›¾åƒæœ‰ 1 ä¸ªé€šé“ï¼ˆç°åº¦ï¼‰ï¼Œä½†å±‚çš„è¾“å‡ºæœ‰ 2 ä¸ªé€šé“ã€‚è¿™ç›¸å½“äºæœ‰ 2 ä¸ªç‹¬ç«‹çš„è¿‡æ»¤å™¨ï¼Œå³ 2 ä¸ªä¸åŒçš„ 3x3 çŸ©é˜µï¼Œæ¯ä¸ªçŸ©é˜µäº§ç”Ÿä¸€ä¸ªé€šé“ã€‚
æˆ‘ç†è§£è¿‡æ»¤å™¨æ˜¯ä¸€ä¸ªå•ä¸€ï¼ˆä¾‹å¦‚ 3x3ï¼‰çŸ©é˜µï¼Œæˆ‘ä»¬åœ¨è¾“å…¥å›¾åƒå‘¨å›´ç§»åŠ¨å®ƒå¹¶è®¡ç®—å®ƒâ€œè¦†ç›–â€çš„åŒºåŸŸçš„æŸä¸ªåŠ æƒå¹³å‡å€¼ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79301125/can-single-convolutional-filter-combine-values-from-input-multiple-channels</guid>
      <pubDate>Sun, 22 Dec 2024 14:04:26 GMT</pubDate>
    </item>
    <item>
      <title>æˆ‘å¯ä»¥åœ¨ MacbookM4 ä¸Šä½¿ç”¨ CUDA å—ï¼Ÿ[é‡å¤]</title>
      <link>https://stackoverflow.com/questions/79300848/can-i-use-cuda-on-macbookm4</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä¸ºæˆ‘çš„æœ¬ç§‘è®ºæ–‡åˆ›å»ºä¸€ä¸ªåŠ¨ä½œæ£€æµ‹ç³»ç»Ÿã€‚
æˆ‘ç°åœ¨æ­£å°è¯•å°† MMSkeleton é›†æˆåˆ°æˆ‘çš„é¡¹ç›®ç®¡é“ä¸­ã€‚https://github.com/open-mmlab/mmskeleton
è¦ä½¿ç”¨ MMSkeletonï¼Œæˆ‘éœ€è¦å®‰è£… PyTorch å’Œ torchvisionï¼ˆéœ€è¦ CUDAï¼‰ï¼Œä½†æ®æˆ‘æ‰€çŸ¥ï¼ŒMac æ— æ³•åšåˆ°è¿™ä¸€ç‚¹ã€‚æˆ‘æ”¶åˆ°æ­¤é”™è¯¯ OSErrorï¼šç¼–è¯‘ MMSkeleton éœ€è¦ CUDAï¼
æœ‰äººçŸ¥é“æˆ‘è¯¥å¦‚ä½•å…‹æœè¿™ä¸ªéšœç¢å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79300848/can-i-use-cuda-on-macbookm4</guid>
      <pubDate>Sun, 22 Dec 2024 10:49:49 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆå½“ refit=True æ—¶ï¼Œåœ¨ RandomizedSearchCV ä¹‹åä¼šè¿›è¡Œé¢å¤–çš„æ‹Ÿåˆï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79300159/why-is-an-additional-fitting-performed-after-randomizedsearchcv-when-refit-true</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ scikit-learn ä¸­çš„ RandomizedSearchCV è¿›è¡Œè¶…å‚æ•°è°ƒæ•´ï¼Œå¹¶æ³¨æ„åˆ°å³ä½¿ refit å‚æ•°è®¾ç½®ä¸º Trueï¼Œåœ¨æ‰¾åˆ°æœ€ä½³å‚æ•°åä¹Ÿä¼šæ‰§è¡Œé¢å¤–çš„æ‹Ÿåˆæ­¥éª¤ã€‚
è¿™æ˜¯ä¸€ä¸ªæœ€å°çš„å¯é‡ç°ç¤ºä¾‹ï¼š
æ¥è‡ª sklearn.datasets å¯¼å…¥ make_classification
æ¥è‡ª sklearn.model_selection å¯¼å…¥ RandomizedSearchCV
æ¥è‡ª sklearn.ensemble å¯¼å…¥ RandomForestClassifier
æ¥è‡ª scipy.stats å¯¼å…¥ randint

# ç”Ÿæˆåˆæˆæ•°æ®é›†
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# å®šä¹‰æ¨¡å‹å’Œå‚æ•°åˆ†å¸ƒ
model = RandomForestClassifier(random_state=42)
param_dist = {
&#39;n_estimators&#39;: randint(10, 100),
&#39;max_depth&#39;: randint(3, 20),
}

# æ‰§è¡Œ RandomizedSearchCV
search = RandomizedSearchCV(
model, param_dist, n_iter=10, cv=3, random_state=42, refit=True
)
search.fit(X, y)

# è®¿é—®æœ€ä½³ä¼°è®¡å™¨
best_model = search.best_estimator_

print(best_model)

æˆ‘ç†è§£ refit=True æ ‡å¿—è¡¨ç¤ºåœ¨è¶…å‚æ•°è°ƒæ•´åï¼Œåº”åœ¨æ•´ä¸ªæ•°æ®é›†ä¸Šé‡æ–°æ‹Ÿåˆæœ€ä½³æ¨¡å‹ã€‚ä½†æ˜¯ï¼Œä¸ºä»€ä¹ˆäº¤å‰éªŒè¯ä¸­çš„â€œæœ€ä½³æ¨¡å‹â€ä¸ç›´æ¥ä½œä¸º search.best_estimator_ è¿”å›ï¼Ÿå¯¹æ•´ä¸ªæ•°æ®é›†æ‰§è¡Œå¦ä¸€ä¸ªæ‹Ÿåˆæ­¥éª¤çš„åŸå› æ˜¯ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79300159/why-is-an-additional-fitting-performed-after-randomizedsearchcv-when-refit-true</guid>
      <pubDate>Sat, 21 Dec 2024 21:49:41 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ MaxViT è¿›è¡Œè¿ç§»å­¦ä¹ æ—¶æˆ‘çš„åˆ†ç±»å™¨åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79300055/what-should-be-my-classifier-in-transfer-learning-using-maxvit</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†åœ¨ Pytorch é¢„è®­ç»ƒæ¨¡å‹ä¸Šè¿›è¡Œè¿ç§»å­¦ä¹ ã€‚æˆ‘å·²ç»èƒ½å¤Ÿä½¿ç”¨ SqueezeNet æˆåŠŸæ‰§è¡Œè¿ç§»å­¦ä¹ ã€‚
å¯¹äº Squeezenetï¼Œæˆ‘çš„åˆ†ç±»å™¨æ˜¯ï¼Œlayers source
model.classifier = nn.Sequential(
nn.Dropout(p=0.2),
nn.Conv2d(512, len(class_names), kernel_size=1),
nn.ReLU(inplace=True),
nn.AdaptiveAvgPool2d((1, 1)))

å¯¹äº Efficientnetï¼Œæˆ‘çš„åˆ†ç±»å™¨æ˜¯ï¼Œlayers source
model.classifier = torch.nn.Sequential(
torch.nn.Dropout(p=0.2, inplace=True),
torch.nn.Linear(in_features=1280,
out_features=output_shape,
bias=True))

æˆ‘ä¹Ÿä¸€ç›´åœ¨å°è¯•ä¸º MaxViT åšç±»ä¼¼çš„äº‹æƒ…ï¼Œæˆ‘æŸ¥çœ‹äº†æºä»£ç ï¼Œå‘ç°å‚æ•°ä¸­æœ‰ block_channels[-1]ã€‚æˆ‘æœ€è¿‘å¼€å§‹ç”¨è¿™ä¸ªï¼Œä¸çŸ¥é“å®ƒä»¬æ˜¯ä»€ä¹ˆï¼Œlayers source
self.classifier = nn.Sequential(
nn.AdaptiveAvgPool2d(1),
nn.Flatten(),
nn.LayerNorm(block_channels[-1]),
nn.Linear(block_channels[-1], block_channels[-1]),
nn.Tanh(),
nn.Linear(block_channels[-1], num_classes, bias=False),
)

å¦‚æœéœ€è¦ï¼Œä»¥ä¸‹æ˜¯æˆ‘ä½¿ç”¨ squeezenet æ‰§è¡Œè¿ç§»å­¦ä¹ çš„å®Œæ•´ä»£ç ï¼Œä»…ä¾›å‚è€ƒã€‚
weights = torchvision.models.SqueezeNet1_0_Weights.DEFAULT
model = torchvision.models.squeezenet1_0(weights=weights).to(device)
auto_transforms = weights.transforms()
train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=d1,
test_dir=d2,
transform=auto_transforms,
batch_size=32)
for param in model.features.parameters():
param.requires_grad = False

torch.manual_seed(42)
torch.cuda.manual_seed(42)
output_shape = len(class_names)

model.classifier = nn.Sequential(
nn.Dropout(p=0.2),
nn.Conv2d(512, len(class_names), kernel_size=1),
nn.ReLU(inplace=True),
nn.AdaptiveAvgPool2d((1, 1))).to(device)

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
torch.manual_seed(42)
torch.cuda.manual_seed(42)
results = engine.train(model=model,
train_dataloader=train_dataloader,
test_dataloader=test_dataloader,
optimizer=optimizer,
loss_fn=loss_fn,
epochs=15,
device=device)

æˆ‘çš„ MaxViT åˆ†ç±»å™¨åº”è¯¥æ˜¯ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79300055/what-should-be-my-classifier-in-transfer-learning-using-maxvit</guid>
      <pubDate>Sat, 21 Dec 2024 20:24:49 GMT</pubDate>
    </item>
    <item>
      <title>ST-GCN æ˜¯å¦è¿‡æ—¶äº†ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79297114/is-st-gcn-outdated</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•æ„å»ºä¸€ä¸ªç®¡é“æ¥è·Ÿè¸ªè§†é¢‘ç›‘æ§å½•åƒä¸­çš„å¼‚å¸¸æƒ…å†µã€‚
ä¸ºäº†å¯¹æ£€æµ‹åˆ°çš„äººçš„è¡Œä¸ºè¿›è¡Œåˆ†ç±»ï¼Œæˆ‘æƒ³ä½¿ç”¨ ST-GCNï¼Œä½†æ˜¯æˆ‘èƒ½æ‰¾åˆ°çš„å”¯ä¸€æ–‡æ¡£æ˜¯ 5 å¹´å‰æ›´æ–°çš„ï¼Œä½†é˜…è¯»æœ€æ–°ç ”ç©¶ ST-GCN ä»åœ¨ä½¿ç”¨ä¸­ã€‚
æœ‰è°çŸ¥é“æ›´æ–°çš„æ–‡æ¡£æˆ–èƒ½ç»™æˆ‘ä¸€äº›æç¤ºï¼Œå‘Šè¯‰æˆ‘å¦‚ä½•æ‰¾åˆ°ä¸€äº›å…³äºå¦‚ä½•å°†å…¶å®ç°åˆ°æˆ‘çš„ç®¡é“ä¸­çš„ä¿¡æ¯ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79297114/is-st-gcn-outdated</guid>
      <pubDate>Fri, 20 Dec 2024 11:42:14 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch GRU é”™è¯¯ RuntimeErrorï¼šå¤§å°ä¸åŒ¹é…ï¼Œm1ï¼š[1600 x 3]ï¼Œm2ï¼š[50 x 20]</title>
      <link>https://stackoverflow.com/questions/66131870/pytorch-gru-error-runtimeerror-size-mismatch-m1-1600-x-3-m2-50-x-20</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/66131870/pytorch-gru-error-runtimeerror-size-mismatch-m1-1600-x-3-m2-50-x-20</guid>
      <pubDate>Wed, 10 Feb 2021 06:23:22 GMT</pubDate>
    </item>
    <item>
      <title>Python ä¸­çš„ç¥ç»ç½‘ç»œ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/61845701/neural-network-in-python</link>
      <description><![CDATA[æˆ‘æœ€è¿‘å¼€å§‹å°è¯•åœ¨ä¸ä½¿ç”¨ä»»ä½• NW æ¨¡å—ï¼ˆå¦‚ Tensor Flowï¼‰çš„æƒ…å†µä¸‹åˆ›å»ºè‡ªå·±çš„ç¥ç»ç½‘ç»œï¼Œä½†æˆ‘æ— æ³•å°†å·²å®šä¹‰çš„å˜é‡æ”¾å…¥å‡½æ•°ä¸­ï¼Œå› æ­¤æˆ‘å°†æ•°æ®æ”¾å…¥æ–‡æœ¬æ–‡ä»¶ä¸­ï¼Œç„¶åå¯¹å…¶è¿›è¡Œè¯»å†™ã€‚è™½ç„¶å®ƒä¸å…è®¸æˆ‘å°†æƒé‡é‡æ–°è½¬æ¢ä¸º intï¼Œä»¥ä¾¿æˆ‘å¯ä»¥å°†å®ƒä»¬ä¹˜ä»¥å®ƒä»¬çš„å­¦ä¹ ç‡ã€‚æˆ‘æ”¶åˆ°ä¸€æ¡é”™è¯¯æ¶ˆæ¯ï¼Œæç¤º int ä¸é€‚ç”¨äºåŸºæ•°ã€‚

ä½ å¯¹æ­¤æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/61845701/neural-network-in-python</guid>
      <pubDate>Sun, 17 May 2020 01:07:59 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•åœ¨ PyTorch ä¸­åˆå§‹åŒ–æƒé‡ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/49433936/how-do-i-initialize-weights-in-pytorch</link>
      <description><![CDATA[å¦‚ä½•åˆå§‹åŒ–ç½‘ç»œçš„æƒé‡å’Œåå·®ï¼ˆä¾‹å¦‚é€šè¿‡ He æˆ– Xavier åˆå§‹åŒ–ï¼‰ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/49433936/how-do-i-initialize-weights-in-pytorch</guid>
      <pubDate>Thu, 22 Mar 2018 16:34:42 GMT</pubDate>
    </item>
    <item>
      <title>ç¥ç»ç½‘ç»œï¼ˆç®€å•ï¼‰</title>
      <link>https://stackoverflow.com/questions/46079541/neural-network-simple</link>
      <description><![CDATA[æˆ‘å¾ˆå¥½å¥‡ä¸ºä»€ä¹ˆæˆ‘æ²¡æœ‰æ‰“å°ä»»ä½•è¾“å‡ºï¼Œå› ä¸ºä»£ç æ²¡æœ‰é”™è¯¯ã€‚
import numpy as np

class NN():
def _init_(self):
# ç§å­éšæœºæ•°ç”Ÿæˆå™¨ï¼Œå› æ­¤æ¯æ¬¡ç¨‹åºè¿è¡Œæ—¶éƒ½ä¼šç”Ÿæˆç›¸åŒçš„æ•°å­—
# np.random.seed(1)

# æ¨¡å‹å•ä¸ªç¥ç»å…ƒï¼Œå…·æœ‰ 3 ä¸ªè¾“å…¥è¿æ¥å’Œ 1 ä¸ªè¾“å‡ºè¿æ¥
# å°†éšæœºæƒé‡åˆ†é…ç»™ 3x1 çŸ©é˜µï¼Œå€¼èŒƒå›´ä¸º -1 åˆ° 1
# å¹³å‡å€¼ä¸º 0
self.synaptic_weights = 2 * np.random.random((3, 1)) - 1

# æè¿° s å½¢æ›²çº¿æˆ‘ä»¬ä¼ é€’è¾“å…¥çš„åŠ æƒå’Œ
# é€šè¿‡æ­¤å‡½æ•°å°†å®ƒä»¬æ ‡å‡†åŒ–ä¸º 0 å’Œ 1 ä¹‹é—´
def __sigmoid(self, x):
return 1 / (1 + np.exp(-x))

# æ¢¯åº¦sigmoid æ›²çº¿
def __sigmoid_derivative(self, x):
return x * (1 - x)

def train(self, training_set_input, training_set_output, number_of_training_iterations):
for iteration in np.xrange(number_of_training_iterations):
# å°†è®­ç»ƒé›†é€šè¿‡ç¥ç»ç½‘ç»œ
output = self.predict(training_set_input)

error = training_set_output - output

# å°†è¯¯å·®ä¹˜ä»¥è¾“å…¥ï¼Œå†ä¹˜ä»¥ sigmoid æ›²çº¿çš„æ¢¯åº¦
adjustment = np.dot(training_set_input.T, error * self.__sigmoid_derivative(output))

# è°ƒæ•´æƒé‡
self.synaptic_weights += adjustment

def predict(self, input):
# å°†è¾“å…¥é€šè¿‡ç¥ç»ç½‘ç»œï¼ˆå•ä¸ªç¥ç»å…ƒï¼‰
return self.__sigmoid(np.dot(inputs, self.synaptic_weights))

if __name__ == &quot;__NN__&quot;:
# åˆå§‹åŒ–å•ç¥ç»å…ƒç¥ç»ç½‘ç»œ
nn = NN()
weightz = nn.synaptic_weights
new_predict = nn.predict(np.array[1, 0, 0])

print(&quot;éšæœºèµ·å§‹çªè§¦æƒé‡&quot;)
print(weightz)

# T å‚ç›´ç¿»è½¬çŸ©é˜µ
training_set_input = np.array([0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1])
training_set_output = np.array([0, 1, 0, 0]).T

# ä½¿ç”¨è®­ç»ƒé›†è®­ç»ƒç½‘ç»œ
# æ‰§è¡Œ 10,000 æ¬¡ï¼Œæ¯æ¬¡è¿›è¡Œå°å¹…è°ƒæ•´
nn.train(training_set_input, training_set_output, 10000)

print(&quot;æ–°çš„èµ·å§‹çªè§¦æƒé‡&quot;)
print(weightz)

# æµ‹è¯•
print(&quot;é¢„æµ‹&quot;)
print(new_predict)

å°†æ–‡ä»¶ä¿å­˜ä¸º NN.py]]></description>
      <guid>https://stackoverflow.com/questions/46079541/neural-network-simple</guid>
      <pubDate>Wed, 06 Sep 2017 15:51:06 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ MLP çš„ç¥ç»ç½‘ç»œåˆ†ç±»å™¨</title>
      <link>https://stackoverflow.com/questions/43238285/neural-network-classifier-using-mlp</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ª Python åº”ç”¨ç¨‹åºï¼Œå®ƒä½¿ç”¨ä¸€ä¸ªæ•°æ®é›†å¯¹æ‰‘å…‹ç‰Œè¿›è¡Œåˆ†ç±»ï¼Œæˆ‘å°†å‘å¸ƒä¸€äº›ç‰‡æ®µã€‚å®ƒä¼¼ä¹æ•ˆæœä¸ä½³ã€‚å®ƒæ— æ³•æ­£ç¡®åœ°å¯¹ç‰Œè¿›è¡Œåˆ†ç±»ã€‚æˆ‘å¾—åˆ°äº†ä»¥ä¸‹é”™è¯¯
ç¬¬ 298 è¡Œï¼Œåœ¨ fit ä¸­
raise ValueError(&quot;Multioutput target data is not supports with &quot;
ValueError: Multioutput target data is not supports with label binarization

ä»¥ä¸‹æ˜¯æˆ‘çš„ä»£ç ï¼š
import pandas as pnd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classes_report
training = pnd.read_csv(&quot;.idea/train.csv&quot;)
training.keys()
training.shape
X = np.array(training)
y = np.array(training)
X_train, X_test, y_train, y_test = train_test_split(X, y)
scaler = StandardScaler()
# ä»…é€‚åˆè®­ç»ƒæ•°æ®
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
mlp = MLPClassifier(hidden_â€‹â€‹layer_sizes=(30, 30, 30, 30, 30, 30, 30, 30, 30))
mlp.fit(X_train, y_train)
predictions = mlp.predict(X_test)
print(classification_report(y_test, predictions))
len(mlp.coefs_)
len(mlp.coefs_[0])
len(mlp.intercepts_[0])

ä»¥ä¸‹æ˜¯æˆ‘ä½¿ç”¨çš„æ•°æ®é›†ç¤ºä¾‹ï¼š
å›¾ç‰‡åœ¨è¿™é‡Œ
è¿™é‡Œæ˜¯æ•°æ®é›†çš„æè¿°ï¼š
https://archive.ics.uci.edu/ml/datasets/Poker+Hand
æœ‰ä»€ä¹ˆé—®é¢˜å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/43238285/neural-network-classifier-using-mlp</guid>
      <pubDate>Wed, 05 Apr 2017 17:50:50 GMT</pubDate>
    </item>
    </channel>
</rss>