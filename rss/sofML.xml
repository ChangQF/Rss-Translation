<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 20 Apr 2024 00:59:14 GMT</lastBuildDate>
    <item>
      <title>DQN 模型中从未实现的目标状态</title>
      <link>https://stackoverflow.com/questions/78356381/goal-state-never-achieved-in-dqn-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78356381/goal-state-never-achieved-in-dqn-model</guid>
      <pubDate>Fri, 19 Apr 2024 22:22:39 GMT</pubDate>
    </item>
    <item>
      <title>在SVM中，当超参数C增大时，margin会变大吗？</title>
      <link>https://stackoverflow.com/questions/78356095/in-svm-when-hyper-parameter-c-increases-the-margin-will-be-larger</link>
      <description><![CDATA[我目前正在研究SVM，发现关于超参数C和margin之间的关系有两种相反的解释。我知道在支持向量分类器中，C 限制 epsilon 的总和不能大于 C。问题是，我发布的第一张图片说当 C 增加时，边距会更大，但我发布的第二张图片和我发现的其他一些信息说边距会变窄。我很困惑。
在此处输入图像描述
在此处输入图像描述]]></description>
      <guid>https://stackoverflow.com/questions/78356095/in-svm-when-hyper-parameter-c-increases-the-margin-will-be-larger</guid>
      <pubDate>Fri, 19 Apr 2024 20:43:04 GMT</pubDate>
    </item>
    <item>
      <title>使用邮递员使用临时凭证调用 Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/78356002/calling-sagemaker-endpoint-using-postman-using-temporary-credentials</link>
      <description><![CDATA[我已将 AWS CLI 配置为通过 SSO 使用配置文件。我已引用此文档 AWS 文档
我想使用邮递员调用 Sagemaker 端点。有没有办法做到。我尝试在邮递员中提供我的凭据，但它返回 404 错误。
一些额外的细节 -
Sagemaker 端点使用 VPC。]]></description>
      <guid>https://stackoverflow.com/questions/78356002/calling-sagemaker-endpoint-using-postman-using-temporary-credentials</guid>
      <pubDate>Fri, 19 Apr 2024 20:13:01 GMT</pubDate>
    </item>
    <item>
      <title>Llama2-7b 根据提示生成文本的运行时间较长</title>
      <link>https://stackoverflow.com/questions/78355789/llama2-7b-long-runtime-to-generate-text-from-a-prompt</link>
      <description><![CDATA[我已将 HuggingFace 中的 Llama2-7b 模型加载到我的计算机上，以根据简单的提示生成文本。该模型加载速度非常快（大约 2 分钟），但当我想从简单的提示中生成非常简单的响应时，例如“什么是 LLM？”该模型需要两个多小时才能生成响应。我需要它运行得更快，但不知道让它运行得更快有什么问题。有什么建议吗？
这是我的代码：
类 LlamaInference():
    “”“使用 Llama 70b 参数 LLM 的文本生成类。生成数据集。“”“
    def __init__(self, 输出文件路径):
        ”“”初始化 LlamaInference 类和所有变量
        关键字参数：
        output_file_path -- 数据集生成后输出文件的位置
        ”“”
        self.output_file_path = 输出文件路径
        self.pipeline = 无
        self.output_list = []
        self.output_list_condensed = []

    def __set_up(自我):
        ”“”使用特定模型和修订版设置 Huggingface 管道
        ”“”
        #model =“meta-llama/Llama-2-70b-chat-hf”
        #revision =“e6152b720bd3cd67afc66e36d06893a0e1f84b48”
        模型=“meta-llama/Llama-2-7b-chat-hf”
        修订版=“08751db2aca9bf2f7f80d2e516117a53d7450235”


    
        self.tokenizer = AutoTokenizer.from_pretrained(model, padding_side=&quot;left&quot;)

        self.pipeline = 变压器.pipeline(
            “文本生成”，
            型号=型号，
            分词器=self.分词器，
            torch_dtype=torch.float16,
            device_map=“自动”，
            修订=修订，
            do_sample=真，
            return_full_text=False
        ）
        self.pipeline.tokenizer.pad_token_id = self.tokenizer.eos_token_id


    def gen_text(自我，提示，**kwargs)：
        ”“”根据提示生成文本

        关键字参数：
        提示——我们向法学硕士提出的问题
        **kwargs——传递给 self.pipeline 的参数
        ”“”
        尝试：
            如果 self.pipeline 为 None：
                self.__set_up()
            如果“batch_size”是不在 kwargs 中：
                kwargs[“batch_size”] = 1
            
            如果“max_new_tokens”是不在 kwargs 中：
                kwargs[“max_new_tokens”] = 2048

            kwargs.update(
                {
                    “pad_token_id”：self.pipeline.tokenizer.eos_token_id，
                    “eos_token_id”：self.pipeline.tokenizer.eos_token_id，
                }
            ）
            显示（&#39;启动管道&#39;）
            token_outputs = self.tokenizer(提示)
            显示（令牌输出）
            输出= self.pipeline（提示，**kwargs）
            显示(&#39;结束管道&#39;)
            返回输出
        除了异常作为错误：
            显示（f&#39;__gen_text错误：{错误}&#39;）

推理 = LlamaInference(&#39;test.json&#39;)
结果 = inference.gen_text(“你好”，max_new_tokens=2048，batch_size=1，温度=0.5)
]]></description>
      <guid>https://stackoverflow.com/questions/78355789/llama2-7b-long-runtime-to-generate-text-from-a-prompt</guid>
      <pubDate>Fri, 19 Apr 2024 19:18:13 GMT</pubDate>
    </item>
    <item>
      <title>从 torchensemble 的基本模型中获取嵌入</title>
      <link>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</link>
      <description><![CDATA[我一直在学习Torchensemble，我想知道你可以如何在最终分类层之前提取嵌入。
这是我的整体模型：
VotingClassifier(
 （基本估计器_）：CCT（
  （分词器）：分词器（
   (conv_layers): 顺序(
    (0): 顺序(
     (0): Conv2d(3, 64, kernel_size=(7, 7), 步长=(2, 2), 填充=(3, 3), 偏差=False)
     (1)：ReLU()
     (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    ）
    (1): 顺序(
     (0): Conv2d(64, 256, kernel_size=(7, 7), 步长=(2, 2), 填充=(3, 3), 偏差=False)
     (1)：ReLU()
     (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    ）
   ）
   （展平器）：展平（start_dim=2，end_dim=3）
  ）
  （分类器）：TransformerClassifier（
   （注意力池）：线性（in_features=256，out_features=1，偏差=True）
   (dropout): Dropout(p=0.0, inplace=False)
   （块）：模块列表（
    (0): TransformerEncoderLayer(
     (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     (self_attn): 注意(
      （qkv）：线性（in_features = 256，out_features = 768，偏差= False）
      (attn_drop): Dropout(p=0.1, inplace=False)
      （项目）：线性（in_features = 256，out_features = 256，偏差= True）
      (proj_drop): Dropout(p=0.0, inplace=False)
     ）
     （线性1）：线性（in_features = 256，out_features = 512，偏差= True）
     (dropout1): Dropout(p=0.0, inplace=False)
     (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     （线性2）：线性（in_features = 512，out_features = 256，偏差= True）
     (dropout2): Dropout(p=0.0, inplace=False)
     (drop_path): 身份()
    ）
    (1-6): 6 x TransformerEncoderLayer(
     (pre_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     (self_attn): 注意(
      （qkv）：线性（in_features = 256，out_features = 768，偏差= False）
      (attn_drop): Dropout(p=0.1, inplace=False)
      （项目）：线性（in_features = 256，out_features = 256，偏差= True）
      (proj_drop): Dropout(p=0.0, inplace=False)
     ）
     （线性1）：线性（in_features = 256，out_features = 512，偏差= True）
     (dropout1): Dropout(p=0.0, inplace=False)
     (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
     （线性2）：线性（in_features = 512，out_features = 256，偏差= True）
     (dropout2): Dropout(p=0.0, inplace=False)
     (drop_path): DropPath()
    ）
   ）
   (范数): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
   （fc）：线性（in_features = 256，out_features = 5013，偏差= True）
  ）
 ）
 (估计器_): ModuleList()
 (_criterion): CrossEntropyLoss()
）

你看，基础模型的最后有一个全连接层（fc）。我想删除它或用 Identity 替换它。怎么做？看起来删除基本估计器中的层没有做任何事情。]]></description>
      <guid>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</guid>
      <pubDate>Fri, 19 Apr 2024 18:25:20 GMT</pubDate>
    </item>
    <item>
      <title>带有产品推荐系统的电子商务网络应用程序</title>
      <link>https://stackoverflow.com/questions/78355434/e-commerce-webapp-with-product-recommandation-system</link>
      <description><![CDATA[您好，我有一个带有推荐系统的电子商务 Web 应用程序的 fyp，您能告诉我如何集成制作一个可以在 React JS 中工作的推荐系统，或者如何将其与 React JS 集成
我已经完成了我的 Mern Stack Web 电子商务应用程序，现在我想创建推荐系统并将其与我的 Web 应用程序连接]]></description>
      <guid>https://stackoverflow.com/questions/78355434/e-commerce-webapp-with-product-recommandation-system</guid>
      <pubDate>Fri, 19 Apr 2024 17:50:13 GMT</pubDate>
    </item>
    <item>
      <title>在序列模型中使用归一化层时，adapt() 会出错吗？</title>
      <link>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</link>
      <description><![CDATA[在顺序模型中使用归一化层时，在调整（）时，我收到未绑定错误：
这是错误
我做了以下事情：
标准化器 = 标准化()
标准化器.adapt(X_train)

但这给了
未绑定错误：赋值之前引用了局部变量“input_shape”。

为什么我会收到此错误？]]></description>
      <guid>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</guid>
      <pubDate>Fri, 19 Apr 2024 17:04:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 进行音频分类总是预测错误</title>
      <link>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</guid>
      <pubDate>Fri, 19 Apr 2024 13:39:10 GMT</pubDate>
    </item>
    <item>
      <title>获取边界框问题</title>
      <link>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</guid>
      <pubDate>Fri, 19 Apr 2024 12:40:40 GMT</pubDate>
    </item>
    <item>
      <title>请为我的毕业设计解决机器学习中牙齿分割模型的Valueerror</title>
      <link>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</link>
      <description><![CDATA[大家好，我从 此处。
该程序应为用户提供两种选择：

从图像中读取并提取特征：此选项使用 FeatureExtraction 模块从图像中提取 9 个特征（包括图像名称）。
读取预先存在的数据集：此选项读取包含 labels.csv、features.csv 和图像文件的数据集。然后它会询问用户：

执行程序的次数（假设为 5）。
使用 K 折交叉验证分割数据所需的折叠数（假设为 5 折叠，即 k=5）。
测试数据集的大小（假设为 20%）。



模型然后将这些参数传递给classification模块中的分类函数。这就是问题出现的地方：

代码将整个数据集传递给 onlyfiles，其中包含 973 个条目。
然后，它会从 labels.csv（有 778 个条目）中识别 images_name 和 label_color。这代表训练数据集，因为我们之前指定了 20% 的测试集（778 = 973 的 80%）。
以下 for 循环迭代由 k_folds.split(images_name) 生成的分割。此时，我们仍在处理训练数据集，并且当 k=5 时，应该有：

train_index 中有 662 个索引（用于训练数据）。
test_index 中有 156 个索引（用于在训练集中进行验证）。



这是下一个 for 循环中发生错误的位置：
对于 train_index 中的 i：
    current_filename = onlyfiles[i].split(&#39;.&#39;)[0].strip()
    如果 current_filename 在训练数据集中：
        # ...（其余代码）
    别的：
        print(f“警告：在 images_name 中找不到‘{current_filename}’，因为它的索引是 {i}.train。”)


第一行根据 train_index 中的索引 i 检索文件名 (current_filename)。假设 i 为 324，train_index 包含从 156 到 777 的索引（而 test_index 范围从 0 到 155）。
出现此错误的原因是，有时循环会尝试在 images_name 中查找 current_filename，但该文件并不存在。这是因为 images_name 只有 778 个条目（训练数据），其余 195 个条目（测试数据）不包括在内。因此，current_filename 实际上可能属于测试数据集，从而导致错误“101_0032.JPG 不在列表中”。

我尝试对列表进行排序并删除随机播放（在 k_folds.split 中设置 shuffle=False），但错误仍然存​​在。我非常感谢您为解决此问题提供一些帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78350657/solving-valueerror-of-tooth-segmentation-model-in-machine-learning-for-my-gradua</guid>
      <pubDate>Thu, 18 Apr 2024 23:03:02 GMT</pubDate>
    </item>
    <item>
      <title>LMST模型敏感性——初学者抗运气</title>
      <link>https://stackoverflow.com/questions/78349854/lmst-model-sensitivity-beginners-anti-luck</link>
      <description><![CDATA[我一直在尝试使用艾伯塔省电力市场的一些非常基本的数据，并尝试使用时间序列数据的 LMST 模型来尝试预测价格。我确实得到“可能”这是我的模型的结果，而且它似乎确实出现了我们可以预期的一些波动（仅根据我自己的市场经验）。
但是，我正在寻求更好地理解我遇到的一些陷阱。
从 keras.models 导入顺序
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dropout
从 keras.layers 导入密集
将 pandas 导入为 pd
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入mean_absolute_error,mean_squared_error
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
导入作业库

# 加载数据
# 加载数据

# 加载数据
csv_file_path = &#39;Frankenstein.csv&#39; # 使用您的实际文件路径更新
df = pd.read_csv(csv_file_path)

# 将“日期/时间”转换为日期时间并提取数据集中存在的组件
如果 df.columns 中的“日期/时间”：
    df[&#39;日期&#39;] = pd.to_datetime(df[&#39;日期/时间&#39;])
    df[&#39;年份&#39;] = df[&#39;日期&#39;].dt.year
    df[&#39;月份&#39;] = df[&#39;日期&#39;].dt.月份
    df[&#39;日期&#39;] = df[&#39;日期&#39;].dt.day
    df[&#39;小时&#39;] = df[&#39;日期&#39;].dt.小时
    df.drop([&#39;日期/时间&#39;, &#39;日期&#39;], axis=1, inplace=True)

# 假设“价格”是目标变量
features = df.drop([&#39;价格&#39;], axis=1)
目标 = df[&#39;价格&#39;]

# 标准化特征和目标
缩放器特征 = MinMaxScaler()
features_scaled = scaler_features.fit_transform(features)
缩放器目标 = MinMaxScaler()
target_scaled = scaler_target.fit_transform(target.values.reshape(-1, 1))

# 创建序列函数
def create_sequences（特征，目标，time_steps = 100）：
    X、y = []、[]
    对于范围内的 i(len(features) - time_steps)：
        X.append(特征[i:(i + time_steps)])
        y.append(目标[i + time_steps])
    返回 np.array(X), np.array(y)

# 使用整个数据集创建序列
X, y = create_sequences(features_scaled, target_scaled.flatten())

# 模型配置
input_shape = (X.shape[1], X.shape[2]) # (time_steps, num_features)

# 定义LSTM模型
模型=顺序（[
    LSTM（单位= 100，return_sequences = True，input_shape = input_shape），
    辍学（0.1），
    LSTM（单位=100），
    辍学（0.1），
    密集（单位=100，激活=&#39;elu&#39;），
    Dense(1) # 预测单个值
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

# 在整个数据集上训练模型
历史= model.fit（X，y，纪元= 150，batch_size = 20，validation_split = 0.1）

# 情节训练&amp;验证损失值
plt.figure(figsize=(10, 6))
plt.plot(history.history[&#39;loss&#39;], label=&#39;火车&#39;)
plt.plot(history.history[&#39;val_loss&#39;], label=&#39;验证&#39;)
plt.title(&#39;模型损失&#39;)
plt.ylabel(&#39;损失&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.legend(loc=&#39;右上&#39;)
plt.show()

# 保存LSTM模型
model_save_path = &#39;trained_lstm_model.h5&#39;
model.save(model_save_path)
print(f&quot;模型已保存到 {model_save_path}&quot;)
joblib.dump(scaler_features, &#39;scaler_features.pkl&#39;)
joblib.dump(scaler_target, &#39;scaler_target.pkl&#39;)

有人可以给绝对的初学者一些建议吗？主要是为了更好地理解我应该如何设置它。我有一个每小时的数据集，是过去三年的历史生成和交换。我正在寻找方法让我的模型对供应与价格的变化更具反应性。]]></description>
      <guid>https://stackoverflow.com/questions/78349854/lmst-model-sensitivity-beginners-anti-luck</guid>
      <pubDate>Thu, 18 Apr 2024 19:18:18 GMT</pubDate>
    </item>
    <item>
      <title>流式 LightGBM 数据集构建在训练中冻结</title>
      <link>https://stackoverflow.com/questions/78344537/streaming-lightgbm-dataset-construction-freezes-on-training</link>
      <description><![CDATA[我一直在尝试使用参考数据集（称为 ref_dataset）以流方式在 Python 中构建 LightGBM 数据集。我不确定它是如何完成的，它涉及调用 Dataset 类中看似非公共的方法。
我已经尝试过：
label_column = “标签”
权重列=“权重”
ref_dataset = lightgbm.Dataset(
   Sample_df.drop(列=[标签列，权重列])
   标签=sample_df[标签_列],
   权重=sample_df[权重列],
   参数=配置，
   **（ref_dataset_kwargs 或 {}），
）
ref_dataset.construct()
temp_dataset = lightgbm.Dataset（无，参考= ref_dataset，params = ref_dataset.get_params（））
# train_filenames_and_part_infos 只是一个元组列表[filename,part_info_dict]
估计行数=总和（
    part_info[“num_rows”] for _，train_filenames_and_part_infos 中的part_info
）
temp_dataset._init_from_ref_dataset(estimated_num_rows, ref_dataset._handle)

权重列表 = []
标签列表=[]
# 这个循环实际上不是我的代码，它更复杂，但基本上是它的作用
对于文件名，train_filenames_and_part_infos 中的 _：
    tbl: pyarrow.Table = load_from_file(文件名)
    标签 = tbl[label_column].to_pandas().to_numpy()
    权重 = tbl[weight_column].to_pandas().to_numpy()

    labels_list.append(标签)
    weights_list.append(权重)
    tbl = tbl.drop_columns([label_column, Weight_column])
    np_array: np.ndarray = tbl.to_pandas().to_numpy()
    如果 temp_dataset._start_row + np_array.shape[0] &gt; temp_dataset.num_data():
        raise RuntimeError(“数据集太小，无法容纳数据”)
    temp_dataset._push_rows(np_array)

all_weights = np.concatenate(weights_list)
all_labels = np.concatenate(labels_list)
实际长度 = all_weights.shape[0]
# 不幸的是，由于各种原因，这个估计并不准确
extra_zeros_features = np.zeros(
     （估计行数 - 实际长度，temp_dataset.num_feature()），dtype=np.float32
）
temp_dataset._push_rows(extra_zeros_features)
_LIB.LGBM_DatasetMarkFinished(temp_dataset._handle)
extra_zeros = np.zeros(估计行数 - 实际长度, dtype=np.float32)
temp_dataset.set_weight(np.concatenate([all_weights, extra_zeros]))
temp_dataset.set_label(np.concatenate([all_labels, extra_zeros]))

lightgbm.train(
    params=config, # 包含分布式投票并行训练的网络参数
    train_set=temp_dataset，
    num_boost_round=100,
    valid_sets=valid_sets, # 在其他地方初始化
    valid_names=valid_names, # 在其他地方初始化
    init_model=starting_model, # 不是很有必要
    **lightgbm_train_kwargs, # 空
）

不幸的是，当我运行这段代码时，我得到了这个控制台输出（有些行可能是无序的，因为我实际上是在分布式上运行它，并且日志是聚合的；我已经做了一些简单的编辑删除干扰线）：
[LightGBM] [Info] 总 bin 137618
[LightGBM] [Info] 尝试绑定端口 50627...
[LightGBM] [Info] 绑定端口50627成功
[LightGBM] [信息] 聆听...
[LightGBM] [Info] 训练集中的数据点数量：3934363，使用的特征数量：1382
[LightGBM] [信息] 连接到等级 0
[LightGBM] [信息] 连接到排名 1
[LightGBM] [信息] 连接到等级 2
[LightGBM] [信息] 连接到等级 3
[LightGBM] [信息] 已连接至等级 4
[LightGBM] [信息] 已连接至排名 5
[LightGBM] [信息] 已连接至排名 6
[LightGBM] [信息] 已连接至排名 8
[LightGBM] [Info] 本地排名：7，机器总数：9
[LightGBM] [Info] 自动选择col-wise多线程，测试开销为5.318313秒。
[LightGBM] [Info] 从分数-0.000000开始训练

然后它就坐在那里，CPU 和网络都处于空闲状态。我没有看到它在几个小时内取得任何进展。我已经检查了所有的排名，是不是我做错了什么？我还如何使用给定的样本进行构建？
更多信息：
检查空闲 Python 进程的堆栈跟踪显示代码卡在：
更新（lightgbm/basic.py:3891）
火车（lightgbm/engine.py:276）
...我的代码...

对于我正在使用的 LightGBM 版本 (4.3.0)，这对应于代码：
_safe_call(_LIB.LGBM_BoosterUpdateOneIter(
                self._handle,
                ctypes.byref(is_finished)))

另一个更新：
不同工人的垃圾箱数量似乎不同；有些有 137608、137612、137616。这是一个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78344537/streaming-lightgbm-dataset-construction-freezes-on-training</guid>
      <pubDate>Thu, 18 Apr 2024 02:25:39 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Vertex AI 中部署自定义容器作为端点</title>
      <link>https://stackoverflow.com/questions/77266349/how-to-deploy-custom-container-in-vertex-ai-as-endpoint</link>
      <description><![CDATA[我正在尝试在 vertex ai 中部署自定义容器作为端点（REST URL 或 API），我能够成功构建 docker 映像，但无法将模型部署为端点，从日志中我也无法了解错误是什么。
下面是我的 Predict.py 、 dockerfile 和部署脚本
将 numpy 导入为 np

def 预测（数据）：
  # 预测函数示例
  打印（数据）
  #result = np.sum(data, axis=1) # 示例：沿轴 1 求和
  结果 = [3,4,5,6]
  results_array = np.array(结果)
  print ({“预测”: results_array.tolist()})
  return ({“预测”: results_array.tolist()})
  预测([3,4,6])

docker 文件
&lt;前&gt;&lt;代码&gt;来自 python:3.10
工作目录/代码

复制 要求.txt 要求.txt
复制模型.pkl 模型.pkl
运行 pip install --升级 pip
运行 pip --版本
运行 pip install -rrequirements.txt
复制 。 。
CMD [“python3”，“predict.py”]

部署脚本
导入操作系统
将 google.cloud.aiplatform 导入为 aiplatform

# 设置您的 GCP 项目 ID、位置和模型名称
项目=“项目ID”
位置=“us-central1”
model_name =“testing_3”；

# 初始化API客户端
aiplatform.init（项目=项目，位置=位置）

# 定义容器镜像URI
container_image_uri = “图像 URI”

# 创建自定义容器预测模型
模型 = aiplatform.Model.upload(
显示名称=模型名称，
serving_container_image_uri=container_image_uri，
 ）

print (“现在部署模型”)
尝试：
  # 部署模型
  端点 = model.deploy(machine_type=&quot;n1-standard-4&quot;)
  打印（端点）
除了异常 e：
  print(f“部署模型时出错：{e}”)

我还尝试运行已部署的 docker 映像，并且其运行没有任何错误，只是我无法部署端点
有人可以帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/77266349/how-to-deploy-custom-container-in-vertex-ai-as-endpoint</guid>
      <pubDate>Tue, 10 Oct 2023 13:43:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 OpenCV 和 Mediapipe 实现逼真的唇色变化？</title>
      <link>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</guid>
      <pubDate>Mon, 20 Mar 2023 17:50:46 GMT</pubDate>
    </item>
    <item>
      <title>生成算法和判别算法有什么区别？ [关闭]</title>
      <link>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</link>
      <description><![CDATA[生成式和生成式有什么区别
判别算法？]]></description>
      <guid>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</guid>
      <pubDate>Mon, 18 May 2009 19:44:45 GMT</pubDate>
    </item>
    </channel>
</rss>