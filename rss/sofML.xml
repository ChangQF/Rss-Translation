<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 21 Mar 2024 06:17:48 GMT</lastBuildDate>
    <item>
      <title>无法解决这个机器训练模型</title>
      <link>https://stackoverflow.com/questions/78197623/unable-to-solve-this-machine-training-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78197623/unable-to-solve-this-machine-training-model</guid>
      <pubDate>Thu, 21 Mar 2024 05:02:49 GMT</pubDate>
    </item>
    <item>
      <title>是否有任何内置的 .Net 软件包或工具可以根据匹配的个人资料数据获取用户推荐？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78197605/is-there-any-inbuilt-net-package-or-tool-to-get-user-recommendation-based-on-th</link>
      <description><![CDATA[我有用户及其个人资料信息，例如他们的兴趣、喜欢、不喜欢等。我想获得有关个人资料信息与当前用户匹配的用户的推荐。需要任何 nuget 包、.Net 代码或任何其他开源在线服务。我使用余弦相似度来查找 1 个用户的个人资料与所有其他用户的个人资料之间的匹配，并在 python 中获取矩阵。]]></description>
      <guid>https://stackoverflow.com/questions/78197605/is-there-any-inbuilt-net-package-or-tool-to-get-user-recommendation-based-on-th</guid>
      <pubDate>Thu, 21 Mar 2024 04:57:39 GMT</pubDate>
    </item>
    <item>
      <title>我在使用tensorflow优化器参数时遇到的值错误问题</title>
      <link>https://stackoverflow.com/questions/78197496/value-error-problem-i-encountered-with-tensorflow-optimizer-parameter</link>
      <description><![CDATA[使用tensorflow的值错误问题
在构建神经网络时，我的张量流代码的一部分出现了问题：错误是
ValueError：无法识别参数：{&#39;lr&#39;：0.001}

我的代码引用的部分是：
model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer=keras.optimizer.Adam(lr=0.001),metrics=[“accuracy”],)

请问有什么想法吗？
导入所需模型后（遵循tensorflow教程）
比如
&lt;前&gt;&lt;代码&gt;keras;同样来自tensorflow.keras的层和模型，以及来自tensorflow.keras.daraset的mnist

我设置模型等于
keras.sequential....
模型.编译...
型号.适合...
模型.评估.

毕竟，我没有得到我在代码中定义的训练和测试数据集的准确性，而是得到了值错误]]></description>
      <guid>https://stackoverflow.com/questions/78197496/value-error-problem-i-encountered-with-tensorflow-optimizer-parameter</guid>
      <pubDate>Thu, 21 Mar 2024 04:11:20 GMT</pubDate>
    </item>
    <item>
      <title>机器学习：以连续数组作为输入、以标量分类变量作为输出的分类技术</title>
      <link>https://stackoverflow.com/questions/78197199/machine-learning-classification-techniques-for-continuous-arrays-as-inputs-and</link>
      <description><![CDATA[如果您对以下内容有任何想法，那就太好了。
假设对于给定的数据集：T 和 Y 是数组，其中 T = [0 1 2 3 5 6 7] Y= [4 7 9 3 6 1] 所以在 T=0 时，Y=4 依此类推 Z = [红色] Z 中只有一个元素。T 和 Y 是连续输入。 Z 离散（可以是红色或黄色）。
另一个给定集合：T = [1 3 4 9 3] Y= [4 9 2 1 6] Z=[黄色]
假设我有很多相似的集合，我可以使用什么分类技术来探索以 T 和 Y 作为连续数组输入并输出单个元素的分类 Z 的关系？
我有点困惑，因为输入本身是数组，而输出只是一个元素]]></description>
      <guid>https://stackoverflow.com/questions/78197199/machine-learning-classification-techniques-for-continuous-arrays-as-inputs-and</guid>
      <pubDate>Thu, 21 Mar 2024 02:22:00 GMT</pubDate>
    </item>
    <item>
      <title>测试精度大于 1，并且一开始就非常高</title>
      <link>https://stackoverflow.com/questions/78197173/testing-accuracy-is-greater-than-1-and-starts-off-very-high</link>
      <description><![CDATA[问题在于，在测试循环中打印时，正确的样本多于样本总数。训练函数正常计算精度，但测试函数始终以 1.1-1.3 的精度开始。此外，这两种准确性一开始都非常高，然后就会下降。
这是我的数据准备
def preprocess_function（示例）：
        返回分词器（示例[“句子”]，
                         填充=“最大长度”，
                         截断=真，
                         最大长度=模型最大长度）
    
    tokenized_datasets = dataset.map(preprocess_function,batched=True)
    tokenized_datasets = tokenized_datasets.remove_columns([“sentence”, “idx”, “attention_mask”])
    tokenized_datasets = tokenized_datasets.rename_column(“标签”, “标签”)
    tokenized_datasets.set_format(“火炬”)

    train_dataset = tokenized_datasets[“train”].shuffle(seed=SEED)
    valid_dataset = tokenized_datasets[“验证”].shuffle(seed=SEED)

    data_collat​​or = DataCollat​​orForLanguageModeling（
        分词器=分词器，
        传销=真实，
        MLM_概率=0.15
    ）

    class_count = [sum(train_dataset[&#39;labels&#39;] == label) 范围内的标签 (NUM_LABELS)]
    class_weights = 1. / torch.tensor(class_count, dtype=torch.float)

    class_weights_all = class_weights[train_dataset[&#39;labels&#39;]]

    加权采样器 = 加权随机采样器（
        权重=class_weights_all，
        num_samples= len(class_weights_all),
        替换=假
    ）

    train_dataloader = 数据加载器(
        训练数据集，
        collat​​e_fn=data_collat​​or,
        批量大小=批量大小，
        采样器=加权采样器，
        pin_memory=真
    ）

    valid_dataloader = 数据加载器(
        有效数据集，
        collat​​e_fn=data_collat​​or,
        批量大小=批量大小，
        pin_memory=真
    ）

这是我的训练和测试循环：
def train_loop(模型,
               训练数据加载器，
               优化器，
               lr_调度程序，
               设备）：
    模型.train()
    总损失= 0
    总正确率 = 0
    样本总数 = 0
    计数器 = 0
    对于步骤，批量枚举（tqdm（train_dataloader））：
        如果计数器 &gt;= 100：
            休息

        batch = {k: v.to(DEVICE) for k, v in batch.items()}

        输出=模型（**批次）
        logits = 输出.logits
        预测 = torch.argmax(logits[:, 8:], -1)
        # print(预测, 预测.size(), len(预测))

        标签=批次[&#39;标签&#39;]
        # print(标签, labels.size(), len(标签))
        正确 = (预测 == 标签).sum().item()
        总正确率 += 正确率
        样本总数 += labels.size(0)

        损失 = 输出.损失
        总损失 += loss.detach()

        # loss.requires_grad = True
        loss.backward()
        优化器.step()
        lr_scheduler.step()
        优化器.zero_grad()

        计数器 += 1

    如果total_samples &gt; 则准确度=total_ Correct /total_samples 0 否则 0
    返回总损失、准确率

def test_loop(模型,
              有效数据加载器，
              设备）：
    模型.eval()
    评估损失 = 0
    总正确率 = 0
    样本总数 = 0
    对于步骤，批量枚举（tqdm（valid_dataloader））：
        batch = {k: v.to(DEVICE) for k, v in batch.items()}

        使用 torch.no_grad()：
            输出=模型（**批次）

        logits = 输出.logits
        预测 = torch.argmax(logits[:, 8:], -1)

        标签=批次[&#39;标签&#39;]
        正确 = (预测 == 标签).sum().item() # 错误行
        总正确率 += 正确率
        样本总数 += labels.size(0)
        print(&quot;正确总数：&quot; + str(total_ Correct) + &quot; ||| 样本总数：&quot; + str(total_samples))

        损失 = 输出.损失
        eval_loss += loss.detach()

    如果total_samples &gt; eval_accuracy =total_ Correct /total_samples 0 否则 0
    返回 eval_loss、eval_accuracy

我想我现在只是没有看到一些东西。我是否使用了相同的变量？]]></description>
      <guid>https://stackoverflow.com/questions/78197173/testing-accuracy-is-greater-than-1-and-starts-off-very-high</guid>
      <pubDate>Thu, 21 Mar 2024 02:12:15 GMT</pubDate>
    </item>
    <item>
      <title>如何修复“TypeError：'BatchEncoding'对象不是迭代器”错误</title>
      <link>https://stackoverflow.com/questions/78197130/how-can-i-fix-a-typeerror-batchencoding-object-is-not-an-iterator-error</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78197130/how-can-i-fix-a-typeerror-batchencoding-object-is-not-an-iterator-error</guid>
      <pubDate>Thu, 21 Mar 2024 01:55:18 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 矩阵乘法形状错误：“RuntimeError：mat1 和 mat2 形状无法相乘”</title>
      <link>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</link>
      <description><![CDATA[我是 PyTorch 的新手，正在创建一个多输出线性回归模型，根据字母为单词着色。 （这将帮助有字素颜色联觉的人更轻松地阅读。）它接收单词并输出 RGB 值。每个单词都表示为 45 个浮点数 [0,1] 的向量，其中 (0, 1] 代表字母，0 代表该位置不存在字母。每个样本的输出应该是一个向量 [r-value, g -值，b-值]。
我懂了
&lt;块引用&gt;
运行时错误：mat1 和 mat2 形状无法相乘（90x1 和 45x3）

当我尝试在训练循环中运行我的模型时。
查看现有的 Stack Overflow 帖子，我认为这意味着我需要重塑我的数据，但我不知道如何/在哪里以解决此问题的方式进行此操作。特别是考虑到我不知道那个 90x1 矩阵来自哪里。
我的模型
我一开始很简单；在我可以让单个层发挥作用之后，可以出现多个层。
类 ColorPredictor(torch.nn.Module):
    #构造函数
    def __init__(自身):
        super(ColorPredictor, self).__init__()
        self.linear = torch.nn.Linear(45, 3, device= device) #编码词向量的长度 &amp; r,g,b 向量的大小
        
    ＃ 预言
    defforward(self, x: torch.Tensor) -&gt;;火炬.张量：
        y_pred = self.线性(x)
        返回 y_pred

我如何加载数据
# 数据集类
数据类（数据集）：
    # 构造函数
    def __init__(自身，输入，输出)：
        self.x = input # 编码词向量列表
        self.y = 输出 # 将 r、g、b 值转换为火炬张量的 Pandas 数据帧
        self.len = len(输入)
    
    # 吸气剂
    def __getitem__(自身，索引)：
        返回 self.x[索引], self.y[索引]
    
    # 获取样本数
    def __len__(自身):
        返回 self.len

# 创建训练/测试分割
train_size = int(0.8 * len(数据))
train_data = 数据(输入[:train_size], 输出[:train_size])
test_data = 数据(输入[train_size:], 输出[train_size:])

# 为训练和测试集创建 DataLoaders
train_loader = DataLoader（数据集= train_data，batch_size = 2）
test_loader = DataLoader（数据集= test_data，batch_size = 2）

发生错误的测试循环
对于范围内的纪元（纪元）：
    ＃ 火车
    model.train() #训练模式
    对于 train_loader 中的 x,y：
        y_pred = model(x) #此处错误
        损失=标准(y_pred, y)
        优化器.zero_grad()
        loss.backward()
        优化器.step()
      

错误回溯

]]></description>
      <guid>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</guid>
      <pubDate>Thu, 21 Mar 2024 01:00:23 GMT</pubDate>
    </item>
    <item>
      <title>为什么线性回归的纯 NumPy 实现的学习率优化如此无效？</title>
      <link>https://stackoverflow.com/questions/78196911/why-is-learning-rate-optimization-to-pure-numpy-implementation-of-linear-regress</link>
      <description><![CDATA[在 numpy 中创建简单的线性回归模型后，我发现改变步长/学习率并不能有效提高模型的准确性或收敛速度。请注意给出此标准模型：
&lt;代码&gt;
％％时间

x = np.arange(100)
y = 3 * x + 5
x = np.column_stack((np.ones(100), x))

w = np.zeros((100, 2))
步长=10**-4
迭代次数 = 10**5

对于范围内的 i（迭代）：
    损失 = 2 * (np.sum(w * x, axis=1) - y)
    w -= step_size * np.average(x * loss[:, None], axis=0)

打印（w[0]）

模型提供以下输出：
&lt;前&gt;&lt;代码&gt;[4.60820653 3.00590689]
CPU时间：用户5.04秒，系统：19.9毫秒，总计：5.06秒
挂壁时间：5.07 秒


更改step_size变量可以被视为超参数优化，但是当将其更改为大于10-4（例如10-3）时，模型无法收敛并爆炸：
&lt;前&gt;&lt;代码&gt;#step_size = 10**-3
[楠楠]
CPU时间：用户4.98秒，系统：38.2毫秒，总计：5.02秒
挂壁时间：5秒

这种行为在数学上是可以预料到的，但遇到这种情况却令人沮丧，并引出了一个问题：如何更有效地优化步长？
&lt;小时/&gt;
我尝试更改与梯度相关的系数（我将梯度变量标记为“损失”），而不是更改步长，因为这也会影响每个步骤的戏剧性（据我所知）给定更大或更小的损失，因此下降的梯度更陡。令人惊讶的是，将损失系数从 2 更改为 5 显着提高了性能（这正是我所做的，而不是优化步长，但我想这是一个单独的主题）。
# 将损耗系数从 2 更改为 5
[4.99998468 3.00000023]
CPU时间：用户5.03秒，系统：42.7毫秒，总计：5.07秒
挂壁时间：5.08 秒
]]></description>
      <guid>https://stackoverflow.com/questions/78196911/why-is-learning-rate-optimization-to-pure-numpy-implementation-of-linear-regress</guid>
      <pubDate>Thu, 21 Mar 2024 00:26:12 GMT</pubDate>
    </item>
    <item>
      <title>如何更改基于 Llama 2 的模型的默认嵌入向量大小？</title>
      <link>https://stackoverflow.com/questions/78196744/how-to-change-default-embedding-vector-size-of-a-llama-2-based-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78196744/how-to-change-default-embedding-vector-size-of-a-llama-2-based-model</guid>
      <pubDate>Wed, 20 Mar 2024 23:26:36 GMT</pubDate>
    </item>
    <item>
      <title>有人在打开 gitbash 时遇到问题吗？我可能弄乱了我的环境变量，然后它不允许它打开任何可以修复它的想法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78196727/is-anyone-had-issues-opening-gitbash-i-might-have-messed-up-my-environment-varia</link>
      <description><![CDATA[我能够打开 gitbash 及其所有文件，并且我需要它才能打开，但它已正确安装。
仍然无法打开我已经使用了任务管理器，建议使用其他一些方法来查看我是否可以更新程序，我有最新版本，我弄乱了我的环境变量，所以可能有人可以帮忙吗？
任务管理器、Winget 键命令提示符、管理员运行应用程序]]></description>
      <guid>https://stackoverflow.com/questions/78196727/is-anyone-had-issues-opening-gitbash-i-might-have-messed-up-my-environment-varia</guid>
      <pubDate>Wed, 20 Mar 2024 23:22:20 GMT</pubDate>
    </item>
    <item>
      <title>vercel：错误：上传文件的大小超过 300MB</title>
      <link>https://stackoverflow.com/questions/78196675/vercel-error-size-of-uploaded-file-exceeds-300mb</link>
      <description><![CDATA[我正在尝试部署一个使用 Deepface.analyze 函数的基本 python 应用程序。尝试在 Vercel 上部署应用程序时，出现此错误：
上传文件大小超过300MB

是因为像deepFace和tensorflow这样的大型库吗？还是因为我的代码结构？
我有一个具有以下结构的基本 python Flask 应用程序：
&lt;前&gt;&lt;代码&gt;静态
--样式.css
模板
--index.html
应用程序.py
要求.txt
]]></description>
      <guid>https://stackoverflow.com/questions/78196675/vercel-error-size-of-uploaded-file-exceeds-300mb</guid>
      <pubDate>Wed, 20 Mar 2024 23:05:34 GMT</pubDate>
    </item>
    <item>
      <title>层顺序从未被调用，因此没有定义的输入</title>
      <link>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</link>
      <description><![CDATA[我的简单脚本给了我这个错误：
从 deepface 导入 DeepFace

face_analysis = DeepFace.analyze(img_path = “face3.jpeg”, model_name = “Facenet”)
打印（面部分析）

层顺序从未被调用，因此没有定义的输入

Deepface版本：0.0.87
张量流
版本：2.16.1]]></description>
      <guid>https://stackoverflow.com/questions/78196623/the-layer-sequential-has-never-been-called-and-thus-has-no-defined-input</guid>
      <pubDate>Wed, 20 Mar 2024 22:50:10 GMT</pubDate>
    </item>
    <item>
      <title>启动 ML 项目指南</title>
      <link>https://stackoverflow.com/questions/78196528/guide-to-starting-a-ml-project</link>
      <description><![CDATA[我正在致力于创建机器学习模型，学习如何将传入电子邮件分类到文件夹中，主要重点是模型必须自主学习，而无需了解电子邮件习惯，并且随着时间的推移，可以更好地进行分类。
有关如何启动此项目的任何提示、视频、链接、知识以及如何创建此自主分类的策略？ （我正在使用安然语料库数据集）。
在启动项目时需要帮助]]></description>
      <guid>https://stackoverflow.com/questions/78196528/guide-to-starting-a-ml-project</guid>
      <pubDate>Wed, 20 Mar 2024 22:20:07 GMT</pubDate>
    </item>
    <item>
      <title>快速文本嵌入以进行逻辑回归</title>
      <link>https://stackoverflow.com/questions/78196310/fasttext-embeddings-in-order-to-do-logistic-regression</link>
      <description><![CDATA[我想进行嵌入，然后进行逻辑回归。输出数据是这些
&lt;预&gt;&lt;代码&gt;0 [[-0.00034277988, 0.0013405628, -1.998733e-05,...
1 [[0.00075779966, -0.00025276924, 0.0009634475,...
2 [[-0.0032675266, -0.0015163509, 0.0051634307, ...
3 [[0.0006605284，-0.0040500723，0.0041460698，-...
                              ...
第4774章 [[0.0005923094, -0.00194318, 0.0015639212, 0.0...
第4775章 [[-0.002365636, 0.0023984204, -0.0004855222, -...
第4776章 [[-0.0028686645, 0.0019738101, 0.0037081288, 0...
第4777章 [[0.0024941873, -0.0019521558, -0.0019918315, ...
名称：推文，长度：4779，dtype：对象

但是为了进行回归，我需要它们为数字类型，因此我需要将每个数字放在不同的列上：[4778 行 x 768 列]
我的fasttext代码是这样的。我不知道更改 fasttext 代码是否更好，还是在准备好嵌入后进行更改
df = pd.read_csv(&#39;OGTDv1.csv&#39;)

Sentence = [word_tokenize(rev.lower()) for rev in df.Tweet.to_string(index=False)]
模型= FastText（句子，vector_size = 128，窗口= 5，min_count = 3，工人= 4，纪元= 10，种子= 42）
model.save(&#39;tokped_review.ft&#39;)

ftext = 模型.wv

def get_sentence_embeddings(句子, 模型):
    标记 = word_tokenize(sentence.lower())
    embeddings = [model.wv[token] for tokens in tokens if token in model.wv]
    返回嵌入

df_emb = df[&#39;Tweet&#39;].apply(lambda x: get_sentence_embeddings(x, model))


打印（df_emb）
df_emb.to_pickle(&#39;ToxicityFastText_Embeddings.pkl&#39;)```
]]></description>
      <guid>https://stackoverflow.com/questions/78196310/fasttext-embeddings-in-order-to-do-logistic-regression</guid>
      <pubDate>Wed, 20 Mar 2024 21:24:02 GMT</pubDate>
    </item>
    <item>
      <title>确定 RTX 4090 上训练性能不佳的原因</title>
      <link>https://stackoverflow.com/questions/78192841/identifying-the-cause-of-poor-training-performance-on-rtx-4090</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78192841/identifying-the-cause-of-poor-training-performance-on-rtx-4090</guid>
      <pubDate>Wed, 20 Mar 2024 11:16:15 GMT</pubDate>
    </item>
    </channel>
</rss>