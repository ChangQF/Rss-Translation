<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 05 Aug 2024 15:16:18 GMT</lastBuildDate>
    <item>
      <title>深度学习中使用拓扑数据分析的示例</title>
      <link>https://stackoverflow.com/questions/78834875/example-of-using-topological-data-analysis-in-deep-learning</link>
      <description><![CDATA[以下是论文：Daniel Leykam 和 Dimitris G. Angelakis，拓扑数据分析和机器学习。
我想要一些在深度学习模型中使用和实现拓扑数据分析的示例、教程和源代码。
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78834875/example-of-using-topological-data-analysis-in-deep-learning</guid>
      <pubDate>Mon, 05 Aug 2024 14:13:42 GMT</pubDate>
    </item>
    <item>
      <title>一维变分自动编码器重构不佳</title>
      <link>https://stackoverflow.com/questions/78834575/bad-reconstruction-of-1-d-variational-autoencoder</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78834575/bad-reconstruction-of-1-d-variational-autoencoder</guid>
      <pubDate>Mon, 05 Aug 2024 13:03:53 GMT</pubDate>
    </item>
    <item>
      <title>yolov9 在自定义数据上进行训练</title>
      <link>https://stackoverflow.com/questions/78834445/yolov9-training-on-custom-data</link>
      <description><![CDATA[各位。我正在尝试在 PyCharm 上用一些自定义数据训练 yolov9，而不是像我看过的许多教程所建议的那样使用 google colab。我该怎么做？
将存储库克隆到我的计算机后，我在虚拟环境中安装了所有必需的软件。然后我创建了训练脚本，但我觉得有些短。
这是我的训练脚本：
import os
import subprocess

dataset_path = &#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject&#39;

def train_yolov5(train_images_path, val_images_path, yaml_file_path, weights_path=&#39;C:/Users/rsingh/Desktop/Musa_PDC/yolov9-main/yolov9-c.pt&#39;, epochs=50):

# 获取 yolov5 目录的绝对路径
yolov9_dir = os.path.abspath(&#39;C:/Users/rsingh/Desktop/Musa_PDC/yolov9-main&#39;)

# 更改当前工作目录到 yolov9 目录
os.chdir(yolov9_dir)
# 训练 yolov9 模型
command = f&#39;python train.py --workers 8 --device cpu --batch 16 --data {dataset_path}/sfdV2_musa.yaml --img 640 --cfg models/detect/yolov9-c.yaml --weights yolov9-c --hyp hyp.scratch-high.yaml --min-items 0 --epochs 5 --close-mosaic 15&#39;

# 执行命令
process = subprocess.Popen(command, shell=True)
process.wait()

if __name__ == &quot;__main__&quot;:
TRAIN_IMAGES_PATH = (
&#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject/captured_images/images/train&#39;)
VAL_IMAGES_PATH = (
&#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject/captured_images/images/val&#39;)
YAML_FILE_PATH = (
&#39;C:/Users/rsingh/Desktop/Rahul_PDC/Repositories/Smart_Factory/YoloV5_Training/sfd_colorobject/sfdV2_musa.yaml&#39;)

# 训练 YOLOv9 模型
train_yolov5(TRAIN_IMAGES_PATH, VAL_IMAGES_PATH、YAML_FILE_PATH）`
]]></description>
      <guid>https://stackoverflow.com/questions/78834445/yolov9-training-on-custom-data</guid>
      <pubDate>Mon, 05 Aug 2024 12:28:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 GAN 生成医学图像</title>
      <link>https://stackoverflow.com/questions/78834126/medical-image-generation-using-gans</link>
      <description><![CDATA[我正在使用 gans 生成合成 ct 扫描图像以用于我的分割任务。我有一个包含 75 张 PNG 图像的数据集，我想生成合成图像。
这是我使用的代码，但我没有得到正确的输出。[在此处输入图像描述](https://i.sstatic.net/82rfdq8T.png)
是否有可用的在线代码或资源可以做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78834126/medical-image-generation-using-gans</guid>
      <pubDate>Mon, 05 Aug 2024 11:07:41 GMT</pubDate>
    </item>
    <item>
      <title>如何在一个短语中组合两个函数机器学习sklearn</title>
      <link>https://stackoverflow.com/questions/78833739/how-to-combine-2-functions-in-one-phrase-machine-learning-sklearn</link>
      <description><![CDATA[我有一个 data_set，用于存储助手对我的问题/任务的回答
data_set = { &#39;whats new&#39;:&#39;passive 没什么特别的...&#39;, &#39;&#39;:&#39;&#39;, }

passive - 与机器人的简单对话中的存根。
助手可以同时执行 2 个功能吗？例如，打开浏览器和游戏的功能。
也就是说，我希望它看起来像这样：
data_set = { &#39;whats new&#39;:&#39;game browser 没什么特别的...&#39;, &#39;&#39;:&#39;&#39;, }

def game():
pass
def browser():
pass

我希望我的助手在一个短语中同时执行 2 个功能]]></description>
      <guid>https://stackoverflow.com/questions/78833739/how-to-combine-2-functions-in-one-phrase-machine-learning-sklearn</guid>
      <pubDate>Mon, 05 Aug 2024 09:28:05 GMT</pubDate>
    </item>
    <item>
      <title>如何保存 TensorFlow 模型并在不同的文件中使用它？</title>
      <link>https://stackoverflow.com/questions/78833727/how-to-save-a-tensorflow-model-and-use-it-in-a-different-file</link>
      <description><![CDATA[我想保存我训练过的模型并将其加载到另一个文件中。
我尝试使用
model.save(my_model.keras)
但当我将其加载到另一个文件中或在运行时断开连接后加载它时（Colab 笔记本），它不起作用。有人可以建议不同的方法或解释我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78833727/how-to-save-a-tensorflow-model-and-use-it-in-a-different-file</guid>
      <pubDate>Mon, 05 Aug 2024 09:24:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 ML 检测二进制斑点中的文本</title>
      <link>https://stackoverflow.com/questions/78833072/detecting-text-in-binary-blobs-using-ml</link>
      <description><![CDATA[上下文 - 我是一名经验丰富的 SWE，但在 ML 方面经验不多，我想执行以下操作：
给定一个大小为 256 的二进制 blob（字节数组），由嵌入有意义文本的随机字节组成，我想用 Python 编写一个可以检测所述文本的 ML 操作。
到目前为止，我已经使用了以下功能/标签：

字节值/预期文本
字节是否为 utf8/blob 中文本的开始/结束位置
每个字节前/后 N 个字节中 utf8 的字节数/偏移量 + 文本长度
我还尝试了几个分类器，包括 SVR 和 NN，但结果非常令人失望。欢迎提出任何想法。

带有预期文本“翻译 NLP”的示例 blob python&quot;

DEC776ADF283C633EFD77472616E736C6174696F6E204E4C5020707974686F6E0B8B520125C98845BC3C4830190ABDE803578AAB59C17F5444887672B7F4405B9167D23EE9893D5415981DF3F6BF06663DDADDFD921F3F7F7EE6C36E0050ED6B8332FAD95CB88CD1AAA33216445FD28384E1E03CB3E3192A78C310CAD18 292D93B727BA73A31AB60A93A4651B7AD8F921CC0055BD4BCE531536D38019C5DA076B66E922FDC76954B32E04FF9F94B9150AC7A20472194DA4CEE348F9115707FEC6 CCD79AC4 6DA94FE489D521A093045BC1929CAD5B77D88C66B86249006FF2FF83358E8E112E1390B4D02461603612BC9EC772A34B63B7FDB5743FD951337AF8B

在十六进制工作室中它看起来像这样：
]]></description>
      <guid>https://stackoverflow.com/questions/78833072/detecting-text-in-binary-blobs-using-ml</guid>
      <pubDate>Mon, 05 Aug 2024 06:46:19 GMT</pubDate>
    </item>
    <item>
      <title>用于聚类的机器学习模型（与 K-means 类似，但功能不同）[关闭]</title>
      <link>https://stackoverflow.com/questions/78833002/machine-leraning-model-for-clusteringsimilar-with-k-means-but-different-functio</link>
      <description><![CDATA[当我研究几种机器学习模型时，
我看到了几种聚类算法，包括 K-Means。
据我所知，K-Means 使用欧几里得距离作为自己的计算方法，
我想要的不是使用欧几里得距离，而是数据的值。
例如，样本分布很广（如坐标），坐标有自己的值。
我想找到平均值较高的 N 个聚类。
有没有其他适合此图的算法，或者我是否只处理 K-Means 算法中的几个参数即可完成此操作。
谢谢
有没有其他适合此图的算法，或者我是否只处理 K-Means 算法中的几个参数即可完成此操作。]]></description>
      <guid>https://stackoverflow.com/questions/78833002/machine-leraning-model-for-clusteringsimilar-with-k-means-but-different-functio</guid>
      <pubDate>Mon, 05 Aug 2024 06:18:22 GMT</pubDate>
    </item>
    <item>
      <title>createDataPartition 给出异常不均匀的测试和训练集</title>
      <link>https://stackoverflow.com/questions/78832537/createdatapartition-gives-abnormally-uneven-test-and-train-sets</link>
      <description><![CDATA[我正在尝试使用 caret 包将我的数据拆分为测试集和训练集。我有 77 行，每列都有完整数据。函数“createDataPartition”导致训练数据为 4 行，测试数据为 73 行，这似乎不对。任何帮助都将不胜感激。这是我的代码：
&gt; # 将数据拆分为训练和测试
&gt; set.seed(123)
&gt; data.full &lt;- data.full %&gt;% select(fasting_status, a1c, glu, uc_ratio)
&gt; training.samples &lt;- data.full %&gt;% 
+ createDataPartition(p = 0.8, list = FALSE)
警告消息：
1：在 createDataPartition(., p = 0.8, list = FALSE) 中：
某些类没有记录 ( )，这些将被忽略
2：在 createDataPartition(., p = 0.8, list = FALSE) 中：
某些类只有一条记录 ( )，这些将被选为样本
&gt; train.data &lt;- data.full[training.samples, ]
&gt; test.data &lt;- data.full[-training.samples, ] ```

这是我的可重现数据：

```&gt; dput(data.full) 结构(列表(fasting_status = 结构(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L、1L、1L、1L、1L、1L、1L、1L、1L、1L、1L、1L、1L、2L、2L、2L、2L、2L、2L、2L、2L、2L、2L、2L、2L、2L、2L、2L、2L、 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L), 级别 = c(&quot;1&quot;, &quot;2&quot;), 类别 = &quot;因素&quot;), 
a1c = c(4.3, 4.5, 4.4, 2.9, 4.3, 4.4, 4.2, 4.5, 4.2, 4.2, 
4.5, 4.5, 4.8, 4.5, 5.2, 4.9, 4.6, 4.2, 4.4, 4.9, 4.6, 4.5, 
    4.4、4.8、4.5、4.1、3.8、3.1、4.3、4.6、4.7、4.9、4.6、4.4、3.1、4.6、4.4、4.2、4.4、5.2、4.4、5.1、4.6、4.7、5.2、4.7、4。 7、4.6、4.4、4.4、4.2、4.5、4.6、4.4、3.2、4.8、5.2、5.2、4.6、4.9、5.6、4.6、4.9、4.5、5.1、4.6、4.9、4.6、4.3、4.6、
4.6, 4.3, 4.6, 4.3, 4.6, 6.5, 4.8), glu = c(88.5, 98, 117.5, 
53, 108.5, 106, 105, 101, 91, 99.5, 128.5, 113, 114, 121.5, 
121, 131.5, 160.5, 96, 110, 140, 119.5, 115.3, 112, 143.5, 
116.5, 116.5, 111, 139.5, 123.5, 131, 113, 137, 114, 98.5, 
    124.5、123.5、111.5、111、127、123、137.5、119、107、130.5、142.5、115、133.5、119、148.3、125.5、138.5、106.5、153.5、 .5、179、145、143、124.5、134、146.5、127.5、124.5、123、129、145.3、125.5、146.5、153.5、115.5、128、110.5、131、 
139.5, 124, 154, 94, 76.3), uc_ratio = c(30.65603924, 15.32801962, 
60.59075991, 7.39973361, 57.84661317, 27.46781116, 16.0944206, 
6.131207848, 94.61568474, 19.50838861, 7.803355443, 19.41549152, 
7.464079119, 19.67095851, 29.50643777, 62.94706724, 80.472103、25.75107296、73.57449418、39.01677721、41.13018598、10.62933697、7.803355443、30.04291845、32.75355771、 9416、5.969860273、22.72153497、7.153075823、75.61823012、23.50296342、53.64806867、11.19611891、38.25340549、 88.36152487、51.50214592、9.196811772、41.98544505、6.35828962、9.196811772、94.87237407、12.87553648、6.035407725、7.3997 3361、10.72961373、11.70503316、9.035464197、16.34988759、11.68917269、35.11509949、61.85306741、11.36076748、 
    12.2624157、7.153075823、14.30615165、10.40447392、3.901677721、52.11526671、21.45922747、30.49469166、81.06819266、 38861、34.33476395、8.0472103、24.94635193、9.754194304、64.3776824、9.196811772、11.92179304、34.87124464、 74.39198856, 124.4635193, 
13.79521766, 5.722460658, 66.76204101, 69.9757432, 19.50838861
)), row.names = c(NA, -77L), class = &quot;data.frame&quot;)```
]]></description>
      <guid>https://stackoverflow.com/questions/78832537/createdatapartition-gives-abnormally-uneven-test-and-train-sets</guid>
      <pubDate>Mon, 05 Aug 2024 02:29:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 NLP 的 MLP 与 Transformer 架构</title>
      <link>https://stackoverflow.com/questions/78832485/mlp-vs-transformer-architecture-for-nlp</link>
      <description><![CDATA[我不太明白在 NLP 中使用经典 MLP 与自注意力转换器之间的区别。自注意力转换器能做什么而 MLP 不能？它与仅仅添加更多隐藏层有何不同？我理解发送键和查询然后创建注意力权重的要点，但对我来说，直觉上（我知道我错了），这似乎是一种额外的抽象，可以做 MLP 用更多隐藏层可以做的事情。转换器修复了 MLP 的 NLP 架构的哪些根本问题？]]></description>
      <guid>https://stackoverflow.com/questions/78832485/mlp-vs-transformer-architecture-for-nlp</guid>
      <pubDate>Mon, 05 Aug 2024 01:51:18 GMT</pubDate>
    </item>
    <item>
      <title>生成 512x512 照片的模型</title>
      <link>https://stackoverflow.com/questions/78831225/model-to-generate-512x512-photos</link>
      <description><![CDATA[我如何让这个模型生成 512x512 像素或更大的图像？现在它生成 64x64 像素的图像。我尝试更改模型中的某些值，但没有成功。这些卷积层如何工作，尤其是 Conv2D 和 Conv2DTranspose？我不明白图像在这些层中是如何调整大小的。
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layer
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt

cd /content/drive/MyDrive

dataset = keras.preprocessing.image_dataset_from_directory(
directory = &#39;Humans&#39;, label_mode = None, image_size = (64,64), batch_size = 32,
shuffle = True
).map(lambda x: x/255.0)

discriminator = keras.models.Sequential(
[
keras.Input(shape = (64,64,3)),
layer.Conv2D(64, kernel_size = 4, strides = 2, padding = &#39;相同&#39;),
layers.LeakyReLU(0.2),
layers.Conv2D(128, kernel_size = 4, strides = 2, padding = &#39;相同&#39;),
layers.LeakyReLU(0.2),
layers.Conv2D(128, kernel_size = 4, strides = 2, padding = &#39;相同&#39;),
layers.LeakyReLU(0.2),
layers.Flatten(),
layers.Dropout(0.2),
layers.Dense(1,activation = &#39;sigmoid&#39;)
]
)

latent_dim = 128
generator = keras.models.Sequential(
[
layers.Input(shape = (latent_dim,)),
layers.Dense(8*8*128),
layers.Reshape((8,8,128)),
layers.Conv2DTranspose(128, kernel_size = 4, strides = 2, padding = &#39;same&#39;),
layers.LeakyReLU(0.2),
layers.Conv2DTranspose(256, kernel_size = 4, strides = 2, padding = &#39;same&#39;),
layers.LeakyReLU(0.2),
layers.Conv2DTranspose(512, kernel_size = 4, strides = 2, padding = &#39;same&#39;),
layers.LeakyReLU(0.2),
layers.Conv2D(3, kernel_size = 5,padding = &#39;same&#39;,activation = &#39;sigmoid&#39;)
]
)

opt_gen = keras.optimizers.Adam(1e-4)
opt_disc = keras.optimizers.Adam(1e-4)
loss_fn = keras.losses.BinaryCrossentropy()

for epoch 在 range(500) 中：
对于 idx，real 在 enumerate(tqdm(dataset)) 中：
batch_size = real.shape[0]
random_latent_vectors = tf.random.normal(shape = (batch_size,latent_dim))
fake = generator(random_latent_vectors)

如果 idx % 50 == 0：
img = keras.preprocessing.image.array_to_img(fake[0])
img.save(f&#39;gen_images/generated_img{epoch}_{idx}_.png&#39;)

使用 tf.GradientTape() 作为 disc_tape：
loss_disc_real = loss_fn(tf.ones((batch_size,1)), discriminator(real))
loss_disc_fake = loss_fn(tf.zeros(batch_size,1), discriminator(fake))
loss_disc = (loss_disc_real+loss_disc_fake)/2

grads = disc_tape.gradient(loss_disc, discriminator.trainable_weights)

opt_disc.apply_gradients(
zip(grads, discriminator.trainable_weights)
)

with tf.GradientTape() as gen_tape:
fake = generator(random_latent_vectors)
output = discriminator(fake)
loss_gen = loss_fn(tf.ones(batch_size,1),output)

grads = gen_tape.gradient(loss_gen, generator.trainable_weights)
opt_gen.apply_gradients(
zip(grads, generator.trainable_weights)
)

我尝试更改图像大小和卷积层中的某些值，但它不起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78831225/model-to-generate-512x512-photos</guid>
      <pubDate>Sun, 04 Aug 2024 13:42:23 GMT</pubDate>
    </item>
    <item>
      <title>无法解决 QiskitMachineLearningError：'输入数据的形状不正确，最后一个维度不等于输入的数量：0，但得到：2'</title>
      <link>https://stackoverflow.com/questions/78828998/not-able-to-resolve-qiskitmachinelearningerror-input-data-has-incorrect-shape</link>
      <description><![CDATA[我收到错误：
32 vqc.fit(X_train, X_test)
33 
34 # 评估分类器

15 帧
/usr/local/lib/python3.10/dist-packages/qiskit_machine_learning/neural_networks/neural_network.py in _validate_input(self, input_data)
132 
133 if shape[-1] != self._num_inputs:
-&gt; 134 引发 QiskitMachineLearningError(
135 f&quot;输入数据的形状不正确，最后一个维度 &quot;
136 f&quot;不等于输入数量： &quot;

QiskitMachineLearningError：&#39;输入数据的形状不正确，最后一个维度不等于输入数量：0，但得到：2。&#39;

来自 qiskit 导入 QuantumCircuit、transpile、assemble
来自 qiskit_aer 导入 Aer
来自 qiskit_machine_learning.algorithms 导入 VQC
来自 qiskit_algorithms.optimizers 导入 COBYLA
来自 qiskit.circuit.library 导入 TwoLocal
来自 sklearn.preprocessing 导入 StandardScaler
来自 sklearn.model_selection 导入 train_test_split
导入 numpy 作为 np

# 用于演示目的的样本数据
# 将其替换为您的实际数据
scaled_data = np.random.rand(150, 2) # 用您的缩放数据替换
y = np.random.randint(0, 3, size=150) # 用您的标签替换

# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.3, random_state=42)

# 根据特征维度定义量子比特的数量
num_qubits = X_train.shape[1]

# 使用正确的参数定义量子特征图和 ansatz
feature_map = TwoLocal(num_qubits=num_qubits, entanglement=&#39;linear&#39;) #, rotation_blocks=[&#39;ry&#39;, &#39;rz&#39;], entanglement_gate=&#39;cz&#39;)
ansatz = TwoLocal(num_qubits=num_qubits, entanglement=&#39;linear&#39;)#, rotation_blocks=[&#39;ry&#39;, &#39;rz&#39;], entanglement_gate=&#39;cz&#39;)

# 定义优化器
optimizer = COBYLA()

# 使用唯一参数名称初始化 VQC 分类器
vqc = VQC(feature_map=feature_map, ansatz=ansatz, optimizer=optimizer)

# 训练量子分类器
vqc.fit(X_train, X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/78828998/not-able-to-resolve-qiskitmachinelearningerror-input-data-has-incorrect-shape</guid>
      <pubDate>Sat, 03 Aug 2024 14:52:35 GMT</pubDate>
    </item>
    <item>
      <title>对 GAN 输出大小的困惑</title>
      <link>https://stackoverflow.com/questions/78687394/confusion-about-output-sizes-of-gan</link>
      <description><![CDATA[我正在尝试理解代码，我对测试单元感到困惑。当我打印输出的形状时，它是 hidden_​​output.shape =(num_test, 20, 4, 4), test_hidden_​​block_stride(hidden_​​output).shape) == (num_test, 20, 10, 10) 和 Gen_output.shape=(num_test, 1,28,28)（对于 Mnist 数据集）。我试图理解这里的大小是如何计算的。任何帮助都将不胜感激！
class Generator(nn.Module):
def __init__(self, z_dim=10, im_chan=1, hidden_​​dim=64):
super(Generator, self).__init__()
self.z_dim = z_dim
# 构建神经网络
self.gen = nn.Sequential(
self.make_gen_block(z_dim, hidden_​​dim * 4),
self.make_gen_block(hidden_​​dim * 4, hidden_​​dim * 2, kernel_size=4, stride=1),
self.make_gen_block(hidden_​​dim * 2, hidden_​​dim),
self.make_gen_block(hidden_​​dim, im_chan, kernel_size=4, final_layer=True),
)
def make_gen_block(self, input_channels, output_channels, kernel_size=3, stride=2, padding=0 ,final_layer=False):
# 构建神经块
layer = []
layer.append(nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding, output_padding=padding))
if not final_layer:
layer.append(nn.BatchNorm2d(output_channels))
layer.append(nn.ReLU(True))
else:
layer.append(nn.Tanh())

return nn.Sequential(*layers)
# 测试
gen = Generator()
num_test = 100
# 测试隐藏块
test_hidden_​​noise = get_noise(num_test, gen.z_dim)
test_hidden_​​block = gen.make_gen_block(10, 20, kernel_size=4, stride=1)
test_uns_noise = gen.unsqueeze_noise(test_hidden_​​noise)
hidden_​​output = test_hidden_​​block(test_uns_noise)
# 检查它是否与其他 strides 兼容
test_hidden_​​block_stride = gen.make_gen_block(20, 20, kernel_size=4, stride=2)
test_final_noise = get_noise(num_test, gen.z_dim) * 20
test_final_block = gen.make_gen_block(10, 20, final_layer=True)
test_final_uns_noise = gen.unsqueeze_noise(test_final_noise)
final_output = test_final_block(test_final_uns_noise)
# 测试整个过程：
test_gen_noise = get_noise(num_test, gen.z_dim)
test_uns_gen_noise = gen.unsqueeze_noise(test_gen_noise)
gen_output = gen(test_uns_gen_noise)

我正在尝试手动计算公式中的大小。我只是看到不同的内核大小、步幅和填充。不确定要使用哪些值。]]></description>
      <guid>https://stackoverflow.com/questions/78687394/confusion-about-output-sizes-of-gan</guid>
      <pubDate>Sun, 30 Jun 2024 00:41:37 GMT</pubDate>
    </item>
    <item>
      <title>无法在 python 中安装 lap==0.4.0 库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>python 在对数逻辑回归中遇到除以零</title>
      <link>https://stackoverflow.com/questions/38125319/python-divide-by-zero-encountered-in-log-logistic-regression</link>
      <description><![CDATA[我正在尝试实现一个多类逻辑回归分类器，以区分 k 个不同的类。
这是我的代码。
import numpy as np
from scipy.special import expit

def cost(X,y,theta,regTerm):
(m,n) = X.shape
J = (np.dot(-(y.T),np.log(expit(np.dot(X,theta))))-np.dot((np.ones((m,1))-y).T,np.log(np.ones((m,1)) - (expit(np.dot(X,theta))).reshape((m,1))))) / m + (regTerm / (2 * m)) * np.linalg.norm(theta[1:])
return J

def梯度（X，y，theta，regTerm）：
（m，n）= X.shape
grad = np.dot（（（expit（np.dot（X，theta）））。reshape（m，1）- y）。T，X）/m +（np.concatenate（（[0]，theta[1：]。T），axis = 0））。reshape（1，n）
返回np.asarray（grad）

def train（X，y，regTerm，learnRate，epsilon，k）：
（m，n）= X.shape
theta = np.zeros（（k，n））
对于i在范围（0，k）中：
previousCost = 0;
currentCost = cost(X,y,theta[i,:],regTerm)
while(np.abs(currentCost-previousCost) &gt; epsilon):
print(theta[i,:])
theta[i,:] = theta[i,:] - learnRate*gradient(X,y,theta[i,:],regTerm)
print(theta[i,:])
previousCost = currentCost
currentCost = cost(X,y,theta[i,:],regTerm)
return theta

trX = np.load(&#39;trX.npy&#39;)
trY = np.load(&#39;trY.npy&#39;)
theta = train(trX,trY,2,0.1,0.1,4)

我可以验证 cost 和 gradient 是否返回正确维度的值（cost 返回标量，gradient 返回 1 乘以n 行向量），但我得到了错误
RuntimeWarning：在 log 中遇到除以零的情况
J = (np.dot(-(y.T),np.log(expit(np.dot(X,theta))))-np.dot((np.ones((m,1))-y).T,np.log(np.ones((m,1)) - (expit(np.dot(X,theta))).reshape((m,1))))) / m + (regTerm / (2 * m)) * np.linalg.norm(theta[1:])

为什么会发生这种情况，我该如何避免？]]></description>
      <guid>https://stackoverflow.com/questions/38125319/python-divide-by-zero-encountered-in-log-logistic-regression</guid>
      <pubDate>Thu, 30 Jun 2016 13:57:13 GMT</pubDate>
    </item>
    </channel>
</rss>