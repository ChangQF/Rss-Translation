<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 18 Jan 2024 12:26:18 GMT</lastBuildDate>
    <item>
      <title>模型遭受巨额亏损</title>
      <link>https://stackoverflow.com/questions/77839031/model-getting-huge-loss</link>
      <description><![CDATA[我正在尝试按标题制作文本生成器。文本最大长度为2500，词典大小为45,000字。这是我正在使用的模型。训练过程中，损失增加，但准确率保持不变。
&lt;前&gt;&lt;代码&gt;纪元 1/75
1311/1311 [================================] - 461s 347ms/步 - 损失：27230606.0000 - 准确度：0.0382
纪元 2/75
1311/1311 [================================] - 454s 346ms/步 - 损失：78650848.0000 - 准确度：0.0382


我在 anaconda 环境中使用 Tensorflow GPU 和 python 3.11。
模型 = keras.Sequential([
    嵌入（vocab_size，256，input_length = max_sequence_length），
    LSTM（单位= 256，kernel_regularizer = l2（0.01），return_sequences = True），
    LSTM（单位= 128，kernel_regularizer = l2（0.01）），
    密集（max_sequence_length，激活=&#39;softmax&#39;）
]）

亚当 = 亚当(lr=0.01)

model.compile(optimizer=adam,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
model.fit（标题_序列_填充，食谱_序列_填充，纪元= 75，详细= 1，
          回调=[ModelCheckpoint(filepath=Settings.new_model_path)])

我尝试增加单位数量、损失类型​​，但没有任何效果。]]></description>
      <guid>https://stackoverflow.com/questions/77839031/model-getting-huge-loss</guid>
      <pubDate>Thu, 18 Jan 2024 11:28:10 GMT</pubDate>
    </item>
    <item>
      <title>如何从数据生成 if-else 条件或树状结构或隐藏规则</title>
      <link>https://stackoverflow.com/questions/77838790/how-to-generate-if-else-conditions-or-tree-like-structure-or-hidden-rules-from-d</link>
      <description><![CDATA[假设我们生活在一个孩子的名字是根据其父母和祖父母的详细信息确定的世界。我想从这样一个给定的数据集中找到所有规则。
假设我有给定的数据：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

父亲
妈妈
奶奶
爷爷
父亲年龄
母亲年龄
孩子姓名


&lt;正文&gt;

蒂姆
帕特里夏

延斯


标记


蒂姆
奥利维亚
海伦娜


37
标记


蒂姆

凯茜
罗尔夫

45
标记


山姆
百合

鲁道夫
36

莎莉


山姆
百合
辛迪
标记
40
42
莎莉


乔治
布伦达
百合
一月
27
28
标记


乔治
波莉
多莉
肯
38

奥利维亚




我想找到这样的规则：

&lt;表类=“s-表”&gt;
&lt;标题&gt;

规则
输出孩子名字


&lt;正文&gt;

父亲：蒂姆
标记


父亲：山姆+母亲：莉莉
莎莉


父亲：乔治 + 母亲：布伦达 + 祖母：莉莉 + 祖父：简 + 父亲年龄：27 + 母亲年龄：28
标记


父亲：乔治 + 母亲：波莉 + 奶奶：多莉 + 爷爷：肯 + 父亲年龄：38 + 母亲年龄：空白
奥利维亚




我的数据很大，输入列更多，所以我无法使用暴力方法。我的限制是在 Python 3.10 中实现它。有什么方法可以不用暴力破解这个程序吗？]]></description>
      <guid>https://stackoverflow.com/questions/77838790/how-to-generate-if-else-conditions-or-tree-like-structure-or-hidden-rules-from-d</guid>
      <pubDate>Thu, 18 Jan 2024 10:48:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么多项式包含在回归中？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77838625/why-polynomial-is-included-in-regression</link>
      <description><![CDATA[多项式回归是非线性的，因为 x 与 f(x,β) 不线性相关；方程本身仍然是线性的，你怎么能证明这个问题是合理的？我在谷歌上得到了很多答案，但我没有得到最好的理由。 .
我在谷歌和其他平台上搜索。]]></description>
      <guid>https://stackoverflow.com/questions/77838625/why-polynomial-is-included-in-regression</guid>
      <pubDate>Thu, 18 Jan 2024 10:24:17 GMT</pubDate>
    </item>
    <item>
      <title>验证损失低于训练损失[关闭]</title>
      <link>https://stackoverflow.com/questions/77838583/validation-loss-lower-than-training-loss</link>
      <description><![CDATA[我在玩 GRU 时遇到以下情况：在此处输入图像描述
据观察，验证损失始终低于训练损失，在开始下降之前达到最大值。我使用的损失函数是MSE。
问题：

验证损失低于训练损失的原因是什么？
为什么验证损失从一开始就这么低？这是否意味着即使未经训练的随机猜测也能产生相当好的结果？

训练集由2000年的时间序列数据组成，而验证集由2002年的数据组成，所以我认为数据泄漏是不可能的。
我也用其他年份训练了 GRU，结果相似。]]></description>
      <guid>https://stackoverflow.com/questions/77838583/validation-loss-lower-than-training-loss</guid>
      <pubDate>Thu, 18 Jan 2024 10:18:40 GMT</pubDate>
    </item>
    <item>
      <title>Catboost 多类分类的训练精度较低</title>
      <link>https://stackoverflow.com/questions/77838402/training-accuracy-is-low-for-catboost-multi-class-classification</link>
      <description><![CDATA[我有以下数据集

我正在使用 CatBoost 分类器来预测多类中的 &#39;ETR&#39;，其中我的文本特征是 [&#39;title&#39;] ，我的分类特征是[&#39;创建时间&#39;，&#39;创建日期&#39;]。我的课程分布如下

我的训练代码如下所示
def train_iter(数据: pd.DataFrame, split_data=True,
                      cat_features=无，text_features=无，目标：str =“ETR”）：
    
    如果 cat_features 为 None：
        print(&#39;指定要训练的特征！&#39;)
        返回
    
    # 分割数据
    如果分割数据：
        print(f“分割数据！”)
        train_data, test_data = train_test_split(数据, random_state=42, test_size=0.2, stratify=data[目标])
    别的：
        训练数据、测试数据 = 数据、数据

    print(f&quot;火车形状：{train_data.shape} | 测试形状：{test_data.shape}&quot;)
            
    #拟合模型
    类 = np.unique(train_data[目标])
    权重= class_weight.compute_class_weight(class_weight=&#39;平衡&#39;,classes=classes,y=train_data[目标])
    class_weights = dict(zip(类、权重))
    
    train_pool = Pool(train_data[cat_features + text_features], train_data[目标], text_features=text_features, cat_features=cat_features)
    test_pool = Pool(test_data[cat_features + text_features], test_data[目标], text_features=text_features, cat_features=cat_features)
    
    模型= CatBoostClassifier（详细= 100，
                               文本特征=文本特征，
                               猫特征=猫特征，
                               eval_metric=&#39;准确度&#39;,
                               l2_leaf_reg=40,
                               学习率=0.5，
                               迭代=1500，
                               类权重=类权重，
                               loss_function=&#39;多类&#39;,
                               分词器=[
                                    {
                                        &#39;tokenizer_id&#39;: &#39;感知&#39;,
                                        &#39;separator_type&#39;: &#39;BySense&#39;,
                                        &#39;小写&#39;：&#39;正确&#39;，
                                        &#39;token_types&#39;:[&#39;单词&#39;, &#39;数字&#39;, &#39;SentenceBreak&#39;],
                                        &#39;sub_tokens_policy&#39;:&#39;几个令牌&#39;
                                    }
                                ],
                                字典=[
                                    {
                                        &#39;dictionary_id&#39;: &#39;单词&#39;,
                                        &#39;max_dictionary_size&#39;: &#39;20000&#39;
                                    }
                                ],
                                特征计算器 = [
                                    &#39;BoW:top_tokens_count=10000&#39;
                                ]）
    
    model.fit(train_pool、eval_set=test_pool、plot=True、use_best_model=True)
    print(f&#39;模型已安装！&#39;)
    
    # 指标
    preds = model.predict(test_pool)
    y_true = test_data[目标]
    acc = precision_score(y_true, preds)
    f1 = f1_score(y_true, preds, 平均值=“宏观”)
    召回=召回得分（y_true，preds，平均值=“宏观”）
    指标 = {“准确率”：acc，“召回率”：召回率，“F1”：f1}
    
    返回模型、指标

model,metrics = train_iter(df, cat_features = [“创建时间”,“创建日期”], text_features = [“标题”], split_data=True)

由于我已经使用类权重处理了类不平衡，并且数据集足够大（615k 行），因此我希望我的模型能够得到良好的训练。但是，我得到了下面的训练图

如图所示，我的训练准确率从 0.23 (23%) 开始，在整个训练过程中，它没有超过 35%。
令人惊讶的是，如果我将多类分类更改为二元分类问题（有 2 个类[&#39;少于 32 小时&#39;，&#39;超过 32 小时&#39;]），我的模型的准确率为 78%。
由于我有异构数据（文本数据和分类数据），我知道 Catboost 最适合这里。我使用了错误的型号吗？或者我可以知道我哪里出错了吗？]]></description>
      <guid>https://stackoverflow.com/questions/77838402/training-accuracy-is-low-for-catboost-multi-class-classification</guid>
      <pubDate>Thu, 18 Jan 2024 09:48:20 GMT</pubDate>
    </item>
    <item>
      <title>mlflow.pyfunc.log_model 排除未使用的 Python 包</title>
      <link>https://stackoverflow.com/questions/77838266/mlflow-pyfunc-log-model-exclude-unused-python-packages</link>
      <description><![CDATA[我在 my_app 中使用 mlflow.pyfunc 来扭曲模型，如下所示：
类 SetfitModelWrapper(mlflow.pyfunc.PythonModel)：

    def __init__(self, 模型: SetFitModel):
        self.model = 模型

    def 预测（自身、上下文、模型输入）：
        经过

wrapped_model = SetfitModelWrapper(模型=模型)
mlflow.pyfunc.log_model(artifact_path=&#39;./artifact&#39;, python_model=wrapped_model)

然后，当我在产品服务器上的 Flask 容器中加载模型时，例如 app.main = mlflow.pyfunc.load_model(model_parameters.name)：
回溯（最近一次调用最后一次）：

错误：导入“app.main”时，引发了 ImportError：

尝试“python -mflask run --help”寻求帮助。
用法： python -mflask run [选项]

ModuleNotFoundError：没有名为“my_app”的模块
                   ^^^^^^^^^^^^^^^^^^^^
    python_model = cloudpickle.load(f)
  文件“/app/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py”，第 327 行，位于 _load_pyfunc
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^
    model_impl = importlib.import_module(conf[MAIN])._load_pyfunc(data_path)
  文件“/app/venv/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py”，第 630 行，在 load_model 中
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    app.model = mlflow.pyfunc.load_model(model_parameters.name)
  文件“/app/app/main.py”，第 42 行，在  中
2024-01-18 12:12:07.001 |错误| app.main::50 - 回溯（最近一次调用）：

ModuleNotFoundError：没有名为“my_app”的模块

看起来mlflow.pyfunc.log_model自动包含在cloudpickle中来自Python环境的所有可能的包。是的，我可以将其添加到产品要求中，但在这种情况下我看到很多未使用的模块。如何手动指定模型运行所需的模块，或排除不必要的模块？]]></description>
      <guid>https://stackoverflow.com/questions/77838266/mlflow-pyfunc-log-model-exclude-unused-python-packages</guid>
      <pubDate>Thu, 18 Jan 2024 09:25:57 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的有损与无损音频格式</title>
      <link>https://stackoverflow.com/questions/77837837/lossy-vs-lossless-audio-format-in-machine-learning</link>
      <description><![CDATA[我们希望提供一个能够从语音中识别某些事物的机器学习模型。特征提取基于专有算法。通常我们一直使用wav文件。我们一直在问自己是否也可以使用像 mp3 这样的东西？由于我们可能无法再次收集我们收集的数据，并且我们无法预见我们的专有算法的进一步开发在某个时候将需要什么样的信息，因此我们担心像 mp3 这样的东西会导致太多信息丢失。你觉得怎么样？
我对具体答案不太感兴趣，因为我知道由于某些细节的悬而未决的问题，不可能给出具体答案。更多的是分享经验和交流想法。例如，有人在机器学习领域有过这样的经验：MP3 中被切除的区域通常对 ML 算法影响很小或没有影响。这只是一个例子。我在互联网上还没有真正找到有关此主题的任何内容。]]></description>
      <guid>https://stackoverflow.com/questions/77837837/lossy-vs-lossless-audio-format-in-machine-learning</guid>
      <pubDate>Thu, 18 Jan 2024 08:13:51 GMT</pubDate>
    </item>
    <item>
      <title>Python dgl 库 API 更新</title>
      <link>https://stackoverflow.com/questions/77837193/python-dgl-library-api-updates</link>
      <description><![CDATA[这是我的代码：
def 标准化（自我，logits）：
    self.\_logits_name = “\_logits”
    self.\_normalizer_name = “\_norm”
    self.g.edata\[self.\_logits_name\] = logits

    self.g.update_all(fn.copy_u(self._logits_name, self._logits_name),
                     fn.sum(self._logits_name, self._normalizer_name))
    返回 self.g.edata.pop(self._logits_name), self.g.ndata.pop(self._normalizer_name)

def edge_softmax(自身):

    如果 self.l0 == 0:
        分数 = self.softmax(self.g, self.g.edata.pop(&#39;a&#39;))
    别的：
        分数，归一化器 = self.normalize(self.g.edata.pop(&#39;a&#39;))
        self.g.ndata[&#39;z&#39;] = 标准化器[:,0,:].unsqueeze(1)

    self.g.edata[&#39;a&#39;] = 分数[:,0,:].unsqueeze(1)

这是堆栈跟踪：
回溯（最近一次调用最后一次）：
文件“/datasets/\_deepnote_work/train.py”，第 211 行，位于 \ 中
主要（参数）

文件“/datasets/\_deepnote_work/train.py”，第 130 行，在 main 中
logits = 模型（特征）

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1518 行，位于 \_wrapped_call_impl
返回 self.\_call_impl(\*args, \*\*kwargs)

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1527 行，位于 \_call_impl
返回forward_call(\*args, \*\*kwargs)

文件“/datasets/\_deepnote_work/gat.py”，第 209 行，向前
h，边缘 = self.gat_layers\[0\](h，边缘)

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1518 行，位于 \_wrapped_call_impl
返回 self.\_call_impl(\*args, \*\*kwargs)

文件“/root/venv/lib/python3.9/site-packages/torch/nn/modules/module.py”，第 1527 行，位于 \_call_impl
返回forward_call(\*args, \*\*kwargs)

文件“/datasets/\_deepnote_work/gat.py”，第 105 行，向前
self.edge_softmax()

文件“/datasets/\_deepnote_work/gat.py”，第 166 行，edge_softmax
分数，归一化器 = self.normalize(self.g.edata.pop(&#39;a&#39;))

文件“/datasets/\_deepnote_work/gat.py”，第 157 行，标准化
self.g.update_all(fn.copy_u(self.\_logits_name, self.\_logits_name),

文件“/root/venv/lib/python3.9/site-packages/dgl/heterograph.py”，第 5110 行，位于 update_all
ndata = core.message_passing()
文件“/root/venv/lib/python3.9/site-packages/dgl/core.py”，第 398 行，message_passing
ndata = invoke_gspmm(g, mfunc, rfunc)

文件“/root/venv/lib/python3.9/site-packages/dgl/core.py”，第 361 行，invoke_gspmm
x = alldata\[mfunc.target\]\[mfunc.in_field\]

文件“/root/venv/lib/python3.9/site-packages/dgl/view.py”，第 80 行，在 _getitem_ 中
返回 self.\_graph.\_get_n_repr(self.\_ntid, self.\_nodes)\[key\]

文件“/root/venv/lib/python3.9/site-packages/dgl/frame.py”，第 688 行，在 _getitem_ 中
返回 self.\_columns\[name\].data
关键错误：&#39;\_logits&#39;

我查看了DGLEdgeBatch的文档，但没有找到任何解决方案
链接到文档：https://docs.dgl.ai/en/1.1.x/api/python/udf.html#edge-wise-user-defined-function
阅读 DGL 的文档并尝试了一些替代函数。但他们没有工作。
因此，如果有人可以帮助我修复/更新代码，那将是一个巨大的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77837193/python-dgl-library-api-updates</guid>
      <pubDate>Thu, 18 Jan 2024 06:02:39 GMT</pubDate>
    </item>
    <item>
      <title>为什么 TF-TRT 转换器不适用于我的型号？</title>
      <link>https://stackoverflow.com/questions/77836878/why-tf-trt-converter-didnt-work-for-my-model</link>
      <description><![CDATA[我想通过使用 TF-TRT 转换我的训练模型以获得更好的推理性能。
我使用了nvidia tensorflow docker镜像，运行测试代码没有问题。
测试代码来自这里：https://github.com/jhson989/tf-to -trt
和详细 Docker 镜像标签：nvcr.io/nvidia/tensorflow:23.12-tf2-py3
但是当我尝试转换经过训练的模型时，它不起作用。
导入tensorflow为tf
从张量流导入keras
从tensorflow.python.compiler.tensorrt导入trt_convert为trt

# 训练后的模型为.h5格式
h5_model_path = &#39;模型/路径/h5/模型名称&#39;
h5_model = keras.models.load_model(model_path,compile=False)

# 需要将.h5转换为saved_model格式才能使用TF-TRT
已保存模型路径 = &#39;模型/路径/已保存模型/模型名称&#39;
tf.saved_model.save（h5_model，saved_model_path）

# 制作一个转换器
conversion_param = trt.TrtConversionParams( precision_mode=trt.TrtPrecisionMode.FP16)
转换器 = trt.TrtGraphConverterV2(input_saved_model_dir=saved_model_path, conversion_params=conversion_param)

# 错误从这里发生
转换器.convert()

发生了这个错误。
回溯（最近一次调用最后一次）：
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py”，第 92 行，位于 NewCheckpointReader 中
    返回 CheckpointReader(compat.as_bytes(filepattern))
RuntimeError：TensorSliceReader 构造函数不成功：无法找到 /model/path/saved_model/model_name/variables/variables 的任何匹配文件

在处理上述异常的过程中，又出现了一个异常：

回溯（最近一次调用最后一次）：
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py”，第 1031 行，位于 load_partial
    加载器=加载器（object_graph_proto，saved_model_proto，export_dir，
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py”，第 226 行，在 __init__ 中
    self._restore_checkpoint()
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py”，第 561 行，位于 _restore_checkpoint
    load_status = saver.restore(variables_path, self._checkpoint_options)
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py”，第 1415 行，在恢复中
    读者 = py_checkpoint_reader.NewCheckpointReader(save_path)
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py”，第 96 行，位于 NewCheckpointReader 中
    错误翻译器（e）
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py”，第 31 行，位于 error_translator 中
    引发errors_impl.NotFoundError（无，无，error_message）
tensorflow.python.framework.errors_impl.NotFoundError：TensorSliceReader构造函数失败：无法找到/model/path/saved_model/model_name/variables/variables的任何匹配文件

在处理上述异常的过程中，又出现了一个异常：

回溯（最近一次调用最后一次）：
  文件“/model/code/convert_model.py”，第 106 行，在 eval 中
    转换器.convert()
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py”，第 1453 行，在转换中
    self._saved_model = load.load(self._input_saved_model_dir,
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py”，第 900 行，加载中
    结果 = load_partial(export_dir, None, 标签, 选项)[“root”]
  文件“/usr/local/lib/python3.10/dist-packages/tensorflow/python/saved_model/load.py”，第 1034 行，位于 load_partial
    引发文件未找到错误（
FileNotFoundError：TensorSliceReader 构造函数失败：找不到 /model/path/saved_model/model_name/variables/variables 的任何匹配文件
 您可能正在尝试在与计算设备不同的设备上加载。考虑将“tf.saved_model.LoadOptions”中的“experimental_io_device”选项设置为 io_device，例如“/job:localhost”。

我已经确认我的模型的 saving_model 版本与测试代码具有相同的目录。
具体来说是“/model/path/saved_model/model_name/variables”目录，其中包含variables.data-00000-of-00001和variables.index。]]></description>
      <guid>https://stackoverflow.com/questions/77836878/why-tf-trt-converter-didnt-work-for-my-model</guid>
      <pubDate>Thu, 18 Jan 2024 04:21:31 GMT</pubDate>
    </item>
    <item>
      <title>NER 模型表现不佳</title>
      <link>https://stackoverflow.com/questions/77836231/ner-model-not-performing-adequately</link>
      <description><![CDATA[我正在为以下标签构建 NER 模型：ACQUIREE_COMPANY 和 ACQUIROR_COMPANY。培训数据基于宣布被收购方和收购方公司合并和收购的新闻稿。我使用 ChatGPT-4 注释了大约 18,000 个示例。我使用 Prodigy 训练模型，使用基本模型 (en_core_web_lg) 和不使用基本模型时的分割率为 80%（训练）-20%（评估）。使用基本模型训练的模型的准确率没有超过大约 70%，而没有基本模型训练的模型的准确率则没有超过 67%。
没有基本模型的训练运行统计数据为：
E # LOSS TOK2VEC LOSS NER ENTS_F ENTS_P ENTS_R SCORE
--- ------ ------------ -------- ------ ------ ------ --- ---
...
  0 3400 236.99 870.02 67.13 68.91 65.44 0.67
...
  0 4600 31159.08 946.75 67.07 73.73 61.52 0.67
...
  0 5000 581.26 919.93 64.44 62.43 66.58 0.64
✔ 将管道保存到输出目录

使用 en_core_web_lg 作为基本模型进行训练的统计数据为：
E # LOSS TOK2VEC LOSS NER ENTS_F ENTS_P ENTS_R SPEED SCORE
--- ------ ------------ -------- ------ ------ ------ --- --- ------
...
  3 19000 0.00 3564.10 72.53 74.67 70.50 6875.54 0.73
  3 20000 0.00 3647.85 72.67 74.46 70.96 7190.40 0.73
...
  5 25000 0.00 3639.24 72.75 74.55 71.03 7433.97 0.73
  5 26000 0.00 3409.12 72.74 74.67 70.91 7425.77 0.73
✔ 将管道保存到输出目录

如何提高准确性？]]></description>
      <guid>https://stackoverflow.com/questions/77836231/ner-model-not-performing-adequately</guid>
      <pubDate>Thu, 18 Jan 2024 00:25:16 GMT</pubDate>
    </item>
    <item>
      <title>感知器算法未收敛于线性可分离数据</title>
      <link>https://stackoverflow.com/questions/77836071/perceptron-algorithm-not-converging-on-linearly-separable-data</link>
      <description><![CDATA[我正在研究感知器问题，我制作了一些假数据，当数据线性可分时，感知器算法不会收敛。
这是线性可分的假数据。
np.random.seed(42)
Linear_df = pd.DataFrame({
    &#39;X1&#39;：np.round（np.concatenate（[np.random.uniform（低= 0，高= 5，大小= 4），np.random.uniform（低= 8，高= 12，大小= 4） ]), 1),
    &#39;X2&#39;：np.round（np.concatenate（[np.random.uniform（低= 0，高= 5，大小= 4），np.random.uniform（低= 8，高= 12，大小= 4） ]),1),
    &#39;Y&#39;: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]
})

然后我在上面运行感知器
clf = 感知器（详细=1，max_iter=1000）
X = Linear_df[[&#39;X1&#39;, &#39;X2&#39;]]
y = 线性_df[&#39;Y&#39;]
clf.fit(X, y)
线性系数 = clf.coef_
线性偏差 = clf.intercept_[0]
打印（clf.coef_）
打印（clf.intercept_）
打印（clf.score（X，y））

8 个 epoch 后的收敛时间为 0.00 秒
[[ 2.3 -2.6]]
[17.]
0.5
但它说它在 8 个 Epoch 后收敛，并且没有产生正确的输出。]
情节如下：

有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77836071/perceptron-algorithm-not-converging-on-linearly-separable-data</guid>
      <pubDate>Wed, 17 Jan 2024 23:19:38 GMT</pubDate>
    </item>
    <item>
      <title>批次和图层归一化差异</title>
      <link>https://stackoverflow.com/questions/77835832/batch-and-layer-normalization-difference</link>
      <description><![CDATA[
在批量归一化中，均值和标准差是按特征计算的，归一化步骤是按实例完成的，在层归一化中，均值和标准差是按实例计算的，归一化步骤是按特征完成的；这对不对？

“批次”有什么用？在批量归一化中？在神经网络中完成第一遍后，我们是否要向网络提供第二批数据？


我找不到任何关于这方面的好的资源，而且定义似乎很难理解。]]></description>
      <guid>https://stackoverflow.com/questions/77835832/batch-and-layer-normalization-difference</guid>
      <pubDate>Wed, 17 Jan 2024 22:14:25 GMT</pubDate>
    </item>
    <item>
      <title>召回分数！=使用confusion_matrix手动计算</title>
      <link>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</link>
      <description><![CDATA[我遇到了一个问题，即使用 recall_score(y, y_pred) 获得的召回分数与使用 confusion_matrix 手动计算的值不匹配。
不仅如此，召回率与特异性的值完全相同，我也在下面手动计算了该值。
这是我正在使用的相关代码：
recall = recall_score(y, y_pred) # &lt;-- 不同的分数

conf_matrix = fusion_matrix(y, y_pred)
tn, fp, fn, tp = conf_matrix.ravel()
Manual_recall = tp / (tp + fn) # &lt;-- 达到这个分数
特异性 = tn / (tn + fp) # &lt;-- 与上面的分数相同

这是发生这种情况的终端中打印的混淆矩阵的示例：
&lt;前&gt;&lt;代码&gt;[[34 6]
 [20 20]]

科学套件召回：0.85
手动召回：0.5
或
&lt;前&gt;&lt;代码&gt;[[29 11]
 [9 31]]

科学套件召回：0.725
手动召回：0.775
问题：
scikit-learn 返回的召回和手动召回不会产生相同的值。
问题：
为什么recall_score和使用confusion_matrix的手动计算可能会产生不同的召回分数结果？
更多信息...

这是一个二元分类问题。

我正在使用 recall_score 的默认阈值。

我尝试确定混淆表是否准确（确实如此）。

]]></description>
      <guid>https://stackoverflow.com/questions/77834628/recall-score-manual-calculation-using-confusion-matrix</guid>
      <pubDate>Wed, 17 Jan 2024 18:08:23 GMT</pubDate>
    </item>
    <item>
      <title>ValidationError：StuffDocumentsChain __root__ 出现 1 个验证错误</title>
      <link>https://stackoverflow.com/questions/76776695/validationerror-1-validation-error-for-stuffdocumentschain-root</link>
      <description><![CDATA[我收到此错误ValidationError：在 llm_chain input_variables 中找不到 StuffDocumentsChain __root__ document_variable_name 上下文的 1 个验证错误：[&#39;chat_history&#39;、&#39;user_query&#39;、&#39;relevant_context&#39;] (type=value_error)
在使用 load_qa_chain 时，我搜索了此错误，但没有找到与此相关的任何内容。谁能告诉我这里缺少什么。
代码：
template = &quot;&quot;&quot;您是一个正在与人类对话的聊天机器人。

给定长文档和问题的以下提取部分，创建最终答案。

{相关上下文}

{聊天记录}
人类：{user_query}
聊天机器人：“”“”

提示=提示模板(
input_variables=[“chat_history”, “user_query”, “relevant_context”],
模板=模板
）

内存= ConversationBufferMemory（memory_key =“聊天历史记录”，input_key =“用户查询”）

llm = OpenAI()
llm_chain = LLMChain(
    llm=llm,
    提示=提示，
    内存=内存，
）

链 = load_qa_chain(
    llm，chain_type =“东西”，内存=内存，提示=提示
）
]]></description>
      <guid>https://stackoverflow.com/questions/76776695/validationerror-1-validation-error-for-stuffdocumentschain-root</guid>
      <pubDate>Thu, 27 Jul 2023 05:20:25 GMT</pubDate>
    </item>
    <item>
      <title>在 sklearn 中训练后是否必须再次使用 fit() ？</title>
      <link>https://stackoverflow.com/questions/49466944/do-i-have-to-use-fit-again-after-training-in-sklearn</link>
      <description><![CDATA[我正在使用LinearRegression()。您可以在下面看到我为预测新功能所做的工作：

&lt;前&gt;&lt;代码&gt; lm = 线性回归()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=say)
    lm.fit(X_train, y_train)
    lm.predict(X_test)
    scr = lm.score(X_test, y_test)
    lm.fit(X, y)
    pred = lm.predict(X_real)

我真的需要lm.fit(X, y)行吗？或者我可以不使用它吗？另外，如果我不需要计算准确性，您认为以下方法是否更好，而不是使用训练和测试？ （如果我不想测试）：

&lt;前&gt;&lt;代码&gt; lm.fit(X, y)
    pred = lm.predict(X_real)

即使我获得了 0.997 的准确度，预测值也没有接近或偏移。有没有办法让预测更准确？]]></description>
      <guid>https://stackoverflow.com/questions/49466944/do-i-have-to-use-fit-again-after-training-in-sklearn</guid>
      <pubDate>Sat, 24 Mar 2018 16:11:42 GMT</pubDate>
    </item>
    </channel>
</rss>