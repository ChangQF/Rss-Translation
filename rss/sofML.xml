<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 19 Apr 2024 18:16:43 GMT</lastBuildDate>
    <item>
      <title>带有产品推荐系统的电子商务网络应用程序</title>
      <link>https://stackoverflow.com/questions/78355434/e-commerce-webapp-with-product-recommandation-system</link>
      <description><![CDATA[您好，我有一个带有推荐系统的电子商务 Web 应用程序的 fyp，您能告诉我如何集成制作一个可以在 React JS 中工作的推荐系统，或者如何将其与 React JS 集成
我已经完成了我的 Mern Stack Web 电子商务应用程序，现在我想创建推荐系统并将其与我的 Web 应用程序连接]]></description>
      <guid>https://stackoverflow.com/questions/78355434/e-commerce-webapp-with-product-recommandation-system</guid>
      <pubDate>Fri, 19 Apr 2024 17:50:13 GMT</pubDate>
    </item>
    <item>
      <title>在序列模型中使用归一化层时，adapt() 会出错吗？</title>
      <link>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</link>
      <description><![CDATA[在顺序模型中使用归一化层时，在调整（）时，我收到未绑定错误：
这是错误
我做了以下事情：
标准化器 = 标准化()
标准化器.adapt(X_train)

但是这给了
未绑定错误：赋值之前引用了局部变量“input_shape”。

为什么我会收到此错误？]]></description>
      <guid>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</guid>
      <pubDate>Fri, 19 Apr 2024 17:04:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 进行音频分类总是预测错误</title>
      <link>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</guid>
      <pubDate>Fri, 19 Apr 2024 13:39:10 GMT</pubDate>
    </item>
    <item>
      <title>尝试将自定义模型部署到 OpenSearch 中会引发 RuntimeError：KeyError：token_type_ids</title>
      <link>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354052/trying-to-deploy-a-custom-model-into-opensearch-throws-a-runtimeerror-keyerror</guid>
      <pubDate>Fri, 19 Apr 2024 13:36:18 GMT</pubDate>
    </item>
    <item>
      <title>获取边界框问题</title>
      <link>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</guid>
      <pubDate>Fri, 19 Apr 2024 12:40:40 GMT</pubDate>
    </item>
    <item>
      <title>梅尔频谱图的卷积自动编码器。不起作用</title>
      <link>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</link>
      <description><![CDATA[# 将列表转换为 numpy 数组
data_array = np.array(data_list, dtype=&#39;float32&#39;)
data_array = np.array(data_array, dtype=&#39;float32&#39;) / 255.0 # 所以我的数据是从0到1
导入操作系统
导入keras
将 numpy 导入为 np
将张量流导入为 tf
从张量流导入keras
从 keras.layers 导入输入、Conv2D、BatchNormalization、MaxPooling2D、UpSampling2D、Flatten、Dense、Reshape、Dropout
从 keras.models 导入模型
从 sklearn.model_selection 导入 train_test_split
#从keras.preprocessing.image导入img_to_array，load_img
从 sklearn.model_selection 导入 train_test_split
#from keras.callbacks 导入 LearningRateScheduler
从 sklearn.model_selection 导入 train_test_split
从 keras.callbacks 导入 TensorBoard
导入时间
从 keras 导入正则化器

train_images, test_images = train_test_split(data_array, test_size=0.1) # 10% 用于测试
train_images, val_images = train_test_split(train_images, test_size=0.1) # 其余的 10% 用于验证

print(f&#39;训练集大小：{train_images.shape}&#39;)
print(f&#39;验证集大小：{val_images.shape}&#39;)
print(f&#39;测试集大小：{test_images.shape}&#39;)

# 超参数正确或接近正确？参数以纸质为准。
H、W、C = 256, 256, 1 # 1 排列 np 黑白
学习率 = 1e-3
批量大小 = 16
纪元 = 50 #Random 纪元
Latent_dim = 128 # 理解

l2_reg = 正则化器.l2(1e-4)

输入=输入（形状=（H，W，C））
x = Conv2D(32, (5, 5), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(输入)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), padding=&#39;same&#39;)(x) #固定池化
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((4, 4), 填充=&#39;相同&#39;)(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
x = MaxPooling2D((2, 2), 填充=&#39;相同&#39;)(x)

# X 是我最后一层的输出

# 关于 X\ 的瓶颈操作
瓶颈=展平()(x)
瓶颈=密集（latent_dim，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（bottleneck）#潜在空间（LS）
瓶颈 = Dropout(0.3)(bottleneck) # 应用 dropout 进行正则化
                                       #输出是瓶颈
#解码器
x = 密集（8* 8* 128，激活=&#39;relu&#39;，kernel_regularizer=l2_reg）（瓶颈）
x = 重塑((8, 8, 128))(x)
x = 上采样2D((2, 2))(x)
x = Conv2D(128, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(64, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)

x = 上采样2D((4, 4))(x)
x = Conv2D(32, (3, 3), 激活=&#39;relu&#39;, 填充=&#39;相同&#39;, kernel_regularizer=l2_reg)(x)
x = BatchNormalization()(x)
#填充？
#x = ZeroPadding2D(padding=((2, 2), (14, 14)))(x) # 大小要求？
# 最终重建
outputs = Conv2D(1, (5, 5), activate=&#39;sigmoid&#39;, padding=&#39;same&#39;, kernel_regularizer=l2_reg)(x) # 修改 1 因为之前有一个 3 : 没有意义，为什么是 sigmoid
#Sigmoid = 0 到 1 之间的值
#或Relu


# 完整的自动编码器模型
自动编码器=模型（输入，输出）
autoencoder.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;,metrics=[&#39;mae&#39;]) # 或 mse
 


# 模型架构
自动编码器.summary()
打印（train_images.shape，test_images.shape）

从 keras.callbacks 导入 EarlyStopping

#early_stopping = EarlyStopping（monitor=&#39;val_loss&#39;，耐心=5，restore_best_weights=True）
# train_images、val_images 在 CAE 开始时预加载

历史=自动编码器.fit(
    train_images, train_images, # 输入和目标
    纪元=纪元，
    批量大小=批量大小，
    洗牌=真，#真
    回调=[张量板],
    验证数据=（val_images，val_images），#validation_data=（val_images，val_images）
）
# 生成重建
rec_images = autoencoder.predict(val_images)[[在此处输入图像描述](https://i.stack.imgur.com/4g01e.png)](https://i.stack.imgur.com/trl9d.png)

我有 2550 个 2 秒的音频文件，我应用了 Mel 扫描图，仅使用 np 数组数据，我为我的 CAE 提供了这些尺寸 2562561。我已经应用了早期停止、主动学习和调节 L2 来提高我的 NN 学习，但我不知道为什么它不起作用。我对 NN 没有太多的经验，我想了解我在 NN 上做错了什么。我将在此处附上代码和结果。如果您想分享您的类似经验和这些问题的解决方案，请提前致谢。 在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78353717/convolutional-autoencoder-from-mel-spectogram-does-not-work</guid>
      <pubDate>Fri, 19 Apr 2024 12:38:40 GMT</pubDate>
    </item>
    <item>
      <title>MLFlow UI 未加载 - 缺少静态内容</title>
      <link>https://stackoverflow.com/questions/78353335/mlflow-ui-not-loading-missing-static-content</link>
      <description><![CDATA[我已经使用 mlflow server ... 部署了 MLFlow 服务器。当访问其部署的 URL https://some.url 时，我会看到一个空白页面并且无法加载。奇怪的是，这在本地主机上不是本地问题。
调查浏览器的控制台，我发现静态 (.../mlflow/build) 文件出现一堆错误，给出 404。
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78353335/mlflow-ui-not-loading-missing-static-content</guid>
      <pubDate>Fri, 19 Apr 2024 11:28:16 GMT</pubDate>
    </item>
    <item>
      <title>如何从 LbfgsLogisticRegression 训练的模型中检索原始模型参数？</title>
      <link>https://stackoverflow.com/questions/78352598/how-can-i-retrieve-original-model-parameters-from-a-lbfgslogisticregression-trai</link>
      <description><![CDATA[我选择使用 LbfgsLogisticRegression，因为它是可重新训练的（可以在不丢失现有模型的情况下对更多数据进行训练）。 （链接)
我的第一批数据通过通常的 Fit 调用训练得很好：
var estimator = mlContext.Transforms.Concatenate(“Features”, nameof(SampleDataEntry.Features))
.Append(mlContext.BinaryClassification.Trainers.LbfgsLogisticRegression(labelColumnName: &quot;name_match&quot;, featureColumnName: nameof(SampleDataEntry.Features)));

但是，当涉及到重新训练时，我显然应该调用 Fit(IDataView, LinearModelParameters)。我有 IDataView，但正在努力获取 LinearModelParameters。 Microsoft 的文档提供了以下不同算法的代码示例：
//提取训练好的模型参数
线性回归模型参数 原始模型参数 =
    ((ISingleFeaturePredictionTransformer)trainedModel).Model 作为 LinearRegressionModelParameters;

但是，当我尝试调整它以检索我自己的模型参数时，我遇到了一系列转换失败。在监视模式下调查 model 对象，我发现它甚至没有代码示例中暗示的 Model 属性。它有一个 .LastTransformer 属性，该属性又包含 .Model。
.LastTransformer 具有类型
Microsoft.ML.Data.BinaryPredictionTransformer&gt;
.LastTransformer.Model 具有类型
Microsoft.ML.Calibrators.ParameterMishingCalibrateModelParameters
打开该模型，我们找到一个 .SubModel 属性，其类型为
Microsoft.ML.Trainers.LinearBinaryModelParameters
但是，如果我检索该组参数，它们不包含 label 字段等基本信息，因此重新训练失败。
任何人都可以向我指出代码示例/教程，或者解释我可以在哪里查找这些原始参数吗？
这是最后一段不起作用的代码：
LinearBinaryModelParameters 原始模型参数 = ((TransformerChain&gt;&gt;)model).LastTransformer.Model.SubModel as LinearBinaryModelParameters;
返回mlContext.BinaryClassification.Trainers.LbfgsLogisticRegression().Fit(splitTrainSet,originalModelParameters);
]]></description>
      <guid>https://stackoverflow.com/questions/78352598/how-can-i-retrieve-original-model-parameters-from-a-lbfgslogisticregression-trai</guid>
      <pubDate>Fri, 19 Apr 2024 09:12:03 GMT</pubDate>
    </item>
    <item>
      <title>自学pdf到数据转换器[关闭]</title>
      <link>https://stackoverflow.com/questions/78352394/self-learning-pdf-to-data-converter</link>
      <description><![CDATA[以下是问题陈述 -
创建尖端、自学的智能 PDF 到数据转换器
目标：

生成式 AI 集成：利用生成式 AI 技术智能地解释和提取多页 PDF 文档中的数据（包括文本、表格和图形），并将其转换为结构化且可用的数据格式。&lt; /里&gt;
自学习能力：整合机器学习模型，使系统能够通过学习每个处理的文档来不断提高转换准确性。这包括理解各种文档布局并根据反馈纠正错误。
处理复杂文档：确保解决方案有效处理布局复杂的文档（例如科学论文、财务报告和法律文档），准确提取数据，同时保持上下文和结构。
效率和可扩展性：开发一种解决方案，不仅准确，而且处理时间高效，能够处理大量文档，并且可扩展以满足个人用户和大型组织的需求。&lt; /里&gt;
用户界面和体验：设计一个用户友好的界面，允许用户上传 PDF 文档、监控转换过程以及轻松编辑或纠正提取数据中的任何不准确之处。

可交付成果：

智能 PDF 到数据转换器的工作原型，展示了生成式 AI 和机器学习在数据提取方面的集成。
原型应有效处理不同类型的文档，例如商业文档（例如采购订单、提单、空运单、装箱单）、财务文档（例如各种布局的发票、付款通知书）和合规文档（例如，运输单、报关单）。
概述解决方案架构、所使用的生成式 AI 和机器学习模型以及用户说明的文档。
重点介绍原型的功能、所解决的挑战以及对数据提取过程的潜在影响的演示。

目前是否有任何模型/变压器或任何工作可以用来解决这个问题以及如何解决这个问题陈述。还有我可以使用的这个问题陈述的任何数据集吗？]]></description>
      <guid>https://stackoverflow.com/questions/78352394/self-learning-pdf-to-data-converter</guid>
      <pubDate>Fri, 19 Apr 2024 08:39:10 GMT</pubDate>
    </item>
    <item>
      <title>使用 Raspberry Pi 4 时 Python 中的多线程崩溃</title>
      <link>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</link>
      <description><![CDATA[我在尝试使用 Raspberry Pi 4B 完成大学项目时遇到问题。
该项目使用 Python 编写，由 5 个线程组成，其中 2 个线程运行机器学习预测，第 3 个线程按顺序运行一系列计算，以达到与机器学习模型预测的输出相同的输出（这样我可以对比输出是否是合理的值）。另外两个线程是：一个等待 10 秒并激活一个标志（开始处理所需的标志），另一个在终端上打印值（都是从 ML 模型和计算中预测的）。
我的问题是，当我尝试同时运行所有线程时，ML 模型运行正确，但我的计算线程不执行任何操作。相反，如果我不启动 ML 线程，计算线程就会正常工作。
我认为Raspberry没有足够的计算能力，因此计算线程崩溃了。
没有必要所有 3 个线程同时运行（我希望能够选择是否要查看终端上打印的 ML 预测或计算输出），因此我尝试禁用线程当我不使用它们时（使用 thread.join() ）并在我决定希望该线程再次开始运行时再次启动它们（thread.start() ）但它无法正常工作。
我还尝试过使用运行预测或计算函数所需的两个标志（ML_flag 和calculations_flag），但也不起作用。
关于我可以使用的其他技术的任何想法，以便 ML 预测和计算单独运行并且不会崩溃？
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78352359/multiple-threads-collapsing-in-python-with-raspberry-pi-4</guid>
      <pubDate>Fri, 19 Apr 2024 08:31:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用已经制作的嵌入来制作索引</title>
      <link>https://stackoverflow.com/questions/78351643/how-to-make-indexes-using-already-made-embeddings</link>
      <description><![CDATA[我是机器学习新手。我想使用 llama_index。我有嵌入。如何使用这些嵌入创建索引？我正在使用huggingface微调法学硕士。如果我理解有误，请纠正我。]]></description>
      <guid>https://stackoverflow.com/questions/78351643/how-to-make-indexes-using-already-made-embeddings</guid>
      <pubDate>Fri, 19 Apr 2024 06:14:32 GMT</pubDate>
    </item>
    <item>
      <title>对于表格数据模型中的过度拟合我该怎么办</title>
      <link>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</link>
      <description><![CDATA[我建立了一个预测模型，用于根据所提供数据中的某些特征来预测结果。
该模型是一个利用 fastai 的表格学习器。
该数据集包含约 300 条记录，分为训练集、验证集和测试集。
我已经实现了解决过度拟合的技术，例如提前停止和权重衰减，但在对未见过的数据进行评估时，模型仍然似乎过度拟合。
此外，我还尝试调整学习率和批量大小等超参数，但没有改善。我怀疑我的模型架构或预处理管道的某些方面可能会导致该问题，但我不确定从哪里开始调查。
鉴于该项目的敏感性，我无法提供有关数据集或预测任务的具体细节，但我可以分享当前模型的预处理和结构。
这是训练的输出：

&lt;标题&gt;

纪元
train_loss
valid_loss
准确度
时间


&lt;正文&gt;

0
0.752707
0.579501
0.776119
00:00


1
0.699270
0.833771
0.776119
00:00


2
0.652438
0.598243
0.791045
00:00


3
0.621083
3.889398
0.776119
00:00


4
0.591348
0.632366
0.791045
00:00


5
0.580582
6.670314
0.791045
00:00



&lt;块引用&gt;
自 epoch 2 以来没有任何改进：提前停止

这是预处理的代码（在我构建了我不能透露的功能之后）。
features 列表定义每个特征，包括有效值范围和权重（feature、range_ 和 weight 如下面的标准化函数中所使用的那样）。
def custom_normalize(df, 特征, range_, 权重):
    df[特征] = 归一化(df[特征], range_)
    df[特征] = df[特征] * 权重
    返回df

分割 = RandomSplitter(valid_pct=0.2)(range_of(df))

procs = [分类，填充缺失]

对于功能，features.items() 中的信息：
    # 确定训练时选择值的范围。
    procs.append(partial(custom_normalize, feature=feature, range_=info[&#39;range&#39;],weight=info[&#39;weight&#39;]))

据我所知，构建模型和训练是非常标准的：
to = TabularPandas(df, procs=procs,
                   cat_names = cat_vars,
                   连续名称=连续变量，
                   y_names=dep_var,
                   分裂=分裂）

dls = to.dataloaders(bs=64)

Early_stop = EarlyStoppingCallback(监视器=&#39;准确度&#39;, min_delta=0.01, 耐心=3)

学习 = tabular_learner(dls, 指标=准确度, wd=0.1)
学习.lr_find()

# 绘制学习率。
learn.recorder.plot_lr_find()

# 根据情节选择学习率。
lr = learn.recorder.lrs[np.argmin(learn.recorder.losses)]

learn.fit_one_cycle(15, lr, cbs=early_stop)
学习.show_results()

# 如果模型不存在则只保存模型
# TODO 将保存包装在条件中，以防止模型存在时保存。
如果不是 os.path.exists(model_fname):
    学习.保存(model_fname)
]]></description>
      <guid>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</guid>
      <pubDate>Tue, 16 Apr 2024 08:38:01 GMT</pubDate>
    </item>
    <item>
      <title>如何将Yolo片段注释转换为coco格式？</title>
      <link>https://stackoverflow.com/questions/77364462/how-to-convert-yolo-segment-annotations-to-coco-format</link>
      <description><![CDATA[我正在尝试将 yolo 段数据集转换为 coco 格式。最初我使用 ultralytics 的 JsonToYolo 从 Coco 转换为 Yolo。现在我想做反之亦然。
我尝试过一些 yolo 到 coco 转换器，例如 YOLO2COCO 和使用五十一转换器。这些只会将 bbox（边界框）值转换为 coco 格式，而不是分段值。分段值为空([])。
可可格式：
“注释”：[
        {
            “id”：1，
            “图像ID”：1，
            “类别 ID”：1，
            “分段”：[
                [
                    5131.4,
                    1099.1,
                    5014.3,
                    1079.0,
                    4918.16,
                    1093.03,
                    4878.82,
                    1161.22,
                    4881.44,
                    1205.81,
                    4898.05,
                    1264.38,
                    4934.77,
                    1283.62,
                    4904.17,
                    1302.85,
                    4982.85,
                    1323.83,
                    4988.97,
                    1338.69,
                    5090.38,
                    1307.22,
                    5135.84,
                    1288.86,
                    5183.05,
                    1283.62,
                    5168.19,
                    1227.67,
                    5179.55,
                    1217.18,
                    5184.8,
                    1199.69,
                    5214.5,
                    1157.7
                ]
            ],
            “区域”：62712.0，
            “bbox”：[
                4878.82,
                1079.0,
                335.68,
                259.69
            ],
            “拥挤”：0，
            “属性”：{
                “用户名”：“”，
                “被遮挡”：假
            }
        },

Yolo 格式：
  0 0.21875 0.380208 0.215625 0.390625 0.215625 0.395833 0.214062 0.401042 0.214062 0.4062 0.40625 0.40625 0.2125 0.2125 0.411458 0.2125 0.2125 0.4270938 0.4210938 0.4210938 0.4210938 0.4210938 0.4210938 0.4210938 0.4210938.4210938.4210938.4210938 375 0.453125 0.209375 0.458333 0.207813 0.463542 0.207813 0.46875 0.20625 0.20625 0.473958 0.20625 0.479167 201562 0.520833 0.201562 0.5625 0.2 0.567708 0.2 0.59375 0.201562 0.598958 0.201562 0.651042 0.203125 0.65625 0.204688 0.651042 0.204688 0.6451042 375 0.619792 0.209375 0.614583 0.210938 0.609375 0.210938 0.604167 0.2125 0.598958 0.598958 0.2125 0.59375 0.2145 0.214062 708 0.217187 0.5625 0.217187 0.552083 0.21875 0.546875 0.21875 0.21875 0.536458 0.220313 0.53125 0.220313 0.520833 0.221875 0.515625 0.221875 0.505208 0.223438 0.5 0.223438 0.489583 0.225 0.484375 0.225 0.46875 0 .226562 0.463542 0.226562 0.432292 0.228125 0.427083 0.228125 0.380208

另一种方法是使用 Roboflow，其中数据以 yolo 格式上传并以 coco 格式导出。但我需要一个将 yolo 注释转换为 coco 格式的脚本。
有线索吗？]]></description>
      <guid>https://stackoverflow.com/questions/77364462/how-to-convert-yolo-segment-annotations-to-coco-format</guid>
      <pubDate>Thu, 26 Oct 2023 06:03:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 OpenCV 和 Mediapipe 实现逼真的唇色变化？</title>
      <link>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75793658/how-to-achieve-realistic-lip-color-change-using-opencv-and-mediapipe</guid>
      <pubDate>Mon, 20 Mar 2023 17:50:46 GMT</pubDate>
    </item>
    <item>
      <title>生成算法和判别算法有什么区别？ [关闭]</title>
      <link>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</link>
      <description><![CDATA[生成式和生成式有什么区别
判别算法？]]></description>
      <guid>https://stackoverflow.com/questions/879432/what-is-the-difference-between-a-generative-and-a-discriminative-algorithm</guid>
      <pubDate>Mon, 18 May 2009 19:44:45 GMT</pubDate>
    </item>
    </channel>
</rss>