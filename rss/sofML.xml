<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sun, 09 Mar 2025 09:15:42 GMT</lastBuildDate>
    <item>
      <title>当用简化运行时，模态可以正常执行。但是，当输入图像时，它无法正常工作</title>
      <link>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</guid>
      <pubDate>Sun, 09 Mar 2025 07:49:34 GMT</pubDate>
    </item>
    <item>
      <title>TPU上的RESNET50计算NAN的准确性和损失，在Google Colab中的CPU上正常工作</title>
      <link>https://stackoverflow.com/questions/79495542/resnet50-on-tpu-calculates-nan-for-accuracy-and-loss-works-fine-on-cpu-in-googl</link>
      <description><![CDATA[我使用Google Colab在V2-8 TPU加速器上培训了RESNET50，我已经用5000张形状（224、224、3）喂了它。我已经对它们进行了规范，没有NAN，没有INF，没有阶级失衡，一切都还好：
  input_shape =（224，224，3）

使用Strategy.scope（）：
    base_model = resnet50（weights =&#39;imagenet&#39;，include_top = false，input_shape = input_shape）
    base_model.trainable = false
    型号= tf.keras.models.sequeential（[[
        base_model，
        tf.keras.layers.globalaveragepooling2d（），
        tf.keras.layers.dense（1024，activation =&#39;relu&#39;），
        tf.keras.layers.dense（6，activation =&#39;sigmoid&#39;） 
    ）））
    model.compile（优化器=&#39;adam&#39;， 
                  损失=&#39;binary_crossentropy&#39;，
                  指标= [&#39;准确性&#39;]）
    
型号
    x_train， 
    y_train， 
    时代= 10， 
    验证_data =（x_val，y_val），
    batch_size = 32
  ）
 
当我对TPU进行训练时，训练期间的准确性和损失成为NAN。当我切换到CPU时，一切正常。
为什么会发生这种情况以及如何解决？
我尝试在Google Colab中对TPU和CPU进行培训。我希望该模型在没有任何问题的情况下进行培训，包括NAN值损失或准确性，尤其是因为培训在CPU上效果很好。但是，当使用TPU时，我遇到了NAN值的准确性和损失。我还验证了数据很干净，没有NAN，无限或失衡问题，并确保模型编译和培训设置是正确的。]]></description>
      <guid>https://stackoverflow.com/questions/79495542/resnet50-on-tpu-calculates-nan-for-accuracy-and-loss-works-fine-on-cpu-in-googl</guid>
      <pubDate>Sun, 09 Mar 2025 07:07:10 GMT</pubDate>
    </item>
    <item>
      <title>AI模型是如何“回收”以做出单个预测的？</title>
      <link>https://stackoverflow.com/questions/79495434/how-ai-models-are-recycled-to-make-a-single-prediction</link>
      <description><![CDATA[这可能是一个愚蠢的问题，但是我必须问，我制作了AI模型，是用于多类别的分类，它运行良好，但除了我不知道如何使用训练有素的模型来做出单个预测或更多。我知道它可能是我要在下面发布的一件代码中，但我无法弄清楚，因此会很感激。
  n_epochs = 200
batch_size = 5
batches_per_epoch = len（x_train）// batch_size

best_acc = 0
best_weights =无
train_loss_hist = []
train_acc_hist = []
test_loss_hist = []
test_acc_hist = []

＃训练循环
对于范围（n_epochs）的时期：

    epoch_loss = []
    epoch_acc = []
    model.train（）
    使用tqdm.trange（batches_per_epoch，unit =; batch; mininterval = 0）作为bar：
        bar.set_description（f＆quot; epoch {epoch}＆quot;）
        因为我在酒吧：
        ＃批量
           start = i * batch_size
           x_batch = x_train [start：start+batch_size]
           y_batch = y_train [start：start+batch_size]
           ＃正向通行证
           y_pred =模型（x_batch）
           损失= loss_fn（y_pred，y_batch）
           ＃向后传球
           优化器.zero_grad（）
           loss.backward（）
           ＃更新权重
           优化器.step（）
           ＃计算和存储指标
           acc =（torch.argmax（y_pred，1）== torch.argmax（y_batch，1））。float（）。平均（）。
           epoch_loss.append（float（loss））
           epoch_acc.append（float（acc））
           bar.set_postfix（
            损失= float（损失），
            ACC = float（ACC）
           ）
＃在评估模式下设置模型并通过测试集运行
model.eval（）
y_pred =模型（x_test）
ce = loss_fn（y_pred，y_test）
acc =（torch.argmax（y_pred，1）== torch.argmax（y_test，1））。float（）。平均（）。
ce = float（CE）
ACC = float（ACC）
＃节省最佳模型
train_loss_hist.append（np.mean（epoch_loss）））
train_acc_hist.append（np.mean（epoch_acc）））
test_loss_hist.append（CE）
test_acc_hist.append（ACC）
如果acc＆gt; best_acc：
    best_acc = acc
    best_weights = copy.deepcopy（model.state_dict（））
print（f＆quot; epoch {epoch}验证：cross-entropy = {ce：.2f}，准确度= {acc*100：.1f}％＆quort;）
 
我也必须提到我使用pytorch来构建模型。这是我的模型：
 类多类（nn.module）：
def __init __（自我）：
    super（）.__ init __（）
    self.hidden = nn.linear（4，8）
    self.act = nn.relu（）
    self.output = nn.linear（8，3）

def向前（self，x）：
    x = self.act（self.hidden（x））
    x = self.Output（x）
    返回x
 
预先感谢]]></description>
      <guid>https://stackoverflow.com/questions/79495434/how-ai-models-are-recycled-to-make-a-single-prediction</guid>
      <pubDate>Sun, 09 Mar 2025 05:02:34 GMT</pubDate>
    </item>
    <item>
      <title>导入pytorch时：“错误加载torch_python.dll或其依赖项之一”</title>
      <link>https://stackoverflow.com/questions/79495211/oserror-when-importing-pytorch-error-loading-torch-python-dll-or-one-of-its-de</link>
      <description><![CDATA[我使用 pip安装火炬安装了pytorch，但是当我尝试导入它时，我会收到以下错误：
  Oserror Trackback（最近的最新通话）  
[1]中的单元，第1行  
----＆gt; 1进口火炬  
      2印刷（Torch .__版本__）  
      3印刷（Torch.version.cuda） 

file＆quort&#39;\。venv \ lib \ site-packages \ torch \ __ init __. py＆quort&#39;,，第274行  
    270增加错误  
    272 kernel32.seterrormode（prev_error_mode）  
 - ＆gt; 274 _load_dll_libraries（）  
    275 del _load_dll_libraries


file＆quot&#39;\。venv \ lib \ site-packages \ torch \ __ init __. py＆quort; py＆quort in _load_dll_libraries in _load_dll_libraries  
    253 err = ctypes.winerror（last_error）  
    254 err.Strerror +=（  
    255 f&#39;错误加载“ {dll}”＆quot;或它的依赖之一。  
    256）  
 - ＆gt; 257增加错误  
    258 Elif Res并非没有：  
    259 is_loaded = true 

Oserror：[Winerror 127]找不到指定的程序。错误加载; \。venv \ lib \ site-packages \ torch \ lib \ torch_python.dll;或它的依赖之一。
 
 我的系统配置：&lt; /strong&gt; 
OS：Windows 11 
Python版本：3.11 
Pytorch版本：2.6.0 
CUDA工具包已安装：11.8 
使用的安装命令：PIP安装火炬
虚拟环境：是（VENV）
 尝试了不同的pytorch安装 
使用官方Pytorch的推荐命令安装
网站：
  pip安装火炬火炬火炬 -  index-url https://download.pytorch.org/whl/cu118
 ]]></description>
      <guid>https://stackoverflow.com/questions/79495211/oserror-when-importing-pytorch-error-loading-torch-python-dll-or-one-of-its-de</guid>
      <pubDate>Sun, 09 Mar 2025 00:03:32 GMT</pubDate>
    </item>
    <item>
      <title>OPENCV，YOLO或培训模型，以预测照片是否满足护照或学校身份证的要求？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79494898/opencv-yolo-or-train-a-model-for-predicting-if-a-photo-meets-requirement-for-pa</link>
      <description><![CDATA[是否可以单独使用OpenCV，或与Yolo（例如Yolo）结合使用OPENCV来验证图像是否适合ID卡吗？没有头饰，没有太阳镜，白色背景。还是训练模型会更容易，更准确？我一直在django中使用yolo的openCV，并且我得到了误报，也许我的代码是错误的，也许这些库是用于更通用的用例，哪种路径是最好的-opencv + yolo或训练我的模型？]]></description>
      <guid>https://stackoverflow.com/questions/79494898/opencv-yolo-or-train-a-model-for-predicting-if-a-photo-meets-requirement-for-pa</guid>
      <pubDate>Sat, 08 Mar 2025 19:17:28 GMT</pubDate>
    </item>
    <item>
      <title>在单个设备上运行时，应该在降低图中删除集体通信操作吗？</title>
      <link>https://stackoverflow.com/questions/79494735/should-collective-communication-ops-be-removed-or-become-no-ops-in-graph-lower</link>
      <description><![CDATA[我正在研究集体通信操作（例如，全合理，全聚集）期间图表降低阶段的优化。我的直觉是，当这些CCL操作在单个设备上执行（或仅包含一个成员的进程组）时，它们没有真正的语义影响，并且可以安全地删除或降低到no-op以避免不必要的开销。 
但是，在检查了Jax，StableHlo（和XLA），NVIDIA的NCCL和TORCH等框架中的实现之后，我还没有找到任何明确的实例，可以在应用此类优化的情况下进行。 
我的问题是：

 这些框架中的任何一个是否实现“单位设备”优化（即，在不需要通信时降低过程中删除或绕过集体OP）？

 如果没有，是否存在特定原因 - 例如维护IR语义，调试或调度考虑因素 - 为什么将集体OP保留，即使它充当NO-OP？


我审查了JAX，StableHlo，NCCL和Torch的源代码和文档。分发，但没有发现在单个设备上运行时删除集体操作的明确优化。]]></description>
      <guid>https://stackoverflow.com/questions/79494735/should-collective-communication-ops-be-removed-or-become-no-ops-in-graph-lower</guid>
      <pubDate>Sat, 08 Mar 2025 17:08:45 GMT</pubDate>
    </item>
    <item>
      <title>解构稳定扩散3.5管道</title>
      <link>https://stackoverflow.com/questions/79494728/deconstructiong-the-stable-diffusion-3-5-pipeline</link>
      <description><![CDATA[我正在尝试解构SD3.5（特别是3.5个介质）管道，以便在降压步骤上具有受控的过程。我无法进行回调，因为我需要根据其他管道修改潜在。
我正在尝试在以下拥抱面指南上执行步骤：
 https://huggingface.co/docs/diffusers/en/using-diffusers/write_own_pipeline_pipeline#deconstruct-the-stable-diffusion-diffusion-pipeline  
我修改了文本编码以适合SD3.5，我还尝试加载整个管道，并在其上运行Encode_prompt函数，以获取文本嵌入和汇总的嵌入，以适应提示和负个提示。当运行该功能并将其输出作为常规管道输入而不是提示提示时，它可以正常工作，因此这似乎不是引起问题的原因。
我还将UNET从文章中更改为使用模型的预训练变压器。之后，我调整了解码器以匹配扩散器上管道源代码上的相同解码。
输出图像在通过扩散器运行管道时看起来并不相同。我不确定在哪里可以找到与SD3管道解构类似的实现，或者我缺少什么。
 在此处输入图像说明  ]]></description>
      <guid>https://stackoverflow.com/questions/79494728/deconstructiong-the-stable-diffusion-3-5-pipeline</guid>
      <pubDate>Sat, 08 Mar 2025 17:06:18 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我创建估算器对象时，AWS SageMaker不提交培训工作？</title>
      <link>https://stackoverflow.com/questions/79492869/why-is-aws-sagemaker-not-submitting-a-training-job-when-i-create-an-estimator-ob</link>
      <description><![CDATA[我正在尝试使用HuggingFace估算器通过GitHub向AWS SageMaker AI API提交培训工作。但是，每次我尝试创建作业时，估算器都会创建一个类型无的对象，并且脚本无限期地挂起。它永远不会完成执行，甚至从未提交给AWS Sagemaker，因为UI和CLI在我检查时都没有显示培训工作。
这是我正在使用的代码，删除了敏感信息：
 ＃导入模块
进口sagemaker
来自sagemaker.huggingface导入huggingface
导入记录

＃故障排除错误
loggging.getLogger（“ sagemaker”）。setlevel（logging.debug）

＃创建会话
session = sagemaker.session（）

＃配置AWS角色
角色= [aws arn]

＃配置各种登录信息
git_config = {
    [存储库登录信息]
}
HF_Token = [HuggingFace登录信息]

＃配置培训容器
打印（“创建估算器对象...”）
估算器= huggingface（
    角色=角色，
    会话=会话，
    instance_count = 1，
    source_dir =;
    py_version =&#39;py310&#39;，
    git_config = git_config，
    entry_point =; train.py;＃＃github中培训脚本的名称
    unignts_file =&#39;sumperient.it.txt＆quot;＃安装其他软件包
    output_path =&#39;s3：// llama-data/model-o-output/&#39;，＃模型检查点的输出
    instance_type =＆quot; ml.p3.2xlarge＆quort＆quort
    环境= {
        “ hf_token”：hf_token
    }，，
    enable_sagemaker_metrics = true，＃log in CloudWatch
    image_uri =&#39;7631043518844.dkr.us-east-1.amazonaws.com/huggingface-pytorch-训练：2.1.0-transformers4.36.36.0-gpu-py310-cu121-cu121-ubuntu20.04&#39;
    hyperparameters = none，＃在train.py中声明的所有超帕拉姆
    triench_repository_access_mode =&#39;platform&#39;＃docker映像在亚马逊ecr中
）
打印（“估算值对象成功创建”

＃配置培训/验证数据
train_input = sagemaker.inputs.traininginput（
    s3_data =; s3：// llama-data/train/＆quot;
    content_type =&#39;text/csv＆quot;
）

验证_input = sagemaker.inputs.trainingInput（
    s3_data =; s3：// llama-data/validate/＆quot;
    content_type =&#39;text/csv＆quot;
）

＃调试：提交前打印萨吉式制造商培训请求
＃request_dict = inestator.latest_training_job.describe_request（）
打印（“ SageMaker培训工作请求：&#39;estemator.latest_training_job）＃**这总是打印“无”，不提交请求**

打印（“呼叫.fit（）...;）
interator.fit（{＃**脚本停止在这一点上工作**
    ＆quot“ train＆quot”：train_input，
    ＆quot“ veration＆quot”：validation_input
}，wait = true，job_name =＆quort; train-llama-small＆quord＆quort＆quots =; quot; all＆quot;
打印（成功创建了培训工作。退出脚本。”）
 
创建估算器后，我尝试列出最新的培训工作，并打印出来：
 估算对象成功创建了
Sagemaker培训工作要求：无
 
当脚本挂断时，这是我在终端中看到的消息：
 您的分支与“原始/主”最新。
[03/07/25 09:31:21]使用提供的S3_Resource fw_utils.py:474进行调试
[03/07/25 09:31:22] Debug Train Arg在处理Exterator.py:2513
                             默认值：
 
，然后列出了会话的所有培训参数。我尝试拔出其他码头图像，以查看是否会改变任何东西，没有效果。
我做错了什么，因为培训工作从未真正创建？]]></description>
      <guid>https://stackoverflow.com/questions/79492869/why-is-aws-sagemaker-not-submitting-a-training-job-when-i-create-an-estimator-ob</guid>
      <pubDate>Fri, 07 Mar 2025 16:07:57 GMT</pubDate>
    </item>
    <item>
      <title>实施心理健康监测的设备ML模型（文本，音频和行为分析）[封闭]</title>
      <link>https://stackoverflow.com/questions/79479223/implementing-on-device-ml-models-for-mental-health-monitoring-text-audio-and</link>
      <description><![CDATA[我正在开发一个分析设备的心理健康监测系统：
  1。文本输入分析  - 来自类型消息的情感分析和情感语调检测。
  2。音频分析 -  从语音记录中检测压力，焦虑和情绪。
  3。搜索历史记录＆amp;行为分析 -  识别浏览模式的变化，可能表明困扰。
 约束： 
必须完全在设备上运行（无云API）。
需要轻巧并在移动/边缘设备上工作。
 我的挑战： 
为每个任务选择合适的ML型号/框架，可以有效地运行在设备上。
预处理和特征提取技术用于实时分析。
优化推理速度而不会损害精度。
我有一些基本的ML知识，但以前从未实施完整的ML管道。对框架，模型选择和实施策略的任何指南将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/79479223/implementing-on-device-ml-models-for-mental-health-monitoring-text-audio-and</guid>
      <pubDate>Sun, 02 Mar 2025 14:19:08 GMT</pubDate>
    </item>
    <item>
      <title>在这种情况下，为什么单次编码会具有更差的准确性？</title>
      <link>https://stackoverflow.com/questions/77610686/why-does-the-one-hot-encoding-give-worse-accuracy-in-this-case</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77610686/why-does-the-one-hot-encoding-give-worse-accuracy-in-this-case</guid>
      <pubDate>Wed, 06 Dec 2023 05:12:08 GMT</pubDate>
    </item>
    <item>
      <title>从keras.engine.topolgy导入网络的错误</title>
      <link>https://stackoverflow.com/questions/70239943/error-to-import-network-from-keras-engine-topolgy</link>
      <description><![CDATA[我通过降低keras（pip install&#39;keras == 2.1.6&#39; -  force-redinstall）来安装拓扑软件包，因为它在较新版本中不存在。我仍在遇到一个错误以导入网络。
 尝试：
来自Keras.Engine.Topology进口网络

错误：
Importerror：无法从&#39;keras.engine.topology&#39;导入名称&#39;网络&#39;（/usr/local/lib/python3.7/dist-packages/keras/engine/engine/topology.py）
 
如果不存在网络，则如何获得该代码（Cyclegan）可以使用Network（）。任何帮助将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/70239943/error-to-import-network-from-keras-engine-topolgy</guid>
      <pubDate>Mon, 06 Dec 2021 01:12:32 GMT</pubDate>
    </item>
    <item>
      <title>训练和测试数据的分配方式 - 张孔上的keras</title>
      <link>https://stackoverflow.com/questions/51006505/how-training-and-test-data-is-split-keras-on-tensorflow</link>
      <description><![CDATA[我目前正在使用神经网络训练我的数据并使用拟合功能。
  history = model.fit（x，encoded_y，batch_size = 50，nb_epoch = 500，verialation_split = 0.2，verbose = 1）
 
现在，我已经使用验证_split 作为 20％。我了解的是，我的培训数据将为 80％，测试数据将为 20％。我很困惑这些数据在后端如何处理。它是否会像Top  80％的样品进行训练，并且低于20％的20％用于测试，或者样品是从介于两者之间随机选择的？如果我想提供单独的培训和测试数据，我将如何使用 model.fit（） ?? 进行操作。
此外，我的第二个问题是如何检查数据是否适合模型？从结果我可以看出，训练精度约为 90％，而验证精度约为 55％。这是否意味着过度安装或不合格的情况？
我的最后一个问题是评估回报是什么？文档表示它返回损失，但我已经在每个时期期间都会获得损失和准确性（作为fit的回报（）（在 history 中））。评估表演返回的精度和得分如何？如果通过评估返回 90％返回的准确性，我可以说我的数据很合适，无论每个时期的个人准确性和损失是什么？？
以下是我的代码：
 导入numpy
进口熊猫
导入matplotlib.pyplot作为PLT
来自keras.models导入顺序
来自keras.layers导入密集，辍学
来自keras.wrappers.scikit_learn导入kerasclassifier
来自sklearn.model_selection导入cross_val_score
从Sklearn.Preprocessing Import LabElenCoder
来自sklearn.model_selection导入stratifiedkfold
从sklearn.prepercorsing进口标准标准
来自Sklearn.Pipeline Import Pipeline
来自keras.utils导入np_utils
来自sklearn.model_selection导入kfold
来自sklearn.metrics导入混乱_matrix
导入Itertools

种子= 7
numpy.random.seed（种子）

dataframe = pandas.read_csv（&#39;inputfile.csv＆quort; skiprows = range（0，0））

dataset = dataframe.values
x = dataset [：，0：50] .astype（float）＃cols-1的数量
y =数据集[：，50]

encoder = labelencoder（）
coder.fit（y）
encoded_y = encoder.transform（y）

encoded_y = np_utils.to_categorical（encoded_y）
打印（&#39;encoded_y =＆quot; encoded_y） 
＃基线模型
def create_baseline（）：
    ＃创建模型
    型号=顺序（）
    model.Add（密集（5，input_dim = 5，kernel_initializer =&#39;normal&#39;，activation =&#39;relu&#39;））
    model.Add（密集（5，kernel_initializer =&#39;normal&#39;，activation =&#39;relu&#39;））
    ＃model.Add（密集（2，kernel_initializer =&#39;normal&#39;，activation =&#39;sigmoid&#39;）））））

    model.Add（密集（2，kernel_initializer =&#39;normal&#39;，activation =&#39;softmax&#39;）））））

    ＃编译模型
    model.compile（loss =&#39;binary_crossentropy&#39;，优化器=&#39;adam&#39;，metrics = [&#39;fecicy&#39;]）＃for binayr分类
        ＃model.compile（loss =&#39;cancorical_crossentropopy&#39;，importizer =&#39;adam&#39;，metrics = [&#39;cocuctiacy&#39;]）＃for Multi类
    返回模型
    

model = create_baseline（）;
历史= model.fit（x，encoded_y，batch_size = 50，nb_epoch = 500，验证_split = 0.2，冗长= 1）

print（history.history.keys（））
＃列出历史记录中的所有数据
print（history.history.keys（））
＃总结历史的准确性
plt.plot（历史学家[&#39;acc&#39;]）
plt.plot（history.history [&#39;val_acc&#39;]）
plt.title（“模型精度”）
plt.ylabel（“准确性”）
plt.xlabel（&#39;epoch&#39;）
plt.legend（[&#39;train&#39;，&#39;test&#39;]，loc =“左上”）
plt.show（）
＃总结损失的历史
plt.plot（历史学家[&#39;损失&#39;]）
plt.plot（历史学家[&#39;val_loss&#39;]）
plt.title（“模型损失”）
plt.ylabel（“损失”）
plt.xlabel（&#39;epoch&#39;）
plt.legend（[&#39;train&#39;，&#39;test&#39;]，loc =“左上”）
plt.show（）


pre_cls = model.predict_classes（x）    
cm1 = Confusion_matrix（encoder.transform（y），pre_cls）
打印（&#39;混淆矩阵：\ n&#39;）
打印（CM1）


得分，acc = model.evaluate（x，encoded_y）
打印（“测试分数：”，分数）
打印（“测试准确性：”，ACC）
 ]]></description>
      <guid>https://stackoverflow.com/questions/51006505/how-training-and-test-data-is-split-keras-on-tensorflow</guid>
      <pubDate>Sun, 24 Jun 2018 02:28:07 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn.decomposition.pca的特征向量的简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我正在尝试了解主组件分析的工作方式，并且我正在 sklearn.datasets.load_iris  dataset上对其进行测试。  我了解每个步骤的工作原理（例如，使用 k 选定的尺寸，将数据，协方差，特征分类，对最高特征值进行排序，将原始数据转换为新轴）。）。
下一步是可视化这些 eigenVectors 在数据集中投射到（在 pc1 vs. pc2 vs. pc2 plot 上，对吗？）。。
有人可以解释如何在缩小尺寸数据集的3D图上绘制[PC1，PC2，PC3]特征向量？
另外，我是否正确绘制了此2D版本？我不确定为什么我的第一个特征向量的长度较短。  我应该乘以特征值吗？

 这是我为实现这一目标所做的一些研究： 
我关注的PCA方法来自：
 https://plot.ly/ipython-notebooks/principal-component-analysis/#shortcut--pca-in-scikit-learn （尽管我不想使用 Plotly 我想坚持使用。
我一直在关注本教程，以绘制特征向量，这似乎很简单： pca for matplotlib 基本示例
我找到了这个，但是我试图做的事情似乎过于复杂，我不想创建一个 fancyarrowpatch ： 的协方差矩阵

 我试图使我的代码尽可能直接地遵循其他教程： 
 导入numpy作为NP
导入大熊猫作为pd
导入matplotlib.pyplot作为PLT
来自sklearn.datasets import load_iris
从sklearn.prepercorsing进口标准标准
来自Sklearn进口分解
进口海洋为SNS； sns.set_style（&#39;whitegrid＆quort; {&#39;axes.grid&#39;：false}）

％matplotlib内联
np.random.seed（0）

＃虹膜数据集
df_data = pd.dataframe（load_iris（）。数据， 
                       index = [＆quot; iris_％d＆quot; ％i for i在范围内（load_iris（）。data.shape [0]）]，
                       列= load_iris（）。feature_names）

se_targets = pd.Series（load_iris（）。目标， 
                       index = [＆quot; iris_％d＆quot; ％i for i在范围内（load_iris（）。data.shape [0]）]， 
                       名称=“物种”

＃缩放平均= 0，var = 1
df_standard = pd.dataframe（standardscaler（）。fit_transform（df_data）， 
                           index = df_data.index，
                           列= df_data.columns）

＃用于主要组合分析的Sklearn

＃昏暗
m = df_standard.shape [1]
k = 2

＃PCA（我倾向于设置它）
m_pca = demomposition.pca（n_components = m）
df_pca = pd.dataframe（m_pca.fit_transform（df_standard）， 
                列= [＆quot; pc％d＆quot;范围内K的％k（1，m + 1）]）。iloc [：，：k]


＃绘制特征向量
#https：//stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

＃这是东西很奇怪的地方...
data = df_standard

mu = data.mean（轴= 0）
eigenVectors，eigenvalues = m_pca.components_，m_pca.explained_variance_ #eigenVectors，eigenvalues，v = np.linalg.svd（data.t，fult_matrices = false）
Projected_data = df_pca＃np.dot（数据，特征向量）

sigma = Projected_data.std（axis = 0）.mean（）

图，ax = plt.subplots（figsize =（10,10））
ax.Scatter（Projected_data [＆quot; pc1;]，Projected_data [＆quot; pc2＆quot;]）
对于轴，zip中的颜色（eigenVectors [：k]，[red&#39;&#39;
＃开始，end = mu，mu + sigma *轴###导致“ valueerror：太多值无法打开（预期2）”

    ＃所以我尝试过，但我认为这是不对的
    start，end =（mu）[：k]，（Mu + Sigma * Axis）[：K] 
    ax.annotate（&#39;&#39;，xy = end，xytext = start，arrowprops = dict（faceColor = color，width = 1.0））
    
ax.set_aspect（&#39;quare&#39;）
plt.show（）
 
  &lt;img alt =“在此处输入图像描述” src =“ https://i.sstatic.net.net/t9st0.png”]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    <item>
      <title>为什么我会获得负面信息收益？ [关闭]</title>
      <link>https://stackoverflow.com/questions/31362320/why-am-i-getting-a-negative-information-gain</link>
      <description><![CDATA[一个人会获得负面信息增益是没有意义的。
但是，基于此示例，我获得了负面信息增益。
这是数据：
  
，如果我计算有关湿度属性的信息增益，我会得到：
  
显然我在这里缺少一些东西。
编辑
澄清我的理解。
整个系统的熵定义为：
  
在这种情况下是：
  
和每个属性的信息增益定义为：
  
对于湿度，我计算为：
系统的熵 - （1/4）湿度正常的熵 - （3/4）湿度高的熵
根据这个libre办公室计算：
  
还是我对属性信息获得的公式的理解是不正确的吗？
解决
我的错误是我没有意识到如果所有类型都是熵，则熵为0。因此，如果一切都是正的，则熵为0，如果全部为负，则也为零。如果相等的量为正且负数，则熵为1。]]></description>
      <guid>https://stackoverflow.com/questions/31362320/why-am-i-getting-a-negative-information-gain</guid>
      <pubDate>Sat, 11 Jul 2015 22:08:45 GMT</pubDate>
    </item>
    <item>
      <title>训练单层感知器时的激活功能[封闭]</title>
      <link>https://stackoverflow.com/questions/515568/activation-function-when-training-a-single-layer-perceptron</link>
      <description><![CDATA[当训练多层神经网络时，使用sigmoidal激活功能才能有效学习。 
训练单层 layer perceptron时，使用sigmoidal激活函数是否有任何优势，或者是一个简单的步骤（Heaviside）函数足够（甚至更可取）？]]></description>
      <guid>https://stackoverflow.com/questions/515568/activation-function-when-training-a-single-layer-perceptron</guid>
      <pubDate>Thu, 05 Feb 2009 11:50:30 GMT</pubDate>
    </item>
    </channel>
</rss>