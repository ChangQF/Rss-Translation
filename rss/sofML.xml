<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 14 Feb 2024 06:18:59 GMT</lastBuildDate>
    <item>
      <title>如何通过部分重新训练 LSTM 网络的某一层来实现迁移学习？</title>
      <link>https://stackoverflow.com/questions/77991684/how-to-implement-transfer-learning-by-re-training-partially-a-certain-layer-of-a</link>
      <description><![CDATA[我有一个由两层组成的 LSTM 网络。我试图通过部分重新训练网络的第一层（仅重新训练网络第一层中随机的一些权重）来执行迁移学习。我加载了之前训练的 LSTM 模型的权重。我将第二层设置为不可训练。对于第一层，我只想重新训练一定比例的权重（假设只重新训练 10% 的权重，从第一层中随机选择），并且我希望第一层中的其余权重为无法训练。
部分代码如下。我也不完全确定是否需要考虑 unit_index= i //4。
&lt;前&gt;&lt;代码&gt;模型 = 顺序()
model.add(LSTM(12, input_shape=(NUM_IN_SEQUENCE,4), 激活 = “tanh”, recurrent_initializer=&#39;正交&#39;, return_sequences=True, use_bias=True))
model.add(LSTM(6, input_shape=(NUM_IN_SEQUENCE,4), 激活 = “tanh”, recurrent_initializer=&#39;正交&#39;, return_sequences=True, use_bias=True))
model.add（密集（2，激活=&#39;线性&#39;））


EarlyStop=EarlyStopping（监视器=&#39;val_loss&#39;，min_delta=0，耐心=3，详细=0，模式=&#39;自动&#39;）
回调列表 = [提前停止]

# 加载之前训练好的权重
model.load_weights(&#39;rnn_model_2.h5&#39;)


# 冻结第二层的权重
model.layers[1].trainable = False


# 随机选择第一层中 10% 的单元进行训练
Total_units_layer_1 = model.layers[0].units
num_trainable_units_layer_1 = int(0.1 * Total_units_layer_1)

# 随机选择可训练单元的索引
trainable_indices = np.random.choice(范围(total_units_layer_1)，大小=num​​_trainable_units_layer_1，替换=False)

# 分配选定的可训练单元
对于 i，枚举中的权重（model.layers[0].trainable_weights）：
    unit_index = i // 4 # 每个 LSTM 单元有 4 个权重（输入、循环、偏置和单元）
    如果可训练索引中的单位索引：
        重量._trainable = True
    别的：
        重量._trainable = False


# 组合模型
model.compile（优化器=&#39;adam&#39;，损失=&#39;mean_squared_error&#39;，指标=[&#39;mse&#39;，&#39;mae&#39;]）


回调 = [
    EarlyStoppingByLossVal(monitor=&#39;val_loss&#39;, value=2e-6, verbose=1),
]


model.fit（x_train，y_train，epochs = 50，batch_size = 64，validation_data =（x_test，y_test），callbacks =回调，详细= 1）
]]></description>
      <guid>https://stackoverflow.com/questions/77991684/how-to-implement-transfer-learning-by-re-training-partially-a-certain-layer-of-a</guid>
      <pubDate>Wed, 14 Feb 2024 01:20:30 GMT</pubDate>
    </item>
    <item>
      <title>StyleGAN 2 将损失分量乘以零，为什么？</title>
      <link>https://stackoverflow.com/questions/77991219/stylegan-2-multiplies-loss-components-with-zero-why</link>
      <description><![CDATA[我在著名的 StyleGAN 2 论文的 3.8k 星代码库中发现了一段相当奇怪的代码。
在损失函数中，他们使用以下表达式：
与 torch.autograd.profiler.record_function(name + &#39;_backward&#39;):
    (real_logits * 0 + loss_Dreal + loss_Dr1).mean().mul(增益).backward()

（他们在 行中使用类似的内容92)
将 real_logits 与 0 相乘在我看来似乎是不必要的计算开销。然而，相同的代码被其他研究人员改编，例如“MAT：用于大孔图像修复的掩模感知变压器”的作者。请参阅此处：
与 torch.autograd.profiler.record_function(name + &#39;_backward&#39;):
    ((real_logits + real_logits_stg1) * 0 + loss_Dreal + loss_Dreal_stg1 + loss_Dr1 + loss_Dr1_stg1).mean().mul(增益).backward()

我唯一的假设是他们想要一种快速的方法来初始化填充零的特定形状的矩阵。然而，这没有任何意义，因为无论如何，所有内容都会在 mean() 中结束。
这还能实现什么其他目的？]]></description>
      <guid>https://stackoverflow.com/questions/77991219/stylegan-2-multiplies-loss-components-with-zero-why</guid>
      <pubDate>Tue, 13 Feb 2024 22:34:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 IML 计算 Shapley 值时出错</title>
      <link>https://stackoverflow.com/questions/77991202/error-calculating-shapley-values-using-iml</link>
      <description><![CDATA[#训练随机森林模型
设置.种子(8431)
cvforest.train &lt;- 训练(x = 训练[, c(3:122, 124:138)], y = 训练[, 123],
                        方法＝“cforest”，度量＝“RMSE”，
                        trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 5),
                        控制= cforest_unbiased（ntree = 1000，minsplit = 5，minbucket = 5）
）

cvforest.model.train&lt;-cvforest.train$finalModel #最终模型对象

#计算 shapley 值
X &lt;- 训练[, c(3:122, 124:138)]
y &lt;- 火车[, 123]

预测器 &lt;- iml::Predictor$new(cvforest.model.train, data = X, y = y)
shapley_vals &lt;- iml::Shapley$new(预测器)

使用上面的代码，我使用 R 中的插入符号和 party 包拟合了一个随机森林模型。现在我想计算该模型的 Shapley 值。但是，当我使用上面的代码创建“shapley_vals”对象时，我发现“results”和“fit”选项为 NULL。我不确定我错过了哪些步骤。关于下一步该做什么有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77991202/error-calculating-shapley-values-using-iml</guid>
      <pubDate>Tue, 13 Feb 2024 22:29:02 GMT</pubDate>
    </item>
    <item>
      <title>人脸识别的关键点网格确定眼睛之间的距离[关闭]</title>
      <link>https://stackoverflow.com/questions/77990682/keypoints-grid-of-face-recognition-to-determine-the-distance-between-eyes</link>
      <description><![CDATA[我正在寻找人脸识别的关键点网格来确定眼睛之间的距离（以厘米为单位）。也许有人有经验或知道这个任务的预科神经网络？
实际上，另一个问题 - 寻找关键点网格以找出屏幕上的划痕（分割任务）。也许，有针对此任务的预教育神经网络？]]></description>
      <guid>https://stackoverflow.com/questions/77990682/keypoints-grid-of-face-recognition-to-determine-the-distance-between-eyes</guid>
      <pubDate>Tue, 13 Feb 2024 20:22:20 GMT</pubDate>
    </item>
    <item>
      <title>眼睛之间的距离，额头上的皱纹[关闭]</title>
      <link>https://stackoverflow.com/questions/77990495/distance-between-eyers-the-wrinkles-on-the-forehead</link>
      <description><![CDATA[我是 ML 和 NN 领域的新手。我知道使用人体测量点进行人脸识别，但没有实践。我有两个任务。

眼距的确定

我有很多不同面孔的照片。我需要确定每个人的眼睛之间的距离（以英寸为单位）。是否可以？如果不深入研究 ML，如何快速实现呢？我可以有另一个任务（眉毛之间的距离或角度）。

额头有皱纹

这是一个类似的任务。我需要在额头的其他浮雕中选择它们，并使用分辨率良好的头部照片确定它们之间的距离。
这可能吗？你能给我任何指示吗？]]></description>
      <guid>https://stackoverflow.com/questions/77990495/distance-between-eyers-the-wrinkles-on-the-forehead</guid>
      <pubDate>Tue, 13 Feb 2024 19:41:30 GMT</pubDate>
    </item>
    <item>
      <title>探索具有不相关特征的二元分类的特征选择策略：寻求多种解决方案[关闭]</title>
      <link>https://stackoverflow.com/questions/77990265/exploring-feature-selection-strategies-for-binary-classification-with-uncorrelat</link>
      <description><![CDATA[我有一个包含 100 多个不相关特征的数据集（平均相关性为 0.15）。问题是二元分类，我尝试过线性模型（套索、岭）、决策树、随机森林，因为它们需要显式特征选择，但没有一个给出好的结果。选择少数特征进行随机训练有时会产生更好的结果。我不知道如何进行功能选择。我不确定哪种算法或特征选择技术可以在这方面帮助我。我还没有尝试过神经网络和其他集成方法。
我的想法是可以有多个不同的特征组（子集），它们可以产生一个好的解决方案。我的目标是找到这样的团体。我应该如何解决这个问题以找到不是一个而是多个解决方案（产生解决方案的功能组）。目的是，这些本质上公式化的特征可以进一步优化，以获得更好的解决方案。
我尝试过线性模型（套索、岭）、决策树、随机森林，因为它们需要明确的特征选择，但没有一个给出好的结果。我也尝试过遗传算法来找到这样的群体，但是速度非常慢。]]></description>
      <guid>https://stackoverflow.com/questions/77990265/exploring-feature-selection-strategies-for-binary-classification-with-uncorrelat</guid>
      <pubDate>Tue, 13 Feb 2024 18:54:07 GMT</pubDate>
    </item>
    <item>
      <title>使用 GPytorch 的高斯过程 - 输出多于输入数据</title>
      <link>https://stackoverflow.com/questions/77990156/gaussian-processes-with-gpytorch-more-output-than-input-data</link>
      <description><![CDATA[我正在遵循基本教程https://docs.gpytorch .ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html 为以下数据训练高斯过程
train_x 是 [4058, 12] 的张量
train_y 是 [4058, 140] 的张量

计算损失时出错
loss = -mll(输出, train_y)

表示output (model(train_x)) 和train_y 没有相同的维度。鉴于此，我尝试了 MultitaskGPModel https:// /docs.gpytorch.ai/en/stable/examples/03_Multitask_Exact_GPs/Multitask_GP_Regression.html 出现非常相似的错误
运行时错误：张量 a (568120) 的大小必须与非单维 0 处张量 b (8116) 的大小匹配

显然MultitaskGPModel要求相同的条目总数相等。有没有办法培养多次入境的全科医生？]]></description>
      <guid>https://stackoverflow.com/questions/77990156/gaussian-processes-with-gpytorch-more-output-than-input-data</guid>
      <pubDate>Tue, 13 Feb 2024 18:30:57 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助将经过训练的 RNN 模型集成到另一个代码的猜测函数中</title>
      <link>https://stackoverflow.com/questions/77990150/need-help-integrating-trained-rnn-model-into-guess-function-of-another-code</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77990150/need-help-integrating-trained-rnn-model-into-guess-function-of-another-code</guid>
      <pubDate>Tue, 13 Feb 2024 18:29:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在图像+文本上训练 Tesseract？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77989712/how-to-train-tesseract-on-images-text</link>
      <description><![CDATA[我正在尝试根据我收集的数据训练一个 Tesseract 模型（从头开始）。数据是简单的文本行+它们的转录。
我的问题是文档真的很混乱。
这里有人可以帮助我或给我一些如何做的指示吗？那里没有真正的指南。]]></description>
      <guid>https://stackoverflow.com/questions/77989712/how-to-train-tesseract-on-images-text</guid>
      <pubDate>Tue, 13 Feb 2024 17:10:24 GMT</pubDate>
    </item>
    <item>
      <title>想要使用 Python 学习 Tensorflow 并想要创建预测情绪之类的模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77989448/want-to-learn-tensorflow-using-python-and-wanted-to-create-models-like-predictin</link>
      <description><![CDATA[我需要一个基本的路线图，例如如何学习和创建模型......
到目前为止我做了什么......

了解 Python 基础知识以及一些 DSA 知识。（中等水平）
了解 Tensorflow 的基础知识，例如安装、Hello World 程序、什么是张量、Tensorflow 中变量和常量的区别。
具备统计基础知识。
了解 NumPy 和 Pandas 的基础知识。

我不知道......

机器学习的一些核心概念，例如监督学习和无监督学习。
我了解线性回归的一些基础知识（基本上是如何工作的），但不知道分类等核心概念，即逻辑回归。
对 GNN 等深度学习概念的了解为零。
不知道如何使用 Tensorflow 构建神经网络。
对 CNN、RNN 等高级主题的了解为零。

我梦想创造的模型......
我基本上想创建一个机器学习模型，它可以使用心率值（可以从传感器获得）来预测或检测人类瞬间的情绪状态。
提出一些替代方法或提供一些可以实施的想法。如果提供的建议可行，我们会考虑并实施。
不知道从哪里开始以及如何开始......
需要在这个领域工作过的人的指导......]]></description>
      <guid>https://stackoverflow.com/questions/77989448/want-to-learn-tensorflow-using-python-and-wanted-to-create-models-like-predictin</guid>
      <pubDate>Tue, 13 Feb 2024 16:24:02 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法可以使用 PDF 文档训练 ML 模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77989400/is-there-a-way-i-can-train-an-ml-model-with-pdf-documents</link>
      <description><![CDATA[我计划从头开始构建一个聊天机器人，以获取法律建议和信息。也就是说，聊天机器人应该能够回答特定的法律是什么、特定情况下的法律法规是什么等等。
我想知道我是否能够使用从各种法律文章及其扩展的 PDF 创建的数据集来完成此操作。如果可以的话，能详细说明一下步骤吗？我是这个领域的初学者，不知道从哪里开始。
我从 Github 发现了三种不同的数据集 - 一种是 PDF 文档，一种是 json 文件（带有指令、输入、输出和提示字段），另一种是 .md 文件。哪个数据集更容易处理？]]></description>
      <guid>https://stackoverflow.com/questions/77989400/is-there-a-way-i-can-train-an-ml-model-with-pdf-documents</guid>
      <pubDate>Tue, 13 Feb 2024 16:14:46 GMT</pubDate>
    </item>
    <item>
      <title>knn手动计算与R类包的比较</title>
      <link>https://stackoverflow.com/questions/77987372/knn-manual-calculation-vs-r-class-package</link>
      <description><![CDATA[为了更好地理解 kNN 方法，我想手动复制 R 使用 class 包的 knn 函数所做的事情。
首先，可以在此处获取数据https://github.com/NPejovicE/kNN。它是一个 csv 文件，包含 3 个类别的交通标志：pedestrian、speed 和 stop。为了解释数据集，假设标志被分为 16 块，每块中心的颜色用 r/g/b 颜色代码测量。因此，每个标志有 48 列 (16 x 3)。数据分为训练数据集和测试数据集。
signs %&gt;% filter(sample == &quot;train&quot;) -&gt; &gt;训练数据
标志%&gt;%过滤器(样本==“测试”)-&gt;测试数据

我想根据测试数据预测第 12 行。
test_data %&gt;% slice(12) %&gt;% select(4:ncol(test_data)) -&gt;我的测试

我将通过 R 中的“类包”进行 kNN 分类：
knn(train_data[4:ncol(train_data)], unlist(my_test), cl = train_data$sign_type)

行人
级别：行人限速

它说这是行人。
现在，我将尝试手动计算缩放值的欧几里得距离。我将仅使用训练和测试数据中所需的列，并从测试数据中提取第 12 行。
train_data[4:ncol(train_data)] -&gt;训练数据清理
test_data[4:ncol(test_data)] -&gt;测试数据清理

as.data.frame(scale(train_data_clean)) -&gt;;缩放训练
as.data.frame(scale(test_data_clean)) -&gt;;缩放测试

scaled_test %&gt;% 切片(12) -&gt;测试行

现在逐步计算距离：
scaled_train - unlist(test_row) -&gt;差异
# 平方差异：
diff^2 -&gt;差异2
# 行间求和：
rowSums(diff2) -&gt;;差异3
# 取平方根：
sqrt(diff3) -&gt;;差异4
# 查找具有最小值的行。
其中.min(diff4) -&gt; n

它说我的 train_data 第 72 行具有最小距离。
当我回顾我的原始列车数据时，它是：
 train_data %&gt;% slice(72) %&gt;% select(sign_type)

它是 stop 而不是类包中的 pedestrian。
我如何从类包中复制结果，我在这里做错了什么吗？
编辑：
即使我用训练数据的平均值和标准差标准化 test_data，结果仍然不同。我从train_data_clen中减去test_data_clen中每一列的相应平均值，然后除以相应列的sd。
#计算列均值和标准差：

取消列表（sapply（train_data_clean，平均值））-&gt;方法
取消列表（sapply（train_data_clean，sd））-&gt;安全数据表

#从 test_data 中的每个观察结果中减去平均值：

as.data.frame(sapply(1:ncol(test_data_clean), function(i) test_data_clean[, i] -means[i])) -&gt;;数据2

#除以sd：
as.data.frame(sapply(1:ncol(data2), function(i) data2[,i]/sds[i])) -&gt;;测试数据标准化


# 重复计算欧氏距离的过程：

test_data_standardized %&gt;% 切片(12) -&gt;测试行
scaled_train - 取消列表（test_row） -&gt;差异
# 平方差异：
diff^2 -&gt;差异2
# 行间求和：
rowSums(diff2) -&gt;;差异3
# 取平方根：
sqrt(diff3) -&gt;;差异4
# 查找具有最小值的行。
其中.min(diff4) -&gt; n

其类型为speed（第 52 行）。]]></description>
      <guid>https://stackoverflow.com/questions/77987372/knn-manual-calculation-vs-r-class-package</guid>
      <pubDate>Tue, 13 Feb 2024 10:58:23 GMT</pubDate>
    </item>
    <item>
      <title>尝试对象检测时出现 opencv 错误</title>
      <link>https://stackoverflow.com/questions/77982625/getting-opencv-errors-while-trying-object-detection</link>
      <description><![CDATA[这是我的代码：
&lt;前&gt;&lt;代码&gt;导入cv2
将 cvlib 导入为 cv

从 cvlib.object_detection 导入draw_bbox
将张量流导入为 tf
打印（tf.__版本__）
#从 gtts 导入 gTTS
#from Playsound 导入 Playsound

视频 = cv2.VideoCapture(0)

# 检查网络摄像头是否打开成功
如果不是 video.isOpened():
    print(“错误：无法打开网络摄像头。”)
    出口（）
别的：
    print(&quot;检测到相机&quot;)
而真实：
    ret, 帧 = video.read()
    打印（框架）
    bbox、标签、conf = cv.detect_common_objects(frame)
    输出图像=绘制_bbox（框架，bbox，标签，conf）

    cv2.imshow(“目标检测”,output_image)

    如果 cv2.waitKey(1) &amp; 0xFF == ord (“q”)：
        休息

我收到以下错误：cv2.error: OpenCV(4.9.0) D:\a\opencv-python\opencv-python\opencv\modules\dnn\src\darknet\darknet_io.cpp： 705：错误：（-215：断言失败）separator_index &lt;函数“cv::dnn::darknet::ReadDarknetFromCfgStream”中的 line.size()
我尝试导航到错误中指定的文件，但我的计算机上没有 D 驱动器，因此我不知道如何找到它。我尝试重新安装 OpenCV 但没有帮助。我在网上看到，导航到该文件并直接编辑它可以解决人们的问题，但我首先如何导航到它。]]></description>
      <guid>https://stackoverflow.com/questions/77982625/getting-opencv-errors-while-trying-object-detection</guid>
      <pubDate>Mon, 12 Feb 2024 15:44:27 GMT</pubDate>
    </item>
    <item>
      <title>如何包装 keras 模型以供 scikit-learn 堆叠集成使用</title>
      <link>https://stackoverflow.com/questions/77982056/how-to-wrap-keras-models-for-scikit-learn-stacking-ensemble-usages</link>
      <description><![CDATA[我有一个已经训练过的 keras 模型列表。我想在 scikit learn 中将它们与 StackingClassifier 一起使用。由于 keras 没有 Predict_proba 方法，我创建了一个包装器。
如果使用我的为 VotingClassifier 包装的模型以及软方法和硬方法，它就可以工作。
但是当我使用堆叠模型时，第一次运行后，它会向我显示此错误。我没有找到任何相关信息。
类 KerasWrapperWithEncoder(BaseEstimator, ClassifierMixin):
    def __init__(自身，keras_model，classes_)：
        self.keras_model = keras_model
        self.encoder = OneHotEncoder(sparse_output=False)
        # L&#39;encoder OneHotEncoder 已经过去了
        self.classes_ = classes_ # 定义可分配类

    def fit(自身, X, y):
        # 模型已安装，不再适合
        y_reshape = y.reshape(-1, 1)
        self.encoder.fit(y_reshape)
        返回自我

    def 预测（自身，X）：
        # 利用 les modèles entraînés pour faire des predictions
        预测 = self.keras_model.predict(X)
        np_argmax = np.argmax(预测，轴=1)
        打印（预测）
        打印（np_argmax）
        返回 np_argmax

    def Predict_proba(自身, X):
        # 返回分类模型的类别概率
        概率 = self.keras_model.predict(X)
        print(&quot;概率形状：&quot;, probabilities.shape) # 调试
        返回概率


keras_wrapped_models_with_encoder = [
    (name.replace(&#39; &#39;, &#39;_&#39;).replace(&#39;__&#39;, &#39;_&#39;), KerasWrapperWithEncoder(model, _target_classes_))
    对于 keras_models.items() 中的名称、模型
]

vote_clf = 投票分类器(
         估计器=all_估计器，
         投票=&#39;软&#39;，
         n_职位=3，
         详细=真）
vote_clf .fit(X_train, y_train) # 完美运行

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
keras_stacking_models_current_year = StackingClassifier(
    估计器=all_估计器，
    Final_estimator=LogisticRegression(),
    简历=简历，
    详细=3，
    # n_jobs=2
）


keras_stacking_models_current_year.fit(X_train, y_train) # 抛出错误


&lt;前&gt;&lt;代码&gt;========================================stacking_models_all_models===== =======================
12105/12105 [================================] - 25s 2ms/步
概率形状：(387348, 3)
训练折叠 (1) 中的类数与类总数 (3) 不匹配。结果可能不适合您的用例。要解决此问题，请使用交叉验证技术来产生正确分层的折叠
_enforce_prediction_order（类、预测、n_classes、方法）
   第1457章
   第1458章）
-&gt;第1459章
   第1460章 1460
   第1461章 回归预测

ValueError：形状不匹配：形状（387348,3）的值数组无法广播到形状（387348,1,3）的索引结果
]]></description>
      <guid>https://stackoverflow.com/questions/77982056/how-to-wrap-keras-models-for-scikit-learn-stacking-ensemble-usages</guid>
      <pubDate>Mon, 12 Feb 2024 14:12:27 GMT</pubDate>
    </item>
    <item>
      <title>为什么 VAE 损失没有收敛到零？</title>
      <link>https://stackoverflow.com/questions/69926777/why-vae-loss-doesn-t-converge-to-zero</link>
      <description><![CDATA[我正在使用变分自动编码器，这是我对损失函数的实现：
类变分自动编码器（nn.Module）：
    # ...一些功能...

    def gaussian_likelihood(self, x_hat, logscale, x):
        刻度 = torch.exp(logscale)
        平均值 = x_hat
        dist = torch.distributions.Normal(平均值，尺度)
        # 测量在 p(x|z) 下看到图像的概率
        log_pxz = dist.log_prob(x)
        返回 log_pxz.sum(dim=(1, 2, 3))

    def 前向（自身，输入）：
        mu, logvar = self.encode(输入)
        z = self.reparameterise(mu, logvar)
        返回 self.decoder(z), mu, logvar, z

    def loss_function(self, x_hat, x, mu, logvar, β=1):
        std = torch.exp(logvar / 2)
        q = torch.distributions.Normal(mu, std)
        z = q.rsample()

        # 重建损失
        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)

        # 吉隆坡
        kl = self.kl_divergence(z, mu, std)

        #埃尔博
        elbo = (kl - 侦察损失)
        elbo = elbo.mean()
        返回埃尔博

    def kl_divergence(self, z, mu, std):
        # --------------------------
        # 蒙特卡罗 KL 散度
        # --------------------------
        # 1. 定义前两个概率（在本例中均为正态概率）
        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))
        q = torch.distributions.Normal(mu, std)

        # 2. 从方程中得到概率
        log_qzx = q.log_prob(z)
        log_pz = p.log_prob(z)

        # 吉隆坡
        kl = (log_qzx - log_pz)
        kl = kl.sum(-1)

        返回吉隆坡

退出解码器时我使用 Sigmoid() 函数。我以这种方式训练模型：
对于范围（0，纪元 + 1）中的纪元：
        如果纪元&gt; 0: # 首先测试未经训练的网络
            模型.train()
            训练损失 = 0
            循环= tqdm（train_loader）
            优化器 = model.setOptimizer(model)
            for x 循环：
                x = x.to(设备)
                x_hat、mu、logvar、特征 = 模型（x）
                损失 = model.loss_function(x_hat, x, mu, logvar)
                train_loss += loss.item()
                优化器.zero_grad()
                loss.backward()
                优化器.step()
                循环.set_postfix(损失=损失)
            train_loss = train_loss /= len(train_loader.dataset)
            print(f&#39;====&gt; Epoch: {epoch} 平均损失: {train_loss:.4f}&#39;)

损失不会稳定为零，而是变为负值（大约 -2）。如果我删除 train_loss = train_loss /= len(train_loader.dataset)，它就会完全偏离。
怎样才能让损失收敛到零？]]></description>
      <guid>https://stackoverflow.com/questions/69926777/why-vae-loss-doesn-t-converge-to-zero</guid>
      <pubDate>Thu, 11 Nov 2021 10:31:58 GMT</pubDate>
    </item>
    </channel>
</rss>