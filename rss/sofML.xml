<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 04 Jan 2024 15:15:35 GMT</lastBuildDate>
    <item>
      <title>不完全理解梯度是如何计算的。我的计算（手工）和约定的梯度公式是不同的</title>
      <link>https://stackoverflow.com/questions/77759064/dont-fully-understand-how-gradients-are-to-be-calculated-my-calculation-by-ha</link>
      <description><![CDATA[我正在尝试实现一个多层感知器，而不使用任何外部库来获得反向传播的直觉。我现在可以自信地说我理解了这个算法。但问题是：我试图手动推导出所有梯度计算方程，但它们并不成立。他们错了。
为了获得更多上下文，我使用交叉熵损失。
例如：
loss = -np.sum(true_labels * np.log(outputs)) / m

然后我们计算这个损失相对于输出的梯度，如下所示：
&lt;预&gt;&lt;代码&gt;dz2 = (1/m) * (-标签/Z2)

但是我在任何地方看到这个特定的梯度都是由以下给出的：
dz2 = Z2 - 标签

我不会进入下一个渐变，因为我认为一旦我明白我在这里做错了什么，这将是解锁其余部分的关键。
更多背景信息：正在 MNIST 数据集、10 个类、1 个隐藏层上进行训练。]]></description>
      <guid>https://stackoverflow.com/questions/77759064/dont-fully-understand-how-gradients-are-to-be-calculated-my-calculation-by-ha</guid>
      <pubDate>Thu, 04 Jan 2024 14:36:45 GMT</pubDate>
    </item>
    <item>
      <title>将大型语料库中的 n 元模型加载到集合中时如何避免内存问题</title>
      <link>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</link>
      <description><![CDATA[我一直在尝试实现一种无监督学习算法，该算法根据从语料库中提取的特定特征来匹配相似性。一个用例是作者识别。该算法的工作方式是从训练语料库中提取不同类型的 n-gram，然后每个作者都会获得一个“指纹”。基于文章中出现的 n 元语法。
为此，我首先需要收集训练语料库中存在的所有 n 元语法。这就是我遇到内存问题的地方，我一直在使用 Yelp 评论数据，并且在某些时候我的程序由于内存限制而崩溃。我尝试过存储中间结果，然后将 n-gram 加载到最终集合中，以避免我的稀疏计算中出现任何潜在的内存泄漏问题，但这也失败了，看来该集合太大了。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/77758125/how-to-circumvent-memory-issues-when-loading-n-grams-from-large-corpus-into-set</guid>
      <pubDate>Thu, 04 Jan 2024 12:00:51 GMT</pubDate>
    </item>
    <item>
      <title>出现错误不知道如何解决请解决？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77757272/error-occurred-i-dont-know-how-to-solve-please-solve</link>
      <description><![CDATA[src.exception.CustomException：python 脚本名称 [c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py] 行号 [18] 错误消息中发生错误 [ python 脚本名称 [c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py] 行号 [52] 错误消息中发生错误 [pickle 中的节点数组具有不兼容的 dtype：
- 预期：{&#39;names&#39;：[&#39;left_child&#39;，&#39;right_child&#39;，&#39;feature&#39;，&#39;threshold&#39;，&#39;impurity&#39;，&#39;n_node_samples&#39;，&#39;weighted_n_node_samples&#39;，&#39;missing_go_to_left&#39;]，&#39;formats&#39;：[&#39;&lt; i8&#39;、&#39;

回溯（最近一次调用最后一次）
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py”，第 52 行，位于 load_object
返回pickle.load(file_obj)
       ^^^^^^^^^^^^^^^^^^^^^^^
文件“sklearn\tree\_tree.pyx”，第 728 行，位于 sklearn.tree._tree.Tree.__setstate__
文件“sklearn\tree\_tree.pyx”，第 1434 行，位于 sklearn.tree._tree._check_node_ndarray
在处理上述异常的过程中，又出现了一个异常：
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py”，第 18 行，在预测中
模型=加载对象（模型路径）
      ^^^^^^^^^^^^^^^^^^^^^^^^
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py”，第 55 行，位于 load_object
引发 CustomException(e,sys)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
在处理上述异常的过程中，又出现了一个异常：
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 1478 行，在 __call__ 中
返回 self.wsgi_app（环境，start_response）
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 1458 行，在 wsgi_app 中
响应 = self.handle_exception(e)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 1455 行，在 wsgi_app 中
响应 = self.full_dispatch_request()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 869 行，在 full_dispatch_request 中
rv = self.handle_user_exception(e)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 867 行，在 full_dispatch_request 中
rv = self.dispatch_request()
     ^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\mishr\AppData\Roaming\Python\Python312\site-packages\flask\app.py”，第 852 行，dispatch_request
返回 self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\application.py”，第 33 行，位于 Predict_datapoint
pred=predict_pipeline.predict(final_new_data)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py”，第 28 行，在预测中
引发 CustomException(e,sys)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
src.exception.CustomException：python 脚本名称中发生错误 [c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\pipelines\prediction_pipeline.py] 行号 [18] 错误消息 [python 脚本名称中发生错误[c:\Users\mishr\OneDrive\Desktop\DaimondPricePrediction\DiamondPricePrediction2\src\utils.py] 行号 [52] 错误消息 [pickle 中的节点数组具有不兼容的 dtype：
- 预期：{&#39;names&#39;：[&#39;left_child&#39;，&#39;right_child&#39;，&#39;feature&#39;，&#39;threshold&#39;，&#39;impurity&#39;，&#39;n_node_samples&#39;，&#39;weighted_n_node_samples&#39;，&#39;missing_go_to_left&#39;]，&#39;formats&#39;：[&#39;&lt; i8&#39;、&#39;]]></description>
      <guid>https://stackoverflow.com/questions/77757272/error-occurred-i-dont-know-how-to-solve-please-solve</guid>
      <pubDate>Thu, 04 Jan 2024 09:53:16 GMT</pubDate>
    </item>
    <item>
      <title>Bigquery ML，用于表中分区的多个线性回归模型</title>
      <link>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</link>
      <description><![CDATA[任务
我想使用 bigquery ml 对表中的分区执行多元线性回归，最好使用 dbt 实现。
背景
该表包含 customer_key、c​​ategory、week_key 和花费。应为每个分区计算回归线：customer_key 和类别，按周升序排序。这样，每个类别的每个客户都可以获得该分区内几周内支出趋势的斜率系数。实际上，我需要每个分区一个回归模型，而不是整个表一个回归模型。回归模型的数量估计约为 1 亿个。因此，我想使用 bigquery 来实现工作负载的并行化。

最终结果应该是一个表，其中包含：所有客户的 customer_key、类别、斜率。

此外，我使用 dbt 来运行所有模型，并使用 bigquery 作为数据的计算和存储。因此，我想使用dbt来实现该解决方案。
研究
通过与各个 llms 的聊天，他们似乎建议结合使用程序语句和跨每个分区的 for 循环来执行回归。但是，我想并行化计算。从这个问题 bigquery ML: Running a regression per group and全部组合起来，似乎“BQML 目前不支持在单个 CREATE MODEL 语句中指定不同的组 id 进行回归。”。
创建临时表partitioned_data AS
选择 customer_key、类别、week_key、支出
来自你的表
按客户键分组，类别；

DECLARE partition_list ARRAY&gt;；
开始
-- 迭代暂存表中的每个分区
FOR 分区 IN (
  选择客户键，类别
  FROM 分区数据
  按客户键分组，类别
 ）
 环形
   -- 提取当前分区的数据
 DECLARE partition_data ARRAY&gt;；
 开始
  FOR week_data IN (
    选择 week_key，花费
    FROM 分区数据
    WHERE customer_key = 分区.customer_key
    AND 类别 = 分区.类别
  ）
  环形
    array_append(partition_data, week_data);
  结束循环；
结尾

-- 为当前分区创建模型
创建或替换模型 my_model
选项（
  model_type = &#39;线性回归&#39;,
  标签=&#39;花费&#39;，
  特征 = &#39;week_key&#39;
）
作为
选择 *
FROM UNNEST(partition_data);
结束循环；
结尾;

创建临时表 Final_results AS
选择
  s.customer_key，
  s.类别，
  米坡度
FROM 分区数据 p
加入 （
  选择
    *,
    斜率 = MEAN(statistics.mean_slope)
   来自 ML.MODEL_STATS(model.my_model)
   按客户键、商店键、类别分组
  ）米
 ON p.customer_key = m.customer_key
 AND p.category = m.category;

但是，这个建议的解决方案无法在 bigquery gui 中运行，也不能在 dbt 中运行。
问题
有人知道如何完成这个回归任务吗？要么在 bigquery 上将上面的 sql 代码作为单独的脚本运行，要么重写它以在 dbt 中工作。]]></description>
      <guid>https://stackoverflow.com/questions/77757181/bigquery-ml-for-multiple-linear-regression-models-on-partitions-in-a-table</guid>
      <pubDate>Thu, 04 Jan 2024 09:36:32 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习的 YAML 文件审查系统 [关闭]</title>
      <link>https://stackoverflow.com/questions/77756484/yaml-file-review-system-using-machine-learning</link>
      <description><![CDATA[想要使用机器学习创建一个 YAML 审核系统。该系统可以分析YAML条目（正确与否），并根据结果得出结果。请就哪种机器学习算法和机器学习框架最适合此目的提出任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/77756484/yaml-file-review-system-using-machine-learning</guid>
      <pubDate>Thu, 04 Jan 2024 07:18:08 GMT</pubDate>
    </item>
    <item>
      <title>多元数据排序算法设计[关闭]</title>
      <link>https://stackoverflow.com/questions/77756234/multivariate-data-ranking-algorithm-design</link>
      <description><![CDATA[目前我已经收集了很多学校的相关数据。每个学校都有教师人数、学生人数、硬件设施等十个评价指标，每个指标的权重我不知道。现在我们想用机器学习算法来自动对高校综合实力进行排名，而不需要参考任何知名的国际排名，比如QS。]]></description>
      <guid>https://stackoverflow.com/questions/77756234/multivariate-data-ranking-algorithm-design</guid>
      <pubDate>Thu, 04 Jan 2024 06:17:23 GMT</pubDate>
    </item>
    <item>
      <title>face_recognition 和 pytorch 模块冲突</title>
      <link>https://stackoverflow.com/questions/77755812/face-recognition-and-pytorch-module-conflict</link>
      <description><![CDATA[导入操作系统，pathlib
将streamlit导入为st
导入操作系统、日期时间、json、sys、pathlib、shutil
将 pandas 导入为 pd
将streamlit导入为st
导入CV2
导入人脸识别
将 numpy 导入为 np
从 PIL 导入图像
进口火炬
导入 torch.nn.function 作为 F
从 torch.nn 导入 Linear、Conv2d、BatchNorm1d、BatchNorm2d、PReLU、ReLU、Sigmoid、AdaptiveAvgPool2d、顺序、模块
颜色_暗 = (0, 0, 153)
颜色_白色 = (255, 255, 255)
def BGR_to_RGB(image_in_array):
    返回 cv2.cvtColor(image_in_array, cv2.COLOR_BGR2RGB)
def main():
    #################################################### #
    st.sidebar.header(“关于”)
    st.sidebar.info(“这个网络应用程序提供了访客监控的演示”
                    “使用“面部识别”和 Streamlit 的 Web 应用程序”）
    ####################################################
    ## 读取相机图像
    img_file_buffer = st.camera_input(&quot;拍照&quot;)

    如果 img_file_buffer 不是 None：
        bytes_data = img_file_buffer.getvalue()

        # 将打开文件中的图像转换为 np.array
        image_array = cv2.imdecode(np.frombuffer(bytes_data,
                                                            np.uint8),
                                            CV2.IMREAD_COLOR)
        image_array_copy = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
        # st.image(cv2_img)
        ## 保存访客历史记录

        ## 验证图像
        # 检测加载图像中的人脸
        最大面数 = 0
        rois = [] # 感兴趣区域（面部区域数组）

        ## 从图像中获取人脸位置
        面部位置 = 面部识别.面部位置（图像数组）
        ## 将图像编码为数字格式
        编码CurFrame=face_recognition.face_encodings(image_array,
                                                            面部位置）

        ## 在图像上生成矩形红框
        对于 idx，枚举（face_locations）中的（上、右、下、左）：
            # 保存脸部的感兴趣区域
            rois.append(image_array[上:下,左:右].copy())

            # 在脸部周围画一个框并为其添加标签
            cv2.rectangle(image_array, (左, 上), (右, 下), COLOR_DARK, 2)
            cv2.rectangle(image_array, (左, 下 + 35), (右, 下), COLOR_DARK, cv2.FILLED)
            字体= cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(image_array, f&quot;#{idx}&quot;, (左 + 5, 下 + 25), 字体, .55, COLOR_WHITE, 1)

        ## 显示图像
        st.image(BGR_to_RGB(image_array)，宽度=720)

        ## 识别的人脸数量
        max_faces = len(face_locations)

        如果 max_faces &gt; 0:
            col1, col2 = st.columns(2)

            # 选择图片中选定的面孔
            face_idxs = col1.multiselect(“选择面#”, range(max_faces),
                                            默认=范围(max_faces))

            ## 过滤超出阈值的相似度
            相似度阈值 = col2.slider(&#39;选择相似度阈值&#39;,
                                                    最小值=0.0，最大值=1.0，
                                                    值=0.5）
                                            ## 检查相似性置信度是否大于此阈值

            标志显示=假

#################################################### #####
如果 __name__ == “__main__”：
    主要的（）
#################################################### #####

我不确定为什么当我同时使用 PyTorch 模块和 Face_recognition 模块时我的代码会崩溃而没有任何日志。除了提出这个问题之外，我没有做过任何研究，但我发现只有一次导入其中一个模块时，代码才会运行。
我想创建一个streamlit应用程序，能够拍照并检测其上的面部编码。]]></description>
      <guid>https://stackoverflow.com/questions/77755812/face-recognition-and-pytorch-module-conflict</guid>
      <pubDate>Thu, 04 Jan 2024 03:57:35 GMT</pubDate>
    </item>
    <item>
      <title>Python 中带有否定词的词袋</title>
      <link>https://stackoverflow.com/questions/77755646/bag-of-words-with-negative-words-in-python</link>
      <description><![CDATA[我有这个文件
这不是普通的文本
这是科学术语的文本
这些文档的正文是这样的
&lt;前&gt;&lt;代码&gt;RepID,Txt

1、K9G3P9 4H477 -Q207KL41 98464 ... Q207KL41
2、D84T8X4 -D9W4S2 -D9W4S2 8E8E65 ... D9W4S2
3、-05L8NJ38 K2DD949 0W28DZ48 207441 ... K2D28K84

我可以使用 BOW 算法构建功能集
这是我的代码
def BOW(df):
  CountVec = CountVectorizer() # 仅使用二元组 ngram_range=(2,2)
  Count_data = CountVec.fit_transform(df)
  Count_data = Count_data.astype(np.uint8)
  cv_dataframe=pd.DataFrame(Count_data.toarray(), columns=CountVec.get_feature_names_out(), index=df.index) # &lt;- 这里
  返回 cv_dataframe.astype(np.uint8)

df_reps = pd.read_csv(“c:\\file.csv”)
df = BOW(df_reps[“Txt”])

结果将是“Txt”中的字数。专栏。
&lt;预&gt;&lt;代码&gt;RepID K9G3P9 4H477 -Q207KL41 98464 ... Q207KL41
1 2 8 3 2 ... 1
2 0 1 2 4 ... 2

这里我需要帮助的地方是，其中一些术语前面有一个-，这应该算作负值
因此，如果文本具有这些值Q207KL41 -Q207KL41 -Q207KL41
在这种情况下，以 - 开头的项应计为负数，因此 Q207KL41 的 BOW 为 -1
而不是具有Q207KL41和-Q207KL41的功能
它们都计入相同的术语Q207KL41，但具有正数和负数
所以 BOW 之后的数据集将如下所示
&lt;预&gt;&lt;代码&gt;RepID K9G3P9 4H477 Q207KL41 98464 ...
1 2 8 -2 2 ...
2 0 1 0 4 ...

如何做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/77755646/bag-of-words-with-negative-words-in-python</guid>
      <pubDate>Thu, 04 Jan 2024 02:56:20 GMT</pubDate>
    </item>
    <item>
      <title>在 scikit-learn 中使用 StandardScaler 时 CustomScaler 中出现类型错误</title>
      <link>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</link>
      <description><![CDATA[我在使用 scikit-learn 的 Python 中遇到自定义缩放器类的问题。我有一个继承自 BaseEstimator 和 TransformerMixin 的 CustomScaler 类，它使用 StandardScaler。但是，我在初始化过程中遇到了类型错误。相关代码如下：
从 sklearn.base 导入 BaseEstimator、TransformerMixin
从 sklearn.preprocessing 导入 StandardScaler

类 CustomScaler(BaseEstimator,TransformerMixin):
    
    def __init__(self,columns,copy=True,with_mean=True,with_std=True):
        self.scaler = StandardScaler(复制,with_mean,with_std)
        self.columns = 列
        self.mean_ = 无
        self.var_ = 无

    def fit(self, X, y=None):
        self.scaler.fit(X[self.columns], y)
        self.mean_ = np.mean(X[self.columns])
        self.var_ = np.var(X[self.columns])
        返回自我

    def 变换（自身，X，y=无，复制=无）：
        init_col_order = X.列
        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)
        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]
        返回 pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]


unscaled_input.columns.values
columns_to_scale = [&#39;月份值&#39;,
       “星期几”、“交通费用”、“上班距离”、
       ‘年龄’、‘每日平均工作负荷’、‘体重指数’、‘儿童’、‘宠物’]

absenteeism_scaler = CustomScaler(columns= columns_to_scale) // 这一步出错
缺席主义_scaler.fit（unscaled_input）

我检查了 StandardScaler 类的 scikit-learn 文档以确保正确使用，但我找不到此错误的任何解决方案。
什么可能导致此问题？有其他方法可以解决这个问题吗？
错误消息：
TypeError Traceback（最近一次调用最后一次）
单元格 In[24]，第 1 行
----&gt; 1 缺勤缩放器 = CustomScaler(columns_to_scale)

Cell In[20]，第 7 行，在 CustomScaler.__init__(self, columns, copy, with_mean, with_std)
      6 def __init__(self, columns, copy=True, with_mean=True, with_std=True):
----&gt; 7 self.scaler = StandardScaler(copy, with_mean, with_std)
      8 self.columns = 列
      9 self.mean_ = 无

TypeError: __init__() 采用 1 个位置参数，但给出了 4 个
]]></description>
      <guid>https://stackoverflow.com/questions/77751265/typeerror-in-customscaler-using-standardscaler-in-scikit-learn</guid>
      <pubDate>Wed, 03 Jan 2024 10:34:48 GMT</pubDate>
    </item>
    <item>
      <title>以 PMML 格式转储的 LightGBM 模型给出了与原始模型不同的预测</title>
      <link>https://stackoverflow.com/questions/77664935/lightgbm-model-dumped-in-pmml-format-gives-different-predictions-from-the-origin</link>
      <description><![CDATA[我训练了一个 lightGBM 模型，它给出了倾向问题的概率。
然后将此模型转换为 PMML 格式，如下所示：
从 sklearn2pmml 导入 sklearn2pmml
sklearn2pmml(trained_model, &#39;prod_trained_model.pmml&#39;)

然后我像这样读取 PMML 模型：
从 pypmml_spark 导入 ScoreModel
model_pipeline = ScoreModel.fromFile(&#39;prod_trained_model.pmml&#39;)

然后我做出这样的预测：
predictions_df = model_pipeline.transform(features_df)

现在的问题是模型预测与原始模型的预测不匹配。预测概率有 5% 到 10% 的变化。
此外，对于输入数据帧中大约 5% 的行，PMML 模型的输出概率为 NaN。而对于完全相同的行，原始模型预测得很好。]]></description>
      <guid>https://stackoverflow.com/questions/77664935/lightgbm-model-dumped-in-pmml-format-gives-different-predictions-from-the-origin</guid>
      <pubDate>Fri, 15 Dec 2023 07:56:51 GMT</pubDate>
    </item>
    <item>
      <title>Llama2 回归语言模型 (huggingface)</title>
      <link>https://stackoverflow.com/questions/77654285/llama2-language-model-for-regression-huggingface</link>
      <description><![CDATA[我尝试利用给定整个输入序列的模型的最后一个隐藏状态，调整 Llama2 来解决回归任务。
如果随后问问题“2+2 的答案是什么”，则应回答4（虚拟问题，用于解释问题）。&lt; /p&gt;
为此，我将在 pytorch 模型中使用它
导入火炬
将 torch.nn 导入为 nn
从 Transformer 导入 LlamaModel、LlamaTokenizer

类 TransformerModel(nn.Module):
    def __init__(self, 模型名称:str, 附加层大小:int = 1):
        super(TransformerModel, self).__init__()
        self.transformer = LlamaModel.from_pretrained(model_name, torch_dtype=torch.float32, cache_dir=“hugginface_cache/models”)
        self.tokenizer = LlamaTokenizer.from_pretrained(model_name,cache_dir=“hugginface_cache/tokenizer”)

        # 添加一个带有一个输出的附加层
        self.additional_layer = nn.Linear(self.transformer.config.hidden_​​size,additional_layer_size)
        
    defforward(self, input_text):
        # 对输入文本进行标记
        input_ids = self.tokenizer(input_text, return_tensors=“pt”).input_ids.to(“cuda”)
        打印（“输入ID：”，输入ID）

        # 获取变压器的输出
        输出 = self.transformer(input_ids)
        
        # 使用整个最后的隐藏状态作为附加层的输入
        最后隐藏状态 = 输出.最后隐藏状态
        打印（&#39;last_hidden_​​state_shape：&#39;，last_hidden_​​state.size（））

        # 应用附加层
        附加输出= self.附加层（最后隐藏状态）

        返回附加输出


model_url = “meta-llama/Llama-2-7b-hf”

模型 = TransformerModel(model_url)

但是，对于给定的输入模型（“Hello world！”），输出是大小为 1,4,1 的张量。
我可以验证标记生成器是否将字符串拆分为 4 个标记，我预计这会导致问题。但是，我不确定如何解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77654285/llama2-language-model-for-regression-huggingface</guid>
      <pubDate>Wed, 13 Dec 2023 14:22:48 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：输入类型（无符号字符）和偏差类型（浮点）应该相同</title>
      <link>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</guid>
      <pubDate>Mon, 11 Dec 2023 11:43:29 GMT</pubDate>
    </item>
    <item>
      <title>Rapids 无法导入 cudf：驱动程序初始化时出错：调用 cuInit 会导致 CUDA_ERROR_NO_DEVICE (100)</title>
      <link>https://stackoverflow.com/questions/77380210/rapids-cannot-import-cudf-error-at-driver-init-call-to-cuinit-results-in-cuda</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77380210/rapids-cannot-import-cudf-error-at-driver-init-call-to-cuinit-results-in-cuda</guid>
      <pubDate>Sat, 28 Oct 2023 16:02:14 GMT</pubDate>
    </item>
    <item>
      <title>开始微调时的损失高于迁移学习的损失</title>
      <link>https://stackoverflow.com/questions/72548173/loss-when-starting-fine-tuning-is-higher-than-loss-from-transfer-learning</link>
      <description><![CDATA[由于我开始使用通过迁移学习学到的权重进行微调，我预计损失会相同或更少。然而，看起来它开始使用一组不同的起始权重进行微调。
启动迁移学习的代码：
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                              include_top=假，
                                              权重=&#39;imagenet&#39;）
base_model.trainable = False

模型 = tf.keras.Sequential([
  基本模型，
  tf.keras.layers.GlobalAveragePooling2D(),
  tf.keras.layers.Dense(单位=3，激活=&#39;sigmoid&#39;)
]）

model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

历元 = 1000
回调= tf.keras.callbacks.EarlyStopping（耐心= 10，restore_best_weights = True）
历史 = model.fit(train_generator,
                    steps_per_epoch=len(train_generator),
                    纪元=纪元，
                    验证数据=val_generator，
                    验证步骤=len(val_generator),
                    回调=[回调],)

上一个纪元的输出：
纪元 29/1000
232/232 [================================] - 492s 2s/步 - 损失：0.1298 - 准确度：0.8940 - val_loss ：0.1220 - val_accuracy：0.8937

开始微调的代码：
model.trainable = True

# 从这一层开始进行微调
微调 = -20

# 冻结 `fine_tune_at` 层之前的所有层
对于 model.layers[:fine_tune_at] 中的图层：
  可训练层 = False

model.compile(优化器=tf.keras.optimizers.Adam(1e-5),
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])

History_fine = model.fit(train_generator,
                         steps_per_epoch=len(train_generator),
                         纪元=纪元，
                         验证数据=val_generator，
                         验证步骤=len(val_generator),
                         回调=[回调],)

但这就是我在前几个时期看到的情况：
纪元 1/1000
232/232 [==============================] - ETA：0秒 - 损失：0.3459 - 准确度：0.8409/usr/ local/lib/python3.7/dist-packages/PIL/Image.py:960：UserWarning：以字节表示透明度的调色板图像应转换为 RGBA 图像
  “以字节表示透明度的调色板图像应该是”
232/232 [==============================] - 509s 2s/步 - 损失：0.3459 - 准确度：0.8409 - val_loss ：0.7755 - val_accuracy：0.7262
纪元 2/1000
232/232 [================================] - 502s 2s/步 - 损失：0.1889 - 准确度：0.9066 - val_loss ：0.5628 - val_accuracy：0.8881

最终损失下降并超过了迁移学习损失：
纪元 87/1000
232/232 [================================] - 521s 2s/步 - 损失：0.0232 - 准确度：0.8312 - val_loss ：0.0481 - val_accuracy：0.8563

为什么第一个微调时期的损失高于迁移学习的最后一个损失？]]></description>
      <guid>https://stackoverflow.com/questions/72548173/loss-when-starting-fine-tuning-is-higher-than-loss-from-transfer-learning</guid>
      <pubDate>Wed, 08 Jun 2022 15:12:54 GMT</pubDate>
    </item>
    <item>
      <title>分类与回归？</title>
      <link>https://stackoverflow.com/questions/33908127/classification-vs-regression</link>
      <description><![CDATA[我不太清楚分类和回归之间有什么区别。
据我了解，分类是绝对的。要么是这个，要么是那个。
回归更多的是一种预测。


上面的两个问题都更像是回归问题，对吧？它都是使用学习算法来预测。谁能举一个分类与回归的例子吗？]]></description>
      <guid>https://stackoverflow.com/questions/33908127/classification-vs-regression</guid>
      <pubDate>Wed, 25 Nov 2015 03:41:55 GMT</pubDate>
    </item>
    </channel>
</rss>