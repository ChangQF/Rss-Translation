<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 11 Jan 2024 15:14:55 GMT</lastBuildDate>
    <item>
      <title>训练随机森林花费的时间太长</title>
      <link>https://stackoverflow.com/questions/77801017/training-random-forest-taking-too-long</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77801017/training-random-forest-taking-too-long</guid>
      <pubDate>Thu, 11 Jan 2024 15:02:53 GMT</pubDate>
    </item>
    <item>
      <title>基于地理空间点数据约束的聚类</title>
      <link>https://stackoverflow.com/questions/77800495/clustering-based-on-constraints-on-geospatial-point-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77800495/clustering-based-on-constraints-on-geospatial-point-data</guid>
      <pubDate>Thu, 11 Jan 2024 13:42:13 GMT</pubDate>
    </item>
    <item>
      <title>创建一个根据所提供的 5 个 PDF 文档内容进行训练的聊天机器人。以下是需要完成的任务：[关闭]</title>
      <link>https://stackoverflow.com/questions/77799235/create-a-chatbot-that-is-trained-based-on-content-from-the-5-pdf-documents-provi</link>
      <description><![CDATA[a.提取文本和数据，将数据转换为数值向量，并将向量和文档详细信息存储在数据库中。
b.聊天机器人需要接受用户查询/输入并根据这些 PDF 文档的内容返回响应。用于响应用户查询/问题的创造力非常重要。
c.当 PDF 中没有找到相关结果时，应依赖法学硕士的内容来构建响应。如果仍然没有合适的答案，它应该提供用户友好的响应。
d. UI 界面应该具有聊天机器人的外观和感觉。
e.创建此功能的视频并向我们发送 Google Drive 或
可以下载的视频文件。
我期待满足上述需求的代码。]]></description>
      <guid>https://stackoverflow.com/questions/77799235/create-a-chatbot-that-is-trained-based-on-content-from-the-5-pdf-documents-provi</guid>
      <pubDate>Thu, 11 Jan 2024 10:15:51 GMT</pubDate>
    </item>
    <item>
      <title>联邦学习全局聚合后准确率下降</title>
      <link>https://stackoverflow.com/questions/77798059/the-accuacy-decreased-after-global-aggregation-in-federated-learning</link>
      <description><![CDATA[我正在开展一个联合学习项目。我编写了一段代码来刺激联邦学习的过程。然而，每次迭代进行全局聚合后，全局模型的测试精度会下降很多，并且在接下来的迭代中保持不变。我使用的聚合算法是FedAvg。我尝试将我的代码分成不同的单元来找出问题所在。
对于本地训练，所选客户训练 3 轮。在这个实验中，将选择所有五个客户端进行训练和聚合，我用于本地的模型是从 torchvision 分叉的 vgg16，数据集是 MNIST，并以 i.i.d 方式分割每个客户端： 
for id, net_id in enumerate(selected):
    logging.info(“训练所选设备 %s。” % (str(net_id)))
    结果 = Userlists[net_id].train(hparams[&#39;n_local_epochs&#39;])
    logging.info(&#39;&gt;&gt; 局部模型 %d: 局部精度: %f in round %d\n&#39; % (id, result[&#39;local_test_acc&#39;], step+1))

在本地模型聚合之前，我使用全局服务器的测试数据来测试本地模型的准确性，
tesc，conf = Misc.compute_accuracy(Userlists[2].model，test_dl_global，get_confusion_matrix=True，device=hparams[&#39;device&#39;])
打印（测试）
&gt; 0.2478966346153846
tesc，conf = Misc.compute_accuracy（Userlists [3] .model，test_dl_global，get_confusion_matrix = True，device = hparams [&#39;device&#39;]）
打印（测试）
&gt; 0.14413060897435898
tesc,conf=misc.compute_accuracy(Userlists[4].model,test_dl_global,get_confusion_matrix=True,device=hparams[&#39;device&#39;])
打印（测试）
&gt; 0.17387820512820512

我使用下面的聚合代码来聚合所选客户端的权重：
&lt;前&gt;&lt;代码&gt;total_sum = 0.0
对于选定的 client_idx：
    Total_sum += 用户列表[client_idx].data_len
    
    
global_para = global_model.state_dict()
client_weights = [torch.tensor( Userlists[client_idx].data_len/total_sum, device=hparams[&#39;device&#39;]) for client_idx in selected]

使用 torch.no_grad()：
    对于顺序，枚举中的 idx（选定）：
        logging.info(f“对于客户端 {idx}”)
        net_para = Userlists[idx].model.state_dict()
        
        如果订单 == 0：
            对于 net_para.keys() 中的键：
                global_para[key] = net_para[key] * client_weights[订单]
        别的：
            对于 net_para.keys() 中的键：
                global_para[key] += net_para[key] * client_weights[订单]


global_model.load_state_dict(global_para)
tesc,conf=misc.compute_accuracy(global_model,train_dl_global,get_confusion_matrix=True,device=hparams[&#39;device&#39;])

全局测试精度下降并保持不变
&lt;前&gt;&lt;代码&gt;&gt; 0.11236666666666667

尽管我尝试增加本地训练的纪元，局部准确率提高到 40%，但全局准确率仍然落入与之前相同的值。我的聚合代码中是否有错误的地方？
测试精度应与本地精度保持在同一水平。]]></description>
      <guid>https://stackoverflow.com/questions/77798059/the-accuacy-decreased-after-global-aggregation-in-federated-learning</guid>
      <pubDate>Thu, 11 Jan 2024 06:30:41 GMT</pubDate>
    </item>
    <item>
      <title>数据帧和多变量标签的嵌套目录上的多视图谱聚类</title>
      <link>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77797916/multi-view-spectral-clustering-on-nested-directories-of-dataframes-and-multivari</guid>
      <pubDate>Thu, 11 Jan 2024 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到<class 'NoneType'> [关闭]</title>
      <link>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</link>
      <description><![CDATA[我正在尝试对我的数据运行深度学习代码；但是，由于输入数据中缺少数据集，我遇到了问题。如何解决这个问题？我正在努力解决下面给出的这个错误，下面还提供了输入链接。
python3 Validation2co.py
BP_benchmarkSet_2.csv
BP seqmodel 启动
序列模块（
  (seq_CNN): 顺序(
    (0): Conv1d(100, 64, kernel_size=(16,), stride=(1,), padding=(8,))
    (1): ReLU(原地=True)
    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv1d(64, 32, kernel_size=(16,), stride=(1,), padding=(8,))
    (4): ReLU(inplace=True)
    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv1d(32, 16, kernel_size=(16,), stride=(1,), padding=(8,))
    (7): ReLU(原地=True)
    (8): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  ）
  （seq_FClayer）：线性（in_features = 3008，out_features = 1024，偏差= True）
  （seq_outlayer）：线性（in_features = 1024，out_features = 491，偏差= True）
）
batch_size_32，learning_rate_0.0001，epoch_time_30
selected_208964_ Protein_score.csv
selected_208964_ Protein_score.csv
警告：iprID Q9HTQ2 数据丢失。跳过...
警告：iprID Q9I559 数据丢失。跳过...
警告：iprID Q9HT21 数据丢失。跳过...
警告：iprID Q9I0Q1 数据丢失。跳过...
警告：iprID Q9HVI7 数据丢失。跳过...
警告：iprID Q9I422 数据丢失。跳过...
警告：iprID Q9I2V9 数据丢失。跳过...
警告：iprID Q9HWB6 数据丢失。跳过...
警告：iprID Q9HVT7 数据丢失。跳过...
警告：iprID Q9I3I5 数据丢失。跳过...
警告：iprID Q9I4C1 数据丢失。跳过...
警告：iprID Q9I5K0 数据丢失。跳过...
警告：iprID P26995 数据丢失。跳过...
警告：iprID Q9I1Y7 数据丢失。跳过...
警告：iprID Q9I316 数据丢失。跳过...
警告：iprID Q9I299 数据丢失。跳过...
警告：iprID Q9I2Q4 数据丢失。跳过...
警告：iprID Q9HT20 数据丢失。跳过...
警告：iprID Q9HV34 数据丢失。跳过...
警告：iprID Q9HX99 数据丢失。跳过...
警告：iprID Q9HZK1 数据丢失。跳过...
警告：iprID Q9HXG5 数据丢失。跳过...
警告：iprID Q9I3F5 数据丢失。跳过...
警告：iprID Q9HV44 数据丢失。跳过...
警告：iprID Q9HY92 数据丢失。跳过...
警告：iprID Q9HVX9 数据丢失。跳过...
警告：iprID Q9I6Z3 数据丢失。跳过...
警告：iprID Q9HU16 数据丢失。跳过...
警告：iprID Q9HYL8 数据丢失。跳过...
警告：iprID Q9HI37 数据丢失。跳过...
警告：iprID Q9I1Y4 数据丢失。跳过...
警告：iprID Q9HW04 数据丢失。跳过...
回溯（最近一次调用最后一次）：
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 990 行，在  中。
    验证（条款[0], 5）
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 972 行，验证中
    每个_fold_scores = Main(train_set, test_set, func=func)
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 831 行，位于 Main 中
    seq_train_out, seq_test_out, seq_t = Seq_train(0.0001, 16, train_benchmark, test_benchmark, 30, func) # 15
  文件“/home/bvs/neelam/input_ourmodel/input/Validation2co.py”，第 408 行，Seq_train
    对于batch_idx，枚举（train_data_loader）中的（seqMatrix，domainStence，ppiVect，GO_annotiations）：
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 681 行，位于 __next__
    数据 = self._next_data()
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/dataloader.py”，第 721 行，位于 _next_data
    data = self._dataset_fetcher.fetch(index) # 可能会引发 StopIteration
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py​​”，第 52 行，在 fetch 中
    返回 self.collat​​e_fn(数据)
  文件“/home/bvs/miniconda3/envs/crisprcasfinder/envs/envML/lib/python3.10/site-packages/torch/utils/data/_utils/collat​​e.py”，第 183 行，default_collat​​e
    引发 TypeError(default_collat​​e_err_msg_format.format(elem_type))
**类型错误：default_collat​​e：批处理必须包含张量、numpy 数组、数字、字典或列表；找到**
]]></description>
      <guid>https://stackoverflow.com/questions/77797754/typeerror-default-collate-batch-must-contain-tensors-numpy-arrays-numbers-d</guid>
      <pubDate>Thu, 11 Jan 2024 04:55:02 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 AWS Sagemaker 向 50 名学生教授数据科学和机器学习？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77797651/how-to-use-aws-sagemaker-for-teaching-data-science-and-machine-learning-to-50-st</link>
      <description><![CDATA[我想为 50 名学生提供数据科学和机器学习方面的培训。我的客户不被允许使用任何 Google 产品，例如 Kaggle 或 Google Colab。因此，我计划使用 AWS，学生可以在 amazon sagemaker ipynb 中运行代码。
有没有什么方法可以让每个学生独立运行他们的笔记本并在 AWS 中进行他们想要的实验，并且我可以监控他们？
我有一个 AWS 组织账户。
我怎样才能做到这一点？
我尝试创建具有 50 个子用户的 IAM 用户，但在笔记本中进行更改后，它会自动反映在另一个子帐户中]]></description>
      <guid>https://stackoverflow.com/questions/77797651/how-to-use-aws-sagemaker-for-teaching-data-science-and-machine-learning-to-50-st</guid>
      <pubDate>Thu, 11 Jan 2024 04:17:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用离群数据来训练随机森林回归以用于填充其他缺失数据</title>
      <link>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</link>
      <description><![CDATA[dataAgeNull = data[data[“年龄”].isnull()]
dataAgeNotNull = data[data[“年龄”].notnull()]
remove_outlier = dataAgeNotNull[(np.abs(dataAgeNotNull[“票价”]-dataAgeNotNull[“票价”].mean())&gt;(4*dataAgeNotNull[“票价”].std()))|
                      (np.abs(dataAgeNotNull[“Family_Size”]-dataAgeNotNull[“Family_Size”].mean())&gt;(4*dataAgeNotNull[“Family_Size”].std()))
                     ]
rfModel_age = RandomForestRegressor(n_estimators=2000,random_state=42)
ageColumns = [&#39;出发&#39;, &#39;票价&#39;, &#39;舱位等级&#39;, &#39;性别&#39;, &#39;Family_Size&#39;, &#39;标题1&#39;, &#39;标题2&#39;,&#39;客舱&#39;,&#39;机票信息&#39;]
rfModel_age.fit(remove_outlier[ageColumns], remove_outlier[“年龄”])

ageNullValues = rfModel_age.predict(X= dataAgeNull[ageColumns])
dataAgeNull.loc[:,&quot;年龄&quot;] = AgeNullValues
数据 = dataAgeNull.append(dataAgeNotNull)
data.reset_index(inplace=True, drop=True)

为什么我们使用“票价”的离群数据和“family_size”训练 RandomForestRegressor 来填充“年龄”的缺失数据？
我试图理解这段代码，但仍然无法弄清楚
4]]></description>
      <guid>https://stackoverflow.com/questions/77797592/why-use-outlier-data-to-train-random-forest-regression-for-the-use-of-filling-ot</guid>
      <pubDate>Thu, 11 Jan 2024 03:58:16 GMT</pubDate>
    </item>
    <item>
      <title>回归任务中日志转换后的指标解释问题</title>
      <link>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</link>
      <description><![CDATA[我目前正在研究房价预测任务，由于目标变量（价格）的非正态分布，我对它进行了对数转换。我使用 RMSE、MAE 和 MAPE 等指标，并且对于模型训练，我使用了 cross_val_score。
获得预测后，我采用 MAE 和 MAPE 指标的指数将其恢复到原始规模。然而，我遇到了意想不到的小值；两个指标都等于 1。我怀疑这些值不正确。
kf = KFold(n_splits=5, random_state=42, shuffle=True)

def rmse_cv（模型）：
    mse_scorer = make_scorer(mean_squared_error)
    rmse = np.sqrt(cross_val_score(模型, 训练, y_train, 评分=mse_scorer, cv=kf))
    返回均方根误差

def mae_cv（模型）：
    mae_scorer = make_scorer(mean_absolute_error)
    mae = cross_val_score(模型, 训练, y_train, 评分=mae_scorer, cv=kf)
    返回梅

def mape_cv（模型）：
    mape_scorer = make_scorer(mean_absolute_percentage_error)
    mape = cross_val_score(模型, 训练, y_train, 评分=mape_scorer, cv=kf)
    返回马普

lightgbm = LGBMRegressor(num_leaves=6, max_depth=7, random_state=42, n_estimators=500, Objective=&#39;回归&#39;)

rmse = rmse_cv(lightgbm)
mae = mae_cv(lightgbm)
映射 = 映射_cv(lightgbm)
print(&#39;Lightgbm rmse %.4f&#39; % (rmse.mean()))
print(&#39;Lightgbm mae %.4f&#39; % (mae.mean()))
print(&#39;Lightgbm mape %.4f&#39; % (mape.mean()))

Lightgbm rmse 0.1331
Lightgbm mae 0.0874
Lightgbm 映射 0.0073

我希望获得合理且可解释的值，以反映模型在原始范围内的性能。然而，这两个指标都得出了意想不到的小值 1，这似乎不准确。我期望在原始价格范围内能够更有意义地表示模型误差。]]></description>
      <guid>https://stackoverflow.com/questions/77797473/issue-with-metrics-interpretation-after-log-transformation-in-regression-task</guid>
      <pubDate>Thu, 11 Jan 2024 03:13:07 GMT</pubDate>
    </item>
    <item>
      <title>人工智能和语言处理[关闭]</title>
      <link>https://stackoverflow.com/questions/77796617/ai-and-language-processing</link>
      <description><![CDATA[在开发人工智能应用程序来分析和减轻社交媒体声明中的声誉风险的背景下，检测潜在攻击性或文化不敏感内容的最有效的自然语言处理技术是什么？
我在 Huggingface 等网站上研究过法学硕士。然而，这种方法似乎有点碰运气，大多数法学硕士都需要进一步的培训。]]></description>
      <guid>https://stackoverflow.com/questions/77796617/ai-and-language-processing</guid>
      <pubDate>Wed, 10 Jan 2024 22:00:34 GMT</pubDate>
    </item>
    <item>
      <title>是什么导致 keras.model.evaluate 出现错误？不兼容的形状：[32] 与 [32,3]，并且“输出”必须具有等级 (ndim)“target.ndim - 1”</title>
      <link>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77795033/what-causes-error-on-keras-model-evaluate-incompatible-shapes-32-vs-32-3</guid>
      <pubDate>Wed, 10 Jan 2024 16:47:49 GMT</pubDate>
    </item>
    <item>
      <title>考虑到 3D CNN 的挑战和预训练 VideoMAE 模型的内存问题，对震颤强度进行分类的有效方法是什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77794520/what-are-efficient-methods-for-classifying-tremor-intensity-given-challenges-wi</link>
      <description><![CDATA[我有一个包含 80 个视频的训练数据集（没有增强）。它们是以 30fps 和 240*480 尺寸录制的 15 秒视频。训练分类模型有哪些选择？问题陈述是我有颤抖者的视频。我想按 1 - 3 级对震颤强度进行分类。请建议一些处理此问题的方法
我尝试过使用 3D CNN，但它需要过多的计算能力。我还尝试通过微调 Huggingface 中的预训练 VideoMAE 模型来训练模型，但它只接受 16 帧而不是 450 帧（15s * 30fps）。我尝试更改拱门，但它给了我内存错误。]]></description>
      <guid>https://stackoverflow.com/questions/77794520/what-are-efficient-methods-for-classifying-tremor-intensity-given-challenges-wi</guid>
      <pubDate>Wed, 10 Jan 2024 15:31:50 GMT</pubDate>
    </item>
    <item>
      <title>Handritten 数字识别算法前向传播中的矩阵乘法效率低下</title>
      <link>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</link>
      <description><![CDATA[我正在用 python 编写手写数字识别神经网络算法，而不使用预先编写的 ML 库。我目前正在尝试实现一个 DenseLayer 类，并在其中实现一个前向传播函数。我当前的功能如下所示。
类 DenseLayer：
  ...
  
  ...
  def for_prop(自身, input_data):
    self.input = input_data

    transpose_weights = self.weights.T
    # matMulComponent = np.matmul(input_data, transpose_weights)
    print(f&quot;转置形状：{transpose_weights.shape} 和输入形状 {input_data.shape}&quot;)
    matMulComponent = input_data.T @ transpose_weights
    打印（len（matMulComponent））

    z = matMulComponent + self.biases.T
    f_wb = self.act_fun(z)
    
    

    self.output = f_wb.reshape(-1, 1)
    print(f&quot;形状结果：{self.output.shape}&quot;)
    返回自身输出

问题是我正在进行大量的重塑和转置以获得结果。这似乎效率不高。
所以我的问题是：

这个实施起来好吗（因此会导致效率低下）
有没有更好的方法来实现这个前向传播函数

这就是我的输入数据数组的样子（我刚刚打印它并采取了 ss）。我供参考的输入数据是一个扁平的 28*28 数组，每个单元格代表一种颜色。我首先对数据进行标准化（z 分数标准化）
输入数据图像
如果有帮助的话，我还截取了第一层的权重格式的屏幕截图。 （请记住，它在 for_prop 函数中使用之前已被转置）。
第一个隐藏层的权重矩阵图片
前向传播似乎确实有效，但这很好：前向传播进度 ]]></description>
      <guid>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</guid>
      <pubDate>Wed, 10 Jan 2024 04:20:06 GMT</pubDate>
    </item>
    <item>
      <title>我在视觉变压器中有矩形图像数据集。我设置 image_size= (128, 256) 但补丁大小可能是多少？</title>
      <link>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</guid>
      <pubDate>Tue, 09 Jan 2024 16:55:52 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归和决策树之间的区别</title>
      <link>https://stackoverflow.com/questions/76161673/difference-between-logistic-regression-and-decision-trees</link>
      <description><![CDATA[我正在研究决策树，并了解到它通常用于分类问题。
但逻辑回归也仅用于分类问题。
于是我在网上到处搜索，但没有得到满意的结果。我真的很困惑我们什么时候应该使用什么，或者给我一些用例，其中任何一个都可以更好地工作]]></description>
      <guid>https://stackoverflow.com/questions/76161673/difference-between-logistic-regression-and-decision-trees</guid>
      <pubDate>Wed, 03 May 2023 08:04:30 GMT</pubDate>
    </item>
    </channel>
</rss>