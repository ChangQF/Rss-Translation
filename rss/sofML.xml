<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 30 Apr 2024 06:19:03 GMT</lastBuildDate>
    <item>
      <title>Google 语音输入指令如何工作？</title>
      <link>https://stackoverflow.com/questions/78406393/how-does-google-voice-typing-instructions-works</link>
      <description><![CDATA[我正在研究一些听写应用程序，例如 Nuance Dragon 等，它允许您用语音进行听写和编辑文本。为了弄清楚这个工作原理，我偶然发现了文档中的谷歌语音输入功能，我对系统的速度和准确性感到震惊。
谷歌语音输入：https://support.google.com/docs/回答/4492226?sjid=14897244542593477678-AP
细微龙：https://www.nuance.com/dragon.html&lt; /p&gt;
所以，这不仅仅是一个简单的 STT 模型来提供转录 - 它允许您转到特定单词、突出显示、应用格式等。我参与了很多后期处理（我认为）
我是一名初级机器学习工程师，所以我了解 STT 模型及其工作原理，但这个语音输入和编辑系统看起来更复杂。
我想知道这样的系统是如何工作的。任何见解将不胜感激。
我试图了解这样的系统的底层架构，但找不到任何具体的东西。我希望了解该系统的人可以帮助我理解它。]]></description>
      <guid>https://stackoverflow.com/questions/78406393/how-does-google-voice-typing-instructions-works</guid>
      <pubDate>Tue, 30 Apr 2024 05:25:06 GMT</pubDate>
    </item>
    <item>
      <title>当时间序列元数据变化时如何构建多元时间序列</title>
      <link>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</link>
      <description><![CDATA[我根据多元、地理、时间序列数据进行预测。
我的数据包括每种产品的历史价格和生产数量，不同的地方生产和销售不同的产品组。例如：

&lt;标题&gt;

旧金山
第 1 个月
第 2 个月
第 3 个月


&lt;正文&gt;

小麦





美元价格
3
4
3


生产数量T
200
100
150


苹果





美元价格
1
2
0.8


生产数量T
20
10
50




&lt;标题&gt;

布里斯班
第 1 个月
第 2 个月
第 3 个月


&lt;正文&gt;

米饭





美元价格
3
4
3


生产数量T
200
100
150


香蕉





美元价格
5
4
3


生产数量T
200
300
450



每个地点的产品列表都不同。我正在寻找异常情况并预测消费类别（我有这方面的专家历史）。我应该如何构建它来进行训练和预测？
&lt;小时/&gt;
我的猜测（你可能可以停止阅读这里，因为我是一个完全的新手，但建议包括迄今为止完成的工作）：
我可以使用的一种方法是将所有价格标准化并平均。 （收集每个区域最重要产品的价格。）但这会消除很多细节。我可以根据种植的数量来猜测每种产品的重要性，但这通常会产生误导。价格和产量之间的关系和紧张关系很重要。
我猜想，暴力方法是在每个示例中包含每个产品，并为未在某个区域交易的任何产品的时间序列使用一个空令牌。但这将是一个非常稀疏且庞大的数据集。
我可以说product1=“大米w2v嵌入”，product2=“香蕉w2v嵌入”，price_timeseries1=[大米价格]，price_timeseries2=[香蕉价格]（加上产量，以及在另一个例子中，小麦和苹果也是如此）？有任何模型能够解释这一点吗？
我最好的猜测是将产品分类，例如，将大米和小麦分类为“碳水化合物”，然后标准化，然后对每个类别的产品进行平均。 （我确实有一个层次结构，但是有没有办法可以导出或学习分类？）我找不到其他人在做这样的事情，而且我对这个领域很陌生，我不可避免地会忽略重要的统计数据详细信息。
源地理数据以行政单位（城镇边界）为单位。我正在考虑选择（a）将所有内容转换为 100km2 网格，或（b）cos（lat）.cos（lon），cos（lat）.sin（lon），sin（lat） 形状质心 lon/lat，以获得 3D 中的（缩放）坐标，以及面积和人口。选项（b）更容易，除了管理单位随着时间的推移而变化，所以我必须将旧的数字重新分配到最新的边界。
（我还将添加位置元数据，例如国家、气候、人口等）
有什么建议/预感吗？
我（也许天真地）正在考虑 ARIMA、XGBoost、LSTM、timeseries变压器，也许Mamba，如果相关的话。鉴于我完全缺乏经验，我怀疑 XGBoost 可能是复杂性/功能和新手超参数调整技能的最佳点，尽管我会尝试更复杂的架构，因为我知道树会错过生产和价格之间的相互作用，这在这里很重要。&lt; /p&gt;
非常感谢您提供任何提示。]]></description>
      <guid>https://stackoverflow.com/questions/78406347/how-to-structure-multivariate-timeseries-when-timeseries-metadata-varies</guid>
      <pubDate>Tue, 30 Apr 2024 05:08:43 GMT</pubDate>
    </item>
    <item>
      <title>选择具有相似精度但变量数量不同的模型</title>
      <link>https://stackoverflow.com/questions/78406265/choosing-model-with-similar-accuracy-but-different-numbers-of-variables</link>
      <description><![CDATA[我使用不同的变量集开发了机器学习模型 (XGBClassifier)，两组的准确度得分都在 80% 左右。然而，一个模型使用 17 个变量，而另一个模型使用 18 个变量。我不确定选择哪种模型进行部署。以下是我正在考虑的一些因素：

可解释性：据我所知，为了便于解释，通常更倾向于使用变量较少的简单模型。这是否意味着我应该倾向于使用 17 个变量的模型？

过度拟合：即使使用两个变量集具有相似的准确度分数，具有 18 个变量的模型是否会由于其较高的复杂性而更容易过度拟合？

计算效率：变量较少 (17) 的模型在训练和预测时间方面的计算效率是否更高？

特征重要性：如何评估具有 18 个变量的模型中附加变量的重要性？有没有办法确定它是否提供了有意义的见解或提高了性能？

数据质量：在做出此决定时是否应该考虑数据集的质量和维度？添加额外变量是否存在任何风险，例如对噪声的敏感性增加或过度拟合？

信息：更多变量是否能为模型提供更多信息，从而做出更好的决策？

考虑：我参加的是 Kaggle 私人竞赛，所以评估考虑得更多。


考虑到这些因素，我应该如何在精度相似但变量数量不同的这两个集合之间做出选择？在这种情况下我应该遵循哪些最佳实践或指南？
任何见解或建议将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78406265/choosing-model-with-similar-accuracy-but-different-numbers-of-variables</guid>
      <pubDate>Tue, 30 Apr 2024 04:35:46 GMT</pubDate>
    </item>
    <item>
      <title>从 Kaggle 保存的模型无法在本地环境中正确预测</title>
      <link>https://stackoverflow.com/questions/78406107/model-saved-from-kaggle-does-not-predict-properly-in-a-local-a-environment</link>
      <description><![CDATA[我有一个在 Kaggle 笔记本中训练的 GAN 架构模型，我想保存它并在本地环境中使用它。该模型是使用 GPU P100 训练的，但我的本地计算机不支持 GUP。
以下代码用于使用火炬保存模型。
torch.save(modelG.state_dict(), &#39;modelG_appl_v1.pt&#39;)

此代码用于加载模型。
类生成器（nn.Module）：
  def __init__(自身, input_size):
    超级().__init__()

    # 3 个 GRU 层，input_size = features
    self.gru_1 = nn.GRU（input_size，1024，batch_first = True）
    self.gru_2 = nn.GRU(1024、 512、batch_first = True)
    self.gru_3 = nn.GRU(512, 256, batch_first = True)
    self.gru_4 = nn.GRU(256, 128, batch_first = True)
    # 3 致密层
    self.线性_1 = nn.线性(256, 128)
    self.linear_2 = nn.Linear(128, 64)
    self.linear_3 = nn.Linear(64, 5)

    self.dropout = nn.Dropout(0.2)


  def 前向（自身，x）：
    使用_cuda = 1
    device = torch.device(“cuda” if (torch.cuda.is_available() &amp; use_cuda) else “cpu”)
    h0 = torch.zeros(1, x.size(0), 1024).to(device) # 第一个 GRU 层的初始隐藏状态 - （GRU 中的层数、批量大小、GRU 中的隐藏单元数）
    out_gru_1, _ = self.gru_1(x, h0)
    out_gru_1 = self.dropout(out_gru_1)

    h1 = torch.zeros(1, x.size(0), 512).to(设备)
    out_gru_2, _ = self.gru_2(out_gru_1, h1)
    out_gru_2 = self.dropout(out_gru_2)

    h2 = torch.zeros(1, x.size(0), 256).to(设备)
    out_gru_3, _ = self.gru_3(out_gru_2, h2)
    out_gru_3 = self.dropout(out_gru_3)

    h3 = torch.zeros(1, x.size(0), 128).to(设备)
    out_gru_4, _ = self.gru_4(out_gru_3, h3)
    out_gru_4 = self.dropout(out_gru_4)


    out_dense_1 = self.linear_1(out_gru_3[:, -1, :])
    out_dense_2 = self.线性_2(out_dense_1)
    out_dense_3 = self.线性_3(out_dense_2)

    返回out_dense_3,out_gru_3

# 加载模型
Prediction_model = Generator(62).to(&#39;cpu&#39;)
Prediction_model.load_state_dict(torch.load(&#39;../models/modelG_appl_v1.pt&#39;, map_location=torch.device(&#39;cpu&#39;)))


获取预测
#获取预测
使用 torch.no_grad()：
  预测模型.eval()
  预测，gru_layer=预测_模型（特征）

该模型加载时没有任何错误，但给出了错误的预测。我已在同一个 Kaggle 笔记本中加载相同的模型并进行预测，它给出了正确的结果。我也尝试过 pickle 和 joblib。
我想知道这个过程中是否有任何错误或建议更好的方法来保存和加载模型。我还有另一个 XGB 模型需要保存。也建议一个方法。]]></description>
      <guid>https://stackoverflow.com/questions/78406107/model-saved-from-kaggle-does-not-predict-properly-in-a-local-a-environment</guid>
      <pubDate>Tue, 30 Apr 2024 03:27:46 GMT</pubDate>
    </item>
    <item>
      <title>神经网络可以有损失函数吗？</title>
      <link>https://stackoverflow.com/questions/78405886/neural-network-can-have-loss-functions</link>
      <description><![CDATA[我自学了神经网络，因为我认为它可以解决我的问题。一般来说，我对机器学习或人工智能一无所知。
我的问题很复杂，但可以很容易地转化为：我需要两个输出，其中一个是坏的，一个是无用的，一个是好的。
示例：一款真人快打风格的游戏，我需要选择：我是否应该攻击，如果我攻击了，我是赢了还是输了。所以：

output_1：我应该攻击吗（布尔值：是/否）
output_2：如果我攻击，我造成或受到伤害（bool：造成/受到伤害）

很明显，在这种情况下，如果我一直选择不攻击，那是没有用的，所以我不能选择理想的输出。
所以我需要攻击，但前提是我的输入告诉我这是一个好主意（例如：距离合适并且对手没有攻击）。
有没有办法只用神经网络来做到这一点？我错过了什么吗？
我问“那个”著名的人工智能引擎如何做到这一点，它告诉我在神经网络中使用损失函数，但我找不到神经网络中损失函数的任何示例，只能在机器学习中找到。
那么如果我想解决这个问题，我是否需要从 NN 更改为任何其他 ML 算法？请问是哪一个？]]></description>
      <guid>https://stackoverflow.com/questions/78405886/neural-network-can-have-loss-functions</guid>
      <pubDate>Tue, 30 Apr 2024 01:52:36 GMT</pubDate>
    </item>
    <item>
      <title>RFE 与 GBM 集成，用于特征选择和超参数调整</title>
      <link>https://stackoverflow.com/questions/78405164/integration-of-rfe-with-gbm-for-feature-selection-and-hyperparameter-tuning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78405164/integration-of-rfe-with-gbm-for-feature-selection-and-hyperparameter-tuning</guid>
      <pubDate>Mon, 29 Apr 2024 21:00:14 GMT</pubDate>
    </item>
    <item>
      <title>如何提高汽车价格估算中的 RMSE？</title>
      <link>https://stackoverflow.com/questions/78405026/how-can-i-improve-the-rmse-in-my-car-price-estimate</link>
      <description><![CDATA[如何提高汽车价格估算中的 RMSE？

首先，我将根据行驶公里数估算缺失的条件值。

&lt;前&gt;&lt;代码&gt;`
new_condition_df = df[df[&#39;condition&#39;].map(condition_mapping) == 2]
top_1000_highest_mileage = new_condition_df.nlargest(1000, &#39;里程&#39;)[&#39;里程&#39;]
average_top_1000_highest_mileage = top_1000_highest_mileage.mean()

# 过滤 DataFrame 中条件为 null 或未指定的行
null_condition_df = df[df[&#39;条件&#39;].isnull() | (df[&#39;条件&#39;] == &#39;&#39;)]

# 根据里程条件更新“条件”
null_condition_df.loc[null_condition_df[&#39;mileage&#39;] &gt;=average_top_1000_highest_mileage, &#39;condition&#39;] = &#39;CONDITION_USED&#39;
null_condition_df.loc[null_condition_df[&#39;里程&#39;] &lt; average_top_1000_highest_mileage, &#39;条件&#39;] = &#39;CONDITION_NEW&#39;

# 使用修改后的行更新原始 DataFrame
df.update(null_condition_df)
`


删除一些空行

columns_with_null = [&#39;color&#39;, &#39;vat_reclaimable&#39;, &#39;cubic_capacity&#39;, &#39;seller_country&#39;, &#39;feature&#39;]
df.dropna（子集=columns_with_null，inplace=True）

df[&#39;air_conditioning&#39;].fillna(&#39;AIRCONDITIONING_NONE&#39;, inplace=True)
df[&#39;parking_camera&#39;].fillna(&#39;PARKINGCAMERA_NONE&#39;, inplace=True)
df[&#39;parking_sensors&#39;].fillna(&#39;PARKINGSENZOR_NONE&#39;, inplace=True)


这里我试图估计drive列的缺失值，其中包含汽车是4x4还是4x2的信息，drive包含大量空值，这就是为什么我用如此复杂的方式估计它方式

features = [&#39;里程&#39;, &#39;立方容量&#39;, &#39;功率&#39;, &#39;年份&#39;] + list(df.columns[df.columns.str.startswith(&#39;car_style_&#39;)]) + list(df .columns[df.columns.str.startswith(&#39;transmission_&#39;)]) + list(df.columns[df.columns.str.startswith(&#39;fuel_type_&#39;)])

train_data = df.dropna(subset=[&#39;drive&#39;]) # Odstranění řádků s chybějícími hodnotami sloupce &#39;drive&#39;
X_train, X_test, y_train, y_test = train_test_split(train_data[features], pd.get_dummies(train_data[&#39;drive&#39;]), test_size=0.2, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

Missing_data = df[df[&#39;drive&#39;].isnull()]
X_missing = Missing_data[特征]
预测值 = model.predict(X_missing)


df_imput = df.copy()
Predicted_df = pd.DataFrame(predicted_values, columns=y_train.columns, index=missing_data.index)
df_impulated.loc[df_impulated[&#39;drive&#39;].isnull(), y_train.columns] = Predicted_df.values

Predicted_df_encoded = pd.DataFrame(predicted_values, columns=y_train.columns, index=missing_data.index)
Predicted_df_encoded = (predicted_df_encoded &gt; 0.5).astype(int)

对于 Predicted_df_encoded.columns 中的列：
    df_impulated[column] = 0 # Přidání sloupce se všemi hodnotami 0
    df_impulated.loc[predicted_df_encoded.index, 列] = Predicted_df_encoded[列].values

unique_values_impulated_encoded = df_impulated[&#39;drive&#39;].unique()
df = df_估算
df.drop(列=[&#39;drive&#39;], inplace=True)


这里我对特征字段进行编码

from sklearn.preprocessing import MultiLabelBinarizer

mlb = MultiLabelBinarizer()
df = df.join(pd.DataFrame(mlb.fit_transform(df[&#39;feature&#39;]),columns=mlb.classes_))
df.fillna(0,就地=True)

df = df.drop(列=[&#39;特征&#39;])


培训本身

df_encoded = pd.get_dummies(df)

X_train, X_test, y_train, y_test = train_test_split(df_encoded.drop(columns=[&#39;price_with_vat_czk&#39;]), df_encoded[&#39;price_with_vat_czk&#39;], test_size=0.25, random_state=42)

模型=线性回归()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)


所有程序：https://onecompiler.com/python/42brp9a4r
数据集https://filetransfer.io/data-package/a0mFEfg4#link
我的 RMSE 约为 64k]]></description>
      <guid>https://stackoverflow.com/questions/78405026/how-can-i-improve-the-rmse-in-my-car-price-estimate</guid>
      <pubDate>Mon, 29 Apr 2024 20:23:39 GMT</pubDate>
    </item>
    <item>
      <title>如何可视化 yolo best.pt 模型架构</title>
      <link>https://stackoverflow.com/questions/78404883/how-to-visualize-yolo-best-pt-model-architecture</link>
      <description><![CDATA[我想以图形方式可视化 yolo v9 模型的架构
我尝试将其转换为 keras 但不起作用]]></description>
      <guid>https://stackoverflow.com/questions/78404883/how-to-visualize-yolo-best-pt-model-architecture</guid>
      <pubDate>Mon, 29 Apr 2024 19:49:00 GMT</pubDate>
    </item>
    <item>
      <title>NefTune 在 Transformers 上获得 0 训练损失</title>
      <link>https://stackoverflow.com/questions/78404768/neftune-receiving-0-training-loss-on-transformers</link>
      <description><![CDATA[我基本上是在尝试使用 Neftune 微调我的模型。模型基于土耳其语言。但在那里我的训练损失为零。我尝试过另一种模型，例如 Turkish-GPT2 没有问题一切都好。我认为模型可能有问题。我不知道如何处理这个问题。
加载模型：
从变压器导入 AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(“asafaya/kanarya-750m”)
模型 = AutoModelForCausalLM.from_pretrained(“asafaya/kanarya-750m”)

v3_prompt =“”“Aşağıda，daha fazla bağlam sağlayan bir girdiyle eşleştirilmiş，bir görevi açıklayan bir talimat bulunmaktadır。请注意，请确保您的设备正常工作。

＃＃＃ 输入：
{}

＃＃＃ 指示：
{}

＃＃＃ 回复：
{}
”“”

更改格式提示：
EOS_TOKEN = tokenizer.eos_token # 必须添加EOS_TOKEN
defformatting_prompts_func（示例）：
    输入=示例[“输入”]
    说明 = 示例[&#39;说明&#39;]
    输出=示例[“响应”]
    文本=[]
    对于 zip 中的输入、指令、输出（输入、指令、输出）：
        # 必须添加EOS_TOKEN，否则你的一代将永远延续下去！
        text = v3_prompt.format(输入、指令、输出) + EOS_TOKEN
        文本.append(文本)
    返回 {“文本”； ：文本，}
经过

从数据集导入数据集

数据集 = Dataset.from_pandas(数据[:40000])
数据集= dataset.map(formatting_prompts_func,batched=True)

Neftune：
from trl import SFTTrainer
从 Transformers 导入 TrainingArguments

trainer_2 = SFTTrainer(
    型号=型号，
    train_dataset=数据集，
    dataset_text_field=&quot;文本&quot;,
    最大序列长度=512，
    neftune_noise_alpha=5,
    包装=假，
    args = 训练参数(
        per_device_train_batch_size = 1, # 批量大小
        gradient_accumulation_steps = 2, # 梯度累积步数
        热身步骤 = 5,
        最大步数 = 80,
        学习率 = 2e-4,
        fp16 = 假，
        bf16 = torch.cuda.is_bf16_supported(),
        日志记录步骤 = 1,
        优化=“adamw_8bit”，
        权重衰减 = 0.01,
        lr_scheduler_type =“线性”，
        种子=3407，
        输出目录=“输出”，
    ),
）
trainer_2.train()

输出：
&lt;前&gt;&lt;代码&gt; [80/80 00:25，纪元 0/1]
步数训练损失
1 0.000000
2 0.000000
3 0.000000
4 0.000000
5 0.000000
6 0.000000
7 0.000000
8 0.000000
9 0.000000
10 0.000000
11 0.000000
12 0.000000
13 0.000000
14 0.000000
15 0.000000
16 0.000000
17 0.000000
18 0.000000
19 0.000000
20 0.000000
21 0.000000
22 0.000000
23 0.000000
24 0.000000
25 0.000000
26 0.000000
27 0.000000
28 0.000000
29 0.000000
30 0.000000
31 0.000000
32 0.000000
33 0.000000
34 0.000000
35 0.000000
36 0.000000
37 0.000000
38 0.000000
39 0.000000
40 0.000000
41 0.000000
42 0.000000
43 0.000000
44 0.000000
45 0.000000
46 0.000000
47 0.000000
48 0.000000
49 0.000000
50 0.000000
51 0.000000
52 0.000000
53 0.000000
54 0.000000
55 0.000000
56 0.000000
57 0.000000
58 0.000000
59 0.000000
60 0.000000
61 0.000000
62 0.000000
63 0.000000
64 0.000000
65 0.000000
66 0.000000
67 0.000000
68 0.000000
69 0.000000
70 0.000000
71 0.000000
72 0.000000
73 0.000000
74 0.000000
75 0.000000
76 0.000000
77 0.000000
78 0.000000
79 0.000000
80 0.000000
TrainOutput（global_step = 80，training_loss = 0.0，metrics = {&#39;train_runtime&#39;：25.3789，&#39;train_samples_per_second&#39;：6.304，&#39;train_steps_per_second&#39;：3.152，&#39;total_flos&#39;：117937578909696.0，&#39;train_loss&#39;：0.0，&#39;epoch&#39;： 0.004})
]]></description>
      <guid>https://stackoverflow.com/questions/78404768/neftune-receiving-0-training-loss-on-transformers</guid>
      <pubDate>Mon, 29 Apr 2024 19:23:04 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[我有以下输入矩阵
inp_tensor = torch.tensor(
        [[0.7860, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.7980, 0.0000],
        [1.0000, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.0000, 1.0000]])

和零元素的索引
mask_indices = torch.tensor(
[[7, 2],
[2, 6]])

如何从与以下矩阵的乘法中排除非零元素：
my_tensor = torch.tensor(
        [[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.2566, 0.7936, 0.9408],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696],
        [0.4414, 0.2969, 0.8317]])

也就是说，不要将其相乘（包括零）：
a = torch.mm(inp_tensor, my_tensor)
打印（一）
张量([[1.7866, 2.5468, 1.6330],
        [2.2041、2.5388、2.3315]]）

我想排除零个元素（以及 my_tensor 的相应行）：
inp_tensor = torch.tensor(
        [[0.7860, 0.1115, 0.6524, 0.6057, 0.3725, 0.7980]]) # 删除零个元素

my_tensor = torch.tensor(
        [[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696]]) # 删除对应的零元素行

b = torch.mm(inp_tensor, my_tensor)
打印(b)
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330]])

inp_tensor = torch.tensor([[1.0000, 0.1115, 0.6524, 0.6057, 0.3725, 1.0000]]) # 删除零个元素

my_tensor = torch.tensor(
        [
        [0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.4414, 0.2969, 0.8317]]) # 删除对应的零元素行

c = torch.mm(inp_tensor, my_tensor)
打印（三）
&gt;&gt;&gt;&gt;&gt;张量([[2.2041, 2.5388, 2.3315]])
打印（火炬.cat（[b，c]））
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330],
        [2.2041、2.5388、2.3315]]）

我需要它是高效的（即，没有for循环），因为我的张量非常大，并且还需要保持梯度（即，如果我调用optimizer.backward( ）更新计算图中的相关参数）]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    <item>
      <title>随机森林 - 优化 AUC 或 F1 分数</title>
      <link>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</link>
      <description><![CDATA[我在 sklearn 中使用随机森林，并且我的数据集相当不平衡（20% 为正类，80% 为其他类）。有没有办法让它针对一些考虑到这一点的指标进行训练（优化），比如 AUC 分数或 F1 分数？我可以使用什么技巧来推动它朝这个方向发展吗？
到目前为止，我想到/尝试过的唯一方法是使用不同的类别权重。
或者，是否有其他实现（或其他模型，例如 xgboost）允许我使用这样的自定义指标？]]></description>
      <guid>https://stackoverflow.com/questions/78402507/random-forest-optimize-for-auc-or-f1-score</guid>
      <pubDate>Mon, 29 Apr 2024 11:49:58 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：基数为 10 的 int() 的文字无效：Q-learning 中的“”</title>
      <link>https://stackoverflow.com/questions/78399063/valueerror-invalid-literal-for-int-with-base-10-in-q-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78399063/valueerror-invalid-literal-for-int-with-base-10-in-q-learning</guid>
      <pubDate>Sun, 28 Apr 2024 17:29:11 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法评估模型是否能够识别有影响的变量（使用 make_classification 生成的变量）？</title>
      <link>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</link>
      <description><![CDATA[我有一个关于 scikit-learn 的 make_classification 的问题。我使用 make_classification（二元分类任务）创建了一个数据集，目的是测试不同模型区分重要特征和不太重要特征的能力。
如何设置一个实验来评估模型是否能够识别有影响的变量？
我查看了 make_classification 的文档，但不幸的是我没有进一步了解。
我设置了以下内容：
X,y = make_classification(n_samples=50000, n_features=10, n_informative=5,
                    n_redundant=2、n_repeated=0、n_classes=2、n_clusters_per_class=2、
                          类间隔=1，
                   Flip_y=0.01，权重=[0.9,0.1]，shuffle=True，random_state=42）

谢谢您，我们非常感谢任何想法或建议。]]></description>
      <guid>https://stackoverflow.com/questions/78398017/is-there-a-way-to-evaluate-whether-a-model-is-able-to-identify-the-variables-tha</guid>
      <pubDate>Sun, 28 Apr 2024 11:37:08 GMT</pubDate>
    </item>
    <item>
      <title>在 lightgbm 中，当数据集构建中已经存在时，为什么 train 和 cv API 接受 categorical_feature 参数</title>
      <link>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</link>
      <description><![CDATA[以下是.cv lightgbm的API
&lt;块引用&gt;
lightgbm.cv（params，train_set，num_boost_round = 100，folds = None，nfold = 5，stratified = True，shuffle = True，metrics = None，feval = None，init_model = None，feature_name =&#39;auto&#39;，categorical_feature =&#39;auto&#39;，fpreproc=None，seed=0，callbacks=None，eval_train_metric=False，return_cvbooster=False）

有一个参数cateogrical_feature
&lt;块引用&gt;
分类特征。如果是 int 列表，则解释为索引。如果是 str 列表，则解释为功能名称（还需要指定 feature_name）。

现在是 .train API 
&lt;块引用&gt;
lightgbm.train(params, train_set, num_boost_round=100, valid_sets=None, valid_names=None, feval=None, init_model=None, feature_name=&#39;auto&#39;, categorical_feature=&#39;auto&#39;, keep_training_booster=False, 回调=None ）

这里还有一个categorical_feature参数。这方面的文档与上面相同
现在，您注意到这两个 API 都使用 lightgbm 数据集 本身带有一个categorical_feature 参数。文档完全一样
问题：

如果两者都指定，哪一个优先？
建议在哪一个位置指定 categorical_feature？
这两种选择在 lightgbm 管道的工作内部是否有任何不同？
]]></description>
      <guid>https://stackoverflow.com/questions/78383840/in-lightgbm-why-do-the-train-and-the-cv-apis-accept-categorical-feature-argument</guid>
      <pubDate>Thu, 25 Apr 2024 10:03:27 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker实例中的CUDA路径解决NameError：名称'_C'未使用GroundingDINO定义</title>
      <link>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</link>
      <description><![CDATA[我正在尝试在 Sagemaker 实例中安装和使用 grounding dino（使用 GPU ）但我收到错误：
NameError：名称“_C”未定义

我发现原因是因为变量CUDA_HOME没有配置所以要解决它我需要设置变量，但是在搜索答案后（我已经检查了公共路径/usr/local/cuda）我找不到sagemaker实例中cuda的安装路径。
cuda 安装在 sagemaker 实例中的什么位置以便我可以设置 CUDA_HOME？]]></description>
      <guid>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</guid>
      <pubDate>Fri, 26 Jan 2024 18:45:06 GMT</pubDate>
    </item>
    </channel>
</rss>