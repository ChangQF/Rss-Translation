<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 02 Feb 2024 09:14:29 GMT</lastBuildDate>
    <item>
      <title>洪水预测模型</title>
      <link>https://stackoverflow.com/questions/77925474/flood-prediction-model</link>
      <description><![CDATA[我有一个带有列的河水测量站的数据集
每天的“water_level_8am”、“water_level_9am”、“24hr_rainfall”，我有洪水风险级别。
我需要建立一个机器学习模型，考虑最近 7 天的水位和降雨量数据，并在不知道第 8 天的数据的情况下预测第 8 天的水位。然后根据预测的水位可以判断是否存在洪水风险。任何人都可以帮忙解决这个问题
我尝试了一些机器学习模型，例如
KNN分类器
逻辑回归
支持向量分类
决策树分类
随机森林分类器。
但我不知道如何正确应用它们]]></description>
      <guid>https://stackoverflow.com/questions/77925474/flood-prediction-model</guid>
      <pubDate>Fri, 02 Feb 2024 08:01:16 GMT</pubDate>
    </item>
    <item>
      <title>我自己的 MNIST 数据集神经网络的成本函数没有减少</title>
      <link>https://stackoverflow.com/questions/77925060/cost-function-not-decreasing-for-my-own-neural-network-for-mnist-dataset</link>
      <description><![CDATA[类 MLP():
    
    def __init__(自身、输入节点、隐藏节点、输出节点):
        self.input_nodes = input_nodes
        self.hidden_​​nodes = 隐藏节点
        self.output_nodes = 输出节点
        
        
        self.input_weights = np.random.randn(self.hidden_​​nodes, self.input_nodes) / np.sqrt(self.input_nodes)
        self.hidden_​​weights = np.random.rand(self.output_nodes, self.hidden_​​nodes) / np.sqrt(self.hidden_​​nodes)
        self.hidden_​​bias = np.zeros((self.output_nodes, 1))
        self.input_bias = np.zeros((self.hidden_​​nodes, 1))
         
        
    def feed_forward(自身,X):
        
        self.Z1 = np.dot(self.input_weights, X) + self.input_bias
        self.A1 = self.sigmoid(self.Z1)
        self.Z2 = np.dot(self.hidden_​​weights, self.A1) + self.hidden_​​bias
        输出 = softmax(self.Z2)
        
        返回
        
        
        
    def sigmoid(自身, x):
        返回 np.where(x &gt;= 0,
                    1 / (1 + np.exp(-x)),
                    np.exp(x) / (1 + np.exp(x)))
        
        
        
    def backprop（自身，inputs_list，targets_list）：
        
        m = 目标列表大小
        输出 = self.feed_forward(inputs_list)
        输出错误 = 输出 - 目标列表
        self.binary_loss = -np.mean(targets_list * np.log(outs) + (1 - Targets_list) * np.log(1 -outs))
        打印（self.binary_loss）
        soft_error = 出局数 * (1-出局数)
        dz2 = 输出错误 * 软错误
        dw2 = 1/m * np.dot(dz2, self.A1.T)
        db2 = 1/m * dz2
        da1 = np.dot(self.hidden_​​weights.T, dz2)
        dz1 = da1 * 自身.A1*(1-自身.A1)
        dw1 = 1/m * np.dot(dz1, input_list.T)
        db1 = 1/m * dz1
        
        
        
        返回 dw1、dw2、db1、db2
    
    
    def get_predictions(self, X2):
        返回 np.argmax(X2, 0)
    
    
    def 火车（自我，inputs_list，targets_list，epochs = 100，lr = 0.001）：
        
        对于范围内的 i（纪元）：
            #print(“迭代：” + str(i))
            
            
            input_weights，hidden_​​weights，input_bias，hidden_​​bias = self.backprop（inputs_list，targets_list）
            self.input_weights = self.input_weights - (lr*input_weights)
            self.hidden_​​weights = self.hidden_​​weights - (lr*hidden_​​weights)
            self.input_bias = self.input_bias - (lr*input_bias)
            self.hidden_​​bias = self.hidden_​​bias - (lr*hidden_​​bias)
            
        输出 = self.feed_forward(inputs_list)
            
        返回 self.get_predictions(输出)

这就是我传递来训练神经网络的内容。为了测试我的神经网络，我训练了1000 个示例。 X_training 只是从 mnist 数据集中读取 train.csv。
X_data = np.array(X_training).T
X_train = X_data[1:785]
X_train.shape



X_train_1 = X_train[:, 0:1000]
X_train_1.shape


Y_train = X_data[0]
Y_targs = np.eye(10)[Y_train]

Y_targs = Y_targs.T
Y_targs.shape


Y_targs_1 = Y_targs[:, 0:1000]
Y_targs_1.shape


c = MLP(784, 100, 10) # 创建具有 784 个输入节点、100 个隐藏层和 10 个输出节点的 MLP 对象。

b = c.train(X_train_1, Y_targs_1, 500, 0.01) # 这给出了成本函数的输出，其永远不会减少



如您所见，在训练 mnist 数据集时，我的成本函数没有减少。它适用于成本函数起作用的一个示例，但是，当存在一个或多个示例时，成本永远不会下降。我想知道我的反向传播方法是否有问题，但看起来没问题？我使用 scipy 库中的 softmax。我将不胜感激任何建议！我基本上对每个输出都进行了热编码，因此我的尺寸看起来也正确。
&lt;前&gt;&lt;代码&gt;0.9239303973120006
0.923930392942585
0.9239303885732107
0.9239303842038776
0.923930379834586
0.9239303754653354
0.9239303710961263
0.9239303667269585
0.9239303623578322
0.923930357988747
0.9239303536197034
0.9239303492507012
0.9239303448817403
0.9239303405128209
0.9239303361439426
0.9239303317751062
0.9239303274063112
0.9239303230375575
0.9239303186688456
0.9239303143001749
0.9239303099315459
0.9239303055629583
0.9239303011944123
0.923930296825908
0.9239302924574451
0.9239302880890238
0.9239302837206442
0.9239302793523064

]]></description>
      <guid>https://stackoverflow.com/questions/77925060/cost-function-not-decreasing-for-my-own-neural-network-for-mnist-dataset</guid>
      <pubDate>Fri, 02 Feb 2024 06:29:54 GMT</pubDate>
    </item>
    <item>
      <title>IBM Watson Annotator for Clinical Data 是否仍然可以使用？</title>
      <link>https://stackoverflow.com/questions/77924873/is-ibm-watson-annotator-for-clinical-data-still-available-for-use</link>
      <description><![CDATA[我尝试访问 IBM 网站，但没有该名称的产品，并且它不断引导我进入一些错误页面
我希望它用于从我的文本数据中提取相关的临床文本，或者您有其他建议。]]></description>
      <guid>https://stackoverflow.com/questions/77924873/is-ibm-watson-annotator-for-clinical-data-still-available-for-use</guid>
      <pubDate>Fri, 02 Feb 2024 05:35:14 GMT</pubDate>
    </item>
    <item>
      <title>OpenPCDet 与 Windows 兼容还是仅与 Linux 兼容？</title>
      <link>https://stackoverflow.com/questions/77924600/is-openpcdet-compatible-with-windows-or-only-linux</link>
      <description><![CDATA[我目前正在使用 OpenPCDet 开发一个项目，在 Windows 环境中设置它时遇到一些问题。官方文档主要参考Linux环境。我想知道 OpenPCDet 是否本质上与 Windows 不兼容，或者是否有特定步骤使其在 Windows 上工作。
是否有人在 Windows 上成功运行 OpenPCDet，如果是，您能否提供一些设置指导或资源？或者，如果 OpenPCDet 仅限于 Linux 环境，是否有针对 Windows 用户的推荐解决方法？
预先感谢您的帮助和见解。
我尝试设置环境，但是当我运行 python setup.pydevelopment 时遇到错误。]]></description>
      <guid>https://stackoverflow.com/questions/77924600/is-openpcdet-compatible-with-windows-or-only-linux</guid>
      <pubDate>Fri, 02 Feb 2024 03:56:47 GMT</pubDate>
    </item>
    <item>
      <title>Imagnet-21K 访问类标签？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77923909/imagnet-21k-accessing-the-class-labels</link>
      <description><![CDATA[是否可以访问 21K 版本 ImageNet 的类标签？
我正在尝试实现一个图像分类网络应用程序。
我正在使用 image net 1K，因为我只能在网上找到那些类标签，但版本很糟糕，它认为猫头鹰是黄鼠狼......有人帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/77923909/imagnet-21k-accessing-the-class-labels</guid>
      <pubDate>Thu, 01 Feb 2024 23:21:18 GMT</pubDate>
    </item>
    <item>
      <title>这个elasticsearch设置是否使用ML节点？</title>
      <link>https://stackoverflow.com/questions/77923033/does-this-elasticsearch-setup-even-use-ml-node</link>
      <description><![CDATA[我按照以下示例设置了用于图像相似性搜索的 Elasticsearch 集群：https ://github.com/radoondas/flask-elastic-image-search
由于不熟悉elasticsearch，我盲目地遵循了这个示例，其中包括一个带有预训练模型的 ML 节点。效果很好。但是，我怀疑我们实际上并没有使用 ML 节点。
我在应用程序中提取密集向量，然后对它们进行索引，并且在查询时也在应用程序中提取向量。我不使用elasticsearch来提取密集向量。
有什么“魔法”吗？当我索引密集向量或执行 KNN 查询时，这使得 Elasticsearch 在幕后使用预训练模型？或者预训练模型和机器学习节点都是我们在实现中不需要的额外东西？]]></description>
      <guid>https://stackoverflow.com/questions/77923033/does-this-elasticsearch-setup-even-use-ml-node</guid>
      <pubDate>Thu, 01 Feb 2024 20:00:42 GMT</pubDate>
    </item>
    <item>
      <title>SMOTE 索引越界</title>
      <link>https://stackoverflow.com/questions/77922807/smote-index-out-of-bounds</link>
      <description><![CDATA[SMOTE 错误
当我尝试使用 SMOTE 进行大约 50 个标签的不平衡多标签分类时，我收到此错误，但我不知道为什么会发生这种情况。
数据极不平衡
例如，标签24有2500个样本，标签4只有100个
数据集包含 37000 个样本
我看到的所有教程都展示了如何将数据简单地插入到 SMOTE 中，并且一切都运行良好，但在我的情况下却不然，我不知道为什么。
有人可以帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/77922807/smote-index-out-of-bounds</guid>
      <pubDate>Thu, 01 Feb 2024 19:16:26 GMT</pubDate>
    </item>
    <item>
      <title>在google colab上使用tensorflow的问题</title>
      <link>https://stackoverflow.com/questions/77922080/problems-with-using-tensorflow-on-google-colab</link>
      <description><![CDATA[我对这一切都很陌生。有人可以告诉我发生了什么事吗？那么我该如何解决这个问题呢？
在此处输入图像描述
基本上，我想使用 tf，但我被卡住了。因为我以前从未使用过它。
我想将它与我的检测模型一起使用。
感谢大家的帮助。
谨此致以崇高敬意，祝大家好运。]]></description>
      <guid>https://stackoverflow.com/questions/77922080/problems-with-using-tensorflow-on-google-colab</guid>
      <pubDate>Thu, 01 Feb 2024 17:05:18 GMT</pubDate>
    </item>
    <item>
      <title>Python单变量线性回归给出水平斜率和高成本</title>
      <link>https://stackoverflow.com/questions/77921840/python-univariate-linear-regression-gives-horizontal-slope-and-high-cost</link>
      <description><![CDATA[我正在做线性回归的作业，但我的预测斜率遇到了问题。无论我做什么，它都会显示为一条水平线。成本也停留在 908787，没有任何改善。我遵循教授的职能，因为他希望这个模型从头开始编码。谁能告诉我我做错了什么？
将 numpy 导入为 np
从 sklearn.datasets 导入 load_diabetes
将 matplotlib.pyplot 导入为 plt

#数据集准备
糖尿病 = load_diabetes()
X = 糖尿病.数据
Y = 糖尿病.目标

# 仅使用一个特征（BMI）
X = X[:, np.newaxis, 2]
X = X.reshape((-1,1))

Y = np.expand_dims(Y, 1)
数据 = np.append(X, Y, 1)

# 随机洗牌
np.随机.种子(1201)
np.random.shuffle(数据)

# 分割数据
总样本 = len(数据)
训练 = 数据[:int(total_sample*0.70)]
dev = 数据[int(total_sample*0.70):int(total_sample*0.85)]
测试=数据[int(total_sample*0.85):]

def get_features_and_labels(数据):
  特征=数据[:,:-1]
  标签=数据[:,-1]
  返回特征、标签

train_x, train_y = get_features_and_labels(train)
dev_x, dev_y = get_features_and_labels(dev)
test_x, test_y = get_features_and_labels(测试)

# 线性回归模型

def univariate_线性_回归（theta，输入）：
  pred = theta[0] + theta[1]*输入
  返回预测值

# 成本函数
defcompute_cost(Y_pred, Y_true):
  J = 1/(2*m) * np.sum((Y_pred - Y_true)**2) # 均方误差
  返回J

def update_theta(theta, X, Y_true, Y_pred, lr):
  theta[0] = theta[0] - (lr * (1/m) * np.sum(Y_pred - Y_true))
  theta[1] = theta[1] - (lr * (1/m) * np.sum((Y_pred - Y_true) * X))
  返回θ

&lt;前&gt;&lt;代码&gt;theta = [0.0, 0.0]
lr = 0.0001
m = len(train_y)
k = 0
plt.figure(figsize=(30, 30))

对于范围（500）内的 i：
  pred = 单变量_线性_回归（theta，train_x）
  成本=compute_cost(pred,train_y)
  theta = update_theta(theta, train_x, train_y, pred, lr)


  如果（i%20==0）：
    print(f&quot;迭代 {i}, 成本: {cost}, Theta: {theta}&quot;)
    k+=1
    plt.子图(5, 5, k)
    plt.scatter(train_x, train_y, color=&#39;b&#39;)
    plt.plot(train_x, pred, &#39;g&#39;)

 s = &#39;theta:[%.4f, %.4f]&#39; %(theta[0], theta[1])
    c = &#39;成本：%.4f&#39; %成本
    plt.title(s+&#39;\n&#39;+c)

图形输出：

我尝试使用学习曲线和初始 theta，但结果仍然相同。]]></description>
      <guid>https://stackoverflow.com/questions/77921840/python-univariate-linear-regression-gives-horizontal-slope-and-high-cost</guid>
      <pubDate>Thu, 01 Feb 2024 16:26:26 GMT</pubDate>
    </item>
    <item>
      <title>将ml模型部署到现有的html和css网站[关闭]</title>
      <link>https://stackoverflow.com/questions/77915496/deploying-ml-model-to-the-existing-website-of-html-and-css</link>
      <description><![CDATA[我们必须将我们开发的用于手语检测的机器学习模型部署到视频通话网站，请帮忙
我尝试部署机器学习模型，但无法成功完成，您能否帮助我完成部署部分和代码]]></description>
      <guid>https://stackoverflow.com/questions/77915496/deploying-ml-model-to-the-existing-website-of-html-and-css</guid>
      <pubDate>Wed, 31 Jan 2024 17:55:46 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 相关模式是违反直觉的 [关闭]</title>
      <link>https://stackoverflow.com/questions/77910332/shap-correlation-patterns-are-counterintuitive</link>
      <description><![CDATA[我开发了一个 ANN 模型来根据 Elisa 数据预测蛋白质翻译后修饰模式。为了简单起见，如何、可行性和参数对于我的问题并不重要，并且省略了一些细节。
对于给定的蛋白质，我将其称为蛋白质 X，它具有泛素作为修饰，但没有磷酸化模式。
我用各种翻译后修饰模式训练了人工神经网络，但有一个关键信息：我的训练数据不包含任何泛素模式（假设有一个原因）
因此，当我使用一组抗体进行 ELISA 时，抗体 a 特异性针对泛素模式，抗体 b 特异性针对磷酸化模式。当我使用抗体 a、抗体 b（和其他抗体）预测蛋白质 x 修饰模式时，我们获得了相当好的准确性。
为了解释模型的工作原理，我运行了 SHAP 分析和二分图来显示特征重要性（抗体）和修改，但得到了令人困惑的结果

对于抗体 a，除泛素外，其他修饰模式的 SHAP 值存在正值和负值，泛素是其特异性的

对于抗体 b，我们还发现了除磷酸化之外的修饰模式的正向和负向 SHAP 值，而蛋白质 x 并不真正具有磷酸化。


那么我该如何解释为什么 SHAP 产生这种模式：1）抗体 a 与其靶标泛素没有任何 SHAP 相关性，但对其其他靶标有 SHAP 相关性，2）抗体 b 与其靶标也没有 SHAP 相关性，但与其他抗体有 SHAP 相关性。其他人代替。
这又是令人困惑的，因为我预计抗体 a 与泛素有 SHAP 相关性，但与其他蛋白没有 SHAP 相关性，然后抗体 b 不应该有任何 SHAP 相关性，因为它的目标是磷酸化，但蛋白 x 没有磷酸化。
我不太相信或无法将 SHAP 的一些限制联系起来，因为它显示了模型的隐藏模式/关系，而不是我们在“现实生活”中所期望的
有人可以对这个观察到的 SHAP 分析提供更细致的见解吗？]]></description>
      <guid>https://stackoverflow.com/questions/77910332/shap-correlation-patterns-are-counterintuitive</guid>
      <pubDate>Wed, 31 Jan 2024 01:27:50 GMT</pubDate>
    </item>
    <item>
      <title>我对 MLagents 2.3.0 有这个问题 [已关闭]</title>
      <link>https://stackoverflow.com/questions/77892933/i-have-this-issue-with-mlagents-2-3-0</link>
      <description><![CDATA[当我开始使用Unity编辑器2020年3月24日学习时，培训立即结束。之后，我看到这个输出
&lt;块引用&gt;
引发 Unity CommunicationException(“UnityEnvironment 工作线程：接收失败。”)
mlagents_envs.exception.UnityCommunicationException：UnityEnvironment工作人员：接收失败。

我不知道如何解决这个问题。我们将感激地接受您的所有建议和决定。]]></description>
      <guid>https://stackoverflow.com/questions/77892933/i-have-this-issue-with-mlagents-2-3-0</guid>
      <pubDate>Sat, 27 Jan 2024 21:49:45 GMT</pubDate>
    </item>
    <item>
      <title>线性回归 RMSE [关闭]</title>
      <link>https://stackoverflow.com/questions/77892345/linear-regression-rmse</link>
      <description><![CDATA[尝试比较不同多项式次数的均方根误差，但最终得到相同的 RMSE。对于不同的学位，我应该得到不同的 RMSE，但我对所有学位都得到相同的 RMSE。我不明白为什么。
train_rmse_errors=[]
test_rmse_errors=[]

对于范围 (1,20) 中的 d：
    
    poly_converter = 多项式特征（度=d，include_bias=False）
    poly_fearures = poly_converter.fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.33, random_state=42)
    模型=线性回归()
    model.fit(X_train,y_train)
    
    train_pred = model.predict(X_train)
    test_pred = model.predict(X_test)
    
    train_rmse = np.sqrt(mean_squared_error(y_train,train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test,test_pred))
    
    train_rmse_errors.append(train_rmse)
    test_rmse_errors.append(test_rmse)
]]></description>
      <guid>https://stackoverflow.com/questions/77892345/linear-regression-rmse</guid>
      <pubDate>Sat, 27 Jan 2024 18:38:33 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“LinearSVC”对象没有属性“coef_”</title>
      <link>https://stackoverflow.com/questions/71160325/attributeerror-linearsvc-object-has-no-attribute-coef</link>
      <description><![CDATA[我使用 LinearSVC 来解决多标签分类问题。由于 LinearSVC 不提供 predict_proba 方法，因此我决定使用 CaliberatedClassifierCV 将决策函数缩放为 [0, 1] 概率。 p&gt;
从 sklearn.svm 导入 LinearSVC
从 sklearn.calibration 导入 CaliberatedClassifierCV

分类器 = CalibrateClassifierCV(LinearSVC(class_weight = &#39;平衡&#39;, max_iter = 100000)
分类器.fit(X_train, y_train)

但是，我还需要访问权重 coef_，但 classifier.base_estimator.coef_ 引发以下错误：
AttributeError：“LinearSVC”对象没有属性“coef_”

我认为classifier.base_estimator返回了校准的分类器并允许访问其所有属性。预先感谢您向我解释我的误解。]]></description>
      <guid>https://stackoverflow.com/questions/71160325/attributeerror-linearsvc-object-has-no-attribute-coef</guid>
      <pubDate>Thu, 17 Feb 2022 14:49:39 GMT</pubDate>
    </item>
    <item>
      <title>如何在 scikit-learn 中显示每次迭代的成本函数？</title>
      <link>https://stackoverflow.com/questions/38179687/how-do-you-show-cost-function-per-iteration-in-scikit-learn</link>
      <description><![CDATA[我最近一直在运行一些线性/逻辑回归模型，我想知道如何输出每次迭代的成本函数。 sci-kit LinearRegression 中的参数之一是“maxiter”，但实际上您需要查看成本与迭代，以找出该值真正需要的值，即是否值得花费计算时间来运行更多迭代等。
我确信我遗漏了一些东西，但我会认为有一种方法可以输出此信息？
提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/38179687/how-do-you-show-cost-function-per-iteration-in-scikit-learn</guid>
      <pubDate>Mon, 04 Jul 2016 08:08:35 GMT</pubDate>
    </item>
    </channel>
</rss>