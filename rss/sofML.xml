<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 30 Dec 2024 09:17:57 GMT</lastBuildDate>
    <item>
      <title>mlagents-learn --help 出现错误（python=3.11、3.10、3.9、3.8）</title>
      <link>https://stackoverflow.com/questions/79316958/mlagents-learn-help-is-giving-errors-python-3-11-3-10-3-9-3-8</link>
      <description><![CDATA[我正在尝试安装 mlagents。我进入了 python 部分，但在使用 pyenv 创建虚拟环境并将本地版本设置为 3.10、3.9 和 3.8 后，它们都不起作用。我升级了 pip，安装了 mlagents，然后安装了 torch、torchvision 和 torchaudio。然后我测试了 mlagents-learn --help，然后因为错误安装了 protobuf 3.20.3。然后我再次测试，得到以下错误
(venv) D:\Unity\AI Ecosystem&gt;mlagents-learn --help
回溯（最近一次调用）：
文件“&lt;frozen runpy&gt;”，第 198 行，在 _run_module_as_main
文件“&lt;frozen runpy&gt;”，第 88 行，在 _run_code
文件“D:\Unity\AI Ecosystem\venv\Scripts\mlagents-learn.exe\__main__.py”，第 4 行，在 &lt;module&gt;
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\trainers\learn.py”，第 2 行，在 &lt;module&gt;
从 mlagents 导入 torch_utils
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\torch_utils\__init__.py”，第 1 行，位于 &lt;module&gt;
从 mlagents.torch_utils.torch 导入 torch 作为 torch # noqa
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\torch_utils\torch.py​​”，第 6 行，位于 &lt;module&gt;
从 mlagents.trainers.settings 导入 TorchSettings
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\trainers\settings.py”，第 644 行，位于 &lt;module&gt;
class TrainerSettings(ExportableSettings):
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\mlagents\trainers\settings.py”，第 667 行，位于 TrainerSettings
cattr.register_structure_hook(
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\cattr\converters.py”，第 207 行，位于 register_structure_hook
self._structure_func.register_cls_list([(cl, func)])
文件“D:\Unity\AI Ecosystem\venv\Lib\site-packages\cattr\dispatch.py​​”，第 55 行，位于 register_cls_list
self._single_dispatch.register(cls, handler)
文件&quot;C:\Users\Ebrah\AppData\Local\Programs\Python\Python311\Lib\functools.py&quot;，第 864 行，在寄存器中
raise TypeError(
TypeError: `register()` 的第一个参数无效。 typing.Dict[mlagents.trainers.settings.RewardSignalType, mlagents.trainers.settings.RewardSignalSettings] 不是类或联合类型。

我尝试安装 cattrs 1.5.0，但错误仍然存​​在。正如我之前所说，我也尝试了 3.11、3.10、3.9 和 3.8，但在所有这些版本中都出现了相同的错误。我的 unity 版本是 2022.3.5f1，但我看不出这会有什么不同。我的 pyenv 版本是 3.1.1。我在 Windows 11 上并且正在使用 pyenv-win。]]></description>
      <guid>https://stackoverflow.com/questions/79316958/mlagents-learn-help-is-giving-errors-python-3-11-3-10-3-9-3-8</guid>
      <pubDate>Mon, 30 Dec 2024 06:36:09 GMT</pubDate>
    </item>
    <item>
      <title>由于模拟程度高，蒙特卡洛树搜索在 1 步内失误</title>
      <link>https://stackoverflow.com/questions/79316664/monte-carlo-tree-search-blundering-mate-in-1-due-to-high-simulations</link>
      <description><![CDATA[我很难理解在 MCTS 中选择终端节点时会发生什么。我看到这里、这里和这里有几篇标题类似的帖子，但它们似乎没有解释我的难点。
假设是白棋先走，W 步虽然在下一步 B 步时失误失利，但仍被扩展，并恰好在出局时获胜。经过反向传播后，W 得分较高，因此选择一个子节点进行扩展，即 B。B 是终端节点，因此我们反向传播黑棋获胜。现在 B 得分较高。现在我看到两种可能性：

允许再次选择 B（尽管它没有子节点），在这种情况下，B 会不断积累越来越多的得分，因为它每次都赢得黑棋并继续被选中。然后 W 将成为根节点模拟程度最高的子节点，因此尽管犯了错误，但仍被选中进行游戏（我根据维基百科文章选择模拟程度最高的节点）。

我不允许再次选择 B。但我认为这会带来另一个问题。如果当前状态是在 W 步之后，并且是黑棋先行，那么黑棋只会选择 B 一次，尽管 B 赢得了比赛，但黑棋不会获胜，因为 B 步的模拟次数会少于其他步。


这似乎是算法的一个非常基本的部分，所以我肯定我错过了一些关于它如何工作的显而易见的东西。提前感谢您的帮助解释。]]></description>
      <guid>https://stackoverflow.com/questions/79316664/monte-carlo-tree-search-blundering-mate-in-1-due-to-high-simulations</guid>
      <pubDate>Mon, 30 Dec 2024 02:07:30 GMT</pubDate>
    </item>
    <item>
      <title>训练最小 U-Net 时的方法错误</title>
      <link>https://stackoverflow.com/questions/79316648/methoderror-in-training-minimal-u-net</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79316648/methoderror-in-training-minimal-u-net</guid>
      <pubDate>Mon, 30 Dec 2024 01:52:08 GMT</pubDate>
    </item>
    <item>
      <title>在 MacOS 上构建 libtorch 时出现链接错误</title>
      <link>https://stackoverflow.com/questions/79316482/linking-error-when-building-libtorch-on-macos</link>
      <description><![CDATA[我正在按照 pytorch api 教程进行操作，但出现以下错误
ld：未知选项：--no-as-needed --as-needed --no-as-needed --as-needed
c++：错误：链接器命令失败，退出代码为 1（使用 -v 查看调用）

我尝试使用 brew install pytorch 手动链接 torch，使用
g++ example-app.cpp -o out -I/opt/homebrew/Cellar/pytorch/2.5.1_3/libexec/lib/python3.13/site-packages/torch/include/torch/csrc/api/include -std=c++17

但我收到此错误
/opt/homebrew/Cellar/pytorch/2.5.1_3//libexec/lib/python3.13/site-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3:10: 致命错误：未找到“torch/csrc/autograd/autograd.h”文件
]]></description>
      <guid>https://stackoverflow.com/questions/79316482/linking-error-when-building-libtorch-on-macos</guid>
      <pubDate>Sun, 29 Dec 2024 22:41:29 GMT</pubDate>
    </item>
    <item>
      <title>Blenderbot：从 json 进行训练时出现关键错误</title>
      <link>https://stackoverflow.com/questions/79315340/blenderbot-key-error-while-training-from-json</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79315340/blenderbot-key-error-while-training-from-json</guid>
      <pubDate>Sun, 29 Dec 2024 09:46:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 PyTorch CNN 处理扩展 MNIST 数据集时网络没有得到改善 [关闭]</title>
      <link>https://stackoverflow.com/questions/79315321/network-not-improving-with-pytorch-cnn-for-extended-mnist-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79315321/network-not-improving-with-pytorch-cnn-for-extended-mnist-dataset</guid>
      <pubDate>Sun, 29 Dec 2024 09:30:26 GMT</pubDate>
    </item>
    <item>
      <title>如何在目录中找到给定图像的相似图像</title>
      <link>https://stackoverflow.com/questions/79315320/how-to-find-similar-images-for-given-image-in-a-directory</link>
      <description><![CDATA[我是机器学习和 Python 的新手，我正在尝试在目录中找到与给定图像最匹配（相似）的图像。
例如，我的文件夹中有 50,000 张硬币图像，并尝试找到与用户指定图像最匹配的前 10 张图像。
这是我的示例文件 https://drive.google.com/drive/folders/1pxz4nuyWfSLcrzs0QZpvqWO77ZI3Vn6M?usp=sharing
这是示例搜索图像 https://drive.google.com/file/d/1cWTxLIjG2pKW4-1g-LYfdAbccG18sPnX/view?usp=sharing
我也用 OpenCV 修改了给定的图像，但没有任何变化，这里是裁剪版本 https://drive.google.com/file/d/1AvZbPgZJvPwSBqNxVZ9N7t-DxTI_Xzsl/view?usp=sharing
预期 18206-f.jpg 应为根据指定示例文件匹配度最高的文件。
我尝试了许多算法并提供了类似下面的解决方案，但找不到合适的解决方案。

我使用了自定义训练模型进行图像分类，如这里所述 https://www.tensorflow.org/tutorials/images/classification 但我失败了，我猜我没有针对特定示例的不同文件，我还尝试了自定义数据增强机制，但再次失败（失败 = 可能找不到正确的相关文件）

我使用了https://github.com/TechyNilesh/DeepImageSearch但失败了我想这种解决方案最适合语义搜索，我需要图像到图像的搜索，例如图像相似性，而不是关键字/内容相似性等。

我使用了 Ahash、Dhash 和 Phash 等哈希算法，但在图像处于不同条件等时失败了。

我尝试了这里提到的 KNN 搜索https://stackoverflow.com/a/56881718/6799182但失败了再次。


import cv2
import os
import numpy as np

from typing import Union

def read_img_from_dir(image_dir: str, query_shape: Union[list, tuple]) -&gt; tuple[list, np.ndarray]:
name_image = []
img_array = np.empty((0, np.prod(query_shape)), dtype=np.float32)
for image_name in os.listdir(image_dir):
name_image.append(image_name)
image = cv2.imread(os.path.join(image_dir, image_name))
if not isinstance(image, np.ndarray):
# 如果路径不是图像
continue
image = cv2.resize(image, query_shape[:2][::-1])
image = image.reshape(1, -1) / 255.
img_array = np.concatenate((img_array, image))
return name_image, img_array 

def find_by_knn(query_img: np.ndarray，list_name：list [str]，数据库：np.ndarray）-&gt;; str:
query_img = query_img.reshape(1, -1) / 255.
dists = np.sqrt(np.sum((database-query_img) ** 2,axis = 1))
idx = dists.argmin()
return list_name[idx]

if __name__==&#39;__main__&#39;:
image_query = &#39;1tl-cropped.png&#39;
image_dir = &#39;sample_flat&#39;
img = cv2.imread(image_query)

# 可选：由于查询图像大小可能很大，调整大小 
# 所有图像为较小的所需形状可以避免 OOM 问题
# 并提高计算速度

# global_shape = (320, 320)
# img = cv2.resize(img, global_shape)

shape = img.shape
name_image, img_array = read_img_from_dir(image_dir, shape)
result = find_by_knn(img, name_image, img_array)
print(result)

请为我提供该任务的正确解决方案。
示例文件：
18206-b.jpg
18206-f.jpg
1853-f.jpg
示例搜索文件：
1-tl.jpg
示例搜索文件（裁剪）：
1tl-cropped.png]]></description>
      <guid>https://stackoverflow.com/questions/79315320/how-to-find-similar-images-for-given-image-in-a-directory</guid>
      <pubDate>Sun, 29 Dec 2024 09:30:09 GMT</pubDate>
    </item>
    <item>
      <title>计算模型的最小二乘误差[关闭]</title>
      <link>https://stackoverflow.com/questions/79315069/calculating-the-least-squares-error-for-a-model</link>
      <description><![CDATA[我做了一些自学，遇到了这个问题。我研究过 LSE 的问题，但我真的不明白这是怎么回事。有人能给我一个关于如何解决这个问题的简单想法吗？我已经花了好几天时间才弄清楚，但没有成功。
]]></description>
      <guid>https://stackoverflow.com/questions/79315069/calculating-the-least-squares-error-for-a-model</guid>
      <pubDate>Sun, 29 Dec 2024 06:25:46 GMT</pubDate>
    </item>
    <item>
      <title>如何防止 C# SoftMax 实现中出现溢出？</title>
      <link>https://stackoverflow.com/questions/79314811/how-do-i-prevent-overflows-in-my-c-sharp-softmax-implementation</link>
      <description><![CDATA[为了从“第一原理”的角度更好地理解机器学习，我正在实现自己的 ML 相关函数。目前，我正在尝试实现 SoftMax：
IEnumerable&lt;double&gt; SoftMax(IEnumerable&lt;double&gt; vector)
{
var exps = vector.Select(v =&gt; Math.Exp(v));
var sumExps = exps.Sum();
return exps.Select(exp =&gt; exp / sumExps);
}

如果我正确理解了 SoftMax，如果我将此函数的结果相加，即 SoftMax(vector).Sum()，则输出应始终为 1。
然而，在几乎所有情况下，这都会返回一个略大于或略小于 1 的值。通常，类似于 1.0568102998178908 或 0.9758570985704772。
我听说这种情况并不罕见（基本上是溢出问题），可以通过从输入到 Math.Exp() 的值中减去输入的最大元素来解决。所以我根据建议想出了这个实现：
IEnumerable&lt;double&gt; SoftMax(IEnumerable&lt;double&gt; vector)
{
var maxVal = vector.Max();
var exps = vector.Select(v =&gt; Math.Exp(v - maxVal));
var sumExps = exps.Sum();
return exps.Select(exp =&gt; exp / sumExps);
}

在测试我的实现时，我传入了一个随机的双精度数集合，如下所示：
IEnumerable&lt;double&gt; vector = Enumerable.Range(0, 100).Select(n =&gt; new Random().NextDouble());
var softMaxVec = SoftMax(vector);
Console.WriteLine(softMaxVec.Sum());

但是我改进后的实现仍然给我带来了同样的问题。我做错了什么？还是我误解了 SoftMax 的工作原理？]]></description>
      <guid>https://stackoverflow.com/questions/79314811/how-do-i-prevent-overflows-in-my-c-sharp-softmax-implementation</guid>
      <pubDate>Sun, 29 Dec 2024 01:01:45 GMT</pubDate>
    </item>
    <item>
      <title>确定在提供的视频中同一辆车被拍摄的次数</title>
      <link>https://stackoverflow.com/questions/79313854/identify-how-many-times-same-vehicle-was-captured-in-the-provided-video</link>
      <description><![CDATA[正在进行视频分析作业，我需要捕捉在给定视频中同一车辆被拍摄的次数。
到目前为止，使用 YOLO11 能够识别汽车、自行车、公共汽车和卡车等车辆。相应地，在视频帧中绘制车辆的矩形。
我不明白如何用一些识别码标记车辆。这样，当同一辆车出现在视频帧中时，我可以增加该车辆的数量。
添加我尝试过的代码
from ultralytics import YOLO
import cv2
from enum import Enum

class DetectionType(Enum):
CAR = 2
MOTORCYCLE = 3
BUS = 5
TRUCK = 6

coco_model = YOLO(&#39;yolo11n.pt&#39;)
cap = cv2.VideoCapture(&#39;testVideo.mp4&#39;)

vehicles = [
DetectionType.CAR.value, 
DetectionType.MOTORCYCLE.value, 
DetectionType.BUS.value,
DetectionType.TRUCK.value
]

ret = True

while ret:
ret, frame = cap.read()

if ret:
#detect vehicle
detections_model = coco_model(frame)[0]

for detection in detections_model.boxes.data.tolist():
x1, y1, x2, y2, score, class_id = detection

if int(class_id) in vehicles:
x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

# 在窗口中显示帧 
cv2.imshow(&#39;video&#39;, frame)

if cv2.waitKey(33) == 27:
break

cap.release()
cv2.destroyAllWindows() 

任何建议或代码片段都会帮助我完成这项作业。]]></description>
      <guid>https://stackoverflow.com/questions/79313854/identify-how-many-times-same-vehicle-was-captured-in-the-provided-video</guid>
      <pubDate>Sat, 28 Dec 2024 13:29:54 GMT</pubDate>
    </item>
    <item>
      <title>需要 chromadb 和 transformers 一起使用，但要求有冲突，因为 chromadb 需要 0.20 版本的 tokenizers，而后者需要 0.21 版本</title>
      <link>https://stackoverflow.com/questions/79309306/need-chromadb-transformers-together-but-have-conflicting-requirements-as-chrom</link>
      <description><![CDATA[我必须在一个项目中同时使用 chromadb 和 transformers，但 chromadb 需要 &lt;=0.20.3 版本的 tokenizers，而 transformers 需要 &gt;=0.21 版本的 tokenizers，并且与 chromadb 兼容的旧版本 transformers 需要 rust 编译器，因此这也不是一种选择。
我尝试升级 transformers、tokenizers，也尝试降级 transformers，但都不起作用，而对于所有这些，我都在使用虚拟环境。]]></description>
      <guid>https://stackoverflow.com/questions/79309306/need-chromadb-transformers-together-but-have-conflicting-requirements-as-chrom</guid>
      <pubDate>Thu, 26 Dec 2024 11:03:46 GMT</pubDate>
    </item>
    <item>
      <title>“使用 YOLO 和 EasyOCR 进行车牌识别时遇到的文本识别问题”</title>
      <link>https://stackoverflow.com/questions/79291987/text-recognition-issues-in-license-plate-recognition-using-yolo-and-easyocr</link>
      <description><![CDATA[问题
我正在开发一个车牌识别系统，使用 YOLOv8 进行检测，使用 EasyOCR 进行文本识别。虽然 YOLO 可以正确检测车牌区域，但 OCR 结果对于阿拉伯语文本和数字通常不准确。
检测到的文本示例：
检测到：“اباز”，这是无关紧要的。
检测到：“الراق”，与“العراق”部分匹配。
像“٢٦٠٤٩٩”这样的数字被准确检测到。
我尝试过的
管道设置：
YOLOv8 检测车牌并提取其边界框。
EasyOCR 处理裁剪后的车牌以进行文本识别。
文本校正：
使用 difflib.get_close_matches() 将 OCR 检测到的文本与预定义单词进行匹配（例如，“العراق”、“دهوك”）。
应用置信度阈值来过滤低置信度结果。
图像预处理：
将车牌区域转换为灰度。
调整区域大小以增强 OCR 性能。
最小可重现示例
import cv2
import easyocr
from ultralytics import YOLO

def detect_plate_with_yolo(image_path, model_path=&quot;yolov8n.pt&quot;):
model = YOLO(model_path)
img = cv2.imread(image_path)
results = model(img)
detections = results[0].boxes.xyxy.cpu().numpy()
if detections:
x1, y1, x2, y2 = map(int, detections[0])
return img[y1:y2, x1:x2]
return None

def perform_ocr_on_plate(plate_img):
reader = easyocr.Reader([&#39;ar&#39;, &#39;en&#39;], gpu=False)
plate_gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)
return reader.readtext(plate_gray, detail=1)

plate_img = detect_plate_with_yolo(&quot;path/to/image.jpg&quot;)
if plate_img is not None:
detected_text = perform_ocr_on_plate(plate_img)
print(detected_text)

预期与实际行为
预期：正确识别阿拉伯语文本和数字（例如，&quot;العراق&quot;）。
实际：部分匹配（例如，&quot;الراق&quot;）或不相关的结果（例如，&quot;اباز&quot;）。
问题
如何使用 EasyOCR 提高阿拉伯语车牌的 OCR 准确率？
有没有比 difflib.get_close_matches() 更好的文本校正替代方案？
哪些额外的预处理步骤可能有助于提高 OCR 性能？]]></description>
      <guid>https://stackoverflow.com/questions/79291987/text-recognition-issues-in-license-plate-recognition-using-yolo-and-easyocr</guid>
      <pubDate>Wed, 18 Dec 2024 17:26:40 GMT</pubDate>
    </item>
    <item>
      <title>‘super’ 对象没有属性‘__sklearn_tags__’</title>
      <link>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</link>
      <description><![CDATA[我在使用 Scikit-learn 中的 RandomizedSearchCV 拟合 XGBRegressor 时遇到了 AttributeError。错误消息指出：
&#39;super&#39; 对象没有属性 &#39;__sklearn_tags__&#39;。

当我在 RandomizedSearchCV 对象上调用 fit 方法时会发生这种情况。我怀疑它可能与 Scikit-learn 和 XGBoost 或 Python 版本之间的兼容性问题有关。我使用的是 Python 3.12，并且 Scikit-learn 和 XGBoost 都安装了最新版本。
我尝试使用 Scikit-learn 中的 RandomizedSearchCV 调整 XGBRegressor 的超参数。我希望模型能够毫无问题地拟合训练数据，并在交叉验证后提供最佳参数。
我还检查了兼容性问题，确保库是最新的，并重新安装了 Scikit-learn 和 XGBoost，但错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</guid>
      <pubDate>Wed, 18 Dec 2024 11:45:52 GMT</pubDate>
    </item>
    <item>
      <title>如何在语言模型中使用标记化？[关闭]</title>
      <link>https://stackoverflow.com/questions/79289981/how-to-use-tokenization-in-language-model</link>
      <description><![CDATA[我一直在训练这个 LM，使用以下超参数：
blocksiz = 128
batchsiz = 32
nemb = 256
nhead = 4
nlayers = 4
evalIters = 100
lr = 3e-4
epochs = 30

我的数据集是 93kb..，
我使用 GPT-2 作为 Tokenizer..
但是，当我使用 GPT-2 Tokenizer 时，训练时间太长了，
但是当我将模型训练为二元组时。它不需要那么多时间。
因此，使用具有 50257 个 Vocabsiz 的 GPT2 作为 tokenizer，会影响模型训练吗？
是否需要更多 GPU 资源来训练？
因此对于小型数据集。我应该使用什么作为标记器...？
我减少了超参数，上面使用的参数是减少的结果
但模型训练时间太长了]]></description>
      <guid>https://stackoverflow.com/questions/79289981/how-to-use-tokenization-in-language-model</guid>
      <pubDate>Wed, 18 Dec 2024 04:30:58 GMT</pubDate>
    </item>
    <item>
      <title>MMpose 推断器不适用于 MP4 文件</title>
      <link>https://stackoverflow.com/questions/78854257/mmpose-inferencer-not-working-for-mp4-files</link>
      <description><![CDATA[我正在尝试使用 MMPose 在视频中的个人的 3D 空间中查找关键点。我使用的代码（之前在 2d 中运行过）是：
from mmpose.apis import MMPoseInferencer
from pathlib import Path
import os

data_folder = Path(&quot;x/videos&quot;)
for filename in os.listdir(data_folder):
if not filename.endswith(&#39;.mp4&#39;):
continue
img_path = os.path.join(data_folder, filename)

inferencer = MMPoseInferencer(pose3d=&quot;human3d&quot;)

result_generator = inferencer(img_path, out_dir=&#39;output&#39;)

每当我尝试访问 results_generator（如 results = [result for result in result_generator]）时，我都会遇到段错误，我猜是因为 result_generator 中没有任何内容。我还希望输出文件夹中有可视化效果和数据，但该文件夹是空的。我有什么明显的错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78854257/mmpose-inferencer-not-working-for-mp4-files</guid>
      <pubDate>Fri, 09 Aug 2024 18:55:46 GMT</pubDate>
    </item>
    </channel>
</rss>