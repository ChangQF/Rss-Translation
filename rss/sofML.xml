<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 07 Jul 2024 03:17:29 GMT</lastBuildDate>
    <item>
      <title>eval（predvars、data、env）中出现错误：未找到对象“s_id”</title>
      <link>https://stackoverflow.com/questions/78715689/error-in-evalpredvars-data-env-object-s-id-not-found</link>
      <description><![CDATA[我正在尝试使用 tidymodels 拟合多层模型。当我拟合单个模型时，我没有遇到问题，但当我将它们组合到工作流集中时，我得到了这些错误。
我看到过有类似错误的帖子，并尝试更新我的代码，但似乎仍然不起作用。
当我在应用配方后查看训练和验证集时，我确实在数据框中找到所有列。不确定错误持续存在的原因。
我希望有人能帮助解决此错误：
pacman::p_load(labelled,forcats,rstanarm,tidymodels,dplyr,parsnip,baguette,future,finetune,rules,rsample,
multilevelmod,ranger,earth,readr,stacks)

plan(multisession)

load(url(&quot;http://alecri.github.io/downloads/data/dental.RData&quot;))

dental_long &lt;- pivot_longer(dental, cols = starts_with(&quot;y&quot;), 
names_to = &quot;measurement&quot;, values_to = &quot;distance&quot;) %&gt;% 
mutate(
age = parse_number(measurement),
measure = fct_inorder(paste(&quot;测量年龄&quot;, age)),
s_id=as.factor(id)
) %&gt;% 
set_variable_labels(
age = &quot;测量时孩子的年龄&quot;,
measure = &quot;时间测量标签&quot;,
distance = &quot;测量值&quot;
) %&gt;% select(-measurement,-id)

#将数据拆分为训练集、验证集和测试集
set.seed(11)
splitsx &lt;- group_initial_split(dental_long, group = s_id,prop = 0.8)

dental_train &lt;- training(splitsx)
dental_val &lt;- testing(splitsx)

#创建交叉验证折叠
foldsx &lt;- group_vfold_cv(dental_train, v = 3,group = s_id,repeats = 3)

#创建简单的建模配方
simple_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
update_role(s_id,new_role = &#39;id&#39;)

#带有多项式项的配方
poly_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
update_role(s_id,new_role = &#39;id&#39;) %&gt;%
step_scale(all_numeric_predictors()) %&gt;%
step_poly(all_numeric_predictors(),degree = 2,keep_original_cols = F) %&gt;%
step_dummy(all_nominal_predictors()) %&gt;% 
step_interact(~all_numeric_predictors():all_numeric_predictors())

mixed_basic_recipex &lt;- recipe(distance ~ ., data = dental_train)

mixed_poly_recipex &lt;- recipe(distance ~ ., data = dental_train) %&gt;% 
step_scale(all_numeric_predictors()) %&gt;%
step_poly(all_numeric_predictors(),degree = 2,keep_original_cols = F) %&gt;%
step_dummy(all_nominal_predictors() &amp; !matches(&#39;s_id&#39;)) #%&gt;% 
# step_interact(~all_numeric_predictors():all_numeric_predictors() )

# df1 &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

#mixed model
lmer_specx &lt;-
linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;lmer&quot;)

bayes_specx &lt;- linear_reg() %&gt;%
set_mode(&quot;regression&quot;) %&gt;%
set_engine(&quot;stan_glmer&quot;)

fullx &lt;- 
workflow_set(
preproc = list(mixed_poly = poly_recipex
), 
models = list(bayesMixed = bayes_specx,lmmixed = lmer_specx

)
)

#贝叶斯调整和度量的设置
bayes_ctrl &lt;-
control_bayes(
save_pred = TRUE,
parallel_over = &quot;everything&quot;,
save_workflow = TRUE,
verbose = TRUE,
no_improve = 20
)
rmse_res &lt;- metric_set(rmse,rsq)

basicbkx &lt;- prep(mixed_basic_recipex) %&gt;% bake(dental_train)
polybkx &lt;- prep(mixed_poly_recipex) %&gt;% bake(dental_train)

polyform &lt;- reformulate(c(setdiff(colnames(polybkx), c(&quot;距离&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)
basicform &lt;- reformulate(c(setdiff(colnames(basicbkx), c(&quot;distance&quot;,&#39;s_id&#39;)),&#39;-s_id + (1 | s_id)&#39;), 
response=&quot;distance&quot;)

all_wfx1 &lt;- fullx %&gt;% 
# update_workflow_model(id=&#39;basic_bayesMixed&#39;,spec=bayes_specx,
# formula = basicform) %&gt;% 
update_workflow_model(id=&#39;mixed_poly_bayesMixed&#39;,spec=bayes_specx,
formula = polyform) %&gt;%
# update_workflow_model(id=&#39;basic_lmmixed&#39;,spec=lmer_specx,
# formula = basicform) %&gt;%
update_workflow_model(id=&#39;mixed_poly_lmmixed&#39;,spec=lmer_specx,
formula = polyform)

test_results &lt;-
all_wfx1 %&gt;%
working_map(
&quot;tune_bayes&quot;,
seed = 10,
resamples = foldsx,
control = bayes_ctrl
)
]]></description>
      <guid>https://stackoverflow.com/questions/78715689/error-in-evalpredvars-data-env-object-s-id-not-found</guid>
      <pubDate>Sat, 06 Jul 2024 19:11:58 GMT</pubDate>
    </item>
    <item>
      <title>从 UE5 中的动作分类器模型获取输入</title>
      <link>https://stackoverflow.com/questions/78714836/taking-input-from-an-action-classifier-model-in-ue5</link>
      <description><![CDATA[我已经训练了一个动作分类器模型，该模型可以实时使用网络摄像头对玩家的动作进行分类。
它使用媒体管道检测人的姿势，并向模型提供 x、y、深度和可见性参数。该模型对人正在执行的动作进行分类。现在我想将此模型的结果输入为游戏中的按钮按下事件。此输入将用于控制我的游戏角色。例如：如果模型检测到拳击动作，则游戏角色将出拳。
解决此问题的最佳方法是什么，以便我在模型决策和游戏动作之间获得尽可能低的延迟？
我研究了虚幻引擎 5 的 NNI 插件，但它似乎无法解决我的问题。我想到使用的一种方法是运行一个 python 脚本，该脚本在检测到动作时按下相关按钮。它将与游戏并行运行。还有其他更好的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78714836/taking-input-from-an-action-classifier-model-in-ue5</guid>
      <pubDate>Sat, 06 Jul 2024 12:29:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 StandardScaler 转换 x_test 数据时收到不合理警告</title>
      <link>https://stackoverflow.com/questions/78714642/getting-unreasonable-warning-while-transforming-the-x-test-data-using-standardsc</link>
      <description><![CDATA[import numpy as np
import pandas as pd
df = pd.read_csv(&#39;C:/Users/sayed/Downloads/placement.csv&#39;)
df = df.iloc[:, 1:]

X = df.iloc[:, 0:2]
Y = df.iloc[:,-1]

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

最后一行给出此警告：
UserWarning: X没有有效的功能名称，但 StandardScaler 配有功能名称 warnings.warn(

我确实向 ChatGPT 询问过这个问题，它给出了以下答案

您收到的警告是由于缩放器的安装方式与使用方式不匹配造成的

我仍然不清楚该警告。如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78714642/getting-unreasonable-warning-while-transforming-the-x-test-data-using-standardsc</guid>
      <pubDate>Sat, 06 Jul 2024 11:01:20 GMT</pubDate>
    </item>
    <item>
      <title>在自定义环境中，Actor-Critic 模型中的奖励没有增加</title>
      <link>https://stackoverflow.com/questions/78714452/rewards-not-increasing-in-actor-critic-model-in-a-custom-environment</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78714452/rewards-not-increasing-in-actor-critic-model-in-a-custom-environment</guid>
      <pubDate>Sat, 06 Jul 2024 09:38:19 GMT</pubDate>
    </item>
    <item>
      <title>我加载一个 float32 Hugging Face 模型，将其转换为 float16，然后保存。我该如何将其加载为 float16？</title>
      <link>https://stackoverflow.com/questions/78713551/i-load-a-float32-hugging-face-model-cast-it-to-float16-and-save-it-how-can-i</link>
      <description><![CDATA[我加载一个 huggingface-transformers float32 模型，将其转换为 float16，然后保存。我如何将其加载为 float16？
示例：
# pip install tr​​ansformers
from transformers import AutoModelForTokenClassification, AutoTokenizer

# 加载模型
model_path = &#39;huawei-noah/TinyBERT_General_4L_312D&#39;
model = AutoModelForTokenClassification.from_pretrained(model_path)
tokenizer = AutoTokenizer.from_pretrained(model_path)

# 将模型转换为 FP16
model.half()

# 检查模型 dtype
def print_model_layer_dtype(model):
print(&#39;\nModel dtypes:&#39;)
for name, param in model.named_pa​​rameters():
print(f&quot;参数：{name}，数据类型：{param.dtype}&quot;)

print_model_layer_dtype(model)
save_directory = &#39;temp_model_SE&#39;
model.save_pretrained(save_directory)

model2 = AutoModelForTokenClassification.from_pretrained(save_directory, local_files_only=True)
print(&#39;\n\n##################&#39;)
print(model2)
print_model_layer_dtype(model2)

在此示例中，model2 加载为 float32 模型（如 print_model_layer_dtype(model2) 所示），即使 model2 已保存为 float16（如 config.json 中所示）。将其加载为 float16 的正确方法是什么？
在 Windows 10 上使用 transformers==4.36.2 和 Python 3.11.7 进行了测试。]]></description>
      <guid>https://stackoverflow.com/questions/78713551/i-load-a-float32-hugging-face-model-cast-it-to-float16-and-save-it-how-can-i</guid>
      <pubDate>Fri, 05 Jul 2024 23:58:06 GMT</pubDate>
    </item>
    <item>
      <title>AlexNet 的顶层和底层如何通信？</title>
      <link>https://stackoverflow.com/questions/78713337/how-do-the-top-and-bottom-layers-of-alexnet-communicate</link>
      <description><![CDATA[我正在尝试使用 PyTorch 重新实现 Krizhevsky et al. (2012)，并且我对 AlexNet 模型的第二和第三卷积层如何精确通信感到困惑（第五层到第六层以及第六层到第七层的输入也是如此，尽管我在这里的问题中省略了这一点）。
在下图中，有两个&quot;过滤器&quot;，它们将输出从上半部分传递到下一个上半部分，但也传递到下半部分。同样，下半部分也有两个&quot;过滤器&quot;将输出传递到下一个下半部分和上半部分。
我没有足够的声誉点来嵌入图像，所以这里是Krizhevsky et al. (2012) 的图 1 的部分屏幕截图。
第二层的输出如何传递到第三层？
我读了这篇论文，除非我错过了什么，否则作者似乎没有准确概述输出是如何从第二层传递到第三层的。我浏览了大量博客文章和 git 存储库，大多数描述都是高级的，大多数实现似乎没有将模型拆分到两个 GPU 之间。
我能找到的最相关的内容是来自 convnet2 readme 的以下句子：

这里，层 conv2a 和 conv2b 将 conv1a 和 conv1b 都作为输入。执行隐式复制操作，以便将 conv1a 的输出放入 conv2b 的输入中，以及将 conv1b 的输出放入 conv2a 的输入中。

我最好的猜测是第二层中的 out_channels 参数实际上应该是 64 而不是 128，然后顶层和底层的输出应该连接为 torch.cat([output_from_top_half, output_from_bottom_half], dim=1) 并传递给第三层的上半部分和下半部分。但我不确定我的理解是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/78713337/how-do-the-top-and-bottom-layers-of-alexnet-communicate</guid>
      <pubDate>Fri, 05 Jul 2024 21:44:17 GMT</pubDate>
    </item>
    <item>
      <title>CNN 模型中的损失函数没有减少吗？</title>
      <link>https://stackoverflow.com/questions/78712668/loss-function-not-decreasing-on-a-cnn-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78712668/loss-function-not-decreasing-on-a-cnn-model</guid>
      <pubDate>Fri, 05 Jul 2024 17:20:29 GMT</pubDate>
    </item>
    <item>
      <title>关于将深度学习存储库称为上游或下游的澄清[关闭]</title>
      <link>https://stackoverflow.com/questions/78711787/clarification-on-referring-to-deep-learning-repositories-as-upstream-or-downstre</link>
      <description><![CDATA[我正在努力理解深度学习模型背景下不同存储库之间的关系。具体来说，我对要使用的适当术语感到好奇。
目前，存在许多深度学习模型存储库，其中上传了用于下游任务的模型，例如 Hugging Face 或 TensorFlow Hub。我相信还有一些存储库存储了用于训练这些模型的代码，通常在 GitHub 等平台上。
我的问题是：
我们可以将深度学习模型存储库（例如 Hugging Face）称为下游存储库，将代码存储库（例如 GitHub）称为上游存储库吗？
我想确保在讨论这些关系时使用正确的术语。任何有关此主题的澄清或资源都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78711787/clarification-on-referring-to-deep-learning-repositories-as-upstream-or-downstre</guid>
      <pubDate>Fri, 05 Jul 2024 13:40:14 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入技术从数据库中进行人脸识别</title>
      <link>https://stackoverflow.com/questions/78688976/face-recognize-from-the-database-using-embedding-technique</link>
      <description><![CDATA[我正在开展一个项目，旨在识别大学记录中是否存在任何个人的照片。所提出的方法涉及将每个学生照片的嵌入及其详细信息存储在矢量数据库中。当需要比较照片时，系统将生成该照片的嵌入值，然后将该值与数据库进行比较。如果该值在特定阈值内，则表明该个人存在于记录中。
我正在寻求专家建议，以确定这种方法是否可行。如果对这种方法有任何疑虑，我将不胜感激最佳解决方案的建议。]]></description>
      <guid>https://stackoverflow.com/questions/78688976/face-recognize-from-the-database-using-embedding-technique</guid>
      <pubDate>Sun, 30 Jun 2024 15:09:55 GMT</pubDate>
    </item>
    <item>
      <title>Unity ML-Agents --num-envs 获取环境 ID</title>
      <link>https://stackoverflow.com/questions/78598596/unity-ml-agents-num-envs-get-env-id</link>
      <description><![CDATA[我想训练一款需要用户登录的游戏。目前，我对登录名进行了硬编码以使用训练帐户。每个玩家只能登录一次，因此使用 --num-envs=x 参数进行训练仍将导致只有一个环境实际进行训练。有没有办法访问当前环境的 ID，以便我可以为每个单独的环境使用不同的登录名？我希望能够说
playerName = $&quot;player{envId};

有没有办法做到这一点？
我研究了 Academy 和 Communicator 实现，但没有发现任何有用的东西。]]></description>
      <guid>https://stackoverflow.com/questions/78598596/unity-ml-agents-num-envs-get-env-id</guid>
      <pubDate>Sun, 09 Jun 2024 12:31:24 GMT</pubDate>
    </item>
    <item>
      <title>在具有标准化变量的模型中缩放样本外预测：恢复到原始比例</title>
      <link>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</link>
      <description><![CDATA[我正在使用一个模型进行预测，其中变量按 $ x_i = \frac{{x_i - \text{mean}(x_i)}}{{\text{sd}(x_i)}} $ 缩放，并且我保存了平均值和标准差。现在，对于样本外预测，假设目标变量 $ ( x_i )$，基于缩放模型，我该如何缩小预测值？
我是否应该使用样本内 $ \text{Mean}(x_i) $ 和 $ \text{sd}(x_i) $ 来缩小样本外预测值，以便：
$ \text{重新缩放的样本外预测} = \text{缩放的预测} \times \text{sd}(x_i) + \text{mean}(x_i) $
这里的适当程序是什么？]]></description>
      <guid>https://stackoverflow.com/questions/78576306/scaling-out-of-sample-forecasts-in-a-model-with-normalized-variables-reverting</guid>
      <pubDate>Tue, 04 Jun 2024 15:17:14 GMT</pubDate>
    </item>
    <item>
      <title>SHAP - 具有多个维度的实例</title>
      <link>https://stackoverflow.com/questions/76083485/shap-instances-that-have-more-than-one-dimension</link>
      <description><![CDATA[我对 SHAP 还很陌生，我想尝试一下，但遇到了一些困难。
该模型已经过训练，似乎表现良好。然后我使用训练数据来测试 SHAP。它看起来像这样：
 var_Braeburn var_Cripps Pink var_Dazzle var_Fuji var_Granny Smith \
0 1 0 0 0 0 
1 0 1 0 0 0 
2 0 1 0 0 0 
3 0 1 0 0 0 
4 0 1 0 0 0 

var_Other Variety var_Royal Gala (Tenroy) root_CG202 root_M793 \
0 0 0 0 0 
1 0 0 1 0 
2 0 0 1 0 
3 0 0 0 0 
4 0 0 0 0 

root_MM106 ... frt_BioRich Organic Compost_single \
0 1 ... 0 
1 0 ... 0
2 0 ... 0 
3 1 ... 0 
4 1 ... 0 

frt_Biomin Boron_single frt_Biomin Zinc_single \
0 0 1 
1 0 0 
2 0 0 
3 0 0 
4 0 0 

frt_Fertco Brimstone90 sulphur_single frt_Fertco Guano _single \
0 0 0 
1 0 0 
2 0 0 
3 0 0 
4 0 0 

frt_Gro Mn_multiple frt_Gro Mn_single frt_Organic Mag Super_multiple \
0 0 0 0 
1 1 0 1 
2 1 0 1 
3 1 0 1 
4 1 0 1

frt_Organic Mag Super_single frt_Other Fertiliser 
0 0 0 
1 0 0 
2 0 0 
3 0 0 
4 0 0 

然后我执行 explainer = shap.Explainer(model) 和 shap_values = explainer(X_train)
此操作运行无错误，shap_values 给出以下结果：
.values =
array([[[ 0.00775555, -0.00775555],
[-0.03221035, 0.03221035],
[-0.0027203 , 0.0027203 ],
...,
[ 0.00259787, -0.00259787],
[-0.00459262, 0.00459262],
[-0.0303394 , 0.0303394 ]],

[[-0.00068313, 0.00068313],
[-0.03006355, 0.03006355],
[-0.00245706, 0.00245706],
...,
[-0.00418809, 0.00418809],
[-0.00088372, 0.00088372],
[-0.00030019, 0.00030019]],

[[-0.00068313, 0.00068313],
[-0.03006355, 0.03006355],
[-0.00245706, 0.00245706],
...,
[-0.00418809, 0.00418809],
[-0.00088372, 0.00088372],
[-0.00030019, 0.00030019]],

...,

但是，当我运行 shap.plots.beeswarm(shap_values) 时，出现以下错误：
ValueError: beeswarm plot 不支持绘制具有多个维度的实例的解释！
我在这里做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/76083485/shap-instances-that-have-more-than-one-dimension</guid>
      <pubDate>Sun, 23 Apr 2023 06:49:07 GMT</pubDate>
    </item>
    <item>
      <title>YOLO v8 的默认网格大小</title>
      <link>https://stackoverflow.com/questions/75904407/default-grid-size-for-yolo-v8</link>
      <description><![CDATA[YOLO 使用网格来分配检测到的对象的中心。在最初的论文中，网格是 7x7
Yolo v8 中的网格大小是多少？
我问这个问题的原因是因为无锚检测，因为它不再根据锚框的偏移量进行计算，而是使用中心。]]></description>
      <guid>https://stackoverflow.com/questions/75904407/default-grid-size-for-yolo-v8</guid>
      <pubDate>Sat, 01 Apr 2023 05:19:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 Huggingface Trainer 进行训练时，如何选择 eval_dataset 的子集？</title>
      <link>https://stackoverflow.com/questions/74257764/how-to-select-a-subset-of-the-eval-dataset-when-training-with-huggingface-traine</link>
      <description><![CDATA[当使用 Huggingface 变换器的 Trainer 时，例如
# 设置训练参数 - 这些参数并没有真正调整，可以随意更改
training_args = Seq2SeqTrainingArguments(
output_dir=&quot;./&quot;,
evaluation_strategy=&quot;steps&quot;,
per_device_train_batch_size=50,
per_device_eval_batch_size=10,
predict_with_generate=True,
logs_steps=2, # 设置为 1000 进行完整训练
save_steps=16, # 设置为 500 进行完整训练
eval_steps=4, # 设置为 8000 进行完整训练
warmup_steps=1, # 设置为 2000 以进行完整训练
max_steps=16, # 删除以进行完整训练
# overwrite_output_dir=True,
save_total_limit=1,
#fp16=True, 
)

# 实例化训练器
trainer = Seq2SeqTrainer(
model=multibert,
tokenizer=tokenizer,
args=training_args,
train_dataset=train_data.with_format(&quot;torch&quot;),
eval_dataset=eval_data.with_format(&quot;torch&quot;),
)

是否有某种方法可以在每 n 个 eval_steps 中从 eval_data 中随机选择/采样？
例如我试过了
eval_data = eval_data.select(range(3000))

...

trainer = Seq2SeqTrainer(
model=multibert,
tokenizer=tokenizer,
args=training_args,
train_dataset=train_data.with_format(&quot;torch&quot;),
eval_dataset=eval_data.with_format(&quot;torch&quot;),
)

但这会在训练之前静态定义 eval_data 子集。
是否可以在训练期间进行选择并使其在每个评估点选择不同的子集？]]></description>
      <guid>https://stackoverflow.com/questions/74257764/how-to-select-a-subset-of-the-eval-dataset-when-training-with-huggingface-traine</guid>
      <pubDate>Mon, 31 Oct 2022 00:42:20 GMT</pubDate>
    </item>
    <item>
      <title>在逻辑回归中使用排名数据</title>
      <link>https://stackoverflow.com/questions/22117692/using-ranking-data-in-logistic-regression</link>
      <description><![CDATA[我正在尝试在逻辑回归中使用一些排名数据。我想使用机器学习来制作一个简单的分类器，以确定网页是否“好”。这只是一个学习练习，所以我不期望获得很好的结果；只是希望学习“过程”和编码技术。
我已将我的数据放入 .csv 中，如下所示：
URL WebsiteText AlexaRank GooglePageRank

在我的测试 CSV 中，我们有：
URL WebsiteText AlexaRank GooglePageRank 标签

标签是二进制分类，用 1 表示“好”，用 0 表示“坏”。
我目前仅使用网站文本运行 LR；我在其上运行了 TF-IDF。
我有两个问题需要帮助：

如何规范化我的 AlexaRank 排名数据？我有一组 10,000 个网页，我有所有网页的 Alexa 排名；但是它们的排名不是 1-10,000。它们在整个互联网中排名靠前，因此虽然 http://www.google.com 可能排名 #1，但 http://www.notasite.com 可能排名 #83904803289480。如何在 Scikit learn 中对此进行规范化，以便从我的数据中获得最佳结果？

我以这种方式运行我的逻辑回归；我几乎可以肯定我做错了。我试图对网站文本进行 TF-IDF，然后添加另外两个相关列并拟合逻辑回归。如果有人能快速验证我是否正确地采用了我想在 LR 中使用的三列，我将不胜感激。
 loadData = lambda f: np.genfromtxt(open(f,&#39;r&#39;), delimiter=&#39; &#39;)

print &quot;loading data..&quot;
traindata = list(np.array(p.read_table(&#39;train.tsv&#39;))[:,2])#Reading WebsiteText 列进行 TF-IDF。
testdata = list(np.array(p.read_table(&#39;test.tsv&#39;))[:,2])
y = np.array(p.read_table(&#39;train.tsv&#39;))[:,-1] #读取标签

tfv = TfidfVectorizer(min_df=3, max_features=None, strip_accents=&#39;unicode&#39;, analyzer=&#39;word&#39;,

token_pattern=r&#39;\w{1,}&#39;, ngram_range=(1, 2), use_idf=1, smooth_idf=1,sublinear_tf=1)

rd = lm.LogisticRegression(penalty=&#39;l2&#39;, dual=True, tol=0.0001, C=1, fit_intercept=True, intercept_scaling=1.0, class_weight=None, random_state=None)

X_all = traindata + testdata
lentrain = len(traindata)

print &quot;fitting pipeline&quot;
tfv.fit(X_all)
print &quot;transforming data&quot;
X_all = tfv.transform(X_all)
X = X_all[:lentrain]
X_test = X_all[lentrain:]

print &quot;20 Fold CV Score: &quot;, np.mean(cross_validation.cross_val_score(rd, X, y, cv=20,scoring=&#39;roc_auc&#39;))

#添加两个整数列
AlexaAndGoogleTrainData = list(np.array(p.read_table(&#39;train.tsv&#39;))[2:,3])#不确定我是否做对了。期望它包含 AlexaRank 和 GooglePageRank 列。
AlexaAndGoogleTestData = list(np.array(p.read_table(&#39;test.tsv&#39;))[2:,3])
AllAlexaAndGoogleInfo = AlexaAndGoogleTestData + AlexaAndGoogleTrainData

#向 X 添加两列。
X = np.append(X, AllAlexaAndGoogleInfo, 1) #我认为我做错了。

print &quot;training on full data&quot;
rd.fit(X,y)
pred = rd.predict_proba(X_test)[:,1]
testfile = p.read_csv(&#39;test.tsv&#39;, sep=&quot;\t&quot;, na_values=[&#39;?&#39;], index_col=1)
pred_df = p.DataFrame(pred, index=testfile.index, columns=[&#39;label&#39;])
pred_df.to_csv(&#39;benchmark.csv&#39;)
print &quot;提交文件已创建..&quot;`


]]></description>
      <guid>https://stackoverflow.com/questions/22117692/using-ranking-data-in-logistic-regression</guid>
      <pubDate>Sat, 01 Mar 2014 17:25:19 GMT</pubDate>
    </item>
    </channel>
</rss>