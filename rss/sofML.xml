<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 29 Jan 2024 09:14:07 GMT</lastBuildDate>
    <item>
      <title>在colab中运行excel文件</title>
      <link>https://stackoverflow.com/questions/77898474/running-excel-file-in-colab</link>
      <description><![CDATA[尝试在 Google colab 中加载 Excel 工作表时收到错误消息。 Excel 包含 5000 多行
我尝试过：data=pd.read_excel(&#39;/content/data_ml.xlsx&#39;)
获得错误：：-------------------------------------------------------- ----------------------------
BadZipFile Traceback（最近一次调用最后一次）
 在&lt;细胞系：1&gt;()
----&gt; 1 data=pd.read_excel(&#39;/content/data_ml.xlsx&#39;)
6帧
_RealGetContents(self) 中的 /usr/lib/python3.10/zipfile.py
第1334章
第1335章
-&gt;第1336章
第1337章1：
第1338章
BadZipFile：文件不是 zip 文件]]></description>
      <guid>https://stackoverflow.com/questions/77898474/running-excel-file-in-colab</guid>
      <pubDate>Mon, 29 Jan 2024 09:04:56 GMT</pubDate>
    </item>
    <item>
      <title>模型“利用”加权损失？</title>
      <link>https://stackoverflow.com/questions/77897842/model-exploiting-weighted-loss</link>
      <description><![CDATA[我正在创建一个进行多类分类的模型，并尝试使用加权损失来优化它。
我的数据集包含 7 个类。这是我拥有的每个数据点的数量：
梅尔：1113
内华达州：6705
密件抄送：514
AKIEC：327
吉隆坡：1099
DF：115
VASC：142
我认为我的模型正在“利用”通过仅返回“AKIEC”来减少该加权损失每次。 （不知道为什么它不是每次都返回 VASC，但 AKIEC 是我观察到的）
这是我的模型在“MEL”上给出的输出图片：
[1.9501211e-02、8.6555272e-02、7.0136093e-02、5.3331017e-02、7.6896048e-01、
1.2218184e-03、2.9415233e-04]
这是我的模型使用的加权损失权重：
{0：0.888866699950075、1：0.3305042436345482、2：0.9486769845232151、3：0.9673489765351972、4：0.8902646030953569、5：0.9885 172241637543, 6: 0.9858212680978532}
这导致分类交叉熵损失约为 0.33，二进制准确度约为 94%。
如果有必要，这是我的模型代码：
def classi(input_shape):
    输入=图层.输入（形状=输入形状）
    vgg19 = k.applications.VGG19（include_top=False，权重=“imagenet”，input_tensor=输入）
    x = vgg19（输入，训练=False）
    
    x = 层.Conv2D(64, 3, 填充=“相同”)(x)
    x = 层.Activation(“relu”)(x)
    x = 层.BatchNormalization()(x)
    #经典层
    对于 [96, 128, 256]:#, 320]:#, 512]:#, 1024, 2048] 中的过滤器：
        x = 层.Conv2D(过滤器, 3, 填充=“相同”)(x)
        x = 层.Activation(“relu”)(x)
        x = 层.BatchNormalization()(x)

        x = 层.Conv2D(过滤器, 3, 填充=“相同”)(x)
        x = 层.Activation(“relu”)(x)
        x = 层.BatchNormalization()(x)

        x = groups.MaxPool2D(3, strides=2, padding=“相同”)(x)

    ＃输出
    x = 层数.Dropout(rate=0.3)(x)
    x = 层.Flatten()(x)
    x = 层.Dense(128, 激活=“sigmoid”)(x)

    输出 = 层.Dense(7, 激活 =“softmax”)(x)

    model = k.Model(输入=输入，输出=输出，名称=“分类”)
    返回模型

我的模型接受过以下训练：
batch_size=8
steps_per_epoch = 10015 //batch_size
纪元 = 60

这里的问题是因为我的加权损失，还是我的模型只是不“好”？足够的？ （训练不够，层数太少......）或者我的指标和损失是否实施不正确？
感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77897842/model-exploiting-weighted-loss</guid>
      <pubDate>Mon, 29 Jan 2024 06:46:18 GMT</pubDate>
    </item>
    <item>
      <title>keras多类分类欠拟合</title>
      <link>https://stackoverflow.com/questions/77897827/keras-multiclass-classification-underfitting</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77897827/keras-multiclass-classification-underfitting</guid>
      <pubDate>Mon, 29 Jan 2024 06:41:23 GMT</pubDate>
    </item>
    <item>
      <title>Causal ML 提出的 Uplift 建模中的 SHAP 解释器错误</title>
      <link>https://stackoverflow.com/questions/77897614/shap-explainer-error-on-uplift-modeling-presented-by-causal-ml</link>
      <description><![CDATA[我有 2 个问题：
1。问题：
我正在尝试在我自己的电脑上实现本教程=&gt; https://causalml.readthedocs.io/en/latest/examples/causal_trees_interpretation。 html
在 TreeExplainer 部分，这里是创建 tree_explainer 对象的代码：
tree_explainer = shap.TreeExplainer(ctree)
# 治疗=0 和治疗=1 的预期值。即 Y|X,T=0 和 Y|X,T=1
tree_explainer.expected_value

我试图在我的电脑上运行此代码，但出现此错误：
&lt;块引用&gt;
&lt;单元格行：1&gt;() 中的类型错误回溯（最近一次调用最后一次）
----&gt; 1 tree_explainer = shap.Explainer(ctree) 2 #treatment=0 和treatment=1 的期望值。即 Y|X,T=0 和 Y|X,T=1 3
tree_explainer.expected_value
/data/envs/berkere/lib/python3.8/site-packages/shap/explainers/_explainer.py
在 init(自身、模型、掩码、链接、算法、output_names、
feature_names, Linearize_link, Seed, **kwargs) 169 # 如果我们到达这里
那么我们不知道如何处理其他人给我们的东西 170:
--&gt;第171章 172
173 # 构建正确的子类
TypeError：传递的模型不可调用且无法分析
直接使用给定的掩码！模型：CausalTreeRegressor()

我该如何处理？
2。问题：
在另一个实现中，我能够获得这样的 SHAP 值：
uplift_model = BaseTClassifier(XGBClassifier(n_estimators=100,
                                             最大深度=5，
                                             Learning_rate=0.1), control_name=&#39;Kontrol&#39;)

uplift_model.fit(df_train[x_names].values,
                 治疗=df_train[&#39;treatment_group_key&#39;].values,
                 y=df_train[&#39;转换&#39;].值)

model_tau = uplift_model.predict(df_test[x_names].values)

uplift_model_shap_values = uplift_model.get_shap_values(X=df_test[x_names].values, tau=model_tau, features=x_names);

然后我想通过本地观察来深入研究。我预测控制分数为 0.000219，治疗分数为 0.041069。在这种情况下，我可以说我必须对这些数据应用治疗（因为治疗得分优于控制得分，并且我可以看到Recommended_treatment 列中的数字为 1）。然后我绘制了 shap.waterfall_plot 我发现这个实例的最重要的特征总是降低 SHAP 值，无论 base_value 是什么。所以我想要一个解释，我应该如何阅读 Uplift 模型的 SHAP 图，因为我们知道 Uplift 模型不像传统的 ML 模型。我非常想知道 Uplift Model 如何决定说“您应该对此数据实施处理（或 2,3，等等）”]]></description>
      <guid>https://stackoverflow.com/questions/77897614/shap-explainer-error-on-uplift-modeling-presented-by-causal-ml</guid>
      <pubDate>Mon, 29 Jan 2024 05:36:39 GMT</pubDate>
    </item>
    <item>
      <title>神经网络可以用来追踪铅笔/钢笔草图吗？</title>
      <link>https://stackoverflow.com/questions/77897604/can-neural-networks-be-used-to-trace-pencil-pen-sketches</link>
      <description><![CDATA[我正在为即将到来的学校项目挑选主题，并认为训练神经网络将铅笔/钢笔绘图的图像跟踪为干净的数字绘图会很酷。我通过让我的输入文件夹是所有铅笔/钢笔绘图，输出文件夹是所有跟踪的数字绘图，为输入和输出创建了一个图像数据集。问题是，当我测试经过训练的 U-Net 卷积神经网络时，我的结果是空白。换句话说，我训练了一个模型，然后在新的铅笔/钢笔绘图图像上使用 model.predict，结果只是一张空白图像，而不是跟踪图像。我知道这是一个相当具体的问题，但如果有人有任何训练机器学习模型以以类似方式基于训练数据生成图像的经验，任何建议将不胜感激！
正如我之前提到的，我尝试使用 U-Net 卷积神经网络来解决这个问题，但没有得到任何结果。我的层由一个输入层、两个 Conv2D 层、一个最大池化层、另外两个 Conv2D 层、一个上采样层和另一个 Conv2D 层组成。由于我对图像机器学习相对较新，因此我不确定是否需要添加额外的层才能使模型保留应根据输入和输出生成图像的理解。]]></description>
      <guid>https://stackoverflow.com/questions/77897604/can-neural-networks-be-used-to-trace-pencil-pen-sketches</guid>
      <pubDate>Mon, 29 Jan 2024 05:33:42 GMT</pubDate>
    </item>
    <item>
      <title>将 YOLOv8 集成到 Transformer 模型中</title>
      <link>https://stackoverflow.com/questions/77897573/integrating-yolov8-to-an-transformer-model</link>
      <description><![CDATA[我是机器学习领域的新手，需要添加 YOLOv8 模型方面的帮助(YOLOv8）到下面的代码，而不是使用 InceptionV3 为我的项目提取图像特征。我需要传递检测到的对象并从 YOLOv8 模型中提取特征，以使用转换器生成标题。
def CNN_Encoder_Incep():
    inception_v3 = tf.keras.applications.InceptionV3(
        include_top=假，
        权重=&#39;imagenet&#39;
    ）
    inception_v3.trainable = False

    输出= inception_v3.output
    输出 = tf.keras.layers.Reshape(
        (-1, 输出.形状[-1]))(输出)

    cnn_model = tf.keras.models.Model(inception_v3.输入，输出)
    返回cnn_model

类 ImageCaptioningModel(tf.keras.Model):

    def __init__(self, cnn_model, 编码器, 解码器, image_aug=None):
        超级().__init__()
        self.cnn_model = cnn_model
        self.encoder = 编码器
        self.decoder = 解码器
        self.image_aug = image_aug
        self.loss_tracker = tf.keras.metrics.Mean(name=&quot;loss&quot;)
        self.acc_tracker = tf.keras.metrics.Mean(name=&quot;准确度&quot;)


    defcalculate_loss(self, y_true, y_pred, mask):
        损失 = self.loss(y_true, y_pred)
        mask = tf.cast(mask, dtype=loss.dtype)
        损失*=掩模
        返回 tf.reduce_sum(loss) / tf.reduce_sum(mask)


    defcalculate_accuracy(self, y_true, y_pred, mask):
        精度 = tf.equal(y_true, tf.argmax(y_pred, axis=2))
        准确度 = tf.math.logic_and(掩码, 准确度)
        准确度 = tf.cast(准确度, dtype=tf.float32)
        掩码 = tf.cast(掩码, dtype=tf.float32)
        返回 tf.reduce_sum(accuracy) / tf.reduce_sum(mask)


    defcompute_loss_and_acc(self,img_embed,captions,training=True):
        编码器输出 = self.encoder(img_embed, 训练=True)
        y_input = 标题[:, :-1]
        y_true = 标题[:, 1:]
        掩码=（y_true！= 0）
        y_pred = self.解码器（
            y_输入，编码器_输出，训练=真，掩码=掩码
        ）
        损失 = self.calculate_loss(y_true, y_pred, mask)
        acc = self.calculate_accuracy(y_true, y_pred, mask)
        回波损耗，ACC


    def train_step(自身, 批次):
        imgs、字幕 = 批处理

        如果 self.image_aug：
            imgs = self.image_aug(imgs)

        img_embed = self.cnn_model(imgs)

        使用 tf.GradientTape() 作为磁带：
            损失，acc = self.compute_loss_and_acc（
                img_embed、字幕
            ）

        训练变量 = (
            self.encoder.trainable_variables + self.decoder.trainable_variables
        ）
        grads = Tape.gradient(损失, train_vars)
        self.optimizer.apply_gradients(zip(grads, train_vars))
        self.loss_tracker.update_state(损失)
        self.acc_tracker.update_state(acc)

        return {“loss”：self.loss_tracker.result()，“acc”：self.acc_tracker.result()}


    def test_step（自身，批次）：
        imgs、字幕 = 批处理

        img_embed = self.cnn_model(imgs)

        损失，acc = self.compute_loss_and_acc（
            img_embed、字幕、训练=False
        ）

        self.loss_tracker.update_state(损失)
        self.acc_tracker.update_state(acc)

        return {“loss”：self.loss_tracker.result()，“acc”：self.acc_tracker.result()}

    @财产
    定义指标（自身）：
        返回 [self.loss_tracker, self.acc_tracker]

cnn_model = CNN_Encoder_Incep()
标题模型 = ImageCaptioningModel(
    cnn_model=cnn_model，编码器=编码器，解码器=解码器，image_aug=图像增强，
）

我尝试这样做，但当我尝试将其传递给 cnn_model 变量时，我不断收到多个错误。
def CNN_Encoder(): yolov8_model = tf.keras.models.load_model(&#39;./content/yolov8n_objdet_oidv7_640x640.pt&#39;) yolov8_model.trainable = False 输出 = yolov8_model.output 输出 = tf.keras.layers.Reshape ((-1，output.shape[-1]))(输出) cnn_model = tf.keras.models.Model(yolov8_model.input，输出) cnn_model_onnx = cnn_model.export(format=&#39;onnx&#39;) return cnn_model]]></description>
      <guid>https://stackoverflow.com/questions/77897573/integrating-yolov8-to-an-transformer-model</guid>
      <pubDate>Mon, 29 Jan 2024 05:22:01 GMT</pubDate>
    </item>
    <item>
      <title>即使预测已在我的数据集中，TensorFlow 模型也总是预测错误的答案</title>
      <link>https://stackoverflow.com/questions/77897418/tensorflow-model-always-predicting-the-wrong-answer-even-when-prediction-is-alre</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77897418/tensorflow-model-always-predicting-the-wrong-answer-even-when-prediction-is-alre</guid>
      <pubDate>Mon, 29 Jan 2024 04:18:58 GMT</pubDate>
    </item>
    <item>
      <title>基于 Tensorflow 的 MIMO Deep-Wide Neural Network with Transfer Learning：有关将预测精度提高到 60% 以上的任何建议（足球预测）</title>
      <link>https://stackoverflow.com/questions/77897300/tensorflow-based-mimo-deep-wide-neural-network-with-transfer-learning-any-advic</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77897300/tensorflow-based-mimo-deep-wide-neural-network-with-transfer-learning-any-advic</guid>
      <pubDate>Mon, 29 Jan 2024 03:26:24 GMT</pubDate>
    </item>
    <item>
      <title>机器学习、人工智能和数据工程课程材料所需的指导</title>
      <link>https://stackoverflow.com/questions/77896962/guidance-required-with-ml-ai-and-data-engineering-course-material</link>
      <description><![CDATA[我是一名拥有 2 年经验的数据工程师，过去 1 年我一直在读研究生，我觉得我已经失去了数据工程概念，而且我有实践知识，但我不认为我有深厚的或学术知识数据工程（特别是我不认为我对可扩展系统的选择有很好的了解，我已经做了一些 ETL 管道，但我不知道技术术语来帮助人们解决如何扩展系统的问题）并且我没有做一些学术研究使用机器学习模型的项目，但我没有适当的注释或机器学习算法的思维导图，比如在哪种情况下哪种模型会比其他模型更受青睐。一般来说，对于机器学习，我依赖谷歌搜索并获取足以满足该场景的模型。
与 AI 类似，我对 LLM 微调进行了修改，我已经完成了一些小型 YouTube 教程。
我预计在几个月后接受面试，我想知道是否有人可以指导我通过一些资源来让我更清楚地了解概念（数据工程、机器学习、人工智能），我不会说我正在寻找深度在细微差别方面的知识，而是对现有概念的更强把握，这可以帮助我在面试中站稳脚跟。
非常感谢任何课程、路线图、建议。
感谢社区。]]></description>
      <guid>https://stackoverflow.com/questions/77896962/guidance-required-with-ml-ai-and-data-engineering-course-material</guid>
      <pubDate>Mon, 29 Jan 2024 00:59:08 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在 python 上制作姿势动画，也许使用索具和姿势估计？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77896382/is-it-possible-to-do-pose-animation-on-python-perhaps-using-rigging-and-pose-es</link>
      <description><![CDATA[我正在尝试制作一个像“https://pose-animator-demo.firebaseapp.com/camera.html”这样的项目，它使用机器学习来找出身体地标，并且卡在动画的位上身体。我正在考虑使用预先装配的身体，然后将其添加到虚拟骨架上。我正在尝试在 python 上完成这一切。这可能吗？
我已经成功制作了一个虚拟骨架，它悬停在实时视频中的身体上，或者如果需要的话可以悬停在黑框上，但我陷入了动画位]]></description>
      <guid>https://stackoverflow.com/questions/77896382/is-it-possible-to-do-pose-animation-on-python-perhaps-using-rigging-and-pose-es</guid>
      <pubDate>Sun, 28 Jan 2024 20:51:26 GMT</pubDate>
    </item>
    <item>
      <title>将图像移动到目录后数字不同</title>
      <link>https://stackoverflow.com/questions/77895090/different-numbers-after-moving-images-into-a-directory</link>
      <description><![CDATA[我试图将一些图像移动到包含 3 个类（石头、布和剪刀）的目录中，以分割基本目录。
我尝试过这段代码：
train_dir = os.path.join(base_dir, &#39;train&#39;)
val_dir = os.path.join(base_dir, &#39;验证&#39;)
test_dir = os.path.join(base_dir, &#39;测试&#39;)

# 创建子目录
对于 [train_dir, val_dir, test_dir] 中的目录：
    os.makedirs（目录，exist_ok=True）

# 类别列表（石头、剪刀、布）
类名 = os.listdir(base_dir)

# 迭代每个类
对于 class_names 中的 class_name：
    class_path = os.path.join(base_dir, class_name)

    如果 os.path.isdir(class_path):
        # 列出类中的所有图像
        images = [img for img in os.listdir(class_path) if img.endswith(&#39;.jpg&#39;) or img.endswith(&#39;.png&#39;) or img.endswith(&#39;.jpeg&#39;) and img != &#39;README_rpc-简历-images.txt&#39;]

        # 将图像分为训练集、验证集和测试集
        训练图像，测试图像，训练标签，测试标签=训练测试分割（
            所有图像、所有标签、test_size=0.2、random_state=42）

        train_images，val_images，train_labels，val_labels = train_test_split（
            训练图像、训练标签、测试大小=0.25、随机状态=42）
        
        对于 [os.path.join(train_dir, class_name), os.path.join(val_dir, class_name), os.path.join(test_dir, class_name)] 中的目录：
            os.makedirs（目录，exist_ok=True）

        # 将图片移动到对应的子目录
        对于 train_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))
        对于 val_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(val_dir, class_name, img))
        对于 test_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(test_dir, class_name, img))

但是在我使用此代码仔细检查了 train_images 和 train_dir 中的图像数量后：
print(f“train_images 中的图像数量: {len(train_images)}”)
print(f&quot;train_dir 中的图像数量: {len(train_dir)}&quot;)

结果是：
train_images 中的图像数量：1312 和
train_dir 中的图像数量：28
我一直在寻找导致这种数字差异的代码出了什么问题。
将train_images中的图像移动到train_dir的目的是train_dir将在生成器中使用：
train_generator = train_datagen.flow_from_directory()

这需要一个目录才能执行此操作。
关于如何解决这个问题有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77895090/different-numbers-after-moving-images-into-a-directory</guid>
      <pubDate>Sun, 28 Jan 2024 14:15:59 GMT</pubDate>
    </item>
    <item>
      <title>如何在 google colab 中使用更多 GPU RAM？</title>
      <link>https://stackoverflow.com/questions/77893929/how-do-i-use-more-of-the-gpu-ram-in-google-colab</link>
      <description><![CDATA[我正在 pytorch 中从事这个深度学习项目，其中我有 2 个完全连接的神经网络，我需要训练然后测试它们。但是当我在 google colab 中运行代码时，它并不比在我的 PC 上的 CPU 上运行快多少。顺便说一句，我有 colab pro。它还使用 A100 GPU 40GB GPU RAM 中的 0.6 个。
导入火炬
导入火炬视觉
导入 torchvision.transforms 作为变换
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim


设备 = torch.device(“cuda:0”)
# 定义变换
变换 = 变换.Compose([
    变换.ToTensor(),
    变换.Normalize((0.5,),(0.5,))
]）

# 加载 FashionMNIST 数据集
trainset = torchvision.datasets.FashionMNIST（&#39;./data&#39;，download=True，train=True，transform=transform）
测试集 = torchvision.datasets.FashionMNIST(&#39;./data&#39;, download=True, train=False, transform=transform)

# 创建数据加载器
trainloader = torch.utils.data.DataLoader(trainset,batch_size=1,shuffle=True,num_workers=2)
testloader = torch.utils.data.DataLoader(testset,batch_size=1,shuffle=False,num_workers=2)

# 为类定义常量
类 = (&#39;T 恤/上衣&#39;, &#39;裤子&#39;, &#39;套头衫&#39;, &#39;连衣裙&#39;, &#39;外套&#39;,
           “凉鞋”、“衬衫”、“运动鞋”、“包”、“踝靴”）




# 定义全连接神经网络
FCNN 类（nn.Module）：
    def __init__(自身, num_layers=1):
        超级（FCNN，自我）.__init__()
        self.num_layers = num_layers
        self.fc_layers = nn.ModuleList()
        如果 self.num_layers == 1:
            self.fc_layers.append(nn.Linear(28 * 28, 1024))
        elif self.num_layers == 2：
            self.fc_layers.append(nn.Linear(28 * 28, 1024))
            self.fc_layers.append(nn.Linear(1024, 1024))
        self.output_layer = nn.Linear(1024, 10)

    def 前向（自身，x）：
        x = x.view(-1, 28 * 28)
        对于 self.fc_layers 中的层：
            x = nn.function.relu(层(x))
        x = self.output_layer(x)
        返回x

# 修改train函数以将输入和标签移动到GPU
def train(网络, 标准, 优化器, epochs=15):
    对于范围内的纪元（纪元）：
        运行损失 = 0.0
        对于 i，enumerate(trainloader, 0) 中的数据：
            输入，标签=数据[0].to（设备），数据[1].to（设备）
            优化器.zero_grad()

            输出 = 净值（输入）
            损失=标准（输出，标签）
            loss.backward()
            优化器.step()

            running_loss += loss.item()
            如果我% 2000 == 1999：
                print(&#39;[%d, %5d] 损失: %.2f&#39; %
                      (epoch + 1, i + 1, running_loss / 2000))
                运行损失 = 0.0

# 定义函数来测试准确性
定义测试（净）：
    正确 = 0
    总计 = 0
    使用 torch.no_grad()：
        对于测试加载器中的数据：
            图像、标签=数据
            输出=净（图像）
            _, 预测 = torch.max(outputs.data, 1)
            总计 += labels.size(0)
            正确+=（预测==标签）.sum().item()

    print(&#39;准确率：%d %%&#39; % (
            100 * 正确/总计))

＃ 主功能
如果 __name__ == “__main__”：
    # 定义网络
    net1 = FCNN(num_layers=1)
    net2 = FCNN(num_layers=2)
    net2.to（设备）

    # 定义损失函数和优化器
    标准 = nn.CrossEntropyLoss()
    优化器1 = optim.SGD(net1.parameters(), lr=0.001, 动量=0.0)
    optimer2 = optim.SGD(net2.parameters(), lr=0.001, 动量=0.0)

    # 使用 1 个 FC 层训练和测试网络
    #print(“1层训练网络...”)
    #train(net1, 标准, 优化器1)
    #测试（网络1）

    # 使用 2 个 FC 层训练和测试网络
    print(&quot;2层训练网络...&quot;)
    训练（net2、标准、优化器2）
    测试（网络2）

尝试在google colab中使用不同的GPU
尝试添加此行以始终使用 CUDA 核心：
设备 = torch.device(“cuda:0”),

并让网络使用该设备：
 设备 = torch.device(“cuda:0”)
]]></description>
      <guid>https://stackoverflow.com/questions/77893929/how-do-i-use-more-of-the-gpu-ram-in-google-colab</guid>
      <pubDate>Sun, 28 Jan 2024 07:11:15 GMT</pubDate>
    </item>
    <item>
      <title>寻求多特征输入的无代码 ML 解决方案来预测多个二进制输出 [关闭]</title>
      <link>https://stackoverflow.com/questions/77892428/seeking-no-code-ml-solution-for-multi-feature-input-to-predict-multiple-binary-o</link>
      <description><![CDATA[我是 ML 世界的新手，但我一直在使用 Microsoft Azure 环境及其现成的模型训练、测试和部署环境。
我已经成功找到了预测模型的选项和算法：多个特征作为输入，单个变量作为输出。
例如，给定个人的：(a) 工作范围、(b) 性别、(c) 酒精消费，我构建的系统能够预测（真/假）该人是否应该执行练习“E1”。
现在，从技术上讲，人们可以训练 20 个与此类似的模型，并使用关于练习“E2”、“E3”等的“SINGLE”二进制输出。
但是，我觉得必须有一种更简单的方法。
这样，为了训练模型，我会为其提供一个 CSV 文件，每个场景/人一行：
第一人：“数据录入员”，男，否==&gt; E1：是，E2：否，E3：是
第二个人：“按摩师”，女，是==&gt; E1：是，E2：是，E3：否
等等...
我向亲爱的社区成员提出的问题是：
什么算法/环境最适合此类任务？ （也许 Microsoft Azure 不是最好的？）
请注意，我希望无需任何编码即可执行上述设置、培训、测试和部署。
我不介意未来所有这些的编码版本；但目前我喜欢学习在无代码环境中执行此操作。
提前非常感谢，
我第一次尝试使用 AzureML，但无法通过使用 Azure ML 中的自动化 ML 功能获得多输出预测模型。我最终部署了一个能够仅预测分类模型目标值之一的模型。]]></description>
      <guid>https://stackoverflow.com/questions/77892428/seeking-no-code-ml-solution-for-multi-feature-input-to-predict-multiple-binary-o</guid>
      <pubDate>Sat, 27 Jan 2024 19:02:14 GMT</pubDate>
    </item>
    <item>
      <title>如何阻塞 OCDNet 管道并仅在 OCRNet 上获取结果？ （NVIDIA 光学字符检测和识别解决方案/OCDR）</title>
      <link>https://stackoverflow.com/questions/77892097/how-to-block-the-ocdnet-pipeline-and-get-the-result-only-on-ocrnet-nvidia-opti</link>
      <description><![CDATA[我正在 Jetson 上本地运行 NVIDIA 光学字符检测和识别解决方案。我想阻止 OCDNet 的管道，只使用 OCRNet 进行推断。我注释掉了所有与 OCDNet 相关的代码。结果是空洞的推论。]]></description>
      <guid>https://stackoverflow.com/questions/77892097/how-to-block-the-ocdnet-pipeline-and-get-the-result-only-on-ocrnet-nvidia-opti</guid>
      <pubDate>Sat, 27 Jan 2024 17:22:01 GMT</pubDate>
    </item>
    <item>
      <title>数据帧的 .corr() 方法不返回理想值仅返回 -1 或 1</title>
      <link>https://stackoverflow.com/questions/77214404/corr-method-for-dataframe-not-returning-ideal-values-only-returns-either-1-o</link>
      <description><![CDATA[理想情况下，它应该为每个单元格返回 -1 到 1 之间的值，但具有相同列名和行名的单元格需要具有 1 值
在执行 corr() 之前尝试用 0 替换 NaN，它返回正确的值，但这些值对于程序的目的来说是不准确的
&lt;前&gt;&lt;代码&gt;# df
            电影A 电影B 电影C 电影D 电影E
安吉 0.000000 南 -0.500000 0.500000 南
安尼维什 1.166667 -0.333333 -0.833333 NaN NaN
杰伊 1.166667 -0.333333 南 -0.833333 南
卡蒂克 0.000000 -1.500000 南 南 1.5
纳曼 南 0.250000 南 -0.250000 南

# df.T.corr()
          安吉·阿尼维什·杰伊·卡西克·纳曼
安吉 1.0 1.0 -1.0 南 南
安尼维什 1.0 1.0 1.0 1.0 NaN
杰伊 -1.0 1.0 1.0 1.0 1.0
卡蒂克 NaN 1.0 1.0 1.0 NaN
纳曼 南 南 1.0 南 1.0
]]></description>
      <guid>https://stackoverflow.com/questions/77214404/corr-method-for-dataframe-not-returning-ideal-values-only-returns-either-1-o</guid>
      <pubDate>Mon, 02 Oct 2023 09:15:04 GMT</pubDate>
    </item>
    </channel>
</rss>