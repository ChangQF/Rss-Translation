<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Tue, 24 Sep 2024 12:33:29 GMT</lastBuildDate>
    <item>
      <title>ä½¿ç”¨æœºå™¨å­¦ä¹ å¯¹ CAD æ¨¡å‹è¿›è¡Œç‰¹å¾æå–[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79018489/feature-extraction-of-cad-models-using-machine-learning</link>
      <description><![CDATA[æˆ‘æƒ³ä» CAD æ¨¡å‹ä¸­æå–æŸäº›ç‰¹å®šäºå¯¹è±¡çš„ç‰¹å¾ã€‚CAD æ¨¡å‹ä»¥ dxf æ–‡ä»¶æ ¼å¼æä¾›ï¼Œç†æƒ³æƒ…å†µä¸‹åº”ä»¥è¿™ç§æ ¼å¼è¿›è¡Œå¤„ç†ã€‚ç”±äº dxf æ–‡ä»¶æ ¼å¼æ˜¯çŸ¢é‡å›¾å½¢ï¼Œæˆ‘çš„æƒ³æ³•æ˜¯åœ¨å›¾å½¢ä¸­æ˜¾ç¤ºç‚¹å’Œè¿æ¥ï¼Œå…¶ä¸­ç‚¹ä»£è¡¨èŠ‚ç‚¹ï¼Œå®ƒä»¬ä¹‹é—´çš„è¿æ¥æ˜¯å›¾å½¢çš„è¾¹ç¼˜ã€‚ç„¶åæˆ‘æƒ³è®­ç»ƒä¸€ä¸ª GCNï¼Œä»¥ä¾¿å®ƒå¯ä»¥å¯¹èŠ‚ç‚¹è¿›è¡Œåˆ†ç±»ã€‚è®©æˆ‘ä»¬ä»¥æ•°å­—ç”µè·¯å›¾ä¸ºä¾‹ï¼šæˆ‘çš„æ¨¡å‹åº”è¯¥ä»è¿™æ ·çš„ç”µè·¯å›¾ä¸­æå–è¿æ¥ã€‚å› æ­¤ï¼Œåº”è¯¥æ‰§è¡ŒèŠ‚ç‚¹åˆ†ç±»ã€‚
å› æ­¤ï¼Œè¯¥è¿‡ç¨‹åº”å¦‚ä¸‹æ‰€ç¤ºï¼š
å‡†å¤‡ç”¨ä½œæµ‹è¯•æ•°æ®çš„æ•°æ®ï¼ˆè¿™é‡Œæˆ‘ä»¬ä»ç„¶éœ€è¦æ¾„æ¸…å¦‚ä½•å‡†ç¡®æ ‡è®° GCN çš„æµ‹è¯•æ•°æ®ï¼‰ã€‚
è®­ç»ƒæ¨¡å‹å¹¶éšååœ¨ä»¥å‰æœªçŸ¥çš„å›¾è¡¨ï¼ˆå°šæœªè§è¿‡çš„ CAD æ¨¡å‹ï¼‰ä¸Šå¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚
ä¹Ÿè®¸åœ¨æ­¤æœŸé—´å‡ºç°äº†ä¸€ä¸ªé—®é¢˜ï¼Œä¸ºä»€ä¹ˆæˆ‘åšæŒä½¿ç”¨ dxf æ–‡ä»¶æ ¼å¼ã€‚åŸå› å¦‚ä¸‹ï¼šæˆ‘ä¸ä»…å¸Œæœ›ä»æˆ‘çš„æ¨¡å‹ä¸­è·å¾—åˆ†ç±»ï¼ˆè¿æ¥ä¸å¦ï¼‰ï¼Œè¿˜å¸Œæœ›è·å¾—è¿æ¥çš„ç¡®åˆ‡ä½ç½®ã€‚ä¸ºæ­¤ï¼Œæˆ‘æ›¾æƒ³è¿‡å¯ä»¥å°†ä½ç½®ä½œä¸ºç‰¹å¾é›†æˆåˆ°èŠ‚ç‚¹çš„ç‰¹å¾å‘é‡ä¸­ï¼Œç„¶åç¨åè®¿é—®å®ƒã€‚
ç°åœ¨æˆ‘ä»¬ç»§ç»­è®¨è®ºæˆ‘çš„é—®é¢˜ï¼š

æˆ‘çš„æƒ³æ³•æ˜¯å¦å¯ä»¥å®ç°ï¼Ÿæˆ‘å¾ˆæ‹…å¿ƒï¼Œå› ä¸ºæˆ‘è¯»åˆ°è¿‡ GCN æ— æ³•è®¿é—®å½’çº³å­¦ä¹ æˆ–ä¸æ˜¯ä¸ºæ­¤è®¾è®¡çš„ã€‚
æ‚¨å¯¹å¯ä»¥é‡‡å–ä»€ä¹ˆæ–¹æ³•æ¥å®ç°è¿™æ ·çš„åŠªåŠ›è¿˜æœ‰å…¶ä»–æƒ³æ³•å—ï¼Ÿ

æˆ‘çš„ç¬¬ä¸€ä¸ªæ–¹æ³•æ˜¯é€šè¿‡ CNN è¿›è¡Œåˆ†ç±»ã€‚ä½†ç”±äºè½¬æ¢ä¸º png æˆ– jpeg å¯¼è‡´å‡ ä½•ä¿¡æ¯ä¸¢å¤±ï¼Œå› æ­¤ä¸å†å¯èƒ½è¿›è¡Œç²¾ç¡®å®šä½ã€‚æå–ç‰¹å¾çš„ä½ç½®æ˜¯ä¸€é¡¹ä¸»è¦ä»»åŠ¡ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79018489/feature-extraction-of-cad-models-using-machine-learning</guid>
      <pubDate>Tue, 24 Sep 2024 11:56:40 GMT</pubDate>
    </item>
    <item>
      <title>cuDNN é”™è¯¯ï¼šCUDNN_STATUS_EXECUTION_FAILED</title>
      <link>https://stackoverflow.com/questions/79018072/cudnn-error-cudnn-status-execution-failed</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79018072/cudnn-error-cudnn-status-execution-failed</guid>
      <pubDate>Tue, 24 Sep 2024 10:04:05 GMT</pubDate>
    </item>
    <item>
      <title>æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹è®­ç»ƒæ ‡ç­¾æœ¬èº«ä½œä¸ºç»“æœ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•æ ¹æ®å…·æœ‰â€œæ¶ˆæ¯â€ã€â€œå°¾å·´â€å’Œâ€œæ‰‹æŒ‡â€ç‰¹å¾çš„æ•°æ®æ„å»ºä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹â€œç‰©ç§â€ï¼Œå¹¶æ ‡è®°â€œç‰©ç§â€ï¼ˆå‚è§ä¸‹é¢ data.csv çš„å‰å‡ è¡Œï¼‰ï¼š



æ¶ˆæ¯
æ‰‹æŒ‡
å°¾å·´
ç‰©ç§




pluvia arbor aquos
4
no
Aquari


cosmix xeno nebuz odbitaz
5
æ˜¯
Zorblax


solarix glixx novum galaxum quasar
5
æ˜¯
Zorblax


arborsectus pesros ekos dootix nimbus
2
æ˜¯
Florian



æˆ‘çš„ä»£ç æ˜¯ï¼š
import warnings
warnings.simplefilter(&quot;ignore&quot;)
import pandas as pd
import numpy as np
å°† matplotlib.pyplot å¯¼å…¥ä¸º plt
ä» sklearn.preprocessing å¯¼å…¥ LabelEncoder
ä» sklearn.feature_extraction.text å¯¼å…¥ CountVectorizer
ä» sklearn.naive_bayes å¯¼å…¥ MultinomialNB

df = pd.read_csv(&quot;data.csv&quot;)
X = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
X = [str (item) for item in X]
y = df[&quot;species&quot;]

le = LabelEncoder()
y = le.fit_transform(y)

cv = CountVectorizer()
X = cv.fit_transform(X).toarray()

model = MultinomialNB()
model.fit(X, y)

test_data = pd.read_csv(&#39;test.csv&#39;)
test_data_array = np.asarray(df[[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]])
test_data_array = [str (item) for item in test_data_array]
test_data_array = cv.fit_transform(test_data_array).toarray()

y_prediction = model.predict(test_data_array)
y_prediction = le.inverse_transform(y_prediction)

print(y_prediction)

æˆ‘æŒ‰ç…§æœ¬æ•™ç¨‹è¿›è¡Œæ“ä½œä¸€æ ·ã€‚
é—®é¢˜æ˜¯ï¼Œå½“æˆ‘å°è¯•è¿è¡Œå®ƒæ—¶ï¼Œé™¤äº†ä¸€äº›å·®å¼‚å¤–ï¼Œå®ƒåªæ˜¯é€å­—é€å¥åœ°è¾“å‡ºåŸå§‹è®­ç»ƒæ•°æ®çš„ç‰©ç§åˆ—ï¼ˆæœ‰ 493 ä¸ªç»“æœï¼Œè€Œæµ‹è¯•æ•°æ®åŒ…å« 299 ä¸ªæ¡ç›®ï¼Œè®­ç»ƒæ•°æ®åŒ…å« 500 ä¸ªæ¡ç›®ï¼‰ã€‚å®ƒå®é™…ä¸Šå¹¶æ²¡æœ‰ä¸ºæµ‹è¯•æ•°æ®é¢„æµ‹ä»»ä½•å†…å®¹ã€‚æˆ‘ä¸æ˜ç™½ä¸ºä»€ä¹ˆä»£ç ä¸èµ·ä½œç”¨ã€‚æœ‰äººèƒ½å¸®å¿™å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79016929/machine-learning-model-predicts-training-labels-themselves-as-result</guid>
      <pubDate>Tue, 24 Sep 2024 04:08:16 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨ smote å°†è¿‡é‡‡æ ·æ•°æ®å­˜å‚¨åœ¨å•ç‹¬çš„å˜é‡ä¸­ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</link>
      <description><![CDATA[åº”ç”¨ Smote è¿‡é‡‡æ ·æŠ€æœ¯åï¼Œæˆ‘åªæƒ³å°†æ–°ç”Ÿæˆçš„å€¼å­˜å‚¨åˆ° X2 å’Œ y2ã€‚X2 çš„ç‹¬ç«‹ç‰¹å¾å’Œ y2 çš„ç›®æ ‡å˜é‡
import numpy as np
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import LabelEncoder
dataset = pd.read_csv(&#39;https://archive.ics.uci.edu/static/public/17/data.csv&#39;)
X = dataset.iloc[:, 1:-1].values
y = dataset.iloc[:, -1].values
le = LabelEncoder()
y = le.fit_transform(y)
smt = SMOTE()
X1, y1 = smt.fit_resample(X, y)
#åœ¨å•ç‹¬çš„å˜é‡ä¸­ä½¿ç”¨ smote å¯¹æ•°æ®è¿›è¡Œè¿‡é‡‡æ ·
#X2 = ?
#y2 = ?

]]></description>
      <guid>https://stackoverflow.com/questions/79016928/how-can-i-store-the-oversampled-data-using-smote-in-a-separate-variable</guid>
      <pubDate>Tue, 24 Sep 2024 04:07:41 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨è¯­è¨€æ£€æµ‹ä¸­ä½¿ç”¨æ•°ç»„ä½œä¸ºç‰¹å¾æ—¶å‡ºç° KeyError</title>
      <link>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</link>
      <description><![CDATA[æˆ‘æ­£åœ¨æŒ‰ç…§æ­¤æ•™ç¨‹ä½¿ç”¨æœºå™¨å­¦ä¹ è¿›è¡Œè¯­è¨€æ£€æµ‹ã€‚ç„¶è€Œï¼Œåœ¨æˆ‘ä½¿ç”¨çš„æ•°æ®é›†ä¸­ï¼Œæœ‰å¤šä¸ªå˜é‡ä½œä¸ºç‰¹å¾ã€‚æˆ‘å°è¯•ç”¨ X = data[&quot;Text&quot;] ä»£æ›¿ X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]ï¼ˆmessageã€fingers å’Œ tail æ˜¯æˆ‘æ­£åœ¨ä½¿ç”¨çš„ä¸‰ä¸ªç‰¹å¾å˜é‡ï¼‰ï¼Œä½†å®ƒä¼šæŠ›å‡º KeyErrorï¼›
Tracebackï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨æœ€åä¸€æ¬¡ï¼‰ï¼š
æ–‡ä»¶ &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;ï¼Œç¬¬ 3805 è¡Œï¼Œåœ¨ get_loc
return self._engine.get_loc(casted_key)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶ &quot;index.pyx&quot;ï¼Œç¬¬ 167 è¡Œï¼Œåœ¨pandas._libs.index.IndexEngine.get_loc
æ–‡ä»¶â€œindex.pyxâ€ï¼Œç¬¬ 196 è¡Œï¼Œä½äº pandas._libs.index.IndexEngine.get_loc
æ–‡ä»¶â€œpandas\\_libs\\hashtable_class_helper.pxiâ€ï¼Œç¬¬ 7081 è¡Œï¼Œä½äº pandas._libs.hashtable.PyObjectHashTable.get_item
æ–‡ä»¶â€œpandas\\_libs\\hashtable_class_helper.pxiâ€ï¼Œç¬¬ 7089 è¡Œï¼Œä½äº pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

ä¸Šè¿°å¼‚å¸¸æ˜¯å¯¼è‡´ä»¥ä¸‹å¼‚å¸¸çš„ç›´æ¥åŸå› ï¼š

å›æº¯ï¼ˆæœ€è¿‘ä¸€æ¬¡è°ƒç”¨ï¼‰ï¼š
æ–‡ä»¶&lt;module&gt; ä¸­çš„ &quot;c:\Users\usr\Downloads\thecode.py&quot;ï¼Œç¬¬ 13 è¡Œ
X = df[&quot;message&quot;, &quot;fingers&quot;, &quot;tail&quot;]
~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶ &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py&quot;, ç¬¬ 4102 è¡Œ, ä½äº __getitem__
indexer = self.columns.get_loc(key)
^^^^^^^^^^^^^^^^^^^^^^^^^^
æ–‡ä»¶ &quot;C:\Users\usr\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\indexes\base.py&quot;, ç¬¬ 3812 è¡Œ, ä½äº get_loc
å¼•å‘ KeyError(key) err
KeyError: (&#39;message&#39;, &#39;fingers&#39;, &#39;tail&#39;)

æˆ‘åº”è¯¥å¦‚ä½•å®ç°ä»£ç æ‰èƒ½ä½¿ç”¨æ‰€æœ‰åŠŸèƒ½è€Œä¸æŠ›å‡ºé”™è¯¯ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79016443/keyerror-when-using-array-as-feature-in-language-detection</guid>
      <pubDate>Mon, 23 Sep 2024 22:15:21 GMT</pubDate>
    </item>
    <item>
      <title>é€šè¿‡æ¨¡å‹å¤§è§„æ¨¡æµ‹è¯•é¢„æµ‹æ¯’æ€§æµ‹å®š</title>
      <link>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</link>
      <description><![CDATA[æˆ‘ç›®å‰æ­£åœ¨åˆ›å»ºä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹æ±¡æŸ“å¯¹ç”Ÿç‰©ä½“çš„æ¯’æ€§æµ‹å®šã€‚ç”±äºæ²¡æœ‰åˆé€‚çš„æ•°æ®é›†ï¼Œæˆ‘è¿˜æ²¡æœ‰å°è¯•ä»»ä½•ä¸œè¥¿ã€‚æˆ‘åªæ˜¯æƒ³é—®é—®æˆ‘çš„ä»£ç æ˜¯å¦åˆé€‚ã€‚æ¬¢è¿æå‡ºæ‰¹è¯„ã€‚æ­¤å¤–ï¼Œå¦‚æœæˆ‘é—æ¼äº†ä»€ä¹ˆæˆ–åº”è¯¥åŒ…æ‹¬ä»€ä¹ˆï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚
æ­¤å¤–ï¼Œæˆ‘æ­£åœ¨è€ƒè™‘æ›´å¤šæ¨¡å‹ï¼Œä¾‹å¦‚ RandomForestRegressorã€Boostingï¼ˆAdaBoostã€GradientBoostï¼‰ã€‚æˆ‘åº”è¯¥è€ƒè™‘è¿™äº›å—ï¼Ÿæ­¤å¤–ï¼Œå½“æˆ‘æœ€ç»ˆè·å¾—æ•°æ®æ—¶ï¼Œæ˜¯å¦æœ‰ä»»ä½•æ¨¡å‹æˆ‘åº”è¯¥ä»æµ‹è¯•ä¸­åˆ é™¤ï¼Ÿ
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv(&#39;&#39;) # åŒ…å«æ•°æ®çš„ csv æ–‡ä»¶ï¼ˆæµ“åº¦å’Œæ­»äº¡ç‡ï¼‰

# åŸºæœ¬å›¾è¡¨
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;Mortality&#39;) 

# è®­ç»ƒä¸æµ‹è¯•çš„åŸºæœ¬åˆ’åˆ†
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=101) 

# çº¿æ€§æ¨¡å‹
from sklearn.linear_model import LinearRegression 
lr_model = LinearRegression()
lr_model.fit(X_train,y_train)
lr_preds = lr_model.predict(X_test)
from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_absolute_error(y_test, lr_preds)
np.sqrt(mean_absolute_error(y_test, lr_preds))
concentration_range = np.arange(0,100) # æ ¹æ®æœ€å°/æœ€å¤§æµ“åº¦è°ƒæ•´
concentration_preds = lr_model.predict(concentration_range.reshape(-1,1))
plt.figure(figsize = (12,6),dpi = 200)
sns.scatterplot(data = df, x = &#39;Concentration&#39;, y = &#39;ä¿¡å·&#39;)
plt.plot(concentration_range,concentration_preds)

# å¤šé¡¹å¼æ¨¡å‹
# ç”¨äºæµ‹è¯•æ¨¡å‹çš„å‡½æ•°
def run_model(model, X_train, y_train, X_test, y_test):
# æ‹Ÿåˆæ¨¡å‹
model.fit(X_train,y_train)

# è·å–æŒ‡æ ‡
preds = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test,preds))
mae = mean_absolute_error(y_test, preds)
print(f&#39;MAE: {mae}&#39;)
print(f&#39;RMSE: {rmse}&#39;)

# ç»˜åˆ¶ç»“æœæ¨¡å‹ä¿¡å·èŒƒå›´
density_range = np.arange(0,100) # å†æ¬¡è°ƒæ•´
density_preds = model.predict(concentration_range.reshape(-1,1))

plt.figure(figsize = (12,8), dpi = 200)
sns.scatterplot(x = &#39;Concentration&#39;, y = &#39;Mortality&#39;, data = df, color = &#39;black&#39;)
plt.plot(concentration_range, density_preds)

æ¥è‡ª sklearn.pipeline å¯¼å…¥ make_pipeline
æ¥è‡ª sklearn.preprocessing å¯¼å…¥ PolynomialFeatures

pipe = make_pipeline(PolynomialFeatures(degree = 2),LinearRegression()) # degree å¯è°ƒæ•´
run_model(pipe, X_train, y_train, X_test, y_test)

# K-Nearest Neighbors æ¨¡å‹
æ¥è‡ª sklearn.neighbors å¯¼å…¥ KNeighborsRegressor
k_values = [1,2,3,4,5,6,7,8,9,10]
for k in k_values:

model = KNeighborsRegressor(n_neighbors=k)
run_model(model, X_train,y_train,X_test, y_test)

# å†³ç­–æ ‘æ¨¡å‹
from sklearn.tree import DecisionTreeRegressor
model = DecisionTreeRegressor()
run_model(model, X_train, y_train, X_test, y_test)

# SVR æ¨¡å‹
from sklearn.svm import SVR # æ”¯æŒå‘é‡å›å½’
from sklearn.model_selection import GridSearchCV
svr = SVR()
param_grid = {&#39;C&#39;:[0.01,0.1,1,5,10,100,1000],
&#39;gamma&#39;:[&#39;auto&#39;,&#39;scale&#39;]}

grid = GridSearchCV(svr, param_grid)
run_model(grid, X_train,y_train,X_test, y_test)
]]></description>
      <guid>https://stackoverflow.com/questions/79016340/predicting-toxicity-assay-through-mass-testing-of-models</guid>
      <pubDate>Mon, 23 Sep 2024 21:25:16 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰äººçŸ¥é“å¦‚ä½•ä¿®å¤åº“é”™è¯¯å—ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79015388/does-anyone-know-how-to-fix-library-error</link>
      <description><![CDATA[æˆ‘é‡åˆ°äº†è¿™ä¸ªé”™è¯¯ï¼Œå°è¯•äº†æ‰€æœ‰æ–¹æ³•ï¼Œä½†è¿˜æ˜¯æ— æ³•è§£å†³ï¼š
ModuleNotFoundError Traceback (most recent call last)
&lt;ipython-input-13-6c7180fd4822&gt; in &lt;cell line: 1&gt;()
----&gt; 1 from crewapi_module import CrewAPI # ç”¨æ­£ç¡®çš„å¯¼å…¥è·¯å¾„æ›¿æ¢
2 
3 crew_api = CrewAPI(api_key=&quot;your_crewai_api_key&quot;)
4 
5 # ç°åœ¨æ‚¨å¯ä»¥ä¸ API äº¤äº’ï¼Œä¾‹å¦‚ï¼š

ModuleNotFoundErrorï¼šæ²¡æœ‰åä¸ºâ€œcrewapi_moduleâ€çš„æ¨¡å—
]]></description>
      <guid>https://stackoverflow.com/questions/79015388/does-anyone-know-how-to-fix-library-error</guid>
      <pubDate>Mon, 23 Sep 2024 15:52:13 GMT</pubDate>
    </item>
    <item>
      <title>å—ä¸åŒèšç±»å¤§å°çº¦æŸçš„ KMeans</title>
      <link>https://stackoverflow.com/questions/79015120/kmeans-constrained-with-different-cluster-size</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªåŒ…å«å•†åº—åæ ‡çš„æ•°æ®æ¡†ï¼Œæˆ‘æƒ³æ ¹æ®ä¾›åº”å•†åº”è¯¥è®¿é—®è¯¥å•†åº—çš„æ—¥æœŸå°†å®ƒä»¬åˆ’åˆ†ä¸ºç°‡ã€‚ä¾‹å¦‚ï¼Œå‡è®¾ä¾›åº”å•†åº”è¯¥è®¿é—® 180 å®¶å•†åº—ã€‚ä»–åº”è¯¥åœ¨å‘¨ä¸€åˆ°å‘¨äº”è®¿é—® 30-34 å®¶å•†åº—ï¼Œå‘¨å…­ï¼Œä»–åº”è¯¥è®¿é—®å…¶ä»–æ—¥å­çš„ 60%ã€‚
æˆ‘è¯¥æ€ä¹ˆåšï¼Ÿä½¿ç”¨ kmeans-constrainedï¼Œæˆ‘åªèƒ½å°†å®ƒä»¬åˆ’åˆ†ä¸ºå¤§å°ç›¸ç­‰çš„ç°‡ã€‚ä¹Ÿè®¸æˆ‘éœ€è¦ä½¿ç”¨æŸç§è§£ç®—å™¨æˆ–åœ¨é›†ç¾¤ä¹‹é—´ç§»åŠ¨ç‚¹ä»¥è¾¾åˆ°æˆ‘æƒ³è¦çš„æ•°å­—ï¼Œä½†æˆ‘ä¸çŸ¥é“å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚
ä»¥ä¸‹æ˜¯å°†å®ƒä»¬å‡ç­‰åˆ’åˆ†çš„ä»£ç ï¼š
# å¾ªç¯éå†ä¾›åº”å•†é›†ç¾¤
for vendor in df[&quot;vendor&quot;].unique():

# æ¯ä¸ªä¾›åº”å•†çš„å•†åº—æ•°é‡
n_shops = df.loc[df[&quot;vendor&quot;] == vendor][&quot;cod_shop&quot;].count()

# ç´¢å¼•
idx = df.loc[df[&quot;vendor&quot;] == vendor].index

# ä¸€å‘¨ä¸­å„å¤©çš„é›†ç¾¤æ•°é‡
num_clusters = 5 # æ˜ŸæœŸä¸€è‡³æ˜ŸæœŸäº”

# é›†ç¾¤çš„å¹³å‡å¤§å°
avg_size = n_shops / (num_clusters + 0.6)

# å®šä¹‰é™åˆ¶
min_shops = round(avg_size - n_shops * pct, 0)
max_shops = math.ceil(avg_size + n_shops * pct)

# æ¨¡å‹
kmeans = KMeansConstrained(n_clusters=num_clusters, size_min=min_shops, size_max=max_shops, random_state=42)
labels = kmeans.fit_predict(df.loc[df[&quot;vendor&quot;] == vendor][[&quot;latitude&quot;, &quot;longitude&quot;]])

# å‘æ•°æ®æ¡†æ·»åŠ æ ‡ç­¾
df.loc[idx, &quot;visit_day&quot;] = labels
]]></description>
      <guid>https://stackoverflow.com/questions/79015120/kmeans-constrained-with-different-cluster-size</guid>
      <pubDate>Mon, 23 Sep 2024 14:42:09 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ NumPy å®ç°åŸºæœ¬ç¥ç»ç½‘ç»œçš„é—®é¢˜</title>
      <link>https://stackoverflow.com/questions/79014083/problem-implementing-a-basic-neural-network-with-numpy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79014083/problem-implementing-a-basic-neural-network-with-numpy</guid>
      <pubDate>Mon, 23 Sep 2024 09:49:44 GMT</pubDate>
    </item>
    <item>
      <title>æ„å»º OCR æ¨¡å‹ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79013996/building-ocr-model</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ç ”ç©¶ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå…¶ä¸­è¾“å…¥æ˜¯å›¾åƒå’Œå®ä½“åç§°ï¼Œç›®æ ‡æ˜¯ä»å›¾åƒä¸­æå–ç›¸åº”çš„å®ä½“å€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå®ä½“åç§°æ˜¯â€œé«˜åº¦â€ï¼Œå¹¶ä¸”å›¾åƒåŒ…å«é—¨çš„é«˜åº¦ï¼Œåˆ™æ¨¡å‹åº”æå–æ­¤å€¼ï¼ˆä¾‹å¦‚ 6 è‹±å°ºï¼‰ä»¥åŠæ­£ç¡®çš„å•ä½ã€‚
è¾“å…¥ï¼š
å›¾åƒï¼šåŒ…å«å¯¹è±¡ï¼ˆä¾‹å¦‚é—¨ï¼‰å’Œç›¸å…³ä¿¡æ¯ï¼ˆä¾‹å¦‚é«˜åº¦æˆ–å…¶ä»–ç›¸å…³æµ‹é‡å€¼ï¼‰ã€‚
å®ä½“åç§°ï¼šå…³é”®å­—ï¼Œä¾‹å¦‚â€œé«˜åº¦â€æˆ–â€œé‡é‡â€ï¼ŒæŒ‡å®šè¦ä»å›¾åƒä¸­æå–çš„å€¼ã€‚
è¾“å‡ºï¼š
ä¸å›¾åƒä¸­çš„å®ä½“ç›¸å¯¹åº”çš„å€¼åŠå…¶å•ä½ï¼ˆä¾‹å¦‚â€œ6 è‹±å°ºâ€ï¼‰ã€‚
æŒ‘æˆ˜ï¼š
å®ä½“å€¼å¯ä»¥å‡ºç°åœ¨å›¾åƒçš„ä¸åŒéƒ¨åˆ†ï¼Œå…·æœ‰ä¸åŒçš„æ–‡æœ¬æ ¼å¼ã€å­—ä½“æˆ–æ ·å¼ã€‚
éœ€è¦è¯†åˆ«å’Œæå–æµ‹é‡å•ä½ï¼ˆä¾‹å¦‚ï¼Œç±³ã€è‹±å°ºï¼‰ä»¥åŠå€¼ã€‚
é—®é¢˜ï¼š

å¤„ç†æ­¤ç±»ä»»åŠ¡çš„æœ€ä½³æ–¹æ³•æˆ–æ¨¡å‹æ¶æ„æ˜¯ä»€ä¹ˆï¼Ÿ
æ˜¯å¦æœ‰ä»»ä½•ç‰¹å®šæŠ€æœ¯æˆ–é¢„è®­ç»ƒæ¨¡å‹å¯ä»¥å¸®åŠ©å°†å›¾åƒå’Œå®ä½“åç§°ç»„åˆä¸ºè¾“å…¥ï¼Œä»¥ä»å›¾åƒä¸­æå–ç›¸åº”çš„å€¼ï¼Ÿ
æˆ‘åº”è¯¥å¦‚ä½•é¢„å¤„ç†å›¾åƒå’Œæ ‡ç­¾ä»¥è®­ç»ƒæ­¤ç±»ä»»åŠ¡çš„æ¨¡å‹ï¼Ÿ
æ˜¯å¦æœ‰ä»»ä½•å…³äºæ¡†æ¶å’Œå·¥å…·çš„æŒ‡å¯¼ã€å‚è€ƒæˆ–å»ºè®®ï¼Ÿ

æˆ‘å°è¯•ä½¿ç”¨å¸¦æœ‰ CTC æŸå¤±çš„ CNN+RNNï¼Œä½†æˆ‘çš„æŸå¤±æ¥è¿‘ 20 å¹¶ä¸”æ²¡æœ‰è¿›ä¸€æ­¥å‡å°‘
è¿™é‡Œæˆ‘é™„ä¸Šäº†æˆ‘çš„ google cloab é“¾æ¥
ç¬”è®°æœ¬é“¾æ¥]]></description>
      <guid>https://stackoverflow.com/questions/79013996/building-ocr-model</guid>
      <pubDate>Mon, 23 Sep 2024 09:27:35 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ Deepface Deepface.represent ä» ROI è·å–åµŒå…¥æ—¶å‡ºé”™</title>
      <link>https://stackoverflow.com/questions/79013712/error-getting-embeddings-from-a-roi-using-deepface-deepface-represent</link>
      <description><![CDATA[æˆ‘åœ¨ä½¿ç”¨ Deepface ä» Retinaface è¯†åˆ«çš„è£å‰ª ROI è·å–åµŒå…¥æ—¶é‡åˆ°äº†é—®é¢˜ã€‚
æˆ‘æ­£å°è¯•ä½¿ç”¨ä¸€äº›åäººçš„æ•°æ®é›†ï¼ˆå›¾åƒï¼‰å­¦ä¹ å¯¹è±¡è¯†åˆ«ï¼Œå¹¶å¯èƒ½è€ƒè™‘å°†å…¶ç”¨äºæˆ‘çš„ä¸ªäººç…§ç‰‡åº“ã€‚æˆ‘å°è¯•ä½¿ç”¨ Haar Cascade è¿›è¡Œäººè„¸æ£€æµ‹ï¼Œå¹¶ä½¿ç”¨ Open Cv ä¸­çš„ LBPHFaceRecognize è¿›è¡Œäººè„¸è¯†åˆ«ï¼Œæ•ˆæœå¾ˆå¥½ã€‚ç„¶åæˆ‘æƒ³å°è¯•ä½¿ç”¨ Retinafce è¿›è¡Œäººè„¸æ£€æµ‹å¹¶è·å¾— ROIã€‚ROI å­˜å‚¨åœ¨åˆ—è¡¨ä¸­ï¼Œå¹¶ä½¿ç”¨ Deepface ä»é€‰å®šçš„ ROI è·å–åµŒå…¥å¹¶å­˜å‚¨åœ¨å¦ä¸€ä¸ªåˆ—è¡¨ä¸­ã€‚æˆ‘æ­£åœ¨å°è¯•å°†åµŒå…¥å­˜å‚¨åˆ°åˆ—è¡¨ä¸­ï¼Œä½†æˆ‘ä¸€ç›´å¾—åˆ°
 raise ValueError(
ValueError: æ— æ³•åœ¨ numpy æ•°ç»„ä¸­æ£€æµ‹åˆ°äººè„¸ã€‚è¯·ç¡®è®¤å›¾ç‰‡

æ˜¯äººè„¸ç…§ç‰‡æˆ–è€ƒè™‘å°† force_detection å‚æ•°è®¾ç½®ä¸º Falseã€‚
è™½ç„¶æ‰€æœ‰å›¾åƒéƒ½æœ‰ä¸€å¼ è¢«æ¸…æ¥šæ£€æµ‹åˆ°çš„äººè„¸ã€‚è¿™æ˜¯æˆ‘çš„ä»£ç ä¾›å‚è€ƒï¼š
import os
import cv2 as cv
from retinaface import RetinaFace
from deepface import DeepFace
import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

artist = [&#39;50cent&#39;] # type: ignore #MJ the GOAT!! , &#39;Kanye&#39;, &#39;Eminem&#39;, &#39;MichaelJackson&#39;
ROOT_DIR = &#39;asset/Face_Recon_Dataset&#39; #å›¾åƒæ•°æ®é›†çš„è·¯å¾„
faces_roi =[]
labels = []
embeddings = []
#ç°åœ¨åœ¨è„¸éƒ¨åæ ‡ä¸Šç”»ä¸€ä¸ªçŸ©å½¢
#è„¸éƒ¨èŒƒå›´æœ‰ï¼š
# x1, y1) = (28, 51) #å·¦ä¸Šè§’
# (x2, y2) = (61, 98) #å³ä¸‹è§’
&quot;&quot;&quot; è¿™å®šä¹‰äº†æ£€æµ‹åˆ°çš„è„¸éƒ¨å‘¨å›´çš„çŸ©å½¢è¾¹ç•Œæ¡†ã€‚
- x1 (28)ï¼šè„¸éƒ¨çš„å·¦è¾¹ç¼˜
- y1 (51)ï¼šè„¸éƒ¨çš„ä¸Šè¾¹ç¼˜
- x2 (61)ï¼šè„¸éƒ¨çš„å³è¾¹ç¼˜
- y2 (98)ï¼šè„¸éƒ¨çš„ä¸‹è¾¹ç¼˜&quot;&quot;&quot;

def get_roi():
for artist_name in artist:
# è·å–è‰ºæœ¯å®¶å§“åçš„ç´¢å¼•
label = artist.index(artist_name)
image_folder = os.path.join(ROOT_DIR,artist_name) # è·å–åŒ…å«å›¾åƒçš„å®é™…æ–‡ä»¶å¤¹
for artist_images in os.listdir(image_folder): # åˆ—å‡ºè¯¥ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒ
image = os.path.join(image_folder,artist_images)
resp = RetinaFace.detect_faces(image)
# ç¡®ä¿äººè„¸å­˜åœ¨
if isinstance(resp,dict):
img = cv.imread(image)
for face_id, face_data in resp.items():
# print(face_id)
# print(&quot;x1: &quot;, face_data[&#39;facial_area&#39;][0])
# print(&quot;y1: &quot;, face_data[&#39;facial_area&#39;][1])
# print(&quot;x2: &quot;, face_data[&#39;facial_area&#39;][2])
# print(&quot;y2: &quot;, face_data[&#39;facial_area&#39;][3], &quot;\n&quot;)
# è¯»å–å›¾åƒ

# æ£€æµ‹äººè„¸
x1 = face_data[&#39;facial_area&#39;][0]
y1 = face_data[&#39;facial_area&#39;][1]
x2 = face_data[&#39;facial_area&#39;][2]
y2 = face_data[&#39;facial_area&#39;][3]

# ä¸ºäººè„¸ç»˜åˆ¶è¾¹ç•Œæ¡† 
# faces_rect = cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
face_roi = img[y1:y2,x1:x2]

#ç”¨å…¶åç§°æ ‡è®°è£å‰ªåçš„ roi äººè„¸
faces_roi.append(face_roi)

labels.append(label)
print(len(faces_roi))
print(len(labels))
print(&quot;å·²æ ‡è®°å’Œç´¢å¼•çš„å›¾åƒ&quot;)
print(&quot;æ­£åœ¨åˆå§‹åŒ–åµŒå…¥è¿‡ç¨‹.....&quot;)
get_embeddings()

def get_embeddings():
&quot;&quot;&quot; ä½¿ç”¨ deepface ä»æ¯ä¸ªäººè„¸ roi ä¸­æå–åµŒå…¥&quot;&quot;&quot;
print(&quot;Satarting embedding: ğŸš€ğŸš€ &quot;)
for roi in faces_roi:
face_roi_resized = cv.resize(roi, (160, 160)) # å°†äººè„¸ ROI è°ƒæ•´ä¸º 160x160 åƒç´ 
embedding = DeepFace.represent(face_roi_resized, model_name=&quot;Facenet&quot;)
print(embedding)
embeddings.append(embedding)
print(&quot;Vectors storage in list..&quot;)

get_roi()

# æ˜¯æ—¶å€™ä½¿ç”¨ svm åˆ†ç±»å™¨æµ‹è¯•å’Œè®­ç»ƒè¿™ä¸ªåå®¶ä¼™äº†
# å°†åµŒå…¥å’Œç´¢å¼•æ ‡è®°ä¸º numpy æ•°ç»„
X = np.array(embeddings) #feature
y = np.array(labels) #label

# å°†æ•°æ®åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒ SVM åˆ†ç±»å™¨
svm_model = SVC(kernel=&#39;linear&#39;) # çº¿æ€§æ ¸æ˜¯åµŒå…¥çš„è‰¯å¥½é»˜è®¤å€¼
svm_model.fit(X_train, y_train)

# è¯„ä¼°æ¨¡å‹
y_pred = svm_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f&quot;SVM æ¨¡å‹å‡†ç¡®ç‡ï¼š{accuracy * 100:.2f}%&quot;)

ä¸ºä»€ä¹ˆå³ä½¿ ROI å·²è¢«è£å‰ªï¼Œè¯¥é”™è¯¯ä»ç„¶å¦‚æ­¤æŒç»­ï¼Œè§£å†³æ­¤é”™è¯¯çš„æœ€ä½³æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79013712/error-getting-embeddings-from-a-roi-using-deepface-deepface-represent</guid>
      <pubDate>Mon, 23 Sep 2024 08:03:12 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆä½¿ç”¨å›å½’ç®—æ³•è€Œä¸æ˜¯åˆ†ç±»ç®—æ³•ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79013513/why-are-regression-algorithms-used-instead-of-classification-algorithms</link>
      <description><![CDATA[ä¼—æ‰€å‘¨çŸ¥ï¼Œåœ¨ ML ä¸­ï¼Œå¦‚æœä¾èµ–ç‰¹å¾æœ¬è´¨ä¸Šæ˜¯è¿ç»­çš„ï¼Œåˆ™åº”ç”¨å›å½’æ¨¡å‹ã€‚ä½†æ˜¯ï¼Œå¦‚æœä¾èµ–ç‰¹å¾æœ¬è´¨ä¸Šæ˜¯åˆ†ç±»çš„ï¼Œåˆ™ä½¿ç”¨åˆ†ç±»ç®—æ³•ã€‚
æ­£å¦‚æ‚¨åœ¨è¿™å¼ å›¾ï¼ˆhttps://i.sstatic.net/9Q3wfudK.pngï¼‰ä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œæœ€å¤§å€¼ä¸ºã€‚å¤§é‡æ•°æ®ç‚¹é‡å¤å‡ºç°ï¼Œè¡¨æ˜å®ƒä»¬æ­£åœ¨å½¢æˆç±»åˆ«ã€‚
é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆè¿™é‡Œä½¿ç”¨å›å½’ï¼Ÿ
è¿™æ˜¯æ•°æ®é›†ï¼šï¼ˆhttps://drive.google.com/file/d/1vTIiQ0NZKgBI-EfpGzfPKHx1VaAdEYdH/view?usp=sharingï¼‰
æˆ‘å’ŒåŒå­¦ã€è€å¸ˆè®¨è®ºäº†è¿™ä¸ªé—®é¢˜ã€‚ä»–ä»¬éƒ½è¯´å›å½’æ˜¯ç”¨æ¥é¢„æµ‹çš„ï¼Œä½†æ²¡äººèƒ½è§£é‡Šä»–ä»¬æ˜¯å¦‚ä½•å¾—å‡ºåº”è¯¥ç”¨å›å½’æ¥ä»£æ›¿åˆ†ç±»çš„ç»“è®ºçš„ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79013513/why-are-regression-algorithms-used-instead-of-classification-algorithms</guid>
      <pubDate>Mon, 23 Sep 2024 07:10:30 GMT</pubDate>
    </item>
    <item>
      <title>å°†éŸ³é¢‘æ–‡ä»¶åˆ†å‰²æˆå—ï¼Œè·³è¿‡å°äºæ‰€éœ€æ—¶é—´é•¿åº¦çš„å—ï¼Œå¹¶é¢„æµ‹æ•´ä¸ªéŸ³é¢‘æ–‡ä»¶çš„æƒ…æ„Ÿ</title>
      <link>https://stackoverflow.com/questions/76253683/split-an-audio-file-into-chunks-skip-the-chunks-less-than-desired-time-duration</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°†éŸ³é¢‘ä¿¡å·åˆ†ç±»ä¸ºæƒ…ç»ªç±»ï¼Œå¹¶ä½¿ç”¨ hugginface çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»…æ¥æ”¶ 8 ç§’çš„éŸ³é¢‘ã€‚æ‰€ä»¥æˆ‘å°†éŸ³é¢‘åˆ†æˆ 8 ç§’çš„æ–‡ä»¶ã€‚
æˆ‘å·²å°†æ–‡ä»¶â€œAâ€åˆ†æˆ a1ã€a2ã€a3ã€a4ã€a5ã€a6ã€a7ã€a8
ç°åœ¨æˆ‘ä½¿ç”¨è¯¥æ¨¡å‹å¯¹æ¯ä¸ªéŸ³é¢‘è¿›è¡Œåˆ†ç±»ï¼Œä½†æˆ‘éœ€è¦é€šè¿‡å–æ–‡ä»¶ a1-a8 çš„é¢„æµ‹å¹³å‡å€¼æ¥æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶â€œAâ€çš„æ€»ä½“ç±»åˆ«ã€‚
æˆ‘è¯¥æ€ä¹ˆåšï¼Œè¯·å¸®å¸®æˆ‘ã€‚
names = []
# ä½¿ç”¨ Ridzuan/Audio_Emotion_Classifier(huggingface) å°†éŸ³é¢‘æ–‡ä»¶çš„å¤§å°è°ƒæ•´ä¸º &lt;8 ç§’ï¼Œä»¥ä¾¿è¿›è¡Œé¢„æµ‹
for file in tqdm(Path(&quot;D:/program/SER_DATA_sample/exg/&quot;).glob(&quot;**/*.wav&quot;)):
name = os.path.basename(file).split(&#39;.&#39;)[0]
names.append(names)
names_df = pd.DataFrame(names)

temp = name
path = []
audio_path = &#39;C:/Users/XTEND/PycharmProjects/DATA_EVAL/RESAMPLE/&#39;
dir_list = os.listdir(audio_path)
# label = os.path.basename(audio_path).split(&#39;_&#39;)[1].split(&#39;.&#39;)[0]

audio = AudioSegment.from_file(file)
length_audio = len(audio)
print(&quot;éŸ³é¢‘æ–‡ä»¶é•¿åº¦&quot;, length_audio)

start = 0
# ä»¥æ¯«ç§’ä¸ºå•ä½ï¼Œè¿™å°†æˆªå– 7 ç§’çš„éŸ³é¢‘
Threshold = 7000
end = 0
counter = 0
num_split = length_audio/threshold
print(num_split)

while start &lt; len(audio):
end += é˜ˆå€¼
print(start, end)
file = audio[start:end]
filename = f&#39;RESAMPLE/{counter}{name}.wav&#39;
file.export(filename, format=&quot;wav&quot;)
print(file)
counter += 1
start += é˜ˆå€¼

file_path = &#39;C:/Users/XTEND/PycharmProjects/DATA_EVAL/RESAMPLE/&#39;
# file_path = &#39;D:/program/XTEND_AUDIO_DATASET/ps/&#39;
dir_list = os.listdir(file_path)
number_files = len(dir_list)
print(number_files)

emo_df = []
routes = []
count = 1

for i in dir_list:
audio_data = file_path + i
routes.append(audio_data)
audio_path_df = pd.DataFrame(paths, columns=[&#39;Path&#39;])
count += 1
print(count, audio_data)

data_ori, sample_rate = librosa.load(audio_data)
data, _ = librosa.effects.trim(data_ori)

test = prepare_test(audio_data)
pred = classifier.predict(test)
pred_df = pd.DataFrame(pred.T, index=[&#39;anger&#39;, &#39;happiness&#39;, &#39;neutral&#39;, &#39;sadness&#39;, &#39;surprised&#39;],
columns=[&#39;Scores&#39;])
print(pred_df)
emo = pred_df[pred_df[&#39;Scores&#39;] == pred_df.max().values[0]].index[0]
print(emo)
emo_df.append(emo)
]]></description>
      <guid>https://stackoverflow.com/questions/76253683/split-an-audio-file-into-chunks-skip-the-chunks-less-than-desired-time-duration</guid>
      <pubDate>Mon, 15 May 2023 11:40:33 GMT</pubDate>
    </item>
    <item>
      <title>æœ‰æ²¡æœ‰åŠæ³•å°† Google Colab ä»£ç è½¬æ¢ä¸º Web æœåŠ¡æˆ– REST API</title>
      <link>https://stackoverflow.com/questions/60443948/is-there-a-way-to-turn-google-colab-code-into-web-services-or-rest-apis</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å—ï¼Œå®ƒä½¿ç”¨ Google Colab çš„å…è´¹ Gâ€‹â€‹PU æ‰§è¡Œ NLP ä»»åŠ¡ï¼Œæˆ‘æƒ³ç”¨å®ƒåˆ¶ä½œä¸€ä¸ª Web åº”ç”¨ç¨‹åºã€‚æˆ‘ä¸€ç›´åœ¨è€ƒè™‘ä½¿ç”¨ React js ä½œä¸ºå‰ç«¯ï¼Œä½¿ç”¨ spring boot ä½œä¸ºåç«¯ï¼Œæƒ³çŸ¥é“æ˜¯å¦æœ‰åŠæ³•å°† Google Colab çš„ä»£ç ä¸åç«¯è¿æ¥èµ·æ¥ã€‚
æƒ³çŸ¥é“åœ¨ Colab ä¸­æ„å»ºåŒ…å« ML æ¨¡å—çš„ Web åº”ç”¨ç¨‹åºçš„å…¶ä»–æ›¿ä»£å»ºè®®ã€‚ä»»ä½•å½¢å¼çš„å¸®åŠ©éƒ½å€¼å¾—èµèµã€‚]]></description>
      <guid>https://stackoverflow.com/questions/60443948/is-there-a-way-to-turn-google-colab-code-into-web-services-or-rest-apis</guid>
      <pubDate>Fri, 28 Feb 2020 01:10:30 GMT</pubDate>
    </item>
    <item>
      <title>é¢ä¸´ ValueErrorï¼šç›®æ ‡æ˜¯å¤šç±»ä½†å¹³å‡å€¼='äºŒè¿›åˆ¶'</title>
      <link>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•å¯¹æˆ‘çš„æ•°æ®é›†ä½¿ç”¨æœ´ç´ è´å¶æ–¯ç®—æ³•ã€‚æˆ‘èƒ½å¤Ÿæ‰¾å‡ºå‡†ç¡®ç‡ï¼Œä½†è¯•å›¾æ‰¾å‡ºç›¸åŒçš„ç²¾ç¡®åº¦å’Œå¬å›ç‡ã€‚ä½†æ˜¯ï¼Œå®ƒæŠ›å‡ºäº†ä»¥ä¸‹é”™è¯¯ï¼š
ValueErrorï¼šç›®æ ‡æ˜¯å¤šç±»ï¼Œä½†å¹³å‡å€¼=&#39;binary&#39;ã€‚è¯·é€‰æ‹©å…¶ä»–å¹³å‡è®¾ç½®ã€‚

æœ‰äººå¯ä»¥å»ºè®®æˆ‘å¦‚ä½•ç»§ç»­å—ï¼Ÿæˆ‘å°è¯•åœ¨ç²¾ç¡®åº¦å’Œå¬å›ç‡åˆ†æ•°ä¸­ä½¿ç”¨average =&#39;micro&#39;ã€‚å®ƒæ²¡æœ‰ä»»ä½•é”™è¯¯ï¼Œä½†å®ƒç»™å‡ºäº†ç›¸åŒçš„å‡†ç¡®åº¦ã€ç²¾ç¡®åº¦å’Œå¬å›ç‡åˆ†æ•°ã€‚
æˆ‘çš„æ•°æ®é›†ï¼š
train_data.csvï¼š
review,label
é¢œè‰²å’Œæ¸…æ™°åº¦æä½³ï¼Œæ­£é¢
å¯æƒœå›¾ç‰‡ä¸å¦‚æˆ‘çš„ 40 è‹±å¯¸ä¸‰æ˜Ÿæ¸…æ™°æ˜äº®ï¼Œè´Ÿé¢

test_data.csvï¼š
review,label
å›¾ç‰‡æ¸…æ™°æ¼‚äº®ï¼Œæ­£é¢
å›¾ç‰‡ä¸æ¸…æ™°ï¼Œè´Ÿé¢

æˆ‘çš„ä»£ç ï¼š
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confused_matrix

X_train, y_train = pd.read_csv(&#39;train_data.csv&#39;)
X_test, y_test = pd.read_csv(&#39;test_data.csv&#39;)

vec = CountVectorizer() 
X_train_transformed = vec.fit_transform(X_train) 
X_test_transformed = vec.transform(X_test)

clf = MultinomialNB()
clf.fit(X_train_transformed, y_train)

score = clf.score(X_test_transformed, y_test)

y_pred = clf.predict(X_test_transformed)
cm = confused_matrix(y_test, y_pred)

precision = precision_score(y_test, y_pred, pos_label=&#39;positive&#39;)
recall = recall_score(y_test, y_pred, pos_label=&#39;positive&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/52269187/facing-valueerror-target-is-multiclass-but-average-binary</guid>
      <pubDate>Tue, 11 Sep 2018 05:28:04 GMT</pubDate>
    </item>
    </channel>
</rss>