<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 10 Sep 2024 15:17:10 GMT</lastBuildDate>
    <item>
      <title>使用 Pytorch 进行人体分割会失败，但使用 Tensorflow Keras 不会失败</title>
      <link>https://stackoverflow.com/questions/78969962/human-segmentation-fails-with-pytorch-not-with-tensorflow-keras</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78969962/human-segmentation-fails-with-pytorch-not-with-tensorflow-keras</guid>
      <pubDate>Tue, 10 Sep 2024 14:18:33 GMT</pubDate>
    </item>
    <item>
      <title>使用 R 预测股票波动性</title>
      <link>https://stackoverflow.com/questions/78969928/forecasting-volatility-of-stocks-in-r</link>
      <description><![CDATA[项目概述：
我正在开展一个项目，使用 469 天内 292 只股票的每日数据来预测股票指数的波动性。我有一个包含 104 个特征的数据集，包括特定于股票的特征、滞后变量和移动平均线。此外，我计算了 6 个波动代理，并计划对每个代理进行 1 天、5 天和 10 天的预测。
目标：
我的目标是：使用经典的时间序列预测方法（例如 ARIMA、GARCH）对波动性进行建模。
应用机器学习技术（例如随机森林、梯度提升、RNN）来提高预测准确性。
具体挑战：
鉴于我的数据结构（每日股票数据、波动代理和各种特征），我不确定如何最好地进行传统时间序列模型和机器学习模型的特征选择和预处理。
我正在寻找有关模型选择的指导、在多变量环境中处理时间序列数据的最佳实践以及任何可以帮助我获得的相关文献开始。
问题：
使用时间序列模型和机器学习技术预测波动性的最佳起点是什么？
是否有任何推荐的资源或论文可以解释如何使用这样的数据集进行波动性预测？
我应该如何处理多元时间序列预测的特征工程和模型验证？
任何关于如何进行的建议、推荐阅读或指示都将不胜感激。谢谢！
如果有任何不清楚的地方，请随时提问
我正在做一个预测股票指数波动率的项目，但由于缺乏某些技术的经验，我不知道如何开始。
以下是我想做的事情：

我有 469 天内 292 只股票的每日数据。
我的数据集包括 104 个特征，例如特定于股票的变量、滞后变量和移动平均线。
我已经计算了 6 个波动率代理，我的目标是预测每个代理未来 1、5 和 10 天的情况。
我计划从经典的时间序列预测方法（例如 ARIMA、GARCH）开始，然后探索机器学习技术，如随机森林或RNN。

我遇到的困难：
我不确定如何开始这个项目。具体来说，我很难理解如何构建数据、选择特征和应用适当的模型。我不知道如何进行时间序列和机器学习方法的特征选择、模型验证和性能评估。
我希望得到一些关于从哪里开始的指导、推荐的方法以及任何可以帮助我学习最佳实践的资源或文献。任何帮助我入门的建议、提示或资源都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78969928/forecasting-volatility-of-stocks-in-r</guid>
      <pubDate>Tue, 10 Sep 2024 14:11:41 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 OpenCV 改进这种图像自然背景扩展方法？</title>
      <link>https://stackoverflow.com/questions/78969286/how-can-i-improve-this-approach-for-natural-background-extension-in-an-image-usi</link>
      <description><![CDATA[我正在使用 Python 中的 OpenCV 扩展图像的背景。我目前的方法是复制边框并对扩展区域应用高斯模糊以将它们混合到原始图像中。目标是使背景扩展看起来更自然，尤其是对于具有一致纹理的图像。
这是我当前使用的代码：
import cv2
import numpy as np

def expand_image_with_smart_blend(image_path, top=50, bottom=50, left=50, right=50):
img = cv2.imread(image_path)
original_h, original_w = img.shape[:2]

expanded_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_REPLICATE)

blured_img = expand_img.copy()

if top &gt; 0:
blured_img[0:top, :] = cv2.GaussianBlur(expanded_img[0:top, :], (51, 51), 0)

如果底部 &gt; 0:
blured_img[original_h + top:original_h + top + bottom, :] = cv2.GaussianBlur(expanded_img[original_h + top:original_h + top + bottom, :], (51, 51), 0)

如果左侧 &gt; 0:
blured_img[:, 0:left] = cv2.GaussianBlur(expanded_img[:, 0:left], (51, 51), 0)

如果右侧 &gt; 0:
blured_img[:, original_w + left:original_w + left + right] = cv2.GaussianBlur(expanded_img[:, original_w + left:original_w + left + right], (51, 51), 0)

cv2.namedWindow(&quot;智能混合扩展图像&quot;, cv2.WINDOW_NORMAL)
cv2.namedWindow(&quot;原始图像&quot;, cv2.WINDOW_NORMAL)
cv2.imwrite(&#39;expanded_smart_blended_image.jpg&#39;, blured_img)
cv2.imshow(&#39;智能混合扩展图像&#39;, blured_img)
cv2.imshow(&quot;原始图像&quot;, img)
cv2.waitKey(0)
cv2.destroyAllWindows()

expand_image_with_smart_blend(&#39;test_img.jpg&#39;, top=100, bottom=100, left=100, right=100)

我尝试过的方法：
cv2.BORDER_REPLICATE：我使用它将原始图像的边缘复制到新扩展的区域中。
高斯模糊：应用于扩展区域以柔化原始图像和新区域之间的过渡。
问题：
结果在某种程度上是可以接受的，但过渡仍然看起来不像我想要的那样自然。特别是：
某些区域的过度模糊使背景看起来不真实。
对于纹理更复杂的图像，边缘复制并不总是有效。
原始图像 结果图像
问题：
在 OpenCV 或其他库中，是否有更复杂的方法来扩展图像的背景，从而产生更自然、无缝的结果？我愿意接受涉及高级图像处理技术或机器学习的方法。任何使用扩散模型的方法都可以。
任何帮助都将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78969286/how-can-i-improve-this-approach-for-natural-background-extension-in-an-image-usi</guid>
      <pubDate>Tue, 10 Sep 2024 11:32:09 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试在自定义数据集上训练我的分割模型时，准确率停留在同一数值上，一点也没有提高</title>
      <link>https://stackoverflow.com/questions/78969275/when-im-trying-to-train-my-segmentation-model-on-a-custom-dataset-the-accuracy</link>
      <description><![CDATA[我尝试过改变学习率、损失和指标，但在自定义数据集上运行时，准确率仍然“完全”相同（0.28）。损失有所减少，但幅度很小
训练循环详情：
它有一个 ResNet50 主干，包括 softmax。使用 tensorflow.keras。
我已将数据加载代码附在下面。

def load_image(image_path):
# 读取图像文件
image = tf.io.read_file(image_path)

# 解码图像
image = tf.image.decode_image(image, channels=3, expand_animations=False)

# 调整图像大小
image = tf.image.resize(image, [224, 224])

# 标准化图像
image = image / 255.0

# tf.print(&quot;调整大小后的图像形状：&quot;, tf.shape(image))

返回图像

def load_mask(mask_path):
# 读取掩码文件
mask = tf.io.read_file(mask_path)

# 解码掩码
mask = tf.image.decode_image(mask, channels=1, expand_animations=False)

#调整掩码大小
mask = tf.image.resize(mask, [224, 224])

# 标准化掩码
mask = mask / 255.0

# tf.print(&quot;调整大小后的掩码形状：&quot;, tf.shape(mask))

return mask

def serialize_example(image, mask):
feature = {
&#39;image&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(tf.cast(image * 255.0, tf.uint8)).numpy()])),
&#39;mask&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[tf.io.encode_jpeg(tf.cast(mask * 255.0, tf.uint8)).numpy()]))
}
example_proto = tf.train.Example(features=tf.train.Features(feature=feature))
return example_proto.SerializeToString()

def _parse_function(proto):
keys_to_features = {
&#39;image&#39;: tf.io.FixedLenFeature([], tf.string),
&#39;mask&#39;: tf.io.FixedLenFeature([], tf.string)
}
parsed_features = tf.io.parse_single_example(proto, keys_to_features)

image = tf.image.decode_jpeg(parsed_features[&#39;image&#39;], channels=3)
mask = tf.image.decode_jpeg(parsed_features[&#39;mask&#39;], channels=1)

image.set_shape([None, None, 3])
mask.set_shape([None, None, 1])

image = tf.image.resize(image, [224, 224]) / 255.0
mask = tf.image.resize(mask, [224, 224]) / 255.0

# 调试：打印图像和掩码的形状
print(f&quot;解析的图像形状：{tf.shape(image)}, 解析的掩码形状：{tf.shape(mask)}&quot;)

return image, mask

def preprocess_and_save_to_tfrecord(images_dir, mask_dir, output_file):
output_dir = os.path.dirname(output_file)
if not os.path.exists(output_dir):
os.makedirs(output_dir)

image_paths = sorted([os.path.join(images_dir, fname) for fname in os.listdir(images_dir) if fname.endswith(&#39;.jpg&#39;)])
mask_paths = sorted([os.path.join(masks_dir, fname) for fname in os.listdir(masks_dir) if fname.endswith(&#39;.jpg&#39;)])

if len(image_paths) != len(mask_paths):
raise ValueError(&quot;图像和掩码的数量不匹配。&quot;)

writer = tf.io.TFRecordWriter(output_file)
for image_path, mask_path in zip(image_paths, mask_paths):
image = load_image(image_path)
mask = load_mask(mask_path)
example = serialize_example(image, mask)
writer.write(example)
print(f&quot;将 {image_path} 和 {mask_path} 写入 TFRecord&quot;)
writer.close()

def load_tfrecord_dataset(tfrecord_file):
dataset = tf.data.TFRecordDataset(tfrecord_file)
dataset = dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)
return dataset
# 定义路径和输出文件
train_images_dir = &#39;segmentation/idd20k_final/train/images&#39;
train_masks_dir = &#39;segmentation/idd20k_final/train/mask&#39;
test_images_dir = &#39;segmentation/idd20k_final/test/images&#39;
test_masks_dir = &#39;segmentation/idd20k_final/test/mask&#39;

train_output_file = &#39;segmentation/idd20k_final/tfrecords/train.tfrecord&#39;
test_output_file = &#39;segmentation/idd20k_final/tfrecords/test.tfrecord&#39;

preprocess_and_save_to_tfrecord(train_images_dir, train_masks_dir, train_output_file)
preprocess_and_save_to_tfrecord(test_images_dir, test_masks_dir, test_output_file)

# 从 TFRecord 加载数据集
train_dataset = load_tfrecord_dataset(train_output_file)
test_dataset = load_tfrecord_dataset(test_output_file)

# 批处理和预取
batch_size = 16
train_dataset = train_dataset.batch(batch_size)
test_dataset = test_dataset.batch(batch_size)

# 这将使用标准 Python 打印形状
print(&quot;train_dataset 中的批次数：&quot;, len(list(train_dataset.as_numpy_iterator())))
print(&quot;test_dataset 中的批次数：&quot;, len(list(test_dataset.as_numpy_iterator())))
`base_learning_rate = 0.001
optimizer = tf.keras.optimizers.SGD(learning_rate=base_learning_rate, motivation=0.2, clipnorm=5.0)
model.compile(optimizer=optimizer,
loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),
metrics=[&#39;accuracy&#39;])`

]]></description>
      <guid>https://stackoverflow.com/questions/78969275/when-im-trying-to-train-my-segmentation-model-on-a-custom-dataset-the-accuracy</guid>
      <pubDate>Tue, 10 Sep 2024 11:29:37 GMT</pubDate>
    </item>
    <item>
      <title>zero123 的更大分辨率输出</title>
      <link>https://stackoverflow.com/questions/78969143/bigger-resolution-output-of-zero123</link>
      <description><![CDATA[我在 instantMesh 上下文中使用 zero123，我想知道 zero123 是否有可能输出更大分辨率的图像？
目前分辨率为 320x320，对于从 InstantMesh 的 3d 重建管道获得良好的输出纹理来说，这个分​​辨率有点低。
代码使用方式如下：
import torch
import request
from PIL import Image
from diffusers import DiffusionPipeline, EulerAncestralDiscreteScheduler

# 加载管道
pipeline = DiffusionPipeline.from_pretrained(
&quot;sudo-ai/zero123plus-v1.1&quot;, custom_pipeline=&quot;sudo-ai/zero123plus-pipeline&quot;,
torch_dtype=torch.float16
)

# 随意调整调度程序！
# `timestep_spacing` 参数在旧版本的 `diffusers` 中不受支持
# 因此可能会降低性能
# 我们建议使用 `diffusers==0.20.2`
pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
pipeline.scheduler.config, timestep_spacing=&#39;trailing&#39;
)
pipeline.to(&#39;cuda:0&#39;)

# 下载示例图像。
cond = Image.open(requests.get(&quot;https://d.skis.ltd/nrp/sample-data/lysol.png&quot;, stream=True).raw)

# 运行管道！
result = pipeline(cond, num_inference_steps=75).images[0]
# 对于一般物体的一般真实和合成图像
# 通常大约有 28 个推理步骤就足够了
# 对于具有面部等精细细节的图像（真实或动漫）
# 您可能需要 75-100 个步骤来构建细节

result.show()
result.save(&quot;output.png&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78969143/bigger-resolution-output-of-zero123</guid>
      <pubDate>Tue, 10 Sep 2024 10:55:23 GMT</pubDate>
    </item>
    <item>
      <title>如何在HuggingFace中组织机器学习项目？</title>
      <link>https://stackoverflow.com/questions/78969051/how-to-organize-a-machine-learning-project-in-huggingface</link>
      <description><![CDATA[虽然我同意没有一种适用于每种用例的“理想”组织方案，但我正在寻找一种标准化的方式来组织 HuggingFace 环境中机器学习 (ML) 项目中编译的代码、脚本、模型和数据。
根据我的经验，机器学习项目包括：

数据：用于训练和评估模型的一个或多个数据集（理想情况下，版本受控）。
模型：ML 模型的权重（同样，版本受控）
代码：用于以下操作的脚本集合：

收集和探索数据；

预处理、聚合数据并创建数据集；和

训练、调整和评估模型。




其他项目可能有其他组件，我有兴趣了解任何其他解决方案。例如，就我而言，我有一个应用程序的源代码，该应用程序利用模型实现特定目标。此应用程序使用 GitHub 进行版本控制。
为了使我的 ML 研究最开放和可重复，我希望将数据集和模型与脚本一起发布。这样，任何人都可以以与我完全相同的方式以最自动化的方式收集数据并训练模型。我发现 HuggingFace 是存储模型和数据集的绝佳场所，尽管无法找到一种结构化的方式将数据和模型脚本包含在各自的存储库中。
目前，我一直将模型和数据集上传到 HuggingFace，但脚本与应用程序源代码一起存储在 GitHub 中。我认为这并不正确，因为脚本与 ML 管道的关系比与后来使用它们的应用程序的关系更密切。]]></description>
      <guid>https://stackoverflow.com/questions/78969051/how-to-organize-a-machine-learning-project-in-huggingface</guid>
      <pubDate>Tue, 10 Sep 2024 10:30:42 GMT</pubDate>
    </item>
    <item>
      <title>Gradcam 与预期结果不符</title>
      <link>https://stackoverflow.com/questions/78968918/gradcam-doesnt-match-with-expected-results</link>
      <description><![CDATA[我为胸部 X 光 (CXR) 图像创建了 GradCAM 可视化，但结果并不如我所料。通常，GradCAM 热图会突出显示整个相关模式，如狗的脸或猫的腿，如下例所示：
我在互联网上看到的任何地方都能看到那些漂亮的热图，它们包裹着应该找到的整个模式
示例：

在这里，您可以清楚地看到模型专注于狗的脸或猫腿后部的图案。这也是人类会解读为猫或狗的部分。
但是，我的 GradCAM 结果看起来不同：

在我的可视化中，倒数第二层（Conv3_1）关注边缘，最后一层（Conv3_2）显示随机点，主要在心脏或胸骨上。尽管如此，我的模型的性能指标确实很好：
我只是假设我的模型只是做出了错误的预测，但准确率约为 96%，模型没有过度拟合，指标非常好
测试准确率：0.9570
测试损失：0.1253
测试 AUC：0.9896
测试精度：0.9719
测试召回率：0.9412

有人能向我解释一下为什么我制作的 gradcam 没有覆盖整个肺部吗？或者病理部位？
它学习的模式是否如此具体，以至于在最后一层只发现一小部分区域？]]></description>
      <guid>https://stackoverflow.com/questions/78968918/gradcam-doesnt-match-with-expected-results</guid>
      <pubDate>Tue, 10 Sep 2024 09:57:16 GMT</pubDate>
    </item>
    <item>
      <title>Prophet 模型如何进行预测？它也能处理损坏的数据吗？</title>
      <link>https://stackoverflow.com/questions/78968204/how-prophet-model-make-predictions-can-it-deal-with-broken-data-too</link>
      <description><![CDATA[我知道 lstm。如果序列长度为 7，那么模型将使用前 7 天的数据来预测第 8 天，然后采用滑动窗口方法。现在我听说了先知模型，它也用于时间序列预测。所以有人能告诉我先知模型如何进行预测吗？如果它是时间序列数据，那么它是否也需要连续的先前数据来进行预测？]]></description>
      <guid>https://stackoverflow.com/questions/78968204/how-prophet-model-make-predictions-can-it-deal-with-broken-data-too</guid>
      <pubDate>Tue, 10 Sep 2024 06:44:57 GMT</pubDate>
    </item>
    <item>
      <title>甜甜圈模型在预测时出现拼写错误</title>
      <link>https://stackoverflow.com/questions/78968086/donut-model-making-spelling-errors-while-predicting</link>
      <description><![CDATA[模型在预测时会随机出现拼写错误和拼写错误
假设单词“Battery”在图像中出现了 2 次，那么它会正确预测并且不会出现拼写错误，但第二次出现时，它会出现拼写错误，如“Batery”或“baery”，只是省略单词和其他错误，例如预测“.1”作为&quot;.I&quot;
我已使用这个在我的自定义数据集上对 naver-clova-ix/donut-base-finetuned-cord-v2 模型进行了微调，现在当我测试模型时，模型正确地预测了结构，我的发票的项目是存在的，但它在预测时会出现拼写错误，有时甚至完全遗漏了项目，尽管我已经提供了充足的数据集。]]></description>
      <guid>https://stackoverflow.com/questions/78968086/donut-model-making-spelling-errors-while-predicting</guid>
      <pubDate>Tue, 10 Sep 2024 06:03:43 GMT</pubDate>
    </item>
    <item>
      <title>调整 GAN 参数的最佳方法是什么？我试过网格搜索，但它的计算成本太高，而且速度很慢</title>
      <link>https://stackoverflow.com/questions/78968083/what-is-the-best-way-to-hypertune-parameters-for-gans-ive-tried-grid-search-bu</link>
      <description><![CDATA[我尝试过网格搜索，但它的计算成本太高，而且速度很慢。如果有其他方法，请告诉我。此外，我的一位同事发现网格搜索并不总能保证 GAN 的最佳参数值。
花费了太多时间，而且整个过程非常困难。]]></description>
      <guid>https://stackoverflow.com/questions/78968083/what-is-the-best-way-to-hypertune-parameters-for-gans-ive-tried-grid-search-bu</guid>
      <pubDate>Tue, 10 Sep 2024 06:02:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 MediaPipe 和 OpenCV 优化从视频中提取坐标的时间</title>
      <link>https://stackoverflow.com/questions/78967995/optimizing-coordinates-extraction-time-from-video-using-mediapipe-and-opencv</link>
      <description><![CDATA[我在 Python 后端服务器中使用 MediaPipe 和 OpenCV 从通过 API 有效负载发送的视频中提取人体姿势坐标。但这需要相当长的时间，例如，1080p 分辨率的 30/50 fps 的 1 秒视频大约需要 2 到 4 秒，3 到 5 秒的视频需要 30 到 45 秒，15 秒的视频大约需要 2 分钟。我尝试降低帧速率，将视频分成多个部分，但坐标提取所需的总体时间并没有改善。
关于如何优化坐标提取时间有什么建议吗？此外，还有其他比 MediaPipe 更快的坐标提取替代方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/78967995/optimizing-coordinates-extraction-time-from-video-using-mediapipe-and-opencv</guid>
      <pubDate>Tue, 10 Sep 2024 05:23:41 GMT</pubDate>
    </item>
    <item>
      <title>跨多个超市类别树的类别映射</title>
      <link>https://stackoverflow.com/questions/78967341/category-mapping-across-multiple-supermarket-category-trees</link>
      <description><![CDATA[我有来自多家超市的数据，包括他们的产品数据库和按产品描述分类的销售记录。我的数据被组织成一个自定义树结构，有 700 个叶节点和 7 个级别，所有产品都位于这些叶子中。我合作的一些超市有自己的分类，有些多达 2,000 个叶子。
我的目标是将我的类别无缝映射到超市的类别。由于他们想要按照他们的分类标准而不是我的分类标准来获取数据，因此手动映射 40 多家超市是不可行的。
最初，我考虑为每个超市训练一个单独的模型来预测我数据库中的所有描述并重新分类，但管理 40 多个模型并不实​​际。另一种策略是使用来自 neuromind/bert-base-portuguese-cased 模型的嵌入（因为数据是葡萄牙语）。我连接了树的各个层级（例如，食物 - 冷食 - 奶酪 - 穆扎雷拉奶酪），并使用 sklearn.metrics.pairwise 中的余弦相似度来查找超市结构中最相似的类别。然而，结果令人失望，即使有明显相似的类别，类别匹配也经常不准确。
我正在考虑大型语言模型方法（可能使用 LangChain 之类的方法）是否可以改进嵌入过程，或者是否有更好的方法。
是否有人解决过类似的问题，或者您对更有效的方法有什么建议？
def get_embedding(text):
inputs = tokenizer(text, return_tensors=&quot;pt&quot;, padding=True, truncation=True, max_length=512)
with torch.no_grad():
outputs = model(**inputs)
return outputs.last_hidden_​​state.mean(dim=1).squeeze().numpy()
]]></description>
      <guid>https://stackoverflow.com/questions/78967341/category-mapping-across-multiple-supermarket-category-trees</guid>
      <pubDate>Mon, 09 Sep 2024 22:14:57 GMT</pubDate>
    </item>
    <item>
      <title>神经元组织学图像分割的最佳方法</title>
      <link>https://stackoverflow.com/questions/78966320/optimal-methods-for-segmenting-histology-images-of-neurons</link>
      <description><![CDATA[我正在研究分割用 H&amp;E 染色的神经元组织学图像。
我很好奇分割这些图像的最有效方法。
我希望从图像中准确地分割出神经元。
我以前使用过细胞姿势分割，但它似乎对我的数据不太适用。
]]></description>
      <guid>https://stackoverflow.com/questions/78966320/optimal-methods-for-segmenting-histology-images-of-neurons</guid>
      <pubDate>Mon, 09 Sep 2024 16:00:24 GMT</pubDate>
    </item>
    <item>
      <title>我怎样才能提高 CNN 的准确性？[关闭]</title>
      <link>https://stackoverflow.com/questions/57834240/how-can-i-improve-my-cnns-accuracy-evolution</link>
      <description><![CDATA[因此，我正在尝试创建一个 CNN，它可以预测胸部 x 射线图像中是否有任何“支撑设备”，但在训练我的模型时，它似乎没有学到任何东西。
我正在使用一个名为“CheXpert”的数据集，它有超过 200,000 张图像可供使用。经过一些“清理”后，最终数据集最终有 100,000 张图像。
就模型而言，我导入了 vgg16 预训练模型的卷积基，并自行添加了 2 个完全连接的层。然后，我冻结了所有卷积基，只训练完全连接的层。这是代码：
from keras.layers import GlobalAveragePooling2D
from keras.models import Model

pretrained_model = VGG16(weights=&#39;imagenet&#39;, include_top=False)

pretrained_model.summary()

for layer in pretrained_model.layers:
layer.trainable = False

x = pretrained_model.output
x = GlobalAveragePooling2D()(x)

dropout = Dropout(0.25)

# 让我们添加一个全连接层
x = Dense(1024,activation=&#39;relu&#39;)(x)
x = dropout(x)
x = Dense(1024,activation =&#39;relu&#39;)(x)
predictions = Dense(1,activation=&#39;sigmoid&#39;)(x)

final_model = Model(inputs=pretrained_model.input, output=predictions)

final_model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;rmsprop&#39;, metrics=[&#39;accuracy&#39;])

据我所知，正常行为应该是准确率从低开始，然后随着时期的推移而增长。但在这里，它只在相同的值（0.93 和 0.95）之间波动。很抱歉，我无法上传图片来向您展示图表。
总而言之，我想知道准确率的微小差异是否意味着模型没有学到任何东西。
我有一个假设：在数据集的所有 100,000 张图像中，95,000 张带有标签“1”，只有 5,000 张带有标签“0”。我认为，如果将带有“1”的图像减少并使其与带有“0”的图像相等，结果就会改变。]]></description>
      <guid>https://stackoverflow.com/questions/57834240/how-can-i-improve-my-cnns-accuracy-evolution</guid>
      <pubDate>Sat, 07 Sep 2019 13:42:46 GMT</pubDate>
    </item>
    <item>
      <title>什么是 Killed:9 以及如何在 macOS 终端中修复？</title>
      <link>https://stackoverflow.com/questions/51833310/what-is-killed9-and-how-to-fix-in-macos-terminal</link>
      <description><![CDATA[我有一段用于机器学习项目的简单 Python 代码。我有一个相对较大的自发语音数据库。我开始训练我的语音模型。由于这是一个庞大的数据库，我让它连夜工作。早上我醒来时看到终端中出现一个神秘的
Killed: 9
行。没有其他内容。没有其他错误消息或需要处理的内容。代码运行良好约 6 小时，占整个过程的 75%，所以我真的不明白哪里出了问题。
什么是 Killed:9 以及如何修复它？浪费数小时的计算时间非常令人沮丧……
如果这很重要，我正在使用 macOS Mojave 测试版。提前谢谢您！]]></description>
      <guid>https://stackoverflow.com/questions/51833310/what-is-killed9-and-how-to-fix-in-macos-terminal</guid>
      <pubDate>Tue, 14 Aug 2018 03:28:58 GMT</pubDate>
    </item>
    </channel>
</rss>