<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 22 May 2024 15:15:55 GMT</lastBuildDate>
    <item>
      <title>为什么 nni 运行多个 python 文件导致我的电脑崩溃？</title>
      <link>https://stackoverflow.com/questions/78518205/why-does-nni-run-multiple-python-files-resulting-in-crashing-of-my-pc</link>
      <description><![CDATA[我尝试过以下方法：
实验名称：超参数搜索
作者姓名：Raj
试用并发数：1
培训服务平台：本地
searchSpacePath：searching_space.json
多线程：真
use注解: false
调音器：
    内置调谐器名称：随机

审判：
    命令：python train.py
    代码目录: .
    GPU数量：1

本地配置：
    使用ActiveGpu：真
    最大TrialNumPerGpu：2
    GPU索引：0

上面的结果导致如此多的Python文件在后台运行并导致我的笔记本电脑崩溃。另外，当我尝试使用 useActiveGpu: false 时，问题仍然存在。即使我以某种方式防止我的笔记本电脑崩溃，链接也无法打开。
但是当我使用 CPU 时，代码如下：
作者姓名：默认
实验名称：超参数搜索
试用并发数：1
培训服务平台：本地
use注解: false
searchSpacePath：searching_space.json
调音器：
  内置调谐器名称：随机
  类参数：
    优化模式：最小化
审判：
  命令：python train.py
  代码目录: .
  GPU数量: 0

nni 链接有效，所有任务都按预期运行并成功。
我使用的是 Pycharm IDE 的虚拟环境，nni 是 3.0 版本，我的操作系统是 Windows 10。我将所有变量设置为 .to(device)，其中我的设备是 cuda。代码不在nni下运行时运行正常，但只有在nni中使用GPU时才会出现问题。
我尝试尝试 TrialConcurrency、useActiveGpu、maxTrialNumPerGpu、gpuIndices。但所有结果都是一样的。笔记本电脑崩溃或链接无法打开，即使打开，“正在运行”、“失败”或“成功”中也不会显示任何内容，并且服务器之后不会立即工作。]]></description>
      <guid>https://stackoverflow.com/questions/78518205/why-does-nni-run-multiple-python-files-resulting-in-crashing-of-my-pc</guid>
      <pubDate>Wed, 22 May 2024 14:20:29 GMT</pubDate>
    </item>
    <item>
      <title>广义 Jensen-Shannon 散度 - 多重分布 - 长度不等的向量 - R</title>
      <link>https://stackoverflow.com/questions/78518168/generalised-jensen-shannon-divergence-multiple-distributions-vectors-of-uneq</link>
      <description><![CDATA[我想计算 R 中长度不等的三个分布（dist1、dist2、dist3）之间的广义 Jensen-Shannon 散度 (GSJD)。
我想知道是否有人可以帮助我：
(1) 将我的原始数据转换为适合 GSJD 分析的概率矩阵，
(2) 以及之后如何在R中运行GSJD。
到目前为止，我一直在使用 Philentropy 库，但没有成功。
我的发行版如下所示。所有帮助将不胜感激
install.packages(“philentropy”)
图书馆（慈善事业）

#具有三个分布的数据

dist1 &lt;- 样本（seq（从 = 0，到 = 1，by = 0.005），大小 = 100，替换 = TRUE）
dist2 &lt;- 样本（seq（从 = 0，到 = 1，by = 0.005），大小 = 150，替换 = TRUE）
dist3 &lt;- 样本（seq（从 = 0，到 = 1，by = 0.005），大小 = 250，替换 = TRUE）
]]></description>
      <guid>https://stackoverflow.com/questions/78518168/generalised-jensen-shannon-divergence-multiple-distributions-vectors-of-uneq</guid>
      <pubDate>Wed, 22 May 2024 14:14:41 GMT</pubDate>
    </item>
    <item>
      <title>如何解决功能未定义错误？</title>
      <link>https://stackoverflow.com/questions/78517764/how-do-i-resolve-features-not-defined-error</link>
      <description><![CDATA[传入 features 参数的函数
这是纽约市出租车乘坐问题的预测分析。
我一直在通过 Great Learning 学习数据科学/机器学习课程。我遇到了一个函数问题，我之前已经定义了参数，但它返回一个错误，指出未定义。非常感谢任何帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78517764/how-do-i-resolve-features-not-defined-error</guid>
      <pubDate>Wed, 22 May 2024 13:07:00 GMT</pubDate>
    </item>
    <item>
      <title>使用 SHAP 解释学习到的潜在空间位置</title>
      <link>https://stackoverflow.com/questions/78517488/using-shap-to-explain-learned-latent-space-position</link>
      <description><![CDATA[我在 MNIST 数据集上的 pytorch 中实现了一个监督自动编码器。
我在潜在空间（大小 8）上使用分类层对其进行监督。在训练期间，我优化了 MSE 重建损失和分类损失 (BCE)。我在潜在空间中有单个实例，这些实例很有趣，我想找到它们不同位置的解释。
所以我的问题是，在潜在维度上使用 SHAP 值是否是一种有效的方法（它有效，我得到了值，但我不确定这是否有意义）。
更具体地说：我想比较例如实例 A 和实例 B。假设在潜在空间中它们相距很远，例如在潜在维度 3 of 8 中。现在我想找到输入中可以解释这种现象的像素。因此，我计算实例 A 和 B 的潜在表示的 SHAP 值，并比较两者的维度 3 的 SHAP 值。这是有效的吗？我认为它与解释多输出回归没有太大不同，对吧？但我还没有看到任何 SHAP 的应用来解释潜在位置
非常感谢您的任何评论！]]></description>
      <guid>https://stackoverflow.com/questions/78517488/using-shap-to-explain-learned-latent-space-position</guid>
      <pubDate>Wed, 22 May 2024 12:17:33 GMT</pubDate>
    </item>
    <item>
      <title>限制中途使用上传的图像来创建新图像</title>
      <link>https://stackoverflow.com/questions/78517370/restrict-mid-journey-to-use-the-uploaded-image-for-creating-new-image</link>
      <description><![CDATA[在中途有没有一种方法可以限制它使用我们自己上传的图像来创建新图像？例如，我有一个帽子的图像，并希望在旅途中创建一个戴着相同帽子的男孩的新图像。
如果不在旅途中，是否有任何图像生成工具可以执行相同的操作。]]></description>
      <guid>https://stackoverflow.com/questions/78517370/restrict-mid-journey-to-use-the-uploaded-image-for-creating-new-image</guid>
      <pubDate>Wed, 22 May 2024 11:55:32 GMT</pubDate>
    </item>
    <item>
      <title>ONNX 中的拆分模型</title>
      <link>https://stackoverflow.com/questions/78517213/splitting-models-in-onnx</link>
      <description><![CDATA[我想评估模型的性能。但我想为此进行分层评估，我需要将深度学习模型拆分为层/子图。你们有什么建议或资源吗？我知道 ONNX 允许您创建模型子图，但这并不是特定于每一层的。如果我想根据层而不是节点来拆分模型怎么办？
这有点超前，但 resnet 有 515 个节点。是否可以创建 10 个子图并通过一些分析来评估它们的每个性能？
目前我正在尝试探索创建给定模型（resnet.onnx）的子图。评估特定层/子图的推理性能的方法有哪些]]></description>
      <guid>https://stackoverflow.com/questions/78517213/splitting-models-in-onnx</guid>
      <pubDate>Wed, 22 May 2024 11:28:15 GMT</pubDate>
    </item>
    <item>
      <title>DQN 显示损失有所改善，但缺乏奖励改善</title>
      <link>https://stackoverflow.com/questions/78516916/dqn-showing-loss-improvements-but-lacking-reward-improvements</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78516916/dqn-showing-loss-improvements-but-lacking-reward-improvements</guid>
      <pubDate>Wed, 22 May 2024 10:32:11 GMT</pubDate>
    </item>
    <item>
      <title>阻止进程时内核崩溃</title>
      <link>https://stackoverflow.com/questions/78516548/kernel-crashed-while-stemming-process</link>
      <description><![CDATA[我使用这个函数来进行句子词干提取
从 nltk.stem 导入 WordNetLemmatizer、PorterStemmer
从 nltk.tokenize 导入 word_tokenize
导入字符串
从 nltk.corpus 导入停用词

标点符号 = set(字符串.标点符号)
english_stopwords = set(stopwords.words(&#39;english&#39;))
porter_stemmer = PorterStemmer()
def clean_text(文本):
    文本 = 文本.lower()
    标记 = word_tokenize(文本)
    clean_tokens = []
    clean_tokens = [如果令牌不在 english_stopwords 中则为令牌中的令牌的令牌]
    clean_tokens = [如果标记不在标点符号中，则标记为标记中的标记]
    clean_tokens = [token 中的 token if token.isalnum()]
    clean_tokens = [porter_stemmer.stem(token) for token in clean_tokens if len(token) &gt;; 0]

    返回 &#39;​​ &#39;.join(cleaned_tokens)


我只是在我的 csv 上运行它
导入 pandas 作为 pd
currData = pd.read_csv(f&#39;../Steam dataset/clean_steam_database(english)_133.csv&#39;)
currData[&#39;review&#39;] = [clean_text(word) for word in currData[&#39;review&#39;]]

但它说：
“在当前单元或前一个单元中执行代码时内核崩溃。
请检查单元格中的代码以确定失败的可能原因。
点击这里查看更多信息。
查看 Jupyter 日志以获取更多详细信息。”
和
给出这个错误：
＆quot;16：23：09.679 [错误]将会话处置为内核进程死亡 ExitCode：3221225725，原因：
16:23:09.706 [info] Cell 2 在 -1716369788.31 秒内完成（开始：1716369788310，结束：未定义）”
它可能是什么？
我实际上是从以下位置获取这个数据集的：
https://www.kaggle.com/datasets/najzeko/ steam-reviews-2021?resource=download
我在已分成 1000 个部分的数据集上运行此代码。
每次执行该函数时，我都会打印以查看哪个索引有问题，但是，当我直接在该索引处运行该函数时，它没有问题。
当我在 google colab 上运行这段代码时，它说
“RecursionError：比较中超出了最大递归深度”
Stem命令有问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78516548/kernel-crashed-while-stemming-process</guid>
      <pubDate>Wed, 22 May 2024 09:32:06 GMT</pubDate>
    </item>
    <item>
      <title>每个时期 Retinanet 模型内的数据流</title>
      <link>https://stackoverflow.com/questions/78516393/flow-of-data-inside-the-retinanet-model-in-each-epoch</link>
      <description><![CDATA[需要通过提供batch_size、epochs和每个epoch的步骤来澄清向retinanet model_network提供了多少数据。
到目前为止，我认为步长的计算如下：
step_size = (total_number_of_data/batch_size)*epochs

而在keras-retinanet中，它以batch_size、epochs和steps_per_epoch作为参数，这与上述情况不同。我有疑问如何进行计算？提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/78516393/flow-of-data-inside-the-retinanet-model-in-each-epoch</guid>
      <pubDate>Wed, 22 May 2024 09:04:14 GMT</pubDate>
    </item>
    <item>
      <title>名为“为视障人士提供帮助”的项目的功能 [关闭]</title>
      <link>https://stackoverflow.com/questions/78515845/features-for-a-project-titled-assistance-for-visually-impaired</link>
      <description><![CDATA[我正在开展一个名为“为视障人士提供援助”的项目。我已经添加了一些功能，并且正在尝试添加更多功能。
任何人都可以向我建议一个可以添加以使其完美的功能列表吗？]]></description>
      <guid>https://stackoverflow.com/questions/78515845/features-for-a-project-titled-assistance-for-visually-impaired</guid>
      <pubDate>Wed, 22 May 2024 07:11:59 GMT</pubDate>
    </item>
    <item>
      <title>ModuleNotFoundError：没有名为“utils.feature_extractor”的模块[关闭]</title>
      <link>https://stackoverflow.com/questions/78515681/modulenotfounderror-no-module-named-utils-feature-extractor</link>
      <description><![CDATA[
嗨，为什么我有这个错误，我的文件上已经有这个函数，但它仍然错误？
我正在创建一个网络钓鱼链接检测，需要在执行结果之前扫描所需的功能。
我已经添加了该功能，我检查了拼写，但什么也没发生。]]></description>
      <guid>https://stackoverflow.com/questions/78515681/modulenotfounderror-no-module-named-utils-feature-extractor</guid>
      <pubDate>Wed, 22 May 2024 06:36:46 GMT</pubDate>
    </item>
    <item>
      <title>确定可最小化预测误差的最佳聚合级别</title>
      <link>https://stackoverflow.com/questions/78514089/determining-an-optimal-level-of-aggregation-that-would-minimize-prediction-error</link>
      <description><![CDATA[我正在寻找一种聚合预测结果的方法，以最大化类别数量，同时最小化分类错误。
举一个激励性的例子，假设我正在执行一个预测任务，按流派对歌曲进行分类，并且有 6 种流派（来自下面的目标列）：



流派（广泛）
流派（目标）




流行音乐
独立音乐流行音乐


流行音乐
超流行音乐


流行音乐
韩国流行音乐


摇滚音乐
另类摇滚音乐


摇滚音乐
经典摇滚音乐


摇滚音乐
硬摇滚音乐



该模型在识别前 4 个类别（独立流行音乐、超流行音乐、韩国流行音乐、另类摇滚音乐）方面具有 100% 的准确率，但将大约 50% 的硬摇滚歌曲误归为经典摇滚，将大约 20% 的经典摇滚歌曲误归为硬摇滚。
基于为此，可以设想以几种方式聚合目标流派，从而减少分类错误。例如

2 个类别：流行音乐、摇滚乐
4 个类别：独立流行音乐、超流行音乐、韩国流行音乐、摇滚乐
5 个类别：独立流行音乐、超流行音乐、韩国流行音乐、另类摇滚乐、其他摇滚乐

在这种情况下，我希望将目标流派聚合到这 5 个类别中，尽可能多地保留类别，同时保持 100% 的准确率。
为了找到理想的聚合结构，我可以对所有可能的聚合进行置换并计算 MSE。但是，考虑到我正在处理的类别数量，这在计算上是不可行的。所以，我想知道是否有一些相关文献可以让我阅读，以便更好地了解如何解决这个问题，或者是否有人有想法。]]></description>
      <guid>https://stackoverflow.com/questions/78514089/determining-an-optimal-level-of-aggregation-that-would-minimize-prediction-error</guid>
      <pubDate>Tue, 21 May 2024 19:51:46 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：用户偏好向量和餐厅特征向量必须具有相同的维数</title>
      <link>https://stackoverflow.com/questions/78475573/valueerror-user-preference-vector-and-restaurant-feature-vectors-must-have-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78475573/valueerror-user-preference-vector-and-restaurant-feature-vectors-must-have-the</guid>
      <pubDate>Tue, 14 May 2024 03:27:58 GMT</pubDate>
    </item>
    <item>
      <title>关于 pytorch 在多 GPU 上的再现性</title>
      <link>https://stackoverflow.com/questions/70178014/something-about-the-reproducibility-of-pytorch-on-multi-gpu</link>
      <description><![CDATA[我设置了随机种子以使我的模型可重现，并且当我使用单个 GPU 来训练我的模型时它可以工作。
但当我尝试使用 nn.DataParallel() 在两个 GPU 上训练我的模型时，它似乎不起作用。每次的结果都不一样。
那么问题出在哪里呢？
设置种子的函数是这样的：
def set_seed(种子):
    随机种子（种子）
    np.random.seed(种子)
    torch.manual_seed(种子)
    torch.cuda.manual_seed（种子）
    torch.cuda.manual_seed_all(种子)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.确定性 = True
]]></description>
      <guid>https://stackoverflow.com/questions/70178014/something-about-the-reproducibility-of-pytorch-on-multi-gpu</guid>
      <pubDate>Wed, 01 Dec 2021 01:15:54 GMT</pubDate>
    </item>
    <item>
      <title>GridSearchCV 返回的精度比默认值差</title>
      <link>https://stackoverflow.com/questions/67666417/gridsearchcv-returns-worse-accuracy-than-default</link>
      <description><![CDATA[我正在使用 Kaggle 的心脏病预测数据集，并发现了一些奇怪的东西，但我找不到答案。
使用带有“liblinear”求解器的默认 Logistic 回归 (C = 1)，我在训练集上获得的准确度为 87.26%，在测试集上的准确度为 86.81%。不错。然而，我尝试使用 GridSearchCV 调整 C，以防我找到更好的值，但我不断得到更差的结果（训练集上的准确度约为 85%，测试集上的准确度约为 82.5%）。
GridSearchCV 是否使用其他指标来比较这些 C 值？我只是不明白为什么它会返回一个更糟糕的解决方案。
我将代码的最后一部分留在这里。
默认 Logistic 回归
从 sklearn.linear_model 导入 LogisticRegression
    
lr = LogisticRegression(求解器 = &#39;lib线性&#39;, random_state = 2)
lr = lr.fit(X_train, y_train)

model_score(lr, X_train, y_train, X_test, y_test)

GridSearchCV
从 sklearn.model_selection 导入 GridSearchCV
# 为逻辑回归寻找更好的超参数
lr_params = [ {&#39;C&#39;: np.logspace(-1, 0.3, 30)} ]

lr = LogisticRegression(求解器 = &#39;lib线性&#39;, random_state = 2)
lr_cv = GridSearchCV(lr, lr_params, cv = 5, 评分 = &#39;准确度&#39;)
lr_cv.fit(X_train, y_train)

lr_best_params = lr_cv.best_params_
lr = 逻辑回归(**lr_best_params)
lr.fit(X_train, y_train)

model_score(lr, X_train, y_train, X_test, y_test)

编辑
此链接中的完整代码 （查看第 4-4.1 节）。]]></description>
      <guid>https://stackoverflow.com/questions/67666417/gridsearchcv-returns-worse-accuracy-than-default</guid>
      <pubDate>Mon, 24 May 2021 03:42:19 GMT</pubDate>
    </item>
    </channel>
</rss>