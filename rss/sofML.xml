<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 28 Jan 2024 18:14:53 GMT</lastBuildDate>
    <item>
      <title>将图像移动到目录后数字不同</title>
      <link>https://stackoverflow.com/questions/77895090/different-numbers-after-moving-images-into-a-directory</link>
      <description><![CDATA[我试图将一些图像移动到包含 3 个类（石头、布和剪刀）的目录中，以分割基本目录。
我尝试过这段代码：
train_dir = os.path.join(base_dir, &#39;train&#39;)
val_dir = os.path.join(base_dir, &#39;验证&#39;)
test_dir = os.path.join(base_dir, &#39;测试&#39;)

# 创建子目录
对于 [train_dir, val_dir, test_dir] 中的目录：
    os.makedirs（目录，exist_ok=True）

# 类别列表（石头、剪刀、布）
类名 = os.listdir(base_dir)

# 迭代每个类
对于 class_names 中的 class_name：
    class_path = os.path.join(base_dir, class_name)

    如果 os.path.isdir(class_path):
        # 列出类中的所有图像
        images = [img for img in os.listdir(class_path) if img.endswith(&#39;.jpg&#39;) or img.endswith(&#39;.png&#39;) or img.endswith(&#39;.jpeg&#39;) and img != &#39;README_rpc-简历-images.txt&#39;]

        # 将图像分为训练集、验证集和测试集
        训练图像，测试图像，训练标签，测试标签=训练测试分割（
            所有图像、所有标签、test_size=0.2、random_state=42）

        train_images，val_images，train_labels，val_labels = train_test_split（
            训练图像、训练标签、测试大小=0.25、随机状态=42）
        
        对于 [os.path.join(train_dir, class_name), os.path.join(val_dir, class_name), os.path.join(test_dir, class_name)] 中的目录：
            os.makedirs（目录，exist_ok=True）

        # 将图片移动到对应的子目录
        对于 train_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(train_dir, class_name, img))
        对于 val_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(val_dir, class_name, img))
        对于 test_images 中的 img：
          Shutil.move(os.path.join(class_path, img), os.path.join(test_dir, class_name, img))

但是在我使用此代码仔细检查了 train_images 和 train_dir 中的图像数量后：
print(f“train_images 中的图像数量: {len(train_images)}”)
print(f&quot;train_dir 中的图像数量: {len(train_dir)}&quot;)

结果是：
train_images 中的图像数量：1312 和
train_dir 中的图像数量：28
我一直在寻找导致这种数字差异的代码出了什么问题。
关于如何解决这个问题有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/77895090/different-numbers-after-moving-images-into-a-directory</guid>
      <pubDate>Sun, 28 Jan 2024 14:15:59 GMT</pubDate>
    </item>
    <item>
      <title>Java Weka API：获取 ROC 面积值</title>
      <link>https://stackoverflow.com/questions/77895012/java-weka-api-getting-roc-area-values</link>
      <description><![CDATA[我正在尝试在 java 类中使用 Weka API。我执行了 10 倍交叉验证，然后使用不同的阈值对数据进行二值化。
但是我是使用 Weka API 的新手，所以不确定我所做的是否正确。我正在获取 ROC 值，但请注意确保它们是正确的。下面是我的代码：
for(int i = 0; i &lt; 阈值.length; i++)
{
     // learnSet 的深拷贝
     ArrayList&gt; learnSetCopy = new ArrayList&lt;&gt;();
     for (ArrayList insideList : learnSet)
     {
         ArrayList; innerCopy = new ArrayList&lt;&gt;();
         for (int[] 数组：innerList)
         {
             int[] arrayCopy = Arrays.copyOf(array, array.length);
             innerCopy.add(arrayCopy);
         }
         learnSetCopy.add(innerCopy);
     }

     // validSet 的深拷贝
     ArrayList&gt; validSetCopy = new ArrayList&lt;&gt;();
     for (ArrayList insideList : validSet)
     {
         ArrayList; innerCopy = new ArrayList&lt;&gt;();
         for (int[] 数组：innerList)
         {
             int[] arrayCopy = Arrays.copyOf(array, array.length);
             innerCopy.add(arrayCopy);
         }
         validSetCopy.add(innerCopy);
     }

     //二值化化学蛋白质相互作用值
     binarizeCpiAttributes(learnSetCopy, 阈值[i]);
     //生成要通过Weka运行的Arff文件
     generateARFF(文件名 + “LearningThreshold” + 阈值[i] + “折叠” + j + “.arff”, attributeNames, learnSetCopy);

     binarizeCpiAttributes(validSetCopy, 阈值[i]);
     generateARFF(文件名 + “ValidThreshold” + 阈值[i] + “Fold” + j + “.arff”, attributeNames, validSetCopy);

     //创建学习和有效arff文件的实例
     实例learningInstances = DataSource.read(fileName + &quot;LearningThreshold&quot; + Threshold[i] + &quot;Fold&quot; + j + &quot;.arff&quot;);
     实例 validInstances = DataSource.read(fileName + &quot;ValidThreshold&quot; + Threshold[i] + &quot;Fold&quot; + j + &quot;.arff&quot;);

     //设置学习和有效集的类标签
     if(learningInstances.classIndex() == -1)
     {
         LearningInstances.setClassIndex(learningInstances.numAttributes()-1);
     }

     if(validInstances.classIndex() == -1)
     {
         validInstances.setClassIndex(validInstances.numAttributes()-1);
     }

     RandomForest cls = new RandomForest();
     字符串[] 选项 = {
         “-P”、“100”、
         “-I”、“100”、
         “-num-slots”、“1”、
         “-K”、“0”、
         “-M”、“1.0”、
         “-V”、“0.001”、
         “-S”、“1”
     };
     cls.setOptions(选项);
     cls.buildClassifier(learningInstances);

     评估 eval = 新评估(learningInstances);
     eval.evaluateModel(cls​​, validInstances);

     System.out.println(&quot;ROC曲线下面积：&quot; + eval.areaUnderROC(1));

     // 根据需要打印或使用 rocAuc 值
     System.out.println(“处理阈值：”+threshold[i]);
}

这是我得到的输出的示例。我确实认为它们应该更高，这让我怀疑我所做的是否正确：
ROC 曲线下面积：0.6000602772754672 使用阈值处理：0.4 ROC 曲线下面积：0.5848854731766124 使用阈值处理：0.5 ROC 曲线下面积：0.594831223628692 使用阈值处理：0.6 ROC 曲线下面积：0.5600 51235684147 处理阈值：0.7 
我在这里所做的是否正确，这是获取 ROC 面积值的正确方法还是我从 Weka API 获取其他值？
我尝试通读所提供的 Weka 文档，但对某些部分感到困惑。]]></description>
      <guid>https://stackoverflow.com/questions/77895012/java-weka-api-getting-roc-area-values</guid>
      <pubDate>Sun, 28 Jan 2024 13:56:04 GMT</pubDate>
    </item>
    <item>
      <title>Tesseract 的训练自定义数据集以及版本之间的差异</title>
      <link>https://stackoverflow.com/questions/77894617/training-custom-dataset-for-tesseract-and-difference-between-versions</link>
      <description><![CDATA[我正在尝试构建自定义数据集，然后对其进行训练，以改进tesseract 的 OCR。
然而，我很难理解确切的步骤或正确的方法。请注意，我在机器学习方面的经验很少，尤其是在神经网络方面。
在开始我的问题之前，我想说，我认为 LSTM 是从 Tesseract 4 开始添加的，并且对于较低版本，默认使用自适应分类器。
我在这里查看了文档：https://github.com/tesseract-ocr/tessdoc  但老实说，我很困惑，因为我的经验为零，并且通过查看一些教程，我发现了很多差异。
我的问题是：

在创建数据集时，我只需要基本上将 .jpeg 图像转换为 .tiff 格式，并为每个 .tiff 创建 .box 文件，该文件基本上是每个字符及其坐标（标签）的容器。这是低于 4 版本的超正方体训练模型的方法吗？
这是问题 1 的后续问题。我正在使用 JTessBoxEditor (https://github.com/nguyenq /jTessBoxEditor）用于创建框文件，我认为它太慢了，因为您无法使用指针选择字符（边界框），但您必须使用文本字段手动完成，是否有更快的方法？
我见过的另一种训练模型的方法基本上是拥有一组图像（.tiff 或 .png），这些图像需要是单行，并将内容转录在 .gt.txt 文件中。基本上，您只需提供整行的文本，而不是指定每个坐标的坐标。我认为这是从 tesseract 4 开始训练 LSTM 模型的方法，对吗？

我尝试识别的图像上的文本如下：








如果您还可以提供有关我的案例场景的确切步骤的详细说明，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77894617/training-custom-dataset-for-tesseract-and-difference-between-versions</guid>
      <pubDate>Sun, 28 Jan 2024 11:33:15 GMT</pubDate>
    </item>
    <item>
      <title>在 python 中使用 Elastic Net 运行回归不断得到 NAN</title>
      <link>https://stackoverflow.com/questions/77894355/running-a-regression-using-elastic-net-in-python-keep-getting-nan</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77894355/running-a-regression-using-elastic-net-in-python-keep-getting-nan</guid>
      <pubDate>Sun, 28 Jan 2024 10:03:08 GMT</pubDate>
    </item>
    <item>
      <title>如何在 google colab 中使用更多 GPU RAM？</title>
      <link>https://stackoverflow.com/questions/77893929/how-do-i-use-more-of-the-gpu-ram-in-google-colab</link>
      <description><![CDATA[我正在 pytorch 中从事这个深度学习项目，其中我有 2 个完全连接的神经网络，我需要训练然后测试它们。但是当我在 google colab 中运行代码时，它并不比在我的 PC 上的 CPU 上运行快多少。顺便说一句，我有 colab pro。它还使用 A100 GPU 40GB GPU RAM 中的 0.6 个。
导入火炬
导入火炬视觉
导入 torchvision.transforms 作为变换
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim


设备 = torch.device(“cuda:0”)
# 定义变换
变换 = 变换.Compose([
    变换.ToTensor(),
    变换.Normalize((0.5,),(0.5,))
]）

# 加载 FashionMNIST 数据集
trainset = torchvision.datasets.FashionMNIST（&#39;./data&#39;，download=True，train=True，transform=transform）
测试集 = torchvision.datasets.FashionMNIST(&#39;./data&#39;, download=True, train=False, transform=transform)

# 创建数据加载器
trainloader = torch.utils.data.DataLoader(trainset,batch_size=1,shuffle=True,num_workers=2)
testloader = torch.utils.data.DataLoader(testset,batch_size=1,shuffle=False,num_workers=2)

# 为类定义常量
类 = (&#39;T 恤/上衣&#39;, &#39;裤子&#39;, &#39;套头衫&#39;, &#39;连衣裙&#39;, &#39;外套&#39;,
           “凉鞋”、“衬衫”、“运动鞋”、“包”、“踝靴”）




# 定义全连接神经网络
FCNN 类（nn.Module）：
    def __init__(自身, num_layers=1):
        超级（FCNN，自我）.__init__()
        self.num_layers = num_layers
        self.fc_layers = nn.ModuleList()
        如果 self.num_layers == 1:
            self.fc_layers.append(nn.Linear(28 * 28, 1024))
        elif self.num_layers == 2：
            self.fc_layers.append(nn.Linear(28 * 28, 1024))
            self.fc_layers.append(nn.Linear(1024, 1024))
        self.output_layer = nn.Linear(1024, 10)

    def 前向（自身，x）：
        x = x.view(-1, 28 * 28)
        对于 self.fc_layers 中的层：
            x = nn.function.relu(层(x))
        x = self.output_layer(x)
        返回x

# 修改train函数以将输入和标签移动到GPU
def train(网络, 标准, 优化器, epochs=15):
    对于范围内的纪元（纪元）：
        运行损失 = 0.0
        对于 i，enumerate(trainloader, 0) 中的数据：
            输入，标签=数据[0].to（设备），数据[1].to（设备）
            优化器.zero_grad()

            输出 = 净值（输入）
            损失=标准（输出，标签）
            loss.backward()
            优化器.step()

            running_loss += loss.item()
            如果我% 2000 == 1999：
                print(&#39;[%d, %5d] 损失: %.2f&#39; %
                      (epoch + 1, i + 1, running_loss / 2000))
                运行损失 = 0.0

# 定义函数来测试准确性
定义测试（净）：
    正确 = 0
    总计 = 0
    使用 torch.no_grad()：
        对于测试加载器中的数据：
            图像、标签=数据
            输出=净（图像）
            _, 预测 = torch.max(outputs.data, 1)
            总计 += labels.size(0)
            正确+=（预测==标签）.sum().item()

    print(&#39;准确率：%d %%&#39; % (
            100 * 正确/总计))

＃ 主功能
如果 __name__ == “__main__”：
    # 定义网络
    net1 = FCNN(num_layers=1)
    net2 = FCNN(num_layers=2)
    net2.to（设备）

    # 定义损失函数和优化器
    标准 = nn.CrossEntropyLoss()
    优化器1 = optim.SGD(net1.parameters(), lr=0.001, 动量=0.0)
    optimer2 = optim.SGD(net2.parameters(), lr=0.001, 动量=0.0)

    # 使用 1 个 FC 层训练和测试网络
    #print(“训练网络1层...”)
    #train(net1, 标准, 优化器1)
    #测试（网络1）

    # 使用 2 个 FC 层训练和测试网络
    print(&quot;2层训练网络...&quot;)
    训练（net2、标准、优化器2）
    测试（网络2）

尝试在google colab中使用不同的GPU
尝试添加此行以始终使用 CUDA 核心：
设备 = torch.device(“cuda:0”),

并让网络使用该设备：
 设备 = torch.device(“cuda:0”)
]]></description>
      <guid>https://stackoverflow.com/questions/77893929/how-do-i-use-more-of-the-gpu-ram-in-google-colab</guid>
      <pubDate>Sun, 28 Jan 2024 07:11:15 GMT</pubDate>
    </item>
    <item>
      <title>运行由 resipy 库组成的代码时出现错误 - from resipy import R2</title>
      <link>https://stackoverflow.com/questions/77893785/getting-error-while-running-the-code-which-consists-of-resipy-library-from-res</link>
      <description><![CDATA[无法导入 meshCalc 扩展，请参阅以下错误：
无法从“resipy.cext”（未知位置）导入名称“meshCalc”
-------------------------------------------------- ------------------------
ImportError Traceback（最近一次调用最后一次）
文件〜\ AppData \ Local \ Programs \ Python \ Python312 \ Lib \ site-packages \ resipy \ meshTools.py：38
     37 尝试：
---&gt; 38 从 resipy.cext 导入 meshCalc 作为 mc
     39 除了异常 e：

ImportError：无法从“resipy.cext”（未知位置）导入名称“meshCalc”

在处理上述异常的过程中，又出现了一个异常：

异常回溯（最近一次调用最后一次）
[2] 中的单元格，第 9 行
      7 导入操作系统
      8 导入时间
----&gt; 9 从 resipy 导入 R2
     11 模型运行次数 = 1
     12 tic = 时间.time()

文件〜\ AppData \ Local \ Programs \ Python \ Python312 \ Lib \ site-packages \ resipy \ __ init __.py：2
      1 名称 =“resipy”
----&gt; 2 从resipy.Project导入ResIPy_version、sysinfo
      3.从resipy.Project导入项目，R2
      4.从resipy.Surve导入Survey

文件〜\ AppData \ Local \ Programs \ Python \ Python312 \ Lib \ site-packages \ resipy \ Project.py：40
     38 从 resipy.parsers 导入 geomParser
     39 从 resipy.r2in 导入 write2in
---&gt; 40 导入 resipy.meshTools 作为 mt
     41 从resipy.meshTools导入cropSurface
     42 从 resipy.template 导入 startAnmt、endAnmt

文件〜\ AppData \ Local \ Programs \ Python \ Python312 \ Lib \ site-packages \ resipy \ meshTools.py：42
     40 print(&#39;无法导入 meshCalc 扩展，请参阅以下错误：&#39;)
     41 print(e)# 需要编译meshCalc
---&gt; 42 raise Exception(&#39;无法导入 meshCalc 扩展来修复问题尝试，&#39;\
     43&#39;更新 ResIPy、更新 Numpy 或重新编译扩展。&#39;)
     45 # 导入 pyvista（如果可用）
     46 尝试：

异常：无法导入 meshCalc 扩展来解决问题，请尝试更新 ResIPy、更新 Numpy 或重新编译扩展。

我收到此错误。

我正在尝试运行由 (from resipy import R2) 行组成的代码。我正在尝试执行，但以下软件包出现错误。
任何帮助将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/77893785/getting-error-while-running-the-code-which-consists-of-resipy-library-from-res</guid>
      <pubDate>Sun, 28 Jan 2024 06:02:30 GMT</pubDate>
    </item>
    <item>
      <title>编写代码或寻找算法来找到最佳配置</title>
      <link>https://stackoverflow.com/questions/77893756/writing-code-or-finding-a-algorithm-to-find-a-optimal-configuration</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77893756/writing-code-or-finding-a-algorithm-to-find-a-optimal-configuration</guid>
      <pubDate>Sun, 28 Jan 2024 05:41:40 GMT</pubDate>
    </item>
    <item>
      <title>CNN 图像分类奇怪的 Sigmoid 预测问题</title>
      <link>https://stackoverflow.com/questions/77893518/cnn-image-classification-weird-sigmoid-predictions-issue</link>
      <description><![CDATA[我正在使用 Tensorflow 开发机器学习神经网络模型，该模型可以识别一个人是否戴着口罩或未给出图像。请在进入 github 链接之前阅读其余部分（其中包含整个笔记本，以防模型本身出现问题）：文字
我的问题是，模型训练完成后（准确度为 96%，损失为 15%），预测输出一个奇怪的 sigmoid 值，远低于阈值 0.5，并且在使用图像的测试图像之间无关紧要戴口罩的人和不戴口罩的人。
如果这有帮助，这是使用 Tensorflow 函数的神经网络模型：
模型=顺序（[
    Conv2D(16, (3,3), 1, 激活=&#39;relu&#39;, input_shape = (256,256,3)),
    最大池化2D(),
    辍学率（0.25），

    Conv2D(32, (3,3), 1, 激活=&#39;relu&#39;),
    最大池化2D(),
    辍学率（0.25），

    Conv2D(16, (3,3), 1, 激活=&#39;relu&#39;),
    最大池化2D(),
    辍学率（0.25），

    展平（），

    密集（256，激活=&#39;relu&#39;），
    辍学（0.5），

    密集（1，激活=&#39;sigmoid&#39;）
]）

另外注：我对此很陌生，所以如果我需要修复一些更复杂的问题，请更深入地解释一下。
到目前为止我做了什么：
我首先认为这是过度拟合（仍然可能是），其中我的第一直觉是降低学习率。在这次修复之前，预测的 sigmoid 值在负数中使用了科学计数法，但后来他们冷静下来，恢复了不使用科学计数法。在其他人帮助我一点之后，我还添加了 Dropout 层，这也让 sigmoid 值平静了一点。然而，它们仍然不是正确的预测，并且它们小于 0.1，这不是 sigmoid 函数所期望的。
简而言之：
如果我能得到这方面的帮助，并能从这些帮助中学习，那就太好了。我希望我提供了必要的信息，但如果需要更多信息，请告诉我。
另外，如果可能的话，请下载存储库并亲自尝试预测。]]></description>
      <guid>https://stackoverflow.com/questions/77893518/cnn-image-classification-weird-sigmoid-predictions-issue</guid>
      <pubDate>Sun, 28 Jan 2024 02:58:25 GMT</pubDate>
    </item>
    <item>
      <title>yolov8 在训练后不会启动冻结：扫描</title>
      <link>https://stackoverflow.com/questions/77893385/yolov8-doesn%c2%b4t-initiate-freezes-after-train-scanning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77893385/yolov8-doesn%c2%b4t-initiate-freezes-after-train-scanning</guid>
      <pubDate>Sun, 28 Jan 2024 01:33:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 Roberta 计算上下文嵌入的正确方法是什么？</title>
      <link>https://stackoverflow.com/questions/77893035/what-is-the-correct-method-to-calculate-contextualized-embeddings-using-roberta</link>
      <description><![CDATA[我正在尝试使用 RobertaModel 计算上下文嵌入。不过，我不确定正确的做法，我尝试了两种方法，第一种方法如下：
从 Transformers 导入 RobertaModel、RobertaTokenizer
进口火炬

模型 = RobertaModel.from_pretrained(&#39;roberta-base&#39;)
tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;)

Captions = [“示例标题”,“七彩鸟”]

tokenized_captions = tokenizer(标题, return_tensors=&#39;pt&#39;, padding=True)

input_ids = tokenized_captions[&#39;input_ids&#39;]
注意掩码 = tokenized_captions[&#39;注意掩码&#39;]

输出=模型（input_ids，attention_mask）
contextualized_embedding = output.last_hidden_​​state

打印（上下文化嵌入）

第一种方法的输出：
张量([[[-0.0524, 0.0920, -0.0036, ..., -0.0810, -0.0577, -0.0343],
         [ 0.0383, -0.1632, 0.1182, ..., -0.3812, -0.1962, -0.0302],
         [-0.0504, 0.0927, -0.0312, ..., -0.1355, -0.0663, -0.0727],
         ...,
         [-0.0478, -0.1817, 0.1025, ..., -0.1187, -0.1293, -0.0288],
         [-0.0478, -0.1817, 0.1025, ..., -0.1187, -0.1293, -0.0288],
         [-0.0478, -0.1817, 0.1025, ..., -0.1187, -0.1293, -0.0288]],

输出包括填充标记的非零权重。对于第二种方法，代码本质上是相同的，区别在于 output 和 contextualized_embedding 行：
输出 = 模型(input_ids)
contextualized_embedding = output.last_hidden_​​state * Attention_mask.unsqueeze(-1).float()

第二种方法的输出：
张量([[[-0.0502, 0.0605, -0.0332, ..., -0.1521, -0.0830, -0.0196],
         [0.0178，-0.2104，0.1093，...，-0.5506，-0.2059，-0.0825]，
         [-0.0484, 0.0579, -0.0615, ..., -0.2082, -0.0855, -0.0473],
         ...,
         [ 0.0000, -0.0000, -0.0000, ..., -0.0000, -0.0000, 0.0000],
         [ 0.0000, -0.0000, -0.0000, ..., -0.0000, -0.0000, 0.0000],
         [ 0.0000, -0.0000, -0.0000, ..., -0.0000, -0.0000, 0.0000]],

在这种情况下，输出显示填充标记为零，我不确定正确的方法，任何人都可以帮我澄清这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/77893035/what-is-the-correct-method-to-calculate-contextualized-embeddings-using-roberta</guid>
      <pubDate>Sat, 27 Jan 2024 22:27:37 GMT</pubDate>
    </item>
    <item>
      <title>我有我的自定义训练模型（best.pt），它检测人和车头灯两件事。现在我想要根据这些条件输出</title>
      <link>https://stackoverflow.com/questions/77891961/i-have-my-custom-trained-model-best-pt-it-detects-two-things-person-and-headl</link>
      <description><![CDATA[你能帮我一下吗......
我有我的自定义训练模型（best.pt），它检测人和车头灯两件事。现在我想要根据以下条件输出： 1. 如果模型仅检测到车头灯返回 0, 2. 如果模型仅检测到人返回 1, 3. 如果模型检测到车头灯和人都返回 0。
&lt;前&gt;&lt;代码&gt;导入cv2
从 ultralytics 导入 YOLO

video_path = &#39;数据/video1.mp4&#39;
video_out_path = &#39;输出.mp4&#39;

cap = cv2.VideoCapture(video_path)

# 检查视频文件是否打开成功
如果不是 cap.isOpened():
    print(“错误：无法打开视频文件。”)
    出口（）

ret, 框架 = cap.read()

# 检查第一帧是否读取成功
如果不转：
    print(“错误：无法读取视频的第一帧。”)
    出口（）

cap_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*&#39;MP4V&#39;), cap.get(cv2.CAP_PROP_FPS),
                          (int(cap.get(3)), int(cap.get(4)))) # 使用 cap.get(3) 和 cap.get(4) 获取宽度和高度

模型 = YOLO(“bestall5.pt”)

检测阈值 = 0.5
休息时：
    结果列表=模型（框架）

    检测到头灯=假
    检测到的人=假

    # 遍历结果列表
    对于 results_list 中的结果：
        # 检查当前结果是否具有必要的属性
        if hasattr(结果, &#39;xyxy&#39;):
            对于 results.xyxy 中的结果：
                x1, y1, x2, y2, 分数, class_id = result.tolist()
                x1, x2, y1, y2 = int(x1), int(x2), int(y1), int(y2)

                # 假设class_id是模型类列表中类的索引
                类名=模型.名称[类id]

                if class_name == “车头灯”且分数&gt;检测阈值：
                    检测到头灯=真
                elif class_name == &quot;人&quot;;且分数&gt;检测阈值：
                    检测到的人 = True

    # 根据指定条件输出
    如果检测到头灯和检测到人：
        输出=0
    elif headlight_Detected：
        输出=0
    elif person_Detected：
        输出=1
    别的：
        输出 = -1 # 未检测到人或前灯

    print(“输出：”, 输出)

    cap_out.write(帧)

    cv2.imshow(&#39;物体检测&#39;,frame)
    
    # 如果按下“q”键则中断循环
    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
        休息

    ret, 框架 = cap.read()

cap.release()
cap_out.release()
cv2.destroyAllWindows()

我尝试了这个，但只得到 -1 作为输出，但我的视频既有车头灯又有人物]]></description>
      <guid>https://stackoverflow.com/questions/77891961/i-have-my-custom-trained-model-best-pt-it-detects-two-things-person-and-headl</guid>
      <pubDate>Sat, 27 Jan 2024 16:40:44 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：编译神经网络进行情感分析时，模块“keras.src.backend”没有属性“floatx”</title>
      <link>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</link>
      <description><![CDATA[从tensorflow.keras.models导入顺序
从tensorflow.keras导入层

# 设置嵌入维度
嵌入尺寸 = 100

# 创建模型
模型=顺序（[
    层.Embedding(max_words, embedding_dim, input_length=max_length),
    层.LSTM(64),
    层.Dense(1, 激活=&#39;sigmoid&#39;)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

# 打印模型摘要
打印（模型.摘要（））

我尝试使用 Jupyter Notebook (.ipynb) 在 VSCode 中编译上述模型，但遇到以下错误：
AttributeError：模块“keras.src.backend”没有属性“floatx”
最初，我成功地编译了模型，但在拟合模型时导致 VScode 崩溃。重新加载 VSCode 后，我收到此错误。
为了解释上下文，我正在尝试构建一个非常基本的 NLP 模型，以根据情绪对亚马逊评论进行分类。我也在使用 Python 3.11 和 Tensorflow 版本 2.15
首先我尝试了以下方法：
导入keras.backend为K
K.set_floatx(&#39;float32&#39;)

但是我遇到了同样的错误。然后我尝试重置 VSCode 并再次运行笔记本，但仍然遇到相同的错误？]]></description>
      <guid>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</guid>
      <pubDate>Sat, 27 Jan 2024 04:41:13 GMT</pubDate>
    </item>
    <item>
      <title>安装斗争</title>
      <link>https://stackoverflow.com/questions/77889759/installation-struggle</link>
      <description><![CDATA[我们正在使用 Qiskit 工具包进行一个量子计算项目。但我们在导入或安装软件包和库时遇到了困难。在 Qiskit 中我们如何导入库和包？
澄清如何从外包安装库的疑问。]]></description>
      <guid>https://stackoverflow.com/questions/77889759/installation-struggle</guid>
      <pubDate>Sat, 27 Jan 2024 01:36:23 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“无法将类强制到data.frame？”</title>
      <link>https://stackoverflow.com/questions/58870663/how-to-solve-cannot-coerce-class-to-data-frame</link>
      <description><![CDATA[第 20 行出现问题：x3 &lt;- lm(Salary ~ ...

&lt;块引用&gt;
  as.data.frame.default(data) 中的错误：无法将类‘c(&quot;train&quot;, &quot;train.formula&quot;)’强制转换为 data.frame

如何解决？
附加（击球手）
击球手

库（插入符号）
设置.种子(123)
# 定义训练控制
设置.种子(123)
train.control &lt;- trainControl(method = &quot;cv&quot;, number = 10)
# 训练模型
x2 &lt;- 训练（工资〜.，数据= x，方法=“lm”，
               trControl = 训练.control)
# 总结结果
打印（x）
x3 &lt;- lm(工资 ~ poly(AtBat,3) + poly(Hits,3) + poly(Walks,3) + poly(CRuns,3) + poly(CWalks,3) + poly(PutOuts,3),数据 = x2)
摘要(x3)
MSE = 均值(x3$残差^2)
print(&quot;均方误差：&quot;)
打印（MSE）
]]></description>
      <guid>https://stackoverflow.com/questions/58870663/how-to-solve-cannot-coerce-class-to-data-frame</guid>
      <pubDate>Fri, 15 Nov 2019 05:09:08 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林时，scikit 中的“ValueError：max_features 必须位于 (0, n_features] ”</title>
      <link>https://stackoverflow.com/questions/42072721/valueerror-max-features-must-be-in-0-n-features-in-scikit-when-using-rand</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/42072721/valueerror-max-features-must-be-in-0-n-features-in-scikit-when-using-rand</guid>
      <pubDate>Mon, 06 Feb 2017 16:32:32 GMT</pubDate>
    </item>
    </channel>
</rss>