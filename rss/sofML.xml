<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 17 Dec 2023 03:13:52 GMT</lastBuildDate>
    <item>
      <title>keras.models.load_model("") 在 h5f.open() 上给出错误</title>
      <link>https://stackoverflow.com/questions/77673041/keras-models-load-model-gives-error-on-h5f-open</link>
      <description><![CDATA[当使用keras.models.load时，它会在h5f.open(name, flags, fapl=fapl)上抛出错误，并显示OSError: Unable to打开文件（未找到文件签名）。
DNN模型文件代码
随机导入
将 numpy 导入为 np
将张量流导入为 tf
从 keras.layers 导入密集、Dropout
从 keras.models 导入顺序
从 keras.regularizers 导入 l1, l2
从 keras.optimizers 导入 Adam

def set_seeds(种子 = 100):
    随机种子（种子）
    np.随机.种子（种子）
    tf.random.set_seed(种子)
    
def CW(df):
    c0, c1 = np.bincount(df[“dir”])
    w0 = (1/c0) * (len(df)) / 2
    w1 = (1/c1) * (len(df)) / 2
    返回 {0:w0, 1:w1}

优化器 = Adam(lr = 0.0001)

def create_model(hl = 2, hu = 100, dropout = False, 速率 = 0.3, 正则化 = False,
                 reg = l1(0.0005)，优化器 = 优化器，input_dim = 无）：
    如果不正则化：
        reg = 无
    模型=顺序（）
    model.add（密集（hu，input_dim = input_dim，activity_regularizer = reg，activation =“relu”））
    如果辍学：
        model.add(Dropout(速率, 种子 = 100))
    对于范围（hl）内的图层：
        model.add（密集（hu，激活=“relu”，activity_regularizer = reg））
        如果辍学：
            model.add(Dropout(速率, 种子 = 100))
    model.add(Dense(1, 激活 = “sigmoid”))
    model.compile（损失=“binary_crossentropy”，优化器=优化器，指标=[“准确性”]）
    返回模型


加载模型和参数
# 加载模型
导入keras
model = keras.models.load_model(“C:/Users/Hussein Ali/Desktop/d/DNNModel.py”)

错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
OSError Traceback（最近一次调用最后一次）
第 3 行 [1] 中的单元格
      1 # 加载模型
      2导入keras
----&gt; 3 模型 = keras.models.load_model(“C:/Users/Hussein Ali/Desktop/d/DNNModel.py”)

文件 C:\anaconda\lib\site-packages\keras\utils\traceback_utils.py:70，位于filter_traceback..error_handler(*args, **kwargs)
     67、filtered_tb = _process_traceback_frames（e.__traceback__）
     68 # 要获取完整的堆栈跟踪，请调用：
     69 # `tf.debugging.disable_traceback_filtering()`
---&gt; 70 从 None 引发 e.with_traceback(filtered_tb)
     71 最后：
     72 删除filtered_tb

文件 C:\anaconda\lib\site-packages\h5py\_hl\files.py:533，在 File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy 、fs_persist、fs_threshold、fs_page_size、page_buf_size、min_meta_keep、min_raw_keep、锁定、alignment_threshold、alignment_interval、**kwds）
    第525章
    526锁定，page_buf_size，min_meta_keep，min_raw_keep，
    [第 527 章]
    [第 528 章]
    第529章
    第530章
    [第 531 章]
    第532章
--&gt;第533章
    第535章
    第536章

文件 C:\anaconda\lib\site-packages\h5py\_hl\files.py:226，在 make_fid（名称、模式、userblock_size、fapl、fcpl、swmr）中
    224 如果 swmr 和 swmr_support:
    225 个标志 |= h5f.ACC_SWMR_READ
--&gt; 226 fid = h5f.open（名称，标志，fapl = fapl）
    227 elif 模式 == &#39;r+&#39;:
    [第 228 章]

文件 h5py\_objects.pyx:54，在 h5py._objects.with_phil.wrapper() 中

文件 h5py\_objects.pyx:55，在 h5py._objects.with_phil.wrapper() 中

文件 h5py\h5f.pyx:106，在 h5py.h5f.open() 中

OSError：无法打开文件（未找到文件签名）
]]></description>
      <guid>https://stackoverflow.com/questions/77673041/keras-models-load-model-gives-error-on-h5f-open</guid>
      <pubDate>Sun, 17 Dec 2023 01:20:24 GMT</pubDate>
    </item>
    <item>
      <title>无法微调 CLIP 模型</title>
      <link>https://stackoverflow.com/questions/77673015/fail-to-finetune-clip-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77673015/fail-to-finetune-clip-model</guid>
      <pubDate>Sun, 17 Dec 2023 01:01:53 GMT</pubDate>
    </item>
    <item>
      <title>你能帮我理解 logit 函数吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77672810/can-you-help-me-to-understand-the-logit-function</link>
      <description><![CDATA[你能帮我理解第二行吗？我不明白对数是如何在第二行消失的。我知道 exp=2.7 但我无法理解转换。请帮忙
在此处输入图片描述
logit 解释。无法理解。]]></description>
      <guid>https://stackoverflow.com/questions/77672810/can-you-help-me-to-understand-the-logit-function</guid>
      <pubDate>Sat, 16 Dec 2023 23:05:27 GMT</pubDate>
    </item>
    <item>
      <title>如何处理我的 RNAseq 数据以便应用机器学习方法进行基因选择？</title>
      <link>https://stackoverflow.com/questions/77672716/how-can-i-process-my-rnaseq-data-in-order-to-apply-machine-learning-methods-for</link>
      <description><![CDATA[我正在处理来自 RNAseq 的数据，其中包含约 3000 个基因的表达值，包括来自患病患者和对照患者的测量值。
我的目标是训练机器学习模型、套索和随机森林，以便选择哪些基因子集能够更好地进行疾病预测。我依赖于平衡的准确性和 P 值 [Acc &gt; NIR]以选择最佳模型。
有人知道可以让我提高性能的技术吗？
我应用了一系列数据处理来改进获得的结果，其中包括：

删除高度相关的预测变量。
消除方差接近于零的预测变量。
我使用 DESeq 和 edgeR 选择差异表达基因。

使用其中一种或多种后，我仍然没有得到好的结果，我一直在 RNAseq 生物信息学论文中寻找信息，但没有发现任何与我已经应用的内容有很大不同的内容。]]></description>
      <guid>https://stackoverflow.com/questions/77672716/how-can-i-process-my-rnaseq-data-in-order-to-apply-machine-learning-methods-for</guid>
      <pubDate>Sat, 16 Dec 2023 22:23:59 GMT</pubDate>
    </item>
    <item>
      <title>使用时间序列数据进行无监督学习？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77672511/unsupervised-learning-with-time-series-data</link>
      <description><![CDATA[我正在处理几个月内每日汇总的用户活动数据（用户不必每天进行活动）。我正在寻找一种将相似用户聚集在一起的方法，但我有点困惑如何将时间序列数据合并到无监督学习算法中。
我对此的想法是旋转数据，以便每月的每一天都有列。然而，我觉得这会导致“维度诅咒”。所以我想知道是否有更好的方法。]]></description>
      <guid>https://stackoverflow.com/questions/77672511/unsupervised-learning-with-time-series-data</guid>
      <pubDate>Sat, 16 Dec 2023 21:07:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么我使用随机森林回归器得到负 R2 分数？</title>
      <link>https://stackoverflow.com/questions/77672303/why-im-getting-a-negative-r2-score-with-random-forest-regressor</link>
      <description><![CDATA[我试图使用 Phyton 中的随机森林模型来预测 MOF 的一些变量（来自一篇科学论文），但 R2 的值为负值（与论文不同，论文为正值）。我实际上不知道问题是否出在我的数据集（涉及将数值分配给字符串）或我的代码中。原始数据集是文学数据集，我的版本是“Dados editados 3”
数据集链接：https://docs.google.com/spreadsheets/d/17r-hxcuuzEFdfsqcAdHe_9iIp1d51IvL/edit?usp=sharing&amp;ouid=111702212107777597741&amp;rtpof=true&amp;sd=true
我尝试多次检查代码，但我不知道我做错了什么，因为 RF 模型是一个非常强大的模型。此外，我还使用检测和删除异常值的函数删除数据集的所有 Nan 值。
代码：
导入 pandas 作为 pd

从 sklearn.model_selection 导入 train_test_split
从 sklearn.model_selection 导入 GridSearchCV
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.ensemble 导入 RandomForestRegressor
从sklearn导入预处理
从 sklearn 导入指标


将 numpy 导入为 np

将seaborn导入为sns

将 matplotlib.pyplot 导入为 plt

进口警告
warnings.filterwarnings(&#39;忽略&#39;)

从 google.colab 导入驱动器

驱动器.mount（&#39;/内容/驱动器&#39;，force_remount = True）

df = pd.read_excel(r&#39;/content/drive/My Drive/Projeto ML/Dados ML.xlsx&#39;,sheet_name =“Dados editados 3”)

打印（df.形状）

df = df.drop(columns = [&#39;酶负载&#39;, &#39;固定率&#39;, &#39;活性保留&#39;] )

df.replace(&#39;-&#39;, np.NaN, inplace = True)

df = df.dropna()

打印（df.形状）

#修改后的函数

def get_outliers(l):
    #如果保留 0.1 和 0.75，那么几乎不会过滤任何异常值
    #q1 是 0.25 分位数，q3 是 0.75 分位数
    q1 = l.分位数(0.25)
    q3 = l.分位数(0.75)
    iqr = q3-q1
    栅栏低 = q1 - 1.5 * iqr
    栅栏高 = q3 + 1.5 * iqr
    返回 [~(i&gt;=fenceLow 且 i&lt;=fenceHigh) for i in l]

离群值 = df.apply(get_outliers)

df = df[~离群值.apply(lambda x:any(x), axis=1)]


X = df.iloc[:, :-1]

Y = df.iloc[:,-1]

x_train，x_test，y_train，y_test = train_test_split（X，Y，test_size = 0.25，random_state = 42）


打印（X）

缩放器 = 预处理.MinMaxScaler(feature_range = (0.1, 0.9))

x_train = 缩放器.fit_transform(x_train)

x_test= 缩放器.fit_transform(x_test)

从 sklearn.model_selection 导入 KFold
从 sklearn.model_selection 导入 GridSearchCV
从 sklearn.model_selection 导入 cross_val_score
从 sklearn.metrics 导入 r2_score
从 matplotlib 导入 pyplot 作为 plt


rf = RandomForestRegressor()

rf.fit(x_train, y_train)

y_pred = rf.predict(x_test)


k_folds = KFold(n_splits = 6)

分数 = cross_val_score(rf, x_train, y_train, cv = k_folds, 评分 = “r2”)



print(&quot;简历分数：&quot;, 分数)
print(&quot;平均简历分数：&quot;, Scores.mean())
print(&quot;平均值中使用的 CV 分数数量：&quot;, len(scores))

在此处输入图像描述
有什么建议吗？！]]></description>
      <guid>https://stackoverflow.com/questions/77672303/why-im-getting-a-negative-r2-score-with-random-forest-regressor</guid>
      <pubDate>Sat, 16 Dec 2023 19:55:00 GMT</pubDate>
    </item>
    <item>
      <title>为什么pytorch损失达到最小值时不稳定，而keras损失保持稳定？</title>
      <link>https://stackoverflow.com/questions/77672172/why-is-pytorch-loss-unstabile-when-reaching-minimum-while-keras-loss-keeps-stab</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77672172/why-is-pytorch-loss-unstabile-when-reaching-minimum-while-keras-loss-keeps-stab</guid>
      <pubDate>Sat, 16 Dec 2023 19:12:16 GMT</pubDate>
    </item>
    <item>
      <title>我应该应用什么预处理来对雕刻文本执行 OCR？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77671624/what-preproccessing-should-i-apply-to-perform-an-ocr-on-an-engraved-text</link>
      <description><![CDATA[我正在尝试对下面有一些其他文本的雕刻数字执行 OCR（参见下图），我正在尝试读取数字并忽略黑色文本。

我尝试过 Google ML 套件文本识别，但它不起作用，我尝试过应用许多过滤器，例如灰度和颜色反转，但它也不起作用。我有一些关于使用 python 和 pytesseract 进行深度学习的线索，但我几乎可以肯定这也行不通。
我想知道，这里的方法是什么？我应该对图像应用任何特定的处理，还是这是一个机器学习问题？这还能解决吗？]]></description>
      <guid>https://stackoverflow.com/questions/77671624/what-preproccessing-should-i-apply-to-perform-an-ocr-on-an-engraved-text</guid>
      <pubDate>Sat, 16 Dec 2023 16:10:46 GMT</pubDate>
    </item>
    <item>
      <title>当我尝试从头开始构建神经网络时出现矩阵乘法错误</title>
      <link>https://stackoverflow.com/questions/77671165/matrix-multiplication-error-when-i-tried-to-build-the-neural-network-from-scratc</link>
      <description><![CDATA[当我了解神经网络的数学工作原理时，我尝试使用 Numpy 从头开始​​构建它。我尝试构建的神经网络结构是具有 3 个节点的 input_layer -&gt; hidden_​​layer_1 有 2 个节点 -&gt; hidden_​​layer_2 有 2 个节点 -&gt;具有 1 个节点的输出层。两个隐藏层都使用ReLu激活函数，输出层使用Sigmoid激活函数。代码如下：
将 numpy 导入为 np
将 pandas 导入为 pd

W1 = np.random.rand(2, 3) # 权重矩阵
W2 = np.random.rand(2, 2)
W3 = np.random.rand(1, 2)

B1 = np.random.rand(2, 1) # 偏差向量
B2 = np.random.rand(2, 1)
B3 = np.random.rand(1, 1)

ReLu = lambda x : np.maximum(x, 0)
S 型 = lambda x : 1/ (1+np.exp(-x))

defforward_prop（输入）：

    Z1 = W1@输入 + B1
    A1 = ReLu(Z1)
    
    Z2 = W2@A1 + B2
    A2 = ReLu(Z2)
    
    Z3 = W3@A2 + B3
    A3 = 乙状结肠(Z3)
        
    返回 Z1、A1、Z2、A2、Z3、A3

d_relu = lambda x : x&gt;0
d_sigmoid = lambda x : np.exp(-x) / (1+np.exp(-x))**2

def back_prop(Z1, A1, Z2, A2, Z3, A3, X, Y):
    
    #衍生品
    dC_dA3 = 2*A3 - 2*Y
    
    dA3_dZ3 = d_sigmoid(Z3)
    dZ3_dW3 = A2
    dZ3_dB3 = 1
    dZ3_dA2 = W3
    
    dA2_dZ2 = d_relu(Z2)
    dZ2_dW2 = A1
    dZ2_dB2 = 1
    dZ2_dA1 = W2
    
    dA1_dZ1 = d_relu(Z1)
    dZ1_dW1 = X
    dZ1_dB1 = 1
    
    dC_dW3 = dC_dA3 @ dA3_dZ3 @ dZ3_dW3.T
    dC_dB3 = dC_dA3 @ dA3_dZ3 * dZ3_dB3
    dC_dA2 = dC_dA3 @ dA3_dZ3 @ dZ3_dA2
    dC_dW2 = dC_dA2 @ dA2_dZ2 @ dZ2_dW2.T
    dC_dB2 = dC_dA2 @ dA2_dZ2 * dZ2_dB2
    dC_dA1 = dC_dA2 @ dA2_dZ2 @ dZ2_dA1 # 问题就在这里
    dC_dW1 = dC_dA1 @ dA1_dZ1 @ dZ1_dW1.T
    dC_dB1 = dC_dA1 @ dA1_dZ1 * dZ1_dB1
    
    返回 dC_dW1、dC_dB1、dC_dW2、dC_dB2、dC_dW3、dC_dB3

数据 = pd.read_csv(&#39;light_dark_font_training_set.csv&#39;)
x = data.iloc[:, :-1].values
y = data.iloc[:, -1].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3)

n = x_train.shape[0]
L = 0.05
历元 = 100_000

对于范围内的 i（纪元）：

    idx = np.random.choice(n, 1, 替换=False)
    x_sample = x_train[idx].transpose()
    y_样本 = y_train[idx]
    
    z1、a1、z2、a2、z3、a3 =forward_prop(x_sample)
    w1、b1、w2、b2、w3、b3 = back_prop(z1、a1、z2、a2、z3、a3、x_sample、y_sample)
    
    W1 -= 长*w1
    W2 -= 长*w2
    W3 -= 长*w3
    
    B1 -= L*b1
    B2 -= L*b2
    B3 -= L*b3
    
    如果 i%10000 == 0:
        打印（一）

当我尝试运行上述程序时，它显示以下值错误，这表明矩阵维度与矩阵乘法不匹配。起初我以为我在反向传播中的偏导数方面遇到了一些问题，但就我的知识而言，它对我来说看起来很好。
为什么会发生这种情况以及如何解决？
&lt;小时/&gt;
ValueError Traceback（最近一次调用最后一次）
 中的 ~\AppData\Local\Temp/ipykernel_11036/3060626554.py
      6
      7 z1, a1, z2, a2, z3, a3 =forward_prop(x_sample)
----&gt; 8 w1, b1, w2, b2, w3, b3 = back_prop(z1, a1, z2, a2, z3, a3, x_sample, y_sample)
      9
     10 W1 -= 长*w1

~\AppData\Local\Temp/ipykernel_11036/566612658.py in back_prop(Z1, A1, Z2, A2, Z3, A3, X, Y)
     22 dC_dW2 = dC_dA2 @ dA2_dZ2 @ dZ2_dW2.T
     23 dC_dB2 = dC_dA2 @ dA2_dZ2 * dZ2_dB2
---&gt; 24 dC_dA1 = dC_dA2 @dA2_dZ2 @dZ2_dA1#问题就在这里
     25 dC_dW1 = dC_dA1 @ dA1_dZ1 @ dZ1_dW1.T
     26 dC_dB1 = dC_dA1 @ dA1_dZ1 * dZ1_dB1

ValueError: matmul: 输入操作数 1 的核心维度 0 不匹配，gufunc 签名为 (n?,k),(k,m?)-&gt;(n?,m?)（大小 2 与 1 不同）
]]></description>
      <guid>https://stackoverflow.com/questions/77671165/matrix-multiplication-error-when-i-tried-to-build-the-neural-network-from-scratc</guid>
      <pubDate>Sat, 16 Dec 2023 13:56:10 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 如何处理输入？</title>
      <link>https://stackoverflow.com/questions/77669743/how-does-lstm-process-input</link>
      <description><![CDATA[我试图在脑海中想象 LSTM 层如何处理给定的输入。
根据我在 PyTorch 和 Keras 中的理解，LSTM 层需要输入 (batch_size, seq_length, input_size) 和 (samples, timesteps, features)分别在哪里：

batch_size = 样本 = 实例/序列的数量。
seq_length = timesteps = 每个实例/序列的时间步数。
input_size = features = 每个时间步长的特征数

我将举一个例子，说明我认为训练如何在 Pythonic 伪代码中发挥作用，我想知道我的理解是否正确。
sequences_states = []
对于批量序列：

    中间状态 = []

    # 相应序列的初始单元和隐藏状态。
    细胞状态 = (0, 0, 0, ..., 0)
    隐藏状态 = (0, 0, 0, ..., 0)

    对于顺序时间步：
        # 根据之前的状态和当前的时间步长计算当前状态。
        cell_state,hidden_​​state = lstm(cell_state,hidden_​​state,时间步长)

    # 存储序列的最终单元格和隐藏状态。
    equences_states.append((cell_state,hidden_​​state))
]]></description>
      <guid>https://stackoverflow.com/questions/77669743/how-does-lstm-process-input</guid>
      <pubDate>Sat, 16 Dec 2023 03:43:28 GMT</pubDate>
    </item>
    <item>
      <title>尽管进行了标准化和交叉验证，模型性能仍面临挑战：使用 Automobile.tn 数据进行的案例研究（1766 条条目）"</title>
      <link>https://stackoverflow.com/questions/77669285/challenges-in-model-performance-despite-standardization-and-cross-validation-a</link>
      <description><![CDATA[从 sklearn.model_selection 导入 cross_val_score
从 sklearn. Linear_model 导入 LinearRegression

# 创建线性回归模型的实例

线性模型 = 线性回归()

# 应用 5 倍交叉验证

cross_val_scores = cross_val_score(线性模型, 缩放数据, y, cv=5, 评分=&#39;neg_mean_squared_error&#39;)

# 分数通常为负数，因为 scikit-learn 为了方便起见颠倒了符号

# 将分数转换为正值

mse_scores = -cross_val_scores

# 显示结果

print(&quot;R_squared:&quot;,r_squared)
打印（“RMSE：”，rmse）

输出：
&lt;前&gt;&lt;代码&gt;R_squared：0.34315292365076344
均方根误差：50511.93582816874
]]></description>
      <guid>https://stackoverflow.com/questions/77669285/challenges-in-model-performance-despite-standardization-and-cross-validation-a</guid>
      <pubDate>Fri, 15 Dec 2023 23:34:17 GMT</pubDate>
    </item>
    <item>
      <title>哪些分类器可以在这个简单的数据集上实现零训练误差？</title>
      <link>https://stackoverflow.com/questions/77668739/which-classifiers-can-achieve-zero-training-error-on-this-simple-data-set</link>
      <description><![CDATA[数据集
i) 我知道为什么逻辑回归在这个数据集上不能实现 0 错误，因为它不能画一条直线来划分类。
其他人呢？
我曾尝试询问法学硕士，但得到的答复令人困惑。]]></description>
      <guid>https://stackoverflow.com/questions/77668739/which-classifiers-can-achieve-zero-training-error-on-this-simple-data-set</guid>
      <pubDate>Fri, 15 Dec 2023 20:44:10 GMT</pubDate>
    </item>
    <item>
      <title>如何将 Iris 数据集加载到数据框中？</title>
      <link>https://stackoverflow.com/questions/77667785/how-to-load-iris-dataset-into-a-data-frame</link>
      <description><![CDATA[我需要将 Iris 数据集加载到数据框中。查看并打印该数据集的信息。然后使用 .describe() 方法，检查数据的描述性统计。
我不太确定我所做的是否正确。
from sklearn.datasets import load_iris
将 pandas 导入为 pd

虹膜 = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
打印（df.info（））
打印（df.描述（））

]]></description>
      <guid>https://stackoverflow.com/questions/77667785/how-to-load-iris-dataset-into-a-data-frame</guid>
      <pubDate>Fri, 15 Dec 2023 17:07:15 GMT</pubDate>
    </item>
    <item>
      <title>如何为此模型创建 Sagemaker 端点？</title>
      <link>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-model</link>
      <description><![CDATA[我创建了一个 VectorDB (FAISS) 并将 PDF 输入到其中。然后我使用 AWS Bedrock 的 Langchain 包装器来调用它。我知道现在存在 Kowledge Base，但至少在 SageMaker 笔记本中，我有更多的控制权。该模型在 SageMaker Notebook 中完美运行，当我提出问题时，它会返回答案。
我想做的是创建一个小网页（并通过 HTTP/REST API），只需在文本字段中提交问题并在文本字段中接收答案。我猜如果链中某个地方没有 Lambda 函数，这很难做到，或者也许不是？
当我查看 Sagemaker 控制台的推理选项卡下时，没有模型或没有端点，或者没有&lt; /strong&gt; 端点配置（因为我没有从 Sagemaker 选择模型，所以我只是在 Python 笔记本中使用 langchain LLM 和 Bedrock，如下所示）。
&lt;前&gt;&lt;代码&gt;导入boto3
导入 json

bedrock = boto3.client(service_name=&quot;bedrock&quot;)
bedrock_runtime = boto3.client(service_name=“bedrock-runtime”)



从 langchain.llms.bedrock 导入 Bedrock
从 langchain.chains 导入 RetrievalQA
从 langchain.prompts 导入 PromptTemplate

嵌入 = BedrockEmbeddings(model_id=“amazon.titan-embed-text-v1”,
                               客户端=bedrock_runtime）

最终我将文档嵌入到 FAISS Vector 数据库中，我查询的就是这个数据库
db = FAISS.from_documents（文档，嵌入）


模型泰坦 = {
    “最大令牌计数”：512，
    “停止序列”：[]，
    “温度”：0.0，
    “顶部P”：0.5
}

# 亚马逊泰坦模型
llm = 基岩(
    model_id=&quot;amazon.titan-text-express-v1&quot;,
    客户端=bedrock_runtime，
    model_kwargs=model_titan,
）

然后定义一个提示......
提示 = 提示模板(
    template=prompt_template, input_variables=[“上下文”, “问题”]
）

并查询数据库：
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type=“东西”，
    检索器=db.as_retriever(
        search_type=“相似度”，
    ),
    return_source_documents=真，
    chain_type_kwargs={“提示”: 提示},
）



query =“未来的技术是什么样的？”

结果 = qa({“查询”: 查询})

print(f&#39;查询: {结果[“查询”]}\n&#39;)
print(f&#39;结果: {结果[“结果”]}\n&#39;)
print(f&#39;上下文文档：&#39;)
对于结果 [“source_documents”] 中的 srcdoc：
      打印（f&#39;{srcdoc}\n&#39;）

这恰好返回了我在 Sagemaker 中需要的内容，我只需要从外部查询数据库即可。
我不想让 lambda 函数每次都重建链。我考虑的是效率，我需要的只是在 lambda 函数中传递查询并返回结果。]]></description>
      <guid>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-model</guid>
      <pubDate>Thu, 14 Dec 2023 14:49:20 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-learn Ridge 分类器：提取类概率</title>
      <link>https://stackoverflow.com/questions/22538080/scikit-learn-ridge-classifier-extracting-class-probabilities</link>
      <description><![CDATA[我目前正在使用 sklearn 的 Ridge 分类器，并且希望将此分类器与 sklearn 和其他库中的分类器集成。为了做到这一点，理想的做法是提取给定输入属于类列表中每个类的概率。目前，我正在使用 model.decision_function(x) 的输出来压缩类，但这返回的是距超平面的距离，而不是直接的概率。
这些距离值从 -1 到 1 左右变化。
distances = dict(zip(clf.classes_, clf.decision_function(x)[0]))

如何将这些距离转换为一组更具体的概率（一系列总和为 1 的正值）？我正在寻找类似 clf.predict_proba() 的东西，它是为 sklearn 中的 SVC 实现的。]]></description>
      <guid>https://stackoverflow.com/questions/22538080/scikit-learn-ridge-classifier-extracting-class-probabilities</guid>
      <pubDate>Thu, 20 Mar 2014 15:43:10 GMT</pubDate>
    </item>
    </channel>
</rss>