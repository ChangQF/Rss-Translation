<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 08 Aug 2024 21:14:46 GMT</lastBuildDate>
    <item>
      <title>机器学习、逻辑回归数据泄露</title>
      <link>https://stackoverflow.com/questions/78850463/machine-learning-logistic-regression-data-leakage</link>
      <description><![CDATA[我的问题涉及使用 SKlearn 逻辑回归和训练测试分割数据集。
给定一个数据集（3500 行，27 个特征，带有 2 个标签 0,1）。我有 20 个已知标签，我将其与 200 个“已知”0 标签一起用作训练和测试集。然后我训练我的逻辑回归模型。运行测试集并检查一些指标。
现在我想在原始数据集上使用该模型。我可以将完整的原始数据集与模型一起使用吗？还是我需要删除我的训练集？我将有 3280 行，而不是原来的 3500 行。
有人告诉我，包含原始训练集会导致数据泄漏问题，因为模型已经看到了训练集？]]></description>
      <guid>https://stackoverflow.com/questions/78850463/machine-learning-logistic-regression-data-leakage</guid>
      <pubDate>Thu, 08 Aug 2024 21:11:55 GMT</pubDate>
    </item>
    <item>
      <title>有人可以指导我学习 Yolov10 的路线图吗？我正在为大学最后一年的项目学习它？[关闭]</title>
      <link>https://stackoverflow.com/questions/78850160/can-anyone-guide-me-the-roadmap-for-learning-yolov10-i-am-learning-it-for-final</link>
      <description><![CDATA[我是一名计算机科学专业的学生，​​目前是第7学期，精通Python。
我对深入研究深度学习的世界很感兴趣，特别是专注于使用YOLOv10进行对象检测。
但是，我对该领域常用的许多工具和框架仍然很陌生，例如TensorFlow、OpenCV和PyTorch。
鉴于YOLOv10是YOLO系列中的最新版本，并引入了几个高级功能，例如NMS无训练和提高效率，我有点不知所措，不知道从哪里开始。
我正在寻找一个可以指导我完成的全面路线图我需要先决条件、必要技能和学习资源才能有效地使用 YOLOv10。
我希望获得建议的一些特定领域包括：
我应该首先掌握的深度学习中的关键基础主题。学习 PyTorch 和 OpenCV 的资源或教程，因为我对它们还不熟悉。
如何理解对象检测概念，特别是在 YOLOv10 的背景下。
为训练和部署 YOLO 模型设置开发环境的最佳实践。
任何可以巩固我理解的推荐项目或练习。
我渴望听到任何在这个领域有经验或自己经历过学习过程的人的意见。任何可以帮助我打下坚实基础并继续使用 YOLOv10 的建议或资源都将非常有价值。]]></description>
      <guid>https://stackoverflow.com/questions/78850160/can-anyone-guide-me-the-roadmap-for-learning-yolov10-i-am-learning-it-for-final</guid>
      <pubDate>Thu, 08 Aug 2024 19:38:10 GMT</pubDate>
    </item>
    <item>
      <title>解决梯度流 Pytorch 问题的推荐步骤</title>
      <link>https://stackoverflow.com/questions/78849999/recommended-steps-to-troubleshoot-gradient-flow-pytorch</link>
      <description><![CDATA[我对 Pytorch 还比较陌生，想知道能否得到一些关于追踪梯度流问题的建议。初始反向传播显示整个 CG 的流动：

但是后续步骤没有显示任何梯度流：

我不想只是在这里贴上我的代码，让一些有心人尝试调试它。我只是在寻求普通 ML 工程师可以采取的任何建议，以尝试解决此类问题。此模型类似于Pointer Network的衍生物，我怀疑掩蔽策略可能会导致 CG 断开连接，但我想验证问题发生的位置。]]></description>
      <guid>https://stackoverflow.com/questions/78849999/recommended-steps-to-troubleshoot-gradient-flow-pytorch</guid>
      <pubDate>Thu, 08 Aug 2024 18:51:13 GMT</pubDate>
    </item>
    <item>
      <title>从 Excel 和 PDF/数据工程中提取值[关闭]</title>
      <link>https://stackoverflow.com/questions/78849785/extract-values-from-excel-and-pdf-data-engineering</link>
      <description><![CDATA[我在 Google Drive 上有许多包含 T12 报告的 Excel 和 PDF 文件，所有报告的结构都不同。不同的会计师对这些列的命名各不相同。我的任务是从这些文件中提取特定的总值，但变量位于不同的地方，并且具有不同的名称变体，例如“重建成本”、“翻新成本”、“翻新总额”等。
我最初构建了逻辑来查找关键字“Total”并将其与相关行匹配。但是，我遇到了许多错误，因为程序在某些文件中找到“Total”，这些文件的名称不同，例如“12 Trailing”。我不断收到新文件，这些文件具有相同值的更多名称变体。
是否可以使用机器学习或其他工具来帮助自动化此过程？我应该使用什么样的逻辑和方法来有效地解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78849785/extract-values-from-excel-and-pdf-data-engineering</guid>
      <pubDate>Thu, 08 Aug 2024 17:53:21 GMT</pubDate>
    </item>
    <item>
      <title>营销中的机器学习算法</title>
      <link>https://stackoverflow.com/questions/78849579/ml-algorithms-in-marketing</link>
      <description><![CDATA[下午好！
我从事营销分析工作，最近我接到一项任务，要将营销预算（假设为 100 万）分配到各个商品类别，从而实现收入最大化。
我熟悉机器学习的基本算法，但经验不足。
如果您能帮助我使用什么算法/提供一些想法，那就太好了？
提前谢谢您！
我有一个想法，先运行回归，但我真的不明白如何进行优化。]]></description>
      <guid>https://stackoverflow.com/questions/78849579/ml-algorithms-in-marketing</guid>
      <pubDate>Thu, 08 Aug 2024 16:49:51 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Sarimax 预测日期？</title>
      <link>https://stackoverflow.com/questions/78849480/how-to-project-forecast-dates-with-sarimax</link>
      <description><![CDATA[我正在使用 Sarimax 进行预测：
# 仅使用 VENDA 过滤数据集
df_int_aux = pd.DataFrame(df_internal[&#39;VENDA&#39;])

# 使用训练数据创建模型
train = round(len(df_int_aux) * 0.85) 
test = len(df_int_aux) - train

model_val = sm.tsa.statespace.SARIMAX(df_int_aux[&quot;VENDA&quot;][:train], order=(0,0,1), seasonal_order=(1, 1, 1, 4), exog=df_internal[&#39;C_EF_VENDA&#39;][:train])

# 拟合模型
model_val_fit = model_val.fit()

# 预测测试数据
validation = model_val_fit.get_forecast(steps=test, exog=df_internal[&#39;C_EF_VENDA&#39;][-test:]) 
validation_mean = validation.predicted_mean

但是，validation_mean 数据集未显示未来日期。它显示的数字索引范围从 101 到 118。数据集有 119 行。我使用前 100 行进行训练，因此第 101 行到第 118 行是模型的预测值。
为什么没有显示预计日期？我该如何解决这个问题？
以下是数据集的示例。可能是因为日期不遵循特定的频率或模式而未显示？
注意 1：数据集已被识别为时间序列。换句话说，日期列已转换为索引。
注释 2：数据集的频率为每周，每月有 4 个日期（4 周）。但是，选择日期的标准并不遵循特定的模式。
 VENDA C_EF_VENDA
DATA 
2022-01-01 6.004414 12.122044
2022-01-11 10.933905 22.073975
2022-01-18 11.589626 23.397781
2022-01-25 21.005069 42.406200
2022-02-01 8.639416 14.461015
2022-02-08 16.847755 28.200475
2022-02-15 17.289413 28.939740
2022-02-22 16.966222 28.398770
2022-03-01 13.172216 16.978590
2022-03-10 19.344759 24.934812
2022-03-18 20.427803 26.330823
2022-03-25 24.636553 31.755775
... ... ...

输出为：
Out[60]: 
101 16.622028
102 16.556887
103 22.744430
104 6.996741
105 11.892359
... ...
118 16.206446
名称：predicted_mean，dtype：float64

其中 101、102、... 应为日期。]]></description>
      <guid>https://stackoverflow.com/questions/78849480/how-to-project-forecast-dates-with-sarimax</guid>
      <pubDate>Thu, 08 Aug 2024 16:26:06 GMT</pubDate>
    </item>
    <item>
      <title>如何在 sklearn 管道中反转序数编码？</title>
      <link>https://stackoverflow.com/questions/78848893/how-can-i-reverse-ordinal-encoding-within-a-sklearn-pipeline</link>
      <description><![CDATA[我正在尝试清理一个数据集，该数据集包含来自不同特征（包括数字和分类）的大量缺失值。我的想法如下：

使用 OrdinalEncoder 只保留数值并将缺失值保留为 NaN（不能使用 OneHotEncoder，因为它会创建新的列，这些列为 NaN）
使用 KNNImputer 估算缺失值
反转编码，因为没有合理的理由在类别中绘制某种顺序

这是我到目前为止的代码：
import pandas as pd
import numpy as np
from sklearn import set_config
set_config(transform_output=&quot;pandas&quot;)
from sklearn.preprocessing import OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import KNNImputer
from sklearn.base import BaseEstimator, TransformerMixin

类 RoundingToIntegerTransformer(BaseEstimator, TransformerMixin):
def fit(self, X, y=None):
return self

def transform(self, X):
return np.round(X) 

类 ReverseOrdinalEncoder(BaseEstimator, TransformerMixin):
def __init__(self,coder_name, categorical_columns):
self.encoder_name =coder_name
self.categorical_columns = categorical_columns

def fit(self, X, y=None):
return self

def transform(self, X, y=None):
X_ = X.copy()
coder = self.encoder_name
X_categorical = X_[categorical_columns] 
X_categorical =coder.inverse_transform(X_categorical)
X_[categorical_columns] = X_categorical
return X_

data = pd.DataFrame({
&#39;类别 1&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;a&#39;, np.nan, &#39;c&#39;, &#39;b&#39;],
&#39;类别 2&#39;: [&#39;x&#39;, &#39;y&#39;, &#39;x&#39;, &#39;z&#39;, np.nan, &#39;y&#39;],
&#39;数值 1&#39;: [1.1, np.nan, 3.3, 4.4, 5.5, np.nan],
&#39;数值 2&#39;: [np.nan, 2.2, np.nan, 4.4, 5.5, 6.6]
})

numerical_columns = data.select_dtypes(include=&#39;number&#39;).columns.tolist()
categorical_columns = data.select_dtypes(include=&#39;object&#39;).columns.tolist()

ordinal_encoder = OrdinalEncoder(encoded_missing_value=np.nan)

first_encoder = ColumnTransformer(transformers=[
(&#39;ordinal_cat&#39;, ordinal_encoder, categorical_columns)
],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False)

imputer = Pipeline([
(&#39;KNN_imputing&#39;, KNNImputer()),
(&#39;rounding&#39;, ColumnTransformer(transformers=[(&#39;round_cat&#39;, RoundingToIntegerTransformer() , categorical_columns)],
remainder=&#39;passthrough&#39;,
verbose_feature_names_out=False))
])

reverse_encoder = ReverseOrdinalEncoder(
编码器名称=first_encoder.transformers[0][1], 
categorical_columns=categorical_columns
)

preprocessor = Pipeline([
(&#39;encoding&#39;, first_encoder),
(&#39;imputing&#39;, imputer),
(&#39;decoding&#39;, reverse_encoder)
])

我尝试了一段时间，但从未成功，我总是收到以下错误：

NotFittedError：此 OrdinalEncoder 实例尚未安装。使用此估算器之前，请使用适当的参数调用“fit”。

我理解这个错误，但我认为由于序数编码器在管道中出现得早，因此当它在反向编码器中使用时会安装好。有什么办法可以让它工作吗？
非常感谢]]></description>
      <guid>https://stackoverflow.com/questions/78848893/how-can-i-reverse-ordinal-encoding-within-a-sklearn-pipeline</guid>
      <pubDate>Thu, 08 Aug 2024 14:07:04 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：名称“model”在模型中使用了 2 次。所有层名称都应唯一</title>
      <link>https://stackoverflow.com/questions/78848605/valueerror-the-name-model-is-used-2-times-in-the-model-all-layer-names-shoul</link>
      <description><![CDATA[我尝试在联合学习管道中引入两个重新训练的客户端并计算其权重的平均值。第一次训练时成功了，但现在第二次出现此错误，我尝试修复，但无法找出问题所在。
以下错误源自行 main(model_FTM_path, model_Stanford_path, save_path)
ValueError：名称“model”在模型中使用了 2 次。所有层名称都应唯一。

# 将两个经过训练的客户端加权到一个文件中

import tensorflow as tf
from Client_Trainer import CustomLoss

# 停用 GPU
tf.config.set_visible_devices([], &#39;GPU&#39;)

# 自定义损失函数
loss_function = CustomLoss.MaskedMSE

def load_model(model_path, prefix):
model = tf.keras.models.load_model(model_path, custom_objects = {&#39;MaskedMSE&#39;: loss_function})

return model

def ensemble(model_FTM, model_Stanford):
# 创建输入层
input_shape = model_FTM.input.shape[1:]
ensemble_input = tf.keras.layers.Input(shape = input_shape, name = &#39;ensemble_input&#39;)

# 获取输出两个模型的
output_FTM = model_FTM(ensemble_input)
output_Stanford = model_Stanford(ensemble_input)

# 平均输出
averaged_output = tf.keras.layers.Average(name = &quot;ensemble_average&quot;)([output_FTM, output_Stanford])

# 创建集成模型
ensemble_model = tf.keras.models.Model(inputs = ensemble_input, output = averaged_output, name = &quot;ensemble_model&quot;)

return ensemble_model

def main(model_FTM_path, model_Stanford_path, save_path):
# 加载模型
model_FTM = load_model(model_FTM_path, &quot;FTM&quot;)
model_Stanford = load_model(model_Stanford_path, &quot;Stanford&quot;)

#构建集成模型
ensemble_model = ensemble(model_FTM, model_Stanford)

# 编译集成模型
ensemble_model.compile(optimizer = &#39;adam&#39;, loss = loss_function, metrics = [&#39;mse&#39;])

# print(&quot;\nEnsemble Model Summary:&quot;)
# ensemble_model.summary()

# 保存集成模型
ensemble_model.save(save_path)

if __name__ == &quot;__main__&quot;:
model_FTM_path = &#39;FTMRetrained_round2.h5&#39;
model_Stanford_path = &#39;StanfordRetrained_round2.h5&#39;
save_path = &#39;weighted_2clients_round2.h5&#39;

main(model_FTM_path, model_Stanford_path, save_path)
]]></description>
      <guid>https://stackoverflow.com/questions/78848605/valueerror-the-name-model-is-used-2-times-in-the-model-all-layer-names-shoul</guid>
      <pubDate>Thu, 08 Aug 2024 13:08:35 GMT</pubDate>
    </item>
    <item>
      <title>由于损失函数，我的模型无法训练</title>
      <link>https://stackoverflow.com/questions/78848428/my-model-would-not-train-because-of-the-loss-function</link>
      <description><![CDATA[--------------------------------------------------------------------------
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-37-9a9cd8046c6f&gt; in &lt;cell line: 18&gt;()
16 loss=tf.keras.losses.CategoricalCrossentropy(),
17 metrics=[&#39;accuracy&#39;])
---&gt; 18 history1=model1.fit(train_data,epochs=5,validation_data=valid_data)

1 frames
/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py in categorical_crossentropy(target, output, from_logits, axis)
552 )
553 if len(target.shape) != len(output.shape):
--&gt; 554 raise ValueError(
555 &quot;参数 `target` 和 `output` 必须具有相同的等级 &quot;
556 &quot;(ndim)。收到： &quot;

ValueError：参数 `target` 和 `output` 必须具有相同的等级 (ndim)。收到：target.shape=(None,)，output.shape=(None, 19)

所以，我不明白问题是什么？？
但是当我使用 SpareCategoricalCrossentropy 训练我的模型时，它工作正常，但准确率很差，在有效数据中为零。
我尝试使用 SpareCategorical，但准确率很低。看到我的数据集来自 kaggle，所以我只是下载了它并给了它一个图像大小
train_dir=&quot;Dataset/train/&quot; test_dir=&quot;Dataset/test/&quot; train_data= Images(train_dir,image_size=(150,150),batch_size=32) valid_data= Images(test_dir,image_size=(150,150),batch_size=32)
我回想起了这一点。现在有人能告诉我该怎么办吗？]]></description>
      <guid>https://stackoverflow.com/questions/78848428/my-model-would-not-train-because-of-the-loss-function</guid>
      <pubDate>Thu, 08 Aug 2024 12:29:54 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft Azure 自定义图像分析模型 - 错误识别产品</title>
      <link>https://stackoverflow.com/questions/78848095/microsoft-azure-custom-image-analysis-model-mistakenly-identifies-products</link>
      <description><![CDATA[我确实需要一些帮助和指导。
我正在为一个产品训练一个自定义图像分析模型。我遵循以下准则 - https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/model-customization?tabs=studio
https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/how-to/shelf-model-customization
不幸的是，在我训练了几个模型并对数据集进行了不同的配置后，我没有看到模型输出有任何改进。
一个数据集包括41 张图片和 19 张图片中的一张。我还用产品本身的图片训练了一个模型。我训练模型的预算是 1 小时，昨晚我训练模型的预算是 7 小时。
但是，当我将输出结果叠加在图像上时，我得到的结果完全相同 - 附上图片。该模型是在带有绿色箭头的产品上进行训练的，但它错误地将带有白色包装的货架产品识别为相同的产品。
]]></description>
      <guid>https://stackoverflow.com/questions/78848095/microsoft-azure-custom-image-analysis-model-mistakenly-identifies-products</guid>
      <pubDate>Thu, 08 Aug 2024 11:18:59 GMT</pubDate>
    </item>
    <item>
      <title>未找到与 torch==1.9.1 匹配的分布</title>
      <link>https://stackoverflow.com/questions/78846461/no-matching-distribution-found-for-torch-1-9-1</link>
      <description><![CDATA[尝试使用 google colab 安装 torchmeta，但它依赖于 torch&lt;1.10.0 and &gt;=1.4.0，每当我尝试安装 torch 1.9.0 或任何版本的 torch&lt;1.10.0 and &gt;=1.4.0 时，都会出现以下错误：

错误：找不到满足要求 torch==1.9.1 的版本（来自版本：1.11.0、1.12.0、1.12.1、1.13.0、1.13.1、2.0.0、2.0.1、2.1.0、2.1.1、2.1.2、2.2.0、2.2.1、2.2.2， 2.3.0、2.3.1、2.4.0)错误：未找到与 torch==1.9.1 匹配的发行版

如何解决此问题？
我正在使用 Google colab，Python 版本 3.10.12。
如果我遇到的问题无法解决，请告诉我使用 colab 安装 torchmeta 的其他方法。
我正在尝试安装 torch&lt;1.10.0 和 &gt;1.4.0，然后安装依赖于我提到的 torch 版本 torch&lt;1.10.0 和 &gt;1.4.0 的 torchmeta。]]></description>
      <guid>https://stackoverflow.com/questions/78846461/no-matching-distribution-found-for-torch-1-9-1</guid>
      <pubDate>Thu, 08 Aug 2024 03:54:54 GMT</pubDate>
    </item>
    <item>
      <title>应用 Pytorch 最小化函数时参数没有改变</title>
      <link>https://stackoverflow.com/questions/78843331/parameters-not-changing-while-applying-pytorch-minimization-fucntion</link>
      <description><![CDATA[获取数据的代码：
import pandas as pd
import torch

dataset = pd.read_csv(&#39;/kaggle/input/fish-bear/population_data.csv&#39;)
years = torch.tensor(dataset[&#39;year&#39;], dtype = torch.float64)
fish_pop = torch.tensor(dataset[&#39;fish_hundreds&#39;], dtype = torch.float64)
bears_pop = torch.tensor(dataset[&#39;bears_hundreds&#39;], dtype = torch.float64)
pop = torch.cat((fish_pop.reshape((51, 1)), bears_pop.reshape((51, 1))), 1)

常微分方程求解器
从 typing 导入 List、Callable、Sequence、NamedTuple、Union

class _Tableau(NamedTuple):

c: List[float]
b: List[float]
a: List[List[float]]

rk4_tableau = _Tableau(c=[0.0, 0.5, 0.5, 1.0],
b=[1 / 6., 1 / 3., 1 / 3., 1 / 6.],
a=[[0.0, 0.0, 0.0, 0.0], [0.5, 0.0, 0.0, 0.0],
[0.0, 0.5, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0]])

def explicit_rk(tableau: _Tableau, fcn: Callable[..., torch.Tensor],
y0: torch.Tensor, t: torch.Tensor,
params: Sequence[torch.Tensor]):
c = tableau.c
a = tableau.a
b = tableau.b
s = len(c)
nt = len(t)

# 设置结果列表
yt_lst: List[torch.Tensor] = []
yt_lst.append(y0)
y = yt_lst[-1]
for i in range(nt - 1):
t0 = t[i]
t1 = t[i + 1]
h = t1 - t0
ks: List[torch.Tensor] = []
ksum: Union[float, torch.Tensor] = 0.0
for j in range(s):
if j == 0:
k = fcn(y, t0, params)
else:
ak: Union[float, torch.Tensor] = 0.0
aj = a[j]
for m in range(j):
ak = aj[m] * ks[m] + ak
k = fcn(h * ak + y, t0 + c[j] * h, params)
ks.append(k)
ksum = ksum + b[j] * k
y = h * ksum + y
yt_lst.append(y)
yt = torch.stack(yt_lst, dim=0)
return yt

def rk4_ivp(fcn: Callable[..., torch.Tensor], y0: torch.Tensor, t: torch.Tensor,
params: Sequence[torch.Tensor], **kwargs):
return explicit_rk(rk4_tableau, fcn, y0, t, params)

最小化代码：
import torch

def lotka_volterra(y, t, params):
y1, y2 = y
a, b, c, d = params

return torch.tensor([a * y1 - b * y1 * y2, c * y2 * y1 - d * y2])

def loss_function(params):

y0 = torch.tensor([fish_pop[0], bears_pop[0]], dtype = torch.float64)

t = torch.linspace(years[0], years[-1], len(years), dtype = torch.float64)

output = rk4_ivp(lotka_volterra, y0, t, params)

loss = torch.sum((output - pop)**2)
loss.requires_grad = True
return loss

def minimal(loss_function, initial_parameters: torch.Tensor):
list_params = []
params = initial_parameters
params.requires_grad = True
optimizer = torch.optim.SGD([params], lr=0.5)

for i in range(5):
optimizer.zero_grad()
loss: torch.Tensor = loss_function(params)
loss.backward()
optimizer.step()
list_params.append(params.detach().clone())

return params, list_params

starting_point = torch.nn.Parameter(torch.tensor([1.1, .4, .1, .4], dtype = torch.float64))
minimized_pa​​rams, list_of_params =最小化（loss_function，starting_point）

loss_function（minimized_pa​​rams），minimized_pa​​rams

在迭代结束时，参数不会得到优化并按原样返回。
结果：
（tensor（118.6865，dtype=torch.float64，requires_grad=True），
参数包含：
tensor（[1.1000, 0.4000, 0.1000, 0.4000]，dtype=torch.float64，
require_grad=True））

Kaggle Notebook 链接：https://www.kaggle.com/code/rakshitsingh421/parameter-estimation/edit
我尝试更改 require_grad 属性，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78843331/parameters-not-changing-while-applying-pytorch-minimization-fucntion</guid>
      <pubDate>Wed, 07 Aug 2024 11:04:40 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 和 Opacus 用于差异隐私</title>
      <link>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</link>
      <description><![CDATA[在使用 Jupyter Notebook（可从此处获取）测试来自 TensorFlow 网站的示例代码时，我遇到了一个错误。您可以在此处找到我关于该错误的 SO 问题。
因此，我决定使用 PyTorch、Opacus 和 PySyft 为相同功能编写等效实现。然而，不幸的是，我又遇到了另一个错误。
下面是实现与 TensorFlow 网站中的示例代码相同功能的代码，但使用 PyTorch 和 Opacus 和 PySyft，以及错误消息。
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from opacus import PrivacyEngine

# 定义一个简单的模型
class SimpleCNN(nn.Module):
def __init__(self):
super(SimpleCNN, self).__init__()
self.conv1 = nn.Conv2d(1, 32, kernel_size=3)
self.fc1 = nn.Linear(32*26*26, 10)

def forward(self, x):
x = torch.relu(self.conv1(x))
x = x.view(-1, 32*26*26)
x = self.fc1(x)
return torch.log_softmax(x, dim=1)

# 数据加载器
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = datasets.MNIST(&#39;.&#39;, train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 初始化模型、优化器和损失函数
model = SimpleCNN()
optimizer = optim.SGD(model.parameters(), lr=0.01)
criterion = nn.NLLLoss()

# 初始化 PrivacyEngine
privacy_engine = PrivacyEngine(
model,
batch_size=64,
sample_size=len(train_loader.dataset),
epochs=1,
max_grad_norm=1.0,
)

privacy_engine.attach(optimizer)

# 训练循环
model.train()
for epoch in range(1):
for data, target in train_loader:
optimizer.zero_grad()
output = model(data)
loss = criterion(output, target)
loss.backward()
optimizer.step()

# 打印隐私统计数据
epsilon, best_alpha = optimizer.privacy_engine.get_privacy_spent(1e-5)
print(f&quot;Epsilon: {epsilon}, Delta: 1e-5&quot;)

错误：
-------------------------------------------------------------------------------
TypeError Traceback (最近一次调用最后一次)
Cell In[1]，第 32 行
29 criterion = nn.NLLLoss()
31 # 初始化 PrivacyEngine
---&gt; 32 privacy_engine = PrivacyEngine(
33 model,
34 batch_size=64,
35 sample_size=len(train_loader.dataset),
36 epochs=1,
37 max_grad_norm=1.0,
38 )
40 privacy_engine.attach(optimizer)
42 # 训练循环

TypeError: PrivacyEngine.__init__() 获得了意外的关键字参数“batch_size”
]]></description>
      <guid>https://stackoverflow.com/questions/78839246/pytorch-and-opacus-for-differential-privacy</guid>
      <pubDate>Tue, 06 Aug 2024 13:17:08 GMT</pubDate>
    </item>
    <item>
      <title>从我的讲话中识别出一个特定的单词</title>
      <link>https://stackoverflow.com/questions/78838735/recognizing-a-specific-word-from-my-speech</link>
      <description><![CDATA[我想实现一个功能，可以在某人说完后重复某个单词。例如：“说娃娃”。可以使用任何其他单词代替娃娃。关键是让助手准确重复娃娃这个词
我想用 vosk 模块实现这个功能。
我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/78838735/recognizing-a-specific-word-from-my-speech</guid>
      <pubDate>Tue, 06 Aug 2024 11:21:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 SKforecast 时出错：[Int64Index([48, ...],\n dtype='int64', name='date_time')] 均不在 [index] 中</title>
      <link>https://stackoverflow.com/questions/77013878/error-when-using-skforecast-none-of-int64index48-n-dtype-int64-na</link>
      <description><![CDATA[我有使用 groupby（基于日期和组）的数据集，结果如下 Dataframe:
| 日期 | 组 | 值 |
|:---- |:------:| -----:|
| 2022-01-01 | 12 | 25.2|
| 2022-01-01 | 15 | 36.54|
| 2022-02-01 | 12 | 55.3|
| 2022-02-01 | 15 | 69.2|

最后我有 177 行。
我的第一个问题是我无法应用 data.asfreq
data = data.asfreq(&#39;MS&#39;) 

我收到此错误：
ValueError：无法在具有重复标签的轴上重新索引

我的第二个问题是当我想应用 xgboost 时我使用了此代码：
data = data.set_index(&#39;date_time&#39;)
#data = data.asfreq(&#39;MS&#39;)
data = data.sort_index()

end_train = &#39;2023-05-01&#39;
end_validation = &#39;2023-06-01&#39;
data_train = data.loc[: end_train, :]
data_val = data.loc[end_train:end_validation, :]
data_test = data.loc[end_train:, :]

print(f&quot;日期训练：{data_train.index.min()} --- {data_train.index.max()} (n={len(data_train)})&quot;)
print(f&quot;日期验证：{data_val.index.min()} --- {data_val.index.max()} (n={len(data_val)})&quot;)
print(f&quot;日期测试：{data_test.index.min()} --- {data_test.index.max()} (n={len(data_test)})&quot;)

forecaster = ForecasterAutoreg(
regressor = XGBRegressor(random_state=123),
lags = 24
)

# 回归器超参数
param_grid = {
&#39;n_estimators&#39;: [100, 500],
&#39;max_depth&#39;: [3, 5, 10],
&#39;learning_rate&#39;: [0.01, 0.1]
}

# 用作预测器的滞后值
lags_grid = [48, 72]

results_grid = grid_search_forecaster(
Forecaster = Forecaster,
y = data.loc[:end_validation, &#39;value&#39;], # 训练和验证数据
param_grid = param_grid,
lags_grid = lags_grid,
steps = 36,
refit = False,
metric = &#39;mean_squared_error&#39;,
initial_train_size = len(data_train),
fixed_train_size = False,
return_best = True,
n_jobs = &#39;auto&#39;,
verbose = False
)

我收到此错误：
KeyError: &quot;None of [Int64Index([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,\n 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n 82, 83, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61、62、\n 63、64、65、66、67、68、69、70、71、72、73、74、75、76]、\n dtype=&#39;int64&#39;, name=&#39;date_time&#39;)] 在 [index]&quot;

我尝试更改 lags_grid，但出现了几乎相同的错误。
在此先感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77013878/error-when-using-skforecast-none-of-int64index48-n-dtype-int64-na</guid>
      <pubDate>Thu, 31 Aug 2023 07:59:30 GMT</pubDate>
    </item>
    </channel>
</rss>