<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 12 Dec 2023 12:26:32 GMT</lastBuildDate>
    <item>
      <title>我的训练功能仅几步之后就意外结束</title>
      <link>https://stackoverflow.com/questions/77646034/my-training-function-ends-unexpectedly-after-only-a-few-steps</link>
      <description><![CDATA[我正在尝试运行 Pix2Pix，但是我的训练功能在前 1k 步中突然停止，没有错误。我使用 PyTorch 来创建鉴别器和生成器。下面是包含 2 个负责训练的函数的代码，一个用于训练每个步骤，一个用于拟合模型。
训练步骤函数：
def train_step(input_image, 目标, 步骤):
    生成器.train()
    判别器.train()

    # 前向传递
    gen_output = 生成器（输入图像）

    Disc_real_output = 鉴别器（输入图像，目标）
    Disc_ generated_output = 鉴别器（input_image，gen_output）

    # 计算损失
    gen_total_loss, gen_gan_loss, gen_l1_loss = 生成器_loss(disc_generate_output,
        生成输出，目标）
    光盘损失 = 判别器损失（光盘真实输出，光盘生成输出）

    # 向后传递
    Generator_optimizer.zero_grad()
    discriminator_optimizer.zero_grad()

    gen_total_loss.backward(retain_graph=True)
    discriminator_optimizer.zero_grad() # 清除生成器梯度
        判别器后向传递
    Disc_loss.backward()

    # 更新权重
    生成器优化器.step()
    discriminator_optimizer.step()

    # 日志记录
    使用 torch.no_grad()：
        writer.add_scalar(&#39;gen_total_loss&#39;, gen_total_loss.item(), global_step=step // 1000)
        writer.add_scalar(&#39;gen_gan_loss&#39;, gen_gan_loss.item(), global_step=step // 1000)
        writer.add_scalar(&#39;gen_l1_loss&#39;, gen_l1_loss.item(), global_step=step // 1000)
        writer.add_scalar(&#39;disc_loss&#39;,disc_loss.item(),global_step=step // 1000)

拟合函数：
def fit(train_loader, test_loader, 步骤):
   example_target, example_input = next(iter(test_loader))
   开始 = 时间.time()

   对于枚举（train_loader）中的步骤（目标，input_image）：
    如果（步骤）% 1000 == 0：
        显示.clear_output(等待=True)

        如果步骤！= 0：
            print(f&#39;1000 步所用时间: {time.time()-start:.2f} 秒\n&#39;)

        开始 = 时间.time()

        生成图像（生成器，示例_输入，示例_目标）
        print(f&quot;步长: {step//1000}k&quot;)

    train_step（输入图像，目标，步骤）

    # 训练步骤
    如果（步长+1）% 10 == 0：
        打印（&#39;。&#39;，结束=&#39;&#39;，刷新= True）

    # 每 5k 步保存（检查点）模型
    如果（步长 + 1）% 5000 == 0：
        火炬.保存（{
            &#39;generator_state_dict&#39;：generator.state_dict(),
            &#39;discriminator_state_dict&#39;: discriminator.state_dict(),
            &#39;generator_optimizer_state_dict&#39;：generator_optimizer.state_dict(),
            &#39;discriminator_optimizer_state_dict&#39;: discriminator_optimizer.state_dict(),
        }, f&#39;检查点_{step + 1}.pt&#39;)

我刚开始使用 GAN，我不确定这里的问题是什么。抱歉，帖子很乱。]]></description>
      <guid>https://stackoverflow.com/questions/77646034/my-training-function-ends-unexpectedly-after-only-a-few-steps</guid>
      <pubDate>Tue, 12 Dec 2023 12:15:15 GMT</pubDate>
    </item>
    <item>
      <title>寻找用于构建领域推荐系统的数据集[关闭]</title>
      <link>https://stackoverflow.com/questions/77645042/seeking-datasets-for-building-a-domain-recommendation-system</link>
      <description><![CDATA[我正在开发一个域推荐系统的项目。为此，我需要包含有关为各种网站提供域服务的公司的详细信息的数据集。具体来说，我正在寻找的数据包括：

公司名称和简介
提供的域名服务类型
域名注册的历史数据
定价和计划选项

在此处发帖之前，我进行了初步研究，但尚未找到满足这些特定要求的数据集。如果有人能向我指出可能提供此类信息的公共数据集或存储库，我将不胜感激。另外，有关如何收集此类数据的建议也会非常有帮助。
请注意，我并不是在寻找专有或机密信息，而是在寻找公开数据或有关如何以道德和合法方式汇总这些数据的建议。]]></description>
      <guid>https://stackoverflow.com/questions/77645042/seeking-datasets-for-building-a-domain-recommendation-system</guid>
      <pubDate>Tue, 12 Dec 2023 09:42:31 GMT</pubDate>
    </item>
    <item>
      <title>如何解决运行时错误尝试在pytorch中的backward()函数中再次向后浏览图形</title>
      <link>https://stackoverflow.com/questions/77644164/how-to-solve-runtimeerror-trying-to-backward-through-the-graph-a-second-time-in</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77644164/how-to-solve-runtimeerror-trying-to-backward-through-the-graph-a-second-time-in</guid>
      <pubDate>Tue, 12 Dec 2023 06:52:02 GMT</pubDate>
    </item>
    <item>
      <title>EconML 和 SHAP</title>
      <link>https://stackoverflow.com/questions/77644092/econml-and-shap</link>
      <description><![CDATA[我们可以使用形状值工具（TreeExplainer）来帮助我们评估EconML中的因果森林并进行一些可视化吗？我正在阅读EconML的cookbook，似乎SHAP在因果推理中可能有用，但我正在尝试在我的程序中应用因果森林！
也许我希望有人能教我如何使用这两个工具！]]></description>
      <guid>https://stackoverflow.com/questions/77644092/econml-and-shap</guid>
      <pubDate>Tue, 12 Dec 2023 06:33:54 GMT</pubDate>
    </item>
    <item>
      <title>用于检测源代码中语法问题的 ML 模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/77644081/ml-model-for-detecting-syntax-issues-in-source-code</link>
      <description><![CDATA[我编写了一个使用正则表达式来识别源代码中的语法错误的工具，该工具还提供了纠正问题的原因和建议。
同样，我需要训练一个机器学习模型，以便处理每个极端情况并将其推广。
需要建议来实现这一目标。（是否使用监督方法或现在哪种方法更好）
示例：避免在 src 代码中使用特定变量、以正确的推荐格式为变量赋值等。]]></description>
      <guid>https://stackoverflow.com/questions/77644081/ml-model-for-detecting-syntax-issues-in-source-code</guid>
      <pubDate>Tue, 12 Dec 2023 06:29:43 GMT</pubDate>
    </item>
    <item>
      <title>VS Code .ipynb 中的 FileUpload 小部件问题：显示“Upload(6)”，但数据长度返回 0</title>
      <link>https://stackoverflow.com/questions/77643801/fileupload-widget-issue-in-vs-code-ipynb-upload6-displayed-but-data-lengt</link>
      <description><![CDATA[我试图使用 widget.FileUpload() 上传文件并打印图像。但上传 6 个图像并尝试在新单元格中运行最后一行后，它返回错误，显示“IndexError：列表索引超出范围”
btn_upload = widgets.FileUpload()
btn_上传


img = PILImage.create(btn_upload.data[-1])

然后我尝试了这条线
print(&quot;上传文件数：&quot;, len(btn_upload.data))
期待“6”因为这是我上传的文件数，所以它返回了 0。]]></description>
      <guid>https://stackoverflow.com/questions/77643801/fileupload-widget-issue-in-vs-code-ipynb-upload6-displayed-but-data-lengt</guid>
      <pubDate>Tue, 12 Dec 2023 05:06:16 GMT</pubDate>
    </item>
    <item>
      <title>如何利用 GPU 减少 xgboost 的处理时间？</title>
      <link>https://stackoverflow.com/questions/77643788/how-can-i-reduce-processing-time-with-xgboost-by-utilizing-my-gpu</link>
      <description><![CDATA[我正在关注数据营的本教程，他们有一件事提到的是利用 GPU 来加快处理时间。他们甚至说它“速度极快”。
然而，我看到了相反的结果。对于下面的代码块，在 10k 提升的情况下，我看到在我的 params 中传递 “hist” 大约需要 30 秒，而在 ” 中传递则只需一分多钟。 gpu_hist&quot; 与我的 params 一起传递。
使用 “gpu_hist” 时，我的 GPU 的使用率上限为 12%，使用 “hist” 时，所有 24 个逻辑核心的使用率上限为 100%
params = {“objective”: “reg:squarederror”, “tree_method”: “gpu_hist”, “subsample”: 0.8,
    “colsample_bytree”：0.8}

evals = [(dtrain_reg, “训练”),(dtest_reg, “验证”)]

n = 10000


模型 = xgb.train(
   参数=参数，
   dtrain=dtrain_reg,
   num_boost_round=n,
   评估=评估，
   详细评估=50，
）

我正在尝试在 jupyter 笔记本的 VSCode 中运行它。

我已安装 CUDA 工具包和 cuDNN
我已检查它们是否已添加到路径中
我已确保安装了正确版本的 xgboost 来使用 GPU。
数据集有 53k 行 10 列，所以我不认为数据集太小
我已确认兼容性（使用 RTX 2060）

我问过 chatGPT，在网上搜索过，甚至问过我正在学习的课程中的导师，但无法诊断为什么“gpu_hist”花费了这么长时间。 vs 只是“历史”。
4 个月前，Stack Overflow 上还有另一个类似问题其响应为零。]]></description>
      <guid>https://stackoverflow.com/questions/77643788/how-can-i-reduce-processing-time-with-xgboost-by-utilizing-my-gpu</guid>
      <pubDate>Tue, 12 Dec 2023 05:02:17 GMT</pubDate>
    </item>
    <item>
      <title>在 Java 中包含 Python 分类器模型</title>
      <link>https://stackoverflow.com/questions/77643780/include-python-classifier-model-in-java</link>
      <description><![CDATA[我已经用 Python 开发了一个 ML 分类器模型，我想从 java 中使用它。
我查找了一些选项，例如 Jython 等。
谁能帮助我，我怎样才能实现这个用例？
我尝试使用 Jython，但没有找到适合此用例的任何好的文档]]></description>
      <guid>https://stackoverflow.com/questions/77643780/include-python-classifier-model-in-java</guid>
      <pubDate>Tue, 12 Dec 2023 04:58:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用坐标 X、Y 和图像训练深度学习模型？</title>
      <link>https://stackoverflow.com/questions/77643418/how-can-i-train-a-deep-learning-model-with-coordinates-x-y-and-images</link>
      <description><![CDATA[我的任务是头影测量地标定位。
我的图像路径的坐标显示在此数据框中。

&lt;表类=“s-表”&gt;
&lt;标题&gt;

文件名
X1
Y1


&lt;正文&gt;

/Images_data/binary0006.png
89
80


/Images_data/binary0008.png
37
70


/Images_data/binary0007.png
50
76


/Images_data/binary0003.png
55
92


/Images_data/binary0005.png
91
64


/Images_data/binary0004.png
100
76




如何准备用于 model.fit 训练的数据集？
我尝试使用 ImageDataGenerator 创建用于训练的图像数据集。
 train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  数据目录，
  label_mode=无，
  验证分割=0.2，
  子集=“训练”，
  种子=123，
  图像大小=（img_高度，img_宽度），
  批量大小=批量大小）

但现在我陷入困境，因为我不知道如何将坐标与图像匹配。]]></description>
      <guid>https://stackoverflow.com/questions/77643418/how-can-i-train-a-deep-learning-model-with-coordinates-x-y-and-images</guid>
      <pubDate>Tue, 12 Dec 2023 02:46:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的模型能够在数据集上进行训练和测试，但当我添加 SoftMax 层并要求其进行预测时却出现错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</guid>
      <pubDate>Mon, 11 Dec 2023 23:58:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 openai 和 langchain 将已创建的 chromadb 集合与法学硕士一起使用？</title>
      <link>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</link>
      <description><![CDATA[我已经使用其文档和元数据创建了 chromadb 集合。
问题是当我想使用 langchain 创建 llm 并传递此 chromadb 集合以用作知识库时。
langchain_chroma = 色度(
客户端=持久客户端，
集合名称=集合.名称,
embedding_function = openai_ef，
）

llm_model =“gtp35turbo-最新”

llm = AzureChatOpenAI(
   api_key=openai_api_key,
   api_version=openai_api_version,
   azure_endpoint=openai_api_base,
   模型=llm_模型）

qa_chain = RetrievalQA.from_chain_type(
   嗯，
   检索器=langchain_chroma.as_retriever(),
   chain_type=&quot;精炼&quot;
）

当我想跑步时：
qa_chain.run(“对象检测问题需要多少数据科学家”)

我收到此错误：
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-81-3cdb65aeb43e&gt;在&lt;细胞系：1&gt;()
----&gt; 1 qa.run(“对象检测问题需要多少数据科学家”)

9帧
/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py 中相似性_search_with_score(self, query, k, filter, where_document, **kwargs)
    第430章）
    第431章：
--&gt;第432章
    第433章
    第434章

AttributeError：“OpenAIEmbeddingFunction”对象没有属性“embed_query”

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</guid>
      <pubDate>Mon, 11 Dec 2023 21:17:23 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：输入类型（无符号字符）和偏差类型（浮点）应该相同</title>
      <link>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</guid>
      <pubDate>Mon, 11 Dec 2023 11:43:29 GMT</pubDate>
    </item>
    <item>
      <title>如何为多重损失设置可训练的权重？</title>
      <link>https://stackoverflow.com/questions/77380874/how-to-have-trainable-weights-for-multiple-losses</link>
      <description><![CDATA[我有一个加权损失，其中包含用于训练模型的多个损失。
损失 = w1 * 损失1 + w2 * 损失2 + w3 * 损失3
loss.backward()

是否有任何可能的方法使 w1、w2 和 w3 可学习参数？我尝试在模型内使用 self.w1 = nn.Parameter(torch.tensor(0.33), require_grad=True) 来初始化它们，但在一次迭代之后，它的值变成了 nan代码&gt;.
当我们想要使权重可学习时，还需要考虑其他问题，例如，什么阻止它们趋于零甚至负数以使损失为零，我们如何确保权重不会集中于只有一次损失。
有没有办法让这些权重可以学习，而不是手动调整权重？]]></description>
      <guid>https://stackoverflow.com/questions/77380874/how-to-have-trainable-weights-for-multiple-losses</guid>
      <pubDate>Sat, 28 Oct 2023 19:14:51 GMT</pubDate>
    </item>
    <item>
      <title>使用 ConvNext 分类器层</title>
      <link>https://stackoverflow.com/questions/74965058/use-the-convnext-classifier-layer</link>
      <description><![CDATA[Convnext 的源代码内部：
self.classifier = nn.Sequential(
    norm_layer(lastconv_output_channels), nn.Flatten(1), nn.Linear(lastconv_output_channels, num_classes)
）

当我调用预训练模型并且我想在分类器层中进行更改时，norm_layer未定义，我不知道如何从源代码中使用它
模型 = torchvision.models.convnext_base(prtrained=True, stochastic_depth_prob=0.1,
                                         层规模=1e-4)

model.classifier = nn.Sequential(
   **norm_layer**(1024), nn.Flatten(1), nn.Linear(1024, 7)
）

请问谁能帮忙写正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/74965058/use-the-convnext-classifier-layer</guid>
      <pubDate>Fri, 30 Dec 2022 19:14:20 GMT</pubDate>
    </item>
    <item>
      <title>感知器权重更新规则的直觉</title>
      <link>https://stackoverflow.com/questions/34477827/intuition-for-perceptron-weight-update-rule</link>
      <description><![CDATA[我无法理解感知器的权重更新规则：
w(t + 1) = w(t) + y(t)x(t)。
假设我们有一个线性可分离的数据集。

w 是一组权重 [w0, w1, w2, ...]，其中 w0 是偏差。
x 是一组输入参数 [x0, x1, x2, ...]，其中 x0 固定为 1 以适应偏差。

在迭代 t 时，其中 t = 0, 1, 2, ...,

w(t) 是迭代 t 时的权重集。
x(t) 是错误分类的训练示例。
y(t) 是 x(t) 的目标输出（-1 或 1）。


&lt;小时/&gt;

为什么这个更新规则会将边界向正确的方向移动？]]></description>
      <guid>https://stackoverflow.com/questions/34477827/intuition-for-perceptron-weight-update-rule</guid>
      <pubDate>Sun, 27 Dec 2015 05:20:30 GMT</pubDate>
    </item>
    </channel>
</rss>