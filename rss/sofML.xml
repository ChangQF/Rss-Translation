<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 02 Jul 2024 12:27:03 GMT</lastBuildDate>
    <item>
      <title>使用在自定义数据集上训练的 YOLOV8 best.pt 文件的对象跟踪算法？</title>
      <link>https://stackoverflow.com/questions/78696932/object-tracking-algo-with-yolov8-best-pt-file-which-is-trained-on-custom-dataset</link>
      <description><![CDATA[我已经使用 YOLOV8 在自定义数据集上训练了一个模型。从中获得了 best.pt 文件，现在我想使用一些跟踪器算法来跟踪该对象。有人可以给我推荐一些算法吗？另外请分享一些链接，以便我可以参考。另外，有人知道如何查看此组合模型的性能指标吗？请分享。谢谢
除了 DeepSORT，因为我已经尝试过了。]]></description>
      <guid>https://stackoverflow.com/questions/78696932/object-tracking-algo-with-yolov8-best-pt-file-which-is-trained-on-custom-dataset</guid>
      <pubDate>Tue, 02 Jul 2024 12:08:35 GMT</pubDate>
    </item>
    <item>
      <title>X(Twitter) 使用 Python 进行抓取 [关闭]</title>
      <link>https://stackoverflow.com/questions/78696532/xtwitter-scraping-using-python</link>
      <description><![CDATA[我想提取特定推文的信息，如内容、图像和其他媒体等。
例如：“https://twitter.com/username/status/123xxxxxxx”
我想提取存储在 ID 为“123xxxxxxx”的推文中的信息。
如何使用 Python 实现它，因为 tweepy 不再起作用，而 ntscraper 允许检索特定个人资料的推文（据我所知）。
我尝试使用 ntscraper，但没有支持抓取特定推文的属性。]]></description>
      <guid>https://stackoverflow.com/questions/78696532/xtwitter-scraping-using-python</guid>
      <pubDate>Tue, 02 Jul 2024 10:43:53 GMT</pubDate>
    </item>
    <item>
      <title>小行星游戏上的 ML RL 与神经网络</title>
      <link>https://stackoverflow.com/questions/78696449/ml-rl-with-neural-network-on-asteroids-game</link>
      <description><![CDATA[我建立了一个 DQ 网络，它可以分析小行星的状态，并且火箭会给出最佳的执行动作（左转、右转、射击、空闲）。但是代理一直在发射子弹？

有人能帮我解决这个问题吗？
我以为代理会探索所有 4 个动作，但它一直在发射子弹，很难向左或向右移动，几乎停留在中心并不断发射子弹。]]></description>
      <guid>https://stackoverflow.com/questions/78696449/ml-rl-with-neural-network-on-asteroids-game</guid>
      <pubDate>Tue, 02 Jul 2024 10:27:16 GMT</pubDate>
    </item>
    <item>
      <title>将文件添加到 Vertex-AI Bucket</title>
      <link>https://stackoverflow.com/questions/78696253/adding-file-to-vertex-ai-bucket</link>
      <description><![CDATA[我在 Google Cloud Vertex-AI 的工作台中使用笔记本，有时我想创建一个多标签 aiplatform.TextDataset。为此，我首先需要拥有 gcs_source。我尝试使用存储在与笔记本同一目录中的 JSON 行文件，但 aiplatform.TextDataset.create() 一直失败并显示以下错误消息：

TypeError：wrap_method() 获得了意外的关键字参数“default_compression”

我认为这是因为我用于 gcs_source 以创建 TextDataset 的 JSON 行文件不在存储桶中。
这是问题吗？如果是这样，我该如何将 JSON 添加到 Bucket？
更新：
这不是问题，我在 Bucket 中使用以下命令创建了文件：
import json
client = storage.Client()
bucket = client.get_bucket(&#39;&lt;my_bucket&gt;&#39;)
blob = bucket.blob(&#39;&lt;my_file&gt;.jsonl&#39;)
with blob.open(&#39;w&#39;) as f:
for d in data:
json.dump(d, f)
f.write(&#39;\n&#39;)

我检查了一下，文件已在 bucket 中正确创建。但我仍然收到相同的错误]]></description>
      <guid>https://stackoverflow.com/questions/78696253/adding-file-to-vertex-ai-bucket</guid>
      <pubDate>Tue, 02 Jul 2024 09:48:03 GMT</pubDate>
    </item>
    <item>
      <title>cuda 12.1 安装中遇到错误，GPU：2x Nvidia L4 张量</title>
      <link>https://stackoverflow.com/questions/78695698/facing-error-in-cuda-12-1-installation-gpu-2x-nvidia-l4-tensor</link>
      <description><![CDATA[我有一台新的 Debian 11 服务器，我在其中添加了 Nvidia L4 Tensor GPU，但在尝试安装 cuda-12.1.0 时出现以下错误。
错误：
make\[1\]：离开目录‘/usr/src/linux-5.10.27’
完成。
内核模块编译完成。
错误：无法加载内核模块‘nvidia.ko’。这种情况最常发生在以下情况下：此内核模块是针对错误或配置不当的内核源构建的，其 gcc 版本与用于构建目标内核的版本不同，或者存在另一个驱动程序（如 nouveau）并阻止 NVIDIA 内核模块获得 NVIDIA 设备的所有权，或者此 NVIDIA Linux 图形驱动程序版本不支持此系统中安装的任何 NVIDIA 设备。
有关详细信息，请参阅文件“/var/log/nvidia-installer.log”末尾的日志条目“内核模块加载错误”和“内核消息”。
内核模块加载错误：没有这样的设备

NVRM：分配给您的 NVIDIA 设备的 PCI I/O 区域无效：
NVRM：BAR0 为 0M @ 0x0（PCI：0000：01：00.0）
nvidia：0000：01：00.0 的探测失败，错误为 -1
NVRM：1 个设备的 NVIDIA 探测例程失败。
NVRM：所有 NVIDIA 设备均未初始化。
nvidia-nvlink：未注册的 Nvlink Core，主设备号 247
错误：安装失败。有关详细信息，请参阅文件“/var/log/nvidia-installer.log”。您可以在 Linux 驱动程序下载页面 (www.nvidia.com) 上的 README 中找到有关修复安装问题的建议。

我尝试了从 Google 和其他资源中获得的以下方法。
  内核更新 (6.x.x-deb)
  手动安装 Nvidia 驱动程序
  添加 repo (ppa:graphics-drivers/ppa)
  Cuda 安装 (运行文件、本地 repo、网络 repo)
我还尝试手动安装 Nvidia 驱动程序 (530.x.x、535.x.x、555.x.x)，但仍然无法获得兼容的驱动程序。
服务器规格：
  操作系统：Debian 11
  Arch：x86_64
  GPU：​​2x Nvidia L4 Tensor
我有上述服务器配置，想要安装cuda-toolkit 12.1.0 带有合适的 Nvidia 驱动程序。Cuda-toolkit 版本：12.1.0]]></description>
      <guid>https://stackoverflow.com/questions/78695698/facing-error-in-cuda-12-1-installation-gpu-2x-nvidia-l4-tensor</guid>
      <pubDate>Tue, 02 Jul 2024 07:57:59 GMT</pubDate>
    </item>
    <item>
      <title>如何将 .mlpackage Core ML 模型转换为 .mlmodel Core ML 模型？</title>
      <link>https://stackoverflow.com/questions/78695468/how-can-one-convert-a-mlpackage-core-ml-model-to-a-mlmodel-core-ml-model</link>
      <description><![CDATA[如何将 .mlpackage 模型转换为 .mlmodel 模型？

在 Ubuntu 20.04 上使用 Hugging Face 的 Exporters lib 创建的 .mlpackage Core ML 模型示例（使用 Python 3.10 和 torch 2.3.1 测试）：
git clone https://github.com/huggingface/exporters.git
cd exporters
pip install -e .
python -m exporters.coreml --model=distilbert-base-uncasederated/ --quantize=float32 
]]></description>
      <guid>https://stackoverflow.com/questions/78695468/how-can-one-convert-a-mlpackage-core-ml-model-to-a-mlmodel-core-ml-model</guid>
      <pubDate>Tue, 02 Jul 2024 07:03:04 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark 中的 RankingMetrics 未按预期工作</title>
      <link>https://stackoverflow.com/questions/78695397/rankingmetrics-in-pyspark-not-working-as-expected</link>
      <description><![CDATA[嗨，我有一个像这样的 pyspark df。
 (&#39;recs&#39;, &#39;array&lt;string&gt;&#39;),
(&#39;model_pred_score&#39;, &#39;array&lt;double&gt;&#39;),
(&#39;ground_truth_score&#39;, &#39;array&lt;double&gt;&#39;),
(&#39;model_ranked_items&#39;, &#39;array&lt;string&gt;&#39;),
(&#39;actual_ranked_items&#39;, &#39;array&lt;string&gt;&#39;)]

其中 recs 包含向客户推荐的商品列表，大小为 n，它将向客户推荐相关和不相关的商品。
model_pred_score 是模型预测的分数，为 int， ground_truth_score 是基于交互计算的浮点数，如果客户根本没有与项目交互，它也可以有 0。
现在我已经对 recs 进行了排序，这将为我们提供 model_ranked_items 和 actual_ranked_items，它们是根据其分数排名的项目。它们都将具有相等大小的 recs 数组列
现在我想计算这些项目的 NDCG 和 Precision，因此我像这样使用 Python 中的 RankingMetrics 库。
predictions_and_labels_rdd = df_grp.rdd.map(lambda row: (row[&quot;model_ranked_items&quot;], row[&quot;actual_ranked_items&quot;]))
ranking_metrics = RankingMetrics(predictions_and_labels_rdd)

ranking_metrics.ndcgAt(10)
ranking_metrics.precisionAt(10)

我不知道我在这里遗漏了什么，但我总是得到所有指标的 1。我后来还为 ndcg 添加了相关性列，但所有指标的得分仍然为 1。
我是否不应该将不相关的项目添加到 ground_truth_set？]]></description>
      <guid>https://stackoverflow.com/questions/78695397/rankingmetrics-in-pyspark-not-working-as-expected</guid>
      <pubDate>Tue, 02 Jul 2024 06:42:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 Flask 进行 ML 项目时出现 500 内部服务器错误[关闭]</title>
      <link>https://stackoverflow.com/questions/78695216/500-internal-server-error-while-using-flask-for-ml-project</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78695216/500-internal-server-error-while-using-flask-for-ml-project</guid>
      <pubDate>Tue, 02 Jul 2024 05:46:46 GMT</pubDate>
    </item>
    <item>
      <title>stackoverflow 如何检测重复的问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78695052/how-stackoverflow-detect-duplicate-questions</link>
      <description><![CDATA[我在网上搜索过，但搞不懂用于判断两个问题是否相似的特征是什么？所以请帮我解释一下用于检测两个问题是否重复的特征工程？另外，对于一个新问题，请告诉我我们如何检测一组彼此相似的问题？]]></description>
      <guid>https://stackoverflow.com/questions/78695052/how-stackoverflow-detect-duplicate-questions</guid>
      <pubDate>Tue, 02 Jul 2024 04:40:07 GMT</pubDate>
    </item>
    <item>
      <title>精确而强大的角点检测（噪声图像、脏污物体）</title>
      <link>https://stackoverflow.com/questions/78694749/precise-and-robust-corner-detection-noisy-image-dirty-object</link>
      <description><![CDATA[鉴于一定的质量控制要求，我们实施了一个自动化系统来测量钢板生产线的某些尺寸。问题是，有时系统不够强大，系统选择的像素不能反映我们人类推理认为的真实角落。该图像大约为 17 MPixels-
此简化的代码片段应代表我们的测量过程：
defcontrast_stretch(image, multiplier=1.0):
min_val = np.min(image)
max_val = np.max(image)
stretched = (image - min_val) * (255 / (max_val - min_val) * multiplier)
stretched = np.clip(stretched, 0, 255).astype(np.uint8)
returnstretched

def distance(pt1, pt2):
return math.sqrt((pt2[0] - pt1[0]) ** 2 + (pt2[1] - pt1[1]) ** 2)

defmeasure_diagonals(image, contours, px_to_mm):
refined_corners = []
for cnt in轮廓：
rect = cv2.minAreaRect(cnt)
box = cv2.boxPoints(rect)
box = np.int0(box)
corners = cv2.cornerSubPix(image, np.float32(box), (5, 5), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))
refined_corners.append(corners)
如果 len(refined_corners) &gt;= 2:
d1 = distance(refined_corners[0][0], refined_corners[0][2])
d2 = distance(refined_corners[1][0], refined_corners[1][2])
m1 = d1 * px_to_mm
m2 = d2 * px_to_mm
diff = abs(m2 - m1)
返回 m1, m2, diff
返回 None, None, None

# 加载校准数据
calibration_data = load_calibration_data(calibration_data_path)
mtx = calibration_data[&quot;mtx&quot;]
dist = calibration_data[&quot;dist&quot;]

# 加载图像
frame = cv2.imread(img_path)

# 不失真图像
frame_undistorted = cv2.undistort(frame, mtx, dist, None, mtx)

# 转换为灰度
gray = cv2.cvtColor(frame_undistorted, cv2.COLOR_BGR2GRAY)

# 应用双边滤波器
filtered_image = cv2.bilateralFilter(gray, 9, 125, 25)

# 增强对比度
enhanced_image =对比度拉伸（过滤图像）

# 检测轮廓
_, edge = cv2.threshold(enhanced_image, 140, 255, cv2.THRESH_BINARY)
contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# 测量对角线
px_to_mm = 0.1 # 示例转换因子
m1, m2, diff = measure_diagonals(enhanced_image, contours, px_to_mm)

这是正确选择角的示例：
ROI 生成阈值（白点），然后是圆角子像素（黑色点）
这是一个错误选择角落的例子：
红色部分是我们知道的真正角落
我知道我们应该改善照明。我们正在测量一个大面积（&gt;4 米），并且要有一个能够生成明亮、均匀图像的照明系统极具挑战性，因此我们应用了大量软件校正，例如双边滤波器、增益和对比度增强器。]]></description>
      <guid>https://stackoverflow.com/questions/78694749/precise-and-robust-corner-detection-noisy-image-dirty-object</guid>
      <pubDate>Tue, 02 Jul 2024 01:35:14 GMT</pubDate>
    </item>
    <item>
      <title>HTML 文件输出未生成</title>
      <link>https://stackoverflow.com/questions/78694578/html-file-output-not-generating</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78694578/html-file-output-not-generating</guid>
      <pubDate>Mon, 01 Jul 2024 23:43:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在 macOS 10.12 上运行 Core ML 模型？</title>
      <link>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</link>
      <description><![CDATA[https://developer.apple.com/documentation/coreml 提到 macOS 10.13+：

如何在 macOS 10.12 上运行 Core ML 模型？

在 Ubuntu 20.04 上使用 Hugging Face 的 Exporters lib:
git clone https://github.com/huggingface/exporters.git
cd exporters
pip install -e .
python -m exporters.coreml --model=distilbert-base-uncasederated/ --quantize=float32 
]]></description>
      <guid>https://stackoverflow.com/questions/78694076/how-can-one-run-a-core-ml-model-on-macos-10-12</guid>
      <pubDate>Mon, 01 Jul 2024 20:13:24 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 Pytorch 提取视觉转换器的倒数第二层输出</title>
      <link>https://stackoverflow.com/questions/78691616/cannot-extract-the-penultimate-layer-output-of-a-vision-transformer-with-a-pytor</link>
      <description><![CDATA[我有以下模型，该模型使用我自己的 DataParallel 训练的数据集进行了调整：
model = timm.create_model(&#39;vit_base_patch16_224&#39;, pretrained=False)
model.head = nn.Sequential(nn.Linear(768, 512),nn.ReLU(),nn.BatchNorm1d(512),nn.Dropout(p=0.2),nn.Linear(512, 141))
checkpoint = torch.load(&#39;vit_b_16v3.pth&#39;)
checkpoint = {k.partition(&#39;module.&#39;)[2]: v for k, v in checkpoint.items()}
# 加载参数
model.load_state_dict(checkpoint)

但是，我不知道如何获取这种视觉转换器的倒数第二层输出。我尝试了本教程，但不起作用。我只想输入一张图片，并有一个 512 维向量来描述它。使用 Tensorflow 做这件事很容易，但在 Pytorch 中我却很挣扎。
我最后的几层如下：
(norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
(fc_norm): Identity()
(head_drop): Dropout(p=0.0, inplace=False)
(head): Sequential(
(0): Linear(in_features=768, out_features=512, bias=True)
(1): ReLU()
(2): BatchNorm1d(512, eps=1e-05, motivation=0.1, affine=True, track_running_stats=True)
(3): Dropout(p=0.2, inplace=False)
(4): Linear(in_features=512, out_features=141, bias=True)
)
)
]]></description>
      <guid>https://stackoverflow.com/questions/78691616/cannot-extract-the-penultimate-layer-output-of-a-vision-transformer-with-a-pytor</guid>
      <pubDate>Mon, 01 Jul 2024 10:16:39 GMT</pubDate>
    </item>
    <item>
      <title>Roboflow Vs. Darknet 用于生成权重文件和创建模型</title>
      <link>https://stackoverflow.com/questions/78691574/roboflow-vs-darknet-for-generating-weight-file-and-creating-the-model</link>
      <description><![CDATA[我有一个 YoloV8 数据文件格式，它是手动完成的数据（图像）注释。
生成模型并因此产生权重文件的最有效和最直接的方法是什么？是通过以下命令使用 darknet 吗：
darknet.exe detector train data/obj.data yolo-obj.cfg backup\yolo-obj_2000.weights

然后使用类似下面的命令生成关联模型：
python tools/model_converter/convert.py cfg/yolov3.cfg weights/yolov3.weights weights/yolov3.h5

或者通过以下命令使用 Roboflow：
version.deploy(model_type=&quot;yolov8&quot;, model_path=f”{HOME}/runs/detect/train/&quot;)

在我看来，darknet 更难安装。]]></description>
      <guid>https://stackoverflow.com/questions/78691574/roboflow-vs-darknet-for-generating-weight-file-and-creating-the-model</guid>
      <pubDate>Mon, 01 Jul 2024 10:07:36 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret 设置独热编码</title>
      <link>https://stackoverflow.com/questions/74001472/pycaret-setup-for-one-hot-encoding</link>
      <description><![CDATA[我陷入了 Pycaret 中分类变量独热编码的问题。问题是，即使设置了我的分类变量，管道也会对分类变量应用规范化，我不知道我做错了什么。
首先，使用下面的代码一切正常：
from pycaret.classification import *
from pycaret.datasets import get_data
import pandas as pd
import numpy as np
import seaborn as sns
dataset = get_data(&#39;income&#39;)
dataset.dtypes

直到我开始设置和
exp_clf01 = setup( data = dataset
, target = &#39;income &gt;50K&#39;
, session_id = 123
, numeric_features = [&#39;age&#39;,&#39;education-num&#39;,&#39;capital-gain&#39;,&#39;capital-loss&#39;,&#39;hours-per-week&#39;]
, categorical_features = [&#39;workclass&#39;,&#39;education&#39;,&#39;marital-status&#39;,&#39;occupation&#39;,&#39;relationship&#39;,&#39;race&#39;,&#39;sex&#39;,&#39;native-country&#39;]
)
df_transformed = get_config(&quot;X_train&quot;)
df_transformed.head()

尝试查看数据框的头部后，它仅将独热编码应用于列 race，并将其他分类输入标准化，我不明白为什么。




age
workclass
education
education-num
marital-status
occupation
other列




46.0
0.303273
0.271186
11.0
0.101942
0.484643
...


27. 0
0.218620
0.412939
13.0
0.044165
0.484643
...


33.0
0.218557
0.568315
 14.0
0.448894
0.455449
...


60.0
0.218557
0.412673
13.0
0.448894
0.484286
&lt; td&gt;...


25.0
0.218620
0.063798
6.0
0.044165
0.229692
...




我该如何防止这种行为？]]></description>
      <guid>https://stackoverflow.com/questions/74001472/pycaret-setup-for-one-hot-encoding</guid>
      <pubDate>Sun, 09 Oct 2022 00:59:48 GMT</pubDate>
    </item>
    </channel>
</rss>