<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 08 Nov 2024 09:17:28 GMT</lastBuildDate>
    <item>
      <title>ML.NET 时间序列预测特定时间段</title>
      <link>https://stackoverflow.com/questions/79169287/ml-net-time-series-predicting-specific-period-of-time</link>
      <description><![CDATA[我是 ML.NET 的新手，一直在尝试使用该框架来预测我周围的一些数据。
据我发现，我们可以使用时间序列来预测未来的一系列值预测，这些值预测与最后输入数据的日期/时间相邻。
是否可以针对相同的训练数据模型对前一段时间（过去）进行预测？
我浏览了 prediction.Predict() 文档，但找不到任何地方可以提供时间作为参数。
在哪里以及如何对特定时间段进行预测是最佳情况？
请随时纠正我的理解并指出正确的方法。]]></description>
      <guid>https://stackoverflow.com/questions/79169287/ml-net-time-series-predicting-specific-period-of-time</guid>
      <pubDate>Fri, 08 Nov 2024 08:24:25 GMT</pubDate>
    </item>
    <item>
      <title>如何修复 ValueError：预期输入 batch_size (49) 与目标 batch_size (64) 匹配</title>
      <link>https://stackoverflow.com/questions/79168959/how-to-fix-valueerror-expected-input-batch-size-49-to-match-target-batch-size</link>
      <description><![CDATA[我一直在修改数据加载器端，但它仍然显示该错误..
这是预处理代码：
预处理：
# 您的代码在这里
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

class ImageDataset(Dataset):
def __init__(self, images, labels, transform=None, target_transform=None):
self.images = images
self.labels = labels
self.transform = transform
self.target_transform = target_transform

def __len__(self):
return len(self.images)

def __getitem__(self, idx):
image = self.images[idx]
label = self.labels[idx]

if self.transform:
image = self.transform(image)

if self.target_transform:
label = self.target_transform(label)

return image, label

# 调整数据大小
resize_transform = transforms.Compose([
transforms.ToTensor(),
transforms.Normalize((0.5,), (0.5,))
])

# 使用 Data Loader，这是一个包装数据集并使用小批量输出每个数据的函数。
train_dataset = ImageDataset(images=x, labels=y, transform=resize_transform)
train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)

# 打印每个数据（dataloader 中的 x 测试和 y 测试）
对于 train_dataloader 中的图像、标签：
print(images.shape)
print(labels.shape)
break

这是模型：
val_dataset = ImageDataset(x_val, y_val, transform=resize_transform)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)

import torch.nn as nn
import torch.nn. functional as F
import torch.optim as optim

class Network(nn.Module):
def __init__(self):
super(Network, self).__init__()
self.conv1 = nn.Conv2d(1, 32, 3)
self.conv2 = nn.Conv2d(32, 64, 3)
self.fc1 = nn.Linear(64 * 16 * 16, 128)
self.fc2 = nn.Linear(128, 64)
self.fc3 = nn.Linear(64, 16) # 针对 16 个类进行调整

self.pool = nn.MaxPool2d(2, 2)

def forward(self, x):
x = self.pool(F.relu(self.conv1(x)))
x = self.pool(F.relu(self.conv2(x)))
x = x.view(-1, 64 * 16 * 16) # 扁平层
x = F.relu(self.fc1(x))
x = F.relu(self.fc2(x))
x = self.fc3(x)
return x

# 定义损失函数和优化器
net = Network()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, influence=0.9)

# 训练模型
num_epochs = 10
for epoch in range(num_epochs):
net.train()
running_loss = 0.0
for i, data in enumerate(train_dataloader, 0):
input, labels = data
optimizer.zero_grad()
output = net(inputs)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()
running_loss += loss.item()

print(f&quot;Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}&quot;)

# 验证准确率
net.eval()
correct = 0
total = 0
with torch.no_grad():
for input, labels in val_loader:
output = net(inputs)
_, predicted = torch.max(outputs.data, 1)
total += labels.size(0)
correct += (predicted == labels).sum().item()

accuracy = 100 * correct / total
print(f&quot;验证准确率：{accuracy:.2f}%&quot;)

print(&quot;完成训练&quot;)


上面提到的错误：ValueError：预期输入 batch_size (49) 与目标 batch_size (64) 匹配。不断出现....
我想知道这里的问题是什么..]]></description>
      <guid>https://stackoverflow.com/questions/79168959/how-to-fix-valueerror-expected-input-batch-size-49-to-match-target-batch-size</guid>
      <pubDate>Fri, 08 Nov 2024 05:55:50 GMT</pubDate>
    </item>
    <item>
      <title>单标签图像分类</title>
      <link>https://stackoverflow.com/questions/79168636/single-label-image-classification</link>
      <description><![CDATA[我正在尝试构建一个单标签图像分类，用于检测损坏/正常的笔记本电脑。我有大约 500 张图像的数据集。我曾尝试使用 ResNet50 CNN，但效果不佳。
我想了解

我是否需要更多数据，如果需要，需要多少？
如果我必须使用现有的 500 张图像数据集，最好的方法是什么？我应该使用什么？任何详细信息都会有所帮助。

PS。我以前没有研究过 ML 模型，这是我的第一次尝试。]]></description>
      <guid>https://stackoverflow.com/questions/79168636/single-label-image-classification</guid>
      <pubDate>Fri, 08 Nov 2024 02:45:20 GMT</pubDate>
    </item>
    <item>
      <title>神经网络可以训练来识别加密货币市场中的艾略特波浪模式吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/79168629/can-neural-networks-be-trained-to-recognize-elliott-wave-patterns-in-the-crypto</link>
      <description><![CDATA[是否有可能训练神经网络来识别加密货币市场数据中已知的艾略特波浪模式？具体来说，神经网络能否从历史价格数据（例如开盘价、最高价、最低价、收盘价、成交量）中发现这些模式并根据它们预测未来趋势？哪些技术或架构对这项任务有效？]]></description>
      <guid>https://stackoverflow.com/questions/79168629/can-neural-networks-be-trained-to-recognize-elliott-wave-patterns-in-the-crypto</guid>
      <pubDate>Fri, 08 Nov 2024 02:41:27 GMT</pubDate>
    </item>
    <item>
      <title>机器学习 Flask 应用程序中的错误 - jinja2.exceptions.TemplateNotFound：index.html</title>
      <link>https://stackoverflow.com/questions/79168341/error-in-machine-learning-flask-app-jinja2-exceptions-templatenotfound-index</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79168341/error-in-machine-learning-flask-app-jinja2-exceptions-templatenotfound-index</guid>
      <pubDate>Thu, 07 Nov 2024 23:03:46 GMT</pubDate>
    </item>
    <item>
      <title>Azure 文档智能自定义模型在提取采购订单字段时失去准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/79168102/azure-document-intelligence-custom-model-losing-accuracy-in-extracting-purchase</link>
      <description><![CDATA[我正在使用 Azure Document Intelligence 读取来自不同客户的采购订单并提取特定字段以自动处理订单。我们在 Document Intelligence Studio 中创建了一个自定义模型，定义了自定义字段，并通过在示例文档中标记相关字段来训练该模型。最初，该模型表现良好，以高精度将数据放置在正确的字段中。
问题：
最近，我们注意到准确度有所下降。即使使用我们训练集中的相同示例文档，该模型现在返回的结果也与预期不同，将数据错误地放置在预定义字段中。我们查看了文档和教程，并按照建议添加了更多训练数据，但这并没有解决问题。
我们尝试过的方法：

向训练数据中添加了更多带标签的样本。

问题：

什么可能导致准确度随着时间的推移而下降，特别是考虑到该模型最初运行良好？可能是我们为其提供的不同采购订单测试数据的数量？
Document Intelligence Studio 中是否有最佳实践或配置技巧可以帮助稳定准确度？
Azure Document Intelligence 中是否有我们可能未使用的自定义模型的高级调整选项？
]]></description>
      <guid>https://stackoverflow.com/questions/79168102/azure-document-intelligence-custom-model-losing-accuracy-in-extracting-purchase</guid>
      <pubDate>Thu, 07 Nov 2024 21:15:59 GMT</pubDate>
    </item>
    <item>
      <title>支持向量机[关闭]</title>
      <link>https://stackoverflow.com/questions/79167180/support-vector-machine</link>
      <description><![CDATA[在支持向量机中，我们是否已经给出了数据集的决策边界，然后我们是否会调整给定的决策边界以最大化边际？]]></description>
      <guid>https://stackoverflow.com/questions/79167180/support-vector-machine</guid>
      <pubDate>Thu, 07 Nov 2024 15:41:52 GMT</pubDate>
    </item>
    <item>
      <title>我如何正确设置“random_state”以使结果始终相同？</title>
      <link>https://stackoverflow.com/questions/79165974/how-do-i-set-random-state-correctly-so-that-my-results-are-always-the-same</link>
      <description><![CDATA[例如，如果我有以下代码片段：
knn = KNeighborsClassifier()
grid_search_knn = GridSearchCV(
estimator=knn,
n_jobs=-1)

我是否必须像这样设置：
knn = KNeighborsClassifier(random_state=42)

grid_search_knn = GridSearchCV(
estimator=knn,
n_jobs=-1
)

或者我是否必须像这样设置？
knn = KNeighborsClassifier(random_state=42)

grid_search_knn = GridSearchCV(
estimator=knn,
random_state=42,
n_jobs=-1
)

正确的为什么是什么？如果我使用随机搜索而不是网格搜索会怎样？]]></description>
      <guid>https://stackoverflow.com/questions/79165974/how-do-i-set-random-state-correctly-so-that-my-results-are-always-the-same</guid>
      <pubDate>Thu, 07 Nov 2024 10:17:56 GMT</pubDate>
    </item>
    <item>
      <title>如何在 PyTorch 中为 Nvidia GeForce RTX 3050 Ti 启用 CUDA？</title>
      <link>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</link>
      <description><![CDATA[我想在我的显卡（Nvidia GeForce RTX 3050 Ti）上运行 PyTorch 库（我在 PyCharm 的虚拟环境中运行该库）。但是，它在 CPU 上运行，每当我使用命令 import torch 和 print(&quot;cuda is available:&quot;, torch.cuda.is_available()) 时，它总是返回 False。
我安装了 CUDA 版本 12.6。我还安装了 PyTorch for CUDA 版本 12.4，因为它是 PyTorch 网站上可用的最新版本。考虑到我的显卡类型，我应该安装什么？]]></description>
      <guid>https://stackoverflow.com/questions/79165030/how-can-i-enable-cuda-in-pytorch-for-nvidia-geforce-rtx-3050-ti</guid>
      <pubDate>Thu, 07 Nov 2024 04:30:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 JAX 训练模型时跟踪测试/验证损失</title>
      <link>https://stackoverflow.com/questions/79158791/tracking-test-val-loss-when-training-a-model-with-jax</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79158791/tracking-test-val-loss-when-training-a-model-with-jax</guid>
      <pubDate>Tue, 05 Nov 2024 10:58:38 GMT</pubDate>
    </item>
    <item>
      <title>如何将特征提取层添加到 Tensorflow 中的序列模型？</title>
      <link>https://stackoverflow.com/questions/78071238/how-to-add-feature-extracted-layer-to-a-sequential-model-in-tensorflow</link>
      <description><![CDATA[resnet_50 = &quot;https://www.kaggle.com/models/tensorflow/resnet-50/frameworks/TensorFlow2/variations/classification/versions/1&quot;
feature_extractor_model = resnet_50
import tensorflow_hub as hub
feature_extractor_layer = hub.KerasLayer(
feature_extractor_model,
input_shape=(224, 224, 3),
trainable=False)
num_classes = len(class_names)
model = tf.keras.Sequential()
model.add(feature_extractor_layer)
model.summary()

我试图将 feature_extractor_layer 添加到 Sequential，但出现以下错误：

ValueError：只有 keras.Layer 的实例可以添加到 Sequential 模型中。已收到：&lt;tensorflow_hub.keras_layer.KerasLayer 对象位于 0x7b6c00794850&gt;（类型为 &lt;class &#39;tensorflow_hub.keras_layer.KerasLayer&#39;&gt;）

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/78071238/how-to-add-feature-extracted-layer-to-a-sequential-model-in-tensorflow</guid>
      <pubDate>Tue, 27 Feb 2024 23:56:01 GMT</pubDate>
    </item>
    <item>
      <title>将 .ckpt 转换为 .h5</title>
      <link>https://stackoverflow.com/questions/74640695/convert-ckpt-to-h5</link>
      <description><![CDATA[我已经使用 resnet18 训练模型进行 mask R-CNN 检测。对于每个时期，它只创建一个“.ckpt”文件。
现在我想使用该 .ckpt 文件作为检测图像的检测器。我有使用“.h5”文件进行检测的 Python 代码。
请帮助我如何使用“.ckpt”文件进行检测。或者我如何将其转换为“.h5”？
谢谢
我曾尝试在训练过程中生成“.h5”文件而不是“.ckpt”，但对我来说不起作用。
现在我需要一种方法来使用“.ckpt”文件来检测图像中的对象。]]></description>
      <guid>https://stackoverflow.com/questions/74640695/convert-ckpt-to-h5</guid>
      <pubDate>Thu, 01 Dec 2022 10:50:58 GMT</pubDate>
    </item>
    <item>
      <title>尝试导出引用“未跟踪”资源的函数 Tensor(“272554:0”, shape=(), dtype=resource)</title>
      <link>https://stackoverflow.com/questions/72313812/tried-to-export-a-function-which-references-untracked-resource-tensor272554</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/72313812/tried-to-export-a-function-which-references-untracked-resource-tensor272554</guid>
      <pubDate>Fri, 20 May 2022 05:07:08 GMT</pubDate>
    </item>
    <item>
      <title>实现 GridSearchCV 和 Pipelines 来对 KNN 算法进行超参数调整</title>
      <link>https://stackoverflow.com/questions/70345909/implementing-gridsearchcv-and-pipelines-to-perform-hyperparameters-tuning-for-kn</link>
      <description><![CDATA[我一直在阅读有关执行 KNN 算法的超参数调整的文章，并了解到实现它的最佳实践是确保对于每次折叠，我的数据集都应该使用管道进行规范化和过度采样（以避免数据泄漏和过度拟合）。
我想做的是，我试图确定可能的最佳邻居数量（n_neighbors），从而为我提供最佳的训练准确率。在代码中，我将邻居数量设置为列表 range (1,50)，迭代次数为 cv=10。
我的代码如下：
# 数据集读取 &amp;预处理库
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

#oversmapling
from imblearn.over_sampling import SMOTE

#KNN 模型相关库
import cuml
from imblearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, GridSearchCV
from cuml.neighbors import KNeighborsClassifier

#加载数据集
df = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/dataset/IanDataset.csv&quot;)

#用零填充缺失值
df = df.fillna(0)

#将数据从对象替换为整数
df[&quot;command response&quot;].replace({&quot;b&#39;0&#39;&quot;: &quot;0&quot;, &quot;b&#39;1&#39;&quot;: &quot;1&quot;}, inplace=True)
df[&quot;binary result&quot;].replace({&quot;b&#39;0&#39;&quot;: &quot;0&quot;, &quot;b&#39;1&#39;&quot;: &quot;1&quot;}, inplace=True)

# 更改某些特征的数据类型以便以后使用 
df[&quot;command response&quot;] = pd.to_numeric(df[&quot;command response&quot;]).astype(float)
df[&quot;binary result&quot;] = pd.to_numeric(df[&quot;binary result&quot;]).astype(int)

# 数据集拆分
X = df.iloc[:, 0:17]
y_bin = df.iloc[:, 17]

# 将数据集拆分为训练和测试用于二元分类
X_train, X_test, y_bin_train, y_bin_test = train_test_split(X, y_bin, random_state=0, test_size=0.2)

#制作在 GridSearchCV 之前进行归一化、过采样和使用分类器的管道
pipe = Pipeline([
(&#39;normalization&#39;, MinMaxScaler()),
(&#39;oversampling&#39;, SMOTE()),
(&#39;classifier&#39;, KNeighborsClassifier(metric=&#39;eculidean&#39;, output=&#39;input&#39;))
])

#使用 GridSearchCV
neighbors = list(range(1,50))
parameters = {
&#39;classifier__n_neighbors&#39;: neighbours 
}

grid_search = GridSearchCV(pipe, parameters, cv=10)
grid_search.fit(X_train, y_bin_train)

print(&quot;最佳准确率：{}&quot; .format(grid_search.best_score_))
print(&quot;最佳邻居数：{}&quot; .format(grid_search.best_estimator_.get_params()[&#39;n_neighbors&#39;]))

在步骤 grid_search.fit(X_train, y_bin_train) 中，程序重复出现我遇到的错误：
/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:619: FitFailedWarning: 估计器拟合失败。这些参数在此训练测试分区上的得分将设置为 nan。详细信息：
回溯（最近一次调用）：
文件“/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py”，第 598 行，在 _fit_and_score 中
estimator.fit(X_train, y_train, **fit_params)
文件“/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py”，第 266 行，在 fit 中
self._final_estimator.fit(Xt, yt, **fit_params_last_step)
文件“/usr/local/lib/python3.7/site-packages/cuml/internals/api_decorators.py”，第 409 行，在 inner_with_setters 中
return func(*args, **kwargs)
文件&quot;cuml/neighbors/kneighbors_classifier.pyx&quot;，第 176 行，位于 cuml.neighbors.kneighbors_classifier.KNeighborsClassifier.fit
文件 &quot;/usr/local/lib/python3.7/site-packages/cuml/internals/api_decorators.py&quot;，第 409 行，位于 inner_with_setters
return func(*args, **kwargs)
文件 &quot;cuml/neighbors/nearest_neighbors.pyx&quot;，第 397 行，位于 cuml.neighbors.nearest_neighbors.NearestNeighbors.fit
ValueError：度量无效。使用 sorted(cuml.neighbors.VALID_METRICSeculidean[brute]) 获取有效选项。

我不确定这个错误来自哪一方，是因为我从 cuML 库而不是 sklearn 导入了 KNN 算法吗？还是我的 Pipeline 和 GridSearchCV 实现有问题？]]></description>
      <guid>https://stackoverflow.com/questions/70345909/implementing-gridsearchcv-and-pipelines-to-perform-hyperparameters-tuning-for-kn</guid>
      <pubDate>Tue, 14 Dec 2021 08:36:26 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.decomposition.PCA 的特征向量简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我试图了解主成分分析的工作原理，并在sklearn.datasets.load_iris数据集上对其进行测试。我了解每个步骤的工作原理（例如，标准化数据、协方差、特征分解、按最高特征值排序、使用K个选定维度将原始数据转换为新轴）。
下一步是可视化这些特征向量在数据集上投影的位置（在PC1 vs. PC2 图上，对吗？）。
有人可以解释如何在降维数据集的 3D 图上绘制 [PC1、PC2、PC3] 特征向量吗？
此外，我是否正确绘制了这个 2D 版本？我不确定为什么我的第一个特征向量的长度较短。我应该乘以特征值吗？

以下是我为实现此目标所做的一些研究：
我遵循的 PCA 方法来自：
https://plot.ly/ipython-notebooks/principal-component-analysis/#Shortcut---PCA-in-scikit-learn（虽然我不想使用 plotly。我想坚持使用 pandas、numpy、sklearn、matplotlib、scipy 和 seaborn）
我一直在遵循这个绘制特征向量的教程，它看起来很不错简单：使用 matplotlib 进行 PCA 的基本示例，但我似乎无法用我的数据复制结果。
我发现了这一点，但对于我想做的事情来说，它似乎过于复杂，而且我不想创建一个 FancyArrowPatch：使用 matplotlib 和 np.linalg 绘制协方差矩阵的特征向量

我试图让我的代码尽可能简单，以便遵循其他代码教程：
导入 numpy 作为 np
导入 pandas 作为 pd
导入 matplotlib.pyplot 作为 plt
从 sklearn.datasets 导入 load_iris
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn 导入 decomposition
导入 seaborn 作为 sns； sns.set_style(&quot;whitegrid&quot;, {&#39;axes.grid&#39; : False})

%matplotlib inline
np.random.seed(0)

# 鸢尾花数据集
DF_data = pd.DataFrame(load_iris().data, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])],
columns = load_iris().feature_names)

Se_targets = pd.Series(load_iris().target, 
index = [&quot;iris_%d&quot; % i for i in range(load_iris().data.shape[0])], 
name = &quot;Species&quot;)

# 缩放平均值 = 0, var = 1
DF_standard = pd.DataFrame(StandardScaler().fit_transform(DF_data), 
index = DF_data.index,
columns = DF_data.columns)

# Sklearn 用于主成分分析

# 维度
m = DF_standard.shape[1]
K = 2

# PCA（我倾向于如何设置它）
M_PCA = decomposition.PCA(n_components=m)
DF_PCA = pd.DataFrame(M_PCA.fit_transform(DF_standard), 
columns=[&quot;PC%d&quot; % k for k in range(1,m + 1)]).iloc[:,:K]

# 绘制特征向量
#https://stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

# 这就是事情变得奇怪的地方...
data = DF_standard

mu = data.mean(axis=0)
特征向量，特征值 = M_PCA.components_, M_PCA.explained_variance_ #eigenvectors, eigenvalues, V = np.linalg.svd(data.T, full_matrices=False)
projected_data = DF_PCA #np.dot(data, eigenvectors)

sigma = projected_data.std(axis=0).mean()

fig, ax = plt.subplots(figsize=(10,10))
ax.scatter(projected_data[&quot;PC1&quot;], projected_data[&quot;PC2&quot;])
for axis, color in zip(eigenvectors[:K], [&quot;red&quot;,&quot;green&quot;]):
# start, end = mu, mu + sigma * axis ### 导致 &quot;ValueError: 需要解压的值太多（预期为 2）&quot;

# 所以我尝试了这个但我认为它不正确
start, end = (mu)[:K], (mu + sigma * axis)[:K] 
ax.annotate(&#39;&#39;, xy=end,xytext=start, arrowprops=dict(facecolor=color, width=1.0))

ax.set_aspect(&#39;equal&#39;)
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    </channel>
</rss>