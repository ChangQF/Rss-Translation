<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 25 May 2024 15:14:50 GMT</lastBuildDate>
    <item>
      <title>如何使用 xml 文件在 Pytorch 中训练模型？</title>
      <link>https://stackoverflow.com/questions/78532699/how-to-train-model-in-pytorch-with-xml-files</link>
      <description><![CDATA[我在文件夹 train 文件夹 gest_a 和 gest_b 中包含照片和 xml 文件。
如何在 pytorch 中使用它训练模型？
我想要实时识别 gest 的文件。我不使用 ipynb 文件，我只使用 .py 文件
预先感谢您的建议和解答]]></description>
      <guid>https://stackoverflow.com/questions/78532699/how-to-train-model-in-pytorch-with-xml-files</guid>
      <pubDate>Sat, 25 May 2024 14:06:01 GMT</pubDate>
    </item>
    <item>
      <title>我需要与目标服务器中的资源使用情况相关的 HTTP 请求数据集</title>
      <link>https://stackoverflow.com/questions/78532565/i-need-a-dataset-of-http-requests-related-to-the-resource-usage-in-the-target-se</link>
      <description><![CDATA[我设计了一个机器学习模型来预测 HTTP 请求在执行服务器中引起的资源负载。我正在努力寻找具有这两个请求的数据集。
任何人都知道包含 HTTP 请求信息的数据集，例如请求的上下文、类型（POST、GET...）主体大小、标头大小、一天中的时间和一周中的某一天以及任何其他参数，以及请求在 HTTP 数据集的同一时间戳期间对服务器资源或服务器 CPU、RAM、网络 IO 数据集的影响？
我想过生成合成数据，但我想不出如何生成现实的数据，因为如果我生成大量 HTTP 调用数据，然后生成资源某些特性的估计，标签将是太偏颇了。我正在考虑通过配置 Web 服务器来生成数据并在监控时对其进行攻击，但这会很长，不会有很多不同的服务......
如果有人了解现有数据集或有办法生成真实且多样化的合成数据，这将会有很大帮助。
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78532565/i-need-a-dataset-of-http-requests-related-to-the-resource-usage-in-the-target-se</guid>
      <pubDate>Sat, 25 May 2024 13:06:29 GMT</pubDate>
    </item>
    <item>
      <title>强化学习在完成数据分类后给予奖励，而不是一一进行，基于CNN的强化学习</title>
      <link>https://stackoverflow.com/questions/78532315/reinforcement-learning-give-reward-after-finishing-the-data-classification-inste</link>
      <description><![CDATA[我正在尝试编写一个基于强化的交易系统，在尝试这样做时，我能做的唯一方法是奖励每个动作的模型，但它实际上执行了糟糕的结果，并且无法添加我想要的所有参数。 F.E 我想添加这些参数，但为了“一一执行”模型中，我无法添加这些参数作为奖励，因为所有这些参数都可以在所有长空持有分类完成后返回
&lt;前&gt;&lt;代码&gt;
如果 roi_percent &lt; 30：
    f = 11.8
elif roi_percent &lt;&lt; 70：
    f = 9.5
elif roi_percent &lt;&lt; 140：
    f = 7.6
elif roi_percent &lt;&lt; 250：
    f = 6.4
elif roi_percent &lt;&lt; 340：
    f = 5
elif roi_percent &lt;&lt; 600：
    f = 3.6
elif roi_percent &lt;&lt; 1000：
    f = 2.46
elif roi_percent &lt;&lt; 1600：
    f = 1.34
别的：
    f = 0.7

sayi = self.条目号

如果萨伊 == 20：
    萨伊 = 70
埃利夫·萨伊10：
    萨伊 = 30 - (10*(10-萨伊))
埃利夫·萨伊20：
    萨伊 = 70 - (4*(20-萨伊))
别的：
    萨伊 = 70 - (1.6*(萨伊 - 20))

奖励 = (roi_percent * f) + (win_loss_ratio * 45) - ((self.max_drawdown * 440) / (93 - self.max_drawdown)) + (sharpe_ratio * 64) + sayi

我们还可以通过 DQN、DDQN、PPO、A2C 模型创建强化学习模型，但我想知道我们如何使用 GRU、LSTM、CNN 等模型来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78532315/reinforcement-learning-give-reward-after-finishing-the-data-classification-inste</guid>
      <pubDate>Sat, 25 May 2024 11:31:19 GMT</pubDate>
    </item>
    <item>
      <title>在OpenAI Gym中，MuJoCo Fetch版本1和版本2的结构是否相同？</title>
      <link>https://stackoverflow.com/questions/78531991/in-openai-gym-is-the-mujoco-fetch-version-1-is-the-same-structure-as-version-2</link>
      <description><![CDATA[我当前正在使用 OpenAI Gym MuJoCo Fetch 环境。由于 MuJoCo 已经开源，Fetch 环境的第 2 版很好地支持了这一点。但网上仍然有很多使用 Fetch 版本 1 的实现（需要手动安装 MuJoCo，而不是通过 pip）。我只是想确定一下版本1和版本2之间的区别。除了MuJoCo安装之外，环境本身是否有任何修改？非常感谢您的帮助。我将非常感谢您的回复。
在重新实现过程中，安装旧版本的 MuJoCo 对我来说既复杂又困难。所以我只是用 -v2s 替换了 Fetch-v1s，我不确定它是否正确，因为它一直失败。这个问题也可能是由于gym版本引起的，但是MuJoCo版本也可能会影响我的重新实现过程。]]></description>
      <guid>https://stackoverflow.com/questions/78531991/in-openai-gym-is-the-mujoco-fetch-version-1-is-the-same-structure-as-version-2</guid>
      <pubDate>Sat, 25 May 2024 09:22:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在缺失值的情况下训练模型并使用预测函数</title>
      <link>https://stackoverflow.com/questions/78531918/how-to-train-a-model-and-use-predict-function-while-having-missing-values</link>
      <description><![CDATA[我正在开发一个 ML 项目，我正在尝试训练一些分类模型，然后对测试 df 进行一些预测。
如何训练一个能够使用每个可用观察值的模型，无论它是否有缺失值？我如何做出预测？
我的 df 的大多数观察结果至少有一个缺失值。
为了训练我的模型，我使用了 caret 库。
例如，给定此模型：
control &lt;- trainControl(method=“cv”，number=10，search=“grid”，summaryFunction = TwoClassSummary，classProbs = TRUE)
unegrid &lt;- Expand.grid(.mtry=c(1:6))
rf &lt;- train(Target~.，data=train，method=“rf”，metric=“ROC”，tuneGrid=tunegrid，ntree=100，trControl=control)

然后我这样做出预测：
test$pred&lt;-predict(rf,test,&#39;prob&#39;)[,2]

在训练时，我已经尝试过这个 na.action 选项：

na.omit;

-na.exclude;

na.pass。

前两个工作正常，但如果我使用 na.pass 我会收到此错误：
出了点问题；所有 ROC 指标值均缺失：
      ROC Sens 规格    
 分钟。   ：NA 最小值。   ：NA 最小值。   : 不适用  
 第一季度：不适用 第一季度：不适用 第一季度：不适用  
 中位数 : NA 中位数 : NA 中位数 : NA  
 平均值：NaN 平均值：NaN 平均值：NaN  
 第三季度：不适用 第三季度：不适用 第三季度：不适用  
 最大限度。   ：不适用 最大。   ：不适用 最大。   : 不适用  
 不适用 :6 不适用 :6 不适用 :6    
错误：停止
警告()
1：Fold01 的模型拟合失败：mtry=1 randomForest.default(x, y, mtry = param$mtry, ...) 中的错误： 
  预测变量中不允许使用 NA

如果我使用前两个之一，当我进行预测时，我会得到与此类似的错误：
set(x, j = name, value = value) 中的错误： 
  提供了 199 个项目，分配给 5425 个项目

]]></description>
      <guid>https://stackoverflow.com/questions/78531918/how-to-train-a-model-and-use-predict-function-while-having-missing-values</guid>
      <pubDate>Sat, 25 May 2024 08:52:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不能只使用Keys来计算self-attention？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78531893/why-cant-we-use-only-keys-to-calculate-self-attention</link>
      <description><![CDATA[我正在阅读有关自我注意机制的内容，论文建议需要计算 3 件事：Key、Query 和 Value。据我了解，具有 Value 的原因是允许根据上下文（这是直观的）调整初始嵌入（在位置编码之后）。但是，我不明白为什么我们需要那里的查询以及为什么我们不能仅使用键进行相似度计算？提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78531893/why-cant-we-use-only-keys-to-calculate-self-attention</guid>
      <pubDate>Sat, 25 May 2024 08:42:13 GMT</pubDate>
    </item>
    <item>
      <title>通过 python 脚本使用模型</title>
      <link>https://stackoverflow.com/questions/78531849/using-a-model-via-python-script</link>
      <description><![CDATA[我可能听不懂复杂的建议和答案，但这是我的大学，我没有时间学习基础知识。
我正在尝试使用我通过 GTZAN 数据集创建的模型 - 音乐流派分类 (https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)
模型具有很高的准确性，但我没有得到令人满意的输出。我不知道需要多少信息，但我觉得我在使用的脚本中犯了一个错误。这是脚本。
导入tensorflow为tf
导入库
将 numpy 导入为 np

# 加载预训练模型
模型 = tf.keras.models.load_model(&#39;C:/Users/VOLKAN/Desktop/SonProject/model.keras&#39;)

# 定义流派（假设您有模型预测的固定流派列表）
types = [&#39;Blues&#39;, &#39;Classical&#39;, &#39;Country&#39;, &#39;Disco&#39;, &#39;Hip-hop&#39;, &#39;Jazz&#39;, &#39;Metal&#39;, &#39;Pop&#39;, &#39;Reggae&#39;, &#39;Rock&#39;] # 替换为实际流派名字

def extract_features(文件路径):
    y，sr = librosa.load（文件路径，持续时间= 30）
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=58)
    mfccs = np.mean(mfccs.T, 轴=0)
    特征 = mfccs[np.newaxis, ...]
    返回特征



def Predict_genre(文件路径):
    特征 = extract_features(文件路径)
    预测 = model.predict(features)
    Genre_index = np.argmax(预测，轴=1)[0]
    返回类型[genre_index]

# 用法示例
audio_file = &#39;C:/Users/VOLKAN/Desktop/Data/genres_original/classical/classical.00059.wav&#39; # 替换为您的音频文件路径
预测流派 = 预测流派（音频文件）
print(f&#39;预测的类型是：{predicted_genre}&#39;)


`
在模型中，我使用了CNN。模型具有 .keras 扩展名。]]></description>
      <guid>https://stackoverflow.com/questions/78531849/using-a-model-via-python-script</guid>
      <pubDate>Sat, 25 May 2024 08:21:11 GMT</pubDate>
    </item>
    <item>
      <title>基于 Python 的模型学习，使用 TF、Keras 和 NLTK 进行标记</title>
      <link>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</link>
      <description><![CDATA[我使用 Tensorflow、keras 和 nltk 进行标记化，用 Python 开发了一个聊天机器人模型。当我在 vs 终端中运行它时，它会显示时间戳和模型提供答案所需的时间，但我试图在使用 React 设计的网站中显示它。如何从输出中删除日志。我已经尝试了一切，包括抑制日志，除非它们很关键，但我仍然无法删除它们。
我尝试使用这个，但它不起作用，它仍然显示它们。我知道日志不是警告，因此它们可能不会因此被删除。
导入 os os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;3&#39;]]></description>
      <guid>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</guid>
      <pubDate>Sat, 25 May 2024 08:01:27 GMT</pubDate>
    </item>
    <item>
      <title>MODIS图像增强优化模型</title>
      <link>https://stackoverflow.com/questions/78531465/image-enhancement-optimum-model-for-modis</link>
      <description><![CDATA[我正在尝试将超分辨率模型应用于 MODIS 500m 图像，以便将其分辨率缩小到 Sentinel-2 的 60m 光谱带。
我知道这是一项非常具有挑战性的任务，因为我的数据集仅包含 20000 张图像，而且到目前为止我还没有在文献中发现类似的内容。
我尝试过实现多种架构，从简单的 CNN 到更复杂的 SRGAN，但我的结果与预期输出相去甚远。您有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78531465/image-enhancement-optimum-model-for-modis</guid>
      <pubDate>Sat, 25 May 2024 05:21:54 GMT</pubDate>
    </item>
    <item>
      <title>A3C 代理（连续动作空间）没有经过适当的训练，只能达到</title>
      <link>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</guid>
      <pubDate>Sat, 25 May 2024 05:21:08 GMT</pubDate>
    </item>
    <item>
      <title>在 CNN 推理中跳过零乘法</title>
      <link>https://stackoverflow.com/questions/78531437/skipping-zero-multiplications-in-cnn-inference</link>
      <description><![CDATA[我在 MNIST 上有一个预训练的 CNN 模型，每次都会加载经过训练的权重和偏差来运行推理。有什么方法可以仅在推理阶段跳过 conv 和 fc 层中的零操作（我不想重新训练它，因此它不需要反向传播）？
由于 MNIST 图像很稀疏，因此我预计跳过零操作时的执行时间会少得多。工作的最优性对我来说并不是那么重要，我只是想看看输入的不同零率下执行时间有多少差异。
我尝试了一些用于 sprase 卷积的存储库，但他们正在考虑您在之后重新训练模型。我期望在 Pytorch 代码中找到一个简单的更改，只跳过零操作。还尝试找到一种方法来更改 Pytorch 的 C++ 代码库，但我无法弄清楚。]]></description>
      <guid>https://stackoverflow.com/questions/78531437/skipping-zero-multiplications-in-cnn-inference</guid>
      <pubDate>Sat, 25 May 2024 05:06:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 xgboost 推断 csv 数据时出现问题</title>
      <link>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</link>
      <description><![CDATA[我在使用 xgboost 进行推断时遇到问题：
简单来说，我想使用 xgboost 执行回归任务，由多个 csv 数据集组成。我将它们拼接成一个数据帧，并使用 train_test_split 分割训练/验证/测试。该模型运行良好（mae：0.6）。但是当我手动拆分训练集和测试集（我挑选了一部分 csv 并将其放入测试文件夹中）时，结果变得非常差（mae：12+）。
我真的很想知道这里发生了什么？我已经发布了下面的一些代码。
1：这是带有train_test_split的分割代码：
# 准备好数据
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 合并数据集
[merged_dataset = pd.concat([pd.DataFrame(dataset.X) 用于数据集中的数据集])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)

# 除法
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.2，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

# 构建xgboost模型
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_test_original, y_test_pred)]

2：这是我在代码后的手动划分：
# 训练数据集
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 测试数据，这是我从原始数据中手动分区的测试集的 csv
测试=[]
test_file = &#39;../data/test_xgboost/Thermal014withMidPos.csv&#39;
测试 = ThermalDataset(test_file)
测试.追加（测试）

＃ 结合
merged_dataset = pd.concat([数据集中的数据集的pd.DataFrame(dataset.X)])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
test_x = pd.concat([pd.DataFrame(test.X) 用于测试中的测试])
test_y = pd.concat([pd.DataFrame(test.y) 用于测试中的测试])

# 标准化
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)
x_fill = 缩放器.fit_transform(test_x)
y_fill = 缩放器.fit_transform(test_y)

＃ 分裂
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.05，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

＃ 火车
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred_scaled = model.predict(X_val)
y_test_pred_scaled = model.predict(X_test)
y_fill_res = model.predict(x_fill)

# inverse_transform 获取原始数据
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_pre = scaler.inverse_transform(y_fill_res.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
y_fill = scaler.inverse_transform(y_fill.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_pre, y_fill)`

我希望能够对单个 csv 文件进行正确推理，并获得与训练中一样好的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</guid>
      <pubDate>Sat, 25 May 2024 02:40:08 GMT</pubDate>
    </item>
    <item>
      <title>langchain RetrievalQA 错误：ValueError：缺少一些输入键：{'query'}</title>
      <link>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</link>
      <description><![CDATA[在 RAG 项目中，我使用 langchain。当我使用查询输入运行 QA 链时，此错误不断出现：
----&gt;;结果 = qa_chain({&#39;查询&#39;: 问题})
ValueError：缺少一些输入键：{&#39;query&#39;}

这是我的代码：
from langchain.chains import RetrievalQA
从 langchain.prompts 导入 PromptTemplate

# 构建提示
template = &quot;&quot;&quot; 根据以下上下文回答问题。
    语境：
    {语境}
    ------------------
    问题：{查询}
    答案：“”

# 法学硕士链
QA_CHAIN_PROMPT = PromptTemplate.from_template(模板)
qa_chain = RetrievalQA.from_chain_type(
    嗯，
    检索器=vectordb.as_retriever(),
    return_source_documents=真，
    chain_type_kwargs={“提示”: QA_CHAIN_PROMPT}
）

Question =“这篇研究论文使用了什么方法？”

结果 = qa_chain({&#39;查询&#39;: 问题})

# 查看查询结果
结果[“结果”]
# 检查我们所在的源文档 
结果[“源文档”][0]
]]></description>
      <guid>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</guid>
      <pubDate>Fri, 24 May 2024 21:23:49 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我相信问题不在于我的代码，而在于库冲突，但我不确定。
导入 pandas 作为 pd
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
从 sklearn.preprocessing 导入 StandardScaler #actually scikit-learn
从 imblearn.over_sampling 导入 RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
    X = dataframe[dataframe.columns[:-1]].values
    Y = dataframe[dataframe.columns[-1]].values

    定标器=标准定标器() 
    X = 缩放器.fit_transform(X) 

    如果过采样：
        ros = RandomOverSampler()
        X, Y = ros.fit_resample(X,Y) 
    数据 = np.hstack((X, np.reshape(Y, (-1, 1))))
    返回数据，X，Y

print(len(train[train[“班级”]==1]))
print(len(train[train[“班级”]==0]))

训练，X_train，Y_train =scale_dataset（训练，True）

我尝试完全导入sklearn，卸载并重新安装scipi和sklearn（作为scikit-learn），安装Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的分段似乎没有保存？关于totalsegmentator</title>
      <link>https://stackoverflow.com/questions/78516029/why-my-segmentations-dont-seem-to-be-saved-about-totalsegmentator</link>
      <description><![CDATA[我一步步按照您的教程进行操作，但得到的结果类似于分段未保存。
这是我输入的语句和得到的结果：
(d:\totalsegmentotar.conda) D:\totalsegmentotar&gt;TotalSegmentator -i hip_left.nii.gz -o 分段 -ta hip_implant

如果您使用此工具，请引用：https://pubs.rsna.org/doi/10.1148/ryai.230024

未检测到 GPU。在CPU上运行。这可能会非常慢。 &#39;--fast&#39; 或 --roi_subset 选项可以帮助减少运行时间。
生成粗糙的身体分割...
重新采样...
1.93 秒内重新采样
预测...
d:\totalsegmentotar.conda\Lib\site-packages\nnunetv2\utilities\plans_handling\plans_handler.py:37: UserWarning: 检测到旧的 nnU-Net 计划格式。尝试重构网络架构参数。如果失败，请为您的数据集重新运行 nnUNetv2_plan_experiment。如果您使用自定义架构，请将 nnU-Net 降级到您实现的版本或更新您的实现+计划。
warnings.warn(“检测到旧的 nnU-Net 计划格式。尝试重建网络架构”
100%|███████████████████████████████████████████████ ███████████████████████████████████████████████████ ███████████████████████████████████████████████████ ██| 1/1 [00:00&lt;00:00, 1.12it/s]
预测12.95秒后
重新采样...
警告：无法裁剪，因为未检测到前景
从 (333, 333, 539) 裁剪到 (333, 333, 539)
预测...
d:\totalsegmentotar.conda\Lib\site-packages\nnunetv2\utilities\plans_handling\plans_handler.py:37: UserWarning: 检测到旧的 nnU-Net 计划格式。尝试重构网络架构参数。如果失败，请为您的数据集重新运行 nnUNetv2_plan_experiment。如果您使用自定义架构，请将 nnU-Net 降级到您实现的版本或更新您的实现+计划。
warnings.warn(“检测到旧的 nnU-Net 计划格式。尝试重建网络架构”
100%|███████████████████████████████████████████████ ███████████████████████████████████████████████████ ███████████████████████████████████████████████████ | 64/64 [04:27&lt;00:00, 4.18s/it]
预测 288.96 秒
保存分段...
0%| | 0/1 [00:00
可以看到分割没有保存，我用切片器软件看确实没有预测结果，什么也没有显示。
当我使用`-tatotal时，分割器进度条发生变化，但不幸的是它似乎没有保存分割的结果。这是我的输出，以及在切片器 5.6.2 中打开的输出文件夹和图像，但没有显示任何内容。
这是我的 powershell 输出
这是我的输出文件夹和在切片器 5.6.2 中打开的图像]]></description>
      <guid>https://stackoverflow.com/questions/78516029/why-my-segmentations-dont-seem-to-be-saved-about-totalsegmentator</guid>
      <pubDate>Wed, 22 May 2024 07:52:18 GMT</pubDate>
    </item>
    </channel>
</rss>