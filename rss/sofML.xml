<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 21 Aug 2024 18:20:22 GMT</lastBuildDate>
    <item>
      <title>我如何测试梯度提升的假设？</title>
      <link>https://stackoverflow.com/questions/78898257/how-can-i-test-the-assumptions-of-gradient-boosting</link>
      <description><![CDATA[我正在尝试对我的数据使用梯度提升，但我不知道如何测试模型的假设。我知道梯度提升需要最低限度的假设。1) 可微分损失函数 2) 树的弱学习器。
是否有任何正式/非正式的方法来在 Python 中测试这两个假设？]]></description>
      <guid>https://stackoverflow.com/questions/78898257/how-can-i-test-the-assumptions-of-gradient-boosting</guid>
      <pubDate>Wed, 21 Aug 2024 17:19:29 GMT</pubDate>
    </item>
    <item>
      <title>尝试训练模型时，cv2 图像形状出现错误</title>
      <link>https://stackoverflow.com/questions/78897608/cv2-error-in-image-shape-while-trying-to-train-model</link>
      <description><![CDATA[我有 imgs、mask 和 labels 数据，我想使用 pytorch 和 dataloaders 创建分割模型
我在尝试训练自定义模型时收到此错误，我认为问题来自自定义数据集类
cv2.error: OpenCV(4.10.0) D:\a\opencv-python\opencv-python\opencv\modules\core\src\matrix_transform.cpp:784: error: (-215:Assertion failed) _src.dims() &lt;= 2 in function &#39;cv::flip&#39;

我的模型开始训练后，我立即收到此错误
这是我的自定义数据集代码：
class DatasetSeg (Dataset):

def __init__ (self, img_dir, mask_dir, label_dir, transform = None):

self.img_dir = img_dir
self.mask_dir = mask_dir
self.label_dir = label_dir
self.transform = transform
self.images = [img for img in os.listdir(img_dir) if img.endswith(&#39;.png&#39;)] 
self.indexes = self.getIndex()

def getIndex(self):

indexes = []
for img in self.images:
indexes.append(int(img[4:8])) #图像被命名为 rgb_XXXX.png
return indexes

def __len__(self):
return len(self.images)

def __getitem__(self, idx):

index = self.indexes[idx]

# 打印尺寸和类型以供调试

img_filename = f&#39;rgb_{index:04d}.png&#39;
mask_filename = f&#39;semantic_segmentation_{index:04d}.png&#39;
labels_filename = f&#39;semantic_segmentation_labels_{index:04d}.json&#39;

img_path = os.path.join(self.img_dir, img_filename)
mask_path = os.path.join(self.mask_dir, mask_filename)
label_path = os.path.join(self.label_dir, labels_filename)

使用 open(label_path, &#39;r&#39;) 作为文件：
labels = json.load(file)

image = Image.open(img_path).convert(&quot;RGB&quot;)
image = np.array(image)

mask = Image.open(mask_path).convert(&quot;RGBA&quot;)
mask = np.array(mask)

class_id_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.uint8)

color_to_class_id = {}

for class_id, color_str in enumerate(labels.keys()):
color = tuple(map(int, color_str.strip(&#39;()&#39;).split(&#39;,&#39;)))
color_to_class_id[color] = class_id

for color, class_id in color_to_class_id.items():

# color_array = np.array(color, dtype=mask.dtype) 
match = np.all(mask == color, axis=-1) #将像素与当前 RGBA 颜色匹配
# print(match)
class_id_mask[match] = class_id #将类 ID 分配给匹配的像素

image = np.transpose(image, (2,0,1))

if self.transform:
perceived = self.transform(image=image, mask=class_id_mask)
image = perceived[&#39;image&#39;]
mask = perceived[&#39;mask&#39;]

print(image.shape, class_id_mask.shape)
return image, class_id_mask

我尝试添加调试打印以查看图像的尺寸，这是 getitem 中打印的输出：(3, 720, 1280) (720, 1280)。]]></description>
      <guid>https://stackoverflow.com/questions/78897608/cv2-error-in-image-shape-while-trying-to-train-model</guid>
      <pubDate>Wed, 21 Aug 2024 14:44:54 GMT</pubDate>
    </item>
    <item>
      <title>根据 scikit-learn ColumnTransformer 访问用于归纳和规范化新数据的值</title>
      <link>https://stackoverflow.com/questions/78896943/accessing-the-values-used-to-impute-and-normalize-new-data-basded-upon-scikit-le</link>
      <description><![CDATA[因此，我使用 ´scikit-learn´ 在训练集上构建机器学习模型，然后在测试集上对它们进行评估。在训练集上，我使用 ColumnTransformer 执行数据插补和缩放，然后使用 Kfold CV 构建逻辑回归模型，最终模型用于预测测试集上的值。最终模型还使用 ColumnTransformer 的结果来插补测试集上的缺失值，例如，最小-最大标量将从训练集中获取最小值和最大值，并在缩放测试集时使用这些值。我如何才能看到这些从训练集中得出然后用于预测测试集的缩放值？我在 ´scikit-learn´ 文档中找不到有关它的任何信息。以下是我使用的代码：
来自 sklearn.linear_model 导入 SGDClassifier
来自 sklearn.model_selection 导入 RepeatedStratifiedKFold
来自 sklearn.model_selection 导入 GridSearchCV
来自 sklearn.compose 导入 ColumnTransformer
来自 sklearn.impute 导入 SimpleImputer
来自 sklearn.pipeline 导入 Pipeline
来自 sklearn.preprocessing 导入 MinMaxScaler、OneHotEncoder

def preprocessClassifierLR(categorical_vars, numeric_vars):###categorical_vars 和 numeric_vars 是定义 X 中存在的分类和数字变量的列名的列表

categorical_pipeline = Pipeline(steps=[(&#39;mode&#39;, SimpleImputer(missing_values=np.nan, strategies=&quot;most_frequent&quot;)),
(&quot;one_hot_encode&quot;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))])

numeric_pipeline = Pipeline(steps=[(&#39;numeric&#39;, SimpleImputer(strategy=&quot;median&quot;)),
(&quot;scaling&quot;, MinMaxScaler())])

col_transform = ColumnTransformer(transformers=[(&quot;cats&quot;, categorical_pipeline, categorical_vars),
(&quot;nums&quot;, numeric_pipeline, numeric_vars)])

lr = SGDClassifier(loss=&#39;log_loss&#39;, penalty=&#39;elasticnet&#39;)
model_pipeline = Pipeline(steps=[(&#39;preprocess&#39;, col_transform),
(&#39;classifier&#39;, lr)])

random_grid_lr = {&#39;classifier__alpha&#39;: [1e-1, 0.2, 0.5],
&#39;classifier__l1_ratio&#39;: [1e-3, 0.5]}

kfold = RepeatedStratifiedKFold(n_splits=10, n_repeats=10, random_state=47)

param_search = GridSearchCV(model_pipeline, random_grid_lr,scoring=&#39;roc_auc&#39;, cv=kfold, refit=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)

param_search = preprocessClassifierLR(categorical_vars, numeric_vars)
train_mod = param_search.fit(X_train, y_train)
print(&quot;Mod AUC:&quot;, train_mod.best_score_)

test_preds = train_mod.predict_proba(X_)[:,1]


我无法提供真实数据，但 X 是一个包含独立变量的数据框，y 是二元结果变量。train_mod 是一个包含列转换器和 SGD 分类器步骤的管道。我可以通过运行 train_mod.best_params_ 轻松从分类器中获取类似的参数信息，例如最佳 lambda 和 alpha 值，但我无法找出用于列转换器的统计数据，例如 1) 用于分类特征的简单插补器的模式，2) 用于数字特征的简单插补器的中值，以及 3) 用于缩放数字特征的最小值和最大值。有人知道如何访问这些信息吗？
提前致谢！
我假设 train_mod.best_estimator_[&#39;preprocess&#39;].transformers_ 包含此信息，类似于 train_mod.best_params_ 为我提供从模型训练中得出的 alpha 和 lambda 值，然后将其应用于测试集。]]></description>
      <guid>https://stackoverflow.com/questions/78896943/accessing-the-values-used-to-impute-and-normalize-new-data-basded-upon-scikit-le</guid>
      <pubDate>Wed, 21 Aug 2024 12:24:53 GMT</pubDate>
    </item>
    <item>
      <title>我在加载 hydra 的配置时遇到了一些问题</title>
      <link>https://stackoverflow.com/questions/78896800/i-get-some-problem-with-load-the-config-of-hydra</link>
      <description><![CDATA[我使用 Google colab 运行代码
code:
import hydra
from pathlib import Path # 导入文件路径处理路径
import sys # 导入 sys 模块
@hydra.main(config_path=&quot;cfgs&quot;, config_name=&quot;config.yaml&quot;)
def main(cfg):
print(cfg) # 打印解析后的配置

from train import Workspace as W

root_dir = Path.cwd()

workspace = W(cfg)

snapshot = root_dir / &#39;snapshot.pt&#39;

if snap.exists():

print(f&#39;resuming: {snapshot}&#39;)

workspace.load_snapshot()

workspace.train()

if name == &#39;ma​​in&#39;:
main()
输出：
用法：colab_kernel_launcher.py [--help] [--hydra-help] [--version] [--cfg {job,hydra,all}]
[--resolve] [--package PACKAGE] [--run] [--multirun]
[--shell-completion] [--config-path CONFIG_PATH]
[--config-name CONFIG_NAME] [--config-dir CONFIG_DIR]
[--info [{all,config,defaults,defaults-tree,plugins,searchpath}]]
[overrides ...]
colab_kernel_launcher.py：错误：无法识别的参数：-f
发生异常，使用 %tb 查看完整回溯。
SystemExit：2
我想要修复此错误]]></description>
      <guid>https://stackoverflow.com/questions/78896800/i-get-some-problem-with-load-the-config-of-hydra</guid>
      <pubDate>Wed, 21 Aug 2024 11:54:28 GMT</pubDate>
    </item>
    <item>
      <title>在 ML 线性回归中绘制多特征数据</title>
      <link>https://stackoverflow.com/questions/78896787/plotting-multi-feature-data-in-ml-linear-regression</link>
      <description><![CDATA[我的问题是关于 sci-kit learn 背后究竟是如何工作的，特别是当我们用多个特征（X）拟合线性回归模型时，例如房价特征和一个 y（价格）

模型如何运作，绘制多特征数据，然后如何在背后为这些数据选择曲线？
我无法绘制数据。]]></description>
      <guid>https://stackoverflow.com/questions/78896787/plotting-multi-feature-data-in-ml-linear-regression</guid>
      <pubDate>Wed, 21 Aug 2024 11:52:23 GMT</pubDate>
    </item>
    <item>
      <title>在进行连续文本分析后更新和添加数据点时，如何计算和更新权重和分数？</title>
      <link>https://stackoverflow.com/questions/78896688/how-to-calculate-and-update-weights-and-score-when-updating-and-adding-data-poin</link>
      <description><![CDATA[我有以下场景。也许有人可以帮助我正确地做到这一点。
我正在做文本分析并得到一组带有分数的主题。我正在存储这些。
我将其保存如下。
`{
&quot;Topic&quot;: {
&quot;TopicName&quot;: &quot;/Computers &amp;电子/编程”，
“得分”：35.371166
}，
“TotalCountOfTopic”：70
}，
{
“主题”：{
“主题名称”：&quot;/科学/计算机科学&quot;，
“得分”：35.900078
}，
“TotalCountOfTopic”：69
}，
{
“主题”：{
“主题名称”：&quot;/商业&amp; Industrial&quot;,
&quot;Score&quot;: 38.20758
},
&quot;TotalCountOfTopic&quot;: 47
}`
我想要做的是随后进行第二批文本分析，并且我想要更新这些数字。
我采取的步骤如下。
将之前运行的分数与我拥有的分数平均，添加新的分数并找到中位数。
`var oldWeight = user.TotalAnalysis[oldTopicIndex].TotalCountOfTopic * user.TotalAnalysis[oldTopicIndex].Topic?.Score;
var totalCount = user.TotalAnalysis[oldTopicIndex].TotalCountOfTopic + 1; // 增加总数
 var updatedTopic = new TopicAverage()
{

Topic = new Topic()
{

Score = (oldWeight + newTopic.Score) / totalCount,// 更正后的加权平均计算

TopicName = newTopic.TopicName
}, 
TotalCountOfTopic = totalCount
};`

我认为这是正确的做法，但我很好奇社区是怎么想的。
谢谢
我采取的步骤如下。
将之前运行的分数与我已有的分数平均，添加新分数并找到中位数。]]></description>
      <guid>https://stackoverflow.com/questions/78896688/how-to-calculate-and-update-weights-and-score-when-updating-and-adding-data-poin</guid>
      <pubDate>Wed, 21 Aug 2024 11:26:23 GMT</pubDate>
    </item>
    <item>
      <title>GAN 模型中图形嵌入的反向传播运行时错误</title>
      <link>https://stackoverflow.com/questions/78896269/runtimeerror-on-backpropagation-in-a-gan-model-for-graph-embeddings</link>
      <description><![CDATA[我正在尝试学习如何在图形嵌入上创建 GAN，但一直遇到错误

RuntimeError：尝试第二次向后遍历图形（或在已释放已保存的张量后直接访问它们）。调用 .backward() 或 autograd.grad() 时，图形的已保存中间值将被释放。如果您需要第二次向后浏览图表，或者在调用向后调用后需要访问已保存的张量，请指定 retain_graph=True。

class Generator(nn.Module):
def __init__(self, label_dim, noise_dim, embedding_dim):
super(Generator, self).__init__()
self.fc1 = nn.Linear(label_dim + noise_dim, 64)
self.fc2= nn.Linear(64, embedding_dim)

def forward(self, label, noise):
label = label.unsqueeze(1).float()
x = torch.cat([label, noise], dim=1)
x = torch.relu(self.fc1(x))
x = self.fc2(x)
return x

class Discriminator(nn.Module):
def __init__(self, embedding_dim):
super(Discriminator, self).__init__()
self.fc1 = nn.Linear(embedding_dim, 64)
self.fc2 = nn.Linear(64, 1)

def forward(self, x):
x = torch.relu(self.fc1(x))
x = torch.sigmoid(self.fc2(x))
return x

subset_size =1000
batch_size = 32
num_epochs = 100
noise_dim = 32
embedding_dim = 32
label_dim = 1

graph_embeddings = torch.stack(graph_embeddings_list).to(device)

dataset = TensorDataset(graph_embeddings,indexed_labels_tensor)

subset_indices = torch.randperm(len(graph_embeddings))[:subset_size]
subset = torch.utils.data.Subset(dataset, subset_indices)

dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)

device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;)

generator = Generator(label_dim=label_dim, noise_dim=noise_dim, embedding_dim=embedding_dim).to(device)
discriminator = Discriminator(embedding_dim=embedding_dim).to(device)

optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)

criterion = nn.BCELoss()

for epoch in range(num_epochs):
for n, (real_embeddings, labels) in enumerate(dataloader):

real_samples_labels = torch.ones((real_embeddings.size(0), 1)).to(device=device)
generated_samples_labels = torch.zeros((real_embeddings.size(0), 1)).to(device=device)

print(&quot;生成的样本形状：&quot;, generated_samples_labels.shape)
print(&quot;真实样本形状：&quot;, real_samples_labels.shape)

real_embeddings = real_embeddings.to(device=device)
labels = labels.to(device=device)

latent_space_samples = torch.randn((labels.size(0), noise_dim)).to(device=device)
generated_samples = generator(labels, latent_space_samples)

all_samples = torch.cat((real_embeddings, generated_samples)).to(torch.float32)
all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels)).to(torch.float32)

discriminator.zero_grad()

output_discriminator = discriminator(all_samples)

print(&quot;判别器输出形状：&quot;, output_discriminator.shape)
print(&quot;判别器输出：&quot;, output_discriminator)

loss_discriminator = criterion(output_discriminator, all_samples_labels)

print(&quot;判别器后向损失：&quot;, loss_discriminator.item())
loss_discriminator.backward() 
print(&quot;已完成鉴别器的反向传递&quot;)
optimizer_D.step()

generator.zero_grad()

latent_space_samples = torch.randn((labels.size(0), noise_dim)).to(device=device)
generated_samples = generator(labels, latent_space_samples)

output_discriminator_generated = discriminator(generated_samples) 
loss_generator = criterion(output_discriminator_generated, real_samples_labels)

print(f&quot;生成器反向传递之前 - epoch {epoch}, batch {n}&quot;)
loss_generator.backward(create_graph=True)
print(f&quot;生成器反向传递之后 - epoch {epoch}, batch {n}&quot;)
optimizer_G.step()

if n == len(dataloader) - 1:
print(f&quot;Epoch: {epoch} Loss D.: {loss_discriminator.item()}&quot;)
print(f&quot;Epoch: {epoch} Loss G.: {loss_generator.item()}&quot;)


我尝试创建一个简单的 GAN 来计算与标签相关的图形嵌入。但错误发生在 loss_discriminator.backward() 部分。
我认为该过程是正确的。我尝试分离并重新计算 loss_generation 中的 output_discriminator，但都无济于事。我仍在学习 GAN 架构和图形数据结构。所以欢迎任何帮助！]]></description>
      <guid>https://stackoverflow.com/questions/78896269/runtimeerror-on-backpropagation-in-a-gan-model-for-graph-embeddings</guid>
      <pubDate>Wed, 21 Aug 2024 09:50:24 GMT</pubDate>
    </item>
    <item>
      <title>COCO json文件中分割值的面积是如何计算的？[关闭]</title>
      <link>https://stackoverflow.com/questions/78895866/how-is-the-area-of-segmentation-value-in-coco-json-file-calculated</link>
      <description><![CDATA[所以我刚刚浏览了一个 COCO JSON 文件，并遇到了一个称为 area 的字段。在使用 cv2.countNonZero() 函数之前，我已经计算了分割面积，并将二进制掩码传递给它，但我不知道 COCO JSON 中的面积值是如何计算的。它只是分割多边形所包围的像素数吗？
如果感兴趣，我在将 SAHI（切片辅助超推理）输出转换为 COCO 格式后获得了 JSON 输出。]]></description>
      <guid>https://stackoverflow.com/questions/78895866/how-is-the-area-of-segmentation-value-in-coco-json-file-calculated</guid>
      <pubDate>Wed, 21 Aug 2024 08:13:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用 model.summary() 时阻止 Jupyter 重新启动？</title>
      <link>https://stackoverflow.com/questions/78895569/how-to-stop-jupyter-from-restarting-when-using-model-summary</link>
      <description><![CDATA[我在 jupyter 上使用 keras，并尝试运行代码“model.summary()”。但是，jupyter 不断重新启动。
我曾尝试将 max_buffer_size 增加到 17gb，但没有成功。有人可以帮忙建议如何解决这个问题吗？谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78895569/how-to-stop-jupyter-from-restarting-when-using-model-summary</guid>
      <pubDate>Wed, 21 Aug 2024 07:03:20 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Selenium 中获得更快的 API 响应？</title>
      <link>https://stackoverflow.com/questions/78893351/how-to-get-a-faster-api-response-in-selenium</link>
      <description><![CDATA[我正在用 selenium 开发一个机器人，当日历在白天变绿时，它会从日历中选择一个日期，当日期变绿时，机器人会选择它，然后加载页面的其余部分以输入信息。但问题是日期只变绿了 2 秒，选择日期后，会向服务器生成一个请求，需要 3 秒才能响应，因此我的机器人在选择日期后出现错误，因为日期在 API 响应之前就变回了红色。我该如何解决这个问题，以便机器人可以在不到 2 秒的时间内完成日期选择过程，而不是 3 秒？
我尝试过隐式和显式等待，但都没有用]]></description>
      <guid>https://stackoverflow.com/questions/78893351/how-to-get-a-faster-api-response-in-selenium</guid>
      <pubDate>Tue, 20 Aug 2024 15:46:11 GMT</pubDate>
    </item>
    <item>
      <title>GradCam：层 Sequenced_1 从未被调用，因此没有定义的输出</title>
      <link>https://stackoverflow.com/questions/78889743/gradcam-the-layer-sequential-1-has-never-been-called-and-thus-has-no-defined-ou</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78889743/gradcam-the-layer-sequential-1-has-never-been-called-and-thus-has-no-defined-ou</guid>
      <pubDate>Mon, 19 Aug 2024 20:51:58 GMT</pubDate>
    </item>
    <item>
      <title>Val_accuracy 正在改变，有时它在补码之间交替（100％-val_acc）</title>
      <link>https://stackoverflow.com/questions/78885395/val-accuracy-inst-changing-and-sometimes-it-alternates-between-it-complement-10</link>
      <description><![CDATA[我被分配根据我读过的一篇论文来实现一个机器学习模型。
这篇论文实现了一个用于属性分类的多任务学习模型（带标签的图像是模型输入，带标签的意思是属性注释，每幅图像有 40 个）。
它是一个多任务学习模型，因为在模型输入层和 40 个属性分支之后有一个共享的密集层，每个分支都有自己的损失函数（所有分支的二元交叉熵）和自己的 S 型激活函数（在最后一层，用于预测 40 个属性中的每一个是否存在于图像中）。
经过大量艰苦的努力，它终于开始在所有分支上返回所有 S 型函数的概率，但只有 val_accuracy 的概率是错误的：val_loss 和损失（训练损失）越来越小，acc（训练准确度）也在正常的概率值范围内，除了 val_accuracy 总是相同的值或它的补码。
例如（仅举 5 个时期为例）：
40 个分支之一的一个属性预测的准确度：
5_o_Clock_Shadow_Accuracy
0 0.823665
1 0.891178
2 0.891178
3 0.891178

同一属性的损失：
 5_o_Clock_Shadow_loss
0 0.921046
1 0.701494
2 0.913597
3 0.765397
4 0.894950

val_loss：
val_5_o_Clock_Shadow_loss
0 730232.750000
1 300412.500000
2 376215.843750
3 0.747685
4 1.607191

最后是 val_Accuracy：
val_5_o_Clock_Shadow_Accuracy
0 0.882382
1 0.117618
2 0.882382
3   0.882382 4 0.882382  我的模型： def subnet(shared_layers_output, i): att_branch = Dense(512, name=&#39;dense_&#39;+str(i)+&#39;_1&#39;)(shared_layers_output) att_branch = ReLU()(att_branch) att_branch = BatchNormal ization()(att_branch) att_branch = Dropout(0.5)(att_branch) att_branch = Dense(512, name=&#39;dense_&#39;+str(i)+&#39;_2&#39;)(att_branch) att_branch = ReLU()(att_branch) att_branch = BatchNormalization()(att_branch) att_branch = Dropout(0.5)(att_branch)

branch_output = Dense(1, name=att_list[i],activation=&#39;sigmoid&#39;)(att_branch)

return branch_output

def multi_task_model():

#输入
input_layer = Input(shape=(512,), name=&#39;input_layer&#39;)

#共享网络（1 个网络）
shared_x = Dense(512, name=&#39;shared_dense_layer&#39;)(input_layer)
shared_x = ReLU()(shared_x)
shared_x = BatchNormalization()(shared_x)
shared_x = Dropout(0.5)(shared_x)

branch_outputs = list()
for i in range(40):
branch_outputs.append(subnet(shared_x, i))

model = Model(input_layer, branch_outputs, name=&#39;model&#39;)

返回模型


训练和测试输入形状：(n_samples, 512)
训练和测试标签输入形状：(40, n_samples)
学习率：1e-03

5_o_Clock_Shadow 损失、val_loss、acc 和 val_acc 超过 5 个时期
 损失 val_loss acc val_acc
0 0.422385 1.949578 0.864272 0.8873
1 0.354094 151.987991 0.888797 0.1127
2 0.354356 58.867992 0.888797 0.1127
3 0.352891 94.257980 0.888797 0.1127
4 0.353390 10.997763 0.888797 0.1127
]]></description>
      <guid>https://stackoverflow.com/questions/78885395/val-accuracy-inst-changing-and-sometimes-it-alternates-between-it-complement-10</guid>
      <pubDate>Sun, 18 Aug 2024 18:38:14 GMT</pubDate>
    </item>
    <item>
      <title>TypeError: max() 收到无效的参数组合 - 得到（str，int），但预期以下之一：</title>
      <link>https://stackoverflow.com/questions/68582886/typeerror-max-received-an-invalid-combination-of-arguments-got-str-int</link>
      <description><![CDATA[我使用 FCN ResNet50 模型对文档图像进行语义分割。我一直在尝试解决这个问题，但到目前为止还没有成功。这是 google colab 上该模型的链接：https://colab.research.google.com/drive/1slJilG1ZBOsk6AqM6AOUaaCxHFSXVMCM?usp=sharing
这是错误：
TypeError：Traceback（最近一次调用最后一次）
&lt;ipython-input-12-f6d0f244c03c&gt;在 &lt;module&gt;() 中
13 
14 model_ft = train_model(final_model, train_dl, criterion, optimizer_ft, exp_lr_scheduler,
---&gt; 15 num_epochs=25)

&lt;ipython-input-11-683ce68860de&gt; 在 train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs) 中
31 使用 torch.set_grad_enabled(phase == &#39;train&#39;):
32 输出，aux = model(inputs.float())
---&gt; 33 _, preds = torch.max(outputs, 1)
34 loss = criterion(outputs, labels)
35 

TypeError: max() 收到无效的参数组合 - 得到 (str, int)，但预期为以下之一：
* (Tensor input)
* (Tensor input, Tensor other, *, Tensor out)
* (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)
* (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)
]]></description>
      <guid>https://stackoverflow.com/questions/68582886/typeerror-max-received-an-invalid-combination-of-arguments-got-str-int</guid>
      <pubDate>Thu, 29 Jul 2021 21:18:47 GMT</pubDate>
    </item>
    <item>
      <title>进行预测时如何处理未包含在训练集中的标签[关闭]</title>
      <link>https://stackoverflow.com/questions/58627102/how-to-deal-with-label-that-not-included-in-training-set-when-doing-prediction</link>
      <description><![CDATA[例如，使用监督学习对 5 个不同的人脸进行分类。
但是当对训练集中没有出现的第 6 个人脸进行测试时，模型仍然会将其预测在 5 个人之内。
当模型之前没有训练过第 6 个人及以后的人脸时，如何让模型将其预测为未知？]]></description>
      <guid>https://stackoverflow.com/questions/58627102/how-to-deal-with-label-that-not-included-in-training-set-when-doing-prediction</guid>
      <pubDate>Wed, 30 Oct 2019 14:01:46 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的 `view()` 起什么作用？</title>
      <link>https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch</link>
      <description><![CDATA[view() 对张量 x 做了什么？负值代表什么？
x = x.view(-1, 16 * 5 * 5)
]]></description>
      <guid>https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch</guid>
      <pubDate>Mon, 27 Feb 2017 07:21:10 GMT</pubDate>
    </item>
    </channel>
</rss>