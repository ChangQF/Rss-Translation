<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sat, 22 Mar 2025 09:17:22 GMT</lastBuildDate>
    <item>
      <title>神经网络内存优化的数据加载</title>
      <link>https://stackoverflow.com/questions/79527073/data-loading-for-neural-network-memory-optimization</link>
      <description><![CDATA[  def load_training_data（pgn_file =&#39;lichess_elite_2022-02.pgn&#39;，max_games = 140000）：
数据= []
以开放（pgn_file）为a：
    对于我的范围（max_games）：
        game = Chess.pgn.Read_game（a）
        板= game.board（）
        用于game.mainline_moves（）：
            input_tensor = board_to_tensor（board）
            label = move_to_index（移动）
            data.append（（input_tensor，label））
            board.push（移动）
        如果我％20000 == 0，而我＆gt; 0：
            打印（f＆quot&#39;załadowanodane z {i}吉尔。
    打印（f&#39;załadowanodane z {max_games} gier。&#39;）
    印刷（&#39;ladowanie danychukońcone。&#39;）

x = [数据中的项目]
y = [数据中的项目]
x_train，x_test，y_train，y_test = train_test_split（x，y，test_size = 0.2，shuffle = false）

返回（x_train，y_train），（x_test，y_test）
 
这是一种用于为我的神经网络加载数据训练和验证的功能，我有16GB的RAM。在我用完RAM和计算机崩溃之前，我可以加载到150000年左右。 board_to_tensor将国际象棋库板转换为浮子的张量，777位代表当前板状态的数字和move_to_index简单地为任何播放的移动提供了唯一的数值。有什么方法可以优化RAM内存的明智，因为我相信我需要更多的一个时代的数据。]]></description>
      <guid>https://stackoverflow.com/questions/79527073/data-loading-for-neural-network-memory-optimization</guid>
      <pubDate>Sat, 22 Mar 2025 07:09:53 GMT</pubDate>
    </item>
    <item>
      <title>当训练模型使用KAFKA和RDL索引4096训练模型时的错误是否超出了尺寸4096的轴0</title>
      <link>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79526992/error-when-training-the-model-for-sensor-data-using-kafka-and-rdl-index-4096-is</guid>
      <pubDate>Sat, 22 Mar 2025 05:30:38 GMT</pubDate>
    </item>
    <item>
      <title>找到回归系数和sarimax的统计显着性</title>
      <link>https://stackoverflow.com/questions/79526168/finding-regression-coefficients-and-statistical-significance-in-sarimax</link>
      <description><![CDATA[我正在考虑在Python中实现Sarimax模型来制作时间序列，并且我想结合一些外源变量，例如温度和降雨mm。只是为了示例，可以说我的目标价值是“有多少人在外面”。是否可以通过沿回归系数或r^2的线路来了解我的外源变量在多大程度上有助于预测的结果（它们所扮演的角色多少）。之后，是否可以计算统计显着性？]]></description>
      <guid>https://stackoverflow.com/questions/79526168/finding-regression-coefficients-and-statistical-significance-in-sarimax</guid>
      <pubDate>Fri, 21 Mar 2025 17:12:33 GMT</pubDate>
    </item>
    <item>
      <title>在Es-Hyperneat算法中实际进化了什么？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79526118/whats-actually-getting-evolved-in-a-es-hyperneat-algorithm</link>
      <description><![CDATA[在ES-Hyperneat算法中，底物中的每个神经元都由生成连接模式的组成模式网络（CPPN）定义。让我们称之为“隐藏节点”中的神经元。而不是“子神经元。” 
 CPPN中的每个隐藏节点具有随机分配的激活函数，并将基板神经元的坐标作为输入（尽管我仍然不确定这些坐标准确表示什么）。 CPPN的输出决定了基材中神经元之间连接的重量。
我们是否会进化和扩展底物神经元和CPPN隐藏节点，或者仅在cppn中只有隐藏的节点？另外，底物的拓扑是如何随着时间的流逝而发展的？]]></description>
      <guid>https://stackoverflow.com/questions/79526118/whats-actually-getting-evolved-in-a-es-hyperneat-algorithm</guid>
      <pubDate>Fri, 21 Mar 2025 16:51:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在pytorch中抑制model.load_state_dict（）的警告？</title>
      <link>https://stackoverflow.com/questions/79525759/how-to-suppress-warnings-from-model-load-state-dict-in-pytorch</link>
      <description><![CDATA[我正在使用加载模型检查点
  model.load_state_dict（state_dict，strict = false）
 
因为模型体系结构与权重完全不匹配。正如预期的那样，这会导致这样的警告消息：
 模型和加载状态dict不完全匹配
Source state_dict中的意外键：backbone.blocks.0.mlp.experts.0.
 
警告很长，因为有很多意外的钥匙。我了解这只是一个警告，而不是实际错误，我想完全压制或隐藏此消息。
有没有干净的方法可以在pytorch中进行？]]></description>
      <guid>https://stackoverflow.com/questions/79525759/how-to-suppress-warnings-from-model-load-state-dict-in-pytorch</guid>
      <pubDate>Fri, 21 Mar 2025 14:33:56 GMT</pubDate>
    </item>
    <item>
      <title>Google Colab：模型培训会自动停止，好像按下Ctrl+C</title>
      <link>https://stackoverflow.com/questions/79524578/google-colab-model-training-stops-automatically-as-if-ctrlc-was-pressed</link>
      <description><![CDATA[我正在Google Colab中训练Yolo模型，但是训练会自动停止，好像我手动按下CTRL+C一样。终端中的最后一个输出显示 ^C，该过程终止而没有任何错误消息。
 没有错误，只有 ^c ^c看起来好像我手动中断   ]]></description>
      <guid>https://stackoverflow.com/questions/79524578/google-colab-model-training-stops-automatically-as-if-ctrlc-was-pressed</guid>
      <pubDate>Fri, 21 Mar 2025 04:58:16 GMT</pubDate>
    </item>
    <item>
      <title>catboost问题？ numpy.dtype的大小改变了，可能表明二进制不兼容。预计从C头96，从PyObject获得88 [封闭]</title>
      <link>https://stackoverflow.com/questions/79524538/catboost-problem-numpy-dtype-size-changed-may-indicate-binary-incompatibility</link>
      <description><![CDATA[ ＃基本导入
导入numpy作为NP
导入大熊猫作为pd
导入matplotlib.pyplot作为PLT 
进口海洋作为SNS
＃建模
来自sklearn.metrics导入均值_squared_error，r2_score
来自Sklearn.neighbors进口kneighborsregressor
从Sklearn.Tre Import DecisionTreeTreeGressor
来自Sklearn.smentermemble Import RandomForestRegressor，adaboostregressor
来自Sklearn.svm导入SVR
来自sklearn.linear_model导入线性重试，山脊，拉索
来自sklearn.metrics import r2_score，mean_absolute_error，mean_squared_error
来自sklearn.model_selection导入随机搜索
来自Catboost Import Catboostregressor
从XGBoost Import XGBRegressor
进口警告
 
当我评论catboost 时，一切都完美地导入
使用Python 3.12.0 
我已经尝试过：

 升级所有相关库（pip install -upgrade＆lt; package_name＆gt;）。

 检查使用PIP列表的过时的软件包 - 已前。

 创建一个新的虚拟环境并重新安装所有内容。


 ive尝试了numpy（＆lt; 2.0.0）的不同版本下载
如何解决这个问题？
错误：
  value error trackback（最近的最新呼叫）
[17]中的单元，第15行
     13来自sklearn.metrics导入r2_score，mean_absolute_error，mean_squared_error
     14来自sklearn.model_selection导入随机搜索
---＆gt; 15来自Catboost Import Catboostregressor
     16来自XGBoost Import XGBRegressor
     17进口警告

文件D：\ git-repos \ end-to-end \ venv \ lib \ lib \ site-packages \ catboost \ catboost \ __ init__.py:1
----＆gt; 1来自.core导入（
      2个功能data，efstrtype，eshapcalctype，efeatureslectionalgorithm，efeaturesleslectiongrouping，
      3池，catboost，catboostClassifier，catboostregressor，catboostranker，catboostror，简历，sample_gaussian_process，train，train，
      4 sum_models，_have_equal_features，to_regressor，to_classifier，to_ranker，multiregressioncustompomtric，
      5个多何件限制态原则，多坐维仪，多坐维群岛。
      6）＃NOQA
      7来自.version导入版本为__vers__＃noqa
      8 __ all__ = [
      9&#39;featuresdata&#39;，&#39;efstrype&#39;，&#39;eshapcalctype&#39;，&#39;efeatureSelectionalgorithm&#39;，&#39;efeatureSelectiongrouping&#39;，&#39;
     10“池”，“ catboost”，“ catboostClassifier”，“ catboostregressor&#39;，&#39;catboostranker&#39;，&#39;catboostror&#39;，&#39;catboostror&#39;，&#39;
   （...）13&#39;MultitargetCustomtric&#39;，&#39;MultitargetCustomObjective&#39;
     14]

文件D：\ git-repos \ end-to-end \ venv \ lib \ site-packages \ catboost \ core.py.py：45
     40通行证
     42进口Scipy.sparse
---＆gt; 45来自.plot_helpers导入save_plot_file，try_plot_offline，offlineMetricVisualizer
     46来自。导入_catboost
     47来自.metrics Itmotinmetric

文件D：\ git-repos \ end-to-end \ venv \ lib \ site-packages \ catboost \ catboost \ plot_helpers.py：5
      2导入OS
      3进口警告
----＆gt; 5来自。导入_catboost
      6 fspath = _catboost.fspath
      9 def try_plot_offline（图）：

文件_catboost.pyx：1，在init _catboost（）中

ValueError：numpy.dtype的大小更改，可能表示二进制不兼容。预计从C标头96，从PyObject获得88
 ]]></description>
      <guid>https://stackoverflow.com/questions/79524538/catboost-problem-numpy-dtype-size-changed-may-indicate-binary-incompatibility</guid>
      <pubDate>Fri, 21 Mar 2025 04:15:41 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的代码不导致张量的错误“元素0”不需要毕业，也不需要grad_fn'</title>
      <link>https://stackoverflow.com/questions/79524465/why-does-not-my-code-cause-the-error-element-0-of-tensors-does-not-require-grad</link>
      <description><![CDATA[给定下面的代码片段，我使用 model.fc1.requires_grad_（false） and  model.fc2.requires_grad_（false）冻结神经网络的权重。
如果我使用损失=标准（输出，y_batch）来计算损失，则训练很好。但是，当我使用 lose = Compute_loss（Model）计算损失时，我会得到错误 RuntimeError：Tensors的Element 0不需要Grad，并且没有Grad_fn 。为什么不 lose = Criterion（输出，y_batch）导致错误？
  def Compute_loss（模型）：
    对于_，params中的params.named_pa​​rameters（）：
        损失= sum（参数）
    回报损失

类SimpleNet（nn.Module）：
    def __init __（self，input_size，hidden_​​size，output_size）：
        超级（SimpleNet，Self）.__ INIT __（）
        self.fc1 = nn.linear（input_size，hidden_​​size）
        self.fc2 = nn.linear（hidden_​​size，output_size）

    def向前（self，x）：
        x = self.fc1（x）
        x = self.fc2（x）
        返回x

model = simpleNet（input_size，hidden_​​size，output_size）

标准= nn.Crossentropyloss（）
优化器= Optim.SGD（model.parameters（），lr = Learning_rate）

对于范围（num_epochs）的时代：
    对于emumerate（dataloader）中的batch_idx（x_batch，y_batch）：
        优化器.zero_grad（）
        输出=模型（x_batch）
        损失=标准（输出，y_batch） 
        ＃损失= compute_loss（模型）
         
        loss.backward（） 
        优化器.step（） 
                
        if（batch_idx + 1）％10 == 0：
            model.fc1.requires_grad_（false）
            model.fc2.requires_grad_（false）
                        
打印（“训练完成！”）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79524465/why-does-not-my-code-cause-the-error-element-0-of-tensors-does-not-require-grad</guid>
      <pubDate>Fri, 21 Mar 2025 02:40:41 GMT</pubDate>
    </item>
    <item>
      <title>如何根据整天的订单时间正确群集每日交货方式？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79524308/how-to-correctly-cluster-daily-delivery-patterns-based-on-order-time-through-the</link>
      <description><![CDATA[我有一个数据集，该数据集在不同时间记录每天的订单数（交货），我正在尝试使用聚类来识别高峰交付期。但是，我在获得有意义的集群方面面临着挑战。
我尝试的是：
 dbscan：

 在这个时间序列的数据中努力识别单独的簇。

 它要么将所有内容分为一个群集，要么产生了太多的小噪声点。


分层聚类：

 多个峰的顶部被分组到同一群集中。

 多个山谷的底部也分为类似的集群。

 结果，我只得到四个主要集群，这与不同的基于时间的峰。


我需要帮助：

 如何更好地段交付时间？

 高斯混合模型（GMM），K-均值或特定时间序列的聚类会更好吗？

 我应该尝试的功能工程技术，例如以不同的方式汇总数据或转换时间变量？


 图形强调部分  
 带有彩色部分的图形  
代码
 
x = df [&#39;time_in_minutes&#39;]。values.reshape（-1，1）
y = df [&#39;orders&#39;]。values.reshape（-1，1）

＃使用Min-Max缩放扩展数据
sualer = minmaxscaler（）
X_SCALED = Scaleer.fit_transform（x）
y_scaled = scale.fit_transform（y）

＃结合聚类的功能
data_scaled = np.hstack（（x_scaled，y_scaled））

＃情节树状图（更好的可视化）
plt.figure（无花果=（12，6））
plt.title（层级聚类的树状图；）
plt.xlabel（“数据点”）
plt.ylabel（“距离”）

＃使用truncate_mode避免压缩问题
sch.dendrogram（sch.linkage（data_scaled，method =&#39;ward&#39;），truncate_mode =＆quot;
plt.show（）

＃应用分层集群
num_clusters = 4＃根据树状图调整
hc = groclomerativeclustering（n_clusters = num_clusters，metric =&#39;euclidean&#39;，linkage =&#39;ward&#39;）
df [&#39;cluster&#39;] = hc.fit_predict（data_scaled）

＃带有不同颜色的绘图群集（修复：使用数字time_in_minutes）
plt.figure（无花果=（12，6））
对于范围内的群集（num_clusters）：
    plt.scatter（df.loc [df [&#39;cluster&#39;] == cluster，&#39;time_in_minutes&#39;]， 
                df.loc [df [&#39;cluster&#39;] ==群集，&#39;arrivals&#39;]， 
                label = f&#39;cluster {cluster}&#39;，alpha = 0.7）

plt.xlabel（&#39;time（分钟）&#39;）
plt.ylabel（“订单”）
plt.title（“随着时间的时间订单”）
plt.legend（）
plt.grid（true，linestyle =&#39; - &#39;，alpha = 0.5）
plt.show（）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79524308/how-to-correctly-cluster-daily-delivery-patterns-based-on-order-time-through-the</guid>
      <pubDate>Thu, 20 Mar 2025 23:51:07 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Codebert嵌入识别类似的代码零件？</title>
      <link>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</link>
      <description><![CDATA[我正在使用Codebert比较两个代码的相似性。例如：
 ＃代码1
def calculate_area（半径）：
返回3.14 *半径 *半径
 
 ＃代码2
def Compute_circle_area（R）：
返回3.14159 * r * r
 
 Codebert创建“嵌入”就像对代码的详细描述为数字。然后，我比较这些数值描述，以查看代码的相似之处。这对于告诉我多少代码是相似的。
但是，我无法分辨Codebert认为哪些部分相似。因为“嵌入”很复杂，我无法轻易看到Codebert的重点。比较逐字代码在这里不起作用。
我的问题是：我如何找出两个代码段的哪些特定部分Codebert认为相似，而不仅仅是获得一般相似性得分？
我尝试了简单的DIFF方法，但这违反了纯粹使用Codebert的目的。
我想知道是否可以单独使用Codebert。]]></description>
      <guid>https://stackoverflow.com/questions/79523261/how-to-identify-similar-code-parts-using-codebert-embeddings</guid>
      <pubDate>Thu, 20 Mar 2025 14:30:35 GMT</pubDate>
    </item>
    <item>
      <title>如何将“ data.irearner”模型转换为azure ml中的“ model.pkl”？</title>
      <link>https://stackoverflow.com/questions/79477586/how-to-convert-data-ilearner-model-to-model-pkl-in-azure-ml</link>
      <description><![CDATA[我在Azure ML中创建了一个管道，该管道使用提升决策树回归训练模型。从我的理解来看，该模型被保存为  data.Ilerner  。。
但是，我无法将此模型转换为  model.pkl  格式，可以使用 joblib 。加载。
 问题： 

如何在 azure ml 中创建 model.pkl 为提升决策树回归模型？
在

  我试图使用以下python脚本加载和转换模型：
 导入lightgbm作为lgb
导入约伯利布

＃加载LightGBM型号
model = lgb.booster（model_file =＆quot; data.ilerner; quot;）

＃另存为泡菜文件
Joblib.dump（Model，“ Model.pkl”） 
 
但是运行脚本时，我会收到以下错误：
 ％python3 convert_to_model_pkl.py 
[LightGBM] [致命]模型文件数据中未知模型格式或子模型类型
Trackback（最近的最新电话）：
  file＆quot＆quot＆quot＆tomasz.olchawa/ng/ml/convert_to_model_pkl.py&quot;，5，第5行，in＆lt; module＆gt;
    model = lgb.booster（model_file =＆quot; data.ilerner; quot;）
  file＆quot＆quot＆quot tomasz.olchawa/ng/ml/myenv/lib/python3.13/site-packages/lightgbm/basic.py&quot; line 3697，in __init__ in __init__
    _safe_call（
    ~~~~~~~~~~^
        _lib.lgbm_boostercreatefrommodelfile（
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^”
    ...＆lt; 3行＆gt; ...
        ）
        ^
    ）
    ^
  file＆quot＆quot /../ ng/ml/myenv/lib/python3.13/site-packages/lightgbm/basic.py，第313行，在_safe_call中
    提高lightgbmerror（_lib.lgbm_getlasterror（）。解码（&#39;utf-8＆quot））
lightgbm.basic.lightgbmerror：未知模型格式或模型文件中的子模型类型
 ]]></description>
      <guid>https://stackoverflow.com/questions/79477586/how-to-convert-data-ilearner-model-to-model-pkl-in-azure-ml</guid>
      <pubDate>Sat, 01 Mar 2025 12:45:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么拥抱面提供的DeepSeek代码会导致“未知量化类型”错误？</title>
      <link>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</link>
      <description><![CDATA[我正在使用huggingface的此代码：
此代码直接从 deepseek上的huggingface网站页面上的页面

 来自变形金刚导入管道

消息= [
{&#39;&#39;：＆quot“ user quot”内容“：;
这是给出的
pipe =管道（＆quot&#39;text-generation＆quot; deepseek-ai/deepseek-r1＆quort; trust_remote_code = true）
管道（消息）
 

，但我无法加载模型。当我这样做时，我会得到这个问题：
  file＆quot＆lt; ...＆gt;/site-packages/transformers/quantizers/auto.py＆quot;，第97行，在from_dict

提高价值Error（

ValueError：未知量化类型，获得FP8-支持类型为： 
[&#39;awq&#39;，&#39;bitsandbytes_4bit&#39;，&#39;bitsandbytes_8bit&#39;，&#39;gptq&#39;，&#39;aqlm&#39;，&#39;quanto&#39;，&#39;eetq&#39;，&#39;eetq&#39;， 
&#39;HQQ&#39;，“压缩张量”，“ fbgemm_fp8&#39;，&#39;torchao&#39;，&#39;bitnet&#39;]
 
我尝试了不同的代码：
 导入火炬
generate_text = pipeline（model =; deepSeek-ai/deepSeek-r1; torch_dtype = torch.bfloat16，trust_remote_code = true，device_map =; auto;
generate_text（消息）
 
这给出以下错误：

raise ValueError( ValueError: Unknown quantization type, got fp8 - supported types are: [&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39;, &#39;higgs&#39;, &#39;hqq&#39;, &#39;compressed-tensors&#39;, &#39;fbgemm_fp8&#39;, &#39;torchao&#39;，&#39;bitnet&#39;，&#39;vptq&#39;] 

我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>Llama2型号在设备MPS上运行时获取WERID符号</title>
      <link>https://stackoverflow.com/questions/78202731/llama2-model-get-werid-symbols-when-running-on-device-mps</link>
      <description><![CDATA[ 来自Transformers Import AutoTokenizer，AutoModelforCausAllm，BitsandBytesConfig，LlamaforCausallm

model_id =＆quot“ meta-llama/llama-2-7b-chat-hf”

tokenizer = autotokenizer.from_pretaining（model_id，token = os.environ [&#39;hf_token&#39;]）
model = automodelforcausallm.from_pretrataining（model_id，device_map =&#39;auto&#39;，token = os.environ [&#39;hf_token&#39;]）

文字=;指示：Quote：想象力更多。来自：＆quot;
设备=&#39;MPS&#39;
型号（设备）
inputs = tokenizer（text，return_tensors =; pt; quot;）。到（设备）
打印（输入）
输出= model.generate（**输入，max_new_tokens = 20）
print（tokenizer.decode（输出[0]，skip_special_tokens = true））
打印（输出）

＆gt;＆gt;＆gt;指示：Quote：想象力更多。来自：ralphљъ，2ъUrlso0\\。ћo0oљoo
 
我有奇怪的符号，例如“ralphљъ，2ъUrlso0.ћo0oљoo”。在MPS上运行时，但在CPU上工作正常。我在128克M2 Ultra Mac Studio上运行。]]></description>
      <guid>https://stackoverflow.com/questions/78202731/llama2-model-get-werid-symbols-when-running-on-device-mps</guid>
      <pubDate>Thu, 21 Mar 2024 20:50:47 GMT</pubDate>
    </item>
    <item>
      <title>如何激活yolov8的MPS</title>
      <link>https://stackoverflow.com/questions/78126688/how-can-%c4%b1-activate-mps-for-yolov8</link>
      <description><![CDATA[ 从超级物质导入YOLO
型号= yolo（; yolov8n.yaml; quot）＃从头开始构建新型号
型号= yolo（＆quot; yolov8n.pt;）
型号（MPS;）
结果= model.train（data =&#39;data/datas.yaml&#39;，
conf = 0.3，
epochs = 3，设备=&#39;mps&#39;）
 
我正在尝试在Yolov8模型上训练模型，但是即使我尝试了3个时代，训练时间也需要数小时。我安装了夜间版本和普通版本，但它不起作用。
我也尝试过，但它不起作用
  torch.backends.mps.is_available（）
版本：Macos Sonoma
 ]]></description>
      <guid>https://stackoverflow.com/questions/78126688/how-can-%c4%b1-activate-mps-for-yolov8</guid>
      <pubDate>Fri, 08 Mar 2024 09:30:30 GMT</pubDate>
    </item>
    <item>
      <title>AI和名称建议的认知服务[关闭]</title>
      <link>https://stackoverflow.com/questions/50003505/ai-and-cognitive-services-for-name-suggestions</link>
      <description><![CDATA[我有一个方案，我试图在某些名称上执行一些模糊匹配，并得出建议与输入的建议匹配的概率。  例如。我们有一个名字提供的“伊丽莎白·琼斯”。  如果我向API提供“ Liz Jones”，是否有任何API可以提供替代名称。  我想要的是为了提供以下内容
 伊丽莎白·琼斯（Elizabeth Jones）
利兹·琼斯
E.琼斯
琼斯
 
我知道有许多可用的认知服务，AI可以得出上下文，即“发票”将提供，“帐单，声明，发票”，但我看不到名称。
有人面临类似的需求吗？]]></description>
      <guid>https://stackoverflow.com/questions/50003505/ai-and-cognitive-services-for-name-suggestions</guid>
      <pubDate>Tue, 24 Apr 2018 13:54:24 GMT</pubDate>
    </item>
    </channel>
</rss>