<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 17 May 2024 06:20:18 GMT</lastBuildDate>
    <item>
      <title>ValueError：参数“target”和“output”必须具有相同的等级（ndim）。收到：target.shape=(None,)，output.shape=(None, 3)</title>
      <link>https://stackoverflow.com/questions/78493744/valueerror-arguments-target-and-output-must-have-the-same-rank-ndim-rece</link>
      <description><![CDATA[我尝试运行以下代码，但它显示此错误
我尝试过使用
tf.keras.utils.to_categorical 函数，但如果我这样做了，它会给我另一个错误，那就是
ValueError：数据基数不明确。确保所有数组包含相同数量的样本。&#39;x&#39; 大小：128, 128, 128, 128, 128, 128, 128
“y”尺寸：7
这是我的代码：
将 numpy 导入为 np
导入操作系统
将 matplotlib.pyplot 导入为 plt
从 sklearn.model_selection 导入 train_test_split
将 cv2 导入为 cv
进口泡菜
导入时间

os.environ[&#39;TF_ENABLE_ONEDNN_OPTS&#39;] = &#39;0&#39;
将张量流导入为 tf

人 = [&#39;H&#39;, &#39;J&#39;, &#39;A&#39;]
目录 = &#39;C:\AI&#39;
图片 = []
标签=[]
haar_cascade = cv.CascadeClassifier(&#39;haar_face.xml&#39;)

对于人中的人：
    路径 = os.path.join(DIR, 人)
    标签 = people.index(person)
    对于 os.listdir(path) 中的 img：
        img_path = os.path.join(路径, img)
        img_array = cv.imread(img_path)
        灰色 = cv.cvtColor(img_array, cv.COLOR_BGR2GRAY)
        face_rect = haar_cascade.detectMultiScale（灰色，scaleFactor = 1.1，minNeighbors = 6）
        对于face_rect 中的(x, y, w, h)：
            face_roi = img_array[y:y + h, x:x + w]
            face_roi = cv.resize(face_roi, (128, 128))
            图像.append(face_roi)
            labels.append(标签)

image_aug = tf.keras.preprocessing.image.ImageDataGenerator（rotation_range=30，shear_range=0.2，zoom_range=0.2，height_shift_range=0.2，width_shift_range=0.2，horizo​​ntal_flip=True，fill_mode=&#39;最近&#39;）

x_train, x_test, y_train, y_test = train_test_split(图像, 标签, test_size=0.2, random_state=4)

x_train = np.array(x_train, dtype=&#39;float&#39;) / 255.0
y_train = np.array(y_train, dtype=&#39;float&#39;) / 255.0

#y_train = tf.keras.utils.to_categorical(y_train, 3)
#y_test = tf.keras.utils.to_categorical(y_test, 3)

模型 = tf.keras.models.Sequential()
输入形状 = (128, 128, 3)

model.add(tf.keras.layers.Conv2D(32, (3, 3), 填充=&#39;相同&#39;, 激活=&#39;relu&#39;, input_shape=input_shape))
model.add(tf.keras.layers.BatchNormalization(axis=-1))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.2))

model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=&#39;相同&#39;, 激活=&#39;relu&#39;))
model.add(tf.keras.layers.BatchNormalization(axis=-1))

model.add(tf.keras.layers.Conv2D(64, (3, 3), padding=&#39;相同&#39;, 激活=&#39;relu&#39;))
model.add(tf.keras.layers.BatchNormalization(axis=-1))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.2))

model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=&#39;相同&#39;, 激活=&#39;relu&#39;))
model.add(tf.keras.layers.BatchNormalization(axis=-1))

model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=&#39;相同&#39;, 激活=&#39;relu&#39;))
model.add(tf.keras.layers.BatchNormalization(axis=-1))

model.add(tf.keras.layers.Conv2D(128, (3, 3), padding=&#39;相同&#39;, 激活=&#39;relu&#39;))
model.add(tf.keras.layers.BatchNormalization(axis=-1))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.2))

model.add(tf.keras.layers.Flatten())
model.add（tf.keras.layers.Dense（512，激活=&#39;relu&#39;））
model.add(tf.keras.layers.BatchNormalization())
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(3, 激活=&#39;softmax&#39;))

NAME = &#39;people-{}&#39;.format(int(time.time()))
tensorboard = tf.keras.callbacks.TensorBoard(log_dir=&#39;logs/{}&#39;.format(NAME))
model.compile(loss=&#39;categorical_crossentropy&#39;, 优化器=&#39;adam&#39;, 指标=[&#39;accuracy&#39;])
历史= model.fit（x_train，y_train，batch_size = 32，epochs = 10，callbacks = [tensorboard]，validation_data =（x_test，y_test），steps_per_epoch = len（x_train）// 32）


如果我取消注释 to_categorical 函数，然后打印 x_train 和 y_train 的形状
它显示 x 为 (24, 128, 128, 3)，y 为 (24, 3)]]></description>
      <guid>https://stackoverflow.com/questions/78493744/valueerror-arguments-target-and-output-must-have-the-same-rank-ndim-rece</guid>
      <pubDate>Fri, 17 May 2024 06:00:30 GMT</pubDate>
    </item>
    <item>
      <title>反馈管理器需要具有单一签名推断的模型</title>
      <link>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</link>
      <description><![CDATA[我在尝试运行机器运行模型时遇到了此错误，该模型应该为驾驶员睡意检测项目提供动力
”
W0000 00:00:1715924294.765512 2256 inference_feedback_manager.cc:114] 反馈管理器需要具有单个签名推理的模型。禁用对反馈张量的支持。”
模型架构如下：
&lt;前&gt;&lt;代码&gt;#**型号**
从 keras.layers 导入 BatchNormalization
模型 = tf.keras.models.Sequential()
# 输入形状是所需的图像大小 145 x 145，颜色为 3 字节

#这是第一个卷积
   model.add(Conv2D(16, 3, 激活=&#39;relu&#39;, input_shape=X_train.shape[1:]))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第二次卷积
   model.add(Conv2D(32, 5, 激活=&#39;relu&#39;))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第三次卷积
  model.add(Conv2D(64, 10, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())
  model.add(MaxPooling2D())
  tf.keras.layers.Dropout(0.3)

# 第四次卷积
  model.add(Conv2D(128, 12, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())

# 将结果压平以输入 DNN
  模型.add(压平())
  model.add（密集（128，激活=&#39;relu&#39;））
  模型.add(Dropout(0.25))
  model.add（密集（64，激活=&#39;relu&#39;））
# 只有 1 个输出神经元。
  model.add（密集（1，激活=&#39;sigmoid&#39;））

  model.compile(loss=“binary_crossentropy”，metrics=[“accuracy”]，optimizer=Adam(lr=0.001))
  历史= model.fit（train_generator，epochs = 10，batch_size = 32，validation_data = test_generator）

# 定义服务签名
  输入签名 = [
      tf.TensorSpec(shape=[None, 145, 145, 3], dtype=tf.float32, name=&#39;input_tensor&#39;)
  ]

@tf.function(input_signature=input_signature)
defserving_fn（输入）：
    返回模型（输入）

export_dir = &#39;E:\系统项目\项目&#39;
tf.saved_model.save（serving_fn，export_dir）

# 加载模型进行推理
load_model = tf.saved_model.load(&#39;my_model.keras&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</guid>
      <pubDate>Fri, 17 May 2024 05:59:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在流模式下应用 .map() 函数并将其保留为拥抱脸部数据集的迭代器而不将其加载到内存中？</title>
      <link>https://stackoverflow.com/questions/78493588/how-to-apply-map-function-and-keep-it-as-an-iterator-for-a-hugging-face-datas</link>
      <description><![CDATA[我目前正在使用 Hugging Face 数据集库，需要使用 .map() 函数对多个数据集（例如 ds_khan 和 ds_mathematica）应用转换，但以模仿流的方式（即，不加载整个数据集进入内存）。我特别感兴趣的是交错这些转换后的数据集，同时保持数据处理尽可能懒惰，类似于streaming=True。
这是我当前代码的相关部分：
从数据集导入 load_dataset, interleave_datasets

def get_hf_khan_ds(path_2_ds: str, split: str = &#39;train&#39;):
    path_2_ds = os.path.expanduser(path_2_ds)
    数据集= load_dataset（&#39;json&#39;，data_files = [path_2_ds]，split = split，streaming = True）
    Problem_as_text = lambda 示例：{&#39;text&#39;: example[&#39;problem&#39;]}
    返回dataset.map（problem_as_text，remove_columns = dataset.column_names）

def main():
    ds_khan = get_hf_khan_ds(&#39;~/gold-ai-olympiad/data/amps/khan/train.jsonl&#39;)
    ds_mathematica = get_hf_khan_ds(&#39;~/gold-ai-olympiad/data/amps/mathematica/train.jsonl&#39;)
    interleaved_datasets = interleave_datasets([ds_khan, ds_mathematica], 概率=[0.5, 0.5])
    对于 interleaved_datasets.take(10) 中的示例：
        打印（样本）

如果 __name__ == &#39;__main__&#39;:
    主要的（）

此设置旨在处理和交错数据集，而不将它们完全加载到内存中。但是，我不确定这种方法是否按照我的意图正确实现了流式计算和惰性求值。
问题：

此代码是否以流式或迭代器式方式正确应用转换？
如果不是，我该如何修改它以确保每个数据集仅根据需要进行处理，而不预加载整个内容？
是否有更有效的方法来交错这些数据集，同时保持流式传输方法？

任何关于如何有效地使用 .map() 和 Streaming=True 来交错数据集的建议或见解将不胜感激（注意我确实在磁盘中有数据集，但最终我想使用 HF 数据集）。
输出：
 表 = cls._concat_blocks(块, axis=0)
地图：100%|█████████████████████████████████████████████ ████████████████████████████████████████| 103059/103059 [00:06&lt;00:00, 16218.25 个示例/秒]
地图：100%|█████████████████████████████████████████████ ████████████████████████████████████████| 103059/103059 [00:07&lt;00:00, 13633.64 个示例/秒]
地图：100%|█████████████████████████████████████████████ ████████████████████████████████████████| 103059/103059 [00:08&lt;00:00, 12444.64 个示例/秒]
/lfs/ampere1/0/brando9/miniconda/envs/gold_ai_olympiad/lib/python3.11/site-packages/datasets/table.py:1421：FutureWarning：promote 已被 Promotion_options=&#39;default&#39; 取代。
  表= cls._concat_blocks（块，轴= 0）
下载数据文件：100%|███████████████████████████████████████████ █████████████████████████████████████████| 1/1 [00:00&lt;00:00, 3792.32it/s]
提取数据文件：100%|███████████████████████████████████████████ ███████████████████████████████████████████| 1/1 [00:00&lt;00:00, 479.84it/s]
生成训练分割：20 个示例 [00:00，3628.29 个示例/秒]
地图：100%|█████████████████████████████████████████████ █████████████████████████████████████████████████| 20/20 [00:00&lt;00:00, 2792.11 示例/秒]
地图：100%|█████████████████████████████████████████████ █████████████████████████████████████████████████| 20/20 [00:00&lt;00:00, 3525.66 示例/秒]
地图：100%|█████████████████████████████████████████████ █████████████████████████████████████████████████| 20/20 [00:00&lt;00:00, 3415.97 示例/秒]
/lfs/ampere1/0/brando9/miniconda/envs/gold_ai_olympiad/lib/python3.11/site-packages/datasets/table.py:1421：FutureWarning：promote 已被 Promotion_options=&#39;default&#39; 取代。
  表= cls._concat_blocks（块，轴= 0）
概率=[0.3333333333333333, 0.3333333333333333, 0.3333333333333333]
/lfs/ampere1/0/brando9/miniconda/envs/gold_ai_olympiad/lib/python3.11/site-packages/datasets/table.py:1421：FutureWarning：promote 已被 Promotion_options=&#39;default&#39; 取代。
  表= cls._concat_blocks（块，轴= 0）
完毕！时间：50.09秒、0.83分钟、0.01小时

我没想到输出会显示整个数据集......这让我很困惑。而且加载时间太长，这很糟糕。
参考：https://discuss.huggingface.co/t/how-to-apply-map-function -and-keep-it-as-an-iterator-for-a-hugging-face-dataset-in-streaming-mode-without-loading-it-to-memroy/87110]]></description>
      <guid>https://stackoverflow.com/questions/78493588/how-to-apply-map-function-and-keep-it-as-an-iterator-for-a-hugging-face-datas</guid>
      <pubDate>Fri, 17 May 2024 05:14:40 GMT</pubDate>
    </item>
    <item>
      <title>我试图运行此命令！pip install tensorflow-gpu in google colab 出现错误</title>
      <link>https://stackoverflow.com/questions/78493587/i-was-trying-to-run-this-command-pip-install-tensorflow-gpu-in-google-colab-to</link>
      <description><![CDATA[收集tensorflow-gpu
使用缓存的tensorflow-gpu-2.12.0.tar.gz (2.6 kB)
错误：子进程退出并出现错误
× python setup.py Egg_info 未成功运行。
│ 退出代码：1
╰─&gt;请参阅上面的输出。
注意：此错误源自子进程，并且可能不是 pip 的问题。
准备元数据（setup.py）...错误
错误：元数据生成失败
× 生成包元数据时遇到错误。
╰─&gt;请参阅上面的输出。
注意：这是上面提到的包的问题，​​而不是 pip 的问题。
提示：详细信息请参见上文。现在该怎么办
检查了blackbox ai，但没有帮助]]></description>
      <guid>https://stackoverflow.com/questions/78493587/i-was-trying-to-run-this-command-pip-install-tensorflow-gpu-in-google-colab-to</guid>
      <pubDate>Fri, 17 May 2024 05:14:37 GMT</pubDate>
    </item>
    <item>
      <title>UndefinedMetricWarning：精度定义不明确，在没有预测样本的标签中设置为 0.0。使用“zero_division”错误</title>
      <link>https://stackoverflow.com/questions/78493410/undefinedmetricwarning-precision-is-ill-defined-and-being-set-to-0-0-in-labels</link>
      <description><![CDATA[我正在 VS Code 上使用 Python 来开始使用 Wine Quality ML 进行训练。
但我不断得到
“UndefinedMetricWarning：精度定义不明确，在没有预测样本的标签中设置为 0.0。使用 zero_division 参数来控制此行为。”
我的[准确率][召回率、fi-score] 一直显示为空白：
 精确召回率 f1-score 支持

           3 0.00 0.00 0.00 4
           4 1.00 0.06 0.11 17
           5 0.69 0.69 0.69 231
           6 0.57 0.62 0.60 226
           7 0.38 0.42 0.40 50
           8 0.00 0.00 0.00 5

    准确度 0.60 533
   宏观平均 0.44 0.30 0.30 533
加权平均 0.61 0.60 0.59 533

我已经设置了：
mlp.fit(X_train, y_train)

预测 = mlp.predict(X_test)
打印（分类报告（y_test，预测，zero_division = 0））
打印（预测，&#39;\n&#39;）

我的代码中的其他所有内容似乎都正常工作：
df = pd.read_csv(&#39;winequality-red.csv&#39;, sep =&#39;;&#39;)


X = df.drop(&#39;质量&#39;, 轴 = 1)
y = df[&#39;质量&#39;]

X_train，X_test，y_train，y_test = train_test_split（X，y，test_size = 0.333，random_state = 0）
X_训练，X_测试

定标器=标准定标器()
缩放器.fit(X_train)

X_train = 缩放器.transform(X_train)
X_test = 缩放器.transform(X_test)

打印（df.head（））
打印(df.describe().transpose())

打印（X_train，&#39;\n&#39;）
打印（X_test，&#39;\n&#39;）

mlp = MLPClassifier(hidden_​​layer_sizes=(11, 11)，激活=&#39;逻辑&#39;，alpha=1e-06，batch_size=&#39;auto&#39;，beta_1=0.9，beta_2=0.999，early_stopping=False，epsilon=1e-08，learning_rate= &#39;自适应&#39;，
                    Learning_rate_init=0.5，max_iter=10000，动量=0.4，n_iter_no_change=10，nesterovs_momentum=True，power_t=0.5，random_state=1，shuffle=True，solver=&#39;sgd&#39;，tol=1e-09，validation_fraction=0.1，
                    详细=10，warm_start=False）

mlp.fit(X_train, y_train)

预测 = mlp.predict(X_test)
打印（分类报告（y_test，预测，zero_division = 0））
打印（预测，&#39;\n&#39;）

打印（confusion_matrix（y_test，预测），&#39;\n&#39;）
打印（分类报告（y_测试，预测））


e = y_test - 预测
e
]]></description>
      <guid>https://stackoverflow.com/questions/78493410/undefinedmetricwarning-precision-is-ill-defined-and-being-set-to-0-0-in-labels</guid>
      <pubDate>Fri, 17 May 2024 03:59:52 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 或 Transformer 模型是否有可逆的实现？</title>
      <link>https://stackoverflow.com/questions/78493118/is-there-any-reversible-implementation-for-lstm-or-transformer-models</link>
      <description><![CDATA[可以训练 LSTM 和转换器来注入数据流（例如键入的文本）并输出概率分数流，即序列到序列。
这对于文体评分、仇恨语言检测等很有用。
我想象用户通过基于 Web 的 GUI 与模型交互。
如果使用后端模型（为了论证：LSTM）是为了在用户文本块旁边动态显示分数，那么在大多数情况下，键入的字符可以通过模型逐一输入-一。
然而，现实世界的书写工具用户经常会出现拼写错误，从而在继续书写之前多次按退格键。这会破坏 seq2seq 模型的流程。可以想象，整个文本块需要再次通过模型输入，以达到先前点（用户“退格”到的点）出现的模型状态。
或者，对于较小的模型，可以在每次按键时缓存模型的状态，但我认为这在大多数情况下是不可行的。
我的问题是：有没有能够“倒带”状态的 seq2seq 模型？ IE。输入字符不是使用输入字符来确定下一个输出项，而是相反地到达，其预期目的是倒带存储单元的内部状态？这太好了，因为前一个示例中的退格键不会触发 LSTM 从最顶部传递整个文本。]]></description>
      <guid>https://stackoverflow.com/questions/78493118/is-there-any-reversible-implementation-for-lstm-or-transformer-models</guid>
      <pubDate>Fri, 17 May 2024 01:47:00 GMT</pubDate>
    </item>
    <item>
      <title>在 python 上从头开始实现 XGBoost</title>
      <link>https://stackoverflow.com/questions/78492767/implementing-xgboost-from-scratch-on-python</link>
      <description><![CDATA[我尝试编写自己的实现
类 XGBoost_own(BaseEstimator, ClassifierMixin):
    def __init__(自身，n_estimators=100，learning_rate=0.2，max_深度=3，
                 损失=&#39;逻辑&#39;，reg_alpha=0，reg_lambda=1，random_state=0）：

        self.n_estimators = n_estimators
        self.最大深度 = 最大深度
        自我学习率 = 学习率
        自我损失=损失
        self.reg_alpha = reg_alpha
        self.reg_lambda = reg_lambda
        self.初始化 = lambda y: np.mean(y) * np.ones([y.shape[0]])
        self.loss_by_iter = []
        self.trees_ = []
        self.boosted_pred = 无
        self.random_state = random_state

    def _sigmoid（自我，预测）：
        返回 1 / (1 + np.exp(-预测))

    def _softmax(自我，预测)：
        exp = np.exp(预测)
        返回 exp / np.sum(exp, axis=1, keepdims=True)

    def _compute_loss_gradient(自身, F, y):
        如果 self.loss == &#39;逻辑&#39;：
            返回 y - self._sigmoid(F)
        别的：
            raise ValueError(“不支持的损失函数”)

    def _compute_regularization_penalty(自我):
        如果 self.reg_alpha == 0:
            返回0
        elif self.reg_alpha &gt; &gt; elif self.reg_alpha &gt; 0 和 self.reg_lambda == 0：
            返回 self.reg_alpha * np.sum(np.abs(tree.coef_))
        elif self.reg_alpha == 0 且 self.reg_lambda &gt; 0:
            返回 0.5 * self.reg_lambda * np.sum(tree.coef_ ** 2)
        elif self.reg_alpha &gt; &gt; elif self.reg_alpha &gt; 0 和 self.reg_lambda &gt; 0:
            返回 self.reg_alpha * np.sum(np.abs(tree.coef_)) + 0.5 * self.reg_lambda * np.sum(tree.coef_ ** 2)
        别的：
            raise ValueError(“正则化参数组合无效”)

    def fit(自身, X, y):
        自我.X = X
        自我.y = y
        self.boosted_pred = np.zeros_like(y)
        F = 自我初始化(y)

        对于范围内的 t(self.n_estimators)：
            残差 = self._compute_loss_gradient(F, y)
            树 = DecisionTreeRegressor(max_深度=self.max_深度, random_state=self.random_state)
            tree.fit(X, 残差)
            self.trees_.append(树)
            更新 = self.learning_rate * tree.predict(X)
            F+=更新
            self.boosted_pred += 更新

        返回自我

    def Predict_proba(自身, X):
        F = np.zeros(X.shape[0])
        对于 self.trees_ 中的树：
            F += self.learning_rate * tree.predict(X)
        F = np.clip(F, -700, 700)
        如果 self.loss == &#39;逻辑&#39;：
            返回 self._sigmoid(F).reshape(-1, 1)
        elif self.loss == &#39;softmax&#39;:
            返回 self._softmax(F)
        别的：
            raise ValueError(“不支持的损失函数”)

    def 预测（自身，X）：
        概率 = self.predict_proba(X)
        返回 np.argmax(proba, axis=1)

    def get_params(self, deep=True):
        返回 {
            &#39;n_estimators&#39;: self.n_estimators,
            &#39;学习率&#39;：自我学习率，
            &#39;最大深度&#39;: self.最大深度,
            &#39;损失&#39;：自我损失，
            &#39;reg_alpha&#39;: self.reg_alpha,
            &#39;reg_lambda&#39;: self.reg_lambda,
            &#39;random_state&#39;: self.random_state,
        }

通过函数运行模型。也许我的实施不正确。我很困惑。另外，有人已经做到了，我很高兴看到 LightGBM、CatBoost、基于直方图的梯度提升的自写实现
def hyperparameter_tuning(模型、param_grid、Xre_train、Yre_train、Xre_test、Yre_test、结果)：
    对于 models.items() 中的名称、型号：
        print(f“调整 {name} 的超参数...”)
        param_grid_name = param_grid[名称]
        grid_search = GridSearchCV(估计器=模型，param_grid=param_grid_name，评分=&#39;准确度&#39;，cv=5，n_jobs=-1)
        grid_search.fit(Xre_train, Yre_train)
        best_params = grid_search.best_params_
        最佳模型 = grid_search.best_estimator_
        Yre_pred = best_model.predict(Xre_test)
        准确度=准确度_分数（Yre_test，Yre_pred）
        精度 = precision_score(Yre_test, Yre_pred, 平均值=&#39;加权&#39;)
        召回率=召回率（Yre_test，Yre_pred，平均值=&#39;加权&#39;）
        f1 = f1_score(Yre_test, Yre_pred, 平均值=&#39;加权&#39;)
        roc_auc = roc_auc_score(Yre_test, best_model.predict_proba(Xre_test), multi_class=&#39;ovr&#39;,average=&#39;加权&#39;)
        混乱=混乱_矩阵（Yre_test，Yre_pred）

我收到错误。多类分类的数据集
numpy.core._exceptions._UFuncOutputCastingError：无法使用转换规则“same_kind”将 ufunc &#39;add&#39; 输出从 dtype(&#39;float64&#39;) 转换为 dtype(&#39;int32&#39;)]]></description>
      <guid>https://stackoverflow.com/questions/78492767/implementing-xgboost-from-scratch-on-python</guid>
      <pubDate>Thu, 16 May 2024 23:00:43 GMT</pubDate>
    </item>
    <item>
      <title>大矩阵和算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78492698/large-matrix-and-algorithm</link>
      <description><![CDATA[您能否编写一种算法，从包含卷积神经网络权重值的文件（csv 格式）中分离并保存矩阵的列，该文件有 20,000 行和 48,000 列？
我想了好几天了，但我写不出这样的算法]]></description>
      <guid>https://stackoverflow.com/questions/78492698/large-matrix-and-algorithm</guid>
      <pubDate>Thu, 16 May 2024 22:26:56 GMT</pubDate>
    </item>
    <item>
      <title>如何利用机器学习算法来提高各个领域的预测准确性和效率？[关闭]</title>
      <link>https://stackoverflow.com/questions/78492345/how-can-machine-learning-algorithms-be-leveraged-to-improve-prediction-accuracy</link>
      <description><![CDATA[应用算法来改进预测
尝试过：制作食物热量预测模型
期待：一种可以提供更高准确性的算法，可以分析食物的适当比例以及其中存在的准确或精确的卡路里含量。]]></description>
      <guid>https://stackoverflow.com/questions/78492345/how-can-machine-learning-algorithms-be-leveraged-to-improve-prediction-accuracy</guid>
      <pubDate>Thu, 16 May 2024 20:33:26 GMT</pubDate>
    </item>
    <item>
      <title>TypeError“NoneType”对象不可下标</title>
      <link>https://stackoverflow.com/questions/78491414/typeerror-nonetype-object-is-not-subscriptable</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78491414/typeerror-nonetype-object-is-not-subscriptable</guid>
      <pubDate>Thu, 16 May 2024 16:44:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 DeepSeekMath 7b 模型在 vllm 中进行无说明的断言</title>
      <link>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78487360/assertion-with-no-scription-in-vllm-with-deepseekmath-7b-model</guid>
      <pubDate>Thu, 16 May 2024 02:49:09 GMT</pubDate>
    </item>
    <item>
      <title>无法使用自定义算法运行训练</title>
      <link>https://stackoverflow.com/questions/78486992/unable-to-run-training-using-a-custom-algorithm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78486992/unable-to-run-training-using-a-custom-algorithm</guid>
      <pubDate>Wed, 15 May 2024 23:54:42 GMT</pubDate>
    </item>
    <item>
      <title>为什么 JAX 编译时间随着 vmap 批处理大小的增加而增长？</title>
      <link>https://stackoverflow.com/questions/78486071/why-does-jax-compilation-time-grow-with-vmap-batch-size</link>
      <description><![CDATA[我正在使用 JAX 来评估批量损失梯度，其中涉及一些复杂的线性代数（包括 Cholesky 分解和解决方案等）。我的梯度损失的示意图形式是
jax.jit( jax.value_and_grad( jax.vmap(loss)(...).mean() ) )

我发现编译/首次评估时间在给定 vmap 的特定批量大小之前是恒定的（正如我通常所期望的那样），然后开始超线性增长。在 A100 上，nbatch &lt;= 64 需要 6 分钟，nbatch=128 需要 13 分钟，nbatch=256 需要 1 小时，这变得很笨拙。
这是一个可重现的示例。经过大量二分之后，我想我看到了简单的批量 cholesky 的相同行为：
# 这里没什么可看的，只是设置我们将要解决的线性系统
诺布斯, ngp = 256, 64
t = np.linspace(0, 1, 诺布)
f = np.arange(1, ngp + 1, dtype=np.float64)

fmat = np.zeros((nobs, 2*ngp), dtype=np.float64)
fmat[:, ::2] = np.sin(2.0 * jnp.pi * f * t[:,np.newaxis])
fmat[:, 1::2] = np.cos(2.0 * jnp.pi * f * t[:,np.newaxis])

一、ones = jax.numpy.identity(nobs, dtype=np.float64), jax.numpy.ones(nobs, dtype=np.float64)

def 函数（pars）：
  ftf = fmat @ jax.numpy.diag(pars**2) @ fmat.T + 1
  cf = jax.scipy.linalg.cho_factor(ftf)
  b = jax.scipy.linalg.cho_solve(cf, 个)
  返回 b.mean()

然后如果我获得转换并编译它
jvg = jax.value_and_grad(lambda pars: jax.vmap(func)(pars).mean())
pars = jax.random.normal(jax.random.PRNGKey(0), (nbatch,2*ngp,))
jjvg = jax.jit(jvg).lower(pars).compile()

我发现编译时间（以秒为单位）随着 nbatch 的增加而增长：
&lt;预&gt;&lt;代码&gt;[16,0.532]、[32,0.507]、[64,0.516]、[128,0.580]、[256,0.652]、[512,0.822]、[1024,1.7]、[2048 ,2.75]

如果我尝试 jax.make_jaxpr 而不是 jax.jit，我会看到每个批量大小的相同代码。
这里可能发生了什么？我使用的是 JAX 0.4.26 和带有 CUDA 12.2 和驱动程序 535.104.05 的 V100。]]></description>
      <guid>https://stackoverflow.com/questions/78486071/why-does-jax-compilation-time-grow-with-vmap-batch-size</guid>
      <pubDate>Wed, 15 May 2024 19:17:27 GMT</pubDate>
    </item>
    <item>
      <title>需要使用 Rand_forest 和 h2o 进行预测的指导</title>
      <link>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</link>
      <description><![CDATA[我有一个随机森林模型，我正在尝试更好地理解它。
为了举例，假设我们有一片蓝莓灌木丛。我们感兴趣的是预测特定灌木丛中腐烂蓝莓的产量以及各个灌木丛中所有蓝莓的收获量。
每个灌木都有一个识别名称：bush_name，例如&#39;bush001&#39;，我们希望根据每个单独的灌木进行预测。例如，我想知道 Bush025 是否在 2/2/22 生产了腐烂的浆果。
为了本示例，输入位于具有以下虚拟结构的 df 中：
train_data &lt;- data.frame(date = c(&quot;2022-01-01&quot;, &quot;2022-01-07&quot;, &quot;2022-02-09&quot;, &quot;2022-05&quot; -01”、“2022-11-01”、“2022-11-02”)、
                   Bush_name = c(“bush001”、“bush001”、“bush001”、“bush043”、“bush043”、“bush043”),
                   错误 = c(2, 0, 1, 0, 3, 1),
                   有腐烂的浆果 = c(1, 0, 0, 1, 1, 0),
                   浆果计数 = c(12, 1, 7, 100, 14, 4),
                   天气 = c(1, 0, 2, 0, 1, 1))

我已经建立了一个随机森林模型，并进行了以下高级设置：
库(agua)
图书馆（防风草）
图书馆（水）

h2o.init(n线程 = -1)

model_fit &lt;- rand_forest(mtry = 10, trees = 100) %&gt;%
  set_engine(“h2o”) %&gt;%
  set_mode(“分类”) %&gt;%
  适合（has_rotten_berry ~ .,
      数据 = train_data) %&gt;%
  step_dummy(灌木名称) %&gt;%
  step_zv(all_predictors()) %&gt;%
  step_normalize(all_predictors())

训练后我确实收到了这条消息：
警告消息：
在 .h2o.processResponseWarnings(res) 中：
  删除坏列和常量列：[bush_name]。

我想知道的是：
当我尝试预测训练模型中的新数据时，似乎我只能使用我已经训练过的灌木丛的 Bush_names 输入新的测试数据。 我假设该模型正在创建特定于灌木丛的预测是否正确？因此必须在训练中输入新的灌木丛信息才能输出这些新灌木丛的未来预测？
示例：我种植了一棵新灌木，bush700，它不存在于原始训练数据集中。如果我尝试使用新的灌木丛数据进行预测，但训练数据中不存在该数据，则会向我传达一条消息：数据中存在新的级别。所以我假设因为这些预测似乎是特定于灌木丛的，并且我们无法为新添加的灌木丛获得任何新的灌木丛预测。
这个假设正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</guid>
      <pubDate>Tue, 07 May 2024 16:58:00 GMT</pubDate>
    </item>
    <item>
      <title>在 Ray 调整上使用 GPU 或 CPU</title>
      <link>https://stackoverflow.com/questions/70208093/use-gpu-or-cpu-on-ray-tune</link>
      <description><![CDATA[我的机器上有 1 个 GPU 和 32 个 CPU。 Ray 中可以单独使用它们吗？例如，一个任务分配有 1 个 CPU，另一任务分配有 1 个 GPU？
如果我使用
 tune.run(trainer_fn,
             样本数=32，
             resources_per_Trial={“GPU”: 1, “CPU”: 1},
             ...

它只运行一列火车，因为只有一个 GPU 可用。我知道我可以使用 0.1 GPU 之类的东西来运行多个火车，但我无法知道哪个火车应该使用 CPU，哪个火车应该使用 GPU。]]></description>
      <guid>https://stackoverflow.com/questions/70208093/use-gpu-or-cpu-on-ray-tune</guid>
      <pubDate>Fri, 03 Dec 2021 00:28:07 GMT</pubDate>
    </item>
    </channel>
</rss>