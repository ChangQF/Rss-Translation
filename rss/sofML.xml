<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 30 Nov 2023 15:13:23 GMT</lastBuildDate>
    <item>
      <title>为什么训练YOLOv8会导致崩溃？</title>
      <link>https://stackoverflow.com/questions/77579052/why-does-training-yolov8-cause-a-crash</link>
      <description><![CDATA[我想在由单个类别的 1080p 图像组成的自定义数据集上训练对象检测。我认为我已经正确准备了数据集（将其上传到 roboflow 显示了正确概述类的图像），但是我似乎无法让模型开始训练。起初，我怀疑我使用的数据集可能太大，无法满足我普通笔记本电脑的处理能力（270 个 1080p 图像及其掩模，总计 1.34GB），因此我将其减少到只有 10 个训练图像和 10 个验证图像。还是没有运气。
我的代码：
从 ultralytics 导入 YOLO

# 加载 COCO 预训练的 YOLOv8n 模型
模型 = YOLO(&#39;yolov8n.pt&#39;)

结果 = model.train(data=&#39;(..)\\dataset\\data.yaml&#39;, epochs=5,
                      imgsz=[1920, 1080])

data.yaml 文件：
&lt;前&gt;&lt;代码&gt;名称：
- 烟草
数控：1
测试：数据集\测试
火车：火车\图像
val: 有效\图像

控制台输出：
图像大小 1920 train、1920 val
使用 0 个数据加载器工作人员
将结果记录到运行\检测\train7
开始训练 5 个 epoch...

      Epoch GPU_mem box_loss cls_loss dfl_loss 实例大小
  0%| | 0/1 [00:00
代码在 0% 处停留大约一分钟，我的计算机死机，然后打印处理完成错误。
假设问题确实源于我糟糕的规格，我可以对自定义数据集使用某种云训练吗？我在哪里可以阅读有关构建和上传用于云训练的自定义数据集的更多信息？]]></description>
      <guid>https://stackoverflow.com/questions/77579052/why-does-training-yolov8-cause-a-crash</guid>
      <pubDate>Thu, 30 Nov 2023 13:59:49 GMT</pubDate>
    </item>
    <item>
      <title>在训练和测试模型时，为什么我们说开发数据和测试数据应该来自相同的分布？</title>
      <link>https://stackoverflow.com/questions/77578962/when-training-and-testing-a-model-why-do-we-say-dev-and-test-data-should-come-f</link>
      <description><![CDATA[我们通常将数据集分为训练数据、开发数据和测试数据。那么为什么我们说开发数据和测试数据应该来自相同的分布呢？我们如何处理开发数据？
我浏览了 andrew ng 的视频，发现了这样的事情！]]></description>
      <guid>https://stackoverflow.com/questions/77578962/when-training-and-testing-a-model-why-do-we-say-dev-and-test-data-should-come-f</guid>
      <pubDate>Thu, 30 Nov 2023 13:46:40 GMT</pubDate>
    </item>
    <item>
      <title>L1 正则化不适用于线性回归</title>
      <link>https://stackoverflow.com/questions/77578761/l1-regularisation-not-working-for-linear-regression</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77578761/l1-regularisation-not-working-for-linear-regression</guid>
      <pubDate>Thu, 30 Nov 2023 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>是否可以微调稳定扩散模型或任何其他扩散模型以支持孟加拉语等不同语言？</title>
      <link>https://stackoverflow.com/questions/77577322/is-it-possible-to-fine-tune-stable-diffusion-model-or-any-other-diffusion-model</link>
      <description><![CDATA[我是一名本科生，对AI了解不多。
我需要一个文本到图像生成器扩散模型，可以将孟加拉文本作为输入并生成图像。是否有任何以孟加拉语文本作为输入的扩散模型？或者我可以微调扩散模型以支持孟加拉语吗？如果可能的话，哪种扩散模型最适合这项任务？]]></description>
      <guid>https://stackoverflow.com/questions/77577322/is-it-possible-to-fine-tune-stable-diffusion-model-or-any-other-diffusion-model</guid>
      <pubDate>Thu, 30 Nov 2023 09:34:51 GMT</pubDate>
    </item>
    <item>
      <title>如何让训练有素的 LSTM 预测了解即将发生的已知特殊事件？</title>
      <link>https://stackoverflow.com/questions/77577239/how-to-make-a-well-trained-lstm-forecast-aware-of-the-upcoming-known-special-eve</link>
      <description><![CDATA[我根据每日销售数据训练了 LSTM 模型，其中包括对销售影响很大的节假日和特殊活动（作为二进制指标）。但是，虽然在测试集之外进行预测，但该模型并未考虑有影响力的已知未来假期。我怎样才能让我的模型意识到这一点？
我使用包含销售和假期的数据集作为二进制指标，直到记录销售的最后一天。我有未来假期二进制指标数据集，但它不包含在此处。问题是如何使用它进行预测。这是我的初始代码，它在测试集上给出了良好的结果：
data = df_resampled[[&#39;销售&#39;, &#39;Hol1&#39;, &#39;Hol2&#39;, &#39;Hol3&#39;, &#39;Hol4&#39;, &#39;Hol5&#39;,&#39;周末&#39;,&#39;夏季&#39;]].values

# 标准化数据

缩放器 = MinMaxScaler(feature_range=(0, 1))
data_scaled = 缩放器.fit_transform(数据)

# 分割数据

train_size = int(len(data_scaled) * 0.8)
训练，测试 = data_scaled[:train_size], data_scaled[train_size:]

# LSTM 训练序列

def create_sequences(数据, seq_length):
序列、目标 = []、[]
对于范围内的 i（len（数据）- seq_length）：
seq = 数据[i:i + seq_length]
目标=数据[i + seq_length]
序列.append(seq)
目标.append(目标)
返回 np.array(序列), np.array(目标)

序列长度 = 10
train_sequences, train_targets = create_sequences(train, seq_length)
test_sequences, test_targets = create_sequences(测试, seq_length)

# 重塑输入（样本、时间步长、特征）

train_sequences = np.reshape(train_sequences, (train_sequences.shape[0], train_sequences.shape[1], train_sequences.shape[2]))
test_sequences = np.reshape(test_sequences, (test_sequences.shape[0], test_sequences.shape[1], test_sequences.shape[2]))

# 具有附加功能的 LSTM 模型

模型=顺序（）
model.add(LSTM(单位=50, input_shape=(train_sequences.shape[1], train_sequences.shape[2])))
model.add(密集(单位=1))
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

# 训练模型

model.fit（train_sequences，train_targets [：，0]，epochs = 50，batch_size = 32）

# 对测试数据进行预测

test_predictions = model.predict(test_sequences)

# 反转至原始比例

test_predictions_inv = scaler.inverse_transform(np.concatenate((test_predictions, test_targets[:, 1:]), axis=1))[:, 0]
test_targets_inv = 缩放器.inverse_transform(test_targets)[:, 0]
]]></description>
      <guid>https://stackoverflow.com/questions/77577239/how-to-make-a-well-trained-lstm-forecast-aware-of-the-upcoming-known-special-eve</guid>
      <pubDate>Thu, 30 Nov 2023 09:22:08 GMT</pubDate>
    </item>
    <item>
      <title>llama 模型来获取 pdf 上下文中问题的答案</title>
      <link>https://stackoverflow.com/questions/77576528/llama-model-to-get-answers-of-the-questions-which-are-in-the-context-of-pdf</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77576528/llama-model-to-get-answers-of-the-questions-which-are-in-the-context-of-pdf</guid>
      <pubDate>Thu, 30 Nov 2023 07:14:31 GMT</pubDate>
    </item>
    <item>
      <title>修改来自google的ml教程代码没有给出预期的结果</title>
      <link>https://stackoverflow.com/questions/77575529/modifying-ml-tutorial-code-from-google-does-not-give-expected-result</link>
      <description><![CDATA[有一个很好的使用tensorflow lib的ml python代码的迷你示例。
Google 代码实验室教程
它（正确地）从线性方程预测一个数字。但仅仅制作一个小模型来训练模型并预测二次函数就会得到完全错误的结果。
导入tensorflow为tf
将 numpy 导入为 np
从张量流导入keras

模型 = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
model.compile(optimizer=&#39;sgd&#39;, loss=&#39;mean_squared_error&#39;)

# 从原始教程修改 -&gt; y = 2x^2-1
xs = np.array([-3.0, -2.0, -1.0, 0.0, 2.0, 3.0, 4.0, 5.0], dtype=float)
ys = np.array([ 17.0, 7.0, 1.0, -1.0, 7.0, 17.0, 31.0, 49.0], dtype=float)

model.fit(xs, ys, epochs=5000)

打印（模型.预测（[1.0]））

给出结果：
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt;打印（模型.预测（[1.0]））
1/1 [================================] - 0s 84ms/步
[[15.999977]]
&gt;&gt;&gt;&gt;&gt;

我本来预计大约。 1.0。
不知道出了什么问题。]]></description>
      <guid>https://stackoverflow.com/questions/77575529/modifying-ml-tutorial-code-from-google-does-not-give-expected-result</guid>
      <pubDate>Thu, 30 Nov 2023 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>fiass 在查找相似图像方面比余弦相似度更好吗？我们应该标准化嵌入吗？</title>
      <link>https://stackoverflow.com/questions/77574460/is-fiass-better-than-cosine-similarity-in-finding-similar-images-should-we-nor</link>
      <description><![CDATA[我正在研究一个产品识别人工智能项目。任务如下：我们必须找到公司销售的图像中的物体，然后我们必须生成 6 个相似的产品，为此我们使用接地恐龙进行零镜头物体检测，然后进行剪辑以计算余弦相似度在裁剪图像的嵌入与具有相同产品类别或类别的图像的嵌入之间，我们的问题如下：
我们希望它检测的类别非常相似，包括凳子、桌子、书桌、架子，因此有时它会对同一对象标记两次，或者将其标记为与真实标签类似的内容。
其次，同一类别的两个看起来不相似的对象之间的余弦相似度有时非常高，而完全相同产品的图像之间的余弦相似度则较低
我们应该做什么任何帮助将非常感激，问题是因为恐龙还是剪辑，我们是否解决检测或相似性
使用 fiass libraray 代替余弦相似度更好吗？它会生成更多相似的图像
我们尝试增加 dino 的阈值，并在提示中使用单个类多次运行它，这样我们可以设置高阈值而不丢失数据
我们的导师建议我们使用伪标签和 100 个带注释的图像对恐龙进行半监督学习
我们无法训练分类器，因为我们的数据集中只有 200 张图像
我们应该在计算余弦相似度之前对嵌入进行归一化]]></description>
      <guid>https://stackoverflow.com/questions/77574460/is-fiass-better-than-cosine-similarity-in-finding-similar-images-should-we-nor</guid>
      <pubDate>Wed, 29 Nov 2023 20:59:25 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种 ML 模型来检测图像中特定对象的数量？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77573916/which-ml-model-should-i-use-for-detecting-number-of-specific-objects-in-an-image</link>
      <description><![CDATA[我有一堆奶酪图像，我需要知道哪种 ML 模型最能解决这个问题。我过去做过一些愿景项目，但这肯定不是我的强项。谁能给我一些入门建议？这可能是一种监督学习，因为我应该事先知道孔的数量，但为了以防万一，请随意建议一种无监督方法。]]></description>
      <guid>https://stackoverflow.com/questions/77573916/which-ml-model-should-i-use-for-detecting-number-of-specific-objects-in-an-image</guid>
      <pubDate>Wed, 29 Nov 2023 19:09:09 GMT</pubDate>
    </item>
    <item>
      <title>RedshiftML - 再训练模型</title>
      <link>https://stackoverflow.com/questions/77573576/redshiftml-retraining-models</link>
      <description><![CDATA[有人有使用 redshiftML 的经验并有更新模型的指导吗？我让我们的 BI 团队在 Redshift 中启用了此功能，但我们的组织没有使用此工具的经验。当我尝试更新模型时，我最终遇到了各种类型的错误，我希望有人能给我指出正确的方向
删除模型时，出现以下错误。这是权限问题吗？
[Amazon](500310) 无效操作：函数 149004315 的缓存查找失败 
重新训练模型时，出现以下错误。是否有关于更换/重新训练模型的指导？
[Amazon](500310) 无效操作：函数“model_name”已存在具有相同参数类型的
没有太多文档，因此我最初按照以下说明开始：https://docs.aws.amazon.com/redshift/latest/dg/r_DROP_MODEL.html
如果我无法克服删除模型的错误，那么我想我最终将不得不设置每日模型版本控制并使数据库膨胀
https://aws.amazon .com/blogs/big-data/implement-model-versioning-with-amazon-redshift-ml/]]></description>
      <guid>https://stackoverflow.com/questions/77573576/redshiftml-retraining-models</guid>
      <pubDate>Wed, 29 Nov 2023 18:09:54 GMT</pubDate>
    </item>
    <item>
      <title>为模型创建输入时，keras 的 Sequential 和 Concatenate 有什么区别？</title>
      <link>https://stackoverflow.com/questions/77571304/what-is-the-difference-between-sequential-and-concatenate-of-keras-while-creatin</link>
      <description><![CDATA[为模型创建输入时，keras 的 Sequential 和 Concatenate 有什么区别？
我见过两种使用 Sequential 创建图层的方法，其中我们只需定义输入的形状，但另一种方法是使用 Concatenate 创建输入。
这两种方法有什么区别？
以下是方法：
方法 1：
模型 = tf.keras.models.Sequential()
model.add(tf.keras.layers.Dense(单位=1, input_shape=(2,), kernel_regularizer=&#39;l1&#39;, 激活=tf.sigmoid))


model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),
                损失=tf.keras.losses.BinaryCrossentropy(),
                指标=指标）

方法 2：
链接：colab。
&lt;前&gt;&lt;代码&gt; my_inputs = {
    # 用于训练模型的特征。
    &#39;中位数收入&#39;: tf.keras.Input(shape=(1,)),
    &#39;total_rooms&#39;: tf.keras.Input(shape=(1,))
  }
# 使用连接层将输入层连接成单个张量。
  # 作为密集层的输入。例如：[input_1[0][0]、input_2[0][0]]
  concatenated_inputs = tf.keras.layers.Concatenate()(my_inputs.values())
  密集=层.密集（单位= 1，名称=&#39;dense_layer&#39;，激活= tf.sigmoid）
  密集输出 = 密集（连接输入）
  “”“创建并编译一个简单的分类模型。”“”
  我的输出 = {
    &#39;密集&#39;：密集输出，
  }
  模型= tf.keras.Model（输入= my_inputs，输出= my_outputs）

  # 调用compile方法将各层构造成模型
  # TensorFlow 可以执行。请注意，我们使用了不同的损失
  # 用于分类的函数而不是用于回归的函数。
  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),
                损失=tf.keras.losses.BinaryCrossentropy(),
                指标=指标）
]]></description>
      <guid>https://stackoverflow.com/questions/77571304/what-is-the-difference-between-sequential-and-concatenate-of-keras-while-creatin</guid>
      <pubDate>Wed, 29 Nov 2023 12:51:28 GMT</pubDate>
    </item>
    <item>
      <title>如何实现基于内容的语音搜索过滤？</title>
      <link>https://stackoverflow.com/questions/77562907/how-to-implement-content-based-filtering-for-voice-search</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77562907/how-to-implement-content-based-filtering-for-voice-search</guid>
      <pubDate>Tue, 28 Nov 2023 10:01:16 GMT</pubDate>
    </item>
    <item>
      <title>Google AI Platform 训练 - 等待作业完成</title>
      <link>https://stackoverflow.com/questions/64806003/google-ai-platform-training-wait-for-the-job-to-finish</link>
      <description><![CDATA[我构建了一个包含大量并行进程的 AI Platform 管道。每个进程都会在 AI 平台上启动一个训练作业，如下所示：
gcloud ai-platform 作业提交培训...

然后它必须等待作业完成才能进入下一步。为此，我尝试将参数 --stream-logs 添加到上述命令中。通过这种方式，它会传输所有日志，直到作业完成。
问题是，有这么多并行进程，我用完了获取日志的请求：
超出配额指标“读取请求”和限制“每分钟读取请求”的配额
服务“logging.googleapis.com”

但我不需要实际流式传输日志，我只需要一种方法来告诉进程“等待”直到训练工作完成。有没有更聪明、更简单的方法来做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/64806003/google-ai-platform-training-wait-for-the-job-to-finish</guid>
      <pubDate>Thu, 12 Nov 2020 14:39:20 GMT</pubDate>
    </item>
    <item>
      <title>keras中train_on_batch()有什么用？</title>
      <link>https://stackoverflow.com/questions/49100556/what-is-the-use-of-train-on-batch-in-keras</link>
      <description><![CDATA[train_on_batch() 与 fit() 有何不同？什么情况下我们应该使用train_on_batch()？]]></description>
      <guid>https://stackoverflow.com/questions/49100556/what-is-the-use-of-train-on-batch-in-keras</guid>
      <pubDate>Sun, 04 Mar 2018 21:13:27 GMT</pubDate>
    </item>
    <item>
      <title>pyspark：名称错误：名称“spark”未定义</title>
      <link>https://stackoverflow.com/questions/39541204/pyspark-nameerror-name-spark-is-not-defined</link>
      <description><![CDATA[我是从官方文档网站复制pyspark.ml示例：
http://spark.apache.org /docs/latest/api/python/pyspark.ml.html#pyspark.ml.Transformer
data = [(Vectors.dense([0.0, 0.0]),), (Vectors.dense([1.0, 1.0]),),(Vectors.dense([9.0, 8.0]),) , (Vectors.dense([8.0, 9.0]),)]
df = Spark.createDataFrame(数据, [“特征”])
kmeans = KMeans(k=2, 种子=1)
模型 = kmeans.fit(df)

但是，上面的示例无法运行并给出以下错误：

&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
NameError Traceback（最近一次调用最后一次）
&lt;ipython-input-28-aaffcd1239c9&gt;在&lt;模块&gt;()中
      1 从 pyspark 导入 *
      2 数据 = [(Vectors.dense([0.0, 0.0]),), (Vectors.dense([1.0, 1.0]),),(Vectors.dense([9.0, 8.0]),), (Vectors.dense ([8.0, 9.0]),)]
----&gt; 3 df = Spark.createDataFrame(数据, [“特征”])
      4 kmeans = KMeans(k=2, 种子=1)
      5 模型 = kmeans.fit(df)

NameError：名称“spark”未定义

需要设置哪些附加配置/变量才能运行示例？]]></description>
      <guid>https://stackoverflow.com/questions/39541204/pyspark-nameerror-name-spark-is-not-defined</guid>
      <pubDate>Fri, 16 Sep 2016 23:05:11 GMT</pubDate>
    </item>
    </channel>
</rss>