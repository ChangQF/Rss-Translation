<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Wed, 12 Mar 2025 12:34:38 GMT</lastBuildDate>
    <item>
      <title>使用机器学习/数据科学技术限制搜索参数[关闭]</title>
      <link>https://stackoverflow.com/questions/79503447/using-machine-learning-data-science-technique-to-restrict-the-search-parameters</link>
      <description><![CDATA[我有一个搜索功能，希望在2个参数之间进行优化。

我希望用户在遍及所有可用记录的情况下都具有尽可能多的灵活性。
我想限制搜索条件，以确保用户在UI上实际上可以使用加载的记录数。

例如，我的搜索具有以下参数：
国家 /地区：用户最多可以选择5种类型。该数据库具有200种独特类型。
创建的日期：我们已经限制了30天。该数据库具有5年的记录。
类别：用户最多可以选择10种类型。该数据库具有3000种独特类型。
想要的结果：
如果用户正在搜索国家，日期范围在10天内，我们知道DB的行计数将为300K，因此我们希望建议用户减少天数。
同样，如果用户正在搜索日本，我们知道在整个5年中，总数只有5K，因此我们不想删除数据范围限制，并建议用户能够搜索更广泛的日期范围。
如何使用机器学习或数据科学技术解决这个问题？
我可以使用蛮力计算每个可能条件的行计数，但随着搜索标准的数量增加，问题似乎并不是最佳的，问题呈指数增长。 ]]></description>
      <guid>https://stackoverflow.com/questions/79503447/using-machine-learning-data-science-technique-to-restrict-the-search-parameters</guid>
      <pubDate>Wed, 12 Mar 2025 11:31:44 GMT</pubDate>
    </item>
    <item>
      <title>从拥抱脸上导入Microsoft/Orca-2-13b时，使Cuda摆脱记忆力</title>
      <link>https://stackoverflow.com/questions/79502752/getting-cuda-out-of-memory-when-importing-microsoft-orca-2-13b-from-hugging-face</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79502752/getting-cuda-out-of-memory-when-importing-microsoft-orca-2-13b-from-hugging-face</guid>
      <pubDate>Wed, 12 Mar 2025 06:05:57 GMT</pubDate>
    </item>
    <item>
      <title>创建用于水压预测的ML模型[关闭]</title>
      <link>https://stackoverflow.com/questions/79502209/creating-ml-model-for-water-pressure-prediction</link>
      <description><![CDATA[我的项目涉及监测管道系统中的水压并使用机器学习来检测异常。
问题：
•我有一个主管，带有压力传感器，可连续监视水压。
•连接到主管的多个阀门可以打开或关闭，创建不同的流动方案。
•我想开发一个可以：的ML模型

预测基于阀状态的预期压力（开放/关闭）。
检测异常，如果实时压力显着偏离预测值。

挑战：
•在许多阀中，组合数的数量呈指数增长（n个阀门为2ⁿ）。存储所有可能的压力值是不切实际的。
•我需要一种在不手动记录每个阀组合的情况下建模系统的方法。
•理想情况下，该模型也应概括和预测，即使是看不见的组合也应推广压力。
到目前为止我的方法：
•我已经考虑使用线性回归模型来映射阀态以施加压力，但担心它可能无法捕获复杂的关系。
•我正在探索神经网络或决策树，但是我不确定如何有效地构建输入功能。
•我计划从传感器中收集现实世界数据，并使用它来训练和验证模型。
我需要帮助：

 最佳ML方法：我应该坚持简单回归，还是像随机森林，梯度增强甚至LSTM之类的东西会更好？

 功能工程：如何有效地表示阀门？

 模型评估：可靠评估性能和标记异常的最佳方法是什么？

 缩放：如何为带有许多阀门的大型系统做这项工作？

]]></description>
      <guid>https://stackoverflow.com/questions/79502209/creating-ml-model-for-water-pressure-prediction</guid>
      <pubDate>Tue, 11 Mar 2025 21:46:49 GMT</pubDate>
    </item>
    <item>
      <title>如何在梯度下降线性回归中减轻高MAE/MSE？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79501719/how-to-mitigate-high-mae-mse-in-gradient-descent-linear-regression</link>
      <description><![CDATA[我正在通过从头开始实现机器学习算法。从基础知识开始，我正在研究线性回归。但是，我面临模型性能的问题。鉴于数据集的简单性，我希望该模型可以密切预测输出，旨在MAE/MSE小于1。。
这是我目前的结果：
  [[[29.76307389]]＃重量
MAE：11.860197526386747
MSE：[320.16732974]
RMSE：[17.89322022]
 
我的问题是：如何减轻高成本功能？这是数据扩展问题（我认为不是）吗？我在代码逻辑中看不到任何缺陷。

我的实现：
 导入numpy作为NP
从sklearn.datasets导入make_regression
来自sklearn.model_selection导入train_test_split

班级体重：

    def __init __（self，n_features：int）：
        self.lim = 1 / np.sqrt（n_features）
        self.n_features = n_features
        self.seed = 42
        np.random.seed（self.seed）

    def Random_uniform（self）：
        返回np.random.uniform（-self.lim，self.lim，（self.n_features，1））

班级回归：
    def __init __（self，n_iter：int，l_rate：float）：
        self.n_iter = n_iter
        self.l_rate = l_rate
        self.w =无
        self.b = 0
        self.Error = 0

    def预测（self，x）：
        返回np.dot（x，self.w） + self.b

    def fit（self，x，y，reg_factor：str = none）：
        n_samples，n_features = x。形状
        如果self.w是无：＃持续权重
            self.w = strige（n_features）.random_rand（）
        y = np.Reshape（y，（-1，1））＃将数组转换为列向量
        正则化= self.regularize（）

        对于_范围（self.n_iter）：
            y_pred = self.predict（x）
            self.error = y -y__pred
            grad_w =（-2 * np.dot（x.t，self.error） / n_samples） 
            grad_b =（-2 * np.sum（self.error）） / n_samples
            self.w-- = self.l_rate * grad_w＃l_rate *（grad_w +正则化_factor）
            self.b- = self.l_rate * grad_b＃l_rate * grad_b


类线性回归（回归）：
    def __init __（self，n_iter：int，l_rate：float）：
        super（）.__ init __（n_iter，l_rate）

    def渐变发达（self，x，y）：
        super（）。拟合（x，y）

类评估对：
    def __init __（self，n：int，y，y_pred）：
        self.n = n
        self.y = np.Reshape（y，（-1，1））＃实际值
        self.y_pred = y_pred＃预测值

    Def Mae（自我）：
        返回np.mean（np.abs（self.y -self.y_pred））
    Def MSE（自我）：
        返回总和（np.pow（（（self.y -self.y_pred），2）） / self.n
    def rmse（self）：
        返回np.sqrt（sum（np.pow（（（self.y -y -self.y_pred）），2）） / self.n）

x，y = make_regression（n_samples = 1000，n_features = 1，噪声= 15，Random_state = 4）

    x_train，x_test，y_train，y_test = train_test_split（
        X，Y，test_size = 0.4，Random_State = 42
    ）

    LR =线性重试（1000，0.01）
    lr.gradientdescent（x_train，y_train）
    lr.printweights（）
    y_pred = lr.predict（x_train）

    mae = essalmetrics（n = x_train.shape [0]，y = y_train，y_pred = y_pred）.mae（）
    打印（f＆quot; mae：{mae}＆quot;）
    MSE = essutuationMetrics（n = x_test.shape [0]，y = y_train，y_pred = y_pred）.mse（）
    打印（MSE：{MSE}＆quot;）
    rmse = evaluationMetrics（n = x_test.shape [0]，y = y_train，y_pred = y_pred）.rmse（）
    打印（f＆quot&#39;rmse：{rmse}＆quot;）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79501719/how-to-mitigate-high-mae-mse-in-gradient-descent-linear-regression</guid>
      <pubDate>Tue, 11 Mar 2025 18:00:42 GMT</pubDate>
    </item>
    <item>
      <title>当我试图运行命令spartlit运行main.py时，为什么我会得到RuntimeError：没有运行事件循环，并且在我的VS代码中？</title>
      <link>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</guid>
      <pubDate>Tue, 11 Mar 2025 09:34:06 GMT</pubDate>
    </item>
    <item>
      <title>生成partialdependedateata函数在用于多类分类模型时返回错误</title>
      <link>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</link>
      <description><![CDATA[我已经使用MLR构建了XGBoost多类分类模型，我想为某些功能可视化部分依赖性。但是，如果我尝试使用 generatePartialDependedAta（）我会收到以下错误：

 Melt.data.table中的错误（AS.Data.table（OUT），MEATH.VARS = target，variable.name = if（td $ type ===：&#39;METAY.VARS&#39;中的一个或多个值无效。

我已经检查了 task.desc 在 task&gt; task 对象和 factor.levels.levels.levels 中的差异。此外，我毫不费力地使用相同的函数生成具有不同目标变量的回归XGBoost的数据。
我的目的是有问题，还是这是一个错误？
这是使用 palmerpenguins 数据集的示例：
 ＃库
图书馆（整洁）
图书馆（Caret）
图书馆（MLR）

Peng＆lt;  -  Palmerpenguins ::企鹅

＃数据分区
set.seed（1234）
Intrain＆lt ;-创建Atapartition（
  y =彭$种，
  p = 0.7，
  列表= f
）

＃构建任务
train_class＆lt;  -  peng [intrain，]％＆gt;％select（-sex，-year）％＆gt;％ 
  CreateMummyFeatures（target =;物种＆quots; cols =;岛; 
  makeClassIftask（data =。，target =;物种；）

＃建立学习者
xgb_class_learner＆lt;  -  makelearner（
  ＆quot“ classif.xgboost”
  predict.type =&#39;响应;
）

＃构建模型
XGB_CLASS＆lt;  - 火车（XGB_CLASS_LEARNER，TRAIN_CLASS）

＃产生部分依赖性
GeneratePartialDependedateData（XGB_Class，Train_class）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</guid>
      <pubDate>Mon, 10 Mar 2025 18:27:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地运行DeepSeek模型</title>
      <link>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</link>
      <description><![CDATA[我试图根据他们的说明在本地运行DeepSeek，但它不能带来一些愚蠢的错误（我将稍后显示）。
这就是我正在做的。

从此处下载最小型号（3.5GB） noreferrer“&gt; https://huggingface.co/deepseek-ai/deepseek-r1-distill-qwen-1.5b  
按照此处的步骤操作： https://github.com/deepseek-ai/deepseek-v3?tab=readMe-Readme-ov-file#6-how-to-to-to-run-locally  

 2.1获取这个项目
 https://github.com/deepseek-ai/deepseek-ai/deepseek-ai/deepseek-v3.git 
 2.2运行码头容器类似于预先创建的卷以放置模型
  docker run  -  gpus all -it -it -name deepSeek01 -rm -mount source = deepSeekv3，target =/root/deepSeekv3 python：3.10 -Slim bash
 
我正在使用python：3.10-slim，因为这里（ https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-how-to-run-locally ）
＆quot&#39; linux只有python 3.10。 Mac和Windows不支持。
 2.3安装最新更新
apt-get Update 
 2.4获取此文件 https://github.com/deepseek-ai/deepseek-v3/blob/main/main/inference/requirements.txt 并安装要求
  pip install -r sumpliont.txt
 
 2.5将模型复制到安装在Docker容器上的音量。这5个文件来自此处 https：//hugging.co/deepseek-aiek-ai/deepseek-ai/deepseek-ai/deepseek-ai/deepseek/deepseek-ipseek-r1-r1-r1-r1-pp&gt;   config.json
generation_config.json
模型。系统
tokenizer.json
tokenizer_config.json
 
 2.6在此处编写的模型转换 https://github.com/deepseek-ai/deepseek-v3?tab=readme-readme-ov-file#model-weights-conversion 通过此命令
  python convert.py-hf-ckpt-path/root/deepSeekv3/source_model -save-path/root/deepSeekv3/converted_model -n-experts 256-model-parelally 16
 
在此步骤中（转换模型）我得到了此错误
  trackback（最近的最新通话）：
  file＆quort＆quort＆quot deepseekv3/inference/convert.py&quot;，第96行，in＆lt; module＆gt;
    main（args.hf_ckpt_path，args.save_path，args.n_experts，args.model_parallel）
  file＆quot＆quot&#39;deepseekv3/inference/convert.py&quot;，第63行，在main中
    主张映射中的密钥
断言
 
因此，基本上，下一步没有意义，因为这是必不可少的步骤。
我的问题：

我做错了什么？
 YouTube上有一些视频，其中DeepSeek与Ollama一起安装了。真的需要吗？我是否应该像他们在这里描述的那样能够运行它， https://github.com/deepseek-ai/deepseek-v3?tab=readmereadme-readme-ov-file#6-how-to-run-locally ？

更新1 
为了调试一点，我添加了这2行。
  print（＆quot;丢失键：＆quot;键）
打印（可用键：＆quot; list（mapping.keys（）））
 
缺少键是以下内容：
  embed_tokens
input_layernorm
down_proj
gate_proj
UP_PROJ
post_attention_layernorm
k_proj
 
虽然所有这些都确实存在于模型中。
另外，@hans Kilian在评论中提到，我可能会放一些文件，而这些文件不需要到source_model文件夹中。
我在convert.py中检查了第11行，其中一些键在模型中不存在。]]></description>
      <guid>https://stackoverflow.com/questions/79468013/how-to-run-deepseek-model-locally</guid>
      <pubDate>Tue, 25 Feb 2025 22:14:20 GMT</pubDate>
    </item>
    <item>
      <title>Importerror：无法从“火炬”（未知位置）导入“张量”的名称</title>
      <link>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</link>
      <description><![CDATA[我正在尝试从Pytorch导入 ：
 来自火炬导入张量
 
但我一直遇到此错误：
  Importerror：无法从“火炬”（未知位置）导入名称&#39;tensor&#39;
 
我尝试的是：

检查是否已安装了Pytorch（ pip show torch ），我正在使用版本 2.5.1 。。
重新安装了Pytorch：
  pip卸载火炬
PIP安装火炬
 

测试了python壳中的导入，但错误仍然存​​在。

环境：

 Python版本：3.10 
 Pytorch版本：2.5.1 
 OS：Windows 10 
虚拟环境：是

我该如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</guid>
      <pubDate>Sat, 18 Jan 2025 13:04:35 GMT</pubDate>
    </item>
    <item>
      <title>Pycharm调试不使用TensorFlow。我该如何解决？</title>
      <link>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</link>
      <description><![CDATA[我已经成功安装了以下内容：
  TensorFlow（最新版本2.16.1）
Keras（最新版本3.1.1
 
我正在使用Pycharm 2023.3.5（社区版）。我有一些代码，其中包括tensorflow：
  ...
从tensorflow.keras导入后端为k
...
 
每当我调试代码时，我会收到一个错误，如下所示：
  trackback（最近的最新通话）：
file＆quot” c：\ program文件\ jetbrains \ pycharm社区版2023.3.5 \ plugins \ python-ce \ helpers \ pydev \ pydev \ _pydevd_bundle \ pydevd_xml.py; pydevd_xml.py;
如果Isinstance（o，t [0]）：
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^因为
file＆quot c：\ program files \ python312 \ lib \ lib \ site-packages \ tensorflow \ python \ python \ platform \ flags.py＆quots＆quot＆quort＆quot＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort of 73，in __getAttribute __
返回自我.__ dict __ [&#39;__包装&#39;] .__ getAttribute __（名称）
       ~~~~~~~~~~~~~~ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^es
KeyError：&#39;__包装&#39;
 
我想相信这个问题不是由TensorFlow引起的，但我似乎无法弄清楚确切的问题。我已经浏览了互联网，但无济于事。我得到的最接近的解决方案是问题，但是在我看来，这似乎是一个不同的问题。拜托，这个崇高平台的人，我的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78241816/pycharm-debug-is-not-working-with-tensorflow-how-do-i-resolve-it</guid>
      <pubDate>Fri, 29 Mar 2024 03:17:26 GMT</pubDate>
    </item>
    <item>
      <title>小学习率与大学习率</title>
      <link>https://stackoverflow.com/questions/62690725/small-learning-rate-vs-big-learning-rate</link>
      <description><![CDATA[在对神经网络的反向传播学习中，我们是否应该从较小的学习率开始并在学习过程中慢慢增加它？还是我们应该从大型学习率开始，并在学习过程中慢慢降低它？
哪个是正确的？]]></description>
      <guid>https://stackoverflow.com/questions/62690725/small-learning-rate-vs-big-learning-rate</guid>
      <pubDate>Thu, 02 Jul 2020 07:02:54 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法找到整个数据集中最具代表性的样本集？</title>
      <link>https://stackoverflow.com/questions/56092302/is-there-a-way-to-find-the-most-representative-set-of-samples-of-the-entire-data</link>
      <description><![CDATA[我正在研究文本分类，我有一组200.000条推文。
这个想法是手动标记一组简短的推文和火车分类器，以预测其余标签。监督学习。
我想知道的是，如果有一种方法可以选择哪些样品在火车集合中包含在火车组中，以使该火车组合是整个数据集的良好代表，并且由于火车组中包含的高度多样性，因此训练有素的分类器具有相当多的信任，可以在其余推文上应用。     。]]></description>
      <guid>https://stackoverflow.com/questions/56092302/is-there-a-way-to-find-the-most-representative-set-of-samples-of-the-entire-data</guid>
      <pubDate>Sat, 11 May 2019 16:37:28 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch模型没有训练[关闭]</title>
      <link>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</link>
      <description><![CDATA[我有一个我无法解决的问题。我正在尝试构建CIFAR -10分类器，但是我每批随机跳跃后我的损失值即使在同一批批次上也无法改善（我什至无法用一批批量过度拟合），所以我想唯一可能的原因是 - 权重是没有更新。 
 我的模块类 
 类NET（NN.MODULE）：
def __init __（自我）：
    超级（net，self）.__ init __（）
    self.conv_pool = nn.Sequepential（
        nn.conv2d（3，64，3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（64、128、3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（128，256，3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（256，512，3，填充= 1），
        nn.relu（），
        nn.maxpool2d（2，2），
        nn.conv2d（512，512，1），
        nn.relu（），
        nn.maxpool2d（2，2））

    self.fcnn = nn。
        nn.linear（512，2048），
        nn.relu（），
        nn.linear（2048，2048），
        nn.relu（），
        nn.linear（2048，10）
    ）

def向前（self，x）：
    x = self.conv_pool（x）
    X = X.View（-1，512）
    x = self.fcnn（x）
    返回x
 
优化器我正在使用：
  net = net（）
标准= nn.Crossentropyloss（）
优化器= optim.sgd（net.parameters（），lr = 0.001，动量= 0.9）
 
我的火车功能：
  def train（）：
对于范围（5）范围内的时期：＃多次循环数据集循环
    对于我的范围（0，df_size）：
        ＃获取数据

        尝试：
            图像，标签= LoadBatch（DS，I）
        除了baseexception：
            继续

        ＃ 裹 
        输入=变量（图像）

        优化器.zero_grad（）

        输出= NET（输入）

        损失=标准（输出，变量（标签））

        loss.backward（）
        优化器.step（）
        ACC =测试（图像，标签）
        打印（“损失：” + str（lose.data [0]） +“精度％：” + str（acc） +“迭代：” + str（i））

        如果我％40 == 39：
            TORCH.SAVE（net.state_dict（），“ model_save_cifar”）

    打印（“完成时代” + str（epoch））
 
我正在使用 batch_size  = 20， image_size  = 32（cifar-10）
  loadBatch 功能返回 longtensor  20x3x32x32的元组，用于图像的 longtensor  20x1 for Labels 
如果您能帮助我或建议可能的解决方案，我会很高兴（我猜是因为NN中的顺序模块，但是我传递给优化器的参数似乎是正确的））]]></description>
      <guid>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</guid>
      <pubDate>Thu, 27 Jul 2017 19:07:27 GMT</pubDate>
    </item>
    <item>
      <title>预测建模 - 分组ID和移动平均值的回归</title>
      <link>https://stackoverflow.com/questions/40221646/predictive-modelling-regression-with-grouped-ids-and-moving-average</link>
      <description><![CDATA[我有一个预测建模问题的问题。起始位置如下所示。 S1-S2是传感器测量值，RUL是我的目标值。
数据架构：
  ID期间S1 S2 S3 Rul
1 1 510.23 643.43 1585.29 6
1 2 512.34 644.89 1586.12 5
1 3 514.65 645.11 1587.99 4
1 4 512.98 647.59 1588.45 3
1 5 516.34 649.04 1590.65 2
1 6 518.12 652.62 1593.09 1
2 1 509.77 640.61 1584.91 9
2 2 510.26 642.06 1586.00 8
2 3 511.95 643.62 1588.09 7 
2 4 513.51 646.51 1589.45 6
2 5 512.17 648.06 1589.54 5
2 6 515.56 646.11 1586.22 4
2 7 518.78 649.34 1586.96 3
2 8 519.90 650.30 1588.95 2
2 9 521.05 651.39 1591.34 1
3 1 501.11 653.99 1580.45 8
3 2 511.45 643.23 1584.09 7
3 3 505.45 643.78 1586.11 6
3 4 504.45 643.43 1588.34 5 
3 5 506.45 643.71 1589.89 4
3 6 511.45 643.33 1591.21 3
3 7 516.45 643.61 1592.42 2
3 8 518.45 643.05 1596.77 1
 
目标：
我的目标是预测看不见数据的剩余有用的现场（rul）。在这种情况下，我只有1种具有不同ID的机器（这意味着1类型和3种不同的物理系统）。为了预测，ID没关系，因为它是同一台机器。此外，我想添加新功能。 S1 S2和S3的移动平均值。因此，我必须添加带有名称A1，A2和A3的三个新列。
例如，A1应该看起来像：
  A1
南
南
512.41
513.32
514.66
515.81
南
南
510.66
511.91
512.54
513.75
515.50
518.08
519.91
南
南
506.00
507.12
505.45
507.45
511.45
515.45
 
下一个问题是，我无法与Nan一起工​​作，因为它是字符串。对于A1，A2和A3，我如何忽略/使用它？
下一个问题是：如何使用带有Train_test_split的Randomforest和Baged Discobled的回归模型来预测看不见的新数据的规则？ （当然，我需要更多数据，此示例仅给出结构。）[S1]，[S2]，[S3]是我的输入，RUR是输出。
此外，我想用平均绝对误差，平均误差和R²。评估模型。
 finaly，我想使用GridSearch方法进行调整。
我知道我想做什么，但是我无法与Python意识到这一点。完整的代码将是完美的。]]></description>
      <guid>https://stackoverflow.com/questions/40221646/predictive-modelling-regression-with-grouped-ids-and-moving-average</guid>
      <pubDate>Mon, 24 Oct 2016 15:04:57 GMT</pubDate>
    </item>
    <item>
      <title>机器学习算法选择</title>
      <link>https://stackoverflow.com/questions/15292547/machine-learning-algorithm-selection</link>
      <description><![CDATA[我是机器学习的新手。我的问题是制作一台机器，根据学生的位置和感兴趣的领域为学生选择大学。即，应该在同一城市中选择与学生地址相同的大学。我对选择算法感到困惑，我可以将perceptron算法用于此任务。 ]]></description>
      <guid>https://stackoverflow.com/questions/15292547/machine-learning-algorithm-selection</guid>
      <pubDate>Fri, 08 Mar 2013 11:07:51 GMT</pubDate>
    </item>
    <item>
      <title>减少机器学习的数学方法？</title>
      <link>https://stackoverflow.com/questions/2652121/less-mathematical-approaches-to-machine-learning</link>
      <description><![CDATA[出于好奇，我一直在阅读机器学习领域，我对所涉及的计算和数学量感到惊讶。  我正在阅读的一本书使用了诸如环理论和PDE的高级概念（注意：我对PDES的唯一知识是他们使用那个有趣的角色）。  考虑到数学本身很难学习。，这让我感到奇怪。

是否有使用不同方法的机器学习分支？
我认为，更多的方法更多地依赖于逻辑，记忆力，毫无根据的假设的构建以及过度归纳的方法是更好的选择，因为这似乎更像动物的思维方式。  动物没有（明确）计算概率和统计；至少据我所知。]]></description>
      <guid>https://stackoverflow.com/questions/2652121/less-mathematical-approaches-to-machine-learning</guid>
      <pubDate>Fri, 16 Apr 2010 10:22:01 GMT</pubDate>
    </item>
    </channel>
</rss>