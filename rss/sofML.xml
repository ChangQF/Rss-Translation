<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 07 Jan 2024 21:12:15 GMT</lastBuildDate>
    <item>
      <title>Kaggle 奖章学位和 Kaggle 路线图</title>
      <link>https://stackoverflow.com/questions/77774899/kaggle-medal-degree-and-kaggle-roadmap</link>
      <description><![CDATA[法提赫·穆罕默德·科奇。作为一名最近开始自己编码并参加数据集和竞赛的数据科学家
为什么我无法赢得奖牌和点赞？我应该怎么办？你给我什么建议？非常感谢。
我写了98个代码，但不明白为什么，我怎么会是第一个
https://www.kaggle.com/code/fatihmehmetkoc/knn -74-成功
在此处输入图像描述
我做了研究，更新了我的代码，但它不起作用]]></description>
      <guid>https://stackoverflow.com/questions/77774899/kaggle-medal-degree-and-kaggle-roadmap</guid>
      <pubDate>Sun, 07 Jan 2024 21:11:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 PYTHONPATH=../:. python pyFile.py 运行文件</title>
      <link>https://stackoverflow.com/questions/77774817/how-to-use-pythonpath-python-pyfile-py-to-run-file</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77774817/how-to-use-pythonpath-python-pyfile-py-to-run-file</guid>
      <pubDate>Sun, 07 Jan 2024 20:50:59 GMT</pubDate>
    </item>
    <item>
      <title>图片自动标注</title>
      <link>https://stackoverflow.com/questions/77774508/automatic-annotation-of-pictures</link>
      <description><![CDATA[我最感兴趣的一点是，可以自动构建边界框，而不是手动注释图片，以进一步对 Yolo 模型进行机器学习，甚至可能不需要对模型进行标记预训练。
我有一个合成数据集，为了训练基于它的模型，有必要构建图片中对象的边界框（ x，y，w，h ），但没有足够的时间手动执行此操作。
感谢您的回答。
yolo_net = cv2.dnn.readNet(&#39;yolov3.weights&#39;, &#39;yolov3.cfg&#39;) # 替换为您的 YOLO 模型文件
Layer_names = yolo_net.getUnconnectedOutLayersNames()


# 注释图像中对象的函数
def annotate_objects（图像路径，输出路径）：
    图像 = cv2.imread(image_path)
    高度，宽度，_ = image.shape

    # 将图像转换为blob并执行前向传递
    blob = cv2.dnn.blobFromImage(图像, 比例因子=1/255.0, 大小=(416, 416), swapRB=True, 作物=False)
    yolo_net.setInput(blob)
    检测= yolo_net.forward(layer_names)

    最大置信度 = 0.0
    最大类别 ID = -1
    最大框=无

    用于检测中的检测：
        对于检测中的 obj：
            分数 = obj[5:]
            class_id = Scores.argmax()
            置信度 = 分数[class_id]

            如果置信度&gt; 0.5: # 根据需要调整置信度阈值
                # 提取边界框坐标
                center_x, center_y, box_width, box_height = (obj[0:4] * [宽度,高度,宽度,高度]).astype(int)
                x, y = int(center_x - box_width / 2), int(center_y - box_height / 2)

                # 跟踪每个类别具有最高置信度的盒子
                如果置信度&gt;最大置信度：
                    最大置信度 = 置信度
                    最大类别 ID = 类别 ID
                    最大框 = (x, y, 框宽度, 框高度)

    # 在图像上为置信度最高的类绘制边界框
    如果 max_class_id != -1:
        cv2.rectangle(图像, (max_box[0], max_box[1]), (max_box[0] + max_box[2], max_box[1] + max_box[3]), (0, 255, 0), 2)

    # 保存带注释的图像
    annotated_image_path = os.path.join(output_path, os.path.basename(image_path))
    cv2.imwrite（注释图像路径，图像）

这个脚本效果不佳，它适用于动物或汽车等常规图片，但不适用于我的特定数据集。]]></description>
      <guid>https://stackoverflow.com/questions/77774508/automatic-annotation-of-pictures</guid>
      <pubDate>Sun, 07 Jan 2024 19:23:08 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助使用 keras* 破译 *lstm seqtoseq 模型无法通过 >> tf.keras.losses.SparseCategoricalCrossentropy 获得优化</title>
      <link>https://stackoverflow.com/questions/77774365/want-help-in-decipher-lstm-seqtoseq-model-using-keras-not-able-to-get-optimiza</link>
      <description><![CDATA[
在使用 lstm seqtoseq 制作聊天机器人时，我在  处遇到错误
使用  分割数据进行预测在此处输入图像描述
ValueError：所有单元格都必须具有 state_size 属性。
https://github.com/IshanThapa/Deep -NLP-A-Z/blob/main/Untitled.ipynb

我尝试了 keras 库溢出代码片段中的代码片段，但无法通过，还想提一下，我是一名学生，没有太多知识从 stackoverflow 寻求帮助，我发布了这个问题..好像有人可以为我提供如何整理的信息这些错误。]]></description>
      <guid>https://stackoverflow.com/questions/77774365/want-help-in-decipher-lstm-seqtoseq-model-using-keras-not-able-to-get-optimiza</guid>
      <pubDate>Sun, 07 Jan 2024 18:37:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorFlow 进行神经网络训练期间，损失激增至 nan</title>
      <link>https://stackoverflow.com/questions/77774308/loss-spikes-to-nan-during-neural-network-training-with-tensorflow</link>
      <description><![CDATA[我正在尝试训练一个简单的神经网络模型来对图像是否是叉子图片进行分类。我有 400 张图片，它们都很简单，即工具在一张空白页上。因此，我尝试用神经网络来训练它，但几乎每次它都完全正常，但在随机时期会因为 nan 而导致损失，然后我的计算机就会崩溃。
这是我的代码
将 numpy 导入为 np
将张量流导入为 tf
从 keras.layers 导入密集
从 keras 导入顺序
从tensorflow.python.keras.losses导入BinaryCrossentropy
从 keras.optimizers 导入 Adam
从 keras.regularizers 导入 l2
  
imageX = np.load(&#39;forkImages.npy&#39;)
imageY = np.load(&#39;forkY.npy&#39;)
打印（图像X[0]）
打印（imageY.shape）

imageX = imageX.astype(&#39;float32&#39;) /255
打印（图像X[0]）

模型=顺序（[
    密集（单位= 25，激活=&#39;sigmoid&#39;，kernel_regularizer = l2（0.0001）），
    密集（单位= 15，激活=&#39;sigmoid&#39;，kernel_regularizer = l2（0.0001）），
    密集（单位= 1，激活=&#39;sigmoid&#39;，kernel_regularizer = l2（0.0001））
]）

model.compile(损失=BinaryCrossentropy(),优化器=Adam(0.00001))

model.fit(imageX,imageY,epochs=100)

打印（imageX.shape[0]）
对于范围内的 i(imageX.shape[0])：
    预测 = model.predict(np.expand_dims(imageX[i],axis=0))
    print(&#39;实际：&#39; + str(imageY[i]) + &#39;，预测：&#39; + str(预测))

我已经尝试了我能想到的和我在互联网上找到的一切。我将隐藏层的激活更改为“relu”。我尝试过更复杂的模型，比如很多层，每个层中有更多单元。我曾尝试取消所有管制。这些都对我的脚本结果没有任何改变。
我在堆栈溢出上看到了类似的问题，但没有一个答案对我有用。]]></description>
      <guid>https://stackoverflow.com/questions/77774308/loss-spikes-to-nan-during-neural-network-training-with-tensorflow</guid>
      <pubDate>Sun, 07 Jan 2024 18:23:52 GMT</pubDate>
    </item>
    <item>
      <title>建立模型时遇到困难</title>
      <link>https://stackoverflow.com/questions/77773807/having-trouble-building-a-model</link>
      <description><![CDATA[我正在使用此数据集（https:// www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000/data）来构建决策树模型，但我在对数据进行热编码时遇到了麻烦。我不断收到错误消息，并说类别不存在于列中，或者我需要一些数字。
集合中只有一个数值。
我尝试将其余值转换为“float64”类型，但这不起作用。我搜索了 one-hot-encoding 教程，他们使用的代码没有将我的数据转换为“0”和“1”。]]></description>
      <guid>https://stackoverflow.com/questions/77773807/having-trouble-building-a-model</guid>
      <pubDate>Sun, 07 Jan 2024 16:03:30 GMT</pubDate>
    </item>
    <item>
      <title>使用所有其他列作为特征来预测汽车成本（金钱）[关闭]</title>
      <link>https://stackoverflow.com/questions/77773234/predict-cost-of-the-car-money-using-all-other-columns-as-features</link>
      <description><![CDATA[(https://i.stack.imgur.com/LhEWU.jpg)
我有以下数据集。任务是预测金钱栏。我面临的问题是我有很多分类特征。为了将这些分类特征放入模型中，我将使用 one-hot 编码。但是，当您查看数据集时，会发现某些特征是描述性的。此外，某些功能在对其应用一种热编码时，将产生额外的列，这将增加模型中数据集的大小。我必须使用所有功能。有关如何解决此问题的任何建议。
我不知道一种热编码是否有效，因为这会导致添加许多其他列。但是，任务规定我必须使用所有功能。一些功能（例如便利性和娱乐性）将导致有许多额外的列。]]></description>
      <guid>https://stackoverflow.com/questions/77773234/predict-cost-of-the-car-money-using-all-other-columns-as-features</guid>
      <pubDate>Sun, 07 Jan 2024 13:28:28 GMT</pubDate>
    </item>
    <item>
      <title>放大后的输出图像颜色与原始图像颜色不同</title>
      <link>https://stackoverflow.com/questions/77772227/upscaled-output-image-color-different-from-orginal</link>
      <description><![CDATA[我已将 Real-ESRGAN-x44-general onnx 转换为 tflite。但得到不同的颜色输出。
输入
output_image_before_conversion
输出
我尝试过的代码：
导入tensorflow.lite作为tflite
将 numpy 导入为 np
导入CV2
导入操作系统

# 定义模型和图像的路径。
model_path = “realesr-general-x4v3_float32.tflite”
input_image_path = &#39;输入.jpg&#39;
输出图像路径 = &#39;输出图像.jpg&#39;

# 检查镜像文件是否存在。
如果不是 os.path.exists(input_image_path):
    引发异常（f“错误：输入图像路径 &#39;{input_image_path}&#39; 不存在。”）

# 加载 TensorFlow Lite 模型。
解释器 = tflite.Interpreter(model_path=model_path)
解释器.allocate_tensors()

# 获取输入和输出的详细信息。
input_details =terpreter.get_input_details()
输出详细信息=解释器.get_output_details()

# 加载并预处理图像。
输入图像 = cv2.imread(输入图像路径)
input_image_rgb = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
input_image_resized = cv2.resize(input_image_rgb, tuple(input_details[0][&#39;shape&#39;][1:3]))
# 跳过标准化以查看是否是问题所在
input_image_normalized = input_image_resized.astype(np.float32) / 255.0

# 设置未归一化的输入张量
terpreter.set_tensor(input_details[0][&#39;index&#39;], [input_image_normalized])

# 运行推理。
解释器.invoke()

# 获取输出结果。
output_data =terpreter.get_tensor(output_details[0][&#39;index&#39;])
输出图像 = np.squeeze(输出数据)

# 假设模型输出在 [0, 1] 范围内，必要时进行反规范化。
# 如果模型输出不在这个范围内，这一步可能需要调整。
输出图像非标准化 = (输出图像 * 255.0).astype(np.uint8)

# 保存颜色转换前的图像以检查原始输出。
cv2.imwrite（&#39;output_image_before_conversion.jpg&#39;，output_image_denormalized）

# 将输出图像从RGB转换为BGR，以与OpenCV的保存功能保持一致。
output_image_bgr = cv2.cvtColor(output_image_denormalized, cv2.COLOR_RGB2BGR)

# 保存颜色转换后的图像以检查最终输出。
cv2.imwrite（输出图像路径，输出图像背景）

# 打印成功消息。
print(f“输出图像已成功保存到‘{output_image_path}’。”)

为什么会发生这种情况以及如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77772227/upscaled-output-image-color-different-from-orginal</guid>
      <pubDate>Sun, 07 Jan 2024 07:18:35 GMT</pubDate>
    </item>
    <item>
      <title>TF Transformer 模型永远不会过拟合，只会停滞不前：训练曲线的解读和改进建议</title>
      <link>https://stackoverflow.com/questions/77762264/tf-transformer-model-never-overfits-and-just-plateaus-interpretation-of-this-tr</link>
      <description><![CDATA[此训练曲线适用于 Transformer 模型，该模型处理 2D（不包括批次）顺序信号并使用 Adam 优化器、32 批次大小和学习率：一个自定义 LR 调度程序，它复制在“Attention is”中使用的预热调度程序所有你需要的&#39;纸。训练曲线如下所示，最终训练损失略低于验证损失，但训练损失永远不会开始回升，我将其解释为模型永远不会开始过度拟合，只是在 90 纪元后停止重新调整权重。
更好的解释和解决方案来改进这个模型？

下面是我的简短的可重现代码：
x_train = np.random.normal(size=(32, 512, 512))
批量大小 = 32
H, W = x_train.shape
行，列= np.indices（（H，W），稀疏= True）
padding_mask_init = np.zeros((H, W, W), dtype=np.bool_)
padding_mask_init[行，1：，列] = 1
padding_mask = padding_mask_init[:batch_size]
嵌入尺寸 = 512
密集_暗 = 2048
头数 = 2
形状 = (batch_size, embed_dim, 512) #(32, 512, 512)
解码器_输入=层.输入（batch_input_shape=形状，dtype=tensorflow.float16）
mha_1 = 层.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
mha_2 = 层.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
Layernorm_1 = 层.LayerNormalization()

Z = 解码器输入
Z = mha_1(查询=Z、值=Z、键=Z、use_causal_mask=True、attention_mask=padding_mask)
Z = layernorm_1(Z + 解码器输入)
Z = mha_2(查询=Z，值=解码器输入，键=解码器输入，attention_mask=padding_mask)
输出=layers.TimeDistributed（keras.layers.Dense（embed_dim，激活=“softmax”））（Z）

模型 = keras.Model(decoder_inputs, 输出)
model.compile（损失=“mean_squared_error”，optimizer=tf.keras.optimizers.Adam（learning_rate=lr_schedule（embed_dim，3000），beta_1=0.9，beta_2=0.98，epsilon=1.0e-9），metrics=[&quot; “准确度”]）

历史= model.fit（数据集，epochs = 200，validation_data = val_dataset）
]]></description>
      <guid>https://stackoverflow.com/questions/77762264/tf-transformer-model-never-overfits-and-just-plateaus-interpretation-of-this-tr</guid>
      <pubDate>Fri, 05 Jan 2024 02:47:25 GMT</pubDate>
    </item>
    <item>
      <title>在聊天机器人中实施实时人工智能分析以进行动态数据分析的策略[关闭]</title>
      <link>https://stackoverflow.com/questions/77757258/strategies-for-implementing-real-time-ai-analytics-in-a-chatbot-for-dynamic-data</link>
      <description><![CDATA[我是一名开发人员，使用各种库和矢量存储构建了一些 RAG 聊天机器人。
我们现在正在构建一个更复杂的聊天机器人，它将查询许多数据源并以图表和表格的形式生成报告。这是基于查询的表单，用户提出问题。
我们的产品团队向我提出了一个问题，我们不是为用户提供基于查询的方法，而是让模型不断分析新数据并通知用户何时应调查新机会和/或就新方法提出建议到用户的日常任务。如果数据处理已经通过传统方式完成并创建通知，那么这可能会非常简单，但我们希望人工智能生成实时分析。 :)
即。新的销售数据将告诉销售人员他们应该修改方法或方向。
我认为这可能可以通过三种方式来完成，但我认为这可能会占用大量资源，因此想就如何最好地解决这个问题获得一些其他想法。

我们可以训练在销售等特定领域接受过训练的监督模型。但模型无法完成所有新的事情。只是销售中使用新数据执行的特定任务？我们向他们发送新数据，他们计算新机会？

我们使用新数据进行微调/重新训练，我不确定微调是否真的有效，除非它只是一个面向任务的微调 LLM？保留似乎是资源密集型的？

我们将新数据发送给拥有多个领域知识的法学硕士。 LLM 并不专门研究这些领域，所以这也许也是一项微调工作？


总而言之，这个想法是让实时人工智能分析（不是传统创建的）出现在您的屏幕上，并用最新信息增强您的工作。
我还没有尝试过任何东西。]]></description>
      <guid>https://stackoverflow.com/questions/77757258/strategies-for-implementing-real-time-ai-analytics-in-a-chatbot-for-dynamic-data</guid>
      <pubDate>Thu, 04 Jan 2024 09:51:33 GMT</pubDate>
    </item>
    <item>
      <title>为什么我无法更改列表的形状或尺寸？</title>
      <link>https://stackoverflow.com/questions/77075206/why-cant-i-change-the-shape-or-dimensions-of-my-list</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;目标 = []
图片 = []

扁平数据 =[]

这些是我在预处理后附加数据集的 3 个列表，但直到现在才能够这样做，因为这些列表和我想要附加到这些列表中的列表的维度不同。 
flattened_data = np.array(flattened_data)
扁平数据=扁平数据.reshape(扁平.形状)

当我尝试使用此方法附加时，我得到以下错误：
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-29-f79792c8d9c0&gt;在&lt;细胞系：2&gt;()
      1 扁平化数据 = np.array(扁平化数据)
----&gt; 2 扁平数据 = 扁平数据.reshape(扁平.形状)
      3 forcategory in class_names: # 迭代类别名称列表
      4 对于 os.listdir(path) 中的 img：
      5

ValueError：无法将大小为 0 的数组重塑为形状 (67500,)

这里，flat是我运行下面的代码后得到的列表。
forcategory in class_names: # 迭代类别名称列表
    对于 os.listdir(path) 中的 img：
        img_array = imread(os.path.join(path, img))
        img_resized = 调整大小(img_array,(150,150,3))
        平 = img_resized.flatten()

就像这种情况一样，我还有两个列表想要分别附加到目标和图像中，但由于相同的错误（即形状或尺寸的差异）而无法这样做。]]></description>
      <guid>https://stackoverflow.com/questions/77075206/why-cant-i-change-the-shape-or-dimensions-of-my-list</guid>
      <pubDate>Sun, 10 Sep 2023 07:46:32 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降算法</title>
      <link>https://stackoverflow.com/questions/76776814/gradient-descent-algorithm</link>
      <description><![CDATA[我最近实现了线性回归的梯度下降代码。但是当我增加迭代次数时，我得到的“w”和“c”值与迭代次数成正比。谁能告诉我问题出在哪里吗？
您可以使用数据集来定义“x”和“y”
&lt;前&gt;&lt;代码&gt;w = c = 0
阿尔法 = 0.0001
y_calc = w * x + c
n = 长度 (x)
p = 浮点数（n）
u = 0
对于范围内的你（100000）：
    y_calc = w * x + c
    w = w + alpha * ((1/p) * np.sum(l * (y - y_calc)))
    c = c + alpha * ((1/p) * np.sum(y - y_calc))
    u += 1
打印（w，c）

&lt;预&gt;&lt;代码&gt;x = [32.50234527, 53.42680403, 61.53035803, 47.47563963, 59.81320787,
55.14218841、52.21179669、39.29956669、48.10504169、52.55001444、
45.41973014、54.35163488、44.1640495、58.16847072、56.72720806、
48.95588857, 44.68719623, 60.29732685, 45.61864377, 38.81681754]

y = [31.70700585, 68.77759598, 62.5623823, 71.54663223, 87.23092513,
78.21151827、79.64197305、59.17148932、75.3312423、71.30087989、
55.16567715、82.47884676、62.00892325、75.39287043、81.43619216、
60.72360244、82.89250373、97.37989686、48.84715332、56.87721319]

预计 w 为 1.389738813163012，c 为 0.03509461674147458]]></description>
      <guid>https://stackoverflow.com/questions/76776814/gradient-descent-algorithm</guid>
      <pubDate>Thu, 27 Jul 2023 05:48:21 GMT</pubDate>
    </item>
    <item>
      <title>ArrowInvalid：名为 input_ids 的第 4 列预期长度为 1000，但长度为 328</title>
      <link>https://stackoverflow.com/questions/76509562/arrowinvalid-column-4-named-input-ids-expected-length-1000-but-got-length-328</link>
      <description><![CDATA[# 格式化
block_size = 128 # 或任何适合您上下文的数字


def group_texts（示例）：
    # 连接所有&#39;input_ids&#39;
    concatenated_examples = sum(示例[“input_ids”], [])
    总长度 = len(连接示例)
    # 组织成固定长度的序列
    序列 = [
        concatenated_examples[i : i + block_size]
        对于范围内的 i（0，总长度，块大小）
    ]
    结果={
        “input_ids”：序列，
        # 移动 CLM 的标签
        “labels”：[sequence[1:] + [tokenizer.eos_token_id] 用于序列中的序列]，
    }
    返回结果


tokenized_dataset = tokenized_dataset.map(
    组文本，
    批处理=真，
    batch_size=1000, # 或任何适合您上下文的数字

我不明白 block_size 和 batch_size 指的是什么？]]></description>
      <guid>https://stackoverflow.com/questions/76509562/arrowinvalid-column-4-named-input-ids-expected-length-1000-but-got-length-328</guid>
      <pubDate>Mon, 19 Jun 2023 19:27:58 GMT</pubDate>
    </item>
    <item>
      <title>无法从“keras.utils.layer_utils”导入名称“CallFunctionSpec”（/usr/local/lib/python3.9/dist-packages/keras/utils/layer_utils.py）</title>
      <link>https://stackoverflow.com/questions/75982832/cannot-import-name-callfunctionspec-from-keras-utils-layer-utils-usr-local</link>
      <description><![CDATA[代码昨天运行良好
代码是：
来自 sklearn 导入指标
从tensorflow.keras.layers导入密集，辍学，激活，扁平化
从tensorflow.keras.models导入顺序
从tensorflow.python.keras.optimizers导入Adam

显示的错误是：
ImportError Traceback（最近一次调用最后一次）
&lt;ipython-input-71-00e64660885b&gt;在&lt;细胞系：2&gt;()
      1 从sklearn导入指标
----&gt; 2 从tensorflow.keras.layers导入Dense、Dropout、Activation、Flatten
      3 从tensorflow.keras.models导入顺序
      4 从tensorflow.python.keras.optimizers导入Adam

7帧
/usr/local/lib/python3.9/dist-packages/keras/ saving/legacy/saved_model/utils.py 在  中
     28 从 keras.utils 导入 tf_contextlib
     29 从 keras.utils.generic_utils 导入 LazyLoader
---&gt; 30 从 keras.utils.layer_utils 导入 CallFunctionSpec
     31
     32training_lib = LazyLoader(“training_lib”, globals(), “keras.engine.training”)

ImportError：无法从“keras.utils.layer_utils”导入名称“CallFunctionSpec”（/usr/local/lib/python3.9/dist-packages/keras/utils/layer_utils.py）


它说无法从“keras.utils.layer_utils”导入“CallFunctionSpec”
但我没有在其中使用 utils
我不需要其中的实用程序，我需要的是图层，但它在实用程序中显示错误
我应该如何解决无法从“keras.utils.layer_utils”导入名称“CallFunctionSpec”
并且此错误已多次出现]]></description>
      <guid>https://stackoverflow.com/questions/75982832/cannot-import-name-callfunctionspec-from-keras-utils-layer-utils-usr-local</guid>
      <pubDate>Tue, 11 Apr 2023 06:07:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 sklearn.neighbors 时出现未来警告该怎么办？</title>
      <link>https://stackoverflow.com/questions/75521999/what-to-do-about-future-warning-when-using-sklearn-neighbors</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/75521999/what-to-do-about-future-warning-when-using-sklearn-neighbors</guid>
      <pubDate>Tue, 21 Feb 2023 14:39:17 GMT</pubDate>
    </item>
    </channel>
</rss>