<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 25 May 2024 18:17:39 GMT</lastBuildDate>
    <item>
      <title>类型错误：单例数组 array(1) 不能被视为有效集合</title>
      <link>https://stackoverflow.com/questions/78532981/typeerror-singleton-array-array1-cannot-be-considered-a-valid-collection</link>
      <description><![CDATA[我有一个数据集，其中目标变量是 1 到 8 之间的数字。
现在我要实现三次SVM。
将 numpy 导入为 np
将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入 roc_auc_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

从 sklearn.svm 导入 SVC

model1 = SVC(内核=&#39;poly&#39;, 度=3)
model1.fit(X_train, y_train)

y_prob = model1.predict(X_test)
y_true = np.argmax(y_prob, 轴=0)

auc = roc_auc_score(y_test, y_true, multi_class=&#39;ovr&#39;)

现在获取 AUC，观察到以下错误：
TypeError：单例数组 array(1) 不能被视为有效集合。

如何解决此错误并找到我的模型的 AUC？]]></description>
      <guid>https://stackoverflow.com/questions/78532981/typeerror-singleton-array-array1-cannot-be-considered-a-valid-collection</guid>
      <pubDate>Sat, 25 May 2024 16:00:43 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 xml 文件在 Pytorch 中训练模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78532699/how-to-train-model-in-pytorch-with-xml-files</link>
      <description><![CDATA[我在文件夹 train 文件夹 gest_a 和 gest_b 中包含照片和 xml 文件。
如何在 pytorch 中使用它训练模型？
我想要实时识别 gest 的文件。我不使用 ipynb 文件，我只使用 .py 文件
预先感谢您的建议和解答]]></description>
      <guid>https://stackoverflow.com/questions/78532699/how-to-train-model-in-pytorch-with-xml-files</guid>
      <pubDate>Sat, 25 May 2024 14:06:01 GMT</pubDate>
    </item>
    <item>
      <title>我需要与目标服务器中的资源使用情况相关的 HTTP 请求数据集</title>
      <link>https://stackoverflow.com/questions/78532565/i-need-a-dataset-of-http-requests-related-to-the-resource-usage-in-the-target-se</link>
      <description><![CDATA[我正在设计一个机器学习模型来预测 HTTP 请求在执行服务器中引起的资源负载。我正在努力寻找具有这两个请求的数据集。
任何人都知道包含 HTTP 请求信息的数据集，例如请求的上下文、类型（POST、GET...）主体大小、标头大小、一天中的时间和一周中的某一天以及任何其他参数，以及请求在 HTTP 数据集的同一时间戳期间对服务器资源或服务器 CPU、RAM、网络 IO 数据集的影响？
我想过生成合成数据，但我想不出如何生成现实的数据，因为如果我生成大量 HTTP 调用数据，然后生成资源某些特性的估计，标签将是太偏颇了。我正在考虑通过配置 Web 服务器来生成数据并在监控时对其进行攻击，但这会很长，不会有很多不同的服务......
有人知道现有数据集或有办法生成真实且多样化的合成数据吗？]]></description>
      <guid>https://stackoverflow.com/questions/78532565/i-need-a-dataset-of-http-requests-related-to-the-resource-usage-in-the-target-se</guid>
      <pubDate>Sat, 25 May 2024 13:06:29 GMT</pubDate>
    </item>
    <item>
      <title>强化学习在完成数据分类后给予奖励，而不是一一进行，基于CNN的强化学习</title>
      <link>https://stackoverflow.com/questions/78532315/reinforcement-learning-give-reward-after-finishing-the-data-classification-inste</link>
      <description><![CDATA[我正在尝试编写一个基于强化的交易系统，在尝试这样做时，我能做的唯一方法是奖励每个动作的模型，但它实际上执行了糟糕的结果，并且无法添加我想要的所有参数。 F.E 我想添加这些参数，但为了“一一执行”模型中，我无法添加这些参数作为奖励，因为所有这些参数都可以在所有长空持有分类完成后返回
如果 roi_percent &lt; 30：
    f = 11.8
elif roi_percent &lt;&lt; 70：
    f = 9.5
elif roi_percent &lt;&lt; 140：
    f = 7.6
elif roi_percent &lt;&lt; 250：
    f = 6.4
elif roi_percent &lt;&lt; 340：
    f = 5
elif roi_percent &lt;&lt; 600：
    f = 3.6
elif roi_percent &lt;&lt; 1000：
    f = 2.46
elif roi_percent &lt;&lt; 1600：
    f = 1.34
别的：
    f = 0.7

sayi = self.条目号

如果萨伊 == 20：
    萨伊 = 70
埃利夫·萨伊10：
    萨伊 = 30 - (10*(10-萨伊))
埃利夫·萨伊20：
    萨伊 = 70 - (4*(20-萨伊))
别的：
    萨伊 = 70 - (1.6*(萨伊 - 20))

奖励 = (roi_percent * f) + (win_loss_ratio * 45) - ((self.max_drawdown * 440) / (93 - self.max_drawdown)) + (sharpe_ratio * 64) + sayi

我们还可以通过 DQN、DDQN、PPO、A2C 模型创建强化学习模型，但我想知道我们如何使用 GRU、LSTM、CNN 等模型来做到这一点。]]></description>
      <guid>https://stackoverflow.com/questions/78532315/reinforcement-learning-give-reward-after-finishing-the-data-classification-inste</guid>
      <pubDate>Sat, 25 May 2024 11:31:19 GMT</pubDate>
    </item>
    <item>
      <title>在 OpenAI Gym 中，MuJoCo Fetch 版本 1 与版本 2 的结构相同吗？</title>
      <link>https://stackoverflow.com/questions/78531991/in-openai-gym-is-the-mujoco-fetch-version-1-the-same-structure-as-version-2</link>
      <description><![CDATA[我正在使用 OpenAI Gym MuJoCo Fetch 环境。由于 MuJoCo 已经开源，Fetch 环境的第 2 版很好地支持了这一点。但网上仍然有很多使用 Fetch 版本 1 的实现（需要手动安装 MuJoCo，而不是通过 pip）。我只是想确定一下版本1和版本2之间的区别。除了MuJoCo安装之外，环境本身是否有任何修改？
在重新实现过程中，安装旧版本的 MuJoCo 对我来说既复杂又困难。所以我只是用 -v2s 替换了 Fetch-v1s，我不确定它是否正确，因为它一直失败。这个问题也可能是由于gym版本引起的，但是MuJoCo版本也可能会影响我的重新实现过程。]]></description>
      <guid>https://stackoverflow.com/questions/78531991/in-openai-gym-is-the-mujoco-fetch-version-1-the-same-structure-as-version-2</guid>
      <pubDate>Sat, 25 May 2024 09:22:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在缺失值的情况下训练模型并使用预测函数</title>
      <link>https://stackoverflow.com/questions/78531918/how-to-train-a-model-and-use-predict-function-while-having-missing-values</link>
      <description><![CDATA[我正在开发一个 ML 项目，我正在尝试训练一些分类模型，然后对测试 df 进行一些预测。
如何训练一个能够使用每个可用观察值的模型，无论它是否有缺失值？我如何做出预测？
我的 df 的大多数观察结果至少有一个缺失值。
为了训练我的模型，我使用了 caret 库。
例如，给定此模型：
control &lt;- trainControl(method=“cv”，number=10，search=“grid”，summaryFunction = TwoClassSummary，classProbs = TRUE)
unegrid &lt;- Expand.grid(.mtry=c(1:6))
rf &lt;- train(Target~.，data=train，method=“rf”，metric=“ROC”，tuneGrid=tunegrid，ntree=100，trControl=control)

然后我这样做出预测：
test$pred&lt;-predict(rf,test,&#39;prob&#39;)[,2]

在训练时，我已经尝试过这个 na.action 选项：

na.omit;

-na.exclude;

na.pass。

前两个工作正常，但如果我使用 na.pass 我会收到此错误：
出了点问题；所有 ROC 指标值均缺失：
      ROC Sens 规格    
 分钟。   ：NA 最小值。   ：NA 最小值。   : 不适用  
 第一季度：不适用 第一季度：不适用 第一季度：不适用  
 中位数 : NA 中位数 : NA 中位数 : NA  
 平均值：NaN 平均值：NaN 平均值：NaN  
 第三季度：不适用 第三季度：不适用 第三季度：不适用  
 最大限度。   ：不适用 最大。   ：不适用 最大。   : 不适用  
 不适用 :6 不适用 :6 不适用 :6    
错误：停止
警告()
1：Fold01 的模型拟合失败：mtry=1 randomForest.default(x, y, mtry = param$mtry, ...) 中的错误： 
  预测变量中不允许使用 NA

如果我使用前两个之一，当我进行预测时，我会得到与此类似的错误：
set(x, j = name, value = value) 中的错误： 
  已提供 199 件物品，分配给 5425 件物品

]]></description>
      <guid>https://stackoverflow.com/questions/78531918/how-to-train-a-model-and-use-predict-function-while-having-missing-values</guid>
      <pubDate>Sat, 25 May 2024 08:52:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们不能只使用Keys来计算self-attention？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78531893/why-cant-we-use-only-keys-to-calculate-self-attention</link>
      <description><![CDATA[我正在阅读有关自我注意机制的内容，论文建议需要计算 3 件事：Key、Query 和 Value。据我了解，具有 Value 的原因是允许根据上下文（这是直观的）调整初始嵌入（在位置编码之后）。但是，我不明白为什么我们需要那里的查询以及为什么我们不能仅使用键进行相似度计算？提前致谢。]]></description>
      <guid>https://stackoverflow.com/questions/78531893/why-cant-we-use-only-keys-to-calculate-self-attention</guid>
      <pubDate>Sat, 25 May 2024 08:42:13 GMT</pubDate>
    </item>
    <item>
      <title>通过 python 脚本使用模型</title>
      <link>https://stackoverflow.com/questions/78531849/using-a-model-via-python-script</link>
      <description><![CDATA[我可能听不懂复杂的建议和答案，但这是我的大学，我没有时间学习基础知识。
我正在尝试使用我通过 GTZAN 数据集创建的模型 - 音乐流派分类 (https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification)
模型具有很高的准确性，但我没有得到令人满意的输出。我不知道需要多少信息，但我觉得我在使用的脚本中犯了一个错误。这是脚本。
导入tensorflow为tf
导入库
将 numpy 导入为 np

# 加载预训练模型
模型 = tf.keras.models.load_model(&#39;C:/Users/VOLKAN/Desktop/SonProject/model.keras&#39;)

# 定义流派（假设您有模型预测的固定流派列表）
types = [&#39;Blues&#39;, &#39;Classical&#39;, &#39;Country&#39;, &#39;Disco&#39;, &#39;Hip-hop&#39;, &#39;Jazz&#39;, &#39;Metal&#39;, &#39;Pop&#39;, &#39;Reggae&#39;, &#39;Rock&#39;] # 替换为实际流派名字

def extract_features(文件路径):
    y，sr = librosa.load（文件路径，持续时间= 30）
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=58)
    mfccs = np.mean(mfccs.T, 轴=0)
    特征 = mfccs[np.newaxis, ...]
    返回特征



def Predict_genre(文件路径):
    特征 = extract_features(文件路径)
    预测 = model.predict(features)
    Genre_index = np.argmax(预测，轴=1)[0]
    返回类型[genre_index]

# 用法示例
audio_file = &#39;C:/Users/VOLKAN/Desktop/Data/genres_original/classical/classical.00059.wav&#39; # 替换为您的音频文件路径
预测流派 = 预测流派（音频文件）
print(f&#39;预测的类型是：{predicted_genre}&#39;)


`
在模型中，我使用了CNN。模型具有 .keras 扩展名。]]></description>
      <guid>https://stackoverflow.com/questions/78531849/using-a-model-via-python-script</guid>
      <pubDate>Sat, 25 May 2024 08:21:11 GMT</pubDate>
    </item>
    <item>
      <title>基于 Python 的模型学习，通过使用 TF、Keras 和 NLTK 进行标记化的意图</title>
      <link>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</link>
      <description><![CDATA[我使用 Tensorflow、keras 和 nltk 进行标记化，用 Python 开发了一个聊天机器人模型。当我在 vs 终端中运行它时，它会显示时间戳和模型提供答案所需的时间，但我试图在使用 React 设计的网站中显示它。如何从输出中删除日志。我已经尝试了一切，包括抑制日志，除非它们很关键，但我仍然无法删除它们。
我尝试使用这个，但它不起作用，它仍然显示它们。我知道日志不是警告，因此它们可能不会因此被删除。
导入 os os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;3&#39;]]></description>
      <guid>https://stackoverflow.com/questions/78531788/python-based-model-learning-through-intents-using-tf-keras-and-nltk-for-tokeniz</guid>
      <pubDate>Sat, 25 May 2024 08:01:27 GMT</pubDate>
    </item>
    <item>
      <title>A3C 代理（连续动作空间）没有经过适当的训练，只能达到</title>
      <link>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78531464/a3c-agent-continuous-action-space-not-being-trained-properly-and-only-reach</guid>
      <pubDate>Sat, 25 May 2024 05:21:08 GMT</pubDate>
    </item>
    <item>
      <title>使用 xgboost 推断 csv 数据时出现问题</title>
      <link>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</link>
      <description><![CDATA[我在使用 xgboost 进行推断时遇到问题：
简单来说，我想使用 xgboost 执行回归任务，由多个 csv 数据集组成。我将它们拼接成一个数据帧，并使用 train_test_split 分割训练/验证/测试。该模型运行良好（mae：0.6）。但是当我手动拆分训练集和测试集（我挑选了一部分 csv 并将其放入测试文件夹中）时，结果变得非常差（mae：12+）。
我真的很想知道这里发生了什么？我已经发布了下面的一些代码。
1：这是带有train_test_split的分割代码：
# 准备好数据
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 合并数据集
[merged_dataset = pd.concat([pd.DataFrame(dataset.X) 用于数据集中的数据集])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)

# 除法
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.2，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

# 构建xgboost模型
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_test_original, y_test_pred)]

2：这是我在代码后的手动划分：
# 训练数据集
数据集 = []
路径=&#39;../data/low_fidelity_chips_res&#39;
对于 os.listdir(path) 中的文件名：
    if filename.endswith(“.csv”)：
        数据集 = ThermalDataset(os.path.join(路径，文件名))
        数据集.append(数据集)

# 测试数据，这是我从原始数据中手动分区的测试集的 csv
测试=[]
test_file = &#39;../data/test_xgboost/Thermal014withMidPos.csv&#39;
测试 = ThermalDataset(test_file)
测试.追加（测试）

＃ 结合
merged_dataset = pd.concat([数据集中的数据集的pd.DataFrame(dataset.X)])
merged_targets = pd.concat([数据集中的数据集的pd.DataFrame(dataset.y)])
test_x = pd.concat([pd.DataFrame(test.X) 用于测试中的测试])
test_y = pd.concat([pd.DataFrame(test.y) 用于测试中的测试])

# 标准化
X_scaled = scaler.fit_transform(merged_dataset)
y_scaled = 缩放器.fit_transform(merged_targets)
x_fill = 缩放器.fit_transform(test_x)
y_fill = 缩放器.fit_transform(test_y)

＃ 分裂
X_train，X_test，y_train，y_test = train_test_split（X_scaled，y_scaled，test_size = 0.05，random_state = 11）
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=11)

＃ 火车
模型= xgb.XGBRegressor（tree_method =&#39;gpu_hist&#39;，gpu_id = device.index，n_estimators = 500，learning_rate = 0.05，max_depth = 8）
model.fit(X_train, y_train)

＃ 评估
y_val_pred_scaled = model.predict(X_val)
y_test_pred_scaled = model.predict(X_test)
y_fill_res = model.predict(x_fill)

# inverse_transform 获取原始数据
y_val_pred = scaler.inverse_transform(y_val_pred_scaled.reshape(-1, 1)).flatten()
y_test_pred = 缩放器.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()
y_pre = scaler.inverse_transform(y_fill_res.reshape(-1, 1)).flatten()
y_val_original = scaler.inverse_transform(y_val.reshape(-1, 1)).flatten()
y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()
y_fill = scaler.inverse_transform(y_fill.reshape(-1, 1)).flatten()
val_mse =mean_squared_error(y_val_original, y_val_pred)
test_mse =mean_squared_error(y_test_original, y_test_pred)
val_mae = Mean_absolute_error(y_val_original, y_val_pred)
test_mae = Mean_absolute_error(y_pre, y_fill)`

我希望能够对单个 csv 文件进行正确推理，并获得与训练中一样好的结果。]]></description>
      <guid>https://stackoverflow.com/questions/78531267/there-was-a-problem-infering-csv-data-with-xgboost</guid>
      <pubDate>Sat, 25 May 2024 02:40:08 GMT</pubDate>
    </item>
    <item>
      <title>langchain RetrievalQA 错误：ValueError：缺少一些输入键：{'query'}</title>
      <link>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</link>
      <description><![CDATA[在 RAG 项目中，我使用的是 langchain。当我使用查询输入运行 QA 链时，此错误一直出现：
----&gt; result = qa_chain({&#39;query&#39;: question})
ValueError: 缺少一些输入键：{&#39;query&#39;}

这是我的代码：
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# 构建提示
template = &quot;&quot;&quot;根据以下上下文回答问题。
上下文：
{context}
------------------
问题：{query}
答案：&quot;&quot;&quot;

# LLM 链
QA_CHAIN_PROMPT = PromptTemplate.from_template(template)
qa_chain = RetrievalQA.from_chain_type(
llm,
trieser=vectordb.as_retriever(),
return_source_documents=True,
chain_type_kwargs={&quot;prompt&quot;: QA_CHAIN_PROMPT}
)

question = &quot;这篇研究论文使用了什么方法？&quot;

result = qa_chain({&#39;query&#39;: question})

# 检查查询结果
result[&quot;result&quot;]
# 检查我们从中获取的源文档
result[&quot;source_documents&quot;][0]
]]></description>
      <guid>https://stackoverflow.com/questions/78530745/langchain-retrievalqa-error-valueerror-missing-some-input-keys-query</guid>
      <pubDate>Fri, 24 May 2024 21:23:49 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我相信问题不在于我的代码，而在于库冲突，但我不确定。
导入 pandas 作为 pd
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
从 sklearn.preprocessing 导入 StandardScaler #actually scikit-learn
从 imblearn.over_sampling 导入 RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
    X = dataframe[dataframe.columns[:-1]].values
    Y = dataframe[dataframe.columns[-1]].values

    定标器=标准定标器() 
    X = 缩放器.fit_transform(X) 

    如果过采样：
        ros = RandomOverSampler()
        X, Y = ros.fit_resample(X,Y) 
    数据 = np.hstack((X, np.reshape(Y, (-1, 1))))
    返回数据，X，Y

print(len(train[train[“班级”]==1]))
print(len(train[train[“班级”]==0]))

训练，X_train，Y_train =scale_dataset（训练，True）

我尝试完全导入sklearn，卸载并重新安装scipi和sklearn（作为scikit-learn），安装Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>损失函数在梯度提升中的作用是什么？</title>
      <link>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</link>
      <description><![CDATA[在梯度提升中，可以使用不同的损失函数。例如，在 sklearn 的 GradientBoostingRegressor 中，可能的损失函数有：“squared_error”、“absolute_error”、“huber”和“quantile”损失函数。
我了解损失函数在梯度下降（而不是梯度提升）中的影响。例如，与绝对误差损失函数相比，平方误差损失函数对大误差的惩罚更大。我们可以在梯度提升的情况下说类似的话吗？]]></description>
      <guid>https://stackoverflow.com/questions/78257038/what-is-the-role-of-loss-functions-in-gradient-boosting</guid>
      <pubDate>Mon, 01 Apr 2024 18:03:20 GMT</pubDate>
    </item>
    <item>
      <title>在 Google Colab Notebook 中安装 ZoeDepth</title>
      <link>https://stackoverflow.com/questions/77030715/installation-of-zoedepth-in-google-colab-notebook</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77030715/installation-of-zoedepth-in-google-colab-notebook</guid>
      <pubDate>Sun, 03 Sep 2023 02:32:35 GMT</pubDate>
    </item>
    </channel>
</rss>