<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 24 Jan 2024 09:14:22 GMT</lastBuildDate>
    <item>
      <title>识别 SMOTE 生成的合成样品</title>
      <link>https://stackoverflow.com/questions/77870847/identify-the-synthetic-samples-generated-by-smote</link>
      <description><![CDATA[我有一个带标签的数据集，X 形状为 7000 x 2400，y 形状为 7000。数据严重不平衡，因此我尝试使用 SMOTE 生成合成样本。不过，我想确定 SMOTE 实际生成的合成样本。
作为示例，下面是一个代码片段：
导入 pandas 作为 pd
将 numpy 导入为 np
从 sklearn.datasets 导入 load_iris
从 imblearn.over_sampling 导入 SMOTE

虹膜 = load_iris()

X = 虹膜[&#39;数据&#39;]
y = 虹膜[&#39;目标&#39;]

#数据是平衡的，所以我故意去掉了一些样本
X = X[:125,::]
y = y[:125]

过采样 = SMOTE()
X_smt, y_smt = oversample.fit_resample(X, y)

数组 X_smt 和 y_smt 既有原始样本又有合成样本。是否有一种简单的方法可以通过索引或其他机制来识别合成样本？]]></description>
      <guid>https://stackoverflow.com/questions/77870847/identify-the-synthetic-samples-generated-by-smote</guid>
      <pubDate>Wed, 24 Jan 2024 06:04:18 GMT</pubDate>
    </item>
    <item>
      <title>梯度消失会导致“没有为任何变量提供梯度”</title>
      <link>https://stackoverflow.com/questions/77870522/can-vanishing-gradients-cause-no-gradients-provided-for-any-variable</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77870522/can-vanishing-gradients-cause-no-gradients-provided-for-any-variable</guid>
      <pubDate>Wed, 24 Jan 2024 04:01:23 GMT</pubDate>
    </item>
    <item>
      <title>如何查询嵌入以进行语义搜索？</title>
      <link>https://stackoverflow.com/questions/77870218/how-to-query-embeddings-for-semantic-search</link>
      <description><![CDATA[我对某些 SKU 商品有 1000 个描述，我想生成逆嵌入映射来进行语义搜索
例如，这就是我所拥有的
项目描述
项目1 [单词1，单词2，单词3，单词4......]
项目2 [字1、字2_2、字3_3、字4_4......]

如您所见，item1 和 item2 共享 word1，但 item1 和 item2 有两个不同的上下文，通过生成嵌入，我们应该能够捕获每个单词的上下文
这是我生成嵌入的方法
my_description = []
以 open(&#39;/content/gdrive/My Drive/my.csv&#39;, &#39;r&#39;) 作为数据：
    df = pd.read_csv(数据, 编码 = (&#39;utf-8&#39;),nrows=100)
    对于索引，df.iterrows() 中的行：
        my_str = 行[&#39;描述&#39;]
        my_description.append(my_str)



进口火炬
从 Transformer 导入 BertTokenizer、BertModel
%matplotlib 内联
tokenizer = BertTokenizer.from_pretrained(&#39;bert-base-uncased&#39;)
模型 = BertModel.from_pretrained(&#39;bert-base-uncased&#39;,
output_hidden_​​states = True, # 模型是否返回所有隐藏状态。
）
模型.eval()


文本2 = 公司描述[0]

# 添加特殊标记。
标记文本2 =“[CLS]” + 文本2 + &quot; [九月]”

# 将句子分割成标记。
tokenized_text2 = tokenizer.tokenize(marked_text2)

# 将标记字符串映射到它们的词汇索引。
indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text2)

snippets_ids2 = [1] * len(tokenized_text2)
tokens_tensor2 = torch.tensor([indexed_tokens2])
snippets_tensors2 = torch.tensor([segments_ids2])

使用 torch.no_grad()：
    输出2 =模型（tokens_tensor2，segments_tensors2）
    隐藏状态2 = 输出2[2]

token_embeddings2 = torch.stack(hidden_​​states2, 暗淡=0)
token_embeddings2.size()
token_embeddings2 = torch.squeeze(token_embeddings2, 暗淡=1)
token_embeddings2.size()
token_embeddings2 = token_embeddings2.permute(1,0,2)
token_embeddings2.size()

token_vecs_cat2 = []

对于 token_embeddings2 中的令牌：
     cat_vec = torch.cat((令牌[-1], 令牌[-2], 令牌[-3], 令牌[-4]), 暗淡= 0)
     token_vecs_cat2.append(cat_vec)
token_vecs_sum2 = []
将 numpy 导入为 np
x_token = np.empty((0, 768))

对于 token_embeddings2 中的令牌：
    sum_vec = torch.sum(token[-4:], dim=0)
    token_vecs_sum2.append(sum_vec)
    x_token = np.concatenate((x_token, sum_vec.numpy().reshape((1,-1))), axis=0)

x_token 将是我所有单词/令牌在一个描述中的嵌入
例如，item1 有 500 个 token，嵌入数为 700
x_token 的形状为 (500 x 700)
所以对于每个项目我都会有这样的东西
项目标记嵌入
项目 1 标记 1 [x1,x2,x3,.....]
项目 1 标记 2 [x1,x2,x3,.....]
....
项目 2 令牌 1_2 [x1,x2,x3,.....]
项目 2 标记 2_2 [x1,x2,x3,.....]
....
项目 n 标记 1_n [x1,x2,x3,.....]
项目 n 标记 2_n [x1,x2,x3,.....]

现在我的问题是如何执行搜索
如果我的搜索查询是一个句子
“word1 word2 word3.....wordn”
如果我为句子中的每个单词生成嵌入，并对每个标记的前 10 个最近邻执行 ANN
如果我的查询有 10 个令牌，我将得到 100 个项目描述（每个令牌 10 个）
在这种情况下，我如何入围前 10 名项目描述？我应该使用哪个令牌？
查询 = [token1, token2.......tokenN]

                   前10名的nearest_neighbor的物品，
query_token1 -&gt;; [项目x1_1、项目x1_2、项目x1_10]
query_token2 -&gt;; [itemx2_1、itemx2_2、itemx2_10]

我做语义搜索错了吗？]]></description>
      <guid>https://stackoverflow.com/questions/77870218/how-to-query-embeddings-for-semantic-search</guid>
      <pubDate>Wed, 24 Jan 2024 02:10:12 GMT</pubDate>
    </item>
    <item>
      <title>加州房价预测例外[关闭]</title>
      <link>https://stackoverflow.com/questions/77870091/california-housing-price-prediction-exception</link>
      <description><![CDATA[我编写了以下代码：

将 pandas 导入为 pd
housing_pd = pd.read_csv(“housing.csv”)
housing_pd
housing_pd[“ocean_proximity”].value_counts()
housing_pd_shuffled = housing_pd.sample(n=len(housing_pd), random_state=1)
housing_pd_shuffled
pd.get_dummies(housing_pd_shuffled[&#39;ocean_proximity&#39;]).head()

在执行最后一行代码（第 7 行）之前，一切似乎都工作得很好。我能否获得额外的帮助来了解为什么会发生这种情况，因为我跟随教程的讲师没有遇到此问题。
尝试多次执行，但我遇到了如下图所示的相同问题： ]]></description>
      <guid>https://stackoverflow.com/questions/77870091/california-housing-price-prediction-exception</guid>
      <pubDate>Wed, 24 Jan 2024 01:23:03 GMT</pubDate>
    </item>
    <item>
      <title>Aws SageMaker 实时随机砍伐森林</title>
      <link>https://stackoverflow.com/questions/77869995/aws-sagemaker-random-cut-forest-real-time</link>
      <description><![CDATA[我正在尝试了解 Sagemaker 的工作原理。我的 OpenSearch 中有一些数据需要识别异常情况。
我知道我可以执行以下逻辑：

将我的 OpenSearch 数据导入为 CSV 或使用 SDK；
使用随机森林砍伐 (RCF) 算法；
在 SageMaker 中生成端点；

但是，我的 OpenSearch 数据是实时的，我希望实时预测有一个（实时）仪表板，我们可以在其中观察异常行为并可能生成某种警报。
当 OpenSearch 收到新数据时，是否有可能在 SageMaker 中自动运行查询并将结果显示在像 Grafana 这样的仪表板上？]]></description>
      <guid>https://stackoverflow.com/questions/77869995/aws-sagemaker-random-cut-forest-real-time</guid>
      <pubDate>Wed, 24 Jan 2024 00:43:59 GMT</pubDate>
    </item>
    <item>
      <title>使用 Keras 将模型连接在一起</title>
      <link>https://stackoverflow.com/questions/77869483/connect-models-together-with-keras</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77869483/connect-models-together-with-keras</guid>
      <pubDate>Tue, 23 Jan 2024 21:53:49 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 创建自定义模型类</title>
      <link>https://stackoverflow.com/questions/77869443/create-custom-model-class-with-python</link>
      <description><![CDATA[我有一个示例类如下：
类 MLP(nn.Module)：
    # 声明一个带有模型参数的层。在这里，我们完全声明两个
    # 连接层
    def __init__(自身):
        # 调用`MLP`父类`Module`的构造函数来执行
        # 必要的初始化。这样，其他函数参数
        # 也可以在类实例化时指定，比如模型
        # 参数，`params`（稍后描述）
        超级().__init__()
        self.hidden = nn.Linear(20, 256) # 隐藏层
        self.out = nn.Linear(256, 10) # 输出层

    # 定义模型的前向传播，即如何返回
    # 基于输入“X”所需的模型输出
    def 向前（自身，X）：
        # 注意这里我们使用 ReLU 中定义的函数版本
        # nn.功能模块。
        返回 self.out(torch.relu(self.hidden(X)))

调用类是这样的：
net = MLP() net(X)
现在，我需要为 4 层模型创建类似的类和函数：
图层配置激活功能
全连接输入大小 128，输出大小 64 ReLU
全连接输入大小 64，输出大小 32 ReLU
辍学概率 0.5 -
全连接输入大小 32，输出大小 1 Sigmoid
我需要传递以下断言：
&lt;前&gt;&lt;代码&gt;模型 = Net()

断言 model.fc1.in_features == 128
断言 model.fc1.out_features == 64
断言 model.fc2.in_features == 64
断言 model.fc2.out_features == 32
断言 model.fc3.in_features == 32
断言 model.fc3.out_features == 1

x = 火炬.rand(2, 128)
输出 = model.forward(x)
断言 output.shape == (2, 1), “Net() 错误！”

这是我到目前为止所拥有的：
类 Net(nn.Module):
    def __init__(自身):
        超级（网络，自我）.__init__()
                
        
        self.fc1 = nn.Linear(128, 64)
        self.fc2 = nn.Linear(64, 32)
        self.dropout = nn.Dropout(p=0.5)
        self.fc3 = nn.Linear(32, 1)
        

    def 前向（自身，x）：
        返回 self.fc3(torch.sigmoid(self.dropout(self.fc2(torch.relu(self.fc1(torch.relu(X)))))))
       

但是我收到错误：
运行时错误：mat1 和 mat2 形状无法相乘（2x20 和 128x64）

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77869443/create-custom-model-class-with-python</guid>
      <pubDate>Tue, 23 Jan 2024 21:44:52 GMT</pubDate>
    </item>
    <item>
      <title>为什么变压器编码器/源掩码具有形状（序列长度、序列长度）？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77869184/why-does-the-transformer-encoder-source-mask-have-shape-sequence-length-sequen</link>
      <description><![CDATA[转换器源/编码器掩码的大小为 (S,S)，其中 S 是输入序列的长度。为什么是方阵？它不应该是一维形状吗？
例如，如果我有一个输入 [x,y,z,0,0,0]，其中 x,y,z 是大小等于隐藏维度的向量，则掩码应为 [1, 1,1,0,0,0] 表示 x,y,z 是 0,0,0 处的输入，是填充]]></description>
      <guid>https://stackoverflow.com/questions/77869184/why-does-the-transformer-encoder-source-mask-have-shape-sequence-length-sequen</guid>
      <pubDate>Tue, 23 Jan 2024 20:46:24 GMT</pubDate>
    </item>
    <item>
      <title>TF 损失：nan - 精度：0.0000e+00</title>
      <link>https://stackoverflow.com/questions/77868774/tf-loss-nan-accuracy-0-0000e00</link>
      <description><![CDATA[我在训练过程中遇到一个问题，损失变为 NaN，而准确度仍为 0.0。我已尝试解决该问题，但正在寻求有关潜在原因和解决方案的建议。
load_images_and_labels 方法从给定文件夹和 JSON 文件读取图像和标签数据。对于每个图像，它从 JSON 注释中提取灰度表示、关联的类别标签和边界框坐标，将它们组织到 NumPy 数组中，以便在机器学习任务中进一步使用。
def load_images_and_labels(folder_path, json_path):
    使用 open(json_path, &#39;r&#39;) 作为 json_file：
        label_data = json.load(json_file)

    图像数据 = []
    标签=[]
    盒子=[]

    对于 label_data[“images”] 中的 image_info：
        image_id = image_info[“id”]

        # 构造文件的完整路径
        文件名=图像信息[“文件名”]
        image_path = os.path.join(文件夹路径, 文件名)

        img = cv2.imread(图像路径)

        img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # 根据 JSON 数据中的 image_id 提取所有标签和边界框
        image_annotations = [label_data[“annotations”中的项目的项目] if item[“image_id”] == image_id]

        # 检查图像是否有注释
        如果图像_注释：
            对于 image_annotations 中的注释：
                # 提取标签和边界框信息
                image_label = 注释[“category_id”]
                bbox = 注释[“bbox”]

                # 将图像、标签和边界框添加到数组中
                image_data.append(img_grey)
                labels.append(image_label)
                盒子.append(bbox)

    # 将列表转换为 NumPy 数组
    image_array = np.array(image_data).astype(&#39;float32&#39;)
    label_array = np.array(标签)
    box_array = np.array(boxes).astype(&#39;float32&#39;)

    返回图像_数组、标签_数组、盒子_数组

方法的形状符合我的期望。
下面你可以看到我训练模型的方法。但我的输出如下所示：
&lt;前&gt;&lt;代码&gt;纪元 1/10
112/112 [================================] - 4s 15ms/步 - 损耗：nan - 精度：2.8035e- 04
纪元 2/10
112/112 [==============================] - 2s 15ms/步 - 损耗：nan - 精度：0.0000e+ 00
纪元 3/10
112/112 [==============================] - 2s 15ms/步 - 损耗：nan - 精度：0.0000e+ 00
纪元 4/10
112/112 [==============================] - 2s 15ms/步 - 损耗：nan - 精度：0.0000e+ 00

input_image = 输入(形状=(400, 400), name=&#39;image_input&#39;)
input_bbox = 输入（形状=（4，），名称=&#39;bounding_box_input&#39;）

# Flachklopfen des Bildes
展平图像 = 展平（）（输入图像）

merged_input = Concatenate()([flatten_image, input_bbox])

x = 密集（64，激活=&#39;relu&#39;）（merged_input）
输出层=密集（28，激活=&#39;softmax&#39;）（x）

模型 = tf.keras.Model(输入=[input_image, input_bbox], 输出=output_layer)
model.compile(optimizer=&#39;adam&#39;,loss=&#39;sparse_categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

＃ 训练
model.fit({&#39;image_input&#39;: train_images, &#39;bounding_box_input&#39;: train_boxes}, train_labels, epochs=10)

我已经考虑过以下事项：

检查数据和标签的正确性。
可以在此处找到证据
标准化图像中的像素值。例如：train_images = train_images / 255.0
]]></description>
      <guid>https://stackoverflow.com/questions/77868774/tf-loss-nan-accuracy-0-0000e00</guid>
      <pubDate>Tue, 23 Jan 2024 19:20:45 GMT</pubDate>
    </item>
    <item>
      <title>优化 CT 扫描分割的 U-Net 训练：专门强调具有感兴趣区域 (ROI) 的切片 [关闭]</title>
      <link>https://stackoverflow.com/questions/77868697/optimizing-u-net-training-for-ct-scan-segmentation-exclusive-emphasis-on-slices</link>
      <description><![CDATA[专门在包含感兴趣区域 (ROI) 的 CT 扫描切片上训练 U-Net 模型，同时排除没有 ROI 的切片，这是一种合理的方法吗？在医学图像分析中采用这种策略进行分割任务有哪些潜在的优点和缺点？
在我进行的测试中，与仅使用 ROI 切片相比，使用所有切片产生了更好的结果。然而，我认为，当将分析限制在仅包含 ROI 的切片时，可以获得最准确的结果。]]></description>
      <guid>https://stackoverflow.com/questions/77868697/optimizing-u-net-training-for-ct-scan-segmentation-exclusive-emphasis-on-slices</guid>
      <pubDate>Tue, 23 Jan 2024 19:04:12 GMT</pubDate>
    </item>
    <item>
      <title>每个用户具有多行的回归模型来预测死亡[关闭]</title>
      <link>https://stackoverflow.com/questions/77868519/regression-model-with-multiple-rows-per-user-to-predict-death</link>
      <description><![CDATA[我正在尝试建立一个回归模型，用于根据用户的实验室报告预测死亡率，问题是在我的数据集中，即使对于同一用户，每一行也是不同的实验室，例如：
值开始类别单位类型显示record.death种子report_Frequency
 3 25.83 1291715668918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
25 26.47 1318326868918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
37 27.42 1386669268918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
49 29.19 1481622868918 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1561456468918 -4803776664509238228 4
74 19.35 1196939625807 生命体征 kg/m2 39156-5 体重指数 (BMI) [比率] 1490267625807 401572787436335446 10

我不太确定使用什么作为我的特征，我使用值、开始（这是时间戳中的实验室日期）和类型（这是指标类型的代码），目标变量是record.death，事情正如您在表中看到的那样，根据每个用户访问实验室的次数，我可以有多个行，我使用线性回归，但我的均方误差太高，可能出了什么问题？也许我需要为这种情况使用另一个模型？]]></description>
      <guid>https://stackoverflow.com/questions/77868519/regression-model-with-multiple-rows-per-user-to-predict-death</guid>
      <pubDate>Tue, 23 Jan 2024 18:25:58 GMT</pubDate>
    </item>
    <item>
      <title>将 xml 注释与图像链接以创建数据集 [关闭]</title>
      <link>https://stackoverflow.com/questions/77868119/link-xml-annotations-with-images-to-create-dataset</link>
      <description><![CDATA[我在一个文件夹中有一个数据集，该文件夹包含 2 个名为 train 的子文件夹，test 火车内部有两个子文件夹注释（它们是 XML 文件）和图像，它们是没有标签或边界框的数据集的图像，所以我想要将它们链接在一起以获得可以操作和训练模型的数据集
请注意，数据集位于我的本地计算机中，我计划使用 YOLOv5 和 google colab
如何将 XML 文件与图像链接并准备好可供使用的数据集？]]></description>
      <guid>https://stackoverflow.com/questions/77868119/link-xml-annotations-with-images-to-create-dataset</guid>
      <pubDate>Tue, 23 Jan 2024 17:15:41 GMT</pubDate>
    </item>
    <item>
      <title>添加 2 个模型作为另一个模型的输入（图表已断开连接）</title>
      <link>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</link>
      <description><![CDATA[我有两个模型：model_A 和 model_B。我想对这两个模型进行元素明智加法，并将结果用作 model_C 的输入。所以，我有这个代码：
从tensorflow.keras.layers导入Conv2D，BatchNormalization，\
    激活、输入、添加
从tensorflow.keras.models导入模型
将 numpy 导入为 np
将张量流导入为 tf

def model_A（输入）：
    x1 = Conv2D(32, 3, padding=&#39;相同&#39;)(输入)
    x1 = BatchNormalization()(x1)
    x1 = 激活(&#39;relu&#39;)(x1)
    
    x2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(x1)
    模型=模型（输入=输入，输出=x​​2，名称=&#39;model_A&#39;）
    返回模型
    

def model_B（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(f1)

    模型=模型（输入=输入，输出=f2，名称=&#39;model_B&#39;）
    返回模型

def model_C（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(16, 3, 填充=&#39;相同&#39;)(f1)
    f2 = BatchNormalization()(f2)
    f2 = 激活(&#39;relu&#39;)(f2)

    f3 = Conv2D(1, 3, 填充=&#39;相同&#39;)(f2)

    模型=模型（输入=输入，输出=f3，名称=&#39;model_C&#39;）
    返回模型
    
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    modelC = model_C（加法）
    
    返回模型（输入，modelC.输出）
    
a = np.random.uniform(0, 1, (100, 32, 32, 3))
b = np.random.uniform(0, 1, (100, 32, 32, 3))
c = np.random.uniform(0, 1, (100, 32, 32, 3))
    
模型 = model_final(32, 32, 3)

优化器 = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(优化器=优化器,
              损失=&#39;mae&#39;,
              指标=[&#39;mae&#39;])
    

如果我运行代码，我会在 Model(inputs=inputs,outputs=f3, name=&#39;model_C&#39;) 处收到Graph Disconnected。所以，为了解决这个问题，我正在做：
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    input_C = 输入((高度,宽度,32))
    modelC = model_C(输入_C)
    modelC = modelC(加法)
    
    模型=模型（输入，模型C）
    返回模型

编译得很好。但是，我不确定这是否正确。如果这样做的逻辑是正确的！]]></description>
      <guid>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</guid>
      <pubDate>Mon, 22 Jan 2024 12:34:03 GMT</pubDate>
    </item>
    <item>
      <title>机器学习[关闭]</title>
      <link>https://stackoverflow.com/questions/77853082/machine-learning</link>
      <description><![CDATA[我一直在使用 Microsoft Azure 环境及其现成的模型训练、测试和部署环境。
我已经成功找到了预测模型的选项和算法：多个特征作为输入，单个变量作为输出。
例如，给定一个人的：(a) 工作范围、(b) 年龄、(c) 体重，我构建的系统能够预测（正确/错误）该人是否应该执行练习“E1”。 
现在，从技术上讲，人们可以训练 20 个与此类似的模型，并使用有关练习“E2”、“E3”等的“SINGLE”二进制输出。
但是，我觉得必须有一种更简单的方法。
这样，为了训练模型，我会为其提供一个 CSV 文件，每个场景/人一行：
第一人：“数据录入员”，24 岁，100 磅 ==&gt; E1 是，E2 否，E3 是
第二个人：“按摩师”，45岁，168磅==&gt; E1 是，E2 是，E3 否
等等...
什么算法/环境最适合此类任务？ （也许 Microsoft Azure 不是最好的？）
我希望无需任何编码即可执行上述设置、培训、测试和部署。
我不介意未来所有这些的编码版本；但目前我喜欢学习在无代码环境中执行此操作。
我通过使用自动化 ML 来训练我的预测模型，尝试使用 Azure ML。但是，我找不到任何功能表明 Azure 可以训练多输出模型。]]></description>
      <guid>https://stackoverflow.com/questions/77853082/machine-learning</guid>
      <pubDate>Sat, 20 Jan 2024 23:17:11 GMT</pubDate>
    </item>
    <item>
      <title>Docker for Lambda (FAST API) 中的{“无法导入模块‘main’：没有名为‘main’的模块”，“errorType”：“Runtime.ImportModuleError”}</title>
      <link>https://stackoverflow.com/questions/71305887/unable-to-import-module-main-no-module-named-main-errortype-runtime</link>
      <description><![CDATA[我已经创建了一个 Fastapi，现在尝试使用 Docker 容器将其部署到 AWS lambda。但有一个错误：
{“errorMessage”：“无法导入模块“main”：没有名为“main”的模块”，“errorType”：“Runtime.ImportModuleError”，“stackTrace”：[] }

我已经尽力了。
这是我的 main.py 文件：
from fastapi 导入 FastAPI
从 starlette.status 导入 HTTP_302_FOUND,HTTP_303_SEE_OTHER
导入spacy
从字符串导入标点符号
从曼古姆进口曼古姆
进口uvicorn
应用程序 = FastAPI()

@app.get(&#39;/&#39;)
def home():
    返回{“答案”：“你好世界”}

@app.get(&#39;/tags&#39;)
def prep_data(文本):
    标签=标记（文本，nlp）
    标签 = getdict(标签)
    返回 {
        ‘标签’：标签
    }

处理程序 = Mangum(应用程序)
如果 __name__ == “__main__”：
    # 处理程序 = Mangum(应用程序)
    uvicorn.run(&#39;main:app&#39;, host=&#39;0.0.0.0&#39;, port=8000, reload=False, root_path=”/”)

该错误表明 main.py 文件没有 main.py 文件，正如您所看到的 dockerfile：
&lt;前&gt;&lt;代码&gt;来自 public.ecr.aws/lambda/python:3.8

复制./应用程序/应用程序

复制 ./requirements.txt /app/requirements.txt

工作目录/应用程序

运行 pip install -rrequirements.txt

CMD [“main.handler”]

我的目录结构是这样的：
&lt;前&gt;&lt;代码&gt;/应用程序
    主要.py
Dockerfile
要求.txt
]]></description>
      <guid>https://stackoverflow.com/questions/71305887/unable-to-import-module-main-no-module-named-main-errortype-runtime</guid>
      <pubDate>Tue, 01 Mar 2022 08:52:48 GMT</pubDate>
    </item>
    </channel>
</rss>