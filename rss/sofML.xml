<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 21 Aug 2024 03:17:50 GMT</lastBuildDate>
    <item>
      <title>对于回归模型 Accord.NET，一遍又一遍地获得相同的输出</title>
      <link>https://stackoverflow.com/questions/78894555/getting-the-same-output-over-and-over-againfor-regression-model-accord-net</link>
      <description><![CDATA[我最近开始使用 Accord.NET，因为我必须承担一个涉及 AI 回归模型的项目。
该模型与自动驾驶汽车有关，数据由 5 个传感器的幅度和一个转弯角度组成作为输出。
DataParser.Parse(out double[][] input, out double[] output,&quot;data.csv&quot;, (0, 4), (4, 5));
var model = new FanChenLinSupportVectorRegression&lt;Gaussian&gt;();
var svm = model.Learn(input, output);

Console.WriteLine(svm.Score(new double[] { 95.0, 0.0, 67.8, 0.0, 0.0 }));

我决定试验一下 FanChenLin 回归算法是否有效。
现在，我面临的问题是，对于输出，我得到的是 217.88 的常数值。我生成了一个模型训练数据，它可能有误，但我希望它在输入不同时给出不同的输出，但在这里，尽管改变了输出，我仍然得到了 217.88 的值。
我编写的数据解析器似乎得到了正确的输入和输出。
由于我对这个库还很陌生，我无法弄清楚出了什么问题，而且我有一个特定的截止日期，在此之前我需要找到解决方案。
我尝试更改复杂度等值，但尽管它们给出了不同的输出，但该输出在不同情况下仍然是恒定的输入。
37.454011884736246,3.142918568673425,64.20316461542878,5.16817211686077,10.31238688359326,21.365509618766623
95.07143064099162,63.641041 12637804,8.413996499504883,53.1354631568148,90.25529066795667,61.22639465322385 73.1993941811405,31.435598107632668,16.162 871409461378,54.06351216101065,50.5252 37244785714,0.16392599623276283 59.86584841970366,50.85706911647028,89.85541885270793,63.742990149820656,82.64574661077417 ,338.3506582186952 15.601864044243651 ,90.7566473926093,60.642905965958995,72.60913337226616,32.00496010306117,1.6476821446117356 15.599452033620265,24.92922291 4887493,0.9197051616629648,97.58520794 625346,89.55232284962005,270.35942257808824 5.8083612168199465,41.038292303562976,10.147154286603211,51.630034830119534,38 .92016787341631,283.0714170955975 86. 61761457749351,75.55511385430486,66.35017691080559,32.2956472941246,1.083765148029836,62.743931568541655 60.11150117432088 ,22.879816549162246,0.5061583846218687 ,79.51861947687037,90.53819764192636,270.3330873043567 70.80725777960456,7.697990982879299,16.080805141749867,27.083225126 207424,9.128667678613356,69.182165231 95599 2.0584494295802447,28.9751452913768,54.87337893665861,43.89714207056361,31.93136375904149,320.77412786375123 96.9909 8521619943,16.122128725400444,69.18951 976926932,7.845638134226595,95.0061967050805,8.435865969658153 83.24426408004217,92.96976523425731,65.19612595026005,2.535 074341545751,95.06071469375561,50.331 93776194861 21.233911067827616,80.8120379564417,22.42693094605598,96.26484146779251,57.34378881232861,293.50639083221773 1 8.182496720710063,63.34037565104234,71 .2179221347536,83.59801205122058,63.183721216979926,317.50014925812815 18.34045098534338,87.14605901877177,23.724908749680 008,69.59742060936979,44.844552197831 98,339.3199373713304 30.42422429595377,80.36720768991145,32.539969815926774,40.89529444142699,29.321077169806454,51.271442 802352 52.475643163223786,18.657005888 603585,74.64914051180241,17.329432007084577,32.8664545369916,15.667156378272637 43.194501864211574,89.25589984899777,64.96 328990472146,15.643704267108605,67.25 184560770384,37.33686449574435 29.122914019804192,53.93422419156507,84.9223410494178,25.024289816459532,75.237452943768,34 8.5473288270272 61.18528947223795,80.7 4401551640625,65.76128923003434,54.92266647061205,79.15790437258485,6.806163770302646 13.949386065204184,89.60912999234932 ,56.830860333547164,71.45959227000624, 78.96181427945538,320.4909103298581
29.214464853521815,31.800347497186387,9.367476782809248,66.01973767177313,9.120610304869036,303.55070797479505
]]></description>
      <guid>https://stackoverflow.com/questions/78894555/getting-the-same-output-over-and-over-againfor-regression-model-accord-net</guid>
      <pubDate>Tue, 20 Aug 2024 22:18:47 GMT</pubDate>
    </item>
    <item>
      <title>‘charmap’ 编解码器无法对位置 18-37 中的字符进行编码：字符映射到 <undefined> 错误</title>
      <link>https://stackoverflow.com/questions/78894108/charmap-codec-cant-encode-characters-in-position-18-37-character-maps-to-un</link>
      <description><![CDATA[我正在尝试使用 django 连接 ml 模型。在这里我加载了模型和必要的编码器。
import joblib
import os
#from keras.model import load_model
from keras.src.saving.saving_api import load_model
from django.conf import settings
import numpy as np

def load_keras_model():
# 定义模型文件的路径
model_path = os.path.join(settings.BASE_DIR, &#39;Ml_Models&#39;, &#39;football_prediction_model.h5&#39;)
print(&quot;Keras model path:&quot;, model_path)

try:
# 加载模型
model1 = load_model(model_path)
# 通过打印其摘要来验证模型加载
print(&quot;模型已成功加载。&quot;)
print(&quot;模型摘要：&quot;)
model1.summary()
return model1

except Exception as e:
# 处理异常并打印错误消息
print(f&quot;加载模型时出错：{str(e)}&quot;)
return None

def load_encoder(filename):
coder_path = os.path.join(settings.BASE_DIR, &#39;Ml_Models&#39;, filename)
print(f&quot;{filename} path:&quot;,coder_path) # 调试路径
return joblib.load(encoder_path)

# 加载所有必要的模型和编码器
model = load_keras_model()
team_label_encoder = load_encoder(&#39;team_label_encoder.pkl&#39;)
outcome_label_encoder = load_encoder(&#39;outcome_label_encoder.pkl&#39;)
scaler = load_encoder(&#39;scaler.pkl&#39;)

def predict_outcome(home_team,away_team,year,month,day,temperature):
try:
print(f&quot;主队： {home_team}&quot;)
print(f&quot;客队：{away_team}&quot;)
print(f&quot;年份：{year}, 月份：{month}, 日：{day}, 温度：{temperature}&quot;)
# 对输入数据进行编码和缩放
home_team_encoded = team_label_encoder.transform([home_team])[0]
away_team_encoded = team_label_encoder.transform([away_team])[0]
temperature_scaled = scaler.transform([[temperature]])[0][0]

print(f&quot;编码的主队：{home_team_encoded}&quot;)
print(f&quot;编码的客队：{away_team_encoded}&quot;)
print(f&quot;缩放的温度：{temperature_scaled}&quot;)

# 为模型准备输入
input_data = np.array([[home_team_encoded, away_team_encoded, year, month, day,temperature_scaled]])
print(f&quot;输入日期：{input_data}&quot;)
input_data = input_data.reshape((1, 1, 6))
print(f&quot;输入更新日期：{input_data}&quot;)

# 进行预测
prediction = model.predict(input_data)
print(f&quot;预测：{prediction}&quot;)
consequence_index = np.argmax(prediction)
print(f&quot;结果索引：{outcome_index}&quot;)

# 将预测映射回原始结果标签
consequence_label = consequence_label_encoder.inverse_transform([outcome_index])
print(f&quot;输出标签：{outcome_label}&quot;)

return consequence_label[0]

except ValueError as e:
return f&quot;Error: {str(e)}&quot;

home_team = &#39;Scotland&#39;
away_team = &#39;England&#39;
year = 2024
month = 8
day = 20
temperature = 25

predicted_outcome = predict_outcome(home_team, away_team, year, month, day,temperature)
print(f&quot;Predicted Outcome: {predicted_outcome}&quot;)

对于上述代码，以下是输出。请注意，我在控制台中包含了部分输出。
主队：苏格兰
客队：英格兰
年份：2024，月份：8，日期：20，温度：25
D:\My Projects\FootBall-Match-Win-Prediction\BackEnd\venv\Lib\site-packages\sklearn\base.py:465：UserWarning：X 没有有效的特征名称，但 MinMaxScaler 配备了特征名称
warnings.warn(
编码的主队：3
编码的客队：1
缩放温度：0.75
输入日期：[[3.000e+00 1.000e+00 2.024e+03 8.000e+00 2.000e+01 7.500e-01]]
输入更新日期：[[[3.000e+00 1.000e+00 2.024e+03 8.000e+00 2.000e+01 7.500e-01]]]

预测结果：错误：“charmap”编解码器无法对位置 18-37 的字符进行编码：
字符映射到 &lt;undefined&gt;

系统检查未发现任何问题（0 静音）。
2024 年 8 月 21 日 - 00:30:52
Django 版本 5.1，使用设置“BackEnd.settings”
在 http://localhost:8000/ 启动开发服务器
使用 CTRL-BREAK 退出服务器。

对于它打印的 predicted_outcome 变量
错误：“charmap”编解码器无法对位置的字符进行编码18-37：
字符映射到 &lt;undefined&gt;。

如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78894108/charmap-codec-cant-encode-characters-in-position-18-37-character-maps-to-un</guid>
      <pubDate>Tue, 20 Aug 2024 19:16:51 GMT</pubDate>
    </item>
    <item>
      <title>利用分割模型对直肠内超声图像中的肿瘤分期进行分类</title>
      <link>https://stackoverflow.com/questions/78893937/leveraging-segmentation-model-for-tumor-stage-classification-in-endorectal-ultra</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78893937/leveraging-segmentation-model-for-tumor-stage-classification-in-endorectal-ultra</guid>
      <pubDate>Tue, 20 Aug 2024 18:28:10 GMT</pubDate>
    </item>
    <item>
      <title>用于训练和测试分割的标准缩放器[关闭]</title>
      <link>https://stackoverflow.com/questions/78893752/standard-scaler-for-train-and-test-split</link>
      <description><![CDATA[在阅读了互联网上的几篇文章后，我了解到最好在将数据分成训练和测试后进行规范化步骤。然后我就有疑问了。
数据被分成X_train、X_test、y_train、y_test。
那么我应该将训练和测试拟合到相同的缩放器对象还是不同的缩放器对象呢
选项 1：
scaler = StandardScaler()
Train_norm = scaler.fit_transform(X_train)
Test_norm = scaler.fit_transform(X_test)
y_train_norm = scaler.fit_transform(y_train)
y_test_norm = scaler.fit_transform(y_test)

选项 2：
scaler_x = StandardScaler()
scaler_y = StandardScaler()
Train_norm = scaler_x.fit_transform(X_train)
Test_norm = scaler_x.fit_transform(X_test)
y_train_norm = scaler_y.fit_transform(y_train)
y_test_norm = scaler_y.fit_transform(y_test)

或者有更好的方法吗？
有人能对此提供见解吗？]]></description>
      <guid>https://stackoverflow.com/questions/78893752/standard-scaler-for-train-and-test-split</guid>
      <pubDate>Tue, 20 Aug 2024 17:32:25 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorFlow 的 Attention Unet：输入形状错误和训练给出 0.999 的准确率</title>
      <link>https://stackoverflow.com/questions/78893443/attention-unet-using-tensorflow-input-shape-error-and-training-gives-0-999-accu</link>
      <description><![CDATA[我的目标是从 CT 扫描中创建癌症部位的遮罩并将其显示给用户。
我正在尝试使用 tf/keras 实现注意力 unet，但遇到了问题。我在数据集方面遇到了问题（当我对它们调用 .shape() 时，每个图像都返回 256x256）并将其传递给模型（预期为 256x256xn）。
这是我收到的错误消息：

输入 Tensor(&quot;data:0&quot;, shape=(None, 256, 256),
dtype=float32) 的输入形状无效。预期形状（无，256，256，2），但输入具有
不兼容的形状（无，256，256）

https://colab.research.google.com/drive/1sNgsP-SAzLdFj7zNe7UBX06Hjg0JV9V1?usp=sharing 是我使用的包含所有代码的笔记本。]]></description>
      <guid>https://stackoverflow.com/questions/78893443/attention-unet-using-tensorflow-input-shape-error-and-training-gives-0-999-accu</guid>
      <pubDate>Tue, 20 Aug 2024 16:08:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 TFIDF 的 SKL 管道中的数据形状问题</title>
      <link>https://stackoverflow.com/questions/78893376/data-shape-issues-in-skl-pipeline-using-tfidf</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78893376/data-shape-issues-in-skl-pipeline-using-tfidf</guid>
      <pubDate>Tue, 20 Aug 2024 15:52:58 GMT</pubDate>
    </item>
    <item>
      <title>适合发票提取的ML模型</title>
      <link>https://stackoverflow.com/questions/78892147/suitable-ml-model-for-invoice-extraction</link>
      <description><![CDATA[我必须构建一个 ml 模型，用于从不同布局的 pdf 文件中提取发票详细信息，例如客户姓名、发票日期、发票号码等。发票 pdf 文件具有不同的格式，例如，在一个 pdf 文件中，发票日期位于右上角，而在另一个 pdf 文件中，则位于左上角。我有大约 252 个样本。我正在使用 202 个样本进行训练，其中 28 个样本用于验证。我目前正在使用每个标签/类的边界框坐标训练张量流更快的 RCNN resnet101 对象检测模型（例如：发票日期，数字是标签），其中 num_train_steps = 2000，批量大小 = 4 和 num_eval_steps = 250。当我在测试图像上测试训练后的模型时，其中一些能够提取发票详细信息，但其中一些给出错误的输出，甚至有时它们为相同的发票详细信息提供多个输出（例如，它们为一个发票日期预测两个值）。我应该如何调整参数（批量大小、num_train_steps、num_eval_steps）？我应该在下载的 ml 模型的配置文件上更改任何内容吗？为了更好地理解，请参阅faster rcnn 的配置文件]]></description>
      <guid>https://stackoverflow.com/questions/78892147/suitable-ml-model-for-invoice-extraction</guid>
      <pubDate>Tue, 20 Aug 2024 11:18:03 GMT</pubDate>
    </item>
    <item>
      <title>Yolop 输出在 SNPE android 上给出 NaN 值</title>
      <link>https://stackoverflow.com/questions/78892125/yolop-output-giving-nan-values-on-snpe-android</link>
      <description><![CDATA[我使用了 YOLOP 模型，并使用 SNPE SDK 将其转换为 dlc 文件。创建输入张量并构建网络。获取输出张量值给出 NaN 值列表。下面给出了我如何配置网络、传递输入张量。但我的变量 laneLineSeg 和 DetOutValues 是 NaN 值。有人能帮我吗？
这是我配置网络、传递输入张量的方法。但我的变量 laneLineSeg、DrivAreaSegValues 和 DetOutValues 是 NaN 值。
private val modelName = &quot;yolop_seg.dlc&quot;
private fun configureNetwork(): NeuralNetwork? {
返回尝试 {

val assetInputStream = applicationContext.assets.open(modelName)
val network = SNPE.NeuralNetworkBuilder(application)
.setDebugEnabled(false)
.setRuntimeOrder(NeuralNetwork.Runtime.GPU_FLOAT16)
.setModel(assetInputStream, assetInputStream.available())
.setCpuFallbackEnabled(true)
.setUseUserSuppliedBuffers(false)
.setUnsignedPD(false)
.setCpuFixedPointMode(false)
.setOutputLayers(&quot;Sigmoid_1671&quot;,&quot;Concat_1534&quot;, &quot;Sigmoid_1808&quot; )

.build()
assetInputStream.close()
network
} catch (e: Exception) {
Log.e(&lt;NETWORK&gt;, e.message.toString())
null
}
}
private fun getClassificationResult(network: NeuralNetwork, bitmap: Bitmap): FloatArray{
val image = Bitmap.createScaledBitmap(bitmap, 640, 640, true)

val inputMap: MutableMap&lt;String, FloatTensor&gt; = HashMap()
val inputNames: Set&lt;String&gt; = network.inputTensorsNames
val outputNames: Set&lt;String&gt; = network.outputTensorsNames
var mInputLayer = &quot;&quot;
val mOutputLayer = &quot;&quot;
mInputLayer = inputNames.iterator().next()

val tensor = network.createFloatTensor(1, 640, 640,3)
val dimension = tensor.shape
val isGrayScale = (dimension[dimension.size - 1] == 1)

val input: FloatArray = if (!isGrayScale) {
loadRgbBitmapAsFloat(image)
} else {
loadGrayScaleBitmapAsFloat(image)
}
tensor.write(input, 0, input.size)
输入映射[mInputLayer] = tensor
val 输出映射 = network.execute(inputsMap)

val driveAreaSeg = outputMap[&quot;drive_area_seg&quot;]
val DrivAreaSegValues = FloatArray(driveAreaSeg!!.size)
driveAreaSeg.read(DrivAreaSegValues, 0, DrivAreaSegValues.size)
val i = 0

val laneLineSeg = outputMap[&quot;lane_line_seg&quot;]
val LanLinSegValues = FloatArray(laneLineSeg!!.size)
laneLineSeg.read(LanLinSegValues, 0, LanLinSegValues.size)

val detOut = outputMap.get(&quot;det_out&quot;)
val DetOutValues = FloatArray(detOut!!.size)
detOut.read(DetOutValues, 0, DetOutValues.size)

return laneLineSeg

]]></description>
      <guid>https://stackoverflow.com/questions/78892125/yolop-output-giving-nan-values-on-snpe-android</guid>
      <pubDate>Tue, 20 Aug 2024 11:13:13 GMT</pubDate>
    </item>
    <item>
      <title>AssertionError LLama-cpp-python 模型加载失败</title>
      <link>https://stackoverflow.com/questions/77864368/assertionerror-llama-cpp-python-model-failed-to-load</link>
      <description><![CDATA[Llama-cpp-python 给我断言错误，尽管我使用的是 GGUF 格式。
我试图用 llama-cpp-python 0.1.85 在 python 3.7.2 中运行 AI 模型，每次运行我的代码时都会出现此错误：
加载模型时出错：MapViewOfFile 失败：没有足够的内存资源来处理此命令。

llama_load_model_from_file：加载模型失败
回溯（最近一次调用）：
文件“server.py”，第 26 行，在 &lt;module&gt;
n_ctx=N_CTX,
文件“D:\AI 2\Venv\lib\site-packages\llama_cpp\llama.py”，第 323 行，在 __init__ 中
断言 self.model 不是 None
AssertionError

我使用的是 GGUF 格式，所以我不知道问题是什么，它在第二台计算机上运行良好，但在我的主机上却不行，有什么帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/77864368/assertionerror-llama-cpp-python-model-failed-to-load</guid>
      <pubDate>Tue, 23 Jan 2024 06:30:48 GMT</pubDate>
    </item>
    <item>
      <title>Scikit-Learn LOOCV 与手动执行产生不同的结果，为什么？</title>
      <link>https://stackoverflow.com/questions/75918536/scikit-learn-loocv-vs-doing-it-manually-give-different-results-why</link>
      <description><![CDATA[因此，我为一个小数据集建立了一个模型，由于它是一个小数据集，我做了一个留一交叉验证 (LOOCV) 检查来确保它的准确性。简而言之，我会手动移除一个样本，训练模型，预测遗漏的样本并保存预测，然后对所有样本重复该过程。然后，我会使用预测列表和实际值来获得 RMSE 和 R2。
今天我发现有一个 Scikit-Learn 实现 sklearn.model_selection.LeaveOneOut，但是，当我尝试它时，它给出了不同的 RMSE 结果，并且拒绝在 LOOCV 方法中使用 R 平方作为准确度（它似乎计算每个样本的准确度，这与 R2 不起作用）。
以下是代码的简要示例：
from numpy import mean
from numpy import std
from sklearn.datasets import make_blobs
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier

cv = LeaveOneOut()
model = RandomForestRegressor(n_estimators=200, max_depth=6,n_jobs=40, random_state=0)

scores = cross_val_score(model, data2SN, labelCL,scoring=&#39;neg_root_mean_squared_error&#39;, cv=cv, n_jobs=-1)
# report performance
print(&#39;Accuracy: %.3f (%.3f)&#39; % (mean(scores), std(scores)))

我猜我是在计算整个数据集的 RMSE，而 LOOCV 是按样本计算的，最终我会取平均值，这就是导致两个代码输出不一致的原因，但是，当我尝试计算每个样本的 RMSE 时失败了（引用此 TypeError：Singleton array 3021.0 不能被视为有效集合）。所以我不确定 LOOCV 中 RMSE 是如何计算的。我不确定是否应该相信我的代码，或者只是盲目地使用 scikit-learn 实现。
我不知道该怎么做，chatGPT 简直令人困惑不已，所以我的人类同胞请帮忙]]></description>
      <guid>https://stackoverflow.com/questions/75918536/scikit-learn-loocv-vs-doing-it-manually-give-different-results-why</guid>
      <pubDate>Mon, 03 Apr 2023 10:38:08 GMT</pubDate>
    </item>
    <item>
      <title>t() 期望张量具有 <= 2 维，但自身是 3D</title>
      <link>https://stackoverflow.com/questions/75274241/t-expects-a-tensor-with-2-dimensions-but-self-is-3d</link>
      <description><![CDATA[我是 PyTorch 的新手，写了如下简单代码来对一些输入进行分类。模型输入有 8*2，批量大小为 2，模型中的输入层有 2 个节点。我不知道哪里出了问题！
X1=np.array([[2,1],[3,2],[-4,-1],[-1,-3],[2,-1],[3,-3],[-2,1],[-4,-2]])
Y1=np.array([0,0,0,0,1,1,1,1])
X=torch.tensor(X1)
Y=torch.tensor(Y1)

BATCH_SIZE=2
trainset= torch.utils.data.TensorDataset(X, Y)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,
shuffle=True, num_workers=1) 
from torch.nn.modules import flatten

learning_rate = 0.01
num_epochs = 20

device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
model = MyModel()
model = model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

## 计算准确率
def get_accuracy(logit, target, batch_size):
&#39;&#39;&#39; 获取训练轮的准确率 &#39;&#39;&#39;
corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()
accuracy = 100.0 * corrects/batch_size
return accuracy.item()

model = MyModel()

# 注释掉 IPython magic 以确保 Python 兼容性。

对于范围（num_epochs）内的 epoch：
train_running_loss = 0.0
train_acc = 0.0

## 训练步骤
对于 trainloader 中的输入、标签：

#inputs=torch.flatten(inputs)
输入、标签=inputs.to(device), 标签.to(device)
#inputs = 输入.to(device)
#labels = 标签.to(device)

optimizer.zero_grad()

## 前向 + 反向传播 + 损失

print(inputs)

输出 = model.forward(inputs)
损失 = criterion(outputs, labels)

loss.backward()

## 更新模型参数
optimizer.step()

train_running_loss += loss.detach().item()
train_acc += get_accuracy(outputs, labels, BATCH_SIZE)

#model.train()
model.eval()
print(&#39;Epoch： %d | 损失： %.4f | 训练准确率： %.2f&#39;%(epoch, train_running_loss / i, train_acc/i))

我的模型如下：
class MyModel(nn.Module):
def __init__(self):
super(MyModel, self).__init__()
self.d1 = nn.Linear(2,3)
self.d2 = nn.Linear(3,1)
self.init_weights()

def init_weights(self):
k1=torch.tensor([0.1,-0.72,0.94,-0.29,0.12,0.44])
k1=torch.unsqueeze(torch.unsqueeze(k1,0),0)
self.d1.weight.data=k1
k2=torch.tensor([1,-1.16,-0.26])
k2=torch.unsqueeze(torch.unsqueeze(k2,0),0)
self.d2.weight.data=k2

def forward(self, x):
x = self.d1(x)
x = F.tanh(x)
x = self.d2(x)
out = F.sigmoid(x)
return out

然后我收到一个错误：
-------------------------------------------------------------------------------
RuntimeError Traceback (most recent call last)
&lt;ipython-input-27-196d819d3ccd&gt; in &lt;module&gt;
101 print(inputs)
102 
--&gt; 103 输出 = model.forward(输入)
104 损失 = 标准(输出，标签)
105 

2 帧
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py in forward(self, input)
112 
113 def forward(self, input: Tensor) -&gt; Tensor:
--&gt; 114 return F.linear(input, self.weight, self.bias)
115 
116 def extra_repr(self) -&gt; str:

RuntimeError: t() 期望张量具有 &lt;= 2 维，但 self 是 3D

我展平了输入，但没有任何变化。我应该怎么做才能修复它？]]></description>
      <guid>https://stackoverflow.com/questions/75274241/t-expects-a-tensor-with-2-dimensions-but-self-is-3d</guid>
      <pubDate>Sun, 29 Jan 2023 10:38:06 GMT</pubDate>
    </item>
    <item>
      <title>在新类中，我收到一个 AttributeError: 无法在 <module '__main__'> 上获取属性 'ResNet1D'</title>
      <link>https://stackoverflow.com/questions/69030379/torch-loadml-model-in-new-class-i-receive-an-attributeerror-cant-get-attribu</link>
      <description><![CDATA[我已使用 Google Colab 在名为 model_prep.py 的文件中成功训练了卷积神经网络模型。该模型的准确率为 92%。现在我对该模型很满意，我已使用 pyTorch 保存了我的模型。
torch.save(model, &#39;/content/drive/MyDrive/myModel.pt&#39;)

我对此的理解是，一旦模型经过完全训练，我就可以使用 pyTorch 保存训练后的模型，然后将其加载到未来的项目中以对新数据进行预测。因此，我创建了一个单独的 test.py 文件，并在其中加载了经过训练的模型，如下所示：
model = torch.load(&#39;/content/drive/MyDrive/myModel.pt&#39;)
model.eval()

但在新的 test.py 文件中，我收到一条错误消息
AttributeError: 无法在 &lt;module &#39;__main__&#39;&gt; 上获取属性 &#39;ResNet1D&#39;

虽然在与创建经过训练的模型相同的笔记本 (model_prep.py) 中加载模型时不会发生此错误。此错误仅在将模型加载到没有模型架构的单独笔记本中时发生。我该如何解决这个问题？我想将经过训练的模型加载到一个新的单独文件中以对新数据执行。有人能提出解决方案吗？
将来，我想使用 tkinter 创建一个 GUI，并部署经过训练的模型，使用 tkinter 文件中的新数据检查预测。这可能吗？]]></description>
      <guid>https://stackoverflow.com/questions/69030379/torch-loadml-model-in-new-class-i-receive-an-attributeerror-cant-get-attribu</guid>
      <pubDate>Thu, 02 Sep 2021 12:33:05 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 预期为 1D 张量，但得到的是 2D 张量</title>
      <link>https://stackoverflow.com/questions/66720543/pytorch-1d-tensors-expected-but-got-2d-tensors</link>
      <description><![CDATA[我一直在用 Python 从头开始​​制作神经网络。输入张量的形状为 [400,3]，target_tensor 的形状为 [400]。在对权重求导时，我遇到了错误。以下是函数：
def sigmoid(z):
return 1 / (1 + torch.exp(-z))

def nueral_net(data,weights,bias):
return sigmoid( ( data @ weights ) + bias )

def loss_function(prediction,actual,m):
return (-1/m) * (torch.sum(actual * torch.log(prediction) + (1-actual) 
* torch.log(1- prediction)))

w = torch.randn(input_tensor.shape[1],1)

b = torch.randn(1,1)

predictions = nueral_net(input_tensor.float() , w, b) #应用模型
loss = loss_function(predictions,target_tensor.unsqueeze(1),400)
dw = (1/400) * torch.dot(input_tensor,(predictions - target_tensor).T)

运行此程序会引发错误：
RuntimeError Traceback (most recent call last)
&lt;ipython-input-26-632338d8fd16&gt; in &lt;module&gt;
1 predictions = nueral_net(input_tensor.float() , w, b) #应用模型
2 loss = loss_function(predictions,target_tensor.unsqueeze(1),400)
----&gt; 3 dw = (1/400) * torch.dot(input_tensor,(predictions - target_tensor).T)
4 db = (1/400) * torch.sum(predictions - target_tensor)
5 #m = input_tensor.shape[0]

RuntimeError: 预期为 1D 张量，但得到的是 2D 和 2D 张量
]]></description>
      <guid>https://stackoverflow.com/questions/66720543/pytorch-1d-tensors-expected-but-got-2d-tensors</guid>
      <pubDate>Sat, 20 Mar 2021 10:32:38 GMT</pubDate>
    </item>
    <item>
      <title>进行预测时如何处理未包含在训练集中的标签</title>
      <link>https://stackoverflow.com/questions/58627102/how-to-deal-with-label-that-not-included-in-training-set-when-doing-prediction</link>
      <description><![CDATA[例如，使用监督学习对 5 个不同的人脸进行分类。
但是当对训练集中没有出现的第 6 个人脸进行测试时，模型仍然会将其预测在 5 个人之内。
当模型之前没有训练过第 6 个人及以后的人脸时，如何让模型将其预测为未知？]]></description>
      <guid>https://stackoverflow.com/questions/58627102/how-to-deal-with-label-that-not-included-in-training-set-when-doing-prediction</guid>
      <pubDate>Wed, 30 Oct 2019 14:01:46 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的 `view()` 起什么作用？</title>
      <link>https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch</link>
      <description><![CDATA[view() 对张量 x 做了什么？负值代表什么？
x = x.view(-1, 16 * 5 * 5)
]]></description>
      <guid>https://stackoverflow.com/questions/42479902/what-does-view-do-in-pytorch</guid>
      <pubDate>Mon, 27 Feb 2017 07:21:10 GMT</pubDate>
    </item>
    </channel>
</rss>