<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 24 May 2024 06:21:09 GMT</lastBuildDate>
    <item>
      <title>2D 图像转 3D 模型的模型推荐？</title>
      <link>https://stackoverflow.com/questions/78525767/models-recommendation-for-2d-images-to-3d-models</link>
      <description><![CDATA[我目前正在做一个电子商务项目，关键需求之一是将产品的2D图像转换为3D模型。我正在寻求有关可用于此任务的最佳模型或工具的建议，特别是那些已在类似用例中被证明有效的模型或工具。
目标是根据 2D 图像创建各种产品的准确且详细的 3D 表示。这些模型需要在处理时间和资源使用方面保持高效，并且必须与我们现有的系统无缝集成。此外，模型应该可扩展以处理大量产品。任何可以帮助我入门的资源、库或教程的建议也将不胜感激。
我尝试了一些 Hugging Face 模型来生成 3D 模型，但输出的准确性或质量没有达到所需的程度。如果您对可能更适合电子商务环境的其他模型或工具有任何经验或建议，我很乐意听取您的意见。对电子商务中产品可视化效果良好的模型的具体见解将特别有价值。]]></description>
      <guid>https://stackoverflow.com/questions/78525767/models-recommendation-for-2d-images-to-3d-models</guid>
      <pubDate>Thu, 23 May 2024 22:13:57 GMT</pubDate>
    </item>
    <item>
      <title>时间序列相关回归中的数据泄漏</title>
      <link>https://stackoverflow.com/questions/78525482/data-leakage-in-time-series-related-regression</link>
      <description><![CDATA[我有一个包含解释变量和目标变量值的数据集。它们都是不同的历史每日值。X 是不同的经济指标，Y 是债券收益率的前瞻性变化。因此，对于第 N 天，X 是当前失业率和通货膨胀率，Y 是 (yield_n+3 / Yield_n) - 1，这是 3 天的变化。
我的问题是，如果我稍后使用来自 sklearn 的 train_test_split，我可以打开 shuffle = True 吗？
我理解，对于典型的时间序列回归，这会导致数据泄漏，但在这里我不使用 Y 的过去值，也不使用任何滞后。
理论上，我想对数据进行打乱，因为从我所看到的，X 和 Y 之间的关系会随着时间而变化，所以如果我仅根据较早和较晚的日期拆分数据，我担心我会在稍微过时的值上训练模型。
顺便说一句，我使用 Gradient Boosting 作为我的模型
那么，在我的情况下我可以使用 shuffle = True 吗？如果是，那么还有哪些其他因素可能会导致泄漏：滞后、季节性影响还是其他因素？]]></description>
      <guid>https://stackoverflow.com/questions/78525482/data-leakage-in-time-series-related-regression</guid>
      <pubDate>Thu, 23 May 2024 20:43:46 GMT</pubDate>
    </item>
    <item>
      <title>Mediapipe 培训数据</title>
      <link>https://stackoverflow.com/questions/78525263/data-for-mediapipe-training</link>
      <description><![CDATA[嘿，大家好，我希望这里有人参与过 mediapipe 框架的图像/视频培训。
我正在尝试向媒体管道框架提供尽可能多的图片，但我发现从各个角度制作人物图片以从人们那里获取数据非常累人。
我还没有尝试媒体管道的视频训练，因为我讨厌它剪切视频。
举个例子，我想训练演习小队，所以我需要三个州来组建一个小队

站立
小队下线
小分队

对于每一个状态，我都需要大量的训练数据来喂养人工智能，否则它不会计算我的运动。
所以我向你们提出的问题如下。
从动作中获取尽可能多的图片而不浪费太多时间的最佳方法是什么。
拍摄曼努埃尔的照片，但我意识到这会花费多少时间]]></description>
      <guid>https://stackoverflow.com/questions/78525263/data-for-mediapipe-training</guid>
      <pubDate>Thu, 23 May 2024 19:45:15 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“sklearn.utils”导入名称“_get_column_indices”</title>
      <link>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</link>
      <description><![CDATA[尝试为 RandomOverSampler 导入 imblearn.over_sampling 时出现导入错误。我相信问题不在于我的代码，而在于库冲突，但我不确定。
导入 pandas 作为 pd
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
from sklearn.preprocessing import StandardScaler #actually scikit-learn
从 imblearn.over_sampling 导入 RandomOverSampler

使用 StandardScaler 和 RandomOverSampler 的代码：
def scale_dataset(dataframe, oversample=False):
    X = dataframe[dataframe.columns[:-1]].values
    Y = dataframe[dataframe.columns[-1]].values

    定标器=标准定标器() 
    X = 缩放器.fit_transform(X) 

    如果过采样：
        ros = RandomOverSampler()
        X, Y = ros.fit_resample(X,Y) 
    数据 = np.hstack((X, np.reshape(Y, (-1, 1))))
    返回数据，X，Y

print(len(train[train[“班级”]==1]))
print(len(train[train[“班级”]==0]))

训练，X_train，Y_train =scale_dataset（训练，True）

我尝试完全导入sklearn，卸载并重新安装scipi和sklearn（作为scikit-learn），安装Tensorflow。
我确实安装了 numpy、scipy、pandas 和其他依赖库。]]></description>
      <guid>https://stackoverflow.com/questions/78524575/importerror-cannot-import-name-get-column-indices-from-sklearn-utils</guid>
      <pubDate>Thu, 23 May 2024 16:54:46 GMT</pubDate>
    </item>
    <item>
      <title>文本分类最新模型</title>
      <link>https://stackoverflow.com/questions/78524470/text-classification-latest-models</link>
      <description><![CDATA[我正在寻找构建一个文本多标签分类器，并且需要一些有关最佳模型的帮助或建议。您能为这项任务推荐一些有效的模型吗？我对大型语言模型 (LLM) 和传统模型都感兴趣。
预先感谢您的建议！]]></description>
      <guid>https://stackoverflow.com/questions/78524470/text-classification-latest-models</guid>
      <pubDate>Thu, 23 May 2024 16:28:40 GMT</pubDate>
    </item>
    <item>
      <title>在 VS Code 上使用计算机视觉 + yolov8 应用程序进行实时网络摄像头数据分类</title>
      <link>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78524343/live-web-cam-data-classification-using-computervision-yolov8-application-on-vs</guid>
      <pubDate>Thu, 23 May 2024 15:57:14 GMT</pubDate>
    </item>
    <item>
      <title>如何确定FastText模型在文本分类中的准确性？</title>
      <link>https://stackoverflow.com/questions/78518695/how-to-find-accuracy-of-fasttext-model-in-text-classification</link>
      <description><![CDATA[在机器学习中，所有模型都有准确度方程，而在 FastText 模型中，我们没有请支持。]]></description>
      <guid>https://stackoverflow.com/questions/78518695/how-to-find-accuracy-of-fasttext-model-in-text-classification</guid>
      <pubDate>Wed, 22 May 2024 15:50:57 GMT</pubDate>
    </item>
    <item>
      <title>线性回归模型的小批量实现的奇怪绘图模式</title>
      <link>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78503641/weird-plot-pattern-for-mini-batch-implementation-of-a-linear-regression-model</guid>
      <pubDate>Sun, 19 May 2024 19:05:35 GMT</pubDate>
    </item>
    <item>
      <title>我无法从“typing_extensions”导入名称“TypeAliasType”</title>
      <link>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</link>
      <description><![CDATA[我是 Python 新手，发现了以下类似错误。我非常感谢您的评论。谢谢
我尝试将 Gradio 库导入为 gr
我已经尝试了一些现有的建议，但结果都是徒劳的。我不知道该怎么办]]></description>
      <guid>https://stackoverflow.com/questions/77450322/i-cannot-import-name-typealiastype-from-typing-extensions</guid>
      <pubDate>Thu, 09 Nov 2023 03:38:10 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：未知层：“CustomScaleLayer”。请确保您使用的是`keras.utils.custom_object_scope`</title>
      <link>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76488688/valueerror-unknown-layer-customscalelayer-please-ensure-you-are-using-aker</guid>
      <pubDate>Fri, 16 Jun 2023 09:13:29 GMT</pubDate>
    </item>
    <item>
      <title>深度学习模型无限训练</title>
      <link>https://stackoverflow.com/questions/62587723/deep-learning-model-training-infinitely</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/62587723/deep-learning-model-training-infinitely</guid>
      <pubDate>Fri, 26 Jun 2020 03:50:17 GMT</pubDate>
    </item>
    <item>
      <title>如何安装 model_evaluation_utils</title>
      <link>https://stackoverflow.com/questions/58693134/how-to-install-model-evaluation-utils</link>
      <description><![CDATA[我正在尝试通过模型评估我们深度学习模型的性能。下面是我的代码。不过，我还是明白了

&lt;块引用&gt;
  没有名为“model_evaluation_utils”的模块

是否有任何 pip 安装或 conda 可以解决此问题？
from keras.preprocessing.image import load_img, img_to_array, array_to_img
从 keras.models 导入 load_model
import model_evaluation_utils as meu # 抛出错误
]]></description>
      <guid>https://stackoverflow.com/questions/58693134/how-to-install-model-evaluation-utils</guid>
      <pubDate>Mon, 04 Nov 2019 12:05:28 GMT</pubDate>
    </item>
    <item>
      <title>SVC 分类器训练花费太多时间</title>
      <link>https://stackoverflow.com/questions/53940258/svc-classifier-taking-too-much-time-for-training</link>
      <description><![CDATA[我正在使用带有线性内核的 SVC 分类器来训练我的模型。
列车数据：42000条记录
 模型 = SVC(概率=True)
    model.fit(self.features_train, self.labels_train)
    y_pred = model.predict(self.features_test)
    train_accuracy = model.score(self.features_train,self.labels_train)
    test_accuracy = model.score(self.features_test, self.labels_test)

训练我的模型需要两个多小时。
难道我做错了什么？ 
另外，可以采取哪些措施来缩短时间
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/53940258/svc-classifier-taking-too-much-time-for-training</guid>
      <pubDate>Thu, 27 Dec 2018 05:43:30 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Google Colab GPU 中安装 CUDA</title>
      <link>https://stackoverflow.com/questions/50560395/how-to-install-cuda-in-google-colab-gpus</link>
      <description><![CDATA[Google Colab GPU 似乎没有附带 CUDA 工具包，我该如何在 Google Colab GPU 中安装 CUDA。我在 Google Colab 中安装 mxnet 时遇到此错误。
安装收集的软件包：mxnet
已成功安装 mxnet-1.2.0


错误：利用 GPU 进行计算的安装不完整。
请确保您已安装 CUDA，并在
您的终端中运行以下行，然后重试：

pip uninstall -y mxnet &amp;&amp; pip install mxnet-cu90==1.1.0


根据您的 CUDA 版本调整“cu90”（“cu75”和“cu80”也可用）。
您还可以通过调用 turicreate.config.set_num_gpus(0) 完全禁用 GPU 使用。
发生异常，使用 %tb 查看完整回溯。

SystemExit: 1
]]></description>
      <guid>https://stackoverflow.com/questions/50560395/how-to-install-cuda-in-google-colab-gpus</guid>
      <pubDate>Mon, 28 May 2018 06:33:13 GMT</pubDate>
    </item>
    <item>
      <title>如何在多元/3D 中实现核密度估计</title>
      <link>https://stackoverflow.com/questions/30696741/how-to-implement-kernel-density-estimation-in-multivariate-3d</link>
      <description><![CDATA[我有类似以下 fromat 的数据集，我试图找出具有最佳带宽的内核密度估计。 
data = np.array([[1, 4, 3], [2, .6, 1.2], [2, 1, 1.2],
         [2, 0.5, 1.4], [5, .5, 0], [0, 0, 0],
         [1, 4, 3], [5, .5, 0], [2, .5, 1.2]])

但我不知道如何处理它。以及如何找到Σ矩阵。 
更新
我尝试使用 scikit-learn 工具包中的 KDE 函数来找出单变量（1D）kde，
# kde 函数
def kde_sklearn(x, x_grid, 带宽):
    kde = KernelDensity(kernel=&#39;高斯&#39;, 带宽=带宽).fit(x)
    log_pdf = kde.score_samples(x_grid[:, np.newaxis])
    返回 np.exp(log_pdf)

# 最优带宽选择
从 sklearn.grid_search 导入 GridSearchCV
grid = GridSearchCV(KernelDensity(), {&#39;带宽&#39;: np.linspace(.1, 1.0, 30)}, cv=20)
网格.fit(x)
bw = grid.best_params_

# 使用 kde 生成 pdf
pdf = kde_sklearn(x, x_grid, bw)
ax.plot(x_grid, pdf, label=&#39;bw={}&#39;.format(bw))
ax.legend(loc=&#39;最佳&#39;)
plt.show()

任何人都可以帮助我将其扩展到多元/在本例中为 3D 数据吗？]]></description>
      <guid>https://stackoverflow.com/questions/30696741/how-to-implement-kernel-density-estimation-in-multivariate-3d</guid>
      <pubDate>Sun, 07 Jun 2015 18:00:35 GMT</pubDate>
    </item>
    </channel>
</rss>