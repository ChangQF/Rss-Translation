<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 28 Oct 2024 01:19:02 GMT</lastBuildDate>
    <item>
      <title>调用 BroadcastTo.call() 时遇到异常</title>
      <link>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79131334/exception-encountered-when-calling-broadcastto-call</guid>
      <pubDate>Sun, 27 Oct 2024 19:29:36 GMT</pubDate>
    </item>
    <item>
      <title>绝对、相对、旋转和学习位置编码之间的区别[关闭]</title>
      <link>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</link>
      <description><![CDATA[位置编码（绝对、相对、旋转）和学习到的位置编码之间有什么区别？
我了解绝对、相对和旋转编码之间的区别，但我无法识别这些编码和学习到的位置编码之间的任何区别。]]></description>
      <guid>https://stackoverflow.com/questions/79131034/difference-between-absolute-relative-rotary-and-learned-positional-encodings</guid>
      <pubDate>Sun, 27 Oct 2024 16:39:04 GMT</pubDate>
    </item>
    <item>
      <title>删除所有人口后，Python NEAT 给出错误</title>
      <link>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130999/python-neat-giving-error-after-deleting-all-the-population</guid>
      <pubDate>Sun, 27 Oct 2024 16:27:23 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中的负损失没有减少</title>
      <link>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79130961/negative-loss-not-decreasing-in-neural-network</guid>
      <pubDate>Sun, 27 Oct 2024 16:07:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么卷积层的输出形状不能跨通道相乘？</title>
      <link>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</link>
      <description><![CDATA[# 第一个卷积层：输入通道 = 1，输出通道 = 32，内核大小 = 5x5，填充 = 2（相同）
self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)
# 第一个池化层：最大池化，内核大小 = 2x2，步长 = 2
self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

# 第二个卷积层：输入通道 = 32，输出通道 = 64，内核大小 = 5x5，填充 = 2（相同）
self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)
# 第二个池化层：最大池化，内核大小 = 2x2， stride = 2
self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

为什么第二个卷积层后的输出不是
14 * 14 * 32 * 64？对于32通道的输入，每个卷积核只作用于一个通道，因此会产生64种不同的结果。难道不应该将32个通道相乘吗？
我得到的答案是：对于输入的每个14 * 14位置，5532核与5532输入区域进行点积将产生14*14的单通道输出。核大小不是5 * 5吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130753/why-doesn-t-the-output-shape-multiply-across-channels-in-convolutional-layers</guid>
      <pubDate>Sun, 27 Oct 2024 14:14:47 GMT</pubDate>
    </item>
    <item>
      <title>输入图像与 TensorFlow 模型输入形状不兼容</title>
      <link>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</link>
      <description><![CDATA[我正在构建一个模型，我想测试它的性能，因此我导入了一个本地文件并加载它，并尝试使用以下代码预测它的标签：
from tensorflow.preprocessing import image
# tensorlfow 等的其他导入。

#...

# 示例图像
img_path = &quot;./Model/data/brain/train/Glioma/images/gg (2).jpg&quot;
img = image.load_img(img_path,target_size=(256,256))
arr = image.img_to_array(img)
t_img = tf.convert_to_tensor(arr)
print(t_img.shape) # 返回 (256,256,3)
# 客户端测试
client = Client(&quot;brain&quot;) # 自定义类。包含模型：顺序（已编译和训练）
client.predict(img=t_img) # 调用 self.model.predict(t_img)

但是我收到以下错误：
输入 Tensor(&quot;data:0&quot;, shape=(32, 256, 3), dtype=float32) 的输入形状无效。预期形状 (None, 256, 256, 3)，但输入具有不兼容的形状 (32, 256, 3)

我在训练模型中有一个输入层，其 input_shape=[256,256,3]（来自图像宽度、高度和 rgb 值）
您能帮助我理解问题并解决它吗？]]></description>
      <guid>https://stackoverflow.com/questions/79130521/input-image-is-not-compatible-with-tensorflow-model-input-shape</guid>
      <pubDate>Sun, 27 Oct 2024 11:57:01 GMT</pubDate>
    </item>
    <item>
      <title>从 CLIP 的中间层提取嵌入</title>
      <link>https://stackoverflow.com/questions/79130488/extracting-embeddings-from-clips-intermediate-layers</link>
      <description><![CDATA[我正在试验 CLIP 模型。
我加载了一个预训练模型，想看看中间层的嵌入是什么样子。我使用的代码如下：
dataset = CelebADataset(root_dir=&quot;celeba/img_align_celeba&quot;, transform=preprocess)
dataloader = DataLoader(dataset, batch_size=32, shuffle=False)

device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
model, _ = clip.load(&quot;ViT-B/32&quot;, device=device)

features = {}
def hook_fn(module, input, output):
features[module] = output[:, 0, :]

# model.patch_embed.register_forward_hook(hook_fn) # 不为 patch_embed 层注册钩子

for i, block in enumerate(model.visual.transformer.resblocks):
block.register_forward_hook(hook_fn) # 每个块

all_features = {
# &#39;patch_embed&#39;: [],
&#39;block_0&#39;: [],
&#39;block_1&#39;: [],
&#39;block_2&#39;: [],
&#39;block_3&#39;: [],
&#39;block_4&#39;: [],
&#39;block_5&#39;: [],
&#39;block_6&#39;: [],
&#39;block_7&#39;: [],
&#39;block_8&#39;: [],
&#39;block_9&#39;: [],
&#39;block_10&#39;: [],
&#39;block_11&#39;: [],
&#39;final&#39;: []
}
all_labels = []

使用 torch.no_grad():
for input in tqdm(dataloader):
input = input.to(device)
final_output = model.encode_image(inputs)

# 将特征转换为 numpy 并存储
for i in range(12):
all_features[f&#39;block_{i}&#39;].append(features[model.visual.transformer.resblocks[i]].cpu().numpy())
all_features[&#39;final&#39;].append(final_output.cpu().numpy())

# all_labels.append(labels.cpu().numpy())

for key在 all_features 中：
all_features[key] = np.concatenate(all_features[key], axis=0)
# all_labels = np.concatenate(all_labels, axis=0)

np.save(&quot;celeba_block0.npy&quot;, all_features[f&#39;block_{0}&#39;])
np.save(&quot;celeba_block1.npy&quot;, all_features[f&#39;block_{1}&#39;])
...

我之前用 Dino 做过类似的事情，在对 Dino 的嵌入进行降维后，我可以看到不同标签组中的图像形成了不同的簇。然而，当我检查 CLIP 的嵌入时，除了最终的嵌入之外，我没有看到清晰的集群。
这是因为 CLIP 的网络结构与 Dino 不同，还是我的代码错误？
我试图查看 CLIP 的结构，但我无法找到对此的解释。]]></description>
      <guid>https://stackoverflow.com/questions/79130488/extracting-embeddings-from-clips-intermediate-layers</guid>
      <pubDate>Sun, 27 Oct 2024 11:38:57 GMT</pubDate>
    </item>
    <item>
      <title>迁移学习预训练模型</title>
      <link>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</link>
      <description><![CDATA[我在 Google Colab 上拟合迁移学习模型。但是，我在代码中遇到了一条警告消息
Epoch 1/30
/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: 
UserWarning：您的 `PyDataset` 类应在其构造函数中调用 `super().__init__(**kwargs)`。`**kwargs` 可以包括 `workers`、`use_multiprocessing`、`max_queue_size`。
请勿将这些参数传递给 `fit()`，因为它们将被忽略。
self._warn_if_super_not_called()

在第一个 epoch 之后，我收到以下错误：
----------------------------------------------------------------------------------------
KeyboardInterrupt Traceback（最近一次调用最后一次）
&lt;ipython-input-23-962a870d4412&gt; in &lt;cell line: 16&gt;()
14 # 拟合模型
15 # 运行单元。执行需要一些时间
---&gt; 16 training_history = model_efficientnet.fit(
17 training_set,
18 validation_data=validate_set,

我已经成功地拟合了其他六个迁移学习模型，没有任何问题，它们的准确率令人满意。
如何解决这个问题？
我想获得训练准确率和验证准确率]]></description>
      <guid>https://stackoverflow.com/questions/78875648/transfer-learning-pretrained-model</guid>
      <pubDate>Thu, 15 Aug 2024 14:49:45 GMT</pubDate>
    </item>
    <item>
      <title>通过电子邮件对话训练 GPT-3</title>
      <link>https://stackoverflow.com/questions/75783524/train-gpt-3-on-email-conversations</link>
      <description><![CDATA[我必须在电子邮件数据上训练 GPT-3，以便支持团队可以从聊天机器人那里快速获得客户之前提出的问题的答案。客户和支持团队之间有电子邮件对话（客户 1 提出问题，支持团队回答，客户 1 提出另一个问题……）。我必须：

过滤重要的对话并仅向 GPT-3 提供它们。
准备并将它们转换为正确的格式，以便我可以训练模型。

关于如何实现这些步骤以及是否使用微调或嵌入，有什么想法吗？
GPT-3 必须将问题与支持团队给出的答案联系起来。]]></description>
      <guid>https://stackoverflow.com/questions/75783524/train-gpt-3-on-email-conversations</guid>
      <pubDate>Sun, 19 Mar 2023 16:44:07 GMT</pubDate>
    </item>
    <item>
      <title>如何对不同特征工程过程中的特征进行标准化和规范化？</title>
      <link>https://stackoverflow.com/questions/66376105/how-to-perform-standardization-and-normalization-on-features-from-different-feat</link>
      <description><![CDATA[我正在处理一个数据集，其中每个样本都包含数字和文本数据。因此，采用多种方法从数据集构建训练特征矩阵。对于数据集中的每个样本，我从 3 个部分构建一个向量表示。

段落文本的 Doc2Vec 向量表示：我使用 gensim 段落向量的实现 将文本编码为 [-5, 5] 之间的 100-D 浮点向量

文本标签的独热编码向量：数据集中的每个样本都有零个或多个文本标签，我汇总数据集中使用的所有唯一标签并将其编码为仅包含 0 和 1 的二进制数组。例如，如果完整的标签集为 [Python, Java, JavaScript, C++]，且样本包含标签 Python 和 Java，则结果向量将为 [1, 1, 0, 0]。

数值数据 &amp;分类数据：

数字数据字段按原样内置到特征向量中
分类数据映射到整数并内置到特征向量中



生成的特征矩阵如下所示
[
[-1.02, 1.33, 2.35, -0.48, ... -4.11, 1, 0, 1, 1, 0, 0, ..., 1, 0, 235, 11.5, 333],
[-0.22, 3.03, 1.95, -0.48, ... -4.11, 0, 1, 1, 1, 0, 0, ..., 0, 0, 233, 22, 333],
[-2.07, -1.33, -2.35, -0.48, ... -4.11, 1, 1, 0, 1, 1, 0, ..., 1, 1, 102, 13, 333],
[-4.32, 4.33, 1.75, -0.48, ... -4.11, 0, 0, 0, 1, 0, 1, ..., 1, 0, 98, 8, 333],
]

我是否应该对数据集应用任何标准化或规范化？如果是，我应该在连接特征的不同部分之前还是之后进行？
我正在使用 scikit-learn，我使用的主要算法是梯度提升。]]></description>
      <guid>https://stackoverflow.com/questions/66376105/how-to-perform-standardization-and-normalization-on-features-from-different-feat</guid>
      <pubDate>Thu, 25 Feb 2021 20:38:50 GMT</pubDate>
    </item>
    <item>
      <title>如何计算召回率、准确率和 f 度量？</title>
      <link>https://stackoverflow.com/questions/56608300/how-to-calculate-recall-precision-and-f-measure</link>
      <description><![CDATA[我正在做一个情绪分析项目。
我需要计算召回率、准确率和 f 度量，但我不知道我的数据集的语法，如下所示：
#训练数据格式，包含文本的单词及其权重和文本的类标签

train_set = [
({&#39;adam&#39;: 0.05,&#39;is&#39;: 0.0, &#39;a&#39;: 0.0, &#39;good&#39;: 0.02, &#39;man&#39;: 0.0}, 1),
({&#39;eve&#39;: 0.0, &#39;is&#39;: 0.0, &#39;a&#39;: 0.0,&#39;good&#39;: 0.02,&#39;woman&#39;: 0.0}, 1),
({&#39;adam&#39;: 0.05, &#39;is&#39;: 0.0, &#39;evil&#39;: 0.0}, 0)]

#0 或 1 表示类标签

#测试数据与训练数据相同

这是我当前的代码
from nltk.classify import apply_features

def naivebyse(finaltfidfVector):
train_set = []
j = 0
for vector in finaltfidfVector:
if j &lt; 2100: # 取 70% 的数据进行训练
train_set.append(vector)
j += 1
else:
break

test_set = []
j = 0
for vector in finaltfidfVector:
if j &lt; 3000 和 j &gt;= 2100：# 测试的 30%
test_set.append(vector)
if j&gt;= 3000:
break
j += 1

classifier = nltk.NaiveBayesClassifier.train(train_set)
print(&quot;讽刺分类器的准确率：&quot;, 
(nltk.classify.accuracy(classifier, test_set)*100))
refsets = collections.defaultdict(set)
testsets = collections.defaultdict(set)

for i, (feats, label) in enumerate(test_set):
refsets[label].add(i)
perceived = classifier.classify(feats)
testsets[observed].add(i)

print(&quot;准确率百分比：&quot; , nltk.metrics.precision(refsets[&#39;1&#39;], 
testsets[&#39;1&#39;])*100)
print(&quot;Recall Percentage : &quot;, nltk.metrics.recall(refsets[&#39;1&#39;], 
testsets[&#39;1&#39;])*100)

异常
Tkinter 回调中的异常
无法重新分配 20234 字节

有人可以提供一些关于如何执行任务的提示吗？]]></description>
      <guid>https://stackoverflow.com/questions/56608300/how-to-calculate-recall-precision-and-f-measure</guid>
      <pubDate>Sat, 15 Jun 2019 07:25:35 GMT</pubDate>
    </item>
    <item>
      <title>深度强化学习 - 如何处理动作空间中的边界[关闭]</title>
      <link>https://stackoverflow.com/questions/51127979/deep-reinforcement-learning-how-to-deal-with-boundaries-in-action-space</link>
      <description><![CDATA[我构建了一个自定义强化学习环境和代理，它类似于迷宫游戏。
在迷宫中有 5 种可能的动作：上、下、左、右和停留。如果被阻挡，例如代理无法上去，那么人们如何设计环境和代理来模拟这种情况？
具体来说，代理处于当前状态s0，根据定义，采取下、左、右动作将使状态更改为其他值并立即获得奖励（如果在出口则为&gt;0）。一种可能的方法是，当采取上动作时，状态将保持在s0，奖励将是一个很大的负数。理想情况下，代理将学习这一点，并且永远不会再在这个状态下上。 
但是，我的代理似乎没有学到这一点。相反，它仍然向上。另一种方法是对代理和环境进行硬编码，使代理在s0时无法执行操作向上，我能想到的是：

当某些状态下不允许向上时，我们查看不同操作的Q值
选择除向上之外具有最大Q值的操作
因此，代理永远不会执行无效操作

我想问的是上述方法是否可行？会不会有什么与此相关的问题？或者有没有更好的设计来处理边界和无效操作？]]></description>
      <guid>https://stackoverflow.com/questions/51127979/deep-reinforcement-learning-how-to-deal-with-boundaries-in-action-space</guid>
      <pubDate>Mon, 02 Jul 2018 00:35:49 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 scikit learn 计算多类别情况的精确度、召回率、准确度和 f1 分数？</title>
      <link>https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case</guid>
      <pubDate>Wed, 15 Jul 2015 04:17:36 GMT</pubDate>
    </item>
    <item>
      <title>QLearning 和永无止境的剧集</title>
      <link>https://stackoverflow.com/questions/1836731/qlearning-and-never-ending-episodes</link>
      <description><![CDATA[假设我们有一个 (x,y) 平面，机器人可以在其中移动。现在我们将世界的中心定义为目标状态，这意味着一旦机器人达到该状态，我们将给予它 100 的奖励。
现在，假设有 4 个状态（我将其称为 A、B、C、D）可以导致目标状态。
第一次处于 A 并进入目标状态时，我们将按如下方式更新 QValues 表：
Q(state = A, action = going to goal state) = 100 + 0

可能会发生以下两种情况之一。我可以在这里结束这一集，然后开始另一个集，让机器人再次找到目标状态，或者我可以继续探索世界，即使我找到了目标状态。如果我尝试这样做，我会看到一个问题。如果我处于目标状态并返回到状态 A，它的 Qvalue 将如下所示：
Q(state = goalState, action = going to A) = 0 + gamma * 100

现在，如果我尝试再次从 A 转到目标状态：
Q(state = A, action = going to goal state) = 100 + gamma * (gamma * 100)

这意味着如果我继续这样做，因为 0 &lt;= gamma &lt;= 0，两个 qValues 都会永远上升。
这是 QLearning 的预期行为吗？我做错了什么吗？如果这是预期行为，这不会导致问题吗？我知道从概率上讲，所有 4 个状态（A、B、C 和 D）都会以相同的速率增长，但即便如此，让它们永远增长也让我有点烦。
允许代理在找到目标后继续探索的想法与代理距离目标状态越近，就越有可能处于可以立即更新的状态有关。]]></description>
      <guid>https://stackoverflow.com/questions/1836731/qlearning-and-never-ending-episodes</guid>
      <pubDate>Wed, 02 Dec 2009 23:53:13 GMT</pubDate>
    </item>
    <item>
      <title>强化学习的良好实现？[关闭]</title>
      <link>https://stackoverflow.com/questions/740389/good-implementations-of-reinforcement-learning</link>
      <description><![CDATA[对于一个人工智能项目，我需要实现一个强化学习算法，该算法可以打败一个简单的俄罗斯方块游戏。该游戏是用 Java 编写的，我们有源代码。我知道强化学习理论的基础知识，但想知道 SO 社区中是否有人有这方面的经验。

对于在俄罗斯方块游戏中实施强化学习，您推荐的阅读材料是什么？
是否有值得一看的优秀开源项目可以完成类似的事情？

越具体越好，但欢迎提供有关该主题的一般资源。
跟进：
这是我为未来的学生提供的解决方案（代码和写作）：
论文 / 代码]]></description>
      <guid>https://stackoverflow.com/questions/740389/good-implementations-of-reinforcement-learning</guid>
      <pubDate>Sat, 11 Apr 2009 16:32:19 GMT</pubDate>
    </item>
    </channel>
</rss>