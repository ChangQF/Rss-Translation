<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 12 Nov 2024 03:19:24 GMT</lastBuildDate>
    <item>
      <title>Vertex AI：Automl-tabular 模板不断给我一个错误</title>
      <link>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</link>
      <description><![CDATA[我正在尝试使用 Google 的 AutoML 产品 (VertexAI) 构建机器学习模型。
我已成功上传我的数据集 - 见下图。

但是，当我尝试使用 AutoML 模板为表格回归创建管道运行时，管道失败。我将在 VertexAI 上展示步骤，我只是使用默认设置而不进行任何更改：





我运行的第一个管道失败了。


我将调试 json 粘贴到 ChatGPT 中。它告诉我尝试将机器类型从 n1-standard-8 或 n1-highmem-8 更改为 n1-standard-4。我试过了，但管道仍然失败。我还确保计算服务已启用正确的设置。
]]></description>
      <guid>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</guid>
      <pubDate>Mon, 11 Nov 2024 11:41:07 GMT</pubDate>
    </item>
    <item>
      <title>提取 Swin-Vit 主干</title>
      <link>https://stackoverflow.com/questions/79177075/extracting-swin-vit-backbone</link>
      <description><![CDATA[我想知道是否有办法提取类似于 resnet 的 Swin-VIT 主干？
我正在尝试训练一些自监督学习算法，其中我只需要获取骨干（特征提取器）并将其传递给我的自监督学习算法（即修复 simCLR/SimSiam、Dino 到骨干）。
使用 resnet，这可以很容易地完成。
resnet = resnet50()
# 加载预训练权重：下面的函数只使用 torch.load 加载权重
resnet = load_model_weights(..., pretrained_weight_file, resnet, num_classes = 51)
# 提取没有 MLP Head 的主干
resnet_bb = torch.nn.Sequential(*list(resnet_bb_model.children())[:-1]) 
# 将主干合并到自监督模型

似乎没有像这样的简单解决方案swin-vit。我一直在使用这个存储库中的 Swin Transformer，因为它包含在大型遥感数据集上训练的预训练权重（在此处输入链接描述）
据我所知，您可以使用 swin_vit.forward_features() 获取 swin-vit 主干的输出
sys.path.append(&quot;RSP/Scene Recognition/models&quot;)
from swin_transformer import SwinTransformer

swin_vit = SwinTransformer()
# 加载预训练权重：仅使用 torch load 加载模型权重
swin_vit = load_model_weights(..., pretrained_weight_file, swin_vit, num_classes = 51)
# 此时，您可以使用 
out = swin_vit.forward_features(img_tensor) 获取特征

但是，我想知道是否有办法将 forward_features 作为单独的类来模仿 resnet_backbone。
原因是当我将它传递给我的自我监督学习算法时，就像这样...
class SimSiam(pl.lightningModule):
def __init__(..., backbone_model):
self.backbone_model = backbone_model
...

def forward(self, x):
f = self.backbone_model.forward_features(X) #(b,3,256,256) -&gt; ... -&gt; #(b, 768)
z = self.projection_head(f) # (b,768) -&gt; ... -&gt; (b,2048)
p = self.prediction_head(z) # (b,2048) -&gt; (b,512) -&gt; (b,2048) 
z = z.detach() #SimSiams 停止梯度以防止崩溃
return z,p
...

... 在训练自监督算法 (SimSiam) 期间，我会得到以下错误。原因是整个骨干模型被传递给 SimSiam 类，但该类只使用了 model.forward_features() 部分（即 Swin-vit 的其余部分，例如未使用的 MLP 头）。
[rank0]: RuntimeError: 看起来您的 LightningModule 具有未用于产生 training_step 返回的损失的参数。如果这是故意的，您必须在 DDP 中启用未使用参数的检测，方法是设置字符串值 strategies=&#39;ddp_find_unused_pa​​rameters_true&#39; 或在策略中设置标志 strategies=DDPStrategy(find_unused_pa​​rameters=True)。
可以通过传递错误中提到的策略来避免 pytorch lightning 中未使用的参数。但是使用 resnet，您永远不会遇到这样的问题，因为您可以只传递骨干（减去 MLP 头），而不是整个骨干模型（带 MLP 头）。
我可能错了，但我觉得在训练完成后加载权重时可能会出现问题（带有骨干训练的自监督学习模型）。因为只有部分模型权重正在更新（如果我们使用策略 =&#39;ddp_find_unused_pa​​rameters_true&#39;）。它可能也很好，但为了避免所有这些，我想知道是否有一种方法可以只传递前向特征（即 swin-vit 骨干），类似于使用 resnet 模型的方式？]]></description>
      <guid>https://stackoverflow.com/questions/79177075/extracting-swin-vit-backbone</guid>
      <pubDate>Mon, 11 Nov 2024 09:26:07 GMT</pubDate>
    </item>
    <item>
      <title>为什么我开始训练时准确度和验证准确度都很低？[关闭]</title>
      <link>https://stackoverflow.com/questions/79175873/why-is-the-accuracy-and-validation-acuuracy-are-very-low-when-i-start-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79175873/why-is-the-accuracy-and-validation-acuuracy-are-very-low-when-i-start-training</guid>
      <pubDate>Sun, 10 Nov 2024 21:35:24 GMT</pubDate>
    </item>
    <item>
      <title>由于填充，遮罩后训练数据和标签的形状不一样</title>
      <link>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</guid>
      <pubDate>Sun, 10 Nov 2024 19:56:09 GMT</pubDate>
    </item>
    <item>
      <title>GGML/pytorch 张量实现</title>
      <link>https://stackoverflow.com/questions/79175622/ggml-pytorch-tensors-implementation</link>
      <description><![CDATA[大家好，我最近开始研究自我注意机制的自定义加速器，我不知道 GGML 张量是如何实现的，希望有人能提供指导。
了解张量的 GGML 实现。]]></description>
      <guid>https://stackoverflow.com/questions/79175622/ggml-pytorch-tensors-implementation</guid>
      <pubDate>Sun, 10 Nov 2024 19:51:32 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程回归实现中矩阵乘法的`ValueError`</title>
      <link>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</link>
      <description><![CDATA[我正在使用平方指数核在 Python 中实现高斯过程回归 (GPR) 模型。但是，我在 predict 方法的矩阵乘法步骤中遇到了 ValueError，特别是在尝试计算平均预测时。
我看到的错误是：
ValueError：matmul：输入操作数 1 在其核心维度 0 中不匹配，gufunc 签名为 
(n?,k),(k,m?)-&gt;(n?,m?)（大小 10 与 100 不同）

代码详细信息
以下是此错误中涉及的代码的细分：
import numpy as np

class SquaredExponentialKernel:
def __init__(self, length_scale=1.0, variance=1.0):
self.length_scale = length_scale
self.variance = variance

def __call__(self, x1, x2):
dist_sq = np.sum((x1 - x2)**2)
return self.variance * np.exp(-0.5 * dist_sq / self.length_scale**2)

def cov_matrix(x1, x2, cov_function) -&gt; np.array:
返回 np.array([[cov_function(a, b) for a in x1] for b in x2])

class GPR:
def __init__(self, data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma: float = 0):
self.noise = white_noise_sigma
self.data_x = data_x
self.data_y = data_y
self.covariance_function = covariance_function
self._inverse_of_covariance_matrix_of_input_noise_adj = np.linalg.inv(
cov_matrix(data_x, data_x, covariance_function) + self.noise * np.identity(len(self.data_x))
)
self._memory = None

def predict(self, test_data: np.ndarray) -&gt;; np.ndarray:
KXX_star = cov_matrix(test_data, self.data_x, self.covariance_function)
KX_starX_star = cov_matrix(test_data, test_data, self.covariance_function)
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)
cov_test_data = KX_starX_star - KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ KXX_star.T)
var_test_data = np.diag(cov_test_data)
self._memory = {&#39;mean&#39;: mean_test_data, &#39;covariance_matrix&#39;: cov_test_data, &#39;variance&#39;: var_test_data}
返回 mean_test_data

# 测试数据
np.random.seed(69)
data_x = np.linspace(-5, 5, 10).reshape(-1, 1)
data_y = np.sin(data_x) + 0.1 * np.random.randn(10, 1)

# 实例化并预测
gpr_se = GPR(data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma=0.1)
test_data = np.linspace(-6, 6, 100).reshape(-1, 1)
mean_predictions = gpr_se.predict(test_data)

维度细分
这是矩阵乘法的维度分析，其中误差发生：

KXX_star 计算为 cov_matrix(test_data, self.data_x, self.covariance_function)，结果形状为 (100, 10)。
self._inverse_of_covariance_matrix_of_input_noise_adj 在 __init__ 方法中计算，形状为 (10, 10)。
self.data_y 形状为 (10, 1)。

有问题的行是：
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)

这应该产生形状为 (100, 1) 的结果，因为：

KXX_star 具有形状 (100, 10)，
(self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y) 导致形状为 (10, 1)。

当矩阵乘法的维度似乎对齐时，为什么我在这里收到维度不匹配错误？我该如何修复它？
我预计这个矩阵乘法能够正常工作，因为尺寸在纸面上看起来是兼容的：KXX_star (100, 10) 乘以 (10, 1) 应该得到 (100, 1)。然而，错误表明尺寸不匹配，这意味着某些东西没有按预期对齐。我检查了 self.data_y、self._inverse_of_covariance_matrix_of_input_noise_adj 和 KXX_star 的形状。还尝试重塑 data_y 以确保它始终为 (10, 1)，但错误仍然存​​在。我期望获得 test_data 的平均预测值作为形状为 (100, 1) 的向量，并且没有任何维度问题。]]></description>
      <guid>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</guid>
      <pubDate>Sun, 10 Nov 2024 15:14:18 GMT</pubDate>
    </item>
    <item>
      <title>尝试弄清楚如何实施 ImGWO</title>
      <link>https://stackoverflow.com/questions/79174187/trying-to-figure-out-how-to-implement-imgwo</link>
      <description><![CDATA[我使用 Google Gemini 填充了这段代码，但我不知道如何使用它。
我正在做一个异常检测和训练模型的项目。我做了一些研究，发现改进的灰狼算法在检测异常方面表现良好。
如果有人能帮我解决这个问题，那将是一个很大的帮助。
#提示：使用 x_train_scaled 和 x_test_scaled 为上述模型实现改进的灰狼优化器算法

import numpy as np
from sklearn.metrics import accuracy_score

#假设 x_train_scaled 和 x_test_scaled 是从前面的代码定义的

def Improved_grey_wolf_optimizer(objective_function, lb, ub, dim, SearchAgents_no=50, Max_iter=1000):
#初始化 alpha、beta 和 delta_pos
Alpha_pos = np.zeros(dim)
Alpha_score = float(&#39;inf&#39;)

Beta_pos = np.zeros(dim)
Beta_score = float(&#39;inf&#39;)

Delta_pos = np.zeros(dim)
Delta_score = float(&#39;inf&#39;)

# 初始化搜索代理的位置
Positions = np.random.uniform(0, 1, (SearchAgents_no, dim)) * (ub - lb) + lb
Convergence_curve = np.zeros(Max_iter)

# 主循环
for l in range(0, Max_iter):
for i in range(0, SearchAgents_no):
# 返回超出搜索空间边界的搜索代理
for j in range(dim):
Positions[i, j] = np.clip(Positions[i, j], lb[j], ub[j])

# 计算每个搜索代理的目标函数
fitness = objective_function(Positions[i, :])

# 更新 Alpha， Beta 和 Delta
如果 fitness &lt; Alpha_score:
Alpha_score = fitness
Alpha_pos = Positions[i, :].copy()

如果 fitness &gt; Alpha_score 且 fitness &lt; Beta_score:
Beta_score = fitness
Beta_pos = Positions[i, :].copy()

如果 fitness &gt; Alpha_score 且 fitness &gt; Beta_score 且 fitness &lt; Delta_score:
Delta_score = fitness
Delta_pos = Positions[i, :].copy()

a = 2 - l * ((2) / Max_iter) # a 从 2 线性减小到 0

# 更新包括 omegas 在内的搜索代理的位置
for i in range(0, SearchAgents_no):
for j in range(0, dim):
r1 = np.random.rand()
r2 = np.random.rand()
A1 = 2 * a * r1 - a
C1 = 2 * r2

D_alpha = abs(C1 * Alpha_pos[j] - Positions[i, j])
X1 = Alpha_pos[j] - A1 * D_alpha

r1 = np.random.rand()
r2 = np.random.rand()
A2 = 2 * a * r1 - a
C2 = 2 * r2

D_beta = abs(C2 * Beta_pos[j] - Positions[i, j])
X2 = Beta_pos[j] - A2 * D_beta

r1 = np.random.rand()
r2 = np.random.rand()
A3 = 2 * a * r1 - a
C3 = 2 * r2

D_delta = abs(C3 * Delta_pos[j] - Positions[i, j])
X3 = Delta_pos[j] - A3 * D_delta

Positions[i, j] = (X1 + X2 + X3) / 3

Convergence_curve[l] = Alpha_score

return Alpha_pos, Convergence_curve

# 示例用法（替换为您的实际目标函数和边界）
def objective_function(solution):
# 这是您将模型与 GWO 集成的地方，预测使用解决方案（权重）
# 然后计算 y_test 的错误。
# 将其替换为您的实际模型评估函数
# 以下只是运行示例的随机值。
y_pred = np.random.randint(0, 10, size=len(x_test_scaled))
return 1 - accuracy_score(y_test, y_pred)

lb = np.array([-1]*x_train_scaled.shape[1]) # 用下限替换
ub = np.array([1]*x_train_scaled.shape[1]) # 用上限替换
dim = x_train_scaled.shape[1]

gwo_y_pred, convergence_curve = Improved_grey_wolf_optimizer(objective_function, lb, ub, dim)
gwo_y_pred

# print(&quot;Improved Grey Wolf Optimiser Report:&quot;)
# print(classification_report(y_test, gwo_y_pred))
print(&quot;Improved Grey Wolf Optimiser准确度：&quot;，accuracy_score(y_test, gwo_y_pred))

这是使用 SVM 实现的，
如果您想知道我在实现之前做了什么，希望这可能会有所帮助。
来自 sklearn.svm 导入 SVC
导入警告
来自 sklearn.exceptions 导入 DataConversionWarning

# 抑制 DataConversionWarning
warnings.filterwarnings(action=&#39;ignore&#39;, category=DataConversionWarning)

# 使用默认参数的支持向量机分类器
svm_model = SVC(random_state=42)

# 在训练数据上拟合模型
svm_model.fit(x_train_scaled, y_train.to_numpy().ravel())

# 在测试集上进行预测
svm_y_pred = svm_model.predict(x_test_scaled)

# SVM 的性能指标
print(&quot;SVM 分类报告：&quot;)
print(classification_report(y_test, svm_y_pred))
print(&quot;SVM 准确率：&quot;, accuracy_score(y_test, svm_y_pred))
]]></description>
      <guid>https://stackoverflow.com/questions/79174187/trying-to-figure-out-how-to-implement-imgwo</guid>
      <pubDate>Sun, 10 Nov 2024 05:19:51 GMT</pubDate>
    </item>
    <item>
      <title>如何修复错误 ValueError：预期输入 batch_size (49) 与目标 batch_size (64) 匹配</title>
      <link>https://stackoverflow.com/questions/79172053/how-to-fix-the-error-valueerror-expected-input-batch-size-49-to-match-target</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79172053/how-to-fix-the-error-valueerror-expected-input-batch-size-49-to-match-target</guid>
      <pubDate>Sat, 09 Nov 2024 03:24:43 GMT</pubDate>
    </item>
    <item>
      <title>我应该安装哪个版本的 torch 和 torchtext [关闭]</title>
      <link>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</link>
      <description><![CDATA[我使用的是 Windows，python 版本为 3.11.4，pandas 版本为 2.2.1

我尝试安装 torch 和 torchtext，但总是出现依赖错误。

这两个版本应该安装哪个？
错误：pip 的依赖解析器目前没有考虑所有已安装的软件包。此行为是以下依赖冲突的根源。

torchaudio 2.1.2 需要 torch==2.1.2，但您有不兼容的 torch 2.1.0+cu118。

成功安装 torch-2.1.0+cu118


那么我在哪里可以找到与 torch 2.1.0 兼容的 torchaudio 版本？
torchaudio pypl 没有像 torchtext 和 torchdata 这样的兼容表。]]></description>
      <guid>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</guid>
      <pubDate>Fri, 08 Nov 2024 20:20:10 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker 端点</title>
      <link>https://stackoverflow.com/questions/79169750/sagemaker-endpoint</link>
      <description><![CDATA[我正在尝试为我的模型创建 sagemaker 端点。我已将包含推理脚本的 docker 文件推送到 aws ECR。我没有使用 model_fn、input_fn、predict_fn 和 output_fn。我只有一个函数，它从 kinesis 视频流中获取实时流，将我已保存到 docker 文件的 yolo 模型应用到 docker 文件中，然后将检测保存到 s3。当我创建端点时，它每次都会失败。我该怎么办？
我尝试将那些 model_fn、input_fn、predict_fn 和 output_fn 放入推理脚本中。因为我不需要它们，所以我在每个文件中都返回了 None，但它不起作用。
Dockerfile
FROM ultralytics/ultralytics:latest
WORKDIR /workspace
COPY inference.py /workspace/inference.py
COPY yolo_weights/PPE_4.pt /workspace/yolo_weights/PPE_4.pt
COPY static/detection_results /workspace/static/detection_results
RUN pip install --no-cache-dir 
boto3
ENTRYPOINT [&quot;python3&quot;, &quot;/workspace/inference.py&quot;]
Inference.py 文件
import boto3
from ultralytics import YOLO
导入 cv2
导入数学
导入时间
导入操作系统
导入日志记录
def model_fn(model_dir):
&quot;&quot;&quot;&quot;
这是一个虚拟实现。您可以将其留空，或者如果您自己处理所有事情，则返回 None。
&quot;&quot;&quot;&quot;
#model_path = os.path.join(model_dir, &#39;PPE_4.pt&#39;)
#model = YOLO(model_path)
logger.info(&quot;this is inside model&quot;)
return None

def input_fn(input_data, content_type):
&quot;&quot;&quot;&quot;&quot;
如果您自己处理所有事情，则这是一个虚拟实现。
&quot;&quot;&quot;&quot;&quot;
logger.info(&quot;this is inside input&quot;)
return # 按原样返回；您可以在 custom_inference_function 中处理预处理。
def predict_fn(input_data, model):
&quot;&quot;&quot;
在此处调用您的自定义推理函数，该函数处理所有事情（模型加载、数据预处理、推理）。
&quot;&quot;&quot;
logger.info(&quot;this is inside predict&quot;)
return
def output_fn(prediction, accept):
&quot;&quot;&quot;
将预测转换为 SageMaker 期望的输出格式。
&quot;&quot;&quot;
logger.info(&quot;this is inside output&quot;)
return
#这是我的自定义函数，它使用 kinesis HLS 流会话从 kinesis 获取直播流，并加载复制到 docker 容器的模型，然后在获取的 kinesis 视频流上使用该模型。
def video_detection_video(output_path, model_path):
#处理代码
video_detection_video(local_output_path, local_model_path)
upload_to_s3(local_output_path, s3_bucket, output_s3_key)]]></description>
      <guid>https://stackoverflow.com/questions/79169750/sagemaker-endpoint</guid>
      <pubDate>Fri, 08 Nov 2024 11:00:30 GMT</pubDate>
    </item>
    <item>
      <title>使用 SelfQueryRetriever 获取文档相似度分数 - Langchain</title>
      <link>https://stackoverflow.com/questions/79165072/getting-document-similarity-scores-with-selfqueryretriever-langchain</link>
      <description><![CDATA[我希望能够在使用 SelfQueryRetriever 时获取检索到的文档的相似度分数，如下所示。
我制作了一个自查询检索器，如下所示：
retriever = SelfQueryRetriever.from_llm(
llm = llm,
vectorstore = vectorstore,
document_contents = document_content_description,
metadata_field_info = metadata_field_info,
enable_limit=True, 
search_type = &quot;similarity_score_threshold&quot;,
search_kwargs={&quot;score_threshold&quot;: 0.80, &quot;k&quot;: 5},
verbose=True
)

检索器能够按预期检索文档，但我想以某种方式显示检索到的文档的相似度分数。可以做到这一点吗？如何做到？检索器返回带有 page_content 和元数据键的文档。]]></description>
      <guid>https://stackoverflow.com/questions/79165072/getting-document-similarity-scores-with-selfqueryretriever-langchain</guid>
      <pubDate>Thu, 07 Nov 2024 05:01:57 GMT</pubDate>
    </item>
    <item>
      <title>FLAML automl 预测概率与预测不匹配</title>
      <link>https://stackoverflow.com/questions/79163315/flaml-automl-prediction-probabilities-do-not-match-the-prediction</link>
      <description><![CDATA[我正在 Fabric 上使用 flaml automl 进行分类练习。
为了利用 spark，我必须使用 to_pandas_on_spark。
这些特征已经组装在一个向量中。
from flaml.automl.spark.utils import to_pandas_on_spark
psdf = to_pandas_on_spark(train_df)

拟合成功，所以我想预测我的测试数据。最佳估计器是 lgbm_spark。
接下来，为了进行评估，我需要一个最终数据框，其中包括目标 alpha 列、预测和概率，以及 test_df（pdate &amp; zm）中存在的 id 列。
psdf_test = to_pandas_on_spark(test_df.select(&quot;features&quot;))
y_pred = automl.predict(psdf_test) 

以上将返回一个带有一列预测的 pyspark.pandas.series.Series
y_pred_prob = automl.predict_proba(psdf_test)

以上将返回一个 pyspark.pandas.series.Series，其中每行都是三个概率的列表。
通常第一个是类别 0 的概率，第二个是类别 1 的概率，第三个是类别 2 的概率。
为了将所有内容整合在一起，我计划将所有内容转换为 pandas 数据框，然后连接起来。
#predictions
y_pred_pd = y_pred.to_pandas() # 转换为 pandas 系列
y_pred_pd = y_pred_pd.to_frame(name=&quot;prediction&quot;) # 转换为列名为“prediction”的 pandas 数据框

# probabilities
y_pred_prob_pd = y_pred_prob.to_pandas() # 转换为 pandas 系列
#y_pred_prob_pd = y_pred_prob_pd.to_frame(name=&quot;probability&quot;) # 转换为列名为“dataframe”的 DataFrame &#39;probability&#39;

# 将 test_df 转换为 pandas DataFrame 以使用标识符重新连接
test_df_pd = test_df.toPandas()

# 连接三个数据框
result_df = pd.concat([test_df_pd, y_pred_pd, y_pred_prob_pd], axis=1)

它有效，但问题是：最高概率与预测不匹配。

请注意，即使假设的类顺序不正确，预测仍然与最高概率不一致概率。

为什么会有差异？
有没有更简洁的方法来实现我想要的结果？
]]></description>
      <guid>https://stackoverflow.com/questions/79163315/flaml-automl-prediction-probabilities-do-not-match-the-prediction</guid>
      <pubDate>Wed, 06 Nov 2024 15:49:17 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow TypeError：无法解压不可迭代的浮点对象</title>
      <link>https://stackoverflow.com/questions/61980349/tensorflow-typeerror-cannot-unpack-non-iterable-float-object</link>
      <description><![CDATA[我正在使用 tensorflow V2.2，在执行 model.evaluate 时遇到 TyepError。有人能告诉我问题可能出在哪里吗？下面显示了执行和错误消息的屏幕截图。
]]></description>
      <guid>https://stackoverflow.com/questions/61980349/tensorflow-typeerror-cannot-unpack-non-iterable-float-object</guid>
      <pubDate>Sun, 24 May 2020 00:50:30 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模型未进行训练</title>
      <link>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</link>
      <description><![CDATA[我有一个问题，已经一个星期没法解决了。我正在尝试构建 CIFAR-10 分类器，但每个批次后的损失值都在随机跳跃，而且准确率甚至在同一批次上也没有提高（我甚至无法用一个批次过度拟合模型），所以我猜唯一可能的原因是 - 权重没有更新。 
我的模块类
class Net(nn.Module):
def __init__(self):
super(Net, self).__init__()
self.conv_pool = nn.Sequential(
nn.Conv2d(3, 64, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(64, 128, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(128, 256, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(256, 512, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(512, 512, 1),
nn.ReLU(),
nn.MaxPool2d(2, 2))

self.fcnn = nn.Sequential(
nn.Linear(512, 2048),
nn.ReLU(),
nn.Linear(2048, 2048),
nn.ReLU(),
nn.Linear(2048, 10)
)

def forward(self, x):
x = self.conv_pool(x)
x = x.view(-1, 512)
x = self.fcnn(x)
return x

我正在使用的优化器：
net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, influence=0.9)

我的训练函数：
def train():
for epoch in range(5): # 多次循环遍历数据集
for i in range(0, df_size):
# 获取数据

try:
images, labels = loadBatch(ds, i)
except BaseException:
continue

# 包装 
输入 = Variable(images)

optimizer.zero_grad()

输出 = net(inputs)

损失 = criterion(outputs, Variable(labels))

损失.backward()
optimizer.step()
acc = test(images,labels)
print(&quot;损失：&quot; + str(loss.data[0]) + &quot; 准确率 %：&quot; + str(acc) + &quot;迭代：&quot; + str(i))

if i % 40 == 39:
torch.save(net.state_dict(), &quot;model_save_cifar&quot;)

print(&quot;Finished epoch &quot; + str(epoch))

我使用的是 batch_size = 20, image_size = 32 (CIFAR-10)
loadBatch 函数返回 LongTensor 20x3x32x32 的元组（用于图像）和 LongTensor 20x1 的元组（用于标签）
如果您能帮助我或提出可能的解决方案，我将非常高兴（我猜是因为 NN 中的顺序模块，但我传递给优化器的参数似乎是正确的）]]></description>
      <guid>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</guid>
      <pubDate>Thu, 27 Jul 2017 19:07:27 GMT</pubDate>
    </item>
    <item>
      <title>R-派对套餐：cforest 真的是装袋吗？</title>
      <link>https://stackoverflow.com/questions/34293471/r-party-package-is-cforest-really-bagging</link>
      <description><![CDATA[我正在使用“party”包来创建回归树的随机森林。
我创建了一个 ForestControl 类，以限制我的树 (ntree)、节点 (maxdepth) 和用于拟合树 (mtry) 的变量的数量。
我不确定的一件事是 cforest 算法是否对其生成的每棵树使用我的训练集的子集。
我在文档中看到它正在装袋，所以我假设它应该如此。但我不确定我是否理解了该函数中的“子集”输入是什么。
我对使用 ctree 得到的结果也感到困惑：绘制树时，我看到我的训练集的所有变量都分类在不同的终端树节点中，而我原本预计它也只使用一个子集。
所以我的问题是，cforest 是否与 ctree 做同样的事情，或者它真的在打包我的训练集？
提前感谢您的帮助！
Ben]]></description>
      <guid>https://stackoverflow.com/questions/34293471/r-party-package-is-cforest-really-bagging</guid>
      <pubDate>Tue, 15 Dec 2015 15:46:47 GMT</pubDate>
    </item>
    </channel>
</rss>