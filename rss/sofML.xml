<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 27 Jan 2024 09:11:48 GMT</lastBuildDate>
    <item>
      <title>为什么 DecisionTreeClassifier 会按照指定的标准错误地分割数据？</title>
      <link>https://stackoverflow.com/questions/77890508/why-decisiontreeclassifier-split-wrongly-the-data-with-the-specified-criterion</link>
      <description><![CDATA[在第一次使用 DecisionTreeClassifier 时，我们得到了样本数为 192 和 346 的两个子树，但是当我们使用文件 Counter 并在 Treeclassifier 决策中设置与分离相同的条件时，我们得到了样本数 171 和 367。这种差异的标志是什么？
DecisionTreeClassifier 代码块：
导入 pandas 作为 pd
从 sklearn.tree 导入 DecisionTreeClassifier
从 sklearn 导入树
将 matplotlib.pyplot 导入为 plt
将 numpy 导入为 np
数据 = pd.read_csv(r“PCOS.csv”)
X = data.drop(“PCOS (Y/N)”, axis=1)
y = 数据[“PCOS (Y/N)”]
模型= DecisionTreeClassifier（max_深度= 2，标准=“基尼”）
模型.fit(X, y)

树.plot_tree(模型)
fn = 数据.列

标签 = [“0”,“1”]
图，轴 = plt.subplots()
tree.plot_tree(模型，feature_names=fn，class_names=label，filled=True)
Fig.savefig(&#39;imagenae.png&#39;)


计数器代码块：
导入 pandas 作为 pd


def 子树（数据，列）：
    第一个列表 = []
    秒列表 = []
    对于范围内的 i（len（数据））：
        如果数据[col][i] &lt;= 7.5：
            first_list.append(data.loc[i, :].values)
        别的：
            sec_l​​ist.append(data.loc[i, :].values)
    基尼系数（第一个列表）
    基尼系数（秒列表）


定义基尼系数（数据）：
    a, b= 0, 0
    对于数据中的 i：
        如果 i[-1] == 0:
            一个+= 1
        别的：
            b+=1
    print(&quot;标签 0 :&quot;, a)
    print(&quot;标签 1 :&quot;, b)


col = [&#39;皮肤变黑(Y/N)&#39;, &#39;毛发生长(Y/N)&#39;, &#39;体重增加(Y/N)&#39;, &#39;周期(R/I)&#39;, &#39;毛囊编号(R)&#39; ,
       &#39;快餐（Y/N）&#39;、&#39;卵泡编号（L）&#39;、&#39;PCOS（Y/N）&#39;]

数据 = pd.read_csv(“PCOS.csv”)[col]

X = data.drop(“PCOS (Y/N)”, axis=1)
y = 数据[[“PCOS（是/否）”]]

subtree(data, &#39;毛囊编号 (L)&#39;)

结果决策树分类器：
192 和 346
结果计数器：
171 和 367
数据库：
数据库
可视化决策树：
可视化决策树]]></description>
      <guid>https://stackoverflow.com/questions/77890508/why-decisiontreeclassifier-split-wrongly-the-data-with-the-specified-criterion</guid>
      <pubDate>Sat, 27 Jan 2024 08:24:18 GMT</pubDate>
    </item>
    <item>
      <title>两阶段推荐系统中的top-K推荐</title>
      <link>https://stackoverflow.com/questions/77890505/top-k-recommendations-in-two-stage-recommendation-system</link>
      <description><![CDATA[为了超越协同过滤并同时在实施阶段实现可扩展，通常使用两阶段推荐模型。我正在考虑这样一个两阶段设置的零售销售推荐问题。但是，我没有找到足够详细的资源来解决我的以下问题以及以下模型构建步骤：

假设我们通过协作过滤模型（例如 SVD 矩阵分解）生成一小部分候选项目（例如 top100）。对于那些从未购买过的用户，我们选择了前 100 名热门商品。在此步骤之后，每个用户都会有她的（希望是个性化的）前 100 个候选项目可供推荐。在此步骤中，数据将是用户-项目矩阵。

在第二阶段，我们使用模型对每个用户的候选项目进行排名。该模型原则上可以是任何预测模型，例如某种助推器。
Q1： 排名模型的数据格式是什么？ 我的想法：当我们想要添加更多功能（例如用户人口统计数据）和其他上下文功能（例如天气）时当顾客访问商店时，数据应以表格格式排列，其中每一行都是一笔交易。这些列应包括所有相关特征，例如用户 ID、项目 ID、用户和项目特征以及交易特征，例如交易时间（上午或下午）、交易天气等。 ）这是一个虚构的示例：



&lt;表类=“s-表”&gt;
&lt;标题&gt;

用户 ID
商品 ID
年龄
商品颜色
一天中的时间
y（是否购买）


&lt;正文&gt;

0
3
20
红色
早上
1


1
4
50
红色
下午
1


2
3
35
蓝色
早上
1


2
5
35？
??
??
0




但是还有更多问题：
Q1.1：我们如何为用户从未购买过的候选商品组成一行？ （上面最后一行） 当然，我们仍然可以记下用户 ID、项目 ID 并分配 y=0，因为交易从未发生过。问题是我们如何填写“项目颜色”的值？和“一天中的时间”？我们只是随机抽取一些值来填充？ （严格来说，虚构交易的年龄可能不是35岁，所以这个专栏也有麻烦。）对于那些虚构的失败交易，我需要采样多少？

问题2：如果我使用二元分类模型作为排名模型，我的 top-k 推荐是什么？对于用户 3，top1 = {项目 2，年龄 = 60，项目颜色 = 红色，一天中的时间 = 早上}，top2 = {...}？

我的想法：现阶段我很想使用升压机。然后，对于每个特征值组合，我们将得到 y 的预测概率。理论上，我可以对这些概率进行降序排序，以获得我的前 k 个推荐。然而，由于预测中需要这些上下文特征值，因此我必须考虑年龄、项目颜色、一天中的时间等的所有组合，如果我有更多这样的特征（即事务属性），那么我就必须考虑更多的组合。但随之而来的是另一个问题：
Q2.1：如果 top-K 推荐看起来像这样怎么办？对于用户 3，

&lt;表类=“s-表”&gt;
&lt;标题&gt;

用户 ID
商品 ID
年龄
商品颜色
一天中的时间
y（预测）


&lt;正文&gt;

3
2
60
红色
早上
0.56


3
2
59
红色
早上
0.52


3
2
58
红色
早上
0.47


3
2
57
红色
早上
0.46




感谢任何讨论或帮助。
我刚刚开始考虑构建一个超越简单的协同过滤系统的推荐系统。两阶段模型听起来很有吸引力，而不是构建一个大的单一模型。据我了解，第一阶段模型试图提高召回率，第二阶段模型试图提供良好的精度值。
乍一看，在两阶段模型中包含更多功能的能力似乎很强大。然而，我发现这也引发了很多问题，比如如何弥补零售商数据等隐式数据集的失败交易？任何讨论或经验分享将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77890505/top-k-recommendations-in-two-stage-recommendation-system</guid>
      <pubDate>Sat, 27 Jan 2024 08:22:43 GMT</pubDate>
    </item>
    <item>
      <title>我尝试使用（ pip install pickle5 ）安装 python 的 pickle 包，但无法安装该包</title>
      <link>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-a</link>
      <description><![CDATA[pip install pickle5

(https://i.stack.imgur.com/PQ52a.png)
它显示“错误：无法为 pickle5 构建轮子，这是安装基于 pyproject.toml 的项目所必需的”
我尝试按照其他帖子中的建议重新安装 Microsoft Visual C++，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77890171/i-tried-installing-the-pickle-package-for-python-using-pip-install-pickle5-a</guid>
      <pubDate>Sat, 27 Jan 2024 05:36:19 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：编译神经网络进行情感分析时，模块“keras.src.backend”没有属性“floatx”</title>
      <link>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</link>
      <description><![CDATA[从tensorflow.keras.models导入顺序
从tensorflow.keras导入层

# 设置嵌入维度
嵌入尺寸 = 100

# 创建模型
模型=顺序（[
    层.Embedding(max_words, embedding_dim, input_length=max_length),
    层.LSTM(64),
    层.Dense(1, 激活=&#39;sigmoid&#39;)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

# 打印模型摘要
打印（模型.摘要（））

我尝试使用 Jupyter Notebook (.ipynb) 在 VSCode 中编译上述模型，但遇到以下错误：
AttributeError：模块“keras.src.backend”没有属性“floatx”
最初，我成功地编译了模型，但在拟合模型时导致 VScode 崩溃。重新加载 VSCode 后，我收到此错误。
为了解释上下文，我正在尝试构建一个非常基本的 NLP 模型，以根据情绪对亚马逊评论进行分类。我也在使用 Python 3.11 和 Tensorflow 版本 2.15
首先我尝试了以下方法：
导入keras.backend为K
K.set_floatx(&#39;float32&#39;)

但是我遇到了同样的错误。然后我尝试重置 VSCode 并再次运行笔记本，但仍然遇到相同的错误？]]></description>
      <guid>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</guid>
      <pubDate>Sat, 27 Jan 2024 04:41:13 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 部署到 sagemaker</title>
      <link>https://stackoverflow.com/questions/77889951/pytorch-deployment-to-sagemaker</link>
      <description><![CDATA[我已压缩并保存到 s3，如下所示：
导入 tar 文件
使用 tarfile.open(&#39;model.tar.gz&#39;, mode=&#39;w:gz&#39;) 作为存档：
archive.add(&#39;Model&#39;, recursive=True)
导入Sagemaker
sagemaker_session = sagemaker.Session()
输入= sagemaker_session.upload_data(path=&#39;model.tar.gz&#39;, key_prefix=&#39;model&#39;)
尝试像这样部署：
从 sagemaker 导入 get_execution_role
从 sagemaker.pytorch.model 导入 PyTorchModel
角色 = get_execution_role()
pytorch_model = PyTorchModel(model_data= &#39;s3://&#39; + sagemaker_session.default_bucket() + &#39;/model/model.tar.gz&#39;, role=role,
Entry_point=&#39;inference.py&#39;,framework_version=&#39;2.1&#39;,py_version=&#39;py310&#39;)
预测器= pytorch_model.deploy（instance_type=&#39;ml.p3.2xlarge&#39;，initial_instance_count=1）
但我收到一个错误：
FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;inference.py&#39;
我尝试了上面解释的所有内容]]></description>
      <guid>https://stackoverflow.com/questions/77889951/pytorch-deployment-to-sagemaker</guid>
      <pubDate>Sat, 27 Jan 2024 03:20:13 GMT</pubDate>
    </item>
    <item>
      <title>安装斗争</title>
      <link>https://stackoverflow.com/questions/77889759/installation-struggle</link>
      <description><![CDATA[我们正在使用 Qiskit 工具包进行一个量子计算项目。但我们在导入或安装软件包和库时遇到了困难。在 Qiskit 中我们如何导入库和包？
澄清如何从外包安装库的疑问。]]></description>
      <guid>https://stackoverflow.com/questions/77889759/installation-struggle</guid>
      <pubDate>Sat, 27 Jan 2024 01:36:23 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch 前向返回张量与标量</title>
      <link>https://stackoverflow.com/questions/77889711/pytorch-forward-return-tensor-versus-scalar</link>
      <description><![CDATA[假设我有一个具有以下前向函数的 Pytorch 模型：
defforward(self, input_tensors):
    ”“”
    所有变量的维度：
    - input_tensors：（头、批次、feature_dim）
    - self.w：（头，feature_dim，1）
    - self.b: (头, 1, 1)
    ”“”

    out = torch.bmm(input_tensor, self.w) + self.b # (头数, 批次, 1)
    out = out.transpose(0, 1).squeeze(2) # （批次，头）
    标签 = torch.ones([批次, 头]) # (批次, 头
    logloss = SOMELOSSFUNC(logits=logits, labels=labels) # 输出可以是 [heads] 维度的标量或张量

    返回对数损失

如果对数损失是标量，则模型会针对一个值进行优化。如果对数损失是 [heads] 维度的张量怎么办？这是否意味着我正在独立优化每个头的 w 和 b ？谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/77889711/pytorch-forward-return-tensor-versus-scalar</guid>
      <pubDate>Sat, 27 Jan 2024 01:18:12 GMT</pubDate>
    </item>
    <item>
      <title>(Keras) 尝试加载以数组形式保存的优化器权重，但不断遇到问题</title>
      <link>https://stackoverflow.com/questions/77889525/keras-trying-to-load-in-saved-optimizer-weights-that-are-in-the-form-of-an-arr</link>
      <description><![CDATA[我很久以前训练了一个模型，当时我无法使用任何内置的 keras 函数保存模型或优化器权重，因为它不断抛出错误，所以我将权重保存为数组。&lt; /p&gt;
现在我尝试再次加载它，但在加载优化器权重时我不断遇到错误。我 100% 确定我正确保存了权重，并且模型架构是正确的，因为我使用了
my_model.optimizer.get_weights()
保存权重（尽管该行代码现在不起作用，因为它说“&#39;Adam&#39;对象没有属性&#39;get_weights&#39;”），我基本上复制粘贴了模型架构。
所以首先，我尝试简单地加载优化器权重，就像使用
my_model.optimizer.set_weights(saved_optimizer_weights)
但我收到以下错误
“您正在对尚未构建的优化器调用“set_weights()”。请在调用“set_weights()”之前调用“optimizer.build(trainable_variables)”创建优化器权重。
我认为“trainable_variables”指的是my_model.trainable_variables，所以我跑了
my_model.optimizer.build(my_model.trainable_variables)
并且成功了。但当我尝试时
my_model.optimizer.set_weights(saved_optimizer_weights)
我再次收到以下错误
“优化器变量 v/top_conv/kernel_25469 的形状 (1, 1, 352, 1408) 与提供的权重形状 (1408,) 不兼容。”
我不太确定从这里该去哪里。]]></description>
      <guid>https://stackoverflow.com/questions/77889525/keras-trying-to-load-in-saved-optimizer-weights-that-are-in-the-form-of-an-arr</guid>
      <pubDate>Fri, 26 Jan 2024 23:53:24 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker实例中的CUDA路径解决NameError：名称'_C'未使用GroundingDINO定义</title>
      <link>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</link>
      <description><![CDATA[我正在尝试在 Sagemaker 实例（使用 GPU）中安装和使用 grounding dino ）但我收到错误：
NameError：名称“_C”未定义

我发现原因是因为变量CUDA_HOME没有配置，所以要解决这个问题我需要设置该变量，但在搜索答案后我找不到cuda在sagemaker实例中安装的路径。
cuda 安装在 sagemaker 实例中的什么位置以便我可以设置 CUDA_HOME？]]></description>
      <guid>https://stackoverflow.com/questions/77888418/cuda-path-in-sagemaker-instances-to-solve-nameerror-name-c-is-not-defined-wi</guid>
      <pubDate>Fri, 26 Jan 2024 18:45:06 GMT</pubDate>
    </item>
    <item>
      <title>TF-TRT 警告：无法 dlopen 某些 TensorRT 库</title>
      <link>https://stackoverflow.com/questions/77888210/tf-trt-warning-cannot-dlopen-some-tensorrt-libraries</link>
      <description><![CDATA[我一直在尝试在HPC集群上搭建虚拟环境，但是每次涉及到使用GPU的tensorflow时都碰壁。
模块加载 python3.8/3.8 eval “$(conda shell.bash hook)” conda 激活 graphgan
之后我使用以下命令来设置环境
conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1.0
当我尝试将tensorflow导入为tf时，它显示以下错误
2024-01-26 23:06:17.968937: I tensorflow/core/platform/cpu_feature_guard.cc:193] 此 TensorFlow 二进制文件使用 oneAPI 深度神经网络库（在 eDNN 上）进行了优化，以使用以下 CPU性能关键操作中的指令：AVX2 AVX512F FMA 要在其他操作中启用它们，请使用适当的编译器标志重建 TensorFlow。 2024-01-26 23:06:18.289070: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] 无法注册 cuBLAS 工厂：在已注册插件 cu BLAS 的情况下尝试注册工厂 2024-01-26 23 ：06：20.132284：Wtensorflow/stream_executor/platform/default/dso_lo ader.cc:64]无法加载动态库“libnvinfer.so.7”； dlerror: libnvinfe r.so.7: 无法打开共享对象文件: 没有这样的文件或目录； LD_LIBRARY_PATH：/opt/ohpc/pub/apps/anaconda3/envs/py38/lib:/home/vanshg.phy21.iitbhu/.conda/envs/graphgan/lib/2024-01-26 23:06:20.132710:W tensorflow/stream_executor/platform/default/dso_lo ader.cc:64] 无法加载动态库“libnvinfer_plugin.so.7”； dlerror: li bnvinfer_plugin.so.7: 无法打开共享对象文件: 没有这样的文件或目录； LD_LIBRARY_PATH：/opt/ohpc/pub/apps/anaconda3/envs/py38/lib:/home/vanshg.phy21。 iitbhu/.conda/envs/graphgan/lib/ 2024-01-26 23:06:20.132755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc: 38] TF-TRT 警告：无法 dlopen 某些 TensorRT 库。如果您想将 Nvidia GPU 与 TensorRT 一起使用，请确保正确安装了上面提到的缺少的库。
我知道这将毫无问题地运行我的代码，但我想使用 GPU 加速。谁能告诉我我应该做什么来解决这个问题
我预计 GPU 会被检测到，就像我在教程中看到的那样。相反，它开始抛出错误。我还检查了它提到的目录，确实文件丢失了。为了使其工作，我必须安装哪些额外的库？]]></description>
      <guid>https://stackoverflow.com/questions/77888210/tf-trt-warning-cannot-dlopen-some-tensorrt-libraries</guid>
      <pubDate>Fri, 26 Jan 2024 18:02:56 GMT</pubDate>
    </item>
    <item>
      <title>在哪里可以找到 ml_utils.model GPS？我看过一些论文引用了这些依赖项，但找不到带有 gp 的 ml_utils 包</title>
      <link>https://stackoverflow.com/questions/77887931/where-can-i-find-ml-utils-model-gps-ive-seen-a-few-papers-reference-these-depe</link>
      <description><![CDATA[ml_utils 包是否仍然与 .models.gp 一起存在？
我找不到它，但现在已经在 4 篇以上的论文中看到过它。
找到了 pandas ml_utils 文档 (https://github.com/KIC/pandas_ml_utils/blob/master/pandas_ml_utils/model/models.py），但在模型下没有看到任何 GP。有人可以帮我弄清楚这些论文是用什么做的吗？他们都只是说 from ml_utils.model import gp 并在依赖项下列出了 ml_utils 。]]></description>
      <guid>https://stackoverflow.com/questions/77887931/where-can-i-find-ml-utils-model-gps-ive-seen-a-few-papers-reference-these-depe</guid>
      <pubDate>Fri, 26 Jan 2024 17:11:19 GMT</pubDate>
    </item>
    <item>
      <title>将从 keras YOLOV8Detector 获取的模型更新到 Apple MLPackage/CoreML</title>
      <link>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</link>
      <description><![CDATA[我按照 KerasCV 上的教程使用 YOLOV8 和 KerasCV 进行高效目标检测，并在 不同的数据集
一段时间后，我能够获得预测并将其可视化，如教程中所述：
&lt; /p&gt;
我想在苹果 iOS 应用程序中使用这个模型，所以我使用了 coremltools 包来转换它。然而，“输出”似乎是这样的。 kerascv 制作的产品并不完全是苹果界所期望的。
模型训练完成后，我可以要求进行预测：
 图像，y_true = next(iter(dataset.take(1)))
 y_pred = model.predict(images) // y_pred 是一个字典

y_pred 是包含这些键的字典 [&#39;boxes&#39;, &#39;confidence&#39;, &#39;classes&#39;, &#39;num_detections&#39;]
使用Netron，我可以看看苹果世界所期待的模型的形状
&lt;img alt=&quot; “ src =“https://github.com/keras-team/keras-cv/assets/170917/5fae9594-694a-477c-a7a2-3c4419e3b98a”/&gt;
如何修改/重塑从 kerascv 生成的模型，这样我就可以拥有一个将置信度和坐标答案作为两个单独的输出输出的模型，而不是输出字典？]]></description>
      <guid>https://stackoverflow.com/questions/77886439/update-model-obtained-from-keras-yolov8detector-to-apple-mlpackage-coreml</guid>
      <pubDate>Fri, 26 Jan 2024 13:00:22 GMT</pubDate>
    </item>
    <item>
      <title>wasserstein GAN 中“没有为任何变量提供梯度”</title>
      <link>https://stackoverflow.com/questions/77870522/no-gradients-provided-for-any-variable-in-wasserstein-gan</link>
      <description><![CDATA[我一直在研究一个旨在输出微笑序列的 GAN 模型。在我的训练步骤中，我收到错误“值错误：没有为任何变量提供梯度”，我在生成器的可训练变量的 gan_model 中遇到了这个问题。我已经正确定义了损失和优化器以及鉴别器的梯度裁剪。
编辑
我已经使用 tf.op 函数（tf.reduce_mean）实现了我的损失函数，并检查了它是否可微。我仍然遇到没有为任何变量提供梯度的错误。我的生成器使用注意机制，并且我已经在我的级别检查了生成器中的任何函数是否不可微分或有任何不正确的输入。
wasserstein 损失函数返回合理的值并且输出形状似乎正确
这是我用于定义生成器和训练协议的相关代码。
损失函数
def wasserstein_loss(y_true, y_pred):
    损失 = tf.reduce_mean(y_true * y_pred)
    回波损耗


y_true = tf.constant([1.0, -1.0, 1.0], dtype=tf.float32)
y_pred = tf.constant([0.5, -0.5, 0.2], dtype=tf.float32)

使用 tf.GradientTape() 作为磁带：
    磁带.watch(y_pred)
    损失 = wasserstein_loss(y_true, y_pred)

梯度 = Tape.gradient(loss, y_pred)

print(&quot;损失：&quot;, loss.numpy())
print(&quot;渐变：&quot;,gradient.numpy())

发电机
def 生成器（latent_dim、num_ Protein_tokens、num_smiles_tokens、max_ Protein_seq_length、max_smiles_length）：

    init_hidden_​​state = 输入（形状=（max_smiles_length，），名称=&#39;s0&#39;）
    init_cell_state = 输入（形状=（max_smiles_length，），名称=&#39;c0&#39;）
    隐藏状态 = 初始化隐藏状态
    细胞状态 = 初始化细胞状态

    input_latent = 输入（形状=（max_smiles_length，latent_dim，），名称=&#39;input_latent&#39;）
    输入蛋白质=输入（形状=（max_蛋白质_seq_length，），名称=&#39;输入蛋白质&#39;）
    embedding_ Protein = 嵌入（num_ Protein_tokens，25，mask_zero = True，input_length = max_ Protein_seq_length）（input_ Protein）

    lstm_蛋白质=双向（LSTM（75，return_sequences = True））（嵌入_蛋白质）
    lstm_combined_outputs =[]
    对于范围内的 t（max_smiles_length）：
        上下文= one_step_attention（lstm_ Protein，hidden_​​state）
        lstm_combined，hidden_​​state，cell_state = post_activation_LSTM_cell（输入=上下文，initial_state = [hidden_​​state，cell_state]）
        lstm_combined_outputs.append(lstm_combined)


    lstm_combined_outputs = 连接（轴=1）（lstm_combined_outputs）
    concat_layer = 连接（轴=2）（[input_latent，lstm_combined_outputs]）
    generated_smiles_array = TimeDistributed(Dense(num_smiles_tokens,activation=&#39;softmax&#39;,name=&#39;output_smiles&#39;))(concat_layer)
    output_smiles = softargmax( generated_smiles_array, beta=1e10)

    生成器模型 = 模型（输入=[输入蛋白，init_hidden_​​state，init_cell_state，input_latent]，输出=output_smiles，名称=&#39;生成器&#39;）

    返回生成器模型

生成器模型 = 生成器（latent_dim、num_ Protein_tokens、num_smiles_tokens、max_ Protein_seq_length、max_smiles_length）
gen_optimizer = RMSprop(learning_rate=0.00005)
生成器模型.编译（损失= wasserstein_loss，优化器= gen_optimizer）

我非常感谢有关此问题的任何帮助，并很乐意分享任何可能相关的代码]]></description>
      <guid>https://stackoverflow.com/questions/77870522/no-gradients-provided-for-any-variable-in-wasserstein-gan</guid>
      <pubDate>Wed, 24 Jan 2024 04:01:23 GMT</pubDate>
    </item>
    <item>
      <title>在本地部署 Azure autoML 模型</title>
      <link>https://stackoverflow.com/questions/77859735/deploying-azure-automl-model-locally</link>
      <description><![CDATA[我已经使用 Azure AutoML 成功训练了一些有前途的模型，现在我想将它们部署在本地。
我使用简单的 CSV 文件作为数据集（使用 Azure ML v1 API）来训练模型。之后，我下载了模型并使用 Microsoft 在 Conda 中提供的评分脚本插入它：


# ---------------------------- ----------------------------
# 版权所有 (c) Microsoft Corporation。版权所有。
#------------------------------------------------- --------
导入 json
导入日志记录
导入操作系统
进口泡菜
将 numpy 导入为 np
将 pandas 导入为 pd
导入作业库

导入 azureml.automl.core
从 azureml.automl.core.shared 导入logging_utilities、log_server
从 azureml.telemetry 导入 INSTRUMENTATION_KEY

从 inference_schema.schema_decorators 导入 input_schema、output_schema
从 inference_schema.parameter_types.numpy_parameter_type 导入 NumpyParameterType
从 inference_schema.parameter_types.pandas_parameter_type 导入 PandasParameterType
从 inference_schema.parameter_types.standard_py_parameter_type 导入 StandardPythonParameterType

data_sample = PandasParameterType(pd.DataFrame({&quot;SIO2&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;AL2O3&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;B2O3&quot; : pd.Series([0.0], dtype=&quot;float32&quot;), &quot;CAO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;K2O&quot;: pd.Series([0.0], dtype=&quot; float32&quot;), &quot;NA2O&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;PBO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;Li2O&quot;: pd.Series( [0.0], dtype=&quot;float32&quot;), &quot;MgO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;SRO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot; BAO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;ZNO&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;P2O5&quot;: pd.Series([0.0], dtype =&quot;float32&quot;), &quot;ZRO2&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;TIO2&quot;: pd.Series([0.0], dtype=&quot;float32&quot;), &quot;Bi2O3&quot;: pd.系列([0.0], dtype=&quot;float32&quot;)}))
input_sample = StandardPythonParameterType({&#39;data&#39;: data_sample})

result_sample = NumpyParameterType(np.array([0.0]))
输出样本 = StandardPythonParameterType({&#39;结果&#39;:result_sample})
Sample_global_parameters = StandardPythonParameterType(1.0)

尝试：
    log_server.enable_telemetry(INSTRUMENTATION_KEY)
    log_server.set_verbosity(&#39;INFO&#39;)
    logger =logging.getLogger(&#39;azureml.automl.core.scoring_script_v2&#39;)
除了：
    经过


定义初始化（）：
    全球模式
    # 这个名称是我们要部署的模型的 model.id 将模型文件反序列化回来
    # 进入sklearn模型
    model_path = os.path.join(os.getenv(&#39;AZUREML_MODEL_DIR&#39;), &#39;model.pkl&#39;)
    路径 = os.path.normpath(model_path)
    path_split = path.split(os.sep)
    log_server.update_custom_dimensions({&#39;model_name&#39;: path_split[-3], &#39;model_version&#39;: path_split[-2]})
    尝试：
        logger.info(“从路径加载模型。”)
        模型 = joblib.load(model_path)
        logger.info(&quot;加载成功。&quot;)
    除了异常 e：
        logging_utilities.log_traceback（e，记录器）
        增加

@input_schema(&#39;输入&#39;, input_sample)
@input_schema（&#39;GlobalParameters&#39;，sample_global_parameters，convert_to_provided_type = False）
@output_schema（输出样本）
def run（输入，全局参数=1.0）：
    数据=输入[&#39;数据&#39;]
    结果=模型.预测(数据)
    返回 {&#39;Results&#39;:result.tolist()}



环境是使用.yml文件设置的，但我总是收到错误消息：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ModuleNotFoundError Traceback（最近一次调用最后一次）
单元格 In[1]，第 12 行
      9 将 pandas 导入为 pd
     10 导入作业库
---&gt; 12 导入 azureml.automl.core
     13 从 azureml.automl.core.shared 导入logging_utilities、log_server
     14 从 azureml.telemetry 导入 INSTRUMENTATION_KEY

ModuleNotFoundError：没有名为“azureml”的模块

但是，我不认为它与软件包有关。当我尝试通过 Azure 中的实时端点部署模型并使用“测试”测试它们时，成功执行后，我收到以下错误消息：
有趣的是，我在 VS 中没有收到此错误消息。相反，当在那里执行 run 函数时，我只收到以下错误消息：


要解析的输入数据类型无效。预期：但得到了 ;
斯塔佩鲁贝尔瓦赫：
 &gt;文件“C:\Users\weightedfinalmodel\scoring_file_v_2_0_0.py”，第 59 行，在  中（当前帧）
 &gt;运行（数据样本）
“inference_schema.schema_decorators”geladen
“__main__”凝胶
“奔跑的”凝胶
Das 程序“python.exe”wurde mit Code 4294967295 (0xffffffff) wasdet。



看起来已经好多了，但我似乎忽略了一些东西。]]></description>
      <guid>https://stackoverflow.com/questions/77859735/deploying-azure-automl-model-locally</guid>
      <pubDate>Mon, 22 Jan 2024 12:07:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 Pre-Train Bert 进行二元分类的 Shap 值：如何提取摘要图？</title>
      <link>https://stackoverflow.com/questions/77785423/shap-value-for-binary-classification-using-pre-train-bert-how-to-extract-summar</link>
      <description><![CDATA[我使用预训练 bert 模型进行二元分类。用小数据训练我的模型后，我想提取这样的摘要图 我想要的图&lt; /a&gt;.然而，我想用文字来代替这些重要的特征。
但是，我不确定一切都好，因为 shap_value 的形状只是二维的。其实，这是有道理的。尽管如此，我没有得到图表，因为如果我使用这段代码，我遇到了两个问题：
shap.summary_plot(shap_values[:,:10],feature_names=feature_importance[&#39;features&#39;].tolist(),features=comments_text)`

问题太不明智了：如果我用 shap_values 或 shap_values[0] 或  更改 shap_values[:,:10] shap_values.values vb.我总是遇到
516：断言 len(shap_values.shape) != 1，“汇总图需要一个矩阵
shap_values，而不是向量。” ==&gt; AssertionError：摘要图需要一个矩阵
shap_values，不是向量。

（拳头问题）
顺便说一句，我的 shap_value 由 10 个输入（shape_value.shape）组成。如果我选择范围从 1 到 147 的最大值，那么绘制图表就一切顺利。然而，此时，该图不合适：我的图仅由蓝点组成（-第二个问题-）。像这样只有蓝色。
注意：shap_values[:,:10]如果数字（10）改变不同的数字，图表显示不同的单词，但图表的总数相同（最多 20）。只有部分词序可以改变。
最小可重现示例：
&lt;前&gt;&lt;代码&gt;导入nlp
将 numpy 导入为 np
将 pandas 导入为 pd
将 scipy 导入为 sp
进口火炬
进口变压器
进口火炬
导入形状

# 加载 BERT 情感分析模型
tokenizer = Transformers.DistilBertTokenizerFast.from_pretrained(
    “distilbert-base-uncased”
）
模型 = Transformers.DistilBertForSequenceClassification.from_pretrained(
    “distilbert-base-uncased-finetuned-sst-2-english”
).cuda()


如果 torch.cuda.is_available():
    设备 = torch.device(“cuda”)
    print(&#39;我们将使用 GPU:&#39;, torch.cuda.get_device_name(0))

别的：
    print(&#39;没有可用的 GPU，请使用 CPU。&#39;)
    设备 = torch.device(“CPU”)

定义 f(x):
    # 对批量句子进行编码
    输入 = tokenizer.batch_encode_plus(x.tolist(), max_length=450,add_special_tokens=True, return_attention_mask=True,padding=&#39;max_length&#39;,truncation=True,return_tensors=&#39;pt&#39;)

    # 将张量发送到与模型相同的设备
    input_ids = 输入[&#39;input_ids&#39;].to(设备)
    注意掩码 = 输入[&#39;注意掩码&#39;].to(设备)
    ＃ 预测
    使用 torch.no_grad()：
        输出=模型（input_ids，attention_mask=attention_masks）[0].detach（）.cpu（）.numpy（）
    分数 = (np.exp(输出).T / np.exp(输出).sum(-1)).T
    val = sp.special.logit(scores[:, 1]) # 使用 1 与其余 logit 单位
    返回值
# 使用 token masker 构建一个解释器
解释器 = shap.Explainer(f, tokenizer )

imdb_train = nlp.load_dataset(“imdb”)[“火车”]
shap_values = 解释器(imdb_train[:10],fixed_context=1,batch_size=16)
队列 = {“”：shap_values}
team_labels = 列表(cohorts.keys())
team_exps = 列表(cohorts.values())
对于范围内的 i(len(cohort_exps))：
    如果 len(cohort_exps[i].shape) == 2:
        队列_exps[i] = 队列_exps[i].abs.mean(0)
特征=cohort_exps[0].data
特征名称=同类群组表达式[0].特征名称
#values = np.array([cohort_exps[i].values for i in range(len(cohort_exps))], dtype=object)
值 = np.array([cohort_exps[i].i 在范围内的值(len(cohort_exps))])
feature_importance = pd.DataFrame(list(zip(feature_names, sum(values))), columns=[&#39;features&#39;, &#39;importance&#39;])
feature_importance.sort_values(by=[&#39;重要性&#39;], 升序=False, inplace=True)
shap.summary_plot(shap_values[:,:10],feature_names=feature_importance[&#39;features&#39;].tolist(),features=imdb_train[&#39;text&#39;][10:20],show=False)


上面的代码产生相同的结果。我花了大约200台电脑，但没有成功:(。我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/77785423/shap-value-for-binary-classification-using-pre-train-bert-how-to-extract-summar</guid>
      <pubDate>Tue, 09 Jan 2024 08:49:10 GMT</pubDate>
    </item>
    </channel>
</rss>