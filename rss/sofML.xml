<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 07 Feb 2024 12:23:28 GMT</lastBuildDate>
    <item>
      <title>如何管理数据集中的字符串参数</title>
      <link>https://stackoverflow.com/questions/77954287/how-to-manage-string-parameters-in-the-dataset</link>
      <description><![CDATA[我是该领域的新手，我正在做一些测试来学习机器学习技术。
我特别想创建一个小模型来预测网球比赛。 数据集如下（大约 500 行）。用作目标的列是“获胜者”。栏目
我正在尝试决策树。我正在使用 python 的 sklearn 库。由于树需要数字参数才能通过 LabelEncoder 运行，因此我转换了不包含字符串的列（我还小心地确保“获胜者”和“获胜者”中的玩家名称相同）。失败者”列被转换为相同的方式）。
此时我有一个疑问。这几乎是“随机”的吗？转换会影响模型的预测精度吗？例如，我想象，如果某个强玩家被赋予很高的价值，而同样的事情发生在一个差的玩家身上，那么模型可能会做出错误的预测……？
我想知道我的怀疑是否合理，如果合理，有没有办法防止这种情况发生？或者在任何情况下一般要维持各种数据之间的合理关系。]]></description>
      <guid>https://stackoverflow.com/questions/77954287/how-to-manage-string-parameters-in-the-dataset</guid>
      <pubDate>Wed, 07 Feb 2024 11:18:31 GMT</pubDate>
    </item>
    <item>
      <title>如何使用Meta Deep Cluster模型？</title>
      <link>https://stackoverflow.com/questions/77954005/how-to-use-meta-deep-cluster-model</link>
      <description><![CDATA[我正在开展一个关于图像分割的机器学习项目。
我发现 Meta 的一些模型可以从图像中学习视觉特征，例如 https://github.com/facebookresearch /deepcluster，这个：https://github.com/facebookresearch/dinov2 或这个： https://github.com/facebookresearch/swav/tree/main .
我尝试使用这个模型，但我不明白如何将它与我的图像数据集一起使用（不是他们提供的图像）。
有类似的指南或类似的东西吗？]]></description>
      <guid>https://stackoverflow.com/questions/77954005/how-to-use-meta-deep-cluster-model</guid>
      <pubDate>Wed, 07 Feb 2024 10:38:07 GMT</pubDate>
    </item>
    <item>
      <title>机器学习Python：预测看不见的输入以获得最佳输出（任何算法都可以）</title>
      <link>https://stackoverflow.com/questions/77953955/machine-learning-python-predict-unseen-inputs-for-optimum-output-any-algorith</link>
      <description><![CDATA[我用随机森林算法（你可以使用任何算法）编写了一个机器学习模型，并用我的数据集成功地训练了它，它准确地预测了我的测试集的输出（y）输入 (x)。到这里为止它工作正常。现在我想添加一个部分，它还可以预测新的 x 的 ungiven 值，它认为 y 将是最大值。所以我希望它基本上针对任何 x 值优化 y，而不需要给它输入 x。
如果需要的话，这是我的代码：（其中没有关于我想添加的部分，它只是训练和测试）：
&lt;前&gt;&lt;代码&gt;

将 numpy 导入为 np
将 pandas 导入为 pd
从 sklearn.metrics 导入 r2_score
将 matplotlib.pyplot 导入为 plt
从 sklearn.preprocessing 导入 StandardScaler
从 sklearn.ensemble 导入 RandomForestRegressor


excel_file_path = r&#39;文件位置&#39;
df = pd.read_excel(excel_file_path)
df.columns=[&#39;Chordwise_Portion&#39;,&#39;变形&#39;,&#39;TSR&#39;,&#39;CP/CP_baseline&#39;]
df[&#39;CP/CP_baseline&#39;] = pd.to_numeric(df[&#39;CP/CP_baseline&#39;], 错误=&#39;强制&#39;)

训练集 = df.iloc[0:350, 0:4]
test_set = df.iloc[350:649, 0:4]


defscale_dataset（数据框）：
  X = dataframe[dataframe.columns[:-1]].values
  y = dataframe[dataframe.columns[-1]].values
  定标器=标准定标器()
  X = 缩放器.fit_transform(X)
  数据 = np.hstack((X, np.reshape(y, (-1, 1))))
  返回数据，X，y

训练，X_train，y_train =scale_dataset（训练集）
测试，X_测试，y_测试=scale_dataset（测试集）


#射频
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_test)


# 计算 R 平方
r2 = r2_score(y_test, y_pred)
r2 = r2*100
打印（）
print(f&#39;R平方: {r2} %&#39;)
打印（）


#最优预测
最大训练=最大（y_训练）
index_max_train = np.where(y_train == np.max(y_train)) ###
max_pred = max(y_pred)
index_max_pred = [np.where(y_pred == max_pred)[0][0]+350]
data_pred = df.iloc[index_max_pred,0:3] ###

######
max_value = max(max_train, max_pred)
如果 max_value == max_train：
  max_data = df.iloc[index_max_train]
别的：
  最大数据 = 数据预测

print(&quot;Cp/Cp_baseline 的最大总体值为：&quot;, max_value,&quot; 对于以下条件：&quot;)
打印（最大数据）
打印（）
print(&quot;Cp/Cp_baseline 的最大预测值为：&quot;, max_pred,&quot; 对于以下条件：&quot;)
打印（数据预测）

# 绘制结果
plt.scatter(X_test[:, 0], y_test, label=&#39;真实数据&#39;)
plt.scatter(X_test[:,0], y_pred, color=&#39;r&#39;, label=&#39;预测数据&#39;)
plt.xlabel(&#39;Chordwise_portion&#39;)
plt.ylabel(&#39;Cp/Cp_baseline&#39;)
title = &quot;随机森林算法 - R^2 = {:.4f} %&quot;.format(r2)

plt.标题（标题）
plt.图例()
plt.show()

]]></description>
      <guid>https://stackoverflow.com/questions/77953955/machine-learning-python-predict-unseen-inputs-for-optimum-output-any-algorith</guid>
      <pubDate>Wed, 07 Feb 2024 10:30:18 GMT</pubDate>
    </item>
    <item>
      <title>seq2seq 仅生成 pad token（NLP、PyTorch）</title>
      <link>https://stackoverflow.com/questions/77953536/seq2seq-generate-only-pad-tokens-nlp-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77953536/seq2seq-generate-only-pad-tokens-nlp-pytorch</guid>
      <pubDate>Wed, 07 Feb 2024 09:24:02 GMT</pubDate>
    </item>
    <item>
      <title>重识别网络训练和验证</title>
      <link>https://stackoverflow.com/questions/77953442/re-identification-network-training-and-validation</link>
      <description><![CDATA[我正在为 VisDrone 执行对象跟踪任务，并且为此目的使用 DeepSORT  。但是这个存储库中的嵌入者在与 VisDrone 数据集非常不同的数据集上进行了预训练。
我想在 VisDrone 上训练 mobilenetv2 作为 ReID 的嵌入网络。据我了解，如果只有 1 个摄像头，我的训练数据集必须包含一组{图像（对象的），标签（该对象的 ID）}。因此，如果以交叉熵损失的方式进行训练，网络将学习对象的 ID。但是，如果我尝试使用 ID 不同的其他对象来验证它，网络将不会预测验证数据集中的 ID。相反，它会预测他们的 ID。训练数据集和验证损失会很高。
我的第一个问题：我关于网络学习对象ID的想法是否正确？因为到处都写着 embedeer 返回对象的特征向量，其长度可能会有所不同，而不考虑 ID 的总数。
我的第二个问题：如何正确验证我的 ReID 网络？
如果有人向我解释为什么学习对象的 ID，然后在另一个数据集上使用这个网络通常是有效的，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77953442/re-identification-network-training-and-validation</guid>
      <pubDate>Wed, 07 Feb 2024 09:10:08 GMT</pubDate>
    </item>
    <item>
      <title>训练图不可散列类型：'numpy.ndarray'</title>
      <link>https://stackoverflow.com/questions/77953227/train-plot-unhashable-type-numpy-ndarray</link>
      <description><![CDATA[我正在尝试进行时间序列预测，通过训练模型使用以前的班级记录来预测未来日期中班级发生的次数，现在我正处于测试数据的阶段，但我有一个错误在运行此代码时，我还添加了完整的错误代码
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-19-2a33e5b15fbb&gt;在&lt;细胞系：4&gt;()
      2 测试 = out[out.index &gt; pd.to_datetime(&quot;2020-11-01&quot;, format=&#39;%Y-%m-%d&#39;)]
      3
----&gt; 4 plt.plot（火车，颜色=“黑色”）
      5 plt.plot（测试，颜色=“红色”）
      6 plt.ylabel(&#39;患者数量&#39;)

7帧
/usr/local/lib/python3.10/dist-packages/matplotlib/category.py 中的 update(self, data)
    第212章
    213 可兑换 = 真
--&gt; [第 214 章]
    215 # OrderedDict 只是迭代数据中的唯一值。
    216 _api.check_isinstance((str, 字节), 值=val)

类型错误：不可散列的类型：&#39;numpy.ndarray&#39;

我从此博客获取的代码
从 google.colab 导入驱动器
drive.mount(&#39;/content/gdrive&#39;,force_remount = True)

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入mean_squared_error
将 matplotlib.pyplot 导入为 plt

data = pd.read_csv(&#39;gdrive/My Drive/Colab_Notebooks/classproject/classdata.csv&#39;, parse_dates=[&#39;time_date&#39;], index_col=&#39;time_date&#39;)
类id = 数据[&#39;类id&#39;]
时间日期 = 数据.索引.日期
数据[&#39;日期&#39;] = data.index.日期

类id = 数据[&#39;类id&#39;]
time_date = data.index.to_series()
m1 = class_id.ne(class_id.shift())
m2 = time_date.dt.date.ne(time_date.dt.date.shift())
data[&#39;count&#39;] = data.groupby((m1 | m2).cumsum()).cumcount().add(1).values

out = data[data.groupby(data.index.date).transform(&#39;size&#39;).gt(1)]

!pip 安装 pandas-datareader

将 pandas_datareader.data 作为 web 导入
导入日期时间

将 pandas 导入为 pd
pd.set_option(&#39;display.max_columns&#39;, None)
pd.set_option(&#39;display.max_rows&#39;, None)

将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns

sns.set()

plt.ylabel(&#39;类别数量&#39;)
plt.xlabel(&#39;日期&#39;)
plt.xticks（旋转=45）

out.index = pd.to_datetime(out[&#39;date&#39;], format=&#39;%Y-%m-%d&#39;)
out.groupby(&#39;doctor_id&#39;).plot()
plt.plot(out.index, out[&#39;count&#39;], )

火车 = out[out.index &lt; pd.to_datetime(&quot;2020-11-01&quot;, format=&#39;%Y-%m-%d&#39;)]
测试 = out[out.index &gt; pd.to_datetime(&quot;2020-11-01&quot;, format=&#39;%Y-%m-%d&#39;)]


&lt;前&gt;&lt;代码&gt;
plt.plot（火车，颜色=“黑色”）
plt.plot（测试，颜色=“红色”）
plt.ylabel(&#39;类数&#39;)
plt.xlabel(&#39;日期&#39;)
plt.xticks（旋转=45）
plt.title(“类数据的训练/测试分割”)
plt.show()

我的输入数据是这样的：
时间戳/class_id
2021-09-27 06:00:00 / A
2021-09-27 03:00:00 / A
2021-09-27 01:00:00 / A
2021-09-27 08:29:00 / C
2021-05-23 08:08:49 / B
2021-05-23 03:21:49 / B
2021-05-23 01:22:11 / C

处理它并添加计数和日期列后：
计数/时间戳/class_id/日期
1 / 2021-09-27 06:00:00 / A / 2021-09-27
2 / 2021-09-27 03:00:00 / A / 2021-09-27
3 / 2021-09-27 01:00:00 / A / 2021-09-27
1 / 2021-09-27 08:29:00 / C / 2021-09-27
1 / 2021-05-23 08:08:49 / B / 2021-05-23
2 / 2021-05-23 03:21:49 / B / 2021-05-23
1 / 2021-05-23 01:22:11 / C / 2021-05-23
]]></description>
      <guid>https://stackoverflow.com/questions/77953227/train-plot-unhashable-type-numpy-ndarray</guid>
      <pubDate>Wed, 07 Feb 2024 08:27:05 GMT</pubDate>
    </item>
    <item>
      <title>如何提取音频文件的一个嵌入？</title>
      <link>https://stackoverflow.com/questions/77952851/how-to-extract-one-embedding-for-audiofile</link>
      <description><![CDATA[我想从视频中提取音频组件的嵌入，以便进一步将它们合并到推荐系统中。
在此之前，我使用 XClip 提取视频的嵌入。我每个视频都有一个嵌入。嵌入的大小为 512。
如何才能获得相同的音频结果（每个音频一个嵌入）？
我想使用 Vggish。但这个模型与其他模型一样，提供了类似 [N_sequence, EmbSize] 的输出。例如。 [62, 128]。
我试图获取每个视频嵌入的平均值，但它产生了非常复杂的嵌入。许多完全不同的视频具有非常相似的音频嵌入（通过点积或余弦相似度）。]]></description>
      <guid>https://stackoverflow.com/questions/77952851/how-to-extract-one-embedding-for-audiofile</guid>
      <pubDate>Wed, 07 Feb 2024 07:15:50 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：值的长度（####）与索引的长度（####）不匹配[重复]</title>
      <link>https://stackoverflow.com/questions/77952546/valueerror-length-of-values-does-not-match-length-of-index</link>
      <description><![CDATA[我必须添加一列，其中包含特定行的特定值。所以我将 df 分成 3 并尝试添加值。
当添加到第二个 split df 时，我想出了
&lt;块引用&gt;
ValueError：值的长度 (4744) 与索引的长度 (1897) 不匹配

即使在 .reset_index(drop=True) 之后，它仍然显示相同的错误。
random_values = np.random.randint(10,25, size=len1)
# 将随机值分配给特定列
列名 = &#39;公交车站距离&#39;
split1[列名] = 随机值

random_values = np.random.randint(5,15, size=len2)
# 将随机值分配给特定列
split2.reset_index(drop=True)
列名 = &#39;公交车站距离&#39;
split2[列名] = 随机值

random_values = np.random.randint(0,6, size=len3)
# 将随机值分配给特定列
列名 = &#39;公交车站距离&#39;
split2[列名] = 随机值

这里，
&lt;前&gt;&lt;代码&gt;len1=len(split1)
len2=len(分割2)
len3=len(分割3)

我希望它添加与第一个拆分 (split1) 类似的值。即使删除索引后，它也是一样的。
我将 len2 作为 len(split2)。所以我想它应该有效。但仍然不是。]]></description>
      <guid>https://stackoverflow.com/questions/77952546/valueerror-length-of-values-does-not-match-length-of-index</guid>
      <pubDate>Wed, 07 Feb 2024 06:08:38 GMT</pubDate>
    </item>
    <item>
      <title>当我的特征变量大部分为零时我该怎么办？</title>
      <link>https://stackoverflow.com/questions/77952098/what-should-i-do-when-my-feature-variables-are-mostly-zero</link>
      <description><![CDATA[我有一组商店销售数据，我想使用外部 POI 特征及其人口统计因素来预测其他商店的销售情况。然而，我的特征变量几乎 80% 为零，其余 20% 有不同的范围。导致所有特征都高度倾斜。
我得到了一个较低的 r 平方值，我已经尝试过随机森林、XGBOOST 以及 cat boost 回归。]]></description>
      <guid>https://stackoverflow.com/questions/77952098/what-should-i-do-when-my-feature-variables-are-mostly-zero</guid>
      <pubDate>Wed, 07 Feb 2024 03:42:49 GMT</pubDate>
    </item>
    <item>
      <title>二值图像分割训练期间类别概率下降</title>
      <link>https://stackoverflow.com/questions/77951083/class-probability-decreasing-during-binary-image-segmentation-training</link>
      <description><![CDATA[我正在训练一个用于裂纹检测的二值图像分割模型，其中裂纹是少数类，使用 Keras 中的标准 UNet 架构。对于损失函数，我使用 Focal Loss，其 alpha 为 0.8，gamma 为 2，因为我读到它在处理不平衡数据时很有用。
在训练期间，训练和验证损失会大幅下降。尽管如此，我还是有一个回调来预测一些样本测试图像，并注意到裂纹类别概率随着时间的推移而降低。最终，预测掩模完全被背景类覆盖。我不确定这里发生了什么，因为我认为焦点损失可以解决这个问题。我也尝试过使用 Dice Loss 来避免调整参数，但看到了类似的行为。
我有什么遗漏的吗？我的标签为 0 表示背景，1 表示裂纹，并且我在最终模型层中使用 sigmoid 函数，以及在卷积块中使用增强层（翻转/随机变换）和 Dropout。]]></description>
      <guid>https://stackoverflow.com/questions/77951083/class-probability-decreasing-during-binary-image-segmentation-training</guid>
      <pubDate>Tue, 06 Feb 2024 21:59:52 GMT</pubDate>
    </item>
    <item>
      <title>keras.LSTM 如何将 3D 输入转换为 2D 输出？</title>
      <link>https://stackoverflow.com/questions/77946209/how-keras-lstm-converts-3d-input-to-2d-output</link>
      <description><![CDATA[根据 keras 的 LSTM 文档，输入应该是具有形状（批量、时间步长、特征）的 3D 张量
输出将为（批次，单位），其中单位是我们想要从 LSTM 单元获得的数字特征。
据我所知，lstm 的单个单元格将隐藏状态、单元格状态和单个数字作为时间戳 t 的输入，并将其输出以 c(t+1) 和 h(t+1) 的形式传递到下一个单元格。但从文档代码来看，它正在生成 2D 形式的输出？
输入 = np.random.random((32, 10, 8))
lstm = keras.layers.LSTM(4)
输出 = lstm(输入)
输出形状
(32, 4)

问题 1：向量表示如何传递给 LSTM？ （在每个时间戳处，它传递 8 个特征。如果有 8 个 lstm 单元并行运行，则输出大小也应为 8）
问题2：最终输出的大小如何为4。（如果我们忽略批量大小）]]></description>
      <guid>https://stackoverflow.com/questions/77946209/how-keras-lstm-converts-3d-input-to-2d-output</guid>
      <pubDate>Tue, 06 Feb 2024 08:25:41 GMT</pubDate>
    </item>
    <item>
      <title>预处理新数据以从 PyCaret 中的现有模型进行预测[关闭]</title>
      <link>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77938501/preprocessing-new-data-for-predictions-from-an-existing-model-in-pycaret</guid>
      <pubDate>Mon, 05 Feb 2024 03:32:23 GMT</pubDate>
    </item>
    <item>
      <title>不知道如何在此机器学习程序中进行用户输入[关闭]</title>
      <link>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</link>
      <description><![CDATA[导入 pandas 作为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.ensemble 导入 RandomForestRegressor
从 sklearn.metrics 导入 r2_score、mean_squared_error

# 加载数据集
dp = pd.read_csv(&#39;https://raw.githubusercontent.com/dataprofessor/data/master/delaney_solubility_with_descriptors.csv&#39;)

# 分离特征（x）和目标变量（y）
y = dp[&#39;logS&#39;]
x = dp.drop(&#39;logS&#39;, 轴=1)

# 分割数据
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)

# 线性回归模型
lr = 线性回归()
lr.fit(x_train, y_train)
y_train_pred_lr = lr.predict(x_train)
y_test_pred_lr = lr.predict(x_test)

# 随机森林回归模型
k1 = RandomForestRegressor（最大深度=2，随机状态=100）
k1.fit(x_train, y_train)
y_train_pred_rf = k1.predict(x_train)
y_test_pred_rf = k1.predict(x_test)

# 评估线性回归模型
y_train_mse_lr =mean_squared_error(y_train, y_train_pred_lr)
y_train_r2_lr = r2_score(y_train, y_train_pred_lr)
y_test_mse_lr = 均方误差(y_test, y_test_pred_lr)
y_test_r2_lr = r2_score(y_test, y_test_pred_lr)

# 评估随机森林回归模型
y_train_mse_rf =mean_squared_error(y_train, y_train_pred_rf)
y_train_r2_rf = r2_score(y_train, y_train_pred_rf)
y_test_mse_rf =mean_squared_error(y_test, y_test_pred_rf)
y_test_r2_rf = r2_score(y_test, y_test_pred_rf)

# 创建数据框
rs_lr = pd.DataFrame({“方法”: [“线性回归”],
                      “训练MSE”：[y_train_mse_lr]，
                      “训练R2”：[y_train_r2_lr]，
                      “测试 MSE”：[y_test_mse_lr]，
                      “测试 R2”：[y_test_r2_lr]})

rs_rf = pd.DataFrame({“方法”: [“随机森林回归器”],
                      “训练MSE”：[y_train_mse_rf]，
                      “训练R2”：[y_train_r2_rf]，
                      “测试 MSE”：[y_test_mse_rf]，
                      “测试 R2”：[y_test_r2_rf]})

# 连接数据帧
结局 = pd.concat([rs_lr, rs_rf],ignore_index=True)
打印（结局）

加载数据集：它使用 Pandas 从 URL 加载数据集。该数据集与分子溶解度相关，包含各种分子描述符。
数据准备：它将特征（x）和目标变量（y）从数据集中分离出来。本例中的目标变量是溶解度的对数 (logS)。
数据拆分：它使用 scikit-learn 中的 train_test_split 函数将数据集拆分为训练集和测试集。训练集用于训练模型，测试集用于评估模型的性能。
模型训练：它使用训练数据训练两个回归模型 - 线性回归模型 (lr) 和随机森林回归模型 (k1)。
预测：它使用经过训练的模型对训练集和测试集进行预测。
模型评估：它使用均方误差 (MSE) 和 R 平方 (R2) 分数评估两个模型的性能。这些指标可以深入了解模型对数据的拟合程度。
创建 DataFrame：它创建两个单独的 DataFrame（rs_lr 和 rs_rf）来存储每个模型的评估指标。
串联：它将两个 DataFrame 连接成一个最终的 DataFrame（结局）。此 DataFrame 总结了两种模型的训练和测试性能。
打印结果：最后，它打印串联的 DataFrame（结局），其中包括线性回归和随机森林回归模型的方法名称、训练 MSE、训练 R2、测试 MSE 和测试 R2。
该程序的目标是比较线性回归和随机森林回归模型在根据描述符预测分子溶解度方面的性能。
我希望用户输入值。那么我该如何修改代码呢？]]></description>
      <guid>https://stackoverflow.com/questions/77937096/dont-know-how-to-do-user-input-in-this-ml-program</guid>
      <pubDate>Sun, 04 Feb 2024 18:32:58 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Roberta 计算最后 4 个隐藏层的加权和？</title>
      <link>https://stackoverflow.com/questions/77933640/how-to-calculate-the-weighted-sum-of-last-4-hidden-layers-using-roberta</link>
      <description><![CDATA[这篇论文中的表格解释了获得嵌入的各种方法，我认为这些方法也适用于 Roberta：

我正在尝试使用 Roberta 计算最后 4 个隐藏层的加权和来获得令牌嵌入，但我不知道这是否是正确的方法，这是我尝试过的代码：
从变压器导入 RobertaTokenizer, RobertaModel
进口火炬

tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;)
模型 = RobertaModel.from_pretrained(&#39;roberta-base&#39;)
Caption = [&#39;这是一只黄色的鸟&#39;, &#39;示例标题&#39;]

tokens = tokenizer(标题, return_tensors=&#39;pt&#39;, padding=True)

input_ids = 标记[&#39;input_ids&#39;]
注意掩码 = 标记[&#39;注意掩码&#39;]

输出=模型（input_ids，attention_mask，output_hidden_​​states = True）

状态 = 输出.hidden_​​states
token_emb = torch.stack([states[i] for i in [-4, -3, -2, -1]]).sum(0).squeeze()
]]></description>
      <guid>https://stackoverflow.com/questions/77933640/how-to-calculate-the-weighted-sum-of-last-4-hidden-layers-using-roberta</guid>
      <pubDate>Sat, 03 Feb 2024 20:34:36 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的决策树创建的分割实际上并未划分样本？</title>
      <link>https://stackoverflow.com/questions/50077562/why-is-my-decision-tree-creating-a-split-that-doesnt-actually-divide-the-sample</link>
      <description><![CDATA[这是我对著名的 Iris 数据集进行二特征分类的基本代码： 
from sklearn.datasets import load_iris
从 sklearn.tree 导入 DecisionTreeClassifier，export_graphviz
从 graphviz 导入源

虹膜 = load_iris()
iris_limited = iris.data[:, [2, 3]] # 这仅获取花瓣长度 &amp;宽度。

# 我使用最大深度来避免过度拟合
# 并简化树，因为我将其用于教育目的
clf = DecisionTreeClassifier(criterion=&quot;基尼&quot;,
                             最大深度=3，
                             随机状态=42）

clf.fit(iris_limited, iris.target)

Visualization_raw = Export_graphviz(clf,
                                    out_file=无，
                                    特殊字符=真，
                                    feature_names=[“长度”,“宽度”],
                                    类名=iris.target_names,
                                    节点 ID=真）

可视化源 = 源（可视化_原始）
Visualization_png_bytes = Visualization_source.pipe(format=&#39;png&#39;)
将 open(&#39;my_file.png&#39;, &#39;wb&#39;) 作为 f：
    f.write（可视化_png_bytes）

当我检查树的可视化时，我发现了这一点：

乍一看这是一棵相当正常的树，但我注意到它有一些奇怪的地方。节点 #6 共有 46 个样本，其中只有一个是杂色的，因此该节点被标记为 virginica。这似乎是一个相当合理的停留地点。然而，由于某种我无法理解的原因，该算法决定进一步分为节点#7 和#8。但奇怪的是，仍然存在的 1 个 versicolor 仍然被错误分类，因为无论如何两个节点最终都具有 virginica 类。它为什么要这样做？它是否盲目地只关注基尼系数的下降，而不考虑它是否有任何影响——这对我来说似乎是奇怪的行为，而且我在任何地方都找不到它的记录。
是否可以禁用，或者这实际上是正确的吗？]]></description>
      <guid>https://stackoverflow.com/questions/50077562/why-is-my-decision-tree-creating-a-split-that-doesnt-actually-divide-the-sample</guid>
      <pubDate>Sat, 28 Apr 2018 14:25:02 GMT</pubDate>
    </item>
    </channel>
</rss>