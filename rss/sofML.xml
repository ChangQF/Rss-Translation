<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sun, 10 Nov 2024 15:15:52 GMT</lastBuildDate>
    <item>
      <title>训练 XGBoost 模型时超参数显示为“无”</title>
      <link>https://stackoverflow.com/questions/79174302/hyperparameters-show-as-none-when-training-xgboost-model</link>
      <description><![CDATA[我正在尝试拟合 XGBoost 回归模型。一旦我训练它，所有超参数都会报告为“无”。
{&#39;objective&#39;: &#39;reg:squarederror&#39;,
&#39;base_score&#39;: None,
&#39;booster&#39;: None,
&#39;colsample_bylevel&#39;: None,
&#39;colsample_bynode&#39;: None,
&#39;colsample_bytree&#39;: None,
&#39;device&#39;: None,
&#39;eval_metric&#39;: None,
&#39;gamma&#39;: None,
&#39;grow_policy&#39;: None,
&#39;interaction_constraints&#39;: None,
&#39;learning_rate&#39;: None,
&#39;max_bin&#39;: None,
&#39;max_cat_threshold&#39;: None,
&#39;max_cat_to_onehot&#39;: None,
&#39;max_delta_step&#39;: None,
&#39;max_depth&#39;: None,
&#39;max_leaves&#39;: None,
&#39;min_child_weight&#39;: None,
&#39;monotone_constraints&#39;: None,
&#39;multi_strategy&#39;: None,
&#39;n_jobs&#39;: None,
&#39;num_parallel_tree&#39;: None,
&#39;random_state&#39;: None,
&#39;reg_alpha&#39;: None,
...
&#39;scale_pos_weight&#39;: None,
&#39;subsample&#39;: None,
&#39;tree_method&#39;: None,
&#39;validate_parameters&#39;: None,
&#39;verbosity&#39;: None}

当我运行 xgb.plot_importance(model, ax=plt.gca()) 时，考虑到数据，它给出了一个看似合理的列表。这让我认为进行了一些成功的训练，但为什么所有超参数都报告为 None？]]></description>
      <guid>https://stackoverflow.com/questions/79174302/hyperparameters-show-as-none-when-training-xgboost-model</guid>
      <pubDate>Sun, 10 Nov 2024 06:53:04 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 模型权重无法正确加载</title>
      <link>https://stackoverflow.com/questions/79173992/tensorflow-model-weights-not-loading-correctly</link>
      <description><![CDATA[我正在尝试用 C++ 为国际象棋引擎加载一个 TensorFlow 神经网络。该模型是在 Python 中训练的，我正在将权重转换为二进制文件，但在 C++ 中加载时尺寸错误。
Python 模型架构：

输入：768 个神经元（扁平的 8x8x12 棋盘状态）
隐藏层：1024 -&gt; 512 -&gt; 256 -&gt; 128 -&gt; 64
输出：1 个神经元（tanh 激活）

在 c++ 中加载时，我得到维度不匹配：
输入大小：768
层数：6
处理层 0
输入大小：1024 # 应为 768
输出大小：768 # 应为 1024

这是我的 python 转换代码：
def convert_model_to_binary(model_path, output_path):
# 加载 TensorFlow 模型
chess_nn = pickle.load(open(model_path, &quot;rb&quot;))
model = chess_nn.model

with open(output_path, &quot;wb&quot;) as f:
# 写入密集层的数量
dense_layers = [
layer
for layer in model.layers
if isinstance(layer, tf.keras.layers.Dense)
]
np.array([len(dense_layers)], dtype=np.int32).tofile(f)

for layer in density_layers:
weights,biases = layer.get_weights()

# 转换为 float32 以实现 c++ 兼容性
weights = weights.astype(
np.float32
)# 无需转置（权重已经处于正确的形状）
biases = biases.astype(np.float32)

# 写入输入和输出维度
input_dim = weights.shape[0]# 行数（输入维度）
output_dim = weights.shape[
1
]# 列数（输出维度）

np.array([input_dim, output_dim], dtype=np.int32).tofile(f)
np.array([output_dim], dtype=np.int32).tofile(f) # 偏置形状

weights.tofile(f)
biases.tofile(f)

和 c++ 加载代码：
bool load_model(const std::string &amp;filename)
{
std::ifstream file(filename, std::ios::binary);
int32_t num_layers;
file.read(reinterpret_cast&lt;char&gt;(&amp;num_layers), sizeof(int32_t));
la​​yer.resize(num_layers);
对于 (int i = 0; i &lt; num_layers; i++)
{
int32_t weight_shape[2];
file.read(reinterpret_cast&lt;char&gt;(weight_shape), 2 sizeof(int32_t));
int32_t bias_shape[1];
file.read(reinterpret_cast&lt;char&gt;(bias_shape), sizeof(int32_t));
la​​yer[i].input_size = weight_shape[1];
layer[i].output_size = weight_shape[0];
layer[i].weights.resize(weight_shape[0] weight_shape[1]);
la​​yer[i].biases.resize(bias_shape[0]);
file.read(reinterpret_cast&lt;char&gt;(layers[i].weights.data()), layer[i].weights.size() sizeof(float));
file.read(reinterpret_cast&lt;char&gt;(layers[i].biases.data()), layers[i].biases.size() sizeof(float));
}
return true;
}

我尝试过的方法：

在保存之前在 python 中转置权重：

weights = weights.T.astype(np.float32)

仍然有维度不匹配，但顺序相反

在 c++ 中交换输入/输出维度：

layers[i].input_size = weight_shape[0];
layers[i].output_size = weight_shape[1];

错误相同但维度不同

在 c++ 中更改权重指数计算：

size_t weight_idx = i * layer.input_size + j; // 原始
size_t weight_idx = j * layer.output_size + i; // 尝试过这个
size_t weight_idx = i + j layer.output_size; // 和这个

仍然得到错误的预测
预期：

权重应以正确的尺寸加载（768-&gt;1024-&gt;512-&gt;256-&gt;128-&gt;64-&gt;1）
模型应给出与 Python 版本类似的预测
输入板状态应正确处理所有层

实际结果：

尺寸反转（1024-&gt;768、512-&gt;1024 等）
在每一层都得到“输入大小不匹配”错误
最终预测总是返回 0
]]></description>
      <guid>https://stackoverflow.com/questions/79173992/tensorflow-model-weights-not-loading-correctly</guid>
      <pubDate>Sun, 10 Nov 2024 01:32:39 GMT</pubDate>
    </item>
    <item>
      <title>尽管进行了超参数调整，模型始终以高置信度将图像分类为猫</title>
      <link>https://stackoverflow.com/questions/79173890/model-always-classifies-images-as-cats-with-high-confidence-despite-hyperparamet</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79173890/model-always-classifies-images-as-cats-with-high-confidence-despite-hyperparamet</guid>
      <pubDate>Sat, 09 Nov 2024 23:32:53 GMT</pubDate>
    </item>
    <item>
      <title>值错误：预期输入形状的轴 -1 的值为 444，但收到的输入形状为 (None, 708)</title>
      <link>https://stackoverflow.com/questions/79173764/value-error-expected-axis-1-of-input-shape-to-have-value-444-but-received-inp</link>
      <description><![CDATA[我正在尝试训练一个 FNN 模型来检测信用卡欺诈。我的分类特征是商家、类别、城市和州。我还使用 StandardScaler 标准化了我的数值特征。我首先对分类特征使用标签编码将它们转换为整数值。然后我想为神经网络模型的分类特征创建嵌入。当我尝试运行代码时，我收到此错误：
ValueError：调用 Functional.call() 时遇到异常。

层“dense_6”的输入 0与层不兼容：预期输入形状的轴 -1 的值为 444，但收到的输入形状为 (None, 708)
这是我的代码：
# 将数据拆分为训练、验证和测试集 (70%、15%、15%)
from sklearn.model_selection import train_test_split
X = df.drop(columns=[&#39;is_fraud&#39;])
y = df[&#39;is_fraud&#39;]
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42) # 70% 训练，30% 临时
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) # 拆分temp 变成 15% val 和 15% test

来自 sklearn.preprocessing 导入 LabelEncoder、StandardScaler
# 标签编码
categorical_columns = [&#39;merchant&#39;, &#39;category&#39;, &#39;city&#39;, &#39;state&#39;]
label_encoded = {}
for col in categorical_columns:
le = LabelEncoder()
X_train[col] = le.fit_transform(X_train[col])
X_val[col] = le.transform(X_val[col])
X_test[col] = le.transform(X_test[col])
label_encoded[col] = le

# 规范化
scaler = StandardScaler()
numerical_features = [&#39;cc_num&#39;, &#39;amt&#39;, &#39;lat&#39;, &#39;long&#39;, &#39;merch_lat&#39;, &#39;merch_long&#39;, &#39;trans_hour&#39;, &#39;trans_day&#39;, &#39;trans_year&#39;, &#39;amt_ratio&#39;, &#39;daily_transaction_count&#39;, &#39;user_location_distance&#39;]
X_train_numerical = scaler.fit_transform(X_train[numerical_features])
X_val_numerical = scaler.transform(X_val[numerical_features])
X_test_numerical = scaler.transform(X_test[numerical_features])

来自 tensorflow.keras.models 导入模型
来自 tensorflow.keras.layers 导入输入、嵌入、密集、扁平化、连接
来自 sklearn.metrics 导入 precision_score、recall_score、roc_auc_score、roc_curve
导入 matplotlib.pyplot 作为 plt

# 定义嵌入维度
embedding_dim = {
&#39;merchant&#39;: 200,
&#39;category&#39;: 7,
&#39;city&#39;: 200,
&#39;state&#39;: 25
}

# 创建嵌入并将其展平为 1D 向量
merchant_input = Input(shape=(1,), name=&#39;merchant&#39;)
merchant_embedding = Embedding(input_dim=len(label_encoded[&#39;merchant&#39;].classes_), output_dim=embedding_dim[&#39;merchant&#39;])(merchant_input)
merchant_embedding = Flatten()(merchant_embedding)

category_input = Input(shape=(1,), name=&#39;category&#39;)
category_embedding = Embedding(input_dim=len(label_encoded[&#39;category&#39;].classes_), output_dim=embedding_dim[&#39;category&#39;])(category_input)
category_embedding = Flatten()(category_embedding)

city_input = 输入(shape=(1,), name=&#39;city&#39;)
city_embedding = 嵌入(input_dim=len(label_encoded[&#39;city&#39;].classes_), output_dim=embedding_dim[&#39;city&#39;])(city_input)
city_embedding = Flatten()(city_embedding)

state_input = 输入(shape=(1,), name=&#39;state&#39;)
state_embedding = 嵌入(input_dim=len(label_encoded[&#39;state&#39;].classes_), output_dim=embedding_dim[&#39;state&#39;])(state_input)
state_embedding = Flatten()(state_embedding)

numerical_input =输入（形状=（len（numerical_features）），名称=&#39;numerical_features&#39;）

# 连接嵌入和数值输入
concat_embed = Concatenate()([merchant_embedding, category_embedding, city_embedding, state_embedding])

concat_layer = Concatenate()([concat_embed, numeric_input])

# FNN 模型
x = Dense(32,activation=&#39;relu&#39;)(concat_layer)
x = Dense(32,activation=&#39;relu&#39;)(x)
输出 = Dense(1,activation=&#39;sigmoid&#39;)(x)

fnn_model = Model(输入=[merchant_input, category_input, city_input, state_input, numeric_input],输出=输出)
fnn_model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

# 准备训练和验证数据
train_inputs = {
&#39;merchant&#39;: X_train[&#39;merchant&#39;],
&#39;category&#39;: X_train[&#39;category&#39;],
&#39;city&#39;: X_train[&#39;city&#39;],
&#39;state&#39;: X_train[&#39;state&#39;],
&#39;numerical_features&#39;: X_train_numerical
}

val_inputs = {
&#39;merchant&#39;: X_val[&#39;merchant&#39;],
&#39;category&#39;: X_val[&#39;category&#39;],
&#39;city&#39;: X_val[&#39;city&#39;],
&#39;state&#39;: X_val[&#39;state&#39;],
&#39;numerical_features&#39;: X_val_numerical
}

# 训练模型
history = fnn_model.fit(train_inputs, y_train，epochs=100，batch_size=32，validation_data=(val_inputs，y_val)，verbose=0)
]]></description>
      <guid>https://stackoverflow.com/questions/79173764/value-error-expected-axis-1-of-input-shape-to-have-value-444-but-received-inp</guid>
      <pubDate>Sat, 09 Nov 2024 21:51:08 GMT</pubDate>
    </item>
    <item>
      <title>在自定义数据集上微调预训练模型的正确方法是什么？[关闭]</title>
      <link>https://stackoverflow.com/questions/79172708/what-is-the-correct-way-of-fine-tuning-a-pre-trained-model-on-custom-dataset</link>
      <description><![CDATA[我正在使用 Python、Keras、Tensorflow 和 MobileNetV2 作为基础模型训练二元分类模型，然后在其上添加我的自定义层。但我不确定微调模型的正确方法是什么，因为我尝试过使用 InceptionV3 和 VGG16 代替 MobileNetV2，但这三个的准确率和损失几乎相同，目前我的模型架构代码是这样的：
# 模型架构
def build_spatiotemporal_model():
mobilenetv2 = MobileNetV2(include_top=False, weights=&#39;imagenet&#39;, input_shape=(IMG_SIZE, IMG_SIZE, 3))
mobilenetv2.trainable = False

#for vgg
#vgg16 = VGG16(include_top=False, weights=&#39;imagenet&#39;, input_shape=(IMG_SIZE, IMG_SIZE, 3))
#vgg16.trainable = False 

#for inception
#inceptionv3 = InceptionV3(include_top=False, weights=&#39;imagenet&#39;, input_shape=(IMG_SIZE, IMG_SIZE, 3))
#inceptionv3.trainable = False 

model = Sequential([
InputLayer(shape=(FRAME_COUNT, IMG_SIZE, IMG_SIZE, 3)),

TimeDistributed(mobilenetv2),

TimeDistributed(MaxPooling2D(pool_size=(2, 2))),

TimeDistributed(BatchNormalization()),

Bidirectional(ConvLSTM2D(256, (3, 3), padding=&#39;same&#39;, return_sequences=True)),

BatchNormalization(),

MaxPooling3D(pool_size=(1, 2, 2)),

Flatten(),
Dense(256, 激活=&#39;relu&#39;),

Dropout(0.6),

Dense(1, 激活=&#39;sigmoid&#39;)
])

返回模型

model = build_spatiotemporal_model()
model.compile(optimizer=Adam(learning_rate=LEARNING_RATE), loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])

由于这 3 个的性能相同，我认为我做错了一些我不知道的事情。
此外，如果我计划通过解冻一些层来进行微调，那么正确的方法是什么？

首先通过冻结所有基础模型层来训练模型几个时期（假设 10 个）。然后解冻一些基础模型层并重新编译和训练几个 epoch。

首先解冻一些基础模型层并编译和训练一次。


那么方法 1 和方法 2 哪一个是正确的？]]></description>
      <guid>https://stackoverflow.com/questions/79172708/what-is-the-correct-way-of-fine-tuning-a-pre-trained-model-on-custom-dataset</guid>
      <pubDate>Sat, 09 Nov 2024 12:03:02 GMT</pubDate>
    </item>
    <item>
      <title>尝试从 Coqui 初学者教程运行 TTS 时出现权限错误</title>
      <link>https://stackoverflow.com/questions/79172651/permission-error-while-trying-to-run-tts-from-coquis-beginner-tutorial</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79172651/permission-error-while-trying-to-run-tts-from-coquis-beginner-tutorial</guid>
      <pubDate>Sat, 09 Nov 2024 11:31:03 GMT</pubDate>
    </item>
    <item>
      <title>尽管测试准确率很高（91％），但模型仍预测 Tkinter GUI 中的同一类 [关闭]</title>
      <link>https://stackoverflow.com/questions/79172357/model-predicts-the-same-class-in-tkinter-gui-despite-high-test-accuracy-91</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79172357/model-predicts-the-same-class-in-tkinter-gui-despite-high-test-accuracy-91</guid>
      <pubDate>Sat, 09 Nov 2024 08:08:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用自定义数据训练 ssd300 模型[关闭]</title>
      <link>https://stackoverflow.com/questions/79172071/how-to-train-ssd300-model-with-custom-data</link>
      <description><![CDATA[我有一个我国的汽车数据集，我想用SSD300模型重新训练这个数据集，我使用python语言，使用pytorch。
我尝试了github上的一些源代码，但大多数都有库错误或识别效果不佳。
我正在寻找适用于python3.12的pytorch源代码]]></description>
      <guid>https://stackoverflow.com/questions/79172071/how-to-train-ssd300-model-with-custom-data</guid>
      <pubDate>Sat, 09 Nov 2024 03:40:55 GMT</pubDate>
    </item>
    <item>
      <title>如何修复错误 ValueError：预期输入 batch_size (49) 与目标 batch_size (64) 匹配</title>
      <link>https://stackoverflow.com/questions/79172053/how-to-fix-the-error-valueerror-expected-input-batch-size-49-to-match-target</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79172053/how-to-fix-the-error-valueerror-expected-input-batch-size-49-to-match-target</guid>
      <pubDate>Sat, 09 Nov 2024 03:24:43 GMT</pubDate>
    </item>
    <item>
      <title>如何训练 seq2seq 模型来转换结构化文本？</title>
      <link>https://stackoverflow.com/questions/79171901/how-to-train-a-seq2seq-model-for-converting-structured-text</link>
      <description><![CDATA[我正在尝试训练一个模型，将一些旧模板转换为 jinja2。
{if $logged_in}
欢迎，&lt;font color=&quot;{#fontColor#}&quot;&gt;{$name}!&lt;/font&gt;
{else}
嗨，{$name}
{/if}

to
{% if context.logged_in %}
欢迎，&lt;font color=&quot;{{ fontColor }}&quot;&gt;{{ context.name }}!&lt;/font&gt;
{% else %}
嗨，{{ context.name }}
{% endif %}

我已经将方法缩小到 seq2seq，并编写了一个小程序，引用了各种博客文章和教程。
但我在保持文本序列方面遇到了麻烦。
我该如何训练它，使它只需要担心 {} 里面的东西，而其他一切都可以原封不动地复制粘贴？]]></description>
      <guid>https://stackoverflow.com/questions/79171901/how-to-train-a-seq2seq-model-for-converting-structured-text</guid>
      <pubDate>Sat, 09 Nov 2024 00:34:10 GMT</pubDate>
    </item>
    <item>
      <title>我应该安装哪个版本的 torch 和 torchtext [关闭]</title>
      <link>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</link>
      <description><![CDATA[我使用的是 Windows，python 版本是 3.11.4，pandas 版本是 2.2.1

我尝试安装 torch 和 torchtext，但总是出现依赖错误。

这两个版本应该安装哪个版本？]]></description>
      <guid>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</guid>
      <pubDate>Fri, 08 Nov 2024 20:20:10 GMT</pubDate>
    </item>
    <item>
      <title>使用余弦相似度来研究推荐特征[关闭]</title>
      <link>https://stackoverflow.com/questions/79171143/working-on-a-recommendation-feature-using-cosine-similarity</link>
      <description><![CDATA[我正在开展一个实习管理项目，其中包括一个推荐功能，用于将学生与实习机会进行匹配。我正在考虑使用余弦相似度，但由于我对这种方法还不熟悉，我想确认我的方法是否可行。
我的计划是将每个学生的个人资料（使用位置、专业和技能等属性）与系统数据库中可用的实习机会进行比较，而无需额外的数据集。我想知道：

以这种方式使用余弦相似度是否可行，即将每个学生的个人资料直接与每个可用的实习机会进行比较？
余弦相似度是否是处理这些类型属性的有效方法，还是我应该考虑更合适的方法？
我仍处于规划阶段，因此无法尝试任何方法或代码，在报告中采用这种方法之前，我很感激任何关于设置建议的见解。
]]></description>
      <guid>https://stackoverflow.com/questions/79171143/working-on-a-recommendation-feature-using-cosine-similarity</guid>
      <pubDate>Fri, 08 Nov 2024 18:10:50 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用函数 shap.Explainer 会根据输入的不同顺序获得不同的 shap 值？</title>
      <link>https://stackoverflow.com/questions/79152799/why-i-get-different-shap-values-according-to-the-different-order-of-inputs-by-us</link>
      <description><![CDATA[我训练了一个二分类模型，并想使用 shap.Explainer 来分析特征贡献。
代码如下：
def f(x):
return model.predict_proba(x)[:, 1]

X100 = shap.utils.sample(X_train, 100)

explainer = shap.Explainer(f, X100, seed=2023)
shap_values = explainer(data.iloc[[0,1,2,3], :])

shap_values.values 的结果如下：




Feature 1
...




sample 0
-0.009703
...


样本 1
-0.009297
...


样本 2
-0.007699
...


样本 3
0.032624
...



但是当输入顺序改变时：
def f(x):
return model.predict_proba(x)[:, 1]

X100 = shap.utils.sample(X_train, 100)

explainer = shap.Explainer(f, X100, seed=2023)
shap_values = explainer(data.iloc[[1,0,2,3], :])

样本 0 和样本 1 的结果已更改：




特征 1
...




样本 1
-0.010012
...


样本0
-0.008277
...


样本 2
-0.007699
...


样本 3
0.032624
...



我不知道有什么区别。]]></description>
      <guid>https://stackoverflow.com/questions/79152799/why-i-get-different-shap-values-according-to-the-different-order-of-inputs-by-us</guid>
      <pubDate>Sun, 03 Nov 2024 13:22:12 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：'tuple' 没有属性 'to'</title>
      <link>https://stackoverflow.com/questions/63825841/attributeerror-tuple-has-no-attribute-to</link>
      <description><![CDATA[我正在编写这个图像分类器，我已经定义了加载器，但出现了这个错误，我对此一无所知。
我已经定义了火车加载器，为了更好地解释，我尝试了这个
for ina,lab in train_loader:
print(type(ina))
print(type(lab)) 

我得到了
&lt;class &#39;torch.Tensor&#39;&gt;
&lt;class &#39;tuple&#39;&gt;

现在，为了训练模型，我做了
def train_model(model,optimizer,n_epochs,criterion):
start_time = time.time()
for epoch in range(1,n_epochs-1):
epoch_time = time.time()
epoch_loss = 0
correct = 0
total = 0
print( &quot;Epoch {}/{}&quot;.format(epoch,n_epochs))

model.train()

for input,labels in train_loader:
input = input.to(device)
labels = labels.to(device)
optimizer.zero_grad()
output = model(inputs)
loss = criterion(output,labels)
loss.backward()
optimizer.step()
epoch_loss +=loss.item()
_,pred =torch.max(output,1)
correct += (pred.cpu()==label.cpu()).sum().item()
total +=labels.shape[0]

acc = correct/total


我得到了错误：
Epoch 1/15
------------------------------------------------------------------------------
AttributeError Traceback (most recent call last)
&lt;ipython-input-36-fea243b3636a&gt; in &lt;module&gt;
----&gt; 1 train_model(model=arch, optimizer=optim, n_epochs=15, criterion=criterion)

&lt;ipython-input-34-b53149a4bac0&gt;在 train_model(model、optimizer、n_epochs、criterion) 中
12 用于 train_loader 中的输入、标签：
13 输入 = 输入。到 (device)
---&gt; 14 标签 = 标签。到 (device)
15 优化器。zero_grad()
16 输出 = 模型 (输入)

AttributeError: &#39;tuple&#39; 对象没有属性 &#39;to&#39;

如果您想要更多信息，请告诉我！
谢谢
编辑：标签看起来像这样。
这是蜜蜂和黄蜂之间的图像分类。它还包含昆虫和非昆虫
(&#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;昆虫&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;, &#39;昆虫&#39;, &#39;昆虫&#39;, &#39;其他&#39;, &#39;蜜蜂&#39;, &#39;其他&#39;, &#39;黄蜂&#39;, &#39;其他&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;其他&#39;, &#39;蜜蜂&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;)
(&#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;蜜蜂&#39;, &#39;其他&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;昆虫&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;蜜蜂&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;昆虫&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;蜜蜂&#39;、&#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;蜜蜂&#39;、&#39;蜜蜂&#39;、&#39;昆虫&#39;、&#39;其他&#39;）]]></description>
      <guid>https://stackoverflow.com/questions/63825841/attributeerror-tuple-has-no-attribute-to</guid>
      <pubDate>Thu, 10 Sep 2020 08:34:32 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 中的步骤和时期有什么区别？</title>
      <link>https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow</link>
      <description><![CDATA[在大多数模型中，都有一个 steps 参数，表示在数据上运行的步骤数。但我在大多数实际使用中看到，我们还会执行拟合函数 N epochs。
用 1 个 epoch 运行 1000 步和用 10 个 epoch 运行 100 步有什么区别？在实践中哪一个更好？连续 epoch 之间有任何逻辑变化吗？数据混洗？]]></description>
      <guid>https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow</guid>
      <pubDate>Tue, 12 Jul 2016 23:20:22 GMT</pubDate>
    </item>
    </channel>
</rss>