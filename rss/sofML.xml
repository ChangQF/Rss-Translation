<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 08 Jun 2024 15:14:57 GMT</lastBuildDate>
    <item>
      <title>自定义图像在 MNIST 神经网络模型中无法从头开始正确预测</title>
      <link>https://stackoverflow.com/questions/78595824/custom-image-is-not-being-predicted-correctly-in-mnist-neural-network-model-from</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78595824/custom-image-is-not-being-predicted-correctly-in-mnist-neural-network-model-from</guid>
      <pubDate>Sat, 08 Jun 2024 13:30:51 GMT</pubDate>
    </item>
    <item>
      <title>如何在多标签分类中实现类别或样本权重采样？</title>
      <link>https://stackoverflow.com/questions/78595351/how-to-implement-class-or-sample-weight-sampling-in-multi-label-classification</link>
      <description><![CDATA[我目前正在研究多标签图像分类问题，我的数据集严重不平衡。我的数据集中的每个图像可以有多个标签。标签以独热编码格式提供。
例如：[1,0,0,0,0,1,0] 等。
我的训练 df：
图像索引查找标签
0 00005504_002.png Pleural_Thickening
1 00003527_002.png Atelectasis|Pneumonia
2 00018285_000.png Effusion|Mass
3 00016971_007.png Emphysema|Mass
4 00014022_071.png Atelectasis|Consolidation|Pleural_Thickening

为了平衡数据集，我考虑对过度代表的类别进行欠采样。但是，我遇到了一个挑战，即它可能会失去模型的有效性。
我正在寻找在 PyTorch 中实现类权重/样本权重。如何在 PyTorch 中有效实现此多标签分类问题？我在网上读到，类权重可能不适用于独热编码标签，可能需要使用样本权重或自定义损失函数。如何使用加权采样实现自定义损失？任何具体建议都将不胜感激。
以下是我的代码：
`resnet50 = ResNet101(input_shape=(256, 256, 3), weights=&#39;imagenet&#39;, include_top=False)

for layer in resnet50.layers[:-3]:
layer.trainable = False

x = Flatten()(resnet50.output)
x = Dense(512,activation=&#39;relu&#39;)(x)
prediction = Dense(13,activation=&#39;sigmoid&#39;)(x) 

model = Model(inputs=resnet50.input,outputs=prediction)
learning_rate = 0.001
adam_optimizer = Adam(learning_rate=learning_rate)

model.compile(optimizer=adam_optimizer,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;, AUC(multi_label=True)])
early_stopping = EarlyStopping(monitor=&#39;val_auc&#39;,patient=5,restore_best_weights=True)
history = model.fit(train_dataset,epochs=100,validation_data=val_dataset,callbacks=[early_stopping])`
]]></description>
      <guid>https://stackoverflow.com/questions/78595351/how-to-implement-class-or-sample-weight-sampling-in-multi-label-classification</guid>
      <pubDate>Sat, 08 Jun 2024 10:12:45 GMT</pubDate>
    </item>
    <item>
      <title>打开AI助手</title>
      <link>https://stackoverflow.com/questions/78595344/open-ai-assistant</link>
      <description><![CDATA[我正在尝试调用此函数
thread = client.beta.threads.create()
但出现此错误
AttributeError Traceback（最近一次调用最后一次）
Cell In[12]，第 1 行
----&gt; 1 thread = client.beta.threads.create()

文件 ~/anaconda3/envs/llm/lib/python3.9/site-packages/openai/resources/beta/threads/threads.py:121，位于 Threads.create(self, messages, metadata, tool_resources, extra_headers, extra_query, extra_body, timeout)
95 &quot;&quot;&quot;
96 创建线程。
97 
(...)
118 timeout：覆盖此请求的客户端级默认超时（以秒为单位）
119 &quot;&quot;&quot;
120 extra_headers = {&quot;OpenAI-Beta&quot;: &quot;assistants=v2&quot;, **(extra_headers 或 {})}
--&gt; 121 return self._post(
122 &quot;/threads&quot;,
123 body=maybe_transform(
124 {
125 &quot;messages&quot;: messages,
126 &quot;metadata&quot;: metadata,
127 &quot;tool_resources&quot;: tool_resources,
128 },
129 thread_create_params.ThreadCreateParams,
130 ),
131 options=make_request_options(
132 extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout
...
51 if isinstance(value, bytes):
52 return value
---&gt; 53 return value.encode(encoding or &quot;ascii&quot;)

AttributeError: &#39;tuple&#39; 对象没有属性 &#39;encode&#39;

我尝试更新 openai，并给出消息，但出现同样的错误]]></description>
      <guid>https://stackoverflow.com/questions/78595344/open-ai-assistant</guid>
      <pubDate>Sat, 08 Jun 2024 10:10:56 GMT</pubDate>
    </item>
    <item>
      <title>为什么 EarlyStopping.stopped_epoch 给出的结果比实际的最后一个 epoch 少一个</title>
      <link>https://stackoverflow.com/questions/78595332/why-does-earlystopping-stopped-epoch-gives-one-less-than-actuall-last-epoch</link>
      <description><![CDATA[我正在使用 keras 训练回归模型。
在代码中，我设置它必须打印 Last epoch 和 Best epoch，只是为了跟踪它，并且它总是将 last epoch 设置为少一个，并不是说有时它将 best epoch 设置为不是它本身的东西，因为我有 MSE 作为要测量的值，有时我会得到这样的结果：
Epoch 9/50
90/90 [===============================] - 3s 36ms/step - loss: 5.4706e-04 - root_mean_squared_error: 0.0234
Epoch 10/50
90/90 [================================] - 3s 34ms/step - loss: 5.1254e-04 - root_mean_squared_error：0.0226
Epoch 11/50
90/90 [===============================] - 3s 35ms/步 - 损失：6.2349e-04 - root_mean_squared_error：0.0250
Epoch 12/50
90/90 [===============================] - 3s 35ms/步 - 损失：6.0034e-04 - root_mean_squared_error：0.0245
Epoch 13/50
90/90 [================================] - 3s 34ms/步 -损失：5.7258e-04 - root_mean_squared_error：0.0239
Epoch 14/50
90/90 [==============================] - 3s 35ms/步 - 损失：6.1547e-04 - root_mean_squared_error：0.0248
Epoch 15/50
90/90 [==============================] - 3s 35ms/步 - 损失：5.4814e-04 - root_mean_squared_error：0.0234
Epoch 16/50
90/90 [================================] - 3s 38ms/step - 损失：5.3549e-04 - root_mean_squared_error：0.0231

最佳时期：9
最后一个时期：15

在这个 ej 中，我们可以看到我所说的，最后一个时期与打印的数字不匹配，总是少 1，并且在这个 ej 中我们还可以看到，最佳时期被称为是时期 9，而显然时期 10（只是下一个，这种情况总是发生）更好，并且在这个特定情况下，时期编号 16 也比时期 9 更好（尽管这种情况并不常见）。
我的代码如下：

# 训练模型
earlystopping = callbacks.EarlyStopping(monitor=&quot;loss&quot;, mode=&quot;min&quot;, waiting=6, restore_best_weights=True)

self.model.fit(x_train , y_train, batch_size=24, epochs=50, callbacks=[earlystopping])

print(f&#39;\nBest epoch: {earlystopping.best_epoch}\nLast Epoch: {earlystopping.stopped_epoch}\n&#39;)

这可能与索引有关，我不知道存储时 epoch 是存储在数组还是列表中，因此，在获取 EarlyStopping.&lt;some_epoch&gt; 的值时，它会为您提供其索引值，因此它少了一个，因为它不是从 1 开始计数，而是从 0 开始计数。
奇怪的部分是最佳 epoch。我的代码有什么问题，它没有识别出更好的时期（就像上面描述的情况一样），因为在大多数情况下，它可能与上一个时期、索引的原因相同，但有时，最佳时期 1 和最后一个时期之间的一些时期比归类为最佳时期的时期要好。]]></description>
      <guid>https://stackoverflow.com/questions/78595332/why-does-earlystopping-stopped-epoch-gives-one-less-than-actuall-last-epoch</guid>
      <pubDate>Sat, 08 Jun 2024 10:07:31 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：使用“bitsandbytes”8 位量化需要加速</title>
      <link>https://stackoverflow.com/questions/78595127/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate</link>
      <description><![CDATA[从 huggingface 下载模型时遇到错误。它在 Google Colab 上运行良好，但在我的 Windows 机器上却无法运行。我使用的是 Python 3.10.0。
错误代码如下所示：
E:\Internships\ConsciusAI\.venv\lib\site-packages\huggingface_hub\file_download.py:1132: FutureWarning: `resume_download` 已弃用，将在版本 1.0.0 中被删除。下载始终会在可能时恢复。如果您想强制进行新的下载，请使用 `force_download=True`。
warnings.warn(
未使用的 kwargs：[&#39;_load_in_4bit&#39;, &#39;_load_in_8bit&#39;, &#39;quant_method&#39;]。这些 kwargs 未在 &lt;class &#39;transformers.utils.quantization_config.BitsAndBytesConfig&#39;&gt; 中使用。
E:\Internships\ConsciusAI\.venv\lib\site-packages\transformers\quantizers\auto.py:159: UserWarning：您已将 `quantization_config` 或等效参数传递给 `from_pretrained`，但您正在加载的模型已经具有 `quantization_config` 属性。将使用模型中的 `quantization_config`。
warnings.warn(warning_msg)
回溯（最近一次调用）：
文件 &quot;E:\Internships\ConsciusAI\email_2.py&quot;，第 77 行，在 &lt;module&gt;
main()
文件“E:\Internships\ConsciusAI\email_2.py”，第 71 行，在 main 中
summary = summary_email(content)
文件“E:\Internships\ConsciusAI\email_2.py”，第 22 行，在 summary_email 中
pipeline = transformers.pipeline(
文件“E:\Internships\ConsciusAI\.venv\lib\site-packages\transformers\pipelines\__init__.py”，第 906 行，在 pipeline 中
framework, model = infer_framework_load_model(
文件“E:\Internships\ConsciusAI\.venv\lib\site-packages\transformers\pipelines\base.py”，第 283 行，在 infer_framework_load_model 中
model = model_class.from_pretrained(model, **kwargs)
文件&quot;E:\Internships\ConsciusAI\.venv\lib\site-packages\transformers\models\auto\auto_factory.py&quot;，第 563 行，在 from_pretrained 中
return model_class.from_pretrained(
File &quot;E:\Internships\ConsciusAI\.venv\lib\site-packages\transformers\modeling_utils.py&quot;，第 3165 行，在 from_pretrained 中
hf_quantizer.validate_environment(
File &quot;E:\Internships\ConsciusAI\.venv\lib\site-packages\transformers\quantizers\quantizer_bnb_4bit.py&quot;，第 62 行，在 validate_environment 中
raise ImportError(
ImportError: 使用 `bitsandbytes` 8 位量化需要 Accelerate：`pip install accelerate` 和最新版本的 bitsandbytes： `pip install -i https://pypi.org/simple/ bitsandbytes`

这是我使用的代码：
def summary_email(content):
model_id = &quot;unsloth/llama-3-8b-Instruct-bnb-4bit&quot;

pipeline = transformers.pipeline(
&quot;text-generation&quot;,
model=model_id,
model_kwargs={
&quot;torch_dtype&quot;: torch.float16,
&quot;quantization_config&quot;: {&quot;load_in_4bit&quot;: True},
&quot;low_cpu_mem_usage&quot;: True,
},
)

messages = [
{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;你很擅长总结&quot;},
{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;帮我总结一下邮件&quot; + content},
]

prompt = pipeline.tokenizer.apply_chat_template(
messages,
tokenize=False,
add_generation_prompt=True
)

terminators = [
pipeline.tokenizer.eos_token_id,
pipeline.tokenizer.convert_tokens_to_ids(&quot;&quot;)
]

output = pipeline(
prompt,
max_new_tokens=256,
eos_token_id=terminators,
do_sample=True,
temperature=0.6,
top_p=0​​.9,
)

我正尝试使用 huggingface 中的“unsloth/llama-3-8b-Instruct-bnb-4bit”总结文本。
它确实在 Google Colab 和 Kaggle 上总结了文本，但在本地机器上没有。]]></description>
      <guid>https://stackoverflow.com/questions/78595127/importerror-using-bitsandbytes-8-bit-quantization-requires-accelerate</guid>
      <pubDate>Sat, 08 Jun 2024 08:37:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 BARTDecoder 和 cached_property 的 Nougat OCR 中的 ImportError 和 TypeError 问题</title>
      <link>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78594832/importerror-and-typeerror-issues-in-nougat-ocr-with-bartdecoder-and-cached-prope</guid>
      <pubDate>Sat, 08 Jun 2024 05:43:48 GMT</pubDate>
    </item>
    <item>
      <title>尽管 Resnet50 的测试和训练准确率很高，但 F1 分数却很低</title>
      <link>https://stackoverflow.com/questions/78594365/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</link>
      <description><![CDATA[我目前正在使用 Resnet50 在 Amazon Berkley Objects 数据集上进行图像分类，我一直面临 F1 分数低的问题，我确保训练和测试样本中的类别相等（总共约 50k 张图像），尽管它不会超过 10%（我知道图像显示的是第 7 个 epoche，但直到运行结束我都不会移动），有什么建议吗？
预处理步骤主要是过滤、数据增强、重新缩放、基本数据准备，数据分为 80 20。]]></description>
      <guid>https://stackoverflow.com/questions/78594365/resnet50-low-f1-score-despite-high-testing-and-training-accuracy</guid>
      <pubDate>Sat, 08 Jun 2024 00:03:13 GMT</pubDate>
    </item>
    <item>
      <title>成本函数增加，然后停止增长</title>
      <link>https://stackoverflow.com/questions/78594171/cost-function-increases-then-stops-growing</link>
      <description><![CDATA[我理解应用梯度下降时成本函数的曲折性质，但让我困扰的是成本一开始只有 300，最后却增加到 1600。
成本函数会在 300 和 4000 之间波动，最终达到 1600。我想我应该得到一个 300 或更低的数字。我尝试过改变学习率，但它仍然将我带到了 1600。我应该得到一个大约 300 的成本，而不是一个增长的成本。
数据：
square_feet = [1661.0, 871.0, 1108.0, 1453.0, 1506.0, 1100.0, 1266.0, 1514.0, 948.0, 1878.0, 1522.0, 931.0, 1475.0, 1177.0, 1844.0, 1469.0, 2155.0, 967.0, 1092.0]
prices = [1350.0, 489.0, 589.0, 539.0, 775.0, 575.0, 749.0, 795.0, 644.9, 590.0, 575.0, 699.0, 999.0, 775.0, 599.0, 599.0, 895.0, 550.0, 849.0]

这两个列表在原始代码中都是 Pandas 系列，但为了清晰起见，已在此处将其转换为列表。
主要：
# 添加起始权重和偏差
w_init = 5e-1 # 每 1 平方英尺的价格增加
b_init = 200 # 最便宜房屋的起始价格

# 梯度下降算法的迭代和学习率
iterations = 10000
alpha = 1.0e-6 # 很微妙，如果设置得太高会导致发散大

w_final，b_final，J_hist，p_hist = gradient_descent（
square_feet，prices，w_init，b_init，alpha，iterations）

print（f&#39;w：{w_final}，b：{b_final}，成本：{J_hist}，权重和偏差：{p_hist}&#39;）

函数：
# 成本函数用于确定实际值和预测值之间的累积误差
def cost_function（x，y，w，b）：

# 1）训练示例的数量
m = x.size
cost = 0

# 2）索引训练示例并考虑每个实例的成本
for i in range（m）：
y_hat = w * x[i] + b
cost += (y_hat-y[i])**2
cost /= 2 * m

# 3）返回总成本
return cost

# 计算梯度，即提高准确率的标量
def gradient_function(x, y, w, b):

m = x.size

# 成本函数关于权重和偏差的偏导数
dj_dw = 0
dj_db = 0

for i in range(m):
y_hat = w * x[i] + b
dj_dw_i = (y_hat - y[i]) * x[i]
dj_db_i = (y_hat - y[i])
dj_db += dj_db_i
dj_dw += dj_dw_i

dj_dw /= m
dj_db /= m

return dj_dw, dj_db

def gradient_descent(x, y, w_init, b_init, learning_rate, 
num_iters):

# 用于绘图
J_history = []
p_history = []
b = b_init
w = w_init

for i in range(num_iters):
dj_dw, dj_db = gradient_function(x, y, w, b) # 梯度

# 更新权重、偏差
w -= learning_rate * dj_dw
b -= learning_rate * dj_db

# 防止资源耗尽；无需存储类似成本
# 过去 100000 次迭代
if i &lt; 100000:
J_history.append(cost_function(x, y, w, b))
p_history.append([w,b])

return w, b, J_history, p_history

我对这个问题感到困惑。]]></description>
      <guid>https://stackoverflow.com/questions/78594171/cost-function-increases-then-stops-growing</guid>
      <pubDate>Fri, 07 Jun 2024 22:10:23 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 损失差异很大</title>
      <link>https://stackoverflow.com/questions/78594078/lstm-losses-diverge-quite-drastically</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78594078/lstm-losses-diverge-quite-drastically</guid>
      <pubDate>Fri, 07 Jun 2024 21:32:37 GMT</pubDate>
    </item>
    <item>
      <title>优化评分指标的多变量线性回归系数</title>
      <link>https://stackoverflow.com/questions/78593935/optimize-coefficients-for-multi-variable-linear-regression-of-scoring-metric</link>
      <description><![CDATA[我有一个电子商务网站，我尝试优化搜索结果，为用户提供最相关的结果。
为了提供最相关的搜索结果，我制定了一个评级指标。评级指标基于产品参数和每个参数的权重构建。
评级分数从 0-1 标准化
fn 函数返回 0-1 的分数
rating = b0*f0(X0) + b0*f1(X1) + bn*fn(Xn)

例如：rating = 0.4*f(seller_score) + 0.25*f(customers_stars) + 0.35*f(return_rate) = 0.683
当有人搜索“厨房椅子”时我根据评分对返回的结果进行排序。
SELECT 
* 
FROM 
db 
WHERE 
category = &quot;kitchen chair&quot; 
ORDER BY ratings DESC 
LIMIT 50

用户点击我记录的一些结果。在最佳情况下，用户将选择第一个结果之一，因为评分效果良好，并且用户可能得到了他想要的东西。但如果用户从列表中选择了第 24 个产品，那么我的评分可能没有得到优化。
我的目标是优化我的评分指标的系数，使其尽可能匹配用户实际点击的内容，这样他们就能首先获得最佳结果。
我有一系列 n 个搜索词，以及它们的结果和用户点击的内容。
我可以使用什么算法来找到 b0、b1、..bn 的最佳系数，这样点击的结果实际上就会位于顶部。现在，我希望找到适合所有搜索词的结果，而不是优化每个搜索词。]]></description>
      <guid>https://stackoverflow.com/questions/78593935/optimize-coefficients-for-multi-variable-linear-regression-of-scoring-metric</guid>
      <pubDate>Fri, 07 Jun 2024 20:43:38 GMT</pubDate>
    </item>
    <item>
      <title>大数据去重</title>
      <link>https://stackoverflow.com/questions/78565978/duplicate-removal-for-large-data</link>
      <description><![CDATA[我正在处理一个零售数据集，其中发票有 250000 个重复值。如何处理数据中的重复项我仍在尝试找出解决查询的方法。我考虑用均值中位数或众数来解决它]]></description>
      <guid>https://stackoverflow.com/questions/78565978/duplicate-removal-for-large-data</guid>
      <pubDate>Sun, 02 Jun 2024 09:23:42 GMT</pubDate>
    </item>
    <item>
      <title>在 sagemaker 中部署 llama-3 8B 时出错：标记器不匹配？</title>
      <link>https://stackoverflow.com/questions/78563364/error-deploying-llama-3-8b-in-sagemaker-tokenizer-mismatch</link>
      <description><![CDATA[尝试部署 meta/llama-3-8B-Instruct 时，我在 sagemaker 代码编辑器中收到以下错误：
“您从此检查点加载的 tokenizer 类与调用此函数的类的类型不同。这可能会导致意外的标记化。
您从此检查点加载的 tokenizer 类是“PreTrainedTokenizerFast”。
调用此函数的类是“LlamaTokenizer”。&quot;
我正在使用 Huggingface API 将模型从 HF Hub 直接加载到 sagemaker 代码编辑器，使用 AWS 中的 ml.g5xlarge 实例类型。使用 HF API 不需要或公开 tokenizer。]]></description>
      <guid>https://stackoverflow.com/questions/78563364/error-deploying-llama-3-8b-in-sagemaker-tokenizer-mismatch</guid>
      <pubDate>Sat, 01 Jun 2024 09:35:46 GMT</pubDate>
    </item>
    <item>
      <title>如何绘制多类别分类中所有类别的 SHAP 摘要图</title>
      <link>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</link>
      <description><![CDATA[我正在使用 XGBoost 和 SHAP 来分析多类分类问题中的特征重要性，并需要帮助同时绘制所有类的 SHAP 摘要图。目前，我一次只能生成一个类的图。
SHAP 版本：0.45.0
Python 版本：3.10.12

这是我的代码：
import xgboost as xgb
import shap
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.metrics import accuracy_score

# 生成合成数据
X, y = make_classification(n_samples=500, n_features=20, n_informative=4, n_classes=6, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# 训练 XGBoost 模型进行多类分类
model = xgb.XGBClassifier(objective=&quot;multi:softprob&quot;, random_state=42)
model.fit(X_train, y_train)

然后我尝试绘制形状值：
# 创建 SHAP TreeExplainer
explainer = shap.TreeExplainer(model)

# 计算测试集的 SHAP 值
shap_values = explainer.shap_values(X_test)

# 尝试绘制所有类的摘要
shap.summary_plot(shap_values, X_test, plot_type=&quot;bar&quot;)

我得到了这个交互图而是：

我在这篇文章的帮助下解决了这个问题：
shap.summary_plot(shap_values[:,:,0], X_test, plot_type=&quot;bar&quot;)

哪个给出类别 0 的正常条形图：

然后我可以对类别 1、2、3 等执行相同操作。
问题是，如何为所有类别制作摘要图？即，单个图显示特征对每个类别的贡献？]]></description>
      <guid>https://stackoverflow.com/questions/78396068/how-to-plot-shap-summary-plots-for-all-classes-in-multiclass-classification</guid>
      <pubDate>Sat, 27 Apr 2024 19:02:16 GMT</pubDate>
    </item>
    <item>
      <title>由于“tokenizer”不为“none”，因此不会使用参数“token_pattern”</title>
      <link>https://stackoverflow.com/questions/77149319/the-parameter-token-pattern-will-not-be-used-since-tokenizer-is-not-none</link>
      <description><![CDATA[我试图删除标点符号和空格（包括换行符）并过滤仅由字母组成的标记，然后返回标记文本。
我首先定义函数
 return [t.text for t in nlp(doc) if \
not t.is_punct and \
not t.is_space and \
t.is_alpha]

然后我进行矢量化
vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer)
train_feature_vects = vectorizer.fit_transform(train_data)

终端卡住了，并说参数“token_pattern”不会被使用，因为“tokenizer”不是“none”。
我做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/77149319/the-parameter-token-pattern-will-not-be-used-since-tokenizer-is-not-none</guid>
      <pubDate>Thu, 21 Sep 2023 10:17:24 GMT</pubDate>
    </item>
    <item>
      <title>darknet 不使用带有 cuda 的 p5000 gpu</title>
      <link>https://stackoverflow.com/questions/68135394/darknet-doesnt-use-p5000-gpu-with-cuda</link>
      <description><![CDATA[我运行这个命令
./darknet detector train data/obj.data cfg/yolov3_training.cfg back/last_4_4_7pm.weights /back -dont_show -gpus 0 

但是 gou 未被使用并且为 0 %
这是我的 makefile；：
%cd darknet
!sed -i &#39;s/OPENCV=0/OPENCV=1/&#39; Makefile
!sed -i &#39;s/GPU=0/GPU=1/&#39; Makefile
!sed -i &#39;s/CUDNN=0/CUDNN=1/&#39; Makefile

这是输出
CUDA 版本：11020 (11000)
警告：CUDA 版本高于驱动程序版本！
, cuDNN: 8.1.0, GPU 数量: 1 
OpenCV 版本: 3.4.11
0
yolov3_training
0 : compute_capability = 610, cudnn_half = 0, GPU: Quadro P5000 
net.optimized_memory = 0 
mini_batch = 4, batch = 64, time_steps = 1, train = 1 
layer filters size/strd(dil) input output
0 Create CUDA-stream - 0 
Create cudnn-handle 0 

这是我的 nvidia smi:
root@n5qr6jidhm:/notebooks/Untitled Folder/darknet# nvidia-smi

2021 年 6 月 25 日星期五 17:53:45
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06 驱动程序版本：450.36.06 CUDA 版本：11.0 |
|-------------------------------+----------------------+-----------------------+
| GPU 名称 Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |
| 风扇温度 Perf Pwr:Usage/Cap| 内存使用情况 | GPU-Util Compute M. |
| | | MIG M. |
|=================================+===========================+===========================|
| 0 Quadro P5000 开启 | 00000000:00:05.0 关闭 | 关闭 |
| 39% 62C P0 126W / 180W | 5725MiB / 16278MiB | 92% 默认 |
| | | N/A |
+-------------------------------------------+----------------------+----------------------+]]></description>
      <guid>https://stackoverflow.com/questions/68135394/darknet-doesnt-use-p5000-gpu-with-cuda</guid>
      <pubDate>Fri, 25 Jun 2021 18:04:35 GMT</pubDate>
    </item>
    </channel>
</rss>