<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 13 Nov 2024 06:24:49 GMT</lastBuildDate>
    <item>
      <title>为什么从直觉上讲，规范化有利于神经网络的学习？</title>
      <link>https://stackoverflow.com/questions/79183566/why-normalisation-is-good-for-learning-in-neural-netwrok-in-intutive-sense</link>
      <description><![CDATA[我一直在想这个问题，当我们进行标准化时，我们会丢失信息的幅度部分，而只保留方向信息，那么为什么丢失这个幅度信息不会影响学习，梯度的幅度部分代表什么？]]></description>
      <guid>https://stackoverflow.com/questions/79183566/why-normalisation-is-good-for-learning-in-neural-netwrok-in-intutive-sense</guid>
      <pubDate>Wed, 13 Nov 2024 05:52:27 GMT</pubDate>
    </item>
    <item>
      <title>VSCode 安装 hugginface relik 库时出错</title>
      <link>https://stackoverflow.com/questions/79182549/vscode-install-error-for-the-hugginface-relik-library</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79182549/vscode-install-error-for-the-hugginface-relik-library</guid>
      <pubDate>Tue, 12 Nov 2024 19:53:20 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch + Ray Tune 报告 ImplicitFunc 太大，不知道哪个引用很大</title>
      <link>https://stackoverflow.com/questions/79181943/pytorch-ray-tune-reporting-implicitfunc-is-too-large-no-idea-which-reference</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79181943/pytorch-ray-tune-reporting-implicitfunc-is-too-large-no-idea-which-reference</guid>
      <pubDate>Tue, 12 Nov 2024 16:21:39 GMT</pubDate>
    </item>
    <item>
      <title>输入数据类型与 SHAP 中请求的输入类型不匹配</title>
      <link>https://stackoverflow.com/questions/79181696/input-data-type-does-not-match-the-requested-input-type-in-shap</link>
      <description><![CDATA[我创建了一个自动编码器模型，而不是使用 Model()。
但我想分析输入矩阵的元素特征，以估计每个元素对潜在空间值的贡献。我使用 SHAP 深度解释器进行分析。但我自己创建的模型与 SHAP 中请求的数据类型不匹配。
我想问是否有其他 SHAP 算法可以使用 tensorflow.tensor 而不是 keras.tensor。
错误信息：
raise ValueError(
ValueError：所有 `inputs` 值都必须是 KerasTensors。收到：inputs=[[[ 0.5075143 1.1158173 0.27439427 ... 0.44567809 0.82088786

warnings.warn(&quot;您的 TensorFlow 版本比 2.4.0 新，因此图形支持已在 Eager 模式下被移除，并且一些静态图可能不受支持。请参阅 PR #1483 进行讨论。&quot;)
multiprocessing.pool.RemoteTraceback: 

]]></description>
      <guid>https://stackoverflow.com/questions/79181696/input-data-type-does-not-match-the-requested-input-type-in-shap</guid>
      <pubDate>Tue, 12 Nov 2024 15:12:36 GMT</pubDate>
    </item>
    <item>
      <title>当我想运行 HuggingFace 模型时，Jupyter Notebook 崩溃了</title>
      <link>https://stackoverflow.com/questions/79181010/jupyter-notebook-is-crashing-when-i-want-to-run-huggingface-models</link>
      <description><![CDATA[我使用 Jupyter Notebook 运行 HuggingFace 的一些 ML 模型。
我使用的是 Mac（M2 芯片，内存 32 GB）
这是我的代码：
import torch
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline

# 步骤 1：从 Hugging Face 的 Model Hub 中选择一个预先训练的 NER 模型
# 这里我们使用&quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;，这是一个在 CoNLL-2003 数据集上微调的常见 NER 模型
model_name = &quot;dbmdz/bert-large-cased-finetuned-conll03-english&quot;

# 步骤 2：加载模型和 tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)

在步骤 2 中，我的内核总是崩溃。我尝试了几种模型，但总是一样。这是错误：
内核重新启动
&lt;kernel name&gt; 的内核似乎已死。它将自动重新启动。

你能帮帮我吗？
我的内存没有满，笔记本电脑是全新的。]]></description>
      <guid>https://stackoverflow.com/questions/79181010/jupyter-notebook-is-crashing-when-i-want-to-run-huggingface-models</guid>
      <pubDate>Tue, 12 Nov 2024 12:02:09 GMT</pubDate>
    </item>
    <item>
      <title>值错误：序列模型‘sequential_3’尚未定义输入形状</title>
      <link>https://stackoverflow.com/questions/79180267/value-error-sequential-model-sequential-3-has-no-defined-input-shape-yet</link>
      <description><![CDATA[导致“Sequential 模型没有定义的输入形状 1”错误的常见错误或遗漏是什么？
预处理层（如 resize_and_rescale 或 data_augmentation）是否会影响模型第一层的 input_shape？
Keras Sequential 模型第一层的 input_shape 参数的用途是什么？
input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)
n_classes = 3

model = models.Sequential([
resize_and_rescale,
data_augmentation,
layer.Conv2D(32, kernel_size = (3,3),activation=&#39;relu&#39;, input_shape = input_shape),
layers.MaxPooling2D((2, 2)),
层。Conv2D（64，kernel_size =（3,3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，kernel_size =（3,3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Conv2D（64，（3，3），激活=&#39;relu&#39;），
层。MaxPooling2D（（2，2）），
层。Flatten（），
层。Dense（64，激活=&#39;relu&#39;），
层。Dense（n_classes，激活=&#39;softmax&#39;),
])

错误显示
值错误：顺序模型“sequential_3”尚未定义输入形状
]]></description>
      <guid>https://stackoverflow.com/questions/79180267/value-error-sequential-model-sequential-3-has-no-defined-input-shape-yet</guid>
      <pubDate>Tue, 12 Nov 2024 08:02:25 GMT</pubDate>
    </item>
    <item>
      <title>MLmetrics F1_Score 函数</title>
      <link>https://stackoverflow.com/questions/79179803/mlmetrics-f1-score-function</link>
      <description><![CDATA[我试图弄清楚当 y_pred 值非二进制时，MLmetrics 库中的 F1_Score 函数如何工作。
例如：
library(MLmetrics)
y &lt;- c(1,1,1,1,1,0,0,0,0,0)
x &lt;- c(1, 0.8, 0.654, 0.99, 0.75, 0.1, 0.3, 0.6, 0.05, 0.2)
x_preds &lt;- ifelse(x &lt; 0.5, 0, 1)
getF1 &lt;- F1_Score(y_true=y, y_pred=x, positive=&quot;1&quot;)
getF2 &lt;- F1_Score(y_true=y, y_pred=x_preds, positive=&quot;1&quot;)

print(getF1)
print(getF2)

给出 getF1=0.3333333 和 getF2 = 0.9090909
R 文档中提供的函数示例旨在计算我所称的 getF2，其中我已明确指定如何根据 0.5 阈值将概率分数分配给任一类标签。我不清楚的是，如果没有指定此阈值（getF1），它如何计算 F1 分数。有人能解释一下，如果在调用 F1_Score 函数之前保留概率分数，并且不将其转换为二进制，那么该函数默认会做什么吗？我无论如何也想不出它是如何得到 0.3333333 的。]]></description>
      <guid>https://stackoverflow.com/questions/79179803/mlmetrics-f1-score-function</guid>
      <pubDate>Tue, 12 Nov 2024 04:35:57 GMT</pubDate>
    </item>
    <item>
      <title>Vertex AI：Automl-tabular 模板不断给我一个错误</title>
      <link>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</link>
      <description><![CDATA[我正在尝试使用 Google 的 AutoML 产品 (VertexAI) 构建机器学习模型。
我已成功上传我的数据集 - 见下图。

但是，当我尝试使用 AutoML 模板为表格回归创建管道运行时，管道失败。我将在 VertexAI 上展示步骤，我只是使用默认设置而不进行任何更改：





我运行的第一个管道失败了。


我将调试 json 粘贴到 ChatGPT 中。它告诉我尝试将机器类型从 n1-standard-8 或 n1-highmem-8 更改为 n1-standard-4。我试过了，但管道仍然失败。我还确保计算服务已启用正确的设置。
]]></description>
      <guid>https://stackoverflow.com/questions/79177501/vertex-ai-automl-tabular-template-keeps-giving-me-an-error</guid>
      <pubDate>Mon, 11 Nov 2024 11:41:07 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程回归实现中矩阵乘法的`ValueError`</title>
      <link>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</link>
      <description><![CDATA[我正在使用平方指数核在 Python 中实现高斯过程回归 (GPR) 模型。但是，我在 predict 方法的矩阵乘法步骤中遇到了 ValueError，特别是在尝试计算平均预测时。
我看到的错误是：
ValueError：matmul：输入操作数 1 在其核心维度 0 中不匹配，gufunc 签名为 
(n?,k),(k,m?)-&gt;(n?,m?)（大小 10 与 100 不同）

代码详细信息
以下是此错误中涉及的代码的细分：
import numpy as np

class SquaredExponentialKernel:
def __init__(self, length_scale=1.0, variance=1.0):
self.length_scale = length_scale
self.variance = variance

def __call__(self, x1, x2):
dist_sq = np.sum((x1 - x2)**2)
return self.variance * np.exp(-0.5 * dist_sq / self.length_scale**2)

def cov_matrix(x1, x2, cov_function) -&gt; np.array:
返回 np.array([[cov_function(a, b) for a in x1] for b in x2])

class GPR:
def __init__(self, data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma: float = 0):
self.noise = white_noise_sigma
self.data_x = data_x
self.data_y = data_y
self.covariance_function = covariance_function
self._inverse_of_covariance_matrix_of_input_noise_adj = np.linalg.inv(
cov_matrix(data_x, data_x, covariance_function) + self.noise * np.identity(len(self.data_x))
)
self._memory = None

def predict(self, test_data: np.ndarray) -&gt;; np.ndarray:
KXX_star = cov_matrix(test_data, self.data_x, self.covariance_function)
KX_starX_star = cov_matrix(test_data, test_data, self.covariance_function)
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)
cov_test_data = KX_starX_star - KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ KXX_star.T)
var_test_data = np.diag(cov_test_data)
self._memory = {&#39;mean&#39;: mean_test_data, &#39;covariance_matrix&#39;: cov_test_data, &#39;variance&#39;: var_test_data}
返回 mean_test_data

# 测试数据
np.random.seed(69)
data_x = np.linspace(-5, 5, 10).reshape(-1, 1)
data_y = np.sin(data_x) + 0.1 * np.random.randn(10, 1)

# 实例化并预测
gpr_se = GPR(data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma=0.1)
test_data = np.linspace(-6, 6, 100).reshape(-1, 1)
mean_predictions = gpr_se.predict(test_data)

维度细分
这是矩阵乘法的维度分析，其中误差发生：

KXX_star 计算为 cov_matrix(test_data, self.data_x, self.covariance_function)，结果形状为 (100, 10)。
self._inverse_of_covariance_matrix_of_input_noise_adj 在 __init__ 方法中计算，形状为 (10, 10)。
self.data_y 形状为 (10, 1)。

有问题的行是：
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)

这应该产生形状为 (100, 1) 的结果，因为：

KXX_star 具有形状 (100, 10)，
(self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y) 导致形状为 (10, 1)。

当矩阵乘法的维度似乎对齐时，为什么我在这里收到维度不匹配错误？我该如何修复它？
我预计这个矩阵乘法能够正常工作，因为尺寸在纸面上看起来是兼容的：KXX_star (100, 10) 乘以 (10, 1) 应该得到 (100, 1)。然而，错误表明尺寸不匹配，这意味着某些东西没有按预期对齐。我检查了 self.data_y、self._inverse_of_covariance_matrix_of_input_noise_adj 和 KXX_star 的形状。还尝试重塑 data_y 以确保它始终为 (10, 1)，但错误仍然存​​在。我期望获得 test_data 的平均预测值作为形状为 (100, 1) 的向量，并且没有任何维度问题。]]></description>
      <guid>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</guid>
      <pubDate>Sun, 10 Nov 2024 15:14:18 GMT</pubDate>
    </item>
    <item>
      <title>我应该安装哪个版本的 torch 和 torchtext [关闭]</title>
      <link>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</link>
      <description><![CDATA[我使用的是 Windows，python 版本为 3.11.4，pandas 版本为 2.2.1

我尝试安装 torch 和 torchtext，但总是出现依赖错误。

这两个版本应该安装哪个？
错误：pip 的依赖解析器目前没有考虑所有已安装的软件包。此行为是以下依赖冲突的根源。

torchaudio 2.1.2 需要 torch==2.1.2，但您有不兼容的 torch 2.1.0+cu118。

成功安装 torch-2.1.0+cu118


那么我在哪里可以找到与 torch 2.1.0 兼容的 torchaudio 版本？
torchaudio pypl 没有像 torchtext 和 torchdata 这样的兼容表。]]></description>
      <guid>https://stackoverflow.com/questions/79171450/which-version-of-torch-and-torchtext-should-i-insitall</guid>
      <pubDate>Fri, 08 Nov 2024 20:20:10 GMT</pubDate>
    </item>
    <item>
      <title>无法使用 transformers 在本地加载模型</title>
      <link>https://stackoverflow.com/questions/79169173/fail-to-use-transformers-to-load-model-locally</link>
      <description><![CDATA[我已使用 transformers 函数将整个模型
下载到本地目录：/home/marcus/Desktop/project/OCR_transformer_practices/models/moondream2
代码如下：
from huggingface_hub import snap_download

# 指定模型 ID 和修订版本
model_id = &quot;vikhyatk/moondream2&quot;
revision = &quot;2024-08-26&quot;

# 指定要下载模型的目录
download_directory = &quot;/home/marcus/Desktop/project/OCR_transformer_practices/models/moondream2&quot; # 将其更改为您想要的路径

# 将模型文件下载到指定目录
local_model_path = snapping_download(repo_id=model_id, revision=revision, local_dir=download_directory)

模型保存在目录中：
当我使用以下代码通过 transformers 从本地目录加载模型时：
from PIL import Image
from transformers import AutoTokenizer, AutoModelForCausalLM
from pathlib import Path
import os

# 获取父目录
project_dir = Path(__file__).parent
model_folder_name = &#39;models/moondream2&#39;
model_dir = str(project_dir/model_folder_name)

# 使用正确的模型 ID 加载 tokenizer 和模型
# model_id = &quot;vikhyatk/moondream2&quot;
tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_dir, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained( pretrained_model_name_or_path=model_dir, use_safetensors=True, trust_remote_code=True,)

弹出错误消息：
回溯（最近一次调用最后一次）：
文件“/home/marcus/Desktop/project/OCR_transformer_practices/moondream_test.py”，第 15 行，位于&lt;module&gt;
model = AutoModelForCausalLM.from_pretrained( pretrained_model_name_or_path=model_dir, use_safetensors=True, trust_remote_code=True,)
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py&quot;，第 553 行，在 from_pretrained 中
model_class = get_class_from_dynamic_module(
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;，第 552 行，在 get_class_from_dynamic_module 中
return get_class_in_module(class_name, final_module, force_reload=force_download)
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;，第 237 行，在 get_class_in_module 中
module_files: List[Path] = [module_file] + sorted(map(Path, get_relative_import_files(module_file)))
文件 &quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;，第 128 行，在 get_relative_import_files 中
new_imports.extend(get_relative_imports(f))
文件&quot;/home/marcus/Desktop/project/OCR_transformer_practices/.venv/lib/python3.10/site-packages/transformers/dynamic_module_utils.py&quot;, line 97, in get_relative_imports
with open(module_file, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:
FileNotFoundError: [Errno 2] 没有这样的文件或目录：&#39;/home/marcus/.cache/huggingface/modules/transformers_modules/moondream2/fourier_features.py&#39;

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/79169173/fail-to-use-transformers-to-load-model-locally</guid>
      <pubDate>Fri, 08 Nov 2024 07:38:50 GMT</pubDate>
    </item>
    <item>
      <title>使用 Tensorflow 在低资源语言和葡萄牙语之间进行机器翻译的语言模型</title>
      <link>https://stackoverflow.com/questions/78911175/a-language-model-for-machine-translation-between-a-low-resource-language-and-por</link>
      <description><![CDATA[我正在尝试使用 Tensorflow 训练一种语言模型，用于在低资源语言和葡萄牙语之间进行机器翻译。不幸的是，我收到以下错误：
PS C:\Users\myuser\PycharmProjects\teste&gt; python .\tensorflow_model.py 
2024-08-23 21:29:50.839647：I tensorflow/core/platform/cpu_feature_guard.cc:182] 此 TensorFlow 二进制文件经过优化，可在性能关键型操作中使用可用的 CPU 指令。
要启用以下指令：SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA，在其他操作中，使用适当的编译器标志重建 TensorFlow。
回溯（最近一次调用）：
文件“.\tensorflow_model.py”，第 52 行，位于 &lt;module&gt;
数据集 = tf.data.Dataset.from_tensor_slices((src_tensor, tgt_tensor)).shuffle(BUFFER_SIZE)
文件 &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py&quot;，第 831 行，在 from_tensor_slices 中
返回 from_tensor_slices_op._from_tensor_slices(tensors, name)
文件 &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\from_tensor_slices_op.py&quot;，第 25 行，在 _from_tensor_slices 中
返回 _TensorSliceDataset(tensors, name=name)
文件&quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\data\ops\from_tensor_slices_op.py&quot;，第 45 行，在 __init__
batch_dim.assert_is_compatible_with(
File &quot;C:\Users\myuser\PycharmProjects\teste\.venv\lib\site-packages\tensorflow\python\framework\tensor_shape.py&quot;，第 300 行，在 assert_is_compatible_with
raise ValueError(&quot;Dimensions %s and %s are notcompatible&quot; %
ValueError: Dimensions 21 and 22 are notcompatible

我该如何克服这个错误？
import tensorflow as tf
import numpy as np
import re
import os

# Clean数据
def preprocess_sentence(sentence):
sentence = sentence.lower().strip()
sentence = re.sub(r&quot;([?.!,¿])&quot;, r&quot; \1 &quot;, sentence)
sentence = re.sub(r&#39;[&quot; &quot;]+&#39;, &quot; &quot;, sentence)
sentence = re.sub(r&quot;[^a-zA-Z?.!,¿]+&quot;, &quot; &quot;, sentence)
sentence = sentence.strip()
sentence = &#39;&lt;start&gt; &#39; + sentence + &#39; &lt;end&gt;&#39;
返回句子

#加载数据的函数
def load_data(file_path_src, file_path_tgt):
src_sentences = open(file_path_src, &#39;r&#39;, encoding=&#39;utf-8&#39;).read().strip().split(&#39;\n&#39;)
tgt_sentences = open(file_path_tgt, &#39;r&#39;, encoding=&#39;utf-8&#39;).read().strip().split(&#39;\n&#39;)

src_sentences = [preprocess_sentence(sentence) for sentence in src_sentences]
tgt_sentences = [preprocess_sentence(sentence) for sentence in tgt_sentences]

返回 src_sentences, tgt_sentences

#加载数据
src_sentences, tgt_sentences = load_data(&#39;src_language.txt&#39;, &#39;portuguese.txt&#39;)

#标记化
src_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=&#39;&#39;)
tgt_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=&#39;&#39;)

src_tokenizer.fit_on_texts(src_sentences)
tgt_tokenizer.fit_on_texts(tgt_sentences)

src_tensor = src_tokenizer.texts_to_sequences(src_sentences)
tgt_tensor = tgt_tokenizer.texts_to_sequences(tgt_sentences)

src_tensor = tf.keras.preprocessing.sequence.pad_sequences(src_tensor, padding=&#39;post&#39;)
tgt_tensor = tf.keras.preprocessing.sequence.pad_sequences(tgt_tensor, padding=&#39;post&#39;)

BUFFER_SIZE = len(src_tensor)

#创建数据集
dataset = tf.data.Dataset.from_tensor_slices((src_tensor, tgt_tensor)).shuffle(BUFFER_SIZE) 
]]></description>
      <guid>https://stackoverflow.com/questions/78911175/a-language-model-for-machine-translation-between-a-low-resource-language-and-por</guid>
      <pubDate>Sun, 25 Aug 2024 12:06:55 GMT</pubDate>
    </item>
    <item>
      <title>无法在 python 中安装 lap==0.4.0 库</title>
      <link>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76463707/unable-to-install-lap-0-4-0-library-in-python</guid>
      <pubDate>Tue, 13 Jun 2023 09:55:26 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow TypeError：无法解压不可迭代的浮点对象</title>
      <link>https://stackoverflow.com/questions/61980349/tensorflow-typeerror-cannot-unpack-non-iterable-float-object</link>
      <description><![CDATA[我正在使用 tensorflow V2.2，在执行 model.evaluate 时遇到 TyepError。有人能告诉我问题可能出在哪里吗？下面显示了执行和错误消息的屏幕截图。
]]></description>
      <guid>https://stackoverflow.com/questions/61980349/tensorflow-typeerror-cannot-unpack-non-iterable-float-object</guid>
      <pubDate>Sun, 24 May 2020 00:50:30 GMT</pubDate>
    </item>
    <item>
      <title>R-派对套餐：cforest 真的是装袋吗？</title>
      <link>https://stackoverflow.com/questions/34293471/r-party-package-is-cforest-really-bagging</link>
      <description><![CDATA[我正在使用“party”包来创建回归树的随机森林。
我创建了一个 ForestControl 类，以限制我的树 (ntree)、节点 (maxdepth) 和用于拟合树 (mtry) 的变量的数量。
我不确定的一件事是 cforest 算法是否对其生成的每棵树使用我的训练集的子集。
我在文档中看到它正在装袋，所以我假设它应该如此。但我不确定我是否理解了该函数中的“子集”输入是什么。
我对使用 ctree 得到的结果也感到困惑：绘制树时，我看到我的训练集的所有变量都分类在不同的终端树节点中，而我原本预计它也只使用一个子集。
所以我的问题是，cforest 是否与 ctree 做同样的事情，或者它真的在打包我的训练集？
提前感谢您的帮助！
Ben]]></description>
      <guid>https://stackoverflow.com/questions/34293471/r-party-package-is-cforest-really-bagging</guid>
      <pubDate>Tue, 15 Dec 2015 15:46:47 GMT</pubDate>
    </item>
    </channel>
</rss>