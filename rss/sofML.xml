<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 29 Jun 2024 03:17:36 GMT</lastBuildDate>
    <item>
      <title>使用 X = tester.drop('label', axis=1) 和 y = tester['label'] 拆分数据时出现 KeyError: “['label'] not found in axis”</title>
      <link>https://stackoverflow.com/questions/78684880/keyerror-label-not-found-in-axis-when-splitting-data-with-x-tester-drop</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78684880/keyerror-label-not-found-in-axis-when-splitting-data-with-x-tester-drop</guid>
      <pubDate>Sat, 29 Jun 2024 01:40:35 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归梯度下降中的不同成本函数算法与成本函数本身</title>
      <link>https://stackoverflow.com/questions/78684727/logistic-regression-different-cost-function-algorithm-in-gradient-descent-vs-cos</link>
      <description><![CDATA[为什么在逻辑回归中成本函数看起来像这样：
在此处输入图像描述
但是，在实现梯度下降时，成本函数基本上被简化为不包含对数的线性回归成本函数：
在此处输入图像描述
我完全理解为什么在逻辑回归中对数是必要的，因为存在多个局部最小值并且可能无法达到全局最小值。那么为什么它们不存在于梯度下降算法中呢？
我原本以为梯度下降中的成本函数是相同的。]]></description>
      <guid>https://stackoverflow.com/questions/78684727/logistic-regression-different-cost-function-algorithm-in-gradient-descent-vs-cos</guid>
      <pubDate>Fri, 28 Jun 2024 23:30:17 GMT</pubDate>
    </item>
    <item>
      <title>kdb+/q q/kdb+ 中的机器学习</title>
      <link>https://stackoverflow.com/questions/78684235/kdb-q-machine-learning-in-q-kdb</link>
      <description><![CDATA[如果我在端口 5012 的 hdb 进程中存储了一个表。
我已经安装了 PyKX 并将其成功导入到终端中的 python 提示符中。
然后我连接到我的 host=‘localhost’, port=5012  并运行一个简单的查询以从 hdb 返回我的数据 q(‘{select name,price,volume,vwap from tab where date&gt;2024.01.01}’)
然后如何在 python 机器学习算法之一中使用这些数据。您如何将表数据转换为可用的 python 数据点，然后输入到您选择的模型中？您是否必须提取每列数据并保存为某种类型的变量，例如在 q 进程中运行 exec  语句？]]></description>
      <guid>https://stackoverflow.com/questions/78684235/kdb-q-machine-learning-in-q-kdb</guid>
      <pubDate>Fri, 28 Jun 2024 19:47:48 GMT</pubDate>
    </item>
    <item>
      <title>用于安装机器的优化模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78684160/optimization-model-for-fitting-a-machine</link>
      <description><![CDATA[我正在从事这个项目，目标是让机器自动对准一个非常具体的点。无需过多细节，我能够轻松确定 0 到 1 范围内的对准程度，并且能够在 x 轴和 y 轴上移动我的机器，并立即看到这个“对准率”如何增加或减少。这在理论上似乎很简单，但有一些问题让我在尝试让机器对准时不知所措。
我的第一个想法是尝试强行使用它。机器永远不会从 0 对准开始，所以我在想我可以让它在给定轴上任意向一个方向移动，看看对准度量是增加还是减少。如果从非零值开始，它总是会看到一些增加或减少。如果它增加，则再次朝该方向移动，如果它减少，则返回并尝试另一个方向，如果它在两个方向上都减少，则停止。我会在另一个轴上重复此操作，效果会很好。
但是，由于对齐的特殊性，我被告知这极易陷入局部最大值。所以我的下一个想法是梯度下降。我将对齐参数设置为负数，并尝试找到最小值。但我以前从未使用过梯度下降，从我在网上看到的 Python 示例中，梯度下降的每个用例都需要了解函数的梯度才能使用。我不知道这一点，所以我不知道梯度下降是否是我想要的。
我想我只是问是否有人对这种情况有任何优化建议，可以推荐仅在不断构建的数据库上工作，而不是预先建立的公式或信息数据库。一开始我只知道当前 (x, y) 方向和当前对齐比率（从 0 到 1），我必须通过进行细微调整并观察这对系统的影响，使其尽可能接近 1，但我还必须避免陷入局部最大值而无法达到最佳状态。也许最好的选择是实现类似蛮力的东西，但强制它跳过多个步骤并重复，如果“最佳”比率小于给定数字（如 0.9 或类似数字）？我不知道。任何帮助都将不胜感激，即使它只是一份其他优化策略的列表，让我可以在自己的时间查找。我甚至不知道其中大多数的正式术语，所以研究很痛苦。]]></description>
      <guid>https://stackoverflow.com/questions/78684160/optimization-model-for-fitting-a-machine</guid>
      <pubDate>Fri, 28 Jun 2024 19:23:42 GMT</pubDate>
    </item>
    <item>
      <title>使用 Yamnet 检测乐器</title>
      <link>https://stackoverflow.com/questions/78684112/detection-of-musical-instruments-using-yamnet</link>
      <description><![CDATA[我的目标是用人工智能（机器学习）检测乐器。
我目前正在使用 Yamnet 模型进行推理，但它的类别范围非常广泛，例如“咆哮”、“打印机”和“钢琴”。我想知道这是否会导致它在检测乐器时不太精确，因为乐器类别只是总类别的一小部分。
Kaggle 上对 Yamnet 模型的描述指出：

您应该进行一定程度的微调和校准，以使 YAMNet 可用于您构建的任何系统。

还有另一个名为 NSynth 的模型，它拥有大量乐器样本数据集，但它用于合成新声音，而不是对乐器进行分类/检测。
在这种情况下，使用 NSynth 对 Yamnet 模块进行微调是否有意义？]]></description>
      <guid>https://stackoverflow.com/questions/78684112/detection-of-musical-instruments-using-yamnet</guid>
      <pubDate>Fri, 28 Jun 2024 19:08:48 GMT</pubDate>
    </item>
    <item>
      <title>如何应用 mlflow 来处理 scipy 模型？</title>
      <link>https://stackoverflow.com/questions/78682858/how-can-i-apply-mlflow-to-handle-scipy-models</link>
      <description><![CDATA[我已经使用 Python 中的 scipy 实现了 ML 模型。该模型解决了线性回归估计问题，该问题将回归权重限制在给定区间内。
一旦模型校准完毕，我就会存储 scipy.optimize 返回的权重，并像这样使用它们来预测新样本：
import numpy as np
def predict(scipy_model, x_test):
w = scipy_model.x
y_pred = np.sum(w * x_test, axis=1)
return y_pred

我想使用 mlflow 在生产环境中部署此模型。但是，我在文档中没有看到如何将 scipy 与 mlflow 集成。
如果不可能，我可以创建一个具有自定义 train 和 predict 函数的自定义“模型”类并将其与 mlflow 集成吗？]]></description>
      <guid>https://stackoverflow.com/questions/78682858/how-can-i-apply-mlflow-to-handle-scipy-models</guid>
      <pubDate>Fri, 28 Jun 2024 13:49:01 GMT</pubDate>
    </item>
    <item>
      <title>使用机器学习确定车辆类别[关闭]</title>
      <link>https://stackoverflow.com/questions/78682086/vehicle-class-determination-using-machine-learning</link>
      <description><![CDATA[如果我的数据集仅包含以下信息：路段容量、路段行程时间、起点-终点行程时间 (ODTT)、平均行程长度和持续时间以及拥堵程度。
并且没有道路图像。我还能使用 ML 将车辆类型分为重型货车和轻型车辆吗？
我还没有尝试过这种方法]]></description>
      <guid>https://stackoverflow.com/questions/78682086/vehicle-class-determination-using-machine-learning</guid>
      <pubDate>Fri, 28 Jun 2024 11:02:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在使用 Haarcascades 时提高我的结果 [关闭]</title>
      <link>https://stackoverflow.com/questions/78682011/how-to-improve-my-results-while-using-haarcascades</link>
      <description><![CDATA[来自 https://github.com/opencv/opencv/tree/master/data/haarcascades
我一直在使用 smile.xml 文件，但它工作得不太准确。
我想知道我可以做些什么来改进它，以便它可以在现实生活中准确实现。
此外，我如何为图像添加标签？
我的代码：
import cv2 as cv
import numpy as np
smile_cascade = cv.CascadeClassifier(&#39;haarcascade_smile.xml&#39;)
face_cascade = cv.CascadeClassifier(&#39;haarcascade_frontalface_default.xml&#39;)
cap = cv.VideoCapture(0)
当 True 时：
ret,img = cap.read()
gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)
faces = face_cascade.detectMultiScale(gray,1.3,5)
对于 (x,y,w,h) 中的 faces:
cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
roi_gray = gray[y:y+h,x:x+w]
roi_color = img[y:y+h,x:x+w]
smiles = smile_cascade.detectMultiScale(gray, 
scaleFactor=1.3, 
minNeighbors=40, 
minSize=(30, 30),
flags=cv.CASCADE_SCALE_IMAGE)
对于 (ex,ey,ew,eh) 中的微笑：
cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)
cv.imshow(&#39;img&#39;,img)
k = cv.waitKey(30) &amp; 0xFF
if k ==27:
break
cap.release()
cv.destroyAllWindows()

一直在我的脸上而不是嘴巴上画矩形。]]></description>
      <guid>https://stackoverflow.com/questions/78682011/how-to-improve-my-results-while-using-haarcascades</guid>
      <pubDate>Fri, 28 Jun 2024 10:47:20 GMT</pubDate>
    </item>
    <item>
      <title>Microsoft Fabric 数据科学 - 如何使用应用模型向导在 Delta 表中保存概率和预测？</title>
      <link>https://stackoverflow.com/questions/78680642/microsoft-fabric-data-science-how-to-save-probabilities-along-with-predictions</link>
      <description><![CDATA[我为二元分类任务创建了一个逻辑回归模型。该模型在预测方面表现良好，我得到了我想要的结果。但随着业务需求的变化，我也想获得每个类别的概率。我使用 predict_proba 方法来获取 2 个类别的概率。这适用于测试数据。我得到了预测及其概率。我将实验保存为 ML 模型（使用 ML 向导中的应用此模型）并按照以下步骤操作：

选择用于评分的源数据
将数据正确映射到我的 ML 模型的输入
指定我的模型输出的目标
创建一个使用 PREDICT 生成预测结果并将其作为增量表存储到 Lakehouse 的笔记本

但是，我只在我的增量表中获得了预测，而没有概率。有没有办法我也可以获得概率？
我按照此链接上的说明进行操作：链接
我注意到的另一件事是在实验和模型的输出模式上，数据类型是 int 32，这对于预测来说是正确的，但对于概率来说应该是大小为 [-1,2] 的数组。
为了以防万一，我还将链接附加到我的笔记本中：笔记本。
]]></description>
      <guid>https://stackoverflow.com/questions/78680642/microsoft-fabric-data-science-how-to-save-probabilities-along-with-predictions</guid>
      <pubDate>Fri, 28 Jun 2024 04:22:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么当我尝试从 (.fif) 文件进行可视化时，会在 mne-python 中收到此运行时警告？</title>
      <link>https://stackoverflow.com/questions/78679466/why-am-i-getting-this-runtime-warning-in-mne-python-while-trying-to-visualize-fr</link>
      <description><![CDATA[我正在努力使用 mne-python 进行预处理的 eeg 通道可视化部分。这些 (&#39;.fif&#39;) 文件是从 (&#39;.mat&#39;) 文件预处理的。这是我在 kaggle 笔记本中使用的代码：
import mne
import os
import numpy as np

# 定义存储 .fif 文件的目录
data_dir = &#39;/kaggle/input/preproccesed-dataset/128-channel-resting(2.0)/kaggle/working/preprocessed_mat_output_directory&#39;

# 列出目录中的所有 .fif 文件
fif_files = [f for f in os.listdir(data_dir) if f.endswith(&#39;-epo.fif&#39;)]

# 加载每个 .fif 文件
epochs_list = [mne.read_epochs(os.path.join(data_dir, fif_file)) for fif_file in fif_files]

# 连接所有将 epochs 合并为单个 Epochs 对象
all_epochs = mne.concatenate_epochs(epochs_list)

# 预处理：应用高通滤波器
all_epochs.filter(l_freq=1.0, h_freq=40.0)

# 执行 ICA
ica = mne.preprocessing.ICA(n_components=20, random_state=97)
ica.fit(all_epochs)

# 根据检查或自动标准手动排除组件
ica.exclude = [0, 1] # 根据已识别的工件组件进行调整

# 将 ICA 应用于 epochs
all_epochs = ica.apply(all_epochs)

# 绘制诱发反应
evoked = all_epochs.average()
evoked.plot()

# 绘制 PSD
fig_psd = all_epochs.plot_psd(fmin=1.0, fmax=40.0, average=True, spatial_colors=False)

# 绘制地形图
fig_topo = evoked.plot_topomap(times=[0.1, 0.2, 0.3], ch_type=&#39;eeg&#39;, average=0.05)

# 计算并绘制 TFR
from mne.time_frequency import tfr_morlet
freqs = np.arange(6, 30, 3)
n_cycles = freqs / 2
power = tfr_morlet(all_epochs, freqs=freqs, n_cycles=n_cycles, return_itc=False, average=True)
fig_tfr = power.plot([0])

# 确保保存目录存在
save_dir = &#39;/kaggle/working/mat_visuals/&#39;
os.makedirs(save_dir, exist_ok=True) # 如果目录不存在，则创建目录

# 保存处理后的数据
all_epochs.save(os.path.join(save_dir, &#39;processed-epochs.fif&#39;), overwrite=True)
evoked.save(os.path.join(save_dir, &#39;evoked-ave.fif&#39;), overwrite=True)

# 如果需要，保存图形
fig_psd.savefig(os.path.join(save_dir, &#39;psd_plot.png&#39;))
fig_topo.savefig(os.path.join(save_dir, &#39;topomap_plot.png&#39;))
fig_tfr.savefig(os.path.join(save_dir, &#39;tfr_plot.png&#39;))

这是我收到的错误：
Runtime-ERROR
我尝试更改这两行代码：
# 绘制 PSD
fig_psd = all_epochs.plot_psd(fmin=1.0, fmax=40.0, average=False, spatial_colors=False)

# 绘制地形图
fig_topo = evoked.plot_topomap(times=False, ch_type=&#39;eeg&#39;, average=0.05)

我还尝试阅读以下 2 个文档：
neurotechedu , mne-python
但我仍然找不到任何解决方案。]]></description>
      <guid>https://stackoverflow.com/questions/78679466/why-am-i-getting-this-runtime-warning-in-mne-python-while-trying-to-visualize-fr</guid>
      <pubDate>Thu, 27 Jun 2024 19:16:05 GMT</pubDate>
    </item>
    <item>
      <title>Oracle 机器学习（OML）df_datetime 给出“未选择任何列”错误</title>
      <link>https://stackoverflow.com/questions/78678402/oracle-machine-learning-oml-df-datetime-gives-no-columns-are-selected-error</link>
      <description><![CDATA[如果有人能帮忙，我遇到了一些编码问题！我试图从 oml.Dataframe df 中获取 Datetime 类型。我试过这个代码：
 df = oml.sync(query=QUERY)
df_datetime = df.select_types(include=[&#39;oml.Datetime&#39;])

但我收到一个错误，提示没有选择任何列。我是否错误地使用了此功能？
我找到了一种解决方法
 df = oml.sync(query=QUERY)
df_datetime = []
for col, dtype in df.dtypes.items():
if dtype.__name__ == &#39;Datetime&#39;:
df_datetime.append(col)

这确实返回了 Datetime 对象，所以我知道它们存在。如果可以的话，我更愿意使用 select_types 方法，如果有人能向我解释我做错了什么。]]></description>
      <guid>https://stackoverflow.com/questions/78678402/oracle-machine-learning-oml-df-datetime-gives-no-columns-are-selected-error</guid>
      <pubDate>Thu, 27 Jun 2024 14:52:10 GMT</pubDate>
    </item>
    <item>
      <title>绘制预测掩码的问题</title>
      <link>https://stackoverflow.com/questions/78669554/issue-with-plotting-predicted-masks</link>
      <description><![CDATA[我目前正在进行一个深度学习项目“叶病分割”。我已经训练了一个模型超过 50 个时期，并获得了以下准确度和损失指标：
训练损失：19.4736，训练准确度：0.9395
验证损失：19.6197，验证准确度：0.9100
测试损失：19.6148，测试准确度：0.9123
但是，当我绘制预测的蒙版时，它们看起来不准确。我的绘图代码有问题吗？
def plot_predictions(model, images, mask, num_samples=5):
predictions = model.predict(images[:num_samples])
for i in range(num_samples):
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.title(&#39;真实图像&#39;)
plt.imshow(images[i])
plt.subplot(1, 3, 2)
plt.title(&#39;地面真相面具&#39;)
plt.imshow(masks[i], cmap=&#39;gray&#39;) # 假设面具已经是二进制的
plt.subplot(1, 3, 3)
plt.title(&#39;预测面具&#39;)
plt.imshow(predictions[i][:, :, 0], cmap=&#39;gray&#39;) # 转换预测面具转换为二进制
plt.show()

plot_predictions(model, test_images.numpy(), test_masks_L, num_samples=5)

原始图像-蒙版-预测蒙版
请检查我的代码并帮助找出可能导致此问题的任何错误？]]></description>
      <guid>https://stackoverflow.com/questions/78669554/issue-with-plotting-predicted-masks</guid>
      <pubDate>Tue, 25 Jun 2024 21:18:52 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 skimage imsave 保存重建的二进制图像</title>
      <link>https://stackoverflow.com/questions/77248571/how-to-save-a-reconstructed-binary-image-using-skimage-imsave</link>
      <description><![CDATA[我一直在尝试使用 skimage 库对图像进行预处理以进行特征提取。但我无法保存图像，因为它给出错误提示“无法将模式 F 写入 PNG”
处理图像的函数在此处给出
def image_process(image):
img = imread(image)
rem_img = remove(img)
rgb_img = rgba2rgb(rem_img)
gray_img = rgb2gray(rgb_img)
bin_img = gray_img &lt; Threshold_otsu(gray_img)
Smooth_img = gaussian(bin_img)
Seed_px = np.copy(smooth_img)
Seed_px[1:-1 , 1:-1]=smooth_img.max()
Mask = Smooth_img
Filled_img = Reconstruction(seed_px , Mask , Method =&#39;erosion&#39;)

返回 filled_img

然后尝试使用 imsave 将图像保存在 BW 目录中
leaf_img = &quot;neem.jpg&quot;
processing_img = image_process(leaf_img)
imsave(&quot;BW/leaf.png&quot;, processing_img)

显示错误
KeyError Traceback (most recent call last)
File C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1299, in _save(im, fp, filename, chunk, save_all)
1298 try:
-&gt; 1299 rawmode, mode = _OUTMODES[mode]
1300 except KeyError as e:

KeyError: &#39;F&#39;

上述异常是导致以下异常的直接原因：

OSError Traceback (most recent call last)
Cell In[26], line 3
1 leaf_img = &quot;neem.jpg&quot;
2 processing_img = image_process(leaf_img)
----&gt; 3 imsave(&quot;BW/leaf.png&quot;, processing_img)

文件 C:\Python\lib\site-packages\skimage\io\_io.py:143，在 imsave(fname, arr, plugin, check_contrast, **plugin_args) 中
141 如果 check_contrast 和 is_low_contrast(arr):
142 warn(f&#39;{fname} 是低对比度图像&#39;)
--&gt; 143 返回 call_plugin(&#39;imsave&#39;, fname, arr, plugin=plugin, **plugin_args)

文件 C:\Python\lib\site-packages\skimage\io\manage_plugins.py:205，在 call_plugin(kind, *args, **kwargs) 中
202 除外 IndexError:
203 引发 RuntimeError(f&#39;无法找到 {kind} 的插件“{plugin}”。&#39;)
--&gt; 205 return func(*args, **kwargs)

文件 C:\Python\lib\site-packages\imageio\v3.py:139，在 imwrite(uri, image, plugin, extension, format_hint, **kwargs) 中
104 def imwrite(uri, image, *, plugin=None, extension=None, format_hint=None, **kwargs):
105 &quot;&quot;&quot;将 ndimage 写入给定的 URI。
106 
107 具体行为取决于所使用的文件类型和插件。要了解
(...)
136 
137 &quot;&quot;&quot;
--&gt; 139 使用 imopen(
140 uri,
141 &quot;w&quot;,
142 legacy_mode=False,
143 plugin=plugin,
144 format_hint=format_hint,
145 extension=extension,
146 ) 作为 img_file:
147coded = img_file.write(image, **kwargs)
149 returncoded

文件 C:\Python\lib\site-packages\imageio\core\v3_plugin_api.py:367，位于 PluginV3.__exit__(self, type, value, traceback)
366def __exit__(self, type, value, traceback) -&gt; None:
--&gt; 367 self.close()

文件 C:\Python\lib\site-packages\imageio\plugins\pillow.py:123，位于 PillowPlugin.close(self) 中
122 def close(self) -&gt; None:
--&gt; 123 self._flush_writer()
125 if self._image:
126 self._image.close()

文件 C:\Python\lib\site-packages\imageio\plugins\pillow.py:457，位于 PillowPlugin._flush_writer(self) 中
454 self.save_args[&quot;save_all&quot;] = True
455 self.save_args[&quot;append_images&quot;] = self.images_to_write
--&gt; 457 primary_image.save(self._request.get_file(), **self.save_args)
458 self.images_to_write.clear()
459 self.save_args.clear()

文件 C:\Python\lib\site-packages\PIL\Image.py:2431，位于 Image.save(self, fp, format, **params)
2428 fp =builtins.open(filename, &quot;w+b&quot;)
2430 尝试：
-&gt; 2431 save_handler(self, fp, filename)
2432 except Exception:
2433 if open_fp:

文件 C:\Python\lib\site-packages\PIL\PngImagePlugin.py:1302，在 _save(im, fp, filename, chunk, save_all) 中
1300 except KeyError as e:
1301 msg = f&quot;cannot write mode {mode} as PNG&quot;
-&gt; 1302 raise OSError(msg) from e
1304 #
1305 # write minimal PNG file
1307 fp.write(_MAGIC)

OSError: 无法在此处将模式 F 写入 PNG 类型


有人可以解释一下这里的问题是什么吗？解决方案将非常有帮助。提前谢谢了]]></description>
      <guid>https://stackoverflow.com/questions/77248571/how-to-save-a-reconstructed-binary-image-using-skimage-imsave</guid>
      <pubDate>Sat, 07 Oct 2023 06:06:06 GMT</pubDate>
    </item>
    <item>
      <title>SelectKBest 与 GaussianNB 结果不精确/不一致</title>
      <link>https://stackoverflow.com/questions/42193893/selectkbest-with-gaussiannb-not-precise-consistent-results</link>
      <description><![CDATA[我想使用 SelectKBest 选择 前 K 个特征 并运行 GaussianNB：
selection = SelectKBest(mutual_info_classif, k=300)

data_transformed = choice.fit_transform(data, labels)
new_data_transformed = choice.transform(new_data)

classifier = GaussianNB()
classifier.fit(data_transformed, labels)
y_predicted = classifier.predict(new_data)
acc = accuracy_score(new_data_labels, y_predicted)

但是，对于相同的数据，我没有得到一致的准确度结果。
准确度为：
0.61063743402354853
0.60678034916768164 
0.61733658140479086 
0.61652456354039786 
0.64778725131952908 
0.58384084449857898

对于相同的数据。我不进行拆分等。我只使用两组静态的 data 和 new_data。
为什么结果会有所不同？如何确保对相同的数据获得相同的准确度？ ]]></description>
      <guid>https://stackoverflow.com/questions/42193893/selectkbest-with-gaussiannb-not-precise-consistent-results</guid>
      <pubDate>Sun, 12 Feb 2017 22:11:29 GMT</pubDate>
    </item>
    <item>
      <title>如何提高机器学习的分类准确性</title>
      <link>https://stackoverflow.com/questions/41447104/how-to-improve-classification-accuracy-for-machine-learning</link>
      <description><![CDATA[我曾使用极限学习机进行分类，发现我的分类准确率只有 70% 以上，这导致我使用集成方法创建更多分类模型，并根据大多数模型的分类对测试数据进行分类。但是，这种方法只能将分类准确率提高一小步。请问还有哪些其他方法可用于提高二维线性不可分数据集的分类准确率？]]></description>
      <guid>https://stackoverflow.com/questions/41447104/how-to-improve-classification-accuracy-for-machine-learning</guid>
      <pubDate>Tue, 03 Jan 2017 15:41:10 GMT</pubDate>
    </item>
    </channel>
</rss>