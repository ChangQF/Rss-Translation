<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 20 May 2024 21:13:21 GMT</lastBuildDate>
    <item>
      <title>尽管进行了对数预处理和指数激活函数，为什么我的 DNN 模型仍无法学习两个输入的乘积？</title>
      <link>https://stackoverflow.com/questions/78508380/why-is-my-dnn-model-failing-to-learn-the-product-of-two-inputs-despite-logarithm</link>
      <description><![CDATA[我正在开发一个涉及前馈深度神经网络 (DNN) 的项目，该网络旨在学习两个输入值的乘积。从理论上讲，这应该很简单，尤其是使用我使用的预处理和激活函数。然而，该模型无法找到正确的权重和偏差，导致插值和外推过程中出现很高的错误。
型号详细信息：

输入：x1、x2
输出：y = x1 * x2
架构：

第 1 层：10 个神经元
第 2 层：10 个神经元
输出层：1 个神经元


激活函数：所有层的身份
预处理：没有直接应用于输入，但尝试使用对数和指数函数来辅助学习。
优化器：Adam，学习率为 0.1
损失函数：均方误差 (MSE)
训练数据：

x1 和 x2 范围：[-100, 100]
纪元：50
批量大小：32


权重和偏差初始化：随机

观察结果：
尽管有这些设置，模型仍会产生重大错误：

插值：

对于 x1 = 2 且 x2 = 1，预期输出为 2，但观察到的输出为 15.2477。
对于 x1 = 1 和 x2 = 2，预期输出为 2，但观察到的输出为 15.193。


外推：

对于 x1 = 150 和 x2 = 200，预期输出为 30,000，但观察到的输出为 -75.753。
对于 x1 = 200 和 x2 = 150，预期输出为 30,000，但观察到的输出为 -109.046。



尝试解决：

尝试了不同的权重初始化策略。
尝试了不同的学习率和优化器。
对输入应用对数预处理并使用指数激活函数。

代码片段：
将张量流导入为 tf
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从tensorflow.keras.optimizers导入Adam

# 模型定义
模型=顺序（[
    密集（10，激活=&#39;线性&#39;，input_shape=（2，）），
    密集（10，激活=&#39;线性&#39;），
    密集（1，激活=&#39;线性&#39;）
]）

# 编译模型
model.compile(优化器=Adam(0.1),loss=&#39;mse&#39;)

# 训练数据样本
将 numpy 导入为 np
x_train = np.random.uniform(-100, 100, (1000, 2))
y_train = x_train[:, 0] * x_train[:, 1]

# 训练模型
model.fit（x_train，y_train，epochs = 50，batch_size = 32）

# 测试模型
test_data = np.array([[150, 200], [200, 150]])
预测 = model.predict(test_data)
打印（预测）

问题：
鉴于设置和故障排除工作，为什么模型无法学习产品操作？架构或预处理步骤是否存在根本性错误？如何修改模型以正确学习两个输入的乘法？
&lt;小时/&gt;
非常感谢任何有助于解决此问题的见解或建议。]]></description>
      <guid>https://stackoverflow.com/questions/78508380/why-is-my-dnn-model-failing-to-learn-the-product-of-two-inputs-despite-logarithm</guid>
      <pubDate>Mon, 20 May 2024 19:09:52 GMT</pubDate>
    </item>
    <item>
      <title>探索医学影像中血癌和结核病检测的 AI 解决方案 [关闭]</title>
      <link>https://stackoverflow.com/questions/78507838/exploring-ai-solutions-for-blood-cancer-and-tb-detection-in-medical-imaging</link>
      <description><![CDATA[我正在研究我的最后一年项目 (FYP)，并且可以使用一些建议来为其选择最佳的人工智能系统。我的项目涉及以下任务之一：
血癌检测：
数据：血液样本的显微图像。
目标：利用图像分析准确检测不同类型的血癌。
结核病 (TB) 检测：
数据：X 射线图像。
目标：开发一种可靠的系统，通过胸部 X 光检查检测结核病。
鉴于这些任务，我需要一个能够有效处理医学图像分析的人工智能系统。以下是我正在考虑的一些具体事项：
预训练模型：是否有任何预训练模型或框架特别适合这些领域的医学图像分析？
框架：在 TensorFlow 和 PyTorch（或任何其他框架）之间，哪一个为处理医学图像提供更好的支持和工具？
性能：关于不同的人工智能系统如何专门用于使用 X 射线进行血癌检测或结核病检测，有什么见解吗？
易于使用：由于这是我最后一年的项目，因此一个相对易于实施且拥有良好社区支持的系统将会非常有帮助。
资源：对于可以帮助开发这些系统的数据集、库或其他工具有什么建议吗？
如果您能分享任何意见、建议或经验，我将不胜感激。非常感谢！
我还没有尝试过人工智能方面的任何东西，但我已经对在血癌和结核病领域使用人工智能进行了深入的研究。我渴望从头开始构建自己的人工智能项目，并沉浸在人工智能的世界中。]]></description>
      <guid>https://stackoverflow.com/questions/78507838/exploring-ai-solutions-for-blood-cancer-and-tb-detection-in-medical-imaging</guid>
      <pubDate>Mon, 20 May 2024 16:54:15 GMT</pubDate>
    </item>
    <item>
      <title>OSError：[Errno 95] 不支持操作：</title>
      <link>https://stackoverflow.com/questions/78507703/oserror-errno-95-operation-not-supported</link>
      <description><![CDATA[我将图像数据放入我的google驱动文件中并转动yolo模型，但出现以下错误
OSError：[Errno 95] 不支持操作：&#39;/content/drive/.shortcut-targets-by-id/1PcS8XwYChBkiYMDD3ruAWArX4lmnMPKu/train.cache.npy&#39;

我按照我在chatgpt中告诉的那样更改了如下代码，但它不起作用
cache=True -&gt;缓存=假
]]></description>
      <guid>https://stackoverflow.com/questions/78507703/oserror-errno-95-operation-not-supported</guid>
      <pubDate>Mon, 20 May 2024 16:19:19 GMT</pubDate>
    </item>
    <item>
      <title>sklearn PolynomialFeatures：如果 LinearRegression 生成 y 截距，是否需要偏差</title>
      <link>https://stackoverflow.com/questions/78507382/sklearn-polynomialfeatures-is-the-bias-required-if-linearregression-generates-a</link>
      <description><![CDATA[我是机器学习的新手，因此我一直在尝试一些模型，试图获得更好的理解。
当我创建特征矩阵时：
X_Poly3（X_Poly3 = 多项式特征（3））

其中 X 是 2 列矩阵，生成的 X_Poly3 包含 10 列：
X1、X2、X1^2、X1.X2、X2^2、X1^3、X1^2.X2、X2^2.X1、X2^3 加上“偏差” 1 列。
当我将 LinearRegression() 拟合到该矩阵时，我最终得到 10 个系数加上 y 截距变量。
我认为 1 的偏差列将充当乘数来创建 y 截距，但如果 LinearRegression 创建 y 截距作为标准，是否需要偏差列？
我创建了一个多项式线性回归模型，但最终得到了看起来与 y 截距相关的 2 个变量。
将 numpy 导入为 np
从 sklearn.preprocessing 导入多项式特征

X = np.arange(6).reshape(3, 2)

poly = 多项式特征(3)
X_Poly3 = poly.fit_transform(X)

从 sklearn. Linear_model 导入 LinearRegression
y_train = np.arange(3).reshape(3, 1)

回归器=线性回归()
regressor.fit(X_Poly3, y_train)

print(regressor.intercept_)
打印（回归器.coef_）
]]></description>
      <guid>https://stackoverflow.com/questions/78507382/sklearn-polynomialfeatures-is-the-bias-required-if-linearregression-generates-a</guid>
      <pubDate>Mon, 20 May 2024 15:10:48 GMT</pubDate>
    </item>
    <item>
      <title>我在数据集上运行了多项式多元回归模型。该模型给出负 r2 值以及正 r2 [关闭]</title>
      <link>https://stackoverflow.com/questions/78507156/i-ran-a-polynomial-multiple-regression-model-on-a-dataset-the-model-give-negati</link>
      <description><![CDATA[我在只有 98 个点的数据集上运行了多项式多元回归模型。当我在不同的数据子集（训练和测试）上运行模型时。它给了我从负到正的 r2 值。我知道我的数据点数量较少。我想问我是否可以坚持以最高的正r2值运行。另外，如果以后需要运行该模型，如何保存该模型？因为当我关闭 r 窗口并再次运行代码时，我没有得到相同的 r2 值和结果，而是得到不同的最高正 r2。
我在 r 中工作，我也尝试了其他不同的模型，例如随机森林和 SVM。但我发现 PMLR 最好。但我得到的 r2 值不一致。]]></description>
      <guid>https://stackoverflow.com/questions/78507156/i-ran-a-polynomial-multiple-regression-model-on-a-dataset-the-model-give-negati</guid>
      <pubDate>Mon, 20 May 2024 14:23:51 GMT</pubDate>
    </item>
    <item>
      <title>通过 Databricks API 创建存储库时出错，缺少所需权限</title>
      <link>https://stackoverflow.com/questions/78506814/error-creating-repo-via-databricks-api-missing-required-permissions</link>
      <description><![CDATA[我正在使用服务主体从 Azure DevOps 创建存储库到 Azure Databricks
curl --location &#39;{{DatabricksHost}}/api/2.0/repos&#39; 
--header &#39;Authorization: {{DATABRICKS_TOKEN}}&#39; 
--header &#39;Content-Type: application/json&#39; 
--header &#39;X-Databricks-Azure-SP-Management-Token: {{AAD_TOKEN}}&#39; 
--header &#39;X-Databricks-Azure-Workspace-Resource-Id: /subscriptions/{{SUB}}resourceGroups/{{RG}}/providers/Microsoft.Databricks/workspaces/{{WORKSPACE}}&#39; 
--data &#39;{
&quot;url&quot;: &quot;https://dev.azure.com/URL/ORG/_git/REPO&quot;,
&quot;provider&quot;: &quot;azureDevOpsServices&quot;,
&quot;path&quot;: &quot;/Repos&quot;,
&quot;sparse_checkout&quot;: {
&quot;patterns&quot;: [
&quot;parent-folder/child-folder&quot;
]
}
}&#39;

我用来获取令牌的命令：

Databricks_token: az account get-access-token --scope 499b84ac-1321-427f-aa17-267ca6975798/.default --query &quot;accessToken&quot; --output tsv

AAD_TOKEN: az account get-access-token --resource https://management.core.windows.net/ --query &quot;accessToken&quot; -o tsv


我收到此错误：
缺少 ID 为“0”的节点上的 [查看] 所需权限

或者有时我会收到错误
&quot;Git 提供程序凭据无效。转到用户设置 &gt; Git 集成以确保：\n1. 您已使用 Git 提供程序凭据输入用户名。\n2. 您已使用凭据选择了正确的 Git 提供程序。\n3.您的个人访问令牌或应用密码具有正确的存储库访问权限。\n4. 您的个人访问令牌尚未过期。\n5. 如果您已使用 Git 提供程序启用 SSO，请务必授权您的令牌。&quot;&quot;

我之前确实成功创建了 git 凭据，我的服务主体在订阅上具有贡献者身份，并且在 Databricks 工作区内具有管理员和用户的权限]]></description>
      <guid>https://stackoverflow.com/questions/78506814/error-creating-repo-via-databricks-api-missing-required-permissions</guid>
      <pubDate>Mon, 20 May 2024 13:11:31 GMT</pubDate>
    </item>
    <item>
      <title>应该使用Python的哪个前端和后端框架在应用程序中部署机器学习模型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78506697/which-frontend-and-backend-framework-of-python-should-use-to-deploy-a-machine-le</link>
      <description><![CDATA[我正在从事一个项目，我们需要建立一个机器学习模型来预测乳腺癌。我们想在 Android 应用程序中部署这个模型。所以，我的问题是哪个后端Python框架更适合这个项目？
我尝试制作一个机器学习模型。现在如何在 Android 应用程序中部署此模型？]]></description>
      <guid>https://stackoverflow.com/questions/78506697/which-frontend-and-backend-framework-of-python-should-use-to-deploy-a-machine-le</guid>
      <pubDate>Mon, 20 May 2024 12:49:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 Minirocket 分类的自定义数据集存在问题</title>
      <link>https://stackoverflow.com/questions/78506562/problems-with-custom-dataset-using-minirocket-classification</link>
      <description><![CDATA[我正在开展一个更大的学校项目，尝试使用 Minirocket/Rocket 对时间序列测量进行分类。我的训练数据由一个包含测量值的一维矩阵和一个包含相应标签 (0/1) 的单独一维矩阵组成。矩阵的长度相等，因此每个测量值都有一个标签。我尝试运行该程序，该程序处理其他示例数据，但总是收到以下错误：“ValueError：发现样本数量不一致的输入变量：[1, 321408]”。我在这里做错了什么？我是否必须以不同的方式格式化训练数据，或者 MiniRocket 是否还有其他我必须调整的设置？
该错误是由以下代码行触发的：classifier.fit(train_x_transform, train_y)
这是我到目前为止尝试运行的完整代码：
导入 pandas 作为 pd
从 sklearn.metrics 导入分类报告
从 sktime.transformations.panel.rocket 导入 MiniRocket
从 sklearn. Linear_model 导入 RidgeClassifierCV
将 numpy 导入为 np

# 加载数据
def load_data(文件路径):
    数据 = pd.read_csv(文件路径)
    X = 数据[&#39;sensor_values_final&#39;].values
    y = 数据[&#39;标签&#39;].值
    断言 len(X) == len(y),“X 和 y 的长度不匹配”
    返回 X, y

train_x, train_y = load_data(r&#39;csv\TrainingData_2024-05-18_18-21-46_train.csv&#39;)
test_x, test_y = load_data(r&#39;csv\TrainingData_2024-05-18_18-21-46_test.csv&#39;)

# 转换数据
minirocket = MiniRocket(10_000) # 默认情况下，MiniRocket 使用约 10,000 个内核
迷你火箭.fit(train_x)
train_x_transform = minirocket.transform(train_x)
test_x_transform = minirocket.transform(test_x)

# 训练模型
分类器 = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))
classifier.fit(train_x_transform, train_y)

# 评估模型
train_y_pred = classifier.predict(train_x_transform)
test_y_pred = 分类器.预测(test_x_transform)

print(&quot;测试集性能：&quot;)
打印（分类报告（test_y，test_y_pred））
]]></description>
      <guid>https://stackoverflow.com/questions/78506562/problems-with-custom-dataset-using-minirocket-classification</guid>
      <pubDate>Mon, 20 May 2024 12:21:28 GMT</pubDate>
    </item>
    <item>
      <title>k-最近分类概率估计问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78506193/k-nearest-classification-probability-estimation-problem</link>
      <description><![CDATA[已知邻居连接方法对噪声敏感。我们将考虑训练样本的一个属性和两个对象的二元分类模型问题：（x_1 = 0.2），（x_2 = 0.7）。第一个对象属于第一类，第二个对象属于第二类。
让我们向对象添加一个新的噪声特征，均匀分布在段 ([0, 1]) 上。现在每个对象都由两个侧面来描述。需要使用具有欧几里德度量的最近邻方法对该空间中的新对象（ u = (0, 0) ）进行分类。
添加第二个噪声对象后，它比第一个更接近对象（u）的概率是多少？
如果可能的话，我想了解使用哪种方法来求解以及应该使用哪些概率和机器学习公式]]></description>
      <guid>https://stackoverflow.com/questions/78506193/k-nearest-classification-probability-estimation-problem</guid>
      <pubDate>Mon, 20 May 2024 10:54:59 GMT</pubDate>
    </item>
    <item>
      <title>SpaCy 变压器 NER 训练 – 变压器零损耗，未训练</title>
      <link>https://stackoverflow.com/questions/78506114/spacy-transformer-ner-training-zero-loss-on-transformer-not-trained</link>
      <description><![CDATA[我正在使用 [&#39;transformer&#39;, &#39;ner&#39;] 组件训练 SpaCy 管道，ner 训练得很好，但 Transformer 的损失为 0，并且我假设它没有进行训练。 
这是我的配置：
&lt;代码&gt;[路径]
矢量=“en_core_web_trf”
init_tok2vec = null
火车=“/home/sxdadmin/spacy/input/train.spacy”
dev =“/home/sxdadmin/spacy/input/dev.spacy”

[系统]
gpu_allocator = “pytorch”;
种子 = 0

[自然语言处理]
lang =“en”；
pipeline = [“变压器”, “ner”]
批量大小 = 512
禁用 = []
创建之前 = null
创建后=空
after_pipeline_creation = null
tokenizer = {“@tokenizers”：“spacy.Tokenizer.v1”}
向量 = {“@vectors”：“spacy.Vectors.v1”}

#################################################### ####################
[成分]
#################################################### ####################

[组件.变压器]
工厂=“变压器”
最大批次项 = 4096

[组件.变压器.模型]
@architectures = “spacy-transformers.TransformerModel.v1”
name = “bert-base-cased”；
tokenizer_config = {“use_fast”：true}

[组件.transformer.model.get_spans]
@span_getters = “spacy-transformers.doc_spans.v1”

[components.transformer.set_extra_annotations]
@annotation_setters = “spacy-transformers.null_annotation_setter.v1”

#################################################### ####################

[组件.ner]
工厂=“ner”
不正确的跨度键 = null
移动=空
计分器 = {“@scorers”：“spacy.ner_scorer.v1”}
update_with_oracle_cut_size = 100

[组件.ner.模型]
@architectures = “spacy.TransitionBasedParser.v2”
state_type =“ner”；
extra_state_tokens = false
隐藏宽度 = 64
最大输出件数 = 2
use_upper = true
nO = 空

#################################################### ####################
[语料库]
#################################################### ####################

[语料库.train]
@readers =“spacy.Corpus.v1”
路径 = ${paths.train}
最大长度 = 3000
gold_preproc = false
限制 = 0
增强器 = null

[语料库.dev]
@readers =“spacy.Corpus.v1”
路径 = ${paths.dev}
最大长度 = 3000
gold_preproc = false
限制 = 0
增强器 = null

#################################################### ####################
[训练]
#################################################### ####################

dev_corpus = “corpora.dev”;
train_corpus = “语料库.train”;
种子 = 0
gpu_allocator = “pytorch”;
辍学率 = 0.1
累积梯度= 1
耐心=1600
最大纪元 = 0
最大步数 = 20000
评估频率 = 200
冻结组件 = []
注释组件 = []
before_to_disk = null
更新前=空

#################################################### ####################

[训练.batcher]
@batchers = “spacy.batch_by_words.v1”
丢弃尺寸过大= false
公差 = 0.2
获取长度=空

[训练.batcher.大小]
@schedules =“compounding.v1”；
开始 = 64
停止= 512
化合物 = 1.001
t = 0.0

#################################################### ####################

[训练记录器]
@loggers = “spacy.ConsoleLogger.v1”
进度条=假

[训练.优化器]
@optimizers =“Adam.v1”；
贝塔1 = 0.9
贝塔2 = 0.999
L2_is_weight_decay = true
L2 = 0.01
梯度剪辑 = 1.0
use_averages = false
每股收益 = 0.00000001
学习率 = 0.001

[训练.score_weights]
ents_f = 1.0
ents_p = 0.0
ents_r = 0.0
ents_per_type = null

#################################################### ####################
[预训练]
#################################################### ####################

[初始化]
矢量=“en_core_web_lg”
init_tok2vec = null
词汇数据=空
查找=空
before_init = null
after_init = null

[初始化.组件]
[初始化.组件.变压器]
[初始化.tokenizer]

和输出：

所有警告均得到满足，著名的 Bert 的 max_length 512 个 token 就是通过文本分割实现的。数据之前已在 [tok2vec, ner] 设置上进行了测试。
请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78506114/spacy-transformer-ner-training-zero-loss-on-transformer-not-trained</guid>
      <pubDate>Mon, 20 May 2024 10:39:58 GMT</pubDate>
    </item>
    <item>
      <title>痤疮数据集上的 Mask R-CNN [关闭]</title>
      <link>https://stackoverflow.com/questions/78505757/mask-r-cnn-on-acne-dataset</link>
      <description><![CDATA[为什么 Mask R-CNN 没有在痤疮数据集上进行训练？如果我在痤疮数据集上训练它来分类痤疮类型，那么它背后的优势是什么？
Mask R-CNN 不在痤疮数据集上进行训练的真实且坚实的原因]]></description>
      <guid>https://stackoverflow.com/questions/78505757/mask-r-cnn-on-acne-dataset</guid>
      <pubDate>Mon, 20 May 2024 09:29:38 GMT</pubDate>
    </item>
    <item>
      <title>当我们升级到最新版本 17 时，PYPMML 模型在响应中返回“无”</title>
      <link>https://stackoverflow.com/questions/78505291/pypmml-model-is-returning-none-in-the-responses-when-we-upgrade-to-latest-vers</link>
      <description><![CDATA[我们在 Flask 应用程序中使用 pypmml 包。最近，我们在 commons-text-1.6.jar 中发现了一个漏洞（当我们安装 pypmml 时，该漏洞出现在站点包中）。 commons-text版本中存在的漏洞&gt;= 1.5，&lt; 1.10.0。
为了缓解此漏洞，我们将软件包版本从 0.9.12 升级到 0.9.17。 最新版本的通用文本版本是1.10。但是，当我们使用请求数据调用预测方法时，模型已开始在响应中给出“无”。旧版本的响应与预期一致。
有人可以帮忙吗？
在此处输入图片描述
我尝试将软件包降级回 0.9.12，它按预期工作，当我降级到该软件包的第一个版本 0.9.0 时，它也正常工作。我无法使用此软件包的较低版本，因为它具有常见的文本 jar 文件漏洞。]]></description>
      <guid>https://stackoverflow.com/questions/78505291/pypmml-model-is-returning-none-in-the-responses-when-we-upgrade-to-latest-vers</guid>
      <pubDate>Mon, 20 May 2024 07:40:14 GMT</pubDate>
    </item>
    <item>
      <title>LLM Studio 无法下载模型并出现错误：无法获取本地颁发者证书</title>
      <link>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</link>
      <description><![CDATA[在LLM studio中，当我尝试下载任何模型时，我遇到以下错误：
下载失败：无法获取本地颁发者证书
]]></description>
      <guid>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</guid>
      <pubDate>Wed, 24 Apr 2024 16:03:26 GMT</pubDate>
    </item>
    <item>
      <title>验证错误：无法实例化 GPT4AllEmbeddings 模型</title>
      <link>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</link>
      <description><![CDATA[我在尝试创建 GPT4AllEmbeddings 实例时遇到问题。但是我不断收到以下错误
单元格 In[15]，第 1 行
----&gt; 1 vectorstore = Chroma.from_documents(文档 = 分割, 嵌入 = GPT4AllEmbeddings())
      2 检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
      3检索文档=检索器.get_relevant_documents（“你是什么？”）

文件 ~\anaconda3\Lib\site-packages\pydantic\main.py:341，在 pydantic.main.BaseModel.__init__() 中

ValidationError：GPT4AllEmbeddings 出现 1 个验证错误
__根__
  无法实例化模型（type=value_error）

这是相关的代码片段
vectorstore = Chroma.from_documents(documents = splits, embeddings = GPT4AllEmbeddings())
检索器 = vectorstore.as_retriever(search_type = &#39;相似度&#39;, search_kwargs = {&#39;k&#39;:6})
retrieved_docs =retrieve.get_relevant_documents(“什么是Young Decade？”)
打印（len（检索文档））
打印（retrieve_docs[0].page_content）

如何解决这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/78152636/validation-error-unable-to-instantiate-gpt4allembeddings-model</guid>
      <pubDate>Wed, 13 Mar 2024 09:36:07 GMT</pubDate>
    </item>
    <item>
      <title>测试和训练数据具有不同的城市，如何查找差异并在测试和训练数据的两列上使用相同的编码系统进行编码</title>
      <link>https://stackoverflow.com/questions/77351990/test-and-train-data-have-different-cities-how-to-find-and-differences-and-encod</link>
      <description><![CDATA[我有一个测试集和训练集。他们有一个城市列，其中一个（火车）有 290 个唯一的，测试有 30 个。我希望有重叠，即伦敦、布里斯托尔都在两组中，但格洛斯特可能在一组上，而不是另一组上。
我还想将这些城市编码为两个集合之间相关的数值，因此伦敦应该在测试和训练中编码为 1。
我查看了 LabelEncoder，但不知道如何让两个集合对它们共享的城市使用相同的编号。
LabelEncoder 工作正常，但两组之间没有相关性。
之前：
df_train[&#39;城市&#39;]
“伦敦”、“布里斯托尔”、“巴黎”、“罗马”、“伦敦”、“伍斯特”

df_test[&#39;城市&#39;]
“巴黎”、“罗马”、“罗马”、“伦敦”、“格洛斯特”

输出：
df_train[&#39;城市&#39;]
1 2 3 4 1 6

df_test[&#39;城市&#39;]
3 4 4 1 7
]]></description>
      <guid>https://stackoverflow.com/questions/77351990/test-and-train-data-have-different-cities-how-to-find-and-differences-and-encod</guid>
      <pubDate>Tue, 24 Oct 2023 12:19:41 GMT</pubDate>
    </item>
    </channel>
</rss>