<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Fri, 28 Feb 2025 03:26:08 GMT</lastBuildDate>
    <item>
      <title>为什么投票表决为“努力”的投票表现有所不同？</title>
      <link>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</link>
      <description><![CDATA[我想从Sklearn和不同参数进行比较性能测试投票classifier。我使用了param网格，然后发现一些难以理解的东西。
我准备了三个分类器
  gnb = gaussiannb（）＃准确性0.795
lr = logisticRegress（）＃准确性0.7925
RFC = RandomforestClassifier（）＃准确性0.94

 
然后我做了两个VaitingClassifiers。两者都有有效的设置为“硬”。但是重量不同。该决定是由多数投票做出的，但其准确性是不同的，这是如何可能的？
  vc_hard_equals = fotingClassifier（estingators = [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （&#39;Randomforest＆quot＆quot; rfc）
    ]，， 
    投票=“硬＆quot” 
    权重=（1，1，1），＃等于权重
    ）
vc_hard_forest_priority = fotingClassifier（估算= [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （“ rancomforest”，rfc），]， 
    投票=“硬＆quot” 
    权重=（1，1，3），＃更大的随机孔（在这种情况下最好的型号）
    ）

vc_hard_equals.fit（x_train，y_train）
vc_hard_forest_priority.fit（x_train，y_train）

print（vc_hard_equals.score（x_test，y_test））＃0.832
print（vc_hard_forest_priority.score（x_test，y_test））＃0.915
 ]]></description>
      <guid>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</guid>
      <pubDate>Fri, 28 Feb 2025 02:14:28 GMT</pubDate>
    </item>
    <item>
      <title>安装Llava</title>
      <link>https://stackoverflow.com/questions/79474039/installing-llava</link>
      <description><![CDATA[是否有人找到了LLAVA的正确依赖关系和安装顺序？我已经尝试了多个选项，但是在尝试采购模型时继续遇到以下错误：
 代码： 
 来自llava.model.builder import load_pretratained_model
来自llava.mm_utils import get_model_name_from_path
model_path =＆quot; liuhaotian/llava-v1.5-7b; quot  ＃7B Llava模型在拥抱面上
tokenizer，model，image_processor，context_len = load_pretrataining_model（
model_path = model_path，
model_base = none，
model_name = get_model_name_from_path（model_path）
）
 
 错误：
无法导入“ llava.model” 的名称“ llavallamaforcausallm”
我遵循了正式文档中的每一个指令，但到目前为止没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/79474039/installing-llava</guid>
      <pubDate>Thu, 27 Feb 2025 22:07:50 GMT</pubDate>
    </item>
    <item>
      <title>稳定的割炬，超级分析，张量子流包装。</title>
      <link>https://stackoverflow.com/questions/79473712/stable-torch-ultralytics-tensorflow-packages-for-requirements-txt</link>
      <description><![CDATA[我正在为实时体育视频分析项目编写要求。
我尝试了多个Python版本，但遇到了兼容性问题。
我应该安装哪些版本？
要求

火炬== 2.1.2 
 torchvision == 0.16.2 
 Ultrytics == 8.3.80 
 opencv-python == 4.9.0.80 

示例代码
 从超级物质导入YOLO
导入CV2
导入操作系统
进口地球


frame_dir =＆quot; data/videos/res/720p＆quot;
output_dir =“数据/视频/检测”
OS.Makedirs（output_dir，equent_ok = true）


型号= yolo（＆quot; yolov8n.pt;）

target_classes = {
    ＆quot“运动球”：32，
    “人＆quot”：0，
}


对于排序中的frame_path（glob.glob（os.path.join）（frame_dir，*。
    帧= cv2.imread（frame_path）
    结果=模型（帧）

    结果结果：
        对于结果中的框。盒子：
            cls_id = int（box.cls [0]）
            如果target_classes.values（）中的cls_id：
                x1，y1，x2，y2 = map（int，box.xyxy [0]）
                label = [k，v in target_classes.items（）如果v == cls_id] [0]
                cv2.Rectangle（框架，（x1，y1），（x2，y2），（0，255，0），2）
                cv2.putText（帧，标签，（x1，y1-5），cv2.font_hershey_simplex，0.5，（0，255，0），2）

    output_path = os.path.join（output_dir，os.path.basename（frame_path））
    cv2.imwrite（output_path，框架）

打印（output_dir）

 
跟踪
  python -c＆quot“ intimp ultrytics;打印（Ultrytics .__版本__）＆quot;

使用numpy 1.x编译的模块无法运行
Numpy 2.1.1可能会崩溃。支持1.x和2.x
Numpy的版本，必须使用Numpy 2.0编译模块。
一些模块可能需要重建，例如使用&#39;pybind11＆gt; = 2.12&#39;。

如果您是模块的用户，最简单的解决方案将是
降级到&#39;numpy＆lt; 2&#39;或尝试升级受影响的模块。
我们希望有些模块需要时间来支持Numpy 2。

Trackback（最近的最新通话）：file＆quot&#39;string＆gt;＆quort 1，第1行，in＆lt; module＆gt;
  file＆quot＆quort＆quot＆quote＆quote＆quotions/my_projements/venv/lib/python3.11/site-packages/ultralytics/__ init __ init __. py＆quot＆quort&#39;&#39;第11行，in＆lt; lt; module＆gt; gt;
    从Ultrytics.Models进口NAS，RTDETR，SAM，YOLO，FASTSAM，YOLOWORLD
  file＆quot＆quort＆quot＆quort＆quot＆quot＆quot＆quotitys/my_projements/venv/lib/python3.11/site-packages/ultralytics/models/models/__ init __ Init __ init __ py＆quort&#39;py＆quort of第3行，in＆lt; module＆gt;
    来自.fastSAM进口FastSAM
  file＆quot＆quot＆quot＆quort＆quot＆quot＆quotiments/my_projements/venv/lib/python3.11/site-packages/ultralytics/models/models/fastsam/fastsam/__ init __ init __. py＆quort;
    来自.model进口FastSAM
  file＆quot＆quort＆quot＆quot＆quot＆quot＆quotiments/my_projements/venv/lib/python3.11/site-packages/ultralytics/models/models/fastsam/fastsam/model.py&quot;&quot;＆quot＆quot＆quot＆quot＆line 5，in＆lt; lt; module＆gt; gt; gt;
    来自ultrytics.engine.model进口模型
  file＆quort＆quort＆quot＆quot＆quot＆quot＆quotments/my_projements/venv/lib/python3.11/site-packages/ultralalytics/engine/model.py&amp;py&quot; line 8，in 8 in＆lt; lt; module＆gt; gt;
    导入火炬
  file＆quort＆quort＆quot＆quote＆quote＆quotiments/my_projements/venv/lib/python3.11/site-packages/torch/__ init __ init __. py＆quort&#39;&#39;&#39;&#39;&#39;第1477行，in＆lt; module＆gt; gt;
    来自。功能导入 *＃noqa：f403
  文件＆quot＆quort＆quot＆quot＆quotiments/my_projements/venv/lib/python3.11/site-packages/torch/functional.py＆quot＆quot;，第9行，in＆lt; module＆gt;
    导入Torch.nn.功能为f
  file＆quot＆quort＆quot＆quote＆quote＆quote＆quotiments/my_projements/venv/lib/python3.11/site-packages/torch/torch/nn/__ init __.
    来自.modules导入 *＃noqa：f403
  file＆quot＆quot＆quot＆quot＆quot＆quotiments/my_projements/venv/venv/lib/python3.11/site-packages/torch/nn/modules/modules/__ init __ init __. py＆quort&#39;＆quort 35，in＆lt; lt; lt; gt; gt;
    来自.transformer导入transformerencoder，trransformerDecoder，\
  file＆quot＆quot＆quot＆quot＆quot＆quot＆quot＆quotions/my_projements/venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py&quot;＆quot＆quot;
    设备：torch.device = torch.device（torch._c._get_default_device（）），＃torch.device（&#39;cpu&#39;），
/library/webserver/documents/my_projement/venv/lib/python3.11/site-packages/torch/torch/nn/modules/transformer.py：20：userWarning：userwarning：userwarning：dropinize nucpy：_array_api：_array_api（_array_api note trigger trigger trigger at in trigger at in triggt at in trigger at in trigger at in trigger at in /users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84。
  设备：torch.device = torch.device（torch._c._get_default_device（）），＃torch.device（&#39;cpu&#39;），
8.3.80
 ]]></description>
      <guid>https://stackoverflow.com/questions/79473712/stable-torch-ultralytics-tensorflow-packages-for-requirements-txt</guid>
      <pubDate>Thu, 27 Feb 2025 19:19:40 GMT</pubDate>
    </item>
    <item>
      <title>如何让pytorch学习系数变量，以使nn.module之外的丢失？</title>
      <link>https://stackoverflow.com/questions/79473125/how-to-let-pytorch-learn-coefficients-variables-for-the-loss-outside-of-nn-modul</link>
      <description><![CDATA[我有这样的损失弹性：
 损失= alpha * loss0 + beta * loss1 + gamma * loss2 + delta * loss3
 
我想制作Alpha，Beta，Gamma和Delta可学习的参数。请注意，Alpha，Beta，Gamma和Delta在NN.Module之外。我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/79473125/how-to-let-pytorch-learn-coefficients-variables-for-the-loss-outside-of-nn-modul</guid>
      <pubDate>Thu, 27 Feb 2025 15:16:32 GMT</pubDate>
    </item>
    <item>
      <title>没有或几个异常的异常检测ML训练[封闭]</title>
      <link>https://stackoverflow.com/questions/79472624/anomaly-detection-ml-training-with-none-or-few-anomalies</link>
      <description><![CDATA[使用隔离森林对无监督的非序列数据进行异常检测时，局部离群因子具有低变化变量，例如温度和湿度。
，我们通过读取模型来训练该模型，这些读数可以被认为是我们案件正常的读数。因此，几乎没有我们的目标“异常”。
它会使模型更敏感地将值标记为异常吗？
可以通过“种植”来解决此类问题。拥有异常。
例如。从温度，二氧化碳，湿度等房间收集读数时，我们会燃烧与之旁边的匹配项，或者亲自更改数据。]]></description>
      <guid>https://stackoverflow.com/questions/79472624/anomaly-detection-ml-training-with-none-or-few-anomalies</guid>
      <pubDate>Thu, 27 Feb 2025 12:07:53 GMT</pubDate>
    </item>
    <item>
      <title>在序列编码中，whand_unknown = use_encoded_values做什么？</title>
      <link>https://stackoverflow.com/questions/79471646/in-ordinal-encoder-what-does-handle-unknown-use-encoded-values-do</link>
      <description><![CDATA[我已经完成了研究，但我对文档和双子座的答案不满意。  use_encoded_value 它是什么意思？我必须通过一个论点作为编码值吗？如果是这样，您可以举例说明它的用法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79471646/in-ordinal-encoder-what-does-handle-unknown-use-encoded-values-do</guid>
      <pubDate>Thu, 27 Feb 2025 05:09:19 GMT</pubDate>
    </item>
    <item>
      <title>BigQuery ML时间序列模型评估保持返回零</title>
      <link>https://stackoverflow.com/questions/79471261/bigquery-ml-time-series-model-evaluate-keeps-returning-null</link>
      <description><![CDATA[我正在使用BigQuery ML来训练ARIMA_PLUS模型，以预测CPU使用情况。该模型成功训练，但是当我运行ml。评估时，所有结果值均为null。
 模型训练查询 
 创建或替换模型`project.dataset.arima_model`
选项（
  model_type =&#39;arima_plus&#39;，
  time_series_timestamp_col =&#39;timestamp_column&#39;，
  time_series_id_col = [&#39;id_column_1&#39;，&#39;id_column_2&#39;]，
  time_series_data_col =&#39;data_column&#39;，
  forecast_limit_lower_bound = 0，
  forecast_limit_upper_bound = 100
） 作为
选择data_column，id_column_1，id_column_2，timestamp_column
来自`project.dataset.source_table`
在“ 2025-02-5”和&#39;2025-02-12&#39;之间的日期（timestamp_column）;
 
 评估查询 
 选择 * 
来自ml.evaluate（
  模型`project.dataset.arima_model`，
  （（
    选择data_column，id_column_1，id_column_2，timestamp_column
    来自`project.dataset.source_table`
    在“ 2025-02-13&#39;和&#39;2025-02-20&#39;之间的日期（timestamp_column）
  ），
  结构（
    true作为persim_gregation， 
    10作为地平线， 
    0.9作为信心_level
  ）
）；
 
 ml.Evaluate成功运行，但返回所有ID的null
查询结果 ]]></description>
      <guid>https://stackoverflow.com/questions/79471261/bigquery-ml-time-series-model-evaluate-keeps-returning-null</guid>
      <pubDate>Wed, 26 Feb 2025 23:29:23 GMT</pubDate>
    </item>
    <item>
      <title>NN回归训练损失初始增加[关闭]</title>
      <link>https://stackoverflow.com/questions/79471142/nn-regression-training-loss-initial-increase</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79471142/nn-regression-training-loss-initial-increase</guid>
      <pubDate>Wed, 26 Feb 2025 22:16:00 GMT</pubDate>
    </item>
    <item>
      <title>如何为AI模型培训构建服务器？ （GPU，硬件和远程访问）[关闭]</title>
      <link>https://stackoverflow.com/questions/79470714/how-to-build-a-server-for-ai-model-training-gpu-hardware-and-remote-access</link>
      <description><![CDATA[我想构建用于培训AI模型的计算机（服务器），包括：

微调聊天机器人LLMS 
机器学习和深度学习模型

我有几个问题：

 我应该购买哪个GPU？我知道GPU对于AI培训很重要，但我不确定哪一个是满足我需求的最佳选择。

 我还需要什么其他硬件？除GPU外，推荐的CPU，RAM，存储和其他组件是什么？

 如何远程控制此服务器？我希望能够从另一个位置访问和管理此服务器。我应该使用什么工具或方法？

 多人可以同时使用该服务器吗？如果我想与朋友或队友共享此服务器，我们如何一起训练模型？

]]></description>
      <guid>https://stackoverflow.com/questions/79470714/how-to-build-a-server-for-ai-model-training-gpu-hardware-and-remote-access</guid>
      <pubDate>Wed, 26 Feb 2025 18:16:44 GMT</pubDate>
    </item>
    <item>
      <title>LSTM培训是否在恢复学习后重置？</title>
      <link>https://stackoverflow.com/questions/79461981/does-lstm-training-reset-after-resuming-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79461981/does-lstm-training-reset-after-resuming-learning</guid>
      <pubDate>Sun, 23 Feb 2025 21:11:38 GMT</pubDate>
    </item>
    <item>
      <title>LLM Studio无法下载错误：无法获得本地发行人证书</title>
      <link>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</link>
      <description><![CDATA[在LLM Studio中，当我尝试下载任何模型时，我将面临以下错误：
下载失败：无法获取本地发行人证书
  &lt;img alt =“在此处输入图像描述” src =“ https：///i.sstatic.net/wkmzi.png”]]></description>
      <guid>https://stackoverflow.com/questions/78379820/llm-studio-fail-to-download-model-with-error-unable-to-get-local-issuer-certif</guid>
      <pubDate>Wed, 24 Apr 2024 16:03:26 GMT</pubDate>
    </item>
    <item>
      <title>在编译时，我该如何解决问题？（depthwise_conv.cc）</title>
      <link>https://stackoverflow.com/questions/78125296/how-can-i-solve-the-problem-during-mbed-compiledepthwise-conv-cc</link>
      <description><![CDATA[我正在研究使用Tinyml Book的机器学习。
我正在尝试编译，但它不起作用。
问题的情况如下：
本书提出了以下过程。
  make -f tensorflow/lite/micro/tools/make/makefile \
target = mbed tags =; cmsis-nn disco_f746ng; generate_micro_speech_mbed_project
 
目录。
  CD TensorFlow/Lite/Micro/Tools/Make/gen/Mbed_cortex-M4/prj/micro_speech/mbed
 
配置MBED盗贼根。
  mbed config root。
 
 mbed部署
  MBED部署
 
修改MBED配置文件以使用C ++11。
  python3 -c&#39;导入fileInput，glob;
for glob.glob中的文件名（“ mbed-os/tools/profiles/*。json＆quot”）：
    对于fileInput.input中的行（文件名，Inplace = true）：
        print(line.replace(&quot;\&quot;-std=gnu++98\&quot;&quot;,&quot;\&quot;-std=c++11\&quot;, \&quot;-fpermissive\&quot;&quot;))&#39;

 
和编译
  mbed compile -m disco_f746ng -t gcc_arm
 
但是，部署过程中存在一些问题。在部署过程中，发生了问题。在寻找解决方案时，我找到了一个建议，以修改make命令如下。
  make -f tensorflow/lite/micro/tools/make/makefile \
target = mbed tags =; cmsis-nn disco_f746ng; generate_micro_speech_mbed_project
 
进行修改后，我以相同的方式进行了编译过程，但遇到了以下错误。
 编译[82.7％]：depthwise_conv.cc
[错误] depthwise_conv.cc@178,9：从&#39;int&#39;到&#39;const cmsis_nn_dims*&#39;[-fpermissive]
[错误] depthwise_conv.cc@178,22：从&#39;int&#39;到&#39;const cmsis_nn_dims*&#39;[-fpermissive]
[error] depthwise_conv.cc@178,49：太多的参数无法函数&#39;int32_t arm_depthwise_conv_s8_opt_get_get_buffer_size（const cmsis_nn_dims*，const cmsis_nnn_dims*）&#39;
[错误] depthwise_conv.cc@184,34：无法将&#39;const&#39;consed char*&#39;转换为&#39;const cmsis_nn_context*&#39;
[错误] depthwise_conv.cc@195,9：在此范围中未声明&#39;arm_math_success&#39;；您的意思是&#39;ARM_MATH_DSP&#39;吗？
[错误] depthwise_conv.cc@184,34：无法将&#39;const&#39;consed char*&#39;转换为&#39;const cmsis_nn_context*&#39;
[error] depthwise_conv.cc@200,34：无法将&#39;const&#39;consed char*&#39;转换为&#39;const cmsis_nn_context*&#39;
[error] depthwise_conv.cc@212,9：在此范围中未声明&#39;arm_math_success&#39;；您的意思是&#39;ARM_MATH_DSP&#39;吗？
[error] depthwise_conv.cc@200,34：无法将&#39;const&#39;consed char*&#39;转换为&#39;const cmsis_nn_context*&#39;
[error] depthwise_conv.cc@272,5：&#39;arm_depthwise_conv_u8_basic_ver1&#39;在此范围中未声明；您的意思是&#39;ARM_DEPTHWIES_CONV_FAST_S16&#39;吗？
[错误]&#39;_queue.simplequeue&#39;对象没有属性&#39;队列&#39;
[mbed]错误：/usr/bin/python3＆quot返回的错误。
       代码：1
       路径：＆quot/home/ghjeon/tensorflow-lite/tensorflow/lite/micro/tools/make/gen/gen/mbed_cortex-m4/prj/prj/micro_speech/mbed;
       Command: &quot;/usr/bin/python3 -u /home/ghjeon/tensorflow-lite/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed/mbed-os/tools/make.py -t GCC_ARM -m DISCO_F746NG --source . -build ./build/disco_f746ng/gcc_arm&quot;
       提示：您可以用“ -v”重试最后一个命令。详细的详细输出
---

 
我无法解决这个问题。我一直无法解决这个问题2天。我要提前感谢任何可以提供帮助的人。
  [错误]&#39;_Queue.simplequeue&#39;对象没有属性&#39;queue&#39;
 
我已经看到了信息，表明可以使用Python 2.7解决上述错误。但是，我不确定这是否允许使用CLI1。因为ARM建议Cli1需要Python 3.7.x版本。]]></description>
      <guid>https://stackoverflow.com/questions/78125296/how-can-i-solve-the-problem-during-mbed-compiledepthwise-conv-cc</guid>
      <pubDate>Fri, 08 Mar 2024 02:44:08 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：不可用的类型：pd.get_dummies的“系列”</title>
      <link>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</link>
      <description><![CDATA[我试图在我拥有的数据框中的某些名义数据上使用 pd.get_dummies （从Kaggle回归）。我将所有名义类别分为列名列表，&#39;obj_nominal&#39;。
我打电话
  pd.get_dummies（df，columns = obj_nominal）
 
我遇到了错误：
  typeError：不可用的类型：&#39;系列&#39;。
 
到目前为止，我唯一完成的预处理是删除数据集中的空值。我还尝试使用sklearn  onehotencoder ，并且会产生相同的错误。
我还尝试使用：进行单独的数据帧
  x = df.iloc [：,, obj_nominal]
 
和在数据框架上通过get_dummies：
  pd.get_dummies（data = x）
 
但仍然没有运气... 
The data is downloadable at https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data]]></description>
      <guid>https://stackoverflow.com/questions/70617092/typeerror-unhashable-type-series-for-pd-get-dummies</guid>
      <pubDate>Fri, 07 Jan 2022 05:51:22 GMT</pubDate>
    </item>
    <item>
      <title>来自_logits = try或false的含义是什么？</title>
      <link>https://stackoverflow.com/questions/55290709/what-does-from-logits-true-or-false-mean-in-sparse-categorical-crossentropy-of</link>
      <description><![CDATA[在Tensorflow 2.0中，
有一个称为的损失功能
  tf.keras.losses.sparse_categorical_crossentropy（标签，目标，from_logits = false）
 
设置 from_logits = true 或 false ？之间有什么区别
我的猜测是，当传入值是logits时，您将从_logits = true设置，并且如果传入值是概率（通过softmax等），则您只需设置from_logits = false（这是默认设置）。。
但是为什么？损失只是一些计算。为什么它需要通过其传入价值而有所不同？
我还在Google的Tensorflow教程中看到
 htttps://wwwww.tensorflow.org/alpha/alpha/alpha/tutorials/tutorials/sequences/sequences/sequences/sequences/textex_gentex_gentex_genert_genert_genert_generat_generatex_generatex_generatex_generatex_generatex_generatect_generation    &gt;
即使最后一层的传入值是logits，它也不会从_logits = true设置。
这是代码
 @tf.function
def train_step（INP，目标）：
  用tf.gradienttape（）作为磁带：
    预测=模型（INP）
    损失= tf.reduce_mean（
        tf.keras.losses.sparse_categorical_crossentropy（目标，预测））
  grads = tape.Gradient（损失，模型。Trainable_variables）
  优化器。Apply_gradients（zip（grads，model.trainable_variables））

  回报损失
 
模型为
 模型= tf.keras.Sequeential（[[[
    tf.keras.layers.embedding（vocab_size，embedding_dim， 
                              batch_input_shape = [batch_size，none]），），
    tf.keras.layers.lstm（rnn_units， 
                        return_sequences = true， 
                        状态= true， 
                        recurrent_initializer =&#39;glorot_uniform&#39;），
    tf.keras.layers.dense（vocab_size）
  ）））
 
没有softmax的最后一层。
（另外，在教程的另一部分中，它设置了 from_logits = true ）
所以，我是否将其设置为 true ？都没有关系？]]></description>
      <guid>https://stackoverflow.com/questions/55290709/what-does-from-logits-true-or-false-mean-in-sparse-categorical-crossentropy-of</guid>
      <pubDate>Thu, 21 Mar 2019 23:26:35 GMT</pubDate>
    </item>
    <item>
      <title>文档分析和标记[封闭]</title>
      <link>https://stackoverflow.com/questions/5107371/document-analysis-and-tagging</link>
      <description><![CDATA[假设我有一堆我想标记，分类等的论文（数千）。理想情况下，我想通过手动对几百个进行分类/标记来训练   ，然后让事物放松。 。
您会推荐哪些资源（书籍，博客，语言）进行此类任务？  我的一部分认为这非常适合 href =“ http://en.wikipedia.org/wiki/latent_semantic_analysis” rel =“ nofollow noreferrer”&gt;潜在的语义分析，但我对几个 ruby​​   gems 。。
贝叶斯分类器可以解决这样的事情吗？  我应该更多地研究语义分析/自然语言处理吗？  或者，我应该只是在寻找关键字密度和映射吗？]]></description>
      <guid>https://stackoverflow.com/questions/5107371/document-analysis-and-tagging</guid>
      <pubDate>Thu, 24 Feb 2011 16:20:43 GMT</pubDate>
    </item>
    </channel>
</rss>