<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 09 Apr 2024 15:13:58 GMT</lastBuildDate>
    <item>
      <title>计算Python中两个sumamries之间的BLEU分数</title>
      <link>https://stackoverflow.com/questions/78299375/calculating-bleu-score-between-two-sumamries-in-python</link>
      <description><![CDATA[预测=“我是ABC。我已经在 XYZ 大学完成了计算机应用学士学位，目前正在通过远程教育攻读计算机应用硕士学位。”


引用=“我是ABC。我已经在 XYZ 完成了为期四年的 PC 应用认证，目前正在通过远程培训攻读 PC 应用研究生学位。”

从 nltk.translate.bleu_score 导入句子_bleu

# 对句子进行标记
Prediction_tokens = Prediction.split()
Reference_tokens = Reference.split()

# 计算 BLEU 分数
bleu_score = Sentence_bleu([参考标记], 预测标记)

# 打印 BLEU 分数
print(f&quot;BLEU 分数: {bleu_score:.4f}&quot;)

我得到的 BLEU 分数为 0。我认为我在某个地方犯了错误。但不确定在哪里。]]></description>
      <guid>https://stackoverflow.com/questions/78299375/calculating-bleu-score-between-two-sumamries-in-python</guid>
      <pubDate>Tue, 09 Apr 2024 14:58:15 GMT</pubDate>
    </item>
    <item>
      <title>静态嵌入与情境化嵌入</title>
      <link>https://stackoverflow.com/questions/78299260/static-vs-contextualized-embeddings</link>
      <description><![CDATA[使用类似于具有一个隐藏层的自动编码器的网络架构的嵌入方法是什么？哪一个？输入是什么？输出是什么？模型中的嵌入向量由哪些部分构成？
我不确定答案是否是 Word2Vec。]]></description>
      <guid>https://stackoverflow.com/questions/78299260/static-vs-contextualized-embeddings</guid>
      <pubDate>Tue, 09 Apr 2024 14:41:00 GMT</pubDate>
    </item>
    <item>
      <title>计算 AI 生成的摘要和人工生成的摘要之间的 BLEU 分数</title>
      <link>https://stackoverflow.com/questions/78299237/calculate-bleu-score-between-ai-generated-summary-and-its-human-derived-summary</link>
      <description><![CDATA[我正在尝试计算人工智能生成的语料库和手动编写的摘要之间的 BLEU、ROGUE 分数。
预测 = &quot;
我是ABC。我已经在 XYZ 大学完成了计算机应用学士学位，目前正在通过远程教育攻读计算机应用硕士学位。
在我的学术旅程中，我已经在 C、C++ 和 Python 等编程语言、SQL 数据库和 uipath 中的 RPA 方面打下了基础，而且我还擅长沟通、解决问题的技能、时间管理等软技能、领导素质 团队合作、协调。我热衷于将我的理论知识转化为现实世界的应用。 ”
手动参考=”
我是ABC。我已经在 XYZ 完成了为期四年的 PC 应用认证，现在正在通过远程培训寻求 PC 应用研究生学位。
在我的学术旅行中，我在 C、C++ 和 Python 等编程语言、SQL 中的数据集和 uipath 中的 RPA 方面建立了自己的基础，而且我还擅长通信、批判性思维能力等微妙能力，有效利用时间，权威质量合作和协调。我热衷于将我的假设信息解释为真正的应用。”
我想通过计算它们的 BLEU 分数和 ROGUE 分数来比较这两个摘要。这是我第一次使用这些指标。所以我不确定是否使用句子_BLEU()或语料库_BLUE或将它们分成标记等。所以如果有人可以帮助我使用Python代码来计算这两个指标？]]></description>
      <guid>https://stackoverflow.com/questions/78299237/calculate-bleu-score-between-ai-generated-summary-and-its-human-derived-summary</guid>
      <pubDate>Tue, 09 Apr 2024 14:36:08 GMT</pubDate>
    </item>
    <item>
      <title>用于回归的非线性数据的离群值检测</title>
      <link>https://stackoverflow.com/questions/78299049/outlier-detection-for-non-linear-data-for-regression</link>
      <description><![CDATA[我正在努力解决两个具有 82% 相关性的参数，这两个参数呈现出非线性关系和连续波动。尽管尝试在 scikit-learn 中使用 LocalOutlierFactor、DBSCAN、IsolationForest 和 PolynomialFeature，但异常值去除仍然具有挑战性。参数1的范围是0.01到0.077，参数2的范围是3到12。
寻求有关有效异常值去除方法的建议，以提高相关性并更好地准备用于训练随机森林回归模型的数据。任何见解或经验将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78299049/outlier-detection-for-non-linear-data-for-regression</guid>
      <pubDate>Tue, 09 Apr 2024 14:08:34 GMT</pubDate>
    </item>
    <item>
      <title>ImportError：无法从“deepface.commons”导入名称“距离”（/opt/anaconda3/envs/LIP/lib/python3.9/site-packages/deepface/commons/__init__.py）</title>
      <link>https://stackoverflow.com/questions/78298624/importerror-cannot-import-name-distance-from-deepface-commons-opt-anacond</link>
      <description><![CDATA[无法在Python中导入deepface
我目前在 macbook 上使用 Pycharm。
虚拟环境已激活，但仍出现以下错误。
谁能帮我一下吗？
Python 3.9
Deepface 0.0.89（最新）
张量流版本2.14.1
虚拟环境已激活。
一切都已安装，但仍无法解决导入错误。]]></description>
      <guid>https://stackoverflow.com/questions/78298624/importerror-cannot-import-name-distance-from-deepface-commons-opt-anacond</guid>
      <pubDate>Tue, 09 Apr 2024 12:57:54 GMT</pubDate>
    </item>
    <item>
      <title>GridSearch + StratifiedGroupKFold 用于连续目标</title>
      <link>https://stackoverflow.com/questions/78298496/gridsearch-stratifiedgroupkfold-for-continous-target</link>
      <description><![CDATA[我想使用 StratifiedGroupKFold 对目标 y 连续且我的组仅的数据集执行 GridSearchCV() 2：

异常值
并非异常值

我一直出错，因为我的目标是“连续的”，但我希望对我的组而不是目标进行分层。例如，假设我进行了 5 次分割，并且有 50 个离群值，那么我想在每个分割中仅保留 10 个离群值。我该如何做到这一点？
这是我尝试过的代码，当然我得到了一个错误：
cv = StratifiedGroupKFold(n_splits=self._k)
组 = X_train[&#39;异常值&#39;].to_numpy()

网格 = GridSearchCV(
            管道，
            网格参数，
            评分=[“neg_mean_squared_error”,“r2”],
            简历=简历，
            详细=0，
            改装=“neg_mean_squared_error”，
）
        
grid.fit(X_train, y_train, groups=groups)

输出：
ValueError：支持的目标类型为：（“二进制”、“多类”）。取而代之的是“连续”。

知道groups变量对应于仅包含0和1的数组。
&lt;前&gt;&lt;代码&gt;&gt;&gt; print(X_train[&#39;离群值])
116 0
86 0
53 0
225 0
647 0
      ..
75 0
112 0
280 0
450 0
108 1
名称：异常值，长度：555，dtype：int64
]]></description>
      <guid>https://stackoverflow.com/questions/78298496/gridsearch-stratifiedgroupkfold-for-continous-target</guid>
      <pubDate>Tue, 09 Apr 2024 12:36:58 GMT</pubDate>
    </item>
    <item>
      <title>R 中 randomForest() 中单棵树生长的停止标准？</title>
      <link>https://stackoverflow.com/questions/78298488/stopping-criterion-for-single-tree-growth-in-randomforest-in-r</link>
      <description><![CDATA[如果在 R 中以基本方式使用库（randomForest）中的函数 randomForest()，森林中单棵树的停止标准是什么：
库（随机森林）
randomForest(y ~ ., 数据 = data_train, ntree = 500)
]]></description>
      <guid>https://stackoverflow.com/questions/78298488/stopping-criterion-for-single-tree-growth-in-randomforest-in-r</guid>
      <pubDate>Tue, 09 Apr 2024 12:35:50 GMT</pubDate>
    </item>
    <item>
      <title>努力开发使用带有 ARFRegressor 算法的 River 库的在线学习代码</title>
      <link>https://stackoverflow.com/questions/78298486/struggling-with-developing-code-for-an-online-learning-using-river-library-with</link>
      <description><![CDATA[我已经分割了数据，但正在努力编写用于训练模型的代码，并使用 pickle 将模型保存在特定目录中以供将来使用。关于如何继续的任何建议？
# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

从河流进口评估
从河流进口森林
来自河流的进口指标
来自河流的进口预处理

型号=（
    预处理.StandardScaler() |
    森林.ARFRegressor(种子=42)
）
指标 = 指标.MAE()

# 在测试集上评估模型
mae = evaluate.progressive_val_score(X_test, y_test, 模型, 指标)
print(f&#39;测试集上的 MAE: {mae}&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78298486/struggling-with-developing-code-for-an-online-learning-using-river-library-with</guid>
      <pubDate>Tue, 09 Apr 2024 12:35:37 GMT</pubDate>
    </item>
    <item>
      <title>TensorBoard HParams 未显示超参数调整的准确性指标</title>
      <link>https://stackoverflow.com/questions/78298357/tensorboard-hparams-not-showing-accuracy-metrics-for-hyperparameter-tuning</link>
      <description><![CDATA[我正在 TensorFlow 中进行超参数调整，并使用 TensorBoard 中的 HParams 插件设置了一个实验来记录不同的配置。我的模型正在使用 dropout 和学习率的变化进行训练，并且我正在记录这些参数以及模型的准确性。但是，当我打开 TensorBoard 并导航到 HParams 仪表板时，不会显示与每个试验相关的准确性指标。该表正确显示了超参数，但“准确性”列为空，即使我的代码使用“准确性”作为指标来编译模型并使用 hp.KerasCallback 进行日志记录。我已经验证了模型训练正确，并且标量仪表板等其他 TensorBoard 功能显示了各个时期的准确性趋势。我正在寻求帮助来理解为什么 HParams 表中没有显示准​​确性以及如何解决此问题。
我使用 TensorBoard 的 HParams 进行超参数调整的代码：
 from tensorboard.plugins.hparams import api as hp
    将张量流导入为 tf
    从tensorflow.keras.layers导入Conv2D、MaxPooling2D、Dense、Flatten、Dropout

    # 定义超参数
    HP_DROPOUT = hp.HParam(&#39;dropout&#39;, hp.Discrete([0.2, 0.3, 0.4]))
    HP_LEARNING_RATE = hp.HParam(&#39;learning_rate&#39;, hp.Discrete([1e-2, 1e-3]))

    # 设置日志记录
    log_dir = &#39;./tensorboard/nn_1&#39;
    使用 tf.summary.create_file_writer(log_dir).as_default()：
        hp.hparams_config(
            hparams=[HP_DROPOUT, HP_LEARNING_RATE],
            指标=[hp.Metric(&#39;准确度&#39;,display_name=&#39;准确度&#39;)]
        ）

    # 训练函数
    def train_test_model(hparams, session_num):
        model_name = f“model_1_session_{session_num}”
        print(f&quot;使用超参数 {hparams} 训练 {model_name}...&quot;)
        模型 = tf.keras.Sequential([
            Conv2D(32, kernel_size=(3, 3), 激活=&#39;elu&#39;),
            辍学（hparams [HP_DROPOUT]），
            Conv2D(32, kernel_size=(3, 3), 激活=&#39;elu&#39;),
            辍学（hparams [HP_DROPOUT]），
            MaxPooling2D(pool_size=(2, 2)),
            展平（），
            密集（10，激活=&#39;softmax&#39;）
        ]）
        模型.编译(
            损失=&#39;分类交叉熵&#39;，
            优化器=tf.keras.optimizers.Adam(hparams[HP_LEARNING_RATE]),
            指标=[&#39;准确性&#39;]
        ）

        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f&#39;{log_dir}/{model_name}&#39;)
        hparams_callback = hp.KerasCallback(writer=f&#39;{log_dir}/{model_name}&#39;, hparams=hparams)

        模型.拟合(
            x_train_reshape, y_train_,
            纪元=3，
            验证数据=（x_val_reshape，y_val），
            回调=[hparams_callback，tensorboard_callback]
        ）

    # 对每组超参数进行训练
    会话编号 = 0
    对于 HP_DROPOUT.domain.values 中的 dropout_rate：
        对于 HP_LEARNING_RATE.domain.values 中的learning_rate：
            hparams = {
                HP_DROPOUT：辍学率，
                HP_LEARNING_RATE：学习率，
            }
            train_test_model(hparams, session_num)
            会话编号 += 1
]]></description>
      <guid>https://stackoverflow.com/questions/78298357/tensorboard-hparams-not-showing-accuracy-metrics-for-hyperparameter-tuning</guid>
      <pubDate>Tue, 09 Apr 2024 12:14:56 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入实现命名实体识别</title>
      <link>https://stackoverflow.com/questions/78298106/implementating-named-entity-recognition-using-embeddings</link>
      <description><![CDATA[我想使用 OpenAI 的 CLIP 模型对图像文本数据集执行多模态命名实体识别。
我已经将这些图像文本转换为嵌入，但是现在如何对它们执行 NER 呢？或者有更好的方法使用 CLIP 模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/78298106/implementating-named-entity-recognition-using-embeddings</guid>
      <pubDate>Tue, 09 Apr 2024 11:27:27 GMT</pubDate>
    </item>
    <item>
      <title>标签未包含在我的张量数据集中</title>
      <link>https://stackoverflow.com/questions/78297824/label-not-included-inside-my-tensor-dataset</link>
      <description><![CDATA[所以我是机器学习的新手，我想使用 BERT 模型中的预训练模型，然后我遇到了标签输出未插入张量类型数据集的问题。有人有解决办法吗？
from sklearn.model_selection import train_test_split
X = 特征[&#39;clean_text&#39;]
y = 特征[&#39;标签&#39;]
X_train、X_test、y_train、y_test=train_test_split(X、y、test_size = 0.3、random_state = 42)
X_train = tokenizer(X_train.tolist(), 填充 = True, 截断 = True)
X_test = tokenizer(X_test.tolist(), 填充 = True, 截断 = True)
X_train = 字典(X_train)
X_test = 字典(X_test)
y_train = y_train.tolist()
y_test = y_test.tolist()
df_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))
df_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))
输入，输出=下一个（iter（df_train））
打印出）

输出如下：tf.Tensor(0, shape=(), dtype=int32)]]></description>
      <guid>https://stackoverflow.com/questions/78297824/label-not-included-inside-my-tensor-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 10:36:28 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种算法来检测汽车多媒体启动时侧边栏的出现？</title>
      <link>https://stackoverflow.com/questions/78297772/which-algorithm-to-use-to-detect-the-appearance-of-sidebar-on-car-multimedia-boo</link>
      <description><![CDATA[我需要创建一个系统来检测从启动汽车多媒体系统到侧边栏首次出现在屏幕上之间所经过的时间。侧边栏具有矩形形状，并且始终位于屏幕的边缘之一。根据汽车制造商的不同，多媒体的外观也有所不同。我想知道如果我不关心执行速度或实时工作，哪种图像检测算法最合适。
SSD、Faster R-CNN、YOLO 还是其他？]]></description>
      <guid>https://stackoverflow.com/questions/78297772/which-algorithm-to-use-to-detect-the-appearance-of-sidebar-on-car-multimedia-boo</guid>
      <pubDate>Tue, 09 Apr 2024 10:25:32 GMT</pubDate>
    </item>
    <item>
      <title>如何计算二元分类概率[关闭]</title>
      <link>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</link>
      <description><![CDATA[我正在研究一些基于数值特征的二元分类问题，例如预测维护、信用卡欺诈、心脏病等。我通常喜欢使用随机森林，因为它用途广泛、稳健且可以获得高指标。
除了预测1或0之外，我还想预测获得1的概率（在0.00到1.00之间浮动）。如何在代码中实现这一点？
我使用了随机森林分类器的predict_proba()方法。然而，它主要产生极值（0.00 - 0.10 和 0.90 - 1.00）。 也许它没有很好地校准？另外，我使用了SVM分类器的decision_function()方法，但SVM似乎不是很通用。因此我正在寻找一种不同的方法。
我更喜欢与 RF 分类器相关的方法，但我对其他方法持开放态度。
这是我的代码的相关部分：
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

校准器 = CaliberatedClassifierCV(rf, cv=&#39;prefit&#39;)
模型 = calibrator.fit(X_train, y_train)

概率 = model.predict_proba(X_test)

y_pred = model.predict(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</guid>
      <pubDate>Tue, 09 Apr 2024 07:56:47 GMT</pubDate>
    </item>
    <item>
      <title>YOLOV8 预测相反类别 [关闭]</title>
      <link>https://stackoverflow.com/questions/78292691/yolov8-predicting-opposite-classes</link>
      <description><![CDATA[我正在尝试使用 Yolov8n.pt 检测对象。我已经使用 RoboFlow 分配了课程。该模型预测的类别非常相反。为什么？如果有请给出解决方案。谢谢。
我无法上传参考图片，因此我添加了该图片的链接。请在下面找到它：]]></description>
      <guid>https://stackoverflow.com/questions/78292691/yolov8-predicting-opposite-classes</guid>
      <pubDate>Mon, 08 Apr 2024 12:57:12 GMT</pubDate>
    </item>
    <item>
      <title>如何解读scikit的learn混淆矩阵和分类报告？</title>
      <link>https://stackoverflow.com/questions/30746460/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report</link>
      <description><![CDATA[我有一个情感分析任务，为此我使用这个语料库，意见有 5 个类别 (非常负、负、neu、pos、非常pos），从1到5。所以我做如下分类：
从 sklearn.feature_extraction.text 导入 TfidfVectorizer
将 numpy 导入为 np
tfidf_vect= TfidfVectorizer(use_idf=True, smooth_idf=True,
                            sublinear_tf=False, ngram_range=(2,2))
从 sklearn.cross_validation 导入 train_test_split, cross_val_score

将 pandas 导入为 pd

df = pd.read_csv(&#39;/corpus.csv&#39;,
                     标头=0，sep=&#39;,&#39;,名称=[&#39;id&#39;,&#39;内容&#39;,&#39;标签&#39;])

X = tfidf_vect.fit_transform(df[&#39;content&#39;].values)
y = df[&#39;标签&#39;].值


从 sklearn 导入交叉验证
X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,
                                                    y，测试大小=0.33）


从 sklearn.svm 导入 SVC
svm_1 = SVC(内核=&#39;线性&#39;)
svm_1.fit(X, y)
svm_1_prediction = svm_1.predict(X_test)

然后通过指标我获得了以下混淆矩阵和分类报告，如下：
print &#39;\n分类报告:\n&#39;,classification_report(y_test, svm_1_prediction)
print &#39;\n混淆矩阵:\n&#39;,confusion_matrix(y_test, svm_1_prediction)

然后，这就是结果：
分类报告：
             精确召回率 f1-score 支持

          1 1.00 0.76 0.86 71
          2 1.00 0.84 0.91 43
          3 1.00 0.74 0.85 89
          4 0.98 0.95 0.96 288
          5 0.87 1.00 0.93 367

平均/总计 0.94 0.93 0.93 858


混淆矩阵：
[[ 54 0 0 0 17]
 [ 0 36 0 1 6]
 [0 0 66 5 18]
 [ 0 0 0 273 15]
 [0 0 0 0 367]]

如何解释上述混淆矩阵和分类报告。我尝试阅读 文档 和这个 问题。但仍然可以解释这里发生了什么，特别是用这些数据？这个矩阵在某种程度上是“对角的”吗？另一方面，召回率、精确率、f1score 和该数据的支持度意味着什么？对于这个数据我能说什么？提前感谢大家]]></description>
      <guid>https://stackoverflow.com/questions/30746460/how-to-interpret-scikits-learn-confusion-matrix-and-classification-report</guid>
      <pubDate>Wed, 10 Jun 2015 03:12:02 GMT</pubDate>
    </item>
    </channel>
</rss>