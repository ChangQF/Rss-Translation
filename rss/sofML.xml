<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 27 May 2024 18:18:52 GMT</lastBuildDate>
    <item>
      <title>我有一个问题“NoneType”对象没有属性“download_as_string”</title>
      <link>https://stackoverflow.com/questions/78540003/i-have-a-problem-with-nonetype-object-has-no-attribute-download-as-string</link>
      <description><![CDATA[
1-逐行查看代码
2- firebase 存储以及它是否有效
3-在 pip $ /path/to/venv/bin/pip install -U requests 中下载我的需求]]></description>
      <guid>https://stackoverflow.com/questions/78540003/i-have-a-problem-with-nonetype-object-has-no-attribute-download-as-string</guid>
      <pubDate>Mon, 27 May 2024 15:41:23 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中找到椭圆的角度（使用图像分析）</title>
      <link>https://stackoverflow.com/questions/78539909/how-do-i-find-the-angle-of-an-ellipse-in-pythonusing-image-analysis</link>
      <description><![CDATA[
我正在处理的问题是试图找到椭圆的半长轴与 x 轴的角度。为此，我必须找到椭圆的长轴，得到长轴的方程，然后得到梯度的反正切值。
我在python中使用的方法是：
我首先加载图像并将其转换为灰度。然后，我使用阈值对灰度图像进行二值化（阈值以上的像素变为白色，阈值以下的像素变为黑色）。然后迭代二值化图像中的每个像素。如果像素为黑色（值为 0），我会计算该像素与椭圆质心（质心）之间的欧几里得距离。最大距离将是长轴，像素和中心的坐标将是我可以用来获得长轴和 theta 的方程的两个坐标。问题是我在 powerpoint 中制作了一张图片，将其旋转到大约 25 度，但我得到的答案是大约 30 度，所以我不知道哪里出错了。有人可以帮我吗？
&lt;前&gt;&lt;代码&gt;导入cv2
将 numpy 导入为 np
从 scipy 导入 ndimage
将 matplotlib.pyplot 导入为 plt
导入数学

def euclidean_distance(a, 行, 列):
    ”“”
    计算两点之间的欧几里得距离。
    参数：
        a（元组）：质心（x，y）。
        row (int)：像素的行索引。
        col (int)：像素的列索引。
    返回：
        float：欧几里德距离。
    ”“”
    返回 np.sqrt((a[0] - 列) ** 2 + (a[1] - 行) ** 2)

定义角度（a、行、列）：
    ”“”
    计算长轴和 x 轴之间的角度。
    参数：
        a（元组）：质心（x，y）。
        row (int)：像素的行索引。
        col (int)：像素的列索引。
    返回：
        浮动：以度为单位的角度。
    ”“”
    斜率 = (a[0] - 列) / (a[1] - 行)
    返回 math.atan(斜率)

# 加载图像
image_path =“/Users/yahya2/Desktop/xy1.png”
img = cv2.imread(图像路径)
a = ndimage.center_of_mass(img)

# 将图像转换为灰度图
灰色 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 将灰度图像二值化
_, img_bin = cv2.threshold(灰色, 128, 255, cv2.THRESH_BINARY)

# 获取图像的尺寸
行、列 = img_bin.shape
最大长度=0
最大行数、最大列数 = 0, 0

# 循环遍历图像中的每个像素
对于范围内的行（行）：
    对于范围内的列（列）：
        # 检查像素是否为黑色 (0)
        如果 img_bin[行, 列] == 0:
            长度=欧几里得距离（a，行，列）
            如果长度&gt;最长长度：
                最大长度 = 长度
                最大行、最大列 = 行、列

# 计算角度
主轴角度 = 角度(a, 最大行, 最大列)
print(f&quot;长轴角度(度): {major_axis_angle:.2f}&quot;)

# 可视化结果
图, ax = plt.subplots(figsize=(8, 8))
ax.imshow(img, cmap=&#39;灰色&#39;)
plt.scatter（max_col，max_row，颜色=&#39;红色&#39;，标记=&#39;x&#39;，s=100）
plt.show()


这是我得到的结果：
]]></description>
      <guid>https://stackoverflow.com/questions/78539909/how-do-i-find-the-angle-of-an-ellipse-in-pythonusing-image-analysis</guid>
      <pubDate>Mon, 27 May 2024 15:21:17 GMT</pubDate>
    </item>
    <item>
      <title>无法从 feature_extractor 获取正确的输入形状</title>
      <link>https://stackoverflow.com/questions/78539772/unable-to-get-correct-shape-of-input-from-feature-extractor</link>
      <description><![CDATA[我尝试从音频片段中提取特征。现在我有 90 个段，它们已填充到相同的长度 48000。所以形状是 (90, 48000)。但是，当我尝试将其输入 feature_extractor 时，出现错误：
运行时错误：需要 2D（未批处理）或 3D（批处理）输入到 conv1d，但得到的输入大小为：[1, 1, 90, 48000]
另外生成了两个维度。有人能帮我吗？谢谢！
processor = AutoProcessor.from_pretrained(“microsoft/wavlm-base-plus-sd”)
使用 autocast()、torch.no_grad()：
                word_wavs = pad_sequence(word_wavs, batch_first=True, padding_value=0) # 90(6windowsize*15words) x 48000(16k*3s)
                word_lens = torch.stack(word_lens)
                输入=处理器（word_wavs，return_tensors =&#39;pt&#39;，sampling_rate = sr，padding = True）

我打印出了输入的形状，注意掩模的形状为 (1, 90)，input_values 的形状为 (1, 90, 48000)。]]></description>
      <guid>https://stackoverflow.com/questions/78539772/unable-to-get-correct-shape-of-input-from-feature-extractor</guid>
      <pubDate>Mon, 27 May 2024 14:51:02 GMT</pubDate>
    </item>
    <item>
      <title>监督异常检测问题中的平衡和不平衡</title>
      <link>https://stackoverflow.com/questions/78539548/balancing-and-imbalancing-in-supervised-anomaly-detection-probelm</link>
      <description><![CDATA[我正在处理一个监督异常检测问题，其中标签为 0 表示正常，1 表示异常。数据集的默认分布高度不平衡，正常和异常的比例分别为 96:4。
因此，我应用随机欠采样将正常和异常的比率降低到 55:45。现在，准确度为 98%，如下面还提供的其他指标所示。这个概念是正确的还是我错了？
准确度：0.98467329
精度：0.98027553
召回率：0.98755102
F1-分数：0.98389996
曲线下面积：0.98500429
卡帕：0.97917268]]></description>
      <guid>https://stackoverflow.com/questions/78539548/balancing-and-imbalancing-in-supervised-anomaly-detection-probelm</guid>
      <pubDate>Mon, 27 May 2024 14:03:46 GMT</pubDate>
    </item>
    <item>
      <title>Python 中导入的 Orange 模型无法正确获取输入数据</title>
      <link>https://stackoverflow.com/questions/78539448/orange-model-imported-in-python-doesnt-get-the-input-data-right</link>
      <description><![CDATA[我通过 Orange 数据挖掘训练了一个模型。这很简单，它只是根据申请人的一些信息来预测他是否可以获得贷款。我想把它放在Python中，但我不明白如何传递数据。此外，我认为我在数据标准化方面犯了错误，比如字符串（因此橙色上的分类值）可能应该变成数字，等等。
我尝试通过表单填充的向量传递数据；直接来自 Excel 文件；我自己输入数据只是为了看看是否发生了变化。似乎没有什么工作正常。在网上冲浪时，我发现了一些有关 .tab 文件的信息（部署 Orange 3 模型），但我不明白如何具体转换为该扩展名。]]></description>
      <guid>https://stackoverflow.com/questions/78539448/orange-model-imported-in-python-doesnt-get-the-input-data-right</guid>
      <pubDate>Mon, 27 May 2024 13:45:24 GMT</pubDate>
    </item>
    <item>
      <title>在与我之前训练的数据集不同的数据集上训练 yolov8 变得非常慢</title>
      <link>https://stackoverflow.com/questions/78539266/training-yolov8-on-a-different-data-set-than-i-had-previously-trained-it-on-beca</link>
      <description><![CDATA[我正在尝试在与我之前训练过的数据集不同的数据集上训练 yolov8。尽管这是一个较小的数据集，但即使 1 个 epoch 也需要极长的时间才能完成。还有其他人遇到这个问题吗？我可能哪里出错了？
我正在尝试在与我之前训练过的数据集不同的数据集上训练 yolov8。尽管这是一个较小的数据集，但即使 1 个 epoch 也需要非常长的时间才能完成。]]></description>
      <guid>https://stackoverflow.com/questions/78539266/training-yolov8-on-a-different-data-set-than-i-had-previously-trained-it-on-beca</guid>
      <pubDate>Mon, 27 May 2024 13:08:40 GMT</pubDate>
    </item>
    <item>
      <title>Unet图像分割的过拟合问题</title>
      <link>https://stackoverflow.com/questions/78539247/overfitting-problem-of-image-segmentation-with-unet</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78539247/overfitting-problem-of-image-segmentation-with-unet</guid>
      <pubDate>Mon, 27 May 2024 13:03:48 GMT</pubDate>
    </item>
    <item>
      <title>需要帮助根据加速度计数据确定步节奏[关闭]</title>
      <link>https://stackoverflow.com/questions/78538684/need-help-determining-step-rhythm-from-accelerometer-data</link>
      <description><![CDATA[上下文：
我目前正在开展一个项目，其中有来自连接到马前腿的 MetaWear 加速计传感器的数据。该数据包括所有三个轴点的时间序列信息，并在马持续慢跑时记录。我之前使用梯度增强机 (GBM) 进行了特征提取，以识别马是否处于慢跑状态或其他步态。
目标：
我的目标是仅根据加速度计数据来确定马慢跑时的节奏。例如，马可以非常慢地慢跑或非常快地慢跑，我希望能够通过测量每分钟的步数来捕获慢跑速度的变化。本质上，我想了解在给定时间范围内步伐节奏重复的频率。
挑战：
我的数据没有标记，但我可以直观地识别重复模式。
我需要一种有效的方法来标记数据，最好不要手动标记所有重复项。
我研究过 Grafana 等工具，但发现它们不能满足我的需求。
问题：
从给定的加速度计数据确定节奏（每分钟的节拍或步数）的最佳方法是什么？
是否有任何拖放标签工具可以帮助有效地标记大约 100 次重复？或者，是否有任何技术可以避免手动标记？
您会推荐任何其他策略来以不同的方式解决这个问题吗？
其他信息：
这是一个链接 https://docs .google.com/document/d/1iAnwyA9y2AlG2p_CiVEAYdeVEJjL9QKPrbyegsFpCJ8/edit?usp=sharing到我的数据屏幕截图以提供更多背景信息。]]></description>
      <guid>https://stackoverflow.com/questions/78538684/need-help-determining-step-rhythm-from-accelerometer-data</guid>
      <pubDate>Mon, 27 May 2024 11:04:47 GMT</pubDate>
    </item>
    <item>
      <title>在Python Google Colab中安装skater包时出现2个错误，这些错误是依赖项冲突和解决不可能错误</title>
      <link>https://stackoverflow.com/questions/78538485/getting-2-errors-while-installing-skater-package-in-python-google-colab-the-err</link>
      <description><![CDATA[!pip installskaker

收集滑冰者

  下载skater-1.1.2.tar.gz (96 kB)

     ──────────────────────────────────────────────────────────────────── 96.7/96.7 kB 1.0 MB/秒 eta 0 :00:00

  准备元数据（setup.py）...完成

已满足要求：/usr/local/lib/python3.10/dist-packages 中的 scikit-learn&gt;=0.18 （来自滑板者）(1.2.2)

收集 scikit-image==0.14 （来自滑板手）

  下载 scikit-image-0.14.0.tar.gz (27.0 MB)

     ────────────────────────────────────────────────────────────────── 27.0/27.0 MB 17.4 MB/秒 eta 0 :00:00

  准备元数据（setup.py）...完成

已满足要求： /usr/local/lib/python3.10/dist-packages 中的 pandas&gt;=0.22.0 （来自滑板者）（2.0.3）

信息：pip 正在查看 Skaker 的多个版本，以确定哪个版本与其他要求兼容。这可能需要一段时间。

收集滑冰者

  下载skater-1.1.0.tar.gz (52 kB)

     ────────────────────────────────────────────────────────────────── 52.5/52.5 kB 1.1 MB/秒 eta 0 :00:00

  准备元数据（setup.py）...完成

  下载skaker-1.0.4.tar.gz (41 kB)

     ────────────────────────────────────────────────────────────────── 41.4/41.4 kB 687.0 kB/s eta 0 :00:00

  准备元数据（setup.py）...完成

  下载skaker-1.0.2.tar.gz (37 kB)

  准备元数据（setup.py）...完成

  下载skaker-1.0.1.tar.gz (36 kB)

  准备元数据（setup.py）...完成

错误：无法安装skate==1.0.1、skate==1.0.2、skate==1.0.4、skate==1.1.0 和skate==1.1.2，因为这些包版本具有冲突的依赖项。



冲突的原因是：

    溜冰者 1.1.2 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.1.0 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.0.4 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.0.2 取决于 ds-lime&gt;=0.1.1.21

    溜冰者 1.0.1 取决于 ds-lime&gt;=0.1.1.21



要解决此问题，您可以尝试：

1.放宽您指定的软件包版本范围

2.删除软件包版本以允许pip尝试解决依赖冲突



错误：分辨率不可能：如需帮助，请访问 https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts

我尝试在 python Google Colab 中安装skaker 包，但出现上述两个错误。我已访问了提到的链接，但无法理解如何解决此问题。]]></description>
      <guid>https://stackoverflow.com/questions/78538485/getting-2-errors-while-installing-skater-package-in-python-google-colab-the-err</guid>
      <pubDate>Mon, 27 May 2024 10:17:51 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模型只学习数据不平衡</title>
      <link>https://stackoverflow.com/questions/78538318/pytorch-model-learns-just-data-imbalance</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78538318/pytorch-model-learns-just-data-imbalance</guid>
      <pubDate>Mon, 27 May 2024 09:40:30 GMT</pubDate>
    </item>
    <item>
      <title>验证码解决：-任何人都可以帮我解决这个验证码问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78537910/captcha-solving-can-anyone-help-me-to-solve-this-captcha-problem</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt;导入cv2
导入 pytesseract
从 PIL 导入图像

image = cv2.imread(&#39;D:\Automation\captchas\captcha.png&#39;)
如果图像为无：
    print(&quot;错误：无法加载图像。请检查文件路径是否正确以及文件是否存在。&quot;)
别的：
    灰色 = cv2.cvtColor(图像, cv2.COLOR_BGR2GRAY)

    _, 阈值 = cv2.threshold(灰色, 8, 255, cv2.THRESH_BINARY)

    内核 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    morphed = cv2.morphologyEx（阈值，cv2.MORPH_CLOSE，内核）
    中值 = cv2.medianBlur(变形, 3)

    
    cv2.imshow(&#39;处理后的图像&#39;, 中位数)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    cv2.imwrite(&#39;D:\Automation\captchas\morphed_image.png&#39;, 中值)

    pytesseract.pytesseract.tesseract_cmd = r&#39;C:/Program Files/Tesseract-OCR/tesseract.exe&#39;
    image_path = “D:\Automation\captchas\morphed_image.png”
    使用 Image.open(image_path) 作为 img：
        文本 = pytesseract.image_to_string(image_path, config=&#39; -c tessedit_char_whitelist=0123456789&#39;)
    打印（“文本：”，文本）

在此处输入图片描述
请我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78537910/captcha-solving-can-anyone-help-me-to-solve-this-captcha-problem</guid>
      <pubDate>Mon, 27 May 2024 08:18:20 GMT</pubDate>
    </item>
    <item>
      <title>如何将张量（pytorch）作为ndarray放入函数中，在每次操作后保留梯度函数？</title>
      <link>https://stackoverflow.com/questions/78536832/how-put-a-tensor-pytorch-as-ndarray-in-a-function-keep-a-gradient-function-af</link>
      <description><![CDATA[如何将 PyTorch 张量作为 ndarray 传递给模拟函数而不丢失梯度信息，或者是否有一种解决方法允许该函数接受张量，同时保留前向和反向传播的必要属性？
TypeError: &#39;model&#39; 必须是 array_like，数据类型为 ， 
得到

导入simulation.dc作为dc
将 numpy 导入为 np

?model = import(//模型路径)
模型=张量（...，requiere_true = True）
dpred = dc.fields.make_a_sintetic_data(模型)
打印（类型（dpred））

＃ 输出：
&gt;&gt;&gt;张量，fn_gradient(...) 
]]></description>
      <guid>https://stackoverflow.com/questions/78536832/how-put-a-tensor-pytorch-as-ndarray-in-a-function-keep-a-gradient-function-af</guid>
      <pubDate>Mon, 27 May 2024 00:59:11 GMT</pubDate>
    </item>
    <item>
      <title>如何使用权重和偏差 wandb 扫描来实现多处理以实现最大程度的并行化，尤其是计数变量在此设置下如何工作？</title>
      <link>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</guid>
      <pubDate>Thu, 23 May 2024 05:25:30 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中却不行 [关闭]</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 Python 编写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def 预处理图像（图像路径）：
    # 加载图像
    img = Image.open(图像路径)
    # 调整图像大小并将其转换为灰度
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将图像转换为 numpy 数组并调整大小为单个向量
    img_array = np.array(img).reshape(1, -1)
    返回img_array
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;成功模型&quot;)
    # 上传并预处理图像
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # 预测班级
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

在橙色工作流程中，我使用了逻辑回归，该模型的准确性相当高。在图像嵌入中我使用了 Inception v3。  这是我获取数据集的位置。我认为我预处理图像的方式有问题，也许它与 Orange 的做法不同，但我找不到有关 Orange 如何做法的任何信息 这是 Orange 工作流程的图像。
编辑：我还尝试在输入中提供一个图像文件夹，结果并不总是相同，但在包含 500 张猫和狗照片的文件夹中，模型仅识别 10 只狗（对绝大多数狗进行错误分类）]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    <item>
      <title>如何从头开始训练 gpt 2？</title>
      <link>https://stackoverflow.com/questions/59327637/how-do-i-train-gpt-2-from-scratch</link>
      <description><![CDATA[我想从头开始训练 gpt 2，但我发现的文章中只有基于预训练模型的微调方法。
我已经使用这个 https://github.com/nshepperd/gpt-2 进行训练现有模型。我应该编辑这些 Python 脚本来从头开始训练吗？]]></description>
      <guid>https://stackoverflow.com/questions/59327637/how-do-i-train-gpt-2-from-scratch</guid>
      <pubDate>Fri, 13 Dec 2019 17:57:46 GMT</pubDate>
    </item>
    </channel>
</rss>