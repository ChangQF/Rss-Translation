<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 07 Apr 2024 06:15:52 GMT</lastBuildDate>
    <item>
      <title>如何为 CNN 机器学习模型制作前端和后端</title>
      <link>https://stackoverflow.com/questions/78286791/how-to-make-a-frontend-and-a-backend-for-a-cnn-machine-learning-model</link>
      <description><![CDATA[我制作了一个机器学习模型来检测马铃薯植株上的疾病。现在我想为模型创建一个前端，从用户那里获取图像并预测输出，同时我还想要一个后端来存储数据。另外我将如何集成前端和后端。
我想知道如何创建一个后端来存储数据。以及如何整合前端和后端。]]></description>
      <guid>https://stackoverflow.com/questions/78286791/how-to-make-a-frontend-and-a-backend-for-a-cnn-machine-learning-model</guid>
      <pubDate>Sun, 07 Apr 2024 05:53:18 GMT</pubDate>
    </item>
    <item>
      <title>如何将预处理图像从 jupyter 笔记本导出到下载中的“preprocessedimages”文件？</title>
      <link>https://stackoverflow.com/questions/78286595/how-can-i-export-preprocessed-images-from-jupyter-notebook-to-preprocessedimage</link>
      <description><![CDATA[我正在开发一款支持机器学习的石头剪刀布游戏应用程序。在探索包含“岩石”的数据集之后文件，“纸质”文件和“剪刀”中，我使用翻转、旋转等变换生成了 RPS 数据集中 1751 个图像的变体。现在，我需要将所有预处理图像导出到名为“preprocessedimages”的空文件中。在我电脑的下载文件中。
如何编写一个循环，将变换（翻转、旋转、重新缩放）应用于数据中的所有图像，并将每个调整后的图像保存在文件夹中？我使用下面的代码生成了增强图像，但如何导出它们？
def Data_Preprocessing(x_train,y_train, x_test, y_test, Batch_size):
    
    
    train_datagen = 图像数据生成器(
        水平翻转=真，
        垂直翻转=真，
        旋转范围 = 20,
        重新缩放 = 1./255)
   
    train_generator = train_datagen.flow（x_train，y_train，batch_size = Batch_size）
    
    test_datagen = ImageDataGenerator（重新缩放= 1./255）
    
    
    test_generator = test_datagen.flow（x_test，y_test，batch_size = Batch_size，shuffle = False）
    
    
    返回train_generator、test_generator

&lt;前&gt;&lt;代码&gt;BATCH_SIZE = 64
train_gen、test_gen = 数据预处理（x_train、y_train、x_test、y_test、Batch_size = BATCH_SIZE）

对于train_gen中的批次：
    图像、标签=批次
    数据可视化（图像、标签、label_str、grid_size = (5, 5)）
]]></description>
      <guid>https://stackoverflow.com/questions/78286595/how-can-i-export-preprocessed-images-from-jupyter-notebook-to-preprocessedimage</guid>
      <pubDate>Sun, 07 Apr 2024 03:54:42 GMT</pubDate>
    </item>
    <item>
      <title>OpenCV 新手，我如何安装/构建 opencv_traincascade</title>
      <link>https://stackoverflow.com/questions/78286577/new-to-opencv-how-do-i-install-build-opencv-traincascade</link>
      <description><![CDATA[所以我一直致力于机器学习项目，并且需要使用 opencv_traincascade 训练自定义数据集。但每当我尝试安装它时，它就永远无法工作。我还有其他东西，比如 opencv_annotation 和其他东西可以工作，但是 traincascade 或 event createsamples 不起作用。我必须手动构建这些吗？
我下载了mingw-gcc、cmake，在网上找不到可行的解决方案。顺便说一句，我有 opencv 4.9.0，手动安装在 anaconda 和我的 C: 驱动器中。我也尝试过寻找一些第三方，他们安装了整个 opencv 并且可以复制，但没有运气。任何帮助将不胜感激，谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78286577/new-to-opencv-how-do-i-install-build-opencv-traincascade</guid>
      <pubDate>Sun, 07 Apr 2024 03:46:34 GMT</pubDate>
    </item>
    <item>
      <title>将 Python 推荐系统连接到 Laravel 应用程序</title>
      <link>https://stackoverflow.com/questions/78286410/connecting-python-recommendation-system-to-laravel-application</link>
      <description><![CDATA[我使用 Python 和余弦相似度算法开发了一个基本的推荐系统。现在，我有兴趣创建一个 Laravel 应用程序来集成这个推荐系统。但是，我不确定如何在两者之间建立联系。
任何帮助将不胜感激！
我没有找到任何可以开始的东西！！]]></description>
      <guid>https://stackoverflow.com/questions/78286410/connecting-python-recommendation-system-to-laravel-application</guid>
      <pubDate>Sun, 07 Apr 2024 01:54:56 GMT</pubDate>
    </item>
    <item>
      <title>所有模型的训练、验证集和测试集的 F1 分数、精确度和召回率均较高</title>
      <link>https://stackoverflow.com/questions/78286020/high-f1-score-precision-and-recall-on-training-validation-set-and-test-set-on</link>
      <description><![CDATA[我正在研究一个关于 Kaggle。有一些特征，例如燃料消耗、燃料等。我尝试根据该数据集进行分类任务，将排放量高于 160 定义为不可接受 (1)，低于 160 定义为可接受 (0)。数据不平衡，可接受类有13269个数据，不可接受类有9287个数据。我尝试使用不同的分类模型，例如随机森林分类器、决策树分类器和逻辑回归，所有这些模型在训练集、验证集甚至测试集上都实现了接近 1 的 f1 分数，这看起来很奇怪。数据没有缺失值或空值，并且在将其输入模型之前由标准定标器进行标准化。
在此处输入图像说明在此处输入图像描述
我的第一个假设是当所有模型都这样执行时数据泄漏。我多次检查了代码，甚至用函数检查了数据集，训练集和测试集之间没有重复的行。我尝试使用所有特征，然后使用随机森林发现最相关的一些特征，例如“COMB（L/100 km）”、“COMB（mpg）”、“燃油消耗”、“HWY（L/100 km）” 100 公里）”、“气缸”、“发动机尺寸”和他们玩了一下，但在所有精确度、召回率和 f1 上仍然获得了高分。我通过偶然从较大的类中删除一些数据来平衡数据集。我使用网格搜索制作模型，因此我尝试通过定义不同的参数网格以及手动定义来使模型更加复杂和简单。我还通过阈值检查了精度和召回率。
在此处输入图片说明
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78286020/high-f1-score-precision-and-recall-on-training-validation-set-and-test-set-on</guid>
      <pubDate>Sat, 06 Apr 2024 21:57:10 GMT</pubDate>
    </item>
    <item>
      <title>循环图像时出现 TensorFlow InvalidArgumentError</title>
      <link>https://stackoverflow.com/questions/78285543/tensorflow-invalidargumenterror-while-looping-over-images</link>
      <description><![CDATA[迭代图像时出现以下错误：
InvalidArgumentError: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} 图像中固有的通道数必须为 1、3 或 4，为 2
     [[{{节点decode_image/DecodeImage}}]] [Op:IteratorGetNext]名称：

我用来定义数据和迭代图像的代码：
data=tf.keras.utils.image_dataset_from_directory（main_path，batch_size=None）

形状=[]
对于枚举（数据）中的 i，（图像，标签）：
    尝试：
        通道大小=图像.形状
        形状.append（通道大小）
    除了 tf.errors.InvalidArgumentError 为 e：
        打印（一）
    

即使指定批量大小，我也会遇到相同的错误。
我使用的数据集是来自 Kaggle 的猫和狗分类数据集。
我最好的猜测是，数据中存在错误的图像，这导致了错误，我想通过循环所有图像来找到该图像。我仍然收到 Try/Except 块的错误。
有什么想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78285543/tensorflow-invalidargumenterror-while-looping-over-images</guid>
      <pubDate>Sat, 06 Apr 2024 18:53:39 GMT</pubDate>
    </item>
    <item>
      <title>Word2Vec Hierarchical Softmax 中的内部顶点是什么？</title>
      <link>https://stackoverflow.com/questions/78285447/whats-inside-inner-vertices-in-word2vec-hierarchical-softmax</link>
      <description><![CDATA[我有一个关于分层 Softmax 的问题。实际上，我不太明白内部顶点（不是叶顶点）中存储的内容。我清楚地理解这个算法的主要思想，但是每一步我们都计算输入词嵌入与内部顶点的词嵌入的点积。那么这些内部顶点内部有哪些向量呢？是否是大小等于 embedding_size 的随机初始化向量，然后它们的坐标由于反向传播步骤而变化，直到我们停止？]]></description>
      <guid>https://stackoverflow.com/questions/78285447/whats-inside-inner-vertices-in-word2vec-hierarchical-softmax</guid>
      <pubDate>Sat, 06 Apr 2024 18:15:41 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 pycaret 获得第二最佳模型参数？</title>
      <link>https://stackoverflow.com/questions/78285377/how-to-get-the-second-best-model-parameter-using-pycaret</link>
      <description><![CDATA[这是我在 google collab 上的代码
# 导入库
从 pycaret.classification 导入 *


exp_clf = 设置（数据，目标=&#39;目标&#39;，规范化=True）


最佳模型 = 比较模型()

这就是结果

此代码将显示最佳模型参数
显示(best_model)

这就是结果

我想知道其他模型参数而不是最佳模型（光梯度增强机），因为 AUC 对我来说不够高。如何显示随机森林分类器的参数？
我尝试了这个，希望它能向我显示第二最佳模型（随机森林）的参数
 显示(best_model[1])

这就是结果
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
TypeError Traceback（最近一次调用最后一次）
&lt;ipython-input-20-63c1d322b8ae&gt;在&lt;细胞系：1&gt;()
----&gt; 1 个显示器（best_model[1]）

类型错误：“LGBMClassifier”对象不可下标
]]></description>
      <guid>https://stackoverflow.com/questions/78285377/how-to-get-the-second-best-model-parameter-using-pycaret</guid>
      <pubDate>Sat, 06 Apr 2024 17:53:04 GMT</pubDate>
    </item>
    <item>
      <title>我认为我的模型过度拟合？有什么建议么？</title>
      <link>https://stackoverflow.com/questions/78285324/i-think-my-model-is-overfitting-any-suggestions</link>
      <description><![CDATA[所以我正在使用来自kaggle的deepfake检测数据集，我的模型似乎过度拟合，大约有2000张图像，其中1k用于“真实”类，1k用于“假”类。所有图像都是面孔。我使用的是 VGG16，因为它众所周知适合深度伪造面部检测。
以下是过去 10 个周期的结果：
找到属于 2 个类别的 1632 个图像。
找到属于 2 个类别的 204 张图像。
找到属于 2 个类别的 205 张图像。
纪元 1/10
51/51 [==============================] - 1234s 24s/步 - 损失：0.1841 - 准确度：0.9577 - val_loss ：0.7258 - val_accuracy：0.6719
纪元 2/10
51/51 [================================] - 1168s 23s/步 - 损失：0.1397 - 准确度：0.9712 - val_loss ：0.7331 - val_accuracy：0.6406
纪元 3/10
51/51 [================================] - 1186s 23s/步 - 损失：0.1215 - 准确度：0.9743 - val_loss ：0.7938 - val_accuracy：0.6719
纪元 4/10
51/51 [==============================] - 1187s 23s/步 - 损失：0.0914 - 准确度：0.9884 - val_loss ：0.8304 - val_accuracy：0.6615
纪元 5/10
51/51 [================================] - 1188s 23s/步 - 损失：0.0705 - 准确度：0.9939 - val_loss ：0.9022 - val_accuracy：0.6562
纪元 6/10
51/51 [================================] - 1155s 23s/步 - 损失：0.0683 - 准确度：0.9896 - val_loss ：0.9072 - val_accuracy：0.6354
纪元 7/10
51/51 [==============================] - 1154s 23s/步 - 损失：0.0541 - 准确度：0.9951 - val_loss ：0.8924 - val_accuracy：0.6719
纪元 8/10
51/51 [==============================] - 1175s 23s/步 - 损失：0.0403 - 准确度：0.9975 - val_loss ：0.9353 - val_accuracy：0.6510
纪元 9/10
51/51 [==============================] - 1189s 23s/步 - 损失：0.0420 - 准确度：0.9969 - val_loss ：1.0692 - val_accuracy：0.6198
纪元 10/10
51/51 [==============================] - 1185s 23s/步 - 损失：0.0288 - 准确度：0.9988 - val_loss ：1.0250 - val_accuracy：0.6510
/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103：UserWarning：您正在通过“model.save()”将模型保存为 HDF5 文件。此文件格式被视为旧格式。我们建议使用原生 Keras 格式，例如`model.save(&#39;my_model.keras&#39;)`。
  saving_api.save_model(
6/6 [================================] - 135s 21s/步 - 损失：1.1160 - 准确度：0.6042
测试精度：0.6041666865348816，结果如下

如果有人想知道，这里是过去 10 个时期的代码：
从 google.colab 导入驱动器
导入操作系统
将张量流导入为 tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
从tensorflow.keras.models导入load_model

train_dir = &#39;/content/drive/MyDrive/dataset/train&#39;
val_dir = &#39;/content/drive/MyDrive/dataset/val&#39;
test_dir = &#39;/content/drive/MyDrive/dataset/test&#39;

＃参数
批量大小 = 32
历元 = 5
图像形状 = (224, 224)

save_model_path = &#39;/content/drive/MyDrive/dataset/trained_model_updated.h5&#39;
模型 = load_model(保存的模型路径)

#预处理
train_datagen = ImageDataGenerator(重新缩放=1./255)
val_datagen = ImageDataGenerator(重新缩放=1./255)
test_datagen = ImageDataGenerator（重新缩放=1./255）

train_generator = train_datagen.flow_from_directory(
    火车目录，
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）

val_generator = val_datagen.flow_from_directory(
    val_dir,
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）

test_generator = test_datagen.flow_from_directory(
    测试目录，
    目标大小=图像形状，
    批量大小=批量大小，
    class_mode=&#39;二进制&#39;
）


model.compile(优化器=&#39;亚当&#39;,
              损失=&#39;binary_crossentropy&#39;,
              指标=[&#39;准确性&#39;])


历史=模型.fit(
    火车发电机，
    steps_per_epoch=train_generator.samples //batch_size,
    纪元=纪元，
    验证数据=val_generator，
    validation_steps=val_generator.samples //batch_size
）


model.save(&#39;/content/drive/MyDrive/dataset/trained_model_updated.h5&#39;)

test_loss, test_acc = model.evaluate(test_generator,steps=test_generator.samples //batch_size)
print(f&#39;测试准确度：{test_acc}&#39;)


我运行了该模型大约 20 个 epoch，并不断更改参数，应用数据增强。尽管该模型对训练数据产生了良好的准确性，但对验证和测试集而言仍停滞在 67% 左右。
在前 5 个 epoch 中，模型的验证准确率确实从 53% 提高到 67%，但在最后 15 个 epoch 中仍然停滞不前。
为了确认，我还尝试使用来自互联网的一些图像，但它没有正确识别这些图像，并且会错误地将一些假图像分类为“真实”。
我很确定它的过度拟合是正确的吗？
我没有计算资源来训练更大的数据集，除了增加数据集大小之外还有其他解决方案吗？任何建议，将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78285324/i-think-my-model-is-overfitting-any-suggestions</guid>
      <pubDate>Sat, 06 Apr 2024 17:38:39 GMT</pubDate>
    </item>
    <item>
      <title>如何正确表示模型的数据</title>
      <link>https://stackoverflow.com/questions/78284870/how-to-correctly-represent-data-for-a-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78284870/how-to-correctly-represent-data-for-a-model</guid>
      <pubDate>Sat, 06 Apr 2024 15:16:11 GMT</pubDate>
    </item>
    <item>
      <title>如何解释神经网络中隐藏神经元的输出？</title>
      <link>https://stackoverflow.com/questions/78281488/how-to-interpret-the-outputs-of-the-hidden-neurons-in-a-neural-network</link>
      <description><![CDATA[我正在训练一个由 2 个神经元组成的 1 个隐藏层的 FNN：
模型 = train1([2])
绘制拟合以及每个隐藏神经元的输出（分布式表示）时：
plot1(X1, y1, label=&quot;train&quot;)
图1（X1测试，y1测试，标签=“测试”）
plot1fit(torch.linspace(0, 13, 500).unsqueeze(1), 模型, 隐藏=True, 比例=False)

输出如下：

当使用 3 个隐藏神经元进行训练时：

如何解释每个隐藏神经元的可视化和输出的拟合情况？]]></description>
      <guid>https://stackoverflow.com/questions/78281488/how-to-interpret-the-outputs-of-the-hidden-neurons-in-a-neural-network</guid>
      <pubDate>Fri, 05 Apr 2024 17:23:10 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM 中的恒定预测值</title>
      <link>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</link>
      <description><![CDATA[我正在尝试使用 LightGBM 回归来预测变量 (Y)。然而我的预测值都是相同的（即常数）。有人可以帮忙检测问题吗？
data_x = [[2021,5,368.92],[2023,11,356.82],[2022,10,352.49],[2023,5,343.63],[2023,10,324.91],[2022,12,352.02],[2021,6,370.7 9] ,[2022,5,386.59],[2019,2,301.56],[2021,4,353.7],[2021,1,303.93],[2021,9,371.94],[2019,4,310.77],[2021,3,345.3],[2020,5,249。 63],[ 2022,4,381.16],[2023,4,363.14],[2019,7,304.19],[2020,7,258.43],[2022,2,412.47],[2022,8,353.43],[2019,6,302.34],[2020,1,319。 88]，[2022年， 7,361.66],[2020,9,265.39],[2022,3,408.72],[2022,1,417.47],[2022,6,351.92],[2022,9,344.06],[2022,11,373.75],[2019,9,314.97], [2019,11,324.14] ,[2023,2,377.23],[2021,11,380.83],[2021,12,403.12],[2023,7,368.73],[2023,1,379.76],[2019,5,295.02],[2023,9,343.78],[2020,4, 248.54],[ 2019,10,314.79],[2019,8,295.92],[2023,3,354.09],[2023,6,357.35],[2021,2,324.31],[2020,3,246.26],[2019,3,295.36],[2020,12,30 6.27]，[2021， 8,376.54],[2020,6,258.21],[2023,8,352.35],[2021,7,370.21],[2020,10,259.13],[2020,8,275.66],[2019,12,315.47],[2020,11,301.27 ],[2021,10,389.23] ,[2019,1,291.94],[2020,2,302.38]]

df_x = pd.DataFrame(data_x, columns=[&#39;年&#39;, &#39;月&#39;, &#39;关闭&#39;])

data_y = [[1479.42],[1654.53],[1537.76],[1621.22],[1567.62],[1528.39],[1444.63],[1562.17],[1356.81],[1463.48],[1558.9],[1463.96] ,[1362.03],[1432.7],[1502.46],[1524.71],[1592.68],[1342.74],[1467.48],[1553.66],[1609.19],[1349.1],[1379.39],[1496.12],[ 1448.08]、[1562.96]、[1525.25]、[1575.06]、[1591.15]、[1544.66]、[1319.9]、[1366.73]、[1482.72]、[1520.73]、[1557.03]、[1577.37]、[1624 .74] ,[1402.05],[1614.94],[1482.28],[1338.88],[1354.6],[1553.65],[1606.36],[1510.78],[1348.05],[1323.39],[1542.95],[1411.64],[ 1493.44],[1563.53],[1414.8],[1452.67],[1491.7],[1451.43],[1467.23],[1477.13],[1360.29],[1386.48]]

df_y = pd.DataFrame(data_y, columns=[&#39;值&#39;])

X_df_earn_ind_fin_train，X_df_earn_ind_fin_test，y_df_earn_ind_fin_train，y_df_earn_ind_fin_test = train_test_split（df_x，df_y，test_size = 0.3，random_state = 21）

hyper_params = {
    &#39;任务&#39;：&#39;训练&#39;，
    &#39;boosting_type&#39;：&#39;gbdt&#39;，
    &#39;目标&#39;：&#39;回归&#39;，
    &#39;公制&#39;：[&#39;mape&#39;，&#39;auc&#39;]，
    “学习率”：0.01，
    “特征分数”：0.9，
    &#39;bagging_fraction&#39;：0.7，
    &#39;bagging_freq&#39;：10，
    “详细”：0，
    &#39;详细评估&#39;：-1，
    “最大深度”：10，
    “叶子数”：96，
    “max_bin”：256，
    “迭代次数”：1000，
    “n_估计器”：250
}

gbm = lgm.LGBMRegressor(**hyper_params)
gbm.fit(X_df_earn_ind_fin_train, y_df_earn_ind_fin_train,
        eval_set=[(X_df_earn_ind_fin_test, y_df_earn_ind_fin_test)],
        eval_metric=&#39;mape&#39;)

y_pred_df_earn_ind_test = gbm.predict(X_df_earn_ind_fin_test)


但是我的输出只是一个常量值的数组
y_pred_df_earn_ind_test =
数组([1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863, 1497.21170863, 1497.21170863,
       1497.21170863, 1497.21170863])


如何纠正这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78257853/constant-predicted-values-in-lightgbm</guid>
      <pubDate>Mon, 01 Apr 2024 21:17:37 GMT</pubDate>
    </item>
    <item>
      <title>pytorch和cuda安装问题</title>
      <link>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</link>
      <description><![CDATA[我正在尝试在 Windows 11 上使用 Anaconda3 安装带有 Cuda 的 PyTorch
我的nvidia-smi输出驱动程序版本：551.76，CUDA版本：12.4
我的火炬版本是我从官方网站安装的 12.2
&lt;前&gt;&lt;代码&gt;火炬2.2.1+cu121
火炬音频2.2.1+cu121
火炬视觉 0.17.1+cu121

但问题是，当我运行 torch.cuda.is_available() 时，它显示 false 作为输出。这里出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/78192733/problem-with-pytorch-and-cuda-installation</guid>
      <pubDate>Wed, 20 Mar 2024 10:58:20 GMT</pubDate>
    </item>
    <item>
      <title>cross_val_predict 中是否有 xgb.XGBRegressor 的示例，其中回调=[early_stop], Early_stop=xgb.callback.EarlyStopping？</title>
      <link>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</link>
      <description><![CDATA[在文档
XGBClassifier 有一个 EarlyStopping：
&lt;前&gt;&lt;代码&gt;```
es = xgboost.callback.EarlyStopping(
    轮数=2，
    min_delta=1e-3,
    save_best=真，
    最大化=假，
    data_name=“validation_0”，
    metric_name=“mlogloss”,
    ）
clf = xgboost.XGBClassifier(tree_method=“hist”, device=“cuda”, 回调=[es])

X, y = load_digits(return_X_y=True)
clf.fit(X, y, eval_set=[(X, y)])```

但是“validation_0”是如何实现的？引用 clf.fit 中的 eval_set 来让 EarlyStopping 指标进行评估？
我尝试将其应用到 XGBRegressor：
`将 xgboost 导入为 xgb
从 sklearn.model_selection 导入 cross_val_predict，KFold
将 pandas 导入为 pd
将 numpy 导入为 np

类 CustomEarlyStopping(xgb.callback.EarlyStopping):
    def __init__(self, rounds=2, min_delta=1e-3, save_best=True, maximise=False, data_name=“validation_0”, metric_name=“rmse”):
        super().__init__(rounds=rounds, min_delta=min_delta, save_best=save_best, maximise=maximize, data_name=data_name, metric_name=metric_name)
    
# 火车模型（10x10 倍 CV）
cvx = KFold(n_splits=10, shuffle=True, random_state=239)
es = 自定义早期停止()

模型= xgb.XGBRegressor（colsample_bytree = 0.3，learning_rate = 0.1，max_深度= 10，alpha = 10，n_estimators = 500，n_jobs = -1，
                     random_state=239，回调=[es]）
model.set_params(tree_method=&#39;approx&#39;, device=&#39;cpu&#39;)

cv_preds = []
对于范围 (0,10) 内的 i：
    cv_preds.append(cross_val_predict(模型, np.asarray(X_train), np.asarray(y_train), cv=cvx, method=&#39;predict&#39;, n_jobs=1, verbose=2))`

我把data_name=“validation_0”放在在 EarlyStopping __init__ 中，而不在每个 cv 折叠中命名测试集。
这段代码的行为有什么问题？谢谢。
XGBRegressor 的代码返回了此错误：
ValueError：必须至少有 1 个验证数据集才能提前停止。

应该发生的情况是 cv_preds 被 10 个预测 y 的 ndarray 填充。]]></description>
      <guid>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</guid>
      <pubDate>Mon, 18 Mar 2024 08:42:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么 ImageDataGenerator() 表现不佳？</title>
      <link>https://stackoverflow.com/questions/58562089/why-is-imagedatagenerator-performing-poorly</link>
      <description><![CDATA[我正在尝试使用 ImageDataGenerator() 构建图像分类模型。
该模型的训练和表现似乎很差。训练损失保持在 15 左右，准确率只有 10%，验证也差不多。
为了看看会发生什么，我尝试在不使用 ImageDataGenerator() 的情况下进行训练，并以类似的方式设置数据。它在训练、验证和测试方面表现得更好。训练损失为 0.71，准确度为 75%；验证损失为 0.8，准确度为 72%。 
我需要使用数据生成器计算出这个模型，因为我将转向更大的数据集，而该数据集无法装入内存。
所以，我想我的问题是我对 ImageDataGenerator() 做错了什么，它的性能如此糟糕，我该如何改善结果？
设置文件时（在所有“训练”、“测试”、“验证”文件夹中），有些类拥有自己的文件夹，这些文件夹中就是图像所在的位置。 
这是代码：
导入tensorflow为tf
从tensorflow.keras.preprocessing.image导入ImageDataGenerator
进口泡菜
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入密集，激活，扁平化，Conv2D，MaxPooling2D，Dropout

data_gen = 图像数据生成器()
IMG_SIZE = 100
train_it = data_gen.flow_from_directory(&#39;D:/.../Train/&#39;, class_mode=&#39;稀疏&#39;,
                                       target_size=(IMG_SIZE, IMG_SIZE),color_mode=&#39;灰度&#39;,shuffle=True,batch_size=32)
val_it = data_gen.flow_from_directory(&#39;D:/.../Validation/&#39;, class_mode=&#39;稀疏&#39;,
                                     target_size=(IMG_SIZE, IMG_SIZE),color_mode=&#39;灰度&#39;,shuffle=True,batch_size=32)

图像大小 = [100, 100]

模型=顺序()
model.add(Conv2D(32,(3,3), input_shape=[*IMAGE_SIZE, 1]))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

模型.add(压平())
model.add(Dense(len(train_it.class_indices), 激活=&#39;softmax&#39;))

model.compile（损失=&#39;sparse_categorical_crossentropy&#39;，优化器=&#39;adam&#39;，指标=[&#39;准确性&#39;]）
model.fit_generator（train_it，epochs = 20，validation_data = val_it）

这是我没有 ImageDataGenerator() 的代码：
使用 OpenCV 设置数据
DATADIR=&#39;D:\...\Train&#39;
CATEGORIES = pickle.load(open(&quot;CATEGORIES.p&quot; , &quot;rb&quot;))
打印（长度（类别））
IMG_SIZE = 100
训练数据=[]

def create_training_data():
    对于类别中的类别：
        路径 = os.path.join(DATADIR,类别)
        class_num = CATEGORIES.index(类别)
        对于 os.listdir(path) 中的 img：
            尝试：
                img_array = cv2.imread(os.path.join(路径,img),cv2.IMREAD_GRAYSCALE)
                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
                Training_data.append([new_array, class_num])
            除了：
                打印（类别）
                打印（图像）

创建训练数据（）

随机播放（训练数据）

X=[]
y=[]
对于特征，训练数据中的标签：
    X.append（功能）
    y.append(标签)

X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 1)
X=X/255.0

模型设置：

&lt;前&gt;&lt;代码&gt;模型=顺序()
model.add(Conv2D(32,(3,3), input_shape=[*IMAGE_SIZE, 1]))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

model.add(Conv2D(32,(3,3)))
model.add(激活(&#39;relu&#39;))
model.add(MaxPooling2D(pool_size=(2,2)))

模型.add(Dropout(0.5))

模型.add(压平())
model.add(Dense(len(CATEGORIES), 激活=&#39;softmax&#39;))

model.compile（损失=&#39;sparse_categorical_crossentropy&#39;，优化器=&#39;adam&#39;，指标=[&#39;准确性&#39;]）
model.fit（X，y，epochs = 20，batch_size = 32，validation_split = 0.1）
]]></description>
      <guid>https://stackoverflow.com/questions/58562089/why-is-imagedatagenerator-performing-poorly</guid>
      <pubDate>Fri, 25 Oct 2019 16:05:15 GMT</pubDate>
    </item>
    </channel>
</rss>