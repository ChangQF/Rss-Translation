<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Mar 2024 06:17:52 GMT</lastBuildDate>
    <item>
      <title>为 CNN 注释图像有多大必要？如果是这样，最快的方法是什么？</title>
      <link>https://stackoverflow.com/questions/78204285/how-necessary-is-it-to-annotate-images-for-a-cnn-if-so-whats-the-fastest-meth</link>
      <description><![CDATA[我有一个带有 keras 和 tensorflow 的 CNN，并且很好奇注释图像的必要性。我的数据集由大约 35k 个图像（7 个类别）组成，单手注释每个图像会花费太多时间。如果有必要，注释图像最快的方法是什么？另外，我应该使用什么类型的注释（例如 bboxes）？
目前我的 CNN 通常具有大约 93^ val 准确度和 97% 训练准确度，但现实生活中的结果和混淆矩阵表明它表现不佳（平均精度约为 40%）。注释值得花时间吗？]]></description>
      <guid>https://stackoverflow.com/questions/78204285/how-necessary-is-it-to-annotate-images-for-a-cnn-if-so-whats-the-fastest-meth</guid>
      <pubDate>Fri, 22 Mar 2024 05:54:54 GMT</pubDate>
    </item>
    <item>
      <title>时间序列滚动窗口功能</title>
      <link>https://stackoverflow.com/questions/78204216/time-series-rolling-windows-feature</link>
      <description><![CDATA[我正在用 Python 创建机器学习模型，但有一些问题。如果我根据我的销售额（目标）列创建滚动平均值特征，是否有必要对其进行移动？
举个例子：
假设我的数据集中有第 01~10 天。例如，如果我在第 10 天的行中创建 7 天的平均滚动窗口列，它将考虑第 7 天作为该行的值来计算滚动平均值。现在，如果我要预测第 11 天，即明天，我需要这一天的销售值才能获得滚动平均值，这没有意义。
因此，我认为始终获取最后 7 天而不考虑当前的情况更有意义。
有人可以帮忙吗？
我在 Python 上尝试过，但我不明白添加此功能的最常见方法是什么]]></description>
      <guid>https://stackoverflow.com/questions/78204216/time-series-rolling-windows-feature</guid>
      <pubDate>Fri, 22 Mar 2024 05:35:21 GMT</pubDate>
    </item>
    <item>
      <title>给定标签集之外的短 2-3 个标记文本或用户搜索查询的序列标签 - NER</title>
      <link>https://stackoverflow.com/questions/78204207/sequence-labelling-for-short-2-3-token-text-or-user-search-queries-out-of-given</link>
      <description><![CDATA[我正在从事一个 NER 项目，并一直在尝试开发一个可部署的模型。
我有 3 种不同类型实体的虚拟电子商务数据，每个实体都有大约 1K 个子实体。训练数据（大小约为 200K）是通过 3K 标签的组合综合创建的。
我尝试使用查询分类模型（带有 3K 标签）开发 FLAIR 序列标签。
FLAIR 模型 （F1 得分：60%） 的表现严重低于分类模型（F1 得分：80%） ）。
我不愿意开发序列标签模块的原因是因为我希望序列标签器也能够检测并提出新实体。
你能帮助我解决哪里可能出错以及我可以尝试哪些其他模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/78204207/sequence-labelling-for-short-2-3-token-text-or-user-search-queries-out-of-given</guid>
      <pubDate>Fri, 22 Mar 2024 05:30:33 GMT</pubDate>
    </item>
    <item>
      <title>Apache Spark 在深度学习模型训练阶段的范围</title>
      <link>https://stackoverflow.com/questions/78204101/apache-sparks-scope-in-deep-learning-model-training-phase</link>
      <description><![CDATA[我注意到 Apache Spark 被大量用于训练数据准备，但我很好奇它与 PyTorch/TensorFlow 一起在训练阶段的潜在作用，特别是在同时具有 CPU 和 GPU 的环境中。我想知道 Spark 在数据加载或缓存方面是否比 PyTorch/TensorFlow 有任何优势，特别是在分布式训练场景中。
虽然 PyTorch 和 TensorFlow 都支持分布式训练，但我很想知道 Spark 的功能是否可以提高性能或减少延迟，特别是在处理可能超出 GPU 内存容量的大型数据集时。]]></description>
      <guid>https://stackoverflow.com/questions/78204101/apache-sparks-scope-in-deep-learning-model-training-phase</guid>
      <pubDate>Fri, 22 Mar 2024 04:51:30 GMT</pubDate>
    </item>
    <item>
      <title>在 aws elastic beanstalk 中创建环境时遇到 docker 错误</title>
      <link>https://stackoverflow.com/questions/78204096/facing-docker-error-while-creating-environment-in-aws-elastic-beanstalk</link>
      <description><![CDATA[实际上，我正在 Beanstalk 中使用 Docker 部署 ML 模型。首先，我将 Docker 镜像（包含我的 ML 模型）上传到 Docker Hub。然后，我使用 docker-compose.yml 将其部署到 Beanstalk 中。在 Beanstalk 中，我使用 Docker 作为平台，并且我的模型需要 GPU 支持。为此，我使用了深度学习 AMI GPU CUDA 11.5.2 (Amazon Linux 2) 20230104，它是通过 NVIDIA CUDA、cuDNN、NCCL、GPU 驱动程序、Docker、NVIDIA-Docker 和 EFA 支持构建的。但是，当我使用此配置构建环境时，遇到以下错误：
**[ERROR]** 执行命令 [app-deploy] - [Track pids in healthd] 期间发生错误。停止运行该命令。错误：更新进程 [docker eb-docker-compose-events eb-docker-compose-log eb-docker-events cfn-hup healthd] pid 符号链接失败，出现错误 读取 pid 源文件 /var/pids/docker.pid 失败，出现错误:open /var/pids/docker.pid: 没有这样的文件或目录。

意味着我的环境正在构建，但它给出了错误消息，例如：Env 构建成功，但有一些错误。我在 eb.engine.log 中发现了此错误消息。
此外，我通过 SSH 检查了 EC2 实例，它显示 NVIDIA 驱动程序、NVIDIA CUDA 和 Docker 已安装（使用以下命令验证：nvidia-smi、docker -v）。我尝试了多种不同的深度学习 AMI，但所有这些 AMI 都遇到了同样的问题。另外，在尝试不同的 AMI 时，我注意到一件奇怪的事情：如果我使用默认设置（例如使用默认 Docker AMI 的 Docker 平台）构建环境，它会成功构建，不会出现任何错误。但是，当我在配置中传递不同的 AMI ID 时，无法正确构建环境。
我是 AWS Elastic Beanstalk 的新手，但我已经彻底准备好官方 Beanstalk 文档。尽管如此，我相信我在环境创建过程中可能会遗漏一些东西。有谁知道如何解决这个错误？]]></description>
      <guid>https://stackoverflow.com/questions/78204096/facing-docker-error-while-creating-environment-in-aws-elastic-beanstalk</guid>
      <pubDate>Fri, 22 Mar 2024 04:49:51 GMT</pubDate>
    </item>
    <item>
      <title>如何将我的 fastai resnet50/vision_learner 训练模型导出到 torchserve 中？</title>
      <link>https://stackoverflow.com/questions/78203794/how-do-i-export-my-fastai-resnet50-vision-learner-trained-model-into-torchserve</link>
      <description><![CDATA[我的目标是将我用 Fastai 训练的模型部署到 Torchserve 中。我正在关注 本教程，但卡在了他为 pytorch 创建模型类的部分。
他提到要在 Torchserve 中运行我们的模型，我们需要以下内容：

模型类
从 pytorch 导出的权重（pth 文件）
处理程序

其中，我得到两个：重量和处理程序。然而，我陷入困境的是模型类。他创建了一个类文件，但我不知道他从哪里获得DynamicUnet作为该类的基础，也不知道他如何将该类与unet_learner混合以创建自定义PyTorch模型类。你能帮我为在学习器 vision_learner 下训练的模型和 resnet50 的预训练模型建立一个模型类吗？]]></description>
      <guid>https://stackoverflow.com/questions/78203794/how-do-i-export-my-fastai-resnet50-vision-learner-trained-model-into-torchserve</guid>
      <pubDate>Fri, 22 Mar 2024 02:55:25 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么类型的人工智能模型来生成练习题？</title>
      <link>https://stackoverflow.com/questions/78203711/what-type-of-ai-model-should-i-use-to-generate-practice-questions</link>
      <description><![CDATA[我有一组英语多项选择题，我想使用 AI 生成更多问题来测验自己。我知道网上有一些平台可以实现这一点，但我想挑战自己，创建自己的简单人工智能架构。在对它进行一些英语问题训练后，我希望它能够生成新问题来帮助我学习。
我应该使用哪种机器学习/智能模型作为基线？非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78203711/what-type-of-ai-model-should-i-use-to-generate-practice-questions</guid>
      <pubDate>Fri, 22 Mar 2024 02:17:43 GMT</pubDate>
    </item>
    <item>
      <title>人工智能物体检测</title>
      <link>https://stackoverflow.com/questions/78203585/ai-object-detection</link>
      <description><![CDATA[我正在尝试使用计算机视觉和人工智能来识别图像中的硬币。
我使用的货币是波斯尼亚货币，问题是一些硬币的颜色和设计相同，唯一的区别是它们的大小。
我知道答案可能是否定的，但是有没有办法可以使用它们的大小来区分它们？]]></description>
      <guid>https://stackoverflow.com/questions/78203585/ai-object-detection</guid>
      <pubDate>Fri, 22 Mar 2024 01:29:24 GMT</pubDate>
    </item>
    <item>
      <title>lightfm python 依赖项使用</title>
      <link>https://stackoverflow.com/questions/78203344/lightfm-python-dependency-usage</link>
      <description><![CDATA[将 numpy 导入为 np
从 lightfm.datasets 导入 fetch_movielens
从 lightfm 导入 LightFM

数据 = fetch_movielens(min_ rating=4.0)

打印（repr（数据[&#39;火车&#39;]））
打印（repr（数据[&#39;测试&#39;]））

模型 = LightFM(损失=&#39;扭曲&#39;)

model.fit(data[&#39;train&#39;], epochs=30, num_threads=2)

defsample_recommendation（模型，数据，user_ids）：
    n_users, n_items = 数据[&#39;train&#39;].shape
    
    对于 user_ids 中的 user_id：
        known_positives = data[&#39;item_labels&#39;][data[&#39;train&#39;].tocsr()[user_id].indices]
        
        分数 = model.predict(user_id, np.arange(n_items))
        
        # 修复此处的标签索引
        top_items = 数据[&#39;item_labels&#39;][np.argsort(-scores)]
        
        print(&quot;用户 %s&quot; % user_id)
        print(&quot;已知的积极结果：&quot;)

        对于known_positives[:3]中的x：
            打印（“％s”％x）
            
        print(&quot;推荐：&quot;)

        # 打印最推荐的商品
        对于 top_items[:3] 中的 x：
            打印（“％s”％x）
            
样本推荐（模型，数据，[3,10,56]）


如果我运行我的代码，只输出电影标题的第一个字母，它应该是完整的电影标题，如何修复它？
我问过ai其中一个chat gpt，他们给出代码建议后，代码仍然不起作用，只显示每部电影的第一个字母。]]></description>
      <guid>https://stackoverflow.com/questions/78203344/lightfm-python-dependency-usage</guid>
      <pubDate>Thu, 21 Mar 2024 23:44:11 GMT</pubDate>
    </item>
    <item>
      <title>调整用于异常检测的 KNN 算法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78202543/tuning-a-knn-algorithm-for-anomaly-detection</link>
      <description><![CDATA[我正在尝试使用 k 最近邻 (KNN) 算法在时间序列数据集中进行异常检测，其中包含工业机器的传感器读数。目标是使用 KNN 识别传感器读数中的任何异常行为，这可能表明机器中的潜在问题或故障。
数据集采用以下格式：
&lt;前&gt;&lt;代码&gt;sensor_data.csv
时间戳、温度、压力、振动
2023-03-22 09:00:00,75.2,101.3,2.1
2023-03-22 09:05:00,75.1,101.2,2.2

这是我的 Python 代码：
导入 pandas 作为 pd
从 sklearn.neighbors 导入 NearestNeighbors

# 加载数据集
Sensor_data = pd.read_csv(&#39;sensor_data.csv&#39;)
X =sensor_data[[&#39;温度&#39;,&#39;压力&#39;,&#39;振动&#39;]]

# 实现 KNN 进行异常检测
knn = 最近邻居(n_neighbors=5, metric=&#39;euclidean&#39;)
knn.fit(X)
距离，索引 = knn.kneighbors(X)

这就是我陷入困境的地方：

如何确定此特定场景中邻居数量 (k) 的最佳值？
欧几里得距离度量是此类数据的最佳选择，还是应该考虑其他距离度量？如果有，是哪些以及为什么？
根据 KNN 返回的距离和索引，如何有效识别和处理传感器读数中的异常情况？
]]></description>
      <guid>https://stackoverflow.com/questions/78202543/tuning-a-knn-algorithm-for-anomaly-detection</guid>
      <pubDate>Thu, 21 Mar 2024 20:09:04 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Ridge 和 Lasso 回归处理数据集中潜在的多重共线性？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78202221/how-to-handle-potential-multicollinearity-in-a-dataset-using-ridge-and-lasso-reg</link>
      <description><![CDATA[包含各种房屋信息的数据集，包括其大小、卧室数量、浴室数量、年龄和相应的销售价格。目标是建立一个线性回归模型，可以根据这些自变量准确预测房屋的销售价格，同时考虑数据中潜在的多重共线性。
数据集以下格式：
house_data.csv
面积、卧室、浴室、年龄、价格
2500,4,3,25,550000
3000,3,2,15,625000
导入 pandas 作为 pd
从 sklearn. Linear_model 导入 LinearRegression、Ridge、Lasso
从 sklearn.model_selection 导入 train_test_split

# 加载数据集
house_data = pd.read_csv(&#39;house_data.csv&#39;)
X = house_data[[&#39;尺寸&#39;, &#39;卧室&#39;, &#39;浴室&#39;, &#39;年龄&#39;]]
y = house_data[&#39;价格&#39;]

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 标准线性回归
Linear_reg = 线性回归()
Linear_reg.fit(X_train, y_train)
Linear_score = Linear_reg.score(X_test, y_test)
print(f&#39;标准线性回归分数：{linear_score}&#39;)

虽然上面的代码适用于标准线性回归，但我正在努力解决以下问题：

如何确定岭回归中正则化参数 (alpha) 的最佳值？
如何在处理数据集中的多重共线性的同时有效实施 Lasso 回归？
]]></description>
      <guid>https://stackoverflow.com/questions/78202221/how-to-handle-potential-multicollinearity-in-a-dataset-using-ridge-and-lasso-reg</guid>
      <pubDate>Thu, 21 Mar 2024 18:51:40 GMT</pubDate>
    </item>
    <item>
      <title>在基于品种的作物产量预测模型中找到每个品种的准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/78199996/finding-the-accuracy-for-each-variety-in-a-variety-based-crop-yield-prediction-m</link>
      <description><![CDATA[我一直在使用回归研究田间作物的产量预测模型。我的输入特征包括 30 多个特定于作物的变量，这些变量是我使用 Google Earth Engine 针对每个由单个多边形标记的田地得出的。我还通过调查了解了每块田地种植的农作物的品种（具体是两种类型）。我想了解每个品种的模型准确性如何。我们以后如何确定模型对每个品种的准确性？
品种 1 - 有 100 个样品
品种 2 - 有 60 个样品
我正在考虑做这样的事情：

如果我遵循 70-30% 的分割，我就有 48 个测试样本。根据每个样本绘制预测产量。
根据多样性将样本分为几类。
通过找出误差差异来计算每个类别的 RMSE/MAE。

我不太确定这种方法。有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78199996/finding-the-accuracy-for-each-variety-in-a-variety-based-crop-yield-prediction-m</guid>
      <pubDate>Thu, 21 Mar 2024 12:40:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 Tensorflow 时 Python 产生的结果比 kotlin 更准确？</title>
      <link>https://stackoverflow.com/questions/78199511/why-does-python-produce-a-more-accurate-result-than-kotlin-when-using-tensorflow</link>
      <description><![CDATA[我正在制作一个应用程序，它将检测不同数字系统中不同的手写数学表达式。截至目前，阻碍任何进展的主要因素是 kotlin 在使用 Tensorflow lite 时产生的不准确性 - 大约 10% 正确。我的 Python 代码非常相似，但它使用常规张量流，并且更加准确 - 大约 70% 正确。
我的想法是图像从 OpenCV Mat 转换为 Tensorbuffer 的方式导致了一些问题，或者预处理的处理方式导致了差异。
我的代码片段如下：

提取边界矩形后，进行预处理和标准化。

val image_roi = Mat(tmp,boundRect)
Imgproc.cvtColor(image_roi, image_roi, Imgproc.COLOR_RGB2GRAY) Imgproc.GaussianBlur(image_roi, image_roi, Size(3.0,3.0), 0.0)
Imgproc.dilate(image_roi, image_roi, Imgproc.getStructuringElement(Imgproc.MORPH_RECT, Size(4.0, 4.0)))
Imgproc.threshold(image_roi, image_roi, 90.0, 255.0, Imgproc.THRESH_BINARY);
Imgproc.resize(image_roi, image_roi, 大小(28.0,28.0))
Core.normalize(image_roi, image_roi, 0.0, 255.0, Core.NORM_MINMAX);
image_roi.convertTo(image_roi, CvType.CV_8UC1)
提取.add(image_roi)


运行预测，将 OpenCV Mat 转换为 Tensorbuffer（第 3 步）

for（提取的img）{
       val 张量缓冲区 = extractBytes(img)
       val 输出 = model.process(tensorBuffer)
       valoutputFeature0=outputs.outputFeature0AsTensorBuffer
       valconf=outputFeature0.floatArray
       out += getLanguageText(conf, 数字)
 
}


将 Mat 转换为 Tensorbbuffer

私有乐趣 extractBytes(img: Mat): TensorBuffer{
        val inputFeature = TensorBuffer.createFixedSize(intArrayOf(1, 28, 28, 1), DataType.FLOAT32)
        val byteBuffer = ByteBuffer.allocateDirect(28 * 28 * 4) // 每个浮点数 4 个字节
        byteBuffer.order(ByteOrder.nativeOrder())
        byteBuffer.rewind()
 
        for (i 从 0 到 28) {
            for (j in 0 到 28) {
                val temp = img.get(i, j)[0].toFloat() // 假设单通道（灰色）
                byteBuffer.putFloat(临时)
            }
        }
 
        inputFeature.loadBuffer(byteBuffer)
        返回输入特征
    }

在下面的粘贴箱中，我也包含了我的 pythin 代码。我需要一些帮助来弄清楚为什么我的模型无法通过 Kotlin 准确预测，但可以通过 Python 准确预测。
https://pastebin.com/BACzTkq6
以下是在 Python 和 Kotlin 中使用相同图像的差异示例：
通过 Kotlin 显示预测的图像
通过 python 显示预测的图像
我尝试了将 Matrix 转换为 Tensorbuffer 的不同方法，我尝试删除大多数（如果不是全部）图像预处理，我尝试让 python 在 Android studio 中工作（但这并没有成功。）]]></description>
      <guid>https://stackoverflow.com/questions/78199511/why-does-python-produce-a-more-accurate-result-than-kotlin-when-using-tensorflow</guid>
      <pubDate>Thu, 21 Mar 2024 11:18:54 GMT</pubDate>
    </item>
    <item>
      <title>ViT 模型的 HuggingFace Inference API 问题 - “图像特征提取”错误</title>
      <link>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</link>
      <description><![CDATA[我的 Vision Transformer (ViT) 模型 rshrott/vit-base-renovation2 的推理 API 遇到问题。
https://huggingface.co/rshrott/vit-base-renovation2 
当我尝试使用 API 时，收到以下错误：
&lt;前&gt;&lt;代码&gt;{
“错误”：“HfApiJson（反序列化（错误（“未知变体图像特征提取，预期音频分类，音频到音频，音频源分离，自动语音识别，特征提取之一，文本分类、标记分类、问答、翻译、摘要、文本生成、text2text-生成、填充掩模、零样本分类、零样本图像分类、会话、表格问答、图像分类、图像分割、图像到文本、文本到语音、...视觉问答、视频分类、文档问答、图像到图像、深度估计，行：1 ，栏目：318）））”
}

有趣的是，当我直接在 Python 中使用 Transformer 管道时，模型按预期工作：
从转换器导入管道
从 PIL 导入图像
导入请求

管道=管道（模型=“rshrott/vit-base-renovation2”）
url = &#39;https://example.com/image.jpeg&#39;
图像= Image.open(requests.get(url,stream=True).raw)
preds = 管道(图像)

此代码运行没有任何问题并返回预期的预测。但是，通过推理 API 使用同一模型时会遇到错误。我怀疑可能存在与预期任务类型相关的配置问题，但我不确定如何解决它。
为什么会出现此错误以及如何修复它？我已经检查了型号卡和配置，但我似乎无法找到“图像特征提取”的来源或原因。]]></description>
      <guid>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</guid>
      <pubDate>Wed, 20 Mar 2024 10:44:57 GMT</pubDate>
    </item>
    <item>
      <title>如何将Polygon格式转换为YOLO格式</title>
      <link>https://stackoverflow.com/questions/74276547/how-to-convert-polygon-format-to-yolo-forma</link>
      <description><![CDATA[多边形 ((799 1776, 799 2016, 490 2016, 490 1776, 799 1776))
这是 POLYGON 中的边界框
我想要 YOLO v5 格式的
导入日志记录
从 pathlib 导入路径
将 pandas 导入为 pd
从 shapely.wkt 导入负载
yolo_output_dir = 路径(“my_yolo”)
yolo_output_dir.mkdir（父母=真，exist_ok=真）
df = (pd
      .read_csv(&#39;images_bboxes.csv&#39;)
      .fillna(值={&#39;几何&#39;: &#39;2&#39;}))

蠕虫类型 = {
    y: x for (x, y) in enumerate(df[&#39;worm_type&#39;].unique())
}
记录.关键（worm_types）

对于 df.groupby(&#39;image_id&#39;, sort=False) 中的 (i, g)：
    dst = yolo_output_dir.joinpath(i).with_suffix(&#39;.txt&#39;)
    日志记录.警告（dst）
    以 dst.open(&#39;w&#39;) 作为 fp：
        对于 g.itertuples(index=False) 中的 i：
            如果我.几何：
                蠕虫 = 蠕虫_类型[i.蠕虫_类型]
                几何=载荷（i.几何）
                (minx, miny, maxx, maxy) = 几何.边界
                (w, h) = (maxx - minx, maxy - miny)
                打印（蠕虫，minx，miny，w，h，文件= fp）

这是我尝试过的代码，但它给出了错误的坐标..
多边形 ((799 1776, 799 2016, 490 2016, 490 1776, 799 1776))
被转换为
0 389.0 1552.0 160.0 165.0
这是错误的]]></description>
      <guid>https://stackoverflow.com/questions/74276547/how-to-convert-polygon-format-to-yolo-forma</guid>
      <pubDate>Tue, 01 Nov 2022 13:15:07 GMT</pubDate>
    </item>
    </channel>
</rss>