<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 02 May 2024 06:19:28 GMT</lastBuildDate>
    <item>
      <title>Model.evaluate 与 Model.predict：Keras、迁移学习：为什么准确度存在如此差异？</title>
      <link>https://stackoverflow.com/questions/78417156/model-evaluate-vs-model-predict-keras-transfer-learning-why-such-difference</link>
      <description><![CDATA[我正在使用预先训练的 resnet 50 模型进行图像分类。运行模型几个时期后，我得到的结果是：
Epoch 8/20 损失：0.5705 - 准确度：0.8785 - val_loss：0.9226 - val_accuracy：0.8135
Epoch 9/20 损失：0.5509 - 准确度：0.8780 - val_loss：0.9321 - val_accuracy：0.7979
获得的这些结果可以改进，但我们暂时保留这些结果。
当我运行 model.evaluate() 时，我获得了一个我期望的值：
# 评估模型 test_loss, test_acc = model.evaluate(val_data_flow) print(&quot;测试准确率:&quot;, test_acc)
测试准确度：0.7978515625
当我运行 Model.predict() 时，准确性非常糟糕：
 精确召回 f1-score 支持

       1 0.33 0.38 0.36 330
       2 0.00 0.00 0.00 14
       3 0.17 0.17 0.17 133
       4 0.09 0.11 0.10 102
       5 0.00 0.00 0.00 5
       6 0.00 0.00 0.00 21
       7 0.12 0.12 0.12 133
       8 0.18 0.16 0.17 154
       9 0.18 0.13 0.15 132

精度 0.21 1024
宏观平均 0.12 0.12 0.12 1024
加权平均值 0.20 0.21 0.21 1024

什么可能导致这样的问题？或者是因为函数 model.predict 和 model.evaluate 的工作方式不同？
我的数据集非常不平衡]]></description>
      <guid>https://stackoverflow.com/questions/78417156/model-evaluate-vs-model-predict-keras-transfer-learning-why-such-difference</guid>
      <pubDate>Thu, 02 May 2024 06:02:21 GMT</pubDate>
    </item>
    <item>
      <title>如何使用已经制作的嵌入尝试不同的分块策略？</title>
      <link>https://stackoverflow.com/questions/78417029/how-to-try-different-chunking-strategies-with-already-make-embeddings</link>
      <description><![CDATA[如何使用已制作的嵌入尝试不同的分块策略？嵌入存储在矢量数据库中。据我所知，在分块过程之后，创建了嵌入。这就是我想知道的原因。如果我错了请纠正我。]]></description>
      <guid>https://stackoverflow.com/questions/78417029/how-to-try-different-chunking-strategies-with-already-make-embeddings</guid>
      <pubDate>Thu, 02 May 2024 05:22:26 GMT</pubDate>
    </item>
    <item>
      <title>图像分析以查找适印性[关闭]</title>
      <link>https://stackoverflow.com/questions/78416596/image-analysis-to-find-printability</link>
      <description><![CDATA[我是编码新手。我有一张 cad 图像 cad.png。 3D 打印后的 CAD 图像 print.png 后的几张图像。
我想将 cad 图像与打印图像进行比较，看看打印是否准确。匹配的百分比是多少。
稍后，如果可能的话，尝试预测它是叠印还是印刷不足。
图像有不同的尺寸。我需要任何参考点来测量图像中的物体吗？
我应该如何进行？]]></description>
      <guid>https://stackoverflow.com/questions/78416596/image-analysis-to-find-printability</guid>
      <pubDate>Thu, 02 May 2024 01:31:25 GMT</pubDate>
    </item>
    <item>
      <title>LSTM 上的推理困难</title>
      <link>https://stackoverflow.com/questions/78416324/difficulty-performing-inference-on-lstm</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78416324/difficulty-performing-inference-on-lstm</guid>
      <pubDate>Wed, 01 May 2024 23:08:48 GMT</pubDate>
    </item>
    <item>
      <title>机器学习 - 神经网络</title>
      <link>https://stackoverflow.com/questions/78416266/machine-learning-neural-network</link>
      <description><![CDATA[我是初学者。我正在尝试创建一个具有一个隐藏层的神经网络，它将图像分为 12 个不同的类别。当我尝试使用梯度下降函数运行代码来开始训练模型时，代码根本不输出任何内容并移至下一个单元格。
definitialize_parameters(hidden_​​units):
    w1 = np.random.randn(hidden_​​units, 640 * 480 * 3) * 0.01
    b1 = np.zeros((hidden_​​units, 1))
    w2 = np.random.randn(12, 隐藏单元) * 0.01
    b2 = np.zeros((12, 1))
    返回 w1、b1、w2、b2

定义 ReLU(Z)：
    返回 np.maximum(0, Z)

def softmax(Z):
    expZ = np.exp(Z)
    返回 expZ / np.sum(expZ, axis=0, keepdims=True)

defforward_propagation(w1, b1, w2, b2, X):
    z1 = np.dot(w1, X) + b1
    a1 = ReLU(z1)
    z2 = np.dot(w2, a1) + b2
    a2 = softmax(z2)
    返回 z1、a1、z2、a2

def onehotencoding(Y):
    one_hot_Y = np.zeros((Y.size, Y.max() + 1))
    one_hot_Y[np.arange(Y.size), Y] = 1
    one_hot_Y = one_hot_Y.T
    返回 one_hot_Y

def导数ReLU(Z)：
    返回Z&gt; 0

def back_propagation(w2, a1, z1, a2, X, Y):
    m = Y 尺寸
    one_hot_Y = onehotencoding(Y)
    dz2 = a2 - one_hot_Y
    dw2 = 1 / m * np.dot(dz2, a1.T)
    db2 = 1 / m * np.sum(dz2, axis=1, keepdims=True)
    dz1 = np.dot(w2.T, dz2) *导数ReLU(z1)
    dw1 = 1 / m * np.dot(dz1, X.T)
    db1 = 1 / m * np.sum(dz1, axis=1, keepdims=True)
    返回 dw1、db1、dw2、db2

def update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):
    w1 = w1 - 阿尔法 * dw1
    b1 = b1 - 阿尔法 * db1
    w2 = w2 - 阿尔法 * dw2
    b2 = b2 - 阿尔法 * db2
    返回 w1、b1、w2、b2

此代码单元格在此结束，后面是此代码块。
def get_predictions(a2):
    返回 np.argmax(a2, 轴=0)

def get_accuracy(预测, Y):
    返回 np.sum(预测 == Y) / Y.size

defgradient_descent(X,Y,hidden_​​units,迭代,alpha):
    w1、b1、w2、b2 = 初始化参数（隐藏单元）
    对于范围内的 i（迭代）：
        z1, a1, z2, a2 = 前向传播(w1, b1, w2, b2, X)
        dw1, db1, dw2, db2 = 反向传播(w2, a1, z1, a2, X, Y)
        w1, b1, w2, b2 = update_parameters(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)
        如果我％10==0：
            预测 = get_predictions(a2)
            准确度 = get_accuracy(预测, Y)
            print(&quot;迭代：&quot;, i)
            print(&quot;准确率：&quot;, 准确率)
    返回 w1、b1、w2、b2


这是开始训练的梯度下降函数。
w1, b1, w2, b2 = 梯度下降(X_train, Y_train, 500, 迭代=1000, alpha=0.1)]]></description>
      <guid>https://stackoverflow.com/questions/78416266/machine-learning-neural-network</guid>
      <pubDate>Wed, 01 May 2024 22:43:52 GMT</pubDate>
    </item>
    <item>
      <title>LightGBM - 我实际上有多少棵树？</title>
      <link>https://stackoverflow.com/questions/78416214/lightgbm-how-many-trees-do-i-actually-have</link>
      <description><![CDATA[初学者在这里尝试 LGBM。我的代码看起来像这样
clf = lgb.LGBMClassifier(max_深度=3，详细程度=-1，n_estimators=3)
clf.fit(train_data[特征],train_data[&#39;y&#39;],sample_weight=train_data[&#39;权重&#39;])
print (f“我有 {clf.n_estimators_} 估计器”)
图，ax = plt.subplots（nrows = 4，figsize =（50,36），sharex = True）
lgb.plot_tree(clf, tree_index=7, dpi=600, ax=ax[0]) # 为什么有第七棵树？
lgb.plot_tree(clf, tree_index=8, dpi=600, ax=ax[1]) # 为什么它有第 8 棵树？
#lgb.plot_tree(clf, tree_index=9, dpi=600, ax=ax[2]) # 崩溃
#lgb.plot_tree(clf, tree_index=10, dpi=600, ax=ax[3]) # 崩溃

令我惊讶的是，尽管有 n_estimators=3，但我似乎有 9 棵树？我如何实际设置树的数量，以及与之相关的，n_estimators 是做什么的？我读过文档，我以为是树的数量，但似乎是别的东西。
另外，我如何解释单独的树及其顺序 0、1、2 等。我了解随机森林，以及每棵树如何同等重要。在 boosting 中，第一棵树最重要，下一棵树的重要性要低得多，下一棵树的重要性要低得多。所以在我的脑海中，当我查看树形图时，我该如何“模拟” LightGBM 推理过程？]]></description>
      <guid>https://stackoverflow.com/questions/78416214/lightgbm-how-many-trees-do-i-actually-have</guid>
      <pubDate>Wed, 01 May 2024 22:24:21 GMT</pubDate>
    </item>
    <item>
      <title>不打乱测试数据时，Torchmetrics 准确度会出现问题。为什么？</title>
      <link>https://stackoverflow.com/questions/78415660/torchmetrics-accuracy-issue-when-dont-shuffle-test-data-why</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78415660/torchmetrics-accuracy-issue-when-dont-shuffle-test-data-why</guid>
      <pubDate>Wed, 01 May 2024 19:45:02 GMT</pubDate>
    </item>
    <item>
      <title>如何微调代码bert模型/建议可以生成yaml代码的模型[关闭]</title>
      <link>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</link>
      <description><![CDATA[任何人都可以建议我如何微调 Codebert 模型。有相关文件吗？请给我一些建议。
我想知道 codebert 是开源的，我们可以使用 cpu 运行它吗？可以生成 ymal 代码吗？或者请推荐适合生成ymal代码的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78415194/how-to-fine-tune-the-code-bert-model-suggest-the-model-that-can-generate-the-y</guid>
      <pubDate>Wed, 01 May 2024 17:45:57 GMT</pubDate>
    </item>
    <item>
      <title>如何根据用户的输入测试模型？ （根据电影评论预测情绪）</title>
      <link>https://stackoverflow.com/questions/78414840/how-to-test-a-model-on-users-input-predict-sentiment-from-movie-reviews</link>
      <description><![CDATA[我的代码：
导入 matplotlib
导入 matplotlib.pyplot 作为 plt
导入 numpy 作为 np
从 keras.utils 导入 to_categorical
从 keras 导入模型
从 keras 导入层
导入 tensorflow 作为 tf
导入 pandas 作为 pd
从 keras.datasets 导入 imdb
(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)

def OneHotEncoding_fn(IMDBData,dimension=10000):
OneHotEncoded_Data=np.zeros((len(IMDBData),dimension)) 
for i,sequence in enumerate(IMDBData):
OneHotEncoded_Data[i,sequence]=1.
返回 OneHotEncoded_Data

training_data=OneHotEncoding_fn(training_data)
testing_data=OneHotEncoding_fn(testing_data)
training_targets=np.asarray(training_targets).astype(&#39;float32&#39;)
testing_targets=np.asarray(testing_targets).astype(&#39;float32&#39;)

model=models.Sequential()
model.add(layers.Dense(50, 激活=&#39;relu&#39;, 输入形状=(10000,)))
model.add(layers.Dropout(0.3, 噪声形状=无, 种子=无))
model.add(layers.Dropout(50, 激活=&#39;relu&#39;))
model.add(layers.Dropout(0.2, 噪声形状=无, 种子=无))
model.add(layers.Dense(50, 激活 = &quot;relu&quot;))
model.add(layers.Dense(1,activation=&#39;sigmoid&#39;))
model.summary()

data_validation=training_data[:5000]
training_data_without_val=training_data[5000:]
targets_validation=training_targets[:5000]
training_targets_without_val=training_targets[5000:]

model.compile(optimizer=&#39;RMSprop&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])
history=model.fit(training_data_without_val,training_targets_without_val,epochs=25,batch_size=512,validation_data=(data_validation,targets_validation))

x = input(&#39;写下您的评论： &#39;)
pred=model.predict(x)

我需要写我的评论（例如“这是一部非常有趣的电影”）来测试模型的准确性。输入后，程序必须将我的单词编码为索引相关的 Keras IMDB 索引并输出结果（1 或 0）。怎么做？
我试图在这里找到信息：https://keras.io/api/datasets/imdb/，但没有成功。我需要编写一个允许您输入用户文本的函数（在报告中，给出网络如何处理用户文本的示例）。错误：无法识别的数据类型：x=这是一部非常有趣的电影（类型为 &lt;class &#39;str&#39;&gt;）]]></description>
      <guid>https://stackoverflow.com/questions/78414840/how-to-test-a-model-on-users-input-predict-sentiment-from-movie-reviews</guid>
      <pubDate>Wed, 01 May 2024 16:26:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 torch autograd 与 functorch 计算的梯度之间存在微小差异？</title>
      <link>https://stackoverflow.com/questions/78414800/why-is-there-a-small-difference-between-gradients-calculated-using-torch-autogra</link>
      <description><![CDATA[我正在使用这个链接解决方案来自上一个问题，比手动循环更有效地计算梯度。
我注意到使用两种方法计算的梯度存在一些细微差别（即 torch.abs(grads_torch - grads_func).sum() 返回 ~10e-06）。什么可以解释这种差异？一种解决方案比另一种更正确吗？
MWE
导入火炬
从torchvision导入数据集，转换
将 torch.nn 导入为 nn

＃＃＃＃＃＃ 设置 ＃＃＃＃＃＃

类 MLP(nn.Module):
    def __init__(自身，输入大小，隐藏大小，输出大小)：
        超级（MLP，自我）.__init__()
        self.fc1 = nn.Linear(输入大小，隐藏大小)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(隐藏大小, 输出大小)
        
    def 前向（自身，x）：
        h = self.fc1(x)
        pred = self.fc2(self.relu(h))
        返回预测值
    
train_dataset = datasets.MNIST(root=&#39;./data&#39;, train=True, download=True,
                            变换=变换.Compose(
                                [transforms.ToTensor(),
                                    变换.Normalize((0.5,),(0.5,))
        ]))

train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=2,shuffle=False)

X, y = next(iter(train_dataloader)) # 随机获取一批数据

net = MLP(28*28, 20, 10) # 定义一个网络


###### 使用 Torch AUTOGRAD GRAD 计算梯度 ######
def计算梯度（模型，X）：
    # 创建一个张量来保存梯度
    梯度 = torch.zeros(X.shape[0], 10, sum(p.numel() for p in model.parameters()))

    # 计算每个输入和目标维度的梯度
    对于范围内的 i(X.shape[0])：
        对于范围 (10) 内的 j：
            model.zero_grad()
            输出 = 模型(X[i])
            # 计算梯度
            grads = torch.autograd.grad(输出[j], model.parameters())
            # 压平梯度并存储它们
            梯度[i, j, :] = torch.cat([g.view(-1) for g in grads])
            
    返回梯度

grads_torch =calculate_gradients(net, X.view(X.shape[0], -1))

###### 现在使用 FUNCTORCH 计算相同的梯度 ######
# 提取函数调用的参数和缓冲区
params = {k: v.detach() for k, v in net.named_pa​​rameters()}
buffers = {k: v.detach() for k, v in net.named_buffers()}

def one_sample(样本):
    # 这将计算单个样本的梯度
    # 我们希望每个输出的梯度与参数相关
    # 这与网络参数的雅可比矩阵相同

    # 定义一个函数，以输入作为返回网络的输出
    call = lambda x: torch.func.function_call(net, (x, 缓冲区), 样本)
    
    # 计算网络与参数的雅可比矩阵
    J = torch.func.jacrev(call)(params)
    
    # J 是一个字典，键为参数名称，值为梯度
    # 我们想要一个张量
    grads = torch.cat([v.flatten(1) for v in J.values()],-1)
    返回毕业生

# 不，我们可以使用 vmap 一次性计算所有样本的梯度
grads_func = torch.vmap(one_sample)(X.flatten(1))

print(torch.allclose(grads_torch, grads_func)) # 返回 True
print(torch.abs(grads_torch - grads_func).sum()) # 返回张量(1.4454e-05)
]]></description>
      <guid>https://stackoverflow.com/questions/78414800/why-is-there-a-small-difference-between-gradients-calculated-using-torch-autogra</guid>
      <pubDate>Wed, 01 May 2024 16:14:45 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：“ParticleSwarmOptimization”对象没有属性“global_best_fitnes”</title>
      <link>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</link>
      <description><![CDATA[用于特征选择的执行代码 PSO 出错
def 健身（位置）：
    selected_features = np.array(位置, dtype=bool)
    X_selected = X.iloc[:, selected_features]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
    
    分类器 = KNeighborsClassifier()
    分类器.fit(X_train, y_train)
    y_pred = 分类器.预测(X_test)
    准确度=准确度_得分(y_test, y_pred)
    返回精度

将 numpy 导入为 np

粒子群优化类：
    def __init__(自身、n_粒子、n_特征、n_迭代、fitness_function、w=0.5、c1=1、c2=2)：
        self.n_粒子 = n_粒子
        self.n_features = n_features
        self.n_iterations = n_iterations
        self.fitness_function = 健身函数
        自我.w = w
        自身.c1 = c1
        自身.c2 = c2

    def 初始化粒子（自身）：
        返回 np.random.choice([0, 1], size=(self.n_articles, self.n_features))

    def update_velocity(自身、速度、个人最佳、全局最佳、位置)：
        认知 = self.c1 * np.random.rand() * (personal_best - 位置)
        社会 = self.c2 * np.random.rand() * (global_best - 位置)
        返回 self.w * 速度 + 认知 + 社交

    def update_position（自身，位置，速度）：
        返回 np.round(1 / (1 + np.exp(-velocity))).astype(int)

    def 优化（自我）：
        self.best_fitness_history = [] # 添加此行来存储健身历史记录

        # 初始化粒子
        位置 = self.initialize_articles()
        速度 = np.zeros((self.n_articles, self.n_features))

        个人最佳 = 位置.copy()
        Personal_best_fitness = np.array([self.fitness_function(pos) for pos in individual_best])

        self.global_best = individual_best[np.argmax(personal_best_fitness)]
        self.global_best_fitness = np.max(personal_best_fitness)

        对于范围内的迭代（self.n_iterations）：
            对于范围内的 i(self.n_articles)：
                # 更新速度和位置
                速度[i] = self.update_velocity(速度[i], individual_best[i], self.global_best, 位置[i])
                位置[i] = self.update_position(位置[i], 速度[i])

                # 更新个人最好成绩
                current_fitness = self.fitness_function(position[i])
                如果 current_fitness &gt;个人最佳健身[i]：
                    个人最佳[i] = 位置[i].copy()
                    个人最佳健康度[i] = 当前健康度

                    # 更新全局最佳值
                    如果 current_fitness &gt; self.global_best_fitness：
                        self.global_best = 位置[i].copy()
                        self.global_best_fitness = current_fitness
                        
                        self.best_fitness_history.append(self.global_best_fitness)

        返回 self.global_best, self.global_best_fitnes
]]></description>
      <guid>https://stackoverflow.com/questions/78414096/attributeerror-particleswarmoptimization-object-has-no-attribute-global-best</guid>
      <pubDate>Wed, 01 May 2024 13:57:37 GMT</pubDate>
    </item>
    <item>
      <title>ValueError（不匹配的列）持续存在</title>
      <link>https://stackoverflow.com/questions/78410491/valueerrormismatched-columns-is-persisting</link>
      <description><![CDATA[在我的代码中，我尝试使用以下代码将数据从数据表放入 df 表（最初为空，仅包含代码定义的 header_row）：
 df = pd.DataFrame(columns=[&#39;time&#39;] + list(map(str, range(30))))
    对于 i，enumerate(sorted(set(data.index.time))) 中的时间：
     df.loc[i] = [time.strftime(format=&#39;%H:%M:%S&#39;)] + list(data.at_time(time)[&#39;load&#39;].values)[:31]

现在数据表看起来（类似地有 30 天的数据）：
导入请求
导入csv
导入操作系统
从 bs4 导入 BeautifulSoup
从日期时间导入日期时间，时间增量

def get_load_data(日期):
    url = &#39;http://www.delhisldc.org/Loaddata.aspx?mode=&#39;
    print(&#39;抓取&#39;, 日期)
    resp = requests.get(url+date) # 向url发送get请求，获取响应
    soup = BeautifulSoup(resp.text, &#39;lxml&#39;) # 美味的 HTML 汤
    table = soup.find(&#39;table&#39;, {&#39;id&#39;:&#39;ContentPlaceHolder3_DGGridAv&#39;}) # 从html中获取表格
    trs = table.findAll(&#39;tr&#39;) # 提取表的所有行
    if len(trs[1:])!=0: # 如果没有数据，则无需创建 2017 年 8 月的 csv 文件
        csv_filename = &#39;月份数据.csv&#39;
        将 open(csv_filename, &#39;a&#39;) 作为 f：
            作家 = csv.writer(f)
            计数=0
            对于 trs[1:] 中的 tr：
                时间，德里 = tr.findChildren(&#39;font&#39;)[:2]
                writer.writerow([日期+&#39; &#39;+时间.文本, 德里.文本])
                计数+=1
    如果计数！= 288：
        print(&#39;某些负载值丢失..&#39;)
    别的：
        打印（&#39;完成&#39;）

# 日期 = 日期.split(&#39;/&#39;)
# 日期.reverse()
&#39;&#39;.加入（日期）
对于范围 (31, 0, -1) 内的 i：
    昨天 = datetime.today() - timedelta(i)
    昨天 = 昨天.strftime(&#39;%d/01/2023&#39;) #在这里你可以更改日期。到你的数据
    获取加载数据（昨天）


!头月数据.csv
数据= pd.read_csv（&#39;monthdata.csv&#39;，标题=无，名称= [&#39;日期时间&#39;，&#39;加载&#39;]，index_col = [0]，parse_dates = [0]，infer_datetime_format = True）

现在我希望 df 是这样的（header_row 代表一个月的时间和日期）：

现在，即使 df 和列表（日期+1）具有相同的列，我也不知道为什么会出现此错误（对于本文中的第一个代码块）：
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-165-10ddc3e7faf7&gt;在&lt;细胞系：2&gt;()
      1 df = pd.DataFrame(columns=[&#39;时间&#39;] + list(map(str, range(30))))
      2 对于 i，enumerate(sorted(set(data.index.time))) 中的时间：
----&gt; 3 df.loc[i] = [time.strftime(format=&#39;%H:%M:%S&#39;)] + list(data.at_time(time)[&#39;load&#39;].values)[:31]
      4 # # data.at_time(time).plot()
      5 # # 如果 idx&gt;10: 中断

2帧
_setitem_with_indexer_missing 中的/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py（自身，索引器，值）
   第2156章
   第2157章
-&gt;第2158章
   2159
   第2160章

ValueError：无法设置列不匹配的行

提前致谢！]]></description>
      <guid>https://stackoverflow.com/questions/78410491/valueerrormismatched-columns-is-persisting</guid>
      <pubDate>Tue, 30 Apr 2024 18:40:39 GMT</pubDate>
    </item>
    <item>
      <title>Google Ads 数据的数据科学/机器学习分析 [关闭]</title>
      <link>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</link>
      <description><![CDATA[我们希望对 Google Ads 数据进行一些 ML 分析，以微调我们的营销效果。有人对方法有什么建议吗？
是否有任何现有的资源，其中有认真的 DS/ML 从业者正在使用来自 Google Ads 的数据，也许还添加了其他来源（YouTube 等），以生成预测分析，从而最大化转化价值。
我们正在考虑：
识别然后可能调整不同的关键字值
识别每个广告系列或广告中可能解释效果的不同特征
通过识别“趋势”主题、主题标签等（而不是被动方法）探索“套利”关键字值的可能性
生成因果发现/因果推理分析以解释事件之间关系的强度
我们理想情况下寻找可以向我们展示该领域现有思想的最佳实践/权威分析师/资源。任何提供分析方法的 GitHub 存储库的建议都将不胜感激。
我们从“Google Ads”的角度在 Google 上搜索了这个问题，并查看了 Reddit，但有很多噪音和“黑盒”解决方案，所以我们决定从严肃的 DS 从业者的角度来解决这个问题……希望你能帮忙。
我们已经将 Google Ads 广告系列、广告和关键字数据通过 PyCaret ML 回归分析，并得到了一些基础结果，但我们现在正在寻找如何推进这一工作的指导。]]></description>
      <guid>https://stackoverflow.com/questions/78409943/data-science-ml-analysis-of-google-ads-data</guid>
      <pubDate>Tue, 30 Apr 2024 16:38:08 GMT</pubDate>
    </item>
    <item>
      <title>如何基于掩码相乘矩阵并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    <item>
      <title>训练精度高 测试精度差</title>
      <link>https://stackoverflow.com/questions/61464796/high-train-accuracy-poor-test-accuracy</link>
      <description><![CDATA[我有一个对 3 个输出进行分类的神经网络。我的数据集非常小，我有 340 张用于训练的图像和 60 张用于测试的图像。我建立了一个模型，编译后的结果如下：
Epoch 97/100
306/306 [==============================] - 46s 151ms/step - loss: 0.2453 - accuracy: 0.8824 - val_loss: 0.3557 - val_accuracy: 0.8922
Epoch 98/100
306/306 [===============================] - 47s 152ms/step - loss: 0.2096 - accuracy: 0.9031 - val_loss: 0.3795 - val_accuracy: 0.8824
Epoch 99/100
306/306 [==============================] - 47s 153ms/step - 损失：0.2885 - 准确度：0.8627 - val_loss：0.4501 - val_accuracy：0.7745
Epoch 100/100
306/306 [==============================] - 46s 152ms/step - 损失：0.1998 - 准确度：0.9150 - val_loss：0.4586 - val_accuracy：0.8627

当我预测测试图像时，测试准确度很差。
我该怎么办？我也使用 ImageDatagenerator 进行数据增强，但结果是一样的。是不是因为我的数据集很小。]]></description>
      <guid>https://stackoverflow.com/questions/61464796/high-train-accuracy-poor-test-accuracy</guid>
      <pubDate>Mon, 27 Apr 2020 17:31:25 GMT</pubDate>
    </item>
    </channel>
</rss>