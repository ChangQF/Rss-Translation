<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 01 Jun 2024 01:06:57 GMT</lastBuildDate>
    <item>
      <title>pytorch 模型返回一个元组而不是张量</title>
      <link>https://stackoverflow.com/questions/78562431/pytorch-model-returns-a-tuple-instead-of-tensor</link>
      <description><![CDATA[我使用 pytorch 在 python 中编写了一个程序。我的问题是：
我的 模型返回的是元组而不是张量。我如何让/强制我的模型返回张量？
这是我的代码：
import torch
from torch import nn
import numpy as np
from torch.optim import Adam

x = np.linspace(0, 1, 50).reshape((-1, 1)).astype(&#39;float32&#39;)
y = np.power(x, 2).reshape((-1, 1)).astype(&#39;float32&#39;)

x = torch.tensor(x)
y = torch.tensor(y)

model = nn.Sequential(
nn.Linear(1, 1),
nn.ReLU()
)

loss = nn.MSELoss()
opt = Adam(model.parameters(), lr=0.001)
model.train()
n_batch = 4
n_epoch = 100
for i in range(n_epoch):
for b in range(0, len(x), n_batch):
inp = x[b:b+n_batch]
out = y[b:b+n_batch]
opt.zero_grad()
pred = model(inp),
ls = loss(pred, out)
ls.backward()
opt.step()

这是我得到的错误：

文件 &quot;...\torch\nn\ functional.py&quot;，第 3355 行，在 mse_loss 中
if not (target.size() == input.size()): AttributeError: &#39;tuple&#39; 对象没有属性 &#39;size&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/78562431/pytorch-model-returns-a-tuple-instead-of-tensor</guid>
      <pubDate>Fri, 31 May 2024 23:27:37 GMT</pubDate>
    </item>
    <item>
      <title>我是否应该为图像贴上它的本质或外观的标签？[关闭]</title>
      <link>https://stackoverflow.com/questions/78562207/should-i-rather-label-my-image-for-what-it-is-or-what-it-looks-like</link>
      <description><![CDATA[对于某些人来说，这可能非常明显，但我正在重新考虑。
我想训练一个 CNN，它可以通过图像识别识别垃圾分类。也就是说，我希望能够拍摄例如麦片盒的照片，结果应该是“纸质”垃圾。
我目前正在清理我的数据集，因为有些图像属于错误的类别。
举个例子：利乐包的外面看起来像纸板箱。纸板通常属于纸质垃圾。但由于内部通常涂有某种塑料，利乐包实际上属于包装垃圾。
这对我来说非常直观，但我不确定神经网络是否能够以某种方式学习这种差异，或者将牛奶盒放入“包装”类别，将形状极其相似甚至由相同材料制成的麦片盒放入“纸”类别是否只会导致不准确的结果。有时，唯一的泄露是盒子的开口，盒子也是塑料的，但在某些图像上，由于角度原因，这个开口是看不见的。其他东西也是如此，比如揉成一团的纸（“纸”）和纸巾（“残留物”）。
简而言之：如果我有一张我知道属于 A 类的图像，但根据图像上可见的内容，它看起来与 B 类一模一样，我该把它归入哪一类？]]></description>
      <guid>https://stackoverflow.com/questions/78562207/should-i-rather-label-my-image-for-what-it-is-or-what-it-looks-like</guid>
      <pubDate>Fri, 31 May 2024 21:39:42 GMT</pubDate>
    </item>
    <item>
      <title>Keras 模型构建出现错误无法将‘51’转换为形状</title>
      <link>https://stackoverflow.com/questions/78562109/keras-model-building-get-error-cannot-convert-51-to-a-shape</link>
      <description><![CDATA[我正在制作一个 keras 模型来对人体姿势进行分类。我从链接中获取了代码
在 Colab 中它运行良好。我在本地出现以下错误
无法将“51”转换为形状。
def Landmarks_to_embedding(landmarks_and_scores):
&quot;&quot;&quot;将输入地标转换为姿势嵌入。&quot;&quot;&quot;
# 将平面输入重塑为具有形状=（17, 3）的矩阵
reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)

# 规范化 2D 地标
skylines = normalize_pose_landmarks(reshaped_inputs[:, :, :2])

# 将规范化的地标坐标展平为向量
embedding = keras.layers.Flatten()(landmarks)

return embedding

inputs = tf.keras.Input(shape=(51))
embedding = skylines_to_embedding(inputs)

layer = keras.layers.Dense(128,activation=tf.nn.relu6)(embedding)
layer = keras.layers.Dropout(0.5)(layer)
layer = keras.layers.Dense(64,激活=tf.nn.relu6)(层)
层 = keras.layers.Dropout(0.5)(层)
输出 = keras.layers.Dense(len(class_names), 激活=&quot;softmax&quot;)(层)

模型 = keras.Model(输入，输出)
模型.summary()
]]></description>
      <guid>https://stackoverflow.com/questions/78562109/keras-model-building-get-error-cannot-convert-51-to-a-shape</guid>
      <pubDate>Fri, 31 May 2024 20:59:15 GMT</pubDate>
    </item>
    <item>
      <title>随机森林/决策树输出概率设计：使用正输出叶样本/总输出叶样本</title>
      <link>https://stackoverflow.com/questions/78561885/random-forest-decision-tree-output-probability-design-using-positive-output-l</link>
      <description><![CDATA[我正在使用 python 和 scikitlearn 设计一个二元分类器随机森林模型，我想在其中检索我的测试集是两个标签之一的概率。据我了解，predict_proba(xtest) 将给我以下结果：
投票给分类器的树数/树数

我发现这太不精确了，因为某些树节点可能将我的（非确定性）样本分成相当精确的叶子（100 个 a 类，0 个 b 类）和不精确的叶子（5 个 a 类，3 个 b 类）。我想要一个“概率”的实现，将我的 n 个分类器输出叶子中的样本总数作为主导，将输出叶子中总体选择的分类器的总数作为分子（即使对于选择大多数树没有选择的类的树及其输出叶子也是如此）。
例如（简单）：
2 棵树：
树 1： 
--- 5, 0 类 A（已选择） 
10 
--- 2, 3 类 B（未选择） 

树 2： 
--- 3, 2 类 A（已选择） 
10 
--- 5, 0 类 B（未选择）

predict_proba 结果：
选择类 A 的树数 (2) / 树数 (2) = 1.0

期望结果：
输出叶子中的 A 类样本数 (8) / 输出叶子中的样本总数 (10) = 0.8

有人知道如何做到这一点，或者他们正在使用什么实现？
我有一个想法，就是遍历每棵树，检索它们的概率，然后取平均值。但是，这会给样本较少的输出叶子带来更高的偏差（选举团风格）。
如何直接访问特定样本的决策树输出叶子的样本数量及其类别（或者甚至只是叶子索引，然后从那里开始）？在随机森林的情况下，对它们求和并取平均值？
如果不行，就完全切换平台/库？或者可能只是增加分类器的数量（不是最佳的）？
一些可能有用的文档？：
dtc.tree_.n_node_samples
dtc.tree_[node_index].n_node_samples ?
]]></description>
      <guid>https://stackoverflow.com/questions/78561885/random-forest-decision-tree-output-probability-design-using-positive-output-l</guid>
      <pubDate>Fri, 31 May 2024 19:44:58 GMT</pubDate>
    </item>
    <item>
      <title>当设备设置为“cuda”时，为什么 optuna 会对我的 CPU 而不是 GPU 施加压力？</title>
      <link>https://stackoverflow.com/questions/78561318/why-is-optuna-stressing-my-cpu-instead-of-gpu-when-device-is-set-to-cuda</link>
      <description><![CDATA[我正在使用 optuna 进行超参数调整，尽管我的设备设置为“cuda”，并且它实际上在 cuda 上运行，因为在 CPU 上完成 10 个 epoch 需要 40 分钟，而目前，完成 30 个 epoch 只需要 6 分钟。这意味着，我的程序正在使用 GPU。但是，我检查发现 CPU 的压力已经达到 100%，而我的 GPU 几乎没有被程序利用。

这是我的硬件和软件规格：
硬件规格：
Lenovo Legion 5 2022
Ryzen 7 6800H
NVIDIA RTX 3060 TDP 140W
16 GB DDR5 RAM 4800 Mhz
1TB PCIE Gen 4 SSD
Optimus 已禁用（仅限 NVIDIA Dgpu）

软件规格：
python 3.10.9
conda 23.3.1
optuna 3.6.0 conda-forge
optuna-dashboard 0.15.1 conda-forge

我找不到任何方法可以解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78561318/why-is-optuna-stressing-my-cpu-instead-of-gpu-when-device-is-set-to-cuda</guid>
      <pubDate>Fri, 31 May 2024 17:00:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么我们只需要一张图片就可以训练 CNN 模型？[关闭]</title>
      <link>https://stackoverflow.com/questions/78560997/why-do-we-only-need-one-picture-to-train-a-cnn-model</link>
      <description><![CDATA[在此处输入图片说明
请看那里的图片。我们可以看到，你可以给模型一张图片，然后模型就可以告诉你它是汽车还是鸟。我的问题是，作为一个监督模型，CNN 应该需要大量的图片来训练，而图片中的情况并非如此。]]></description>
      <guid>https://stackoverflow.com/questions/78560997/why-do-we-only-need-one-picture-to-train-a-cnn-model</guid>
      <pubDate>Fri, 31 May 2024 15:41:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 keras 中添加具有可训练参数的自定义损失函数</title>
      <link>https://stackoverflow.com/questions/78559415/how-to-add-custom-loss-function-with-trainable-parameter-in-keras</link>
      <description><![CDATA[我正在训练一个 LSTM 模型来预测未来的值。为此，我想定义一个与“mse”相同的自定义损失函数。但平方差将与指数项相乘，e^alpha。并且这个 alpha 项应该随着训练过程而更新。
我不确定我是否朝着正确的方向前进，但我已经用 mse 训练了模型，它通过使用真实数据给出了很好的预测。但作为现实生活中的预测，当我们在一段时间内没有真实数据时，我的模型应该使用最后一个预测作为模型下一个输入的输入，就像这样。在将模型作为此任务进行测试时，预测值不断偏离最后一个真实值。当一段时间后有新的真实数据可用时，它应该与未来的值相匹配。]]></description>
      <guid>https://stackoverflow.com/questions/78559415/how-to-add-custom-loss-function-with-trainable-parameter-in-keras</guid>
      <pubDate>Fri, 31 May 2024 09:59:12 GMT</pubDate>
    </item>
    <item>
      <title>即使指定了某些列，Pandas 也会获取数据框的所有列</title>
      <link>https://stackoverflow.com/questions/78559070/pandas-takes-all-columns-of-a-dataframe-even-when-some-columns-are-specified</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78559070/pandas-takes-all-columns-of-a-dataframe-even-when-some-columns-are-specified</guid>
      <pubDate>Fri, 31 May 2024 08:59:38 GMT</pubDate>
    </item>
    <item>
      <title>yolo 训练精度低，map少</title>
      <link>https://stackoverflow.com/questions/78558728/yolo-training-with-low-precision-and-low-map</link>
      <description><![CDATA[我正在使用 YOLOv5 训练一个模型来识别纸牌游戏中的纸牌。我从预训练模型 yolov5s.pt 开始，我的数据集由 138 张图片组成。然而，训练期间准确率和 mAP 非常低，分别从 2.35e-05 和 2.27e-05 开始，经过 80 个 epoch 后，它们仅达到 0.0169 和 0.0547。
我不知道问题出在哪里。有人能帮我吗？
这是训练批次图像和输出表的图片。


顺便说一句，我只想识别弃牌，而不是手牌。
我试过改变批次大小等。但变化不大。]]></description>
      <guid>https://stackoverflow.com/questions/78558728/yolo-training-with-low-precision-and-low-map</guid>
      <pubDate>Fri, 31 May 2024 07:43:37 GMT</pubDate>
    </item>
    <item>
      <title>具有不平衡类别的 U-Net 分割的图像块提取</title>
      <link>https://stackoverflow.com/questions/78555784/image-patch-extraction-for-u-net-segmentation-with-imbalanced-classes</link>
      <description><![CDATA[我正在使用 U-Net 进行多类图像分割项目。
我的数据集的类别分布不平衡。有些类别几乎出现在每幅图像中，而其他类别则很少见。我不确定图像修补的最佳方法：
在每个补丁内做出相等的类别表示？在这种情况下，对于某些类别，我将不得不使用数据增强技术。
还是保持补丁内原始的不平衡比例？]]></description>
      <guid>https://stackoverflow.com/questions/78555784/image-patch-extraction-for-u-net-segmentation-with-imbalanced-classes</guid>
      <pubDate>Thu, 30 May 2024 14:57:49 GMT</pubDate>
    </item>
    <item>
      <title>由于 decision_function，使用 roc_auc 度量的 KNeighborsClassifier 的 GridSearchCV 和 cross_val_score 返回错误</title>
      <link>https://stackoverflow.com/questions/78552800/gridsearchcv-and-cross-val-score-with-kneighborsclassifier-using-roc-auc-metric</link>
      <description><![CDATA[我正在研究二元分类问题。
类别分布为正：30% - 负：70%。因此，我决定使用 roc_auc 作为度量标准
然后，我在 KNeighborsClassifier 上运行超参数调整，但出现错误，我不知道如何解决
我使用的 scikit-learn 版本是 &#39;1.2.2&#39;
这是代码
param_grid = [ 
{
&#39;knn__n_neighbors&#39;: np.arange(2, 30, 1),
&#39;knn__weights&#39; : [&#39;uniform&#39;, &#39;distance&#39;],
&#39;knn__algorithm&#39; : [&#39;auto&#39;, &#39;ball_tree&#39;, &#39;kd_tree&#39;],
&#39;knn__leaf_size&#39;: np.arange(30, 1000, 20)
}
]

knn = Pipeline([
(&quot;preprocessing&quot;, preprocessing),
(&quot;knn&quot;, KNeighborsClassifier())
])

grid_search = GridSearchCV(
knn,
param_grid,
cv=cv,
scoring=&quot;roc_auc&quot;,
verbose=0
)
grid_search.fit(x_train, y_train)
grid_search.best_params_

错误是
/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: 评分失败。此训练测试分区中这些参数的分数将设置为 nan。详细信息：
回溯（最近一次调用）：
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 373 行，在 _score 中
y_pred = method_caller(clf, “decision_function”, X)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 73 行，在 _cached_call 中
返回 getattr(estimator, method)(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件&quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_available_if.py&quot;, line 32, in __get__
if not self.check(obj):
^^^^^^^^^^^^^^^
File &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py&quot;, line 46, in check
getattr(self._final_estimator, attr)
AttributeError: &#39;KNeighborsClassifier&#39; object has no attribute &#39;decision_function&#39;

在处理上述异常时，发生了另一个异常：

它说 KNeighborsClassifier 没有属性 decision_function
经过一些阅读，我明白了 decision_function 在度量标准为roc_auc
现在，即使存在此问题，如何运行超参数调整？
此外，即使在使用 KNeighborsClassifier 和 roc_auc 作为指标运行时，cross_val_score 也会返回 nan
knn = Pipeline([
(&quot;preprocessing&quot;, preprocessing),
(&quot;knn&quot;, KNeighborsClassifier(
algorithm=&#39;auto&#39;,
leaf_size=30,
metric=&#39;minkowski&#39;,
n_neighbors=28,
weights=&#39;uniform&#39;
))
])
scores = cross_val_score(knn, x_train, y_train, cv=cv)
scores

错误是
/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:794: UserWarning: 评分失败。此训练测试分区中这些参数的分数将设置为 nan。详细信息：
回溯（最近一次调用）：
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 117 行，在 __call__ 中
score = scorer(estimator, *args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_scorer.py”，第 444 行，在 _passthrough_scorer 中
返回 estimator.score(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件&quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/pipeline.py&quot;，第 722 行，得分
返回 self.steps[-1][1].score(Xt, y, **score_params)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py&quot;，第 668 行，得分
返回 accuracy_score(y, self.predict(X), sample_weight=sample_weight)
^^^^^^^^^^^^^^^^^
文件 &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_classification.py&quot;，第234，在预测中
neigh_ind = self.kneighbors(X, return_distance=False)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;/opt/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py&quot;，第 824 行，在 kneighbors 中
results = ArgKmin.compute(

现在由 predict() 完成]]></description>
      <guid>https://stackoverflow.com/questions/78552800/gridsearchcv-and-cross-val-score-with-kneighborsclassifier-using-roc-auc-metric</guid>
      <pubDate>Thu, 30 May 2024 04:00:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么加载 AutoTokenizer 会占用这么多的 RAM？</title>
      <link>https://stackoverflow.com/questions/78546693/why-loading-autotokenizer-takes-so-much-ram</link>
      <description><![CDATA[我测量了脚本使用的 RAM，惊讶地发现它占用了大约 300Mb 的 RAM，而 tokenizer 文件本身大约只有 9MB。这是为什么？
我试过：
from transformers import AutoTokenizer
from memory_profiler import profile

@profile
def load_tokenizer():
path = &quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot; 
tokenizer = AutoTokenizer.from_pretrained(path)

return tokenizer

load_tokenizer()

输出：
行 # 内存使用量 增量 发生次数 行内容
==================================================================
4 377.4 MiB 377.4 MiB 1 @profile
5 def load_tokenizer():
6 377.4 MiB 0.0 MiB 1 path = &quot;sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2&quot; 
7 676.6 MiB 299.2 MiB 1 tokenizer = AutoTokenizer.from_pretrained(path)
8 
9 
10 676.6 MiB 0.0 MiB 1 返回 tokenizer
]]></description>
      <guid>https://stackoverflow.com/questions/78546693/why-loading-autotokenizer-takes-so-much-ram</guid>
      <pubDate>Tue, 28 May 2024 22:44:10 GMT</pubDate>
    </item>
    <item>
      <title>VertexAIException - 调用 Gemini-Pro API 时出现列表索引超出范围错误</title>
      <link>https://stackoverflow.com/questions/77930819/vertexaiexception-list-index-out-of-range-error-when-calling-gemini-pro-api</link>
      <description><![CDATA[我正在以连续的方式调用 Google Gemini-Pro API（例如每分钟大约 50 个查询）。我相信我已经正确设置了我的 VertexAI 项目和凭据。当我使用的连续查询数低于一个恒定的条时，查询将运行，并且响应将正常接收。但是，一旦查询数量增加到上述条以上，就会出现以下错误：

IndexError - 列表索引超出范围

请注意，发生此错误的查询数“条”取决于每个查询的长度，并且如果查询的长度在程序执行过程中保持不变，则该查询数是一致的。例如，在尝试将查询长度增加大约 20% 后，查询数量从大约 330 个下降到大约 60 个。

文件
&quot;/Users/user/anaconda3/envs/chat1/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py&quot;,
line 1315, in text
return self.candidates[0].text
~~~~~~~~~~~~~~~^^^ IndexError: 列表索引超出范围

是什么原因造成的？我已将 VertexAI 服务器位置设置为：“us-central1”，据我所知，其配额应仅为 300 个查询/分钟。由于我连续进行 API 调用，但低于 60 个查询/分钟的速率，因此我认为我的使用情况尚可。我目前正在使用免费的 VertexAI 试用帐户（免费赠送 300 美元信用额度）。
我编写的 Gemini Pro API 调用函数是：
def gemini_response(message: str) -&gt; str:
# 初始化 Vertex AI
vertexai.init(project=&quot;project-id-0123&quot;, location=&quot;us-central1&quot;)

# 加载模型
model = GenerativeModel(&quot;gemini-pro&quot;)

# 查询模型
response = model.generate_content(message)
return response.text

在调试 candidates 变量出了什么问题时，变量检查结果如下所示：
&gt; self 
&gt; prompt_feedback {block_reason: OTHER} 
&gt; usage_metadata {prompt_token_count: 505 total_token_count: 505 } 

&gt; self.candidates 
&gt; []

&gt; self._raw_response 
&gt; prompt_feedback {block_reason: OTHER}
&gt; usage_metadata {prompt_token_count: 505 total_token_count: 505 }
]]></description>
      <guid>https://stackoverflow.com/questions/77930819/vertexaiexception-list-index-out-of-range-error-when-calling-gemini-pro-api</guid>
      <pubDate>Sat, 03 Feb 2024 04:05:38 GMT</pubDate>
    </item>
    <item>
      <title>Optuna 在大量试验中建议相同的参数值（重复试验浪费时间和预算）</title>
      <link>https://stackoverflow.com/questions/64836142/optuna-suggests-the-same-parameter-values-in-a-lot-of-trials-duplicate-trials-t</link>
      <description><![CDATA[由于某种原因，Optuna TPESampler 和 RandomSampler 多次尝试对任何参数使用相同的建议整数值（也可能是浮点数和对数均匀值）。我找不到阻止它反复建议相同值的方法。在 100 次试验中，其中相当一部分只是重复的。唯一建议值计数最终在 100 次试验中约为 80-90。如果我包含更多参数进行调整，比如 3 个，我甚至会看到所有 3 个参数在 100 次试验中都获得了相同的值几次。
就像这样。min_data_in_leaf 的 75 被使用了 3 次：
[I 2020-11-14 14:44:05,320] 第 8 次试验结束，值为：45910.54012028659，参数为：{&#39;min_data_in_leaf&#39;: 75}。最佳的是试验 4，其值为：45805.19030897498。
[I 2020-11-14 14:44:07,876] 试验 9 完成，其值为：45910.54012028659，参数为：{&#39;min_data_in_leaf&#39;: 75}。最佳的是试验 4，其值为：45805.19030897498。
[I 2020-11-14 14:44:10,447] 试验 10 完成，其值为：45831.75933279074，参数为：{&#39;min_data_in_leaf&#39;: 43}。最佳的是试验 4，其值为：45805.19030897498。
[I 2020-11-14 14:44:13,502] 试验 11 完成，其值为：46125.39810101329，参数为：{&#39;min_data_in_leaf&#39;: 4}。最佳的是试验 4，其值为：45805.19030897498。
[I 2020-11-14 14:44:16,547] 试验 12 完成，其值为：45910.54012028659，参数为：{&#39;min_data_in_leaf&#39;: 75}。最佳的是第 4 次试验，其值为：45805.19030897498。
以下示例代码：
def lgb_optuna(trial):

rmse = []

params = {
&quot;seed&quot;: 42,
&quot;objective&quot;: &quot;regression&quot;,
&quot;metric&quot;: &quot;rmse&quot;,
&quot;verbosity&quot;: -1,
&quot;boosting&quot;: &quot;gbdt&quot;,
&quot;num_iterations&quot;: 1000,
&#39;min_data_in_leaf&#39;: trial.suggest_int(&#39;min_data_in_leaf&#39;, 1, 100)
}

cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=False)
for train_index, test_index in cv.split(tfd_train, tfd_train[:,-1]):
X_train, X_test = tfd_train[train_index], tfd_train[test_index]
y_train = X_train[:,-2].copy()
y_test = X_test[:,-2].copy()

dtrain = lgb.Dataset(X_train[:,:-2], label=y_train)
dtest = lgb.Dataset(X_test[:,:-2], label=y_test)

booster_gbm = lgb.train(params, dtrain, valid_sets=dtest, verbose_eval=False)

y_predictions = booster_gbm.predict(X_test[:,:-2])
final_mse = mean_squared_error(y_test, y_predictions)
final_rmse = np.sqrt(final_mse)
rmse.append(final_rmse)

return np.mean(rmse)

study = optuna.create_study(sampler=TPESampler(seed=42), direction=&#39;minimize&#39;) 
study.optimize(lgb_optuna, n_trials=100) 
]]></description>
      <guid>https://stackoverflow.com/questions/64836142/optuna-suggests-the-same-parameter-values-in-a-lot-of-trials-duplicate-trials-t</guid>
      <pubDate>Sat, 14 Nov 2020 16:33:17 GMT</pubDate>
    </item>
    <item>
      <title>我如何知道使用 SelectKBest 选择了哪些功能？</title>
      <link>https://stackoverflow.com/questions/50942553/how-do-i-know-which-features-are-selected-with-selectkbest</link>
      <description><![CDATA[运行 SelectKBest 后会选择一些特征，结果以数组形式返回，因此我不知道它们是什么特征，因为我的训练集有数千个特征。
我想在测试集中找到并挑选出这些特征，然后删除其余特征。有什么方便的方法吗？谢谢！
代码如下：
from sklearn.feature_selection import SelectKBest, f_regression
X_opt=SelectKBest(f_regression,k=2000)
X_new=X_opt.fit_transform(df_train_X_mm, train_y)
X_new`

结果如下：
array([[0. , 0. , 0. , ..., 0. , 0. ,
0. ],
[0. , 0. , 0.00688335, ..., 0. , 0. ,
0. ],
[0. , 0. , 0. , ..., 0. , 0. ,
0. ],
...,
[0. , 0. ，0. ，...，0. ，0. ，
0. ]，
[0. ，0. ，0. ，...，0. ，0. ，
0. ]，
[0. ，0. ，0.06257587，...，0. ，0. ，
0. ]])
]]></description>
      <guid>https://stackoverflow.com/questions/50942553/how-do-i-know-which-features-are-selected-with-selectkbest</guid>
      <pubDate>Wed, 20 Jun 2018 07:25:42 GMT</pubDate>
    </item>
    </channel>
</rss>