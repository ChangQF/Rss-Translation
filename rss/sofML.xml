<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 28 Jan 2024 03:13:58 GMT</lastBuildDate>
    <item>
      <title>CNN 图像分类奇怪的 Sigmoid 预测问题</title>
      <link>https://stackoverflow.com/questions/77893518/cnn-image-classification-weird-sigmoid-predictions-issue</link>
      <description><![CDATA[我正在使用 Tensorflow 开发机器学习神经网络模型，该模型可以识别一个人是否戴着口罩或未给出图像。请在进入 github 链接之前阅读其余部分（其中包含整个笔记本，以防模型本身出现问题）：文字
我的问题是，模型训练完成后（准确度为 96%，损失为 15%），预测输出一个奇怪的 sigmoid 值，远低于阈值 0.5，并且在使用图像的测试图像之间无关紧要戴口罩的人和不戴口罩的人。
如果这有帮助，这是使用 Tensorflow 函数的神经网络模型：
模型=顺序（[
    Conv2D(16, (3,3), 1, 激活=&#39;relu&#39;, input_shape = (256,256,3)),
    最大池化2D(),
    辍学率（0.25），

    Conv2D(32, (3,3), 1, 激活=&#39;relu&#39;),
    最大池化2D(),
    辍学率（0.25），

    Conv2D(16, (3,3), 1, 激活=&#39;relu&#39;),
    最大池化2D(),
    辍学率（0.25），

    展平（），

    密集（256，激活=&#39;relu&#39;），
    辍学（0.5），

    密集（1，激活=&#39;sigmoid&#39;）
]）

另外注：我对此很陌生，所以如果我需要修复一些更复杂的问题，请更深入地解释一下。
到目前为止我做了什么：
我首先认为这是过度拟合（仍然可能是），其中我的第一直觉是降低学习率。在这次修复之前，预测的 sigmoid 值在负数中使用了科学计数法，但后来他们冷静下来，恢复了不使用科学计数法。在其他人帮助我一点之后，我还添加了 Dropout 层，这也让 sigmoid 值平静了一点。然而，它们仍然不是正确的预测，并且它们小于 0.1，这不是 sigmoid 函数所期望的。
简而言之：
如果我能得到这方面的帮助，并能从这些帮助中学习，那就太好了。我希望我提供了必要的信息，但如果需要更多信息，请告诉我。
另外，如果可能的话，请下载存储库并亲自尝试预测。]]></description>
      <guid>https://stackoverflow.com/questions/77893518/cnn-image-classification-weird-sigmoid-predictions-issue</guid>
      <pubDate>Sun, 28 Jan 2024 02:58:25 GMT</pubDate>
    </item>
    <item>
      <title>yolov8 在训练后不会启动冻结：扫描</title>
      <link>https://stackoverflow.com/questions/77893385/yolov8-doesn%c2%b4t-initiate-freezes-after-train-scanning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77893385/yolov8-doesn%c2%b4t-initiate-freezes-after-train-scanning</guid>
      <pubDate>Sun, 28 Jan 2024 01:33:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 Roberta 计算上下文嵌入的正确方法是什么？</title>
      <link>https://stackoverflow.com/questions/77893035/what-is-the-correct-method-to-calculate-contextualized-embeddings-using-roberta</link>
      <description><![CDATA[我正在尝试使用 RobertaModel 计算上下文嵌入。不过，我不确定正确的做法，我尝试了两种方法，第一种方法如下：
从 Transformers 导入 RobertaModel、RobertaTokenizer
进口火炬

模型 = RobertaModel.from_pretrained(&#39;roberta-base&#39;)
tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;)

Captions = [“示例标题”,“七彩鸟”]

tokenized_captions = tokenizer(标题, return_tensors=&#39;pt&#39;, padding=True)

input_ids = tokenized_captions[&#39;input_ids&#39;]
注意掩码 = tokenized_captions[&#39;注意掩码&#39;]

输出=模型（input_ids，attention_mask）
contextualized_embedding = output.last_hidden_​​state

打印（上下文化嵌入）

第一种方法的输出：
张量([[[-0.0524, 0.0920, -0.0036, ..., -0.0810, -0.0577, -0.0343],
         [ 0.0383, -0.1632, 0.1182, ..., -0.3812, -0.1962, -0.0302],
         [-0.0504, 0.0927, -0.0312, ..., -0.1355, -0.0663, -0.0727],
         ...,
         [-0.0478, -0.1817, 0.1025, ..., -0.1187, -0.1293, -0.0288],
         [-0.0478, -0.1817, 0.1025, ..., -0.1187, -0.1293, -0.0288],
         [-0.0478, -0.1817, 0.1025, ..., -0.1187, -0.1293, -0.0288]],

输出包括填充标记的非零权重。对于第二种方法，代码本质上是相同的，区别在于 output 和 contextualized_embedding 行：
输出 = 模型(input_ids)
contextualized_embedding = output.last_hidden_​​state * Attention_mask.unsqueeze(-1).float()

第二种方法的输出：
张量([[[-0.0502, 0.0605, -0.0332, ..., -0.1521, -0.0830, -0.0196],
         [0.0178，-0.2104，0.1093，...，-0.5506，-0.2059，-0.0825]，
         [-0.0484, 0.0579, -0.0615, ..., -0.2082, -0.0855, -0.0473],
         ...,
         [ 0.0000, -0.0000, -0.0000, ..., -0.0000, -0.0000, 0.0000],
         [ 0.0000, -0.0000, -0.0000, ..., -0.0000, -0.0000, 0.0000],
         [ 0.0000, -0.0000, -0.0000, ..., -0.0000, -0.0000, 0.0000]],

在这种情况下，输出显示填充标记为零，我不确定正确的方法，任何人都可以帮我澄清这一点吗？]]></description>
      <guid>https://stackoverflow.com/questions/77893035/what-is-the-correct-method-to-calculate-contextualized-embeddings-using-roberta</guid>
      <pubDate>Sat, 27 Jan 2024 22:27:37 GMT</pubDate>
    </item>
    <item>
      <title>分割模型 (UNet) 验证指标中无法解释的振荡</title>
      <link>https://stackoverflow.com/questions/77892890/unexplained-oscillations-in-validation-metrics-for-segmentation-model-unet</link>
      <description><![CDATA[我目前正在训练分割模型 (UNet)，并且在验证指标中遇到了令人费解的行为。在训练过程中，训练损失持续下降，并且交并集（IoU）值稳步上升，这与我的预期相符。
然而，当我检查验证数据的指标时（见下图），我观察到了无法解释的强烈振荡。这种波动与训练指标中看到的整体改善趋势并不相符。我已经仔细检查了我的代码和超参数，但我仍然无法查明这些振荡的根本原因。
有人可以阐明验证指标可能表现出如此明显振荡的潜在原因吗？在模型训练的背景下解释验证结果时，我是否应该考虑常见的陷阱或因素？
当加载具有最高（平均）IoU（在验证数据上）的模型时，测试集上的结果非常好（IoU：0.805）。
我最近添加了一些更多的增强功能，因为我认为这是由于过度拟合，但这并没有解决（或减少）这种行为。
以下是指标图：
]]></description>
      <guid>https://stackoverflow.com/questions/77892890/unexplained-oscillations-in-validation-metrics-for-segmentation-model-unet</guid>
      <pubDate>Sat, 27 Jan 2024 21:32:47 GMT</pubDate>
    </item>
    <item>
      <title>在前向传递过程中，我不断收到“索引超出自身范围”的信息</title>
      <link>https://stackoverflow.com/questions/77892848/i-keep-getting-index-out-of-range-in-self-during-forward-pass</link>
      <description><![CDATA[我正在微调 Longformer 编码器解码器模型以进行多文档文本摘要。当我尝试进行前向传递时，它给我一个错误“索引超出自身范围”。输入形状似乎是正确的，但调试器指出 torch Embedding 中出现了问题。我该如何解决这个问题？
&lt;前&gt;&lt;代码&gt;num_epochs = 8
num_training_steps = num_epochs * len(train_dataloader)
优化器 = Adam(MODEL.parameters(), lr=3e-5)
lr_scheduler = get_scheduler(
    name=“线性”，optimizer=optimizer，num_warmup_steps=1，num_training_steps=num_training_steps # 稍后更改！！！！！！！
）
Progress_bar = tqdm(范围(num_training_steps))

# 训练模式
模型.train()

对于范围内的纪元（num_epochs）：
  对于batch_idx，批量枚举（train_dataloader）：

    # 编码数据
    input_ids_all = []
    对于批处理[“文档”]中的集群：
      文章 = cluster.split(“|||||”)[:-1]
      对于 i，枚举中的文章（文章）：
        文章 = 文章.replace(“\n”, “”)
        文章=“ ”.join(文章.split())
        文章[i] = 文章
      输入 ID = []
      对于文章中的文章：
        input_ids.extend(TOKENIZER.encode(article, truncation=True, max_length=4096 // len(articles))[1:-1])
        input_ids.append(DOCSEP_TOKEN_ID)
      input_ids = ([TOKENIZER.bos_token_id]+input_ids+[TOKENIZER.eos_token_id])
      input_ids_all.append(torch.tensor(input_ids))
      input_ids = torch.nn.utils.rnn.pad_sequence(input_ids_all,batch_first=True,padding_value=PAD_TOKEN_ID)

    # 前向传递
    global_attention_mask = torch.zeros_like(input_ids)
    全局注意力掩码[:, 0] = 1
    global_attention_mask[input_ids == DOCSEP_TOKEN_ID] = 1

    打印（input_ids.shape）
    # 输出 = MODEL.forward(input_ids) # &lt;---------------------------------------------------- -------------------------------------------------- ------ 导致错误
    输出 = MODEL.forward(input_ids=input_ids_all, global_attention_mask=global_attention_mask)

    # 反向传播
    损失 = 输出.损失
    loss.backward()

    # GD
    优化器.step()
    lr_scheduler.step()
    优化器.zero_grad()
    进度条.更新(1)

    # 解码输出
    generated_str = TOKENIZER.batch_decode（ generated_ids.tolist（），skip_special_tokens = True）
    metric.add_batch（预测= generated_str，引用=批[“摘要”]）

    # 计算指标
    print(f&quot;纪元: {epoch+1}, 批次: {batch_idx+1}:&quot;)
    打印（度量.计算（））
]]></description>
      <guid>https://stackoverflow.com/questions/77892848/i-keep-getting-index-out-of-range-in-self-during-forward-pass</guid>
      <pubDate>Sat, 27 Jan 2024 21:16:16 GMT</pubDate>
    </item>
    <item>
      <title>将拥抱脸部音频分类器转换为 TFLite 格式</title>
      <link>https://stackoverflow.com/questions/77892732/convert-hugging-face-audio-classifier-to-tflite-format</link>
      <description><![CDATA[我正在制作一个在 Android 手机上运行的模型，它将能够识别一组特定的音频命令。有 6 个命令，所以我需要一个包含 7 个类的分类器，每个命令一个，加上一个用于任何无法识别的类。
为此，我首先采用了 facebook/wav2vec2-base，并在每个命令类包含 1000 个示例的数据集上对其进行训练，另外还有 2000 个包含“无法识别”单词的示例。分类器表现出色。
TFLite 似乎是将模型移植到 Android 上的最佳方式，因此使用 optimization 将其导出为 TFLite 格式（optimum-cli export tflite --task audio-classification ...）。这并不容易，因为一开始它失败并出现错误 KeyError: “tflite 后端尚不支持 wav2vec2 (tf_wav2_vec2_for_sequence_classification)。仅支持 [&#39;onnx&#39;]。如果您想支持 tflite，请提出 PR 或提出问题。”。
最终我将其导出到 onnx，然后导出到 tf，最后导出到 TFLite。该模型太大，约 500MB，因此我使用动态量化将其缩小到约 100MB。整数量化确实搞乱了模型，所以我将其保留为动态量化。
我想将该模型与更简单的模型进行比较，但是 wav2vec2 没有任何“小”或“微小”变体。相反，我使用了 Whisper，它旨在用于 ASR（而非分类），使用 openai/whisper-tiny 变体。使用 transformers.WhisperForAudioClassification 加载它，因为分类是我的目标，并在同一数据集上对其进行了微调。尽管体积小得多（30MB），但它的性能优于第一个模型 - 太棒了。
尝试将此模型（用于分类的微调 Whisper 模型）导出到 TFLite 时出现问题：

直接导出到 TFLite（optimum-cli export tflite --task audio-classification ...）不起作用，因为任务 audio-classification 只能识别 Wav2Vec2。因此，将它用于 Whisper 模型会引发 ValueError: Unrecognized configuration class 对于这种 AutoModel：TFAutoModelForAudioClassification。模型类型应为 Wav2Vec2Config 之一。推测的解释：Whisper 本质上是 ASR，而不是分类器。
导出到 ONNX（optimum-cli export onnx --task audio-classification ...）不起作用，因为 ValueError：要求导出任务音频的耳语模型 -分类，但 Optimum ONNX 导出器仅支持特征提取、过去特征提取、自动语音识别、耳语自动语音识别等任务。请使用支持的任务。如果您希望 ONNX 导出耳语支持任务音频分类，请在 https://github.com/huggingface/optimum/issues 上提出问题。

对于如何让这个模型在 Android 上运行有什么建议吗？我是 Android 机器学习新手，所以也许我遗漏了一些明显的东西。我试图解释一些背景和迄今为止我所尝试的内容，并提供详细信息，以防有人提出实现我的目标的更好方法的建议。任何想法都非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/77892732/convert-hugging-face-audio-classifier-to-tflite-format</guid>
      <pubDate>Sat, 27 Jan 2024 20:36:25 GMT</pubDate>
    </item>
    <item>
      <title>机器学习平台[关闭]</title>
      <link>https://stackoverflow.com/questions/77892428/machine-learning-platforms</link>
      <description><![CDATA[我是 ML 世界的新手，但我一直在使用 Microsoft Azure 环境及其现成的模型训练、测试和部署环境。
我已经成功找到了预测模型的选项和算法：多个特征作为输入，单个变量作为输出。
例如，给定一个人的：(a) 工作范围、(b) 年龄、(c) 体重，我构建的系统能够预测（真/假）该人是否应该执行练习“E1”。 
现在，从技术上讲，人们可以训练 20 个与此类似的模型，并使用有关练习“E2”、“E3”等的“SINGLE”二进制输出。
但是，我觉得必须有一种更简单的方法。
这样，为了训练模型，我会为其提供一个 CSV 文件，每个场景/人一行：
第一人：“数据录入员”，24 岁，100 磅 ==&gt; E1 是，E2 否，E3 是
第二个人：“按摩师”，45岁，168磅==&gt; E1 是，E2 是，E3 否
等等...
我向亲爱的社区成员提出的问题是：
什么算法/环境最适合此类任务？ （也许 Microsoft Azure 不是最好的？）
请注意，我希望无需任何编码即可执行上述设置、培训、测试和部署。
我不介意未来所有这些的编码版本；但目前我喜欢学习在无代码环境中执行此操作。
提前非常感谢，
我第一次尝试 AzureMl，但无法通过使用 Azure ML 中的自动化 Ml 功能获得多输出预测模型。我最终部署了一个仅能够预测分类模型的目标值之一的模型。]]></description>
      <guid>https://stackoverflow.com/questions/77892428/machine-learning-platforms</guid>
      <pubDate>Sat, 27 Jan 2024 19:02:14 GMT</pubDate>
    </item>
    <item>
      <title>线性回归均方根误差</title>
      <link>https://stackoverflow.com/questions/77892345/linear-regression-rmse</link>
      <description><![CDATA[尝试比较不同多项式次数的均方根误差，但最终得到相同的 RMSE。
train_rmse_errors=[]
test_rmse_errors=[]
对于范围（1,20）内的 d：
poly_converter = PolynomialFeatures（度= d，include_bias = False）
poly_fearures = poly_converter.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(poly_features, y, test_size=0.33, random_state=42)
模型=线性回归()
model.fit(X_train,y_train)

train_pred = model.predict(X_train)
test_pred = model.predict(X_test)

train_rmse = np.sqrt(mean_squared_error(y_train,train_pred))
test_rmse = np.sqrt(mean_squared_error(y_test,test_pred))

train_rmse_errors.append(train_rmse)
test_rmse_errors.append(test_rmse)
]]></description>
      <guid>https://stackoverflow.com/questions/77892345/linear-regression-rmse</guid>
      <pubDate>Sat, 27 Jan 2024 18:38:33 GMT</pubDate>
    </item>
    <item>
      <title>在 Flask 框架中集成 ML 模型时似乎无法解决此错误</title>
      <link>https://stackoverflow.com/questions/77892140/cant-seem-to-solve-this-error-while-integrating-a-ml-model-in-a-flask-framework</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77892140/cant-seem-to-solve-this-error-while-integrating-a-ml-model-in-a-flask-framework</guid>
      <pubDate>Sat, 27 Jan 2024 17:33:27 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：使用高斯贝叶斯和高斯朴素贝叶斯对点进行分类时，操作数无法与形状 (1,13) (14,) 一起广播</title>
      <link>https://stackoverflow.com/questions/77892117/valueerror-operands-could-not-be-broadcast-together-with-shapes-1-13-14-wh</link>
      <description><![CDATA[我正在尝试对此数据集中的数据点进行分类：https: //sharon.srworkspace.com/ml/datasets/hw1/wine.data.csv。我几乎从头开始在 Python 中使用高斯贝叶斯和高斯朴素贝叶斯分类器。因此，在模型的训练测试拆分之后，我实现了这些函数来对数据点进行分类：
将 numpy 导入为 np
从 scipy.stats 导入 multivariate_normal

def Classify_point_gaussian_bayes(x):
    类 = np.unique(y)
    可能性= []
    
    对于类中的 c：
        类数据 = 数据[y == c]
        先验 = len(class_data) / len(数据)
        平均值 = np.mean(class_data, axis=0)
        cov = np.cov(class_data.T)
                
        可能性= multivariate_normal.pdf(x_reshape,mean=mean,cov=cov,allow_singular=True)
        likelihoods.append(先验 * 可能性)
    
    返回类别[np.argmax(可能性)]

def Classify_point_gaussian_naive_bayes(x):
    类 = np.unique(y)
    可能性= []
    
    对于类中的 c：
        类数据 = 数据[y == c]
        先验 = len(class_data) / len(数据)
        平均值 = np.mean(class_data, axis=0)
        var = np.var(class_data, 轴=0)
                
        可能性= multivariate_normal.pdf(x_reshape,mean=mean,cov=np.diag(var),allow_singular=True)
        likelihoods.append(先验 * 可能性)
    
    返回类别[np.argmax(可能性)]

然后我必须查看这两种方法的测试精度，我以这种形式进行：
&lt;前&gt;&lt;代码&gt;res = []
对于 idx，枚举中的 test_point(X_test.values)：
    res.append(classify_point_gaussian_bayes(test_point) == y_test[idx])
print(f&#39;高斯贝叶斯的测试精度为 {res.count(True)/len(res)}&#39;)

分辨率=[]
对于 idx，枚举中的 test_point(X_test.values)：
    res.append(classify_point_gaussian_naive_bayes(test_point) == y_test[idx])
print(f&#39;高斯朴素贝叶斯的测试精度为 {res.count(True)/len(res)}&#39;)

但我仍然遇到同样的错误：ValueError：操作数无法与形状 (1,13) (14,) 一起广播。
&lt;小时/&gt;
更具体地说：
ValueError Traceback（最近一次调用最后一次）
单元格 In[42]，第 3 行
      1 资源 = []
      2 对于 idx，enumerate(X_test.values) 中的 test_point：
----&gt; 3 res.append(classify_point_gaussian_bayes(test_point) == y_test[idx])
      4 print(f&#39;高斯贝叶斯的测试精度为 {res.count(True)/len(res)}&#39;)
      6 资源 = []

单元格 In[41]，第 21 行
     18 # 重塑 x 使其具有与平均值相同数量的特征
     19 x_reshape = x.reshape(1, -1)
---&gt; 21 可能性 = multivariate_normal.pdf(x_reshape,mean=mean,cov=cov,allow_singular=True)
     22likelihoods.append(先验*可能性)
     24 个返回类别[np.argmax(likelihoods)]

文件c：\ Users \ User \ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ scipy \ stats \ _multivariate.py：583，在multivariate_normal_gen.pdf（self，x，mean，cov，allow_singular）
    第581章
    第582章
--&gt;第583章
    第584章
    第585章

文件c：\ Users \ User \ AppData \ Local \ Programs \ Python \ Python311 \ Lib \ site-packages \ scipy \ stats \ _multivariate.py：526，在multivariate_normal_gen._logpdf（self，x，mean，cov_object）中
    507“”“”多元正态概率密度函数的对数。
    508
    第509章 参数
   （...）
    第523章
    第524章
    第525章
--&gt; 526 dev = x - 平均值
    第527章1：
    第528章

ValueError：操作数无法与形状 (1,13) (14,) 一起广播

由于这是一个关于尺寸的问题，我尝试在两个函数中使用此行调整函数作为参数的 x 数据点的大小：x_reshape = x.reshape(1, -1)甚至：x_reshape = x.reshape(-1)。
但它不起作用，仍然给我带来与上面相同的错误。]]></description>
      <guid>https://stackoverflow.com/questions/77892117/valueerror-operands-could-not-be-broadcast-together-with-shapes-1-13-14-wh</guid>
      <pubDate>Sat, 27 Jan 2024 17:26:09 GMT</pubDate>
    </item>
    <item>
      <title>使用 Torchio 对两个图像应用完全相同的变换</title>
      <link>https://stackoverflow.com/questions/77892019/apply-the-exact-same-transformation-to-two-images-using-torchio</link>
      <description><![CDATA[我想使用 torchio 对两个图像（图像和分割数据）应用完全相同的转换。这两个图像都存储在名为 image_data 和 segmentation_data 的 numpy 数组中。
到目前为止，我添加了一些增强功能：
self.augmentations = tio.Compose([
            仿射变换，
            弹性变换，
            翻转变换，
            交换变换
        ]）

例如， elastic_transform = tio.RandomElasticDeformation 并尝试通过以下方式将它们应用到图像：
 subject_image = tio.Subject(image=tio.ScalarImage(tensor=image_data))
        subject_segmentation = tio.Subject(
            图像=tio.ScalarImage(张量=segmentation_data))
        数据集 = tio.SubjectsDataset([subject_image, subject_segmentation])
        数据集 = self.augmentations(数据集)
        image_data = 数据集[0][&#39;image&#39;].data
        分段数据 = 数据集[1][&#39;图像&#39;].data

不幸的是，这是不正确的（因为 Compose 无法与主题数据集一起使用），但我找不到任何有关如何正确执行此操作的信息。有人可以帮忙吗？]]></description>
      <guid>https://stackoverflow.com/questions/77892019/apply-the-exact-same-transformation-to-two-images-using-torchio</guid>
      <pubDate>Sat, 27 Jan 2024 16:57:43 GMT</pubDate>
    </item>
    <item>
      <title>我有我的自定义训练模型（best.pt），它检测人和车头灯两件事。现在我想要根据这些条件输出</title>
      <link>https://stackoverflow.com/questions/77891961/i-have-my-custom-trained-model-best-pt-it-detects-two-things-person-and-headl</link>
      <description><![CDATA[你能帮我一下吗......
我有我的自定义训练模型（best.pt），它检测人和车头灯两件事。现在我想要根据以下条件输出： 1. 如果模型仅检测到车头灯返回 0, 2. 如果模型仅检测到人返回 1, 3. 如果模型检测到车头灯和人都返回 0。
&lt;前&gt;&lt;代码&gt;导入cv2
从 ultralytics 导入 YOLO

video_path = &#39;数据/video1.mp4&#39;
video_out_path = &#39;输出.mp4&#39;

cap = cv2.VideoCapture(video_path)

# 检查视频文件是否打开成功
如果不是 cap.isOpened():
    print(“错误：无法打开视频文件。”)
    出口（）

ret, 框架 = cap.read()

# 检查第一帧是否读取成功
如果不转：
    print(“错误：无法读取视频的第一帧。”)
    出口（）

cap_out = cv2.VideoWriter(video_out_path, cv2.VideoWriter_fourcc(*&#39;MP4V&#39;), cap.get(cv2.CAP_PROP_FPS),
                          (int(cap.get(3)), int(cap.get(4)))) # 使用 cap.get(3) 和 cap.get(4) 获取宽度和高度

模型 = YOLO(“bestall5.pt”)

检测阈值 = 0.5
休息时：
    结果列表=模型（框架）

    检测到头灯=假
    检测到的人=假

    # 遍历结果列表
    对于 results_list 中的结果：
        # 检查当前结果是否具有必要的属性
        if hasattr(结果, &#39;xyxy&#39;):
            对于 results.xyxy 中的结果：
                x1, y1, x2, y2, 分数, class_id = result.tolist()
                x1, x2, y1, y2 = int(x1), int(x2), int(y1), int(y2)

                # 假设class_id是模型类列表中类的索引
                类名=模型.名称[类id]

                if class_name == “车头灯”且分数&gt;检测阈值：
                    检测到头灯=真
                elif class_name == &quot;人&quot;;且分数&gt;检测阈值：
                    检测到的人 = True

    # 根据指定条件输出
    如果检测到头灯和检测到人：
        输出=0
    elif headlight_Detected：
        输出=0
    elif person_Detected：
        输出=1
    别的：
        输出 = -1 # 未检测到人或前灯

    print(“输出：”, 输出)

    cap_out.write(帧)

    cv2.imshow(&#39;物体检测&#39;,frame)
    
    # 如果按下“q”键则中断循环
    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
        休息

    ret, 框架 = cap.read()

cap.release()
cap_out.release()
cv2.destroyAllWindows()

我尝试了这个，但只得到 -1 作为输出，但我的视频既有车头灯又有人]]></description>
      <guid>https://stackoverflow.com/questions/77891961/i-have-my-custom-trained-model-best-pt-it-detects-two-things-person-and-headl</guid>
      <pubDate>Sat, 27 Jan 2024 16:40:44 GMT</pubDate>
    </item>
    <item>
      <title>使用 sympy 时消除格式字符串冲突</title>
      <link>https://stackoverflow.com/questions/77891386/get-rid-of-format-string-conflict-when-using-sympy</link>
      <description><![CDATA[我正在学习用于机器学习的 Python 编码。当我尝试使用 sympy 求损失函数的导数时，它会与格式字符串发生冲突。
将 numpy 导入为 np
将 sympy 导入为 sp

def 预测（X，w，b）：
    返回 np.dot(X, w) + b

def 损失(X, w, b, Y):
    返回 np.mean((预测(X, w, b) - Y) ** 2)

X, Y = np.loadtxt(“code/02_first/pizza.txt”，unpack=True，skiprows=1)

# 将 X 和 Y 转换为 sympy 符号
X, w, b, Y = sp.symbols(“X w b Y”)

def 梯度(X, w, b, Y):
    loss_expr = 损失(X, w, b, Y)
    dw_dX = sp.diff(loss_expr, w)
    db_dX = sp.diff(loss_expr, b)
    返回 dw_dX, db_dX

def train(X, Y, 迭代, lr):
    w = sp.symbols(&#39;w&#39;)
    b = sp.symbols(&#39;b&#39;)
    
    对于范围内的 i（迭代）：
        损失值 = 损失(X, w, b, Y)
        print(f&quot;迭代: {i:4d}, 损失: {loss_value:.10f}&quot;)
        dw_dX, db_dX = 梯度(X, w, b, Y)
        w -= dw_dX * lr
        b -= db_dX * lr
    返回w,b

w, b = 训练(X, Y, 迭代=20000, lr=0.001)

print(f&quot;\nw = {w:.10f}, b = {b:.10f}&quot;)
print(f&quot;预测: x = 20 ==&gt; y = {predict(20, w, b):.2f}&quot;)

类型错误：传递给 Pow.__format__ 的格式字符串不受支持

数据以 txt 形式存在（或通过链接此处&lt; /a&gt;):
预订披萨
13 33
2 16
14 32
23 51
13 27
1 16
18 34
10 17
26 29
3 15
3 15
21 32
7月22日
22 37
2 13
27 44
6 16
10 21
18 37
15 30
9 26
26 34
8月23日
15 39
10 27
21 37
5 17
6 18
13 25
13 23

我可以只使用numpy，但这样做我需要自己计算损失函数，这不是有效的（并且很容易用括号引发错误）。
如果您能解释该错误以及为什么 sympy 与格式字符串不兼容，我们将不胜感激。另外，如何使用 sympy 生成正确的脚本？
提前非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77891386/get-rid-of-format-string-conflict-when-using-sympy</guid>
      <pubDate>Sat, 27 Jan 2024 13:35:43 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：编译神经网络进行情感分析时，模块“keras.src.backend”没有属性“floatx”</title>
      <link>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</link>
      <description><![CDATA[从tensorflow.keras.models导入顺序
从tensorflow.keras导入层

# 设置嵌入维度
嵌入尺寸 = 100

# 创建模型
模型=顺序（[
    层.Embedding(max_words, embedding_dim, input_length=max_length),
    层.LSTM(64),
    层.Dense(1, 激活=&#39;sigmoid&#39;)
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

# 打印模型摘要
打印（模型.摘要（））

我尝试使用 Jupyter Notebook (.ipynb) 在 VSCode 中编译上述模型，但遇到以下错误：
AttributeError：模块“keras.src.backend”没有属性“floatx”
最初，我成功地编译了模型，但在拟合模型时导致 VScode 崩溃。重新加载 VSCode 后，我收到此错误。
为了解释上下文，我正在尝试构建一个非常基本的 NLP 模型，以根据情绪对亚马逊评论进行分类。我也在使用 Python 3.11 和 Tensorflow 版本 2.15
首先我尝试了以下方法：
导入keras.backend为K
K.set_floatx(&#39;float32&#39;)

但是我遇到了同样的错误。然后我尝试重置 VSCode 并再次运行笔记本，但仍然遇到相同的错误？]]></description>
      <guid>https://stackoverflow.com/questions/77890079/attributeerror-module-keras-src-backend-has-no-attribute-floatx-when-compil</guid>
      <pubDate>Sat, 27 Jan 2024 04:41:13 GMT</pubDate>
    </item>
    <item>
      <title>如何解决“无法将类强制到data.frame？”</title>
      <link>https://stackoverflow.com/questions/58870663/how-to-solve-cannot-coerce-class-to-data-frame</link>
      <description><![CDATA[第 20 行出现问题：x3 &lt;- lm(Salary ~ ...

&lt;块引用&gt;
  as.data.frame.default(data) 中的错误：无法将类‘c(&quot;train&quot;, &quot;train.formula&quot;)’强制转换为 data.frame

如何解决？
附加（击球手）
击球手

库（插入符号）
设置.种子(123)
# 定义训练控制
设置.种子(123)
train.control &lt;- trainControl(method = &quot;cv&quot;, number = 10)
# 训练模型
x2 &lt;- 训练（工资〜.，数据= x，方法=“lm”，
               trControl = 训练.control)
# 总结结果
打印（x）
x3 &lt;- lm(工资 ~ poly(AtBat,3) + poly(Hits,3) + poly(Walks,3) + poly(CRuns,3) + poly(CWalks,3) + poly(PutOuts,3),数据 = x2)
摘要(x3)
MSE = 均值(x3$残差^2)
print(&quot;均方误差：&quot;)
打印（MSE）
]]></description>
      <guid>https://stackoverflow.com/questions/58870663/how-to-solve-cannot-coerce-class-to-data-frame</guid>
      <pubDate>Fri, 15 Nov 2019 05:09:08 GMT</pubDate>
    </item>
    </channel>
</rss>