<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 30 Jan 2025 15:17:11 GMT</lastBuildDate>
    <item>
      <title>模仿单个个体的合成数据</title>
      <link>https://stackoverflow.com/questions/79400139/synthetic-data-whic-mimics-a-single-individual</link>
      <description><![CDATA[传统 GAN 生成的合成数据集与原始数据集来自同一分布。是否有任何实例可以使用整个数据集中的单个样本来创建唯一的合成数据样本？]]></description>
      <guid>https://stackoverflow.com/questions/79400139/synthetic-data-whic-mimics-a-single-individual</guid>
      <pubDate>Thu, 30 Jan 2025 13:56:09 GMT</pubDate>
    </item>
    <item>
      <title>Whisper 模型实时端点容器部署在 Azure ML 上失败</title>
      <link>https://stackoverflow.com/questions/79399452/whisper-model-real-time-endpoint-container-deployment-failed-on-azure-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79399452/whisper-model-real-time-endpoint-container-deployment-failed-on-azure-ml</guid>
      <pubDate>Thu, 30 Jan 2025 09:50:51 GMT</pubDate>
    </item>
    <item>
      <title>在使用 YOLO v8 DETECT TRAIN 进行对象检测时，如何在每个时期提取验证集上的预测？</title>
      <link>https://stackoverflow.com/questions/79398928/how-to-extract-the-predictions-on-the-validation-set-at-each-epoch-when-using-y</link>
      <description><![CDATA[我使用的是 yolo 模型 yolov8l.pt 的 CLI 版本（可通过下面的 WEIGHTS 参数访问）：
!yolo detect train model={WEIGHTS} data=&#39;data/tvt3_data_v8.yaml&#39; single_cls imgsz={IMG_SIZE} batch={BATCH_SIZE} epochs={3}

当前工作原理
在训练期间，在每个时期：

计算训练损失
计算验证损失和验证召回率、准确率和 mAP

在训练结束时，选择最佳 .pt 模型并在验证集上进行评估。
我需要从脚本中获得什么
在每个epoch，我想提取在 VALIDATION 数据集上做出的预测
我该怎么做？]]></description>
      <guid>https://stackoverflow.com/questions/79398928/how-to-extract-the-predictions-on-the-validation-set-at-each-epoch-when-using-y</guid>
      <pubDate>Thu, 30 Jan 2025 06:02:26 GMT</pubDate>
    </item>
    <item>
      <title>dsac_tools（使用 pytorch 计算本质矩阵）计算问题</title>
      <link>https://stackoverflow.com/questions/79398453/dsac-toolscalculate-essential-matrix-using-pytorch-computational-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79398453/dsac-toolscalculate-essential-matrix-using-pytorch-computational-problem</guid>
      <pubDate>Wed, 29 Jan 2025 23:36:30 GMT</pubDate>
    </item>
    <item>
      <title>具有 40,000 个状态和 81 个动作的 Q 学习是否可行？</title>
      <link>https://stackoverflow.com/questions/79398056/is-q-learning-feasible-with-40-000-states-and-81-actions</link>
      <description><![CDATA[我正在使用 Q-learning 解决一个问题，其中状态数为 40,000，操作数为 81，因此 Q 表大小为 3,240,000 个条目。使用 Q-learning 处理如此大的数据集是否可行，还是需要额外的技术来优化学习过程？]]></description>
      <guid>https://stackoverflow.com/questions/79398056/is-q-learning-feasible-with-40-000-states-and-81-actions</guid>
      <pubDate>Wed, 29 Jan 2025 20:01:22 GMT</pubDate>
    </item>
    <item>
      <title>在 GPU 上进行 PyWavelets 计算</title>
      <link>https://stackoverflow.com/questions/79396894/doing-pywavelets-calculation-on-gpu</link>
      <description><![CDATA[目前正在使用 PyWavelets 进行分类器工作，这是我的计算块：
class WaveletLayer(nn.Module):
def __init__(self):
super(WaveletLayer, self).__init__()

def forward(self, x):
def wavelet_transform(img):
coeffs = pywt.dwt2(img.cpu().numpy(), &quot;haar&quot;)
LL, (LH, HL, HH) = coeffs
return (
torch.from_numpy(LL).to(img.device),
torch.from_numpy(LH).to(img.device),
torch.from_numpy(HL).to(img.device),
torch.from_numpy(HH).to(img.device),
)

# 将小波变换分别应用于每个通道
LL, LH, HL, HH = zip(
*[wavelet_transform(x[:, i : i + 1]) for i in range(x.shape[1])]
)

# 连接结果
LL = torch.cat(LL, dim=1)
LH = torch.cat(LH, dim=1)
HL = torch.cat(HL, dim=1)
HH = torch.cat(HH, dim=1)

return torch.cat([LL, LH, HL, HH], dim=1)


此模块的输出将进入 resnet 块进行学习，在此过程中，我发现 CPU 堵塞，从而减慢了训练过程
我正在尝试使用 GPU 进行这些计算。]]></description>
      <guid>https://stackoverflow.com/questions/79396894/doing-pywavelets-calculation-on-gpu</guid>
      <pubDate>Wed, 29 Jan 2025 13:26:29 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Spark 中重现 ML 模型的结果？[重复]</title>
      <link>https://stackoverflow.com/questions/79396752/how-to-reproduce-the-results-of-an-ml-model-in-spark</link>
      <description><![CDATA[我正在 Spark (Pyspark) 中创建一个机器学习模型（随机森林），并进行交叉验证和网格搜索。我有两个数据框：一个用于训练，一个用于测试，均存储在 Parquet 中。
在运行整个管道进行模型的训练和验证以及测试后，我确认实验的可重复性无法得到保证，也就是说，即使在所有允许此参数的函数中为“种子”定义一个固定值，在创建新的 Spark 会话并重新运行管道时，我也无法获得完全相同的结果。
使用不同的数据库执行此测试，我确认在某些情况下，在某些执行中可以获得相同的混淆矩阵，但分数不一样，交叉验证结果（AUC ROC）也不一样。代码总是一样的。相同的 Spark 配置。这对决策树、随机森林和梯度提升都有效。这些模型通过精度、召回率、f1 分数、准确率、auc roc 和 auc pr 进行了评估，并被证明是非确定性的。
我的问题是：如何确保在两次或多次执行模型管道的相同代码时，我可以获得相同的结果？如果不可能，为什么不可能？
我为所有允许使用它的函数定义了一个固定种子。
我重复执行了几十次，始终使用相同的数据、相同的设置和相同的测试参数。
以下是实验的片段：
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator

# spark session

# read dataframe training_data

random_forest = RandomForestClassifier(seed=42, labelCol=&quot;label&quot;, featuresCol=&quot;features&quot;)

param_grid = ParamGridBuilder()\
.addGrid(random_forest.numTrees, [10, 50])\
.addGrid(random_forest.maxDepth, [5, 10])\
.build()

evaluator = BinaryClassificationEvaluator(metricName=&quot;areaUnderROC&quot;, labelCol=&quot;label&quot;)

cross_validator = CrossValidator(estimator=random_forest, 
estimatorParamMaps=param_grid, 
evaluator=evaluator, 
numFolds=5, 
seed=42)

cv_model = cross_validator.fit(training_data)

best_model = cv_model.bestModel

predictions = best_model.transform(test_data)
predictions.select(&quot;features&quot;, &quot;label&quot;, &quot;probability&quot;, &quot;prediction&quot;).show()

auc_roc = evaluator.evaluate(best_model.transform(test_data))

print(&quot;AUC-ROC:&quot;, auc_roc)
]]></description>
      <guid>https://stackoverflow.com/questions/79396752/how-to-reproduce-the-results-of-an-ml-model-in-spark</guid>
      <pubDate>Wed, 29 Jan 2025 12:40:12 GMT</pubDate>
    </item>
    <item>
      <title>使用输入层作为第二个输入层的权重</title>
      <link>https://stackoverflow.com/questions/79396213/using-an-input-layer-as-a-weight-to-a-second-input-layer</link>
      <description><![CDATA[我有两个输入结构，其中第二个输入中的每个特征都使用输入 1 的值来计算每个特征。然后，第二个输入层连接到隐藏层，最后连接到单个输出层。因此，假设我在第一个输入中有 A、B、C，在第二个输入中有 G M N O，其中例如 G 被计算为总和（A 到 C），并且 G M N O 连接到隐藏层。如何使用 tensorflow keras 实现这一点？ G M N O 是连接到隐藏层的输入层。
input_elements = Input(shape=(4,), name=&quot;Elemental_Composition&quot;)
input_descriptors = Input(shape=(7,), name=&quot;Descriptors&quot;)

combined = concatenate([input_elements, input_descriptors])
hidden = Dense(64,activation=&quot;relu&quot;)(combined)
output = Dense(1,activation=&quot;linear&quot;)(hidden)
]]></description>
      <guid>https://stackoverflow.com/questions/79396213/using-an-input-layer-as-a-weight-to-a-second-input-layer</guid>
      <pubDate>Wed, 29 Jan 2025 09:17:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用“tf.data.Dataset.save”将数据集保存在多个分片中</title>
      <link>https://stackoverflow.com/questions/79395477/how-to-save-a-dataset-in-multiple-shards-using-tf-data-dataset-save</link>
      <description><![CDATA[如何使用 tf.data.Dataset.save() 将 tf.data.Dataset 保存到多个分片中？我正在使用 tf.data.experimental.make_csv_dataset 从 CSV 读取我的数据集。
此处的 TF 文档 不是很有用。有一个 shard_func 参数，但给出的示例没有帮助，并且不清楚如何以确定性方式映射到 int。使用随机 int 似乎也不起作用。
类似问题 此处 中的解决方案为我生成了一个错误
TypeError：不支持 % 的操作数类型：&#39;collections.OrderedDict&#39; 和 &#39;int&#39;
单分片（有效）
以下成功保存到单个分片。
import pandas as pd
import numpy as np
import tensorflow as tf

# gen data
n=10000
pd.DataFrame(
{&#39;label&#39;: np.random.randint(low=0, high=2, size=n),
&#39;f1&#39;: np.random.random(n),
&#39;f2&#39;: np.random.random(n),
&#39;f3&#39;: np.random.random(n),
&#39;c1&#39;: np.random.randint(n),
&#39;c2&#39;: np.random.randint(n)}
).to_csv(&#39;tmp.csv&#39;)
# 将数据加载到 tf.data.Dataset
data_ts = tf.data.experimental.make_csv_dataset(
&#39;tmp.csv&#39;, 1, label_name=&#39;label&#39;, num_epochs=1)
data_ts.save(&#39;tmp.data&#39;) # 单个分片，有效！

使用 randint 的多个分片（保存单个分片）
尝试使用随机数保存到多个分片，仍然只保存到单个分片，尽管文件名中有一个随机整数。
# 尝试使用随机数进行分片。
def random_shard_function(features, label):
return np.int64(np.random.randint(10))
data_ts.save(&#39;tmp2.data&#39;, shard_func=random_shard_function)



Modulo shard（错误）
尝试这个解决方案问题。
def modulo_shard_function(features, label):
return x &amp; 10
data_ts.save(&#39;tmp2.data&#39;, shard_func=modulo_shard_function)

TypeError: &amp; 不支持的操作数类型：&#39;collections.OrderedDict&#39; 和 &#39;int&#39;
调试 - 不知道 shard_fun 如何工作。
如果我打印出输入，似乎分片函数只运行一次，张量是 SymbolicTensors
def debug_shard_function(features, label):
for val in features.items():
print(f&#39;{val=}&#39;)
print(f&#39;{label=}&#39;)
print(f&#39;{type(val[1])}&#39;)
return np.int64(10)
data_ts.save(&#39;tmp2.data&#39;, shard_func=debug_shard_function)

输出：
仍然保存到单个分片
val=(&#39;&#39;, &lt;tf.Tensor &#39;args_0:0&#39; shape=(None,) dtype=int32&gt;)
val=(&#39;f1&#39;, &lt;tf.Tensor &#39;args_3:0&#39; shape=(None,) dtype=float32&gt;)
val=(&#39;f2&#39;, &lt;tf.Tensor &#39;args_4:0&#39; shape=(None,) dtype=float32&gt;)
val=(&#39;f3&#39;, &lt;tf.Tensor &#39;args_5:0&#39; shape=(None,) dtype=float32&gt;)
val=(&#39;c1&#39;, &lt;tf.Tensor &#39;args_1:0&#39; shape=(None,) dtype=int32&gt;)
val=(&#39;c2&#39;, &lt;tf.Tensor &#39;args_2:0&#39; shape=(None,) dtype=int32&gt;)
label=&lt;tf.Tensor &#39;args_6:0&#39; shape=(None,) dtype=int32&gt;
&lt;class &#39;tensorflow.python.framework.ops.SymbolicTensor&#39;&gt;
]]></description>
      <guid>https://stackoverflow.com/questions/79395477/how-to-save-a-dataset-in-multiple-shards-using-tf-data-dataset-save</guid>
      <pubDate>Wed, 29 Jan 2025 00:08:54 GMT</pubDate>
    </item>
    <item>
      <title>自定义字母表的文本识别</title>
      <link>https://stackoverflow.com/questions/79394460/text-recogniton-for-custom-alphabet</link>
      <description><![CDATA[我有一个虚构的字母表，由大约 20 种形状和字母组成，它们与希腊字母和西里尔字母相似。
它们是作为资产生成的，我为它们每个都制作了 30 x 30 的图像。我想创建一个特殊的图像处理工具来实时翻译它们。
它们总是打印在黑色多边形上。
所以我尝试使用通用 opencv2 方法使用黑色多边形进行检测，并且成功了。
为了扫描和检测字母，我尝试了 ORB 特征提取和匹配，但没有成功。由于相似的符文形状，它在整个字母中都发现了特征。
我曾尝试使用 Yolo11 训练对象检测模型，但由于数据量少（我没有已打印的示例，我尝试生成具有不同角度的模拟图像），它成本高且表现不佳。
我没有足够的数据来训练 HOG。
是否有一个简单的 Python 模式匹配算法，可以考虑现实生活中相机的小倾斜平移和滚动，因此仍然可以检测字母？
编辑 -&gt;
以下是我拥有的一些字母示例

]]></description>
      <guid>https://stackoverflow.com/questions/79394460/text-recogniton-for-custom-alphabet</guid>
      <pubDate>Tue, 28 Jan 2025 16:02:10 GMT</pubDate>
    </item>
    <item>
      <title>如何从接地恐龙的预测函数中提取边界框坐标？</title>
      <link>https://stackoverflow.com/questions/79393871/how-to-extract-bounding-box-coordinates-from-grounding-dinos-predict-function</link>
      <description><![CDATA[预测函数返回的框似乎不是规范化的形式，即使与图像宽度和高度相乘后，我也无法获得边界框的坐标。
import torch
from groundingdino.util.inference import load_model, load_image, predict, annotate
import cv2

# 加载模型
model = load_model(&quot;../GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py&quot;,
&quot;../GroundingDINO/weights/groundingdino_swint_ogc.pth&quot;)
IMAGE_PATH = &quot;.asset/cat_dog.jpeg&quot;
TEXT_PROMPT = &quot;person . animal . bird . object&quot;
BOX_THRESHOLD = 0.35
TEXT_THRESHOLD = 0.25

# 加载图像
image_source, image = load_image(IMAGE_PATH)

# 执行预测
boxes, logits, phrases = predict(
model=model,
image=image,
caption=TEXT_PROMPT,
box_threshold=BOX_THRESHOLD,
text_threshold=TEXT_THRESHOLD
)

# 获取图像尺寸
ht, wd = image_source.shape[:2]
print(ht, wd, image_source.shape[:2])

# 将边界框转换为绝对坐标
abs_box = boxes * torch.tensor([wd, ht, wd, ht])
abs_box = [abs_bo.numpy().astype(&quot;int&quot;) for abs_bo in abs_box]

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

for abs_bo in abs_box:
cv2.rectangle(annotated_frame, (abs_bo[0], abs_bo[1]),[![enter image description here][1]][1] (abs_bo[2], abs_bo[3]), (255, 0, 0), 2)

cv2.imwrite(&quot;annotated_image.jpg&quot;, annotated_frame)



蓝色框由“绝对”坐标，任何关于如何操作返回的数据以获得绝对坐标的见解都将非常有帮助，谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/79393871/how-to-extract-bounding-box-coordinates-from-grounding-dinos-predict-function</guid>
      <pubDate>Tue, 28 Jan 2025 12:45:28 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 分类器中获取属性错误</title>
      <link>https://stackoverflow.com/questions/79374019/getting-attribute-error-in-keras-classifier</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79374019/getting-attribute-error-in-keras-classifier</guid>
      <pubDate>Tue, 21 Jan 2025 10:21:29 GMT</pubDate>
    </item>
    <item>
      <title>无法访问自由变量“fig”，因为它与封闭范围内的值没有关联</title>
      <link>https://stackoverflow.com/questions/79270292/cannot-access-free-variable-fig-where-it-is-not-associated-with-a-value-in-enc</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79270292/cannot-access-free-variable-fig-where-it-is-not-associated-with-a-value-in-enc</guid>
      <pubDate>Wed, 11 Dec 2024 02:04:10 GMT</pubDate>
    </item>
    <item>
      <title>训练损失随着训练次数的增加而不减少</title>
      <link>https://stackoverflow.com/questions/73811288/training-loss-increases-instead-of-decrease-with-epochs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/73811288/training-loss-increases-instead-of-decrease-with-epochs</guid>
      <pubDate>Thu, 22 Sep 2022 08:10:36 GMT</pubDate>
    </item>
    <item>
      <title>Pyspark 错误-在 pandas_udf 内部实现时参数无效，不是字符串或列</title>
      <link>https://stackoverflow.com/questions/73032656/pyspark-error-invalid-argument-not-a-string-or-column-while-implementing-insi</link>
      <description><![CDATA[此代码在 pandas_udf 之外运行良好，但在尝试在 udf 内部实现相同代码时出现此错误。为了避免 pyspark 和 python 函数名称之间的冲突，我已明确从 pyspark 导入特定函数。使用 fuzzywuzzy 进行字符串匹配，并使用 nltk 根据 ngram 技术将字符串划分为子字符串。这段代码在没有 udf 的情况下运行时间太长，所以决定使用 pandas_udf，但不知道为什么会出现这个错误。
import json
from pyspark.sql.types import StringType, StructField, StructType
from pyspark.sql.functions import pandas_udf, PandasUDFType

from nltk.util import ngrams, everygrams
from fuzzywuzzy import process, fuzz

model_results_schema = StructType(
[StructField(&quot;Output&quot;, StringType(), True)]
)

@pandas_udf( model_results_schema, PandasUDFType.GROUPED_MAP )
def get_ccep_results( model_input ):

def ngram_filter(list1, list2):
sorted_list1 = sorted(list1, key = lambda a: (a[1], len(a[0])), reverse =True)
sorted_list2 = sorted(list2, key = lambda a: (a[1], len(a[0])), reverse =True)
rslt1 =list(filter(lambda t: t[1]&gt;58, sorted_list1))#根据需求改变阈值
rslt2 =list(filter(lambda t: t[1]&gt;58, sorted_list2))#根据需求改变阈值
if len(rslt1)!=0:
a = rslt1[0][0]
else:
a =&#39;&#39;
if len(rslt2)!=0:
b = rslt2[0][0]
else:
b =&#39;&#39;
return a, b

def ngram_fuzzy_match(n_gram, attribute):
list_res=[]
for i in n_gram:
r = process.extract(i, attribute)
list_res.append(r)
flat_list = [x for xs in list_res for x in xs] 
sorted_list = sorted(flat_list,key = lambda x: x[1], reverse=True )
list_br =[]
for j in attribute:
p = process.extract(j, n_gram)
list_br.append(p)
flat_list1 = [x for xs in list_br for x in xs] 
sorted_list1 = sorted(flat_list1,key =lambda x: x[1] , reverse=True )
attribute_value, n_gram_value = ngram_filter(flat_list, flat_list1)
return attribute_value, n_gram_value

def ngrams_prod_desc(prod_desc, internal_att_list):
prod_desc_temp = prod_desc
temp_dict ={x:[] for x in range(0,len(internal_att_list))}
for ind, x in enumerate(internal_att_list):

list1 = list(everygrams(prod_desc_temp.split())) #为每个描述创建 n-gram
res = [&#39; &#39;.join(tups) for tups in list1]
if len(res)!=0:
r,ngram_candidate = ngram_fuzzy_match(res, x) #此函数执行 n-gram 和之间的模糊匹配属性

temp_dict[ind].append(r) # 此处出错
prod_desc_temp=prod_desc_temp.replace(ngram_candidate, &#39;&#39;).strip()
else:
temp_dict[ind].append(None)

return json.dumps(temp_dict)

dictionary = model_input[&#39;cleaned_external&#39;].apply(lambda x: ngrams_prod_desc(x, attribute_list))
result = pd.DataFrame([dictionary])

return result

model_output = (frame_combined.groupby([&#39;prod_id&#39;]).apply(get_ccep_results)) # 此处出错

frame_combined -

更新 -
尝试了这个并得到异常 -

try:
model_output = (frame_combined.groupby([&#39;prod_id&#39;]).apply(get_ccep_results))
except Exception as e:
print(e)
]]></description>
      <guid>https://stackoverflow.com/questions/73032656/pyspark-error-invalid-argument-not-a-string-or-column-while-implementing-insi</guid>
      <pubDate>Tue, 19 Jul 2022 07:18:33 GMT</pubDate>
    </item>
    </channel>
</rss>