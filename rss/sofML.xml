<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 26 Jan 2024 00:58:06 GMT</lastBuildDate>
    <item>
      <title>在Python中应用kmeans后如何存储300个图像文件？</title>
      <link>https://stackoverflow.com/questions/77883689/how-to-store-300-image-files-after-applying-kmeans-in-python</link>
      <description><![CDATA[我正在开发一个链接的项目&lt;a href=&quot;https://stackoverflow.com/questions/77857949/how-to-convert-numpy-array-to-polars-dataframe-with-multiple-outputs ”在这里&lt;/a&gt;。我正在运行 K 均值算法，但它没有加载到 Polars 数据框中。我尝试使用 Intel scikit-learn 软件包，这减少了小样本的时间。对于完整的数据集，我的内存不足。我尝试使用列表，并且能够加载到 pickle 文件（使用 pandas），但它是 6 GB。看来我需要使用数据库。是否有任何适用于 Python 的 Postgres 数据库包示例对此处使用有帮助？我想在算法运行后对每组图像使用某种类型的流式传输或转储以避免内存问题。我的笔记本电脑上还有 8GB NVIDIA 1650，但无法让 Intel scikit-learn 包工作（GPU 选项）。如果我能够从 GPU 的速度和数据库的内存分配中获益，那将会很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77883689/how-to-store-300-image-files-after-applying-kmeans-in-python</guid>
      <pubDate>Fri, 26 Jan 2024 00:49:55 GMT</pubDate>
    </item>
    <item>
      <title>“java.lang.IllegalArgumentException：字节缓冲区的大小和形状不匹配。” - 但他们确实</title>
      <link>https://stackoverflow.com/questions/77883608/java-lang-illegalargumentexception-the-size-of-byte-buffer-and-the-shape-do-no</link>
      <description><![CDATA[我正在尝试使用 Android Studio 中的以下代码将 ML 模型集成到 Android 应用中：
predictBtn.setOnClickListener(new View.OnClickListener() {
            @覆盖
            公共无效onClick（查看视图）{
                尝试 {
                    ModelUnquant 模型 = ModelUnquant.newInstance(MainActivity.this);


                    // 检查位图是否不为空
                    if (位图！= null) {
                        // 创建输入以供参考。
                        TensorBuffer inputFeature0 = TensorBuffer.createFixedSize(new int[]{1, 244, 244, 3}, DataType.FLOAT32);

                        位图 = Bitmap.createScaledBitmap(位图, 244, 244, true);
                        inputFeature0.loadBuffer(TensorImage.fromBitmap(bitmap).getBuffer());

                        // 运行模型推理并获取结果。
                        ModelUnquant.Outputs 输出 = model.process(inputFeature0);
                        TensorBufferoutputFeature0=outputs.getOutputFeature0AsTensorBuffer();

                        // 在这里更改类号
                        result.setText(labels[getMax(outputFeature0.getFloatArray())]+“”);
                    } 别的 {
                        // 处理bitmap为null的情况
                        result.setText(“错误：无图像”);
                    }

                    // 如果不再使用则释放模型资源。
                    模型.close();
                } catch (IOException e) {
                    // TODO 处理异常
                }
            }
        });

返回以下错误：
致命异常：main
进程：com.example.archeyewitness，PID：15698

java.lang.IllegalArgumentException：字节缓冲区的大小和形状不匹配。

在 org.tensorflow.lite.support.common.SupportPreconditions.checkArgument（SupportPreconditions.java:104）

在 org.tensorflow.lite.support.tensorbuffer.TensorBuffer.loadBuffer(TensorBuffer.java:309)

在 org.tensorflow.lite.support.tensorbuffer.TensorBuffer.loadBuffer(TensorBuffer.java:328)

在 com.example.archeyewitness.MainActivity$3.onClick(MainActivity.java:96)

现在，我尝试通过打印字节缓冲区的大小和形状来调试它：
Log.d(&quot;DebugInfo&quot;, &quot;张量缓冲区大小：&quot; + tensorBufferSize);
Log.d(&quot;DebugInfo&quot;, &quot;字节缓冲区大小:&quot; + byteBufferSize);
Log.d(“DebugInfo”, “张量缓冲区形状：” + Arrays.toString(tensorBufferShape));
Log.d(“DebugInfo”, “预期形状：” + Arrays.toString(byteBufferShape));


返回以下内容：
张量缓冲区大小：150528
2024-01-25 18:29:33.965 14367-14367 DebugInfo com.example.archeyewitness D 字节缓冲区大小：150528
2024-01-25 18:29:33.965 14367-14367 DebugInfo com.example.archeyewitness D 张量缓冲区形状：[1, 224, 224, 3]
2024-01-25 18:29:33.965 14367-14367 DebugInfo com.example.archeyewitness D 预期形状：[1, 224, 224, 3]
2024-01-25 18:29:33.971 14367-14367 AndroidRuntime com.example.archeyewitness D 关闭虚拟机
2024-01-25 18:29:33.992 14367-14367 AndroidRuntime com.example.archeyewitness

如您所见，尺寸确实匹配，但我仍然遇到相同的错误。有人可以解释一下发生了什么事吗？我正在失去理智，而且显然不是最聪明的。]]></description>
      <guid>https://stackoverflow.com/questions/77883608/java-lang-illegalargumentexception-the-size-of-byte-buffer-and-the-shape-do-no</guid>
      <pubDate>Fri, 26 Jan 2024 00:16:55 GMT</pubDate>
    </item>
    <item>
      <title>如何采用在 Python 中训练并使用 Pickle 保存的机器学习模型，并在 C++ 中将其作为预测模型运行？</title>
      <link>https://stackoverflow.com/questions/77883553/how-do-i-take-a-machine-learning-model-that-i-trained-in-python-and-saved-with</link>
      <description><![CDATA[我有一个用Python训练的机器学习模型，我需要最好将该模型转换成可以在C++中运行的dll。我希望也许有一个可以读取 pickle 的 C++ 包，或者其他一些可以共享机器学习模型进行预测的 Python/C++ 库。
我发现了这个名为 Pickling tools 的库，它应该用于 Python 和 C++ 之间的交叉通信，其口号是“How can I pickle in C++?”但我很难找到将我的pickle 放入C++ 中的部分。
http://www.picklingtools.com/html/usersguide.html ]]></description>
      <guid>https://stackoverflow.com/questions/77883553/how-do-i-take-a-machine-learning-model-that-i-trained-in-python-and-saved-with</guid>
      <pubDate>Thu, 25 Jan 2024 23:54:37 GMT</pubDate>
    </item>
    <item>
      <title>管道并行神经网络[关闭]</title>
      <link>https://stackoverflow.com/questions/77883493/pipeline-parallel-neural-network</link>
      <description><![CDATA[图中的Cn、Cn-x、Cn+1、Cn-x+1是什么意思？我正在阅读有关 Pipedream 管道并行的内容，但无法理解该图像。
论文链接（图4）：
https://arxiv.org/pdf/1806.03377.pdf
pipedream 图像
论文中提到C是计算，但没有提到n,x, n+1,n-x是什么。]]></description>
      <guid>https://stackoverflow.com/questions/77883493/pipeline-parallel-neural-network</guid>
      <pubDate>Thu, 25 Jan 2024 23:32:35 GMT</pubDate>
    </item>
    <item>
      <title>如何保留 Oracle Machine Learning (OML) k-means 模型？</title>
      <link>https://stackoverflow.com/questions/77883357/how-can-i-persist-an-oracle-machine-learning-oml-k-means-model</link>
      <description><![CDATA[此示例不展示如何将 k-means 聚类模型保存到数据库中。有没有办法做到这一点并且有示例代码吗？
适用于 Python 的 Oracle 机器学习
这是我创建模型的方法，
# 创建KM模型对象并拟合。
km_mod = oml.km(n_clusters = 3, **设置).fit(数据)
]]></description>
      <guid>https://stackoverflow.com/questions/77883357/how-can-i-persist-an-oracle-machine-learning-oml-k-means-model</guid>
      <pubDate>Thu, 25 Jan 2024 22:46:42 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch LSTM 多目标维度错误</title>
      <link>https://stackoverflow.com/questions/77883294/pytorch-lstm-multi-target-dimension-error</link>
      <description><![CDATA[我几天来一直在尝试执行 LSTM 多目标，但没有成功，因为数据集的前 8 列是目标，其他列是特征，从而产生维度错误。挑战包括根据特征值预测 8 个整数值可以是 0、1 或 2 的目标。之前我成功创建了一个 LSTM 来预测单个目标列，该目标列是所有 8 列的总和。但这个总和在置信度得分中产生了不良结果。有什么错误吗？
导入 pandas 作为 pd
将 numpy 导入为 np

# 设置种子以实现可重复性
np.随机.种子(42)

# 创建数据框
data = {&#39;col_&#39; + str(i+1): np.random.choice([0, 1, 2], 100) 如果 i &lt; 8 else np.random.uniform(-0.99, 0.99, 100) for i in range(100)}
df = pd.DataFrame(数据)
df.head()

# 显示数据框
打印（df）

进口火炬
将 torch.nn 导入为 nn
导入 torch.optim 作为 optim
从 torch.utils.data 导入 DataLoader，TensorDataset
从 sklearn.model_selection 导入 train_test_split
从 sklearn.preprocessing 导入 StandardScaler

# 提取目标和特征
目标 = df.iloc[:, :8].values
特征 = df.iloc[:, 8:].values

# 缩放功能
定标器=标准定标器()
特征=scaler.fit_transform（特征）

# 将目标转换为 LongTensor
目标 = torch.tensor(targets, dtype=torch.long)

# 将特征转换为FloatTensor
特征 = torch.tensor(特征, dtype=torch.float32)

# 将数据分为训练集和测试集
features_train、features_test、targets_train、targets_test = train_test_split(
    特征、目标、test_size=0.2、random_state=None
）

# 创建数据加载器
train_dataset = TensorDataset（features_train，targets_train）
train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)

# 定义LSTM模型
类 LSTMModel(nn.Module):
    def __init__(自身、输入大小、隐藏大小、层数、输出大小):
        super(LSTMModel, self).__init__()
        self.lstm = nn.LSTM(input_size,hidden_​​size,num_layers,batch_first=True)
        self.fc = nn.Linear(隐藏大小, 输出大小)

    def 前向（自身，x）：
        输出，_ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        返回

# 设置超参数
输入大小 = features.shape[1]
隐藏大小 = 64
层数 = 2
output_size = 8 # 目标类的数量
纪元数 = 10
学习率 = 0.001

# 实例化模型、损失函数和优化器
模型 = LSTMModel(输入大小、隐藏大小、层数、输出大小)
标准 = nn.CrossEntropyLoss()
优化器 = optim.Adam(model.parameters(), lr=learning_rate)

# 训练循环
对于范围内的纪元（num_epochs）：
    对于train_loader中的batch_features、batch_targets：
        优化器.zero_grad()
        输出=模型（batch_features）
        损失 = 标准（输出，batch_targets）
        loss.backward()
        优化器.step()

    print(f&#39;Epoch [{epoch+1}/{num_epochs}], 损失: {loss.item():.4f}&#39;)

# 在测试集上评估模型
模型.eval()
使用 torch.no_grad()：
    test_outputs = 模型（features_test）
    _, 预测 = torch.max(test_outputs, 1)

# 计算准确率
正确=(预测==targets_test).sum().item()
总计=targets_test.size(0)
准确率=正确率/总分
print(f&#39;测试准确度: {accuracy:.4f}&#39;)

运行时错误：
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- ------------------------------- IndexError Traceback（最近一次调用最后一次）Cell In[4]，第 60 58 行，针对batch_features , train_loader 中的batch_targets: 59 Optimizer.zero_grad() ---&gt; 60 输出 = 模型（batch_features） 61 损失 = criteria（输出，batch_targets） 62 loss.backward（）

文件 c:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\site-packages\torch\nn\modules\module.py:1501，在 Module._call_impl(self, *args, **kwargs)第1496章 第1497章第1498章 1499、第1500章第1501章 return front_call(*args, **kwargs) 第1502章 使用jit时不要调用函数 第1503章 full_backward_hooks, non_full_backward_hooks = [], []

Cell In[4]，第 40 行 38 def forward(self, x): 39 out, _ = self.lstm(x) ---&gt; 40 out = self.fc(out[:, -1, :]) 41 返回 out

IndexError：2 维张量的索引过多

我尝试多次修改 LSTModel 类，但没有得到安全结果]]></description>
      <guid>https://stackoverflow.com/questions/77883294/pytorch-lstm-multi-target-dimension-error</guid>
      <pubDate>Thu, 25 Jan 2024 22:32:05 GMT</pubDate>
    </item>
    <item>
      <title>我的自定义 OCR 模型不起作用并且在每种情况下都预测错误</title>
      <link>https://stackoverflow.com/questions/77883259/my-custom-ocr-model-dont-work-and-predicts-wrong-in-every-case</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77883259/my-custom-ocr-model-dont-work-and-predicts-wrong-in-every-case</guid>
      <pubDate>Thu, 25 Jan 2024 22:22:10 GMT</pubDate>
    </item>
    <item>
      <title>如何使用逻辑算法对性别进行谓词？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77882972/how-to-make-predicate-to-gender-using-logistic-algorithm</link>
      <description><![CDATA[附有问题的 Data.csv
https://www.mediafire.com/file/8h65adtolvx6nyo/Data .csv/文件
我的 Excel 文件有 5 列

最喜欢的颜色：最喜欢的颜色（受访者报告的颜色分为暖色、冷色或中性色）。
最喜欢的音乐流派：最喜欢的广泛音乐流派。
最喜欢的饮料：最喜欢的酒精饮料。
最喜欢的软饮料：最喜欢的碳酸饮料
性别：受访者报告的二元性别

如何使用带有预处理和探索性数据分析的逻辑算法来预测性别？
我尝试使用 python Collab 进行的操作
如何完成代码，直到我用性别进行谓词？
df = pd.read_csv(&#39;Data.csv&#39;)

# 探索数据集
打印（df.head（））
打印（df.info（））
# ...执行进一步的探索性分析

# 第2步：预处理

# 处理缺失值
df = df.dropna() # 删除缺失值的行，或使用插补技术

我尝试更清晰的数据
df = pd.read_csv(&#39;Data.csv&#39;)

# 探索数据集
打印（df.head（））
打印（df.info（））
# 进行进一步的探索性分析

# 第2步：预处理

df = df.dropna()

那么如何使用 python 和 colab 机器学习来恢复代码以生成谓词性别？]]></description>
      <guid>https://stackoverflow.com/questions/77882972/how-to-make-predicate-to-gender-using-logistic-algorithm</guid>
      <pubDate>Thu, 25 Jan 2024 21:13:37 GMT</pubDate>
    </item>
    <item>
      <title>在 Cloud Functions 中运行 MobileNetV2</title>
      <link>https://stackoverflow.com/questions/77882843/running-mobilenetv2-in-cloud-functions</link>
      <description><![CDATA[我正在尝试使用 Cloud Functions v2、Python 3.11 和 Tensorflow 2.15 获取给定图像的特征。
由于某种原因，模型在获取预测时没有返回，因此我的函数超时。
我一直在添加更多的 CPU，确切地说是 8 个以及 32GB 内存，但我仍然找不到返回任何结果的方法。
这是我正在执行的代码的一部分：
从 keras.applications 导入 MobileNetV2
从 keras.preprocessing 导入图像
从 keras.applications.mobilenet_v2 导入 preprocess_input

# include_top=False - 排除最终的分类层，专注于提取特征。
# pooling=&#39;avg&#39; - 添加全局平均池化层以将特征图压缩为单个向量（嵌入）。
#weights=&#39;imagenet&#39; - 使用在 ImageNet 上预先训练的权重以实现更好的特征提取。
模型 = MobileNetV2(权重=&#39;imagenet&#39;, include_top=False, pooling=&#39;avg&#39;)

def extract_embeddings(image_url):
  
    响应 = requests.get(image_url)
    响应.raise_for_status()

    img = image.load_img(BytesIO(响应.内容), target_size=(224, 224))

    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, 轴=0)
    img_array = 预处理_输入(img_array)

    嵌入 = model.predict(img_array)
    print(“预测的嵌入”)
    返回 embeddings.flatten()

我在这里有点迷失，所以希望有人能帮忙
我尝试扩展我的资源，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/77882843/running-mobilenetv2-in-cloud-functions</guid>
      <pubDate>Thu, 25 Jan 2024 20:45:38 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn 机器学习 ANN 模型在 Flask API 调用期间未加载 [关闭]</title>
      <link>https://stackoverflow.com/questions/77881808/sklearn-machine-learning-ann-model-not-loading-during-an-flask-api-call</link>
      <description><![CDATA[我有2个Python代码，1个是使用tensorflow和sklearn训练ANN模型。另一种是加载训练好的模型并进行预测。如果我在本地运行它们并将第二段代码作为函数调用，它可以完美地工作并且能够产生预测。
但是，当我尝试公开加载模型并使用 Flask 预测 API 调用的代码时，模型未加载，并且我不断收到有关反序列化的错误消息。
我将代码上传到我的 GitHub 中。如果有人能帮助我对此进行调试，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/77881808/sklearn-machine-learning-ann-model-not-loading-during-an-flask-api-call</guid>
      <pubDate>Thu, 25 Jan 2024 17:16:42 GMT</pubDate>
    </item>
    <item>
      <title>将客户输入与词汇列表进行比较并分配正确的 ID [关闭]</title>
      <link>https://stackoverflow.com/questions/77881445/comparing-customer-input-to-a-vocabulary-list-and-assigning-the-right-id</link>
      <description><![CDATA[我正在使用张量流开发机器学习模型。
我有一个预设的词汇列表（即我们系统中的产品名称和描述），我正在尝试在其上训练我的模型
最终目标是从客户那里获取他们对正在列出的“小蓝色靴子”产品的描述的输入。例如，我们的模型能够正确地将输入分类为“鞋类”。
我已经构建了脚本来集成来自张量流的预训练语言模型，但在输入真实的客户数据进行测试之前，我一直坚持在词汇表上训练我的模型的最佳方法。
我想在词汇列表上对其进行训练，因为它非常详细地说明了哪些项目属于某些类别，并且我用于训练和验证的客户数据并未包含词汇列表所考虑的所有可能性。
想知道仅在词汇列表上预训练我的模型，然后将其作为预训练模型集成到新模型中是否最好？是否有人知道另一条最佳路线？]]></description>
      <guid>https://stackoverflow.com/questions/77881445/comparing-customer-input-to-a-vocabulary-list-and-assigning-the-right-id</guid>
      <pubDate>Thu, 25 Jan 2024 16:17:44 GMT</pubDate>
    </item>
    <item>
      <title>在机器学习中使用日期时间</title>
      <link>https://stackoverflow.com/questions/77881238/using-datetime-in-machine-learning</link>
      <description><![CDATA[我有一个具有各种功能的 pandas 数据集，包括日期时间功能。
它看起来像这样：
&lt;前&gt;&lt;代码&gt; DD SSCL1 SEG_CLASS_CODE FCLCLD PASS_BK SA AU DTD DAY_OF_YEAR
0 2018-01-01 C C 1 0 0 18 -1 1
1 2018-01-01 C C 0 0 7 26 -1 1
2 2018-01-01 C C 0 0 9 18 -1 1
3 2018-01-01 C C 1 10 0 18 -1 1
4 2018-01-01 C C 0 9 1 18 -1 1

我需要使用DD列来训练模型。问题是如何对这一列进行编码？
我无法使用循环特征编码，如下所述：
如何处理机器学习数据预处理中的日期变量- 处理
因为在我教授模型的领域，2020 年与 2018 年不同，2022 年 2 月也不是 2023 年 2 月。因此，年、月和日有时会有所不同。
我的想法是以某种方式将日期时间转换为整数。例如，要获取总天数、小时数、分钟数或秒数，但我不知道起点（也许像往常一样是 1970 年 1 月 1 日）。
最简单的使用方法：dataset[&#39;DD&#39;]).apply(lambda x: x.value)，所以我会得到这样的结果：
&lt;前&gt;&lt;代码&gt;0 1514764800000000000
1 1514764800000000000
2 1514764800000000000
3 1514764800000000000
4 1514764800000000000
                  ...
1450583 1577577600000000000
1450584 1577664000000000000
1450585 1577664000000000000
1450586 1577145600000000000
1450587 1577232000000000000
名称：DD，长度：1450588，数据类型：int64

之后我想使用 MinMaxScaler 或 Standardscaler。
有没有办法根据我的要求对日期时间进行编码？]]></description>
      <guid>https://stackoverflow.com/questions/77881238/using-datetime-in-machine-learning</guid>
      <pubDate>Thu, 25 Jan 2024 15:45:18 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入张量流模型的 pyinstaller 转换为可执行文件，但预测和预测图像未显示</title>
      <link>https://stackoverflow.com/questions/76063824/converting-to-executable-using-pyinstaller-having-tensorflow-model-embeded-but-p</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76063824/converting-to-executable-using-pyinstaller-having-tensorflow-model-embeded-but-p</guid>
      <pubDate>Thu, 20 Apr 2023 12:01:37 GMT</pubDate>
    </item>
    <item>
      <title>如何给出整数列表作为 Tensorflow 数据集中的输入？</title>
      <link>https://stackoverflow.com/questions/65270127/how-to-give-a-list-of-integers-as-input-in-tensorflow-dataset</link>
      <description><![CDATA[我们正在尝试使用张量流微调/训练预训练的 RoBERTa 模型。为此，我们必须从数据帧创建一个 tf.data.Dataset。
数据框如下所示：

其中三个选项都是编码字符串，答案是一个整数，对应选项 A、B 或 C。
我们尝试使用以下方法创建 tf.dataset：
features= [&#39;选项A&#39;, &#39;选项B&#39;, &#39;选项C&#39;]

训练数据集 = (
    tf.data.Dataset.from_tensor_slices(
        （
            tf.cast(train_data[特征].values, tf.float32),
            tf.cast(train_data[&#39;答案&#39;].values, tf.int32)
        ）
    ）
）

但是这不起作用，因为我们收到以下错误：
ValueError：无法将 NumPy 数组转换为张量（不支持的对象类型列表）。

我读到我们不能将列表用作 tf.dtype，我们现在在其中放置了“float32”。但我们也无法将数据框中的列表转换为浮点数。
我们如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/65270127/how-to-give-a-list-of-integers-as-input-in-tensorflow-dataset</guid>
      <pubDate>Sat, 12 Dec 2020 21:44:39 GMT</pubDate>
    </item>
    <item>
      <title>什么是逻辑？ softmax 和 softmax_cross_entropy_with_logits 有什么区别？</title>
      <link>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</link>
      <description><![CDATA[在 tensorflow API 文档中，他们使用名为 logits 的关键字。它是什么？很多方法都是这样写的：
tf.nn.softmax(logits, name=None)

如果logits只是一个通用的Tensor输入，为什么它被命名为logits？
&lt;小时/&gt;
其次，下面两种方法有什么区别？
tf.nn.softmax(logits, name=None)
tf.nn.softmax_cross_entropy_with_logits（logits，标签，名称=无）

我知道 tf.nn.softmax 的作用，但不知道另一个。一个例子真的很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop</guid>
      <pubDate>Sat, 12 Dec 2015 14:03:27 GMT</pubDate>
    </item>
    </channel>
</rss>