<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 29 Dec 2023 18:16:42 GMT</lastBuildDate>
    <item>
      <title>VS Code中深度学习运行速度慢</title>
      <link>https://stackoverflow.com/questions/77733157/slow-running-speed-of-deep-learning-in-vs-code</link>
      <description><![CDATA[我正在尝试在 vs code 中运行一个非常简单的代码，但运行需要大约 40 分钟，尽管我在 google collab 中使用 4t GPU 运行它，只花了 2 分钟，我的系统大约是中高端，我不明白我现在使用快速图书库有什么问题，我检查了 ram、CPU 和 GPU 的温度，但只有 ram 超过 50%，其他都低于 50%
我尝试安装 GPU 软件包，并尝试了 YouTube 和 google 中的所有内容，但没有一个能正常工作]]></description>
      <guid>https://stackoverflow.com/questions/77733157/slow-running-speed-of-deep-learning-in-vs-code</guid>
      <pubDate>Fri, 29 Dec 2023 17:10:03 GMT</pubDate>
    </item>
    <item>
      <title>如何在DDP中更新学生网络的某些层的梯度和其他层的移动平均值？</title>
      <link>https://stackoverflow.com/questions/77733082/how-to-update-stduent-networks-some-layers-with-gradient-and-other-layers-with</link>
      <description><![CDATA[我 拥有一个用于自我监督学习网络的学生-教师网络。基本上，我的教师网络预测类别并计算损失并使用梯度流更新其参数。通常，学生网络使用教师网络的移动平均值来更新其参数。但就我而言，我的学生网络有一些独特的层，需要使用梯度流进行训练。
例如，如图所示，学生网络中有一个独特的层（X层），其余部分对于两个网络都是通用的。学生网络中的第1层、第2层和第3层需要用教师网络的移动平均值进行更新，第x层需要用梯度流进行更新。如何使用 Python torch DDP 设计这样的网络。]]></description>
      <guid>https://stackoverflow.com/questions/77733082/how-to-update-stduent-networks-some-layers-with-gradient-and-other-layers-with</guid>
      <pubDate>Fri, 29 Dec 2023 16:51:29 GMT</pubDate>
    </item>
    <item>
      <title>如何用视频数据训练一些模型</title>
      <link>https://stackoverflow.com/questions/77733070/how-to-train-some-model-with-video-data</link>
      <description><![CDATA[我用这样的图像训练了我的模型：
类 ASDataset(数据集):
    def __init__(self, client_file: str, imposter_file: str, 转换=无):
        将 open(client_file, &quot;r&quot;) 作为 f：
            client_files = f.read().splitlines()
        将 open(imposter_file, &quot;r&quot;) 作为 f：
            imposter_files = f.read().splitlines()
        self.labels = torch.cat((torch.ones(len(client_files)), torch.zeros(len(imposter_files))))
        self.imgs = client_files + imposter_files
        self.transforms = 变换

    def __len__(自身):
        返回 len(self.imgs)

    def __getitem__(self, idx):
        img_name = self.imgs[idx]
        img = Image.open(img_name)
        标签 = self.labels[idx]
        如果自我变换：
            img = self.transforms(img)
        返回图片、标签

train_dataset = ASDataset(client_file=“/kaggle/input/nuaaaa/raw/client_train_raw.txt”，imposter_file=“/kaggle/input/nuaaaa/raw/imposter_train_raw.txt”，transforms=预处理)
val_dataset = ASDataset(client_file=“/kaggle/input/nuaaaa/raw/client_test_raw.txt”，imposter_file=“/kaggle/input/nuaaaa/raw/imposter_test_raw.txt”，transforms=预处理)

# 创建数据加载器
train_loader = DataLoader(train_dataset,batch_size=8,shuffle=True)
val_loader = DataLoader(val_dataset,batch_size=8,shuffle=False)


但现在我有了视频数据，据我了解，我需要更改 class ASDataset。我尝试了不同的变体。例如：
类VideoDataset（数据集）：
    def __init__(self, video_file: str, 标签: int, 转换=无):
        self.video = cv2.VideoCapture(video_file)
        self.label = 标签
        self.transforms = 变换

    def __len__(自身):
        return int(self.video.get(cv2.CAP_PROP_FRAME_COUNT))

    def __getitem__(self, idx):
        self.video.set(cv2.CAP_PROP_POS_FRAMES, idx)
        成功，frame = self.video.read()
        如果没有成功：
            raise ValueError(“读取帧失败”)
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # 转换为RGB
        如果自我变换：
            框架 = self.transforms(框架)
        返回框架，自我标签

但是没有人给我结果。
请帮助我，如何使用视频数据进行训练？
数据示例client_train_raw.txt：
&lt;前&gt;&lt;代码&gt;/kaggle/input/dfdcdfdc/DFDCDFDC/dbnygxtwek.mp4
/kaggle/input/dfdcdfdc/DFDCDFDC/dbtbbhakdv.mp4
/kaggle/输入/dfdcdfdc/DFDCDFDC/ddepeddixj.mp4
]]></description>
      <guid>https://stackoverflow.com/questions/77733070/how-to-train-some-model-with-video-data</guid>
      <pubDate>Fri, 29 Dec 2023 16:49:09 GMT</pubDate>
    </item>
    <item>
      <title>使用自我训练的 AI 模型生成导入定义[关闭]</title>
      <link>https://stackoverflow.com/questions/77733066/generate-import-definitions-using-a-self-trained-ai-modell</link>
      <description><![CDATA[在我们的应用程序中，我们有一个导入模块，用户可以在其中指定如何从文本文件（以及其他文件类型、XML 和 ODBC）中提取数据。与将文本文件导入 Excel 有点类似 - 但有更多的可能性。大多数文本文件都具有不符合标准的专有结构。导入模块可以处理各种结构，例如简单的 csv 文件以及嵌套的键值对等。
我们有这方面的样本数据（可能有 100 个或数百个示例）。
所以我正在考虑创建和训练一个人工智能模型，该模型可以为使用的任何新文件创建这样的导入定义。用户只需打开文件，AI 模型就会创建第一个导入定义（如何以及在何处提取应用程序中表和列的文本）。
所以这里的输入是具有未知结构的文本，输出是已定义的结构。
我在 C++ 编程方面有经验，但在 AI 方面没有经验。
如何才能做到这一点？我还无法找到一些与这个问题至少有点相似的示例或教程。
任何提示表示赞赏。]]></description>
      <guid>https://stackoverflow.com/questions/77733066/generate-import-definitions-using-a-self-trained-ai-modell</guid>
      <pubDate>Fri, 29 Dec 2023 16:48:15 GMT</pubDate>
    </item>
    <item>
      <title>如何使用可教学机器解决游戏中的滞后问题</title>
      <link>https://stackoverflow.com/questions/77732846/how-to-fix-lag-in-game-using-teachable-machine</link>
      <description><![CDATA[我正在使用我训练过的谷歌可教学机器模型制作 p5.js 游戏。当我向左移动时，我的角色也会这样做，并且我无法击中其他物体（汽车）。
这有效，模型响应我的动作并且玩家实际移动。
首先，我在没有可教学机器模型的情况下进行了尝试，一切都在 60fps 上运行良好。
但是从我添加模型的那一刻起，游戏运行速度非常慢。好像是5fps。关于如何优化这个有什么想法吗？
编辑：我用 3 个类训练了这个模型，每个类包含 300-400 个图像，并训练了 100 个周期，这样的数据是否太多了？我应该减少它并且它会运行得更好吗？
游戏.js：
// game.js
让玩家；
让汽车=[]；
让poseNet；
让视频；

函数游戏（）{
  this.enter = function () {
    玩家 = 新玩家(1400, 700 / 2);
    汽车=[]；

    // 初始化 PoseNet
    poseNet = ml5.poseNet(视频, modelLoaded);
    poseNet.on（“姿势”，gotPoses）；
  };

  this.setup = 函数 () {
    帧速率（60）；
    // 创建视频捕捉对象
    视频 = createCapture(VIDEO, videoLoaded);
    视频大小（宽度，高度）；
    视频.隐藏(); // 最初隐藏视频
  };

  函数视频加载（）{
    console.log(&quot;视频已加载！&quot;);

    // 模型加载后附加gotPoses监听器
    poseNet.on（“姿势”，gotPoses）；
  }

  函数模型加载（）{
    console.log(&quot;模型已加载！&quot;);

    // 开始捕捉视频
    视频.播放();
  }

  this.draw = 函数 () {
    背景（0）；

    图像模式（中心）；
    图像（背景，宽度/2，高度/2，宽度，高度）；

    // 每隔几秒生成一辆新车
    if (frameCount % 60 === 0) {
      让 randomX = random(宽度);
      让 randomColor = 颜色(随机(255), 随机(255), 随机(255));
      让 newCar = new Car(randomX, 0, randomColor);
      cars.push(newCar);
    }

    // 显示并移动每辆车
    for (让 i = cars.length - 1; i &gt;= 0; i--) {
      让 currentCar = cars[i];
      currentCar.display();
      currentCar.move();

      // 检查与玩家的碰撞
      如果 （
        碰撞矩形圆（
          当前Car.x，
          当前Car.y，
          50、
          50、
          玩家.x,
          玩家.y,
          50、
          50
        ）
      ）{
        游戏结束（）;
      }

      // 删除屏幕外的汽车
      if (currentCar.y &gt; 高度) {
        汽车.splice(i, 1);
      }
    }

    // 显示并移动玩家
    玩家.显示();

    // 连续进行姿态检测
    poseNet.singlePose(视频);
  };

  函数 getPoses(姿势) {
    if (poses.length &gt; 0) {
      让姿势=姿势[0].姿势；

      让noseX =pose.keypoints[0].position.x;

      if (noseX &lt; 宽度 / 3) {
        console.log(&quot;向右移动&quot;);
        玩家.移动(“右”);
      } else if (noseX &gt; (2 * 宽度) / 3) {
        console.log(“向左移动”);
        玩家.移动(“左”);
      } 别的 {
        console.log(“直线”);
      }
    }
  }

  函数游戏结束（）{
    经理=新的场景管理器（）；

    // 切换到游戏结束场景
    manager.showScene(游戏结束);
  }
}


玩家等级：
// 玩家类别
玩家类{
  构造函数（x，y）{
    这个.x = x;
    这个.y = y;
    这个.速度 = 5;
  }

  展示（） {
    // 将玩家绘制为一个圆圈
    填充(255,0,0);
    椭圆(this.x, this.y, 50, 50);
  }

  移动（方向）{
    // 根据给定的方向移动玩家
    if (方向===“右”){
      this.x += this.速度；
    } else if (方向===“左”){
      this.x -= this.速度；
    }

    this.x = 约束(this.x, 0, 宽度);
  }
}
]]></description>
      <guid>https://stackoverflow.com/questions/77732846/how-to-fix-lag-in-game-using-teachable-machine</guid>
      <pubDate>Fri, 29 Dec 2023 15:56:35 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中对新数据集进行预测</title>
      <link>https://stackoverflow.com/questions/77732371/make-prediction-on-new-data-set-in-r</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77732371/make-prediction-on-new-data-set-in-r</guid>
      <pubDate>Fri, 29 Dec 2023 14:03:24 GMT</pubDate>
    </item>
    <item>
      <title>具有命名实体识别（NER）的聊天机器人</title>
      <link>https://stackoverflow.com/questions/77732089/chat-bot-with-named-entity-recognition-ner</link>
      <description><![CDATA[在创建 Telegram 机器人助手时需要建议，该助手将能够识别自然语言（俄语）、对其进行分析，并根据上下文提取实体（当前仅提取日期）。用户的文本可以非常多样化，包括手写日期和数字格式的日期。我打算用 Node.JS 来编写它。我知道 GPT 的存在，但由于某些原因，我无法使用它。请分享您的经验，了解如何最好地执行此任务、需要注意哪些陷阱以及执行的复杂性。我没有机器学习、神经网络和 NLP 方面的经验。
目前，我进行了大量的谷歌搜索，并找到了 2 个适合我的库。它们是 TensorFlow 和 Natural。他们有多适合解决这项任务？]]></description>
      <guid>https://stackoverflow.com/questions/77732089/chat-bot-with-named-entity-recognition-ner</guid>
      <pubDate>Fri, 29 Dec 2023 12:52:11 GMT</pubDate>
    </item>
    <item>
      <title>为什么“sklearn.svm.LinearSVC”的执行时间比“sklearn.svm.SVC”更长？</title>
      <link>https://stackoverflow.com/questions/77731956/why-is-sklearn-svm-linearsvc-taking-longer-to-execute-than-sklearn-svm-svc</link>
      <description><![CDATA[我正在使用 scikit-learn 中的 LinearSVC 和 SVC 类执行超参数调整，尽管我使用  执行的搜索量增加了 10 倍SVC类比LinearSVC执行时间短很多，可能是什么原因呢？我认为 LinearSVC 更优化。
我正在使用 Olivetti 面孔数据集
这是我正在执行的两个搜索：
从 sklearn.svm 导入 LinearSVC
从 sklearn.svm 导入 SVC
从 sklearn.model_selection 导入 GridSearchCV

#LinearSVC超参数调优------------------------
参数网格 = [
    {&#39;svc__C&#39;: np.logspace(-3,3, num=10)}
]

full_pipeline = 管道([
    (“预处理”, StandardScaler(with_mean=False)),
    (“svc”,LinearSVC(random_state=0))
    ]）

svc_rnd_search = GridSearchCV(full_pipeline, param_grid=param_grid, cv=10,
                           评分=&#39;准确度&#39;,n_jobs=-1)

# 测量执行时间
开始时间 = 时间()

#运行搜索
svc_rnd_search.fit(X_train, y_train)

# 计算执行时间
结束时间 = 时间()
执行时间毫秒 = (结束时间 - 开始时间) * 1000
print(f&quot;执行时间: {execution_time_ms:.3f}ms&quot;)

#SVC超参数调优------------------------------------------------
参数网格 = [
    {&#39;svc__C&#39;: np.logspace(-2,3, num=10),
     &#39;svc__gamma&#39;: np.logspace(-5,1, num=10),
     &#39;svc__kernel&#39;: [&#39;rbf&#39;]}
]

full_pipeline = 管道([
    (“预处理”, StandardScaler(with_mean=False)),
    (“svc”,SVC())
    ]）

svc_rnd_search = GridSearchCV(full_pipeline, param_grid=param_grid, cv=10,
                           评分=&#39;准确度&#39;,n_jobs=-1)

# 测量执行时间
开始时间 = 时间()

#运行搜索
svc_rnd_search.fit(X_train, y_train)

# 计算执行时间
结束时间 = 时间()
执行时间毫秒 = (结束时间 - 开始时间) * 1000
print(f&quot;执行时间: {execution_time_ms:.3f}ms&quot;)

第一个代码块 (LinearSVC) 的执行时间为 1087635 毫秒，而 SVC 类的执行时间为 36961 毫秒。]]></description>
      <guid>https://stackoverflow.com/questions/77731956/why-is-sklearn-svm-linearsvc-taking-longer-to-execute-than-sklearn-svm-svc</guid>
      <pubDate>Fri, 29 Dec 2023 12:18:51 GMT</pubDate>
    </item>
    <item>
      <title>即使训练和测试数据集具有良好的准确性，模型也无法正确分类[关闭]</title>
      <link>https://stackoverflow.com/questions/77730582/model-not-classifying-correctly-even-with-good-accuracy-on-training-and-test-dat</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77730582/model-not-classifying-correctly-even-with-good-accuracy-on-training-and-test-dat</guid>
      <pubDate>Fri, 29 Dec 2023 06:36:45 GMT</pubDate>
    </item>
    <item>
      <title>当所有列都是 float64 和 int64 时，为什么 dtype: object</title>
      <link>https://stackoverflow.com/questions/77730058/why-is-the-dtype-object-when-all-columns-are-float64-and-int64</link>
      <description><![CDATA[print(cleaned_train.dtypes)

打印（“--”）

打印（cleaned_test.dtypes）

观察年份 int64

保险期间 float64

住宅 int64

Building_Painted float64

建筑_围栏浮体64

Building_Type float64

索取 float64

建筑尺寸 float64

地理代码 float64

数据类型：对象

--

观察年份 int64

保险期间 float64

住宅 int64

Building_Painted float64

建筑_围栏浮体64

Building_Type float64

索取 float64

建筑尺寸 float64

地理代码 float64

数据类型：对象

尝试获取 dtype:numeric 但得到了对象]]></description>
      <guid>https://stackoverflow.com/questions/77730058/why-is-the-dtype-object-when-all-columns-are-float64-and-int64</guid>
      <pubDate>Fri, 29 Dec 2023 03:03:31 GMT</pubDate>
    </item>
    <item>
      <title>我试图识别两张脸是否相似，而不是使用 opencv 的人脸识别[关闭]</title>
      <link>https://stackoverflow.com/questions/77728809/i-was-trying-to-identify-the-two-face-are-similar-are-not-using-face-recognition</link>
      <description><![CDATA[我创建了一个函数来识别人脸，它需要 Net,Mat 输入
我是机器学习新手。我试图获取图像的值并比较它们。我将值存储在列表中，当我尝试将值添加到其中时出现错误]]></description>
      <guid>https://stackoverflow.com/questions/77728809/i-was-trying-to-identify-the-two-face-are-similar-are-not-using-face-recognition</guid>
      <pubDate>Thu, 28 Dec 2023 19:29:40 GMT</pubDate>
    </item>
    <item>
      <title>在 WSL conda 环境中安装 lightgbm GPU</title>
      <link>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</link>
      <description><![CDATA[如何安装LightGBM？
我检查了多个来源，但仍然无法安装。
我尝试了 pip 和 conda 但都返回错误：
[LightGBM] [警告] 目前不支持在 CUDA 中使用稀疏特征。
[LightGBM] [致命] 此版本中未启用 CUDA Tree Learner。
请使用 CMake 选项 -DUSE_CUDA=1 重新编译

我尝试过的内容如下：
git clone --recursive https://github.com/microsoft/LightGBM
cd LightGBM/
mkdir -p 构建
光盘构建
cmake -DUSE_GPU=1 ..
使-j$(nproc)
cd ../python-package
点安装。
]]></description>
      <guid>https://stackoverflow.com/questions/77728334/install-lightgbm-gpu-in-a-wsl-conda-env</guid>
      <pubDate>Thu, 28 Dec 2023 17:34:48 GMT</pubDate>
    </item>
    <item>
      <title>媒体管道是否与深脸一起使用进行人脸识别以获得更好的准确性</title>
      <link>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</link>
      <description><![CDATA[我使用深脸进行识别，但准确性不好，所以我尝试实现媒体管道，在​​其中提取地标，因此我将其提供给深脸以获得更好的准确性。有什么办法可以做到这一点吗？
我从媒体管道中提取特征向量，但我如何将其传递到深层面部。他们有可能做到这一点吗？ 
深度人脸是否采用media pipeline地标进行人脸识别以获得更高的准确率？]]></description>
      <guid>https://stackoverflow.com/questions/77726072/is-media-pipe-is-use-with-deep-face-for-face-recognition-for-better-accuracy</guid>
      <pubDate>Thu, 28 Dec 2023 09:38:05 GMT</pubDate>
    </item>
    <item>
      <title>MLFLOW 工件存储在 ftp 服务器上但未显示在 ui 中</title>
      <link>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</link>
      <description><![CDATA[我在远程跟踪服务器上训练期间使用 MLFLOW 存储一些参数和指标。现在我还尝试添加一个 .png 文件作为工件，但由于 MLFLOW 服务器远程运行，我将该文件存储在 ftp 服务器上。我通过以下方式提供了 ftp 服务器地址和 MLFLOW 路径：
mlflow 服务器 --backend-store-uri sqlite:///mlflow.sqlite --default-artifact-root ftp://user:password@1.2.3.4/artifacts/ --host 0.0.0.0 &amp;

现在我训练一个网络并通过运行来存储工件：
mlflow.set_tracking_uri(remote_server_uri)
mlflow.set_experiment(“默认”)
mlflow.pytorch.autolog()

使用 mlflow.start_run()：
    mlflow.log_params(flow_params)
    训练师.fit(模型)
    训练师.test()
    mlflow.log_artifact(“confusion_matrix.png”)
mlflow.end_run()

我将 .png 文件保存在本地，然后使用 mlflow.log_artifact(“confusion_matrix.png”) 将其记录到与实验对应的右侧文件夹中的 ftp 服务器。到目前为止，一切正常，只是该工件没有显示在在线 mlflow ui 中。记录的参数和指标正常显示。工件面板保持空白，仅显示
未记录任何工件
使用日志工件 API 存储 MLflow 运行的文件输出。

我发现了类似的线程，但仅限于在本地 mlflow 存储上遇到相同问题的用户。不幸的是，我无法将这些修复应用于我的问题。有人知道如何解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/68728492/mlflow-artifacts-stored-on-ftp-server-but-not-showing-in-ui</guid>
      <pubDate>Tue, 10 Aug 2021 14:15:42 GMT</pubDate>
    </item>
    <item>
      <title>从huggingface特征提取管道中获取句子嵌入</title>
      <link>https://stackoverflow.com/questions/64685243/getting-sentence-embedding-from-huggingface-feature-extraction-pipeline</link>
      <description><![CDATA[如何从 Huggingface 的特征提取管道中获取整个句子的嵌入？
我了解如何获取每个标记的特征（如下），但如何获取整个句子的总体特征？
feature_extraction = pipeline(&#39;feature-extraction&#39;, model=“distilroberta-base”, tokenizer=“distilroberta-base”)
features = feature_extraction(“我是句子”)
]]></description>
      <guid>https://stackoverflow.com/questions/64685243/getting-sentence-embedding-from-huggingface-feature-extraction-pipeline</guid>
      <pubDate>Wed, 04 Nov 2020 17:52:22 GMT</pubDate>
    </item>
    </channel>
</rss>