<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sun, 19 May 2024 12:25:17 GMT</lastBuildDate>
    <item>
      <title>使用 Transformer 的简单 QA 模型中的运行时错误</title>
      <link>https://stackoverflow.com/questions/78501874/runtimeerror-in-a-simple-qa-model-using-transformer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501874/runtimeerror-in-a-simple-qa-model-using-transformer</guid>
      <pubDate>Sun, 19 May 2024 07:28:22 GMT</pubDate>
    </item>
    <item>
      <title>名称特征不匹配 ML</title>
      <link>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501675/name-feature-mismatch-ml</guid>
      <pubDate>Sun, 19 May 2024 05:37:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在训练模型时修复此 KeyError？</title>
      <link>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501325/how-to-fix-this-keyerror-while-training-my-model</guid>
      <pubDate>Sun, 19 May 2024 00:36:44 GMT</pubDate>
    </item>
    <item>
      <title>标准化将 NaN 值插入到我的数据框中</title>
      <link>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78501262/normalization-inserting-nan-values-into-my-dataframe</guid>
      <pubDate>Sat, 18 May 2024 23:40:21 GMT</pubDate>
    </item>
    <item>
      <title>GflowNet 无法学习某些奖励</title>
      <link>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</link>
      <description><![CDATA[我尝试将问题简化为以下代码：
# 图表上的转换
转换 = {
    # 0：无操作
    ＃1：N
    ＃2：S
    ＃3：W
    ＃4：E
    1：{0：1、1：2、2：1、3：3、4：1}，
    2：{0：2、1：12、2：1、3：2、4：2}，
    3: {0: 3, 1: 3, 2: 3, 3: 4, 4: 1},
    4：{0：4、1：5、2：4、3：6、4：3}，
    5: {0: 5, 1: 13, 2: 4, 3: 5, 4: 5},
    6: {0: 6, 1: 6, 2: 6, 3: 7, 4: 4},
    7: {0: 7, 1: 8, 2: 7, 3: 9, 4: 6},
    8: {0: 8, 1: 14, 2: 7, 3: 8, 4: 8},
    9: {0: 9, 1: 9, 2: 9, 3: 10, 4: 7},
    10: {0: 10, 1: 11, 2: 10, 3: 10, 4: 9},
    11: {0: 11, 1: 15, 2: 10, 3: 16, 4: 11},
    12: {0: 12, 1: 18, 2: 2, 3: 12, 4: 12},
    13: {0: 13, 1: 19, 2: 5, 3: 13, 4: 13},
    14: {0: 14, 1: 20, 2: 8, 3: 14, 4: 14},
    15: {0: 15, 1: 21, 2: 11, 3: 17, 4: 15},
    16: {0: 16, 1: 17, 2: 16, 3: 16, 4: 11},
    17: {0: 17, 1: 22, 2: 16, 3: 23, 4: 15},
    18: {0: 18, 1: 18, 2: 12, 3: 25, 4: 18},
    19: {0: 19, 1: 19, 2: 13, 3: 26, 4: 25},
    20: {0: 20, 1: 20, 2: 14, 3: 27, 4: 26},
    21: {0: 21, 1: 21, 2: 15, 3: 22, 4: 27},
    22: {0: 22, 1: 22, 2: 17, 3: 24, 4: 21},
    23: {0: 23, 1: 24, 2: 17, 3: 23, 4: 17},
    24: {0: 24, 1: 22, 2: 23, 3: 24, 4: 22},
    25: {0: 25, 1: 25, 2: 25, 3: 19, 4: 18},
    26: {0: 26, 1: 26, 2: 26, 3: 20, 4: 19},
    27: {0: 27, 1: 27, 2: 27, 3: 21, 4: 20}
}

＃ 模型
类 TBModel(nn.Module):
  def __init__(self, num_hid):
    超级().__init__()

    self.mlp_forward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                     nn.LeakyReLU(),
                                     nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.mlp_backward = nn.Sequential(nn.Linear(TRAJECTORY_LENGTH, num_hid),
                                      nn.LeakyReLU(),
                                      nn.Linear(num_hid, OUTPUT_DIMS))
    
    self.logZ = nn.Parameter(torch.ones(1))

  def 前向（自身，x）：
    P_F = self.mlp_forward(x)
    返回P_F
  
  def向后（自身，x）：
    P_B = torch.tensor([(1/INPUT_DIMS)]*INPUT_DIMS)#self.mlp_backward(x)

    返回P_B

# 奖励函数
def奖励_that_model_does_not_learn（轨迹）：
  目标轨迹 = [21, 27, 20, 14, 8]
  奖励=0
  对于范围内的 i(len(轨迹))：
    如果轨迹[i] == goal_trajectory[i]：
      奖励=奖励+1
  返回 torch.tensor(奖励)

def奖励_that_model_learns（轨迹）：
  如果轨迹 == [21, 27, 20, 14, 8]：
    返回 torch.tensor([1])
  返回 torch.tensor([0])


模型 = TBModel(512)
opt = torch.optim.Adam(model.parameters(), 3e-4)

tb_losses = []
tb_奖励 = []
logZs = []
小批量损失= 0
小批量奖励 = 0

对于 tqdm.tqdm 中的剧集（范围（NUM_EPOCHS），ncols = 40）：
  
  gflow_state = torch.zeros(TRAJECTORY_LENGTH)
  状态 = 起始节点
  总计_P_F = 0
  总P_B = 0
  轨迹=[]

  对于范围内的 t（TRAJECTORY_LENGTH）：
    轨迹.append(状态)
    P_F_s = model.forward(gflow_state)
    P_B_s = torch.tensor([(1/5)])

    猫=分类（logits=P_F_s）
    动作 = cat.sample()
    _gflow_state = gflow_state.clone()
    _gflow_state[t] = 操作
    gflow_state = _gflow_state.clone()

    new_state = 转换[状态][action.item()]
    Total_P_F += cat.log_prob(动作)
    Total_P_B += torch.log(P_B_s)

    状态 = 新状态

  奖励=reward_that_model_does_not_learn（轨迹）

  损失 = (model.logZ +total_P_F - torch.log(reward).clip(-20) -total_P_B).pow(2)
  
  minibatch_loss += 损失
  minibatch_reward += 奖励

  if (episode + 1) % BATCH_SIZE == 0:
    wandb.log({
      “损失”：minibatch_loss.item(),
      “奖励”：minibatch_reward.item()/BATCH_SIZE,
      “Z”：model.logZ.item()
    })
    minibatch_loss.backward()
    opt.step()
    opt.zero_grad()
    小批量损失= 0
    小批量奖励 = 0

这是我对 GFlowNet 的实现。我正在使用此模型引导代理通过具有 27 个节点的地图，如转换所述。 GFlowNet 对动作排列进行采样，这些动作将使代理在地图上移动。在轨迹结束时，将为代理计算奖励。该模型能够通过奖励reward_that_model_learns来学习明确的轨迹。然而，代理在学习优化由 reward_that_model_does_not_learn 定义的奖励时要困难得多。两者之间的唯一区别是，一个得分为全有或全无，而另一种则对轨迹给予部分评分。我不明白为什么该模型可以与一个模型斗争，但可以学习另一个模型，因为在这两种情况下，它都处理相同的状态空间（动作的排列）。如果能从理论上理解为什么某些奖励更难学习以及如何继续前进，那就太好了，谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78501031/gflownet-fails-to-learn-certain-rewards</guid>
      <pubDate>Sat, 18 May 2024 21:22:00 GMT</pubDate>
    </item>
    <item>
      <title>感知器的图像识别不起作用</title>
      <link>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</link>
      <description><![CDATA[我必须调整我的图像识别代码，以便它使用感知器来代替分类器进行图像识别。我按照讲师提供的示例执行了所有操作（并且我正在使用他们的感知器代码）。使用分类器，我的图像识别工作完美，没有出错，但是当我用感知器替换这些分类器时，无论我使用什么图像，它总是被识别为第二种类型。
我的图像识别代码：
folder_names=[“First_type”] 、“第二类型”、“第三类型”]
images_in_folder=[25, 25, 25]
标签=[]
学习矩阵 = []

网络=感知器.PerceptronNetwork(6000,1)
label_matrix=[[0],[1],[2]]*25
大小=75,6000
Learning_matrix=np.zeros(大小，dtype=np.float32)

def GaborFilter(image_name):
    k大小 = 31
    西格玛 = 5
    theta_range = np.array([0, np.pi/4, np.pi/2])
    
    频率 = np.array([1.1, 2.1, 3.1, 4.1, 5.1])
    相位=0
    gabor_filter_points = []
    
    原始图像 = cv2.imread(图像名称, cv2.IMREAD_GRAYSCALE)
    调整大小的图像 = cv2.resize(原始图像, (1000, 1000))
    
    step_size_height = resized_image.shape[1] // 20
    step_size_width = resized_image.shape[0] // 20

    对于 theta_range 中的 theta：
        对于频率中的 freq：
            过滤器= cv2.getGaborKernel（（ksize，ksize），西格玛，西塔，频率，相位）
            filtered_image=cv2.filter2D（src=resized_image，d深度=-1，kernel=filter）
            对于范围内的 x（0，resized_image.shape[0]，step_size_width）：
                对于范围内的 y(0, resized_image.shape[1], step_size_height):
                    gabor_filter_points.append(filtered_image[x][y]/255)
    返回 gabor_filter_points

gabor_attributes=[]

对于范围（25）内的 image_nr：
    对于folder_index，枚举中的num_of_images（images_in_folder）：
        文件夹名称 = 文件夹名称[文件夹索引]
        image_path = os.path.join(folder_name, str(image_nr + 1) + &quot;.jpg&quot;)
        gabor_attr_for_image = GaborFilter(图像路径)
        gabor_attributes.append(gabor_attr_for_image)

学习矩阵=gabor_attributes
纪元数=0
对于范围（100）内的纪元：
    总错误数=0
    对于范围 (75) 内的 i：
        error_in_network=network.teachNetwork(learning_matrix[i],label_matrix[i])
        总错误数+=网络中的错误数
    number_of_epochs+=1
    如果总错误数==0：
        休息;

识别矩阵=[]
recognize_matrix=(GaborFilter(“Test.jpg”))
雷兹=[10]
网络.giveNetworkAnswer(recognition_matrix, rez)

如果 rez[0]==0:
    print(&quot;第一种类型&quot;)
elif rez[0]==1:
    print(&quot;第二个管子&quot;)
elif rez[0]==2:
    print(&quot;第三种类型&quot;)
别的：
    print(&quot;错误：&quot;+str(rez[0]))

感知器代码，由我的讲师提供：
### 单独的神经元（感知器）类###
神经元类：
    利亚姆达 = 0.001
    def __init__(this, input_nr):
        this.input_number = input_nr
        this.权重 = []

        对于范围内的 i（this.input_number）：
            this.weights.append(np.random.normal(0, 0.01))
        this.threshold = np.random.normal(0, 0.01)
        
    def 响应（此，输入信号）：
        总和 = 0
        对于范围内的 i（this.input_number）：
            sum += inputSignal[i] * this.weights[i]
        sum -= this.threshold
        如果总和 &gt; 返回 1 0 否则 0
            
    def changeWeights(this, inputSignal, targetResponse):
        实际响应 = this.response(inputSignal)
        错误 = 目标响应 - 实际响应
        
        如果错误！= 0：
            对于范围内的 i（this.input_number）：
                deltaSvoris = this.liambda * inputSignal[i] * 错误
                this.weights[i] += deltaSvoris
            this.threshold += this.liambda * 错误
        返回错误
           
########## 感知器 ANN 类 ############
类感知器网络：
    def __init__(this, 输入_nr, 输出_nr):
        this.input_number = input_nr
        this.neuronNumber = 输出编号
        this.outputLayer = []
        对于范围内的 i(this.neuronNumber)：
            神经元 = 神经元(this.input_number)
            this.outputLayer.append(神经元)

    def示教网络（这个，输入向量，输出向量）：
        错误编号输入输出 = 0
        对于范围内的 i(this.neuronNumber)：
            神经响应 = this.outputLayer[i].response(inputVector)
            如果神经元响应！= 输出向量[i]：
                错误= this.outputLayer [i] .changeWeights（inputVector，outputVector [i]）
                错误编号输入输出+=abs(错误)
        返回错误编号输入输出
    
    def GiveNetworkAnswer(this, inputVector, networkResponse):
        对于范围内的 i(this.neuronNumber)：
            networkResponse[i] = this.outputLayer[i].response(inputVector)
            打印（f“{networkResponse}”）

我尝试更改纪元数，打印出一些值以查看我使用的数据是否存在错误，但没有运气。]]></description>
      <guid>https://stackoverflow.com/questions/78500607/image-recognition-with-perceptrons-not-working</guid>
      <pubDate>Sat, 18 May 2024 18:12:53 GMT</pubDate>
    </item>
    <item>
      <title>我用自己的数据集训练yolo模型，但是没有测试结果</title>
      <link>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</link>
      <description><![CDATA[我正在使用 Yolov3 模型以及从 Kaggle 收到的数据集来训练模型。模型训练已完成，我将新权重添加到备份文件夹中。我运行了我训练过的一种水果进行测试，但没有发生对象检测。同一图像显示为 Prediction.jpg。训练看起来不错，但我不明白为什么它不能检测物体。请帮助我。
火车站代码：
./darknet探测器列车 /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/Desktop/Projects/Bitirmeprojesi/yolov3.weights

测试终端代码：
./darknet探测器测试 /Users/melisabagcivan/darknet/data/obj.data /Users/melisabagcivan/darknet/cfg/yolov3.cfg /Users/melisabagcivan/darknet/backup/yolov3_final.weights -thresh 0.25 -out预测.jpg

我设置并编辑了 obj.data、obj.names 和 yolov3.cfg 文件。
我有 3 个类别：苹果、香蕉和橙子。我已经根据3个类在cfg文件中正确设置了filter和class值等值。
cfg 文件
[网]
# 测试
批次=64
细分=1
＃ 训练
细分=16
宽度= 608
高度=608
通道=3
动量=0.9
衰减=0.0005
角度=0
饱和度=1.5
曝光=1.5
色调=0.3

学习率=0.001
烧入=1000
max_batches = 6000 # 类数 * 2000
政策=步骤
步骤=3600,4800 # max_batches num %80, %90
尺度=.1,.1

数据集中除了.jpg图片外，还有yolo格式的同名.txt文件。
在此处输入图像描述文件图像
包含所有图像路径的 train.txt 和 test.txt 文件也已准备就绪。
当我在终端中运行测试命令时，它可以工作，但图片看起来相同，没有检测对象的边界框。我确定我已经安装了 Opencv。我正在使用 macOS。为什么它没有检测到它？请有人帮忙。我多次通过 make clean 清理暗网，并通过 make opencv = 1 运行它，但结果没有改变。
[yolo]参数：iou损失：mse（2），iou_norm：0.75，obj_norm：1.00，cls_norm：1.00，delta_norm：1.00，scale_x_y：1.00
总 BFLOPS 137.613
平均输出 = 1052318
正在从 /Users/melisabagcivan/darknet/backup/yolov3_final.weights 加载权重...
 看过 64 个，训练过：32013 个 K 图像（500 Kilo-batches_64）
完毕！从权重文件加载 107 层
输入图像路径：/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg
 检测层：82-类型=28
 检测层数：94-型=28
 检测层：106-类型=28
/Users/melisabagcivan/Desktop/Projects/yoloOD/dataset/test/38_Orange.jpg：预测为 6738.129000 毫秒。

我尝试了很多图像，但它没有在任何图像中绘制方框。我不明白是它无法检测到还是我在测试时犯了错误。]]></description>
      <guid>https://stackoverflow.com/questions/78497575/i-train-yolo-model-with-my-own-data-set-but-there-is-no-test-result</guid>
      <pubDate>Fri, 17 May 2024 19:21:32 GMT</pubDate>
    </item>
    <item>
      <title>从 Orange 导出的模型在 Orange 中运行良好，但在 Python 中运行不佳 [关闭]</title>
      <link>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</link>
      <description><![CDATA[我用 Orange 训练了一个机器学习模型，可以非常准确地对狗和猫进行分类。但是，当我将模型导出到 pickle 文件并在 Python 中加载时，无论输入数据如何，它都会一致预测“cat”。
这是我用 python 写的：
导入pickle
从 PIL 导入图像
将 numpy 导入为 np

modello = &#39;modelli/catDogsLogisticRegression.pkcls&#39;

def load_model_from_pickle(modello):
    尝试：
        使用 open(modello, &#39;rb&#39;) 作为 file_pickle：
            模型 = pickle.load(file_pickle)
            返回模型
    除了文件未找到错误：
        print(f“文件 {modello} 非 trovato。”)
        返回无

def preprocess_image(image_path):
    # 想象中的卡里卡
    img = Image.open(图像路径)
    # 在 scala di grigi 中进行想象和转换
    img = img.resize((32, 64)).convert(&#39;L&#39;)
    # 将 l&#39;immagine 转换为 un array numpy 并将 Ridimensiona 转换为 un unico vettare
    img_array = np.array(img).reshape(1, -1)
    返回img_array
*强调文字*
加载模型 = load_model_from_pickle(modello)
如果加载模型：
    print(&quot;成功模型&quot;)
    # 模型用途
    # Carica e pre-elabora un&#39;immagine
    image_path = &#39;甘蔗.jpg&#39;
    新数据 = 预处理图像（图像路径）
    # Prevedere la classe del nuovo esempio
    Predicted_class = returned_model.predict(new_data)[0]
    print(“Prevista 类：”, &#39;Gatto&#39; if Predicted_class == 0 else &#39;Cane&#39;)
别的：
    print(“模型错误。”)

在橙色工作流程中，我使用了逻辑回归，该模型的准确性相当高。 这是我获取数据集的位置。我认为我预处理图像的方式有问题，也许它与Orange方法不同，但我无法解决问题 这是橙色工作流程的图像。知道为什么模型在 Python 中表现不同吗？我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78497427/model-exported-from-orange-works-well-in-orange-but-not-in-python</guid>
      <pubDate>Fri, 17 May 2024 18:43:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用决策树算法和bert模型对文本进行分类？</title>
      <link>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-model-to-classify-a-text</link>
      <description><![CDATA[我想集成并使用 BERT 和决策树两种算法进行文本分类，因此我需要该领域的指导和帮助。
如果有人有这个领域的源代码或文章，请提供给我。或者即使朋友有更好的建议将 BERT 算法与任何其他算法结合起来]]></description>
      <guid>https://stackoverflow.com/questions/78497176/how-to-use-decision-tree-algorithm-with-bert-model-to-classify-a-text</guid>
      <pubDate>Fri, 17 May 2024 17:44:40 GMT</pubDate>
    </item>
    <item>
      <title>学习率不更新</title>
      <link>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</link>
      <description><![CDATA[def make_prediction(x0,t0):
    输入 = torch.vstack([x0,t0])
    Layer_1 = torch.matmul(w0,输入)
    返回层_1

损失1 = nn.MSELoss()
def loss_function():
            u_t=(make_prediction(x,t+inf_s)-make_prediction(x,t))/inf_s
            u_x=(make_prediction(x+inf_s,t)-make_prediction(x,t))/inf_s
            u_xx=(make_prediction(x+inf_s,t)-2*make_prediction(x,t)+make_prediction(x-inf_s,t))/inf_s**2
            返回 (1/N_i)*(loss1(make_prediction(x0IC,t0IC), u0IC))+(1/N_b)*(loss1(make_prediction(x0BC1,t0BC1), u0BC1))
            +(1/N_b)*(loss1(make_prediction(x0BC2,t0BC2), u0BC2))+(1/N_f)*(np.pi/0.01)*(loss1(u_xx-u_t-make_prediction(x,t)*u_x , 0))

def train_step(w,b, 学习率):
    可训练变量 = [w,b]
    优化器 = torch.optim.SGD(trainable_variables, lr=learning_rate,momentum=0.9)
    调度程序 = torch.optim.lr_scheduler.ExponentialLR(优化器, gamma=0.01)
    损失 = loss_function()
    loss.backward()
    使用 torch.no_grad()：
        w -= 学习率 * w.grad
        b -= 学习率 * b.grad
        w.grad.zero_()
        b.grad.zero_()
    优化器.step()
    调度程序.step()
train_step(w,偏差,学习率)

我运行此代码（通过scheduler.ExponentialLR），但学习率没有变化。
您认为问题从何而来？
我写了完整的代码...感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/78496983/learning-rate-not-updating</guid>
      <pubDate>Fri, 17 May 2024 16:56:52 GMT</pubDate>
    </item>
    <item>
      <title>我的逻辑回归模型有问题[关闭]</title>
      <link>https://stackoverflow.com/questions/78493918/i-am-having-problem-with-my-logistic-regression-model</link>
      <description><![CDATA[我的模型精度很差。此数据取自 https://archive.ics.uci .edu/dataset/15/breast+cancer+wisconsin+original 显示逻辑回归模型的准确度为 96%，所以问题确实出在我的模型中。我建立了以下模型：
# 导入数据集
tumor_study &lt;- read.csv(“breast-cancer-wisconsin.data”, header = FALSE, na.strings = “NA”)

# 添加列名
特征&lt;-c(“id_number”，“ClumpThickness”，“Uniformity_CellSize”，
              “Uniformity_CellShape”、“边缘粘附”、
              “SingleEpithelial_CellSize”、“BareNuclei”、“Bland_Chromatin”、
              “Normal_Nucleoli”、“Mitoses”、“Class”）

colnames(tumor_study) &lt;- 特征

# 清洗数据
# 删除第一列（id_number）
肿瘤研究 &lt;- 肿瘤研究[,-1]

# 转换“?” BareNuclei 列中为 NA，然后为数字
tumor_study$BareNuclei[tumor_study$BareNuclei == &quot;?&quot;] &lt;- NA
tumor_study$BareNuclei &lt;- as.numeric(tumor_study$BareNuclei)

# 删除 BareNuclei 中缺失值的行
tumor_study &lt;-tumor_study[!is.na(tumor_study$BareNuclei),]

# 将类转换为因子
tumor_study$Class &lt;- 因子(tumor_study$Class, level = c(2, 4), labels = c(“良性”, “恶性”))

# 将数据集分为训练集和测试集
库（caTools）
设置.种子(123)
split &lt;-sample.split(tumor_study$Class, SplitRatio = 0.8)
Training_set &lt;-tumor_study[split == TRUE,]
test_set &lt;-tumor_study[split == FALSE,]

# 应用特征缩放
训练集[, 1:9] &lt;- 比例(训练集[, 1:9])
test_set[, 1:9] &lt;- 比例(test_set[, 1:9])

# 构建逻辑回归模型
分类器 &lt;- glm(公式 = Class ~ ., family = 二项式, data = Training_set)

# 预测训练集的概率
prob_y_train &lt;- 预测（分类器，类型 = &#39;响应&#39;，newdata = Training_set[,-10]）
Predicted_y_training &lt;- ifelse(prob_y_train &gt;= 0.5,“良性”,“恶性”)

# 使用 test_set 进行预测
prob_y_test &lt;- 预测（分类器，类型 = &#39;响应&#39;，newdata = test_set[,-10]）
Predicted_y_test &lt;- ifelse(prob_y_test &gt;= 0.5,“良性”,“恶性”)

# 使用混淆矩阵检查准确性
cm_test &lt;- 表(test_set[,10], Predicted_y_test)
打印（厘米_测试）

但我的准确率接近 2%。
如何找出模型中的问题？]]></description>
      <guid>https://stackoverflow.com/questions/78493918/i-am-having-problem-with-my-logistic-regression-model</guid>
      <pubDate>Fri, 17 May 2024 06:43:30 GMT</pubDate>
    </item>
    <item>
      <title>反馈管理器需要具有单一签名推断的模型</title>
      <link>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</link>
      <description><![CDATA[我在尝试运行机器运行模型时遇到了此错误，该模型应该为驾驶员睡意检测项目提供动力
&lt;前&gt;&lt;代码&gt;W0000 00:00:1715924294.765512 2256 inference_feedback_manager.cc:114]
反馈管理器需要具有单一签名推断的模型。
禁用对反馈张量的支持。

模型架构如下：
&lt;前&gt;&lt;代码&gt;#**型号**
从 keras.layers 导入 BatchNormalization
模型 = tf.keras.models.Sequential()
# 输入形状是所需的图像大小 145 x 145，颜色为 3 字节

#这是第一个卷积
   model.add(Conv2D(16, 3, 激活=&#39;relu&#39;, input_shape=X_train.shape[1:]))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第二次卷积
   model.add(Conv2D(32, 5, 激活=&#39;relu&#39;))
   model.add(BatchNormalization())
   model.add(MaxPooling2D())
   tf.keras.layers.Dropout(0.3)

# 第三次卷积
  model.add(Conv2D(64, 10, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())
  model.add(MaxPooling2D())
  tf.keras.layers.Dropout(0.3)

# 第四次卷积
  model.add(Conv2D(128, 12, 激活=&#39;relu&#39;))
  model.add(BatchNormalization())

# 将结果压平以输入 DNN
  模型.add(压平())
  model.add（密集（128，激活=&#39;relu&#39;））
  模型.add(Dropout(0.25))
  model.add（密集（64，激活=&#39;relu&#39;））
# 只有 1 个输出神经元。
  model.add（密集（1，激活=&#39;sigmoid&#39;））

  model.compile(loss=“binary_crossentropy”，metrics=[“accuracy”]，optimizer=Adam(lr=0.001))
  历史= model.fit（train_generator，epochs = 10，batch_size = 32，validation_data = test_generator）

# 定义服务签名
  输入签名 = [
      tf.TensorSpec(shape=[None, 145, 145, 3], dtype=tf.float32, name=&#39;input_tensor&#39;)
  ]

@tf.function(input_signature=input_signature)
defserving_fn（输入）：
    返回模型（输入）

export_dir = &#39;E:\系统项目\项目&#39;
tf.saved_model.save（serving_fn，export_dir）

# 加载模型进行推理
load_model = tf.saved_model.load(&#39;my_model.keras&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/78493742/feedback-manager-requires-a-model-with-a-single-signature-inference</guid>
      <pubDate>Fri, 17 May 2024 05:59:50 GMT</pubDate>
    </item>
    <item>
      <title>为职位推荐系统选择正确的集成方法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</link>
      <description><![CDATA[我正在开发一个机器学习职位推荐系统，我正在考虑使用集成学习方法。我使用的数据集很全面，包括各种属性，如职位名称、职位描述、薪水、位置和公司详细信息。它包含数字、分类和文本数据的混合。
我计划使用一种结合多种模型和技术的混合方法来提高其性能：
协同过滤或矩阵分解来捕获用户和职位发布之间的交互。
神经网络来处理复杂的数据类型，如职位描述中的文本。
决策树或随机森林具有可解释性和处理数字和分类数据混合的能力。
我正在寻找关于哪种集成方法最适合这项任务的建议。我希望模型能够很好地过滤、灵活处理数据类型、在训练和时间方面具有良好的性能并提供可解释性。
我还没有开始，但我会考虑尝试任何合理的方法！]]></description>
      <guid>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</guid>
      <pubDate>Fri, 10 May 2024 17:51:56 GMT</pubDate>
    </item>
    <item>
      <title>如何将FastAI分类器集成到sklearn VotingClassifier中？</title>
      <link>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</link>
      <description><![CDATA[我有一堆表格数据，我成功地训练了一个 RandomForestClassifier、一个 GradientBoostingClassifier 和一个深度学习模型（来自 fastai 的表格学习器代码&gt;) 与他们一起。我在结果中注意到，每个模型在特定标签上都比其他模型做得更好，每个模型都不同。我想知道是否可以将所有模型放入 VotingClassifier （来自 sklearn 的模型）。我对 RandomForestClassifier 和 GradientBoostingClassifier 没有任何问题，但我没有找到任何有关将表格学习器放入 VotingClassifier 中的信息。可以这样做吗？]]></description>
      <guid>https://stackoverflow.com/questions/78435090/how-to-integrate-fastai-classifier-into-sklearn-votingclassifier</guid>
      <pubDate>Mon, 06 May 2024 07:21:01 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：模块“numpy.linalg._umath_linalg”没有属性“_ilp64”</title>
      <link>https://stackoverflow.com/questions/77451004/attributeerror-module-numpy-linalg-umath-linalg-has-no-attribute-ilp64</link>
      <description><![CDATA[在 google colab 上运行此代码块。 “导入nltk”导致了这个问题。
错误说明：
/usr/local/lib/python3.10/dist-packages/numpy/testing/_private/utils.py 在  中
     55 IS_PYSTON = hasattr(sys, “pyston_version_info”)
     56 HAS_REFCOUNT = getattr(sys, &#39;getrefcount&#39;, None) 不是 None 也不是 IS_PYSTON
---&gt; 57 HAS_LAPACK64 = numpy.linalg._umath_linalg._ilp64
     58
     59 _OLD_PROMOTION = lambda: np._get_promotion_state() == &#39;旧版&#39;

**属性错误：模块“numpy.linalg._umath_linalg”没有属性“_ilp64”**

导入系统
将 numpy 导入为 np
#!pip uninstall -y numpy
#!pip 安装 numpy
!pip 安装安装工具
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
进口警告
导入csv
导入 urllib.parse 作为解析
进口泡菜
!pip卸载-y nltk
!pip 安装 nltk
导入nltk
nltk.download(&#39;punkt&#39;)
从 nltk.tokenize 导入 word_tokenize
从 urllib.parse 导入取消引用

如何纠正同样的问题？
我尝试卸载并重新安装 numpy 和 nltk。我也尝试升级它们，但同样的错误仍然存​​在。]]></description>
      <guid>https://stackoverflow.com/questions/77451004/attributeerror-module-numpy-linalg-umath-linalg-has-no-attribute-ilp64</guid>
      <pubDate>Thu, 09 Nov 2023 06:45:03 GMT</pubDate>
    </item>
    </channel>
</rss>