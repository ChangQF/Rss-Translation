<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 23 Jan 2024 18:18:05 GMT</lastBuildDate>
    <item>
      <title>将 xml 注释与图像链接以创建数据集 [关闭]</title>
      <link>https://stackoverflow.com/questions/77868119/link-xml-annotations-with-images-to-create-dataset</link>
      <description><![CDATA[我在一个文件夹中有一个数据集，该文件夹包含 2 个名为 train 的子文件夹，test 火车内部有两个子文件夹注释（它们是 XML 文件）和图像，它们是没有标签或边界框的数据集的图像，所以我想要将它们链接在一起以获得可以操作和训练模型的数据集
我想要数据集，我可以操作和训练我的模型，注意数据集在我的本地计算机中，并且我计划使用 YOLOv5]]></description>
      <guid>https://stackoverflow.com/questions/77868119/link-xml-annotations-with-images-to-create-dataset</guid>
      <pubDate>Tue, 23 Jan 2024 17:15:41 GMT</pubDate>
    </item>
    <item>
      <title>提取 STA 库中的集群成员资格</title>
      <link>https://stackoverflow.com/questions/77867534/extracting-cluster-membership-in-sta-library</link>
      <description><![CDATA[我一直在 R 中使用拓扑数据分析库进行聚类，称为半监督拓扑分析“STA”。
但是，与我之前用于聚类的许多库不同，没有调用来提取聚类，例如x$cluster。那么，我想知道如何提取诸如聚类分配和轮廓值之类的内容？
下面的代码和链接。
https://tianshufeng.github.io/STA/articles/STA.html 
https://rdrr.io/github/TianshuFeng/SemiMapper /man/mapper.sta.html
#安装和加载

devtools::install_github(“TianshuFeng/STA”)
图书馆（STA）

#虚拟数据

x1 = 重复次数(1:3, 次数 = 100)
x2 = 重复(1:3, 次数 = 100)
x3 = 重复次数(1:3, 次数 = 100)
x4 = 重复(1:3, 次数 = 100)
x5 = 重复(1:3, 次数 = 100)

DAT &lt;- data.frame(x1, x2,x3,x4,x5)
DAT &lt;- data.frame(lapply(DAT, function(x) as.numeric(as.character(x))))

#STA代码

MAP &lt;-mapper.sta(DAT,
                  过滤器值 = DAT$x1,
                  间隔数 = 5,
                  重叠百分比 = 40,
                  dist_method = “曼哈顿”,
                  cluster_method = “分层”,
                  NbClust_cluster_method = &quot;单个&quot;,
                  num_bins_when_clustering = 10,
                  cluster_index = “轮廓”;
）

simple_visNet(MAP, 过滤器 = DAT$x1, color_filter = TRUE)

＃＃＃＃边注
#如果存在带有依赖项的错误消息，请仅运行最后一段代码

cluster_cutoff_at_first_empty_bin &lt;- 函数（高度，直径，num_bins_when_clustering）{
  
  # 如果只有两个点（一个高度值），那么我们就有一个簇
  if (长度(高度) == 1) {
    if (高度 == 直径) {
      截止值 &lt;- Inf
      返回（截止）
    }
  }
  
  bin_breaks &lt;- seq(from=min(heights), to=diam,
                    by=(直径 - 最小(高度))/num_bins_when_clustering)
  if (长度(bin_breaks) == 1) { bin_breaks &lt;- 1 }
  
  myhist &lt;- hist(c(高度，直径)，breaks=bin_breaks，plot=FALSE)
  z &lt;- (myhist$counts == 0)
  如果（总和（z）== 0）{
    截止值 &lt;- Inf
    返回（截止）
  } 别的 {
    # 返回逻辑向量的索引 (z == TRUE)，min 给出最小索引
    截止 &lt;- myhist$mids[ min(which(z == TRUE)) ]
    返回（截止）
  }
  
}
]]></description>
      <guid>https://stackoverflow.com/questions/77867534/extracting-cluster-membership-in-sta-library</guid>
      <pubDate>Tue, 23 Jan 2024 15:41:35 GMT</pubDate>
    </item>
    <item>
      <title>如何更改微调技能中的学习率[关闭]</title>
      <link>https://stackoverflow.com/questions/77867150/how-to-change-the-learn-rate-in-the-fine-tune-skill</link>
      <description><![CDATA[查询：

在特定层将学习率提高十倍的目的：我想了解实现选择背后的基本原理，如果param_group为 True 时，全连接层 (net .fc）设置为默认学习率（learning_rate * 10）的十倍。这种方法有哪些好处和潜在影响？

在此处输入图像描述

动态学习率调整的可行性：是否可以动态调整学习率，例如，通过使用正弦函数在一定范围（例如，从 0 到pi/2）？如何在此代码的上下文中实现这一点，特别是对于不同的层，例如全连接层（接近 pi/2）和卷积层（接近 0） ？
]]></description>
      <guid>https://stackoverflow.com/questions/77867150/how-to-change-the-learn-rate-in-the-fine-tune-skill</guid>
      <pubDate>Tue, 23 Jan 2024 14:48:15 GMT</pubDate>
    </item>
    <item>
      <title>此 MinMaxScaler 实例尚未安装。在使用此估计器之前，使用适当的参数调用“fit”。NotFittedError [关闭]</title>
      <link>https://stackoverflow.com/questions/77866770/this-minmaxscaler-instance-is-not-fitted-yet-call-fit-with-appropriate-argume</link>
      <description><![CDATA[xgb = XGBRegressor(n_estimators=1000，learning_rate=0.01)
xgb.fit(X_train3,y_train1,eval_set=[(X_train3,y_train1),(X_valid3,y_valid1)],early_stopping_rounds=100,verbose=True)
Predicted_results_v = xgb.predict(X_train3)
Predicted_results_t = xgb.predict(X_train3)
Predicted_results_v = Predicted_results_v.reshape(-1,1)
Predicted_results_t = Predicted_results_t.reshape(-1,1)
Predicted_reults_v = scaler1.inverse_transform(predicted_results_v)
Predicted_results_t = 缩放器.inverse_transform(predicted_results_t)

我正在使用 xgboost 库作为股票交易的机器学习模型。为了缩放数据，使用了 MinMaxScaler，但它无法适应数据，因为它引发了错误
NotFittedError：此 MinMaxScaler 实例尚未安装。
在使用此估计器之前，请使用适当的参数调用“fit”。
]]></description>
      <guid>https://stackoverflow.com/questions/77866770/this-minmaxscaler-instance-is-not-fitted-yet-call-fit-with-appropriate-argume</guid>
      <pubDate>Tue, 23 Jan 2024 13:45:59 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试在 vsc 上使用 pip 安装tensorflow，但即使安装后，在运行代码时它也会显示“没有名为‘tensorflow’的模块”[关闭]</title>
      <link>https://stackoverflow.com/questions/77866135/im-trying-to-install-tensorflow-using-pip-on-vsc-but-even-after-installing-o</link>
      <description><![CDATA[所以，我在这里尝试在 vsc 上使用 pip 安装tensorflow，但出现错误，没有名为tensorflow的模块。我尝试重新安装，但显示相同的错误。目前tensorflow所需的python版本是3.8-3.11，我正在使用3.10.10和最新版本的pip。我该如何让它发挥作用？
我想在本地运行它，不想使用虚拟环境，我正在使用 vsc
安装了tensorflow-cpu，但在导入时抛出错误，“没有名为“tensorflow”的模块”。]]></description>
      <guid>https://stackoverflow.com/questions/77866135/im-trying-to-install-tensorflow-using-pip-on-vsc-but-even-after-installing-o</guid>
      <pubDate>Tue, 23 Jan 2024 12:01:38 GMT</pubDate>
    </item>
    <item>
      <title>如何清理存在拼写错误的数据以进行文本分类？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77866039/how-to-clean-my-data-which-has-spelling-errors-for-text-classification</link>
      <description><![CDATA[我的文本数据包含金融句子，其中有很多拼写错误和无意义的单词。我已经做了很多清理工作，但仍然留下一些文字。有什么方法可以帮助纠正我的数据的这种不稳定现象吗？
我已经尝试了所有的清理方法和缩写的处理。但这些就像手动输入]]></description>
      <guid>https://stackoverflow.com/questions/77866039/how-to-clean-my-data-which-has-spelling-errors-for-text-classification</guid>
      <pubDate>Tue, 23 Jan 2024 11:44:15 GMT</pubDate>
    </item>
    <item>
      <title>该模型不断预测同一类[关闭]</title>
      <link>https://stackoverflow.com/questions/77865558/this-model-keeps-predicting-the-same-class</link>
      <description><![CDATA[我编写了一个用于预测药用植物的代码，但它一直预测相同类型的植物（印楝）
即使我的输入不同。
https://colab.research.google.com/drive/1dDmFyach90W7wjWu8mOW1xbOvctRLB3Y ?usp=共享
这是我的代码的链接。
我的数据集
请尽快完成，我有一个项目要到期。
我尝试最小化数据集，就像我在堆栈溢出时看到的那样。
但它一直给出相同的输出。
我希望它能够正确预测叶子的类型。]]></description>
      <guid>https://stackoverflow.com/questions/77865558/this-model-keeps-predicting-the-same-class</guid>
      <pubDate>Tue, 23 Jan 2024 10:25:14 GMT</pubDate>
    </item>
    <item>
      <title>IndexError：数组索引太多：数组是一维的，但在使用多列 y 输入时对 2 个进行了索引</title>
      <link>https://stackoverflow.com/questions/77864377/indexerror-too-many-indices-for-array-array-is-1-dimensional-but-2-were-index</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77864377/indexerror-too-many-indices-for-array-array-is-1-dimensional-but-2-were-index</guid>
      <pubDate>Tue, 23 Jan 2024 06:33:21 GMT</pubDate>
    </item>
    <item>
      <title>AssertionError LLama-cpp-python 模型加载失败</title>
      <link>https://stackoverflow.com/questions/77864368/assertionerror-llama-cpp-python-model-failed-to-load</link>
      <description><![CDATA[即使我使用 GGUF 格式，Llama-cpp-python 也会出现断言错误。
我正在尝试使用 llama-cpp-python 0.1.85 在 python 3.7.2 中运行 AI 模型，每次运行我的代码时都会收到此错误：
加载模型时出错：MapViewOfFile 失败：没有足够的内存资源来处理此命令。

llama_load_model_from_file：加载模型失败
回溯（最近一次调用最后一次）：
  文件“server.py”，第 26 行，位于  中。
    n_ctx=N_CTX,
  文件“D:\AI 2\Venv\lib\site-packages\llama_cpp\llama.py”，第 323 行，位于 __init__ 中
    断言 self.model 不是 None
断言错误

我使用的是 GGUF 格式，所以我不知道问题是什么，它在第二台计算机上运行良好，但在我的主机上运行不佳，有什么帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/77864368/assertionerror-llama-cpp-python-model-failed-to-load</guid>
      <pubDate>Tue, 23 Jan 2024 06:30:48 GMT</pubDate>
    </item>
    <item>
      <title>我使用 Diffusers 来训练 LoRA。训练图像是我的照片，但结果图像不像我</title>
      <link>https://stackoverflow.com/questions/77864227/i-use-diffusers-to-train-lora-training-images-are-my-photos-but-the-result-ima</link>
      <description><![CDATA[这是我的训练代码。
from Accelerate.utils import write_basic_config
write_basic_config()

导入操作系统

os.environ[“MODEL_NAME”] = “runwayml/stable-diffusion-v1-5”
os.environ[“INSTANCE_DIR”] =“/notebooks/me_photos”
os.environ[“OUTPUT_DIR”] =“/notebooks/me_model_1_22”
script_path =“/notebooks/diffusers/examples/dreambooth/train_dreambooth_lora.py”

!加速启动{script_path} \
  --pretrained_model_name_or_path={os.environ[“MODEL_NAME”]} \
  --instance_data_dir={os.environ[“INSTANCE_DIR”]} \
  --output_dir={os.environ[“OUTPUT_DIR”]} \
  --instance_prompt=&quot;Ryan 的照片&quot; \
  --分辨率=512 \
  --train_batch_size=1 \
  --learning_rate=2e-6 \
  --max_train_steps=2400 \
  --gradient_checkpointing \
  --use_8bit_adam \
  --with_prior_preservation \
  --prior_loss_weight=1.0 \
  --class_data_dir=“/notebooks/faces_prior_preservation” \
  --class_prompt=“人脸照片”

这是生成图像的代码。
从扩散器导入 DiffusionPipeline
进口火炬

# 初始化日志记录
导入日志记录
日志记录.basicConfig（级别=日志记录.INFO）
记录器=logging.getLogger()


管道 = DiffusionPipeline.from_pretrained(“runwayml/stable-diffusion-v1-5”,
                                         torch_dtype=torch.float16,
                                         use_safetensors=真，
                                         变体=“fp16”）
管道.to(“cuda”)


pipeline.load_lora_weights（“/notebooks/me_model_1_22”，weight_name =“pytorch_lora_weights.safetensors”，adapter_name =“me”）

active_adapters = pipeline.get_active_adapters()
活动适配器

logger.info(f“LoRA {active_adapters} 加载成功。”)


# 生成图像
提示=“瑞安的照片”
洛拉规模= 1
图像=管道（
    提示，num_inference_steps=30，cross_attention_kwargs={“scale”：lora_scale}
).图片[0]

# 保存图像
输出路径=“/notebooks/image_of_me2.png”
图像.保存（输出路径）
logger.info(f“图像保存在 {output_path}”)

＃ 清理
删除图像
torch.cuda.empty_cache()


]]></description>
      <guid>https://stackoverflow.com/questions/77864227/i-use-diffusers-to-train-lora-training-images-are-my-photos-but-the-result-ima</guid>
      <pubDate>Tue, 23 Jan 2024 05:52:20 GMT</pubDate>
    </item>
    <item>
      <title>部署时ValueError：无法确定Excel文件格式[关闭]</title>
      <link>https://stackoverflow.com/questions/77863886/when-deploy-valueerror-excel-file-format-cannot-be-determined</link>
      <description><![CDATA[我的本​​地计算机上有一个 Excel 工作表，它正在为我的 Streamlit 应用程序提供数据。该应用程序和每个组件在我的本地系统上运行良好。但我在部署时解决了这个问题
ValueError：无法确定 Excel 文件格式，您必须手动指定引擎。

我添加了引擎openpyxl
df = pd.read_excel(f, engine=“openpyxl”).reindex(columns = customer_id).dropna(how=&#39;all&#39;, axis=1)

现在我得到了一个不同的错误：
BadZipFile：文件不是 zip 文件
]]></description>
      <guid>https://stackoverflow.com/questions/77863886/when-deploy-valueerror-excel-file-format-cannot-be-determined</guid>
      <pubDate>Tue, 23 Jan 2024 03:45:05 GMT</pubDate>
    </item>
    <item>
      <title>添加 2 个模型作为另一个模型的输入（图表已断开连接）</title>
      <link>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</link>
      <description><![CDATA[我有两个模型：model_A 和 model_B。我想对这两个模型进行元素明智加法，并将结果用作 model_C 的输入。所以，我有这个代码：
从tensorflow.keras.layers导入Conv2D，BatchNormalization，\
    激活、输入、添加
从tensorflow.keras.models导入模型
将 numpy 导入为 np
将张量流导入为 tf

def model_A（输入）：
    x1 = Conv2D(32, 3, padding=&#39;相同&#39;)(输入)
    x1 = BatchNormalization()(x1)
    x1 = 激活(&#39;relu&#39;)(x1)
    
    x2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(x1)
    模型=模型（输入=输入，输出=x​​2，名称=&#39;model_A&#39;）
    返回模型
    

def model_B（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(32, 3, 填充=&#39;相同&#39;)(f1)

    模型=模型（输入=输入，输出=f2，名称=&#39;model_B&#39;）
    返回模型

def model_C（输入）：
    f1 = Conv2D(32, 3, 填充=&#39;相同&#39;)(输入)
    f1 = BatchNormalization()(f1)
    f1 = 激活(&#39;relu&#39;)(f1)
    
    f2 = Conv2D(16, 3, 填充=&#39;相同&#39;)(f1)
    f2 = BatchNormalization()(f2)
    f2 = 激活(&#39;relu&#39;)(f2)

    f3 = Conv2D(1, 3, 填充=&#39;相同&#39;)(f2)

    模型=模型（输入=输入，输出=f3，名称=&#39;model_C&#39;）
    返回模型
    
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    modelC = model_C（加法）
    
    返回模型（输入，modelC.输出）
    
a = np.random.uniform(0, 1, (100, 32, 32, 3))
b = np.random.uniform(0, 1, (100, 32, 32, 3))
c = np.random.uniform(0, 1, (100, 32, 32, 3))
    
模型 = model_final(32, 32, 3)

优化器 = tf.keras.optimizers.Adam(learning_rate=0.0001)
model.compile(优化器=优化器,
              损失=&#39;mae&#39;,
              指标=[&#39;mae&#39;])
    

如果我运行代码，我会在 Model(inputs=inputs,outputs=f3, name=&#39;model_C&#39;) 处收到Graph Disconnected。所以，为了解决这个问题，我正在做：
def model_final(高度、宽度、通道):
    输入=输入（（高度，宽度，通道））
    
    modelA = model_A(输入)
    modelB = model_B(输入)
    
    加法 = Add()([modelA.output, modelB.output])
    
    input_C = 输入((高度,宽度,32))
    modelC = model_C(输入_C)
    modelC = modelC(加法)
    
    模型=模型（输入，模型C）
    返回模型

编译得很好。但是，我不确定这是否正确。如果这样做的逻辑是正确的！]]></description>
      <guid>https://stackoverflow.com/questions/77859877/addition-of-2-models-as-input-to-another-graph-disconnected</guid>
      <pubDate>Mon, 22 Jan 2024 12:34:03 GMT</pubDate>
    </item>
    <item>
      <title>为什么感知器没有按预期进行训练？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77858926/why-is-the-perceptron-not-training-as-expected</link>
      <description><![CDATA[我试图学习神经网络，并从感知器开始。
我看了一些教程并完全按照它们进行操作，但它对我不起作用。


var canvas = document.querySelector(&#39;canvas&#39;)
画布宽度=内部宽度；
画布高度=内部高度；
var c = canvas.getContext(&#39;2d&#39;)



函数符号（val）{
  如果（值&gt;= 0）{
    返回1
  } 别的 {
    返回-1
  }
}

类感知器{
  构造函数（数字）{
    this.权重 = []
    这个.lr = 0.1

    for (var i = 0; i &lt; num; i++) {
      this.weights.push(Math.random() * 2 - 1)
    }
  }

  猜测（输入）{
    变量总和 = 0
    for (var i = 0; i &lt; this.weights.length; i++) {
      sum += this.weights[i] * 输入[i]
    }
    var 输出 = 符号（总和）
    返回输出
  }

  训练（输入，目标）{
    var 猜测 = this.guess(输入)
    var 错误 = 目标 - 猜测

    for (var i = 0; i &lt; this.weights.length; i++) {
      this.weights[i] += 错误 * 输入[i] * this.lr
    }
  }
}

var Brain = 新感知器(2)

变量点 = []


类点{
  构造函数（x，y）{
    这个.x = x
    这个.y = y
    这个.标签 = 0

    c.线宽=2

    if (this.y &lt; canvas.height / 2) {
      这个.标签 = 1
    } else if (this.y &gt; canvas.height / 2) {
      这个.标签 = -1
    }
  }
  画（） {
    c.beginPath()
    c.arc(this.x, this.y, 10, 0, Math.PI * 2, false)
    c.fill()
    if (this.label == 1) {
      c.中风()
    }
  }
  更新（） {



    this.draw()
  }
}

for (var i = 0; i &lt; 100; i++) {
  point.push(new Point(Math.random() * canvas.width, Math.random() * canvas.height))
}


函数动画（）{
  请求动画帧（动画）
  c.clearRect(0, 0, canvas.width, canvas.height)
  点.forEach(点=&gt;{


    Brain.train([point.x, point.y], point.label)
    var猜测 = Brain.guess([point.x, point.y])
    if (猜测==点.标签) {
      c.fillStyle = &quot;绿色&quot;
    } 别的 {
      c.fillStyle = &quot;红色&quot;
    }
    点.update()
  })
}

动画（）
&lt;代码&gt;* {
  保证金：0；
  填充：0；
}

帆布 {
  位置：绝对；
}




这是我的代码
谁能告诉我这是怎么回事吗？
我的目标是让感知器对点进行分类，其中屏幕一半以上的点应具有 1 的值，而屏幕一半以下的点应具有 -1 的值
它正确预期的点应该用绿色着色，其他点应该用红色着色，但有些球没有变成绿色。
请注意，我在动画函数中使用了训练函数，以便每帧训练网络。]]></description>
      <guid>https://stackoverflow.com/questions/77858926/why-is-the-perceptron-not-training-as-expected</guid>
      <pubDate>Mon, 22 Jan 2024 09:48:47 GMT</pubDate>
    </item>
    <item>
      <title>多种产品的预测模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77857775/forecasting-model-for-multiple-products</link>
      <description><![CDATA[嗨，我是数据科学的一个相对较新的人，我有一个时间序列问题，我必须预测 100 多种产品的销售，并且所有产品都有不同的模式，而且新产品会不断添加，这很困难要单独建模它们，我还必须设置再训练流程，如何简化这个过程，有没有什么方法可以概括模型选择、验证和再训练，而不必每次都单独建模？
我的问题陈述是，当上传产品的销售数据时，我必须实时训练模型并给出预测，如何自动化此过程，而无需手动清理数据、处理缺失值和异常值、选择建模和调整超参数？]]></description>
      <guid>https://stackoverflow.com/questions/77857775/forecasting-model-for-multiple-products</guid>
      <pubDate>Mon, 22 Jan 2024 05:19:57 GMT</pubDate>
    </item>
    <item>
      <title>使用 Scikit-learn 确定 RF 模型中每个类的特征重要性</title>
      <link>https://stackoverflow.com/questions/50201913/using-scikit-learn-to-determine-feature-importances-per-class-in-a-rf-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/50201913/using-scikit-learn-to-determine-feature-importances-per-class-in-a-rf-model</guid>
      <pubDate>Sun, 06 May 2018 16:20:44 GMT</pubDate>
    </item>
    </channel>
</rss>