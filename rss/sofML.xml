<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 23 May 2024 12:26:47 GMT</lastBuildDate>
    <item>
      <title>图像分割-使用python进行无监督学习</title>
      <link>https://stackoverflow.com/questions/78522757/image-segmentation-unsupervised-learning-using-python</link>
      <description><![CDATA[我在kaggle上运行以下代码
img = imread(“/kaggle/input/image-segmentation/ladybug.png”)
x = img.reshape(-1, 3)
kmeans = KMeans(n_clusters=8, random_state=42).fit(x)
segmented_img = kmeans.cluster_centers_[kmeans.labels_]
Segmented_img = Segmented_img.reshape(img.shape)
图 = plt.figure()
ax = Fig.add_subplot(1,2,1)
斧头.imshow(img)

ax = Fig.add_subplot(1,2,2)
ax.imshow(segmented_img)

我得到这个输出。请告诉我为什么我没有获得分割图像。
生成的可视化。]]></description>
      <guid>https://stackoverflow.com/questions/78522757/image-segmentation-unsupervised-learning-using-python</guid>
      <pubDate>Thu, 23 May 2024 11:19:11 GMT</pubDate>
    </item>
    <item>
      <title>如何从电脑屏幕上的 (x,y) 像素点确定 3D 凝视矢量值？</title>
      <link>https://stackoverflow.com/questions/78522525/how-to-determine-3d-gaze-vector-values-from-x-y-pixels-points-on-pc-screen</link>
      <description><![CDATA[我有一个拍摄对象距离屏幕 X 厘米。屏幕尺寸 (S1xS2) 分辨率也是已知的。摄像头位于屏幕顶部中间。屏幕上显示随机点。我也有面部标志检测。
问题是，如何获得人注视位置的 3D 凝视向量？]]></description>
      <guid>https://stackoverflow.com/questions/78522525/how-to-determine-3d-gaze-vector-values-from-x-y-pixels-points-on-pc-screen</guid>
      <pubDate>Thu, 23 May 2024 10:37:40 GMT</pubDate>
    </item>
    <item>
      <title>利用 500 多个拟合模型的预测能力来预测多个并发应用程序用户的输入</title>
      <link>https://stackoverflow.com/questions/78522289/using-the-prediction-power-of-500-fitted-models-for-predicting-the-input-of-mul</link>
      <description><![CDATA[我正在开发一个应用程序，它将同时接收来自多个用户的输入 JSON 对象。我们假设有一个交货时间估算应用程序。另外，我们假设一个 JSON 对象类似于 {“feaure_1”: 0.45, “feature_2”: 1,...}。
我有 1 亿行历史数据，出于内存效率的原因，我将历史数据拆分为 500 个块。因此，它的块有 200k 行。现在，对于每个块，我都训练了一个 RandomForestRegressor() 并将其回归器保存到磁盘，名称为 chunk_{i}_model.joblib。
我的问题是如何利用这 500 个模型（未来可能是 1_000、2_000 甚至更多）的预测能力，使用用户的单个输入进行快速预测。
到目前为止我已经看到了两种方法：
方法 1：平均预测
预测 = np.zeros((1, len(models)))
    对于 i，枚举中的模型（模型）：
        预测[:, i] = model.predict(json_input)
    返回 np.mean(预测，轴=1)

此方法将迭代每个保存的模型（因此，迭代 500 次），将生成 500 个交付时间结果，对结果进行平均并向用户返回响应。

优点：内存使用量较少
缺点：等待响应的空闲时间较长。 （执行 500 多次迭代 + 从磁盘读取每个模型的时间）。

方法 2：使用前 20 个模型。
我有一个 JSON 元数据文件，用于记录测试数据的模型名称和 RMSE 分数。同样，测试数据位于每个块内（每个块 200_000 行 -&gt; 170_000 训练，30_000 测试）。我可以过滤前 20 个 RMSE 分数，并使用这些前 20 个模型进行平均方法。

优点：执行速度更快，因为仅迭代 20 个模型。
缺点：当我使用所有 500 个模型时（在方法 1 中），在 20*200_000 = 4_000_000 条记录上训练的 20 个模型的预测可能会错过 100_000_000 条记录中的模式。

我可以使用其他方法来有效应对这一软件开发挑战吗？我正在尝试开发一种解决方案，该解决方案可以使用 Python（而不是 Spark）针对许多模型和来自多个用户的请求进行扩展。此外，使用 VotingRegressor() 或元堆栈方法也是不可能的，因为我每次都必须重新调整数据。我正在寻找的解决方案将使用已安装在较小的原始数据块中的模型，直到使用所有 1 亿条历史记录。]]></description>
      <guid>https://stackoverflow.com/questions/78522289/using-the-prediction-power-of-500-fitted-models-for-predicting-the-input-of-mul</guid>
      <pubDate>Thu, 23 May 2024 09:54:41 GMT</pubDate>
    </item>
    <item>
      <title>AIF360 我是否使用 BinaryLabel 或 StandardDataset 作为自定义数据集/数据框？</title>
      <link>https://stackoverflow.com/questions/78522103/aif360-do-i-use-binarylabel-or-standarddataset-for-a-custom-dataset-dataframe</link>
      <description><![CDATA[我有一个自定义数据集，已将其加载到数据框中，并且希望使用 AIF360 进行公平的机器学习。
我总是使用 pandas 的 get_dummies() 方法对分类特征进行 one-hot 编码。
现在，我是否必须将 BinaryLabelDataset 类用于 one-hot 编码数据，而 StandardDataset 类也用于自定义数据集，但尚未进行 one-hot 编码？
基本上，我不确定在哪种情况下使用哪个类（对于一个热编码的数据帧 = BinaryLabelDataset？ - 对于没有转换的数据帧 = StandardDataset？）
我阅读了 AIF360 的文档和 API 参考指南。但是，我不太清楚应该使用哪一个。
我知道 BinaryLabelDataset 类是基于 StandardDataset 类构建的。
另外，StandardDataset类还可以做一些数据转换。
另外，我还可以使用与 sklearn 兼容的 API。]]></description>
      <guid>https://stackoverflow.com/questions/78522103/aif360-do-i-use-binarylabel-or-standarddataset-for-a-custom-dataset-dataframe</guid>
      <pubDate>Thu, 23 May 2024 09:22:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在不执行代码的情况下计算代码的递归深度/循环深度？</title>
      <link>https://stackoverflow.com/questions/78521967/how-to-calculate-recursion-depth-loop-depth-of-a-code-without-executing-it</link>
      <description><![CDATA[我正在尝试构建一个模型，该模型能够从静态变量（例如行数、函数数量、复杂性等）推断出动态指标，例如内存分配、GPU 消耗和 CPU 消耗。 
我想到的一个问题是如何将输入作为静态特征包含在这个模型中（我认为这是一个非常相关的变量）
以阶乘函数为例：
&lt;前&gt;&lt;代码&gt;结果 = 1
  对于范围 (1, 8 + 1) 内的 i：
     结果*=我
  返回结果

结果 = 1
  对于范围 (1, 80000 + 1) 内的 i：
     结果*=我
  返回结果

在此示例中，第二个代码的执行时间比第一个代码长得多。这种差异对于人眼来说是显而易见的，但如何才能静态地使模型变得明显呢？我指的是一个可以理解输入参数影响的通用模型。这可以在不执行代码的情况下实现吗？]]></description>
      <guid>https://stackoverflow.com/questions/78521967/how-to-calculate-recursion-depth-loop-depth-of-a-code-without-executing-it</guid>
      <pubDate>Thu, 23 May 2024 08:58:11 GMT</pubDate>
    </item>
    <item>
      <title>实施机器学习模型来评估成绩并根据教育流数据库选择继续教育路径的最简单方法是什么？</title>
      <link>https://stackoverflow.com/questions/78521362/what-is-the-easiest-way-to-implement-a-ml-model-to-evaluate-grades-and-choose-th</link>
      <description><![CDATA[要实施用于评估学生成绩和推荐教育途径的机器学习模型，首先要收集和预处理数据，包括成绩、课外活动和学生兴趣。对数据进行标准化和编码，然后将其分为训练集和测试集。选择并训练适当的模型，例如决策树或随机森林，并使用准确性和 F1 分数等指标评估其性能。使用用户友好的界面部署模型，以提供实时建议并确保遵守数据隐私法。利用新数据和反馈不断改进模型，解决任何偏差以保持公平性和准确性。
期望基于全面的数据分析，提供准确、公正的指导。目标是创建一个用户友好的实时推荐系统，通过新数据和反馈不断改进，同时确保数据隐私并解决潜在偏见。]]></description>
      <guid>https://stackoverflow.com/questions/78521362/what-is-the-easiest-way-to-implement-a-ml-model-to-evaluate-grades-and-choose-th</guid>
      <pubDate>Thu, 23 May 2024 06:46:07 GMT</pubDate>
    </item>
    <item>
      <title>寻找特定于移动设备的二进制文件的数据集</title>
      <link>https://stackoverflow.com/questions/78521260/seeking-dataset-of-mobile-specific-binaries</link>
      <description><![CDATA[我目前正在训练机器学习模型，并需要特定于移动设备的二进制文件的数据集。尽管我付出了努力，但我仍然无法找到大量的数据集。
向我建议的另一种选择是从 AOSP 批量下载二进制文件，但我不确定如何开始此过程。]]></description>
      <guid>https://stackoverflow.com/questions/78521260/seeking-dataset-of-mobile-specific-binaries</guid>
      <pubDate>Thu, 23 May 2024 06:19:48 GMT</pubDate>
    </item>
    <item>
      <title>如何使用权重和偏差 wandb 扫描实现多处理以实现最大并行化，特别是计数变量在此设置中如何工作？</title>
      <link>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78521104/how-to-implement-multiprocessing-with-weights-and-biases-wandb-sweeps-for-maximu</guid>
      <pubDate>Thu, 23 May 2024 05:25:30 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 if 条件将两个 scikit-learn 子模型组合成一个集成并将其保存到 pickle 文件中？</title>
      <link>https://stackoverflow.com/questions/78520659/how-to-combine-two-scikit-learn-sub-models-into-an-ensemble-using-an-if-conditio</link>
      <description><![CDATA[我使用 IF 条件训练了两个 scikit-learn 模型（根据 X1 功能定义的标准生成了两个训练集）。如何将这个 if 条件与这两个经过训练的模型集成到一个单个整体模型中并将其保存到 pickle 文件中？]]></description>
      <guid>https://stackoverflow.com/questions/78520659/how-to-combine-two-scikit-learn-sub-models-into-an-ensemble-using-an-if-conditio</guid>
      <pubDate>Thu, 23 May 2024 02:12:38 GMT</pubDate>
    </item>
    <item>
      <title>matplotlib 未在 macOS Sonoma VS code 上正确安装 [已关闭]</title>
      <link>https://stackoverflow.com/questions/78519268/matplotlib-not-installing-correctly-on-macos-sonoma-vs-code</link>
      <description><![CDATA[在此处输入图片描述
我安装的所有其他模块导入正常，但 matplotlib 返回警告。我用了
pip3 install matplotlib 以便安装它，感谢您的帮助！
这是错误导入“matplotlib”无法从源代码解决]]></description>
      <guid>https://stackoverflow.com/questions/78519268/matplotlib-not-installing-correctly-on-macos-sonoma-vs-code</guid>
      <pubDate>Wed, 22 May 2024 17:58:55 GMT</pubDate>
    </item>
    <item>
      <title>如何学习如何在 React 和 JS 中创建搜索 + 机器学习推荐算法？</title>
      <link>https://stackoverflow.com/questions/78519224/how-can-i-learn-how-to-create-a-searching-machine-learning-recommender-algorit</link>
      <description><![CDATA[我目前正在启动我的 A level 计算机科学 NEA 项目，并希望基本上构建 supercook 的克隆 在用户登录的地方，输入他们拥有的成分，应用程序将向他们显示从网上找到的食谱。然后我想实现一个机器学习方面，用户可以根据他们喜欢的程度对食谱进行评分，并且算法将调整向用户提供的推荐食谱。我要到四月份才能完成这个项目（我仍然会在学习所有其他科目的同时完成这个项目，所以没有无限的空闲时间）。
我该如何学习使用 React + javascript 以及如何学习如何创建显示菜谱的算法以及机器学习方面的内容？我对这个项目有所有的想法，以及我希望它如何运作，我只是希望有人指导我去哪里学习。  那么您认为在 Brain.js 或 Tensorflow.js 之类的东西中从头开始进行所有机器学习是否可行？或者尝试将预先存在的推荐算法适应我的应用程序会更好吗？如果是这样，我将如何解决这个问题？请记住，我的 javascript + React 知识非常有限，因此我正在从头开始学习这些知识，并且几乎没有机器学习知识。
我一直在对这些主题进行大量搜索，但由于我对这些类型的算法、推荐系统和机器学习的了解有限，我不太清楚我在做什么，所以需要一个清晰的解释和一些指导关于去哪里和做什么将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78519224/how-can-i-learn-how-to-create-a-searching-machine-learning-recommender-algorit</guid>
      <pubDate>Wed, 22 May 2024 17:47:47 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的分段好像没有被保存？关于totalsegmentator</title>
      <link>https://stackoverflow.com/questions/78516029/why-my-segmentations-dont-seem-to-be-saved-about-totalsegmentator</link>
      <description><![CDATA[我一步步按照你的教程操作，但得到的结果是“分段未保存”
这是我输入的语句和得到的结果：
(d:\totalsegmentotar.conda) D:\totalsegmentotar&gt;TotalSegmentator -i hip_left.nii.gz -o 分段 -ta hip_implant

如果您使用此工具，请引用：https://pubs.rsna.org/doi/10.1148/ryai.230024

未检测到 GPU。在CPU上运行。这可能会非常慢。 &#39;--fast&#39; 或 --roi_subset 选项可以帮助减少运行时间。
生成粗糙的身体分割...
重新采样...
1.93 秒内重新采样
预测...
d:\totalsegmentotar.conda\Lib\site-packages\nnunetv2\utilities\plans_handling\plans_handler.py:37: UserWarning: 检测到旧的 nnU-Net 计划格式。尝试重构网络架构参数。如果失败，请为您的数据集重新运行 nnUNetv2_plan_experiment。如果您使用自定义架构，请将 nnU-Net 降级到您实现的版本或更新您的实现+计划。
warnings.warn(“检测到旧的 nnU-Net 计划格式。尝试重建网络架构”
100%|███████████████████████████████████████████████ ███████████████████████████████████████████████████ ███████████████████████████████████████████████████ ██| 1/1 [00:00&lt;00:00, 1.12it/s]
预测12.95秒后
重新采样...
警告：无法裁剪，因为未检测到前景
从 (333, 333, 539) 裁剪到 (333, 333, 539)
预测...
d:\totalsegmentotar.conda\Lib\site-packages\nnunetv2\utilities\plans_handling\plans_handler.py:37: UserWarning: 检测到旧的 nnU-Net 计划格式。尝试重构网络架构参数。如果失败，请为您的数据集重新运行 nnUNetv2_plan_experiment。如果您使用自定义架构，请将 nnU-Net 降级到您实现的版本或更新您的实现+计划。
warnings.warn(“检测到旧的 nnU-Net 计划格式。尝试重建网络架构”
100%|███████████████████████████████████████████████ ███████████████████████████████████████████████████ ███████████████████████████████████████████████████ | 64/64 [04:27&lt;00:00, 4.18s/it]
预测 288.96 秒
保存分段...
0%| | 0/1 [00:00
可以看到分割没有保存，我用切片器软件看确实没有预测结果，什么也没有显示。
当我使用`-tatotal时，分割器进度条发生变化，但不幸的是它似乎没有保存分割的结果。这是我的输出，以及在切片器 5.6.2 中打开的输出文件夹和图像，但没有显示任何内容。
抱歉，我是新手，还不能显示图片，如果您看到了，请打开链接。
这是我的 powershell 输出
她是我的输出文件夹，并且是在切片器 5.6.2 中打开的图像]]></description>
      <guid>https://stackoverflow.com/questions/78516029/why-my-segmentations-dont-seem-to-be-saved-about-totalsegmentator</guid>
      <pubDate>Wed, 22 May 2024 07:52:18 GMT</pubDate>
    </item>
    <item>
      <title>对数核和指数激活的非线性关系模型准确率无法达到 100%</title>
      <link>https://stackoverflow.com/questions/78514097/model-accuracy-for-non-linear-relationship-with-logarithm-kernel-and-exponential</link>
      <description><![CDATA[我正在开展一个项目，需要使用神经网络对非线性关系进行建模。关系为 ( y = 3x_1^2x_2^3 )。网络设置如下：

预处理：输入的自然对数
网络设计：单层，一个神经元
激活函数：指数
损失函数：MAE（平均绝对误差）
优化器： Adam
纪元：50
批量大小：32

输入和预期输出：

输入：([x1, x2])
正确权重：([2, 3])
正确的偏差：(\ln 3)

尽管有这些设置，我仍无法达到 100% 的准确度。我尝试过随机初始化权重和偏差以及使用特定值。
这是代码：
将 numpy 导入为 np
将张量流导入为 tf
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从tensorflow.keras.optimizers导入Adam

# 生成数据
x1 = np.random.randint(1, 21, 大小=(1000, 1))
x2 = np.random.randint(1, 21, 大小=(1000, 1))
y = 3 * (x1 ** 2) * (x2 ** 3)

# 预处理数据
log_x1 = np.log(x1)
log_x2 = np.log(x2)
log_inputs = np.hstack((log_x1, log_x2))

# 定义模型
模型=顺序（）
model.add（密集（1，input_dim = 2，激活=&#39;指数&#39;，kernel_initializer =&#39;ones&#39;，bias_initializer =&#39;zeros&#39;））

# 编译模型
model.compile(优化器=Adam(learning_rate=0.01), loss=&#39;mae&#39;)

# 训练模型
model.fit（log_inputs，np.log（y），epochs = 50，batch_size = 32）

# 评估模型
test_x1 = np.array([[2], [4], [5]])
test_x2 = np.array([[3], [7], [19]])
test_inputs = np.hstack((np.log(test_x1), np.log(test_x2)))
预测 = model.predict(test_inputs)
print(np.exp(预测))

有人对如何提高该模型的准确性有建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78514097/model-accuracy-for-non-linear-relationship-with-logarithm-kernel-and-exponential</guid>
      <pubDate>Tue, 21 May 2024 19:54:48 GMT</pubDate>
    </item>
    <item>
      <title>获取“ValidationError：VectorstoreIndexCreator 嵌入的 1 个验证错误”</title>
      <link>https://stackoverflow.com/questions/78112934/getting-validationerror-1-validation-error-for-vectorstoreindexcreator-embeddi</link>
      <description><![CDATA[我正在尝试构建一个 pdf 聊天机器人，您可以在其中上传 pdf 并询问与 pdf 相关的问题。为此，我正在考虑基于 RAG 的应用程序。所以我想为我的输入 pdf 创建矢量嵌入，但是当我这样做时，
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
embed_model = HuggingFaceEmbedding(model_name=“BAAI/bge-small-en-v1.5”)
index_creator = VectorstoreIndexCreator(
    矢量store_cls = 卡桑德拉，
    嵌入=嵌入模型，
    text_splitter = RecursiveCharacterTextSplitter(
        块大小 = 400,
        块重叠 = 30
    ),

    矢量store_kwargs={
        &#39;会话&#39;：会话，
        &#39;键空间&#39;：键空间，
        &#39;表名&#39;：表名
    }
）

我收到验证错误。
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ValidationError Traceback（最近一次调用最后一次）
&lt;ipython-input-17-b83dc7fd1587&gt;在&lt;细胞系：4&gt;()
      2 keyspace = “pdf_qa_name”
      3 
----&gt; 4 index_creator = VectorstoreIndexCreator(
      5 矢量store_cls = 卡桑德拉，
      6 嵌入 = embed_model,

/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py 在 __init__(__pydantic_self__, **data)
    第 339 部分
    第340章
--&gt;第341章
    第342章
    第343章

ValidationError：VectorstoreIndexCreator 出现 1 个验证错误
嵌入
  预期 Embeddings 的实例（type=type_error.任意_type；expected_throtary_type=Embeddings）

有什么想法吗？
尝试了 2 个不同的模型（Jina 和 BAAI/bge）。错误不会继续。我正在使用 open ai gpt 3.5 api。]]></description>
      <guid>https://stackoverflow.com/questions/78112934/getting-validationerror-1-validation-error-for-vectorstoreindexcreator-embeddi</guid>
      <pubDate>Wed, 06 Mar 2024 08:47:33 GMT</pubDate>
    </item>
    <item>
      <title>如何将极坐标数据框与 scikit-learn 一起使用？</title>
      <link>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</link>
      <description><![CDATA[我无法使用 polars 数据框和 scikit-learn 进行 ML 训练。
目前，我正在预处理 polars 中的所有数据框，并将它们转换为 pandas 进行模型训练，以使其正常工作。
有没有方法可以直接将 polars 数据框和 scikit-learn API 一起使用（无需先转换为 pandas）？]]></description>
      <guid>https://stackoverflow.com/questions/74398563/how-to-use-polars-dataframes-with-scikit-learn</guid>
      <pubDate>Fri, 11 Nov 2022 05:59:55 GMT</pubDate>
    </item>
    </channel>
</rss>