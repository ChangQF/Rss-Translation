<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 02 Oct 2024 18:23:31 GMT</lastBuildDate>
    <item>
      <title>为什么 tf.keras.models.load_model 要重新构建模型？</title>
      <link>https://stackoverflow.com/questions/79047845/why-is-the-tf-keras-models-load-model-building-the-model-again</link>
      <description><![CDATA[ValueError: 顺序模型“sequential_2”已配置为使用
输入形状（None、224、224、3）。您无法使用 input_shape [None、224、224、3] 构建它

def load_model(model_path):
&quot;&quot;&quot;
从指定路径加载已保存的模型。
&quot;&quot;&quot;

tf.keras.config.enable_unsafe_deserialization()
print(f&quot;正在加载已保存的模型：{model_path}&quot;)
model = tf.keras.models.load_model(model_path)
return model

loaded_1000_image_model = load_model(&#39;/content/drive/MyDrive/Dog Vision/models/20241002-16491727887796-1000-images-mobilenetv2-Adam.h5&#39;)

我原本以为它会加载模型而不会出现任何错误，但由于某种原因，它给出了一个值错误，尽管我没有尝试重建或再次给出任何输入形状。]]></description>
      <guid>https://stackoverflow.com/questions/79047845/why-is-the-tf-keras-models-load-model-building-the-model-again</guid>
      <pubDate>Wed, 02 Oct 2024 17:18:38 GMT</pubDate>
    </item>
    <item>
      <title>我的模型目前存在多少过度拟合问题？</title>
      <link>https://stackoverflow.com/questions/79047127/how-much-of-an-overfitting-issue-do-my-models-currently-have</link>
      <description><![CDATA[我正在使用三个机器学习模型 - 逻辑回归、梯度提升和深度神经网络 - 使用相对简单的数据集和使用“sklearn”的机器学习模型模板。我获得的性能指标似乎很强，但我的老师提到了过度拟合的可能性，因为测试准确率略低于训练准确率。此外，它是一种二元分类。
我进行了 5 倍交叉验证，交叉验证分数非常接近我的模型准确率。但是，我仍然不确定这是否表示过度拟合，或者我的模型是否按预期运行。
以下是每个模型的结果：
逻辑回归：
测试准确率：97.69%
训练准确率：98.15%
平均交叉验证得分：97.97%
梯度提升：
测试准确率：97.98%
训练准确率：98.79%
平均交叉验证得分：97.97%
深度神经网络：
测试准确率：97.49%
训练准确率： 98.23%
平均交叉验证得分：97.92%
我是否可以得出结论：尽管可能存在轻微的过度拟合，但模型对于分类仍然有效，并且所使用的特征可能对于对目标进行分类非常有用？]]></description>
      <guid>https://stackoverflow.com/questions/79047127/how-much-of-an-overfitting-issue-do-my-models-currently-have</guid>
      <pubDate>Wed, 02 Oct 2024 14:05:29 GMT</pubDate>
    </item>
    <item>
      <title>构建电子邮件解析、数据提取和数据验证的系统[关闭]</title>
      <link>https://stackoverflow.com/questions/79047083/build-a-system-for-email-parsing-and-data-extraction-and-data-validation</link>
      <description><![CDATA[我正在为 B2B 匹配平台开发 MVP。核心思想是根据客户的需求和能力自动将客户与服务提供商配对。以下是我想要实现的目标：

从收到的电子邮件中提取数据（客户要求和服务提供商详细信息）：非结构化数据（客户和服务提供商之间的沟通没有标准）
以可用的格式构造这些数据
将这些结构化数据用于智能匹配系统

目前，我正在使用 OpenAI 的 API（gpt4-* 模型）来处理电子邮件解析和数据提取。虽然它在大多数情况下都能正常工作，但我担心它在生产环境中的稳健性和可靠性：有时，我会出现幻觉。
我的问题是：对于这种任务，有没有比这种方法更强大的替代方案？我正在寻找能够实现以下功能的东西：

可靠地解析电子邮件并提取相关信息
处理大量电子邮件
提供一致且易于使用的结构化输出

我只接受开源解决方案。
我尝试过的方法：

使用 OpenAI API 模型从非结构化数据中提取关键信息，但我仍然有幻觉。

我还需要一种实时构造数据的方法。]]></description>
      <guid>https://stackoverflow.com/questions/79047083/build-a-system-for-email-parsing-and-data-extraction-and-data-validation</guid>
      <pubDate>Wed, 02 Oct 2024 13:55:12 GMT</pubDate>
    </item>
    <item>
      <title>我可以采取下一步措施来制作一个好的图像重复和接近重复查找器[关闭]</title>
      <link>https://stackoverflow.com/questions/79046818/next-steps-i-can-take-to-make-a-good-image-duplicate-and-near-duplicate-finder</link>
      <description><![CDATA[我正在尝试制作一个可以查找图像重复和近似图像重复的应用程序，以便从您的图像库中查找相似的照片。我有一个 NAS 设置，里面有大约 30-40gb 的图像，其中很多图像都有我和我的家人拍摄的多张类似图像。
对于我当前的实现，我可以拍摄 2 幅图像，从中提取嵌入（使用 CLIP 库），比较它的余弦相似度（对于精确重复）和欧几里得距离（对于压缩重复，如从聊天中下载的图像或图像的屏幕截图）。
我如何进一步推进这个项目并制作更好的应用程序？我目前的实现如下所示：
main.py
从 PIL 导入图像
导入 torch
导入 numpy 作为 np
导入 cv2 作为 cv
导入 clip
从 sklearn.cluster 导入 KMeans

设备 = &quot;cpu&quot;
image_path = &quot;assets/photos/aayush.jpeg&quot;
image_path2 = &quot;assets/photos/aayushResized.png&quot;

# 加载 CLIP 模型和预处理函数
model, preprocess = clip.load(&quot;ViT-L/14&quot;, device, jit=False)

# 预处理图像并添加批处理维度
image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
image2 = preprocess(Image.open(image_path2)).unsqueeze(0).to(device)

print(&quot;处理后的图像数据类型为：&quot;, type(image))

def calculate_distance(embedding1, embedding2):
&quot;&quot;&quot; 计算两幅图像之间的欧几里得距离 &quot;&quot;&quot;
dist = torch.nn. functional.pairwise_distance(embedding1, embedding2)
return (dist)

def calculate_cosine_similarity(embedding1, embedding2):
&quot;&quot;&quot; 计算 2 个图像嵌入之间的余弦相似度 &quot;&quot;&quot;
return torch.nn. functional.cosine_similarity(embedding1, embedding2)

def resize_with_aspect_ratio(raw_image_path, new_width):
# 读取原始图像
original_image = cv.imread(raw_image_path)

# 计算纵横比
aspects_ratio = original_image.shape[1] / original_image.shape[0]

# 根据所需宽度确定新高度
determined_height = int(new_width / aspects_ratio)

# 调整图像大小
resized_image = cv.resize(original_image, (new_width, determined_height))
print(&quot;Newly Resized images shape: &quot;, resized_image.shape)
cv.imshow(&quot;Screen&quot;, resized_image)
cv.imwrite(&quot;aayushResized.png&quot;, resized_image)
cv.waitKey(0)
cv.destroyAllWindows()

return resized_image

def normalize(image):
# 计算每个通道的标准差
channel_stds = np.std(image, axis=(0, 1))
print(channel_stds)
# 通过将图像除以通道标准差来进行归一化
normalized_image = image / channel_stds
return (normalized_image)

def clutster(image):
kmeans = KMeans(n_clusters=2, random_state=0, n_init=&quot;auto&quot;).fit(X)

# 从模型中获取图像嵌入

with torch.no_grad():
emb1 = model.encode_image(image)
emb2 = model.encode_image(image2)

print(&quot;嵌入的数据类型为：&quot;, type(emb1), &quot;And &quot;, type(emb2))
# print(emb1, &quot;\n &quot;, emb2)

# 计算嵌入之间的余弦相似度
similarity = calculate_cosine_similarity(emb1, emb2)
distance = calculate_distance(emb1, emb2)

print(f&quot;余弦相似度：{similarity.item()} {type(similarity)}&quot;)
print(f&quot;欧几里得距离：{distance.item()} {type(similarity)}&quot;)


cluster.py
# 使用聚类算法 [k means] 将张量聚类在一起：
import os
import torch
import clip
from PIL import Image
import numpy as np
from sklearn.cluster import KMeans

device =“CPU”
model, preprocess = clip.load(&quot;ViT-L/14&quot;, device, jit=False)
# labels = [&quot;a&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;c&quot;, &quot;d&quot;]
name_list = []
np_array = []

# 循环遍历图像文件夹
for photos in os.listdir(&quot;assets/photos&quot;):
image_path = os.path.join(&quot;assets/photos&quot;, photos)
# 预处理图像并获取其张量
image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
name_list.append(photos)
# 将张量的高维展平为类似2dim
numpyImage = np.array(image).flatten()
np_array.append(numpyImage)

k = 3
kmeans = KMeans(n_clusters=k, random_state=42)
kmeans.fit(np_array)

# 获取 int 类标签（由 KMeans 自动生成）
cluster_labels = kmeans.labels_
image_cluster_map = {}
# 循环遍历图像并为其赋予标签
for i, labels in enumerate(cluster_labels):
# print(f&quot;Image {i} 属于集群 {labels}&quot;)
image_cluster_map[f&#39;image_{name_list[i]}&#39;] = labels

# 查看我们的最终集群
for i, (key, value) in enumerate(image_cluster_map.items()):
print(key, &quot;标记为：“，值）

]]></description>
      <guid>https://stackoverflow.com/questions/79046818/next-steps-i-can-take-to-make-a-good-image-duplicate-and-near-duplicate-finder</guid>
      <pubDate>Wed, 02 Oct 2024 12:49:21 GMT</pubDate>
    </item>
    <item>
      <title>体育比赛结果的机器学习算法[关闭]</title>
      <link>https://stackoverflow.com/questions/79045323/algorithm-for-machine-learning-on-sports-results</link>
      <description><![CDATA[我正在尝试学习 ML 的基础知识（通过使用 ML.NET），但未能让模型真正产生任何可用的东西。目前，我不知道我是否真正理解了什么是“特征”或任何其他东西（标签除外）。
这没有帮助，因为大多数示例都很糟糕，并且不断改变事物的名称（我假设特征/组件/类别等）有时是同一个东西。
多年来，我有大量来自体育赛事的数据，需要通过算法来查找可能不正确的结果。
实际上，我们有年龄/种族类型/距离/性别/路线类型和结果时间。它需要是一个无监督模型（我们没有干净的训练数据）。我们需要在训练后反馈数据，以找到可能错误的值，以便对其进行检查。
此后，该模型将用于检查输入的新结果。
最好的算法是什么，哪种工具可以运行它。此时，我们已经决定 ML.NET 可能无法满足我们的要求。
ML.NET RandomizedPCA，回归算法。将测试值输入生成的模型只会产生奇怪的结果。]]></description>
      <guid>https://stackoverflow.com/questions/79045323/algorithm-for-machine-learning-on-sports-results</guid>
      <pubDate>Wed, 02 Oct 2024 04:08:16 GMT</pubDate>
    </item>
    <item>
      <title>为什么即使我设置了随机状态，我的 RF 中的准确度分数也会发生变化？</title>
      <link>https://stackoverflow.com/questions/79045081/why-do-accuracy-scores-vary-in-my-rf-even-though-i-set-the-random-state</link>
      <description><![CDATA[我正在使用 scikit 学习随机森林，如果我再次运行分析，准确度得分除了最后几位数字外基本保持不变。这是我应该担心的事情吗？还是我可能对随机状态的处理有误？我在下面粘贴了我的操作方法：
rf = RandomForestClassifier(random_state=42)

这是我在代码开头所做的，然后我做了类似的事情：
# 准备用于交叉验证的变量
X = df[included_columns] # 特征
y = df[&#39;strategy_encoded&#39;] # 目标变量

# 识别每个策略的参与者
unique_strategies = df[&#39;strategy&#39;].unique()
strategy_participants = {strategy: df[df[&#39;strategy&#39;] == strategies][&#39;participant_number&#39;].unique() for strategies in unique_strategies}

# 生成用于交叉验证的参与者组合
participant_combinations = list(product(*strategy_participants.values()))

# 初始化结果列表
accuracies = []
training_accuracies = []
confusion_matrices = []
classification_reports = []

# 使用参与者组合进行交叉验证
for combo in contest_combinations:
# 根据参与者组合进行训练-测试拆分
test_indices = df[df[&#39;participant_number&#39;].isin(combo)].index
train_indices = df[~df.index.isin(test_indices)].index

X_train, X_test = X.loc[train_indices], X.loc[test_indices]
y_train, y_test = y.loc[train_indices], y.loc[test_indices]

# 训练模型
rf = RandomForestClassifier()
rf.fit(X_train, y_train)

# 训练准确率
y_train_pred = rf.predict(X_train)
train_accuracy = accuracy_score(y_train, y_train_pred)
training_accuracies.append(train_accuracy)

# 测试准确率
y_pred = rf.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
accuracies.append(test_accuracy)

# 混淆矩阵和分类报告
conf_matrix = chaos_matrix(y_test, y_pred)
chaos_matrices.append(conf_matrix)

class_report = classes_report(y_test, y_pred, output_dict=True)
classes_reports.append(class_report)

# 计算各折叠的平均结果
average_test_accuracy = np.mean(accuracies)
average_training_accuracy = np.mean(training_accuracies)
average_conf_matrix = np.mean(confusion_matrices, axis=0)

# 输出结果
print(&quot;平均测试准确率：&quot;, average_test_accuracy)
print(&quot;平均训练准确率：&quot;, average_training_accuracy)
print(&quot;平均混淆矩阵:\n&quot;, average_conf_matrix)
]]></description>
      <guid>https://stackoverflow.com/questions/79045081/why-do-accuracy-scores-vary-in-my-rf-even-though-i-set-the-random-state</guid>
      <pubDate>Wed, 02 Oct 2024 00:49:50 GMT</pubDate>
    </item>
    <item>
      <title>是不是只有我一个人觉得 Python 模块的设置简直就是一场噩梦？[关闭]</title>
      <link>https://stackoverflow.com/questions/79044839/is-it-just-me-or-are-python-modules-a-nightmare-to-setup</link>
      <description><![CDATA[我最近改用 Python 来探索 ML 和 AI。我使用 Linux Mint 和 Jupyter 笔记本来处理 Python。所以我安装了 Tensorflow、TFlearn 和 six.moves，以及感觉像二十或两个其他模块。我尝试运行以下命令，
from __future__ import absolute_import, division, print_function

import os
import pickle
from six.moves import urllib

import tflearn
from tflearn.data_utils import *

我得到
AttributeError：模块“PIL.Image”没有属性“ANTIALIAS”

当我运行它时。所以我试着研究它，你知道在我问问题之前试着做一个好孩子，似乎枕头模块不再受支持或该功能已弃用。我怎样才能让 tflearn 工作？
所以我尝试了不同的方法，我尝试使用 langchain 在本地运行 huggingface。我安装了模块并运行代码，结果出现有关未安装模块的错误。所以我会安装该模块并再次运行代码，结果却出现有关未安装模块的另一个错误。所以我安装了那个模块，重新运行代码，结果却出现另一个错误。最后我让这些行运行起来
from langchain.llms import HuggingFacePipeline
from langchain import PromptTemplate, LLMChain

在让上述代码最终运行后，我尝试了以下操作。这都是我尝试遵循的教程中的内容。
model_id = &quot;lmsys/fastchat-t5-3b-v1.0&quot;
llm = HuggingFacePipeline.from_model_id(
model_id=model_id,
task=&quot;text2text-generation&quot;,
model_kwargs={&quot;temperature&quot;: 0, &quot;max_length&quot;: 1000},
)

我遇到了大量的属性错误和异常。T 尝试了另一种方式来使用本地 LLM 并安装了 Dalai Llama 下载了 13b 羊驼模型，然后通过端口将其打开到浏览器中。然后我问了一些问题，但没有得到任何回应。所以现在我想知道为什么我还要继续使用 Python。尽管 Python 被宣传为“适合初学者”，但它一直非常令人沮丧。我可以仅使用文本编辑器和 Linux 上的 Bash 以及运行 docker 镜像来在 C++ 中运行 SDL2 程序，因此我并不是一个完全的新手，但到目前为止，我使用 python 的编程经验只是调试环境，仅此而已。
似乎我尝试了一切。我只是希望它能工作。如果模块无法使用更新的代码安装它自己的必备组件，那它有什么用呢？
*编辑
所以我想问题的重点是，我是唯一一个在使用 tflearn 设置 python 环境时遇到问题的人吗？如果我必须进入我安装的代码并更改某些内容才能使其真正工作，那么 Tflearn 实际上就坏了。我不得不找到一个疯狂的解决方法来修复我的 c++ 编译器，但一旦完成，就完成了。我在 c++ 之前尝试过 Python，但对模块地狱感到沮丧。我玩了几年 C++，作为一种爱好，但当我想更深入地了解神经网络和机器学习时，我听说了 tensorflow 和 tflearn，结果又回到了模块地狱。也许我应该忘记 tflearn，尝试 torch，但我担心我会再次找到模块。]]></description>
      <guid>https://stackoverflow.com/questions/79044839/is-it-just-me-or-are-python-modules-a-nightmare-to-setup</guid>
      <pubDate>Tue, 01 Oct 2024 21:49:51 GMT</pubDate>
    </item>
    <item>
      <title>创建 PartitionedDatasets 的 Kedro PartitionedDataset</title>
      <link>https://stackoverflow.com/questions/79044783/create-kedro-partitioneddataset-of-partitioneddatasets</link>
      <description><![CDATA[我正在做一个 kedro 项目，我想自动标记数千个音频文件，对它们进行转换，然后将它们存储在一个文件夹中，每个子文件夹对应一个标签。我希望该文件夹成为我的 yml 文件的目录条目
我遵循此 Kedro 教程并创建了我自己的自定义数据集，用于在 kedro 目录中保存/加载 .wav 文件。我还能够在 catalog.yml 中创建 PartitionedDataset  目录条目，例如
audio_folder:
type:partitions.PartitionedDataset
dataset:my_kedro_project.datasets.audio_dataset.SoundDataset
path:data/output/audios/
filename_suffix:&quot;.WAV&quot;

用于在 Kedro 目录中保存/加载 .WAV 文件的文件夹。
我需要的下一个抽象级别是能够创建一个与包含文件夹（例如上面的 audio_folder）相对应的目录条目。我不想通过动态创建目录条目来实现这一点，而是通过扩展 PartitionedDataset 类来实现。这是因为我希望文件夹的文件夹成为我的 catalog.yml 的一部分。我的问题是

这可能吗？你们有人尝试过这样的事情吗？
如果可能的话，我的自定义类应该只包含 _load、_save 和 _describe 方法，就像我在自定义 AbstractDataset 时一样？
]]></description>
      <guid>https://stackoverflow.com/questions/79044783/create-kedro-partitioneddataset-of-partitioneddatasets</guid>
      <pubDate>Tue, 01 Oct 2024 21:22:40 GMT</pubDate>
    </item>
    <item>
      <title>Azure Web 应用部署显示 503 错误，但 Flask 应用在本地运行良好</title>
      <link>https://stackoverflow.com/questions/79043708/azure-web-app-deployment-shows-503-error-but-flask-app-works-fine-locally</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79043708/azure-web-app-deployment-shows-503-error-but-flask-app-works-fine-locally</guid>
      <pubDate>Tue, 01 Oct 2024 14:59:18 GMT</pubDate>
    </item>
    <item>
      <title>神经网络输入数据中的特征应该是行还是列？</title>
      <link>https://stackoverflow.com/questions/79041608/should-features-be-rows-or-columns-in-input-data-for-neural-networks</link>
      <description><![CDATA[我已经实现了一个神经网络，并且对处理输入矩阵的数据形状的正确方法有疑问。具体来说，我想知道输入数据 X 是否应该在行上有示例而在列上有特征，或者反过来（行上有特征而在列上有示例）。
目前，我已经实现了它以采用形状为 (num_features, num_examples) 的 X。但是，我发现相互矛盾的来源表明，在许多库和框架中，相反的做法是常态。例如，当我加载 MNIST 数据集时，它会以 (num_examples, num_features) 的形式出现，这要求我在将数据作为输入提供给神经网络之前对其进行转置
鉴于此情况，如果常见的做法确实是使用 (num_examples, num_features)：

我是否应该接受原始形状的 X 并在内部对其进行转置？
我是否应该更改实现以直接使用其他维度的 X？
我是否应该简单地在网络文档中记录预期形状？
]]></description>
      <guid>https://stackoverflow.com/questions/79041608/should-features-be-rows-or-columns-in-input-data-for-neural-networks</guid>
      <pubDate>Tue, 01 Oct 2024 04:07:49 GMT</pubDate>
    </item>
    <item>
      <title>XFormersMetadata.__init__() 收到意外的关键字参数“is_prompt”</title>
      <link>https://stackoverflow.com/questions/79036452/xformersmetadata-init-got-an-unexpected-keyword-argument-is-prompt</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79036452/xformersmetadata-init-got-an-unexpected-keyword-argument-is-prompt</guid>
      <pubDate>Sun, 29 Sep 2024 13:03:20 GMT</pubDate>
    </item>
    <item>
      <title>ImportError: 导入 o​​nnx_cpp2py_export 时 DLL 加载失败：动态链接库 (DLL) 初始化例程失败</title>
      <link>https://stackoverflow.com/questions/78996950/importerror-dll-load-failed-while-importing-onnx-cpp2py-export-a-dynamic-link</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78996950/importerror-dll-load-failed-while-importing-onnx-cpp2py-export-a-dynamic-link</guid>
      <pubDate>Wed, 18 Sep 2024 07:08:40 GMT</pubDate>
    </item>
    <item>
      <title>在函数中创建 VLLM 对象时会导致内存错误，即使明确清除 GPU 缓存也是如此，只有共享引用才能使代码不会崩溃</title>
      <link>https://stackoverflow.com/questions/78959131/vllm-objects-cause-memory-errors-when-created-in-a-function-even-when-explicitly</link>
      <description><![CDATA[我在 Python 中使用 VLLM 库时遇到了问题。具体来说，当我在函数内部创建 VLLM 模型对象时，我遇到了内存问题，并且无法有效清除 GPU 内存，即使在删除对象并使用 torch.cuda.empty_cache() 之后也是如此。
当我尝试在函数内部实例化 LLM 对象时会出现问题，但如果我在父进程或全局范围内实例化该对象，则不会发生这种情况。这表明 VLLM 在函数中创建和管理对象时存在问题，从而导致内存保留和 GPU 耗尽。
以下是代码的简化版本：
import torch
import gc
from vllm import LLM

def run_vllm_eval(model_name, samples_params, path_2_eval_dataset):
# 在函数中实例化 LLM
llm = LLM(model=model_name, dtype=torch.float16, trust_remote_code=True)

# 在此处运行一些 VLLM 推理或评估（简化）
result = llm.generate([path_2_eval_dataset], samples_params)

# 推理后清理
del llm
gc.collect()
torch.cuda.empty_cache()

# 在此之后，GPU 内存不会被清除正确并导致 OOM 错误
run_vllm_eval()
run_vllm_eval()
run_vllm_eval()

但是
llm = run_vllm_eval2()
llm = run_vllm_eval2(llm)
llm = run_vllm_eval2(llm)

有效。
即使明确删除 LLM 对象并清除缓存后，GPU 内存仍未正确释放，导致在尝试加载或运行同一脚本中的另一个模型时出现内存不足 (OOM) 错误。
我尝试过的方法：

使用 del 删除 LLM 对象。
运行 gc.collect() 以触发 Python 的垃圾集合。
使用 torch.cuda.empty_cache() 清除 CUDA 内存。
确保父进程中没有实例化 VLLM 对象。

当在函数内创建 LLM 对象时，这些似乎都无法解决问题。
问题：

在函数内创建 VLLM 对象时，有人遇到过类似的内存问题吗？
是否有推荐的方法来管理或清除函数中的 VLLM 对象以防止 GPU 内存保留？
在这种情况下，是否存在与标准 Hugging Face 或 PyTorch 模型不同的特定 VLLM 处理技术？
]]></description>
      <guid>https://stackoverflow.com/questions/78959131/vllm-objects-cause-memory-errors-when-created-in-a-function-even-when-explicitly</guid>
      <pubDate>Sat, 07 Sep 2024 00:58:59 GMT</pubDate>
    </item>
    <item>
      <title>将safetensors模型格式（LLaVA模型）转换为gguf格式</title>
      <link>https://stackoverflow.com/questions/78763327/convert-safetensors-model-formatllava-model-into-gguf-format</link>
      <description><![CDATA[我想在 ollama 中进行 LLaVA 推理，因此我需要将其转换为 gguf 文件格式。
我的模型具有文件格式 safetensors。（使用 lora 训练）
似乎 ollama 仅支持 llama，但不支持 llava，如下所示，
https://github.com/ollama/ollama/blob/main/docs/import.md
我遵循了 llama.cpp 的说明，并在此处使用了代码 convert_lora_to_gguf.py，
https://github.com/ggerganov/llama.cpp/blob/master/convert_lora_to_gguf.py
但是我收到如下错误：
ERROR:lora-to-gguf:不支持 Model LlavaLlamaForCausalLM

如果我在模型文件的 config.json 中写入 llama 模型并运行以下代码，则会收到另一个错误。
model_instance.gguf_writer.add_string(gguf.Keys.General.TYPE, gguf.GGUFType.ADAPTER)
model_instance.gguf_writer.add_string(gguf.Keys.Adapter.TYPE, &quot;lora&quot;)
model_instance.gguf_writer.add_float32(gguf.Keys.Adapter.LORA_ALPHA, float(alpha))
model_instance.gguf_writer.add_quantization_version(gguf.GGML_QUANT_VERSION)
logger.info(&quot;Exporting model...&quot;)
model_instance.write()
logger.info(f&quot;模型已成功导出至 {model_instance.fname_out}&quot;)

Traceback (most recent call last):
File &quot;C:\Users\jjjy2\OneDrive\Desktop\VLM_FastAPI\ollama\convert_lora_to_gguf.py&quot;, line 373, in &lt;module&gt;
model_instance.gguf_writer.add_string(gguf.Keys.General.FILE_TYPE, gguf.GGUFType.ADAPTER)
AttributeError: module &#39;gguf&#39; has no attribute &#39;GGUFType&#39;

似乎所有代码和 gguf 包都不支持 llava，只支持 llama。我必须将我自己训练的模型转换为 gguf。我无法使用 hugging face 的 gguf llava 模型进行推理。
有没有办法转换它？]]></description>
      <guid>https://stackoverflow.com/questions/78763327/convert-safetensors-model-formatllava-model-into-gguf-format</guid>
      <pubDate>Thu, 18 Jul 2024 08:47:53 GMT</pubDate>
    </item>
    <item>
      <title>给定的梯度下降代码是按顺序还是同时更新参数？</title>
      <link>https://stackoverflow.com/questions/78582076/is-the-given-code-for-gradient-descent-updating-the-parameters-sequentially-or-s</link>
      <description><![CDATA[我是机器学习的新手，一直在学习梯度下降算法。我相信此代码使用同时更新，即使它看起来像是顺序更新。由于偏导数的值是在更新 w 或 b 之前计算的，即从原始 w 和 b 开始，因此应用于单个 w、b 的算法是从原始值开始应用的。我错了吗？

dj_dw=((w*x[i]+b-y[i])*x[i])/m
dj_db=(w*x[i]+b-y[i])/m
w=w-a*dj_dw
b=b-a*dj_db

语言是 python3。
x 和 y 是训练集。
w 和 b 是应用算法的参数。
我正在使用梯度下降算法进行线性回归。
dj_dw 是均方误差成本函数对 w 的偏微分。dj_db 也是如此。
如有错误，敬请原谅，我是新手。
我尝试使用 gemini 和 chatgpt 进行交叉检查，他们说这是连续的，因此造成混淆]]></description>
      <guid>https://stackoverflow.com/questions/78582076/is-the-given-code-for-gradient-descent-updating-the-parameters-sequentially-or-s</guid>
      <pubDate>Wed, 05 Jun 2024 15:28:51 GMT</pubDate>
    </item>
    </channel>
</rss>