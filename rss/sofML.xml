<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 10 Dec 2024 09:20:32 GMT</lastBuildDate>
    <item>
      <title>从softmax输出中获取不确定性和置信度</title>
      <link>https://stackoverflow.com/questions/79267578/get-uncertainty-and-confidence-from-softmax-output</link>
      <description><![CDATA[给定四个 3 类 softmax 输出向量，如下所示：
# 高置信度和低不确定性
A = [0.8, 0.1, 0.1]

# 高置信度和高不确定性
B = [0.8, 0.19, 0.01]

# 低置信度和低不确定性
C = [0.5, 0.125, 0.125]

# 低置信度和高不确定性
D = [0.5, 0.49, 0.01]

我希望有一个包或库或函数，其中输入是 softmax 向量，输出是不确定性和置信度，两者的范围都从 0（低不确定性/置信度） 到 1（高不确定性/置信度）
例如，返回具有置信度和不确定性的元组分别为：
compute_conf_uncert(A) -&gt; (0.8, 0.1)
compute_conf_uncert(B) -&gt; (0.8, 0.9)
...
]]></description>
      <guid>https://stackoverflow.com/questions/79267578/get-uncertainty-and-confidence-from-softmax-output</guid>
      <pubDate>Tue, 10 Dec 2024 08:57:42 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Keras 组合预先训练好的层将多个模型合并为一个</title>
      <link>https://stackoverflow.com/questions/79267084/how-to-combine-multiple-models-into-one-by-combining-pre-trained-layers-using-ke</link>
      <description><![CDATA[我有多个经过预训练的分类模型。我想将它们组合成一个模型。每个模型都包含相同的 EfficentNet 和 Resnet 架构，然后是连接层和 Conv 层，然后是密集层。我想从每个模型中删除 Resnet 和 EfficentNet，并仅对整个“final_model”使用一个。之前，模型是在冻结的 EfficentNet 和 Resnet 上使用 imagenet 权重进行训练的。
我尝试过这样的解决方案，但当我尝试通过在测试数据集上运行此模型来验证权重是否相同时，它给出了随机输出。
shared_input = Input(shape=(224, 224, 3), name=&quot;shared_input&quot;)

efficient_net = EfficientNetB7(weights=&#39;imagenet&#39;, include_top=False, input_shape=(SIZE, SIZE, 3))
resnet = ResNet152(weights=&#39;imagenet&#39;, include_top=False, input_shape=(SIZE, SIZE, 3))

efficient_net = efficient_net(shared_input)
resnet = resnet(shared_input)

shared_conc = Concatenate()([efficient_net, resnet])

for i in范围（模型数量）：
模型 = 加载模型（f“model_nb_{i}.keras”）
小模型 = 模型（模型.layers[4].输入，模型.layers[-1].输出）
小模型.append（小模型（shared_conc））

组合输出 = 连接（名称=“最终输出”（轻量级输出）
最终模型 = 模型（输入=[shared_input]，输出=[组合输出]）
]]></description>
      <guid>https://stackoverflow.com/questions/79267084/how-to-combine-multiple-models-into-one-by-combining-pre-trained-layers-using-ke</guid>
      <pubDate>Tue, 10 Dec 2024 05:19:07 GMT</pubDate>
    </item>
    <item>
      <title>我想研究第三磨牙。如何通过机器学习来唯一地识别牙齿？[关闭]</title>
      <link>https://stackoverflow.com/questions/79267013/i-want-to-work-with-3rd-molar-teeth-how-can-i-uniquely-identify-the-teeth-throu</link>
      <description><![CDATA[一般来说，第三磨牙有 4 颗。我想唯一地识别每颗牙齿。如果缺少任何一颗，我也想通过机器学习来识别它。
我曾尝试注释其中一张牙齿图像。但我没有得到任何有价值的结果。]]></description>
      <guid>https://stackoverflow.com/questions/79267013/i-want-to-work-with-3rd-molar-teeth-how-can-i-uniquely-identify-the-teeth-throu</guid>
      <pubDate>Tue, 10 Dec 2024 04:26:21 GMT</pubDate>
    </item>
    <item>
      <title>GFPGAN CoreML 模型无法正常工作</title>
      <link>https://stackoverflow.com/questions/79266909/gfpgan-coreml-model-isnt-working-correctly</link>
      <description><![CDATA[我尝试从 hoseins77/gfpgan 和 TheMurusTeam/coreml-upscaler-gfpgan 下载 GFPGAN CoreML 模型，但是当我在我的项目中使用它时，输出的图像不正确。 GFPGAN 似乎总体上工作正常，因为它可以在此处在线运行，但 CoreML 模型似乎不起作用。
以下是几个示例：


下面是运行该模型的代码。我是否需要进行一些其他配置才能使 GFPGAN CoreML 模型正常工作？
func getPhotoSharpened(_ photo: CGImage) async -&gt; CGImage? {
guard let vnModel = await getVNModelFromStorage() else { return nil }

let coreMLRequest = VNCoreMLRequest(model: vnModel)
coreMLRequest.imageCropAndScaleOption = .scaleFit

do {
let handler = VNImageRequestHandler(cgImage: photo, options: [:])
try handler.perform([coreMLRequest])
} catch {
print(&quot;Error sharpening photo: \(error)&quot;)
}

guard
let results = coreMLRequest.results as? [VNPixelBufferObservation],
let outputPixelBuffer = results.first?.pixelBuffer
else {
print(&quot;无法从模型获取输出&quot;); return nil
}

let ciImage = CIImage(cvPixelBuffer: outputPixelBuffer)
let desireAspectRatio = CGFloat(photo.width) / CGFloat(photo.height)
// cropped 函数在其他地方定义。
let croppedImage = cropped(ciImage, toAspectRatio: desireAspectRatio)

let context = CIContext()
guard let sharpenedImage = context.createCGImage(croppedImage, from: croppedImage.extent) else {
print(&quot;无法从 CIImage 创建锐化 CGImage&quot;)
return nil
}

return sharpenedImage
}

private func getVNModelFromStorage() async -&gt; VNCoreMLModel? {
do {
// gpfganFileUrl 在其他地方定义。
let mlModel = try await MLModel.load(contentsOf: gpfganFileUrl, configuration: .init())
return try VNCoreMLModel(for: mlModel)
} catch {
print(&quot;无法从文件加载 GFPGAN 模型，错误为：\(error)&quot;); return nil
}
}

]]></description>
      <guid>https://stackoverflow.com/questions/79266909/gfpgan-coreml-model-isnt-working-correctly</guid>
      <pubDate>Tue, 10 Dec 2024 02:53:43 GMT</pubDate>
    </item>
    <item>
      <title>尝试下载 Llama3.3-70B-Instruct 时，客户端出现 URL 错误“403 Forbidden”[关闭]</title>
      <link>https://stackoverflow.com/questions/79266687/client-error-403-forbidden-for-url-while-trying-to-download-llama3-3-70b-instr</link>
      <description><![CDATA[我尝试使用下载 Llama
$ llama model download --source meta --model-id Llama3.3-70B-Instruct
并输入我的 URL。
但是，它给了我一个错误。我在 Debian 12 bookworm 上使用 pyhton3.11 虚拟环境。
我做错了什么，或者我应该允许它吗？
这是一个 pyhton 3.11 虚拟环境，使用 debian 12。]]></description>
      <guid>https://stackoverflow.com/questions/79266687/client-error-403-forbidden-for-url-while-trying-to-download-llama3-3-70b-instr</guid>
      <pubDate>Mon, 09 Dec 2024 23:27:45 GMT</pubDate>
    </item>
    <item>
      <title>Gym 的 box 2d（openAI）无法成功安装[关闭]</title>
      <link>https://stackoverflow.com/questions/79266612/gyms-box-2d-openai-doesnt-install-successfully</link>
      <description><![CDATA[我尝试更新所有这些软件包，但没有任何效果。
brew update
brew install gcc
brew install swig

这两张是我在安装 gym box 2d 时遇到的错误的截图]]></description>
      <guid>https://stackoverflow.com/questions/79266612/gyms-box-2d-openai-doesnt-install-successfully</guid>
      <pubDate>Mon, 09 Dec 2024 22:27:27 GMT</pubDate>
    </item>
    <item>
      <title>使用 OpenCV 从正面识别和计数书籍[关闭]</title>
      <link>https://stackoverflow.com/questions/79266411/recognition-and-counting-of-books-from-front-using-opencv</link>
      <description><![CDATA[我想开发一个应用程序，让我可以计算书架上的书籍数量。如果它还可以给我一份书籍清单就好了，因为几乎所有书籍的书脊上都有名字。主要问题是要找出每一本书，有些书是同一种颜色，所以可能很难把它们挑出来。我该如何进行分割并使用像素分析来准确计数。
我还没有开始。我只是需要一些关于如何去做的想法。
(https://i.sstatic.net/fDewOa6t.jpg)(https://i.sstatic.net/7A5czzJe.jpg)]]></description>
      <guid>https://stackoverflow.com/questions/79266411/recognition-and-counting-of-books-from-front-using-opencv</guid>
      <pubDate>Mon, 09 Dec 2024 20:46:33 GMT</pubDate>
    </item>
    <item>
      <title>NotFittedError：此 DecisionTreeClassifier 实例尚未在 Jupyter 中安装</title>
      <link>https://stackoverflow.com/questions/79266379/notfittederror-this-decisiontreeclassifier-instance-is-not-fitted-yet-in-jupyte</link>
      <description><![CDATA[我正在 Jupyter Notebook 上开展一个机器学习项目，分析最便宜的电动汽车。
我在 Jupyter Notebook 上运行此单元：
fig = plt.figure(figsize=(25,20))
tree.plot_tree(clf)
plt.show()

我收到此错误：
-------------------------------------------------------------------------------
NotFittedError Traceback（最近一次调用最后一次）
~\AppData\Local\Temp\ipykernel_8784\285030017.py in &lt;module&gt;
1 fig = plt.figure(figsize=(25,20))
----&gt; 2 tree.plot_tree(clf)
3 plt.show()

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\tree\_export.py 在 plot_tree(decision_tree、max_depth、feature_names、class_names、label、filled、impurity、node_ids、proportion、rounded、precision、ax、fontsize) 中
178 &quot;&quot;&quot;
179 
--&gt; 180 check_is_fitted(decision_tree)
181 
182 exporter = _MPLTreeExporter(

~\.conda\envs\electricvehiclepriceprediction\lib\site-packages\sklearn\utils\validation.py in check_is_fitted(estimator, attributed, msg, all_or_any)
1220 
1221 如果未安装：
-&gt; 1222 引发 NotFittedError(msg % {&quot;name&quot;: type(estimator).__name__})
1223 
1224 

NotFittedError：此 DecisionTreeClassifier 实例尚未安装。使用此估算器之前，请使用适当的参数调用“fit”。
&lt;图形尺寸 2500x2000，轴数为 0&gt;

做了什么我试试？
我尝试使用以下代码：
tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42) 
tree_clf.fit(X_test, y_test)
DecisionTreeClassifier(max_depth=2, random_state=42)
clf = tree.DecisionTreeClassifier(random_state=0)
fig = plt.figure(figsize=(25,20))
tree.plot_tree(clf)
plt.show()

这是我的笔记本的链接：https://github.com/SteveAustin583/cheapest-electric-car/blob/main/ElectricCars.ipynb
如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79266379/notfittederror-this-decisiontreeclassifier-instance-is-not-fitted-yet-in-jupyte</guid>
      <pubDate>Mon, 09 Dec 2024 20:32:17 GMT</pubDate>
    </item>
    <item>
      <title>使用 PPO 的自定义环境的奖励没有改善</title>
      <link>https://stackoverflow.com/questions/79266195/reward-not-improving-for-a-custom-environment-using-ppo</link>
      <description><![CDATA[我一直在尝试在 Gym 实现的自定义环境中训练代理，其目标是通过调整每个节点的有功功率（负载）来解决电网中的电压违规问题。我主要尝试了两种算法，即 stable-baselines3、PPO 和 DDPG。但是，这两种算法的结果都非常糟糕（例如奖励随着时间的推移而减少），我希望有人能帮助我找到更好的方向。
因此，代理会进行观察，其中包含每个节点的电压值和一些其他连续值，然后执行操作，即更改电网每个节点上的负载的能力（因此是一个具有 24 个连续值的数组），然后执行功率流以确定新的电压值，然后根据这些新的电压值计算奖励。
我希望我的代理尽可能少地采取行动，并在最少的时间步内解决违规问题。因此，我按以下方式构建了奖励函数：

如果没有违规，我会给它 10 的奖励，并且情节终止
在每个步骤中，如果有违规，我会施加基本惩罚，并添加与调整幅度成比例的额外惩罚
如果代理所做的调整过于极端，以至于我的功率流算法无法收敛并停止工作，我会施加 -10 的惩罚，情节结束。

情节设置：情节从包含违规的初始观察开始。当一个情节结束时，下一个情节将从另一个带有电压的观察开始（有些带有违规行为）。
我的 PPO 模型具有以下参数：
model = PPO(&quot;MlpPolicy&quot;, env, verbose=1, n_steps=256, tensorboard_log=&quot;C:\Users\antonio\Downloads\RL&quot;, ent_coef=0.01, gamma=0.9)

我选择了较低的伽马，因为代理需要优先快速解决违规行为。
以下是 10k 步 PPO 尝试的指标：

对于 DDPG，我使用了 SB3 的默认值，得到了以下结果：

就是这样，抱歉发了这么长的帖子。无论如何，您有什么建议可以给我吗？]]></description>
      <guid>https://stackoverflow.com/questions/79266195/reward-not-improving-for-a-custom-environment-using-ppo</guid>
      <pubDate>Mon, 09 Dec 2024 19:11:43 GMT</pubDate>
    </item>
    <item>
      <title>两个不同时间段的 HR -LR 对的超分辨率实现 [关闭]</title>
      <link>https://stackoverflow.com/questions/79264696/super-resolution-implementation-for-hr-lr-pairs-in-two-different-time-periods</link>
      <description><![CDATA[我正在使用一年中不同时间拍摄的 HR 和 LR 航拍图像对深入研究超分辨率 (SR)。我有在不同时间但针对同一区域拍摄的 25 厘米分辨率图像和 8 厘米分辨率图像，我的目标是训练一个模型，将 25 厘米图像升级到 8 厘米分辨率，然后将结果与地面实况 8 厘米图像进行比较。
我认为我的方法属于基于学习框架的单图像 SR。我计划使用基于 GAN 的方法，但我仍在研究确切的方法。例如，基于参考的 SR 使用附近的 HR 区域作为参考，而真实世界的 SR 似乎更接近我的情况，因为我将面临对齐图像、处理时间变化和有效验证实施等挑战。
如果您有与此类问题相关的见解、论文或存储库，我很乐意听听！您会如何对这项工作进行分类？关于解决时间和空间差异或其他挑战有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/79264696/super-resolution-implementation-for-hr-lr-pairs-in-two-different-time-periods</guid>
      <pubDate>Mon, 09 Dec 2024 10:52:09 GMT</pubDate>
    </item>
    <item>
      <title>Google Colab 免费套餐：使用自定义数据集对 LLAMA 2 进行微调时代码在 51,000 个示例处停止</title>
      <link>https://stackoverflow.com/questions/76765564/google-colab-free-tier-code-stops-at-51-000-examples-while-fine-tuning-llama-2</link>
      <description><![CDATA[我在使用自定义数据集在 Google Colab 上微调 Llama 2 时遇到了一个问题。尽管我的数据集包含 61,609 个示例，但在训练过程中，代码会在 51,000 个示例时停止运行。奇怪的是，当我使用更大的数据集测试代码时，它运行得非常好。我按照 YouTube 上的教程对 Llama 2 进行了微调，您可以在下面找到原始的 Colab 和教程链接。
教程链接：YouTube 教程
原始 Colab：Google Colab
数据集链接：My Custom数据集
代码：
!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git
!pip install -q datasets bitsandbytes einops wandb

from datasets import load_dataset
from transformers import AutoTokenizer, TrainingArguments
from peft import LoraConfig, get_peft_model
from trl import SFTTrainer

# 加载数据集
dataset_name = &#39;harpyerr/merged-pf&#39;
dataset = load_dataset(dataset_name, split=&quot;train&quot;)

# 定义 model_name、lora_alpha、lora_dropout、lora_r 和其他配置
model_name = &quot;your_pretrained_model_name&quot; # 用预训练模型的名称替换
lora_alpha = 16
lora_dropout = 0.1
lora_r = 64

# 初始化 tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token

# 定义 LoraConfig
peft_config = LoraConfig(
lora_alpha=lora_alpha,
lora_dropout=lora_dropout,
r=lora_r,
bias=&quot;none&quot;,
task_type=&quot;CAUSAL_LM&quot;
)

# 定义训练参数
output_dir = &quot;./results&quot;
per_device_train_batch_size = 4
gradient_accumulation_steps = 4
optim = &quot;paged_adamw_32bit&quot;
save_steps = 100
logging_steps = 10
learning_rate = 2e-4
max_grad_norm = 0.3
max_steps = 100
warmup_ratio = 0.03
lr_scheduler_type = &quot;constant&quot;

training_arguments = TrainingArguments(
output_dir=output_dir,
per_device_train_batch_size=per_device_train_batch_size,
gradient_accumulation_steps=gradient_accumulation_steps,
optim=optim,
save_steps=save_steps,
logs_steps=logging_steps,
learning_rate=learning_rate,
fp16=True,
max_grad_norm=max_grad_norm,
max_steps=max_steps,
warmup_ratio=warmup_ratio,
group_by_length=True,
lr_scheduler_type=lr_scheduler_type,
)

# 初始化 SFTTrainer
max_seq_length = 512
trainer = SFTTrainer(
model=model,
train_dataset=dataset,
peft_config=peft_config,
dataset_text_field=&quot;text&quot;,
max_seq_length=max_seq_length,
tokenizer=tokenizer,
args=training_arguments,
)

# 将所有规范化层转换为 float32
import torch
for name, module in trainer.model.named_modules():
if &quot;norm&quot; in name:
module = module.to(torch.float32)

# 开始训练
trainer.train()

我尝试使用不同且大小更大的数据集来检查问题是否特定于我的自定义数据集。令人惊讶的是，当我使用其他更大的数据集时，代码运行良好，没有任何停机问题。因此，我推断问题不在于代码或训练器，而可能与我的自定义数据集的特定特征有关。]]></description>
      <guid>https://stackoverflow.com/questions/76765564/google-colab-free-tier-code-stops-at-51-000-examples-while-fine-tuning-llama-2</guid>
      <pubDate>Tue, 25 Jul 2023 18:25:00 GMT</pubDate>
    </item>
    <item>
      <title>如何配置 YOLOv8 yaml 文件以访问 Azure 上的 Blob 存储数据集？</title>
      <link>https://stackoverflow.com/questions/75848981/how-to-configure-yolov8-yaml-file-to-access-blob-storage-dataset-on-azure</link>
      <description><![CDATA[上下文
我想使用 Yolo (v8) 训练自定义模型。我已经在本地机器上运行了它，但速度很慢，我想在 Azure Machine Learning Studio 上运行该作业以提高效率。我正在使用 Azure ML SDK v2。
问题
当我在 Azure ML 上运行时，我收到一条错误消息，提示 YOLO 无法找到我的训练图像。
回溯（最近一次调用最后一次）：
文件“/opt/conda/envs/ptca/lib/python3.8/site-packages/ultralytics/yolo/engine/trainer.py”，第 125 行，位于 __init__
self.data = check_det_dataset(self.args.data)
文件“/opt/conda/envs/ptca/lib/python3.8/site-packages/ultralytics/yolo/data/utils.py”，第 243 行，位于 check_det_dataset
raise FileNotFoundError(msg)
FileNotFoundError: 
数据集&#39;custom.yaml&#39; 未找到⚠️，缺少路径 [&#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/valid/images&#39;]

代码/分析
这是我用来运行作业的代码：
command_job = command(
display_name=&#39;Test Run 1&#39;,
code=&quot;./src/&quot;,
command=&quot;yolo detect train data=custom.yaml model=yolov8n.pt epochs=1 imgsz=1280 seed=42&quot;,
environment=&quot;my-custom-env:3&quot;,
compute=compute_target
)​​

在我的本地机器上（使用 Visual Studio 代码）， custom.yaml 文件位于 ./src/ 目录中。当我运行上述作业时，custom.yaml 已上传并出现在作业的 Code 部分中（在 Azure ML Studio 中查看）。通过调查，我认为这是具有以下路径的计算工作目录：
&#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/&#39;

我的 custom.yaml 如下所示：
path: ../
train: train/images
val: valid/images

nc: 1
names: [&quot;bike&quot;]

因此，YOLO 正在查看我的 custom.yaml，使用根目录作为路径，并尝试在其中找到 valid/images目录：
&#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/valid/images&#39;

我的图像位于我的 Datastore 中，而不是该目录中，因此出现错误。
我已尝试过 - 更新 custom.yaml 路径
我的所有数据（train 和 valid）都包含在 AzureBlobStorage 中。在 Azure ML Studio 中，我创建了一个 Datastore 并将我的数据添加为 Dataset（引用我的 AzureBlobStorage 帐户）。我的文件结构是：
Dataset/
- Train/
- Images
- Labels
- Valid/
- Images
- Labels

在我的 custom.yaml 文件中，我尝试将 path 替换为以下内容：
 **存储 URI**：https://mystorageaccount.blob.core.windows.net/my-datasets
**数据存储 URI**：azureml://subscriptions/XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX/resourcegroups/my-rg/workspaces/my_workspage/datastores/my_datastore/paths/Dataset/

如果我这样做，我会得到相同的错误。这次它将 path 附加到工作目录的末尾。示例：
 &#39;/mnt/azureml/cr/j/18bdc3371eca4975a0c4a7123f9adaec/exe/wd/https://mystorageaccount.blob.core.windows.net/my-datasets/valid/images&#39;

我尝试过的方法 - mounting / download 数据集
我已阅读 Microsoft 文档 - （例如 此处 和 此处） - 内容如下：

对于大多数场景，您将使用 URI（uri_folder 和 uri_file） - 存储中的一个位置，可以通过将存储安装或下载到节点轻松映射到作业中计算节点的文件系统。

感觉我应该将我的数据（在我的 Datastore 中）映射到计算文件系统。然后我可以在我的 custom.yaml 中使用该路径。文档没有明确说明我该如何做。
简而言之：如何在 Azure ML 上设置我的数据，以便我的 custom.yaml 中的 path 指向数据？]]></description>
      <guid>https://stackoverflow.com/questions/75848981/how-to-configure-yolov8-yaml-file-to-access-blob-storage-dataset-on-azure</guid>
      <pubDate>Sun, 26 Mar 2023 16:16:11 GMT</pubDate>
    </item>
    <item>
      <title>sklearn.exceptions.NotFittedError：此 DecisionTreeClassifier 实例尚未适合</title>
      <link>https://stackoverflow.com/questions/74928705/sklearn-exceptions-notfittederror-this-decisiontreeclassifier-instance-is-not-f</link>
      <description><![CDATA[我尝试使用 DecisionTreeClassifier 在 Python 中不使用 graphviz 的情况下使用图像数据的模式可视化决策树，但我一直收到错误
sklearn.exceptions.NotFittedError：此 DecisionTreeClassifier 实例尚未拟合。在使用此估算器之前，请使用适当的参数调用“fit”。

即使我在 google colab 和 VScode 中尝试，仍然会收到错误。我的数据集只有 2 列，即 ModusH 和 Index。
这是我的数据集示例
数据集
这是代码：
datapisang= pd.read_csv(&#39;DataModusdiperbaiki.csv&#39;) 
X= datapisang[[&#39;ModusH&#39;]] 
Y= datapisang[[&#39;Index&#39;]] 
X_train, X_test, Y_train, Y_test = train_test_split(X, Y) 
# 模型
DT_model= DecisionTreeClassifier() 
DT_model.fit(X_train,Y_train) 
DT_model.print_tree() 
data = [Modus_citra] # 模式图像 
hasilprediksi = DT_model.predict([data]) 

fn = [&#39;ModusH&#39;] 
cn = [&#39;Index&#39;] 

fig,axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4),dpi=300)

tree.plot_tree(DT_model,
feature_names = fn, 
class_names=cn,
filled = True);

fig.savefig(&#39;imagename.png&#39;)

我尝试进行可视化，但即使使用 graphviz，每次都会出错。如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/74928705/sklearn-exceptions-notfittederror-this-decisiontreeclassifier-instance-is-not-f</guid>
      <pubDate>Tue, 27 Dec 2022 11:28:09 GMT</pubDate>
    </item>
    <item>
      <title>NotFittedError：此 DecisionTreeClassifier 实例尚未适合</title>
      <link>https://stackoverflow.com/questions/70864176/notfittederror-this-decisiontreeclassifier-instance-is-not-fitted-yet</link>
      <description><![CDATA[我正在尝试运行基于决策树的模型。我尝试了以下操作：
X = df[[&#39;Quantity&#39;]]
y = df[[&#39;label&#39;]]
params = {&#39;max_depth&#39;:[2,3,4], &#39;min_samples_split&#39;:[2,3,5,10]}
clf_dt = DecisionTreeClassifier()
clf = GridSearchCV(clf_dt, param_grid=params,scoring=&#39;f1&#39;)
clf.fit(X, y)
clf_dt = DecisionTreeClassifier(clf.best_params_)

并收到此处提到的警告
FutureWarning：通过 criterion={&#39;max_depth&#39;: 2, &#39;min_samples_split&#39;: 2} 作为关键字参数。从版本 1.0（重命名为 0.25）开始，将这些作为位置参数传递将导致错误
warnings.warn(f&quot;将 {args_msg} 作为关键字参数传递。来自版本 &quot;

后来，我尝试运行下面的代码并收到错误（但我已经使用 .fit() 拟合了模型）
from sklearn import tree
tree.plot_tree(clf_dt, filled=True, feature_names = list(X.columns), class_names=[&#39;Iris-setosa&#39;, &#39;Iris-versicolor&#39;, &#39;Iris-virginica&#39;])

NotFittedError：此 DecisionTreeClassifier 实例尚未拟合。在使用此估算器之前，请使用适当的参数调用 
&#39;fit&#39;。

我该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/70864176/notfittederror-this-decisiontreeclassifier-instance-is-not-fitted-yet</guid>
      <pubDate>Wed, 26 Jan 2022 13:28:32 GMT</pubDate>
    </item>
    <item>
      <title>如何从 NLTK 导入和使用停用词列表？</title>
      <link>https://stackoverflow.com/questions/70698947/how-to-import-and-use-stopwords-list-from-nltk</link>
      <description><![CDATA[我已经从 nltk.corpus 导入了 stopwords，但出现 STOPWORDS 未定义 错误。以下是我的代码：
import nltk
from nltk.corpus import stopwords
#创建停用词列表：
stopwords = set(STOPWORDS)

以上代码出现以下错误：
NameError：名称“STOPWORDS”未定义
]]></description>
      <guid>https://stackoverflow.com/questions/70698947/how-to-import-and-use-stopwords-list-from-nltk</guid>
      <pubDate>Thu, 13 Jan 2022 15:18:48 GMT</pubDate>
    </item>
    </channel>
</rss>