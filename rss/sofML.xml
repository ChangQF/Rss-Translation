<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 10 May 2024 18:18:42 GMT</lastBuildDate>
    <item>
      <title>是否可以训练神经网络以输入随机森林分类器或任何其他类型的分类器（例如 XGBoost 或决策树）？</title>
      <link>https://stackoverflow.com/questions/78461828/is-it-possible-to-train-a-neural-network-to-feed-into-a-random-forest-classifier</link>
      <description><![CDATA[我想创建一个模型架构来预测未来的股价走势，如下所示：

该模型的目标是预测未来 3 个月内价格是上涨还是下跌。
我尝试过一些模型，例如 Logistic 回归、神经网络、XGBoost 等。我得到了一些不错的结果。通过使用随机森林分类器，我得到了迄今为​​止最好的结果。我如何使用神经网络对数据进行编码，然后将这些值传递给随机森林分类器进行分类，而不是使用如图所示的使用 S 形函数的最终输出层（使用 Python、Keras 和 SKlearn）。
我对 Keras 不是很熟悉，所以我想知道是否有可能训练一个输入到单独分类器的神经网络，如果可以，该怎么做。]]></description>
      <guid>https://stackoverflow.com/questions/78461828/is-it-possible-to-train-a-neural-network-to-feed-into-a-random-forest-classifier</guid>
      <pubDate>Fri, 10 May 2024 17:53:36 GMT</pubDate>
    </item>
    <item>
      <title>为职位推荐系统选择正确的集成方法</title>
      <link>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</link>
      <description><![CDATA[我正在开发机器学习职位推荐系统，并且正在考虑使用集成学习方法。我使用的数据集很全面，包括各种属性，例如职位名称、职位描述、工资、地点和公司详细信息。它包含数字、分类和文本数据的混合。
我计划使用结合多种模型和技术的混合方法来提高其性能：
协作过滤或矩阵分解来捕获用户和职位发布之间的交互。
神经网络用于处理复杂的数据类型，例如职位描述中的文本。
决策树或随机森林的可解释性以及处理数字和分类数据混合的能力。
我正在寻求关于哪种集成方法最适合这项任务的建议。我希望模型能够很好地过滤、灵活地处理数据类型、在训练和时间上具有良好的性能，并提供可解释性。谢谢大家&amp;祝你有美好的一天！
我还没有开始，但我会考虑尝试任何合理的方法！]]></description>
      <guid>https://stackoverflow.com/questions/78461822/choosing-the-right-ensemble-method-for-a-job-recommendation-system</guid>
      <pubDate>Fri, 10 May 2024 17:51:56 GMT</pubDate>
    </item>
    <item>
      <title>如何限制 13b 参数 LLM 模型以提供简短响应</title>
      <link>https://stackoverflow.com/questions/78461646/how-to-restrict-a-13b-parameter-llm-model-to-provide-short-responses</link>
      <description><![CDATA[我尝试提示模型将响应保持在一定的字数限制内，但这不起作用。
当使用最大令牌时，我看到响应在最后被截断。
我使用的是 13b 型号。
关于如何实现这项工作有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78461646/how-to-restrict-a-13b-parameter-llm-model-to-provide-short-responses</guid>
      <pubDate>Fri, 10 May 2024 17:07:46 GMT</pubDate>
    </item>
    <item>
      <title>如何使用深度学习将位于各自房间的扬声器（音频设备）分组为集群？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78461347/how-to-group-speakers-audio-devices-located-in-their-respective-rooms-into-clu</link>
      <description><![CDATA[当前的任务涉及对位于不同房间的扬声器进行分组。例如，如果房间 1 中有 3 个设备，房间 2 中有 5 个设备，则目标是创建两组：一组用于房间 1，另一组用于房间 2，每个组包含各自的扬声器。为了实现这一目标，我们分析声音样本。这些样本是通过从一个扬声器播放声音并从同一房间的其他扬声器录制声音来收集的。此过程会生成一个 .wav 文件，其中包含在该特定房间中播放的声音的录音。
该项目的目的是增强对音频设备相对位置的理解，并探索对这些设备进行智能分组的有效方法或算法。我们的目标是利用这些见解来开发原型设备，以实际演示这一概念。随后，将对原型的性能进行评估，以评估其有效性。
以下是扬声器的基本功能：

扬声器可以播放声音文件，例如“alarm.mp3”。
扬声器可以录制任何声音，并使用其内置麦克风将其保存为 .wav 文件。
您可以调节扬声器输出的音量，使其更大或更小。
您还可以使用 dB 值修改输入增益，该增益决定麦克风捕获的声音量。

这是我解决这个问题的方法：
首先，我将多个设备放置在不同的房间中：扬声器 1 和 2 放置在房间 1 中，扬声器 3、4 和 5 放置在房间 2 中，扬声器 6 和 7 放置在房间 3 中。然后，我自动化了一个流程，其中每个扬声器录制 10 秒，同时另一个扬声器播放声音剪辑，例如“alarm.mp3” 6 秒。这会产生 7 个以聆听和演奏扬声器命名的样本（录音），例如“speaker3_speaker1”和“speaker3_speaker1”。表示扬声器 3 正在录音，而扬声器 1 正在播放。我对所有扬声器组合重复了这个过程，为我提供了一些可以使用的数据。
接下来，我使用 Python 库 Librosa 从这些录音中提取声音特征，包括梅尔倒谱系数 (MFCC) 和梅尔频谱图，它们本质上是代表声音特征的图像。这些特征作为深度学习模型的输入。
现在，我开发了一个 Siamese 神经网络来处理这些 MFCC 和频谱图图像并生成输出。但是，我目前陷入这个阶段，不确定如何继续。
我遇到的一个挑战是，即使扬声器 3 和 7 位于不同的房间，模型也可能会错误地认为它们位于同一个房间，因为它们来自同一家公司，具有相同的型号，并且玩游戏相同的声音文件(“alarm.mp3”)。此问题使分组过程变得复杂。
我正在寻求有关如何解决此问题的建议以及推进此项目的任何其他想法。我愿意探索上述之外的替代想法。请随意提出任何其他有助于解决前面段落中概述的挑战的方法或策略。]]></description>
      <guid>https://stackoverflow.com/questions/78461347/how-to-group-speakers-audio-devices-located-in-their-respective-rooms-into-clu</guid>
      <pubDate>Fri, 10 May 2024 16:08:30 GMT</pubDate>
    </item>
    <item>
      <title>FileNotFoundError：[Errno 2]没有这样的文件或目录：'Models\\model_new.json'</title>
      <link>https://stackoverflow.com/questions/78461085/filenotfounderror-errno-2-no-such-file-or-directory-models-model-new-json</link>
      <description><![CDATA[&lt;前&gt;&lt;代码&gt; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

FileNotFoundError：[Errno 2]没有这样的文件或目录：&#39;Models\\model_new.json&#39;[文本]

这是我在下面的代码中遇到的错误。怎么解决呢。项目存储库的 Github 链接发布在底部。
类应用：

    def __init__(自身):

        self.hs = Hunspell(&#39;en_US&#39;)
        self.vs = cv2.VideoCapture(0)
        self.当前图像 = 无
        self.current_image2 = 无
        self.json_file = open(&quot;Models\model_new.json&quot;, &quot;r&quot;)
        self.model_json = self.json_file.read()
        self.json_file.close()

        self.loaded_model = model_from_json(self.model_json)
        self.loaded_model.load_weights(“模型\model_new.h5”)

        self.json_file_dru = open(&quot;Models\model-bw_dru.json&quot; , &quot;r&quot;)
        self.model_json_dru = self.json_file_dru.read()
        self.json_file_dru.close()

        self.loaded_model_dru = model_from_json(self.model_json_dru)
        self.loaded_model_dru.load_weights(“模型\model-bw_dru.h5”)
        self.json_file_tkdi = open(&quot;Models\model-bw_tkdi.json&quot; , &quot;r&quot;)
        self.model_json_tkdi = self.json_file_tkdi.read()
        self.json_file_tkdi.close()

        self.loaded_model_tkdi = model_from_json(self.model_json_tkdi)
        self.loaded_model_tkdi.load_weights(“模型\model-bw_tkdi.h5”)
        self.json_file_smn = open(&quot;Models\model-bw_smn.json&quot; , &quot;r&quot;)
        self.model_json_smn = self.json_file_smn.read()
        self.json_file_smn.close()

        self.loaded_model_smn = model_from_json(self.model_json_smn)
        self.loaded_model_smn.load_weights(“模型\model-bw_smn.h5”)

https://github.com/emnikhil/Sign-Language-To -文本转换
这是我用于最后一年项目的项目，[如果您必须获取我已附加的我从中克隆项目的存储库的任何参考，则会出现此错误]
这个项目是关于使用 CNN 将美国手语转换为文本，并应用高斯模糊滤波器和灰度来减小图像的大小。我找不到问题的任何解决方案，因此我没有尝试或更改任何代码行并寻找问题的解决方案。
]]></description>
      <guid>https://stackoverflow.com/questions/78461085/filenotfounderror-errno-2-no-such-file-or-directory-models-model-new-json</guid>
      <pubDate>Fri, 10 May 2024 15:19:30 GMT</pubDate>
    </item>
    <item>
      <title>有序 Logit 回归的预测如何工作？</title>
      <link>https://stackoverflow.com/questions/78461070/how-does-prediction-for-ordered-logit-regression-work</link>
      <description><![CDATA[我正在学习有序逻辑回归，我想知道预测在数学上是如何运作的，我该如何在 Python 中自己完成它。我知道在 Python 中我可以简单地使用预测，但我想知道如何仅使用 model.summary() 中的系数进行预测。
import pandas as pd
from statsmodels.miscmodels.ordinal_model import OrderedModel

data = pd.DataFrame({
&#39;score&#39;: [3.2, 4.5, 5.6, 6.7, 7.8, 8.9, 9.1],
&#39;rating&#39;: [1,2,3,4,5,6,6] 
})

X = data[[&#39;score&#39;]]
y = data[&#39;rating&#39;]

ordinal_model = OrderedModel(y, X, distr=&#39;logit&#39;)

ordinal_results = ordinal_model.fit(method=&#39;bfgs&#39;)

print(ordinal_results.summary())


结果是：
时间：17:05:52 
观测数：7 
Df 残差：1 
Df 模型：1 
===================================================================================================
coef std err z P&gt;|z| [0.025 0.975]
-----------------------------------------------------------------------------
得分 66.3902 5669.125 0.012 0.991 -1.1e+04 1.12e+04
1/2 285.5835 2.56e+04 0.011 0.991 -4.98e+04 5.04e+04
2/3 4.2698 88.656 0.048 0.962 -169.493 178.032
3/4 4.1879 155.834 0.027 0.979 -301.241 309.617
4/5 4.3867 136.765 0.032 0.974 -263.668 272.442
5/6 3.4706 220.734 0.016 0.987 -429.161 436.102
=====================================================================================

使用 coef 向量如何获得与 相同的输出
ordinal_results.model.predict(ordinal_results.params, exog = (4.3))

[[0.5264086 0.4735914 0. 0. 0. 0. ]]


我认为我应该简单地对 coef 和新数据的线性和使用 softmax，但那没有用]]></description>
      <guid>https://stackoverflow.com/questions/78461070/how-does-prediction-for-ordered-logit-regression-work</guid>
      <pubDate>Fri, 10 May 2024 15:16:52 GMT</pubDate>
    </item>
    <item>
      <title>MNIST - mnist.train_images() 问题 - HTTPError: Forbidden</title>
      <link>https://stackoverflow.com/questions/78460997/mnist-problem-with-mnist-train-images-httperror-forbidden</link>
      <description><![CDATA[我目前正在学习神经网络，我想使用 train_images() 函数，但我无法这样做。如果我运行以下代码：
导入 mnist

图像 = mnist.train_images()

，我会得到：
runfile(&#39;C:/Users/deriv/untitled0.py&#39;, wdir=&#39;C:/Users/deriv&#39;)
回溯（最近一次调用最后一次）：

  compat_exec 中的文件 ~\anaconda3\Lib\site-packages\spyder_kernels\py3compat.py:356
    exec（代码，全局变量，局部变量）

  文件 c:\users\deriv\untitled0.py:3
    图像 = mnist.train_images()

  train_images 中的文件 ~\anaconda3\Lib\site-packages\mnist\__init__.py:161
    返回 download_and_parse_mnist_file(&#39;train-images-idx3-ubyte.gz&#39;)

  download_and_parse_mnist_file 中的文件 ~\anaconda3\Lib\site-packages\mnist\__init__.py:143
    fname = download_file(fname, target_dir=target_dir, force=force)

  download_file 中的文件 ~\anaconda3\Lib\site-packages\mnist\__init__.py:59
    urlretrieve(url, target_fname)

  urlretrieve 中的文件 ~\anaconda3\Lib\urllib\request.py:241
    将 contextlib.close(urlopen(url, data)) 作为 fp：

  urlopen 中的文件 ~\anaconda3\Lib\urllib\request.py:216
    返回 opener.open(url, 数据, 超时)

  文件 ~\anaconda3\Lib\urllib\request.py:525 打开
    响应=方法（请求，响应）

  http_response 中的文件 ~\anaconda3\Lib\urllib\request.py:634
    响应 = self.parent.error(

  文件 ~\anaconda3\Lib\urllib\request.py:563 错误
    返回 self._call_chain(*args)

  _call_chain 中的文件 ~\anaconda3\Lib\urllib\request.py:496
    结果 = func(*args)

  http_error_default 中的文件 ~\anaconda3\Lib\urllib\request.py:643
    引发 HTTPError(req.full_url, 代码, msg, hdrs, fp)

HTTP 错误：禁止

我使用pip install正确安装了mnist，但是，我不知道为什么** mnist.train_images()** 会导致错误。抱歉，如果这是一个简单的问题，但是它会对我有很大帮助。
我不知道是否应该直接从 http://下载文件/yann.lecun.com/exdb/mnist/。但是我无法这样做，因为我没有访问此资源的权限。]]></description>
      <guid>https://stackoverflow.com/questions/78460997/mnist-problem-with-mnist-train-images-httperror-forbidden</guid>
      <pubDate>Fri, 10 May 2024 15:02:52 GMT</pubDate>
    </item>
    <item>
      <title>我做了什么？ :) 迁移学习方法分类所需的帮助</title>
      <link>https://stackoverflow.com/questions/78460958/what-have-i-done-help-needed-in-classifying-a-transfer-learning-approach</link>
      <description><![CDATA[我想我有一些菜鸟问题，但是，我正在尝试对方法进行分类。
在这些方法的情况下，一组特征 A（源域？）通过数值方法转换为一组特征 B（目标域）。在具体情况下，这些特征是在荷载下具有预曲率 (A) 的梁 (A) 和直梁 (B) 的中心线位置矢量。我有数值方法将预弯梁的中心线位置数据转换为直梁。转换后，接受过直梁训练的学习器正在估计输入数据的负载。
它是什么样的迁移学习？
我倾向于将其称为基于映射，但在文献中我发现了三个类别：

即时
基于功能
基于模型
基于关系

我假设在将数据提供给例如之前转换数据神经网络将是基于特征的。
或者我完全一无所知，这不被认为是迁移学习。
我很高兴得到你的帮助。
提前致谢并欢呼。]]></description>
      <guid>https://stackoverflow.com/questions/78460958/what-have-i-done-help-needed-in-classifying-a-transfer-learning-approach</guid>
      <pubDate>Fri, 10 May 2024 14:55:52 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：反序列化类“BatchNormalization”时出错</title>
      <link>https://stackoverflow.com/questions/78460953/typeerror-error-when-deserializing-class-batchnormalization</link>
      <description><![CDATA[TypeError：使用 config={&#39;name&#39;: &#39;bn_conv1&#39;, &#39;trainable&#39;: False, &#39;momentum&#39;: 0.99, &#39;epsilon&#39;: 1e-05, &#39;center&#39;: True 反序列化类 &#39;BatchNormalization&#39; 时出错， &#39;scale&#39;：True，&#39;beta_initializer&#39;：{&#39;class_name&#39;：&#39;零&#39;，&#39;config&#39;：{}}，&#39;gamma_initializer&#39;：{&#39;class_name&#39;：&#39;Ones&#39;，&#39;config&#39;：{}}，&#39;moving_mean_initializer &#39;：{&#39;class_name&#39;：&#39;零&#39;，&#39;config&#39;：{}}，&#39;moving_variance_initializer&#39;：{&#39;class_name&#39;：&#39;Ones&#39;，&#39;config&#39;：{}}，&#39;beta_regularizer&#39;：无，&#39;gamma_regularizer&#39;：无，&#39;beta_constraint&#39;：无，&#39;gamma_constraint&#39;：无，&#39;freeze&#39;：True}。
遇到异常：无法识别的关键字参数传递给 BatchNormalization：{&#39;freeze&#39;: True}
这是我在使用 ImageAI 对象检测时遇到的问题。
我真的不知道如何处理它，所以我会尝试你所说的一切。谢谢]]></description>
      <guid>https://stackoverflow.com/questions/78460953/typeerror-error-when-deserializing-class-batchnormalization</guid>
      <pubDate>Fri, 10 May 2024 14:55:08 GMT</pubDate>
    </item>
    <item>
      <title>克利夫兰心脏病数据集 - 如何提高测试准确性？</title>
      <link>https://stackoverflow.com/questions/78460930/cleveland-heart-disease-dataset-how-to-improve-test-accurarcy</link>
      <description><![CDATA[我使用带有反向传播的多层感知器来预测心脏病，并且使用此处链接的数据集：https://drive.google.com/file/d/1ZuVXGbE6UVQFJ5ab5m1k4LzvDNTtLqYQ/view?usp=sharing
它有 303 条记录和 4 个输出类别 (0、1、2、3、4)，以 0 到 4 的等级表示心脏病的严重程度。
数据集中存在缺失数据，我通过将缺失值替换为相应特征的平均值来处理。
这是我设置用于训练模型的参数：

隐藏层神经元数量 = 100，单隐藏层

输出层神经元数量 = 5

隐藏层激活函数=logsig

输出层激活函数=softmax

训练函数 = trainlm

学习率 = 0.001

最大验证失败次数 = 10

最大纪元 = 5000

最小梯度 = 1.99e-8


但无论我做什么——调整学习率，都不会。隐藏层等 - 测试精度保持在 55% 到 60% 之间，但训练精度可以达到 80% 以上，而且我也需要测试精度 &gt;80%。
我怎样才能实现我的目标？请帮我解决这个问题，谢谢。
%加载数据集
数据 = readtable(&#39;C:\Users\User\Desktop\processed.cleveland.csv&#39;);

% 将表格转换为矩阵
X = table2array(数据(:, 1:13)); % 假设前13列是输入特征
y = table2array(数据(:, 14)); % 假设最后一列是输出标签

% 处理缺失值（如果有）
% 用相应特征的平均值替换缺失值
X = fillmissing(X, &#39;线性&#39;); % 或“最近”

% % 标准化输入特征
% X = 归一化(X);

% Z 分数标准化
mu = nanmean(X); % 计算每个特征的平均值，忽略 NaN
西格玛 = nanstd(X); % 计算每个特征的标准差，忽略 NaN
X = (X - mu) ./ 西格玛; % 执行 Z 分数标准化

% 将数据分成训练集和测试集
cv = cvpartition(大小(X,1),&#39;HoldOut&#39;,0.5); % 30% 的数据用于测试
idxTrain = 训练(cv); % 训练集索引
idxTest = 测试(cv); % 测试集索引

X_train = X(idxTrain,:);
y_train = y(idxTrain,:);

X_test = X(idxTest,:);
y_test = y(idxTest,:);

% 定义 MLP 架构
隐藏层大小 = [100]; % 具有 10 个神经元的单个隐藏层

% 选择输出层的激活函数
输出层激活 = &#39;softmax&#39;; % Softmax 用于多类分类

% 创建 MLP 模型
网络=模式网络(hiddenLayerSize);

% 设置隐藏层的激活函数
对于 i = 1:numel(hiddenLayerSize)
    net.layers{i}.transferFcn = &#39;logsig&#39;; % 应用 ReLU
    net.layers{i}.userdata.dropoutFraction = 0.5; % 辍学分数（根据需要调整）
结尾

% 设置输出层的激活函数
net.layers{end}.transferFcn = outputLayerActivation;

% 设置训练函数
net.trainFcn = &#39;trainlm&#39;;

% 设置训练选项
net.trainParam.lr = 0.001; % 学习率
net.trainParam.max_fail = 10; % 最大验证失败次数
net.trainParam.epochs = 5000; % 最大纪元
net.trainParam.min_grad = 1.99e-8; % 最小梯度

% 使用训练数据训练 MLP 模型
net = train(net, X_train&#39;, ind2vec(y_train&#39;+1)); % &#39;+1&#39; 将标签转换为基于 1 的索引

% 使用测试数据测试训练后的模型
y_pred = net(X_test&#39;);

这是我得到的结果，希望可以作为参考：






]]></description>
      <guid>https://stackoverflow.com/questions/78460930/cleveland-heart-disease-dataset-how-to-improve-test-accurarcy</guid>
      <pubDate>Fri, 10 May 2024 14:52:24 GMT</pubDate>
    </item>
    <item>
      <title>ValueError: matmul: 输入操作数 1 的核心维度 0 不匹配，gufunc 签名为 (n?,k),(k,m?)->(n?,m?)（大小 5 与 3 不同）</title>
      <link>https://stackoverflow.com/questions/78460776/valueerror-matmul-input-operand-1-has-a-mismatch-in-its-core-dimension-0-with</link>
      <description><![CDATA[将 numpy 导入为 np
从 numpy.linalg 导入 inv
从 scipy.linalg 导入 pinv

# 定义必要的函数
def create_laplacian_from_adjacency(adj_matrix):
    Degree_matrix = np.diag(adj_matrix.sum(axis=1))

    laplacian_matrix = Degree_matrix - adj_matrix
    
    返回拉普拉斯矩阵

def dirichlet_energy(L, X):
    “”““用于平滑度量化的狄利克雷能量。”“””
    返回 np.trace(X.T @ L @ X)

def update_C(X, X_tilde, L, C, gamma, alpha, lam, J):
    “”“”使用具有主函数近似的梯度下降来更新C。
    p, k = C.shape
    C_old = np.copy(C)
    
    梯度_f = (-2 * gamma * L @ C_old @ inv(C_old.T @ L @ C_old + J) +
                  alpha * (C_old @ X_tilde - X) @ X_tilde.T +
                  2 * L @ C_old @ X_tilde @ X_tilde.T + lam * C_old @ np.ones((k, k)))
    
    # 主要函数优化步骤（简化方法）
    t = 0.01 # 学习率，需要根据实际应用进行调整
    C_new = pinv(C_old - t * 梯度_f)
    C_new = np.maximum(C_new, 0) # 强制非负性
    返回C_new

def update_X(X, L, C, alpha):
    “”“”基于更新的C来更新X(tilda)。“”“”
    inv_matrix = inv((2/alpha) * (C.T @ L @ C)) + (C.T @ C)
    X_tilde_new = inv_matrix @ C.T @ X
    返回 X_tilde_new

def fgc_algorithm(X, L, alpha, gamma, lam, iterations=5):
    “”“”执行特征图粗化算法。“”“”
    p, n = X.形状
    k = 3 # 假设粗化的降维为 3
    C = np.random.rand(p, k)*0.1
    J = np.full((k, k), 1/k)
    X_代字号 = pinv(C)@X

    对于范围内的 i（迭代）：
        C = update_C(X, X_tilde, L, C, gamma, alpha, lam, J)
        X_tilde = update_X(X, L, C, alpha)
        当前能量 = dirichlet_energy(L, X_tilde)
        print(f&quot;迭代 {i}: 狄利克雷能量 = {current_energy}&quot;)

    L_c=C.T@L@C
    返回 C、L_c、X_tilde

＃ 例子：
X = np.random.rand(5, 7) # 10 个节点的随机特征
adj_matrix = np.array([
    [0, 1, 0, 0, 0],
    [1, 0, 1, 1, 1],
    [0, 1, 0, 1, 0],
    [0, 1, 1, 0, 1],
    [1, 1, 0, 1, 0]
]）
L = create_laplacian_from_adjacency(adj_matrix) # 创建样本拉普拉斯矩阵
alpha, gamma, lam = 0.1, 1, 0.5 # 正则化参数

C、L_c、X_tilde = fgc_algorithm(X、L、alpha、gamma、lam)
print(&quot;更新的 C 矩阵：\n&quot;, C)
print(&quot;L_C 矩阵:\n&quot;, L_c)
print(&quot;更新后的特征矩阵 X(tilda):\n&quot;, X_tilde)


我正在尝试实现特色粗化图算法，但每次代码到达第 34 行时：inv_matrix = inv((2/alpha) * (C.T @ L @ C)) + (C.T @ C),
出现了上述错误。
我已经尝试检查所有内容，但根据我的说法，矩阵的尺寸是正确的，所以我不太明白为什么会出现这个问题？
如果您碰巧明白这一点，请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/78460776/valueerror-matmul-input-operand-1-has-a-mismatch-in-its-core-dimension-0-with</guid>
      <pubDate>Fri, 10 May 2024 14:28:29 GMT</pubDate>
    </item>
    <item>
      <title>在 R 中使用 SMOTE 训练模型和对不平衡测试数据的最佳截止</title>
      <link>https://stackoverflow.com/questions/78460227/using-smote-train-model-and-optimal-cutoff-on-unbalanced-test-data-in-r</link>
      <description><![CDATA[我的原始数据集有一个二元因变量，其中 3% 的值为 1。首先，我将原始数据集分为训练集和测试集（80-20 分割）。由于它同时具有数字和二进制自变量，因此我在火车上使用 SMOTENC 来创建平衡的火车数据集。我在平衡训练数据集上生成逻辑回归模型，并使用 F-Measure 作为确定最佳截止值的指标。但现在，我在测试数据集上使用什么截止值？由于它是不平衡的，因此使用从平衡训练数据集中找到的最佳截止值是灾难性的。]]></description>
      <guid>https://stackoverflow.com/questions/78460227/using-smote-train-model-and-optimal-cutoff-on-unbalanced-test-data-in-r</guid>
      <pubDate>Fri, 10 May 2024 12:50:37 GMT</pubDate>
    </item>
    <item>
      <title>构建音频到图像分类并做出最佳架构模型</title>
      <link>https://stackoverflow.com/questions/78451244/building-audio-to-image-classification-and-make-a-best-architecture-model</link>
      <description><![CDATA[如何确定音频到图像分类模型构建的任何特定应用程序或用例？
我尝试制作像CNN一样的架构模型，但它无法预测图像，我期望模型能够将相应的图像识别为音频，但毕竟很难实现。]]></description>
      <guid>https://stackoverflow.com/questions/78451244/building-audio-to-image-classification-and-make-a-best-architecture-model</guid>
      <pubDate>Wed, 08 May 2024 21:33:54 GMT</pubDate>
    </item>
    <item>
      <title>如何根据掩蔽将矩阵相乘并排除元素？</title>
      <link>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</link>
      <description><![CDATA[我有以下输入矩阵
inp_tensor = torch.tensor(
        [[0.7860, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.7980, 0.0000],
        [1.0000, 0.1115, 0.0000, 0.6524, 0.6057, 0.3725, 0.0000, 1.0000]])

以及我想要排除的元素的索引（在本例中它们是零元素，但它们可以是任何值）
mask_indices = torch.tensor(
[[7, 2],
[2, 6]])

如何从与以下矩阵的乘法中排除这些元素：
my_tensor = torch.tensor(
        [[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.2566, 0.7936, 0.9408],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696],
        [0.4414, 0.2969, 0.8317]])

也就是说，不要将其相乘，包括这些值（本例中为零）：
a = torch.mm(inp_tensor, my_tensor)
打印（一）
张量([[1.7866, 2.5468, 1.6330],
        [2.2041、2.5388、2.3315]]）

我想排除（零）元素（以及 my_tensor 的相应行），这样它们就不会参与计算图：
inp_tensor = torch.tensor(
        [[0.7860, 0.1115, 0.6524, 0.6057, 0.3725, 0.7980]]) # 根据索引删除元素（这里是零）

my_tensor = torch.tensor(
        [[0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.2666, 0.6274, 0.2696]]) # 删除对应的零元素行

b = torch.mm(inp_tensor, my_tensor)
打印(b)
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330]])

inp_tensor = torch.tensor([[1.0000, 0.1115, 0.6524, 0.6057, 0.3725, 1.0000]]) # 根据索引删除元素（这里是零）

my_tensor = torch.tensor(
        [
        [0.8823, 0.9150, 0.3829],
        [0.9593, 0.3904, 0.6009],
        [0.1332, 0.9346, 0.5936],
        [0.8694, 0.5677, 0.7411],
        [0.4294, 0.8854, 0.5739],
        [0.4414, 0.2969, 0.8317]]) # 删除对应的零元素行

c = torch.mm(inp_tensor, my_tensor)
打印（三）
&gt;&gt;&gt;&gt;&gt;张量([[2.2041, 2.5388, 2.3315]])
打印（火炬.cat（[b，c]））
&gt;&gt;&gt;&gt;&gt;张量([[1.7866, 2.5468, 1.6330],
        [2.2041、2.5388、2.3315]]）

我需要它是高效的（即，没有for循环），因为我的张量非常大，并且还需要保持梯度（即，如果我调用optimizer.backward( ）更新计算图中的相关参数）
请注意，inp_tensor 的每一行都有相同数量的要删除的元素（例如，本示例中的零个元素）。因此，mask_indices 的每一行也将具有相同数量的元素（例如，本例中为 2）。]]></description>
      <guid>https://stackoverflow.com/questions/78404705/how-to-multiply-matrices-and-exclude-elements-based-on-masking</guid>
      <pubDate>Mon, 29 Apr 2024 19:07:12 GMT</pubDate>
    </item>
    <item>
      <title>带有正则化的 Numpy 线性回归</title>
      <link>https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization</link>
      <description><![CDATA[我没有发现我的正则化线性回归代码有什么问题。未正规化我只是这样，我有理由确定这是正确的：
将 numpy 导入为 np

def get_model（特征，标签）：
    返回 np.linalg.pinv(features).dot(labels)

这是我的正则化解决方案的代码，我没有看到它有什么问题：
def get_model(特征、标签、lamb=0.0):
    n_cols = features.shape[1]
    返回 linalg.inv(features.transpose().dot(features) +lambda * np.identity(n_cols))\
            .dot(features.transpose()).dot(标签)

使用羔羊的默认值 0.0，我的意图是它应该给出与（正确的）非正则化版本相同的结果，但差异实际上相当大。
有人看出问题出在哪里吗？]]></description>
      <guid>https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization</guid>
      <pubDate>Mon, 15 Dec 2014 03:26:53 GMT</pubDate>
    </item>
    </channel>
</rss>