<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Sat, 10 Aug 2024 06:20:07 GMT</lastBuildDate>
    <item>
      <title><AI>AI 在驾驶辅助评估系统中有哪些用途？</title>
      <link>https://stackoverflow.com/questions/78855323/aiwhat-are-some-of-the-ways-in-which-ai-can-be-used-in-relation-to-driver-assi</link>
      <description><![CDATA[我正在学习驾驶辅助领域的人工智能。
我的导师告诉我要清楚在哪些领域以及出于什么目的我会使用人工智能。
以下是我在网上研究和询问 ChatGPT 时得到的想法。
个性化驾驶员指导
领域：驾驶员行为优化
目的：

人工智能可用于开发适应个人驾驶风格的个性化驾驶员指导系统。
通过分析一段时间内的数据，该系统可以提供量身定制的反馈，帮助驾驶员提高燃油效率、减少车辆磨损，甚至提高安全性。
该系统可以与现有的远程信息处理集成，并使用人工智能生成针对每个驾驶员的特定见解。

数据收集：

车载诊断 (OBD) 数据：从车辆的 OBD 系统，包括加速模式、制动行为和燃油消耗。
驾驶员分析：分析一段时间内的驾驶模式，为每个驾驶员创建一份档案，然后可用于个性化指导建议。

如果有比我选择的更值得关注的细分领域，请告诉我。
或者如果您有任何建议或其他想法，我很乐意听取。]]></description>
      <guid>https://stackoverflow.com/questions/78855323/aiwhat-are-some-of-the-ways-in-which-ai-can-be-used-in-relation-to-driver-assi</guid>
      <pubDate>Sat, 10 Aug 2024 05:52:07 GMT</pubDate>
    </item>
    <item>
      <title>构建 ML 模型时如何选择合适的标签</title>
      <link>https://stackoverflow.com/questions/78854998/how-to-choose-the-appropriate-label-when-building-a-ml-model</link>
      <description><![CDATA[我正在尝试为特定任务训练模型。
这里有一个简单的描述：
image1
image2
以下是两个不同数据集的屏幕截图：图 1 中的数据顺序正确，没有错误，也没有缺失数据。另一方面，图 2 中的数据是无序的，包含噪音，并且有缺失数据。
我想训练一个模型，当输入图 2 中显示类型的数据时，该模型可以返回图 1 中显示类型的数据。
我尝试使用 RF 和 CNN 模型，但结果并没有像我预期的那样发展。我在想这可能是由于标签选择不正确造成的。
其实从图1中，很容易就能发现其中的联系。
例如，
1 2 3 4
A A-1 B B-1
A2 A2-1 B2 B2-1
A3 A3-1 B3 B3-1
A4 A4-1 B4 B4-1
图1这类数据中，A=A2-1，A2=A3-1\
因此，我希望模型能够学习到这种关系，然后在乱序的数据（图2）中找出正确的顺序。一旦确定了一个正确的序列，就可以通过递归得到正确且唯一的顺序。由于行与行之间是相互对应的（即 A A-1 B B-1 固定在同一行），一旦正确确定了一列的序列，整个序列也正确确定了。
所以我尝试使用模型来解决这个问题。该模型能够运行并学到了一些东西，但没有学到任何有用的东西。我开始意识到问题可能在于标签选择。（事实上，这个问题可能可以用算法来解决，但我想用机器学习来实现它。）
我希望有人能就如何选择标签以及拆分训练集和验证集提供建议。]]></description>
      <guid>https://stackoverflow.com/questions/78854998/how-to-choose-the-appropriate-label-when-building-a-ml-model</guid>
      <pubDate>Sat, 10 Aug 2024 01:22:04 GMT</pubDate>
    </item>
    <item>
      <title>我该如何解释这个训练/验证损失曲线？[关闭]</title>
      <link>https://stackoverflow.com/questions/78854439/how-can-i-interpret-this-training-validation-loss-curve</link>
      <description><![CDATA[我实现了机器学习算法进行分类，并生成了训练/验证损失曲线。
这里是：
训练/验证损失曲线
我该如何解释它，我从未见过这样的曲线。它是否显示了一个好的模型？感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/78854439/how-can-i-interpret-this-training-validation-loss-curve</guid>
      <pubDate>Fri, 09 Aug 2024 19:57:12 GMT</pubDate>
    </item>
    <item>
      <title>使用基于随机傅里叶特征 (RFF) 的核 LMS 进行在线联邦学习模拟时出现意外 MSE 行为</title>
      <link>https://stackoverflow.com/questions/78854316/unexpected-mse-behavior-in-online-federated-learning-simulation-using-random-fou</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78854316/unexpected-mse-behavior-in-online-federated-learning-simulation-using-random-fou</guid>
      <pubDate>Fri, 09 Aug 2024 19:13:39 GMT</pubDate>
    </item>
    <item>
      <title>MMpose 推断器不适用于 MP4 文件</title>
      <link>https://stackoverflow.com/questions/78854257/mmpose-inferencer-not-working-for-mp4-files</link>
      <description><![CDATA[我正在尝试使用 MMPose 在视频中的个人的 3D 空间中查找关键点。我使用的代码（之前在 2d 中运行过）是：
from mmpose.apis import MMPoseInferencer
from pathlib import Path
import os

data_folder = Path(&quot;x/videos&quot;)
for filename in os.listdir(data_folder):
if not filename.endswith(&#39;.mp4&#39;):
continue
img_path = os.path.join(data_folder, filename)

inferencer = MMPoseInferencer(pose3d=&quot;human3d&quot;)

result_generator = inferencer(img_path, out_dir=&#39;output&#39;)

每当我尝试访问 results_generator（如 results = [result for result in result_generator]）时，我都会遇到段错误，我猜是因为 result_generator 中没有任何内容。我还希望输出文件夹中有可视化效果和数据，但该文件夹是空的。我有什么明显的错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78854257/mmpose-inferencer-not-working-for-mp4-files</guid>
      <pubDate>Fri, 09 Aug 2024 18:55:46 GMT</pubDate>
    </item>
    <item>
      <title>如何下载机器学习的数据集但仅限于我的 python 文件中？</title>
      <link>https://stackoverflow.com/questions/78854017/how-do-i-download-datasets-for-machine-learning-but-only-in-my-python-file</link>
      <description><![CDATA[我需要下载音频数据集。我正在关注此 Tensorflow 教程，但我不知道如何获取像教程中用于设置原点的链接。我正在使用 Google Collab。
DATASET_PATH = &#39;data/mini_speech_commands&#39;

data_dir = pathlib.Path(DATASET_PATH)
if not data_dir.exists():
tf.keras.utils.get_file(
&#39;mini_speech_commands.zip&#39;,
origin=&quot;http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip&quot;,
extract=True,
cache_dir=&#39;.&#39;, cache_subdir=&#39;data&#39;)

commands = np.array(tf.io.gfile.listdir(str(data_dir)))
commands = commands[(commands != &#39;README.md&#39;) &amp; (commands != &#39;.DS_Store&#39;)]
print(&#39;Commands:&#39;, command)

按照教程中的所有内容，它可以正常工作，但我不明白将音频数据集放入我的 python 文件中的过程以及如何浏览每个音频。]]></description>
      <guid>https://stackoverflow.com/questions/78854017/how-do-i-download-datasets-for-machine-learning-but-only-in-my-python-file</guid>
      <pubDate>Fri, 09 Aug 2024 17:32:08 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Movenet 检测正确和不正确的姿势？[关闭]</title>
      <link>https://stackoverflow.com/questions/78853603/how-would-i-use-movenet-to-detect-correct-and-incorrect-poses</link>
      <description><![CDATA[我正在尝试使用 Tensorflow、Keras 和 Movenet 检测正确和不正确的坐姿。目前，我在训练、有效和测试文件夹中有好姿势和坏姿势文件夹，其中包含相应的姿势。我对编码模型的方法有一些想法，但我不确定哪种方法真正有效/最合适：

保留好姿势/坏姿势文件夹，使用数据构建和训练 CNN，然后构建/训练微调神经网络以对好姿势和坏姿势进行分类

仅保留好姿势图像，使用斜率计算某些身体部位的正确位置，不构建 CNN。我能想到的唯一问题是，如果某个身体部位阻碍了另一个身体部位怎么办？例如，我有一张正确姿势的照片，我的手臂放在桌子上，准备打字，但我还有另一张正确姿势的照片，我的手臂放在身体两侧，前臂向下不可见。或者姿势不正确，如果有人身体倾斜，脸靠在手上，身体的某些部位就看不见了怎么办？我或 Movenet 会如何处理这种情况？

完全不同的方法

]]></description>
      <guid>https://stackoverflow.com/questions/78853603/how-would-i-use-movenet-to-detect-correct-and-incorrect-poses</guid>
      <pubDate>Fri, 09 Aug 2024 15:33:58 GMT</pubDate>
    </item>
    <item>
      <title>如何完成遮挡的形状？[关闭]</title>
      <link>https://stackoverflow.com/questions/78853333/how-to-complete-occluded-shapes</link>
      <description><![CDATA[我正在做一个项目来补全遮挡形状。
我浏览了互联网，发现我们可以使用插值方法来完成不完整的曲线，但唯一的问题是，在我使用的数据中（在包含每条曲线的点的 csv 文件中），曲线是封闭的……有什么想法可以做到这一点吗？

就像下面给出的这张图片一样，输入是一个 csv 文件，其中包含 3 条曲线的数据点，这些曲线都是封闭的。如果我单独绘制被遮挡的椭圆的输入点，它们将像第二张照片一样出现，而不仅仅是不完整的椭圆边界曲线。

输出应如下所示：
]]></description>
      <guid>https://stackoverflow.com/questions/78853333/how-to-complete-occluded-shapes</guid>
      <pubDate>Fri, 09 Aug 2024 14:32:17 GMT</pubDate>
    </item>
    <item>
      <title>无法设置张量：获取 STRING 类型的值，但输入 0 应为 FLOAT32 类型，名称：serving_default_args_0:0</title>
      <link>https://stackoverflow.com/questions/78853060/cannot-set-tensor-got-value-of-type-string-but-expected-type-float32-for-input</link>
      <description><![CDATA[当我尝试加载模型时，我收到一条错误消息
这是我的代码
interpreter = tf.lite.Interpreter(model_path=&quot;/content/colab_model.tflite&quot;)
interpreter.allocate_tensors()

# 获取输入和输出张量。
input_details = explainer.get_input_details()
output_details = explainer.get_output_details()
# 打印输入详细信息以了解其预期类型和形状
for input_detail in input_details:
print(f&quot;Name: {input_detail[&#39;name&#39;]}, Shape: {input_detail[&#39;shape&#39;]}, Dtype: {input_detail[&#39;dtype&#39;]}&quot;)

# 将用户 ID 转换为字符串
user_id_value = np.array([&#39;42&#39;], dtype=np.str_) 

# 将配方 ID 转换为字符串
recipe_id_values = np.array([&#39;49&#39;, &#39;66&#39;, &#39;62&#39;], dtype=np.str_)

# 使用字符串设置张量值
interpreter.set_tensor(input_details[0][&#39;index&#39;], np.array([recipe_id_values[0]])) 
interpreter.set_tensor(input_details[1][&#39;index&#39;], user_id_value)

# 调用模型
interpreter.invoke()

# 获取输出
output_data = interpretationer.get_tensor(output_details[0][&#39;index&#39;])
print(output_data)

错误
ValueError: 无法设置张量：得到的值类型为 STRING，但输入 0 的预期类型为 FLOAT32，名称为：serving_default_args_0:0

当我尝试先将其转换为浮点 32 时，出现错误
RuntimeError: 将浮点转换为字符串是错误的支持的委托内核未初始化节点号 19 (TfLiteFlexDelegate) 准备失败。委托内核未初始化节点号 19 (TfLiteFlexDelegate) 准备失败。委托内核未初始化节点号 19
(TfLiteFlexDelegate) 准备失败。
]]></description>
      <guid>https://stackoverflow.com/questions/78853060/cannot-set-tensor-got-value-of-type-string-but-expected-type-float32-for-input</guid>
      <pubDate>Fri, 09 Aug 2024 13:30:18 GMT</pubDate>
    </item>
    <item>
      <title>如何集成一项功能来识别手绘形状并实时重新绘制它[关闭]</title>
      <link>https://stackoverflow.com/questions/78852946/how-to-integrate-a-feature-to-recognize-hand-drawn-shapes-and-redraw-it-in-real</link>
      <description><![CDATA[我正在构建一个项目，它可以跟踪我的手指运动并根据我的运动在屏幕上绘图。为此，我使用了 mediaPipe Hands 解决方案。我想集成一个功能来识别圆形、矩形等形状，并以理想的形式重新绘制它。
（当然是视频流）
我实现了一个功能来识别使用 OpenCV 在屏幕上绘制的形状。我尝试在绘图模式下捕获手指跟踪的点，并使用这些点来检测所绘制的形状是圆形还是矩形。我期望它在完成后准确识别形状。然而，实际发生的是，一旦我进入绘图模式，系统就开始将我的手指检测为圆形，并在手指移动到的每个点周围绘制一个圆圈。
我如何检测我正在绘制的形状，然后完美地重新绘制它们？
def understand_shape(points):
if len(points) &lt; 5：
return None

# 计算点的边界框
x_coords, y_coords = zip(*points)
min_x, max_x = min(x_coords), max(x_coords)
min_y, max_y = min(y_coords), max(y_coords)
width, height = max_x - min_x, max_y - min_y

# 使用半径方差检查圆
center_x, center_y = np.mean(x_coords), np.mean(y_coords)
radii = [distance.euclidean((x, y), (center_x, center_y)) for x, y in points]
mean_radius = np.mean(radii)
radius_variance = np.var(radii)

if radius_variance &lt; 1000：# 调整阈值以提高准确度
return (&quot;circle&quot;, (int(center_x), int(center_y), int(mean_radius)))

# 使用纵横比检查矩形
if 0.9 &lt; width / height &lt; 1.1：# 允许正方形略有偏差
if all(min_x &lt;= x &lt;= max_x and min_y &lt;= y &lt;= max_y for x, y in points):
return (&quot;rectangle&quot;, (min_x, min_y, max_x, max_y))

return None

def draw_shape(shape, imgCanvas):
if shape[0] == &quot;circle&quot;:
_, (center_x, center_y, radius) = shape
cv2.circle(imgCanvas, (center_x, center_y), radius, (0, 0, 255), 2)
elif shape[0] == &quot;rectangle&quot;:
_, (min_x, min_y, max_x, max_y) = shape
cv2.rectangle(imgCanvas, (min_x, min_y), (max_x, max_y), (0, 0, 255), 2)
]]></description>
      <guid>https://stackoverflow.com/questions/78852946/how-to-integrate-a-feature-to-recognize-hand-drawn-shapes-and-redraw-it-in-real</guid>
      <pubDate>Fri, 09 Aug 2024 13:06:37 GMT</pubDate>
    </item>
    <item>
      <title>如何找到参数之间的因果关系？[关闭]</title>
      <link>https://stackoverflow.com/questions/78852790/how-to-find-causal-relationship-between-parameters</link>
      <description><![CDATA[我的公司生产嵌入式设备，我们从这些设备中收集了一堆参数（几百个），保存在 CSV 文件中。现在我想找到一个重要的错误参数和所有其他参数之间的因果关系。到目前为止，我所做的就是训练一个 SVM 模型，以重要的错误参数为目标，其余参数为特征，然后找到对目标参数贡献最大的特征。我对结果非常满意，因为贡献最大的标签实际上是有意义的，并且该模型在测试数据上的准确率超过了 90%。
但我不知道如何从这些结果继续找到特定事件中的贡献参数。例如，如果触发了这个错误参数 - 我如何使用我训练过的模型知道哪个参数是贡献最大的参数（假设所有其他参数的上下文）？目前，模型只能告诉我触发错误参数的可能性 - 但不能反过来。]]></description>
      <guid>https://stackoverflow.com/questions/78852790/how-to-find-causal-relationship-between-parameters</guid>
      <pubDate>Fri, 09 Aug 2024 12:31:24 GMT</pubDate>
    </item>
    <item>
      <title>使用 device_map 选择可用的 GPU 设备</title>
      <link>https://stackoverflow.com/questions/78852192/choose-available-gpu-devices-with-device-map</link>
      <description><![CDATA[from transformers import AutoTokenizer, AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(
model_id,
torch_dtype=torch.bfloat16,
device_map=&quot;cuda:3&quot;,
)

服务器上有很多 GPU，但我只能使用其中两个。我应该如何配置 device_map（或其他参数）才能让模型在两个 GPU 上运行？]]></description>
      <guid>https://stackoverflow.com/questions/78852192/choose-available-gpu-devices-with-device-map</guid>
      <pubDate>Fri, 09 Aug 2024 10:04:34 GMT</pubDate>
    </item>
    <item>
      <title>将图像数据地理配准到 Google staelite 地图的最佳方法是什么？</title>
      <link>https://stackoverflow.com/questions/78852106/what-is-the-best-way-to-georeference-image-data-to-google-staelite-map</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78852106/what-is-the-best-way-to-georeference-image-data-to-google-staelite-map</guid>
      <pubDate>Fri, 09 Aug 2024 09:42:51 GMT</pubDate>
    </item>
    <item>
      <title>我该如何修剪这个神经网络？</title>
      <link>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network</link>
      <description><![CDATA[我正在使用 TensorFlow 在 Python 中创建一个用于 PA 行为建模的传统神经网络。该模型接收输入 I 和 Q 值并预测放大器输出。所以这是一个包含两列的 .csv 文件。我的目标之一是修剪（或以任何方式优化）我构建的模型。原始模型运行良好。但是，我在修剪创建、训练和测试的模型时遇到了问题。
以下是原始模型：
import os

os.environ[&#39;TF_ENABLE_ONEDNN_OPTS&#39;] = &#39;0&#39;

import keras
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Model, load_model, save_model, clone_model, Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.metrics import Accuracy
import tensorflow_model_optimization as tfmot
import time

# 加载数据
data_input = pd.read_csv(&#39;Input_TimeAligned.csv&#39;,header = None)
data_input.columns = [&#39;i&#39;,&#39;q&#39;]
data_input.describe()
data_input.head()

data_input_arr = data_input.to_numpy()
print(&#39;以数组形式输入数据：&#39;,data_input_arr)
print(len(data_input_arr))
print()

data_output = pd.read_csv(&#39;Output_TimeAligned.csv&#39;,header = None)
data_output.columns = [&#39;i&#39;,&#39;q&#39;]
data_output.describe()
data_output.head()

data_output_arr = data_output.to_numpy()
print(&#39;以数组形式输出数据：&#39;,data_output_arr)
print(len(data_output_arr))
print()

data_input_tr = data_input_arr[0:122879,:]
data_output_tr = data_output_arr[0:122879,:]

data_input_test = data_input_arr[122880:491519,:]

data_output_test = data_output_arr[122880:491519,:]

X_train = data_input_tr
y_train = data_output_tr

X_test = data_input_test
y_test = data_output_test

# 定义模型架构。
开始 = time.time()
模型 = keras.Sequential([
keras.layers.InputLayer(input_shape = (2,)),
keras.layers.Dense(单位 = 128, 激活 = &#39;tanh&#39;, 名称 = &#39;layer_1&#39;),
keras.layers.Dense(单位 = 256, 激活 = &#39;tanh&#39;, 名称 = &#39;layer_2&#39;),
keras.layers.Dense(单位 = 512, 激活 = &#39;tanh&#39;, 名称 = &#39;layer_3&#39;),
keras.layers.Dense(单位 = 256, 激活 = &#39;tanh&#39;, 名称 = &#39;layer_4&#39;),
keras.layers.Dense(单位 = 128, 激活 = &#39;tanh&#39;, 名称 = &#39;layer_5&#39;),
keras.layers.Dense(单位 = 2, 激活 = &#39;tanh&#39;, name = &#39;output_layer&#39;),
])

model.compile(loss = &#39;mean_squared_error&#39;, optimizer = &#39;adam&#39;, metrics = [&#39;Accuracy&#39;])
end = time.time()
print(&#39;编译模型所用时间为：&#39;, end - start)
print()

print(model.summary())
print()

start = time.time()
model.fit(X_train, y_train, epochs = 3, batch_size = 32) 
end = time.time()
print(&#39;训练模型所用时间为：&#39;, end - start)
print()

start = time.time()
y_hat = model.predict(X_test)
end = time.time()
print(&#39;测试模型所用时间为：&#39;, end - start)
print(&#39;预测输出为：&#39;, y_hat)
print()

start = time.time()
model.evaluate(X_test, y_test)
end = time.time()
print(&#39;评估模型所用时间为：&#39;, end - start)
print()

我尝试了如下所示的修剪：
prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude

# 定义修剪模型。
pruning_params = {
&#39;pruning_schedule&#39;: tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0,
final_sparsity=0.50,
begin_step=0,
end_step=1000)
}

model_for_pruning = prune_low_magnitude(model, **pruning_params)

# `prune_low_magnitude` 需要重新编译。
model_for_pruning.compile(optimizer=&#39;adam&#39;,
loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
metrics=[&#39;accuracy&#39;])

model_for_pruning.summary()

start = time.time()
model.compile(
loss=&quot;mse&quot;,
optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)
)
end = time.time()
print(&#39;编译修剪模型所花费的时间为：&#39;, end - start)
print()

print(model.summary())
print()

start = time.time()
model.fit(
X_train, 
y_train, 
epochs=3, 
batch_size=32, 
#callbacks= pruning_callback, 
# verbose=1
)
end = time.time()
print(&#39;训练修剪模型所花费的时间为：&#39;, end - start)

start = time.time()
y_hat = model.predict(X_test)
end = time.time()
print(&#39;测试修剪模型所花费的时间为：&#39;, end - start)
print(&#39;预测输出为：&#39;, y_hat)
print()

start = time.time()
model.evaluate(X_test, y_test)
end = time.time()
print(&#39;评估修剪模型所花费的时间为：&#39;, end - start)
print()

这是我收到的错误：
ValueError: `prune_low_magnitude` 只能修剪以下类型的对象：keras.models.Sequential、keras 函数模型、keras.layers.Layer、keras.layers.Layer 列表。您传递了一个类型为 Sequential 的对象。

我在这里做错了什么？]]></description>
      <guid>https://stackoverflow.com/questions/78851708/how-can-i-prune-this-neural-network</guid>
      <pubDate>Fri, 09 Aug 2024 07:50:59 GMT</pubDate>
    </item>
    <item>
      <title>无需深度学习或 Tesseract 的文本图像二元分类器</title>
      <link>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</link>
      <description><![CDATA[我有 20k 张小标签图像，每张图像都有单词“Back”或“Front”。
图像分辨率为全部 (200px, 25px)

我可以使用 tesseract_OCR 对这些图像进行 100% 准确率的分类。
 txt = pytesseract.image_to_string(img, lang=&#39;eng&#39;)
if &quot;Front&quot; in txt:
return &quot;Front&quot;
if &quot;Back&quot; in txt:
return &quot;Back&quot;

问题是，它太慢了（20k 张图像需要 1 小时）并且需要安装 OCR 包。
我知道即使是 3 层的简单 CNN 也能很好地运行，但我认为这个问题似乎可以用简单的算法解决，而不需要复杂的技术。
你能给我推荐一种新方法吗？
谢谢。]]></description>
      <guid>https://stackoverflow.com/questions/78842184/text-image-binary-classifier-without-deep-learning-or-tesseract</guid>
      <pubDate>Wed, 07 Aug 2024 06:46:36 GMT</pubDate>
    </item>
    </channel>
</rss>