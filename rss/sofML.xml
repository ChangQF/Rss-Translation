<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Mon, 10 Mar 2025 12:35:53 GMT</lastBuildDate>
    <item>
      <title>错误分类的样本是单独的类[关闭]</title>
      <link>https://stackoverflow.com/questions/79496368/misclassified-samples-as-a-separate-class</link>
      <description><![CDATA[我一直在尝试将一组数据分类用于二进制分类。我看到数据的一个子集被错误分类，我删除了该子集，分类器的准确性从88％提高到96％。
我正在考虑为这些样本创建一个单独的类，然后与多类分类进行分类。这是合适的吗？
还有其他处理这些样品的方法吗？这些样本现在由二进制分类器随机分配给两个类。至少几次，我将决策树重现。]]></description>
      <guid>https://stackoverflow.com/questions/79496368/misclassified-samples-as-a-separate-class</guid>
      <pubDate>Sun, 09 Mar 2025 18:06:59 GMT</pubDate>
    </item>
    <item>
      <title>我在形状对齐中遇到了错误，该如何解决？</title>
      <link>https://stackoverflow.com/questions/79496192/i-am-having-a-error-with-shape-alignment-how-can-i-solve-this</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79496192/i-am-having-a-error-with-shape-alignment-how-can-i-solve-this</guid>
      <pubDate>Sun, 09 Mar 2025 16:02:56 GMT</pubDate>
    </item>
    <item>
      <title>如何在虚幻引擎5中加入libtorch？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-in-unreal-engine-5</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79496110/how-to-include-libtorch-in-unreal-engine-5</guid>
      <pubDate>Sun, 09 Mar 2025 15:03:36 GMT</pubDate>
    </item>
    <item>
      <title>当用简化运行时，模态可以正常执行。但是，当输入图像时，它无法正常工作</title>
      <link>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79495567/when-run-with-streamlit-the-modal-performs-properly-however-when-an-image-is</guid>
      <pubDate>Sun, 09 Mar 2025 07:49:34 GMT</pubDate>
    </item>
    <item>
      <title>无法使用NLTK功能</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>二进制分类：为什么使用+1/0作为标签， +1/-1甚至 +100/-100之间有什么区别</title>
      <link>https://stackoverflow.com/questions/74752325/binary-classification-why-use-1-0-as-label-whats-the-difference-between-1-1</link>
      <description><![CDATA[在二进制分类问题中，我们通常将+1用于正标，为负标签0。  这是为什么？特别是为什么使用0而不是-1作为负面标签？
使用-1用于负标签，甚至更普遍，我们可以将+100用于正标签，而-100可以用于负标签？？]]></description>
      <guid>https://stackoverflow.com/questions/74752325/binary-classification-why-use-1-0-as-label-whats-the-difference-between-1-1</guid>
      <pubDate>Sat, 10 Dec 2022 11:05:01 GMT</pubDate>
    </item>
    <item>
      <title>重新启动运行时，模型负载获得不同的结果</title>
      <link>https://stackoverflow.com/questions/68116676/model-load-get-different-result-after-restart-runtime</link>
      <description><![CDATA[我已经使用Google Colab编写了Resnet50型号。训练我的模型后，然后在不重新启动运行时间的情况下保存模型后，将获得相同的结果，但是在重新启动运行时Google Colab并运行 Xtrain，Ytest，Ytest，X_Val，Y_VAL，Y_VAL 然后再次加载模型，我将获得不同的结果。
这是我的代码：
  #hyperParameter和回调
batch_size = 128
num_epochs = 120
input_shape =（48、48、1）
num_classes = 7

#compile模型。
从keras.optimizer进口亚当，sgd
model = resnet50（input_shape =（48、48、1），类= 7）
优化器= SGD（Learning_rate = 0.0005）
model.compile（优化器=优化器，lose =&#39;Sparse_categorical_crossentropy&#39;，metrics = [&#39;准确性&#39;]）

model.summary（）
历史= model.fit（
    data_generator.flow（Xtrain，ytrain，），
    step_per_epoch = len（xtrain） / batch_size，
    epochs = num_epochs， 
    详细= 1，
    验证_data =（x_val，y_val））

导入matplotlib.pyplot作为PLT 
model.save（&#39;fix_model_resnet50editsgd5st.h5&#39;）

#plot图
准确性=历史[&#39;精确度&#39;]
val_accuracy =历史[&#39;val_accuracy&#39;]
损失=历史[&#39;损失&#39;]
val_loss =历史[&#39;val_loss&#39;]
num_epochs = range（len（准确性））
plt.plot（num_epochs，准确性，&#39;r&#39;，label =&#39;triending acc&#39;）
plt.plot（num_epochs，val_accuracy，&#39;b&#39;，label =&#39;验证acc&#39;）
plt.title（“训练和验证精度”）
plt.ylabel（“准确性”）  
plt.xlabel（&#39;epoch&#39;）
plt.legend（）
plt. -figure（）
plt.plot（num_epochs，损失，&#39;r&#39;，label =“训练损失”）
plt.plot（num_epochs，val_loss，&#39;b&#39;，label =&#39;验证损失&#39;）
plt.title（“培训和验证损失”）
plt.ylabel（“损失”）  
plt.xlabel（&#39;epoch&#39;）
plt.legend（）
plt.show（）

#load模型
来自keras.models import load_model
model_load = load_model（&#39;fix_model_resnet50editsgd5st.h5&#39;）

model_load.summary（）


testdatamodel = model_load.evaluate（Xtest，ytest） 
打印（“测试损失” + str（testdatamodel [0]））
打印（“测试ACC：＆quot” + str（testdatamodel [1]））

traindata = model_load.evaluate（xtrain，ytrain） 
打印（“测试损失” + str（traindata [0]））
打印（“测试acc：＆quot” + str（traindata [1]））

valdata = model_load.evaluate（x_val，y_val） 
打印（“测试损失” + str（valdata [0]））
打印（“测试acc：＆quot” + str（valdata [1]））
 
  - 训练和保存模型后，然后运行加载模型，而无需重新启动运行时Google Colab：
如您所见
测试损失：0.9411-精度：0.6514 
火车损失：0.7796-准确性：0.7091 
  modelevaluateTestest＆amp;火车 
在重新启动运行时Colab之后再次运行加载模型：
测试损失：0.7928-准确性：0.6999 
火车损失：0.8189-准确性：0.6965 
 重新启动运行时评估测试和训练 ]]></description>
      <guid>https://stackoverflow.com/questions/68116676/model-load-get-different-result-after-restart-runtime</guid>
      <pubDate>Thu, 24 Jun 2021 13:25:12 GMT</pubDate>
    </item>
    <item>
      <title>如何在XGBoost中的提升回合之间显示错误输出？</title>
      <link>https://stackoverflow.com/questions/58429786/how-to-show-error-output-between-boosting-rounds-in-xgboost</link>
      <description><![CDATA[我正在使用Scikit-Learn API， XGBRegressor 。我正在尝试使我的模型尽可能详细。这些是模型的参数。这是在Kaggle内核上运行的。  df_train 和 df_target 是pandas dataframes。
  model = XGB.XGBRegressor（
    n_estimators = 2 ** 8，
    max_depth = 5，
    Learning_rate = 0.04，
    子样本= 0.9，
    colsample_bytree = 0.9，    
    objective =&#39;reg：squarederror&#39;，
    booster =&#39;gbtree&#39;，
    eximplease_type =&#39;strige&#39;，
    tree_method =&#39;gpu_hist&#39;，
    静音= false，    
    Random_State =种子
）
 
这是 fit（）的参数。我必须看到像LightGBM这样的提升回合之间的训练RMSE。 XGBoost具有该功能吗？
  model.fit（df_train，df_target，eval_metric =&#39;rmse&#39;，eval_set = [（df_train，df_target）]，verbose = true）
 ]]></description>
      <guid>https://stackoverflow.com/questions/58429786/how-to-show-error-output-between-boosting-rounds-in-xgboost</guid>
      <pubDate>Thu, 17 Oct 2019 09:52:56 GMT</pubDate>
    </item>
    <item>
      <title>无法获得我的线性回归的准确分数</title>
      <link>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</link>
      <description><![CDATA[我正在基于IMDB数据进行回归模型，以预测IMDB值。在线性回归上，我无法获得准确的得分。
我的代码行：
 量表
 
错误：
  valueerror：不支持连续
 
如果我要更改该线以获得R2分数，
  Metrics.R2_Score（test_y，linear_predicated_rating）
 
我能够获得R2而没有任何错误。
我为什么看到这个？
注意： test_y 是pandas dataframe]]></description>
      <guid>https://stackoverflow.com/questions/45627784/unable-to-obtain-accuracy-score-for-my-linear-regression</guid>
      <pubDate>Fri, 11 Aug 2017 05:46:30 GMT</pubDate>
    </item>
    <item>
      <title>决策树与逻辑回归相结合[关闭]</title>
      <link>https://stackoverflow.com/questions/41692017/decision-trees-combined-with-logistic-regression</link>
      <description><![CDATA[基本上我的问题与以下论文有关（仅读取节 1. Introwuction ，的开始 3.预测模型结构   3.1决策树特征变换，其他一切都可以跳过））
  https://pdfs.semanticscholar.org/daf9/ed5dc6c6bad5367d7d7fd8561527da30e9b8dd.pdf.pdf  
本文表明，与仅使用决策树或线性分类（不是两者）相比，二进制分类可以表现出更好的性能（例如，逻辑回归）。
简单地说，诀窍是我们有几个决策树（假设2棵树以简单起见，第一棵树带有3个叶子节点和带有2个叶子节点的第二棵树）和一些实现的特征矢量 x ，这是所有决策树的输入 
 so，

如果第一棵树的决定是叶节点1 ，第二个树的决定是叶节点2 ，那么线性分类器将接收二进制字符串 [1 0 0 0 0 0 1]  
如果第一棵树的决定是叶节点2 ，第二个树的决定是叶节点1 ，则线性分类器将接收二进制字符串 [0 1 0 1 0 1 0]  

等等
If we used only decision trees (without linear classification), clearly we would have either class 100/ class 010/class 001 for 1st tree and class 10/ class 01 for 2nd tree, but in this scheme the outputs of trees are combined into binary string which is fed to linear classifier.因此，尚不清楚如何训练这些决策树吗？我们拥有的是上述向量 x ，然后单击/无单击，这是线性分类的输出，而不是树
有什么想法？]]></description>
      <guid>https://stackoverflow.com/questions/41692017/decision-trees-combined-with-logistic-regression</guid>
      <pubDate>Tue, 17 Jan 2017 08:16:17 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn.decomposition.pca的特征向量的简单图</title>
      <link>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</link>
      <description><![CDATA[我正在尝试了解主组件分析的工作方式，并且我正在 sklearn.datasets.load_iris  dataset上对其进行测试。  我了解每个步骤的工作原理（例如，使用 k 选定的尺寸，将数据，协方差，特征分类，对最高特征值进行排序，将原始数据转换为新轴）。）。
下一步是可视化这些 eigenVectors 在数据集中投射到（在 pc1 vs. pc2 vs. pc2 plot 上，对吗？）。。
如何在还原尺寸数据集的3D图上绘制[PC1，PC2，PC3]特征向量？
另外，我是否正确绘制了此2D版本？我不确定为什么我的第一个特征向量的长度较短。  我应该乘以特征值吗？

 这是我为实现这一目标所做的一些研究： 
我关注的PCA方法来自：
 https://plot.ly/ipython-notebooks/principal-component-analysis/#shortcut--pca-in-scikit-learn （尽管我不想使用 Plotly 我想坚持使用。
我一直在关注本教程，以绘制特征向量，这似乎很简单： pca for matplotlib 基本示例
我找到了这个，但是我试图做的事情似乎过于复杂，我不想创建一个 fancyarrowpatch ： 的协方差矩阵

 我试图使我的代码尽可能直接地遵循其他教程： 
 导入numpy作为NP
导入大熊猫作为pd
导入matplotlib.pyplot作为PLT
来自sklearn.datasets import load_iris
从sklearn.prepercorsing进口标准标准
来自Sklearn进口分解
进口海洋为SNS； sns.set_style（&#39;whitegrid＆quort; {&#39;axes.grid&#39;：false}）

％matplotlib内联
np.random.seed（0）

＃虹膜数据集
df_data = pd.dataframe（load_iris（）。数据， 
                       index = [＆quot; iris_％d＆quot; ％i for i在范围内（load_iris（）。data.shape [0]）]，
                       列= load_iris（）。feature_names）

se_targets = pd.Series（load_iris（）。目标， 
                       index = [＆quot; iris_％d＆quot; ％i for i在范围内（load_iris（）。data.shape [0]）]， 
                       名称=“物种”

＃缩放平均= 0，var = 1
df_standard = pd.dataframe（standardscaler（）。fit_transform（df_data）， 
                           index = df_data.index，
                           列= df_data.columns）

＃用于主要组合分析的Sklearn

＃昏暗
m = df_standard.shape [1]
k = 2

＃PCA（我倾向于设置它）
m_pca = demomposition.pca（n_components = m）
df_pca = pd.dataframe（m_pca.fit_transform（df_standard）， 
                列= [＆quot; pc％d＆quot;范围内K的％k（1，m + 1）]）。iloc [：，：k]


＃绘制特征向量
#https：//stackoverflow.com/questions/18299523/basic-example-for-pca-with-matplotlib

＃这是东西很奇怪的地方...
data = df_standard

mu = data.mean（轴= 0）
eigenVector，eigenvalues = m_pca.components_，m_pca.explained_variance_ #eigenVectors，eigenvalues，v = np.linalg.svd（data.t，fult_matrices = false）
Projected_data = df_pca＃np.dot（数据，特征向量）

sigma = Projected_data.std（axis = 0）.mean（）

图，ax = plt.subplots（figsize =（10,10））
ax.Scatter（Projected_data [＆quot; pc1;]，Projected_data [＆quot; pc2＆quot;]）
对于轴，zip中的颜色（eigenVectors [：k]，[red&#39;&#39;
＃开始，end = mu，mu + sigma *轴###导致“ valueerror：太多值无法打开（预期2）”

    ＃所以我尝试过，但我认为这是不对的
    start，end =（mu）[：k]，（Mu + Sigma * Axis）[：K] 
    ax.annotate（&#39;&#39;，xy = end，xytext = start，arrowprops = dict（faceColor = color，width = 1.0））
    
ax.set_aspect（&#39;quare&#39;）
plt.show（）
 
  &lt;img alt =“在此处输入图像描述” src =“ https://i.sstatic.net.net/t9st0.png”]]></description>
      <guid>https://stackoverflow.com/questions/37976564/simple-plots-of-eigenvectors-for-sklearn-decomposition-pca</guid>
      <pubDate>Wed, 22 Jun 2016 19:20:15 GMT</pubDate>
    </item>
    <item>
      <title>逻辑回归和软磁回归之间的差异[封闭]</title>
      <link>https://stackoverflow.com/questions/36051506/difference-between-logistic-regression-and-softmax-regression</link>
      <description><![CDATA[我知道逻辑回归是用于二进制分类和用于多类问题的软磁回归。如果我使用相同的数据训练多个逻辑回归模型并将其结果归一化以获取多级分类器而不是使用一个SoftMax模型，将会有任何差异。我认为结果是相同的。我可以说：“所有多级分类器都是二进制分类器的级联结果”。 （神经元网络除外）]]></description>
      <guid>https://stackoverflow.com/questions/36051506/difference-between-logistic-regression-and-softmax-regression</guid>
      <pubDate>Thu, 17 Mar 2016 04:08:48 GMT</pubDate>
    </item>
    <item>
      <title>Sklearn Lasso回归是否比山脊回归差？</title>
      <link>https://stackoverflow.com/questions/35714772/sklearn-lasso-regression-is-orders-of-magnitude-worse-than-ridge-regression</link>
      <description><![CDATA[我目前使用 sklearn.linear_model 模块实现了脊和拉索回归。
然而，套索回归似乎在同一数据集上差3个数量级！
我不确定怎么了，因为从数学上讲，这不应该发生。这是我的代码：
  def ridge_regression（x_train，y_train，x_test，y_test，model_alpha）：
    clf = linear_model.ridge（model_alpha）
    clf.fit（x_train，y_train）
    预测= clf.predict（x_test）
    损失= np.sum（（预测-y_test）** 2）
    回报损失

def lasso_regression（x_train，y_train，x_test，y_test，model_alpha）：
    clf = linear_model.lasso（model_alpha）
    clf.fit（x_train，y_train）
    预测= clf.predict（x_test）
    损失= np.sum（（预测-y_test）** 2）
    回报损失


x_train，x_test，y_train，y_test = cross_validation.train_test_split（x，x，y，test_size = 0.1，randy_state = 0）
对于alpha，在[0，0.01，0.1，0.5，1，2，5，10，100，1000，10000]中：
    打印（alpha =&#39; + str（alpha） +;
    
对于[1、1.25、1.5、1.75、5、5、10、100、1000、10000、100000、1000000]中的alpha。
    打印（alpha =&#39; + str（alpha） +;
 
这是我的输出：
  alpha = 0：20575.7121727的拉索损失
alpha的套索损失= 0.01：19762.8763969
alpha的套索损失= 0.1：17656.9926418
alpha的拉索损失= 0.5：15699.2014387
alpha的拉索损失= 1：15619.9772649
alpha的拉索损失= 2：15490.0433166
alpha的拉索损失= 5：15328.4303197
alpha的拉索损失= 10：15328.4303197
alpha的拉索损失= 100：15328.4303197
alpha的套索损失= 1000：15328.4303197
alpha的拉索损失= 10000：15328.4303197
Alpha的脊损失= 1：61.6235890425
alpha = 1.25：61.6360790934
alpha的脊损失= 1.5：61.6496312133
alpha = 1.75：61.6636076713
alpha的脊损失= 2：61.6776331539
alpha的脊损失= 5：61.8206621527
Alpha的脊损失= 10：61.9883144732
alpha的脊损失= 100：63.9106882674
alpha = 1000：69.3266510866
alpha = 10000：82.0056669678
alpha的脊损失= 100000：88.4479064159
alpha = 1000000：91.7235727543
 
任何想法为什么？]]></description>
      <guid>https://stackoverflow.com/questions/35714772/sklearn-lasso-regression-is-orders-of-magnitude-worse-than-ridge-regression</guid>
      <pubDate>Tue, 01 Mar 2016 04:36:23 GMT</pubDate>
    </item>
    <item>
      <title>TypeError：稀疏基质长度模棱两可；使用RF分类器时使用getnnz（）或Shape [0]？</title>
      <link>https://stackoverflow.com/questions/28314337/typeerror-sparse-matrix-length-is-ambiguous-use-getnnz-or-shape0-while-usi</link>
      <description><![CDATA[我正在学习Scikit学习中的随机森林，例如，我想使用自己的数据集使用随机森林分类器进行文本分类。因此，首先，我用TFIDF对文本进行了介绍，以进行分类：
 来自sklearn.semble import incort fandyForestClassifier
classifier = RandomforestClassifier（n_estimators = 10） 
classifier.fit（x_train，y_train）           
预测= classifier.predict（x_test）
 
当我运行分类时，我得到了：
  typeError：传递了一个稀疏矩阵，但是需要密集的数据。使用X.ToArray（）转换为密集的Numpy数组。
 
然后，我使用 .toArray（）  x_train ，我得到了以下内容：
  typeError：稀疏矩阵长度是模棱两可的；使用getnnz（）或形状[0]
 
来自以前的问题当我了解我需要减少数量阵列的尺寸性时，我需要相同的尺寸：
 来自sklearn.decomposition.truncated_svd import truncatedSvd        
pca = truncatedSvd（n_components = 300）                                
X_REDUDS_TRAIN = PCA.FIT_TRANSFORM（X_TRAIN）               

从sklearn.semblection incort intim                 
classifier = RandomforestClassifier（n_estimators = 10）                  
classifier.fit（x_reduced_train，y_train）                            
预测= clastifier.predict（x_testing） 
 
然后我得到了这个例外：
 文件“/usr/local/lib/python2.7/site-packages/sklearn/ensemble/forest.py”，第419行，
    n_samples = len（x）
  文件“/usr/local/lib/python2.7/site-packages/scipy/sparse/base.py”，第192行，in __len __
    提高类型（“稀疏矩阵长度是模棱两可的；使用getnnz（）”
TypeError：稀疏基质长度模棱两可；使用getnnz（）或形状[0]
 
我尝试了以下内容：
 预测= classifier.predict（x_train.getnnz（）） 
 
并得到了：
 文件“/usr/local/lib/python2.7/site-packages/sklearn/ensemble/forest.py”，第419行，
    n_samples = len（x）
TypeError：&#39;int&#39;类型的对象没有len（）
 
从中提出了两个问题：如何使用随机森林正确分类？  x_train ？ 
然后我尝试了以下内容：
  df = pd.read_csv（&#39;/path/file.csv&#39;，
header = 0，sep =&#39;，&#39;，names = [&#39;id&#39;，&#39;text&#39;，&#39;label&#39;]）



x = tfidf_vect.fit_transform（df [&#39;text&#39;]。值）
y = df [&#39;label&#39;]。值



来自sklearn.decomposition.truncated_svd导入truncatedSVD
pca = truncatedSvd（n_components = 2）
x = pca.fit_transform（x）

a_train，a_test，b_train，b_test = train_test_split（x，y，test_size = 0.33，andural_state = 42）

从sklearn.semblection incort intim

classifier = RandomforestClassifier（n_estimators = 10）
classifier.fit（a_train，b_train）
预测= classifier.predict（a_test）

来自sklearn.metrics.metrics导入precision_score，recker_score，confusion_matrix，classification_report
打印&#39;\ nscore：&#39;，classifier.score（a_train，b_test）
打印&#39;\ nprecision：&#39;，precision_score（b_test，预测）
打印&#39;\ nRecall：&#39;，recker_score（b_test，预测）
打印&#39;\ n confussion矩阵：\ n&#39;，confusion_matrix（b_test，预测）
打印&#39;\ n clasification报告：\ n&#39;，classification_report（b_test，预测）
 ]]></description>
      <guid>https://stackoverflow.com/questions/28314337/typeerror-sparse-matrix-length-is-ambiguous-use-getnnz-or-shape0-while-usi</guid>
      <pubDate>Wed, 04 Feb 2015 05:48:35 GMT</pubDate>
    </item>
    <item>
      <title>Python中的文本分类 - （基于NLTK句子）[封闭]</title>
      <link>https://stackoverflow.com/questions/23178275/text-classification-in-python-nltk-sentence-based</link>
      <description><![CDATA[我需要对文本进行分类，并且我正在使用文本blob python模块来实现它。我可以使用幼稚的贝叶斯分类器/决策树。我担心以下提到的要点。

 我需要分类句子为参数/而不是参数。我正在使用两个分类器，并使用APT数据集​​训练模型。我的问题是我只需要用关键字训练模型吗？或者我可以用所有可能的参数训练数据集和非参数示例句子？从文本分类准确性和检索时间方面，哪种方法是最好的方法？

 由于分类要么是参数/而不是参数，因此哪个分类器将获得确切的结果？这是天真的贝叶斯/决策树/正幼稚的贝叶斯？

]]></description>
      <guid>https://stackoverflow.com/questions/23178275/text-classification-in-python-nltk-sentence-based</guid>
      <pubDate>Sun, 20 Apr 2014 04:01:27 GMT</pubDate>
    </item>
    </channel>
</rss>