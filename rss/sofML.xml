<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 28 Mar 2024 15:14:30 GMT</lastBuildDate>
    <item>
      <title>网络抓取项目[关闭]</title>
      <link>https://stackoverflow.com/questions/78238872/web-scraping-project</link>
      <description><![CDATA[我正在构建一个项目，该项目从包含远程作业的网站上抓取作业详细信息（主要关注远程开发人员作业）。这是链接：https://remote.co/remote-jobs/developer/ 
到目前为止，我已经能够获取职位名称、公司、薪水以及指向包含有关特定职位发布的更多信息的各个页面的链接，我已经能够将结果存储在 Pandas DataFrame 中，然后存储在Excel 文件。为此，我使用了 BeautifulSoup、Requests 和 Pandas 库。
我的数据框的图像
对于一些职位发布，工资没有列出（要么是 0 美元，要么没有给出），所以这给了我一个进一步推进项目的机会。我想进入每个职位发布的每个网页并提取更多特征，例如所需的经验年限，职位级​​别，公司规模，所需的技术（我打算将这部分分解为多个特征，例如所需的前端知识，后端知识所需的云知识、所需的 DevOps 知识等）以及我可以提取的任何其他可能的特征，并使用它们来训练一个模型，我可以用它来预测未指定薪资的职位发布的价格。
但是，我在知道如何解决这个问题时遇到了一些麻烦，每个单独的职位列表页面都有不同的结构，因此很难编写正确抓取所需信息的代码。
我希望 Stack Overflow 上的一些人可以帮助我，我也愿意接受与此无关的任何建议，这些建议可以使我的项目变得更好。
谢谢！
我现在陷入困境，不知道如何实现我的想法。]]></description>
      <guid>https://stackoverflow.com/questions/78238872/web-scraping-project</guid>
      <pubDate>Thu, 28 Mar 2024 14:24:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 Geotiff 图像分割</title>
      <link>https://stackoverflow.com/questions/78238294/segmentation-with-geotiff-image</link>
      <description><![CDATA[我想用 python 进行 k-means 分割。我的代码适用于 jpg 图像，但是当我尝试使用 geotiff 时，它只会使图像变成黑白。我怎么解决这个问题？下面是我的代码；
导入 matplotlib 作为 mpl
将 matplotlib.pyplot 导入为 plt
将 matplotlib.image 导入为 mpimg
从 sklearn.cluster 导入 KMeans

从 PIL 导入图像
Image.MAX_IMAGE_PIXELS = 无

从 google.colab 导入驱动器
驱动器.mount（&#39;/内容/驱动器&#39;）

# Dosya yolu，Google Drive&#39;ınızda dosyanın bulunduğu yol

file_path = &#39;/content/drive/MyDrive/Colab Notebooks/ortofoto.tif&#39;

# TIFF dosyasını oku
图像 = mpimg.imread(文件路径)
[文本]([https://stackoverflow.com](https://stackoverflow.com))

# 多斯亚伊·戈斯特
plt.imshow(图像)
plt.show()

X=图像.reshape(-1, 4)
kmeans=KMeans(n_clusters=2, n_init=10).fit(X)

segmented_img=kmeans.cluster_centers_[kmeans.labels_]
splited_img=segmented_img.reshape(image.shape)
plt.imshow(segmented_img/255)
]]></description>
      <guid>https://stackoverflow.com/questions/78238294/segmentation-with-geotiff-image</guid>
      <pubDate>Thu, 28 Mar 2024 12:48:44 GMT</pubDate>
    </item>
    <item>
      <title>无法加载可示教机器模型</title>
      <link>https://stackoverflow.com/questions/78237621/unable-to-load-the-teachable-machine-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78237621/unable-to-load-the-teachable-machine-model</guid>
      <pubDate>Thu, 28 Mar 2024 10:51:19 GMT</pubDate>
    </item>
    <item>
      <title>在 Azure Auto ML 上运行模型时遇到奇怪的错误</title>
      <link>https://stackoverflow.com/questions/78237575/strange-error-encountered-when-running-a-model-on-azure-auto-ml</link>
      <description><![CDATA[我已经在 Azure Auto ML 上研究分类器几天了，当我尝试禁用一些不需要的变量时，遇到了以下错误。
我以前从未遇到过此类错误。即使在仅使用我感兴趣的变量创建新数据集之后，错误仍然存​​在。我需要帮助来解决这个问题。谢谢
您在 Auto ML 上的数据集上使用的唯一 SQL 代码是 SELECT * FROM my_table，它可以工作，因为我可以在 Azure ML studio 上看到数据。另外我昨天才开始出现这个错误，我不知道为什么。
获取数据时遇到错误。
错误代码：ScriptExecution.Database.Unexpected
本机错误：数据流访问错误：ExecutionError(DatabaseError(Unknown(&quot;SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \&quot;解析错误位于行：1，列：22：不正确&#39;stmt&#39; 附近的语法。\&quot;，服务器：\&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 }))&quot;, Some( SQLError(Server(TokenError { 代码：103010，状态：1，类：16，消息：“行：1，列：22 处的解析错误：&#39;stmt&#39; 附近的语法不正确。”，服务器：“数据平台-sql-data-warehouse-server”，过程：“”，行：1 }))))))
    VisitError(ExecutionError(DatabaseError(Unknown(&quot;SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \&quot;第 1 行解析错误，第 22 列：“stmt”附近语法不正确) .\&quot;，服务器：\&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 }))&quot;，Some(SQLError(Server(TokenError) { 代码：103010，状态：1，类：16，消息：“第 1 行解析错误，第 22 列：&#39;stmt&#39; 附近的语法不正确。”，服务器：“data-platform-sql-data-仓库服务器”，过程：“”，行：1 })))))))
=&gt;失败并执行错误：执行数据库查询时发生错误。
    ExecutionError(DatabaseError(Unknown(&quot;SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \&quot;行解析错误：1，列：22：&#39;stmt&#39;附近的语法不正确。\ ”，服务器：\“data-platform-sql-data-warehouse-server\”，过程：\“\”，行：1 }))”，Some(SQLError(Server(TokenError { code ：103010，状态：1，类：16，消息：“行：1，列：22处解析错误：‘stmt’附近的语法不正确。”，服务器：“data-platform-sql-data-warehouse-服务器”，过程：“”，行：1 }))))))
错误消息：数据库执行失败，并显示“SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \”解析错误位于行：1，列：22：“stmt”附近的语法不正确。 \&quot;，服务器：\&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 }))&quot;。 “Ok(SQLError(Server(TokenError { code: 103010，state: 1，class: 16，message: \”解析错误位于行：1，列：22：“stmt”附近的语法不正确。\”，server : \&quot;data-platform-sql-data-warehouse-server\&quot;，过程：\&quot;\&quot;，行：1 })))&quot;| session_id=af8ac40c-2ffe-410f-8ecb-70e45405ef78

谢谢
我刚刚关闭了模型不需要的一些变量。因此，我只需创建该数据集的新版本，其中变量较少，我可以将其用于新版本的模型，这是我过去几周一直在做的事情。
我创建了一个新数据集，仅包含我需要的变量，但出现了相同的错误。现在，无论我做什么，我似乎总是遇到同样的错误。]]></description>
      <guid>https://stackoverflow.com/questions/78237575/strange-error-encountered-when-running-a-model-on-azure-auto-ml</guid>
      <pubDate>Thu, 28 Mar 2024 10:44:51 GMT</pubDate>
    </item>
    <item>
      <title>关于聚类和句子相似度的项目想法[关闭]</title>
      <link>https://stackoverflow.com/questions/78237571/project-idea-about-clustering-and-sentences-similarity</link>
      <description><![CDATA[我当前的项目是将句子嵌入到集群中。我已经有了与我的句子数据集的一部分关联的嵌入和一些集群。
我的目标是利用句子与嵌入的相似性，以便将集群应用于每个句子。
我打算使用 K 最近邻算法来用集群来标记我的每个句子。但我不确定它是否会有效地工作。
您对这种方法有何看法？我应该考虑其他方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78237571/project-idea-about-clustering-and-sentences-similarity</guid>
      <pubDate>Thu, 28 Mar 2024 10:44:24 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用训练有素的layoutlmv3时出现问题</title>
      <link>https://stackoverflow.com/questions/78237278/issue-when-trying-to-use-trained-layoutlmv3</link>
      <description><![CDATA[我正在尝试布局我训练的模型，但我不知道该怎么做。
我混合了互联网上的一些想法来做到这一点，但当我运行它时，结果完全错误。尽管在训练期间我的 F1 分数为 0.924242，准确度分数为 0.948276，但这些框根本不匹配。我在 80 个图像数据集上训练了我的模型。
我一直在尝试使用我经过培训的layoutlmv3模型，以便在我的学校项目中本地使用
如果有人能提供帮助，那就太棒了，我是机器学习的初学者。很多TKS
我一直在尝试的代码：
model_name = “checkpoint-1000”
模型 = AutoModelForTokenClassification.from_pretrained(model_name)
处理器 = AutoProcessor.from_pretrained(“microsoft/layoutlmv3-base”, apply_ocr=True)

id2label = {0: &#39;key_achats_marchandises&#39;, 1: &#39;key_actif_circulant&#39;, 2: &#39;key_actif_immobilise&#39;, 3: &#39;key_ca&#39;, 4: &#39;key_charges_sociales&#39;, 5: &#39;key_date_cloture&#39;, 6: &#39;key_dette&#39;, 7: &#39;key_disponibilites&#39; , 8: &#39;key_dotations_immobilizes&#39;, 9: &#39;key_impots&#39;, 10: &#39;key_passif_circulant&#39;, 11: &#39;key_resultat_exploitations&#39;, 12: &#39;key_rn&#39;, 13: &#39;key_salaire&#39;, 14: &#39;key_transports_expeditions&#39;,}

label2color = {“key_achats_marchandises”：“蓝色”，“key_actif_circulant”：“绿色”，“key_actif_immobilise”：“橙色”，“key_ca”：“红色”，“key_charges_sociales”：“紫色”、“key_date_cloture”：“青色”、“key_dette”：“品红色”、“key_disponibilites”：“黄色”、“key_dotations_immobilizes”：“蓝色”、“key_impots”：“紫色”绿色”、“key_passif_circulant”：“橙色”、“key_resultat_exploitations”：“红色”、“key_rn”：“紫色”、“key_salaire”：“青色”、“key_transports_expeditions”：“洋红色”,}

def unnormalize_box(bbox, 宽度, 高度):
     返回 [ 宽度 * (bbox[0] / 1000), 高度 * (bbox[1] / 1000), 宽度 * (bbox[2] / 1000), 高度 * (bbox[3] / 1000), ]

def iob_to_label(标签):
      退货标签

def process_image(图像):
      image = Image.open(image).convert(“RGB”) print(type(image)) 宽度，高度 = image.size
      编码=处理器（图像，截断= True，return_offsets_mapping = True，return_tensors =“pt”）
      offset_mapping = 编码.pop(&#39;offset_mapping&#39;)

      输出=模型（**编码）

      预测=outputs.logits.argmax(-1).squeeze().tolist()
      token_boxes=encoding.bbox.squeeze().tolist()
      打印（预测）
      is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0
      true_predictions = [id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]
      true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]
      打印（真实预测）
      绘制 = ImageDraw.Draw(图像)
      字体 = ImageFont.load_default()
      对于预测，zip 中的框（true_predictions，true_boxes）：
          预测标签 = iob_to_label(预测)
          绘制.矩形（盒子，轮廓= label2color [预测标签]）
          draw.text((box[0]+10, box[1]-10), text=predicted_label, fill=label2color[predicted_label], font=font)

      返回图像
process_image(“bilans_842953788_2019-02-28_C_2020-01-31_page_5.png”)
]]></description>
      <guid>https://stackoverflow.com/questions/78237278/issue-when-trying-to-use-trained-layoutlmv3</guid>
      <pubDate>Thu, 28 Mar 2024 09:56:34 GMT</pubDate>
    </item>
    <item>
      <title>如何使用动态输入形状在onnx运行时Web中调用onnx（忽略输入形状检查）</title>
      <link>https://stackoverflow.com/questions/78237036/how-to-call-onnx-in-onnx-runtime-web-with-dynamic-input-shapeignoring-input-sha</link>
      <description><![CDATA[我使用 python 获取我的 onnx 输入形状
providers = [&#39;AzureExecutionProvider&#39;, &#39;CPUExecutionProvider&#39;] # 指定您所需的提供程序
sess_options = onnxruntime.SessionOptions()
sess = onnxruntime.InferenceSession(model_path、sess_options、providers=providers)
input_shape = sess.get_inputs()[0].shape
print(f&quot;输入形状：{input_shape}&quot;)

显示
输入形状：[&#39;input_dynamic_axes_1&#39;, &#39;input_dynamic_axes_2&#39;, &#39;input_dynamic_axes_3&#39;, &#39;input_dynamic_axes_4&#39;]

当我在js中运行onnx时
 const session = wait ort.InferenceSession.create(model, {
    executionProviders：[“webgpu”，“webgl”]，
  });
  常量提要：任意 = {}；
  const inputNames = session.inputNames;
  feeds[inputNames[0]] = inputTensor;
  const 结果 = 等待 session.run(feeds);
  const outputData = 结果[session.outputNames[0]].data;
  返回任意的输出数据；

它引发错误
 未捕获（承诺中）错误：输入张量 [0] 检查失败：预期形状 &#39;[,,,]&#39; 但得到 [1,3,800,400]
      验证输入张量尺寸
      规范化和验证输入
      （匿名函数）
      事件
      跑步
      跑步
      跑步
      运行推理

我认为原因是onnx输入形状是动态的，所以下面的onnx js代码总是设置expectedDim == [null, null,null,null]
 私有 validateInputTensorDims(
      graphInputDims: Array&lt;只读数字[]&gt;,给定输入: Tensor[], noneDimSupported: boolean) {
    for (让 i = 0; i 
所以我的问题是：如何使用动态输入形状在onnx运行时网络中调用onnx（忽略输入形状检查）]]></description>
      <guid>https://stackoverflow.com/questions/78237036/how-to-call-onnx-in-onnx-runtime-web-with-dynamic-input-shapeignoring-input-sha</guid>
      <pubDate>Thu, 28 Mar 2024 09:15:04 GMT</pubDate>
    </item>
    <item>
      <title>如何为 ml.net C# 创建二进制数据帧？</title>
      <link>https://stackoverflow.com/questions/78237006/how-can-i-create-binary-dataframe-for-ml-net-c</link>
      <description><![CDATA[我正在尝试创建一个二进制数据帧，但原语无法工作，并且不知道如何使用 VBuffer 数据帧列，因此请指导如何创建二进制数据帧
已经尝试过primitiveDatframes，但现在给出了预期的结果]]></description>
      <guid>https://stackoverflow.com/questions/78237006/how-can-i-create-binary-dataframe-for-ml-net-c</guid>
      <pubDate>Thu, 28 Mar 2024 09:09:04 GMT</pubDate>
    </item>
    <item>
      <title>在后端使用大文件</title>
      <link>https://stackoverflow.com/questions/78236586/using-large-files-in-the-backend</link>
      <description><![CDATA[我在后端使用 Flask 框架制作了一个对象检测网站，并使用 yolov3.weights(240mb) 文件作为预训练模型。我只是想知道托管此类在后端运行 yolov3 等大文件的网站的正确方法是什么
不知道如何解决这个问题，只是寻找正确的方法]]></description>
      <guid>https://stackoverflow.com/questions/78236586/using-large-files-in-the-backend</guid>
      <pubDate>Thu, 28 Mar 2024 07:47:25 GMT</pubDate>
    </item>
    <item>
      <title>如何将 tfidfvectorizer 的功能从英语修改为西班牙语</title>
      <link>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</link>
      <description><![CDATA[我有一个 tfidfvectorizer，它适合英语文本数据来预测英语通话的情绪。任务是将其转换为西班牙语。我想使用此 tfidfvectorizers 的权重，并希望将功能从英语转换为西班牙语，例如“谢谢”变成“gracias”并使用旧的权重。所以本质上我想使用相同的 tfidf 矢量器，但修改了特征名称。有人可以建议一些方法在 Python 中做到这一点吗？
编辑：我已经将功能从英语转换为西班牙语，并在英语文本上训练了 tfidf。我需要一种使用旧权重和新功能构建 tfidf 的方法，而不使用 fit 函数或将所有文本转换为西班牙语。]]></description>
      <guid>https://stackoverflow.com/questions/78232328/how-to-modify-features-of-tfidfvectorizer-from-english-to-spanish</guid>
      <pubDate>Wed, 27 Mar 2024 14:11:46 GMT</pubDate>
    </item>
    <item>
      <title>用户警告：RNN 模块权重不是单个连续内存块的一部分</title>
      <link>https://stackoverflow.com/questions/78209777/userwarning-rnn-module-weights-are-not-part-of-single-contiguous-chunk-of-memor</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78209777/userwarning-rnn-module-weights-are-not-part-of-single-contiguous-chunk-of-memor</guid>
      <pubDate>Sat, 23 Mar 2024 04:48:10 GMT</pubDate>
    </item>
    <item>
      <title>TF2 和 python 中的 BERT 预处理器模型存在问题</title>
      <link>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</link>
      <description><![CDATA[我正在尝试使用 BERT 来做一个文本分类项目。但是我一直遇到这个错误
`
ValueError Traceback（最近一次调用最后一次）
单元格 In[37]，第 4 行
      2 text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
      3 bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;预处理&#39;)
----&gt; 4 preprocessed_text = bert_preprocess(text_input)
      5 bert_encoder = hub.KerasLayer(encoder_url,
      6 可训练=真，
      7 名称=&#39;BERT_编码器&#39;)
      8 个输出 = bert_encoder(preprocessed_text)
ValueError：调用层“预处理”时遇到异常（类型 KerasLayer）。
KerasTensor 是象征性的：它是形状和数据类型的占位符。它没有任何实际的数值。您无法将其转换为 NumPy 数组。

调用层“预处理”接收的参数（类型 KerasLayer）：
  输入=
  • 培训=无

KerasTensor 是象征性的：它是形状和数据类型的占位符。它没有任何实际的数值。您无法将其转换为 NumPy 数组。



构建此模型时：
&lt;前&gt;&lt;代码&gt;
preprocess_url = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/en-uncased-preprocess/versions/3&#39;
编码器网址 = &#39;https://www.kaggle.com/models/tensorflow/bert/frameworks/TensorFlow2/variations/bert-en-uncased-l-12-h-768-a-12/versions/2&#39;

# Bert 层
text_input = tf.keras.Input(shape=(), dtype=tf.string, name=&#39;text&#39;)
bert_preprocess = hub.KerasLayer(preprocess_url, name=&#39;预处理&#39;)
预处理文本 = bert_preprocess(text_input)
bert_encoder = hub.KerasLayer(encoder_url,
                              可训练=真，
                              名称=&#39;BERT_编码器&#39;)
输出= bert_encoder（预处理文本）

# 神经网络层
l = tf.keras.layers.Dropout(0.1)(输出[&#39;pooled_output&#39;])
l = tf.keras.layers.Dense(num_classes, 激活=&#39;softmax&#39;, name=&#39;输出&#39;)(l)

# 构建最终模型
模型 = tf.keras.Model(输入=[text_input], 输出=[l])

我看过无数的教程，甚至使用了张量流文档上的教程，即使我复制和粘贴，它们仍然不起作用。我尝试过不同版本的 tf、tf-text 和 tf-hub。我在这个项目中使用了tensorflow-gpu-jupyter docker 容器。
这是我安装库的方法：
!pip install “tensorflow-text”
!pip install “tf-models-official”
!pip install “tensorflow-hub”

版本是：
张量流：2.16.1
张量流文本：2.16.1
张量流中心：0.16.1
我看到的有关此问题的所有其他论坛都说要执行 tf.config.run_functions_eagerly(True) 但这不起作用。
任何事情都会有所帮助。如果您知道如何解决请回答。]]></description>
      <guid>https://stackoverflow.com/questions/78183834/issue-with-bert-preprocessor-model-in-tf2-and-python</guid>
      <pubDate>Tue, 19 Mar 2024 01:42:01 GMT</pubDate>
    </item>
    <item>
      <title>Pycaret 3.3.0 Compare_models() 显示所有模型 AUC 为零</title>
      <link>https://stackoverflow.com/questions/78169647/pycaret-3-3-0-compare-models-show-zeros-for-all-models-auc</link>
      <description><![CDATA[在使用compare_model()评估模型期间。所有 AUC 均为零。
Pycaret 3.3.0 的这个输出很奇怪。这是什么原因？
[1]: https://i.stack.imgur.com/qm2ZT.png]]></description>
      <guid>https://stackoverflow.com/questions/78169647/pycaret-3-3-0-compare-models-show-zeros-for-all-models-auc</guid>
      <pubDate>Fri, 15 Mar 2024 21:02:29 GMT</pubDate>
    </item>
    <item>
      <title>scikeras.wrappers.KerasClassifier 返回 ValueError：无法解释指标标识符：loss</title>
      <link>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</link>
      <description><![CDATA[我正在研究 KerasClassifier，因为我想将其插入 scikit-learn 管道中，但我收到了前面提到的 ValueError。
以下代码应该能够重现我遇到的错误：
从 sklearn.model_selection 导入 KFold，cross_val_score
从 sklearn.preprocessing 导入 StandardScaler
从 scikeras.wrappers 导入 KerasClassifier
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从 sklearn.datasets 导入 load_iris
将 numpy 导入为 np

数据 = load_iris()
X = 数据.数据
y = 数据.目标

def create_model():
    模型=顺序（）
    model.add（密集（8，input_dim = 4，激活=&#39;relu&#39;））
    model.add（密集（3，激活=&#39;softmax&#39;））
    model.compile(loss=&#39;sparse_categorical_crossentropy&#39;,
                  优化器=&#39;亚当&#39;,
                  指标=[&#39;准确性&#39;])
    返回模型

clf = KerasClassifier(build_fn=create_model,
                      纪元=100，
                      批量大小=10，
                      详细=1)

管道=管道([
    (&#39;缩放器&#39;, StandardScaler()),
    （&#39;clf&#39;，clf）
]）

kf = KFold(n_splits=5, shuffle=True, random_state=42)
结果= cross_val_score（管道，X，y，cv = kf）
print(&quot;交叉验证准确度：&quot;, np.mean(结果))

似乎我的模型正在随着纪元的运行而被编译。但是，之后我收到错误：
ValueError：无法解释指标标识符：丢失

tensorflow 和 scikeras 库的版本是：
scikeras==0.12.0
张量流==2.15.0

编辑：
最终我尝试了不同的库版本，以下内容让我成功运行了代码，看来问题是由 scikit-learn 的版本引起的：
scikeras==0.12.0
张量流==2.15.0
scikit学习==1.4.1
]]></description>
      <guid>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</guid>
      <pubDate>Fri, 01 Mar 2024 17:03:39 GMT</pubDate>
    </item>
    <item>
      <title>错误：运行时错误：给定组=1，大小权重[64,3,3,3]，预期输入[1,12,320,320]有3个通道，但得到了12个通道</title>
      <link>https://stackoverflow.com/questions/77935195/error-runtimeerror-given-groups-1-weight-of-size-64-3-3-3-expected-inpu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77935195/error-runtimeerror-given-groups-1-weight-of-size-64-3-3-3-expected-inpu</guid>
      <pubDate>Sun, 04 Feb 2024 09:23:02 GMT</pubDate>
    </item>
    </channel>
</rss>