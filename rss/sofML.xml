<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>æ ‡è®°ä¸ºæœºå™¨å­¦ä¹ çš„æ´»è·ƒé—®é¢˜ - å †æ ˆå†…å­˜æº¢å‡º</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>æ¥è‡ª stackoverflow.com çš„æœ€æ–° 30 æ¡</description>
    <lastBuildDate>Sat, 28 Dec 2024 15:15:17 GMT</lastBuildDate>
    <item>
      <title>ç¡®å®šåœ¨æä¾›çš„è§†é¢‘ä¸­åŒä¸€è¾†è½¦è¢«æ‹æ‘„çš„æ¬¡æ•°</title>
      <link>https://stackoverflow.com/questions/79313854/identify-how-many-times-same-vehicle-was-captured-in-the-provided-video</link>
      <description><![CDATA[æ­£åœ¨è¿›è¡Œè§†é¢‘åˆ†æä½œä¸šï¼Œæˆ‘éœ€è¦æ•æ‰åœ¨ç»™å®šè§†é¢‘ä¸­åŒä¸€è½¦è¾†è¢«æ‹æ‘„çš„æ¬¡æ•°ã€‚
åˆ°ç›®å‰ä¸ºæ­¢ï¼Œä½¿ç”¨ YOLO11 èƒ½å¤Ÿè¯†åˆ«æ±½è½¦ã€è‡ªè¡Œè½¦ã€å…¬å…±æ±½è½¦å’Œå¡è½¦ç­‰è½¦è¾†ã€‚ç›¸åº”åœ°ï¼Œåœ¨è§†é¢‘å¸§ä¸­ç»˜åˆ¶è½¦è¾†çš„çŸ©å½¢ã€‚
æˆ‘ä¸æ˜ç™½å¦‚ä½•ç”¨ä¸€äº›è¯†åˆ«ç æ ‡è®°è½¦è¾†ã€‚è¿™æ ·ï¼Œå½“åŒä¸€è¾†è½¦å‡ºç°åœ¨è§†é¢‘å¸§ä¸­æ—¶ï¼Œæˆ‘å¯ä»¥å¢åŠ è¯¥è½¦è¾†çš„æ•°é‡ã€‚
æ·»åŠ æˆ‘å°è¯•è¿‡çš„ä»£ç 
from ultralytics import YOLO
import cv2
from enum import Enum

class DetectionType(Enum):
CAR = 2
MOTORCYCLE = 3
BUS = 5
TRUCK = 6

coco_model = YOLO(&#39;yolo11n.pt&#39;)
cap = cv2.VideoCapture(&#39;testVideo.mp4&#39;)

vehicles = [
DetectionType.CAR.value, 
DetectionType.MOTORCYCLE.value, 
DetectionType.BUS.value,
DetectionType.TRUCK.value
]

ret = True

while ret:
ret, frame = cap.read()

if ret:
#detect vehicle
detections_model = coco_model(frame)[0]

for detection in detections_model.boxes.data.tolist():
x1, y1, x2, y2, score, class_id = detection

if int(class_id) in vehicles:
x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)

# åœ¨çª—å£ä¸­æ˜¾ç¤ºå¸§ 
cv2.imshow(&#39;video&#39;, frame)

if cv2.waitKey(33) == 27:
break

cap.release()
cv2.destroyAllWindows() 

ä»»ä½•å»ºè®®æˆ–ä»£ç ç‰‡æ®µéƒ½ä¼šå¸®åŠ©æˆ‘å®Œæˆè¿™é¡¹ä½œä¸šã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79313854/identify-how-many-times-same-vehicle-was-captured-in-the-provided-video</guid>
      <pubDate>Sat, 28 Dec 2024 13:29:54 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨å“ªé‡Œå¯ä»¥æ‰¾åˆ°æœ‰å…³ PC æ“ä½œçš„ä¿¡æ¯ï¼Ÿ [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79313849/where-to-find-information-about-pc-operation</link>
      <description><![CDATA[éœ€è¦æœ‰å…³æœºå™¨ä»£ç ææ–™çš„å¸®åŠ©ã€‚æˆ‘æ­£åœ¨å¯»æ‰¾æœ‰å…³ PC åœ¨ç‰©ç†å’Œè½¯ä»¶å±‚é¢å¦‚ä½•å·¥ä½œçš„å®Œæ•´è§£é‡Šã€‚æœ‰äººå¯ä»¥å¸®å¿™å—ï¼Ÿæ‰¾ä¸åˆ°æœ‰å…³æ­¤ä¸»é¢˜çš„ä»»ä½•å†…å®¹ã€‚ä¹Ÿè®¸æœ‰äººå¯¹æ­¤æ„Ÿå…´è¶£ï¼Ÿ
ç”¨äºè‡ªæˆ‘å‘å±•]]></description>
      <guid>https://stackoverflow.com/questions/79313849/where-to-find-information-about-pc-operation</guid>
      <pubDate>Sat, 28 Dec 2024 13:24:10 GMT</pubDate>
    </item>
    <item>
      <title>çº¿æ€§å›å½’æ¨¡å‹å‹‰å¼ºä¼˜åŒ–äº†æˆªè·b</title>
      <link>https://stackoverflow.com/questions/79312660/linear-regression-model-barely-optimizes-the-intercept-b</link>
      <description><![CDATA[æˆ‘ä»å¤´å¼€å§‹ç¼–å†™äº†ä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ã€‚æˆ‘ä½¿ç”¨â€œæ®‹å·®å¹³æ–¹å’Œâ€ä½œä¸ºæ¢¯åº¦ä¸‹é™çš„æŸå¤±å‡½æ•°ã€‚ä¸ºäº†è¿›è¡Œæµ‹è¯•ï¼Œæˆ‘ä½¿ç”¨çº¿æ€§æ•°æ® (y=x)
è¿è¡Œç®—æ³•æ—¶ï¼Œæˆªè· b å‡ ä¹æ²¡æœ‰å˜åŒ–ã€‚å› æ­¤æ–œç‡ m è®¡ç®—ä¸æ­£ç¡®ã€‚
%matplotlib qt5 
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

X = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
y = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12345)

class LinearRegression():
def __init__(self):
self.X = None
self.y = None

def ssr(self, m, b):
sum = 0
for i in range(len(self.X)):
sum += (self.y[i] - (m * self.X[i] + b) ) ** 2

return sum

def ssr_gradient(self, m, b):
sum_m = 0
sum_b = 0
n = len(self.X)
for i in range(n):
error = self.y[i] - (m * self.X[i] + b)
derivative_m = -(2/n) * self.X[i] * error # ç›¸å¯¹äº m çš„å¯¼æ•°
derivative_b = -(2/n) * error # ç›¸å¯¹äº m çš„å¯¼æ•°b
sum_m += derived_m
sum_b += derived_b

return sum_m, sum_b

def fit(self, X, y, m, b): # æ¢¯åº¦ä¸‹é™
self.X = X
self.y = y

M, B = np.meshgrid(np.arange(-10, 10, 0.1), np.arange(-10, 10, 0.1))
SSR = np.zeros_like(M)
for i in range(M.shape[0]):
for j in range(M.shape[1]):
SSR[i, j] = self.ssr(M[i, j], B[i, j])

fig, axis = plt.subplots(1, 2, figsize=(12, 6))
gd_model = fig.add_subplot(121,æŠ•å½±=â€œ3dâ€ï¼Œcomputed_zorder=False)
lin_reg_model = axis[1] 

current_pos = (m, b, self.ssr(m, b))
learning_rate = 0.001
min_step_size = 0.001
max_steps = 1000
current_steps = 0

while(current_steps &lt; max_steps):
M_derivative, B_derivative = self.ssr_gradient(current_pos[0], current_pos[1])
M_step_size, B_step_size = M_derivative * learning_rate, B_derivative * learning_rate

if abs(M_step_size) &lt; min_step_size æˆ– abs(B_step_size) &lt; min_step_size:
break

M_new, B_new = current_pos[0] - M_step_size, current_pos[1] - B_step_size

current_pos = (M_new, B_new, self.ssr(M_new, B_new))

print(f&quot;å‚æ•°ï¼šmï¼š{current_pos[0]}; bï¼š{current_pos[1]}; SSRï¼š{current_pos[2]}&quot;)

current_steps += 1

x = np.arange(0, 10, 1)
y = current_pos[0] * x + current_pos[1]
lin_reg_model.scatter(X_train, y_train, label=&quot;Train&quot;, s=75, c=&quot;#1f77b4&quot;)
lin_reg_model.plot(x, y)

gd_model.plot_surface(M, B, SSR, cmap=&quot;viridis&quot;, zorder=0)
gd_model.scatter(current_pos[0], current_pos[1], current_pos[2], c=&quot;red&quot;, zorder=1)
gd_model.set_xlabel(&quot;æ–œç‡ m&quot;)
gd_model.set_ylabel(&quot;æˆªè· b&quot;)
gd_model.set_zlabel(&quot;æ®‹å·®å¹³æ–¹å’Œ&quot;)

plt.tight_layout()
plt.pause(0.001)

gd_model.clear()
lin_reg_model.clear()

self.m = current_pos[0]
self.b = current_pos[1]

def predict(self, X_test):
return self.m * X_test + self.b

lin_reg_model = LinearRegression()
lin_reg_model.fit(X_train, y_train, 1, 10)


è¿™æ˜¯åˆå§‹å€¼ m=1 å’Œ b=10 çš„ç»“æœï¼š
å‚æ•°ï¼šmï¼š-0.45129949840919587ï¼›bï¼š9.50972664859535ï¼›SSRï¼š145.06534359577407

æ˜¾ç„¶è¿™ä¸æ˜¯æœ€ä½³çš„ï¼Œå› ä¸ºæˆ‘çš„æ•°æ®æ˜¯çº¿æ€§çš„ã€‚å› æ­¤æœ€ä½³å‚æ•°åº”è¯¥æ˜¯ m=1 å’Œ b=0
ä½†æˆ‘åœ¨ä»£ç ä¸­æ‰¾ä¸åˆ°é—®é¢˜ã€‚è¯¥ç®—æ³•æ ¹æ®åˆå§‹å€¼æ‰“å°ä¸åŒçš„ç»“æœï¼Œä½†åªè¦ SSR å‡½æ•°æ°å¥½æœ‰ä¸€ä¸ªæœ€å°å€¼ï¼Œå®ƒå°±åº”è¯¥ä¸€éåˆä¸€éåœ°æ‰“å°ç›¸åŒçš„ç»“æœã€‚
æˆ‘å°è¯•ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡ï¼Œä½†é—®é¢˜ä»ç„¶å­˜åœ¨ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79312660/linear-regression-model-barely-optimizes-the-intercept-b</guid>
      <pubDate>Fri, 27 Dec 2024 19:40:21 GMT</pubDate>
    </item>
    <item>
      <title>RCNN RESNET 50 æ¨¡å‹ - æˆ‘çš„é£Ÿç‰©å›è´­ TRAIN [å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79312423/rcnn-resnet-50-model-my-food-repo-train</link>
      <description><![CDATA[æˆ‘å¯ä»¥å¯»æ±‚å¸®åŠ©å—ï¼Ÿ
æˆ‘æ‰¾åˆ°äº†è¿™ç¯‡ç§‘å­¦æ–‡ç« ï¼š
https://www.frontiersin.org/journals/nutrition/articles/10.3389/fnut.2022.875143/full
å…¶ä¸­æœ‰ä¸€ä¸ªæŒ‡å‘å­˜å‚¨åº“çš„é“¾æ¥ï¼Œå…¶ä¸­åŒ…å«åœ¨ COCO æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚
æˆ‘æƒ³åœ¨ MyFoodRepo æ•°æ®é›†ä¸Šè®­ç»ƒå…¶ä¸­ä¸€ä¸ªæ¨¡å‹ï¼ˆmask r-CNN ResNet50ï¼‰ã€‚æˆ‘æƒ³åœ¨ Google Colab pro ä¸­ä½¿ç”¨ GPUï¼ˆæˆ‘æœ¬åœ°æ²¡æœ‰è¿™ç§å¯èƒ½æ€§ï¼‰ï¼Œä½†åº“å…¼å®¹æ€§å­˜åœ¨å¾ˆå¤§é—®é¢˜ï¼ˆColab æœ‰ CUDA 12.2ï¼‰ã€‚æˆ‘å°è¯•äº†å¾ˆå¤šæ–¹æ³•ï¼Œä½†è‡³ä»Šè¿˜æ²¡æœ‰æ‰¾åˆ°è§£å†³åŠæ³•ã€‚ä¹Ÿè®¸æœ‰äººæœ‰ä¸»æ„ï¼ŸğŸ™ğŸ¼
https://gitlab.aicrowd.com/.../myfoodrepo-experiments/
mmdetetection å­˜åœ¨å¾ˆå¤šé—®é¢˜ï¼š(]]></description>
      <guid>https://stackoverflow.com/questions/79312423/rcnn-resnet-50-model-my-food-repo-train</guid>
      <pubDate>Fri, 27 Dec 2024 17:20:38 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface Trainer åœ¨å®Œæˆæ‰€æœ‰ Epoch ä¹‹å‰åœæ­¢</title>
      <link>https://stackoverflow.com/questions/79312241/huggingface-trainer-stops-before-completing-all-epochs</link>
      <description><![CDATA[æˆ‘æ­£åœ¨ä½¿ç”¨ Huggingface Trainer è¿›è¡Œåºåˆ—åˆ†ç±»ä»»åŠ¡ï¼Œé…ç½®å¦‚ä¸‹ï¼š

num_train_epochs=5
save_strategy=&quot;epoch&quot;
evaluation_strategy=&quot;epoch&quot;
load_best_model_at_end=False

ä½†æ˜¯ï¼Œè®­ç»ƒåœ¨ç¬¬ 4 ä¸ª epoch ä¹‹ååœæ­¢ï¼Œå°½ç®¡æˆ‘é¢„è®¡å®ƒä¼šå®Œæˆæ‰€æœ‰ 5 ä¸ª epochã€‚
ä»¥ä¸‹æ˜¯æˆ‘çš„è®­ç»ƒå‚æ•°å’Œ Trainer è®¾ç½®çš„ç‰‡æ®µï¼š
åœ¨æ­¤å¤„è¾“å…¥å›¾ç‰‡è¯´æ˜
outputTable
æˆ‘æ€€ç–‘å®ƒå¯èƒ½ä¸æ—©æœŸåœæ­¢è¡Œä¸ºã€æ¢¯åº¦ç´¯ç§¯æˆ–å…¶ä»–å‚æ•°äº¤äº’æœ‰å…³ã€‚
æˆ‘è¿˜ç¡®ä¿æ²¡æœ‰ä½¿ç”¨æ—©æœŸåœæ­¢å›è°ƒã€‚
å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Ÿ
æˆ‘å°è¯•è¿‡çš„æ–¹æ³•ï¼š
æˆ‘åœ¨ TrainingArguments ä¸­è®¾ç½®äº† num_train_epochs=5ï¼Œå¹¶ä½¿ç”¨äº† Huggingface Transformers åº“ä¸­çš„ Trainerã€‚æˆ‘çš„ç›®æ ‡æ˜¯è®­ç»ƒæ¨¡å‹æ°å¥½ 5 ä¸ªæ—¶æœŸã€‚æˆ‘ç¡®è®¤æ²¡æœ‰åº”ç”¨ä»»ä½•æ—©æœŸåœæ­¢å›è°ƒæˆ–é¢å¤–çš„ç»ˆæ­¢é€»è¾‘ã€‚
æˆ‘çš„é¢„æœŸï¼š
è®­ç»ƒè¿‡ç¨‹åº”è¯¥è¿è¡Œæ‰€æœ‰ 5 ä¸ªæ—¶æœŸï¼Œè®°å½•æŒ‡æ ‡å¹¶æŒ‰ç…§é…ç½®åœ¨æ¯ä¸ªæ—¶æœŸåä¿å­˜æ£€æŸ¥ç‚¹ã€‚
å‘ç”Ÿäº†ä»€ä¹ˆï¼š
è®­ç»ƒåœ¨ç¬¬ 4 ä¸ªæ—¶æœŸååœæ­¢ï¼Œæ²¡æœ‰ä»»ä½•é”™è¯¯æ¶ˆæ¯ã€‚å°½ç®¡ num_train_epochs æ˜ç¡®è®¾ç½®ä¸º 5ï¼Œä½†æ—¥å¿—ä»è¿‡æ—©åœ°è¡¨æ˜è®­ç»ƒè¿‡ç¨‹ç»“æŸã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79312241/huggingface-trainer-stops-before-completing-all-epochs</guid>
      <pubDate>Fri, 27 Dec 2024 15:54:31 GMT</pubDate>
    </item>
    <item>
      <title>å¦‚ä½•ä½¿ç”¨å¤šç±»æ•°æ®é›†è®­ç»ƒæ¨¡å‹æ¥é¢„æµ‹å·¥ä½œè§’è‰²ï¼Ÿ[å…³é—­]</title>
      <link>https://stackoverflow.com/questions/79312226/how-to-train-a-model-to-predict-job-roles-with-multi-class-dataset</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å±•ä¸€ä¸ªé¡¹ç›®ï¼Œæ ¹æ®åŒ…å«39 ä¸ªç‰¹å¾å’Œ33 ä¸ªç‹¬ç‰¹å·¥ä½œè§’è‰²ä½œä¸ºç›®æ ‡æ ‡ç­¾çš„æ•°æ®é›†æ¥é¢„æµ‹å·¥ä½œè§’è‰²ã€‚æ•°æ®é›†æœ‰ 20,000 è¡Œï¼ŒåŒ…æ‹¬æ•°å€¼åˆ—å’Œåˆ†ç±»åˆ—ã€‚
ä»¥ä¸‹æ˜¯æ•°æ®é›†çš„æ‘˜è¦ï¼š

æ•°å€¼ç‰¹å¾ (14)ï¼šå­¦æœ¯ç§‘ç›®ï¼ˆä¾‹å¦‚æ“ä½œç³»ç»Ÿã€ç®—æ³•ï¼‰çš„ç™¾åˆ†æ¯”ã€é€»è¾‘å•†è¯„åˆ†ã€å‚åŠ çš„é»‘å®¢é©¬æ‹‰æ¾ç­‰ã€‚
äºŒè¿›åˆ¶ç‰¹å¾ (16)ï¼šè¯¸å¦‚â€œå¯ä»¥åœ¨ç³»ç»Ÿä¹‹å‰é•¿æ—¶é—´å·¥ä½œå—ï¼Ÿâ€ï¼Œâ€œè‡ªå­¦èƒ½åŠ›ï¼Ÿâ€ç­‰é—®é¢˜ã€‚
åˆ†ç±»ç‰¹å¾ (8)ï¼šåŒ…æ‹¬â€œè®¤è¯â€ã€â€œè®°å¿†èƒ½åŠ›â€åˆ†æ•°â€ã€â€œæ„Ÿå…´è¶£çš„èŒä¸šé¢†åŸŸâ€ç­‰ã€‚
ç›®æ ‡å˜é‡ï¼šå»ºè®®çš„å·¥ä½œè§’è‰²ï¼ˆä¾‹å¦‚ï¼Œâ€œæ•°æ®åº“å¼€å‘äººå‘˜â€ã€â€œè½¯ä»¶å·¥ç¨‹å¸ˆâ€ç­‰ï¼‰ã€‚

é—®é¢˜ï¼š
æˆ‘é¢„å¤„ç†äº†æ•°æ®é›†å¹¶å°è¯•äº†éšæœºæ£®æ—ã€SVMå’ŒXGBoostç­‰è®­ç»ƒæ¨¡å‹ï¼Œä½†å‡†ç¡®ç‡ä»ç„¶ä¸€ç›´å¾ˆä½ï¼ˆçº¦ 3%ï¼‰ã€‚æˆ‘æ€€ç–‘æˆ‘çš„é¢„å¤„ç†ã€æ¨¡å‹é€‰æ‹©æˆ–è¶…å‚æ•°è°ƒæ•´å¯èƒ½å­˜åœ¨é—®é¢˜ã€‚
é¢„å¤„ç†ç®¡é“ï¼š
ä»¥ä¸‹æ˜¯æˆ‘é¢„å¤„ç†æ•°æ®çš„æ–¹æ³•ï¼š
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler

def transform_data(df):
X = df.drop(&#39;Suggested Job Role&#39;, axis=1)
y = df[&#39;Suggested Job Role&#39;]

# ç‰¹å¾ç±»å‹
two_category_features = [&#39;can work long time before system?&#39;, &#39;self-learning capacity?&#39;, 
&#39;Extra-courses did&#39;, &#39;talenttests taken?&#39;, &#39;olympiads&#39;, &#39;Job/Higherå­¦ä¹ ï¼Ÿ&#39;,
&#39;ä»å¹´é•¿è€…æˆ–é•¿è¾ˆé‚£é‡Œè·å–ä¿¡æ¯&#39;, &#39;å¯¹æ¸¸æˆæ„Ÿå…´è¶£&#39;, &#39;æœŸæœ›è–ªèµ„èŒƒå›´&#39;, 
&#39;å¤„äºæ‹çˆ±å…³ç³»ä¸­ï¼Ÿ&#39;, &#39;è¡Œä¸ºæ¸©å’Œè¿˜æ˜¯å¼ºç¡¬ï¼Ÿ&#39;, &#39;ç®¡ç†æˆ–æŠ€æœ¯&#39;, 
&#39;è–ªæ°´/å·¥ä½œ&#39;, &#39;åŠªåŠ›/èªæ˜çš„å‘˜å·¥&#39;, &#39;æ›¾ç»åœ¨å›¢é˜Ÿä¸­å·¥ä½œè¿‡å—ï¼Ÿ&#39;, &#39;å†…å‘&#39;]

categorical_features = [&#39;è®¤è¯&#39;, &#39;ç ”è®¨ä¼š&#39;, &#39;é˜…è¯»å’Œå†™ä½œæŠ€èƒ½&#39;, 
&#39;è®°å¿†èƒ½åŠ›å¾—åˆ†&#39;, &#39;æ„Ÿå…´è¶£çš„ç§‘ç›®&#39;, 
&#39;æ„Ÿå…´è¶£çš„èŒä¸šé¢†åŸŸ&#39;, &#39;æƒ³è¦åœ¨å“ªå®¶å…¬å¸å®‰é¡¿ä¸‹æ¥ï¼Ÿ&#39;, 
&#39;æ„Ÿå…´è¶£çš„ä¹¦ç±ç±»å‹&#39;]

numeric_features = [&#39;æ“ä½œç³»ç»Ÿä¸­çš„å­¦æœ¯ç™¾åˆ†æ¯”&#39;, &#39;ç®—æ³•ä¸­çš„ç™¾åˆ†æ¯”&#39;, 
&#39;ç¼–ç¨‹æ¦‚å¿µä¸­çš„ç™¾åˆ†æ¯”&#39;, &#39;è½¯ä»¶å·¥ç¨‹ä¸­çš„ç™¾åˆ†æ¯”&#39;,
&#39;è®¡ç®—æœºç½‘ç»œå æ¯”&#39;, &#39;ç”µå­å­¦ç§‘å æ¯”&#39;, 
&#39;è®¡ç®—æœºæ¶æ„å æ¯”&#39;, &#39;æ•°å­¦å æ¯”&#39;, 
&#39;æ²Ÿé€šæŠ€å·§å æ¯”&#39;, &#39;é€»è¾‘å•†è¯„åˆ†&#39;, 
&#39;é»‘å®¢é©¬æ‹‰æ¾&#39;, &#39;ç¼–ç æŠ€èƒ½è¯„åˆ†&#39;, &#39;å…¬å¼€æ¼”è®²è¦ç‚¹&#39;, &#39;æ¯å¤©å·¥ä½œæ—¶é—´&#39;]

# é¢„å¤„ç†ç®¡é“
two_category_transformer = Pipeline(steps=[
(&#39;ordinal&#39;, OrdinalEncoder())
])
categorical_transformer = Pipeline(steps=[
(&#39;onehot&#39;, OneHotEncoder(handle_unknown=&#39;ignore&#39;))
])
numeric_transformer = Pipeline(steps=[
(&#39;minmax&#39;, MinMaxScaler())
])

# ç»„åˆè½¬æ¢
preprocessor = ColumnTransformer(transformers=[
(&#39;two_cat&#39;, two_category_transformer, two_category_features),
(&#39;cat&#39;, categorical_transformer, categorical_features),
(&#39;minmax&#39;, numeric_transformer, numeric_features)
])

formed_X = preprocessor.fit_transform(X)
return formed_X, y

å°è¯•çš„æ¨¡å‹ï¼š

éšæœºæ£®æ—ï¼šä½¿ç”¨é»˜è®¤å‚æ•°ã€‚
SVMï¼šå°è¯•ä½¿ç”¨ RBF å†…æ ¸ï¼Œé»˜è®¤è¶…å‚æ•°ã€‚
XGBoostï¼šé»˜è®¤å‚æ•°ã€‚

å°½ç®¡å°è¯•äº†è¿™äº›æ¨¡å‹ï¼Œå‡†ç¡®ç‡ä»ç„¶åœç•™åœ¨ 3% å·¦å³ã€‚

é—®é¢˜ï¼š

ä¸ºä»€ä¹ˆæ¨¡å‹åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¸ä½³ï¼Ÿ
æˆ‘åº”è¯¥å°è¯•å“ªäº›ç‰¹å®šçš„æŠ€æœ¯æˆ–æ–¹æ³•ï¼ˆä¾‹å¦‚ï¼Œè¶…å‚æ•°è°ƒæ•´ã€ç‰¹å¾é€‰æ‹©ã€è¿‡é‡‡æ ·ï¼‰ï¼Ÿ
æˆ‘å¦‚ä½•æ›´å¥½åœ°å¤„ç†ç›®æ ‡å˜é‡çš„é«˜åŸºæ•°ï¼ˆ33 ä¸ªç‹¬ç‰¹çš„å·¥ä½œè§’è‰²ï¼‰ï¼Ÿ
]]></description>
      <guid>https://stackoverflow.com/questions/79312226/how-to-train-a-model-to-predict-job-roles-with-multi-class-dataset</guid>
      <pubDate>Fri, 27 Dec 2024 15:48:34 GMT</pubDate>
    </item>
    <item>
      <title>pytorchä¸­å¦‚ä½•åœ¨å•èŠ‚ç‚¹å•GPUç³»ç»Ÿä¸­å¼€å‘å¤šGPUæ¨¡å—ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79311997/how-to-develop-multi-gpu-modules-in-single-node-single-gpu-system-in-pytorch</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å¼€å‘ä¸€ä¸ªå¤š GPU PyTorch åº”ç”¨ç¨‹åºã€‚torch.distributed ä¸­çš„ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ scatter/gatherï¼‰ä¸èƒ½æ»¡è¶³æˆ‘çš„è¦æ±‚ï¼Œå› æ­¤æˆ‘éœ€è¦å¼€å‘å‰å‘/åå‘ä¼ æ’­æ­¥éª¤ï¼Œåœ¨ GPU ä¹‹é—´å‘é€å’Œæ¥æ”¶æ¢¯åº¦ï¼ŒåŒæ—¶ä½¿ç”¨å†…ç½®æ–¹æ³• scatter/gatherã€‚æˆ‘å¯ä»¥è‡ªå·±åšã€‚æˆ‘çš„æœ€ç»ˆåº”ç”¨ç¨‹åºå°†åœ¨å¤š GPU æœåŠ¡å™¨ä¸Šæ‰§è¡Œã€‚
å¯¹äºå¼€å‘ï¼Œé¢„ç®—é™åˆ¶å°†æˆ‘é™åˆ¶åœ¨å•èŠ‚ç‚¹å• GPU æœåŠ¡å™¨ä¸Šï¼Œå› ä¸ºæˆ‘ä»¬çš„ç»„ç»‡å…±äº«å¤§å‹é›†ç¾¤æœåŠ¡å™¨ã€‚æˆ‘é‡åˆ°çš„ä¸€ä¸ªé—®é¢˜æ˜¯åœ¨è¿™ä¸ªå• GPU ç³»ç»Ÿä¸­æ¨¡æ‹Ÿå¤š GPU è®¾ç½®ã€‚
å¦‚ä½•åœ¨å• GPU ç³»ç»Ÿä¸­æ¨¡æ‹Ÿå¤š GPU è®¾ç½®ä»¥æµ‹è¯•è¿™äº›æ¨¡å—ï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79311997/how-to-develop-multi-gpu-modules-in-single-node-single-gpu-system-in-pytorch</guid>
      <pubDate>Fri, 27 Dec 2024 14:10:33 GMT</pubDate>
    </item>
    <item>
      <title>äº¤å‰éªŒè¯ç»“æœä¸æ··æ·†çŸ©é˜µæŒ‡æ ‡ä¹‹é—´çš„å·®å¼‚</title>
      <link>https://stackoverflow.com/questions/79311670/discrepancy-between-cross-validation-results-and-confusion-matrix-metrics</link>
      <description><![CDATA[æˆ‘æœ‰ä¸€ä¸ªé—®é¢˜ï¼šæˆ‘ä½¿ç”¨åˆ†å±‚ 10 å€äº¤å‰éªŒè¯å¯¹åˆ†ç±»æ¨¡å‹è¿›è¡Œ 5 æ¬¡é‡å¤ï¼Œå¹¶æŠ¥å‘Šç»“æœã€‚é—®é¢˜æ˜¯ï¼Œå½“å®ƒç»˜åˆ¶æ··æ·†çŸ©é˜µæ—¶ï¼Œæˆ‘æ‰‹åŠ¨è®¡ç®—çŸ©é˜µä¸­çš„å‡†ç¡®åº¦å’Œå…¶ä»–æŒ‡æ ‡ï¼Œå®ƒä»¬ä¸æŠ¥å‘Šçš„ç»“æœä¸åŒ
æˆ‘å°è¯•æ±‡æ€»æ‰€æœ‰ç»“æœå¹¶ä½¿ç”¨å®Œå…¨ç›¸åŒçš„ç»“æœç»˜åˆ¶æ··æ·†æŒ‡æ ‡ï¼Œä½†æ²¡æœ‰æˆåŠŸ]]></description>
      <guid>https://stackoverflow.com/questions/79311670/discrepancy-between-cross-validation-results-and-confusion-matrix-metrics</guid>
      <pubDate>Fri, 27 Dec 2024 11:23:26 GMT</pubDate>
    </item>
    <item>
      <title>ä¸ºä»€ä¹ˆ batch() ä»…è¿”å›ä¸€ä¸ªæ‰¹æ¬¡ï¼Ÿ</title>
      <link>https://stackoverflow.com/questions/79309133/why-does-batch-return-only-one-batch</link>
      <description><![CDATA[æˆ‘æ˜¯å›¾åƒå¤„ç†æ–¹é¢çš„æ–°æ‰‹ã€‚æˆ‘æœ‰ä¸¤ä¸ªäºŒè¿›åˆ¶ç±»ä½œä¸ºå­ç›®å½•ï¼Œæ€»å…±æœ‰ 496 å¼ å›¾åƒï¼Œæœ€åä¸€ä¸ªæ‰¹æ¬¡ä¸­è¿˜æœ‰å‰©ä½™çš„ 13 å¼ å›¾åƒï¼Œè¿™æœ‰é—®é¢˜ã€‚å› æ­¤ï¼Œæœ€åä¸€ä¸ªæ‰¹æ¬¡ä¸­çš„ tf.dataset å¼ é‡ä¸æ˜¯ (32, 300, 300, 3)ï¼Œè€Œæ˜¯ (16, 300, 300, 3)ã€‚å®é™…ä¸Šï¼Œæˆ‘æ³¨æ„åˆ°ï¼š

shuffle åå®ƒåŒ…å« 13 ä¸ªæ‰¹æ¬¡
æ‰¹å¤„ç†åå®ƒåªäº§ç”Ÿ 1 ä¸ªæ‰¹æ¬¡ï¼ˆæˆ‘å‡è®¾å®ƒæ˜¯å‰©ä½™æ‰¹æ¬¡ï¼‰
drop_remainder æ—¶æ•°æ®ä¸ºç©º

ä¸ºä»€ä¹ˆ shuffle ååªå‰©ä¸‹ 1 ä¸ªæ‰¹æ¬¡ï¼Ÿ
image_size = (300, 300)
batch_size = 32

train_dataset = image_dataset_from_directory(
dataset_dir,
image_size=(image_size[0], image_size[1]),
batch_size=batch_size,
label_mode=&quot;binary&quot;,
validation_split=0.2,
subset=&quot;training&quot;,
seed=123,
)

train_dataset = train_dataset.shuffle(1000)
train_dataset = train_dataset.batch(
batch_size=batch_size, drop_remainder=True
).prefetch(buffer_size=AUTOTUNE)

print(train_dataset.cardinality().numpy())
]]></description>
      <guid>https://stackoverflow.com/questions/79309133/why-does-batch-return-only-one-batch</guid>
      <pubDate>Thu, 26 Dec 2024 09:23:52 GMT</pubDate>
    </item>
    <item>
      <title>åˆ†ç¦»å›¾åƒå†…çš„ç›²æ–‡å­—ç¬¦</title>
      <link>https://stackoverflow.com/questions/79306951/separation-of-braille-characters-inside-of-an-image</link>
      <description><![CDATA[æˆ‘æ­£åœ¨åšä¸€ä¸ªå°†ç›²æ–‡è½¬æ¢ä¸ºæ–‡æœ¬çš„é¡¹ç›®ã€‚æˆ‘å·²ç»ç¼–å†™äº†ä»å›¾åƒä¸­è¯†åˆ«ç›²æ–‡ç‚¹çš„ä»£ç ï¼Œä½†æˆ‘ä¸çŸ¥é“å¦‚ä½•å°†ç›²æ–‡åˆ†å‰²æˆå•å…ƒæ ¼ã€‚
è¿™éƒ¨åˆ†æ˜¯è¯†åˆ«å›¾åƒä¸­çš„æ–‘ç‚¹ï¼ˆè¾ƒå°çš„ä½è´¨é‡å›¾åƒç›®å‰ä¸èµ·ä½œç”¨ï¼‰
import cv2
import numpy as np
from sklearn.cluster import KMeans

# åŠ è½½å›¾åƒ
image_path = &quot;braille.jpg&quot;
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

# è®¾ç½® SimpleBlobDetector
params = cv2.SimpleBlobDetector_Params()

# æŒ‰åŒºåŸŸè¿‡æ»¤ï¼ˆæ–‘ç‚¹å¤§å°ï¼‰
params.filterByArea = True
params.minArea = 100 # æ ¹æ®ç‚¹å¤§å°è¿›è¡Œè°ƒæ•´
params.maxArea = 1000

# æŒ‰åœ†åº¦è¿‡æ»¤
params.filterByCircularity = True
params.minCircularity = 0.9 # è°ƒæ•´ç‚¹çš„å½¢çŠ¶

# æŒ‰å‡¸åº¦è¿‡æ»¤
params.filterByConvexity = False
params.minConvexity = 0.7

# æŒ‰æƒ¯æ€§è¿‡æ»¤ï¼ˆåœ†åº¦ï¼‰
params.filterByInertia = True
params.minInertiaRatio = 0.95

# ä½¿ç”¨å‚æ•°åˆ›å»ºæ£€æµ‹å™¨
detector = cv2.SimpleBlobDetector_create(params)

# æ£€æµ‹æ–‘ç‚¹
keypoints = detector.detect(image)

# å°†æ£€æµ‹åˆ°çš„æ–‘ç‚¹ç»˜åˆ¶ä¸ºçº¢è‰²åœ†åœˆ
output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
output_image = cv2.drawKeypoints(output_image, keypoints, np.array([]),
(0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

print(&quot;è¾“å‡ºå›¾åƒ&quot;)
cv2.imshow(&quot;è¾“å‡ºå›¾åƒ&quot;,output_image)
cv2.waitKey(0)
cv2.destroyAllWindows()

print(f&quot;æ£€æµ‹åˆ°çš„æ–‘ç‚¹æ•°é‡ï¼š{len(keypoints)}&quot;)

ä»¥ä¸‹ä»£ç å°† blob çš„åæ ‡æ”¾åœ¨å›¾å½¢ä¸Šï¼ˆè®¤ä¸ºè¿™ç§æ–¹å¼å¯èƒ½æ›´å®¹æ˜“æ“ä½œï¼‰
#å°†å›¾åƒè½¬æ¢ä¸ºå›¾å½¢

import matplotlib.pyplot as plt
import numpy

blob_coords = np.array([kp.pt for kp in keypoints]) #blob çš„åæ ‡
rounded_coords = np.round(blob_coords).astype(int) #å››èˆäº”å…¥çš„åæ ‡

x_coords = rounded_coords[:, 0]
y_coords = rounded_coords[:, 1]

# åŸºäºé‚»è¿‘åº¦çš„åˆ†ç»„
# å¦‚æœ X è·ç¦»å°äºæœ€å°è·ç¦»
# å¦‚æœ Y è·ç¦»å°äºæœ€å°è·ç¦»
# å­˜å‚¨ X å’Œ Y åæ ‡

# è®¡ç®—æœ€å° x å’Œ yå·®å¼‚ï¼ˆå°è¯•åŸºäºæ¥è¿‘åº¦ï¼‰
minx = 10000
miny = 10000
for i in x_coords:
for j in x_coords:
if abs(i - j) &lt;= minx and (15 &lt; abs(i - j)): # å•å…ƒæ ¼å®½åº¦é˜ˆå€¼
minx = abs(i - j)

for i in y_coords:
for j in y_coords:
if abs(i - j) &lt;= miny and (15 &lt; abs(i - j)): # å•å…ƒæ ¼é«˜åº¦é˜ˆå€¼
miny = abs(i - j)

print(f&quot;Smallest x difference: {minx}, Smallest y difference: {miny}&quot;,)

# ç»˜å›¾
fig, ax = plt.subplots()
ax.scatter(x_coords, y_coords, color=&quot;blue&quot;) # ç»˜åˆ¶æ–‘ç‚¹
ax.invert_yaxis()
plt.title(&quot;Braille Cell Detection&quot;)
plt.show()

å°è¯•é€šè¿‡æ¥è¿‘åº¦å°†å®ƒä»¬åˆ†å¼€ï¼ˆä½äºæˆ‘å°è¯•å°†è·ç¦»å¾ˆè¿‘çš„ç‰©ä½“åˆ†ç»„åˆ°ä¸€èµ·ï¼ˆæˆ‘å°†è·ç¦»å¾ˆè¿‘çš„ç‰©ä½“åˆ†ç»„åˆ°ä¸€èµ·ï¼‰ï¼Œä½†æˆ‘æ— æ³•ç†è§£å…¶ä¸­çš„é€»è¾‘ã€‚æˆ‘ä¹Ÿå°è¯•äº†ç»„èšç±» (Kmeans)ï¼Œä½†å®ƒä¸æ˜¯å¾ˆå‡†ç¡®ï¼Œå¹¶ä¸”ä¸é€‚ç”¨äºå…·æœ‰ä¸åŒå­—ç¬¦æ•°çš„å›¾åƒï¼Œå› ä¸ºå®ƒéœ€è¦ä¸æ–­çŸ¥é“è¦å½¢æˆå¤šå°‘ä¸ªç°‡ã€‚
# å°è¯• kmeans èšç±»æ–¹æ³•
# kmeans ä¸èµ·ä½œç”¨ï¼ˆæ— æ³•ä»å›¾åƒä¸­æ‰¾å‡ºç°‡çš„æ•°é‡ï¼‰
# å¦‚æœå¯ä»¥æ‰¾å‡º nclustersï¼Œåˆ™å¯ä»¥å·¥ä½œ

å¯¼å…¥æ•°å­¦
ä» sklearn.cluster å¯¼å…¥ KMeans

blob_coords = np.array([kp.pt for kp in keypoints]) # æå– blob çš„ (x, y) ä½ç½®
rounded_coords = np.round(blob_coords).astype(int) # ä¸ºç®€å•èµ·è§ï¼Œå¯¹åæ ‡è¿›è¡Œå››èˆäº”å…¥

x_coords = rounded_coords[:, 0]
y_coords = rounded_coords[:, 1]

fig, ax = plt.subplots()
ax.scatter(x_coords, y_coords, color=&quot;blue&quot;) # ç»˜åˆ¶æ–‘ç‚¹

ax.invert_yaxis() # åè½¬ Y è½´ä»¥è·å¾—ç±»ä¼¼å›¾åƒçš„åæ ‡
plt.title(&quot;ç›²æ–‡å•å…ƒæ£€æµ‹&quot;)
plt.show()

inertias = []

# 2
kmeans = KMeans(n_clusters=26)
kmeans.fit(rounded_coords)

plt.scatter(x_coords,y_coords, c=kmeans.labels_)
plt.show()
]]></description>
      <guid>https://stackoverflow.com/questions/79306951/separation-of-braille-characters-inside-of-an-image</guid>
      <pubDate>Wed, 25 Dec 2024 05:54:00 GMT</pubDate>
    </item>
    <item>
      <title>ä½¿ç”¨ YOLO å°†æ— ç•Œè¾“å…¥å¯¼å‡ºåˆ° mlpackage/mlmodel æ–‡ä»¶</title>
      <link>https://stackoverflow.com/questions/79305588/use-yolo-with-unbounded-input-exported-to-an-mlpackage-mlmodel-file</link>
      <description><![CDATA[æˆ‘æƒ³åˆ›å»ºä¸€ä¸ª .mlpackage æˆ– .mlmodel æ–‡ä»¶ï¼Œå¯ä»¥å°†å…¶å¯¼å…¥ Xcode è¿›è¡Œå›¾åƒåˆ†å‰²ã€‚ä¸ºæ­¤ï¼Œæˆ‘æƒ³ä½¿ç”¨ YOLO ä¸­çš„åˆ†å‰²åŒ…æ¥æ£€æŸ¥å®ƒæ˜¯å¦ç¬¦åˆæˆ‘çš„éœ€æ±‚ã€‚
ç°åœ¨çš„é—®é¢˜æ˜¯ï¼Œæ­¤è„šæœ¬åˆ›å»ºçš„ .mlpackage æ–‡ä»¶ä»…æ¥å—å›ºå®šå¤§å°ï¼ˆ640x640ï¼‰çš„å›¾åƒï¼š
from ultralytics import YOLO

model = YOLO(&quot;yolo11n-seg.pt&quot;)

model.export(format=&quot;coreml&quot;)

æˆ‘æƒ³åœ¨è¿™é‡Œè¿›è¡Œä¸€äº›æ›´æ”¹ï¼Œå¯èƒ½ä½¿ç”¨ coremltoolsï¼Œä»¥å¤„ç†æ— ç•ŒèŒƒå›´ï¼ˆæˆ‘æƒ³å¤„ç†ä»»æ„å¤§å°çš„å›¾åƒï¼‰ã€‚è¿™é‡Œæœ‰ä¸€äº›æè¿°ï¼šhttps://apple.github.io/coremltools/docs-guides/source/flexible-inputs.html#enable-unbounded-rangesï¼Œä½†æˆ‘ä¸æ˜ç™½å¦‚ä½•ç”¨æˆ‘çš„è„šæœ¬å®ç°å®ƒã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79305588/use-yolo-with-unbounded-input-exported-to-an-mlpackage-mlmodel-file</guid>
      <pubDate>Tue, 24 Dec 2024 12:23:06 GMT</pubDate>
    </item>
    <item>
      <title>iOS Swift æ ¹æ®ç”¨æˆ·æ•°æ®è¿›è¡ŒåŠ¨æ€æœºå™¨å­¦ä¹ </title>
      <link>https://stackoverflow.com/questions/79295972/ios-swift-dynamic-machine-learning-from-user-data</link>
      <description><![CDATA[æ˜¯å¦å¯ä»¥ä½¿ç”¨ Apple ML æ¡†æ¶åŠ¨æ€å­¦ä¹ åº”ç”¨ä¸­çš„ç”¨æˆ·è¡Œä¸ºï¼Ÿæˆ‘å·²ç»ä½¿ç”¨ Create ML åº”ç”¨ç¨‹åºè®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œç„¶åæˆ‘å¯ä»¥ä» iOS è®¾å¤‡æ›´æ–°å¹¶é‡æ–°è®­ç»ƒå—ï¼Ÿè¿™å°±æ˜¯æˆ‘ç›®å‰ä½¿ç”¨è¯¥æ¨¡å‹çš„æ–¹å¼ã€‚
public func calculateMuscleRecoveryTime(_ workout: Workout) {
do {

let config = MLModelConfiguration()
let model = try MuscleRecoveryModel(configuration: config)

let allMuscleGroups = workout.exercises
.compactMap { $0.muscles } // å±•å¹³æ¯ä¸ªé”»ç‚¼çš„è‚Œè‚‰æ•°ç»„
.reduce(Set&lt;MuscleGroup&gt;()) { $0.union($1) } // è”åˆä»¥åˆ é™¤é‡å¤é¡¹

let uniqueMuscleGroups = Array(allMuscleGroups)

for muscleGroup in uniqueMuscleGroups {
let trainingIntensity = Int64(workout.intensity.intValue)
let lastTrainedTimestamp = workout.date
let timeAgo = timeAgoInSeconds(from: lastTrainedTimestamp)
let muscleName = muscleGroup.rawValue.lowercased()

let prediction = try model.prediction(muscle: muscleName, intense: trainingIntensity, lastTrained: timeAgo)
}
} catch let error {
print(&quot;Error: &quot;, error)
}
}
]]></description>
      <guid>https://stackoverflow.com/questions/79295972/ios-swift-dynamic-machine-learning-from-user-data</guid>
      <pubDate>Fri, 20 Dec 2024 01:10:59 GMT</pubDate>
    </item>
    <item>
      <title>éšæœºæ£®æ—åˆ†ç±»å™¨çš„ä¿®æ”¹</title>
      <link>https://stackoverflow.com/questions/79290974/modification-of-random-forest-classifier</link>
      <description><![CDATA[æˆ‘æ­£åœ¨å°è¯•æ›´æ”¹éšæœºæ£®æ—åˆ†ç±»å™¨çš„åŠŸèƒ½ã€‚è™½ç„¶é€šå¸¸æ¯æ¬¡åˆ†å‰²éƒ½ä¼šéšæœºé€‰æ‹©ç‰¹å¾ï¼Œä½†æˆ‘å¸Œæœ›æ¯æ¬¡åˆ†å‰²æ—¶éƒ½è¯„ä¼°ä¸€ä¸ªç‰¹å®šç‰¹å¾ã€‚æˆ‘çŸ¥é“è¿™ä¼šå½±å“æ€§èƒ½ï¼Œä½†æˆ‘æƒ³å°è¯•ä¸€ä¸‹è¿™åœ¨éå¸¸å…·ä½“çš„ç”¨ä¾‹ä¸­æ˜¯å¦æ˜¯ä¸ªå¥½ä¸»æ„ã€‚å› æ­¤ï¼Œè°ƒæ•´çš„ç»“æœåº”ä¸ºï¼šç”¨äºåˆ†å‰²çš„ç‰¹å¾æ˜¯éšæœºé€‰æ‹©çš„ï¼ˆåƒå¾€å¸¸ä¸€æ ·ï¼‰ï¼Œä½†å§‹ç»ˆä¼šè€ƒè™‘ä¸€ä¸ªç‰¹å®šç‰¹å¾ï¼ˆä¾‹å¦‚ç´¢å¼• 15ï¼‰ï¼ˆä¸ä¸€å®šä½¿ç”¨ï¼‰ã€‚æ®æˆ‘æ‰€çŸ¥ï¼Œæ²¡æœ‰å…è®¸æˆ‘æŒ‡å®šè¯¥åŠŸèƒ½çš„å‡½æ•°ï¼ˆå¦‚æœæœ‰ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼‰ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79290974/modification-of-random-forest-classifier</guid>
      <pubDate>Wed, 18 Dec 2024 11:48:27 GMT</pubDate>
    </item>
    <item>
      <title>â€˜superâ€™ å¯¹è±¡æ²¡æœ‰å±æ€§â€˜__sklearn_tags__â€™</title>
      <link>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</link>
      <description><![CDATA[æˆ‘åœ¨ä½¿ç”¨ Scikit-learn ä¸­çš„ RandomizedSearchCV æ‹Ÿåˆ XGBRegressor æ—¶é‡åˆ°äº† AttributeErrorã€‚é”™è¯¯æ¶ˆæ¯æŒ‡å‡ºï¼š
&#39;super&#39; å¯¹è±¡æ²¡æœ‰å±æ€§ &#39;\_\_sklearn_tags__&#39;ã€‚

å½“æˆ‘åœ¨ RandomizedSearchCV å¯¹è±¡ä¸Šè°ƒç”¨ fit æ–¹æ³•æ—¶ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚æˆ‘æ€€ç–‘å®ƒå¯èƒ½ä¸ Scikit-learn å’Œ XGBoost æˆ– Python ç‰ˆæœ¬ä¹‹é—´çš„å…¼å®¹æ€§é—®é¢˜æœ‰å…³ã€‚æˆ‘ä½¿ç”¨çš„æ˜¯ Python 3.12ï¼Œå¹¶ä¸” Scikit-learn å’Œ XGBoost éƒ½å®‰è£…äº†æœ€æ–°ç‰ˆæœ¬ã€‚
æˆ‘å°è¯•ä½¿ç”¨ Scikit-learn ä¸­çš„ RandomizedSearchCV è°ƒæ•´ XGBRegressor çš„è¶…å‚æ•°ã€‚æˆ‘å¸Œæœ›æ¨¡å‹èƒ½å¤Ÿæ¯«æ— é—®é¢˜åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå¹¶åœ¨äº¤å‰éªŒè¯åæä¾›æœ€ä½³å‚æ•°ã€‚
æˆ‘è¿˜æ£€æŸ¥äº†å…¼å®¹æ€§é—®é¢˜ï¼Œç¡®ä¿åº“æ˜¯æœ€æ–°çš„ï¼Œå¹¶é‡æ–°å®‰è£…äº† Scikit-learn å’Œ XGBoostï¼Œä½†é”™è¯¯ä»ç„¶å­˜â€‹â€‹åœ¨ã€‚]]></description>
      <guid>https://stackoverflow.com/questions/79290968/super-object-has-no-attribute-sklearn-tags</guid>
      <pubDate>Wed, 18 Dec 2024 11:45:52 GMT</pubDate>
    </item>
    <item>
      <title>åœ¨ Google Cloud Functions ä¸­éƒ¨ç½² Keras æ¨¡å‹è¿›è¡Œé¢„æµ‹</title>
      <link>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</link>
      <description><![CDATA[æˆ‘ä¸€ç›´åœ¨å°è¯•å°†ä¸€ä¸ªéå¸¸ç®€å•çš„ Keras ç©å…·æ¨¡å‹éƒ¨ç½²åˆ° Cloud Functionsï¼Œè¯¥æ¨¡å‹å¯ä»¥é¢„æµ‹å›¾åƒçš„ç±»åˆ«ï¼Œä½†ç”±äºæœªçŸ¥åŸå› ï¼Œå½“æ‰§è¡Œåˆ° predict æ–¹æ³•æ—¶ï¼Œå®ƒä¼šå¡ä½ï¼Œä¸ä¼šæŠ›å‡ºä»»ä½•é”™è¯¯ï¼Œæœ€ç»ˆä¼šè¶…æ—¶ã€‚
import functions_framework
import io
import numpy as np
import tensorflow as tf

from tensorflow.keras.models import load_model
from PIL import Image

model = load_model(&quot;gs://&lt;my-bucket&gt;/cifar10_model.keras&quot;)

class_names = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;]

def preprocess_image(image_file):
img = Image.open(io.BytesIO(image_file.read()))
img = img.resize((32, 32))
img = np.array(img)
img = img / 255.0
img = img.reshape(1, 32, 32, 3)
return img

@functions_framework.http
def predict(request):
image = preprocess_image(request.files[&#39;image_file&#39;])
print(image.shape) # è¿™ä¼šæ‰“å° OK
prediction = model.predict(image)
print(prediction) # æ°¸è¿œä¸ä¼šæ‰“å°
predict_class = class_names[np.argmax(prediction)]
return f&quot;Predicted class: {predicted_class}&quot;

æœ¬åœ°è°ƒè¯•è¿è¡Œè‰¯å¥½ï¼Œé¢„æµ‹é€Ÿåº¦å¦‚é¢„æœŸä¸€æ ·å¿«ï¼ˆæ¨¡å‹æƒé‡æ–‡ä»¶ä¸º 2MBï¼‰ã€‚æˆ‘è¿˜åœ¨æ­¤è¿‡ç¨‹ä¸­æ·»åŠ äº†å‡ ä¸ªæ‰“å°ï¼ˆä»ä¸Šé¢çš„ä»£ç ç‰‡æ®µä¸­åˆ é™¤ï¼‰ï¼Œæ‰§è¡Œå·¥ä½œæ­£å¸¸ï¼Œç›´åˆ° predict æ–¹æ³•ã€‚
å³ä½¿æœ€å°è®¡ç®—é…ç½®åº”è¯¥å¯ä»¥å·¥ä½œï¼Œæˆ‘è¿˜æ˜¯å°è¯•ä¿ç•™æ›´å¤šå†…å­˜å’Œ CPUï¼Œä½†æ²¡æœ‰ä»»ä½•æ•ˆæœã€‚è¯¥æ¨¡å‹æ‰˜ç®¡åœ¨å­˜å‚¨ä¸­ï¼Œæˆ‘å°è¯•å…ˆä¸‹è½½å®ƒï¼Œä½†ä¹Ÿæ²¡æœ‰ç”¨ã€‚æˆ‘ä¹Ÿå°è¯•åœ¨ tf.device(&#39;/cpu:0&#39;) ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œé¢„æµ‹ï¼Œä¼ é€’ step=1 å‚æ•°å¹¶é¦–å…ˆå°†å›¾åƒæ•°ç»„è½¬æ¢ä¸º Keras æ•°æ®é›†ï¼Œå¦‚ ChatGPT æ‰€å»ºè®®çš„é‚£æ ·ï¼Œç»“æœç›¸åŒã€‚å®é™…ä¸Šï¼Œè°ƒç”¨ predict æ ¹æœ¬æ²¡æœ‰æ‰“å°ä»»ä½•å†…å®¹ã€‚è°ƒç”¨ call è€Œä¸æ˜¯ predict æ²¡æœ‰ä»»ä½•æ•ˆæœã€‚
æˆ‘é”™è¿‡äº†ä»€ä¹ˆï¼Ÿ]]></description>
      <guid>https://stackoverflow.com/questions/79288128/deploying-keras-model-for-prediction-in-google-cloud-functions</guid>
      <pubDate>Tue, 17 Dec 2024 13:51:16 GMT</pubDate>
    </item>
    </channel>
</rss>