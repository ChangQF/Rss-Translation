<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 05 Feb 2024 21:13:08 GMT</lastBuildDate>
    <item>
      <title>如何校准 opensearch 异常检测</title>
      <link>https://stackoverflow.com/questions/77943830/how-to-calibrate-opensearch-anomaly-detection</link>
      <description><![CDATA[我正在尝试校准 OpenSearch 异常检测，但有几个问题。
我的大部分流程都以秒为单位记录：COUNT 1 - Sale:February 5, 2024 @ 15:50:49.000。有些时段我们没有任何记录，一般周末的流量很低。
在下面的两个配置中，我遇到了在周末开始（周六和周日）和周一开始时发出警报的问题。因为周六和周日流量下降很多，周一又增加，恢复正常流量。
配置1：

探测器间隔：10m，
窗口延迟：1m，
木瓦尺寸：8。

**配置2：**

探测器间隔：1m，
窗口延迟：1m，
木瓦尺寸：8。

这种类型的变体可接受的配置是什么？

]]></description>
      <guid>https://stackoverflow.com/questions/77943830/how-to-calibrate-opensearch-anomaly-detection</guid>
      <pubDate>Mon, 05 Feb 2024 20:34:27 GMT</pubDate>
    </item>
    <item>
      <title>我想制作一个职业建议模型[关闭]</title>
      <link>https://stackoverflow.com/questions/77943423/i-want-to-make-a-career-suggestion-model</link>
      <description><![CDATA[有一个数据集，其中包含职位名称和描述。当一个人输入他的技能时，我需要输出他应该做什么类别的工作。我已经使用余弦相似度创建了它。（如果你能告诉我更好的方法，那也会有帮助）现在我需要提供建议，以提高他的技能。
如果他输入统计和Python技能。模型应该可以说是学习数据科学。或者学习数据分析。
你能给我一个关于如何做到这一点的建议吗？非常感谢这种方法。
（发展法学硕士不是一种选择）
我被困在这里了。非常感谢任何帮助]]></description>
      <guid>https://stackoverflow.com/questions/77943423/i-want-to-make-a-career-suggestion-model</guid>
      <pubDate>Mon, 05 Feb 2024 19:11:21 GMT</pubDate>
    </item>
    <item>
      <title>如何训练 Tortoise TTS 模型将英语视频配音为 URDU 语言 [关闭]</title>
      <link>https://stackoverflow.com/questions/77942946/how-to-train-tortoise-tts-model-for-dubing-english-video-to-urdu-language</link>
      <description><![CDATA[我正在做AI配音平台。我想将英语语音视频配音为乌尔都语语音。我已经实现了以下许多模块

从视频中提取音频（完成）
从音频中提取文本（完成）
将英语文本转换为乌尔都语文本（完成）

现在，我想使用这个URDU文本（从输入中提取和转换，如上所述[1,2,3]）和参考英语音频（从TTS 模型中的视频广告在 [1]) 中进行了讨论。
我想要的是 --&gt;该 TTS 模型从参考音频中提取特征和韵律样本，并说出具有完美语音克隆的乌尔都语文本。]]></description>
      <guid>https://stackoverflow.com/questions/77942946/how-to-train-tortoise-tts-model-for-dubing-english-video-to-urdu-language</guid>
      <pubDate>Mon, 05 Feb 2024 17:38:45 GMT</pubDate>
    </item>
    <item>
      <title>InvalidParameterError：GridSearchCV 的“评分”参数必须是其中的 str</title>
      <link>https://stackoverflow.com/questions/77942581/invalidparametererror-the-scoring-parameter-of-gridsearchcv-must-be-a-str-amo</link>
      <description><![CDATA[当我尝试将训练数据集拟合到 GridsearchCV 时，它指出评分必须是以下各项中的一个：
{&#39;jaccard_samples&#39;, &#39; precision_macro&#39;, &#39;balanced_accuracy&#39;, ...&lt;允许类的长列表，请参阅编辑历史记录&gt;...},
一个可调用对象、“list”的实例、“tuple”的实例、“dict”的实例或 None。
而是得到了{&#39;精确度&#39;、&#39;召回率&#39;、&#39;准确度&#39;、&#39;f1&#39;}。”

尽管我的评分列表是：“{&#39; precision&#39;,&#39;f1&#39;,&#39;recall&#39;,&#39;accuracy&#39;}”。
我在 VS Code 中使用 Jupyter 内核扩展运行代码。我尝试将其更改为仅对“召回”进行评分，并且它有效，但是我希望有多个评分变量。]]></description>
      <guid>https://stackoverflow.com/questions/77942581/invalidparametererror-the-scoring-parameter-of-gridsearchcv-must-be-a-str-amo</guid>
      <pubDate>Mon, 05 Feb 2024 16:42:58 GMT</pubDate>
    </item>
    <item>
      <title>Keras 中的多输出 ResNet 模型：损失字典和训练问题</title>
      <link>https://stackoverflow.com/questions/77942574/multi-output-resnet-model-in-keras-issue-with-loss-dictionary-and-training</link>
      <description><![CDATA[我正在使用 Keras 和 ResNet50 进行多输出分类任务。该数据集由面部图像组成，每张图像都有四个相关标签，分别代表无聊、投入、困惑和沮丧的强度，每个标签的范围从 1 到 4。

框架：图像的绝对路径。
无聊：无聊的强度（1 到 4）。
参与度：参与度（1 到 4）。
混乱：混乱的强度（1 到 4）。
挫败感：挫败感的强度（1 到 4）。

我想创建一个基于 ResNet 的模型，具有多个输出来同时预测这四个标签。
从tensorflow导入keras
从tensorflow.keras导入输入
从tensorflow.keras.applications导入ResNet50
从tensorflow.keras导入层、模型

基础模型 = ResNet50(input_shape=(128, 128, 3),
                      include_top=假，
                      权重=&#39;imagenet&#39;）

模型 = models.Sequential([
    基本模型，
    图层.GlobalAveragePooling2D(),
    层.Dense(64, 激活=&#39;relu&#39;),
    层.Dense（4，激活=&#39;softmax&#39;，名称=&#39;无聊&#39;），
    层.Dense（4，激活=&#39;softmax&#39;，名称=&#39;参与&#39;），
    层.Dense(4, 激活=&#39;softmax&#39;, name=&#39;Confusion&#39;),
    层.Dense（4，激活=&#39;softmax&#39;，名称=&#39;挫败感&#39;）
]）


model.compile(优化器=&#39;亚当&#39;,
              损失={&#39;无聊&#39;: &#39;categorical_crossentropy&#39;,
                    &#39;参与度&#39;: &#39;categorical_crossentropy&#39;,
                    &#39;混乱&#39;: &#39;categorical_crossentropy&#39;,
                    &#39;挫败感&#39;: &#39;categorical_crossentropy&#39;},
              指标=[&#39;准确性&#39;])
模型.summary()

&lt;前&gt;&lt;代码&gt;错误：
ValueError：发现与任何模型输出都不对应的意外损失或指标：dict_keys([&#39;Boredom&#39;, &#39;Engagement&#39;, &#39;Confusion&#39;])。有效模式输出名称：[&#39;Frustration&#39;]。收到的结构是：{&#39;Boredom&#39;：&#39;categorical_crossentropy&#39;，&#39;Engagement&#39;：&#39;categorical_crossentropy&#39;，&#39;Confusion&#39;：&#39;categorical_crossentropy&#39;}

我真的不知道出了什么问题，名字是匹配的]]></description>
      <guid>https://stackoverflow.com/questions/77942574/multi-output-resnet-model-in-keras-issue-with-loss-dictionary-and-training</guid>
      <pubDate>Mon, 05 Feb 2024 16:41:58 GMT</pubDate>
    </item>
    <item>
      <title>如何正确训练多智能体强化学习策略？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77942291/how-to-correctly-train-policies-in-multi-agent-rl</link>
      <description><![CDATA[我深入研究多智能体强化学习，在阅读了一些文献后，我想澄清一些方法，因为我不太确定。现在通过以下两种情况可以清楚地看出：

独立学习：每个智能体有一个不同的策略，每个智能体具有相同奖励函数的不同奖励。
πag1: obsag1 → aag1 → rag1
πag2: obsag2 → aag2 → rag2

联合学习：为所有智能体同时制定一项（全局）政策决策，并提供一项全局奖励
πag: [obsag1, obsag2, obsag3] → [aag1 sub&gt;, aag2, aag3] → rglob = rag1 + rag2&lt; /sub&gt; + rag3


但是使用CTDE方法（集中批评分散执行），我不太清楚应该如何正确应用它。可以实施和组合以下政策和奖励选项：

独特的策略：每个代理都有自己的策略：πag_i
共享策略：每个代理使用相同的策略：πag
每个代理的不同奖励值（通过相同的奖励函数）：aag_i → rag_i
向所有代理提供共享/全局奖励：aag_i → rglob = sum(rag_i ）

我还知道可以将部分分数 α 分配给 3) 中的不同奖励。即 rag_i + α*sum(rag_j\i) 以增强合作。
但这才是“正确的方法”？学习 MARL 中与异构代理的协调行为，特别是在应用 CTDE 时？
我的目标是将 MARL 应用到游戏中，其中异构代理必须攻击并摧毁对手。目前我正在使用 CTDE，其中相同类型的代理使用相同的共享策略，并且它们获得不同的奖励值（具有相同的奖励函数）。我也尝试过共享奖励，但没有注意到显着的变化。我通过 PPO 更新我的策略，因此我不使用显式的 MARL 算法。
我只是想确保我走的是正确的路。这不是实施的问题，而是整个概念的问题。]]></description>
      <guid>https://stackoverflow.com/questions/77942291/how-to-correctly-train-policies-in-multi-agent-rl</guid>
      <pubDate>Mon, 05 Feb 2024 16:01:35 GMT</pubDate>
    </item>
    <item>
      <title>扫描发票 PDF 上的 OCR [关闭]</title>
      <link>https://stackoverflow.com/questions/77942170/ocr-on-scanned-invoice-pdfs</link>
      <description><![CDATA[我刚刚开始在我的公司从事 OCR 工作。我公司面临的最大挑战之一是检索扫描的 PDF 图像中的一些特定属性，例如帐号、总费用、帐单地址、公司名称等。我已经开始研究 TesseractOCR，但文档对我来说太痛苦了。在我的自定义数据集上完成并训练模型非常困难。有人可以帮助我如何实现这一目标吗？
P.S：我也尝试过 docTR、TrOCR、EasyOCR 等，但我不明白如何在我的自定义数据集上训练这些模型？
我无法理解如何在我的自定义数据集上训练这些模型？因为关于这方面的文档对于像我这样的初学者来说并不是那么简单]]></description>
      <guid>https://stackoverflow.com/questions/77942170/ocr-on-scanned-invoice-pdfs</guid>
      <pubDate>Mon, 05 Feb 2024 15:43:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 python 算法将相似的名称分组在一起</title>
      <link>https://stackoverflow.com/questions/77941625/group-similar-names-together-using-a-python-algorithm</link>
      <description><![CDATA[我需要一个项目的帮助，我有一个涉及多个产品的名称列表，但有些名称指的是同一产品，只是以不同的方式编写（如下所示）对最相似的名称进行分类的最佳方法是什么帽子很可能指的是同一组产品
示例
只有一种产品可以这样命名：
-EXFORGE 5 MG/160 B/28 COMP
-EXFORGE 5MG /160 Bte 28
-EXFORGE COMP 5 MG _160 B / 28
-Exforge 5 MG 160 B/28 COMP。
尝试了 FuzzyWuzzy 库，但它没有给我一个好的结果
这就是我所做的
来自 fuzzywuzzy 导入过程

# 假设“data”是表格数据中的产品名称列
数据 = [
    &#39;EXFORGE 5 MG/160 B/28 COMP&#39;,
    &#39;EXFORGE 5MG /160 Bte 28&#39;，
    &#39;多利普兰500MG&#39;，
    &#39;多利普兰 5.0 MG&#39;，
    &#39;EXFORGE COMP 5 MG _160 B / 28&#39;,
    &#39;Exforge 5 MG 160 B/28 COMP.&#39;,
    &#39;Doliprane 500MG Comp&#39;，
    &#39;EXFORGE CP.PEL 5MG/160 MG 28&#39;,
    “环丙沙星 500 MG/5 ML IV 100 ML 输注溶液”，
    “环丙沙星 500MG/5ML IV 100 ML Sol for Inf”，
    “输注用环丙沙星溶胶 500 MG/5 ML 100 ML”，
    “环丙沙星 500 MG/5 ML IV 100 ML 输注溶胶”，
    “环丙沙星 500 MG IV 100 ML Sol for Inf”，
    “扑热息痛 500 MG 片剂 30 片”，
    “扑热息痛 500MG 片剂 30 片”，
    “扑热息痛片 500 MG 30 片”，
    “扑热息痛片 500 MG 30 片”，
    “扑热息痛 500 MG 30 片”，
    “赖诺普利 10 MG 片剂 28 片”，
    “赖诺普利 10MG 片剂 28 片”，
    &#39;赖诺普利 Tab 10 MG 28s&#39;，
    &#39;赖诺普利片 10 MG 28s&#39;，
    “赖诺普利 10 MG 28 片”，
    “辛伐他汀 20 MG 片剂 100 片”，
    “辛伐他汀 20MG 片剂 100 片”，
    “辛伐他汀片 20 MG 100s”，
    “辛伐他汀片 20 MG 100s”，
    “辛伐他汀 20 MG 100 片”，
    “奥美拉唑 20 MG 胶囊 28 粒”，
    “奥美拉唑 20MG 胶囊 28 粒”，
    “奥美拉唑胶囊 20 MG 28 粒”，
    “奥美拉唑胶囊 20 MG 28 粒”，
    “奥美拉唑 20 MG 28 粒胶囊”
]

# 定义相似度阈值
阈值 = 87

# 初始化组列表
组 = []

# 将相似名称添加到组中的函数
def add_to_group(组, 名称):
    对于组中的现有名称：
        if process.extractOne(existing_name, [name])[1] &gt;= 阈值：
            返回真
    返回错误

# 迭代数据以形成组
对于数据中的名称：
    添加 = 假
    对于组中的组：
        如果添加到组（组，名称）：
            组.添加(名称)
            添加=真
            休息
    如果没有添加：
        groups.append({名称})

# 打印最相似名称的组
对于 idx，枚举中的组（组，1）：
    print(f&quot;组 {idx}: {group}&quot;)

只有 3 组而不是 7 组，当我将阈值调整为 88 而不是 87 时，它变成了 10 组]]></description>
      <guid>https://stackoverflow.com/questions/77941625/group-similar-names-together-using-a-python-algorithm</guid>
      <pubDate>Mon, 05 Feb 2024 14:22:59 GMT</pubDate>
    </item>
    <item>
      <title>coco注释数据集的滑动窗口[关闭]</title>
      <link>https://stackoverflow.com/questions/77941194/sliding-window-for-coco-annotated-dataset</link>
      <description><![CDATA[我正在尝试使用大图像（20.000px）数据集训练模型，以检测异常。
由于缺陷可能非常小，所以我使用滑动窗口方法将图像切割成 448x488px 的块（使用 SAHI python 包）。
我遇到以下问题：
每个断层都用多边形注释。但正如您所看到的，多边形比断层本身要大一些。所以现在滑动窗口（红色）与多边形（蓝色）重叠。这意味着该窗口被分类为有故障，而实际上它是正确的。

现在这会影响准确性、召回率和精确度分数。我想过在每个窗口上使用最小面积注释阈值，但这是不可能的，因为有些错误非常小。
还尝试使注释更加精确，这导致召回率提高了 20%。
对于这种情况有好的做法吗？]]></description>
      <guid>https://stackoverflow.com/questions/77941194/sliding-window-for-coco-annotated-dataset</guid>
      <pubDate>Mon, 05 Feb 2024 13:08:31 GMT</pubDate>
    </item>
    <item>
      <title>在小批量梯度下降中应用StandardScaler，应用程序错误[关闭]</title>
      <link>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</link>
      <description><![CDATA[ValueError：需要 2D 数组，却得到 1D 数组：
数组=[0。 0. 0. ... 0. 0. 1.]。
如果数据具有单个特征，则使用 array.reshape(-1, 1) 重塑数据；如果数据包含单个样本，则使用 array.reshape(1, -1) 重塑数据。

当我尝试运行代码时，我不断收到此错误：
# 分离特征 (X) 和目标变量 (y)
X = np.array(df[&#39;默认&#39;])
y = np.array(df[&#39;默认&#39;])
l = len(X)

# 将数据分为训练集和测试集

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 添加特征标量器 Z 分数标准化

定标器=标准定标器()
X_train_scaled = 缩放器.fit_transform(X_train)
X_test_scaled = 缩放器.transform(X_test)


# 实现小批量梯度

类 mini_batch_gradient_descent:
    
    def create_batch(self,X_train,y_train,batch_size):
        小批量=[]
        数据=np.stack((X_train,y_train),轴=1)
        np.random.shuffle(数据)
        batches=X_train.shape[0]//batch_size
        对于范围内的 i（批次）：
            mini_batch=数据[i*batch_size:(i+1)*batch_size]
            mini_batches.append((mini_batch[:,0], mini_batch[:,1]))
        如果 X_train.shape[0]/batch_size!=0:
            mini_batch=数据[i*batch_size:]
            mini_batches.append((mini_batch[:, 0], mini_batch[:,1]))
        返回小批量
    
    def fit(self,X_train,y_test,alpha,epochs,batch_size):
        self.m=np.random.randn(1,1)
        self.c=np.random.randn(1,1)
        l=len(X_train)
        对于范围内的 i（纪元）：
            批次= self.create_batch（X_train，y_train，batch_size）
            对于批量批次：
                xb=批次[0]
                yb=批次[1]
                xb=xb.reshape(1, xb.shape[0])
                截距=np.sum((np.dot(self.m,xb)+self.c)-yb)
                斜率=np.sum((np.dot(self.m,xb)+self.c)-yb)
                self.m=self.m-alpha*(斜率/l)
                self.c=self.c-alpha*(斜率/l)
    
    def 斜率截距():
        print(f&quot;斜率为 {self.m[0][0]}&quot;)
        print(f&quot;截距为 {self.c[0][0]}&quot;)
        
    
    def 预测（自我，X_test）：
        X_test=X_test.reshape(X_test.shape[0],1)
        self.m=self.m.reshape(self.m.shape[1],self.m.shape[0])
        结果=np.dot(X_test, self.m)+self.c
        返回结果

我尝试使用 loc/iloc，但它一直收到错误。
我正在使用数据帧，然后转换为 np.array 来运行程序。它可以在没有功能缩放器的情况下工作，但当我尝试实现缩放器时，它开始给我错误。不确定在功能扩展方面我还有什么其他选择。]]></description>
      <guid>https://stackoverflow.com/questions/77937974/applying-standardscaler-in-mini-batch-gradient-descent-error-in-application</guid>
      <pubDate>Sun, 04 Feb 2024 23:19:53 GMT</pubDate>
    </item>
    <item>
      <title>比较不同模型的 F1 分数的概率阈值图</title>
      <link>https://stackoverflow.com/questions/77935679/comparing-probability-threshold-graphs-for-f1-score-for-different-models</link>
      <description><![CDATA[下面是两个并排的图，针对不平衡的数据集。

我们有一个非常大的不平衡数据集，我们正在以不同的方式处理/转换。每次转换后，我们都会对其运行 xgboost 估计器。
左侧是三个 xgboost 模型在三个不同转换数据集上的 PR 曲线。从左图可以看出，3条PR曲线全部重叠；事实上，其中两个（红色和绿色）曲线下的面积是相同的。
右侧是来自相同三个模型但在不同概率阈值下的 F1 分数（根据测试数据计算）的图。左右图中模型的颜色匹配。红色和绿色模型在不同概率阈值下的峰值 F1 分数大致相同。蓝色模型的峰值 F1 分数略低于其他两个模型的峰值 F1 分数。我的问题是：
&lt;块引用&gt;
a.我可以说，绿色模型比红色模型“远”好，因为它的 F1 分数在很大的概率阈值范围内相当稳定，而红色模型的 F1 分数随着概率阈值的微小变化而迅速下降。概率阈值。
b.红色和蓝色这两种型号中，哪一种更好，为什么？

如果您能给出合理的答复，我将不胜感激，因为它可能对我的工作有所帮助。顺便说一句，我已经进行了大量关于 F1 分数、AUC 和 PR 曲线的讨论，包括这个。
简单地说，这个问题涉及如何解释不同模型的 F1 分数阈值图，因为 PR 曲线没有得出结论。]]></description>
      <guid>https://stackoverflow.com/questions/77935679/comparing-probability-threshold-graphs-for-f1-score-for-different-models</guid>
      <pubDate>Sun, 04 Feb 2024 11:59:48 GMT</pubDate>
    </item>
    <item>
      <title>在 Rust-linfa 中加载用于预测的线性回归模型</title>
      <link>https://stackoverflow.com/questions/77932307/loading-a-linear-regression-model-back-up-for-prediction-in-rust-linfa</link>
      <description><![CDATA[我一直在研究 Rust 机器学习的 linfa，特别是线性回归模型。我希望能够保存和加载经过训练的线性回归模型，但我无法找到实现此目的的方法。
方法 1：
到目前为止，我的方法是获取训练中涉及的主要参数，这些参数可以从 linfa 的线性回归实现中获取，并将它们存储在一个可以存储为 JSON 文件的结构中（通过 serde_json 完成）。然而，在此之后我不知道如何将其加载回来进行训练。
以上内容详情如下：
存储训练参数的结构：
struct ModelJson {
    系数：Vec f64 ，
    拦截：f64，
}

存储过程：
let model = lin_reg.fit(&amp;dataset)?;
让 model_json = ModelJson {
    系数： model.params().to_vec(),
    拦截： model.intercept(),
};

存储的数据看起来如何：
{“系数”:[-0.00017907873576254802,-0.00100659702068151,-0.0008275037845519519,0.0004613216043979551,0.00103006349345 99436]，“拦截”：50.525680622870084}

方法 2：
关于序列化和反序列化整个模型，我发现以下信息表明 linfa 中支持相同的操作。
加载和保存模型
这引出了我的第二种方法，其中我使用了 linfa-linear 的 serde 功能（包含 LinearRegression 模型），首先在我的 Cargo.toml 中包含以下内容：
linfa-clustering = {version=&quot;0.7.0&quot;, features=[&quot;serde&quot;]}
根据我对实现的理解，此功能为 LinearRegression 实现了以下功能：
Serde 序列化和反序列化实现 - 派生
上述实现：
&lt;前&gt;&lt;代码&gt;#[cfg_attr(
    特征=“serde”，
    派生（序列化，反序列化），
    serde(crate = “serde_crate”)
)]
/// 可用于进行预测的拟合线性回归模型。
pub struct FittedLinearRegression; {
    截距：F，
    参数：Array1,
}

发现于： linfa-线性导出实现
我的实现如下：
let model = lin_reg.fit(&amp;dataset)?;
让序列化 = serde_json::to_string(&amp;model).unwrap();

但是此方法出现以下错误：
不满足特征边界 `FittedLinearRegression: serde::ser::Serialize`
以下其他类型实现了特征 `serde::ser::Serialize`：
  布尔值
  字符
  大小
  i8
  i16
  i32
  i64
  i128
和其他 133 个rustcClick 以获取完整的编译器诊断
main.rs(82, 22)：此调用引入的绑定所需

是否有其他方法可以做到这一点，或者是否有某种方法可以使这些方法之一发挥作用？]]></description>
      <guid>https://stackoverflow.com/questions/77932307/loading-a-linear-regression-model-back-up-for-prediction-in-rust-linfa</guid>
      <pubDate>Sat, 03 Feb 2024 13:44:24 GMT</pubDate>
    </item>
    <item>
      <title>在 Flask 框架中集成 ML 模型时似乎无法解决此错误</title>
      <link>https://stackoverflow.com/questions/77892140/cant-seem-to-solve-this-error-while-integrating-a-ml-model-in-a-flask-framework</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77892140/cant-seem-to-solve-this-error-while-integrating-a-ml-model-in-a-flask-framework</guid>
      <pubDate>Sat, 27 Jan 2024 17:33:27 GMT</pubDate>
    </item>
    <item>
      <title>配置 Kaggle 以在两个 T4 GPU 之间进行分布式训练和内存共享</title>
      <link>https://stackoverflow.com/questions/77875716/configuring-kaggle-for-distributed-training-and-memory-sharing-across-two-t4-gpu</link>
      <description><![CDATA[我正在尝试在 Kaggle 上使用以下命令来训练 Dreambooth：
！加速启动 --num_cpu_threads_per_process=2 “./sdxl_train.py” \
  --pretrained_model_name_or_path=“stabilityai/stable-diffusion-xl-base-1.0” \
  --train_data_dir=“数据集/img” \
  --reg_data_dir=“数据集/reg” \
  --output_dir=“输出” \
  --output_name=“SDXLDreambooth” \
  --save_model_as=“安全张量” \
  --train_batch_size=1 \
  --max_train_steps=8000 \
  --save_every_n_steps=4001 \
  --optimizer_type=“adafactor” \
  --optimizer_argsscale_parameter=Falserelative_step=Falsewarmup_init=False\
  --xformers \
  --lr_scheduler=“constant_with_warmup” \
  --lr_warmup_steps=100 \
  --learning_rate=2.5e-6 \
  --max_grad_norm=0.0 \
  --分辨率=“1024,1024” \
  --save_ precision =“fp16” \
  --save_n_epoch_ratio=1 \
  --max_data_loader_n_workers=1 \
  --persistent_data_loader_workers \
  --mixed_ precision =“fp16” \
  --full_fp16 \
  --logging_dir=&quot;日志&quot; \
  --log_prefix=“最后” \
  --gradient_checkpointing \
  --caption_extension=“.txt” \
  --no_half_vae \
  --缓存潜伏

并添加 --train_text_encoder 会在具有 16 GB VRAM 的 P100 GPU 上出现内存不足错误，即使启用了所有优化。我已经测试过在 Modal 上具有 24 GB VRAM 的 L4 GPU 上运行相同的命令，并且它成功运行最大 VRAM 利用率约为 18 GB。
但是，我注意到 Kaggle 还提供了使用两个 T4 GPU（每个 GPU 具有 16 GB VRAM）的选项，这让我想知道是否可以更改那里的环境配置（包括例如更改脚本， DeepSpeed 配置、加速配置等）以允许在 2 个 GPU 之间共享内存，其总组合内存 (32 GB) 应允许命令运行（需要 18 GB 内存）。
Kaggle 设置的默认行为似乎是在 2 个 GPU 之间复制配置并并行处理训练，因此使用 --train_text_encoder 选项，脚本将需要每个 GPU 18 GB ，导致内存不足错误。
我应该如何配置环境，以便允许两个 GPU 之间共享内存，并避免收到内存不足错误？
&lt;小时/&gt;
编辑：以下是示例笔记本和一些运行的一些链接：

笔记本；
OOM 使用两个 15 GB T4 GPU 运行；
使用 1 个 16 GB P100 GPU 成功运行.

这些都没有启用 --train-text-encoder，因为它会导致 OOM 错误。以下是第一次运行时 T4 GPU 的内存利用率：
]]></description>
      <guid>https://stackoverflow.com/questions/77875716/configuring-kaggle-for-distributed-training-and-memory-sharing-across-two-t4-gpu</guid>
      <pubDate>Wed, 24 Jan 2024 19:22:44 GMT</pubDate>
    </item>
    <item>
      <title>无法创建机器学习模型</title>
      <link>https://stackoverflow.com/questions/61084824/cannot-create-model-for-machine-learning</link>
      <description><![CDATA[我正在创建一个用于检测脑肿瘤的 python 应用程序。 
关于数据：
该数据集包含 2 个文件夹：yes 和 no，其中包含 253 个脑部 MRI 图像。 yes 文件夹包含 155 个肿瘤性脑部 MRI 图像，no 文件夹包含 98 个非肿瘤性脑部 MRI 图像。
# 张量板
log_file_name = f&#39;brain_tumor_detection_cnn_{int(time.time())}&#39;
张量板 = TensorBoard(log_dir=f&#39;logs/{log_file_name}&#39;)

# 检查点
# 包含纪元和验证（开发）准确性的唯一文件名
filepath=&quot;cnn-parameters-improvement-{epoch:02d}-{val_acc:.2f}&quot;
# 保存迄今为止最好的验证（开发）精度的模型
checkpoint = ModelCheckpoint(&quot;models/{}.model&quot;.format(filepath, monitor=&#39;val_acc&#39;, verbose=1, save_best_only=True, mode=&#39;max&#39;))


# ## 训练模型

model.fit（x = X_train，y = y_train，batch_size = 32，epochs = 10，validation_data =（X_val，y_val），callbacks = [tensorboard，检查点]）

在训练模型时，出现以下错误：

&lt;前&gt;&lt;代码&gt;纪元 1/10
91/91 [================================] - 预计到达时间：0 秒 - 损失：0.7457 - 准确度：0.6735
-------------------------------------------------- ------------------------
KeyError Traceback（最近一次调用最后一次）
_get_file_path 中的 c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py（自我、纪元、日志）
   攀上漂亮女局长之后1243
-&gt;第1244章
   攀上漂亮女局长之后1245

关键错误：&#39;val_acc&#39;

在处理上述异常的过程中，又出现了一个异常：

KeyError Traceback（最近一次调用最后一次）
&lt;ipython-input-20-b50661a1419b&gt;在&lt;模块&gt;中
      1 开始时间 = time.time()
      2
----&gt; 3 model.fit（x = X_train，y = y_train，batch_size = 32，epochs = 10，validation_data =（X_val，y_val），callbacks = [tensorboard，检查点]）
      4
      5 结束时间 = time.time()

_method_wrapper 中的 c:\python38\lib\site-packages\tensorflow\python\keras\engine\training.py(self, *args, **kwargs)
     64 def _method_wrapper（自我，*args，**kwargs）：
     65 if not self._in_multi_worker_mode(): # pylint: 禁用=受保护的访问
---&gt; 66 返回方法（self，*args，**kwargs）
     67
     68 # 已经在 `run_distribute_coordinator` 中运行。

c:\python38\lib\site-packages\tensorflow\python\keras\engine\training.py 适合（自我，x，y，batch_size，纪元，详细，回调，validation_split，validation_data，shuffle，class_weight，sample_weight，initial_epoch 、steps_per_epoch、validation_steps、validation_batch_size、validation_freq、max_queue_size、workers、use_multiprocessing、**kwargs）
    第811章
    812
--&gt;第813章
    第814章
    第815章 打破

c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py 在 on_epoch_end(self, epoch, 日志)
    363 日志 = self._process_logs(日志)
    364 self.callbacks中的回调：
--&gt;第365章
    第366章
    367 def on_train_batch_begin（自我，批次，日志=无）：

c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py 在 on_epoch_end(self, epoch, 日志)
   第1175章
   第1176章
-&gt;第1177章
   第1178章
   第1179章 1179

_save_model 中的 c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py(self、纪元、日志)
   1194 int) 或 self.epochs_since_last_save &gt;= self.period:
   第1195章
-&gt;第1196章
   1197
   第1198章

_get_file_path 中的 c:\python38\lib\site-packages\tensorflow\python\keras\callbacks.py（自我、纪元、日志）
   第1244章
   攀上漂亮女局长之后1245
-&gt; 1246 raise KeyError(&#39;无法格式化此回调文件路径：“{}”。&#39;
   1247 &#39; 原因 : {}&#39;.format(self.filepath, e))
   第1248章

KeyError：&#39;无法格式化此回调文件路径：“models/cnn-parameters-improvement-{epoch:02d}-{val_acc:.2f}.model”。原因：\&#39;val_acc\&#39;&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/61084824/cannot-create-model-for-machine-learning</guid>
      <pubDate>Tue, 07 Apr 2020 16:30:01 GMT</pubDate>
    </item>
    </channel>
</rss>