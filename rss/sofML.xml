<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 04 Oct 2024 12:32:52 GMT</lastBuildDate>
    <item>
      <title>我应该学习哪些课程才能更好地理解机器学习？[关闭]</title>
      <link>https://stackoverflow.com/questions/79054030/what-courses-should-i-learn-to-better-understand-machine-learning</link>
      <description><![CDATA[我正在学习 Python 矩阵和 AI（在大学，这是我的专业），具体来说，我学习的是该领域（高密度第六代网络 (6G) 中的 AI）
我不太明白代码是什么，代码会生成带有 1 到 9 之间数字的随机图片（非常基本的代码）
我可以观看哪些课程以更好地理解，因为大家都知道老师不在乎。
我还没有尝试任何东西，但我找到了一些可以开始的东西，我正在等待有经验的程序员的建议]]></description>
      <guid>https://stackoverflow.com/questions/79054030/what-courses-should-i-learn-to-better-understand-machine-learning</guid>
      <pubDate>Fri, 04 Oct 2024 11:23:25 GMT</pubDate>
    </item>
    <item>
      <title>非最大抑制 (NMS) [关闭]</title>
      <link>https://stackoverflow.com/questions/79053506/non-maximum-suppression-nms</link>
      <description><![CDATA[我想知道为什么不直接选择具有最大卑劣分数的窗口，我不明白这样做的问题在哪里，为什么不直接选择最高分数而不做 NMS 所做的其他事情？
NMS 选择最高分数，然后与其他框应用 IOU“交集优于并集”，如果 IOU 返回的值高于某个阈值，则删除该框
最终，如果 NMS 产生多个框，那么我们将选择最高分数？
那么为什么我们必须经历所有这些，为什么不立即选择得分最高的框？]]></description>
      <guid>https://stackoverflow.com/questions/79053506/non-maximum-suppression-nms</guid>
      <pubDate>Fri, 04 Oct 2024 08:55:27 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Pytorch 中将 DistributedSampler 与类权重结合使用？</title>
      <link>https://stackoverflow.com/questions/79052969/how-to-use-class-weights-with-distributedsampler-in-pytorch</link>
      <description><![CDATA[我有一个高度不平衡的数据集，需要在多 GPU 设置上进行训练。在单个 GPU 上，类不平衡可以通过 WeightedRandomSampler 来处理。然后我会将采样器对象传递给 DataLoader。但在多 GPU 设置中，由于我使用 DistributedSampler 作为采样器，因此我无法以相同的方式传递 WeightedRandomSampler。如何在我的 DataLoader 中同时使用两者？
这是我使用 DistributedSampler 的代码：
train_dataset = SampleDataset(data_root=data_root, transform=train_transforms, num_classes=num_classes)
train_sampler = DistributedSampler(train_dataset, num_replicas=world_size)
train_loader = DataLoader(train_dataset,
batch_size=batch_size,
pin_memory=True,
sampler=train_sampler,
num_workers=0)

]]></description>
      <guid>https://stackoverflow.com/questions/79052969/how-to-use-class-weights-with-distributedsampler-in-pytorch</guid>
      <pubDate>Fri, 04 Oct 2024 05:51:45 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：如果没有传递“decoder_input_ids”或“decoder_inputs_embeds”，则“input_ids”不能为“None”</title>
      <link>https://stackoverflow.com/questions/79052681/valueerror-if-no-decoder-input-ids-or-decoder-inputs-embeds-are-passed-in</link>
      <description><![CDATA[我正在尝试获取佛罗伦萨 2 模型的解码器隐藏状态。我按照这个 https://huggingface.co/microsoft/Florence-2-large/blob/main/modeling_florence2.py 来了解前向方法中的参数。我尝试了类似这样的方法
# 使用 output_hidden_​​states=True 将输入传递给模型以获取隐藏状态
with torch.no_grad():
outputs = model(
input_ids=inputs[&quot;input_ids&quot;],
pixel_values=inputs[&quot;pixel_values&quot;],
tention_mask=inputs[&quot;attention_mask&quot;],
output_hidden_​​states=True, # 请求隐藏状态
)

但是执行此操作时出现此错误：
ValueError：如果未传递 decoder_input_ids 或 decoder_inputs_embeds，则 input_ids 不能为 None。请传递 input_ids 或 decoder_input_ids 或 decoder_inputs_embeds。
我无法完全理解错误，因为它说“input_ids 不能为 None”但我的 input_ids 不是 None。它类似于：
tensor([[ 0, 2264, 473, 5, 2274, 6192, 116, 2]], device=&#39;cuda:1&#39;)
此外，我仅使用此模型进行推理，decoder_input_ids 是什么意思，我可以在哪里找到它以在前向方法中传递。]]></description>
      <guid>https://stackoverflow.com/questions/79052681/valueerror-if-no-decoder-input-ids-or-decoder-inputs-embeds-are-passed-in</guid>
      <pubDate>Fri, 04 Oct 2024 02:40:48 GMT</pubDate>
    </item>
    <item>
      <title>尝试在 TensorFlow 中拟合 DQN 模型时出现空断言错误</title>
      <link>https://stackoverflow.com/questions/79051833/empty-assertion-error-when-trying-to-fit-dqn-model-in-tensorflow</link>
      <description><![CDATA[我正在尝试训练 RL TensorFlow 模型。
该模型以形状为 (2,2) 的元组作为输入，并期望输出离散数。
我已经更新到 keras-rl2，所以这不是问题的根源。
模型如下：
def build_model(actions):
model = Sequential()

model.add(layers.Input(shape=(2,2)))

model.add(layers.Flatten())

model.add(layers.Dense(24,activation=&quot;relu&quot;))
model.add(layers.Dense(24,activation=&quot;relu&quot;))

model.add(layers.Dense(actions,activation=&quot;linear&quot;))
return model

模型编译完美无缺。
为了训练代理，我使用以下内容：
import os
os.environ[&#39;TF_USE_LEGACY_KERAS&#39;] = &#39;1&#39;

from rl.agents import DQNAgent
from rl.policy import BoltzmannQPolicy
from rl.memory import SequentialMemory

def build_agent(model, action):
policy = BoltzmannQPolicy()
memory = SequentialMemory(limit=50000, window_length=1)
dqn = DQNAgent(
model=model, 
memory=memory, 
policy=policy, 
nb_actions=actions,
nb_steps_warmup=10, 
target_model_update=1e-2)
return dqn

dqn = build_agent(model, action)
dqn.compile(Adam(learning_rate=1e-3), metrics=[&#39;mae&#39;])

这也不会返回任何错误。
但是，当我尝试使用以下方法拟合模型时，会出现错误
dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)

它返回此错误：
-------------------------------------------------------------------------------
AssertionError Traceback (most recent call last)
Cell In[52], line 1
----&gt; 1 dqn.fit(env, nb_steps=50000, visualize=False, verbose=2)

文件 ~/.local/lib/python3.10/site-packages/rl/core.py:135，在 Agent.fit(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)
133 if self.processor is not None:
134 observer = self.processor.process_observation(observation)
--&gt; 135 assert observer is not None
137 # 在情节开始时执行随机开始，但不将它们记录到体验中。
138 # 这会稍微改变游戏之间的起始位置。
139 nb_random_start_steps = 0 if nb_max_start_steps == 0 else np.random.randint(nb_max_start_steps)

AssertionError: 

是的，断言确实是空的。
我尝试更新我使用的包，因为以前出现过这个问题，但似乎无法解决这个特定问题。我也不认为这是环境问题，因为只传递了元组，以前环境没有出现任何问题。]]></description>
      <guid>https://stackoverflow.com/questions/79051833/empty-assertion-error-when-trying-to-fit-dqn-model-in-tensorflow</guid>
      <pubDate>Thu, 03 Oct 2024 18:43:52 GMT</pubDate>
    </item>
    <item>
      <title>我有 3 列：Column1 需要最大化，Column 2 和 Column3 需要最小化。帮我用这三列建立一个目标列 [关闭]</title>
      <link>https://stackoverflow.com/questions/79051819/i-have-a-3-columns-column1-needs-to-be-maximized-column-2-and-column3-need-to</link>
      <description><![CDATA[我有 3 列：Column1 需要最大化，Column 2 和 Column3 需要最小化。请帮我用这三列构建一个目标列
我尝试过实现
我用来实现目标变量的公式
由于我想最小化 Column2 和 Column3，所以我取了它们的逆。这个想法是，Column2 和 Column3 的值越小，反转时比率就越大。
这通过奖励 Column1 的高值同时惩罚 Column2 和 Column3 的高值来实现（因为大值的逆会更小）。
寻找更好的目标综合。]]></description>
      <guid>https://stackoverflow.com/questions/79051819/i-have-a-3-columns-column1-needs-to-be-maximized-column-2-and-column3-need-to</guid>
      <pubDate>Thu, 03 Oct 2024 18:38:22 GMT</pubDate>
    </item>
    <item>
      <title>将物体检测 YOLOv8 与自动电磁阀解锁/锁定响应相连接 [关闭]</title>
      <link>https://stackoverflow.com/questions/79050772/connecting-object-detection-yolov8-with-automatic-solenoid-unlock-lock-response</link>
      <description><![CDATA[我正尝试使用基本机制（即 电磁阀锁 和解锁机制）对我的项目进行编码。一旦识别出物品，整个代码便可正常工作；我只想补充一点，当找到物品时，它会打印 // Bottle.identified... 此打印将在等待 5-8 秒后自动打开电磁阀。我正在尝试在 YouTube 上观看教程，但我想知道您是否有任何意见或好的建议。
import cv2
import surveillance as sv
from ultralytics import YOLO
import numpy as np

model = YOLO(&#39;yolov8n.pt&#39;)

bounding_box_annotator = sv.BoxAnnotator()
label_annotator = sv.LabelAnnotator()

cap = cv2.VideoCapture(0)

cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)

print(&quot;Camera initialized and ready.&quot;)

CONFIDENCE_THRESHOLD = 0.4

object_class_ids = [39, 44, 42, 41]

当 True 时：
ret, frame = cap.read()

if not ret:
print(&quot;无法捕获帧。退出。&quot;)
break

results = model.predict(frame)

detections = sv.Detections.from_ultralytics(results[0])

confidence_mask = detections.confidence &gt; CONFIDENCE_THRESHOLD
class_mask = np.isin(detections.class_id, object_class_ids)
filtered_mask = np.logical_and(confidence_mask, class_mask)
filtered_detections = detections[filtered_mask]

if len(filtered_detections) &gt; 0:
print(f&quot;过滤后的检测：{filtered_detections}&quot;)

annotated_image = bounding_box_annotator.annotate(scene=frame, detections=filtered_detections)
annotated_image = label_annotator.annotate(scene=annotated_image, detections=filtered_detections)
else:

annotated_image = frame

cv2.imshow(&#39;带有注释的相机供稿&#39;, annotated_image)

if cv2.waitKey(1) &amp; 0xFF == ord(&#39;q&#39;):
print(&quot;&#39;q&#39; 按下，正在关闭...&quot;)
break

cap.release()
cv2.destroyAllWindows()
]]></description>
      <guid>https://stackoverflow.com/questions/79050772/connecting-object-detection-yolov8-with-automatic-solenoid-unlock-lock-response</guid>
      <pubDate>Thu, 03 Oct 2024 13:34:25 GMT</pubDate>
    </item>
    <item>
      <title>GNU Octave 是多线程的吗？</title>
      <link>https://stackoverflow.com/questions/79050512/is-gnu-octave-multi-threaded</link>
      <description><![CDATA[根据这个老问题的答案，GNU Octave 似乎是一个单线程应用程序。
但是，我正在试验一个名为nnet的旧 Octave 神经网络包，并惊讶地发现我的 Octave 程序使用了笔记本电脑的所有 4 个核心。自从我链接的问题提出以来，情况有变化吗？GNU Octave 现在是多线程的吗？据我所知，我没有看到 nnet 内部有任何并行实现。
有关我的安装的一些信息：

我的操作系统是 Linux Mint 20
我的机器有 4 个处理单元（这是 nproc 在我的终端中显示的内容）
我的 Octave 版本是 5.2.0（如果这有区别的话，我正在使用 GUI）

我的代码相当简单，只导入了 nnet 包，没有其他内容。当我查看运行程序时的资源时，我看到所有核心都已使用（下面是 htop 屏幕截图）

这是我正在做的事情：
pkg load nnet

starttime = clock();

# 取自 http://matlab.izmiran.ru/help/toolbox/nnet/newff.html
Pr = -1:0.00005:1;
Tr = 3*sin(pi*Pr)-cos(pi*Pr);
Prmin = min(Pr);
Prmax = max(Pr);
net = newff([Prmin Prmax],[3 2 1],{&#39;tansig&#39;,&#39;logsig&#39;,&#39;purelin&#39;},&#39;trainlm&#39;);
[net] = train(net,Pr,Tr,[],[],[]);
[netoutput] = sim(net,Pr);

etime(clock(),starttime)

% 测试结果 
plot(Pr,Tr,&#39;b+&#39;);
hold on; 
plot(Pr,netoutput,&#39;r-&#39;);
hold off;
]]></description>
      <guid>https://stackoverflow.com/questions/79050512/is-gnu-octave-multi-threaded</guid>
      <pubDate>Thu, 03 Oct 2024 12:19:13 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：从“视频息肉分割：深度学习视角”复制代码时编译扩展对象时出错</title>
      <link>https://stackoverflow.com/questions/79049069/runtimeerror-error-compiling-objects-for-extension-when-copying-code-from-vide</link>
      <description><![CDATA[当我尝试从一篇名为“视频息肉分割：深度学习视角”的论文中复制代码并按照步骤“python setup.py build evolve”时，它总是提到“RuntimeError：编译扩展对象时出错”。还有很多错误：
回溯（最近一次调用最后一次）：
文件“/home/jinghong/VPS/lib/module/PNS/setup.py”，第 17 行，位于&lt;module&gt;
setup(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/__init__.py&quot;, 第 117 行, 在 setup 中
return distutils.core.setup(**attrs)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/core.py&quot;, 第 183 行, 在 setup 中
return run_commands(dist)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/core.py&quot;, 第 199 行, 在 run_commands 中
dist.run_commands()
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/dist.py&quot;, 第 954 行, 在 run_commands 中
self.run_command(cmd)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/dist.py&quot;, 第 950 行, 在 run_command 中
super().run_command(command)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/dist.py&quot;, 第 973 行, 在 run_command 中
cmd_obj.run()
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build.py&quot;，第 135 行，在 run_command 中
self.run_command(cmd_name)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/cmd.py&quot;，第 316 行，在 run_command 中
self.distribution.run_command(command)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/dist.py&quot;，第 950 行，在 run_command 中
super().run_command(command)
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/dist.py&quot;，第 973 行，在 run_command 中
cmd_obj.run()
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/command/build_ext.py&quot;，第 98 行，在 run 中
_build_ext.run(self)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;，第 359 行，在 run 中
self.build_extensions()
文件&quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;，第 709 行，位于 build_extensions
build_ext.build_extensions(self)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;，第 476 行，位于 build_extensions
self._build_extensions_serial()
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;，第 502 行，位于 _build_extensions_serial
self.build_extension(ext)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/command/build_ext.py&quot;, 第 263 行, 在 build_extension
_build_ext.build_extension(self, ext)
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/setuptools/_distutils/command/build_ext.py&quot;, 第 557 行, 在 build_extension
objects = self.compiler.compile(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;, 第 530 行, 在unix_wrap_ninja_compile
_write_ninja_file_and_compile_objects(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;, 行 1355, 位于 _write_ninja_file_and_compile_objects
_run_ninja_build(
文件 &quot;/home/jinghong/anaconda3/envs/PNS/lib/python3.9/site-packages/torch/utils/cpp_extension.py&quot;, 行 1682, 位于 _run_ninja_build
raise RuntimeError(message) from e
RuntimeError: 编译扩展对象时出错

我不知道如何解决这个问题，有人能帮我吗？]]></description>
      <guid>https://stackoverflow.com/questions/79049069/runtimeerror-error-compiling-objects-for-extension-when-copying-code-from-vide</guid>
      <pubDate>Thu, 03 Oct 2024 03:55:10 GMT</pubDate>
    </item>
    <item>
      <title>为什么 tf.keras.models.load_model 要重新构建模型？</title>
      <link>https://stackoverflow.com/questions/79047845/why-is-the-tf-keras-models-load-model-building-the-model-again</link>
      <description><![CDATA[ValueError: 顺序模型“sequential_2”已配置为使用
输入形状（None、224、224、3）。您无法使用 input_shape [None、224、224、3] 构建它

def load_model(model_path):
&quot;&quot;&quot;
从指定路径加载已保存的模型。
&quot;&quot;&quot;

tf.keras.config.enable_unsafe_deserialization()
print(f&quot;正在加载已保存的模型：{model_path}&quot;)
model = tf.keras.models.load_model(model_path)
return model

loaded_1000_image_model = load_model(&#39;/content/drive/MyDrive/Dog Vision/models/20241002-16491727887796-1000-images-mobilenetv2-Adam.h5&#39;)

我原本以为它会加载模型而不会出现任何错误，但由于某种原因，它给出了一个值错误，尽管我没有尝试重建或再次给出任何输入形状。]]></description>
      <guid>https://stackoverflow.com/questions/79047845/why-is-the-tf-keras-models-load-model-building-the-model-again</guid>
      <pubDate>Wed, 02 Oct 2024 17:18:38 GMT</pubDate>
    </item>
    <item>
      <title>创建 PartitionedDatasets 的 Kedro PartitionedDataset</title>
      <link>https://stackoverflow.com/questions/79044783/create-kedro-partitioneddataset-of-partitioneddatasets</link>
      <description><![CDATA[我正在做一个 kedro 项目，我想自动标记数千个音频文件，对它们进行转换，然后将它们存储在一个文件夹中，每个子文件夹对应一个标签。我希望该文件夹成为我的 yml 文件的目录条目
我遵循此 Kedro 教程并创建了我自己的自定义数据集，用于在 kedro 目录中保存/加载 .wav 文件。我还能够在 catalog.yml 中创建 PartitionedDataset  目录条目，例如
audio_folder:
type:partitions.PartitionedDataset
dataset:my_kedro_project.datasets.audio_dataset.SoundDataset
path:data/output/audios/
filename_suffix:&quot;.WAV&quot;

用于在 Kedro 目录中保存/加载 .WAV 文件的文件夹。
我需要的下一个抽象级别是能够创建一个与包含文件夹（例如上面的 audio_folder）相对应的目录条目。我不想通过动态创建目录条目来实现这一点，而是通过扩展 PartitionedDataset 类来实现。这是因为我希望文件夹的文件夹成为我的 catalog.yml 的一部分。我的问题是

这可能吗？你们有人尝试过这样的事情吗？
如果可能的话，我的自定义类应该只包含 _load、_save 和 _describe 方法，就像我在自定义 AbstractDataset 时一样？

编辑
我最终决定创建另一个扩展 AbstractDataset 的自定义类。以下是有关 _load 和 _save 方法的一些详细信息：
def _load(self):
subfolder_names=[ subfolder_name 
for subfolder_name in os.listdir(self._mainfolderpath) 
if os.path.isdir(os.path.join(self._mainfolderpath, subfolder_name)) 
]

wav_paths_dict={}
for subfolder_name in subfolder_names:
subfolder_path=os.path.join(self._mainfolderpath, subfolder_name)
wav_files=[]
for root, dirs, files in os.walk(subfolder_path):
for file in files:
if file.lower().endswith(&#39;.wav&#39;):
wav_file_path=os.path.join(root, file)
wav_file_name=os.path.split(wav_file_path)[-1].replace(&#39;.wav&#39;,&#39;&#39;).replace(&#39;.WAV&#39;,&#39;&#39;)
wav_files.append((wav_file_name,wav_file_path))
wav_paths_dict[subfolder_name]=dict(wav_files)

partitioned_dataset_dict={}
for subfolder_name, sub_dict in wav_paths_dict.items():
partitioned_dataset=[(wav_file_name,SoundDataset(wav_file_path).load()) for wav_file_name,wav_file_path in sub_dict.items()]
partitioned_dataset_dict[subfolder_name]=dict(partitioned_dataset)

return partitioned_dataset_dict

并且
def _save(self, subfolders_dictionary):
if os.path.isdir(self._mainfolderpath):
for root, dirs, files in os.walk(self._mainfolderpath,topdown=False):
for name in files:
os.remove(os.path.join(root, name))
for name in dirs:
os.rmdir(os.path.join(root, name))
os.rmdir(self._mainfolderpath)
os.mkdir(self._mainfolderpath)
for subfolder_name in subfolders_dictionary.keys():
subfolder_path=os.path.join(self._mainfolderpath, subfolder_name) 
os.mkdir(os.path.normpath(subfolder_path))

#print(subfolder_name, subfolder_path)
partitioned_dataset = PartitionedDataset(
path=subfolder_path,
dataset=SoundDataset,
filename_suffix=&quot;.WAV&quot;,
)

partitioned_dataset.save(subfolders_dictionary[subfolder_name])
]]></description>
      <guid>https://stackoverflow.com/questions/79044783/create-kedro-partitioneddataset-of-partitioneddatasets</guid>
      <pubDate>Tue, 01 Oct 2024 21:22:40 GMT</pubDate>
    </item>
    <item>
      <title>如何解决 torchmeta 冲突</title>
      <link>https://stackoverflow.com/questions/79034188/how-to-fix-torchmeta-conflicts</link>
      <description><![CDATA[尝试使用 google colab 安装“torchmeta”。但显示以下错误：
错误：无法安装 torchmeta==1.1.0、torchmeta==1.1.1、torchmeta==1.2.0、torchmeta==1.2.1、torchmeta==1.2.2、torchmeta==1.3.0、torchmeta==1.3.1、torchmeta==1.3.2、torchmeta==1.3.3、torchmeta==1.3.4、torchmeta==1.4.0、torchmeta==1.4.1、torchmeta==1.4.2、torchmeta==1.4.3、torchmeta==1.4.4、torchmeta==1.4.5、torchmeta==1.4.6， torchmeta==1.5.0、torchmeta==1.5.1、torchmeta==1.5.2、torchmeta==1.5.3、torchmeta==1.6.0、torchmeta==1.6.1、torchmeta==1.7.0 和 torchmeta==1.8.0，因为这些软件包版本存在依赖冲突。

冲突的原因是：
torchmeta 1.8.0 依赖于 torch&lt;1.10.0 和 &gt;=1.4.0
torchmeta 1.7.0 依赖于 torch&lt;1.9.0 和 &gt;=1.4.0
torchmeta 1.6.1 依赖于 torch&lt;1.8.0 和 &gt;=1.4.0
要解决此问题，您可以尝试：
1. 放宽您指定的软件包版本范围
2. 删除软件包版本以允许 pip 尝试解决依赖项冲突

我需要有人帮助我解决这个问题，我也尝试安装较低版本的 pytorch，但我不能，有什么方法可以安装 torchmeta，请等待详细答复。我使用的是 windows (google colab) Pytorch-geometric 2.3.1]]></description>
      <guid>https://stackoverflow.com/questions/79034188/how-to-fix-torchmeta-conflicts</guid>
      <pubDate>Sat, 28 Sep 2024 12:32:30 GMT</pubDate>
    </item>
    <item>
      <title>如何定义仅部分可训练的 PyTorch 张量</title>
      <link>https://stackoverflow.com/questions/77737016/how-to-define-pytorch-tensor-that-is-only-partially-trainable</link>
      <description><![CDATA[我正在尝试构建一个自定义模型来在 PyTorch 中训练，长话短说，我需要构建一个张量，其中除矩形次对角线块之外的所有元素都设置为零，至关重要的是，优化过程应该只触及这个次对角线块的元素，而所有零保持不变。为此，我定义了一个自定义 pytorch 网络，并使用 nn.Parameter 定义了我的矩形块
class My_Network(nn.Module):
def __init__(self , vertical_dim , Horizo​​ntal_dim):
super().__init__()
self.total_dim = vertical_dim + Horizo​​ntal_dim
self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , Horizo​​ntal_dim))


这样，如果我错了，请纠正我，PyTorch 应该用随机值初始化这个张量的值，并将它们注册为训练期间要优化的模型的参数。但是现在我陷入了困境，我想告诉 PyTorch 构建一个方阵张量，其维度等于 self.total_dim，除了次对角线块之外，其余均为零，正如我在计算中所说，我将在前向方法中定义 pytorch 应该只训练次对角线块。
我可以根据需要添加零张量，而无需将其设置为模型参数，如下所示（如果我没记错的话）：
class My_Network(nn.Module):
def __init__(self , vertical_dim , Horizo​​ntal_dim):
super().__init__()
self.total_dim = vertical_dim + Horizo​​ntal_dim
self.subdiagonal_block = nn.Parameter(torch.rand(vertical_dim , Horizo​​ntal_dim))
self.total_zero_tensor = torch.zeros(self.total_dim, self.total_dim)


但是现在我该如何告诉 PyTorch 将我的下对角线块插入这个零矩阵的左下角？我需要定义这个矩阵以便进行计算（我需要执行矩阵乘法），但至关重要的是，只有小的下对角线块才被视为一组要训练的参数。]]></description>
      <guid>https://stackoverflow.com/questions/77737016/how-to-define-pytorch-tensor-that-is-only-partially-trainable</guid>
      <pubDate>Sat, 30 Dec 2023 18:32:49 GMT</pubDate>
    </item>
    <item>
      <title>文件名中的键值对是否有标准的文件命名约定？[关闭]</title>
      <link>https://stackoverflow.com/questions/10087079/is-there-a-standard-file-naming-convention-for-key-value-pairs-in-filename</link>
      <description><![CDATA[我有多个以它们所包含的内容命名的数据文件。例如
machine-testM_pid-1234_key1-value1.log

键和值由 - 和 _ 分隔。有没有更好的语法？有没有自动读取这些文件/文件名的解析器？
这里的想法是文件名是人类和机器可读的。]]></description>
      <guid>https://stackoverflow.com/questions/10087079/is-there-a-standard-file-naming-convention-for-key-value-pairs-in-filename</guid>
      <pubDate>Tue, 10 Apr 2012 10:32:32 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的学习曲线是什么？</title>
      <link>https://stackoverflow.com/questions/4617365/what-is-a-learning-curve-in-machine-learning</link>
      <description><![CDATA[我想知道机器学习中的学习曲线是什么。绘制它的标准方法是什么？我的意思是我的图的 x 轴和 y 轴应该是什么？]]></description>
      <guid>https://stackoverflow.com/questions/4617365/what-is-a-learning-curve-in-machine-learning</guid>
      <pubDate>Thu, 06 Jan 2011 16:48:44 GMT</pubDate>
    </item>
    </channel>
</rss>