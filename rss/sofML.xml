<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Tue, 18 Feb 2025 18:23:43 GMT</lastBuildDate>
    <item>
      <title>推荐系统中的可伸缩性问题</title>
      <link>https://stackoverflow.com/questions/79449194/scalability-issue-in-recommender-system</link>
      <description><![CDATA[我是推荐系统的新手，目前我正在建立一个基于协作过滤的建议系统。在我的数据集中，当前有600个用户和9000个项目具有不同的评分。我已经创建了一个用户项目交互矩阵，并且正在使用Numpy进行所有操作。我正在使用Pearson相关系数作为与每个用户相对的顶级K相似用户的方法。我当前找到有关每个目标用户最相似的用户的当前代码具有O（m^2  n）的时间复杂性和O（m  n）的空间复杂性，其中m是用户和n是项目的数量。
考虑到这段时间的复杂性，对于大量用户来说，这是不可行的。在研究后，我发现降低尺寸可能是一种解决方案。但是我担心的是，如果我减少用户数量，那么整个系统将无法为建议部分做出公正的态度，因为我想为每个用户推荐。
那么，优化的不同方法是什么，以便在缩放缩放的情况下有助于？]]></description>
      <guid>https://stackoverflow.com/questions/79449194/scalability-issue-in-recommender-system</guid>
      <pubDate>Tue, 18 Feb 2025 17:52:29 GMT</pubDate>
    </item>
    <item>
      <title>minibatchkmeans bertopic不返回一半数据的主题</title>
      <link>https://stackoverflow.com/questions/79449168/minibatchkmeans-bertopic-not-returning-topics-for-half-of-data</link>
      <description><![CDATA[我正在尝试将推文数据集主题。我有大约5000万条推文。不幸的是，由于嵌入，如此大的数据集将不适合RAM（甚至128GB）。因此，我一直在努力根据 docs  docs  &gt; 
因此：
 来自bertopic.vectorizer inlinecountvectorizer inlinecountvectorizer
从bertopic.Dectorizer导入ClasStFidFtransFormer
来自Sklearn.Cluster Import Minibatchkmeans
导入numpy作为NP


class safeincrementalpca（regementalpca）：
    def partial_fit（self，x，y = none）：
        ＃确保输入是连续的，并且在float64中
        x = np.sascontiguularray（x，dtype = np.float64）
        返回super（）。partial_fit（x，y）
    
    def变换（self，x）：
        结果= super（）。变换（x）
        ＃强制输出为float64并连续
        返回np.sascontiguularray（结果，dtype = np.float64）


vectorizer_model = onlinecountVectorizer（stop_words =;英语）
ctfidf_model = classtfidftransformer（redy_frequent_words = true，bm25_weighting = true）
umap_model = safeincrementalpca（n_components = 100）
cluster_model = minibatchkmeans（n_clusters = 1000，andural_state = 0）

来自伯托进口的伯托

topic_model = bertopic（umap_model = umap_model，
                       hdbscan_model = cluster_model，

对于docs_delayed，emb_delayed in tqdm（zip（docs_partitions，embeddings_partitions），total = len（docs_partitions））：

    docs_pdf = docs_delayed.compute（）
    emb_pdf = emb_delayed.compute（）

    docs = docs_pdf [&#39;text;]。tolist（）
    embeddings = np.vstack（emb_pdf [&#39;embeddings&#39;]。tolist（））
    
    ＃部分适合您的模型（确保您的模型像许多Scikit-Learn估计器一样支持Partial_fit）
    topic_model.partial_fit（文档，嵌入）

 
然后将数据集转换为SQL数据库：
 
对于docs_delayed，emb_delayed in tqdm（zip（docs_partitions，embeddings_partitions），total = len（docs_partitions））：

    docs_pdf = docs_delayed.compute（）
    emb_pdf = emb_delayed.compute（）
    docs = docs_pdf [&#39;text;]。tolist（）
    embeddings = np.vstack（emb_pdf [&#39;embeddings&#39;]。tolist（））

    ＃3）在此碎片上涂抹伯托
    主题，probs = topic_model.transform（文档，嵌入）

    ＃将主题保存到数据框
    df_topics = pd.dataframe（{{
        ＆quot&#39;tweet_id＆quot;：docs_pdf [;
        主题“：主题，
        概率＆quot：概率
    }））

    ## Merge＆amp;存储在DB中
    docs_pdf [主题;] = df_topics [tope;
    docs_pdf [概率＆quot＆quort＆quort＆quotisy = df_topics [＆quot&#39;概率;]
    docs_pdf.to_sql（“ tweets”;引擎，发动机，if_exists =＆quot&#39;append＆quort; quot; index = false）
 
我已经尝试这样做了一段时间，这是我得到的最接近的示例。唯一的问题是，数据集的一半在末尾数据库中具有零主题。从我对理论的了解来看，Minibatchkmeans不应有任何异常值，因此所有推文应至少分配给至少一个主题，对吗？我已经检查了有关的未分类推文，他们的文档中没有任何内容表明很难对其进行分类（相对于其他分类）。
我很高兴听到有关可能出了什么问题以及如何解决此问题的任何建议！
谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/79449168/minibatchkmeans-bertopic-not-returning-topics-for-half-of-data</guid>
      <pubDate>Tue, 18 Feb 2025 17:42:59 GMT</pubDate>
    </item>
    <item>
      <title>为什么在训练LSTM模型时面对“ CUDA错误：设备端断言触发”？</title>
      <link>https://stackoverflow.com/questions/79448910/why-facing-cuda-error-device-side-assert-triggered-while-training-lstm-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79448910/why-facing-cuda-error-device-side-assert-triggered-while-training-lstm-model</guid>
      <pubDate>Tue, 18 Feb 2025 16:05:55 GMT</pubDate>
    </item>
    <item>
      <title>Qiskit Importerror</title>
      <link>https://stackoverflow.com/questions/79448915/qiskit-importerror</link>
      <description><![CDATA[我试图使用以下内容导入量子级：
 来自qiskit_machine_learning.kernels导入量子kernel
 
但是我遇到了这个错误：
 来自qiskit_machine_learning.kernels导入量子kernel
Importerror：无法从&#39;qiskit_machine_learning.kernels&#39;导入名称&#39;量子kernel&#39; 
（c：\ user \ pshre \ appdata \ local \ program \ python \ python \ python310 \ lib \ site-packages \ qiskit_machine_learning \ kernels \ kernels \ __ init__ init__.py）
 
 qiskit版本：0.8.2 
我已经更新了模块：
  pip安装 - 升级qiskit-machine学习
 ]]></description>
      <guid>https://stackoverflow.com/questions/79448915/qiskit-importerror</guid>
      <pubDate>Tue, 18 Feb 2025 16:05:55 GMT</pubDate>
    </item>
    <item>
      <title>OPENCV：从图像分割/提取打印机标签</title>
      <link>https://stackoverflow.com/questions/79448585/opencv-segmenting-extracting-printer-labels-from-image</link>
      <description><![CDATA[我有来自打印机的标签的镜头。 这是录像中的框架。
我想从框架中提取单个标签（即检测每个单独标签的边界）。
我最初尝试与一些形态学操作一起尝试轮廓检测，但是标签内的印刷内容（矩形和数字）正在干扰边缘检测，因此很难仅隔离标签边框。 
有人解决了类似问题吗？哪些预处理技术或替代方法最适合仅可靠地分割标签边缘？]]></description>
      <guid>https://stackoverflow.com/questions/79448585/opencv-segmenting-extracting-printer-labels-from-image</guid>
      <pubDate>Tue, 18 Feb 2025 14:26:06 GMT</pubDate>
    </item>
    <item>
      <title>这两个实现洛拉（低级适应）之间有什么区别吗？</title>
      <link>https://stackoverflow.com/questions/79447495/is-there-any-difference-between-these-two-implementations-of-lora-low-rank-adap</link>
      <description><![CDATA[我们都知道洛拉是一种低级适应方法，可以表达如下：x = w_0 * x +（a @ b） * x。我有两个不同的代码实现。它们之间有什么区别吗？
代码1：
  def向前（self，x）：
    x = x @ self.lora_a
    x = x @ self.lora_b
    x = self.scaling * x
    返回x
 
代码2：
  def向前（self，x）：
    x = x @（self.lora_a @ self.lora_b）
    x = self.scaling * x
    返回x
 
从数学角度来看，两者均似乎是等效的。但是，当我在玩具数据集上运行两个实现时，我观察到它们的性能有很小的差异 - 编码2的性能稍好。
为什么会发生这种轻微的差异？是否有基本的计算或优化细微差别可以解释这一点？
我不完全确定两个实现是否正确。我经常在GitHub存储库中看到代码1，但是我注意到代码2的性能稍好一些。为什么可能是这种情况？]]></description>
      <guid>https://stackoverflow.com/questions/79447495/is-there-any-difference-between-these-two-implementations-of-lora-low-rank-adap</guid>
      <pubDate>Tue, 18 Feb 2025 07:56:56 GMT</pubDate>
    </item>
    <item>
      <title>寻求2到3D超声重建的开源数据集[封闭]</title>
      <link>https://stackoverflow.com/questions/79446055/seeking-open-source-datasets-for-2d-to-3d-ultrasound-reconstruction</link>
      <description><![CDATA[我目前正在研究一个专注于将2D超声图像转换为3D型号的项目。要培训我的AI模型，我正在寻找专门为2到3D超声重建设计的开源数据集。
您知道可用于此目的的任何公开可用数据集吗？如果没有，我将非常感谢有关工具，资源或方法的任何建议，这些建议可以帮助我为此任务创建自己的数据集。
I checked out this ResearchGate link, but I couldn&#39;t find a way下载数据集。]]></description>
      <guid>https://stackoverflow.com/questions/79446055/seeking-open-source-datasets-for-2d-to-3d-ultrasound-reconstruction</guid>
      <pubDate>Mon, 17 Feb 2025 16:37:20 GMT</pubDate>
    </item>
    <item>
      <title>转换型号。</title>
      <link>https://stackoverflow.com/questions/79446020/convert-model-safetensors-in-onnx</link>
      <description><![CDATA[我已经从v1-5-pruned-emeonly.safetensors模型中创建了一个使用kohya的自定义模型，现在想将此模型导入C＃应用程序。我读到我可以使用ONNX来执行此操作，但我被卡在加载型号的权重。代码如下
 从扩散器导入StablediffusionPipeline
导入火炬
从SafetEnsors进口Safe_open

model_path =＆quot&#39;runwayml/stable-diffusion-v1-5＆quot;
pipe = stablediffusionpipeline.from_pretrataining（model_path，torch_dtype = torch.float16）

lora_path =＆quot; p718_long_crack_v1.safetensors;

pipe.unet.load_attn_procs（lora_path）

pipe.to（“ cuda”

unet = pipe.unet
 
产生以下错误
 加载管道组件...：100％|██████████| 7/7 [00：01＆lt; 00：00，4.75it/s]
d：\ onnx \ venv \ lib \ site-packages \ diffusers \ loaders \ loaders \ unet.py：212：future warnning：`load_attn_procs`被弃用，将在版本0.40.0中删除。使用`load_attn_procs（）`方法已被弃用，并将在将来的版本中删除。请使用`load_lora_adapter（）`。
  dobecate（&#39;load_attn_procs; quot；＆quot＆quot; quot; quot;
Trackback（最近的最新电话）：
  file＆quort＆quot d：\ onnx \ converter.py”，第11行，in＆lt; module＆gt;
    pipe.unet.load_attn_procs（lora_path）
  file＆quot＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ huggingface_hub \ utils \ _validators.py＆quort＆quort＆quort＆quort＆quort＆quort＆quort in _inner_fn in _inner_fn
    返回fn（*args，** kwargs）
  file＆quot＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ diffusers \ loaders \ loaders \ unet.py;
    is_model_cpu_offload，is_sequential_cpu_offload = self._process_lora（
  file＆quort＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ diffusers \ loaders \ loaders \ unet.py;
    lora_config_kwargs = get_peft_kwargs（rank，network_alphas，state_dict，is_unet = true）
  file＆quot＆quot d：\ onnx \ venv \ lib \ lib \ site-packages \ diffusers \ utils \ peft_utils.py＆quot＆quort＆quort＆quort＆quort＆quort 153，在get_peft_kwargs中
    r = lora_alpha = list（rank_dict.values（））[0]
indexError：列表索引以外
 
我正在接受错误的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79446020/convert-model-safetensors-in-onnx</guid>
      <pubDate>Mon, 17 Feb 2025 16:23:26 GMT</pubDate>
    </item>
    <item>
      <title>如何对混合VAR-LSTM模型执行样本外预测？</title>
      <link>https://stackoverflow.com/questions/79445942/how-to-perform-out-of-sample-forecast-for-a-hybrid-var-lstm-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79445942/how-to-perform-out-of-sample-forecast-for-a-hybrid-var-lstm-model</guid>
      <pubDate>Mon, 17 Feb 2025 15:56:31 GMT</pubDate>
    </item>
    <item>
      <title>如何在不同的数据范围内训练Sklearn模型？</title>
      <link>https://stackoverflow.com/questions/79439462/how-to-train-sklearn-model-in-different-dataframes</link>
      <description><![CDATA[我有一个用“ knn”制作的ML模型在Scikit-Learn中，注意到我的数据越多，我的模型就会越准确地说服它的预测。问题是，我有很多数据框架显示了我想预测的同一系统的不同情况。是否可以在那些不同的数据范围内训练模型？因为如果我致电.fit（），则将重置它是以前的培训。
  x_cleaned = x.dropna（）
y_cleaned = y [x_cleaned.index]
x_training，x_test，y_training，y_test = train_test_split（x_cleaned，y__cleaned，test_size = 0.15，Random_State = 0）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79439462/how-to-train-sklearn-model-in-different-dataframes</guid>
      <pubDate>Fri, 14 Feb 2025 13:01:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么2048年游戏训练对我来说不正常？</title>
      <link>https://stackoverflow.com/questions/79411336/why-is-training-for-the-game-2048-not-working-well-for-me</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79411336/why-is-training-for-the-game-2048-not-working-well-for-me</guid>
      <pubDate>Tue, 04 Feb 2025 10:28:14 GMT</pubDate>
    </item>
    <item>
      <title>培训LLM在图数据库中用于查询生成的LLM</title>
      <link>https://stackoverflow.com/questions/77613507/training-llm-for-query-generation-in-a-graph-database</link>
      <description><![CDATA[如果我已经开发了一个具有自己的查询语言的图形数据库。我必须找到一种方法来馈送图形，然后LLM应该能够生成我们数据库的查询。
我在Langchain中发现了类似的东西，我们可以将其喂入RDF文件，然后将生成Sparql查询。
所以我对此有很多疑问，因为我非常陌生：
是否可以像我们的数据库那样培训LLM上的全新技术。如果可能的话，那么如何。
我知道我们必须向LLM提供培训数据。因此，在这种情况下，将是我们数据库查询的数据集。如果是，那么我们必须在数据集中提供多少查询。
对不起，如果没有详细详细介绍，这只是我第二次在这里问。]]></description>
      <guid>https://stackoverflow.com/questions/77613507/training-llm-for-query-generation-in-a-graph-database</guid>
      <pubDate>Wed, 06 Dec 2023 13:34:06 GMT</pubDate>
    </item>
    <item>
      <title>预测后解开数据麻烦</title>
      <link>https://stackoverflow.com/questions/76020437/trouble-unscaling-data-after-predictions</link>
      <description><![CDATA[我正在研究一个项目，我正在尝试预测1970年至2022年的MLB播放器统计数据。我有2个数据集，一个用于击球手，我预测5个具有20个功能的统计数据，另一个用于投手，我可以预测。 6个具有25个功能的统计数据。我目前正在研究决策树模型，但也计划使用线性回归和LSTM模型。
在最初缩放数据集之前，我删除了我使用的字符串列，年度和列来比较结果。
  remove_bat_cols = [&#39;name&#39;，&#39;tm&#39;，&#39;年&#39;，&#39;nxt_ba&#39;，&#39;nxt_rbi&#39;，&#39;nxt_hr&#39;，&#39;nxt_bb&#39;，&#39;nxt_bb&#39;，&#39;nxt_so&#39;]
remove_pitch_cols = [&#39;name&#39;，&#39;tm&#39;，&#39;年&#39;，&#39;nxt_era&#39;，&#39;nxt_so&#39;，&#39;nxt_whip&#39;，&#39;nxt_bb&#39;，&#39;nxt_w&#39;，&#39;nxt_w&#39;，&#39;nxt_sv&#39;]

BAT_COLS =击球。
pitch_cols =俯仰。
 
我然后缩放了我的数据
  sualer = minmaxscaler（）
thatting.loc [：，bat_cols] = scaler.fit_transform（击球[BAT_COLS]）
pitching.loc [：,, pitch_cols] = scaler.fit_transform（pitching [pitch_cols]）
 
我最初试图将步骤扭转为解开
  thatting.loc [：，bat_cols] = scaler.inverse_transform（击球[bat_cols]）
pitching.loc [：,, pitch_cols] = scaleer.inverse_transform（pitching [pitch_cols]）
 
但我收到以下错误：
  valueerror：操作数无法与形状一起播放（26768,29）（31，）（26768,29） 
 
我还尝试添加预测的列，甚至仅尝试过预测的列并接收相同的列。]]></description>
      <guid>https://stackoverflow.com/questions/76020437/trouble-unscaling-data-after-predictions</guid>
      <pubDate>Sat, 15 Apr 2023 05:00:54 GMT</pubDate>
    </item>
    <item>
      <title>Azure机器学习</title>
      <link>https://stackoverflow.com/questions/70853882/azure-machine-learning</link>
      <description><![CDATA[我可以在Azure中创建机器学习工作区，因为我不能选择一个区域。
你能帮我吗？
 错误  ]]></description>
      <guid>https://stackoverflow.com/questions/70853882/azure-machine-learning</guid>
      <pubDate>Tue, 25 Jan 2022 18:32:29 GMT</pubDate>
    </item>
    <item>
      <title>tensorflow.js的最佳模型类型用于颜色预测？</title>
      <link>https://stackoverflow.com/questions/53416245/best-model-type-in-tensorflow-js-for-color-prediction</link>
      <description><![CDATA[我意识到出现问题时，我正在创建一个颜色预测因子。我让模型成功地工作，但是预测总是在约2.5至5.5的同一中值范围内。该模型应该输出与每种颜色相对应的0到达8，并且每种颜色的数据点均匀量。是否可以使用更好的模型，以便它可以预测某些内容为0或7？我认为不会，因为它认为他们是某种异常值。
这是我的模型
  const Model = tf.sequenenty（）;

const hidden = tf.layers.dense（{{
  单位：3，
  INPUTSHAPE：[3] //每个输入具有3个值R，G和B
}）;
const output = tf.layers.dense（{{
  单位：1 //只有一个输出（与RGB值相对应的颜色
    }）;
model.Add（隐藏）;
model.Add（输出）;

model.compile（{
  激活：“ Sigmoid”，
  损失：“ MeansquaredError”，
  优化器：tf.train.sgd（0.005）
}）;
 
这是我问题的好模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/53416245/best-model-type-in-tensorflow-js-for-color-prediction</guid>
      <pubDate>Wed, 21 Nov 2018 16:14:03 GMT</pubDate>
    </item>
    </channel>
</rss>