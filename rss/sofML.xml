<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 30 Nov 2023 06:18:20 GMT</lastBuildDate>
    <item>
      <title>尝试通过函数添加列时出错</title>
      <link>https://stackoverflow.com/questions/77575878/error-in-trying-to-add-a-column-via-a-function</link>
      <description><![CDATA[所以我正在尝试使用决策树的学生成绩预测数据集来练习我的技能。我试图根据最后 3 列（G1、G2、G3）的平均值来预测通过/失败，其中高于最高分数 (20) 70% 的任何内容都是通过，否则，学生会失败。
代码如下：
def Define_grade(df):
    # 创建一个列表来存储数据
    等级=[]

    # 对于列中的每一行，
    对于 df[&#39;Gave&#39;] 中的行：
        如果行 &gt;= (0.7 * df[&#39;Gave&#39;].max()):
            Grade.append(“通过”)
        否则：grade.append(“失败”)
    # 从列表中创建一列
    df[&#39;成绩&#39;] = 成绩
df.head()

我运行了一下，没有发现错误。然而，每次我检查时，我期待的新列“等级”都不会出现。请帮助我
谢谢
我复制了对数据集发表评论的人的代码，就像他们之前所做的那样。我稍微更改了代码以适应我所做的事情。然而，我没有成功。请帮忙。
示例代码链接如下
https://www.kaggle.com/code /samuelmjoseph/student-grade-prediction-using-decisiontree]]></description>
      <guid>https://stackoverflow.com/questions/77575878/error-in-trying-to-add-a-column-via-a-function</guid>
      <pubDate>Thu, 30 Nov 2023 04:23:57 GMT</pubDate>
    </item>
    <item>
      <title>如何使用同一台计算机为多个用户高效加载深度学习模型</title>
      <link>https://stackoverflow.com/questions/77575664/how-to-efficiently-load-deep-learning-model-for-multiple-users-using-the-same-co</link>
      <description><![CDATA[我正在制作一个使用多个深度学习模型的简单软件。该软件安装在计算机上。并且有多个用户同时使用该软件（使用远程桌面连接）。
我认为如果每个用户单独加载模型，将会出现内存不足的问题。
在这种情况下加载模型的最佳方法是什么？我们可以加载模型一次，然后让每个用户都访问同一个加载的模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/77575664/how-to-efficiently-load-deep-learning-model-for-multiple-users-using-the-same-co</guid>
      <pubDate>Thu, 30 Nov 2023 03:12:24 GMT</pubDate>
    </item>
    <item>
      <title>修改来自google的ml教程代码没有给出预期的结果</title>
      <link>https://stackoverflow.com/questions/77575529/modifying-ml-tutorial-code-from-google-does-not-give-expected-result</link>
      <description><![CDATA[有一个很好的使用tensorflow lib的ml python代码的迷你示例。
Google 代码实验室教程
它（正确地）从线性方程预测一个数字。但仅仅制作一个小模型来训练模型并预测二次函数就会得到完全错误的结果。
导入tensorflow为tf
将 numpy 导入为 np
从张量流导入keras

模型 = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])
model.compile(optimizer=&#39;sgd&#39;, loss=&#39;mean_squared_error&#39;)

# 从原始教程修改 -&gt; y = 2x^2-1
xs = np.array([-3.0, -2.0, -1.0, 0.0, 2.0, 3.0, 4.0, 5.0], dtype=float)
ys = np.array([ 17.0, 7.0, 1.0, -1.0, 7.0, 17.0, 31.0, 49.0], dtype=float)

model.fit(xs, ys, epochs=5000)

打印（模型.预测（[1.0]））

给出结果：
&lt;前&gt;&lt;代码&gt;&gt;&gt;&gt;打印（模型.预测（[1.0]））
1/1 [================================] - 0s 84ms/步
[[15.999977]]
&gt;&gt;&gt;&gt;&gt;

我本来预计大约。 1.0。
不知道出了什么问题。]]></description>
      <guid>https://stackoverflow.com/questions/77575529/modifying-ml-tutorial-code-from-google-does-not-give-expected-result</guid>
      <pubDate>Thu, 30 Nov 2023 02:28:17 GMT</pubDate>
    </item>
    <item>
      <title>OpenAi 从我的应用程序中检索数据</title>
      <link>https://stackoverflow.com/questions/77575498/openai-to-retive-data-from-my-application</link>
      <description><![CDATA[我管理一个包含数千个商机、客户、联系人等的 CRM 应用程序。我正在寻求实现类似聊天的功能，允许用户提出问题并从存储的记录中检索数据。例如，他们可以查询价值超过 10,000 美元的机会。
最初，我探索使用 NLP to SQL 方法。我向 OpenAI 提供了我的表结构和用户提示，执行生成的 SQL 查询产生了准确的结果。然而，正如在各种实例中所观察到的那样，仅仅依靠 OpenAI 生成 SQL 会带来安全风险。
我正在探索替代方法。一种想法是为特定任务创建专用 API，然后使用 OpenAI 对其进行训练。这看起来是一个可行的解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/77575498/openai-to-retive-data-from-my-application</guid>
      <pubDate>Thu, 30 Nov 2023 02:19:04 GMT</pubDate>
    </item>
    <item>
      <title>遇到影响 GPT 代码存储库的问题</title>
      <link>https://stackoverflow.com/questions/77574375/running-into-issues-with-affect-gpts-code-repo</link>
      <description><![CDATA[我本质上正在阅读这篇论文，并想运行他们的代码，但目前无法，
有人可以向我提供运行其代码所需的看似简短的 google collab 脚本吗？
https://github.com/zeroQiaoba/AffectGPT
我尝试运行它，但遇到了一些问题，例如 app.py 未运行]]></description>
      <guid>https://stackoverflow.com/questions/77574375/running-into-issues-with-affect-gpts-code-repo</guid>
      <pubDate>Wed, 29 Nov 2023 20:42:13 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用哪种机器学习模型来检测奶酪中的孔洞数量？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77573916/which-ml-model-should-i-use-for-detecting-number-of-holes-in-cheese</link>
      <description><![CDATA[我有一堆奶酪图像，我需要一种算法来计算奶酪上有多少个洞。我过去做过一些愿景项目，但这肯定不是我的强项。谁能给我一些入门建议？这可能是一种监督学习，因为我应该事先知道孔的数量，但为了以防万一，请随意建议一种无监督方法。]]></description>
      <guid>https://stackoverflow.com/questions/77573916/which-ml-model-should-i-use-for-detecting-number-of-holes-in-cheese</guid>
      <pubDate>Wed, 29 Nov 2023 19:09:09 GMT</pubDate>
    </item>
    <item>
      <title>如何在 SKLearn Estimator 上使用 Sagemaker HyperparameterTuner？</title>
      <link>https://stackoverflow.com/questions/77573670/how-do-i-use-sagemaker-hyperparametertuner-on-a-sklearn-estimator</link>
      <description><![CDATA[我正在关注 Amazon Sagemaker 研讨会尝试利用 Sagemaker 的多个实用程序，而不是像我目前所做的那样在笔记本上运行所有内容。
问题是，在研讨会上，他们教您如何使用来自 AWS 的现成 XGBoost 图像来使用 HyperparameterTuner，而我的大多数管道都使用 Scikit-Learn 模型，例如 GradientBoostingClassifier 或 RandomForest，因此我实例化了一个估计器如下此示例文件：
sklearn = SKLearn(entry_point=&quot;train.py&quot;,
                  Framework_version =“1.2-1”，
                  instance_type=“ml.m5.xlarge”，
                  角色=角色，
                  超参数=fixed_hyperparameters
）

之后，我使用刚刚创建的估计器实例化一个 HyperparameterTuner 作业，其中包含我想要测试的超参数范围。
hyperparameters_ranges = {
    “n_estimators”: ContinuousParameter(100, 500),
    “学习率”：连续参数（1e-2，1e-1），
    “最大深度”：IntegerParameter(2, 5),
    “子样本”：连续参数（0.6，1），
    “max_df”：连续参数（0.4，1），
    “max_features”：IntegerParameter(5, 25),
    “use_idf”：CategoricalParameter([True, False])
}

度量=“验证：f1”

调谐器 = 超参数调谐器(
    sklearn,
    公制，
    超参数范围，
    最大作业数=2,
    最大并行作业数=2
）

我的问题是，我没有找到任何有关如何访问“train.py”内部 SKLearn 估计器中传递的超参数的信息。文件。我也没有找到最佳超参数存储在哪里，因此我可以将它们用于最终模型。有人可以告诉我这是否可能吗？或者如果有另一种更简单的方法可以提供替代方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/77573670/how-do-i-use-sagemaker-hyperparametertuner-on-a-sklearn-estimator</guid>
      <pubDate>Wed, 29 Nov 2023 18:27:13 GMT</pubDate>
    </item>
    <item>
      <title>应该支持数组（不仅仅是类似列表）输入的评分规则的分解，但会给出错误</title>
      <link>https://stackoverflow.com/questions/77573489/decomposition-of-scoring-rule-for-array-not-just-list-like-inputs-should-be-su</link>
      <description><![CDATA[我已经获得了 model_diagnostics.scoring 函数 decompose 来处理类似列表的输入，例如文档中的示例。
from model_diagnostics.scoring import SquaredError，分解
将 numpy 导入为 np
将 pandas 导入为 pd
se = 平方误差()
y_true = [0, 0, 0, 1, 1, 1]
y_pred = [0.1, 0.4, 0.3, 0.3, 0.99, 0.9]
分解（y_true，y_pred，评分函数= se）

在特定的上下文中，我们可以将这种分解视为给出与统计中感兴趣的 Brier 分数相关的各种度量。然而，Brier 分数对于比较类别数组（矩阵）和类别概率数组的矩阵（多类或多标签问题）有意义，我也对这种设置中的分解感兴趣。但是，decompose 函数并未按其应有的方式工作。
from model_diagnostics.scoring import SquaredError，分解
将 numpy 导入为 np
将 pandas 导入为 pd
np.随机.种子(2023)
se = 平方误差()
y_true = np.random.multinomial(1, np.ones(3)/3, 10)
y_pred = np.random.dirichlet(np.ones(3), 10)
分解（y_true，y_pred，评分函数= se）
分解（y_true.T，y_pred.T，scoring_function = se）
分解（y_true.T，y_pred，scoring_function = se）
分解（y_true，y_pred.T，scoring_function = se）

使用 decompose 的前两次尝试失败，并出现 具有多个元素的数组的真值不明确。使用 a.any() 或 a.all() 错误消息。 （最后两个也失败了，尽管它们只是我半绝望地尝试让它工作，但我知道会失败。）
但是，decompose 的文档提到输入可以是类似数组的，所以我似乎想做一些文档说支持的事情。是什么赋予了？如何使用数组？]]></description>
      <guid>https://stackoverflow.com/questions/77573489/decomposition-of-scoring-rule-for-array-not-just-list-like-inputs-should-be-su</guid>
      <pubDate>Wed, 29 Nov 2023 17:54:48 GMT</pubDate>
    </item>
    <item>
      <title>pandas 中的 read_parquet 和 read_table 有什么区别？</title>
      <link>https://stackoverflow.com/questions/77572902/whats-the-difference-between-read-parquet-and-read-table-in-pandas</link>
      <description><![CDATA[我在尝试读取镶木地板文件时遇到了挑战。最初，我怀疑该文件可能已损坏。然而，改变读取方法后，文件被成功处理。这个解决方案花了相当长的时间才确定，主要是因为我在机器学习领域相对缺乏经验。
这些方法有什么区别？为什么第一种方法给我一个损坏的文件？
正在工作
data = pd.read_parquet(&#39;data.parquet&#39;,engine=&#39;fastparquet&#39;)

无法正常工作，文件损坏并抛出异常 utf-8，我们尝试在记事本中修复
data = pq.read_table(&#39;data.parquet&#39;)
df = data.to_pandas()
]]></description>
      <guid>https://stackoverflow.com/questions/77572902/whats-the-difference-between-read-parquet-and-read-table-in-pandas</guid>
      <pubDate>Wed, 29 Nov 2023 16:24:05 GMT</pubDate>
    </item>
    <item>
      <title>神经网络中用 Transformer 替代 LSTM</title>
      <link>https://stackoverflow.com/questions/77570734/replace-lstm-with-transformer-in-neural-network</link>
      <description><![CDATA[我正在尝试在汽车行车记录仪视频中实现事故预期模型（Anticipating-Accidents）。我的目标是用 Transformer 替换原始项目中使用的 LSTM 并比较结果。使用 Tensorflow 2 可行吗？我做了一些研究，但我不确定这种变化会对代码结构和模型逻辑产生多大影响。如果有人有任何建议，我们将非常感谢任何帮助。到目前为止，我刚刚做了一些小的调整，使代码可以与 Tensorflow 2 和 Python 3 一起使用，因为原始代码已经过时了（你可以找到我的分叉存储库 此处）。]]></description>
      <guid>https://stackoverflow.com/questions/77570734/replace-lstm-with-transformer-in-neural-network</guid>
      <pubDate>Wed, 29 Nov 2023 11:26:12 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的线性回归实现不起作用？</title>
      <link>https://stackoverflow.com/questions/77569740/why-is-my-implementation-of-linear-regression-not-working</link>
      <description><![CDATA[我正在尝试在 python 中从头开始实现线性回归。
作为参考，以下是我使用过的数学公式：方程
这是我尝试过的：
类线性回归：
    
    def __init__(
    自己，
    特征：np.ndarray[np.float64]，
    目标：np.ndarray[np.float64]，
    ）-&gt;没有任何：
        self.features = np.concatenate((np.ones((features.shape[0], 1)), features), axis=1)
        self.targets = 目标
        self.params = np.random.randn(features.shape[1] + 1)
        self.num_samples = features.shape[0]
        self.num_feats = features.shape[1]
        自我成本 = []
    
    def假设（自我）-&gt; np.ndarray[np.float64]：
        返回 np.dot(self.features, self.params)
    
    def cost_function(self) -&gt;; def cost_function(self) -&gt; np.float64：
        pred_vals = self.hypothesis()
        return (1 / (2 * self.num_samples)) * np.dot((pred_vals - self.targets).T, pred_vals - self.targets)
    
    def update(self, alpha: np.float64) -&gt;;没有任何：
        self.params = self.params - (alpha / self.num_samples) * (self.features.T @ (self.hypothesis() - self.targets))
    
    defgradientDescent(self, alpha: np.float64, 阈值: np.float64, max_iter: int) -&gt;没有任何：
        收敛=假
        计数器 = 0
        未收敛时：
            计数器 += 1
            curr_cost = self.cost_function()
            self.costs.append(curr_cost)
            自我更新（阿尔法）
            new_cost = self.cost_function()
            如果abs(new_cost - curr_cost) &lt;临界点：
                收敛=真
            如果计数器&gt;最大迭代次数：
                收敛=真

我使用了这样的类：
regr = LinearRegression(features=np.linspace(0, 1000, 200, dtype=np.float64).reshape((20, 10)), 目标= np.linspace(0, 200, 20, dtype=np.float64))
regr.gradientDescent(0.1, 1e-3, 1e+3)
regr.cost_function()

但是，我收到以下错误：
RuntimeWarning：标量幂中遇到溢出
  return (1 / (2 * self.num_samples)) * (la.norm(self.hypothesis() - self.targets) ** 4)

RuntimeWarning：标量减法中遇到无效值
  如果abs(new_cost - curr_cost) &lt;临界点：

RuntimeWarning：matmul 中遇到溢出
  self.params = self.params - (alpha / self.num_samples) * (self.features.T @ (self.hypothesis() - self.targets))

究竟出了什么问题？]]></description>
      <guid>https://stackoverflow.com/questions/77569740/why-is-my-implementation-of-linear-regression-not-working</guid>
      <pubDate>Wed, 29 Nov 2023 08:54:58 GMT</pubDate>
    </item>
    <item>
      <title>在 Mac 上安装 pgvector 扩展</title>
      <link>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</link>
      <description><![CDATA[我正在尝试在我的 Mac 上安装 postgres 矢量扩展，但我得到了
错误：扩展名“向量”没有版本“0.4.0”的安装脚本或更新路径。

这就是我所做的：

按照 github 上所示的安装指南进行操作：


但是当我运行CREATE EXTENSION vector;时出现错误：
错误：无法打开扩展控制文件“/Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/vector.control”：没有这样的文件或目录


我使用以下方法将 pgvector 的内容复制到 posgresql/extension 中：
sudo cp -r ~/Downloads/pgvector/* /Applications/Postgres.app/Contents/Versions/13/share/postgresql/extension/


尝试运行CREATE EXTENSION向量；现在错误是：
错误：扩展名“向量”没有版本“0.4.0”的安装脚本或更新路径。

这里有人遇到过这个问题吗？
顺便说一句，我正在使用PostgreSQL 13.10]]></description>
      <guid>https://stackoverflow.com/questions/75664004/install-pgvector-extension-on-mac</guid>
      <pubDate>Tue, 07 Mar 2023 15:32:42 GMT</pubDate>
    </item>
    <item>
      <title>如何使用OrdinalEncoder()设置自定义顺序？</title>
      <link>https://stackoverflow.com/questions/72170947/how-to-use-ordinalencoder-to-set-custom-order</link>
      <description><![CDATA[我的二手车价格预测数据集中有一列名为“Owner_Type”的列。它有四个唯一值，即[&#39;第一&#39;、&#39;第二&#39;、&#39;第三&#39;、&#39;第四&#39;]。现在最有意义的顺序是 First &gt; &gt;第二个&gt;第三&gt;第四，价格相对于该订单下降。如何使用 OrdinalEncoder() 为值指定此顺序？请帮帮我，谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/72170947/how-to-use-ordinalencoder-to-set-custom-order</guid>
      <pubDate>Mon, 09 May 2022 11:05:12 GMT</pubDate>
    </item>
    <item>
      <title>Google AI Platform 训练 - 等待作业完成</title>
      <link>https://stackoverflow.com/questions/64806003/google-ai-platform-training-wait-for-the-job-to-finish</link>
      <description><![CDATA[我构建了一个包含大量并行进程的 AI Platform 管道。每个进程都会在 AI 平台上启动一个训练作业，如下所示：
gcloud ai-platform 作业提交培训...

然后它必须等待作业完成才能进入下一步。为此，我尝试将参数 --stream-logs 添加到上述命令中。通过这种方式，它会传输所有日志，直到作业完成。
问题是，有这么多并行进程，我用完了获取日志的请求：
超出配额指标“读取请求”和限制“每分钟读取请求”的配额
服务“logging.googleapis.com”

但我不需要实际流式传输日志，我只需要一种方法来告诉进程“等待”直到训练工作完成。有没有更聪明、更简单的方法来做到这一点？]]></description>
      <guid>https://stackoverflow.com/questions/64806003/google-ai-platform-training-wait-for-the-job-to-finish</guid>
      <pubDate>Thu, 12 Nov 2020 14:39:20 GMT</pubDate>
    </item>
    <item>
      <title>如何摆脱 pandas 将 Excel 工作表中的大量数字转换为指数？</title>
      <link>https://stackoverflow.com/questions/38689125/how-to-get-rid-of-pandas-converting-large-numbers-in-excel-sheet-to-exponential</link>
      <description><![CDATA[在 Excel 工作表中，我有两列数字很大。
但是当我使用 read_excel() 读取 Excel 文件并显示数据框时，
这两列以带有指数的科学格式打印。
如何摆脱这种格式？
谢谢
Pandas 输出
]]></description>
      <guid>https://stackoverflow.com/questions/38689125/how-to-get-rid-of-pandas-converting-large-numbers-in-excel-sheet-to-exponential</guid>
      <pubDate>Sun, 31 Jul 2016 23:08:26 GMT</pubDate>
    </item>
    </channel>
</rss>