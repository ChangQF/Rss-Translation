<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 07 Jun 2024 01:05:53 GMT</lastBuildDate>
    <item>
      <title>可教机器使用哪个版本的 tensorFlow/Keras？</title>
      <link>https://stackoverflow.com/questions/78589351/what-version-of-tensorflow-keras-does-teachable-machine-use</link>
      <description><![CDATA[我尝试按照 YouTube 上的教程操作（https://www.youtube.com/watch?v=wa2ARoUUdU8&amp;t=2877s&amp;ab_channel=Murtaza%27sWorkshop-RoboticsandAI）。当我尝试运行 tennsorflow 时，一直出现错误。视频中，该人使用 https://teachablemachine.withgoogle.com/train/tiny_image 来训练模型。我完成了所有步骤，但是在运行时（视频的 49:32。它没有运行）错误与使用支持组参数的 TensorFlow / Keras 版本训练的模型有关，但我正在使用的当前 TensorFlow / Keras 版本无法识别它。提醒一下，我使用的是 vs 而不是 py charms 和 dowloand tensflow，我的版本是 2.16.1
这是我的代码：
import cv2
from cvzone.HandTrackingModule import HandDetector
from cvzone.ClassificationModule import Classifier
import numpy as np
import tensorflow as tf
import math
import time
import tensorflow as tf
print(tf.__version__)

cap = cv2.VideoCapture(0)
detector = HandDetector(maxHands=1)#决定要检测多少只手
classifier = Classifier(&quot;Model/keras_model.h5&quot;,&quot;Model/labels.txt&quot;)

offset = 20 #用于裁剪图像以增加尺寸
imgSize = 300

folder = “数据/C” #数据存储位置
counter = 0#知道将保存多少图像

labels = [&quot;A&quot;,&quot;B&quot;,&quot;C&quot;]

while True:
success, img = cap.read()
hands, img = detector.findHands(img)
#裁剪图像
if hands:#还要注意，当手很大/离相机太近时，程序将停止工作
hand = hands[0]#仅适用于 1 只手
x,y,w,h = hand[&#39;bbox&#39;]#粘合框并给出尺寸

imgWhite = np.ones((imgSize,imgSize,3),np.uint8)*255#创建白色背景用于裁剪图像
imgCrop = img[y-offset:y+h+offset,x-offset:x+w+offset]#给出边界框要求

imgCropShape = imgCrop.shape

aspectRatio = h/w

ifaspectRatio&gt;1:#图像高度
k = imgSize/h #拉伸高度
wCal=math.ceil(k*w)
imgResize=cv2.resize(imgCrop,(wCal,imgSize))
imgResizeShape = imgResize.shape
wGap = math.ceil((imgSize-wCal)/2)
#在白色图像上叠加图像
imgWhite[:,wGap:wCal+wGap] = imgResize #中心图像
#发送值
#predection,index = classifier.getPrediction(img)
#print(predection,index)
else:#图像宽度
k = imgSize/w #拉伸高度
hCal=math.ceil(k*h)
imgResize=cv2.resize(imgCrop,(imgSize,hCal))
imgResizeShape = imgResize.shape
hGap = math.ceil((imgSize-hCal)/2)
#在白色图像上叠加图像
imgWhite[hGap:hCal+hGap,:] = imgResize #居中图像

cv2.imshow(&quot;ImageCrop&quot;, imgCrop)#再裁剪一次
cv2.imshow(&quot;ImageWhite&quot;, imgWhite)

cv2.imshow(&quot;Image&quot;, img)
key =cv2.waitKey(1)#1 毫秒延迟

]]></description>
      <guid>https://stackoverflow.com/questions/78589351/what-version-of-tensorflow-keras-does-teachable-machine-use</guid>
      <pubDate>Thu, 06 Jun 2024 22:56:18 GMT</pubDate>
    </item>
    <item>
      <title>训练误差持续下降，但测试误差却没有下降，即使测试数据集是训练数据集的子集</title>
      <link>https://stackoverflow.com/questions/78589173/train-error-decreases-consistently-but-test-error-does-not-even-when-test-data</link>
      <description><![CDATA[我的数据包含来自传感器的 6 个特征。我正在用这些数据训练 LSTM 网络来预测三个值。
在训练过程中，我的训练损失随着每个时期而持续减少，但测试损失在几个时期后并没有减少多少。
当训练数据和测试数据之间没有重叠时就会出现这种情况。因此，我尝试使用训练数据的子集作为测试数据。
但是，仍然是相同的行为，测试损失仍然没有减少。
以下是 LSTM 模型和训练器的代码。
class LSTMModel(nn.Module):
def __init__(self, in_dim=6, hidden_​​size=200, num_layers=1, output_size=3):
super(LSTMModel, self).__init__()
self.lstm_1 = nn.LSTM(in_dim, hidden_​​size, num_layers, batch_first=True)
self.lstm_2 = nn.LSTM(hidden_​​size, hidden_​​size, num_layers, batch_first=True)
self.lstm_3 = nn.LSTM(hidden_​​size, hidden_​​size, num_layers, batch_first=True)
self.lstm_4 = nn.LSTM(hidden_​​size, hidden_​​size, num_layers, batch_first=True)
self.fc = nn.Linear(hidden_​​size, output_size)

def forward(self, x):
x, _ = self.lstm_1(x)
x, _ = self.lstm_2(x)
x, _ = self.lstm_3(x)
x, _ = self.lstm_4(x)
output = self.fc(x[:, -1, :])
return output

class SimpleModelTrainer:
def __init__(self, model, train_dataset, test_dataset, batch_size=1024, epochs=100, lr=0.005): # window_size=200, do_windowing=True, waiting=5, pad_testing_data = False

self.model = model
self.optimizer = AdamW(params=self.model.parameters(), lr=lr)

self.lr = lr
self.epochs = epochs
self.batch_size = batch_size
self.loss_fn = nn.L1Loss()
self.train_data = train_dataset
self.test_data = test_dataset

def train(self):
self.train_dataloader = torch.utils.data.DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device=device))
self.test_dataloader = torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size, shuffle=True, generator=torch.Generator(device=device))
total_samples = 0

for epoch in tqdm(range(self.epochs), desc=&quot;epoch&quot;):
self.model.train()
total_loss = 0

for train_data in tqdm(self.train_dataloader, desc=&quot;train&quot;):

X = train_data[0]
Y = train_data[1]

if X.shape[0] != self.batch_size: continue # 以避免 RuntimeError: 形状 &#39;[16, 1, 256]&#39; 对于大小为 3328 的输入无效

total_samples += self.batch_size

y_hat = self.model(X)

loss = self.loss_fn(y_hat, Y)
self.optimizer.zero_grad()
loss.backward()
self.optimizer.step()
total_loss += loss.item()

avg_train_loss = total_loss / total_samples
val_loss = self.test(self.test_dataloader)
print(f&quot;Epoch {epoch} - Train loss:{avg_train_loss:.10f}, Val loss:{val_loss:.10f}&quot;)

def test(self, dataloader):
self.model.eval()
with torch.no_grad():
total_loss = 0
total_samples = 0
for test_data in tqdm(dataloader, desc=&quot;test&quot;):
X = test_data[0]
Y = test_data[1]

if X.shape[0] != self.batch_size: continue # 以避免 RuntimeError: shape &#39;[Y, 200, 6]&#39; 对于大小为 Z 的输入无效

total_samples += self.batch_size 

y_hat = self.model(X)

loss = self.loss_fn(y_hat, Y)
total_loss += loss.item()

val_loss = total_loss/total_samples
return val_loss

我尝试使用随机生成的虚拟变量数据集。它给出了与上述完全相同的行为！
您可以在此 colab 笔记本中查看它。
正如您在笔记本中看到的那样，自第一个时期以来，验证损失一直停留在 0.00048。但训练损失随着每个时期持续下降，从 0.00048 下降到第 28 个时期的 0.000016。
（当我写这个问题时，它仍在训练。）测试数据集是训练数据集的子集：
train_dataset = CustomDataset(windowed_input_data, windowed_target_data)
test_dataset = CustomDataset(windowed_input_data[:20000], windowed_target_data[:20000])

因此，我相信我应该得到类似的验证损失行为，验证损失也应该达到约 0.00001。我想我在代码中犯了一些愚蠢的错误（错误的 pytorch API 调用？）我的眼睛根本无法帮助我。有人可以帮帮我吗？我在概念上错过了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78589173/train-error-decreases-consistently-but-test-error-does-not-even-when-test-data</guid>
      <pubDate>Thu, 06 Jun 2024 21:42:12 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 目录结构与文档不同</title>
      <link>https://stackoverflow.com/questions/78588051/tensorflow-directory-structure-different-from-documentation</link>
      <description><![CDATA[文档中的内容
来自我的 .venv 的 TensorFlow 目录
我试图访问最新版本的 TensorFlow 中的某些函数，如 tf.strings 等。网站上的文档说要以某种方式执行此操作，但 python 无法识别它们。我想要使用的函数只是在“api_packages.txt”文件中列出，但没有办法真正调用它们。我该怎么做才能访问这些模块？
尝试从使用不同版本的在线资源中学习时也会非常令人困惑，因为很多目录已经迁移到不同的位置。
模块无法识别的示例
我尝试引用所示的模块，但无法识别。]]></description>
      <guid>https://stackoverflow.com/questions/78588051/tensorflow-directory-structure-different-from-documentation</guid>
      <pubDate>Thu, 06 Jun 2024 16:44:35 GMT</pubDate>
    </item>
    <item>
      <title>预先训练的模型将评论分类</title>
      <link>https://stackoverflow.com/questions/78587853/pre-trained-model-to-classify-comment-into-category</link>
      <description><![CDATA[是否有任何预先训练好的模型可以将评论分类为投诉、赞赏/表扬、询问等？
如果没有，是否可以使用 ChatGPT 为每个类别创建合成数据并训练分类器来完成此任务？
欢迎提出所有建议！！]]></description>
      <guid>https://stackoverflow.com/questions/78587853/pre-trained-model-to-classify-comment-into-category</guid>
      <pubDate>Thu, 06 Jun 2024 16:04:53 GMT</pubDate>
    </item>
    <item>
      <title>无法在 jupyter notebook 上安装 tensorflow 模块</title>
      <link>https://stackoverflow.com/questions/78587775/unable-to-install-tensorflow-module-on-jupyter-notebook</link>
      <description><![CDATA[我尝试使用 !pip install tensorflow 在 jupyter notebook 上安装 tensorflow，但它给出了以下输出：OSError Traceback (most recent call last)
Cell In[5], line 1
----&gt; 1 get_ipython().system(&#39;pip install tensorflow&#39;)
File /lib/python3.11/site-packages/IPython/core/interactiveshell.py:2653, in InteractiveShell.system_piped(self, cmd)
2648 raise OSError(&quot;Background processes not supports.&quot;)
2650 # 我们明确不返回子进程状态代码，因为
2651 # 非 None 值将触发 :func:sys.displayhook 调用。
2652 # 相反，我们将 exit_code 存储在 user_ns 中。
-&gt; 2653 self.user_ns[&#39;_exit_code&#39;] = system(self.var_expand(cmd,depth=1))
File /lib/python3.11/site-packages/IPython/utils/_process_emscripten.py:11, in system(cmd)
10 def system(cmd):
---&gt; 11 raise OSError(&quot;Not available&quot;)
OSError: Not available
我尝试在另一个 jupyter notebook 帐户上使用相同的命令：!pip install tensorflow，但它给出了相同的输出，即不可用]]></description>
      <guid>https://stackoverflow.com/questions/78587775/unable-to-install-tensorflow-module-on-jupyter-notebook</guid>
      <pubDate>Thu, 06 Jun 2024 15:50:17 GMT</pubDate>
    </item>
    <item>
      <title>为什么张量的值不在[0:1]区间？</title>
      <link>https://stackoverflow.com/questions/78587688/why-the-value-of-the-tensor-is-not-in-01-interval</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78587688/why-the-value-of-the-tensor-is-not-in-01-interval</guid>
      <pubDate>Thu, 06 Jun 2024 15:32:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在多元回归中显示预测因子重要性+特征名称？</title>
      <link>https://stackoverflow.com/questions/78587419/how-can-i-display-predictor-importance-feature-name-in-multivariate-regression</link>
      <description><![CDATA[我正在探索一个数据集，目的是找到任何有趣的关系（有很多感兴趣的变量，我想看看哪些特征或特征组合可以预测它们）。
作为第一种方法，我成功地用套索计算了一个多变量（几个目标变量）回归。
pipeline = Pipeline([
(&#39;scaler&#39;, StandardScaler()),
(&#39;model&#39;, Lasso())])

search = GridSearchCV(pipeline,
{&#39;model__alpha&#39;:np.arange(0.1,10,0.1)},
cv = 5,scoring=&quot;neg_mean_squared_error&quot;,verbose=3
)
search.fit(X_train,y_train)
search.best_params_
coefficients = search.best_estimator_.named_steps[&#39;model&#39;].coef_
importance = np.abs(系数)

现在我想看看预测因子的重要性，包括它们的特征名称，因为 importance 只是一堆数字。
我考虑过创建一个包含特征和目标的列名的数组并打印名称 + 系数，但我的问题是我不完全确定如何确保对应关系（正确的名称与正确的系数一起显示）。
有人能帮我吗？
这里有一些额外的信息：

预测因子数量：26
目标数量：30
importance 的形状：（30, 26）

我也非常感谢关于使用哪些重要性指标的任何其他建议或有关可能分析的任何建议。]]></description>
      <guid>https://stackoverflow.com/questions/78587419/how-can-i-display-predictor-importance-feature-name-in-multivariate-regression</guid>
      <pubDate>Thu, 06 Jun 2024 14:49:37 GMT</pubDate>
    </item>
    <item>
      <title>xgboast scale_pos_weight 如果训练数据集的正样本多于负样本，是否仍然正确平衡？</title>
      <link>https://stackoverflow.com/questions/78587301/xgboast-scale-pos-weight-if-the-training-dataset-has-more-positive-samples-than</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我确信 scale_pos_weight 会是一种更好的方法。是否可以假设因为它小于 1，所以它仍然会正确平衡？当然，特异性在我的研究中很重要，但我们的目标更多是关于召回率、精确度和 f1 分数。这是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/xgboast-scale-pos-weight-if-the-training-dataset-has-more-positive-samples-than</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>使用 paddleocr 从图像文档中提取表格</title>
      <link>https://stackoverflow.com/questions/78586625/extract-tables-from-image-documents-using-paddleocr</link>
      <description><![CDATA[我是 Ocr 的新手。我正尝试从图像格式的表格中提取数据。

为此我想使用 paddleocr，paddleocr 是否适合这些类型的表格图像。如果可以，有人可以提供图像的资源或教程吗？或者是否有任何适用于表格图像的软件包]]></description>
      <guid>https://stackoverflow.com/questions/78586625/extract-tables-from-image-documents-using-paddleocr</guid>
      <pubDate>Thu, 06 Jun 2024 12:37:33 GMT</pubDate>
    </item>
    <item>
      <title>我可以实施 Google Lens API 来从给定图像中识别汽车的品牌和型号吗？[关闭]</title>
      <link>https://stackoverflow.com/questions/78586504/can-i-implement-google-lens-api-to-identify-brand-and-model-of-a-car-from-a-give</link>
      <description><![CDATA[我正在尝试寻找一个可以从给定的汽车图像中识别汽车品牌或名称的 API。

我尝试过 Google Cloud Vision API，但它只是将汽车检测为汽车，而不是它的具体信息。
我也尝试过 SERP API，但它对我的用例也没有用。

我正在寻找：
我可以获得一些可以集成来获取图像中汽车品牌的 Google API 吗？]]></description>
      <guid>https://stackoverflow.com/questions/78586504/can-i-implement-google-lens-api-to-identify-brand-and-model-of-a-car-from-a-give</guid>
      <pubDate>Thu, 06 Jun 2024 12:17:42 GMT</pubDate>
    </item>
    <item>
      <title>使用自定义数据集训练 ViTPose (Vision Transformer) 时损失为零</title>
      <link>https://stackoverflow.com/questions/78586455/loss-is-zero-while-training-vitpose-vision-transformer-with-custom-dataset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78586455/loss-is-zero-while-training-vitpose-vision-transformer-with-custom-dataset</guid>
      <pubDate>Thu, 06 Jun 2024 12:08:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 logistf 包时，Firth 的模型在 R 中卡住了（出现未收敛警告，CPU 使用率高达 99%）</title>
      <link>https://stackoverflow.com/questions/78579401/firths-model-stuck-with-non-converge-warning-and-cpu-usage-99-in-r-using-the</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78579401/firths-model-stuck-with-non-converge-warning-and-cpu-usage-99-in-r-using-the</guid>
      <pubDate>Wed, 05 Jun 2024 07:34:40 GMT</pubDate>
    </item>
    <item>
      <title>Huggingface 管道可用模型</title>
      <link>https://stackoverflow.com/questions/78328539/huggingface-pipeline-available-models</link>
      <description><![CDATA[我正在使用 Python 中的 Huggingface 来对特定的 LLM 文本生成模型进行推理。到目前为止，我使用这样的管道来初始化模型，然后插入用户的输入并检索响应：
import torch
from transformers import pipeline
print(torch.cuda.is_available())

generator = pipeline(&#39;text-generation&#39;, model=&#39;gpt2&#39;, device=&quot;cuda&quot;)
#推理代码

但是，当我用 google/gemma-2b-it 或其他一些模型更改 gpt2 时，它可能会要求进行身份验证，或者直接出现错误，表明它无法从 pipeline() 获得。
我知道有些模型需要特定的标记器和依赖项，但是，有没有办法从 pipeline() 列出所有可用的模型？有什么方法可以在 pipeline() 中使用其他模型及其所有依赖项，而无需在脚本中导入或使用它们？]]></description>
      <guid>https://stackoverflow.com/questions/78328539/huggingface-pipeline-available-models</guid>
      <pubDate>Mon, 15 Apr 2024 12:54:43 GMT</pubDate>
    </item>
    <item>
      <title>从熊猫数据框中删除高度相关的列</title>
      <link>https://stackoverflow.com/questions/44889508/remove-highly-correlated-columns-from-a-pandas-dataframe</link>
      <description><![CDATA[我有一个名为 data 的数据框，我使用其计算了相关矩阵
corr = data.corr()

如果两列之间的相关性大于 0.75，我想从数据框 data 中删除其中一列。我尝试了一些选项
raw =corr[(corr.abs()&gt;0.75) &amp; (corr.abs() &lt; 1.0)]

但这没有帮助；我需要 raw 中值非零的列号。基本上是以下 R 命令的一些 Python 等效命令（使用函数 findCorrelation）。
{hc=findCorrelation(corr,cutoff = 0.75)

hc = sort(hc)

data &lt;- data[,-c(hc)]}

如果有人能帮助我在 Python pandas 中获取类似于上述 R 命令的命令，那将会很有帮助。]]></description>
      <guid>https://stackoverflow.com/questions/44889508/remove-highly-correlated-columns-from-a-pandas-dataframe</guid>
      <pubDate>Mon, 03 Jul 2017 15:39:25 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 中的 L1/L2 正则化</title>
      <link>https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch</link>
      <description><![CDATA[如何在 PyTorch 中添加 L1/L2 正则化而无需手动计算？]]></description>
      <guid>https://stackoverflow.com/questions/42704283/l1-l2-regularization-in-pytorch</guid>
      <pubDate>Thu, 09 Mar 2017 19:54:19 GMT</pubDate>
    </item>
    </channel>
</rss>