<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Wed, 26 Jun 2024 09:17:47 GMT</lastBuildDate>
    <item>
      <title>为什么返回 null</title>
      <link>https://stackoverflow.com/questions/78671410/why-is-it-returning-null</link>
      <description><![CDATA[从 fastapi 导入 FastAPI、文件、上传文件
导入 uvicorn
导入 numpy 作为 np
从 io 导入 BytesIO
从 PIL 导入图像
导入 tensorflow 作为 tf
app = FastAPI()

MODEL = tf.keras.models.load_model(&quot;../models/1&quot;)
CLASS_NAMES = [&quot;早疫病&quot;, &quot;晚疫病&quot;, &quot;健康&quot;]
@app.get(&quot;/ping&quot;)
async def ping():
返回&quot;hello world&quot;

def read_file_as_image(data) -&gt; np.ndarray:
image = np.array(Image.open(BytesIO(data)))
返回图像

@app.post(&quot;/predict&quot;)
async def predict(
file: UploadFile = File(...)
):
image = read_file_as_image(await file.read())
img_batch = np.expand_dims(image,0)

predictions = MODEL.predict(img_batch)
predict_class = CLASS_NAMES[np.argmax(predictions[0])]
confidence = np.max(predictions[0])
返回 {
&#39;class&#39; : predict_class,
&#39;confidence&#39; : float(confidence)
}

if __name__ == &quot;__main__&quot;:
uvicorn.run(app, host=&#39;localhost&#39;, port=8000)

我尝试使用 Fastapi 获取我的预测模型的输出，但它返回 null
它应该返回类名和置信度，但它只是返回 null]]></description>
      <guid>https://stackoverflow.com/questions/78671410/why-is-it-returning-null</guid>
      <pubDate>Wed, 26 Jun 2024 09:09:31 GMT</pubDate>
    </item>
    <item>
      <title>Python 中的 ElasticNetCV：获取具有相应 MSE 的超参数完整网格？</title>
      <link>https://stackoverflow.com/questions/78671295/elasticnetcv-in-python-get-full-grid-of-hyperparameters-with-corresponding-mse</link>
      <description><![CDATA[我在 Python 中用三个分割拟合了一个 ElasticNetCV：
import numpy as np
from sklearn.linear_model import LinearRegression

#样本数据：
num_samples = 100 # 样本数量
num_features = 1000 # 特征数量
X = np.random.rand(num_samples, num_features)
Y = np.random.rand(num_samples)

#模型
l1_ratios = np.arange(0.1, 1.1, 0.1)
tscv=TimeSeriesSplit(max_train_size=None, n_splits=3)
regr = ElasticNetCV(cv=tscv.split(X), random_state=42,l1_ratio=l1_ratios)
regr.fit(X,Y)

现在我想获取超参数组合的整个网格以及相应的 MSE 作为数据框，我尝试了以下方法。但是，问题在于，生成的数据框显示的超参数组合的 MSE 并未显示为 ElasticNetCV 对象中的最小值，该对象可以通过 regr.alpha_ 和 regr.l1_ratio_ 获得
:
mse_path = regr.mse_path_
alpha_path = regr.alphas_

# 重塑 mse_path，使 l1_ratios、n_alphas、cross_validation_step 作为单独的列
mse_values = mse_path.flatten()
alpha_values = alpha_path.flatten()
l1_values=np.tile(l1_ratios ,int(alpha_values.shape[0]/l1_ratios.shape[0]))
repeated_l1_ratios = np.repeat(l1_ratios, 100)

# mse维度为 (11, 100, 3)
array_3d = mse

# 将 3D 数组展平为 2D 数组
# 每个形状为 (100, 3) 的子数组都将成为新 2D 数组中的一行
array_2d = array_3d.reshape(-1, 3)

# 从 2D 数组创建 DataFrame
df = pd.DataFrame(array_2d, columns=[&#39;MSE Split1&#39;, &#39;MSE Split2&#39;, &#39;MSE Split3&#39;])

df[&#39;alpha_values&#39;] = alpha_values
df[&#39;l1_values&#39;] = duplicate_l1_ratios

以下结果导致超参数组合不是真实的组合。因此，在组合 MSE 和超参数值时，会出现问题：
# 计算三个分割中每行的最小 MSE
df[&#39;Min MSE&#39;] = df[[&#39;MSE Split1&#39;, &#39;MSE Split2&#39;, &#39;MSE Split3&#39;]].min(axis=1)

# 确定总体最小 MSE 的行
min_mse_row_index = df[&#39;Min MSE&#39;].idxmin()

# 检索最小 MSE 的行
min_mse_row = df.loc[min_mse_row_index]

print(&quot;所有分割中 MSE 最小的行：&quot;)
print(min_mse_row)
]]></description>
      <guid>https://stackoverflow.com/questions/78671295/elasticnetcv-in-python-get-full-grid-of-hyperparameters-with-corresponding-mse</guid>
      <pubDate>Wed, 26 Jun 2024 08:49:51 GMT</pubDate>
    </item>
    <item>
      <title>已给出所创建函数所需的所有参数，但它却说缺少参数 [关闭]</title>
      <link>https://stackoverflow.com/questions/78670512/the-all-the-arguments-required-for-a-created-function-are-given-yet-it-says-argu</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78670512/the-all-the-arguments-required-for-a-created-function-are-given-yet-it-says-argu</guid>
      <pubDate>Wed, 26 Jun 2024 05:45:18 GMT</pubDate>
    </item>
    <item>
      <title>在实施有关使用 Python 进行 ML 集成的 Github 项目时遇到了困难</title>
      <link>https://stackoverflow.com/questions/78670360/got-stuck-in-implementing-a-github-project-about-ml-integration-with-python</link>
      <description><![CDATA[我是一名新开发人员，正在尝试不同的项目，我正在尝试实现这个 Git 存储库（https://github.com/jowpereira/MetaTrader-Python-Integration），它本质上是将 ML 模型与策略测试器集成：实现价格预测的回归模型。
安装先决条件后，每次运行时，我都会遇到这个问题
从 CMD 获取消息
它转换为 &lt;&lt;--等待配置文件--&gt;&gt;
以下是任何感兴趣的人的代码
def main():
file = File()
file.delete_file(PATH_COMMON.format(INIT_ARCHIVE))
file.delete_file(PATH_COMMON.format(INIT_OK_ARCHIVE))
file.delete_file(PATH_COMMON.format(TESTE_ARCHIVE))
file.delete_file(PATH_COMMON.format(TESTE_PREDICT))

while True:
print(&quot;&lt;&lt;--Aguardando o配置文件--&gt;&gt;&quot;)
typerun = file.check_init_param(PATH_COMMON.format(INIT_ARCHIVE))
time.sleep(1)

file.save_file_csv(PATH_COMMON.format(INIT_OK_ARCHIVE))

if typerun == 0:
print(&#39;&lt;&lt;-- {} --&gt;&gt;&#39;.format(&quot;Script Python - Modo Teste&quot;))
while True:
accept = file.check_open_file(PATH_COMMON.format(TESTE_ARCHIVE))
file.delete_file(PATH_COMMON.format(TESTE_ARCHIVE))

if len(receive) == 0:
continue

if accept[&quot;command&quot;][0].upper() == &quot;START&quot;:
header = [&quot;open&quot;, &quot;close&quot;]
payload = []

for i in range(len(receive)):
row = [
str(receive[&quot;open&quot;][i]),
str(receive[&quot;close&quot;][i])
]
payload.append(row)

df = pd.DataFrame(payload, columns=header)
smoothed_df = df.ewm(alpha=0.1).mean()
smoothed_df[&#39;macd&#39;], smoothed_df[&#39;signal&#39;] = macd(smoothed_df)
smoothed_df[&#39;ema&#39;] = ema(smoothed_df)
smoothed_df[&#39;rsi&#39;] = rsi(smoothed_df)
selected_df = smoothed_df[[&#39;open&#39;, &#39;macd&#39;, &#39;ema&#39;, &#39;rsi&#39;, &#39;close&#39;]].dropna()

# 预览
next_week_prediction = predict_next_week(selected_df, MODEL_PATH, window_size)
file.save(PATH_COMMON.format(TESTE_PREDICT), str(next_week_prediction[0]))
continue

elif accept[&quot;command&quot;][0].upper() == &quot;STOP&quot;:
file.delete_file(PATH_COMMON.format(TESTE_PREDICT))
continue

if name == &quot;ma​​in&quot;:
main()
我已经给作者发短信了，但他没有回复我，请问有谁知道如何解决这个问题吗？
按照 Git 存储库中的说明，安装了所有先决条件和安装 Metatrader 5 也在 CMD 中，当我收到以前的错误消息时，但不是，我不知道配置文件是什么意思]]></description>
      <guid>https://stackoverflow.com/questions/78670360/got-stuck-in-implementing-a-github-project-about-ml-integration-with-python</guid>
      <pubDate>Wed, 26 Jun 2024 04:38:21 GMT</pubDate>
    </item>
    <item>
      <title>使用 CycleGAN-and-pix2pix 开源仓库中的 cycleGan 模型进行图像推理</title>
      <link>https://stackoverflow.com/questions/78669614/image-inference-with-cyclegan-model-from-cyclegan-and-pix2pix-open-source-repo</link>
      <description><![CDATA[我已经根据CycleGAN-and-pix2pix 开源API在google colab上训练了一个cycleGan模型。
对于训练过程，我使用了 !python train.py --dataroot /content/drive/MyDrive/project/dataset --name F2F --model cycle_gan --display_id -1 
为了从我使用的文件夹中推断图像集
opt = TestOptions()
#defined 选项出现在这里
dataset = create_dataset(opt) 
初始化模型
model = create_model(opt)
model.setup(opt)
model.eval()
data_iter = iter(dataset.dataloader)
data_dict = next(data_iter)
input_image_tensor = data_dict[&#39;A&#39;]
data = {&#39;A&#39;: input_image_tensor,&#39;A_paths&#39;: &#39;&#39;}
model.set_input(data)
model.test()
visuals = model.get_current_visuals()
output_image = visuals[&#39;fake&#39;]
output_image_np = output_image.squeeze().cpu().numpy().transpose(1, 2, 0)
output_image_np = ((output_image_np - output_image_np.min()) / (output_image_np.max() - output_image_np.min()) * 255).astype(np.uint8)
output_image_np = cv2.cvtColor(output_image_np, cv2.COLOR_BGR2RGB)
cv2_imshow(output_image_np)


上述代码片段按预期工作并产生了良好的结果。
现在，我想推断单个图像而不经过加载器。
我试图模仿 create_dataset(opt) 中的图像预处理，它是一个 API 函数，使用以下代码：
def preprocess(image):
if image.ndim == 2 or image.shape[2] == 1:
image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
elif image.shape[2] == 4:
image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)
elif image.shape[2] == 3:
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
pil_image = transforms.ToPILImage()(image)
transform_pipeline = transforms.Compose([
transforms.Resize(286),
transforms.CenterCrop(256),
transforms.ToTensor(),
transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
image_tensor = transform_pipeline(pil_image)
image_tensor = image_tensor.unsqueeze(0)

返回 image_tensor

input_image = cv2.imread(&#39;/content/drive/MyDrive/dataset/testA/image_1.jpg&#39;)
input_image_tensor = preprocess(input_image)
data = {&#39;A&#39;: input_image_tensor,&#39;A_paths&#39;: &#39;&#39;}
model.set_input(data)
model.test()
visuals = model.get_current_visuals()
output_image = visuals[&#39;fake&#39;]
output_image_np = output_image.squeeze().cpu().numpy().transpose(1, 2, 0)
output_image_np = ((output_image_np - output_image_np.min()) / (output_image_np.max() - output_image_np.min()) * 255).astype(np.uint8)
output_image_np = cv2.cvtColor(output_image_np, cv2.COLOR_BGR2RGB)
cv2_imshow(output_image_np)

但生成的图像非常模糊，并且没有像使用 create_dataset(opt) 函数中的加载器那样提供精细调整的结果。
如能提供任何有关如何实现此目的的帮助，我将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/78669614/image-inference-with-cyclegan-model-from-cyclegan-and-pix2pix-open-source-repo</guid>
      <pubDate>Tue, 25 Jun 2024 21:42:50 GMT</pubDate>
    </item>
    <item>
      <title>绘制预测掩码的问题</title>
      <link>https://stackoverflow.com/questions/78669554/issue-with-plotting-predicted-masks</link>
      <description><![CDATA[我目前正在进行一个深度学习项目“叶病分割”。我已经训练了一个模型超过 50 个时期，并获得了以下准确度和损失指标：
训练损失：19.4736，训练准确度：0.9395
验证损失：19.6197，验证准确度：0.9100
测试损失：19.6148，测试准确度：0.9123
但是，当我绘制预测的蒙版时，它们看起来不准确。我的绘图代码有问题吗？
def plot_predictions(model, images, mask, num_samples=5):
predictions = model.predict(images[:num_samples])
for i in range(num_samples):
plt.figure(figsize=(15, 5))
plt.subplot(1, 3, 1)
plt.title(&#39;真实图像&#39;)
plt.imshow(images[i])
plt.subplot(1, 3, 2)
plt.title(&#39;地面真相面具&#39;)
plt.imshow(masks[i], cmap=&#39;gray&#39;) # 假设面具已经是二进制的
plt.subplot(1, 3, 3)
plt.title(&#39;预测面具&#39;)
plt.imshow(predictions[i][:, :, 0], cmap=&#39;gray&#39;) # 转换预测面具转换为二进制
plt.show()

plot_predictions(model, test_images.numpy(), test_masks_L, num_samples=5)

原始图像-蒙版-预测蒙版
请检查我的代码并帮助找出可能导致此问题的任何错误？]]></description>
      <guid>https://stackoverflow.com/questions/78669554/issue-with-plotting-predicted-masks</guid>
      <pubDate>Tue, 25 Jun 2024 21:18:52 GMT</pubDate>
    </item>
    <item>
      <title>监督学习中的过度拟合检测[关闭]</title>
      <link>https://stackoverflow.com/questions/78668764/overfitting-detection-in-supervised-learning</link>
      <description><![CDATA[我很困惑在尝试检测模型的过度拟合时应该考虑什么。
假设我有一个分类问题，主要指标是 ROC-AUC。我将数据分为训练集和测试集。我对训练集进行交叉验证，并收集平均指标和具有最佳参数的模型。然后我使用这个模型来预测 X_test。
CV 指标：~0.75 ROC-AUC
测试：~0.74 ROC-AUC
但是当我执行 model(best_parameters).fit(X_train, y_train) 然后执行 .predict_proba(X_train) 时，我得到 ROC-AUC = 1.0。此外，在交叉验证期间，训练折叠指标为 1.0。
如果我的训练指标 = 1.0，这是否意味着模型过度拟合？或者我根本不应该根据训练指标来判断？还应该监控损失函数吗？]]></description>
      <guid>https://stackoverflow.com/questions/78668764/overfitting-detection-in-supervised-learning</guid>
      <pubDate>Tue, 25 Jun 2024 17:21:12 GMT</pubDate>
    </item>
    <item>
      <title>由于 keras 中的 SSL 错误，无法加载 MNIST 数据集...load_data() 函数</title>
      <link>https://stackoverflow.com/questions/78668638/unable-to-load-mnist-data-set-due-to-ssl-error-in-keras-load-data-function</link>
      <description><![CDATA[import keras
(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()
...

我目前开始使用机器学习，但由于错误，我无法加载 MNIST 数据集：

异常：https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 上的 URL 获取失败：无 -- [SSL：CERTIFICATE_VERIFY_FAILED] 证书验证失败：无法获取本地颁发者证书(_ssl.c:1000)

我确保一切都是最新的（macOS 版本 14.5、pip 版本 24.1、最新的 tensorflow 和 keras 库以及最新的 safari 和 vscode 版本）。我尝试重新安装 keras 几次，确保不要从 pip3 缓存中下载最新的 pip 24.1 版本。这个错误一直存在，我还没有找到解决办法。我唯一弄清楚的是，这是由 ...load_data() 函数导致的错误。
如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78668638/unable-to-load-mnist-data-set-due-to-ssl-error-in-keras-load-data-function</guid>
      <pubDate>Tue, 25 Jun 2024 16:48:10 GMT</pubDate>
    </item>
    <item>
      <title>Polars - 性能问题 - 尝试为每行创建一个新的数据框</title>
      <link>https://stackoverflow.com/questions/78668432/polars-issues-with-performance-attempting-to-create-a-new-dataframe-per-row</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78668432/polars-issues-with-performance-attempting-to-create-a-new-dataframe-per-row</guid>
      <pubDate>Tue, 25 Jun 2024 16:01:45 GMT</pubDate>
    </item>
    <item>
      <title>Keras model.export() 因模型中的 NoneType 形状而失败</title>
      <link>https://stackoverflow.com/questions/78666998/keras-model-export-fails-because-of-nonetype-shapes-in-model</link>
      <description><![CDATA[我正尝试微调 keras_cv 库中的 DeepLabV3Plus 模型以用于自定义数据集，但在尝试导出为 SavedModel 格式时，我收到此错误：
文件“C:\Users\u\.pyenv\pyenv-win\versions\3.10.2\lib\site-packages\keras\src\utils\traceback_utils.py”，第 731 行，位于 error_handler *
return fn(*args, **kwargs)

TypeError：调用 UpSampling2D.call() 时遇到异常。

* 不支持的操作数类型：&#39;NoneType&#39; 和 &#39;int&#39;

UpSampling2D.call() 收到的参数：
• input=tf.Tensor(shape=(None, None, None, 256), dtype=float32)

这很令人困惑，因为我在调用 DeepLabV3Plus.from_preset 时已将模型的输入形状指定为 [224,224,3]，但模型摘要显示所有层的 None 形状（请参阅此处了解 model.summary() 输出）。但是，从我看到的笔记本来看，即使您指定了输入形状，这也是预期的行为。
至于训练脚本，这是我使用的代码：
model = keras_cv.models.DeepLabV3Plus.from_preset(
&quot;mobilenet_v3_large_imagenet&quot;,
num_classes=NUM_CLASSES,
input_shape=[224,224,3],
load_weights=True
)

layers_to_train = 1
def disable_training(x): x.trainable = False
[disable_training(layer) for layer in model.layers[:-layers_to_train]]
model.summary()

model.compile(
optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),
loss=[keras.losses.CategoricalFocalCrossentropy(from_logits=False, alpha=class_weights, gamma=3)],
metrics=[keras.metrics.OneHotMeanIoU(num_classes=NUM_CLASSES), &#39;accuracy&#39;])

callback_cyclic = CyclicLR(base_lr = LEARNING_RATE, max_lr = MAX_LEARNING_RATE, step_size=STEP_SIZE, mode = CYCLIC_MODE)

history = model.fit(train_dataset, epochs=NUM_EPOCHS, batch_size=NUM_BATCH, validation_data=val_dataset, callbacks=[callback_cyclic])

model.export(savepath_dir+&quot;model.tf&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/78666998/keras-model-export-fails-because-of-nonetype-shapes-in-model</guid>
      <pubDate>Tue, 25 Jun 2024 11:14:12 GMT</pubDate>
    </item>
    <item>
      <title>当打开 cv 和 spyder 时如何安装 MASK RCNN？</title>
      <link>https://stackoverflow.com/questions/78666765/how-to-install-mask-rcnn-when-have-open-cv-and-spyder</link>
      <description><![CDATA[我正致力于通过 MASK RCNN 方法提取图像中的形状。但是当我尝试安装 maskrcnn 时，问题出现了，因为它与 Spyder 3.11 版本兼容。所以我去了 Python 网站下载它，但适用于 maskrcnn 的 3.7 和 3.6 Python 版本已经结束了。我无法下载它们来使用 mask RCNN。
我该如何解决这个问题？
我使用 Anaconda 提示符进行安装，但没有成功。每次我运行包含 maskrcnn 的代码时，都会出现错误，提示没有找到 keras 的模块：]]></description>
      <guid>https://stackoverflow.com/questions/78666765/how-to-install-mask-rcnn-when-have-open-cv-and-spyder</guid>
      <pubDate>Tue, 25 Jun 2024 10:27:35 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 CV/ML 识别重叠图片中的不同符号？</title>
      <link>https://stackoverflow.com/questions/78666370/how-to-recognize-different-symbols-in-a-picture-with-overlapping-using-cv-ml</link>
      <description><![CDATA[我有一张包含每个项目里程碑信息的图片。每个里程碑都用独特的符号在图表中标记。在图片中，我们有不同的三角形或正方形，颜色也不同。
我需要从图例中的符号中提取有关日期的信息。这意味着我需要知道每个符号及其图例的位置。然后在 x 轴和 y 轴上搜索临近日期。
里程碑图片
我尝试过使用 cv2 进行颜色识别。首先，我提取了 x-y 轴上的日期并保存了它们的位置。我对黄色菱形使用 cv2，效果很好。但是当涉及到红色或灰色时，因为有不同的符号，但都是红色。我无法仅使用 cv2 来区分它们。
cv2 中的传统计算机视觉方法无法处理重叠。例如有两种类型的红色三角形，一种指向左侧。面对所有这些问题，我无法找到一种好的方法来识别图例中的每个符号。你有什么建议吗？
也许训练 ML 是一个潜在的解决方案。我有大约 1000 张这样的图片。我不知道这是否足以训练一个模型。但是工作量也会很大。
我也试过模板匹配，但是根本不起作用。
import cv2
import numpy as np
import matplotlib.pyplot as plt

img = cv2.imread(&#39;7053.jpg&#39;)
logo = cv2.imread(&#39;yellow.png&#39;)
height, width, _ = logo.shape

cv2.imshow(&#39;logo&#39;, logo)
cv2.waitKey(0)
cv2.destroyAllWindows()

methods = [cv2.TM_CCOEFF, cv2.TM_CCOEFF_NORMED, cv2.TM_CCORR, cv2.TM_CCORR_NORMED, cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]
titles = [&#39;cv2.TM_CCOEFF&#39;, &#39;cv2.TM_CCOEFF_NORMED&#39;, &#39;cv2.TM_CCORR&#39;, &#39;cv2.TM_CCORR_NORMED&#39;, &#39;cv2.TM_SQDIFF&#39;, &#39;cv2.TM_SQDIFF_NORMED&#39;]

对于 i 在范围内（len（methods））：
curImg = img.copy()
method = methods[i]
result = cv2.matchTemplate(img, logo, method)
min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)

如果 method 在 [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED] 中：
top_left = min_loc
else:
top_left = max_loc

bottom_right = (top_left[0] + width, top_left[1] + 高度)
cv2.rectangle(curImg, 左上角, 右下角, 255, 10)

cv2.imshow(&#39;img&#39;, curImg)
cv2.waitKey(0)
]]></description>
      <guid>https://stackoverflow.com/questions/78666370/how-to-recognize-different-symbols-in-a-picture-with-overlapping-using-cv-ml</guid>
      <pubDate>Tue, 25 Jun 2024 09:04:21 GMT</pubDate>
    </item>
    <item>
      <title>尝试读取 .wav 文件，但只能转换 20 秒的对话</title>
      <link>https://stackoverflow.com/questions/78665946/trying-to-read-a-wav-file-but-was-able-to-convert-only-20s-conversation</link>
      <description><![CDATA[我尝试读取 .wav 文件，但只能将 20 秒的对话转换为文本。
 # 读取 .wav 文件的代码 
import Speech_recognition as sr
r = sr.Recognizer()
audio = r&quot;D:\Fraud_Call_Detection\audio1.wav&quot;
使用 sr.AudioFile(audio) 作为源：
audio = r.record(source)
print (&#39;完成！&#39;)

尝试：

text = (r.recognize_google(audio, language=&quot;en-HK&quot;))
print (text)

except Exception as e：
print (e)

输出：
]]></description>
      <guid>https://stackoverflow.com/questions/78665946/trying-to-read-a-wav-file-but-was-able-to-convert-only-20s-conversation</guid>
      <pubDate>Tue, 25 Jun 2024 07:33:04 GMT</pubDate>
    </item>
    <item>
      <title>使用不同的总 epoch 数，对同一 epoch 得出不同的结果</title>
      <link>https://stackoverflow.com/questions/78664794/different-results-for-the-same-epoch-using-different-number-of-total-epochs</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78664794/different-results-for-the-same-epoch-using-different-number-of-total-epochs</guid>
      <pubDate>Mon, 24 Jun 2024 22:35:04 GMT</pubDate>
    </item>
    <item>
      <title>使用 Cord-V2 数据集微调 LayoutLmv3</title>
      <link>https://stackoverflow.com/questions/78606543/fine-tuning-layoutlmv3-using-cord-v2-dataset</link>
      <description><![CDATA[我正在使用 CORD-v2 数据集对 LayoutLMv3 进行微调。我在数据预处理部分遇到了困难，特别是如何从图像中正确提取总量 (TTC)。我在网上找到的示例似乎使用了较旧的 CORD 数据集，该数据集的格式不同。新的 CORD-v2 数据集仅包含图像和地面实况标签。
如何解决这个问题？
我尝试过 YouTube 和 Hugging Face 中的示例，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78606543/fine-tuning-layoutlmv3-using-cord-v2-dataset</guid>
      <pubDate>Tue, 11 Jun 2024 09:22:25 GMT</pubDate>
    </item>
    </channel>
</rss>