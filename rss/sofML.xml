<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 18 Apr 2024 09:14:19 GMT</lastBuildDate>
    <item>
      <title>如何从 Neural Prophet 模型中提取线性回归系数？</title>
      <link>https://stackoverflow.com/questions/78346142/how-can-i-extract-linear-regression-coefficients-from-a-neural-prophet-model</link>
      <description><![CDATA[我使用 NP 作为我正在构建的预测工具的一部分。
我真的希望能够访问我的额外回归量的线性回归系数估计值，以便在我正在整理的一些洞察工作中使用。
在 Prophet 中，我可以使用 regressor_coefficients() 函数来执行此操作，但是我在 NP 文档中找不到有关如何执行此操作的任何内容。
任何帮助/建议或替代方法表示赞赏
谢谢
乔
尝试过查看 NP 文档并使用 Prophet 的 regressor_coefficients() 函数（不出所料，它不起作用）]]></description>
      <guid>https://stackoverflow.com/questions/78346142/how-can-i-extract-linear-regression-coefficients-from-a-neural-prophet-model</guid>
      <pubDate>Thu, 18 Apr 2024 08:57:53 GMT</pubDate>
    </item>
    <item>
      <title>当损失不减少时，我该怎么办？</title>
      <link>https://stackoverflow.com/questions/78345591/when-loss-dont-decrease-what-should-i-do</link>
      <description><![CDATA[我正在使用 LSTM、Fasttext 和 pytorch 构建情感分析模型。
我制作了一个 CustomDataset 和一个 ML 模型。
但我的模型不学习，损失值永远不会减少。
这种情况我应该检查什么？
首先，向阅读此内容的人致歉。我不知道如何提出好问题。
所以，我在这里留下了很多东西。
我关注了此内容中的许多部分
https://www.kaggle.com/code /arunmohan003/sentiment-analysis-using-lstm-pytorch
我的模型与该内容中的模型几乎相同
这是我的代码
类 SentimentLSTM(nn.Module):
    def __init__(自身、输入大小、隐藏大小、层数、输出尺寸):
        super(SentimentLSTM, self).__init__()
        self.hidden_​​size = 隐藏大小
        self.input_size = input_size
        self.num_layers = num_layers
        self.output_dim = 输出_dim
        
        self.lstm = nn.LSTM(input_size=self.input_size, hide_size=self.hidden_​​size, num_layers=num_layers,batch_first = True)
        
        self.线性 = nn.Linear(self.hidden_​​size, self.output_dim)
        self.dropout = nn.Dropout(0.3)
        self.sig = nn.Sigmoid()
        
    def 前向（自身，x，隐藏）：
        # input_size = torch.size([16(batch_size), 32(seq_len), 100(embedded_dim)])
        批量大小 = x.size(0)
        lstm_out, (hn, cn) = self.lstm(x, 隐藏)
        
        drop_out = self.dropout(lstm_out)
        re_drop_out = drop_out.reshape([-1, self.hidden_​​size])
        
        线性输出 = self.线性(re_drop_out)
        
        sig_out = self.sig(线性输出)
        sig_out = sig_out.view(batch_size, -1)
        sig_out = sig_out[:, -1]
        
        返回sig_out
        
    def init_hidden(自身,batch_size,设备):
        h0 = torch.zeros((self.num_layers, batch_size, self.hidden_​​size), dtype=torch.float32).to(device)
        c0 = torch.zeros((self.num_layers, batch_size, self.hidden_​​size), dtype = torch.float32).to(device)
        隐藏 = (h0, c0)
        
        返回隐藏

&lt;前&gt;&lt;代码&gt;num_layers = 1
输入大小 = 100
隐藏大小 = 128
输出调暗 = 1

lstm_model = SentimentLSTM(input_size=input_size,hidden_​​size=hidden_​​size,num_layers=num_layers,output_dim=output_dim)

loss_func = nn.BCELoss()
优化器 = torch.optim.Adam(lstm_model.parameters(), lr = lr)

&lt;前&gt;&lt;代码&gt;打印(lstm_model)
情绪LSTM(
  (lstm): LSTM(100, 128, batch_first=True)
  （线性）：线性（in_features=128，out_features=1，偏差=True）
  (dropout): Dropout(p=0.3, inplace=False)
  (sig): Sigmoid()
）

这是模型训练代码
def model_train（数据加载器，模型）：
    
    训练损失 = []
    训练加速度 = 0.0
    模型.train()
    隐藏 = model.init_hidden(batch_size, 设备)

    对于输入，tqdm(dataloader) 中的标签：
        输入，标签=输入.to（设备），标签.to（设备）
        lstm_model.zero_grad()

        pred = 模型（输入，隐藏）
        #print(pred.shape, labels.shape)
        损失 = loss_func(pred, 标签)
        优化器.zero_grad()
        loss.backward()
        train_losses.append(loss.item())

        准确度 = acc(预测值, 标签)

        train_acc += 准确度


    epoch_train_loss = np.mean(train_losses)
    epoch_train_acc = train_acc/len(train_dataloader.dataset)
        
    返回epoch_train_loss、epoch_train_acc

epoch_tr_acc, epoch_tr_loss = [], []
对于范围内的纪元（纪元）：
    epoch_train_loss, epoch_train_acc = model_train(train_dataloader, lstm_model)
    epoch_tr_loss.append(epoch_train_loss)
    epoch_tr_acc.append(epoch_train_acc)

用 10 个句子和 1000 个时期进行测试
&lt;前&gt;&lt;代码&gt;纪元 1
训练损失：0.7045215368270874 验证损失：1.0
训练精度：37.5 验证精度：67.02091693878174
===================================================
501纪元
训练损失：0.6963606029748917 验证损失：1.0
训练精度：37.5 验证精度：67.02091693878174
===================================================
1001纪元
训练损失：0.7010972499847412 验证损失：1.0
训练精度：37.5 验证精度：67.02091693878174
===================================================

内容太长，实在抱歉。如果您想要更简单的信息，请发表评论...
我已经尝试过更改损失函数、批量大小、num_word（序列长度）和激活函数、添加线性层、重塑输出
我应该检查我的模型的哪些内容？]]></description>
      <guid>https://stackoverflow.com/questions/78345591/when-loss-dont-decrease-what-should-i-do</guid>
      <pubDate>Thu, 18 Apr 2024 07:24:37 GMT</pubDate>
    </item>
    <item>
      <title>如何在没有类标签的情况下可视化实例预测？</title>
      <link>https://stackoverflow.com/questions/78345121/how-to-visualize-instance-predictions-but-without-class-labels</link>
      <description><![CDATA[导入 matplotlib.pyplot 作为 plt
Predicted_images_path = os.path.abspath(“/content/predicted”)
dataset_dicts_validation = DatasetCatalog.get(&#39;void-detection-2-valid&#39;)
对于 dataset_dicts_validation 中的 d：
    im = cv2.imread(d[“文件名”])
    输出 = 预测器(im)
    v = 展示台(im[:, :, ::-1],
                   元数据=元数据，
                   比例=0.5，
                   instance_mode=ColorMode.IMAGE_BW
    ）
    out = v.draw_instance_predictions(outputs[“instances”].to(“cpu”))
    图 = plt.figure(frameon=False, dpi=1)
    图.set_size_英寸(1024,1024)
    ax = plt.Axes(图, [0., 0., 1., 1.])
    ax.set_axis_off()
    图.add_axes(ax)
    ax.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB),spect=&#39;auto&#39;)
    Fig.savefig(f&quot;{predicted_images_path}/{d[&#39;file_name&#39;].split(&#39;/&#39;)[-1]}&quot;)

分割图像：

我使用 detectorron2 来训练模型并对检测到的空洞进行预测。如何仅标记分段而不使用文字的形状。
二值图像：
]]></description>
      <guid>https://stackoverflow.com/questions/78345121/how-to-visualize-instance-predictions-but-without-class-labels</guid>
      <pubDate>Thu, 18 Apr 2024 05:51:09 GMT</pubDate>
    </item>
    <item>
      <title>在 OCI OML 中使用关联规则训练模型时出现错误</title>
      <link>https://stackoverflow.com/questions/78345096/getting-an-error-while-training-a-model-with-association-rule-in-oci-oml</link>
      <description><![CDATA[我正在使用 OCI 的机器学习功能来对我的数据使用关联规则模型。
我有以下设置。
设置 = {&#39;ASSO_MIN_SUPPORT&#39;:&#39;0.04&#39;,
&#39;ASSO_MIN_CONFIDENCE&#39;:&#39;0.1&#39;,
&#39;ASSO_MAX_RULE_LENGTH&#39;: &#39;2&#39;,
“ODMS_ITEM_ID_COLUMN_NAME”:“PRODUCT_NAME”}
ar_mod = oml.ar(**设置)
ar_mod = ar_mod.fit(SALES_TRANS_CUST, case_id = &#39;CUST_ID&#39;)
我收到以下错误：
oracledb.thick_impl._raise_from_info oracledb.exceptions.DatabaseError：ORA-40104：模型构建的训练数据无效
我正在尝试使用 fit() 方法训练模型，但它给出错误。]]></description>
      <guid>https://stackoverflow.com/questions/78345096/getting-an-error-while-training-a-model-with-association-rule-in-oci-oml</guid>
      <pubDate>Thu, 18 Apr 2024 05:42:48 GMT</pubDate>
    </item>
    <item>
      <title>滴灌管的自动检测和测量</title>
      <link>https://stackoverflow.com/questions/78344991/automating-detection-and-measurement-of-drip-irrigation-pipes</link>
      <description><![CDATA[我正在使用无人机图像来自动从中提取一些数据。我想自动检测和测量田野中布置的灌溉线的长度，如下所示。我可以采取什么方法来实现这一目标？图像处理中是否有合适的基于规则的技术，例如颜色、边缘检测等？或者我应该使用一些对象检测技术？如果使用这些，注释和训练模型的最佳方法是什么？
该图像如下所示，下面显示了放大版本。

在此图像（上图的放大部分）中，您可以看到滴水线（其颜色始终为黑色，但有时在更复杂的背景和环境中，它们也可能并不总是直线，也可能是弯曲的）

期待听到社区的消息。
问候，
马卡兰德]]></description>
      <guid>https://stackoverflow.com/questions/78344991/automating-detection-and-measurement-of-drip-irrigation-pipes</guid>
      <pubDate>Thu, 18 Apr 2024 05:09:44 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 Python TensorFlow 2.x 模型执行不通过 API 调用使用 eager 模式？</title>
      <link>https://stackoverflow.com/questions/78344802/why-does-my-python-tensorflow-2-x-model-execution-not-use-eager-mode-by-api-call</link>
      <description><![CDATA[我正在尝试将 TensorFlow 设置为 eager 模式，因为我的模型是为了在 eager 模式（而不是图形模式）下运行而构建的。
我发现我的推理请求中有一部分处于非急切模式，并且这些请求失败了。为什么 10% 的请求会发生这种情况，这完全是一个谜。
我添加了一个代码块来进行健全性检查，并尝试强制 TF 在急切模式下运行（如果不是）。奇怪的是，当 TF 进入图形模式时，代码继续失败。
现在，我添加了一些日志来查看 TF 是否进入 eager 模式。在这两种情况下，布尔值都返回为 False。
代码在这里：
 如果不是 tf.executing_eagerly():
            logger.info(“未启用急切执行。正在启用急切执行。”, kv=self.stats_tags)
            tf.compat.v1.enable_eager_execution()
            logger.info(f“启用热切执行模式：{tf.executing_eagerly()}”, kv=self.stats_tags)
            tf.config.experimental_run_functions_eagerly(真)
            logger.info(f“启用热切执行模式：{tf.executing_eagerly()}”, kv=self.stats_tags)

对正在发生的事情有什么想法吗？为什么？
我预计上述 API 调用之一会将 TensorFlow 置于 eager 模式。]]></description>
      <guid>https://stackoverflow.com/questions/78344802/why-does-my-python-tensorflow-2-x-model-execution-not-use-eager-mode-by-api-call</guid>
      <pubDate>Thu, 18 Apr 2024 04:02:55 GMT</pubDate>
    </item>
    <item>
      <title>针对一系列产品微调 SDXL 的最有效方法</title>
      <link>https://stackoverflow.com/questions/78344547/most-efficient-way-to-fine-tune-sdxl-for-range-of-product</link>
      <description><![CDATA[我想在一系列产品上使用 LoRA 微调 SDXL，以便 SDXL 稍后可以生成这些产品的图像。
我有很多产品。最有效的微调方法是什么？
我是只为所有产品训练一个 LoRA 还是为每个产品或任何其他替代品训练多个 LoRA？该产品包括家具和其他可销售物品。]]></description>
      <guid>https://stackoverflow.com/questions/78344547/most-efficient-way-to-fine-tune-sdxl-for-range-of-product</guid>
      <pubDate>Thu, 18 Apr 2024 02:30:56 GMT</pubDate>
    </item>
    <item>
      <title>流式 LightGBM 数据集构建在训练中冻结</title>
      <link>https://stackoverflow.com/questions/78344537/streaming-lightgbm-dataset-construction-freezes-on-training</link>
      <description><![CDATA[我一直在尝试使用参考数据集（称为 ref_dataset）以流方式在 Python 中构建 LightGBM 数据集。我不确定它是如何完成的，它涉及调用 Dataset 类中看似非公共的方法。
我已经尝试过：
label_column = “标签”
权重列=“权重”
ref_dataset = lightgbm.Dataset(
   Sample_df.drop(列=[标签列，权重列])
   标签=sample_df[标签_列],
   权重=sample_df[权重列],
   参数=配置，
   **（ref_dataset_kwargs 或 {}），
）
ref_dataset.construct()
temp_dataset = lightgbm.Dataset（无，参考= ref_dataset，params = ref_dataset.get_params（））
# train_filenames_and_part_infos 只是一个元组列表[filename,part_info_dict]
估计行数=总和（
    part_info[“num_rows”] for _，train_filenames_and_part_infos 中的part_info
）
temp_dataset._init_from_ref_dataset(estimated_num_rows, ref_dataset._handle)

权重列表 = []
标签列表=[]
# 这个循环实际上不是我的代码，它更复杂，但基本上是它的作用
对于文件名，train_filenames_and_part_infos 中的 _：
    tbl: pyarrow.Table = load_from_file(文件名)
    标签 = tbl[label_column].to_pandas().to_numpy()
    权重 = tbl[weight_column].to_pandas().to_numpy()

    labels_list.append(标签)
    weights_list.append(权重)
    tbl = tbl.drop_columns([label_column, Weight_column])
    np_array: np.ndarray = tbl.to_pandas().to_numpy()
    如果 temp_dataset._start_row + np_array.shape[0] &gt; temp_dataset.num_data():
        raise RuntimeError(“数据集太小，无法容纳数据”)
    temp_dataset._push_rows(np_array)

all_weights = np.concatenate(weights_list)
all_labels = np.concatenate(labels_list)
实际长度 = all_weights.shape[0]
# 不幸的是，由于各种原因，这个估计并不准确
extra_zeros_features = np.zeros(
     （估计行数 - 实际长度，temp_dataset.num_feature()），dtype=np.float32
）
temp_dataset._push_rows(extra_zeros_features)
_LIB.LGBM_DatasetMarkFinished(temp_dataset._handle)
extra_zeros = np.zeros(估计行数 - 实际长度, dtype=np.float32)
temp_dataset.set_weight(np.concatenate([all_weights, extra_zeros]))
temp_dataset.set_label(np.concatenate([all_labels, extra_zeros]))

lightgbm.train(
    params=config, # 包含分布式投票并行训练的网络参数
    train_set=temp_dataset，
    num_boost_round=100,
    valid_sets=valid_sets, # 在其他地方初始化
    valid_names=valid_names, # 在其他地方初始化
    init_model=starting_model, # 不是很有必要
    **lightgbm_train_kwargs, # 空
）

不幸的是，当我运行这段代码时，我得到了这个控制台输出（有些行可能是无序的，因为我实际上是在分布式上运行它，并且日志是聚合的；我已经做了一些简单的编辑删除干扰线）：
[LightGBM] [Info] 总 bin 137618
[LightGBM] [Info] 尝试绑定端口 50627...
[LightGBM] [Info] 绑定端口50627成功
[LightGBM] [信息] 聆听...
[LightGBM] [Info] 训练集中的数据点数量：3934363，使用的特征数量：1382
[LightGBM] [信息] 连接到等级 0
[LightGBM] [信息] 连接到排名 1
[LightGBM] [信息] 连接到等级 2
[LightGBM] [信息] 连接到等级 3
[LightGBM] [信息] 已连接至等级 4
[LightGBM] [信息] 已连接至排名 5
[LightGBM] [信息] 已连接至排名 6
[LightGBM] [信息] 已连接至排名 8
[LightGBM] [Info] 本地排名：7，机器总数：9
[LightGBM] [Info] 自动选择col-wise多线程，测试开销为5.318313秒。
[LightGBM] [Info] 从分数-0.000000开始训练

然后它就坐在那里，CPU 和网络都处于空闲状态。我没有看到它在几个小时内取得任何进展。我已经检查了所有的排名，是不是我做错了什么？我还如何使用给定的样本进行构建？
更多信息：
检查空闲 Python 进程的堆栈跟踪显示代码卡在：
更新（lightgbm/basic.py:3891）
火车（lightgbm/engine.py:276）
...我的代码...

对于我正在使用的 LightGBM 版本 (4.3.0)，这对应于代码：
_safe_call(_LIB.LGBM_BoosterUpdateOneIter(
                self._handle,
                ctypes.byref(is_finished)))
]]></description>
      <guid>https://stackoverflow.com/questions/78344537/streaming-lightgbm-dataset-construction-freezes-on-training</guid>
      <pubDate>Thu, 18 Apr 2024 02:25:39 GMT</pubDate>
    </item>
    <item>
      <title>最后一个维度的有效乘法</title>
      <link>https://stackoverflow.com/questions/78344508/effective-multiplication-over-last-dimension</link>
      <description><![CDATA[我有两个火炬张量 - A 形状为 (15, 100, 256) 和 B 形状为 (120, 2010, 256)。如何对最后一个维度进行有效乘法并获得形状 (15, 100, 120, 2010) 的张量。我尝试了类似 torch.einsum(&#39;ijk, mnk -&gt; ijmn&#39;, A, B) 的方法，但据我了解，这种方法隐式创建中间张量并需要大量内存和时间。我还尝试了 opt_einsum 库，但与 torch.einsum 相比，在时间和内存使用方面没有看到很大的差异
当然，我可以在循环中完成它，但我想要得到在时间和内存使用方面都有效的解决方案。预先感谢您]]></description>
      <guid>https://stackoverflow.com/questions/78344508/effective-multiplication-over-last-dimension</guid>
      <pubDate>Thu, 18 Apr 2024 02:13:36 GMT</pubDate>
    </item>
    <item>
      <title>模型在来自麦克风的输入上运行良好，但在从 Websocket 流式传输后效果很差</title>
      <link>https://stackoverflow.com/questions/78344455/model-works-well-on-input-from-microphone-but-terribly-after-its-streamed-from</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78344455/model-works-well-on-input-from-microphone-but-terribly-after-its-streamed-from</guid>
      <pubDate>Thu, 18 Apr 2024 01:51:50 GMT</pubDate>
    </item>
    <item>
      <title>使用矩阵分解的复制 ML.NET 示例/教程电影推荐器</title>
      <link>https://stackoverflow.com/questions/78343327/duplication-ml-net-example-tutorial-movie-recommender-using-matrix-factorization</link>
      <description><![CDATA[我是机器学习新手，但我有 C# 经验，这就是为什么我想选择 Ml.net 来熟悉该主题。
当我掌握了这个概念后，我决定创建一个电影推荐模型，该模型将采用以前的评论并推荐具有与 Microsoft ML.NET 教程中提供的相同示例的电影。
我的问题是，当我在创建管道时在下面的函数中构建和训练模型时，我没有看到Recommendation() 的方法调用。顺便说一下，我使用的是VS2022和.NET 8.0。谁能告诉我为什么？
使用 Microsoft.ML；
使用 Microsoft.ML.Trainers；
使用 Microsoft.ML.Data；
使用 Microsoft.ML.Transforms；

ITransformer BuildAndTrainModel（MLContext mlContext，IDataView TrainingDataView）
{
    //第 3 步：通过对 userId 和 movieID 这两个特征进行编码来转换数据。这些编码特征将作为输入提供
    // 到我们的 MatrixFactorizationTrainer。
    var dataProcessingPipeline = mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: &quot;userIdEncoded&quot;, inputColumnName: nameof(MovieRating.userId))
                   .Append(mlContext.Transforms.Conversion.MapValueToKey(outputColumnName: &quot;movieIdEncoded&quot;, inputColumnName: nameof(MovieRating.movi​​eId)));

    //指定MatrixFactorization训练器的选项
    MatrixFactorizationTrainer.Options 选项 = new MatrixFactorizationTrainer.Options();
    options.MatrixColumnIndexColumnName = &quot;userIdEncoded&quot;;
    options.MatrixRowIndexColumnName = &quot;movieIdEncoded&quot;;
    options.LabelColumnName = &quot;标签&quot;;
    选项.NumberOfIterations = 20;
    选项.ApproximationRank = 100;

    //第4步：创建训练管道
    var TrainingPipeLine = dataProcessingPipeline.Append(mlContext.Recommendation().Transforms.MatrixFactorization(options));

   

    Console.WriteLine(“================训练模型==============”);
    ITransformer模型=trainingPipeLine.Fit(trainingDataView);

    返回模型；
}


我在 Github 代码中进行了一些搜索，但没有得到任何提示。]]></description>
      <guid>https://stackoverflow.com/questions/78343327/duplication-ml-net-example-tutorial-movie-recommender-using-matrix-factorization</guid>
      <pubDate>Wed, 17 Apr 2024 19:10:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 pyTorch 推荐汽车的聊天机器人 [关闭]</title>
      <link>https://stackoverflow.com/questions/78342744/chatbot-which-recommends-cars-using-pytorch</link>
      <description><![CDATA[我用 pyTorch 构建了一个聊天机器人，但它不起作用，因为事实上，该机器人理解的输入太少。
我来自德国，所以我构建了一个可以用德语运行的机器人，也许这就是问题所在，因为在预处理过程中单词的词干会减少，但我不确定这是否是问题所在。
这是 GitHub 链接：https://github.com/konstantinByr/Chatbot
我已经尝试添加更多层并使用不同的超参数。
目前神经网络有五层、五个批规范和 dropout。我还尝试使用自我调整学习率（没有成功）并将纪元数从 100 更改为 10.000.000。目前我不知道如何才能将机器人调整到正确的设置。]]></description>
      <guid>https://stackoverflow.com/questions/78342744/chatbot-which-recommends-cars-using-pytorch</guid>
      <pubDate>Wed, 17 Apr 2024 17:13:33 GMT</pubDate>
    </item>
    <item>
      <title>Keras-rl2 错误与 Tensorflow 的兼容性</title>
      <link>https://stackoverflow.com/questions/78340927/keras-rl2-error-compability-with-tensorflow</link>
      <description><![CDATA[我目前在使用 keras-rl2 和 tensorflow 时遇到问题，我不知道为什么，我只是在互联网上搜索 keras-rl2、tensorflow 和 keras 文档，但没有找到解决方案。
目前，我想将keras-rl2与最新版本的tensorflow（2.16.1和keras 3）一起使用，但在使用时遇到了一些这样的错误
from rl.agents import DKQAgent

ModuleNotFoundError Traceback（最近一次调用最后一次）
单元格 In[37]，第 1 行
----&gt; 1 导入rl.agents
      3 print(&quot;RL 代理库版本：&quot;, rl.agents.__version__)

文件 D:\Anaconda\Lib\site-packages\rl\agents\__init__.py:2
      1 从.dqn导入DQNAgent、NAFAgent、ContinuationDQNAgent
----&gt; 2 从.ddpg导入DDPGAgent
      3 从.cem导入CEMAgent
      4 从.sarsa导入SarsaAgent、SARSAAgent

文件 D:\Anaconda\Lib\site-packages\rl\agents\dqn.py:8
      5 从tensorflow.keras.layers导入Lambda，输入，层，密集
      7.从rl.core导入Agent
----&gt; 8 从 rl.policy 导入 EpsGreedyQPolicy、GreedyQPolicy
      9 从 rl.util 导入 *
     12 defmean_q(y_true, y_pred):

文件 D:\Anaconda\Lib\site-packages\rl\core.py:8
      4 将numpy导入为np
      5 从tensorflow.keras.callbacks导入历史记录
      7 从 rl.callbacks 导入 (
----&gt; 8 回调列表，
      9 测试记录器，
     10 训练情节记录器，
     11 训练间隔记录器，
     12 展示台
     13）
     16级代理：
     17 “”“”所有已实现代理的抽象基类。
     18
     19 每个代理通过首先观察环境（由 `Env` 类定义）进行交互
   （...）
     37 处理器（`Processor` 实例）：有关详细信息，请参阅[处理器](#processor)。
     38、“”“”

文件 D:\Anaconda\Lib\site-packages\rl\callbacks.py:12
      9 fromtensorflow.python.keras.callbacks import Callback as KerasCallback, CallbackList as KerasCallbackList
     10 从tensorflow.python.keras.utils.generic_utils导入Progbar
---&gt; 12类回调（KerasCallback）：
     13 def _set_env（自身，环境）：
     14 self.env = 环境

ModuleNotFoundError：没有名为“keras.utils.generic_utils”的模块

当我认为我只需要将其降级到某个版本（例如 2.13.0 和 keras 2.13.0）时，它仍然会出现这样的错误
&lt;前&gt;&lt;代码&gt;-------------------------------------------------------- -------------------------------------------
ImportError Traceback（最近一次调用最后一次）
单元格 In[18]，第 1 行
----&gt; 1 从 rl.agents.dqn 导入 DQNAgent

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\agents\__init__.py:1
----&gt; 1 从.dqn导入DQNAgent、NAFAgent、ContinuationDQNAgent
      2 从.ddpg导入DDPGAgent
      3 从.cem导入CEMAgent

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\agents\dqn.py:7
      4 从tensorflow.keras.models导入模型
      5 从tensorflow.keras.layers导入Lambda，输入，层，密集
----&gt; 7.从rl.core导入Agent
      8 从 rl.policy 导入 EpsGreedyQPolicy、GreedyQPolicy
      9 从 rl.util 导入 *

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\core.py:7
      4 将numpy导入为np
      5 从tensorflow.keras.callbacks导入历史记录
----&gt; 7 从 rl.callbacks 导入 (
      8 回调列表，
      9 测试记录器，
     10 训练情节记录器，
     11 训练间隔记录器，
     12 展示台
     13）
     16级代理：
     17 “”“”所有已实现代理的抽象基类。
     18
     19 每个代理通过首先观察环境（由 `Env` 类定义）进行交互
   （...）
     37 处理器（`Processor` 实例）：有关详细信息，请参阅[处理器](#processor)。
     38、“”“”

文件 D:\Anaconda\envs\AI\Lib\site-packages\rl\callbacks.py:8
      6 将 numpy 导入为 np
      7 将tensorflow导入为tf
----&gt; 8 从tensorflow.keras导入__version__作为KERAS_VERSION
      9 fromtensorflow.python.keras.callbacks import Callback as KerasCallback, CallbackList as KerasCallbackList
     10 从tensorflow.python.keras.utils.generic_utils导入Progbar

ImportError：无法从“tensorflow.keras”导入名称“__version__”（D:\Anaconda\envs\AI\Lib\site-packages\keras\api\_v2\keras\__init__.py）

任何人都可以给我一个解释或解决方案，为什么它总是错误？
感谢您的关心]]></description>
      <guid>https://stackoverflow.com/questions/78340927/keras-rl2-error-compability-with-tensorflow</guid>
      <pubDate>Wed, 17 Apr 2024 12:20:33 GMT</pubDate>
    </item>
    <item>
      <title>机器学习模型中分类数据平均二进制编码方法的澄清</title>
      <link>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</link>
      <description><![CDATA[有很多方法可以将分类数据转换为用于各种统计任务的数值数据。然而，大多数编码方法（例如 One-Hot 编码）会创建更多数据集列，从而产生高维数据。
因此，我引入了一种称为平均二进制编码的方法，该方法在训练模型中应用二进制数据表示。方法如下：

哪里|N|是分类数据X中二进制值的长度，B是分类数据X的二进制表示。
&lt;前&gt;&lt;代码&gt;|分类数据 |应用于配方|编码数据|
| ---------------- | -------------------------------------------------- -------------------------------------------------- --| ------------------ |
|男 | (0+1+0+0+1+1+0+1+0+1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0 +1+1+0+0+1+0+1) ÷ 32 | 0.46875 |
|女 | (0+1+0+0+0+1+1+0+0+1+1+0+0+1+0+1+0+1+1+0+1+1+0+1+0 +1+1+0+0+0+0+1+0+1+1+0+1+1+0+0+0+1+1+0+0+1+0+1) ÷ 48 | 0.4791666666666667 |
|是的 | (0+1+0+1+1+0+0+1+0+1+1+0+0+1+0+1+0+1+1+1+0+0+1+1) ÷ 24 | 0.5416666666666666 |
|没有 | (0+1+0+0+1+1+1+0+0+1+1+0+1+1+1+1) ÷16 | 0.625 | 0.625
| 1 | (0+0+1+1+0+0+0+1) ÷ 8 | 0.375 | 0.375
| 0 | (0+0+1+1+0+0+0+0) ÷ 8 | 0.25 | 0.25

例如，
分类数据“男性”的二进制表示为 01001101011000010110110001100101。
该二进制数据的长度是 32。
因此，根据公式，编码值为0.46875。
我想进一步了解这种编码方法，看看它是否适用于统计模型。
对分类数据进行编码是否有任何具体注意事项或限制？]]></description>
      <guid>https://stackoverflow.com/questions/78339753/clarification-on-average-binary-encoding-method-for-categorical-data-in-machine</guid>
      <pubDate>Wed, 17 Apr 2024 09:09:55 GMT</pubDate>
    </item>
    <item>
      <title>安装Tensorflow（构建pip包）</title>
      <link>https://stackoverflow.com/questions/78291576/installing-tensorflow-building-pip-package</link>
      <description><![CDATA[我正在尝试在 WSL2 上安装tensorflow 2.6.0。我遵循指南（https://www.tensorflow.org/install/source?hl =pl）以及之后：
bazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow --config=cuda

我有一个错误：
自动配置警告：未设置“TMP”环境变量，默认使用“C:\Windows\Temp”
错误：跳过&#39;//tensorflow/tools/pip_package:wheel&#39;：没有这样的目标&#39;//tensorflow/tools/pip_package:wheel&#39;：目标&#39;wheel&#39;未在/home/定义的包&#39;tensorflow/tools/pip_package&#39;中声明jakmacc/tensorflow/tensorflow/工具/pip_package/BUILD
警告：目标模式解析失败。
错误：没有这样的目标&#39;//tensorflow/tools/pip_package:wheel&#39;：目标&#39;wheel&#39;未在/home/jakmacc/tensorflow/tensorflow/tools/pip_package/BUILD定义的包&#39;tensorflow/tools/pip_package&#39;中声明
信息：经过时间：10.827 秒
信息：0 个进程。
失败：构建未成功完成（已加载 2 个包）

不知道怎么解决
我想解决这个错误。
我也尝试了该命令：
bazel build //tensorflow/tools/pip_package:wheel --repo_env=WHEEL_NAME=tensorflow_cpu
]]></description>
      <guid>https://stackoverflow.com/questions/78291576/installing-tensorflow-building-pip-package</guid>
      <pubDate>Mon, 08 Apr 2024 09:38:59 GMT</pubDate>
    </item>
    </channel>
</rss>