<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 12 Jan 2024 12:25:41 GMT</lastBuildDate>
    <item>
      <title>无法对具有 4 个键列和一个索引列的缩放数据执行逆变换</title>
      <link>https://stackoverflow.com/questions/77806320/failure-to-perform-inverse-transform-of-scaled-data-with-4-key-columns-and-an-in</link>
      <description><![CDATA[我正在尝试使用简单的 LSTM 模型来预测太阳能产量，因此，每当我尝试运行代码行时都会遇到问题，它会给我错误
这是我用来预测错误点的完整代码
df[&#39;DateTime&#39;] = df[&#39;Date&#39;].astype(str) + &#39; &#39; + df[&#39;Time&#39;].astype(str)
df = df.drop([&#39;日期&#39;, &#39;时间&#39;], axis=1)
df = df.set_index(&#39;日期时间&#39;)
features = [&#39;温度(°C)&#39;, &#39;风速(m/s)&#39;, &#39;SolarIrrad(W/m2)&#39;]
目标 = &#39;太阳能光伏发电（瓦）&#39;

train_size = int(len(df) * 0.8)
训练，测试 = df.iloc[:train_size], df.iloc[train_size:]

定标器=标准定标器()
scaler.fit(训练[特征])
train_scaled = scaler.transform(train[特征])
test_scaled = scaler.transform(测试[特征])

def create_sequences(数据, target_index, seq_length):
    X、y = []、[]
    对于范围内的 i(len(data)-seq_length)：
        序列=数据[i:(i+seq_length)]
        目标值 = 数据[i+seq_length, 0]
        # 将序列和目标附加到列表中
        X.append(序列)
        y.append(目标值)
    # 将列表转换为 numpy 数组
    X = np.array(X)
    y = np.array(y)
    返回 X, y
序列长度 = 4

X_train, y_train = create_sequences(train_scaled, 目标, seq_length)
X_test, y_test = create_sequences(test_scaled, 目标, seq_length)

模型=顺序（）
model.add(LSTM(单位=50，激活=&#39;relu&#39;，input_shape=(X_train.shape[1]，X_train.shape[2])))
model.add(密集(单位=1))
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)

Early_stopping = EarlyStopping（监视器=&#39;val_loss&#39;，耐心= 5，restore_best_weights = True）

历史= model.fit（X_train，y_train，epochs = 50，batch_size = 32，validation_split = 0.2，callbacks = [early_stopping]，verbose = 1）

y_pred = model.predict(X_test)

concatenated_pred = np.concatenate([X_test_last_col, y_pred_last_col], axis=-1)

错误：
ValueError Traceback（最近一次调用最后一次）
&lt;ipython-input-43-cc4afc30ab89&gt;在&lt;细胞系：6&gt;()
4
5 # 沿最后一个轴连接
6 concatenated_pred = np.concatenate([X_test_last_col, y_pred_last_col], axis=-1)
7
8 # 逆变换
/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py in concatenate(*args, **kwargs)
ValueError：所有输入数组必须具有相同的维数，但索引 0 处的数组有 3 个维度，索引 1 处的数组有 2 个维度

我期待它成功地进行逆变换]]></description>
      <guid>https://stackoverflow.com/questions/77806320/failure-to-perform-inverse-transform-of-scaled-data-with-4-key-columns-and-an-in</guid>
      <pubDate>Fri, 12 Jan 2024 11:43:14 GMT</pubDate>
    </item>
    <item>
      <title>如何在时间序列 LSTM 模型中将数据拆分为训练集、验证集和测试集？</title>
      <link>https://stackoverflow.com/questions/77806128/how-to-split-my-data-into-training-validation-and-testing-sets-in-a-time-series</link>
      <description><![CDATA[我遇到了将数据拆分为训练/验证/测试集的不同策略（嵌套、K-Fold 等），但我不确定该选择哪一种。我想做的是从海面无人机的运动中估计波浪参数。无人机在不同设置下遵循特定的轨迹。
我不知道进行多步骤验证是否与我的案例相关。我想检查我的模型是否过度拟合，是否有可能扩充我的数据集。]]></description>
      <guid>https://stackoverflow.com/questions/77806128/how-to-split-my-data-into-training-validation-and-testing-sets-in-a-time-series</guid>
      <pubDate>Fri, 12 Jan 2024 11:09:31 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Roberta 计算单词和句子嵌入？</title>
      <link>https://stackoverflow.com/questions/77805776/how-to-calculate-word-and-sentence-embedding-using-roberta</link>
      <description><![CDATA[我正在尝试使用 Roberta 计算单词和句子嵌入，对于单词嵌入，我从 RobertaModel 类中提取最后一个隐藏状态 outputs[0]，但是我不确定这是否是正确的计算方法。
至于句子嵌入，我不知道如何计算它们，这是我尝试过的代码：
从 Transformers 导入 RobertaModel、RobertaTokenizer
进口火炬

模型 = RobertaModel.from_pretrained(&#39;roberta-base&#39;)
tokenizer = RobertaTokenizer.from_pretrained(&#39;roberta-base&#39;)
Captions = [“示例标题”、“lorem ipsum”、“这只鸟是黄色的，有红色翅膀”、“嗨”、“示例”]

encoded_captions = [tokenizer.encode(caption) 用于字幕中的字幕]

# 用 0 将序列填充到相同的长度
max_len = max(len(seq) 用于编码字幕中的 seq)
padded_captions = [seq + [0] * (max_len - len(seq)) 对于encoded_captions中的seq]

# 转换为批量大小为 5 的 PyTorch 张量
input_ids = torch.tensor(padded_captions)

输出=模型(input_ids)
word_embedding = 输出[0].连续()
句子嵌入 = ??????

如何使用 Roberta 计算单词和句子嵌入？]]></description>
      <guid>https://stackoverflow.com/questions/77805776/how-to-calculate-word-and-sentence-embedding-using-roberta</guid>
      <pubDate>Fri, 12 Jan 2024 10:05:01 GMT</pubDate>
    </item>
    <item>
      <title>使用列表存储的梯度下降导致多变量优化图像处理算法中的除零误差</title>
      <link>https://stackoverflow.com/questions/77805644/gradient-descent-using-list-storage-resulting-in-division-by-zero-error-in-image</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77805644/gradient-descent-using-list-storage-resulting-in-division-by-zero-error-in-image</guid>
      <pubDate>Fri, 12 Jan 2024 09:39:27 GMT</pubDate>
    </item>
    <item>
      <title>标准化流程的转变[关闭]</title>
      <link>https://stackoverflow.com/questions/77805312/transformation-in-normalizing-flow</link>
      <description><![CDATA[我正在实现一个基于流程的模型。解码 (z-&gt;x) 步骤的仿射变换为： x_{i} = f(x_{i-1}) = x_{i-1}*exp(s) + t，编码步骤为： x_ {i-1} = f_1(x_{i}) = (x_{i} - t)/ exp(s)。
我的问题是，由于该函数是双射的，我可以使用 f_1 进行解码，使用 f 进行编码吗？我将从 z ~ N(0, 1) 到 x ~ N(mu, var) 的仿射变换视为重新参数化技巧： x_{i} = x_{i-1}*std + mu
我尝试了 2 种情况，f_1 解码对于 z ~ N(0, I) 到 Halfmoon 给出了更好的结果。但不知道理论上是否正确。]]></description>
      <guid>https://stackoverflow.com/questions/77805312/transformation-in-normalizing-flow</guid>
      <pubDate>Fri, 12 Jan 2024 08:42:56 GMT</pubDate>
    </item>
    <item>
      <title>谷歌colab笔记本，不工作“错误：页面不工作”无法提供安全连接”</title>
      <link>https://stackoverflow.com/questions/77805252/google-colab-notebook-not-working-error-the-page-not-working-cant-provide</link>
      <description><![CDATA[我的互联网连接良好，其他网站运行良好，但当我尝试打开 google Colab Notebook 时，页面无法运行”错误是：该网站无法提供安全连接？
任何人都可以回答并指导我解决此错误。谢谢
问题是这样的：]]></description>
      <guid>https://stackoverflow.com/questions/77805252/google-colab-notebook-not-working-error-the-page-not-working-cant-provide</guid>
      <pubDate>Fri, 12 Jan 2024 08:28:47 GMT</pubDate>
    </item>
    <item>
      <title>使用 tSNE 后在 MNIST 数据集上应用 KMeans</title>
      <link>https://stackoverflow.com/questions/77805020/applying-kmeans-on-the-mnist-dataset-after-using-tsne</link>
      <description><![CDATA[我在 MNIST 数据集上使用 tSNE，并得到了非常好的结果（当我可视化该图时，所有 10 个标签都分离得很好）。
现在，我想对从 tSNE 建模获得的数据应用 KMeans，并再次将其可视化。
不幸的是，这次我得到了非常糟糕的结果 - 集群看起来非常错误。
我知道 t-SNE 空间中的点之间的距离和关系可能不一定保留原始高维空间中存在的结构，当将 KMeans 等聚类算法直接应用于 t 时，这可能会导致误导性的解释。 -SNE嵌入。
我想问 - 有什么我可以做得更好的吗？
非常感谢！
代码示例：
tsne = TSNE(n_components=2, perplexity=15,learning_rate=200, exaggeration=1)
x_train_tsne = tsne.fit(x_train)

kmeans = KMeans(n_clusters=10, n_init=1, init=&#39;kmeans++&#39;)
labels_kmeans = kmeans.fit_predict(x_train)

对于 np.unique(labels_kmeans) 中的数字：
   索引 = (labels_kmeans == 数字)
   plt.scatter(x_train_tsne[索引，0]，x_train_tsne[索引，1]，s=5，alpha=0.8，标签=str(数字))
]]></description>
      <guid>https://stackoverflow.com/questions/77805020/applying-kmeans-on-the-mnist-dataset-after-using-tsne</guid>
      <pubDate>Fri, 12 Jan 2024 07:35:51 GMT</pubDate>
    </item>
    <item>
      <title>我想通过上传图片来查找“车辆品牌和型号”</title>
      <link>https://stackoverflow.com/questions/77804868/i-want-to-find-vehicle-make-and-model-by-uploading-the-image</link>
      <description><![CDATA[我想创建一个Python模型来在上传车辆图像后识别车辆的品牌和型号。
导入deeplake
从张量流导入keras
从tensorflow.keras导入层

加载训练和测试子集
train_dataset = deeplake.load(“hub://activeloop/stanford-cars-train”)
test_dataset = deeplake.load(“hub://activeloop/stanford-cars-test”)

创建 TensorFlow 数据加载器
train_dataloader = train_dataset.tensorflow()
test_dataloader = test_dataset.tensorflow()

定义常量
image_height, image_width, num_channels = (224, 224, 3) # 根据您的数据集进行调整
num_classes = 196 # 数据集中的汽车类别数量

假设您的数据集有一个“images”键
input_layer=layers.Input(shape=(image_height, image_width, num_channels), name=&#39;images&#39;)
x = 层.Conv2D(32, (3, 3), 激活=&#39;relu&#39;)(input_layer)
x = 层数.MaxPooling2D((2, 2))(x)
x = 层.Conv2D(64, (3, 3), 激活=&#39;relu&#39;)(x)
x = 层数.MaxPooling2D((2, 2))(x)
x = 层.Conv2D(128, (3, 3), 激活=&#39;relu&#39;)(x)
x = 层.Flatten()(x)
x = 层.Dense(256, 激活=&#39;relu&#39;)(x)
输出层=层.Dense（num_classes，激活=&#39;softmax&#39;，名称=&#39;car_models&#39;）（x）

模型= keras.Model（输入=输入层，输出=输出层）

编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;sparse_categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

指定 epoch 数和其他训练参数
&lt;前&gt;&lt;代码&gt;num_epochs = 10

训练模型
model.fit（train_dataloader，epochs = num_epochs，validation_data = test_dataloader）

在测试集上评估模型
test_loss, test_accuracy = model.evaluate(test_dataloader)
print(f&#39;测试准确度: {test_accuracy * 100:.2f}%&#39;)

对新图像进行预测
假设您有一个新图像（将“your_image_path”替换为实际路径）
来自tensorflow.keras.preprocessing导入图像
将 numpy 导入为 np

new_image_path = &#39;/content/bmw2.jpg&#39;
img = image.load_img(new_image_path, target_size=(image_height, image_width))
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) # 添加批量维度
img_array /= 255.0 # 标准化像素值

进行预测
预测 = model.predict(img_array)
Predicted_class = np.argmax(预测[0])

将预测的类别映射到实际的汽车品牌和型号（您可能需要从类别索引到品牌和型号的映射）
class_mapping = {} # 定义类映射
Predicted_make_model = class_mapping.get(predicted_class,“未知”)

print(f&#39;给定图像的预测品牌和型号为：{predicted_make_model}&#39;)
]]></description>
      <guid>https://stackoverflow.com/questions/77804868/i-want-to-find-vehicle-make-and-model-by-uploading-the-image</guid>
      <pubDate>Fri, 12 Jan 2024 06:57:25 GMT</pubDate>
    </item>
    <item>
      <title>UserWarning：X 没有有效的功能名称，但 KNeighborsClassifier 配备了功能名称 warnings.warn</title>
      <link>https://stackoverflow.com/questions/77804804/userwarning-x-does-not-have-valid-feature-names-but-kneighborsclassifier-was-f</link>
      <description><![CDATA[ID曾经_已婚毕业性别职业消费_分数细分家庭_大小年龄工作_经历
0 462809 0 0 1 5 2 3 3 4 1
1 462643 1 1 0 2 0 0 2 18 15
2 466315 1 1 0 2 2 1 0 44 1
3 461735 1 1 1 7 1 1 1 44 0
4 462669 1 1 0 3 1 0 5 20 15
……………………………………
8063 464018 0 0 1 9 2 3 6 4 0
8064 464685 0 0 1 4 2 3 3 15 3
8065 465406 0 1 0 5 2 3 0 14 1
8066 467299 0 1 0 5 2 1 3 8 1
8067 461879 1 1 1 4 0 1 2 17 0
8068行×10列
` data1=data.drop([&quot;ID&quot;,&quot;分割&quot;],axis=1)
from sklearn.model_selection import train_test_split
     x_train,x_test,y_train,y_test=train_test_split(data1,data.Segmentation,test_size=0.20,random_state=50)

 从 sklearn.neighbors 导入 KNeighborsClassifier
 knn=KNeighborsClassifier(n_neighbors=17)
 knn.fit(x_train,y_train)
 tahmin=knn.predict(x_test)

 knn.score(x_test,y_test)
 #0.4838909541511772
 knn.predict([[1,1,0,2,0,2,18,15]])

UserWarning：X 没有有效的功能名称，但 KNeighborsClassifier 已安装了功能名称
#warnings.warn(
#你的文本数组([1])`
当我做出预测时，我并没有预料到这个警告。]]></description>
      <guid>https://stackoverflow.com/questions/77804804/userwarning-x-does-not-have-valid-feature-names-but-kneighborsclassifier-was-f</guid>
      <pubDate>Fri, 12 Jan 2024 06:45:16 GMT</pubDate>
    </item>
    <item>
      <title>只能在 mycode 中将大小为 1 的数组转换为 Python 标量</title>
      <link>https://stackoverflow.com/questions/77804678/can-only-convert-an-array-of-size-1-to-a-python-scalar-in-mycode</link>
      <description><![CDATA[def time_lag(数据, 滞后):
    ”“”
    将数据集转换为网格信息的时间序列并吐出时间滞后的时间序列
    data - csv 文件的全名
    ”“”
    time_orig = pd.to_datetime(&#39;1900-01-01&#39;)

    df = pd.read_csv(数据)
    df.columns = [&#39;时间&#39;, &#39;wind_u10&#39;, &#39;wind_v10&#39;, &#39;slp&#39;, &#39;体重&#39;, &#39;浪涌&#39;]
    
    # 重新组织矩阵
    df_new = df.loc[df[&#39;权重&#39;] == df[&#39;权重&#39;].unique()[0]]
    df_new.drop([&#39;weight&#39;], axis = 1, inplace=True) #, &#39;surge&#39;
    
    对于范围 (1,10) 内的 i：
        df_sub = df.loc[df[&#39;weight&#39;] == df[&#39;weight&#39;].unique()[i]]
        df_sub.drop([&#39;weight&#39;, &#39;surge&#39;], axis = 1, inplace=True)
        df_new = pd.merge(df_new, df_sub, on=&#39;时间&#39;)
    
    
    # 滞后时间序列数据
    lagged_df = df_new.copy() # 防止修改原始矩阵
    对于范围内的 j（滞后）：
        #lagged.drop(j, 轴 = 0, 就地 = True)
        lagged_df[&#39;时间&#39;] = lagged_df[&#39;时间&#39;]+4
        
        # 删除最后一行，因为 df_new 中没有匹配的行
        lagged_df.drop（lagged_df.tail（1）.index.item（），轴= 0，就地= True）
        
        # 从 df_new 中删除最上面的行以匹配滞后
        df_new.drop（df_new.head（1）.index.item（），轴= 0，就地= True）
        
        # 将滞后数据与 df_new 合并
        df_new = pd.merge(df_new, lagged_df, on = &#39;时间&#39;, how = &#39;外部&#39;, \
                       后缀 = (&#39;_left&#39;, &#39;_right&#39;))
    df_new = df_new.T.reset_index(drop=True).T
    ind = df_new.loc[pd.isna(df_new[df_new.shape[1]-1]), :].index
    df_new.drop(ind, inplace=True)
    
    # 风暴潮时间序列数据
    Surge_ts = pd.DataFrame(df.loc[df[&#39;体重&#39;] == \
                                df[&#39;体重&#39;].unique()[0]][[&#39;时间&#39;, &#39;激增&#39;]])
    # 删除缺失值/NaN 值
    Surge_ts.reset_index(inplace=True) # 重置子集 isnans 的索引
    Surge_ts.drop([&#39;index&#39;], axis = 1, inplace=True)
    indx = Surge_ts.loc[pd.isna(surge_ts[“surge”]), :].index
    df_new.drop(indx, inplace=True)
    Surge_ts.drop(indx, inplace=True)
    
    # 根据 df_new 过滤浪涌
    lagged_time = 列表(df_new[0])
    time_df_new = [float(x) for x in df_new[0]]
    time_surge_ts = [float(x) for x in rush_ts[&#39;time&#39;]]
    时间_两者 = []
    对于 lagged_time 中的 k：
        if ((time_df_new 中的 k) &amp; (time_surge_ts 中的 k)):
            time_both.append(int(k))
            
    Surge_ts = Surge_ts[surge_ts[&#39;time&#39;].isin(time_both)]
    
    dt = pd.DataFrame(columns = [&#39;日期&#39;]);
    对于 Surge_ts.index 中的 i：
        dt.loc[i, &#39;日期&#39;] = time_orig + \
            datetime.timedelta(小时 = int(surge_ts.loc[i, &#39;时间&#39;]))
            
    Surge_ts[&#39;日期&#39;] = dt
    df_new = df_new[df_new[0].isin([x*1.0 for x in time_both])]
    df_new.drop(4, axis = 1, inplace = True) # 移除无滞后的浪涌数据
    返回 df_new、surge_ts

数据 = &#39;stormdata.csv&#39;
x, 浪涌 = time_lag(数据,3)
]]></description>
      <guid>https://stackoverflow.com/questions/77804678/can-only-convert-an-array-of-size-1-to-a-python-scalar-in-mycode</guid>
      <pubDate>Fri, 12 Jan 2024 06:15:18 GMT</pubDate>
    </item>
    <item>
      <title>如何使用人工智能识别文本和字典映射</title>
      <link>https://stackoverflow.com/questions/77804632/how-to-identify-text-and-dictionary-mapping-using-ai</link>
      <description><![CDATA[我正在从事一个医疗保健项目，我将收到一份包含有关患者疾病、药物等详细信息的文本。我有一个特定于领域的标准词典，其中包含疾病的标准术语和唯一的 ID。我需要创建一个人工智能模型来处理文本，然后识别字典中的正确映射。
示例：
在文字中 - 患者提到我从过去三天开始就胃痛，医生给我开了 xxx 药。
输出 - 腹痛 [1032713]（它产生了该症状的唯一 ID 和相应的标准术语）
有人可以指导我应该采取什么方法来解决这个问题吗？
我探索并发现我应该为文本和字典单词创建单词嵌入。但字典里可能有数百万个单词，这实际上是不可能的。]]></description>
      <guid>https://stackoverflow.com/questions/77804632/how-to-identify-text-and-dictionary-mapping-using-ai</guid>
      <pubDate>Fri, 12 Jan 2024 06:03:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 LOOCV 进行 K 最近邻的问题</title>
      <link>https://stackoverflow.com/questions/77804296/problem-conducting-k-nearest-neighbors-using-loocv</link>
      <description><![CDATA[我有一个示例表，我想对其进行 KKNN 分类。变量 V4 是响应，我希望分类器查看新数据点是否将分类为 0 或 1（实际数据有 12 列，第 12 列是响应，但我仍然会简化示例
库(kknn)

数据 &lt;- data.frame(
  V1=c(1.2,2.5,3.1,4.8,5.2),
  V2=c(0.7, 1.8, 2.3, 3.9, 4.1),
  V3=c(2.3, 3.7, 1.8, 4.2, 5.5),
  V4= c(0, 1, 0, 1, 0)
）

现在，我想使用 for 循环通过 LOOCV 构建 kknn 分类。假设 kknn=3
for (i in 1:nrow(data)) {
  train_data &lt;- 数据[-i, 1:3]
  train_data_response &lt;- data.frame(data[-i, 4])
  colnames(train_data_response) &lt;- “响应”
  test_set &lt;- 数据[i, 3]
  模型 &lt;- kknn(公式=train_data_response ~ ., data.frame(train_data),
                data.frame(test_set)，k=3，scale=TRUE)
}

现在我收到以下错误：
&lt;块引用&gt;
model.frame.default(公式，数据=训练)中的错误：
变量“train_data_response”的类型（列表）无效

有什么办法可以解决这个错误吗？我认为 kknn 接受矩阵或数据帧。我的训练和测试数据确实是数据框，那么什么给出了？
另外，我的 LOOCV 操作正确吗？谢谢]]></description>
      <guid>https://stackoverflow.com/questions/77804296/problem-conducting-k-nearest-neighbors-using-loocv</guid>
      <pubDate>Fri, 12 Jan 2024 04:15:37 GMT</pubDate>
    </item>
    <item>
      <title>初始化 VAE 权重</title>
      <link>https://stackoverflow.com/questions/77804014/initializing-vae-weights</link>
      <description><![CDATA[我正在训练遵循以下整体架构的 VAE：

变压器编码器
Mu/Logvar -&gt;重新参数化-&gt;潜在z
变压器解码器

根据典型的 VAE 设置，Mu 和 Logvar 只是两个前馈网络。然而，当我用标准值（例如权重为 0.5，偏差为 0）初始化它们时，我发现模型的初始 KL 损失巨大 - 例如5,000-20,000+。
当然，这个下降得相当快，但模型仍然花费数百个时期将 KL 损失从 300 降至 &lt;50。
一个“解决方法”我发现将权重初始化为低得多的值，并使用学习率预热。但初始化权重非常小：
def init_weights(self, initrange=0.0001) -&gt; &gt;没有任何：
        self.embedding_layer.weight.data.uniform_(-0.5, 0.5)
        
        nn.init.uniform_(self.fc_mu.weight, -initrange, initrange)
        nn.init.uniform_(self.fc_logvar.weight, -initrange, initrange)
        nn.init.zeros_(self.fc_mu.bias)
        nn.init.zeros_(self.fc_logvar.bias)

这样做的结果是一个更加稳定的 KL 损失（开始时约为 1.5），但我担心它会阻止我的解码器学习有意义的表示。实际的重建损失因此受到巨大影响。
所以我的问题是：这是 VAE 的已知问题吗？有什么我可以尝试的特定初始化技巧吗？或者也许我应该从正常值开始，让模型训练的时间明显更长？
提前非常感谢。]]></description>
      <guid>https://stackoverflow.com/questions/77804014/initializing-vae-weights</guid>
      <pubDate>Fri, 12 Jan 2024 02:14:48 GMT</pubDate>
    </item>
    <item>
      <title>在 XGBoost 和 SHAP 中使用子采样数据的 SHAP 解释器错误</title>
      <link>https://stackoverflow.com/questions/77800921/shap-explainer-error-using-subsampled-data-in-xgboost-and-shap</link>
      <description><![CDATA[我正在尝试对数据子集进行随机采样，以从 XGBoost 模型创建 SHAP TreeExplainer 对象。我使用数据子集，因为从完整数据集（200K+）行创建 TreeExplainer 对象需要几天的时间才能运行。但是，当我运行代码时，我收到 TreeExplainer 错误。
我的代码：
&lt;前&gt;&lt;代码&gt;导入xgboost
将 numpy 导入为 np
将 pandas 导入为 pd
导入形状

数据= np.load（&#39;pandas_df.pkl&#39;，allow_pickle = True）
X = 数据[[&#39;feat_1&#39;, &#39;feat_2&#39;, ...., &#39;feat_n&#39;]]
y = 数据[[&#39;响应&#39;]]
X_train，X_test，y_train，y_test = train_test_split（X，y，test_size = 0.2，random_state = 0）

模型 = xgboost.XGBRFClassifier()
model.fit(X_train, y_train)

shap_sample_x_test = X_test.sample(n = 1000, random_state = 0)

解释器 = shap.Explainer(模型)
shap_values = 解释器(shap_sample_x_test)

shap.plots.beeswarm(shap_values)

这会导致此错误：
ExplainerError：TreeExplainer 中的可加性检查失败！请确保您传递给解释器的数据矩阵与模型训练时的形状相同。如果您的数据形状正确，请在 GitHub 上报告此情况。考虑使用 feature_perturbation=&#39;interventional&#39; 选项重试。此检查失败，因为其中一个样本的 SHAP 值总和为 -1.947115，而模型输出为 -1.936696。如果这种差异可以接受，您可以设置 check_additivity=False 来禁用此检查。
]]></description>
      <guid>https://stackoverflow.com/questions/77800921/shap-explainer-error-using-subsampled-data-in-xgboost-and-shap</guid>
      <pubDate>Thu, 11 Jan 2024 14:49:03 GMT</pubDate>
    </item>
    <item>
      <title>在 Sagemaker 中部署 dolly2 模型进行嵌入，但在调用端点时收到 400 错误</title>
      <link>https://stackoverflow.com/questions/76380739/deployed-dolly2-model-in-sagemaker-for-embeddings-but-receiving-a-400-error-whe</link>
      <description><![CDATA[我已经在 sagemaker 中部署了 dolly2 模型，并且正在尝试创建一些用于嵌入的向量，该代码对于文本生成来说效果很好，但是在更改 inference.py 来处理嵌入之后，我收到以下错误
otocore.errorfactory.ModelError：调用 InvokeEndpoint 操作时发生错误 (ModelError)：从主服务器收到客户端错误 (400)，消息为“{
  “代码”：400，
  “类型”：“InternalServerException”，
  &quot;message&quot;: &quot;(\&quot;您需要定义以下之一 [\u0027audio-classification\u0027, \u0027automatic-speech-recognition\u0027, \u0027feature-extraction\u0027, \u0027text-classification\u0027, \u0027标记分类\u0027、\u0027问答\u0027、\u0027表格问答\u0027、\u0027视觉问答\u0027、\u0027文档问答\u0027、\u0027填充掩码\u0027、\u0027摘要\u0027、\u0027翻译\u0027、\u0027text2文本生成\u0027、\u0027文本生成\u0027、\u0027零样本分类\u0027、\u0027零样本图像分类\u0027、\u0027会话\u0027、\u0027图像-分类\u0027、\u0027图像分割\u0027、\u0027图像到文本\u0027、\u0027对象检测\u0027、\u0027零镜头对象检测\u0027、\u0027深度估计\u0027、\u0027视频分类\ u0027] 作为环境 \u0027HF_TASK\u0027.\&quot;, 403)&quot;
}

下面您还可以看到我用于嵌入的代码
导入json
导入操作系统
导入boto3
从变压器进口管道


def invoke_sagemaker_endpoint():
    # 创建 SageMaker 客户端
    sagemaker_client = boto3.client(“sagemaker-runtime”)

    # 定义端点名称和负载
    endpoint_name = &#39;XXX&#39; # 替换为您的 SageMaker 端点名称
    Payload = {“inputs”：“这是一个大文档。”} # 按照模型的预期更新有效负载格式

    # 将请求发送到 SageMaker 端点
    响应= sagemaker_client.invoke_endpoint（
        端点名称=端点名称，
        ContentType =“应用程序/json”，
        正文=json.dumps(有效负载),
    ）

    # 解析响应并提取嵌入向量
    response_body = response[“Body”].read().decode(“utf-8”)
    response_json = json.loads(response_body)

    如果“嵌入”是在response_json中：
        嵌入 = response_json[“嵌入”]
        embeddings_vector = embeddings[0] # 嵌入作为列表返回
        返回嵌入向量
    别的：
        返回无


如果 __name__ == “__main__”：
    # 将嵌入的 HF_TASK 环境变量设置为“feature-extraction”
    os.environ[&quot;HF_TASK&quot;] = &quot;特征提取&quot;
    # 调用 SageMaker 端点
    embeddings_vector = invoke_sagemaker_endpoint()

    如果嵌入向量：
        打印（嵌入向量）
    别的：
        print(“响应中未发现嵌入。”)



和 inference.py
&lt;前&gt;&lt;代码&gt;
进口火炬
从变压器进口管道

def model_fn(model_dir):
    模型=管道（
        “文本生成”，
        模型=模型目录，
        torch_dtype=torch.bfloat16,
        trust_remote_code=真，
        device_map=“自动”，
        model_kwargs={“load_in_8bit”：True}，
    ）
    分词器=模型.分词器
    embeddings_model = 模型.model

    defgenerate_embeddings（输入）：
        输入 = tokenizer(输入、截断=True、填充=“最长”、return_tensors=“pt”)
        使用 torch.no_grad()：
            输出 = embeddings_model(**输入)
        嵌入=outputs.last_hidden_​​state.mean(dim=1).squeeze(0).tolist()
        返回嵌入

    defretrieve_qa（问题，上下文）：
        输入 = {“问题”：问题，“上下文”：上下文}
        qa_outputs = 模型（问题，上下文）
        返回 qa_outputs

    返回模型、generate_embeddings、retrieve_qa

更改了推理，将 HF 重新部署到 sagemaker，从 api 网关而不是 sagemaker 端点调用]]></description>
      <guid>https://stackoverflow.com/questions/76380739/deployed-dolly2-model-in-sagemaker-for-embeddings-but-receiving-a-400-error-whe</guid>
      <pubDate>Thu, 01 Jun 2023 09:59:24 GMT</pubDate>
    </item>
    </channel>
</rss>