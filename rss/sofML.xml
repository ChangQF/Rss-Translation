<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 20 Apr 2024 12:23:25 GMT</lastBuildDate>
    <item>
      <title>如何计算尖峰神经网络电路实现中的“每个尖峰能量”？</title>
      <link>https://stackoverflow.com/questions/78358095/how-to-calculate-energy-per-spike-in-spiking-neural-networks-circuit-implemen</link>
      <description><![CDATA[在一些科学文献中（例如this和this) 关于 LIF（一种尖峰神经网络）的模拟电路实现，作者提到了“每尖峰能量”和“每个概要的能量”作为评价参数之一。有谁知道如何从电路级实现中计算它？
我想知道如何计算“每次峰值能量”来自电路植入的参数。]]></description>
      <guid>https://stackoverflow.com/questions/78358095/how-to-calculate-energy-per-spike-in-spiking-neural-networks-circuit-implemen</guid>
      <pubDate>Sat, 20 Apr 2024 11:56:58 GMT</pubDate>
    </item>
    <item>
      <title>在 keras 中，当模型拟合 epochs=5000 时，代码看起来非常庞大</title>
      <link>https://stackoverflow.com/questions/78358018/in-keras-while-model-fitting-with-epochs-5000-the-code-looks-so-huge</link>
      <description><![CDATA[所以，我正在尝试深度学习中的梯度下降。代码是这样的。
model=keras.Sequential([keras.layers.Dense(1, input_shape= (2,),activation=&#39;sigmoid&#39;, kernel_initializer=&#39;ones&#39;,bias_initializer=&#39;zeros&#39;)])

model.compile(optimizer=&#39;adam&#39;,loss=&#39;binary_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

model.fit(x_train_scaled,y_train, epochs=5000)

当 epochs=5000 时，我应该获得约 90% 的准确率。但它在 jupyter 中占有重要地位。
我试图在较短的空间内达到 90% 的准确率。因为当我想引用上面的代码时，有很多东西需要滚动。]]></description>
      <guid>https://stackoverflow.com/questions/78358018/in-keras-while-model-fitting-with-epochs-5000-the-code-looks-so-huge</guid>
      <pubDate>Sat, 20 Apr 2024 11:30:52 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试使用 grad-cam，但得到 ValueError: The layerequential has never be called and 因此没有定义的输入</title>
      <link>https://stackoverflow.com/questions/78357635/i-am-trying-to-use-grad-cam-but-get-valueerror-the-layer-sequential-has-never</link>
      <description><![CDATA[导入tensorflow为tf

将 numpy 导入为 np

导入CV2

从 keras.models 导入 load_model

模型 = load_model(r&#39;.\CNN.keras&#39;)

# 定义感兴趣的层（例如，conv2d_19）

图层名称 = &#39;conv2d_1&#39;

# 创建一个模型来输出所选层的激活

activation_model = tf.keras.Model(输入=model.input, 输出=model.get_layer(layer_name).output)

# 生成示例输入图像（替换为您的实际数据）

input_image = np.random.rand(1, 120, 120, 3) # 示例形状，根据需要调整

# 获取输出相对于所选层的梯度

使用 tf.GradientTape() 作为磁带：

    最后的卷积层输出 = 激活模型（输入图像）

    磁带.watch(last_conv_layer_output)

    preds = 模型（输入图像）

    top_class = tf.argmax(preds[0])

# 计算顶层类相对于所选层的梯度

grads = Tape.gradient(preds[:, top_class], last_conv_layer_output)[0]

# 计算热图的权重

权重 = tf.reduce_mean(梯度, 轴=(0, 1))

# 将特征图乘以权重以获得热图

热图 = tf.reduce_sum(last_conv_layer_output * 权重，轴=-1)

# 调整热图大小以匹配输入图像大小

heatmap = cv2.resize(heatmap.numpy(), (input_image.shape[1], input_image.shape[2]))

# 标准化热图

热图 = np.maximum(热图, 0) / np.max(热图)

# 将热图叠加在原始图像上

热图 = cv2.applyColorMap(np.uint8(255 * 热图), cv2.COLORMAP_JET)

superimpose_img = cv2.addWeighted(input_image[0], 0.6, 热图, 0.4, 0)

# 显示或保存叠加图像

cv2.imshow(“Grad-CAM”, superimulated_img)

cv2.waitKey(0)

cv2.destroyAllWindows()

这是我的代码，但我明白
ValueError：层顺序从未被调用，因此没有定义的输入。

我希望从 grad-cam 获取热图，以便我可以可视化触发模型预测的图像部分]]></description>
      <guid>https://stackoverflow.com/questions/78357635/i-am-trying-to-use-grad-cam-but-get-valueerror-the-layer-sequential-has-never</guid>
      <pubDate>Sat, 20 Apr 2024 09:07:26 GMT</pubDate>
    </item>
    <item>
      <title>警告：由于元数据条目“名称”无效而跳过 C:\Users\abhis\AppData\Roaming\Python\Python312\site-packages\jupyter_client-8.6.0.dist-info [已关闭]</title>
      <link>https://stackoverflow.com/questions/78357455/warning-skipping-c-users-abhis-appdata-roaming-python-python312-site-packages</link>
      <description><![CDATA[[] [参考图片]我遇到了错误，希望得到解决该错误的帮助。有人可以提供有关如何解决此问题的指导吗？
它应该显示我的系统中安装的所有库列表，没有任何错误]]></description>
      <guid>https://stackoverflow.com/questions/78357455/warning-skipping-c-users-abhis-appdata-roaming-python-python312-site-packages</guid>
      <pubDate>Sat, 20 Apr 2024 08:09:54 GMT</pubDate>
    </item>
    <item>
      <title>在自动训练中将适配器与模型合并时出错</title>
      <link>https://stackoverflow.com/questions/78357392/error-in-merging-adapter-with-model-in-autotrain</link>
      <description><![CDATA[我正在尝试使用 Hugging Face 中的自动训练来微调某些模型。由于我没有大量的计算资源，因此我尝试微调模型 EleutherAI/pythia-14m 和此数据集。但我收到了这条消息：
无法合并适配器权重：为 PeftModelForCausalLM 加载 state_dict 时出错：
    base_model.model.gpt_neox.embed_in.weight 的大小不匹配：从检查点复制形状为 torch.Size([50280, 128]) 的参数，当前模型中的形状为 torch.Size([50277, 128])。
    base_model.model.embed_out.weight 的大小不匹配：从检查点复制形状为 torch.Size([50280, 128]) 的参数，当前模型中的形状为 torch.Size([50277, 128])。

当我启动此脚本时发生此错误，该脚本只是用 Jupiter 编写的终端命令。
!auto​​train llm \
     - 火车 \
    --模型“EleutherAI/pythia-14m” \
    --项目名称“my-llm” \
    --数据路径数据/ \
    --text-列文本 \
    --批量大小“4” \
    --lr“2e-5” \
    --纪元“3” \
    --块大小“1024” \
    --预热比率“0.03” \
    --lora-r“16” \
    --lora-alpha“32”； \
    --lora-dropout“0.05” \
    --权重衰减“0”。 \
    --梯度累积“4” \
    --logging-steps“10” \
    --use-peft \
    --合并适配器\

此外，当我尝试在拥抱脸部空间中进行自动训练时，也出现了同样的问题。
我没有机器学习经验，所以我无法想象，什么会导致这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/78357392/error-in-merging-adapter-with-model-in-autotrain</guid>
      <pubDate>Sat, 20 Apr 2024 07:38:52 GMT</pubDate>
    </item>
    <item>
      <title>对质谱数据库搜索结果进行分类的统计方法</title>
      <link>https://stackoverflow.com/questions/78357067/statistical-methods-for-classifying-mass-spectrometry-database-search-results</link>
      <description><![CDATA[作为一名新手，我想尝试生物信息学方面的一些东西，即用于对质谱数据库搜索结果进行分类的机器学习统计方法。然而，我未能获得用于此目的的公开数据。
我尝试在 NCBI 上搜索某种要使用的数据，但未能在本地计算机上下载和使用任何数据。]]></description>
      <guid>https://stackoverflow.com/questions/78357067/statistical-methods-for-classifying-mass-spectrometry-database-search-results</guid>
      <pubDate>Sat, 20 Apr 2024 05:17:15 GMT</pubDate>
    </item>
    <item>
      <title>使用自动调谐后，如何改进训练/验证图的准确性和损失？ （美国有线电视新闻网）</title>
      <link>https://stackoverflow.com/questions/78357031/how-can-i-improve-the-results-of-this-training-validation-graph-of-accuracy-and</link>
      <description><![CDATA[训练和验证准确性和损失图
我运行了我的 CNN 模型（7 个类、大约 33k 图像和 22 层）100 个 epoch，并得到了这张图。它不是扁平的，而是非常尖的。下面是我添加到模型中的图层。
模型 = 顺序（[
    数据增强，
    图层.重新缩放(1./255, input_shape=(img_height, img_width, 3)),
    层.Conv2D(16, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Conv2D(32, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Conv2D(64, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层数.Dropout(0.05),
    层.Conv2D(128, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Conv2D(256, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层数.Dropout(0.05),
    层.Conv2D(512, 3, 填充=&#39;相同&#39;, 激活=&#39;relu&#39;),
    层.MaxPooling2D(),
    层.Flatten(),
    层.密集（512，激活=&#39;relu&#39;），
    层数.Dropout(0.05),
    层.Dense(256, 激活=&#39;relu&#39;),
    层数.Dropout(0.05),
    层.Dense(128, 激活=&#39;relu&#39;),
    Layers.Dense(num_classes, name=&quot;outputs&quot;)
]）

这是我运行自动调整数据的方法
AUTOTUNE = tf.data.AUTOTUNE

train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

这是使用自动调谐之前图表的样子
添加自动调谐之前的图表
虽然这个图表也不平坦，但它仍然比第一个图表好得多。如何使我的图表变平？
我不太确定如何正确展平图表。我只需要运行更多的纪元吗？]]></description>
      <guid>https://stackoverflow.com/questions/78357031/how-can-i-improve-the-results-of-this-training-validation-graph-of-accuracy-and</guid>
      <pubDate>Sat, 20 Apr 2024 04:55:34 GMT</pubDate>
    </item>
    <item>
      <title>在weka中重新采样过滤器</title>
      <link>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</link>
      <description><![CDATA[我的数据集中的数据实例数量很少。所以，我尝试了“重新采样” Weka中的过滤器可以增加数据量，从而提高模型性能。样本量百分比设置为200可以吗？因为那时我在交叉验证测试中获得了良好的相关系数。
我想知道将样本大小百分比设置为 200 时，重新采样过滤器是否工作正常。
使用此过滤器后，我的模型会准确预测吗？
由于数据量较少，是否有其他增强方法可以增强模型的性能？]]></description>
      <guid>https://stackoverflow.com/questions/78356992/resample-filter-in-weka</guid>
      <pubDate>Sat, 20 Apr 2024 04:29:50 GMT</pubDate>
    </item>
    <item>
      <title>无法安装gensim模块</title>
      <link>https://stackoverflow.com/questions/78356738/unable-to-install-gensim-module</link>
      <description><![CDATA[我尝试在终端中运行“pip install gensim”命令，但发生了以下情况：
*ld_w2v_模型
运行 build_ext
构建“gensim.models.word2vec_inner”扩展
错误：需要 Microsoft Visual C++ 14.0 或更高版本。使用“Microsoft C++ 构建工具”获取它：https://visualstudio.microsoft。 com/visual-cpp-build-tools/
[输出结束]
注意：此错误源自子进程，并且可能不是 pip 的问题。
错误：gensim 构建轮子失败
构建gen​​sim失败
错误：无法为 gensim 构建轮子，这是安装基于 pyproject.toml 的项目所必需的
*
我该如何解决此错误？
我尝试使用“pip install --use-pep517 gensim==3.8.0”命令并安装了它，但是，在运行我的实际 python 脚本时，模块的错误仍然发生：
回溯（最近一次调用最后一次）：
文件“C:\Users\Anuja Alice Thomas\Documents\CHRIST UNIVERSITY\Trimester 3\Java Planning\Assignments\Sample1\python.py”，第 4 行，位于
导入gensim
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim_init_.py”，第 5 行，位于
from gensim 导入解析、语料库、matutils、接口、模型、相似性、摘要、utils # noqa:F401
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\corpora_init_.py”，第 6 行，位于
from .indexedcorpus import IndexedCorpus # noqa:F401 必须出现在其他类之前
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\corpora\indexedcorpus.py”，第 15 行，位于
从 gensim 导入接口、utils
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\interfaces.py”，第 21 行，位于
从 gensim 导入 utils、matutils
文件“C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\gensim\matutils.py”，第 24 行，位于
从 scipy.linalg.special_matrices 导入 triu
ImportError: 无法从 &#39;scipy.linalg.special_matrices&#39; 导入名称 &#39;triu&#39; (C:\Users\Anuja Alice Thomas\AppData\Local\Programs\Python\Python312\Lib\site-packages\scipy\linalg\special_matrices.py) ]]></description>
      <guid>https://stackoverflow.com/questions/78356738/unable-to-install-gensim-module</guid>
      <pubDate>Sat, 20 Apr 2024 01:37:22 GMT</pubDate>
    </item>
    <item>
      <title>从 torchensemble 中的基本模型获取嵌入</title>
      <link>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78355585/getting-embeddings-from-the-base-model-in-torchensemble</guid>
      <pubDate>Fri, 19 Apr 2024 18:25:20 GMT</pubDate>
    </item>
    <item>
      <title>在序列模型中使用归一化层时，adapt() 会出错吗？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</link>
      <description><![CDATA[在顺序模型中使用归一化层时，通过适应（），我收到了未绑定错误：
这是错误
我做了以下事情：
标准化器 = 标准化()
标准化器.adapt(X_train)

但这给出了以下错误：
未绑定错误：赋值前引用了局部变量“input_shape”。
为什么我会收到此错误？如果不是这样，还有其他方法可以标准化神经网络中的数据吗？]]></description>
      <guid>https://stackoverflow.com/questions/78355246/adapt-gives-error-while-using-normalization-layer-in-sequential-models</guid>
      <pubDate>Fri, 19 Apr 2024 17:04:02 GMT</pubDate>
    </item>
    <item>
      <title>使用 CNN 进行音频分类总是预测错误</title>
      <link>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78354074/audio-classification-using-cnn-predicting-wrong-all-the-time</guid>
      <pubDate>Fri, 19 Apr 2024 13:39:10 GMT</pubDate>
    </item>
    <item>
      <title>获取边界框问题</title>
      <link>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78353726/getting-bounding-box-issue</guid>
      <pubDate>Fri, 19 Apr 2024 12:40:40 GMT</pubDate>
    </item>
    <item>
      <title>LMST模型敏感性——初学者抗运气</title>
      <link>https://stackoverflow.com/questions/78349854/lmst-model-sensitivity-beginners-anti-luck</link>
      <description><![CDATA[我一直在尝试使用艾伯塔省电力市场的一些非常基本的数据，并尝试使用时间序列数据的 LMST 模型来尝试预测价格。我确实得到“可能”这是我的模型的结果，而且它似乎确实出现了我们可以预期的一些波动（仅根据我自己的市场经验）。
但是，我正在寻求更好地理解我遇到的一些陷阱。
从 keras.models 导入顺序
从 keras.layers 导入 LSTM
从 keras.layers 导入 Dropout
从 keras.layers 导入密集
将 pandas 导入为 pd
从 sklearn.preprocessing 导入 MinMaxScaler
从 sklearn.model_selection 导入 train_test_split
从 sklearn.metrics 导入mean_absolute_error,mean_squared_error
将 numpy 导入为 np
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
导入作业库

# 加载数据
# 加载数据

# 加载数据
csv_file_path = &#39;Frankenstein.csv&#39; # 使用您的实际文件路径更新
df = pd.read_csv(csv_file_path)

# 将“日期/时间”转换为日期时间并提取数据集中存在的组件
如果 df.columns 中的“日期/时间”：
    df[&#39;日期&#39;] = pd.to_datetime(df[&#39;日期/时间&#39;])
    df[&#39;年份&#39;] = df[&#39;日期&#39;].dt.year
    df[&#39;月份&#39;] = df[&#39;日期&#39;].dt.月份
    df[&#39;日期&#39;] = df[&#39;日期&#39;].dt.day
    df[&#39;小时&#39;] = df[&#39;日期&#39;].dt.小时
    df.drop([&#39;日期/时间&#39;, &#39;日期&#39;], axis=1, inplace=True)

# 假设“价格”是目标变量
features = df.drop([&#39;价格&#39;], axis=1)
目标 = df[&#39;价格&#39;]

# 标准化特征和目标
缩放器特征 = MinMaxScaler()
features_scaled = scaler_features.fit_transform(features)
缩放器目标 = MinMaxScaler()
target_scaled = scaler_target.fit_transform(target.values.reshape(-1, 1))

# 创建序列函数
def create_sequences（特征，目标，time_steps = 100）：
    X、y = []、[]
    对于范围内的 i(len(features) - time_steps)：
        X.append(特征[i:(i + time_steps)])
        y.append(目标[i + time_steps])
    返回 np.array(X), np.array(y)

# 使用整个数据集创建序列
X, y = create_sequences(features_scaled, target_scaled.flatten())

# 模型配置
input_shape = (X.shape[1], X.shape[2]) # (time_steps, num_features)

# 定义LSTM模型
模型=顺序（[
    LSTM（单位= 100，return_sequences = True，input_shape = input_shape），
    辍学（0.1），
    LSTM（单位=100），
    辍学（0.1），
    密集（单位=100，激活=&#39;elu&#39;），
    Dense(1) # 预测单个值
]）

# 编译模型
model.compile(optimizer=&#39;adam&#39;, loss=&#39;mean_squared_error&#39;)

# 在整个数据集上训练模型
历史= model.fit（X，y，纪元= 150，batch_size = 20，validation_split = 0.1）

# 情节训练&amp;验证损失值
plt.figure(figsize=(10, 6))
plt.plot(history.history[&#39;loss&#39;], label=&#39;火车&#39;)
plt.plot(history.history[&#39;val_loss&#39;], label=&#39;验证&#39;)
plt.title(&#39;模型损失&#39;)
plt.ylabel(&#39;损失&#39;)
plt.xlabel(&#39;纪元&#39;)
plt.legend(loc=&#39;右上&#39;)
plt.show()

# 保存LSTM模型
model_save_path = &#39;trained_lstm_model.h5&#39;
model.save(model_save_path)
print(f&quot;模型已保存到 {model_save_path}&quot;)
joblib.dump(scaler_features, &#39;scaler_features.pkl&#39;)
joblib.dump(scaler_target, &#39;scaler_target.pkl&#39;)

有人可以给绝对的初学者一些建议吗？主要是为了更好地理解我应该如何设置它。我有一个每小时的数据集，是过去三年的历史生成和交换。我正在寻找方法让我的模型对供应与价格的变化更具反应性。]]></description>
      <guid>https://stackoverflow.com/questions/78349854/lmst-model-sensitivity-beginners-anti-luck</guid>
      <pubDate>Thu, 18 Apr 2024 19:18:18 GMT</pubDate>
    </item>
    <item>
      <title>对于表格数据模型中的过度拟合我该怎么办</title>
      <link>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</link>
      <description><![CDATA[我建立了一个预测模型，用于根据所提供数据中的某些特征来预测结果。
该模型是一个利用 fastai 的表格学习器。
该数据集包含约 300 条记录，分为训练集、验证集和测试集。
我已经实现了解决过度拟合的技术，例如提前停止和权重衰减，但在对未见过的数据进行评估时，模型仍然似乎过度拟合。
此外，我还尝试调整学习率和批量大小等超参数，但没有改善。我怀疑我的模型架构或预处理管道的某些方面可能会导致该问题，但我不确定从哪里开始调查。
鉴于该项目的敏感性，我无法提供有关数据集或预测任务的具体细节，但我可以分享当前模型的预处理和结构。
这是训练的输出：

&lt;标题&gt;

纪元
train_loss
valid_loss
准确度
时间


&lt;正文&gt;

0
0.752707
0.579501
0.776119
00:00


1
0.699270
0.833771
0.776119
00:00


2
0.652438
0.598243
0.791045
00:00


3
0.621083
3.889398
0.776119
00:00


4
0.591348
0.632366
0.791045
00:00


5
0.580582
6.670314
0.791045
00:00



&lt;块引用&gt;
自 epoch 2 以来没有任何改进：提前停止

这是预处理的代码（在我构建了我不能透露的功能之后）。
features 列表定义每个特征，包括有效值范围和权重（feature、range_ 和 weight 如下面的标准化函数中所使用的那样）。
def custom_normalize(df, 特征, range_, 权重):
    df[特征] = 归一化(df[特征], range_)
    df[特征] = df[特征] * 权重
    返回df

分割 = RandomSplitter(valid_pct=0.2)(range_of(df))

procs = [分类，填充缺失]

对于功能，features.items() 中的信息：
    # 确定训练时选择值的范围。
    procs.append(partial(custom_normalize, feature=feature, range_=info[&#39;range&#39;],weight=info[&#39;weight&#39;]))

据我所知，构建模型和训练是相当标准的：
to = TabularPandas(df, procs=procs,
                   cat_names = cat_vars,
                   连续名称=连续变量，
                   y_names=dep_var,
                   分裂=分裂）

dls = to.dataloaders(bs=64)

Early_stop = EarlyStoppingCallback(监视器=&#39;准确度&#39;, min_delta=0.01, 耐心=3)

学习 = tabular_learner(dls, 指标=准确度, wd=0.1)
学习.lr_find()

# 绘制学习率。
learn.recorder.plot_lr_find()

# 根据情节选择学习率。
lr = learn.recorder.lrs[np.argmin(learn.recorder.losses)]

learn.fit_one_cycle(15, lr, cbs=early_stop)
学习.show_results()

# 如果模型不存在则只保存模型
# TODO 将保存包装在条件中，以防止模型存在时保存。
如果不是 os.path.exists(model_fname):
    学习.保存(model_fname)
]]></description>
      <guid>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</guid>
      <pubDate>Tue, 16 Apr 2024 08:38:01 GMT</pubDate>
    </item>
    </channel>
</rss>