<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 29 Jan 2024 18:15:52 GMT</lastBuildDate>
    <item>
      <title>SHAP 图表难以阅读的问题</title>
      <link>https://stackoverflow.com/questions/77901671/the-problem-of-having-a-hard-to-read-shap-chart</link>
      <description><![CDATA[我为具有六个输入和两个输出、1000 个观测值的数据集绘制了 SHAP 图表。我还选择了瀑布型 SHAP 图表。
我遇到的问题是这些点出现在彼此的顶部（垂直），如附图所示。 在此处输入图片描述
所以我发现很难解释输入对输出的影响。
这是我的代码：
&lt;前&gt;&lt;代码&gt;数据集 =
x = df.iloc[:, 0:6]
y = df.iloc[:, [6, 7]]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)
rf_model = RandomForestRegressor()
rf_pipeline = 管道([
    (&#39;缩放器&#39;, StandardScaler()),
    （&#39;回归&#39;，rf_model）
]）
rf_pipeline.fit(x_train, y_train)

解释器 = shap.TreeExplainer(rf_model)
shap_values = 解释器.shap_values(x_test)

shap.summary_plot(shap_values[0], x_test)
plt.title(&#39;输出 1 的 SHAP 值&#39;)

shap.summary_plot(shap_values[1], x_test)
plt.title(&#39;输出 2 的 SHAP 值&#39;)

问题很可能与数据的范围有关，因为绘制图表时，x 轴从大约 -350 到 30 开始。当我缩小范围时，第一个变量的点（位于顶部）消失。
你们以前遇到过这样的问题吗？您是如何解决的？]]></description>
      <guid>https://stackoverflow.com/questions/77901671/the-problem-of-having-a-hard-to-read-shap-chart</guid>
      <pubDate>Mon, 29 Jan 2024 17:50:19 GMT</pubDate>
    </item>
    <item>
      <title>在 librosa 中重新调整音频时面临问题</title>
      <link>https://stackoverflow.com/questions/77901612/facing-problem-in-reshampling-audio-in-librosa</link>
      <description><![CDATA[我正在尝试使用我的数据集微调 wev2vec2 模型。因此我加载了音频。现在想将它们下采样到 16khz。但 librosa.reshape 函数给出了我无法解决的错误。错误是“resample() 需要 1 个位置参数，但给出了 3 个”
首先我尝试使用 sr 16khz 的 librosa 加载它。但由于我在这方面的经验较少。因此，我在项目的后期部分遇到了问题。我找到了一个以不同方式完成的代码。所以。我尝试使用他的方法，但现在面临问题。
这部分工作正常
数据库={}
音频 = []
PSR = []
对于 df[&#39;audio&#39;] 中的路径：
  Speech_array,sr = torchaudio.load(路径)
  audios.append(speech_array[0].numpy())
  psr.追加(sr)
数据库[&#39;音频&#39;] = 音频
数据库[&#39;psr&#39;] = psr

每个索引都出现错误
导入librosa
将 numpy 导入为 np

# 假设“database”是包含“audio”和“psr”列的 DataFrame

# 存储新采样率的列表
新_sr = []

# 对每个音频信号重新采样并存储新的采样率
对于范围内的 i(len(database[&#39;psr&#39;]))：
    尝试：
        audio_signal = np.asarray(database[&#39;audio&#39;][i]) # 将音频转换为 numpy 数组
        Original_sr = database[&#39;psr&#39;][i] # 原始采样率

        # 检查音频信号是否为单声道（单声道）
        如果audio_signal.ndim == 1：
            # 对单声道音频信号重新采样
            resampled_audio = librosa.resample(audio_signal,original_sr,16000)
        别的：
            # 对多通道音频的每个通道分别重新采样
            重新采样通道 = []
            对于 audio_signal 中的通道：
                resampled_channel = librosa.resample（通道，original_sr，16000）
                resampled_channels.append(resampled_channel)
            resampled_audio = np.array(resampled_channels)

        # 将重新采样的音频存储回 DataFrame 中
        数据库[&#39;音频&#39;][i] = resampled_audio

        # 存储新的采样率（16000 Hz）
        new_sr.append(16000)
    除了异常 e：
        print(f“处理索引 {i} 处的音频时出错：{e}”)

# 向 DataFrame 添加新的采样率
数据库[&#39;newsr&#39;] = new_sr
]]></description>
      <guid>https://stackoverflow.com/questions/77901612/facing-problem-in-reshampling-audio-in-librosa</guid>
      <pubDate>Mon, 29 Jan 2024 17:37:05 GMT</pubDate>
    </item>
    <item>
      <title>无法在 celery 工作线程中使用 YOLO 加载和预测图像</title>
      <link>https://stackoverflow.com/questions/77901605/not-able-to-load-and-predict-on-images-using-yolo-inside-celery-worker</link>
      <description><![CDATA[这是我的代码
导入系统
从 Question_Detection.inference_object_detection.check_model 导入 verify_model
从记录器导入记录器
从 ultralytics 导入 YOLO


类 ModelNotFoundError（异常）：
    经过


def load_model():
    尝试：
        成功，model_path = verify_model()
        logger.info(“模型加载开始”)
        如果没有成功：
            raise ModelNotFoundError(&quot;未找到模型！&quot;)
        logger.info(“123”)
        记录器.info（模型路径）
        _模型 = YOLO(模型路径)
        logger.info(“456”)
        如果 _model 为 None：
            raise ModelNotFoundError(“模型未加载！”)
        logger.info(“789”)
        返回 _model, _model.names
    除了 ModelNotFoundError 为 e：
        记录器.错误(e)
        sys.exit(1) # 以非零退出代码退出系统以指示错误
    除了异常 e：
        记录器.错误(e)
        返回无，无



def 推理（图像）：
    ”“”
    图像推理
    :param images: 可以是单个图像、图像列表或目录
    :return: 结果列表
    ”“”
    logger.info(“开始图像推理！”)
    模型，类别 = load_model()
    如果模型为无：
        raise ModelNotFoundError(“模型未加载！”)

    res = 模型（图像），类别
    logger.info(&quot;图像推理完成！&quot;)
    返回资源

如果我正常调用推理，它就像黄油一样工作
但是，当同一个函数被另一个 celery 工作函数调用时，这不起作用。
它甚至不会抛出任何错误。
调试时，model_path之后没有记录任何内容，基本上没有到达456行。
任何人都可以帮助调试为什么我无法加载模型。
正如您可能在代码中看到的那样，它使用 YOLO]]></description>
      <guid>https://stackoverflow.com/questions/77901605/not-able-to-load-and-predict-on-images-using-yolo-inside-celery-worker</guid>
      <pubDate>Mon, 29 Jan 2024 17:35:56 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 wandb 的 pytorch 框架在 Kaggle 中解决这个问题？</title>
      <link>https://stackoverflow.com/questions/77901559/how-to-solve-this-issue-in-kaggle-with-pytorch-framework-for-wandb</link>
      <description><![CDATA[ # 构建模型
    模型 = 构建模型()

    # 初始化运行
    运行 = wandb.init(entity = &#39;scortinhas&#39;,
                     项目 = &#39;mnist-教程&#39;,
                     配置=CFG，
                     保存代码=真，
                     #组=&#39;安&#39;,
                     #job_type = &#39;火车&#39;
    ）

我正在使用 Kaggle 的教程测试 W 和 B，每次我遇到这个问题并且运行确切的问题时我都无法解决它。这是下面的错误 -


我尝试升级wandb并重新启动内核，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/77901559/how-to-solve-this-issue-in-kaggle-with-pytorch-framework-for-wandb</guid>
      <pubDate>Mon, 29 Jan 2024 17:28:38 GMT</pubDate>
    </item>
    <item>
      <title>如何通过 AI/ML 分析日志</title>
      <link>https://stackoverflow.com/questions/77900640/how-to-analyze-logs-via-ai-ml</link>
      <description><![CDATA[我正在做一个小项目，尝试分析日志并在出现错误时提供根本原因和解决问题的建议。
我有一个 Databricks 作业不断运行以提供日志。我想实时分析这些日志，如果发现异常，实时提供建议。
由于这些日志是非结构化数据，我在想是否可以使用 NLP 来解决这个问题。基本了解日志的上下文并提供建议。
我曾使用机器学习模型对结构化数据进行异常检测，但这是我第一次使用非结构化数据。
我需要以下方面的帮助

如何/在哪里存储可训练的日志？我遇到了矢量数据库，但不确定它是否有帮助。
如何在 llama、gpt 模型之上训练这些基于服务的日志？由于这些模型已经拥有“世俗知识”，因此它们应该能够提供 70% 的建议。但 Databricks 作业给出了一些特定于我的服务的日志，我认为这些日志需要培训。
鉴于有现成的训练模型，如何向模型提供实时日志以使其理解上下文？

由于我是人工智能工作的新手，任何建议/程序/文档/博客/包/Azure 服务都会有很大帮助！！]]></description>
      <guid>https://stackoverflow.com/questions/77900640/how-to-analyze-logs-via-ai-ml</guid>
      <pubDate>Mon, 29 Jan 2024 15:02:18 GMT</pubDate>
    </item>
    <item>
      <title>部署在 Streamlit Coumminity Cloud 上的机器学习模型给出了错误的预测</title>
      <link>https://stackoverflow.com/questions/77899985/machine-learning-model-after-deployed-on-streamlit-coumminity-cloud-is-giving-wr</link>
      <description><![CDATA[我创建了一个垃圾邮件预测机器学习模型，为了创建一个界面，我去了 pycharm 并编写了 app.py 代码，还有另外两个文件 &lt; app.py 文件中使用了 code&gt;vectorizer.pkl 和 model.pkl，在终端上我编写了 streamlit run app.py，它把我带到了本地主机 8501 浏览器，现在一切都很顺利，做出了正确的预测。我想公开这个应用程序以在 GitHub 上分享链接。我在 streamlit 社区云上创建了一个帐户，将其与我的 GitHub 链接起来，并部署了该应用程序。 GitHub 存储库包含所有必要的文件，包括带有整个 ml 模型、app.py、model.pkl,requirements.txt 的笔记本， 向量化器.pkl。现在的问题是，使用公共链接部署的应用程序对于完全相同的输入给出了不同的预测（即说“不是垃圾邮件”而不是“垃圾邮件”）。我将输出附在此处，请告诉我该怎么做。
单击这些链接可查看附加的图像：


app.py 文件的 Github 链接：https:// github.com/ardra1111/Spam-Gaurd/blob/main/app.py
Streamlit 云应用程序的链接：https://spam-gaurd-ir5t9kbcsjpdkus4cveywj.streamlit.app/ 
当我第一次在 streamlit.io 上部署该应用程序时，它运行良好。几周前，但由于不活动，链接不起作用，所以我删除了该应用程序，并重新开始将其部署为新应用程序，我不明白下一步应该做什么来解决此问题？
我第一次尝试使用渲染将其部署在那里，并且遇到了同样的问题，请帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/77899985/machine-learning-model-after-deployed-on-streamlit-coumminity-cloud-is-giving-wr</guid>
      <pubDate>Mon, 29 Jan 2024 13:14:02 GMT</pubDate>
    </item>
    <item>
      <title>通过 Docker 镜像使用时将 Faiss 索引写入文件的问题</title>
      <link>https://stackoverflow.com/questions/77899677/issue-on-writing-faiss-index-to-a-file-when-using-through-docker-image</link>
      <description><![CDATA[我有一个 FastAPI Docker 映像，在启动部分中，我从 Redis 获取 FAISS 索引的二进制版本，使用 pickle.loads 解封它，然后使用
file_path = os.path.join(folder_path, &#39;index.faiss&#39;)
faiss.write_index(faissModelFromRedis,file_path)
将其写入文件。这在本地有效，但是当使用 Docker 部署到 Azure Web App 时，它会抛出异常
文件“/app/main.py”，第 38 行，位于 loadModelAndSetRetriever 2024-01-27T14:03:27.547507225Z faiss.write_index(faiss_model,file_path) 2024-01-27T14:03:27.547510425Z 文件“ /usr/local/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py”，第 10200 行，在 write_index 2024-01-27T14:03:27.547513825Z 返回 _swigfaiss_avx2.write_index(*args) 2024-01-27T14 ：03：27.547517125Z TypeError：重载函数“write_index”的参数数量或类型错误。 2024-01-27T14:03:27.547520225Z 可能的 C/C++ 原型是： 2024-01-27T14:03:27.547523325Z faiss::write_index(faiss::Index const *,char const *) 2024-01-27T14:03 :27.547526526Z faiss::write_index(faiss::Index const *,FILE *) 2024-01-27T14:03:27.547529526Z faiss::write_index(faiss::Index const *,faiss::IOWriter *) 
我们如何解决这个问题？
我尝试使用 pickle.dumps，但使用 Faiss，它无法读取已保存文件的索引。
还尝试在 Dockerfile 中添加 chmod 777 或新用户添加命令，认为这是 faiss 的写入访问问题。]]></description>
      <guid>https://stackoverflow.com/questions/77899677/issue-on-writing-faiss-index-to-a-file-when-using-through-docker-image</guid>
      <pubDate>Mon, 29 Jan 2024 12:19:42 GMT</pubDate>
    </item>
    <item>
      <title>机器学习中的语音识别[关闭]</title>
      <link>https://stackoverflow.com/questions/77899035/speech-recognition-in-machine-learning</link>
      <description><![CDATA[我举办了一场关于机器学习中语音识别的研讨会，在这次研讨会中我们提供了演示、算法和演示文稿
任何人都可以帮助我进行 ML 语音识别
用于 ML 模型中的语音识别
、演示和演示]]></description>
      <guid>https://stackoverflow.com/questions/77899035/speech-recognition-in-machine-learning</guid>
      <pubDate>Mon, 29 Jan 2024 10:30:40 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI Gym 步骤功能不起作用错误需要 5 个变量才能解压</title>
      <link>https://stackoverflow.com/questions/77898872/openai-gym-step-function-doesnt-work-error-needs-5-variables-to-unpack</link>
      <description><![CDATA[导入健身房
从 nes_py.wrappers 导入 JoypadSpace
从 Contra.actions 导入 SIMPLE_MOVMENT、COMPLEX_MOVMENT、RIGHT_ONLY
SIMPLE_MOVMENT #简化环境

环境=gym.make（&#39;Contra-v0&#39;）
envi = JoypadSpace(envi, SIMPLE_MOVMENT)

重新启动=真

对于范围（1000）内的帧：
    如果重新启动：
        状态 = envi.reset()
    action = envi.action_space.sample() # 生成随机动作
    state,reward,restart,truncated,inf=envi.step(action)#采取随机生成的动作
    envi.render() # 只显示游戏
环境.close()

运行代码后，出现以下错误：
&lt;前&gt;&lt;代码&gt;---&gt; 50 观察、奖励、终止、截断、info = self.env.step(action)
     51 self._elapsed_steps += 1
     53 如果 self._elapsed_steps &gt;= self._max_episode_steps：

ValueError：没有足够的值来解压（预期为 5，实际为 4）

)
我一直在努力解决这个问题，但我不知道如何解决它。我尝试使用较旧的健身房版本，但仍然不起作用
其他人就堆栈溢出提出了同样的问题，但有一个不清楚的答案。]]></description>
      <guid>https://stackoverflow.com/questions/77898872/openai-gym-step-function-doesnt-work-error-needs-5-variables-to-unpack</guid>
      <pubDate>Mon, 29 Jan 2024 10:06:00 GMT</pubDate>
    </item>
    <item>
      <title>在colab中运行excel文件</title>
      <link>https://stackoverflow.com/questions/77898474/running-excel-file-in-colab</link>
      <description><![CDATA[尝试在 Google colab 中加载 Excel 工作表时收到错误消息。 Excel 包含 5000 多行。
我尝试过：data=pd.read_excel(&#39;/content/data_ml.xlsx&#39;)
获得错误：:---------------------------------------- -----------------------------------
BadZipFile Traceback（最近一次调用最后一次）
&lt;ipython-input-3-0935045ece15&gt;在&lt;细胞系：1&gt;()
----&gt; 1 data=pd.read_excel(&#39;/content/data_ml.xlsx&#39;)

6帧
_RealGetContents(self) 中的 /usr/lib/python3.10/zipfile.py
   第1334章
   第1335章
-&gt;第1336章
   第1337章1：
   第1338章

BadZipFile：文件不是 zip 文件
]]></description>
      <guid>https://stackoverflow.com/questions/77898474/running-excel-file-in-colab</guid>
      <pubDate>Mon, 29 Jan 2024 09:04:56 GMT</pubDate>
    </item>
    <item>
      <title>在 Colab 上访问 TensorFlow Open Image open_images_v4/200k 时出现问题；继续下载原始数据集</title>
      <link>https://stackoverflow.com/questions/77896924/trouble-access-to-tensorflow-open-image-open-images-v4-200k-on-colab-keep-downl</link>
      <description><![CDATA[所以我尝试在 Google Colab 上导入 open_images_v4/200k 数据集，但它不断下载超过 500 GiB 的原始文件，我没有足够的存储空间，也不需要使用那么大的数据集.
我尝试过使用 ds, info = tfds.load(&#39;open_images_v4/200k&#39;, with_info=True) 进行基本导入
然后开始下载，预计大小为 565.11 GiB。第二次我得到了明显的错误，我没有足够的存储空间。
我只想使用 60.70 GiB v4/200k。
请帮忙！]]></description>
      <guid>https://stackoverflow.com/questions/77896924/trouble-access-to-tensorflow-open-image-open-images-v4-200k-on-colab-keep-downl</guid>
      <pubDate>Mon, 29 Jan 2024 00:35:37 GMT</pubDate>
    </item>
    <item>
      <title>让谢尔曼-莫里森更新更加高效</title>
      <link>https://stackoverflow.com/questions/77884077/make-sherman-morrison-update-more-efficient</link>
      <description><![CDATA[我需要计算 CIFAR10 数据集子集的点上的参数梯度的协方差矩阵。为此，我有以下代码：
from torch.func import function_call, vmap, grad

model1 = LogisticModel().to(设备)

def loss_fn（预测，目标）：
  损失 = nn.CrossEntropyLoss()
  回波损耗（预测、目标）

defcompute_loss（参数，缓冲区，样本，目标）：
  批次=样本.unsqueeze(0)
  目标 = target.unsqueeze(0)

  预测 = function_call(model1, (params, buffers), (batch,))
  损失= loss_fn（预测，目标）
  回波损耗

ft_compute_grad = grad(compute_loss)
ft_compute_sample_grad = vmap(ft_compute_grad, in_dims=(无, 无, 0, 0))

def sherman_morrison_update(A, u, v):
  vT = v.T
  金=A@u

  α = 1/(1 + vT@Au)
  A = A - alpha*torch.outer(Au, vT@A)
  返回A

testloader1 = DataLoader（test_dataset，batch_size = 512）
params = {k: v.detach() for k, v in model1.named_pa​​rameters()}
buffers = {k: v.detach() for k, v in model1.named_buffers()}
w = 0

p_covs = {p:torch.eye(q.flatten().shape[0]).to(device) for p,q in param_grads.items()}
param_grad_mean = {p:torch.zeros(q​​.flatten().shape[0]).to(device) for p,q in param_grads.items()}

对于 tqdm(testloader1) 中的 x,y：
  param_grads = ft_compute_sample_grad(参数、缓冲区、x.to(设备)、y.to(设备))
  对于 p，q，zip 中的平均值（param_grads.values（），p_covs，param_grad_mean）：
    对于 p 中的 p_grad：
      w += 1
      diff = p_grad.flatten() - param_grad_mean[平均值]
      param_grad_mean[平均值] += diff / w
      p_covs[q] = sherman_morrison_update(A=p_covs[q], u=diff, v= diff)

现在，这是非常低效的，并且在每次迭代中执行此操作都非常耗时。
此外，我们无法真正同时获取所有点的参数梯度，因为这会导致内存问题（因此我转向 Sherman-Morrison）。
有没有办法提高效率？谢尔曼-莫里森的更好实施？还有什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/77884077/make-sherman-morrison-update-more-efficient</guid>
      <pubDate>Fri, 26 Jan 2024 03:37:37 GMT</pubDate>
    </item>
    <item>
      <title>识别 SMOTE 生成的合成样本</title>
      <link>https://stackoverflow.com/questions/77870847/identify-the-synthetic-samples-generated-by-smote</link>
      <description><![CDATA[我有一个带标签的数据集，X 形状为 7000 x 2400，y 形状为 7000。数据严重不平衡，因此我尝试使用 SMOTE 生成合成样本。不过，我想确定 SMOTE 实际生成的合成样本。
作为示例，下面是一个代码片段：
将 pandas 导入为 pd
将 numpy 导入为 np
从 sklearn.datasets 导入 load_iris
从 imblearn.over_sampling 导入 SMOTE

虹膜 = load_iris()

X = 虹膜[&#39;数据&#39;]
y = 虹膜[&#39;目标&#39;]

#数据是平衡的，所以我故意去掉了一些样本
X = X[:125,::]
y = y[:125]

过采样 = SMOTE()
X_smt, y_smt = oversample.fit_resample(X, y)

数组 X_smt 和 y_smt 既有原始样本又有合成样本。是否有一种简单的方法可以通过索引或其他机制来识别合成样本？]]></description>
      <guid>https://stackoverflow.com/questions/77870847/identify-the-synthetic-samples-generated-by-smote</guid>
      <pubDate>Wed, 24 Jan 2024 06:04:18 GMT</pubDate>
    </item>
    <item>
      <title>Flower - 联邦学习的每一轮模型精度都是相同的[关闭]</title>
      <link>https://stackoverflow.com/questions/77855250/model-accuracy-is-the-same-after-every-round-with-flower-federated-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77855250/model-accuracy-is-the-same-after-every-round-with-flower-federated-learning</guid>
      <pubDate>Sun, 21 Jan 2024 14:33:27 GMT</pubDate>
    </item>
    <item>
      <title>手动实施多元线性回归的 AIC 分数</title>
      <link>https://stackoverflow.com/questions/58965317/implementing-aic-score-for-multiple-linear-regression-manually</link>
      <description><![CDATA[我已经手动实现了一个多元线性回归类，现在我正在研究度量方法。我尝试手动计算AIC和BIC分数，但结果不正确。原因是我没有使用 Log Likelihood 函数，而是使用了 SSE 方法。您能否建议我如何更改实现来计算完整的 AIC 和 BIC 分数？
这是我的方法现在的样子：
 def AIC_BIC(self, 实际 = None, pred = None):
    如果实际为 None：
      实际 = 自我响应
    如果 pred 为 None：
      pred = self.response_pred

    n = len（实际）
    k = self.num_features

    残差 = np.subtract(pred, 实际)
    RSS = np.sum(np.power(残差, 2))

    AIC = n * np.log(RSS / n) + 2 * k
    BIC = n * np.log(RSS / n) + k * np.log(n)

    退货（AIC、BIC）

请尝试为我提供手动方法，而不是图书馆调用。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/58965317/implementing-aic-score-for-multiple-linear-regression-manually</guid>
      <pubDate>Thu, 21 Nov 2019 00:11:59 GMT</pubDate>
    </item>
    </channel>
</rss>