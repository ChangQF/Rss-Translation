<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 11 Nov 2024 03:21:52 GMT</lastBuildDate>
    <item>
      <title>为什么我开始训练时准确度和验证准确度都很低？[关闭]</title>
      <link>https://stackoverflow.com/questions/79175873/why-is-the-accuracy-and-validation-acuuracy-are-very-low-when-i-start-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79175873/why-is-the-accuracy-and-validation-acuuracy-are-very-low-when-i-start-training</guid>
      <pubDate>Sun, 10 Nov 2024 21:35:24 GMT</pubDate>
    </item>
    <item>
      <title>由于填充，遮罩后训练数据和标签的形状不一样</title>
      <link>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79175635/training-data-and-labels-dont-have-the-same-shape-after-masking-due-padding</guid>
      <pubDate>Sun, 10 Nov 2024 19:56:09 GMT</pubDate>
    </item>
    <item>
      <title>高斯过程回归实现中矩阵乘法的`ValueError`</title>
      <link>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</link>
      <description><![CDATA[我正在使用平方指数核在 Python 中实现高斯过程回归 (GPR) 模型。但是，我在 predict 方法的矩阵乘法步骤中遇到了 ValueError，特别是在尝试计算平均预测时。
我看到的错误是：
ValueError：matmul：输入操作数 1 在其核心维度 0 中不匹配，gufunc 签名为 
(n?,k),(k,m?)-&gt;(n?,m?)（大小 10 与 100 不同）

代码详细信息
以下是此错误中涉及的代码的细分：
import numpy as np

class SquaredExponentialKernel:
def __init__(self, length_scale=1.0, variance=1.0):
self.length_scale = length_scale
self.variance = variance

def __call__(self, x1, x2):
dist_sq = np.sum((x1 - x2)**2)
return self.variance * np.exp(-0.5 * dist_sq / self.length_scale**2)

def cov_matrix(x1, x2, cov_function) -&gt; np.array:
返回 np.array([[cov_function(a, b) for a in x1] for b in x2])

class GPR:
def __init__(self, data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma: float = 0):
self.noise = white_noise_sigma
self.data_x = data_x
self.data_y = data_y
self.covariance_function = covariance_function
self._inverse_of_covariance_matrix_of_input_noise_adj = np.linalg.inv(
cov_matrix(data_x, data_x, covariance_function) + self.noise * np.identity(len(self.data_x))
)
self._memory = None

def predict(self, test_data: np.ndarray) -&gt;; np.ndarray:
KXX_star = cov_matrix(test_data, self.data_x, self.covariance_function)
KX_starX_star = cov_matrix(test_data, test_data, self.covariance_function)
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)
cov_test_data = KX_starX_star - KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ KXX_star.T)
var_test_data = np.diag(cov_test_data)
self._memory = {&#39;mean&#39;: mean_test_data, &#39;covariance_matrix&#39;: cov_test_data, &#39;variance&#39;: var_test_data}
返回 mean_test_data

# 测试数据
np.random.seed(69)
data_x = np.linspace(-5, 5, 10).reshape(-1, 1)
data_y = np.sin(data_x) + 0.1 * np.random.randn(10, 1)

# 实例化并预测
gpr_se = GPR(data_x, data_y, covariance_function=SquaredExponentialKernel(), white_noise_sigma=0.1)
test_data = np.linspace(-6, 6, 100).reshape(-1, 1)
mean_predictions = gpr_se.predict(test_data)

维度细分
这是矩阵乘法的维度分析，其中误差发生：

KXX_star 计算为 cov_matrix(test_data, self.data_x, self.covariance_function)，结果形状为 (100, 10)。
self._inverse_of_covariance_matrix_of_input_noise_adj 在 __init__ 方法中计算，形状为 (10, 10)。
self.data_y 形状为 (10, 1)。

有问题的行是：
mean_test_data = KXX_star @ (self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y)

这应该产生形状为 (100, 1) 的结果，因为：

KXX_star 具有形状 (100, 10)，
(self._inverse_of_covariance_matrix_of_input_noise_adj @ self.data_y) 导致形状为 (10, 1)。

当矩阵乘法的维度似乎对齐时，为什么我在这里收到维度不匹配错误？我该如何修复它？
我预计这个矩阵乘法能够正常工作，因为尺寸在纸面上看起来是兼容的：KXX_star (100, 10) 乘以 (10, 1) 应该得到 (100, 1)。然而，错误表明尺寸不匹配，这意味着某些东西没有按预期对齐。我检查了 self.data_y、self._inverse_of_covariance_matrix_of_input_noise_adj 和 KXX_star 的形状。还尝试重塑 data_y 以确保它始终为 (10, 1)，但错误仍然存​​在。我期望获得 test_data 的平均预测值作为形状为 (100, 1) 的向量，并且没有任何维度问题。]]></description>
      <guid>https://stackoverflow.com/questions/79175150/valueerror-in-matrix-multiplication-for-gaussian-process-regression-implementa</guid>
      <pubDate>Sun, 10 Nov 2024 15:14:18 GMT</pubDate>
    </item>
    <item>
      <title>训练 XGBoost 模型时超参数显示为“无”</title>
      <link>https://stackoverflow.com/questions/79174302/hyperparameters-show-as-none-when-training-xgboost-model</link>
      <description><![CDATA[我正在尝试拟合 XGBoost 回归模型。一旦我训练它，所有超参数都会报告为“无”。
{&#39;objective&#39;: &#39;reg:squarederror&#39;,
&#39;base_score&#39;: None,
&#39;booster&#39;: None,
&#39;colsample_bylevel&#39;: None,
&#39;colsample_bynode&#39;: None,
&#39;colsample_bytree&#39;: None,
&#39;device&#39;: None,
&#39;eval_metric&#39;: None,
&#39;gamma&#39;: None,
&#39;grow_policy&#39;: None,
&#39;interaction_constraints&#39;: None,
&#39;learning_rate&#39;: None,
&#39;max_bin&#39;: None,
&#39;max_cat_threshold&#39;: None,
&#39;max_cat_to_onehot&#39;: None,
&#39;max_delta_step&#39;: None,
&#39;max_depth&#39;: None,
&#39;max_leaves&#39;: None,
&#39;min_child_weight&#39;: None,
&#39;monotone_constraints&#39;: None,
&#39;multi_strategy&#39;: None,
&#39;n_jobs&#39;: None,
&#39;num_parallel_tree&#39;: None,
&#39;random_state&#39;: None,
&#39;reg_alpha&#39;: None,
...
&#39;scale_pos_weight&#39;: None,
&#39;subsample&#39;: None,
&#39;tree_method&#39;: None,
&#39;validate_parameters&#39;: None,
&#39;verbosity&#39;: None}

当我运行 xgb.plot_importance(model, ax=plt.gca()) 时，考虑到数据，它给出了一个看似合理的列表。这让我认为进行了一些成功的训练，但为什么所有超参数都报告为 None？]]></description>
      <guid>https://stackoverflow.com/questions/79174302/hyperparameters-show-as-none-when-training-xgboost-model</guid>
      <pubDate>Sun, 10 Nov 2024 06:53:04 GMT</pubDate>
    </item>
    <item>
      <title>尝试弄清楚如何实施 ImGWO</title>
      <link>https://stackoverflow.com/questions/79174187/trying-to-figure-out-how-to-implement-imgwo</link>
      <description><![CDATA[我使用 Google Gemini 填充了这段代码，但我不知道如何使用它。
我正在做一个异常检测和训练模型的项目。我做了一些研究，发现改进的灰狼算法在检测异常方面表现良好。
如果有人能帮我解决这个问题，那将是一个很大的帮助。
#提示：使用 x_train_scaled 和 x_test_scaled 为上述模型实现改进的灰狼优化器算法

import numpy as np
from sklearn.metrics import accuracy_score

#假设 x_train_scaled 和 x_test_scaled 是从前面的代码定义的

def Improved_grey_wolf_optimizer(objective_function, lb, ub, dim, SearchAgents_no=50, Max_iter=1000):
#初始化 alpha、beta 和 delta_pos
Alpha_pos = np.zeros(dim)
Alpha_score = float(&#39;inf&#39;)

Beta_pos = np.zeros(dim)
Beta_score = float(&#39;inf&#39;)

Delta_pos = np.zeros(dim)
Delta_score = float(&#39;inf&#39;)

# 初始化搜索代理的位置
Positions = np.random.uniform(0, 1, (SearchAgents_no, dim)) * (ub - lb) + lb
Convergence_curve = np.zeros(Max_iter)

# 主循环
for l in range(0, Max_iter):
for i in range(0, SearchAgents_no):
# 返回超出搜索空间边界的搜索代理
for j in range(dim):
Positions[i, j] = np.clip(Positions[i, j], lb[j], ub[j])

# 计算每个搜索代理的目标函数
fitness = objective_function(Positions[i, :])

# 更新 Alpha， Beta 和 Delta
如果 fitness &lt; Alpha_score:
Alpha_score = fitness
Alpha_pos = Positions[i, :].copy()

如果 fitness &gt; Alpha_score 且 fitness &lt; Beta_score:
Beta_score = fitness
Beta_pos = Positions[i, :].copy()

如果 fitness &gt; Alpha_score 且 fitness &gt; Beta_score 且 fitness &lt; Delta_score:
Delta_score = fitness
Delta_pos = Positions[i, :].copy()

a = 2 - l * ((2) / Max_iter) # a 从 2 线性减小到 0

# 更新包括 omegas 在内的搜索代理的位置
for i in range(0, SearchAgents_no):
for j in range(0, dim):
r1 = np.random.rand()
r2 = np.random.rand()
A1 = 2 * a * r1 - a
C1 = 2 * r2

D_alpha = abs(C1 * Alpha_pos[j] - Positions[i, j])
X1 = Alpha_pos[j] - A1 * D_alpha

r1 = np.random.rand()
r2 = np.random.rand()
A2 = 2 * a * r1 - a
C2 = 2 * r2

D_beta = abs(C2 * Beta_pos[j] - Positions[i, j])
X2 = Beta_pos[j] - A2 * D_beta

r1 = np.random.rand()
r2 = np.random.rand()
A3 = 2 * a * r1 - a
C3 = 2 * r2

D_delta = abs(C3 * Delta_pos[j] - Positions[i, j])
X3 = Delta_pos[j] - A3 * D_delta

Positions[i, j] = (X1 + X2 + X3) / 3

Convergence_curve[l] = Alpha_score

return Alpha_pos, Convergence_curve

# 示例用法（替换为您的实际目标函数和边界）
def objective_function(solution):
# 这是您将模型与 GWO 集成的地方，预测使用解决方案（权重）
# 然后计算 y_test 的错误。
# 将其替换为您的实际模型评估函数
# 以下只是运行示例的随机值。
y_pred = np.random.randint(0, 10, size=len(x_test_scaled))
return 1 - accuracy_score(y_test, y_pred)

lb = np.array([-1]*x_train_scaled.shape[1]) # 用下限替换
ub = np.array([1]*x_train_scaled.shape[1]) # 用上限替换
dim = x_train_scaled.shape[1]

gwo_y_pred, convergence_curve = Improved_grey_wolf_optimizer(objective_function, lb, ub, dim)
gwo_y_pred

# print(&quot;Improved Grey Wolf Optimiser Report:&quot;)
# print(classification_report(y_test, gwo_y_pred))
print(&quot;Improved Grey Wolf Optimiser准确度：&quot;，accuracy_score(y_test, gwo_y_pred))

这是使用 SVM 实现的，
如果您想知道我在实现之前做了什么，希望这可能会有所帮助。
来自 sklearn.svm 导入 SVC
导入警告
来自 sklearn.exceptions 导入 DataConversionWarning

# 抑制 DataConversionWarning
warnings.filterwarnings(action=&#39;ignore&#39;, category=DataConversionWarning)

# 使用默认参数的支持向量机分类器
svm_model = SVC(random_state=42)

# 在训练数据上拟合模型
svm_model.fit(x_train_scaled, y_train.to_numpy().ravel())

# 在测试集上进行预测
svm_y_pred = svm_model.predict(x_test_scaled)

# SVM 的性能指标
print(&quot;SVM 分类报告：&quot;)
print(classification_report(y_test, svm_y_pred))
print(&quot;SVM 准确率：&quot;, accuracy_score(y_test, svm_y_pred))
]]></description>
      <guid>https://stackoverflow.com/questions/79174187/trying-to-figure-out-how-to-implement-imgwo</guid>
      <pubDate>Sun, 10 Nov 2024 05:19:51 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 模型权重无法正确加载</title>
      <link>https://stackoverflow.com/questions/79173992/tensorflow-model-weights-not-loading-correctly</link>
      <description><![CDATA[我正在尝试用 C++ 为国际象棋引擎加载一个 TensorFlow 神经网络。该模型是在 Python 中训练的，我正在将权重转换为二进制文件，但在 C++ 中加载时尺寸错误。
Python 模型架构：

输入：768 个神经元（扁平的 8x8x12 棋盘状态）
隐藏层：1024 -&gt; 512 -&gt; 256 -&gt; 128 -&gt; 64
输出：1 个神经元（tanh 激活）

在 c++ 中加载时，我得到维度不匹配：
输入大小：768
层数：6
处理层 0
输入大小：1024 # 应为 768
输出大小：768 # 应为 1024

这是我的 python 转换代码：
def convert_model_to_binary(model_path, output_path):
# 加载 TensorFlow 模型
chess_nn = pickle.load(open(model_path, &quot;rb&quot;))
model = chess_nn.model

with open(output_path, &quot;wb&quot;) as f:
# 写入密集层的数量
dense_layers = [
layer
for layer in model.layers
if isinstance(layer, tf.keras.layers.Dense)
]
np.array([len(dense_layers)], dtype=np.int32).tofile(f)

for layer in density_layers:
weights,biases = layer.get_weights()

# 转换为 float32 以实现 c++ 兼容性
weights = weights.astype(
np.float32
)# 无需转置（权重已经处于正确的形状）
biases = biases.astype(np.float32)

# 写入输入和输出维度
input_dim = weights.shape[0]# 行数（输入维度）
output_dim = weights.shape[
1
]# 列数（输出维度）

np.array([input_dim, output_dim], dtype=np.int32).tofile(f)
np.array([output_dim], dtype=np.int32).tofile(f) # 偏置形状

weights.tofile(f)
biases.tofile(f)

和 c++ 加载代码：
bool load_model(const std::string &amp;filename)
{
std::ifstream file(filename, std::ios::binary);
int32_t num_layers;
file.read(reinterpret_cast&lt;char&gt;(&amp;num_layers), sizeof(int32_t));
la​​yer.resize(num_layers);
对于 (int i = 0; i &lt; num_layers; i++)
{
int32_t weight_shape[2];
file.read(reinterpret_cast&lt;char&gt;(weight_shape), 2 sizeof(int32_t));
int32_t bias_shape[1];
file.read(reinterpret_cast&lt;char&gt;(bias_shape), sizeof(int32_t));
la​​yer[i].input_size = weight_shape[1];
layer[i].output_size = weight_shape[0];
layer[i].weights.resize(weight_shape[0] weight_shape[1]);
la​​yer[i].biases.resize(bias_shape[0]);
file.read(reinterpret_cast&lt;char&gt;(layers[i].weights.data()), layer[i].weights.size() sizeof(float));
file.read(reinterpret_cast&lt;char&gt;(layers[i].biases.data()), layers[i].biases.size() sizeof(float));
}
return true;
}

我尝试过的方法：

在保存之前在 python 中转置权重：

weights = weights.T.astype(np.float32)

仍然有维度不匹配，但顺序相反

在 c++ 中交换输入/输出维度：

layers[i].input_size = weight_shape[0];
layers[i].output_size = weight_shape[1];

错误相同但维度不同

在 c++ 中更改权重指数计算：

size_t weight_idx = i * layer.input_size + j; // 原始
size_t weight_idx = j * layer.output_size + i; // 尝试过这个
size_t weight_idx = i + j layer.output_size; // 和这个

仍然得到错误的预测
预期：

权重应以正确的尺寸加载（768-&gt;1024-&gt;512-&gt;256-&gt;128-&gt;64-&gt;1）
模型应给出与 Python 版本类似的预测
输入板状态应正确处理所有层

实际结果：

尺寸反转（1024-&gt;768、512-&gt;1024 等）
在每一层都得到“输入大小不匹配”错误
最终预测总是返回 0
]]></description>
      <guid>https://stackoverflow.com/questions/79173992/tensorflow-model-weights-not-loading-correctly</guid>
      <pubDate>Sun, 10 Nov 2024 01:32:39 GMT</pubDate>
    </item>
    <item>
      <title>尽管测试准确率很高（91％），但模型仍预测 Tkinter GUI 中的同一类 [关闭]</title>
      <link>https://stackoverflow.com/questions/79172357/model-predicts-the-same-class-in-tkinter-gui-despite-high-test-accuracy-91</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79172357/model-predicts-the-same-class-in-tkinter-gui-despite-high-test-accuracy-91</guid>
      <pubDate>Sat, 09 Nov 2024 08:08:39 GMT</pubDate>
    </item>
    <item>
      <title>如何使用自定义数据训练 ssd300 模型[关闭]</title>
      <link>https://stackoverflow.com/questions/79172071/how-to-train-ssd300-model-with-custom-data</link>
      <description><![CDATA[我有一个我国的汽车数据集，我想用SSD300模型重新训练这个数据集，我使用python语言，使用pytorch。
我尝试了github上的一些源代码，但大多数都有库错误或识别效果不佳。
我正在寻找适用于python3.12的pytorch源代码]]></description>
      <guid>https://stackoverflow.com/questions/79172071/how-to-train-ssd300-model-with-custom-data</guid>
      <pubDate>Sat, 09 Nov 2024 03:40:55 GMT</pubDate>
    </item>
    <item>
      <title>如何修复错误 ValueError：预期输入 batch_size (49) 与目标 batch_size (64) 匹配</title>
      <link>https://stackoverflow.com/questions/79172053/how-to-fix-the-error-valueerror-expected-input-batch-size-49-to-match-target</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79172053/how-to-fix-the-error-valueerror-expected-input-batch-size-49-to-match-target</guid>
      <pubDate>Sat, 09 Nov 2024 03:24:43 GMT</pubDate>
    </item>
    <item>
      <title>使用 SelfQueryRetriever 获取文档相似度分数 - Langchain</title>
      <link>https://stackoverflow.com/questions/79165072/getting-document-similarity-scores-with-selfqueryretriever-langchain</link>
      <description><![CDATA[我希望能够在使用 SelfQueryRetriever 时获取检索到的文档的相似度分数，如下所示。
我制作了一个自查询检索器，如下所示：
retriever = SelfQueryRetriever.from_llm(
llm = llm,
vectorstore = vectorstore,
document_contents = document_content_description,
metadata_field_info = metadata_field_info,
enable_limit=True, 
search_type = &quot;similarity_score_threshold&quot;,
search_kwargs={&quot;score_threshold&quot;: 0.80, &quot;k&quot;: 5},
verbose=True
)

检索器能够按预期检索文档，但我想以某种方式显示检索到的文档的相似度分数。可以做到这一点吗？如何做到？检索器返回带有 page_content 和元数据键的文档。]]></description>
      <guid>https://stackoverflow.com/questions/79165072/getting-document-similarity-scores-with-selfqueryretriever-langchain</guid>
      <pubDate>Thu, 07 Nov 2024 05:01:57 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用函数 shap.Explainer 会根据输入的不同顺序获得不同的 shap 值？</title>
      <link>https://stackoverflow.com/questions/79152799/why-i-get-different-shap-values-according-to-the-different-order-of-inputs-by-us</link>
      <description><![CDATA[我训练了一个二分类模型，并想使用 shap.Explainer 来分析特征贡献。
代码如下：
def f(x):
return model.predict_proba(x)[:, 1]

X100 = shap.utils.sample(X_train, 100)

explainer = shap.Explainer(f, X100, seed=2023)
shap_values = explainer(data.iloc[[0,1,2,3], :])

shap_values.values 的结果如下：




Feature 1
...




sample 0
-0.009703
...


样本 1
-0.009297
...


样本 2
-0.007699
...


样本 3
0.032624
...



但是当输入顺序改变时：
def f(x):
return model.predict_proba(x)[:, 1]

X100 = shap.utils.sample(X_train, 100)

explainer = shap.Explainer(f, X100, seed=2023)
shap_values = explainer(data.iloc[[1,0,2,3], :])

样本 0 和样本 1 的结果已更改：




特征 1
...




样本 1
-0.010012
...


样本0
-0.008277
...


样本 2
-0.007699
...


样本 3
0.032624
...



我不知道有什么区别。]]></description>
      <guid>https://stackoverflow.com/questions/79152799/why-i-get-different-shap-values-according-to-the-different-order-of-inputs-by-us</guid>
      <pubDate>Sun, 03 Nov 2024 13:22:12 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Gradio 中的输入/输出前添加标题或文本？</title>
      <link>https://stackoverflow.com/questions/76901604/how-to-add-heading-or-text-before-input-output-in-gradio</link>
      <description><![CDATA[我做了一个 MNIST 机器学习项目，并将其部署在 gradio 上。任何用户都不会明白他应该输入什么才能使用该模型。所以我想在 gradio live 网站上添加标题或描述，以便任何人都能理解。
我尝试使用 gradio block、gradio.markdown，但它在 Google colab 上不起作用]]></description>
      <guid>https://stackoverflow.com/questions/76901604/how-to-add-heading-or-text-before-input-output-in-gradio</guid>
      <pubDate>Mon, 14 Aug 2023 19:17:22 GMT</pubDate>
    </item>
    <item>
      <title>AttributeError：'tuple' 没有属性 'to'</title>
      <link>https://stackoverflow.com/questions/63825841/attributeerror-tuple-has-no-attribute-to</link>
      <description><![CDATA[我正在编写这个图像分类器，我已经定义了加载器，但出现了这个错误，我对此一无所知。
我已经定义了火车加载器，为了更好地解释，我尝试了这个
for ina,lab in train_loader:
print(type(ina))
print(type(lab)) 

我得到了
&lt;class &#39;torch.Tensor&#39;&gt;
&lt;class &#39;tuple&#39;&gt;

现在，为了训练模型，我做了
def train_model(model,optimizer,n_epochs,criterion):
start_time = time.time()
for epoch in range(1,n_epochs-1):
epoch_time = time.time()
epoch_loss = 0
correct = 0
total = 0
print( &quot;Epoch {}/{}&quot;.format(epoch,n_epochs))

model.train()

for input,labels in train_loader:
input = input.to(device)
labels = labels.to(device)
optimizer.zero_grad()
output = model(inputs)
loss = criterion(output,labels)
loss.backward()
optimizer.step()
epoch_loss +=loss.item()
_,pred =torch.max(output,1)
correct += (pred.cpu()==label.cpu()).sum().item()
total +=labels.shape[0]

acc = correct/total


我得到了错误：
Epoch 1/15
------------------------------------------------------------------------------
AttributeError Traceback (most recent call last)
&lt;ipython-input-36-fea243b3636a&gt; in &lt;module&gt;
----&gt; 1 train_model(model=arch, optimizer=optim, n_epochs=15, criterion=criterion)

&lt;ipython-input-34-b53149a4bac0&gt;在 train_model(model、optimizer、n_epochs、criterion) 中
12 用于 train_loader 中的输入、标签：
13 输入 = 输入。到 (device)
---&gt; 14 标签 = 标签。到 (device)
15 优化器。zero_grad()
16 输出 = 模型 (输入)

AttributeError: &#39;tuple&#39; 对象没有属性 &#39;to&#39;

如果您想要更多信息，请告诉我！
谢谢
编辑：标签看起来像这样。
这是蜜蜂和黄蜂之间的图像分类。它还包含昆虫和非昆虫
(&#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;昆虫&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;, &#39;昆虫&#39;, &#39;昆虫&#39;, &#39;其他&#39;, &#39;蜜蜂&#39;, &#39;其他&#39;, &#39;黄蜂&#39;, &#39;其他&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;, &#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;其他&#39;, &#39;蜜蜂&#39;, &#39;黄蜂&#39;, &#39;蜜蜂&#39;)
(&#39;黄蜂&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;蜜蜂&#39;, &#39;其他&#39;, &#39;黄蜂&#39;, &#39;昆虫&#39;, &#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;昆虫&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;蜜蜂&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;昆虫&#39;、&#39;黄蜂&#39;、&#39;黄蜂&#39;、&#39;蜜蜂&#39;、&#39;黄蜂&#39;、&#39;昆虫&#39;、&#39;蜜蜂&#39;、&#39;蜜蜂&#39;、&#39;昆虫&#39;、&#39;其他&#39;）]]></description>
      <guid>https://stackoverflow.com/questions/63825841/attributeerror-tuple-has-no-attribute-to</guid>
      <pubDate>Thu, 10 Sep 2020 08:34:32 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 模型未进行训练</title>
      <link>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</link>
      <description><![CDATA[我有一个问题，已经一个星期没法解决了。我正在尝试构建 CIFAR-10 分类器，但每个批次后的损失值都在随机跳跃，而且准确率甚至在同一个批次上也没有提高（我甚至无法用一个批次过度拟合模型），所以我猜唯一可能的原因是 - 权重没有更新。 
我的模块类
class Net(nn.Module):
def __init__(self):
super(Net, self).__init__()
self.conv_pool = nn.Sequential(
nn.Conv2d(3, 64, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(64, 128, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(128, 256, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(256, 512, 3, padding=1),
nn.ReLU(),
nn.MaxPool2d(2, 2),
nn.Conv2d(512, 512, 1),
nn.ReLU(),
nn.MaxPool2d(2, 2))

self.fcnn = nn.Sequential(
nn.Linear(512, 2048),
nn.ReLU(),
nn.Linear(2048, 2048),
nn.ReLU(),
nn.Linear(2048, 10)
)

def forward(self, x):
x = self.conv_pool(x)
x = x.view(-1, 512)
x = self.fcnn(x)
return x

我正在使用的优化器：
net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, influence=0.9)

我的训练函数：
def train():
for epoch in range(5): # 多次循环遍历数据集
for i in range(0, df_size):
# 获取数据

try:
images, labels = loadBatch(ds, i)
except BaseException:
continue

# 包装 
输入 = Variable(images)

optimizer.zero_grad()

输出 = net(inputs)

损失 = criterion(outputs, Variable(labels))

损失.backward()
optimizer.step()
acc = test(images,labels)
print(&quot;损失：&quot; + str(loss.data[0]) + &quot; 准确率 %：&quot; + str(acc) + &quot;迭代：&quot; + str(i))

if i % 40 == 39:
torch.save(net.state_dict(), &quot;model_save_cifar&quot;)

print(&quot;Finished epoch &quot; + str(epoch))

我使用的是 batch_size = 20, image_size = 32 (CIFAR-10)
loadBatch 函数返回 LongTensor 20x3x32x32 的元组（用于图像）和 LongTensor 20x1 的元组（用于标签）
如果您能帮助我或提出可能的解决方案，我将非常高兴（我猜是因为 NN 中的顺序模块，但我传递给优化器的参数似乎是正确的）]]></description>
      <guid>https://stackoverflow.com/questions/45359111/pytorch-model-is-not-training</guid>
      <pubDate>Thu, 27 Jul 2017 19:07:27 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 中的步骤和时期有什么区别？</title>
      <link>https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow</link>
      <description><![CDATA[在大多数模型中，都有一个 steps 参数，表示在数据上运行的步骤数。但我在大多数实际使用中看到，我们还会执行拟合函数 N epochs。
用 1 个 epoch 运行 1000 步和用 10 个 epoch 运行 100 步有什么区别？在实践中哪一个更好？连续 epoch 之间有任何逻辑变化吗？数据混洗？]]></description>
      <guid>https://stackoverflow.com/questions/38340311/what-is-the-difference-between-steps-and-epochs-in-tensorflow</guid>
      <pubDate>Tue, 12 Jul 2016 23:20:22 GMT</pubDate>
    </item>
    </channel>
</rss>