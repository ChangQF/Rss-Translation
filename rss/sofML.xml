<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Sun, 30 Mar 2025 12:31:53 GMT</lastBuildDate>
    <item>
      <title>有什么办法知道这些是否是真正的权重？</title>
      <link>https://stackoverflow.com/questions/79544280/is-there-any-way-to-know-if-these-are-real-weights</link>
      <description><![CDATA[我正在使用此存储库： htttps://github.com/github.com/github.com/chang-chang-chang-chang-chiy-chi/chi-chi/tract-blacknet-floff-2 &lt;22 &lt;2我是这个领域的新手，请不要重视我。
我想用存储库中的权重运行模型，但是我不知道这些是否是由它们训练的真正权重。此外，此 error 在克隆后在存储库中运行preditive.py代码时会弹出：
  ps c：\ users \ georg \ oneDrive \ documents \ prajj \ tracknet-badminton-tracking-tracking-tensorflow2＆gt; Python Predive.py
2025-03-30 12：37：07.788180：i Tensorflow/core/core/platform/cpu_feature_guard.cc：193]该张力型二进制二进制已通过Oneapi深层神经网络库（ONEDNN）优化
要在其他操作中启用它们，请使用适当的编译器标志来重建TensorFlow。
2025-03-30 12：37：07.792615：i tensorflow/core/councom/councom_runtime/process_util.cc：146]使用默认的Inter OP设置创建新线程池：2。使用Inter_op_parallelist inter_op_parallelism_threads调音以获得最佳性能。
成功加载权重
成功加载CSV文件
开始预测......
1/1 [====================================]
Trackback（最近的最新电话）：
  file＆quot＆quort c：\ user \ georg \ oneDrive \ documents \ prajj \ tracknet-badminton-tracking-tensorflow2 \ precade.predive.py＆quot＆quort＆quort＆quort＆quot＆quid＆quort＆quid＆quid＆quid＆quins; line 137 in＆lt; module
    _，cnts，_ = cv2.findcontours（h_pred [0] .copy（），cv2.retr_external，cv2.chain_approx_simple）
ValueError：没有足够的值解开包装（预期3，获得2）
警告：TensorFlow：检测对象或模型或TF.Train.Checkpoint正在用未修复的值删除。有关所讨论的特定值，请参见以下日志。要使这些警告保持沉默，请使用status.expect_partial（）。请参阅https://www.tensorflow.org/api_docs/python/tf/train/checkpoint#restoreorfor Restore函数返回的状态对象的详细信息。
警告：TensorFlow：在恢复的对象中找不到检查点中的值：（ root）.optimizer.decay
警告：TensorFlow：在恢复的对象中找不到检查点中的值：（ root）.optimizer.learning_rate
警告：TensorFlow：在恢复的对象中找不到检查点中的值：（ root）.optimizer.rho
警告：TensorFlow：在恢复对象中找不到检查点中的值：（ root）.optimizer.iter。
警告：TensorFlow：在恢复的对象中找不到检查点中的值：（root）.optimizer的状态&#39;accam_grad&#39;for（root）.conv_t1.bn_1.gamma
警告：TensorFlow：在恢复的对象中找不到检查点中的值：（root）.optimizer的状态&#39;accom_grad&#39;for（root）.conv_t1.bn_1.beta
警告：TensorFlow：在恢复的对象中找不到检查点中的值：（root）.optimizer的状态&#39;accam_grad&#39;for（root）.conv_t1.conv_1.kernel
警告：TensorFlow：在恢复的对象中找不到检查点中的值：（root）.optimizer的状态&#39;accam_grad&#39;for（root）.conv_t1.conv_1.bias
 ]]></description>
      <guid>https://stackoverflow.com/questions/79544280/is-there-any-way-to-know-if-these-are-real-weights</guid>
      <pubDate>Sun, 30 Mar 2025 07:15:48 GMT</pubDate>
    </item>
    <item>
      <title>TrackNet：使用TrackNet实时跟踪Shuttlecock，并更新分数[闭合]</title>
      <link>https://stackoverflow.com/questions/79543955/tracknet-tracking-a-shuttlecock-in-real-time-with-a-webcam-using-tracknet-and-u</link>
      <description><![CDATA[我正在尝试为项目开发羽毛球实时跟踪和评分系统。我可以使用踪迹获取实时数据吗？
我正在使用 https://github.com/qaz812345/tracknetv3 这个模型
检测视频很好，但是当我尝试使用我从chatgpt获得的实时跟踪代码时，它显示错误：
  runtimeerror：tracknet加载state_dict中的错误（s）：

down_block_1.conv_1.conv.的尺寸不匹配。
 
也有SEQ LENG的另一个错误
如果不可能，还有其他方法吗？
它可以与设置缓冲区一起加载一些实时框架，然后在持续的周期中对其进行处理？]]></description>
      <guid>https://stackoverflow.com/questions/79543955/tracknet-tracking-a-shuttlecock-in-real-time-with-a-webcam-using-tracknet-and-u</guid>
      <pubDate>Sat, 29 Mar 2025 22:07:02 GMT</pubDate>
    </item>
    <item>
      <title>在图像中检测表情符号[封闭]</title>
      <link>https://stackoverflow.com/questions/79543795/detecting-emojis-in-an-image</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79543795/detecting-emojis-in-an-image</guid>
      <pubDate>Sat, 29 Mar 2025 19:27:22 GMT</pubDate>
    </item>
    <item>
      <title>如何在增强学习中量化估计偏差？ [关闭]</title>
      <link>https://stackoverflow.com/questions/79543440/how-is-estimation-bias-quantified-in-reinforcement-learning</link>
      <description><![CDATA[在各种估计问题中，尤其是在RL域中，我们目前正在研究Q学习及其变体，我们经常遇到术语估计偏差，这是指估计器的预期值与真实参数的系统偏差。&gt; 。
例如，Thrun（1993）[1]提到估计器具有估计偏差，但我正在寻找一种量化它的标准方法。我知道偏见通常被定义为：
 偏见（θ̂）= e [θ̂]  - θ
 
其中 θ̂ 是估计器，θ是true参数。
但是，在实际应用中，当我们只有一个数据样本时，用于量级或量化的标准技术是什么？在机器学习，统计或计量经济学中，是否有特定的数值或计算方法在现实世界中估算它？
我的观点：
我目前正在进行有关量化 Q-学习和双Q学习算法的偏差的研究。强化学习的关键挑战之一是了解估计偏置如何在价值函数更新中传播。引入了双Q学习，以减轻标准Q学习中存在的高估偏差，但准确地测量这种偏见仍然是一个开放的问题。
根据我观察到的，大多数研究通过经验绩效评估而不是通过直接定量来分析偏见。某些技术，例如使用自举置信区间或蒙特卡洛推广，试图通过将学习的价值功能与地面真相回报进行比较来估计偏差。但是，是否有一种更标准化的方法来量化和比较不同学习算法的偏差？
此外，我在最近的神经论文[2]中遇到了 amse的概念（渐近平方误差）。 AMSE由：给出
  amse（θ̂_n）= e [（θ̂_n -θ）²]
 
其中 n 是样本尺寸。但是，本文采用了零引用方法，这意味着该引用设置为零，而不是假设已知的真实值θ，并且对此进行了所有错误测量。这实际上意味着：
  amse（θ̂_n）= e [θ̂_n²]
 
所有偏差估计是相对而不是绝对的。
这种零引用方法如何影响强化学习中估计偏差的解释？ AMSE是否可以成为量化Q学习估计量中偏差的合适度量，还是有其他方法更适合强化学习应用？
 RL中的任何参考文献或示例，尤其是在Q学习和双重学习中，都将不胜感激。 

参考：
 [1] Thrun，S。（1993）。 偏见和学习算法中稳定性的量化。卡内基·梅隆大学。 
 [2] Bartlett，P。L.，Long，P.M.，Lugosi，G。，＆amp; Tsigler，A。（2020）。线性回归中的良性过度拟合。神经。 &lt;a href =“ https://proceedings.neurips.cc/paper_files/paper/2020/file/4bfbd52f4e8466dc12aaf30b7e057b6666-paper.pdf.pdf”]]></description>
      <guid>https://stackoverflow.com/questions/79543440/how-is-estimation-bias-quantified-in-reinforcement-learning</guid>
      <pubDate>Sat, 29 Mar 2025 15:12:34 GMT</pubDate>
    </item>
    <item>
      <title>在Pytorch中使用大于1的批次尺寸时的错误</title>
      <link>https://stackoverflow.com/questions/79519426/error-when-using-batch-size-greater-than-1-in-pytorch</link>
      <description><![CDATA[我正在构建一个神经网络，以预测使用VVC（多功能视频编码）在压缩过程中如何对图像进行分区。该模型从YUV420图像中获取单个Y框架作为输入，并使用包含地面真相块位置和尺寸的CSV文件进行训练。
输入和地面真相

  输入： 1-Frame YUV420 10位图像。

  地面真相：具有块位置，大小和其他分区标志的CSV文件。


示例（388016_320x480_37.yuv）
在此处输入图像描述 
示例（388016_320x480_37.csv）
在这里输入图像说明 
问题描述：
我实现了 train.py 和 dataset.py ，但是当设置 batch_size＆gt; 1 在 dataloader 中。批量大小为1，该模型正常工作，但是增加批处理大小会导致运行时错误。
代码摘要：
以下是我的 custom_collat​​e_fn 和 dataloader 设置的简化版本：
  def custom_collat​​e_fn（批次）：
    帧= [批次中的项目]＃y帧张量
    块= [批次中的项目]＃块信息
    框架= torch.stack（帧，dim = 0）＃沿批处理尺寸堆叠帧
    返回框架，块

dataloader = dataloader（
    数据集，
    batch_size = batch_size， 
    shuffle = true，
    Collat​​e_fn = custom_collat​​e_fn
）
 
观察：

 当 batch_size = 1 时， blocks_batch 在训练环中是包含一组块数据的列表。

 带有 batch_size＆gt; 1 ，它成为列表的列表，在索引时会导致错误。


  i，（frame，blocks_batch）枚举（dataLoader）：
    frame = frame.to（设备）＃形状：[batch_size，1，h，w]
    blocks = blocks_batch [0]＃与batch_size = 1一起使用，但大小较大
 
我的假设：
似乎是由处理 blocks_batch 当 batch_size＆gt; 1 。嵌套列表结构使得很难处理多批次。
问题：

 如何调整 custom_collat​​e_fn 或训练循环以有效处理大于1的批次大小？

 如果有更好的方法可以通过批处理处理可变的块数据，我将感谢任何建议。


  file＆quod＆quot＆quode＆users \ indersration \ documents \ documents \ vvc_fast \ test4 \ test4 \ train.py＆quid＆quort＆quort＆quort＆quort＆quort＆quid＆quot 91 in＆lt; module＆gt;
    loss1 =标准（out_split，target_split）
  file＆quot; c：\ programData \ miniconda3 \ envs \ enkeNv3 \ lib \ lib \ site-packages \ torch \ thnn \ nn \ modules \ module.py;
    返回self._call_impl（*args，** kwargs）
  file＆quot; c：\ programData \ miniconda3 \ envs \ newenv3 \ lib \ lib \ site-packages \ torch \ thnn \ nn \ modules \ module.py;
    返回forward_call（*args，** kwargs）
  file＆quot; c：\ programdata \ miniconda3 \ envs \ newenv3 \ lib \ lib \ site-packages \ torch \ nn \ nn \ loss.py.py＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort＆quort in 725
    返回f.binary_cross_entropy_with_logits（输入，目标，
  file＆quot c：\ programData \ miniconda3 \ envs \ newenv3 \ lib \ lib \ site-packages \ torch \ nn \ functional.py;
    提高ValueError（f＆quot“目标大小（{target.size（）}）必须与输入大小（{input.size（）}）相同
ValueError：目标大小（TORCH.SIZE（[1，1]））必须与输入大小（Torch.Size（[2，1]））相同
 ]]></description>
      <guid>https://stackoverflow.com/questions/79519426/error-when-using-batch-size-greater-than-1-in-pytorch</guid>
      <pubDate>Wed, 19 Mar 2025 07:28:29 GMT</pubDate>
    </item>
    <item>
      <title>特征的长度不等于形状值的长度</title>
      <link>https://stackoverflow.com/questions/79515542/length-of-features-is-not-equal-to-the-length-of-shap-values</link>
      <description><![CDATA[我正在运行一个随机的森林模型，并获得某些特征的重要性，并试图运行形状分析。问题是，每当我尝试绘制塑造值时，我都会遇到此错误：
  dimensionError：功能的长度不等于shap_values的长度。 
 
我不知道发生了什么。当我运行XGBoost模型时，一切似乎都很好，我可以看到数据集的形状图。它的数据集完全相同，但它不会与随机森林一起运行。它用于二进制分类。
这是我的python代码：
 来自sklearn.semble import incort fandyForestClassifier
来自sklearn.model_selection导入train_test_split，cross_val_score
来自sklearn.metrics导入精度，precision_score，recke_score，f1_score，confusion_matrix

＃从功能中删除主键列“ ID”

功能= result.drop（columns = [&#39;pq2&#39;，&#39;id&#39;]）＃删除目标和ID列
target =结果[&#39;pq2&#39;]＃目标变量

＃将数据分为80-20的培训和测试集
x_train，x_test，y_train，y_test = train_test_split（功能，target，test_size = 0.2，andural_state = 42）
 
＃初始化随机森林分类器
rf_model = RandomforestClassifier（N_Estimators = 100，Random_State = 42）

＃将模型适合培训数据
rf_model.fit（x_train，y_train）

＃做出预测
y_pred = rf_model.predict（x_test）

导入塑造

＃为随机森林模型创建树状解释器
解释器= shap.treeexplainer（rf_model）

＃计算测试集的形状值
shap_values = ruminder.shap_values（x_test）

＃绘制形状摘要图
shap.summary_plot（shap_values，x_test，feature_names = features_names）

＃绘制整体特征重要性的塑形栏图

shap.summary_plot（shap_values，x_test，feature_names = features_names，plot_type =; bar＆quot; quot;
 
测试集的形状为（829,22），但是随机森林的外形值始终返回（22,2），我不知道如何修复它。数据集已经进行了预处理，列是0-1S或数值列。]]></description>
      <guid>https://stackoverflow.com/questions/79515542/length-of-features-is-not-equal-to-the-length-of-shap-values</guid>
      <pubDate>Mon, 17 Mar 2025 19:16:45 GMT</pubDate>
    </item>
    <item>
      <title>保存到磁盘中的磁盘[封闭]时会遇到Unicode错误</title>
      <link>https://stackoverflow.com/questions/79436672/getting-unicode-error-while-saving-to-disk-in-distiset</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79436672/getting-unicode-error-while-saving-to-disk-in-distiset</guid>
      <pubDate>Thu, 13 Feb 2025 15:04:10 GMT</pubDate>
    </item>
    <item>
      <title>有关培训物理知情神经网络的问题[关闭]</title>
      <link>https://stackoverflow.com/questions/79415961/issue-regarding-training-physics-informed-neural-network</link>
      <description><![CDATA[我正在通过波传播数据培训物理知情的神经网络。训练输入的形状为（193524369，3）。我目前使用的批量尺寸为2048和Epoch 300。对于培训模型，我总共给了20,000批。因此，基本上，要训练模型，我使用的是20,000批次，每个批次都有2048个数据，几乎是我整个数据集的10％。该代码正在Tesla V100-PCIE-32GB GPU上运行。
训练进度非常慢，训练模型可能需要几个月的时间。但是，NN并不那么沉重，而有那么多节点和层。我该如何使培训进度更快？
我对更快地进行培训过程有些疲惫。使培训批量更大可以使其变得更好一些，但这会导致准确性降低。我应该如何优化以使训练过程更快并保持准确性更好？]]></description>
      <guid>https://stackoverflow.com/questions/79415961/issue-regarding-training-physics-informed-neural-network</guid>
      <pubDate>Wed, 05 Feb 2025 19:21:17 GMT</pubDate>
    </item>
    <item>
      <title>Importerror：无法从“火炬”（未知位置）导入“张量”的名称</title>
      <link>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</link>
      <description><![CDATA[我正在尝试从Pytorch导入 ：
 来自火炬导入张量
 
但我一直遇到此错误：
  Importerror：无法从“火炬”（未知位置）导入名称&#39;tensor&#39;
 
我尝试的是：

检查是否已安装了Pytorch（ pip show torch ），我正在使用版本 2.5.1 。。
重新安装了Pytorch：
  pip卸载火炬
PIP安装火炬
 

测试了python壳中的导入，但错误仍然存​​在。

环境：

 Python版本：3.10 
 Pytorch版本：2.5.1 
 OS：Windows 10 
虚拟环境：是

我该如何解决此问题？]]></description>
      <guid>https://stackoverflow.com/questions/79367182/importerror-cannot-import-name-tensor-from-torch-unknown-location</guid>
      <pubDate>Sat, 18 Jan 2025 13:04:35 GMT</pubDate>
    </item>
    <item>
      <title>我正在创建一个扑朔迷离的应用程序来检测手势并在文本中转换为聋人和愚蠢的人[封闭]</title>
      <link>https://stackoverflow.com/questions/75481225/i-am-creating-a-flutter-app-to-detect-hand-gestures-and-convert-them-in-text-for</link>
      <description><![CDATA[是否有人可以为我提供有关如何启动项目，从我可以获取数据集以及如何将手势转换为文本的路线图？还是有任何SDK或API，如果您能为我提供git链接，那就太好了]]></description>
      <guid>https://stackoverflow.com/questions/75481225/i-am-creating-a-flutter-app-to-detect-hand-gestures-and-convert-them-in-text-for</guid>
      <pubDate>Fri, 17 Feb 2023 07:21:32 GMT</pubDate>
    </item>
    <item>
      <title>如何将稀疏的numpy数组转换为数据框架？</title>
      <link>https://stackoverflow.com/questions/64746124/how-to-convert-sparse-numpy-array-to-dataframe</link>
      <description><![CDATA[下面是代码段，
 来自sklearn.com pos import columntransformer
从sklearn.preprocessing导入onehotencoder
ct = columnTransFormer（变形金刚= [（&#39;encoder&#39;，onehotencoder（），[2,3,4]）]，剩余=&#39;PassThrough&#39;）
x = np.array（ct.fit_transform（x_data））
X.Shape
 
我得到下面的输出
 （）
 
当我尝试打印X时，我会像以下那样获得输出
  array（＆lt; 8820x35类型&#39;＆lt; class&#39;numpy.float64&#39;&#39;＆gt;&#39;&#39;的稀疏矩阵
    在压缩稀疏行格式中存储了41527个元素，dtype = object）
 
现在，当我尝试将此数组转换为DataFrame 时
  x = pd.dataframe（x）
 
我在以下错误以下
  valueerror：必须通过2-D输入
 
如何将我的numpy数组转换为dataframe？]]></description>
      <guid>https://stackoverflow.com/questions/64746124/how-to-convert-sparse-numpy-array-to-dataframe</guid>
      <pubDate>Mon, 09 Nov 2020 05:03:36 GMT</pubDate>
    </item>
    <item>
      <title>如何在Python中从头开始选择逻辑回归的功能？</title>
      <link>https://stackoverflow.com/questions/48403445/how-to-select-features-for-logistic-regression-from-scratch-in-python</link>
      <description><![CDATA[我一直在尝试从头开始编码逻辑回归，但是我正在使用乳腺癌数据集中的所有功能，并且我想选择一些功能（特别是我发现Scikit-Learn在与之进行比较并在数据上使用其功能选择时选择的功能）。但是，我不确定在我的代码中在哪里做，我目前拥有的是：
  x_train = [&#39;texture_mean&#39;，&#39;Smoothness_mean&#39;，&#39;compactness_mean&#39;，&#39;symmetry_mean&#39;，&#39;radius_se&#39;，&#39;symmetry_se&#39;
&#39;fractal_dimension_se&#39;，&#39;radius_worst&#39;，&#39;texture_worst&#39;，&#39;reage_worst&#39;，&#39;smoothness_worst&#39;，&#39;compactness_worst&#39;]
x_test = [&#39;texture_mean&#39;，&#39;Smoothness_mean&#39;，&#39;compactness_mean&#39;，&#39;symmetry_mean&#39;，&#39;radius_se&#39;，&#39;symmetry_se&#39;
&#39;fractal_dimension_se&#39;，&#39;radius_worst&#39;，&#39;texture_worst&#39;，&#39;reage_worst&#39;，&#39;smoothness_worst&#39;，&#39;compactness_worst&#39;]

Def Sigmoid（Z）：
    返回1/（1 + np.exp（-z））

DEF假设（Theta，X）：   
    返回sigmoid（x @ theta）

def cost_function（x，y，theta，m）：
    嗨=假设（theta，x）
    _y = y.Reshape（-1，1）
    j = 1/float（m） * np.sum（-_ y * np.log（hi） - （1-_y） * np.log（1-hi））
    返回j

def cost_function_derivivative（x，y，theta，m，alpha）：
    嗨=假设（theta，x）
    _y = y.Reshape（-1，1）
    j = alpha/float（m） * x.t @（hi -_y）
    返回j

def gradient_descent（x，y，theta，m，alpha）：
    new_theta = theta -cost_function_derivitive（x，y，theta，m，alpha）
    返回new_theta

缺陷准确性（theta）：
    正确= 0
    长度= len（x_test）
    预测=（假设（theta，x_test）＆gt; 0.5） 
    _y = y_test.Reshape（-1，1）
    正确=预测== _y
    my_accuracy =（np.sum（正确） /长度）*100
    打印（&#39;lr精度：&#39;，my_accuracy，“％＆quot”）

def logistic_regression（x，y，alpha，theta，num_iters）：
    m = len（y）
    对于x范围（num_iters）：
        new_theta = gradient_descent（x，y，theta，m，alpha）
        theta = new_theta
        如果x％100 == 0：
            打印＃（&#39;Theta：&#39;，Theta）    
            打印＃（&#39;COST：&#39;，cost_function（x，y，theta，m））
    准确性（theta）
EP = .012 
oniration_theta = np.random.rand（x_train.shape [1]，1） * 2 * EP -EP
alpha = 0.5
迭代= 10000
logistic_regression（x_train，y_train，alpha，initial_theta，迭代）
 
我假设如果我手动更改功能x_train和x_test的功能，其中包含在内，但是我会在 prinity_theta  line上遇到错误：
  attributeError：&#39;列表&#39;对象没有属性&#39;shape&#39; 
 ]]></description>
      <guid>https://stackoverflow.com/questions/48403445/how-to-select-features-for-logistic-regression-from-scratch-in-python</guid>
      <pubDate>Tue, 23 Jan 2018 13:55:31 GMT</pubDate>
    </item>
    <item>
      <title>如何了解损失，acc，val_loss，val_acc在keras模型拟合中？</title>
      <link>https://stackoverflow.com/questions/47299624/how-to-understand-loss-acc-val-loss-val-acc-in-keras-model-fitting</link>
      <description><![CDATA[这是我的KERAS模型结果（在4160个样品上训练，在1040个样本上进行验证）：
 时代1/20
4160/4160-损失：3.3455- ACC：0.1560 -Val_loss：1.6047 -Val_acc：0.4721

时期2/20
4160/4160-损失：1.7639- ACC：0.4274 -Val_loss：0.7060 -Val_acc：0.8019

时期3/20
4160/4160-损失：1.0887- ACC：0.5978 -Val_loss：0.3707 -Val_acc：0.9087

时期4/20
4160/4160-损失：0.7736- ACC：0.7067 -Val_loss：0.2619 -Val_acc：0.9442

时期5/20
4160/4160-损失：0.5784- ACC：0.7690 -Val_loss：0.2058 -Val_acc：0.9433

时期6/20
4160/4160-损失：0.5000- ACC：0.8065 -Val_loss：0.1557 -Val_acc：0.9750

时期7/20
4160/4160-损失：0.4179- ACC：0.8296 -Val_loss：0.1523 -Val_acc：0.9606

时期8/20
4160/4160-损失：0.3758- ACC：0.8495 -Val_loss：0.1063 -Val_acc：0.9712

时期9/20
4160/4160-损失：0.3202- ACC：0.8740 -Val_loss：0.1019 -Val_acc：0.9798

时期10/20
4160/4160-损失：0.3028- ACC：0.8788 -Val_loss：0.1074 -Val_acc：0.9644

时期11/20
4160/4160-损失：0.2696- ACC：0.8923 -Val_loss：0.0581 -Val_acc：0.9856

时期12/20
4160/4160-损失：0.2738- ACC：0.8894 -Val_loss：0.0713 -Val_acc：0.9837

时代13/20
4160/4160-损失：0.2609- ACC：0.8913 -Val_loss：0.0679 -Val_acc：0.9740

时期14/20
4160/4160-损失：0.2556- ACC：0.9022 -Val_loss：0.0599 -Val_acc：0.9769

时期15/20
4160/4160-损失：0.2384- ACC：0.9053 -Val_loss：0.0560 -Val_acc：0.9846

时代16/20
4160/4160-损失：0.2305- ACC：0.9079 -Val_loss：0.0502 -Val_acc：0.9865

时期17/20
4160/4160-损失：0.2145- ACC：0.9185 -Val_loss：0.0461 -Val_acc：0.9913

时期18/20
4160/4160-损失：0.2046- ACC：0.9183 -Val_loss：0.0524 -Val_acc：0.9750

时期19/20
4160/4160-损失：0.2055- ACC：0.9120 -Val_loss：0.0440 -Val_acc：0.9885

时代20/20
4160/4160-损失：0.1890- ACC：0.9236 -Val_loss：0.0501 -Val_acc：0.9827
 
这是我的理解：

 两个损失（损失和val_loss）正在减少，拖曳ACC（ACC和Val_ACC）正在增加。因此，这表明建模是很好的。

  val_acc是模型预测的良好程度。因此，就我的情况而言，看起来模型在6个时代后接受了很好的训练，而其余的培训是不需要的。 


我的问题是：

  ACC（在训练集上）总是比Val_ACC更小，实际上要小得多。这是正常的吗？为什么会发生这种情况？在我看来，ACC通常应该比Val_acc更好。

  20个时期后，ACC仍在增加。那么，当ACC停止增加时，我应该使用更多的时期并停止吗？或者，无论ACC的趋势如何，我都应该停在Val_ACC停止增加的地方

 对我的结果还有其他想法吗？

]]></description>
      <guid>https://stackoverflow.com/questions/47299624/how-to-understand-loss-acc-val-loss-val-acc-in-keras-model-fitting</guid>
      <pubDate>Wed, 15 Nov 2017 04:56:05 GMT</pubDate>
    </item>
    <item>
      <title>训练后如何用分布的时间来替换嵌入层？</title>
      <link>https://stackoverflow.com/questions/39532572/how-to-replace-an-embedding-layer-with-a-time-distributed-dense-after-training</link>
      <description><![CDATA[我有以下问题：

 我想使用LSTM网络进行文本分类。为了加快训练的速度并使代码更加清楚，我想沿沿 keras.tokenizer 嵌入层以训练我的模型。 
 一旦我训练了我的模型 - 我想计算输出W.R.T.的显着性图。输入。为此，我决定将嵌入层替换为 timeDistributedDense 。 

您知道什么是最好的方法。对于一个简单的模型，我可以简单地使用已知权重的模型来重建模型 - 但我想使其尽可能通用 - 例如替换模型结构的未来并使我的框架尽可能不可知。]]></description>
      <guid>https://stackoverflow.com/questions/39532572/how-to-replace-an-embedding-layer-with-a-time-distributed-dense-after-training</guid>
      <pubDate>Fri, 16 Sep 2016 13:21:25 GMT</pubDate>
    </item>
    <item>
      <title>如何实现“相关”度量算法？ [关闭]</title>
      <link>https://stackoverflow.com/questions/42489/how-to-implement-a-related-degree-measure-algorithm</link>
      <description><![CDATA[今天早些时候，当我在Stackoverflow中出现令人惊讶的功能时，我将要问一个问题。当我写我的问题标题时，Stackoverflow向我提出了几个相关问题，我发现已经有两个类似的问题。那真是太棒了！ 
然后，我开始思考如何实现此类功能。我将如何通过相关性订购问题：

有更高数量的问题
单词与新问题匹配
如果比赛数为
同样，言语的顺序被认为
标题中出现的单词
更高的相关性

这将是一个简单的工作流程或复杂的分数算法？
有些人可以增加召回，也许？
是否有某些库该功能？
您还要考虑其他哪些方面？
也许杰夫可以回答自己！您是如何在Stackoverflow中实现的？ ：）]]></description>
      <guid>https://stackoverflow.com/questions/42489/how-to-implement-a-related-degree-measure-algorithm</guid>
      <pubDate>Wed, 03 Sep 2008 20:21:04 GMT</pubDate>
    </item>
    </channel>
</rss>