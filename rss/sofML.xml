<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>主动问题标记的机器学习 - 堆栈溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>最近的30个来自stackoverflow.com</description>
    <lastBuildDate>Tue, 11 Mar 2025 12:35:19 GMT</lastBuildDate>
    <item>
      <title>如何使用Python SDK将环境变量传递到亚马逊萨吉式制造商的自定义培训脚本？</title>
      <link>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</link>
      <description><![CDATA[我正在使用Amazon Sagemaker中的脚本进行自定义模型，并使用Python SDK启动这项工作。我想将一些环境变量（例如API键或配置标志）传递到培训作业，以便通过OS.Environ在脚本中访问它们。
这是我的代码的简化版本：
 来自sagemaker.stimator导入估算器

估算器=估算器（
    image_uri =&#39;123456789012.dkr.ecr.us-west-2.amazonaws.com/my-custom-image：最新图像&#39;，
    角色=角色，
    instance_count = 1，
    instance_type =&#39;ml.g5.xlarge&#39;，
    entry_point =&#39;train.py&#39;，
    source_dir =&#39;src&#39;，
    环境= {
        &#39;my_api_key&#39;：&#39;abcdef123456&#39;，
        &#39;debug_mode&#39;：&#39;true&#39;
    }
）
 
在我的培训脚本中，我尝试读取变量：
 导入OS

api_key = os.environ.get（&#39;my_api_key&#39;）
打印（＆quot; api键：＆quot; api_key）
 
这是使用Python SDK将环境变量传递给萨吉人培训工作的正确方法吗？我应该注意任何局限性或最佳实践，特别是对于诸如API键之类的敏感信息？]]></description>
      <guid>https://stackoverflow.com/questions/79500324/how-can-i-pass-environment-variables-to-a-custom-training-script-in-amazon-sagem</guid>
      <pubDate>Tue, 11 Mar 2025 10:00:30 GMT</pubDate>
    </item>
    <item>
      <title>当我试图运行命令spartlit运行main.py时，为什么我会得到RuntimeError：没有运行事件循环，并且在我的VS代码中？</title>
      <link>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79500227/why-am-i-getting-runtimeerror-no-running-event-loop-and-in-my-vs-code-when-i-am</guid>
      <pubDate>Tue, 11 Mar 2025 09:34:06 GMT</pubDate>
    </item>
    <item>
      <title>如何删除具有不同文件名和大小但在Android中相同的内容的重复图像？</title>
      <link>https://stackoverflow.com/questions/79499987/how-to-delete-duplicate-images-with-different-file-names-and-sizes-but-identical</link>
      <description><![CDATA[我在我的Android设备上有大量从iPhone传输的图像。不幸的是，我现在有许多重复的图像：
没有相同的文件名。
没有相同的文件大小或分辨率。
但是包含相同的视觉内容（相同的图像）。
我想根据它们的内容查找并删除这些重复的图像（不是基于文件名，大小或分辨率）。
我尝试通过Google App搜索文件中的内置选项，但找不到根据内容检测重复图像的任何选项。
我要寻找的是：是否有任何可以根据内容扫描和删除重复图像的Android应用程序或工具？另外，我可以使用任何Python脚本或开源工具来实现这一目标吗？我的目标是自动删除所有具有相同内容的重复图像，无论其文件名，大小或分辨率如何。
任何建议或解决方案都将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/79499987/how-to-delete-duplicate-images-with-different-file-names-and-sizes-but-identical</guid>
      <pubDate>Tue, 11 Mar 2025 07:53:05 GMT</pubDate>
    </item>
    <item>
      <title>如何实现具有有限数据和较大姿势/样式变化的强大动漫角色搜索系统？</title>
      <link>https://stackoverflow.com/questions/79499907/how-to-implement-a-robust-anime-character-search-system-with-limited-data-and-la</link>
      <description><![CDATA[我目前正在努力实施“动漫角色搜索”系统，我非常感谢您可能拥有的任何建议或参考。
使用经典的计算机视觉技术检测动漫图像是相对简单的。例如，一个众所周知的示例是Trace.Moe，它使用Lucene Image Search（LIRE）和其他传统方法准确地指出了给定屏幕截图的动漫剧集和时间戳。这种方法不一定依靠现代深度学习。它仅根据旧视觉算法使用特征提取。
然而，随着AI的兴起，许多人开始使用CNN，VIT或其他深度学习模型（通常来自拥抱面）进行图像特征提取和基于向量的搜索。在我自己的设置中，如果目标动漫角色图像已经索引，我可以达到100％的准确性（即使没有高级矢量数据库（例如基于HNSW的解决方案）），因为系统很容易检索相同或近乎功能的匹配。  
核心问题是，动漫角色的嵌入可能对姿势或样式的轻微变化也极为敏感。如果角色仅移动位置，则嵌入空间中的距离可能会飙升。我尝试通过对比度学习解决这个问题（特别是2022年左右的对比度方法），但到目前为止，结果一直不足。 
一个很大的挑战是数据集本身的性质：有很多字符标签，但每个字符相对较少，样式差异很大。有时，给定角色只有一个参考图像。当只有一两个图像开始时，典型的增强方法无济于事。我考虑使用ControlNet或类似技术生成更多图像来模拟不同的姿势和观点，但是由于参考图像，GAN或扩散模型很少，因此难以产生高质量的一致变化。
我还研究了诸如佛罗伦萨，dinov2和剪辑之类的自动接地方法，以解析或分割图像，然后尝试统一共享功能，但我不确定实践中的效果如何。总的来说，我感到卡住了。该域与标准图像搜索有所不同，因为数据有限，变化很大，即使在完全不同的姿势或艺术风格下，系统也需要识别相同的字符。
即使刮擦Kaggle和其他来源也只能产生几十万张图像，这远远不够覆盖那里的各种动漫角色。数据收集本身是一个巨大的挑战。
你们中有人处理类似问题吗？您是否知道建立强大的动漫角色搜索系统的最佳实践或相关参考，尤其是在此类数据筛选条件下？任何指示或建议将不胜感激。预先感谢您的帮助！]]></description>
      <guid>https://stackoverflow.com/questions/79499907/how-to-implement-a-robust-anime-character-search-system-with-limited-data-and-la</guid>
      <pubDate>Tue, 11 Mar 2025 07:11:13 GMT</pubDate>
    </item>
    <item>
      <title>与拆分数量少的类交叉验证的错误</title>
      <link>https://stackoverflow.com/questions/79499678/error-on-crossvalidation-with-classes-that-have-less-samples-than-number-of-spli</link>
      <description><![CDATA[我目前正在研究这个问题：
 https://github.com/scikit-com/scikit-learn/scikit-learn/scikit-learn/scikit-learn/scikit-learn/issues/30832  
我正在研究修复它的可能方法。
说明：
使用logistic回归和交叉验证时，在交叉验证时，样本少于拆分数量的类别少于每倍的样本，导致执行Python程序时出现错误。
即使这可能是一个数据问题，也应该有更好的方法来处理它。
复制错误的代码：
来自sklearn.linear_model导入logisticRegressioncv
导入numpy作为NP
n，m = 20，5
x = np.random.randn（n，m）
y = np.random.randint（0，2，n）
y [-3：] = [3，4，5]
logisticRegressioncv（）。fit（x，y）
我想到的一些方法：

将系数设置为代表性不足的类中的0; 
根据我们拥有的真实数据自动创建新数据（即使仅是1个示例）; 
重复数据，直到最低样本的类达到分裂次数； 
简单地提出一个更有意义的例外。

这只是一个数据问题，我应该提出一个例外，还是我可以在这里做更多的事情？
您能给我一些有关解决此问题的好方法的提示或想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79499678/error-on-crossvalidation-with-classes-that-have-less-samples-than-number-of-spli</guid>
      <pubDate>Tue, 11 Mar 2025 04:44:50 GMT</pubDate>
    </item>
    <item>
      <title>我可以将Pytorch与Django Web框架集成在一起吗？</title>
      <link>https://stackoverflow.com/questions/79499340/can-i-integrate-pytorch-with-django-web-framework</link>
      <description><![CDATA[您好，我希望使用Django在网站上创建一些游戏。我想对游戏进行一些机器学习，以便玩家可以与机器学习模型进行比赛。 Django和Pytorch的结合是否可以？我听说了一些称为ONNX的东西，可以帮助将模型提供到前端，我只是想仔细检查与Django一起使用的，而不仅仅是与Nodejs一起使用。如果它不起作用，那么我会感谢任何其他解决方案。
感谢您的任何见解]]></description>
      <guid>https://stackoverflow.com/questions/79499340/can-i-integrate-pytorch-with-django-web-framework</guid>
      <pubDate>Mon, 10 Mar 2025 23:06:51 GMT</pubDate>
    </item>
    <item>
      <title>生成partialdependedateata函数在用于多类分类模型时返回错误</title>
      <link>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</link>
      <description><![CDATA[我已经使用MLR构建了XGBoost多类分类模型，我想为某些功能可视化部分依赖性。但是，如果我尝试使用 generatePartialDependedAta（）我会收到以下错误：

 Melt.data.table中的错误（AS.Data.table（OUT），MEATH.VARS = target，variable.name = if（td $ type ===：&#39;METAY.VARS&#39;中的一个或多个值无效。

我已经检查了 task.desc 在 task&gt; task 对象和 factor.levels.levels.levels 中的差异。此外，我毫不费力地使用相同的函数生成具有不同目标变量的回归XGBoost的数据。
我的目的是有问题，还是这是一个错误？
这是使用 palmerpenguins 数据集的示例：
 ＃库
图书馆（整洁）
图书馆（MLR）

Peng＆lt;  -  Palmerpenguins ::企鹅

＃数据分区
set.seed（1234）
Intrain＆lt ;-创建Atapartition（
  y =彭$种，
  p = 0.7，
  列表= f
）

＃构建任务
train_class＆lt;  -  peng [intrain，]％＆gt;％select（-sex，-year）％＆gt;％ 
  CreateMummyFeatures（target =;物种＆quots; cols =;岛; 
  makeClassIftask（data =。，target =;物种；）

＃建立学习者
xgb_class_learner＆lt;  -  makelearner（
  ＆quot“ classif.xgboost”
  predict.type =&#39;响应;
）

＃构建模型
XGB_CLASS＆lt;  - 火车（XGB_CLASS_LEARNER，TRAIN_CLASS）

＃产生部分依赖性
GeneratePartialDependedateData（XGB_Class，Train_class）
 ]]></description>
      <guid>https://stackoverflow.com/questions/79498849/generatepartialdependencedata-function-returns-error-when-used-for-multiclass-cl</guid>
      <pubDate>Mon, 10 Mar 2025 18:27:01 GMT</pubDate>
    </item>
    <item>
      <title>如何训练网络以检测激光云点对象</title>
      <link>https://stackoverflow.com/questions/79498544/how-to-train-a-network-to-detect-lidar-pointcloud-objects</link>
      <description><![CDATA[我目前正在使用OS1 LIDAR传感器，因此我可以访问PointCloud数据集。但是事实是，我需要能够识别对象（项目的目标）。
我知道如何预处理数据，如何注释数据，并且我一直在阅读有关Pointpillars和深入学习以学习如何训练网络的信息，但是没有存储库来解释如何在自定义数据上进行操作。
有人对如何培训网络以获取定制数据或您有来源有任何想法吗？他们中的大多数与汽车或行人有关，但我想确定自己的物体。
我真的很感激，因为这项任务很艰难，我不是专家。
谢谢！
我一直在使用MATLAB可视化和注释我感兴趣的对象，但是我无法继续下一步，因为我不了解它们。
https://www.mathworks.com/help/lidar/ug/object-detection-with-point-clouds.html]]></description>
      <guid>https://stackoverflow.com/questions/79498544/how-to-train-a-network-to-detect-lidar-pointcloud-objects</guid>
      <pubDate>Mon, 10 Mar 2025 16:00:24 GMT</pubDate>
    </item>
    <item>
      <title>损失的计算梯度W.R.T学习率Pytorch</title>
      <link>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79498420/computing-gradient-of-loss-w-r-t-learning-rate-pytorch</guid>
      <pubDate>Mon, 10 Mar 2025 15:11:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么投票表决为“努力”的投票表现有所不同？</title>
      <link>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</link>
      <description><![CDATA[我想从Sklearn和不同参数进行比较性能测试投票classifier。我使用了param网格，然后发现一些难以理解的东西。
我准备了三个分类器
  gnb = gaussiannb（）＃准确性0.795
lr = logisticRegress（）＃准确性0.7925
RFC = RandomforestClassifier（）＃准确性0.94

 
然后我做了两个VaitingClassifiers。两者都有有效的设置为“硬”。但是重量不同。该决定是由多数投票做出的，但其准确性是不同的，这是如何可能的？
  vc_hard_equals = fotingClassifier（estionators = [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （&#39;Randomforest＆quot＆quot; rfc）
    ]，， 
    投票=“硬＆quot” 
    权重=（1，1，1），＃等于权重
    ）
vc_hard_forest_priority = fotingClassifier（估算= [[
        （&#39;naivebayes＆quot; gnb）， 
        （“ LogisticRegression＆quot”，lr）， 
        （“ rancomforest”，rfc），]， 
    投票=“硬＆quot” 
    权重=（1，1，3），＃更大的随机孔（在这种情况下最好的型号）
    ）

vc_hard_equals.fit（x_train，y_train）
vc_hard_forest_priority.fit（x_train，y_train）

print（vc_hard_equals.score（x_test，y_test））＃0.832
print（vc_hard_forest_priority.score（x_test，y_test））＃0.915
 ]]></description>
      <guid>https://stackoverflow.com/questions/79474361/why-votingclassifer-performance-with-voting-set-to-hard-is-different-with-diff</guid>
      <pubDate>Fri, 28 Feb 2025 02:14:28 GMT</pubDate>
    </item>
    <item>
      <title>在Palantir Foundry模型培训参数（平均，SD）中评估过程是否从“火车数据”到“测试数据”？</title>
      <link>https://stackoverflow.com/questions/79469004/do-evaluate-process-in-palantir-foundry-model-training-parameters-mean-sd-fro</link>
      <description><![CDATA[如果我正确理解了该过程，则在机器学习中缩放测试数据时，应使用从培训数据中学到的缩放参数（如平均值和标准偏差）来转换测试数据，而不是测试数据本身。。
所以正确的步骤是：

将数据分开：将数据集分为培训和测试集。
缩放训练数据：计算和应用缩放参数（例如平均值，标准偏差）到训练数据。
将相同的参数应用于测试数据

要实现上述步骤，我使用：

  fit_transform 缩放“培训数据”，
 转换携带“培训数据”参数以“测试数据” 

但是，当我评估“测试数据”时，我如何在Palantir铸造模型中实现这一目标，我看不到评估配置的选项。有谁知道Palantir是否在评估配置中构建功能？携带参数过程会自动发生吗？如果没有，我该怎么做才能实现？
  fit_transform 然后变换在Palantir Foundry模型培训中等效]]></description>
      <guid>https://stackoverflow.com/questions/79469004/do-evaluate-process-in-palantir-foundry-model-training-parameters-mean-sd-fro</guid>
      <pubDate>Wed, 26 Feb 2025 08:32:02 GMT</pubDate>
    </item>
    <item>
      <title>增加自我注意力后，CNN网络的非确定性行为</title>
      <link>https://stackoverflow.com/questions/79439790/non-deterministic-behavior-of-a-cnn-network-after-adding-self-attention</link>
      <description><![CDATA[当我添加nlbloclos时，在我的网络（简单CNN）中添加了一个自发层时，网络的结果不再可重现，当我再次训练它时，结果是不同的。但是，当我删除网络中的nlblocks时，它是确定性的。
这是代码：
  os.environ [＆quot&#39;cuda_visible_devices;
os.environ [&#39;tf_cpp_min_log_level&#39;] =&#39;3&#39;
种子= 42
os.environ [&#39;tf_deterministic_ops&#39;] =&#39;1&#39;
tf.config.experiment.enable_op_determinism（）

os.environ [&#39;pythonhashseed&#39;] = str（seed）
os.environ [&#39;tf_cudnn_deterministic&#39;] =&#39;1&#39; 

随机种子（种子）
np.random.seed（种子）
tf.random.set_seed（种子）

tf.keras.backend.set_floatx（&#39;float64&#39;）



nlblock类（层）：
    def __init __（self，num_channels，** kwargs）：
        super（nlblock，self）.__ init __（** kwargs）
        self.num_channels = num_channels
        self.theta = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =＆quort; same＆quot;）
        self.phi = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =＆quort; same＆quot;）
        self.g = conv1d（filters = num_channels，kernel_size = 1，步幅= 1，padding =; same＆quort;）
        self.attention_layer =注意（）＃keras注意层

    def呼叫（self，输入）：
        ＃变换功能图
        query = self.theta（输入）＃query（q）
        key = self.phi（输入）＃key（k）
        value = self.g（输入）＃value（v）

        ＃应用注意力层
        activation_output = self.attention_layer（[查询，键，值]）

        ＃残差连接
        返回输入 +注意_Output
        
＃定义NL注意的模型
def build_model（）：
    优化器= ADAM（Learning_rate = 0.002，beta_1 = 0.89，beta_2 = 0.995）

    输入= tf.keras.input（shape =（num_time_steps，1））＃输入层
    
    ＃Conv Block 1
    x = conv1d（filters = 64，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（输入）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 64）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）

    ＃Conv 2 2
    x = conv1d（filters = 32，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（x）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 32）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）
    x =辍学（0.1）（x）

    ＃Conv Block 3
    x = conv1d（filters = 16，kernel_size = 3，activation =&#39;relu&#39;，padding =&#39;same&#39;）（x）
    x = batchnormatorization（）（x）
    x = nlblock（num__channels = 16）（x）＃nl注意
    x = maxpooling1d（pool_size = 2）（x）
    x =辍学（0.35）（x）

    ＃完全连接的图层
    x = flatten（）（x）
    x =密集（40，激活=&#39;relu&#39;）（x）
    x =辍学（0.35）（x）
    输出=致密（20）（x）＃回归的输出层
    
    ＃编译模型
    型号= tf.keras.model（输入，输出）
    model.compile（优化器=优化器，lose = root_mean_squared_error，metrics = [&#39;mean_absolute_error&#39;]）
    
    返回模型

model = build_model（）

redy_lr = reducelronplateau（monitor =&#39;val_loss&#39;，因子= 0.6，耐心= 25，min_lr = 1e-6）
早期_Stopping =早期踩踏（Monitor =&#39;Val_loss&#39;，Patience = 30，Restore_best_weights = true）
＃步骤5：训练模型
历史= model.fit（x_train_scaled，y_train，validation_data =（x_val_scaled，y_val），
                epochs = 180，batch_size = 90，callbacks = [redion_lr，ropand_stopping]，冗长= 0）

test_loss，test_mae = model.evaluate（x_test_scaled，y_test，batch_size = len（x_test_scaled），词= 0）
 
我还使用tf.matmul（）和softmax使用自定义注意块，但没有任何改变。]]></description>
      <guid>https://stackoverflow.com/questions/79439790/non-deterministic-behavior-of-a-cnn-network-after-adding-self-attention</guid>
      <pubDate>Fri, 14 Feb 2025 15:08:45 GMT</pubDate>
    </item>
    <item>
      <title>为什么拥抱面提供的DeepSeek代码会导致“未知量化类型”错误？</title>
      <link>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</link>
      <description><![CDATA[我正在使用huggingface的此代码：
此代码直接从 deepseek上的huggingface网站页面上的页面

 来自变形金刚导入管道

消息= [
{&#39;&#39;：＆quot“ user quot”内容“：;
这是给出的
pipe =管道（＆quot&#39;text-generation＆quot; deepseek-ai/deepseek-r1＆quort; trust_remote_code = true）
管道（消息）
 

，但我无法加载模型。当我这样做时，我会得到这个问题：
  file＆quot＆lt; ...＆gt;/site-packages/transformers/quantizers/auto.py＆quot;，第97行，在from_dict

提高价值Error（

ValueError：未知量化类型，获得FP8-支持类型为： 
[&#39;awq&#39;，&#39;bitsandbytes_4bit&#39;，&#39;bitsandbytes_8bit&#39;，&#39;gptq&#39;，&#39;aqlm&#39;，&#39;quanto&#39;，&#39;eetq&#39;，&#39;eetq&#39;， 
&#39;HQQ&#39;，“压缩张量”，“ fbgemm_fp8&#39;，&#39;torchao&#39;，&#39;bitnet&#39;]
 
我尝试了不同的代码：
 导入火炬
generate_text = pipeline（model =; deepSeek-ai/deepSeek-r1; torch_dtype = torch.bfloat16，trust_remote_code = true，device_map =; auto;
generate_text（消息）
 
这给出以下错误：

raise ValueError( ValueError: Unknown quantization type, got fp8 - supported types are: [&#39;awq&#39;, &#39;bitsandbytes_4bit&#39;, &#39;bitsandbytes_8bit&#39;, &#39;gptq&#39;, &#39;aqlm&#39;, &#39;quanto&#39;, &#39;eetq&#39;, &#39;higgs&#39;, &#39;hqq&#39;, &#39;compressed-tensors&#39;, &#39;fbgemm_fp8&#39;, &#39;torchao&#39;，&#39;bitnet&#39;，&#39;vptq&#39;] 

我该怎么办？]]></description>
      <guid>https://stackoverflow.com/questions/79424312/why-does-huggingface-provided-deepseek-code-result-in-an-unknown-quantization-t</guid>
      <pubDate>Sun, 09 Feb 2025 03:05:30 GMT</pubDate>
    </item>
    <item>
      <title>无法使用NLTK功能</title>
      <link>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78862426/unable-to-use-nltk-functions</guid>
      <pubDate>Mon, 12 Aug 2024 15:17:29 GMT</pubDate>
    </item>
    <item>
      <title>在线差异更新批处理数据 /颜色频道的有效算法更新</title>
      <link>https://stackoverflow.com/questions/75545944/efficient-algorithm-for-online-variance-update-over-batched-data-color-channel</link>
      <description><![CDATA[我有大量的多维数据（图像），并希望计算所有轴（颜色通道）的方差。内存明智，我无法创建一个大数组来计算一个步骤的方差。因此，我需要分批加载数据并以在线方式以某种方式更新当前差异。
 玩具示例 
最后，批处理明智的更新在线应匹配 recript_var 。
但是，我很难为此找到有效的算法。
 导入numpy作为np
np.random.seed（0）
＃正确计算方差
all_data = np.random.randint（0，9，（9，3））＃＆lt;  - 不适合记忆
recripe_var = all_data.var（axis = 0）
＃创建批次
batches = all_data.Reshape（-1，3，3）

在线_var = 0
批处理批量：
   batch_var = batch.var（轴= 0）
   在线_var =？  ＃如何正确更新此
surstert np.allclose（recript_var，online_var）
 

我找到了

如何以有效考虑整个批次的有效方式更新多个新观察的方差？]]></description>
      <guid>https://stackoverflow.com/questions/75545944/efficient-algorithm-for-online-variance-update-over-batched-data-color-channel</guid>
      <pubDate>Thu, 23 Feb 2023 14:10:26 GMT</pubDate>
    </item>
    </channel>
</rss>