<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 26 Aug 2024 12:30:11 GMT</lastBuildDate>
    <item>
      <title>模型训练时的输入形状问题</title>
      <link>https://stackoverflow.com/questions/78914400/input-shape-problem-during-model-training</link>
      <description><![CDATA[大家好，我的代码中出现了这个问题，你能帮我吗？
ValueError: 输入 0 层“ functional”与层不兼容：预期形状=（None，4096），发现形状=（None，64，4096）
代码：
def generator_output_signature():
return (
(
tf.TensorSpec(shape=[batch_size, 4096], dtype=tf.float32), # X1 具有很多维度
tf.TensorSpec(shape=[batch_size, max_length], dtype=tf.int32) # X2 具有很多维度
),
tf.TensorSpec(shape=[batch_size, vocab_size], dtype=tf.float32) # y 具有很多维度
)
train_dataset = tf.data.Dataset.from_generator(
lambda: data_generator(train_ids, mining, features, tokenizer, max_length, vocab_size, batch_size),
output_signature=generator_output_signature()
)
train_dataset = train_dataset.batch(batch_size).p​​refetch(tf.data.AUTOTUNE)
image_input = 输入(shape=(4096,))
caption_input = 输入(shape=(max_length,))
x = Embedding(vocab_size, 256)(caption_input) # 输出形状：(None, max_length, 256)
x = LSTM(256)(x) # 输出形状：(None, 256)
image_features = Dense(256,activation=&#39;relu&#39;)(image_input) # 输出形状：(None, 256)
x = Add()([x, image_features])
x = Dense(vocab_size,activation=&#39;softmax&#39;)(x) # 输出形状：(None,vocab_size)
model = Model(inputs=[image_input,caption_input],outputs=x)
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;)
print(model.summary())
我试图删除额外的维度，但这是不可能的，所以我无法训练我的模型。]]></description>
      <guid>https://stackoverflow.com/questions/78914400/input-shape-problem-during-model-training</guid>
      <pubDate>Mon, 26 Aug 2024 12:28:50 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Stable Baselines3 中改变 TD3 模型的输出激活函数？</title>
      <link>https://stackoverflow.com/questions/78914358/how-to-change-the-output-activation-function-of-the-td3-model-in-stable-baseline</link>
      <description><![CDATA[我正在使用 Stable Baselines3 库进行强化学习，并想修改 TD3 模型。具体来说，我想更改 TD3 模型输出层中使用的激活函数。
我该如何实现？
我尝试修改 Stable Baselines3 库中 TD3 模型的输出激活函数。具体来说，我想用不同的激活函数替换默认的 tanh 激活函数。]]></description>
      <guid>https://stackoverflow.com/questions/78914358/how-to-change-the-output-activation-function-of-the-td3-model-in-stable-baseline</guid>
      <pubDate>Mon, 26 Aug 2024 12:16:40 GMT</pubDate>
    </item>
    <item>
      <title>每个时期后根据补丁重建图像</title>
      <link>https://stackoverflow.com/questions/78914175/reconstruct-images-from-patches-after-every-epoch</link>
      <description><![CDATA[我打算在每个 epoch 之后从补丁中重建图像。
batch_size = 20
epochs = 15

for epoch in range(epochs):

label_as_fake = np.zeros((batch_size, 1)) 
label_as_real = np.ones((batch_size,1)) 

for ii in tqdm(range(len(train_hr_batches))):
lr_imgs = train_lr_batches[ii] 
hr_imgs = train_hr_batches[ii] 

generated_images = generator.predict_on_batch(lr_imgs)

调用重建函数保存图像
if (epoch+1) % 1 ==0:
reconstructed_sr = reconstruct_patches(generated_images, image_height, image_width, patch_height, patch_width) 
save_images(reconstructed_sr, f&#39;reconstructed_sr_epoch_{epoch+1}.TIF&#39;)


当我有 100 个补丁时，此代码仅迭代一次并尝试从 20 个补丁重建图像。在尝试重建图像之前，我该如何修改它以对 100 个补丁进行完整运行？
Cell In[39]，第 7 行
reconstructed_sr = reconstruct_patches(generated_images, image_height, image_width, patch_height, patch_width)

Cell In[37]，reconstruct_patches 中的第 12 行
raise ValueError(f&quot;expected {expected_num_patches} patches but found {actual_num_patches} patches&quot;)

ValueError: expected 100 patches but found 20 patches

代码仅在定义的 batch_size 结束后尝试重建图像]]></description>
      <guid>https://stackoverflow.com/questions/78914175/reconstruct-images-from-patches-after-every-epoch</guid>
      <pubDate>Mon, 26 Aug 2024 11:36:54 GMT</pubDate>
    </item>
    <item>
      <title>由于尺寸不相等，处理化学分子原子时出现批处理错误</title>
      <link>https://stackoverflow.com/questions/78913966/batching-error-when-processing-chemical-molecule-atoms-because-sizes-not-equal</link>
      <description><![CDATA[我目前正在设计一个可以根据节点特征、边缘特征预测属性的神经网络。但是，当我尝试将批处理大小设置为大于 1 时，事情就出错了。分子中的原子数不同，因此在将多个分子批处理在一起时会导致错误。更具体地说，将出现错误：
RuntimeError：堆栈期望每个张量大小相等，但在条目 0 处得到 [6, 25]，在条目 1 处得到 [8, 25]
。6 和 8 表示该分子中有 6/8 个原子，25 表示每个原子有 25 个特征。有没有比根据另一个类似问题添加零来调整大小更好的解决方案，因为分子的大小可能高达 30 或更大。]]></description>
      <guid>https://stackoverflow.com/questions/78913966/batching-error-when-processing-chemical-molecule-atoms-because-sizes-not-equal</guid>
      <pubDate>Mon, 26 Aug 2024 10:39:01 GMT</pubDate>
    </item>
    <item>
      <title>GIT 分支策略 [关闭]</title>
      <link>https://stackoverflow.com/questions/78913825/git-branching-strategies</link>
      <description><![CDATA[我需要分析所有存储库的提交历史并确定分支策略。我们如何确定它们是否遵循特定的分支策略
以下是我尝试过的方法，但它仅涵盖基于主干的开发。通过查看生成工件的分支，尝试将其标记为 TBD。我可以访问 github api 以及工件、存储库、组织的映射
我需要一个万无一失的算法来确定给定存储库上遵循了哪些分支实践。]]></description>
      <guid>https://stackoverflow.com/questions/78913825/git-branching-strategies</guid>
      <pubDate>Mon, 26 Aug 2024 10:04:22 GMT</pubDate>
    </item>
    <item>
      <title>使用 TensorRT 10.3 进行转换和推理</title>
      <link>https://stackoverflow.com/questions/78913648/conversion-and-inference-with-tensorrt-10-3</link>
      <description><![CDATA[我正在尝试使用 .onnx 模型并使用 TensorRT 加快其推理速度。我已经安装了所有东西，并且我非常有信心一切都正确完成，并且没有版本冲突或类似问题。
我对大量关于如何使用 TensorRT 实现推理的文章和指南感到困惑，我似乎无法让其中任何一个发挥作用！我使用 TensorRT 10.3，据我所知，与以前的版本相比，它有很多变化和重构。
此外，我看到了同一事物的不同版本，我不知道该遵循哪一个……NVIDIA 的文档没有我希望的那么有用，而且我手头有一个特殊案例，因为我尝试转换的模型有多个输入（更具体地说，两个输入，比如形状为 (none, H, W, C) 的“input_0”和形状为 (none, H, W, C) 的“input_1”）。
有人可以提供一些帮助，或者提供关于如何转换模型并将其用于推理的最新指南吗？如果能提供关于这种多输入情况的任何其他说明，我将不胜感激，我已经画了好几天的圆圈了。]]></description>
      <guid>https://stackoverflow.com/questions/78913648/conversion-and-inference-with-tensorrt-10-3</guid>
      <pubDate>Mon, 26 Aug 2024 09:15:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 CLIP Vision Encoder 创建自定义对象检测模型</title>
      <link>https://stackoverflow.com/questions/78913273/create-a-custom-object-detection-model-with-clip-vision-encoder</link>
      <description><![CDATA[我目前想知道是否可以仅使用剪辑图像编码器来创建我自己的自定义对象检测模型？
我曾尝试从 CLIP 图像编码器中提取图像的嵌入。我想尝试将其提供给一些现有的对象检测模型，例如 YOLOv5 等，其中 CLIP 图像编码器是特征提取器。然而，我无法理解，我该如何继续这个想法。这可能吗？如果是，建议如何继续？]]></description>
      <guid>https://stackoverflow.com/questions/78913273/create-a-custom-object-detection-model-with-clip-vision-encoder</guid>
      <pubDate>Mon, 26 Aug 2024 07:30:04 GMT</pubDate>
    </item>
    <item>
      <title>Python文本检测OpenCV+Roboflow OCR相机性能非常滞后问题</title>
      <link>https://stackoverflow.com/questions/78913244/python-text-detection-opencvroboflow-ocr-camera-performance-very-lag-problem</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78913244/python-text-detection-opencvroboflow-ocr-camera-performance-very-lag-problem</guid>
      <pubDate>Mon, 26 Aug 2024 07:22:14 GMT</pubDate>
    </item>
    <item>
      <title>为什么每次运行程序都会得到不同的准确度</title>
      <link>https://stackoverflow.com/questions/78911839/why-get-different-accuracy-every-time-run-program</link>
      <description><![CDATA[我使用 Python 中的 keras tensorflow 训练模型。
另外，正如您在下面的代码中看到的，我使用了种子参数，但每次我用相同的数据运行相同的代码时，我都会面临不同的准确率百分比。
我的代码：
#Seed
tf.random.set_seed(42)
np.random.seed(42)
set_random_seed(42)
random.seed(42)

data = (&#39;data.csv&#39;)

data = pd.get_dummies(data, columns=[&#39;cp&#39;, &#39;restecg&#39;], drop_first=True)

X = data.drop(&#39;num&#39;, axis=1)
y = data[&#39;num&#39;]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

def create_model(optimizer=&#39;adam&#39;, init=&#39;glorot_uniform&#39;, neurons=[16, 8], dropout_rate=0.3):
model = Sequential()
model.add(Input(shape=(X_train.shape[1],)))
model.add(Dense(neurons[0],activation=&#39;relu&#39;, kernel_initializer=init))
model.add(BatchNormalization())
model.add(Dropout(dropout_rate))
model.add(Dense(neurons[1],activation=&#39;relu&#39;))
model.add(BatchNormalization())
model.add(Dropout(dropout_rate))
model.add(Dense(1,activation=&#39;sigmoid&#39;))
model.compile(optimizer=optimizer, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
返回模型

param_grid = {
&#39;optimizer&#39;: [&#39;adam&#39;, &#39;rmsprop&#39;],
&#39;model__neurons&#39;: [[16, 8]],
&#39;model__init&#39;: [&#39;glorot_uniform&#39;, &#39;normal&#39;],
&#39;model__dropout_rate&#39;: [0.3],
&#39;epochs&#39;: [50], 
&#39;batch_size&#39;: [10],
}

model = KerasClassifier(model=create_model, verbose=0)

kfold = KFold(n_splits=3, shuffle=True, random_state=42)
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, n_jobs=-1)
grid_search_result = grid_search.fit(X_train, y_train)

print(f&quot;最佳参数：{grid_search_result.best_params_}&quot;)

print(f&quot;最佳准确度：{grid_search_result.best_score_}&quot;)

best_model = grid_search_result.best_estimator_

keras_model = best_model.model
keras_model.trainable = False 

y_pred_prob = best_model.predict(X_test).flatten()
y_pred = np.where(y_pred_prob &gt; 0.5, 1, 0)

accuracy = accuracy_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred_prob)

print(f&#39;Accuracy (手动计算): {accuracy:.2f}&#39;)
print(f&#39;ROC AUC: {roc_auc:.2f}&#39;)

我需要每次都获得相同的准确度。
我应该如何解决这个问题？]]></description>
      <guid>https://stackoverflow.com/questions/78911839/why-get-different-accuracy-every-time-run-program</guid>
      <pubDate>Sun, 25 Aug 2024 17:25:44 GMT</pubDate>
    </item>
    <item>
      <title>将具有大内核的 maxpool 转换为具有小内核的 maxpool 的等效堆栈[关闭]</title>
      <link>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</link>
      <description><![CDATA[我有一个 onnx 模型，它有一些这样的 MaxPool 层：

我无法使用这些内核形状，因为我只能从 1x1 变为 3x3。 4x4 被认为不是最佳的，但我可以使用它。
我尝试用一​​堆 3x3 内核替换它们，如下所示：

我错误计算了此图像中的输出形状，但我会修复它。
我的疑问是，即使我修复了 MaxPool 层，输出是否会与具有更大内核的原始输出相似？我无法弄清楚应该使用什么组合才能使输出与原始内核相似或最接近。]]></description>
      <guid>https://stackoverflow.com/questions/78895371/converting-maxpool-with-big-kernels-to-equivalent-stacks-of-maxpool-with-small-k</guid>
      <pubDate>Wed, 21 Aug 2024 06:09:06 GMT</pubDate>
    </item>
    <item>
      <title>对于小型神经网络，激活函数的最佳选择是什么</title>
      <link>https://stackoverflow.com/questions/69240517/what-is-the-best-choice-for-an-activation-function-in-case-of-small-sized-neural</link>
      <description><![CDATA[我正在使用 pytorch 和 autograd 来构建我的神经网络架构。它是一个具有单个输入和输出的小型 3 层网络。假设我必须根据一些初始条件预测一些输出函数，并且我正在使用自定义损失函数。
我面临的问题是：

我的损失最初收敛，但梯度最终消失。

我尝试过 S 型激活和 tanh。tanh 在损失收敛方面给出了稍好的结果。

我尝试过使用 ReLU，但由于我的神经网络中没有太多权重，权重变得无效，并且无法给出良好的结果。


除了 S 型和 tanh 之外，还有其他激活函数可以很好地处理小型神经网络的梯度消失问题吗？还有什么建议我可以尝试吗？]]></description>
      <guid>https://stackoverflow.com/questions/69240517/what-is-the-best-choice-for-an-activation-function-in-case-of-small-sized-neural</guid>
      <pubDate>Sun, 19 Sep 2021 05:20:49 GMT</pubDate>
    </item>
    <item>
      <title>Adam 优化器与梯度下降</title>
      <link>https://stackoverflow.com/questions/52014332/adam-optimizer-vs-gradient-descent</link>
      <description><![CDATA[我想了解 Adam 优化器和梯度下降优化器之间的区别，以及在哪种情况下最适合使用哪一个。我正在查看 TF 网站，但如果你知道哪里可以以更好、更易于理解的方式解释这些内容，请告诉我？]]></description>
      <guid>https://stackoverflow.com/questions/52014332/adam-optimizer-vs-gradient-descent</guid>
      <pubDate>Sat, 25 Aug 2018 05:30:44 GMT</pubDate>
    </item>
    <item>
      <title>ReLU 何时会杀死神经元？</title>
      <link>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</link>
      <description><![CDATA[我对 ReLU 死亡问题感到困惑。ReLU 只会在前向传递期间杀死神经元吗？还是在后向传递期间也会杀死神经元？]]></description>
      <guid>https://stackoverflow.com/questions/50349176/when-does-relu-kill-the-neurons</guid>
      <pubDate>Tue, 15 May 2018 11:35:06 GMT</pubDate>
    </item>
    <item>
      <title>SGD（随机梯度下降）与反向传播</title>
      <link>https://stackoverflow.com/questions/37953585/sgdstochastic-gradient-descent-vs-backpropagation</link>
      <description><![CDATA[您能告诉我随机梯度下降（SGD）和反向传播之间的区别吗？]]></description>
      <guid>https://stackoverflow.com/questions/37953585/sgdstochastic-gradient-descent-vs-backpropagation</guid>
      <pubDate>Tue, 21 Jun 2016 20:02:39 GMT</pubDate>
    </item>
    <item>
      <title>阶跃函数计算限制</title>
      <link>https://stackoverflow.com/questions/28462891/step-function-computational-limitations</link>
      <description><![CDATA[阶跃函数作为神经网络的激活函数有哪些局限性？
我听说非线性函数需要具有普遍性，但阶跃函数在这方面处于什么位置？它们是否与线性激活函数一样有限？它们会被归类为线性函数吗？]]></description>
      <guid>https://stackoverflow.com/questions/28462891/step-function-computational-limitations</guid>
      <pubDate>Wed, 11 Feb 2015 19:30:18 GMT</pubDate>
    </item>
    </channel>
</rss>