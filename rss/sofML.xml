<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 27 Jan 2025 09:18:58 GMT</lastBuildDate>
    <item>
      <title>如何在 Keras 3 中打印出层间的张量值？</title>
      <link>https://stackoverflow.com/questions/79389885/how-do-i-print-out-the-tensor-values-in-between-layers-in-keras-3</link>
      <description><![CDATA[我正在使用带有 PyTorch 后端的 Keras 3（出于某种原因，我无法让 TF 后端工作，而且我从未使用过 JAX）。
我正在尝试将其他人编写的模型移植到另一个运行时，我想在每一层之后转储有关张量的汇总统计信息，以便找出我在移植过程中错误实现的哪个操作（可能是注意，哈哈）。
如何将打印语句插入 Keras 3 模型？我能找到的所有其他答案都与 tf.keras 有关，这似乎与我正在使用的完全不同。也没有方法 keras.backend.print_tensor()。
我也尝试过创建一个这样的中间模型（为了便于理解，我挑选的模型是 Moonshine）：
encoder = model.encoder.encoder
encoder_intermediate_model = Model(
input=encoder.inputs, output=[layer.output for layer incoder.layers]
)

但尝试运行此程序时会崩溃，并出现模糊错误：
回溯（最近一次调用）：
文件“C:\Users\ibiyemi\projects\wellington-ml\moonshine.py”，第 764 行，位于&lt;module&gt;
编码器输出 = 编码器中间模型 (
^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\ibiyemi\projects\wellington-ml\.venv\Lib\site-packages\keras\src\utils\traceback_utils.py&quot;，第 122 行，位于 error_handler 中
从 None 引发 e.with_traceback(filtered_tb)
文件 &quot;C:\Users\ibiyemi\projects\wellington-ml\.venv\Lib\site-packages\torch\nn\modules\module.py&quot;，第 1736 行，位于 _wrapped_call_impl 中
返回 self._call_impl(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
文件 &quot;C:\Users\ibiyemi\projects\wellington-ml\.venv\Lib\site-packages\torch\nn\modules\module.py&quot;，第 1747 行，在 _call_impl 中
return forward_call(*args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyError: &quot;调用 Functional.call() 时遇到异常。\n\n\x1b[1m2365371176512\x1b[0m\n\nFunctional.call() 收到的参数:\n • 输入=[&#39;torch.Tensor(shape=torch.Size([1, 1248, 416]), dtype=float32)&#39;, &#39;torch.Tensor(shape=torch.Size([1]), dtype=int32)&#39;]\n • training=None\n • mask=[&#39;None&#39;, &#39;None&#39;]&quot;
]]></description>
      <guid>https://stackoverflow.com/questions/79389885/how-do-i-print-out-the-tensor-values-in-between-layers-in-keras-3</guid>
      <pubDate>Mon, 27 Jan 2025 06:20:25 GMT</pubDate>
    </item>
    <item>
      <title>ML-Agents 代理无法在 Unity 中完成简单的“射弹到目标”任务</title>
      <link>https://stackoverflow.com/questions/79389655/ml-agents-agent-not-converging-for-simple-projectile-to-target-task-in-unity</link>
      <description><![CDATA[代理在重力作用下向目标发射弹丸。代理只有一个动作 - 射击角度。发射力是恒定的。我还没有改变目标的位置。因此这应该是微不足道的，因为模型只需要学习正确的射击角度。但经过 300000 个训练步骤后，模型仍然射击不稳定。
代理：
使用 Unity.MLAgents;
使用 Unity.MLAgents.Actuators;
使用 Unity.MLAgents.Sensors;
使用 UnityEngine;

公共类 ProjectileAgent：代理
{
公共 Transform 目标; //带有 2D 碰撞器和“目标”标签的固定目标
公共 Transform launchPoint; //生成弹丸的位置
公共 GameObject projectilePrefab; //带有 Rigidbody2D 和 ProjectileCollision 脚本的预制件
公共 float fixedForce = 500f; // 对射弹施加恒定的力

private bool hasLaunched = false;

public override void OnEpisodeBegin()
{
hasLaunched = false;
RequestDecision(); // 在每个情节开始时请求一个决定
}

public override void CollectObservations(VectorSensor sensor)
{
// 观察从发射点到目标的相对位置 (x,y)
Vector2 diff = target.position - launchPoint.position;
sensor.AddObservation(diff.x);
sensor.AddObservation(diff.y);
}

public override void OnActionReceived(ActionBuffers action)
{
if (!hasLaunched)
{
// 一个连续动作 (0..1) 映射到 [0..180] 度
float angle01 = Mathf.Clamp01(actions.ContinuousActions[0]);
float angleDegrees = Mathf.Lerp(0f, 180f, angle01);

LaunchProjectile(angleDegrees);
hasLaunched = true;
}
}

private void LaunchProjectile(float angleDegrees)
{
GameObject projObj = Instantiate(projectilePrefab, launchPoint.position, Quaternion.identity);
ProjectileCollision projScript = projObj.GetComponent&lt;ProjectileCollision&gt;();
projScript.agent = this;

Rigidbody2D rb = projObj.GetComponent&lt;Rigidbody2D&gt;();
float rad = angleDegrees * Mathf.Deg2Rad;
Vector2 direction = new Vector2(Mathf.Cos(rad), Mathf.Sin(rad));
rb.AddForce(direction * fixedForce);
}

// 射弹击中目标时调用
public void OnHitTarget()
{
AddReward(1.0f);
EndEpisode();
}

// 射弹未击中目标时调用
public void OnMiss(Vector2 projectilePosition)
{
float distance = Vector2.Distance(projectilePosition, target.position);
float maxDistance = 10f; // 根据需要调整
float vicinity = 1f - (distance / maxDistance);
vicinity = Mathf.Clamp01(proximity);

// 接近目标时获得部分奖励
AddReward(proximity * 0.5f);

// 未击中时获得小额惩罚
AddReward(-0.1f);
EndEpisode();
}

// Unity 编辑器中测试的启发式方法（随机角度）
public override void Heuristic(in ActionBuffers actionOut)
{
actionOut.ContinuousActions[0] = Random.value;
}
}

Projectile:
using UnityEngine;

public class ProjectileCollision : MonoBehaviour
{
public ProjectileAgent agent;

private void Start()
{
// 短暂时间后销毁，以便我们可以记录未击中
Destroy(gameObject, lifetime);
}

private void OnCollisionEnter2D(Collision2D collision)
{
if (collision.gameObject.CompareTag(&quot;Target&quot;))
{
agent.OnHitTarget();
}
else
{
agent.OnMiss(transform.position);
}
Destroy(gameObject);
}
}


我尝试过的方法

奖励塑造：
击中目标可获得 +1 奖励，近距离击中可获得部分基于距离的奖励，未击中可获得少量负奖励。
我将击中奖励提高到 +3，降低了未击中惩罚，等等。
训练步骤：
我使用 PPO 运行了 300k+ 步。
碰撞检查：
日志确认 OnHitTarget() 和 OnMiss() 在预期时间触发。
固定力和重力：
通过硬编码角度，验证箭可以手动到达目标。
重力已设置，因此物理上可以击中。
无随机目标：
目标目前固定在一个位置以保持简单。
]]></description>
      <guid>https://stackoverflow.com/questions/79389655/ml-agents-agent-not-converging-for-simple-projectile-to-target-task-in-unity</guid>
      <pubDate>Mon, 27 Jan 2025 02:47:35 GMT</pubDate>
    </item>
    <item>
      <title>我的神经网络从头开始拒绝收敛，但在前馈中运行良好</title>
      <link>https://stackoverflow.com/questions/79389036/my-neural-netwok-from-scratch-refuse-to-converge-it-works-fine-in-feed-forward</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79389036/my-neural-netwok-from-scratch-refuse-to-converge-it-works-fine-in-feed-forward</guid>
      <pubDate>Sun, 26 Jan 2025 18:03:14 GMT</pubDate>
    </item>
    <item>
      <title>无法获取 SentenceTransformer 模型的训练准确率、训练损失、验证准确率、验证损失图</title>
      <link>https://stackoverflow.com/questions/79388997/unable-to-get-the-training-accuracy-training-loss-validation-accuracy-validat</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79388997/unable-to-get-the-training-accuracy-training-loss-validation-accuracy-validat</guid>
      <pubDate>Sun, 26 Jan 2025 17:42:51 GMT</pubDate>
    </item>
    <item>
      <title>在 Keras 3.5 中使用 SavedModel 格式</title>
      <link>https://stackoverflow.com/questions/79388942/using-savedmodel-format-in-keras-3-5</link>
      <description><![CDATA[我正在学习机器学习入门课程，在尝试使用 tf.keras.models.load_model(Path_to_pb_model) 加载 Savedformat 模型时遇到了问题。
我正在使用 Tensorflow 2.17.1 和 Keras 3.5
显然 Keras 3 只接受“.keras”或“.h5”格式。
首先，我有点困惑，因为根据这个文档：
保存和加载模型，你应该能够保存 &amp;在 Keras 3 中加载 .pb 模型

文档有误吗？因为当我尝试在 Colab 中运行此代码时，出现错误，提示仅支持 .keras 和 .h5 文件格式。
另外，我还查看了本指南，了解如何使用 tf.saved_model API 加载和保存 SavedModel 格式，但这不会返回 Keras 对象，也没有“.evaluate()”或“.predict()”方法。
那么有没有办法在 Keras3 中加载 SavedModel 格式？然后在我的测试数据上评估该模型？
提前谢谢。
亚历克斯]]></description>
      <guid>https://stackoverflow.com/questions/79388942/using-savedmodel-format-in-keras-3-5</guid>
      <pubDate>Sun, 26 Jan 2025 17:06:14 GMT</pubDate>
    </item>
    <item>
      <title>如何将 5 个训练模型组合成一个模型，并使用组合模型进行预测？</title>
      <link>https://stackoverflow.com/questions/79388433/how-can-i-combine-5-trained-models-into-a-single-one-and-use-the-combined-model</link>
      <description><![CDATA[我必须实现联合学习。因此，我训练了 5 个模型的列表，并在不同的数据集上训练了每个模型。现在我必须将列表中训练过的模型组合起来，但我不知道该怎么做。之后我必须使用组合模型对测试集进行预测。
class MulticlassClassification:
def __init__(self, input_dims, layer, num_classes):
self.model = Sequential(name=&quot;server_model&quot;)
self.model.add(Dense(
layer[0],
input_shape=(input_dims,),
activation=&#39;relu&#39;
))
for l in layer[1:]:
self.model.add(Dense(l,activation=&#39;relu&#39;))
self.model.add(Dense(num_classes,activation=&#39;softmax&#39;))
self.model.compile(
loss=&#39;sparse_categorical_crossentropy&#39;,
optimizer=&#39;adam&#39;,
metrics=[&#39;accuracy&#39;]
)
self.model.summary()
def set_avg_weights(self,模型):
all_weights = np.array([
model.model.get_weights()
for model in models
])
avg_weights = np.mean(all_weights, axis=0)
self.model.set_weights(avg_weights)

all_weights = np.array([
model.model.get_weights()
for model in models
])
avg_weights = np.mean(all_weights, axis=0)
self.model.set_weights(avg_weights)
def fit(self, X, Y, epochs, batch_size):
self.model.fit(X, Y.to_numpy(), epochs=epochs, batch_size=batch_size)

def predict(self, X, Y):
preds = self.model.predict(X)
preds = [np.argmax(p) for p in preds]
print(classification_report(Y, preds))
ConfusionMatrixDisplay.from_predictions(Y, preds)

#同时进行预处理和训练
label_encoder = preprocessing.LabelEncoder()
model = []
for i in range(5):
model.append(MulticlassClassification(27, [20, 20, 20], num_classes=5))
for i in range(5):
file_path = os.path.join(folder_path, nodes_list[i])
df = pd.read_csv(file_path)
df=df.drop([&#39;FLAGS&#39;],axis=1)
df[&#39;PKT_TYPE&#39;]=label_encoder.fit_transform(df[&#39;PKT_TYPE&#39;])
df[&#39;PKT_CLASS&#39;]=label_encoder.fit_transform(df[&#39;PKT_CLASS&#39;])
df[&#39;NODE_NAME_TO&#39;]=label_encoder.fit_transform(df[&#39;NODE_NAME_TO&#39;])
df[&#39;NODE_NAME_FROM&#39;]=label_encoder.fit_transform(df[&#39;NODE_NAME_FROM&#39;])
print(df[&#39;PKT_TYPE&#39;].unique())
print(df[&#39;NODE_NAME_FROM&#39;].unique())
print(df[&#39;NODE_NAME_TO&#39;].unique())
print(df[&#39;PKT_CLASS&#39;].unique())
X=df.drop([&#39;PKT_CLASS&#39;],axis=1)
Y=df[&#39;PKT_CLASS&#39;]
X1, X2, Y1, Y2= train_test_split(X, Y, train_size=0.9984375, random_state=1)
model[i].fit(X1, Y1, epochs=20, batch_size=32)

#现在我必须将列表 model[] 中的所有模型合并为一个。怎么做？
#然后我必须使用新模型预测测试集。```
]]></description>
      <guid>https://stackoverflow.com/questions/79388433/how-can-i-combine-5-trained-models-into-a-single-one-and-use-the-combined-model</guid>
      <pubDate>Sun, 26 Jan 2025 11:30:49 GMT</pubDate>
    </item>
    <item>
      <title>用时间链接表示特征的 ML 模型类型</title>
      <link>https://stackoverflow.com/questions/79388422/type-of-ml-model-to-represent-features-with-a-time-link</link>
      <description><![CDATA[我正在尝试建立一个模型来预测合同的价格。合约在特定日期具有特定事件和状态。
例如：
2025/01/10 - 波动率：1.2，障碍：1.5，息票 1.1
2025/01/14 - 波动率：0.9，障碍：1.55，息票 1.15
简要解释是，当达到障碍时，息票就会支付。
每个事件日期都有 15 个特征，包括该日期的市场状态以及波动性和远期价格等财务参数。
我希望能够将可变长度序列（不同的合约可能具有不同的障碍日期/息票日期数量）放入网络并获得价格。
首先，我对所有内容进行了标准化，包括标准化为合约长度的时间点
起初我想使用 LSTM，但 LSTM 用于预测序列数据。这不是连续数据，因为前一个时间步骤与下一个时间步骤无关。尽管每个特征都有一个时间相关维度，因为每个特征都与某个时间点相关联
在这种情况下我应该使用哪种技术？
示例特征矩阵
时间障碍 优惠券 波动性 前向
0.1 1.1 1.4 1.5 0.98
0.3 0 0 1.3 0.97
0.9 1.4 1.6 0.3 0.95
0.95. 1.0. 1.8. 2.4. 0.97

此特征矩阵表示合同的定义。基本上，在时间 0.1 时，障碍为 1.1，并支付 1.4 的优惠券。在时间 0.3 时，没有障碍或优惠券，但我们有一些波动性和前向信息确实会影响合同的价格。更改时间值可能会显著影响价格。
因此它不是时间序列数据，因为它不是随时间变化的序列。它只是表示合约所处环境的事件和状态。使用其中一些参数的蒙特卡罗方法将计算价格，但我需要使用 ML 来计算]]></description>
      <guid>https://stackoverflow.com/questions/79388422/type-of-ml-model-to-represent-features-with-a-time-link</guid>
      <pubDate>Sun, 26 Jan 2025 11:23:17 GMT</pubDate>
    </item>
    <item>
      <title>评估期间出现断言错误：Detectron2 RetinaNet 微调中预测的类别 ID 超出范围</title>
      <link>https://stackoverflow.com/questions/79387630/assertionerror-during-evaluation-predicted-class-id-out-of-range-in-detectron2</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79387630/assertionerror-during-evaluation-predicted-class-id-out-of-range-in-detectron2</guid>
      <pubDate>Sat, 25 Jan 2025 22:27:24 GMT</pubDate>
    </item>
    <item>
      <title>使用预训练模型作为特征提取器，并使用 dbn 进行分类</title>
      <link>https://stackoverflow.com/questions/79386281/usage-of-pretrained-models-as-feature-extractor-and-dbn-for-clasification</link>
      <description><![CDATA[是否可以使用 2 个预先训练的模型（例如 mobilevit、nasnetmobile）提取白血病分类的特征，然后连接这些特征并使用 深度信念网络 进行分类？
如何做到这一点？或者这种方法的性能是否较低？
如果可能，有人可以分享有关此的示例代码吗？]]></description>
      <guid>https://stackoverflow.com/questions/79386281/usage-of-pretrained-models-as-feature-extractor-and-dbn-for-clasification</guid>
      <pubDate>Sat, 25 Jan 2025 06:31:48 GMT</pubDate>
    </item>
    <item>
      <title>InvalidArgumentError：在 Google Colab 上训练 TensorFlow RetinaNet 模型时，流执行器中没有 DNN</title>
      <link>https://stackoverflow.com/questions/79377971/invalidargumenterror-no-dnn-in-stream-executor-while-training-a-tensorflow-reti</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79377971/invalidargumenterror-no-dnn-in-stream-executor-while-training-a-tensorflow-reti</guid>
      <pubDate>Wed, 22 Jan 2025 13:57:32 GMT</pubDate>
    </item>
    <item>
      <title>错误：在对象检测模型中，计算损失时，张量 a (810) 的大小必须与非单维 3 上的张量 b (36) 的大小匹配</title>
      <link>https://stackoverflow.com/questions/79364056/error-the-size-of-tensor-a-810-must-match-the-size-of-tensor-b-36-at-non-si</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79364056/error-the-size-of-tensor-a-810-must-match-the-size-of-tensor-b-36-at-non-si</guid>
      <pubDate>Fri, 17 Jan 2025 08:17:32 GMT</pubDate>
    </item>
    <item>
      <title>将多个模型指标运行记录到 MLFlow 中的同一个图中</title>
      <link>https://stackoverflow.com/questions/79308237/logging-multiple-model-metrics-runs-to-the-same-plot-in-mlflow</link>
      <description><![CDATA[我正在对模型参数进行网格搜索优化，并使用将损失记录到 MLFlow
Mlflow.log_metric(f“{run_number}_Loss”, returns, iteration)

但对于每次新运行，我在 MLFlow UI 中都会得到不同的图。
有没有办法多次记录到同一个图，也许是不同的颜色，并添加图例以便能够轻松比较不同的运行？]]></description>
      <guid>https://stackoverflow.com/questions/79308237/logging-multiple-model-metrics-runs-to-the-same-plot-in-mlflow</guid>
      <pubDate>Wed, 25 Dec 2024 19:50:23 GMT</pubDate>
    </item>
    <item>
      <title>如何从 TensorFlow Model Garden 中的自定义数据集训练的 RetinaNet ResNet50 模型获取预测并检索模型详细信息？</title>
      <link>https://stackoverflow.com/questions/79295907/how-do-i-get-predictions-from-a-custom-dataset-trained-retinanet-resnet50-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79295907/how-do-i-get-predictions-from-a-custom-dataset-trained-retinanet-resnet50-model</guid>
      <pubDate>Fri, 20 Dec 2024 00:12:30 GMT</pubDate>
    </item>
    <item>
      <title>当我运行以下代码时，TypeError: JoypadSpace.reset() 得到了一个意外的关键字参数“seed”，我该如何解决这个问题？</title>
      <link>https://stackoverflow.com/questions/76509663/typeerror-joypadspace-reset-got-an-unexpected-keyword-argument-seed-when-i</link>
      <description><![CDATA[当我运行此代码时：
从 nes_py.wrappers 导入 JoypadSpace
导入 gym
导入 gym_super_mario_bros
从 gym_super_mario_bros.actions 导入 SIMPLE_MOVEMENT
从 gym.wrappers 导入 GrayScaleObservation
从 stable_baselines3.common.vec_env 导入 VecFrameStack、DummyVecEnv
从 matplotlib 导入 pyplot 作为 plt

env = gym_super_mario_bros.make(&#39;SuperMarioBros-v0&#39;,apply_api_compatibility=True,render_mode=&quot;human&quot;)
env = JoypadSpace(env, SIMPLE_MOVEMENT)
env = GrayScaleObservation(env,keep_dim=True)
env = DummyVecEnv([lambda:env])
env = VecFrameStack(env,4,channels_order=&#39;last&#39;)
state = env.reset()

我收到以下错误：

我应该如何修复此问题？]]></description>
      <guid>https://stackoverflow.com/questions/76509663/typeerror-joypadspace-reset-got-an-unexpected-keyword-argument-seed-when-i</guid>
      <pubDate>Mon, 19 Jun 2023 19:47:30 GMT</pubDate>
    </item>
    <item>
      <title>如何将视频中的音频分割并转录为带时间戳的片段？</title>
      <link>https://stackoverflow.com/questions/75794919/how-to-segment-and-transcribe-an-audio-from-a-video-into-timestamped-segments</link>
      <description><![CDATA[我想根据每行台词的内容将视频记录分成几章。记录将用于为每个章节生成一系列开始和结束时间戳。这类似于 YouTube 现在“自动分章”视频的方式。
示例 .srt 记录：
...

70
00:02:53,640 --&gt; 00:02:54,760
好的，排在第五位，

71
00:02:54,760 --&gt; 00:02:57,640
我们还有另一个习惯，每天可以节省我大约 15 分钟
...

我使用 ChatGPT 执行此操作的运气很差，因为它很难按主题进行分段并准确地回忆起开始和结束时间戳。我现在正在探索是否还有其他选项可以做到这一点。
我知道使用一些 Python 库可以实现基于时间序列的主题建模。我还阅读了有关文本平铺作为另一种选择的文章。有哪些选项可以实现这样的结果？
注意：上面的格式 (.srt) 不是必需的。它只是将输入作为带有开始和结束时间戳的文本内容列表。]]></description>
      <guid>https://stackoverflow.com/questions/75794919/how-to-segment-and-transcribe-an-audio-from-a-video-into-timestamped-segments</guid>
      <pubDate>Mon, 20 Mar 2023 20:14:46 GMT</pubDate>
    </item>
    </channel>
</rss>