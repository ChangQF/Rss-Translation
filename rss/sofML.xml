<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 10 Jan 2024 09:14:10 GMT</lastBuildDate>
    <item>
      <title>关系分类器评估需要很长时间</title>
      <link>https://stackoverflow.com/questions/77792061/relation-classifier-evaluation-taking-a-long-time</link>
      <description><![CDATA[我有一个深度学习模型，可以预测主体、客体以及它们之间的关系。对于培训，我有这些注释并且可以使用它们。在评估中，我没有这些注释，因此目前我只是对每个图像的所有可能的对象组合进行采样。问题是：图像中可能有 20 个对象，那么我必须测试 400 个关系。乘以批量大小，我的模型必须生成 &gt; 1000 个组合边界框，并将它们在图像上对齐。此操作大大延长了评估时间。培训大约需要 1 小时，而评估最多需要 12 小时。我是否误解了评估抽样，或者我的方法是否错误。目前，我正在分别对所有对象和所有可能的关系进行 Roi 对齐，然后我将连接这些特征以使用分类层。
这是我使用的模型]]></description>
      <guid>https://stackoverflow.com/questions/77792061/relation-classifier-evaluation-taking-a-long-time</guid>
      <pubDate>Wed, 10 Jan 2024 09:01:58 GMT</pubDate>
    </item>
    <item>
      <title>如何匹配2个矩阵中的值（Matlab）</title>
      <link>https://stackoverflow.com/questions/77791924/how-to-matching-values-in-2-matrix-matlab</link>
      <description><![CDATA[Matlab问题
例如我的数据集
&lt;前&gt;&lt;代码&gt; A= [0:00:01 1 1 1
         0:00:02 2 2 2
         0:00:03 3 3 3
         0:00:04 4 4 4
         0:00:05 5 5 5
         0:00:06 6 6 6
         0:00:07 7 7 7
         0:00:08 8 8 8
         0:00:09 9 9 9
         0:00:10 10 10 10]



 B = [0:00:02 A A A
         0:00:04 BB BB
         0:00:06 C C C
         0:00:08 DD DD
         0:00:010 EE EE
         0:00:012 F F F
         0:00:014 GG GG
         0:00:016 小时 小时
         0:00:018 我我我
         0:00:20 JJJ]

我可以按 A 数据集中的条件匹配 B 数据集并创建新矩阵吗？
提出新的矩阵
&lt;前&gt;&lt;代码&gt;C =[0:00:02 A A A
     0:00:04 BB BB
     0:00:06 C C C
     0:00:08 DD DD
     0:00:010 E E E]

非常感谢
我尝试在 Matlab 中编码并期望一些建议/或示例代码]]></description>
      <guid>https://stackoverflow.com/questions/77791924/how-to-matching-values-in-2-matrix-matlab</guid>
      <pubDate>Wed, 10 Jan 2024 08:38:37 GMT</pubDate>
    </item>
    <item>
      <title>我正在努力使用 bert-base-uncased 模型在句子的基础上创建标题</title>
      <link>https://stackoverflow.com/questions/77791809/i-am-working-on-creating-a-title-on-the-basis-of-sentence-using-bert-base-uncase</link>
      <description><![CDATA[我正在使用 python bert-base-uncased 模型基于句子创建标题。这是我编写的代码。我需要根据 possible_labels 预测标题。有什么可能的方法可以根据 possible_labels 执行标题预测。
加载预训练的 BERT 模型和分词器以进行文本分类
从转换器导入 AutoTokenizer、AutoModelForSequenceClassification
进口火炬
model_name = “bert-base-uncased”；
tokenizer = AutoTokenizer.from_pretrained(model_name)
模型 = AutoModelForSequenceClassification.from_pretrained(model_name)

定义类标签
可能的标签 = [
    “问候”，
    《再见》，
    《表达谢意》，
    “道歉”，
    “请求”，
    “命令或指示”，
    “广告或促销”，
    “新闻更新”，
    “问题”，
    “积极情绪”，
    “负面情绪”，
    “中立声明”，
    # 根据需要添加更多标签
]

输入句子进行分类
&lt;前&gt;&lt;代码&gt;
text = “正在工作”;

# 对输入句子进行分词和编码
编码输入 = 分词器（文本，return_tensors =“pt”）

# 进行预测
输出=模型（**编码输入）

# 获取预测的类别索引
Predicted_class_index = torch.argmax(output.logits, dim=1).item()

# 获取预测标签
预测标签=可能的标签[预测类别索引]

打印结果
&lt;前&gt;&lt;代码&gt;
print(&quot;输入句子：&quot;, text)
print(&quot;预测标签：&quot;, Predicted_label)

打印所有概率
概率 = torch.nn.function.softmax(output.logits, dim=1).tolist()[0]
对于标签，zip 中的概率（possible_labels，概率）：
    print(f“{label} 的概率：{prob:.4f}”)

]]></description>
      <guid>https://stackoverflow.com/questions/77791809/i-am-working-on-creating-a-title-on-the-basis-of-sentence-using-bert-base-uncase</guid>
      <pubDate>Wed, 10 Jan 2024 08:18:12 GMT</pubDate>
    </item>
    <item>
      <title>查找同时包含数字和字符串数据类型的特定列中的最大值</title>
      <link>https://stackoverflow.com/questions/77791806/find-the-maximum-value-in-a-specfic-column-that-contains-both-numeric-and-string</link>
      <description><![CDATA[我有一个 df，其中包含一列（例如“经度”），该列同时包含数字和字符串数据类型。
例如：[5，“高”，“3”]
我想将包含文本数据的行（例如“high”）更改为列中的最大值（例如“5”），您会使用哪种方法/函数？
谢谢。
我想使用 df[&#39;latitude&#39;].max() 函数，但它无法比较字符串和数字数据类型。]]></description>
      <guid>https://stackoverflow.com/questions/77791806/find-the-maximum-value-in-a-specfic-column-that-contains-both-numeric-and-string</guid>
      <pubDate>Wed, 10 Jan 2024 08:17:39 GMT</pubDate>
    </item>
    <item>
      <title>我想制作一个程序来读取大型文本文件（例如书籍）并在 python 中输出它们的流派[关闭]</title>
      <link>https://stackoverflow.com/questions/77791719/i-want-to-make-a-program-which-reads-large-text-files-such-as-books-and-outputs</link>
      <description><![CDATA[我认为制作一个读取文本文件（例如书籍）的程序会很有用，并输出其流派。我的研究得出的结论是，我可能需要在大量书籍及其类型上训练我自己的语言模型。这真的是最好的方法吗？如果是，我应该如何在 Python 中做到这一点？
我希望所使用的任何方法都是免费的。以及在 Mac 上工作。]]></description>
      <guid>https://stackoverflow.com/questions/77791719/i-want-to-make-a-program-which-reads-large-text-files-such-as-books-and-outputs</guid>
      <pubDate>Wed, 10 Jan 2024 08:01:59 GMT</pubDate>
    </item>
    <item>
      <title>pytorch 训练中不允许进行多重处理</title>
      <link>https://stackoverflow.com/questions/77791682/multiprocessing-not-allowed-in-pytorch-training</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77791682/multiprocessing-not-allowed-in-pytorch-training</guid>
      <pubDate>Wed, 10 Jan 2024 07:53:01 GMT</pubDate>
    </item>
    <item>
      <title>Handritten 数字识别算法前向传播中的矩阵乘法效率低下</title>
      <link>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</link>
      <description><![CDATA[我正在用 python 编写手写数字识别神经网络算法，而不使用预先编写的 ML 库。我目前正在尝试实现一个 DenseLayer 类，并在其中实现一个前向传播函数。我当前的功能如下所示。


DenseLayer 类：
  ...
  
  ...
  def for_prop(自身, input_data):
    self.input = input_data

    transpose_weights = self.weights.T
    # matMulComponent = np.matmul(input_data, transpose_weights)
    print(f&quot;转置形状：{transpose_weights.shape} 和输入形状 {input_data.shape}&quot;)
    matMulComponent = input_data.T @ transpose_weights
    打印（len（matMulComponent））

    z = matMulComponent + self.biases.T
    f_wb = self.act_fun(z)
    
    

    self.output = f_wb.reshape(-1, 1)
    print(f&quot;形状结果：{self.output.shape}&quot;)
    返回 self.output



问题是我正在进行大量的重塑和转置以获得结果。这看起来效率不高。我只是像这样实现它，因为这是我让它工作的唯一方法。
所以我的问题是：

这个实施起来好吗（因此会导致效率低下）
有没有更好的方法来实现这个前向传播函数

这就是我的输入数据数组的样子（我刚刚打印它并采取了 ss）。我供参考的输入数据是一个扁平的 28*28 数组，每个单元格代表一种颜色。我首先对数据进行标准化（z 分数标准化）
输入数据图像
如果有帮助的话，我还截取了第一层的权重格式的屏幕截图。 （请记住，它在 for_prop 函数中使用之前已被转置）。
第一个隐藏层的权重矩阵图片
前向传播似乎确实有效，但这很好：前向传播进度 
任何有关我做错的事情的帮助将不胜感激:)]]></description>
      <guid>https://stackoverflow.com/questions/77790906/matrix-multiplication-in-forward-propogation-for-handritten-digit-recog-algo-ine</guid>
      <pubDate>Wed, 10 Jan 2024 04:20:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 DCGAN 模型在训练中表现如此糟糕？</title>
      <link>https://stackoverflow.com/questions/77790800/why-is-my-dcgan-model-performing-so-bad-in-training</link>
      <description><![CDATA[我一直在尝试创建一个 DCGAN 作为一个项目来尝试理解它是如何工作的，但是；我遇到的主要问题之一是判别器似乎一直过度拟合。我不确定这是否是由于模型本身或可能是错误的超参数造成的，也许我可能遗漏了一些东西，我想帮助理解原因；我尝试了不同的学习率组合，但在 15 个 epoch 左右之后，我不断得到鉴别器准确率 100% 的相同结果。这是 Colab 的链接：
https://drive.google.com/file/d/1CrZYEV6RNaklKqXYgrbF4SqggxHvabh0/查看？usp=drive_link
我尝试过让整体架构更简单，在超参数中使用不同的值，但我迷失了方向，我认为现在是时候让真正了解这些东西的人来让我了解我不了解的地方了做正确的事。]]></description>
      <guid>https://stackoverflow.com/questions/77790800/why-is-my-dcgan-model-performing-so-bad-in-training</guid>
      <pubDate>Wed, 10 Jan 2024 03:34:03 GMT</pubDate>
    </item>
    <item>
      <title>NLTK 词形还原器收到错误 BadZipFile：文件不是 zip 文件</title>
      <link>https://stackoverflow.com/questions/77790772/nltk-lemmatizer-received-error-badzipfile-file-is-not-a-zip-file</link>
      <description><![CDATA[我正在尝试使用 NLTK 包中的词形还原器，但出现此错误
_RealGetContents 中的文件 /opt/anaconda3/lib/python3.8/zipfile.py:1336
raise BadZipFile(“文件不是 zip 文件”)
BadZipFile：文件不是 zip 文件
我的代码如下
导入nltk
从 nltk.corpus 导入停用词
导入字符串
进口再
将 pandas 导入为 pd
从 nltk.stem 导入 WordNetLemmatizer
wn = WordNetLemmatizer()
print(wn.lemmatize(&#39;均值&#39;))
print(wn.lemmatize(&#39;含义&#39;))
到目前为止已采取措施但仍无法解决问题：

我尝试使用 conda uninstall nltk 卸载 nltk 软件包并重新下载
我还尝试删除 nltk_data 文件并使用 nltk.download() 再次下载该文件。我注意到随后弹出了下载文件的窗​​口，文件的状态为“已过时”，并且我还收到了错误“下载的 zip 文件出错”

有人可以帮助我吗？我很想学习 NLP，但我目前被困在这里。预先感谢您]]></description>
      <guid>https://stackoverflow.com/questions/77790772/nltk-lemmatizer-received-error-badzipfile-file-is-not-a-zip-file</guid>
      <pubDate>Wed, 10 Jan 2024 03:19:26 GMT</pubDate>
    </item>
    <item>
      <title>如何将变量的每个组合纳入机器学习建模？</title>
      <link>https://stackoverflow.com/questions/77790711/how-to-get-every-combi-of-vars-into-ml-modeling</link>
      <description><![CDATA[假设我有 var a 和 b。我正在使用 var a 进行聚类，另一个使用 b 进行聚类，另一个使用 a 和 b 进行聚类。我不知道如何用 python 实现这个。
感谢您的建议
在下面的代码中，我添加了“#HAS TO BE AUTOMATED”我认为需要自动化的地方
示例数据：
    id 年龄 bp sg al 苏 rbc
0 0 48 80 1.020 1 0 1
1 1 7 50 1.020 4 0 1


id：建模中不需要
年龄 bp sg al su ：数字
rbc ：分类

将 numpy 导入为 np
将 pandas 导入为 pd
将 matplotlib.pyplot 导入为 plt
将seaborn导入为sns
从 kmodes 导入 kprototypes

数据集 = pd.read_csv(..)
df=数据集.copy()


#删除不必要的列
df.drop(列=[“id”],inplace=True)

#标准化
columns_to_normalize = [&#39;age&#39;,&#39;bp&#39;,&#39;sg&#39;,&#39;al&#39;,&#39;su&#39;] #必须自动化
df[columns_to_normalize] = df[columns_to_normalize].apply(lambda x: (x - x.mean()) / np.std(x))


#获取值数组
data_array=df.值


#指定数据类型
data_array[:, 0:4] = data_array[:, 0:4].astype(float) #必须自动化
data_array[:, 5] = data_array[:, 5].astype(str) #必须自动化


#创建未经训练的模型
untrained_model = kprototypes.KPrototypes(n_clusters=2,max_iter=20)


#预测集群
集群 = untrained_model.fit_predict(data_array, categorical=[5])

数据集[“聚类标签”]=聚类
print(&quot;聚类后的数据是：&quot;)

]]></description>
      <guid>https://stackoverflow.com/questions/77790711/how-to-get-every-combi-of-vars-into-ml-modeling</guid>
      <pubDate>Wed, 10 Jan 2024 03:01:06 GMT</pubDate>
    </item>
    <item>
      <title>将 Pytorch 模型 .pth 转换为 onnx 模型时遇到问题</title>
      <link>https://stackoverflow.com/questions/77790645/having-problem-on-converting-pytorch-model-pth-into-onnx-model</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77790645/having-problem-on-converting-pytorch-model-pth-into-onnx-model</guid>
      <pubDate>Wed, 10 Jan 2024 02:28:32 GMT</pubDate>
    </item>
    <item>
      <title>我在视觉变压器中有矩形图像数据集。我设置 image_size= (128, 256) 但补丁大小可能是多少？</title>
      <link>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77788451/i-have-rectangular-image-dataset-in-vision-transformers-i-set-image-size-128</guid>
      <pubDate>Tue, 09 Jan 2024 16:55:52 GMT</pubDate>
    </item>
    <item>
      <title>SHAP 解释器获取错误的数据类型[关闭]</title>
      <link>https://stackoverflow.com/questions/77785286/shap-explainer-getting-wrong-datatype</link>
      <description><![CDATA[这是我的代码。我正在尝试获取 X 射线图像的 SHAP 值。
model.eval()

＃ 转型
def preprocess_image(image_path):
    图像 = Image.open(image_path).convert(&#39;RGB&#39;)
    变换 = 变换.Compose([
        变换.调整大小((224, 224)),
        变换.ToTensor(),
        变换.Normalize(平均值=[0.485,0.456,0.406],std=[0.229,0.224,0.225]),])
    input_image = 变换（图像）.unsqueeze（0）
    返回输入图像

image_path = &#39;C.jpg&#39;
输入图像 = 预处理图像（图像路径）

masker = shap.maskers.Image(“inpaint_telea”, input_image.size())

解释器= shap.Explainer（模型，掩码器，output_names = [“A”，“B”，“C”]）

shap_values = 解释器(input_image)

shap.image_plot(shap_values, input_image.numpy())

当我运行此命令时，解释器获取错误的数据类型，并且出现此错误：
 *（张量输入、张量权重、张量偏差、整数步幅元组、整数填充元组、整数膨胀元组、整数组）
      不匹配，因为某些参数具有无效类型： (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple (int, int)!, int)
 *（张量输入、张量权重、张量偏差、整数步幅元组、str 填充、整数膨胀元组、整数组）
      不匹配，因为某些参数具有无效类型： (!numpy.ndarray!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple (int, int)!, int)

上线：
shap_values = 解释器(input_image)

我想获取图像 C.jpg 的 SHAP 值]]></description>
      <guid>https://stackoverflow.com/questions/77785286/shap-explainer-getting-wrong-datatype</guid>
      <pubDate>Tue, 09 Jan 2024 08:26:58 GMT</pubDate>
    </item>
    <item>
      <title>分割模型推理延迟问题</title>
      <link>https://stackoverflow.com/questions/77678168/segmentation-model-inference-latency-issue</link>
      <description><![CDATA[我使用了 pyannote 的开源分割模型和 Diart diarization 的说话者二值化存储库，使用 diart==0.5.1，
在 diart/blocks/segmentation.py 中，我进行了以下更改::
 与 torch.no_grad()：
        wave=rearrange(self.formatter.cast(waveform),“批量采样通道-&gt;批量通道采样”)
        # 波火炬.Tensor (1, 1, 80000)
        打印（wave.get_device（））
        开始 = 时间.time()
        输出 = self.model(wave.to(self.device)).cpu()
        停止=时间.time()
        print(&#39;分段时间:&#39;)
        打印（停止-开始）
        # 输出：torch.Tensor (1, 293, 3)
    返回 self.formatter.restore_type(输出)

在输出中，seg时间：0.4s
但是如果我尝试在 diart 存储库之外进行推断（在独立的存储库中）：
defegmentation_model(self,batch:np.ndarray) -&gt;; np.ndarray：
    块 = torch.tensor(batch)
    print(chunks.get_device()) # -1

    使用 torch.no_grad()：
        尝试：
            打印（块.形状）
            输出 = self.model(chunks.to(self.device)).cpu()
        除了 RuntimeError 作为例外：
            如果 is_oom_error（异常）：
                引发内存错误（
                    f&quot;batch_size ({self.batch_size: d}) 可能太大。 ”
                    f“尝试使用较小的值，直到内存错误消失。”
                ）
            别的：
                引发异常

    返回输出.numpy()

此处分段时间：10s
资源、输入格式、形状、类型一切都是相同的
为什么延迟不同？
期望延迟相同]]></description>
      <guid>https://stackoverflow.com/questions/77678168/segmentation-model-inference-latency-issue</guid>
      <pubDate>Mon, 18 Dec 2023 09:38:17 GMT</pubDate>
    </item>
    <item>
      <title>在 Python 中绘制 LSTM 模型的 SHAP 值</title>
      <link>https://stackoverflow.com/questions/77536125/plot-the-shap-values-for-lstm-model-in-python</link>
      <description><![CDATA[我有以下正在运行的代码。
将 numpy 导入为 np
导入形状
从张量流导入keras

X = np.array([[(1,2,3,3,1),(3,2,1,3,2),(3,2,2,3,3),(2,2,1 ,1,2),(2,1,1,1,1)],
              [(4,5,6,4,4),(5,6,4,3,2),(5,5,6,1,3),(3,3,3,2,2),( 2,3,3,2,1)],
              [(7,8,9,4,7),(7,7,6,7,8),(5,8,7,8,8),(6,7,6,7,8),( 5,7,6,6,6)],
              [(7,8,9,8,6),(6,6,7,8,6),(8,7,8,8,8),(8,6,7,8,7),( 8,6,7,8,8)],
              [(4,5,6,5,5),(5,5,5,6,4),(6,5,5,5,6),(4,4,3,3,3),( 5,5,4,4,5)],
              [(4,5,6,5,5),(5,5,5,6,4),(6,5,5,5,6),(4,4,3,3,3),( 5,5,4,4,5)],
              [(1,2,3,3,1),(3,2,1,3,2),(3,2,2,3,3),(2,2,1,1,2),( 2,1,1,1,1)]])
y = np.array([0, 1, 2, 2, 1, 1, 0])

# 使用正确的输入形状更新模型
模型 = keras.Sequential([
    keras.layers.LSTM(128, return_sequences=True, input_shape=(5, 5)), # 带有返回序列的 LSTM 层
    keras.layers.LSTM(128, return_sequences=False), # 另一个 LSTM 层
    keras.layers.Flatten(),
    keras.layers.Dense(128, 激活=&#39;relu&#39;),
    keras.layers.Dense(3,activation=&#39;softmax&#39;) # 3个输出类
]）
model.compile(optimizer=&#39;adam&#39;,loss=&#39;sparse_categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

# 训练模型
model.fit(X, y, epochs=10)

# 将 GradientExplainer 与模型本身一起使用
解释器 = shap.GradientExplainer(模型, X)
shap_values = 解释器.shap_values(X)
打印（形状值）

我想显示一个漂亮的 SHAP 值图。
我尝试了以下代码行
shap.summary_plot(shap_values, X, feature_names=[&#39;特征 1&#39;, &#39;特征 2&#39;, &#39;特征 3&#39;, &#39;特征 4&#39;, &#39;特征 5&#39;]) 
但不工作]]></description>
      <guid>https://stackoverflow.com/questions/77536125/plot-the-shap-values-for-lstm-model-in-python</guid>
      <pubDate>Thu, 23 Nov 2023 10:27:08 GMT</pubDate>
    </item>
    </channel>
</rss>