<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 03 Jan 2024 01:00:47 GMT</lastBuildDate>
    <item>
      <title>使用 Numpy Randn 将高斯噪声添加到训练数据中</title>
      <link>https://stackoverflow.com/questions/77749174/adding-gaussian-noise-to-your-training-data-with-numpy-randn</link>
      <description><![CDATA[我正在 Tensorflow 上训练一个模型，并希望使用随机噪声作为数据增强的一种方式，以增加有限的样本量，并可能进行正则化。 X_train 是我的训练数据，形状为（sample_size，2D 数组）
噪声 = np.random.randn(x_train.shape[0], x_train.shape[1], x_train.shape[2])
x_train += 噪声

与数据幅度相比，这引入了太多的噪声，因为范围是 +-1，均值为零（自然），这与我的数据大致相同。
我的问题是如何以更合理的方式添加噪声（我应该除以一个数量级并添加 f.e.），以及添加高斯噪声实际上是否可以产生更好的训练模型？
欢迎任何意见。]]></description>
      <guid>https://stackoverflow.com/questions/77749174/adding-gaussian-noise-to-your-training-data-with-numpy-randn</guid>
      <pubDate>Wed, 03 Jan 2024 00:22:38 GMT</pubDate>
    </item>
    <item>
      <title>大（O）沙箱和机器学习算法</title>
      <link>https://stackoverflow.com/questions/77749084/big-o-of-the-sandbox-and-machine-learning-algorithm</link>
      <description><![CDATA[我想对 Cuckoo 沙箱的计算进行比较，并希望将其与一些机器和深度学习算法进行比较：

逻辑回归
k-最近邻居
支持向量机
人工神经网络
长短期记忆

那么布谷鸟沙箱或一般沙箱的 Big(O) 以及上述 ML 算法的 Big(O) 是多少]]></description>
      <guid>https://stackoverflow.com/questions/77749084/big-o-of-the-sandbox-and-machine-learning-algorithm</guid>
      <pubDate>Tue, 02 Jan 2024 23:48:41 GMT</pubDate>
    </item>
    <item>
      <title>将多变量时间序列数据集转换为单变量时间序列数据集</title>
      <link>https://stackoverflow.com/questions/77748902/turning-multivariate-time-series-dataset-into-univariate</link>
      <description><![CDATA[我正在使用深度学习算法进行单变量时间序列预测，因此我需要拥有大量数据集。这是因为我打算研究基于物联网的能源消耗时间序列数据。我找到了一些数据集，但它们的大小仍然不足以解决我的问题。
但是，我确实有一个可用的多元时间序列数据集，该数据集也相当大。为了训练目的将多变量数据集转换为单变量数据集是否可以接受？如果是这样，我打算仅保留目标列并删除所有其他列。这种方法正确吗，或者有替代的想法吗？”]]></description>
      <guid>https://stackoverflow.com/questions/77748902/turning-multivariate-time-series-dataset-into-univariate</guid>
      <pubDate>Tue, 02 Jan 2024 22:37:33 GMT</pubDate>
    </item>
    <item>
      <title>如何使用GPT-2计算单词和句子嵌入？</title>
      <link>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</link>
      <description><![CDATA[我正在开发一个使用 GPT-2（特别是 GPT2Model 类）计算单词和句子嵌入的程序。对于词嵌入，我在转发 input_ids 后提取最后一个隐藏状态 outputs[0]，其形状为 batch size x seq len ，到 GPT2Model 类。至于句子嵌入，我在序列末尾提取单词的隐藏状态。这是我尝试过的代码：
从变压器导入 GPT2Tokenizer、GPT2Model
进口火炬

tokenizer = GPT2Tokenizer.from_pretrained(&#39;gpt2&#39;)
模型 = GPT2Model.from_pretrained(&#39;gpt2&#39;)
Captions = [“示例标题”、“示例鸟”、“鸟是黄色的，有红色翅膀”、“嗨”、“非常好”]

encoded_captions = [tokenizer.encode(caption) 用于字幕中的字幕]

# 用 0 将序列填充到相同的长度
max_len = max(len(seq) 用于编码字幕中的 seq)
padded_captions = [seq + [0] * (max_len - len(seq)) 对于encoded_captions中的seq]

# 转换为批量大小为 5 的 PyTorch 张量
input_ids = torch.tensor(padded_captions)

输出=模型(input_ids)
word_embedding = 输出[0].连续()
句子嵌入 = word_embedding[ :, -1, : ].contigious()


我不确定我对单词和句子嵌入的计算是否正确，任何人都可以帮我确认这一点，感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/77748737/how-to-calculate-word-and-sentence-embedding-using-gpt-2</guid>
      <pubDate>Tue, 02 Jan 2024 21:55:52 GMT</pubDate>
    </item>
    <item>
      <title>sklearn 线性回归 特征名称应与拟合期间传递的特征名称相匹配</title>
      <link>https://stackoverflow.com/questions/77748547/sklearn-linear-regression-the-feature-names-should-match-those-that-were-passed</link>
      <description><![CDATA[我尝试使用 sklearn 线性回归创建模型后计算 r 平方值。
我只是简单

导入 csv 数据集
过滤感兴趣的列
在训练和测试中拆分数据集
创建模型
对测试进行预测
计算 r 平方以了解模型与测试数据集的拟合程度

数据集取自 https://www.kaggle.com/datasets/jeremylarcher/american-house-prices-and-demographics-of-top-cities
代码如下
&#39;&#39;&#39;让我们验证一下价格和浴室床位数量之间是否存在相关性&#39;&#39;&#39;

将 pandas 导入为 pd
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression

df = pd.read_csv(&#39;数据/American_Housing_Data_20231209.csv&#39;)

df_interesting_columns = df[[&#39;床&#39;, &#39;浴室&#39;, &#39;价格&#39;]]

Independent_variables = df_interesting_columns[[&#39;床&#39;, &#39;浴室&#39;]]
dependent_variable = df_interesting_columns[[&#39;价格&#39;]]

X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, test_size=0.2)

模型=线性回归()
model.fit(X_train, y_train)

预测 = model.predict(X_test)

print(model.score(y_test, 预测))

但我收到错误
ValueError：特征名称应与拟合期间传递的名称相匹配。
在拟合时看不到的特征名称：

价格
在适合时看到的功能名称，但现在丢失了：
浴室
床位

有人可以帮我理解我做错了什么吗？
谢谢，我希望能正确解释]]></description>
      <guid>https://stackoverflow.com/questions/77748547/sklearn-linear-regression-the-feature-names-should-match-those-that-were-passed</guid>
      <pubDate>Tue, 02 Jan 2024 21:01:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的 clean-python 中的 AI 没有按预期学习？</title>
      <link>https://stackoverflow.com/questions/77748132/why-is-my-ai-in-neat-python-not-learning-as-expected</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77748132/why-is-my-ai-in-neat-python-not-learning-as-expected</guid>
      <pubDate>Tue, 02 Jan 2024 19:21:07 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv8多类实例分割</title>
      <link>https://stackoverflow.com/questions/77747887/yolov8-instance-segmentation-of-multiple-classes</link>
      <description><![CDATA[我正在寻求有关 YOLOv8 中多类实例分割的帮助。我已经用 Detectron2 完成了这个任务，想要进行比较。在 Detectron2 中，我需要获取包含图像、蒙版和注释文本文件的文件夹，我在其中指定了边界框和相应的标签（鸟类物种）。但也许这对于 YOLOv8 是不可能的？ Detectron2 的注释如下所示：
图像文件名：“img2.png” # img2.png 是包含形状的二值掩模图像
图像尺寸（X x Y）：824 x 824
具有基本事实的对象：3

# 对象 1 的详细信息
对象1的原始标签：“物种1”
对象 1 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(0, 733) - (9, 751)
对象 1 的像素蒙版：“mask2.png”

# 对象 2 的详细信息
对象2的原始标签：“物种2”
对象 2 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(93, 664) - (143, 684)
对象 2 的像素蒙版：“mask2.png”

# 对象 3 的详细信息
对象3的原始标签：“物种1”
对象 3 的边界框：(Xmin, Ymin) - (Xmax, Ymax)：(39, 621) - (60, 667)
对象 3 的像素蒙版：“mask2.png”

实际上 YOLOv8 实例分割的所有教程都集中在一个类上。此外，他们经常专注于使用 Roboflow 进行标签，这对我来说并不有趣，因为我从已有的 ESRI shapefile 转换标签。我使用来自无人机图像的 shapefile 和鸟类光栅，将来自 shapefile 的二进制蒙版的标签转换为标签。我找到了一个教程，它实际上专注于创建标签没有口罩，但仍然只有一节课。使用它，我创建了另一个文件夹“标签”，在其中创建包含对象坐标的文本文件。利用这个，我可以成功地使用一个分割鸟类的模型。 YOLOv8 的标签现在看起来像这样：
&lt;预&gt;&lt;代码&gt;0 0.16019417475728157 0.8058252427184466 0.15898058252427186 0.8070388349514563 0.1529126213592233 0.8070388349514563 ... 0.1650485436893204 0.8070388349514563 0.1638349514563107 0.8070388349514563 0.16262135922330098 0.8058252427184466

0 0.055825242718446605 0.7536407766990292 0.055825242718446605 0.7560679611650486 0.05461165048543689 0.7572815533980582 ... 0 .06067961165048544 0.7536407766990292
0 0.09951456310679611 0.6747572815533981 0.09951456310679611 0.6759708737864077

0.09587378640776699 0.6796116504854369 0.09587378640776699 0.6808252427184466 0.09344660194174757 0.683252427184466 ... 0.1031 5533980582524 0.6771844660194175 0.10194174757281553 0.6759708737864077 0.10072815533980582 0.6759708737864077

但我因此想要更多。我知道如何在配置文件中指定类的数量及其名称。但是，我不确定如何在标签文本文件中指定类。从我在网上找到的内容来看，它们只包含像素坐标。另外，如果我已经有了二进制掩码和边界框注释，我想知道是否有更有效的方法来为 30,000 多个图像创建标签。作为参考，每张图像通常有多种鸟类，并且图像中也可能有不同的鸟类种类。
如何使用YOLOv8实现多类实例分割？]]></description>
      <guid>https://stackoverflow.com/questions/77747887/yolov8-instance-segmentation-of-multiple-classes</guid>
      <pubDate>Tue, 02 Jan 2024 18:23:27 GMT</pubDate>
    </item>
    <item>
      <title>将 pdf 转换为图像进行处理时出现错误索引超出范围</title>
      <link>https://stackoverflow.com/questions/77747660/error-index-out-of-range-converting-pdf-to-image-for-processing-it</link>
      <description><![CDATA[将结果转换为可下标时遇到问题？
将 PDF 转换为图像时出错：“结果”对象不可下标。
我还尝试了不同的库，例如 PDF2IMG，但它在处理过程中陷入困境，您建议对此进行最佳编辑吗？我正在尝试将 pdf 转换为图像，然后对其进行处理并获取基于聊天的查询答案类型。
错误：
&lt;前&gt;&lt;代码&gt;回溯：
文件“C:\Users\arbaz\Documents\MultiLangModel\venv\Lib\site-packages\streamlit\runtime\scriptrunner\script_runner.py”，第 534 行，位于 _run_script
    exec（代码，模块.__dict__）
文件“C:\Users\arbaz\Documents\MultiLangModel\app2.py”，第 54 行，在  中
    响应2 = get_gemini_response_from_pdf(input_prompt2, pdf_images, input2)^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^
文件“C:\Users\arbaz\Documents\MultiLangModel\app2.py”，第 14 行，位于 get_gemini_response_from_pdf
    response2 = model2.generate_content([input_prompt, pdf_images[0], input2])~~~~~~~~~~

代码：
from dotenv import load_dotenv
将streamlit导入为st
从 PIL 导入图像
将 google.generativeai 导入为 genai
导入convertapi
导入操作系统
导入io
导入临时文件

Convertapi.api_secret = &#39;密钥&#39;
genai.configure(api_key=&#39;秘密密钥&#39;)
def get_gemini_response_from_pdf(input_prompt, pdf_images, input2):
    model2 = genai.GenerativeModel(&#39;gemini-pro-version&#39;)
    响应2 = model2.generate_content([input_prompt, pdf_images[0], input2])
    返回response2.text

def Convert_pdf_to_images(上传文件):
    尝试：
        temp_file = f“tmp{uploaded_file.name}”
        以 open(temp_file, &#39;wb&#39;) 作为文件：
            文件.write(uploaded_file.read())

        结果 = Convertapi.convert(&#39;jpg&#39;, {&#39;文件&#39;: temp_file}, from_format=&#39;pdf&#39;)
        if result[&#39;response&#39;][&#39;status&#39;] == &#39;Ok&#39;:
            返回结果[&#39;文件&#39;]
        别的：
            st.write(f&quot;转换失败: {result[&#39;response&#39;][&#39;message&#39;]}&quot;)
            返回 []
    除了异常 e：
        st.write(f“将 PDF 转换为图像时出错：{e}”)
        返回 []

st.set_page_config(page_title=&quot;使用人工智能的文档阅读器&quot;)
st.header(“这是我使用人工智能的文档阅读器”)

input_prompt2 = “””
               您是理解护照、银行对账单和资产金融投资等文件的专家。
               您将收到护照、银行对账单、发票以及资产和金融投资的输入 pdf 文件。
               您必须根据输入图像回答问题
               ”“”
input2 = st.text_input(&quot;PDF文档输入提示：&quot;, key=&quot;input2&quot;)
uploaded_file2 = st.file_uploader(&quot;上传 PDF 文件&quot;, type=&quot;pdf&quot;)
pdf_图像 = []

如果 uploaded_file2 不是 None：
    pdf_images = 转换 pdf_to_images(uploaded_file2)
    对于 pdf_images 中的 img_data：
        img_bytes = img_data[&#39;数据&#39;]
        图像 = Image.open(io.BytesIO(img_bytes))
        st.image(图像, 标题=“转换后的图像”, use_column_width=True)
    
    Submit_pdf = st.button(“生成 Pdf 响应”)
    如果提交_pdf：
        响应2 = get_gemini_response_from_pdf(input_prompt2, pdf_images, input2)
        st.subheader(“响应是”)
        st.write(响应2)

我正在尝试将 pdf 转换为图像，然后对其进行处理并获取基于聊天的查询答案。
尝试了多个库，例如 pdf2img 和其他逻辑]]></description>
      <guid>https://stackoverflow.com/questions/77747660/error-index-out-of-range-converting-pdf-to-image-for-processing-it</guid>
      <pubDate>Tue, 02 Jan 2024 17:28:36 GMT</pubDate>
    </item>
    <item>
      <title>“在微控制器上部署边缘脉冲训练车辆检测和颜色分类模型”</title>
      <link>https://stackoverflow.com/questions/77747578/deploying-edge-impulse-trained-vehicle-detection-and-color-classification-model</link>
      <description><![CDATA[我们目前正在启动一个项目，重点是使用 Edge Impulse 进行车辆检测和颜色分类。我们的目标是在 Edge Impulse 平台中训练我们的图像数据集，然后将模型部署到微控制器上。我们正在寻找的微控制器应该既与 Edge Impulse 兼容，又具有成本效益，能够实现数据的实时分类。
我们主要关注的是了解在微控制器上部署 Edge Impulse 训练模型的可行性和兼容性。我们的最终目标是无缝集成模型，使微控制器能够准确地对实时数据进行分类。
任何有关适合此目的的经济高效的微控制器的指导或建议都非常有价值。
如果在微控制器上部署被证明是不切实际的，我们将不胜感激有关符合我们目标的替代方法的建议。
提前致谢]]></description>
      <guid>https://stackoverflow.com/questions/77747578/deploying-edge-impulse-trained-vehicle-detection-and-color-classification-model</guid>
      <pubDate>Tue, 02 Jan 2024 17:09:06 GMT</pubDate>
    </item>
    <item>
      <title>图像处理——如何检测此类图像[关闭]</title>
      <link>https://stackoverflow.com/questions/77747526/image-processing-how-to-detect-this-type-of-images</link>
      <description><![CDATA[在此处输入图片描述
我有一个护照尺寸图像的数据集，必须对其进行验证。但我无法了解如何检测这种类型的图像，因为这对我来说是无效的。
图像应完全拟合才能认为有效，否则无效。
请参考附件中的图片并帮助我。
我已经尝试了各种方法，但仍然无法获得所需的输出。请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/77747526/image-processing-how-to-detect-this-type-of-images</guid>
      <pubDate>Tue, 02 Jan 2024 17:00:35 GMT</pubDate>
    </item>
    <item>
      <title>TimeoutError：处理报价和初始化工作人员尚未在 10.0 秒内完成[关闭]</title>
      <link>https://stackoverflow.com/questions/77747419/timeouterror-processing-offer-and-initializing-the-worker-has-not-finished-in-1</link>
      <description><![CDATA[(https://i.stack.imgur.com/OGVax.png
我在渲染上部署了我的机器学习 Web 应用程序，它引发了这个问题。
然而它在本地主机上工作得很好
有什么解决办法吗？
我尝试查找各种​​网站，但找不到出路。请帮忙。]]></description>
      <guid>https://stackoverflow.com/questions/77747419/timeouterror-processing-offer-and-initializing-the-worker-has-not-finished-in-1</guid>
      <pubDate>Tue, 02 Jan 2024 16:36:18 GMT</pubDate>
    </item>
    <item>
      <title>我需要帮助提高我的张量流模型的准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/77734479/i-needed-help-improveing-the-accuracy-of-my-tensorflow-model</link>
      <description><![CDATA[所以我编写了一组基本的张量流代码，测试集准确率达到 97%，然后使用下面的代码帮助我编写一些数字，保存屏幕并打开图像，然后将其转换为 28x28 图像，然后将其输入到模型中，但由于某种原因，模型总是预测 4。
如果您想查看完整代码，请参阅存储库链接：https://github.com/Deadskullcandy/ Mnist_Model
导入 pygame


# 初始化 Pygame
pygame.init()

# 设置屏幕
宽度, 高度 = 280, 280
屏幕 = pygame.display.set_mode((宽度，高度))
pygame.display.set_caption(&#39;绘制并预测&#39;)

# 设置颜色
白色 = (255, 255, 255)

# 设置绘图参数
绘图 = 假

# 主循环
运行=真
在跑步的时候：
    对于 pygame.event.get() 中的事件：
        如果 event.type == pygame.QUIT：
            运行=假
        
        elif event.type == pygame.MOUSEBUTTONDOWN：
            绘图=真实
        
        elif event.type == pygame.MOUSEBUTTONUP：
            绘图 = 假
        
        elif event.type == pygame.MOUSEMOTION 和绘图：
            mouse_pos = pygame.mouse.get_pos()
            pygame.draw.circle（屏幕，白色，mouse_pos，5）
        
        elif event.type == pygame.KEYDOWN：
            如果 event.key == pygame.K_SPACE：
                pygame.image.save（屏幕，&#39;temp.png&#39;）
                图像 = pygame.image.load(&#39;temp.png&#39;).convert()
                图像 = pygame.transform.scale(图像,(28,28))
                图像 = pygame.transform.flip(图像, True, False)
                image_array = pygame.surfarray.array2d(图像)
                image_array = np.resize(image_array,(1,28,28))
                预测=probability_model.predict(image_array)
                打印（np.argmax（预测[0]））

            如果 event.key == pygame.K_r:
                screen.fill(&#39;黑色&#39;)
                
    pygame.display.flip()

pygame.quit()

我不知道如何修复它或模型发生了什么]]></description>
      <guid>https://stackoverflow.com/questions/77734479/i-needed-help-improveing-the-accuracy-of-my-tensorflow-model</guid>
      <pubDate>Sat, 30 Dec 2023 00:28:56 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：无法序列化 <class 'ellipsis'> 类型的对象省略号</title>
      <link>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</link>
      <description><![CDATA[我正在通过《Python 深度学习》一书学习 Tensorflow / Keras。第 8 章解释了如何使用预训练模型。但是，提供的代码无法运行，并且在执行 model.fit 时收到错误消息：
类型错误：无法序列化  类型的对象省略号。
要可序列化，类必须实现“get_config()”方法。

我使用的是 Tensorflow 版本 2.15.0
该程序使用来自 kaggle 的 dogs-vs-cats 数据集。它创建一个较小的子集并创建训练、验证和测试数据集。这一切都有效，就像本书中其他一些示例所使用的那样。然后，它使用预训练的 VGG16 模型并训练与其连接的密集层
这是我的代码：
导入tensorflow为tf
从张量流导入keras

#使用kaggle API令牌上传kaggle.json文件
从 google.colab 导入文件
文件.上传()

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle
!chmod 600 ~/.kaggle/kaggle.json

!unzip -qq 狗大战猫.zip
!unzip -qq火车.zip

导入操作系统、shutil、pathlib
Original_dir = pathlib.Path(“火车”)
new_base_dir = pathlib.Path(“狗与猫_小”)

def make_subset(子集名称, 开始索引, 结束索引):
    对于（“猫”，“狗”）中的类别：
        dir = new_base_dir / 子集名称 / 类别
        os.makedirs（目录）
        fnames = [f&quot;{category}.{i}.jpg&quot;;对于范围内的 i(start_index, end_index)]
        对于 fnames 中的 fname：
            Shutil.copyfile(src=original_dir / fname, dst=dir / fname)

make_subset(“火车”, start_index=0, end_index=1000)
make_subset(“验证”, start_index=1000, end_index=1500)
make_subset(“测试”, start_index=1500, end_index=2500)

导入路径库

base_dir = pathlib.Path(“狗与猫_小”)

train_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“火车”，
    图像大小=(180, 180),
    批量大小=32
）

validation_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“验证”，
    图像大小=(180, 180),
    批量大小=32
）

test_dataset = keras.utils.image_dataset_from_directory(
    base_dir /“测试”，
    图像大小=(180, 180),
    批量大小=32
）

#创建神经网络
conv_base = keras.applications.vgg16.VGG16(
  权重=“imagenet”，
  include_top=False
）
conv_base.trainable = False

data_augmentation = keras.Sequential(
    [
      keras.layers.RandomFlip(“水平”),
      keras.layers.RandomRotation(0.1),
      keras.layers.RandomZoom(0.2)
    ]
）

输入 = keras.Input(形状=(180, 180, 3))
x = 数据增强（输入）
x = keras.applications.vgg16.preprocess_input(x)
x = 转换基数(x)
x = keras.layers.Flatten()(x)
x = keras.layers.Dense(256)(x)
x = keras.layers.Dropout(0.5)(x)
输出 = keras.layers.Dense(1, 激活 =“sigmoid”)(x)

模型= keras.Model（输入，输出）

模型.编译(
    损失=“binary_crossentropy”，
    优化器=“rmsprop”，
    指标=[“准确度”]
）

回调 = [
    keras.callbacks.ModelCheckpoint(
        文件路径=“features_extraction_with_data_augmentation.keras”，
        save_best_only=真，
        监视器=“val_loss”
    ）
]

History = model.fit( # 这里抛出错误
    训练数据集，
    纪元=50，
    验证数据=验证数据集，
    回调=回调
）
]]></description>
      <guid>https://stackoverflow.com/questions/77716307/typeerror-cannot-serialize-object-ellipsis-of-type-class-ellipsis</guid>
      <pubDate>Tue, 26 Dec 2023 08:20:52 GMT</pubDate>
    </item>
    <item>
      <title>预测后如何取消数据缩放？</title>
      <link>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</link>
      <description><![CDATA[我有一个具有 2 个特征（价格和数量）的数据集1 个预测变量（价格），并使用 LTSM 模型根据前一组价格预测下一个价格。
首先我缩放数据集：
#缩放数据
缩放器 = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(数据集)

最后我想取消缩放：
#获取模型预测价格值
预测 = model.predict(x_test)
预测=scaler.inverse_transform(预测)

但这不起作用，我收到此错误：
ValueError：形状为 (400,1) 的不可广播输出操作数与广播形状 (400,2) 不匹配
]]></description>
      <guid>https://stackoverflow.com/questions/63380766/how-to-unscale-data-after-predictions</guid>
      <pubDate>Wed, 12 Aug 2020 16:20:50 GMT</pubDate>
    </item>
    <item>
      <title>如何使用管道中的最佳估计器来预测测试集？</title>
      <link>https://stackoverflow.com/questions/56615768/how-to-use-best-estimator-from-pipeline-to-predict-test-set</link>
      <description><![CDATA[我使用 XGBoost 开发了一个管道，它为我返回了最佳估计器。
但是，尝试使用这个最佳估计器来预测我的测试集时，会出现以下错误：“ValueError：仅 pandas DataFrames 支持使用字符串指定列”。
下面是我使用的管道的代码：
注意：ct 只是使用 SimpleImputer 和 OneHotEncoder 用于分类列的 ColumnTransformer 和 SimpleImputer和用于数字列的 StandardScaler
ml_step_1 = (&#39;transform&#39;, ct)
ml_step_2 = (&#39;PCA&#39;, PCA())
xgb = (&#39;xgb&#39;, XGBRegressor())
xgb_pipe = 管道([ml_step_1, ml_step_2, xgb])
xgb = RandomizedSearchCV(xgb_pipe, xgb_param_grid, cv=kf, 评分=&#39;neg_mean_absolute_error&#39;);
xgb.fit(train_full_features, train_full_target);

运行以下管道，这是我得到的最佳估计器：
最佳 XGBoost 参数：{&#39;xgb__silent&#39;：True，&#39;xgb__n_estimators&#39;：1000，&#39;xgb__max_深度&#39;：4，&#39;xgb__learning_rate&#39;：0.099999999999999999，&#39;transform__num__imputer__strategy&#39;：&#39;中值&#39;，&#39;transform__cat__imputer__strategy&#39;：&#39;most_frequent&#39;，&#39;pca__n_components&#39;：68}

现在，我调用了这个最佳估计器并执行了以下操作：
test_full_imp = pd.DataFrame(xgb.best_estimator_.named_steps[&#39;transform&#39;].transform(test_full))
test_final = xgb.best_estimator_.named_steps[&#39;pca&#39;].transform(test_full_imp)
预测 = xgb.best_estimator_.predict(test_final)
]]></description>
      <guid>https://stackoverflow.com/questions/56615768/how-to-use-best-estimator-from-pipeline-to-predict-test-set</guid>
      <pubDate>Sun, 16 Jun 2019 03:07:00 GMT</pubDate>
    </item>
    </channel>
</rss>