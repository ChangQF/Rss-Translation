<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Mon, 18 Mar 2024 12:23:59 GMT</lastBuildDate>
    <item>
      <title>机器学习过程中 TPU 到底用在什么地方？</title>
      <link>https://stackoverflow.com/questions/78180134/where-exactly-are-tpus-used-during-machine-learning</link>
      <description><![CDATA[我想知道当前技术水平中机器学习 TPU 期间通常使用哪些算法步骤。特别是，我很感兴趣它们是否用于推理、反向传播和/或卷积。
我知道脉动阵列的工作原理以及 TPU 的基本原理，并且它们可以比 CPU/GPU 更快地执行非稀疏矩阵乘法，这是有道理的。但例如对于卷积，相乘矩阵通常非常稀疏。在那里使用 TPU 仍然有意义吗？
如果有任何详细的解释或此类解释的链接，我将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78180134/where-exactly-are-tpus-used-during-machine-learning</guid>
      <pubDate>Mon, 18 Mar 2024 12:16:32 GMT</pubDate>
    </item>
    <item>
      <title>如何在不使用 LLM 的情况下将随机文件（具有不同名称）分组到适当的文件夹中？</title>
      <link>https://stackoverflow.com/questions/78179964/how-can-i-group-random-files-with-different-names-into-appropriate-folders-wit</link>
      <description><![CDATA[我想构建一个产品，可以根据文件名自动组织文件夹/子文件夹和文件，并根据文件名的相似性将它们分组。我知道这个问题可以通过 LLM（特别是 ChatGPT4）来解决，但这会带来一些问题。 1. 隐私，不是每个人都愿意将自己的文件名发送到这个系统。 2. 输入长度，OpenAI 上下文窗口有一定的长度限制，因此如果您有一个包含 1000 个或更多文件的文件夹，它将无法处理此长度。 3. 令牌成本，即使您可以处理 1000 个或更多文件，这也会变得非常昂贵。出于这个原因，我正在寻找替代方案。 （本地法学硕士可以解决隐私问题，但无法解决问题 2）。
我确信存在机器学习技术，可以根据单词背后含义的相似性将单词聚集在一起，但我还没有找到一个可以立即满足我需要的库。&lt; /p&gt;
这是我想要实现的目标的示例：
输入（文件名）：

历史家庭作业.pdf
报告.docx
山.png
历史测试.docx
天气数据.csv
地理笔记.docx
艺术品1.png
artwork2.png

输出（建议的文件夹名称）：

历史
地理
艺术
其他

请注意，输出文件夹不是预先确定的组。例如，输入可能是其他 10 个随机文件，您应该根据输入建议新名称的算法。
我找到的最接近的解决方案是在 python 中使用 WordNet 并查找上位词来对单词进行分组。问题是它不是很准确。]]></description>
      <guid>https://stackoverflow.com/questions/78179964/how-can-i-group-random-files-with-different-names-into-appropriate-folders-wit</guid>
      <pubDate>Mon, 18 Mar 2024 11:46:56 GMT</pubDate>
    </item>
    <item>
      <title>有没有办法在没有 Nvidia GPU 的情况下训练我的模型？</title>
      <link>https://stackoverflow.com/questions/78179649/is-there-a-way-to-train-my-model-without-an-nvidia-gpu</link>
      <description><![CDATA[所以我的实习项目涉及在我公司的代码库上训练/微调模型。因此，他们希望我不要使用任何云解决方案，以避免泄露敏感数据。
但是，我公司的笔记本电脑并不是最强大的：
CPU：第 11 代 Intel(R) Core(TM) i7-1165G7 @ 2.80GHz 2.80 GHz
内存：16.0 GB
GPU：英特尔 Iris Xe 显卡
所以我不能使用cuda进行训练。据我了解，CPU 上的训练时间大约是 GPU 上的 30-35 倍，这将是一个很大的劣势。
除了使用云之外，我的另一个选择是向公司请求一台更好的笔记本电脑，但该笔记本电脑也具有相同的 GPU。该笔记本电脑的规格：
CPU：第12代Intel(R) Core(TM) i7-12800H 2.40GHz
内存：32.0 GB
GPU：英特尔 Iris Xe 显卡
我想使用的模型是 Microsoft 的 CodeReviewer (https://huggingface.co/microsoft/codereviewer），我想在我公司存储库的 PR 上对其进行微调，并利用模型的“审核评论生成”任务。
我将用于微调的数据集尚未准备好，因此不确定文件有多大，但 jsonl 中至少有 500-1000 行数据，所以数量不是很大，我猜大约 20 -30MB。
我尝试在 Pytorch 中使用 Huggingface 的转换器和加速库，并在一些示例数据集上训练模型以进行测试。该数据集约为 15-20MB（700 行），使用 Google Colab 的 T4 GPU 进行训练需要 4 分钟。如果我们将其乘以 30，则意味着 CPU 上的训练时间为 2 小时，这是相当多的时间。
所以我的问题是，是否可以在合理的时间内在我的笔记本电脑（或其他公司的笔记本电脑）上训练它，而无需花费很长时间，或者我唯一的解决方案是使用云解决方案？&lt; /p&gt;]]></description>
      <guid>https://stackoverflow.com/questions/78179649/is-there-a-way-to-train-my-model-without-an-nvidia-gpu</guid>
      <pubDate>Mon, 18 Mar 2024 10:50:55 GMT</pubDate>
    </item>
    <item>
      <title>将外生变量整合到分层时间序列 (HTS) 预测中：</title>
      <link>https://stackoverflow.com/questions/78179129/integrating-exogenous-variables-into-hierarchical-time-series-hts-forecasting</link>
      <description><![CDATA[我有销售数据，其中包括有关城市、商店、产品、假期和天气的信息。我需要使用分层时间序列 (HTS) 来预测产品级别的销售额。如何将外生变量纳入 HTS 模型？]]></description>
      <guid>https://stackoverflow.com/questions/78179129/integrating-exogenous-variables-into-hierarchical-time-series-hts-forecasting</guid>
      <pubDate>Mon, 18 Mar 2024 09:24:13 GMT</pubDate>
    </item>
    <item>
      <title>预测客户的下一个购买日</title>
      <link>https://stackoverflow.com/questions/78179087/predicting-customers-next-purchase-day</link>
      <description><![CDATA[我正在开发一个项目，需要预测客户的下一个购买日。我有一个数据集，其中包括客户购买历史记录、RFM（新近度、频率、货币）分数以及其他功能，例如：
最近三次购买之间的天数，
均值&amp;购买天数差异的标准差
您能否建议我可以用于此预测任务的最有效的模型或方法？我正在寻找一种可以利用这些功能以及数据的时间序列性质来提供准确预测的方法。
任何建议或见解将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78179087/predicting-customers-next-purchase-day</guid>
      <pubDate>Mon, 18 Mar 2024 09:17:12 GMT</pubDate>
    </item>
    <item>
      <title>具有一个标签的训练集，具有许多其他标签的测试集</title>
      <link>https://stackoverflow.com/questions/78179042/training-set-with-one-label-testing-set-with-many-other-labels</link>
      <description><![CDATA[我一直在从事一个机器学习项目，专注于心电图记录中的异常检测。目标是区分正常和异常记录，异常类别包括各种类型的异常情况。提供的数据集由标记为“正常”的训练集和标记为多个类别的测试集组成，包括“异常”、“噪声”和其他标签。
在这种情况下，最适合的机器学习方法是什么？会是有监督的机器学习吗？正常类和异常类都有标签数据，但是如何用一个标签来训练模型，而测试数据有很多其他标签。或者半监督将是更好的预测方法？
我确实想尝试半监督机器学习，但我还没有真正有机会学习它。所以这对我来说是一个挑战。]]></description>
      <guid>https://stackoverflow.com/questions/78179042/training-set-with-one-label-testing-set-with-many-other-labels</guid>
      <pubDate>Mon, 18 Mar 2024 09:09:04 GMT</pubDate>
    </item>
    <item>
      <title>是否有 xgb.XGBRegressor 的示例，其中回调=[early_stop], Early_stop=xgb.callback.EarlyStopping 用于 cross_val_predict？</title>
      <link>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</link>
      <description><![CDATA[在文档
XGBClassifier 有一个 EarlyStopping：
&lt;前&gt;&lt;代码&gt;```
es = xgboost.callback.EarlyStopping(
    轮数=2，
    min_delta=1e-3,
    save_best=真，
    最大化=假，
    data_name=“validation_0”，
    metric_name=“mlogloss”,
    ）
clf = xgboost.XGBClassifier(tree_method=“hist”, device=“cuda”, 回调=[es])

X, y = load_digits(return_X_y=True)
clf.fit(X, y, eval_set=[(X, y)])```

但是“validation_0”是如何实现的？引用 clf.fit 中的 eval_set 来让 EarlyStopping 指标进行评估？
我尝试将其应用到 XGBRegressor：
`将 xgboost 导入为 xgb
从 sklearn.model_selection 导入 cross_val_predict，KFold
将 pandas 导入为 pd
将 numpy 导入为 np

类 CustomEarlyStopping(xgb.callback.EarlyStopping):
    def __init__(self, rounds=2, min_delta=1e-3, save_best=True, maximise=False, data_name=“validation_0”, metric_name=“rmse”):
        super().__init__(rounds=rounds, min_delta=min_delta, save_best=save_best, maximise=maximize, data_name=data_name, metric_name=metric_name)
    
# 火车模型（10x10 倍 CV）
cvx = KFold(n_splits=10, shuffle=True, random_state=239)
es = 自定义早期停止()

模型= xgb.XGBRegressor（colsample_bytree = 0.3，learning_rate = 0.1，max_深度= 10，alpha = 10，n_estimators = 500，n_jobs = -1，
                     random_state=239，回调=[es]）
model.set_params(tree_method=&#39;approx&#39;, device=&#39;cpu&#39;)

cv_preds = []
对于范围 (0,10) 内的 i：
    cv_preds.append(cross_val_predict(模型, np.asarray(X_train), np.asarray(y_train), cv=cvx, method=&#39;predict&#39;, n_jobs=1, verbose=2))`

我把data_name=“validation_0”放在在 EarlyStopping __init__ 中，而不在每个 cv 折叠中命名测试集。
这段代码的行为有什么问题？谢谢。
XGBRegressor 的代码返回了此错误：
ValueError：必须至少有 1 个验证数据集才能提前停止。

应该发生的情况是 cv_preds 被 10 个预测 y 的 ndarray 填充。]]></description>
      <guid>https://stackoverflow.com/questions/78178902/is-there-example-of-xgb-xgbregressor-with-callbacks-early-stop-early-stop-xgb</guid>
      <pubDate>Mon, 18 Mar 2024 08:42:57 GMT</pubDate>
    </item>
    <item>
      <title>Python Flask 错误：导入“依赖项”时，引发了 ImportError</title>
      <link>https://stackoverflow.com/questions/78178785/python-flask-error-while-importing-dependencies-an-importerror-was-raised</link>
      <description><![CDATA[ 文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 1488 行，位于__称呼__
    返回 self.wsgi_app（环境，start_response）
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 1466 行，在 wsgi_app 中
    响应 = self.handle_exception(e)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask_cors\extension.py”，第 176 行，位于wrapped_function 中
    返回 cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 1463 行，在 wsgi_app 中
    响应 = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 872 行，在 full_dispatch_request 中
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask_cors\extension.py”，第 176 行，位于wrapped_function 中
    返回 cors_after_request(app.make_response(f(*args, **kwargs)))
                                                ^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 870 行，在 full_dispatch_request 中
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\flask\app.py”，第 855 行，dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args) # 类型：忽略[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  文件“C:\Users\Y.L.Deepak\OneDrive\Desktop\Twizer-main\app.py”，第 154 行，在标签中
    从 keras.models 导入 load_model
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\__init__.py”，第 3 行，在  中
    从 keras 导入 __internal__
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\__internal__\__init__.py”，第 3 行，在  中
    从 keras.__internal__ 导入后端
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\__internal__\backend\__init__.py”，第 3 行，在  中
    从 keras.src.backend 导入_initialize_variables 作为initialize_variables
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\src\__init__.py”，第 21 行，在  中
    从 keras.src 导入应用程序
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\src\applications\__init__.py”，第 18 行，在  中
    从 keras.src.applications.convnext 导入 ConvNeXtBase
  文件“C:\Users\Y.L.Deepak\AppData\Roaming\Python\Python311\site-packages\keras\src\applications\convnext.py”，第 26 行，在  中
    将tensorflow.compat.v2导入为tf
ModuleNotFoundError：没有名为“tensorflow.compat”的模块

我的前端应用程序正在显示，但在前端输入任何文本提示后，我遇到了这些错误有人可以帮助我吗！！！]]></description>
      <guid>https://stackoverflow.com/questions/78178785/python-flask-error-while-importing-dependencies-an-importerror-was-raised</guid>
      <pubDate>Mon, 18 Mar 2024 08:15:42 GMT</pubDate>
    </item>
    <item>
      <title>我无法使用 Gradio Client API 使用图像进行预测</title>
      <link>https://stackoverflow.com/questions/78176532/i-cant-use-the-gradio-client-api-to-make-a-prediction-using-images</link>
      <description><![CDATA[我正在尝试按照以下示例将图像发送到 Gradio Client API：
从“@gradio/client”导入{ client }；

const response_0 = 等待 fetch(“https://raw.githubusercontent.com/gradio-app/gradio/main/test/test_files/bus.png”);
const exampleImage =等待response_0.blob();
                        
const app = 等待客户端(“airvit2/pet_classifier”);
const 结果 =等待 app.predict(“/预测”, [
                exampleImage, // &#39;img&#39; 图像组件中的 blob
    ]);

console.log(结果.数据);

但它返回此错误：
&lt;前&gt;&lt;代码&gt;{
    “类型”：“状态”，
    “端点”：“/预测”，
    “fn_index”：0，
    “时间”：“2024-03-17T18:36:53.270Z”，
    “队列”：正确，
    “消息”：空，
    “阶段”：“错误”，
    “成功”：假
}

这是我的 Gradio 代码：
from fastai.vision.all import *
将渐变导入为 gr

学习 = load_learner(&#39;model.pkl&#39;)

def 预测（img）：
    print(&quot;图片：&quot;, img)
    img = 加载图像(img)
    # img = PILImage.create(img)
    pred, pred_idx, probs = learn.predict(img)
    返回预测值

gr.Interface(fn = 预测，输入 = gr.Image(type=“pil”，高度 = 224，宽度 = 224)，输出 = gr.Label(num_top_classes = 3)).launch(share = True)


我尝试将图像格式更改为 Blob，但没有成功。]]></description>
      <guid>https://stackoverflow.com/questions/78176532/i-cant-use-the-gradio-client-api-to-make-a-prediction-using-images</guid>
      <pubDate>Sun, 17 Mar 2024 18:57:11 GMT</pubDate>
    </item>
    <item>
      <title>YOLOv8 自定义模型不进行预测</title>
      <link>https://stackoverflow.com/questions/78176290/yolov8-custom-model-not-making-predictions</link>
      <description><![CDATA[我使用自定义训练的 Yolov8 模型来预测物理门是关闭还是打开。我已经在自定义数据集上训练了 Yolov8，但即使传递用于训练的相同数据，它也不会进行任何检测。
我使用了大约 300 张图像的数据集。
这是我的代码：
导入操作系统

从 ultralytics 导入 YOLO
导入CV2


VIDEOS_DIR = os.path.join(&#39;.&#39;, &#39;视频&#39;)

video_path = os.path.join(VIDEOS_DIR, &#39;样本门.mp4&#39;)
video_path_out = &#39;{}_out.mp4&#39;.format(video_path)

cap = cv2.VideoCapture(video_path)
ret, 框架 = cap.read()
H、W、_ = 框架.形状
out = cv2.VideoWriter(video_path_out, cv2.VideoWriter_fourcc(*&#39;MP4V&#39;), int(cap.get(cv2.CAP_PROP_FPS)), (W, H))

model_path = os.path.join(&#39;.&#39;, &#39;运行&#39;, &#39;检测&#39;, &#39;训练&#39;, &#39;权重&#39;, &#39;last.pt&#39;)


model = YOLO(model_path) # 加载自定义模型


休息时：

    结果=模型（框架）[0]
    对于 results.boxes.data.tolist() 中的结果：
        x1, y1, x2, y2, 分数, class_id = 结果
        打印（x1，y1，x2，y2）

        cv2.矩形(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 4)
        cv2.putText(frame, results.names[int(class_id)].upper(), (int(x1), int(y1 - 10)),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3, cv2.LINE_AA)

    输出.write(帧)
    ret, 框架 = cap.read()

cap.release()
out.release()
cv2.destroyAllWindows()

以下是训练结果：https://i.stack.imgur。 com/huyZR.png]]></description>
      <guid>https://stackoverflow.com/questions/78176290/yolov8-custom-model-not-making-predictions</guid>
      <pubDate>Sun, 17 Mar 2024 17:43:55 GMT</pubDate>
    </item>
    <item>
      <title>在 SageMaker 上的 TensorFlow Recommenders 中初始化 FactorizedTopK 时出错：“无法将‘计数器’转换为形状”</title>
      <link>https://stackoverflow.com/questions/78144515/error-initializing-factorizedtopk-in-tensorflow-recommenders-on-sagemaker-cann</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78144515/error-initializing-factorizedtopk-in-tensorflow-recommenders-on-sagemaker-cann</guid>
      <pubDate>Tue, 12 Mar 2024 03:28:18 GMT</pubDate>
    </item>
    <item>
      <title>如何在本地运行主宰模型</title>
      <link>https://stackoverflow.com/questions/78143186/how-to-run-juggernaut-model-in-local</link>
      <description><![CDATA[我想使用 python 在本地电脑上运行微调的稳定扩散模型。例如剑圣：https://huggingface.co/RunDiffusion/Juggernaut-XL-v9
这是我的代码（它适用于 stable-diffusion-xl-base-1.0）：
随机导入
从扩散器导入 DiffusionPipeline、StableDiffusionXLImg2ImgPipeline
进口火炬
导入气相色谱
导入时间

# 用于清理内存
GC.collect()
torch.cuda.empty_cache()

开始时间 = 时间.time()

型号 =“RunDiffusion/Juggernaut-XL-v9”
管道 = DiffusionPipeline.from_pretrained(
    模型，
    torch_dtype=torch.float16,
）

管道.to(“cuda”)

提示=（“中世纪男性骑士肖像，阳刚的外观，背景中的战斗，清晰的焦点，高度详细，电影风格的灯光，阴影”）
种子 = random.randint(0, 2**32 - 1)

生成器 = torch.Generator(“cuda”).manual_seed(seed)
图像=管道（提示=提示，生成器=生成器，num_inference_steps=1）
图像=图像.图像[0]
image.save(f&quot;output_images/{seed}.png&quot;)

结束时间 = time.time()

总时间 = 结束时间 - 开始时间
分钟 = int(total_time // 60)
秒 = int(总时间 % 60)

print(f&quot;花费: {分钟} 分 {秒} 秒&quot;)
print(f&quot;保存到output_images/{seed}.png&quot;)


但我得到：
&lt;块引用&gt;
OSError：在目录中找不到名为 pytorch_model.bin、tf_model.h5、model.ckpt.index 或 flax_model.msgpack 的文件时出错

可能是因为python、cuda版本的原因。我正在删除我的库版本：
Python 3.9.0
PyTorch：2.2.0+cu118
CUDA：11.8
扩散器：0.26.3
变形金刚：4.38.1]]></description>
      <guid>https://stackoverflow.com/questions/78143186/how-to-run-juggernaut-model-in-local</guid>
      <pubDate>Mon, 11 Mar 2024 20:12:01 GMT</pubDate>
    </item>
    <item>
      <title>Python 中 HIV/AIDS 治疗的预测建模 - 特征选择 [关闭]</title>
      <link>https://stackoverflow.com/questions/78133554/predictive-modeling-for-hiv-aids-treatment-in-python-feature-selection</link>
      <description><![CDATA[我正在研究健康分析领域的预测建模项目，特别关注使用 Python 优化 HIV/AIDS 治疗结果。我收集了具有各种特征的数据集，包括患者人口统计数据、治疗历史和实验室结果。
有关 EDA 的任何提示，以提高我的模型的准确性。此外，如果您能提供有关特征工程的一般想法或技巧，我们将不胜感激。]]></description>
      <guid>https://stackoverflow.com/questions/78133554/predictive-modeling-for-hiv-aids-treatment-in-python-feature-selection</guid>
      <pubDate>Sat, 09 Mar 2024 19:01:33 GMT</pubDate>
    </item>
    <item>
      <title>scikeras.wrappers.KerasClassifier 返回 ValueError：无法解释指标标识符：loss</title>
      <link>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</link>
      <description><![CDATA[我正在研究 KerasClassifier，因为我想将其插入 scikit-learn 管道中，但我收到了前面提到的 ValueError。
以下代码应该能够重现我遇到的错误：
从 sklearn.model_selection 导入 KFold，cross_val_score
从 sklearn.preprocessing 导入 StandardScaler
从 scikeras.wrappers 导入 KerasClassifier
从tensorflow.keras.models导入顺序
从tensorflow.keras.layers导入Dense
从 sklearn.datasets 导入 load_iris
将 numpy 导入为 np

数据 = load_iris()
X = 数据.数据
y = 数据.目标

def create_model():
    模型=顺序（）
    model.add（密集（8，input_dim = 4，激活=&#39;relu&#39;））
    model.add（密集（3，激活=&#39;softmax&#39;））
    model.compile(loss=&#39;sparse_categorical_crossentropy&#39;,
                  优化器=&#39;亚当&#39;,
                  指标=[&#39;准确性&#39;])
    返回模型

clf = KerasClassifier(build_fn=create_model,
                      纪元=100，
                      批量大小=10，
                      详细=1)

管道=管道([
    (&#39;缩放器&#39;, StandardScaler()),
    （&#39;clf&#39;，clf）
]）

kf = KFold(n_splits=5, shuffle=True, random_state=42)
结果= cross_val_score（管道，X，y，cv = kf）
print(&quot;交叉验证准确度：&quot;, np.mean(结果))

似乎我的模型正在随着纪元的运行而被编译。但是，之后我收到错误：
ValueError：无法解释指标标识符：丢失

tensorflow 和 scikeras 库的版本是：
scikeras==0.12.0
张量流==2.15.0

编辑：
最终我尝试了不同的库版本，以下内容让我成功运行了代码，看来问题是由 scikit-learn 的版本引起的：
scikeras==0.12.0
张量流==2.15.0
scikit学习==1.4.1
]]></description>
      <guid>https://stackoverflow.com/questions/78089332/scikeras-wrappers-kerasclassifier-returning-valueerror-could-not-interpret-metr</guid>
      <pubDate>Fri, 01 Mar 2024 17:03:39 GMT</pubDate>
    </item>
    <item>
      <title>在 JavaScript 中加载经过训练的机器学习模型</title>
      <link>https://stackoverflow.com/questions/63395832/load-trained-machine-learning-model-in-javascript</link>
      <description><![CDATA[我正在 python 中使用 sklearn 来构建/训练一些模型（随机森林回归器、Kmeans、SVM，...），并且我想在 web 应用程序 Javascript/html 中使用这些经过训练的模型。有没有办法做到这一点？
我已经看到tensorflow.js允许使用keras模型做这样的事情。但在我看来，python 中的 TF/keras 仅限于神经网络。
我也见过sklearn-porter，但它似乎仅限于某些特定模型（主要是分类）。如果有人成功使用它，他们可以告诉我更多信息吗？
预先感谢您的帮助]]></description>
      <guid>https://stackoverflow.com/questions/63395832/load-trained-machine-learning-model-in-javascript</guid>
      <pubDate>Thu, 13 Aug 2020 13:04:36 GMT</pubDate>
    </item>
    </channel>
</rss>