<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Tue, 04 Feb 2025 03:19:11 GMT</lastBuildDate>
    <item>
      <title>sklearn 随机森林的不同结果（带种子）</title>
      <link>https://stackoverflow.com/questions/79410458/different-results-with-seed-for-sklearn-random-forest</link>
      <description><![CDATA[我正在使用 sklearn 运行随机森林。我正在为随机森林设置种子，以及拆分数据以进行交叉验证。当我连续多次重新运行代码时，它给出了相同的结果。但是，一个月后重新运行相同的代码，我得到了略有不同的特征重要性。在其他一些类似的分析中，准确度指标也不同。数据没有改变。我在 Google Colab 上运行。
这是我的代码：
# 配置
file_path = &#39;/content/drive/My Drive/dataset.csv&#39;
columns_to_keep = [
&#39;target_column&#39;, &#39;feature_a&#39;, &#39;feature_b&#39;, &#39;feature_c&#39;, &#39;feature_d&#39;, &#39;feature_e&#39;,
&#39;feature_f&#39;, &#39;feature_g&#39;, &#39;feature_h&#39;, &#39;feature_i&#39;, &#39;feature_j&#39;, &#39;feature_k&#39;, &#39;feature_l&#39;,
&#39;feature_m&#39;, &#39;feature_n&#39;, &#39;feature_o&#39;, &#39;feature_p&#39;, &#39;feature_q&#39;, &#39;feature_r&#39;, &#39;feature_s&#39;,
&#39;feature_t&#39;, &#39;feature_u&#39;, &#39;feature_v&#39;, &#39;feature_w&#39;, &#39;feature_x&#39;, &#39;feature_y&#39;, &#39;feature_z&#39;,
&#39;feature_aa&#39;, &#39;feature_ab&#39;, &#39;feature_ac&#39;, &#39;feature_ad&#39;, &#39;feature_ae&#39;, &#39;feature_af&#39;, &#39;feature_ag&#39;,
&#39;feature_ah&#39;, &#39;feature_ai&#39;, &#39;feature_aj&#39;, &#39;feature_ak&#39;, &#39;feature_al&#39;, &#39;feature_am&#39;, &#39;feature_an&#39;
]

df = pd.read_csv(file_path, usecols=columns_to_keep)

categorical_columns = [&#39;feature_ak&#39;, &#39;feature_al&#39;, &#39;feature_am&#39;, &#39;feature_an&#39;, &#39;feature_ao&#39;]
one_hot_columns = [&#39;feature_al&#39;, &#39;feature_ak&#39;]

df = df.dropna()

# 对指定列进行独热编码
le = LabelEncoder()
for col in one_hot_columns:
df[col] = le.fit_transform(df[col])

# 将指定列转换为分类
for col in categorical_columns:
df[col] = df[col].astype(&#39;category&#39;)

# 拆分为特征和目标
X = df.drop(columns=[&#39;target_column&#39;])
y = df[&#39;target_column&#39;]

# 初始化 RandomForestClassifier 模型
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# 初始化 k 倍交叉验证
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# 存储结果
feature_importances_list = []
all_y_true = []
all_y_pred = []

# 执行 k 倍交叉验证
for fold_num, (train_index, test_index) in enumerate(kf.split(X), start=1):
# 拆分数据
X_train, X_test = X.iloc[train_index], X.iloc[test_index]
y_train, y_test = y.iloc[train_index], y.iloc[test_index]

# 训练随机森林模型
rf_model.fit(X_train, y_train)

# 在测试集上进行预测
y_pred = rf_model.predict(X_test)

# 收集所有真实和预测标签
all_y_true.extend(y_test)
all_y_pred.extend(y_pred)

# 获取此折叠的特征重要性
feature_importances_list.append(rf_model.feature_importances_)

# 计算并打印此折叠的准确度
accuracy_fold = accuracy_score(y_test, y_pred)
print(f&quot;Fold {fold_num} Accuracy: {accuracy_fold:.4f}&quot;)

# 计算所有预测的准确度
accuracy_cv = accuracy_score(all_y_true, all_y_pred)

# 生成分类报告
final_report = classes_report(all_y_true, all_y_pred, digits=3)

# 折叠的平均特征重要性
average_importance = sum(feature_importances_list) / len(feature_importances_list)

# 创建带有特征名称的 DataFrame及其相应的平均重要性
feature_names = X.columns
importance_df = pd.DataFrame({
&#39;Feature&#39;: feature_names,
&#39;Importance&#39;: average_importance
}).sort_values(by=&#39;Importance&#39;, accending=False)

# 打印结果
print(f&quot;具有 k 倍 CV 的随机森林模型的总体准确率：{accuracy_cv:.4f}&quot;)

print(&quot;\n最终分类报告：&quot;)
print(final_report)

print(&quot;\n随机森林特征重要性（各倍平均）：&quot;)
print(importance_df.head(20))

非常感谢您的帮助。]]></description>
      <guid>https://stackoverflow.com/questions/79410458/different-results-with-seed-for-sklearn-random-forest</guid>
      <pubDate>Tue, 04 Feb 2025 02:34:12 GMT</pubDate>
    </item>
    <item>
      <title>训练/测试损失低，但预测不佳</title>
      <link>https://stackoverflow.com/questions/79410070/low-train-test-loss-but-bad-prediction</link>
      <description><![CDATA[我试图估算不同频率的 2 个阻抗值。我的输入是 3 个变量（720 组）+ 频率（89 个不同值）~64K 数据集，输出是 720 组中的每个组在每个频率的两个阻抗值。我将这些数据分成 80/20 的训练/测试集，并从数据集中保留了 2 个样本，用于完全无偏估计。
我的训练/测试损失相当/非常低，甚至 =0（取决于时期数），当估计数据集中包含的变量的阻抗时，我可以得到完美的拟合（当然），但当从数据集中保留的样本进行预测时，效果并不好。
训练和测试损失似乎也有点过于相互跟随/相互叠加，我似乎无法通过增加训练时间来引起测试损失（过度拟合）的上升。所以这看起来像是一个问题？
我正在使用 pytorch，这是第一次（而且我对 ML 总体来说还很陌生），似乎无法找出问题所在，因此任何帮助/建议都将不胜感激。如果您想查看我混乱的代码，我已经创建了一个 repo。
我尝试优化超参数，降低训练/测试损失，但这仍然不能让我的预测变得更好。]]></description>
      <guid>https://stackoverflow.com/questions/79410070/low-train-test-loss-but-bad-prediction</guid>
      <pubDate>Mon, 03 Feb 2025 21:34:31 GMT</pubDate>
    </item>
    <item>
      <title>我可以使用哪些方法来找出行人轨迹的部分</title>
      <link>https://stackoverflow.com/questions/79409749/what-are-methods-i-can-use-to-find-out-parts-of-trajectory-that-is-pedestrian-tr</link>
      <description><![CDATA[我有一个表示手机移动轨迹的数据集，该轨迹由步行和驾车行驶的路段组成。数据包括经度、纬度和时间戳。我需要提取所有步行行驶的子轨迹。有没有现成的解决方案可以解决这个问题？如果没有，我该如何处理这个任务？我很乐意收到任何建议
我试图在互联网上寻找现成的解决方案，但没有找到任何有价值的东西]]></description>
      <guid>https://stackoverflow.com/questions/79409749/what-are-methods-i-can-use-to-find-out-parts-of-trajectory-that-is-pedestrian-tr</guid>
      <pubDate>Mon, 03 Feb 2025 18:56:03 GMT</pubDate>
    </item>
    <item>
      <title>TensorFlow 无法在 Google Colab 中加载 Adam 优化器</title>
      <link>https://stackoverflow.com/questions/79409678/tensorflow-unable-to-load-adam-optimizer-in-google-colab</link>
      <description><![CDATA[我正在尝试在 Google Colab 中使用 Adam 组织器。我有以下代码：
import tensorflow as tf
import numpy as np
from transformers import BertTokenizer, TFBertForSequenceClassification
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import SparseCategoricalCrossentropy

我使用以下代码编译我的模型：
model.compile(
optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),
loss=SparseCategoricalCrossentropy(from_logits=True),
metrics=[&quot;accuracy&quot;]
)

但我得到了：
ValueError Traceback（最近一次调用最后)
&lt;ipython-input-38-0183d53e319d&gt; 在 &lt;cell line: 0&gt;()
----&gt; 1 model.compile(
2 optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),
3 loss=SparseCategoricalCrossentropy(from_logits=True),
4 metrics=[&quot;accuracy&quot;]
5 )

2 frames
/usr/local/lib/python3.11/dist-packages/tf_keras/src/optimizers/__init__.py 在 get(identifier, **kwargs)
333 )
334 else:
--&gt; 335 引发 ValueError(
336 f&quot;无法解释优化器标识符：{identifier}&quot;
337 )

ValueError：无法解释优化器标识符：&lt;keras.src.optimizers.adam.Adam 对象位于 0x7cef33ad4050&gt;

我遗漏了什么？]]></description>
      <guid>https://stackoverflow.com/questions/79409678/tensorflow-unable-to-load-adam-optimizer-in-google-colab</guid>
      <pubDate>Mon, 03 Feb 2025 18:22:46 GMT</pubDate>
    </item>
    <item>
      <title>奖励信号在强化学习期间如何应用于 LLM？</title>
      <link>https://stackoverflow.com/questions/79409562/how-is-reward-signal-applied-to-the-llm-during-reinforcement-learning</link>
      <description><![CDATA[一旦有了奖励信号，你如何将其应用于 LLM？它仍然是反向传播吗？它仍然是每个 token 吗？
SFT 和 RL 有什么区别？]]></description>
      <guid>https://stackoverflow.com/questions/79409562/how-is-reward-signal-applied-to-the-llm-during-reinforcement-learning</guid>
      <pubDate>Mon, 03 Feb 2025 17:22:29 GMT</pubDate>
    </item>
    <item>
      <title>为什么我必须将数据从 torch.Size([50]) 解压到 torch.Size([50, 1])</title>
      <link>https://stackoverflow.com/questions/79409149/why-do-i-have-to-unsqueeze-the-data-from-torch-size50-to-torch-size50-1</link>
      <description><![CDATA[我正在学习 FreeCodeCamp 的 PyTorch 深度学习课程，疑问是：
weight = 0.7
bias = 0.3
start = 0
end = 1
step = 0.02

X = torch.arange(start, end, step).unsqueeze(dim=1)
y=weight*X + bias
X[:10], y[:10]
train_split=int(0.8*len(X))
print(X.shape, y.shape)

为什么使用 unsqueeze 函数生成大小为 [50, 1] 的张量，而不是 [50]？导师说这会导致错误，但我不知道为什么会发生错误？
你能用数学以及不使用数学的基本原理来回答这个问题吗？
尝试训练模型后，我收到此错误：
y_prediction = model_v2(X_train)
IndexError：维度超出范围（预期在 [-1, 0] 范围内，但得到 -2）]]></description>
      <guid>https://stackoverflow.com/questions/79409149/why-do-i-have-to-unsqueeze-the-data-from-torch-size50-to-torch-size50-1</guid>
      <pubDate>Mon, 03 Feb 2025 14:44:08 GMT</pubDate>
    </item>
    <item>
      <title>Ultralytics 是否提供单独的跟踪 API？</title>
      <link>https://stackoverflow.com/questions/79408953/does-ultralytics-provide-a-separate-api-for-tracking</link>
      <description><![CDATA[我想使用独立于分段的跟踪来单独缩放它们。据我所知，分段是一个无状态推理过程，应用于每个帧，不依赖于先前的帧。相比之下，持久跟踪是一个依赖于先前结果的状态过程。
这种理解有道理吗？Ultralytics 是否为跟踪和分段提供了单独的 API？]]></description>
      <guid>https://stackoverflow.com/questions/79408953/does-ultralytics-provide-a-separate-api-for-tracking</guid>
      <pubDate>Mon, 03 Feb 2025 13:23:28 GMT</pubDate>
    </item>
    <item>
      <title>梯度下降 3D 可视化 Python</title>
      <link>https://stackoverflow.com/questions/79407494/gradient-descent-3d-visualization-python</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79407494/gradient-descent-3d-visualization-python</guid>
      <pubDate>Sun, 02 Feb 2025 22:49:15 GMT</pubDate>
    </item>
    <item>
      <title>ML.NET 时间序列预测的奇怪常数表现：SsaForecastingEstimator.Fit</title>
      <link>https://stackoverflow.com/questions/79407198/ml-net-strange-constant-performance-of-timeseries-forecast-ssaforecastingestima</link>
      <description><![CDATA[我正在使用 ML.NET 训练时间序列预测模型
没有任何问题，但我最近想知道什么真正影响了 SsaForecastingEstimator.Fit 方法的性能。我注意到它几乎从未使用接近 100% 的 CPU，而是大约 60-70%（其他用户也提到了这一点：我如何才能在 ML.NET 的训练过程中充分利用 CPU 的潜力？）
我现在有机会将我的 CPU 从 i5 12400 换成 i5 14600KF
我没想到会对性能产生巨大影响，但令我惊讶的是，它根本没有影响性能。训练时间几乎与秒相同。在 fit 方法中是否应用了某种固定的训练时间，或者这里发生了什么？
SsaForecastingEstimator pipeline = Context.Forecasting.ForecastBySsa(windowSize: 300, seriesLength: 3600, trainSize: 3600, horizo​​n: 30, outputColumnName: @&quot;col1&quot;, inputColumnName: @&quot;col1&quot;, confidenceLowerBoundColumn: @&quot;col1_LB&quot;, confidenceUpperBoundColumn: @&quot;col1_UB&quot;); 
SsaForecastingTransformer model = pipeline.Fit(trainData);
使用 (TimeSeriesPredictionEngine&lt;TimeSeriesModelInput, TimeSeriesModelOutput&gt; ForecastingEngine = model.CreateTimeSeriesEngine&lt;TimeSeriesModelInput, TimeSeriesModelOutput&gt;(Context))
{
TimeSeriesModelOutput Forecast = ForecastingEngine.Predict();
...
}


进行了一次分析运行，验证了拟合方法是否消耗了最多的 CPU 时间：确实如此
比较了 Debug 和 Release 版本：没有区别
CPU 交换：没有区别
]]></description>
      <guid>https://stackoverflow.com/questions/79407198/ml-net-strange-constant-performance-of-timeseries-forecast-ssaforecastingestima</guid>
      <pubDate>Sun, 02 Feb 2025 19:29:23 GMT</pubDate>
    </item>
    <item>
      <title>QuickUMLS 始终对任何输入文本返回“UNK”</title>
      <link>https://stackoverflow.com/questions/79406743/quickumls-always-returns-unk-for-any-input-text</link>
      <description><![CDATA[我正在使用 QuickUMLS 从文本中提取 UMLS 概念唯一标识符 (CUI)，但无论我输入什么词，它总是返回“UNK”。这是我的代码：
from quickumls import QuickUMLS

quickumls_fp = &quot;med7_en/lib/python3.10/site-packages/quickumls&quot;
matcher = QuickUMLS(quickumls_fp)

def extract_umls_cuis(text):
&quot;&quot;&quot;使用 QuickUMLS 提取 UMLS CUI。&quot;&quot;&quot;
if isinstance(text, str):
matches = matcher.match(text)
if matches:
return [match[&#39;cui&#39;] for match in matches[0]]
else:
return &quot;UNK&quot;

sample_text = &quot;diclofenac.&quot;
print(extract_umls_cuis(sample_text))

我已检查的内容：

QuickUMLS 安装：我已正确安装 QuickUMLS。
UMLS 数据可用性：我已将正确的路径设置为 QuickUMLS。
不同的输入词：我尝试了各种医学术语，但都返回“UNK”。
]]></description>
      <guid>https://stackoverflow.com/questions/79406743/quickumls-always-returns-unk-for-any-input-text</guid>
      <pubDate>Sun, 02 Feb 2025 14:12:55 GMT</pubDate>
    </item>
    <item>
      <title>为什么混淆矩阵图的第二行的值缺失了？</title>
      <link>https://stackoverflow.com/questions/79406524/why-values-in-the-second-row-of-the-confusion-matrix-plot-are-missing</link>
      <description><![CDATA[我按照下面的代码构建了一个混淆矩阵：
conf_matrix = chaos_matrix(y_test, y_test_predictions)

print(conf_matrix)

[[122 27]
[ 40 42]]

观察到它的值都放在一个数组中。我现在想用这些信息使用 matplotlib 和 seaborn 库绘制这些值。为此，请使用或遵循代码 trecho。
plt.figure(figsize=(3, 3), dpi=300)
# 放大所有文本的大小
sns.set(font_scale = 1.1)

ax = sns.heatmap(conf_matrix, annot=True, fmt=&#39;d&#39;, )

# 设置 x 轴标签和刻度。
ax.set_xlabel(&quot;预测诊断&quot;, fontsize=14, labelpad=20)
ax.xaxis.set_ticklabels([&#39;Negative&#39;, &#39;Positive&#39;])

# 设置 y 轴标签和刻度
ax.set_ylabel(&quot;实际诊断&quot;, fontsize=14, labelpad=20)
ax.yaxis.set_ticklabels([&#39;Negative&#39;, &#39;Positive&#39;])

# 设置图标题
ax.set_title(&quot;糖尿病检测模型的混淆矩阵&quot;, fontsize=14, pad=20)

plt.show()

要使用此代码，应在每个单元格中绘制混淆矩阵值，数字 40 和 42 将不会出现（第二条矩阵线）。你有没有被别人超越过？
我使用的是 jupyter notebook 7.0.8、python 3.11.7、matplotlib 3.8.0 和 seaborn 0.12.2。]]></description>
      <guid>https://stackoverflow.com/questions/79406524/why-values-in-the-second-row-of-the-confusion-matrix-plot-are-missing</guid>
      <pubDate>Sun, 02 Feb 2025 11:45:00 GMT</pubDate>
    </item>
    <item>
      <title>尽管安装了 CUDA 驱动程序，TensorFlow 2.14.1 仍无法在 Ubuntu 24.04.1 LTS 上检测到 GPU</title>
      <link>https://stackoverflow.com/questions/79403749/tensorflow-2-14-1-not-detecting-gpu-on-ubuntu-24-04-1-lts-despite-cuda-drivers-b</link>
      <description><![CDATA[我在 Ubuntu 24.04.1 LTS 上使用 TensorFlow 2.14.1。当我打开 Python 终端并导入 TensorFlow（import tensorflow as tf）时，我遇到以下警告：
I tensorflow/tsl/cuda/cudart_stub.cc:28] 无法在您的机器上找到 cuda 驱动程序，GPU 将无法使用。
E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] 无法注册 cuDNN 工厂：尝试注册插件 cuDNN 工厂，但已注册一个
E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] 无法注册 cuDNN 工厂：尝试注册插件 cuDNN 工厂，但已注册一个

关闭 Python 后，我在终端中运行了 nvidia-smi，我的 GPU 被检测到（见下图）。

但是，当我尝试使用以下命令在 TensorFlow 中列出物理 GPU 设备时：
physical_devices = tf.config.list_physical_devices(&#39;GPU&#39;)
print(&quot;Num GPUs:&quot;, len(physical_devices))

我得到：
Num GPUs: 0

有人遇到过这个问题吗？为什么 TensorFlow 无法检测到我的 GPU，即使 nvidia-smi 显示它？
编辑：对于那些考虑关闭这个问题的人来说，这与使用 TensorFlow（用于构建神经网络的库）进行编程直接相关。这个问题阻止我使用 GPU，这对性能至关重要。这似乎与 Stack Overflow 的主题非常相关。]]></description>
      <guid>https://stackoverflow.com/questions/79403749/tensorflow-2-14-1-not-detecting-gpu-on-ubuntu-24-04-1-lts-despite-cuda-drivers-b</guid>
      <pubDate>Fri, 31 Jan 2025 18:48:41 GMT</pubDate>
    </item>
    <item>
      <title>从 pix2pix 实现矢量化生成的线条</title>
      <link>https://stackoverflow.com/questions/79402632/vectorize-generated-lines-from-a-pix2pix-implementation</link>
      <description><![CDATA[我有以下使用 pix2pix 模型生成的图像。我希望生成的线条是直的，并且具有相同的高度（如果是水平的）和相同的宽度（如果是垂直的）。
基本上这些线是墙壁，稍后应该被渲染为房子里的墙壁。
有没有任何 python /ml 逻辑可以实现这一点？
]]></description>
      <guid>https://stackoverflow.com/questions/79402632/vectorize-generated-lines-from-a-pix2pix-implementation</guid>
      <pubDate>Fri, 31 Jan 2025 11:47:17 GMT</pubDate>
    </item>
    <item>
      <title>Optuna 样本固定参数取决于另一个参数</title>
      <link>https://stackoverflow.com/questions/75635528/optuna-sample-fixed-parameter-depending-on-another-parameter</link>
      <description><![CDATA[在我的设置中，我有一个类似以下的抽象情况，它仅作为示例案例：
base = trial.suggest_int(1, 3)
power = trial.suggest_int(1, 10)
# value = base ** power

当 base == 1 时，power 参数变得无关紧要，我想将其固定为 1。
例如：
base = trial.suggest_int(&quot;base&quot;, 1, 3)
if base == 1:
# 不同的分布！但仍在另一个内部。
power = trial.suggest_int(&quot;power&quot;, 1, 1) 
else:
power = trial.suggest_int(&quot;power&quot;, 1, 10)

虽然这种方法可行，但会以 ValueError 的形式产生后续问题，因为底层分布并不相同。

我如何建议一个具有相同参数名称的固定值，该值取决于试验中采样的另一个值？]]></description>
      <guid>https://stackoverflow.com/questions/75635528/optuna-sample-fixed-parameter-depending-on-another-parameter</guid>
      <pubDate>Sat, 04 Mar 2023 12:01:19 GMT</pubDate>
    </item>
    <item>
      <title>错误 conda.core.link:_execute(698): 安装包“defaults::icu-58.2-ha925a31_3”时发生错误</title>
      <link>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</link>
      <description><![CDATA[我使用 anaconda prompt conda create -n talkingbot python=3.5 创建了环境，然后安装了 pip install tensorflow==1.0.0（遵循与 udemy 课程中使用的相同命令），但是当我尝试使用 conda install spyder 安装 spyder 时，它给了我这个错误：
准备交易：完成
验证交易：完成
执行交易：完成
错误 conda.core.link:_execute(698)：安装包“defaults::icu-58.2-ha925a31_3”时发生错误。
回滚事务：完成

[Errno 13] 权限被拒绝：&#39;C:\\Users\\Lenovo\\anaconda3\\envs\\talkingbot\\Library\\bin\\icudt58.dll&#39;
()

然后我尝试使用 anaconda navigator 安装 spyder，但 spyder 也未安装。
帮我解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/63871492/error-conda-core-link-execute698-an-error-occurred-while-installing-package</guid>
      <pubDate>Sun, 13 Sep 2020 13:42:24 GMT</pubDate>
    </item>
    </channel>
</rss>