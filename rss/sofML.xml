<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Thu, 01 Aug 2024 18:19:55 GMT</lastBuildDate>
    <item>
      <title>两个数据集的随机森林的数据集结构</title>
      <link>https://stackoverflow.com/questions/78822403/dataset-structure-for-random-forest-of-two-datasets</link>
      <description><![CDATA[我有两个单独的数据集，就变量而言，它们包含相同类型的数据，涉及 2000 多名农民，但针对的是同一农民的 2021 年和 2022 年（列数相同，为 70，行数不同；两者都接近 5000）。我必须使用机器学习和随机森林算法预测 2023 年的产量 (Y)（动物公斤数/农场总公顷数）。但是，我不确定您如何统一数据集（2021 年和 2022 年），或者我应该如何设置最终数据集以进行预测，这意味着：

我应该将两个数据集统一为一个吗？如果是，怎么办？
选项 A：



ID 农民
KG 动物
农场公顷
产量
年份
...




1
30
2
15
2021
...


1
40
3
13
2022
...


2
 20
4
5
2021
...


2
30
5
6
2022
...


...
...
...
...
...
...



选项B:



农民 ID
2021 年牲畜公斤数
2022 年牲畜公斤数
2021 年农场公顷数
2022 年农场公顷数
2021 年产量
产量2022




1
30
40
2
3
15
13


2
20
30
4
5
5
6


...
...
...
...
...
...
...



如果不是，最好的构造方法是什么？算法需要什么来构造数据集？或者它需要什么输入才能进行可靠的预测（我是机器学习的新手）？

我是否应该只将基于 2021 年的变化数据添加到 2022 年的数据集中，因此 kg、农场公顷的增加、减少 ecc 的百分比添加到新列中？或者应该如何设置？

我应该使用另一个机器学习模型进行预测吗？如果是，哪一个？我知道我不能使用时间序列预测，因为时间数据很少。

]]></description>
      <guid>https://stackoverflow.com/questions/78822403/dataset-structure-for-random-forest-of-two-datasets</guid>
      <pubDate>Thu, 01 Aug 2024 17:50:10 GMT</pubDate>
    </item>
    <item>
      <title>训练模型时出现错误“对象 __array__ 方法未生成数组”</title>
      <link>https://stackoverflow.com/questions/78822263/getting-error-object-array-method-not-producing-an-array-while-training-a</link>
      <description><![CDATA[我正在尝试使用神经网络模型 Sequential 来训练一个模型。在模型编译之前，一切都进展顺利。当我点击 model.fit() 进行模型训练时，我收到错误“对象 array 方法未生成数组”。请告诉我错误在哪里。我还打印了 X_train 和 y_train 样本及其形状。
下面是相同的代码。
 from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.utils import to_categorical
import numpy as np

# 编码分类特征
label_encoders = {}
for column in solidated_super.columns:
le = LabelEncoder()
solided_super[column] = le.fit_transform(consolidated_super[column])
label_encoders[column] = le

# 将数据拆分为输入和输出
X = solided_super[[&#39;DeviceName_df1&#39;, &#39;AlarmName_df1&#39;]].values
y = solided_super[[&#39;DeviceName_df2&#39;, &#39;AlarmName_df2&#39;]].values

# 对输出标签进行独热编码
y_device = to_categorical(consolidated_super[&#39;DeviceName_df2&#39;])
y_alarm = to_categorical(consolidated_super[&#39;AlarmName_df2&#39;])

# 合并独热编码的输出
y = np.concatenate([y_device, y_alarm], axis=1)

# 确保 y 为数字且具有正确的形状
print(f&#39;X shape: {X.shape}, y shape: {y.shape}&#39;)
print(f&#39;X sample: {X[:5]}, y sample: {y[:5]}&#39;)

//上述打印语句的运算
X shape: (396, 2), y shape: （396，25）
X 样本：[[16 19]
[16 19]
[16 19]
[16 19]
[12 20]]，y 样本：[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 
0. 0.
1.]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.
0.]
[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.
0.]]
///

# 将数据拆分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
random_state=42)

# 对输入特征进行归一化
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# 定义神经网络模型
model = Sequential()
model.add(Input(shape=(X_train.shape[1],)))
model.add(Dense(64,activation=&#39;relu&#39;))
model.add(Dense(32,activation=&#39;relu&#39;))
model.add(Dense(y_train.shape[1],activation=&#39;softmax&#39;)) # 使用softmax进行多类分类
#编译模型
model.compile(optimizer=&#39;adam&#39;,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

#训练模型
model.fit(X_train,y_train,epochs=50,batch_size=8,validation_split=0.2)

在执行model.fit()时，我得到错误：-
ValueError Traceback（最近一次调用最后一次）Cell In[59]，第 2 行
1#训练模型
----&gt; 2 model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.2)
文件 C:\Python312\Lib\site-packages\keras\src\utils\traceback_utils.py:122，位于 filter_traceback.&lt;locals&gt;.error_handler(*args, **kwargs)
119filtered_tb = _process_traceback_frames(e.__traceback__)
120 # 要获取完整的堆栈跟踪，请调用：
121 # `keras.config.disable_traceback_filtering()`
--&gt; 122 从 None 中引发 e.with_traceback(filtered_tb)
123 最后：
124 delfiltered_tb
文件 C:\Python312\Lib\site-packages\tensorflow\python\framework\constant_op.py:108，在 convert_to_eager_tensor(value, ctx, dtype) 中
106 dtype = dtypes.as_dtype(dtype).as_datatype_enum
107 ctx.ensure_initialized()
--&gt; 108 返回 ops.EagerTensor(value, ctx.device_name, dtype)
ValueError: 对象 __array__ 方法未生成数组

示例数据框为：-
{
&#39;DeviceName_df1&#39;: [&#39;Device A&#39;, &#39;Device B&#39;, &#39;Device C&#39;],
&#39;AlarmName_df1&#39;: [&#39;Alarm1&#39;, &#39;Alarm2&#39;, &#39;Alarm3&#39;],
&#39;DeviceName_df2&#39;: [&#39;Device X&#39;, &#39;Device Y&#39;, &#39;Device Z&#39;],
&#39;AlarmName_df2&#39;: [&#39;Alarm4&#39;, &#39;Alarm5&#39;, &#39;Alarm6&#39;]
}

所有字符串值。]]></description>
      <guid>https://stackoverflow.com/questions/78822263/getting-error-object-array-method-not-producing-an-array-while-training-a</guid>
      <pubDate>Thu, 01 Aug 2024 17:19:22 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow model.evaluate() 不支持 None 值。如何修复？[重复]</title>
      <link>https://stackoverflow.com/questions/78822124/tensorflow-model-evaluate-none-values-not-supported-how-to-fix</link>
      <description><![CDATA[我正在尝试使用卷积自动编码器对一组图像进行异常检测。我尝试使用 model.evaluate()，但收到错误“model.evaluate() 不支持无值”
我最初的想法是使用 keras.preprocessing.image 中的 ImageDataGenerator，但后来已被弃用。我试图实现类似以下功能：
 validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(
#&#39;path to folder&#39;,
target_size=(SIZE, SIZE),
batch_size=batch_size,
class_mode=&#39;input&#39;
)

我的代码（发布如下）与此代码之间的区别在于，此代码使用“input”作为其类模式（意味着标签与输入图像相同）。我知道 model.evaluate() 不支持下面我的函数提出的 none 值，但我不知道应该用什么来替换它，因为我对此还不熟悉。
 validation_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\{}\Downloads\archive (1)\noncloud_test&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
label_mode=None
)

这是我根据 @GillesOttervanger 的建议更新的代码。
 SIZE = 128
batch_size = 64

train_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\{}\Downloads\archive (1)\noncloud_train&#39;, 
image_size=(SIZE, SIZE),
batch_size=batch_size,
)

validation_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\{}\Downloads\archive (1)\noncloud_test&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
)

anomaly_generator = preprocessing.image_dataset_from_directory(
r&#39;C:\Users\{}\Downloads\archive (1)\cloud&#39;,
image_size=(SIZE, SIZE),
batch_size=batch_size,
)

rescaling_layer = layer.Rescaling(1./255)

def change_inputs(images, labels):
x = tensorflow.image.resize(rescaling_layer(images),[SIZE, SIZE], 
method=tensorflow.image.ResizeMethod.NEAREST_NEIGHBOR)
return x, x

# 对数据集应用预处理
train_dataset = train_generator.map(change_inputs)
validation_dataset = validation_generator.map(change_inputs)
anomaly_dataset = anomaly_generator.map(change_inputs)
]]></description>
      <guid>https://stackoverflow.com/questions/78822124/tensorflow-model-evaluate-none-values-not-supported-how-to-fix</guid>
      <pubDate>Thu, 01 Aug 2024 16:45:17 GMT</pubDate>
    </item>
    <item>
      <title>AWS SageMaker createJob 不存在程序并停留在“inProgress”状态</title>
      <link>https://stackoverflow.com/questions/78821736/aws-sagemaker-createjob-not-existing-a-program-and-stuck-in-inprogress-status</link>
      <description><![CDATA[我有一个 SageMaker 作业，它运行并创建一个用于进行预测的模型。
该过程从 createProcessingJob、createTrainingJob、createModelJob 和 createTransform 开始。
我在 createProcessingJob 和 createTransform 作业中遇到了错误。
我用于 createTransformJob 的 docker 镜像是 python:3.11，我在网上研究时，尝试了多种退出代码的方法。
sys.exit(0)
os._exit(0)
os.abort()
os.kill()
os.kill(os.getpid(), singal.SIGTERM)

以上方法均无效。
我找到了这篇帖子：https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-signal-success-failure.html
它让我意识到我可能缺少权限。
但是，当我检查 AWS CloudTrail 时，我没有看到任何错误消息。
因此，目前，我找不到任何错误消息，但作业未正确完成。
我找不到该帖子，但我还看到一篇 AWS 帖子建议使用 sys.exit()。
该帖子还提到，根据图像，程序不会自行退出。
因此，如果我使用 python:3.11，我应该怎么做才能退出代码？
或者我不应该使用 python3.11？
我不想使用停止条件或手动停止并处理这种情况。]]></description>
      <guid>https://stackoverflow.com/questions/78821736/aws-sagemaker-createjob-not-existing-a-program-and-stuck-in-inprogress-status</guid>
      <pubDate>Thu, 01 Aug 2024 15:17:47 GMT</pubDate>
    </item>
    <item>
      <title>模型输出与输入具有相同的形状</title>
      <link>https://stackoverflow.com/questions/78821552/model-output-has-the-same-shape-as-the-input</link>
      <description><![CDATA[我尝试制作一个股票价格预测程序，而不是根据最后 60 个值获取单个值，而是获得一个具有不同数字的输出，其形状与输入相同，而不是单个值。
# 代码来自 colab

!pip install yfinance tensorflow==2.10.0
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import yfinance as yf
import datetime as dt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM
import tensorflow as tf

start = dt.datetime(2012,1,1)
end = dt.datetime(2020,1,1)

data = yf.download(&quot;META&quot;, start=&#39;2012-01-01&#39;, end=&#39;2020-01-01&#39;)

data = pd.DataFrame(data)
data.head()

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(data[&#39;Close&#39;].values.reshape(-1,1))

prediction_days = 60
x_train = []
y_train = []

for x in range(prediction_days,len(scaled_data)):
x_train.append(scaled_data[x-prediction_days:x,0]​​)
y_train.append(scaled_data[x,0])

x_train, y_train = np.array(x_train), np.array(y_train)
x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))
ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(32)

model = Sequential()
model.add(tf.keras.Input(shape = (60,1)))
model.add(Dense(64,activation = &#39;relu&#39;))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units = 50, return_sequences=True))
model.add(Dropout(0.2))
model.add(Dense(64,activation = &#39;relu&#39;))
model.add(Dense(1))

model.compile(optimizer = &#39;adam&#39;,loss = tf.keras.losses.MeanSquaredError())
model.fit(ds,epochs = 10)

test_data = yf.download(&quot;META&quot;, start=&#39;2020-01-01&#39;, end=&#39;2024-07-30&#39;)
actual_prices = test_data[&#39;Close&#39;].values
total_dataset = pd.concat((data[&#39;Close&#39;], test_data[&#39;Close&#39;]),axis = 0)
model_inputs = total_dataset[len(total_dataset)-len(test_data)-prediction_days:].values
model_inputs = model_inputs.reshape(-1,1)
model_inputs = scaler.transform(model_inputs)

x_test = []

对于 x in range(prediction_days, len(model_inputs)):
x_test.append(model_inputs[x-prediction_days:x,0]​​)

x_test = np.array(x_test)
x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))
print(x_test)
predicted_prices = model.predict(x_test)
print(predicted_prices)

#predicted_prices = scaler.inverse_transform(predicted_prices)

&#39;&#39;&#39;
plt.plot(actual_prices,color = &#39;black&#39;,label = &#39;实际 META 价格&#39;)
plt.plot(predicted_prices,color = &#39;green&#39;,label = &#39;预测 META 价格&#39;)
plt.title(&#39;Meta&#39;)
plt.xlabel(&#39;时间&#39;)
plt.ylabel(&#39;股票价格&#39;)
plt.legend()
plt.show()
&#39;&#39;&#39;

我尝试了不同的 tensorflow 版本和不同的损失函数，我甚至为最后一层设置了不同的激活函数，但还是不起作用。
模式的输入形状为 (60,1)，输出应该只有一个数字，但却是一个形状为 (60,1) 的随机数的完整列表（当我在我的情况下运行它时，输入形状是 (1150,60,1)并且输出也是 (1150,60,1))]]></description>
      <guid>https://stackoverflow.com/questions/78821552/model-output-has-the-same-shape-as-the-input</guid>
      <pubDate>Thu, 01 Aug 2024 14:40:25 GMT</pubDate>
    </item>
    <item>
      <title>Colab：内存不足，无法加载 Llama 3</title>
      <link>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</link>
      <description><![CDATA[我当时正在按照 Youtube 上的教程操作，想加载 Llama3 8B：
model_name = &quot;meta-llama/Meta-Llama-3-8B-Instruct&quot;

tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hugging_face_key)
model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key)

收到：“您的会话失败，因为所有可用 RAM 都已使用”
尝试：model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=hugging_face_key, low_cpu_mem_usage=True) 
但再次出现同样的错误]]></description>
      <guid>https://stackoverflow.com/questions/78821038/colab-not-enough-ram-to-load-llama-3</guid>
      <pubDate>Thu, 01 Aug 2024 12:45:03 GMT</pubDate>
    </item>
    <item>
      <title>Pyannote：离线加载并应用说话人区分</title>
      <link>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</link>
      <description><![CDATA[我尝试离线使用 Pyannotes 模型。
我是这样加载和应用模型的：
from pyannote.audio import Pipeline

access_token = &#39;xxxxxxxxxxx&#39;

model = Pipeline.from_pretrained(
&quot;pyannote/speaker-diarization-3.1&quot;,
use_auth_token=access_token)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

这样就没问题了。
但是现在我按照离线使用的说明操作：https://github.com/pyannote/pyannote-audio/blob/develop/tutorials/applying_a_pipeline.ipynb
我的目录结构如下：
src-
     |-pyannote_offline_config.yaml
     |-pyannote_pytorch_model.bin
---- YAML ----
version: 3.1.0

pipeline:
name: pyannote.audio.pipelines.SpeakerDiarization
params:
clustering: AgglomerativeClustering
embedding: pyannote/wespeaker-voxceleb-resnet34-LM
embedding_batch_size: 32
embedding_exclude_overlap: true
分段：src/pyannote_pytorch_model.bin
分段批处理大小：32

参数：
聚类：
方法：质心
min_cluster_size：12
阈值：0.7045654963945799
分段：
min_duration_off：0.0

---- 正在加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但结果却是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
好的，下次尝试：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(path_yaml)

params = {&#39;clustering&#39;:
{&#39;method&#39;: &#39;centroid&#39;,
&#39;min_cluster_size&#39;: 12,
&#39;threshold&#39;: 0.7045654963945799},
&#39;segmentation&#39;:
{&#39;min_duration_off&#39;: 0.0}}

pipeline = model.instantiate(params)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

pipeline(path_in,
num_speakers=num_speakers).labels()

但结果是：“必须先使用 pipeline.instantiate(parameters) 实例化管道，然后才能应用它。”
我不明白问题所在。
如果我这样做，它就会起作用：
---- 加载模型 ----
path_yaml = &#39;src/pyannote_offline_config.yaml&#39;

model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;, path_yaml)

path_in = &#39;blabla/1-137-A-32.wav&#39;

num_speakers = 1

model(path_in,
num_speakers=num_speakers).labels()

但上传到 gitlab 后，测试管道显示：“无法下载‘pyannote/speaker-diarization-3.1’管道。
这可能是因为管道是私有的或封闭的，因此请确保进行身份验证。访问 https://hf.co/settings/tokens
创建您的访问令牌并重试：
Pipeline.from_pretrained(&#39;pyannote/speaker-diarization-3.1&#39;,
... use_auth_token=YOUR_AUTH_TOKEN)&quot;
因此，似乎我的本地计算机上有一些东西没有通过 pip 安装下载。例如，如果我不使用 yaml 加载它，而只使用 model = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization-3.1&quot;)，它也会起作用。]]></description>
      <guid>https://stackoverflow.com/questions/78820971/pyannote-load-and-apply-speaker-diarization-offline</guid>
      <pubDate>Thu, 01 Aug 2024 12:28:41 GMT</pubDate>
    </item>
    <item>
      <title>有哪些方法可以将图像与设置融合在一起？[关闭]</title>
      <link>https://stackoverflow.com/questions/78820940/what-are-some-approaches-for-blending-an-image-in-with-a-setting</link>
      <description><![CDATA[我有一张想要放入场景中的物体图像，我尝试了几种不同的方法，以下是我最初的印象

使用物体图像和提示作为输入生成整个场景（发现物体变化太大）
覆盖绘画（结果质量不一致）
使用预选图像作为场景并通过蒙版、裁剪、重新照明、使用 opencv 添加阴影等方式添加（半手动执行此操作时效果非常好

到目前为止，第 3 种方法最有希望，这让我想到是否有任何工具或方法可以专门做到这一点，而不是我将一堆不同的增强步骤堆叠在一起？]]></description>
      <guid>https://stackoverflow.com/questions/78820940/what-are-some-approaches-for-blending-an-image-in-with-a-setting</guid>
      <pubDate>Thu, 01 Aug 2024 12:22:54 GMT</pubDate>
    </item>
    <item>
      <title>需要一些开源软件资源或代码片段来自动注释图像[关闭]</title>
      <link>https://stackoverflow.com/questions/78820910/need-some-open-source-software-resource-or-code-snippet-for-automatic-annotation</link>
      <description><![CDATA[我目前正在使用 labelImg、cvat（免费试用版）软件对图像进行手动注释。我需要一些帮助来查找用于自动注释图像的开源软件资源或代码片段。Manually_annotated_Img
我需要一些帮助来查找用于自动注释图像的开源软件资源或代码片段]]></description>
      <guid>https://stackoverflow.com/questions/78820910/need-some-open-source-software-resource-or-code-snippet-for-automatic-annotation</guid>
      <pubDate>Thu, 01 Aug 2024 12:15:53 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 llama 3 8b 训练 LLaVA-NeXT</title>
      <link>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78820834/how-to-train-llava-next-with-llama-3-8b</guid>
      <pubDate>Thu, 01 Aug 2024 11:56:36 GMT</pubDate>
    </item>
    <item>
      <title>裁剪、旋转或翻转重复项的图像识别</title>
      <link>https://stackoverflow.com/questions/78820730/image-recognition-for-cropped-rotated-or-flipped-duplicates</link>
      <description><![CDATA[多年来，我收集了大量图像，我想清除积累的重复图像。
大多数图像都可以通过寻找视觉相似性轻松找到，因为差异可能只是由于不同的 JPEG 级别而产生的压缩伪影。
但我也有一部分图像被翻转或旋转了 90/180/270 度，目前我不知道如何轻松找到它们。
我尝试的一种方法是收集所有图像的直方图“指纹”，然后强力比较所有翻转和 90 度旋转的排列与匹配对。
但后来我遇到了一个问题，即 CV2 提供的各种直方图算法对非常相似的图像有不同的假阳性和假阴性。
这仍然是减少一些重复项的一种选择，但显然并不理想。
但它无法解决裁剪图像的剩余问题。此时，我认为最好进行图像识别。
所以我想知道我应该为此研究什么。我尝试过使用 Milvus，但我从未设置过类似的东西，所以我还没有取得很大进展。
这就是为什么我要尝试看看我是否在这里寻找正确的选择，同时牢记我的要求：

它应该是开源的，或者没有前期成本，这只是一种“爱好”毕竟是项目
它应该有一个与 Python 的接口，无论它是第一方还是第三方，对我来说都无所谓
它不需要了解它在图像中看到的是什么，只需要了解以下内容：
(&quot;其他图像&quot; 表示其数据库中的图像)

&quot;此图像看起来像是另一幅图像的一部分&quot;
&quot;此图像看起来像是另一幅图像的翻转/旋转版本&quot;



我理解这显然需要首先训练识别算法，但如何做到这一点才能得到上面列出的结果也是我需要指导的事情。
例如，我如何以正确的方式准备训练图像，以便它可以学习模式而不是精确的图像。]]></description>
      <guid>https://stackoverflow.com/questions/78820730/image-recognition-for-cropped-rotated-or-flipped-duplicates</guid>
      <pubDate>Thu, 01 Aug 2024 11:30:46 GMT</pubDate>
    </item>
    <item>
      <title>如何在 TensorFlow Pipeline 中对大型数据集应用图像增强？</title>
      <link>https://stackoverflow.com/questions/78816835/how-to-apply-image-augmentations-in-tensorflow-pipeline-for-large-dataset</link>
      <description><![CDATA[我有一个图像数据集，每个图像包含一个 1 到 5 个字母的单词。我想使用深度学习对每个图像中组成单词的字符进行分类。这些图像的标签格式如下：
totalcharacter_indexoffirstchar_indexofsecondchar_.._indexoflastchar
我正尝试将这些图像加载到 TensorFlow 管道中，以降低由于内存限制而导致的复杂性。下面是我从目录加载和处理图像和标签的代码：
def process_img(file_path):
label = get_label(file_path)
image = tf.io.read_file(file_path)
image = tf.image.decode_png(image, channels=1) 
image = tf.image.convert_image_dtype(image, tf.float32) 
target_shape = [695, 1204]
image = tf.image.resize_with_crop_or_pad(image, target_shape[0], target_shape[1])

# 对标签进行编码
coded_label = tf.py_function(func=encode_label, inp=[label], Tout=tf.float32)
coded_label.set_shape([5, len(urdu_alphabets)])

return image,coded_label
input_dir = &#39;/kaggle/input/dataset/Data/*&#39;
images_ds = tf.data.Dataset.list_files(input_dir, shuffle=True)

train_count = int(tf.math.round(len(images_ds) * 0.8))
train_ds = images_ds.take(train_count)
test_ds = images_ds.skip(train_count)
train_ds = train_ds.map(process_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.map(process_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.batch(32)
train_ds = train_ds.cache()
test_ds = test_ds.cache()
train_ds = train_ds.shuffle(len(train_ds))
test_ds = test_ds.prefetch(tf.data.AUTOTUNE)
print(train_ds)
print(test_ds)

train_ds 如下所示：
&lt;_PrefetchDataset element_spec=(TensorSpec(shape=(None, 695, 1204, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5, 39), dtype=tf.float32, name=None))&gt;
现在，我想对图像应用简单的增强，例如旋转、剪切、侵蚀和扩张。我最初使用了以下函数：
def augment(image, label):
image = tf.image.random_flip_left_right(image)
image = tf.image.random_flip_up_down(image)
image = tf.keras.preprocessing.image.random_rotation(image, rg=15, row_axis=0, col_axis=1, channel_axis=2, fill_mode=&#39;nearest&#39;, cval=0.0, interpolation_order=1)
image = tf.image.random_zoom(image, [0.85, 0.85])
image = tf.image.random_shear(image, 0.3)
image = tf.image.random_shift(image, 0.1, 0.1)
return image, label

train_augmented_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)
train_augmented_ds = train_augmented_ds.prefetch(buffer_size=tf.data.AUTOTUNE)

但是，tf.image 中的许多函数都已弃用。如何以高效的方式在 TensorFlow 管道中将这些增强应用于图像？
注意：我可以通过不使用 TensorFlow 管道使用 NumPy 数组加载图像来执行这些增强，但我的数据集非常大（110 万张图像），因此我需要一种高效的方法来执行此操作。]]></description>
      <guid>https://stackoverflow.com/questions/78816835/how-to-apply-image-augmentations-in-tensorflow-pipeline-for-large-dataset</guid>
      <pubDate>Wed, 31 Jul 2024 14:11:01 GMT</pubDate>
    </item>
    <item>
      <title>如何在线托管 TensorFlow 模型</title>
      <link>https://stackoverflow.com/questions/76187823/how-to-host-tensorflow-model-online</link>
      <description><![CDATA[我正在尝试使用 TensorFlow Serving 将 ML 模型作为 REST API 提供服务。我想知道是否有办法在线托管模型而不是本地托管？
我需要托管一个 ML 模型，其中在进行预测时有一个与字符串 id 相关的映射。该模型是一个 .h5 文件。该程序在笔记本中运行。但在开发移动应用程序时，我不知道如何进行托管。]]></description>
      <guid>https://stackoverflow.com/questions/76187823/how-to-host-tensorflow-model-online</guid>
      <pubDate>Sat, 06 May 2023 08:09:39 GMT</pubDate>
    </item>
    <item>
      <title>对分类任务进行投票</title>
      <link>https://stackoverflow.com/questions/74401221/performing-voting-for-classification-tasks</link>
      <description><![CDATA[我想知道是否可以对分类任务进行投票。我看过很多博客解释如何使用投票进行回归。如下所示。
# 使用默认参数初始化所有模型对象
model_1 = LinearRegression()
model_2 = xgb.XGBRegressor()
model_3 = RandomForestRegressor()

# 在训练数据集上训练所有模型
model_1.fit(X_train, y_target)
model_2.fit(X_train, y_target)
model_3.fit(X_train, y_target)

# 在验证数据集上预测输出
pred_1 = model_1.predict(X_test)
pred_2 = model_2.predict(X_test)
pred_3 = model_3.predict(X_test)

# 对所有 3 个模型的预测取平均值后的最终预测
pred_final = (pred_1+pred_2+pred_3)/3.0

# 打印实际值与预测值之间的均方误差
print(mean_squared_error(y_test, pred_final))
]]></description>
      <guid>https://stackoverflow.com/questions/74401221/performing-voting-for-classification-tasks</guid>
      <pubDate>Fri, 11 Nov 2022 10:34:58 GMT</pubDate>
    </item>
    <item>
      <title>如何计算最佳批次大小？</title>
      <link>https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size</link>
      <description><![CDATA[有时我会遇到一个问题：
分配形状为
的张量时发生 OOM
例如
分配形状为 (1024, 100, 160) 的张量时发生 OOM

其中 1024 是我的批处理大小，我不知道其余的是多少。如果我减少批处理大小或模型中的神经元数量，它就会运行良好。
是否有一种通用方法可以根据模型和 GPU 内存计算最佳批处理大小，这样程序就不会崩溃？
简而言之：我希望我的模型的批处理大小尽可能大，这将适合我的 GPU 内存并且不会使程序崩溃。]]></description>
      <guid>https://stackoverflow.com/questions/46654424/how-to-calculate-optimal-batch-size</guid>
      <pubDate>Mon, 09 Oct 2017 20:25:09 GMT</pubDate>
    </item>
    </channel>
</rss>