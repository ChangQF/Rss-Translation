<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Sat, 09 Mar 2024 18:15:26 GMT</lastBuildDate>
    <item>
      <title>如何计算微调稳定扩散模型的Inception Score</title>
      <link>https://stackoverflow.com/questions/78133289/how-to-calculate-inception-score-of-fine-tune-stable-diffusion-model</link>
      <description><![CDATA[我想计算稳定扩散模型的初始分数，我找到了分数代码，但不确定如何生成.npz
我们使用稳定扩散 1.5 进行微调
我想知道如何计算稳定扩散的初始分数以及 FID 等其他参数]]></description>
      <guid>https://stackoverflow.com/questions/78133289/how-to-calculate-inception-score-of-fine-tune-stable-diffusion-model</guid>
      <pubDate>Sat, 09 Mar 2024 17:40:54 GMT</pubDate>
    </item>
    <item>
      <title>构建新的推荐系统[关闭]</title>
      <link>https://stackoverflow.com/questions/78132563/building-new-recommender-system</link>
      <description><![CDATA[构建新闻推荐系统，使用什么样的推荐模型，基于什么进行推荐，如何收集新闻推荐系统的数据？此外，我需要相同的示例数据。

如何收集相关数据？
我需要示例数据。
]]></description>
      <guid>https://stackoverflow.com/questions/78132563/building-new-recommender-system</guid>
      <pubDate>Sat, 09 Mar 2024 13:48:55 GMT</pubDate>
    </item>
    <item>
      <title>使用mutual_info_classif进行多类目标和特征选择[关闭]</title>
      <link>https://stackoverflow.com/questions/78132544/multi-class-target-and-feature-selection-using-mutual-info-classif</link>
      <description><![CDATA[假设数据集有 1500 个特征、2500 个实例和 7 个类（类别/目标）。
在多类分类的情况下，目标列将有 7 个不同的值。我想使用mutual_info_classif提取重要特征。 mutual_info_classif 会按预期工作吗？
我已经完成了代码并得到了结果。我不太确定结果的有效性。]]></description>
      <guid>https://stackoverflow.com/questions/78132544/multi-class-target-and-feature-selection-using-mutual-info-classif</guid>
      <pubDate>Sat, 09 Mar 2024 13:43:09 GMT</pubDate>
    </item>
    <item>
      <title>准确度为 90%，RMSE 值也很低，但验证损失图在我的 LSTM 模型中有很多尖峰。我怎样才能解决这个问题？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78132521/accuracy-is-90-rmse-values-is-also-low-but-validation-loss-graph-has-alot-of-s</link>
      <description><![CDATA[我创建了一个用于时间序列预测的 LSTM 模型。我的价值观如下，
测试集的 RMSE 分数：1.55
测试集的准确度：89.8838968601839

我的验证损失图中有很多峰值，如下所示。如何减少峰值并修复此图表？

我的代码如下，
从 keras.models 导入顺序

def lstm_model(trainX,trainY):
  #创建堆叠的 LSTM 模型
  模型=顺序（）
  model.add(LSTM(64,activation=&#39;relu&#39;,input_shape=(trainX.shape[1],trainX.shape[2]),return_sequences=False))
  模型.add(Dropout(0.2))
  model.add(密集(1))
  # 编译模型
  model.compile(optimizer=&#39;adam&#39;, loss=&#39;mse&#39;)

  print(&quot;LSTM 模型摘要&quot;)
  打印（模型.摘要（））
  打印(“---------------------------------------------- ----------”）

  # 拟合模型
  历史= model.fit（trainX，trainY，epochs = 200，batch_size = 8，validation_split = 0.01，verbose = 1）
  打印（历史）
  打印(“---------------------------------------------- ----------”）

  #model.save(&#39;/content/gdrive/MyDrive/MScProject/Implementation/lstm.h5&#39;)
  位置 = &#39;/content/gdrive/MyDrive/MScProject/Implementation/&#39; + 银行名称 + &#39;/lstm.h5&#39;
  模型.保存（位置）

  rmse = evaluate_models(历史, 模型)
  返回均方根误差

rmse = lstm_model(trainX,trainY)
模型测试（rmse）
]]></description>
      <guid>https://stackoverflow.com/questions/78132521/accuracy-is-90-rmse-values-is-also-low-but-validation-loss-graph-has-alot-of-s</guid>
      <pubDate>Sat, 09 Mar 2024 13:36:46 GMT</pubDate>
    </item>
    <item>
      <title>如何将包含得分值的列与其余列的 knn 得分相结合</title>
      <link>https://stackoverflow.com/questions/78132065/how-to-combine-a-column-containing-score-value-with-knn-score-of-rest-of-the-col</link>
      <description><![CDATA[假设我有一个包含 3 列的数据框，如下所示：

&lt;标题&gt;

得分
一个
B


&lt;正文&gt;

0.9953
1
0


0.5436
0
1



我计算了字符串列的相似度得分并将其添加到数据框中。现在对于 A 列和 B 列（也是字符串数据），我已对其进行编码并将其传递给 knn。该 knn 模型根据相似度分数生成最近邻。现在，我仅使用 A 和 B 获得最近邻居。我应该如何将 Score 列与此模型合并？我最近开始探索机器学习，因此非常感谢您在这方面的帮助。
我想做的就是采用阈值并根据分数列过滤 df，然后将这个新的 df 传递给 knn 模型。或者首先从 knn 模型中获取最近的邻居，然后，我考虑将这些邻居数据的 knn 分数与“分数”列相加，然后对数据帧进行排序以获得最相似的数据。但我认为这不是正确的方法。]]></description>
      <guid>https://stackoverflow.com/questions/78132065/how-to-combine-a-column-containing-score-value-with-knn-score-of-rest-of-the-col</guid>
      <pubDate>Sat, 09 Mar 2024 10:54:08 GMT</pubDate>
    </item>
    <item>
      <title>转换 Y 标签以执行多标签分类</title>
      <link>https://stackoverflow.com/questions/78132000/transforming-y-label-to-perform-multi-label-classification</link>
      <description><![CDATA[我正在尝试在  上实现多标签分类澳大利亚技能分类数据集，我必须在其中从单个实体的 600 个职位中预测出符合个人资料的多个职位。
问题是我无法将“ANZSCO_Title”转换为“ANZSCO_Title”。以某种方式我可以对其应用多标签分类。
请提出解决方案。
我尝试直接在其上使用 LabelBinarizer，但这给了我每行 598 个零和 1 个一。
我需要一个 y 标签，其中这 600 个标题位于单独的列中，根据是否符合分数标记为 1 或 0。
目前供参考“ANZSCO_Title”看起来像这样：数据集示例
但我希望所有标题都是单独的列，以便我可以对其应用 MultiLabelBinarizer。]]></description>
      <guid>https://stackoverflow.com/questions/78132000/transforming-y-label-to-perform-multi-label-classification</guid>
      <pubDate>Sat, 09 Mar 2024 10:28:45 GMT</pubDate>
    </item>
    <item>
      <title>我已经在 Streamlit 上部署了模型 [关闭]</title>
      <link>https://stackoverflow.com/questions/78131982/i-had-deploying-the-model-on-streamlit</link>
      <description><![CDATA[ 文件 ~\anaconda3\Lib\site-packages\keras\src\engine\base_layer.py:3531 在 load_own_variables 中
    引发值错误（

ValueError：层“embedding_1”需要 1 个变量，但在加载期间收到 0 个变量。预期：[&#39;embedding_1/embeddings:0&#39;]

请给我解决方案]]></description>
      <guid>https://stackoverflow.com/questions/78131982/i-had-deploying-the-model-on-streamlit</guid>
      <pubDate>Sat, 09 Mar 2024 10:22:14 GMT</pubDate>
    </item>
    <item>
      <title>idae 关于定义强化学习中的临时行动 [关闭]</title>
      <link>https://stackoverflow.com/questions/78131909/idae-on-defining-the-temporary-action-in-reinforcement-learning</link>
      <description><![CDATA[有功能和操作的列表。我希望程序进行强化学习，通过观察代码的输入来预测下一行要写什么。
特征 = [a,b,c,d]
操作 = [+,-,*,/,平均值,众数,中位数,...)
# 观察空间为以下代码块

#####观察####
缓存_1 = a+b
缓存_2 = b+c/a
####结束观察###
cache_3 = cache_1 + cache_2 # 动作/预测

假设有两种类型的输出：features_selection 和operators_selection。在特征选择中，最后一层将有 4 个输出：[a,b,c,d]。我的问题是如何使 tem 输入（上例中的 cache_1 和 cache_2）也包含在最后一层中，或者对这些额外输入有任何想法。
如果我们只限制在程序上使用2个缓存，它将是[a,b,c,d,cache_1,cache_2]，但是缓存在不同的任务和观察中会有不同的含义。
有什么好的办法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78131909/idae-on-defining-the-temporary-action-in-reinforcement-learning</guid>
      <pubDate>Sat, 09 Mar 2024 09:55:13 GMT</pubDate>
    </item>
    <item>
      <title>当只有一个输出时，“loss_weights”参数必须是 Python 浮点数。收到的是：loss_weights=[0.5] 类型 <class 'list'> [关闭]</title>
      <link>https://stackoverflow.com/questions/78131388/when-there-is-only-a-single-output-the-loss-weights-argument-must-be-a-python</link>
      <description><![CDATA[model = Model([in_src, in_tar],out)
model.compile(优化器 = Adam(0.0002,0.5), loss = &#39;binary_crossentropy&#39;, loss_weights = [0.5])

训练时出现错误：
ValueError：当只有一个输出时，“loss_weights”参数必须
是一个Python浮点数。相反收到：loss_weights=[0.5] of type 

但是，如果我将其替换为 0.5 而不是 [0.5]，则会在编译时出现错误：
ValueError：预期的“loss_weights”参数是列表、元组或字典。
相反收到：loss_weights=0.5 类型 

有趣的是，我复制此代码的上一个笔记本没有给出任何错误并且工作正常
tensorflow版本为2.15.0]]></description>
      <guid>https://stackoverflow.com/questions/78131388/when-there-is-only-a-single-output-the-loss-weights-argument-must-be-a-python</guid>
      <pubDate>Sat, 09 Mar 2024 06:02:09 GMT</pubDate>
    </item>
    <item>
      <title>ValueError：无法将字符串转换为浮点数：'Curtis RIngraham Directge'</title>
      <link>https://stackoverflow.com/questions/78131238/valueerror-could-not-convert-string-to-float-curtis-ringraham-directge</link>
      <description><![CDATA[我正在进行数据分割和交叉验证。
对于数据分割，我需要仅提取测试数据集，并保留其余数据以进行交叉验证。我在交叉验证结束时收到 ValueError: Could not conversion string to float: &#39;Curtis RIngraham Directge&#39; 错误。我应该如何修复它？
数据分割
from sklearn.model_selection import train_test_split
从 sklearn.model_selection 导入 KFold

# 首先提取我们的测试数据并将其存储在x_test, y_test中
特征 = features_df.to_numpy()
标签 = labels_df.to_numpy()
_x, x_test, _y, y_test = train_test_split(特征, 标签, test_size=0.10, random_state=42)

# 设置 k = 5
k = 5

kfold_spliter = KFold(n_splits=k)

Folds_data = [] # 这是一种低效的方法，但仍然这样做

折叠 = 1
对于 kfold_spliter.split(_x) 中的 train_index、validation_index：
    x_train , x_valid = _x[train_index,:],_x[validation_index,:]
    y_train , y_valid = _y[train_index,:] , _y[validation_index,:]
    print (f&quot;Fold {fold} 训练数据形状 = {(x_train.shape,y_train.shape)}&quot;)
    print (f&quot;折叠{fold}验证数据形状 = {(x_valid.shape,y_valid.shape)}&quot;)
    折叠+=1
    Folds_data.append((x_train,y_train,x_valid,y_valid))

交叉验证
best_validation_accuracy = 0
最佳模型名称=“”
最佳模型=无

# 迭代所有模型
对于 all_models.keys() 中的 model_name：

    print (f“评估 {model_name} ...”)
    模型 = all_models[模型名称]

    # 让我们存储所有折叠的训练和验证精度
    train_acc_for_all_folds = []
    valid_acc_for_all_folds = []

    #迭代所有折叠
    对于 i，折叠 enumerate(folds_data)：
        x_train、y_train、x_valid、y_valid = 折叠

        # 训练模型
        _ = model.fit(x_train,y_train.flatten())

        # 根据训练数据评估模型
        y_pred_train = model.predict(x_train)

        # 根据验证数据评估模型
        y_pred_valid = model.predict(x_valid)

        # 计算训练准确率
        train_acc = precision_score(y_pred_train , y_train)

        # 存储每次折叠的训练准确率
        train_acc_for_all_folds.append(train_acc)

        # 计算验证准确率
        valid_acc = precision_score(y_pred_valid , y_valid.flatten())

        # 存储每次折叠的验证准确性
        valid_acc_for_all_folds.append(valid_acc)

    #k 次折叠的平均训练准确度
    avg_training_acc = sum(train_acc_for_all_folds)/k

    print (f“模型 {model_name} = {avg_training_acc} 的平均训练精度”)

    #k 次折叠的平均验证准确度
    avg_validation_acc = sum(valid_acc_for_all_folds)/k

    print (f“模型 {model_name} = {avg_validation_acc} 的平均验证精度”)

    # 根据平均验证准确度选择最佳模型
    如果 avg_validation_acc &gt;最佳验证准确度：
        最佳验证准确度 = 平均验证准确度
        最佳型号名称 = 型号名称
        最佳模型 = 模型
    打印（f“------------------------------------”）

print (f“任务的最佳模型是 {best_model_name}，其验证精度为 {best_validation_accuracy}”)

尝试查找任何剩余的 x_train、y_train、x_valid 和 y_valid 字符串值，但找不到任何值。]]></description>
      <guid>https://stackoverflow.com/questions/78131238/valueerror-could-not-convert-string-to-float-curtis-ringraham-directge</guid>
      <pubDate>Sat, 09 Mar 2024 04:32:23 GMT</pubDate>
    </item>
    <item>
      <title>使用 detectorron2 训练 Mask RCNN 自定义实例分割找到混淆矩阵、f1 分数、IOU</title>
      <link>https://stackoverflow.com/questions/78131227/using-detectron2-to-train-mask-rcnn-custom-instance-segmentation-to-find-confusi</link>
      <description><![CDATA[我正在使用 detectorron2 和 pytorch 进行自定义对象检测（Mask RCNN）。
评估结果
所以，上图就是我训练的评估结果。如何编码准确度、精度、F1 分数和混淆矩阵？
我从中获取的训练代码
https://github.com/ahmad12hamdan99/Rovers_vs_Cars/blob/main/detectron2。 ipynb
下面我展示了训练的示例代码，也可以从上面的链接获取
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
训练师.train()

# 查看张量板中的训练曲线：
%reload_ext 张量板
%tensorboard --logdir $OUTPUT_DIR_PATH

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR,
“model_final.pth”）
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7
预测器 = DefaultPredictor(cfg)

dataset_valid = DatasetCatalog.get(VALID_DATA_SET_NAME)

对于 dataset_valid 中的 d：
    img = cv2.imread(d[“文件名”])
    输出 = 预测器(img)
    
    可视化工具 = 可视化工具（
        img[:, :, ::-1],
        元数据=元数据，
        比例=0.8，
        instance_mode=ColorMode.IMAGE_BW
    ）
    输出 =





  Visualizer.draw_instance_predictions(输出[“实例”]。
       to(“cpu”))cv2_imshow(out.get_image()[:, :, ::-1])

从 detectorron2.evaluation 导入 COCOEvaluator，
 数据集推理
从 detector2.data 导入 build_detection_test_loader
evaluator = COCOEvaluator(“分段测试”,
输出目录=cfg.OUTPUT_DIR)
val_loader = build_detection_test_loader(cfg, “分段测试”)
打印（inference_on_dataset（预测器.模型，val_loader，评估器））
]]></description>
      <guid>https://stackoverflow.com/questions/78131227/using-detectron2-to-train-mask-rcnn-custom-instance-segmentation-to-find-confusi</guid>
      <pubDate>Sat, 09 Mar 2024 04:25:12 GMT</pubDate>
    </item>
    <item>
      <title>模型性能评估[关闭]</title>
      <link>https://stackoverflow.com/questions/78131181/model-performance-evaluation</link>
      <description><![CDATA[我正在 Open AI Gym 中制作一个具有稳定基线的自定义 Boid 植绒环境 3。 
它是如何工作的：

我传递了 boids 的位置文件。
对其进行 3000 个时间步长的模型测试，并输出每集的奖励，即位置文件

训练初始位置与测试不同。
我关心的是我的模型的性能。当从不同的初始位置陈述时，它会输出类似的奖励，并且机器人按照预期移动，我还生成了一个移动视频文件。
正确工作模型的输出
奖励功能
defcalculate_combined_reward(self,agent,neighbor_positions):
        总奖励=0
        out_of_flock=False

        if (len(neighbor_positions) &gt; 0):
            对于 neighbour_positions 中的 neighbour_position：
                
                距离 = np.linalg.norm(agent.position - neighbour_position)

                if (距离 
问题：
当我在不改变任何内容的情况下重新训练几次并进行测试时，只是为了保持一致性，它表现不佳，而且我的剧集奖励大多为负。虽然我什么也没改变。幸运的是，我保存了性能最佳的模型。
我训练并输出正确性能的模型（我已附上照片）是一个经过良好训练的模型，是侥幸还是过度拟合？]]></description>
      <guid>https://stackoverflow.com/questions/78131181/model-performance-evaluation</guid>
      <pubDate>Sat, 09 Mar 2024 03:50:52 GMT</pubDate>
    </item>
    <item>
      <title>使用迁移学习时模型不学习</title>
      <link>https://stackoverflow.com/questions/76521642/model-is-not-learning-when-using-transfer-learning</link>
      <description><![CDATA[我是机器学习的初学者，我正在尝试开发一个可以根据面部数据集预测年龄的模型。然而，我的模型没有学习，我正在努力找出原因。我正在导入 VGG16 架构，但它仍然无法学习。我已经搜索过论坛，甚至尝试仅在 2 个示例上训练模型，但它仍然无法过拟合。
在整个训练过程中，训练准确性几乎没有增加，验证准确性也没有增加。
path = “../input/agedetection/dataset/dataset”
文件= os.listdir(路径)
X = []
年龄_温度 = []

对于文件中的文件：
    img = cv2.imread(路径+&#39;/&#39;+文件)
    img = cv2.resize(img, dsize = target_size)
    X.追加（img）
    字段 = file.split(&#39;_&#39;)
    Age_temp.append(字段[0])

X = np.array(X).astype(&#39;float32&#39;)
X = X/255

#将年龄转换为不同的括号 - 0-20, 21-40, 41-60,61+
年龄 = np.zeros(len(age_temp))

对于范围内的 i(len(age_temp))：
    curr_age = int(age_temp[i])
    如果 curr_age &lt;= 20：
        值=0
    elif curr_age &lt;= 40：
        值=1
    elif curr_age &lt;= 60：
        值=2
    别的：
        值=3
    年龄[i] = val

年龄 = to_categorical(年龄, 班级数 = 4)
年龄 = 年龄.astype(&#39;float32&#39;)

base_model_age = tf.keras.applications.VGG16(input_shape=input_shape,include_top=False,weights=“imagenet”)
对于 base_model_age.layers[:-20] 中的图层：
    层.trainable=False
model_age = 顺序()
model_age.add(base_model_age)
model_age.add(压平())
model_age.add（密集（1024，激活=&#39;relu&#39;））
model_age.add（密集（4，激活=&#39;relu&#39;））

model_age.compile(优化器=Adam(亚当),
              损失=&#39;mse&#39;
              ,指标=[&#39;准确性&#39;])

hist_age = model_age.fit(X_train,age_train,
                         验证数据=（X_验证，年龄_验证），
                         epochs=10，steps_per_epoch=256，
                         回调=[lrd, mcp])
]]></description>
      <guid>https://stackoverflow.com/questions/76521642/model-is-not-learning-when-using-transfer-learning</guid>
      <pubDate>Wed, 21 Jun 2023 09:05:40 GMT</pubDate>
    </item>
    <item>
      <title>Python - 从 OLS 模型中获取排列重要性</title>
      <link>https://stackoverflow.com/questions/70623835/python-grabbing-permutation-importance-from-ols-model</link>
      <description><![CDATA[正如标题所述，我试图获取 OLS 模型中特征的排列重要性，但我得到的是：
TypeError：估计器应该是实现“fit”方法的估计器，已通过
这是我的代码：
导入 pandas 作为 pd
从 sklearn.inspection 导入 permutation_importance
从 sklearn.model_selection 导入 train_test_split
将 statsmodels.api 导入为 sm

df = pd.read_csv(r&#39;my_file&#39;)

X = df.drop（我的因变量）
y = df[我的因变量）

X_train, X_test, y_train, y_test = train_test_split(X, y)

模型 - sm.OLS(y_train, X_train).fit()
打印（模型.摘要（））

分数 = permuation_importance(模型, X_train, y_train, 评分=&#39;neg_root_mean_squared_error&#39;)

重要性 = 分数.importances_mean

对于枚举中的 i,v（重要性）：
   print(&#39;特征：%0d，得分：%.5f&#39; % (i,v))

我有一种感觉，因为我使用的模型不是来自 sklearn，所以想知道是否有办法从 OLS 模型中获取特征指标？谢谢！！]]></description>
      <guid>https://stackoverflow.com/questions/70623835/python-grabbing-permutation-importance-from-ols-model</guid>
      <pubDate>Fri, 07 Jan 2022 15:51:40 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Keras 中累积大批量的梯度</title>
      <link>https://stackoverflow.com/questions/55268762/how-to-accumulate-gradients-for-large-batch-sizes-in-keras</link>
      <description><![CDATA[我正在使用一个对内存要求很高的 CNN 模型来执行分类任务。
这对我在训练期间可以使用的批量大小造成了很大的限制。
一种解决方案是在训练期间累积梯度，这意味着模型的权重不会在每个批次后更新。相反，相同的权重用于多个批次，而每个批次的梯度会被累积，然后针对单个权重更新操作进行平均。
我正在使用 Tensorflow 后端 Keras，并且我非常确定 Keras 没有现成的函数/方法来实现此目的。
如何为 Keras/tensorflow 模型完成此操作？]]></description>
      <guid>https://stackoverflow.com/questions/55268762/how-to-accumulate-gradients-for-large-batch-sizes-in-keras</guid>
      <pubDate>Wed, 20 Mar 2019 19:26:43 GMT</pubDate>
    </item>
    </channel>
</rss>