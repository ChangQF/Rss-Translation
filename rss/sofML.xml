<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 12 Dec 2023 06:18:48 GMT</lastBuildDate>
    <item>
      <title>VS Code .ipynb 中的 FileUpload 小部件问题：显示“Upload(6)”，但数据长度返回 0</title>
      <link>https://stackoverflow.com/questions/77643801/fileupload-widget-issue-in-vs-code-ipynb-upload6-displayed-but-data-lengt</link>
      <description><![CDATA[我试图使用 widget.FileUpload() 上传文件并打印图像。但上传 6 张图像并尝试在新单元格中运行最后一行后，它返回错误，提示“索引超出范围”
btn_upload = widgets.FileUpload()
btn_上传


img = PILImage.create(btn_upload.data[-1])

在此处输入图像描述
然后我尝试了这条线
print(&quot;上传文件数：&quot;, len(btn_upload.data))
期待“6”因为这是我上传的文件数，所以它返回了 0。]]></description>
      <guid>https://stackoverflow.com/questions/77643801/fileupload-widget-issue-in-vs-code-ipynb-upload6-displayed-but-data-lengt</guid>
      <pubDate>Tue, 12 Dec 2023 05:06:16 GMT</pubDate>
    </item>
    <item>
      <title>如何利用 GPU 减少 xgboost 的处理时间？</title>
      <link>https://stackoverflow.com/questions/77643788/how-can-i-reduce-processing-time-with-xgboost-by-utilizing-my-gpu</link>
      <description><![CDATA[我正在关注数据营的本教程，他们有一件事提到的是利用 GPU 来加快处理时间。他们甚至说它“速度极快”。
然而，我看到了相反的结果。对于下面的代码块，在 10k 提升的情况下，我看到在我的 params 中传递 “hist” 大约需要 30 秒，而在 ” 中传递则只需一分多钟。 gpu_hist&quot; 与我的 params 一起传递。
使用 “gpu_hist” 时，我的 GPU 的使用率上限为 12%，使用 “hist” 时，所有 24 个逻辑核心的使用率上限为 100%
params = {“objective”: “reg:squarederror”, “tree_method”: “gpu_hist”, “subsample”: 0.8,
    “colsample_bytree”：0.8}

evals = [(dtrain_reg, “训练”),(dtest_reg, “验证”)]

n = 10000


模型 = xgb.train(
   参数=参数，
   dtrain=dtrain_reg,
   num_boost_round=n,
   评估=评估，
   详细评估=50，
）

我正在尝试在 jupyter 笔记本的 VSCode 中运行它。

我已安装 CUDA 工具包和 cuDNN
我已检查它们是否已添加到路径中
我已确保安装了正确版本的 xgboost 来使用 GPU。
数据集有 53k 行 10 列，所以我不认为数据集太小
我已确认兼容性（使用 RTX 2060）

我问过 chatGPT，在网上搜索过，甚至问过我正在学习的课程中的导师，但无法诊断为什么“gpu_hist”花费了这么长时间。 vs 只是“历史”。
4 个月前在 stackoverflow 上还有另一个类似问题零回应。如有任何帮助，我们将不胜感激！]]></description>
      <guid>https://stackoverflow.com/questions/77643788/how-can-i-reduce-processing-time-with-xgboost-by-utilizing-my-gpu</guid>
      <pubDate>Tue, 12 Dec 2023 05:02:17 GMT</pubDate>
    </item>
    <item>
      <title>在 Java 中包含 Python 分类器模型</title>
      <link>https://stackoverflow.com/questions/77643780/include-python-classifier-model-in-java</link>
      <description><![CDATA[我已经用 Python 开发了一个 ML 分类器模型，我想从 java 中使用它。
我查找了一些选项，例如 Jython 等。
谁能帮助我，我怎样才能实现这个用例？
我尝试使用 Jython，但没有找到适合此用例的任何好的文档]]></description>
      <guid>https://stackoverflow.com/questions/77643780/include-python-classifier-model-in-java</guid>
      <pubDate>Tue, 12 Dec 2023 04:58:16 GMT</pubDate>
    </item>
    <item>
      <title>如何使用坐标 X、Y 和图像训练深度学习模型？</title>
      <link>https://stackoverflow.com/questions/77643418/how-can-i-train-a-deep-learning-model-with-coordinates-x-y-and-images</link>
      <description><![CDATA[我的任务是头影测量地标定位。
我的图像路径的坐标显示在此数据框中。

&lt;表类=“s-表”&gt;
&lt;标题&gt;

文件名
X1
Y1


&lt;正文&gt;

/Images_data/binary0006.png
89
80


/Images_data/binary0008.png
37
70


/Images_data/binary0007.png
50
76


/Images_data/binary0003.png
55
92


/Images_data/binary0005.png
91
64


/Images_data/binary0004.png
100
76




如何准备用于 model.fit 训练的数据集？
我尝试使用 ImageDataGenerator 创建用于训练的图像数据集。
 train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  数据目录，
  label_mode=无，
  验证分割=0.2，
  子集=“训练”，
  种子=123，
  图像大小=（img_高度，img_宽度），
  批量大小=批量大小）

但现在我陷入困境，因为我不知道如何将坐标与图像匹配。]]></description>
      <guid>https://stackoverflow.com/questions/77643418/how-can-i-train-a-deep-learning-model-with-coordinates-x-y-and-images</guid>
      <pubDate>Tue, 12 Dec 2023 02:46:05 GMT</pubDate>
    </item>
    <item>
      <title>为什么我的模型能够在数据集上进行训练和测试，但在添加 SoftMax 层并要求其进行预测时出现错误？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77642982/how-come-my-model-is-able-to-train-and-test-on-a-dataset-but-gives-an-error-when</guid>
      <pubDate>Mon, 11 Dec 2023 23:58:34 GMT</pubDate>
    </item>
    <item>
      <title>交叉验证和标准缩放，以便在每次迭代时对训练部分进行 fit_transformed，而验证部分仅进行变换</title>
      <link>https://stackoverflow.com/questions/77642740/cross-validation-and-standard-scaling-so-that-on-each-iteration-the-train-part-i</link>
      <description><![CDATA[我有 X 数据，我想要进行交叉验证，并且我需要以某种方式在交叉验证的每次迭代中使用 StandardScaler，因此它的训练部分是 fit_transformed，而它的验证部分仅进行转换。我应该如何将其包含在逻辑中。我正在使用 LGBM 模型。
我很困惑如何处理它]]></description>
      <guid>https://stackoverflow.com/questions/77642740/cross-validation-and-standard-scaling-so-that-on-each-iteration-the-train-part-i</guid>
      <pubDate>Mon, 11 Dec 2023 22:38:00 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 openai 和 langchain 将已创建的 chromadb 集合与法学硕士一起使用？</title>
      <link>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</link>
      <description><![CDATA[我已经使用其文档和元数据创建了 chromadb 集合。
问题是当我想使用 langchain 创建 llm 并传递此 chromadb 集合以用作知识库时。
langchain_chroma = 色度(
客户端=持久客户端，
集合名称=集合.名称,
embedding_function = openai_ef，
）

llm_model =“gtp35turbo-最新”

llm = AzureChatOpenAI(
   api_key=openai_api_key,
   api_version=openai_api_version,
   azure_endpoint=openai_api_base,
   模型=llm_模型）

qa_chain = RetrievalQA.from_chain_type(
   嗯，
   检索器=langchain_chroma.as_retriever(),
   chain_type=&quot;精炼&quot;
）

当我想跑步时：
qa_chain.run(“对象检测问题需要多少数据科学家”)

我收到此错误：
AttributeError Traceback（最近一次调用最后一次）
&lt;ipython-input-81-3cdb65aeb43e&gt;在&lt;细胞系：1&gt;()
----&gt; 1 qa.run(“对象检测问题需要多少数据科学家”)

9帧
/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py 中相似性_search_with_score（自我，查询，k，过滤器，where_document，**kwargs）
    第430章）
    第431章：
--&gt;第432章
    第433章
    第434章

AttributeError：“OpenAIEmbeddingFunction”对象没有属性“embed_query”

如何解决？]]></description>
      <guid>https://stackoverflow.com/questions/77642444/how-can-you-use-an-already-created-chromadb-collection-with-a-llm-using-openai-a</guid>
      <pubDate>Mon, 11 Dec 2023 21:17:23 GMT</pubDate>
    </item>
    <item>
      <title>设计神经网络时，如何调用 keras.NonNeg()？</title>
      <link>https://stackoverflow.com/questions/77642420/when-designing-a-neural-network-how-do-i-call-keras-nonneg</link>
      <description><![CDATA[我试图确保我的 y 值都不为负数。我找不到代码示例。如何使用这个功能？
在构建模型的函数中，我将该函数放在 model.add 函数之上。我希望我的 y 值都不会为负。]]></description>
      <guid>https://stackoverflow.com/questions/77642420/when-designing-a-neural-network-how-do-i-call-keras-nonneg</guid>
      <pubDate>Mon, 11 Dec 2023 21:13:19 GMT</pubDate>
    </item>
    <item>
      <title>没有属性。切换到 mps 时出现张量列表错误 [关闭]</title>
      <link>https://stackoverflow.com/questions/77641848/no-attribute-to-error-for-a-list-of-tensors-while-switching-to-mps</link>
      <description><![CDATA[defforward(self,fft_result_tensors):
    # 前向通过网络

    # 如果可用的话使用 MPS（可选）
    尝试：
       导入 torch.backends.mps
       可用=真
    除了导入错误：
                      可用=假

    如果可用：
                   设备=“mps”；
                   fft_result_tensors = [fft_result_tensors 中张量的tensor.to(device)]
                   自身到（设备）

错误：
&lt;前&gt;&lt;代码&gt;&gt; 77 fft_result_tensors = fft_result_tensors.to（设备）
     78 自传（设备）
     80 # 在将输入提供给模型之前对其进行压缩

AttributeError：“列表”对象没有属性“to”

我添加了for ...in，但仍然不起作用]]></description>
      <guid>https://stackoverflow.com/questions/77641848/no-attribute-to-error-for-a-list-of-tensors-while-switching-to-mps</guid>
      <pubDate>Mon, 11 Dec 2023 19:06:53 GMT</pubDate>
    </item>
    <item>
      <title>获取标准普尔成分股的股票方向[关闭]</title>
      <link>https://stackoverflow.com/questions/77641810/getting-the-stock-direction-of-the-sp-components</link>
      <description><![CDATA[我们通常使用一两只股票作为线性回归的自变量（例如 SPX 和 GOOG），并使用 AAPL 作为因变量，用于预测 AAPL 股票的方向。
假设我们使用所有 S&amp;P500 成分，每个成分都有自己的功能，例如收盘价、移动平均线、相对强弱指数&lt; /code&gt;, ..etc，我们使用 80% 的 S&amp;P500 成分作为训练集，20% 作为测试数据集。
我需要什么类型的机器学习技术来实现此模型？]]></description>
      <guid>https://stackoverflow.com/questions/77641810/getting-the-stock-direction-of-the-sp-components</guid>
      <pubDate>Mon, 11 Dec 2023 18:57:47 GMT</pubDate>
    </item>
    <item>
      <title>如何创建实时预测代码？</title>
      <link>https://stackoverflow.com/questions/77641103/how-do-i-create-a-real-time-prediction-code</link>
      <description><![CDATA[我想创建一个实时基本手语翻译器来翻译字母和数字。我使用 CNN 完成了训练，我可以通过将新图像放入文件并运行比较来测试新图像。我如何使其实时？
我尝试了网上建议的一些步骤，但相机似乎没有检测到我的手，而且准确性很糟糕
导入操作系统
将张量流导入为 tf
将 numpy 导入为 np
导入路径库
导入 json

使用 open(“model_arch.json”, “r”) 作为 json_file：
    model_json = json_file.read()

模型 = tf.keras.models.model_from_json(model_json)
model.load_weights(“model_weights.h5”)

data_dir = pathlib.Path(&#39;C:\\Users\\User\\Documents\\FYP\\FYP\\data&#39;)
图像高度 = 180
图像宽度 = 180

train_ds = tf.keras.utils.image_dataset_from_directory(
    数据目录，
    验证分割=0.2，
    子集=“训练”，
    种子=123，
    图像大小=（img_高度，img_宽度），
    批量大小=32
）

类名=train_ds.类名

test_directory = &quot;C:\\Users\\User\\Documents\\FYP\\FYP\\test&quot;;
image_count = len(列表(data_dir.glob(&#39;*/*.jpeg&#39;)))
test_image_paths = [os.path.join(test_directory, f) for f in os.listdir(test_directory) if f.lower().endswith(&#39;.jpeg&#39;)]

如果不是 test_image_paths：
    print(“在指定的测试目录中找不到 JPEG 图像。”)
    出口（）

对于 test_image_paths 中的 test_image_path：
    尝试：
        img = tf.keras.utils.load_img(
            test_image_path, target_size=(img_height, img_width)
        ）
    除了异常 e：
        print(f“加载图像 {test_image_path} 时出错：{e}”)
        继续

    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    预测 = model.predict(img_array)
    分数 = tf.nn.softmax(预测[0])

    预测类别 = 类别名称[np.argmax(分数)]
    置信度 = 100 * np.max(分数)

    打印（
        f“图像最有可能属于具有{置信度：.2f}％置信度的{预测_类}类。”
    ）
]]></description>
      <guid>https://stackoverflow.com/questions/77641103/how-do-i-create-a-real-time-prediction-code</guid>
      <pubDate>Mon, 11 Dec 2023 16:43:36 GMT</pubDate>
    </item>
    <item>
      <title>RuntimeError：输入类型（无符号字符）和偏差类型（浮点）应该相同</title>
      <link>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77639321/runtimeerror-input-type-unsigned-char-and-bias-type-float-should-be-the-sam</guid>
      <pubDate>Mon, 11 Dec 2023 11:43:29 GMT</pubDate>
    </item>
    <item>
      <title>MSE 值远大于应有的值 [关闭]</title>
      <link>https://stackoverflow.com/questions/77607939/mse-value-is-way-bigger-than-it-should-be</link>
      <description><![CDATA[知道我在这里做错了什么吗：
我的数据集约为 20k 行，mse 约为 11298955095.811989，我不太确定我做错了什么？
我试图找到哪个数据集以及哪个 k 给出最小值，但没有一个值有任何意义：
随机导入
def split_df(数据帧):
    data_rows = dataframe.values.tolist()

    随机播放（数据行）

    训练值 = 0.7
    split_index = int(len(data_rows) * train_val)

    train_data = data_rows[:split_index]
    test_data = data_rows[split_index:]

    train_df = pd.DataFrame(train_data, columns=dataframe.columns)
    test_df = pd.DataFrame(test_data, columns=dataframe.columns)

    返回train_df、test_df

从 sklearn.neighbors 导入 KNeighborsRegressor
从 sklearn.metrics 导入mean_squared_error

数据帧 = [no_nulls、outliers_removed、mean_impulated、median_impulated]
目标 = &#39;中位房屋价值&#39;
k_vals = 范围(1, 30)

对于数据帧中的 df：
    mse_字典 = {}
    X = df.drop(columns=[target]) # 特征
    y = df[target] # 目标变量

    # 将数据分为训练和测试
    train_df, test_df = split_df(df)

    # 训练和测试的单独特征和目标变量
    X_train = train_df.drop(列=[目标])
    y_train = train_df[目标]
    X_test = test_df.drop(列=[目标])
    y_test = test_df[目标]
    
    对于 k_vals 中的 k：
        knn_regressor = KNeighborsRegressor(n_neighbors=k)
        knn_regressor.fit(X_train, y_train)
        预测 = knn_regressor.predict(X_test)
        squared_errors = (预测 - y_test) ** 2 # 计算平方误差
        mse = squared_errors.mean() # 计算平方误差的平均值以获得 MSE
        mse_dictionary[k] = mse

    print(f“数据帧 {df} 的 MSE 字典：{mse_dictionary}”)
    # 用于调试的附加信息
    print(f&quot;最大 MSE: {max(mse_dictionary.values())}&quot;)
    print(f&quot;最小 MSE: {min(mse_dictionary.values())}&quot;)
    print(f&quot;平均 MSE: {sum(mse_dictionary.values()) / len(mse_dictionary)}&quot;)
]]></description>
      <guid>https://stackoverflow.com/questions/77607939/mse-value-is-way-bigger-than-it-should-be</guid>
      <pubDate>Tue, 05 Dec 2023 16:54:01 GMT</pubDate>
    </item>
    <item>
      <title>使用 ConvNext 分类器层</title>
      <link>https://stackoverflow.com/questions/74965058/use-the-convnext-classifier-layer</link>
      <description><![CDATA[Convnext 的源代码内部：
self.classifier = nn.Sequential(
    norm_layer(lastconv_output_channels), nn.Flatten(1), nn.Linear(lastconv_output_channels, num_classes)
）

当我调用预训练模型并且我想在分类器层中进行更改时，norm_layer未定义，我不知道如何从源代码中使用它
模型 = torchvision.models.convnext_base(prtrained=True, stochastic_depth_prob=0.1,
                                         层规模=1e-4)

model.classifier = nn.Sequential(
   **norm_layer**(1024), nn.Flatten(1), nn.Linear(1024, 7)
）

请问谁能帮忙写正确吗？]]></description>
      <guid>https://stackoverflow.com/questions/74965058/use-the-convnext-classifier-layer</guid>
      <pubDate>Fri, 30 Dec 2022 19:14:20 GMT</pubDate>
    </item>
    <item>
      <title>Vowpal Wabbit：低阶矩阵分解？</title>
      <link>https://stackoverflow.com/questions/39040721/vowpal-wabbit-low-rank-matrix-factorization</link>
      <description><![CDATA[我有一个非常基本的问题。我想做低阶矩阵分解，我正在查看 Vowpal Wabbit有关该主题的文档。我的问题是：
这两种方法之间有区别吗？（实现或其他）

&lt;前&gt;&lt;代码&gt;$ vw --lrq ab5

或
$ vw -q ab --rank 5

这里，a和b是特征命名空间，5是潜在因子维度。

&lt;小时/&gt;

可能的后续行动：
如果这些是等价的，--rank 也适用于高阶交互吗？]]></description>
      <guid>https://stackoverflow.com/questions/39040721/vowpal-wabbit-low-rank-matrix-factorization</guid>
      <pubDate>Fri, 19 Aug 2016 13:49:06 GMT</pubDate>
    </item>
    </channel>
</rss>