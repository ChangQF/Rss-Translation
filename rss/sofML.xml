<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Wed, 08 May 2024 21:14:56 GMT</lastBuildDate>
    <item>
      <title>R 中的 randomForest 模型过度拟合，为什么？</title>
      <link>https://stackoverflow.com/questions/78451179/overfitting-in-randomforest-model-in-r-why</link>
      <description><![CDATA[我正在尝试使用以下代码在 R 中训练随机森林模型：
# 加载必要的库
库（随机森林）
库（readxl）
库（插入符号）
图书馆(e1071)

# 加载带有标签的原始DataFrame
df &lt;- read_excel(&#39;~/Downloads/tfidf_r.xlsx&#39;)
df$label...2 &lt;- as.factor(df$label...2)

# 将数据分为训练集和测试集
设置.种子(42)
train_indices &lt;- createDataPartition(df$review_id, p = 0.7, list = FALSE)
train_data &lt;- df[train_indices, ]
test_data &lt;- df[-train_indices, ]

# 使用正则化初始化并训练随机森林分类器
random_forest_model &lt;- train(label...2 ~ ., data = train_data, method = &quot;rf&quot;,
                             trControl = trainControl(方法 = &quot;cv&quot;, 数量 = 10))

# 打印模型
打印（随机森林模型）

# 对测试数据进行预测
y_pred &lt;- 预测（random_forest_model，newdata = test_data）

我在这段代码中没有看到任何过度拟合或超参数的原因。
因为我得到这个输出：
准确度：1
                 95% 置信区间：(0.9757, 1)
    无信息率：0.6067
    P值[Acc&gt; NIR]：&lt; 2.2e-16

这没有意义，它的准确度不可能 = 1。
而且，mtry=5477 没有意义。
 mtry 精度 Kappa
     2 0.6050980 0.0000000
   104 0.9341923 0.8576043
  5477 0.9942017 0.9877979

使用准确性来选择最佳模型
 最大的值。
该模型使用的最终值为 mtry = 5477。

为什么会这样，我哪里错了？]]></description>
      <guid>https://stackoverflow.com/questions/78451179/overfitting-in-randomforest-model-in-r-why</guid>
      <pubDate>Wed, 08 May 2024 21:13:51 GMT</pubDate>
    </item>
    <item>
      <title>与 SVM 等其他方法相比，使用 PSO 进行特征选择并使用 RF 进行预测，精度没有提高太多的原因是什么？</title>
      <link>https://stackoverflow.com/questions/78451007/what-is-the-reason-for-not-increasing-accurac-much-by-using-pso-for-features-sel</link>
      <description><![CDATA[使用 RF 定义适应度函数
def Fitness_function(特征):
如果没有特征：
返回0.0
创建单独的分类器
clf= RandomForestClassifier(n_estimators=52,max_depth=20, criteria=“gini”,random_state=777)

selected_feature_indices = [特征中特征的列表(X.columns).index(feature)]
selected_features = X_train[:, selected_feature_indices]

预测
clf.fit(selected_features, y_train) `你的文本`
y_pred = clf1.predict(X_test[:, selected_feature_indices]) `你的文本`

返回准确度分数（y_test，y_pred）

存储进度数据的列表
迭代值 = []
precision_values = [] 您的文本
PSO 参数
inertia_weight = 0.5 你的文字
c1, c2 = 2.0, 2.0 您的文字]]></description>
      <guid>https://stackoverflow.com/questions/78451007/what-is-the-reason-for-not-increasing-accurac-much-by-using-pso-for-features-sel</guid>
      <pubDate>Wed, 08 May 2024 20:24:42 GMT</pubDate>
    </item>
    <item>
      <title>NER 模型训练中具有波动损失的恒定评估指标：模型是否能学到任何东西？</title>
      <link>https://stackoverflow.com/questions/78450933/constant-evaluation-metrics-with-fluctuating-loss-in-ner-model-training-is-the</link>
      <description><![CDATA[我正在使用预训练的 BERT 模型 (BertForTokenClassification) 来训练 NER 任务。我使用准确度和 F1_score 作为我的评估指标。主要问题是该模型在每个时期都显示相同的分数，表明它没有学习。但训练损失和分数在各个时期也不是恒定的。什么可能导致此问题？
[训练函数](https://i.sstatic.net/Dd1gTli4.png)
[评估函数] (https://i.sstatic.net/EJpr3CZP.png)
[训练循环] (https://i.sstatic.net/ZLQXorLm.png)
[结果] (https://i.sstatic.net/mLvoAquD.png ）
我检查了模型的参数是否可训练（requires_grad =True），但没有帮助。另外，我尝试了几种学习率的尺度，但它以相同的态度给了我不同的结果（在不同时期保持不变）。我做错了什么吗？]]></description>
      <guid>https://stackoverflow.com/questions/78450933/constant-evaluation-metrics-with-fluctuating-loss-in-ner-model-training-is-the</guid>
      <pubDate>Wed, 08 May 2024 20:07:15 GMT</pubDate>
    </item>
    <item>
      <title>有没有一种方法可以通过文本内容“毒害井”，同时保持其对人类读者有用？</title>
      <link>https://stackoverflow.com/questions/78450631/is-there-a-way-to-poison-the-well-via-text-content-while-keeping-it-useful-for</link>
      <description><![CDATA[Nightshade 和 Glaze 是在图像中嵌入微小变化的工具，这些变化可能会降低、阻止或损害使用这些图像生成衍生内容的机器学习模型。
有没有办法在文本输入中达到类似的效果？]]></description>
      <guid>https://stackoverflow.com/questions/78450631/is-there-a-way-to-poison-the-well-via-text-content-while-keeping-it-useful-for</guid>
      <pubDate>Wed, 08 May 2024 18:47:15 GMT</pubDate>
    </item>
    <item>
      <title>在训练用于分类文本数据的 ML 模型时，是否有方法可以优先考虑或提高特征重要性？</title>
      <link>https://stackoverflow.com/questions/78450312/is-there-a-way-to-prioritize-or-increase-feature-importance-while-training-a-ml</link>
      <description><![CDATA[我有一个文本数据集，其中包含产品描述。我需要将这些描述分类到不同的产品中。我正在使用 TFIDF 向量化将标记向量化为用于训练的特征。对于任何目标标签，是否有办法优先考虑或增加或减少某些特征或单词的重要性？
根据产品描述，我确定了某些关键字并对它们进行矢量化以训练机器学习模型。在某些描述中，可能存在与多个目标标签相关的多个关键字。在这种情况下，如果我可以给出某些关键字，其重要性高于其他关键字，那么它将帮助模型识别正确的标签或产品。有没有办法为这些特征分配权重？]]></description>
      <guid>https://stackoverflow.com/questions/78450312/is-there-a-way-to-prioritize-or-increase-feature-importance-while-training-a-ml</guid>
      <pubDate>Wed, 08 May 2024 17:33:10 GMT</pubDate>
    </item>
    <item>
      <title>如何强制模型使用变量</title>
      <link>https://stackoverflow.com/questions/78450279/how-to-force-a-model-to-use-a-variable</link>
      <description><![CDATA[我有用于训练二元分类模型的数据。
set.seed(1)
n &lt;- 20
dat &lt;- cbind.data.frame(target=as.factor(sample(0:1,n,T)),
                        价格=圆(rnorm(n)+1000,2),
                        var1=样本(1:n),
                        var2=round(rnorm(n),2),
                        var3=round(rnorm(n),2))

.
 目标价格 var1 var2 var3
1 1 1001.03 5 -0.95 1.16
2 0 1000.21 13 -0.02 -0.45
3 0 999.49 11 1.20 1.95
4 0 1000.95 7 0.71 0.86
5 1 1001.49 20 -0.44 1.07
6 0 999.45 10 0.78 -1.76
7 1 998.78 12 -1.64 -0.77
8 1 998.23 8 0.67 0.12

我想强制我的模型考虑我在做出的每个决策中指定的变量 price。
我将用一个例子来解释我的意思。
假设我正在使用由规则组成的随机森林模型，在这种情况下，我希望每个规则中都有一个 price 变量。
这些都是很好的规则，因为每个规则都有一个变量价格
 价格&lt;=1001.49 &amp;变量1&gt;0.105
 var2&lt;=0.12&amp;价格&gt;1001.03 &amp;变量3&gt;-0.025
 价格≤998.23&amp;价格&gt;=997.23

这些都是不好的规则，我希望模型中没有这样的规则
var3&lt;=0.57 &amp; var3&gt;0.105
var2&lt;=0.12&amp; var2&gt;-1.005 &amp;变量3&gt;-0.025
变量1&lt;=6.5

我知道我无法影响模型本身，但也许我可以以某种方式更改数据集中的变量，最终迫使模型在每个决策中强制使用 price 变量。
作为测试，您可以使用此代码从经过训练的随机森林模型中提取规则。
库（inTrees）
库（随机森林）
规则 &lt;- randomForest(target~., dat, ntree=20) |&gt;
          RF2List（）|&gt;
          提取规则（数据）|&gt;
          唯一（）|&gt;
          getRuleMetric(dat[,-1], dat$target) |&gt;;
          pruneRule(dat[,-1], dat$target) |&gt;;
          buildLearner(dat[,-1], dat$target)

.
presentRules(规则, colnames(dat[,-1]))

    长度 频率 错误 条件 预测
[1，]“2” “0.35” “0” &quot;var1&lt;=15.5 &amp; var2&lt;=-0.05” “1”
[2，]“3” “0.2” “0” &quot;var1&lt;=13.5&amp; var2&gt;-0.05 &amp; var3&lt;=-0.315” “0”
[3，]“1” “0.1” “0” “var2&gt;1.255” “1”
[4，]“2” “0.1” “0” &quot;var1&gt;17 &amp; var2&gt;-1.55” “1”
[5，]“1” “0.1” “0” “var3≤-0.16” “0”
[6，]“2” “0.1” “0” &quot;var2&gt;-0.05 &amp; var3＞0.49” “0”
[7，]“1” “0.05” “0” “其他” “1”

正如您在此阶段所看到的，模型拒绝在其规则中使用变量 price。但我的任务的具体情况意味着我不需要不使用价格的规则。
总而言之，我的问题是这样的：
如何更改数据集以强制模型在每个规则中使用 price？]]></description>
      <guid>https://stackoverflow.com/questions/78450279/how-to-force-a-model-to-use-a-variable</guid>
      <pubDate>Wed, 08 May 2024 17:26:29 GMT</pubDate>
    </item>
    <item>
      <title>训练级联 R-CNN 时损失图中的随机峰值</title>
      <link>https://stackoverflow.com/questions/78449913/random-spikes-in-loss-graph-when-training-cascade-r-cnn</link>
      <description><![CDATA[我目前正在使用 MMDetection 训练 Cascade R-CNN 模型，并且我注意到训练期间损失图中出现随机峰值。我的配置如下：

纪元：100
学习率：0.0002
批量大小：4
优化器：带有梯度裁剪的 Adam
调度程序：我使用 LinearLR 和 CosineAnnealingLR 的预热策略

尽管使用一致的训练设置，这些峰值在整个训练过程中还是偶尔出现。如图所示
损失图
什么可能导致这些随机损失峰值，以及如何减轻它们？对于调试或稳定训练过程有什么具体建议吗？
我尝试过的：

验证数据集是否存在损坏或标签错误的图像。
将初始学习率降低至 0.0001，但没有看到显着改善。
调整了梯度裁剪范数，但尖峰仍然存在。
]]></description>
      <guid>https://stackoverflow.com/questions/78449913/random-spikes-in-loss-graph-when-training-cascade-r-cnn</guid>
      <pubDate>Wed, 08 May 2024 16:18:45 GMT</pubDate>
    </item>
    <item>
      <title>深度学习中的孪生网络和卷积网络有什么区别？</title>
      <link>https://stackoverflow.com/questions/78449190/what-are-the-differences-between-siamese-network-and-convolution-network-in-deep</link>
      <description><![CDATA[我对这个领域很陌生，我目前正在学习神经网络，并且接触过 CNN（卷积神经网络），但我看到有些人使用 Siamese 网络来处理图像数据
它们之间有什么区别，我应该使用哪个来进行图像分类/识别/相似性？]]></description>
      <guid>https://stackoverflow.com/questions/78449190/what-are-the-differences-between-siamese-network-and-convolution-network-in-deep</guid>
      <pubDate>Wed, 08 May 2024 14:14:35 GMT</pubDate>
    </item>
    <item>
      <title>生成随机字符串的预训练模型</title>
      <link>https://stackoverflow.com/questions/78448547/pretrained-models-generating-a-random-strings</link>
      <description><![CDATA[我是机器学习新手，知识不够。在过去的两周里，我尝试使用 ollama 包装器来玩一些现成的模型，实际上效果很好。但是，当我尝试解码它们的输出时，我使用的拥抱脸部模型中很少有它是一些随机的混乱字母串，对我来说没有任何意义。现在我只想知道我是否错过了进一步调整模型之类的东西，或者我可能以错误的方式进行了操作。

我尝试过 HuggingFace 上提供的一些预训练医学模型，例如 https://huggingface.co /UFNLP/gatortron-base 还有一些其他生物 llms。 *
]]></description>
      <guid>https://stackoverflow.com/questions/78448547/pretrained-models-generating-a-random-strings</guid>
      <pubDate>Wed, 08 May 2024 12:33:28 GMT</pubDate>
    </item>
    <item>
      <title>如何使用神经网络进行PCB差异检测（黄金样本与实际样本）？</title>
      <link>https://stackoverflow.com/questions/78448316/how-to-use-neural-networks-for-pcb-difference-detection-golden-sample-vs-actua</link>
      <description><![CDATA[我正在开展一个项目，需要检测两个印刷电路板 (PCB) 之间的差异：黄金样本（参考）和实际样本。我想利用神经网络来完成这项任务，但需要有关具体技术和使用方法的指导。
以下是我的项目的详细信息：

我有黄金样品和实际样品的图像或扫描件
多氯联苯。目标是自动识别并突出显示差异
在这两个 PCB 之间。

具体来说，我正在寻求以下方面的建议：

什么类型的神经网络架构适合于此
图像比较任务？
我应该如何构建数据集来训练神经网络？
我应该使用成对的图像（黄金样本，实际样本）
标记差异？
准备 PCB 图像时建议采取哪些预处理步骤
在将它们输入神经网络之前？任何其他考虑因素
或者有效实施此类系统的最佳实践？

我对神经网络和图像处理相对较新，因此任何见解、教程或代码示例将不胜感激。谢谢！]]></description>
      <guid>https://stackoverflow.com/questions/78448316/how-to-use-neural-networks-for-pcb-difference-detection-golden-sample-vs-actua</guid>
      <pubDate>Wed, 08 May 2024 11:53:48 GMT</pubDate>
    </item>
    <item>
      <title>我使用 Ultralytics AI 的代码缓慢且滞后</title>
      <link>https://stackoverflow.com/questions/78446384/my-code-using-ultralytics-ai-is-slow-and-laggy</link>
      <description><![CDATA[我是一名高中生，试图做一些有趣的项目并将其放到我的网站上。目前，我正在使用 OpenCV 开发石头、剪刀、布游戏，但是当我在网络摄像头上本地尝试时，加载时间大约需要 2 分钟，当我看到网络摄像头时，速度非常慢且滞后。我想知道如何解决这个问题。我计划使用 React.js 前端和 Django 或 Flask 后端。我在脚本中做错了什么，或者在添加前端和后端时是否必须更改架构。或者是否有地方可以托管前端和后端以更快地计算并解决问题？或者我应该使用什么工具来代替 OpenCV？
从 ultralytics 导入 YOLO
导入CV2
随机导入
导入时间
从 ultralytics.utils.plotting 导入注释器

# 初始化YOLO模型
模型 = YOLO(&#39;runs\\detect\\train6\\weights\\best.pt&#39;)

# 初始化网络摄像头
上限 = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # 设置帧宽度
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # 设置框架高度
cap.set(cv2.CAP_PROP_FPS, 15) # 限制每秒帧数以减少处理负载

玩家得分 = 0
cpu_分数 = 0

def确定_获胜者（玩家，CPU）：
    全局玩家分数、cpu_分数
    如果玩家==CPU：
        返回“平局！”
    elif (player == &#39;rock&#39; and cpu == &#39;scissors&#39;) 或 \
         (player == &#39;剪刀&#39; and cpu == &#39;布&#39;) 或 \
         （玩家 == &#39;纸&#39; 和 cpu == &#39;石头&#39;）：
        玩家得分 += 1
        返回“玩家获胜！”
    别的：
        cpu_score += 1
        返回“CPU 获胜！”

options = [&#39;石头&#39;, &#39;布&#39;, &#39;剪刀&#39;]

而真实：
    ret, img = cap.read()
    如果不转：
        break # 如果没有捕获到帧则退出循环

    # 使用模型进行预测
    结果 = model.predict(img)
    注释器 = 注释器(img, line_width=2, example_text=&#39;&#39;)

    # 显示倒计时
    [“Rock”、“Paper”、“Shoot!”] 中的倒计时：
        cv2.putText(img, 倒计时, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow(&#39;YOLO V8 检测&#39;, img)
        cv2.waitKey(1000) # 每个倒计时步骤等待 1 秒

    cpu_choice = random.choice(选择)
    玩家选择=无

    如果结果：
        对于结果中的 r：
            盒子 = r.盒子
            对于盒中盒：
                b = 盒子.xyxy[0]
                c = 盒子.cls
                玩家选择 = model.names[int(c)]
                annotator.box_label(b, f&quot;{player_choice} vs CPU: {cpu_choice}&quot;)

    如果玩家选择：
        游戏结果=确定获胜者（玩家选择，CPU选择）
        cv2.putText(img, game_result, (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(img, f&quot;玩家: {player_score} CPU: {cpu_score}&quot;, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

    # 显示带有注释的最终帧
    img = 注释器.result()
    cv2.imshow(&#39;YOLO V8 检测&#39;, img)
    cv2.waitKey(5000) # 显示结果后等待5秒

    如果 cv2.waitKey(1) &amp; 0xFF == ord(&#39; &#39;):
        休息

cap.release()
cv2.destroyAllWindows()


我尝试了多线程处理并试图提高循环效率，但没有效果。]]></description>
      <guid>https://stackoverflow.com/questions/78446384/my-code-using-ultralytics-ai-is-slow-and-laggy</guid>
      <pubDate>Wed, 08 May 2024 06:11:12 GMT</pubDate>
    </item>
    <item>
      <title>需要使用 Rand_forest 和 h2o 进行预测的指导</title>
      <link>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</link>
      <description><![CDATA[我有一个随机森林模型，我正在尝试更好地理解它。
为了举例，假设我们有一片蓝莓灌木丛。我们感兴趣的是预测特定灌木丛中腐烂蓝莓的产量以及各个灌木丛中所有蓝莓的收获量。
每个灌木都有一个识别名称：bush_name，例如&#39;bush001&#39;，我们希望根据每个单独的灌木进行预测。例如，我想知道 Bush025 是否在 2/2/22 生产了腐烂的浆果。
为了本示例，输入位于具有以下虚拟结构的 df 中：
train_data &lt;- data.frame(date = c(&quot;2022-01-01&quot;, &quot;2022-01-07&quot;, &quot;2022-02-09&quot;, &quot;2022-05&quot; -01”、“2022-11-01”、“2022-11-02”)、
                   Bush_name = c(“bush001”、“bush001”、“bush001”、“bush043”、“bush043”、“bush043”),
                   错误 = c(2, 0, 1, 0, 3, 1),
                   有腐烂的浆果 = c(1, 0, 0, 1, 1, 0),
                   浆果计数 = c(12, 1, 7, 100, 14, 4),
                   天气 = c(1, 0, 2, 0, 1, 1))

我已经建立了一个随机森林模型，并进行了以下高级设置：
库(agua)
图书馆（防风草）
图书馆（水）

h2o.init(n线程 = -1)

model_fit &lt;- rand_forest(mtry = 10, trees = 100) %&gt;%
  set_engine(“h2o”) %&gt;%
  set_mode(“分类”) %&gt;%
  适合（has_rotten_berry ~ .,
      数据 = train_data) %&gt;%
  step_dummy(灌木名称) %&gt;%
  step_zv(all_predictors()) %&gt;%
  step_normalize(all_predictors())

训练后我确实收到了这条消息：
警告消息：
在 .h2o.processResponseWarnings(res) 中：
  删除坏列和常量列：[bush_name]。

我想知道的是：
当我尝试预测训练模型中的新数据时，似乎我只能使用我已经训练过的灌木丛的 Bush_names 输入新的测试数据。 我假设该模型正在创建特定于灌木丛的预测是否正确？因此必须在训练中输入新的灌木丛信息才能输出这些新灌木丛的未来预测？
示例：我种植了一棵新灌木，bush700，它不存在于原始训练数据集中。如果我尝试使用新的灌木丛数据进行预测，但训练数据中不存在该数据，则会向我传达一条消息：数据中有新的级别。所以我假设因为这些预测似乎是特定于灌木丛的，并且我们无法为新添加的灌木丛获得任何新的灌木丛预测。
这个假设正确吗？
谢谢您，对于可能令人困惑的隐喻，我深表歉意。也欢迎您对该模型可能有的任何其他反馈。]]></description>
      <guid>https://stackoverflow.com/questions/78444040/need-guidance-on-predictions-with-rand-forest-and-h2o-with-r</guid>
      <pubDate>Tue, 07 May 2024 16:58:00 GMT</pubDate>
    </item>
    <item>
      <title>Pandas 代码在 datacamp 实践中是错误的 [关闭]</title>
      <link>https://stackoverflow.com/questions/78439826/pandas-code-is-wrong-in-datacamp-practical</link>
      <description><![CDATA[&lt;块引用&gt;
实践考试：房屋销售
Real Agents 是一家专注于销售房屋的房地产公司。
Real Agents 在一个大都市区销售多种类型的房屋。
有些房屋销售缓慢，有时需要降低价格才能找到买家。
为了保持竞争力，Real Agents 希望优化其试图出售的房屋的挂牌价格。
他们希望通过根据房屋的特征预测其售价来实现这一目标。
如果他们能够提前预测销售价格，就可以缩短销售时间。
数据
数据集包含该地区以前出售的房屋的记录。

&lt;标题&gt;

列
姓名
标准


&lt;正文&gt;

house_id
标称。
房屋的唯一标识符。不可能缺少值。


城市
标称。
房屋所在的城市。 “Silvertown”、“Riverford”、“Teasdale”和“Poppleton”之一。将缺失值替换为“未知”。


促销价
离散。
房屋的售价（以美元计）。值可以是任何大于或等于零的正数。删除缺失的条目。


促销日期
离散。
最后一次出售房屋的日期。将缺失值替换为 2023-01-01。


列出的月份
连续。
房屋在最后一次销售之前在市场上挂牌的月数，四舍五入到小数点后一位。将缺失值替换为列出的平均月数，精确到小数点后一位。


卧室
离散。
房子里的卧室数量。任何大于或等于零的正值。将缺失值替换为平均卧室数，四舍五入到最接近的整数。


房屋类型
序数。
“梯田”之一（两堵共用墙）、“半独立式” （一堵共用墙），或“独立”。 （无共用墙）。用最常见的房屋类型替换缺失值。


区域
连续。
房屋面积，以平方米为单位，四舍五入到小数点后一位。用平均值替换缺失值，精确到小数点后一位。



任务1
Real Agents 的团队知道房产所在的城市会对售价产生影响。
不幸的是，他们认为这并不总是记录在数据中。
计算城市缺失值的数量。
您应该使用文件“house_sales.csv”中的数据。
您的输出应该是一个对象missing_city，其中包含此列中缺失值的数量。
所有必需的数据都应该已创建，并具有所需的列，并识别和替换缺失的值。

将 pandas 导入为 pd

# 从 CSV 文件加载数据集
数据 = pd.read_csv(“house_sales.csv”)

# 检查“city”中是否有缺失值柱子
missing_city = data[“city”].isnull().sum()

# 替换“城市”中缺失的值带有“未知”的列
data[“城市”].fillna(“未知”, inplace=True)

在这段代码中发现错误吗？]]></description>
      <guid>https://stackoverflow.com/questions/78439826/pandas-code-is-wrong-in-datacamp-practical</guid>
      <pubDate>Tue, 07 May 2024 02:23:03 GMT</pubDate>
    </item>
    <item>
      <title>将 NumPy 函数转换为 TensorFlow 操作时的图形执行问题</title>
      <link>https://stackoverflow.com/questions/78439375/graph-execution-issue-with-converting-numpy-function-to-tensorflow-ops</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78439375/graph-execution-issue-with-converting-numpy-function-to-tensorflow-ops</guid>
      <pubDate>Mon, 06 May 2024 22:24:20 GMT</pubDate>
    </item>
    <item>
      <title>XGBoost分类器的SHAP解释中expected_value的计算</title>
      <link>https://stackoverflow.com/questions/77126001/calculation-of-expected-value-in-shap-explanations-of-xgboost-classifier</link>
      <description><![CDATA[我们如何理解 SHAP explainer.expected_value？为什么sigmoid变换后与y_train.mean()不一样？
下面是代码摘要，供快速参考。本笔记本中提供了完整代码： https://github.com /MenaWANG/ML_toy_examples/blob/main/explain%20models/shap_XGB_classification.ipynb
模型 = xgb.XGBClassifier()
model.fit(X_train, y_train)
解释器 = shap.Explainer(模型)
shap_test = 解释器(X_test)
shap_df = pd.DataFrame(shap_test.values)

#对于每种情况，如果我们将所有特征的形状值加上预期值相加，我们就可以获得该情况的余量，然后可以将其转换为返回该情况的预测概率：
np.isclose(model.predict(X_test, output_margin=True),explainer.expected_value + shap_df.sum(axis=1))
＃真的

但是为什么下面的内容不正确呢？为什么经过 sigmoid 变换后，XGBoost 分类器的 explainer.expected_value 与 y_train.mean() 不一样？
expit(explainer.expected_value) == y_train.mean()
＃错误的
]]></description>
      <guid>https://stackoverflow.com/questions/77126001/calculation-of-expected-value-in-shap-explanations-of-xgboost-classifier</guid>
      <pubDate>Mon, 18 Sep 2023 09:28:55 GMT</pubDate>
    </item>
    </channel>
</rss>