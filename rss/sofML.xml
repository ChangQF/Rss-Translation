<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Fri, 22 Mar 2024 03:14:42 GMT</lastBuildDate>
    <item>
      <title>如何将我的 fastai resnet50/vision_learner 训练模型导出到 torchserve 中？</title>
      <link>https://stackoverflow.com/questions/78203794/how-do-i-export-my-fastai-resnet50-vision-learner-trained-model-into-torchserve</link>
      <description><![CDATA[我的目标是将我用 Fastai 训练的模型部署到 Torchserve 中。我正在关注 本教程，但卡在了他为 pytorch 创建模型类的部分。
他提到要在 Torchserve 中运行我们的模型，我们需要以下内容：

模型类
从 pytorch 导出的权重（pth 文件）
处理程序

其中，我得到两个：重量和处理程序。然而，我陷入困境的是模型类。他创建了一个类文件，但我不知道他从哪里获得DynamicUnet作为该类的基础，也不知道他如何将该类与unet_learner混合以创建自定义PyTorch模型类。你能帮我为在学习器 vision_learner 下训练的模型和 resnet50 的预训练模型建立一个模型类吗？]]></description>
      <guid>https://stackoverflow.com/questions/78203794/how-do-i-export-my-fastai-resnet50-vision-learner-trained-model-into-torchserve</guid>
      <pubDate>Fri, 22 Mar 2024 02:55:25 GMT</pubDate>
    </item>
    <item>
      <title>我应该使用什么类型的人工智能模型来生成练习题？</title>
      <link>https://stackoverflow.com/questions/78203711/what-type-of-ai-model-should-i-use-to-generate-practice-questions</link>
      <description><![CDATA[我有一组英语多项选择题，我想使用 AI 生成更多问题来测验自己。我知道网上有一些平台可以实现这一点，但我想挑战自己，创建自己的简单人工智能架构。在对它进行一些英语问题训练后，我希望它能够生成新问题来帮助我学习。
我应该使用哪种机器学习/智能模型作为基线？非常感谢！]]></description>
      <guid>https://stackoverflow.com/questions/78203711/what-type-of-ai-model-should-i-use-to-generate-practice-questions</guid>
      <pubDate>Fri, 22 Mar 2024 02:17:43 GMT</pubDate>
    </item>
    <item>
      <title>人工智能物体检测</title>
      <link>https://stackoverflow.com/questions/78203585/ai-object-detection</link>
      <description><![CDATA[我正在尝试使用计算机视觉和人工智能来识别图像中的硬币。
我使用的货币是波斯尼亚货币，问题是一些硬币的颜色和设计相同，唯一的区别是它们的大小。
我知道答案可能是否定的，但是有没有办法可以使用它们的大小来区分它们？]]></description>
      <guid>https://stackoverflow.com/questions/78203585/ai-object-detection</guid>
      <pubDate>Fri, 22 Mar 2024 01:29:24 GMT</pubDate>
    </item>
    <item>
      <title>lightfm python 依赖项使用</title>
      <link>https://stackoverflow.com/questions/78203344/lightfm-python-dependency-usage</link>
      <description><![CDATA[将 numpy 导入为 np
从 lightfm.datasets 导入 fetch_movielens
从 lightfm 导入 LightFM

数据 = fetch_movielens(min_ rating=4.0)

打印（repr（数据[&#39;火车&#39;]））
打印（repr（数据[&#39;测试&#39;]））

模型 = LightFM(损失=&#39;扭曲&#39;)

model.fit(data[&#39;train&#39;], epochs=30, num_threads=2)

defsample_recommendation（模型，数据，user_ids）：
    n_users, n_items = 数据[&#39;train&#39;].shape
    
    对于 user_ids 中的 user_id：
        known_positives = data[&#39;item_labels&#39;][data[&#39;train&#39;].tocsr()[user_id].indices]
        
        分数 = model.predict(user_id, np.arange(n_items))
        
        # 修复此处的标签索引
        top_items = 数据[&#39;item_labels&#39;][np.argsort(-scores)]
        
        print(&quot;用户 %s&quot; % user_id)
        print(&quot;已知的积极结果：&quot;)

        对于known_positives[:3]中的x：
            打印(“%s”%x)
            
        print(&quot;推荐：&quot;)

        # 打印最推荐的商品
        对于 top_items[:3] 中的 x：
            打印(“%s”%x)
            
样本推荐（模型，数据，[3,10,56]）


如果我运行我的代码，只输出电影标题的第一个字母，它应该是完整的电影标题，如何修复它？
我问过ai其中一个chat gpt，他们给出代码建议后，代码仍然不起作用，只显示每部电影的第一个字母。]]></description>
      <guid>https://stackoverflow.com/questions/78203344/lightfm-python-dependency-usage</guid>
      <pubDate>Thu, 21 Mar 2024 23:44:11 GMT</pubDate>
    </item>
    <item>
      <title>轨迹和位置算法[关闭]</title>
      <link>https://stackoverflow.com/questions/78202619/algorithm-for-trajectory-and-position</link>
      <description><![CDATA[我正在尝试创建一个项目，计划使用某种类型的相机拍摄地面的高 fps (100-200) 照片，然后将这些照片相互比较，以提取运动信息，例如x,y 坐标、速度和距离。
我正在考虑光流，但是还有其他方法可以解决这个问题吗？
速度永远不会超过 5m/s，但精度要求很高。]]></description>
      <guid>https://stackoverflow.com/questions/78202619/algorithm-for-trajectory-and-position</guid>
      <pubDate>Thu, 21 Mar 2024 20:26:00 GMT</pubDate>
    </item>
    <item>
      <title>调整用于异常检测的 KNN 算法 [关闭]</title>
      <link>https://stackoverflow.com/questions/78202543/tuning-a-knn-algorithm-for-anomaly-detection</link>
      <description><![CDATA[我正在尝试使用 k 最近邻 (KNN) 算法在时间序列数据集中进行异常检测，其中包含工业机器的传感器读数。目标是使用 KNN 识别传感器读数中的任何异常行为，这可能表明机器中的潜在问题或故障。
数据集采用以下格式：
&lt;前&gt;&lt;代码&gt;sensor_data.csv
时间戳、温度、压力、振动
2023-03-22 09:00:00,75.2,101.3,2.1
2023-03-22 09:05:00,75.1,101.2,2.2

这是我的 Python 代码：
导入 pandas 作为 pd
从 sklearn.neighbors 导入 NearestNeighbors

# 加载数据集
Sensor_data = pd.read_csv(&#39;sensor_data.csv&#39;)
X =sensor_data[[&#39;温度&#39;,&#39;压力&#39;,&#39;振动&#39;]]

# 实现 KNN 进行异常检测
knn = 最近邻居(n_neighbors=5, metric=&#39;euclidean&#39;)
knn.fit(X)
距离，索引 = knn.kneighbors(X)

这就是我陷入困境的地方：

如何确定此特定场景中邻居数量 (k) 的最佳值？
欧几里得距离度量是此类数据的最佳选择，还是应该考虑其他距离度量？如果有，是哪些以及为什么？
根据 KNN 返回的距离和索引，如何有效识别和处理传感器读数中的异常情况？
]]></description>
      <guid>https://stackoverflow.com/questions/78202543/tuning-a-knn-algorithm-for-anomaly-detection</guid>
      <pubDate>Thu, 21 Mar 2024 20:09:04 GMT</pubDate>
    </item>
    <item>
      <title>输入形状如何改变模型架构？</title>
      <link>https://stackoverflow.com/questions/78202453/how-does-the-input-shape-change-model-architecture</link>
      <description><![CDATA[在以下两种情况下我得到不同的结果：
示例 1：训练数据具有形状（batch_size，n_steps），模型为：
model_dense = tf.keras.Sequential([
   tf.keras.layers.Dense(1)
]）

示例 2：我的训练数据具有形状 (batch_size, n_steps, 1)，模型具有形状
model_dense = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=[n_steps, 1]),
    tf.keras.layers.Dense(1)
]）


示例 2 的训练效果要好得多。两个模型都有 n_steps+1 个可训练参数，我认为示例 2 的展平层只会展平通道维度，因此使其等同于示例 1。我认为我错过了一些简单的东西。]]></description>
      <guid>https://stackoverflow.com/questions/78202453/how-does-the-input-shape-change-model-architecture</guid>
      <pubDate>Thu, 21 Mar 2024 19:43:55 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 Ridge 和 Lasso 回归处理数据集中潜在的多重共线性？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78202221/how-to-handle-potential-multicollinearity-in-a-dataset-using-ridge-and-lasso-reg</link>
      <description><![CDATA[包含各种房屋信息的数据集，包括其大小、卧室数量、浴室数量、年龄和相应的销售价格。目标是建立一个线性回归模型，可以根据这些自变量准确预测房屋的销售价格，同时考虑数据中潜在的多重共线性。
数据集以下格式：
house_data.csv
面积、卧室、浴室、年龄、价格
2500,4,3,25,550000
3000,3,2,15,625000
导入 pandas 作为 pd
从 sklearn. Linear_model 导入 LinearRegression、Ridge、Lasso
从 sklearn.model_selection 导入 train_test_split

# 加载数据集
house_data = pd.read_csv(&#39;house_data.csv&#39;)
X = house_data[[&#39;尺寸&#39;, &#39;卧室&#39;, &#39;浴室&#39;, &#39;年龄&#39;]]
y = house_data[&#39;价格&#39;]

# 将数据分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 标准线性回归
Linear_reg = 线性回归()
Linear_reg.fit(X_train, y_train)
Linear_score = Linear_reg.score(X_test, y_test)
print(f&#39;标准线性回归分数：{linear_score}&#39;)

虽然上面的代码适用于标准线性回归，但我正在努力解决以下问题：

如何确定岭回归中正则化参数 (alpha) 的最佳值？
如何在处理数据集中的多重共线性的同时有效实施 Lasso 回归？
]]></description>
      <guid>https://stackoverflow.com/questions/78202221/how-to-handle-potential-multicollinearity-in-a-dataset-using-ridge-and-lasso-reg</guid>
      <pubDate>Thu, 21 Mar 2024 18:51:40 GMT</pubDate>
    </item>
    <item>
      <title>找到每个类别的图像原型？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78200700/find-the-image-prototypes-for-each-class</link>
      <description><![CDATA[我尝试实现一种方法，该方法采用所有图像特征和相应的标签来为每个类生成图像原型。我在网上搜索过，但找不到任何教程或可用代码来验证我所做的是否正确。
此外，我尝试计算加权图像原型，其中每个图像都有自己的权重。但是，我仍然不确定这种方法是否准确。
labels = torch.arange(num_classes)
weights = torch.tesnor([......]) ## 大小 N 的权重 = num_images
类均值 = []
对于可用标签中的 i：
    idx = (伪标签 == i)
    样本计数 = idx.float().sum().item()
    如果样本数&gt; 0.0：
        壮举=特征[idx]
        class_emebdding = torch.sum(feat*weights[idx],dim=0)
        class_emebdding /= class_emebdding.norm()
原型 = torch.stack(class_means, 0)
]]></description>
      <guid>https://stackoverflow.com/questions/78200700/find-the-image-prototypes-for-each-class</guid>
      <pubDate>Thu, 21 Mar 2024 14:31:36 GMT</pubDate>
    </item>
    <item>
      <title>在基于品种的作物产量预测模型中找到每个品种的准确性[关闭]</title>
      <link>https://stackoverflow.com/questions/78199996/finding-the-accuracy-for-each-variety-in-a-variety-based-crop-yield-prediction-m</link>
      <description><![CDATA[我一直在使用回归研究田间作物的产量预测模型。我的输入特征包括 30 多个特定于作物的变量，这些变量是我使用 Google Earth Engine 针对每个由单个多边形标记的田地得出的。我还通过调查了解了每块田地种植的农作物的品种（具体是两种类型）。我想了解每个品种的模型准确性如何。我们以后如何确定模型对每个品种的准确性？
品种 1 - 有 100 个样品
品种 2 - 有 60 个样品
我正在考虑做这样的事情：

如果我遵循 70-30% 的分割，我就有 48 个测试样本。根据每个样本绘制预测产量。
根据多样性将样本分为几类。
通过找出误差差异来计算每个类别的 RMSE/MAE。

我不太确定这种方法。有什么建议吗？]]></description>
      <guid>https://stackoverflow.com/questions/78199996/finding-the-accuracy-for-each-variety-in-a-variety-based-crop-yield-prediction-m</guid>
      <pubDate>Thu, 21 Mar 2024 12:40:06 GMT</pubDate>
    </item>
    <item>
      <title>为什么使用 Tensorflow 时 Python 产生的结果比 kotlin 更准确？</title>
      <link>https://stackoverflow.com/questions/78199511/why-does-python-produce-a-more-accurate-result-than-kotlin-when-using-tensorflow</link>
      <description><![CDATA[我正在制作一个应用程序，它将检测不同数字系统中不同的手写数学表达式。截至目前，阻碍任何进展的主要因素是 kotlin 在使用 Tensorflow lite 时产生的不准确性 - 大约 10% 正确。我的 Python 代码非常相似，但它使用常规张量流，并且更加准确 - 大约 70% 正确。
我的想法是图像从 OpenCV Mat 转换为 Tensorbbuffer 的方式导致了一些问题，或者预处理的处理方式导致了差异。
我的代码片段如下：

提取边界矩形后，进行预处理和标准化。

val image_roi = Mat(tmp,boundRect)
Imgproc.cvtColor(image_roi, image_roi, Imgproc.COLOR_RGB2GRAY) Imgproc.GaussianBlur(image_roi, image_roi, Size(3.0,3.0), 0.0)
Imgproc.dilate(image_roi, image_roi, Imgproc.getStructuringElement(Imgproc.MORPH_RECT, Size(4.0, 4.0)))
Imgproc.threshold(image_roi, image_roi, 90.0, 255.0, Imgproc.THRESH_BINARY);
Imgproc.resize(image_roi, image_roi, 大小(28.0,28.0))
Core.normalize(image_roi, image_roi, 0.0, 255.0, Core.NORM_MINMAX);
image_roi.convertTo(image_roi, CvType.CV_8UC1)
提取.add(image_roi)


运行预测，将 OpenCV Mat 转换为 Tensorbuffer（第 3 步）

for（提取的img）{
       val 张量缓冲区 = extractBytes(img)
       val 输出 = model.process(tensorBuffer)
       valoutputFeature0=outputs.outputFeature0AsTensorBuffer
       valconf=outputFeature0.floatArray
       out += getLanguageText(conf, 数字)
 
}


将 Mat 转换为 Tensorbbuffer

私有乐趣 extractBytes(img: Mat): TensorBuffer{
        val inputFeature = TensorBuffer.createFixedSize(intArrayOf(1, 28, 28, 1), DataType.FLOAT32)
        val byteBuffer = ByteBuffer.allocateDirect(28 * 28 * 4) // 每个浮点数 4 个字节
        byteBuffer.order(ByteOrder.nativeOrder())
        byteBuffer.rewind()
 
        for (i 从 0 到 28) {
            for (j in 0 到 28) {
                val temp = img.get(i, j)[0].toFloat() // 假设单通道（灰色）
                byteBuffer.putFloat(临时)
            }
        }
 
        inputFeature.loadBuffer(byteBuffer)
        返回输入特征
    }

在下面的粘贴箱中，我也包含了我的 pythin 代码。我需要一些帮助来弄清楚为什么我的模型无法通过 Kotlin 准确预测，但可以通过 Python 准确预测。
https://pastebin.com/BACzTkq6
以下是在 Python 和 Kotlin 中使用相同图像的差异示例：
通过 Kotlin 显示预测的图像
通过 python 显示预测的图像
我尝试了将 Matrix 转换为 Tensorbuffer 的不同方法，我尝试删除大部分（如果不是全部）图像预处理，我尝试让 python 在 Android studio 中工作（但这并没有成功。）]]></description>
      <guid>https://stackoverflow.com/questions/78199511/why-does-python-produce-a-more-accurate-result-than-kotlin-when-using-tensorflow</guid>
      <pubDate>Thu, 21 Mar 2024 11:18:54 GMT</pubDate>
    </item>
    <item>
      <title>PyTorch 矩阵乘法形状错误：“RuntimeError：mat1 和 mat2 形状无法相乘”</title>
      <link>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</link>
      <description><![CDATA[我是 PyTorch 的新手，正在创建一个多输出线性回归模型，根据字母为单词着色。 （这将帮助有字素颜色联觉的人更轻松地阅读。）它接收单词并输出 RGB 值。每个单词都表示为 45 个浮点数 [0,1] 的向量，其中 (0, 1] 代表字母，0 代表该位置不存在字母。每个样本的输出应该是一个向量 [r-value, g -值，b-值]。
我懂了
&lt;块引用&gt;
运行时错误：mat1 和 mat2 形状无法相乘（90x1 和 45x3）

当我尝试在训练循环中运行我的模型时。
查看现有的 Stack Overflow 帖子，我认为这意味着我需要重塑我的数据，但我不知道如何/在哪里以解决此问题的方式进行此操作。特别是考虑到我不知道那个 90x1 矩阵来自哪里。
我的模型
我一开始很简单；在我可以让单个层发挥作用之后，可以出现多个层。
类 ColorPredictor(torch.nn.Module):
    #构造函数
    def __init__(自身):
        super(ColorPredictor, self).__init__()
        self.linear = torch.nn.Linear(45, 3, device= device) #编码词向量的长度 &amp; r,g,b 向量的大小
        
    ＃ 预言
    defforward(self, x: torch.Tensor) -&gt;;火炬.张量：
        y_pred = self.线性(x)
        返回 y_pred

我如何加载数据
# 数据集类
数据类（数据集）：
    # 构造函数
    def __init__(自身，输入，输出)：
        self.x = input # 编码词向量列表
        self.y = 输出 # 将 r、g、b 值转换为火炬张量的 Pandas 数据帧
        self.len = len(输入)
    
    # 吸气剂
    def __getitem__(自身，索引)：
        返回 self.x[索引], self.y[索引]
    
    # 获取样本数
    def __len__(自身):
        返回 self.len

# 创建训练/测试分割
train_size = int(0.8 * len(数据))
train_data = 数据(输入[:train_size], 输出[:train_size])
test_data = 数据(输入[train_size:], 输出[train_size:])

# 为训练和测试集创建 DataLoaders
train_loader = DataLoader（数据集= train_data，batch_size = 2）
test_loader = DataLoader（数据集= test_data，batch_size = 2）

发生错误的测试循环
对于范围内的纪元（纪元）：
    ＃ 火车
    model.train() #训练模式
    对于 train_loader 中的 x,y：
        y_pred = model(x) #此处错误
        损失=标准(y_pred, y)
        优化器.zero_grad()
        loss.backward()
        优化器.step()
      

错误回溯


新尝试：
将 45x1 输入张量更改为 2x45 输入张量，第二列全为零。这适用于第一次运行 train_loader 循环，但在第二次运行 train_loader 循环期间，我得到另一个矩阵乘法错误，这次是大小为 90x2 和 45x3 的矩阵。]]></description>
      <guid>https://stackoverflow.com/questions/78196998/pytorch-matrix-multiplication-shape-error-runtimeerror-mat1-and-mat2-shapes-c</guid>
      <pubDate>Thu, 21 Mar 2024 01:00:23 GMT</pubDate>
    </item>
    <item>
      <title>ViT 模型的 HuggingFace Inference API 问题 - “图像特征提取”错误</title>
      <link>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</link>
      <description><![CDATA[我的 Vision Transformer (ViT) 模型 rshrott/vit-base-renovation2 的推理 API 遇到问题。
https://huggingface.co/rshrott/vit-base-renovation2 
当我尝试使用 API 时，收到以下错误：
&lt;前&gt;&lt;代码&gt;{
“错误”：“HfApiJson（反序列化（错误（“未知变体图像特征提取，预期音频分类，音频到音频，音频源分离，自动语音识别，特征提取之一，文本分类、标记分类、问答、翻译、摘要、文本生成、text2text-生成、填充掩模、零样本分类、零样本图像分类、会话、表格问答、图像分类、图像分割、图像到文本、文本到语音、...视觉问答、视频分类、文档问答、图像到图像、深度估计，行：1 ，栏目：318）））”
}

有趣的是，当我直接在 Python 中使用 Transformer 管道时，模型按预期工作：
从转换器导入管道
从 PIL 导入图像
导入请求

管道=管道（模型=“rshrott/vit-base-renovation2”）
url = &#39;https://example.com/image.jpeg&#39;
图像= Image.open(requests.get(url,stream=True).raw)
preds = 管道(图像)

此代码运行没有任何问题并返回预期的预测。但是，通过推理 API 使用同一模型时会遇到错误。我怀疑可能存在与预期任务类型相关的配置问题，但我不确定如何解决它。
为什么会出现此错误以及如何修复它？我已经检查了型号卡和配置，但我似乎无法找到“图像特征提取”的来源或原因。]]></description>
      <guid>https://stackoverflow.com/questions/78192634/issue-with-huggingface-inference-api-for-vit-model-image-feature-extraction</guid>
      <pubDate>Wed, 20 Mar 2024 10:44:57 GMT</pubDate>
    </item>
    <item>
      <title>一种计算给定数据集中给定属性的循环数的方法</title>
      <link>https://stackoverflow.com/questions/77524730/a-way-to-count-the-number-of-cycles-of-an-given-attribute-in-a-given-dataset</link>
      <description><![CDATA[我想找到给定的电机故障电流数据集中的周期数，它是由在不同时间测量的电机电流给出的，我想知道它是否可以被视为一个信号或者它只是一个信号模式？
电机故障电流
我尝试了一些库，但它们适用于不同的条件，例如它们对所使用的信号有零交叉点，并且我找不到可以为此变成零交叉的点，因为电机电流始终为+ve并且因此它只是随着时间的推移而稍微波动，因此我得到了一个情节
data = pd.read_csv(“healthy.csv”)
y = np.array(data.Current_A)
x = 数据.索引
date_array = pd.array(data.TimeStamp)
plt.plot(日期数组,y)

我在这里使用了 3ph 健康电机电流数据集，有一件事，该数据集有空格作为“”当前-A” ，应固定为“Current_A”]]></description>
      <guid>https://stackoverflow.com/questions/77524730/a-way-to-count-the-number-of-cycles-of-an-given-attribute-in-a-given-dataset</guid>
      <pubDate>Tue, 21 Nov 2023 17:18:31 GMT</pubDate>
    </item>
    <item>
      <title>如何将Polygon格式转换为YOLO格式</title>
      <link>https://stackoverflow.com/questions/74276547/how-to-convert-polygon-format-to-yolo-forma</link>
      <description><![CDATA[多边形 ((799 1776, 799 2016, 490 2016, 490 1776, 799 1776))
这是 POLYGON 中的边界框
我想要 YOLO v5 格式的
导入日志记录
从 pathlib 导入路径
将 pandas 导入为 pd
从 shapely.wkt 导入负载
yolo_output_dir = 路径(“my_yolo”)
yolo_output_dir.mkdir（父母=真，exist_ok=真）
df = (pd
      .read_csv(&#39;images_bboxes.csv&#39;)
      .fillna(值={&#39;几何&#39;: &#39;2&#39;}))

蠕虫类型 = {
    y: x for (x, y) in enumerate(df[&#39;worm_type&#39;].unique())
}
记录.关键（worm_types）

对于 df.groupby(&#39;image_id&#39;, sort=False) 中的 (i, g)：
    dst = yolo_output_dir.joinpath(i).with_suffix(&#39;.txt&#39;)
    日志记录.警告（dst）
    以 dst.open(&#39;w&#39;) 作为 fp：
        对于 g.itertuples(index=False) 中的 i：
            如果我.几何：
                蠕虫 = 蠕虫_类型[i.蠕虫_类型]
                几何=载荷（i.几何）
                (minx, miny, maxx, maxy) = 几何.边界
                (w, h) = (maxx - minx, maxy - miny)
                打印（蠕虫，minx，miny，w，h，文件= fp）

这是我尝试过的代码，但它给出了错误的坐标..
多边形 ((799 1776, 799 2016, 490 2016, 490 1776, 799 1776))
被转换为
0 389.0 1552.0 160.0 165.0
这是错误的]]></description>
      <guid>https://stackoverflow.com/questions/74276547/how-to-convert-polygon-format-to-yolo-forma</guid>
      <pubDate>Tue, 01 Nov 2022 13:15:07 GMT</pubDate>
    </item>
    </channel>
</rss>