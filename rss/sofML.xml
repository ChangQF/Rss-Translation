<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Thu, 21 Dec 2023 12:24:44 GMT</lastBuildDate>
    <item>
      <title>Xgboost 多类单调约束</title>
      <link>https://stackoverflow.com/questions/77697642/xgboost-multiclass-monotonic-constraints</link>
      <description><![CDATA[我有一个问题，我的价格是可变的，我需要将此价格分类为获胜/未获胜。如果价格上涨，概率应该单调下降。我使用工作正常的单调约束（xgboost库参数 https://xgboost .readthedocs.io/en/stable/tutorials/monotonic.html)
我使用的是 xgboost python 包版本 2.0.1。
现在，我正在尝试将我的解决方案升级为多类分类问题。现在，对于每个价格，我想知道属于第 1 类（获胜）、第 2 类（第二名）和第 3 类（其余位置）的概率。
使用 xgboost &#39;objective&#39; = &#39;multi:softprob&#39; 我得到了相当好的结果。但是， &#39;monotone_constraints&#39; = {&quot;price&quot;: -1} 没有任何效果。
是否有保证多类分类问题中的单调约束？ xgboost 是解决这个问题的最佳库吗？是否还需要确保单调约束？]]></description>
      <guid>https://stackoverflow.com/questions/77697642/xgboost-multiclass-monotonic-constraints</guid>
      <pubDate>Thu, 21 Dec 2023 11:24:57 GMT</pubDate>
    </item>
    <item>
      <title>如何从具有一对多关系的数据集开始创建用于机器学习的数据集？</title>
      <link>https://stackoverflow.com/questions/77696639/how-do-i-create-a-dataset-for-machine-learning-starting-from-datasets-that-have</link>
      <description><![CDATA[我有一个数据集（我们称之为 dataset1，它是一个 3000x6 数据集），结构如下：
X1,X2,X3,X4,X5,观察索引
D,3,3,0.12,0.3,0
B,2,3,0.2,0.27,1
B,4,5,0.2,0.18,2
A,3,5,0.28,0.24,3
B,3,5,0.17,0.29,4
列“ObservationIndex”包含一个扩展的整数序列，用作包含许多行（准确地说是 191 行）的 CSV 文件的索引。
因此，对于 dataset1 中的每一行，都存在一个对应的包含 191 行的 CSV 文件。
每个对应的 191 行 csv 的结构如下：
head_id,tail_id,initial_condition,目标变量
152331933,152432928,假,假
152331933,152432917,假,假
152331933,152331936,假,假
152331936,152943327,假,假
目的是预测目标变量，可以是 1 或 0。
如何创建可输入机器学习模型的数据集？
我的想法围绕着需要以某种方式创建新特征以形成正确的数据集。但是这个目标变量应该是什么？我已经排除了将所有 CSV 文件合并在一起的可能性，因为这会生成巨大的数据集。但是，我不确定在使用这些新功能训练模型后，如何恢复到对原始目标变量进行分类的原始问题。]]></description>
      <guid>https://stackoverflow.com/questions/77696639/how-do-i-create-a-dataset-for-machine-learning-starting-from-datasets-that-have</guid>
      <pubDate>Thu, 21 Dec 2023 08:31:21 GMT</pubDate>
    </item>
    <item>
      <title>如何将预测与标签相匹配 [CNN]？ [关闭]</title>
      <link>https://stackoverflow.com/questions/77696572/how-do-i-match-predictions-with-labels-cnn</link>
      <description><![CDATA[我在 https://www.kaggle.com/datasets/iamsouravbanerjee/indian-food-images-dataset/data
Colab 文件：
https://colab.research.google.com/drive/1HWnVTUFf- CpZmNc16ZlQU_O5zwz_Elf4?usp=共享
我能够获得预测，但无法将其转换为菜名。我的项目需要它获取菜名，这样我才能获取它的营养。
如何让标签适用于此模型？
从tensorflow.keras.models导入load_model
从tensorflow.keras.preprocessing导入图像
从tensorflow.keras.applications.xception导入preprocess_input，decode_predictions
将 numpy 导入为 np

all_classes = [&#39;modak&#39;、&#39;bhindi_masala&#39;、&#39;butter_chicken&#39;、&#39;sohan_halwa&#39;、&#39;bhatura&#39;、&#39;poha&#39;、&#39;chicken_razala&#39;、&#39;imarti&#39;、&#39;qubani_ka_meetha&#39;、&#39;kajjikaya&#39;、&#39;makki_di_roti_sarson_da_saag&#39;、&#39;misi_roti&#39; , &#39;palak_paneer&#39;, &#39;naan&#39;, &#39;chikki&#39;, &#39;kachori&#39;, &#39;poornalu&#39;, &#39;anarsa&#39;, &#39;lassi&#39;, &#39;pithe&#39;, &#39;ghevar&#39;, &#39;sohan_papdi&#39;, &#39;chicken_tikka_masala&#39;, &#39;kadai_paneer&#39;, &#39; chhena_kheeri&#39;、&#39;rasgulla&#39;、&#39;lyangcha&#39;、&#39;chak_hao_kheer&#39;、&#39;aloo_gobi&#39;、&#39;navrattan_korma&#39;、&#39;daal_puri&#39;、&#39;phirni&#39;、&#39;chana_masala&#39;、&#39;kofta&#39;、&#39;dharwad_pedha&#39;、&#39;aloo_shimla_mirch&#39;、&#39;paneer_butter_masala &#39; , &#39;sandesh&#39;, &#39;double_ka_meetha&#39;, &#39;karela_bharta&#39;, &#39;maach_jhol&#39;, &#39;sheera&#39;, &#39;chicken_tikka&#39;, &#39;kalakand&#39;, &#39;misti_doi&#39;, &#39;biryani&#39;, &#39;ras_malai&#39;, &#39;daal_baati_churma&#39;, &#39;pootharekulu&#39;, &#39; gajar_ka_halwa&#39;、&#39;rabri&#39;、&#39;boondi&#39;、&#39;sutar_feni&#39;、&#39;aloo_tikki&#39;、&#39;malapua&#39;、&#39;薄饼&#39;、&#39;gulab_jamun&#39;、&#39;shankarpali&#39;、&#39;dal_makhani&#39;、&#39;ledikeni&#39;、&#39;kadhi_pakoda&#39;、&#39;shrikhand&#39; , &#39;cham_cham&#39;, &#39;bandar_laddu&#39;, &#39;unni_appam&#39;, &#39;aloo_matar&#39;, &#39;doodhpak&#39;, &#39;adhirasam&#39;, &#39;basundi&#39;, &#39;sheer_korma&#39;, &#39;mysore_pak&#39;, &#39;aloo_methi&#39;, &#39;dal_tadka&#39;, &#39;kakinada_khaja&#39;, &#39; gavvalu&#39;、&#39;dum_aloo&#39;、&#39;litti_chokha&#39;、&#39;ariselu&#39;、&#39;jalebi&#39;、&#39;kuzhi_paniyaram&#39;]
img_path = &#39;/content/JalebiIndia.jpg&#39; # 替换为图像路径
img = image.load_img(img_path, target_size=(100, 100)) # 调整大小以匹配模型的预期输入大小
img_array = image.img_to_array(img)
img_array = np.expand_dims(img_array, 轴=0)
img_array = 预处理_输入(img_array)

# 获取模型预测
预测 = model_Xception.predict(img_array)

# 获取预测的类别索引
Predicted_class_index = np.argmax(预测)

# 将预测的类索引映射到您的自定义类标签
预测类标签 = 所有类[预测类索引]

print(&quot;预测类别：&quot;)
打印（预测的类标签）
]]></description>
      <guid>https://stackoverflow.com/questions/77696572/how-do-i-match-predictions-with-labels-cnn</guid>
      <pubDate>Thu, 21 Dec 2023 08:13:17 GMT</pubDate>
    </item>
    <item>
      <title>Sagemaker 端点 - 创建 ML 指标和仪表板</title>
      <link>https://stackoverflow.com/questions/77696324/sagemaker-endpoints-creating-ml-metrics-and-dashboards</link>
      <description><![CDATA[我部署了一个 sagemaker 端点。该模型是我创建的自定义随机森林模型。
日志被推送到 Cloudwatch，我手动添加了一个日志，显示提取的特征和模型得分。
我的最终目标是创建一个仪表板，我可以在其中评估模型的稳定性并查找数据或模型漂移。
关于如何做到这一点有什么建议吗？
现在我有一个 jupyter 笔记本，它查询写入分数（仅分数）的 mongoDB，并让我了解正在发生的事情。
这是一个手动过程，因为我们有多个端点写入不同类型的数据库，所以最好的办法是将 cloudwatch 作为源。]]></description>
      <guid>https://stackoverflow.com/questions/77696324/sagemaker-endpoints-creating-ml-metrics-and-dashboards</guid>
      <pubDate>Thu, 21 Dec 2023 07:16:53 GMT</pubDate>
    </item>
    <item>
      <title>使用 tf.GradientTape() 中的 stop_recording() 跳过某些数据的某些元素的反向传播</title>
      <link>https://stackoverflow.com/questions/77696138/skipping-backpropagation-for-certain-element-of-certain-data-with-stop-recording</link>
      <description><![CDATA[假设我有(4, 2)格式的数据，我的目的是预测三个0或1。（简单的sigmoid问题）
因为我知道这些数据应该用 CNN 处理，所以我将使用 keras.layers.Conv1D 等。
这是一个最小的示例。
&lt;前&gt;&lt;代码&gt;BATCH_SIZE = 2
Sample_inputs = keras.Input((4, 2), batch_size=BATCH_SIZE) # 形状: (BATCH_SIZE, 4, 2)
cnn_layer = keras.layers.Conv1D(3, kernel_size=2, use_bias=False) # 对于较少的可训练变量没有偏差。
cnn_outputs = cnn_layer(sample_inputs) # 形状: (BATCH_SIZE, 3, 3)
密集层 = keras.layers.Dense(1, use_bias=False)
最终输出=密集层（cnn_输出）#形状：（BATCH_SIZE，3，1）

dummy_model = keras.Model(sample_inputs, Final_outputs)

但我的问题是，我知道y_true的某些部分是错误的！
让我进一步说明，
train_x = tf.random.normal((BATCH_SIZE*5, 4, 2)) # 假设我们有 10 个数据
train_y = tf.reshape(tf.random.categorical(tf.math.log([[0.5, 0.5]]),
    num_samples=BATCH_SIZE*5*3*1, dtype=tf.int32), (BATCH_SIZE*5, 3, 1)) # 使值变为 0 或 1。

假设 train_y[2:3, :, :] 是一个张量 shape=(1, 3, 1), dtype=int32, array([[[1], [ 0], [0]]]).但我确信这个张量的第一个元素被污染了。因此，我不希望针对该元素反向传播我的梯度，但我仍然希望针对第二个和第三个元素训练 dummy_model 的 trainable_variables，因为每个数据都非常有价值。
问题1。我这样做在逻辑上正确吗？我仍然可以使用受污染模型的相应模型来计算 y_pred。我还可以跳过特定数据的特定元素的反向传播，当它不可避免时，对吧？
（也许这可能会导致一些偏斜或在某种意义上挑选数据，我知道）
问题2。张量流实现。
经过长时间的研究，我的策略是使用 tf.GradientTape() 的 stop_recording() 方法。
我会将受污染的部分标记（或编辑）为整数 100，并且每当循环注意到 y_batch 中存在 100 时，使用 &lt; code&gt;tf.where(y_batch == 100)，设置cond=True，让tf.GradientTape()照常做他所做的事情，直到然后，将 tf.UnconnectedGradients.ZERO 替换为受污染的，...
我知道这听起来很疯狂，甚至不确定它是否值得。但至少，我的想法是对的吗？]]></description>
      <guid>https://stackoverflow.com/questions/77696138/skipping-backpropagation-for-certain-element-of-certain-data-with-stop-recording</guid>
      <pubDate>Thu, 21 Dec 2023 06:31:10 GMT</pubDate>
    </item>
    <item>
      <title>随着时间的推移预测比例[关闭]</title>
      <link>https://stackoverflow.com/questions/77695627/forecast-proportions-through-time</link>
      <description><![CDATA[我想预测 1-3-6 个月内阳性（样本检测呈阳性）的比例。我的数据有很多负样本测试，因此，它是按月汇总的。假设我有这些数据，它与我所拥有的数据类似。
导入 pandas 作为 pd
将 numpy 导入为 np

日期 = [&#39;2021-07&#39;, &#39;2014-10&#39;, &#39;2014-07&#39;, &#39;2015-04&#39;, &#39;2023-07&#39;, &#39;2006-08&#39;, &#39;2014-04&#39;, &#39;2022-02&#39; , &#39;2019-03&#39;, &#39;2016-04&#39;, &#39;2013-09&#39;, &#39;2013-05&#39;, &#39;2015-01&#39;, &#39;2014-03&#39;, &#39;2012-05&#39;, &#39;2021-08&#39;, &#39; 2016-11&#39;, &#39;2013-06&#39;, &#39;2020-05&#39;, &#39;2006-05&#39;, &#39;2019-06&#39;, &#39;2008-07&#39;, &#39;2017-11&#39;, &#39;2016-06&#39;, &#39;2005- 10&#39;, &#39;2009-04&#39;, &#39;2018-04&#39;, &#39;2005-12&#39;, &#39;2023-02&#39;, &#39;2013-04&#39;, &#39;2013-07&#39;, &#39;2015-09&#39;, &#39;2017-08&#39; , &#39;2012-02&#39;, &#39;2023-06&#39;, &#39;2020-07&#39;, &#39;2008-06&#39;, &#39;2007-09&#39;, &#39;2018-09&#39;, &#39;2015-07&#39;, &#39;2011-10&#39;, &#39; 2014-09&#39;, &#39;2021-09&#39;, &#39;2008-02&#39;, &#39;2009-10&#39;, &#39;2007-10&#39;, &#39;2016-05&#39;, &#39;2022-06&#39;, &#39;2008-09&#39;, &#39;2005- 09&#39;]
正数 = [2, 10, 13, 16, 7, 21, 9, 0, 10, 18, 11, 2, 2, 3, 3, 18, 14, 3, 20, 17, 18, 14, 9, 1 , 4, 10, 22, 11, 8, 11, 2, 19, 16, 0, 22, 0, 6, 19, 14, 10, 19, 8, 13, 2, 3, 2, 11, 13, 16 , 8]
总计 = [122, 69, 145, 122, 117, 111, 64, 146, 54, 189, 136, 171, 159, 125, 66, 199, 160, 75, 171, 168, 167, 133, 154, 171 , 120, 81, 63, 121, 129, 91, 68, 90, 61, 161, 143, 179, 168, 94, 175, 74, 117, 53, 85, 93, 82, 61, 154, 188, 175 ，161]
国家= [&#39;西班牙&#39;，&#39;巴西&#39;，&#39;墨西哥&#39;，&#39;英国&#39;，&#39;意大利&#39;，&#39;德国&#39;，&#39;墨西哥&#39;，&#39;阿根廷&#39;，&#39;德国&#39;，&#39;墨西哥&#39;，&#39;墨西哥&#39;，&#39;意大利&#39;, &#39;英国&#39;, &#39;英国&#39;, &#39;英国&#39;, &#39;意大利&#39;, &#39;墨西哥&#39;, &#39;巴西&#39;, &#39;墨西哥&#39;, &#39;英国&#39;, &#39;意大利&#39;, &#39;意大利&#39;, &#39;德国&#39;, &#39;加拿大&#39;、&#39;巴西&#39;、&#39;巴西&#39;、&#39;西班牙&#39;、&#39;加拿大&#39;、&#39;德国&#39;、&#39;西班牙&#39;、&#39;阿根廷&#39;、&#39;美国&#39;、&#39;巴西&#39;、&#39;德国&#39;、&#39;德国&#39;、&#39;美国”、“西班牙”、“加拿大”、“加拿大”、“美国”、“墨西哥”、“西班牙”、“西班牙”、“阿根廷”、“阿根廷”、“美国”、“英国” 、“墨西哥”、“意大利”、“墨西哥”]
food_groups = [&#39;香肠&#39;, &#39;即食&#39;, &#39;即食&#39;, &#39;香肠&#39;, &#39;即食&#39;, &#39;婴儿食品&#39;, &#39;香肠&#39;, &#39;婴儿食品&#39;, &#39;婴儿食品”、“香肠”、“意大利面”、“意大利面”、“即食食品”、“香肠”、“婴儿食品”、“意大利面”、“意大利面”、“即食食品”、“即食”、“即食”、“即食”、“香肠”、“肉类”、“面食”、“即食”、“婴儿食品”、“面食” &#39;, &#39;即食&#39;, &#39;即食&#39;, &#39;香肠&#39;, &#39;肉类&#39;, &#39;肉类&#39;, &#39;香肠&#39;, &#39;婴儿食品&#39;, &#39;肉类&#39;, &#39;婴儿食品&#39;, &#39;面食&#39;, &#39;意大利面&#39;, &#39;肉&#39;, &#39;肉&#39;, &#39;意大利面&#39;, &#39;意大利面&#39;, &#39;肉&#39;, &#39;意大利面&#39;, &#39;香肠&#39;, &#39;即食&#39;, &#39;即食&#39;, ‘香肠’、‘即食’、‘意大利面’]

df = pd.DataFrame({
    “日期”：日期，
    “积极”：积极的一面，
    “总计”：总计，
    “国家”：国家，
    &#39;食物组&#39;：食物组
})
df[“p”] = df[“正”] / df[“总计”]

df


我可以使用什么机器学习模型？我的数据高度不平衡，有什么想法可以解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/77695627/forecast-proportions-through-time</guid>
      <pubDate>Thu, 21 Dec 2023 03:41:39 GMT</pubDate>
    </item>
    <item>
      <title>在 Kaggle 上进行模型训练时如何使用多个 GPU</title>
      <link>https://stackoverflow.com/questions/77694839/how-can-i-use-multiple-gpus-during-model-training-on-kaggle</link>
      <description><![CDATA[在 Kaggle 上，我有 2 个 GPU T4，但我不明白如何在 Pytorch 中使用它们或调整代码以在 2 个 GPU 上进行训练
2 个 GPU 的图片
我的训练代码：
对于范围（2）中的纪元：

    运行损失 = 0.0
    对于 tqdm（数据集）中的数据：
        输入，标签=数据
        优化器.zero_grad()
        输出 = 模型（输入）
        损失=标准（输出，标签）
        loss.backward()
        优化器.step()

        running_loss += loss.item()
]]></description>
      <guid>https://stackoverflow.com/questions/77694839/how-can-i-use-multiple-gpus-during-model-training-on-kaggle</guid>
      <pubDate>Wed, 20 Dec 2023 22:41:19 GMT</pubDate>
    </item>
    <item>
      <title>我正在尝试找出如何检测聊天机器人用例的意图</title>
      <link>https://stackoverflow.com/questions/77693754/i-am-trying-to-figure-out-how-to-detect-intents-for-chatbot-use-cases</link>
      <description><![CDATA[我想构建一个聊天机器人，我可以在其中预定义一些意图以及 5-10 个可能的问题。聊天机器人应该能够检测给定用户查询的意图。
当我在网上查看时，大多数解决方案都指向针对意图分类任务微调预训练的语言模型。我不想在每次创建聊天机器人时都对模型进行微调，因为它很昂贵。有没有更简单的解决方案？]]></description>
      <guid>https://stackoverflow.com/questions/77693754/i-am-trying-to-figure-out-how-to-detect-intents-for-chatbot-use-cases</guid>
      <pubDate>Wed, 20 Dec 2023 18:29:57 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch中的动态量化量化后开始随机训练</title>
      <link>https://stackoverflow.com/questions/77692089/dynamic-quantization-in-pytorch-starts-random-training-after-quantization</link>
      <description><![CDATA[当我运行以下动态量化代码时，它开始使用一些随机自然图像进行 100 个时期的训练，我不想再次进行训练。我有预训练的权重，我只是想量化我的预训练的权重以减少推理时间：
从 ultralytics 导入 YOLO
进口火炬
导入火炬.量化

模型=YOLO(&#39;pre_trained_weights.pt&#39;)

model.load_state_dict(torch.load(&#39;checkpoint.pth&#39;)) #不知道这一步是否必要

qmodel = torch.quantization.quantize_dynamic(模型, dtype = torch.quint8)

我尝试了上面的代码，我希望我只是想量化我的预训练权重以减少推理时间]]></description>
      <guid>https://stackoverflow.com/questions/77692089/dynamic-quantization-in-pytorch-starts-random-training-after-quantization</guid>
      <pubDate>Wed, 20 Dec 2023 13:53:49 GMT</pubDate>
    </item>
    <item>
      <title>机器学习后出现相同指标结果的问题[关闭]</title>
      <link>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77686328/problem-with-identical-metrics-results-after-machine-learning</guid>
      <pubDate>Tue, 19 Dec 2023 15:36:36 GMT</pubDate>
    </item>
    <item>
      <title>将变量从一个模块导入到另一个模块[关闭]</title>
      <link>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77678535/importing-variables-from-one-module-to-other</guid>
      <pubDate>Mon, 18 Dec 2023 10:44:18 GMT</pubDate>
    </item>
    <item>
      <title>AutoTrain 高级 CLI：错误：无法识别的参数：--fp16 --use-int4</title>
      <link>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</link>
      <description><![CDATA[我目前在使用提供的自动训练工具在 Colab 笔记本中使用 LLM 模型微调数据时遇到问题。错误消息表明 autotrain 无法识别参数“--fp16”和“--use-int4”。我已经检查了文档和语法，但问题仍然存在。您能否提供解决此问题的指导或提供有关任何潜在解决方案的见解？谢谢。
/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13：
 UserWarning：无法加载图像Python扩展：&#39;/usr/local/lib/python3.10/dist-packages/torchvision/image.so：未定义符号：_ZN3c104cuda9SetDeviceEi&#39;如果您不打算使用`torchvision中的图像功能。 io`，你可以忽略这个警告。否则，您的环境可能有问题。在从源代码构建“torchvision”之前，您是否安装了“libjpeg”或“libpng”？ warn( 用法: autotrain  [] AutoTrain 高级 CLI: 错误: 无法识别的参数: --fp16 --use-int4

错误的屏幕截图
直到昨天，这段代码在这个 https://github.com/huggingface/autotrain-advanced 存储库中给出的 colab 笔记本上运行良好微调LLM，现在出现此错误。]]></description>
      <guid>https://stackoverflow.com/questions/77664921/autotrain-advanced-cli-error-unrecognized-arguments-fp16-use-int4</guid>
      <pubDate>Fri, 15 Dec 2023 07:53:31 GMT</pubDate>
    </item>
    <item>
      <title>如何为此笔记本创建 Sagemaker 端点？</title>
      <link>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-notebook</link>
      <description><![CDATA[我创建了一个 VectorDB (FAISS) 并将 PDF 输入到其中。然后我使用 AWS Bedrock 的 Langchain 包装器来调用它。我知道现在存在 Kowledge Base，但至少在 SageMaker 笔记本中，我有更多的控制权。该模型在 SageMaker Notebook 中完美运行，当我提出问题时，它会返回答案。
我想做的是创建一个小网页（并通过 HTTP/REST API），只需在文本字段中提交问题并在文本字段中接收答案。我猜如果链中某个地方没有 Lambda 函数，这很难做到，或者也许不是？
当我查看 Sagemaker 控制台的推理选项卡下时，没有模型或没有端点，或者没有&lt; /strong&gt; 端点配置（因为我没有从 Sagemaker 选择模型，所以我只是在 Python 笔记本中使用 langchain LLM 和 Bedrock，如下所示）。
&lt;前&gt;&lt;代码&gt;导入boto3
导入 json

bedrock = boto3.client(service_name=&quot;bedrock&quot;)
bedrock_runtime = boto3.client(service_name=“bedrock-runtime”)



从 langchain.llms.bedrock 导入 Bedrock
从 langchain.chains 导入 RetrievalQA
从 langchain.prompts 导入 PromptTemplate

嵌入 = BedrockEmbeddings(model_id=“amazon.titan-embed-text-v1”,
                               客户端=bedrock_runtime）

最终我将文档嵌入到 FAISS Vector 数据库中，我查询的就是这个数据库
db = FAISS.from_documents（文档，嵌入）


模型泰坦 = {
    “最大令牌计数”：512，
    “停止序列”：[]，
    “温度”：0.0，
    “顶部P”：0.5
}

# 亚马逊泰坦模型
llm = 基岩(
    model_id=&quot;amazon.titan-text-express-v1&quot;,
    客户端=bedrock_runtime，
    model_kwargs=model_titan,
）

然后定义一个提示......
提示 = 提示模板(
    template=prompt_template, input_variables=[“上下文”, “问题”]
）

并查询数据库：
qa = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type=“东西”，
    检索器=db.as_retriever(
        search_type=“相似度”，
    ),
    return_source_documents=真，
    chain_type_kwargs={“提示”: 提示},
）



query =“未来的技术是什么样的？”

结果 = qa({“查询”: 查询})

print(f&#39;查询: {结果[“查询”]}\n&#39;)
print(f&#39;结果: {结果[“结果”]}\n&#39;)
print(f&#39;上下文文档：&#39;)
对于结果 [“source_documents”] 中的 srcdoc：
      打印（f&#39;{srcdoc}\n&#39;）

这恰好返回了我在 Sagemaker 中需要的内容，我只需要从外部查询数据库即可。
我不想让 lambda 函数每次都重建链。我考虑的是效率，我需要的只是在 lambda 函数中传递查询并返回结果。
]]></description>
      <guid>https://stackoverflow.com/questions/77660996/how-can-i-create-a-sagemaker-endpoint-for-this-notebook</guid>
      <pubDate>Thu, 14 Dec 2023 14:49:20 GMT</pubDate>
    </item>
    <item>
      <title>更改张量流中预训练模型的输出层</title>
      <link>https://stackoverflow.com/questions/77162671/changing-the-output-layer-of-a-pre-trained-model-in-tensorflow</link>
      <description><![CDATA[我有一个预先训练的模型，只想将输出层更改为具有更多单元的新层。在本例中，旧输出层有 18 个单元，新输出层应有 20 个单元。
我当前的实现如下所示：
old_model = load_model(model_filepath)
helper_model = 模型(输入=old_model.inputs, 输出=old_model.layers[-2].output)
new_output = Dense(单位 = old_model.layers[-1].units + 增量，激活=&#39;softmax&#39;，activity_regularizer=l1_l2(l1l2[0],
                       l1l2[1]))(helper_model.output)
new_model = 模型(输入=helper_model.input, 输出=new_output)

如果我打印 new_model.summary() 并查看最后一层，一切看起来都很好：
 密集（密集）（无，20）2580 [&#39;dropout[0][0]&#39;]

=================================================== =====================================

但是，当我尝试训练 new_model 时，出现以下错误：
ValueError：形状（无，18）和（无，20）不兼容

为什么我会收到此消息以及如何解决此问题？我是否需要重塑图层？]]></description>
      <guid>https://stackoverflow.com/questions/77162671/changing-the-output-layer-of-a-pre-trained-model-in-tensorflow</guid>
      <pubDate>Sat, 23 Sep 2023 10:42:30 GMT</pubDate>
    </item>
    <item>
      <title>为什么 sklearn MLPClassifier 无法预测异或？</title>
      <link>https://stackoverflow.com/questions/63057691/why-cant-sklearn-mlpclassifier-predict-xor</link>
      <description><![CDATA[理论上，具有单个隐藏层和 3 个神经元的 MLP 足以正确预测异或。有时它可能无法正确收敛，但 4 个神经元是安全的选择。
这是一个示例
我尝试使用 sklearn.neural_network.MLPClassifier 重现此问题：
从sklearn导入neural_network
从 sklearn.metrics 导入准确度分数、精确度分数、召回分数
将 numpy 导入为 np


x_train = np.random.uniform(-1, 1, (10000, 2))
tmp = x_train &gt; 0
y_train = 2 * (tmp[:, 0] ^ tmp[:, 1]) - 1

模型=neural_network.MLPClassifier(
    hidden_​​layer_sizes=(3,), n_iter_no_change=100,
    Learning_rate_init=0.01，max_iter=1000
).fit(x_train, y_train)

x_test = np.random.uniform(-1, 1, (1000, 2))
tmp = x_test &gt; 0
y_test = 2 * (tmp[:, 0] ^ tmp[:, 1]) - 1

预测 = model.predict(x_test)
print(f&#39;准确率: {accuracy_score(y_pred=预测, y_true=y_test)}&#39;)
print(f&#39;recall: {recall_score(y_pred=预测, y_true=y_test)}&#39;)
print(f&#39;精度: { precision_score(y_pred=预测, y_true=y_test)}&#39;)

我只能得到大约 0.75 的准确度，而张量流游乐场模型是完美的，你知道是什么造成了差异吗？
还尝试使用张量流：
模型 = tf.keras.Sequential(layers=[
    tf.keras.layers.Input(形状=(2,)),
    tf.keras.layers.Dense(4, 激活=&#39;relu&#39;),
    tf.keras.layers.Dense(1)
]）

model.compile(loss=tf.keras.losses.binary_crossentropy)

x_train = np.random.uniform(-1, 1, (10000, 2))
tmp = x_train &gt; 0
y_train = (tmp[:, 0] ^ tmp[:, 1])

model.fit(x=x_train, y=y_train)

x_test = np.random.uniform(-1, 1, (1000, 2))
tmp = x_test &gt; 0
y_test = (tmp[:, 0] ^ tmp[:, 1])

预测 = model.predict(x_test) &gt; 0.5
print(f&#39;准确率: {accuracy_score(y_pred=预测, y_true=y_test)}&#39;)
print(f&#39;recall: {recall_score(y_pred=预测, y_true=y_test)}&#39;)
print(f&#39;精度: { precision_score(y_pred=预测, y_true=y_test)}&#39;)

通过这个模型，我得到了与 scikit-learn 模型类似的结果......所以这不仅仅是一个 scikit-learn 问题 - 我是否缺少一些重要的超参数？
编辑
好的，将损失更改为均方误差而不是交叉熵，现在我在张量流示例中获得了 0.92 的精度。我猜这是 MLPClassifier 的问题？]]></description>
      <guid>https://stackoverflow.com/questions/63057691/why-cant-sklearn-mlpclassifier-predict-xor</guid>
      <pubDate>Thu, 23 Jul 2020 15:22:48 GMT</pubDate>
    </item>
    </channel>
</rss>