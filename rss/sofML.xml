<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Fri, 20 Sep 2024 06:23:50 GMT</lastBuildDate>
    <item>
      <title>如何在将作业提交给 QPU 之前预先检查代码中的错误</title>
      <link>https://stackoverflow.com/questions/79005253/how-to-before-hand-check-for-errors-in-the-code-before-submitting-the-job-to-qpu</link>
      <description><![CDATA[在 QSVM 的背景下，是否有一种方法可以在将量子代码提交给 QPU 进行处理之前检查错误，因为即使代码有错误，QPU 也会运行，这意味着我们将白白浪费大量时间，所以有没有什么办法可以解决这个问题。]]></description>
      <guid>https://stackoverflow.com/questions/79005253/how-to-before-hand-check-for-errors-in-the-code-before-submitting-the-job-to-qpu</guid>
      <pubDate>Fri, 20 Sep 2024 04:51:21 GMT</pubDate>
    </item>
    <item>
      <title>完成 model.register 后，如何在新的 SageMaker Studio UI 中访问评估指标？</title>
      <link>https://stackoverflow.com/questions/79005084/how-to-access-evaluation-metrics-in-new-sagemaker-studio-ui-after-doing-model-re</link>
      <description><![CDATA[我正在为机器学习模型构建 MLOP 管道。注册模型后，如何在 SageMake Studio UI 中访问模型的评估指标？
这是我在 S3 中保存的示例 evaluation.json
{
&quot;metric_groups&quot;: [
{
&quot;name&quot;: &quot;regression_metrics&quot;,
&quot;metric_data&quot;: [
{
&quot;name&quot;: &quot;mse&quot;,
&quot;value&quot;: 6107087691.96
},
{
&quot;name&quot;: &quot;mae&quot;,
&quot;value&quot;: 46717.104
},
{
&quot;name&quot;: &quot;rmse&quot;,
&quot;value&quot;: 78147.85
},
{
&quot;name&quot;: &quot;r2&quot;,
&quot;value&quot;: 0.90
]
}
]
}

这是我的注册步骤：
import logs
from sagemaker.workflow.functions import Join
from sagemaker.model_metrics import MetricsSource, ModelMetrics
from sagemaker.workflow.step_collections import RegisterModel

def create_register_step(
role,
sagemaker_session,
model_package_group_name,
model_approval_status,
training_step,
evaluation_step
):

logs.basicConfig(level=logging.INFO)
logs.info(f&#39;创建注册步骤&#39;)

# log evaluation_report
logs.info(f&#39;评估报告：{evaluation_step}&#39;)

evaluation_s3_uri = evaluation_step.properties.ProcessingOutputConfig.Outputs[&#39;evaluation&#39;].S3Output.S3Uri

model_metrics = ModelMetrics(
model_statistics=MetricsSource(
s3_uri=Join(
on=&quot;/&quot;,
values=[
evaluation_s3_uri,
&quot;evaluation.json&quot;
]
),
content_type=&quot;application/json&quot;
)
)

# 创建 RegisterModel 步骤
register_step = RegisterModel(
name=&#39;ModelRegisterStep&#39;,
estimator=training_step.estimator,
model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,
content_types=[&quot;text/csv&quot;],
response_types=[&quot;text/csv&quot;],
inference_instances=[&quot;ml.m5.large&quot;, &quot;ml.m5.xlarge&quot;],
transform_instances=[&quot;ml.m5.large&quot;],
model_package_group_name=model_package_group_name,
approved_status=model_approval_status,
model_metrics=model_metrics
)

return register_step


我的管道执行成功，但我看不到评估指标
附加图片
我也尝试过手动将 S3 中的评估报告添加到模型版本中，但没有成功]]></description>
      <guid>https://stackoverflow.com/questions/79005084/how-to-access-evaluation-metrics-in-new-sagemaker-studio-ui-after-doing-model-re</guid>
      <pubDate>Fri, 20 Sep 2024 03:26:51 GMT</pubDate>
    </item>
    <item>
      <title>R中一个记录和另一个数据集之间的Gower距离</title>
      <link>https://stackoverflow.com/questions/79004932/gower-distance-between-one-record-and-another-dataset-in-r</link>
      <description><![CDATA[我想计算数据集 1 的一条记录与数据集 2 的所有记录之间的 Gower 距离。我可以编写如下代码吗？
library(gower)

data(iris)
dat1 &lt;- iris[1:10,]
dat2 &lt;- iris[11:30,]

gower::gower_dist(dat1[1,], dat2)

这给了我长度为 20 的结果。

0.09079365 0.09873016 0.16142857 0.29476190 0.20920635 0.33079365 0.21936508 0.05000000 0.23952381 0.11507937 0.12095238 0.15079365 0.16984127 0.24523810 0.16539683 0.12920635 0.17206349 0.03555556 0.02761905 0.14063492

我可以将第一个值解释为 dat1[1,] 和 dat2[1,] 之间的 gower 距离，将第二个值解释为 dat1[1,] 和 dat2[2,] 之间的 gower 距离，依此类推吗？
让我感到困惑的是，如果我计算
gower::gower_dist(dat1[1,],dat2[1,])

，这给了我

0.75

它应该是 0.09079365 吗？为什么是 0.75？
最终，我想计算 dat1 中每个观测值与 dat2 中每个观测值的 gower 距离。]]></description>
      <guid>https://stackoverflow.com/questions/79004932/gower-distance-between-one-record-and-another-dataset-in-r</guid>
      <pubDate>Fri, 20 Sep 2024 01:30:11 GMT</pubDate>
    </item>
    <item>
      <title>使用 MATLAB 和 Roboflow 从标记图像测量裂缝宽度 [关闭]</title>
      <link>https://stackoverflow.com/questions/79003546/measuring-crack-width-from-labeled-images-using-matlab-and-roboflow</link>
      <description><![CDATA[我有一个包含裂缝的图像数据集，我使用 MATLAB 中的像素标记对其进行了标记。我使用 Roboflow 用这些标记图像训练了一个模型。现在，我想测量图像中裂缝的宽度。图像还有一个网格供参考
具体来说，我需要模型：

测量裂缝宽度。
将裂缝归类为：

&quot;小于 0.3 毫米&quot;
&quot;大于 0.3 毫米&quot;



此外，输出应包括裂缝的类型（例如，发际线、结构等）。
我到目前为止尝试过的方法：
我已经使用 Roboflow 训练了模型，但我不确定如何继续测量裂缝宽度。
我探索过使用 MATLAB 进行像素标记，但还没有找到正确的方法来计算宽度并根据 0.3 毫米阈值对其进行分类。
问题：
我应该采用什么方法来测量图像中的裂缝宽度？
是否有特定的工具、库或软件（除 MATLAB 和 Roboflow 之外）可以帮助完成这项任务？
有人可以推荐相关课程或文档来帮助我改进我的方法吗？]]></description>
      <guid>https://stackoverflow.com/questions/79003546/measuring-crack-width-from-labeled-images-using-matlab-and-roboflow</guid>
      <pubDate>Thu, 19 Sep 2024 16:18:54 GMT</pubDate>
    </item>
    <item>
      <title>层“edsr_model”的输入 0 与层不兼容：预期形状=（None，None，None，3），发现形状=（1，16，24，24，3）</title>
      <link>https://stackoverflow.com/questions/79002391/input-0-of-layer-edsr-model-is-incompatible-with-the-layer-expected-shape-no</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/79002391/input-0-of-layer-edsr-model-is-incompatible-with-the-layer-expected-shape-no</guid>
      <pubDate>Thu, 19 Sep 2024 11:52:43 GMT</pubDate>
    </item>
    <item>
      <title>需要图案加工的技术流程[关闭]</title>
      <link>https://stackoverflow.com/questions/79001874/need-technical-flow-for-pattern-machining</link>
      <description><![CDATA[我想要一个可以告诉我应该对数据中的某些 ID 执行哪些操作的东西。例如，我们应该更新还是忽略类型为“xyz”的 ID？这个选择应该由先前的操作支持。我可以使用什么技术来实现这一点？
我查了一下 scikit-learn；它会有帮助吗？]]></description>
      <guid>https://stackoverflow.com/questions/79001874/need-technical-flow-for-pattern-machining</guid>
      <pubDate>Thu, 19 Sep 2024 09:35:17 GMT</pubDate>
    </item>
    <item>
      <title>CustomScaler 类型的对象未在 gurobi_ml 中注册/支持</title>
      <link>https://stackoverflow.com/questions/79000471/object-of-type-customscaler-is-not-registered-supported-with-gurobi-ml</link>
      <description><![CDATA[我在 sklearn.pipeline.make_pipeline 中构建了一个 CustomScaler 来缩放我的数据。它包含 transform 和 inversetransform 函数。当我使用 gurobipy 优化回归模型时，我得到了标题错误。Gurobi 文档中没有明确提到他们不接受 CustomScaler，但提到他们接受 StandardScalar 的很多地方。我是否需要使用不同的方法来制定我的问题，或者我可以在 gurobipy_ml 中使用 CustomScalar？
我采用了最简单的方法并使用 StandardScalar，但用作 CustomeScalar，并得到
NotRegistred：CustomScaler 类型的对象未在 gurobi_ml 中注册/支持。

class CustomScaler(BaseEstimator, TransformerMixin):
def __init__(self):
self.scaler = StandardScaler()

def fit(self, X, y=None):
return self.scaler.fit(X)

def transform(self, X):
return self.scaler.transform(X)

def inverse_transform(self, X):
return self.scaler.inverse_transform(X)
]]></description>
      <guid>https://stackoverflow.com/questions/79000471/object-of-type-customscaler-is-not-registered-supported-with-gurobi-ml</guid>
      <pubDate>Wed, 18 Sep 2024 23:50:16 GMT</pubDate>
    </item>
    <item>
      <title>将 Tensorflow 从 2.15.0 升级到 2.17.0 后，加载 .h5 中保存的模型时出现问题</title>
      <link>https://stackoverflow.com/questions/78999039/problems-loading-a-model-saved-in-h5-after-upgrading-tensorflow-from-2-15-0-to</link>
      <description><![CDATA[我使用 tensorflow 库版本 2.15.0 创建了一个 LSTM 模型。
我现在必须在一个新项目中使用创建的模型，但在这个项目中我必须使用所有更新的库以及最新的 python 版本，所以我不得不做一些更改，这些是关键的更新：




从
到




python
3.11.5
3.12.6


h5py
3.9.0
3.11.0


keras
2.15.0
3.5.0


numpy
1.24.3
1.26.4


pandas
2.0.3
2.2.2


tensorboard
2.15.2
2.17.2


tensorflow
2.15.0
2.17.0


tensorflow-intel
2.15.0
2.17.0



在新项目中我唯一使用的 tensorflow 是用于 load_model，我这样做：
def load_model_and_hyperparams(model_name):

logging.info(f&quot;Loading model and parameters for &#39;{model_name}&#39;&quot;)

try:
model_path = os.path.join(os.getcwd(), &quot;python&quot;, model_name, f&quot;{model_name}.h5&quot;)
model = tf.keras.models.load_model(model_path) 

params_path = os.path.join(os.getcwd(), &quot;python&quot;, model_name, &quot;_hyperparameters.json&quot;)
with open(params_path, &#39;r&#39;) as f:
params = json.load(f)

logging.info(f&quot;Model and成功加载 {model_name} 的参数&quot;)
返回模型，参数

除外异常为 e:
logging.error(f&quot;无法加载 {model_name} 的模型或参数。错误：{e}&quot;)
引发

这是我得到的错误：

18-09-2024 16:28:08 INFO：正在加载“modello_canale”的模型和参数
18-09-2024 16:28:08 ERROR：无法加载 modello_canale 的模型或参数。
错误：传递给 LSTM 的关键字参数无法识别：{&#39;time_major&#39;：False}

我尝试将模型加载到旧版本的 tensorflow 中，并从存储在 HDF5(.h5) 文件中的模型配置中删除 time_major 属性。
据我所知，这应该是 h5 文件结构的示例：

/

═── model_weights (group)
│ ═── layer_1 (group)
│ │ └── weights (dataset)
│ └── layer_2 (group)
│ └── weights (dataset)
═── model_config (group 或 dataset)
│ └── properties (键值对，如 &#39;time_major&#39;)
└── training_config (group)
└── optimizer (dataset)

这种方法不需要重新训练或重新创建模型，而是直接修改 HDF5 文件中存储的模型配置以删除无效参数，从而允许模型无错误地加载。
我不知道还能尝试什么。我的目标是删除 time_major，而不必在 2.17.0 版本中重新创建模型。]]></description>
      <guid>https://stackoverflow.com/questions/78999039/problems-loading-a-model-saved-in-h5-after-upgrading-tensorflow-from-2-15-0-to</guid>
      <pubDate>Wed, 18 Sep 2024 15:24:44 GMT</pubDate>
    </item>
    <item>
      <title>如何在 tensorboard logger add_image 中设置 cmap = 'hsv'？</title>
      <link>https://stackoverflow.com/questions/78996316/how-to-set-a-cmap-hsv-in-tensorboard-logger-add-image</link>
      <description><![CDATA[我有一个通道图像，想使用 writer.add_image 将它们添加到 tensorboard 记录器中，如下所示：
 generated_images_to_show = torch.cat(gtimage_cpu, predimage_cpu), dim=0)
gen_image_grid = make_grid(generated_images_to_show .unsqueeze(1), nrow=inputs.size(0), padding=6, normalize=False)
writer.add_image(&#39;Validation Gen Comparison&#39;, gen_image_grid, epoch)

我生成的图像有一个通道，我需要使用 cmap= &#39;hsv&#39; 绘制它们，但 add_image 中没有可用的 cmap 功能。在这种情况下，我该怎么办？我只想在 tensorboard 中查看结果。
一种解决方案是将图像转换为 RGB 通道，然后使用 cmap=hsv 并将转换后的图像记录到 tensorboard，还有其他（也许更有效的）解决方案吗？]]></description>
      <guid>https://stackoverflow.com/questions/78996316/how-to-set-a-cmap-hsv-in-tensorboard-logger-add-image</guid>
      <pubDate>Wed, 18 Sep 2024 01:48:03 GMT</pubDate>
    </item>
    <item>
      <title>预测多元时间序列（《动手机器学习》一书第 15 章）错误</title>
      <link>https://stackoverflow.com/questions/77623127/forecasting-multivariate-time-series-in-chapter-15-of-the-book-hands-on-machin</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/77623127/forecasting-multivariate-time-series-in-chapter-15-of-the-book-hands-on-machin</guid>
      <pubDate>Thu, 07 Dec 2023 21:20:01 GMT</pubDate>
    </item>
    <item>
      <title>如何继续openai API的不完整响应</title>
      <link>https://stackoverflow.com/questions/76206459/how-to-continue-incomplete-response-of-openai-api</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/76206459/how-to-continue-incomplete-response-of-openai-api</guid>
      <pubDate>Tue, 09 May 2023 06:33:09 GMT</pubDate>
    </item>
    <item>
      <title>无法更改嵌入维度以将其传递给 gpt2</title>
      <link>https://stackoverflow.com/questions/74996908/cant-change-embedding-dimension-to-pass-it-through-gpt2</link>
      <description><![CDATA[我正在练习图像字幕，在张量的不同维度方面遇到了一些问题。所以我的图像嵌入又名大小 [1, 512]，但我用于字幕生成的 GPT2 需要大小 [n, 768]，其中 n 是字幕开头的标记数。我不知道如何更改图像嵌入的维度以使其通过 GPT2。
我认为用零填充图像嵌入是个好主意，因此大小将是 [1, 768]，但我认为这会对结果字幕产生负面影响。
谢谢你的帮助！
我曾尝试用零填充图像嵌入，使其大小为 [1, 768]，但我认为这不会有太大帮助]]></description>
      <guid>https://stackoverflow.com/questions/74996908/cant-change-embedding-dimension-to-pass-it-through-gpt2</guid>
      <pubDate>Tue, 03 Jan 2023 17:50:56 GMT</pubDate>
    </item>
    <item>
      <title>np.where：“ValueError：操作数不能与形状一起广播（38658637，）（9456，）”</title>
      <link>https://stackoverflow.com/questions/62721390/np-where-valueerror-operands-could-not-be-broadcast-together-with-shapes-386</link>
      <description><![CDATA[我有两个具有两种不同形状的数据框：

df_rts_1 #Shape: (38658637, 7)
df_crsh_rts #Shape: (9456, 6)

我尝试使用 np.where 根据以下特定条件将列值 (df_rts_1[&#39;crash&#39;]) 更新为等于 1：

df_rts_1[&#39;tmc_code&#39;]= df_crsh_rts[&#39;tmc&#39;]
df_rts_1[&#39;measurement_tstamp&#39;] 介于 df_crsh_rts[&#39;Start_time&#39;] 和df_crsh_rts[&#39;Closed_time&#39;]

我的代码：
df_rts_1[&#39;crash&#39;] = np.where((df_rts_1[&#39;tmc_code&#39;].values == df_crsh_rts[&#39;tmc&#39;].values) &amp; ((df_rts_1[&#39;measurement_tstamp&#39;].values &gt; df_crsh_rts[&#39;Start_time&#39;].values) &amp; (df_rts_1[&#39;measurement_tstamp&#39;].values &gt; df_crsh_rts[&#39;Closed_time&#39;].values)), 1, df_rts_1[&#39;crash&#39;])

我收到了标题中的错误。我对 Python/数据科学还很陌生。]]></description>
      <guid>https://stackoverflow.com/questions/62721390/np-where-valueerror-operands-could-not-be-broadcast-together-with-shapes-386</guid>
      <pubDate>Fri, 03 Jul 2020 19:07:11 GMT</pubDate>
    </item>
    <item>
      <title>如何计算 CNN 的权重数量？</title>
      <link>https://stackoverflow.com/questions/59343843/how-to-compute-number-of-weights-of-cnn</link>
      <description><![CDATA[考虑到用于将图像分为两类的卷积神经网络，我们如何计算权重数量：

输入：100x100 灰度图像。
第 1 层：具有 60 个 7x7 卷积滤波器的卷积层（步长 = 1，有效填充）。
第 2 层：具有 100 个 5x5 卷积滤波器的卷积层（步长 = 1，有效填充）。
第 3 层：最大池化层，将第 2 层下采样 4 倍（例如，从 500x500 到 250x250）
第 4 层：具有 250 个单元的密集层
第 5 层：具有 200 个单元的密集层单元
第 6 层：单输出单元

假设每层都存在偏差。此外，池化层具有权重（类似于 AlexNet）
这个网络有多少个权重？
一些 Keras 代码
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv2D, MaxPooling2D

model = Sequential()

# 第 1 层
model.add(Conv2D(60, (7, 7), input_shape = (100, 100, 1), padding=&quot;same&quot;, activity=&quot;relu&quot;))

# 第 2 层
model.add(Conv2D(100, (5, 5), padding=&quot;same&quot;, activity=&quot;relu&quot;))

# 第3
model.add(MaxPooling2D(pool_size=(2, 2)))

# 第 4 层
model.add(Dense(250))

# 第 5 层
model.add(Dense(200))

model.summary()
]]></description>
      <guid>https://stackoverflow.com/questions/59343843/how-to-compute-number-of-weights-of-cnn</guid>
      <pubDate>Sun, 15 Dec 2019 12:19:58 GMT</pubDate>
    </item>
    <item>
      <title>自适应带宽核密度估计</title>
      <link>https://stackoverflow.com/questions/31483625/adaptive-bandwidth-kernel-density-estimation</link>
      <description><![CDATA[似乎有大量信息和工具可用于实现标准的多变量或单变量核密度估计。但是，我目前处理的离散地理数据特别稀疏，并且往往聚集在人口密度较高的地区。
也就是说，我在地图上有许多点（经度和纬度），我想根据这些点估计概率密度，但我需要以某种方式对人口密度进行归一化。从周围看，似乎解决此类问题的正确方法是实现某种最近邻自适应带宽来进行核估计。然而，stats.gaussian_kde 似乎不支持自适应带宽。有人知道我如何自己实现这一点，或者是否有任何可用于自适应带宽 KDE 的软件包？]]></description>
      <guid>https://stackoverflow.com/questions/31483625/adaptive-bandwidth-kernel-density-estimation</guid>
      <pubDate>Fri, 17 Jul 2015 19:47:58 GMT</pubDate>
    </item>
    </channel>
</rss>