<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 16 Apr 2024 09:14:07 GMT</lastBuildDate>
    <item>
      <title>对于表格数据模型中的过度拟合我该怎么办</title>
      <link>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</link>
      <description><![CDATA[我建立了一个预测模型，用于根据所提供数据中的某些特征来预测结果。
该模型是一个利用 fastai 的表格学习器。
该数据集包含约 300 条记录，分为训练集、验证集和测试集。
我已经实现了解决过度拟合的技术，例如提前停止和权重衰减，但在对未见过的数据进行评估时，模型仍然似乎过度拟合。
此外，我还尝试调整学习率和批量大小等超参数，但没有改善。我怀疑我的模型架构或预处理管道的某些方面可能会导致该问题，但我不确定从哪里开始调查。
鉴于该项目的敏感性，我无法提供有关数据集或预测任务的具体细节，但我可以分享当前模型的预处理和结构。
这是训练的输出：

&lt;标题&gt;

纪元
train_loss
valid_loss
准确度
时间


&lt;正文&gt;

0
0.752707
0.579501
0.776119
00:00


1
0.699270
0.833771
0.776119
00:00


2
0.652438
0.598243
0.791045
00:00


3
0.621083
3.889398
0.776119
00:00


4
0.591348
0.632366
0.791045
00:00


5
0.580582
6.670314
0.791045
00:00



&lt;块引用&gt;
自 epoch 2 以来没有任何改进：提前停止

这是预处理的代码（在我构建了我不能透露的功能之后）。
features 列表定义每个特征，包括有效值范围和权重（feature、range_ 和 weight 如下面的标准化函数中所使用的那样）。
def custom_normalize(df, 特征, range_, 权重):
    df[特征] = 归一化(df[特征], range_)
    df[特征] = df[特征] * 权重
    返回df

分割 = RandomSplitter(valid_pct=0.2)(range_of(df))

procs = [分类，填充缺失]

对于功能，features.items() 中的信息：
    # 确定训练时选择值的范围。
    procs.append(partial(custom_normalize, feature=feature, range_=info[&#39;range&#39;],weight=info[&#39;weight&#39;]))

据我所知，构建模型和训练是相当标准的：
to = TabularPandas(df, procs=procs,
                   cat_names = cat_vars,
                   连续名称=连续变量，
                   y_names=dep_var,
                   分裂=分裂）

dls = to.dataloaders(bs=64)

Early_stop = EarlyStoppingCallback(监视器=&#39;准确度&#39;, min_delta=0.01, 耐心=3)

学习 = tabular_learner(dls, 指标=准确度, wd=0.1)
学习.lr_find()

# 绘制学习率。
learn.recorder.plot_lr_find()

# 根据情节选择学习率。
lr = learn.recorder.lrs[np.argmin(learn.recorder.losses)]

learn.fit_one_cycle(15, lr, cbs=early_stop)
学习.show_results()

# 如果模型不存在则只保存模型
# TODO 将保存包装在条件中，以防止模型存在时进行保存。
如果不是 os.path.exists(model_fname):
    学习.保存(model_fname)
]]></description>
      <guid>https://stackoverflow.com/questions/78333191/what-can-i-do-about-overfitting-in-tabular-data-model</guid>
      <pubDate>Tue, 16 Apr 2024 08:38:01 GMT</pubDate>
    </item>
    <item>
      <title>不使用 aruco 标记检测物体的大小</title>
      <link>https://stackoverflow.com/questions/78332353/not-detecting-the-size-of-object-using-aruco-markers</link>
      <description><![CDATA[我有一个使用aruco标记来检测实时物体识别的代码，使用yolo v8模型，它检测到物体但不检测到大小
代码运行并给出输出：0: 192x224 1 aloo methi, 91.7ms
从 ultralytics 导入 YOLO
导入CV2
将 numpy 导入为 np

# 加载YOLO模型
model_path = &#39;D:/Food_Images.v1i.yolov8/runs/detect/train/weights/last.pt&#39;
模型 = YOLO(模型路径)

# ArUco 定义
aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)
参数 = cv2.aruco.DetectorParameters()
检测器 = cv2.aruco.ArucoDetector(aruco_dict, 参数)

# 使用 YOLO 预测边界框
结果 = model.predict(source=&#39;0&#39;, show=True)

对于结果中的结果：
    盒子=结果.盒子
    对于盒中盒：
        x1, y1, x2, y2 = 盒子.xyxy
        宽度 = x2 - x1
        高度 = y2 - y1
        print(f&#39;边界框大小：width={width}, height={height}&#39;)
        
        # 检测ArUco标记
        角点、id、rejectedImgPoints = detector.detectMarkers()
        print(f&#39;ArUco 标记角: {corners}&#39;)
        print(f&#39;ArUco 标记 ID: {ids}&#39;)
        
        如果 ids 不是 None 并且 len(ids) &gt; 0:
            marker_size = 10 # 标记的大小，以厘米为单位（根据实际标记大小进行调整）
            Pixel_size = Corners[0][0][1][0] - Corners[0][0][0][0] # 假设标记是正方形
            cm_per_pixel = 标记尺寸 / 像素尺寸
            打印（f&#39;cm_per_pixel：{cm_per_pixel}&#39;）
            对象大小 = 宽度 * 高度 * cm_per_pixel
            print(f&#39;物体尺寸：{object_size} cm^2&#39;)

# 打印 YOLO 结果
打印（结果）

如何获取对象大小？]]></description>
      <guid>https://stackoverflow.com/questions/78332353/not-detecting-the-size-of-object-using-aruco-markers</guid>
      <pubDate>Tue, 16 Apr 2024 05:45:13 GMT</pubDate>
    </item>
    <item>
      <title>训练边缘 TPU 的 keras 对象检测模型（珊瑚）</title>
      <link>https://stackoverflow.com/questions/78332142/train-keras-object-detection-model-for-edge-tpucoral</link>
      <description><![CDATA[对于客户，我需要训练一个能够在珊瑚板上运行以进行边缘 TPU 推理的对象检测模型，有一些使用 TensorFlow Lite Model Maker 简化过程的示例或使用 kerasCV 的其他一些示例（不适用于Edge TPU），但对于这个客户，我们希望使用纯 keras，因为模型制作者无法满足一些要求（据我所知，如果错误，请纠正我），特别是：

需要计算一些额外的指标（例如：一些用 coco 获得的指标）
评估者）

需要跟踪张量板中的指标以比较不同的
运行、不同的数据集、执行提前停止、检测下/上
装修等


有人做过类似的事情吗？或者有什么例子或想法吗？]]></description>
      <guid>https://stackoverflow.com/questions/78332142/train-keras-object-detection-model-for-edge-tpucoral</guid>
      <pubDate>Tue, 16 Apr 2024 04:35:48 GMT</pubDate>
    </item>
    <item>
      <title>LogisticRegression 模型产生 100% 的准确度</title>
      <link>https://stackoverflow.com/questions/78332079/logisticregression-model-producing-100-percent-accuracy</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78332079/logisticregression-model-producing-100-percent-accuracy</guid>
      <pubDate>Tue, 16 Apr 2024 04:09:28 GMT</pubDate>
    </item>
    <item>
      <title>提供 LSTM 密集层的先前时间戳预测作为下一个时间戳的附加输入</title>
      <link>https://stackoverflow.com/questions/78331808/providing-previous-time-stamp-prediction-of-dense-layer-of-lstm-as-additional-in</link>
      <description><![CDATA[下面是训练模型代码的一些部分
Prev_pred=无

对于范围内的 t(Ty)：

# 步骤 2.A：执行注意力机制的一步以获取步骤 t 的上下文向量
上下文 = one_step_attention(X[:,t,:], cnn_model_input, s)
打印（上下文.形状）

# 将后注意力 LSTM 单元应用到“上下文”向量。
如果 prev_pred 为 None：
  # 使用所需的形状初始化 prev_pred
  prev_pred = tf.keras.Input(shape=(1, 特征))
  prev_pred = tf.zeros_like(prev_pred)
  #print(prev_pred.shape)
别的 ：
  prev_pred=重复向量(1)(prev_pred)
  #print(prev_pred.shape)


s,_,c = LSTM(n_s, return_state = True)(上下文,initial_state=[s, c])

# 将 Dense 层应用于后置 LSTM 的隐藏状态输出
输出=密集（特征，激活=&#39;线性&#39;）（s）
上一个_pred=输出

# 步骤 2.D：追加“out”到“输出”列表（≈ 1 行）
输出.append(out)



# 创建模型
模型=模型（输入=[X_CNN_输入，X_lstm_输入，s0，c0]，输出=输出）

返回模型

以下是我的变量的维度。
上下文-&gt; （无，无，64）
s-&gt; （无，64）
出-&gt; （无，30）
prev_pred -&gt;;我已经让它成形了（无、1、30）

我尝试了很多事情，例如串联和在通道方向上向 prev_pred 添加 34 个长度的附加零后应用 Add() 层，以便可以轻松地添加上下文，但没有任何效果会出现不同的错误。&lt; /p&gt;
#context = tf.concat([context, prev_pred], axis=-1) # 与之前的预测连接
#context=Add()(context,prev_pred) # 已经在通道方向上为 prev_pred 添加了零，但是为了避免混淆，此处未包含该部分

上面这两种方法都不行
在我的代码中
n_s 值为 64
特征值为30

如果我既不使用串联也不使用添加，我的代码就可以正常工作。]]></description>
      <guid>https://stackoverflow.com/questions/78331808/providing-previous-time-stamp-prediction-of-dense-layer-of-lstm-as-additional-in</guid>
      <pubDate>Tue, 16 Apr 2024 02:22:36 GMT</pubDate>
    </item>
    <item>
      <title>是否可以在Android应用程序上同时运行两个音频分类tflite模型？</title>
      <link>https://stackoverflow.com/questions/78331786/is-it-possible-to-run-two-audio-classification-tflite-model-at-the-same-time-on</link>
      <description><![CDATA[我正在尝试修改 TensorFlow Lite 音频分类 Android 演示，以同时运行 YAMNet.tflite 和 voice.tflite 模型。我的目标是让应用程序在 YAMNet 检测到语音并且语音模型检测到向上、向下、向左或向右命令时做出反应。但是，由于 YAMNet 的输入张量为 (1,16000)，而语音的输入张量为 (1,44032)，因此这两个模型的输入张量不同，只有最先声明的分类器才会进行预测。
我想问是否有办法修改此示例代码以同时运行具有不同输入张量的两个模型？或者有没有更好的方法来实现我想要的功能？]]></description>
      <guid>https://stackoverflow.com/questions/78331786/is-it-possible-to-run-two-audio-classification-tflite-model-at-the-same-time-on</guid>
      <pubDate>Tue, 16 Apr 2024 02:12:13 GMT</pubDate>
    </item>
    <item>
      <title>Pytorch - 保留前 K 个重复值</title>
      <link>https://stackoverflow.com/questions/78331706/pytorch-keep-first-k-repeating-values</link>
      <description><![CDATA[我有 2 个大小相同的一维张量，一个张量包含表示 id 的值，而另一个张量包含与该 id 关联的值。
例如
ids : 张量([0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2])
值： 张量([2, 7, 1, 3, 4, 7, 8, 9, 3, 4, 2])

我想保留每个唯一 ID 的前 K 个值和 ID：
# 保留前 3 个（注意：由于 id 1 中只有 2 个，因此只需保留 2 个）
id : 张量([0, 0, 0, 1, 1, 2, 2, 2])
值： 张量([2, 7, 1, 4, 7, 8, 9, 3])

我不知道如何有效地解决这个问题。计算 id 的单个 for 循环运行速度太慢。
其他上下文
我使用它来尝试对专家混合变压器模型的令牌分配进行负载平衡。
假设有一些输入：
# [批次、标记、值]
x = 火炬.randn(2, 10, 3)

路由器登录：
# 5 位专家可供选择
门 = torch.nn.Linear(3, 5)
logits = torch.nn.function.softmax(gate(x), dim=-1, dtype=torch.float)

我首先从路由器获取每个令牌选定的专家：
权重，选定 = torch.topk(logits, 1)
权重，选定 = map(lambda x: x.squeeze(dim=-1), (权重，选定))

给定一定的容量C，然后我希望每个专家处理的令牌不要超过C。此外，如果向专家提供的 C 令牌以上，它应该处理路由器赋予的最高权重的令牌并跳过其余令牌。
我不太确定如何有效地解决这个问题。这是我的尝试，因此这个问题来自哪里：
首先按专家及其各自的权重对值进行排序：
重要性 = 所选内容 + 权重
指数 = torch.argsort(重要性, 降序=True)

# 选择的权重现在将按专家排序，并且在每个专家中按路由器权重排序
选定= torch.gather（选定，-1，索引）
权重 = torch.gather(权重, -1, 指数)

循环遍历每个专家和流程
结果 = torch.zeros_like(x)
对于我来说，枚举专家（专家）：
  批处理，令牌 = torch.where(selected == i)

  # 将标记映射到输入中的正确索引
  令牌=索引[批次，令牌]

  # 这里 `batch` 代表“ids”在原来的问题中
  # 和“token”代表“值”在原来的问题中
  #
  # 这是我需要保留每个“批次”的前 K 个的地方。其中 K 是
  # 容量`C`

  # 计算结果
  结果[批次，令牌] += 专家(
    输入[批次，令牌]
  ）
]]></description>
      <guid>https://stackoverflow.com/questions/78331706/pytorch-keep-first-k-repeating-values</guid>
      <pubDate>Tue, 16 Apr 2024 01:34:09 GMT</pubDate>
    </item>
    <item>
      <title>Tensorflow 模型无法训练。帮我找到答案</title>
      <link>https://stackoverflow.com/questions/78331232/tensorflow-model-wont-train-help-me-find-the-answer</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78331232/tensorflow-model-wont-train-help-me-find-the-answer</guid>
      <pubDate>Mon, 15 Apr 2024 22:06:04 GMT</pubDate>
    </item>
    <item>
      <title>是否仅仅因为训练损失低于验证损失就被认为是“过度拟合”？ [关闭]</title>
      <link>https://stackoverflow.com/questions/78331085/is-it-considered-overfitting-just-because-the-training-loss-is-lower-than-vali</link>
      <description><![CDATA[一般来说，在训练机器学习模型时，如果验证损失高于训练损失，是否会被认为是过拟合？
在示例图像中，训练和验证损失都持续减少，但验证损失在大约 200 个时期与训练损失交叉，并且差异似乎在增加。这是否表明模型过度拟合？如果这种趋势随着进一步的训练而持续下去，并且训练/有效损失都较低但差异很大，这是一件坏事吗？
在示例图像中，训练和验证损失都持续减少，但验证损失在大约 200 个时期与训练损失交叉，并且差异似乎在增加。这是否表明模型过度拟合？如果这种趋势随着进一步的训练而持续下去，并且训练/有效损失都较低但差异很大，这是一件坏事吗？
]]></description>
      <guid>https://stackoverflow.com/questions/78331085/is-it-considered-overfitting-just-because-the-training-loss-is-lower-than-vali</guid>
      <pubDate>Mon, 15 Apr 2024 21:21:14 GMT</pubDate>
    </item>
    <item>
      <title>如何根据数据集的标签将数据集拆分为文件夹？</title>
      <link>https://stackoverflow.com/questions/78330964/how-to-split-a-dataset-into-folders-depending-in-its-labels</link>
      <description><![CDATA[我在一个文件夹中有一个图像数据集，我想根据包含所有图像 ID 及其标签的 csv 文件将其分成多个文件夹，因此我想阅读以进行检查和分离。另外我想在 Kaggle 上工作，那么如果我想将输出保存在工作目录中是否可以？
我尝试了以下代码，但它在某些方面不起作用。
&lt;前&gt;&lt;代码&gt;
`#首先将图像排序到子文件夹import pandas as pdimport osimport Shutil

将所有图像转储到一个文件夹中并指定路径：

data_dir = os.getcwd() + “/data/all_images/”

我们想要子文件夹的目标目录的路径

dest_dir = os.getcwd() + “/data/reorganized/”

读取包含图像名称和相应标签的csv文件

df= pd.read_csv(&#39;metadata.csv&#39;)print(df[&#39;dx&#39;].value_counts())

label=df[&#39;dx&#39;].unique().tolist() #提取标签到列表中label_images = []

将图像复制到新文件夹

for i in label:os.mkdir(dest_dir + str(i) + &quot;/&quot;)sample = df[df[&#39;dx&#39;] == i][&#39;image_id&#39;]label_images.extend (示例)for id in label_images:shutil.copyfile((data_dir + &quot;/&quot;+ id +&quot;.jpg&quot;), (dest_dir + i + &quot;/&quot;+id+&quot;.jpg&quot;))标签图像=[]

#现在我们准备好处理子文件夹中的图像了

FOR Keras 数据生成

#flow_from_directory 方法#当图像被排序并放置在相应的类/标签文件夹中时有用#从文件夹名称自动识别类。

创建数据生成器

from keras.preprocessing.image import ImageDataGeneratorimport osfrom matplotlib import pyplot as plt

#定义数据生成器。在这里我们可以定义要应用于 imagesdatagen = ImageDataGenerator() 的任何转换

定义包含子文件夹的训练目录

train_dir = os.getcwd() + “/data/reorganized/” ///这不起作用#USe flow_from_directorytrain_data_keras = datagen.flow_from_directory(directory=train_dir,class_mode=&#39;categorical&#39;,batch_size=16, #一次16张图像target_size=(32,32)) #调整图像大小

#我们可以检查单个批次的图像。x, y = next(train_data_keras)#查看范围 (0,15) 内的 i 的每个图像：image = x[i].astype(int)plt. imshow(图像)plt.show()`
]]></description>
      <guid>https://stackoverflow.com/questions/78330964/how-to-split-a-dataset-into-folders-depending-in-its-labels</guid>
      <pubDate>Mon, 15 Apr 2024 20:49:06 GMT</pubDate>
    </item>
    <item>
      <title>LCEL Lanchais RAG 顺序链的问题</title>
      <link>https://stackoverflow.com/questions/78330865/problem-with-lcel-lanchais-rag-sequential-chains</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78330865/problem-with-lcel-lanchais-rag-sequential-chains</guid>
      <pubDate>Mon, 15 Apr 2024 20:20:37 GMT</pubDate>
    </item>
    <item>
      <title>尝试使用tensorflow.keras库训练神经网络时出错</title>
      <link>https://stackoverflow.com/questions/78330820/error-whilst-attempting-to-train-neural-network-using-tensorflow-keras-library</link>
      <description><![CDATA[我正在使用 tensorflow.keras 开发我的第一个 ML 深度学习项目
这是一个简单的彩票预测，我在完成在线课程后用它来积累我的知识。
输入 1 到 90 之间的 90 个整数值。
输出从输入的 90 个值中选择的 5 个值。
当执行拟合“model.fit(X, train_output_catg, epochs=50, batch_size=32)”时
我遇到错误：
ValueError：参数 target 和 output 必须具有相同的等级 (ndim)。收到：target.shape=(None, 5, 90), output.shape=(None, 5)
我网络上的输出层是：
输出层
model.add(Dense(5,activation=&#39;softmax&#39;))
我正在使用以下损失函数：
编译模型
model.compile（optimizer=&#39;adam&#39;，loss=&#39;categorical_crossentropy&#39;，metrics=[&#39;accuracy&#39;]）
因为我有整数，所以我使用以下方法将其转换为分类值：
#将 y 更改为分类值
train_output_catg = tf.keras.utils.to_categorical(y - 1, num_classes=None)
我明白问题所在，但不知道如何解决。
我的输出层形状如下“output.shape=(None, 5)”但我的目标形状是“target.shape=(None, 5, 90)”
我最初的“X”和“y”数组是：
X 形状：(2223, 90)
y 的形状：(2223, 5)
然后在“y”数组上，我执行了 to_categorical（如上所述），将其转换为 3 维数组，导致失败，因为输出数组和目标数组之间不匹配。
感谢您提供的任何帮助。
我期望函数 tf.keras.utils.to_categorical 为我提供与“y”数组相同的维度数组，但由于它添加了额外的维度，所以我遇到了上述错误。]]></description>
      <guid>https://stackoverflow.com/questions/78330820/error-whilst-attempting-to-train-neural-network-using-tensorflow-keras-library</guid>
      <pubDate>Mon, 15 Apr 2024 20:06:55 GMT</pubDate>
    </item>
    <item>
      <title>更改 pytorch 中中毒的输入[关闭]</title>
      <link>https://stackoverflow.com/questions/78329685/change-input-for-poisoning-in-pytorch</link>
      <description><![CDATA[实际上，我有这段代码，最初下载了 cifar 10 数据集并对图像应用了中毒（编辑右下角）
然而，此时我需要使用本地的图像，数据集分为 5 个文件夹，其中每个文件夹都是不同的类。这是我尝试编写的代码，但它给了我错误：
将 numpy 导入为 np
从复制导入深复制

标准化参数 = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]
输入大小 = 224
路径=&#39;./DB&#39;


defgenerate_trigger(trigger_type):
    if trigger_type == &#39;checkerboard_1corner&#39;: # 棋盘位于右下角
        模式 = np.zeros(形状=(32, 32, 1), dtype=np.uint8) + 122
        掩码 = np.zeros(形状=(32, 32, 1), dtype=np.uint8)
        触发值 = [[0, 0, 255], [0, 255, 0], [255, 0, 255]]
        触发区域 = [-1, 0, 1]
        对于trigger_region中的h：
            对于trigger_region中的w：
                模式[30 + h, 30 + w, 0] = 触发值[h + 1][w + 1]
                掩码[30 + h, 30 + w, 0] = 1
    返回模式、掩码


def add_trigger_dirty_label（data_set，trigger_type，poison_rate，poison_target，trigger_alpha = 1.0）：
    模式，掩码=generate_trigger(trigger_type=trigger_type)
    poison_cand = [i for i in range(len(data_set.targets)) if data_set.targets[i] !=poison_target]
    poison_set = 深度复制(data_set)
    poison_num = int(poison_rate * len(poison_cand))
    选择= np.random.choice(poison_cand,毒药_num,replace=False)

    对于选择中的 idx：
        orig=poison_set.data[idx]
        poison_set.data[idx] = np.clip(
            (1 - 掩码) * 原始 + 掩码 * ((1 - 触发阿尔法) * 原始 + 触发阿尔法 * 模式), 0, 255
        ).astype(np.uint8)
        poison_set.targets[idx] =poison_target
    trigger_info = {&#39;trigger_pattern&#39;: 模式[np.newaxis, :, :, :], &#39;trigger_mask&#39;: 掩码[np.newaxis, :, :, :],
                    &#39;trigger_alpha&#39;：trigger_alpha，&#39;poison_target&#39;：np.array（[poison_target]），
                    &#39;data_index&#39;：选择}
    返回poison_set、trigger_info


def add_trigger_clean_label（数据集，trigger_type，poison_rate，poison_target，trigger_alpha = 1.0）：
    模式，掩码=generate_trigger(trigger_type=trigger_type)
    poison_cand = [i for i in range(len(data_set.targets)) if data_set.targets[i] ==poison_target]
    poison_set = 深度复制(data_set)
    poison_num = int(poison_rate * len(poison_cand))
    选择= np.random.choice(poison_cand,毒药_num,replace=False)

    对于选择中的 idx：
        orig=poison_set.data[idx]
        poison_set.data[idx] = np.clip(
            (1 - 掩码) * 原始 + 掩码 * ((1 - 触发阿尔法) * 原始 + 触发阿尔法 * 模式), 0, 255
        ).astype(np.uint8)
    trigger_info = {&#39;trigger_pattern&#39;: 模式[np.newaxis, :, :, :], &#39;trigger_mask&#39;: 掩码[np.newaxis, :, :, :],
                    &#39;trigger_alpha&#39;：trigger_alpha，&#39;poison_target&#39;：np.array（[poison_target]），
                    &#39;data_index&#39;：选择}
    返回poison_set、trigger_info


def add_predefined_trigger(data_set,trigger_info):
    如果trigger_info为None：
        返回数据集

    poison_set = 深度复制(data_set)

    模式=trigger_info[&#39;trigger_pattern&#39;]
    掩码=trigger_info[&#39;trigger_mask&#39;]
    阿尔法=触发器信息[&#39;trigger_alpha&#39;]

    对于范围内的 idx(len(poison_set))：
        orig=poison_set.data[idx]
        poison_set.data[idx] = np.clip(
            (1 - 掩模) * orig + 掩模 * ((1 - alpha) * orig + alpha * 图案), 0, 255
        ).astype(np.uint8)

    返回poison_set

从torchvision导入数据集，转换


data_transforms = 变换.Compose([
    变换.调整大小(INPUT_SIZE),
    变换.ToTensor(),
    变换.Normalize(NORMALIZATION_PARAMS[0], NORMALIZATION_PARAMS[1])
]）

image_dataset = datasets.ImageFolder(root=PATH, 变换=data_transforms)
#image_dataset = CIFAR10(root=&#39;./&#39;,train=True,download=True,transform=data_transforms)

中毒率 = 0.1
毒物目标 = 1

poisoned_dataset，trigger_info = add_trigger_dirty_label（image_dataset，&#39;checkerboard_1corner&#39;，poison_rate，poison_target）

请注意以下错误：
回溯（最近一次调用最后一次）：
  文件“C:\Users\enric\PycharmProjects\Avvelenatore\main.py”，第 92 行，在  中
    poisoned_dataset，trigger_info = add_trigger_dirty_label（image_dataset，&#39;checkerboard_1corner&#39;，poison_rate，poison_target）
  文件“C:\Users\enric\PycharmProjects\Avvelenatore\main.py”，第 30 行，位于 add_trigger_dirty_label
    orig=poison_set.data[idx]
  文件“C:\Users\enric\anaconda3\envs\pytorch\lib\site-packages\torch\utils\data\dataset.py”，第 83 行，在 __getattr__ 中
    引发属性错误
属性错误

你能帮我解决这个问题吗？]]></description>
      <guid>https://stackoverflow.com/questions/78329685/change-input-for-poisoning-in-pytorch</guid>
      <pubDate>Mon, 15 Apr 2024 16:00:49 GMT</pubDate>
    </item>
    <item>
      <title>scikit-learn 导入无法导入名称“METRIC_MAPPING64”</title>
      <link>https://stackoverflow.com/questions/78327535/scikit-learn-import-cannot-import-name-metric-mapping64</link>
      <description><![CDATA[我正在尝试将线性模型从 scikit-learn 导入到 vscode 中，并收到意外的错误消息。
导入sklearn
从sklearn导入线性模型

错误：
无法从“sklearn.metrics._dist_metrics”导入名称“METRIC_MAPPING64”

我不想导入这些指标，如何解决这个问题？
使用的scikit-learn版本是1.1.3。]]></description>
      <guid>https://stackoverflow.com/questions/78327535/scikit-learn-import-cannot-import-name-metric-mapping64</guid>
      <pubDate>Mon, 15 Apr 2024 09:54:33 GMT</pubDate>
    </item>
    <item>
      <title>无法解释优化器标识符：<keras.src.optimizers.adam.Adam 对象位于 0x7d8646d22b00></title>
      <link>https://stackoverflow.com/questions/78323015/could-not-interpret-optimizer-identifier-keras-src-optimizers-adam-adam-object</link>
      <description><![CDATA[我正在使用这样的模型训练数据集
导入tensorflow为tf
从tensorflow.keras.optimizers导入Adam

优化器 = Adam(learning_rate=2e-5)

# 编译模型（使用优化器）
model.compile(优化器=优化器,
              损失=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              指标=[&#39;准确性&#39;])


# 训练模型
model.fit（train_inputs，train_labels，epochs=epochs，batch_size=batch_size）

它返回此错误：
ValueError：无法解释优化器标识符：
optimizer.adam 但它无法正常工作]]></description>
      <guid>https://stackoverflow.com/questions/78323015/could-not-interpret-optimizer-identifier-keras-src-optimizers-adam-adam-object</guid>
      <pubDate>Sun, 14 Apr 2024 07:12:50 GMT</pubDate>
    </item>
    </channel>
</rss>