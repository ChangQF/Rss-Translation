<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - 堆栈内存溢出</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 条</description>
    <lastBuildDate>Mon, 10 Jun 2024 15:16:56 GMT</lastBuildDate>
    <item>
      <title>PINN 解决 1D PDE，损失没有下降</title>
      <link>https://stackoverflow.com/questions/78603134/pinn-solving-1d-pde-loss-does-not-go-down</link>
      <description><![CDATA[我正在尝试使用 PINN 解决 1D d(psi)/d(x) = S。左：固定值边界条件。右：零梯度边界条件。
当 S = 0 时，训练速度非常快。它只预测均匀值。
但如果 S 不是均匀的 0，损失就会下降得非常慢。
我将我的代码附在下面（libtorch）。该代码可以轻松编译，我确信它没有错误。如果 S 的值非常大，损失也更难下降。
有什么建议吗？谢谢。
#include &lt;torch/torch.h&gt;

using namespace std;
class NN
:
public torch::nn::Module 
{
torch::nn::Sequential net_;

公共：

NN()
{
net_ = register_module
(
&quot;net&quot;, 
torch::nn::Sequential
(
torch::nn::Linear(1,20),
torch::nn::ReLU(),
torch::nn::Linear(20,20),
torch::nn::ReLU(),
torch::nn::Linear(20,20),
torch::nn::ReLU(),
torch::nn::Linear(20,20),
torch::nn::ReLU(),
torch::nn::Linear(20,1)
)
);
}

auto forward(torch::Tensor x)
{
return net_-&gt;forward(x);
}
};

int main()
{
int iter = 1;
int IterationNum = 5000;
double learning_rate = 0.001;
torch::nn::MSELoss criterion = torch::nn::MSELoss();
std::shared_ptr&lt;NN&gt; model = std::make_shared&lt;NN&gt;();
std::shared_ptr&lt;torch::optim::Adam&gt; adam = 
std::make_shared&lt;torch::optim::Adam&gt;
(
model-&gt;parameters(), 
torch::optim::AdamOptions(learning_rate)
);

// 计算域
double dx = 0.1;
自动网格 = torch::arange(0.0, 1.0 + dx, dx, torch::requires_grad()).unsqueeze(1);
//自动源 = torch::full_like(mesh, 0.0);
自动源 = 
torch::tensor
(
{0.0,0.0,0.0,0.0,0.0,0.0,50.0,0.0,0.0,0.0,0.0,0.0}
).reshape({-1, 1});

自动入口 = torch::full({1}, mesh.index({0}).item());
自动出口 = torch::full({1}, mesh.index({-1}).item());
自动 psiInlet = torch::full({1}, 10.0);

//cout&lt;&lt; &quot;inlet\n&quot; &lt;&lt; 入口 &lt;&lt; endl;
//cout&lt;&lt; &quot;出口\n&quot; &lt;&lt; 出口 &lt;&lt; endl;
//cout&lt;&lt; &quot;psiInlet\n&quot; &lt;&lt; psiInlet &lt;&lt; endl;
//cout&lt;&lt; &quot;源\n&quot; &lt;&lt; 源 &lt;&lt; endl;
//cout&lt;&lt; &quot;网格\n&quot; &lt;&lt; 网格 &lt;&lt; endl;

for (int i = 0; i &lt; IterationNum; i++) 
{
adam-&gt;zero_grad();

auto psiInletPred = model-&gt;forward(入口);
auto lossInlet = criterion(psiInletPred, psiInlet);

自动 psi = model-&gt;forward(mesh);
自动 dpsidx = 
torch::autograd::grad
(
{psi},
{mesh},
{torch::ones_like(psi)},
true,
true
)[0];
自动 loss_pde = criterion(dpsidx, source);

自动 loss = loss_pde + lossInlet;
loss.backward();
adam-&gt;step();

if (iter % 100 == 0) 
{
cout &lt;&lt; iter &lt;&lt; &quot; loss = &quot; &lt;&lt; loss.item() &lt;&lt; endl;
}
iter++;
}

自动 psiFinal = model-&gt;forward(mesh);
cout&lt;&lt; &quot;psiFinal\n&quot; &lt;&lt; psiFinal &lt;&lt; endl;

std::cout&lt;&lt; &quot;完成！&lt;&lt; std::endl;
return 0;
}

输出：
100 损失 = 239.65
200 损失 = 210.191
300 损失 = 193.635
400 损失 = 197.778
500 损失 = 203.71
600 损失 = 192.241
700 损失 = 189.999
800 损失 = 177.973
900 损失 = 190.415
1000 损失 = 186.3
1100 损失 = 198.209
1200 损失 = 196.226
1300 损失 = 179.71
1400 损失 = 193.564
1500 损失 = 192.17
1600 损失 = 173.498
1700 损失 = 190.252
1800 损失 = 189.662
1900 损失 = 189.473
2000 损失 = 189.412
2100 损失 = 189.397
2200 损失 = 189.394
2300 损失 = 189.394
2400 损失 = 189.394
2500 损失 = 189.394
2600 损失 = 189.394
2700 损失 = 189.394
2800 损失 = 189.394

使其训练更好的建议]]></description>
      <guid>https://stackoverflow.com/questions/78603134/pinn-solving-1d-pde-loss-does-not-go-down</guid>
      <pubDate>Mon, 10 Jun 2024 15:14:13 GMT</pubDate>
    </item>
    <item>
      <title>类型错误：“StratifiedShuffleSplit”对象不可迭代</title>
      <link>https://stackoverflow.com/questions/78602817/typeerror-stratifiedshufflesplit-object-is-not-iterable</link>
      <description><![CDATA[我有这段代码：
来自 sklearn.datasets 导入 fetch_lfw_people
lfw_people = fetch_lfw_people(min_faces_per_person=60, resize=0.4)
X = lfw_people.data
y = lfw_people.target
target_names = [lfw_people.target_names[a] for a in y]
n_samples, h, w = lfw_people.images.shape
来自 collections 导入 Counter
for name, count in Counter(target_names).items():
print (&quot;%20s %i&quot; % (name, count))

来自 sklearn.model_selection 导入 StratifiedShuffleSplit

train, test = list(StratifiedShuffleSplit(target_names, test_size=0.1, random_state=101))[0]

plt.subplot(1, 4, 1)
plt.axis(&#39;off&#39;)
for k,m in enumerate(X[train][y[train]==6][:4]):
plt.subplot(1, 4, 1+k)
if k==0:
plt.title(&#39;训练集&#39;)
plt.axis(&#39;off&#39;)
plt.imshow(m.reshape(50,37), cmap=plt.cm.gray, interpolation=&#39;nearest&#39;)
plt.show()

for k,m in enumerate(X[test][y[test]==6][:4]):
plt.subplot(1, 4, 1+k)
if k==0:
plt.title(&#39;测试集&#39;)
plt.axis(&#39;off&#39;)
plt.imshow(m.reshape(50,37), cmap=plt.cm.gray, interpolation=&#39;nearest&#39;)
plt.show()

它给了我这个错误：
TypeError: &#39;StratifiedShuffleSplit&#39; 对象不可迭代


我做错了什么？令人困惑的是代码来自一本书，我只是复制它，并没有改变它。库中的某些东西发生了变化，导致代码不再起作用？感谢您的帮助
代码最多显示人物图片，但它不会]]></description>
      <guid>https://stackoverflow.com/questions/78602817/typeerror-stratifiedshufflesplit-object-is-not-iterable</guid>
      <pubDate>Mon, 10 Jun 2024 14:12:18 GMT</pubDate>
    </item>
    <item>
      <title>使用 shap 或 lime 解释天气预报 PyTorch 模型的输出</title>
      <link>https://stackoverflow.com/questions/78602768/using-shap-or-lime-to-explain-output-for-a-weather-prediction-pytorch-model</link>
      <description><![CDATA[我曾尝试使用 SHAP 来分析天气预报模型。它不是分类器，而分类器似乎是这些包最常见的用例。
我对所有这些都不太有经验，但我正在考虑改用 Lime，希望这样会更容易？
对吗？我发现 Lime 似乎不适合 PyTorch，我肯定必须将我的张量更改为 np.Arrays。对此有什么直觉吗？
我尝试使用 Shaps Deep Explainer，但尚未成功。这是一个抽象的问题。]]></description>
      <guid>https://stackoverflow.com/questions/78602768/using-shap-or-lime-to-explain-output-for-a-weather-prediction-pytorch-model</guid>
      <pubDate>Mon, 10 Jun 2024 14:02:58 GMT</pubDate>
    </item>
    <item>
      <title>如何从模型调用而不是 logits 中获得 [0, 1] 之间的标准化概率作为输出？</title>
      <link>https://stackoverflow.com/questions/78601616/how-to-obtain-normalized-probabilities-between-0-1-as-output-from-model-call</link>
      <description><![CDATA[我有一个经过训练的图像语义分割模型。
由于我的预测中有很多 FP，我想使用模型置信度参数进行阈值处理，该参数将设置为 [0, 1] 范围内的值。
到目前为止，我都是这样做的：
logits = model_to_predict(img_tensor, training=False).logits # (batch, NUM_CLASSES, w, h)
sigmoid_logits = tf.math.sigmoid(logits)

if model_confidence:
confidence_logits = tf.where(sigmoid_logits &gt;= model_confidence, sigmoid_logits, 0)
pred = tf.argmax(confident_logits, axis=1)

else:
pred = tf.argmax(logits, axis=1)

pred = tf.cast(tf.squeeze(pred, axis=0), tf.uint8)

但是这些解决方案导致每个图像的概率从 0 到 1，而预期结果是，在一个图像的范围内，概率将在 0 到 0.3 之间，而在另一个图像的情况下，假设在 0 到 0.8 之间。
那么在将模型置信度设置为 0.5 后，第一张图像将不会检测到 FP 对象
我如何才能实现这个结果？我使用 SegFormer（预训练）模型。]]></description>
      <guid>https://stackoverflow.com/questions/78601616/how-to-obtain-normalized-probabilities-between-0-1-as-output-from-model-call</guid>
      <pubDate>Mon, 10 Jun 2024 09:56:16 GMT</pubDate>
    </item>
    <item>
      <title>在预处理 CT 扫描图像系列数据以训练 CNN 模型以获得更好的准确性时，我应该如何具体地关注我感兴趣的区域？</title>
      <link>https://stackoverflow.com/questions/78601522/how-specific-should-i-be-with-my-region-of-interest-while-preprocessing-a-ct-sca</link>
      <description><![CDATA[我正在尝试训练一个 3D CNN 模型，以对一个数据集上的癌症分期进行分类，该数据集由头部到颈部的 CT 图像系列组成，分为 5 个类别，与癌症的分期相对应。每个阶段都有与每位患者（总共 606 位患者）相对应的文件夹，每个文件夹包含 120 帧 CT 图像系列。我想将一个图像立方体输入到模型中，以考虑空间分辨率和深度分辨率，并将图像立方体分类为五个类别之一。
在 120 张图像中，大约有 10 帧存在癌症。
我将整个图像集（每个患者 120 张）作为 3D 图像立方体传入 3D 卷积模型，对数据进行归一化，其结构如下所示）：
num_classes = 5
model = Sequential([
tf.keras.Input(shape=(255, 255, 120, 1)),
# 卷积层 1
Conv3D(16, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),

MaxPooling3D((2, 2, 1), strides=(2, 2, 1), padding=&quot;same&quot;),

# 卷积层 2
Conv3D(32, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2), padding=&quot;same&quot;),

# 卷积层 3
Conv3D(32, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2),padding=&quot;same&quot;),

# 卷积层 4
Conv3D(64, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2),padding=&quot;same&quot;),

# 卷积层 5
Conv3D(128, (3, 3, 3),activation=&#39;relu&#39;),
BatchNormalization(),

# 卷积层 6
Conv3D(128, (3, 3, 3), 激活=&#39;relu&#39;),
BatchNormalization(),
MaxPooling3D((2, 2, 2), strides=(2, 2, 2),padding=&quot;same&quot;),
#Dropout(0.25),
# Flatten 层
Flatten(),

# Dense 层 1
Dense(256, 激活=&#39;relu&#39;, kernel_initializer = &#39;glorot_uniform&#39;, kernel_regularizer=tf.keras.regularizers.L2(0.01)),
BatchNormalization(),
#Dropout(0.35),
# Dense 层 2
Dense(128, 激活=&#39;relu&#39;, kernel_initializer = &#39;glorot_uniform&#39;, kernel_regularizer=tf.keras.regularizers.L2(0.01)),
BatchNormalization(),
#Dropout(0.25),
# 输出层
Dense(num_classes,activation=&#39;softmax&#39;)
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;])

这是我将 DICOM 图像加载到输入 (X) 和输出 (Y) 标签中的方式：
def load_dicom_images(folder_path):
images = []
for file in sorted(os.listdir(folder_path)):
ds = pydicom.dcmread(os.path.join(folder_path,file))
# 转换为灰度图像并调整大小为 255x255
image = ds.pixel_array
image = cv2.resize(image, (255, 255))
# 标准化图像
normalized_images= (image.astype(np.float32)-image.mean())/image.std()
images.append(normalized_images)
# 将列表转换为 numpy 数组
images = np.array(images)
return images

def load_data(stage_folder): # 阶段文件夹包含与类别相关的五个文件夹
X = []
y = [] 
# 将阶段映射到标签
stage_to_label = {&#39;阶段 I&#39;: 0, &#39;阶段 II&#39;: 1, &#39;阶段 III&#39;: 2, &#39;阶段 IVA&#39;: 3, &#39;阶段 IVB&#39;: 4 }

for stage in os.listdir(stage_folder):
stage_path = os.path.join(stage_folder, stage)
label = stage_to_label[stage]
forp​​atient_id in os.listdir(stage_path):
patient_folder = os.path.join(stage_path,patient_id)
selected_images = load_dicom_images(patient_folder)

X.append(selected_images)
y.append(label)

X = np.array(X)
y = np.array(y)

# 将 y 转换为分类（独热编码）
y = to_categorical(y,num_classes=5)

返回 X,y

history = model.fit(X_train,y_train,batch_size=1,epochs=50,validation_data=(X_test,y_test),verbose = True,callbacks=callbacks)

这会导致训练准确率（21%）和验证准确率较低，并且验证损失会随着每个时期而增加。我已经根据 CNN 的输入重塑了数据。
我是否需要进一步处理我的数据，通过过滤掉其余部分来仅包含癌症帧，还是应该包含整个数据以保留深度分辨率并寻找不同的方法来提高准确性？]]></description>
      <guid>https://stackoverflow.com/questions/78601522/how-specific-should-i-be-with-my-region-of-interest-while-preprocessing-a-ct-sca</guid>
      <pubDate>Mon, 10 Jun 2024 09:39:03 GMT</pubDate>
    </item>
    <item>
      <title>MultiScale Vision Transformer 张量不匹配形状问题</title>
      <link>https://stackoverflow.com/questions/78600117/multiscale-vision-transformer-tensor-mismatch-shape-issue</link>
      <description><![CDATA[MultiScale Vision Transformer 似乎存在张量不匹配形状问题。有人知道如何解决这个问题吗？
https://github.com/facebookresearch/mvit/issues/22]]></description>
      <guid>https://stackoverflow.com/questions/78600117/multiscale-vision-transformer-tensor-mismatch-shape-issue</guid>
      <pubDate>Mon, 10 Jun 2024 00:51:05 GMT</pubDate>
    </item>
    <item>
      <title>时间序列中具有小数据集的机器学习模型</title>
      <link>https://stackoverflow.com/questions/78599891/machine-learning-models-with-small-datasets-in-time-series</link>
      <description><![CDATA[我正在开展一个预测项目，我的数据集包含 24 个月的历史销售数据。我使用 20 个月进行训练和验证，其余 4 个月进行测试。对于验证，我使用滚动预测起源（类似于 TimeSeriesSplit）。
我尝试使用几种模型，包括 SVR、GBR、随机森林、Facebook Prophet、ARIMA 和线性回归。但是，我很难找到一个正常工作的模型。我所有的预测图看起来都不一致，并且与数据不太吻合。
您能否解释为什么机器学习模型在像我这样的小数据集上可能表现不佳，并建议任何更适合小数据集的技术或模型？
我所有的预测结果看起来都像图像一样，有一条直线。
谢谢！
在此处输入图片描述]]></description>
      <guid>https://stackoverflow.com/questions/78599891/machine-learning-models-with-small-datasets-in-time-series</guid>
      <pubDate>Sun, 09 Jun 2024 22:25:42 GMT</pubDate>
    </item>
    <item>
      <title>使用随机森林对心电图数据进行验证和测试的准确率较低</title>
      <link>https://stackoverflow.com/questions/78599809/low-validation-and-test-accuracy-with-random-forest-on-ecg-data</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78599809/low-validation-and-test-accuracy-with-random-forest-on-ecg-data</guid>
      <pubDate>Sun, 09 Jun 2024 21:43:40 GMT</pubDate>
    </item>
    <item>
      <title>如何提高多标签分类的准确度得分？</title>
      <link>https://stackoverflow.com/questions/78598665/how-to-improve-accuracy-score-in-multilabel-classification</link>
      <description><![CDATA[我想知道如何在多标签分类问题中提高准确率并降低损失。
如果你查看 sklearn 参考，你会发现在多类和多输出算法中提到了多标签，我现在正在测试它。
（https://scikit-learn.org/stable/modules/multiclass.html）
样本数据使用sklearn.datasets中的make_multilabel_classification有10个特征，通过修改n_classes创建一个数据集。
当multilabel有两个类时，似乎准确率和损失都比较令人满意。
from numpy import mean
from numpy import std
from sklearn.datasets import make_multilabel_classification
from sklearn.neighbors import KNeighborsClassifier

from sklearn.metrics import accuracy_score, hamming_loss

# define dataset
X, y = make_multilabel_classification(n_samples=10000, n_features=10, n_classes=2, random_state=1)

# 总结数据集形状
print(X.shape, y.shape)
# 总结前几个示例
for i in range(10):
print(X[i], y[i])

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
print(scaler.mean_)
print(scaler.var_)

x_train_std = scaler.transform(X_train)
x_test_std = scaler.transform(X_test)

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(x_train_std, y_train)

pred = knn.predict(x_test_std)

print(accuracy_score(y_test, pred))
print(hamming_loss(y_test, pred))

accuracy_score: 0.8345, hamming_loss: 0.08875
但是，随着类别数超过3，准确率得分逐渐下降，损失增加。
# define dataset
X, y = make_multilabel_classification(n_samples=10000, n_features=10, n_classes=3, random_state=1)

n_classes= 3 --&gt; accuracy_score: 0.772, hamming_loss: 0.116
n_classes= 4 --&gt; accuracy_score: 0.4875, hamming_loss: 0.194125
使用 RandomForestClassifier 算法时也是如此，如参考中所示，或者使用 ClassifierChain(estimator=SVC) 使用不支持多标签分类的算法时也是如此。
我想知道为什么会出现这种情况，以及如何调整超参数以提高准确性？]]></description>
      <guid>https://stackoverflow.com/questions/78598665/how-to-improve-accuracy-score-in-multilabel-classification</guid>
      <pubDate>Sun, 09 Jun 2024 13:03:31 GMT</pubDate>
    </item>
    <item>
      <title>Python 中事件/事件关系的关联规则</title>
      <link>https://stackoverflow.com/questions/78591986/association-rule-on-incident-event-relations-in-python</link>
      <description><![CDATA[我有两组数据：一个事件列表和一个已解决的事件列表，以及导致每个事件的事件。如何训练模型来预测哪个事件导致新事件发生？
例如，使用以下方法：
已解决的训练事件列表：



N°
服务来源
客户来源
...
事件来源




1
服务 A
人力资源团队
...
A345


2
服务 B
开发团队
...
B678


3
服务 A
外部
...
C901



培训活动列表：



N°
目标服务
变更生效
开发人员
...




A345
服务 A
函数重构
Mike I
...


U567
服务 C
函数弃用
Mike I
...


B678
服务 B
错误修复
John D
...


T234
服务 A
函数重构
Dave L
...


C901
服务 A
函数弃用
Dave L
...


V890
服务 B
错误修复
Mike I
...



我现在希望模型预测此事件的来源：



N°
服务来源
客户来源
...
事件源




4
服务 C
外部
...




来自此事件列表：



N°
目标服务
变更生效
开发人员
...




R123
服务 A
函数重构
Mike I
...


S456
服务 C
函数弃用
Mike I
...


T789
服务 C
错误修复
John D
...


]]></description>
      <guid>https://stackoverflow.com/questions/78591986/association-rule-on-incident-event-relations-in-python</guid>
      <pubDate>Fri, 07 Jun 2024 12:38:09 GMT</pubDate>
    </item>
    <item>
      <title>如果训练数据集中的正样本多于负样本，XGBoost 的 scale_pos_weight 是否可以正确平衡正样本？</title>
      <link>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</link>
      <description><![CDATA[经过研究，我意识到 scale_pos_weight 通常计算为训练数据中负样本数量与正样本数量的比率。我的数据集有 840 个负样本和 2650 个正样本，因此比率为 0.32。如果我的样本反过来，我相信 scale_pos_weight 会是一种更好的方法。
是否可以安全地假设，由于比率小于 1，它仍将正确平衡类别？特异性在我的研究中很重要，但我们的主要目标集中在召回率、精确度和 F1 分数上。此设置是否会通过最大程度地影响特异性而导致更多的假阳性？]]></description>
      <guid>https://stackoverflow.com/questions/78587301/does-xgboosts-scale-pos-weight-correctly-balance-the-positive-samples-if-the-tr</guid>
      <pubDate>Thu, 06 Jun 2024 14:27:52 GMT</pubDate>
    </item>
    <item>
      <title>tf.keras.callbacks.ModelCheckpoint 保存 HDF5 格式或 SavedModel 格式</title>
      <link>https://stackoverflow.com/questions/75587367/tf-keras-callbacks-modelcheckpoint-saves-hdf5-format-or-savedmodel-format</link>
      <description><![CDATA[save_weights_only=False 时，如何配置 tf.keras.callbacks.ModelCheckpoint 以保存 SavedModel 格式而不是 HDF5 格式？
与此相关的两个问题。我使用的是 TF2.4
https://github.com/tensorflow/tensorflow/issues/39679
https://github.com/keras-team/keras/issues/16657]]></description>
      <guid>https://stackoverflow.com/questions/75587367/tf-keras-callbacks-modelcheckpoint-saves-hdf5-format-or-savedmodel-format</guid>
      <pubDate>Tue, 28 Feb 2023 02:34:32 GMT</pubDate>
    </item>
    <item>
      <title>当观察次数有限时的时间序列预测</title>
      <link>https://stackoverflow.com/questions/59054968/time-series-prediction-when-you-have-limited-number-of-observations</link>
      <description><![CDATA[我在 Keras 中训练了一个 NN 来预测每周需求，并进行了所有超参数调整，我能得到的最好的结果就是下图。
我的理解是，由于两个原因，预测结果不好：

我没有足够的观察值（每周需求）
信号本身看起来非常随机，很难预测这种信号。

你有处理类似时间序列数据的经验吗？你有什么建议吗？
]]></description>
      <guid>https://stackoverflow.com/questions/59054968/time-series-prediction-when-you-have-limited-number-of-observations</guid>
      <pubDate>Tue, 26 Nov 2019 16:06:11 GMT</pubDate>
    </item>
    <item>
      <title>如何比较两个 keras 模型的相似度</title>
      <link>https://stackoverflow.com/questions/52991969/how-to-compare-the-similarity-of-two-keras-models</link>
      <description><![CDATA[我使用函数式 API 构建了一个 Keras 模型，并使用 model_from_json() 函数创建了第二个模型。我想看看两个模型的模型层（而不是权重）是否完全相同。
如何比较这两个 Keras 模型？
编辑
根据以下评论，我可能会比较每个层。下面这样的代码有意义吗：
for l1, l2 in zip(mdl.layers, mdl2.layers):
print (l1.get_config() == l2.get_config())
]]></description>
      <guid>https://stackoverflow.com/questions/52991969/how-to-compare-the-similarity-of-two-keras-models</guid>
      <pubDate>Thu, 25 Oct 2018 14:38:21 GMT</pubDate>
    </item>
    <item>
      <title>如何从 scikit-learn 决策树中提取决策规则？</title>
      <link>https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree</link>
      <description><![CDATA[我可以从决策树中经过训练的树中提取底层决策规则（或“决策路径”）作为文本列表吗？
类似于：
如果 A&gt;0.4，则如果 B&lt;0.2，则如果 C&gt;0.8，则 class=&#39;X&#39;
]]></description>
      <guid>https://stackoverflow.com/questions/20224526/how-to-extract-the-decision-rules-from-scikit-learn-decision-tree</guid>
      <pubDate>Tue, 26 Nov 2013 17:58:00 GMT</pubDate>
    </item>
    </channel>
</rss>