<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>标记为机器学习的活跃问题 - Thinbug</title>
    <link>https://stackoverflow.com/questions/tagged/?tagnames=machine-learning&sort=active</link>
    <description>来自 stackoverflow.com 的最新 30 个</description>
    <lastBuildDate>Tue, 09 Apr 2024 12:25:19 GMT</lastBuildDate>
    <item>
      <title>TensorBoard HParams 未显示超参数调整的准确性指标</title>
      <link>https://stackoverflow.com/questions/78298357/tensorboard-hparams-not-showing-accuracy-metrics-for-hyperparameter-tuning</link>
      <description><![CDATA[我正在 TensorFlow 中进行超参数调整，并使用 TensorBoard 中的 HParams 插件设置了一个实验来记录不同的配置。我的模型正在使用 dropout 和学习率的变化进行训练，并且我正在记录这些参数以及模型的准确性。但是，当我打开 TensorBoard 并导航到 HParams 仪表板时，不会显示与每个试验相关的准确性指标。该表正确显示了超参数，但“准确性”列为空，即使我的代码使用“准确性”作为指标来编译模型并使用 hp.KerasCallback 进行日志记录。我已经验证了模型训练正确，并且标量仪表板等其他 TensorBoard 功能显示了各个时期的准确性趋势。我正在寻求帮助来理解为什么 HParams 表中没有显示准​​确性以及如何解决此问题。
我使用 TensorBoard 的 HParams 进行超参数调整的代码：
 from tensorboard.plugins.hparams import api as hp
    将张量流导入为 tf
    从tensorflow.keras.layers导入Conv2D、MaxPooling2D、Dense、Flatten、Dropout

    # 定义超参数
    HP_DROPOUT = hp.HParam(&#39;dropout&#39;, hp.Discrete([0.2, 0.3, 0.4]))
    HP_LEARNING_RATE = hp.HParam(&#39;learning_rate&#39;, hp.Discrete([1e-2, 1e-3]))

    # 设置日志记录
    log_dir = &#39;./tensorboard/nn_1&#39;
    使用 tf.summary.create_file_writer(log_dir).as_default()：
        hp.hparams_config(
            hparams=[HP_DROPOUT, HP_LEARNING_RATE],
            指标=[hp.Metric(&#39;准确度&#39;,display_name=&#39;准确度&#39;)]
        ）

    # 训练函数
    def train_test_model(hparams, session_num):
        model_name = f“model_1_session_{session_num}”
        print(f&quot;使用超参数 {hparams} 训练 {model_name}...&quot;)
        模型 = tf.keras.Sequential([
            Conv2D(32, kernel_size=(3, 3), 激活=&#39;elu&#39;),
            辍学（hparams [HP_DROPOUT]），
            Conv2D(32, kernel_size=(3, 3), 激活=&#39;elu&#39;),
            辍学（hparams [HP_DROPOUT]），
            MaxPooling2D(pool_size=(2, 2)),
            展平（），
            密集（10，激活=&#39;softmax&#39;）
        ]）
        模型.编译(
            损失=&#39;分类交叉熵&#39;，
            优化器=tf.keras.optimizers.Adam(hparams[HP_LEARNING_RATE]),
            指标=[&#39;准确性&#39;]
        ）

        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f&#39;{log_dir}/{model_name}&#39;)
        hparams_callback = hp.KerasCallback(writer=f&#39;{log_dir}/{model_name}&#39;, hparams=hparams)

        模型.拟合(
            x_train_reshape, y_train_,
            纪元=3，
            验证数据=（x_val_reshape，y_val），
            回调=[hparams_callback，tensorboard_callback]
        ）

    # 对每组超参数进行训练
    会话编号 = 0
    对于 HP_DROPOUT.domain.values 中的 dropout_rate：
        对于 HP_LEARNING_RATE.domain.values 中的learning_rate：
            hparams = {
                HP_DROPOUT：辍学率，
                HP_LEARNING_RATE：学习率，
            }
            train_test_model(hparams, session_num)
            会话编号 += 1
]]></description>
      <guid>https://stackoverflow.com/questions/78298357/tensorboard-hparams-not-showing-accuracy-metrics-for-hyperparameter-tuning</guid>
      <pubDate>Tue, 09 Apr 2024 12:14:56 GMT</pubDate>
    </item>
    <item>
      <title>使用嵌入实现命名实体识别</title>
      <link>https://stackoverflow.com/questions/78298106/implementating-named-entity-recognition-using-embeddings</link>
      <description><![CDATA[我想使用 OpenAI 的 CLIP 模型对图像文本数据集执行多模态命名实体识别。
我已经将这些图像文本转换为嵌入，但是现在如何对它们执行 NER 呢？或者有更好的方法使用 CLIP 模型吗？]]></description>
      <guid>https://stackoverflow.com/questions/78298106/implementating-named-entity-recognition-using-embeddings</guid>
      <pubDate>Tue, 09 Apr 2024 11:27:27 GMT</pubDate>
    </item>
    <item>
      <title>标签未包含在我的张量数据集中</title>
      <link>https://stackoverflow.com/questions/78297824/label-not-included-inside-my-tensor-dataset</link>
      <description><![CDATA[所以我是机器学习的新手，我想使用 BERT 模型中的预训练模型，然后我遇到了标签输出未插入张量类型数据集的问题。有没有人有解决办法？
from sklearn.model_selection import train_test_split
X = 特征[&#39;clean_text&#39;]
y = 特征[&#39;标签&#39;]
X_train、X_test、y_train、y_test=train_test_split(X、y、test_size = 0.3、random_state = 42)
X_train = tokenizer(X_train.tolist(), 填充 = True, 截断 = True)
X_test = tokenizer(X_test.tolist(), 填充 = True, 截断 = True)
X_train = 字典(X_train)
X_test = 字典(X_test)
y_train = y_train.tolist()
y_test = y_test.tolist()
df_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))
df_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))
输入，输出=下一个（iter（df_train））
打印出）

输出如下：tf.Tensor(0, shape=(), dtype=int32)]]></description>
      <guid>https://stackoverflow.com/questions/78297824/label-not-included-inside-my-tensor-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 10:36:28 GMT</pubDate>
    </item>
    <item>
      <title>使用哪种算法来检测汽车多媒体启动时侧边栏的出现？</title>
      <link>https://stackoverflow.com/questions/78297772/which-algorithm-to-use-to-detect-the-appearance-of-sidebar-on-car-multimedia-boo</link>
      <description><![CDATA[我需要创建一个系统来检测从启动汽车多媒体系统到侧边栏首次出现在屏幕上之间所经过的时间。侧边栏具有矩形形状，并且始终位于屏幕的边缘之一。根据汽车制造商的不同，多媒体的外观也有所不同。我想知道如果我不关心执行速度或实时工作，哪种图像检测算法最合适。
SSD、Faster R-CNN、YOLO 还是其他？]]></description>
      <guid>https://stackoverflow.com/questions/78297772/which-algorithm-to-use-to-detect-the-appearance-of-sidebar-on-car-multimedia-boo</guid>
      <pubDate>Tue, 09 Apr 2024 10:25:32 GMT</pubDate>
    </item>
    <item>
      <title>识别和清理数据集中有问题的三元组</title>
      <link>https://stackoverflow.com/questions/78297420/identifying-and-cleaning-problematic-triplets-in-a-dataset</link>
      <description><![CDATA[我有三元组（嵌入、嵌入、相关标志）我有大约 5k 个这样的三元组。
有一些三元组（一些少量）实际上并不相关，但在我的数据中显示为相关。
嵌入维度为512。
什么是不相关我认为没有问题。
有什么想法可以找到那些被怀疑是错误的有问题的三元组，可以手动检查和清理。
我尝试构建分类器，但它们的性能不太好。]]></description>
      <guid>https://stackoverflow.com/questions/78297420/identifying-and-cleaning-problematic-triplets-in-a-dataset</guid>
      <pubDate>Tue, 09 Apr 2024 09:23:02 GMT</pubDate>
    </item>
    <item>
      <title>某些模型是否会在相同数据上过度拟合而另一些模型则不然？</title>
      <link>https://stackoverflow.com/questions/78296935/can-some-models-overfit-and-others-not-on-the-same-data</link>
      <description><![CDATA[我正在使用 scikit learn 构建 ML 模型。根据特征重要性删除一些特征并尝试避免多重共线性后，一些模型显示出过度拟合的迹象，而另一些则没有。我仍然可以相信其中一个模型（在我的例子中是梯度增强回归器）非常适合数据吗？
对模型进行初步训练后，我得到了训练和测试数据的这些指标：
所有型号
然后，我排除了出现过拟合迹象的模型，只剩下这三个最佳模型：
前三名模型
训练、测试和验证数据之间是否有足够的一致性来选择梯度增强回归器作为最佳模型？]]></description>
      <guid>https://stackoverflow.com/questions/78296935/can-some-models-overfit-and-others-not-on-the-same-data</guid>
      <pubDate>Tue, 09 Apr 2024 08:04:55 GMT</pubDate>
    </item>
    <item>
      <title>如何计算二元分类概率[关闭]</title>
      <link>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</link>
      <description><![CDATA[我正在研究一些基于数值特征的二元分类问题，例如预测维护、信用卡欺诈、心脏病等。我通常喜欢使用随机森林，因为它用途广泛、稳健且可以获得高指标。
除了预测1或0之外，我还想预测获得1的概率（在0.00到1.00之间浮动）。如何在代码中实现这一点？
我使用了随机森林分类器的predict_proba()方法。然而，它主要产生极值（0.00 - 0.10 和 0.90 - 1.00）。 也许它没有很好地校准？另外，我使用了SVM分类器的decision_function()方法，但SVM似乎不是很通用。因此我正在寻找一种不同的方法。
我更喜欢与 RF 分类器相关的方法，但我对其他方法持开放态度。
这是我的代码的相关部分：
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

校准器 = CaliberatedClassifierCV(rf, cv=&#39;prefit&#39;)
模型 = calibrator.fit(X_train, y_train)

概率 = model.predict_proba(X_test)

y_pred = model.predict(X_test)
]]></description>
      <guid>https://stackoverflow.com/questions/78296900/how-to-calculate-binary-classification-probabilites</guid>
      <pubDate>Tue, 09 Apr 2024 07:56:47 GMT</pubDate>
    </item>
    <item>
      <title>如何在各个图表上绘制多个线性回归特征与预测结果</title>
      <link>https://stackoverflow.com/questions/78296899/how-to-plot-multiple-linear-regression-features-vs-predicted-results-on-individu</link>
      <description><![CDATA[我正在研究一个电视广告数据集，该数据集具有 3 个特征（电视、广播、报纸）和 1 个因变量（销售额）。通过使用多元线性回归，我找到了预测销售额，并将其与 y_test 数据集上的实际值进行了比较。我已经确认我的模型获得了很高的 r2 分数。
我知道在多元线性回归中，多个特征可以在更高维度的图上可视化。但是，我希望在单独的图表上查看每个单独的特征与预测结果。
导入pandas
导入numpy
从 sklearn.model_selection 导入 train_test_split
从 sklearn. Linear_model 导入 LinearRegression
从 sklearn.metrics 导入 r2_score
将 statsmodels.api 导入为 sm
将 matplotlib.pyplot 导入为 plt

#导入数据集并分配给X和y
df = pandas.read_csv(“广告.csv”)
df = df.drop(df.columns[[0]], 轴=1)
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].值

#将数据集分割成X_train, X_test, y_train, y_test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

#初始化回归器并使用 X_train 和 y_train 对其进行训练
回归器=线性回归()
回归器.fit(X_train, y_train)

#预测测试结果并用实际值绘制它们
y_pred = 回归器.预测(X_test)
print(&quot;预测值/实际值&quot;)
print(numpy.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), axis=1))

#评估预测结果的模型性能
r_squared_线性 = r2_score(y_test, y_pred)
print(f“多元线性回归模型性能为{r_squared_线性}”)

#查看OLS回归结果
mod = sm.OLS(y.reshape(-1, 1), X)
res = mod.fit()
打印（res.summary（））

#在各个图表上绘制数据集的每个特征与预测结果


这是我的代码，它可以正常工作。我只想用 matplotlib 完成绘图部分。我想绘制每个单独的特征（电视、广播、报纸）与模型预测的 y_pred 值的关系图，包括每个图上的线性回归线。
如果有人能向我展示如何使用 for 循环（以确保它适用于不同数据集上的任何特征计数），我将不胜感激。
此外，为了获得额外的知识，我如何使用 y_pred 结果绘制同一图中的所有特征？]]></description>
      <guid>https://stackoverflow.com/questions/78296899/how-to-plot-multiple-linear-regression-features-vs-predicted-results-on-individu</guid>
      <pubDate>Tue, 09 Apr 2024 07:56:36 GMT</pubDate>
    </item>
    <item>
      <title>性能是评估分类模型（ML模型？）的唯一方法</title>
      <link>https://stackoverflow.com/questions/78296359/is-performance-the-only-way-to-evaluate-classification-modelml-model</link>
      <description><![CDATA[我想知道如何评估某个分类模型是否做得“好”。
通常，精度、AUC-ROC等性能通常用于评估，但我认为过拟合的模型表现出了良好的性能。
所以我想知道如何知道模型本身制作得好不好。评估模型有什么标准吗？
Chatgpt 向我展示了一些标准，例如通用性、可扩展性、稳健性，但我想从可靠的研究论文中更多地了解它。可以推荐一下吗？]]></description>
      <guid>https://stackoverflow.com/questions/78296359/is-performance-the-only-way-to-evaluate-classification-modelml-model</guid>
      <pubDate>Tue, 09 Apr 2024 05:58:26 GMT</pubDate>
    </item>
    <item>
      <title>如何解决问题：RuntimeWarning：在标量乘法中遇到溢出</title>
      <link>https://stackoverflow.com/questions/78296161/how-to-solve-the-issue-runtimewarning-overflow-encountered-in-scalar-multiply</link>
      <description><![CDATA[257：用户警告：n_fft=2048 对于长度=3 的输入信号来说太大
警告.警告(
C:\Users\shrey\OneDrive\Desktop\ML_Projects\EmotionDetector\Audio_Video\myenv\lib\site-packages\librosa\core\spectrum.py:371: RuntimeWarning: 标量乘法中遇到溢出
util.MAX_MEM_BLOCK // (np.prod(y_frames.shape[:-1]) * y_frames.itemsize)
我想打开 Gui 窗口，要求用户打开视频，分析视频中人的声音并检测情绪]]></description>
      <guid>https://stackoverflow.com/questions/78296161/how-to-solve-the-issue-runtimewarning-overflow-encountered-in-scalar-multiply</guid>
      <pubDate>Tue, 09 Apr 2024 04:52:23 GMT</pubDate>
    </item>
    <item>
      <title>NLP挑战解决方案[关闭]</title>
      <link>https://stackoverflow.com/questions/78296037/nlp-challenge-solution</link>
      <description><![CDATA[简介
本次任务的目标
是客观评估你的技术实力以及使用状态解决业务问题的能力
最先进的 NLP 技术、数据库和潜在的定制机器学习。
请注意，主题、数据和问题反映了正在进行的案例。
任务
我们正在构建一个最先进的对话式聊天机器人，该机器人使用涵盖以下内容的财务文件
交易。聊天机器人的目标是以最高精度回答用户问题（保持真实
文件）。
您手头有两个 pdf 文件，描述了与金融交易相关的风险因素（两个文档
每个人都有自己的交易），我们的聊天机器人的用户希望根据相关知识获得答案
文件。
例子
用户：向我展示 rsik 因素的概要
聊天机器人：第一份文件中概述的风险因素是：

...
…
A。 ……
b. ...
…
第二份文件中概述的风险因素是：
...
...
…
A。 ……
b. ……
C。 ……
d. ...
…
A。 ……
b. ……
我。 ...
…
为了帮助您入门，请使用这些问题来开始您的旅程。
您将选择什么技术来构建 chatot 的基础？
您将选择什么技术来制作模型？
现在，假设您拥有可以回答用户问题的语言模型
问题。
A。您将选择什么指标来评估它
b.您将使用什么数据集（也许您应该构建一个）
在某个时刻，您将需要一个数据库来存储文档（因为我们将添加更多
文件：本次挑战赛仅提供 2 份文件）：
A。这个数据库是什么？
b.请详细说明您的选择与其他替代方案相比的优势。

提示

探索最先进的解决方案以及该领域目前正在发生的事情
A。开放人工智能
b.骆驼指数
C。朗查恩
d. ...等等
向我们展示您的编码技能
传达您的思维过程
发挥自己的优势 - 花更多时间研究模型、数据库、对话式 AI 或
根据您的技能进行检索/搜索

我的问题：
有人可以帮助我解决这个挑战吗？我对使用 llama 索引或 langchain 感到困惑，或者有更好的解决方案，并对数据库选择感到困惑]]></description>
      <guid>https://stackoverflow.com/questions/78296037/nlp-challenge-solution</guid>
      <pubDate>Tue, 09 Apr 2024 04:01:19 GMT</pubDate>
    </item>
    <item>
      <title>启动 Tensorflow Extended Evaluator 组件时出错</title>
      <link>https://stackoverflow.com/questions/78291105/error-when-starting-tensorflow-extended-evaluator-component</link>
      <description><![CDATA[]]></description>
      <guid>https://stackoverflow.com/questions/78291105/error-when-starting-tensorflow-extended-evaluator-component</guid>
      <pubDate>Mon, 08 Apr 2024 08:14:42 GMT</pubDate>
    </item>
    <item>
      <title>NeuralProphet 中的多变量预测</title>
      <link>https://stackoverflow.com/questions/78281016/multivariate-forecast-in-neuralprophet</link>
      <description><![CDATA[我正在尝试构建一个全局模型来同时预测两个时间序列。下面的代码运行没有错误。但预测数据帧的所有 NaN 都对应于两个 ID 之一（即有两个时间序列）。 yhat 值也全部为 NaN。我做错了什么或遗漏了什么吗？
m = NeuralProphet(
    yearly_seasonality=真，
    week_seasonality=真，
    daily_seasonality=假，
    分位数=分位数，
    n_lags=60,
    纪元=100，
    n_预测=30，
    loss_func=&#39;胡贝尔&#39;,
）
m.set_plotting_backend(&#39;绘图&#39;)
m.highlight_nth_step_ahead_of_each_forecast(step_number=10)

指标 = m.fit(train_df[[&#39;ds&#39;, &#39;y&#39;, &#39;ID&#39;]])

df_future = m.make_future_dataframe(
    火车_df，
    n_historic_predictions=真，
）

预测 = m.predict(df_future)
]]></description>
      <guid>https://stackoverflow.com/questions/78281016/multivariate-forecast-in-neuralprophet</guid>
      <pubDate>Fri, 05 Apr 2024 15:44:18 GMT</pubDate>
    </item>
    <item>
      <title>我如何提取边界框的 x 和 y 坐标</title>
      <link>https://stackoverflow.com/questions/78266928/how-do-i-extract-the-x-and-y-coordinates-of-the-bounding-boxes</link>
      <description><![CDATA[我的代码定义了一个 ROS 节点，用于使用 YOLO 算法在图像中进行对象检测，特别是使用从指定文件路径加载的 YOLO 模型。该节点订阅了广播图像的 ROS 主题 (/camera/color/image_raw)。收到图像后，会触发回调函数，使用 CvBridge 将 ROS 图像消息转换为 OpenCV 图像格式。然后该图像由 YOLO 模型处理以检测对象。结果（包括检测到的对象框）将打印到控制台。为了防止连续处理和重新处理图像，在处理第一个图像后设置一个标志（image_processed）。此外，处理后的图像将保存到指定的文件夹（临时）。该节点保持活动状态，侦听新图像，直到手动关闭。
#!/usr/bin/python3
导入罗斯比
从sensor_msgs.msg导入图像
从 cv_bridge 导入 CvBridge
导入CV2
导入操作系统
从 ultralytics 导入 YOLO

类节点（对象）：
    def __init__(自身):
        self.yolo_model = YOLO(&#39;/home/user/catkin_ws/src/run_folder/content/runs/obb/train/weights/best.pt&#39;)
        self.br = CvBridge()
        self.image_processed = False # 指示图像是否已处理的标志

        # 订阅发布图像的ROS主题
        rospy.Subscriber(“/camera/color/image_raw”, Image, self.callback)

    def 回调（自身，消息）：
        if not self.image_processed: # 仅当尚未处理图像时才处理
            image = self.br.imgmsg_to_cv2(msg) # 将ROS图像消息转换为OpenCV图像

            # 使用 YOLO 进行物体检测
            结果= self.yolo_model.predict（图像，显示= True）
            对于结果 [0] 中的 r：
                打印（“---------------------------”）
                打印（r.boxes）

            # 第一次处理后保存图像
            self.save_image(图像, &#39;临时&#39;)
            self.image_processed = True # 将标志设置为 True 以避免重新处理

    def save_image(自身, 图像, 文件夹名称):
        如果不是 os.path.exists(folder_name):
            os.makedirs(文件夹名称)
        
        file_path = os.path.join(folder_name, &#39;image.jpg&#39;)
        cv2.imwrite（文件路径，图像）
        print(f“图像保存在{file_path}”)

如果 __name__ == &#39;__main__&#39;:
    rospy.init_node（“image_processor_with_yolo”，匿名= True）
    节点 = 节点()
    rospy.spin() # 保持节点运行直到关闭


当我尝试提取边界框时，我得到“无”在输出中。]]></description>
      <guid>https://stackoverflow.com/questions/78266928/how-do-i-extract-the-x-and-y-coordinates-of-the-bounding-boxes</guid>
      <pubDate>Wed, 03 Apr 2024 10:11:55 GMT</pubDate>
    </item>
    <item>
      <title>控制 Scikit Learn 中逻辑回归的阈值</title>
      <link>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</link>
      <description><![CDATA[我在高度不平衡的数据集上使用 scikit-learn 中的 LogisticRegression() 方法。我什至将 class_weight 功能设置为 auto。
我知道在逻辑回归中应该可以知道特定类对的阈值是多少。 
是否可以知道 LogisticRegression() 方法设计的每个一对一类的阈值是多少？
我在文档页面中没有找到任何内容。
默认情况下，无论参数值如何，它是否都会应用 0.5 值作为所有类的阈值？]]></description>
      <guid>https://stackoverflow.com/questions/28716241/controlling-the-threshold-in-logistic-regression-in-scikit-learn</guid>
      <pubDate>Wed, 25 Feb 2015 10:11:33 GMT</pubDate>
    </item>
    </channel>
</rss>